
Feedback Control
of Dynamic Systems
Seventh Edition
Gene F. Franklin
Stanford University
J. David Powell
Stanford University
Abbas Emami-Naeini
SC Solutions, Inc.
Boston
Columbus
Indianapolis
New York
San Francisco
Upper Saddle River
Amsterdam
Cape Town
Dubai
London
Madrid
Milan
Munich
Paris
Montreal
Toronto
Delhi
Mexico City
São Paulo
Sydney
Hong Kong
Seoul
Singapore
Taipei
Tokyo

Vice President and Editorial Director,
Operations Specialist: Linda Sager
ECS: Marcia J. Horton
Cover Designer: Black Horse Designs
Executive Editor: Holly Stark
Permissions Project Manager: Rachel Youdelman
Editorial Assistant: Sandra Rodriguez
Full-service Project Management:
Executive Marketing Manager: Tim Galligan
Pavithra Jayapaul
Marketing Assistant: Jon Bryant
Composition: Jouve India
Senior Managing Editor: Scott Disanno
Printer/Binder: Courier Westford
Production Program Manager: Clare Romeo
Cover Printer: PhoenixColor Hagerstown
Production Project Manager: Rose Kernan
Typeface: 10/12 Times
Director of Operations: Nick Sklitsis
Copyright © 2015, 2010, 1999 by Pearson Higher Education, Inc., Upper Saddle River, NJ 07458.All rights reserved. Manufactured
in the United States of America. This publication is protected by Copyright and permissions should be obtained from the publisher
prior to any prohibited reproduction, storage in a retrieval system, or transmission in any form or by any means, electronic,
mechanical, photocopying, recording, or likewise. To obtain permission(s) to use materials from this work, please submit a written
request to Pearson Higher Education, Permissions Department, One Lake Street, Upper Saddle River, NJ 07458.
Many of the designations by manufacturers and seller to distinguish their products are claimed as trademarks. Where those
designations appear in this book, and the publisher was aware of a trademark claim, the designations have been printed in initial
caps or all caps.
The author and publisher of this book have used their best efforts in preparing this book. These efforts include the development,
research, and testing of theories and programs to determine their effectiveness. The author and publisher make no warranty of any
kind, expressed or implied, with regard to these programs or the documentation contained in this book. The author and publisher
shall not be liable in any event for incidental or consequential damages with, or arising out of, the furnishing, performance, or use
of these programs.
Cover photos courtesy of: Surgery robot, DigitalArt/Corbis; NASA's Grover, Lora Koenig/NASA Goddard/NASA; Delivery drone,
Mipan/Fotolia; SpaceShipOne, Henning Dalhoff/Science Source/Photo Researchers, Inc.
Pearson Education Ltd., London
Pearson Education Singapore, Pte. Ltd
Pearson Education Canada, Inc.
Pearson Education—Japan
Pearson Education Australia PTY, Limited
Pearson Education North Asia, Ltd., Hong Kong
Pearson Educación de Mexico, S.A. de C.V.
Pearson Education Malaysia, Pte. Ltd.
Pearson Education, Inc., Upper Saddle River, New Jersey
Library of Congress Cataloging-in-Publication Data
Franklin, Gene F.
Feedback control of dynamic systems / Gene F. Franklin, J. David Powell,
Abbas Emami-Naeini. — Seventh edition.
pages cm
Includes bibliographical references and index.
ISBN-13: 978-0-13-349659-8
ISBN-10: 0-13-349659-7
1. Feedback control systems.
I. Powell, J. David, 1938-
II. Emami-Naeini, Abbas.
III. Title.
TJ216.F723
2014
629.8'3—dc23
2014004059
Matlab® and Simulink® are registered trademarks of The MathWorks, Inc., 4 Apple Hill Drive, Natick, MA.
10 9 8 7 6 5 4 3 2 1
ISBN:978-0-13-349659-8
ISBN:
0-13-349659-7

To the memory of Gene F. Franklin

This page intentionally left blank

Contents
Preface
xiii
1
An Overview and Brief History of Feedback Control
1
A Perspective on Feedback Control
1
Chapter Overview
2
1.1
A Simple Feedback System
3
1.2
A First Analysis of Feedback
6
1.3
Feedback System Fundamentals
10
1.4
A Brief History
11
1.5
An Overview of the Book
17
Summary
19
Review Questions
19
Problems
20
2
Dynamic Models
23
A Perspective on Dynamic Models
23
Chapter Overview
24
2.1
Dynamics of Mechanical Systems
24
2.1.1
Translational Motion
24
2.1.2
Rotational Motion
31
2.1.3
Combined Rotation and Translation
39
2.1.4
Complex Mechanical Systems (W)**
42
2.1.5
Distributed Parameter Systems
42
2.1.6
Summary: Developing Equations of Motion
for Rigid Bodies
44
2.2
Models of Electric Circuits
45
2.3
Models of Electromechanical Systems
50
2.3.1
Loudspeakers
50
2.3.2
Motors
52
2.3.3
Gears
56
△
2.4
Heat and Fluid-Flow Models
57
△
2.4.1
Heat Flow
58
2.4.2
Incompressible Fluid Flow
61
2.5
Historical Perspective
68
Summary
71
Review Questions
71
Problems
72
**Sectionswith(W)indicatesthatadditionalmaterialislocatedonthewebatwww.FPE7e.com.
v

vi
Contents
3
Dynamic Response
84
A Perspective on System Response
84
Chapter Overview
85
3.1
Review of Laplace Transforms
85
3.1.1
Response by Convolution
86
3.1.2
Transfer Functions and Frequency Response
91
3.1.3
The L−Laplace Transform
101
3.1.4
Properties of Laplace Transforms
103
3.1.5
Inverse Laplace Transform by Partial-Fraction
Expansion
105
3.1.6
The Final Value Theorem
107
3.1.7
Using Laplace Transforms to Solve Differential
Equations
109
3.1.8
Poles and Zeros
111
3.1.9
Linear System Analysis Using Matlab®
112
3.2
System Modeling Diagrams
118
3.2.1
The Block Diagram
118
3.2.2
Block-Diagram Reduction Using Matlab
122
3.2.3
Mason's Rule and the Signal Flow Graph (W)
123
3.3
Effect of Pole Locations
123
3.4
Time-Domain Speciﬁcations
131
3.4.1
Rise Time
132
3.4.2
Overshoot and Peak Time
132
3.4.3
Settling Time
134
3.5
Effects of Zeros and Additional Poles
137
3.6
Stability
146
3.6.1
Bounded Input-Bounded Output Stability
147
3.6.2
Stability of LTI Systems
148
3.6.3
Routh's Stability Criterion
149
3.7
Obtaining Models from Experimental Data:
△
System Identiﬁcation (W)
156
3.8
Amplitude and Time Scaling (W)
156
△
3.9
Historical Perspective
156
Summary
157
Review Questions
159
Problems
159
4
A First Analysis of Feedback
180
A Perspective on the Analysis of Feedback
180
Chapter Overview
181
4.1
The Basic Equations of Control
182
4.1.1
Stability
183
4.1.2
Tracking
184
4.1.3
Regulation
185
4.1.4
Sensitivity
186

Contents
vii
4.2
Control of Steady-State Error to Polynomial Inputs:
System Type
188
4.2.1
System Type for Tracking
189
4.2.2
System Type for Regulation and Disturbance
Rejection
194
4.3
The Three-Term Controller: PID Control
196
4.3.1
Proportional Control (P)
196
4.3.2
Integral Control (I)
198
4.3.3
Derivative Control (D)
201
4.3.4
Proportional Plus Integral Control (PI)
201
4.3.5
PID Control
202
4.3.6
Ziegler-Nichols Tuning of the PID
Controller
206
4.4
Feedforward Control by Plant Model Inversion
212
4.5
Introduction to Digital Control (W)
214
△
4.6
Sensitivity of Time Response to Parameter Change (W)
215
△
4.7
Historical Perspective
215
Summary
217
Review Questions
218
Problems
218
5
The Root-Locus Design
Method
234
A Perspective on the Root-Locus Design Method
234
Chapter Overview
235
5.1
Root Locus of a Basic Feedback System
235
5.2
Guidelines for Determining a Root Locus
240
5.2.1
Rules for Determining a Positive (180◦)
Root Locus
242
5.2.2
Summary of the Rules for Determining a
Root Locus
248
5.2.3
Selecting the Parameter Value
249
5.3
Selected Illustrative Root Loci
251
5.4
Design Using Dynamic Compensation
264
5.4.1
Design Using Lead Compensation
266
5.4.2
Design Using Lag Compensation
270
5.4.3
Design Using Notch Compensation
272
5.4.4
Analog and Digital Implementations (W)
274
△
5.5
A Design Example Using the Root Locus
275
5.6
Extensions of the Root-Locus Method
281
5.6.1
Rules for Plotting a Negative (0◦)
Root Locus
281
5.6.2
Consideration of Two Parameters
284
△
5.6.3
Time Delay (W)
286
△
5.7
Historical Perspective
287

viii
Contents
Summary
289
Review Questions
290
Problems
291
6
The Frequency-Response
Design Method
308
A Perspective on the Frequency-Response Design Method
308
Chapter Overview
309
6.1
Frequency Response
309
6.1.1
Bode Plot Techniques
317
6.1.2
Steady-State Errors
330
6.2
Neutral Stability
331
6.3
The Nyquist Stability Criterion
333
6.3.1
The Argument Principle
334
6.3.2
Application of The Argument Principle
to Control Design
335
6.4
Stability Margins
348
6.5
Bode's Gain-Phase Relationship
357
6.6
Closed-Loop Frequency Response
361
6.7
Compensation
363
6.7.1
PD Compensation
363
6.7.2
Lead Compensation (W)
364
6.7.3
PI Compensation
374
6.7.4
Lag Compensation
375
6.7.5
PID Compensation
381
6.7.6
Design Considerations
387
6.7.7
Speciﬁcations in Terms of the Sensitivity
△
Function
389
6.7.8
Limitations on Design in Terms of the Sensitivity
△
Function
394
6.8
Time Delay
398
△
6.8.1
Time Delay via the Nyquist Diagram (W)
400
6.9
Alternative Presentation of Data
400
△
6.9.1
Nichols Chart
400
6.9.2
The Inverse Nyquist Diagram (W)
404
6.10
Historical Perspective
404
Summary
405
Review Questions
408
Problems
408
7
State-Space Design
433
A Perspective on State-Space Design
433
Chapter Overview
434
7.1
Advantages of State-Space
434
7.2
System Description in State-Space
436
7.3
Block Diagrams and State-Space
442

Contents
ix
7.4
Analysis of the State Equations
444
7.4.1
Block Diagrams and Canonical Forms
445
7.4.2
Dynamic Response from the State
Equations
457
7.5
Control-Law Design for Full-State Feedback
463
7.5.1
Finding the Control Law
464
7.5.2
Introducing the Reference Input with Full-State
Feedback
473
7.6
Selection of Pole Locations for Good Design
477
7.6.1
Dominant Second-Order Poles
477
7.6.2
Symmetric Root Locus (SRL)
479
7.6.3
Comments on the Methods
488
7.7
Estimator Design
489
7.7.1
Full-Order Estimators
489
7.7.2
Reduced-Order Estimators
495
7.7.3
Estimator Pole Selection
499
7.8
Compensator Design: Combined Control
Law and Estimator (W)
501
7.9
Introduction of the Reference Input
with the Estimator (W)
514
7.9.1
General Structure for the Reference Input
515
7.9.2
Selecting the Gain
524
7.10
Integral Control and Robust Tracking
525
7.10.1 Integral Control
526
7.10.2 Robust Tracking Control: The Error-Space
△
Approach
528
7.10.3 Model-Following Design
539
△
7.10.4 The Extended Estimator
543
△
7.11
Loop Transfer Recovery
547
△
7.12
Direct Design with Rational Transfer
△
Functions
552
7.13
Design for Systems with Pure Time Delay
556
△
7.14
Solution of State Equations (W)
559
7.15
Historical Perspective
559
Summary
562
Review Questions
565
Problems
566
8
Digital Control
590
A Perspective on Digital Control
590
Chapter Overview
591
8.1
Digitization
591
8.2
Dynamic Analysis of Discrete Systems
594
8.2.1
z-Transform
594
8.2.2
z-Transform Inversion
595

x
Contents
8.2.3
Relationship Between s and z
597
8.2.4
Final Value Theorem
599
8.3
Design Using Discrete Equivalents
601
8.3.1
Tustin's Method
602
8.3.2
Zero-Order Hold (ZOH) Method
605
8.3.3
Matched Pole-Zero (MPZ) Method
607
8.3.4
Modiﬁed Matched Pole-Zero
(MMPZ) Method
611
8.3.5
Comparison of Digital Approximation
Methods
612
8.3.6
Applicability Limits of the Discrete Equivalent
Design Method
613
8.4
Hardware Characteristics
613
8.4.1
Analog-to-Digital (A/D) Converters
614
8.4.2
Digital-to-Analog Converters
614
8.4.3
Anti-Alias Preﬁlters
615
8.4.4
The Computer
616
8.5
Sample-Rate Selection
617
8.5.1
Tracking Effectiveness
618
8.5.2
Disturbance Rejection
618
8.5.3
Effect of Anti-Alias Preﬁlter
619
8.5.4
Asynchronous Sampling
620
8.6
Discrete Design
620
△
8.6.1
Analysis Tools
621
8.6.2
Feedback Properties
622
8.6.3
Discrete Design Example
623
8.6.4
Discrete Analysis of Designs
626
8.7
Discrete State-Space Design Methods (W)
628
8.8
Historical Perspective
628
Summary
629
Review Questions
631
Problems
631
9
Nonlinear Systems
637
A Perspective on Nonlinear Systems
637
Chapter Overview
638
9.1
Introduction and Motivation: Why Study
Nonlinear Systems?
639
9.2
Analysis by Linearization
641
9.2.1
Linearization by Small-Signal Analysis
641
9.2.2
Linearization by Nonlinear Feedback
646
9.2.3
Linearization by Inverse Nonlinearity
647
9.3
Equivalent Gain Analysis Using the Root
Locus
648
9.3.1
Integrator Antiwindup
655

Contents
xi
9.4
Equivalent Gain Analysis Using Frequency
Response: Describing Functions
658
9.4.1
Stability Analysis Using Describing
Functions
665
9.5
Analysis and Design Based on Stability
670
△
9.5.1
The Phase Plane
670
9.5.2
Lyapunov Stability Analysis
677
9.5.3
The Circle Criterion
683
9.6
Historical Perspective
690
Summary
691
Review Questions
691
Problems
692
10
Control System Design: Principles and Case
Studies
703
A Perspective on Design Principles
703
Chapter Overview
704
10.1
An Outline of Control Systems
Design
705
10.2
Design of a Satellite's Attitude
Control
711
10.3
Lateral and Longitudinal Control
of a Boeing 747
729
10.3.1 Yaw Damper
733
10.3.2 Altitude-Hold Autopilot
741
10.4
Control of the Fuel-Air Ratio
in an Automotive Engine
747
10.5
Control of the Read/Write Head Assembly
of a Hard Disk
755
10.6
Control of RTP Systems in Semiconductor Wafer
Manufacturing
763
10.7
Chemotaxis or How E. Coli Swims Away
from Trouble
777
10.8
Historical Perspective
786
Summary
788
Review Questions
790
Problems
790
Appendix A
Laplace Transforms
804
A.1
The L−Laplace Transform
804
A.1.1
Properties of Laplace Transforms
805
A.1.2
Inverse Laplace Transform by Partial-Fraction
Expansion
813
A.1.3
The Initial Value Theorem
816
A.1.4
Final Value Theorem
817

xii
Contents
Appendix B
Solutions to the Review Questions
819
Appendix C
Matlab Commands
835
Bibliography
840
Index
848
ListofAppendicesonthewebatwww.fpe7e.com
Appendix WA: A Review of Complex Variables
Appendix WB: Summary of Matrix Theory
Appendix WC: Controllability and Observability
Appendix WD: Ackermann's Formula for Pole Placement
Appendix W2.1.4: Complex Mechanical Systems
Appendix W3.2.3: Mason's Rule and Signal Flow Graph
Appendix W3.6.3.1: Routh Special Cases
Appendix W3.7: System Identiﬁcation
Appendix W3.8: Amplitude and Time Scaling
Appendix W4.1.4.1: The Filtered Case
Appendix W4.2.2.1: Truxal's Formula for the Error
Constants
Appendix W4.5: Introduction to Digital Control
Appendix W4.6: Sensitivity of Time Response to Parameter
Change
Appendix W5.4.4: Analog and Digital Implementations
Appendix W5.6.3: Root Locus with Time Delay
Appendix W6.7.2: Digital Implementation of
Example 6.15
Appendix W6.8.1: Time Delay via the Nyquist Diagram
Appendix W6.9.2: The Inverse Nyquist Diagram
Appendix W7.8: Digital Implementation of Example 7.31
Appendix W7.9: Digital Implementation of Example 7.33
Appendix W7.14: Solution of State Equations
Appendix W8.7: Discrete State-Space Design Methods

Preface
In this Seventh Edition we again present a text in support of a ﬁrst course
in control and have retained the best features of our earlier editions. For this
edition, we have responded to a survey of users by adding some material (for
example, gears in Chapter 2) and moved other little-used material from the
printed book (for example, digital control in the early chapters) to a website
that is fully accessible to readers. We have also updated the text throughout
so that it uses the improved features of Matlab®. But perhaps the biggest jolt
to our readers is that we succumbed to the times, and changed the notation
used for the state-space description from (F, G, H, J) to (A, B, C, D)! In
past editions, our loyalty to the early pioneers in the state-space approach
overwhelmed our ability to accept reality, and we stayed with the classical
notation. However, for this edition, we decided the time has come to accept
the reality that the dominant notation in the ﬁeld today is (A, B, C, D) as is
the notation in Matlab. We have also added a section on feedfoward control
to Chapter 4 and a model-following section to Chapter 7. In addition, the
presentation of PID control has been improved as has some of the Laplace
transform material. We strive to equip control system designers with the
theory, basic design methods, and an introduction to computer-aided design
methods. At the same time, we also strive to equip designers with a basic
understanding so that computer results can be guided and veriﬁed. The case
studies in Chapter 10 have been retained and updated where needed. Finally,
in order to guide the reader in ﬁnding speciﬁc topics, both in the text and on
our website, we have expanded the table of contents to include entries for
material that is on the website as well as in the printed book.
Thebasicstructureofthebookisunchangedandwecontinuetocombine
analysis with design using the three approaches of the root locus, frequency
response, and state-variable equations. The text continues to include many
carefully worked out examples to illustrate the material. As before, we pro-
vide a set of review questions at the end of each chapter with answers in the
back of the book to assist the students in verifying that they have learned the
material.
In the three central chapters on design methods we continue to expect
the students to learn how to perform the very basic calculations by hand
and make a rough sketch of a root locus or Bode plot as a sanity check
on the computer results and as an aid to design. However, we introduce
the use of Matlab early on in recognition of the universal use of software
tools in control analysis and design. Furthermore, in recognition of the fact
that very few instructors were using the early material on Digital Control
in Chapters 4, 5, and 6 in the sixth edition, that material was moved to
our website and Chapter 8 was modiﬁed so that it provides a stand-alone
introduction to Digital Control. For those instructors wanting to include the
digital implementation of controllers early in their teaching, the material can
xiii

xiv
Preface
www.FPE7e.com QR Code
be downloaded and used without change from the order that existed in the
sixth edition or the students can be directed to the material in Chapter 8.
As before, we have prepared a collection of all the Matlab ﬁles (both "m"
ﬁles and Simulink® "mdl" ﬁles) used to produce the ﬁgures in the book.
These are available along with the advanced material described above at our
website at www.FPE7e.com
New to this Edition
We feel that this Seventh Edition presents the material with good pedagogical
support, provides strong motivation for the study of control, and represents
a solid foundation for meeting the educational challenges. We introduce the
study of feedback control, both as a specialty in itself and as support for
many other ﬁelds.
A more detailed list of the changes is:
•
Added new section on Fundamentals to Chapter 1
•
Added new section on Gears to Chapter 2
•
Updated Matlab commands throughout the book in order to utilize
current capabilities of the software
•
Rewrote section on the Laplace transform and frequency response in
Chapter 3
•
Rewrote section on PID control in Chapter 4
•
Added section on Feedforward control in Chapter 4
•
Moved the section on digital control in Chapter 4 to a dedicated website
for the book (www.FPE7e.com)
•
Revised section in Chapter 4 on the effect of zeros on a system
•
Moved the sections on digital control and time delay in Chapter 5 to the
website
•
Moved the sections on digital control in Chapter 6 to the website
•
Rewrote sections on stability and compensation in Chapter 6 for clarity
and consistency with current standards in the industry
•
Expanded discussion of Nichols plots in Chapter 6
•
Moved sections of digital control in Chapter 7 to the website
•
Revised notation of the state-space system from (F, G, H, J) to
(A, B, C, D) in Chapters 7, 9, and 10.
•
To prevent any ambiguity, the notation for the compensation was
changed from D(s) to Dc(s) throughout the text because of the change
in the state-space notation

Preface
xv
•
Added the model-following procedure to Chapter 7
•
Several sections were rewritten in Chapter 8 for clarity
•
Added section on the ZOH approximate method in Chapter 8
•
Updatedtheenginecontrolexampleandsubstantiallyrevisedthesystem
biology case study in Chapter 10
•
Approximately 20% of the problems in the book are revised or new in
all chapters
Addressing the Educational Challenges
Some of the educational challenges facing students of feedback control are
long-standing; others have emerged in recent years. Some of the challenges
remain for students across their entire engineering education; others are
unique to this relatively sophisticated course. Whether they are old or new,
general or particular, the educational challenges we perceived were critical
to the evolution of this text. Here we will state several educational challenges
and describe our approaches to each of them.
•
CHALLENGE
Students must master design as well as analysis
techniques.
Design is central to all of engineering and especially so to control
systems. Students ﬁnd that design issues, with their corresponding oppor-
tunities to tackle practical applications, are particularly motivating. But
students also ﬁnd design problems difﬁcult because design problem state-
ments are usually poorly posed and lack unique solutions. Because of both its
inherent importance and its motivational effect on students, design is empha-
sized throughout this text so that conﬁdence in solving design problems is
developed from the start.
The emphasis on design begins in Chapter 4 following the development
of modeling and dynamic response. The basic idea of feedback is introduced
ﬁrst, showing its inﬂuence on disturbance rejection, tracking accuracy, and
robustness to parameter changes. The design orientation continues with uni-
form treatments of the root locus, frequency response, and state variable
feedback techniques. All the treatments are aimed at providing the knowl-
edge necessary to ﬁnd a good feedback control design with no more complex
mathematical development than is essential to clear understanding.
Throughout the text, examples are used to compare and contrast the
design techniques afforded by the different design methods and, in the cap-
stone case studies of Chapter 10, complex real-world design problems are
attacked using all the methods in a uniﬁed way.
•
CHALLENGE
New ideas continue to be introduced into control.
Control is an active ﬁeld of research and hence there is a steady inﬂux
of new concepts, ideas, and techniques. In time, some of these elements
develop to the point where they join the list of things every control engineer

xvi
Preface
must know. This text is devoted to supporting students equally in their need
to grasp both traditional and more modern topics.
In each of our editions we have tried to give equal importance to root
locus, frequency response, and state-variable methods for design. In this
edition we continue to emphasize solid mastery of the underlying tech-
niques, coupled with computer-based methods for detailed calculation. We
also provide an early introduction to data sampling and discrete controllers
in recognition of the major role played by digital controllers in our ﬁeld.
While this material can be skipped to save time without harm to the ﬂow of
the text, we feel that it is very important for students to understand that com-
puter control is widely used and that the most basic techniques of computer
control are easily mastered.
•
CHALLENGE
Students need to manage a great deal of information.
The vast array of systems to which feedback control is applied and the
growing variety of techniques available for the solution of control prob-
lems means that today's student of feedback control must learn many new
ideas. How do students keep their perspective as they plow through lengthy
and complex textual passages? How do they identify highlights and draw
appropriate conclusions? How do they review for exams? Helping students
with these tasks was a criterion for the Fourth, Fifth, and Sixth Editions and
continues to be addressed in this Seventh Edition. We outline these features
below.
FEATURE
1. Chapter openers offer perspective and overview. They place the speciﬁc
chapter topic in the context of the discipline as a whole and they brieﬂy
overview the chapter sections.
2. Margin notes help students scan for chapter highlights. They point to
important deﬁnitions, equations, and concepts.
3. Shaded highlights identify key concepts within the running text. They
also function to summarize important design procedures.
4. Bulleted chapter summaries help with student review and prioritization.
These summaries brieﬂy reiterate the key concepts and conclusions of
the chapter.
5. Synopsis of design aids. Relationships used in design and throughout
the book are collected inside the back cover for easy reference.
6. The color blue is used (1) to highlight useful pedagogical features, (2) to
highlight components under particular scrutiny within block diagrams,
(3) to distinguish curves on graphs, and (4) to lend a more realistic look
to ﬁgures of physical systems.
7. Review questions at the end of each chapter with solutions in the back
to guide the student in self-study
8. Historical perspectives at the end of each chapter provide some back-
ground and color on how or why the material in that particular chapter
evolved.

Preface
xvii
•
CHALLENGE
Students of feedback control come from a wide range
of disciplines.
Feedback control is an interdisciplinary ﬁeld in that control is applied
to systems in every conceivable area of engineering. Consequently, some
schools have separate introductory courses for control within the standard
disciplines and some, like Stanford, have a single set of courses taken by
students from many disciplines. However, to restrict the examples to one
ﬁeld is to miss much of the range and power of feedback but to cover the
whole range of applications is overwhelming. In this book we develop the
interdisciplinary nature of the ﬁeld and provide review material for several of
the most common technologies so that students from many disciplines will
be comfortable with the presentation. For Electrical Engineering students
who typically have a good background in transform analysis, we include
in Chapter 2 an introduction to writing equations of motion for mechanical
mechanisms. For mechanical engineers, we include in Chapter 3 a review
of the Laplace transform and dynamic response as needed in control. In
addition, we introduce other technologies brieﬂy and, from time to time, we
present the equations of motion of a physical system without derivation but
with enough physical description to be understood from a response point
of view. Examples of some of the physical systems represented in the text
include the read-write head for a computer disk drive, a satellite tracking
system, the fuel-air ratio in an automobile engine, and an airplane automatic
pilot system.
Outline of the Book
The contents of the printed book are organized into ten chapters and three
appendices. Optional sections of advanced or enrichment material marked
with a triangle (△) are included at the end of some chapters. Examples
and problems based on this material are also marked with a triangle (△).
There are also four full appendices on the website plus numerous appendices
that supplement the material in most of the chapters. The appendices in the
printed book include Laplace transform tables, answers to the end-of-chapter
review questions, and a list of Matlab commands. The appendices on the
website include a review of complex variables, a review of matrix theory,
some important results related to state-space design, and optional material
supporting or extending several of the chapters.
In Chapter 1, the essential ideas of feedback and some of the key design
issues are introduced. This chapter also contains a brief history of control,
from the ancient beginnings of process control to ﬂight control and elec-
tronic feedback ampliﬁers. It is hoped that this brief history will give a
context for the ﬁeld, introduce some of the key ﬁgures who contributed to its
development, and provide motivation to the student for the studies to come.
Chapter 2 is a short presentation of dynamic modeling and includes
mechanical,
electrical,
electromechanical,
ﬂuid,
and thermodynamic

xviii
Preface
devices. This material can be omitted, used as the basis of review home-
work to smooth out the usual nonuniform preparation of students, or covered
in-depth depending on the needs of the students.
Chapter 3 covers dynamic response as used in control. Again, much
of this material may have been covered previously, especially by electri-
cal engineering students. For many students, the correlation between pole
locations and transient response and the effects of extra zeros and poles on
dynamic response represent new material. Stability of dynamic systems is
also introduced in this chapter. This material needs to be covered carefully.
Chapter 4 presents the basic equations and transfer functions of feed-
back along with the deﬁnitions of the sensitivity function. With these tools,
open-loop and closed-loop control are compared with respect to disturbance
rejection, tracking accuracy, and sensitivity to model errors. Classiﬁcation
of systems according to their ability to track polynomial reference signals
or to reject polynomial disturbances is described with the concept of system
type. Finally, the classical proportional, integral, and derivative (PID) con-
trol structure is introduced and the inﬂuence of the controller parameters on a
system's characteristic equation is explored along with PID tuning methods.
Following the overview of feedback in Chapter 4, the core of the book
presents the design methods based on root locus, frequency response, and
state-variable feedback in Chapters 5, 6, and 7, respectively.
Chapter 8 develops the tools needed to design feedback control for
implementation in a digital computer. However, for a complete treatment
of feedback control using digital computers, the reader is referred to the
companion text, Digital Control of Dynamic Systems, by Franklin, Powell,
and Workman; Ellis-Kagle Press, 1998.
In Chapter 9 the nonlinear material includes techniques for the lin-
earization of equations of motion, analysis of zero memory nonlinearity as a
variable gain, frequency response as a describing function, the phase plane,
Lyapunov stability theory, and the circle stability criterion.
In Chapter 10 the three primary approaches are integrated in several
case studies and a framework for design is described that includes a touch
of the real-world context of practical control design.
Course Conﬁgurations
The material in this text can be covered ﬂexibly. Most ﬁrst-course students
in controls will have some dynamics and Laplace transforms. Therefore,
Chapter 2 and most of Chapter 3 would be a review for those students.
In a ten-week quarter, it is possible to review Chapter 3, and cover all of
Chapters 1, 4, 5, and 6. Most optional sections should be omitted. In the
second quarter, Chapters 7 and 9 can be covered comfortably including
the optional sections. Alternatively, some optional sections could be omit-
ted and selected portions of Chapter 8 included. A semester course should
comfortably accommodate Chapters 1-7, including the review materials of
Chapters 2 and 3, if needed. If time remains after this core coverage, some

Preface
xix
introduction of digital control from Chapter 8, selected nonlinear issues from
Chapter 9, and some of the case studies from Chapter 10 may be added.
The entire book can also be used for a three-quarter sequence of courses
consisting of modeling and dynamic response (Chapters 2 and 3), classical
control (Chapters 4-6), and modern control (Chapters 7-10).
Two basic 10-week courses are offered at Stanford and are taken by
seniors and ﬁrst-year graduate students who have not had a course in con-
trol, mostly in the departments ofAeronautics andAstronautics, Mechanical
Engineering, and Electrical Engineering. The ﬁrst course reviews Chapters 2
and 3 and covers Chapters 4-6. The more advanced course is intended for
graduate students and reviews Chapters 4-6 and covers Chapters 7-10. This
sequence complements a graduate course in linear systems and is the prereq-
uisite to courses in digital control, nonlinear control, optimal control, ﬂight
control, and smart product design. Some of the subsequent courses include
extensive laboratory experiments. Prerequisites for the course sequence
include dynamics or circuit analysis and Laplace transforms.
Prerequisites to This Feedback Control Course
Thisbookisforaﬁrstcourseattheseniorlevelforallengineeringmajors. For
the core topics in Chapters 4-7, prerequisite understanding of modeling and
dynamic response is necessary. Many students will come into the course with
sufﬁcient background in those concepts from previous courses in physics,
circuits, and dynamic response. For those needing review, Chapters 2 and 3
should ﬁll in the gaps.
An elementary understanding of matrix algebra is necessary to under-
stand the state-space material. While all students will have much of this
in prerequisite math courses, a review of the basic relations is given in
Appendix WB and a brief treatment of particular material needed in control
is given at the start of Chapter 7. The emphasis is on the relations between
linear dynamic systems and linear algebra.
Supplements
The website mentioned above includes the dot-m and dot-mdl ﬁles used
to generate all the Matlab ﬁgures in the book, and these may be copied
and distributed to the students as desired. The website also contains some
more advanced material and appendices which are outlined in the Table
of Contents. A Solutions Manual with complete solutions to all homework
problems is available to instructors only.
Acknowledgments
Finally, we wish to acknowledge our great debt to all those who have con-
tributed to the development of feedback control into the exciting ﬁeld it
is today and speciﬁcally to the considerable help and education we have

xx
Preface
received from our students and our colleagues. In particular, we have ben-
eﬁted in this effort by many discussions with the following who taught
introductory control at Stanford: A. E. Bryson, Jr., R. H. Cannon, Jr.,
D. B. DeBra, S. Rock, S. Boyd, C. Tomlin, P. Enge, A. Okamura, and
C. Gerdes. Other colleagues who have helped us include D. Fraser, N. C.
Emami, B. Silver, M. Dorfman, D. Brennan, K. Rudie, L. Pao, F. Khorrami,
K. Lorell, M. Tischler, D. de Roover, and P. D. Mathur.
Special thanks go to the many students who have provided almost all
the solutions to the problems in the book.
Tribute to Gene Franklin
It is with great personal sadness that we report the passing of Prof. Gene
Franklin on August 9, 2012. He participated in the initial planning for this
edition and contributed to the rewriting of some of the material in Chapter 3.
Gene was a mentor, teacher, advisor, and good friend to us both. We are
especially proud to have been his friend. We have had a multitude of meetings
as we collaborated on the writing of this textbook's editions over 28 years,
and every single one of those meetings has been friendly and enjoyable. We
each have expressed different viewpoints over the years on how to present
various topics, but we were always able to encompass the views into the book
in a friendly and collaborative manner. We learned control along with humor
from Gene in grad school classes, and we beneﬁtted from his mentoring: in
one case as a new Assistant Professor, and in the other as a Ph.D. advisee.
Collectively, we have collaborated on research, created new courses and
laboratories, and written two textbooks over a period of 40 years. Gene
always had a smile with a twinkle in his eye and was a pleasure to work
with. We have lost a dear friend and colleague. Gene was a true gentleman.
J.D.P.
A.E.-N.
Stanford, California

1
An Overview and Brief
History of Feedback Control
A Perspective on Feedback Control
Feedback control of dynamic systems is a very old concept with many
characteristics that have evolved over time. The central idea is that
a dynamic system's output can be measured and fed back to a con-
troller of some kind and used to affect the system. There are several
variations on this theme.
A system that involves a person controlling a machine, as in driv-
ing an automobile, is called manual control. A system that involves
machines only, as when room temperature can be set by a thermo-
stat, is called automatic control. Systems designed to hold an output
steady against unknown disturbances are called regulators, while
systems designed to track a reference signal are called tracking or
servo systems. Control systems are also classiﬁed according to the
information used to compute the controlling action. If the controller
does not use a measure of the system output being controlled in
computing the control action to take, the system is called open-loop
control. If the controlled output signal is measured and fed back
for use in the control computation, the system is called closed-loop
or feedback control. There are many other important properties of
control systems in addition to these most basic characteristics. For
example, we will mainly consider feedback of current measurements
1

2
Chapter 1 An Overview and Brief History of Feedback Control
as opposed to predictions of the future; however, a very familiar
example illustrates the limitation imposed by that assumption. When
driving a car, the use of simple feedback corresponds to driving in
a thick fog where one can only see the road immediately at the front
of the car and is unable to see the future required position! Looking
at the road ahead is a form of predictive control and this informa-
tion, which has obvious advantages, would always be used where it
is available; but in most automatic control situations studied in this
book, observation of the future track or disturbance is not possible.
In any case, the control designer should study the process to see if
any information could anticipate either a track to be followed or a
disturbance to be rejected. If such a possibility is feasible, the con-
trol designer should use it to feedforward an early warning to the
control system. An example of this is in the control of steam pressure
in the boiler of an electric power generation plant. The electricity
demand cycle over a day is well known; therefore, when it is known
that there will soon be an increased need for electrical power, that
information can be fed forward to the boiler controller in anticipation
of a soon-to-be-demanded increase in steam ﬂow.
The applications of feedback control have never been more excit-
ing than they are today. Automatic landing and collision avoidance
systems are now being used and the use of satellite navigation in
future designs promises a revolution in our ability to navigate in an
ever more crowded airspace. In the magnetic data storage devices
for computers known as hard disks, control of the read/write head
assembly is often designed to have tracking errors on the order of
microns and to move at speeds of a fraction of a millisecond. Control
is essential to the operation of systems from cell phones to jumbo
jets and from washing machines to oil reﬁneries as large as a small
city. Applications of control to driverless cars and surgical robotic sys-
tems are emerging. The list goes on and on. In fact, many engineers
refer to control as a hidden technology because of its essential impor-
tance to so many devices and systems while being mainly out of sight.
The future will no doubt see engineers create even more imaginative
applications of feedback control.
Chapter Overview
In this chapter we begin our exploration of feedback control using a
simple familiar example: a household furnace controlled by a thermo-
stat. The generic components of a control system are identiﬁed within
the context of this example. In another example in Section 1.2—an
automobile cruise control—we develop the elementary static equa-
tions and assign numerical values to elements of the system model
in order to compare the performance of open-loop control to that
of feedback control when dynamics are ignored. Section 1.3 then
introduces the key elements in control system design. In order to

1.1 A Simple Feedback System
3
provide a context for our studies and to give you a glimpse of how
the ﬁeld has evolved, Section 1.4 provides a brief history of control
theory and design. In addition, later chapters have brief sections
of additional historical notes on the topics covered there. Finally,
Section 1.5 provides a brief overview of the contents and organization
of the entire book.
1.1
A Simple Feedback System
In feedback systems the variable being controlled—such as temperature or
speed—is measured by a sensor and the measured information is fed back
to the controller to inﬂuence the controlled variable. The principle is readily
illustrated by a very common system, the household furnace controlled by
a thermostat. The components of this system and their interconnections are
shown in Fig. 1.1. Such a picture identiﬁes the major parts of the system and
shows the directions of information ﬂow from one component to another.
We can easily analyze the operation of this system qualitatively from
the graph. Suppose both the temperature in the room where the thermostat
is located and the outside temperature are signiﬁcantly below the reference
temperature (also called the set point) when power is applied. The thermostat
will be on and the control logic will open the furnace gas valve and light
the ﬁre box. This will cause heat Qin to be supplied to the house at a rate
that will be signiﬁcantly larger than the heat loss Qout. As a result, the room
temperature will rise until it exceeds the thermostat reference setting by
a small amount. At this time the furnace will be turned off and the room
temperature will start to fall toward the outside value. When it falls a small
amount below the set point, the thermostat will come on again and the cycle
will repeat. Typical plots of room temperature along with the furnace cycles
of on and off are shown in Fig. 1.1. The outside temperature remains at 50◦F
and the thermostat is initially set at 55◦F.At 6 a.m., the thermostat is stepped
to 65◦F and the furnace brings it to that level and cycles the temperature
around that ﬁgure thereafter.1 Notice that the house is well insulated, so that
the fall of temperature with the furnace off is signiﬁcantly slower than the
rise with the furnace on. From this example, we can identify the generic
components of the elementary feedback control system as shown in Fig. 1.2.
The central component of this feedback system is the process whose
output is to be controlled. In our example the process would be the house
whose output is the room temperature and the disturbance to the process is
the ﬂow of heat from the house, Qout, due to conduction through the walls
and roof to the lower outside temperature. (The outward ﬂow of heat also
depends on other factors such as wind, open doors, and so on.) The design
of the process can obviously have a major impact on the effectiveness of
the controls. The temperature of a well-insulated house with thermopane
windows is clearly easier to control than otherwise. Similarly, the design of
1Notice that the furnace had come on a few minutes before 6 a.m. on its regular nighttime
schedule.

4
Chapter 1 An Overview and Brief History of Feedback Control
Desired
temperature
Thermostat
Gas
valve
Furnace
Heat loss
House
Room
temperature
Qin
Qout
-
 + 
70
60
50
40
30
20
10
0
Temperature (˚F)
0
2
4
6
Time (hours)
8
10
12
14
16
Room temperature
Outside temperature
Furnace off
Furnace on
(a)
(b)
©
Figure 1.1
Feedback control: (a) component block diagram of a room temperature control system; (b) plot of room
temperature and furnace action
aircraft with control in mind makes a world of difference to the ﬁnal perfor-
mance. In every case, the earlier the issues of control are introduced into the
process design, the better. The actuator is the device that can inﬂuence the
controlled variable of the process and in our case, the actuator is a gas fur-
nace. Actually, the furnace usually has a pilot light or striking mechanism, a
gas valve, and a blower fan, which turns on or off depending on the air tem-
perature in the furnace. These details illustrate the fact that many feedback
systems contain components that themselves form other feedback systems.2
The central issue with the actuator is its ability to move the process output
with adequate speed and range. The furnace must produce more heat than
the house loses on the worst day and must distribute it quickly if the house
temperature is to be kept in a narrow range. Power, speed, and reliability
2Jonathan Swift (1733) said it this way: "So, Naturalists observe, a ﬂea Hath smaller ﬂeas that
on him prey; And these have smaller still to bite 'em; And so proceed, ad inﬁnitum."

1.1 A Simple Feedback System
5
Reference
Output
Control
signal
Actuator
Disturbance
Sensor
Sensor
noise
Input
filter
Process
Controller
-
 + 
Plant
©
Figure 1.2
Component block diagram of an elementary feedback control
are usually more important than accuracy. Generally, the process and the
actuator are intimately connected and the control design centers on ﬁnding
a suitable input or control signal to send to the actuator. The combination
of process and actuator is called the plant and the component that actually
computes the desired control signal is the controller. Because of the ﬂexibil-
ity of electrical signal processing, the controller typically works on electrical
signals although the use of pneumatic controllers based on compressed air
has a long and important place in process control. With the development of
digital technology, cost-effectiveness and ﬂexibility have led to the use of
digital signal processors as the controller in an increasing number of cases.
The component labeled thermostat in Fig. 1.1 measures the room temper-
ature and is called the sensor in Fig. 1.2, a device whose output inevitably
contains sensor noise. Sensor selection and placement are very important in
control design, for it is sometimes not possible for the true controlled vari-
able and the sensed variable to be the same. For example, although we may
really wish to control the house temperature as a whole, the thermostat is in
one particular room, which may or may not be at the same temperature as the
rest of the house. For instance, if the thermostat is set to 68◦F but is placed in
the living room near a roaring ﬁreplace, a person working in the study could
still feel uncomfortably cold.3,4 As we will see, in addition to placement,
3In the renovations of the kitchen in the house of one of the authors, the new ovens were placed
against the wall where the thermostat was mounted on the other side. Now when dinner is baked
in the kitchen on a cold day, the author freezes in his study unless the thermostat is reset.
4The story is told of the new employee at the nitroglycerin factory who was to control the
temperature of a critical part of the process manually. He was told to "keep that reading below
300◦." On a routine inspection tour, the supervisor realized that the batch was dangerously
hot and found the worker holding the thermometer under cold water tap to bring it down to
300◦. They got out just before the explosion. Moral: sometimes automatic control is better than
manual.

6
Chapter 1 An Overview and Brief History of Feedback Control
important properties of a sensor are the accuracy of the measurements as
well as low noise, reliability, and linearity. The sensor will typically convert
the physical variable into an electrical signal for use by the controller. Our
general system also includes an input ﬁlter whose role is to convert the ref-
erence signal to electrical form for later manipulation by the controller. In
some cases the input ﬁlter can modify the reference command input in ways
that improve the system response. Finally, there is a controller to compute
the difference between the reference signal and the sensor output to give the
controller a measure of the system error. The thermostat on the wall included
the sensor, input ﬁlter, and the controller. A few decades ago, the user sim-
ply set the thermostat manually to achieve the desired room temperature at
the thermostat location. Over the last few decades, the addition of a small
computer in the thermostat has enabled storing the desired temperature over
the day and week and more recently, thermostats have gained the ability to
learn what the desired temperature should be and to base that value, in part,
on whether anybody will be home soon!5
This text will present methods for analyzing feedback control systems
and will describe the most important design techniques engineers can use in
applying feedback to solve control problems. We will also study the speciﬁc
advantages of feedback that compensate for the additional complexity it
demands.
1.2
A First Analysis of Feedback
The value of feedback can be readily demonstrated by quantitative analysis
of a simpliﬁed model of a familiar system, the cruise control of an automobile
(Fig. 1.3). To study this situation analytically, we need a mathematical model
of our system in the form of a set of quantitative relationships among the
Figure 1.3
Component block
diagram of automobile
cruise control
Desired
speed
Controller
Control
variable
Throttle
Actuator
Engine
Road
grade
Auto
body
Actual
speed
Speedometer
Sensor
Measured
speed
Sensor
noise
??
Process
5The sensor has a motion detector to determine whether anybody is home and the user can
command the unit from afar via the Internet. One example is by Nest, who was recently
purchased by Google. See: www.nest.com

1.2 A First Analysis of Feedback
7
variables. For this example, we ignore the dynamic response of the car and
consider only the steady behavior. (Dynamics will, of course, play a major
role in later chapters.) Furthermore, we assume that for the range of speeds
to be used by the system, we can approximate the relations as linear. After
measuring the speed of the vehicle on a level road at 65 mph, we ﬁnd that a 1◦
change in the throttle angle (our control variable, u) causes a 10 mph change
in speed (the output variable, y), hence the value 10 in the box between u and
y in Fig. 1.4, which is a block diagram of the plant. Generally, the block
diagram shows the mathematical relationships of a system in graphical form.
From observations while driving up and down hills, it is found that when the
grade changes by 1%, we measure a speed change of 5 mph, hence the value
0.5 in the upper box in Fig. 1.4, which reﬂects that a 1% grade change has
half the effect of a 1◦change in the throttle angle. The speedometer is found
to be accurate to a fraction of 1 mph and will be considered exact. In the
block diagram the connecting lines carry signals and a block is like an ideal
ampliﬁer which multiplies the signal at its input by the value marked in the
block to give the output signal. To sum two or more signals, we show lines
for the signals coming into a summer, a circle with the summation sign 
inside. An algebraic sign (plus or minus) beside each arrow head indicates
whether the input adds to or subtracts from the total output of the summer.
For this analysis, we wish to compare the effects of a 1% grade on the output
speed when the reference speed is set for 65 with and without feedback to
the controller.
In the ﬁrst case, shown in Fig. 1.5, the controller does not use the
speedometer reading but sets u = r/10, where r is the reference speed,
which is, 65 mph. This is an example of an open-loop control system. The
Open-loop control
Figure 1.4
Block diagram of the
cruise control plant
10
0.5
 + 
w (% grade)
y
u
Control
(5)
Output speed
(mph)
-
©
Figure 1.5
Open-loop cruise
control
Plant
Controller
10
0.5
-
 + 
w
y
r
u
1/10
©

8
Chapter 1 An Overview and Brief History of Feedback Control
term open loop refers to the fact that there is no closed path or loop around
which the signals go in the block diagram; that is, the control variable u is
independent of the output variable, y. In our simple example, the open-loop
output speed, yol, is given by the equations
yol = 10(u −0.5w)
= 10
 r
10 −0.5w

= r −5w.
The error in output speed is
eol = r −yol
(1.1)
= 5w,
(1.2)
and the percent error is
% error = 500w
r .
(1.3)
If r = 65 and the road is level, then w = 0 and the speed will be 65 with
no error. However, if w = 1 corresponding to a 1% grade, then the speed
will be 60 and we have a 5-mph error, which is a 7.69% error in the speed.
For a grade of 2%, the speed error would be 10 mph, which is an error of
15.38%, and so on. The example shows that there would be no error when
w = 0, but this result depends on the controller gain being the exact inverse
of the plant gain of 10. In practice, the plant gain is subject to change and if
it does, errors are introduced by this means also. If there is an error in the
plant gain in open-loop control, the percent speed error would be the same
as the percent plant-gain error.
The block diagram of a feedback scheme is shown in Fig. 1.6, where the
controller gain has been set to 10. In this simple example, we have assumed
that we have an ideal sensor providing a measurement of ycl. In this case the
equations are
Figure 1.6
Closed-loop cruise
control
Controller
10
0.5
-
 + 
w
ycl
r
u
10
-
 + 
Plant
©
©

1.2 A First Analysis of Feedback
9
ycl = 10u −5w,
u = 10(r −ycl).
Combining them yields
ycl = 100r −100ycl −5w,
101ycl = 100r −5w,
ycl = 100
101r −
5
101w,
ecl =
r
101 + 5w
101.
Thus the feedback has reduced the sensitivity of the speed error to the grade
by a factor of 101 when compared with the open-loop system. Note, however,
that there is now a small speed error on level ground because even when
w = 0,
ycl = 100
101r = 0.99r mph.
This error will be small as long as the loop gain (product of plant and con-
troller gains) is large.6 If we again consider a reference speed of 65 mph and
compare speeds with a 1% grade, the percent error in the output speed is
% error = 100
65 × 100
101
−
65 × 100
101
−
5
101

65 × 100
101
(1.4)
= 100
5 × 101
101 × 65 × 100
(1.5)
= 0.0769%.
(1.6)
The reduction of the speed sensitivity to grade disturbances and plant
gain in our example is due to the loop gain of 100 in the feedback case.
Unfortunately, there are limits to how high this gain can be made; when
dynamics are introduced, the feedback can make the response worse than
before, or even cause the system to become unstable. The dilemma is illus-
The design
trade-off
trated by another familiar situation where it is easy to change a feedback
gain. If one tries to raise the gain of a public-address ampliﬁer too much,
the sound system will squeal in a most unpleasant way. This is a situation
where the gain in the feedback loop—from the speakers to the microphone
through the ampliﬁer back to the speakers—is too much. The issue of how
6In case the error is too large, it is common practice to reset the reference, in this case to 101
100 r,
so the output reaches the true desired value.

10
Chapter 1 An Overview and Brief History of Feedback Control
to get the gain as large as possible to reduce the errors without making the
system become unstable and squeal is what much of feedback control design
is all about.
1.3
Feedback System Fundamentals
To achieve good control there are typical goals:
•
Stability: The system must be stable at all times. This is an absolute
requirement.
•
Tracking: The system output must track the command reference signal
as closely as possible.
•
Disturbance rejection: The system output must be as insensitive as
possible to disturbance inputs.
•
Robustness: The aforementioned goals must be met even if the model
used in the design is not completely accurate or if the dynamics of the
physical system change over time.
The requirement of stability is basic and instability may have two
causes. In the ﬁrst place, the system being controlled may be unstable. This
is illustrated by the Segway vehicle, which will simply fall over if the control
is turned off. A second cause of instability may be the addition of feedback!
Such an instability is called a "vicious circle," where the feedback signal that
is circled back makes the situation worse rather than better. Stability will be
discussed in much more detail in Chapters 3 and 4.
There are many examples of the requirement of having the system's out-
put track a command signal. For example, driving a car so that the vehicle
stays in its lane is command tracking. Today, this is done by the driver;
however, there are schemes now under development where the car's "auto-
driver" will carry out this task using feedback control while the driver does
other things, for example, surﬁng the Internet. Similarly, ﬂying an airplane
on the approach to landing requires that a glide path be accurately tracked
by the pilot or an autopilot. It is routine for today's aircraft autopilots to
carry this out including the ﬂare to the actual touchdown. The autopilot
accepts inputs from the Instrument Landing System (ILS) that provides an
electronic signal showing the desired landing trajectory, then commands the
aircraft control surfaces so that it follows the desired trajectory as closely as
possible.
Disturbance rejection is one of the very oldest applications of feedback
control. In this case, the "command" is simply a constant set point to which
the output is to be held as the environment changes.A very common example
of this is the room thermostat whose job it is to hold the room temperature
close to the set point as outside temperature and wind change, and as doors
and windows are opened and closed.
Finally, to design a controller for a dynamic system, it is necessary to
have a mathematical model of the dynamic response of the system being
controlled in all but the simplest cases. Unfortunately, almost all physical
systems are very complex and often nonlinear. As a result, the design will

1.4 A Brief History
11
usually be based on a simpliﬁed model and must be robust enough that
the system meets its performance requirements when applied to the real
device. Furthermore, as time and the environment change, even the best of
models will be in error because the system dynamics have changed. Again,
the design must not be too sensitive to these inevitable changes and it must
work well enough regardless.
The tools available to control engineers to design and build feedback
control systems have evolved over time. Especially important has been the
development of digital computers both as computation aids and as embed-
ded control devices. As computation devices, computers have permitted
identiﬁcation of increasingly complex models and the application of very
sophisticated control design methods. Also, as embedded devices, digital
controllers have permitted the implementation of very complex control laws.
Control engineers must not only be skilled in using these design tools but
also need to understand the concepts behind these tools to be able to make
the best use of them. Also important is that the control engineer understand
both the capabilities and the limitations of the controller devices available.
1.4
A Brief History
An interesting history of early work on feedback control has been written
by Mayr (1970), who traces the control of mechanisms to antiquity. Two of
the earliest examples are the control of ﬂow rate to regulate a water clock
and the control of liquid level in a wine vessel, which is thereby kept full
regardless of how many cups are dipped from it. The control of ﬂuid ﬂow
rate is reduced to the control of ﬂuid level, since a small oriﬁce will produce
constant ﬂow if the pressure is constant, which is the case if the level of
the liquid above the oriﬁce is constant. The mechanism of the liquid-level
control invented in antiquity and still used today (for example, in the water
tank of the ordinary ﬂush toilet) is the ﬂoat valve. As the liquid level falls, so
Liquid-level control
does the ﬂoat, allowing the ﬂow into the tank to increase; as the level rises,
the ﬂow is reduced and if necessary cut off. Fig. 1.7 shows how a ﬂoat valve
operates. Notice here that sensor and actuator are not separate devices but
are contained in the carefully shaped ﬂoat-and-supply-tube combination.
A more recent invention described by Mayr (1970) is a system, designed
by Cornelis Drebbel in about 1620, to control the temperature of a furnace
Drebbel's incubator
Figure 1.7
Early historical control
of liquid level and ﬂow
Supply
Float

12
Chapter 1 An Overview and Brief History of Feedback Control
used to heat an incubator7 (Fig. 1.8). The furnace consists of a box to contain
the ﬁre, with a ﬂue at the top ﬁtted with a damper. Inside the ﬁre box is the
double-walled incubator box, the hollow walls of which are ﬁlled with water
to transfer the heat evenly to the incubator. The temperature sensor is a glass
vessel ﬁlled with alcohol and mercury and placed in the water jacket around
the incubator box. As the ﬁre heats the box and water, the alcohol expands
and the riser ﬂoats up, lowering the damper on the ﬂue. If the box is too cold,
the alcohol contracts, the damper is opened, and the ﬁre burns hotter. The
desired temperature is set by the length of the riser, which sets the opening
of the damper for a given expansion of the alcohol.
A famous problem in the chronicles of control systems was the search
for a means to control the rotation speed of a shaft. Much early work (Fuller,
1976) seems to have been motivated by the desire to automatically control the
speed of the grinding stone in a wind-driven ﬂour mill. Of various methods
attempted, the one with the most promise used a conical pendulum, or ﬂy-
ball governor, to measure the speed of the mill. The sails of the driving
Fly-ball
governor
windmill were rolled up or let out with ropes and pulleys, much like a
window shade, to maintain ﬁxed speed. However, it was adaptation of these
principles to the steam engine in the laboratories of James Watt around 1788
that made the ﬂy-ball governor famous.An early version is shown in Fig. 1.9,
while Figs. 1.10 and 1.11 show a close-up of a ﬂy-ball governor and a sketch
of its components.
The action of the ﬂy-ball governor (also called a centrifugal governor)
is simple to describe. Suppose the engine is operating in equilibrium. Two
weighted balls spinning around a central shaft can be seen to describe a
cone of a given angle with the shaft. When a load is suddenly applied to
Figure 1.8
Drebbel's incubator for
hatching chicken eggs
Water
Flue
gases
Metal plate
Fire
Alcohol
Mercury
Float
Riser
Damper
Eggs
7French doctors introduced incubators into the care of premature babies over 100 years ago.

1.4 A Brief History
13
Figure 1.9
Photograph of an early
Watt steam engine
Source: Mary Evans Picture
Library/Alamy
Figure 1.10
Close-up of the ﬂy-ball
governor
Source: Washington
Imaging/Alamy
the engine, its speed will slow, and the balls of the governor will drop to
a smaller cone. Thus the ball angle is used to sense the output speed. This
action, through the levers, will open the main valve to the steam chest (which
is the actuator) and admit more steam to the engine, restoring most of the
lost speed. To hold the steam valve at a new position, it is necessary for
the ﬂy balls to rotate at a different angle, implying that the speed under
load is not exactly the same as before. We saw this effect earlier with cruise
control, where feedback control gave a very small error. To recover the exact
same speed in the system, it would require resetting the desired speed setting
by changing the length of the rod from the lever to the valve. Subsequent

14
Chapter 1 An Overview and Brief History of Feedback Control
Figure 1.11
Operating parts of a
ﬂy-ball governor
Pivot
To engine
inlet
Butterfly valve
Steam
Sleeve
Balls
Rotation
Pulley
from engine
inventors introduced mechanisms that integrated the speed error to provide
automatic reset. In Chapter 4 we will analyze these systems to show that
such integration can result in feedback systems with zero steady-state error
to constant disturbances.
Because Watt was a practical man, he did not engage in theoretical
analysis of the governor, similar to the millwrights earlier. Fuller (1976)
has traced the early development of control theory to a period of studies
from Christian Huygens in 1673 to James Clerk Maxwell in 1868. Fuller
Beginnings of
control theory
gives particular credit to the contributions of G. B. Airy, professor of math-
ematics and astronomy at Cambridge University from 1826 to 1835 and
Astronomer Royal at Greenwich Observatory from 1835 to 1881. Airy was
concerned with speed control; if his telescopes could be rotated counter to
the rotation of the earth, a ﬁxed star could be observed for extended peri-
ods. Using the centrifugal-pendulum governor he discovered that it was
capable of unstable motion—"and the machine (if I may so express myself)
became perfectly wild" (Airy, 1840; quoted in Fuller, 1976). According
to Fuller, Airy was the ﬁrst worker to discuss instability in a feedback
control system and the ﬁrst to analyze such a system using differential equa-
tions. These attributes signal the beginnings of the study of feedback control
dynamics.
The ﬁrst systematic study of the stability of feedback control was appar-
ently given in the paper "On Governors" by Maxwell (1868).8 In this paper,
Maxwell developed the differential equations of the governor, linearized
Stability analysis
them about equilibrium, and stated that stability depends on the roots of a cer-
tain (characteristic) equation having negative real parts. Maxwell attempted
8An exposition of Maxwell's contribution is given in Fuller (1976).

1.4 A Brief History
15
to derive conditions on the coefﬁcients of a polynomial that would hold if
all the roots had negative real parts. He was successful only for second- and
third-order cases. Determining criteria for stability was the problem for the
Adams Prize of 1877, which was won by E. J. Routh.9 His criterion, devel-
oped in his essay, remains of sufﬁcient interest that control engineers are still
learning how to apply his simple technique. Analysis of the characteristic
equation remained the foundation of control theory until the invention of
the electronic feedback ampliﬁer by H. S. Black in 1927 at Bell Telephone
Laboratories.
Shortly after publication of Routh's work, the Russian mathematician
Lyapunov (1892) began studying the question of stability of motion. His
studies were based on the nonlinear differential equations of motion and also
included results for linear equations that are equivalent to Routh's criterion.
His work was fundamental to what is now called the state-variable approach
to control theory, but was not introduced into the control literature until about
1958.
The development of the feedback ampliﬁer is brieﬂy described in an
interesting article based on a talk by Bode (1960) reproduced in Bellman and
Frequency response
Kalaba (1964). With the introduction of electronic ampliﬁers, long-distance
telephoning became possible in the decades following World War I. How-
ever, as distances increased, so did the loss of electrical energy; in spite of
using larger-diameter wires, increasing numbers of ampliﬁers were needed
toreplacethelostenergy. Unfortunately, largenumbersofampliﬁersresulted
in much distortion since the small nonlinearity of the vacuum tubes then used
in electronic ampliﬁers were multiplied many times. To solve the problem of
reducing distortion, Black proposed the feedback ampliﬁer. As mentioned
earlier in connection with the automobile cruise control, the more we wish to
reduce errors (or distortion), the more feedback we need to apply. The loop
gain from actuator to plant to sensor to actuator must be made very large.
With high gain the feedback loop begins to squeal and is unstable. Here was
Maxwell's and Routh's stability problem again, except that in this technol-
ogy the dynamics were so complex (with differential equations of order 50
being common) that Routh's criterion was not very helpful. So the communi-
cations engineers at Bell Telephone Laboratories, familiar with the concept
of frequency response and the mathematics of complex variables, turned to
complex analysis. In 1932, H. Nyquist published a paper describing how
to determine stability from a graphical plot of the loop frequency response.
From this theory developed an extensive methodology of feedback-ampliﬁer
design described by Bode (1945) and still extensively used in the design of
feedback controls. Nyquist and Bode plots are discussed in more detail in
Chapter 6.
9E. J. Routh was ﬁrst academically in his class at Cambridge University in 1854, while
J. C. Maxwell was second. In 1877, Maxwell was on the Adams Prize Committee that chose
the problem of stability as the topic for the year.

16
Chapter 1 An Overview and Brief History of Feedback Control
Simultaneous with the development of the feedback ampliﬁer, feedback
control of industrial processes was becoming standard. This ﬁeld, charac-
terized by processes that are not only highly complex but also nonlinear and
subject to relatively long time delays between actuator and sensor, devel-
oped proportional-integral-derivative (PID) control. The PID controller
PID control
was ﬁrst described by Callender et al. (1936). This technology was based
on extensive experimental work and simple linearized approximations to
the system dynamics. It led to standard experiments suitable to application
in the ﬁeld and eventually to satisfactory "tuning" of the coefﬁcients of
the PID controller. (PID controllers are covered in Chapter 4.) Also under
development at this time were devices for guiding and controlling aircraft;
especially important was the development of sensors for measuring aircraft
altitude and speed. An interesting account of this branch of control theory is
given in McRuer (1973).
An enormous impulse was given to the ﬁeld of feedback control during
World War II. In the United States, engineers and mathematicians at the MIT
Radiation Laboratory combined their knowledge to bring together not only
Bode's feedback ampliﬁer theory and the PID control of processes but also
the theory of stochastic processes developed by Wiener (1930). The result
was the development of a comprehensive set of techniques for the design of
servomechanisms, as control mechanisms came to be called. Much of this
work was collected and published in the records of the Radiation Laboratory
by James et al. (1947).
Another approach to control systems design was introduced in 1948 by
W. R. Evans, who was working in the ﬁeld of guidance and control of aircraft.
Many of his problems involved unstable or neutrally stable dynamics, which
made the frequency methods difﬁcult, so he suggested returning to the study
of the characteristic equation that had been the basis of the work of Maxwell
and Routh nearly 70 years earlier. However, Evans developed techniques
and rules allowing one to follow graphically the paths of the roots of the
characteristic equation as a parameter was changed. His method, the root
locus, is suitable for design as well as for stability analysis and remains an
Root locus
important technique today. The root-locus method developed by Evans is
covered in Chapter 5.
During the 1950s several authors,
including R. Bellman and
R. E. Kalman in the United States and L. S. Pontryagin in the U.S.S.R.,
State-variable design
began again to consider the ordinary differential equation (ODE) as a model
for control systems. Much of this work was stimulated by the new ﬁeld of
control of artiﬁcial earth satellites, in which the ODE is a natural form for
writing the model. Supporting this endeavor were digital computers, which
could be used to carry out calculations unthinkable 10 years before. (Now,
of course, these calculations can be done by any engineering student with a
laptop computer.) The work of Lyapunov was translated into the language
of control at about this time, and the study of optimal controls, begun by
Wiener and Phillips during World War II, was extended to optimizing trajec-
tories of nonlinear systems based on the calculus of variations. Much of this
work was presented at the ﬁrst conference of the newly formed International

1.5 An Overview of the Book
17
Federation of Automatic Control held in Moscow in 1960.10 This work did
not use the frequency response or the characteristic equation but worked
directly with the ODE in "normal" or "state" form and typically called for
extensive use of computers. Even though the foundations of the study of
ODEs were laid in the late 19th century, this approach is now often called
modern control to distinguish it from classical control, which uses Laplace
transforms and complex variable methods of Bode and others. In the period
from the 1970s continuing through the present, we ﬁnd a growing body of
work that seeks to use the best features of each technique.
Thus we come to the current state of affairs where the principles of
control are applied in a wide range of disciplines, including every branch
of engineering. The well-prepared control engineer needs to understand the
basic mathematical theory that underlies the ﬁeld and must be able to select
the best design technique suited to the problem at hand. With the ubiquitous
use of computers it is especially important that the engineer is able to use his
or her knowledge to guide and verify calculations done on the computer.11
1.5
An Overview of the Book
The central purpose of this book is to introduce the most important tech-
niquesforsingle-input-single-outputcontrolsystemsdesign. Chapter2 will
review the techniques necessary to obtain physical models of the dynamic
systems that we wish to control. These include model making for mechani-
cal, electric, electromechanical, and a few other physical systems. Chapter 2
also describes brieﬂy the linearization of nonlinear models, although this
will be discussed more thoroughly in Chapter 9.
In Chapter 3 and Appendix A we will discuss the analysis of dynamic
response using Laplace transforms along with the relationship between time
response and the poles and zeros of a transfer function. The chapter also
includes a discussion of the critical issue of system stability, including the
Routh test.
In Chapter 4 we will cover the basic equations and features of feedback.
An analysis of the effects of feedback on disturbance rejection, tracking
accuracy, sensitivity to parameter changes, and dynamic response will be
given. The idea of elementary PID control is discussed.
In Chapters 5, 6, and 7 we introduce the techniques for realizing the
control objectives ﬁrst identiﬁed in Chapter 4 in more complex dynamic sys-
tems. These include the root locus, frequency response, and state variable
techniques. These are alternative means to the same end and have different
10Optimal control gained a large boost when Bryson and Denham (1962) showed that the path
of a supersonic aircraft should actually dive at one point in order to reach a given altitude in
minimum time. This nonintuitive result was later demonstrated to skeptical ﬁghter pilots in
ﬂight tests.
11For more background on the history of control, see the survey papers appearing in the IEEE
Control Systems Magazine of November 1984 and June 1996.

18
Chapter 1 An Overview and Brief History of Feedback Control
advantages and disadvantages as guides to design of controls. The meth-
ods are fundamentally complementary, and each needs to be understood to
achieve the most effective control systems design.
In Chapter 8 we develop the ideas of implementing controllers in a
digital computer. The chapter addresses how one "digitizes" the control
equations developed in Chapters 4 through 7, how the sampling introduces
a delay that tends to destabilize the system, and how the sample rate needs
to be a certain multiple of the system frequencies for good performance.
Just as the Laplace transform does for non sampled signals, the analysis of
sampled systems requires another analysis tool—the z-transform—and that
tool is described and its use is illustrated.
Most real systems are nonlinear to some extent. However, the analyses
and design methods in most of the book up to here are for linear systems. In
Chapter 9 we explain why the study of linear systems is pertinent, why it is
useful for design even though most systems are nonlinear, and how designs
for linear systems can be modiﬁed to handle many common nonlinearities
in the systems being controlled. The chapter covers saturation, describing
functions, adaptive control and the anti-windup controller, and contains a
brief introduction to Lyapunov stability theory.
Application of all the techniques to problems of substantial complexity
are discussed in Chapter 10. The design methods are brought to bear simul-
taneously on speciﬁc case studies which are representative of real-world
problems.
Control designers today make extensive use of computer-aided control
systems design software that is commercially available. Furthermore, most
Computer aids
instructional programs in control systems design make software tools avail-
able to the students. The most widely used software for the purpose are
Matlab® and Simulink® from The MathWorks. Matlab routines have been
included throughout the text to help illustrate this method of solution and
many problems require computer aids for solution. Many of the ﬁgures in the
book were created using Matlab and the ﬁles for their creation are available
free of charge on the web at http://www.FPE7e.com. Students and instruc-
tors are invited to use these ﬁles as it is believed that they should be helpful
in learning how to use computer methods to solve control problems.
Needless to say, many topics are not treated in the book. We do not
extend the methods to multivariable controls, which are systems with more
than one input and/or output, except as part of the case study of the rapid
thermal process in Chapter 10. Nor is optimal control treated in more than a
very introductory manner in Chapter 7.
Also beyond the scope of this text is a detailed treatment of the exper-
imental testing and modeling of real hardware, which is the ultimate test
of whether any design really works. The book concentrates on analysis and
design of linear controllers for linear plant models—not because we think
that is the ﬁnal test of a design, but because that is the best way to grasp the
basic ideas of feedback and is usually the ﬁrst step in arriving at a satisfactory
design. We believe that mastery of the material here will provide a founda-
tion of understanding on which to build knowledge of the actual physical

Review Questions
19
behavior of control systems—a foundation strong enough to allow one to
build a personal design method in the tradition of all those who worked to
give us the knowledge we present here.
SUMMARY
•
Control is the process of making a system variable adhere to a particular
value, called the reference value. A system designed to follow a chang-
ing reference is called tracking control or a servo. A system designed
to maintain an output ﬁxed regardless of the disturbances present is
called a regulating control or a regulator.
•
Two kinds of control were deﬁned and illustrated based on the informa-
tion used in control and named by the resulting structure. In open-loop
control the system does not measure the output and there is no correc-
tion of the actuating signal to make that output conform to the reference
signal. In closed-loop control the system includes a sensor to measure
the output and uses feedback of the sensed value to inﬂuence the control
variable.
•
A simple feedback system consists of the process (or plant) whose
output is to be controlled, the actuator whose output causes the process
output to change, a reference command signal, and output sensors that
measure these signals, and the controller that implements the logic by
which the control signal that commands the actuator is calculated.
•
Blockdiagramsarehelpfulforvisualizingsystemstructureandtheﬂow
of information in control systems. The most common block diagrams
represent the mathematical relationships among the signals in a control
system.
•
A well-designed feedback control system will be stable, track a desired
input or set point, reject disturbances, and be insensitive (or robust)
to changes in the math model used for design.
•
The theory and design techniques of control have come to be divided
into two categories: classical control methods use Laplace transforms
(or z-transform) and were the dominant methods for control design until
modern control methods based on ODEs in state form were introduced
into the ﬁeld starting in the 1960s. Many connections have been discov-
ered between the two categories and well-prepared engineers must be
familiar with both techniques.
REVIEW QUESTIONS
1.1
What are the main components of a feedback control system?
1.2
What is the purpose of the sensor?
1.3
Give three important properties of a good sensor.
1.4
What is the purpose of the actuator?

20
Chapter 1 An Overview and Brief History of Feedback Control
1.5
Give three important properties of a good actuator.
1.6
What is the purpose of the controller? Give the input(s) and output(s) of the
controller.
1.7
What physical variable is measured by a tachometer?
1.8
Describe three different techniques for measuring temperature.
1.9
Why do most sensors have an electrical output, regardless of the physical
nature of the variable being measured?
PROBLEMS
1.1 Draw a component block diagram for each of the following feedback control
systems.
(a) The manual steering system of an automobile
(b) Drebbel's incubator
(c) The water level controlled by a ﬂoat and valve
(d) Watt's steam engine with ﬂy-ball governor
In each case, indicate the location of the elements listed below and give the
units associated with each signal.
•
The process
•
The process desired output signal
•
The sensor
•
The actuator
•
The actuator output signal
•
The controller
•
The controller output signal
•
The reference signal
•
The error signal
Notice that in a number of cases the same physical device may perform more
than one of these functions.
1.2 Identify the physical principles and describe the operation of the thermostat in
your home or ofﬁce.
1.3 A machine for making paper is diagrammed in Fig. 1.12. There are two main
parameters under feedback control: the density of ﬁbers as controlled by the
Controller
Machine
chest
Thick stock
Consistency
sensor
Valve input
Head box
Wire
Dryers
Dryer control
input
Paper
Moisture
sensor
White water
CV
Figure 1.12
A papermaking machine

Problems
21
consistency of the thick stock that ﬂows from the headbox onto the wire, and the
moisture content of the ﬁnal product that comes out of the dryers. Stock from
the machine chest is diluted by white water returning from under the wire as
controlled by a control valve (CV).A meter supplies a reading of the consistency.
At the "dry end" of the machine, there is a moisture sensor. Draw a block
diagram and identify the nine components listed in Problem 1.1 part (d) for the
following:
(a) Control of consistency
(b) Control of moisture
1.4 Many variables in the human body are under feedback control. For each of
the following controlled variables, draw a block diagram showing the process
being controlled, the sensor that measures the variable, the actuator that causes
it to increase and/or decrease, the information path that completes the feedback
path, and the disturbances that upset the variable. You may need to consult an
encyclopedia or textbook on human physiology for information on this problem.
(a) Blood pressure
(b) Blood sugar concentration
(c) Heart rate
(d) Eye-pointing angle
(e) Eye-pupil diameter
1.5 Draw a block diagram of the components for temperature control in a refrigerator
or automobile air-conditioning system.
1.6 Draw a block diagram of the components for an elevator-position control. Indi-
catehowyouwouldmeasurethepositionoftheelevatorcar. Consideracombined
coarse and ﬁne measurement system. What accuracies do you suggest for each
sensor? Your system should be able to correct for the fact that in elevators for
tall buildings there is signiﬁcant cable stretch as a function of cab load.
1.7 Feedback control requires being able to sense the variable being controlled.
Because electrical signals can be transmitted, ampliﬁed, and processed easily,
often we want to have a sensor whose output is a voltage or current proportional
to the variable being measured. Describe a sensor that would give an electrical
output proportional to the following:
(a) Temperature
(b) Pressure
(c) Liquid level
(d) Flow of liquid along a pipe (or blood along an artery)
(e) Linear position
(f) Rotational position
(g) Linear velocity
(h) Rotational speed
(i) Translational acceleration
(j) Torque
1.8 Eachofthe variableslisted in Problem 1.7 can be brought under feedback control.
Describe an actuator that could accept an electrical input and be used to control
the variables listed. Give the units of the actuator output signal.

22
Chapter 1 An Overview and Brief History of Feedback Control
1.9 Feedback in Biology
(a) Negative Feedback in Biology: When a person is under long-term stress (say,
a couple of weeks before an exam!), hypothalamus (in the brain) secretes
a hormone called Corticotropin Releasing Factor (CRF) which binds to a
receptor in the pituitary gland stimulating it to produce Adrenocorticotropic
hormone (ACTH), which in turn stimulates the adrenal cortex (outer part of
the adrenal glands) to release the stress hormone Glucocorticoid (GC). This
in turn shuts down (turns off the stress response) for both CRF and ACTH
production by negative feedback via the bloodstream until GC returns to its
normal level. Draw a block diagram of this closed-loop system.
(b) Positive Feedback in Biology: This happens in some unique circumstances.
Considerthebirthprocessofababy. Pressurefromtheheadofthebabygoing
through the birth canal causes contractions via secretion of a hormone called
oxytocin which causes more pressure which in turn intensiﬁes contractions.
Once the baby is born, the system goes back to normal (negative feedback).
Draw a block diagram of this closed-loop system.

2
Dynamic Models
A Perspective on Dynamic Models
The overall goal of feedback control is to use feedback to cause the
output variable of a dynamic process to follow a desired reference
variable accurately, regardless of the reference variable's path and
regardless of any external disturbances or any changes in the dynam-
ics of the process. This complex design goal is met by a number of
simple, distinct steps. The ﬁrst of these is to develop a mathemat-
ical description (called a dynamic model or mathematical model)
of the process to be controlled. The term model, as it is used and
understood by control engineers, means a set of differential equa-
tions that describe the dynamic behavior of the process. A model can
be obtained using principles of the underlying physics or by testing a
prototype of the device, measuring its response to inputs, and using
the data to construct an analytical model. We will focus only on using
physics in this chapter. There are entire books written on experimen-
tally determining models, sometimes called system identiﬁcation,
and these techniques are described very brieﬂy in Chapter 3. A careful
control system designer will typically rely on at least some experi-
ments to verify the accuracy of the model when it is derived from
physical principles.
In many cases the modeling of complex processes is difﬁcult and
expensive, especially when the important steps of building and test-
ingprototypesareincluded. However, inthisintroductorytext, wewill
focus on the most basic principles of modeling for the most common
physical systems. More comprehensive sources and specialized texts
will be referenced throughout where appropriate for those wishing
more detail.
23

24
Chapter 2 Dynamic Models
In later chapters we will explore a variety of analysis methods for
dealing with the dynamic equations and their solution for purposes of
designing feedback control systems.
Chapter Overview
The fundamental step in building a dynamic model is writing the
dynamic equations for the system. Through discussion and a variety
of examples, Section 2.1 demonstrates how to write the dynamic
equations for a variety of mechanical systems. In addition, the section
demonstrates the use of Matlab to ﬁnd the time response of a simple
system to a step input. Furthermore, the ideas of transfer functions
and block diagrams are introduced, along with the idea that problems
can also be solved via Simulink.
Electric circuits and electromechanical systems are modeled in
Sections 2.2 and 2.3, respectively.
For those wanting modeling examples for more diverse dynamic
systems, Section 2.4, which is optional, extends the discussion to
heat- and ﬂuid-ﬂow systems.
ThechapterconcludeswithSection2.5, adiscussionofthehistory
behind the discoveries that led to the knowledge that we take for
granted today.
The differential equations developed in modeling are often non-
linear. Because nonlinear systems are signiﬁcantly more challenging
to solve than linear ones and because linear models are usually
adequate for purposes of control design, the emphasis in the early
chapters is primarily on linear systems. However, we do show how to
linearize simple nonlinearities in this chapter and show how to use
Simulink to numerically solve for the motion of a nonlinear system.
A much more extensive discussion of linearization and analysis of
nonlinear systems is contained in Chapter 9.
In order to focus on the important ﬁrst step of developing math-
ematical models, we will defer explanation of the computational
methods used to solve the dynamic equations developed in this
chapter until Chapter 3.
2.1
Dynamics of Mechanical Systems
2.1.1
Translational Motion
The cornerstone
for obtaining a mathematical model, or the dynamic
Newton's law for
translational motion
equations,1 for any mechanical system is Newton's law,
F = ma,
(2.1)
1For systems with moving parts, these equations are typically referred to as the "equations of
motion."

2.1 Dynamics of Mechanical Systems
25
where
F = the vector sum of all forces applied to each body in a system,
newtons (N),
a = the vector acceleration of each body with respect to an inertial
reference frame (that is, one that is neither accelerating nor rotat-
ing with respect to the stars); often called inertial acceleration,
m/sec2,
m = mass of the body, kg.
Note that here in Eq. (2.1), as throughout the text, we use the convention
of boldfacing the type to indicate that the quantity is a matrix or vector,
possibly a vector function.
A force of 1 N will impart an acceleration of 1 m/sec2 to a mass of
1 kg. The "weight" of an object is mg, where g is the acceleration of gravity
(= 9.81 m/sec2), which is the quantity measured on scales. Scales are typ-
ically calibrated in kilograms, which is used as a direct measure of mass
assuming the standard value for g.
Application of this law typically involves deﬁning convenient coordi-
Use of free-body diagram
in applying Newton's law
nates to account for the body's motion (position, velocity, and acceleration),
determining the forces on the body using a free-body diagram, and then
writing the equations of motion from Eq. (2.1). The procedure is simplest
when the coordinates chosen express the position with respect to an inertial
reference frame because, in this case, the accelerations needed for Newton's
law are simply the second derivatives of the position coordinates.
EXAMPLE 2.1
A Simple System; Cruise Control Model
1. Write the equations of motion for the speed and forward motion of
the car shown in Fig. 2.1 assuming that the engine imparts a force u as
shown. Take the Laplace transform of the resulting differential equation
and ﬁnd the transfer function between the input u and the output v.
2. Use Matlab to ﬁnd the response of the velocity of the car for the case
in which the input jumps from being u = 0 at time t = 0 to a constant
Figure 2.1
Cruise control model
u

26
Chapter 2 Dynamic Models
u = 500 N thereafter. Assume that the car mass m is 1000 kg and
viscous drag coefﬁcient, b = 50 N·sec/m.
Solution
1. Equations of motion: For simplicity we assume that the rotational
inertia of the wheels is negligible and that there is friction retarding
the motion of the car that is proportional to the car's speed with a
proportionality constant, b.2 The car can then be approximated for
modeling purposes using the free-body diagram seen in Fig. 2.2, which
deﬁnes coordinates, shows all forces acting on the body (heavy lines),
and indicates the acceleration (dashed line). The coordinate of the car's
position x is the distance from the reference line shown and is chosen so
that positive is to the right. Note that in this case the inertial acceleration
is simply the second derivative of x (that is, a = ¨x) because the car
position is measured with respect to an inertial reference frame. The
equation of motion is found using Eq. (2.1). The friction force acts
opposite to the direction of motion; therefore it is drawn opposite to the
direction of positive motion and entered as a negative force in Eq. (2.1).
The result is
u −b˙x = m¨x,
(2.2)
or
¨x + b
m ˙x = u
m.
(2.3)
For the case of the automotive cruise control where the variable of
interest is the speed, v (=˙x), the equation of motion becomes
˙v + b
mv = u
m.
(2.4)
The solution of such an equation will be covered in detail in Chapter 3;
however, the essence is that you assume a solution of the form v = Voest
given an input of the form u = Uoest. Then, since ˙v = sVoest, the
differential equation can be written as3

s + b
m

Voest = 1
mUoest.
(2.5)
Figure 2.2
Free-body diagram for
cruise control
x
Friction
force bx
u
x
m
2If the speed is v, the aerodynamic portion of the friction force is actually proportional to v2.
We have assumed it to be linear here for simplicity.
3The use of an operator for differentiation was developed by Cauchy in about 1820 based on
the Laplace transform, which was developed in about 1780. In Chapter 3 we will show how to
derive transfer functions using the Laplace transform (Refer to Gardner and Barnes, 1942).

2.1 Dynamics of Mechanical Systems
27
The est term cancels out, and we ﬁnd that
Vo
Uo
=
1
m
s + b
m
.
(2.6)
For reasons that will become clear in Chapter 3, this is often written
using capital letters to signify that it is the "transform" of the solution, or
V(s)
U(s) =
1
m
s + b
m
.
(2.7)
This expression of the differential equation (2.4) is called the transfer
Transfer function
function and will be used extensively in later chapters. Note that, in
essence, we have substituted s for d/dt in Eq. (2.4). This transfer fun-
tion serves as a math model that relates the car's velocity to the forces
propelling the car, that is, inputs from the accelerator pedal. Transfer
functions of a system will be used in later chapters to design feedback
controllers such as a cruise control device found in many modern cars.
2. Time response: The dynamics of a system can be prescribed to Matlab
in terms of its transfer function as can be seen in the Matlab statements
below that implements Eq. (2.7). The step function in Matlab calcu-
lates the time response of a linear system to a unit step input. Because
the system is linear, the output for this case can be multiplied by the
magnitude of the input step to derive a step response of any amplitude.
Equivalently, sys can be multiplied by the magnitude of the input step.
The statements
Step response with Matlab
s=tf('s');
% sets up the mode to deﬁne the
transfer function
sys = (1/1000)/(s + 50/1000);
% deﬁnes the transfer function from
Eq. (2.7) with the numbers ﬁlled in.
step(500*sys);
% plots the step response for u = 500.
calculate and plot the time response of velocity for an input step with
a 500-N magnitude. The step response is shown in Fig. 2.3.
Figure 2.3
Response of the car
velocity to a step in u
10
8
6
4
2
0
Velocity (m/sec)
0
10
20
30
40
50
60
70
80
90 100
Time (sec)

28
Chapter 2 Dynamic Models
Newton's law also can be applied to systems with more than one mass.
In this case it is particularly important to draw the free-body diagram of each
mass, showing the applied external forces as well as the equal and opposite
internal forces that act from each mass on the other.
EXAMPLE 2.2
A Two-Mass System: Suspension Model
Figure 2.4 shows an automobile suspension system. Write the equations
of motion for the automobile and wheel motion assuming one-dimensional
vertical motion of one quarter of the car mass above one wheel. A system
consisting of one of the four wheel suspensions is usually referred to as a
quarter-car model. The system can be approximated by the simpliﬁed sys-
tem shown in Fig. 2.5 where two spring constants and a damping coefﬁcient
are deﬁned. Assume that the model is for a car with a mass of 1580 kg,
including the four wheels, which have a mass of 20 kg each. By placing
a known weight (an author) directly over a wheel and measuring the car's
deﬂection, we ﬁnd that ks = 130,000 N/m. Measuring the wheel's deﬂection
for the same applied weight, we ﬁnd that kw ≃1,000,000 N/m. By using the
step response data in Fig. 3.19(b) and qualitatively observing that the car's
response to a step change matches the damping coefﬁcient curve for ζ = 0.7
in the ﬁgure, we conclude that b = 9800 N·sec/m.
Figure 2.4
Automobile suspension
Figure 2.5
The quarter-car model
m1
m2
b
y
x
r
ycar
Road surface
Inertial reference
ks
kw

2.1 Dynamics of Mechanical Systems
29
Solution. The system can be approximated by the simpliﬁed system shown
in Fig. 2.5. The coordinates of the two masses, x and y, with the reference
directions as shown, are the displacements of the masses from their equi-
librium conditions. The equilibrium positions are offset from the springs'
unstretched positions because of the force of gravity. The shock absorber
is represented in the schematic diagram by a dashpot symbol with friction
constant b. The magnitude of the force from the shock absorber is assumed to
be proportional to the rate of change of the relative displacement of the two
masses—that is, the force = b( ˙y−˙x). The force of gravity could be included
in the free-body diagram; however, its effect is to produce a constant offset of
x and y. By deﬁning x and y to be the distance from the equilibrium position,
the need to include the gravity forces is eliminated.
The force from the car suspension acts on both masses in proportion
to their relative displacement with spring constant ks. Figure 2.6 shows the
free-body diagram of each mass. Note that the forces from the spring on the
two masses are equal in magnitude but act in opposite directions, which is
also the case for the damper.A positive displacement y of mass m2 will result
in a force from the spring on m2 in the direction shown and a force from
the spring on m1 in the direction shown. However, a positive displacement
x of mass m1 will result in a force from the spring ks on m1 in the opposite
direction to that drawn in Fig. 2.6, as indicated by the minus x term for the
spring force.
The lower spring kw represents the tire compressibility, for which there
is insufﬁcient damping (velocity-dependent force) to warrant including a
dashpot in the model. The force from this spring is proportional to the dis-
tance the tire is compressed and the nominal equilibrium force would be
that required to support m1 and m2 against gravity. By deﬁning x to be the
distance from equilibrium, a force will result if either the road surface has a
bump (r changes from its equilibrium value of zero) or the wheel bounces
(x changes). The motion of the simpliﬁed car over a bumpy road will result
in a value of r(t) that is not constant.
As previously noted, there is a constant force of gravity acting on each
mass; however, this force has been omitted, as have been the equal and
opposite forces from the springs. Gravitational forces can always be omitted
from vertical-spring mass systems (1) if the position coordinates are deﬁned
from the equilibrium position that results when gravity is acting, and (2) if
the spring forces used in the analysis are actually the perturbation in spring
forces from those forces acting at equilibrium.
Figure 2.6
Free-body diagrams for
suspension system
m1
x
kw(x - r)
ks(y - x)
m2
y
b(y - x)
ks(y - x)
b(y - x)

30
Chapter 2 Dynamic Models
Applying Eq. (2.1) to each mass and noting that some forces on each
mass are in the negative (down) direction yields the system of equations
b( ˙y −˙x) + ks( y −x) −kw(x −r) = m1¨x,
(2.8)
−ks( y −x) −b( ˙y −˙x) = m2¨y.
(2.9)
Some rearranging results in
¨x + b
m1
(˙x −˙y) + ks
m1
(x −y) + kw
m1
x = kw
m1
r,
(2.10)
¨y + b
m2
( ˙y −˙x) + ks
m2
( y −x) = 0.
(2.11)
The most common source of error in writing equations for systems
like these are sign errors. The method for keeping the signs straight in the
Check for sign errors
preceding development entailed mentally picturing the displacement of the
masses and drawing the resulting force in the direction that the displacement
would produce. Once you have obtained the equations for a system, a check
on the signs for systems that are obviously stable from physical reasoning can
be quickly carried out. As we will see when we study stability in Section 6
of Chapter 3, a stable system always has the same signs on similar variables.
For this system, Eq. (2.10) shows that the signs on the ¨x, ˙x, and x terms are
all positive, as they must be for stability. Likewise, the signs on the ¨y, ˙y, and
y terms are all positive in Eq. (2.11).
The transfer function is obtained in a similar manner as before for zero
initial conditions. Substituting s for d/dt in the differential equations yields
s2X(s) + s b
m1
(X(s) −Y(s)) + ks
m1
(X(s) −Y(s)) + kw
m1
X(s) = kw
m1
R(s),
s2Y(s) + s b
m2
(Y(s) −X(s)) + ks
m2
(Y(s) −X(s)) = 0,
which, after some algebra and rearranging to eliminate X(s), yields the
transfer function
Y (s)
R (s) =
kwb
m1m2

s + ks
b

s4 +

b
m1 + b
m2

s3 +

ks
m1 + ks
m2 + kw
m1

s2 +

kwb
m1m2

s + kwks
m1m2
.
(2.12)
To determine numerical values, we subtract the mass of the four wheels
from the total car mass of 1580 kg and divide by 4 to ﬁnd that m2 = 375 kg.
The wheel mass was measured directly to be m1 = 20 kg. Therefore, the
transfer function with the numerical values is
Y(s)
R(s) =
1.31e06(s + 13.3)
s4 + (516.1)s3 + (5.685e04)s2 + (1.307e06)s + 1.733e07.
(2.13)

2.1 Dynamics of Mechanical Systems
31
We will see in Chapter 3 and later chapters how this sort of transfer function
will allow us to ﬁnd the response of the car body to inputs resulting from the
car motion over a bumpy road.
2.1.2
Rotational Motion
Application of Newton's law to one-dimensional rotational systems requires
Newton's law for
rotational motion
that Eq. (2.1) be modiﬁed to
M = Iα,
(2.14)
where
M = the sum of all external moments about the center of mass of a body,
N · m,
I = the body's mass moment of inertia about its center of mass, kg·m2,
α = the angular acceleration of the body, rad/sec2.
EXAMPLE 2.3
Rotational Motion: Satellite Attitude Control Model
Satellites, as shown in Fig. 2.7, usually require attitude control so that anten-
nas, sensors, and solar panels are properly oriented. Antennas are usually
pointed toward a particular location on earth, while solar panels need to be
oriented toward the sun for maximum power generation. To gain insight into
the full three-axis attitude control system, it is helpful to consider one axis
at a time. Write the equations of motion for one axis of this system and show
how they would be depicted in a block diagram. In addition, determine the
transfer function of this system and construct the system as if it were to be
evaluated via Matlab's Simulink.
Solution. Figure 2.8 depicts this case, where motion is allowed only about
the axis perpendicular to the page. The angle θ that describes the satellite
orientation must be measured with respect to an inertial reference—that is,
a reference that has no angular acceleration. The control force comes from
reaction jets that produce a moment of Fcd about the mass center. There
may also be small disturbance moments MD on the satellite, which arise
primarily from solar pressure acting on any asymmetry in the solar panels.
Applying Eq. (2.14) yields the equation of motion
Fcd + MD = I ¨θ.
(2.15)
The output of this system, θ, results from integrating the sum of the input
Double-integrator
plant
torques twice; hence this type of system is often referred to as the double-
integrator plant. The transfer function can be obtained as described for
Eq. (2.7) and is
(s)
U(s) = 1
I
1
s2 ,
(2.16)

32
Chapter 2 Dynamic Models
Figure 2.7
Communications
satellite
Source: Courtesy Space
Systems/Loral (SSL)
Figure 2.8
Satellite control
schematic
MD
Fc
u
u
Inertial
reference
Gas
jet
d

2.1 Dynamics of Mechanical Systems
33
Figure 2.9
Block diagrams
representing Eq. (2.15)
in the upper half and
Eq. (2.16) in the lower
half
Fcd + MD
s2®(s)
s ®(s)
®(s)
 U(s)
1
I
1
I
1
s
1
s
u
u
u
Figure 2.10
Simulink block diagram
of the
double-integrator plant
1
s
U
1/I
Integrator 1 Integrator 2
Scope
1
1
1
s
where U = Fcd + MD. In this form, the system is often referred to as the
1/s2 plant.
1/s2 plant
Figure 2.9 shows a block diagram representing Eq. (2.15) in the upper
half and a block diagram representing Eq. (2.16) in the lower half. This
simple system can be analyzed using the linear analysis techniques that are
described in later chapters, or via Matlab as we saw in Example 2.1. It
can also be numerically evaluated for an arbitrary input time history using
Simulink, which is a sister software package to Matlab for interactive, non-
linear simulation and has a graphical user interface with drag and drop
properties. Figure 2.10 shows a block diagram of the system as depicted
by Simulink.
In many cases a system, such as the disk-drive read/write head shown
in Fig. 2.11, in reality has some ﬂexibility, which can cause problems in the
design of a control system. Particular difﬁculty arises when there is ﬂexibil-
ity, as in this case, between the sensor and actuator locations. Therefore, it is
often important to include this ﬂexibility in the model even when the system
seems to be quite rigid.
EXAMPLE 2.4
Flexibility: Flexible Read/Write for a Disk Drive
Assume that there is some ﬂexibility between the read head and the drive
motor in Fig. 2.11. Find the equations of motion relating the motion of the
read head to a torque applied to the base.
Solution. The dynamic model for this situation is shown schematically in
Fig. 2.12. This model is dynamically similar to the resonant system shown
in Fig. 2.5 and results in equations of motion that are similar in form to
Eqs. (2.10) and (2.11). The moments on each body are shown in the free-
body diagrams in Fig. 2.13. The discussion of the moments on each body
is essentially the same as the discussion for Example 2.2, except that the
springs and damper in that case produced forces, instead of moments that

34
Chapter 2 Dynamic Models
Figure 2.11
Disk read/write
mechanism
Source: Courtesy of the
authors
Figure 2.12
Disk read/write head
schematic for modeling
Head
inertia
I2
Motor
inertia
I1
Flexible
shaft
k, b
Mc  +  MD
u1
Read head and
track sensor
Disk
u2
act on each inertia, as in this case. When the moments are summed, equated
to the accelerations according to Eq. (2.14), and rearranged, the result is
I1 ¨θ1 + b( ˙θ1 −˙θ2) + k(θ1 −θ2) = Mc + MD,
(2.17)
I2 ¨θ2 + b( ˙θ2 −˙θ1) + k(θ2 −θ1) = 0.
(2.18)

2.1 Dynamics of Mechanical Systems
35
Figure 2.13
Free-body diagrams of
the disk read/write
head
Mc  +  MD
u1
u1
k(u1 - u2)
b(u1 - u2)
k(u1 - u2)
b(u1 - u2)
I1
I2
u2
u2
Ignoring the disturbance torque MD and the damping b for simplicity,
we ﬁnd the transfer function from the applied torque Mc to the read head
motion to be
2 (s)
Mc (s) =
k
I1I2s2

s2 + k
I1 + k
I2
.
(2.19)
It might also be possible to sense the motion of the inertia where the
torque is applied, θ1, in which case the transfer function with the same
simpliﬁcations would be
1 (s)
Mc (s) =
I2s2 + k
I1I2s2

s2 + k
I1 + k
I2
.
(2.20)
These two cases are typical of many situations in which the sensor and
actuator may or may not be placed in the same location in a ﬂexible body.
We refer to the situation between sensor and actuator in Eq. (2.19) as the
Collocated sensor and
actuator
"noncollocated" case,whereas Eq. (2.20) describes the "collocated" case.
You will see in Chapter 5 that it is far more difﬁcult to control a system
when there is ﬂexibility between the sensor and actuator (noncollocated
case) than when the sensor and actuator are rigidly attached to one another
(the collocated case).
In the special case in which a point in a rotating body is ﬁxed with respect
to an inertial reference frame, as is the case with a pendulum, Eq. (2.14) can
be applied such that M is the sum of all moments about the ﬁxed point and
I is the moment of inertia about the ﬁxed point.
EXAMPLE 2.5
Rotational Motion: Pendulum
1. Write the equations of motion for the simple pendulum shown in
Fig. 2.14, where all the mass is concentrated at the end point and there
is a torque, Tc, applied at the pivot.
2. Use Matlab to determine the time history of θ to a step input in Tc of
1 N·m. Assume l = 1 m, m = 1 kg, and g = 9.81 m/sec2.

36
Chapter 2 Dynamic Models
Figure 2.14
Pendulum
mg
Tc
u
l
Solution
1. Equations of motion: The moment of inertia about the pivot point is
I = ml2. The sum of moments about the pivot point contains a term
from gravity as well as the applied torque Tc. The equation of motion,
obtained from Eq. (2.14), is
Tc −mgl sin θ = I ¨θ,
(2.21)
which is usually written in the form
¨θ + g
l sin θ = Tc
ml2 .
(2.22)
This equation is nonlinear due to the sin θ term. A general discussion of
nonlinear equations is contained in Chapter 9; however, we can proceed
with a linearization of this case by assuming the motion is small enough
that sin θ ∼= θ. Then Eq. (2.22) becomes the linear equation
¨θ + g
l θ = Tc
ml2 .
(2.23)
With no applied torque, the natural motion is that of a harmonic
oscillator with a natural frequency of 4
ωn =
g
l .
(2.24)
ThetransferfunctioncanbeobtainedasdescribedforEq.(2.7), yielding
(s)
Tc(s) =
1
ml2
s2 + g
l
.
(2.25)
4In a grandfather clock it is desired to have a pendulum period of exactly 2 sec. Show that the
pendulum should be approximately 1 m in length.

2.1 Dynamics of Mechanical Systems
37
2. Time history: The dynamics of a system can be prescribed to Matlab in
terms of its transfer function and the step response via the step function.
The Matlab statements
t = 0:0.02:10;
% vector of times for output, 0 to 10 at 0.02
increments
m = 1;
% value of mass (Kg)
L = 1;
% value of length (m)
g = 9.81;
% value of gravity, g (m/sec2)
s = tf('s');
% sets up transfer function input mode
sys = (1/(m*Lˆ2))/
(sˆ2 + g/L)
y = step(sys,t);
% computes step responses at times given
by t for step at t = 0
Rad2Deg = 57.3;
% converts radians to degrees
plot(t, Rad2Deg*y)
% converts output from radians to degrees
and plots step response
will produce the desired time history shown in Fig. 2.15.
As we saw in this example, the resulting equations of motion are often
nonlinear. Such equations are much more difﬁcult to solve than linear ones,
and the kinds of possible motions resulting from a nonlinear model are much
more difﬁcult to categorize than those resulting from a linear model. It is
therefore useful to linearize models in order to gain access to linear analysis
methods. It may be that the linear models and linear analysis are used only
for the design of the control system (whose function may be to maintain
Figure 2.15
Response of the
pendulum to a step
input of 1 N·m in the
applied torque
0
2
4
6
8
10
0
2
4
6
8
10
12
Time (sec)
Pendulum angle, u (°)

38
Chapter 2 Dynamic Models
the system in the linear region). Once a control system is synthesized and
shown to have desirable performance based on linear analysis, it is then
prudent to carry out further analysis or an accurate numerical simulation
of the system with the signiﬁcant nonlinearities in order to validate that
performance. Simulink is an expedient way to carry out these simulations
Simulink
and can handle most nonlinearities. Use of this simulation tool is carried out
byconstructingablockdiagram5 thatrepresentstheequationsofmotion. The
linear equation of motion for the pendulum with the parameters as speciﬁed
in Example 2.5 can be seen from Eq. (2.23) to be
¨θ = −9.81 ∗θ + 1,
(2.26)
and this is represented in Simulink by the block diagram in Fig. 2.16. Note
that the circle on the left side of the ﬁgure, with the + and −signs indicating
addition and subtraction, implements Eq. (2.26).
The result of running this numerical simulation will be essentially iden-
tical to the linear solution shown in Fig. 2.15 because the solution is for
relatively small angles where sin θ ∼= θ. However, using Simulink to solve
fortheresponseenablesustosimulatethenonlinearequationsothatwecould
analyze the system for larger motions. In this case, Eq. (2.26) becomes
¨θ = −9.81 ∗sin θ + 1,
(2.27)
andtheSimulinkblockdiagramshowninFig.2.17implementsthisnonlinear
equation.
Simulink is capable of simulating all commonly encountered non-
linearities, including deadzones, on-off functions, stiction, hysteresis,
aerodynamic drag (a function of v2), and trigonometric functions. All real
Figure 2.16
The Simulink block
diagram representing
the linear equation
(2.26)
Step
Gain 1
Integrator
Ts
Integrator 1
Gain 2
Gain
9.81
9.81*
57.3
Scope
1
1s
1s
(°)
u
u
u
u
u
Figure 2.17
The Simulink block
diagram representing
the nonlinear
equation (2.27)
Step Gain 1
Gain 3
Integrator 3
Integrator 2
Trigonometric
function
57.3
1
9.81
sin
Scope
1
S
1
S
5A more extensive discussion of block diagrams is contained in Section 2.1 of Chapter 3

2.1 Dynamics of Mechanical Systems
39
systems have one or more of these characteristics in varying degrees. These
nonlinearities will be expanded upon in detail in Chapter 9.
EXAMPLE 2.6
Use of Simulink for Nonlinear Motion: Pendulum
Use Simulink to determine the time history of θ for the pendulum in Exam-
ple 2.5. Compare it against the linear solution for Tc values of 1 N·m and 4
N·m.
Solution.
Time history: The Simulink block diagrams for the two cases
discussed above are combined and both outputs in Figs. 2.16 and 2.17 are
sent via a "multiplexer block (Mux)" to the "scope" so they can be plotted
on the same graph. Figure 2.18 shows the combined block diagram where
the gain, K, represents the values of Tc. The outputs of this system for Tc
values of 1 N · m and 4 N· m are shown in Fig. 2.19. Note that for Tc =
1 N·m, the outputs at the top of the ﬁgure remain at 12◦or less and the
linear approximation is extremely close to the nonlinear output. For Tc =
4 N·m, the output angle grows near to 50◦and a substantial difference in
the response magnitude and frequency is apparent due to θ being a poor
approximation to sin θ at these magnitudes. In fact, since sin θ compared to
θ signiﬁes a reduced gravitational restoring force at the higher angles, we
see an increased amplitude and slower frequency.
Chapter 9 is devoted to the analysis of nonlinear systems and greatly
expands on these ideas.
2.1.3
Combined Rotation and Translation
In some cases, mechanical systems contain both translational and rotational
portions. The procedure is the same as that described in Sections 2.1.1
and 2.1.2: sketch the free-body diagrams, deﬁne coordinates and positive
directions, determine all forces and moments acting, and apply Eqs. (2.1)
and/or (2.14). An exact derivation of the equations for these systems can
become quite involved; therefore, the complete analysis for the following
Figure 2.18
Block diagram of the
pendulum for both the
linear and nonlinear
models
Integrator
Integrator 1
Integrator 2
Step
K
Gain 1
Gain 3
Trigonometric
function
Gain
Gain 2
Mux
Scope
9.81
9.81
57.3
1s
Integrator 3
1s
1s
sin
1s

40
Chapter 2 Dynamic Models
Figure 2.19
Response of the
pendulum Simulink
numerical simulation
for the linear and
nonlinear models:
(a) for Tc = 1 N·m;
(b) Tc = 4 N·m
0
1
2
3
4
5
6
7
8
9
10
0
Time (sec)
u (°)
Linear
(b) Tc = 4 N.m
Nonlinear
5
10
15
20
25
30
35
40
45
50
0
u (°)
Linear
response
(a) Tc = 1 N.m
Nonlinear
response
5
10
15
20
25
30
35
40
45
50
example is contained in Appendix W2.1.4 located at www.FPE7e.com and
only the linearized equations of motion and their transfer functions are given
here.
EXAMPLE 2.7
Rotational and Translational Motion: Hanging Crane
Write the equations of motion for the hanging crane shown schematically
in Fig. 2.20. Linearize the equations about θ = 0, which would typically be
valid for the hanging crane. Also linearize the equations for θ = π, which
represents the situation for the inverted pendulum shown in Fig. 2.21. The
trolley has mass mt and the hanging crane (or pendulum) has mass mp and
inertia about its mass center of I. The distance from the pivot to the mass
center of the pendulum is l; therefore, the moment of inertia of the pendulum
about the pivot point is (I + mpl2).

2.1 Dynamics of Mechanical Systems
41
Figure 2.20
Schematic of the crane
with hanging load
x
u
mt
u
I, mp
Figure 2.21
Inverted pendulum
x
u
mt
u¿
I, mp
Solution.
Free-body diagrams need to be drawn for the trolley and the
pendulum and the reaction forces considered where the two attach to one
another. We carry out this process in Appendix W2.1.3. After Newton's
laws are applied for the translational motion of the trolley and the rotational
motion of the pendulum, it will be found that the reaction forces between
the two bodies can be eliminated, and the only unknowns will be θ and x.
The results are two coupled second-order nonlinear differential equations in
θ and x with the input being the force applied to the trolley, u. They can
be linearized in a manner similar to that done for the simple pendulum by
assuming small angles. For small motions about θ = 0, we let cos θ ∼= 1,
sin θ ∼= θ, and ˙θ2 ∼= 0; thus the equations are approximated by
(I + mpl2) ¨θ + mpglθ = −mpl¨x,
(mt + mp)¨x + b˙x + mpl ¨θ = u.
(2.28)
Note that the ﬁrst equation is very similar to the simple pendulum,
Eq. (2.21), where the applied torque arises from the trolley accelerations.
Likewise, the second equation representing the trolley motion, x, is very
similar to the car translation in Eq. (2.3), where the forcing term arises from
the angular acceleration of the pendulum. Eliminating x in these two coupled
equations leads to the desired transfer function. Neglecting the friction term,
b, simpliﬁes the algebra and leads to an approximate transfer function from
the control input u to hanging crane angle θ:
(s)
U(s) =
−mpl
((I + mpl2)(mt + mp) −m2pl2)s2 + mpgl(mt + mp).
(2.29)

42
Chapter 2 Dynamic Models
For the inverted pendulum in Fig. 2.21, where θ ∼= π, assume θ = π + θ′,
where θ′ represents motion from the vertical upward direction. In this case,
Inverted pendulum
equations
sin θ ∼= −θ′, cos θ ∼= −1, and the nonlinear equations become6
(I + mpl2) ¨θ′ −mpglθ′ = mpl¨x,
(mt + mp)¨x + b˙x −mpl ¨θ′ = u.
(2.30)
As noted in Example 2.2, a stable system will always have the same signs
on each variable, which is the case for the stable hanging crane modeled by
Eqs. (2.28). However, the signs on θ and ¨θ in the ﬁrst equation in Eq. (2.30)
are opposite, thus indicating instability, which is the characteristic of the
inverted pendulum.
The transfer function, again without friction, is
′(s)
U(s) =
mpl
((I + mpl2)(mt + mp) −m2pl2)s2 −mpgl(mt + mp).
(2.31)
Evaluation of this transfer function for an inﬁnitessimal step in u will result
in a diverging value of θ′ thus requiring feedback to remain upright, a subject
for Chapter 5.
In Chapter 5 you will learn how to stabilize systems using feedback
and will see that even unstable systems like an inverted pendulum can be
stabilized provided there is a sensor that measures the output quantity and
a control input. For the case of the inverted pendulum perched on a trolley,
it would be required to measure the pendulum angle, θ′, and provide a
control input, u, that accelerated the trolley in such a way that the pendulum
remained pointing straight up. In years past, this system existed primarily in
university control system laboratories as an educational tool. However, more
recently, there is a practical device in production and being sold that employs
essentially this same dynamic system: The Segway. It uses a gyroscope so
that the angle of the device is known with respect to vertical, and electric
motors provide a torque on the wheels so that it balances the device and
provides the desired forward or backward motion. It is shown in Fig. 2.22.
2.1.4
Complex Mechanical Systems
Thissectioncontainsthederivationoftheequationsofmotionformechanical
systems. In particular, it contains the full derivation of the equations of
motion for the hanging crane in Example 2.7 and the inverted pendulum on
a cart. See Appendix W2.1.4 at www.FPE7e.com.
2.1.5
Distributed Parameter Systems
All the preceding examples contained one or more rigid bodies, although
some were connected to others by springs. Actual structures—for exam-
ple, satellite solar panels, airplane wings, or robot arms—usually bend, as
6The inverted pendulum is often described with the angle of the pendulum being positive for
clockwise motion. If deﬁned that way, then the sign reverses on all terms in Eqs. (2.30) in θ′
or ¨θ′.

2.1 Dynamics of Mechanical Systems
43
Figure 2.22
The Segway, which is
similar to the inverted
pendulum and is kept
upright by a feedback
control system
Source: Photo courtesy of
David Powell
shown by the ﬂexible beam in Fig. 2.23(a). The equation describing its
motion is a fourth-order partial differential equation that arises because the
mass elements are continuously distributed along the beam with a small
amount of ﬂexibility between elements. This type of system is called a
distributed parameter system. The dynamic analysis methods presented
in this section are not sufﬁcient to analyze this case; however, more advanced
texts (Thomson and Dahleh, 1998) show that the result is
EI ∂4w
∂x4 + ρ ∂2w
∂t2 = 0,
(2.32)
where
E = Young's modulus,
I = beam area moment of inertia,
ρ = beam density,
w = beam deﬂection at length x along the beam.
The exact solution to Eq. (2.32) is too cumbersome to use in designing
control systems, but it is often important to account for the gross effects of
bending in control systems design.

44
Chapter 2 Dynamic Models
Figure 2.23
(a) Flexible robot arm
used for research at
Stanford University;
(b) model for
continuous ﬂexible
beam;(c) simpliﬁed
model for the ﬁrst
bending mode;
(d) model for the ﬁrst
and second bending
modes
Source: Photo courtesy of
E. Schmitz/Courtesy of authors
(b)
(c)
(d)
w
The continuous beam in Fig. 2.23(b) has an inﬁnite number of vibration-
mode shapes, all with different frequencies. Typically, the lowest-frequency
modes have the largest amplitude and are the most important to approxi-
mate well. The simpliﬁed model in Fig. 2.23(c) can be made to duplicate
the essential behavior of the ﬁrst bending mode shape and frequency and
would usually be adequate for controller design. If frequencies higher than
the ﬁrst bending mode are anticipated in the control system operation, it
may be necessary to model the beam as shown in Fig. 2.23(d), which can
be made to approximate the ﬁrst two bending modes and frequencies. Like-
wise, higher-order models can be used if such accuracy and complexity are
A ﬂexible structure can be
approximated by a lumped
parameter model
deemed necessary (Schmitz, 1985; Thomson and Dahleh, 1998). When a
continuously bending object is approximated as two or more rigid bodies
connected by springs, the resulting model is sometimes referred to as a
lumped parameter model.
2.1.6
Summary: Developing Equations of Motion for Rigid
Bodies
The physics necessary to write the equations of motion of a rigid body is
entirely given by Newton's laws of motion. The method is as follows:

2.2 Models of Electric Circuits
45
1. Assign variables such as x and θ that are both necessary and sufﬁcient
to describe an arbitrary position of the object.
2. Draw a free-body diagram of each component. Indicate all forces acting
on each body and their reference directions. Also indicate the accelera-
tions of the center of mass with respect to an inertial reference for each
body.
3. ApplyNewton'slawintranslation[Eq.(2.1)]and/orrotation[Eq.(2.14)]
form.
4. Combine the equations to eliminate internal forces.
5. The number of independent equations should equal the number of
unknowns.
2.2
Models of Electric Circuits
Electric circuits are frequently used in control systems largely because of
the ease of manipulation and processing of electric signals. Although con-
trollers are increasingly implemented with digital logic, many functions are
still performed with analog circuits. Analog circuits are faster than digital
and, for very simple controllers, an analog circuit would be less expensive
than a digital implementation. Furthermore, the power ampliﬁer for elec-
tromechanical control and the anti-alias preﬁlters for digital control must be
analog circuits.
Electric circuits consist of interconnections of sources of electric voltage
and current, and other electronic elements such as resistors, capacitors, and
transistors. An important building block for circuits is an operational ampli-
ﬁer (or op-amp),7 which is also an example of a complex feedback system.
Some of the most important methods of feedback system design were devel-
oped by the designers of high-gain, wide-bandwidth feedback ampliﬁers,
mainly at the Bell Telephone Laboratories between 1925 and 1940. Elec-
tric and electronic components also play a central role in electromechanical
energy conversion devices such as electric motors, generators, and electrical
sensors. In this brief survey we cannot derive the physics of electricity or
give a comprehensive review of all the important analysis techniques. We
will deﬁne the variables, describe the relations imposed on them by typi-
cal elements and circuits, and describe a few of the most effective methods
available for solving the resulting equations.
Symbols for some linear circuit elements and their current-voltage rela-
tions are given in Fig. 2.24. Passive circuits consist of interconnections of
resistors, capacitors, and inductors. With electronics, we increase the set of
electrical elements by adding active devices, including diodes, transistors,
and ampliﬁers.
7Oliver Heaviside introduced the mathematical operation p to signify differentiation so that
pv = dv/dt. The Laplace transform incorporates this idea, using the complex variable s.
Ragazzini et al. (1947) demonstrated that an ideal, high-gain electronic ampliﬁer permitted
one to realize arbitrary "operations" in the Laplace transform variable s, so they named it the
operational ampliﬁer, commonly abbreviated to op-amp.

46
Chapter 2 Dynamic Models
Figure 2.24
Elements of electric
circuits
i
 + 
 - 
i
 + 
 - 
ys
 + 
 - 
i
 + 
y
y
y
y
 - 
Resistor
Capacitor
Inductor
Voltage
source
Symbol
y = Ri
Equation
i = C dy
dt
y = L di
dt
y = ys
is
i
Current
source
i = is
The basic equations of electric circuits, called Kirchhoff's laws, are as
Kirchhoff's laws
follows:
1. Kirchhoff's current law (KCL): The algebraic sum of currents leaving
a junction or node equals the algebraic sum of currents entering that
node.
2. Kirchhoff's voltage law (KVL): The algebraic sum of all voltages
taken around a closed path in a circuit is zero.
With complex circuits of many elements, it is essential to write the equa-
tions in a careful, well-organized way. Of the numerous methods for doing
this, we choose for description and illustration the popular and powerful
scheme known as node analysis. One node is selected as a reference and
we assume the voltages of all other nodes to be unknowns. The choice of
reference is arbitrary in theory, but in actual electronic circuits the common,
or ground, terminal is the obvious and standard choice. Next, we write equa-
tions for the selected unknowns using the current law (KCL) at each node.
We express these currents in terms of the selected unknowns by using the
element equations in Fig. 2.24. If the circuit contains voltage sources, we

2.2 Models of Electric Circuits
47
must substitute a voltage law (KVL) for such sources. Example 2.8 illustrates
how node analysis works.
EXAMPLE 2.8
Equations for the Bridged Tee Circuit
Determine the differential equations for the circuit shown in Fig. 2.25.
Solution. We select node 4 as the reference and the voltages v1, v2, and
v3 at nodes 1, 2, and 3 as the unknowns. We start with the degenerate KVL
relationship
v1 = vi.
(2.33)
At node 2 the KCL is
−v1 −v2
R1
+ v2 −v3
R2
+ C1
dv2
dt = 0,
(2.34)
and at node 3 the KCL is
v3 −v2
R2
+ C2
d(v3 −v1)
dt
= 0.
(2.35)
These three equations describe the circuit. If desired, one could eliminate v2
from the above equations, thus obtaining a second-order differential equation
that describes the dynamic relationship between the input, vi(= v1), and
output, v3(= vo).
EXAMPLE 2.9
Equations for a Circuit with a Current Source
Determine the differential equations for the circuit shown in Fig. 2.26.
Choose the capacitor voltages and the inductor current as the unknowns.
Solution. We select node 4 as the reference and the voltages v1 and v2 at
nodes 1 and 2 and the current through the capacitor, iL, as unknowns. We
start with the KCL relationships:
At node 1 the KCL is
i(t) = i3 + i1 + iL,
(2.36)
and at node 2 the KCL is
iL = i2 + i4.
(2.37)
Figure 2.25
Bridged tee circuit
 +  - 
 + 
 - 
C2
C1
3
2
1
4
 + 
 - 
y0
y3
y2
y1
yi
 + 
 - 
R2
R1
 + 
 - 
 + 
 - 

48
Chapter 2 Dynamic Models
Figure 2.26
Circuit for Example 2.9
R1
C1
C2
L
R2
i4
i2
i(t)
iL
i1
i3
1
4
y1
2 y2
y = 0
Furthermore, from Fig. 2.24, we see that
i3 = v1
R1
,
(2.38)
i1 = C1
dv1
dt ,
(2.39)
i2 = C2
dv2
dt ,
(2.40)
i4 = v2
R2
,
(2.41)
v1 −v2 = L diL
dt .
(2.42)
These reduce to three differential equations in the three unknowns,
i(t) = v1
R1
+ C1
dv1
dt + iL,
(2.43)
iL = C2
dv2
dt + v2
R2
,
(2.44)
v1 = L diL
dt +v2.
(2.45)
Kirchhoff's laws can also be applied to circuits that contain an
operational ampliﬁer. The simpliﬁed circuit of the op-amp is shown in
Operational ampliﬁer
Fig. 2.27(a) and the schematic symbol is drawn in Fig. 2.27(b). If the posi-
tive terminal is not shown, it is assumed to be connected to ground, v+ = 0,
and the reduced symbol of Fig. 2.27(c) is used. For use in control circuits, it
is usually assumed that the op-amp is ideal with the values R1 = ∞, R0 = 0,
and A = ∞. The equations of the ideal op-amp are extremely simple, being
i+ = i−= 0,
(2.46)
v+ −v−= 0.
(2.47)
The gain of the ampliﬁer is assumed to be so high that the output voltage
becomes vout = whatever it takes to satisfy these equations. Of course, a real
ampliﬁer only approximates these equations, but unless they are speciﬁcally
described, we will assume all op-amps are ideal. More realistic models are
the subject of several problems given at the end of the chapter.

2.2 Models of Electric Circuits
49
Figure 2.27
(a) Op-amp simpliﬁed
circuit; (b) op-amp
schematic symbol;
(c) reduced symbol
for v+ = 0
R1
R0
i-
i-
i0
i+
i+
+
-
y0 = A(y+ - y-)
y0
y0
(a)
(b)
(c)
-
+
-
y-
y-
y-
y+
y+
EXAMPLE 2.10
Op-Amp Summer
Find the equations and transfer functions of the circuit shown in Fig. 2.28.
Solution.
Equation (2.47) requires that v−= 0, and thus the currents
are i1 = v1/R1, i2 = v2/R2, and iout = vout/Rf . To satisfy Eq. (2.46),
i1 + i2 + iout = 0, from which it follows that v1/R1 + v2/R2 + vout/Rf = 0,
and we have
vout = −
Rf
R1
v1 + Rf
R2
v2

.
(2.48)
From this equation we see that the circuit output is a weighted sum of the
input voltages with a sign change. The circuit is called a summer.
The op-amp summer
A second important example for control is given by the op-amp
integrator.
EXAMPLE 2.11
Integrator
Find the transfer function for the circuit shown in Fig. 2.29.
Op-amp as integrator
Figure 2.28
The op-amp summer
y1
Rf
R1
R2
y2
-
i2
i1
iout
yout

50
Chapter 2 Dynamic Models
Figure 2.29
The op-amp integrator
yin
C
Rin
-
iout
yout
Solution.
In this case the equations are differential and Eqs. (2.46) and
(2.47) require
iin + iout = 0,
(2.49)
so that
vin
Rin
+ C dvout
dt
= 0.
(2.50)
Equation (2.50) can be written in integral form as
vout = −
1
RinC
	 t
0
vin(τ) dτ + vout(0).
(2.51)
Using the operational notation that d/dt = s in Eq. (2.50), the transfer
function (which assumes zero initial conditions) can be written as
Vout(s) = −1
s
Vin(s)
RinC .
(2.52)
Thus the ideal op-amp in this circuit performs the operation of
integration and the circuit is simply referred to as an integrator.
2.3
Models of Electromechanical Systems
Electric current and magnetic ﬁelds interact in two ways that are particularly
important to an understanding of the operation of most electromechanical
actuators and sensors. If a current of i amp in a conductor of length l m is
arranged at right angles in a magnetic ﬁeld of B teslas, then there is a force
on the conductor at right angles to the plane of i and B, with magnitude
F = Bli N.
(2.53)
This equation is the basis of conversion of electric energy to mechanical
Law of motors
work and is called the law of motors.
2.3.1
Loudspeakers
EXAMPLE 2.12
Modeling a Loudspeaker
A typical geometry for a loudspeaker for producing sound is sketched in
Fig. 2.30. The permanent magnet establishes a radial ﬁeld in the cylindrical
gap between the poles of the magnet. The force on the conductor wound on

2.3 Models of Electromechanical Systems
51
Figure 2.30
Geometry of a
loudspeaker: (a) overall
conﬁguration; (b) the
electromagnet and
voice coil
Permanent magnet
Coil
Cone
Bobbin
S
N
S
Electromagnet
Cone
(a)
(b)
Low-force
suspension
the bobbin causes the voice coil to move, producing sound.8 The effects of
the air can be modeled as if the cone had equivalent mass M and viscous
friction coefﬁcient b. Assume that the magnet establishes a uniform ﬁeld
B of 0.5 tesla and the bobbin has 20 turns at a 2-cm diameter. Write the
equations of motion of the device.
Solution. The current is at right angles to the ﬁeld, and the force of interest
is at right angles to the plane of i and B, so Eq. (2.53) applies. In this case
the ﬁeld strength is B = 0.5 tesla and the conductor length is
l = 20 × 2π
100m = 1.26 m.
Thus, the force is
F = 0.5 × 1.26 × i = 0.63i N.
The mechanical equation follows from Newton's laws, and for a mass
M and friction coefﬁcient b, the equation is
M¨x + b˙x = 0.63i.
(2.54)
This second-order differential equation describes the motion of the loud-
speaker cone as a function of the input current i driving the system.
Substituting s for d/dt in Eq. (2.54) as before, the transfer function is easily
found to be
X(s)
I(s) =
0.63/M
s(s + b/M).
(2.55)
The second important electromechanical relationship is the effect of
mechanical motion on electric voltage. If a conductor of length l m is moving
8Similar voice-coil motors are commonly used as the actuator for the read/write head assembly
of computer hard-disk data access devices.

52
Chapter 2 Dynamic Models
in a magnetic ﬁeld of B teslas at a velocity of v m/sec at mutually right angles,
an electric voltage is established across the conductor with magnitude
e = Blv V.
(2.56)
This expression is called the law of generators.
Law of generators
EXAMPLE 2.13
Loudspeaker with Circuit
For the loudspeaker in Fig. 2.30 and the circuit driving it in Fig. 2.31, ﬁnd
the differential equations relating the input voltage va to the output cone dis-
placement x. Assume the effective circuit resistance is R and the inductance
is L.
Solution.
The loudspeaker motion satisﬁes Eq. (2.54), and the motion
results in a voltage across the coil as given by Eq. (2.56), with the velocity
˙x. The resulting voltage is
ecoil = Bl˙x = 0.63˙x.
(2.57)
This induced voltage effect needs to be added to the analysis of the circuit.
The equation of motion for the electric circuit is
L di
dt + Ri = va −0.63˙x.
(2.58)
These two coupled equations, (2.54) and (2.58), constitute the dynamic
model for the loudspeaker.
Again substituting s for d/dt in these equations, the transfer function
between the applied voltage and the loudspeaker displacement is found to
be
X(s)
Va(s) =
0.63
s

(Ms + b)(Ls + R) + (0.63)2.
(2.59)
2.3.2
Motors
A common actuator based on the laws of motors and generators and used
DC motor
actuators
in control systems is the direct current (DC) motor to provide rotarymotion.
A sketch of the basic components of a DC motor is given in Fig. 2.32. In
Figure 2.31
A loudspeaker showing
the electric circuit
 + 
 - 
ya
 + 
 - 
R
i
x
L
ecoil

2.3 Models of Electromechanical Systems
53
Figure 2.32
Sketch of a DC motor
S
Stator magnet
Rotor windings
Stator magnet
Brush
Brush
Shaft
Bearings
Shaft angle um
ia
Commutator
N
addition to housing and bearings, the nonturning part (stator) has magnets,
which establish a ﬁeld across the rotor. The magnets may be electromagnets
or, for small motors, permanent magnets. The brushes contact the rotating
commutator, which causes the current always to be in the proper conductor
windings so as to produce maximum torque. If the direction of the current
is reversed, the direction of the torque is reversed.
The motor equations give the torque T on the rotor in terms of the
armature current ia and express the back emf voltage in terms of the shaft's
Back emf
rotational velocity ˙θm.9
Thus,
T = Kt ia,
(2.60)
e = Ke ˙θm.
(2.61)
In consistent units, the torque constant Kt equals the electric constant Ke,
but in some cases the torque constant will be given in other units, such as
ounce-inches per ampere, and the electric constant may be expressed in units
of volts per 1000 rpm. In such cases the engineer must make the necessary
translations to be certain the equations are correct.
EXAMPLE 2.14
Modeling a DC Motor
Find the equations for a DC motor with the equivalent electric circuit shown
in Fig. 2.33(a). Assume that the rotor has inertia Jm and viscous friction
coefﬁcient b.
Solution.
The free-body diagram for the rotor, shown in Fig. 2.33(b),
deﬁnes the positive direction and shows the two applied torques, T and
b ˙θm. Application of Newton's laws yields
Jm ¨θm + b ˙θm = Ktia.
(2.62)
9Because the generated electromotive force (emf) works against the applied armature voltage,
it is called the back emf.

54
Chapter 2 Dynamic Models
Figure 2.33
DC motor: (a) electric
circuit of the armature;
(b) free-body diagram
of the rotor
+
-
+
-
ya
Ra
La
e = Keum
(a)
um
bum
T
(b)
ia
Jm
Analysis of the electric circuit, including the back emf voltage, shows the
electrical equation to be
La
dia
dt + Raia = va −Ke ˙θm.
(2.63)
With s substituted for d/dt in Eqs. (2.62) and (2.63), the transfer function
for the motor is readily found to be
m(s)
Va(s) =
Kt
s[(Jms + b)(Las + Ra) + KtKe].
(2.64)
In many cases the relative effect of the inductance is negligible compared
with the mechanical motion and can be neglected in Eq. (2.63). If so, we can
combine Eqs. (2.62) and (2.63) into one equation to get
Jm ¨θm +

b + KtKe
Ra

˙θm = Kt
Ra
va.
(2.65)
From Eq. (2.65) it is clear that in this case the effect of the back emf is
indistinguishable from the friction, and the transfer function is
m(s)
Va(s) =
Kt
Ra
Jms2 +

b + KtKe
Ra

s
(2.66)
=
K
s(τs + 1),
(2.67)
where
K =
Kt
bRa + KtKe
,
(2.68)
τ =
RaJm
bRa + KtKe
.
(2.69)

2.3 Models of Electromechanical Systems
55
Inmanycases, atransferfunctionbetweenthemotorinputandtheoutput
speed (ω = ˙θm) is required. In such cases, the transfer function would be
(s)
Va(s) = sm(s)
Va(s) =
K
τs + 1.
(2.70)
Another device used for electromechanical energy conversion is the
alternating current (AC) induction motor invented by N. Tesla. Elementary
AC motor actuators
analysis of the AC motor is more complex than that of the DC motor. A
typical experimental set of curves of torque versus speed for ﬁxed frequency
and varying amplitude of applied (sinusoidal) voltage is given in Fig. 2.34.
Although the data in the ﬁgure are for a constant engine speed, they can be
used to extract the motor constants that will provide a dynamic model for
the motor. For analysis of a control problem involving an AC motor such as
that described by Fig. 2.34, we make a linear approximation to the curves
for speed near zero and at a midrange voltage to obtain the expression
T = K1va −K2 ˙θm.
(2.71)
The constant K1 represents the ratio of a change in torque to a change in
voltage at zero speed and is proportional to the distance between the curves
at zero speed. The constant K2 represents the ratio of a change in torque to
a change in speed at zero speed and a midrange voltage; therefore, it is the
slope of a curve at zero speed as shown by the line at V2. For the electrical
portion, values for the armature resistance Ra and inductance La are also
determined by experiment. Once we have values for K1, K2, Ra, and La, the
analysis proceeds as the analysis in Example 2.14 for the DC motor. For the
case in which the inductor can be neglected, we can substitute K1 and K2
into Eq. (2.65) in place of Kt/Ra and KtKe/Ra, respectively.
Torque, T
Torque, T
ya = V1
ya = V2 (7V1)
Speed, um
V3
V2
V1
ya = V4
Speed, um
(a)
(b)
Slope K2
Figure 2.34
Torque-speed curves for a servo motor showing four amplitudes of armature voltage:(a) low-
rotor-resistance machine; (b) high-rotor-resistance machine showing four values of armature voltage, va

56
Chapter 2 Dynamic Models
In addition to the DC and AC motors mentioned here, control systems
use brushless DC motors (Reliance Motion Control Corp., 1980) and step-
ping motors (Kuo, 1980). Models for these machines, developed in the
works just cited, do not differ in principle from the motors considered in
this section. In general, the analysis, supported by experiment, develops the
torque as a function of voltage and speed similar to the AC motor torque-
speed curves given in Fig. 2.34. From such curves one can obtain a linearized
formula such as Eq. (2.71) to use in the mechanical part of the system and
an equivalent circuit consisting of a resistance and an inductance to use in
the electrical part.
2.3.3
Gears
Themotorsusedforcontrolpurposesareoftenusedinconjunctionwithgears
△
as shown in Fig. 2.35 in order to multiply the torque. The force transmitted
by the teeth of one gear is equal and opposite to the force applied to the other
gear as shown in Fig. 2.35(a); therefore, since torque = force × distance,
the torques applied to and from each shaft by the teeth obeys
T1
r1
= T2
r2
= f , force applied by teeth
(2.72)
and thus we see that the torque multiplication is proportional to the radius
of the gears, r, or equivalently, the number of teeth, N, in each gear,
T2
T1
= r2
r1
= N2
N1
= n,
(2.73)
where we have deﬁned the quantity, n, to be the gear ratio.
Similarly, the velocity of the contact tooth of one gear is the same as the
velocity of the tooth on the opposite gear, and since velocity = ωr, where ω
is the angular velocity,
ω1r1 = ω2r2 = v.
Thus,
ω1
ω2
= r2
r1
= N2
N1
= n.
(2.74)
Figure 2.35
(a) Geometry
deﬁnitions and forces
on teeth; (b) deﬁnitions
for the dynamic analysis
(a)
(b)
Friction, b1
Friction, b2
T2
J2
J1
T1
Tm
Gear 2
N2
Gear 1
N1
f, y
y
f
u2, v2
u1, v1
r2
r1

2.4 Heat and Fluid-Flow Models
57
Furthermore, the angles will change in proportion to the angular
velocities, so that
θ1
θ2
= ω1
ω2
= N2
N1
= n.
(2.75)
Note these are all geometric relationships in the sense that we have not
considered any inertias or accelerations of the gear train. These relationships
simply change the scale factor on the torque and speed from a motor. There
is also another effect that must be considered: the effective rotational inertia
and damping of the system when considering the dynamics. Suppose the
servo motor whose output torque is Tm is attached to gear 1. Also suppose
the servo's gear 1 is meshed with gear 2, and the angle θ2 describes its
position (body 2). Furthermore, the inertia of gear 1 and all that is attached
to it (body 1) is J1, while the inertia of the second gear and all the attached
load (body 2) is J2, similarly for the friction b1 and b2. We wish to determine
the transfer function between the applied torque, Tm, and the output θ2, that
is, 2(s)/Tm(s). The equation of motion for body 1 is
J1 ¨θ1 + b1 ˙θ1 = Tm −T1,
(2.76)
where T1 is the reaction torque from gear 2 acting back on gear 1. For body
2 the equation of motion is
J2 ¨θ2 + b2 ˙θ2 = T2,
(2.77)
where T2 is the torque applied on gear 2 by gear 1. Note that these are
not independent systems because the motion is tied together by the gears.
Substituting θ2 for θ1 in Eq. (2.76) using the relationship from Eq. (2.75),
replacing T2 with T1 in Eq. (2.77) using the relationship in Eq. (2.73), and
eliminating T1 between the two equations results in
(J2 + J1n2) ¨θ2 + (b2 + b1n2) ˙θ2 = nTm.
(2.78)
So the transfer funtion is
2(s)
Tm(s) =
n
Jeqs2 + beqs,
(2.79)
where
Jeq = J2 + J1n2, and beq = b2 + b1n2.
(2.80)
These quantities are referred to as the "equivalent" inertias and damping
coefﬁcients.10 If the transfer function had been desired between the applied
torque, Tm, and θ1, a similar analysis would be required to arrive at the
equivalent inertias and damping, which would be different from those above.
2.4
Heat and Fluid-Flow Models
Thermodynamics, heat transfer, and ﬂuid dynamics are each the subject of
△
complete textbooks. For purposes of generating dynamic models for use in
control systems, the most important aspect of the physics is to represent the
dynamic interaction between the variables. Experiments are usually required
10The equivalent inertia is sometimes referred to as "reﬂected impedance"; however, this term
is more typically applied to electronic circuits.

58
Chapter 2 Dynamic Models
to determine the actual values of the parameters and thus to complete the
dynamic model for purposes of control systems design.
2.4.1
Heat Flow
Some control systems involve regulation of temperature for portions of the
system. The dynamic models of temperature control systems involve the
ﬂow and storage of heat energy. Heat energy ﬂows through substances at a
rate proportional to the temperature difference across the substance; that is,
q = 1
R(T1 −T2),
(2.81)
where
q = heat-energy ﬂow, joules per second (J/sec)
R = thermal resistance, ◦C/J · sec
T = temperature, ◦C.
The net heat-energy ﬂow into a substance affects the temperature of the
substance according to the relation
˙T = 1
C q,
(2.82)
where C is the thermal capacity. Typically, there are several paths for heat to
ﬂow into or out of a substance, and q in Eq. (2.82) is the sum of heat ﬂows
obeying Eq. (2.81).
EXAMPLE 2.15
Equations for Heat Flow
A room with all but two sides insulated (1/R = 0) is shown in Fig. 2.36.
Find the differential equations that determine the temperature in the room.
Solution. Application of Eqs. (2.81) and (2.82) yields
˙TI = 1
CI
 1
R1
+ 1
R2

(TO −TI),
where
CI = thermal capacity of air within the room,
TO = temperature outside,
TI = temperature inside,
R2 = thermal resistance of the room ceiling,
R1 = thermal resistance of the room wall.
Normally the material properties are given in tables as follows:
1. The speciﬁc heat at constant volume cv, which is converted to heat
Speciﬁc heat
capacity by
C = mcv,
(2.83)
where m is the mass of the substance;

2.4 Heat and Fluid-Flow Models
59
Figure 2.36
Dynamic model for room
temperature
q2
q1
R2
R1
Temperature
outside, TO
2. The thermal conductivity11 k, which is related to thermal resistance R by
Thermal conductivity
1
R = kA
l ,
where A is the cross-sectional area and l is the length of the heat-ﬂow
path.
In addition to ﬂow due to transfer, as expressed by Eq. (2.81), heat can
also ﬂow when a warmer mass ﬂows into a cooler mass, or vice versa. In
this case,
q = wcv(T1 −T2),
(2.84)
where w is the mass ﬂow rate of the ﬂuid at T1 ﬂowing into the reservoir
at T2. For a more complete discussion of dynamic models for temperature
control systems, see Cannon (1967) or textbooks on heat transfer.
EXAMPLE 2.16
Equations for Modeling a Heat Exchanger
A heat exchanger is shown in Fig. 2.37. Steam enters the chamber through
the controllable valve at the top, and cooler steam leaves at the bottom. There
is a constant ﬂow of water through the pipe that winds through the middle
of the chamber so that it picks up heat from the steam. Find the differential
equations that describe the dynamics of the measured water outﬂow temper-
ature as a function of the area As of the steam-inlet control valve when open.
The sensor that measures the water outﬂow temperature, being downstream
from the exit temperature in the pipe, lags the temperature by td sec.
Solution. The temperature of the water in the pipe will vary continuously
along the pipe as the heat ﬂows from the steam to the water. The temperature
of the steam will also reduce in the chamber as it passes over the maze of
pipes. An accurate thermal model of this process is therefore quite involved
because the actual heat transfer from the steam to the water will be propor-
tional to the local temperatures of each ﬂuid. For many control applications
it is not necessary to have great accuracy because the feedback will correct
for a considerable amount of error in the model. Therefore, it makes sense
to combine the spatially varying temperatures into single temperatures Ts
11In the case of insulation for houses, resistance is quoted as R-values; for example, R-11 refers
to a substance that has a resistance to heat-ﬂow equivalent to that given by 11 in. of solid wood.

60
Chapter 2 Dynamic Models
Figure 2.37
Heat exchanger
Steam @ Tsi
Water
ww @ Twi
ws = KsAs
Steam @ Ts
Tm
Water @ Tw
As
and Tw for the outﬂow steam and water temperatures, respectively. We then
assume that the heat transfer from steam to water is proportional to the dif-
ference in these temperatures, as given by Eq. (2.81). There is also a ﬂow of
heat into the chamber from the inlet steam that depends on the steam ﬂow
rate and its temperature according to Eq. (2.84),
qin = wscvs(Tsi −Ts),
where
ws = KsAs, mass ﬂow rate of the steam,
As = area of the steam inlet valve,
Ks = ﬂow coefﬁcient of the inlet valve,
cvs = speciﬁc heat of the steam,
Tsi = temperature of the inﬂow steam,
Ts = temperature of the outﬂow steam.
The net heat ﬂow into the chamber is the difference between the heat from
the hot incoming steam and the heat ﬂowing out to the water. This net
ﬂow determines the rate of temperature change of the steam according to
Eq. (2.82),
Cs ˙Ts = AsKscvs(Tsi −Ts) −1
R(Ts −Tw),
(2.85)
where
Cs = mscvs is the thermal capacity of the steam in the chamber
with mass ms,
R = the thermal resistance of the heat ﬂow averaged over the
entire exchanger.

2.4 Heat and Fluid-Flow Models
61
Likewise, the differential equation describing the water temperature is
Cw ˙Tw = wwccw(Twi −Tw) + 1
R(Ts −Tw),
(2.86)
where
ww = mass ﬂow rate of the water,
ccw = speciﬁc heat of the water,
Twi = temperature of the incoming water,
Tw = temperature of the outﬂowing water.
To complete the dynamics, the time delay between the measurement and the
exit ﬂow is described by the relation
Tm(t) = Tw(t −td),
where Tm is the measured downstream temperature of the water and td is
the time delay. There may also be a delay in the measurement of the steam
temperature Ts, which would be modeled in the same manner.
Equation (2.85) is nonlinear because the quantity Ts is multiplied by the
control input As. The equation can be linearized about Tso (a speciﬁc value
of Ts) so that Tsi −Ts is assumed constant for purposes of approximating
the nonlinear term, which we will deﬁne as Ts. In order to eliminate the
Twi term in Eq. (2.86), it is convenient to measure all temperatures in terms
of deviation in degrees from Twi. The resulting equations are then
Cs ˙Ts = −1
RTs + 1
RTw + KscvsTsAs,
Cw ˙Tw = −
 1
R + wwcvw

Tw + 1
RTs,
Tm = Tw(t −td).
Although the time delay is not a nonlinearity, we will see in Chapter 3
that operationally, Tm = e−tdsTw. Therefore, the transfer function of the heat
exchanger has the form
Tm(s)
As(s) =
Ke−tds
(τ1s + 1)(τ2s + 1).
(2.87)
2.4.2
Incompressible Fluid Flow
Fluid ﬂows are common in many control system components. One exam-
ple is the hydraulic actuator, which is used extensively in control systems
Hydraulic actuator
because it can supply a large force with low inertia and low weight. They are
often used to move the aerodynamic control surfaces of airplanes; to gim-
bal rocket nozzles; to move the linkages in earth-moving equipment, farm
tractor implements, snow-grooming machines; and to move robot arms.

62
Chapter 2 Dynamic Models
The physical relations governing ﬂuid ﬂow are continuity, force equi-
librium, and resistance. The continuity relation is simply a statement of the
The continuity relation
conservation of matter; that is,
˙m = win −wout,
(2.88)
where
m = ﬂuid mass within a prescribed portion of the system,
win = mass ﬂow rate into the prescribed portion of the system,
wout = mass ﬂow rate out of the prescribed portion of the system.
EXAMPLE 2.17
Equations for Describing Water Tank Height
Determine the differential equation describing the height of the water in the
tank in Fig. 2.38.
Solution. Application of Eq. (2.88) yields
˙h = 1
Aρ (win −wout) ,
(2.89)
where
A = area of the tank,
ρ = density of water,
h = m/Aρ = height of water,
m = mass of water in the tank.
Force equilibrium must apply exactly as described by Eq. (2.1) for
mechanical systems. Sometimes in ﬂuid-ﬂow systems some forces result
from ﬂuid pressure acting on a piston. In this case the force from the ﬂuid is
f = pA,
(2.90)
where
f = force,
p = pressure in the ﬂuid,
A = area on which the ﬂuid acts.
Figure 2.38
Water tank example
in
out
h
Pressure p1

2.4 Heat and Fluid-Flow Models
63
EXAMPLE 2.18
Modeling a Hydraulic Piston
Determine the differential equation describing the motion of the piston actu-
ator shown in Fig. 2.39, given that there is a force FD acting on it and a
pressure p in the chamber.
Solution.
Equations (2.1) and (2.90) apply directly, where the forces
include the ﬂuid pressure as well as the applied force. The result is
M¨x = Ap −FD,
where
A = area of the piston,
p = pressure in the chamber,
M = mass of the piston,
x = position of the piston.
In many cases of ﬂuid-ﬂow problems, the ﬂow is resisted either by a
constriction in the path or by friction. The general form of the effect of
resistance is given by
w = 1
R(p1 −p2)1/α,
(2.91)
where
w = mass ﬂow rate,
p1, p2 = pressures at ends of the path through which ﬂow is occurring,
R, α = constants whose values depend on the type of restriction.
Or, as is more commonly used in hydraulics,
Q = 1
ρR(p1 −p2)1/α,
(2.92)
where
Q = volume ﬂow rate, where Q = w/ρ,
ρ = ﬂuid density.
Figure 2.39
Hydraulic piston
actuator
x
Piston
Liquid at
pressure p
FD

64
Chapter 2 Dynamic Models
The constant α takes on values between 1 and 2. The most common
value is approximately 2 for high ﬂow rates (those having a Reynolds number
Re > 105) through pipes or through short constrictions or nozzles. For very
slow ﬂows through long pipes or porous plugs wherein the ﬂow remains
laminar (Re ≲1000), α = 1. Flow rates between these extremes can
yield intermediate values of α. The Reynolds number indicates the relative
importance of inertial forces and viscous forces in the ﬂow. It is proportional
to a material's velocity and density and to the size of the restriction, and it is
inversely proportional to the viscosity. When Re is small, the viscous forces
predominate and the ﬂow is laminar. When Re is large, the inertial forces
predominate and the ﬂow is turbulent.
Note that a value of α = 2 indicates that the ﬂow is proportional to the
square root of the pressure difference and therefore will produce a nonlinear
differential equation. For the initial stages of control systems analysis and
design, itistypicallyveryusefultolinearizetheseequationssothatthedesign
techniques described in this book can be applied. Linearization involves
selecting an operating point and expanding the nonlinear term to be a small
perturbation from that point.
EXAMPLE 2.19
Linearization of Water Tank Height and Outﬂow
Find the nonlinear differential equation describing the height of the water
in the tank in Fig. 2.38. Assume that there is a relatively short restriction at
the outlet and that α = 2. Also linearize your equation about the operating
point ho.
Solution. Applying Eq. (2.91) yields the ﬂow out of the tank as a function
of the height of the water in the tank:
wout = 1
R(p1 −pa)1/2.
(2.93)
Here,
p1 = ρgh + pa, the hydrostatic pressure,
pa = ambient pressure outside the restriction.
Substituting Eq. (2.93) into Eq. (2.89) yields the nonlinear differential
equation for the height:
˙h = 1
Aρ

win −1
R
√p1 −pa

.
(2.94)
Linearization involves selecting the operating point po = ρgho + pa and
substituting p1 = po + p into Eq. (2.93). Then we expand the nonlinear
term according to the relation
(1 + ε)β ∼= 1 + βε,
(2.95)
where ε ≪1. Equation (2.93) can thus be written as
wout =
√po −pa
R

1 +
p
po −pa
1/2
∼=
√po −pa
R

1 + 1
2
p
po −pa

.
(2.96)

2.4 Heat and Fluid-Flow Models
65
The linearizing approximation made in Eq. (2.96) is valid as long as p ≪
po −pa; that is, as long as the deviations of the system pressure from the
chosen operating point are relatively small.
Combining Eqs. (2.89) and (2.96) yields the following linearized
equation of motion for the water tank level:
˙h = 1
Aρ

win −
√po −pa
R

1 + 1
2
p
po −pa

.
Because p = ρgh, this equation reduces to
˙h = −
g
2AR√po −pa
h + win
Aρ −
√po −pa
ρAR
,
(2.97)
which is a linear differential equation for ˙h. The operating point is not an
equilibrium point because some control input is required to maintain it. In
other words, when the system is at the operating point (h = 0) with no
input (win = 0), it will move from that point because ˙h ̸= 0. So if no water
is ﬂowing into the tank, the tank will drain, thus moving it from the reference
point. To deﬁne an operating point that is also an equilibrium point, we need
to require that there be a nominal ﬂow rate,
wino
Aρ =
√po −pa
ρAR
,
and deﬁne the linearized input ﬂow to be a perturbation from that value.
Hydraulic actuators obey the same fundamental relationships we saw in
Hydraulic actuators
the water tank: continuity [Eq. (2.88)], force balance [Eq. (2.90)], and ﬂow
resistance [Eq. (2.91)]. Although the development here assumes the ﬂuid to
be perfectly incompressible, in fact, hydraulic ﬂuid has some compressibility
due primarily to entrained air. This feature causes hydraulic actuators to
have some resonance because the compressibility of the ﬂuid acts like a stiff
spring. This resonance limits their speed of response.
EXAMPLE 2.20
Modeling a Hydraulic Actuator
1. Find the nonlinear differential equations relating the movement θ of the
control surface to the input displacement x of the valve for the hydraulic
actuator shown in Fig. 2.40.
2. Find the linear approximation to the equations of motion when ˙y =
constant, with and without an applied load—that is, when F ̸= 0 and
when F = 0. Assume that θ motion is small.
Solution
1. Equations of motion: When the valve is at x = 0, both passages are
closed and no motion results. When x > 0, as shown in Fig. 2.40, the
oil ﬂows clockwise as shown and the piston is forced to the left. When
x < 0, the ﬂuid ﬂows counterclockwise. The oil supply at high pressure

66
Chapter 2 Dynamic Models
l
d
u
Fa
F
Aerodynamic
control surface
Low-pressure
oil
High-pressure
oil
p2
p1
x
y
pe
ps
pe
2
1
2
1
Valve
Figure 2.40
Hydraulic actuator with valve
ps enters the left side of the large piston chamber, forcing the piston to
the right. This causes the oil to ﬂow out of the valve chamber from the
rightmost channel instead of the left.
We assume that the ﬂow through the oriﬁce formed by the valve is
proportional to x; that is,
Q1 =
1
ρR1
(ps −p1)1/2x.
(2.98)
Similarly,
Q2 =
1
ρR2
(p2 −pe)1/2x.
(2.99)
The continuity relation yields
A˙y = Q1 = Q2,
(2.100)
where
A = piston area.
The force balance on the piston yields
A(p1 −p2) −F = m¨y,
(2.101)
where
m = mass of the piston and the attached rod,
F = force applied by the piston rod to the control surface attachment
point.
Furthermore, themomentbalanceofthecontrolsurfaceusingEq.(2.14)
yields
I ¨θ = Fl cos θ −Fad,
(2.102)

2.4 Heat and Fluid-Flow Models
67
where
I = moment of inertia of the control surface and attachment about
the hinge,
Fa = applied aerodynamic load.
To solve this set of ﬁve equations, we require the following
additional kinematic relationship between θ and y:
y = l sin θ.
(2.103)
The actuator is usually constructed so that the valve exposes the two
passages equally; therefore, R1 = R2, and we can infer from Eqs. (2.98)
to (2.100) that
ps −p1 = p2 −pe.
(2.104)
These relations complete the nonlinear differential equations of motion;
they are formidable and difﬁcult to solve.
2. Linearization and simpliﬁcation: For the case in which ˙y = a constant
(¨y = 0) and there is no applied load (F = 0), Eqs. (2.101) and (2.104)
indicate that
p1 = p2 = ps + pe
2
.
(2.105)
Therefore, using Eq. (2.100) and letting sin θ = θ (since θ is assumed
to be small), we get
˙θ =
√ps −pe
√
2AρRl
x.
(2.106)
This represents a single integration between the input x and the output
θ, where the proportionality constant is a function only of the supply
pressure and the ﬁxed parameters of the actuator. For the case ˙y =
constant but F ̸= 0, Eqs. (2.101) and (2.104) indicate that
p1 = ps + pe + F/A
2
and
˙θ =
√ps −pe −F/A
√
2AρRl
x.
(2.107)
This result is also a single integration between the input x and the output
θ, but the proportionality constant now depends on the applied load F.
As long as the commanded values of x produce θ motion that has
a sufﬁciently small value of ¨θ, the approximation given by Eq. (2.106)
or (2.107) is valid and no other linearized dynamic relationships are
necessary. However, as soon as the commanded values of x produce
accelerations in which the inertial forces (m¨y and the reaction to I ¨θ) are
a signiﬁcant fraction of ps −pe, the approximations are no longer valid.
We must then incorporate these forces into the equations, thus obtaining
a dynamic relationship between x and θ that is much more involved

68
Chapter 2 Dynamic Models
than the pure integration implied by Eq. (2.106) or (2.107). Typically,
for initial control system designs, hydraulic actuators are assumed to
obey the simple relationship of Eq. (2.106) or (2.107). When hydraulic
actuators are used in feedback control systems, resonances have been
encountered that are not explained by using the approximation that the
device is a simple integrator as in Eq. (2.106) or (2.107). The source of
the resonance is the neglected accelerations discussed above along with
the additional feature that the oil is slightly compressible due to small
quantities of entrained air. This phenomenon is called the "oil-mass
resonance."
2.5
Historical Perspective
Newton's second law of motion (Eq. 2.1) was ﬁrst published in his
PhilosophiæNaturalis Principia Mathematica in 1686 along with his two
other famous laws of motion. The ﬁrst: A body will continue with the same
uniform motion unless acted on by an external unbalanced force, and the
third: To every action there is an equal and opposite reaction. Isaac Newton
also published his law of gravitation in this same publication, which stated
that every mass particle attracts all other particles by a force proportional to
the inverse of the square of the distance between them and the product of
their two masses. His basis for developing these laws was the work of several
other early scientists, combined with his own development of the calculus
in order to reconcile all the observations. It is amazing that these laws still
stand today as the basis for almost all dynamic analysis with the exception
of Einstein's additions in the early 1900s for relativistic effects. It is also
amazing that Newton's development of calculus formed the foundation of
our mathematics that enable dynamic modeling. In addition to being bril-
liant, he was also very eccentric. As Brennan writes in Heisenberg Probably
Slept Here, "He was seen about campus in his disheveled clothes, his wig
askew, wearing run-down shoes and a soiled neckpiece. He seemed to care
about nothing but his work. He was so absorbed in his studies that he forgot
to eat." Another interesting aspect of Newton is that he initially developed
the calculus and the now famous laws of physics about 20 years prior to
publishing them! The incentive to publish them arose from a bet between
three men having lunch at a pub in 1684: Edmond Halley, Christopher Wren,
and Robert Hooke. They all had the opinion that Kepler's elliptical charac-
terization of planetary motion could be explained by the inverse square law,
but nobody had ever proved it, so they "placed a bet as to who could ﬁrst
prove the conjecture."12 Halley went to Newton for help due to his fame as
a mathematician, who responded he had already done it many years ago and
12Much of the background on Newton was taken from Heisenberg Probably Slept Here, by
Richard P. Brennan, 1997. The book discusses his work and the other early scientists that laid
the groundwork for Newton.

2.5 Historical Perspective
69
would forward the papers to him. He not only did that shortly afterward, but
followed it up with the Principia with all the details two years later.
The basis for Newton's work started with the astronomer Nicholas
Copernicus more than a hundred years before the Principia was published.
He was the ﬁrst to speculate that the planets revolved around the sun, rather
than everything in the skies revolving around the earth. But Copernicus'
heretical notion was largely ignored at the time, except by the church who
banned his publication. However, two scientists did take note of his work:
Galileo Galilei in Italy and Johannes Kepler in Austria. Kepler relied on a
large collection of astronomical data taken by a Danish astronomer, Tycho
Brahe, and concluded that the planetary orbits were ellipses rather than
the circles that Copernicus had postulated. Galileo was an expert telescope
builder and was able to clearly establish that the earth was not the center
of all motion, partly because he was able to see moons revolving around
other planets. He also did experiments with rolling balls down inclined
planes that strongly suggested that F = ma (alas, it's a myth that he did
his experiments by dropping objects out of the Leaning Tower of Pisa).
Galileo published his work in 1632, which raised the ire of the church
who then later banned him to house arrest until he died.13 It was not until
1985 that the church recognized the important contributions of Galileo!
These men laid the groundwork for Newton to put it all together with
his laws of motion and the inverse square gravitational law. With these
two physical principles, all the observations ﬁt together with a theoret-
ical framework that today forms the basis for the modeling of dynamic
systems.
The sequence of discoveries that ultimately led to the laws of dynamics
that we take for granted today were especially remarkable when we stop
to think that they were all carried out without a computer, a calculator, or
even a slide rule. On top of that, Newton had to invent calculus in order to
reconcile the data.
After publishing the Principia, Newton went on to be elected to Parlia-
ment and was given high honors, including being the ﬁrst man of science
to be knighted by the Queen. He also got into ﬁghts with other scientists
fairly regularly and used his powerful positions to get what he wanted. In
one instance, he wanted data from the Royal Observatory that was not forth-
coming fast enough. So he created a new board with authority over the
Observatory and had theAstronomer Royal expelled from the Royal Society.
Newton also had other less scientiﬁc interests. Many years after his death,
John Maynard Keynes found that Newton had been spending as much of his
time on metaphysical occult, alchemy, and biblical works as he had been on
physics.
More than a hundred years after Newton's Principia, Michael Faraday
performed a multitude of experiments and postulated the notion of electro-
magnetic lines of force in free space. He also discovered induction (Faraday's
13Galileo's life, accomplishments, and house arrest are very well described in Dava Sobel's
book, Galileo's Daughter.

70
Chapter 2 Dynamic Models
Law), which led to the electric motor and the laws of electrolysis. Faraday
was born into a poor family, had virtually no schooling, and became an
apprentice to a bookbinder at age 14. There he read many of the books being
bound and became fascinated by science articles. Enthralled by these, he
maneuvered to get a job as a bottle washer for a famous scientist, eventually
learned enough to be a competitor to him, and ultimately became a professor
at the Royal Institution in London. But lacking a formal education, he had no
mathematical skills, and lacked the ability to create a theoretical framework
for his discoveries. Faraday became a famous scientist in spite of his hum-
ble origins. After he had achieved fame for his discoveries and was made
a Fellow of the Royal Society, the prime minister asked him what good his
inventions could be.14 Faraday's answer was, "Why Prime Minister, some-
day you can tax it." But in those days, scientists were almost exclusively men
born into privilege; so Faraday had been treated like a second-class citizen
by some of the other scientists. As a result, he rejected knighthood as well
as burial at Westminster Abbey. Faraday's observations, along with those
by Coulomb and Ampere, led James Clerk Maxwell to integrate all their
knowledge on magnetism and electricity into Maxwell's equations. Against
the beliefs of most prominent scientists of the day (Faraday being an excep-
tion), Maxwell invented the concepts of ﬁelds and waves that explained
magnetic and electrostatic forces and was the key to creating the unifying
theory.Although Newton had discovered the spectrum of light, Maxwell was
also the ﬁrst to realize that light was one type of the same electromagnetic
waves, and its behavior was explained as well by Maxwell's equations. In
fact, the only constants in his equations are μ and ε. The constant speed of
light is c = 1/√με.
Maxwell was a Scottish mathematician and theoretical physicist. His
work has been called the second great uniﬁcation in physics, the ﬁrst being
that due to Newton. Maxwell was born into the privileged class and was
given the beneﬁts of an excellent education and he excelled at it. In fact,
he was an extremely gifted theoretical and experimental scientist as well
as a very generous and kind man with many friends and little vanity. In
addition to unifying the observations of electromagnetics into a theory that
still governs our engineering analyses today, he was the ﬁrst to present an
explanation of how light travels, the primary colors, the kinetic theory of
gases, the stability of Saturn's rings, and the stability of feedback control
systems! His discovery of the three primary colors (red, green, and blue)
forms the basis of our color television to this day. His theory showing the
speed of light is a constant was difﬁcult to reconcile with Newton's laws
and led Albert Einstein to create the special theory of relativity in the early
1900s. This led Einstein to say, "One scientiﬁc epoch ended and another
began with James Clerk Maxwell."15
14E = MC2, A Biography of the World's Most Famous Equation, by David Bodanis, Walker
and Co., New York, 2000.
15The Man Who Changed Everything: The Life of James Clerk Maxwell, Basil Mahon, Wiley,
Chichester, UK, 2003.

Review Questions
71
SUMMARY
Mathematical modeling of the system to be controlled is the ﬁrst step
in analyzing and designing the required system controls. In this chapter we
developed analytical models for representative systems. Important equations
for each category of system are summarized in Table 2.1. It is also possible
to obtain a mathematical model using experimental data exclusively. This
approach is discussed brieﬂy in Chapter 3 and more extensively in Chapter 12
of Franklin, Powell, and Workman (1998).
TABLE 2.1
Key Equations for Dynamic Models
Important Laws
Associated
Equation
System
or Relationships
Equations
Number(s)
Mechanical
Translational motion
F = ma
(2.1)
(Newton's law)
Rotational motion
M = Iα
(2.14)
Electrical
Operational ampliﬁer
(2.46), (2.47)
Electromechanical
Law of motors
F = Bli
(2.53)
Law of generators
e = Blv
(2.56)
Torque developed in a rotor
T = Ktia
(2.60)
Back emf
Voltage generated as a result
e = Ke ˙θm
(2.61)
of rotation of a rotor
Gears
Effective inertia
Jeq = J2 + J1n2
(2.80)
Heat ﬂow
Heat-energy ﬂow
q = 1/R(T1 −T2)
(2.81)
Temperature as a function of
˙T = 1
C q
(2.82)
heat-energy ﬂow
Speciﬁc heat
C = mcv
(2.83)
Fluid ﬂow
Continuity relation
˙m = win −wout
(2.88)
(conservation of matter)
Force of a ﬂuid acting
f = pA
(2.90)
on a piston
Effect of resistance to ﬂuid
w = 1/R(p1 −p2)1/α
(2.91)
ﬂow
REVIEW QUESTIONS
2.1
What is a "free-body diagram"?
2.2
What are the two forms of Newton's law?
2.3
For a structural process to be controlled, such as a robot arm, what is the
meaning of "collocated control"? "Noncollocated control"?
2.4
State Kirchhoff's current law.
2.5
State Kirchhoff's voltage law.
2.6
When, why, and by whom was the device named an "operational ampliﬁer"?
2.7
What is the major beneﬁt of having zero input current to an operational
ampliﬁer?

72
Chapter 2 Dynamic Models
2.8
Why is it important to have a small value for the armature resistance Ra of an
electric motor?
2.9
What are the deﬁnition and units of the electric constant of a motor?
2.10
What are the deﬁnition and units of the torque constant of an electric motor?
2.11
Why do we approximate a physical model of the plant (which is always
nonlinear) with a linear model?
2.12
Give the relationships for the following:
△
(a)
Heat ﬂow across a substance
(b)
Heat storage in a substance
2.13
Name and give the equations for the three relationships governing ﬂuid ﬂow.
△
PROBLEMS
Problems for Section 2.1: Dynamics of Mechanical Systems
2.1
Write the differential equations for the mechanical systems shown in Fig. 2.41.
For Fig. 2.41(a) and (b), state whether you think the system will eventually
decay so that it has no motion at all, given that there are nonzero initial
conditions for both masses and there is no input; give a reason for your answer.
2.2
Write the differential equation for the mechanical system shown in Fig. 2.42.
State whether you think the system will eventually decay so that it has no
Figure 2.41
Mechanical systems
x1
m1
x2
k2
b1
k1
y
(a)
m2
k3
No friction
No friction
m1
(b)
m2
k3
No friction
Friction, b1
k2
k1
b1
F
m1
(c)
m2
No friction
Friction, b1
k2
k1

Problems
73
Figure 2.42
Mechanical system for
Problem 2.2
m1
K1
x1
b2
x2
K1
K2
No friction
m1
No friction
motion at all, given that there are nonzero initial conditions for both masses,
and give a reason for your answer.
2.3
Write the equations of motion for the double-pendulum system shown in
Fig. 2.43. Assume that the displacement angles of the pendulums are small
enough to ensure that the spring is always horizontal. The pendulum rods are
taken to be massless, of length l, and the springs are attached three-fourths of
the way down.
Figure 2.43
Double pendulum
m
k
m
2.4
Write the equations of motion of a pendulum consisting of a thin, 2 kg stick
of length l suspended from a pivot. How long should the rod be in order for
the period to be exactly 1 sec? (The inertia I of a thin stick about an end point
is 1
3ml2. Assume that θ is small enough that sin θ ∼= θ.) Why do you think
grandfather clocks are typically about 6 ft high?
2.5
For the car suspension discussed in Example 2.2, plot the position of the car
and the wheel after the car hits a "unit bump"(that is, r is a unit step) using
Matlab. Assume that m1 = 10 kg, m2 = 250 kg, Kw = 500,000 N/m, and
Ks = 10,000 N/m. Find the value of b that you would prefer if you were a
passenger in the car.
2.6
Write the equations of motion for a body of mass M suspended from a
ﬁxed point by a spring with a constant k. Carefully deﬁne where the body's
displacement is zero.
2.7
Automobile manufacturers are contemplating building active suspension sys-
tems. The simplest change is to make shock absorbers with a changeable
damping, b(u1). It is also possible to make a device to be placed in parallel
with the springs that has the ability to supply an equal force, u2, in opposite
directions on the wheel axle and the car body.
(a) Modify the equations of motion in Example 2.2 to include such control
inputs.
(b) Is the resulting system linear?

74
Chapter 2 Dynamic Models
(c) Is it possible to use the force u2 to completely replace the springs and
shock absorber? Is this a good idea?
2.8
In many mechanical positioning systems there is ﬂexibility between one part
of the system and another. An example is shown in Fig. 2.7 where there is
ﬂexibility of the solar panels. Figure 2.44 depicts such a situation, where a
force u is applied to the mass M and another mass m is connected to it. The
coupling between the objects is often modeled by a spring constant k with
a damping coefﬁcient b, although the actual situation is usually much more
complicated than this.
(a) Write the equations of motion governing this system.
(b) Find the transfer function between the control input u and the output y.
Figure 2.44
Schematic of a system
with ﬂexibility
b
k
u
M
m
y
x
2.9
Modify the equation of motion for the cruise control in Example 2.1, Eq. (2.4),
so that it has a control law; that is, let
u = K(vr −v),
(2.108)
where
vr = reference speed,
(2.109)
K = constant.
(2.110)
This is a "proportional"control law in which the difference between vr and
the actual speed is used as a signal to speed the engine up or slow it down.
Revise the equations of motion with vr as the input and v as the output and
ﬁnd the transfer function. Assume that m = 1500 kg and b = 70 N·sec/m,
and ﬁnd the response for a unit step in vr using Matlab. Using trial and error,
ﬁnd a value of K that you think would result in a control system in which the
actual speed converges as quickly as possible to the reference speed with no
objectionable behavior.
2.10
Determine the dynamic equations for lateral motion of the robot in Fig. 2.45.
Assume it has three wheels with a single, steerable wheel in the front where
the controller has direct control of the rate of change of the steering angle,
Usteer, with geometry as shown in Fig. 2.46. Assume the robot is going in
approximately a straight line and its angular deviation from that straight line
is very small. Also assume that the robot is traveling at a constant speed, Vo.
The dynamic equations relating the lateral velocity of the center of the robot
as a result of commands in Usteer are desired.

Problems
75
Figure 2.45
Robot for delivery of
hospital supplies
Source: AP Images
Figure 2.46
Model for robot motion
L
2
L
us
Problems for Section 2.2: Models of Electric Circuits
2.11
A ﬁrst step toward a realistic model of an op-amp is given by the following
equations and is shown in Fig. 2.47:
Vout = 107
s + 1[v+ −v−],
i+ = i−= 0.
Figure 2.47
Circuit for Problem 2.11
Rin
y-
y+
Vin
Vout
Rf
-
+

76
Chapter 2 Dynamic Models
Find the transfer function of the simple ampliﬁcation circuit shown using this
model.
2.12
Show that the op-amp connection shown in Fig. 2.48 results in Vout = Vin if
the op-amp is ideal. Give the transfer function if the op-amp has the nonideal
transfer function of Problem 2.11.
Figure 2.48
Circuit for Problem 2.12
y-
y+
Vin
Vout
- 
+
2.13
A common connection for a motor power ampliﬁer is shown in Fig. 2.49. The
idea is to have the motor current follow the input voltage, and the connection
is called a current ampliﬁer. Assume that the sense resistor rs is very small
compared with the feedback resistor R, and ﬁnd the transfer function from
Vin to Ia. Also show the transfer function when Rf = ∞.
Figure 2.49
Op-amp circuit for
Problem 2.13
Rin
Rs
R
Vin
Vout
DC motor
Rf
-
+
-
+
Ia
y-
y+
2.14
An op-amp connection with feedback to both the negative and the positive
terminalsisshowninFig.2.50. Iftheop-amphasthenonidealtransferfunction
given in Problem 2.11, give the maximum value possible for the positive
feedbackratio, P =
r
r+R, intermsofthenegativefeedbackratio, N =
Rin
Rin+Rf ,
for the circuit to remain stable.
2.15
Write the dynamic equations and ﬁnd the transfer functions for the circuits
shown in Fig. 2.51.
(a) Passive lead circuit
(b) Active lead circuit
(c) Active lag circuit
(d) Passive notch circuit
2.16
The very ﬂexible circuit shown in Fig. 2.52 is called a biquad because its
transfer function can be made to be the ratio of two second-order or quadratic

Problems
77
Figure 2.50
Op-amp circuit for
Problem 2.14
Rin
Vin
Vout
Rf
R
r
y-
y+
-
+
Figure 2.51
(a) Passive lead;
(b) active lead;
(c) active lag; and
(d) passive notch
circuits
(b)
(a)
Vout
(c)
R1
R2
Vin
C
Rf
Vout
Rin
Vin
R2
R1
C
R
(d)
R/2
2C
R
C
C
Vout
Vin
R2
R1
C
u
y

78
Chapter 2 Dynamic Models
R1
Rc
Rb
Ra
R2
R
R
R
C
C
Vout
-
-
-
R
Vin
V1
V2
V3
R
Rd
Figure 2.52
Op-amp biquad
polynomials. By selecting different values for Ra, Rb, Rc, and Rd, the circuit
can realize a low-pass, band-pass, high-pass, or band-reject (notch) ﬁlter.
(a) Show that if Ra = R and Rb = Rc = Rd = ∞, the transfer function from
Vin to Vout can be written as the low-pass ﬁlter
Vout
Vin
=
A
s2
ω2n + 2ζ s
ωn + 1
,
(2.111)
where
A = R
R1
,
ωn =
1
RC ,
ζ =
R
2R2
.
(b) Using the Matlab command step, compute and plot on the same graph
the step responses for the biquad of Fig. 2.52 for A = 2, ωn = 2, and
ζ = 0.1, 0.5, and 1.0.
2.17
Find the equations and transfer function for the biquad circuit of Fig. 2.52 if
Ra = R, Rd = R1, and Rb = Rc = ∞.
Problems for Section 2.3: Models of Electromechanical Systems
2.18
The torque constant of a motor is the ratio of torque to current and is often
given in ounce-inches per ampere. (Ounce-inches have dimension force ×
distance, where an ounce is 1/16 of a pound.) The electric constant of a motor
is the ratio of back emf to speed and is often given in volts per 1000 rpm. In
consistent units, the two constants are the same for a given motor.

Problems
79
(a) Show that the units ounce-inches per ampere are proportional to volts per
1000 rpm by reducing both to MKS (SI) units.
(b) A certain motor has a back emf of 25 V at 1000 rpm. What is its torque
constant in ounce-inches per ampere?
(c) What is the torque constant of the motor of part (b) in newton-meters per
ampere?
2.19
The electromechanical system shown in Fig. 2.53 represents a simpliﬁed
model of a capacitor microphone. The system consists in part of a parallel
plate capacitor connected into an electric circuit. Capacitor plate a is rigidly
fastened to the microphone frame. Sound waves pass through the mouthpiece
and exert a force fs(t) on plate b, which has mass M and is connected to the
frame by a set of springs and dampers. The capacitance C is a function of the
distance x between the plates, as follows:
C(x) = εA
x ,
where
ε = dielectric constant of the material between the plates,
A = surface area of the plates.
The charge q and the voltage e across the plates are related by
q = C(x)e.
The electric ﬁeld in turn produces the following force fe on the movable plate
that opposes its motion:
fe = q2
2εA.
(a) Write differential equations that describe the operation of this system. (It
is acceptable to leave in nonlinear form.)
(b) Can one get a linear model?
(c) What is the output of the system?
Figure 2.53
Simpliﬁed model for
capacitor microphone
 - 
 + 
x
K
B
L
R
i(t)
fs(t)
M
a
e
y
b
A
2.20
A very typical problem of electromechanical position control is an electric
motor driving a load that has one dominant vibration mode. The problem
arises in computer-disk-head control, reel-to-reel tape drives, and many other

80
Chapter 2 Dynamic Models
applications. A schematic diagram is sketched in Fig. 2.54. The motor has an
electrical constant Ke, a torque constant Kt, an armature inductance La, and a
resistance Ra. The rotor has an inertia J1 and a viscous friction B. The load has
an inertia J2. The two inertias are connected by a shaft with a spring constant
k and an equivalent viscous damping b. Write the equations of motion.
Figure 2.54
Motor with a ﬂexible
load
La
Ra
ya
+ 
- 
J1
J2
u2
u1
k, b
2.21
For the robot in Fig. 2.45, assume you have command of the torque on a servo
△
motor that is connected to the drive wheels with gears that have a 2:1 ratio so
that the torque on the wheels is increased by a factor of 2 over that delivered
by the servo. Determine the dynamic equations relating the speed of the robot
with respect to the torque command of the servo. Your equations will require
certain quantities, for example, mass of vehicle, inertia, and radius of the
wheels. Assume you have access to whatever you need.
2.22
Using Fig. 2.35, derive the transfer function between the applied torque,
△
Tm, and the output, θ2, for the case when there is a spring attached to the
output load. That is, there is a torque applied to the output load, Ts, where
Ts = −Ksθ2.
Problems for Section 2.4: Heat and Fluid-Flow Models
△
2.23
A precision table-leveling scheme shown in Fig. 2.55 relies on thermal expan-
sion of actuators under two corners to level the table by raising or lowering
their respective corners. The parameters are as follows:
Tact = actuator temperature,
Tamb = ambient air temperature,
Figure 2.55
(a) Precision table kept
level by actuators;
(b) side view of one
actuator
yi
Tact
(b)
d
yi
(a)

Problems
81
Rf = heat-ﬂow coefﬁcient between the actuator and the air,
C = thermal capacity of the actuator,
R = resistance of the heater.
Assume that (1) the actuator acts as a pure electric resistance, (2) the heat ﬂow
into the actuator is proportional to the electric power input, and (3) the motion
d is proportional to the difference between Tact and Tamb due to thermal
expansion. Find the differential equations relating the height of the actuator
d versus the applied voltage vi.
2.24
An air conditioner supplies cold air at the same temperature to each room on
the fourth ﬂoor of the high-rise building shown in Fig. 2.56(a). The ﬂoor plan
is shown in Fig. 2.56(b). The cold airﬂow produces an equal amount of heat
ﬂow q out of each room. Write a set of differential equations governing the
temperature in each room, where
To = temperature outside the building,
Ro = resistance to heat ﬂow through the outer walls,
Ri = resistance to heat ﬂow through the inner walls.
Assume that (1) all rooms are perfect squares, (2) there is no heat ﬂow through
the ﬂoors or ceilings, and (3) the temperature in each room is uniform through-
out the room. Take advantage of symmetry to reduce the number of differential
equations to three.
Figure 2.56
Building
air-conditioning:
(a) high-rise building;
(b) ﬂoor plan of the
fourth ﬂoor
Fourth
floor
Ro
Ri
(a)
(b)
2.25
For the two-tank ﬂuid-ﬂow system shown in Fig. 2.57, ﬁnd the differential
equations relating the ﬂow into the ﬁrst tank to the ﬂow out of the second tank.
2.26
A laboratory experiment in the ﬂow of water through two tanks is sketched
in Fig. 2.58. Assume that Eq. (2.93) describes ﬂow through the equal-sized
holes at points A, B, or C.

82
Chapter 2 Dynamic Models
Figure 2.57
Two-tank ﬂuid-ﬂow
system for Problem 2.25
wout
win
Figure 2.58
Two-tank ﬂuid-ﬂow
system for Problem 2.26
Pump
A
B
C
h1
h3
h2
(a) With holes at B and C, but none at A, write the equations of motion for
this system in terms of h1 and h2. Assume that when h2 = 10 cm, the
outﬂow is 200 g/min.
(b) At h1 = 30 cm and h2 = 10 cm, compute a linearized model and the
transfer function from pump ﬂow (in cubic-centimeters per minute) to h2.
(c) Repeat parts (a) and (b) assuming hole B is closed and hole A is open.
Assume that h3 = 20 cm, h1 > 20 cm, and h2 < 20 cm.
2.27
The equations for heating a house are given by Eqs. (2.81) and (2.82), and in
a particular case can be written with time in hours as
C dTh
dt
= Ku −Th −To
R
,
where
(a) C is the thermal capacity of the house, BTU/◦F,
(b) Th is the temperature in the house, ◦F,
(c) To is the temperature outside the house, ◦F,

Problems
83
(d) K is the heat rating of the furnace, = 90, 000 BTU/h,
(e) R is the thermal resistance, ◦F per BTU/h,
(f) u is the furnace switch, = 1 if the furnace is on and = 0 if the furnace
is off.
It is measured that, with the outside temperature at 32◦F and the house at 60◦F,
the furnace raises the temperature 2◦F in six min (0.1 h). With the furnace
off, the house temperature falls 2◦F in 40 min. What are the values of C and
R for the house?

3
Dynamic Response
0
2
4
6
8
10
12
vnt
2.0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
y(t)
z  =  0
0.1
0.2
0.3
0.4
0.5
0.6
z  =  0.7
0.8
0.9
1.0
A Perspective on System Response
We discussed in Chapter 2 how to obtain the dynamic model of a
system. In designing a control system, it is important to see how well
a trial design matches the desired performance. We do this by solving
the equations of the system model.
There are two ways to approach solving the dynamic equations.
For a quick, approximate analysis we use linear analysis techniques.
The resulting approximations of system response provide insight into
why the solution has certain features and how the system might be
changed to modify the response in a desired direction. In contrast,
a precise picture of the system response typically calls for numerical
simulation of nonlinear equations of motion using computer aids. This
chapter focuses on linear analysis and computer tools that can be used
to solve for the time response of linear systems.
There are three domains within which to study dynamic response:
the Laplace transform (s-plane), the frequency response, and the
84

3.1 Review of Laplace Transforms
85
state space (analysis using the state-variable description). The well-
preparedcontrolengineerneedstobeﬂuentinallofthem, sotheywill
betreatedindepthinChapters5, 6, and7, respectively. Thepurposeof
this chapter is to discuss some of the fundamental mathematical tools
needed before studying analysis in the s-plane, frequency response,
and state space.
Chapter Overview
The Laplace transform, reviewed in Section 3.1 (and Appendix A), is
the mathematical tool for transforming differential equations into an
easier-to-manipulate algebraic form. In addition to the mathemati-
cal tools at our disposal, there are graphical tools that can help us to
visualize the model of a system and evaluate the pertinent mathemat-
ical relationships between elements of the system. One approach is
the block diagram, which was introduced in Chapter 1. Block-diagram
manipulation is discussed in Section 3.2 and allows the manipulation
of transfer functions.
Once the transfer function has been determined, we can identify
its poles and zeros, which tell us a great deal about the system charac-
teristics, including its frequency response introduced in Section 3.1.
Sections 3.3 to 3.5 focus on poles and zeros and some of the ways
for manipulating them to steer system characteristics in a desired
way. When feedback is introduced, the possibility that the system may
become unstable is introduced. To study this effect, in Section 3.6
we consider the deﬁnition of stability and Routh's test, which can
determine stability by examining the coefﬁcients of the system's
characteristic equation. Finally, Section 3.7 provides a historical per-
spective for the material in this chapter. An alternative representation
of a system in graphical form is the signal-ﬂow graph and ﬂow graphs
that allow the determination of complicated transfer functions, which
are discussed in Appendix W3.2.3 on the web at www.fpe7e.com.
3.1
Review of Laplace Transforms
Two attributes of linear time-invariant systems (LTIs) form the basis for
almost all analytical techniques applied to these systems:
1. A linear system response obeys the principle of superposition.
2. The response of an LTI system can be expressed as the convolution of
the input with the unit impulse response of the system.
The concepts of superposition, convolution, and impulse response will
be deﬁned shortly.
From the second property (as we will show), it follows immediately that
the response of an LTI system to an exponential input is also exponential.
This result is the principal reason for the usefulness of Fourier and Laplace
transforms in the study of LTI systems.

86
Chapter 3 Dynamic Response
3.1.1
Response by Convolution
The principle of superposition states that if the system has an input that
Superposition principle
can be expressed as a sum of signals, then the response of the system can be
expressed as the sum of the individual responses to the respective signals.
We can express superposition mathematically. Consider the system to have
input u and output y. Suppose further that, with the system at rest, we apply
the input u1(t) and observe the output y1(t).After restoring the system to rest,
we apply a second input u2(t) and again observe the output, which we call
y2(t). Then, we form the composite input u(t) = α1u1(t)+α2u2(t). Finally,
if superposition applies, then the response will be y(t) = α1y1(t) + α2y2(t).
Superposition will apply if and only if the system is linear.
EXAMPLE 3.1
Superposition
Show that superposition holds for the system modeled by the ﬁrst-order
linear differential equation
˙y + ky = u.
Solution. We let u = α1u1 + α2u2 and assume that y = α1y1 + α2y2. Then
˙y = α1˙y1+α2˙y2. If we substitute these expressions into the system equation,
we get
α1˙y1 + α2˙y2 + k(α1y1 + α2y2) = α1u1 + α2u2.
From this it follows that
α1(˙y1 + ky1 −u1) + α2(˙y2 + ky2 −u2) = 0.
(3.1)
If y1 is the solution with input u1 and y2 is the solution with input u2, then
Eq. (3.1) is satisﬁed, the response is the sum of the individual responses, and
superposition holds.
Notice that the superposition result of Eq. (3.1) would also hold if k were
a function of time. If k were constant, we call the system time invariant. In
that case, it follows that if the input is delayed or shifted in time, then the
output is unchanged except also being shifted by exactly the same amount.
Mathematically, this is expressed by saying that, if y1(t) is the output caused
by u1(t) then y1(t −τ) will be the response to u1(t −τ).
EXAMPLE 3.2
Time Invariance
Consider
˙y1(t) + k(t)y1(t) = u1(t),
(3.2)
and
˙y2(t) + k(t)y2(t) = u1(t −τ),
where τ is a constant shift. Assume that y2(t) = y1(t −τ); then
dy1(t −τ)
dt
+ k(t)y1(t −τ) = u1(t −τ).

3.1 Review of Laplace Transforms
87
Let us make the change of variable t −τ = η, then
dy1(η)
dη
+ k(η + τ)y1(η) = u1(η).
(3.3)
Eq. (3.3) can satisfy Eq. (3.2) only if τ = 0, or if k(η + τ) = k = constant,
in which case
dy1(η)
dη
+ ky1(η) = u(η),
which is Eq. (3.1). Therefore, we conclude that if the system is time invariant,
y(t −τ) will be the response to u(t −τ); that is, if the input is delayed by
τ sec, then the output is also delayed by τ sec.
We are able to solve for the response of a linear system to a general
signal simply by decomposing the given signal into a sum of the elementary
components and, by superposition, concluding that the response to the gen-
eral signal is the sum of the responses to the elementary signals. In order for
this process to work, the elementary signals need to be sufﬁciently "rich" that
any reasonable signal can be expressed as a sum of them, and their responses
have to be easy to ﬁnd. The most common candidates for elementary signals
for use in linear systems are the impulse and the exponential.
Suppose the input signal to an LTI system is a short pulse as u1(t) = p(t),
and the corresponding output signal is y1(t) = h(t) as shown in Fig. 3.1(a).
Now if the input is scaled to u1(t) = u(0)p(t), then by the scaling property
of superposition, the output response will be y1(t) = u(0)h(t). We showed
that an LTI system obeys time invariance. If we delay the short pulse signal
in time by τ, then the input is of the form u2(t) = p(t −τ) and the output
response will also be delayed by the same amount y2(t) = h(t −τ) as shown
in Fig. 3.1(b). Now, by superposition, the response to the two short pulses
will be the sum of their individual outputs as shown in Fig. 3.1(c). If we
have four pulses as the input, then the output will be the sum of the four
individual responses as shown in Fig. 3.1(d). Any arbitrary input signal u(t)
may be approximated by a series of pulses as shown in Fig. 3.2. We deﬁne
Short pulse
a short pulse p(t) as a rectangular pulse having unit area such that
p(t) =

1
,
0 ≤t ≤
0,
elsewhere
(3.4)
as shown in Fig. 3.1(a). Suppose the response of the system to p(t) is
deﬁned as h(t). The response at time n to u(k)p(k) is
u(k)h(n −k).
By superposition, the total response to the series of the short pulses at time
t is given by
y(t) =
k=∞

k=0
u(k)h(t −k).
(3.5)

88
Chapter 3 Dynamic Response
Figure 3.1
Illustration of
convolution as the
response of a system to
a series of short pulse
(impulse) input signals
p (t)
h (t)
p (t)
p (t)
p (t-t)
h (t-t)
t (sec)
t (sec)
t (sec)
t (sec)
t (sec)
t
t
¢
t
Input signal
System output
0
t (sec)
0
0
0
0
0
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1 2 3 4 5
Time (sec)
y (t)
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
y (t)
6 7 8 9 10
0 1 2 3 4 5
Time (sec)
6 7 8 9 10
1
¢
1
¢
1
¢
1
¢
1
¢
t+¢
t+¢
t
2t
3t
2t+¢
3t+¢
¢
0
t+¢
(a)
(b)
(c)
(d)
1
Figure 3.2
Illustration of the
representation of a
general input signal as
the sum of short pulses
¢
0
2¢3¢
5¢
10¢
t (sec)
u (t)

3.1 Review of Laplace Transforms
89
If we take the limit as  →0, the basic pulse gets more and more narrow
and taller and taller while holding a constant area. We then have the concept
of an impulse signal, δ(t), and that will allow us to treat continuous signals.
In that case we have,
lim
→0
p(t) = δ(t),
(3.6)
lim
→0h(t) = h(t) = the impulse response.
(3.7)
Moreover, in the limit as  →0, the summation in Eq. (3.5) is replaced by
the integral
y(t) =
 ∞
0
u(τ)h(t −τ) dτ,
(3.8)
which is the convolution integral.
The idea for the impulse comes from dynamics. Suppose we wish to
studythemotionofabaseballhitbyabat. Thedetailsofthecollisionbetween
the bat and ball can be very complex as the ball deforms and the bat bends;
however, for purposes of computing the path of the ball, we can summarize
the effect of the collision as the net velocity change of the ball over a very
short time period. We assume that the ball is subjected to an impulse, a very
Impulse response
intense force for a very short time. The physicist Paul Dirac suggested that
such forces could be represented by the mathematical concept of an impulse
δ(t), which has the property that
Deﬁnition of impulse
δ(t) = 0
t ̸= 0,
(3.9)
 ∞
−∞
δ(t)dt = 1.
(3.10)
If f (t) is continuous at t = τ, then it has the "sifting property."
Sifting property of impulse
 ∞
−∞
f (τ)δ(t −τ) dτ = f (t).
(3.11)
In other words, the impulse is so short and so intense that no value of f
matters except over the short range where the δ occurs. Since integration is
a limit of a summation process, Eq. (3.11) can be viewed as representing
the function f as a sum of impulses. If we replace f by u, then Eq. (3.11)
represents an input u(t) as a sum of impulses of intensity u(t −τ). To ﬁnd
the response to an arbitrary input, the principle of superposition tells us that
we need only ﬁnd the response to a unit impulse.
If the system is not only linear but also time invariant (LTI), then the
impulse response is given by h(t −τ) because the response at t to an input
applied at τ depends only on the difference between the time the impulse
is applied and the time we are observing the response, that is, the elapsed
time. Time-invariant systems are called shift invariant for this reason. For
time-invariant systems, the output for a general input is given by the integral
y(t) =
 ∞
−∞
u(τ)h(t −τ) dτ,
(3.12)

90
Chapter 3 Dynamic Response
or by changing of variables as τ1 = t −τ
y(t) =
 −∞
∞
u(t −τ1)h(τ1) (−dτ1) =
 ∞
−∞
h(τ)u(t −τ) dτ.
(3.13)
This is the convolution integral.
The convolution integral
EXAMPLE 3.3
Convolution
We can illustrate convolution with a simple system. Determine the impulse
response for the system described by the differential equation
˙y + ky = u = δ(t),
with an initial condition of y(0) = 0 before the impulse.
Solution. Because δ(t) has an effect only near t = 0, we can integrate this
equation from just before zero to just after zero with the result that
 0+
0−˙y dt + k
 0+
0−y dt =
 0+
0−δ(t) dt.
The integral of ˙y is simply y, the integral of y over so small a range is zero,
and the integral of the impulse over the same range is unity. Therefore,
y(0+) −y(0−) = 1.
Because the system was at rest before application of the impulse, y(0−) = 0.
Thus the effect of the impulse is that y(0+) = 1. For positive time we have
the differential equation
˙y + ky = 0,
y(0+) = 1.
If we assume a solution y = Aest, then ˙y = Asest. The preceding equation
then becomes
Asest + kAest = 0,
s + k = 0,
s = −k.
Because y(0+) = 1, it is necessary that A = 1. Thus the solution for the
impulse response is y(t) = h(t) = e−kt for t > 0. To take care of the fact
that h(t) = 0 for negative time, we deﬁne the unit-step function
Unit step
1(t) =
0,
t < 0,
1,
t ≥0.
With this deﬁnition, the impulse response of the ﬁrst-order system becomes
h(t) = e−kt1(t).
The response of this system to a general input is given by the convolution of
this impulse response with the input

3.1 Review of Laplace Transforms
91
y(t) =
 ∞
−∞
h(τ)u(t −τ) dτ
=
 ∞
−∞
e−kτ1(τ)u(t −τ) dτ
=
 ∞
0
e−kτu(t −τ) dτ.
For time-invariant systems, the output for a general input is given by
the integral
y(t) =
∞

−∞
u(τ)h(t −τ)dτ.
(3.14)
Notice that the limits on the integral are at inﬁnity. Thus, either or both h
and u may be nonzero for negative time. If h has values for negative time, it
means that the system response starts before the input is applied! Systems
which do this are called non-causal because they do not obey the usual law
Non-causal system
of cause and effect.1 Of course all physical systems are causal. Furthermore,
in most cases of interest we take t = 0 as the time when the input starts. In
this case, with causal systems, the integral may be written as
y(t) =
t

0
u(τ)h(t −τ)dτ.
(3.15)
3.1.2
Transfer Functions and Frequency Response
A simple version of the transfer function concept was developed in Chapter 2.
A more rigorous treatment of this concept using the convolution integral
follows. The evaluation of the convolution integral Eq. (3.14) can be difﬁcult
and an indirect approach has been developed using the Laplace transform2
deﬁned as
Y(s) =
∞

−∞
y(t)e−stdt.
Applying this transform to the convolution,
Y(s) =
∞

−∞
⎡
⎣
∞

−∞
h(τ)u(t −τ)dτ
⎤
⎦e−stdt.
1A system is said to be causal if the output is not dependent on future inputs, that is, "the system
does not laugh before it is tickled."
2Many properties of the Laplace transform are given in Appendix A.

92
Chapter 3 Dynamic Response
Next we exchange the order of integration such that we integrate with respect
to t ﬁrst
Y(s) =
∞

−∞
⎡
⎣
∞

−∞
u(t −τ)e−stdt
⎤
⎦h(τ)dτ.
Changing variables of the inner integral by deﬁning t −τ = η, we get
Y(s) =
∞

−∞
⎡
⎣
∞

−∞
u(η)e−s(η+τ)dt
⎤
⎦h(τ)dτ,
(3.16)
Y(s) =
⎡
⎣
∞

−∞
u(η)e−sηdη
⎤
⎦
∞

−∞
h(τ)e−sτdτ,
Y(s) = U(s)H(s).
In this solution, U(s) is the Laplace transform of the input time function
and H(s), the Laplace transform of the impulse response, is deﬁned as the
transfer function. By this operation, the complicated convolution integral
Transfer function
is replaced by a simple multiplication of the transforms. What remains is
to interpret the transforms and the transfer function. In the ﬁrst instance,
the integrals of the transforms usually do not converge for all values of the
variable s and they are only deﬁned for a ﬁnite region in the s-plane.
Animmediateconsequenceofconvolutionisthataninputoftheformest
results in an output H(s)est. Note that both input and output are exponential
timefunctions, andthattheoutputdiffersfromtheinputonlyintheamplitude
H(s). H(s) is deﬁned as the transfer function of the system. The speciﬁc
constant s may be complex, expressed as s = σ1 + jω. Thus, both the input
and the output may be complex. If we let u(t) = est in Eq. (3.13), then
y(t) =
 ∞
−∞
h(τ)u(t −τ) dτ,
y(t) =
 ∞
−∞
h(τ)es(t−τ) dτ,
y(t) =
 ∞
−∞
h(τ)este−sτ dτ,
y(t) =
 ∞
−∞
h(τ)e−sτ dτest,
y(t) = H(s)est,
(3.17)

3.1 Review of Laplace Transforms
93
where
H(s) =
 ∞
−∞
h(τ)e−sτ dτ.3
(3.18)
Laplace deﬁned this integral and it is called the Laplace transform. Notice
that the limits on the integral are −∞to +∞, implying that h(t) may have
values at any time. Equation (3.18) needs to be interpreted carefully.4 Notice
that this input is exponential for all time (−∞< t < ∞) and Eq. (3.18)
represents the response for all time and hence there are no initial conditions
and Eq. (3.17) gives the steady-state behavior of the system. Therefore, if
the input is an exponential for all time and if we know the transfer function
H(s), the output is readily computed by multiplication and the need for
convolution goes away! The important conclusion is that if the input is an
exponential time function so is the output and the scaling term is the transfer
function. For any real, causal system, h(t) = 0 for t < 0 and the limits on
the integral can be set from 0 to ∞
H(s) =
 ∞
0
h(τ)e−sτ dτ.
For a causal system Eq. (3.13) simpliﬁes to
y(t) =
 ∞
0
h(τ)u(t −τ) dτ.
(3.19)
EXAMPLE 3.4
Transfer Function
Compute the transfer function for the system of Example 3.1, and ﬁnd the
output y for all time (−∞< t < ∞) when the input u = est for all time and
s is a given complex number.
Solution. The system equation from Example 3.3 is
˙y(t) + ky(t) = u(t) = est.
(3.20)
We assume that we can express y(t) as H(s)est. With this form, we have
˙y = sH(s)est, and Eq. (3.20) reduces to
sH(s)est + kH(s)est = est.
(3.21)
Solving for the transfer function H(s), we get
H(s) =
1
s + k .
3The integral does not converge for every value of s and care must be taken to be sure that the
result is not used where it does not exist. Refer to Appendix A for details.
4The corresponding output for the system is the particular solution from the well-known result
for solving linear ordinary differential equations.

94
Chapter 3 Dynamic Response
Substituting this back into Eq. (3.17) yields the output for all time
y(t) =
est
s + k .
The integral in Eq. (3.18) does not need to be computed to ﬁnd the
transfer function of a system. Instead, one can assume a solution of the form
of Eq. (3.17), substitute that into the differential equation of the system, then
solve for the transfer function H(s).
The transfer function can be formally deﬁned as follows: The function
H(s), whichisthetransfergainfromU(s)toY(s)—inputtooutput—iscalled
Transfer function
the transfer function of the system. It is the ratio of the Laplace transform
of the output of the system to the Laplace transform of the input. We can
derive the transfer function explicitly. If we take the Laplace transform of
both sides of Eq. (3.19) we have Y(s) = H(s)U(s) and
Y(s)
U(s) = H(s),
(3.22)
with the key assumption that all of the initial conditions on the system are
zero.
Transfer function
The transfer function H(s) is the ratio of the Laplace transform
of the output of the system to its input assuming all zero initial
conditions.
If the input u(t) is the unit impulse δ(t), then y(t) is the unit impulse
response. The Laplace transform of u(t) is 1 and the transform of y(t) is
H(s) because
Y(s) = H(s).
(3.23)
In words, this is to say
Transfer function
The transfer function H(s) is the Laplace transform of the unit
impulse response h(t).
Thus, one way to characterize an LTI system is by applying a unit
impulse and measuring the resulting response, which is a description (the
inverse Laplace transform) of the transfer function.
For example, given the ordinary differential equation describing a third-
order system with the output y(t) and input u(t)
...y + a1¨y + a2˙y + a3y = b1¨u + b2˙u + b3u,
(3.24)
we take the Laplace transform of both sides of the equation, assuming zero
initial conditions (y(0−) = ˙y(0−) = ¨y(0−) = u(0−) = ˙u(0−) = 0), to
obtain
s3Y(s) + a1s2Y(s) + a2sY(s) + a3Y(s) = b1s2U(s) + b2sU(s) + b3U(s),
(3.25)

3.1 Review of Laplace Transforms
95
(s3 + a1s2 + a2s + a3)Y(s) = (b1s2 + b2s + b3)U(s),
which leads to the transfer function H(s),
H(s) = Y(s)
U(s) =
b1s2 + b2s + b3
s3 + a1s2 + a2s + a3
= b(s)
a(s).
(3.26)
This idea can then be easily extended to a system of any order n.
EXAMPLE 3.5
Transfer Function for an RC Circuit
Compute the transfer function for the RC circuit driven by a voltage source
as shown in Fig. 3.3.
Solution. The system equation from Kirchhoff's voltage law is
Ri(t) + y(t) = u(t),
i(t) = C dy(t)
dt ,
or
RC˙y + y = u(t).
If the input voltage is a unit impulse signal
RC˙y + y = δ(t),
and we take the Laplace transform of both sides of the above equation (see
Appendix A)
RC(sY(s) −y(0−)) + Y(s) = U(s) = 1,
then assuming zero initial condition (y(0−) = 0) we ﬁnd
H(s) = Y(s)
U(s) = Y(s) =
1
RCs + 1.
The output, that is, the inverse Laplace transform of Y(s), is the impulse
response
y(t) = h(t) =
1
RC e−t
RC 1(t).
Therefore, the transfer function for this system is
H(s) = L{h(t)} =
1
RCs + 1.
Figure 3.3
RC circuit diagram
+
-
+
-
R
C
y(t)
u(t)
i(t)

96
Chapter 3 Dynamic Response
A very common way to use the exponential response of LTIs is in ﬁnding
the frequency response, or response to a sinusoid. First, we express the
Frequency response
sinusoid as a sum of two exponential expressions (Euler's relation):
A cos(ωt) = A
2 (e jωt + e−jωt).
If we let s = jω in the basic response formula Eq. (3.17), then the response
to u(t) = e jωt is y(t) = H( jω)e jωt; similarly, the response to u(t) = e−jωt
is H(−jω)e−jωt. By superposition, the response to the sum of these two
exponentials, which make up the cosine signal, is the sum of the responses:
y(t) = A
2 [H(jω)e jωt + H(−jω)e−jωt].
(3.27)
The transfer function H( jω) is a complex number that can be represented
in polar form or in magnitude-and-phase form as H( jω) = M(ω)e jϕ(ω), or
simply H = Me jϕ. With this substitution, Eq. (3.27) becomes
y(t) = A
2 M

e j(ωt+ϕ) + e−j(ωt+ϕ)
,
= AM cos(ωt + ϕ),
(3.28)
where
M = |H( jω)|, ϕ = ∠H( jω).
This means that if a system represented by the transfer function H(s) has a
sinusoidal input with magnitude A, the output will be sinusoidal at the same
frequency with magnitude AM and will be shifted in phase by the angle ϕ.
EXAMPLE 3.6
Frequency Response
For the system in Example 3.1, ﬁnd the response to the sinusoidal input
u = A cos(ωt). That is,
a. ﬁnd the frequency response and plot the response for k = 1,
b. determine the complete response due to the sinusoidal input u(t) =
sin(10t) again with k = 1.
Solution. In Example 3.4 we found the transfer function of the system in
Example 1. To ﬁnd the frequency response, we let s = jω so that
H(s) =
1
s + k =⇒H( jω) =
1
jω + k .
From this we get
M =

1
jω + k
 =
1
√
ω2 + k2
and
ϕ = −tan−1 
ω
k

.
According to Eq. (3.28), the response of this system to a sinusoid will be
y(t) = AM cos(ωt + ϕ).
(3.29)
M is usually referred to as the amplitude ratio and ϕ is referred to as the
phase and they are both functions of the input frequency, ω. The Matlab

3.1 Review of Laplace Transforms
97
program that follows is used to compute the amplitude ratio and phase for
k = 1, as shown in Fig. 3.4. The logspace command is used to set the fre-
quency range (on a logarithmic scale) and the bode command is used to
compute the frequency response in Matlab. Presenting frequency response
inthismanner(thatis, onalog-logscale)wasoriginatedbyH.W.Bode; thus,
these plots are referred to as "Bode plots."5 (See Chapter 6, Section 6.1.)
k = 1;
tf=('s');
% deﬁne Laplace variable
sysH = 1/(s+k);
% deﬁne system by its transfer function
w = logspace(-2,2);
% set frequency w to 50 values from
10−2 to 10+2
[mag,phase] = bode(sysH,w);
% compute frequency response
loglog(w,squeeze(mag));
% log-log plot of magnitude
semilogx(w,squeeze(phase));
% semi-log plot of phase
We can generalize the frequency response by study of the Laplace
transform of a signal f (t) as a generalization of Eq. (3.18)
F(s) =
 ∞
−∞
f (t)e−stdt.
(3.30)
Figure 3.4
Frequency-response
plot for k = 1
10-2
10-1
100
101
102
10-2
10-1
100
101
102
v (rad/sec)
Magnitude
v (rad/sec)
Phase
 -90
-60
-30
0
10-2
10-1
100
M
f5
5Note that % is used in Matlab to denote comments.

98
Chapter 3 Dynamic Response
If we apply this deﬁnition to both u(t) and y(t) and use the convolution
The key property of
Laplace transforms
integral Eq. (3.13), we ﬁnd that
Y(s) = H(s)U(s),
(3.31)
where Y(s) and U(s) are the Laplace transforms of y(t) and u(t),
respectively.
Laplace transforms such as Eq. (3.30) can be used to study the com-
plete response characteristics of feedback systems, including the transient
Transient response
response—that is, the time response to an initial condition or suddenly
applied signal. This is in contrast to the use of Fourier transforms, which
only take into account the steady-state response. A standard problem in con-
trol is to ﬁnd the response y(t) of a system given the input u(t) and a model
of the system. With Eq. (3.30), we have a means for computing the response
of LTI systems to quite general inputs. Given any input into a system, we
compute the transform of the input and the transfer function for the system.
The transform of the output is then given by Eq. (3.31) as the product of these
two. If we wanted the time function of the output, we would need to "in-
vert" Y(s) to get what is called the inverse transform; this step is typically
not carried out explicitly. Nevertheless, understanding the process necessary
for deriving y(t) from Y(s) is important because it leads to insight into the
behavior of linear systems. Hence, given a general linear system with trans-
fer function H(s) and an input signal u(t), the procedure for determining
y(t) using the Laplace transform is given by the following steps:
STEP 1. Determine the transfer function: H(s) = L{impulse response of
the system}. Compute H(s) by the following steps:
(a) Take the Laplace transform of the equations of motion. A table of
transform properties is frequently useful in this process.
(b) Solve the resulting algebraic equations. Often this step is greatly
helped by drawing the corresponding block diagram and solving the
equations by graphical manipulation of the blocks or using Matlab.
STEP 2. Determine the Laplace transform of the input signal: U(s) =
L{u(t)}.
STEP 3. Compute the Laplace transform of the output: Y(s) = H(s)U(s).
STEP 4. Break up Y(s) by partial-fraction expansion.
STEP 5. Find the output of the system by computing the inverse Laplace
transform of Y(s) in Step 4, y(t) = L−1{Y(s)} [that is, invert Y(s) to get
y(t)]:
(a) Look up the components of y(t) in a table of transform-time function
pairs.
(b) Combine the components to give the total solution in the desired
form.
As already mentioned, Steps 4 and 5 are almost never carried out in
practice, and a modiﬁed solution for a qualitative rather than a quantita-
tive solution is often adequate and almost always used for control design
purposes. The process begins with the ﬁrst three steps as before. However,
rather than inverting Y(s), one can use prior knowledge and intuition about
the effects of pole and zero locations in Y(s) on the response y(t) to estimate

3.1 Review of Laplace Transforms
99
key features of y(t). That is, we get information about y(t) from the pole-
zero constellation of Y(s) without actually inverting it, as discussed in the
rest of this chapter. We can also obtain equivalent information from the Bode
plot (see Chapter 6) if that is available.
While it is possible to determine the transient response properties of the
system using Eq. (3.30), it is generally more useful to use a simpler version
of the Laplace transform based on the input beginning at time zero.
EXAMPLE 3.7
Frequency Response (Example 3.6 continued)
To continue with the system in Example 3.6, determine the response to an
input that begins at t = 0 as u(t) = sin(10t)1(t), notice that from Laplace
transform tables (Appendix A, Table A.2), we have
L{u(t)} = L{sin(10t)} =
10
s2 + 100,
where L denotes the Laplace transform, and the output of the system using
partial fraction expansion (see Section 3.1.5) is given by
Y(s) = H(s)U(s)
=
1
s + 1
10
s2 + 100,
=
α1
s + 1 +
α0
s + j10 +
α∗
0
s −j10,
=
10
101
s + 1 +
j
2(1−j10)
s + j10 +
−j
2(1+j10)
s −j10 .
The inverse Laplace transform of the output is given by (see Appendix A)
y(t) = 10
101e−t +
1
√
101
sin(10t + ϕ)
= y1(t) + y2(t),
where
ϕ = tan−1(−10) = −84.2◦.
The component y1(t) is called the transient response as it decays to
zero as time goes on and the component y2(t) is called the steady state and
equals the response given by Eq. (3.29). Fig. 3.5(a) is a plot of the time
history of the output showing the different components (y1, y2) and the
composite (y) output response. The output frequency is 10 rad/sec and the
steady-state phase difference measured from Fig. 3.5(b) is approximately
10*δt = 1.47 rad = 84.2◦.6 Figure 3.5(b) shows the output lags the input
by 84.2◦. It also shows that the steady-state amplitude of the output is the
amplitude ratio
1
√
101 = 0.0995 (that is, the amplitude of the input signal
times the magnitude of the transfer function evaluated at ω = 10 rad/sec).
6The phase difference may also be determined by a Lissajous pattern.

100
Chapter 3 Dynamic Response
Figure 3.5
(a) Complete transient
response; (b) phase lag
between output and
input
1
10
9
8
7
6
Time (sec)
(a)
Transient response
5
4
3
2
0
-0.1
-0.05
0
0.05
0.1
0.15
0.2
0.25
Output
y2
y
y1
9.1
10
9.9
9.8
9.7
9.6
Time (sec)
(b)
Steady-state response
9.5
9.4
9.3
9.2
9
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
Output, input
dt
y(t)
u(t)
This example illustrates that the response of an LTI system to a sinusoid
of frequency ω is a sinusoid with the same frequency and with an ampli-
tude ratio equal to the magnitude of the transfer function evaluated at the
input frequency. Furthermore, the phase difference between input and output
signals is given by the phase of the transfer function evaluated at the input
frequency. The magnitude ratio and phase difference can be computed from
the transfer function as just discussed; they can also be measured experi-
mentally quite easily in the laboratory by driving the system with a known

3.1 Review of Laplace Transforms
101
sinusoidal input and measuring the steady-state amplitude and phase of the
system's output. The input frequency is set to sufﬁciently many values so
that curves such as the one in Fig. 3.4 are obtained.
3.1.3
The L−Laplace Transform
In this book it is useful to deﬁne a one-sided (or unilateral) Laplace trans-
form, which uses 0−(that is, a value just before t = 0) as the lower limit
of integration in Eq. (3.30). The L−Laplace transform of f (t), denoted by
Deﬁnition of Laplace
transform
L−{f (t)} = F(s), is a function of the complex variable s = σ1 + jω, where
F(s) =
 ∞
0−f (t)e−st dt.
(3.32)
The decaying exponential term in the integrand in effect provides a built-in
convergence factor if σ1 > 0. This means that even if f (t) does not vanish
as t →∞, the integrand will vanish for sufﬁciently large values of σ if f
does not grow at a faster-than-exponential rate. The fact that the lower limit
of integration is at 0−allows the use of an impulse function at t = 0, as
illustrated in Example 3.3; however, this distinction between t = 0−and
t = 0 does not usually come up in practice. We will therefore, for the most
part, drop the minus superscript on t = 0; however, we will return to using
the notation t = 0−when an impulse at t = 0 is involved and the distinction
is of practical value.
If Eq. (3.32) is a one-sided transform, then by extension, Eq. (3.30) is a
two-sided Laplace transform.7 We will use the L symbol from here on to
mean L−.
On the basis of the formal deﬁnition in Eq. (3.32), we can ascertain
the properties of Laplace transforms and compute the transforms of com-
mon time functions. The analysis of linear systems by means of Laplace
transforms usually involves using tables of common properties and time
functions, so we have provided this information in Appendix A. The tables
of time functions and their Laplace transforms, together with the table of
properties, permit us to ﬁnd transforms of complex signals from simpler
ones. For a thorough study of Laplace transforms and extensive tables, see
Churchill (1972) and Campbell and Foster (1948). For more study of the
two-sided transform, see Van der Pol and Bremmer (1955). These authors
show that the time function can be obtained from the Laplace transform by
the inverse relation
f (t) =
1
2πj
 σc+j∞
σc−j∞
F(s)est ds,
(3.33)
where σc is a selected value to the right of all the singularities of F(s) in the
s-plane. In practice, this relation is seldom used. Instead, complex Laplace
transforms are broken down into simpler ones that are listed in the tables
along with their corresponding time responses.
Let us compute a few Laplace transforms of some typical time functions.
7The other possible one-sided transform is, of course, L+, in which the lower limit of the
integral is 0+. This is sometimes used in other applications.

102
Chapter 3 Dynamic Response
EXAMPLE 3.8
Step and Ramp Transforms
Find the Laplace transform of the step a1(t) and ramp bt1(t) functions.
Solution. For a step of size a, f (t) = a1(t), and from Eq. (3.32) we have
F(s) =
 ∞
0
ae−st dt = −ae−st
s

∞
0
= 0 −−a
s
= a
s ,
Re(s) > 0.
For the ramp signal f (t) = bt1(t), again from Eq. (3.32) we have
F(s) =
 ∞
0
bte−st dt =

−bte−st
s
−be−st
s2
∞
0
= b
s2 ,
Re(s) > 0,
where we employed the technique of integration by parts,

u dv = uv −

v du,
with u = bt and dv = e−st dt. We can then extend the domain of the validity
of F(s) to the entire s-plane except at the pole location namely the origin
(see Appendix A).
A more subtle example is that of the impulse function.
EXAMPLE 3.9
Impulse Function Transform
Find the Laplace transform of the unit-impulse function.
Solution. From Eq. (3.32) we get
F(s) =
 ∞
0−δ(t)e−st dt =
 0+
0−δ(t) dt = 1.
(3.34)
It is the transform of the unit-impulse function that led us to choose the
L−transform rather than the L+ transform.
EXAMPLE 3.10
Sinusoid Transform
Find the Laplace transform of the sinusoid function.
Solution. Again, we use Eq. (3.32) to get
L{sin ωt} =
 ∞
0
(sin ωt)e−st dt.
(3.35)
If we substitute the relation from Eq. (WA.34) in Appendix WA (available
at www.fpe7e.com),
sin ωt = e jωt −e−jωt
2j

3.1 Review of Laplace Transforms
103
into Eq. (3.35), we ﬁnd that
L{sin ωt} =
 ∞
0
e jωt −e−jωt
2j

e−st dt
= 1
2j
 ∞
0

e( jω−s)t −e−( jω+s)t
dt
= 1
2j

1
jω −se( jω−s)t −
1
jω + se−( jω+s)t

∞
0
=
ω
s2 + ω2 ,
Re(s) > 0.
We can then extend the domain of the validity of computed Laplace transform
to the entire s-plane except at the pole locations s = ±jω (see Appendix A).
Table A.2 in Appendix A lists Laplace transforms for elementary
time functions. Each entry in the table follows from direct application of
the transform deﬁnition of Eq. (3.32), as demonstrated by Examples 3.8
through 3.10.
3.1.4
Properties of Laplace Transforms
In this section, we will address each of the signiﬁcant properties of the
Laplace transform listed in Table A.1. For the proofs of these properties and
related examples as well as the Initial Value Theorem, the reader is referred
to Appendix A.
1. Superposition
One of the most important properties of the Laplace transform is that it is
linear, which means that the principle of superposition applies:
L{αf1(t) + βf2(t)} = αF1(s) + βF2(s).
(3.36)
The amplitude scaling property is a special case of this; that is,
L{αf (t)} = αF(s).
(3.37)
2. Time Delay
Suppose a function f (t) is delayed by λ > 0 units of time, f1(t) = f (t −λ).
Its Laplace transform is
F1(s) =
 ∞
0
f (t −λ)e−st dt = e−sλF(s).
(3.38)
From this result we see that a time delay of λ corresponds to multiplication
of the transform by e−sλ.

104
Chapter 3 Dynamic Response
3. Time Scaling
It is sometimes useful to time-scale equations of motion. For example, in the
control system of a disk drive, it is meaningful to measure time in millisec-
onds (see also Chapter 10). If the time t is scaled by a factor a, f1(t) = f (at),
then the Laplace transform of the time-scaled signal is
F1(s) =
 ∞
0
f (at)e−st dt = 1
|a|F

 s
a

.
(3.39)
4. Shift in Frequency
Multiplication (modulation) of f (t) by an exponential expression in the time
domain, f1(t) = e−atf (t), corresponds to a shift in the frequency domain:
F1(s) =
 ∞
0
e−atf (t)e−st dt = F(s + a).
(3.40)
5. Differentiation
The transform of the derivative of a signal is related to its Laplace transform
and its initial condition as follows:
L
df
dt

=
 ∞
0−
df
dt

e−st dt = −f (0−) + sF(s).
(3.41)
Another application of Eq. (3.41) leads to
L{¨f } = s2F(s) −sf (0−) −˙f (0−).
(3.42)
Repeated application of Eq. (3.41) leads to
L{ f m(t)} = smF(s)−sm−1f (0−)−sm−2˙f (0−)−· · ·−f (m−1)(0−), (3.43)
where f m(t) denotes the mth derivative of f (t) with respect to time.
6. Integration
The Laplace transform of the integral of a time function f (t); f1(t) =
 t
0 f (ξ) dξ, is given by,
F1(s) = L
 t
0
f (ξ) dξ

= 1
s F(s),
(3.44)
which means that we simply multiply the function's Laplace transform by 1
s .
7. Convolution
We have seen previously that the response of a system is determined by
convolving the input with the impulse response of the system, or by forming
the product of the transfer function and the Laplace transform of the input.
The discussion that follows extends this concept to various time functions.

3.1 Review of Laplace Transforms
105
Convolution in the time domain corresponds to multiplication in the
frequency domain. Assume that L{ f1(t)} = F1(s) and L{ f2(t)} = F2(s).
Then
L{ f1(t) ∗f2(t)} =
 ∞
0
f1(t) ∗f2(t)e−st dt = F1(s)F2(s).
(3.45)
where ∗is the convolution operator. This implies that
L−1{F1(s)F2(s)} = f1(t) ∗f2(t).
(3.46)
A similar, or dual, of this result is discussed next.
8. Time Product
Multiplication in the time domain corresponds to convolution in the
frequency domain:
L{ f1(t)f2(t)} =
1
2πjF1(s) ∗F2(s).
(3.47)
9. Multiplication by Time
Multiplication by time f1(t) = tf (t) corresponds to differentiation in the
frequency domain:
F1(s) = L{tf (t)} = −d
dsF(s).
(3.48)
3.1.5
Inverse Laplace Transform by Partial-Fraction
Expansion
The easiest way to ﬁnd f (t) from its Laplace transform F(s), if F(s) is
rational, is to expand F(s) as a sum of simpler terms that can be found
in the tables. The basic tool for performing this operation is called partial-
fraction expansion. Consider the general form for the rational function F(s)
consisting of the ratio of two polynomials:
F(s) = b1sm + b2sm−1 + · · · + bm+1
sn + a1sn−1 + · · · + an
.
(3.49)
By factoring the polynomials, this same function could also be expressed in
terms of the product of factors as
F(s) = K m
i=1(s −zi)
n
i=1(s −pi).
(3.50)
We will discuss the simple case of distinct poles here. For a transform
F(s) representing the response of any physical system, m ≤n. When s = zi,
s is referred to as a zero of the function, and when s = pi, s is referred to
Zeros and poles
as a pole of the function. Assuming for now that the poles {pi} are real or
complex but distinct, we rewrite F(s) as the partial fraction
F(s) =
C1
s −p1
+
C2
s −p2
+ · · · +
Cn
s −pn
.
(3.51)

106
Chapter 3 Dynamic Response
Next, we determine the set of constants {Ci}. We multiply both sides of
Eq. (3.51) by the factor s −p1 to get
(s −p1)F(s) = C1 + s −p1
s −p2
C2 + · · · + (s −p1)Cn
s −pn
.
(3.52)
If we let s = p1 on both sides of Eq. (3.52), then all the Ci terms will equal
zero except for the ﬁrst one. For this term,
C1 = (s −p1)F(s)|s=p1.
(3.53)
The other coefﬁcients can be expressed in a similar form:
Ci = (s −pi)F(s)|s=pi.
This process is called the cover-up method because, in the factored form of
The cover-up method of
determining coefﬁcients
F(s)[Eq.(3.50)], wecancoveruptheindividualdenominatorterms, evaluate
the rest of the expression with s = pi, and determine the coefﬁcients Ci. Once
this has been completed, the time function becomes
f (t) =
n

i=1
Cie pit1(t),
because, as entry 7 in Table A.2 shows, if
F(s) =
1
s −pi
,
then
f (t) = e pit1(t).
For the cases of quadratic factors or repeated roots in the denominator, see
Appendix A.
EXAMPLE 3.11
Partial-Fraction Expansion: Distinct Real Roots
Suppose you have computed Y(s) and found that
Y(s) = (s + 2)(s + 4)
s(s + 1)(s + 3).
Find y(t).
Solution. We may write Y(s) in terms of its partial-fraction expansion:
Y(s) = C1
s +
C2
s + 1 +
C3
s + 3.
Using the cover-up method, we get
C1 = (s + 2)(s + 4)
(s + 1)(s + 3)

s=0
= 8
3.

3.1 Review of Laplace Transforms
107
In a similar fashion,
C2 = (s + 2)(s + 4)
s(s + 3)

s=−1
= −3
2,
and
C3 = (s + 2)(s + 4)
s(s + 1)

s=−3
= −1
6.
We can check the correctness of the result by adding the components again to
verify that the original function has been recovered. With the partial fraction
the solution can be looked up in the tables at once to be
y(t) = 8
31(t) −3
2e−t1(t) −1
6e−3t1(t).
The partial fraction expansion may be computed using the residue
function in Matlab:
num = conv([1 2],[1 4]);
% form numerator polynomial
den = conv([1 1 0],[1 3]);
% form denominator polynomial
[r,p,k] = residue(num,den);
% compute the residues
which yields the result
r = [-0.1667 -1.5000 2.6667]';
p = [-3 -1 0]';
k = [];
and agrees with the hand calculations. Note that the conv function in Matlab
is used to multiply two polynomials. (The arguments of the function are the
polynomial coefﬁcients.)
3.1.6
The Final Value Theorem
An especially useful property of the Laplace transform in control known as
the Final Value Theorem allows us to compute the constant steady-state
value of a time function given its Laplace transform. The theorem follows
from the development of partial-fraction expansion. Suppose we have a
transform Y(s) of a signal y(t) and wish to know the ﬁnal value y(t) from
Y(s). There are three possibilities for the limit. It can be constant, undeﬁned,
or unbounded. If Y(s) has any poles (that is, denominator roots, as described
in Section 3.1.5) in the right half of the s-plane—that is, if the real part of
any pi > 0—then y(t) will grow and the limit will be unbounded. If Y(s)
has a pair of poles on the imaginary axis of the s-plane (that is, pi = ±jω),
then y(t) will contain a sinusoid that persists forever and the ﬁnal value will
not be deﬁned. Only one case can provide a nonzero constant ﬁnal value: If
all poles of Y(s) are in the left half of the s-plane, except for one at s = 0,
then all terms of y(t) will decay to zero except the term corresponding to
the pole at s = 0, and that term corresponds to a constant in time. Thus,

108
Chapter 3 Dynamic Response
the ﬁnal value is given by the coefﬁcient associated with the pole at s = 0.
Therefore, the Final Value Theorem is as follows:
The Final Value Theorem
If all poles of sY(s) are in the left half of the s-plane, then
lim
t→∞y(t) = lim
s→0 sY(s).
(3.54)
This relationship is proved in Appendix A.
EXAMPLE 3.12
Final Value Theorem
Find the ﬁnal value of the system corresponding to
Y(s) =
3(s + 2)
s(s2 + 2s + 10).
Solution. Applying the Final Value Theorem, we obtain
y(∞) = sY(s)|s=0 = 3 · 2
10 = 0.6.
Thus, after the transients have decayed to zero, y(t) will settle to a constant
value of 0.6.
Care must be taken to apply the Final Value Theorem only to stable
Use the Final Value
Theorem on stable systems
only
systems (see Section 3.6). While one could use Eq. (3.54) on any Y(s),
doing so could result in erroneous results, as shown in the next example.
EXAMPLE 3.13
Incorrect Use of the Final Value Theorem
Find the ﬁnal value of the signal corresponding to
Y(s) =
3
s(s −2).
Solution. If we blindly apply Eq. (3.54), we obtain
y(∞) = sY(s)|s=0 = −3
2.
However,
y(t) =

−3
2 + 3
2e2t

1(t),
and Eq. (3.54) yields the constant term only. Of course, the true ﬁnal value is
unbounded, because of the unstable pole at s = 2.
The theorem can also be used to ﬁnd the DC gain of a system. The DC
Computing DC gain by the
Final Value Theorem
gain is the ratio of the output of a system to its input (presumed constant)
after all transients have decayed. To ﬁnd the DC gain, we assume that there
is a unit-step input [U(s) = 1/s] and we use the Final Value Theorem to

3.1 Review of Laplace Transforms
109
compute the steady-state value of the output. Therefore, for a system transfer
function G(s),
DC gain = lim
s→0 sG(s)1
s = lim
s→0 G(s).
(3.55)
EXAMPLE 3.14
DC Gain
Find the DC gain of the system whose transfer function is
G(s) =
3(s + 2)
(s2 + 2s + 10).
Solution. Applying Eq. (3.55), we get
DC gain = G(s)|s=0 = 3 · 2
10 = 0.6.
3.1.7
Using Laplace Transforms to Solve Differential
Equations
Laplace transforms can be used to solve differential equations using the
properties described in Appendix A. First, we ﬁnd the Laplace transform of
the differential equation using the differentiation properties in Eqs. (A.12)
and (A.13) inAppendixA. Then we ﬁnd the Laplace transform of the output;
using partial-fraction expansion and Table A.2, this can be converted to a
time response function. We will illustrate this with three examples.
EXAMPLE 3.15
Homogeneous Differential Equation
Find the solution to the differential equation
¨y(t) + y(t) = 0,
where
y(0) = α, ˙y(0) = β.
Solution.
Using Eq. (3.42), the Laplace transform of the differential
equation is
s2Y(s) −αs −β + Y(s) = 0,
(s2 + 1)Y(s) = αs + β,
Y(s) =
αs
s2 + 1 +
β
s2 + 1.
After looking up in the transform tables (Table A.2, Appendix A) the two
terms on the right side of the preceding equation, we get
y(t) = [α cos t + β sin t]1(t),
where 1(t) denotes a unit-step function. We can verify that this solution is
correct by substituting it back into the differential equation.

110
Chapter 3 Dynamic Response
Another example will illustrate the solution when the equations are
not homogeneous—that is, when the system is forced.
EXAMPLE 3.16
Forced Differential Equation
Find the solution to the differential equation ¨y(t)+5˙y(t)+4y(t) = 3, where
y(0) = α, ˙y(0) = β.
Solution. Taking the Laplace transform of both sides using Eqs. (3.41) and
(3.42), we get
s2Y(s) −sα −β + 5[sY(s) −α] + 4Y(s) = 3
s .
Solving for Y(s) yields
Y(s) = s(sα + β + 5α) + 3
s(s + 1)(s + 4)
.
The partial-fraction expansion using the cover-up method is
Y(s) =
3
4
s −
3−β−4α
3
s + 1
+
3−4α−4β
12
s + 4
.
Therefore, the time function is given by
y(t) =
3
4 + −3 + β + 4α
3
e−t + 3 −4α −4β
12
e−4t

1(t).
By differentiating this solution twice and substituting the result in the
original differential equation, we can verify that this solution satisﬁes the
differential equation.
The solution is especially simple if the initial conditions are all zero.
EXAMPLE 3.17
Forced Equation Solution with Zero Initial Conditions
Find the solution to ¨y(t) + 5˙y(t) + 4y(t) = u(t), y(0) = 0, ˙y(0) = 0,
u(t) = 2e−2t1(t),
1. using partial-fraction expansion,
2. using Matlab.
Solution
1. Taking the Laplace transform of both sides, we get
s2Y(s) + 5sY(s) + 4Y(s) =
2
s + 2.
Solving for Y(s) yields
Y(s) =
2
(s + 2)(s + 1)(s + 4).
The partial-fraction expansion using the cover-up method is
Y(s) = −
1
s + 2 +
2
3
s + 1 +
1
3
s + 4.

3.1 Review of Laplace Transforms
111
Therefore, the time function is given by
y(t) =

−1e−2t + 2
3e−t + 1
3e−4t

1(t).
2. The partial-fraction expansion may also be computed using the Matlab
residue function,
num = 2;
% form numerator
den = poly([-2;-1;-4]);
% form denominator polynomial
from its roots
[r,p,k] = residue(num,den);
% compute the residues
which results in the desired answer
r = [0.3333 -1 0.6667]';
p = [-4 -2 -1]';
k = [];
and agrees with the hand calculations.
The primary value of using the Laplace transform method of solving
differential equations is that it provides information concerning the qualita-
tive characteristic behavior of the response. Once we know the values of the
Poles indicate response
character.
poles of Y(s), we know what kind of characteristic terms will appear in the
response. In the last example, the pole at s = −1 produced a decaying y =
Ce−t term in the response. The pole at s = −4 produced a y = Ce−4t term in
the response, which decays faster. If there had been a pole at s = +1, there
would have been a growing y = Ce+t term in the response. Using the pole
locations to understand in essence how the system will respond is a powerful
tool and will be developed further in Section 3.3. Control systems designers
often manipulate design parameters so that the poles have values that would
give acceptable responses, and they skip the steps associated with converting
those poles to actual time responses until the ﬁnal stages of the design. They
use trial-and-error design methods (as described in Chapter 5) that graph-
ically present how changes in design parameters affect the pole locations.
Onceadesignhasbeenobtained, withpolelocationspredictedtogiveaccept-
able responses, the control designer determines a time response to verify that
the design is satisfactory. This is typically done by computer, which solves
the differential equations directly by using numerical computer methods.
3.1.8
Poles and Zeros
A rational transfer function can be described either as a ratio of two
polynomials in s,
H(s) = b1sm + b2sm−1 + · · · + bm+1
sn + a1sn−1 + · · · + an
= N(s)
D(s),
(3.56)
or as a ratio in factored zero pole form
H(s) = K
m
i=1(s −zi)
n
i=1(s −pi).
(3.57)

112
Chapter 3 Dynamic Response
K is called the transfer function gain. The roots of the numerator
z1, z2, . . . , zm are called the ﬁnite zeros of the system. The zeros are locations
Zeros
in the s-plane where the transfer function is zero. If s = zi, then
H(s)|s=zi = 0.
The zeros also correspond to the signal transmission-blocking properties
of the system and are also called the transmission zeros of the system. The
system has the inherent capability to block frequencies coinciding with its
zero locations. If we excite the system with the nonzero input, u = u0es0t,
where s0 is not a pole of the system, then the output is identically zero,8
y ≡0, for frequencies where s0 = zi. The zeros also have a signiﬁcant effect
on the transient properties of the system (see Section 3.5).
The roots of the denominator, p1, p2, . . . , pn, are called the poles9 of the
Poles
system. The poles are locations in the s-plane where the magnitude of the
transfer function becomes inﬁnite. If s = pi, then
|H(s)|s=pi = ∞.
The poles of the system determine its stability properties, as we shall see
in Section 3.6. The poles of the system also determine the natural or unforced
behavior of the system, referred to as the modes of the system. The zeros
and poles may be complex quantities, and we may display their locations in
a complex plane, which we refer to as the s-plane. The locations of the poles
and zeros lie at the heart of feedback control design and have signiﬁcant
practical implications for control system design. The system is said to have
n −m zeros at inﬁnity if m < n because the transfer function approaches
zero as s approaches inﬁnity. If the zeros at inﬁnity are also counted, the
system will have the same number of poles and zeros. No physical system
can have n < m; otherwise, it would have an inﬁnite response at ω = ∞.
If zi = pj, then there are cancellations in the transfer function, which may
lead to undesirable system properties as discussed in Chapter 7.
3.1.9
Linear System Analysis Using Matlab
The ﬁrst step in analyzing a system is to write down (or generate) the set
of time-domain differential equations representing the dynamic behavior
of the physical system. These equations are generated from the physical
laws governing the system behavior—for example, rigid body dynamics,
thermo-ﬂuid mechanics, and electromechanics, as described in Chapter 2.
The next step in system analysis is to determine and designate inputs and
outputs of the system and then to compute the transfer function characteriz-
ing the input-output behavior of the dynamic system. Earlier in this chapter,
we discussed that a linear dynamic system may also be represented by the
8Identically zero means that the output and all of its derivatives are zero for t > 0.
9The meaning of the pole can also be appreciated by visualizing a 3-D plot of the transfer
function, where the real and imaginary parts of s are plotted on the x and y axes, and the
magnitude of the transfer function is plotted on the vertical z axis. For a single pole, the resulting
3-Dplotwilllooklikeatentwiththe"tent-pole"beinglocatedatthepoleofthetransferfunction!

3.1 Review of Laplace Transforms
113
Laplace transform of its differential equation—that is, its transfer function.
The transfer function may be expressed as a ratio of two polynomials as in
Eq. (3.56) or in factored zero-pole form as in Eq. (3.57). By analyzing the
transfer function, we can determine the dynamic properties of the system,
both in a qualitative and quantitative manner. One way of extracting use-
ful system information is simply to determine the pole-zero locations and
deduce the essential characteristics of the dynamic properties of the system.
Another way is to determine the time-domain properties of the system by
determining the response of the system to typical excitation signals such
as impulses, steps, ramps, and sinusoids. Yet another way is to determine
the time response analytically by computing the inverse Laplace transform
using partial-fraction expansions and Tables A.1 and A.2. Of course, it is
also possible to determine the system response to an arbitrary input.
We will now illustrate this type of analysis by carrying out the preceding
calculations for some of the physical systems addressed in the examples in
Chapter 2 in order of increasing degree of difﬁculty. We will go back and
forth between the different representations of the system, transfer function,
pole-zero, and so on, using Matlab as our computational engine. Matlab
typically accepts the speciﬁcation of a system in several forms, including
transfer function and zero-pole, and refers to these two descriptions as tf
and zp, respectively. Furthermore, it can transform the system description
from any one form to another.
EXAMPLE 3.18
Cruise Control Transfer Function Using Matlab
Find the transfer function between the input u and the position of the car x
in the cruise control system in Example 2.1.
Solution.
From Example 2.1 we ﬁnd that the transfer function of the
system is
H(s) = 0s2 + 0s + 0.001
s2 + 0.05s + 0
=
0.001
s(s + 0.05).
In Matlab, the coefﬁcients of the numerator polynomial are displayed
as the row vector num and the denominator coefﬁcients are displayed as den.
The results for this example are
num = [0
0
0.001]
and
den = [1
0.05
0].
They can be returned by Matlab in this form using the printsys(num,den)
Matlab printsys
command. The pole-zero description is computed using the Matlab com-
mand
[z,p,k] = tf2zp(num,den)
and would result in the transfer function in factored form, where z = [ ],
p =

0
−0.05
′, and k = 0.001.

114
Chapter 3 Dynamic Response
EXAMPLE 3.19
DC Motor Transfer Function Using Matlab
In Example 2.13, assume that Jm = 0.01 kg·m2, b = 0.001 N·m·sec, Kt =
Ke = 1, Ra = 10 , and La = 1 H. Find the transfer function between the
input va and
1. the output θm,
2. the output ω = ˙θm.
Solution
1. Substituting the preceding parameters into Example 2.13, we ﬁnd that
the transfer function of the system is
H(s) =
100
s3 + 10.1s2 + 101s =
100
s(s2 + 10.1s + 101).
In Matlab we display the coefﬁcients of the numerator polynomial as
the row vector numa and the denominator as dena. The results for this
example are
numa = [ 0
0
0
100 ]
and
dena = [ 1
10.1
101
0 ].
The pole-zero description is computed using the Matlab command
[z,p,k] = tf2zp(numa,dena)
which results in
z = [ ],
p =
 0
−5.0500
+8.6889j
−5.0500
−8.6889j ′ ,
k = 100,
and yields the transfer function in factored form:
H(s) =
100
s(s + 5.05 + j8.6889)(s + 5.05 −j8.6889).
2. If we consider the velocity ˙θm as the output, then we ﬁnd numb=
[0 0 100], denb=[1 10.1 101], which tells us that the transfer function is
G(s) =
100s
s3 + 10.1s2 + 101s =
100
s2 + 10.1s + 101.
This is as expected, because ˙θm is simply the derivative of θm; thus
L{ ˙θm} = sL{θm}. For a unit-step command in va, we can compute the
step response in Matlab (recall Example 2.1):
s=tf('s');
% deﬁne Laplace variable
sysb=100/(sˆ3+10.1*sˆ2+101*s)
% form transfer function

3.1 Review of Laplace Transforms
115
Figure 3.6
Transient response for
DC motor
0
1
Time (sec)
2
3
4
5
0
0.2
0.4
0.6
0.8
0
1.2
1.4
v(rad/sec)
t=0:0.01:5;
% form time vector
y=step(sysb,t)
% compute step response;
plot(t,y)
% plot step response
The system yields a steady-state constant angular velocity as shown in
Fig. 3.6. Note that there is a slight offset, since the system does not
have unity DC gain.
When a dynamic system is represented by a single differential equation
of any order, ﬁnding the polynomial form of the transfer function from that
differential equation is usually easy. Therefore, you will ﬁnd it best in these
cases to specify a system directly in terms of its transfer function.
EXAMPLE 3.20
Transformations Using Matlab
Find the transfer function of the system whose differential equation is
¨y + 6˙y + 25y = 9u + 3˙u.
Solution. Using the differentiation rules given by Eqs. (3.41) and (3.42),
we see by inspection that
Y(s)
U(s) =
3s + 9
s2 + 6s + 25.
The Matlab statements are
numG = [3 9];
% form numerator
denG = [1 6 25];
% form denominator
If the transfer function was desired in factored form, it could be obtained
by transforming the tf description. Therefore, the Matlab statement

116
Chapter 3 Dynamic Response
% convert from numerator-denominator polynomials to pole-zero form
[z,p,k] = tf2zp(numG,denG)
would result in z = −3, p = [−3 + 4j
−3 −4j]′, k = 3. This means that
the transfer function could also be written as
Y(s)
U(s) =
3(s + 3)
(s + 3 −4j)(s + 3 + 4j).
We may also convert from zero-pole representation to the transfer function
representation using the Matlab zp2tf command
% convert from pole-zero form to numerator-denominator polynomials
[numG,denG]=zp2tf(z,p,k)
For this example, z=[−3], p=[−3+i*4;−3−i*4], k=[3] will yield the
numerator and denominator polynomials.
EXAMPLE 3.21
Satellite Transfer Function Using Matlab
1. Find the transfer function between the input Fc and the satellite attitude
θ in Example 2.3 and
2. Determinetheresponseofthesystemtoa25-Npulseof0.1-secduration,
starting at t = 5 sec. Let d = 1 m and I = 5000 kg·m2.
Solution
1. From Example 2.3, d
I =
1
5000 = 0.0002

m
kg·m2

and this means that
the transfer function of the system is
H(s) = 0.0002
s2
,
which can also be determined by inspection for this particular case. We
may display the coefﬁcients of the numerator polynomial as the row
vector num and the denominator as the row vector den. The results for
this example are
numG = [0
0
0.0002]
and
denG = [1
0
0].
2. The following Matlab statements compute the response of the system
to a 25-N, 0.1-sec duration thrust pulse input:
s=tf('s');
% deﬁne Laplace variable
sysG=0.0002/s ˆ2;
% deﬁne system by its transfer function
t=0:0.01:10;
% set up time vector with dt = 0.01 sec
% pulse of 25N, at 5 sec, for 0.1 sec duration
u1=[zeros(1,500)
25*ones(1,10)
zeros(1,491)];
% pulse input
[y1]=lsim(sysG,u1,t);
% linear simulation
ff=180/pi;
% conversion factor from radians to degrees

3.1 Review of Laplace Transforms
117
y1=ff*y1;
% output in degrees
plot(t,u1);
% plot input signal
plot(t,y1);
% plot output response
The system is excited with a short pulse (an impulse input) that has the
effect of imparting a nonzero angle θ0 at time t = 5 sec on the system.
Because the system is undamped, in the absence of any control it drifts
with constant angular velocity with a value imparted by the impulse at
t = 5 sec. The time response of the input is shown in Fig. 3.7(a) along
with the drift in angle θ in Fig. 3.7(b).
We now excite the system with the same positive-magnitude thrust
pulse at time t = 5 sec but follow that with a negative pulse with the
same magnitude and duration at time t = 6.1 sec. [See Fig. 3.8(a) for
the input thrust.] Then the attitude response of the system is as shown in
Fig. 3.8(b). This is actually how the satellite attitude angle is controlled
in practice. The additional relevant Matlab statements are
Figure 3.7
Transient response for
satellite: (a) thrust
input; (b) satellite
attitude
0
2
Time (sec)
(a)
5
7
9
1
4
3
6
8
10
0
5
10
15
20
25
Thrust, Fc
0
2
Time (sec)
(b)
5
7
9
1
4
3
6
8
10
0
0.04
0.08
0.12
0.02
0.06
0.1
0.14
0.16
u5

118
Chapter 3 Dynamic Response
Figure 3.8
Transient response for
satellite (double pulse):
(a) thrust input;
(b) satellite attitude
0
2
Time (sec)
(a)
5
7
9
1
4
3
6
8
10
-25
-15
-5
5
15
20
-20
-10
0
10
25
Thrust, Fc
0
2
Time (sec)
(b)
5
7
9
1
4
3
6
8
10
0
0.005
0.015
0.025
0.03
0.01
0.02
0.035
u5
% double pulse input
u2=[zeros(1,500) 25*ones(1,10) zeros(1,100) -25*ones(1,10)
zeros(1,381)];
[y2]=lsim(sysG,u2,t);
% linear simulation
plot(t,u2);
% plot input signal
ff=180/pi;
% conversion factor from radians to degrees
y2=ff*y2;
% output in degrees
plot(t,y2);
% plot output response
3.2
System Modeling Diagrams
3.2.1
The Block Diagram
To obtain the transfer function, we need to ﬁnd the Laplace transform of
the equations of motion and solve the resulting algebraic equations for the
relationship between the input and the output. In many control systems, the

3.2 System Modeling Diagrams
119
system equations can be written so that their components do not interact
except by having the input of one part be the output of another part. In these
cases, it is easy to draw a block diagram that represents the mathematical
relationships in a manner similar to that used for the component block dia-
gram in Fig. 1.2, Chapter 1. The transfer function of each component is
placed in a box, and the input-output relationships between components are
indicated by lines and arrows. We can then solve the equations by graphical
simpliﬁcation, which is often easier and more informative than algebraic
manipulation, even though the methods are in every way equivalent. Draw-
ings of three elementary block diagrams are seen in Fig. 3.9. It is convenient
to think of each block as representing an electronic ampliﬁer with the trans-
fer function printed inside. The interconnections of blocks include summing
points, where any number of signals may be added together. These are rep-
resented by a circle with the symbol  inside. In Fig. 3.9(a), the block
with transfer function G1(s) is in series with the block with transfer func-
tion G2(s), and the overall transfer function is given by the product G2G1.
In Fig. 3.9(b) two systems are in parallel with their outputs added, and the
overall transfer function is given by the sum G1+G2. These diagrams derive
simply from the equations that describe them.
Figure 3.9(c) shows a more complicated case. Here the two blocks are
connected in a feedback arrangement so that each feeds into the other. When
the feedback Y2(s) is subtracted, as shown in the ﬁgure, we call it negative
feedback. As you will see, negative feedback is usually required for system
Negative feedback
stability. For now, we will simply solve the equations and then relate them
back to the diagram. The equations are
U1(s) = R(s) −Y2(s),
Y2(s) = G2(s)G1(s)U1(s),
Y1(s) = G1(s)U1(s),
and their solution is
Y1(s) =
G1(s)
1 + G1(s)G2(s)R(s).
(3.58)
We can express the solution by the following rule:
The gain of a single-loop negative feedback system is given by the
forward gain divided by the sum of 1 plus the loop gain.
When the feedback is added instead of subtracted, we call it positive
feedback. In this case, the gain is given by the forward gain divided by
Positive feedback
the sum of 1 minus the loop gain.
The three elementary cases given in Fig. 3.9 can be used in combination
to solve, by repeated reduction, any transfer function deﬁned by a block
diagram. However, the manipulations can be tedious and subject to error
when the topology of the diagram is complicated. Fig. 3.10 shows exam-
ples of block-diagram algebra that complement those shown in Fig. 3.9.

120
Chapter 3 Dynamic Response
G1
U1(s)
 + 
 - 
G2
Y2(s)
U(s)
G1
G2
 + 
 + 
Y(s)
(a)
(b)
R(s)
G1
G2
(c)
U1(s)
Y1(s)
Y(s)
Y2(s)
U2(s)
Y(s)
U(s) = G2  +  G1
=
Y(s)
R(s)
G1
1  +  G2G1
Y2(s)
U1(s)  = G2G1
©
©
Figure 3.9
Three examples of elementary block diagrams: (a) series; (b) parallel; (c) feedback
Figure 3.10
Examples of
block-diagram algebra:
(a) moving a pickoff
point; (b) moving a
summer; (c) conversion
to unity feedback
G1
U1
(a)
Y2
Y1
Pick-off
point
G1
U1
Y2
Y1
G1
1
G1
U1
(b)
Y1
G1
U1
Y1
+
-
G1
U2
U2
+
-
G1
R
(c)
Y1
R
Y
+
-
+
-
G2
U1
G2
1
G2
G1
U2
Y2
Y
©
©
©
©
K
K
K
Figures 3.10(a) and (b) show how the interconnections of a block dia-
gram can be manipulated without affecting the mathematical relationships.
Figure 3.10(c) shows how the manipulations can be used to convert a general
system (on the left) to a system without a component in the feedback path,
usually referred to as a unity feedback system.
Unity feedback system
In all cases, the basic principle is to simplify the topology while main-
taining exactly the same relationships among the remaining variables of the
block diagram. In relation to the algebra of the underlying linear equations,
block-diagram reduction is a pictorial way to solve equations by eliminating
variables.

3.2 System Modeling Diagrams
121
Figure 3.11
Block diagram of a
second-order system
R
2
+
-
+
+
Y
4
s
1
s
(a)
R
-
+
Y
2s + 4
s
1
s
(b)
©
©
©
EXAMPLE 3.22
Transfer Function from a Simple Block Diagram
Find the transfer function of the system shown in Fig. 3.11(a).
Solution.
First we simplify the block diagram by reducing the parallel
combination of the controller path. This results in the diagram of Fig. 3.11(b),
and we use the feedback rule to obtain the closed-loop transfer function:
T(s) = Y(s)
R(s) =
2s+4
s2
1 + 2s+4
s2
=
2s + 4
s2 + 2s + 4.
EXAMPLE 3.23
Transfer Function from the Block Diagram
Find the transfer function of the system shown in Fig. 3.12(a).
Solution.
First we simplify the block diagram. Using the principles of
Eq. (3.58), we replace the feedback loop involving G1 and G3 by its equiv-
alent transfer function, noting that it is a positive feedback loop. The result
is Fig. 3.12(b). The next step is to move the pick off point preceding G2 to
its output [see Fig. 3.12(a)], as shown in Fig. 3.12(c). The negative feedback
loop on the left is in series with the subsystem on the right, which is com-
posed of the two parallel blocks G5 and G6/G2. The overall transfer function
can be written using all three rules for reduction given by Fig. 3.9:
T(s) = Y(s)
R(s) =
G1G2
1−G1G3
1 + G1G2G4
1−G1G3

G5 + G6
G2

,
=
G1G2G5 + G1G6
1 −G1G3 + G1G2G4
.
As we have seen, a system of algebraic equations may be represented by
a block diagram that represents individual transfer functions by blocks and
has interconnections that correspond to the system equations. A block dia-
gram is a convenient tool to visualize the system as a collection of interrelated
subsystems that emphasize the relationships among the system variables.

122
Chapter 3 Dynamic Response
Figure 3.12
Example for
block-diagram
simpliﬁcation
G1
+
-
+
+
G3
G4
G2
G6
G5
+
+
Y
(a)
G6
G4
G2
G5
+
+
Y
1- G1G3
G1
+
-
R
R
(b)
G4
G2
G5
+
+
Y
1- G1G3
G1
+
-
R
(c)
G2
G6
©
©
©
©
©
©
©
3.2.2
Block-Diagram Reduction Using Matlab
If the individual transfer functions are available for components in a control
system, it is possible to use Matlab commands to compute the transfer func-
tions of interconnected systems. The three commands series, parallel, and
feedback can be used for this purpose. They compute the transfer functions
of two component block transfer functions in series, parallel, and feedback
conﬁgurations, respectively. The next simple example illustrates their use.
EXAMPLE 3.24
Transfer Function of a Simple System Using Matlab
Repeat the computation of the transfer function for the block diagram in
Fig. 3.11(a) using Matlab.
Solution. We label the transfer function of the separate blocks shown in
Fig. 3.11(a) as illustrated in Fig. 3.13. Then we combine the two parallel
blocks G1 and G2 by

3.3 Effect of Pole Locations
123
Figure 3.13
Example for
block-diagram
simpliﬁcation
R
G1
G6
G2
G4
+
-
+
+
Y
©
©
s=tf('s');
% specify a transfer function using
a rational function in the Laplace
variable s
sysG1=2;
% deﬁne subsystem G1
sysG2=4/s;
% deﬁne subsystem G2
sysG3=parallel(sysG1,sysG2);
% parallel combination of G1 and G2
sysG4=1/s;
% deﬁne subsystem G4
sysG5=series(sysG3,sysG4);
% series combination of G3 and G4
sysG6=1;
sysCL=feedback(sysG5,sysG6,-1);
% feedback combination of G5 and G6
The Matlab results are sysCL of the form
Y(s)
R(s) =
2s + 4
s2 + 2s + 4,
and this is the same result as the one obtained by block-diagram reduction.
3.2.3
Mason's Rule and the Signal Flow Graph
An alternative to block-diagram reduction is the Mason's rule that is a useful
technique for determining transfer functions of complicated interconnected
systems. See Appendix W3.2.3 at www.fpe7e.com.
3.3
Effect of Pole Locations
Once the transfer function has been determined by any of the available
methods, we can start to analyze the response of the system it represents.
When the system equations are simultaneous ordinary differential equations
(ODEs), the transfer function that results will be a ratio of polynomials;
that is,
H(s) = b(s)/a(s).
If we assume that b and a have no common factors (as is usually the case),
then values of s such that a(s) = 0 will represent points where H(s) is inﬁn-
ity. As we discussed in Section 3.1.5, these s-values are called poles of H(s).
Poles
Values of s such that b(s) = 0 are points where H(s) = 0 and the corre-
sponding s-locations are called zeros. The effect of zeros on the transient
Zeros
response will be discussed in Section 3.5. These poles and zeros completely
describe H(s) except for a constant multiplier. Because the impulse response
is given by the time function corresponding to the transfer function, we call

124
Chapter 3 Dynamic Response
the impulse response the natural response of the system. We can use the
The impulse response is
the natural response.
poles and zeros to compute the corresponding time response and thus iden-
tify time histories with pole locations in the s-plane. For example, the poles
identify the classes of signals contained in the impulse response, as may be
seen by a partial-fraction expansion of H(s). For a ﬁrst-order pole,
H(s) =
1
s + σ .
Table A.2, entry 7 indicates that the impulse response will be an exponential
First-order system impulse
response
function; that is,
h(t) = e−σt1(t).
When σ > 0, the pole is located at s < 0, the exponential expression decays,
and we say the impulse response is stable. If σ < 0, the pole is to the right
Stability
of the origin. Because the exponential expression here grows with time, the
impulse response is referred to as unstable (Section 3.6). Fig. 3.14(a) shows
a typical stable response and deﬁnes the time constant
Time constant τ
τ = 1/σ,
(3.59)
as the time when the response is 1/e times the initial value. Hence, it is a
measure of the rate of decay. The straight line is tangent to the exponential
curve at t = 0 and terminates at t = τ. This characteristic of an exponential
expression is useful in sketching a time plot or checking computer results.
Figure 3.14(b) shows the impulse and step response for a ﬁrst-order
system computed using Matlab.
EXAMPLE 3.25
Response versus Pole Locations, Real Roots
Compare the time response with the pole locations for the system with a
transfer function between input and output given by
H(s) =
2s + 1
s2 + 3s + 2.
(3.60)
Solution. The numerator is
b(s) = 2

s + 1
2

,
and the denominator is
a(s) = s2 + 3s + 2 = (s + 1)(s + 2).
The poles of H(s) are therefore at s = −1 and s = −2 and the one (ﬁnite)
zero is at s = −1
2. A complete description of this transfer function is shown
by the plot of the locations of the poles and the zeros in the s-plane using
the Matlab pzmap(num,den) function with
num=[2 1];
den=[1 3 2];
(see Fig. 3.15). A partial-fraction expansion of H(s) results in
H(s) = −
1
s + 1 +
3
s + 2.

3.3 Effect of Pole Locations
125
Figure 3.14
First-order system
response: (a) impulse
response; (b) impulse
response and step
response using Matlab
h(t)
1.0
0.8
0.6
0.4
0.2
0 0
1.0
2.0
3.0
4.0
Time (sec)
t  =  t
e-st
1
e
0
2
Time (sec)
1
3
4
0
0.2
0.4
0.6
0.8
1
h(t), y(t)
(b)
y
h
(a)
Figure 3.15
Sketch of s-plane
showing poles as
crosses and zeros as
circles
1
-1
-2
-j
j
Im(s)
Re(s)
= Zero
= Pole
From Table A.2, we can look up the inverse of each term in H(s), which will
give us the time function h(t) that would result if the system input were an
impulse. In this case,
h(t) =

−e−t + 3e−2t
t ≥0,
0
t < 0.
(3.61)

126
Chapter 3 Dynamic Response
Figure 3.16
Time functions
associated with points
in the s-plane (LHP, left
half-plane; RHP, right
half-plane)
Im(s)
Re(s)
LHP
RHP
Stable
Unstable
We see that the shape of the component parts of h(t), which are e−t and
e−2t, are determined by the poles at s = −1 and −2. This is true of more
complicated cases as well: In general, the shapes of the components of the
natural response are determined by the locations of the poles of the transfer
function.
A sketch of these pole locations and corresponding natural responses is
"Fast poles" and "slow
poles" refer to relative rate
of signal decay.
given in Fig. 3.16, along with other pole locations including complex ones,
which will be discussed shortly.
The role of the numerator in the process of partial-fraction expansion
is to inﬂuence the size of the coefﬁcient that multiplies each component.
Because e−2t decays faster than e−t, the signal corresponding to the pole at
−2 decays faster than the signal corresponding to the pole at −1. For brevity
we simply say that the pole at −2 is faster than the pole at −1. In general,
poles farther to the left in the s-plane are associated with natural signals that
decay faster than those associated with poles closer to the imaginary axis. If
the poles had been located with positive values of s (in the right half of the
s-plane), the response would have been a growing exponential function and
thus unstable. Fig. 3.17 shows that the fast 3e−2t term dominates the early
part of the time history and that the −e−t term is the primary contributor
later on.
The purpose of this example is to illustrate the relationship between the
poles and the character of the response, which can be done exactly only by
ﬁnding the inverse Laplace transform and examining each term as before.
Impulse response using
Matlab
However, if we simply wanted to plot the impulse response for this example,
the expedient way would be to use the Matlab sequence
s=tf('s');
% deﬁne Laplace variable
sysH=(2*s+1)/(s ˆ2+3*s+2);
% deﬁne system from its numerator
and denominator
impulse(sysH);
% compute impulse response

3.3 Effect of Pole Locations
127
Figure 3.17
Impulse response
of Example 3.25
[Eq. (3.60)]
h(t)
2.0
1.5
1.0
0.5
0
-0.5
6
5
4
3
2
1
0
Time (sec)
The result is shown in Fig. 3.17.
Complex poles can be deﬁned in terms of their real and imaginary parts,
traditionally referred to as
s = −σ ± jωd.
This means that a pole has a negative real part if σ is positive. Since
complex poles always come in complex conjugate pairs, the denominator
corresponding to a complex pair will be
a(s) = (s + σ −jωd)(s + σ + jωd) = (s + σ)2 + ω2
d.
(3.62)
When ﬁnding the transfer function from second-order differential equations,
we typically write the result in the polynomial form
H(s) =
ω2
n
s2 + 2ζωns + ω2n
.
(3.63)
By multiplying out the form given by Eq. (3.62) and comparing it with
the coefﬁcients of the denominator of H(s) in Eq. (3.63), we ﬁnd the
correspondence between the parameters to be
σ = ζωn
and
ωd = ωn

1 −ζ 2,
(3.64)
where the parameter ζ is the damping ratio10 and ωn is the undamped
Damping ratio; damped
and undamped natural
frequency
natural frequency. The poles of this transfer function are located at a radius
ωn in the s-plane and at an angle θ = sin−1 ζ, as shown in Fig. 3.18.
Therefore, the damping ratio reﬂects the level of damping as a fraction
of the critical damping value where the poles become real. In rectangular
coordinates the poles are at s = −σ ± jωd. When ζ = 0, we have no
damping, θ = 0, and the damped natural frequency ωd = ωn, the undamped
natural frequency.
For purposes of ﬁnding the time response from TableA.2 corresponding
to a complex transfer function, it is easiest to manipulate the H(s) so that
10In communications and ﬁlter engineering, the standard second-order transfer function is
written as H = 1/[1 + Q(s/ωn + ωn/s)]. Here, ωn is called the band center and Q is the
quality factor. Comparison with Eq. (3.63) shows that Q = 1/2ζ.

128
Chapter 3 Dynamic Response
Figure 3.18
s-plane plot for a pair of
complex poles
Im(s)
Re(s)
u = sin-1z
vn
vd
s
the complex poles ﬁt the form of Eq. (3.62), because then the time response
can be found directly from the table. Equation (3.63) can be rewritten as
H(s) =
ω2
n
(s + ζωn)2 + ω2n(1 −ζ 2).
(3.65)
Therefore, from entry number 20 in Table A.2 and the deﬁnitions in
Eq. (3.64), we see that the impulse response is
Standard second-order
system impulse response
h(t) =
ωn

1 −ζ 2 e−σt(sin ωdt)1(t).
(3.66)
Fig. 3.19(a) plots h(t) for several values of ζ such that time has been normal-
ized to the undamped natural frequency ωn. Note that the actual frequency
ωd decreases slightly as the damping ratio increases. Note also that for very
low damping the response is oscillatory, while for large damping (ζ near 1)
the response shows no oscillation. A few of these responses are sketched in
Fig. 3.16 to show qualitatively how changing pole locations in the s-plane
affect impulse responses.You will ﬁnd it useful as a control designer to com-
mit the image of Fig. 3.16 to memory so that you can understand instantly
how changes in pole locations inﬂuence the time response.
Three pole locations are shown in Fig. 3.20 for comparison with the
Stability depends on
whether natural response
grows or decays.
corresponding impulse responses in Fig. 3.19(a). The negative real part of the
pole, σ, determines the decay rate of an exponential envelope that multiplies
the sinusoid, as shown in Fig. 3.21. Note that if σ < 0 (and the pole is
in the RHP), then the natural response will grow with time, so, as deﬁned
earlier, the system is said to be unstable. If σ = 0, the natural response
neither grows nor decays, so stability is open to debate. If σ > 0, the natural
response decays, so the system is stable.
It is also interesting to examine the step response of H(s)—that is, the
Step response
response of the system H(s) to a unit-step input u = 1(t), where U(s) = 1/s.
The step-response transform is given by Y(s) = H(s)U(s), which is found
in Table A.2, entry 21. Figure 3.19(b), which plots y(t) for several values of
ζ, shows that the basic transient response characteristics from the impulse
response carry over quite well to the step response; the difference between

3.3 Effect of Pole Locations
129
Figure 3.19
Responses of
second-order systems
versus ζ : (a)impulse
responses; (b) step
responses
(b)
0.9
z = 1
0
2
4
6
8
10
12
1.0
0.8
0.6
0.4
0.2
0.0
-0.2
-0.4
-0.6
-0.8
-1.0
y(t)
vnt
(a)
0
2
4
6
8
10
12
vnt
2.0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
y(t)
z = 0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
z = 0
0.1
0.2
0.3
0.4
0.5
0.6
z = 0.7
0.8
0.9
1.0
the two responses is that the step response's ﬁnal value is the commanded
unit step.
EXAMPLE 3.26
Oscillatory Time Response
Discuss the correlation between the poles of
H(s) =
2s + 1
s2 + 2s + 5,
(3.67)

130
Chapter 3 Dynamic Response
Figure 3.20
Pole locations
corresponding to three
values of ζ
Re(s)
Im(s)
Re(s)
Im(s)
Re(s)
Im(s)
455
305
17.55
z = 0.707
z = 0.5
z = 0.3
Figure 3.21
Second-order system
response with an
exponential envelope
bound
0
Time (sec)
30
25
20
15
10
5
-1
-0.6
- 0.2
0.2
0.6
0.8
- 0.8
- 0.4
0
0.4
1
h(t)
 - e-st
e-st
and the impulse response of the system and ﬁnd the exact impulse response.
Solution. From the form of H(s) given by Eq. (3.63), we see that
ω2
n = 5 ⇒ωn =
√
5 = 2.24 rad/sec
and
2ζωn = 2 ⇒ζ =
1
√
5
= 0.447.
This indicates that we should expect a frequency of around 2 rad/sec with
very little oscillatory motion. In order to obtain the exact response, we
manipulate H(s) until the denominator is in the form of Eq. (3.62):
H(s) =
2s + 1
s2 + 2s + 5 =
2s + 1
(s + 1)2 + 22 .
From this equation we see that the poles of the transfer function are complex,
with real part −1 and imaginary parts ±2j. Table A.2 has two entries, num-
bers 19 and 20, that match the denominator. The right side of the preceding

3.4 Time-Domain Speciﬁcations
131
Figure 3.22
System response for
Example 3.25
0
Time (sec)
6
5
4
3
2
1
- 2
- 1.5
- 1
- 0.5
0
0.5
1
1.5
2
h(t)
equation needs to be broken into two parts so that they match the numerators
of the entries in the table:
H(s) =
2s + 1
(s + 1)2 + 22 = 2
s + 1
(s + 1)2 + 22 −1
2
2
(s + 1)2 + 22 .
Thus, the impulse response is
h(t) =

2e−t cos 2t −1
2e−t sin 2t

1(t).
Fig. 3.22 is a plot of the response and shows how the envelope attenuates
the sinusoid, the domination of the 2 cos 2t term, and the small phase shift
caused by the −1
2 sin 2t term.
As in the previous example, the expedient way of determining the
Impulse response by
Matlab
impulse response would be to use the Matlab sequence
s=tf('s');
% deﬁne Laplace variable
sysH=(2*s+1)/(sˆ2+2*s+5);
% deﬁne system by its numerator
and denominator
t=0:0.1:6;
% form time vector
y=impulse(sysH,t);
% compute impulse response
plot(t,y);
% plot impulse response
as shown in Fig. 3.22.
3.4
Time-Domain Speciﬁcations
Performance speciﬁcations for a control system design often involve certain
Deﬁnitions of rise time,
settling time, overshoot,
and peak time
requirements associated with the time response of the system. The require-
ments for a step response are expressed in terms of the standard quantities
illustrated in Fig. 3.23:
1. The rise time tr is the time it takes the system to reach the vicinity of
its new set point.

132
Chapter 3 Dynamic Response
Figure 3.23
Deﬁnition of rise time
tr, settling time ts, and
overshoot Mp
t
Mp
tp
ts
tr
1
0.9
0.1
;1%
2. The settling time ts is the time it takes the system transients to decay.
3. The overshoot Mp is the maximum amount the system overshoots
its ﬁnal value divided by its ﬁnal value (and is often expressed as a
percentage).
4. The peak time tp is the time it takes the system to reach the maximum
overshoot point.
3.4.1
Rise Time
For a second-order system, the time responses shown in Fig. 3.19(b) yield
information about the speciﬁcations that is too complex to be remembered
unless converted to a simpler form. By examining these curves in light of the
deﬁnitions given in Fig. 3.23, we can relate the curves to the pole-location
parameters ζ and ωn. For example, all the curves rise in roughly the same
time. If we consider the curve for ζ = 0.5 to be an average, the rise time11
from y = 0.1 to y = 0.9 is approximately ωntr = 1.8. Thus we can say that
tr ∼= 1.8
ωn
.
(3.68)
Although this relationship could be embellished by including the effect of
the damping ratio, it is important to keep in mind how Eq. (3.68) is typically
used. It is accurate only for a second-order system with no zeros; for all
other systems it is a rough approximation to the relationship between tr
and ωn. Most systems being analyzed for control systems design are more
complicated than the pure second-order system, so designers use Eq. (3.68)
with the knowledge that it is a rough approximation only.
3.4.2
Overshoot and Peak Time
For the overshoot Mp we can be more analytical. This value occurs when
the derivative is zero, which can be found from calculus. The time history
11Rise time tr.

3.4 Time-Domain Speciﬁcations
133
of the curves in Fig. 3.19(b), found from the inverse Laplace transform of
H(s)/s, is
y(t) = 1 −e−σt

cos ωdt + σ
ωd
sin ωdt

,
(3.69)
where ωd = ωn

1 −ζ 2 and σ = ζωn. We may rewrite the preceding
equation using the trigonometric identity
A sin(α) + B cos(α) = C cos(α −β),
or
C =

A2 + B2 =
1

1 −ζ 2 ,
β = tan−1
A
B

= tan−1

ζ

1 −ζ 2

= sin−1(ζ),
with A = σ
ωd , B = 1, and α = ωdt, in a more compact form as
Standard second-order
system step response
y(t) = 1 −
e−σt

1 −ζ 2 cos(ωdt −β).
(3.70)
When y(t) reaches its maximum value, its derivative will be zero:
˙y(t) = σe−σt

cos ωdt + σ
ωd
sin ωdt

−e−σt(−ωd sin ωdt + σ cos ωdt) = 0,
= e−σt
σ 2
ωd
+ ωd

sin ωdt = 0.
This occurs when sin ωdt = 0, so
ωdtp = π
and thus
Peak time tp
tp = π
ωd
.
(3.71)
Substituting Eq. (3.71)into the expression for y(t), we compute
y(tp) = 1 + Mp = 1 −e−σπ/ωd

cos π + σ
ωd
sin π

,
= 1 + e−σπ/ωd.
Thus we have the formula
Overshoot Mp
Mp = e−πζ/√
1−ζ 2,
0 ≤ζ < 1,
(3.72)

134
Chapter 3 Dynamic Response
Figure 3.24
Overshoot versus
damping ratio for the
second-order system
100
90
80
70
60
50
40
30
20
10
0
Mp (%)
0.0
0.2
0.4
0.6
0.8
1.0
z
16%
5%
which is plotted in Fig. 3.24. Two frequently used values from this curve are
Mp = 0.16 for ζ = 0.5 and Mp = 0.05 for ζ = 0.7, that is, 16% and 5%
overshoot, respectively.
3.4.3
Settling Time
The ﬁnal parameter of interest from the transient response is the settling time
ts. This is the time required for the transient to decay to a small value so that
y(t) is almost in the steady state. Various measures of smallness are possible.
For illustration we will use 1% as a reasonable measure; in other cases 2%
or 5% are used. As an analytic computation, we notice that the deviation of
y from 1 is the product of the decaying exponential e−σt and the circular
functions sine and cosine. The duration of this error is essentially decided
by the transient exponential, so we can deﬁne the settling time as that value
Settling time ts
of ts when the decaying exponential reaches 1%:
e−ζωnts = 0.01.
Therefore,
ζωnts = 4.6,
or
ts = 4.6
ζωn
= 4.6
σ ,
(3.73)
where σ is the negative real part of the pole, as may be seen from Fig. 3.18.
Equations (3.68), (3.72), and (3.73) characterize the transient response
of a system having no ﬁnite zeros and two complex poles and with undamped
natural frequency ωn, damping ratio ζ, and negative real part σ. In analysis
and design, they are used to estimate rise time, overshoot, and settling time,

3.4 Time-Domain Speciﬁcations
135
Im(s)
Re(s)
Im(s)
Re(s)
Im(s)
Re(s)
Im(s)
Re(s)
vn
sin-1z
s
(a)
(b)
(c)
(d)
Figure 3.25
Graphs of regions in the s-plane delineated by certain transient requirements: (a) rise time;
(b) overshoot; (c) settling time; (d) composite of all three requirements
respectively, for just about any system. In design synthesis we wish to specify
Design synthesis
tr, Mp, and ts and to ask where the poles need to be so that the actual responses
are less than or equal to these speciﬁcations. For speciﬁed values of tr, Mp,
and ts, the synthesis form of the equation is then
ωn ≥1.8
tr
,
(3.74)
ζ ≥ζ(Mp)
(from Fig. 3.24),
(3.75)
σ ≥4.6
ts
.
(3.76)
These equations, which can be graphed in the s-plane as shown in
Fig. 3.25(a-c), will be used in later chapters to guide the selection of pole and
zero locations to meet control system speciﬁcations for dynamic response.
It is important to keep in mind that Eqs. (3.74)-(3.76) are qualitative
guides and not precise design formulas. They are meant to provide only a
startingpointforthedesigniteration.Afterthecontroldesigniscomplete, the
time response should always be checked by an exact calculation, usually by
numerical simulation, to verify whether the time speciﬁcations have actually
been met. If not, another iteration of the design is required.
For a ﬁrst-order system,
First-order system step
response
H(s) =
σ
s + σ ,
and the transform of the step response is
Y(s) =
σ
s(s + σ).
We see from entry 11 in Table A.2 that Y(s) corresponds to
y(t) = (1 −e−σt)1(t).
(3.77)

136
Chapter 3 Dynamic Response
Comparison with the development for Eq. (3.73) shows that the value of ts
for a ﬁrst-order system is the same:
ts = 4.6
σ .
No overshoot is possible, so Mp = 0. The rise time from y = 0.1 to y = 0.9
can be seen from Fig. 3.14 to
tr = ln 0.9 −ln 0.1
σ
= 2.2
σ .
However, it is more typical to describe a ﬁrst-order system in terms of its
Time constant τ
time constant, which was deﬁned in Fig. 3.14 to be τ = 1/σ.
EXAMPLE 3.27
Transformation of the Speciﬁcations to the s-Plane
Solution. Without knowing whether or not the system is second order with
no zeros, it is impossible to ﬁnd the allowable region accurately. Regardless
of the system, we can obtain a ﬁrst approximation using the relationships
for a second-order system. Equation (3.74) indicates that
ωn ≥1.8
tr
= 3.0 rad/sec,
Eq. (3.75) and Fig. 3.24 indicate that
ζ ≥0.6,
and Eq. (3.76) indicates that
σ ≥4.6
3 = 1.5 sec.
The allowable region is anywhere to the left of the solid line in Fig. 3.26.
Note that any pole meeting the ζ and ωn restrictions will automatically meet
the σ restriction.
Figure 3.26
Time domain
speciﬁcations region
in s-plane for
Example 3.27
3
2
1
0
- 1
- 2
- 3
- 3
- 4
- 5
- 2
- 1
0
1
Re(s)
Im(s)

3.5 Effects of Zeros and Additional Poles
137
3.5
Effects of Zeros and Additional Poles
Relationships such as those shown in Fig. 3.25 are correct for the simple
second-order system; for more complicated systems they can be used only
as guidelines. If a certain design has an inadequate rise time (is too slow),
we must raise the natural frequency; if the transient has too much overshoot,
then the damping needs to be increased; if the transient persists too long, the
poles need to be moved to the left in the s-plane.
Thus far only the poles of H(s) have entered into the discussion. There
may also be zeros of H(s).12 At the level of transient analysis, the zeros
Effect of zeros
exert their inﬂuence by modifying the coefﬁcients of the exponential terms
whose shape is decided by the poles, as seen in Example 3.25. To illustrate
The effect of zeros near
poles
this further, consider the following two transfer functions, which have the
same poles but different zeros:
H1(s) =
2
(s + 1)(s + 2)
=
2
s + 1 −
2
s + 2,
(3.78)
H2(s) =
2(s + 1.1)
1.1(s + 1)(s + 2)
= 2
1.1
 0.1
s + 1 + 0.9
s + 2

= 0.18
s + 1 + 1.64
s + 2.
(3.79)
They are normalized to have the same DC gain (that is, gain at s = 0). Notice
that the coefﬁcient of the (s + 1) term has been modiﬁed from 2 in H1(s)
to 0.18 in H2(s). This dramatic reduction is brought about by the zero at
s = −1.1 in H2(s), which almost cancels the pole at s = −1. If we put the
zero exactly at s = −1, this term will vanish completely. In general, a zero
near a pole reduces the amount of that term in the total response. From the
equation for the coefﬁcients in a partial-fraction expansion, Eq. (3.51),
C1 = (s −p1)F(s)|s=p1,
we can see that if F(s) has a zero near the pole at s = p1, the value of F(s)
will be small because the value of s is near the zero. Therefore, the coefﬁcient
C1, which reﬂects how much of that term appears in the response, will be
small.
Inordertotakeintoaccounthowzerosaffectthetransientresponsewhen
designing a control system, we consider transfer functions with two complex
12We assume that b(s) and a(s) have no common factors. If this is not so, it is possible for b(s)
and a(s) to be zero at the same location and for H(s) to not equal zero there. The implications
of this case will be discussed in Chapter 7, when we have a state-space description.

138
Chapter 3 Dynamic Response
poles and one zero. To expedite the plotting for a wide range of cases, we
write the transform in a form with normalized time and zero locations:
H(s) =
(s/αζωn) + 1
(s/ωn)2 + 2ζ(s/ωn) + 1.
(3.80)
The zero is located at s = −αζωn = −ασ. If α is large, the zero will be far
removed from the poles and the zero will have little effect on the response. If
α ∼= 1, the value of the zero will be close to that of the real part of the poles
and can be expected to have a substantial inﬂuence on the response. The
step-response curves for ζ = 0.5 and ζ = 0.707 for several values of α are
plotted in Figs. 3.27 and 3.28. We see that the major effect of the zero is to
increase the overshoot Mp and reduce rise time, tr, whereas it has very little
inﬂuence on the settling time. A plot of Mp versus α is given in Fig. 3.29.
The plot shows that the zero has very little effect on Mp if α > 3, but as
α decreases below 3, it has an increasing effect, especially when α = 1 or
less.
Figure 3.27 can be explained in terms of Laplace-transform analysis.
First we replace s/ωn with s:
H(s) =
s/αζ + 1
s2 + 2ζs + 1.
This has the effect of normalizing frequency in the transfer function and
normalizing time in the corresponding step responses; thus τ = ωnt. We
then rewrite the transfer function as the sum of two terms:
H(s) =
1
s2 + 2ζs + 1 + 1
αζ
s
s2 + 2ζs + 1.
(3.81)
Figure 3.27
Plots of the step
response of a
second-order system
with a zero (ζ = 0.5)
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
a = 1
2
4
100
Step response of H(s)
0
2
4
6
8
10
vnt

3.5 Effects of Zeros and Additional Poles
139
Figure 3.28
Plots of the step
response of a
second-order system
with a zero (ζ = 0.707)
1.8
1.6
1.4
1.2
1
0.8
0.6
Step response of H(s)
0.4
0.2
0
0
2
4
6
8
10
vn t
a = 1
2 4 100
Figure 3.29
Plot of overshoot Mp as
a function of normalized
zero location α. At
α = 1, the real part of
the zero equals the real
part of the poles
2.0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
Mp
0
2
4
6
8
10
a
z = 0.3
0.5
0.7
The ﬁrst term, which we shall call H0(s), is the original term (having no
ﬁnite zero), and the second term Hd(s), which is introduced by the zero, is
a product of a constant (1/αζ) times s times the original term. The Laplace
transform of df /dt is sF(s), so Hd(s) corresponds to a product of a constant
times the derivative of the original term, that is,
y(t) = y0(t) + yd(t) = y0(t) + 1
αζ
.y0(t).
The step responses of H0(s) denoted by y0(t) and Hd(s) denoted by yd(t)
are plotted in Fig. 3.30. Looking at these curves, we can see why the zero
increased the overshoot: The derivative has a large hump in the early part of
the curve, and adding this to the H0(s) response lifts up the total response of
H(s) to produce the overshoot. This analysis is also very informative for the
RHP or
nonminimum-phase zero
case when α < 0 and the zero is in the RHP where s > 0. (This is typically

140
Chapter 3 Dynamic Response
Figure 3.30
Second-order step
responses y(t) of the
transfer functions H(s),
H0(s), and Hd(s)
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
-0.2
y(t)
0
2
4
6
8
10
Time (sec)
y(t)
y0(t)
yd(t)
Figure 3.31
Step responses y(t) of a
second-order system
with a zero in the RHP:
a nonminimum-phase
system
1.5
1.0
0.5
0
- 0.5
- 1.0
- 1.5
0
2
4
6
8
10
Time (sec)
y(t)
y0(t)
yd(t)
y(t)
called an RHP zero and is sometimes referred to as a nonminimum-phase
zero, a topic to be discussed in more detail in Section 6.1.1.) In this case the
derivative term is subtracted rather than added. A typical case is sketched in
Fig. 3.31.
EXAMPLE 3.28
Effect of the Proximity of the Zero to the Pole Locations
on the Transient Response
Consider the second-order system with a ﬁnite zero and unity DC gain,
H(s) = 24
z
(s + z)
(s + 4)(s + 6).
Determine the effect of the zero location (s = −z) on the unit-step
response when z = {1, 2, 3, 4, 5, 6}.

3.5 Effects of Zeros and Additional Poles
141
Solution. The step response is the inverse Laplace transform of
H1(s) = H(s)1
s = 24
z
(s + z)
s(s + 4)(s + 6) = 24
z
s
s(s + 4)(s + 6)
+
24
s(s + 4)(s + 6)
and is the sum of the two parts,
y(t) = y1(t) + y2(t),
where
y1(t) = 12
z e−4t −12
z e−6t,
y2(t) = z
 t
0
y1(τ)dτ = −3e−4t + 2e−6t + 1,
and
y(t) = 1 +
12
z −3

e−4t +

2 −12
z

e−6t.
It is seen that if z = 4 or z = 6, one of the modes of the system is absent from
the output, and the response is ﬁrst order due to the pole-zero cancellations.
The step responses of the system is shown in Fig. 3.32 (z = 4, dashed, z = 6
dot dashed). It is seen that the effect of the zero is most pronounced in terms
of the additional overshoot for z = 1 (zero location closest to the origin).
The system also has overshoot for z = 2, 3. For z = 4 or z = 6 the responses
are ﬁrst order as expected. It is interesting that for z = 5, where the zero is
located between the two poles, there is no overshoot. This is generally the
Figure 3.32
Effect of zero on
transient response
z = 1
z = 2
z = 3
z = 6
0
0.5
1
1.5
2
2.5
0
0.5
1
1.5
2
2.5
Time (sec)
Unit-step response

142
Chapter 3 Dynamic Response
case because the zero effectively compensates for the effect of the second
pole, rendering the system as ﬁrst order at any given frequency.
EXAMPLE 3.29
Effect of the Proximity of the Complex Zeros
to the Lightly Damped Poles
Consider the third-order feedback system with a pair of lightly damped poles
and a pair of complex zeros with the transfer function,
H(s) =
(s + α)2 + β2
(s + 1)

(s + 0.1)2 + 1
.
Determine the effect of the complex zero locations (s = −α ± jβ) on
the unit-step response of the system for the three different zero locations
(α, β) = (0.1, 1.0), (α, β) = (0.25, 1.0), and (α, β) = (0.5, 1.0) as shown
in Fig. 3.33.
Solution.
We plot the three unit-step responses using Matlab as shown
in Fig. 3.34. The effect of the lightly damped modes are clearly seen as
oscillations in the step responses for the cases where (α, β) = (0.25, 1.0)
or (α, β) = (0.5, 1.0), that is, when the complex zeros are not close to the
locations of the lightly damped poles as shown in Fig. 3.33. On the other
hand, if the complex zeros cancel the lightly damped poles exactly as is the
case for (α, β) = (0.1, 1.0), the oscillations are completely eliminated in
the step response. In practice, the locations of the lightly damped poles are
not known precisely and exact cancellation is not really possible. However,
Figure 3.33
Locations of complex
zeros
s
−0.25
−0.5
−1.0
jw
j1
j1
0

3.5 Effects of Zeros and Additional Poles
143
Figure 3.34
Effect of complex zeros
on transient response
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Time (sec)
Unit-step response
a = 0.5
a = 0.25
a = 0.1
placing the complex zeros near the locations of the lightly damped poles
may provide sufﬁcient improvement in step response performance. We will
come back to this technique later in Chapters 5, 7, and 10 in the context of
dynamic compensator design.
EXAMPLE 3.30
Aircraft Response Using Matlab
The transfer function between the elevator and altitude of the Boeing 747
aircraft described in Section 10.3.2 can be approximated as
h(s)
δe(s) =
30(s −6)
s(s2 + 4s + 13).
1. Use Matlab to plot the altitude time history for a 1◦impulsive ele-
vator input. Explain the response, noting the physical reasons for the
nonminimum-phase nature of the response.
2. Examine the accuracy of the approximations for tr, ts, and Mp
[Eqs. (3.68) and (3.73) and Fig. 3.24].
Solution
1. The Matlab statements to create the impulse response for this case are
u = -1;
% u = delta e
sysG=u*30*(s-6)/
% deﬁne system by its transfer function
(sˆ3+4*sˆ2+13*s)
y=impulse(sysG);
% compute impulse response; y = h
plot(y);
% plot impulse response

144
Chapter 3 Dynamic Response
The result is the plot shown in Fig. 3.35. Notice how the altitude
drops initially and then rises to a new ﬁnal value. The ﬁnal value is
predicted by the Final Value Theorem:
h(∞) = s 30(s −6)(−1)
s(s2 + 4s + 13)

s=0
= 30(−6)(−1)
13
= +13.8.
The fact that the response has a ﬁnite ﬁnal value for an impulsive input is
Response of a
nonminimum-phase
system
due to the s-term in the denominator. This represents a pure integration
and the integral of an impulse function is a ﬁnite value. If the input had
been a step, the altitude would have continued to increase with time; in
other words the integral of a step function is a ramp function.
The initial drop is predicted by the RHP zero in the transfer
function. The negative elevator deﬂection is deﬁned to be upward by
convention (see Fig. 10.31). The upward deﬂection of the elevators
drives the tail down, which rotates the craft nose up and produces the
climb. The deﬂection at the initial instant causes a downward force
before the craft has rotated; therefore, the initial altitude response is
down. After rotation, the increased lift resulting from the increased
angle of attack of the wings causes the airplane to climb.
2. The rise time from Eq. (3.68) is
tr = 1.8
ωn
= 1.8
√
13
= 0.5 sec.
We ﬁnd the damping ratio ζ from the relation
2ζωn = 4 ⇒ζ =
2
√
13
= 0.55.
From Fig. 3.24 we ﬁnd the overshoot Mp to be 0.14. Because 2ζωn =
2σ = 4, [Eq. (3.73)] shows that
ts = 4.6
σ
= 4.6
2 = 2.3 sec.
Detailed examination of the time history h(t) from Matlab output
shows that tr ∼= 0.43 sec, Mp ∼= 0.14, and ts ∼= 2.6 sec, which are
Figure 3.35
Response of an
airplane's altitude to an
impulsive elevator input
0
Time (sec)
6
5
4
3
2
1
0
2
4
6
8
10
14
12
16
Altitude (ft)
-2

3.5 Effects of Zeros and Additional Poles
145
reasonably close to the estimates. The only signiﬁcant effect of the
nonminimum-phase zero was to cause the initial response to go in the
"wrong direction" and make the response somewhat sluggish.
In addition to studying the effects of zeros, it is useful to consider the
Effect of extra pole
effects of an extra pole on the standard second-order step response. In this
case, we take the transfer function to be
H(s) =
1
(s/αζωn + 1)[(s/ωn)2 + 2ζ(s/ωn) + 1].
(3.82)
Plots of the step response for this case are shown in Fig. 3.36 for ζ = 0.5
and several values of α. In this case the major effect is to increase the rise
time. A plot of the rise time versus α is shown in Fig. 3.37 for several values
of ζ.
Fromthisdiscussionwecandrawseveralconclusionsaboutthedynamic
response of a simple system as revealed by its pole-zero patterns:
Effects of Pole-Zero Patterns on Dynamic Response
1. For a second-order system with no ﬁnite zeros, the transient response
parameters are approximated as follows:
Rise time:
tr ∼= 1.8
ωn
,
Overshoot:
Mp ∼=
⎧
⎨
⎩
5%,
ζ = 0.7,
16%,
ζ = 0.5
(see Fig. 3.24),
35%,
ζ = 0.3,
Settling time:
ts ∼= 4.6
σ .
Figure 3.36
Step responses for
several third-order
systems with ζ = 0.5
1.2
1.0
0.8
0.6
0.4
0.2
0 0
2
4
6
8
10
vnt
y(t)
a = 1
2
5
100

146
Chapter 3 Dynamic Response
Figure 3.37
Normalized rise time for
several locations of an
additional pole
a
9
8
7
6
5
4
3
2
1
vntr
0
1
2
3
4
5
6
7
8
9
10
z = 1.0
0.7
0.5
2. A zero in the left half-plane (LHP) will increase the overshoot if the
zero is within a factor of 4 of the real part of the complex poles. A plot
is given in Fig. 3.29.
3. A zero in the RHP will depress the overshoot (and may cause the step
response to start out in the wrong direction).
4. An additional pole in the LHP will increase the rise time signiﬁcantly
if the extra pole is within a factor of 4 of the real part of the complex
poles. A plot is given in Fig. 3.37.
3.6
Stability
For nonlinear and time-varying systems, the study of stability is a complex
and often difﬁcult subject. In this section, we will consider only LTI systems
for which we have the following condition for stability:
An LTI system is said to be stable if all the roots of the transfer
function denominator polynomial have negative real parts (that is,
they are all in the left hand s-plane) and is unstable otherwise.
A system is stable if its initial conditions decay to zero and is unstable
if they diverge. As just stated, an LTI (constant parameter) system is stable
Stable system
if all the poles of the system are strictly inside the left half s-plane [that is,
all the poles have negative real parts (s = −σ + jω, σ > 0)]. If any pole
of the system is in the right half s-plane (that is, has a positive real part,
s = −σ + jω, σ < 0), then the system is unstable, as shown in Fig. 3.16.
Unstable system
With any simple pole on the jω axis (σ = 0), small initial conditions will
persist. For any other pole with σ = 0, oscillatory motion will persist.
Therefore, a system is stable if its transient response decays and unstable if

3.6 Stability
147
it does not. Figure 3.16 shows the time response of a system due to its pole
locations.
In later chapters, we will address more advanced notions of stability,
suchasNyquist'sfrequency-responsestabilitytest(Chapter6)andLyapunov
stability (Chapter 9).
3.6.1
Bounded Input-Bounded Output Stability
A system is said to have bounded input-bounded output (BIBO) stability
if every bounded input results in a bounded output (regardless of what goes
on inside the system). A test for this property is readily available when the
system response is given by convolution. If the system has input u(t), output
y(t), and impulse response h(t), then
y(t) =
 ∞
−∞
h(τ)u(t −τ)dτ.
(3.83)
If u(t) is bounded, then there is a constant M such that |u| ≤M < ∞, and
the output is bounded by
|y| =


hu dτ

≤

|h||u| dτ
≤M
 ∞
−∞
|h(τ)| dτ.
Thus the output will be bounded if
 ∞
−∞|h| dτ is bounded.
On the other hand, suppose the integral is not bounded and the bounded
input u(t −τ) = +1 if h(τ) > 0 and u(t −τ) = −1 if h(τ) < 0. In this
case,
y(t) =
 ∞
−∞
|h(τ)|dτ,
(3.84)
and the output is not bounded. We conclude that
Mathematical deﬁnition
of BIBO stability
The system with impulse response h(t) is BIBO-stable if and only
if the integral
 ∞
−∞
|h(τ)|dτ < ∞.
EXAMPLE 3.31
BIBO Stability for a Capacitor
As an example, determine the capacitor driven by a current source sketched
in Fig. 3.38. The capacitor voltage is the output and the current is the input.
Solution. The impulse response of this setup is h(t) = 1(t), the unit step.
Now for this response,

148
Chapter 3 Dynamic Response
Figure 3.38
Capacitor driven by
current source
u(t)
y(t)
+
-
C
 ∞
−∞
|h(τ)|dτ =
 ∞
0
dτ
(3.85)
is not bounded. The capacitor is not BIBO-stable. Notice that the transfer
function of the system is 1/s and has a pole on the imaginary axis. Physically
we can see that constant input current will cause the voltage to grow, and
thus the system response is neither bounded nor stable. In general, if an LTI
system has any pole13 on the imaginary axis or in the RHP, the response
will not be BIBO-stable; if every pole is inside the LHP, then the response
will be BIBO-stable. Thus for these systems, pole locations of the transfer
function can be used to check for stability.
An alternative to computing the integral of the impulse response or
even to locating the roots of the characteristic equation is given by Routh's
stability criterion, which we will discuss in Section 3.6.3.
3.6.2
Stability of LTI Systems
Consider the LTI system whose transfer function denominator polynomial
leads to the characteristic equation
sn + a1sn−1 + a2sn−2 + · · · + an = 0.
(3.86)
Assume that the roots {pi} of the characteristic equation are real or complex,
but are distinct. Note that Eq. (3.86) shows up as the denominator in the
transfer function for the system as follows before any cancellation of poles
by zeros is made:
T(s) = Y(s)
R(s) = b0sm + b1sm−1 + · · · + bm
sn + a1sn−1 + · · · + an
= K m
i=1(s −zi)
n
i=1(s −pi) ,
m ≤n.
(3.87)
The solution to the differential equation whose characteristic equation is
given by Eq. (3.86) may be written using partial-fraction expansion as
y(t) =
n

i=1
Kiepit,
(3.88)
where {pi} are the roots of Eq. (3.86) and {Ki} depend on the initial condi-
tions and zero locations. If a zero were to cancel a pole in the RHP for the
13Determination of BIBO stability by pole location.

3.6 Stability
149
transfer function, the corresponding Ki would equal zero in the output, but
the unstable transient would appear in some internal variable.
The system is stable if and only if (necessary and sufﬁcient condition)
every term in Eq. (3.88) goes to zero as t →∞:
epit →0
for all pi.
This will happen if all the poles of the system are strictly in the LHP, where
Re{pi} < 0.
(3.89)
If any poles are repeated, the response must be changed from that of
Eq. (3.88) by including a polynomial in t in place of Ki, but the conclu-
sion is the same. This is called internal stability. Therefore, the stability of
Internal stability occurs
when all poles are strictly
in the LHP.
a system can be determined by computing the location of the roots of the
characteristic equation and determining whether they are all in the LHP. If
the system has any poles in the RHP, it is unstable. Hence the jω axis is
the stability boundary between asymptotically stable and unstable response.
The jω axis is the stability
boundary.
If the system has nonrepeated jω axis poles, then it is said to be neutrally
stable. For example, a pole at the origin (an integrator) results in a nonde-
caying transient. A pair of complex jω axis poles results in an oscillating
response (with constant amplitude). If the system has repeated poles on
the jω axis, then it is unstable [as it results in te±jωit terms in Eq. (3.88)].
For example, a pair of poles at the origin (double integrator) results in an
unbounded response. Matlab software makes the computation of the poles,
and therefore determination of the stability of the system, relatively easy.
An alternative to locating the roots of the characteristic equation is given
by Routh's stability criterion, which we will discuss next.
3.6.3
Routh's Stability Criterion
There are several methods of obtaining information about the locations of
the roots of a polynomial without actually solving for the roots. These meth-
ods were developed in the 19th century and were especially useful before
the availability of Matlab software. They are still useful for determining the
ranges of coefﬁcients of polynomials for stability, especially when the coef-
ﬁcients are in symbolic (nonnumerical) form. Consider the characteristic
equation of an nth-order system14:
a(s) = sn + a1sn−1 + a2sn−2 + · · · + an−1s + an.
(3.90)
It is possible to make certain statements about the stability of the system
without actually solving for the roots of the polynomial. This is a classical
problem and several methods exist for the solution.
14Without loss of generality, we can assume the polynomial to be monic (that is, the coefﬁcient
of the highest power of s is 1).

150
Chapter 3 Dynamic Response
A necessary condition for stability of the system is that all of the roots
A necessary condition for
Routh stability
of Eq. (3.90) have negative real parts, which in turn requires that all the {ai}
be positive.15
A necessary (but not sufﬁcient) condition for stability is that all the
coefﬁcients of the characteristic polynomial be positive.
If any of the coefﬁcients are missing (are zero) or are negative, then
the system will have poles located outside the LHP. This condition can be
checked by inspection. Once the elementary necessary conditions have been
satisﬁed, we need a more powerful test. Equivalent tests were independently
proposed by Routh in 1874 and Hurwitz in 1895; we will discuss the former
version. Routh's formulation requires the computation of a triangular array
that is a function of the {ai}. He showed that a necessary and sufﬁcient
A necessary and sufﬁcient
condition for stability
condition for stability is that all of the elements in the ﬁrst column of this
array be positive.
A system is stable if and only if all the elements in the ﬁrst column
of the Routh array are positive.
To determine the Routh array, we ﬁrst arrange the coefﬁcients of the
characteristic polynomial in two rows, beginning with the ﬁrst and sec-
ond coefﬁcients and followed by the even-numbered and odd-numbered
Routh array
coefﬁcients:
sn
:
1
a2
a4
· · ·
sn−1 :
a1
a3
a5
. . .
We then add subsequent rows to complete the Routh array:
Row
n
sn:
1
a2
a4
· · ·
Row
n −1
sn−1:
a1
a3
a5
· · ·
Row
n −2
sn−2:
b1
b2
b3
· · ·
Row
n −3
sn−3:
c1
c2
c3
· · ·
...
...
...
...
...
Row
2
s2:
∗
∗
Row
1
s1:
∗
Row
0
s0:
∗
We compute the elements from the (n −2)th and (n −3)th rows as follows:
b1 = −
det
 1
a2
a1
a3

a1
= a1a2 −a3
a1
,
15This is easy to see if we construct the polynomial as a product of ﬁrst- and second-order
factors.

3.6 Stability
151
b2 = −
det
 1
a4
a1
a5

a1
= a1a4 −a5
a1
,
b3 = −
det
 1
a6
a1
a7

a1
= a1a6 −a7
a1
,
c1 = −
det
 a1
a3
b1
b2

b1
= b1a3 −a1b2
b1
,
c2 = −
det
 a1
a5
b1
b3

b1
= b1a5 −a1b3
b1
,
c3 = −
det
 a1
a7
b1
b4

b1
= b1a7 −a1b4
b1
.
Note that the elements of the (n−2)th row and the rows beneath it are formed
from the two previous rows using determinants, with the two elements in the
ﬁrst column and other elements from successive columns. Normally, there
are n + 1 elements in the ﬁrst column when the array terminates. If these
are all positive, then all the roots of the characteristic polynomial are in the
LHP. However, if the elements of the ﬁrst column are not all positive, then
the number of roots in the RHP equals the number of sign changes in the
column. A pattern of +, −, + is counted as two sign changes: one change
from + to −and another from −to +. For a simple proof of the Routh test,
the reader is referred to Ho et al. (1998).
EXAMPLE 3.32
Routh's Test
The polynomial
a(s) = s6 + 4s5 + 3s4 + 2s3 + s2 + 4s + 4
satisﬁes the necessary condition for stability since all the {ai} are positive
and nonzero. Determine whether any of the roots of the polynomial are in
the RHP.
Solution. The Routh array for this polynomial is
s6:
1
3
1
4
s5:
4
2
4
0
s4:
5
2 = 4 · 3 −1 · 2
4
0 = 4 · 1 −4 · 1
4
4 = 4 · 4 −1 · 0
4
s3:
2 =
5
2 · 2 −4 · 0
5
2
−12
5 =
5
2 · 4 −4 · 4
5
2
0

152
Chapter 3 Dynamic Response
s2:
3 =
2 · 0 −5
2

−12
5

2
4 =
2 · 4 −
5
2 · 0

2
s:
−76
15 =
3

−12
5

−8
3
0
s0:
4 =
−76
15 · 4 −0
−76
15
.
We conclude that the polynomial has RHP roots, since the elements of the
ﬁrst column are not all positive. In fact, there are two poles in the RHP
because there are two sign changes.16
Note that, in computing the Routh array, we can simplify the rest of the
calculations by multiplying or dividing a row by a positive constant. Also
note that the last two rows each have one nonzero element.
Routh's method is also useful in determining the range of parameters
for which a feedback system remains stable.
EXAMPLE 3.33
Stability versus Parameter Range
Consider the system shown in Fig. 3.39. The stability properties of the system
are a function of the proportional feedback gain K. Determine the range of
K over which the system is stable.
Solution. The characteristic equation for the system is given by
1 + K
s + 1
s(s −1)(s + 6) = 0,
or
s3 + 5s2 + (K −6)s + K = 0.
The corresponding Routh array is
s3 :
1
K −6
s2 :
5
K
s :
(4K −30)/5
s0 :
K.
Figure 3.39
A feedback system for
testing stability
©
 + 
-
r
K
s + 1
s(s + 1)(s + 6)
y
16The actual roots of the polynomial computed with the Matlab roots command are −3.2644,
0.7797 ± 0.7488j, −0.6046 ± 0.9935j, and −0.8858, which, of course, agree with our
conclusion.

3.6 Stability
153
Figure 3.40
Transient responses for
the system in Fig. 3.39
0
2
4
6
8
10
12
Time (sec)
3.0
2.5
2.0
1.5
1.0
0.5
0
-0.5
-1.0
y
K = 7.5
K = 13
K = 25
For the system to be stable, it is necessary that
4K −30
5
> 0
and
K > 0,
or
K > 7.5
and
K > 0.
Thus, Routh's method provides an analytical answer to the stability ques-
tion. Although any gain satisfying this inequality stabilizes the system, the
dynamic response could be quite different depending on the speciﬁc value
of K. Given a speciﬁc value of the gain, we may compute the closed-loop
poles by ﬁnding the roots of the characteristic polynomial. The characteristic
polynomial has the coefﬁcients represented by the row vector (in descending
powers of s)
denT = [1 5 K-6 K]
and we may compute the roots using the Matlab function
Computing roots by Matlab
roots(denT).
For K = 7.5 the roots are at −5 and ±1.22j, and the system is neutrally
stable. Note that Routh's method predicts the presence of poles on the jω
axis for K = 7.5. If we set K = 13, the closed-loop poles are at −4.06
and −0.47 ± 1.7j, and for K = 25, they are at −1.90 and −1.54 ± 3.27j.
In both these cases, the system is stable as predicted by Routh's method.
Fig. 3.40 shows the transient responses for the three gain values. To obtain
these transient responses, we compute the closed-loop transfer function
T(s) = Y(s)
R(s) =
K(s + 1)
s3 + 5s2 + (K −6)s + K ,
s=tf('s');
% deﬁne the Laplace variable
sysT=K*(s+1)/(sˆ3+5*sˆ2+(K-6)*s+K);
% deﬁne transfer function
step(sysT);
% compute the step response
produce a plot of the (unit) step response.

154
Chapter 3 Dynamic Response
Figure 3.41
System with
proportional-integral
(PI) control
R
©
 + 
-
K  + 
1
(s + 1)(s + 2)
Y
KI
s
EXAMPLE 3.34
Stability versus Two Parameter Ranges
Find the range of the controller gains (K, KI) so that the PI (proportional-
integral; see Chapter 4) feedback system in Fig. 3.41 is stable.
Solution. The characteristic equation of the closed-loop system is
1 +

K + KI
s

1
(s + 1)(s + 2) = 0,
which we may rewrite as
s3 + 3s2 + (2 + K)s + KI = 0.
The corresponding Routh array is
s3 :
1
2 + K
s2 :
3
KI
s :
(6 + 3K −KI)/3
s0 :
KI.
For internal stability we must have
KI > 0
and
K > 1
3KI −2.
The allowable region can be plotted in Matlab using the ensuing commands
fh=@(KI,K) 6+3*K−KI;
ezplot(fh)
hold on;
f=@(KI, K) KI;
ezplot(f);
and is the shaded area in the (KI, K) plane shown in Fig. 3.42, which repre-
sents an analytical solution to the stability question. This example illustrates
the real value of Routh's approach and why it is superior to the numeri-
cal approaches. It would have been more difﬁcult to arrive at these bounds
on the gains using numerical search techniques. The closed-loop transfer
function is
T(s) = Y(s)
R(s) =
Ks + KI
s3 + 3s2 + (2 + K)s + KI
.
As in Example 3.33, we may compute the closed-loop poles for different
values of the dynamic compensator gains by using the Matlab function on
Matlab roots
the denominator polynomial
denT = [1 3 2+K KI]; % form denominator
Similarly, we may ﬁnd the zero by ﬁnding the root of the numerator
polynomial

3.6 Stability
155
Figure 3.42
Allowable region for
stability
KI
K
0
6
-2
-1
Figure 3.43
Transient response for
the system in Fig. 3.41
0
1
2
3
4
5
6
7
8
9
10
Time (sec)
1.2
1.0
0.8
0.6
0.4
0.2
0
y
K = 1, KI = 0
K = 1, KI = 1
K = 10, KI = 5
numT = [K KI]; % form numerator
The closed-loop zero of the system is at −KI/K. Fig. 3.43 shows the
transient response for three sets of feedback gains. For K = 1 and KI = 0,
the closed-loop poles are at 0 and −1.5 ± 0.86j, and there is a zero at the
origin. For K = KI = 1, the poles and zeros are all at −1. For K = 10 and
KI = 5, the closed-loop poles are at −0.46 and −1.26 ± 3.3j and the zero is
at −0.5. The step responses were obtained using the Matlab function
sysT=tf(numT,denT);
% deﬁne system by its numerator and denominator
step(sysT)
% compute step response
There is a large steady-state error in this case when KI = 0. (See
Chapter 4.)
If the ﬁrst term in one of the rows is zero or if an entire row is zero,
then the standard Routh array cannot be formed, so we have to use one of
the special techniques described next.

156
Chapter 3 Dynamic Response
Special Cases
If only the ﬁrst element in one of the rows of the Routh array is zero or
an entire row of the Routh array is zero, special modiﬁcations to the Routh
array computations are necessary. For details, see Appendix W.3.6.3 on the
web available at www.fpe7e.com.
The Routh-Hurwitz result assumes that the characteristic polynomial
coefﬁcients are known precisely. It is well known that the roots of a polyno-
mial can be very sensitive to even slight perturbations in the polynomial coef-
ﬁcients. If the range of variation on each one of the polynomial coefﬁcients
is known, then a remarkable result called the Kharitonov Theorem (1978)
allows one to test just four so-called Kharitonov polynomials, using the
Routh test, to see if the polynomial coefﬁcient variations result in instability.
3.7
Obtaining Models from Experimental Data:
System Identiﬁcation
There are several reasons for using experimental data to obtain a model of
△
the dynamic system to be controlled. The available information and related
techniques in this area are under the banner of system identiﬁcation. See
Appendix W3.7 available on the web at www.fpe7e.com.
3.8
Amplitude and Time Scaling
In some cases in practice due to extreme variations in magnitudes of real data
△
amplitude scaling is necessary. See Appendix W3.8 on the web available at
www.fpe7e.com.
3.9
Historical Perspective
Oliver Heaviside (1850-1925) was an eccentric English electrical engineer,
mathematician, and physicist. He was self-taught and left school at the
age of 16 to become a telegraph operator. He worked mostly outside the
scientiﬁc community that was hostile to him. He reformulated Maxwell's
equations in the form that is used today. He also laid down the foundations
of telecommunication and hypothesized the existence of the ionosphere. He
developed the symbolic procedure known as Heaviside's operational calcu-
lus for solving differential equations. The Heaviside calculus was widely
popular among electrical engineers in the 1920s and 1930s. This was later
shown to be equivalent to the more rigorous Laplace transform named
after the French mathematician Pierre-Simon Laplace (1749-1827) who had
worked on operational calculus earlier.
Laplace was also an astronomer and a mathematician who is some-
times referred to as the "The Newton of France." He studied the origin and
dynamical stability of the solar system completing Newton's work in his
ﬁve-volume Méchanique céleste (Celestial Mechanics). Laplace invented
the general concept of potential as in a gravitational or electric ﬁeld and

Summary
157
described by Laplace's equation. Laplace had a brief political career as
Napoleon's Interior Minister. During a famous exchange with Napoleon
who asked Laplace why he had not mentioned God in Méchanique céleste,
Laplace is said to have replied that "Sir, there was no need for that hypothe-
sis." He was an opportunist and changed sides as the political winds shifted.
Laplace's operational property transforms a differential equation into an
algebraic operation that is much easier to manipulate in engineering appli-
cations. It is also applicable to solutions of partial differential equations,
the original problem that Laplace was concerned with while developing the
transform. Laplace formulated the Laplace's equation with applications to
electromagnetic theory, ﬂuid dynamics, and astronomy. Laplace also made
fundamental contributions to probability theory.
Laplace and Fourier transforms are intimately related (seeAppendixA).
The Fourier series and the Fourier transform, developed in that order, provide
methods for representing signals in terms of exponential functions. Fourier
series are used to represent a periodic signal with discrete spectra in terms of
a series. Fourier transforms are used to represent a non-periodic signal with
continuous spectra in terms of an integral. The Fourier transform is named
after the French mathematician Jean Batiste Joseph Fourier (1768-1830)
who used Fourier series to solve the heat conduction equation expressed in
terms of Fourier series. Laplace and Fourier were contemporaries and knew
each other very well. In fact, Laplace was one of Fourier's teachers. Fourier
accompanied Napoleon on his Egyptian expedition in 1798 as a science
advisor and is also credited with the discovery of the greenhouse effect.
Transform methods provide a unifying method in applications to solving
many engineering problems. Linear transforms such as the Laplace trans-
form and Fourier transform are useful for studying linear systems. While
Fourier transforms are useful to study the steady-state behavior, Laplace
transforms are used for studying the transient and closed-loop behavior of
dynamic systems. The book by Gardner and Barnes in 1942 was inﬂuential
in popularizing the Laplace transform in the United States.
SUMMARY
•
The Laplace transform is the primary tool used to determine the behav-
ior of linear systems. The Laplace transform of a time function (t) is
given by
L[ f (t)] = F(s) =
 ∞
0−f (t)e−st dt.
(3.91)
•
This relationship leads to the key property of Laplace transforms,
namely,
L[ ˙f (t)] = sF(s) −f (0−).
(3.92)
•
This property allows us to ﬁnd the transfer function of a linear
ODE. Given the transfer function G(s) of a system and the input u(t),
with transform U(s), the system output transform is Y(s) = G(s)U(s).

158
Chapter 3 Dynamic Response
•
Normally, inverse transforms are found by referring to tables such as
Table A.2 in Appendix A or by computer. Properties of Laplace trans-
forms and their inverses are summarized in Table A.1 in Appendix A.
•
The Final Value Theorem is useful in ﬁnding steady-state errors for
stable systems: If all the poles of s Y(s) are in the LHP, then
lim
t→∞y(t) = lim
s→0 s Y(s).
(3.93)
•
Block diagrams are a convenient way to show the relationships between
the components of a system. They can usually be simpliﬁed using the
relations in Fig. 3.10 and Eq. (3.58); that is, the transfer function of the
block diagram
G1(s)
Y1(s)
G2(s)
R1(s)
©
+
-
is equivalent to
Y1(s) =
G1(s)
1 + G1(s)G2(s)R1(s).
(3.94)
•
The locations of poles in the s-plane determine the character of the
response, as shown in Fig. 3.16.
•
The location of a pole in the s-plane is deﬁned by the parameters shown
in Fig. 3.18. These parameters are related to the time-domain quantities
of rise time tr, settling time ts, and overshoot Mp, which are deﬁned
in Fig. 3.23. The correspondences between them, for a second-order
system with no zeros, are given by
tr ∼= 1.8
ωn
,
(3.95)
Mp = e−πζ/√
1−ζ 2,
(3.96)
ts = 4.6
ζωn
.
(3.97)
•
When a zero in the LHP is present, the overshoot increases. This effect
is summarized in Figs. 3.27, 3.28 and 3.29.
•
When a real RHP is present, the step response starts off in the "wrong
direction," and the response is more sluggish. This effect is summarized
in Fig. 3.31, and is called the nonminimum phase behavior.
•
When an additional stable pole is present, the system response is more
sluggish. This effect is summarized in Figs. 3.36 and 3.37.
•
For a stable system, all the closed-loop poles must be in the LHP.
•
A system is stable if and only if all the elements in the ﬁrst column of
the Routh array are positive. To determine the Routh array, refer to the
formulas in Section 3.6.3.

Problems
159
REVIEW QUESTIONS
3.1
What is the deﬁnition of "transfer function"?
3.2
What are the properties of systems whose responses can be described by
transfer functions?
3.3
What is the Laplace transform of f (t −λ)1(t −λ) if the transform of f (t) is
F(s)?
3.4
State the Final Value Theorem (FVT).
3.5
What is the most common use of the FVT in control?
3.6
Given a second-order transfer function with damping ratio ζ and natural fre-
quency ωn, what is the estimate of the step response rise time? What is the
estimate of the percent overshoot in the step response? What is the estimate
of the settling time?
3.7
What is the major effect of a zero in the left half-plane on the second-order
step response?
3.8
What is the most noticeable effect of a zero in the right half-plane on the step
response of the second-order system?
3.9
What is the main effect of an extra real pole on the second-order step response?
3.10
Why is stability an important consideration in control system design?
3.11
What is the main use of Routh's criterion?
3.12
Under what conditions might it be important to know how to estimate a transfer
function from experimental data?
PROBLEMS
Problems for Section 3.1: Review of Laplace Transforms
3.1
Show that, in a partial-fraction expansion, complex conjugate poles have
coefﬁcients that are also complex conjugates. (The result of this relationship
is that whenever complex conjugate pairs of poles are present, only one of the
coefﬁcients needs to be computed.)
3.2
Find the Laplace transform of the following time functions:
(a) f (t) = 1 + 7t
(b) f (t) = 4 + 7t + t2 + δ(t), where δ(t) is the unit impulse function
(c) f (t) = e−t + 2e−2t + te−3t
(d) f (t) = (t + 1)2
(e) f (t) = sinh t
3.3
Find the Laplace transform of the following time functions:
(a) f (t) = 4 cos 6t
(b) f (t) = sin 3t + 2 cos 3t + e−t sin 3t
(c) f (t) = t2 + e−2t sin 3t
3.4
Find the Laplace transform of the following time functions:
(a) f (t) = t sin t
(b) f (t) = t cos 3t

160
Chapter 3 Dynamic Response
(c) f (t) = te−t + 2t cos t
(d) f (t) = t sin 3t −2t cos t
(e) f (t) = 1(t) + 2t cos 2t
3.5
Find the Laplace transform of the following time functions (* denotes
convolution):
(a) f (t) = sin t sin 7t
(b) f (t) = sin2 t + 7 cos2 t
(c) f (t) = (sin t)/t
(d) f (t) = sin t ∗sin t
(e) f (t) =
t
0
cos(t −τ) sin τdτ
3.6
Given that the Laplace transform of f (t) is F(s), ﬁnd the Laplace transform
of the following:
(a) g(t) = f (t) cos t
(b) g(t) =
t
0
t1
0
f (τ)dτdt1
3.7
Find the time function corresponding to each of the following Laplace
transforms using partial-fraction expansions:
(a) F(s) =
1
s(s+1)
(b) F(s) =
5
s(s+1)(s+5)
(c) F(s) =
3s+2
s2+2s+10
(d) F(s) =
3s2+6s+6
(s+1)(s2+6s+10)
(e) F(s) =
1
s2+16
(f) F(s) =
2(s+3)
(s+1)(s2+16)
(g) F(s) = s+1
s2
(h) F(s) = 1
s6
(i) F(s) =
4
s4+4
(j) F(s) = e−s
s2
3.8
Find the time function corresponding to each of the following Laplace
transforms:
(a) F(s) =
1
s(s+1)2
(b) F(s) = s2+s+1
s3−1
(c) F(s) = 2(s2+s+1)
s(s+1)2
(d) F(s) = s3+s+2
s4−4
(e) F(s) = 2(s+2)(s+5)2
(s+1)(s2+4)2
(f) F(s) =
s2−1
(s2+1)2
(g) F(s) = tan−1
1
s


Problems
161
3.9
Solve the following ODEs using Laplace transforms:
(a) ¨y(t) + ˙y(t) + 3y(t) = 0; y(0) = 1, ˙y(0) = 2
(b) ¨y(t) −2˙y(t) + 4y(t) = 0; y(0) = 1, ˙y(0) = 2
(c) ¨y(t) + ˙y(t) = sin t; y(0) = 1, ˙y(0) = 2
(d) ¨y(t) + 3y(t) = sin t; y(0) = 1, ˙y(0) = 2
(e) ¨y(t) + 2˙y(t) = et; y(0) = 1, ˙y(0) = 2
(f) ¨y(t) + y(t) = t; y(0) = 1, ˙y(0) = −1
3.10
Using the convolution integral, ﬁnd the step response of the system whose
impulse response is given below and shown in Fig. 3.44:
h(t) =
 te−t
t ≥0,
0
t < 0.
Figure 3.44
Impulse response for
Problem 3.10
0
2
4
6
8
10
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Time (sec)
h(t)
3.11
Using the convolution integral, ﬁnd the step response of the system whose
impulse response is given below and shown in Fig. 3.45:
h(t) =
 1,
0 ≤t ≤2,
0,
t < 0 and t > 2.
Figure 3.45
Impulse response for
Problem 3.11
-1
-0.5
0
0.5
1
1.5
2
2.5
3
0
0.5
1
1.5
h(t)
Time (sec)
3.12
Consider the standard second-order system
G(s) =
ω2n
s2 + 2ζωns + ω2n
.

162
Chapter 3 Dynamic Response
(a) Write the Laplace transform of the signal in Fig. 3.46.
(b) What is the transform of the output if this signal is applied to G(s)?
(c) Find the output of the system for the input shown in Fig. 3.46.
Figure 3.46
Plot of input signal for
Problem 3.12
u(t)
1
1
2
3
Time (sec)
3.13
A rotating load is connected to a ﬁeld-controlled DC motor with negligible
ﬁeld inductance. A test results in the output load reaching a speed of 1 rad/sec
within 1/2 sec when a constant input of 100V is applied to the motor terminals.
The output steady-state speed from the same test is found to be 2 rad/sec.
Determine the transfer function (s)
Vf (s) of the motor.
Figure 3.47
Tape drive schematic
x1
x2
F
Vacuum
column
r1
r2
Head
v1
v2
Take-up
capstan
ia = u
J1, B1
No friction
B
K
Idler
wheel
J2, B2
DC motor
3.14
A simpliﬁed sketch of a computer tape drive is given in Fig. 3.47.
(a) Write the equations of motion in terms of the parameters listed below.
K and B represent the spring constant and the damping of tape stretch,
respectively, and ω1 and ω2 are angular velocities. A positive current
applied to the DC motor will provide a torque on the capstan in the clock-
wise direction as shown by the arrow. Find the value of current that just
cancels the force, F, then eliminate the constant current and its balancing

Problems
163
force, F, from your equations. Assume positive angular velocities of the
two wheels are in the directions shown by the arrows.
J1 = 5 × 10−5 kg·m2, motor and capstan inertia,
B1 = 1 × 10−2 N·m·sec, motor damping,
r1 = 2 × 10−2 m,
Kt = 3 × 10−2 N·m/A, motor-torque constant,
K = 2 × 104 N/m,
B = 20 N/m·sec,
r2 = 2 × 10−2 m,
J2 = 2 × 10−5 kg·m2,
B2 = 2 × 10−2 N·m·sec, viscous damping, idler,
F = 6 N, constant force,
˙x1 = tape velocity m/sec (variable to be controlled).
(b) Find the transfer function from motor current to the tape position.
(c) Find the poles and zeros of the transfer function in part (b).
(d) Use Matlab to ﬁnd the response of x1 to a step in ia.
3.15
For the system in Fig. 2.54, compute the transfer function from the motor
voltage to position θ2.
3.16
Compute the transfer function for the two-tank system in Fig. 2.58 with holes
at A and C.
3.17
For a second-order system with transfer function
G(s) =
2
s2 + s −2,
determine the following:
(a) The DC gain;
(b) The ﬁnal value to a unit-step input.
3.18
Consider the continuous rolling mill depicted in Fig. 3.48. Suppose that the
motion of the adjustable roller has a damping coefﬁcient b, and that the force
exerted by the rolled material on the adjustable roller is proportional to the
material's change in thickness: Fs = c(T −x). Suppose further that the DC
motor has a torque constant Kt and a back emf constant Ke, and that the
rack-and-pinion has effective radius of R.
(a) What are the inputs to this system? The output?
(b) Without neglecting the effects of gravity on the adjustable roller, draw a
block diagram of the system that explicitly shows the following quantities:
Vs(s), I0(s), F(s) (the force the motor exerts on the adjustable roller),
and X(s).
(c) Simplify your block diagram as much as possible while still identifying
each output and input separately.

164
Chapter 3 Dynamic Response
+
-
io(t)
-
+
ya(t)
ys(t)
1 : N
Gear ratio
Rack and
pinion
Motion of
material
out of rollers
Thickness T
Thickness x
Vertically
adjustable
roller
Fixed
roller
La
Ra
Fm
Figure 3.48
Continuous rolling mill
Problems for Section 3.2: System Modeling Diagrams
3.19
Consider the block diagram shown in Fig. 3.49. Note that ai and bi are con-
stants. Compute the transfer function for this system. This special structure is
called the "control canonical form" and will be discussed further in Chapter 7.
Figure 3.49
Block diagram for
Problem 3.19
©
+
+
+
©
+
+
+ +
U(s)
-a1
X1
b1
-a2
-a3
b2
b3
Y(s)
1s
1s
X2
X3
1s

Problems
165
3.20
Find the transfer functions for the block diagrams in Fig. 3.50.
Figure 3.50
Block diagrams for
Problem 3.20
G1


G2

Y
R
(a)
G1


G7

Y
R
(b)
G3
G2
G4


G6
G5
G1
G1




G6


Y
R
G7
G2
G3





G4
G5
(c)






3.21
Find the transfer functions for the block diagrams in Fig. 3.51, using the ideas
of block-diagram simpliﬁcation. The special structure in Fig. 3.51(b) is called
the "observer canonical form" and will be discussed in Chapter 7.
3.22
Use block-diagram algebra to determine the transfer function between R(s)
and Y(s) in Fig. 3.52.
3.23
Find the transfer functions for the block diagrams in Fig. 3.51, using Mason's
△
rule.
3.24
Use Mason's rule to determine the transfer function between R(s) and Y(s) in
△
Fig. 3.52.
Problems for Section 3.3: Effect of Pole Locations
3.25
For the electric circuit shown in Fig. 3.53, ﬁnd the following:
(a) The time-domain equation relating i(t) and v1(t);
(b) The time-domain equation relating i(t) and v2(t);
(c) Assuming all initial conditions are zero, the transfer function V2(s)
V1(s) and
the damping ratio ζ and undamped natural frequency ωn of the system;
(d) The values of R that will result in v2(t) having an overshoot of no more
than 25%, assuming v1(t) is a unit step, L = 10 mH, and C = 4 μF.

166
Chapter 3 Dynamic Response
©
+
-
G1
R
G2
©
+
+
©
+
+
H2
G3
H3
©
+
+
Y
(a)
©
+
-
b3
a3
1s
©
+
-
+
+
b2
a2
1s
©
+
-
b1
a1
1s
R
Y
(b)
©
+
-
- -
a1
a2
a3
1s
b3
©
+
+
+
b2
1s
©
+
b1
1s
Y
R
©
+
-
R(s)
©
+
-
©
+
+
Y(s)
D(s)
B(s)
H(s)
A(s)
G(s)
(c)
(d)
Figure 3.51
Block diagrams for Problem 3.21
3.26
For the unity feedback system shown in Fig. 3.54, specify the gain K of the
proportional controller so that the output y(t) has an overshoot of no more
than 10% in response to a unit step.
3.27
For the unity feedback system shown in Fig. 3.55, specify the gain and pole
location of the compensator so that the overall closed-loop response to a unit-
step input has an overshoot of no more than 25%, and a 1% settling time of
no more than 0.1 sec. Verify your design using Matlab.

Problems
167
Figure 3.52
Block diagram for
Problem 3.22
©
-
-
+
©
+
-
©
+
+
Y(s)
R(s)
G2
G3
G1
©
+
-
G4
H2
G5
H4
H3
G6
Figure 3.53
Circuit for Problem 3.25
L
R
C
y2(t)
y1(t)
i(t)
+
-
+
-
Figure 3.54
Unity feedback system
for Problem 3.26
K
©
+
-
s(s + 2)
1
R(s)
Y(s)
Figure 3.55
Unity feedback system
for Problem 3.27
©
+
-
s + 25
100
R(s)
Y(s)
s + a
K
Compensator
Plant
Problems for Section 3.4: Time-Domain Speciﬁcation
3.28
Suppose you desire the peak time of a given second-order system to be less
than t′p. Draw the region in the s-plane that corresponds to values of the poles
that meet the speciﬁcation tp < t′p.
3.29
A certain servomechanism system has dynamics dominated by a pair of com-
plex poles and no ﬁnite zeros. The time-domain speciﬁcations on the rise time
(tr), percent overshoot (Mp), and settling time (ts) are given by
tr ≤0.6 sec ,
Mp ≤17%,
ts ≤9.2 sec .
(a) Sketch the region in the s-plane where the poles could be placed so that
the system will meet all three speciﬁcations.
(b) Indicate on your sketch the speciﬁc locations (denoted by ×) that will
have the smallest rise time and also meet the settling time speciﬁcation
exactly.

168
Chapter 3 Dynamic Response
3.30
A feedback system has the following response speciﬁcations:
•
Percent overshoot Mp ≤16%
•
Settling time ts ≤6.9 sec
•
Rise time tr ≤1.8 sec
(a) Sketch the region of acceptable closed-loop poles in the s-plane for the
system, assuming the transfer function can be approximated as simple
second order.
(b) What is the expected overshoot if the rise time and settling time
speciﬁcations are met exactly?
3.31
Suppose you are to design a unity feedback controller for a ﬁrst-order plant
depicted in Fig. 3.56. (As you will learn in Chapter 4, the conﬁguration shown
is referred to as a proportional-integral controller.) You are to design the
controller so that the closed-loop poles lie within the shaded regions shown
in Fig. 3.57.
Figure 3.56
Unity feedback system
for Problem 3.31
K
©
+
-
s
KI
R
Y
©
+
+
s + a
Ka
e(t)
Figure 3.57
Desired closed-loop
pole locations for
Problem 3.31
Re(s)
Im(s)
-2
-4
2
4
u1
u2
-2
(a) What values of ωn and ζ correspond to the shaded regions in Fig. 3.57?
(A simple estimate from the ﬁgure is sufﬁcient.)
(b) Let Kα = α = 2. Find values for K and KI so that the poles of the
closed-loop system lie within the shaded regions.
(c) Prove that no matter what the values of Kα and α are, the controller
provides enough ﬂexibility to place the poles anywhere in the complex
(left-half) plane.
3.32
The open-loop transfer function of a unity feedback system is
G(s) =
K
s(s + 2).
The desired system response to a step input is speciﬁed as peak time tp = 1 sec
and overshoot Mp = 5%.

Problems
169
(a) Determine whether both speciﬁcations can be met simultaneously by
selecting the right value of K.
(b) Sketch the associated region in the s-plane where both speciﬁcations are
met, and indicate what root locations are possible for some likely values
of K.
(c) Relax the speciﬁcations in part (a) by the same factor and pick a suitable
value for K, and use Matlab to verify that the new speciﬁcations are
satisﬁed.
3.33
A simple mechanical system is shown in Fig. 3.58(a). The parameters are
k = spring constant, b = viscous friction constant, m = mass. A step of 2 N
force is applied as F = 2 × 1(t) and the resulting step response is shown in
Fig. 3.58(b). What are the values of the system parameters k, b, and m?
3.34
A mechanical system is shown in Fig. 3.59. The mass M = 20 kg and the
control force, u, is proportional to the reference input, u = Ar.
(a) Derive the transfer function from R to Y.
Figure 3.58
(a) Mechanical system
for Problem 3.33;
(b) step response for
Problem 3.33
x
No friction
F
b
k
(a)
0
1
2
3
4
5
6
7
0
0.02
0.04
0.06
0.08
0.1
0.12
Time (sec)
x(t)
(b)

170
Chapter 3 Dynamic Response
(b) Determine the values of the parameters k, b, A such that the system has a
rise time of tr = 1 sec and overshoot of Mp = 16%, and zero-steady-state
error to a step in r.
Figure 3.59
Simple mechanical
system for Problem 3.34
k
b
y
u
M
3.35
The equations of motion for the DC motor shown in Fig. 2.32 were given in
Eqs. (2.62-2.63) as
Jm ¨θm +

b + KtKe
Ra

˙θm = Kt
Ra
va.
Assume that
Jm = 0.01 kg·m2,
b = 0.001 N·m·sec,
Ke = 0.02 V·sec,
Kt = 0.02 N·m/A,
Ra = 10 .
(a) Find the transfer function between the applied voltage va and the motor
speed ˙θm.
(b) What is the steady-state speed of the motor after a voltage va = 10 V has
been applied?
(c) Find the transfer function between the applied voltage va and the shaft
angle θm.
(d) Suppose feedback is added to the system in part (c) so that it becomes a
position servo device such that the applied voltage is given by
va = K(θr −θm)
where K is the feedback gain. Find the transfer function between θr
and θm.
(e) What is the maximum value of K that can be used if an overshoot
M < 20% is desired?
(f) What values of K will provide a rise time of less than 4 sec? (Ignore the
Mp constraint.)
(g) Use Matlab to plot the step response of the position servo system for
values of the gain K = 0.5, 1, and 2. Find the overshoot and rise time for
each of the three step responses by examining your plots. Are the plots
consistent with your calculations in parts (e) and (f)?
3.36
You wish to control the elevation of the satellite-tracking antenna shown
in Fig. 3.60 and Fig. 3.61. The antenna and drive parts have a moment of

Problems
171
inertia J and a damping B; these arise to some extent from bearing and aero-
dynamic friction, but mostly from the back emf of the DC drive motor. The
equations of motion are
J ¨θ + B ˙θ = Tc,
where Tc is the torque from the drive motor. Assume that
J = 600,000 kg·m2
B = 20,000 N·m·sec.
(a) Find the transfer function between the applied torque Tc and the antenna
angle θ.
(b) Suppose the applied torque is computed so that θ tracks a reference
command θr according to the feedback law
Tc = K(θr −θ),
where K is the feedback gain. Find the transfer function between θr and θ.
Figure 3.60
Satellite-tracking
antenna
Source: Courtesy Space
Systems/Loral
Figure 3.61
Schematic of antenna
for Problem 3.36
u

172
Chapter 3 Dynamic Response
(c) What is the maximum value of K that can be used if you wish to have an
overshoot Mp < 10%?
(d) What values of K will provide a rise time of less than 80 sec? (Ignore the
Mp constraint.)
(e) Use Matlab to plot the step response of the antenna system for K =
200, 400, 1000, and 2000. Find the overshoot and rise time of the four
step responses by examining your plots. Do the plots to conﬁrm your
calculations in parts (c) and (d)?
3.37
Show that the second-order system
¨y + 2ζωn˙y + ω2
ny = 0,
y(0) = yo,
˙y(0) = 0,
has the response
y(t) = yo
e−σt

1 −ζ 2 sin(ωdt + cos−1 ζ).
Prove that, for the underdamped case (ζ < 1), the response oscillations decay
at a predictable rate (see Fig. 3.62) called the logarithmic decrement
δ = ln yo
y1
= ln eστd = στd =
2πζ

1 −ζ 2
= ln y1
y1
∼= ln yi
yi
,
where
τd = 2π
ωd
=
2π
ωn

1 −ζ 2 ,
is the damped natural period of vibration. The damping coefﬁcient in terms
of the logarithmic decrement is then
ζ =
δ

4π2 + δ2 .
Figure 3.62
Deﬁnition of
logarithmic decrement
t
¢y1
¢y2
td
y0
y1
y2

Problems
173
Problems for Section 3.5: Effects of Zeros and Additional Poles
3.38
In aircraft control systems, an ideal pitch response (qo) versus a pitch
command (qc) is described by the transfer function
Qo(s)
Qc(s) =
τω2n(s + 1/τ)
s2 + 2ζωns + ω2n
.
The actual aircraft response is more complicated than this ideal transfer func-
tion; nevertheless, the ideal model is used as a guide for autopilot design.
Assume that tr is the desired rise time and that
ωn = 1.789
tr
,
1
τ = 1.6
tr
,
ζ = 0.89.
Show that this ideal response possesses a fast settling time and minimal
overshoot by plotting the step response for tr = 0.8, 1.0, 1.2, and 1.5 sec.
3.39
Approximate each of the transfer functions given below with a second-order
transfer function.
G1(s) =
(0.5s + 1)(s + 1)
(0.55s + 1)(0.95s + 1)(s2 + s + 1),
G2(s) =
(0.5s + 1)(s + 1)
(0.55s + 1)(0.95s + 1)(s2 + 0.2s + 1),
G3(s) =
(−0.5s + 1)(s + 1)
(0.95s + 1)(0.05s + 1)(s2 + s + 1),
G4(s) =
(0.5s + 1)(s + 1)
(0.55s + 1)(0.05s + 1)(s2 + s + 1),
G5(s) =
(0.5s + 1)(0.02s + 1)
(0.55s + 1)(0.95s + 1)(s2 + s + 1).
3.40
A system has the closed-loop transfer function
Y(s)
R(s) = T(s) =
2700(s + 25)
(s + 1)(s + 45)(s + 60)(s2 + 8s + 25),
where R is a step of size 7.
(a) Give an expression for the form of the output time history as a sum of
terms showing the shape of each component of the response.
(b) Give an estimate of the settling time of this step response.
3.41
Consider the system shown in Fig. 3.63, where
G(s) =
1
s(s + 3)
and
Dc(s) = K(s + z)
s + p
.

174
Chapter 3 Dynamic Response
Figure 3.63
Unity feedback system
for Problem 3.41
Dc(s)
R(s)
Y(s)
©
-
+
G(s)
Find K, z, and p so that the closed-loop system has a 10% overshoot to a step
input and a settling time of 1.5 sec (1% criterion).
3.42
Sketch the step response of a system with the transfer function
△
G(s) =
s/2 + 1
(s/40 + 1)[(s/4)2 + s/4 + 1].
Justify your answer on the basis of the locations of the poles and zeros. (Do
not ﬁnd the inverse Laplace transform.) Then compare your answer with the
step response computed using Matlab.
3.43
A closed-loop transfer function is given below:
H(s) =
 s
10
2 + 0.1
 s
10

+ 1
  s
2 + 1
  s
0.1 + 1

 s
4
2 +
 s
4

+ 1
  s
10
2 + 0.09
 s
10

+ 1
 
s
0.02 + 1
.
Estimate the percent overshoot, Mp, and the transient settling time, ts, for this
system.
3.44
A transfer function, G(s), is given below:
G(s) =
 s
100
2 + 0.01
 s
100

+ 1

 s
10
2 +
 s
10

+ 1
 
s
5 + 1
  s
100
2 + 0.1
 s
100

+ 1
.
If a step input is applied to this plant, what do you estimate the rise-time,
settling time, and overshoot to be? Give a brief statement of your reasons in
each case.
3.45
Three closed-loop transfer functions are given below:
Y(s)
R(s) = T1(s) =
2
(s2 + 2s + 2),
Y(s)
R(s) = T2(s) =
2(s + 3)
2(s2 + 2s + 2),
Y(s)
R(s) = T3(s) =
6
(s + 3)(s2 + 2s + 2).
In each case, provide estimates of the rise time, settling time, and percent
overshoot to a unit-step input in r.
3.46
Five transfer functions are given below:
(a) Which transfer function(s) will meet an overshoot speciﬁcation of
Mp ≤5%?
(b) Which transfer function(s) will meet a rise time speciﬁcation of tr ≤
0.5 sec?

Problems
175
(c) Which transfer function(s) will meet a settling time speciﬁcation of ts ≤
2.5 sec?
G1(s) =
40
(s2 + 4s + 40),
G2(s) =
40
(s + 1)(s2 + 4s + 40),
G3(s) =
120
(s + 3)(s2 + 4s + 40),
G4(s) =
20(s + 2)
(s + 1)(s2 + 4s + 40),
G5(s) =
36040/401(s2 + s + 401)
(s2 + 4s + 40)(s2 + s + 901).
3.47
Consider the two nonminimum-phase systems,
G1(s) = −
2(s −1)
(s + 1)(s + 2),
(3.98)
G2(s) =
3(s −1)(s −2)
(s + 1)(s + 2)(s + 3).
(3.99)
(a) Sketch the unit-step responses for G1(s) and G2(s), paying close attention
to the transient part of the response.
(b) Explain the difference in the behavior of the two responses as it relates to
the zero locations.
(c) Consider a stable, strictly proper system (that is, m zeros and n poles,
where m < n). Let y(t) denote the step response of the system. The step
response is said to have an undershoot if it initially starts off in the "wrong"
direction. Prove that a stable, strictly proper system has an undershoot if
and only if its transfer function has an odd number of real RHP zeros.
3.48
Find the relationships for the impulse response and the step response
corresponding to Eq. (3.65) for the cases where
(a) the roots are repeated.
(b) the roots are both real. Express your answers in terms of hyperbolic
functions (sinh, cosh) to best show the properties of the system response.
(c) the value of the damping coefﬁcient, ζ, is negative.
3.49
Consider the following second-order system with an extra pole:
H(s) =
ω2np
(s + p)(s2 + 2ζωns + ω2n).
Show that the unit-step response is
y(t) = 1 + Ae−pt + Be−σt sin(ωdt −θ),
where
A =
−ω2n
ω2n −2ζωnp + p2 ,

176
Chapter 3 Dynamic Response
B =
p
 
(p2 −2ζωnp + ω2n)(1 −ζ 2)
,
θ = tan−1

1 −ζ 2
−ζ
+ tan−1 ωn

1 −ζ 2
p −ζωn
.
(a) Which term dominates y(t) as p gets large?
(b) Give approximate values for A and B for small values of p.
(c) Which term dominates as p gets small? (Small with respect to what?)
(d) Using the preceding explicit expression for y(t) or the step command in
Matlab, and assuming that ωn = 1 and ζ = 0.7, plot the step response of
the preceding system for several values of p ranging from very small to
very large. At what point does the extra pole cease to have much effect
on the system response?
3.50
Consider the second-order unity DC gain system with an extra zero,
H(s) =
ω2n(s + z)
z(s2 + 2ζωns + ω2n).
(a) Show that the unit-step response for the system is given by
y(t) = 1 −
!
1 + ω2n
z2 −2ζωn
z

1 −ζ 2
e−σt cos(ωdt + β1),
where
β1 = tan−1 −ζ + ωnz

1 −ζ 2 .
(b) Derive an expression for the step response overshoot, Mp, of this system.
(c) For a given value of overshoot, Mp, how do we solve for ζ and ωn?
3.51
The block diagram of an autopilot designed to maintain the pitch attitude θ
of an aircraft is shown in Fig. 3.64. The transfer function relating the elevator
angle δe and the pitch attitude θ is
(s)
δe(s) = G(s) =
50(s + 1)(s + 2)
(s2 + 5s + 40)(s2 + 0.03s + 0.06),
where θ is the pitch attitude in degrees and δe is the elevator angle in degrees.
The autopilot controller uses the pitch attitude error e to adjust the elevator
according to the transfer function
δe(s)
E(s) = Dc(s) = K(s + 3)
s + 10 .
Using Matlab, ﬁnd a value of K that will provide an overshoot of less than
10% and a rise time faster than 0.5 sec for a unit-step change in θr. After
examining the step response of the system for various values of K, comment
on the difﬁculty associated with making rise time and overshoot measurements
for complicated systems.

Problems
177
Figure 3.64
Block diagram of
autopilot for
Problem 3.51
©
+
-
G(s)
Aircraft
Dc(s)
Control
de
e
ur
u
Problems for Section 3.6: Stability
3.52
A measure of the degree of instability in an unstable aircraft response is the
amount of time it takes for the amplitude of the time response to double (see
Fig. 3.65), given some nonzero initial condition.
(a) For a ﬁrst-order system, show that the time to double is
τ2 = ln 2
p
where p is the pole location in the RHP.
(b) For a second-order system (with two complex poles in the RHP), show
that
τ2 =
ln 2
−ζωn
.
Figure 3.65
Time to double
Time
Amplitude
2A
A
0
-A
2
3.53
Suppose that unity feedback is to be applied around the listed open-loop
systems. Use Routh's stability criterion to determine whether the resulting
closed-loop systems will be stable.
(a) KG(s) =
4(s+2)
s(s3+2s2+3s+4)
(b) KG(s) = 2(s+4)
s2(s+1)
(c) KG(s) = 4(s3+2s2+s+1)
s2(s3+2s2−s−1)
3.54
Use Routh's stability criterion to determine how many roots with positive real
parts the following equations have:
(a) s4 + 8s3 + 32s2 + 80s + 100 = 0
(b) s5 + 10s4 + 30s3 + 80s2 + 344s + 480 = 0
(c) s4 + 2s3 + 7s2 −2s + 8 = 0
(d) s3 + s2 + 20s + 78 = 0
(e) s4 + 6s2 + 25 = 0
3.55
Find the range of K for which all the roots of the following polynomial are in
the LHP:
s5 + 5s4 + 10s3 + 10s2 + 5s + K = 0.

178
Chapter 3 Dynamic Response
Use Matlab to verify your answer by plotting the roots of the polynomial in
the s-plane for various values of K.
3.56
The transfer function of a typical tape-drive system is given by
KG(s) =
K(s + 4)
s[(s + 0.5)(s + 1)(s2 + 0.4s + 4)],
where time is measured in milliseconds. Using Routh's stability criterion,
determine the range of K for which this system is stable when the characteristic
equation is 1 + KG(s) = 0.
3.57
Consider the closed-loop magnetic levitation system shown in Fig. 3.66.
Determine the conditions on the system parameters (a, K, z, p, K◦) to
guarantee closed-loop system stability.
Figure 3.66
Magnetic levitation
system for Problem 3.57
Ko
Y
(s2 - a2)
©
+
-
R
e
u
(s + z)
(s + p)
K
3.58
Consider the system shown in Fig. 3.67.
Figure 3.67
Control system for
Problem 3.58
©
+
-
e-sT
R
 Y
s(s + 1)
A
(a) Compute the closed-loop characteristic equation.
(b) For what values of (T, A) is the system stable? Hint: An approximate
answer may be found using
e−Ts ∼= 1 −Ts,
or
e−Ts ∼=
1 −T
2 s
1 + T
2 s
,
for the pure delay. As an alternative, you could use the computer Matlab
(Simulink) to simulate the system or to ﬁnd the roots of the system's
characteristic equation for various values of T and A.
3.59
Modify the Routh criterion so that it applies to the case in which all the
poles are to be to the left of −α when α > 0. Apply the modiﬁed test to the
polynomial
s3 + (6 + K)s2 + (5 + 6K)s + 5K = 0,
ﬁnding those values of K for which all poles have a real part less than −1.
3.60
Suppose the characteristic polynomial of a given closed-loop system is
computed to be
s4+(11+K2)s3+(121+K1)s2+(K1+K1K2+110K2+210)s+11K1+100 = 0.

Problems
179
Figure 3.68
Electric power-line
conductor
y
x
a
a
np2
(
)
T
Spring
constant
Ice
a
Wind y
Relative wind =    y2 + y2
Conductor
y
0L
0a + D0 6 0
Find constraints on the two gains K1 and K2 that guarantee a stable closed-
loop system, and plot the allowable region(s) in the (K1, K2) plane. You may
wish to use the computer to help solve this problem.
3.61
Overhead electric power lines sometimes experience a low-frequency, high-
amplitude vertical oscillation, or gallop, during winter storms when the line
conductors become covered with ice. In the presence of wind, this ice can
assume aerodynamic lift and drag forces that result in a gallop up to several
meters in amplitude. Large-amplitude gallop can cause clashing conduc-
tors and structural damage to the line support structures caused by the large
dynamic loads. These effects in turn can lead to power outages. Assume that
the line conductor is a rigid rod, constrained to vertical motion only, and sus-
pended by springs and dampers as shown in Fig. 3.68. A simple model of this
conductor galloping is
m¨y + D(α)˙y −L(α)v
(˙y2 + v2)1/2
+ T

nπ
ℓ

y = 0,
where
m = mass of conductor,
y = conductor's vertical displacement,
D = aerodynamic drag force,
L = aerodynamic lift force,
v = wind velocity,
α = aerodynamic angle of attack = −tan−1(˙y/v),
T = conductor tension,
n = number of harmonic frequencies,
ℓ= length of conductor.
Assume that L(0) = 0 and D(0) = D0 (a constant), and linearize the equation
around the value y = ˙y = 0. Use Routh's stability criterion to show that
galloping can occur whenever
∂L
∂α + D0 < 0.

4
A First Analysis of Feedback
A Perspective on the Analysis of Feedback
In the next three chapters, we will introduce three techniques for
the design of controllers. Before doing so, it is useful to develop
the assumptions to be used and to derive the equations that are
common to each of the design approaches we describe. As a general
observation, the dynamics of systems to which control is applied
are nonlinear and very complex. However, in this initial analysis,
we assume that the plant to be controlled as well as the controller
can be represented as dynamic systems which are linear and time
invariant (LTI). We also assume that they have only single inputs and
single outputs, for the most part, and may thus be represented by
simple scalar transfer functions. As we mentioned in Chapter 1, our
basic concerns for control are stability, tracking, regulation, and
sensitivity. The goal of the analysis in this chapter is to revisit each
of these requirements in a linear dynamic setting and to develop
equations that will expose constraints placed on the controller and
identify elementary objectives to be suggested for the controllers.
The two fundamental structures for realizing controls are the
open-loop structure as shown in Fig. 4.1, and the closed-loop struc-
ture, also known as feedback control, as shown in Fig. 4.2. The
deﬁnition of open-loop control is that there is no closed signal
path whereby the output inﬂuences the control effort. In the struc-
ture shown in Fig. 4.1, the controller transfer function modiﬁes the
180

Chapter 4 A First Analysis of Feedback 181
reference input signal before it is applied to the plant. This controller
might cancel the unwanted dynamics of the plant and replace them
with the more desirable dynamics of the controller. In other cases,
open-loop control actions are taken on the plant as the environment
changes, actions that are calibrated to give a good response but are
not dependent on measuring the actual response. An example of this
would be an aircraft autopilot whose parameters are changed with
altitude or speed but not by feedback of the craft's motion. Feedback
control, on the other hand, uses a sensor to measure the output and
by feedback indirectly modiﬁes the dynamics of the system. Although
it is possible that feedback may cause an otherwise stable system to
become unstable (a vicious circle), feedback gives the designer more
ﬂexibility and a preferable response to each of our objectives when
compared to open-loop control.
Chapter Overview
The chapter begins with consideration of the basic equations of a
simple open-loop structure and of an elementary feedback structure.
In Section 4.1, the equations for the two structures are presented in
general form and compared in turn with respect to stability, tracking,
regulation, and sensitivity. In Section 4.2, the steady-state errors
in response to polynomial inputs are analyzed in more detail. As part
of the language of steady-state performance, control systems are
assigned a type number according to the maximum degree of the
input polynomial for which the steady-state error is a ﬁnite constant.
For each type an appropriate error constant is deﬁned, which allows
the designer to easily compute the size of this error.
Although Maxwell and Routh developed a mathematical basis for
assuring stability of a feedback system, design of controllers from
the earliest days was largely trial and error based on experience.
From this tradition there emerged an almost universal controller,
the proportional-integral-derivative (PID) structure considered in
Section 4.3. This device has three elements: a Proportional term to
close the feedback loop, an Integral term to assure zero error to con-
stant reference and disturbance inputs, and a Derivative term to
improve (or realize!) stability and good dynamic response. In this
section, these terms are considered and their respective effects illus-
trated. As part of the evolution of the PID controller design, a major
step was the development of a simple procedure for selecting the
three parameters, a process called "tuning the controller." Ziegler
and Nichols developed and published a set of experiments to be run,
characteristics to be measured, and tuning values to be recommended
as a result. These procedures are discussed in this section. The con-
cept of feedforward control by plant model inversion is discussed in
Section 4.4. In the optional Section 4.5, a brief introduction to the

182
Chapter 4 A First Analysis of Feedback
increasingly common digital implementation of controllers is given.
Sensitivity of time response to parameter changes is discussed in
Section 4.6. Finally, Section 4.7 provides the historical perspective
for the material in this chapter.
4.1
The Basic Equations of Control
We begin by collecting a set of equations and transfer functions that will be
used throughout the rest of the text. For the open-loop system of Fig. 4.1, if
we take the disturbance to be at the input of the plant, the output is given by
Yol = GDolR + GW,
(4.1)
and the error, the difference between reference input and system output, is
given by
Eol = R −Yol,
(4.2)
= R −[GDolR + GW],
(4.3)
= [1 −GDol]R −GW.
(4.4)
The open-loop transfer function in this case is Tol(s) = G(s)Dol(s).
For feedback control, Fig. 4.2 gives the basic unity feedback structure of
interest. There are three external inputs: the reference, R, which the output is
expected to track; the plant disturbance, W, which the control is expected to
counteract so it does not disturb the output; and the sensor noise, V, which
the controller is supposed to ignore.
For the feedback block diagram of Fig. 4.2, the equations for the output
and the control are given by the superposition of the responses to the three
inputs individually, as follows:
Ycl =
GDcl
1 + GDcl
R +
G
1 + GDcl
W −
GDcl
1 + GDcl
V,
(4.5)
U =
Dcl
1 + GDcl
R −
GDcl
1 + GDcl
W −
Dcl
1 + GDcl
V.
(4.6)
Figure 4.1
Open-loop system
showing reference, R,
control, U, disturbance,
W, and output Y
W(s)
R(s)
Y(s)
+
+
U(s)
Controller
Dol(s)
Plant
G(s)
©
Figure 4.2
Closed-loop system
showing the reference,
R, control, U,
disturbance, W, output,
Y, and sensor noise, V
+
+
R(s)
-
+
Y(s)
V
W(s)
U(s)
Plant
G(s)
+
+
Controller
Dcl(s)
©
©
©

4.1 The Basic Equations of Control
183
Perhaps more important than these is the equation for the error, Ecl = R−Ycl.
Ecl = R −

GDcl
1 + GDcl
R +
G
1 + GDcl
W −
GDcl
1 + GDcl
V

,
(4.7)
=
1
1 + GDcl
R −
G
1 + GDcl
W +
GDcl
1 + GDcl
V.
(4.8)
We can rewrite Eqs. (4.5), (4.6) and (4.8) in a nice compact form:
Ycl = T R + GSW −T V,
(4.9)
U = DclSR −T W −DclSV,
(4.10)
Ecl = SR −GSW + T V,
(4.11)
where we deﬁne the two transfer functions
S =
1
1 + GDcl
,
(4.12)
and
T =
GDcl
1 + GDcl
.
(4.13)
In this case, the closed-loop transfer function is Tcl = T =
GDcl
1 + GDcl
. The
signiﬁcance of these two transfer functions will become apparent later in
this section.
With these equations, we will explore the four basic objectives of sta-
bility, tracking, regulation, and sensitivity for both the open-loop and the
closed-loop cases.
4.1.1
Stability
As we discussed in Chapter 3, the requirement for stability is simply stated:
All poles of the transfer function must be in the left half-plane (LHP). In
the open-loop case described by Eq. (4.1), these are the poles of GDol. To
see the restrictions this requirement places on the controller, we deﬁne the
polynomials a(s), b(s), c(s), and d(s) so that G(s) = b(s)
a(s) and Dol(s) = c(s)
d(s).
Therefore GDol = bc
ad . With these deﬁnitions, the stability requirement is
that neither a(s) nor d(s) may have roots in the right half-plane (RHP). A
naive engineer might believe that if the plant is unstable with a(s) having a
root in the RHP, the system might be made stable by canceling this pole with
a zero of c(s). However, the unstable pole remains and the slightest noise
or disturbance will cause the output to grow until stopped by saturation or
system failure. Likewise, if the plant shows poor response because of a zero
of b(s) in the RHP, an attempt to ﬁx this by cancellation using a root of d(s)
will similarly result in an unstable system. We conclude that an open-loop
structure cannot be used to make an unstable plant to be stable and therefore
cannot be used if the plant is already unstable.

184
Chapter 4 A First Analysis of Feedback
For the feedback system, from Eq. (4.8), the system poles are the roots
of 1 + GDcl = 0. Again using the polynomials deﬁned above, the system
characteristic equation is
1 + GDcl = 0,
(4.14)
1 + b(s)c(s)
a(s)d(s) = 0,
(4.15)
a(s)d(s) + b(s)c(s) = 0.
(4.16)
From this equation, it is clear that the feedback case grants considerably
more freedom to the controller design than does the open-loop case. How-
ever, one must still avoid unstable cancellations. For example, if the plant is
unstable and therefore a(s) has a root in the RHP, we might cancel this pole
by putting a zero of c(s) at the same place. However, Eq. (4.16) shows that as
a result, the unstable pole remains a pole of the system and this method will
not work. However, unlike the open-loop case, having a pole of a(s) in the
RHP does NOT prevent the design of a feedback controller that will make
the system stable. For example, in Chapter 2 we derived the transfer function
for the inverted pendulum, which, for simple values, might be G(s) =
1
s2−1
for which we have b(s) = 1 and a(s) = s2 −1 = (s+1)(s−1). Suppose we
try Dcl(s) = K(s+γ )
s+δ . The characteristic equation that results for the system is
(s + 1)(s −1)(s + δ) + K(s + γ ) = 0.
(4.17)
This is the problem that Maxwell faced in his study of governors: Under what
conditions on the parameters will all the roots of this equation be in the LHP?
The problem was solved by Routh. In our case, a simple solution is to take
γ = 1 and the common (stable) factor cancels. Note that the cancellation is
ﬁne in this case, because (s + 1) is a stable pole. The resulting second-order
equation can be easily solved to place the remaining two poles at any point
desired.
Exercise. If we wish to force the characteristic equation to be s2 +2ζωns+
ω2
n = 0, solve for K and δ in terms of ζ and ωn.
4.1.2
Tracking
The tracking problem is to cause the output to follow the reference input
as closely as possible. In the open-loop case, if the plant is stable and has
neither poles nor zeros in the RHP, then in principle the controller can be
selected to cancel the transfer function of the plant and substitute whatever
desired transfer function the engineer wishes. This apparent freedom, how-
ever, comes with three caveats. First, in order to physically build it, the
controller transfer function must be proper, meaning that it cannot be given
more zeros than it has poles. Second, the engineer must not get greedy and
request an unrealistically fast design. This entire analysis has been based on
the assumption that the plant is linear and a demand for a fast response will
demand large inputs to the plant, inputs that will be sure to saturate the sys-
tem if the demand is too great. Again, it is the responsibility of the engineer
to know the limits of the plant and to set the desired overall transfer function

4.1 The Basic Equations of Control
185
to a reasonable value with this knowledge. Third and ﬁnally, although one
can, in principle, stably cancel any pole in the LHP, the next section on
sensitivity faces up to the fact that the plant transfer function is subject to
change and if one tries to cancel a pole that is barely inside the LHP, there
is a good chance of disaster as that pole moves a bit and exposes the system
response to unacceptable transients.
Exercise. For a plant having the transfer function G(s) =
1
s2+3s+9 it is
proposed to use a controller in a unity feedback system and having the
transfer function Dcl(s) =
c2s2+c1s+c0
s(s+d1)
. Solve for the parameters of this
controller so that the closed loop will have the characteristic equation (s + 6)
(s + 3)(s2 + 3s + 9) = 0.1
{Answer: c2 = 18, c1 = 54, c0 = 162, d1 = 9}.
Exercise. Show that if the reference input to the system of the above exercise
is a step of amplitude A, the steady-state error will be zero.
4.1.3
Regulation
The problem of regulation is to keep the error small when the reference is at
most a constant set point and disturbances are present. A quick look at the
open-loop block diagram reveals that the controller has no inﬂuence at all on
the system response to either of the disturbances, w, or v, so this structure is
useless for regulation. We turn to the feedback case. From Eq. (4.8), we ﬁnd
a conﬂict between w and v in the search for a good controller. For example,
the term giving the contribution of the plant disturbance to the system error
is
G
1+GDcl W. To select Dcl to make this term small, we should make Dcl as
large as possible and inﬁnite if that is feasible. On the other hand, the error
term for the sensor noise is
GDcl
1+GDcl V. In this case, unfortunately, if we select
Dcl to be large, the transfer function tends to unity and the sensor noise is
not reduced at all! What are we to do? The resolution of the dilemma is to
observe that each of these terms is a function of frequency so one of them can
be large for some frequencies and small for others. With this in mind, we also
note that the frequency content of most plant disturbances occurs at very low
frequencies and, in fact, the most common case is a bias, which is all at zero
frequency! On the other hand, a good sensor will have no bias and can be
constructed to have very little noise over the entire range of low frequencies
of interest. Thus, using this information, we design the controller transfer
function to be large at the low frequencies, where it will reduce the effect
of w, and we make it small at the higher frequencies, where it will reduce
the effects of the high frequency sensor noise. The control engineer must
determine in each case the best place on the frequency scale to make the
crossover from ampliﬁcation to attenuation.
Exercise. Show that if w is a constant bias and if Dcl has a pole at s = 0,
then the error due to this bias will be zero. However, show that if G has a
pole at zero, the error due to this bias will not be zero.
1This process is called "pole placement," a technique to be discussed in Chapter 7.

186
Chapter 4 A First Analysis of Feedback
4.1.4
Sensitivity
Suppose a plant is designed with gain G at a particular frequency but in oper-
ation it changes to be G+δG. This represents a fractional or percent change
of gain of δG/G. For the purposes of this analysis, we set the frequency
at zero and take the open-loop controller gain to be ﬁxed at Dol(0). In the
open-loop case, the nominal overall gain is thus Tol = GDol, and with the
perturbed plant gain, the overall gain would be
Tol + δTol = Dol(G + δG) = DolG + DolδG = Tol + DolδG.
Therefore, the gain change is δTol = DolδG. The sensitivity, ST
G, of a transfer
function, Tol, to a plant gain, G, is deﬁned to be the ratio of the fractional
change in Tol deﬁned as δTol
Tol to the fractional change in G. In equation form,
ST
G =
δTol
Tol
δG
G
,
(4.18)
= G
Tol
δTol
δG .
(4.19)
Substituting the values, we ﬁnd that
δTol
Tol
= DolδG
DolG = δG
G .
(4.20)
This means that a 10% error in G would yield a 10% error in Tol. In the
open-loop case, therefore, we have computed that S = 1.
From Eq. (4.5), the same change in G in the feedback case yields the
new steady-state feedback gain as
Tcl + δTcl =
(G + δG)Dcl
1 + (G + δG)Dcl
,
where Tcl is the closed-loop gain. We can compute the sensitivity of this
closed-loop gain directly using differential calculus. The closed-loop steady-
state gain is
Tcl =
GDcl
1 + GDcl
.
The ﬁrst-order variation is proportional to the derivative and is given by
δTcl = dTcl
dG δG.
The general expression for sensitivity from Eq. (4.18) is given by
STcl
G ≜sensitivity of Tcl with respect to G,
STcl
G ≜G
Tcl
dTcl
dG ,
(4.21)

4.1 The Basic Equations of Control
187
so
STcl
G =
G
GDcl/(1 + GDcl)
(1 + GDcl)Dcl −Dcl(GDcl)
(1 + GDcl)2
,
=
1
1 + GDcl
.
(4.22)
This result exhibits a major advantage of feedback2:
Advantage of feedback
In feedback control, the error in the overall transfer function gain
is less sensitive to variations in the plant gain by a factor of S =
1
1+GDcl compared to errors in open-loop control gain.
If the gain is such that 1+GDcl = 100, a 10% change in plant gain G will
cause only a 0.1% change in the steady-state gain. The open-loop controller
is 100 times more sensitive to gain changes than the closed-loop system with
loop gain of 100. The example of the unity feedback case is so common that
we will refer to the result of Eq. (4.22) simply as the sensitivity, S, without
subscripts or superscripts. Hence, we deﬁne the sensitivity function for a
feedback system as
S =
1
1 + GDcl
.
(4.23)
Its usefulness will be demonstrated for dynamic feedback controller
design in Chapter 6. The complementary sensitivity function is deﬁned as
Sensitivity function
(a fancy alternative name for the closed-loop transfer function!)
T =
GDcl
1 + GDcl
= 1 −S.
(4.24)
These two transfer functions are very important for feedback control
design, and they illustrate the fundamental relationship of feedback systems
A fundamental
relationship of feedback
systems
(that will be explored further in Chapter 6)
S + T = 1.
(4.25)
The results in this section so far have been computed under the assump-
tion of the steady-state error in the presence of constant inputs, either
reference or disturbance. Very similar results can be obtained for the steady-
state behavior in the presence of a sinusoidal reference or disturbance signal.
This is important because there are times when such signals naturally occur
as, for example, with a disturbance of 60 Hz due to power-line interference
in an electronic system. The concept is also important because more com-
plex signals can be described as containing sinusoidal components over a
band of frequencies and analyzed using superposition of one frequency at a
time. For example, it is well known that human hearing is restricted to sig-
nals in the frequency range of about 60 to 15,000 Hz. A feedback ampliﬁer
2Bode, who developed the theory of sensitivity as well as many other properties of feedback,
deﬁned sensitivity as S = 1 + GD, the inverse of our choice.

188
Chapter 4 A First Analysis of Feedback
and loudspeaker system designed for high-ﬁdelity sound must accurately
track any sinusoidal (pure tone) signal in this range. If we take the con-
troller in the feedback system shown in Fig. 4.2 to have the transfer function
Dcl(s) and we take the process to have the transfer function G(s), then the
steady-state open-loop gain at the sinusoidal signal of frequency ωo will be
|G( jωo)Dcl( jωo)| and the error of the feedback system will be
|E( jωo)| = |R( jωo)|

1
1 + G( jωo)Dcl( jωo)
 .
(4.26)
Thus, to reduce errors to 1% of the input at the frequency ωo, we must make
|1+GDcl| ≥100 or, effectively, |G( jωo)Dcl( jωo)| ≳100 and a good audio
ampliﬁer must have this loop gain over the range 2π60 ≤ω ≤2π15, 000.
We will revisit this concept in Chapter 6 as part of the design based on
frequency-response techniques.
The Filtered Case
For the case where there is a non-unity pre ﬁlter F(s) following the reference
input, R(s), and non-unity sensor dynamics H(s), the equations for the
system output and the various sensitivity functions need to be re-derived. The
details are available in Appendix W4.1.4.1 on the web at www.fpe7e.com.
4.2
Control of Steady-State Error to Polynomial
Inputs: System Type
In studying the regulator problem, the reference input is taken to be a con-
stant. It is also the case that the most common plant disturbance is a constant
bias. Even in the general tracking problem, the reference input is often con-
stant for long periods of time or may be adequately approximated as if it
were a polynomial in time, usually one of low degree. For example, when an
antenna is tracking the elevation angle to a satellite, the time history as the
satellite approaches overhead is an S-shaped curve as sketched in Fig. 4.3.
This signal may be approximated by a linear function of time (called a ramp
function or velocity input) for a signiﬁcant time relative to the speed of
response of the servomechanism. As another example, the position control
of an elevator has a ramp function reference input, which will direct the
elevator to move with constant speed until it comes near the next ﬂoor. In
rare cases, the input can even be approximated over a substantial period
as having a constant acceleration. Consideration of these cases leads us to
consider steady-state errors in stable systems with polynomial inputs.
Figure 4.3
Signal for satellite
tracking
Time (sec)
us

4.2 Control of Steady-State Error to Polynomial Inputs: System Type
189
As part of the study of steady-state errors to polynomial inputs, a termi-
nology has been developed to express the results. For example, we classify
systems as to "type" according to the degree of the polynomial that they
can reasonably track. For example, a system that can track a polynomial of
degree 1 with a constant error is called Type 1. Also, to quantify the tracking
error, several "error constants" are deﬁned. In all of the following analysis,
it is assumed that the systems are stable, else the analysis makes no sense
at all.
4.2.1
System Type for Tracking
In the unity feedback case shown in Fig. 4.2, the system error is given by Eq.
(4.8). If we consider tracking the reference input alone and set W = V = 0,
then the equation for the error is simply
E =
1
1 + GDcl
R = SR,
where
S =
1
1 + GDcl
.
(4.27)
To consider polynomial inputs, we let r(t) = tk/k!1(t) for which the
transform is R =
1
sk+1 .We take a mechanical system as the basis for a generic
reference nomenclature, calling step inputs for which k = 0 "position"
inputs, ramp inputs for which k = 1 are called "velocity" inputs, and if
k = 2, the inputs are called "acceleration" inputs, regardless of the units
of the actual signals. Application of the Final Value Theorem to the error
formula gives the result
lim
t→∞e(t) = ess = lim s
s→0 E(s),
(4.28)
= lim
s→0s
1
1 + GDcl
R(s),
(4.29)
= lim
s→0s
1
1 + GDcl
1
sk+1 .
(4.30)
We consider ﬁrst a system for which GDcl has no pole at the origin, that
is, no integrator, and a unit-step input for which R(s) = 1/s. Thus r(t) is a
polynomial of degree 0. In this case, Eq. (4.30) reduces to
ess = lim
s→0s
1
1 + GDcl
1
s ,
(4.31)
ess
rss
= ess
1 = ess =
1
1 + GDcl(0),
(4.32)
where rss = limt→∞r(t) = 1. We deﬁne this system to be Type 0 and we
deﬁne the constant, GDcl(0) ≜Kp, as the "position error constant." Notice
that the above equation yields the relative error and if the input should be a
polynomial of degree higher than 1, the resulting error would grow without
bound. A polynomial of degree 0 is the highest degree a system of Type 0
can track at all. If GDcl(s) has one pole at the origin, we could continue
this line of argument and consider ﬁrst-degree polynomial inputs but it is

190
Chapter 4 A First Analysis of Feedback
quite straightforward to evaluate Eq. (4.30) in a general setting. For this
case, it is necessary to describe the behavior of the controller and plant as s
approaches 0. For this purpose, we collect all the terms except the pole (s)
at the origin into a function GDclo(s), which is ﬁnite at s = 0 so that we can
deﬁne the constant GDclo(0) = Kn and write the loop transfer function as
GDcl(s) = GDclo(s)
sn
.
(4.33)
For example, if GDcl has no integrator, then n = 0. If the system has
one integrator, then n = 1, and so forth. Substituting this expression into
Eq. (4.30),
ess = lim
s→0s
1
1 + GDclo(s)
sn
1
sk+1 ,
(4.34)
= lim
s→0
sn
sn + Kn
1
sk .
(4.35)
From this equation, we can see at once that if n > k then e = 0 and if
n < k then e →∞. If n = k = 0, then ess =
1
1+K0 and if n = k ̸= 0,
then ess = 1/Kn. As we discussed above, if n = k = 0, the input is a zero-
degree polynomial otherwise known as a step or position, the constant Ko
is called the "position constant" written as Kp, and the system is classiﬁed
as "Type 0." If n = k = 1, the input is a ﬁrst-degree polynomial otherwise
known as a ramp or velocity input and the constant K1 is called the "velocity
constant" written as Kv. This system is classiﬁed "Type 1" (read "type one").
In a similar way, systems of Type 2 and higher types may be deﬁned. A clear
picture of the situation is given by the plot in Fig. 4.4 for a system of Type 1
having a ramp reference input. The error between input and output of size 1
Kv
is clearly marked.
Figure 4.4
Relationship between
ramp response and Kv
0
1
2
3
4
5
6
7
8
9
10
10
9
8
7
6
5
4
3
2
1
0
Time (sec)
r, y
r
y
1
Ky
ess =  

4.2 Control of Steady-State Error to Polynomial Inputs: System Type
191
TABLE 4.1
Errors as a Function of System Type
Type Input
Step (position)
Ramp (velocity)
Parabola (acceleration)
Type 0
1
1 + Kp
∞
∞
Type 1
0
1
Kv
∞
Type 2
0
0
1
Ka
Using Eq. (4.33), these results can be summarized by the following
equations:
Kp = lim
s→0 GDcl(s),
n = 0,
(4.36)
Kv = lim
s→0 sGDcl(s),
n = 1,
(4.37)
Ka = lim
s→0 s2GDcl(s),
n = 2.
(4.38)
The type information can also be usefully gathered in a table of error
values as a function of the degree of the input polynomial and the type of
the system as shown in Table 4.1.
EXAMPLE 4.1
System Type for Speed Control
Determine the system type and the relevant error constant for speed control
with proportional feedback given by D(s) = kP. The plant transfer function
is G =
A
τs+1.
Solution. In this case, GDcl =
kPA
τs+1 and applying Eq. (4.36) we see that
n = 0 as there is no pole at s = 0. Thus, the system is Type 0 and the error
constant is a position constant given by Kp = kPA.
EXAMPLE 4.2
System Type Using Integral Control
Determine the system type and the relevant error constant for the speed-
control example with proportional plus integral control having controller
given by Dc = kP + kI/s. The plant transfer function is G =
A
τs+1.
Solution.
In this case, the loop transfer function is GDcl(s) = A(kPs+kI)
s(τs+1)
and, as a unity feedback system with a single pole at s = 0, the system is
immediately seen as Type 1. The velocity constant is given by Eq. (4.37) to
be Kv = lim
s→0sGDcl(s) = AkI.

192
Chapter 4 A First Analysis of Feedback
The deﬁnition of system type helps us to identify quickly the ability of
a system to track polynomials. In the unity feedback structure, if the process
parameterschangewithoutremovingthepoleattheorigininaType1system,
the velocity constant will change but the system will still have zero steady-
state error in response to a constant input and will still be Type 1. Similar
statements can be made for systems of Type 2 or higher. Thus, we can say
that system type is a robust property with respect to parameter changes
Robustness of system type
in the unity feedback structure. Robustness is a major reason for preferring
unity feedback over other kinds of control structure.
Another form of the formula for the error constants can be developed
directly in terms of the closed-loop transfer function T (s). From Fig. 4.5,
the transfer function including a sensor transfer function is
Y(s)
R(s) = T (s) =
GDc
1 + GDcH ,
(4.39)
and the system error is
E(s) = R(s) −Y(s) = R(s) −T (s)R(s).
(4.40)
The reference-to-error transfer function is thus
E(s)
R(s) = 1 −T (s),
(4.41)
and the system error transform is
E(s) = [1 −T (s)]R(s).
(4.42)
We assume that the conditions of the Final Value Theorem are satisﬁed,
namely that all poles of sE(s) are in the LHP. In that case, the steady-state
error is given by applying the Final Value Theorem to get
ess = lim
t→∞e(t) = lim
s→0 sE(s) = lim
s→0 s[1 −T (s)]R(s).
(4.43)
Ifthereferenceinputisapolynomialofdegreek, theerrortransformbecomes
E(s) =
1
sk+1 [1 −T (s)],
(4.44)
and the steady-state error is given again by the Final Value Theorem:
ess = lim
s→0 s1 −T (s)
sk+1
= lim
s→0
1 −T (s)
sk
.
(4.45)
As before, the result of evaluating the limit in Eq. (4.45) can be zero, a
nonzero constant, or inﬁnite and if the solution to Eq. (4.45) is a nonzero
constant, the system is referred to as Type k. Notice that a system of Type 1
or higher has a closed-loop DC gain of 1.0, which means that T(0) = 1 in
these cases.
EXAMPLE 4.3
System Type for a Servo with Tachometer Feedback
Consider an electric motor position control problem including a non-unity
feedback system caused by having a tachometer ﬁxed to the motor shaft and

4.2 Control of Steady-State Error to Polynomial Inputs: System Type
193
Figure 4.5
Closed-loop system with
sensor dynamics. R =
reference, U = control,
Y = output, V = sensor
noise
©
©
+
-
+
+
©
+
+
Y(s)
V(s)
R(s)
W(s)
Controller
Dol(s)
U(s)
Plant
G(s)
Sensor
H(s)
its voltage (which is proportional to shaft speed) is fed back as part of the
control as shown in Fig. 4.5. The parameters are
G(s) =
1
s(τs + 1),
Dc(s) = kP,
H(s) = 1 + kts.
Determine the system type and relevant error constant with respect to
reference inputs.
Solution. The system error is
E(s) = R(s) −Y(s),
= R(s) −T (s)R(s),
= R(s) −
Dc(s)G(s)
1 + H(s)Dc(s)G(s)R(s),
= 1 + (H(s) −1)Dc(s)G(s)
1 + H(s)Dc(s)G(s)
R(s).
The steady-state system error from Eq. (4.45) is
ess = lim
s→0 sR(s)[1 −T (s)].
For a polynomial reference input, R(s) = 1/sk+1 and hence
ess = lim
s→0
[1 −T (s)]
sk
= lim
s→0
1
sk
s(τs + 1) + (1 + kts −1)kP
s(τs + 1) + (1 + kts)kP
,
= 0 ,
k = 0,
= 1 + ktkP
kP
,
k = 1;
therefore the system is Type 1 and the velocity constant is Kv =
kP
1+ktkP .
Notice that if kt > 0, perhaps to improve stability or dynamic response,
the velocity constant is smaller than with simply the unity feedback value
of kP. The conclusion is that if tachometer feedback is used to improve
dynamic response, the steady-state error is usually increased, that is, there
is a trade-off between improving stability and reducing steady-state error.

194
Chapter 4 A First Analysis of Feedback
4.2.2
System Type for Regulation and Disturbance
Rejection
A system can also be classiﬁed with respect to its ability to reject polynomial
disturbance inputs in a way analogous to the classiﬁcation scheme based on
reference inputs. The transfer function from the disturbance input W(s) to
the error E(s) is
E(s)
W(s) = −Y(s)
W(s) = Tw(s),
(4.46)
because, if the reference is equal to zero, the output is the error. In a sim-
ilar way as for reference inputs, the system is Type 0 if a step disturbance
input results in a nonzero constant steady-state error and is Type 1 if a
ramp disturbance input results in a steady-state value of the error that is
a nonzero constant, and so on. In general, following the same approach
used in developing Eq. (4.35), we assume that a constant n and a function
To,w(s) can be deﬁned with the properties that To,w(0) = 1/Kn,w and that
the disturbance-to-error transfer function can be written as
Tw(s) = snTo,w(s).
(4.47)
Then the steady-state error to a disturbance input, which is a polynomial of
degree k, is
yss = lim
s→0

sTw(s) 1
sk+1

,
= lim
s→0

To,w(s)sn
sk

.
(4.48)
From Eq. (4.48), if n > k, then the error is zero and if n < k, the error is
unbounded. If n = k, the system is type k and the error is given by 1/Kn,w.
EXAMPLE 4.4
System Type for a DC Motor Position Control
Consider the simpliﬁed model of a DC motor in unity feedback as shown
in Fig. 4.6, where the disturbance torque is labeled W(s). This case was
considered in Example 2.11.
(a) Use the controller
Dc(s) = kP,
(4.49)
and determine the system type and steady-state error properties with respect
to disturbance inputs.
(b) Let the controller transfer function be given by
Dc(s) = kP + kI
s ,
(4.50)
and determine the system type and the steady-state error properties for
disturbance inputs.

4.2 Control of Steady-State Error to Polynomial Inputs: System Type
195
Figure 4.6
DC motor with unity
feedback
W(s)
A
B
+
+
+
+
-1.0
Dc(s)
s(ts + 1)
A
Y
R
©
©
Solution.
(a) The closed-loop transfer function from W to E (where
R = 0) is
Tw(s) = −
B
s(τs + 1) + AkP
,
= s0To,w,
n = 0,
Ko,w = −AkP
B .
Applying Eq. (4.48) we see that the system is Type 0 and the steady-state
error to a unit-step torque input is ess = −B/AkP. From the earlier section,
this system is seen to beType 1 for reference inputs and illustrates that system
type can be different for different inputs to the same system.
(b) For this controller the disturbance error transfer function is
Tw(s) = −
Bs
s2(τs + 1) + (kPs + kI)A,
(4.51)
n = 1,
(4.52)
Kn,w = −AkI
B ,
(4.53)
and therefore the system is Type 1 and the error to a unit-ramp disturbance
input will be
ess = −B
AkI
.
(4.54)
Truxal's Formula
Truxal (1955) derived a formula for the velocity constant of a Type 1 sys-
tem in terms of the closed-loop poles and zeros. See Appendix W4.2.2.1 at
www.fpe7e.com.

196
Chapter 4 A First Analysis of Feedback
4.3
The Three-Term Controller: PID Control
In later chapters, we will study three general analytic and graphical design
techniques based on the root locus, the frequency response, and the state-
space formulation of the equations. Here, we describe a control method
having an older pedigree that was developed through long experience and
by trial and error. Starting with simple proportional feedback, engineers
early discovered integral control action as a means of eliminating bias offset.
Then, ﬁnding poor dynamic response in many cases, an "anticipatory" term
based on the derivative was added. The result is called the three-term or PID
controller and has the transfer function
Dc(s) = kP + kI
s + kDs,
(4.55)
where kP is the proportional term, kI is the integral term, and kD is the
derivative term. We will discuss them in turn.
4.3.1
Proportional Control (P)
When the feedback control signal is linearly proportional to the system error
u(t) = kPe(t),
(4.56)
wecalltheresult Proportionalfeedback. Hence, thecontrolsignalisrelated
Proportional control
to the system error instantaneously. This was the case for the feedback used
in the controller of speed in Section 4.1 for which the controller transfer
function is
U(s)
E(s) = Dcl(s) = kP.
(4.57)
The controller is purely algebraic with no dynamics and kP is called the
proportional gain. We can view the proportional controller as an ampliﬁer
with a "knob" that can be adjusted up or down. If the plant is second order,
as, for example, for a motor with non-negligible inductance,3 then the plant
transfer function can be written as
G(s) =
A
s2 + a1s + a2
.
(4.58)
In this case, the characteristic equation for the closed-loop system with
proportional control is
1 + kPG(s) = 0,
(4.59)
that results in
s2 + a1s + a2 + kPA = 0.
(4.60)
The designer can control the constant term, (a2 + kPA), in this equation by
selecting kP, which determines the natural frequency but cannot control the
damping term a1 since it is independent of kP. The system is Type 0 and
3See Section 2.3.

4.3 The Three-Term Controller: PID Control
197
if kP is made large to get adequately small steady-state error, the damping
may be much too low for satisfactory transient response with proportional
control alone. To illustrate these features of proportional control, assume
that we have the plant G(s) under proportional control as shown in Fig. 4.2
and assume that a1 = 1.4, a2 = 1, and A = 1. The proportional controller
is indicated by Eq. (4.57). Figure 4.7 shows the closed-loop response of
Y(s)
R(s) = T (s) =
kPG(s)
1 + kPG(s),
(4.61)
for a unit-step command input, r = 1(t), with kP = 1.5 and kP = 6. The
output, y, of the system exhibits a steady-state tracking error that decreases
as the proportional feedback gain is increased. Furthermore, the response
also clearly exhibits a decrease in damping as the gain is increased and an
increase in the speed of response. Using the Final Value Theorem would
also show that the steady-state error decreases as the gain, kP, is increased as
well as the fact that the control value, u(t), reaches a steady non zero value.
The output and the control signal due to a disturbance are given by
Y(s)
W(s) =
G(s)
1 + kPG(s),
U(s)
W(s) = −
kPG(s)
1 + kPG(s).
By comparing the closed-loop transfer functions between the disturbance
response and the command response, it can be seen that a step disturbance,
w, will also yield a steady-state tracking error and control value in a similar
manner to the reference input shown in Fig. 4.7. The error due to the distur-
bance will also decrease as the gain, kP, is increased and the damping will
degrade.
Figure 4.7
Illustration of the
steady-state tracking
error and the effect of
the different
proportional feedback
gain values on the
system damping
1.2
1
0.8
0.6
y(t)
0.4
0.2
00
2
4
6
y = r
kp = 6
kp = 1.5
Time (sec)
8
10

198
Chapter 4 A First Analysis of Feedback
For systems beyond second order, the situation is more complicated
than that illustrated above. The damping of some of the poles might increase
while decreasing in others as the gain is increased. Also, a higher gain will
increase the speed of response but typically at the cost of a larger transient
overshoot and less overall damping. For systems of large order, increasing
proportional gain will typically lead to instability for a high enough gain.
AnyType 0 system with proportional control will have a nonzero steady-state
offset in response to a constant reference input and will not be capable of
completely rejecting a constant disturbance input. One way to improve the
steady-state accuracy of control without using extremely high proportional
gain is to introduce integral control, which we will discuss next.
4.3.2
Integral Control (I)
When a feedback control signal is linearly proportional to the integral of
the system error, we call the result Integral feedback. The goal of integral
Integral control
control is to minimize the steady-state tracking error and the steady-state
output response to disturbances. This control law is of the form
u(t) = kI
 t
t0
e(τ) dτ,
(4.62)
and kI is called the integral gain. This means that the control signal at
each instant of time is a summation of all past values of the tracking error;
therefore, the control action is based on the "history" of the system error.
Figure 4.8 illustrates that the control signal at any instant of time is propor-
tional to the area under the system error curve (shown here for time t1). The
controller becomes
U(s)
E(s) = Dcl(s) = kI
s ,
(4.63)
which is dynamic and we see that it has inﬁnite gain at DC (that is, for s = 0).
Hence, we would certainly expect superior performance in the steady state
from such a controller. That is indeed the case as illustrated below. This
feedback has the primary virtue that it can provide a ﬁnite value of control
with zero system error. This comes about because u(t) is a function of all
past values of e(t) rather than just the current value, as in the proportional
case. This feature means that constant disturbances can be canceled with
zero error because e(t) no longer has to be ﬁnite to produce a control signal
that will counteract the constant disturbance.
Again, assume that we have the plant G(s) under integral control as
shown in Fig. 4.2 and that G(s) is for the same motor that we used in
Section 4.3.1. This simple system can be stabilized by integral control alone.
From Fig. 4.2 and using the controller in Eq. (4.63), we see that the tracking
error, the control signal, and the output due to a reference input are given by
E(s)
R(s) =
1
1 + kI
s G(s)
=
s
s + kIG(s),
U(s)
R(s) =
kI
s
1 + kI
s G(s)
=
kI
s + kIG(s),
(4.64)

4.3 The Three-Term Controller: PID Control
199
Figure 4.8
Integral control is
based on the history of
the system error
1
0.8
0.6
0.4
0.2
0
e(t)
-0.2
-0.40
5
t1
10
Time (sec)
Area
15
20
u(t1) = k1 µ e(t) dt = k1 · area
t1
0
Y(s)
R(s) = T (s) =
kI
s G(s)
1 + kI
s G(s)
=
kIG(s)
s + kIG(s).
(4.65)
Now assume a unit-step reference input r(t) = 1(t) with R(s) = 1/s.
From Eqs. (4.64) and (4.65) and using the Final Value Theorem (noting that
G(0) = 1), we have
y(∞) =
kIG(0)
0 + kIG(0) = 1,
e(∞) =
0
0 + kIG(0) = 0,
(4.66)
u(∞) =
kI
0 + kIG(0) = G(0)−1 = 1.
(4.67)
Note that the steady-state tracking error will be zero no matter what the value
of kI is, whereas there was always a tracking error with the proportional
controller no matter what the value of kP was. The integral gain kI can
be selected purely to provide an acceptable dynamic response; however,
typically it will cause instability if raised sufﬁciently high. Note also that
the steady-state control is a constant and is equal to the inverse DC gain of
the plant which makes a lot of sense intuitively.
The output and the control signal due to a disturbance input are given by
Y(s)
W(s) =
sG(s)
s + kIG(s),
U(s)
W(s) = −
kIG(s)
s + kIG(s).
(4.68)
Now assume a unit-step disturbance input w(t) = 1(t) with W(s) = 1/s.
From Eq. (4.68) and using the Final Value Theorem we have

200
Chapter 4 A First Analysis of Feedback
Figure 4.9
Illustration of constant
disturbance rejection
property of integral
control: (a) system
output; (b) control
effort
1
0.5
0
y(t)
0
5
10
15
Time (sec)
20
25
30
-0.5
0
-0.5
-1
u(t)
0
5
10
15
Time (sec)
20
25
30
-1.5
(a)
(b)
y(∞) =
0 · G(0)
0 + kIG(0) = 0,
u(∞) = −
kIG(0)
0 + kIG(0) = −1.
(4.69)
These two equations show a zero steady-state error in the output and a ﬁnal
value of the control signal that cancels the disturbance exactly. Figure 4.9
illustrates the responses for kI = 0.5. The conclusion is that in this case,
integral feedback results in zero steady-state output error in both tracking
and disturbance rejection. Furthermore, plant parameter changes can be
tolerated; that is, the results above are independent of the plant parameter
values. Also, regardless of the value of the integral gain, kI, the asymptotic
tracking and disturbance rejection properties are preserved provided that the
closed-loop system remains stable. These properties of integral control are
referredtoasrobust. TheadditionofintegralcontroltotheG(s)abovecaused
Robustness property
of integral control
the closed-loop system to become Type 1 and those features will occur for
any Type 1 system. However, as already discussed in Section 4.2.2, Type 1
systems do have a constant tracking error to a ramp reference input as will
this example of integral control.
Given these remarkable properties of integral control, it is certainly
worth the additional cost in implementation complexity. Whenever an actu-
ator is used that can saturate (which is almost always the case), extra care
is required in implementing integral control. The controller must be aug-
mented with an anti-windup feature to deal with the actuator saturation (see
Chapter 9).

4.3 The Three-Term Controller: PID Control
201
4.3.3
Derivative Control (D)
The ﬁnal term in the classical controller is Derivative feedback, also called
Derivative control
rate feedback. The goal of derivative feedback is to improve closed-loop
system stability as well as speeding up the transient response and reducing
overshoot. Therefore, whenever increased stability is desired, the use of
derivative feedback is called for. In derivative feedback, the control law is
u(t) = kD˙e(t),
(4.70)
where kD is the derivative gain and the control signal is proportional to the
rate of change (or derivative) of the system error for which the Dcl(s) in
Fig. 4.2 becomes
U(s)
E(s) = Dcl(s) = kDs.
(4.71)
Derivative control is almost never used by itself; it is usually augmented by
proportional control. The key reason is that the derivative does not supply
information on the desired end state. In addition, if e(t) were to remain con-
stant, the output of a derivative controller would be zero and a proportional
or integral control would be needed to provide a control signal at this time. A
key feature of derivative control is that derivative control "knows" the slope
of the error signal, so it takes control action based on the trend in the error
signal. Hence it is said to have an "anticipatory" behavior. One disadvantage
of derivative control is that it tends to amplify noise, a subject that will be
discussed in more depth in Chapter 6.
An important effect of the derivative term is that it gives a sharp response
to suddenly changing signals. Because of this, the derivative term is some-
times introduced into the feedback path as shown in Fig. 4.10(a) in order to
eliminate an excessive response to a step in the reference input. This could
be either a part of the standard controller or could describe a velocity sensor
such as a tachometer on the shaft of a motor. The closed-loop characteristic
equation is the same as if the term were in the forward path as given by
Eq. (4.55) and drawn in Fig. 4.10(b). It is important to notice that the zeros
from the reference to the output are different in the two cases. With the
derivative in the feedback path, the reference is not differentiated, which is
how the undesirable response to sudden changes is avoided.
4.3.4
Proportional Plus Integral Control (PI)
Adding an integral term to the proportional controller to achieve the lower
steady-state errors results in the proportional plus integral (PI) control
equation in the time domain:
Proportional plus integral
control
u(t) = kPe(t) + kI
 t
t0
e(τ) dτ,
(4.72)
for which the Dcl(s) in Fig. 4.2 becomes
U(s)
E(s) = Dcl(s) = kP + kI
s .
(4.73)

202
Chapter 4 A First Analysis of Feedback
Figure 4.10
Block diagram of the
PID controller: (a) with
the D-term in the
feedback path; (b) with
the D-term in the
forward path
(a)
G(s)
+
-
Y
W
U
R
-
+
+
kDs
kP + s
kI
(b)
G(s)
+
-
Y
W
U
R
+
+
kP  + s
kI +kDs
©
©
©
©
Most controllers implemented in practice, if they have an integral term, will
also have a proportional term. This combination generally allows for a faster
response than a pure integral control alone. Introduction of the integral term
raises the type to Type 1 and the system can therefore reject completely
constant bias disturbances. If the system is second order or higher the use of
PID control is required if we wish to have arbitrary dynamics.
4.3.5
PID Control
Putting all the three terms together results in the proportional plus integral
plus derivative (PID) control equation in the time domain:
PID control
u(t) = kPe(t) + kI
 t
t0
e(τ) dτ + kD˙e(t),
(4.74)
for which the Dcl(s) in Fig. 4.2 becomes
U(s)
E(s) = Dcl(s) = kP + kI
s + kDs.
(4.75)
To illustrate the effect of PID control, consider speed control but with the
second-order plant as in Eq. (4.58). In that case, the characteristic equation
from 1 + GDcl = 0 becomes
s2 + a1s + a2 + A(kP + kI
s + kDs) = 0,
s3 + a1s2 + a2s + A(kPs + kI + kDs2) = 0.
(4.76)
Collecting like powers of s terms results in
s3 + (a1 + AkD)s2 + (a2 + AkP)s + AkI = 0.
(4.77)

4.3 The Three-Term Controller: PID Control
203
The point here is that this equation, whose three roots determine the nature of
the dynamic response of the system, has three free parameters in kP, kI, and
kD and that by selection of these parameters, the roots can be uniquely and,
in theory, arbitrarily determined. Without the derivative term, there would
be only two free parameters, but with three roots, the choice of roots of
the characteristic equation would be restricted. To illustrate the effect more
concretely, a numerical example is useful.
EXAMPLE 4.5
PID Control of Motor Speed
Consider the DC motor speed control with parameters4
Jm = 1.13 × 10−2
b = 0.028 N·m·sec/rad,
La = 10−1 H,
N·m· sec2 /rad,
Ra = 0.45 	,
Kt = 0.067 N·m/amp,
Ke = 0.067 V·sec/rad.
(4.78)
These parameters were deﬁned in Example 2.14 in Chapter 2. Use the
controller parameters
kP = 3,
kI = 15 sec,
kD = 0.3 sec
(4.79)
and discuss the responses of this system to steps in a disturbance torque and
steps in the reference input using the three different controllers: P, PI, and
PID. Let the unused controller parameters be zero.
Solution. Figure 4.11(a) illustrates the effects of P, PI, and PID feedback
on the step disturbance response of the system. Note that adding the inte-
gral term increases the oscillatory behavior but eliminates the steady-state
-6
8
6
4
2
0
-2
-4
Amplitude
0
1
2
3
4
5
6
Time (msec)
(a)
0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
Amplitude
0
1
2
3
4
5
6
Time (msec)
(b)
P
PI
PID
P
PI
PID
Figure 4.11
Responses of P, PI, and PID control to: (a) step disturbance input; (b) step reference input
4These values have been scaled to measure time in milliseconds by multiplying the true La and
Jm by 1000 each.

204
Chapter 4 A First Analysis of Feedback
error and that adding the derivative term reduces the oscillation while main-
taining zero steady-state error. Figure 4.11(b) illustrates the effects of P, PI,
and PID feedback on the step reference response with similar results. The
step responses can be computed by forming the numerator and denominator
coefﬁcient vectors (in descending powers of s) and using the step function
in Matlab.
EXAMPLE 4.6
PI Control for a DC Motor Position Control
Consider the simpliﬁed model of a DC motor in unity feedback as shown in
Fig. 4.6 where the disturbance torque is labeled W(s). Let the sensor be −h
rather than −1.
(a) Use the proportional controller
Dc(s) = kP,
(4.80)
and determine the system type and steady-state error properties with respect
to disturbance inputs.
(b) Let the control be PI as given by
Dc(s) = kP + kI
s ,
(4.81)
and determine the system type and the steady-state error properties for
disturbance inputs.
Solution.
(a) The closed-loop transfer function from W to E (where
R = 0) is
Tw(s) = −
B
s(τs + 1) + AkPh,
= s0To,w,
n = 0,
Ko,w = −AkPh
B
.
Applying Eq. (4.48) we see that the system is Type 0 and the steady-state
error to a unit-step torque input is ess = −B/AkP. From the earlier section,
this system is seen to beType 1 for reference inputs and illustrates that system
type can be different for different inputs to the same system. However, in
this case the system is Type 0 for reference inputs.
(b) If the controller is PI, the disturbance error transfer function is
Tw(s) = −
Bs
s2(τs + 1) + (kPs + kI)Ah,
(4.82)
n = 1,
(4.83)
Kn,w = −AkIh
B ,
(4.84)

4.3 The Three-Term Controller: PID Control
205
and therefore the system is Type 1 and the error to a unit-ramp disturbance
input in this case will be
ess = −B
AkIh.
(4.85)
EXAMPLE 4.7
Satellite Attitude Control
Consider the model of a satellite attitude control system shown in Fig. 4.12(a)
where
J = moment of inertia,
W = disturbance torque,
K = sensor and reference gain,
Dc(s) = the compensator.
With equal input ﬁlter and sensor scale factors, the system with PD control
can be redrawn with unity feedback as in Fig. 4.12(b) and with PID control
drawn as in Fig. 4.12(c). Assume that the control results in a stable system
and determine the system types and error responses to disturbances of the
control system for
(a) System Fig. 4.12(b) Proportional plus derivative control where Dc(s) =
kP + kDs,
(b) System Fig. 4.12(c) Proportional plus integral plus derivative control
where Dc(s) = kP + kI/s + kDs.5
Solution. (a) We see from inspection of Fig. 4.12(b) that with two poles at
the origin in the plant, the system is Type 2 with respect to reference inputs.
The transfer function from disturbance to error is
Tw(s) =
1
Js2 + kDs + kP
,
(4.86)
= To,w(s),
(4.87)
for which n = 0 and Ko,w = kP. The system is Type 0 and the error to a unit
disturbance step is 1/kP.
(b) With PID control, the forward gain has three poles at the origin,
so this system is Type 3 for reference inputs but the disturbance transfer
function is
Tw(s) =
s
Js3 + kDs2 + kPs + kI
,
(4.88)
n = 1,
(4.89)
To,w(s) =
1
Js3 + kDs2 + kPs + kI
,
(4.90)
5Notice that these controller transfer functions have more zeros than poles and are therefore
not practical. In practice, the derivative term would have a high-frequency pole, which has been
omitted for simplicity in these examples.

206
Chapter 4 A First Analysis of Feedback
Figure 4.12
Model of a satellite
attitude control:
(a) basic system; (b) PD
control; (c) PID control
(a)
R
+
+
+
-
Dc(s)
W
K
K
U
Js
1
s
1
u = Y
u
(b)
R
+
+
+
+
W
Js2
1
Y
-1.0
kp + kDs
(c)
R
+
 + 
 + 
+
W
Js2
1
Y
 -1.0
kp + 
+ kDs
s
kI
©
©
©
©
©
©
from which the system is Type 1 and the error constant is kI; so the error to
a disturbance ramp of unit slope will be 1/kI.
4.3.6
Ziegler-Nichols Tuning of the PID Controller
When the PID controller was being developed, selecting values for the sev-
eral terms (known as "tuning" the controller) was often a hit and miss affair.
To bring order to the situation and make life easier for plant operators, control
engineers looked for ways to make the tuning more systematic. Callender
et al. (1936) proposed a design for PID controllers by specifying satisfac-
tory values for the terms based on estimates of the plant parameters that an
operating engineer could make from experiments on the process itself. This
approach was extended by Ziegler and Nichols (1942, 1943) who recognized
that the step responses of a large number of process control systems exhibit a
process reaction curve like that shown in Fig. 4.13, which can be generated

4.3 The Three-Term Controller: PID Control
207
Figure 4.13
Process reaction curve
t
y(t)
L = td
Lag
t
A
t
A
Slope R = A
t  = Reaction rate
from experimental step response data. The S-shape of the curve is charac-
teristic of many systems and can be approximated by the step response of a
Transfer function for a
high-order system with a
characteristic process
reaction curve
plant with transfer function
Y(s)
U(s) = Ae−std
τs + 1,
(4.91)
which is a ﬁrst-order system with a time delay or "transportation lag" of
td sec. The constants in Eq. (4.91) can be determined from the unit-step
response of the process. If a tangent is drawn at the inﬂection point of the
reaction curve, then the slope of the line is R = A/τ, the intersection of the
tangent line with the time axis identiﬁes the time delay L = td and the ﬁnal
value gives the value of A.6
Ziegler and Nichols gave two methods for tuning the PID controller
for such a model. In the ﬁrst method the choice of controller parameters is
designed to result in a closed-loop step response transient with a decay ratio
of approximately 0.25. This means that the transient decays to a quarter of its
Tuning by decay ratio of
0.25
value after one period of oscillation, as shown in Fig. 4.14. A quarter decay
corresponds to ζ = 0.21 and, while low for many applications, was seen
as a reasonable compromise between quick response and adequate stability
margins for the process controls being considered. The authors simulated the
equations for the system on an analog computer and adjusted the controller
parameters until the transients showed the decay of 25% in one period. The
regulator parameters suggested by Ziegler and Nichols for the controller
terms deﬁned by
Dc(s) = kP

1 + 1
TIs + TDs

,
(4.92)
are given in Table 4.2.
In the ultimate sensitivity method the criteria for adjusting the
Tuning by evaluation at
limit of stability (ultimate
sensitivity method)
parameters are based on evaluating the amplitude and frequency of the
oscillations of the system at the limit of stability rather than on taking a
step response. To use the method, the proportional gain is increased until
6K. J. Åström and others have pointed out that a time constant, τ, can also be estimated from
the curve and claim that a more effective tuning can be done by including that parameter.

208
Chapter 4 A First Analysis of Feedback
Figure 4.14
Quarter decay ratio
0.25
1
Period
t
y(t)
TABLE 4.2
Ziegler-Nichols Tuning for the Regulator
Dc(s) = kP(1 + 1/TIs + TDs), for a Decay Ratio of 0.25
Type of Controller
Optimum Gain
P
kP = 1/RL
PI
 kP = 0.9/RL
TI = L/0.3
PID
⎧
⎨
⎩
kP = 1.2/RL
TI = 2L
TD = 0.5L
Figure 4.15
Determination of
ultimate gain and
period
 + 
 - 
Process
r
y
Ku
e
©
the system becomes marginally stable and continuous oscillations just begin
with amplitude limited by the saturation of the actuator. The corresponding
gain is deﬁned as Ku (called the ultimate gain) and the period of oscilla-
tion is Pu (called the ultimate period). These are determined as shown in
Figs. 4.15 and 4.16. Pu should be measured when the amplitude of oscil-
lation is as small as possible. Then the tuning parameters are selected as
shown in Table 4.3.
Experience has shown that the controller settings according to Ziegler-
Nichols rules provide acceptable closed-loop response for many systems.
As seen from the ensuing examples, the step response method generally
suggests gains that are higher than the ultimate sensitivity method. The
process operator will often do ﬁnal tuning of the controller iteratively on the
actual process to yield satisfactory control.

4.3 The Three-Term Controller: PID Control
209
Figure 4.16
Neutrally stable system
Impulse response
0
20
40
60
80
100
120
0.010
0.008
0.006
0.004
0.002
0.00
-0.002
-0.004
-0.006
-0.008
-0.010
Time (sec)
TABLE 4.3
Ziegler-Nichols Tuning for the Regulator
Dc(s) = kP(1 + 1/TIs + TDs), Based on the Ultimate
Sensitivity Method
Type of Controller
Optimum Gain
P
kP = 0.5Ku
PI
 kP = 0.45Ku
TI = Pu
1.2
PID
⎧
⎨
⎩
kP = 1.6Ku
TI = 0.5Pu
TD = 0.125Pu
EXAMPLE 4.8
Tuning of a Heat Exchanger: Quarter Decay Ratio
Consider the heat exchanger discussed in Chapter 2. The process reaction
curve of this system is shown in Fig. 4.17. Determine proportional and PI
regulator gains for the system using the Ziegler-Nichols rules to achieve a
quarter decay ratio. Plot the corresponding step responses.
Solution. From the process reaction curve we measure the maximum slope
to be R ∼=
1
90 and the time delay to be L ∼= 13 sec. According to the
Ziegler-Nichols rules of Table 4.2 the gains are
Proportional : kP = 1
RL = 90
13 = 6.92,
PI : kP = 0.9
RL = 6.22
and
TI = L
0.3 = 13
0.3 = 43.3.
Figure 4.18(a) shows the step responses of the closed-loop system to these
two regulators. Note that the proportional regulator results in a steady-state

210
Chapter 4 A First Analysis of Feedback
Figure 4.17
A measured process
reaction curve
0.0
100.0
200.0
300.0
400.0
Time (sec)
1.2
1.0
0.8
0.6
0.4
0.2
0
y
y
y
400.0
300.0
200.0
100.0
0.0
Time (sec)
(b)
400.0
300.0
200.0
100.0
0.0
Time (sec)
(a)
PI
PI
Proportional
Proportional
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
Figure 4.18
Closed-loop step responses
offset, while the PI regulator tracks the step exactly in the steady state.
Both regulators are rather oscillatory and have considerable overshoot. If
we arbitrarily reduce the gain kP by a factor of 2 in each case, the overshoot
and oscillatory behaviors are substantially reduced, as shown in Fig. 4.18(b).
EXAMPLE 4.9
Tuning of a Heat Exchanger: Oscillatory Behavior
Proportional feedback was applied to the heat exchanger in the previous
example until the system showed nondecaying oscillations in response to a
short pulse (impulse) input, as shown in Fig. 4.19. The ultimate gain is mea-
sured to be Ku = 15.3, and the period was measured at Pu = 42 sec.

4.3 The Three-Term Controller: PID Control
211
Determine the proportional and PI regulators according to the Ziegler-
Nichols rules based on the ultimate sensitivity method. Plot the correspond-
ing step responses.
Solution. The regulators from Table 4.3 are
Proportional : kP = 0.5Ku,
kP = 7.65,
PI : kP = 0.45Ku,
kP = 6.885,
and
TI = 1
1.2Pu = 35.
The step responses of the closed-loop system are shown in Fig. 4.20(a). Note
that the responses are similar to those in Example 4.8. If we reduce kP by
50%, then the overshoot is substantially reduced, as shown in Fig. 4.20(b).
Figure 4.19
Ultimate period of heat
exchanger
Impulse response
0
20
40
60
80
100
120
0.010
0.008
0.006
0.004
0.002
0.00
-0.002
-0.004
-0.006
-0.008
-0.010
Time (sec)
y
y
400.0
300.0
200.0
100.0
0.0
Time (sec)
(b)
400.0
300.0
200.0
100.0
0.0
Time (sec)
(a)
PI
PI
Proportional
Proportional
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
Figure 4.20
Closed-loop step responses

212
Chapter 4 A First Analysis of Feedback
Thisshowsthatthetuningrulesprovideagoodstartingpointbutconsiderable
ﬁne tuning may still be needed.
4.4
Feedforward Control by Plant Model Inversion
Section 4.3 showed that proportional control typically yields a steady-state
error in the output due to disturbances or input commands. Integral control
was introduced in order to reduce those errors to zero for steady distur-
bances or constant reference commands; however, integral control typically
decreases the damping or stability of a system. One way to partly resolve this
conﬂict is to provide some feedforward of the control that will eliminate
Feedforward
the steady-state errors due to command inputs. This is possible because the
command inputs are known and can be determined directly by the controller;
thus, we should be able to compute the value of the control input that will
produce the desired outputs being commanded. Disturbances are not always
measurable, but can also be used for feedforward control whenever they are
measured. The solution is simply to determine the inverse of the DC gain of
the plant transfer function model and incorporate that into the controller as
shown in Fig. 4.21. If this is done, the feedforward will provide the control
Figure 4.21
Feedforward control
structure for:
(a) tracking;
(b) disturbance
rejection
R
Compensator
Plant
inverse
DC gain
Plant
Y
G-1(0)
G(s)
+
+
+
-
©
©
Dc(s)
U
(a)
R
Compensator
Plant
inverse
DC gain
Plant
U
Y
W
G-1(0)
G(s)
+
+
-
-
©
©
©
Dc(s)
(b)

4.4 Feedforward Control by Plant Model Inversion
213
effort required for the desired command input and the feedback takes care
of the differences between the real plant and the plant model plus the effects
of any disturbances.
EXAMPLE 4.10
Feedforward Control for DC Motor
Consider the same DC motor speed-control system (Eq. 4.58) of Section 4.3
with the two different values of proportional controller gain kP = 1.5, 6.
(a) Use feedforward control to eliminate the steady-state tracking error for a
step reference input. (b) Also use feedforward control to eliminate the effect
of a constant output disturbance signal on the output of the system.
Solution.
(a) In this case the plant inverse DC gain is G−1(0) = 1. We
implement the closed-loop system as shown in Fig. 4.21(a) with G(s) given
by Eq. (4.58) and Dc(s) = kP. The closed-loop transfer function is
Y(s) = G(s)[kPE(s) + R(s)],
E(s) = R(s) −Y(s),
Y(s)
R(s) = T (s) = (1 + kP)G(s)
1 + kPG(s) .
Note that the closed-loop DC gain is unity (T (0) = 1). Figure 4.22 illustrates
the effect of feedforward control in eliminating the steady-state tracking
error due to a step reference input for the two values of kP. Addition of the
feedforward control results in zero steady-state tracking error.
Figure 4.22
Tracking performance
with addition of
feedforward
0
0
0.5
y(t)
1
1.5
kp = 1.5
kp = 6
2
4
Time (sec)
Tracking response
6
8
10

214
Chapter 4 A First Analysis of Feedback
Figure 4.23
Constant disturbance
rejection performance
with addition of
feedforward
Disturbance rejection response
0
2
4
6
8
10
−0.5
0
0.5
1
Time (sec)
y(t)
kp = 1.5
kp = 6
(b) Similarly, we implement the closed-loop system as shown in
Fig. 4.21(b) with G(s) given by Eq. (4.58) and Dc(s) = kP. The closed-loop
transfer function is
Y(s) = W(s) + G(s)[kPE(s) −W(s)],
E(s) = R(s) −Y(s), with R(s) = 0,
Y(s)
W(s) = Tw(s) =
1 −G(s)
1 + kPG(s).
Note that the closed-loop DC gain is zero (Tw(s) = 0). Figure 4.23 illustrates
the effect of feedforward control in eliminating the steady-state error for a
constant output disturbance, again for the two values of kP. We observe
that by using the inverse of the DC gain, this feedforward only controls the
steady-state effect of the reference and disturbance inputs. More complex
feedforward control can be used by inverting G(s) over an entire frequency
range.
4.5
Introduction to Digital Control
So far, we have assumed that the systems and controllers are all continuous
△
time systems and that they obey differential equations. That implies that the
controllers would be implemented using analog circuits such as those dis-
cussed in Section 2.2. In fact, most control systems today are implemented in
digital computers which are not able to implement the continuous controllers

4.7 Historical Perspective
215
exactly. Instead, they approximate the continuous control by algebraic equa-
tions called difference equations. A very short description of how one would
convert a continuous Dc(s) to difference equations that can be coded directly
into a computer is contained inAppendixW4.5 at www.fpe7e.com. For more
details, see Chapter 8 in this text or see Digital Control of Dynamic Systems,
by Franklin, Powell, and Workman, 3rd ed, 1998, for a complete discussion
of the topic.
4.6
Sensitivity of Time Response to Parameter
Change
Since many control speciﬁcations are in terms of the step response, the
△
sensitivity of the time response to parameter changes is sometimes very
useful to explore. To learn more see Appendix W4.6 at www.fpe7e.com.
4.7
Historical Perspective
The ﬁeld of control is characterized by two paths: theory and practice.
Control theory is basically the application of mathematics to solve control
problems, whereas control practice, as used here, is the practical appli-
cation of feedback in devices where it is found to be useful. Historically,
practical applications have come ﬁrst with control being introduced by trial
and error. Although the applicable mathematics is often known, the theory
describing how the control works and pointing the way to improvements
has typically been applied later. For example, James Watt's company began
manufacturing steam engines using the ﬂy-ball governor in 1788 but it was
not until 1840 that G. B.Airy described instability in a similar device and not
until 1868 when J. C. Maxwell published "On Governors" with a theoretical
description of the problem. Then it was not until 1877, almost 100 years
after the steam engine control was introduced, that E. J. Routh published a
solution giving the requirements for stability. This situation has been called
the "Gap between Theory and Practice" and continues to this day as a source
of creative tension that stimulates both theory and practice.
Regulation is central to the process industries, from making beer to
making gasoline. In these industries, there are a host of variables that need
to be kept constant. Typical examples are temperature, pressure, volume,
ﬂow rates, composition, and chemical properties such as pH level. However,
before one can regulate by feedback, one must be able to measure the variable
of interest. Before there was control, there were sensors. In 1851, George
Taylor and David Kendall founded the company that later became the Taylor
Instrument Company in Rochester, NY, to make thermometers and baro-
meters for weather forecasting. In 1855 they were making thermometers for
several industries, including the brewing industry where they were used for
manual control. Other early entries into the instrument ﬁeld were the Bristol
Company, founded in Naugatuck, CT, in 1889 by William Bristol, and the
Foxboro Company, founded in Foxboro, MA, in 1908 by William's father

216
Chapter 4 A First Analysis of Feedback
and two of his brothers. For example, one of Bristol's instruments was used
by Henry Ford to measure (and presumably control) steam pressure while
he worked at the Detroit Edison Company. The Bristol Company pioneered
in telemetry that permitted instruments to be placed at a distance from the
process so a plant manager could monitor several variables at once. As the
instruments became more sophisticated, and devices such as motor-driven
valves became available, they were used in feedback control often using
simple on-off methods as described in Chapter 1 for the home furnace. An
important fact was that the several instrument companies agreed upon stan-
dards for the variables used so a plant could mix and match instruments and
controllers from different suppliers. In 1920, Foxboro introduced a controller
based on compressed air that included reset or integral action. Eventually,
each of these companies introduced instruments and controllers that could
implement full PID action. A major step was taken for tuning PID con-
trollers in 1942 when Ziegler and Nichols, working for Taylor Instruments,
published their method for tuning based on experimental data.
The poster child for the tracking problem was that of the anti-aircraft
gun, whether on land or at sea. The idea was to use radar to track the target
and to have a controller that would predict the path of the aircraft and aim the
gun to a position such that the projectile would hit the target when it got there.
The Radiation Laboratory was set up at MIT during World War II to develop
such radars, one of which was the SCR-584. Interestingly, one of the major
contributors to the control methods developed for this project was none other
than Nick Nichols who had earlier worked on tuning PID controllers. When
the record of the Rad Lab was written, Nichols was selected to be one of the
editors of volume 25 on control.
H. S. Black joined Bell Laboratories in 1921 and was assigned to ﬁnd
a design for an electronic ampliﬁer suitable for use as a repeater on the
long lines of the telephone company. The basic problem was that the gain
of the vacuum tube components he had available drifted over time and he
needed a design that, over the audio frequency range, maintained a speciﬁc
gain with great precision in the face of these drifts. Over the next few years
he tried many approaches, including a feed forward technique designed to
cancel the tube distortion. While this worked in the laboratory, it was much
too sensitive to be practical in the ﬁeld. Finally, in August of 1927,7 while
on the ferry boat from Staten Island to Manhattan, he realized that negative
feedback might work and he wrote the equations on the only paper available,
a page of the New York Times. He applied for a patent in 1928 but it was
not issued until December 1937.8 The theory of sensitivity and many other
theories of feedback were worked out by H. W. Bode.
7Black was 29 years old at the time.
8According to the story, many of Black's colleagues at the Bell laboratories did not believe it
was possible to feed back a signal 100 times as large as was the input and still keep the system
stable. As will be discussed in Chapter 6, this dilemma was solved by H. Nyquist, also at the
labs.

Summary
217
SUMMARY
•
The most important measure of the performance of a control system is
the system error to all inputs.
•
Compared to open-loop control, feedback can be used to stabilize an
otherwise unstable system, to reduce errors to plant disturbances, to
improve the tracking of reference inputs, and to reduce the system's
transfer function sensitivity to parameter variations.
•
Sensor noise introduces a conﬂict between efforts to reduce the error
caused by plant disturbances and efforts to reduce the errors caused by
the sensor noise.
•
Classifying a system as Type k indicates the ability of the system to
achieve zero steady-state error to polynomials of degree less than but
not equal to k. A stable unity feedback system is Type k with respect to
reference inputs if the loop gain G(s)Dc(s) has k poles at the origin in
which case we can write
G(s)Dc(s) = A(s + z1)(s + z2) · · ·
sk(s + p1)(s + p2) · · ·,
and the error constant is given by
Kk = lim
s→0skG(s)Dc(s) = Az1z2 · · ·
p1p2 · · · .
(4.93)
•
A table of steady-state errors for unity feedback systems of Types 0, 1,
and 2 to reference inputs is given in Table 4.1.
•
Systems can be classiﬁed as to type for rejecting disturbances by com-
puting the system error to polynomial disturbance inputs. The system is
Type k to disturbances if the error is zero to all disturbance polynomials
of degree less than k but nonzero for a polynomial of degree k.
•
Increasing the proportional feedback gain reduces steady-state errors
but high gain almost always destabilizes the system. Integral control
provides robust reduction in steady-state errors, but also may make the
system less stable. Derivative control increases damping and improves
stability. These three kinds of control combined to form the classical
three-term PID controller.
•
The standard PID controller is described by the equations
U(s) =

kP + kI
s + kDs

E(s)
or
U(s) = kP

1 + 1
TIs + TDs

E(s) = Dc(s)E(s).
This latter form is ubiquitous in the process-control industry and
describes the basic controller in many control systems.
•
UsefulguidelinesfortuningPIDcontrollerswerepresentedinTables4.2
and 4.3.
•
Matlab can compute a discrete equivalent with the command c2d.

218
Chapter 4 A First Analysis of Feedback
REVIEW QUESTIONS
4.1
Give three advantages of feedback in control.
4.2
Give two disadvantages of feedback in control.
4.3
A temperature control system is found to have zero error to a constant tracking
input and an error of 0.5◦C to a tracking input that is linear in time, rising at
the rate of 40◦C/ sec. What is the system type of this control system and what
is the relevant error constant (Kp or Kv or Ka)?
4.4
What are the units of Kp, Kv, and Ka?
4.5
What is the deﬁnition of system type with respect to reference inputs?
4.6
What is the deﬁnition of system type with respect to disturbance inputs?
4.7
Why does system type depend on where the external signal enters the system?
4.8
What is the main objective of introducing integral control?
4.9
What is the major objective of adding derivative control?
4.10
Why might a designer wish to put the derivative term in the feedback rather
than in the error path?
4.11
What is the advantage of having a "tuning rule" for PID controllers?
4.12
Give two reasons to use a digital controller rather than an analog controller.
4.13
Give two disadvantages to using a digital controller.
4.14
Give the substitution in the discrete operator z for the Laplace operator s if
the approximation to the integral in Eq. (8) in Appendix W4.5 is taken to be
the rectangle of height e(kTs) and base Ts.
PROBLEMS
Problems for Section 4.1: The Basic Equations of Control
4.1
If S is the sensitivity of the unity feedback system to changes in the plant
transfer function and T is the transfer function from reference to output, show
that S + T = 1.
4.2
We deﬁne the sensitivity of a transfer function G to one of its parameters k as
the ratio of percent change in G to percent change in k.
SG
k = dG/G
dk/k = d ln G
d ln k = k
G
dG
dk .
The purpose of this problem is to examine the effect of feedback on sensitivity.
In particular, we would like to compare the topologies shown in Fig. 4.24 for
connecting three ampliﬁer stages with a gain of −K into a single ampliﬁer
with a gain of −10.
(a) For each topology in Fig. 4.24, compute βi so that if K = 10, Y = −10R.
(b) For each topology, compute SG
k when G = Y
R . (Use the respective βi
values found in part (a).) Which case is the least sensitive?
(c) Compute the sensitivities of the systems in Fig. 4.24(b,c) to β2 and β3.
Using your results, comment on the relative need for precision in sensors
and actuators.

Problems
219
Figure 4.24
Three-ampliﬁer
topologies for
Problem 4.2
b1
R
Y
-K
-K
-K
(a)
(b)
(c)
R
Y
-K
-K
-K
+
+
b3
+
+
R
-K
+
+
-K
b2
+
+
-K
Y
b2
b2
©
©
©
©
4.3
Compare the two structures shown in Fig. 4.25 with respect to sensitivity
to changes in the overall gain due to changes in the ampliﬁer gain. Use the
relation
S = d ln F
d ln K = K
F
dF
dK ,
as the measure. Select H1 and H2 so that the nominal system outputs satisfy
F1 = F2, and assume KH1 > 0.
+
-
R
H1
K
+
-
H1
K
F1
(a)
+
-
R
H2
K
K
F2
(b)
©
©
©
Figure 4.25
Block diagrams for Problem 4.3
4.4
A unity feedback control system has the open-loop transfer function
G(s) =
A
s(s + a).
(a) Compute the sensitivity of the closed-loop transfer function to changes in
the parameter A.
(b) Compute the sensitivity of the closed-loop transfer function to changes in
the parameter a.

220
Chapter 4 A First Analysis of Feedback
(c) If the unity gain in the feedback changes to a value of β ̸= 1, compute
the sensitivity of the closed-loop transfer function with respect to β.
4.5
Compute the equation for the system error for the feedback system shown in
Fig. 4.5.
Problems for Section 4.2: Control of Steady-State Error
4.6
Consider the DC motor control system with rate (tachometer) feedback shown
in Fig. 4.26(a).
(a) Find values for K′ and k′t so that the system of Fig. 4.26(b) has the same
transfer function as the system of Fig. 4.26(a).
(b) Determine the system type with respect to tracking θr and compute the
system Kv in terms of parameters K′ and k′t.
(c) Does the addition of tachometer feedback with positive kt increase or
decrease Kv?
+
+
-
u
ur
(a)
Kp
-
K
k
1
Km
s(1 + tms)
kts
-
u
ur
(b)
K¿
s(1 + tms)
1 + k¿ts
+
©
©
©
Figure 4.26
Control system for Problem 4.6
4.7
A block diagram of a control system is shown in Fig. 4.27.
(a) If r is a step function and the system is closed-loop stable, what is the
steady-state tracking error?
(b) What is the system type?
(c) What is the steady-state error to a ramp velocity 5.0 if K2 = 2 and K1 is
adjusted to give a system step overshoot of 17%?
Figure 4.27
Closed-loop system for
Problem 4.7
©
+
-
Y
R
©
-
+
K2s
K1 (s + 3)
(s + 10)
1
s(s + 10)
0.5
0.5
4.8
A standard feedback control block diagram is shown in Fig. 4.5 with the values
G(s) = 1
s ; Dc(s) = 2(s + 1)
s
; H(s) =
100
(s + 100).

Problems
221
(a) Let W = 0 and compute the transfer function from R to Y.
(b) Let R = 0 and compute the transfer function from W to Y.
(c) What is the tracking error if R is a unit-step input and W ≡0?
(d) What is the tracking error if R is a unit-ramp input and W ≡0?
(e) What is the system type and the corresponding error coefﬁcient?
Figure 4.28
Control system for
Problem 4.10
 + 
 - 
Dc(s)
Y
R
1
s(s + 1)
©
4.9
A generic negative feedback system with non-unity transfer function in the
feedback path is shown in Fig. 4.5.
(a) Find the steady-state tracking error for this system to a ramp reference
input.
(b) If G(s) has a single pole at the origin in the s-plane, what is the requirement
on H(s) such that the system will remain a Type 1 system?
(c) Suppose,
G(s) =
1
s(s + 1)2 ; Dcl(s) = 0.73; H(s) = 2.75s + 1
0.36s + 1,
showing a lead compensation in the feedback path. What is the value of
the velocity error coefﬁcient, Kv?
4.10
Consider the system shown in Fig. 4.28, where
Dc(s) = K (s + α)2
s2 + ω2o
.
(a) Prove that if the system is stable, it is capable of tracking a sinusoidal
reference input r = sin ωot with zero steady-state error. (Hint: Look at
the transfer function from R to E and consider the gain at ωo.)
(b) Use Routh's criterion to ﬁnd the range of K such that the closed-loop
system remains stable if ωo = 1 and α = 0.25.
4.11
Consider the system shown in Fig. 4.29, which represents control of the angle
of a pendulum that has no damping.
(a) What condition must Dc(s) satisfy so that the system can track a ramp
reference input with constant steady-state error?
Figure 4.29
Control system for
Problem 4.11
 + 
 - 
 + 
 + 
W
s2
1
Dc(s)
R
K
Y
 + 
 - 
©
©
©

222
Chapter 4 A First Analysis of Feedback
(b) For a transfer function Dc(s) that stabilizes the system and satisﬁes the
condition in part(a), ﬁnd the class of disturbances w(t) that the system
can reject with zero steady-state error.
4.12
A unity feedback system has the overall transfer function
Y(s)
R(s) = T (s) =
ω2n
s2 + 2ζωns + ω2n
.
Give the system type and corresponding error constant for tracking polynomial
reference inputs in terms of ζ and ωn.
4.13
Consider the second-order system
G(s) =
1
s2 + 2ζs + 1.
We would like to add a transfer function of the form Dc(s) = K(s+a)
(s+b) in series
with G(s) in a unity feedback structure.
(a) Ignoring stability for the moment, what are the constraints on K, a, and
b so that the system is Type 1?
(b) What are the constraints placed on K, a, and b so that the system is both
stable and Type 1?
(c) What are the constraints on a and b so that the system is both Type 1 and
remains stable for every positive value for K?
4.14
Consider the system shown in Fig. 4.30(a).
(a) What is the system type? Compute the steady-state tracking error due to
a ramp input r(t) = rot1(t).
(b) For the modiﬁed system with a feed forward path shown in Fig. 4.30(b),
give the value of Hf so the system is Type 2 for reference inputs and
compute the Ka in this case.
(c) Is the resulting Type 2 property of this system robust with respect to
changes in Hf , that is, will the system remain Type 2 if Hf changes
slightly?
Figure 4.30
Control system for
Problem 4.14
(a)
(b)
 + 
 - 
Y
R
s(vs + 1)
A
 + 
 - 
Y
 + 
 + 
R
s(vs + 1)
A
Hf s
Hr
©
©
©

Problems
223
4.15
A controller for a satellite attitude control with transfer function G=1/s2 has
been designed with a unity feedback structure and has the transfer function
Dc(s) = 10(s+2)
s+5
.
(a) Find the system type for reference tracking and the corresponding error
constant for this system.
(b) If a disturbance torque adds to the control so that the input to the process
is u + w, what is the system type and corresponding error constant with
respect to disturbance rejection?
4.16
A compensated motor position control system is shown in Fig. 4.31. Assume
that the sensor dynamics are H(s) = 1.
Figure 4.31
Control system for
Problem 4.16
Sensor
 + 
 - 
Y
R
 + 
 + 
W
1
s(s + 2)
Plant
H(s)
s + 4
s + 30
Compensator
160
©
©
(a) Can the system track a step reference input r with zero steady-state error?
If yes, give the value of the velocity constant.
(b) Can the system reject a step disturbance w with zero steady-state error?
If yes, give the value of the velocity constant.
(c) Compute the sensitivity of the closed-loop transfer function to changes in
the plant pole at −2.
(d) In some instances there are dynamics in the sensor. Repeat parts (a) to (c)
for H(s) =
20
s+20 and compare the corresponding velocity constants.
4.17
The general unity feedback system shown in Fig. 4.32 has disturbance inputs
w1, w2, and w3 and is asymptotically stable. Also,
G1(s) = K1
m1
i=1(s + z1i)
sl1 m1
i=1(s + p1i), G2(s) = K2
m1
i=1(s + z2i)
sl2 m1
i=1(s + p2i).
Show that the system is of Type 0, Type ℓ1, and Type (ℓ1 + ℓ2) with
respect to disturbance inputs w1, w2, and w3, respectively.
Figure 4.32
Single input-single
output unity feedback
system with disturbance
inputs
 + 
 - 
Y
R
 + 
 + 
W1
G1(s)
W2
 + 
 + 
W3
G2(s)
©
©
©
4.18
One possible representation of an automobile speed-control system with
integral control is shown in Fig. 4.33.

224
Chapter 4 A First Analysis of Feedback
(a) With a zero reference velocity input vc = 0, ﬁnd the transfer function
relating the output speed v to the wind disturbance w.
(b) What is the steady-state response of v if w is a unit-ramp function?
(c) What type is this system in relation to reference inputs? What is the value
of the corresponding error constant?
(d) What is the type and corresponding error constant of this system in relation
to tracking the disturbance w?
Figure 4.33
System using integral
control
 + 
 - 
 + 
W
s
m
Vc
 + 
 - 
k1
k2
s
k1E
k3
k1
F
V
©
©
4.19
For the feedback system shown in Fig. 4.34, ﬁnd the value of α that will
make the system Type 1 for K = 5. Give the corresponding velocity constant.
Show that the system is not robust by using this value of α and computing the
tracking error e = r −y to a step reference for K = 4 and K = 6.
Figure 4.34
Control system for
Problem 4.19
 + 
 - 
R
s + 2
K
Y
a
©
4.20
Suppose you are given the system depicted in Fig. 4.35(a) where the plant
parameter a is subject to variations.
(a) Find G(s) so that the system shown in Fig. 4.35(b) has the same transfer
function from r to y as the system in Fig. 4.35(a).
 + 
 - 
R
Y
s + a
1
s
1
4
1
 + 
 + 
4
 + 
 + 
U
 - 
x
(a)
 + 
 - 
R
Y
G(s)
(b)
E(t)
©
©
©
©
Figure 4.35
Control system for Problem 4.20

Problems
225
(b) Assume that a = 1 is the nominal value of the plant parameter. What are
the system type and the error constant in this case?
(c) Now assume that a = 1 + δa, where δa is some perturbation to the
plant parameter. What are the system type and the error constant for the
perturbed system?
4.21
Two feedback systems are shown in Fig. 4.36.
(a) Determine values for K1, K2, and K3 so that
(i)
both systems exhibit zero steady-state error to step inputs (that is,
both are Type 1), and
(ii) their static velocity constant Kv = 1 when K0 = 1.
(b) Suppose K0 undergoes a small perturbation: K0 →K0+δK0. What effect
does this have on the system type in each case? Which system has a type
which is robust? Which system do you think would be preferred?
 + 
 - 
Y
R
K0
4s + 1
(a)
 + 
 - 
Y
K0
4s + 1
(b)
R
K3
K2
K1
s
U
U
©
©
Figure 4.36
Two feedback systems for Problem 4.21
4.22
You are given the system shown in Fig. 4.37, where the feedback gain β is
subject to variations. You are to design a controller for this system so that the
output y(t) accurately tracks the reference input r(t).
(a) Let β =1. You are given the following three options for the controller
Dci(s):
Dc1(s) = kP,
Dc2(s) = kPs + kI
s
,
Dc3(s) = kPs2 + kIs + k2
s2
.
Choose the controller (including particular values for the controller con-
stants) that will result in a Type 1 system with a steady-state error to a
unit reference ramp of less than 1
10.
(b) Next, suppose that there is some attenuation in the feedback path that is
modeled by β = 0.9. Find the steady-state error due to a ramp input for
your choice of Dci = (s) in part (a).
(c) If β = 0.9, what is the system type for part (b)? What are the values of
the appropriate error constant?
Figure 4.37
Control system for
Problem 4.22
 + 
 - 
Y
R
Dci(s)
10
(s + 1)(s + 10)
b
a
©

226
Chapter 4 A First Analysis of Feedback
4.23
Consider the system shown in Fig. 4.38.
(a) Find the transfer function from the reference input to the tracking error.
(b) For this system to respond to inputs of the form r(t) = tn1(t) (where
n < q) with zero steady-state error, what constraint is placed on the
open-loop poles p1, p2, · · · , pq?
Figure 4.38
Control system for
Problem 4.23
 + 
 - 
Y
R
1
(s + p1)(s + p2) · · · (s + pq)
E
©
4.24
Consider the system shown in Fig. 4.39.
(a) Compute the transfer function from R(s) to E(s) and determine the steady-
state error (ess) for a unit-step reference input signal, and a unit-ramp
reference input signal.
(b) Determine the locations of the closed-loop poles of the system.
(c) Select the system parameters (k, kP, kI) such that the closed-loop system
has damping coefﬁcient ζ = 0.707 and ωn = 1. What percent overshoot
would you expect in y(t) for unit-step reference input?
(d) Find the tracking error signal as a function of time, e(t), if the reference
input to the system, r(t), is a unit-ramp.
(e) How can we select the PI controller parameters (kP, kI) to ensure that the
amplitude of the transient tracking error, |e(t)|, from part (d) is small?
(f) What is the transient behavior of the tracking error, e(t), for a unit-ramp
reference input if the magnitude of the integral gain, kI, is very large?
Does the unit-ramp response have an overshoot in that case?
Figure 4.39
Control system diagram
for Problem 4.24
©
+
-
Y
R
e
U
Plant
Controller
AkP +
B
s
kI
s
k
4.25
A linear ODE model of the DC motor with negligible armature inductance
(La = 0) and with a disturbance torque w was given earlier in the chapter; it
is restated here, in slightly different form, as
JRa
Kt
¨θm + Ke ˙θm = υa + Ra
Kt
w,
where θm is measured in radians. Dividing through by the coefﬁcient of ¨θm,
we obtain
¨θm + a1 ˙θm = b0υa + c0w,
where
a1 = KtKe
JRa
,
b0 = Kt
JRa
,
c0 = 1
J .

Problems
227
With rotating potentiometers, it is possible to measure the positioning error
between θ and the reference angle θr or e = θref −θm. With a tachometer we
can measure the motor speed ˙θm. Consider using feedback of the error e and
the motor speed ˙θm in the form
υa = K(e −TD ˙θm),
where K and TD are controller gains to be determined.
(a) Draw a block diagram of the resulting feedback system showing both θm
and ˙θm as variables in the diagram representing the motor.
(b) Suppose the numbers work out so that a1 = 65, b0 = 200, and c0 = 10.
If there is no load torque (w = 0), what speed (in rpm) results from
va = 100 V?
(c) Using the parameter values given in part (b), let the control be D =
kP + kDs and ﬁnd kP and kD so that, using the results of Chapter 3, a
step change in θref with zero load torque results in a transient that has
an approximately 17% overshoot and that settles to within 5% of steady
state in less than 0.05 sec.
(d) Derive an expression for the steady-state error to a reference angle input
and compute its value for your design in part (c) assuming θref = 1 rad.
(e) Derive an expression for the steady-state error to a constant disturbance
torque when θref = 0 and compute its value for your design in part (c)
assuming w = 1.0.
4.26
We wish to design an automatic speed control for an automobile. Assume
that (1) the car has a mass m of 1000 kg, (2) the accelerator is the control
U and supplies a force on the automobile of 10 N per degree of accelerator
motion, and (3) air drag provides a friction force proportional to velocity of
10 N · sec/m.
(a) Obtain the transfer function from control input U to the velocity of the
automobile.
(b) Assume the velocity changes are given by
V(s) =
1
s + 0.02U(s) +
0.05
s + 0.02W(s),
where V is given in meters per second, U is in degrees, and W is the
percent grade of the road. Design a proportional control law U = −kPV
that will maintain a velocity error of less than 1 m/sec in the presence of
a constant 2% grade.
(c) Discuss what advantage (if any) integral control would have for this
problem.
(d) Assuming that pure integral control (that is, no proportional term) is
advantageous, select the feedback gain so that the roots have critical
damping (ζ = 1).
4.27
Consider the automobile speed control system depicted in Fig. 4.40.
(a) Find the transfer functions from W(s) and from R(s) to Y(s).
(b) Assume that the desired speed is a constant reference r, so that R(s) = ros .
Assume that the road is level, so w(t) = 0. Compute values of the gains
kP, Hr, and Hy to guarantee that
lim
t→∞y(t) = ro.

228
Chapter 4 A First Analysis of Feedback
Figure 4.40
Automobile
speed-control system
Y
R
 + 
 + 
W
 + 
 - 
Hy
Hr
kp
s + a
A
s + a
B
R = 
Y = 
W = 
Desired speed
Actual speed
Road grade, %
©
©
Include both the open-loop (assuming Hy = 0) and feedback cases
(Hy ̸= 0) in your discussion.
(c) Repeat part (b) assuming that a constant grade disturbance W(s) = wos is
present in addition to the reference input. In particular, ﬁnd the variation
in speed due to the grade change for both the feed forward and feedback
cases. Use your results to explain (1) why feedback control is necessary
and (2) how the gain kP should be chosen to reduce steady-state error.
(d) Assume that w(t) = 0 and that the gain A undergoes the perturbation
A + δA. Determine the error in speed due to the gain change for both the
feed forward and feedback cases. How should the gains be chosen in this
case to reduce the effects of δA?
4.28
Consider the multivariable system shown in Fig. 4.41. Assume that the system
is stable. Find the transfer functions from each disturbance input to each output
and determine the steady-state values of y1 and y2 for constant disturbances.
We deﬁne a multivariable system to be type k with respect to polynomial inputs
at wi if the steady-state value of every output is zero for any combination of
inputs of degree less than k and at least one input is a nonzero constant for an
input of degree k.What is the system type with respect to disturbance rejection
at w1 and at w2?
Figure 4.41
Multivariable system
 + 
 - 
 + 
 + 
W1
s
1
R1
Y1
s + 1
1
 + 
 - 
R2
 + 
 + 
s + 1
1
s + 2
1
 + 
 + 
W2
Y2
©
©
©
©
©
Problems for Section 4.3: The Three-Term Controller: PID Control
4.29
The transfer functions of speed control for a magnetic tape-drive system are
shown in Fig. 4.42. The speed sensor is fast enough that its dynamics can be
neglected and the diagram shows the equivalent unity feedback system.

Problems
229
(a) Assuming the reference is zero, what is the steady-state error due to a step
disturbance torque of 1 N·m? What must the ampliﬁer gain K be in order
to make the steady-state error ess ≤0.01 rad/sec?
(b) Plot the roots of the closed-loop system in the complex plane and accu-
rately sketch the time response of the output for a step reference input
using the gain K computed in part (a).
(c) Plot the region in the complex plane of acceptable closed-loop poles cor-
responding to the speciﬁcations of a 1% settling time of ts ≤0.1 sec and
an overshoot Mp ≤5%.
(d) Give values for kP and kD for a PD controller, which will meet the
speciﬁcations.
(e) How would the disturbance-induced steady-state error change with the
new control scheme in part (d)? How could the steady-state error to a
disturbance torque be eliminated entirely?
Figure 4.42
Speed-control system
for a magnetic tape
drive
K
 + 
 - 
10
0.5s + 1
Amplifier
Torque
motor
 + 
 + 
Torque
Disturbance
torque
1
Js + b
Tape
dynamics
Æm
Reference
speed, Ær
J = 0.10 kg·m2
b = 1.00 N·m·sec
©
©
4.30
Consider the system shown in Fig. 4.43 with PI control.
(a) Determine the transfer function from R to Y.
(b) Determine the transfer function from W to Y.
(c) What are the system type and error constant with respect to reference
tracking?
(d) What are the system type and error constant with respect to disturbance
rejection?
Figure 4.43
Control system for
Problem 4.30
s
kPs + kI
 + 
 - 
Y
W
U
R
 + 
 + 
s2 + s + 20
10
©
©
4.31
Consider the second-order plant with transfer function
G(s) =
1
(s + 1)(5s + 1),
and in a unity feedback structure.

230
Chapter 4 A First Analysis of Feedback
(a) Determine the system type and error constant with respect to tracking
polynomial reference inputs of the system for P [Dc = kP], PD [Dc(s) =
kP + kDs], and PID [Dc(s) = kP + kIs + kDs] controllers. Let kP = 19,
kI = 0.5, and kD = 4
19.
(b) Determine the system type and error constant of the system with respect to
disturbance inputs for each of the three regulators in part (a) with respect
to rejecting polynomial disturbances w(t) at the input to the plant.
(c) Is this system better at tracking references or rejecting disturbances?
Explain your response brieﬂy.
(d) Verify your results for parts (a) and (b) using Matlab by plotting unit-step
and -ramp responses for both tracking and disturbance rejection.
4.32
The DC motor speed control shown in Fig. 4.44 is described by the differential
equation
˙y + 60y = 600va −1500w,
where y is the motor speed, va is the armature voltage, and w is the load torque.
Assume the armature voltage is computed using the PI control law
va = −

kPe + kI
 t
0
edt

,
where e = r −y.
(a) Compute the transfer function from W to Y as a function of kP and kI.
(b) Compute values for kP and kI so that the characteristic equation of the
closed-loop system will have roots at −60 ± 60j.
Figure 4.44
DC Motor speed-control
block diagram for
Problems 4.32 and 4.33
 + 
 - 
Y
W
e
ya
R
 + 
 - 
Dc(s)
600
1500
s + 60
1
©
©
4.33
For the system in Fig. 4.44, compute the following steady-state errors:
(a) to a unit-step reference input;
(b) to a unit-ramp reference input;
(c) to a unit-step disturbance input;
(d) for a unit-ramp disturbance input.
(e) Verify your answers to (a) and (d) using Matlab. Note that a ramp response
can be generated as a step response of a system modiﬁed by an added
integrator at the reference input.
4.34
Consider the satellite-attitude control problem shown in Fig. 4.45 where the
normalized parameters are

Problems
231
J = 10
spacecraft inertia, N·m·sec2/rad
θr = reference satellite attitude, rad.
θ = actual satellite attitude, rad.
Hy = 1
sensor scale, factor V/rad.
Hr = 1
reference sensor scale factor,V/rad.
w = disturbance torque, N·m.
(a) Use proportional control, P, with Dc(s) = kP, and give the range of values
for kP for which the system will be stable.
(b) Use PD control, let Dc(s) = (kP + kDs), and determine the system type
and error constant with respect to reference inputs.
(c) Use PD control, let Dc(s) = (kP + kDs), and determine the system type
and error constant with respect to disturbance inputs.
(d) Use PI control, let Dc(s) = (kP + kIs ), and determine the system type and
error constant with respect to reference inputs.
(e) Use PI control, let Dc(s) = (kP + kIs ), and determine the system type and
error constant with respect to disturbance inputs.
(f) Use PID control, let Dc(s) = (kP + kIs + kDs), and determine the system
type and error constant with respect to reference inputs.
(g) Use PID control, let Dc(s) = (kP + kIs + kDs), and determine the system
type and error constant with respect to disturbance inputs.
Figure 4.45
Satellite attitude
control
Hy
 + 
 - 
 + 
 + 
Js
1
w
Hr
s
1
Dc(s)
u
ur
©
©
4.35
Automaticshipsteeringisparticularlyusefulinheavyseaswhenitisimportant
to maintain the ship along an accurate path. Such a control system for a large
tanker is shown in Fig. 4.46, with the plant transfer function relating heading
changes to rudder deﬂection in radians.
(a) Write the differential equation that relates the heading angle to rudder
angle for the ship without feedback.
(b) This control system uses simple proportional feedback with the gain of
unity. Is the closed-loop system stable as shown? (Hint: use Routh's
criterion.)
(c) Is it possible to stabilize this system by changing the proportional gain
from unity to a lower value?
(d) Use Matlab to design a dynamic controller of the form Dc(s) = K

s+a
s+b
2
so that the closed-loop system is stable and in response to a step heading

232
Chapter 4 A First Analysis of Feedback
command it has zero steady-state error and less than 10% overshoot. Are
these reasonable values for a large tanker?
Figure 4.46
Ship-steering control
system for Problem 4.35
©
+
-
cr
d
-0.164(s + 0.2)(s - 0.32)
s2(s + 0.25)(s - 0.009)
Rudder
angle
Heading c
4.36
The unit-step response of a paper machine is shown in Fig. 4.47(a) where
the input into the system is stock ﬂow onto the wire and the output is basis
weight (thickness). The time delay and slope of the transient response may be
determined from the ﬁgure.
Figure 4.47
Paper-machine
response data for
Problem 4.36
Step response
1.0
0.8
0.6
0.4
0.2
0.0
0.3
0.4
-0.1
0.0
0.1
0.2
-0.2
-0.3
-0.4
Unit impulse response
0
(b)
Time (sec)
1
2
3
4
5
6
7
8
9 10
0
(a)
Time (sec)
1
2
3
4
5
6
7
8
9 10
(a) Find the proportional-, PI-, and PID-controller parameters using the
Ziegler-Nichols transient-response method.
(b) Using proportional feedback control, control designers have obtained a
closed-loop system with the unit impulse response shown in Fig. 4.47(b).
When the gain Ku = 8.556, the system is on the verge of instability. Deter-
mine the proportional-, PI-, and PID-controller parameters according to
the Ziegler-Nichols ultimate sensitivity method.
4.37
A paper machine has the transfer function
G(s) = e−2s
3s + 1,
where the input is stock ﬂow onto the wire and the output is basis weight or
thickness.
(a) Find the PID-controller parameters using the Ziegler-Nichols tuning
rules.
(b) The system becomes marginally stable for a proportional gain of Ku =
3.044 as shown by the unit impulse response in Fig. 4.48. Find the optimal
PID-controller parameters according to the Ziegler-Nichols tuning rules.

Problems
233
Figure 4.48
Unit impulse response
for the paper machine
in Problem 4.37
0.0
5.0
10.0
15.0
20.0
25.0
0.020
0.015
0.010
0.005
0.00
-0.005
-0.010
-0.015
Time (sec)
y
Problems for Section 4.4: Feedforward Control by Plant
△
Model Inversion
4.38
Consider the DC motor speed-control system shown in Fig. 4.49 with pro-
portional control. (a) Add feedforward control to eliminate the steady-state
tracking error for a step reference input. (b) Also add feedforward control to
eliminate the effect of a constant output disturbance signal, w, on the output
of the system.
Figure 4.49
Block diagram for
Problem 4.38
©
©
-
59.292
(s2 + 6.978s + 15.123)
Y
W
R
3
+
Problems for Section 4.5: Introduction to Digital Control
△
4.39
Compute the discrete equivalents for the following possible controllers using
the trapezoid rule of Eq. (14) in Appendix W4.5. Let Ts = 0.05 sec in each
case.
(a) Dc1(s) = (s + 2)/2,
(b) Dc2(s) = 2 s+2
s+4,
(c) Dc3(s) = 5 s+2
s+10,
(d) Dc4(s) = 5 (s+2)(s+0.1)
(s+10)(s+0.01).
4.40
Give the difference equations corresponding to the discrete controllers found
in Problem 4.39, respectively.
(a) Part 1.
(b) Part 2.
(c) Part 3.
(d) Part 4.

5
The Root-Locus Design
Method
A Perspective on the Root-Locus
Design Method
In Chapter 3, we related the features of a step response, such as rise
time, overshoot, and settling time, to pole locations in the s-plane
of the transform of a second-order system characterized by the nat-
ural frequency ωn, the damping ratio ζ, and the real part σ. This
relationship is shown graphically in Fig. 3.15. We also examined the
changes in these transient-response features when a pole or a zero is
added to the transfer function. In Chapter 4, we saw how feedback can
improve steady-state errors and can also inﬂuence dynamic response
by changing the system's pole locations. In this chapter, we present
a speciﬁc technique that shows how changes in one of a system's
parameters will modify the roots of the characteristic equation, which
are the closed-loop poles, and thus change the system's dynamic
response. The method was developed by W. R. Evans who gave rules
for plotting the paths of the roots, a plot he called the Root Locus.
With the development of Matlab and similar software, the rules are
no longer needed for detailed plotting, but we feel it is essential for
a control designer to understand how proposed dynamic controllers
will inﬂuence a locus as a guide in the design process. We also feel
234

5.1 Root Locus of a Basic Feedback System
235
that it is important to understand the basics of how loci are generated
in order to perform sanity checks on the computer results. For these
reasons, study of the Evans rules is important.
The root locus is most commonly used to study the effect of loop
gain variations; however, the method is general and can be used to
plottherootsofanypolynomialwithrespecttoanyonerealparameter
that enters the equation linearly. For example, the root-locus method
can be used to plot the roots of a characteristic equation as the gain
of a velocity sensor feedback changes, or the parameter can be a
physical parameter, such as motor inertia or armature inductance.
Chapter Overview
We open Section 5.1 by illustrating the root locus for some simple
feedback systems for which the equations can be solved directly. In
Section 5.2, we show how to put an equation into the proper form
for developing the rules for the root-locus behavior. In Section 5.3,
this approach is applied to determine the locus for a number of typ-
ical control problems, which illustrate the factors that inﬂuence the
ﬁnal shape. Matlab is used for detailed plotting of speciﬁc loci. When
adjustment of the selected parameter alone cannot produce a sat-
isfactory design, designs using other parameters can be studied or
dynamic elements such as lead, lag, or notch compensations can be
introduced, as described in Section 5.4. In Section 5.5, the uses of the
root locus for design are summarized by a comprehensive design for
the attitude control of a small airplane. In Section 5.6, the root-locus
method is extended to guide the design of systems with a negative
parameter, systems with more than one variable parameter, and sys-
tems with simple time delay. Finally, Section 5.7 gives historical notes
on the origin of root-locus design.
5.1
Root Locus of a Basic Feedback System
We begin with the basic feedback system shown in Fig. 5.1. For this system,
the closed-loop transfer function is
Y(s)
R(s) = T (s) =
Dc(s)G(s)
1 + Dc(s)G(s)H(s),
(5.1)
and the characteristic equation, whose roots are the poles of this transfer
function, is
1 + Dc(s)G(s)H(s) = 0.
(5.2)
To put the equation in a form suitable for study of the roots as a param-
eter changes, we ﬁrst put the equation in polynomial form and select the
parameter of interest, which we will call K. We assume that we can deﬁne
component polynomials a(s) and b(s) so that the characteristic polynomial

236
Chapter 5 The Root-Locus Design Method
Figure 5.1
Basic closed-loop block
diagram
 + 
 - 
 + 
 + 
R
Y
Controller
Plant
Dc(s)
G(s)
Sensor
H(s)
U
W
 + 
 + 
V
©
©
©
is in the form a(s) + Kb(s). We then deﬁne the transfer function L(s) = b(s)
a(s)
so that the characteristic equation can be written as1
1 + KL(s) = 0 where L(s) = b(s)
a(s) .
(5.3)
If, as is often the case, the parameter is the gain of the controller, then L(s)
is simply proportional to Dc(s)G(s)H(s). Evans suggested that we plot the
locus of all possible roots of Eq. (5.3) as K varies from zero to inﬁnity,
and then use the resulting plot to aid us in selecting the best value of K.
Furthermore, by studying the effects of additional poles and zeros on this
graph, we can determine the consequences of additional dynamics added to
Dc(s) as compensation in the loop. We thus have a tool not only for selecting
the speciﬁc parameter value but for designing the dynamic compensation as
well. The graph of all possible roots of Eq. (5.3) relative to parameter K is
called the root locus, and the set of rules to construct this graph is called the
Evans's method
root-locus method of Evans. We begin our discussion of the method with
the mechanics of constructing a root locus, using the equation in the form
of Eq. (5.3) and K as the variable parameter.
To set the notation for our study, we assume here that the transfer func-
tion L(s) is a rational function whose numerator is a monic2 polynomial b(s)
of degree m and whose denominator is a monic polynomial a(s) of degree
n such that3 n ≥m. Therefore, m = the number of zeros, while n = the
number of poles. We can factor these polynomials as
b(s) = sm + b1sm−1 + · · · + bm
= (s −z1)(s −z2) · · · (s −zm)
1In the most common case, L(s) is the loop transfer function of the feedback system and K is the
gain of the controller-plant combination. However, the root locus is a general method suitable
for the study of any polynomial and any parameter that can be put in the form of Eq. (5.3).
2Monic means that the coefﬁcient of the highest power of s is 1.
3If L(s) is the transfer function of a physical system, it is necessary that n ≥m or else the
system would have an inﬁnite response to a ﬁnite input. If the parameter should be chosen so
that n < m, then we can consider the equivalent equation 1 + K−1L(s)−1 = 0.

5.1 Root Locus of a Basic Feedback System
237
=
m

i=1
(s −zi),
(5.4)
a(s) = sn + a1sn−1 + · · · + an
=
n

i=1
(s −pi).
The roots of b(s) = 0 are the zeros of L(s) and are labeled zi, and the
roots of a(s) = 0 are the poles of L(s) and are labeled pi. The roots of the
characteristic equation itself are ri from the factored form (n > m),
a(s) + Kb(s) = (s −r1)(s −r2) · · · (s −rn).
(5.5)
We may now state the root-locus problem expressed in Eq. (5.3) in
several equivalent but useful ways. Each of the following equations has the
same roots:
1 + KL(s) = 0,
(5.6)
1 + K b(s)
a(s) = 0,
(5.7)
a(s) + Kb(s) = 0,
(5.8)
L(s) = −1
K .
(5.9)
Equations (5.6)-(5.9) are sometimes referred to as the root-locus form
Root-locus forms
or Evans form of a characteristic equation. The root locus is the set of values
of s for which Eqs. (5.6)-(5.9) hold for some positive real value4 of K.
Because the solutions to Eqs. (5.6)-(5.9) are the roots of the closed-loop
system characteristic equation and are thus closed-loop poles of the system,
the root-locus method can be thought of as a method for inferring dynamic
properties of the closed-loop system as the parameter K changes.
EXAMPLE 5.1
Root Locus of a Motor Position Control
In Chapter 2 we saw that a normalized transfer function of a DC motor
voltage-to-position can be
m(s)
Va(s) = Y(s)
U(s) = G(s) =
A
s(s + c).
Solve for the root locus of closed-loop poles of the system created by feeding
back the output m as shown in Fig. 5.1 with respect to the parameter A if
Dc(s) = H(s) = 1 and also c = 1.
4If K is positive, the locus is called the "positive" locus. We will consider later the simple
changes if K < 0, resulting in a "negative" locus.

238
Chapter 5 The Root-Locus Design Method
Figure 5.2
Root locus for
L(s) =
1
s(s+1)
-2
-1
Real axis
0
1
2
-1.5
-1
-0.5
0
0.5
1
1.5
Imaginary axis
u = sin-1 1 = 305
Solution. In terms of our notation, the values are
L(s) =
1
s(s + 1),
b(s) = 1,
m = 0,
zi = {empty},
(5.10)
K = A,
a(s) = s2 + s,
n = 2,
pi = 0, −1.
From Eq. (5.8), the root locus is a graph of the roots of the quadratic equation
a(s) + Kb(s) = s2 + s + K = 0.
(5.11)
Using the quadratic formula, we can immediately express the roots of
Eq. (5.11) as
r1, r2 = −1
2 ±
√1 −4K
2
.
(5.12)
A plot of the corresponding root locus is shown in Fig. 5.2. For 0 ≤K ≤
1/4, the roots are real between −1 and 0. At K = 1/4 there are two roots at
−1/2, and for K > 1/4 the roots become complex with real parts constant
at −1/2 and imaginary parts that increase essentially in proportion to the
square root of K. The dashed lines in Fig. 5.2 correspond to roots with a
damping ratio ζ = 0.5. The poles of L(s) at s = 0 and s = −1 are marked
by the symbol ×, and the points where the locus crosses the lines where the
damping ratio equals 0.5 are marked with dots (•). We can compute K at the
point where the locus crosses ζ = 0.5 because we know that if ζ = 0.5, then
θ = 30◦and the magnitude of the imaginary part of the root is
√
3 times the
magnitude of the real part. Since the size of the real part is 1
2, from Eq. (5.12)
we have
√4K −1
2
=
√
3
2 ,
and, therefore, K = 1.
We can observe several features of this simple locus by looking at
Eqs. (5.11) and (5.12) and Fig. 5.2. First, there are two roots and, thus,
two loci which we call branches of the root locus. At K = 0 these branches
begin at the poles of L(s) (which are at 0 and −1), as they should, since for
K = 0 the system is open-loop and the characteristic equation is a(s) = 0.

5.1 Root Locus of a Basic Feedback System
239
As K is increased, the roots move toward each other, coming together at
s = −1
2, and at that point they break away from the real axis. After the
Breakaway points are
where roots move away
from the real axis
breakaway point, the roots move off to inﬁnity with equal real parts, so the
sum of the two roots is always −1. From the viewpoint of design, we see
that by altering the value of the parameter K, we can cause the closed-loop
poles to be at any point along the locus in Fig. 5.2. If some points along this
locus correspond to a satisfactory transient response, then we can complete
the design by choosing the corresponding value of K; otherwise, we are
forced to consider a more complex controller. As we pointed out earlier, the
root locus technique is not limited to focusing on the system gain (K = A
in Example 5.1); the same ideas are applicable for ﬁnding the locus with
respect to any parameter that enters linearly in the characteristic equation.
EXAMPLE 5.2
Root Locus with Respect to a Plant Open-Loop Pole
Consider the characteristic equation as in Example 5.1, again with Dc(s) =
H(s) = 1 except now let A = 1. Select c as the parameter of interest in the
equation
1 + G(s) = 1 +
1
s(s + c).
(5.13)
Find the root locus of the characteristic equation with respect to c.
Solution. The corresponding closed-loop characteristic equation in poly-
nomial form is
s2 + cs + 1 = 0.
(5.14)
Equation (5.6) applies directly if we rearrange Eq. (5.14) with the following
deﬁnitions:
L(s) =
s
s2+1,
b(s) = s,
m = 1,
zi = 0,
K = c,
a(s) = s2 + 1,
n = 2,
pi = +j, −j.
(5.15)
Thus, the root-locus form of the characteristic equation is
1 + c
s
s2 + 1 = 0.
ThesolutionstoEq.(5.14)areeasilycomputedusingthequadraticformulaas
r1, r2 = −c
2 ±
√
c2 −4
2
.
(5.16)
The locus of solutions is shown in Fig. 5.3, with the poles [roots of a(s)]
again indicated by ×'s and the zero [root of b(s)] by the circle (⃝). Note
that when c = 0, the roots are at the ×'s on the imaginary axis and the
corresponding response would be oscillatory. The damping ratio ζ grows as
c increases from 0.At c = 2, there are two roots at s = −1, and the two locus
segments abruptly change direction and move in opposite directions along
the real axis; this point of multiple roots where two or more roots come into
the real axis is called a break-in point.
Break-in point

240
Chapter 5 The Root-Locus Design Method
Figure 5.3
Root locus versus
damping factor c for
1 + G(s) =
1 +
1
s(s+c) = 0
-2
-1
Real axis
0
1
2
-1.5
-1
-0.5
0
0.5
1
1.5
Imaginary axis
Of course, computing the root locus for a quadratic equation is easy
to do since we can solve the characteristic equation for the roots, as was
done in Eqs. (5.12) and (5.16), and directly plot these as a function of the
parameter K or c. To be useful, the method must be suitable for higher-
order systems for which explicit solutions are difﬁcult to obtain; therefore,
rules for the construction of a general root locus were developed by Evans.
With the availability of Matlab, these rules are no longer necessary to plot
a speciﬁc locus because the command rlocus(sys) will do that. However, in
control design we are interested not only in a speciﬁc locus but also in how
to modify the dynamics in such a way as to propose a system that will meet
the dynamic response speciﬁcations for good control performance. For this
purpose, it is very useful to be able to roughly sketch a locus so as to be
able to evaluate the consequences of possible compensation alternatives. It
is also important to be able to quickly evaluate the correctness of a computer-
generated locus to verify that what is plotted by Matlab is in fact what was
meant to be plotted. It is easy to get a constant wrong or to leave out a term
and GIGO5 is the well-known ﬁrst rule of computation.
5.2
Guidelines for Determining a Root Locus
We begin with a formal deﬁnition of a root locus. From the form of Eq. (5.6),
we deﬁne the root locus this way:
Deﬁnition I. The root locus is the set of values of s for which
1 + KL(s) = 0 is satisﬁed as the real parameter K varies from 0 to
+∞. Typically, 1 + KL(s) = 0 is the characteristic equation of the
system, and in this case the roots on the locus are the closed-loop
poles of that system.
5Garbage in, Garbage out.

5.2 Guidelines for Determining a Root Locus
241
Now suppose we look at Eq. (5.9). If K is to be real and positive, L(s) must
be real and negative. In other words, if we arrange L(s) in polar form as
magnitude and phase, then the phase of L(s) must be 180◦in order to satisfy
Eq. (5.9). We can thus deﬁne the root locus in terms of this phase condition
as follows.
The basic root-locus rule;
the phase of L(s) = 180◦
Deﬁnition II. The root locus of L(s) is the set of points in the s-
plane where the phase of L(s) is 180◦. To test whether a point in the
s-plane is on the locus, we deﬁne the angle to the test point from
a zero as ψi and the angle to the test point from a pole as φi then
Deﬁnition II is expressed as those points in the s-plane where, for
an integer ℓ,

ψi −

φi = 180◦+ 360◦(l −1).
(5.17)
The immense merit of Deﬁnition II is that, while it is very difﬁcult to
solve a high-order polynomial by hand, computing the phase of a transfer
function is relatively easy. The usual case is when K is real and positive, and
we call this case the positive or 180◦locus. When K is real and negative,
L(s) must be real and positive with a phase of 0◦, and this case is called the
negative or 0◦locus.
From Deﬁnition II we can, in principle, determine a positive root
locus for a complex transfer function by measuring the phase and mark-
ing those places where we ﬁnd 180◦. This direct approach can be illustrated
by considering the example
L(s) =
s + 1
s(s + 5)[(s + 2)2 + 4].
(5.18)
In Fig. 5.4, the poles of this L(s) are marked × and the zero is marked ⃝.
Suppose we select the test point s0 = −1+2j. We would like to test whether
or not s0 lies on the root locus for some value of K. For this point to be on
Figure 5.4
Measuring the phase of
Eq. (5.18)
-6
-4
-2
Real axis
0
2
-3
-2
-1
0
1
2
3
Imaginary axis
f2 = 0
f3
s0
c1
f4
f1

242
Chapter 5 The Root-Locus Design Method
the locus, we must have ∠L(s0) = 180◦+ 360◦(l −1) for some integer l,
or equivalently, from Eq. (5.18),
∠(s0+1)−∠s0−∠(s0+5)−∠[(s0+2)2+4] = 180◦+360◦(l−1). (5.19)
The angle from the zero term s0 + 1 can be computed6 by drawing a
line from the location of the zero at −1 to the test point s0. In this case the
line is vertical and has a phase angle marked ψ1 = 90◦in Fig. 5.4. In a
similar fashion, the vector from the pole at s = 0 to the test point s0 is shown
with angle φ1, and the angles of the two vectors from the complex poles at
−2±2j to s0 are shown with angles φ2 and φ3. The phase of the vector s0 +5
is shown with angle φ4. From Eq. (5.19), we ﬁnd the total phase of L(s) at
s = s0 to be the sum of the phases of the numerator term corresponding to
the zero minus the phases of the denominator terms corresponding to the
poles:
∠L = ψ1 −φ1 −φ2 −φ3 −φ4
= 90◦−116.6◦−0◦−76◦−26.6◦
= −129.2◦.
Since the phase of L(s) is not 180◦, we conclude that s0 is not on the root
locus, so we must select another point and try again. Although measuring
phase is not particularly hard, measuring phase at every point in the s-plane
is hardly practical. Therefore, to make the method practical, we need some
general guidelines for determining where the root locus is. Evans developed
a set of rules for this purpose, which we will illustrate by applying them to
the root locus for
L(s) =
1
s[(s + 4)2 + 16].
(5.20)
We begin by considering the positive locus, which is by far the most com-
mon case.7 The ﬁrst three rules are relatively simple to remember and are
essential for any reasonable sketch. The last two are less useful but are used
occasionally. As usual, we assume that Matlab or its equivalent is always
available to make an accurate plot of a promising locus.
5.2.1
Rules for Determining a Positive (180◦) Root Locus
RULE 1. The n branches of the locus start at the poles of L(s) and m of these
branches end on the zeros of L(s). From the equation a(s) + Kb(s) = 0, if
K = 0, the equation reduces to a(s) = 0, whose roots are the poles. When
K approaches inﬁnity, s must be such that either b(s) = 0 or s →∞. Since
there are m zeros where b(s) = 0, m branches can end in these places. The
case for s →∞is considered in Rule 3.
6The graphical evaluation of the magnitude and phase of a complex number is reviewed in
Appendix WA, Section 5.3.
7The negative locus will be considered in Section 5.6.

5.2 Guidelines for Determining a Root Locus
243
Figure 5.5
Rule 2. The real-axis
parts of the locus are to
the left of an odd
number of poles and
zeros
-8
-2
-4
-6
Real axis
0
1
2
-4
-2
2
4
Imaginary axis
s0
f3 = 0
f1
f2
RULE 2. The loci are on the real axis to the left of an odd number of poles
and zeros.
If we take a test point on the real axis, such as s0 in Fig. 5.5, we ﬁnd that
the angles φ1 and φ2 of the two complex poles cancel each other, as would
the angles from complex conjugate zeros. Angles from real poles or zeros
are 0◦if the test point is to the right and 180◦if the test point is to the left of a
given pole or zero. Therefore, for the total angle to add to 180◦+360◦(l−1),
the test point must be to the left of an odd number of real-axis poles plus
zeros as shown in Fig. 5.5.
RULE 3. For large s and K, n −m branches of the loci are asymptotic to
lines at angles φl radiating out from the point s = α on the real axis, where
φl = 180◦+ 360◦(l −1)
n −m
,
l = 1, 2, . . . , n −m,
(5.21)
α =
 pi − zi
n −m
.
As K →∞, the equation
L(s) = −1
K
(5.22)
can be satisﬁed only if L(s) = 0. This can occur in two apparently different
ways. In the ﬁrst instance, as discussed in Rule 1, m roots will be found to
approach the zeros of L(s). The second manner in which L(s) may go to
zero is if s →∞since, by assumption, n is larger than m. The asymptotes
describe how these n −m roots approach s →∞. For large s, the equation
1 + K sm + b1sm−1 + · · · + bm
sn + a1sn−1 + · · · + an
= 0
(5.23)

244
Chapter 5 The Root-Locus Design Method
can be approximated8 by
1 + K
1
(s −α)n−m = 0.
(5.24)
This is the equation for a system in which there are n−m poles, all clustered
at s = α. Another way to visualize this same result is to consider the picture
we would see if we could observe the locations of poles and zeros from a
vantage point of very large s: They would appear to cluster near the s-plane
origin. Thus, m zeros would cancel the effects of m of the poles, and the
other n−m poles would appear to be in the same place. We say that the locus
of Eq. (5.23) is asymptotic to the locus of Eq. (5.24) for large values of K
and s. We need to compute α to ﬁnd the locus for the resulting asymptotic
system. To ﬁnd the locus, we choose our search point s0 such that s0 = Rejφ
for some large ﬁxed value of R and variable φ. Since all poles of this simple
system are in the same place, the angle of its transfer function is 180◦if all
n −m angles, each equal to φl, sum to 180◦. Therefore, φl is given by
(n −m)φl = 180◦+ 360◦(l −1)
for some integer l. Thus, the asymptotic root locus consists of radial lines at
The angles of the
asymptotes
the n −m distinct angles given by
φl = 180◦+ 360◦(l −1)
n −m
,
l = 1, 2, . . . , n −m.
(5.25)
For the system described by Eq. (5.20), n −m = 3 and φ1,2,3 = 60◦, 180◦,
and 300◦or ±60◦, 180◦.
The lines of the asymptotic locus come from s0 = α on the real axis.
To determine α, we make use of a simple property of polynomials. Suppose
we consider the monic polynomial a(s) with coefﬁcients ai and roots pi, as
in Eq. (5.4), and we equate the polynomial form with the factored form
sn + a1sn−1 + a2sn−2 + · · · + an = (s −p1)(s −p2) · · · (s −pn).
If we multiply out the factors on the right side of this equation, we see that
the coefﬁcient of sn−1 is −p1−p2−· · ·−pn. On the left side of the equation,
we see that this term is a1. Thus a1 = − pi; in other words, the coefﬁcient
of the second highest term in a monic polynomial is the negative sum of its
roots—in this case, the poles of L(s). Applying this result to the polynomial
b(s), we ﬁnd the negative sum of the zeros to be b1. These results can be
written as
−b1 =  zi,
−a1 =  pi.
(5.26)
Finally, we apply this result to the closed-loop characteristic polynomial
obtained from Eq. (5.23):
8This approximation can be obtained by dividing a(s) by b(s) and matching the dominant two
terms (highest powers in s) to the expansion of (s −α)n−m.

5.2 Guidelines for Determining a Root Locus
245
sn + a1sn−1 + · · · + an + K(sm + b1sm−1 + · · · + bm)
(5.27)
= (s −r1)(s −r2) · · · (s −rn) = 0.
Note that the sum of the roots is the negative of the coefﬁcient of sn−1 and
is independent of K if m < n −1. Therefore, if L(s) has at least two more
poles than zeros, we have a1 = − ri. We have thus shown that the center
point of the roots does not change with K if m < n −1, and that the open-
loop and closed-loop sum is the same and is equal to −a1, which can be
expressed as
−

ri = −

pi.
(5.28)
For large values of K, we have seen that m of the roots ri approach the zeros
zi and n −m of the roots approach the branches of the asymptotic system
1
(s−α)n−m whose poles add up to (n −m)α. Combining these results, we
conclude that the sum of all the roots equals the sum of those roots that go
to inﬁnity plus the sum of those roots that go to the zeros of L(s):
−

ri = −(n −m)α −

zi = −

pi.
Solving for α, we get
The center of the
asymptotes
α =
 pi − zi
n −m
.
(5.29)
Notice that in the sums  pi and  zi the imaginary parts always add to
zero, since complex poles and zeros always occur in complex conjugate
pairs. Thus, Eq. (5.29) requires information about the real parts only. For
Eq. (5.20),
α = −4 −4 + 0
3 −0
= −8
3 = −2.67.
The asymptotes at ±60◦are shown dashed in Fig. 5.6. Notice that they cross
the imaginary axis at ±(2.67)j
√
3 = ±4.62j. The asymptote at 180◦was
already found on the real axis by Rule 2.
Figure 5.6
The asymptotes are
n −m radial lines from
α at equal angles
-10
-5
Real axis
0
5
-6
-4
-2
0
2
4
6
Imaginary axis

246
Chapter 5 The Root-Locus Design Method
RULE 4. The angle of departure of a branch of the locus from a single pole
is given by
φdep =

ψi −

i̸=dep
φi −180◦,
(5.30)
where  φi is the sum of the angles to the remaining poles and  ψi is the
sum of the angles to all the zeros. The angles of departure for repeated poles
with multiplicity, q, is given by
Rule for departure angles
qφl,dep =

ψi −

i̸=l,dep
φi −180◦−360◦(l −1).
(5.31)
where l is an integer and takes on the values 1, 2, . . . , q. Note that if there
are q repeated poles, there will be q branches of the locus departing from
the poles.
Likewise, the angle(s) of arrival of a branch at a zero with multiplicity
q is given by
Rule for arrival angles
qψl,arr =

φi −

i̸=l,arr
ψi + 180◦+ 360◦(l −1).
(5.32)
where  φi is the sum of the angles to all the poles,  ψi is the sum of the
angles to the remaining zeros, and again, l takes on the values 1, 2, . . . , q so
there will be q branches of the locus arriving at the zeros.
The rules above all arise from the basic root locus phase condition in
Eq. (5.17) as we will now demonstrate. To compute the angle by which a
branch of the locus departs from one of the poles, we take a test point s0 very
near the pole in question, deﬁne the angle from that pole to the test point as
φ1, and transpose all other terms of Eq. (5.17) to the right-hand side. We can
illustrate the process by taking the test point s0 to be near the pole at −4+4j
of our example and computing the angle of L(s0). The situation is sketched
in Fig. 5.7, and the angle from −4 + 4j to the test point we deﬁne as φ1.
We select the test point close enough to the pole that the angles φ2 and φ3 to
the test point can be considered the same as those angles to the pole. Thus,
φ2 = 90◦, φ3 = 135◦, and φ1 can be calculated from the angle condition as
whatever it takes to make the total be 180◦. The calculation is
Figure 5.7
The departure and
arrival angles are found
by looking near a pole
or zero
-10
-5
Real axis
0
5
-6
-4
-2
0
2
4
6
Imaginary axis
f2
Pole 1
Pole 3
f3
f1
Pole 2
s0

5.2 Guidelines for Determining a Root Locus
247
φ1 = −90◦−135◦−180◦
(5.33)
= −405◦
(5.34)
= −45◦.
(5.35)
By the complex conjugate symmetry of the plots, the angle of departure of
the locus near the pole at −4 −4j will be +45◦.
If there had been zeros in L(s), the angles from the pole to the zeros
would have been added to the right side of Eq. (5.33). For the general case,
we can see from Eq. (5.33) that the angle of departure from a single pole is
that given by Eq. (5.30). For a multiple pole of order q, we must count the
angle from the pole q times. This alters Eq. (5.30) to Eq. (5.31) where l takes
on q values because there are q branches of the locus that depart from such
a multiple pole.
The process of calculating a departure angle for small values of K, as
shown in Fig. 5.7, is also valid for computing the angle by which a root
locus arrives at a zero of L(s) for large values of K. The general formula that
results is that given by Eq. (5.32)
This rule is particularly useful if a system has poles near the imaginary
axis, because it will show if the locus branch from the pole starts off toward
the stable left half-plane (LHP) or heads toward the unstable right half-plane
(RHP).
RULE 5. The locus can have multiple roots at points on the locus and the
branches will approach a point of q roots at angles separated by
180◦+ 360◦(l −1)
q
(5.36)
and will depart at angles with the same separation. As with any polynomial,
it is possible for a characteristic polynomial of a degree greater than 1 to have
multiple roots. For example, in the second-order locus of Fig. 5.2, there are
two roots at s = −1/2 when K = 1/4. Here the horizontal branches of
the locus come together and the vertical branches break away from the real
axis, becoming complex for K > 1/4. The locus arrives at 0◦and 180◦and
departs at +90◦and −90◦.
In order to compute the angles of arrival and departure from a point
of multiple roots, it is useful to use a trick we call the continuation locus.
Continuation locus
We can imagine plotting a root locus for an initial range of K, perhaps for
0 ≤K ≤K1. If we let K = K1 + K2, we can then plot a new locus with
parameter K2, a locus which is the continuation of the original locus and
whose starting poles are the roots of the original system at K = K1. To see
how this works, we return to the second-order root locus of Eq. (5.11) and
let K1 be the value corresponding to the breakaway point K1 = 1/4. If we
let K = 1/4 + K2, we have the locus equation s2 + s + 1/4 + K2 = 0, or

s + 1
2
2
+ K2 = 0.
(5.37)
The steps for plotting this locus are, of course, the same as for any other,
except that now the initial departure of the locus of Eq. (5.37) corresponds

248
Chapter 5 The Root-Locus Design Method
Figure 5.8
Root locus for
L(s) =
1
s(s2+8s+32)
-10
-5
Real axis
0
5
-6
-4
-2
0
2
4
6
Imaginary axis
to the breakaway point of the original locus of Eq. (5.11), i.e., s = −1/2 on
Fig. 5.2. Applying the rule for departure angles [Eq. (5.31)] from the double
pole at s = −1/2, we ﬁnd that
2φdep = −180◦−360◦(l −1),
(5.38)
φdep = −90◦−180◦(l −1),
(5.39)
φdep = ±90◦(departure angles at breakaway).
(5.40)
In this case, the arrival angles at s = −1/2 are, from the original root locus,
along the real axis and are clearly 0◦and 180◦.
The complete locus for our third-order example is drawn in Fig. 5.8.
It combines all the results found so far—that is, the real-axis segment, the
center of the asymptotes and their angles, and the angles of departure from
the poles. It is usually sufﬁcient to draw the locus by using only Rules 1 to 3,
which should be memorized. Rule 4 is sometimes useful to understand how
locus segments will depart, especially if there is a pole near the jω axis. Rule
5 is sometimes useful to help interpret plots that come from the computer
and, as we shall see in the next section, to explain qualitative changes in
some loci as a pole or zero is moved. The actual locus in Fig. 5.8 was drawn
using the Matlab commands
s = tf('s');
sysL = 1/(s*((s+4)ˆ2 + 16));
rlocus(sysL)
We will next summarize the rules for drawing a root locus.
5.2.2
Summary of the Rules for Determining a Root Locus
RULE 1. The n branches of the locus start at the poles of L(s) and m branches
end on the zeros of L(s).
RULE 2. The loci are on the real axis to the left of an odd number of poles
and zeros.

5.2 Guidelines for Determining a Root Locus
249
RULE 3. For large s and K, n −m branches of the loci are asymptotic to
lines at angles φl radiating out from the center point s = α on the real axis,
where
φl = 180◦+ 360◦(l −1)
n −m
,
l = 1, 2, . . . , n −m,
(5.41)
α =
 pi − zi
n −m
.
(5.42)
RULE 4. The angle(s) of departure of a branch of the locus from a pole of
multiplicity q is given by
qφl,dep =

ψi −

φi −180◦−360◦(l −1),
(5.43)
where l = 1, 2, . . . , q and the angle(s) of arrival of a branch at a zero of
multiplicity q is given by
qψl,arr =

φi −

ψi + 180◦+ 360◦(l −1).
(5.44)
RULE 5. The locus can have multiple roots at points on the locus of
multiplicity q. The branches will approach a point of q roots at angles
separated by
180◦+ 360◦(l −1)
q
(5.45)
and will depart at angles with the same separation, forming an array of 2q
rays equally spaced. If the point is on the real axis, then the orientation of
this array is given by the real-axis rule. If the point is in the complex plane,
then the angle of departure rule must be applied.
5.2.3
Selecting the Parameter Value
The positive root locus is a plot of all possible locations for roots to the
equation 1 + KL(s) = 0 for some real positive value of K. The purpose of
design is to select a particular value of K that will meet the speciﬁcations for
static and dynamic response. We now turn to the issue of selecting K from
a particular locus so that the roots are at speciﬁc places. Although we shall
show how the gain selection can be made by hand calculations from a plot
of the locus, this is almost never done by hand because the determination
can be accomplished easily by Matlab. It is useful, however, to be able to
perform a rough sanity check on the computer-based results by hand.
Using Deﬁnition II of the locus, we developed rules to sketch a root locus
from the phase of L(s) alone. If the equation is actually to have a root at a
particular place when the phase of L(s) is 180◦, then a magnitude condition
must also be satisﬁed. This condition is given by Eq. (5.9), rearranged as
K = −1
L(s).
(5.46)
For values of s on the root locus, the phase of L(s) is 180◦, so we can write
the magnitude condition as
K = 1
|L|.
(5.47)

250
Chapter 5 The Root-Locus Design Method
Figure 5.9
Root locus for
L(s) =
1
s[(s+4)2+16]
showing calculations of
gain K
s0
s2
s0
s1
0.5
0.5
s0
s3
6
0
1
4
2
0
2
4
6
8
6
4
2
0
2
4
6
Imaginary axis
Real axis
Equation (5.47) has both an algebraic and a graphical interpretation. To
see the latter, consider the locus of 1 + KL(s), where
L(s) =
1
s[(s + 4)2 + 16].
(5.48)
For this transfer function, the locus is plotted in Fig. 5.9. In Fig. 5.9, the lines
corresponding to a damping ratio of ζ = 0.5 are sketched and the points
where the locus crosses these lines are marked with dots (•). Suppose we
wish to set the gain so that the roots are located at the dots. This corresponds
to selecting the gain so that two of the closed-loop system poles have a
damping ratio of ζ = 0.5. (We will ﬁnd the third pole shortly.) What is the
value of K when a root is at the dot? From Eq. (5.47), the value of K is given
by 1 over the magnitude of L(s0), where s0 is the coordinate of the dot. On
the ﬁgure we have plotted three vectors marked s0 −s1, s0 −s2, and s0 −s3,
which are the vectors from the poles of L(s) to the point s0. (Since s1 = 0,
the ﬁrst vector equals s0.) Algebraically, we have
L(s0) =
1
s0(s0 −s2)(s0 −s3).
(5.49)
Using Eq. (5.47), this becomes
K =
1
|L(s0)| = |s0||s0 −s2||s0 −s3|.
(5.50)
The graphical interpretation of Eq. (5.50) shows that its three magni-
Graphical calculation of
the desired gain
tudes are the lengths of the corresponding vectors drawn on Fig. 5.9 (see
Appendix WD). Hence, we can compute the gain to place the roots at the
dot (s = s0) by measuring the lengths of these vectors and multiplying the
lengths together, provided that the scales of the imaginary and real axes are
identical. Using the scale of the ﬁgure, we estimate that
|s0| ∼= 4.0,
|s0 −s2| ∼= 2.1,
|s0 −s3| ∼= 7.7.

5.3 Selected Illustrative Root Loci
251
Thus, the gain is estimated to be
K = 4.0(2.1)(7.7) ∼= 65.
We conclude that if K is set to the value 65, then a root of 1+KL will be at s0,
which has the desired damping ratio of 0.5. Another root is at the conjugate
of s0. Where is the third root? The third branch of the locus lies along the
negative real axis. If performing the calculations by hand, we would need to
take a test point, compute a trial gain, and repeat this process until we have
found the point where K = 65. However, if performing a check on Matlab's
determination, it is sufﬁcient to merely use the procedure above to verify the
gain at the root location indicated by the computer.
To use Matlab, plot the locus using the command rlocus(sysL), for exam-
ple, then the command [K,p] = rlocﬁnd(sysL) will produce a crosshair on the
plot and, when spotted at the desired location of the root and selected with
a mouse click, the value of the gain K is returned as well as the roots corre-
sponding to that K in the variable p. The use of rltool makes this even easier,
and will be discussed in more detail in Example 5.7.
Finally, withthegainselected, itispossibletocomputetheerrorconstant
of the control system.A process with the transfer function given by Eq. (5.48)
has one integrator and, in a unity feedback conﬁguration, will be a Type 1
control system. In this case the steady-state error in tracking a ramp input is
given by the velocity constant:
Kv = lim
s→0 sKL(s)
(5.51)
= lim
s→0 s
K
s[(s + 4)2 + 16]
(5.52)
= K
32.
(5.53)
With the gain set for complex roots at a damping ζ = 0.5, the root-locus gain
is K = 65, so from Eq. (5.53) we get Kv = 65/32 ∼= 2 sec−1. If the closed-
loop dynamic response, as determined by the root locations, is satisfactory
and the steady-state accuracy, as measured by Kv, is good enough, then the
design can be completed by gain selection alone. However, if no value of
K satisﬁes all of the constraints, as is typically the case, then additional
modiﬁcations are necessary to meet the system speciﬁcations.
5.3
Selected Illustrative Root Loci
A number of important control problems are characterized by a process with
the simple "double integrator" transfer function
G(s) = 1
s2 .
(5.54)
The control of attitude of a satellite is described by this equation. Also, the
read/write head assembly of a computer hard-disk drive is typically ﬂoating

252
Chapter 5 The Root-Locus Design Method
on an air bearing so that friction is negligible for all but the smallest motion.
The motor is typically driven by a current source so the back emf does not
affect the torque. The result is a plant described by Eq. (5.54). If we form a
unity feedback system with this plant, and a proportional controller, the root
locus with respect to controller gain is
1 + kp
1
s2 = 0.
(5.55)
If we apply the rules to this (trivial) case, the results are as follows:
RULE 1. The locus has two branches that start at s = 0.
RULE 2. There are no parts of the locus on the real axis.
RULE 3. The two asymptotes have origin at s = 0 and are at the angles of
±90◦.
RULE 4. The loci depart from s = 0 at the angles of ±90◦.
Conclusion: The locus consists of the imaginary axis and the transient would
be oscillatory for any value of kp. A more useful design results with the use
of proportional plus derivative control.
EXAMPLE 5.3
Root Locus for Satellite Attitude Control with PD Control
The characteristic equation with PD control is
1 +

kp + kDs
 1
s2 = 0.
(5.56)
To put the equation in root-locus form, we deﬁne K = kD, and for the
moment arbitrarily select the gain ratio9 as kp/kD = 1, which results in the
root-locus form
1 + K s + 1
s2
= 0.
(5.57)
Solution. Again we compute the results of the rules:
RULE 1. There are two branches that start at s = 0, one of which terminates
on the zero at s = −1 and the other of which approaches inﬁnity.
RULE 2. The real axis to the left of s = −1 is on the locus.
RULE 3. Since n −m = 1, there is one asymptote along the negative real
axis.
RULE 4. The angles of departure from the double pole at s = 0 are ±90◦.
9Given a speciﬁc physical system, this number would be selected with consideration of the
speciﬁed rise time of the design or the maximum control signal (control authority) of the
actuator.

5.3 Selected Illustrative Root Loci
253
Figure 5.10
Root locus for
L(s) = G(s) = (s+1)
s2
-6
-4
Real axis
-2
0
2
-3
-2
-1
0
1
2
3
Imaginary axis
RULE 5. From Rules 1-4, it should be clear that the locus will curl around
the zero, rejoin the real axis to the left of the zero, and terminate as indicated
by Rule 1. It turns out that the locus segments rejoin the real axis at s = −2,
which creates a point of multiple roots. Evaluation of the angle of arrival at
this point will show that the segments arrive at ±90◦. We conclude that two
branches of the locus leave the origin going north and south, and that they
curve around10 without passing into the RHP and break into the real axis
at s = −2, from which point one branch goes west toward inﬁnity and the
other goes east to rendezvous with the zero at s = −1. The locus is plotted
in Fig. 5.10 with the commands
s = tf('s');
sysS = (s +1)/(sˆ2);
rlocus( sysS)
Comparing this case with that for the simple 1/s2, we see that
The addition of the zero has pulled the locus into the LHP, a point
of general importance in constructing a compensation.
In the previous case, we considered pure PD control. However, as
we have mentioned earlier, the physical operation of differentiation is not
practical and in practice PD control is approximated by
Dc(s) = kp +
kDs
s/p + 1,
(5.58)
10You can prove that the path is a circle by assuming that s + 1 = ejθ and showing that
the equation has a solution for a range of positive K and real θ under this assumption. (See
Problem 5.18.)

254
Chapter 5 The Root-Locus Design Method
which can be put in root-locus form by deﬁning K = kp + pkD and z =
pkp/K so that11
Dc(s) = K s + z
s + p.
(5.59)
For reasons we will see when we consider design by frequency response, this
controller transfer function is called a "lead compensator" provided z < p or,
referring to the frequent implementation by electrical components, a "lead
network."The characteristic equation for the 1/s2 plant with this controller is
1 + Dc(s)G(s) = 1 + KL(s) = 0,
1 + K
s + z
s2(s + p) = 0.
EXAMPLE 5.4
Root Locus of the Satellite Control with Modiﬁed
PD or Lead Compensation
To evaluate the effect of the added pole, we will again set z = 1 and consider
three different values for p. We begin with a somewhat large value, p = 12,
and consider the root locus for
1 + K
s + 1
s2(s + 12).
(5.60)
Solution. Again, we apply the rules for plotting a root locus:
RULE 1. There are now three branches to the locus, two starting at s = 0
and one starting at s = −12.
RULE 2. The real axis segment −12 ≤s ≤−1 is part of the locus.
RULE 3. There are n −m = 3 −1 = 2 asymptotes centered at α =
−12−(−1)
2
= −11/2 and at the angles ±90◦.
RULE 4. The angles of departure of the branches at s = 0 are again ±90◦.
The angle of departure from the pole at s = −12 is at 0◦.
There are several possibilities on how the locus segments behave while
still adhering to the guidance above. Matlab is the expedient way to discover
the paths. The Matlab commands
s = tf('s');
sysL = (s + 1)/((sˆ2)*(s + 12));
rlocus(sysL)
show that two branches of locus break vertically from the poles at s = 0,
curve around to the left without passing into the RHP, and break in at s =
−2.3, where one branch goes right to meet the zero at s = −1 and the other
goes left, where it is met by the root that left the pole at s = −12. These two
11The use of z here for zero is not to be confused with the use of the operator z used in deﬁning
the discrete transfer function that is described in Chapter 8.

5.3 Selected Illustrative Root Loci
255
Figure 5.11
Root locus for
L(s) =
(s+1)
s2(s+12)
-6
-4
Real axis
-2
0
2
-3
-2
-1
0
1
2
3
Imaginary axis
form a multiple root at s = −5.2 and break away there and approach the
vertical asymptotes located at s = −5.5. The locus is plotted in Fig. 5.11.
Considering this locus, we see that the effect of the added pole has been
to distort the simple circle of the PD control but, for points near the origin,
the locus is quite similar to the earlier case. The situation changes when the
pole is brought closer in.
EXAMPLE 5.5
Root Locus of the Satellite Control with Lead Having
a Relatively Small Value for the Pole
Now consider p = 4 and draw the root locus for
1 + K
s + 1
s2(s + 4) = 0.
(5.61)
Solution. Again, by the rules, we have the following:
RULE 1. There are again three branches to the locus, two starting from
s = 0 and one from s = −4.
RULE 2. The segment of the real axis −4 ≤s ≤−1 is part of the locus.
RULE 3. There are two asymptotes centered at α = −3/2 and at the angles
±90◦.
RULE 4. The branches again depart from the poles at s = 0 at ±90◦.
RULE 5. The Matlab commands
s = tf('s');
sysL = (s + 1)/((sˆ2)*(s + 4));
rlocus(sysL)
show that two branches of this locus break away vertically from the poles
at s = 0, curve slightly to the left and join the asymptotes going north and
south. The locus segment from the root at s = −4 goes east and terminates
at the zero. In this case, the locus differs from the case when s = −12 in

256
Chapter 5 The Root-Locus Design Method
Figure 5.12
Root locus for
L(s) =
(s+1)
s2(s+4)
-6
-4
Real axis
-2
0
2
-3
-2
-1
0
1
2
3
Imaginary axis
that there are no break-in or breakaway points on the real axis as part of the
locus. The Matlab plot is given in Fig. 5.12.
In these two cases we have similar systems, but in one case, p = 12,
there were both break-in and breakaway points on the real axis, whereas for
p = 4, these features have disappeared. A logical question might be to ask
at what point they went away. As a matter of fact, it happens at p = 9, and
we'll look at that locus next.
EXAMPLE 5.6
The Root Locus for the Satellite with a Transition
Value for the Pole
Plot the root locus for
1 + K
s + 1
s2(s + 9) = 0.
(5.62)
Solution.
RULE 1. The locus has three branches, starting from s = 0 and s = −9.
RULE 2. The real axis segment −9 ≤s ≤−1 is part of the locus.
RULE 3. The two asymptotes are centered at α = −8/2 = −4.
RULE 4. The departures are, as before, at ±90◦from s = 0.
RULE 5. The Matlab commands
s = tf('s')
sysL = (s + 1)/((sˆ2)*(s+9));
rlocus(sysL)
produces the locus in Fig. 5.13. It shows the two branches of this locus break
away vertically from the poles at s = 0 and curl around and join the real
axis again at s = −3 with an angle of arrival of ±60◦while the branch
from the pole at s = −9 heads east and joins the other two poles at s = −3
with an angle of arrival of 0◦. These three locus segments continue on by

5.3 Selected Illustrative Root Loci
257
Figure 5.13
Root locus for
L(s) =
(s+1)
s2(s+9)
-6
-4
Real axis
-2
0
2
-3
-2
-1
0
1
2
3
Imaginary axis
splitting out of s = −3 at the departure angles of 0◦and ±120◦, with one
heading into the zero and the other two heading away to the northwest to
join the asymptotes. Using Rule 5 would conﬁrm these angles of arrival and
departure.12 Note that this special locus shape only occurs when the ratio of
the pole value to the zero value is exactly 9:1 for this form of L(s). It is the
transition locus between the two types depicted by Examples 5.4 and 5.5.
This transition is discussed in more detail below and will be demonstrated
via Matlab in Example 5.7.
From Figs. 5.11 through 5.13, it is evident that when the third pole
is near the zero (p near 1), there is only a modest distortion of the locus
that would result for Dc(s)G(s) ∼= K 1
s2 , which consists of two straight-line
locus branches departing at ±90◦from the two poles at s = 0. Then, as
we increase p, the locus changes until at p = 9; the locus breaks in at −3
in a triple multiple root. As the pole p is moved to the left beyond −9, the
locus exhibits distinct break-in and breakaway points, approaching, as p gets
very large, the circular locus of one zero and two poles. Figure 5.13, when
p = 9, is thus a transition locus between the two second-order extremes,
which occur at p = 1 (when the zero is canceled) and p →∞(where the
extra pole has no effect).
EXAMPLE 5.7
An Exercise to Repeat the Prior Examples Using rltool
Repeat Examples 5.3 through 5.6 using Matlab's rltool feature.
Solution. rltool is an interactive root-locus design tool in Matlab that pro-
vides a graphical user interface (GUI) for performing root-locus analysis and
design. rltool provides an easy way to design feedback controllers because
it allows rapid iterations and quickly shows their effect on the resulting root
locus. To illustrate the use of the tool, the Matlab commands
12The shape of this special root locus is a trisectrix of Maclaurin, a plane curve that can be used
to trisect an angle.

258
Chapter 5 The Root-Locus Design Method
Figure 5.14
rltool graphical user
interface
s = tf('s');
sysL = (s + 1)/(sˆ2);
rltool(sysL)
will initiate the GUI and produce the root locus shown in Fig. 5.10, which
is similar to Examples 5.4 through 5.6, but without the pole on the negative
real axis that was moved around for illustration purposes in the three prior
examples. By clicking on "Compensator Editor" in the "Control and Esti-
mation Tools Manager" window, right clicking on the "Dynamics" dialog
window and selecting "add pole/zero," you can add a pole at the location
s = −12. This will produce the locus that is shown in Figs. 5.11 and 5.14.
Now put your mouse on the pole at s = −12, hold down the mouse button,
and slide it from s = −12 to s = −4 slowly, so you can examine the locus
shapes at all intermediate points. Be especially careful (and slow) as you
pass through s = −9 because the locus shape changes very quickly with
the pole in this region. Note that you can also put your mouse on one of
the closed-loop poles (squares) and slide that along the locus. It will show
you the location of the other roots that correspond to that value of the gain,
K, and the frequency and damping of the closed-loop roots will be shown

5.3 Selected Illustrative Root Loci
259
for when the roots are complex pairs. More detail can be found in the rltool
Tutorial in Appendix WR.
A useful conclusion drawn from this example is the following:
An additional pole moving in from the far left tends to push the
locus branches to the right as it approaches a given locus.
The double integrator is the simplest model of the examples, assuming
a rigid body with no friction. A more realistic case would include the effects
of ﬂexibility in the satellite attitude control, where at least the solar panels
would be ﬂexible. In the case of the disk drive read/write mechanism, the
head and supporting arm assembly always has ﬂexibility and usually a very
complex behavior with a number of lightly damped modes, which can often
be usefully approximated by a single dominant mode. In Section 2.1 it was
shown that ﬂexibility in the disk drive added a set of complex poles to the
1/s2 model. Generally there are two possibilities, depending on whether the
sensor is on the same rigid body as the actuator, which is called the collocated
case,13 or is on another body, which is called the noncollocated case.14 We
begin with consideration of the collocated case similar to that given by
Eq. (2.20). As we saw in Chapter 2, the transfer function in the collocated
case has not only a pair of complex poles but also a pair of nearby complex
zeros located at a lower natural frequency than the poles. The numbers in the
examples that follow are chosen more to illustrate the root-locus properties
than to represent particular physical models.
EXAMPLE 5.8
Root Locus of the Satellite Control with a Collocated Flexibility
Plot the root locus of the characteristic equation 1 + G(s)Dc(s) = 0, where
G(s) =
(s + 0.1)2 + 62
s2[(s + 0.1)2 + 6.62]
(5.63)
is in a unity feedback structure with the controller transfer function
Dc(s) = K s + 1
s + 12.
(5.64)
Solution. In this case,
L(s) = s + 1
s + 12
(s + 0.1)2 + 62
s2[(s + 0.1)2 + 6.62]
has both poles and zeros near the imaginary axis and we should expect to
ﬁnd the departure angles of particular importance.
13Typical of the satellite attitude control, where the ﬂexibility arises from solar panels and both
actuator and sensor act on the main body of the satellite.
14Typical of the satellite, where there is ﬂexibility between an attitude sensor and the controller.
This case is also typical of computer hard-disk read/write head control, where the motor is on
one end of the arm and the head is on the other.

260
Chapter 5 The Root-Locus Design Method
Figure 5.15
Figure for computing a
departure angle for
L(s) =
s+1
s+12
(s+0.1)2+62
s2[(s+0.1)2+6.62]
-15
-10
Real axis
0
-5
5
-8
-6
-4
-2
0
2
4
6
8
Imaginary axis
f5
c1
f1
f2, f3
f4
Solution
RULE 1. There are ﬁve branches to the locus, three of which approach ﬁnite
zeros and two of which approach the asymptotes.
RULE 2. The real-axis segment −12 ≤s ≤−1 is part of the locus.
RULE 3. The center of the two asymptotes is at
α = −12 −0.1 −0.1 −(−0.1 −0.1 −1)
5 −3
= −11
2 .
The angle of the asymptotes is ±90◦.
RULE 4. We compute the departure angle from the pole at s = −0.1+j6.6.
The angle at this pole we will deﬁne to be φ1. The other angles are marked
on Fig. 5.15. The root-locus condition is
φ1 = ψ1 + ψ2 + ψ3 −(φ2 + φ3 + φ4 + φ5) −180◦,
φ1 = 90◦+ 90◦+ tan−1(6.6) −[90◦+ 90◦+ 90◦
+ tan−1
6.6
12

] −180◦,
(5.65)
φ1 = 81.4◦−90◦−28.8◦−180◦,
= −217.4◦= 142.6◦,
so the root leaves this pole up and to the left, into the stable region of the
plane. An interesting exercise would be to compute the arrival angle at the
zero located at s = −0.1 + j6.
Using Matlab, the locus is plotted in Fig. 5.16. Note that all the attributes
that were determined using the simple rules were exhibited by the plot, thus
verifying in part that the data were entered correctly.

5.3 Selected Illustrative Root Loci
261
Figure 5.16
Root locus for L(s) =
s+1
s+12
(s+0.1)2+62
s2[(s+0.1)2+6.62]
-15
-10
Real axis
0
-5
5
-8
-6
-4
-2
0
2
4
6
8
Imaginary axis
The previous example showed that
In the collocated case, the presence of a single ﬂexible mode intro-
duces a lightly damped root to the characteristic equation but does
not cause the system to be unstable.
The departure angle calculation showed that the root departs from the
pole introduced by the ﬂexible mode toward the LHP. Next, let's consider
the noncollocated case, for which we take the plant transfer function to be
G(s) =
1
s2[(s + 0.1)2 + 6.62],
(5.66)
compensated again by the lead
Dc(s) = K s + 1
s + 12.
(5.67)
As these equations show, the noncollocated transfer function has the com-
plex poles but does not have the associated complex zeros as in the previous
example, and that we also saw for the collocated case of Chapter 2 in
Eq. (2.20). This will have a substantial effect, as illustrated by Example 5.9.
EXAMPLE 5.9
Root Locus for the Noncollocated Case
Apply the rules and draw the root locus for
KL(s) = DcG = K s + 1
s + 12
1
s2[(s + 0.1)2 + 6.62],
(5.68)
paying special attention to the departure angles from the complex poles.
Solution
RULE 1. There are ﬁve branches to the root locus, of which one approaches
the zero and four approach the asymptotes.
RULE 2. The real-axis segment deﬁned by −12 ≤s ≤−1 is part of the
locus.

262
Chapter 5 The Root-Locus Design Method
RULE 3. The center of the asymptotes is located at
α = −12 −0.2 −(−1)
5 −1
= −11.2
4
,
and the angles for the four asymptotic branches are at ±45◦, ±135◦.
RULE 4. We again compute the departure angle from the pole at s = −0.1+
j6.6. The angle at this pole we will deﬁne to be φ1. The other angles are
marked on Fig. 5.17. The root locus condition is
φ1 = ψ1 −(φ2 + φ3 + φ4 + φ5) −180◦,
φ1 = tan−1(6.6) −
	
90◦+ 90◦+ 90◦+ tan−1
6.6
12

−180◦,
φ1 = 81.4◦−90◦−90◦−90◦−28.8◦−180◦,
(5.69)
φ1 = 81.4◦−90◦−28.8◦−360◦,
φ1 = −37.4◦.
In this case, the root leaves the pole down and to the right, toward the
unstable region. We would expect the system to soon become unstable as
gain is increased.
RULE 5. The locus is plotted in Fig. 5.18 with the commands
Figure 5.17
Figure to compute
departure angle for
L(s) =
s+1
s+12
(s+0.1)2+62
s2[(s+0.1)2+6.62]
-15
-10
Real axis
0
-5
5
-8
-6
-4
-2
0
2
4
6
8
Imaginary axis
f5
c1
f1
f2, f3
f4
Figure 5.18
Root locus for L(s) =
s+1
s+12
(s+0.1)2+62
s2[(s+0.1)2+6.62]
-15
-10
Real axis
0
-5
5
-8
-6
-4
-2
0
2
4
6
8
Imaginary axis

5.3 Selected Illustrative Root Loci
263
s = tf('s');
sysG = 1/((sˆ2)*((s + 0.1)ˆ2 + (6.6)ˆ2));
sysD = (s + 1)/(s + 12);
sysL = sysD*sysG;
rlocﬁnd(sysL)
and is seen to agree with the calculations above. By using rltool, we see that
the locus from the complex poles enter into the RHP almost immediately
as the gain is increased. Furthermore, by selecting those roots so that they
are just to the left of the imaginary axis, it can be seen that the dominant
slow roots down near the origin have extremely low damping. Therefore, this
systemwillhaveaverylightlydampedresponsewithveryoscillatoryﬂexible
modes. It would not be considered acceptable with the lead compensator as
chosen for this example.
A Locus with Complex Multiple Roots
We have seen loci with break-in and breakaway points on the real axis. Of
course, an equation of fourth or higher order can have multiple roots that
are complex. Although such a feature of a root locus is a rare event, it is an
interesting curiosity that is illustrated by the next example.
EXAMPLE 5.10
Root Locus Having Complex Multiple Roots
Sketch the root locus of 1 + KL(s) = 0, where
L(s) =
1
s(s + 2)[(s + 1)2 + 4].
Solution
RULE 1. There are four branches of the locus, all of which approach the
four asymptotes.
RULE 2. The real-axis segment −2 ≤s ≤0 is on the locus.
RULE 3. The center of the asymptotes is at
α = −2 −1 −1 −0 + 0
4 −0
= −1
and the angles are φl = 45◦, 135◦, −45◦, −135◦.
RULE 4. The departure angle φdep from the pole at = −1 + 2j, based on
Fig. 5.19, is
φdep = φ3 = −φ1 −φ2 −φ4 + 180◦
= −tan−1
 2
−1

−tan−1
2
1

−90◦+ 180◦
−116.6◦−63.4◦−90◦+ 180◦
= −90◦.

264
Chapter 5 The Root-Locus Design Method
Figure 5.19
Figure to compute
departure angle for
L(s) =
1
s(s+1)[(s+1)2+4]
-4
-2
Real axis
0
2
4
-3
-2
-1
0
1
2
3
Imaginary axis
f3
f1
f2
f4
Figure 5.20
Root locus for
L(s) =
1
s(s+1)[(s+1)2+4]
-4
-2
Real axis
0
2
4
-3
-2
-1
0
1
2
3
Imaginary axis
We can observe at once that, along the line s = −1 + jω, φ2 and φ1 are
angles of an isosceles triangle and always add to 180◦. Hence, the entire line
from one complex pole to the other is on the locus in this special case.
RULE 5. Using Matlab, we see that there are multiple roots at s =
−1±1.22j, and branches of the locus (Fig. 5.20) come together at −1±1.22j.
Using Rule 5, we can verify that the locus segments break away at 0◦and
180◦as shown by Matlab.
The locus in this example is a transition between two types of loci: one
where the complex poles are to the left of the example case and approach the
asymptotes at ±135◦, and another where the complex poles are to the right
of their positions in the example and approach the asymptotes at ±45◦.
5.4
Design Using Dynamic Compensation
Consideration of control design begins with the design of the process itself.
The importance of early consideration of potential control problems in the
design of the process and selection of the actuator and sensor cannot be

5.4 Design Using Dynamic Compensation
265
overemphasized. It is not uncommon for a ﬁrst study of the control to sug-
gest that the process itself can be changed by, for example, adding damping
or stiffness to a structure to make a ﬂexibility easier to control. Once these
factors have been taken into account, the design of the controller begins. If
the process dynamics are of such a nature that a satisfactory design cannot
be obtained by adjustment of the proportional gain alone, then some modi-
ﬁcation or compensation of the dynamics is indicated. While the variety of
possible compensation schemes is great, three categories have been found
to be particularly simple and effective. These are lead, lag, and notch com-
pensations.15 Lead compensation approximates the function of PD control
Lead and lag
compensations
and acts mainly to speed up a response by lowering rise time and decreasing
the transient overshoot. Lag compensation approximates the function of PI
control and is usually used to improve the steady-state accuracy of the sys-
tem. Notch compensation will be used to achieve stability for systems with
lightly damped ﬂexible modes, as we saw with the satellite attitude control
having noncollocated actuator and sensor. In this section we will examine
Notch compensation
techniques to select the parameters of these three schemes. Lead, lag, and
notch compensations have historically been implemented using analog elec-
tronics and, hence were often, referred to as networks. Today, however, most
new control system designs use digital computer technology, in which the
compensation is implemented in the software. In this case, one needs to
compute discrete equivalents to the analog transfer functions, as described
in Chapter 8, and in Franklin et al. (1998).
Compensation with a transfer function of the form
Dc(s) = K s + z
s + p
(5.70)
is called lead compensation if z < p and lag compensation if z > p. Compen-
sation is typically placed in series with the plant, as shown in Fig. 5.21. It can
also be placed in the feedback path and in that location has the same effect
on the overall system poles but results in different transient responses from
reference inputs. The characteristic equation of the system in Fig. 5.21 is
1 + Dc(s)G(s) = 0,
1 + KL(s) = 0,
Figure 5.21
Feedback system with
compensation
 + 
 - 
R
Y
Controller
Plant
G(s)
Dc(s)
U
©
15The names of these compensation schemes derive from their frequency (sinusoidal)
responses, wherein the output leads the input in one case (a positive phase shift) and lags
the input in another (a negative phase shift). The frequency response of the third looks as if a
notch had been cut in an otherwise ﬂat frequency response. See Chapter 6.

266
Chapter 5 The Root-Locus Design Method
where K and L(s) are selected to put the equation in root-locus form as
before.
5.4.1
Design Using Lead Compensation
To explain the basic stabilizing effect of lead compensation on a system, we
ﬁrst consider proportional control for which Dc(s) = K. If we apply this
compensation to a second-order position control system with normalized
transfer function
G(s) =
1
s(s + 1),
the root locus with respect to K is shown as the solid-line portion of the locus
in Fig. 5.22. Also shown in Fig. 5.22 is the locus produced by proportional
plus derivative control, where Dc(s) = K(s + 2). The modiﬁed locus is the
circle sketched with dashed lines. As we saw in the examples, the effect of
the zero is to move the locus to the left, toward the more stable part of the s-
plane. If, now, our speed-of-response speciﬁcation calls for ωn ∼= 2 rad/sec,
then proportional control alone (Dc = K) can produce only a very low value
of damping ratio ζ when the roots are put at the required value of ωn. Hence,
at the required gain, the transient overshoot will be substantial. However, by
adding the zero of PD control, we can move the locus to a position having
closed-loop roots at ωn = 2 rad/sec and damping ratio ζ ≥0.5. We have
"compensated" the given dynamics by using Dc(s) = K(s + 2).
As we observed earlier, pure derivative control is not normally practical
because of the ampliﬁcation of sensor noise implied by the differentiation
and must be approximated. If the pole of the lead compensation is placed
well outside the range of the design ωn, then we would not expect it to upset
the dynamic response of the design in a serious way. For example, consider
the lead compensation
Dc(s) = K s + 2
s + p.
Figure 5.22
Root loci for
1 + D(s)G(s) = 0,
G(s) =
1
s(s+1): with
compensation D(s) = K
(solid lines) and with
D(s) = K(s + 2)
(dashed lines)
Imaginary axis
Real axis
-6
2
1
0
-1
-2
-3
-4
-5
-3
-2
-1
0
1
2
3

5.4 Design Using Dynamic Compensation
267
Figure 5.23
Root loci for three cases
with G(s) =
1
s(s+1):
(a) D(s) = (s+2)
(s+20);
(b) D(s) = (s+2)
(s+10);
(c) D(s) = s + 2 (solid
lines)
Imaginary axis
Real axis
-6
2
1
0
-1
-2
-3
-4
-5
-3
-2
-1
0
1
2
3
Lead pole at -20
Lead pole at -10
PD control
The root loci for two cases with p = 10 and p = 20 are shown in
Fig. 5.23, along with the locus for PD control. The important fact about
these loci is that for small gains, before the real root departing from −p
approaches −2, the loci with lead compensation are almost identical to the
locus for which Dc(s) = K(s+2). Note that the effect of the pole is to lower
the damping, but for the early part of the locus, the effect of the pole is not
great if p > 10.
Selecting exact values of z and p in Eq. (5.70) for particular cases is
often done by trial and error, which can be minimized with experience.
Selection of the
zero and pole of a lead
In general, the zero is placed in the neighborhood of the closed-loop ωn, as
determined by rise-time or settling-time requirements, and the pole is located
at a distance 5 to 20 times the value of the zero location. But there are trade-
offs to consider. The choice of the exact pole location is a compromise
between the conﬂicting effects of noise suppression, for which one wants
a small value for p, and compensation effectiveness for which one wants
a large p. In general, if the pole is too close to the zero, then, as seen in
Fig. 5.23, the root locus moves back too far toward its uncompensated shape
and the zero is not successful in doing its job. On the other hand, for reasons
that are perhaps easier to understand from the frequency response, when the
pole is too far to the left, the magniﬁcation of sensor noise appearing at the
output of Dc(s) is too great and the motor or other actuator of the process can
be overheated by noise energy in the control signal, u(t). With a large value
of p, the lead compensation approaches pure PD control. A simple example
will illustrate the approach.
EXAMPLE 5.11
Design Using Lead Compensation
Find a compensation for G(s) = 1/[s(s + 1)] that will provide overshoot of
no more than 20% and rise time of no more than 0.3 sec.
Solution. From Chapter 3, we estimate that a damping ratio of ζ ≥0.5 and
a natural frequency of ωn ∼= 1.8
0.3 ∼= 6 rad/sec should satisfy the requirements.

268
Chapter 5 The Root-Locus Design Method
To provide some margin, we will shoot for ζ ≥0.5 and ωn ≥7 rad/sec.
Considering the root loci plotted in Fig. 5.23, we will ﬁrst try
Dc(s) = K s + 2
s + 10.
Figure 5.24 shows that K = 70 will yield ζ = 0.56 and ωn = 7.7 rad/sec,
which satisﬁes the goals based on the initial estimates. The third pole will be
at s = −2.4 with K = 70. Because this third pole is so near the lead zero at
−2, the overshoot should not be increased very much from the second-order
case. However, Fig. 5.25 shows that the step response of the system exceeds
the overshoot speciﬁcation by a small amount. Typically, lead compensation
intheforwardpathwillincreasethestep-responseovershootbecausethezero
of the compensation has a differentiating effect, as discussed in Chapter 3.
The rise-time speciﬁcation has been met because the time for the amplitude
to go from 0.1 to 0.9 is less than 0.3 sec.
Figure 5.24
Root locus for lead
design
 -14
4
2
0
 -2
 -4
 -6
 -8
 -10
 -12
Real axis
 -8
 -6
 -4
 -2
0
2
4
6
8
Imaginary axis
Damping = 0.5
K = 70
v = 7
Figure 5.25
Step response for
Example 5.11
0
1.8
1.5
1.2
0.9
0.6
0.3
Time (sec)
1.4
1.2
1
0.8
0.6
0.4
0.2
0
Amplitude

5.4 Design Using Dynamic Compensation
269
Figure 5.26
Illustration of the
tuning of the dynamic
lead compensator using
rltool
We want to tune the compensator to achieve better damping in order to
reduce the overshoot in the transient response. The expedient way to do this
is to use rltool,
s = tf('s');
sysG=1/(s*(s + 1));
sysD=(s + 2)/(s + 10);
rltool(sysG,sysD)
By moving the pole of the lead compensator more to the left in order to
pull the locus in that direction, and selecting K = 91, we obtain
Dc(s) = 91 (s + 2)
(s + 13),
which will provide more damping than the previous design iteration. Fig-
ure 5.26 shows the root locus with the s-plane regions superimposed on
the same plot from rltool. The transient response from rltool is shown in
Fig. 5.27 and demonstrates that the overshoot speciﬁcation is now met (in
fact exceeded) with Mp = 17% and the rise time has degraded some from
the previous iteration, but still satisﬁes the 0.3-sec speciﬁcation.

270
Chapter 5 The Root-Locus Design Method
Figure 5.27
Step response for
K = 91 and
L(s) = (s+2)
(s+13)
1
s(s+1)
1.4
1.2
1
0.8
0.6
0.4
0.2
0
Amplitude
0
0.2
0.4
0.6
0.8
1
Time (sec)
1.2
1.4
1.6
1.8
As stated earlier, the name lead compensation is a reﬂection of the fact
that to sinusoidal signals, these transfer functions impart phase lead. For
example, the phase of Eq. (5.70) at s = jω is given by
φ = tan−1
ω
z

−tan−1
ω
p

.
(5.71)
If z < p, then φ is positive, which by deﬁnition indicates phase lead. The
details of design using the phase angle of the lead compensation will be
treated in Chapter 6.
5.4.2
Design Using Lag Compensation
Once satisfactory dynamic response has been obtained, perhaps by using one
or more lead compensations, we may discover that the low-frequency gain—
the value of the relevant steady-state error constant, such as Kv—is still too
low. As we saw in Chapter 4, the system type, which determines the degree
of the polynomial the system is capable of following, is determined by the
order of the pole of the transfer function Dc(s)G(s) at s = 0. If the system is
Type 1, the velocity-error constant, which determines the magnitude of the
error to a ramp input, is given by lims→0 sDc(s)G(s). In order to increase
this constant, it is necessary to do so in a way that does not upset the already
satisfactory dynamic response. Thus, we want an expression for Dc(s) that
will yield a signiﬁcant gain at s = 0 to raise Kv (or some other steady-state

5.4 Design Using Dynamic Compensation
271
error constant) but is nearly unity (no effect) at the higher frequency ωn,
where dynamic response is determined. The result is
Dc(s) = s + z
s + p,
z > p,
(5.72)
where the values of z and p are small compared with ωn, yet Dc(0) =
z/p = 3 to 10 (the value depending on the extent to which the steady-state
gain requires boosting). Because z > p, the phase φ given by Eq. (5.71)
is negative, corresponding to phase lag. Hence a device with this transfer
function is called lag compensation.
The effects of lag compensation on dynamic response can be studied
An example of lag
compensation
by looking at the corresponding root locus. Again, we take G(s) =
1
s(s+1),
include the lead compensation KDc1(s) = K(s+2)
(s+13) that produced the locus
in Fig. 5.26. With the gain of K = 91 from the previous tuned example, we
ﬁnd that the velocity constant is
Kv = lim
s→0 sKDc1G
= lim
s→0 s(91) s + 2
s + 13
1
s(s + 1)
= 91 ∗2
13
= 14.
Suppose we require that Kv = 70 sec−1in order to reduce the velocity
error by a factor of 5. To obtain this, we require a lag compensation with
z/p = 5 in order to increase the velocity constant by a factor of 5. This can be
accomplished with a pole at p = −0.01 and a zero at z = −0.05, which keeps
the values of both z and p very small so that Dc2(s) would have little effect
on the portions of the locus representing the dominant dynamics around
ωn = 7 rad/sec. The result is a lag compensation with the transfer function
of Dc2(s) = (s+0.05)
(s+0.01). The root locus with both lead and lag compensation
is plotted in Fig. 5.28 and we see that, for the large scale on the left, the
locus is not noticeably different from that in Fig. 5.26. This was the result of
selecting very small values for the pole and zero. With K = 91, the dominant
roots are at −5.8 ± j6.5. The effect of the lag compensation can be seen by
expanding the region of the locus around the origin as shown on the right side
of Fig. 5.28. Here we can see the circular locus that is a result of the small
pole and zero. A closed-loop root remains very near the lag-compensation
zero at −0.05 + 0j; therefore, the transient response corresponding to this
root will be a very slowly decaying term, which will have a small magnitude
because the zero will almost cancel the pole in the transfer function. Still,
the decay is so slow that this term may seriously inﬂuence the settling time.
Furthermore, the zero will not be present in the step response to a disturbance
torque and the slow transient will be much more evident there. Because of
this effect, it is important to place the lag pole-zero combination at as high
a frequency as possible without causing major shifts in the dominant root
locations.

272
Chapter 5 The Root-Locus Design Method
−12
−10
−8
−6
−4
−2
2
−8
−6
−4
−2
2
4
6
8
Im(s)
Re(s)
−0.08
−0.06
−0.04
−0.02
0.02
0.04
0.06
0.08
Im(s)
Re(s)
−0.14 −0.12
−0.1
−0.08 −0.06 −0.04
−0.02
0.02
0.04
Figure 5.28
Root locus with both lead and lag compensation
5.4.3
Design Using Notch Compensation
Suppose the design has been completed with lead and lag compensation
given by
KDc(s) = 91 s + 2
s + 13
s + 0.05
s + 0.01,
(5.73)
but is found to have a substantial oscillation at about 50 rad/sec when tested,
because there was an unsuspected ﬂexibility of the noncollocated type at a
natural frequency of ωn = 50 rad/sec. On reexamination, the plant transfer
function, including the effect of the ﬂexibility, is estimated to be
G(s) =
2500
s(s + 1)(s2 + s + 2500).
(5.74)
A mechanical engineer claims that some of the "control energy" has spilled
over into the lightly damped ﬂexible mode and caused it to be excited. In
other words, as we saw from the similar system whose root locus is shown
in Fig. 5.18, the very lightly damped roots at 50 rad/sec have been made
even less damped or perhaps unstable by the feedback. The best method
to ﬁx this situation is to modify the structure so that there is a mechanical
increase in damping. Unfortunately, this is often not possible because it is
found too late in the design cycle. If it isn't possible, how else can this
oscillation be corrected? There are at least two possibilities. An additional
lag compensation might lower the loop gain far enough that there is greatly
reduced spillover and the oscillation is eliminated. Reducing the gain at the
high frequency is called gain stabilization. If the response time resulting
Gain stabilization
from gain stabilization is too long, a second alternative is to add a zero near
the resonance so as to shift the departure angles from the resonant poles

5.4 Design Using Dynamic Compensation
273
so as to cause the closed-loop root to move into the LHP, thus causing the
associated transient to die out. This approach is called phase stabilization,
Phase stabilization
and its action is similar to that of ﬂexibility in the collocated motion control
discussed earlier. Gain and phase stabilization are explained more precisely
by their effect on the frequency response in Chapter 6 where these methods
of stabilization will be discussed further. For phase stabilization, the result
is called a notch compensation, and an example has a transfer function
Dnotch(s) = s2 + 2ζωos + ω2
o
(s + ωo)2
.
(5.75)
A necessary design decision is whether to place the notch frequency above
or below that of the natural resonance of the ﬂexibility in order to get the
necessary phase. A check of the angle of departure shows that with the plant
as compensated by Eq. (5.73) and the notch as given, it is necessary to place
the frequency of the notch above that of the resonance to get the departure
angle to point toward the LHP. Thus the compensation is added with the
transfer function
Dnotch(s) = s2 + 0.8s + 3600
(s + 60)2
.
(5.76)
The gain of the notch at s = 0 has been kept at 1 so as not to change the Kv.
The new root locus is shown in Fig. 5.29 and the step response is shown in
Fig. 5.30. Note from the step response that the oscillations are well damped,
the rise-time speciﬁcation is still met, but the overshoot has degraded. To
rectify the increased overshoot and strictly meet all the speciﬁcations, further
Figure 5.29
Root locus with lead,
lag, and notch
−120
−100
−80
−60
−40
Real axis
−20
100
80
60
40
20
0
20
−60
−20
−40
0
20
40
60
Imaginary axis
0.86
0.94
0.985
0.985
0.94
0.86
0.76
0.64
0.5
0.34
0.16
0.76
0.64
0.5
0.34
0.16

274
Chapter 5 The Root-Locus Design Method
Figure 5.30
Step response with
lead, lag, and notch
compensations
1.5
1
0.5
0
0
0.2
0.4
0.6
0.8
Time (sec)
Amplitude
1
1.2
1.4
1.6
1.8
iteration should be carried out in order to provide more damping of the fast
roots in the vicinity of ωn = 7 rad/sec.
When considering notch or phase stabilization, it is important to under-
stand that its success depends on maintaining the correct phase at the
frequency of the resonance. If that frequency is subject to signiﬁcant change,
which is common in many cases, then the notch needs to be removed far
enough from the nominal frequency in order to work for all cases. The result
may be interference of the notch with the rest of the dynamics and poor per-
formance. As a general rule, gain stabilization is substantially more robust
to plant changes than is phase stabilization.
5.4.4
Analog and Digital Implementations
Compensation can be physically realized in various ways. Most compensa-
△
tion can be implemented using analog electronics similar to that described in
Section 2.2. However, it is very common today to implement compensation
using digital devices.
As an example of an analog realization, a circuit diagram for lead
compensation using an operational ampliﬁer is shown in Fig. 5.31. The
transfer function of the circuit in Fig. 5.31 is readily found by the methods
of Chapter 2 to be
Dlead(s) = −a s + z
s + p,
(5.77)
Figure 5.31
Possible circuit of a lead
compensation
Vin
V0
-
C
Rf
R1
R2

5.5 A Design Example Using the Root Locus
275
where
a = p
z ,
if
Rf = R1 + R2,
z =
1
R1C ,
p = R1 + R2
R2
·
1
R1C .
A short section describing the implementation of a lead compensa-
tion using a digital device and a comparison of the results with an analog
implementation is contained in Appendix W5.4.4. See www.FPE7e.com
5.5
A Design Example Using the Root Locus
EXAMPLE 5.12
Control of a Small Airplane
For the Piper Dakota shown in Fig. 5.32, the transfer function between the
elevator input and the pitch attitude is
G(s) = θ(s)
δe(s) =
160(s + 2.5)(s + 0.7)
(s2 + 5s + 40)(s2 + 0.03s + 0.06),
(5.78)
where
θ = pitch attitude, degrees (see Fig. 10.30),
δe = elevator angle, degrees.
(For a more detailed discussion of longitudinal aircraft motion, refer to
Section 10.3.)
1. Design an autopilot so that the response to a step elevator input has a
rise time of 1 sec or less and an overshoot less than 10%.
2. When there is a constant disturbing moment acting on the aircraft so that
the pilot must supply a constant force on the controls for steady ﬂight,
it is said to be out of trim. The transfer function between the disturbing
moment and the attitude is the same as that due to the elevator; that is,
θ(s)
Md(s) =
160(s + 2.5)(s + 0.7)
(s2 + 5s + 40)(s2 + 0.03s + 0.06),
(5.79)
where Md is the moment acting on the aircraft. There is a separate
aerodynamic surface for trimming, δt, that can be actuated and will
change the moment on the aircraft. It is shown in the close-up of the
tail in Fig. 5.32. Its inﬂuence is depicted in the block diagram shown
in Fig. 5.33(a). For both manual and autopilot ﬂight, it is desirable to
adjust the trim so that there is no steady-state control effort required
from the elevator (that is, so δe = 0). In manual ﬂight, this means that
no force is required by the pilot to keep the aircraft at a constant altitude,
whereas in autopilot control it means reducing the amount of electrical

276
Chapter 5 The Root-Locus Design Method
Figure 5.32
Autopilot design in the
Piper Dakota, showing
elevator and trim tab
Source: Photos courtesy of
Denise Freeman
dt(s)
KDc(s)
1
 - 
 + 
e(s)
Md(s)
 + 
 + 
 + 
 + 
de(s)
G(s)
u(s)
ur(s)
de(s)
G(s)
u(s)
(a)
(b)
©
©
©
Figure 5.33
Block diagrams for autopilot design: (a) open loop; (b) feedback scheme excluding trim
power required and saving wear and tear on the servomotor that drives
the elevator. Design an autopilot that will command the trim δt so as
to drive the steady-state value of δe to zero for an arbitrary constant
moment Md as well as meet the speciﬁcations in part (a).
Solution
1. To satisfy the requirement that the rise time tr ≤1 sec, Eq. (3.60)
indicates that, for the ideal second-order case, ωn must be greater than

5.5 A Design Example Using the Root Locus
277
1.8 rad/sec. And to provide an overshoot of less than 10%, Fig. 3.23
indicates that ζ should be greater than 0.6, again, for the ideal second-
order case. In the design process, we can examine a root locus for a
candidate for feedback compensation and then look at the resulting
time response when the roots appear to satisfy the design guidelines.
However, since this is a fourth-order system, the design guidelines
might not be sufﬁcient, or they might be overly restrictive.
To initiate the design process, it is often instructive to look at
the system characteristics with proportional feedback, that is, where
Dc(s) = 1 in Fig. 5.33(b). The statements in Matlab to create a
root locus with respect to K and a time response for the proportional
feedback case with K = 0.3 are as follows:
s = tf('s');
sysG = (160*(s + 2.5)*(s + 0.7))/((sˆ2 + 5*s + 40)*(sˆ2 + 0.03*s +
0.06));
rlocus(sysG)
K = 0.3;
sysL = K*sysG;
[sysT] = feedback (sysL,1);
step(sysT)
The resulting root locus and time response are shown with dashed lines
in Figs. 5.34 and 5.35. Notice from Fig. 5.34 that the two faster roots
Re(s)
Im(s)
Re(s)
Im(s)
-2
-3
-4
1.0
0.5
-0.5
-1.0
Im(s)
5
10
-5
-10
-15
-20
Im(s)
-5
-10
K = 1.5
K = 1.5
K = 0.3
K = 0.3
Proportional feedback
Lead compensator
Figure 5.34
Root loci for autopilot design

278
Chapter 5 The Root-Locus Design Method
Figure 5.35
Time-response plots for
autopilot design
1.55
1.05
0.55
05
0
1
2
3
4
5
6
Lead compensator
Proportional feedback
u
Time (sec)
will always have a damping ratio ζ that is less than 0.4; therefore,
proportional feedback will not be acceptable. Also, the slower roots
have some effect on the time response shown in Fig. 5.35 (dashed
curve) with K = 0.3 in that they cause a long-term settling. However,
the dominating characteristic of the response that determines whether
or not the compensation meets the speciﬁcations is the behavior in the
ﬁrst few seconds, which is dictated by the fast roots. The low damping
of the fast roots causes the time response to be oscillatory, which leads
to excess overshoot and a longer settling time than desired.
We saw in Section 5.4.1 that lead compensation causes the locus
to shift to the left, a change needed here to increase the damping. Some
trial and error will be required to arrive at a suitable pole and zero
location. Values of z = 3 and p = 20 in Eq. (5.70) have a substantial
effect in moving the fast branches of the locus to the left; thus
Dc(s) = s + 3
s + 20.
Trial and error is also required to arrive at a value of K that meets the
speciﬁcations. The statements in Matlab to add this compensation are
Lead compensation via
Matlab
sysD = (s + 3)/(s + 20);
sysDG = sysD*sysG;
rlocus(sysDG)
K = 1.5;
sysKDG = K*sysDG;
sysT = feedback(sysKDG,1);
step(sysT)
The root locus for this case and the corresponding time response
are also shown in Figs. 5.34 and 5.35 by the solid lines. Note that the
damping of the fast roots that corresponds to K = 1.5 is ζ = 0.52,
which is slightly lower than we would like; also, the natural frequency
is ωn = 15 rad/sec, much faster than we need. However, these values
are close enough to meeting the guidelines to suggest a look at the

5.5 A Design Example Using the Root Locus
279
time response. In fact, the time response shows that tr ∼= 0.9 sec and
Mp ∼= 8%, both within the speciﬁcations, although by a very slim
margin.
In sum, the primary design path consisted of adjusting the com-
pensation to inﬂuence the fast roots, examining their effect on the
time response, and continuing the design iteration until the time
speciﬁcations were satisﬁed.
2. The purpose of the trim is to provide a moment that will eliminate a
steady-state nonzero value of the elevator. Therefore, if we integrate the
elevator command δe and feed this integral to the trim device, the trim
should eventually provide the moment required to hold an arbitrary
altitude, thus eliminating the need for a steady-state δe. This idea is
showninFig.5.36(a). Ifthegainontheintegralterm KI issmallenough,
the destabilizing effect of adding the integral should be small and the
system should behave approximately as before, since that feedback
loop has been left intact. The block diagram in Fig. 5.36(a) can be
reduced to that in Fig. 5.36(b) for analysis purposes by deﬁning the
compensation to include the PI form
DI(s) = KDc(s)

1 + KI
s

.
However, it is important to keep in mind that, physically, there will
be two outputs from the compensation: δe (used by the elevator
servomotor) and δt (used by the trim servomotor).
The characteristic equation of the system with the integral term is
1 + KDcG + KI
s KDcG = 0.
To aid in the design process, it is desirable to ﬁnd the locus of roots with
respect to KI, but the characteristic equation is not in any of the root-
locus forms given by Eqs. (5.6)-(5.9). Therefore, dividing by 1+KDcG
yields
1 + (KI/s)KDcG
1 + KDcG
= 0.
 - 
 + 
Md
 + 
 + 
 + 
 + 
G(s)
u
ur
G(s)
u
(a)
(b)
DI(s)
Md
dt
1
s
KI
 - 
 + 
ur
KDc(s)
de
 + 
 + 
©
©
©
©
©
Figure 5.36
Block diagram showing the trim-command loop

280
Chapter 5 The Root-Locus Design Method
Re(s)
Re(s)
-1
-2
-3
-4
1.5
1.0
0.5
-0.5
-1.5
-1.0
Im(s)
5
10
15
-5
-10
-15
-20
Im(s)
-5
-10
-15
Figure 5.37
Root locus versus KI: assumes an added integral term and lead compensation with a gain K = 1.5;
roots for KI = 0.15 marked with •
To put this system in root locus form, we deﬁne
L(s) = 1
s
KDcG
1 + KDcG,
(5.80)
so that KI becomes the root locus parameter. In Matlab, with
KDcG
1+KDcG
already computed as sysT, we construct the integrator as sysIn = tf(1,[1
0]), the loop gain of the system with respect to KI as sysL = sysIn*sysT,
and the root locus with respect to KI is found with rltool(sysL).
It can be seen from the locus in Fig. 5.37 that the damping of the fast
roots decreases as KI increases, as is typically the case when integral
control is added. This shows the necessity for keeping the value of KI
as low as possible. After some trial and error, we select KI = 0.15. This
value has little effect on the roots—note the roots are virtually on top of
the previous roots obtained without the integral term—and little effect
ontheshort-termbehaviorofthestepresponse, asshowninFig.5.38(a),
so the speciﬁcations are still met. KI = 0.15 does cause the longer-term
attitude behavior to approach the commanded value with no error, as
we would expect with integral control. It also causes δe to approach
zero [Fig. 5.38(b) shows it settling in approximately 30 sec], which is
good because this is the reason for choosing integral control in the ﬁrst
place. The time for the integral to reach the correct value is predicted by
the new, slow real root that is added by the integral term at s = −0.14.
The time constant associated with this root is τ = 1/0.14 ∼= 7 sec. The

5.6 Extensions of the Root-Locus Method
281
Figure 5.38
Step response for the
case with an integral
term and 5◦command
0
6
5
4
3
2
1
0
5
10
15
20
25
30
Time (sec)
w (5)
0
0.2
0.1
0
-0.1
-0.2
5
10
15
20
25
30
Time (sec)
fe (5)
settling time to 1% for a root with σ = 0.14 is shown by Eq. (3.65) to
be ts = 33 sec, which agrees with the behavior in Fig. 5.38(b).
5.6
Extensions of the Root-Locus Method
As we have seen in this chapter, the root-locus technique is a graphical
scheme to show locations of possible roots of an algebraic equation as a
single real parameter varies. The method can be extended to consider neg-
ative values of the parameter, a sequential consideration of more than one
parameter, and systems with time delay. In this section we examine these
possibilities.Another interesting extension to nonlinear systems is discussed
in Chapter 9.
5.6.1
Rules for Plotting a Negative (0◦) Root Locus
We now consider modifying the root-locus procedure to permit analysis of
negative values of the parameter. In a number of important cases, the transfer
function of the plant has a zero in the RHP and is said to be nonminimum
phase. The result is often a locus of the form 1 + A(zi −s)G′(s) = 1 +
(−A)(s−zi)G′(s) = 0, and in the standard form the parameter K = −A must

282
Chapter 5 The Root-Locus Design Method
be negative. Another important issue calling for understanding the negative
locus arises in building a control system. In any physical implementation of
a control system there are inevitably a number of ampliﬁers and components
whose gain sign must be selected. By Murphy's Law,16 when the loop is ﬁrst
closed, the sign will be wrong and the behavior will be unexpected unless
the engineer understands how the response will go if the gain which should
be positive is instead negative. So what are the rules for a negative locus
(a root locus relative to a negative parameter)? First of all, Eqs. (5.6)-(5.9)
must be satisﬁed for negative values of K, which implies that L(s) is real
and positive. In other words, for the negative locus, the phase condition is
Deﬁnition of a Negative
Root Locus
The angle of L(s) is 0◦+ 360◦(l −1) for s on the negative locus.
The steps for plotting a negative locus are essentially the same as for
the positive locus, except that we search for places where the angle of L(s)
is 0◦+360◦(l −1) instead of 180◦+360◦(l −1). For this reason, a negative
locus is also referred to as a 0◦root locus. This time we ﬁnd that the locus is
to the left of an even number of real poles plus zeros (the number zero being
even). Computation of the asymptotes for large values of s is, as before,
given by
α =
 pi − zi
n −m
,
(5.81)
but we modify the angles to be
φl = 360◦(l −1)
n −m
, where l = 1, 2, 3, . . . , n −m
(shifted by
180◦
(n−m) from the 180◦locus). Following are the guidelines for
plotting a 0◦locus:
RULE 1. (As before) The n branches of the locus leave the poles and m
branches approach the zeros and n −m branches approach the asymptotes.
RULE 2. The locus is on the real axis to the left of an even number of real
poles plus zeros.
RULE 3. The asymptotes are described by
α =
 pi − zi
n −m
= −a1 + b1
n −m
,
φl = 360◦(l −1)
n −m
,
l = 1, 2, 3, . . . , n −m.
Notice that the angle condition here is measured from 0◦rather than from
180◦as it was in the positive locus.
16Anything that can go wrong, will go wrong.

5.6 Extensions of the Root-Locus Method
283
RULE 4. Departure angles from poles and arrival angles to zeros are found
by searching in the near neighborhood of the pole or zero where the phase
of L(s) is 0◦, so that
qφdep =

ψi −

φi −360◦(l −1),
qψarr =

φi −

ψi + 360◦(l −1),
where q is the order of the pole or zero and l takes on q integer values such
that the angles are between ±180◦.
RULE 5. The locus can have multiple roots at points on the locus and the
branches will approach a point of q roots at angles separated by
180◦+ 360◦(l −1)
q
and will depart at angles with the same separation.
The result of extending the guidelines for constructing root loci to
include negative parameters is that we can visualize the root locus as a
set of continuous curves showing the location of possible solutions to the
equation 1 + KL(s) = 0 for all real values of K, both positive and negative.
One branch of the locus departs from every pole in one direction for posi-
tive values of K, and another branch departs from the same pole in another
direction for negative K. Likewise, all zeros will have two branches arriving,
one with positive and the other with negative values of K. For the n −m
excess poles, there will be 2(n −m) branches of the locus asymptotically
approaching inﬁnity as K approaches positive and negative inﬁnity, respec-
tively. For a single pole or zero, the angles of departure or arrival for the
two locus branches will be 180◦apart. For a double pole or zero, the two
positive branches will be 180◦apart and the two negative branches will be
at 90◦to the positive branches.
Thenegativelocusisoftenrequiredwhenstudyinganonminimumphase
transfer function. A well-known example is that of the control of liquid level
in the boiler of a steam power plant. If the level is too low, the actuator valve
adds(relatively)coldwatertotheboilingwaterinthevessel. Theinitialeffect
of the addition is to slow down the rate of boiling, which reduces the number
and size of the bubbles and causes the level to fall momentarily, before the
added volume and heat cause it to rise again to the new increased level. This
initial underﬂow is typical of nonminimum phase systems. Another typical
nonminimum phase transfer function is that of the altitude control of an
airplane. To make the plane climb, the upward deﬂection of the elevators
initially causes the plane to drop before it rotates and climbs. A Boeing 747
in this mode can be described by the scaled and normalized transfer function
G(s) =
6 −s
s(s2 + 4s + 13).
(5.82)
To put 1 + KG(s) in root-locus form, we need to multiply by −1 to get
G(s) = −
s −6
s(s2 + 4s + 13).
(5.83)

284
Chapter 5 The Root-Locus Design Method
Figure 5.39
Negative root locus
corresponding to L(s) =
(s −6)/s(s2 + 4s + 13)
-5
0
Real axis
5
10
-6
-4
-2
0
2
4
6
Imaginary axis
EXAMPLE 5.13
Negative Root Locus for an Airplane
Sketch the negative root locus for the equation
1 + K
s −6
s(s2 + 4s + 13) = 0.
(5.84)
Solution
RULE 1. There are three branches and two asymptotes.
RULE 2. A real-axis segment is to the right of s = 6 and a segment is to the
left of s = 0.
RULE 3. The angles of the asymptotes are φl = (l−1)360◦
2
= 0◦, 180◦, and
the center of the asymptotes is at α = −2−2−(6)
3−1
= −5.
RULE 4. The branch departs the pole at s = −2 + j3 at the angle
φ = tan−1
 3
−8

−tan−1
 3
−2

−90◦+ 360◦(l −1),
φ = 159.4◦−123.7◦−90◦+ 360◦(l −1),
φ = −54.3◦.
The locus is plotted in Fig. 5.39 by Matlab, which is seen to be consistent
with these values.
5.6.2
Consideration of Two Parameters
An important technique for practical control is to consider a structure with
△
two loops, an inner loop around an actuator or part of the process dynamics
and an outer loop around the entire plant-plus-inner-controller. The process
is called successive loop closure. A controller is selected for the inner loop
Successive loop closure
to be robust and give good response alone, and then the outer loop can be
designed to be simpler and more effective than if the entire control was done

5.6 Extensions of the Root-Locus Method
285
without the aid of the inner loop. The use of the root locus to study such a
system with two parameters can be illustrated by a simple example.
EXAMPLE 5.14
Root Locus Using Two Parameters in Succession
A block diagram of a relatively common servomechanism structure is shown
in Fig. 5.40. Here a speed-measuring device (a tachometer) is available and
the problem is to use the root locus to guide the selection of the tachometer
gain KT as well as the ampliﬁer gain KA. The characteristic equation of the
system in Fig. 5.40 is
1 +
KA
s(s + 1) + KT
s + 1 = 0,
which is not in the standard 1 + KL(s) form. After clearing fractions, the
characteristic equation becomes
s2 + s + KA + KTs = 0,
(5.85)
which is a function of two parameters, whereas the root locus technique can
consider only one parameter at a time. In this case, we set the gain KA to
a nominal value of 4 and consider ﬁrst the locus with respect to KT. With
KA = 4, Eq. (5.85) can be put into root-locus form for a root-locus study
with respect to KT with L(s) =
s
s2+s+4, or
1 + KT
s
s2 + s + 4 = 0.
(5.86)
For this root locus, the zero is at s = 0 and the poles are at the roots of
s2 + s + 4 = 0, or s = −1
2 ± 1.94j. A sketch of the locus using the rules as
before is shown in Fig. 5.41.
From this locus, we can select KT so the complex roots have a speciﬁc
damping ratio or take any other value of KT that would result in satisfactory
roots for the characteristic equation. Consider KT = 1. Having selected a
trial value of KT, we can now re-form the equation to consider the effects
of changing from KA = 4 by taking the new parameter to be K1 so that
KA = 4 + K1. The locus with respect to K1 is governed by Eq. (5.50), now
with L(s) =
1
s2+2s+4, so that the locus is for the equation
1 + K1
1
s2 + 2s + 4 = 0.
(5.87)
Note that the poles of the new locus corresponding to Eq. (5.87) are the roots
of the previous locus, which was drawn versus KT, and the roots were taken
Figure 5.40
Block diagram of a
servomechanism
structure, including
tachometer feedback
 + 
 - 
R
Y
s + 1
1
s
1
KA
 + 
 - 
1
KT
©
©

286
Chapter 5 The Root-Locus Design Method
Figure 5.41
Root locus of
closed-loop poles of the
system in Fig. 5.40
versus KT
Re(s)
Im(s)
Figure 5.42
Root locus versus
K1 = KA + 4 after
choosing KT = 1
Re(s)
Im(s)
at KT = 1. The locus is sketched in Fig. 5.42, with the previous locus versus
KT left dashed. We could draw a locus with respect to K1 for a while, stop,
resolve the equation, and continue the locus with respect to KT, in a sort of
see-saw between the parameters KA and KT, and thus use the root locus to
study the effects of two parameters on the roots of a characteristic equation.
Notice, of course, that we can also plot the root locus for negative values of
K1 and thus consider values of KA less than 4.
5.6.3
Time Delay
Time delays often arise in control systems, both from delays in the process
△
itself and from delays in the processing of sensed signals. Chemical plants
often have processes with a time delay representing the time material takes
to be transported via pipes or other conveyer. In measuring the attitude
of a spacecraft en route to Mars, there is a signiﬁcant time delay for the
sensed quantity to arrive back on Earth due to the speed of light. Time delay
Time delays always reduce
the stability of a system.
always reduces the stability of a system; therefore, it is important to be
able to analyze its effect. Use of the Padé approximant adds a rational
function that approximates the effect of a time delay so one can analyze its
effect on the stability of a system. This method is described in Appendix
W5.6.3 at www.FPE7e.com. The effect of time delays is also covered via

5.7 Historical Perspective
287
frequency response design in Chapter 6. Using frequency response methods,
it is possible to show the effect of a time delay exactly and easily. The
destabilizing effect is clearly exposed by Fig. 6.80.
5.7
Historical Perspective
In Chapter 1, we gave an overview of the early development of feedback
control analysis and design including frequency response and root-locus
design. Root-locus design was introduced in 1948 by Walter R. Evans, who
was working in the ﬁeld of guidance and control of aircraft and missiles at the
Autonetics Division of North American Aviation (now a part of The Boeing
Co.). Many of his problems involved unstable or neutrally stable dynamics,
which made the frequency methods difﬁcult, so he suggested returning to
the study of the characteristic equation that had been the basis of the work
of Maxwell and Routh nearly 70 years earlier. However, rather than treat the
algebraic problem, Evans posed it as a graphical problem in the complex
s-plane. Evans was also interested in the character of the dynamic response
of the aerospace vehicles being controlled; therefore, he wanted to solve
for the closed-loop roots in order to understand the dynamic behavior. To
facilitate this understanding, Evans developed techniques and rules allowing
one to follow graphically the paths of the roots of the characteristic equation
as a parameter was changed. His method is suitable for design as well as
for stability analysis and remains an important technique today. Originally,
it enabled the solutions to be carried out by hand since computers were not
readily available to designers; however, root-loci remain an important tool
today for aiding the design process. As we learned in this chapter, Evans
method involves ﬁnding a locus of points where the angles to the other
poles and zeros add up to a certain value. To aid in this determination, Evans
invented the "Spirule." It could be used to measure the angles and to perform
the addition or subtraction very quickly. A skilled controls engineer could
evaluate whether the angle criterion was met for a fairly complex design
problem in a few seconds. In addition, a logarithmic spiral curve on a portion
of the device allowed the designer to multiply distances from points on the
locus to the poles and zeros, in order to determine the gain at a selected spot
on the locus in a manner analogous to a slide rule.
Evans was clearly motivated to aid the engineer in their design and anal-
ysis of control systems. Computers were basically not available to designers
in the 1940s and 50s. Large mainframe computers started being used, some-
what, for large-scale data processing by corporations in the 1950s, but there
were no courses in engineering programs that taught the use of computers
for analysis and design until about 1960. Engineering usage became com-
monplace through the 1960s, but the process involved submitting a job to a
mainframe computer via a large deck of punched cards and waiting for the
results for hours or overnight, a situation that was not conducive to any kind
of design iteration. Mainframe computers in that era were just transitioning
from vacuum tubes to transistors, random access memory would be in the
neighborhood of 32k(!), and the long-term data storage was by a magnetic

288
Chapter 5 The Root-Locus Design Method
Figure 5.43
The Friden mechanical
calculator
Source: Mark Richards/
Courtesy of the Computer
History Museum
tape drive. Random access drums and disks arrived during that decade, thus
greatly speeding up the process of retrieving data.A big step forward in com-
puting for engineers occurred when the batch processing based on punched
cards was replaced by time share with many users at remote terminals during
the late 1960s and early 1970s. Mechanical calculators were also available
through the 1940s, 50s, and 60s that could add, subtract, multiply, and divide
and cost about $1500 in the early 1960s. The very high-end devices (about
$3000) could also do square roots. These machines were the basis for the
complex computations done at Los Alamos during World War II. They were
the size of a typewriter, had a large carriage that went back and forth during
the calculations, and would occasionally ring a bell at the end of the carriage
stroke (see Fig. 5.43). They were accurate to eight or more decimal places
and were often used after the advent of computers to perform spot checks
of the results, but a square root could take tens of seconds to complete, the
machines were noisy, and the process was tedious. Enterprising engineers
learned which particular calculations played certain tunes and it was not
unusual to hear favorites, such as Jingle Bells.
The personal computer arrived in the late 1970s, although the ones at
that time utilized an audio cassette tape for data storage and had very limited
random access memory, usually less than 16k. But as these desktop machines
matured over the ensuing decade, the age of the computer for engineering
design came into its own. First came the ﬂoppy disk for long-term data stor-
age, followed by the hard drive toward the mid- and late-1980s. Initially,
the BASIC and APL languages were the primary methods of programming.
Matlab was introduced by Cleve Moler in the 1970s. Two things happened in
1984: Apple introduced the point and click MacIntosh and PC-Matlab was
introduced by The MathWorks, which was speciﬁcally founded to commer-
cialize Matlab on personal computers. Initially, The MathWorks'Matlab was
primarily written for control system analysis, but has branched out into many
ﬁelds since the initial introduction.At that point in the evolution, the engineer
could truly perform design iterations with little or no time between trials.
Other similar programs were available for mainframe computers before that
time; two being CTRL-C and MATRIXx; however, those programs did not
adapt to the personal computer revolution and have faded from general use.

Summary
289
SUMMARY
•
A root locus is a graph of the values of s that are solutions to the equation
1 + KL(s) = 0
with respect to a real parameter K.
1. When K > 0, s is on the locus if ∠L(s) = 180◦, producing a 180◦
or positive K locus.
2. When K < 0, s is on the locus if ∠L(s) = 0◦, producing a 0◦or
negative K locus.
•
If KL(s) is the loop transfer function of a system with negative feedback,
then the characteristic equation of the closed-loop system is
1 + KL(s) = 0,
and the root-locus method displays the effect of changing the gain K on
the closed-loop system roots.
•
A speciﬁc locus for a system sysL in Matlab notation can be plotted by
rlocus(sysL) and rltool(sysL).
•
A working knowledge of how to determine a root locus is useful for
verifying computer results and for suggesting design alternatives.
•
The key features for aid in sketching or verifying a computer generated
180◦locus are as follows:
1. The locus is on the real axis to the left of an odd number of poles
plus zeros.
2. Of the n branches, m approach the zeros of L(s) and n−m branches
approach asymptotes centered at α and leaving at angles φl:
n = number of poles,
m = number of zeros,
n −m = number of asymptotes,
α =
 pi − zi
n −m
,
φl = 180◦+ 360◦(l −1)
n −m
,
l = 1, 2, . . . , n −m.
3. Branches of the locus depart from the poles of order q and arrive
at the zeros of order q with angles
φl,dep = 1
q
⎛
⎝
ψi −

i̸=dep
φi −180◦−360◦(l −1)
⎞
⎠,
ψl,arr = 1
q
⎛
⎝
φi −

i̸=arr
ψi + 180◦+ 360◦(l −1)
⎞
⎠,

290
Chapter 5 The Root-Locus Design Method
where
q = order of the repeated pole or zero,
ψi = angles from the zeros,
φi = angles from the poles.
l = 1, 2, . . . , q
•
The parameter K corresponding to a root at a particular point s0 on the
locus can be found from
K =
1
|L(s0)|,
where |L(s0)| can be found graphically by measuring the distances from
s0 to each of the poles and zeros.
•
For a locus drawn with rlocus(sysL), the parameter and corresponding
roots can be found with [K,p] = rlocﬁnd(sysL) or with rltool.
•
Lead compensation, given by
Dc(s) = s + z
s + p,
z < p,
approximates proportional-derivative (PD) control. For a ﬁxed error
coefﬁcient, it generally moves the locus to the left and improves the
system damping.
•
Lag compensation, given by
Dc(s) = s + z
s + p,
z > p,
approximates proportional-integral (PI) control. It generally improves
the steady-state error for ﬁxed speed of response by increasing the low-
frequency gain and typically degrades stability.
•
The root locus can be used to analyze successive loop closures by
△
studying two (or more) parameters in succession.
REVIEW QUESTIONS
5.1
Give two deﬁnitions for the root locus.
5.2
Deﬁne the negative root locus.
5.3
Where are the sections of the (positive) root locus on the real axis?
5.4
What are the angles of departure from two coincident poles at s = −a on the
real axis? There are no poles or zeros to the right of −a.
5.5
What are the angles of departure from three coincident poles at s = −a on
the real axis? There are no poles or zeros to the right of −a.
5.6
What is the principal effect of a lead compensation on a root locus?
5.7
What is the principal effect of a lag compensation on a root locus in the vicinity
of the dominant closed-loop roots?
5.8
What is the principal effect of a lag compensation on the steady-state error to
a reference input?

Problems
291
5.9
Why is the angle of departure from a pole near the imaginary axis especially
important?
5.10
Deﬁne a conditionally stable system.
5.11
Show, with a root-locus argument, that a system having three poles at the
origin MUST be either unstable or, at best, conditionally stable.
PROBLEMS
Problems for Section 5.1: Root Locus of a Basic Feedback System
5.1
Set up the listed characteristic equations in the form suited to Evans's root-
locus method. Give L(s), a(s), and b(s) and the parameter K in terms of the
original parameters in each case. Be sure to select K so that a(s) and b(s) are
monic in each case and the degree of b(s) is not greater than that of a(s).
(a) s + (1/τ) = 0 versus parameter τ
(b) s2 + cs + c + 1 = 0 versus parameter c
(c) (s + c)3 + A(Ts + 1) = 0
(i)
versus parameter A,
(ii) versus parameter T,
(iii) versus the parameter c, if possible. Say why you can or cannot. Can
a plot of the roots be drawn versus c for given constant values of A
and T by any means at all?
(d) 1 +

kp + kI(s) + kDs
τs+1

G(s) = 0. Assume that G(s) = A c(s)
d(s), where
c(s) and d(s) are monic polynomials with the degree of d(s) greater than
that of c(s).
(i)
versus kp
(ii) versus kI
(iii) versus kD
(iv) versus τ
Problems for Section 5.2: Guidelines for Sketching a Root Locus
5.2
Roughly sketch the root loci for the pole-zero maps as shown in Fig. 5.44
without the aid of a computer. Show your estimates of the center and angles
of the asymptotes, a rough evaluation of arrival and departure angles for
complex poles and zeros, and the loci for positive values of the parameter K.
Each pole-zero map is from a characteristic equation of the form
1 + K b(s)
a(s) = 0,
where the roots of the numerator b(s) are shown as small circles ◦and the
roots of the denominator a(s) are shown as ×'s on the s-plane. Note that in
Fig. 5.44(c) there are two poles at the origin.
5.3
For the characteristic equation
1 +
K
s2(s + 1)(s + 5) = 0,

292
Chapter 5 The Root-Locus Design Method
Figure 5.44
Pole-zero maps
(a)
(b)
(c)
2
(d)
(e)
(f)
(a) Draw the real-axis segments of the corresponding root locus.
(b) Sketch the asymptotes of the locus for K →∞.
(c) Sketch the locus
(d) Verify your sketch with a Matlab plot.
5.4
Real poles and zeros. Sketch the root locus with respect to K for the equation
1+KL(s) = 0 and the listed choices for L(s). Be sure to give the asymptotes,
and the arrival and departure angles at any complex zero or pole. After com-
pleting each hand sketch, verify your results using Matlab. Turn in your hand
sketches and the Matlab results on the same scales.
(a) L(s) =
2
s(s+1)(s+5)(s+10)
(b) L(s) =
(s+3)
s(s+1)(s+5)(s+10)
(c) L(s) =
(s+2)(s+4)
s(s+1)(s+5)(s+10)
(d) L(s) =
(s+2)(s+6)
s(s+1)(s+5)(s+10)
5.5
Complex poles and zeros. Sketch the root locus with respect to K for the
equation 1 + KL(s) = 0 and the listed choices for L(s). Be sure to give the
asymptotes and the arrival and departure angles at any complex zero or pole.
After completing each hand sketch, verify your results using Matlab. Turn in
your hand sketches and the Matlab results on the same scales.
(a) L(s) =
1
s2+3s+10
(b) L(s) =
1
s(s2+3s+10)
(c) L(s) =
(s2+2s+8)
s(s2+2s+10)

Problems
293
(d) L(s) = (s2+2s+12)
s(s2+2s+10)
(e) L(s) =
s2+1
s(s2+4)
(f) L(s) =
s2+4
s(s2+1)
5.6
Multiple poles at the origin. Sketch the root locus with respect to K for the
equation 1 + KL(s) = 0 and the listed choices for L(s). Be sure to give the
asymptotes and the arrival and departure angles at any complex zero or pole.
After completing each hand sketch, verify your results using Matlab. Turn in
your hand sketches and the Matlab results on the same scales.
(a) L(s) =
1
s2(s+8)
(b) L(s) =
1
s3(s+8)
(c) L(s) =
1
s4(s+8)
(d) L(s) =
(s+3)
s2(s+8)
(e) L(s) =
(s+3)
s3(s+4)
(f) L(s) = (s+1)2
s3(s+4)
(g) L(s) =
(s+1)2
s3(s+10)
5.7
Mixed real and complex poles. Sketch the root locus with respect to K for the
equation 1 + KL(s) = 0 and the listed choices for L(s). Be sure to give the
asymptotes and the arrival and departure angles at any complex zero or pole.
After completing each hand sketch, verify your results using Matlab. Turn in
your hand sketches and the Matlab results on the same scales.
(a) L(s) =
(s+3)
s(s+10)(s2+2s+2)
(b) L(s) =
(s+3)
s2(s+10)(s2+6s+25)
(c) L(s) =
(s+3)2
s2(s+10)(s2+6s+25)
(d) L(s) =
(s+3)(s2+4s+68)
s2(s+10)(s2+4s+85)
(e) L(s) =
[(s+1)2+1]
s2(s+2)(s+3)
5.8
RHP and zeros. Sketch the root locus with respect to K for the equation 1 +
KL(s) = 0 and the listed choices for L(s). Be sure to give the asymptotes and
the arrival and departure angles at any complex zero or pole. After completing
each hand sketch, verify your results using Matlab. Turn in your hand sketches
and the Matlab results on the same scales.
(a) L(s) = s+2
s+10
1
s2−1; the model for a case of magnetic levitation with lead
compensation.
(b) L(s) =
s+2
s(s+10)
1
(s2−1); the magnetic levitation system with integral
control and lead compensation.

294
Chapter 5 The Root-Locus Design Method
(c) L(s) = s−1
s2
(d) L(s) =
s2+2s+1
s(s+20)2(s2−2s+2). What is the largest value that can be obtained
for the damping ratio of the stable complex roots on this locus?
(e) L(s) =
(s+2)
s(s−1)(s+6)2
(f) L(s) =
1
(s−1)[(s+2)2+3]
5.9
Put the characteristic equation of the system shown in Fig. 5.45 in root-locus
form with respect to the parameter α, and identify the corresponding L(s),
a(s), and b(s). Sketch the root locus with respect to the parameter α, estimate
the closed-loop pole locations, and sketch the corresponding step responses
when α = 0, 0.5, and 2. Use Matlab to check the accuracy of your approximate
step responses.
Figure 5.45
Control system for
Problem 5.9
Y
 - 
 + 
R
s(s + 2)
5
1 + as
©
5.10
Use the Matlab function rltool to study the behavior of the root locus of
1 + KL(s) for
L(s) =
(s + a)
s(s + 1)(s2 + 8s + 52)
as the parameter a is varied from 0 to 10, paying particular attention to the
region between 2.5 and 3.5. Verify that a multiple root occurs at a complex
value of s for some value of a in this range.
5.11
Use Routh's criterion to ﬁnd the range of the gain K for which the systems in
Fig. 5.46 are stable, and use the root locus to conﬁrm your calculations.
 - 
 + 
R
Y
K
(a)
 - 
 + 
R
Y
K
(b)
s(s - 2)(s2 + 2s + 10)
s + 2
s(s + 5)(s + 6)(s2 + 2s + 1)
s2 + s + 2
©
©
Figure 5.46
Feedback systems for Problem 5.11
5.12
Sketch the root locus for the characteristic equation of the system for which
L(s) =
(s + 2)
s2(s + 5),
and determine the value of the root-locus gain for which the complex conjugate
poles have the maximum damping ratio. What is the approximate value of the
damping?

Problems
295
5.13
For the system in Fig. 5.47,
(a) Find the locus of closed-loop roots with respect to K.
(b) Is there a value of K that will cause all roots to have a damping ratio
greater than 0.5?
(c) Find the values of K that yield closed-loop poles with the damping ratio
ζ = 0.707.
(d) Use Matlab to plot the response of the resulting design to a reference step.
Figure 5.47
Feedback system for
Problem 5.13
 - 
 + 
R
Y
s + 13
s + 1
(
)
K
s2(s2 + 100)
s2 + 81
©
5.14
For the feedback system shown in Fig. 5.48, ﬁnd the value of the gain K that
results in dominant closed-loop poles with a damping ratio ζ = 0.5.
Figure 5.48
Feedback system for
Problem 5.14
 - 
Y(s)
R(s)
10
 - 
 + 
 + 
s
1
Ks
s
1
 + 
 + 
©
©
©
Problems for Section 5.3: Selected Illustrative Root Loci
5.15
A simpliﬁed model of the longitudinal motion of a certain helicopter near
hover has the transfer function
G(s) =
9.8(s2 −0.5s + 6.3)
(s + 0.66)(s2 −0.24s + 0.15)
and the characteristic equation 1 + Dc(s)G(s) = 0. Let Dc(s) = kp at ﬁrst.
(a) Compute the departure and arrival angles at the complex poles and zeros.
(b) Sketch the root locus for this system for parameter K = 9.8kp. Use axes
−4 ≤x ≤4; −3 ≤y ≤3.
(c) Verify your answer using Matlab. Use the command axis([−4 4 −3 3])
to get the right scales.
(d) Suggest a practical (at least as many poles as zeros) alternative compen-
sation Dc(s) that will at least result in a stable system.
5.16
(a) For the system given in Fig. 5.49, plot the root locus of the characteristic
equation as the parameter K1 is varied from 0 to ∞with λ = 2. Give the
corresponding L(s), a(s), and b(s).
(b) Repeat part (a) with λ = 5. Is there anything special about this value?

296
Chapter 5 The Root-Locus Design Method
Figure 5.49
Control system for
Problem 5.16
 - 
Y
R
5
s + 10
2
s
1
s + l
K1
0.1
0.2
 + 
 + 
 + 
 + 
 + 
©
©
©
(c) Repeat part (a) for ﬁxed K1 = 2, with the parameter K = λ varying from
0 to ∞.
5.17
For the system shown in Fig. 5.50, determine the characteristic equation and
sketch the root locus of it with respect to positive values of the parameter c.
Give L(s), a(s), and b(s), and be sure to show with arrows the direction in
which c increases on the locus.
Figure 5.50
Control system for
Problem 5.17
 - 
R
c + s
c + 16s
s2
9
Y
 + 
©
5.18
Suppose you are given a system with the transfer function
L(s) = (s + z)
(s + p)2 ,
where z and p are real and z > p. Show that the root locus for 1 + KL(s) = 0
with respect to K is a circle centered at z with radius given by
r = (z −p).
Hint: Assume s + z = rejφ and show that L(s) is real and negative for real φ
under this assumption.
5.19
The loop transmission of a system has two poles at s = −1 and a zero at
s = −2. There is a third real-axis pole p located somewhere to the left of the
zero. Several different root loci are possible, depending on the exact location
of the third pole. The extreme cases occur when the pole is located at inﬁnity
or when it is located at s = −2. Give values for p and sketch the three distinct
types of loci.
5.20
For the feedback conﬁguration of Fig. 5.51, use asymptotes, center of asymp-
totes, angles of departure and arrival, and the Routh array to sketch root loci
for the characteristic equations of the listed feedback control systems versus
the parameter K. Use Matlab to verify your results.
(a) G(s) =
K
s(s+1+3j)(s+1−3j),
H(s) = s+2
s+8
(b) G(s) = K
s2 ,
H(s) = s+1
s+3

Problems
297
(c) G(s) = K(s+5)
(s+1) ,
H(s) = s+7
s+3
(d) G(s) = K(s+3+4j)(s+3−4j)
s(s+1+2j)(s+1−2j) ,
H(s) = 1 + 3s
Figure 5.51
Feedback system for
Problem 5.20
Y
 - 
 + 
R
G(s)
H(s)
©
5.21
Consider the system in Fig. 5.52.
(a) Using Routh's stability criterion, determine all values of K for which the
system is stable.
(b) Use Matlab to draw the root locus versus K and ﬁnd the values of K at
the imaginary-axis crossings.
Figure 5.52
Feedback system for
Problem 5.21
 - 
 + 
R
Y
K
s(s2 + 4s + 5)
s + 3
s + 1
1
©
Problems for Section 5.4: Design Using Dynamic Compensation
5.22
Let
G(s) =
1
(s + 2)(s + 3)
and
Dc(s) = K s + a
s + b.
Using root-locus techniques, ﬁnd values for the parameters a, b, and K of the
compensation Dc(s) that will produce closed-loop poles at s = −1 ± j for the
system shown in Fig. 5.53.
Figure 5.53
Unity feedback system
for Problems 5.22, 5.28,
and 5.33
Y
 - 
 + 
R
Dc(s)
G(s)
©
5.23
Suppose that in Fig. 5.53
G(s) =
1
s(s2 + 2s + 5)
and
Dc(s) =
K
s + 2.
Without using Matlab, sketch the root locus with respect to K of the char-
acteristic equation for the closed-loop system, paying particular attention to
points that generate multiple roots. Find the value of K at that point, state
what the location of the mulitple roots is, and how many multiple roots
there are.

298
Chapter 5 The Root-Locus Design Method
5.24
Suppose the unity feedback system of Fig. 5.53 has an open-loop plant given
by G(s) = 1/s2. Design a lead compensation Dc(s) = K s+z
s+p to be added in
series with the plant so that the dominant poles of the closed-loop system are
located at s = −2 ± 2j.
5.25
Assume that the unity feedback system of Fig. 5.53 has the open-loop plant
G(s) =
1
s(s + 3)(s + 6).
Design a lag compensation to meet the following speciﬁcations:
•
The step response settling time is to be less than 5 sec.
•
The step response overshoot is to be less than 17%.
•
The steady-state error to a unit-ramp input must not exceed 10%.
5.26
A numerically controlled machine tool positioning servomechanism has a
normalized and scaled transfer function given by
G(s) =
1
s(s + 1).
Performance speciﬁcations of the system in the unity feedback conﬁguration
of Fig. 5.53 are satisﬁed if the closed-loop poles are located at s = −1±j
√
3.
(a) Show that this speciﬁcation cannot be achieved by choosing proportional
control alone, Dc(s) = kp.
(b) DesignaleadcompensatorDc(s) = K s+z
s+p thatwillmeetthespeciﬁcation.
5.27
A servomechanism position control has the plant transfer function
G(s) =
10
s(s + 1)(s + 10).
You are to design a series compensation transfer function Dc(s) in the unity
feedback conﬁguration to meet the following closed-loop speciﬁcations:
•
The response to a reference step input is to have no more than 16%
overshoot.
•
The response to a reference step input is to have a rise time of no more
than 0.4 sec.
•
The steady-state error to a unit ramp at the reference input must be less
than 0.05.
(a) Designaleadcompensationthatwillcausethesystemtomeetthedynamic
response speciﬁcations, ignoring the error requirement.
(b) What is the velocity constant Kv for your design? Does it meet the error
speciﬁcation?
(c) Design a lag compensation to be used in series with the lead you have
designed to cause the system to meet the steady-state error speciﬁcation.
(d) Give the Matlab plot of the root locus of your ﬁnal design.
(e) Give the Matlab response of your ﬁnal design to a reference step.
5.28
Assume that the closed-loop system of Fig. 5.53 has a feed forward transfer
function
G(s) =
1
s(s + 2).
Design a lag compensation so that the dominant poles of the closed-loop
system are located at s = −1 ± j and the steady-state error to a unit-ramp
input is less than 0.2.

Problems
299
5.29
An elementary magnetic suspension scheme is depicted in Fig. 5.54. For
small motions near the reference position, the voltage e on the photo detector
is related to the ball displacement x (in meters) by e = 100x. The upward
force (in newtons) on the ball caused by the current i (in amperes) may be
approximated by f = 0.5i + 20x. The mass of the ball is 20 g and the gravi-
tational force is 9.8 N/kg. The power ampliﬁer is a voltage-to-current device
with an output (in amperes) of i = u + V0.
(a) Write the equations of motion for this set up.
(b) Give the value of the bias V0 that results in the ball being in equilibrium
at x = 0.
(c) What is the transfer function from u to e?
(d) Suppose that the control input u is given by u = −Ke. Sketch the root
locus of the closed-loop system as a function of K.
(e) Assume that a lead compensation is available in the form U
E = Dc(s) =
K s+z
s+p. Give values of K, z, and p that yield improved performance over
the one proposed in part (d).
Figure 5.54
Elementary magnetic
suspension
u
i
V0
Photo
detector
e
Light
Solenoid
Ball
x
5.30
A certain plant with the nonminimum phase transfer function
G(s) =
4 −2s
s2 + s + 9
is in a unity positive feedback system with the controller transfer function
Dc(s).
(a) Use Matlab to determine a (negative) value for Dc(s) = K so that the
closed-loop system with negative feedback has a damping ratio ζ = 0.707.
(b) Use Matlab to plot the system's response to a reference step.
5.31
Consider the rocket-positioning system shown in Fig. 5.55.
(a) Show that if the sensor that measures x has a unity transfer function, the
lead compensator
H(s) = K s + 2
s + 4
stabilizes the system.
(b) Assume that the sensor transfer function is modeled by a single pole with
a 0.1 sec time constant and unity DC gain. Using the root-locus procedure,
ﬁnd a value for the gain K that will provide the maximum damping ratio.

300
Chapter 5 The Root-Locus Design Method
Figure 5.55
Block diagram for
rocket-positioning
control system
x
 - 
 + 
H(s)
s2
1
Sensor
Fc
F
©
5.32
For the system in Fig. 5.56,
(a) Find the locus of closed-loop roots with respect to K.
(b) Find the maximum value of K for which the system is stable. Assume
K = 2 for the remaining parts of this problem.
(c) What is the steady-state error (e = r −y) for a step change in r?
(d) What is the steady-state error in y for a constant disturbance w1?
(e) What is the steady-state error in y for a constant disturbance w2?
(f) If you wished to have more damping, what changes would you make to
the system?
Figure 5.56
Control system for
Problem 5.32
Y
 - 
 + 
1
s2
1
R
K
 + 
W2
 + 
 + 
W1
 + 
(s + 6 + 2j)(s + 6 - 2j)
100
s
 + 
 + 
©
©
©
©
5.33
Consider the plant transfer function
G(s) =
bs + k
s2[mMs2 + (M + m)bs + (M + m)k]
to be put in the unity feedback loop of Fig. 5.53. This is the transfer function
relating the input force u(t) and the position y(t) of mass M in the noncol-
located sensor and actuator problem. In this problem, we will use root-locus
techniques to design a controller Dc(s) so that the closed-loop step response
has a rise time of less than 0.1 sec and an overshoot of less than 10%. You
may use Matlab for any of the following questions:
(a) Approximate G(s) by assuming that m ∼= 0, and let M = 1, k = 1,
b = 0.1, and Dc(s) = K. Can K be chosen to satisfy the performance
speciﬁcations? Why or why not?
(b) Repeat part (a) assuming that Dc(s) = K(s + z), and show that K and z
can be chosen to meet the speciﬁcations.
(c) Repeat part (b), but with a practical controller given by the transfer
function
Dc(s) = K p(s + z)
s + p .

Problems
301
Pick p so that the values for K and z computed in part (b) remain more or
less valid.
(d) Now suppose that the small mass m is not negligible, but is given by
m = M/10. Check to see if the controller you designed in part (c) still
meets the given speciﬁcations. If not, adjust the controller parameters so
that the speciﬁcations are met.
5.34
Consider the Type 1 system drawn in Fig. 5.57. We would like to design the
compensation Dc(s) to meet the following requirements: (1) The steady-state
value of y due to a constant unit disturbance w should be less than 4
5, and
(2) the damping ratio ζ = 0.7. Using root-locus techniques,
(a) Show that proportional control alone is not adequate.
(b) Show that proportional-derivative control will work.
(c) Find values of the gains kp and kD for Dc(s) = kp + kDs that meet the
design speciﬁcations with at least a 10% margin.
Figure 5.57
Control system for
Problem 5.34
Y
 - 
 + 
Dc(s)
 + 
 + 
W
s(s + 1)
1
R
©
©
5.35
Using a sample rate of 10 Hz, ﬁnd the Dc(z) that is the discrete equivalent
△
to your Dc(s) from Problem 5.7 using the trapezoid rule. Evaluate the time
response using Simulink, and determine whether the damping ratio require-
ment is met with the digital implementation. (Note: The material to do this
problem is covered in the AppendixW4.5 at www.FPE7e.com or in Chapter 8.)
Problems for Section 5.5: A Design Example Using the Root Locus
5.36
Consider the positioning servomechanism system shown in Fig. 5.58, where
ei = Koθi,
eo = Kpotθo,
Ko = 10 V/rad,
T = motor torque = Ktia,
km = Kt = torque constant = 0.1 N·m/A,
Figure 5.58
Positioning
servomechanism
uo
Jm
JL
ef
ei
eo
ui
Filter
s + 10
10
Sensor
Ko
Sensor
Ko
 + 
 - 
©
KA
ya
km

302
Chapter 5 The Root-Locus Design Method
Ke = back emf constant = 0.1 V·sec
Ra = armature resistance = 10 ,
Gear ratio = 1:1,
JL + Jm = total inertia = 10−3 kg·m2,
va = KA(ei −ef ).
(a) What is the range of the ampliﬁer gain KA for which the system is stable?
Estimate the upper limit graphically using a root-locus plot.
(b) Choose a gain KA that gives roots at ζ = 0.7. Where are all three closed-
loop root locations for this value of KA?
5.37
We wish to design a velocity control for a tape-drive servomechanism. The
transfer function from current I(s) to tape velocity (s) (in millimeters per
millisecond per ampere) is
(s)
I(s) =
15(s2 + 0.9s + 0.8)
(s + 1)(s2 + 1.1s + 1).
We wish to design a Type 1 feedback system so that the response to a reference
step satisﬁes
tr ≤4 msec,
ts ≤15 msec,
Mp ≤0.05.
(a) Use the integral compensator kI/s to achieve Type 1 behavior, and sketch
the root locus with respect to kI. Show on the same plot the region of
acceptable pole locations corresponding to the speciﬁcations.
(b) Assume a proportional-integral compensator of the form kp(s + α)/s,
and select the best possible values of kp and α you can ﬁnd. Sketch the
root-locus plot of your design, giving values for kp and α, and the velocity
constant Kv your design achieves. On your plot, indicate the closed-loop
poles with a dot (•) and include the boundary of the region of acceptable
root locations.
5.38
The normalized, scaled equations of a cart as drawn in Fig. 5.59 of mass
mc holding an inverted uniform pendulum of mass mp and length ℓwith no
friction are
¨θ −θ = −v,
(5.88)
¨y + βθ = v,
where β =
3mp
4(mc+mp) is a mass ratio bounded by 0 < β < 0.75. Time is
measured in terms of τ = ωot where ω2o = 3g(mc+mp)
ℓ(4mc+mp). The cart motion y
is measured in units of pendulum length as y = 3x
4ℓand the input is force
normalized by the system weight v =
u
g(mc+mp). These equations can be used
to compute the transfer functions

V = −
1
s2 −1,
(5.89)
Y
V = s2 −1 + β
s2(s2 −1) .
(5.90)

Problems
303
Figure 5.59
Figure of cart pendulum
for Problem 5.38
Trolley or cart
y
u
In this problem you are to design a control for the system by ﬁrst closing a
loop around the pendulum, Eq. (5.89), and then, with this loop closed, closing
a second loop around the cart plus pendulum, Eq. (5.90). For this problem,
let the mass ratio be mc = 5mp.
(a) Draw a block diagram for the system with V input and both Y and θ as
outputs.
(b) Design a lead compensation Dc(s) = K s+z
s+p for the  loop to cancel the
pole at s = −1 and place the two remaining poles at −4 ± j4. The new
control is U(s), where the force is V(s) = U(s) + Dc(s)(s). Draw the
root locus of the angle loop.
(c) Compute the transfer function of the new plant from U to Y with Dc(s)
in place.
(d) Design a controller Dc(s) for the cart position with the pendulum loop
closed. Draw the root locus with respect to the gain of Dc(s).
(e) Use Matlab to plot the control, cart position, and pendulum position for
a unit step change in cart position.
5.39
Consider the 270-ft U.S. Coast Guard cutter Tampa (902) shown in Fig. 5.60.
Parameter identiﬁcation based on sea-trials data (Trankle, 1987) was used to
estimate the hydrodynamic coefﬁcients in the equations of motion. The result
is that the response of the heading angle of the ship ψ to rudder angle δ and
wind changes w can be described by the second-order transfer functions
Gδ(s) = ψ(s)
δ(s) =
−0.0184(s + 0.0068)
s(s + 0.2647)(s + 0.0063),
Gw(s) = ψ(s)
w(s) =
0.0000064
s(s + 0.2647)(s + 0.0063),
where
ψ
= heading angle, rad,
ψr
= reference heading angle, rad,
r
= yaw rate, rad/sec,
δ
= rudder angle, rad,
w = wind speed, m/sec.
(a) Determine the open-loop settling time of r for a step change in δ.
(b) In order to regulate the heading angle ψ, design a compensator that uses
ψ and the measurement provided by a yaw-rate gyroscope (that is, by

304
Chapter 5 The Root-Locus Design Method
0¿ 10¿ 20¿ 30¿ 40¿ 50¿
COAST
GUARD
Figure 5.60
USCG cutter Tampa (902) for Problem 5.39
˙ψ = r). The settling time of ψ to a step change in ψr is speciﬁed to be
less than 50 sec, and for a 5◦change in heading, the maximum allowable
rudder angle deﬂection is speciﬁed to be less than 10◦.
(c) Check the response of the closed-loop system you designed in part (b)
to a wind gust disturbance of 10 m/sec. (Model the disturbance as a step
input.) If the steady-state value of the heading due to this wind gust is
more than 0.5◦, modify your design so that it meets this speciﬁcation
as well.
5.40
Golden Nugget Airlines has opened a free bar in the tail of their airplanes in
an attempt to lure customers. In order to automatically adjust for the sudden
weight shift due to passengers rushing to the bar when it ﬁrst opens, the
airline is mechanizing a pitch-attitude autopilot. Figure 5.61 shows the block
diagram of the proposed arrangement. We will model the passenger moment
as a step disturbance Mp(s) = M0/s, with a maximum expected value for
M0 of 0.6.
(a) What value of K is required to keep the steady-state error in θ to less than
0.02 rad (∼= 1◦)? (Assume the system is stable.)
(b) Draw a root locus with respect to K.
Figure 5.61
Golden Nugget Airlines
autopilot
u
u
 - 
 + 
 + 
 + 
Elevator
servo
s + 10
K
ur
Me
Mp
Aircraft
dynamics
s2 + 4s + 5
s + 3
s
1
KTu
Rate gyro
KT
Attitude
sensor
1
©
©

Problems
305
(c) Based on your root locus, what is the value of K when the system becomes
unstable?
(d) Suppose the value of K required for acceptable steady-state behavior is
600. Show that this value yields an unstable system with roots at
s = −2.9, −13.5, +1.2 ± 6.6j.
(e) You are given a black box with rate gyro written on the side and told
that, when installed, it provides a perfect measure of ˙θ, with output KT ˙θ.
Assume that K = 600 as in part (d) and draw a block diagram indicat-
ing how you would incorporate the rate gyro into the autopilot. (Include
transfer functions in boxes.)
(f) For the rate gyro in part (e), sketch a root locus with respect to KT.
(g) What is the maximum damping factor of the complex roots obtainable
with the conﬁguration in part (e)?
(h) What is the value of KT for part (g)?
(i) Suppose you are not satisﬁed with the steady-state errors and damping
ratio of the system with a rate gyro in parts (e) through (h). Discuss the
advantages and disadvantages of adding an integral term and extra lead
networks in the control law. Support your comments using Matlab or with
rough root-locus sketches.
5.41
Consider the instrument servomechanism with the parameters given in
Fig. 5.62. For each of the following cases, draw a root locus with respect
to the parameter K, and indicate the location of the roots corresponding to
your ﬁnal design:
(a) Lead network: Let
H(s) = 1,
Dc(s) = K s + z
s + p,
p
z = 6.
Select z and K so that the roots nearest the origin (the dominant roots)
yield
ζ ≥0.4,
−σ ≤−7,
Kv ≥162
3 sec−1 .
(b) Output-velocity (tachometer) feedback: Let
H(s) = 1 + KTs
and
Dc(s) = K.
SelectKT andK sothatthedominantrootsareinthesamelocationasthose
of part (a). Compute Kv. If you can, give a physical reason explaining the
reduction in Kv when output derivative feedback is used.
Figure 5.62
Control system for
Problem 5.41
 - 
 + 
R
Y
s2 + 51s + 550
1
Dc(s)
u
H(s)
s
1
Sensor
Compensator
©

306
Chapter 5 The Root-Locus Design Method
(c) Lag network: Let
H(s) = 1
and
Dc(s) = K s + 1
s + p.
Using proportional control, is it possible to obtain a Kv = 12 at ζ = 0.4?
Select K and p so that the dominant roots correspond to the proportional-
control case but with Kv = 100 rather than Kv = 12.
Problems for Section 5.6: Extensions of the Root Locus Method
5.42
Plot the loci for the 0◦locus or negative K for each of the following:
(a) The examples given in Problem 5.3
(b) The examples given in Problem 5.4
(c) The examples given in Problem 5.5
(d) The examples given in Problem 5.6
(e) The examples given in Problem 5.7
(f) The examples given in Problem 5.8
5.43
Suppose you are given the plant
L(s) =
1
s2 + (1 + α)s + (1 + α),
where α is a system parameter that is subject to variations. Use both positive
and negative root-locus methods to determine what variations in α can be
tolerated before instability occurs.
5.44
Consider the system in Fig. 5.63.
△
(a) Use Routh's criterion to determine the regions in the K1, K2 plane for
which the system is stable.
(b) Use rltool to verify your answer to part (a).
Figure 5.63
Feedback system for
Problem 5.44
 - 
 + 
R
Y
s
K2
K1(1 + )
s(s + 1)(s + 0.5)
1
E
U
©
5.45
The block diagram of a positioning servomechanism is shown in Fig. 5.64.
△
(a) Sketch the root locus with respect to K when no tachometer feedback is
present KT = 0.
Figure 5.64
Control system for
Problem 5.45
Y
 - 
 + 
K
R
©
 - 
 + 
s + 2
1
s
1
KT
©

Problems
307
(b) Indicate the root locations corresponding to K = 16 on the locus of part
(a). For these locations, estimate the transient-response parameters tr,
Mp, and ts. Compare your estimates to measurements obtained using the
step command in Matlab.
(c) For K = 16, draw the root locus with respect to KT.
(d) For K = 16 and with KT set so that Mp = 0.05 (ζ = 0.707), estimate tr
and ts. Compare your estimates to the actual values of tr and ts obtained
using Matlab.
(e) For the values of K and KT in part (d), what is the velocity constant Kv
of this system?
5.46
Consider the mechanical system shown in Fig. 5.65, where g and a0 are gains.
△
The feedback path containing gs controls the amount of rate feedback. For a
ﬁxed value of a0, adjusting g corresponds to varying the location of a zero in
the s-plane.
(a) With g = 0 and τ = 1, ﬁnd a value for a0 such that the poles are complex.
(b) Fix a0 at this value, and construct a root locus that demonstrates the effect
of varying g.
Figure 5.65
Control system for
Problem 5.46
©
 - 
 + 
a0
ui
©
 + 
 + 
gs
s(ts + 1)
1
uo
5.47
Sketch the root locus with respect to K for the system in Fig. 5.66 using
△
the Pad´e(1,1) approximation and the ﬁrst-order lag approximation. For both
approximations, what is the range of values of K for which the system is
unstable? (Note: The material to answer this question is contained inAppendix
W5.6.3 discussed in www.FPE7e.com.)
Figure 5.66
Control system for
Problem 5.47
©
 - 
 + 
K
R
Y
s + 0.01
1
e -s
5.48
Prove that the plant G(s) = 1/s3 cannot be made unconditionally stable if
△
pole cancellation is forbidden.
5.49
For the equation 1 + KG(s), where
△
G(s) =
1
s(s + p)[(s + 1)2 + 4],
use Matlab to examine the root locus as a function of K for p in the range
from p = 1 to p = 10, making sure to include the point p = 2.

6
The Frequency-Response
Design Method
A Perspective on the Frequency-Response
Design Method
The design of feedback control systems in industry is probably accom-
plished using frequency-response methods more often than any
other. Frequency-response design is popular primarily because it pro-
vides good designs in the face of uncertainty in the plant model. For
example, for systems with poorly known or changing high-frequency
resonances, we can temper the feedback compensation to alleviate
the effects of those uncertainties. Currently, this tempering is carried
out more easily using frequency-response design than with any other
method.
Another advantage of using frequency response is the ease with
which experimental information can be used for design purposes. Raw
measurements of the output amplitude and phase of a plant under-
going a sinusoidal input excitation are sufﬁcient to design a suitable
feedback control. No intermediate processing of the data (such as
ﬁnding poles and zeros or determining system matrices) is required
to arrive at the system model. The wide availability of computers has
Photo courtesy of Minneapolis Star Tribune/ZUMA Press/Newscom.
308

6.1 Frequency Response
309
rendered this advantage less important now than it was years ago;
however, for relatively simple systems, frequency response is often
still the most cost-effective design method. Yet another advantage is
that speciﬁcations for control systems are typically provided in terms
of a system's frequency-response characteristics. Therefore, design
in the frequency domain directly ensures that the speciﬁcations are
met rather than having to transform them to other parameters.
The underlying theory for determining stability in all situations
is somewhat challenging and requires a rather broad knowledge of
complex variables. However, the methodology of frequency-response
design does not require that the designer remembers the details of
the theory and the stability rules are fairly straightforward.
Chapter Overview
The chapter opens with a discussion of how to obtain the frequency
response of a system by analyzing its poles and zeros. An important
extension of this discussion is how to use Bode plots to graphically
displaythefrequencyresponse. InSections6.2and6.3wediscusssta-
bility brieﬂy and then in more depth the use of the Nyquist stability
criterion. In Sections 6.4 through 6.6 we introduce the notion of sta-
bility margins, discuss Bode's gain-phase relationship, and study the
closed-loop frequency response of dynamic systems. The gain-phase
relationship suggests a very simple rule for compensation design:
Shape the frequency-response magnitude so that it crosses magni-
tude 1 with a slope of −1. As with our treatment of the root-locus
method, we describe how adding dynamic compensation can adjust
the frequency response (Section 6.7) and improve system stability
and/or error characteristics.
In optional Sections 6.7.7 and 6.7.8 we discuss issues of sensi-
tivity that relate to the frequency response, including material on
sensitivity functions and stability robustness. The next two sections
on analyzing time delays in the system and Nichols charts rep-
resent additional, somewhat advanced material that may also be
considered optional. The ﬁnal Section 6.10 is a short history of the
frequency-response design method.
6.1
Frequency Response
The basic concepts of frequency response were discussed in Section 3.1.2.
In this section we will review those ideas and extend the concepts for use in
control system design.
A linear system's response to sinusoidal inputs—called the system's
Frequency response
frequency response—can be obtained from knowledge of its pole and zero
locations.

310
Chapter 6 The Frequency-Response Design Method
To review the ideas, we consider a system described by
Y(s)
U(s) = G(s),
where the input u(t) is a sine wave with an amplitude A:
u(t) = A sin(ωot)1(t).
This sine wave has a Laplace transform
U(s) =
Aωo
s2 + ω2o
.
With zero initial conditions, the Laplace transform of the output is
Y(s) = G(s)
Aωo
s2 + ω2o
.
(6.1)
A partial-fraction expansion of Eq. (6.1) [assuming that the poles of G(s)
Partial-fraction expansion
are distinct] will result in an equation of the form
Y(s) =
α1
s −p1
+
α2
s −p2
+ · · · +
αn
s −pn
+
αo
s + jωo
+
α∗
o
s −jωo
,
(6.2)
where p1, p2, . . . , pn are the poles of G(s), αo would be found by performing
the partial-fraction expansion, and α∗
o is the complex conjugate of αo. The
time response that corresponds to Y(s) is
y(t) = α1ep1t+α2ep2t+· · ·+αnepnt+2|αo| cos(ωot+φ),
t ≥0,
(6.3)
where
φ = tan−1
Im(αo)
Re(αo)

.
If all the poles of the system represent stable behavior (the real parts of
p1, p2, . . . , pn < 0), the natural unforced response will die out eventually,
and therefore the steady-state response of the system will be due solely to
the sinusoidal term in Eq. (6.3), which is caused by the sinusoidal exci-
tation. Example 3.6 determined the response of the system G(s) =
1
(s+1)
to the input u = sin 10t and showed that response in Fig. 3.5, which is
repeated here as Fig. 6.1. It shows that e−t, the natural part of the response
associated with G(s), disappears after several time constants, and the pure
sinusoidal response is essentially all that remains. Example 3.6 showed that
the remaining sinusoidal term in Eq. (6.3) can be expressed as
y(t) = AM cos(ωot + φ),
(6.4)

6.1 Frequency Response
311
Figure 6.1
Response of
G(s) =
1
(s+1) to an
input of sin 10t
0.20
0.15
0.10
0.05
0
-0.05
-0.10
Output, y
1
0
2
3
4
5
6
7
8
9
10
Time (sec)
where
M = |G( jωo)| = |G(s)|s=jωo
=

{Re[G( jωo)]}2 + {Im[G( jωo)]}2,
(6.5)
φ = tan−1
Im[G( jωo)]
Re[G( jωo)]

= ∠G( jωo).
(6.6)
In polar form,
G( jωo) = Me jφ.
(6.7)
Equation (6.4) shows that a stable system with transfer function G(s) excited
by a sinusoid with unit amplitude and frequency ωo will, after the response
has reached steady state, exhibit a sinusoidal output with a magnitude M(ωo)
and a phase φ(ωo) at the frequency ωo. The facts that the output y is a sinusoid
Frequency-response plot
with the same frequency as the input u and that the magnitude ratio M and
phase φ of the output are independent of the amplitude A of the input are
a consequence of G(s) being a linear constant system. If the system being
excited were a nonlinear or time-varying system, the output might contain
frequencies other than the input frequency, and the output-input ratio might
be dependent on the input magnitude.
More generally, the magnitude M is given by |G( jω)|, and the phase
Magnitude and phase
φ is given by ∠G( jω); that is, the magnitude and angle of the complex
quantity G(s) are evaluated with s taking on values along the imaginary axis
(s = jω). The frequency response of a system consists of these functions of
frequency that tell us how a system will respond to a sinusoidal input of any
frequency. We are interested in analyzing the frequency response not only
because it will help us understand how a system responds to a sinusoidal
input, but also because evaluating G(s) with s taking on values along the
jω axis will prove to be very useful in determining the stability of a closed-
loop system. As we saw in Chapter 3, the jω axis is the boundary between
stability and instability; we will see in Section 6.4 that evaluating G( jω)

312
Chapter 6 The Frequency-Response Design Method
provides information that allows us to determine closed-loop stability from
the open-loop G(s).
EXAMPLE 6.1
Frequency-Response Characteristics of a Capacitor
Consider the capacitor described by the equation
i = C dv
dt ,
where v is the voltage input and i is the current output. Determine the
sinusoidal steady-state response of the capacitor.
Solution. The transfer function of this circuit is
I(s)
V(s) = G(s) = Cs,
so
G( jω) = Cjω.
Computing the magnitude and phase, we ﬁnd that
M = |Cjω| = Cω
and
φ = ∠(Cjω) = 90◦.
For a unit-amplitude sinusoidal input v, the output i will be a sinusoid with
magnitude Cω, and the phase of the output will lead the input by 90◦. Note
that for this example the magnitude is proportional to the input frequency
while the phase is independent of frequency.
EXAMPLE 6.2
Frequency-Response Characteristics of a Lead Compensator
Recall from Chapter 5 [Eq. (5.70)] the transfer function of the lead
compensation, which is equivalent to
Dc(s) = K Ts + 1
αTs + 1,
α < 1.
(6.8)
1. Analytically determine its frequency-response characteristics and dis-
cuss what you would expect from the result.
2. Use Matlab to plot Dc( jω) with K = 1, T = 1, and α = 0.1 for
0.1 ≤ω ≤100, and verify the features predicted from the analysis
in 1, above.
Solution
1. Analytical evaluation: Substituting s = jω into Eq. (6.8), we get
Dc( jω) = K Tjω + 1
αTjω + 1.

6.1 Frequency Response
313
From Eqs. (6.5) and (6.6) the amplitude is
M = |Dc| = |K|

1 + (ωT)2

1 + (αωT)2 ,
and the phase is given by
φ = ∠(1 + jωT) −∠(1 + jαωT)
= tan−1(ωT) −tan−1(αωT).
At very low frequencies the amplitude is just |K|, and at very high
frequencies it is |K/α|. Therefore, the amplitude is higher at very high
frequency. The phase is zero at very low frequencies and goes back to
zero at very high frequencies. At intermediate frequencies, evaluation
of the tan−1(·) functions would reveal that φ becomes positive. These
are the general characteristics of lead compensation.
2. Computer evaluation: A Matlab script for frequency-response eval-
uation was shown for Example 3.6. A similar script for the lead
compensation:
s = tf('s');
sysD = (s + 1)/ (s/10 + 1);
w=logspace(-1,2);
% determines frequencies over
range of interest
[mag,phase] = bode(sysD,w);
% computes magnitude and phase
over frequency range of interest
loglog(w,squeeze(mag)),grid;
axis([0.1 100 1 10])
semilogx(w,squeeze(phase)),grid;
axis([0.1 100 0 60])
produces the frequency-response magnitude and phase plots shown in
Fig 6.2.
The analysis indicated that the low-frequency magnitude should
be K (= 1) and the high-frequency magnitude should be K/α(= 10),
which are both veriﬁed by the magnitude plot. The phase plot also
veriﬁes that the value approaches zero at high and low frequencies and
that the intermediate values are positive.
In the cases for which we do not have a good model of the system and
wish to determine the frequency-response magnitude and phase experimen-
tally, we can excite the system with a sinusoid varying in frequency. The
magnitude M(ω) is obtained by measuring the ratio of the output sinusoid
to input sinusoid in the steady state at each frequency. The phase φ(ω) is the
measured difference in phase between input and output signals.1
1Agilent Technologies produces instruments called spectral analyzers that automate this
experimental procedure and greatly speed up the process.

314
Chapter 6 The Frequency-Response Design Method
Figure 6.2
(a) Magnitude;
(b) phase for the lead
compensation in
Example 6.2
f (5)
Magnitude
10-1
100
101
102
0
20
(b)
v (rad/sec)
10-1
100
101
102
(a)
v (rad/sec)
db
0
10
20
30
40
50
60
100
101
A great deal can be learned about the dynamic response of a system
from knowledge of the magnitude M(ω) and the phase φ(ω) of its trans-
fer function. In the obvious case, if the signal is a sinusoid, then M and
φ completely describe the response. Furthermore, if the input is periodic,
then a Fourier series can be constructed to decompose the input into a sum
of sinusoids, and again M(ω) and φ(ω) can be used with each component
to construct the total response. For transient inputs, our best path to under-
standing the meaning of M and φ is to relate the frequency response G( jω)
to the transient responses calculated by the Laplace transform. For example,
in Fig. 3.19(b) we plotted the step response of a system having the transfer
function
G(s) =
1
(s/ωn)2 + 2ζ(s/ωn) + 1,
(6.9)
for various values of ζ. These transient curves were normalized with respect
to time as ωnt. In Fig. 6.3 we plot M(ω) and φ(ω) for these same values
of ζ to help us see what features of the frequency response correspond
to the transient-response characteristics. Speciﬁcally, Figs. 3.19(b) and 6.3
indicatetheeffectofdampingonsystemtimeresponseandthecorresponding
effect on the frequency response. They show that the damping of the system
can be determined from the transient-response overshoot or from the peak
in the magnitude of the frequency response [Fig. 6.3 (a)]. Furthermore,
from the frequency response, we see that ωn is approximately equal to the
bandwidth—the frequency where the magnitude starts to fall off from its
low-frequency value. (We will deﬁne bandwidth more formally in the next
paragraph.) Therefore, the rise time can be estimated from the bandwidth.
We also see that the peak overshoot in frequency is approximately 1/2ζ for
ζ < 0.5, so the peak overshoot in the step response can be estimated from the

6.1 Frequency Response
315
Figure 6.3
Frequency response
of Eq. (6.9);
(a) Magnitude;
(b) Phase
db
10
1
0.1
0.01
0.8
0.6
0.4
0.2
8
6
4
2
0.08
0.06
0.04
0.02
05
-305
-605
-905
-1205
-1505
-18050.1
1
10
0.2
0.4
0.6 0.8
2
4
6
8
v/vn
(b)
0.1
1
10
0.2
0.4
0.6 0.8
2
4
6
8
v/vn
(a)
0.1
0.2
0.5
0.9
Phase
Magnitude
20
0
-20
-40
0.3
z = 0.7
z = 0.05
0.1
0.2
0.3
z = 0.9
0.7
0.5
z = 0.05
peak overshoot in the frequency response. Thus, we see that essentially the
same information is contained in the frequency-response curve as is found
in the transient-response curve.
A natural speciﬁcation for system performance in terms of frequency
response is the bandwidth, deﬁned to be the maximum frequency at which
Bandwidth

316
Chapter 6 The Frequency-Response Design Method
Figure 6.4
Simpliﬁed system
deﬁnition
Y
©
+
+
R
KG(s)
Figure 6.5
Deﬁnitions of
bandwidth and
resonant peak
Amplitude ratio, ƒT(s)ƒ
Resonant peak, Mr
db
Bandwidth, vBW
20
0
-20
-3
10
1
0.1
0.7
v (rad/sec)
the output of a system will track an input sinusoid in a satisfactory manner.
By convention, for the system shown in Fig. 6.4 with a sinusoidal input r,
the bandwidth is the frequency of r at which the output y is attenuated to a
factor of 0.707 times the input.2 Figure 6.5 depicts the idea graphically for
the frequency response of the closed-loop transfer function
Y(s)
R(s)
= T (s) =
KG(s)
1 + KG(s).
The plot is typical of most closed-loop systems in that (1) the output follows
the input (|T | ∼= 1) at the lower excitation frequencies, and (2) the output
ceases to follow the input (|T | < 1) at the higher excitation frequencies. The
maximum value of the frequency-response magnitude is referred to as the
resonant peak Mr.
Bandwidth is a measure of speed of response and is therefore similar to
time-domain measures such as rise time and peak time or the s-plane measure
of dominant-root(s) natural frequency. In fact, if the KG(s) in Fig. 6.4 is
such that the closed-loop response is given by Fig. 6.3, we can see that the
bandwidth will equal the natural frequency of the closed-loop root (that is,
ωBW = ωn for a closed-loop damping ratio of ζ = 0.7). For other damping
ratios, the bandwidth is approximately equal to the natural frequency of the
closed-loop roots, with an error typically less than a factor of 2.
The deﬁnition of the bandwidth stated here is meaningful for systems
that have a low-pass ﬁlter behavior, as is the case for any physical control
system. In other applications the bandwidth may be deﬁned differently.Also,
if the ideal model of the system does not have a high-frequency roll-off
(e.g., if it has an equal number of poles and zeros), the bandwidth is inﬁnite;
2If the output is a voltage across a 1- resistor, the power is v2 and when |v| = 0.707, the
power is reduced by a factor of 2. By convention, this is called the half-power point.

6.1 Frequency Response
317
however, this does not occur in nature as nothing responds well at inﬁnite
frequencies.
In many cases, the designer's primary concern is the error in the sys-
tem due to disturbances rather than the ability to track an input. For error
analysis, we are more interested in one of the sensitivity functions deﬁned
in Section 4.1, S(s), rather than T (s). For most open-loop systems with
high gain at low frequencies, S(s) for a disturbance input will have very
low values at low frequencies and grows as the frequency of the input or
disturbance approaches the bandwidth. For analysis of either T (s) or S(s),
it is typical to plot their response versus the frequency of the input. Either
frequency response for control systems design can be evaluated using the
computer, or can be quickly sketched for simple systems using the efﬁcient
methods described in the following Section 6.1.1. The methods described
next are also useful to expedite the design process as well as to perform
sanity checks on the computer output.
6.1.1
Bode Plot Techniques
Display of frequency response is a problem that has been studied for a long
time. Before computers, this was accomplished by hand; therefore, it was
useful to be able to accomplish this quickly. The most useful technique for
hand plotting was developed by H. W. Bode at Bell Laboratories between
1932 and 1942. This technique allows plotting that is quick and yet sufﬁ-
ciently accurate for control systems design. Most control systems designers
now have access to computer programs that diminish the need for hand plot-
ting; however, it is still important to develop good intuition so that you can
quickly identify erroneous computer results, and for this you need the abil-
ity to perform a sanity check and in some cases to determine approximate
results by hand.
The idea in Bode's method is to plot magnitude curves using a loga-
rithmic scale and phase curves using a linear scale. This strategy allows us
to plot a high-order G( jω) by simply adding the separate terms graphically,
as discussed in Appendix B. This addition is possible because a complex
expression with zero and pole factors can be written in polar (or phasor)
form as
G( jω) = ⃗s1⃗s2
⃗s3⃗s4⃗s5
=
r1e jθ1r2e jθ2
r3e jθ3r4e jθ4r5e jθ5 =
 r1r2
r3r4r5

e j(θ1+θ2−θ3−θ4−θ5).
(6.10)
(The overhead arrow indicates a phasor.) Note from Eq. (6.10) that the
phases of the individual terms are added directly to obtain the phase of
Composite plot from
individual terms
the composite expression, G( jω). Furthermore, because
|G( jω)| =
r1r2
r3r4r5
,
it follows that
log10 |G( jω)| = log10 r1+log10 r2−log10 r3−log10 r4−log10 r5.
(6.11)

318
Chapter 6 The Frequency-Response Design Method
We see that addition of the logarithms of the individual terms provides the
logarithm of the magnitude of the composite expression. The frequency
response is typically presented as two curves; the logarithm of magnitude
versus log ω and the phase versus log ω. Together these two curves constitute
a Bode plot of the system. Because
Bode plot
log10 Me jφ = log10 M + jφ log10 e,
(6.12)
we see that the Bode plot shows the real and imaginary parts of the logarithm
of G( jω). In communications it is standard to measure the power gain in
Decibel
decibels (db), or "Power db":3
|G|db = 10 log10
P2
P1
.
(6.13)
Here P1 and P2 are the input and output powers. Because power is
proportional to the square of the voltage, the power gain is also given by
|G|db = 20 log10
V2
V1
.
(6.14)
Hence we can present a Bode plot as the magnitude in decibels versus log ω
and the phase in degrees versus log ω.4 In this book we give Bode plots in
the form log |G| versus log ω; also, we mark an axis in decibels on the right-
hand side of the magnitude plot to give you the choice of working with the
representation you prefer. However, for frequency-response plots, we are not
actually plotting power, and use of Eq. (6.14) can be somewhat misleading.
If the magnitude data are derived in terms of log |G|, it is conventional to
plot them on a log scale but identify the scale in terms of |G| only (without
"log"). If the magnitude data are given in decibels, the vertical scale is linear
such that each decade of |G| represents 20 db.
Advantages of Working with Frequency Response
in Terms of Bode Plots
1. Dynamic compensator design can be based entirely on Bode plots.
Advantages of Bode plots
2. Bode plots can be determined experimentally.
3. Bode plots of systems in series (or tandem) simply add, which is quite
convenient.
4. The use of a log scale permits a much wider range of frequencies to be
displayed on a single plot than is possible with linear scales.
It is important for the control systems engineer to understand the Bode
plot techniques for several reasons: This knowledge allows the engineer not
only to deal with simple problems, but also to perform a sanity check on
3Researchers at Bell Laboratories ﬁrst deﬁned the unit of power gain as a bel (named for
Alexander Graham Bell, the founder of the company). However, this unit proved to be too
large, and hence a decibel or db (1/10 of a bel) was selected as a more useful unit. The
abbreviation dB is also sometimes used; however, Bode used db and we choose to follow his
lead.
4Henceforth we will drop the base of the logarithm; it is understood to be 10.

6.1 Frequency Response
319
computer results for more complicated cases. Often approximations can be
used to quickly sketch the frequency response and deduce stability, as well
as to determine the form of the needed dynamic compensations. Finally,
an understanding of the plotting method is useful in interpreting frequency-
response data that have been generated experimentally.
In Chapter 5 we wrote the open-loop transfer function in the form
KG(s) = K (s −z1)(s −z2) · · ·
(s −p1)(s −p2) · · ·
(6.15)
because it was the most convenient form for determining the degree of stabil-
ity from the root locus with respect to the gain K. In working with frequency
response, we are only interested in evaluating G(s) along the jω axis, so it
is more convenient to replace s with jω and to write the transfer functions in
the Bode form
Bode form of the transfer
function
KG( jω) = Ko( jω)n ( jωτ1 + 1)( jωτ2 + 1) · · ·
( jωτa + 1)( jωτb + 1) · · ·.
(6.16)
This form also causes the gain Ko to be directly related to the transfer-
function magnitude at very low frequencies. In fact, for systems with n = 0,
Ko is the gain at ω = 0 in Eq. (6.16) and is also equal to the DC gain of
the system. Although a straightforward calculation will convert a transfer
function in the form of Eq. (6.15) to an equivalent transfer function in the
form of Eq. (6.16), note that K and Ko will not usually have the same value
in the two expressions.
Transfer functions can also be rewritten according to Eqs. (6.10) and
(6.11). As an example, suppose that
KG( jω) = Ko
jωτ1 + 1
( jω)2( jωτa + 1).
(6.17)
Then
∠KG( jω) = ∠Ko + ∠( jωτ1 + 1) −∠( jω)2 −∠( jωτa + 1)
(6.18)
and
log |KG( jω)| = log |Ko| + log |jωτ1 + 1| −log |( jω)2|
−log |jωτa + 1|.
(6.19)
In decibels, Eq. (6.19) becomes
|KG( jω)|db = 20 log |Ko| + 20 log |jωτ1 + 1| −20 log |( jω)2|
−20 log |jωτa + 1|.
(6.20)
All transfer functions for the kinds of systems we have talked about so
far are composed of three classes of terms:
Classes of terms of transfer
functions
1. Ko( jω)n.
2. ( jωτ + 1)±1.
3.

jω
ωn
	2
+ 2ζ jω
ωn + 1
±1
.

320
Chapter 6 The Frequency-Response Design Method
Figure 6.6
Magnitude of ( jω)n
1000
100
10
1
0.1
0.1
1
10
100
1000
Slope is +1, or
20 db/decade
ƒ(jv)nƒ
v (rad/sec)
60
50
40
30
20
10
db
0
n = -1
n = +1
n = +2
-10
-20
First we will discuss the plotting of each individual term and how the
terms affect the composite plot including all the terms; then we will discuss
how to draw the composite curve.
1. Ko( jω)n Because
Class 1: singularities at the
origin
log Ko|( jω)n| = log Ko + n log |jω|,
the magnitude plot of this term is a straight line with a slope n ×
(20 db per decade). Examples for different values of n are shown in
Fig. 6.6. Ko( jω)n is the only class of term that affects the slope at the
lowest frequencies, because all other terms are constant in that region.
The easiest way to draw the curve is to locate ω = 1 and plot log Ko
at that frequency. Then draw the line with slope n through that point.5
The phase of ( jω)n is φ = n × 90◦; it is independent of frequency and
is thus a horizontal line: −90◦for n = −1, −180◦for n = −2, +90◦
for n = +1, and so forth.
2. ( jωτ + 1) The magnitude of this term approaches one asymptote at very
Class 2: ﬁrst-order term
low frequencies and another asymptote at very high frequencies:
(a) For ωτ ≪1, jωτ + 1 ∼= 1.
(b) For ωτ ≫1, jωτ + 1 ∼= jωτ.
If we call ω = 1/τ the break point, then we see that below the break
Break point
point the magnitude curve is approximately constant (= 1), while above
the break point the magnitude curve behaves approximately like the
class 1 term Ko( jω). The example plotted in Fig. 6.7, G(s) = 10s + 1,
shows how the two asymptotes cross at the break point and how the
5In decibels the slopes are n × 20 db per decade or n × 6 db per octave (an octave is a change
in frequency by a factor of 2).

6.1 Frequency Response
321
Figure 6.7
Magnitude plot for
jωτ + 1; τ = 10
100
10.0
1.0
0.1
0.01
0.1
1.0
10
100
1000
v (rad/sec)
ƒ jv10 + 1ƒ
-20
40
20
0
db
Break point
1.4
ƒGƒ = 1.4
Asymptotes
3
Figure 6.8
Phase plot for jωτ + 1;
τ = 10
v (rad/sec)
j( jv10 + 1)
115
Asymptote
115
0.02
0.01
0.1
0.2
0.4
1
905
605
305
05
-305
Break point
Asymptote
actual magnitude curve lies above that point by a factor of 1.4 (or +3 db).
(If the term were in the denominator, it would be below the break point
by a factor of 0.707 or −3 db.) Note that this term will have only a
small effect on the composite magnitude curve below the break point,
because its value is equal to 1 (= 0 db) in this region. The slope at
high frequencies is +1 (or +20 db per decade). The phase curve can
also be easily drawn by using the following low- and high-frequency
asymptotes:
(a) For ωτ ≪1, ∠1 = 0◦.
(b) For ωτ ≫1, ∠jωτ = 90◦.
(c) For ωτ ∼= 1, ∠( jωτ + 1) ∼= 45◦.
For ωτ ∼= 1, the ∠( jω + 1) curve is tangent to an asymptote going
from 0◦at ωτ = 0.2 to 90◦at ωτ = 5, as shown in Fig. 6.8. The ﬁgure
also illustrates the three asymptotes (dashed lines) used for the phase
plot and how the actual curve deviates from the asymptotes by 11◦at
their intersections. Both the composite phase and magnitude curves are
unaffected by this class of term at frequencies below the break point by
more than a factor of 10 because the term's magnitude is 1 (or 0 db) and
its phase is less than 5◦.

322
Chapter 6 The Frequency-Response Design Method
3. [( jω/ωn)2 + 2ζ( jω/ωn) + 1]±1 This term behaves in a manner similar
Class 3: second-order term
to the class 2 term, with differences in detail: The break point is now
ω = ωn. The magnitude changes slope by a factor of +2 (or +40 db
per decade) at the break point (and −2, or −40 db per decade, when
the term is in the denominator). The phase changes by ±180◦, and
the transition through the break-point region varies with the damping
ratio ζ. Figure 6.3 shows the magnitude and phase for several different
damping ratios when the term is in the denominator. Note that the mag-
nitude asymptote for frequencies above the break point has a slope of
−2 (or −40 db per decade), and that the transition through the break-
point region has a large dependence on the damping ratio. A rough
determination of this transition can be made by noting that
Peak amplitude
|G( jω)| = 1
2ζ
at
ω = ωn
(6.21)
for this class of second-order term in the denominator. If the term was
in the numerator, the magnitude would be the reciprocal of the curve
plotted in Fig. 6.3(a).
NosuchhandyruleasEq.(6.21)existsforsketchinginthetransition
for the phase curve; therefore, we would have to resort to Fig. 6.3(b)
for an accurate plot of the phase. However, a very rough idea of the
transition can be gained by noting that it is a step function for ζ = 0,
while it obeys the rule for two ﬁrst-order (class 2) terms when ζ = 1
with simultaneous break-point frequencies. All intermediate values of
ζ fall between these two extremes. The phase of a second-order term is
always ±90◦at ωn.
When the system has several poles and several zeros, plotting the fre-
quency response requires that the components be combined into a composite
Composite curve
curve. To plot the composite magnitude curve, it is useful to note that the
slope of the asymptotes is equal to the sum of the slopes of the individual
curves. Therefore, the composite asymptote curve has integer slope changes
at each break-point frequency: +1 for a ﬁrst-order term in the numerator,
−1 for a ﬁrst-order term in the denominator, and ±2 for second-order terms.
Furthermore, the lowest-frequency portion of the asymptote has a slope
determined by the value of n in the ( jω)n term and is located by plotting the
point Koωn at ω = 1. Therefore, the complete procedure consists of plotting
the lowest-frequency portion of the asymptote, then sequentially changing
the asymptote's slope at each break point in order of ascending frequency,
and ﬁnally drawing the actual curve by using the transition rules discussed
earlier for classes 2 and 3.
The composite phase curve is the sum of the individual curves. Addition
of the individual phase curves graphically is made possible by locating the
curves so that the composite phase approaches the individual curve as closely
as possible. A quick but crude sketch of the composite phase can be found by
starting the phase curve below the lowest break point and setting it equal to
n × 90◦. The phase is then stepped at each break point in order of ascending
frequency. The amount of the phase step is ±90◦for a ﬁrst-order term and

6.1 Frequency Response
323
±180◦for a second-order term. Break points in the numerator indicate a
positive step in phase, while break points in the denominator indicate a
negative phase step.6 The plotting rules so far have only considered poles
and zeros in the left half-plane (LHP). Changes for singularities in the right
half-plane (RHP) will be discussed at the end of the section.
Summary of Bode Plot Rules
1. Manipulate the transfer function into the Bode form given by Eq. (6.16).
2. Determine the value of n for the Ko( jω)n term (class 1). Plot the low-
frequency magnitude asymptote through the point Ko at ω = 1 with a
slope of n (or n × 20 db per decade).
3. Complete the composite magnitude asymptotes: Extend the low-
frequency asymptote until the ﬁrst frequency break point. Then step
the slope by ±1 or ±2, depending on whether the break point is from a
ﬁrst- or second-order term in the numerator or denominator. Continue
through all break points in ascending order.
4. The approximate magnitude curve is increased from the asymptote value
by a factor of 1.4 (+3 db) at ﬁrst-order numerator break points, and
decreased by a factor of 0.707 (−3 db) at ﬁrst-order denominator break
points. At second-order break points, the resonant peak (or valley)
occurs according to Fig. 6.3(a), using the relation |G( jω)| = 1/2ζ at
denominator (or |G( jω)| = 2ζ at numerator) break points.
5. Plot the low-frequency asymptote of the phase curve, φ = n × 90◦.
6. As a guide, the approximate phase curve changes by ±90◦or ±180◦at
each break point in ascending order. For ﬁrst-order terms in the numer-
ator, the change of phase is +90◦; for those in the denominator the
change is −90◦. For second-order terms, the change is ±180◦.
7. Locate the asymptotes for each individual phase curve so that their phase
change corresponds to the steps in the phase toward or away from the
approximate curve indicated by Step 6. Each individual phase curve
occurs as indicated by Fig. 6.8 or Fig. 6.3(b).
8. Graphically add each phase curve. Use grids if an accuracy of about
±5◦is desired. If less accuracy is acceptable, the composite curve can
be done by eye. Keep in mind that the curve will start at the lowest-
frequency asymptote and end on the highest-frequency asymptote and
willapproachtheintermediateasymptotestoanextentthatisdetermined
by how close the break points are to each other.
EXAMPLE 6.3
Bode Plot for Real Poles and Zeros
Plot the Bode magnitude and phase for the system with the transfer function
KG(s) =
2000(s + 0.5)
s(s + 10)(s + 50).
6This approximate method was pointed out to us by our Parisian colleagues.

324
Chapter 6 The Frequency-Response Design Method
Solution
1. We convert the function to the Bode form of Eq. (6.16):
KG( jω) =
2[( jω/0.5) + 1]
jω[( jω/10) + 1][( jω/50) + 1].
2. We note that the term in jω is ﬁrst order and in the denominator, so
n = −1. Therefore, the low-frequency asymptote is deﬁned by the ﬁrst
term:
KG( jω) = 2
jω.
This asymptote is valid for ω < 0.1, because the lowest break point is
at ω = 0.5. The magnitude plot of this term has the slope of −1 (or
−20 db per decade). We locate the magnitude by passing through the
value 2 at ω = 1 even though the composite curve will not go through
this point because of the break point at ω = 0.5. This is shown in
Fig. 6.9(a).
3. We obtain the remainder of the asymptotes, also shown in Fig. 6.9(a):
The ﬁrst break point is at ω = 0.5 and is a ﬁrst-order term in the
numerator, which thus calls for a change in slope of +1. We therefore
draw a line with 0 slope that intersects the original −1 slope. Then
we draw a −1 slope line that intersects the previous one at ω = 10.
Finally, we draw a −2 slope line that intersects the previous −1 slope
at ω = 50.
4. The actual curve is approximately tangent to the asymptotes when far
away from the break points, a factor of 1.4 (+3 db) above the asymptote
at the ω = 0.5 break point, and a factor of 0.7 (−3 db) below the
asymptote at the ω = 10 and ω = 50 break points.
5. Because the phase of 2/jω is −90◦, the phase curve in Fig. 6.9(b) starts
at −90◦at the lowest frequencies.
6. The result is shown in Fig. 6.9(c).
7. The individual phase curves, shown dashed in Fig. 6.9(b), have the cor-
rect phase change for each term and are aligned vertically so that their
phase change corresponds to the steps in the phase from the approx-
imate curve in Fig. 6.9(c). Note that the composite curve approaches
each individual term.
8. The graphical addition of each dashed curve results in the solid com-
posite curve in Fig. 6.9(b). As can be seen from the ﬁgure, the vertical
placement of each individual phase curve makes the required graphi-
cal addition particularly easy because the composite curve approaches
each individual phase curve in turn.
EXAMPLE 6.4
Bode Plot with Complex Poles
As a second example, draw the frequency response for the system
KG(s) =
10
s[s2 + 0.4s + 4].
(6.22)

6.1 Frequency Response
325
Figure 6.9
Composite plots:
(a) magnitude;
(b) phase;
(c) approximate phase
0.1
1.0
10
100
Break points
Magnitude, ƒGƒ
v (rad/sec)
0.5
10
50
(a)
60
40
20
0
-20
db
1000
100
10
1
0.1
2
Slope = -1
Actual magnitude curve
Slope = 0
Asymptotes
Slope = -1
Slope = -2
Phase, jG
05
-905
-1805
-305
-605
-1205
-1505
0.1
1.0
10
100
1000
v (rad/sec)
(c)
Approximate
0.5
50
Actual
Phase, jG
0.1
1.0
10
100
1000
v (rad/sec)
(b)
05
-905
-1805
s/50 + 1
1
s/10 + 1
1
1
s/0.5 + 1
Composite

326
Chapter 6 The Frequency-Response Design Method
Solution. A system like this is more difﬁcult to plot than the one in the
previous example because the transition between asymptotes is dependent on
the damping ratio; however, the same basic ideas illustrated in Example 6.3
apply.
This system contains a second-order term in the denominator. Pro-
ceeding through the steps, we convert Eq. (6.22) to the Bode form of
Eq. (6.16):
KG(s) = 10
4
1
s(s2/4 + 2(0.1)s/2 + 1).
Starting with the low-frequency asymptote, we have n = −1 and |G( jω)| ∼=
2.5/ω. The magnitude plot of this term has a slope of −1 (−20 db per decade)
and passes through the value of 2.5 at ω = 1 as shown in Fig. 6.10(a).
For the second-order pole, note that ωn = 2 and ζ = 0.1. At the break-
point frequency of the poles, ω = 2, the slope shifts to −3 (−60 db per
decade). At the pole break point the magnitude ratio above the asymptote
is 1/2ζ = 1/0.2 = 5. The phase curve for this case starts at φ = −90◦,
corresponding to the 1/s term, falls to φ = −180◦at ω = 2 due to the
pole as shown in Fig. 6.10(b), and then approaches φ = −270◦for higher
Figure 6.10
Bode plot for a transfer
function with complex
poles: (a) magnitude;
(b) phase
1000
100
10
1
0.1
00.1
-605
-1005
-1405
-1805
-2205
-2605
-3005
Phase, jG
db
10
1
0.1
0.2
0.4
v (rad/sec)
2
4
(b)
10
1
0.1
0.2
0.4
v (rad/sec)
2
4
(a)
60
40
20
-20
-40
Magnitude, ƒGƒ
0
Slope = -3
Slope = -1
Approximation

6.1 Frequency Response
327
frequencies. Because the damping is small, the stepwise approximation is a
very good one. The true composite phase curve is shown in Fig. 6.10(b).
EXAMPLE 6.5
Bode Plot for Complex Poles and Zeros:
Satellite with Flexible Appendages
As a third example, draw the Bode plots for a system with second-order
terms. The transfer function represents a mechanical system with two equal
masses coupled with a lightly damped spring. The applied force and position
measurement are collocated on the same mass. For the transfer function, the
time scale has been chosen so that the resonant frequency of the complex
zeros is equal to 1. The transfer function is
KG(s) =
0.01(s2 + 0.01s + 1)
s2[(s2/4) + 0.02(s/2) + 1].
Solution.
Proceeding through the steps, we start with the low-frequency
asymptote, 0.01/ω2. It has a slope of −2 (−40 db per decade) and passes
through magnitude = 0.01 at ω = 1, as shown in Fig. 6.11(a). At the break-
point frequency of the zero, ω = 1, the slope shifts to zero until the break
point of the pole, which is located at ω = 2, when the slope returns to a slope
of −2. To interpolate the true curve, we plot the point at the zero break point,
ω = 1, with a magnitude ratio below the asymptote of 2ζ = 0.01.At the pole
break point, the magnitude ratio above the asymptote is 1/2ζ = 1/0.02 =
50. The magnitude curve is a "doublet"of a negative pulse followed by a
positive pulse. Figure 6.11(b) shows that the phase curve for this system
starts at −180◦(corresponding to the 1/s2 term), jumps 180◦to φ = 0 at
ω = 1, due to the zeros, and then falls 180◦back to φ = −180◦at ω = 2,
due to the pole. With such small damping ratios the stepwise approximation
is quite good. (We haven't drawn this on Fig. 6.11(b), because it would not be
easily distinguishable from the true phase curve.) Thus, the true composite
phase curve is a nearly square pulse between ω = 1 and ω = 2.
In actual designs, Bode plots are made with a computer. However, acquiring
the ability to determine how Bode plots should behave is a useful skill,
because it gives the designer insight into how changes in the compensation
parameters will affect the frequency response. This allows the designer to
iterate to the best designs more quickly.
EXAMPLE 6.6
Computer-Aided Bode Plot for Complex Poles and Zeros
Repeat Example 6.5 using Matlab.
Solution. To obtain Bode plots using Matlab, we call the function bode as
follows:
s = tf('s');
sysG = 0.01*(sˆ2 + 0.01*s + 1)/((sˆ2)*((sˆ2 )/4 + 0.01*s + 1));

328
Chapter 6 The Frequency-Response Design Method
Figure 6.11
Bode plot for a transfer
function with complex
poles and zeros:
(a) magnitude;
(b) phase
100
10
1
0.1
0.01
0.001
0.0001
Magnitude, ƒGƒ
   40
   20
-20
-40
-60
-80
db
205
-205
-605
-1005
-1405
-1805
Phase, jG
10
1
0.1
v (rad/sec)
(b)
10
1
0.1
v (rad/sec)
(a)
0
[mag, phase, w] = bode(sysG);
loglog(w,squeeze(mag))
semilogx(w,squeeze(phase))
These commands will result in a Bode plot that matches that in Fig. 6.11
very closely. To obtain the magnitude plot in decibels, the last three lines
can be replaced with
bode(sysG).
Nonminimum-Phase Systems
A system with a zero in the RHP undergoes a net change in phase when
evaluated for frequency inputs between zero and inﬁnity, which, for an
associated magnitude plot, is greater than if all poles and zeros were in
the LHP. Such a system is called nonminimum phase. As can be deduced
from the construction in Fig. WA.3 in Appendix WA,7 if the zero is in the
7See www.FPE7e.com.

6.1 Frequency Response
329
RHP, then the phase decreases at the zero break point instead of exhibiting
the usual phase increase that occurs for an LHP zero. Consider the transfer
functions
G1(s) = 10 s + 1
s + 10,
G2(s) = 10 s −1
s + 10.
Both transfer functions have the same magnitude for all frequencies; that is,
|G1( jω)| = |G2( jω)|,
as shown in Fig. 6.12(a). But the phases of the two transfer functions are
drastically different [Fig. 6.12(b)]. A "minimum-phase" system (i.e., all
zeros in the LHP) with a given magnitude curve will produce the smallest
net change in the associated phase, as shown in G1, compared with what
the nonminimum-phase system will produce, as shown by the phase of G2.
The discrepancy between G1 and G2 with regard to the phase change would
be greater if two or more zeros of the plant were in the RHP.
Figure 6.12
Bode plot minimum-
and nonminimum-
phase systems: for
(a) magnitude;
(b) phase
Phase
1805
Magnitude
10
db
20
0.01
0.1
1.0
10
100
1000
1205
605
05
1
v (rad/sec)
(b)
0.01
0.1
1.0
10
100
1000
v (rad/sec)
(a)
0
ƒG1(jv)ƒ = ƒG2(jv)ƒ
jG2(jv)
jG1(jv)

330
Chapter 6 The Frequency-Response Design Method
6.1.2
Steady-State Errors
We saw in Section 4.2 that the steady-state error of a feedback system
decreases as the gain of the open-loop transfer function increases. In plotting
a composite magnitude curve, we saw in Section 6.1.1 that the open-loop
transfer function, at very low frequencies, is approximated by
KG( jω) ∼= Ko( jω)n.
(6.23)
Therefore, we can conclude that the larger the value of the magnitude on the
low-frequency asymptote, the lower the steady-state errors will be for the
closed-loop system. This relationship is very useful in the design of com-
pensation: Often we want to evaluate several alternate ways to improve
stability and to do so we want to be able to see quickly how changes in the
compensation will affect the steady-state errors.
For a system of the form given by Eq. (6.16)—that is, where n = 0
Position-error constant
in Eq. (6.23) (a Type 0 system)—the low-frequency asymptote is a constant
and the gainKo of the open-loop system is equal to the position-error constant
Kp. For a unity feedback system with a unit-step input, the Final Value
Theorem (Section 3.1.6) was used in Section 4.2.1 to show that the steady-
state error is given by
ess =
1
1 + Kp
.
For a unity-feedback system in which n = −1 in Eq. (6.23), deﬁned to be
Velocity error coefﬁcient
a Type 1 system in Section 4.2.1, the low-frequency asymptote has a slope
of −1. The magnitude of the low-frequency asymptote is related to the gain
according to Eq. (6.23); therefore, we can again read the gain, Ko/ω, directly
from the Bode magnitude plot. Equation (4.37) tells us that the velocity-error
constant
Kν = Ko,
where, for a unity-feedback system with a unit-ramp input, the steady-state
error is
ess = 1
Kν
.
The easiest way of determining the value of Kν in a Type 1 system
is to read the magnitude of the low-frequency asymptote at ω = 1 rad/sec,
because this asymptote is A(ω) = Kν/ω. In some cases the lowest-frequency
break point will be below ω = 1 rad/sec; therefore, the asymptote needs to
extend to ω = 1 rad/sec in order to read Kν directly. Alternately, we could
read the magnitude at any frequency on the low-frequency asymptote and
compute it from Kν = ωA(ω).
EXAMPLE 6.7
Computation of Kν
As an example of the determination of steady-state errors, a Bode magnitude
plot of an open-loop system is shown in Fig. 6.13. Assuming that there is
unity feedback as in Fig. 6.4, ﬁnd the velocity-error constant, Kν.

6.2 Neutral Stability
331
Figure 6.13
Determination of Kv
from the Bode plot
for the system
KG(s) =
10
s(s+1)
0.01
0.1
1
10
v (rad/sec)
Magnitude
1000
100
10
1
0.1
0.01
60
40
20
0
-20
-40
db
Ky = 10
Solution.
Because the slope at the low frequencies is −1, we know that
the system is Type 1. The extension of the low-frequency asymptote crosses
ω = 1 rad/sec at a magnitude of 10. Therefore, Kν = 10 and the steady-state
error to a unit ramp for a unity-feedback system would be 0.1. Alternatively,
at ω = 0.01 we have |A(ω)| = 1000; therefore, from Eq. (6.23) we have
Ko = Kν ∼= ω|A(ω)| = 0.01(1000) = 10.
6.2
Neutral Stability
In the early days of electronic communications, most instruments were
judged in terms of their frequency response. It is therefore natural that when
the feedback ampliﬁer was introduced, techniques to determine stability in
the presence of feedback were based on this response.
Suppose the closed-loop transfer function of a system is known. We can
determine the stability of a system by simply inspecting the denominator in
factored form (because the factors give the system roots directly) to observe
whether the real parts are positive or negative. However, the closed-loop
transfer function is usually not known; in fact, the whole purpose behind
understanding the root-locus technique is to be able to ﬁnd the factors of
the denominator in the closed-loop transfer function, given only the open-
loop transfer function. Another way to determine closed-loop stability is to
evaluate the frequency response of the open-loop transfer function KG( jω)
and then perform a test on that response. Note that this method also does
not require factoring the denominator of the closed-loop transfer function.
In this section we will explain the principles of this method.
Suppose we have a system deﬁned by Fig. 6.14(a) and whose root locus
behaves as shown in Fig. 6.14(b); that is, instability results if K is larger
than 2. The neutrally stable points lie on the imaginary axis—that is, where

332
Chapter 6 The Frequency-Response Design Method
Figure 6.14
Stability example:
(a) system deﬁnition;
(b) root locus
Re(s)
Im(s)
©
-
+
R
Y
K
s(s + 1)2
1
(a)
-1
2
1
-1
-2
Im(s)
-2
K = 2
K = 2
K 6 2
K 7 2
(b)
K = 2 and s = j1.0. Furthermore, we saw in Section 5.1 that all points on
the locus have the property that
|KG(s)| = 1
and
∠G(s) = 180◦.
At the point of neutral stability we see that these root-locus conditions hold
for s = jω, so
|KG( jω)| = 1
and
∠G( jω) = 180◦.
(6.24)
Thus a Bode plot of a system that is neutrally stable (i.e., with K deﬁned
such that a closed-loop root falls on the imaginary axis) will satisfy the
conditions of Eq. (6.24). Figure 6.15 shows the frequency response for the
system whose root locus is plotted in Fig. 6.14(b) for various values of K.
The magnitude response corresponding to K = 2 passes through 1 at the
same frequency (ω = 1 rad/sec) at which the phase passes through 180◦, as
predicted by Eq. (6.24).
Having determined the point of neutral stability, we turn to a key ques-
tion: Does increasing the gain increase or decrease the system's stability?
We can see from the root locus in Fig. 6.14(b) that any value of K less than
the value at the neutrally stable point will result in a stable system. At the
frequency ω where the phase ∠G( jω) = −180◦(ω = 1 rad/sec), the mag-
nitude |KG( jω)| < 1.0 for stable values of K and > 1 for unstable values of
K. Therefore, we have the following trial stability condition, based on the
character of the open-loop frequency response:
Stability condition
|KG( jω)| < 1
at
∠G( jω) = −180◦.
(6.25)
This stability criterion holds for all systems for which increasing gain leads to
instabilityand |KG( jω)| crossesthemagnitude (=1)once, themostcommon
situation. However, there are systems for which an increasing gain can lead
from instability to stability; in this case, the stability condition is
|KG( jω)| > 1
at
∠G( jω) = −180◦.
(6.26)

6.3 The Nyquist Stability Criterion
333
Figure 6.15
Frequency-response
magnitude and phase
for the system in
Fig. 6.14
Magnitude, ƒKG(jv)ƒ  
Phase, jG(jv)
0.1
1
10
100
0.1
1
10
100
v (rad/sec)
v (rad/sec)
db
40
20
0
-20
-40
-60
-905
-1805
-2705
100
10
1
0.1
0.01
0.001
K = 10
K = 2
K = 0.1
-355
+805
There are also cases when |KG( jω)| crosses magnitude (=1) more than once.
One way to resolve the ambiguity that is usually sufﬁcient is to perform a
rough sketch of the root locus. Another, more rigorous, way to resolve
the ambiguity is to use the Nyquist stability criterion, the subject of the
next section. However, because the Nyquist criterion is fairly complex, it
is important while studying it to bear in mind the theme of this section,
namely, that for most systems a simple relationship exists between closed-
loop stability and the open-loop frequency response.
6.3
The Nyquist Stability Criterion
For most systems, as we saw in the previous section, an increasing gain
eventually causes instability. In the very early days of feedback control
design, this relationship between gain and stability margins was assumed to
be universal. However, designers found occasionally that in the laboratory
the relationship reversed itself; that is, the ampliﬁer would become unstable
when the gain was decreased. The confusion caused by these conﬂicting
observations motivated Harry Nyquist of the Bell Telephone Laboratories
to study the problem in 1932. His study explained the occasional reversals

334
Chapter 6 The Frequency-Response Design Method
and resulted in a more sophisticated analysis with no loopholes. Not sur-
prisingly, his test has come to be called the Nyquist stability criterion.
It is based on a result from complex variable theory known as the argu-
ment principle,8 as we brieﬂy explain in this section and in more detail in
Appendix WD.
The Nyquist stability criterion relates the open-loop frequency response
to the number of closed-loop poles of the system in the RHP. Study of
the Nyquist criterion will allow you to determine stability from the fre-
quency response of a complex system, perhaps with one or more resonances,
where the magnitude curve crosses 1 several times and/or the phase crosses
180◦several times. It is also very useful in dealing with open-loop unsta-
ble systems, nonminimum-phase systems, and systems with pure delays
(transportation lags).
6.3.1
The Argument Principle
Consider the transfer function H1(s) whose poles and zeros are indicated
in the s-plane in Fig. 6.16(a). We wish to evaluate H1 for values of s on
the clockwise contour C1. (Hence this is called a contour evaluation.) We
Figure 6.16
Contour evaluations:
(a) s-plane plot of poles
and zeros of H1(s) and
the contour C1;
(b) H1(s) for s on C1;
(c) s-plane plot of poles
and zeros of H2(s) and
the contour C1;
(d) H2(s) for s on C1
Re(s)
Im(s)
Im[H1(s)]
Re[H1(s)]
Re(s)
Re[H2(s)]
Im(s)
Im[H2(s)]
(a)
(b)
(c)
(d)
u1
f1
u2
f2
s0
H1(s)
C1
s0ˆ
H2(s)
a
u1
f1
u2
s0
f2
C1
s0ˆ
a
8Sometimes referred to as "Cauchy's Principle of the Argument."

6.3 The Nyquist Stability Criterion
335
choose the test point so for evaluation. The resulting complex quantity has
the form H1(so) = ⃗v = |⃗v|e jα. The value of the argument of H1(so) is
α = θ1 + θ2 −(φ1 + φ2).
As s traverses C1 in the clockwise direction starting at so, the angle α of H1(s)
in Fig. 6.16(b) will change (decrease or increase), but it will not undergo a
net change of 360◦as long as there are no poles or zeros within C1. This is
because none of the angles that make up α go through a net revolution. The
angles θ1, θ2, φ1, and φ2 increase or decrease as s traverses around C1, but
they return to their original values as s returns to so without rotating through
360◦. This means that the plot of H1(s) [Fig. 6.16(b)] will not encircle the
origin. This conclusion follows from the fact that α is the sum of the angles
indicated in Fig. 6.16(a), so the only way that α can be changed by 360◦
after s executes one full traverse of C1 is for C1 to contain a pole or zero.
Now consider the function H2(s), whose pole-zero pattern is shown in
Fig. 6.16(c). Note that it has a singularity (pole) within C1. Again, we start
at the test point so. As s traverses in the clockwise direction around C1, the
contributions from the angles θ1, θ2, and φ1 change, but they return to their
original values as soon as s returns to so. In contrast, φ2, the angle from the
pole within C1, undergoes a net change of −360◦after one full traverse of
C1. Therefore, the argument of H2(s) undergoes the same change, causing
H2 to encircle the origin in the counterclockwise direction, as shown in
Fig. 6.16(d). The behavior would be similar if the contour C1 had enclosed
a zero instead of a pole. The mapping of C1 would again enclose the origin
once in the H2(s)-plane, except it would do so in the clockwise direction.
Thus we have the essence of the argument principle:
A contour map of a complex function will encircle the origin Z −P
times, where Z is the number of zeros and P is the number of poles
of the function inside the contour.
For example, if the number of poles and zeros within C1 is the same, the net
angles cancel and there will be no net encirclement of the origin.
6.3.2
Application of The Argument Principle
to Control Design
To apply the principle to control design, we let the C1 contour in the s-plane
encircle the entire RHP, the region in the s-plane where a pole would cause
an unstable system (Fig. 6.17). The resulting evaluation of H(s) will encircle
the origin only if H(s) has an RHP pole or zero.
As stated earlier, what makes all this contour behavior useful is that a
contour evaluation of an open-loop KG(s) can be used to determine stability
of the closed-loop system. Speciﬁcally, for the system in Fig. 6.18, the
closed-loop transfer function is
Y(s)
R(s) = T (s) =
KG(s)
1 + KG(s).

336
Chapter 6 The Frequency-Response Design Method
Figure 6.17
An s-plane plot of a
contour C1 that
encircles the entire RHP
Contour at
infinity
C1
C1
Im(s)
Re(s)
Figure 6.18
Block diagram for
Y(s)/R(s) =
KG(s)/[1 + KG(s)]
Y
©
-
+
R
KG(s)
Therefore, the closed-loop roots are the solutions of
1 + KG(s) = 0,
and we apply the principle of the argument to the function 1 + KG(s). If the
evaluation contour of this function of s enclosing the entire RHP contains
a zero or pole of 1 + KG(s), then the evaluated contour of 1 + KG(s) will
encircle the origin. Notice that 1+KG(s) is simply KG(s) shifted to the right
1 unit, as shown in Fig. 6.19. Therefore, if the plot of 1 + KG(s) encircles
the origin, the plot of KG(s) will encircle −1 on the real axis. Therefore,
we can plot the contour evaluation of the open-loop KG(s), examine its
encirclements of −1, and draw conclusions about the origin encirclements
of the closed-loop function 1 + KG(s). Presentation of the evaluation of
Re
Re
Im
Im
[KG(s)]s=C1
[1 + KG(s)]s=C1
-1
0
0
Figure 6.19
Evaluations of KG(s) and 1 + KG(s): Nyquist plots

6.3 The Nyquist Stability Criterion
337
KG(s) in this manner is often referred to as a Nyquist plot, or polar plot,
Nyquist plot; polar plot
because we plot the magnitude of KG(s) versus the angle of KG(s).
To determine whether an encirclement is due to a pole or zero, we write
1 + KG(s) in terms of poles and zeros of KG(s):
1 + KG(s) = 1 + K b(s)
a(s) = a(s) + Kb(s)
a(s)
.
(6.27)
Equation (6.27) shows that the poles of 1 + KG(s) are also the poles of
G(s). Because it is safe to assume that the poles of G(s) [or factors of a(s)]
are known, the (rare) existence of any of these poles in the RHP can be
accounted for. Assuming for now that there are no poles of G(s) in the RHP,
an encirclement of −1 by KG(s) indicates a zero of 1 + KG(s) in the RHP,
and thus an unstable root of the closed-loop system.
We can generalize this basic idea by noting that a clockwise contour
C1 enclosing a zero of 1 + KG(s)—that is, a closed-loop system root—will
result in KG(s) encircling the −1 point in a clockwise direction. Likewise,
if C1 encloses a pole of 1 + KG(s)—that is, if there is an unstable open-
loop pole—there will be a counterclockwise KG(s) encirclement of −1.
Furthermore, if two poles or two zeros are in the RHP, KG(s) will encircle
−1 twice, and so on. The net number of clockwise encirclements, N, equals
the number of zeros (closed-loop system roots) in the RHP, Z, minus the
number of open-loop poles in the RHP, P:
N = Z −P.
This is the key concept of the Nyquist stability criterion.
A simpliﬁcation in the plotting of KG(s) results from the fact that any
KG(s) that represents a physical system will have zero response at inﬁnite
frequency (i.e., has more poles than zeros). This means that the big arc of
C1 corresponding to s at inﬁnity (Fig. 6.17) results in KG(s) being a point of
inﬁnitesimally small value near the origin for that portion of C1. Therefore,
we accomplish a complete evaluation of a physical system KG(s) by letting s
traverse the imaginary axis from −j∞to +j∞(actually, from −jωh to +jωh,
where ωh is large enough that |KG( jω)| is much less than 1 for all ω > ωh).
The evaluation of KG(s) from s = 0 to s = j∞has already been discussed
in Section 6.1 under the context of ﬁnding the frequency response of KG(s).
Because G(−jω) is the complex conjugate of G( jω), we can easily obtain
the entire plot of KG(s) by reﬂecting the 0 ≤s ≤+ j∞portion about the real
axis, to get the −j∞≤s < 0 portion. Hence we see that closed-loop stability
can be determined in all cases by examination of the frequency response of
the open-loop transfer function on a polar plot. In some applications, models
of physical systems are simpliﬁed so as to eliminate some high-frequency
dynamics. The resulting reduced-order transfer function might have an equal
number of poles and zeros. In that case the big arc of C1 at inﬁnity needs to
be considered.
In practice, many systems behave like those discussed in Section 6.2,
so you need not carry out a complete evaluation of KG(s) with subsequent
inspection of the −1 encirclements; a simple look at the frequency response

338
Chapter 6 The Frequency-Response Design Method
may sufﬁce to determine stability. However, in the case of a complex system
for which the simplistic rules given in Section 6.2 become ambiguous, you
will want to perform the complete analysis, summarized as follows:
Procedure for Determining Nyquist Stability
1. Plot KG(s) for −j∞≤s ≤+ j∞. Do this by ﬁrst evaluating
KG( jω) for ω = 0 to ωh, where ωh is so large that the magnitude
of KG( jω) is negligibly small for ω > ωh, then reﬂecting the
image about the real axis and adding it to the preceding image. The
magnitude of KG( jω) will be small at high frequencies for any
physical system. The Nyquist plot will always be symmetric with
respect to the real axis. The plot is normally created by the NYQUIST
Matlab m-ﬁle.
2. Evaluatethenumberofclockwiseencirclementsof −1, andcallthat
number N. Do this by drawing a straight line in any direction from
−1 to ∞. Then count the net number of left-to-right crossings of the
straight line by KG(s). If encirclements are in the counterclockwise
direction, N is negative.
3. Determine the number of unstable (RHP) poles of G(s), and call
that number P.
4. Calculate the number of unstable closed-loop roots Z:
Z = N + P.
(6.28)
For stability we wish to have Z = 0; that is, no characteristic equation
roots in the RHP.
Let us now examine a rigorous application of the procedure for
determining stability using Nyquist plots for some examples.
EXAMPLE 6.8
Nyquist Plot for a Second-Order System
Determine the stability properties of the system deﬁned in Fig. 6.20.
Solution. The root locus of the system in Fig. 6.20 is shown in Fig. 6.21.
It shows that the system is stable for all values of K. The magnitude of the
frequency response of KG(s) is plotted in Fig. 6.22(a) for K = 1, and the
phase is plotted in Fig. 6.22(b); this is the typical Bode method of presenting
frequency response and represents the evaluation of G(s) over the interesting
Figure 6.20
Control system for
Example 6.8
©
-
+
R
Y
K
(s + 1)2
1

6.3 The Nyquist Stability Criterion
339
Figure 6.21
Root locus of
G(s) =
1
(s+1)2 with
respect to K
Re(s)
Im(s)
Root
locus
Root
locus
-2
-3
-1
1
2
3
2
1
-1
-2
Figure 6.22
Open-loop Bode plot for
G(s) =
1
(s+1)2
Magnitude, ƒG(jv)ƒ  
10.0
20
db
1.0
0.1
0.01
0.001
0.1
1
10
100
0
-20
-40
-60
v (rad/sec)
(a)
0.1
1
10
100
v (rad/sec)
(b)
A
Phase, jG(jv)
05
-905
-1805
B
C
D
E
A
C
D
B
range of frequencies. The same information is replotted in Fig. 6.23 in the
Nyquist (polar) plot form. Note how the points A, B, C, D, and E are
mapped from the Bode plot to the Nyquist plot in Fig. 6.23. The arc from
G(s) = +1 (ω = 0) to G(s) = 0 (ω = ∞) that lies below the real axis is
derived from Fig. 6.22. The portion of the C1 arc at inﬁnity from Fig. 6.17
transforms into G(s) = 0 in Fig. 6.23; therefore, a continuous evaluation of

340
Chapter 6 The Frequency-Response Design Method
Figure 6.23
Nyquist plot9 of the
evaluation of KG(s) for
s = C1 and K = 1
0.5
-0.5
1.0
0.5j
v = -1
v = 1
v = q, E
Im[G(s)]
Re[G(s)]
G(s) for s = -jq to 0
A
B
C
D
G(s) for s = 0 to +jq 
-0.5j
v = 0
G(s) with s traversing C1 is completed by simply reﬂecting the lower arc
about the real axis. This creates the portion of the contour above the real axis
and completes the Nyquist (polar) plot. Because the plot does not encircle
−1, N = 0. Also, there are no poles of G(s) in the RHP, so P = 0. From
Eq. (6.28), we conclude that Z = 0, which indicates there are no unstable
roots of the closed-loop system for K = 1. Furthermore, different values of
K would simply change the magnitude of the polar plot, but no positive value
of K would cause the plot to encircle −1, because the polar plot will always
cross the negative real axis when KG(s) = 0. Thus the Nyquist stability
criterion conﬁrms what the root locus indicated: the closed-loop system is
stable for all K > 0.
The Matlab statements that will produce this Nyquist plot are
s = tf('s');
sysG = 1/(s+1)ˆ2;
nyquist(sysG);
Often the control systems engineer is more interested in determining a
range of gains K for which the system is stable than in testing for stability at a
speciﬁc value of K. To accommodate this requirement, but to avoid drawing
multiple Nyquist plots for various values of the gain, the test can be slightly
modiﬁed. To do so, we scale KG(s) by K and examine G(s) to determine
stability for a range of gains K. This is possible because an encirclement of
−1 by KG(s) is equivalent to an encirclement of −1/K by G(s). Therefore,
instead of having to deal with KG(s), we need only consider G(s), and count
the number of the encirclements of the −1/K point.
Applying this idea to Example 6.8, we see that the Nyquist plot cannot
encircle the −1/K point. For positive K, the −1/K point will move along
9The shape of this Nyquist plot is a cardioid, meaning "heart-shaped," plane curve. The name
was ﬁrst used by de Castillon in the Philosophical Transactions of the Royal Society in 1741.
The cardioid is also used in optics.

6.3 The Nyquist Stability Criterion
341
the negative real axis, so there will not be an encirclement of G(s) for any
value of K > 0.
(There are also values of K < 0 for which the Nyquist plot shows the
system to be stable; speciﬁcally, −1 < K < 0. This result may be veriﬁed
by drawing the 0◦locus.)
EXAMPLE 6.9
Nyquist Plot for a Third-Order System
As a second example, consider the system G(s) = 1/s(s + 1)2 for which the
closed-loop system is deﬁned in Fig. 6.24. Determine its stability properties
using the Nyquist criterion.
Solution. This is the same system discussed in Section 6.2. The root locus
in Fig. 6.14(b) shows that this system is stable for small values of K but
unstable for large values of K. The magnitude and phase of G(s) in Fig. 6.25
are transformed into the Nyquist plot shown in Fig. 6.26. Note how the
points A, B, C, D, and E on the Bode plot of Fig. 6.25 map into those on the
Nyquist plot of Fig. 6.26. Also note the large arc at inﬁnity that arises from
the open-loop pole at s = 0. This pole creates an inﬁnite magnitude of G(s)
Figure 6.24
Control system for
Example 6.9
©
 - 
 + 
R
Y
K
s(s + 1)2
1
Figure 6.25
Bode plot for
G(s) = 1/s(s + 1)2
Magnitude, ƒGƒ  
20
db
0.1
0.01
0.001
0.1
1
100
0
-20
-40
-60
v (rad/sec)
(a)
0.1
1
10
100
v (rad/sec)
(b)
A
Phase, jG
-905
-2705
B
D
E
A
C
D
B
-1805
C
10
E
1
10

342
Chapter 6 The Frequency-Response Design Method
Figure 6.26
Nyquist plot10 for
G(s) =
1
s(s+1)2
Re[G(s)]
D
Im[G(s)]
v = 0-
v 7 0
v 6 0
v = 0+
v = ;1
v = q, E
-1/Ks
-1/Kl
 -0.5
Arc at q
all from v _ 0
-2
C
B
A
at ω = 0; in fact, a pole anywhere on the imaginary axis will create an arc
at inﬁnity. To correctly determine the number of −1/K point encirclements,
we must draw this arc in the proper half-plane: Should it cross the positive
real axis, as shown in Fig. 6.26, or the negative one? It is also necessary to
assess whether the arc should sweep out 180◦(as in Fig. 6.26), 360◦, or 540◦.
A simple artiﬁce sufﬁces to answer these questions. We modify the C1
contour to take a small detour around the pole either to the right (Fig. 6.27)
or to the left. It makes no difference to the ﬁnal stability question which
way, but it is more convenient to go to the right because then no poles are
introduced within the C1 contour, keeping the value of P equal to 0. Because
the phase of G(s) is the negative of the sum of the angles from all of the
poles, we see that the evaluation results in a Nyquist plot moving from +90◦
for s just below the pole at s = 0, across the positive real axis to −90◦
for s just above the pole. Had there been two poles at s = 0, the Nyquist
plot at inﬁnity would have executed a full 360◦arc, and so on for three or
more poles. Furthermore, for a pole elsewhere on the imaginary axis, a 180◦
clockwise arc would also result but would be oriented differently than the
example shown in Fig. 6.26.
10The shape of this Nyquist plot is a translated strophoid plane curve, meaning "a belt with a
twist." The curve was ﬁrst studied by Barrow in 1670.

6.3 The Nyquist Stability Criterion
343
Figure 6.27
C1 contour enclosing
the RHP for the system
in Example 6.9
Re(s)
Im(s)
Im(s)
C1
The Nyquist plot crosses the real axis at ω = 1 with |G| = 0.5, as
indicated by the Bode plot. For K > 0, there are two possibilities for the
location of −1/K: inside the two loops of the Nyquist plot, or outside the
Nyquist contour completely. For large values of K (Kl in Fig. 6.26), −0.5 <
−1/Kl < 0 will lie inside the two loops; hence N = 2, and therefore, Z = 2,
indicating that there are two unstable roots. This happens for K > 2. For
small values of K (Ks in Fig. 6.26), −1/K lies outside the loops; thus N = 0,
and all roots are stable. All this information is in agreement with the root
locus in Fig. 6.14(b). (When K < 0, −1/K lies on the positive real axis,
then N = 1, which means Z = 1 and the system has one unstable root. The
0◦root locus will verify this result.)
For this and many similar systems, we can see that the encirclement
criterion reduces to a very simple test for stability based on the open-loop
frequency response: The system is stable if |KG( jω)| < 1 when the phase
of G( jω) is 180◦. Note that this relation is identical to the stability criterion
given in Eq. (6.25); however, by using the Nyquist criterion, we don't require
the root locus to determine whether |KG( jω)| < 1 or |KG( jω)| > 1.
We draw the Nyquist plot using Matlab, with
s = tf('s');
sysG = 1 / (s*(s + 1)ˆ2);
nyquist(sysG)
axis([-3 3 -3 3])

344
Chapter 6 The Frequency-Response Design Method
The axis command scaled the plot so that only points between +3 and
−3 on the real and imaginary axes were included. Without manual scaling,
the plot would be scaled based on the maximum values computed by Matlab
and the essential features in the vicinity of the −1 region would be lost.
For systems that are open-loop unstable, care must be taken because now
P ̸= 0 in Eq. (6.28). We shall see that the simple rules from Section 6.2 will
need to be revised in this case.
EXAMPLE 6.10
Nyquist Plot for an Open-Loop Unstable System
The third example is deﬁned in Fig. 6.28. Determine its stability properties
using the Nyquist criterion.
Solution. The root locus for this system is sketched in Fig. 6.29 for K > 1.
The open-loop system is unstable because it has a pole in the RHP. The open-
loop Bode plot is shown in Fig. 6.30. Note in the Bode that |KG( jω)| behaves
exactly the same as if the pole had been in the LHP. However, ∠G( jω)
increases by 90◦instead of the usual decrease at a pole. Any system with a
pole in the RHP is unstable; hence, it is difﬁcult11 to determine its frequency
response experimentally because the system never reaches a steady-state
sinusoidal response for a sinusoidal input. It is, however, possible to compute
the magnitude and phase of the transfer function according to the rules in
Figure 6.28
Control system for
Example 6.10
©
 - 
 + 
10
s(
 - 1)
s + 1
s
R
Y
K
Figure 6.29
Root locus for
G(s) =
(s+1)
s(s/10−1)
Re(s)
Im(s)
Im(s)
-2
-4
-6
-8
2
4
6
8
10
4
2
-4
-2
11It is possible to determine the frequency response of an unstable plant experimentally by
placing a stabilizing feedback around it, then measuring the amplitude and phase of the input
and output of the plant while providing input to the entire system through the frequency range
of interest.

6.3 The Nyquist Stability Criterion
345
Figure 6.30
Bode plot for
G(s) =
(s+1)
s(s/10−1)
Magnitude, ƒGƒ  
10
1
0.1
20
db
0
-20
Phase, jG
2705
905
1805
0.1
1
10
100
v (rad/sec)
(b)
2205
1405
0.1
1
10
100
v (rad/sec)
(a)
Section 6.1. The pole in the RHP affects the Nyquist encirclement criterion,
because the value of P in Eq. (6.28) is +1.
We convert the frequency-response information of Fig. 6.30 into the
Nyquist plot in Fig. 6.31(a) as in the previous examples. As before, the C1
detour around the pole at s = 0 in Fig. 6.31(b) creates a large arc at inﬁnity
in Fig. 6.31(a). This arc crosses the negative real axis because of the 180◦
phase contribution of the pole in the RHP as shown by Fig. 6.31(b).
The real-axis crossing occurs at |G(s)| = 1 because in the Bode plot
|G(s)| = 1 when ∠G(s) = +180◦, which happens to be at ω ∼= 3 rad/sec.
The contour shows two different behaviors, depending on the values of
K (> 0). For large values of K (K1 in Fig. 6.31(a)), there is one counterclock-
wise encirclement of the −1 point (−1/Kl in the ﬁgure); hence, N = −1.
However, because P = 1 from the RHP pole, Z = N + P = 0, so there are
no unstable system roots and the system is stable for K > 1. For small values
of K (Ks in Fig. 6.31(a)), N = +1 because of the clockwise encirclement of
−1 (−1/Ks in the ﬁgure) and Z = 2, indicating two unstable roots. These
results can be veriﬁed qualitatively by the root locus in Fig. 6.29 where we
see that low values of K produce the portions of the loci that are in the RHP
(unstable) and that both branches cross into the LHP (stable) for high values
of K.
If K < 0, −1/K is on the positive real axis so that N = 0 and Z = 1,
indicating the system will have one unstable closed-loop pole. A 0◦root

346
Chapter 6 The Frequency-Response Design Method
Figure 6.31
Example 6.10, (a)
Nyquist plot12 of
G(s) =
(s+1)
s(s/10−1), (b) C1
contour
Re[G(s)]
Im[G(s)]
v = ;   10
-1.1
-1
v 7 0
v = q
-1/Ks
-1/Kl
Arc at q
all from v    0
(a)
A
C
B
v 6 0
Im(s)
'1805
C1
Re(s)
A
(b)
B
C
locus will show a branch of the locus emanating from the pole at s = +10
to inﬁnity; thus verifying that there will always be one unstable root.
As with all systems, the stability boundary occurs at |KG( jω)| = 1
for the phase of ∠G( jω) = 180◦. However, in this case, |KG( jω)| must
be greater than 1 to yield the correct number of −1 point encirclements to
achieve stability. This polarity reversal of the normal rules can be rigorously
determined via the Nyquist plot; however, in practice, it is usually more
12The shape of this Nyquist plot is a strophoid.

6.3 The Nyquist Stability Criterion
347
expedient to sketch the root locus and to determine the correct rules based
on its behavior.
To draw the Nyquist plot using Matlab, use the following commands:
s = tf('s');
sysG = (s + 1)/(s*(s/10 - 1));
nyquist(sysG)
axis([-3 3 -3 3])
The existence of the RHP pole in Example 6.10 affected the Bode
plotting rules of the phase curve and affected the relationship between encir-
clements and unstable closed-loop roots because P = 1 in Eq. (6.28). But
we apply the Nyquist stability criterion without any modiﬁcations. The same
is true for systems with a RHP zero; that is, a nonminimum-phase zero has
no effect on the Nyquist stability criterion, but the Bode plotting rules are
affected.
EXAMPLE 6.11
Nyquist Plot Characteristics
Find the Nyquist plot for the third-order system
G(s) = s2 + 3
(s + 1)2
and reconcile the plot with the characteristics of G(s). If the G(s) is to be
included in a feedback system as shown in Fig. 6.18, then determine whether
the system is stable for all positive values of K.
Solution.
To draw the Nyquist plot using Matlab, use the following
commands:
s = tf('s')
sysG = (sˆ2 + 3)/(s + 1)ˆ2;
nyquist(sysG)
axis([−2 3 −3 3])
The result is shown in Fig. 6.32. Note that there are no arcs at inﬁnity
for this case due to the lack of any poles at the origin or on the jω axis. Also
note that the Nyquist curve associated with the Bode plot (s = +jω) starts
at (3, 0), ends at (1, 0), and, therefore, starts and ends with a phase angle
of 0◦. This is as it should be since the numerator and denominator of G(s)
are equal order and there are no singularities at the origin. So the Bode plot
should start and end with a zero phase. Also note that the Nyquist plot goes
through (0, 0) as s goes through s = +j
√
3, as it should since the magnitude
equals zero when s is at a zero. Furthermore, note that the phase goes from
−120◦as s approaches (0, 0) to +60◦as s departs from (0, 0). This behavior
follows since a Bode plot phase will jump by +180◦instantaneously as s
passes through a zero on the jω axis. The phase initially decreases as the plot
leaves the starting point at (3, 0) because the lowest frequency singularity is
the pole at s = −1.

348
Chapter 6 The Frequency-Response Design Method
Figure 6.32
Nyquist plot13 for
Example 6.11
-2
+
-1.5 -1 -0.5
0
0.5
1
1.5
2
2.5
3
-3
-2
-1
0
1
2
3
Real axis
Imaginary axis
Changing the gain, K, will increase or decrease the magnitude of the
Nyquist plot but it can never cross the negative-real axis. Therefore, the
closed-loop system will always be stable for positive K. Exercise: Verify
this result by making a rough root-locus sketch by hand.
6.4
Stability Margins
A large fraction of control system designs behave in a pattern roughly similar
to that of the system in Section 6.2 and Example 6.9 in Section 6.3; that is, the
system is stable for all small gain values and becomes unstable if the gain
increases past a certain critical point. Knowing exactly what the margins
are for which a control system remains stable is of critical importance. Two
commonly used quantities that measure the stability margin for such systems
are directly related to the stability criterion of Eq. (6.25): gain margin and
phase margin. In this section we will deﬁne and use these two concepts
to study system design. Another measure of stability, originally deﬁned by
Smith (1958), combines these two margins into one called the vector margin
(sometimes called the complex margin) which gives a better indication of
stability for complicated cases.
The gain margin (GM) is the factor by which the gain can be increased
Gain margin
(or decreased in certain cases) before instability results. For the typical case,
it can be read directly from the Bode plot (for example, see Fig. 6.15)
13The shape of this Nyquist plot is a limaçon, a fact pointed out by the third author's son, who
was in a 10th grade trigonometry class at the time. Limaçon means "snail" in French from the
Latin "limax," and was ﬁrst investigated by Dürer in 1525.

6.4 Stability Margins
349
by measuring the vertical distance between the |KG( jω)| curve and the
magnitude = 1 line at the frequency where ∠G( jω) = −180◦. We see
from the ﬁgure that when K = 0.1, the GM = 20 (or 26 db) because
|KG( jω)| = 0.05. When K = 2, the system is neutrally stable with
|KG( jω)| = 1, thus GM = 1 (0 db). For K = 10, |KG( jω)| = 5, the
GM = 0.2 (−14 db) and the system is unstable. Note that, for this typical
system, the GM is the factor by which the gain K can be increased before
instability results; therefore, |GM| < 1 (or |GM| < 0 db) indicates an unsta-
ble system. The GM can also be determined from a root locus with respect
to K by noting two values of K: (1) at the point where the locus crosses the
jω-axis, and (2) at the nominal closed-loop poles. The GM is the ratio of
these two values.
Another measure that is used to indicate the stability margin in a system
is the phase margin (PM). It is the amount by which the phase of G( jω)
Phase margin
exceeds −180◦when |KG( jω)| = 1, which is an alternative way of measur-
ing the degree to which the stability conditions of Eq. (6.25) are met. For the
case in Fig. 6.15, we see that PM ∼= 80◦for K = 0.1, PM = 0◦for K = 2,
and PM = −35◦for K = 10. A positive PM is required for stability.
The stability margins may also be deﬁned in terms of the Nyquist plot.
Figure 6.33 shows that GM and PM are measures of how close the complex
quantity G( jω) comes to encircling the −1 point, which is another way of
stating the neutral-stability point speciﬁed by Eq. (6.24). Again we can see
that the GM indicates how much the gain can be raised before instability
results in a system like the one in Example 6.9. The PM is the differ-
ence between the phase of G( jω) and 180◦when KG( jω) crosses the circle
|KG(s)| = 1; the positive value of PM is assigned to the stable case (i.e.,
with no Nyquist encirclements). So we see that the two margins measure the
distance between the Nyquist plot and the −1 point in two dimensions;
the GM measures along the horizontal axis, while the PM measures along
the unit circle.
It is easier to determine these margins directly from the Bode plot than
from the Nyquist plot. The term crossover frequency, ωc, is often used
Crossover frequency
to refer to the frequency at which the magnitude is unity, or 0 db. While
Figure 6.33
Nyquist plot for deﬁning
GM and PM
Re[KG(s)]
Im[KG(s)]
Re[KG(s)]
Im[KG(s)]
-1
PM
1/GM
KG( jv)

350
Chapter 6 The Frequency-Response Design Method
the crossover frequency is easily determined from the open-loop frequency-
response plot, this frequency is highly correlated with the closed-loop system
bandwidth and, therefore, the speed of response of the system. The closed-
loop system bandwidth is deﬁned in Section 6.1 and its detailed relationship
to the crossover frequency is discussed in Section 6.6.
The open-loop frequency-response data shown in Figure 6.34 is the
same data plotted in Fig. 6.25, but for the case with K = 1. The PM (= 22◦)
and GM (= 2) are apparent from Figure 6.34 and match those that could
have been obtained (with more difﬁculty) from the Nyquist plot shown in
Fig. 6.26. The real-axis crossing at −0.5 corresponds to a GM of 1/0.5 or 2
and the PM could be computed graphically by measuring the angle of G( jω)
as it crosses the magnitude = 1 circle.
One of the useful aspects of frequency-response design is the ease with
which we can evaluate the effects of gain changes. In fact, we can determine
the PM from Fig. 6.34 for any value of K without redrawing the magnitude or
phase information. We need only indicate on the ﬁgure where |KG( jω)| = 1
for selected trial values of K, as has been done with dashed lines in Fig. 6.35.
Figure 6.34
GM and PM from the
magnitude and phase
plot
0.2
1
10
2
PM = 225
v (rad/sec)
1/GM = 0.5,
GM = 2 (= 6 db)
-20
0
20
db
0.2
1
10
2
v (rad/sec)
10
5
2
1
0.5
0.2
0.1
Magnitude, ƒG(jv)ƒ
Phase, jG(jv)
-905
-1805
-2705

6.4 Stability Margins
351
Figure 6.35
PM versus K from the
frequency-response
data
0.2
1
10
v (rad/sec)
-20
0
20
db
0.2
1
10
2
v (rad/sec)
10
5
2
1
0.5
0.2
0.1
Magnitude, ƒG(jv)ƒ
Phase, jG(jv)
-905
-1805
-2705
= 1/K      K = 0.2
ƒKG(jv)ƒ = 1
for K = 0.5
ƒKG(jv)ƒ = 1
for K = 5
2
PM = 705
PM = +455
for K = 0.5
PM = -225 for
K = 5
Now we can see that K = 5 yields an unstable PM of −22◦, while a gain
of K = 0.5 yields a PM of +45◦. Furthermore, if we wish a certain PM
(say 70◦), we simply read the value of |G( jω)| corresponding to the fre-
quency that would create the desired PM (here ω = 0.2 rad/sec yields 70◦,
where |G( jω)| = 5), and note that the magnitude at this frequency is 1/K.
Therefore, a PM of 70◦will be achieved with K = 0.2.
The PM is more commonly used to specify control system performance
because it is most closely related to the damping ratio of the system. This
can be seen for the open-loop second-order system
G(s) =
ω2
n
s(s + 2ζωn),
(6.29)
which, with unity feedback, produces the closed-loop system
T (s) =
ω2
n
s2 + 2ζωns + ω2n
.
(6.30)

352
Chapter 6 The Frequency-Response Design Method
It can be shown that the relationship between the PM and ζ in this system is
PM = tan−1
⎡
⎢⎣
2ζ

1 + 4ζ 4 −2ζ 2
⎤
⎥⎦,
(6.31)
and this function is plotted in Fig. 6.36. Note that the function is approx-
imately a straight line up to about PM = 60◦. The dashed line shows a
straight-line approximation to the function, where
ζ ∼= PM
100.
(6.32)
It is clear that the approximation holds only for PM below about 70◦. Further-
more, Eq. (6.31) is only accurate for the second-order system of Eq. (6.30).
In spite of these limitations, Eq. (6.32) is often used as a rule of thumb for
relating the closed-loop damping ratio to PM. It is useful as a starting point;
however, it is important always to check the actual damping of a design, as
well as other aspects of the performance, before calling the design complete.
The GM for the second-order system [given by Eq. (6.29)] is inﬁnite
(GM = ∞), because the phase curve does not cross −180◦as the frequency
increases. This would also be true for any ﬁrst- or second-order system.
Additional data to aid in evaluating a control system based on its PM can
be derived from the relationship between the resonant peak Mr and ζ seen in
Fig. 6.3. Note that this ﬁgure was derived for the same system [Eq. (6.9)] as
Eq. (6.30). We can convert the information in Fig. 6.36 into a form relating
Mr to the PM. This is depicted in Fig. 6.37, along with the step-response
overshoot Mp. Therefore, we see that, given the PM, one can determine the
overshoot of the closed-loop step response for a second-order system with
no zeros, which serves as a rough estimate for any system.
Many engineers think directly in terms of the PM when judging whether
Importance of PM
a control system is adequately stabilized. In these terms, a PM = 30◦is
often judged to be the lowest adequate value. Furthermore, some value of
the PM is often stated speciﬁcally as a required speciﬁcation of the feedback
system design. In addition to testing the stability of a system design using
the PM, a designer would typically also be concerned with meeting a speed-
of-response speciﬁcation such as bandwidth, as discussed in Section 6.1. In
terms of the frequency-response parameters discussed so far, the crossover
Figure 6.36
Damping ratio versus
PM
05 105 205 305 405 505 605 705 805
1.0
0.8
0.6
0.4
0.2
0
Damping ratio, z
Phase margin

6.4 Stability Margins
353
Figure 6.37
Transient-response
overshoot (Mp) and
frequency-response
resonant peak (Mr)
versus PM for
T(s) =
ω2
n
s2+2ζωns+ω2n
05 105 205 305 405 505 605 705 805 905
Phase margin
Mr
Mp
Mp (overshoot fraction)
Transient-response peak magnitude
Mr (overshoot multiple)
Frequency-response resonant peak
4
3
2
1
0
1.00
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0
0.10
frequency would best describe a system's speed of response. This idea will
be discussed further in Sections 6.6 and 6.7.
In some cases the PM and GM are not helpful indicators of stability. For
ﬁrst- and second-order systems, the phase never crosses the 180◦line; hence,
the GM is always ∞and not a useful design parameter. For higher-order
systems it is possible to have more than one frequency where |KG( jω)| = 1
or where ∠KG( jω) = 180◦, and the margins as previously deﬁned need
clariﬁcation. An example of this can be seen in Fig. 10.12, where the mag-
nitude crosses 1 three times. In that case, a decision was made to deﬁne PM
by the ﬁrst crossing, because the PM at this crossing was the smallest of
the three values and thus the most conservative assessment of stability. A
Nyquist plot based on the data in Fig. 10.12 would show that the portion of
the Nyquist curve closest to the −1 point was the critical indicator of stabil-
ity, and therefore use of the crossover frequency yielding the minimum value
of PM was the logical choice. Alternatively, the Nichols plot discussed in
Nichols Plot
Section 6.9 can be used to resolve any uncertainty in the stability margins.At
best, a designer needs to be judicious when applying the margin deﬁnitions
described in Fig. 6.33. In fact, the actual stability margin of a system can
be rigorously assessed only by examining the Nyquist or Nichols plots to
determine its closest approach to the −1 point.
To aid in this analysis, Smith (1958) introduced the vector margin
Vector margin
(sometimes called the complex margin), which he deﬁned to be the distance
to the −1 point from the closest approach of the Nyquist plot.14 Figure 6.38
illustrates the idea graphically. Because the vector margin is a single margin
parameter, it removes all the ambiguities in assessing stability that come with
using GM and PM in combination. In the past it has not been used extensively
due to difﬁculties in computing it. However, with the widespread availability
of computer aids, the idea of using the vector margin to describe the degree
of stability is much more feasible.
14This value is closely related to the use of the sensitivity function for design and the concept
of stability robustness, to be discussed in optional Section 6.7.8.

354
Chapter 6 The Frequency-Response Design Method
Figure 6.38
Deﬁnition of the vector
margin on the Nyquist
plot
Re[G(s)]
Im[G(s)]
Vector
margin
-1
Figure 6.39
Root locus for a
conditionally stable
system
Re(s)
Im(s)
-2
-4
-6
-8
-10
4
-4
A
B
There are certain practical examples in which an increase in the gain can
Conditionally stable
systems
make the system stable. As we saw in Chapter 5, these systems are called
conditionally stable. A representative root-locus plot for such systems is
shown in Fig. 6.39. For a point on the root locus, such as A, an increase in
the gain would make the system stable by bringing the unstable roots into the
LHP. For point B, either a gain increase or decrease could make the system
become unstable. Therefore, several GMs exist that correspond to either gain
reduction or gain increase, and the deﬁnition of the GM in Fig. 6.33 is not
valid.
EXAMPLE 6.12
Stability Properties for a Conditionally Stable System
Determine the stability properties as a function of the gain K for the system
with the open-loop transfer function
KG(s) = K(s + 10)2
s3
.
Solution.
This is a system for which increasing gain causes a transition
from instability to stability. The root locus in Fig. 6.40(a) shows that the
system is unstable for K < 5 and stable for K > 5. The Nyquist plot in
Fig. 6.40(b) was drawn for the stable value K = 7. Determination of the
margins according to Fig. 6.33 yields PM = +10◦(stable) and GM = 0.7
(unstable). According to the rules for stability discussed earlier, these two
margins yield conﬂicting signals on the system's stability.

6.4 Stability Margins
355
Figure 6.40
System in which
increasing gain leads
from instability to
stability: (a) root locus;
(b) Nyquist plot
Re(s)
Im(s)
-10
-20
-30
-40
25
20
15
10
5
-5
-10
-20
-25
K = 7
K = 5
Re[G(s)]
Im[G(s)]
105
-1
1.4
Portion of Nyquist plot
portrayed by Bode plots
v = 0
v S q
(a)
(b)
We resolve the conﬂict by counting the Nyquist encirclements in
Fig. 6.40(b). There is one clockwise encirclement and one counterclock-
wise encirclement of the −1 point. Hence there are no net encirclements,
which conﬁrms that the system is stable for K = 7. For systems like this it
is best to resort to the root locus and/or Nyquist plot (rather than the Bode
plot) to determine stability.
EXAMPLE 6.13
Nyquist Plot for a System with Multiple Crossover Frequencies
Draw the Nyquist plot for the system
G(s) =
85(s + 1)(s2 + 2s + 43.25)
s2(s2 + 2s + 82)(s2 + 2s + 101)
=
85(s + 1)(s + 1 ± 6.5j)
s2(s + 1 ± 9j)(s + 1 ± 10j),
and determine the stability margins.
Solution.
The Nyquist plot (Fig. 6.41) shows qualitatively that there are
three crossover frequencies of the magnitude = 1 circle; therefore, there will
be three corresponding PM values. The Bode plot for this system (Fig. 6.42)
shows the three crossings of magnitude = 1 at 0.75, 9.0, and 10.1 rad/sec
which indicate PM's of 37◦, 80◦, and 40◦, respectively. The key indicator of
stability in this case is the proximity of the Nyquist plot as it approaches the
−1 point while crossing the real axis. Because there is only one crossing of
the real axis of the Nyquist plot (and, therefore, one crossing of the −180◦
line of the Phase plot), there is only one value of the GM. From the Bode
plot, we see that the phase crosses −180◦at ω = 10.4 rad/sec where the
magnitude = 0.79. Therefore, the GM = 1/0.79 = 1.26 which is the most
useful stability margin for this example. Note that if there had been multiple
crossings of −180◦, the smallest value of the GM determined at the various

356
Chapter 6 The Frequency-Response Design Method
Figure 6.41
Nyquist plot of the
complex system in
Example 6.13
Re[G(s)]
Im[G(s)]
-2
2
0.5
-1
1
1
Figure 6.42
Bode plot of the system
in Example 6.13
Magnitude
100
-100
Phase
05
0.1
1
10
100
0.2 0.4
2
4 6
20
4060
-505
-1005
-1505
-2005
-2505
-3005
-1805
v (rad/sec)
(b)
0.1
1
10
100
0.2 0.4
2
4 6
20
4060
v (rad/sec)
(a)
-80
-60
-40
-20
0
20
40
db
10
1
0.1
0.01
0.001
0.0001
0.00001
1/GM = 0.79
GM = 1.26
PM = 375
−180◦crossings would be the correct value of GM because that is where
the system would become unstable as the gain is increased. (See Tischler,
2012, pg. 226.)
In summary, many systems behave roughly like Example 6.9, and for
them, the GM and PM are well deﬁned and useful. There are also frequent

6.5 Bode's Gain-Phase Relationship
357
instances of more complicated systems where the Bode plot has multiple
magnitude 1 or −180◦crossovers for which the stability criteria deﬁned by
Fig. 6.33 are less clear; therefore, we need to determine possible values of
GM and PM, and then revert back to the Nyquist stability criterion for an
in-depth understanding and determination of the correct stability margins.
6.5
Bode's Gain-Phase Relationship
One of Bode's important contributions is the following theorem:
For any stable minimum-phase system (i.e., one with no RHP zeros
or poles), the phase of G( jω) is uniquely related to the magnitude
of G( jω).
When the slope of |G( jω)| versus ω on a log-log scale persists at a
constant value for approximately a decade of frequency, the relationship is
particularly simple and is given by
∠G( jω) ∼= n × 90◦,
(6.33)
where n is the slope of |G( jω)| in units of decade of amplitude per decade
of frequency. For example, in considering the magnitude curve alone in
Fig. 6.43, we see that Eq. (6.33) can be applied to the two frequencies
ω1 = 0.1 (where n = −2) and ω2 = 10 (where n = −1), which are a
decade removed from the change in slope, to yield the approximate values
of phase, −180◦and −90◦. The exact phase curve shown in the ﬁgure
veriﬁes that indeed the approximation is quite good. It also shows that the
approximation will degrade if the evaluation is performed at frequencies
closer to the change in slope.
An exact statement of the Bode gain-phase theorem is
∠G( jωo) = 1
π
 +∞
−∞
dM
du

W(u) du
in radians,
(6.34)
where
M = log magnitude = ln |G( jω)|,
u = normalized frequency = ln(ω/ωo),
dM/du ∼= slope n, as deﬁned in Eq. (6.33),
W(u) = weighting function = ln(coth|u|/2).
Figure 6.44 is a plot of the weighting function W(u) and shows how the
phase is most dependent on the slope at ωo; it is also dependent, though to a
lesser degree, on slopes at neighboring frequencies. The ﬁgure also suggests
that the weighting could be approximated by an impulse function centered
at ωo. We may approximate the weighting function as
W(u) ∼= π2
2 δ(u),

358
Chapter 6 The Frequency-Response Design Method
Figure 6.43
An approximate
gain-phase relationship
demonstration
0.1
1
10
0.1
1
10
100
v (rad/sec)
Magnitude, ƒG(jv)ƒ
Phase, jG(jv)
v1
v2
0.1
1
10
v (rad/sec)
40
20
0
-20
db
-905
-1205
-1505
-1805
Slope, n = - 2
n = - 1
Figure 6.44
Weighting function in
Bode's gain-phase
theorem
W(u)
u
0
2
4
6
-6
-4
-2
v0
0.1v0
10v0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
which is precisely the approximation made to arrive at Eq. (6.33) using the
"sifting"property of the impulse function (and conversion from radians to
degrees).
In practice, Eq. (6.34) is never used, but Eq. (6.33) is used as a guide to
infer stability from |G(ω)| alone. When |KG( jω)| = 1,
∠G( jω) ∼= −90◦
if n = −1,
∠G( jω) ∼= −180◦
if n = −2.
For stability we want ∠G( jω) > −180◦for the PM to be > 0. Therefore,
we adjust the |KG( jω)| curve so that it has a slope of −1 at the "crossover"

6.5 Bode's Gain-Phase Relationship
359
frequency, ωc (i.e., where |KG( jω)| = 1). If the slope is −1 for a decade
Crossover frequency
above and below the crossover frequency, then PM ∼= 90◦; however, to
ensure a reasonable PM, it is usually necessary only to insist that a −1 slope
(−20 db per decade) persist for a decade in frequency that is centered at
the crossover frequency. We therefore see that there is a very simple design
criterion:
Adjust the slope of the magnitude curve |KG( jω)| so that it crosses
over magnitude 1 with a slope of −1 for a decade around ωc.
This criterion will usually be sufﬁcient to provide an acceptable PM,
and hence provide adequate system damping. To achieve the desired speed
of response, the system gain is adjusted so that the crossover point is at
a frequency that will yield the desired bandwidth or speed of response as
determined by Eq. (3.60). Recall that the natural frequency ωn, bandwidth,
and crossover frequency are all approximately equal, as will be discussed
further in Section 6.6.
EXAMPLE 6.14
Use of Simple Design Criterion for Spacecraft Attitude Control
For the spacecraft attitude-control problem deﬁned in Fig. 6.45, ﬁnd a suit-
able expression for KDc(s) that will provide good damping and a bandwidth
of approximately 0.2 rad/sec. Also determine the frequency where the sen-
sitivity function S = 0.7 (= −3 db). This frequency is often referred to as
the "Disturbance Rejection Bandwidth," or ωDRB.
Disturbance Rejection
Bandwidth, ωDRB
Solution.
The magnitude of the frequency response of the spacecraft
(Fig. 6.46) clearly requires some reshaping, because it has a slope of −2
(or −40 db per decade) everywhere. The simplest compensation to do the
Figure 6.45
Spacecraft
attitude-control system
®com
s2
1
G(s) = 
©
 - 
 + 
Compensation
Spacecraft
KDc(s)
®
Figure 6.46
Magnitude of the
spacecraft's frequency
response
0.1
1
10
100 1000
1000
100
10
1
0.1
v (rad/sec)
Magnitude, ƒG(jv)ƒ
60
40
20
0
-20
db
Slope = -2 or 
-40 db/decade

360
Chapter 6 The Frequency-Response Design Method
job consists of using proportional and derivative terms (a PD compensator),
which produces the relation
KDc(s) = K(TDs + 1).
(6.35)
We will adjust the gain K to produce the desired bandwidth, and adjust
break point ω1 = 1/TD to provide the −1 slope at the crossover frequency.
The actual design process to achieve the desired speciﬁcations is now very
simple: We pick a value of K to provide a crossover at 0.2 rad/sec and choose
a value of ω1 that is about four times lower than the crossover frequency, so
that the slope will be −1 in the vicinity of the crossover. Figure 6.47 shows
the steps we take to arrive at the ﬁnal compensation:
1. Plot |G( jω)|.
2. Modifytheplottoinclude|Dc( jω)|, withω1 = 0.05rad/sec(TD = 20),
so that the slope will be ∼= −1 at ω = 0.2 rad/sec.
3. Determine that |DcG| = 100, where the |DcG| curve crosses the line
ω = 0.2 rad/sec, which is where we want magnitude 1 crossover to be.
4. In order for crossover to be at ω = 0.2 rad/sec, compute
K =
1
|DcG|ω=0.2
=
1
100 = 0.01.
Therefore,
KDc(s) = 0.01(20s + 1)
will meet the speciﬁcations, thus completing the design.
If we were to draw the phase curve of KDcG, we would ﬁnd that PM = 75◦,
which is certainly quite adequate. This result follows because the slope of
−1 occurs for a decade centered around the crossover frequency. A plot of
Figure 6.47
Compensated open-loop
transfer function
v1
Slope = -2 or -40 db per decade
Slope = -1 or -20 db per decade
ƒD(jv)G(jv)ƒ
ƒG(jv)ƒ
0.01
0.02
0.1
0.2
1
80
60
40
db
10,000
2000
1000
200
100
20
Magnitude, ƒDGƒ
v (rad/sec)
100
1
=
ƒKDGƒ = 1       K
= 0.01

6.6 Closed-Loop Frequency Response
361
Figure 6.48
Closed-loop frequency
response of
(s) and
(s)
10
1
0
0.7
db
v (rad/sec)
Magnitude
0.2
0.10.01
0.05
0.1
0.2
1-20
-3
20
T (jv)
S(jv)
the closed-loop frequency-response magnitude, T (s), (Fig. 6.48) shows that,
indeed, the crossover frequency and the bandwidth are almost identical in
this case; therefore, the desired bandwidth of 0.2 rad/sec has been met. The
sensitivity function was deﬁned by Eq. (4.17) and for this problem is
T
S =
1
1 + KDcG.
S(s) is also shown on Fig. 6.48, where it can be seen that S has the value
S
of 0.7 or −3db at ω = 0.15 rad/sec. The concept of a disturbance rejection
characteristic at a certain frequency (ωDRB) is often speciﬁed as a require-
ment for an acceptable design of a feedback system. Basically, ωDRB is the
maximum frequency at which the disturbance rejection (i.e., the sensitivity
function, S ) is below a certain amount, in this case −3db; so in this example,
ωDRB = 0.15 rad/sec.
The step response of the closed-loop system is shown in Fig. 6.49 and
its 14% overshoot conﬁrms the adequate damping.
6.6
Closed-Loop Frequency Response
The closed-loop bandwidth was deﬁned in Section 6.1 and in Fig. 6.5.
Figure 6.3 showed that the natural frequency is always within a factor of two
of the bandwidth for a second-order system. In Example 6.14, we designed
the compensation so that the crossover frequency was at the desired band-
width and veriﬁed by computation that the bandwidth was identical to the
crossover frequency. Generally, the match between the crossover frequency

362
Chapter 6 The Frequency-Response Design Method
Figure 6.49
Step response for PD
compensation
10
0
20
30
40
50
60
70
80
90
100
Time (sec)
1.2
1.0
0.8
0.6
0.4
0.2
0
u
and the bandwidth is not as good as in Example 6.14. We can help estab-
lish a more exact correspondence by making a few observations. Consider
a system in which |KG( jω)| shows the typical behavior
|KG( jω)| ≫1
for
ω ≪ωc,
|KG( jω)| ≪1
for
ω ≫ωc,
where ωc is the crossover frequency. The closed-loop frequency-response
magnitude is approximated by
|T ( jω)| =

KG( jω)
1 + KG( jω)
 ∼=
 1,
ω ≪ωc,
|KG|,
ω ≫ωc.
(6.36)
In the vicinity of crossover, where |KG( jω)| = 1, |T ( jω)| depends
heavily on the PM.A PM of 90◦means that ∠G( jωc) = −90◦, and therefore
|T ( jωc)| = 0.707. On the other hand, PM = 45◦yields |T ( jωc)| = 1.31.
The exact evaluation of Eq. (6.36) was used to generate the curves of
|T ( jω)| in Fig. 6.50. It shows that the bandwidth for smaller values of PM
Figure 6.50
Closed-loop bandwidth
with respect to PM
ƒT(jv)ƒ
ƒKG(jv)ƒ
PM = 905
2vc
5vc 10vc
ƒT(jv)ƒ _ ƒKG(jv)ƒ
v (rad/sec)
PM = 225
PM = 455
Bandwidth
Magnitude, ƒT(jv)ƒ and ƒG(jv)ƒ
2.0
1.0
0.7
0.2
0.1
-3
-20
db
0
vc

6.7 Compensation
363
is typically somewhat greater than ωc, though usually it is less than 2ωc;
thus
ωc ≤ωBW ≤2ωc.
Another speciﬁcation related to the closed-loop frequency response is
the resonant-peak magnitude Mr, deﬁned in Fig. 6.5. Figures 6.3 and 6.37
show that, for linear systems, Mr is generally related to the damping of
the system. In practice, Mr is rarely used; most designers prefer to use the
PM to specify the damping of a system, because the imperfections that make
systems nonlinear or cause delays usually erode the phase more signiﬁcantly
than the magnitude.
As demonstrated in the last example, it is also important in the design
to achieve certain error characteristics and these are often evaluated as a
function of the input or disturbance frequency. In some cases, the primary
function of the control system is to regulate the output to a certain constant
input in the presence of disturbances. For these situations, the key item of
interest for the design would be the closed-loop frequency response of the
error with respect to disturbance inputs.
6.7
Compensation
As we discussed in Chapters 4 and 5, dynamic elements (or compensation)
are typically added to feedback controllers to improve the system's stability
and error characteristics because the process itself cannot be made to have
acceptable characteristics with proportional feedback alone.
Section 4.3 discussed the basic types of feedback: proportional, deriva-
tive, and integral. Section 5.4 discussed three kinds of dynamic compensa-
tion: lead compensation, which approximates proportional-derivative (PD)
feedback, lag compensation, which approximates proportional-integral (PI)
control, and notch compensation, which has special characteristics for deal-
ing with resonances. In this section we discuss these and other kinds of
compensation in terms of their frequency-response characteristics.
The frequency-response stability analysis to this point has usually
considered the closed-loop system to have the characteristic equation
1 + KG(s) = 0. With the introduction of compensation, the closed-loop
characteristic equation becomes 1 + KDc(s)G(s) = 0, and all the previous
discussion in this chapter pertaining to the frequency response of KG(s)
applies directly to the compensated case if we apply it to the frequency
response of KDc(s)G(s). We call this quantity L(s), the "loop gain," or
open-loop transfer function of the system, where L(s) = KDc(s)G(s).
6.7.1
PD Compensation
We will start the discussion of compensation design by using the frequency
response with PD control. The compensator transfer function, given by
PD compensation
Dc(s) = (TDs + 1),
(6.37)
was shown in Fig. 5.22 to have a stabilizing effect on the root locus of a
second-order system. The frequency-response characteristics of Eq. (6.37)

364
Chapter 6 The Frequency-Response Design Method
are shown in Fig. 6.51. A stabilizing inﬂuence is apparent by the increase in
phase and the corresponding +1 slope at frequencies above the break point
1/TD. We use this compensation by locating 1/TD so that the increased phase
occurs in the vicinity of crossover (that is, where |KDc(s)G(s)| = 1), thus
increasing the PM.
Note that the magnitude of the compensation continues to grow with
increasing frequency. This feature is undesirable because it ampliﬁes the
high-frequency noise that is typically present in any real system and, as a
continuous transfer function, cannot be realized with physical elements. It
is also the reason we stated in Section 5.4 that pure derivative compensation
gives trouble.
6.7.2
Lead Compensation
In order to alleviate the high-frequency ampliﬁcation of the PD com-
pensation, a ﬁrst-order pole is added in the denominator at frequencies
substantially higher than the break point of the PD compensator. Thus the
phase increase (or lead) still occurs, but the ampliﬁcation at high frequencies
is limited. The resulting lead compensation has a transfer function of
Lead compensation
Dc(s) = TDs + 1
αTDs + 1,
α < 1,
(6.38)
Figure 6.51
Frequency response of
PD control
ƒDc(s)ƒ
db
jDc(s)
10
905
0.1
0.2
1
2
10
vT
605
305
05
v = TD
1
5
2
1
0.5
0.2
0.1
20
-20
0
v = TD
1
0.1
0.2
1
2
10
vT

6.7 Compensation
365
where
1/α is the ratio between the pole/zero break-point frequencies.
Figure 6.52 shows the frequency response of this lead compensation. Note
that a signiﬁcant amount of phase lead is still provided, but with much
less ampliﬁcation at high frequencies. A lead compensator is generally used
whenever a substantial improvement in damping of the system is required.
The phase contributed by the lead compensation in Eq. (6.38) is given by
φ = tan−1(TDω) −tan−1(αTDω).
It can be shown (see Problem 6.44) that the frequency at which the phase is
maximum is given by
ωmax =
1
TD
√α .
(6.39)
The maximum phase contribution—that is, the peak of the ∠Dc(s) curve in
Fig. 6.52—corresponds to
sin φmax = 1 −α
1 + α ,
(6.40)
or
α = 1 −sin φmax
1 + sin φmax
.
Another way to look at this is the following: The maximum phase occurs
at a frequency that lies midway between the two break-point frequencies
(sometimes called corner frequencies) on a logarithmic scale,
Figure 6.52
Lead-compensation
frequency response with
1/α = 10
ƒDc(s)ƒ
db
jDc(s)
10
5
905
605
305
05
2
1
0.5
0.2
0.1
20
0
-20
0.1
1
10
100
vTD
0.1
1
10
100
vTD
v = aTD
1
fmax
TD
1
v =
v = vmax

366
Chapter 6 The Frequency-Response Design Method
log ωmax = log 1/√TD
√αTD
= log
1
√TD
+ log
1
√αTD
= 1
2

log
 1
TD

+ log
 1
αTD

,
(6.41)
as shown in Fig. 6.52. Alternatively, we may state these results in terms
of the pole-zero locations. Rewriting Dc(s) in the form used for root-locus
analysis, we have
Dc(s) = s + z
s + p.
(6.42)
Problem 6.44 shows that
ωmax =

|z| |p|
(6.43)
and
log ωmax = 1
2(log |z| + log |p|).
(6.44)
These results agree with the previous ones if we let z =
−1/TD and
p = −1/αTD in Eqs. (6.39) and (6.41).
For example, a lead compensator with a zero at s = −2 (TD = 0.5) and
a pole at s = −10 (αTD = 0.1) (and thus α = 1
5) would yield the maximum
phase lead at
ωmax =
√
2 · 10 = 4.47 rad/sec.
The amount of phase lead at the midpoint depends only on α in Eq. (6.40)
and is plotted in Fig. 6.53. For α = 1/5, Fig. 6.53 shows that φmax = 40◦.
Note from the ﬁgure that we could increase the phase lead up to 90◦using
higher15 values of the lead ratio, 1/α; however, Fig. 6.52 shows that increas-
Lead ratio
ing values of 1/α also produces higher ampliﬁcations at higher frequencies.
Thus our task is to select a value of 1/α that is a good compromise between
an acceptable PM and an acceptable noise sensitivity at high frequencies.
Usually the compromise suggests that a lead compensation should contribute
Figure 6.53
Maximum phase
increase for lead
compensation
905
1
605
305
05
100
40 60
20
10
4
6 8
2
Maximum phase lead
a
1
15Lead ratio = 1/α.

6.7 Compensation
367
a maximum of 70◦to the phase. If a greater phase lead is needed, then a
double-lead compensation would be suggested, where
Dc(s) =
 TDs + 1
αTDs + 1
2
.
Even if a system had negligible amounts of noise present and the
pure derivative compensation of Eq. (6.37) were acceptable, a continuous
compensation would look more like Eq. (6.38) than Eq. (6.37) because of
the impossibility of building a pure differentiator. No physical system—
mechanical or electrical—responds with inﬁnite amplitude at inﬁnite fre-
quencies, so there will be a limit in the frequency range (or bandwidth) for
which derivative information (or phase lead) can be provided. This is also
true with a digital implementation. Here, the sample rate limits the high-
frequency ampliﬁcation and essentially places a pole in the compensation
transfer function.
EXAMPLE 6.15
Lead Compensation for a DC Motor
As an example of designing a lead compensator, let us repeat the design of
compensation for the DC motor with the transfer function
G(s) =
1
s(s + 1)
that was carried out in Section 5.4.1. This also represents the model of
a satellite tracking antenna (see Fig. 3.60). This time we wish to obtain
a steady-state error of less than 0.1 for a unit-ramp input. Furthermore, we
desire an overshoot Mp < 25%. Determine the lead compensation satisfying
the speciﬁcations.
Solution. The steady-state error is given by
ess = lim
s→0 s

1
1 + KDc(s)G(s)

R(s),
(6.45)
where R(s) = 1/s2 for a unit ramp, so Eq. (6.45) reduces to
ess = lim
s→0

1
s + KDc(s)[1/(s + 1)]

=
1
KDc(0).
Therefore, we ﬁnd that KDc(0), the steady-state gain of the compensation,
cannot be less than 10 (Kv ≥10) if it is to meet the error criterion, so we pick
K = 10. To relate the overshoot requirement to PM, Fig. 6.37 shows that
a PM of 45◦should sufﬁce. The frequency response of KG(s) in Fig. 6.54
shows that the PM = 20◦if no phase lead is added by compensation. If it
werepossibletosimplyaddphasewithoutaffectingthemagnitude, wewould
need an additional phase of only 25◦at the KG(s) crossover frequency of ω =
3 rad/sec. However, maintaining the same low-frequency gain and adding a
compensator zero would increase the crossover frequency; hence more than
a 25◦phase contribution will be required from the lead compensation. To be
safe, we will design the lead compensator so that it supplies a maximum

368
Chapter 6 The Frequency-Response Design Method
Figure 6.54
Frequency response for
lead-compensation
design
v (rad/sec)
Magnitude, ƒLƒ
Phase (deg) jL
KG(s)
KDc(s)G(s)
Lead pole
0.1
0.2
1
2
10
v (rad/sec)
0.1
0.2
1
2
10
200
100
10
1
-905
-1205
-1505
-1805
-2105
-2405
Lead zero
PM = 205
535
2
20
40
20
0
db
phase lead of 40◦. Fig. 6.53 shows that 1/α = 5 will accomplish that goal.
We will derive the greatest beneﬁt from the compensation if the maximum
phase lead from the compensator occurs at the crossover frequency. With
some trial and error, we determine that placing the zero at ω = 2 rad/sec
and the pole at ω = 10 rad/sec causes the maximum phase lead to be at the
crossover frequency. The compensation, therefore, is
KDc(s) = 10 s/2 + 1
s/10 + 1.
The frequency-response characteristics of L(s) = KDc(s)G(s) in Fig. 6.54
can be seen to yield a PM of 53◦, which satisﬁes the design goals.
1. The root locus for this design, originally given as Fig. 5.24, is repeated
here as Fig. 6.55, with the root locations marked for K = 10. The
locus is not needed for the frequency-response design procedure; it is
presented here only for comparison with the root-locus design method
presented in Chapter 5, which had an equivalent gain of K = 14. For

6.7 Compensation
369
Figure 6.55
Root locus for lead
compensation design
2
s
KDc(s) = K 
+ 1
10
s + 1
G(s) = s(s + 1)
1
K = 10
Im(s)
Re(s)
10
8
6
4
2
-2
-4
-6
-10
-8
5
0
-10
-15
-5
Figure 6.56
Step response of lead
compensator design for
Example 6.15
1.2
0
0
0.5
1
0.2
0.4
0.6
0.8
1
Time (sec)
1.4
1.6
1.8
2
y
further comparison, Fig. 6.56 shows the time response of the system
to a step command. Comparing it to Fig. 5.25, we see that the current
design is slightly slower, having a rise time tr = 0.33 sec compared to
the tr = 0.26 sec for Fig. 5.25.
The design procedure used in Example 6.15 can be summarized as
follows:
1. Determine the low-frequency gain so that the steady-state errors are
within speciﬁcation.
2. Select the combination of lead ratio 1/α and zero values (1/TD) that
achieves an acceptable PM at crossover.
3. The pole location is then at (1/αTD).
This design procedure will apply to many cases; however, keep in mind
that the speciﬁc procedure followed in any particular design may need to be
tailored to its particular set of speciﬁcations.
In Example 6.15 there were two speciﬁcations: peak overshoot and
steady-state error. We transformed the overshoot speciﬁcation into a PM, but
the steady-state error speciﬁcation we used directly. No speed-of-response
type of speciﬁcation was given; however, it would have impacted the design
in the same way that the steady-state error speciﬁcation did. The speed

370
Chapter 6 The Frequency-Response Design Method
of response or bandwidth of a system is directly related to the crossover
frequency, as we pointed out earlier in Section 6.6. Figure 6.54 shows that
the crossover frequency was ∼5 rad/sec. We could have increased it by
raising the gain K and increasing the frequency of the lead compensator pole
and zero in order to keep the slope of −1 at the crossover frequency. Raising
the gain would also have decreased the steady-state error to be better than the
speciﬁed limit. The GM was never introduced into the problem because the
stability was adequately speciﬁed by the PM alone. Furthermore, the GM
would not have been useful for this system because the phase never crossed
the 180◦line and the GM was always inﬁnite.
In
lead-compensation
designs
there
are
three
primary
design
Design parameters for lead
networks
parameters:
1. The crossover frequency ωc, which determines bandwidth ωBW , rise
time tr, and settling time ts;
2. The PM, which determines the damping coefﬁcient ζ and the over-
shoot Mp;
3. The low-frequency gain, which determines the steady-state error
characteristics.
Thedesignproblemistoﬁndthebestvaluesfortheparameters, giventhe
requirements. In essence, lead compensation increases the value of ωc/L(0)
(= ωc/Kv for a Type 1 system). That means that, if the low-frequency gain
is kept the same, the crossover frequency will increase. Or, if the crossover
frequency is kept the same, the low-frequency gain will decrease. Keeping
this interaction in mind, the designer can assume a ﬁxed value of one of these
three design parameters and then adjust the other two iteratively until the
speciﬁcations are met. One approach is to set the low-frequency gain to meet
the error speciﬁcations and add a lead compensator to increase PM at the
crossover frequency.An alternative is to pick the crossover frequency to meet
a time response speciﬁcation, then adjust the gain and lead characteristics so
that the PM speciﬁcation is met. A step-by-step procedure is outlined next
for these two cases. They apply to a sizable class of problems for which a
single lead is sufﬁcient. As with all such design procedures, it provides only
a starting point; the designer will typically ﬁnd it necessary to go through
several design iterations in order to meet all the speciﬁcations.
Design Procedure for
Lead Compensation
1. Determine the gain K to satisfy error or bandwidth requirements:
(a) to meet error requirements, pick K to satisfy error constants
(Kp, Kv, or Ka) so that ess error speciﬁcation is met, or
alternatively,
(b) to meet bandwidth requirements, pick K so that the open-loop
crossover frequency is a factor of two below the desired closed-
loop bandwidth.
2. Evaluate the PM of the uncompensated system using the value of
K obtained from Step 1.

6.7 Compensation
371
3. Allow for extra margin (about 10◦), and determine the needed phase
lead φmax.
4. Determine α from Eq. (6.40) or Fig. 6.53.
5. Pick ωmax to be at the crossover frequency; thus the zero is at
1/TD = ωmax
√α and the pole is at 1/αTD = ωmax/√α.
6. Draw the compensated frequency response and check the PM.
7. Iterate on the design. Adjust compensator parameters (poles, zeros,
and gain) until all speciﬁcations are met. Add an additional lead
compensator (that is, a double-lead compensation) if necessary.
While these guidelines will not apply to all the systems you will
encounter in practice, they do suggest a systematic trial-and-error process
to search for a satisfactory compensator that will usually be successful.
EXAMPLE 6.16
Lead Compensator for a Temperature Control System
The third-order system
KG(s) =
K
(s/0.5 + 1)(s + 1)(s/2 + 1)
is representative of a typical temperature control system. Design a lead
compensator such that Kp = 9 and the PM is at least 25◦.
Solution. Let us follow the design procedure:
1. Given the speciﬁcation for Kp, we solve for K:
Kp = lim
s→0 KG(s) = K = 9.
2. The Bode plot of the uncompensated system, KG(s), with K = 9 can
be created by the Matlab statements below and is shown in Fig. 6.57
along with the two compensated cases.
s = tf('s');
sysG = 9/((s/0.5 + 1)*(s + 1)*(s/2 + 1));
w=logspace(−1,1);
[mag,phase] = bode(sysG,w);
loglog(w,squeeze(mag)),grid;
semilogx(w,squeeze(phase)),grid;
It is difﬁcult to read the PM and crossover frequencies accurately
from the Bode plots; therefore, the Matlab command
[GM,PM,Wcg,Wcp] = margin(mag,phase,w);
can be invoked. The quantity PM is the phase margin and Wcp is the
frequency at which the gain crosses magnitude 1. (GM and Wcg are the

372
Chapter 6 The Frequency-Response Design Method
Figure 6.57
Bode plot for the
lead-compensation
design in Example 6.16
10-1
101
100
v  (rad/sec)
(b)
10-1
101
100
v  (rad/sec)
(a)
-250
-200
-150 -180
-100
-50
Phase (deg)
Magnitude
385
75
165
10-1
100
101
0
20
-20
db
KGD2
GD1
GD2
G
KGD1
KG
GM and the frequency at which the phase crosses −180◦.) For this
example, the output is
GM =1.25, PM = 7.14, Wcg = 1.87, Wcp = 1.68,
which says that the PM of the uncompensated system is 7◦and that this
occurs at a crossover frequency of 1.7 rad/sec.
3. Allowing for 10◦of extra margin, we want the lead compensator to
contribute 25◦+ 10◦−7◦= 28◦at the crossover frequency. The extra
margin is typically required because the lead will increase the crossover
frequency from the open-loop case, at which point more phase increase
will be required.
4. From Fig. 6.53 we see that α = 1/3 will produce approximately 30◦
phase increase midway between the zero and pole.
5. As a ﬁrst cut, let's place the zero at 1 rad/sec (TD = 1) and the pole
at 3 rad/sec (αTD =
1/3), thus bracketing the open-loop crossover
frequency and preserving the factor of 3 between pole and zero, as
indicated by α = 1/3. The lead compensator is
D1(s) =
s + 1
s/3 + 1 =
1
0.333
s + 1
s + 3

.
6. The Bode plot of the system with D1(s) (Fig. 6.57, middle curve) has a
PM of 16◦. We did not achieve the desired PM of 30◦, because the lead
shifted the crossover frequency from 1.7 rad/sec to 2.3 rad/sec, thus
increasing the required phase increase from the lead. The step response
of the system with D1(s) (Fig. 6.58) shows a very oscillatory response,
as we might expect from the low PM of 16◦.
7. We repeat the design with extra phase increase and move the zero
location slightly to the right so that the crossover frequency won't be

6.7 Compensation
373
Figure 6.58
Step response for
lead-compensation
design
0
20
18
16
14
12
10
8
6
4
2
Time (sec)
0
0.5
1
1.5
D2
D1
y
shifted so much. We choose α = 1/10 with the zero at s = −1.5, so
D2(s) = s/1.5 + 1
s/15 + 1 = 1
0.1
s + 1.5
s + 15

.
This compensation produces a PM = 38◦, and the crossover frequency
lowers slightly to 2.2 rad/sec. Figure 6.57 (upper curve) shows the fre-
quency response of the revised design. Figure 6.58 shows a substantial
reduction in the oscillations, which you should expect from the higher
PM value.
EXAMPLE 6.17
Lead-Compensator Design for a Type 1
Servomechanism System
Consider the third-order system
KG(s) = K
10
s(s/2.5 + 1)(s/6 + 1).
This type of system would result for a DC motor with a lag in the shaft
position sensor. Design a lead compensator so that the PM = 45◦and
Kv = 10.
Solution. Again, we follow the design procedure given earlier:
1. As given, KG(s) will yield Kv = 10 if K = 1. Therefore, the Kv require-
ment is met by K = 1 and the low-frequency gain of the compensation
should be 1.
2. The Bode plot of the system is shown in Fig. 6.59. The PM of the
uncompensated system (lower curve) is approximately −4◦, and the
crossover frequency is at ωc ∼= 4 rad/sec.
3. Allowing for 5◦of extra PM, we need PM = 45◦+ 5◦−(−4◦) = 54◦
to be contributed by the lead compensator.
4. From Fig. 6.53 we ﬁnd that α must be 0.1 to achieve a maximum phase
lead of 54◦.
5. The new gain crossover frequency will be higher than the open-loop
value of ωc = 4 rad/sec, so let's select the pole and zero of the lead
compensation to be at 20 and 2 rad/sec, respectively. So the candidate
compensator is
D1(s) = s/2 + 1
s/20 + 1 = 1
0.1
s + 2
s + 20.

374
Chapter 6 The Frequency-Response Design Method
Figure 6.59
Bode plot for the
lead-compensation
design in Example 6.17
10-1
102
101
100
v (rad/sec)
(b)
10-1
102
101
100
v (rad/sec)
(a)
-250
-200
-150
-100
-50
Phase (deg)
Magnitude
10-2
100
10-1
101
0
20
-20
-40
db
GD2
KG
-180
-45
465
235
KGD1
KGD2
GD1
G
6. The Bode plot of the compensated system (Fig. 6.59, middle curve)
shows a PM of 23◦. Further iteration will show that a single-lead com-
pensator cannot meet the speciﬁcation because of the high-frequency
slope of −3.
7. We need a double-lead compensator in this system. If we try a
compensator of the form
D2(s) =
1
(0.1)2
(s + 2)(s + 4)
(s + 20)(s + 40) =
(s/2 + 1)(s/4 + 1)
(s/20 + 1)(s/40 + 1),
we obtain PM = 46◦. The Bode plot for this case is shown as the upper
curve in Fig. 6.59.
Both Examples 6.16 and 6.17 are third order. Example 6.17 was more difﬁ-
cult to design compensation for, because the error requirement, Kv, forced
the crossover frequency, ωc, to be so high that a single lead could not provide
enough PM.
6.7.3
PI Compensation
In many problems it is important to keep the bandwidth low and also to
reduce the steady-state error. For this purpose, a proportional-integral (PI)
PI compensation
or lag compensator is useful. From Eq. (4.73), we see that PI control has the
transfer function
Dc(s) = K
s

s + 1
TI

,
(6.46)
which results in the frequency-response characteristics shown in Fig. 6.60.
The desirable aspect of this compensation is the inﬁnite gain at zero
frequency, which reduces the steady-state errors. This is accomplished, how-
ever, at the cost of a phase decrease at frequencies lower than the break point

6.7 Compensation
375
Figure 6.60
Frequency response of
PI control
v = TI
1
jDc(s)
ƒDc(s)ƒ
vTI
0.1K
-605
0.1
1
10
0.2
2
vTI
0.1
1
10
0.2
2
v = TI
1
-905
-305
05
0.2K
K
2K
10K
at ω = 1/TI. Therefore, 1/TI is usually located at a frequency substantially
less than the crossover frequency so that the system's PM is not affected
signiﬁcantly.
6.7.4
Lag Compensation
As we discussed in Section 5.4, lag compensation approximates PI con-
Lag compensation
trol. Its transfer function was given by Eq. (5.72) for root-locus design, but
for frequency-response design, it is more convenient to write the transfer
function of the lag compensation alone in the Bode form
Dc(s) = α TIs + 1
αTIs + 1,
α > 1,
(6.47)
where α is the ratio between the zero/pole break-point frequencies. The com-
plete controller will almost always include an overall gain K and perhaps
other dynamics in addition to the lag compensation. Although Eq. (6.47)
looks very similar to the lead compensation in Eq. (6.38), the fact is that
α > 1 causes the pole to have a lower break-point frequency than the
zero. This relationship produces the low-frequency increase in amplitude and
phase decrease (lag) apparent in the frequency-response plot in Fig. 6.61 and
givesthecompensationtheessentialfeatureofintegralcontrol—anincreased
low-frequency gain. The typical objective of lag-compensation design is to

376
Chapter 6 The Frequency-Response Design Method
Figure 6.61
Frequency response of
lag compensation with
α = 10
jDc(s)
ƒDc(s)ƒ
vTI
v =
10
05
0.1
1
10
vTI
0.1
1
10
-305
-605
-905
-1205
5
2
1
a = 10
-20
20
0
db
v = TI
1
1
aTI
provide additional gain of α in the low-frequency range and to leave the sys-
tem sufﬁcient PM. Of course, phase lag is not a useful effect, and the pole
and zero of the lag compensator are selected to be at much lower frequen-
cies than the uncompensated system crossover frequency in order to keep
the effect on the PM to a minimum. Thus, the lag compensator increases the
open-loop DC gain, thereby improving the steady-state response character-
istics, without changing the transient-response characteristics signiﬁcantly.
If the pole and zero are relatively close together and near the origin (that is,
if the value of TI is large), we can increase the low-frequency gain (and thus
Kp, Kv, or Ka) by a factor α without moving the closed-loop poles appre-
ciably. Hence, the transient response remains approximately the same while
the steady-state response is improved.
We now summarize a step-by-step procedure for lag-compensator
Design Procedure for Lag
Compensation
design.
1. Determine the open-loop gain K that will meet the PM requirement
without compensation.
2. Draw the Bode plot of the uncompensated system with crossover
frequency from Step 1, and evaluate the low-frequency gain.
3. Determine α to meet the low-frequency gain error requirement.

6.7 Compensation
377
4. Choose the corner frequency ω = 1/TI (the zero of the lag com-
pensator) to be one octave to one decade below the new crossover
frequency ωc.
5. The other corner frequency (the pole location of the lag compen-
sator) is then ω = 1/αTI.
6. Iterate on the design. Adjust compensator parameters (poles, zeros,
and gain) to meet all the speciﬁcations.
EXAMPLE 6.18
Lag-Compensator Design for Temperature Control System
Again consider the third-order system of Example 6.16:
KG(s) =
K
 1
0.5s + 1

(s + 1)
 1
2s + 1
.
Design a lag compensator so the PM is at least 40◦and Kp = 9.
Solution. We follow the design procedure previously enumerated.
1. From the open-loop plot of KG(s), shown for K = 9 in Fig. 6.57, it can
be seen that a PM > 40◦will be achieved if the crossover frequency
ωc ≲1 rad/sec. This will be the case if K = 3. So we pick K = 3 in
order to meet the PM speciﬁcation.
2. The Bode plot of KG(s) in Fig. 6.62 with K = 3 shows that the PM is
≈50◦and the low-frequency gain is now 3. Exact calculation of the
PM using Matlab's margin shows that PM = 53◦.
Figure 6.62
Frequency response of
lag-compensation
design in Example 6.18
(b)
10-2
10-1
101
100
10-2
10-1
101
100
v (rad/sec)
v (rad/sec)
(a)
-250
-200
-150 -180
-100
-50
Phase (deg) jL
Magnitude, ƒLƒ
535
10-1
100
101
0
20
-20
db
KGDc
KGDc
KG
KG

378
Chapter 6 The Frequency-Response Design Method
Figure 6.63
Step response of
lag-compensation
design in Example 6.18
0
20
18
16
14
12
10
8
6
4
2
Time (sec)
0
1.2
0.8
0.4
y
3. The low-frequency gain should be raised by a factor of 3, which means
the lag compensation needs to have α = 3.
4. We choose the corner frequency for the zero to be approximately a
factor of 5 slower than the expected crossover frequency—that is, at
0.2 rad/sec. So, 1/TI = 0.2, or TI = 5.
5. We then have the value for the other corner frequency: ω = 1/αTI =
1
(3)(5) = 1/15 rad/sec. The compensator is thus
Dc(s) = 3 5s + 1
15s + 1.
The compensated frequency response is also shown in Fig. 6.62. The
low-frequency gain of KDc(0)G(0) = 3K = 9, thus Kp = 9 and the
PM lowers slightly to 44◦, which satisﬁes the speciﬁcations. The step
response of the system, shown in Fig. 6.63, illustrates the reasonable
damping that we would expect from PM = 44◦.
6. No iteration is required in this case.
Note that Examples 6.16 and 6.18 are both for the same plant, and both
had the same steady-state error requirement. One was compensated with
lead and one was compensated with lag. The result is that the bandwidth
of the lead-compensated design is higher than that for the lag-compensated
design by approximately a factor of 3. This result can be seen by comparing
the crossover frequencies of the two designs.
Abeneﬁcialeffectoflagcompensation, anincreaseinthelow-frequency
gain for better error characteristics, was just demonstrated in Example 6.18.
However, in essence, lag compensation reduces the value of ωc/L(0)
(= ωc/Kv for a Type 1 system). That means that, if the crossover fre-
quency is kept the same, the low-frequency gain will increase. Likewise,
if the low-frequency gain is kept the same, the crossover frequency will
decrease. Therefore, lag compensation could also be interpreted to reduce
the crossover frequency and thus obtain a better PM. The procedure for
design in this case is partially modiﬁed. First, pick the low-frequency gain
to meet error requirements, then locate the lag compensation pole and zero
in order to provide a crossover frequency with adequate PM. The next exam-
ple illustrates this design procedure. The end result of the design will be the
same no matter what procedure is followed.

6.7 Compensation
379
EXAMPLE 6.19
Lag Compensation of the DC Motor
Repeat the design of the DC motor control in Example 6.15, this time using
lag compensation. Fix the low-frequency gain in order to meet the error
requirement of Kv = 10; then use the lag compensation to meet the PM
requirement of 45◦. Compare the open-loop Bode magnitude plots and the
time responses for Examples 6.15 and 6.19.
Solution. The frequency response of the system KG(s), with the required
gain of K = 10, is shown in Fig. 6.64. The uncompensated system has
a crossover frequency at approximately 3 rad/sec where the PM = 20◦.
The designer's task is to select the lag compensation break points so that
the crossover frequency is lowered and more favorable PM results. To pre-
vent detrimental effects from the compensation phase lag, the pole and zero
position values of the compensation need to be substantially lower than the
new crossover frequency. One possible choice is shown in Fig. 6.64: The
lag zero is at 0.1 rad/sec, and the lag pole is at 0.01 rad/sec. This selec-
tion of parameters produces a PM of 50◦, thus satisfying the speciﬁcations.
Figure 6.64
Frequency response of
lag-compensation
design in Example 6.19
v (rad/sec)
PM = 205
0.001
0.01
0.1
2
10
0.2
v (rad/sec)
0.001
0.01
0.1
1
2
0.2
1
Lag zero
Lag pole
KDc(s)G(s)
KG(s)
PM = 505
-905
-1205
-1505
-1805
-2105
100
10
1
20
2
0
20
40
db
Phase, jL
Magnitude, ƒLƒ

380
Chapter 6 The Frequency-Response Design Method
Here the stabilization is achieved by keeping the crossover frequency to a
region where G(s) has favorable phase characteristics. However, note that
ωc ∼= 0.8 rad/sec for this case compared to the ωc ∼= 5 rad/sec for the Exam-
ple 6.15 where lead compensation was used. The criterion for selecting the
pole and zero locations 1/TI is to make them low enough to minimize the
effects of the phase lag from the compensation at the crossover frequency.
Generally, however, the pole and zero are located no lower than necessary,
because the additional system root (compare with the root locus of a sim-
ilar system design in Fig. 5.28) introduced by the lag will be in the same
frequency range as the compensation zero and will have some effect on the
output response, especially the response to disturbance inputs.
The response of the system to a step reference input is shown in Fig. 6.65.
It shows no steady-state error to a step input, because this is a Type 1 system.
However, the introduction of the slow root from the lag compensation has
caused the response to require about 25 sec to settle down to the zero steady-
state value and the rise time, tr = 2 sec compared to tr = 0.33 sec for
Example 6.15. This difference in rise time is to be expected based on the
difference in crossover frequencies. The overshoot Mp is somewhat larger
than you would expect from the guidelines, based on a second-order system
shown in Fig. 6.37 for a PM = 50◦; however, the performance is adequate.
As we saw previously for a similar situation, Examples 6.15 and 6.19
meet an identical set of speciﬁcations for the same plant in very different
ways. In the ﬁrst case the speciﬁcations are met with a lead compensation,
and a crossover frequency ωc = 5 rad/sec (ωBW ∼= 6 rad/sec) results. In
the second case the same speciﬁcations are met with a lag compensation,
and ωc ∼= 0.8 rad/sec (ωBW ∼= 0.9 rad/sec) results. Clearly, had there been
speciﬁcations for rise time or bandwidth, they would have inﬂuenced the
choice of compensation (lead or lag). Likewise, if the slow settling to the
steady-state value was a problem, it might have suggested the use of lead
compensation instead of lag.
In more realistic systems, dynamic elements usually represent the actu-
ator and sensor as well as the process itself, so it is typically impossible to
raise the crossover frequency much beyond the value representing the speed
of response of the components being used. Although linear analysis seems
Important caveat on
design strategy
to suggest that almost any system can be compensated, in fact, if we attempt
Figure 6.65
Step response of
lag-compensation
design in Example 6.19
15
20
25
10
5
0
0
0.2
0.4
0.6
0.8
1
1.2
y
Time (sec)

6.7 Compensation
381
to drive a set of components much faster than their natural frequencies,
the system will saturate, the linearity assumptions will no longer be valid,
and the linear design will represent little more than wishful thinking. With
this behavior in mind, we see that simply increasing the gain of a system
and adding lead compensators to achieve an adequate PM may not always
be possible. It may be preferable to satisfy error requirements by adding a
lag network so that the closed-loop bandwidth is kept at a more reasonable
frequency.
6.7.5
PID Compensation
For problems that need PM improvement at ωc and low-frequency gain
improvement, it is effective to use both derivative and integral control. By
combining Eqs. (6.37) and (6.46), we obtain PID control. A common way
to write its transfer function is
PID compensation
Dc(s) = K
s

(TDs + 1)

s + 1
TI

,
(6.48)
and its frequency-response characteristics are shown in Fig. 6.66. This form
is slightly different from that given by Eq. (4.75); however, the effect of
Figure 6.66
Frequency response of
PID compensation with
TI
TD = 20
ƒDc(s)ƒ
v = TI
1
v = TD
1
jDc(s)
10K
905
0.1
1
10
100
vTI
0.1
1
10
100
vTI
605
305
05
-305
-605
-905
2K
K
0.2
2
0.2
2

382
Chapter 6 The Frequency-Response Design Method
the difference is inconsequential. This compensation is roughly equiva-
lent to combining lead and lag compensators in the same design, and so
is sometimes referred to as a lead-lag compensator. Hence, it can provide
simultaneous improvement in transient and steady-state responses.
EXAMPLE 6.20
PID Compensation Design for Spacecraft Attitude Control
A simpliﬁed design for spacecraft attitude control was presented in
Section 6.5; however, here we have a more realistic situation that includes a
sensor lag and a disturbing torque. Figure 6.67 deﬁnes the system.
1. Design a PID controller to have zero steady-state error to a constant-
disturbance torque, a PM of 65◦, and as high a bandwidth as is
reasonably possible.
2. Plot the step response versus a command input and the step response
to a constant disturbance torque.
3. Plot the closed-loop frequency response,

com , and the sensitivity
function, S.
4. Determine ωBW and ωDRB.
5. For a torque disturbance from solar pressure that acts as a sinusoid at
the orbital rate (ω = 0.001 rad/sec or ≈100-minute period), comment
on the usefulness of this controller to attenuate solar pressure effects.
Solution. First, let us take care of the steady-state error. For the spacecraft
to be at a steady ﬁnal value, the total input torque, Td + Tc, must equal zero.
Therefore, if Td ̸= 0, then Tc = −Td. The only way this can be true with
no error (e = 0) is for Dc(s) to contain an integral term. Hence, including
integral control in the compensation will meet the steady-state requirement.
This could also be veriﬁed mathematically by use of the FinalValueTheorem
(see Problem 6.47).
The frequency response of the spacecraft and sensor, GH, where
G(s) = 0.9
s2
and H(s) =

2
s + 2

,
(6.49)
Figure 6.67
Block diagram of
spacecraft control using
PID design,
Example 6.20
©
 - 
 + 
Sensor
Compensation
®com
Td
Tc
s + 2
2
s2
0.9
®m
®
Dc(s)
©
 + 
 + 
Spacecraft
Disturbance
torque

6.7 Compensation
383
is shown in Fig. 6.68. The slopes of −2 (that is, −40 db per decade) and −3
(−60 db per decade) show that the system would be unstable for any value
of K if no derivative feedback were used. This is clear because of Bode's
gain-phase relationship, which shows that the phase would be −180◦for the
−2 slope and −270◦for the −3 slope, which would correspond to a PM of
0◦or −90◦, respectively. Therefore, derivative control is required to bring
the slope to −1 at the crossover frequency that was shown in Section 6.5 to
be a requirement for stability. The problem now is to pick values for the three
parameters in Eq. (6.48)—K, TD, and TI—that will satisfy the speciﬁcations.
The easiest approach is to work ﬁrst on the phase so that PM = 65◦is
achieved at a reasonably high frequency. This can be accomplished primarily
by adjusting TD, noting that TI has a minor effect if sufﬁciently larger than
Figure 6.68
Compensation for PID
design in Example 6.20
v (rad/sec)
TI
1  = 0.005
Slope =  -2
-3
{
1000
100
10
1
0.1
-905
-1205
-1505
-1805
-2705
Magnitude, ƒLƒ
Phase, jL
20
0.001
0.01
0.1
1
10
100
2
5
v (rad/sec)
0.001
0.01
0.1
1
10
100
2
5
-2105
-2405
vc = 0.5 rad/sec
TD
1 = 0.1
ƒG(s)ƒ
ƒDc(s)G(s)ƒ
(K = 1)
Dc(s)G(s), TD
1 ... 0.05
Dc(s)G(s), TD
1  = 0.1
jG(s)
PM = 655
60
40
20
0
-20
-40
db

384
Chapter 6 The Frequency-Response Design Method
TD. Once the phase is adjusted, we establish the crossover frequency; then
we can easily determine the gain K.
We examine the phase of the PID controller in Fig. 6.66 to determine
what would happen to the compensated spacecraft system, Dc(s)G(s), as TD
is varied. If 1/TD ≥2 rad/sec, the phase lead from the PID control would
simply cancel the sensor phase lag, and the composite phase would never
exceed −180◦, an unacceptable situation. If 1/TD ≤0.01, the composite
phase would approach −90◦for some range of frequencies and would exceed
−115◦for an even wider range of frequencies; the latter threshold would
provide a PM of 65◦. In the compensated phase curve shown in Fig. 6.68,
1/TD = 0.1, which is the largest value of 1/TD that could provide the required
PM of 65◦. The phase would never cross the −115◦(65◦PM) line for any
1/TD > 0.1. For 1/TD = 0.1, the crossover frequency ωc that produces the 65◦
PM is 0.5 rad/sec. For a value of 1/TD ≪0.05, the phase essentially follows
the dotted curve in Fig. 6.68, which indicates that the maximum possible
ωc is approximately 1 rad/sec and is provided by 1/TD = 0.05. Therefore,
0.05 < 1/TD < 0.1 is the only sensible range for 1/TD; anything less than 0.05
would provide no signiﬁcant increase in bandwidth, while anything more
than 0.1 could not meet the PM speciﬁcation. Although the ﬁnal choice is
somewhat arbitrary, we have chosen 1/TD = 0.1 for our ﬁnal design.
Our choice for 1/TI is a factor of 20 lower than 1/TD; that is, 1/TI =
0.005. A factor less than 20 would negatively impact the phase at crossover,
thus lowering the PM. Furthermore, it is generally desirable to keep the
compensated magnitude as large as possible at frequencies below ωc in
order to have a faster transient response and smaller errors; maintaining 1/TD
and 1/TI at the highest possible frequencies will bring this about.An alternate
approach for this problem would have been to pick 1/TD = 0.05 in order to
have a larger phase increase. This would have allowed a higher value of 1/TI
which would have provided for a faster response of the integral portion of
the controller. Note for this system that the sensor break point at 2 rad/sec
is limiting how high 1/TD can be selected. Problem 6.63 examines alternate
designs for this system.
The only remaining task is to determine the proportional part of the PID
controller, or K. Unlike the system in Example 6.18, where we selected K
in order to meet a steady-state error speciﬁcation, here we select a value
of K that will yield a crossover frequency at the point corresponding to
the required PM of 65◦. The basic procedure for ﬁnding K, discussed in
Section 6.6, consists of plotting the compensated system amplitude with
K = 1, ﬁnding the amplitude value at crossover, then setting 1/K equal to
that value. Figure 6.68 shows that when K = 1, |Dc(s)G(s)| = 20 at the
desired crossover frequency ωc = 0.5 rad/sec. Therefore,
1
K = 20,
so
K = 1
20 = 0.05.
The compensation equation that satisﬁes all of the speciﬁcations is now
complete:
Dc(s) = 0.05
s
[(10s + 1)(s + 0.005)].

6.7 Compensation
385
It is interesting to note that this system would become unstable if the
gain were lowered so that ωc ≤0.02 rad/sec, the region in Fig. 6.68 where
the phase of the compensated system is less than −180◦. As mentioned in
Section 6.4, this situation is referred to as a conditionally stable system. A
root locus with respect to K for this and any conditionally stable system
would show the portion of the locus corresponding to very low gains in the
RHP.
The response of the system for a unit step θcom is found from
T (s) = 
com
=
DcG
1 + DcGH
and is shown in Fig. 6.69(a). It exhibits well damped behavior, as should be
expected with a 65◦PM. The response of the system for a step disturbance
torque of Td is found from

Td
=
G
1 + DcGH .
Very low values of disturbance torques exist in space, for example a constant
Td = 0.0175 N-m yields the response shown in Fig. 6.69(b). Note that the
integral control term does eventually drive the error to zero; however, it is
slow due to the presence of a closed-loop pole and zero both in the vicinity
of s = −0.005. They resulted from the integral term 1/TI being located slow
enough to not impact the PM unduly. If the slow disturbance response is
not acceptable, increasing 1/TI will speed up the response; however, it will
also decrease the PM and damping of the system. Alternatively, it would
also be possible to select a lower value of 1/TD, thus giving some extra PM
and allowing for a higher value of 1/TI without sacriﬁcing the desired PM.
Problem 6.63 provides the reader with the opportunity to examine other
design possibilities for this system.
Time (sec)
(Deg)
1.2
(Deg)
1.80
1.60
1.40
1.20
1.00
0.80
0.60
0.40
0.20
0 0
Time (sec)
0
5
10
15
20
25
30
35
40
100 200 300 400 500 600 700 800 900 1000
1.0
0.8
0.6
0.4
0.2
0
(a)
(b)
Figure 6.69
Transient response for PID example: (a) unit step command response; (b) step torque disturbance
response

386
Chapter 6 The Frequency-Response Design Method
The frequency response of T (s) and S(s) for the system are shown in
Fig. 6.70, where
S(s) =
1
1 + DcGH .
When these two curves cross the magnitude 0.707 (−3 db) line, the values
of ωBW and ωDRB are determined as shown in the ﬁgure. The result is that
ωBW = 0.7 rad/sec and ωDRB = 0.3 rad/sec. Most disturbances on satellites
have a periodicitiy at the orbital rate of 0.001 rad/sec. We see from the ﬁgure
that the sensitivity function, S, is approximately 10−5 at that frequency,
which implies a large attenuation of errors. There is decreasing error atten-
uation as the disturbance frequency increases, and there is almost no error
attenuation at the system bandwidth of ≈0.7 rad/sec, as you would expect.
Another guide to the errors on orbit is apparent from Fig. 6.69(b). Here we
see that a step error essentially dies out to zero in approximately 1000 sec
due to the integral control feature. This compares with the orbital period of
100 min, or 6000 sec. Therefore, we see that orbital disturbances will be
heavily attenuated by this controller.
Note from the design process that the bandwidth was limited by the
response characteristics of the sensor, which had a bandwidth of 2 rad/sec.
Therefore, the only way to improve the error characteristics would be to
increase the bandwidth of the sensor. On the other hand, increasing the
bandwidth of the sensor may introduce jitter from the high-frequency sensor
noise. Thus we see one of the classic trade-off dilemmas: the designer has
to make a judgment as to which feature (low errors due to disturbances or
low errors due to sensor noise) is the more important to the overall system
performance.
T
S
Figure 6.70
Frequency responses of
the closed-loop transfer
function,
( jω), and
the sensitivity function,
( jω)
10-3
10-2
-40
-20
-3
0
20
db
10-1
0.7
10-3
10-2
v (rad/sec)
10 -1
100
0.3
0.7
100
101
Magnitude
vDRB
T (jv)
S(jv)
vBW

6.7 Compensation
387
1. PD control adds phase lead at all frequencies above the break point.
If there is no change in gain on the low-frequency asymptote, PD
compensation will increase the crossover frequency and the speed
of response. The increase in magnitude of the frequency response
at the higher frequencies will increase the system's sensitivity to
noise.
2. Leadcompensationaddsphaseleadatafrequencybandbetweenthe
twobreakpoints, whichareusuallyselectedtobracketthecrossover
frequency. Ifthereisnochangeingainonthelow-frequencyasymp-
tote, lead compensation will increase both the crossover frequency
and the speed of response over the uncompensated system.
3. PI control increases the frequency-response magnitude at frequen-
cies below the break point, thereby decreasing steady-state errors.
It also contributes phase lag below the break point, which must
be kept at a low enough frequency to avoid degrading the stability
excessively.
4. Lag compensation increases the frequency-response magnitude at
frequencies below the two break points, thereby decreasing steady-
state errors. Alternatively, with suitable adjustments in K, lag
compensation can be used to decrease the frequency-response mag-
nitude at frequencies above the two break points, so that ωc yields
an acceptable PM. Lag compensation also contributes phase lag
betweenthetwobreakpoints, whichmustbekeptatfrequencieslow
enough to keep the phase decrease from degrading the PM exces-
sively. This compensation will typically provide a slower response
than using lead compensation.
6.7.6
Design Considerations
We have seen in the preceding designs that characteristics of the open-loop
Summary of
Compensation
Characteristics
Bode plot of the loop gain, L(s) (= KDcG), determine performance with
respect to steady-state errors, low-frequency errors, and dynamic response
including stability margins. Other properties of feedback, developed in
Chapter4, includereducingtheeffectsofsensornoiseandparameterchanges
on the performance of the system.
The consideration of steady-state errors or low-frequency errors due to
command inputs and disturbances has been an important design component
in the different design methods presented. Design for acceptable errors due
to command inputs and disturbances can be thought of as placing a lower
bound on the low-frequency gain of the open-loop system. Another aspect of
the sensitivity issue concerns the high-frequency portion of the system. So
far, Chapter 4 and Sections 5.4 and 6.7 have brieﬂy discussed the idea that, to
alleviate the effects of sensor noise, the gain of the system at high frequencies
must be kept low. In fact, in the development of lead compensation, we added
a pole to pure derivative control speciﬁcally to reduce the effects of sensor

388
Chapter 6 The Frequency-Response Design Method
noise at the higher frequencies. It is not unusual for designers to place an
extra pole in the compensation, that is, to use the relation
Dc(s) =
TDs + 1
(αTDs + 1)2 ,
in order to introduce even more attenuation for noise reduction.
A second consideration affecting high-frequency gains is that many
systems have high-frequency dynamic phenomena, such as mechanical
resonances, that could have an impact on the stability of a system. In very-
high-performance designs, these high-frequency dynamics are included in
the plant model, and a compensator is designed with a speciﬁc knowledge
of those dynamics. A standard approach to designing for unknown high-
frequency dynamics is to keep the high-frequency gain low, just as we did
for sensor-noise reduction. The reason for this can be seen from the gain-
frequency relationship of a typical system, shown in Fig. 6.71. The only
way instability can result from high-frequency dynamics is if an unknown
high-frequency resonance causes the magnitude to rise above 1. Conversely,
if all unknown high-frequency phenomena are guaranteed to remain below
a magnitude of 1, stability can be guaranteed. The likelihood of an unknown
resonance in the plant G rising above 1 can be reduced if the nominal high-
frequency loop gain (L) is lowered by the addition of extra poles in Dc(s).
When the stability of a system with resonances is assured by tailoring the
high-frequency magnitude never to exceed 1, we refer to this process as
amplitude or gain stabilization. Of course, if the resonance characteristics
Gain stabilization
are known exactly, a specially tailored compensation, such as one with a
notch at the resonant frequency, can be used to change the phase at a speciﬁc
frequency to avoid encirclements of −1, thus stabilizing the system even
though the amplitude does exceed magnitude 1. This method of stabiliza-
tion is referred to as phase stabilization. A drawback to phase stabilization
Phase stabilization
is that the resonance information is often not available with adequate preci-
sion or varies with time; therefore, the method is more susceptible to errors
in the plant model used in the design. Thus, we see that sensitivity to plant
uncertainty and sensor noise are both reduced by sufﬁciently low loop gain
at high-frequency.
Figure 6.71
Effect of high-frequency
plant uncertainty
v
High frequency
vc
ƒL(s)ƒ
1

6.7 Compensation
389
These two aspects of sensitivity—high- and low-frequency behavior—
can be depicted graphically, as shown in Fig. 6.72. There is a minimum low-
frequencygainallowableforacceptablesteady-stateandlow-frequencyerror
performance and a maximum high-frequency gain allowable for acceptable
noise performance and for low probability of instabilities caused by plant-
modeling errors. We deﬁne the low-frequency lower bound on the frequency
response as W1 and the upper bound as W−1
2 , as shown in the ﬁgure. Between
these two bounds the control engineer must achieve a gain crossover near
the required bandwidth; as we have seen, the crossover must occur at a slope
of −1 or slightly steeper for good PM and hence damping.
For example, if a control system was required to follow a sinusoidal
reference input with frequencies from 0 to ω1 with errors no greater than
1%, the function W1 would be 100 from ω = 0 to ω1. Similar ideas enter
into deﬁning possible values for the W−1
2
function which would constrain
the open-loop gain to be below W−1
2
for frequencies above ω2. These ideas
will be discussed further in the following subsections.
6.7.7
Speciﬁcations in Terms of the Sensitivity Function
We have seen how the gain and phase margins give useful information about
△
therelativestabilityofnominalsystemsandcanbeusedtoguidethedesignof
lead and lag compensations. However, the GM and PM are only two numbers
and have limitations as guides to the design of realistic control problems. We
can express more complete design speciﬁcations in the frequency domain
if we ﬁrst give frequency descriptions for the external signals, such as the
reference and disturbance, and consider the sensitivity function deﬁned in
Section 4.1. For example, we have so far described dynamic performance by
the transient response to simple steps and ramps.A more realistic description
of the actual complex input signals is to represent them as random processes
with corresponding frequency power density spectra. A less sophisticated
Figure 6.72
Design criteria for low
sensitivity
v
vc
Steady-state
error boundary
Sensor noise and plant
uncertainty boundary
W1
W
Magnitude of L(s)
1
2
-1

390
Chapter 6 The Frequency-Response Design Method
description, which is adequate for our purposes, is to assume that the signals
can be represented as a sum of sinusoids with frequencies in a speciﬁed
range. For example, we can usually describe the frequency content of the
reference input as a sum of sinusoids with relative amplitudes given by a
magnitude function |R| such as that plotted in Fig. 6.73, which represents a
signal with sinusoidal components having about the same amplitudes up to
some value ω1 and very small amplitudes for frequencies above that. With
this assumption, the response tracking speciﬁcation can be expressed by a
statement such as "the magnitude of the system error is to be less than the
bound eb (a value such as 0.01) for any sinusoid of frequency ωo in the
range 0 ≤ωo ≤ω1 with amplitude given by |R( jωo)|." To express such a
performance requirement in terms that can be used in design, we consider
again the unity-feedback system drawn in Fig. 6.74. For this system, the
error is given by
E( jω) =
1
1 + DcGR = S( jω)R,
(6.50)
Figure 6.73
Plot of typical reference
spectrum
10-2
10-1
100
101
102
v (rad/sec)
ƒRƒ
db
10-1
100
101
102
103
-20
0
20
40
60
W1
Figure 6.74
Closed-loop block
diagram
©
 - 
 + 
©
 + 
 + 
R
Y
E
U
Dc
G
©
 + 
 + 
W
V

6.7 Compensation
391
where we have used the sensitivity function
Sensitivity function
S =
1
1 + DcG.
(6.51)
In addition to being the factor multiplying the system error, the sensitivity
function is also the reciprocal of the distance of the Nyquist curve, DcG, from
the critical point −1. A large value for S indicates a Nyquist plot that comes
closetothepointofinstability. Thefrequency-basederrorspeciﬁcationbased
on Eq. (6.50) can be expressed as |E| = |S| |R| ≤eb. In order to normalize
the problem without needing to deﬁne both the spectrum R and the error
bound each time, we deﬁne the real function of frequency W1(ω) = |R| /eb
and the requirement can be written as
|S|W1 ≤1.
(6.52)
EXAMPLE 6.21
Performance Bound Function
Aunity-feedbacksystemistohaveanerrorlessthan0.005forallunityampli-
tude sinusoids below frequency 100 Hertz. Draw the performance frequency
function W1(ω) for this design.
Solution.
The spectrum, from the problem description, is unity for 0 ≤
ω ≤200π rad/sec. Because eb = 0.005, the required function is given by a
rectangle of amplitude 1/0.005 = 200 over the given range. The function
is plotted in Fig. 6.75.
Figure 6.75
Plot of example
performance function,
W1
101
102
103
104
v (rad/sec)
ƒW1ƒ
db
10-2
100
10-1
101
102
103
-40
0
-20
20
40
60

392
Chapter 6 The Frequency-Response Design Method
The expression in Eq. (6.52) can be translated to the more familiar Bode
plot coordinates and given as a requirement on loop gain by observing that
over the frequency range when errors are small the loop gain is large. In that
case |S| ≈1/|DcG|, and the requirement is approximately
W1
|DcG| ≤1,
|DcG| ≥W1.
(6.53)
This requirement can be seen as an extension of the steady-state error
requirement from just ω = 0 to the range 0 ≤ωo ≤ω1.
In addition to the requirement on dynamic performance, the designer is
usually required to design for stability robustness. By this we mean that,
Stability robustness
while the design is done for a nominal plant transfer function, the actual
system is expected to be stable for an entire class of transfer functions that
represents the range of changes that are expected to be faced as temperature,
age, and other operational and environmental factors vary the plant dynamics
from the nominal case. A realistic way to express this uncertainty is to
describe the plant transfer function as having a multiplicative uncertainty:
G( jω) = Go( jω)[1 + W2(ω)△( jω)].
(6.54)
In Eq. (6.54), the real function W2 is a magnitude function that expresses
the size of changes as a function of frequency that the transfer function is
expected to experience. In terms of G and Go, the expression is
W2 =

G −Go
Go
 .
(6.55)
The shape of W2 is almost always very small for low frequencies (we know
the model very well there) and increases substantially as we go to higher
frequencies, where parasitic parameters of unmodeled structural ﬂexibility
is common. A typical shape is sketched in Fig. 6.76. The complex function,
△( jω), represents the uncertainty in phase and is restricted only by the
constraint
0 ≤|△| ≤1.
(6.56)
We assume that the nominal design has been done and is stable, so that the
Nyquist plot of DcGo satisﬁes the Nyquist stability criterion. In this case,
the nominal characteristic equation 1 + DcGo = 0 is never satisﬁed for any
real frequency. If the system is to have stability robustness, the characteristic
equation using the uncertain plant as described by Eq. (6.54) must not go
to zero for any real frequency for any value of △. The requirement can be
written as
1 + DcG ̸= 0,
(6.57)
1 + DcGo[1 + W2△] ̸= 0,
(1 + DcGo)(1 + T W2△) ̸= 0,

6.7 Compensation
393
Figure 6.76
Plot of typical plant
uncertainty, W2
10-2
10-1
100
101
102
v (rad/sec)
ƒW2ƒ
db
10-2
100
10-1
101
102
103
-40
0
-20
20
40
60
where we have deﬁned the complementary sensitivity function as
Complementary sensitivity
function
T ( jω) = DcGo/(1 + DcGo) = 1 −S.
(6.58)
Because the nominal system is stable, the ﬁrst term in Eq. (6.57), (1+DcGo),
is never zero. Thus, if Eq. (6.57) is not to be zero for any frequency and any
△, then it is necessary and sufﬁcient that
|T W2△| < 1,
which reduces to
|T | W2 < 1,
(6.59)
making use of Eq. (6.56). As with the performance speciﬁcation, for
single-input-single-output unity-feedback systems this requirement can be
approximated by a more convenient form. Over the range of high frequencies
where W2 is non-negligible because there is signiﬁcant model uncertainty,
DcGo is small. Therefore we can approximate T ≈DcGo, and the constraint
reduces to
|DcGo| W2 < 1,
|DcGo| <
1
W2 .
(6.60)
The robustness issue is important to design and can affect the high-
frequency open-loop frequency response, as discussed above. However, as
discussed earlier, it is also important to limit the high-frequency magnitude
in order to attenuate noise effects.

394
Chapter 6 The Frequency-Response Design Method
EXAMPLE 6.22
Typical Plant Uncertainty
The uncertainty in a plant model is described by a function W2 that is zero
untilω = 3000, increaseslinearlyfromtheretoavalueof100atω = 10,000,
and remains at 100 for higher frequencies. Plot the constraint on DcGo to
meet this requirement.
Solution. Where W2 = 0, there is no constraint on the magnitude of loop
gain; above ω = 3000, 1/W2 = DcGo is a hyperbola from ∞to 0.01 at
ω = 10,000 and remains at 0.01 for ω > 10,000. The bound is sketched in
Fig. 6.77.
In practice, the magnitude of the loop gain is plotted on log-log (Bode)
coordinates, and the constraints of Eqs. (6.53) and (6.60) are included on the
same plot. A typical sketch is drawn in Fig. 6.72. The designer is expected
to construct a loop gain that will stay above W1 for frequencies below ω1,
cross over the magnitude 1 line (|DcG| = 0) in the range ω1 ≤ω ≤ω2, and
stay below 1/W2 for frequencies above ω2.
6.7.8
Limitations on Design in Terms of the Sensitivity
Function
One of the major contributions of Bode was to derive important limitations
△
on transfer functions that set limits on achievable design speciﬁcations. For
Figure 6.77
Plot of constraint on
|DcGo|(= |W−1
2 |)
102
103
104
105
v (rad/sec)
db
10-2
100
10-1
101
102
-40
0
-20
20
40
ƒDG0ƒ constraint

6.7 Compensation
395
example, one would like to have the system error kept small for the widest
possible range of frequencies and yet have a system that is robustly stable
for a very uncertain plant. In terms of the plot in Fig. 6.78, we want W1
and W2 to be very large in their respective frequency ranges and for ω1 to
be pushed up close to ω2. Thus the loop gain is expected to plunge with a
large negative slope from being greater than W1 to being less than 1/W2 in
a very short span, while maintaining a good PM to assure stability and good
dynamic performance. The Bode gain-phase formula given earlier shows
that this is impossible with a linear controller, by showing that the minimum
possible phase is determined by an integral depending on the slope of the
magnitude curve. If the slope is constant for a substantial range around ωo,
then Eq. (6.34) can be approximated by
φ(ωo) ≈π
2
dM
du

u=0
,
(6.61)
where M is the log magnitude and u = log ω/ωo. If, for example, the phase
is to be kept above −150◦to maintain a 30◦PM, then the magnitude slope
near ωo is estimated to be
dM
du ≈2
π

−150 π
180
	
≈−1.667.
If we try to make the average slope steeper (more negative) than this, we
will lose the PM. From this condition, the design rule was developed that the
asymptotes of the Bode plot magnitude, which are restricted to be integral
Figure 6.78
Tracking and stability
robustness constraints
on the Bode plot; an
example of impossible
constraints
10-2
100
102
104
v (rad/sec)
db
10-2
100
10-1
101
102
-40
0
-20
20
40
Loop gain constraint
W1
W2
-1
v1
v2

396
Chapter 6 The Frequency-Response Design Method
values for rational functions, should be made to cross over the zero-db line
at a slope of −1 over a frequency range of about one decade around the
crossover frequency, as already discussed in Section 6.5. Modiﬁcations to
this rule need to be made in particular cases, of course, but the limitation
implied by Eq. (6.61) is a hard limit that cannot be avoided. Thus, it is clear
that it would be impossible to stabilize the system of Fig. 6.78.
EXAMPLE 6.23
Robustness Constraints
If W1 = W2 = 100, and we want PM = 30◦, what is the minimum ratio of
ω2/ω1?
Solution. The slope is
log W1 −log 1
W2
log ω1 −log ω2
= 2 + 2
log ω1
ω2
= −1.667.
Thus, the log of the ratio is log ω1/ω2 = −2.40 and ω2 = 251ω1.
An alternative to the standard Bode plot as a design guide can be based
on a plot of the sensitivity function as a function of frequency. In this for-
mat, Eq. (6.52) requires that |S| <
1
W1 over the range 0 ≤ω ≤ω1 for
performance, and Eq. (6.60) requires that |S| ≈1 over the range ω2 ≤ω
for stability robustness. It should come as no surprise that Bode found a
limitation on the possibilities in this case, too. The constraint, extended by
Freudenberg and Looze (1985), shows that an integral of the sensitivity func-
tion is determined by the presence of poles in the RHP. Suppose the loop
gain DcGo has np poles, pi, in the RHP and "rolls off" at high frequencies
at a slope faster than −1. For rational functions, this means that there is an
excess of at least two more ﬁnite poles than zeros. Then it can be shown that
 ∞
0
ln(|S|) dω = π
np

i=1
Re{pi}.
(6.62)
IftherearenoRHPpoles, thentheintegraliszero. Thismeansthatifwemake
the log of the sensitivity function very negative over some frequency band
to reduce errors in that band, then, of necessity, ln |S| will be positive over
anotherpartoftheband, anderrorswillbeampliﬁedthere. Thischaracteristic
is sometimes referred to as the "water bed effect." If there are unstable poles,
Water bed effect
the situation is worse, because the positive area where sensitivity magniﬁes
the error must exceed the negative area where the error is reduced by the
feedback. If the system is minimum phase, then it is, in principle, possible
to keep the magnitude of the sensitivity small by spreading the sensitivity
increase over all positive frequencies to inﬁnity, but such a design requires
an excessive bandwidth and is rarely practical. If a speciﬁc bandwidth is
imposed, then the sensitivity function is constrained to take on a ﬁnite,
possibly large, positive value at some point below the bandwidth.As implied

6.7 Compensation
397
by the deﬁnition of the vector margin (VM) in Section 6.4 (Fig. 6.38), a large
Vector margin
Smax corresponds to a Nyquist plot that comes close to the −1 critical point
and a system having a small vector margin, because
VM =
1
Smax
.
(6.63)
If the system is not minimum-phase, the situation is worse. An alterna-
tive to Eq. (6.62) is true if there is a nonminimum-phase zero of DcGo, a
zero in the RHP. Suppose that the zero is located at zo = σo + jωo, where
σo > 0. Again, we assume there are np RHP poles at locations pi with conju-
gate values pi. Now the condition can be expressed as a two-sided weighted
integral
 ∞
−∞
ln(|S|)
σo
σ 2o + (ω −ωo)2 dω = π
np

i=1
ln

pi + zo
pi −zo
 .
(6.64)
In this case, we do not have the "roll-off" restriction, and there is no pos-
sibility of spreading the positive area over high frequencies, because the
weighting function goes to zero with frequency. The important point about
this integral is that if the nonminimum-phase zero is close to a RHP pole, the
right side of the integral can be very large, and the excess of positive area is
required to be correspondingly large. Based on this result, one expects espe-
cially great difﬁculty meeting both tracking and robustness speciﬁcations on
sensitivity with a system having RHP poles and zeros close together.
EXAMPLE 6.24
Sensitivity Function for Antenna
Compute and plot the sensitivity function for the design of the antenna for
which G(s) = 1/s(s + 1) and Dc(s) = 10(0.5s + 1)/(0.1s + 1).
Solution. The sensitivity function for this case is
S =
s(s + 1)(s + 10)
s3 + 11s2 + 60s + 100,
(6.65)
and the plot shown in Fig. 6.79 is given by the Matlab commands
s = tf('s');
sysS = s*(s + 1)*(s + 10)/(sˆ3 + 11*sˆ2 + 60*s + 100);
[mag,ph,w] = bode(sysS);
loglog(w,squeeze(mag)),grid
The largest value of S is given by M = max(mag) and is 1.366, from
which the vector margin is VM = 0.732.

398
Chapter 6 The Frequency-Response Design Method
Figure 6.79
Sensitivity function for
Example 6.24
v (rad/sec)
|S|
100
101
10−1
10−1
101
102
100
10−2
6.8
Time Delay
The Laplace transform of a pure time delay is GD(s) = e−sTd, which can
△
be approximated by a rational function (Padé approximate) as shown in
Appendix W5.6.3. Although this same approximation could be used with
frequency-response methods, an exact analysis of the delay is possible.
The frequency response of the delay is given by the magnitude and phase
of e−sTd|s=jω. The magnitude is
Time-delay magnitude
|GD( jω)| = |e−jωTd| = 1,
for all ω.
(6.66)
This result is expected, because a time delay merely shifts the signal in time
Time-delay phase
and has no effect on its magnitude. The phase is
∠GD( jω) = −ωTd
(6.67)
in radians, and it grows increasingly negative in proportion to the frequency.
This, too, is expected, because a ﬁxed time delay Td becomes a larger fraction
or multiple of a sine wave as the period drops, due to increasing frequency.
A plot of ∠GD( jω) is drawn in Fig. 6.80. Note that the phase lag is greater
than 270◦for values of ωTd greater than about 5 rad. This trend implies
that it would be virtually impossible to stabilize a system (or to achieve a
positive PM) with a crossover frequency greater than ω = 5/Td, and it would
be difﬁcult for frequencies greater than ω ∼= 3/Td. These characteristics
essentially place a constraint on the achievable bandwidth of any system
with a time delay. (See Problem 6.64 for an illustration of this constraint.)
The frequency domain concepts such as the Nyquist criterion apply
directly to systems with pure time delay. This means that no approximations
(Padé type or otherwise) are needed and the exact effect of time delay can
be applied to a Bode plot, as shown in the following example.

6.8 Time Delay
399
Figure 6.80
Phase lag due to pure
time delay
vTd (rad)
0.01
0.1
1
10
100 1000
05
-905
-1805
-2705
-3605
-4505
-5405
-6305
-7205
jGD(jv)
EXAMPLE 6.25
Effect of Sampling on Stability
When implementing a control system with a digital computer to create com-
pensation, the output of the plant is sampled periodically, used for computer
calculations, then output as the control at the same sample rate. The effect
of this is to create a delay that, on average, is half the sample period, Ts.
Determine the effect on the PM in Example 6.15 if it were implemented with
a digital controller with a sample period of Ts = 0.05 sec and estimate what
that would do to the step response overshoot. How slowly could you sample
if it was necessary to limit the decrease in the PM to less than 20◦?
Solution. A sample period of Ts = 0.05 sec will inject a time delay of
Ts/2 = 0.05/2 = 0.025 = Td sec. From Eq. (6.67), we see that the phase
lag due to this sampling at Example 6.15's crossover frequency of 5 rad/sec,
where we measure the PM, is ∠GD = −ωTd = −(5)(0.025) = −0.125 rad
= −7◦. Therefore, the PM will decrease from 53◦for the continuous imple-
mentation to approximately 46◦for the digital implementation. Figure 6.37
shows that the overshoot, Mp, will be degraded from ≈16% to ≈22%. This
is a very approximate analysis, but gives a rough idea of what to expect when
implementing a controller via sampling and a digital computer.
In order to limit the phase lag to 20◦at ω = 5 rad/sec, we see from
Eq.(6.67) that the maximum tolerable Td = 20/(5 ∗57.3) = 0.07 sec, so
that the slowest sampling acceptable would be Ts = 0.14 sec. Note, however,
that this large decrease in the PM would result in the overshoot increasing
from ≈20% to ≈40%.
The example illustrates that a time delay, whether introduced by digital
sampling or by any other source, has a very severe effect on the achievable
bandwidth. Evaluation of the effect using Eq. (6.67) or Fig. 6.80 is simple
and straightforward, thus giving a quick analysis of the limitations imposed
by any delay in the system.

400
Chapter 6 The Frequency-Response Design Method
6.8.1
Time Delay via the Nyquist Diagram
One can also evaluate the effect of a time delay using a Nyquist diagram,
and this is shown in Appendix W6.8.1 available at www.FPE7e.com.
6.9
Alternative Presentation of Data
Other ways to present frequency-response data have been developed to aid
△
both in understanding design issues and in easing the designer's work load.
Their use in easing the work load has largely been eliminated with the com-
mon use of computer-aided design; however, one technique that continues to
be widely used in the design process is the Nichols chart. For those interested,
we also present the inverse Nyquist method in Appendix W6.9.2
6.9.1
Nichols Chart
A rectangular plot of log |G( jω)| versus ∠G( jω) can be drawn by simply
transferring the information directly from the separate magnitude and phase
portions in a Bode plot; one point on the new curve thus results from a given
value of the frequency ω. This means that the new curve is parameterized as
a function of frequency. As with the Bode plots, the magnitude information
is plotted on a logarithmic scale, while the phase information is plotted on
a linear scale. This template was suggested by N. Nichols and is usually
referred to as a Nichols chart. The idea of plotting the magnitude of G( jω)
versus its phase is similar to the concept of plotting the real and imaginary
parts of G( jω), which formed the basis for the Nyquist plots shown in
Sections 6.3 and 6.4. However, it is difﬁcult to capture all the pertinent
characteristics of G( jω) on the linear scale of the Nyquist plot. The log
scale for magnitude in the Nichols chart alleviates this difﬁculty, allowing
this kind of presentation to be useful for design.
For any value of the complex transfer function G( jω), Section 6.6
showed that there is a unique mapping to the unity-feedback closed-loop
transfer function
T ( jω) =
G( jω)
1 + G( jω),
(6.68)
or in polar form,
T ( jω) = M(ω)e jα(ω),
(6.69)
where M(ω) is the magnitude of the closed-loop transfer function and α(ω)
is the phase of the closed-loop transfer function. Speciﬁcally, let us deﬁne
M and N such that
M =

G
1 + G
 ,
(6.70)
α = tan−1(N) = ∠
G
1 + G.
(6.71)
It can be proven that the contours of constant closed-loop magnitude
and phase are circles when G( jω) is presented in the linear Nyquist plot.
These circles are referred to as the M and N circles, respectively.
M and N circles

6.9 Alternative Presentation of Data
401
0.1-1805
-1605
-1405
-1205
-1005
-805
-605
-405
j Dc(s)G(s)
0.10
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
10
9
8
7
6
5
4
3
2
ƒDc(s)G(s)ƒ
5.0
2.0
1.50
1.30
1.20
1.10
1.05
1.00
0.95
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.15
-15
-25
-55
-105
-305
-55
-205
Closed-
loop
magnitude
Closed-
loop
phase
Figure 6.81
Nichols chart
The Nichols chart also contains contours of constant closed-loop magni-
tude and phase based on these relationships, as shown in Fig. 6.81; however,
they are no longer circles, because the Nichols charts are semilog plots of
magnitude versus linear phase. A designer can therefore graphically deter-
mine the bandwidth of a closed-loop system from the plot of the open-loop
data on a Nichols chart by noting where the open-loop curve crosses the 0.70
contour of the closed-loop magnitude and determining the frequency of the
corresponding data point. Likewise, a designer can determine the resonant-
peak amplitude Mr by noting the value of the magnitude of the highest
closed-loop contour tangent to the curve. The frequency associated with the
magnitude and phase at the point of tangency is sometimes referred to as
the resonant frequency ωr. Similarly, a designer can determine the GM by
Resonant frequency
observing the value of the gain where the Nichols plot crosses the −180◦
line, and the PM by observing the phase where the plot crosses the amplitude

402
Chapter 6 The Frequency-Response Design Method
1 line.16 Matlab provides for easy drawing of a Nichols chart via the nichols
m-ﬁle.
EXAMPLE 6.26
Nichols Chart for PID Example
Determine the a) bandwidth, b) resonant-peak magnitude, and c) PM of the
compensated system whose frequency response is shown in Fig. 6.68.
Solution.
The open-loop magnitude and phase information of the com-
pensated design example seen in Fig. 6.68 is shown on a Nichols chart in
Fig. 6.82. When comparing the two ﬁgures, it is important to divide the mag-
nitudes in Fig. 6.68 by a factor of 20 in order to obtain |Dc(s)G(s)| rather
than the normalized values used in Fig. 6.68. Because the curve crosses the
0.1
-1805
-1605
-1405
-1205
-1005
-805
-605
-405
j Dc(s)G(s)
0.10
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
10
9
8
7
6
5
4
3
2
ƒDc(s)G(s)ƒ
5.0
2.0
1.50
1.30
1.20
1.10
1.05
1.00
0.95
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.15
-15
-25
-55
-105
-305
-55
-205
Closed-
loop
magnitude
Closed-
loop
phase
Mr
v = 2 rad/sec
v = 0.1 rad/sec
BW
PM = 645
v = 0.8 rad/sec
v = 0.5 rad/sec
v = 1 rad/sec
Figure 6.82
Nichols chart for determining bandwidth, Mr, and PM for Example 6.26
16James, H. M., N. B. Nichols, and R. S. Phillips (1947).

6.9 Alternative Presentation of Data
403
closed-loop magnitude 0.70 contour at ω = 0.8 rad/sec, we see that the band-
width of this system is 0.8 rad/sec. The PM is determined by the phase when
the curve crosses the magnitude = 1 line. Because the largest-magnitude
contour touched by the curve is 1.20, we also see that Mr = 1.2.
EXAMPLE 6.27
Stability Margins from Nichols Chart for Complex System
For the system of Example 6.13, whose Nyquist plot is shown in Fig. 6.41,
determinethePMandGMusingtheNicholsplot. Commentonwhichmargin
is the more critical.
Solution. Figure 6.83 shows a Nichols chart with frequency-response data
from Fig. 6.42. Note that the PM for the magnitude 1 crossover frequency
0.1
-1805
-1605
-1405
-1205
-1005
-805
-605
-405
j Dc(s)G(s)
0.10
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
10
9
8
7
6
5
4
3
2
ƒDc(s)G(s)ƒ
5.0
2.0
1.50
1.30
1.20
1.10
1.05
1.00
0.95
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.15
-15
-55
-105
-55
-205
Closed-
loop
magnitude
Closed-
loop
phase
-305
-25
Figure 6.83
Nichols chart of the complex system in Examples 6.13 and 6.27

404
Chapter 6 The Frequency-Response Design Method
is 36◦and the GM is 1.25 (= 1/0.8). It is clear from this presentation
of the data that the most critical portion of the curve is where it crosses
the −180◦line; hence the GM is the most relevant stability margin in this
example.
For complex systems for which the −1 encirclements need to be eval-
uated, the magnitude log scale of the Nichols chart enables us to examine a
wider range of frequencies than a Nyquist plot does, as well as allowing us
to read the gain and phase margins directly. Although Matlab will directly
compute PM and GM, the algorithm may lead to suspicious results for very
complex cases and the analyst may want to verify the result using the Matlab
nichols m-ﬁle so the actual encirclements can be examined and the bases for
the PM and GM better understood. In some cases, the speciﬁcations for
Exclusion zone for a
stability speciﬁcation
the desired margins are stated in terms of an "exclusion zone" around the
−1 point on the Nichols chart (magnitude =1, phase = −180◦). The zone
is typically an ellipse or similar shape with the vertical and horizontal axes
limits given. To satisfy the speciﬁcation, the frequency-response data on
the Nichols chart must not pierce any portion of the ellipse; thus, this sort
of stability margin requirement is similar to the vector margin described in
Section 6.7.8
Historically, the Nichols chart was used to aid the design process when
done without beneﬁt of a computer. A change in gain, for example, can be
evaluated by sliding the curve vertically on transparent paper over a standard
Nichols chart as shown in Fig. 6.81. The GM, PM, and bandwidth were
then easy to read off the chart, thus allowing evaluations of several values
of gain with a minimal amount of effort. With access to computer-aided
methods, however, we can now calculate the bandwidth and perform many
repetitive evaluations of the gain or any other parameter with a few key
strokes. Some modern design techniques, such as the Quantitative Feedback
Theory ("QFT," Horowitz and Sidi, 1992) still heavily rely on the Nichols
chart as the central tool to guide the feedback design.
6.9.2
The Inverse Nyquist Diagram
The inverse Nyquist diagram simpliﬁes a determination of the stability mar-
gins and has been used in the past. It is described in more detail in Appendix
W6.9.2 available at www.FPE7e.com.
6.10
Historical Perspective
As discussed in Chapter 5, engineers before 1960s did not have access to
computers to help in their analyses. Therefore, any method that allowed
the determination of stability or response characteristics that did not require
factoring the characteristic equation was highly useful. The invention of the

Summary
405
electronic feedback ampliﬁer by H. S. Black in 1927 at Bell Telephone Lab-
oratories provided extra incentive to develop methods for feedback control
design and the development of the frequency-response method was the ﬁrst
that enabled design iteration for this purpose.
The development of the feedback ampliﬁer is brieﬂy described in an
interesting article based on a talk by Hendrik W. Bode (1960) reproduced
in Bellman and Kalaba (1964). With the introduction of electronic ampli-
ﬁers, long-distance telephoning became possible in the decades following
World War I. However, as distances increased, so did the loss of electrical
energy; in spite of using larger-diameter wire, increasing numbers of ampli-
ﬁers were needed to replace the lost energy. Unfortunately, large numbers
of ampliﬁers resulted in much distortion since the small nonlinearity of the
vacuum tubes then used in electronic ampliﬁers was multiplied many times.
To solve the problem of reducing distortion, Black proposed the feedback
ampliﬁer. As discussed earlier in Chapter 4, the more we wish to reduce
errors (or distortion), the higher the feedback needs to be. The loop gain
from actuator to plant to sensor to actuator must be made very large. But
the designers found that too high a gain produced a squeal and the feedback
loop became unstable. In this technology the dynamics were so complex
(with differential equations of order 50 being common) that Routh's crite-
rion, the only way of solving for stability at the time, was not very helpful.
So the communications engineers at Bell Telephone Laboratories, familiar
with the concept of frequency response and the mathematics of complex
variables, turned to complex analysis. In 1932 H. Nyquist published a paper
describing how to determine stability from a graphical plot of the open-loop
frequency response. Bode then developed his plotting methods in 1938 that
made them easy to create without extensive calculations or help from a com-
puter. From the plotting methods and Nyquist's stability theory, an extensive
methodology of feedback ampliﬁer design was developed by Bode (1945)
and extensively used still in the design of feedback controls. The reasons for
using the method today are primarily to allow for a good design no matter
what the unmodeled dynamics are, to expedite the design process even when
carried out with a computer that is fully capable of solving the characteristic
equation, and to provide a visual tool to examine the design. After devel-
oping the frequency-response design methods prior to World War II, Bode
went on to help in electronic ﬁre control devices during the war. The methods
that he had developed for feedback ampliﬁers proved highly applicable to
servomechanisms for the effort. Bode characterized this crossover of control
system design methods as being a "sort of shotgun marriage."
SUMMARY
•
The frequency-response Bode plot is a graph of the transfer function
magnitude in logarithmic scale and the phase in linear scale versus
frequency in logarithmic scale. For a transfer function G(s),

406
Chapter 6 The Frequency-Response Design Method
M = |G( jω)| = |G(s)|s=jω
=

{Re[G( jω)]}2 + {Im[G( jω)]}2
φ = tan−1
Im[G( jω)]
Re[G( jω)]

= ∠G( jω).
•
For a transfer function in Bode form,
KG(ω) = K0(jω)n ( jωτ1 + 1)( jωτ2 + 1) · · ·
( jωτa + 1)( jωτb + 1) · · ·,
the Bode frequency response can be easily plotted by hand using the
rules described in Section 6.1.1.
•
Bode plots can be obtained using computer algorithms (bode in Matlab),
but hand-plotting skills are still extremely helpful.
•
For a second-order system, the peak magnitude of the Bode plot is
related to the damping by
|G( jω)| = 1
2ζ
at ω = ωn.
•
A method of determining the stability of a closed-loop system based
on the frequency response of the system's open-loop transfer function
is the Nyquist stability criterion. Rules for plotting the Nyquist plot
are described in Section 6.3. The number of RHP closed-loop roots is
given by
Z = N + P,
where
N = number of clockwise encirclements of the −1 point,
P = number of open-loop poles in the RHP.
For a stable closed-loop system, Z must be 0, resulting in N = −P.
•
The Nyquist plot may be obtained using computer algorithms (nyquist
in Matlab).
•
The gain margin (GM) and phase margin (PM) can be determined
directly by inspecting the open-loop Bode plot or the Nyquist plot.
Also, use of Matlab's margin function determines the values directly.
•
For a standard second-order system, the PM is related to the closed-loop
damping by Eq. (6.32),
ζ ∼= PM
100.
•
The bandwidth of the system is a measure of speed of response. For
control systems, it is deﬁned as the frequency corresponding to 0.707
(−3 db) in the closed-loop magnitude Bode plot and is approximately
given by the crossover frequency ωc, which is the frequency at which
the open-loop gain curve crosses magnitude 1.
•
The vector margin is a single-parameter stability margin based on the
closest point of the Nyquist plot of the open-loop transfer function to
the critical point −1/K.

Summary
407
•
For a stable minimum-phase system, Bode's gain-phase relationship
uniquely relates the phase to the gain of the system and is approximated
by Eq. (6.33),
∠G( jω) ∼= n × 90◦,
wherenistheslopeof|G( jω)|inunitsofdecadeofamplitudeperdecade
of frequency. The relationship shows that, in most cases, stability is
ensured if the gain plot crosses the magnitude 1 line with a slope of −1.
•
Experimental frequency-response data of the open-loop system can be
used directly for analysis and design of a closed-loop control system
with no analytical model.
•
For the system shown in Fig. 6.84, the open-loop Bode plot is the fre-
quency response of GDc, and the closed-loop frequency response is
obtained from T (s) = GDc/(1 + GDc).
Figure 6.84
Typical system
©
-
+
R
Y
Dc
G
E
•
Thefrequency-responsecharacteristicsofseveraltypesofcompensation
have been described, and examples of design using these characteristics
have been discussed. Design procedures were given for lead and lag
compensators in Section 6.7. The examples in that section show the
ease of selecting speciﬁc values of design variables, a result of using
frequency-response methods. A summary was provided at the end of
Section 6.7.5.
•
Lead compensation, given by Eq. (6.38),
Dc(s) = TDs + 1
αTDs + 1,
α < 1,
is a high-pass ﬁlter and approximates PD control. It is used whenever
substantial improvement in damping of the system is required. It tends
to increase the speed of response of a system for a ﬁxed low-frequency
gain.
•
Lag compensation, given by Eq. (6.47),
Dc(s) = α TIs + 1
αTIs + 1,
α > 1,
(6.72)
is a low-pass ﬁlter and approximates PI control. It is usually used to
increase the low-frequency gain of the system so as to improve steady-
state response for ﬁxed bandwidth. For a ﬁxed low-frequency gain, it
will decrease the speed of response of a system.
•
PID compensation can be viewed as a combination of lead and lag
compensation.
•
Tracking-error reduction and disturbance rejection can be speciﬁed in
terms of the low-frequency gain of the Bode plot. Sensor-noise rejection

408
Chapter 6 The Frequency-Response Design Method
can be speciﬁed in terms of high-frequency attenuation of the Bode plot
(see Fig. 6.72).
•
The Nichols plot is an alternate representation of the frequency response
△
as a plot of gain versus phase and is parameterized as a function of
frequency.
•
Time delay can be analyzed exactly in a Bode plot or a Nyquist plot.
△
REVIEW QUESTIONS
6.1
Why did Bode suggest plotting the magnitude of a frequency response on
log-log coordinates?
6.2
Deﬁne a decibel.
6.3
What is the transfer-function magnitude if the gain is listed as 14 db?
6.4
Deﬁne gain crossover.
6.5
Deﬁne phase crossover.
6.6
Deﬁne phase margin, PM.
6.7
Deﬁne gain margin, GM.
6.8
What Bode plot characteristic is the best indicator of the closed-loop step
response overshoot?
6.9
What Bode plot characteristic is the best indicator of the closed-loop step
response rise time?
6.10
What is the principal effect of a lead compensation on Bode plot performance
measures?
6.11
What is the principal effect of a lag compensation on Bode plot performance
measures?
6.12
How do you ﬁnd the Kv of a Type 1 system from its Bode plot?
6.13
Why do we need to know beforehand the number of open-loop unstable poles
in order to tell stability from the Nyquist plot?
6.14
What is the main advantage in control design of counting the encirclements of
−1/K of Dc( jω)G( jω) rather than encirclements of −1 of KDc( jω)G( jω)?
6.15
Deﬁne a conditionally stable feedback system. How can you identify one on
a Bode plot?
6.16
A certain control system is required to follow sinusoids, which may be any
△
frequency in the range 0 ≤ωℓ≤450 rad/sec and have amplitudes up to
5 units, with (sinusoidal) steady-state error to be never more than 0.01. Sketch
(or describe) the corresponding performance function W1(ω).
PROBLEMS
Problems for Section 6.1: Frequency Response
6.1
(a) Show that α0 in Eq. (6.2), with A = Uo and ωo = ω, is
α0 =

G(s) U0ω
s −jω
s=−jω
= −U0G(−jω) 1
2j ,

Problems
409
and
α∗
0 =

G(s) U0ω
s + jω
s=+jω
= U0G( jω) 1
2j .
(b) By assuming the output can be written as
y(t) = α0e−jωt + α∗
0 e jωt,
derive Eqs. (6.4)-(6.6).
6.2
(a) Calculate the magnitude and phase of
G(s) =
1
s + 10
by hand for ω = 1, 2, 5, 10, 20, 50, and 100 rad/sec.
(b) Sketch the asymptotes for G(s) according to the Bode plot rules, and
compare these with your computed results from part (a).
6.3
Sketch the asymptotes of the Bode plot magnitude and phase for each of the
following open-loop transfer functions. After completing the hand sketches,
verify your result using Matlab. Turn in your hand sketches and the Matlab
results on the same scales.
(a) L(s) =
2000
s(s + 200)
(b) L(s) =
100
s(0.1s + 1)(0.5s + 1)
(c) L(s) =
1
s(s + 1)(0.02s + 1)
(d) L(s) =
1
(s + 1)2(s + 10)2
(e) L(s) =
10(s + 4)
s(s + 1)(s + 100)
(f) L(s) =
1000(s + 0.1)
s(s + 1)(s + 8)2
(g) L(s) =
(s + 5)(s + 10)
s(s + 1)(s + 100)
(h) L(s) =
4s(s + 10)
(s + 100)(s + 500)
(i) L(s) =
s
(s + 1)(s + 10)(s + 50)
6.4
Real poles and zeros. Sketch the asymptotes of the Bode plot magnitude and
phase for each of the listed open-loop transfer functions. After completing the
hand sketches, verify your result using Matlab. Turn in your hand sketches
and the Matlab results on the same scales.
(a) L(s) =
1
s(s + 1)(s + 5)(s + 10)
(b) L(s) =
(s + 2)
s(s + 1)(s + 5)(s + 10)
(c) L(s) =
(s + 2)(s + 6)
s(s + 1)(s + 5)(s + 10)
(d) L(s) =
(s + 2)(s + 4)
s(s + 1)(s + 5)(s + 10)
6.5
Complex poles and zeros. Sketch the asymptotes of the Bode plot magnitude
and phase for each of the listed open-loop transfer functions, and approxi-
mate the transition at the second-order break point, based on the value of the

410
Chapter 6 The Frequency-Response Design Method
damping ratio. After completing the hand sketches, verify your result using
Matlab. Turn in your hand sketches and the Matlab results on the same scales.
(a) L(s) =
1
s2 + 3s + 10
(b) L(s) =
1
s(s2 + 3s + 10)
(c) L(s) =
(s2 + 2s + 8)
s(s2 + 2s + 10)
(d) L(s) = (s2 + 1)
s(s2 + 4)
(e) L(s) = (s2 + 4)
s(s2 + 1)
6.6
Multiple poles at the origin. Sketch the asymptotes of the Bode plot magnitude
and phase for each of the listed open-loop transfer functions.After completing
the hand sketches, verify your result with Matlab. Turn in your hand sketches
and the Matlab results on the same scales.
(a) L(s) =
1
s2(s + 10)
(b) L(s) =
1
s3(s + 8)
(c) L(s) =
1
s4(s + 10)
(d) L(s) =
(s + 3)
s2(s + 10)
(e) L(s) =
(s + 3)
s3(s + 5)
(f) L(s) =
(s + 1)2
s3(s + 10)
(g) L(s) =
(s + 1)2
s3(s + 10)2
6.7
Mixed real and complex poles. Sketch the asymptotes of the Bode plot magni-
tude and phase for each of the listed open-loop transfer functions. Embellish
the asymptote plots with a rough estimate of the transitions for each break
point. After completing the hand sketches, verify your result with Matlab.
Turn in your hand sketches and the Matlab results on the same scales.
(a) L(s) =
(s + 2)
s(s + 10)(s2 + 2s + 2)
(b) L(s) =
(s + 2)
s2(s + 10)(s2 + 6s + 25)
(c) L(s) =
(s + 2)2
s2(s + 10)(s2 + 6s + 25)
(d) L(s) =
(s + 2)(s2 + 4s + 68)
s2(s + 10)(s2 + 4s + 85)
(e) L(s) =
[(s + 1)2 + 1]
s2(s + 2)(s + 3)
6.8
Right half-plane poles and zeros. Sketch the asymptotes of the Bode plot
magnitude and phase for each of the listed open-loop transfer functions. Make
sure that the phase asymptotes properly take the RHP singularity into account

Problems
411
by sketching the complex plane to see how the ∠L(s) changes as s goes from 0
to + j∞. After completing the hand sketches, verify your result with Matlab.
Turn in your hand sketches and the Matlab results on the same scales.
(a) L(s) = s + 2
s+10
1
s2−4 (The model for a case of magnetic levitation with lead
compensation)
(b) L(s) =
s + 2
s(s + 10)
1
(s2−1) (The magnetic levitation system with integral
control and lead compensation)
(c) L(s) = s−1
s2
(d) L(s) =
s2 + 2s+1
s(s+20)2(s2−2s+2)
(e) L(s) =
(s + 2)
s(s−1)(s + 6)2
(f) L(s) =
1
(s−1)[(s + 2)2 + 3]
6.9
A certain system is represented by the asymptotic Bode diagram shown in
Fig. 6.85. Find and sketch the response of this system to a unit-step input
(assuming zero initial conditions).
Figure 6.85
Magnitude portion of
Bode plot for
Problem 6.9
10
1
0.1
1
10
100
1000
v
ƒGƒ
6.10
Prove that a magnitude slope of −1 in a Bode plot corresponds to −20 db per
decade or −6 db per octave.
6.11
A normalized second-order system with a damping ratio ζ = 0.5 and an
additional zero is given by
G(s) =
s/a + 1
s2 + s + 1.
Use Matlab to compare the Mp from the step response of the system for
a = 0.01, 0.1, 1, 10, and 100 with the Mr from the frequency response of
each case. Is there a correlation between Mr and Mp?
6.12
A normalized second-order system with ζ = 0.5 and an additional pole is
given by
G(s) =
1
[(s/p) + 1](s2 + s + 1).
Draw Bode plots with p = 0.01, 0.1, 1, 10, and 100. What conclusions can
you draw about the effect of an extra pole on the bandwidth compared with
the bandwidth for the second-order system with no extra pole?

412
Chapter 6 The Frequency-Response Design Method
6.13
For the closed-loop transfer function
T(s) =
ω2n
s2 + 2ζωns + ω2n
,
derive the following expression for the bandwidth ωBW of T(s) in terms of
ωn and ζ:
ωBW = ωn

1 −2ζ 2 +

2 + 4ζ 4 −4ζ 2.
Assuming that ωn = 1, plot ωBW for 0 ≤ζ ≤1.
6.14
Consider the system whose transfer function is
G(s) =
A0ω0s
s2 + ω0
Q s + ω2
0
.
This is a model of a tuned circuit with quality factor Q.
(a) Compute the magnitude and phase of the transfer function analytically,
and plot them for Q = 0.5, 1, 2, and 5 as a function of the normalized
frequency ω/ω0.
(b) Deﬁne the bandwidth as the distance between the frequencies on either
side of ω0 where the magnitude drops to 3 db below its value at ω0, and
show that the bandwidth is given by
BW = 1
2π
ω0
Q

.
(c) What is the relation between Q and ζ?
6.15
A DC voltmeter schematic is shown in Fig. 6.86. The pointer is damped so
that its maximum overshoot to a step input is 10%.
(a) What is the undamped natural frequency of the system?
(b) What is the damped natural frequency of the system?
(c) Plot the frequency response using Matlab to determine what input fre-
quency will produce the largest magnitude output?
Figure 6.86
Voltmeter schematic
u
T
k
y
I = 40 * 10-6 kg · m2
k = 4 * 10-6 kg · m2/sec2
T = input torque = Kmy
y = input voltage
Km = 4 * 10-6 N · m/V
I

Problems
413
(d) Suppose this meter is now used to measure a 1-V AC input with a fre-
quency of 2 rad/sec. What amplitude will the meter indicate after initial
transients have died out? What is the phase lag of the output with respect
to the input? Use a Bode plot analysis to answer these questions. Use the
lsim command in Matlab to verify your answer in part (d).
Problems for Section 6.2: Neutral Stability
6.16
Determine the range of K for which the closed-loop systems (see Fig. 6.18)
are stable for each of the cases below by making a Bode plot for K = 1
and imagining the magnitude plot sliding up or down until instability results.
Verify your answers by using a very rough sketch of a root-locus plot.
(a) KG(s) = K(s + 3)
s + 30
(b) KG(s) =
K
(s + 10)(s + 1)2
(c) KG(s) = K(s + 10)(s + 1)
(s + 100)(s + 5)3
6.17
Determine the range of K for which each of the listed systems is stable by
making a Bode plot for K = 1 and imagining the magnitude plot sliding up
or down until instability results. Verify your answers by using a very rough
sketch of a root-locus plot.
(a) KG(s) = K(s + 1)
s(s + 10)
(b) KG(s) = K(s + 1)
s2(s + 10)
(c) KG(s) =
K
(s + 2)(s2 + 9)
(d) KG(s) = K(s + 1)2
s3(s + 10)
Problems for Section 6.3: The Nyquist Stability Criterion
6.18
(a) Sketch the Nyquist plot for an open-loop system with transfer function
1/s2; that is, sketch
1
s2
s=C1
,
where C1 is a contour enclosing the entire RHP, as shown in Fig. 6.17.
(Hint: Assume C1 takes a small detour around the poles at s = 0, as
shown in Fig. 6.27)
(b) Repeat part (a) for an open-loop system whose transfer function is
G(s) =
1
s2 + ω2
0
.
6.19
Sketch the Nyquist plot based on the Bode plots for each of the following
systems, and then compare your result with that obtained by using the Matlab
command nyquist: Don't be concerned with the details of exactly where the
curve goes, but do make sure it crosses the real axis at the right spot, has
the correct number of −1 encirclements and goes off to inﬁnity in the correct
direction.
(a) KG(s) = K(s + 2)
s + 10
(b) KG(s) =
K
(s + 10)(s + 2)2

414
Chapter 6 The Frequency-Response Design Method
(c) KG(s) = K(s + 10)(s + 1)
(s + 100)(s + 2)3
(d) Using your plots, estimate the range of K for which each system is stable,
and qualitatively verify your result by using a rough sketch of a root-locus
plot.
6.20
Draw a Nyquist plot for
KG(s) = K(s + 1)
s(s + 3) ,
(6.73)
choosing the contour to be to the right of the singularity on the jω-axis. Next,
using the Nyquist criterion, determine the range of K for which the system
is stable. Then redo the Nyquist plot, this time choosing the contour to be
to the left of the singularity on the imaginary axis. Again, using the Nyquist
criterion, check the range of K for which the system is stable. Are the answers
the same? Should they be?
6.21
Draw the Nyquist plot for the system in Fig. 6.87. Using the Nyquist stability
criterion, determine the range of K for which the system is stable. Consider
both positive and negative values of K.
Figure 6.87
Control system for
Problem 6.21
K
©
-
+
R
Y
s + 1
1
s2 + 2s + 2
1
6.22
(a) For ω = 0.1 to 100 rad/sec, sketch the phase of the minimum-phase
system
G(s) = s + 1
s + 10
s=jω
and the nonminimum-phase system
G(s) = −s −1
s + 10
s=jω
,
noting that ∠( jω −1) decreases with ω rather than increasing.
(b) Does an RHP zero affect the relationship between the −1 encirclements
on a polar plot and the number of unstable closed-loop roots in Eq. (6.28)?
(c) Sketch the phase of the following unstable system for ω = 0.1 to 100
rad/sec:
G(s) = s + 1
s −10
s=jω
.
(d) Check the stability of the systems in (a) and (c) using the Nyquist criterion
on KG(s). Determine the range of K for which the closed-loop system is
stable, and check your results qualitatively by using a rough root-locus
sketch.

Problems
415
6.23
Nyquist plots and the classical plane curves: Determine the Nyquist plot,
using Matlab, for the systems given below, with K = 1, and verify that
the beginning point and end point for the jω > 0 portion have the correct
magnitude and phase:
(a) The classical curve called Cayley's Sextic, discovered by Maclaurin in
1718:
KG(s) = K
1
(s + 1)3 .
(b) The classical curve called the Cissoid, meaning ivy-shaped:
KG(s) = K
1
s(s + 1).
(c) The classical curve called the Folium of Kepler, studied by Kepler in
1609:
KG(s) = K
1
(s −1)(s + 1)2 .
(d) The classical curve called the Folium (not Kepler's):
KG(s) = K
1
(s −1)(s + 2).
(e) The classical curve called the Nephroid, meaning kidney-shaped:
KG(s) = K 2(s + 1)(s2 −4s + 1)
(s −1)3
.
(f) The classical curve called Nephroid of Freeth, named after the English
mathematician T. J. Freeth:
KG(s) = K (s + 1)(s2 + 3)
4(s −1)3
.
(g) A shifted Nephroid of Freeth:
KG(s) = K (s2 + 1)
(s −1)3 .
Problems for Section 6.4: Stability Margins
6.24
The Nyquist plot for some actual control systems resembles the one shown in
Fig. 6.88. What are the gain and phase margin(s) for the system of Fig. 6.88,
given that α = 0.4, β = 1.3, and φ = 40◦. Describe what happens to the
stability of the system as the gain goes from zero to a very large value. Sketch
what the corresponding root locus must look like for such a system. Also,
sketch what the corresponding Bode plots would look like for the system.
6.25
The Bode plot for
G(s) =
100[(s/10) + 1]
s[(s/1) −1][(s/100) + 1]
is shown in Fig. 6.89.
(a) Why does the phase start at −270◦at the low frequencies?
(b) Sketch the Nyquist plot for G(s).

416
Chapter 6 The Frequency-Response Design Method
Figure 6.88
Nyquist plot for
Problem 6.24
Re[G(s)]
Im[G(s)]
vo
vL
b
a
f
v*
vH
-1
1
Figure 6.89
Bode plot for
Problem 6.25
v (rad/sec)
0.01
0.1
1
10
100
1000
v (rad/sec)
0.01
0.1
1
10
100
1000
1000
100
10
1
0.1
0.01
0.001
60
40
20
0
-20
-40
-60
-905
-1805
-2705
ƒGƒ
db
jG
(c) Is the closed-loop system for the Bode plot shown in Fig. 6.89 stable?
(d) Will the system be stable if the gain is lowered by a factor of 100? Make
a rough sketch of a root locus for the system, and qualitatively conﬁrm
your answer.

Problems
417
6.26
Suppose that in Fig. 6.90,
G(s) =
25(s + 1)
s(s + 2)(s2 + 2s + 16).
Use Matlab's margin to calculate the PM and GM for G(s) and, on the
basis of the Bode plots, conclude which margin would provide more useful
information to the control designer for this system.
Figure 6.90
Control system for
Problem 6.26
©
-
+
R
Y
G(s)
6.27
Consider the system given in Fig. 6.91.
(a) Use Matlab to obtain Bode plots for K = 1, and use the plots to estimate
the range of K for which the system will be stable.
(b) Verify the stable range of K by using margin to determine PM for selected
values of K.
(c) Use rlocus to determine the values of K at the stability boundaries.
(d) Sketch the Nyquist plot of the system, and use it to verify the number of
unstable roots for the unstable ranges of K.
(e) Using Routh's criterion, determine the ranges of K for closed-loop
stability of this system.
Figure 6.91
Control system for
Problem 6.27
©
 - 
 + 
R
Y
K
s - 1
1
(s + 1)2 + 1
s + 2
6.28
Suppose that in Fig. 6.90,
G(s) =
3.2(s + 1)
s(s + 2)(s2 + 0.2s + 16).
Use Matlab's margin to calculate the PM and GM for G(s), and comment on
whether you think this system will have well-damped closed-loop roots.
6.29
For a given system, show that the ultimate period Pu and the correspond-
ing ultimate gain Ku for the Ziegler-Nichols method can be found by using
the following:
(a) Nyquist diagram
(b) Bode plot
(c) Root locus
6.30
If a system has the open-loop transfer function
G(s) =
ω2n
s(s + 2ζωn)

418
Chapter 6 The Frequency-Response Design Method
with unity feedback, then the closed-loop transfer function is given by
T(s) =
ω2n
s2 + 2ζωns + ω2n
.
Verify the values of the PM shown in Fig. 6.36 for ζ = 0.1, 0.4, and 0.7.
6.31
Consider the unity-feedback system with the open-loop transfer function
G(s) =
K
s(s + 1)[(s2/25) + 0.4(s/5) + 1].
(a) Use Matlab to draw the Bode plots for G( jω), assuming that K = 1.
(b) What gain K is required for a PM of 45◦? What is the GM for this value
of K?
(c) What is Kv when the gain K is set for PM = 45◦?
(d) Create a root locus with respect to K, and indicate the roots for a PM
of 45◦.
6.32
For the system depicted in Fig. 6.92(a), the transfer-function blocks are
deﬁned by
G(s) =
1
(s + 2)2(s + 4)
and
H(s) =
1
s + 1.
(a) Using rlocus and rlocﬁnd, determine the value of K at the stability
boundary.
(b) Using rlocus and rlocﬁnd, determine the value of K that will produce roots
with damping corresponding to ζ = 0.707.
(c) What is the GM of the system if the gain is set to the value determined
in part (b)? Answer this question without using any frequency-response
methods.
(d) Create the Bode plots for the system, and determine the GM that results
for PM = 65◦. What damping ratio would you expect for this PM?
(e) Sketch a root locus for the system shown in Fig. 6.92 (b). How does it
differ from the one in part (a)?
(f) For the systems in Figs. 6.92 (a) and (b), how does the transfer function
Y2(s)/R(s) differ from Y1(s)/R(s)? Would you expect the step response
to r(t) to be different for the two cases?
Y1
©
 - 
 + 
R
K
H(s)
G(s)
Y2
©
 - 
 + 
R
K
G(s)
H(s)
(b)
(a)
Figure 6.92
Block diagram for Problem 6.32: (a) unity feedback; (b) H(s) in feedback

Problems
419
6.33
For the system shown in Fig. 6.93, use Bode and root-locus plots to determine
the gain and frequency at which instability occurs. What gain (or gains) gives
a PM of 20◦? What is the GM when PM = 20◦?
Figure 6.93
Control system for
Problem 6.33
©
 - 
 + 
R
Y
s2(s + 3)(s2 + 2s + 25)
(s + 1)(s + 2)
K
6.34
A magnetic tape-drive speed-control system is shown in Fig. 6.94. The
speed sensor is slow enough that its dynamics must be included. The speed-
measurement time constant is τm = 0.5 sec; the reel time constant is τr =
J/b = 4 sec, where b = the output shaft damping constant = 1 N·m· sec;
and the motor time constant is τ1 = 1 sec.
(a) Determine the gain K required to keep the steady-state speed error to less
than 7% of the reference-speed setting.
(b) Determine the gain and phase margins of the system. Is this a good system
design?
Figure 6.94
Magnetic tape-drive
speed control
©
 - 
 + 
t1s + 1
K
Js + b
1
tms + 1
1
Torque
vc
Amplifier
and motor
Tape drive
Sensor
v
6.35
For the system in Fig. 6.95, determine the Nyquist plot and apply the Nyquist
criterion
(a) to determine the range of values of K (positive and negative) for which
the system will be stable, and
(b) to determine the number of roots in the RHP for those values of K for
which the system is unstable. Check your answer by using a rough root-
locus sketch.
Figure 6.95
Control system for
Problems 6.35, 6.69,
and 6.70
©
 - 
 + 
K
s(s + 1)(s + 3)
3
R
E
F
Y
Yˆ
Sensor
1
6.36
For the system shown in Fig. 6.96, determine the Nyquist plot and apply the
Nyquist criterion

420
Chapter 6 The Frequency-Response Design Method
Figure 6.96
Control system for
Problem 6.36
©
 - 
 + 
K
R
E
F
Y
Sensor
1
(s - 1)2
s + 1
(a) to determine the range of values of K (positive and negative) for which
the system will be stable, and
(b) to determine the number of roots in the RHP for those values of K for
which the system is unstable. Check your answer by using a rough root-
locus sketch.
6.37
For the system shown in Fig. 6.97, determine the Nyquist plot and apply the
Nyquist criterion
(a) to determine the range of values of K (positive and negative) for which
the system will be stable, and
(b) to determine the number of roots in the RHP for those values of K for
which the system is unstable. Check your answer by using a rough root-
locus sketch.
Figure 6.97
Control system for
Problem 6.37
©
 - 
 + 
K
R
E
Y
Sensor
1
(s + 1)2
s - 1
F
6.38
The Nyquist diagrams for two stable, open-loop systems are sketched in
Fig. 6.98. The proposed operating gain is indicated as K0, and arrows indi-
cate increasing frequency. In each case give a rough estimate of the following
quantities for the closed-loop (unity feedback) system:
(a) Phase margin;
(b) Damping ratio;
Figure 6.98
Nyquist plots for
Problem 6.38
Re[G(s)]
Im[G(s)]
Im[G(s)]
Re[G(s)]
(a)
(b)
K0
1
-
K0
1
-

Problems
421
(c) Range of gain for stability (if any);
(d) System type (0, 1, or 2).
6.39
The steering dynamics of a ship are represented by the transfer function
V(s)
δr(s) = G(s) =
K[−(s/0.142) + 1]
s(s/0.325 + 1)(s/0.0362 + 1),
where V is the ship's lateral velocity in meters per second, and δr is the rudder
angle in radians.
(a) Use the Matlab command bode to plot the log magnitude and phase of
G( jω) for K = 0.2.
(b) On your plot, indicate the crossover frequency, PM, and GM.
(c) Is the ship-steering system stable with K = 0.2?
(d) What value of K would yield a PM of 30◦, and what would the crossover
frequency be?
6.40
For the open-loop system
KG(s) =
K(s + 1)
s2(s + 10)2 ,
determine the value for K at the stability boundary and the values of K at the
points where PM = 30◦.
Problems for Section 6.5: Bode's Gain-Phase Relationship
6.41
Thefrequencyresponseofaplantinaunity-feedbackconﬁgurationissketched
in Fig. 6.99. Assume that the plant is open-loop stable and minimum-phase.
(a) What is the velocity constant Kv for the system as drawn?
(b) What is the damping ratio of the complex poles at ω = 100?
Figure 6.99
Magnitude frequency
response for
Problem 6.41
v (rad/sec)
1
10
100
1000
20
100
10
1
0.1
0.01
40
20
0
-40
-20
ƒGƒ
db

422
Chapter 6 The Frequency-Response Design Method
(c) Approximately what is the system error in tracking (following) a
sinusoidal input of ω = 3 rad/sec?
(d) What is the PM of the system as drawn? (Estimate to within ±10◦.)
6.42
For the system
G(s) =
100(s/a + 1)
s(s + 1)(s/b + 1),
where b = 10a, ﬁnd the approximate value of a that will yield the best PM
by sketching only candidate values of the frequency-response magnitude.
Problem for Section 6.6: Closed-Loop Frequency Response
6.43
For the open-loop system
KG(s) =
K(s + 1)
s2(s + 20)2 ,
determine the value for K that will yield PM ≥30◦and the maximum possible
closed-loop bandwidth. Use Matlab to ﬁnd the bandwidth.
Problems for Section 6.7: Compensation Design
6.44
For the lead compensator
Dc(s) = TDs + 1
αTDs + 1,
where α < 1,
(a) Show that the phase of the lead compensator is given by
φ = tan−1(TDω) −tan−1(αTDω).
(b) Show that the frequency where the phase is maximum is given by
ωmax =
1
TD
√α
and that the maximum phase corresponds to
sin φmax = 1 −α
1 + α .
(c) Rewrite your expression for ωmax to show that the maximum-phase fre-
quency occurs at the geometric mean of the two corner frequencies on a
logarithmic scale:
log ωmax = 1
2

log 1
TD
+ log
1
αTD

.
(d) To derive the same results in terms of the pole-zero locations, rewrite
Dc(s) as
Dc(s) = s + z
s + p,
and then show that the phase is given by
φ = tan−1
 ω
|z|

−tan−1
 ω
|p|

,

Problems
423
such that
ωmax =

|z| |p|.
Hence the frequency at which the phase is maximum is the square root of
the product of the pole and zero locations.
6.45
For the third-order servo system
G(s) =
50,000
s(s + 10)(s + 50),
use Bode plot sketches to design a lead compensator so that PM ≥50◦and
ωBW ≥20 rad/sec. Then verify and reﬁne your design by using Matlab.
6.46
For the system shown in Fig. 6.100, suppose that
G(s) =
5
s(s + 1)(s/5 + 1).
Use Bode plot sketches to design a lead compensation Dc(s) with unity DC
gain so that PM ≥40◦. Then verify and reﬁne your design by using Matlab.
What is the approximate bandwidth of the system?
Figure 6.100
Control system for
Problem 6.46
Y
©
 - 
 + 
R
E
Dc
G
6.47
DerivethetransferfunctionfromTd toθ forthesysteminFig.6.67. Thenapply
the Final Value Theorem (assuming Td = constant) to determine whether
θ(∞) is nonzero for the following two cases:
(a) When Dc(s) has no integral term: lim
s→0 Dc(s) = constant;
(b) When Dc(s) has an integral term:
Dc(s) = D′c(s)
s
In this case, lim
s→0 D′c(s) = constant.
6.48
The inverted pendulum has a transfer function given by Eq. (2.31), which is
similar to
G(s) =
1
s2 −0.25.
(a) Use Bode plot sketches to design a lead compensator to achieve a PM
of 30◦. Then verify and reﬁne your design by using Matlab.
(b) Sketch a root locus and correlate it with the Bode plot of the system.
(c) Could you obtain the frequency response of this system experimentally?
6.49
The open-loop transfer function of a unity-feedback system is
G(s) =
K
s(s/5 + 1)(s/50 + 1).

424
Chapter 6 The Frequency-Response Design Method
(a) Use Bode plot sketches to design a lag compensator for G(s) so that the
closed-loop system satisﬁes the following speciﬁcations:
(i) The steady-state error to a unit-ramp reference input is less than 0.01.
(ii) PM ≥40◦.
(b) Verify and reﬁne your design by using Matlab.
6.50
The open-loop transfer function of a unity-feedback system is
G(s) =
K
s(s/5 + 1)(s/200 + 1).
(a) Use Bode plot sketches to design a lead compensator for G(s) so that the
closed-loop system satisﬁes the following speciﬁcations:
(i) The steady-state error to a unit-ramp reference input is less than 0.01.
(ii) For the dominant closed-loop poles, the damping ratio ζ ≥0.4.
(b) Verify and reﬁne your design using Matlab, including a direct computation
of the damping of the dominant closed-loop poles.
6.51
A DC motor with negligible armature inductance is to be used in a position
control system. Its open-loop transfer function is given by
G(s) =
50
s(s/5 + 1).
(a) Use Bode plot sketches to design a compensator for the motor so that the
closed-loop system satisﬁes the following speciﬁcations:
(i) The steady-state error to a unit-ramp input is less than 1/200.
(ii) The unit-step response has an overshoot of less than 20%.
(iii) The bandwidth of the compensated system is no less than that of the
uncompensated system.
(b) Verify and/or reﬁne your design using Matlab, including a direct
computation of the step-response overshoot.
6.52
The open-loop transfer function of a unity-feedback system is
G(s) =
K
s(1 + s/5)(1 + s/20).
(a) Sketch the system block diagram, including input reference commands
and sensor noise.
(b) Use Bode plot sketches to design a compensator for G(s) so that the
closed-loop system satisﬁes the following speciﬁcations:
(i) The steady-state error to a unit-ramp input is less than 0.01.
(ii) PM ≥45◦.
(iii) The steady-state error for sinusoidal inputs with ω < 0.2 rad/sec is
less than 1/250.
(iv) Noise components introduced with the sensor signal at frequencies
greater than 200 rad/sec are to be attenuated at the output by at least
a factor of 100.
(c) Verify and/or reﬁne your design using Matlab, including a computation
of the closed-loop frequency response to verify (iv).

Problems
425
6.53
Consider a Type 1 unity-feedback system with
G(s) =
K
s(s + 1).
Use Bode plot sketches to design a lead compensator so that Kv = 20 sec−1
and PM > 40◦. Use Matlab to verify and/or reﬁne your design so that it meets
the speciﬁcations.
6.54
Consider a satellite attitude-control system with the transfer function
G(s) =
0.05(s + 25)
s2(s2 + 0.1s + 4).
Amplitude-stabilize the system using lead compensation so that GM ≥
2 (6 db), and PM ≥45◦, keeping the bandwidth as high as possible with
a single lead.
6.55
In one mode of operation, the autopilot of a jet transport is used to control
altitude. For the purpose of designing the altitude portion of the autopilot
loop, only the long-period airplane dynamics are important. The line-
arized relationship between altitude and elevator angle for the long-period
dynamics is
G(s) = h(s)
δ(s) =
20(s + 0.01)
s(s2 + 0.01s + 0.0025)
ft/ sec
deg .
The autopilot receives from the altimeter an electrical signal proportional to
altitude. This signal is compared with a command signal (proportional to the
altitude selected by the pilot), and the difference provides an error signal.
The error signal is processed through compensation, and the result is used
to command the elevator actuators. A block diagram of this system is shown
in Fig. 6.101. You have been given the task of designing the compensation.
Begin by considering a proportional control law Dc(s) = K.
Figure 6.101
Control system for
Problem 6.55
©
 - 
 + 
Dc(s)
HR
H
s
1
d
d(s)
(s)
h
h
(a) Use Matlab to draw a Bode plot of the open-loop system for Dc(s) =
K = 1.
(b) WhatvalueofK wouldprovideacrossoverfrequency(i.e., where|G| = 1)
of 0.16 rad/sec?
(c) For this value of K, would the system be stable if the loop were closed?
(d) What is the PM for this value of K?
(e) Sketch the Nyquist plot of the system, and locate carefully any points
where the phase angle is 180◦or the magnitude is unity.
(f) Use Matlab to plot the root locus with respect to K, and locate the roots
for your value of K from part (b).
(g) What steady-state error would result if the command was a step change
in altitude of 1000 ft?

426
Chapter 6 The Frequency-Response Design Method
For parts (h) and (i), assume a compensator of the form
Dc(s) = TDs + 1
αTDs + 1.
(h) Choose the parameters K, TD, and α so that the crossover frequency
is 0.16 rad/sec and the PM is greater than 50◦. Verify your design by
superimposing a Bode plot of Dc(s)G(s)/K on top of the Bode plot you
obtained for part (a), and measure the PM directly.
(i) Use Matlab to plot the root locus with respect to K for the system, includ-
ing the compensator you designed in part (h). Locate the roots for your
value of K from part (h).
(j) Altitude autopilots also have a mode in which the rate of climb is sensed
directly and commanded by the pilot.
(i)
Sketch the block diagram for this mode;
(ii) Modify the G(s) stated above for the case where the variable to be
controlled is the rate of altitude change;
(iii) Design Dc(s) so that the system has the same crossover frequency as
the altitude hold mode and the PM is greater than 50◦.
6.56
For a system with open-loop transfer function
G(s) =
10
s[(s/1.4) + 1][(s/3) + 1],
design a lag compensator with unity DC gain so that PM ≥40◦. What is the
approximate bandwidth of this system?
6.57
For the ship-steering system in Problem 6.39,
(a) Design a compensator that meets the following speciﬁcations:
(i) Velocity constant Kv = 2,
(ii) PM ≥50◦,
(iii) Unconditional stability (PM > 0 for all ω ≤ωc, the crossover
frequency).
(b) For your ﬁnal design, draw a root locus with respect to K, and indicate
the location of the closed-loop poles.
6.58
Consider a unity-feedback system with
G(s) =
1
s (s/20 + 1)

s2/1002 + 0.5s/100 + 1
.
(6.74)
(a) A lead compensator is introduced with α = 1/5 and a zero at 1/T = 20.
How must the gain be changed to obtain crossover at ωc = 31.6 rad/sec,
and what is the resulting value of Kv?
(b) With the lead compensator in place, what is the required value of K for a
lag compensator that will readjust the gain to a Kv value of 100?
(c) Place the pole of the lag compensator at 3.16 rad/sec, and determine the
zero location that will maintain the crossover frequency at ωc = 31.6
rad/sec. Plot the compensated frequency response on the same graph.
(d) Determine the PM of the compensated design.
6.59
Golden NuggetAirlines had great success with their free bar near the tail of the
airplane. (See Problem 5.40.) However, when they purchased a much larger

Problems
427
airplane to handle the passenger demand, they discovered that there was some
ﬂexibility in the fuselage that caused a lot of unpleasant yawing motion at
the rear of the airplane when in turbulence, which caused the revelers to spill
their drinks. The approximate transfer function for the rigid body roll/yawl
motion, called the "Dutch roll" mode (Section 10.3.1) is
r(s)
δr(s) =
8.75(4s2 + 0.4s + 1)
(s/0.01 + 1)(s2 + 0.24s + 1),
where r is the airplane's yaw rate and δr is the rudder angle. In performing
a ﬁnite element analysis (FEA) of the fuselage structure and adding those
dynamics to the Dutch roll motion, they found that the transfer function needed
additional terms which reﬂected the fuselage lateral bending that occurred due
to excitation from the rudder and turbulence. The revised transfer function is
r(s)
δr(s) =
8.75(4s2 + 0.4s + 1)
(s/0.01 + 1)(s2 + 0.24s + 1) ·
1
(s2/ω2
b + 2ζs/ωb + 1)
,
where ωb is the frequency of the bending mode (= 10 rad/sec) and ζ is the
bending mode damping ratio (=0.02). Most swept-wing airplanes have a "yaw
damper," which essentially feeds back yaw rate measured by a rate gyro to the
rudder with a simple proportional control law. For the new Golden Nugget
airplane, the proportional feedback gain K = 1, where
δr(s) = −Kr(s).
(6.75)
(a) Make a Bode plot of the open-loop system, determine the PM and GM
for the nominal design, and plot the step response and Bode magnitude
of the closed-loop system. What is the frequency of the lightly damped
mode that is causing the difﬁculty?
(b) Investigate remedies to quiet down the oscillations, but maintain the same
low-frequency gain in order not to affect the quality of the Dutch roll
damping provided by the yaw rate feedback. Speciﬁcally, investigate each
of the following, one at a time:
(i)
Increasing the damping of the bending mode from ζ = 0.02 to
ζ = 0.04 (would require adding energy-absorbing material in the
fuselage structure).
(ii) Increasing the frequency of the bending mode from ωb = 10 rad/sec
to ωb = 20 rad/sec (would require stronger and heavier structural
elements).
(iii) Adding a low-pass ﬁlter in the feedback—that is, replacing K in Eq.
(6.75) with KDc(s), where
Dc(s) =
1
s/τp + 1
(iv) Adding a notch ﬁlter as described in Section 5.4.3. Pick the frequency
of the notch zero to be at ωb, with a damping of ζ = 0.04, and pick
the denominator poles to be (s/100 + 1)2, keeping the DC gain of
the ﬁlter = 1.
(c) Investigate the sensitivity of the preceding two compensated designs
(iii and iv) by determining the effect of a reduction in the bending mode

428
Chapter 6 The Frequency-Response Design Method
frequency of −10%. Speciﬁcally, reexamine the two designs by tabulating
the GM, PM, closed-loop bending mode damping ratio, and resonant-peak
amplitude, and qualitatively describe the differences in the step response.
(d) What do you recommend to Golden Nugget to help their customers quit
spilling their drinks? (Telling them to get back in their seats is not an
acceptable answer for this problem! Make the recommendation in terms
of improvements to the yaw damper.)
6.60
Consider a system with the open-loop transfer function (loop gain)
△
G(s) =
1
s(s + 1)(s/10 + 1).
(a) Create the Bode plot for the system, and ﬁnd GM and PM.
(b) Compute the sensitivity function and plot its magnitude frequency
response.
(c) Compute the vector margin (VM).
6.61
Prove that the sensitivity function S(s) has magnitude greater than 1 inside a
△
circle with a radius of 1 centered at the −1 point. What does this imply about
the shape of the Nyquist plot if closed-loop control is to outperform open-loop
control at all frequencies?
6.62
Consider the system in Fig. 6.100 with the plant transfer function
△
G(s) =
10
s(s/10 + 1).
(a) We wish to design a compensator Dc(s) that satisﬁes the following design
speciﬁcations:
(i)
Kv = 100,
(ii) PM ≥45◦,
(iii) Sinusoidal inputs of up to 1 rad/sec to be reproduced with ≤2%
error,
(iv) Sinusoidal inputs with a frequency of greater than 100 rad/sec to be
attenuated at the output to ≤5% of their input value.
(b) Create the Bode plot of G(s), choosing the open-loop gain so that
Kv = 100.
(c) Show that a sufﬁcient condition for meeting the speciﬁcation on sinu-
soidal inputs is that the magnitude plot lies outside the shaded regions in
Fig. 6.102. Recall that
Y
R =
KG
1 + KG
and
E
R =
1
1 + KG.
(d) Explain why introducing a lead network alone cannot meet the design
speciﬁcations.
(e) Explain why a lag network alone cannot meet the design speciﬁcations.
(f) Develop a full design using a lead-lag compensator that meets all
the design speciﬁcations without altering the previously chosen low-
frequency open-loop gain.
6.63
For Example 6.20, redo the design by selecting 1/TD = 0.05 and then deter-
mining the highest possible value 1/TI that will meet the PM requirement.
Then examine the improvement, if any, in the response to a step disturbance
torque.

Problems
429
Figure 6.102
Control system
constraints for
Problem 6.62
0.01
0.1
1
v (rad/sec)
10
100
1000
Magnitude, ƒL(jv)ƒ
0.01
0.1
1
10
100
1000
W1
W2
-1
Problems for Section 6.8: Time Delay
△
6.64
Assume that the system
G(s) = e−Tds
s + 10
has a 0.2-sec time delay (Td = 0.2 sec). While maintaining a phase margin
≥40◦, ﬁnd the maximum possible bandwidth by using the following:
(a) One lead-compensator section
Dc(s) = K s + a
s + b,
where b/a = 100.
(b) Two lead-compensator sections
Dc(s) = K
s + a
s + b
2
,
where b/a = 10.
(c) Comment on the statement in the text about the limitations on the
bandwidth imposed by a delay.
6.65
Determine the range of K for which the following systems are stable:
(a) G(s) = K e−4s
s
(b) G(s) = K
e−s
s(s+2)
6.66
Consider the heat exchanger of Example 2.16 with the open-loop transfer
function
G(s) =
e−5s
(10s + 1)(60s + 1).
(a) Design a lead compensator that yields PM ≥45◦and the maximum
possible closed-loop bandwidth.
(b) Design a PI compensator that yields PM ≥45◦and the maximum possible
closed-loop bandwidth.

430
Chapter 6 The Frequency-Response Design Method
Problems for Section 6.9: Alternative Presentations of Data
△
6.67
A feedback control system is shown in Fig. 6.103. The closed-loop system is
speciﬁed to have an overshoot of less than 30% to a step input.
Figure 6.103
Control system for
Problem 6.67
©
 - 
 + 
R
Y
s(s + 2)
K
(a) Determine the corresponding PM speciﬁcation in the frequency domain
and the corresponding closed-loop resonant-peak value Mr.
(See
Fig. 6.37.)
(b) From Bode plots of the system, determine the maximum value of K that
satisﬁes the PM speciﬁcation.
(c) Plot the data from the Bode plots [adjusted by the K obtained in part (b)]
on a copy of the Nichols chart in Fig. 6.81, and determine the resonant-
peak magnitude Mr. Compare that with the approximate value obtained
in part (a).
(d) Use the Nichols chart to determine the resonant-peak frequency ωr and
the closed-loop bandwidth.
6.68
The Nichols plots of an uncompensated and a compensated system are shown
in Fig. 6.104.
(a) What are the resonance peaks of each system?
(b) What are the PM and GM of each system?
(c) What are the bandwidths of each system?
(d) What type of compensation is used?
6.69
Consider the system shown in Fig. 6.95.
(a) Construct
an
inverse
Nyquist
plot
of
[Y( jω)/E( jω)]−1.
(See
Appendix W6.9.2.)
(b) Show how the value of K for neutral stability can be read directly from
the inverse Nyquist plot.
(c) For K = 4, 2, and 1, determine the gain and phase margins.
(d) Construct a root-locus plot for the system, and identify corresponding
points in the two plots. To what damping ratios ζ do the GM and PM of
part (c) correspond?
6.70
An unstable plant has the transfer function
Y(s)
F(s) =
s + 1
(s −1)2 .
A simple control loop is to be closed around it, in the same manner as in the
block diagram in Fig. 6.95.
(a) Construct an inverse Nyquist plot of Y/F. (See Appendix W6.9.2.)
(b) Choose a value of K to provide a PM of 45◦. What is the correspond-
ing GM?

Problems
431
Closed-
loop
magnitude
Closed-
loop
phase
0.1
-1805
-1605
-1405
-1205
-1005
-805
-605
-405
jDc(s)G(s)
0.10
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
10
9
8
7
6
5
4
3
2
ƒDc(s)G(s)ƒ
5.0
2.0
1.50
1.30
1.10
1.05
1.00
0.95
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.15
-15
-25
-55
-105
-305
1.20
-205
-55
Uncompensated
Compensated
v = 20
v = 30
v = 70
v = 0
v = 40
v = 25
v = 40
Figure 6.104
Nichols plots for Problem 6.68
(c) What can you infer from your plot about the stability of the system when
K < 0?
(d) Construct a root-locus plot for the system, and identify corresponding
points in the two plots. In this case, to what value of ζ does PM = 45◦
correspond?
6.71
Consider the system shown in Fig. 6.105(a).
(a) Construct a Bode plot for the system.
(b) Use your Bode plot to sketch an inverse Nyquist plot. (See Appendix
W6.9.2.)
(c) Consider closing a control loop around G(s), as shown in Fig. 6.105(b).
Using the inverse Nyquist plot as a guide, read from your Bode plot the
values of GM and PM when K = 0.7, 1.0, 1.4, and 2. What value of K
yields PM = 30◦?

432
Chapter 6 The Frequency-Response Design Method
(d) Construct a root-locus plot, and label the same values of K on the locus. To
what value of ζ does each pair of PM/GM values correspond? Compare
ζ versus PM with the rough approximation in Fig. 6.36.
Figure 6.105
Control system for
Problem 6.71
U
Y
G(s) =  s(s + 2)2
4
(b)
©
 - 
 + 
K
R
E
U
Y
Sensor
1
G(s)
(a)

7
State-Space Design
Vertical
Fuselage
reference
axis
Rotor
thrust
Rotor
u
d
u
A Perspective on State-Space Design
In addition to the transform techniques of root locus and frequency
response, there is a third major method of designing feedback control
systems: the state-space method. We will introduce the state-variable
method of describing differential equations. In state-space design,
the control engineer designs a dynamic compensation by working
directly with the state-variable description of the system. Like the
transform techniques, the aim of the state-space method is to ﬁnd a
compensation Dc(s), such as that shown in Fig. 7.1, that satisﬁes the
design speciﬁcations. Because the state-space method of describing
the plant and computing the compensation is so different from the
transform techniques, it may seem at ﬁrst to be solving an entirely dif-
ferent problem. We selected the examples and analysis given toward
the end of this chapter to help convince you that, indeed, state-space
design results in a compensator with a transfer function Dc(s) that is
equivalent to those Dc(s) compensators obtained with the other two
methods.
Because it is particularly well suited to the use of computer tech-
niques, state-space design is increasingly studied and used today by
control engineers.
433

434
Chapter 7 State-Space Design
Figure 7.1
A control system design
deﬁnition
+
-
R
Y
Compensation
Plant
G(s)
E
U
Dc(s)
©
Chapter Overview
This chapter begins by considering the purposes and advantages of
using state-space design. We discuss selection of state-variables
and state-space models for various dynamic systems through sev-
eral examples in Section 7.2. Models in state-variable form enhance
our ability to apply the computational efﬁciency of computer-aided
design tools such as Matlab. In Section 7.3 we show that it is ben-
eﬁcial to look at the state-variable form in terms of an analog
computer simulation model. In Section 7.4 we review the development
of state-variable equations from block diagrams. We then solve for the
dynamic response, using state equations for both hand and computer
analysis. Having covered these preliminary fundamentals, we next
proceed to the major task of control system design via state-space.
The steps of the design method are as follows:
1. Select closed-loop pole (root as referred to in previous chapters)
locations and develop the control law for the closed-loop system
that corresponds to satisfactory dynamic response (Sections 7.5
and 7.6).
2. Design an estimator (Section 7.7).
3. Combine the control law and the estimator (Section 7.8).
4. Introduce the reference input (Sections 7.5.2 and 7.9).
After working through the central design steps, we brieﬂy
explore the use of integral control in state-space (Section 7.10). The
next three sections of this chapter consider brieﬂy some additional
concepts pertaining to the state-space method; because they are rel-
atively advanced, they may be considered optional to some courses or
readers. Finally, Section 7.15 provides some historical perspective for
the material in this chapter.
7.1
Advantages of State-Space
The idea of state-space comes from the state-variable method of describing
differential equations. In this method the differential equations describing a
dynamic system are organized as a set of ﬁrst-order differential equations
in the vector-valued state of the system, and the solution is visualized as a
trajectory of this state vector in space. State-space control design is the
technique in which the control engineer designs a dynamic compensation by
workingdirectlywiththestate-variabledescriptionofthesystem.Wewillsee

7.1 Advantages of State-Space
435
that the ordinary differential equations (ODEs) of physical dynamic systems
can be manipulated into state-variable form. In the ﬁeld of mathematics,
where ODEs are studied, the state-variable form is called the normal form
Normal form
for the equations. There are several good reasons for studying equations in
this form, three of which are listed here:
•
To study more general models: The ODEs do not have to be linear or
stationary. Thus, by studying the equations themselves, we can develop
methods that are very general. Having them in state-variable form gives
us a compact, standard form for study. Furthermore, the techniques of
state-space analysis and design easily extend to systems with multiple
inputs and/or multiple outputs. Of course, in this text we study mainly
linear time-invariant (LTI) models with single input and output (for the
reasons given earlier).
•
To introduce the ideas of geometry into differential equations: In
physics, the plane of position versus velocity of a particle or rigid
body is called the phase plane, and the trajectory of the motion can
Phase plane
be plotted as a curve in this plane. The state is a generalization of that
idea to include more than two dimensions. While we cannot easily plot
more than three dimensions, the concepts of distance, of orthogonal
and parallel lines, and other concepts from geometry can be useful in
visualizing the solution of an ODE as a path in state-space.
•
To connect internal and external descriptions: The state of a dynamic
system often directly describes the distribution of internal energy in
the system. For example, for electro-mechanical systems it is common
to select the following as state-variables: position (potential energy),
velocity (kinetic energy), capacitor voltage (electric energy), inductor
current (magnetic energy), and thermal systems temperature (thermal
energy). The internal energy can always be computed from the state-
variables. By a system of analysis to be described shortly, we can relate
the state to the system inputs and outputs and thus connect the internal
variables to the external inputs and to the sensed outputs. In contrast,
the transfer function relates only the input to the output and does not
show the internal behavior. The state form keeps the latter information,
which is sometimes important.
Use of the state-space approach has often been referred to as modern
control design, and use of transfer-function-based methods, such as root
locus and frequency response, referred to as classical control design. How-
ever, because the state-space method of description for ODEs has been in
use for over 100 years and was introduced to control design in the late 1950s,
it seems somewhat misleading to refer to it as modern. We prefer to refer
to the two design approaches as the state-space methods and the transform
methods.
Advantages of state-space design are especially apparent when the sys-
tem to be controlled has more than one control input or more than one sensed
output. However, in this book we shall examine the ideas of state-space
design using the simpler Single-Input-Single-Output (SISO) systems. The

436
Chapter 7 State-Space Design
design approach used for the systems described in state form is "divide and
conquer." First, we design the control as if all of the state were measured and
available for use in the control law. This provides the possibility of assigning
arbitrary dynamics for the system. Having a satisfactory control law based
on full-state feedback, we introduce the concept of an observer and con-
struct estimates of the state based on the sensed output. We then show that
these estimates can be used in place of the actual state-variables. Finally, we
introduce the external reference-command inputs to complete the structure.
Only at this point can we recognize that the resulting compensation has the
same essential structure as that developed with transform methods.
Before we can begin the design using state descriptions, it is necessary to
develop some analytical results and tools from matrix linear algebra for use
throughoutthechapter.Weassumethatyouarefamiliarwithsuchelementary
matrix concepts as the identity matrix, triangular and diagonal matrices, and
the transpose of a matrix. We also assume that you have some familiarity
with the mechanics of matrix algebra, including adding, multiplying, and
inverting matrices. More advanced results will be developed in Section 7.4
in the context of the dynamic response of a linear system. All of the linear
algebra results used in this chapter are repeated in Appendix WB available
at www.fpe7e.com for your reference and review.
7.2
System Description in State-Space
The motion of any ﬁnite dynamic system can be expressed as a set of ﬁrst-
order ODEs. This is often referred to as the state-variable representation. For
example, the use of Newton's law and the free-body diagram in Section 2.1
typically lead to second-order differential equations—that is, equations that
contain the second derivative, such as ¨x in Eq. (2.3) or ¨θ in Eq. (2.15). The
latter equation can be expressed as
˙x1 = x2,
(7.1)
˙x2 = u
I ,
(7.2)
where
u = Fcd + MD,
x1 = θ,
x2 = ˙θ,
˙x2 = ¨θ.
The output of this system is θ, the satellite attitude. These same equations
Standard form of linear
differential equations
can be represented in the state-variable form as the vector equation
˙x = Ax + Bu,
(7.3)
where the input is u and the output is
y = Cx + Du.
(7.4)

7.2 System Description in State-Space
437
The column vector x is called the state of the system and contains n elements
for an nth-order system. For mechanical systems, the state vector elements
usually consist of the positions and velocities of the separate bodies, as is the
case for the example in Eqs. (7.1) and (7.2). The quantityA is an n×n system
matrix, B is an n × 1 input matrix, C is a 1 × n row matrix referred to as
the output matrix, and D is a scalar called the direct transmission term.1
To save space, we will sometimes refer to a state vector by its transpose,
x = [ x1
x2
. . .
xn ]T,
which is equivalent to
x =
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦.
The differential equation models of more complex systems, such as
those developed in Chapter 2 on mechanical, electrical, and electrome-
chanical systems, can be described by state-variables through selection of
positions, velocities, capacitor voltages, and inductor currents as suitable
state-variables.
In this chapter we will consider control systems design using the state-
variable form. For the case in which the relationships are nonlinear [such as
the case in Eqs. (2.22), (2.94), and (2.98)], the linear form cannot be used
directly. One must linearize the equations as we did in Chapter 2 to ﬁt the
form (see also Chapter 9).
The state-variable method of specifying differential equations is
used by computer-aided control systems design software packages (for
example Matlab). Therefore, in order to specify linear differential equa-
tions to the computer, you need to know the values of the matrices A, B, C,
and the constant D.
EXAMPLE 7.1
Satellite Attitude Control Model in State-Variable Form
Determine the A, B, C, D matrices in the state-variable form for the satellite
attitude control model in Example 2.3 with MD = 0.
Solution. Deﬁne the attitude and the angular velocity of the satellite as the
state-variables so that x ≜[θ ω]T.2 The single second-order equation (2.15)
can then be written in an equivalent way as two ﬁrst-order equations:
˙θ = ω,
˙ω = d
I Fc.
1We use the A, B, C, and D notation as it is becoming more standard. In previous editions of
this textbook we used F, G, H, and J for historical reasons. We hope this is not too serious of
a jolt to the faculty using our text!
2The symbol ≜means "is to be deﬁned."

438
Chapter 7 State-Space Design
These equations are expressed, using Eq. (7.3), ˙x = Ax + Bu, as
 ˙θ
˙ω
	
=
 0
1
0
0
	  θ
ω
	
+

0
d/I
	
Fc.
The output of the system is the satellite attitude, y = θ. Using Eq. (7.4),
y = Cx + Du, this relation is expressed as
y = [ 1
0 ]
 θ
ω
	
.
Therefore, the matrices for the state-variable form are
A =
 0
1
0
0
	
,
B =

0
d/I
	
,
C = [ 1
0 ],
D = 0,
and the input u = Fc.
For this very simple example, the state-variable form is a more cumber-
some way of writing the differential equation than the second-order version
in Eq. (2.15). However, the method is not more cumbersome for most sys-
tems, and the advantages of having a standard form for use in computer-aided
design have led to widespread use of the state-variable form.
The next example has more complexity and shows how to use Matlab
to ﬁnd the solution of linear differential equations.
EXAMPLE 7.2
Cruise Control Step Response
(a) Rewrite the equation of motion from Example 2.1 in state-variable
form, where the output is the car position x.
(b) Use Matlab to ﬁnd the response of the velocity of the car for the case
in which the input jumps from being u = 0 at time t = 0 to a constant
u = 500 N thereafter. Assume that the car mass m is 1000 kg and
b = 50 N·sec/m.
Solution
(a) Equations of motion: First we need to express the differential equa-
tion describing the plant, Eq. (2.3), as a set of simultaneous ﬁrst-order
equations. To do so, we deﬁne the position and the velocity of the car as
the state-variables x and v, so that x = [x v]T. The single second-order
equation, Eq. (2.3), can then be rewritten as a set of two ﬁrst-order
equations:
˙x = v,
˙v = −b
mv + 1
mu.

7.2 System Description in State-Space
439
Next, we use the standard form of Eq. (7.3), ˙x = Ax + Bu, to express
these equations:
 ˙x
˙v
	
=
 0
1
0
−b/m
	  x
v
	
+

0
1/m
	
u.
(7.5)
The output of the system is the car position y = x, which is expressed
in matrix form as
y = [ 1
0 ]
 x
v
	
,
or
y = Cx.
So the state-variable-form matrices deﬁning this example are
A =
 0
1
0
−b/m
	
,
B =

0
1/m
	
,
C = [ 1
0 ],
D = 0.
(b) Time response: The equations of motion are those given in part (a),
except that now the output is v. Therefore, the output matrix is
C = [ 0
1 ].
The coefﬁcients required are b/m = 0.05 and 1/m = 0.001. The
numerical values of the matrices deﬁning the system are thus
A =
 0
1
0
−0.05
	
,
B =

0
0.001
	
,
C = [ 0
1 ],
D = 0.
The step function in Matlab computes the time response of a linear
system to a unit-step input. Because the system is linear, the output for
this case can be multiplied by the magnitude of the input step to derive
a step response of any amplitude. Equivalently, the B matrix can be
multiplied by the magnitude of the input step.
The statements
Step response with Matlab
A = [0 1;0 -0.05];
B = [0;0.001];
C = [0 1];
D = 0;
sys = ss(A, 500*B,C,D);
% step gives unit step response,
so 500*B gives u=500 N.
step(sys);
% plots the step response
compute and plot the time response for an input step with a 500-N
magnitude. The step response is shown in Fig. 7.2.
EXAMPLE 7.3
Bridged Tee Circuit in State-Variable Form
Determine the state-space equations for the circuit shown in Fig. 2.25.
Solution. In order to write the equations in the state-variable form (that is, a
set of simultaneous ﬁrst-order differential equations), we select the capacitor

440
Chapter 7 State-Space Design
Figure 7.2
Response of the car
velocity to a step in u
10
8
6
4
2
0
Velocity
0
50
100
Time (sec)
voltages vC1 and vC2 as the state elements (that is, x = [vC1vC2]T) and vi as
the input (that is, u = vi). Here vC1 = v2, vC2 = v1 −v3, and still v1 = vi.
Thus v1 = vi, v2 = vC1, and v3 = vi −vC2 as the output (that is, y = v3). In
terms of vC1 and vC2, Eq. (2.34) is
vC1 −vi
R1
+ vC1 −(vi −vC2)
R2
+ C1
dvC1
dt
= 0.
Rearranging this equation into standard form, we get
dvC1
dt
= −1
C1

 1
R1
+ 1
R2

vC1 −1
C1

 1
R2

vC2 + 1
C1

 1
R1
+ 1
R2

vi.
(7.6)
In terms of vC1 and vC2, Eq. (2.35) is
vi −vC2 −vC1
R2
+ C2
d
dt (vi −vC2 −vi) = 0.
In standard form, the equation is
dvC2
dt
= −vC1
C2R2
−vC2
C2R2
+
vi
C2R2
.
(7.7)
Equations (2.34)-(2.35) are entirely equivalent to the state-variable form,
Eqs. (7.6) and (7.7), in describing the circuit. The standard matrix
deﬁnitions are
A =
⎡
⎣−1
C1

1
R1 + 1
R2

−1
C1

1
R2

−
1
C2R2
−
1
C2R2
⎤
⎦,
B =
⎡
⎣
1
C1

1
R1 + 1
R2

1
C2R2
⎤
⎦,
C =
0
−1
, D = 1.

7.2 System Description in State-Space
441
EXAMPLE 7.4
Loudspeaker with Circuit in State-Variable Form
For the loudspeaker in Fig. 2.30 and the circuit driving it in Fig. 2.31, ﬁnd
the state-space equations relating the input voltage va to the output cone
displacement x. Assume that the effective circuit resistance is R and the
inductance is L.
Solution.
Recall the two coupled equations, (2.54) and (2.58), that
constitute the dynamic model for the loudspeaker:
M¨x + b˙x = 0.63i,
L di
dt + Ri = va −0.63˙x.
A logical state vector for this third-order system would be x= [x ˙x i]T, which
leads to the standard matrices
A =
⎡
⎣
0
1
0
0
−b/M
0.63/M
0
−0.63/L
−R/L
⎤
⎦,
B =
⎡
⎣
0
0
1/L
⎤
⎦,
C =
 1
0
0 
,
D = 0,
where now the input u = va.
EXAMPLE 7.5
Modeling a DC Motor in State-Variable Form
Find the state-space equations for the DC motor with the equivalent electric
circuit shown in Fig. 2.33(a).
Solution.
Recall the equations of motion [Eqs. (2.62) and (2.63)] from
Chapter 2:
Jm ¨θm + b ˙θm = Ktia,
La
dia
dt + Raia = va −Ke ˙θm.
A state vector for this third-order system is x=

θm
˙θm
ia
T, which leads
to the standard matrices
A =
⎡
⎢⎣
0
1
0
0
−b
Jm
Kt
Jm
0
−Ke
La
−Ra
La
⎤
⎥⎦,
B =
⎡
⎢⎣
0
0
1
La
⎤
⎥⎦,
C =
 1
0
0 
,
D = 0,
where the input u = va.
The state-variable form can be applied to a system of any order.
Example 7.6 illustrates the method for a fourth-order system.

442
Chapter 7 State-Space Design
EXAMPLE 7.6
Flexible Disk Drive in State-Variable Form
Find the state-variable form of the differential equations for Example 2.4,
where the output is θ2.
Solution. Deﬁne the state vector to be
x =

θ1
˙θ1
θ2
˙θ2
T .
Then solve Eqs. (2.17) and (2.18) for ¨θ1 and ¨θ2 so that the state-variable form
is more apparent. The resulting matrices are
A =
⎡
⎢⎢⎣
0
1
0
0
−k
I1
−b
I1
k
I1
b
I1
0
0
0
1
k
I2
b
I2
−k
I2
−b
I2
⎤
⎥⎥⎦,
B =
⎡
⎢⎢⎣
0
1
I1
0
0
⎤
⎥⎥⎦,
C =
 0
0
1
0 
,
D = 0.
Difﬁculty arises when the differential equation contains derivatives
of the input u. Techniques to handle this situation will be discussed in
Section 7.4.
7.3
Block Diagrams and State-Space
Perhaps, the most effective way of understanding the state-variable equations
is via an analog computer block-diagram representation. The structure of
the representation uses integrators as the central element, which are quite
suitable for a ﬁrst-order, state-variable representation of dynamic equations
for a system. Even though the analog computers are almost extinct, analog
computer implementation is still a useful concept for state-variable design,
and in the circuit design of analog compensation.3
The analog computer was a device composed of electric components
designed to simulate ODEs. The basic dynamic component of the analog
computer is an integrator, constructed from an operational ampliﬁer with
a capacitor feedback and a resistor feed-forward as shown in Fig. 2.29.
Because an integrator is a device whose input is the derivative of its output,
as shown in Fig. 7.3, if, in an analog-computer simulation, we identify
the outputs of the integrators as the state, we will then automatically have
the equations in state-variable form. Conversely, if a system is described
by state-variables, we can construct an analog-computer simulation of that
system by taking one integrator for each state-variable and connecting its
input according to the given equation for that state-variable as expressed in
Figure 7.3
An integrator
1
s
x
x
3As well as due to its historical signiﬁcance.

7.3 Block Diagrams and State-Space
443
the state-variable equations. The analog-computer diagram is a picture of
the state equations.
The components of a typical analog computer used to accomplish these
functions are shown in Fig. 7.4. Notice that the operational ampliﬁer has a
sign change that gives it a negative gain.
EXAMPLE 7.7
Analog-Computer Implementation
Find a state-variable description and the transfer function of the third-order
system shown in Fig. 7.5 whose differential equation is
...y + 6¨y + 11˙y + 6y = 6u.
Solution. We solve for the highest derivative term in the ODE to obtain
...y = −6¨y −11˙y −6y + 6u.
(7.8)
Now we assume that we have this highest derivative and note that the lower
order terms can be obtained by integration as shown in Fig. 7.6(a). Finally,
we apply Eq. (7.8) to complete the realization shown in Fig. 7.6(b). To obtain
the state description, we simply deﬁne the state-variables as the output of
the integrators x1 = ¨y, x2 = ˙y, x3 = y, to obtain
˙x1 = −6x1 −11x2 −6x3 + 6u,
˙x2 = x1,
˙x3 = x2,
Figure 7.4
Components of an
analog computer
10
1
10
1
e1
e2
e1
e1
e2
e0  = •
e0  = -(10e1+e2)
e0  =  ke1
(10e1+e2) dt + IC
0 
k
1
k
IC
t
0
Integrator
Summer
Potentiometer
Figure 7.5
Block diagram for a
third-order system
 + 
 + 
 + 
 + 
y
1
s
1
s
1
s
x1
x2
x3
u
6
 -6
-11
 -6
©

444
Chapter 7 State-Space Design
Figure 7.6
Block diagram of a
system to solve
...y +6¨y+11˙y+6y = 6u,
using only integrators
as dynamic elements:
(a) intermediate
diagram; (b) ﬁnal
diagram
+
+
+
+
1
s
1
s
1
s
y
y
y
y
u
6
-6
-11
-6
1
s
1
s
1
s
y
y
y
y
(b)
(a)
©
which provides the state-variable description
A =
⎡
⎣
−6
−11
−6
1
0
0
0
1
0
⎤
⎦,
B =
⎡
⎣
6
0
0
⎤
⎦,
C = [ 0
0
1 ],
D = 0.
The Matlab statement
[num,den]=ss2tf(A,B,C,D)
will yield the transfer function
Y(s)
U(s) =
6
s3 + 6s2 + 11s + 6.
If the transfer function were desired in factored form, it could be obtained by
transforming either the ss or tf description. Therefore, either of the Matlab
statements
[z,p,k] = ss2zp(A,B,C,D)
and
[z,p,k] = tf2zp(num,den)
would result in
z = [],
p =
 −3
−2
−1 ′ ,
k = 6.
This means that the transfer function could also be written in factored form as
Y(s)
U(s) = G(s) =
6
(s + 1)(s + 2)(s + 3).
7.4
Analysis of the State Equations
In the previous section we introduced and illustrated the process of selecting
a state and organizing the equations in state form. In this section we review
that process and describe how to analyze the dynamic response using the

7.4 Analysis of the State Equations
445
state description. In Section 7.4.1 we begin by relating the state description
to block diagrams and the Laplace transform description and to consider the
fact that for a given system the choice of state is not unique. We show how to
use this nonuniqueness to select among several canonical forms for the one
that will help solve the particular problem at hand; a control canonical form
makes feedback gains of the state easy to design.After studying the structure
of state equations in Section 7.4.2, we consider the dynamic response and
show how transfer-function poles and zeros are related to the matrices of
the state descriptions. To illustrate the results with hand calculations, we
offer a simple example that represents the model of a thermal system. For
more realistic examples, a computer-aided control systems design software
package such as Matlab is especially helpful; relevant Matlab commands
will be described from time to time.
7.4.1
Block Diagrams and Canonical Forms
We begin with a thermal system that has a simple transfer function
G(s) = b(s)
a(s) =
s + 2
s2 + 7s + 12 =
2
s + 4 + −1
s + 3.
(7.9)
The roots of the numerator polynomial b(s) are the zeros of the transfer
function, and the roots of the denominator polynomial a(s) are the poles.
Notice that we have represented the transfer function in two forms, as a ratio
of polynomials and as the result of a partial-fraction expansion. In order
to develop a state description of this system (and this is a generally useful
technique), we construct a block diagram that corresponds to the transfer
function (and the differential equations) using only isolated integrators as the
dynamic elements. We present several special forms which we call canonical
forms. One such block diagram, structured in control canonical form, is
drawn in Fig. 7.7. The central feature of this structure is that each state-
variable feeds back to the control input, u, through the coefﬁcients of the
system matrix Ac.
Once we have drawn the block diagram in this form, we can identify
the state description matrices simply by inspection; this is possible because
when the output of an integrator is a state-variable, the input of that integrator
Figure 7.7
A block diagram
representing Eq. (7.9) in
control canonical form
Y
+
+
+
U
2
s
1
s
1
+
+
-7
-12
1
x2
+
x1 x2
x1
©
©
©

446
Chapter 7 State-Space Design
is the derivative of that variable. For example, in Fig. 7.7, the equation for
the ﬁrst state-variable is
˙x1 = −7x1 −12x2 + u.
Continuing in this fashion, we get
˙x2 = x1,
y = x1 + 2x2.
These three equations can then be rewritten in the matrix form
˙x = Acx + Bcu,
(7.10)
y = Ccx,
(7.11)
where
Ac =
 −7
−12
1
0
	
,
Bc =
 1
0
	
,
(7.12a)
Cc = [ 1
2 ],
Dc = 0,
(7.12b)
and where the subscript c refers to control canonical form.
Two signiﬁcant facts about this form are that the coefﬁcients 1 and 2 of
the numerator polynomial b(s) appear in the Cc matrix, and (except for the
leading term) the coefﬁcients 7 and 12 of the denominator polynomial a(s)
appear (with opposite signs) as the ﬁrst row of the Ac matrix. Armed with
this knowledge, we can thus write down by inspection the state matrices
in control canonical form for any system whose transfer function is known
as a ratio of numerator and denominator polynomials. If b(s) = b1sn−1 +
b2sn−2 + · · · + bn and a(s) = sn + a1sn−1 + a2sn−2 + · · · + an, the Matlab
Matlab tf2ss
steps are
num = b = [b1
b2
· · ·
bn ]
den = a = [1
a1
a2
· · ·
an]
[Ac,
Bc,
Cc,
Dc] = tf2ss(num,den).
We read tf2ss as "transfer function to state-space." The result will be
Control canonical form
Ac =
⎡
⎢⎢⎢⎢⎢⎣
−a1
−a2
· · ·
· · ·
−an
1
0
· · ·
· · ·
0
0
1
0
· · ·
0
...
...
0
...
0
0 · · ·
· · ·
1
0
⎤
⎥⎥⎥⎥⎥⎦
,
Bc =
⎡
⎢⎢⎢⎢⎢⎣
1
0
0
...
0
⎤
⎥⎥⎥⎥⎥⎦
,
(7.13a)
Cc =
 b1
b2
· · ·
· · ·
bn

,
Dc = 0.
(7.13b)
The block diagram of Fig. 7.7 and the corresponding matrices of
Eq. (7.12) are not the only way to represent the transfer function G(s).
A block diagram corresponding to the partial-fraction expansion of G(s) is
given in Fig. 7.8. Using the same technique as before, with the state-variables

7.4 Analysis of the State Equations
447
Figure 7.8
Block diagram for
Eq. (7.12) in modal
canonical form
Y
+
+
U
2
s
1
s
1
+
+
-4
z1
-1
-3
+
+
z2
z1
z2
©
©
©
marked as shown in the ﬁgure, we can determine the matrices directly from
the block diagram as being
˙z = Amz + Bmu,
y = Cmz + Dmu,
where
Am =
−4
0
0
−3
	
,
Bm =
1
1
	
,
(7.14a)
Cm = [
2
−1 ],
Dm = 0,
(7.14b)
and the subscript m refers to modal canonical form. The name for this
Modal form
form derives from the fact that the poles of the system transfer function are
sometimes called the normal modes of the system. The important fact about
the matrices in this form is that the system poles (here −4 and −3) appear
as the elements along the diagonal of the Am matrix, and the residues, the
numerator terms in the partial-fraction expansion (here 2 and −1), appear in
the Cm matrix.
Expressing a system in modal canonical form can be complicated by
two factors: (1) the elements of the matrices will be complex when the poles
of the system are complex and (2) the system matrix cannot be diagonal
when the partial-fraction expansion has repeated poles. To solve the ﬁrst
problem, we express the complex poles of the partial-fraction expansion as
conjugatepairsinsecond-ordertermssothatalltheelementsremainreal. The
corresponding Am matrix will then have 2×2 blocks along the main diagonal
representing the local coupling between the variables of the complex-pole
set. To handle the second difﬁculty, we also couple the corresponding state-
variables, so that the poles appear along the diagonal with off-diagonal terms
indicating the coupling. A simple example of this latter case is the satellite
system from Example 7.1, whose transfer function is G(s) = 1/s2. The
system matrices for this transfer function in a modal form are
Am =
 0
1
0
0
	
,
Bm =
 0
1
	
,
Cm = [ 1
0 ],
Dm = 0.
(7.15)

448
Chapter 7 State-Space Design
EXAMPLE 7.8
State Equations in Modal Canonical Form
A "quarter car model" [see Eq. (2.12)] with one resonant mode has a transfer
function given by
G(s) =
2s + 4
s2(s2 + 2s + 4) = 1
s2 −
1
s2 + 2s + 4.
(7.16)
Find state matrices in modal form describing this system.
Solution. The transfer function has been given in real partial-fraction form.
To get state-description matrices, we draw a corresponding block diagram
with integrators only, assign the state, and write down the corresponding
matrices. This process is not unique, so there are several acceptable solutions
to the problem as stated, but they will differ in only trivial ways. A block
diagram with a satisfactory assignment of variables is given in Fig. 7.9.
Notice that the second-order term to represent the complex poles has
been realized in control canonical form. There are a number of other pos-
sibilities that can be used as alternatives for this part. This particular form
allows us to write down the system matrices by inspection:
A =
⎡
⎢⎢⎣
0
0
0
0
1
0
0
0
0
0
−2
−4
0
0
1
0
⎤
⎥⎥⎦,
B =
⎡
⎢⎢⎣
1
0
1
0
⎤
⎥⎥⎦,
C = [ 0
1
0
−1 ],
D = 0.
(7.17)
Thus far, we have seen that we can obtain the state description from
a transfer function in either control or modal form. Because these matrices
represent the same dynamic system, we might ask as to, what is the rela-
tionship between the matrices in the two forms (and their corresponding
state-variables)? More generally, suppose we have a set of state equations
that describe some physical system in no particular form, and we are given a
problem for which the control canonical form would be helpful. (We will see
suchaprobleminSection7.5.) Isitpossibletocalculatethedesiredcanonical
Figure 7.9
Block diagram for a
fourth-order system in
modal canonical form
with shading indicating
portion in control
canonical form
Y
+
+
U
-1
s
1
s
1
+
+
-2
-4
x3
x4
s
1
s
1
+
+
x1
x3
x1
x2
©
©
©

7.4 Analysis of the State Equations
449
form without obtaining the transfer function ﬁrst? To answer these questions
requires a look at the topic of state transformations.
Consider a system described by the state equations
State description and
output
equation
˙x = Ax + Bu,
(7.18a)
y = Cx + Du.
(7.18b)
As we have seen, this is not a unique description of the dynamic system. We
considerachangeofstatefromx toanewstatezthatisalineartransformation
of x. For a nonsingular transformation matrix T, we let
x = Tz.
(7.19)
By substituting Eq. (7.19) into Eq. (7.18a), we have the dynamic
equations in terms of the new state z:
˙x = T˙z = ATz + Bu,
(7.20a)
˙z = T−1ATz + T−1Bu,
(7.20b)
˙z = ¯Az + ¯Bu.
(7.20c)
In Eq. (7.20c),
Transformation of state
¯A = T−1AT,
(7.21a)
¯B = T−1B.
(7.21b)
Then we substitute Eq. (7.19) into Eq. (7.18b) to get the output in terms of
the new state z:
y = CTz + Du
= ¯Cz + ¯Du.
Here
¯C = CT,
¯D = D.
(7.22)
Given the general matrices A, B, and C and scalar D, we would like to
ﬁnd the transformation matrix T such that ¯A, ¯B, ¯C, and ¯D are in a particular
form, for example, control canonical form. To ﬁnd such a T, we assume
that A, B, C, and D are already in the required form, further assume that
the transformation T has a general form, and match terms. Here we will
work out the third-order case; how to extend the analysis to the general case
should be clear from the development. It goes like this.
First we rewrite Eq. (7.21a) as
¯AT−1 = T−1A.
If ¯A is in control canonical form, and we describe T−1 as a matrix with rows
t1, t2, and t3, then
⎡
⎣
−a1
−a2
−a3
1
0
0
0
1
0
⎤
⎦
⎡
⎣
t1
t2
t3
⎤
⎦=
⎡
⎣
t1A
t2A
t3A
⎤
⎦.
(7.23)

450
Chapter 7 State-Space Design
Working out the third and second rows gives the matrix equations
t2 = t3A,
(7.24a)
t1 = t2A = t3A2.
(7.24b)
From Eq. (7.21b), assuming that ¯B is also in control canonical form, we have
the relation
T−1B = ¯B,
or
⎡
⎣
t1B
t2B
t3B
⎤
⎦=
⎡
⎣
1
0
0
⎤
⎦.
(7.25)
Combining Eqs. (7.24) and (7.25), we get
t3B = 0,
t2B = t3AB = 0,
t1B = t3A2B = 1.
These equations can, in turn, be written in matrix form as
t3[ B
AB
A2B ] = [ 0
0
1 ],
or
t3 = [ 0
0
1 ]C−1,
(7.26)
where the controllability matrix C = [ B
AB
A2B ]. Having t3, we
Controllability matrix
transformation to control
canonical form
can now go back to Eq. (7.24) and construct all the rows of T−1.
To sum up, the recipe for converting a general state description of
dimension n to control canonical form is as follows:
•
From A and B, form the controllability matrix
C = [ B
AB
· · ·
An−1B ].
(7.27)
•
Compute the last row of the inverse of the transformation matrix as
tn = [ 0
0
· · ·
1 ]C−1.
(7.28)
•
Construct the entire transformation matrix as
T−1 =
⎡
⎢⎢⎢⎣
tnAn−1
tnAn−2
...
tn
⎤
⎥⎥⎥⎦.
(7.29)
•
Compute the new matrices from T−1, using Eqs. (7.21a), (7.21b), and
(7.22).
When the controllability matrix C is nonsingular, the corresponding A
and B matrices are said to be controllable. This is a technical property that
Controllable systems
usually holds for physical systems and will be important when we consider
feedback of the state in Section 7.5. We will also consider a few physical
illustrations of loss of controllability at that time.

7.4 Analysis of the State Equations
451
Because computing the transformation given by Eq. (7.29) is numer-
ically difﬁcult to do accurately, it is almost never done. The reason for
developing this transformation in some detail is to show how such changes
of state could be done in theory and to make the following important
observation:
One can always transform a given state description to control
canonical form if (and only if) the controllability matrix C is
nonsingular.
If we need to test for controllability in a real case with numbers, we use a
numerically stable method that depends on converting the system matrices to
"staircase" form rather than on trying to compute the controllability matrix.
Problem 7.30 at the end of the chapter calls for consideration of this method.
An important question regarding controllability follows directly from
our discussion so far: What is the effect of a state transformation on control-
lability? We can show the result by using Eqs. (7.27), (7.21a), and (7.21b).
The controllability matrix of the system (A, B) is
Cx = [ B
AB
· · ·
An−1B ].
(7.30)
After the state transformation, the new description matrices are given by
Eqs. (7.21a) and (7.21b), and the controllability matrix changes to
Cz = [ ¯B
¯A ¯B
· · ·
¯An−1 ¯B ]
(7.31a)
= [ T−1B
T−1ATT−1B
· · ·
T−1An−1TT−1B ] (7.31b)
= T−1Cx.
(7.31c)
Thus we see that Cz is nonsingular if and only if Cx is nonsingular, yielding
the following observation:
A change of state by a nonsingular linear transformation does not
change controllability.
We return once again to the transfer function of Eq. (7.9), this time to
represent it with the block diagram having the structure known as observer
Observer canonical form
canonical form (Fig. 7.10). The corresponding matrices for this form are
Ao =

−7
1
−12
0
	
,
Bo =
 1
2
	
,
(7.32a)
Co =

1
0 
,
Do = 0.
(7.32b)
The signiﬁcant fact about this canonical form is that the output feeds back
to each one of the state-variables through the coefﬁcients of the system
matrix Ao.

452
Chapter 7 State-Space Design
Figure 7.10
Observer canonical form
for the second-order
system
U
s
1
+
+
2
-12
Y
+
+
-7
s
1
+
x1
x2
x1
x2
©
©
Let us now consider what happens to the controllability of this system
as the zero at −2 is varied. For this purpose, we replace the second element 2
of Bo with the variable zero location −zo and form the controllability matrix:
Cx = [ Bo
AoBo ]
(7.33a)
=
 1
−7 −zo
−zo
−12
	
.
(7.33b)
The determinant of this matrix is a function of zo:
det(Cx) = −12 + (zo)(−7 −zo)
= −(z2
o + 7zo + 12).
This polynomial is zero for zo = −3 or −4, implying that controllability is
lost for these values. What does this mean? In terms of the parameter zo, the
transfer function is
G(s) =
s −zo
(s + 3)(s + 4).
If zo = −3 or −4, there is a pole-zero cancellation and the transfer function
reduces from a second-order system to a ﬁrst-order one. When zo = −3,
for example, the mode at −3 is decoupled from the input and control of this
mode is lost.
Notice that we have taken the transfer function given by Eq. (7.9) and
given it two realizations, one in control canonical form and one in observer
canonical form. The control form is always controllable for any value of
the zero, while the observer form loses controllability if the zero cancels
either of the poles. Thus, these two forms may represent the same transfer
function, but it may not be possible to transform the state of one to the state of
the other (in this case, from observer to control canonical form). Although
a transformation of state cannot affect controllability, the particular state
selected from a transfer function can:
Controllability is a function of the state of the system and cannot
be decided from a transfer function.
To discuss controllability more at this point would take us too far aﬁeld.
The closely related property of observability and the observer canonical

7.4 Analysis of the State Equations
453
form will be taken up in Section 7.7.1. A more detailed discussion of these
properties of dynamic systems is given in the Appendix WC available at
www. fpe7e.com, for those who would like to learn more.
We return now to the modal form for the equations, given by Eqs. (7.14a)
and (7.14b) for the example transfer function. As mentioned before, it is not
always possible to ﬁnd a modal form for transfer functions that have repeated
poles, so we assume our system has only distinct poles. Furthermore, we
assume that the general state equations given by Eqs. (7.18a) and (7.18b)
apply. We want to ﬁnd a transformation matrix T deﬁned by Eq. (7.19) such
that the transformed Eqs. (7.21a) and (7.22) will be in modal form. In this
case, we assume that the A matrix is diagonal and that T is composed of
the columns t1, t2, and t3. With this assumption, the state transformation
Eq. (7.21a) becomes
T ¯A = AT
 t1
t2
t3

⎡
⎣
p1
0
0
0
p2
0
0
0
p3
⎤
⎦= A[ t1
t2
t3 ].
(7.34)
Equation (7.34) is equivalent to the three vector-matrix equations
Transformation to modal
form
piti = Ati,
i = 1, 2, 3.
(7.35)
In matrix algebra Eq. (7.35) is a famous equation, whose solution is known
as the eigenvector/eigenvalue problem. Recall that ti is a vector, A is a
Eigenvectors
matrix, and pi is a scalar. The vector ti is called an eigenvector of A, and
pi is called the corresponding eigenvalue. Because we saw earlier that the
Eigenvalues
modal form is equivalent to a partial-fraction-expansion representation with
the system poles along the diagonal of the state matrix, it should be clear that
these "eigenvalues" are precisely the poles of our system. The transformation
matrix that will convert the state description matrices to modal form has as
its columns the eigenvectors of A, as shown in Eq. (7.34) for the third-
order case. As it happens, there are robust, reliable computer algorithms to
compute eigenvalues and the eigenvectors of quite large systems using the
QR algorithm.4 In Matlab, the command p = eig(A) is the way to compute
Matlab eig
the poles if the system equations are in state form.
Notice also that Eq. (7.35) is homogeneous in that, if ti is an eigenvector,
so is αti, for any scalar α. In most cases the scale factor is selected so that the
length (square root of the sum of squares of the magnitudes of the elements)
is unity. Matlab will perform this operation. Another option is to select the
scale factors so that the input matrix ¯B is composed of all 1's. The latter
choice is suggested by a partial-fraction expansion with each part realized
in control canonical form. If the system is real, then each element of A is
real, and if p = σ + jω is a pole, so is the conjugate, p∗= σ −jω. For these
eigenvalues, the eigenvectors are also complex and conjugate. It is possible
to compose the transformation matrix using the real and complex parts of
4This algorithm is part of Matlab and all other well-known computer-aided design packages.
It is carefully documented in the software package LAPACK (Anderson et al., 1999). See also
Strang (2006).

454
Chapter 7 State-Space Design
the eigenvectors separately, so the modal form is real but has 2 × 2 blocks
for each pair of complex poles. Later, we will see the result of the Matlab
function that does this, but ﬁrst let us look at the simple real-poles case.
EXAMPLE 7.9
Transformation of Thermal System from Control to Modal Form
Find the matrix to transform the control form matrices in Eq. (7.12) into the
modal form of Eq. (7.14).
Solution.
According to Eqs. (7.34) and (7.35), we need ﬁrst to ﬁnd the
eigenvectors and eigenvalues of the Ac matrix. We take the eigenvectors to be
 t11
t21
	
and
 t12
t22
	
.
The equations using the eigenvector on the left are
 −7
−12
1
0
	  t11
t21
	
= p
 t11
t21
	
,
(7.36a)
−7t11 −12t21 = pt11,
(7.36b)
t11 = pt21.
(7.36c)
Substituting Eq. (7.36c) into Eq. (7.36b) results in
−7pt21 −12t21 = p2t21,
(7.37a)
p2t21 + 7pt21 + 12t21 = 0,
(7.37b)
p2 + 7p + 12 = 0,
(7.37c)
p = −3, −4.
(7.37d)
We have found (again!) that the eigenvalues (poles) are −3 and −4;
furthermore, Eq. (7.36c) tells us that the two eigenvectors are
 −4t21
t21
	
and
 −3t22
t22
	
,
where t21 and t22 are arbitrary nonzero scale factors. We want to select the
two scale factors such that both elements of Bm in Eq. (7.14a) are unity. The
equation for Bm in terms of Bc is TBm = Bc, and its solution is t21 = −1
and t22 = 1. Therefore, the transformation matrix and its inverse5 are
T =

4
−3
−1
1
	
,
T−1 =
 1
3
1
4
	
.
(7.38)
Elementary matrix multiplication shows that, using T as deﬁned by
Eq. (7.38), the matrices of Eqs. (7.12) and (7.14) are related as follows:
Am = T−1AcT,
Bm = T−1Bc,
Cm = CcT,
Dm = Dc.
(7.39)
5To ﬁnd the inverse of a 2×2 matrix, you need only interchange the elements subscripted "11"
and "22," change the signs of the "12" and the "21" elements, and divide by the determinant
[= 1 in Eq. (7.38)].

7.4 Analysis of the State Equations
455
These computations can be carried out by using the following Matlab
statements
T = [4 −3; −1 1];
Am = inv(T)*Ac*T;
Bm = inv(T)*Bc;
Cm = Cc*T;
Dm = Dc;
The next example has ﬁve state-variables and, in state-variable form,
is too complicated for hand calculations. However, it is a good example
for illustrating the use of computer software designed for the purpose. The
model we will use is based on a physical state after amplitude and time
scaling have been done.
EXAMPLE 7.10
Using Matlab to Find Poles and Zeros of Tape-Drive System
Find the eigenvalues of the system matrix described below for the tape-drive
control (see Fig. 3.50). Also, compute the transformation of the equations
of the tape drive in their given form to modal canonical form. The system
matrices are
A =
⎡
⎢⎢⎢⎢⎣
0
2
0
0
0
−0.1
−0.35
0.1
0.1
0.75
0
0
0
2
0
0.4
0.4
−0.4
−1.4
0
0
−0.03
0
0
−1
⎤
⎥⎥⎥⎥⎦
,
B =
⎡
⎢⎢⎢⎢⎣
0
0
0
0
1
⎤
⎥⎥⎥⎥⎦
,
(7.40)
C2 =
0.0
0.0
1.0
0.0
0.0
Servomotor position output,
C3 =
0.5
0.0
0.5
0.0
0.0
Position at read/write head as output,
CT =
−0.2
−0.2
0.2
0.2
0.0
Tension output,
D = 0.0.
The state vector is deﬁned as
x =
⎡
⎢⎢⎢⎢⎣
x1 (tape position at capstan)
ω1 (speed of the drive wheel)
x3 (position of the tape at the head)
ω2 (output speed)
i
(current into capstan motor)
⎤
⎥⎥⎥⎥⎦
.
The matrix C3 corresponds to making x3 (the position of the tape over the
read/writehead)theoutput, andthematrixCT correspondstomakingtension
the output.
Solution. To compute the eigenvalues using Matlab, we write
P = eig(A),

456
Chapter 7 State-Space Design
which results in
P =
⎡
⎢⎢⎢⎢⎣
−0.6371 + 0.6669i
−0.6371 −0.6669i
0.0000
−0.5075
−0.9683
⎤
⎥⎥⎥⎥⎦
.
Notice that the system has all poles in the left half-plane (LHP) except for
one pole at the origin. This means that a step input will result in a ramp
output, so we conclude that the system has Type 1 behavior.
To transform to modal form, we use the Matlab function canon:
Matlab canon
sysG = ss(A,B,C3,D);
[sysGm,TI]=canon(sysG,'modal');
[Am,Bm,Cm,Dm]=ssdata(sysGm)
The result of this computation is
Am = Am =
⎡
⎢⎢⎢⎢⎣
−0.6371
0.6669
0.0000
0.0000
0.0000
−0.6669
−0.6371
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
−0.5075
0.0000
0.0000
0.0000
0.0000
0.0000
−0.9683
⎤
⎥⎥⎥⎥⎦
.
Notice that the complex poles appear in the 2 × 2 block in the upper-left
corner of Am, and the real poles fall on the main diagonal of this matrix. The
rest of the computations from canon are
Bm = Bm =
⎡
⎢⎢⎢⎢⎣
0.4785
−0.6274
−1.0150
−3.5980
4.9133
⎤
⎥⎥⎥⎥⎦
,
Cm = Cm = [ 1.2569
−1.0817
−2.8284
1.8233
0.4903 ],
Dm = Dm = 0,
T I = T−1 =
⎡
⎢⎢⎢⎢⎣
−0.3439
−0.3264
0.3439
0.7741
0.4785
0.1847
−0.7291
−0.1847
0.0969
−0.6247
−0.1844
−1.3533
−0.1692
−0.3383
−1.0150
0.3353
−2.3627
−0.3353
−1.0161
−3.5980
−0.0017
0.2077
0.0017
0.0561
4.9133
⎤
⎥⎥⎥⎥⎦
.
It happens that canon was written to compute the inverse of the transforma-
tion we are working with (as you can see from TI in the previous equation),
so we need to invert our Matlab results. The inverse is computed from
T = inv(T I)

7.4 Analysis of the State Equations
457
and results in
T = T =
⎡
⎢⎢⎢⎢⎣
0.3805
0.8697
−2.8284
1.3406
0.4714
−0.4112
−0.1502
0.0000
−0.3402
−0.2282
2.1334
−3.0330
−2.8284
2.3060
0.5093
0.3317
1.6776
0.0000
−0.5851
−0.2466
0.0130
−0.0114
−0.0000
0.0207
0.2160
⎤
⎥⎥⎥⎥⎦
.
The eigenvectors computed with [V,P]=eig(F) are
Eigenvalues
V = V =
⎡
⎢⎢⎢⎢⎣
−0.1168 + 0.1925i
−0.1168 −0.1925i
−0.7071
0.4871
0.5887
−0.0270 −0.1003i
−0.0270 + 0.1003i
−0.0000
−0.1236
−0.2850
0.8797
0.8797
−0.7071
0.8379
0.6360
−0.2802 + 0.2933i
−0.2802 −0.2933i
−0.0000
−0.2126
−0.3079
0.0040 + 0.0010i
0.0040 −0.0010i
0.0000
0.0075
0.2697
⎤
⎥⎥⎥⎥⎦
.
Notice that the ﬁrst two columns of the real transformation T are com-
posed of the real and the imaginary parts of the ﬁrst eigenvector in the ﬁrst
column of V. It is this step that causes the complex roots to appear in the 2×2
block in the upper left of the Am matrix. The vectors in V are normalized
to unit length, which results in nonnormalized values in Bm and Cm. If we
found it desirable to do so, we could readily ﬁnd further transformations to
make each element of Bm equal 1 or to interchange the order in which the
poles appear.
7.4.2
Dynamic Response from the State Equations
Having considered the structure of the state-variable equations, we now turn
to ﬁnding the dynamic response from the state description and to the relation-
ships between the state description and our earlier discussion in Chapter 6
of the frequency response and poles and zeros. Let us begin with the gen-
eral equations of state given by Eqs. (7.18a) and (7.18b), and consider the
problem in the frequency domain. Taking the Laplace transform of
˙x = Ax + Bu,
(7.41)
we obtain
sX(s) −x(0) = AX(s) + BU(s),
(7.42)
which is now an algebraic equation. If we collect the terms involving X(s)
on the left side of Eq. (7.42), keeping in mind that in matrix multiplication
order is very important, we ﬁnd that6
(sI −A)X(s) = BU(s) + x(0).
6The identity matrix I is a matrix of ones on the main diagonal and zeros everywhere else;
therefore, Ix = x.

458
Chapter 7 State-Space Design
If we premultiply both sides by the inverse of (sI −A), then
X(s) = (sI −A)−1BU(s) + (sI −A)−1x(0).
(7.43)
The output of the system is
Y(s) = CX(s) + DU(s),
(7.44a)
= C(sI −A)−1BU(s) + C(sI −A)−1x(0) + DU(s).
(7.44b)
This equation expresses the output response to both an initial condition and
an external forcing input. Collecting the terms involving U(s) and assuming
Transfer function from
state equations
zero initial conditions result in the transfer function of the system,
G(s) = Y(s)
U(s) = C(sI −A)−1B + D.
(7.45)
EXAMPLE 7.11
Thermal System Transfer Function from the State Description
Use Eq. (7.45) to ﬁnd the transfer function of the thermal system described
by Eqs. (7.12a) and (7.12b).
Solution. The state-variable description matrices of the system are
A =
−7
−12
1
0
	
,
B =
1
0
	
,
C = [ 1
2 ],
D = 0.
To compute the transfer function according to Eq. (7.45), we form
sI −A =
 s + 7
12
−1
s
	
,
and compute
(sI −A)−1 =
 s
−12
1
s + 7
	
s(s + 7) + 12 .
(7.46)
We then substitute Eq. (7.46) into Eq. (7.45) to get
G(s) =
[ 1
2 ]
 s
−12
1
s + 7
	  1
0
	
s(s + 7) + 12
(7.47)
=
[ 1
2 ]
 s
1
	
s(s + 7) + 12
(7.48)
=
(s + 2)
(s + 3)(s + 4).
(7.49)
The results can also be found using the Matlab statements,
[num,den] = ss2tf(A,B,C,D)

7.4 Analysis of the State Equations
459
and yield num = [0 1 2] and den = [1 7 12], which agrees with the hand
calculations above.
Because Eq. (7.45) expresses the transfer function in terms of the general
state-space descriptor matrices A, B, C, and D, we are able to express poles
and zeros in terms of these matrices. We saw earlier that by transforming the
state matrices to diagonal form, the poles appear as the eigenvalues on the
main diagonal of the A matrix. We now take a systems theory point of view
to look at the poles and zeros as they are involved in the transient response
of a system.
As we saw in Chapter 3, a pole of the transfer function G(s) is a value
of generalized frequency s such that, if s = pi, then the system can respond
to an initial condition as Kiepit, with no forcing function u. In this context,
pi is called a natural frequency or natural mode of the system. If we take
the state-space equations (7.18a and 7.18b) and set the forcing function u to
zero, we have
˙x = Ax.
(7.50)
If we assume some (as yet unknown) initial condition
x(0) = x0,
(7.51)
and that the entire state motion behaves according to the same natural fre-
quency, then the state can be written as x(t) = epitx0. It follows from
Eq. (7.50) that
˙x(t) = piepitx0 = Ax = Aepitx0,
(7.52)
or
Ax0 = pix0.
(7.53)
We can rewrite Eq. (7.53) as
( piI −A)x0 = 0.
(7.54)
Equations (7.53) and (7.54) constitute the eigenvector/eigenvalue problem
we saw in Eq. (7.35) with eigenvalues pi and, in this case, eigenvectors x0
of the matrix A. If we are just interested in the eigenvalues, we can use the
Transfer function poles
from state equations
fact that for a nonzero x0, Eq. (7.54) has a solution if and only if
det( piI −A) = 0.
(7.55)
These equations show again that the poles of the transfer function are the
eigenvalues of the system matrix A. The determinant equation (7.55) is a
polynomial in the eigenvalues pi known as the characteristic equation. In
Example 7.9 we computed the eigenvalues and eigenvectors of a particular
matrix in control canonical form. As an alternative computation for the poles
of that system, we could solve the characteristic equation (7.55). For the
system described by Eqs. (7.12a) and (7.12b), we can ﬁnd the poles from
Eq. (7.55) by solving
det(sI −A) = 0,
(7.56a)

460
Chapter 7 State-Space Design
det
 s + 7
12
−1
s
	
= 0,
(7.56b)
s(s + 7) + 12 = (s + 3)(s + 4) = 0.
(7.56c)
This conﬁrms again that the poles of the system are the eigenvalues of A.
We can also determine the transmission zeros of a system from the state-
variable description matrices A, B, C, and D using a systems theory point
of view. From this perspective, a zero is a value of generalized frequency
s such that the system can have a nonzero input and state and yet have an
output of zero. If the input is exponential at the zero frequency zi, given by
u(t) = u0ezit,
(7.57)
then the output is identically zero:
y(t) ≡0.
(7.58)
The state-space description of Eqs. (7.57) and (7.58) would be
u = u0ezit,
x(t) = x0ezit,
y(t) ≡0.
(7.59)
Thus
˙x = ziezitx0 = Aezitx0 + Bu0ezit,
(7.60)
or
[ziI −A
−B]
 x0
u0
	
= 0,
(7.61)
and
y = Cx + Du = Cezitx0 + Du0ezit ≡0.
(7.62)
Combining Eqs. (7.61) and (7.62), we get
 ziI −A
−B
C
D
	  x0
u0
	
=
 0
0
	
.
(7.63)
From Eq. (7.63) we can conclude that a zero of the state-space system is a
Transfer function zeros
from state equations
value of zi where Eq. (7.63) has a nontrivial solution. With one input and
one output, the matrix is square, and a solution to Eq. (7.63) is equivalent to
a solution to
det
 ziI −A
−B
C
D
	
= 0.
(7.64)
EXAMPLE 7.12
Zeros for the Thermal System from a State Description
Compute the zero(s) of the thermal system described by Eq. (7.12).
Solution. We use Eq. (7.64) to compute the zeros:
det
⎡
⎣
s + 7
12
−1
−1
s
0
1
2
0
⎤
⎦= 0,
−2 −s = 0,
s = −2.
Note that this result agrees with the zero of the transfer function given by
Eq. (7.9). The result can also be found using the following Matlab statements:

7.4 Analysis of the State Equations
461
sysG = ss(Ac,Bc,Cc,Dc);
[z,gain] = tzero(sysG)
and yields z = −2.0 and gain = 1.
Equation (7.55) for the characteristic equation and Eq. (7.64) for the
zeros polynomial can be combined to express the transfer function in a
compact form from state-description matrices as
G(s) =
det
 sI −A
−B
C
D
	
det(sI −A)
.
(7.65)
(See Appendix WB available at www. fpe7e.com for more details.) While
Eq. (7.65) is a compact formula for theoretical studies, it is very sensitive to
numerical errors. A numerically stable algorithm for computing the transfer
function is described in Emami-Naeini and Van Dooren (1982). Given the
transfer function, we can compute the frequency response as G( jω), and as
discussed earlier, we can use Eqs. (7.54) and (7.63) to ﬁnd the poles and
zeros, upon which the transient response depends, as we saw in Chapter 3.
EXAMPLE 7.13
Analysis of the State Equations of a Tape Drive
Compute the poles, zeros, and transfer function for the equations of the
tape-drive servomechanism given in Example 7.10.
Solution. There are two different ways to compute the answer to this prob-
lem. The most direct is to use the Matlab function ss2tf (state-space to
Matlab ss2tf
transfer function), which will give the numerator and denominator polyno-
mials directly. This function permits multiple inputs and outputs; the ﬁfth
argument of the function tells which input is to be used. We have only
one input here but must still provide the argument. The computation of
the transfer function from motor-current input to the servomotor position
output is
[N2, D2] = ss2tf(A, B, C2, D, 1),
which results in
N2 = [ 0
0
0.0000
0
0.6000
1.2000 ],
D2 = [ 1.0000
2.7500
3.2225
1.8815
0.4180
−0.0000 ].
Similarly, for the position at the read/write head, the transfer function
polynomials are computed by
[N3, D3] = ss2tf(A, B, C3, D, 1),
which results in
N3 = [ 0
−0.0000
−0.0000
0.7500
1.3500
1.2000 ],
D3 = [ 1.0000
2.7500
3.2225
1.8815
0.4180
−0.0000 ].

462
Chapter 7 State-Space Design
Finally, the transfer function to tension is
[NT, DT] = ss2tf(A, B, CT, D, 1),
producing
NT = [ 0
−0.0000
−0.1500
−0.4500
−0.3000
0.0000 ],
DT = [ 1.0000
2.7500
3.2225
1.8815
0.4180
−0.0000 ].
It is interesting to check to see whether the poles and zeros determined this
way agree with those found by other means. To ﬁnd the roots of a polynomial
Matlab roots
such as the one corresponding to D3, we use the Matlab function roots:
roots(D3) =
⎡
⎢⎢⎢⎢⎣
−0.6371 + 0.6669i
−0.6371 −0.6669i
−0.9683
−0.5075
0.0000
⎤
⎥⎥⎥⎥⎦
,
which yields the poles of the system. Checking with Example 7.10, we
conﬁrm that they agree.
How about the zeros? We can ﬁnd these by ﬁnding the roots of the
numerator polynomial. We compute the roots of the polynomial N3:
roots(N3) =
⎡
⎢⎢⎣
−0.76667 + 2.3727 × 107i
−0.76667 −2.3727 × 107i
−0.9000 + 0.8888i
−0.9000 −0.8888i
⎤
⎥⎥⎦.
Here we notice that the ﬁrst two roots are given with a magnitude of 107,
which seems inconsistent with the values given for the polynomial. The
problem is that Matlab has used the very small leading terms in the poly-
nomial as real values and thereby introduced extraneous roots that are for
all practical purposes at inﬁnity. The true zeros are found by truncating the
polynomial to the signiﬁcant values using the statement
N3R = N3(4 : 6),
to get
N3R = [ 0.7499
1.3499
1.200 ],
roots(N3R) =
 −0.9000 + 0.8888i
−0.9000 −0.8888i
	
.
The other approach is to compute the poles and zeros separately and,
if desired, combine these into a transfer function. The poles were computed
with eig in Example 7.10 and are
P =
⎡
⎢⎢⎢⎢⎣
−0.6371 + 0.6669i
−0.6371 −0.6669i
0.0000
−0.5075
−0.9683
⎤
⎥⎥⎥⎥⎦
.

7.5 Control-Law Design for Full-State Feedback
463
The zeros can be computed by the equivalent of Eq. (7.63) with the function
Matlab tzero
tzero (transmission zeros). The zeros depend on which output is being used,
of course, and are respectively given below. For the position of the tape at
the servomotor as the output, the statement
sysG2 = ss(A, B, C2, D)
[ZER2, gain2] = tzero(sysG2)
yields
ZER2 = −2.0000, gain2 = 0.6.
For the position of the tape over the read/write head as the output, we use
the statement
sysG3 = ss(A, B, C3, D)
[ZER3, gain3] = tzero(sysG3)
ZER3 =
 −0.9000 + 0.8888i
−0.9000 −0.8888i
	
, gain3 = 0.75.
We note that these results agree with the values previously computed from
the numerator polynomial N3. Finally, for the tension as output, we use
sysGT = ss(A, B, CT, D)
[ZERT, gainT] = tzero(sysGT)
to get
ZERT =
⎡
⎣
0
−1.9999
−1.0000
⎤
⎦, gainT = −0.15.
From these results we can write down, for example, the transfer function
to position x3 as
G(s) = X3(s)
E1(s)
=
0.75s2 + 1.35s + 1.2
s5 + 2.75s4 + 3.22s3 + 1.88s2 + 0.418s
=
0.75(s + 0.9 ± 0.8888j)
s(s + 0.507)(s + 0.968)(s + 0.637 ± 0.667j).
(7.66)
7.5
Control-Law Design for Full-State Feedback
One of the attractive features of the state-space design method is that it
consists of a sequence of independent steps, as mentioned in the chapter
overview. The ﬁrst step, discussed in Section 7.5.1, is to determine the

464
Chapter 7 State-Space Design
control law. The purpose of the control law is to allow us to assign a set of
pole locations for the closed-loop system that will correspond to satisfactory
dynamic response in terms of rise time and other measures of transient
response. In Section 7.5.2 we will show how to introduce the reference input
with full-state feedback, and in Section 7.6 we will describe the process of
ﬁnding the poles for good design.
The second step—necessary if the full state is not available—is to design
an estimator (sometimes called an observer), which computes an estimate
Estimator/observer
of the entire state vector when provided with the measurements of the system
indicated by Eq. (7.18b). We will examine estimator design in Section 7.7.
The third step consists of combining the control law and the estimator.
Figure 7.11 shows how the control law and the estimator ﬁt together and how
the combination takes the place of what we have been previously referring
to as compensation. At this stage, the control-law calculations are based on
The control law and the
estimator together form
the compensation
the estimated state rather than the actual state. In Section 7.8 we will show
that this substitution is reasonable, and also that using the combined control
law and estimator results in closed-loop pole locations that are the same as
those determined when designing the control and estimator separately.
The fourth and ﬁnal step of state-space design is to introduce the refer-
ence input in such a way that the plant output will track external commands
with acceptable rise-time, overshoot, and settling-time values. At this point
in the design, all the closed-loop poles have been selected, and the designer is
concerned with the zeros of the overall transfer function. Figure 7.11 shows
the command input r introduced in the same relative position as was done
with the transform design methods; however, in Section 7.9 we will show
how to introduce the reference at another location, resulting in different zeros
and (usually) superior control.
7.5.1
Finding the Control Law
The ﬁrst step in the state-space design method, as mentioned earlier, is to ﬁnd
the control law as feedback of a linear combination of the state-variables—
Control law
that is,
Figure 7.11
Schematic diagram of
state-space
+
-
C
-K
Control law
Estimator
xˆ
Plant
Matrix of
constants
State vector
estimate
Y
Compensation
u
R
x
x = Ax + Bu
©

7.5 Control-Law Design for Full-State Feedback
465
u = −Kx = −[ K1
K2
· · ·
Kn ]
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦.
(7.67)
We assume for feedback purposes that all the elements of the state vector
are at our disposal which is why we refer to this as "full-state," feedback. In
practice, of course, this would usually be a ridiculous assumption; moreover,
a well-trained control designer knows that other design methods do not
require so many sensors. The assumption that all state-variables are available
merely allows us to proceed with this ﬁrst step.
Equation (7.67) tells us that the system has a constant matrix in the
state-vector feedback path, as shown in Fig. 7.12. For an nth-order system,
there will be n feedback gains, K1, . . . , Kn, and because there are n roots of
the system, it is possible that there are enough degrees of freedom to select
arbitrarily any desired root location by choosing the proper values of Ki.
This freedom contrasts sharply with root-locus design, in which we have
only one parameter and the closed-loop poles are restricted to the locus.
Substituting the feedback law given by Eq. (7.67) into the system
described by Eq. (7.18a) yields
˙x = Ax −BKx.
(7.68)
The characteristic equation of this closed-loop system is
Control characteristic
equation
det[sI −(A −BK)] = 0.
(7.69)
When evaluated, this yields an nth-order polynomial in s containing the gains
K1, . . . , Kn. The control-law design then consists of picking the gains K so
that the roots of Eq. (7.69) are in desirable locations. Selecting desirable
root locations is an inexact science that may require some iteration by the
designer. Issues in their selection are considered in Examples 7.14 to 7.16
as well as in Section 7.6. For now, we assume that the desired locations are
known, say,
s = s1, s2, . . . , sn.
Then the corresponding desired (control) characteristic equation is
αc(s) = (s −s1)(s −s2) . . . (s −sn) = 0.
(7.70)
Hence the required elements of K are obtained by matching coefﬁcients in
Eqs. (7.69) and (7.70). This forces the system's characteristic equation to be
identical to the desired characteristic equation and the closed-loop poles to
be placed at the desired locations.
Figure 7.12
Assumed system for
control-law
C
Y
u
x
u = -Kx
x = Ax + Bu

466
Chapter 7 State-Space Design
EXAMPLE 7.14
Control Law for a Pendulum
Suppose you have a pendulum with frequency ω0 and a state-space
description given by
 ˙x1
˙x2
	
=

0
1
−ω2
0
0
	  x1
x2
	
+
 0
1
	
u.
(7.71)
Find the control law that places the closed-loop poles of the system so
that they are both at −2ω0. In other words, you wish to double the natural
frequency and increase the damping ratio ζ from 0 to 1.
Solution. From Eq. (7.70) we ﬁnd that
αc(s) = (s + 2ω0)2
(7.72a)
= s2 + 4ω0s + 4ω2
0.
(7.72b)
Equation (7.69) tells us that
det[sI −(A −BK)]
= det
 s
0
0
s
	
−


0
1
−ω2
0
0
	
−
 0
1
	
[ K1
K2 ]

,
or
s2 + K2s + ω2
0 + K1 = 0.
(7.73)
Equating the coefﬁcients with like powers of s in Eqs. (7.72b) and (7.73)
yields the system of equations
K2 = 4ω0,
ω2
0 + K1 = 4ω2
0,
and therefore,
K1 = 3ω2
0,
K2 = 4ω0.
Thus the control law in concise form is
K = [ K1
K2 ] = [ 3ω2
0
4ω0 ].
Figure 7.13 shows the response of the closed-loop system to the initial con-
ditions x1 = 1.0, x2 = 0.0, and ω0 = 1. It shows a very well damped
response, as would be expected from having two roots at s = −2. The
Matlab command impulse was used to generate the plot.
Calculating the gains using the technique illustrated in Example 7.14
becomes rather tedious when the order of the system is higher than 3. There
are, however, special "canonical" forms of the state-variable equations for
which the algebra for ﬁnding the gains is especially simple. One such canon-
ical form that is useful in control law design is the control canonical form
as discussed in Section 7.4.1. Consider the third-order system7
...y + a1¨y + a2˙y + a3y = b1¨u + b2˙u + b3u,
(7.74)
7This development is exactly the same for higher-order systems.

7.5 Control-Law Design for Full-State Feedback
467
Figure 7.13
Impulse response of the
undamped oscillator
with full-state feedback
ω0 = 1
Time (sec)
1
2
3
4
5
6
7
0
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1.0
Amplitude
x1
x2
u/4
which corresponds to the transfer function
G(s) = Y(s)
U(s) =
b1s2 + b2s + b3
s3 + a1s2 + a2s + a3
= b(s)
a(s).
(7.75)
Suppose we introduce an auxiliary variable (referred to as the partial state)
ξ, which relates a(s) and b(s) as shown in Fig. 7.14(a). The transfer function
from U to ξ is
ξ(s)
U(s) =
1
a(s),
(7.76)
or
...
ξ + a1¨ξ + a2 ˙ξ + a3ξ = u.
(7.77)
It is easy to draw a block diagram corresponding to Eq. (7.77) if we rearrange
the equation as follows:
...
ξ = −a1¨ξ −a2 ˙ξ −a3ξ + u.
(7.78)
The summation is indicated in Fig. 7.14(b), where each ξ on the right-hand
side is obtained by sequential integration of
...
ξ . To form the output, we go
back to Fig. 7.14(a) and note that
Y(s) = b(s)ξ(s),
(7.79)
which means that
y = b1¨ξ + b2 ˙ξ + b3ξ.
(7.80)
We again pick off the outputs of the integrators, multiply them by {bi}'s, and
form the right-hand side of Eq. (7.74) using a summer to yield the output as
shown in Fig. 7.14(c). In this case, all the feedback loops return to the point
of the application of the input, or "control" variable, and hence the form
is referred to as the control canonical form as discussed in Section 7.4.1.
Reduction of the structure by Mason's rule or by elementary block diagram
operations veriﬁes that this structure has the transfer function given by G(s).

468
Chapter 7 State-Space Design
Figure 7.14
Derivation of control
canonical form
(a)
(b)
l
U
Y
a(s)
1
b(s)
(c)
a1
s
1
s
1
s
1
a2
a3
+
-
-
-
U
l
l
l
l
a1
x1c
x2c
x3c
s
1
s
1
s
1
a2
a3
b3
+
-
-
+
+
+
-
U
l
l
l
l
b1
b2
Y
©
©
©
Taking the state as the outputs of the three integrators numbered, by
convention, from the left, namely,
x1 = ¨ξ1, x2 = ˙ξ, x3 = ξ,
(7.81)
we obtain
˙x1 =
...
ξ = −a1x1 −a2x2 −a3x3 + u,
˙x2 = x1,
˙x3 = x2.
(7.82)
We may now write the matrices describing the control canonical form in
general:
Ac =
⎡
⎢⎢⎢⎢⎢⎣
−a1
−a2
· · ·
· · ·
−an
1
0
· · ·
· · ·
0
0
1
0
· · ·
0
...
...
0
0
0
· · ·
1
0
⎤
⎥⎥⎥⎥⎥⎦
,
Bc =
⎡
⎢⎢⎢⎢⎢⎣
1
0
0
...
0
⎤
⎥⎥⎥⎥⎥⎦
,
(7.83a)
Cc =
 b1
b2
· · ·
· · ·
bn

,
Dc = 0.
(7.83b)

7.5 Control-Law Design for Full-State Feedback
469
The special structure of this system matrix is referred to as the upper com-
Companion form matrix
panion form because the characteristic equation is a(s) = sn + a1sn−1 +
a2sn−2 + · · · + an and the coefﬁcients of this monic "companion" polyno-
mial are the elements in the ﬁrst row of Ac. If we now form the closed-loop
system matrix Ac −BcKc, we ﬁnd that
Ac −BcKc =
⎡
⎢⎢⎢⎢⎢⎣
−a1 −K1
−a2 −K2
· · ·
· · ·
−an −Kn
1
0
· · ·
· · ·
0
0
1
0
· · ·
0
...
...
...
0
0
· · ·
1
0
⎤
⎥⎥⎥⎥⎥⎦
. (7.84)
By visually comparing Eqs. (7.83a) and (7.84), we see that the closed-
loop characteristic equation is
sn + (a1 + K1)sn−1 + (a2 + K2)sn−2 + · · · + (an + Kn) = 0.
(7.85)
Therefore, if the desired pole locations result in the characteristic equation
given by
αc(s) = sn + α1sn−1 + α2sn−2 + · · · + αn = 0,
(7.86)
then the necessary feedback gains can be found by equating the coefﬁcients
in Eqs. (7.85) and (7.86):
K1 = −a1 + α1, K2 = −a2 + α2, . . . , Kn = −an + αn.
(7.87)
We now have an algorithm for a design procedure: Given a system of
order n described by an arbitrary (A, B) and given a desired nth-order monic
characteristic polynomial αc(s), we (1) transform (A, B) to control canonical
form (Ac, Bc) by changing the state x = Tz and (2) solve for the control
gains by inspection using Eq. (7.87) to give the control law u = −Kcz.
Because this gain is for the state in the control form, we must (3) transform
the gain back to the original state to get K = KcT−1.
An alternative to this transformation method is given by Ackermann's
Ackermann's formula for
pole placement
formula (1972), which organizes the three-step process of converting to
(Ac, Bc), solving for the gains, and converting back again into the very
compact form
K = [ 0
· · ·
0
1 ]C−1αc(A),
(7.88)
such that
C = [ B
AB
A2B
· · ·
An−1B ],
(7.89)
where C is the controllability matrix we saw in Section 7.4, n gives the
order of the system and the number of state-variables, and αc(A) is a matrix
deﬁned as
αc(A) = An + α1An−1 + α2An−2 + · · · + αnI,
(7.90)
where the αi are the coefﬁcients of the desired characteristic polynomial
Eq. (7.86). Note that Eq. (7.90) is a matrix equation. Refer to Appendix WD
available at www.fpe7e.com for the derivation of Ackermann's formula.

470
Chapter 7 State-Space Design
EXAMPLE 7.15
Ackermann's Formula for Undamped Oscillator
(a) Use Ackermann's formula to solve for the gains for the undamped
oscillator of Example 7.14. (b) Verify the calculations with Matlab for
ω0 = 1.
Solution
(a) The desired characteristic equation is αc(s) = (s + 2ω0)2. Therefore,
the desired characteristic polynomial coefﬁcients,
α1 = 4ω0,
α2 = 4ω2
0,
are substituted into Eq. (7.90) and the result is
αc(A) =
 −ω2
0
0
0
−ω2
0
	
+ 4ω0

0
1
−ω2
0
0
	
+ 4ω2
0
 1
0
0
1
	
,
(7.91a)
=
 3ω2
0
4ω0
−4ω3
0
3ω2
0
	
.
(7.91b)
The controllability matrix is
C = [ B
AB ] =
 0
1
1
0
	
,
which yields
C−1 =
 0
1
1
0
	
.
(7.92)
Finally, we substitute Eqs. (7.92) and (7.91a) into Eq. (7.88) to get
K = [ K1
K2 ]
= [ 0
1 ]
 0
1
1
0
	  3ω2
0
4ω0
−4ω3
0
3ω2
0
	
.
Therefore
K = [ 3ω2
0
4ω0 ],
which is the same result we obtained previously.
(b) The Matlab statements
wo = 1;
A = [0 1;−wo*wo 0];
B = [0;1];
pc = [−2*wo;−2*wo];
K = acker(A,B,pc)
yield K = [ 3
4 ], which agrees with the hand calculations above.

7.5 Control-Law Design for Full-State Feedback
471
As was mentioned earlier, computation of the controllability matrix has
very poor numerical accuracy, and this carries over toAckermann's formula.
Equation (7.88), implemented in Matlab with the function acker, can be used
Matlab Acker, Place
for the design of SISO systems with a small (≤10) number of state-variables.
For more complex cases a more reliable formula is available, implemented
in Matlab with place. A modest limitation on place is that, because it is based
on assigning closed-loop eigenvectors, none of the desired closed-loop poles
may be repeated; that is, the poles must be distinct,8 a requirement that does
not apply to acker.
The fact that we can shift the poles of a system by state feedback to
any desired location is a rather remarkable result. The development in this
section reveals that this shift is possible if we can transform (A, B) to the
control form (Ac, Bc), which in turn is possible if the system is control-
lable. In rare instances the system may be uncontrollable, in which case no
possible control will yield arbitrary pole locations. Uncontrollable systems
have certain modes, or subsystems, that are unaffected by the control. This
usually means that parts of the system are physically disconnected from the
input. For example, in modal canonical form for a system with distinct poles,
one of the modal state-variables is not connected to the input if there is a
zero entry in the Bm matrix. A good physical understanding of the system
being controlled would prevent any attempt to design a controller for an
uncontrollable system. As we saw earlier, there are algebraic tests for con-
trollability; however, no mathematical test can replace the control engineer's
understanding of the physical system. Often the physical situation is such
that every mode is controllable to some degree, and, while the mathemat-
ical tests indicate the system is controllable, certain modes are so weakly
controllable that designs to control them are virtually useless.
Airplane control is a good example of weak controllability of certain
An example of weak
controllability
modes. Pitch plane motion xp is primarily affected by the elevator δe and
weakly affected by rolling motion xr. Rolling motion is essentially affected
only by the ailerons δa. The state-space description of these relationships is
 ˙xp
˙xr
	
=
 Ap
ε
0
Ar
	  xp
xr
	
+
 Bp
0
0
Br
	  δe
δa
	
,
(7.93)
where the matrix of small numbers ε represents the weak coupling from
rolling motion to pitching motion. A mathematical test of controllability for
this system would conclude that pitch plane motion (and therefore altitude)
is controllable by the ailerons as well as by the elevator! However, it is
impractical to attempt to control an airplane's altitude by rolling the aircraft
with the ailerons.
Another example will illustrate some of the properties of pole placement
by state feedback and the effects of loss of controllability on the process.
8One may get around this restriction by moving the repeated poles by very small amounts to
make them distinct.

472
Chapter 7 State-Space Design
EXAMPLE 7.16
How Zero Location Can Affect the Control Law
A speciﬁc thermal system is described by Eq. (7.32a) in observer canonical
form with a zero at s = z0. (a) Find the state feedback gains necessary for
placing the poles of this system at the roots of s2 + 2ζωns + ω2
n (that is, at
−ζωn ± jωn

1 −ζ 2). (b) Repeat the computation with Matlab, using the
parameter values z0 = 2, ζ = 0.5, and ωn = 2 rad/sec.
Solution
(a) The state description matrices are
Ao =

−7
1
−12
0
	
,
Bo =

1
−z0
	
,
Co = [
1
0 ],
Do = 0.
First we substitute these matrices into Eq. (7.69) to get the closed-loop
characteristic equation in terms of the unknown gains and the zero
position:
s2 + (7 + K1 −z0K2)s + 12 −K2(7z0 + 12) −K1z0 = 0.
Next we equate this equation to the desired characteristic equation to
get the equations
K1 −z0K2 = 2ζωn −7,
−z0K1 −(7z0 + 12)K2 = ω2
n −12.
The solutions to these equations are
K1 = z0(14ζωn −37 −ω2
n) + 12(2ζωn −7)
(z0 + 3)(z0 + 4)
,
K2 = z0(7 −2ζωn) + 12 −ω2
n
(z0 + 3)(z0 + 4)
.
(b) The following Matlab statements can be used to ﬁnd the solution:
Ao = [−7 1;−12 0];
zo = 2;
Bo = [1;−zo];
pc = roots([1 2 4]);
K = place(Ao,Bo,pc)
These statements yield K= [−3.80 0.60], which agrees with the hand
calculations. If the zero were close to one of the open-loop poles, say
z0 = −2.99, then we ﬁnd K= [2052.5 −688.1].
Two important observations should be made from this example. The ﬁrst is
that the gains grow as the zero z0 approaches either −3 or −4, the values
where this system loses controllability. In other words, as controllability is
almost lost, the control gains become very large.

7.5 Control-Law Design for Full-State Feedback
473
The system has to work harder and harder to achieve control as
controllability slips away.
Apart from controllability, any actuator has limited dynamic range and
saturation limits. Therefore, even though for a system that is controllable,
the poles can be placed in arbitrary locations, some locations may be quite
undesirable as they would drive the actuators into saturation.
The second important observation illustrated by the example is that
both K1 and K2 grow as the desired closed-loop bandwidth given by ωn is
increased. From this, we conclude that
To move the poles a long way requires large gains.
These observations lead us to a discussion of how we might go about
selecting desired pole locations in general. Before we begin that topic, we
will complete the design with full-state feedback by showing how the refer-
ence input might be applied to such a system and what the resulting response
characteristics are.
7.5.2
Introducing the Reference Input with Full-State
Feedback
Thus far, the control has been given by Eq. (7.67), or u = −Kx. In order
to study the transient response of the pole-placement designs to input com-
mands, it is necessary to introduce the reference input into the system. An
obvious way to do this is to change the control to u = −Kx + r. However,
the system will now almost surely have a nonzero steady-state error to a step
input. The way to correct this problem is to compute the steady-state values
of the state and the control input that will result in zero output error and then
force them to take these values. If the desired ﬁnal values of the state and
the control input are xss and uss respectively, then the new control formula
should be
u = uss −K(x −xss),
(7.94)
so that when x = xss (no error), u = uss. To pick the correct ﬁnal values, we
must solve the equations so that the system will have zero steady-state error
to any constant input. The system differential equations are the standard
ones:
˙x = Ax + Bu,
(7.95a)
y = Cx + Du.
(7.95b)
In the constant steady state, Eqs. (7.95a) and (7.95b) reduce to the pair
0 = Axss + Buss,
(7.96a)
yss = Cxss + Duss.
(7.96b)

474
Chapter 7 State-Space Design
We want to solve for the values for which yss = rss for any value of rss. To
Gain calculation for
reference input
do this, we make xss = Nxrss and uss = Nurss. With these substitutions we
can write Eqs. (7.96) as a matrix equation; the common factor of rss cancels
out to give the equation for the gains:
 A
B
C
D
	  Nx
Nu
	
=
 0
1
	
.
(7.97)
This equation can be solved for Nx and Nu to get
 Nx
Nu
	
=
 A
B
C
D
	−1  0
1
	
.
With these values, we ﬁnally have the basis for introducing the reference
Control equation with
reference input
input so as to get zero steady-state error to a step input:
u = Nur −K(x −Nxr)
(7.98a)
= −Kx + (Nu + KNx)r.
(7.98b)
The coefﬁcient of r in parentheses is a constant that can be computed
beforehand. We give it the symbol ¯N, so
u = −Kx + ¯Nr.
(7.99)
The block diagram of the system is shown in Fig. 7.15.
EXAMPLE 7.17
Introducing the Reference Input
Compute the necessary gains for zero steady-state error to a step command at
x1, and plot the resulting unit step response for the oscillator in Example 7.14
with ω0 = 1.
Solution. We substitute the matrices of Eq. (7.71) (with ω0 = 1 and C =
[ 1
0 ] because y = x1) into Eq. (7.97) to get
⎡
⎣
0
1
0
−1
0
1
1
0
0
⎤
⎦
 Nx
Nu
	
=
⎡
⎣
0
0
1
⎤
⎦·
(7.100)
The solution is (x=a\b in Matlab where a and b are the left- and right-hand
side matrices, respectively),
Nx =
 1
0
	
,
Nu = 1,
Figure 7.15
Block diagram for
introducing the
reference input with
full-state feedback:
(a) with state and
control gains; (b) with a
single composite gain
Nu
Y
+
+
R
-K
Plant
+
-
Nx
u
x
(a)
(b)
Y
+
+
R
-K
Plant
u
x
N
©
©
©

7.5 Control-Law Design for Full-State Feedback
475
and, for the given control law, K = [3ω2
0 4ω0] = [ 3
4 ],
¯N = Nu + KNx = 4.
(7.101)
The corresponding step response (using the Matlab step command) is plotted
in Fig. 7.16.
Note that there are two equations for the control—Eqs. (7.98b) and (7.99).
While these expressions are equivalent in theory, they differ in practical
implementation in that Eq. (7.98b) is usually more robust to parameter errors
than Eq. (7.99), particularly when the plant includes a pole at the origin and
Type 1 behavior is possible. The difference is most clearly illustrated by the
next example.
EXAMPLE 7.18
Reference Input to a Type 1 System: DC Motor
Compute the input gains necessary to introduce a reference input with zero
steady-state error to a step for the DC motor of Example 5.1, which in
state-variable form is described by the matrices:
DC Motor
A =
 0
1
0
−1
	
,
B =
 0
1
	
,
C =
 1
0 
,
D = 0.
Assume that the state feedback gain is [ K1
K2 ].
Solution.
If we substitute the system matrices of this example into the
equation for the input gains, Eq. (7.97), we ﬁnd that the solution is
Nx =
 1
0
	
,
Nu = 0,
¯N = K1.
Figure 7.16
Step response of
oscillator to a reference
input
Time (sec)
0
1
2
3
4
5
6
7
-0.2
0
0.2
0.4
0.6
0.8
1.0
Amplitude
x1
x2
u/4
uss
xss

476
Chapter 7 State-Space Design
With these values, the expression for the control using Nx and Nu
[Eq. (7.98b)] reduces to
u = −K1(x1 −r) −K2x2,
while the one using ¯N [Eq. (7.99)] becomes
u = −K1x1 −K2x2 + K1r.
The block diagrams for the systems using each of the control equations are
given in Fig. 7.17. When using Eq. (7.99), as shown in Fig. 7.17(b), it is
necessary to multiply the input by a gain K1(= ¯N) exactly equal to that
used in the feedback. If these two gains do not match exactly, there will be
a steady-state error. On the other hand, if we use Eq. (7.98b), as shown in
Fig. 7.17(a), there is only one gain to be used on the difference between the
reference input and the ﬁrst state, and zero steady-state error will result even
if this gain is slightly in error. The system of Fig. 7.17(a) is more robust than
the system of Fig. 7.17(b).
With the reference input in place, the closed-loop system has input r
and output y. From the state description we know that the system poles are
at the eigenvalues of the closed-loop system matrix, A −BK. In order to
compute the closed-loop transient response, it is necessary to know where
the closed-loop zeros of the transfer function from r to y are. They are to
be found by applying Eq. (7.64) to the closed-loop description, which we
assume has no direct path from input u to output y, so that D = 0. The zeros
are values of s such that
det

sI −(A −BK)
−¯NB
C
0
	
= 0.
(7.102)
Figure 7.17
Alternative structures
for introducing the
reference input: (a) Eq.
(7.98b); (b) Eq. (7.99)
(a)
(b)
+
-
R
s
1
x1
x2
-K1
+
+
-K2
u
s
1
+
+
R
s
1
x1
N
+
+
-K2
-K1
s
1
x2
u
©
©
©
©

7.6 Selection of Pole Locations for Good Design
477
We can use two elementary facts about determinants to simplify Eq. (7.102).
In the ﬁrst place, if we divide the last column by ¯N, which is a scalar, then the
point where the determinant is zero remains unchanged. The determinant is
also not changed if we multiply the last column by K and add it to the ﬁrst
(block) column, with the result that the BK term is cancelled out. Thus the
matrix equation for the zeros reduces to
det
 sI −A
−B
C
0
	
= 0.
(7.103)
Equation (7.103) is the same as Eq. (7.64) for the zeros of the plant before
the feedback was applied. The important conclusion is that
When full-state feedback is used as in Eq. (7.98b) or (7.99), the
zeros remain unchanged by the feedback.
7.6
Selection of Pole Locations for Good Design
The ﬁrst step in the pole-placement design approach is to decide on the
closed-loop pole locations. When selecting pole locations, it is always useful
to keep in mind that the required control effort is related to how far the open-
loop poles are moved by the feedback. Furthermore, when a zero is near a
pole, the system may be nearly uncontrollable and, as we saw in Section 7.5,
moving such poles requires large control gains and thus a large control
effort; however, the designer is able to temper the choices to take control
effort into account. Therefore, a pole-placement philosophy that aims to ﬁx
only the undesirable aspects of the open-loop response and avoids either
large increases in bandwidth or efforts to move poles that are near zeros
will typically allow smaller gains, and thus smaller control actuators, than a
philosophy that arbitrarily picks all the poles without regard to the original
open-loop pole and zero locations.
In this section we discuss two techniques to aid in the pole-selection
process. The ﬁrst approach—dominant second-order poles—deals with pole
Two methods of pole
selection
selection without explicit regard for their effect on control effort; however,
the designer is able to temper the choices to take control effort into account.
The second method (called optimal control, or symmetric root locus) does
speciﬁcally address the issue of achieving a balance between good system
response and control effort.
7.6.1
Dominant Second-Order Poles
The step response corresponding to the second-order transfer function with
complex poles at radius ωn and damping ratio ζ was discussed in Chapter 3.
The rise time, overshoot, and settling time can be deduced directly from
the pole locations. We can choose the closed-loop poles for a higher-order
system as a desired pair of dominant second-order poles, and select the rest
of the poles to have real parts corresponding to sufﬁciently damped modes,

478
Chapter 7 State-Space Design
so that the system will mimic a second-order response with reasonable con-
trol effort. We also must make sure that the zeros are far enough into the
LHP to avoid having any appreciable effect on the second-order behavior.
A system with several lightly damped high-frequency vibration modes plus
two rigid-body low-frequency modes lends itself to this philosophy. Here we
can pick the low-frequency modes to achieve desired values of ωn and ζ and
select the rest of the poles to increase the damping of the high-frequency
modes, while holding their frequency constant in order to minimize con-
trol effort. To illustrate this design method, we obviously need a system of
higher than second-order; we will use the tape drive servomotor described
in Example 7.10.
EXAMPLE 7.19
Pole Placement as a Dominant Second-Order System
Design the tape servomotor by the dominant second-order poles method to
have no more than 5% overshoot and a rise time of no more than 4 sec. Keep
the peak tension as low as possible.
Solution.
From the plots of the second-order transients in Fig. 3.19, a
damping ratio ζ = 0.7 will meet the overshoot requirement and, for this
damping ratio, a rise time of 4 sec suggests a natural frequency of about 1/1.5.
There are ﬁve poles in all, so the other three need to be placed far to the left
of the dominant pair; for our purposes, "far" means the transients due to
the fast poles should be over (signiﬁcantlly faster) well before the transients
due to the dominant poles, and we assume a factor of 4 in the respective
undamped natural frequencies to be adequate. From these considerations,
the desired poles are given by
pc =

−0.707 + 0.707 ∗j; −0.707 −0.707 ∗j; −4; −4; −4

/1.5.
(7.104)
With these desired poles, we can use the function acker with A and B from
Example 7.10, Eq. (7.67), to ﬁnd the control gains
K2 = [ 8.5123
20.3457
−1.4911
−7.8821
6.1927 ].
(7.105)
These are found with the following Matlab statements:
Matlab acker
A = [0 2 0 0 0;−.1 −.35 .1 .1.75;0 0 0 2 0;.4 .4 −.4 −1.4 0;
0 −.03 0 0 −1];
B = [0;0;0;0;1];
pc = [−.707+.707*j;−.707−.707*j;−4;−4;−4]/1.5;
K2 = acker(A,B,pc)
The step response and the corresponding tension plots for this and
another design (to be discussed in Section 7.6.2) are given in Figs. 7.18
and 7.19. Notice that the rise time is approximately 4 sec and the overshoot
is about 5%, as speciﬁed.
Because the design process is iterative, the poles we selected should be
seen as only a ﬁrst step, to be followed by further modiﬁcations to meet the
speciﬁcations as accurately as necessary.

7.6 Selection of Pole Locations for Good Design
479
Figure 7.18
Step responses of the
tape servomotor
designs
Time (msec)
x3
Tape position
1.2
1.0
0.8
0.6
0.4
0.2
0
0
2
4
6
8
10
12
Dominant
second order
LQR
Figure 7.19
Tension plots for tape
servomotor step
responses
Time (msec)
T
0
2
4
6
8
10
12
0.02
0.0
-0.02
-0.04
-0.06
-0.08
-0.10
-0.12
Tape tension
Dominant
second order
LQR
For this example we happened to select adequate pole locations on the
ﬁrst try.
7.6.2
Symmetric Root Locus (SRL)
A most effective and widely used technique of linear control systems design
is the optimal linear quadratic regulator (LQR). The simpliﬁed version
LQR design
of the LQR problem is to ﬁnd the control such that the performance index
J =
 ∞
0
[ρz2(t) + u2(t)] dt
(7.106)

480
Chapter 7 State-Space Design
is minimized for the system
˙x = Ax + Bu,
(7.107a)
z = C1x,
(7.107b)
where ρ in Eq. (7.106) is a weighting factor of the designer's choice. A
remarkable fact is that the control law that minimizes J is given by linear-
state feedback
u = −Kx.
(7.108)
Here the optimal value of K is that which places the closed-loop poles at the
stable roots (those in the LHP) of the symmetric root-locus (SRL) equation
Symmetric root locus
(Kailath, 1980)
1 + ρG0(−s)G0(s) = 0,
(7.109)
where G0 is the open-loop transfer function from u to z:
G0(s) = Z(s)
U(s) = C1(sI −A)−1B = N(s)
D(s).
(7.110)
Note that this is a root-locus problem as discussed in Chapter 5 with
respect to the parameter ρ, which weighs the relative cost of (tracking error)
z2 with respect to the control effort u2 in the performance index equa-
tion (7.106). Note also that s and −s affect Eq. (7.109) in an identical manner;
therefore, for any root s0 of Eq. (7.109), there will also be a root at −s0. We
call the resulting root locus a SRL, since the locus in the LHP will have a
mirror image in the right half-plane (RHP); that is, they are symmetric with
respect to the imaginary axis. We may thus choose the optimal closed-loop
poles by ﬁrst selecting the matrix C1, which deﬁnes the tracking error and
which the designer wishes to keep small, and then choosing ρ, which bal-
ances the importance of this tracking error against the control effort. Notice
that the output we select as tracking error does not need to be the plant sensor
output. That is why we call the output in Eq. (7.107) z rather than y.
Selecting a set of stable poles from the solution of Eq. (7.109) results
in desired closed-loop poles, which we can then use in a pole-placement
calculation such as Ackermann's formula [Eq. (7.88)] to obtain K. As with
all root loci for real transfer functions G0, the locus is also symmetric with
respect to the real axis; thus there is symmetry with respect to both the
SRL equation
real and imaginary axes. We can write the SRL equation in the standard
root-locus form
1 + ρ N(−s)N(s)
D(−s)D(s) = 0,
(7.111)
obtain the locus poles and zeros by reﬂecting the open-loop poles and zeros
of the transfer function from U to Z across the imaginary axis (which doubles
the number of poles and zeros), and then sketch the locus. Note that the locus
could be either a 0◦or 180◦locus, depending on the sign of G0(−s)G0(s)
in Eq. (7.109). A quick way to determine which type of locus to use (0◦or
180◦) is to pick the one that has no part on the imaginary axis. The real-axis

7.6 Selection of Pole Locations for Good Design
481
rule of root locus plotting will reveal this right away. For the controllability
assumptions we have made here, plus the assumption that all the system
modes are present in the chosen output z, the optimal closed-loop system is
guaranteed to be stable; thus no part of the locus can be on the imaginary axis.
EXAMPLE 7.20
SRL for Servo Speed Control
Plot the SRL for the following servo speed control system with z = y:
˙y = −ay + u,
(7.112a)
G0(s) =
1
s + a.
(7.112b)
Solution. The SRL equation [Eq. (7.109)] for this example is
1 + ρ
1
(−s + a)(s + a) = 0.
(7.113)
The SRL, shown in Fig. 7.20, is a 0◦locus. The optimal (stable) pole can be
determined explicitly in this case as
s = −

a2 + ρ.
(7.114)
Thus, the closed-loop root location that minimizes the performance index of
Eq. (7.106) lies on the real axis at the distance given by Eq. (7.114) and is
always to the left of the open-loop root.
EXAMPLE 7.21
SRL Design for Satellite Attitude Control
Draw the SRL for the satellite system with z = y.
Solution. The equations of motion are
˙x =
 0
1
0
0
	
x +
 0
1
	
u,
(7.115)
y = [ 1
0 ] x.
(7.116)
We then calculate from Eqs. (7.115) and (7.116) so that
G0(s) = 1
s2 .
(7.117)
Figure 7.20
SRL for a ﬁrst-order
system
Re(s)
Im(s)
r 7 0
r = 0
-a
a
r = 0
r 7 0

482
Chapter 7 State-Space Design
The symmetric 180◦loci are shown in Fig. 7.21. The Matlab statements to
generate the SRL are
s=tf('s');
sysGG=1/sˆ4;
rlocus(sysGG);
It is interesting to note that the (stable) closed-loop poles have damping
of ζ = 0.707. We would choose two stable roots for a given value of ρ,
for example, s = −1 ± j1 for ρ = 4.07, on the SRL and use them for
pole-placement and control-law design.
Choosing different values of ρ can provide us with pole locations that
achieve varying balances between a fast response (small values of

z2 dt)
and a low control effort (small values of

u2 dt). Figure 7.22 shows the
design trade-off curve for the satellite (double-integrator) plant [Eq. (7.15)]
for various values of ρ ranging from 0.01 to 100. The curve has two asymp-
totes (dashed lines) corresponding to low (large ρ) and high (small ρ) penalty
on the control usage. In practice, usually a value of ρ corresponding to a
point close to the knee of the trade-off curve is chosen. This is because it
provides a reasonable compromise between the use of control and the speed
of response. For the satellite plant, the value of ρ = 1 corresponds to the
knee of the curve. In this case the closed-loop poles have a damping ratio
of ζ = 0.707! Figure 7.23 shows the associated Nyquist plot, which has a
phase margin PM = 65◦and inﬁnite gain margin. These excellent stabil-
ity properties are a general feature of LQR designs. However, recall that
this method assumes that all the state variables are available (measured) for
feedback, which is not the case in general. The state variables that are not
measured may be estimated as shown in the next section, and the excellent
LQR stability properties may not be attainable.
Figure 7.21
SRL for the satellite
r = 0
r = 4.07
r = 4.07
Re(s)
Im(s)
Im(s)
-1
+1
+j
-j

7.6 Selection of Pole Locations for Good Design
483
Figure 7.22
Design trade-off curve
for satellite plant
25
0
5
10
15
20
0
5
10
15
20
25
r = 100
r = 0.01
r = 1
u2 dt
0
q
z2 dt
0
q
µ
µ
Figure 7.23
Nyquist plot for LQR
design
Imaginary axis
1.5
-1.5
-1.0
-0.5
0
0.5
1.0
-2.5
-2.0
-1.5
-1.0
-0.5
0
0.5
1.0
Real axis
It is also possible to locate optimal pole locations for the design of an
open-loop unstable system using the SRL and LQR method.
EXAMPLE 7.22
SRL Design for an Inverted Pendulum
Draw the SRL for the linearized equations of the simple inverted pendulum
with ωo = 1. Take the output, z, to be the sum of twice the position plus the
velocity (so as to weight or penalize both position and velocity).
Solution. The equations of motion are
˙x =

0
1
ω2
0
0
	
x +

0
−1
	
u.
(7.118)
For the speciﬁed output of 2 × position + velocity, we compute the output by
z = [ 2
1 ]x.
(7.119)

484
Chapter 7 State-Space Design
We then calculate from Eqs. (7.118) and (7.119) so that
G0(s) = −s + 2
s2 −ω2
0
.
(7.120)
The symmetric 0◦loci are shown in Fig. 7.24. The Matlab statements to
generate the SRL are (for ωo = 1),
s=tf('s');
G=-(s+2)/(sˆ2-1);
G1=-(-s+2)/(sˆ2-1);
sysGG=G*G1;
rlocus(sysGG);
For ρ = 1, we ﬁnd that the closed-loop poles are at −1.36 ± j0.606, cor-
responding to K = [ −2.23
−2.73 ]. If we substitute the system matrices
of this example into the equation for the input gains, Eq. (7.97), we ﬁnd that
the solution is
Nx =
 1
0
	
,
Nu = 1,
¯N = −1.23.
With these values, the expression for the control using Nx and Nu
[Eq. (7.98b)] the controller reduces to
u = −Kx + ¯Nr.
The corresponding step response for position is shown in Fig. 7.25.
As a ﬁnal example in this section, we consider again the tape servo-
motor and introduce LQR design using the computer directly to solve for
Figure 7.24
SRL for the inverted
pendulum
Re(s)
Im(s)
2
3
4
-2
-3
-4
-1
-2
-3
1
2
3

7.6 Selection of Pole Locations for Good Design
485
Figure 7.25
Step response for the
inverted pendulum
Position, x1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
4.5
0
0.5
1
1.5
2
2.5
3
3.5
4
Time (sec)
the optimal control law. From Eqs. (7.106) and (7.108), we know that the
informationneededtoﬁndtheoptimalcontrolisgivenbythesystemmatrices
A and B and the output matrix C1. Most computer-aided software packages,
including Matlab, use a more general form of Eq. (7.106):
J =
 ∞
0
(xTQx + uTRu) dt.
(7.121)
Equation (7.121) reduces to the simpler form of Eq. (7.106) if we take Q =
ρCT
1 C1 and R = 1. The direct solution for the optimal control gain is the
Matlab lqr
Matlab statement
K=lqr(A, B, Q, R).
(7.122)
One reasonable method to start the LQR design iteration is suggested by
Bryson's rule (Bryson and Ho, 1969). In practice, an appropriate choice to
Bryson's rule
obtain acceptable values of x and u is to initially choose diagonal matrices
Q and R such that
Qii = 1/maximum acceptable value of [x2
i ],
Rii = 1/maximum acceptable value of [u2
i ].
The weighting matrices are then modiﬁed during subsequent iterations
to achieve an acceptable trade-off between performance and control effort.
EXAMPLE 7.23
LQR Design for a Tape Drive
(a) Find the optimal control for the tape drive of Example 7.10, using the
positionx3 astheoutputfortheperformanceindex. Letρ = 1. Compare
the results with that of dominant second order obtained before.
(b) Compare the LQR designs for ρ = 0.1, 1, 10.
Solution
(a) All we need to do here is to substitute the matrices into Eq. (7.122),
form the feedback system, and plot the response. The performance

486
Chapter 7 State-Space Design
index matrix is the scalar R = 1; the most difﬁcult part of the problem
is ﬁnding the state-cost matrix Q. With the output-cost variable z = x3,
the output matrix from Example 7.10 is
C3 = [ 0.5
0
0.5
0
0 ],
and with ρ = 1, the required matrix is
Q = CT
3 C3
=
⎡
⎢⎢⎣
0.25
0
0.25
0
0
0
0
0
0
0
0.25
0
0.25
0
0
0
0
0
0
0
⎤
⎥⎥⎦.
The gain is given by Matlab, using the following statements:
A=[0 2 0 0 0; −.1 −.35 .1 .1.75;0 0 0 2 0;.4 .4 −.4 −1.4;0
−.03 0 0 −1];
B=[0; 0; 0; 0; 1];
C3=[.5 0 .5 0 0];
R=1;
rho=1;
Q=rho*C3'*C3;
K=lqr(A,B,Q,R)
The Matlab computed gain is
K = [ 0.6526
2.1667
0.3474
0.5976
1.0616 ].
(7.123)
The results of a position step and the corresponding tension are plotted
in Figs. 7.18 and 7.19 (using step) with the earlier responses for com-
parison. Obviously, there is a vast range of choice for the elements of
Q and R, so substantial experience is needed in order to use the LQR
method effectively.
(b) The LQR designs may be repeated as in part (a) with the same Q and
R, but with ρ = 0.1, 10. Figure 7.26 shows a comparison of position
step and the corresponding tension for the three designs. As seen from
the results, the smaller values of ρ correspond to higher cost on the
control and slower response, whereas the larger values of ρ correspond
to lower cost on the control and relatively fast response.
Limiting Behavior of LQR Regulator Poles
It is interesting to consider the limiting behavior of the optimal closed-loop
poles as a function of the root-locus parameter (that is, ρ) although, in
practice, neither case would be used.
"Expensive control" case (ρ →0): Equation (7.106) primarily penal-
izes the use of control energy. If the control is expensive, the optimal control
does not move any of the open-loop poles except for those that are in the
RHP. The poles in the RHP are simply moved to their mirror images in the

7.6 Selection of Pole Locations for Good Design
487
Figure 7.26
(a) Step response of
the tape servomotor
for LQR designs;
(b) corresponding
tension for tape
servomotor step
responses
(a)
(b)
Tape position, x3
0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
12
0
2
4
6
8
10
Time (msec)
0.10
-0.25
-0.20
-0.15
-0.10
-0.05
0
0.05
12
0
2
4
6
8
10
Time (msec)
Tape tension, T
r = 0.1
r = 10
r = 1
r = 10
r = 1
r = 0.1
LHP. The optimal control does this to stabilize the system using minimum
control effort and makes no attempt to move any of the poles of the system
that are already in the LHP. The closed-loop pole locations are simply the
starting points on the SRL in the LHP. The optimal control does not speed
up the response of the system in this case. For the satellite plant, the vertical
dashed line in Fig. 7.22 corresponds to the "expensive control" case and
illustrates that the very low control usage results in a very large error in z.
"Cheap control" case (ρ →∞): In this case control energy is no object
and arbitrary control effort may be used by the optimal control law. The
control law then moves some of the closed-loop pole locations right on top of
thezerosintheLHP.TherestaremovedtoinﬁnityalongtheSRLasymptotes.
If the system is nonminimum phase, some of the closed-loop poles are moved
to mirror images of these zeros in the LHP, as shown in Example 7.22. The

488
Chapter 7 State-Space Design
rest of the poles go to inﬁnity and do so along a Butterworth ﬁlter pole
pattern, as shown in Example 7.21. The optimal control law provides the
fastest possible response time consistent with the LQR cost function. The
feedback gain matrix K becomes unbounded in this case. For the double-
integrator plant, the horizontal dashed line in Fig. 7.22 corresponds to the
"cheap control" case.
Robustness Properties of LQR Regulators
It has been proved (Anderson and Moore, 1990) that the Nyquist plot for
LQR design avoids a circle of unity radius centered at the −1 point as shown
in Fig. 7.23. This leads to extraordinary phase and gain margin properties.
It can be shown (Problem 7.33) that the return difference must satisfy
|1 + K( jωI −A)−1B| ≥1.
(7.124)
Let us rewrite the loop gain as the sum of its real and imaginary parts:
L( jω) = K( jωI −A)−1B = Re(L( jω)) + jIm(L( jω)).
(7.125)
Equation (7.124) implies that
([Re(L( jω)]+1)2 + [Im(L( jω)]2 ≥1,
(7.126)
which means that the Nyquist plot must indeed avoid a circle centered at −1
with unit radius. This implies that 1
2 < GM < ∞, which means that the "up-
ward" gain margin is GM = ∞and the "downward" gain margin is GM = 1
2
(see also Problem 6.24 of Chapter 6). Hence the LQR gain matrix, K, can be
LQR gain and phase
margins
multiplied by a large scalar or reduced by half with guaranteed closed-loop
system stability. The phase margin, PM, is at least ±60◦. These margins
are remarkable, and it is not realistic to assume that they can be achieved in
practice, because of the presence of modeling errors and lack of sensors!
7.6.3
Comments on the Methods
The two methods of pole selection described in Sections 7.6.1 and 7.6.2
are alternatives the designer can use for an initial design by pole place-
ment. Note that the ﬁrst method (dominant second order) suggests selecting
closed-loop poles without regard to the effect on the control effort required
to achieve that response. In some cases, therefore, the resulting control effort
may be unrealistically high. The second method (SRL), on the other hand,
selects poles that result in some balance between system errors and con-
trol effort. The designer can easily examine the relationship between shifts
in that balance (by changing ρ) and system root locations, time response,
and feedback gains. Whatever initial pole-selection method we use, some
modiﬁcation is almost always necessary to achieve the desired balance of

7.7 Estimator Design
489
bandwidth, overshoot, sensitivity, control effort, and other practical design
requirements. Further insight into pole selection will be gained from the
examplesthatillustratecompensationinSection7.8andfromthecasestudies
in Chapter 10.
7.7
Estimator Design
The control law designed in Section 7.5 assumed that all the state-variables
are available for feedback. In most cases, not all the state-variables are
measured. The cost of the required sensors may be prohibitive, or it may be
physically impossible to measure all of the state-variables, as in, for example,
a nuclear power plant. In this section we demonstrate how to reconstruct all
of the state-variables of a system from a few measurements. If the estimate
of the state is denoted by ˆx, it would be convenient whether we could replace
the true state in the control law given by Eq. (7.99) with the estimates, so
that the control becomes u = −Kˆx + ¯Nr. This is indeed possible, as we
shall see in Section 7.8, so construction of a state estimate is a key part of
state-space control design.
7.7.1
Full-Order Estimators
One method of estimating the state is to construct a full-order model of the
plant dynamics,
˙ˆx = Aˆx + Bu,
(7.127)
where ˆx is the estimate of the actual state x. We know A, B, and u(t).
Hence this estimator will be satisfactory if we can obtain the correct initial
condition x(0) and set ˆx(0) equal to it. Figure 7.27 depicts this open-loop
estimator. However, it is precisely the lack of information about x(0) that
requires the construction of an estimator. Otherwise, the estimated state
would track the true state exactly. Thus, if we made a poor estimate for the
initial condition, the estimated state would have a continually growing error
or an error that goes to zero too slowly to be of use. Furthermore, small
errors in our knowledge of the system (A, B) would also cause the estimate
to diverge from the true state.
To study the dynamics of this estimator, we deﬁne the error in the
estimate to be
˜x = x −ˆx.
(7.128)
Then the dynamics of this error system are given by
˙˜x = ˙x −˙ˆx = A˜x,
˜x(0) = x(0) −ˆx(0).
(7.129)
Figure 7.27
Block diagram for the
open-loop estimator
y
u
Process
(A, B)
C
x
xˆ
Model
(A, B)
C
yˆ

490
Chapter 7 State-Space Design
Figure 7.28
Block diagram for the
closed-loop estimator
+
-
u(t)
Process
(A, B)
C
Model
(A, B)
C
x(t)
x(t)
ˆ
y(t)
ˆ
L
y(t)
©
We have no ability to inﬂuence the rate at which the state estimate converges
to the true state.
We now invoke the golden rule: When in trouble, use feedback. Consider
feeding back the difference between the measured and estimated outputs and
Feed back the output error
to correct the state
estimate equation.
correcting the model continuously with this error signal. The equation for
this scheme, shown in Fig. 7.28, is
˙ˆx = Aˆx + Bu + L(y −Cˆx).
(7.130)
Here L is a proportional gain deﬁned as
L = [l1, l2, . . . , ln]T,
(7.131)
and is chosen to achieve satisfactory error characteristics. The dynamics of
the error can be obtained by subtracting the estimate [Eq. (7.130)] from the
state [Eq. (7.41)], to get the error equation
˙˜x = (A −LC)˜x.
(7.132)
The characteristic equation of the error is now given by
Estimate-error
characteristic equation
det[sI −(A −LB)] = 0.
(7.133)
If we can choose L so that A−LC has stable and reasonably fast eigenvalues,
˜x will decay to zero and remain there—independent of the known forcing
function u(t) and its effect on the state x(t) and irrespective of the initial
condition ˜x(0). This means that ˆx(t) will converge to x(t), regardless of the
value of ˆx(0); furthermore, we can choose the dynamics of the error to be
stable as well as much faster than the open-loop dynamics determined by A.
Note that in obtaining Eq. (7.132), we have assumed that A, B, and C
are identical in the physical plant and in the computer implementation of
the estimator. If we do not have an accurate model of the plant (A, B, C),
the dynamics of the error are no longer governed by Eq. (7.132). However,
we can typically choose L so that the error system is still at least stable and
the error remains acceptably small, even with (small) modeling errors and
disturbing inputs. It is important to emphasize that the nature of the plant
and the estimator are quite different. The plant is a physical system such as
a chemical process or servomechanism, whereas the estimator is usually a
digital processor computing the estimated state according to Eq. (7.130).
The selection of L can be approached in exactly the same fashion as K
is selected in the control-law design. If we specify the desired location of
the estimator error poles as
si = β1, β2, . . . , βn,

7.7 Estimator Design
491
then the desired estimator characteristic equation is
αe(s) = (s −β1)(s −β2) · · · (s −βn).
(7.134)
We can then solve for L by comparing coefﬁcients in Eqs. (7.133) and
(7.134).
EXAMPLE 7.24
An Estimator Design for a Simple Pendulum
Design an estimator for the simple pendulum. Compute the estimator gain
matrix that will place both the estimator error poles at −10ω0 (ﬁve times as
fast as the controller poles selected in Example 7.14). Verify the result using
Matlab for ω0 = 1. Evaluate the performance of the estimator.
Solution. The equations of motion are
˙x =
 0
1
−ω2
0
0
	
x +
0
1
	
u,
(7.135a)
y = [1
0]x.
(7.135b)
We are asked to place the two estimator error poles at −10ω0. The corres-
ponding characteristic equation is
αe(s) = (s + 10ω0)2 = s2 + 20ω0s + 100ω2
0.
(7.136)
From Eq. (7.133), we get
det[sI −(A −LC)] = s2 + l1s + l2 + ω2
0.
(7.137)
Comparing the coefﬁcients in Eqs. (7.136) and (7.137), we ﬁnd that
L =
 l1
l2
	
=
 20ω0
99ω2
0
	
.
(7.138)
The result can also be found from Matlab. For example, for ω0 = 1, the
following Matlab statements:
wo=1;
A=[0 1;−wo*wo 0];
C=[1 0];
pe=[-10*wo;−10*wo];
Lt=acker(A',C',pe);
L=Lt'
yield L = [20 99]T and agrees with the preceding hand calculations.
Performance of the estimator can be tested by adding the actual state
feedback to the plant and plotting the estimation errors. Note that this is
not the way the system will ultimately be built, but this approach provides
a means of validating the estimator performance. Combining Eq. (7.68) of

492
Chapter 7 State-Space Design
the plant with state feedback with Eq. (7.130) of the estimator with output
feedback results in the following overall system equations:
 ˙x
˙ˆx
	
=

A −BK
0
LC −BK
A −LC
	  x
ˆx
	
,
(7.139)
y = [ C
0 ]
 x
ˆx
	
,
(7.140)
˜y = [ C
−C ]
 x
ˆx
	
.
(7.141)
A block diagram of the setup is drawn in Fig. 7.29.
The response of this closed-loop system with ω0 = 1 to an initial con-
dition x0 = [1.0, 0.0]T and ˆx0 = [0, 0]T is shown in Fig. 7.30, where K is
obtained from Example 7.14 and L comes from Eq. (7.138). The response
may be obtained using the commands impulse or initial in Matlab. Note
Matlab commands
impulse, initial
that the state estimates converge to the actual state-variables after an initial
transient even though the initial value of ˆx had a large error. Also note that
the estimation error decays approximately ﬁve times faster than the decay
of the state itself, as we designed it to do.
Figure 7.29
Estimator connected to
the plant
+
-
y
+
+
Plant
Estimator
u
u
C
K
ˆy
r
x
N
xˆ
x = Ax + Bu
y = Cx
~
x = Ax + Bu + Ly
ˆ
ˆ
~y
©
©
Figure 7.30
Initial-condition
response of oscillator
showing x and ˆx
Time (sec)
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0
-0.5
-1.0
Amplitude
0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
x1
x2
x2
x1
ˆ
ˆ

7.7 Estimator Design
493
Observer Canonical Form
As was the case for control-law design, there is a canonical form for which
the estimator gain design equations are particularly simple and the existence
of a solution is obvious. We introduced this form in Section 7.4.1. The
equations are in the observer canonical form and have the structure:
˙xo = Aoxo + Bou,
(7.142a)
y = Coxo,
(7.142b)
where
Ao =
⎡
⎢⎢⎢⎢⎣
−a1
1
0
0
. . .
0
−a2
0
1
0
. . .
...
...
...
...
1
−an
0
0
0
⎤
⎥⎥⎥⎥⎦
,
Bo =
⎡
⎢⎢⎢⎣
b1
b2
...
bn
⎤
⎥⎥⎥⎦,
Co = [
1
0
0
. . .
0 ],
Do = 0.
A block diagram for the third-order case is shown in Fig. 7.31. In observer
Observer canonical form
canonical form, all the feedback loops come from the output, or observed
signal. Like the control canonical form, the observer canonical form is a
"direct" form because the values of the signiﬁcant elements in the matrices
are obtained directly from the coefﬁcients of the numerator and denominator
polynomials of the corresponding transfer function G(s). The matrix Ao is
called a left companion matrix to the characteristic equation because the
coefﬁcients of the equation appear on the left side of the matrix.
Oneoftheadvantagesoftheobservercanonicalformisthattheestimator
gains can be obtained from it by inspection. The estimator error closed-loop
matrix for the third-order case is
Ao −LCo =
⎡
⎣
−a1 −l1
1
0
−a2 −l2
0
1
−a3 −l3
0
0
⎤
⎦,
(7.143)
which has the characteristic equation
s3 + (a1 + l1)s2 + (a2 + l2)s + (a3 + l3) = 0,
(7.144)
Figure 7.31
Observer canonical form
of a third-order system
Y
-
+
U
b3
s
1
-
+
a3
b2
b1
-
+
s
1
a2
a1
s
1
x3o
+
+
x2o
x1o
©
©
©

494
Chapter 7 State-Space Design
and the estimator gain can be found by comparing the coefﬁcients of
Eq. (7.144) with αe(s) from Eq. (7.134).
In a development exactly parallel with the control-law case, we can ﬁnd
a transformation to take a given system to observer canonical form if and only
if the system has a structural property that in this case we call observability.
Roughly speaking, observability refers to our ability to deduce information
about all the modes of the system by monitoring only the sensed outputs.
Unobservability results when some mode or subsystem is disconnected phys-
ically from the output and therefore no longer appears in the measurements.
For example, if only derivatives of certain state-variables are measured, and
these state-variables do not affect the dynamics, a constant of integration is
obscured. This situation occurs with a plant having the transfer function 1/s2
if only velocity is measured, for then it is impossible to deduce the initial
value of the position. On the other hand, for an oscillator, a velocity mea-
surement is sufﬁcient to estimate position because the acceleration, and con-
sequently the velocity observed, are affected by position. The mathematical
test for determining observability is that the observability matrix,
O =
⎡
⎢⎢⎢⎣
C
CA
...
CAn−1
⎤
⎥⎥⎥⎦,
(7.145)
must have independent columns. In the one output case we will study, O is
square, so the requirement is that O be nonsingular or have a nonzero deter-
minant. In general, we can ﬁnd a transformation to observer canonical form
if and only if the observability matrix is nonsingular. Note that this is analo-
gous to our earlier conclusions for transforming system matrices to control
canonical form.
As with control-law design, we could ﬁnd the transformation to observer
form, compute the gains from the equivalent of Eq. (7.144), and transform
back. An alternative method of computing L is to use Ackermann's formula
Ackermann's estimator
formula
in estimator form, which is
L = αe(A)O−1
⎡
⎢⎢⎢⎣
0
0
...
1
⎤
⎥⎥⎥⎦,
(7.146)
where O is the observability matrix given in Eq. (7.145).
Duality
You may already have noticed from this discussion the considerable resem-
blance between estimation and control problems. In fact, the two problems
are mathematically equivalent. This property is called duality. Table 7.1
Duality of estimation and
control
shows the duality relationships between the estimation and control prob-
lems. For example, Ackermann's control formula [Eq. (7.88)] becomes the

7.7 Estimator Design
495
TABLE 7.1
Duality
Control
Estimation
A
AT
B
CT
C
BT
estimator formula Eq. (7.146) if we make the substitutions given inTable 7.1.
We can demonstrate this directly using matrix algebra. The control problem
is to select the row matrix K for satisfactory placement of the poles of the
system matrix A−BK; the estimator problem is to select the column matrix
L for satisfactory placement of the poles of A −LC. However, the poles of
A −LC equal those of (A −LC)T = AT −CTLT, and in this form, the
algebra of the design for LT is identical to that for K. Therefore, where we
used Ackermann's formula or the place algorithm in the forms
Matlab commands acker,
place
K=acker(A, B, pc),
K=place(A, B, pc),
for the control problem, we use
Lt=acker(A', C', pe),
Lt=place(A', C', pe),
L=Lt',
where pe is a vector containing the desired estimator error poles for the
estimator problem.
Thus duality allows us to use the same design tools for estimator prob-
lems as for control problems with proper substitutions. The two canonical
forms are also dual, as we can see by comparing the triples (Ac, Bc, Cc) and
(A◦, B◦, C◦).
7.7.2
Reduced-Order Estimators
The estimator design method described in Section 7.7.1 reconstructs the
entire state vector using measurements of some of the state-variables. If the
sensors have no noise, a full-order estimator contains redundancies, and it
seems reasonable to question the necessity for estimating state-variables that
are measured directly. Can we reduce the complexity of the estimator using
the state-variables that are measured directly and exactly?Yes. However, it is
better to implement a full-order estimator if there is signiﬁcant noise on the
measurementsbecause, inadditiontoestimatingunmeasuredstate-variables,
the estimator ﬁlters the measurements.
The reduced-order estimator reduces the order of the estimator by the
number (1 in this text) of sensed outputs. To derive this estimator, we start

496
Chapter 7 State-Space Design
with the assumption that the output equals the ﬁrst state as, for example,
y = xa. If this is not so, a preliminary step is required. Transforming to
observer form is possible but overkill; any nonsingular transformation with
C as the ﬁrst row will do. We now partition the state vector into two parts:
xa, which is directly measured, and xb, which represents the remaining
state-variables that need to be estimated. If we partition the system matrices
accordingly, the complete description of the system is given by
 ˙xa
˙xb
	
=
 Aaa
Aab
Aba
Abb
	  xa
xb
	
+
 Ba
Bb
	
u,
(7.147a)
y = [ 1
0 ]
 xa
xb
	
.
(7.147b)
The dynamics of the unmeasured state-variables are given by
˙xb = Abbxb + Abaxa + Bbu



known input
,
(7.148)
where the right-most two terms are known and can be considered as an input
into the xb dynamics. Because xa = y, the measured dynamics are given by
the scalar equation
˙xa = ˙y = Aaay + Aabxb + Bau.
(7.149)
If we collect the known terms of Eq. (7.149) on one side, yielding
˙y −Aaay −Bau



known measurement
= Aabxb,
(7.150)
we obtain a relationship between known quantities on the left side, which we
considermeasurements, andunknownstate-variablesontheright. Therefore,
Eqs. (7.149) and (7.150) have the same relationship to the state xb that the
original equation [Eq. (7.147b)] had to the entire state x. Following this line
of reasoning, we can establish the following substitutions in the original
estimator equations to obtain a (reduced-order) estimator of xb:
x ←xb,
(7.151a)
A ←Abb,
(7.151b)
Bu ←Abay + Bbu,
(7.151c)
y ←˙y −Aaay −Bau,
(7.151d)
C ←Aab.
(7.151e)
Therefore, the reduced-order estimator equations are obtained by substitut-
ing Eqs. (7.151) into the full-order estimator [Eq. (7.130)]:
˙ˆxb = Abbˆxb + Abay + Bbu



input
+ L (˙y −Aaay −Bau



measurement
−Aabˆxb).
(7.152)
If we deﬁne the estimator error to be
˜xb
= xb −ˆxb,
(7.153)

7.7 Estimator Design
497
Figure 7.32
Reduced-order
estimator structure
+
+
+
L
Aba - LAaa
Bb - LBa
Abb - LAab
xb - Ly
xc
xc
xb - Ly
xb
y
u
s
1
+
+
ˆ
ˆ
ˆ
©
©
then the dynamics of the error are given by subtracting Eq. (7.148) from
Eq. (7.152) to get
˙˜xb = (Abb −LAab)˜xb,
(7.154)
and its characteristic equation is given by
det[sI −(Abb −LAab)] = 0.
(7.155)
We design the dynamics of this estimator by selecting L so that Eq. (7.155)
matches a reduced order αe(s). Now Eq. (7.152) can be rewritten as
˙ˆxb = (Abb −LAab)ˆxb + (Aba −LAaa)y + (Bb −LBa)u + L˙y.
(7.156)
The fact that we must form the derivative of the measurements in Eq. (7.156)
appears to present a practical difﬁculty. It is known that differentiation ampli-
ﬁes noise, so if y is noisy, the use of ˙y is unacceptable. To get around this
difﬁculty, we deﬁne the new controller state to be
xc
= ˆxb −Ly.
(7.157)
In terms of this new state, the implementation of the reduced-order estimator
is given by
˙xc = (Abb −LAab)ˆxb + (Aba −LAaa)y + (Bb −LBa)u,
(7.158)
and ˙y no longer appears directly. A block-diagram representation of the
reduced-order estimator is shown in Fig. 7.32.
EXAMPLE 7.25
A Reduced-Order Estimator Design for Pendulum
Design a reduced-order estimator for the pendulum that has the error pole
Reduced-order estimator
at −10ω0.
Solution. We are given the system equations
 ˙x1
˙x2
	
=

0
1
−ω2
0
0
	  x1
x2
	
+
 0
1
	
u,
y = [ 1
0 ]
 x1
x2
	
.
The partitioned matrices are
 Aaa
Aab
Aba
Abb
	
=

0
1
−ω2
0
0
	
,
 Ba
Bb
	
=
 0
1
	
.

498
Chapter 7 State-Space Design
Figure 7.33
Initial-condition
response of the
reduced-order
estimator
Time (sec)
10
Amplitude
0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
8
6
4
2
0
-2
x2
x2
x1
ˆ
From Eq. (7.155), we ﬁnd the characteristic equation in terms of L:
s −(0 −L) = 0.
We compare it with the desired equation,
αe(s) = s + 10ω0 = 0,
which yields
L = 10ω0.
The estimator equation, from Eq. (7.158), is
˙xc = −10ω0ˆx2 −ω2
0y + u,
and the state estimate, from Eq. (7.157), is
ˆx2 = xc + 10ω0y.
We use the control law given in the earlier examples. The response of the
estimator to a plant initial condition x0 = [1.0, 0.0]T and an estimator initial
condition xc0 = 0 is shown in Fig. 7.33 for ω0 = 1. The response may be
obtainedusingthecommandsimpulseor initial inMatlab. Notethesimilarity
Matlab impulse, initial
of the initial-condition response to that of the full-order estimator plotted in
Fig. 7.30.
The reduced-order estimator gain can also be found from Matlab using
Lt = acker(Abb', Aab', pe),
Lt = place(Abb', Aab', pe),
L = Lt'.
The conditions for the existence of the reduced-order estimator are the
same as for the full-order estimator—namely, observability of (Abb, Aab)
which can be shown to be the same as the observability of (A, C).

7.7 Estimator Design
499
7.7.3
Estimator Pole Selection
We can base our selection of estimator pole locations on the techniques dis-
Design rules of thumb for
selecting estimator poles
cussed in Section 7.6 for the case of controller poles. As a rule of thumb,
the estimator poles can be chosen to be faster than the controller poles by a
factor of 2 to 6. This ensures a faster decay of the estimator errors compared
with the desired dynamics, thus causing the controller poles to dominate the
total response. If sensor noise is large enough to be a major concern, we
may choose the estimator poles to be slower than two times the controller
poles, which would yield a system with lower bandwidth and more noise
smoothing. However, we would expect the total system response in this case
to be strongly inﬂuenced by the location of the estimator poles. If the esti-
mator poles are slower than the controller poles, we would expect the system
response to disturbances to be dominated by the dynamic characteristics of
the estimator rather than by those selected by the control law.
In comparison with the selection of controller poles, estimator pole
selection requires us to be concerned with a much different relationship
than with control effort. As in the controller, there is a feedback term in
the estimator that grows in magnitude as the requested speed of response
increases. However, this feedback is in the form of an electronic signal or
a digital word in a computer, so its growth causes no special difﬁculty. In
the controller, increasing the speed of response increases the control effort;
this implies the use of a larger actuator, which in turn increases its size,
weight, and cost. The important consequence of increasing the speed of
response of an estimator is that the bandwidth of the estimator becomes
higher, thus causing more sensor noise to pass on to the control actuator.
Of course, if (A, C) are not observable, then no amount of estimator gain
can produce a reasonable state estimate. Thus, as with controller design, the
best estimator design is a balance between good transient response and low-
enough bandwidth that sensor noise does not signiﬁcantly impair actuator
activity. Both dominant second-order and optimal control ideas can be used
to meet the requirements.
There is a result for estimator gain design based on the SRL. In optimal
estimation theory, the best choice for estimator gain is dependent on the
ratio of sensor noise intensity ν to process (disturbance) noise intensity [w in
Eq. (7.160)]. This is best understood by reexamining the estimator equation
˙ˆx = Aˆx + Bu + L(y −Cˆx)
(7.159)
to see how it interacts with the system when process noise w is present. The
plant with process noise is described by
Process noise
˙x = Ax + Bu + B1w,
(7.160)
and the measurement equation with sensor noise ν is described by
Sensor noise
y = Cx + ν.
(7.161)
The estimator error equation with these additional inputs is found directly by
subtracting Eq. (7.159) from Eq. (7.160) and substituting Eq. (7.161) for y:
˙˜x = (A −LC)˜x + B1w −Lν.
(7.162)

500
Chapter 7 State-Space Design
In Eq. (7.162) the sensor noise is multiplied by L and the process noise
is not. If L is very small, then the effect of sensor noise is removed, but
the estimator's dynamic response will be "slow," so the error will not reject
effects of w very well. The state of a low-gain estimator will not track
uncertain plant inputs very well. These results can, with some success, also
be applied to model errors in, for example, A or B. Such model errors will add
terms to Eq. (7.162) and act like additional process noise. On the other hand,
if L is large, then the estimator response will be fast and the disturbance or
process noise will be rejected, but the sensor noise, multiplied by L, results
in large errors. Clearly, a balance between these two effects is required. It
turns out that the optimal solution to this balance can be found under very
reasonable assumptions by solving an SRL equation for the estimator that
is very similar to the one for the optimal control formulation [Eq. (7.109)].
The estimator SRL equation is
Estimator SRL equation
1 + qGe(−s)Ge(s) = 0,
(7.163)
where q is the ratio of input disturbance noise intensity to sensor noise
intensity and Ge is the transfer function from the process noise to the sensor
output and is given by
Ge(s) = C(sI −A)−1B1.
(7.164)
Note from Eqs. (7.109) and (7.163) that Ge(s) is similar to G0(s). However,
a comparison of Eqs. (7.110) and (7.164) shows that Ge(s) has the input
matrix B1 instead of B, and that G0 is the transfer function from the control
input u to cost output z and has output matrix C1 instead of C.
The use of the estimator SRL [Eq. (7.163)] is identical to the use of the
controller SRL. A root locus with respect to q is generated, thus yielding
sets of optimal estimator poles corresponding more or less to the ratio of
process noise intensity to sensor noise intensity. The designer then picks the
set of (stable) poles that seems best, considering all aspects of the problem.
An important advantage of using the SRL technique is that after the process
noise input matrix B1 has been selected, the "arbitrariness" is reduced to one
degree of freedom, the selection q, instead of the many degrees of freedom
required to select the poles directly in a higher-order system.
A ﬁnal comment concerns the reduced-order estimator. Because of the
presence of a direct transmission term from y through L to xb (see Fig. 7.32),
thereduced-orderestimatorhasamuchhigherbandwidthfromsensortocon-
trolwhencomparedwiththefull-orderestimator. Therefore, ifsensornoiseis
a signiﬁcant factor, the reduced-order estimator is less attractive because the
potential saving in complexity is more than offset by the increased sensitivity
to noise.
EXAMPLE 7.26
SRL Estimator Design for a Simple Pendulum
Draw the estimator SRL for the linearized equations of the simple inverted
pendulum with ωo = 1. Take the output to be a noisy measurement of
position with noise intensity ratio q.

7.8 Compensator Design: Combined Control Law and Estimator
501
Figure 7.34
Symmetric root locus
for the inverted
pendulum estimator
design
-5
-4
-3
-2
-1
0
1
2
3
4
5
Imaginary axis
-5
-4
-3
-2
-1
0
1
2
3
4
5
Real axis
q = 0
q = 365
q = 365
q = 0
Solution. We are given the system equations
 ˙x1
˙x2
	
=

0
1
−ω2
0
0
	  x1
x2
	
+
 0
1
	
w,
y = [ 1
0 ]
 x1
x2
	
+ v.
We then calculate from Eq. (7.164) that
Ge(s) =
1
s2 + ω2
0
.
The symmetric 180◦loci are shown in Fig. 7.34. The Matlab statements to
generate the SRL are (for ωo = 1)
s=tf('s');
G=1/(sˆ2+1);
sysGG=G*G;
rlocus(sysGG);
We would choose two stable roots for a given value of q, for example,
s = −3 ± j3.18 for q = 365, and use them for estimator pole placement.
7.8
Compensator Design: Combined Control
Law and Estimator
If we take the control-law design described in Section 7.5, combine it with
the estimator design described in Section 7.7, and implement the control law
by using the estimated state-variables, the design is complete for a regulator
Regulator
that is able to reject disturbances but has no external reference input to track.
However, because the control law was designed for feedback of the actual
(not the estimated) state, you may wonder what effect using ˆx in place of x
has on the system dynamics. In this section we compute this effect. In doing

502
Chapter 7 State-Space Design
so we will compute the closed-loop characteristic equation and the open-
loop compensator transfer function. We will use these results to compare the
state-space designs with root-locus and frequency-response designs.
The plant equation with feedback is now
˙x = Ax −BKˆx,
(7.165)
which can be rewritten in terms of the state error ˜x as
˙x = Ax −BK(x −˜x).
(7.166)
The overall system dynamics in state form are obtained by combining
Eq. (7.166) with the estimator error [Eq. (7.132)] to get
 ˙x
˙˜x
	
=
 A −BK
BK
0
A −LC
	  x
˜x
	
.
(7.167)
The characteristic equation of this closed-loop system is
det
 sI −A + BK
−BK
0
sI −A + LC
	
= 0.
(7.168)
Because the matrix is block triangular (see Appendix WD available at
www.fpe7e.com), we can rewrite Eq. (7.168) as
det(sI −A + BK) · det(sI −A + LC) = αc(s)αe(s) = 0.
(7.169)
In other words, the set of poles of the combined system consists of the union
Poles of the
combined control law and
estimator
of the control poles and the estimator poles. This means that the designs of
the control law and the estimator can be carried out independently, yet when
they are used together in this way, the poles remain unchanged.9
Tocomparethestate-variablemethodofdesignwiththetransformmeth-
ods discussed in Chapters 5 and 6, we note from Fig. 7.35 that the blue shaded
portion corresponds to a compensator. The state equation for this compen-
sator is obtained by including the feedback law u = −Kˆx (because it is part
of the compensator) in the estimator Eq. (7.130) to get
˙ˆx = (A −BK −LC)ˆx + Ly,
(7.170a)
u = −Kˆx.
(7.170b)
Figure 7.35
Estimator and controller
mechanization
Control law
Plant
y(t)
Compensator
u(t)
x(t)
x(t)
C
y
w
Sensor
u(t)
x = Ax + Bu
-K
ˆ
Estimator
x = Ax + Bu
+ L(y - Cx)
ˆ
ˆ
ˆ
9This is a special case of the separation principle (Gunckel and Franklin, 1963), which holds
in much more general contexts and allows us to obtain an overall optimal design by combining
the separate designs of control law and estimator in certain stochastic cases.

7.8 Compensator Design: Combined Control Law and Estimator
503
Note that Eq. (7.170a) has the same structure as Eq. (7.18a), which we
repeat here:
˙x = Ax + Bu.
(7.171)
Because the characteristic equation of Eq. (7.18a) is
det(sI −A) = 0,
(7.172)
the characteristic equation of the compensator is found by comparing
Eqs. (7.170a) and (7.171), and substituting the equivalent matrices into
Eq. (7.172) to get
det(sI −A + BK + LC) = 0.
(7.173)
Note that we never speciﬁed the roots of Eq. (7.173) nor used them in our dis-
cussion of the state-space design technique. (Note also that the compensator
is not guaranteed to be stable; the roots of Eq. (7.173) can be in the RHP.)
The transfer function from y to u representing the dynamic compensator
Compensator transfer
function
is obtained by inspecting Eq. (7.45) and substituting in the corresponding
matrices from Eq. (7.173):
Dc(s) = U(s)
Y(s) = −K(sI −A + BK + LC)−1L.
(7.174)
The same development can be carried out for the reduced-order
estimator. Here the control law is
u = −[ Ka
Kb ]
 xa
ˆxb
	
= −Kay −Kbˆxb.
(7.175)
Substituting Eq. (7.175) into Eq. (7.171) and using Eq. (7.158) and some
algebra, we obtain
˙xc = Arxc + Bry,
(7.176a)
u = Crxc + Dry,
(7.176b)
where
Ar = Abb −LAab −(Bb −LBa)Kb,
(7.177a)
Br = ArL + Aba −LAaa −(Bb −LBa)Ka,
(7.177b)
Cr = −Kb,
(7.177c)
Dr = −Ka −KbL.
(7.177d)
The dynamic compensator now has the transfer function
Reduced-order
compensator transfer
function
Dcr(s) = U(s)
Y(s) = Cr(sI −Ar)−1Br + Dr.
(7.178)
When we compute Dc(s) or Dcr(s) for a speciﬁc case, we will ﬁnd that they
are very similar to the classical compensators given in Chapters 5 and 6, in
spite of the fact that they are arrived at by entirely different means.

504
Chapter 7 State-Space Design
EXAMPLE 7.27
Full-Order Compensator Design for Satellite Attitude Control
Design a compensator using pole placement for the satellite plant with
transfer function 1/s2. Place the control poles at s = −0.707 ± 0.707j
(ωn = 1 rad/sec, ζ = 0.707) and place the estimator poles at ωn = 5 rad/sec,
ζ = 0.5.
Solution. Astate-variabledescriptionforthegiventransferfunctionG(s) =
1/s2 is
˙x =
 0
1
0
0
	
x +
 0
1
	
u,
y =
 1
0 
x.
If we place the control roots at s = −0.707 ± 0.707j (ωn = 1 rad/sec,
ζ = 0.7), then
αc(s) = s2 + s
√
2 + 1.
(7.179)
From K = place(A,B,pc), the state feedback gain is found to be
K =

1
√
2

.
If the estimator error roots are at ωn = 5 rad/sec and ζ = 0.5, the desired
estimator characteristic polynomial is
αe(s) = s2 + 5s + 25 = s + 2.5 ± 4.3j,
(7.180)
and, from Lt = place(A',C',pe), the estimator feedback-gain matrix is found
to be
L =
 5
25
	
.
The compensator transfer function given by Eq. (7.174) is
Dc(s) = −40.4
(s + 0.619)
s + 3.21 ± 4.77j,
(7.181)
which looks very much like a lead compensator in that it has a zero on the real
axis to the right of its poles; however, rather than one real pole, Eq. (7.181)
has two complex poles. The zero provides the derivative feedback with phase
lead, and the two poles provide some smoothing of sensor noise.
The effect of the compensation on this system's closed-loop poles can be
evaluated in exactly the same way we evaluated compensation in Chapters 5
and 6 using root-locus or frequency-response tools. The gain of 40.4 in
Eq. (7.181) is a result of the pole selection inherent in Eqs. (7.179) and
(7.180). If we replace this speciﬁc value of compensator gain with a variable
gain K, then the characteristic equation for the closed-loop system of plant
plus compensator becomes
1 + K
(s + 0.619)
(s + 3.21 ± 4.77j)s2 = 0.
(7.182)
The root-locus technique allows us to evaluate the roots of this equation with
respect to K, as drawn in Fig. 7.36. Note that the locus goes through the roots

7.8 Compensator Design: Combined Control Law and Estimator
505
Figure 7.36
Root locus for the
combined controller
and estimator, with
process gain as the
parameter
Re(s)
Im(s)
-2
-4
-6
-8
6
4
2
-2
-4
-6
K = 40.4
K = 40.4
Figure 7.37
Frequency response for
G(s) = 1/s2
v (rad/sec)
0.1
1
10
100
0.1
1
10
100
0.02 0.04
0.2
0.40.6
2
4
6
20
40 60
Compensated
Uncompensated
100
10
1
0.1
0.01
-1205
-1505
-1805
-2105
-2405
-2705
Phase
Magnitude
535
40
20
0
-20
v (rad/sec)
db
selected for Eqs. (7.179) and (7.180), and, when K = 40.4, the four roots of
the closed-loop system are equal to those speciﬁed.
The frequency-response plots given in Fig. 7.37 show that the compen-
sation designed using state-space accomplishes the same results that one
Identical results of
state-space and frequency
response design methods
would strive for using frequency-response design. Speciﬁcally, the uncom-
pensated phase margin of 0◦increases to 53◦in the compensated case, and
the gain K = 40.4 produces a crossover frequency ωc = 1.35 rad/sec.
Both these values are roughly consistent with the controller closed-loop

506
Chapter 7 State-Space Design
roots, with ωn = 1 rad/sec and ζ = 0.7, as we would expect, because
these slow controller poles are dominant in the system response over the fast
estimator poles.
Now we consider a reduced-order estimator for the same system.
EXAMPLE 7.28
Reduced-Order Compensator Design for a Satellite
Attitude Control
Repeat the design for the 1/s2 satellite plant, but use a reduced-order
estimator. Place the one estimator pole at −5 rad/sec.
Solution. From Eq. (7.155) we know that the estimator gain is
L = 5,
and from Eqs. (7.176a, b) the scalar compensator equations are
˙xc = −6.41xc −33.1y,
u = −1.41xc −8.07y,
where, from Eq. (7.157),
xc = ˆx2 −5y.
The compensator has the transfer function calculated from Eq. (7.178) to be
Dcr(s) = −8.07(s + 0.619)
s + 6.41
,
and is shown in Fig. 7.38.
The reduced-order compensator here is precisely a lead network. This is
a pleasant discovery, as again it shows that transform and state-variable tech-
niques can result in exactly the same type of compensation. The root locus
of Fig. 7.39 shows that the closed-loop poles occur at the assigned locations.
The frequency response of the compensated system seen in Fig. 7.40 shows
a phase margin of about 55◦. As with the full-order estimator, analysis by
other methods conﬁrms the selected root locations.
More subtle properties of the pole-placement method can be illustrated
by a third-order system.
Figure 7.38
Simpliﬁed block
diagram of a
reduced-order
controller that is a lead
network
Y
s
1
+
+
U
+
+
0.619
-8.07
-6.41
©
©

7.8 Compensator Design: Combined Control Law and Estimator
507
Figure 7.39
Root locus of a
reduced-order
controller and 1/s2
process, root locations
at K = 8.07 shown by
the dots
Re(s)
Im(s)
-2
-4
-6
-8
4
2
0.1
1
10
100
0.02
0.04
0.2
0.4 0.6
2
4
6
20
40 60
0.1
1
10
100
v (rad/sec)
v (rad/sec)
555
Compensated
Uncompensated
100
10
1
0.1
0.01
-1205
-1505
-1805
-2105
Phase
Magnitude
40
20
0
-20
db
8
Figure 7.40
Frequency response for G(s) = 1/s2 with a reduced-order estimator
EXAMPLE 7.29
Full-Order Compensator Design for DC Servo
Use the state-space pole-placement method to design a compensator for the
DC servo system with the transfer function
G(s) =
10
s(s + 2)(s + 8).
Using a state description in observer canonical form, place the control poles
at pc = [−1.42; −1.04 ± 2.14j] locations and the full-order estimator poles
at pe = [−4.25; −3.13 ± 6.41j].

508
Chapter 7 State-Space Design
Figure 7.41
DC servo in observer
canonical form
U
s
1
-
+
16
Y
-
+
10
s
1
10
s
1
©
©
Solution. A block diagram of this system in observer canonical form is
shown in Fig. 7.41. The corresponding state-space matrices are
A =
⎡
⎣
−10
1
0
−16
0
1
0
0
0
⎤
⎦,
B =
⎡
⎣
0
0
10
⎤
⎦,
C =

1
0
0 
,
D = 0.
The desired poles are
pc =

−1.42; −1.04 + 2.14 ∗j; −1.04 −2.14 ∗j

.
We compute the state feedback gain to be K=(A,B,pc),
K = [ −46.4
5.76
−0.65 ].
The estimator error poles are at
pe = [−4.25; −3.13 + 6.41 ∗j; −3.13 −6.41 ∗j];
We compute the estimator gain to be Lt=place(A', C', pe), L=Lt',
L =
⎡
⎣
0.5
61.4
216
⎤
⎦.
The compensator transfer function, as given by substituting into
Eq. (7.174), is
Dc(s) = −190
(s + 0.432)(s + 2.10)
(s −1.88)(s + 2.94 ± 8.32j).
Figure 7.42 shows the root locus of the system of compensator and plant
in series, plotted with the compensator gain as the parameter. It veriﬁes that
the roots are in the desired locations speciﬁed when the gain K = 190 in
spite of the peculiar (unstable) compensation that has resulted. Even though
this compensator has an unstable root at s = +1.88, all system closed-loop
poles (controller and estimator) are stable.
An unstable compensator is typically not acceptable because of the dif-
ﬁculty in testing either the compensator by itself or the system in open loop
during a bench checkout. In some cases, however, better control can be
achieved with an unstable compensator; then its inconvenience in checkout
may be worthwhile.10
10There are even systems that cannot be stabilized with a stable compensator.

7.8 Compensator Design: Combined Control Law and Estimator
509
Figure 7.42
Root locus for DC servo
pole assignment
-2
-4
-6
-8
6
8
4
-4
-6
-8
2
Re(s)
Im(s)
4
Figure 7.33 shows that a direct consequence of the unstable compen-
sator is that the system becomes unstable as the gain is reduced from its
nominal value. Such a system is called conditionally stable and should
Conditionally stable
compensator
be avoided if possible. As we shall see in Chapter 9, actuator saturation in
response to large signals has the effect of lowering the effective gain, and
in a conditionally stable system, instability can result. Also, if the electron-
ics are such that the control ampliﬁer gain rises continuously from zero to
the nominal value during startup, such a system would be initially unstable.
These considerations lead us to consider alternative designs for this system.
EXAMPLE 7.30
Redesign of the DC Servo System with
a Reduced-Order Estimator
Design a compensator for the DC servo system of Example 7.29 using the
same control poles but with a reduced-order estimator. Place the estimator
poles at −4.24 ± 4.24j positions with ωn = 6 rad/sec and ζ = 0.707.
Solution. The reduced-order estimator corresponds to poles at
pe =

−4.24 + 4.24 ∗j; −4.24 −4.24 ∗j

.
After partitioning we have,
 Aaa
Aab
Aba
Abb
	
=
⎡
⎣
−10
1
0
−16
0
1
0
0
0
⎤
⎦,
⎡
⎣
Ba
Bb
⎤
⎦=
⎡
⎣
0
0
10
⎤
⎦.
Solving for the estimator error characteristic polynomial,
det(sI −Abb + LAab) = αe(s),

510
Chapter 7 State-Space Design
Figure 7.43
Root locus for DC servo
reduced-order
controller
Re(s)
Im(s)
1
1
-1
-3
3
4
5
6
2
3
-1
-2
-4
-5
-6
-7
-8
-4
-5
we ﬁnd (using place) that
L =
 8.5
36
	
.
The compensator transfer function, given by Eq. (7.178), is computed to be
Dcr(s) = 20.93(s −0.735)(s + 1.871)
(s + 0.990 ± 6.120 j) .
The associated root locus for this system is shown in Fig. 7.43. Note that
A nonminimum-phase
compensator
this time we have a stable but nonminimum-phase compensator and a zero-
degree root locus. The RHP portion of the locus will not cause difﬁculties
because the gain has to be selected to keep all closed-loop poles in the LHP.
As a next pass at the design for this system, we attempt a design with the SRL.
EXAMPLE 7.31
Redesign of the DC Servo Compensator Using the SRL
Design a compensator for the DC servo system of Example 7.29 using
pole placement based on the SRL. For the control law, let the cost out-
put z be the same as the plant output; for the estimator design, assume
that the process noise enters at the same place as the system control signal.
Select roots for a control bandwidth of about 2.5 rad/sec, and choose the
estimator roots for a bandwidth of about 2.5 times faster than the control
bandwidth (6.3 rad/sec). Verify the design by plotting the step response and
commenting. SeeAppendix W7.8 available at www.fpe7e.com for a discrete
implementation of the solution.
Solution.
Because the problem has speciﬁed that B1 = B and C1 = C,
then the SRL is the same for the control as for the estimator, so we need
to generate only one locus based on the plant transfer function. The SRL
for the system is shown in Fig. 7.44. From the locus, we select −2 ± 1.56j

7.8 Compensator Design: Combined Control Law and Estimator
511
Figure 7.44
Symmetric root locus
for DC servo system
Re(s)
Im(s)
1
1
-1
-2
-3
-4
-5
2
3
4
5
2
3
4
5
6
7
8
-1
-2
-3
-4
-5
-6
-7
-8
-9
Controller poles
Estimator poles
and −8.04 as the desired control poles (pc=[−2+1.56*j;−2−1.56*j;−8.04])
and −4±4.9j and −9.169 (pe=[−4+4.9*j;−4−4.9*j;−9.169]) as the desired
estimator poles. The state feedback gain is K=(A,B,pc), or
K = [ −0.285
0.219
0.204 ],
and the estimator gain is Lt=place(A', C', pe), L=Lt', or
L =
⎡
⎣
7.17
97.4
367
⎤
⎦.
Notice that the feedback gains are much smaller than before. The result-
ing compensator transfer function is computed from Eq. (7.174) to be
Dc(s) = −
94.5(s + 7.98)(s + 2.52)
(s + 4.28 ± 6.42j)(s + 10.6).
We now take this compensator, put it in series with the plant, and use the
compensator gain as the parameter. The resulting ordinary root locus of the
closed-loop system is shown in Fig. 7.45. When the root-locus gain equals
the nominal gain of 94.5, the roots are at the closed-loop locations selected
from the SRL, as they should be. The step response and the associated control
effort are shown in Fig. 7.46.
Note that the compensator is now stable and minimum phase. This
improved design comes about in large part because the plant pole at s = −8
is virtually unchanged by either controller or estimator. It does not need
to be changed for good performance; in fact, the only feature in need of
repair in the original G(s) is the pole at s = 0. Using the SRL technique,
we essentially discovered that the best use of control effort is to shift the
two low-frequency poles at s = 0 and −2 and to leave the pole at s = −8
virtually unchanged. As a result, the control gains are much lower and the
compensator design is less radical. This example illustrates why LQR design
is typically preferable over pole placement.

512
Chapter 7 State-Space Design
Figure 7.45
Root locus for pole
assignment from
the SRL
Re(s)
Im(s)
1
1
-1
-2
-3
-4
-6
-7
2
3
4
7
6
2
-2
-4
-6
-10
Controller poles
Estimator poles
Armed with the knowledge gained from Example 7.31, let us go back, with
a better selection of poles, to investigate the use of pole placement for this
example. Initially we used the third-order locations, which produced three
poles with a natural frequency of about 2 rad/sec. This design moved the
pole at s = −8 to s = −1.4, thus violating the principle that open-loop
poles should not be moved unless they are a problem. Now let us try it again,
this time using dominant second-order locations to shift the slow poles, and
leaving the fast pole alone at s = −8.
EXAMPLE 7.32
DC Servo System Redesign with Modiﬁed Dominant
Second-Order Pole Locations
Design a compensator for the DC servo system of Example 7.29 using pole
placement with control poles given by
pc =[−1.41 ± 1.41 j; −8]
and the estimator poles given by
pe =[−4.24 ± 4.24j; −8].
Solution. With these pole locations, we ﬁnd that the required feedback gain
is (using K=place(A,B,pc))
K = [ −0.469
0.234
0.0828 ],
which has a smaller magnitude than the case where the pole at s = −8 was
moved.

7.8 Compensator Design: Combined Control Law and Estimator
513
Figure 7.46
Step response and
control effort: (a) step
response, (b) control
signal
0
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1
2
3
4
5
Time (sec)
y
(a)
0
-2
1
0
-1
2
3
4
5
6
7
1
2
3
4
5
Time (sec)
u
(b)
We ﬁnd the estimator gain to be (using Lt = place(A', C', pe), L=Lt')
L =
⎡
⎣
6.48
87.8
288
⎤
⎦.
The compensator transfer function is computed from Eq. (7.174)
Dc(s) = −
414(s + 2.78)(s + 8)
(s + 4.13 ± 5.29j)(s + 9.05),
which is stable and minimum phase. This example illustrates the value of
judicious pole selection and of the SRL technique.

514
Chapter 7 State-Space Design
The poor pole selection inherent in the initial use of the poles results in
higher control effort and produces an unstable compensator. Both of these
undesirable features are eliminated using the SRL (or LQR), or by improved
pole selection. But we really need to use SRL to guide the proper selection
of poles. The bottom line is that SRL (or LQR) is the method of choice!
As seen from some of the preceding examples, we have shown the use
of optimal design via the SRL. However, it is more common in practice to
skip that step and use LQR directly.
7.9
Introduction of the Reference Input
with the Estimator
The controller obtained by combining the control law studied in Section 7.5
with the estimator discussed in Section 7.8 is essentially a regulator design.
This means that the characteristic equations of the control and the estimator
are chosen for good disturbance rejection—that is, to give satisfactory tran-
sients to disturbances such as w(t). However, this design approach does not
consider a reference input, nor does it provide for command following,
which is evidenced by a good transient response of the combined sys-
tem to command changes. In general, good disturbance rejection and good
command following both need to be taken into account in designing a con-
trol system. Good command following is done by properly introducing the
reference input into the system equations.
Let us repeat the plant and controller equations for the full-order esti-
mator; the reduced-order case is the same in concept, differing only in
detail:
Plant:
˙x = Ax + Bu,
(7.183a)
y = Cx;
(7.183b)
Controller:
˙ˆx = (A −BK −LC)ˆx + Ly,
(7.184a)
u = −Kˆx.
(7.184b)
Figure 7.47 shows two possibilities for introducing the command input r into
the system. This ﬁgure illustrates the general issue of whether the compen-
sation should be put in the feedback or feed-forward path. The response of
the system to command inputs is different, depending on the conﬁguration,
because the zeros of the transfer functions are different. The closed-loop
poles are identical, however, as can be easily veriﬁed by letting r = 0 and
noting that the systems are then identical.
The difference in the responses of the two conﬁgurations can be seen
quite easily. Consider the effect of a step input in r. In Fig. 7.47(a) the step
will excite the estimator in precisely the same way that it excites the plant;
thus the estimator error will remain zero during and after the step. This
means that the estimator dynamics are not excited by the command input,

7.9 Introduction of the Reference Input with the Estimator
515
Figure 7.47
Possible locations for
introducing the
command input:
(a) compensation in the
feedback path;
(b) compensation in the
feed-forward path
(a)
(b)
©
-
 + 
Plant
e
y
r
Estimator
K
u
Compensator
-xˆ
©
 + 
 + 
Plant
u
-K
y
r
Estimator
x
Compensator
ˆ
N
so the transfer function from r to y must have zeros at the estimator pole
locations that cancel those poles. As a result, a step command will excite
system behavior that is consistent with the control poles alone—that is, with
the roots of det(sI −A + BK) = 0.
In Fig. 7.47(b), a step command in r enters directly only into the estima-
tor, thus causing an estimation error that decays with the estimator dynamic
characteristics in addition to the response corresponding to the control poles.
Therefore, a step command will excite system behavior consistent with both
control roots and estimator roots—that is, the roots of
det(sI −A + BK) · det(sI −A + LC) = 0.
For this reason, the conﬁguration shown in Fig. 7.47(a) is typically the supe-
rior way to command the system, where ¯N is found using Eqs. (7.97)-(7.99).
In Section 7.9.1, we will show a general structure for introducing the
reference input with three choices of parameters that implement either the
feed-forward or the feedback case. We will analyze the three choices from
the point of view of the system zeros and the implications the zeros have for
the system transient response. Finally, in Section 7.9.2 we will show how to
select the remaining parameter to eliminate constant errors.
7.9.1
General Structure for the Reference Input
Given a reference input r(t), the most general linear way to introduce r into
the system equations is to add terms proportional to it in the controller equa-
tions. We can do this by adding ¯Nr to Eq. (7.184b) and Mr to Eq. (7.184a).

516
Chapter 7 State-Space Design
Note that in this case, ¯N is a scalar and M is an n × 1 vector. With these
additions, the controller equations become
Controller equations
˙ˆx = (A −BK −LC)ˆx + Ly + Mr,
(7.185a)
u = −Kˆx + ¯Nr.
(7.185b)
The block diagram is shown in Fig. 7.48(a). The alternatives shown in
Fig. 7.47 correspond to different choices of M and ¯N. Because r(t) is an
external signal, it is clear that neither M nor ¯N affects the characteristic
equation of the combined controller-estimator system. In transfer-function
terms, the selection of M and ¯N will affect only the zeros of transmission
from r to y and, as a consequence, can signiﬁcantly affect the transient
response but not the stability. How can we choose M and ¯N to obtain satis-
factory transient response? We should point out that we assigned the poles
of the system by feedback gains K and L, and we are now going to assign
zeros by feed-forward gains M and ¯N.
There are three strategies for choosing M and ¯N:
Three methods for
selecting M and ¯N
1. Autonomous estimator: Select M and ¯N so that the state estimator error
equation is independent of r [Fig. 7.48(b)].
©
+
+
Plant
x
y
r
N
M
u
Estimator
©
+
+
Plant
x
y
r
u
Estimator
(a)
(b)
Plant
x
y
u
Estimator
(c)
© -
+
r
-e
ˆ
ˆ
ˆ
N
Figure 7.48
Alternative ways to introduce the reference input: (a) general case—zero assignment; (b) standard
case—estimator not excited, zeros = αe(s); (c) error-control case—classical compensation

7.9 Introduction of the Reference Input with the Estimator
517
2. Tracking-error estimator: Select M and ¯N so that only the tracking error,
e = (r −y), is used in the control [Fig. 7.48(c)].
3. Zero-assignment estimator: Select M and ¯N so that n of the zeros of the
overall transfer function are assigned at places of the designer's choice
[Fig. 7.48(a)].
CASE 1. From the viewpoint of estimator performance, the ﬁrst method
is quite attractive and the most widely used of the alternatives. If ˆx is to gener-
ate a good estimate of x, then surely ˜x should be as free of external excitation
as possible; that is, ˜x should be uncontrollable from r. The computation of
M and ¯N to bring this about is quite easy. The estimator error equation is
found by subtracting Eq. (7.185a) from Eq. (7.183a), with the plant output
[Eq. (7.183b)] substituted into the estimator [Eq. (7.184a)] and the control
[Eq. (7.184b)] substituted into the plant [Eq. (7.183a)]:
˙x −˙ˆx = Ax + B(−Kˆx + ¯Nr)
−[(A −BK −LC)ˆx + Ly + Mr],
(7.186a)
˙˜x = (A −LC)˜x + B ¯Nr −Mr.
(7.186b)
If r is not to appear in Eq. (7.186a), then we should choose
M = B ¯N.
(7.187)
Because ¯N is a scalar, M is ﬁxed to within a constant factor. Note that with
this choice of M, we can write the controller equations as
u = −Kˆx + ¯Nr,
(7.188a)
˙ˆx = (A −LC)ˆx + Bu + Ly,
(7.188b)
which matches the conﬁguration in Fig. 7.48(b). The net effect of this choice
is that the control is computed from the feedback gain and the reference
input before it is applied, and then the same control is input to both the plant
and the estimator. In this form, if the plant control is subject to saturation
(as shown by the inclusion of the saturation nonlinearity in Fig. 7.48(b), and
discussed in Chapter 9), the same control limits can be applied in Eq. (7.188)
to the control entering the equation for the estimate ˆx, and the nonlinearity
cancels out of the ˜x equation. This behavior is essential for proper estimator
performance. The block diagram corresponding to this technique is shown
in Fig. 7.48(b). We will return to the selection of the gain factor on the
reference input, ¯N, in Section 7.9.2 after discussing the other two methods
of selecting M.
CASE 2. The second approach suggested earlier is to use the tracking
error. This solution is sometimes forced on the control designer when the
sensor measures only the output error. For example, in many thermostats
the output is the difference between the temperature to be controlled and
the setpoint temperature, and there is no absolute indication of the reference
temperature available to the controller. Also, some radar tracking systems
have a reading that is proportional to the pointing error, and this error signal
alone must be used for feedback control. In these situations, we must select

518
Chapter 7 State-Space Design
M and ¯N so that Eqs. (7.188) are driven by the error only. This requirement
is satisﬁed if we select
¯N = 0
and
M = −L.
(7.189)
Then the estimator equation is
˙ˆx = (A −BK −LC)ˆx + L(y −r).
(7.190)
The compensator in this case, for low-order designs, is a standard lead
compensator in the forward path. As we have seen in earlier chapters, this
design can have a considerable amount of overshoot because of the zero
of the compensator. This design corresponds exactly to the compensators
designed by the transform methods given in Chapters 5 and 6.
CASE 3. The third method of selecting M and ¯N is to choose the values
so as to assign the system's zeros to arbitrary locations of the designer's
choice. This method provides the designer with the maximum ﬂexibility
in satisfying transient-response and steady-state gain constraints. The other
two methods are special cases of this third method.All three methods depend
on the zeros. As we saw in Section 7.5.2, when there is no estimator and the
reference input is added to the control, the closed-loop system zeros remain
ﬁxed as the zeros of the open-loop plant. We now examine what happens to
the zeros when an estimator is present. To do so, we reconsider the controller
of Eqs. (7.188). If there is a zero of transmission from r to u, then there is
necessarily a zero of transmission from r to y, unless there is a pole at the
same location as the zero. It is therefore sufﬁcient to treat the controller alone
to determine what effect the choices of M and ¯N will have on the system
zeros. The equations for a zero from r to u from Eqs. (7.188) are given by
det
 sI −A + BK + LC
−M
−K
¯N
	
= 0.
(7.191)
(We let y = 0 because we care only about the effect of r.) If we divide the
last column by the (nonzero) scalar ¯N and then add to the rest the product
of K times the last column, we ﬁnd that the feed-forward zeros are at the
values of s such that
det
 sI −A + BK + LC −M
¯N K
−M
¯N
0
1
	
= 0,
or
det

sI −A + BK + LC −M
¯N K

= γ (s) = 0.
(7.192)
Now Eq. (7.192) is exactly in the form of Eq. (7.133) for selecting L to yield
desired locations for the estimator poles. Here we have to select M/ ¯N for
a desired zero polynomial γ (s) in the transfer function from the reference
input to the control. Thus the selection of M provides a substantial amount
of freedom to inﬂuence the transient response. We can add an arbitrary

7.9 Introduction of the Reference Input with the Estimator
519
nth-order polynomial to the transfer function from r to u and hence from r
to y; that is, we can assign n zeros in addition to all the poles that we assigned
previously. If the roots of γ (s) are not canceled by the poles of the system,
then they will be included in zeros of transmission from r to y.
Two considerations can guide us in the choice of M/ ¯N—that is, in
the location of the zeros. The ﬁrst is dynamic response. We have seen in
Chapter 3 that the zeros inﬂuence the transient response signiﬁcantly, and
the heuristic guidelines given there may suggest useful locations for the
available zeros. The second consideration, which will connect state-space
design to another result from transform techniques, is steady-state error or
velocity-constant control. In Chapter 4 we derived the relationship between
the steady-state accuracy of a Type 1 system and the closed-loop poles and
zeros. If the system is Type 1, then the steady-state error to a step input will
be zero and to a unit-ramp input will be
e∞= 1
Kv
,
(7.193)
where Kv is the velocity constant. Furthermore, it can be shown that if the
closed-loop poles are at {pi} and the closed-loop zeros are at {zi}, then (for
a Type 1 system) Truxal's formula gives
Truxal's formula
1
Kv
=
 1
zi
−
 1
pi
.
(7.194)
Equation (7.194) forms the basis for a partial selection of γ (s), and hence
of M and ¯N. The choice is based on two observations:
1. If |zi −pi| ≪1, then the effect of this pole-zero pair on the dynamic
response will be small, because the pole is almost canceled by the zero,
and in any transient the residue of the pole at pi will be very small.
2. Even though zi−pi is small, it is possible for 1/zi−1/pi to be substantial
and thus to have a signiﬁcant inﬂuence on Kv according to Eq. (7.194).
Application of these two guidelines to the selection of γ (s), and hence
of M and ¯N, results in a lag-network design. We illustrate this with an
example.
EXAMPLE 7.33
Servomechanism: Increasing the Velocity Constant
through Zero Assignment
Consider the second-order servomechanism system described by
Lag compensation by a
state-space method
G(s) =
1
s(s + 1),
and with state description
˙x1 = x2,
˙x2 = −x2 + u.
Design a controller using pole placement so that both poles are at s = −2
and the system has a velocity constant Kv = 10 sec−1. Verify the design

520
Chapter 7 State-Space Design
by plotting the step response and the control effort. See Appendix W7.9
available at www.fpe7e.com for a discrete implementation of the solution.
Solution. For this problem, the state feedback gain
K = [ 8
3 ],
results in the desired control poles. However, with this gain, Kv = 2 sec−1,
and we need Kv = 10 sec−1. What effect will using estimators designed
according to the three methods for M and ¯N selection have on our design?
Using the ﬁrst strategy (the autonomous estimator), we ﬁnd that the value
of Kv does not change. If we use the second method (error control), we
introduce a zero at a location unknown beforehand, and the effect on Kv will
not be under direct design control. However, if we use the third option (zero
placement) along with Truxal's formula [Eq. (7.194)], we can satisfy both
the dynamic response and the steady-state requirements.
First we must select the estimator pole p3 and the zero z3 to satisfy
Eq. (7.194) for Kv = 10 sec−1. We want to keep z3 −p3 small, so that there
is little effect on the dynamic response, and yet have 1/z3 −1/p3 be large
enough to increase the value of Kv. To do this, we arbitrarily set p3 small
compared with the control dynamics. For example, we let
p3 = −0.1.
Notice that this approach is opposite to the usual philosophy of estimation
design, where fast response is the requirement. Now, using Eq. (7.194) to get
1
Kv
= 1
z3
−1
p1
−1
p2
−1
p3
,
where p1 = −2 + 2j, p2 = −2 −2j, and p3 = −0.1, we solve for z3 such
that Kv = 10 we obtain
1
Kv
= 4
8 + 1
0.1 + 1
z3
= 1
10,
or
z3 = −1
10.4 = −0.096.
We thus design a reduced-order estimator to have a pole at −0.1 and choose
M/ ¯N such that γ (s) has a zero at −0.096. A block diagram of the resulting
system is shown in Fig. 7.49(a). You can readily verify that this system has
the overall transfer function
Y(s)
R(s) =
8.32(s + 0.096)
(s2 + 4s + 8)(s + 0.1),
(7.195)
for which Kv = 10 sec−1, as speciﬁed.
The compensation shown in Fig. 7.49(a) is nonclassical in the sense that
it has two inputs (e and y) and one output. If we resolve the equations to
provide pure error compensation by ﬁnding the transfer function from e and

7.9 Introduction of the Reference Input with the Estimator
521
Figure 7.49
Servomechanism with
assigned zeros (a lag
network): (a) the
two-input compensator;
(b) equivalent
unity-feedback system
(a)
(b)
Y
©
-
+
R
s
1
0.8
©
+
+
-3.1
©
+
+
+
8.32
s(s + 1)
1
3.02
u
e
(s + 4.08)(s + 0.0196)
(s + 1)(8.32s + 0.8)
Y
©
-
+
R
s(s + 1)
1
u
e
xc
u, which would give Eq. (7.195), we obtain the system shown in Fig. 7.49(b).
This can be seen as follows: The relevant controller equations are
˙xc = 0.8 e −3.1 u,
u = 8.32 e + 3.02 y + xc,
where xc is the controller state. Taking the Laplace transform of these equa-
tions, eliminating Xc(s), and substituting for the output [Y(s) = G(s)U(s)],
we ﬁnd that the compensator is described by
U(s)
E(s) = Dc(s) =
(s + 1)(8.32s + 0.8)
(s + 4.08)(s + 0.0196).
This compensation is a classical lag-lead network. The root locus of the
system in Fig. 7.49(b) is shown in Fig. 7.50. Note the pole-zero pattern
near the origin that is characteristic of a lag network. The Bode plot in
Fig. 7.51 shows the phase lag at low frequencies and the phase lead at high
frequencies. The step response of the system is shown in Fig. 7.52 (a) and
shows the presence of a "tail" on the response due to the slow pole at −0.1.
The associated control effort is shown in Fig. 7.52 (b). Of course, the system
is Type 1 and the system will have zero tracking error eventually.
We now reconsider the ﬁrst two methods for choosing M and ¯N, this time
to examine their implications in terms of zeros. Under the ﬁrst rule (for the
autonomous estimator), we let M = B ¯N. Substituting this into Eq. (7.192)
yields, for the controller feed-forward zeros,
det(sI −A + LC) = 0.
(7.196)

522
Chapter 7 State-Space Design
Figure 7.50
Root locus of lag-lead
compensation
-1
-2
-3
-4
Re(s)
Im(s)
-1
-1
0.12
0.08
0.08
0.12
-0.08
-0.16
-0.24
Figure 7.51
Frequency response of
lag-lead compensation
Magnitude
1000
v (rad/sec)
100
10
1
0.1
0.01
100
10
1
0.1
0.01
0.001
0.0001
2 4 6
0.4
40
v (rad/sec)
100
Phase
90
120
150
180
10
1
0.1
0.01
2 4 6
0.4
40
(a)
(b)

7.9 Introduction of the Reference Input with the Estimator
523
Figure 7.52
Response of the system
with lag compensation:
(a) step response;
(b) control effort
0
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1
2
3
4
5
Time (sec)
y
(a)
0
-1
1
0
2
3
4
5
6
7
8
9
1
2
3
4
5
Time (sec)
u
(b)
This is exactly the equation from which L was selected to make the charac-
teristic polynomial of the estimator equation equal to αe(s). Thus we have
created n zeros in exactly the same locations as the n poles of the estimator.
Because of this pole-zero cancellation (which causes "uncontrollability" of
the estimator modes), the overall transfer function poles consist only of the
state feedback controller poles.
The second rule (for a tracking-error estimator) selects M = −L and
¯N = 0. If these are substituted into Eq. (7.191), then the feed-forward zeros
are given by
det
 sI −A + BK + LC
L
−K
0
	
= 0.
(7.197)

524
Chapter 7 State-Space Design
If we postmultiply the last column by C and subtract the result from the ﬁrst
n columns, and then premultiply the last row by B and add it to the ﬁrst n
rows, Eq. (7.197) then reduces to
det
 sI −A
L
−K
0
	
= 0.
(7.198)
If we compare Eq. (7.198) with the equations for the zeros of a system in a
state description, Eq. (7.63), we see that the added zeros are those obtained
by replacing the input matrix with L and the output with K. Thus, if we wish
to use error control, we have to accept the presence of these compensator
zeros that depend on the choice of K and L and over which we have no
direct control. For low-order cases this results, as we said before, in a lead
compensator as part of a unity feedback topology.
Let us now summarize our ﬁndings on the effect of introducing the
Transfer function for the
closed-loop system when
reference input is
included in controller
reference input. When the reference input signal is included in the controller,
the overall transfer function of the closed-loop system is
T (s) = Y(s)
R(s) = Ksγ (s)b(s)
αe(s)αc(s) ,
(7.199)
where Ks is the total system gain and γ (s) and b(s) are monic poly-
nomials. The polynomial αc(s) results in a control gain K such that
det[sI −A + BK] = αc(s). The polynomial αe(s) results in estimator
gains L such that det[sI −A + LC] = αe(s). Because, as designers, we
get to choose αc(s) and αe(s), we have complete freedom in assigning the
poles of the closed-loop system. There are three ways to handle the polyno-
mial γ (s): We can select it so that γ (s) = αe(s) by using the implementation
of Fig. 7.48(b), in which case M/ ¯N is given by Eq. (7.187); we may accept
γ (s) as given by Eq. (7.198), so that error control is used; or we may give
γ (s) arbitrary coefﬁcients by selecting M/ ¯N from Eq. (7.192). It is impor-
tant to point out that the plant zeros represented by b(s) are not moved by
this technique and remain as part of the closed-loop transfer function unless
αc or αe are selected to cancel some of these zeros.
7.9.2
Selecting the Gain
We now turn to the process of determining the gain ¯N for the three methods
of selecting M. If we choose method 1, the control is given by Eq. (7.188a)
and ˆxss = xss. Therefore, we can use either ¯N = Nu +KNx, as in Eq. (7.99),
or u = Nur −K(ˆx −Nxr). This is the most common choice. If we use the
second method, the result is trivial; recall that ¯N = 0 for error control. If we
use the third method, we pick ¯N such that the overall closed-loop DC gain
is unity.11
11A reasonable alternative is to select ¯N such that, when r and y are both unchanging, the DC
gain from r to u is the negative of the DC gain from y to u. The consequences of this choice are
that our controller can be structured as a combination of error control and generalized derivative
control, and if the system is capable of Type 1 behavior, that capability will be realized.

7.10 Integral Control and Robust Tracking
525
The overall system equations then are
 ˙x
˙˜x
	
=
 A −BK
BK
0
A −LC
	  x
˜x
	
+

B
B −¯M
	
¯Nr,
(7.200a)
y = [ C
0 ]
 x
˜x
	
,
(7.200b)
where ¯M is the outcome of selecting zero locations with either Eq. (7.192)
or Eq. (7.187). The closed-loop system has unity DC gain if
−[ C
0 ]
 A −BK
BK
0
A −LC
	−1 
B
B −¯M
	
¯N = 1.
(7.201)
If we solve Eq. (7.201) for ¯N, we get12
¯N = −
1
C(A −BK)−1B[1 −K(A −LC)−1(B −¯M)].
(7.202)
The techniques in this section can be readily extended to reduced-order
estimators.
7.10
Integral Control and Robust Tracking
The choices of ¯N gain in Section 7.9 will result in zero steady-state error
to a step command, but the result is not robust because any change in the
plant parameters will cause the error to be nonzero. We need to use integral
control to obtain robust tracking.
In the state-space design methods discussed so far, no mention has
been made of integral control, and no design examples have produced a
compensation containing an integral term. In Section 7.10.1 we show how
integral control can be introduced by a direct method of adding the integral of
the system error to the dynamic equations. Integral control is a special case
of tracking a signal that does not go to zero in the steady-state. We introduce
(in Section 7.10.2) a general method for robust tracking that will present the
internal model principle, which solves an entire class of tracking problems
and disturbance-rejection controls. Finally, in Section 7.10.4, we show that
if the system has an estimator and also needs to reject a disturbance of
known structure, we can include a model of the disturbance in the estimator
equations and use the computer estimate of the disturbance to cancel the
effects of the real plant disturbance on the output.
12We have used the fact that
 A
C
0
B
	−1
=
 A−1
−A−1CB−1
0
B−1
	
.

526
Chapter 7 State-Space Design
7.10.1
Integral Control
We start with an ad hoc solution to integral control by augmenting the state
vector with the integrator dynamics. For the system
˙x = Ax + Bu + B1w,
(7.203a)
y = Cx,
(7.203b)
we can feed back the integral of the error,13 e = y −r, as well as the state of
the plant, x, by augmenting the plant state with the extra (integral) state xI,
which obeys the differential equation
˙xI = Cx −r(= e).
Thus
xI =
 t
e(τ)dτ.
The augmented state equations become
Augmented
state equations with
integral control
 ˙xI
˙x
	
=
 0
C
0
A
	  xI
x
	
+
 0
B
	
u −
 1
0
	
r +
 0
B1
	
w, (7.204)
and the feedback law is
Feedback law with integral
control
u = −[ K1
K0 ]
 xI
x
	
,
or simply
u = −K
 xI
x
	
.
With this revised deﬁnition of the system, we can apply the design techniques
from Section 7.5 in a similar fashion; they will result in the control structure
shown in Fig. 7.53.
EXAMPLE 7.34
Integral Control of a Motor Speed System
Consider the motor speed system described by
Y(s)
U(s) =
1
s + 3,
Figure 7.53
Integral control
structure
©
+
-
r
-K1
©
+
+
-K0
e
s
1
xI
u
Plant
x
y
13Watch out for the sign here; we are using the negative of the usual convention.

7.10 Integral Control and Robust Tracking
527
that is, A = −3, B = 1, and C = 1. Design the system to have integral
control and two poles at s = −5. Design an estimator with pole at s = −10.
The disturbance enters at the same place as the control. Evaluate the tracking
and disturbance rejection responses.
Solution. The pole-placement requirement is equivalent to
pc = [−5; −5].
The augmented system description, including the disturbance w, is
 ˙xI
˙x
	
=
 0
1
0
−3
	  xI
x
	
+
 0
1
	
(u + w) −
 1
0
	
r.
Therefore, we can ﬁnd K from
det

sI −
 0
1
0
−3
	
+
 0
1
	
K

= s2 + 10s + 25,
or
s2 + (3 + K0)s + K1 = s2 + 10s + 25.
Consequently,
K = [ K1
K0 ] = [ 25
7 ].
We may verify this result using acker. The system is shown with feedbacks
in Fig. 7.54, along with a disturbance input w.
The estimator gain L = 7 is obtained from
αe(s) = s + 10 = s + 3 + L.
The estimator equation is of the form
˙ˆx = (A −LC)ˆx + Bu + Ly
= −10ˆx + u + 7y,
and
u = −K0ˆx = −7ˆx.
The step response y1 due to a step reference input r and the output
disturbance response y2 due to a step disturbance input w are shown in
Fig. 7.55(a) and the associated control efforts (u1 and u2) are shown in
Fig. 7.55(b). As expected, the system is Type 1 and tracks the step reference
input and rejects the step disturbance asymptotically.
Figure 7.54
Integral control
example
©
+
-
-25
©
+
+
-7
e
s
1
xI
Plant
Estimator
y
s + 3
1
©
+
+
w
r
xˆ

528
Chapter 7 State-Space Design
Figure 7.55
Transient response for
motor speed system:
(a) step responses;
(b) control efforts
0
4
3.5
3
2.5
2
1.5
1
0.5
5
4.5
(b)
Time (sec)
0
4
3.5
3
2.5
2
1.5
1
0.5
5
4.5
(a)
Time (sec)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
-0.5
0.5
1
1.5
2
2.5
3
3.5
u(t)
y
y2
y1
u1
u2
7.10.2
Robust Tracking Control: The Error-Space Approach
In Section 7.10.1 we introduced integral control in a direct way and selected
△
the structure of the implementation so as to achieve integral action with
respect to reference and disturbance inputs. We now present a more ana-
lytical approach to giving a control system the ability to track (with zero
steady-state error) a nondecaying input and to reject (with zero steady-state
error) a nondecaying disturbance such as a step, ramp, or sinusoidal input.
The method is based on including the equations satisﬁed by these external
signals as part of the problem formulation and solving the problem of con-
trol in an error space, so we are assured that the error approaches zero
even if the output is following a nondecaying, or even a growing, command
(such as a ramp signal) and even if some parameters change (the robustness

7.10 Integral Control and Robust Tracking
529
property). The method is illustrated in detail for signals that satisfy differ-
ential equations of order 2, but the extension to more complex signals is not
difﬁcult.
Suppose we have the system state equations
˙x = Ax + Bu + B1w,
(7.205a)
y = Cx,
(7.205b)
and a reference signal that is known to satisfy a speciﬁc differential equation.
The initial conditions on the equation generating the input are unknown.
For example, the input could be a ramp whose slope and initial value are
unknown. Plant disturbances of the same class may also be present. We
wish to design a controller for this system so that the closed-loop system
will have speciﬁed poles, and can also track input command signals, and
reject disturbances of the type described without steady-state error. We will
develop the results only for second-order differential equations. We deﬁne
the reference input to satisfy the relation
¨r + α1˙r + α2r = 0,
(7.206)
and the disturbance to satisfy exactly the same equation:
¨w + α1 ˙w + α2w = 0.
(7.207)
The (tracking) error is deﬁned as
e = y −r.
(7.208)
The problem of tracking r and rejecting w can be seen as an exercise in
The meaning of robust
control
designing a control law to provide regulation of the error, which is to say
that the error e tends to zero as time gets large. The control must also be
structurally stable or robust, in the sense that regulation of e to zero in
the steady-state occurs even in the presence of "small" perturbations of the
original system parameters. Note that, in practice, we never have a perfect
model of the plant, and the values of parameters are virtually always subject
to some change, so robustness is always very important.
We know that the command input satisﬁes Eq. (7.206), and we would
like to eliminate the reference from the equations in favor of the error. We
begin by replacing r in Eq. (7.206) with the error of Eq. (7.208). When we do
this, the reference cancels because of Eq. (7.206), and we have the formula
for the error in terms of the state:
¨e + α1˙e + α2e = ¨y + α1˙y + α2y
(7.209a)
= C¨x + α1C˙x + α2Cx.
(7.209b)
We now replace the plant state vector with the error-space state, deﬁned by
ξ = ¨x + α1˙x + α2x.
(7.210)
Similarly, we replace the control with the control in error space, deﬁned as
μ = ¨u + α1˙u + α2u.
(7.211)

530
Chapter 7 State-Space Design
With these deﬁnitions, we can replace Eq. (7.209b) with
¨e + α1˙e + α2e = Cξ.
(7.212)
The state equation for ξ is given by14
Robust control equations
in the error space
˙ξ = ...x + α1¨x + α2˙x = Aξ + Bμ.
(7.213)
Noticethatthedisturbance, aswellasthereference, cancelsfromEq.(7.213).
Equations (7.212) and (7.213) now describe the overall system in an error
space. In standard state-variable form, the equations are
˙z = Asz + Bsμ,
(7.214)
where z = [ e
˙e
ξT ]T and
As =
⎡
⎣
0
1
0
−α2
−α1
C
0
0
A
⎤
⎦,
Bs =
⎡
⎣
0
0
B
⎤
⎦.
(7.215)
The error system (As, Bs) can be given arbitrary dynamics by state feedback
if it is controllable. If the plant (A, B) is controllable and does not have a
zero at any of the roots of the reference-signal characteristic equation
αr(s) = s2 + α1s + α2,
then the error system (As, Bs) is controllable.15 We assume these conditions
hold; therefore, there exists a control law of the form
μ = −[ K2
K1
K0 ]
⎡
⎣
e
˙e
ξ
⎤
⎦= −Kz,
(7.216)
such that the error system has arbitrary dynamics by pole placement. We
now need to express this control law in terms of the actual process state x
and the actual control. We combine Eqs. (7.216), (7.210), and (7.211) to get
the control law in terms of u and x (we write u(2) to mean d2u
dt2 ):
(u + K0x)(2) +
2

i=1
αi(u + K0x)(2−i) = −
2

i=1
Kie(2−i).
(7.217)
The structure for implementing Eq. (7.217) is very simple for tracking con-
stant inputs. In that case the equation for the reference input is ˙r = 0. In
terms of u and x, the control law [Eq. (7.217)] reduces to
˙u + K0˙x = −K1e.
(7.218)
14Notice that this concept can be extended to more complex equations in r and to multivariable
systems.
15 For example, it is not possible to add integral control to a plant that has a zero at the origin.

7.10 Integral Control and Robust Tracking
531
Here we need only to integrate to reveal the control law and the action of
integral control:
u = −K1
 t
e(τ) dτ −K0x.
(7.219)
A block diagram of the system, shown in Fig. 7.56, clearly shows the pres-
ence of a pure integrator in the controller. In this case the only difference
between the internal model method of Fig. 7.56 and the ad hoc method of
Fig. 7.54 is the relative location of the integrator and the gain.
A more complex problem that clearly shows the power of the error-space
approach to robust tracking is posed by requiring that a sinusoid be tracked
with zero steady-state error. The problem arises, for instance, in the control
of a mass-storage disk-head assembly.
EXAMPLE 7.35
Disk-Drive Servomechanism: Robust Control
to Follow a Sinusoid
A simple normalized model of a computer disk-drive servomechanism is
given by the equations
A =
 0
1
0
−1
	
,
B =
 0
1
	
,
B1 =
 0
1
	
,
C =
 1
0 
,
J = 0.
Because the data on the disk are not exactly on a centered circle, the servo
must follow a sinusoid of radian frequency ω0 determined by the spindle
speed.
(a) Give the structure of a controller for this system that will follow the
given reference input with zero steady-state error.
(b) Assume ω0 = 1 and that the desired closed-loop poles are at −1±j
√
3
and −
√
3 ± j1.
(c) Demonstrate the tracking and disturbance rejection properties of the
system using Matlab or Simulink.
Figure 7.56
Integral control using
the internal model
©
+
-
r
©
+
+
-K0
e
s
1
u
Plant
x
y
-K1

532
Chapter 7 State-Space Design
Solution
(a) The reference input satisﬁes the differential equation ¨r = −ω2
0r so
that α1 = 0 and α2 = ω2
0. With these values, the error-state matrices,
according to Eq. (7.215), are
As =
⎡
⎢⎢⎣
0
1
0
0
−ω2
0
0
1
0
0
0
0
1
0
0
0
−1
⎤
⎥⎥⎦,
Bs =
⎡
⎢⎢⎣
0
0
0
1
⎤
⎥⎥⎦.
The characteristic equation of As −BsK is
s4 + (1 + K02)s3 + (ω2
0 + K01)s2 + [K1 + ω2
0(1 + K02)]s + K01ω2
0K2 = 0,
from which the gain may be selected by pole assignment. The com-
pensator implementation from Eq. (7.217) has the structure shown in
Fig. 7.57, which clearly shows the presence of the oscillator with fre-
quency ω0 (known as the internal model of the input generator) in
Internal model principle
the controller.16
(b) Now assume that ω0 = 1 rad/sec and the desired closed-loop poles are
as given:
pc = [−1 + j ∗
√
3; −1 −j ∗
√
3; −
√
3 + j; −
√
3 −j].
Then the feedback gain is
K = [K2 K1 : K0] = [2.0718 16.3923 : 13.9282 4.4641],
which results in the controller
˙xc = Acxc + Bce,
u = Ccxc −K0x,
Figure 7.57
Structure of the
compensator for the
servomechanism to
track exactly the
sinusoid of frequency
ω0
Compensator
y
©
+
-
r
-K2
-K1
©
+
+
©
+
+
s(s + 1)
1
e
s
1
s
1
-v0
2
Internal model
©
+
+
©
+
+
-K01
-K02
u
x2
x1
Plant
16This is a particular case of the internal model principle, which requires that a model of the
external or exogenous signal be in the controller for robust tracking and disturbance rejection,
see Francis and Wonham (1975) for a systematic treatment of this topic.

7.10 Integral Control and Robust Tracking
533
with
Ac =

0
1
−1
0
	
,
Bc =
 −16.3923
−2.0718
	
,
Cc =

1
0 
.
The relevant Matlab statements are
% plant matrices
A=[0 1; 0 −1];
B=[0;1];
C=[1 0];
D=[0];
% form error space matrices
omega=1;
As=[0 1 0 0;−omega*omega 0 1 0;0 0 0 1;0 0 0 −1];
Bs=[0;0;B];
% desired closed-loop poles
j=sqrt(-1);
pc=[−1+sqrt(3)*j ;−1−sqrt(3)*j;−sqrt(3)+j;−sqrt(3)−j];
K=place(As,Bs,pc);
% form controller matrices
K1=K(:,1:2);
Ko=K(:,3:4);
Ac=[0 1;−omega*omega 0];
Bc=−[K(2);K(1)];
Cc=[1 0];
Dc=[0];
The controller frequency response is shown in Fig. 7.58 and shows
a gain of inﬁnity at the rotation frequency of ω0 = 1 rad/sec. The
frequency response from r to e [that is, the sensitivity function S(s)],
is shown in Fig. 7.59 and reveals a sharp notch at the rotation fre-
quency ω0 = 1 rad/sec. The same notch is also present in the frequency
response of the transfer function from w to y.
(c) Figure 7.60 shows the Simulink simulation diagram for the system.
Although the simulations can also be done in Matlab, it is more instruc-
tive to use the interactive graphical environment of Simulink. Simulink
also provides the capability to add nonlinearities (see Chapter 9) and
carry out robustness studies efﬁciently.17 The tracking properties of
the system are shown in Fig. 7.61(a), showing the asymptotic tracking
property of the system. The associated control effort and the tracking
error signal are shown in Fig. 7.61(b) and (c), respectively. The distur-
bance rejection properties of the system are illustrated in Fig. 7.62(a),
displaying asymptotic disturbance rejection of sinusoidal disturbance
17In general, the design can be done in Matlab and (nonlinear) simulations can be carried out
in Simulink.

534
Chapter 7 State-Space Design
Figure 7.58
Controller frequency
response for robust
servomechanism
Phase (deg)
Magnitude (db)
10-2
10-1
100
101
v (rad/sec)
10-2
10-1
100
101
v (rad/sec)
-200
-150
-100
-50
0
50
100
0
50
100
150
200
250
Figure 7.59
Sensitivity function
frequency response for
robust servomechanism
Phase (deg)
Magnitude (db)
10-1
100
101
102
v (rad/sec)
10-1
100
101
102
v (rad/sec)
100
150
200
250
300
-200
-150
-100
-50
0
50
input. The associated control effort is shown in Fig. 7.62(b). The closed-
loop frequency response [that is, the complementary transfer function
T (s)]fortherobustservomechanismisshowninFig.7.63.Asseenfrom
the ﬁgure, the frequency response from r to y is unity at ω0 = 1 rad/sec
as expected.
Simulink simulation
The zeros of the system from r to e are located at ± j, −2.7321
± j2.5425. The robust tracking properties are due to the presence of
the blocking zeros at ±j. The zeros from w to y, both blocking zeros,
are located at ±j. The robust disturbance rejection properties are due
to the presence of these blocking zeros.
Blocking zeros

7.10 Integral Control and Robust Tracking
535
Scope2
r
+
-
+
+
++
+
+
Scope1
-16.392
-2.0718
-4.4641
-13.928
To
workspace
e
r
e
u
x2
x1
To
workspace2
Gain
Gain1
Gain3
Gain2
Gain5
s
1
s
1
s
1
s
1
+
+
+
+
-1
-1
Integrator2
To
workspace1
Out 1
Integrator1
Integrator
Integrator3
Scope
1
y
Gain4
Figure 7.60
Simulink block diagram for robust servomechanism
From the nature of the pole-placement problem, the state z in Eq. (7.214)
will tend toward zero for all perturbations in the system parameters as long
as As −BsK remains stable. Notice that the signals that are rejected are
those that satisfy the equations with the values of αi actually implemented in
the model of the external signals. The method assumes that these are known
and implemented exactly. If the implemented values are in error, then a
steady-state error will result.
Now let us repeat the example of Section 7.10.1 for integral control.
EXAMPLE 7.36
Integral Control Using the Error-Space Design
For the system
H(s) =
1
s + 3,
with the state-variable description
A = −3,
B = 1,
C = 1,
construct a controller with poles at s = −5 to track an input that satisﬁes
˙r = 0.
Solution. The error-space system is
 ˙e
˙ξ
	
=
 0
1
0
−3
	  e
ξ
	
+
 0
1
	
μ,

536
Chapter 7 State-Space Design
Figure 7.61
(a) Tracking properties
for robust
servomechanism;
(b) control effort;
(c) tracking error signal
Reference, output
0
25
20
15
10
5
(a)   Time (sec)
-1.5
-1
-0.5
0
0.5
1
1.5
r
y
0
5
10
15
20
25
-2
-1.5
-1
-0.5
0
0.5
1
1.5
(b)   Time (sec)
Control, u
0
5
10
15
20
25
-0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
(c)   Time (sec)
Error signal, e 
with e = y −r, ξ = ˙x, and μ = ˙u. If we take the desired characteristic
equation to be
αc(s) = s2 + 10s + 25,
then the pole-placement equation for K is
det[sI −As + BsK] = αc(s).
(7.220)

7.10 Integral Control and Robust Tracking
537
Figure 7.62
(a) Disturbance
rejection properties for
robust
servomechanism;
(b) control effort
Disturbance, output
0
25
20
15
10
5
(a)   Time (sec)
-1
-0.6
-0.4
0
0.4
0.8
-0.8
-0.1
0.2
0.6
1
w
y
0
5
10
15
20
25
-1.5
-1
-0.5
0
0.5
1
(b)   Time (sec)
Control, u 
Figure 7.63
Closed-loop frequency
response for robust
servomechanism
Phase (deg)
Magnitude (db)
10-2
10-1
100
101
v (rad/sec)
10-2
10-1
100
101
v (rad/sec)
-270
-225
-135
-180
-90
-45
0
45
90
-40
-30
-20
-10
0
10

538
Chapter 7 State-Space Design
In detail, Eq. (7.220) is
s2 + (3 + K0)s + K1 = s2 + 10s + 25,
which gives
K = [ 25
7 ] = [ K1
K0 ],
and the system is implemented as shown in Fig. 7.64. The transfer function
from r to e for this system, the sensitivity function
E(s)
R(s) = S(s) = −
s(s + 10)
s2 + 10s + 25,
showsablockingzeroats = 0, whichpreventstheconstantinputfromaffect-
ing the error. The closed-loop transfer function—that is, the complementary
sensitivity function—is
Y(s)
R(s) = T (s) = 1 −S(s) =
25
s2 + 10s + 25.
The structure of Fig. 7.65 permits us to add a feed-forward of the refer-
ence input, which provides one extra degree of freedom in zero assignment.
If we add a term proportional to r in Eq. (7.219), then
u = −K1
 t
e(τ) dτ −K0x + Nr.
(7.221)
This relationship has the effect of creating a zero at −K1/N. The location of
this zero can be chosen to improve the transient response of the system. For
actual implementation, we can rewrite Eq. (7.221) in terms of e to get
u = −K1
 t
e(τ) dτ −K0x + N(y −e).
(7.222)
Figure 7.64
Example of internal
model with
feed-forward
Y
©
+
-
R
-25
s
1
-N
©
+
+
©
+
+
-7
+
N
s + 3
1
Figure 7.65
Internal model as
integral control with
feed-forward
Y
©
+
-
R
Plant
e
x
-K1
s
1
-N
©
+
+
©
+
+
©
+
+
N
-K0
u

7.10 Integral Control and Robust Tracking
539
Figure 7.66
Step responses with
integral control and
feed-forward
Time (sec)
N = 8
0
0.5
1.0
1.5
2.0
2.5
3.0
1.2
1.0
0.8
0.6
0.4
0.2
0
Amplitude
5
0
The block diagram for the system is shown in Fig. 7.65. For our example,
the overall transfer function now becomes
Y(s)
R(s) =
Ns + 25
s2 + 10s + 25.
Notice that the DC gain is unity for any value of N and that, through our
choice of N, we can place the zero at any real value to improve the dynamic
response. A natural strategy for locating the zero is to have it cancel one of
the system poles, in this case at s = −5. The step response of the system
is shown in Fig. 7.66 for N = 5, as well as for N = 0 and 8. With the
understanding that one pole can be cancelled in integral control designs, we
make sure to choose one of the desired control poles such that it is both real
and able to be cancelled through the proper choice of N.
7.10.3
Model-Following Design
A related method to track a persistent reference input is called model-
△
following design (see Fig. 7.67). This is an open-loop method that uses the
feedforward of the state of the model to construct a speciﬁc control input.
This control will force the plant output to asymptotically track the output of
the desired model which may or may not be persistent. As an example, the
desired model can be the speciﬁed path that an aircraft is required to track
accurately. LTI models with nonzero initial conditions can be used to gener-
ate such paths. Alternatively, an impulsive input can be used to establish the
initial condition on the desired model (as done here). The technique can pro-
duce superior tracking properties to follow such desired paths. The method
is described more fully in Bryson (1994), including the case of disturbance
rejection, and used to synthesize the landing ﬂare logic for the Boeing 747
aircraft. Assume we have a plant described by the triple (A, B, C), having
state x and output y. Furthermore, assume a given model that produces the
desired response of the plant which is described by the triple (Am, Bm, Cm),

540
Chapter 7 State-Space Design
Figure 7.67
Block diagram for the
model-following design
Model
Plant
u
A B
C 0
y
e
ym
x
z
z
[Am Bm]
Cm
N
M
K
©
©
©
-
-
-
+
+
+
dx
d
du
with state z and output ym. The idea is to use the states x and z to construct
a control signal so that the error y −ym "quickly" approaches zero. In other
words, we want the plant to follow the model with an error that goes to
zero. As you will see in the ensuing development, we will tailor the control
input such that the output of the plant is forced to follow the desired refer-
ence input. The control law uses the feedforward of the model state, z, and
the feedback of the plant state x. The constant feedforward gain matrices
M and N are obtained from the solution of a set of linear equations. The
feedback gain, K, is designed as usual to stabilize or speed up the plant
dynamics. We now derive the model-following design from ﬁrst principles,
and illustrate the results with an example.
Consider the plant described by
˙x = Ax + Bu,
(7.223)
y = Cx,
(7.224)
and the desired model given by
˙z = Amz + Bmδ(t),
(7.225)
ym = Cmz,
(7.226)
where Am is nm × nm. In our case, the model is driven by the impulse, δ(t),
or essentially initial conditions only. Assume that the dimensions of u, y,
and ym are the same. Let
x = Mz + δx,
(7.227)
u = Nz + δu,
(7.228)
y = ym + δy,
(7.229)
where M and N are constant matrices. We wish that δy →0 rapidly so
that y →ym. If we substitute Eqs. (7.227) and (7.228) in Eqs. (7.223) and
(7.224), we obtain
M˙z + δ˙x = A(Mz+δx) + B(Nz + δu),
(7.230)
y = ym + δy = C(Mz + δx),
(7.231)

7.10 Integral Control and Robust Tracking
541
which we can rewrite as
δ˙x= Aδx + Bδu + (AM −MAm+BN)z −MBmδ(t),
(7.232)
δy = Cδx + (CM −Cm)z.
(7.233)
If we select the matrices M and N so that the matrices multiplying the model
state z in Eqs. (7.232) and (7.233) vanish, we have the two ensuing matrix
equations18
AM −MAm + BN = 0,
(7.234)
CM = Cm.
(7.235)
Eq. (7.234) is called a Sylvester equation. In Eqs. (7.234) and (7.235), there
are nm(n + 1) linear equations in the nm(n + 1) unknown elements of the
matrices M and N. A necessary and sufﬁcient condition for the existence of
the solution to Eqs. (7.234) and (7.235) is that the transmission zeros of the
plant do not coincide with the eigenvalues of the model Am. Let the control
law be
u = Nz −K(x −Mz),
(7.236)
where K is designed in the usual way so that A −BK has a satisfactory
stable control. We observe that
δu = u −Nz = Nz −K(x −Mz) −Nz = −Kδx.
(7.237)
With the given control law, Eq. (7.236), the plant equations become
˙x = Ax + B(Nz −K(x −Mz)),
(7.238)
= (A −BK)x + B(N + KM)z.
In the frequency domain, noting that Z(s) = (sI −Am)−1Bm, this can be
written as
X(s) = (sI −A + BK)−1B(N + KM)(sI −Am)−1Bm.
(7.239)
Now substituting for BN from Eq. (7.234) and adding and subtracting sM
this can be written as
X(s) = (sI −A + BK)−1[MAm −AM + BKM](sI −Am)−1Bm,
(7.240)
X(s) = (sI −A + BK)−1[(sI −A + BK)M −M(sI −Am)](sI −Am)−1Bm.
(7.241)
If we now multiply this out, the result is
X(s) = M(sI −Am)−1Bm −(sI −A + BK)−1MBm.
(7.242)
The output, Y(s) = CX(s) is thus
Y(s) = CM(sI −Am)−1Bm −C(sI −A + BK)−1MBm.
(7.243)
18Bryson (1994) presents an algorithm to solve Eqs. (7.234) and (7.235), using the Matlab
Kronecker product (kron) command.

542
Chapter 7 State-Space Design
Finally, as CM = Cm, we have
Y(s) = Cm(sI −Am)−1Bm −C(sI −A + BK)−1MBm,
(7.244)
and therefore, in the time domain,
y(t) = ym(t) −[decaying transient term controlled by K],
(7.245)
which is what we set out to show.
EXAMPLE 7.37
Model-following for Disk Drive
Assume the model to be followed is given by an oscillator, that is,
Am =

0
1
−1
0
	
, Bm =
 0
1
	
,
Cm =

1
0 
.
The plant is the same as given in Example 7.36 and we wish to track the same
sine wave signal. Assume that the desired closed-loop poles are given by
pc = [−1 + j ∗
√
3; −1 −j ∗
√
3].
Solution. The feedback gain is
K =
 4
1 
.
We solve Eqs. (7.234) and (7.235) for this case to obtain
M =

1
0
0
1
	
,
N =
 −1
1 
.
The internal model design is the same as in Example 7.36. A comparison
of the tracking error for the internal model and model-following designs are
shown in Figs. 7.68 and 7.69. Both techniques track the sinusoid exactly
in an asymptotic fashion and the model-following technique has a snappier
response and the smaller maximum error as seen from Fig. 7.69.
Now let us investigate the robustness of the two techniques with respect
to plant perturbations. For comparison of robustness properties, both the
model-following system and the internal model closed-loop systems were
run but with the plant system matrix perturbed to be
˜A =
 0
1
0
−1.1
	
.
The tracking errors for the two cases are plotted in Fig. 7.70. Notice that
in Fig. 7.70 the model-following design has the smaller maximum error
but, being non-robust, has a persistent error while the internal model design
continues to track the sine wave exactly.

7.10 Integral Control and Robust Tracking
543
Figure 7.68
Comparison of the
tracking properties for
the two designs: desired
model (r), model-
following design (yMF ),
and internal model
design (yIM, Exam-
ple 7.36) with the
nominal plant model
-1.50
5
10
15
Time (sec)
yIM
Nominal plant
20
25
-1
-0.5
0
Reference, output
0.5
1
1.5
yMF
r
Figure 7.69
Comparison of the
tracking error
signals for the two
designs with the
nominal plant model
Nominal plant
IM
MF
0.7
0.6
0.5
0.4
0.3
0.2
Error signal, e
0.1
0
0
5
10
Time (sec)
15
20
25
-0.1
7.10.4
The Extended Estimator
Our discussion of robust control so far has used a control based on full-
△
state feedback. If the state is not available, then as in the regular case, the
full-state feedback, Kx, can be replaced by the estimates, Kˆx, where the
estimator is built as before. As a ﬁnal look at ways to design control with
external inputs, in this section we develop a method for tracking a reference
input and rejecting disturbances. The method is based on augmenting the

544
Chapter 7 State-Space Design
Figure 7.70
Comparison of the
tracking errors of the
two designs with the
perturbed plant model
Perturbed plant
IM
MF
0.7
0.6
0.5
0.4
0.3
0.2
Error signal, e, for perturbed plant
0.1
0
0
5
10
Time (sec)
15
20
25
-0.1
estimator to include estimates from external signals in a way that permits us
to cancel out their effects on the system error.
Suppose the plant is described by the equations
˙x = Ax + Bu + Bw,
(7.246a)
y = Cx,
(7.246b)
e = Cx −r.
(7.246c)
Furthermore, assume that both the reference r and the disturbance w are
known to satisfy the equations19
αw(s)w = αρ(s)w = 0,
(7.247)
αr(s)r = αρ(s)r = 0,
(7.248)
where
αρ(s) = s2 + α1s + α2,
corresponding to polynomials αw(s) and αr(s) in Fig. 7.71(a). In general,
we would select the equivalent disturbance polynomial αρ(s) in Fig. 7.71(b)
to be the least common multiple of αw(s) and αr(s). The ﬁrst step is to
recognize that, as far as the steady-state response of the output is concerned,
there is an input-equivalent signal ρ that satisﬁes the same equation as r and
w and enters the system at the same place as the control signal, as shown in
19Again we develop the results for a second-order equation in the external signals; the discussion
can be extended to higher-order equations.

7.10 Integral Control and Robust Tracking
545
aw(s)
1
+
+
G(s)
+
-
u
e
u
e
W
r
+
+
G(s)
+
-
W
r
ar(s)
1
ar(s)
1
+
+
+
-
G(s)
Extended estimator
-K
ˆr
r
xˆ
u
e
+
-
Extended estimator
-K
ˆr
xˆ
(a)
(b)
(c)
©
©
©
©
©
©
©
Figure 7.71
Block diagram of a system for tracking and disturbance rejection with extended estimator: (a) equivalent
disturbance; (b) block diagram for design; (c) block diagram for implementation
Fig. 7.71(b). As before, we must assume that the plant does not have a zero
at any of the roots of Eq. (7.247). For our purposes here, we can replace
Eqs. (7.223) with
˙x = Ax + B(u + ρ),
(7.249a)
e = Cx.
(7.249b)
If we can estimate this equivalent input, we can add to the control a term −ˆρ
that will cancel out the effects of the real disturbance and reference and cause
the output to track r in the steady-state. To do this, we combine Eqs. (7.223)
and (7.247) into a state description to get
˙z = Asz + Bsu,
(7.250a)
e = Csz,
(7.250b)
where z = [ρ
˙ρ
xT]T. The matrices are
As =
⎡
⎣
0
1
0
−α2
−α1
0
B
0
A
⎤
⎦,
Bs =
⎡
⎣
0
0
B
⎤
⎦,
(7.251a)
Cs = [0
0
C].
(7.251b)
The system given by Eqs. (7.251) is not controllable since we cannot inﬂu-
ence ρ from u. However, if A and C are observable and if the system (A, B, C)
does not have a zero that is also a root of Eq. (7.247), then the system of
Eq. (7.251) will be observable, and we can construct an observer that will
compute estimates of both the state of the plant and of ρ. The estimator
equations are standard, but the control is not:
˙ˆz = Asˆz + Bsu + L(e −Csˆz),
(7.252a)
u = −Kˆx −ˆρ.
(7.252b)

546
Chapter 7 State-Space Design
In terms of the original variables, the estimator equations are
˙ˆz =
⎡
⎣
˙ˆρ
¨ˆρ
˙ˆx
⎤
⎦=
⎡
⎣
0
1
0
−α2
−α1
0
B
0
A
⎤
⎦
⎡
⎣
ˆρ
˙ˆρ
ˆx
⎤
⎦+
⎡
⎣
0
0
B
⎤
⎦u+
⎡
⎣
l1
l2
L3
⎤
⎦[e−Cˆx].
(7.253)
The overall block diagram of the system fordesign is shown in Fig. 7.71(b). If
we write out the last equation for ˆx in Eq. (7.253) and substitute Eq. (7.252b),
a simpliﬁcation of sorts results because a term in ˆρ cancels out:
˙ˆx = B ˆρ + Aˆx + B(−Kˆx −ˆρ) + L3(e −Cˆx)
= Aˆx + B(−Kˆx) + L3(e −Cˆx)
= Aˆx + B¯u + L3(e −Cˆx).
With the estimator of Eq. (7.253) and the control of Eq. (7.252b), the state
equation is
˙x = Ax + B(−Kˆx −ˆρ) + Bρ.
(7.254)
In terms of the estimation errors, Eq. (7.254) can be rewritten as
˙x = (A −BK)x + BK˜x + B ˜ρ.
(7.255)
Because we designed the estimator to be stable, the values of ˜ρ and ˜x go
to zero in the steady state, and the ﬁnal value of the state is not affected by
the external input. The block diagram of the system for implementation is
drawn in Fig. 7.71(c). A very simple example will illustrate the steps in this
process.
EXAMPLE 7.38
Steady-State Tracking and Disturbance Rejection of Motor
Speed by Extended Estimator
Construct an estimator to control the state and cancel a constant bias at the
output and track a constant reference in the motor speed system described by
˙x = −3x + u,
(7.256a)
y = x + w,
(7.256b)
˙w = 0,
(7.256c)
˙r = 0.
(7.256d)
Place the control pole at s = −5 and the two extended estimator poles at
s = −15.
Solution. To begin, we design the control law by ignoring the equivalent
disturbance. Rather, we notice by inspection that a gain of −2 will move
the single pole from −3 to the desired −5, Therefore, K = 2. The sys-
tem augmented with equivalent external input ρ, which replaces the actual
disturbance w and the reference r, is given by
˙ρ = 0,
˙x = −3x + u + ρ,
e = x.

7.11 Loop Transfer Recovery
547
+
+
+
-
W
r
u
e
+
-
Extended estimator
-2
(a)
(b)
s + 3
1
0
2
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
Time (sec)
-7
-6
-5
-4
-3
-2
-1
0
1
2
ˆr
xˆ
y, x, r
ˆ ˆ
y
ˆr
xˆ
©
©
©
Figure 7.72
Motor speed system with extended estimator: (a) block diagram; (b) command step response and
disturbance step response
The extended estimator equations are
˙ˆρ = l1(e −ˆx),
˙ˆx = −3ˆx + u + ˆρ + l2(e −ˆx).
The estimator error gain is found to be L = [ 225
27 ]T from the
characteristic equation
det
 s
l1
1
s + 3 + l2
	
= s2 + 30s + 225.
A block diagram of the system is given in Fig. 7.72(a), and the step responses
to input at the command r (applied at t = 0 sec) and at the disturbance w
(applied at t = 0.5 sec) are shown in Fig. 7.72(b).
7.11
Loop Transfer Recovery
The introduction of an estimator in a state feedback controller loop may
△
adversely affect the stability robustness properties of the system [that is, the
phase margin (PM) and gain margin (GM) properties may become arbitrarily
poor, as shown by Doyle's famous example (Doyle, 1978)]. However, it is
possible to modify the estimator design so as to try to "recover" the LQR
stability robustness properties to some extent. This process, called LTR, is
LTR
especially effective for minimum-phase systems. To achieve the recovery,
some of the estimator Loop Transfer Recovery poles are placed at (or near)
the zeros of the plant and the remaining poles are moved (sufﬁciently far)
into the LHP. The idea behind LTR is to redesign the estimator in such a way
as to shape the loop gain properties to approximate those of LQR.

548
Chapter 7 State-Space Design
The use of LTR means that feedback controllers can be designed to
achieve desired sensitivity [S(s)] and complementary sensitivity functions
[T (s)] at critical (loop-breaking) points in the feedback system (for example,
at either the input or output of the plant). Of course, there is a price to be
paidforthisimprovementinstabilityrobustness! Thenewlydesignedcontrol
system may have worse sensor noise sensitivity properties. Intuitively, one
can think of making (some of) the estimator poles arbitrarily fast so that
the loop gain is approximately that of LQR. Alternatively, one can think of
essentially "inverting" the plant transfer function so that all the LHP poles of
the plant are cancelled by the dynamic compensator to achieve the desired
loop shape. There are obvious trade-offs, and the designer needs to be careful
to make the correct choice for the given problem, depending on the control
system speciﬁcations.
LTR is a well-known technique now, and speciﬁc practical design pro-
cedures have been identiﬁed (Athans, 1986; Stein and Athans, 1987; Saberi
et al., 1993). The same procedures may also be applied to nonminimum
phase systems, but there is no guarantee on the extent of possible recovery.
The LTR technique may be viewed as a systematic procedure to study design
trade-offs for linear quadratic-based compensator design (Doyle and Stein,
1981). We will now formulate the LTR problem.
Consider the linear system
˙x = Ax + Bu + w,
(7.257a)
y = Cx + v,
(7.257b)
wherew and v areuncorrelatedzero-meanwhiteGaussianprocessandsensor
noise with covariance matrices Rw ≥0 and Rv ≥0. The estimator design
yields
˙ˆx = Aˆx + Bu + L(y −ˆy),
(7.258a)
ˆy = Cˆx,
(7.258b)
resulting in the usual dynamic compensator
Dc(s) = −K(sI −A + BK + LC)−1L.
(7.259)
We will now treat the noise parameters, Rw and Rv, as design "knobs" in
the dynamic compensator design. Without loss of generality, let us choose
Rw = T and Rv = 1. For LTR, assume that  = qB, where q is a scalar
design parameter. The estimator design is then based on the speciﬁc design
parameters Rw and Rv. It can be shown that, for a minimum-phase system,
as q becomes large (Doyle and Stein, 1979),
lim
q→∞Dc(s)G(s) = K(sI −A)−1B,
(7.260)
the convergence is pointwise in s and the degree of recovery can be arbitrarily
good. This design procedure in effect "inverts" the plant transfer function in
Plant inversion
the limit as q →∞:
lim
q→∞Dc(s) = K(sI −A)−1BG−1(s).
(7.261)

7.11 Loop Transfer Recovery
549
This is precisely the reason that full-loop transfer recovery is not possible
for a nonminimum-phase system. This limiting behavior may be explained
using the symmetric root loci. As q →∞, some of the estimator poles
approach the zeros of
Ge(s) = C(sI −A)−1,
(7.262)
and the rest tend to inﬁnity20 [see Eqs. (7.163) and (7.164)]. In practice, the
LTR design procedure can still be applied to a nonminimum-phase plant. The
LTR for
nonminimum-phase
systems
degree of recovery will depend on the speciﬁc locations of the nonminimum-
phase zeros. Sufﬁcient recovery should be possible at many frequencies
if the RHP zeros are located outside the speciﬁed closed-loop bandwidth.
Limits on achievable performance of feedback systems due to RHP zeros
are discussed in Freudenberg and Looze (1985). We will next illustrate the
LTR procedure by a simple example.
EXAMPLE 7.39
LTR Design for Satellite Attitude Control
Consider the satellite system with state-space description
A =
 0
1
0
0
	
,
B =
 0
1
	
,
C =
 1
0 
,
D = 0.
(a) Design an LQR controller with Q = ρCTC and R = 1, ρ = 1, and
determine the loop gain.
(b) Then design a compensator that recovers the LQR loop gain of part (a)
using the LTR technique for q = 1, 10, 100.
(c) Compare the different candidate designs in part (b) with respect to the
actuator activity due to additive white Gaussian sensor noise.
Solution. Using lqr, the selected LQR weights result in the feedback gain
K = [1
1.414]. The loop transfer function is
K(sI −A)−1B = 1.414(s + 0.707)
s2
.
A magnitude frequency response plot of this LQR loop gain is shown in
Fig. 7.73. For the estimator design using lqe, let  = qB, Rw = T,
Rv = 1, and choose q = 10, resulting in the estimator gain
L =
 14.142
100
	
.
The compensator transfer function is
Dc(s) = K(sI −A + BK + LC)−1L
= 155.56(s + 0.6428)
(s2 + 15.556s + 121) =
155.56(s + 0.6428)
(s + 7.77 + j7.77)(s + 7.77 −j7.77),
20In a Butterworth conﬁguration.

550
Chapter 7 State-Space Design
Figure 7.73
Frequency response
plots for LTR design
Magnitude
Phase (deg)
-270
-240
-210
-180
-150
-120
-90
10-1
v (rad/sec)
100
101
102
103
10-1
100
101
102
103
v (rad/sec)
10-5
100
GM1
PM1
PM
GM2
GM
LQR
LQR
q = 100
q = 10
q = 1
q = 1
q = 10
q = 100
and the loop transfer function is
Dc(s)G(s) =
155.56(s + 0.6428)
s2(s + 7.77 + j7.77)(s + 7.77 −j7.77).
Figure 7.73 shows the frequency response of the loop transfer function for
several values of q (q = 1, 10,100), along with the ideal LQR loop transfer
function frequency response. As seen from this ﬁgure, the loop gain tends
to approach that of LQR as the value of q increases. As seen in Fig. 7.73,
for q = 10, the "recovered" gain margin is GM = 11.1 = 20.9 db and the
PM= 55.06◦. Sample Matlab statements to carry out the preceding LTR
design procedure are as follows:
A=[0 1; 0 0];
B=[0;1];
C=[1 0];
D=[0];
sys0=ss(A,B,C,D);
C1=[1 0];
sys=ss(A,B,C1,D);
w=logspace(−1,3,1000);
rho=1.0;
Q=rho*C1'*C1;
r=1;
[K]=lqr(A,B,Q,r)
sys1=ss(A,B,K,0);
[maggk1,phasgk1]=bode(sys1,w);

7.11 Loop Transfer Recovery
551
q=10;
gam=q*B;
Q1=gam'*gam;
rv=1;
[L]=lqe(A,gam,C,Q1,rv)
Matlab lqr
aa=A−B*K−L*C;
bb=L;
cc=K;
dd=0;
sysk=ss(aa,bb,cc,dd);
sysgk=series(sys0,sysk);
Matlab lqe
[maggk,phasgk,w]=bode(sysgk,w);
Matlab bode
[gm,phm,wcg,wcp]=margin(maggk,phsgk,w)
Matlab margin
loglog(w,[maggk1(:) maggk(:)]);
semilogx(w,[phasgk1(:) phsgk(:)]);
To determine the effect of sensor noise, ν, on the actuator activity, we
determine the transfer function from ν to u as shown in Fig. 7.74. For the
selected value of LTR design parameter, q = 10, we have
U(s)
V(s) = H(s) =
−Dc(s)
1 + Dc(s)G(s)
=
−155.56s2(s + 0.6428)
s4 + 15.556s3 + 121s2 + 155.56s + 99.994.
One reasonable measure of the effect of the sensor noise on the actuator
activity is the root-mean-square (RMS) value of the control, u, due to the
RMS value
additive noise, ν. The RMS value of the control may be computed as
∥u∥rms =

 1
T0
 T0
0
u(t)2dt
1/2
,
(7.263)
where T0 is the signal duration. Assuming white Gaussian noise ν, the RMS
value of the control can also be determined analytically (Boyd and Barratt,
1991). The closed-loop Simulink diagram with band-limited white sensor
noise excitation is shown in Fig. 7.75. The values of the RMS control were
computed for different values of the LTR design parameter q, using the
Simulink simulations, and are tabulated in Table 7.2. The results suggest
Simulink simulation
Figure 7.74
Closed-loop system for
LTR design
R
-
+
Y
V
+
+
Dc(s)
G(s)
©
©

552
Chapter 7 State-Space Design
Figure 7.75
Simulink block diagram
for LTR design
y = Cx + Du
x¿ = Ax + Bu
State-space controller
Scope1
-
+
++
Integrator1 s
1
Integrator s
1
Band-limited
white noise
To workspace3
y
Scope2
To workspace4
u
TABLE 7.2
Computed RMS Control for Various
Values of LTR Tuning Parameter q
q
∥u∥rms
1
0.1454
10
2.8054
100
70.5216
increased vulnerability due to actuator wear as q is increased. Refer to Matlab
commands ltry and ltru for the LTR computations.
7.12
Direct Design with Rational Transfer
Functions
An alternative to the state-space methods discussed so far is to postulate
△
a general-structure dynamic controller with two inputs (r and y) and one
output (u) and to solve for the transfer function of the controller to give a
speciﬁed overall r-to-y transfer function. A block diagram of the situation is
shown in Fig. 7.76. We model the plant as the transfer function
Y(s)
U(s) = b(s)
a(s),
(7.264)
rather than by state equations. The controller is also modeled by its transfer
General controller in
polynomial form
function, in this case a transfer function with two inputs and one output:
U(s) = −cy(s)
d(s) Y(s) + cr(s)
d(s) R(s).
(7.265)
Here d(s), cy(s), and cr(s) are polynomials. In order for the controller of
Fig. 7.76 and Eq. (7.265) to be implemented, the orders of the numera-
tor polynomials cy(s) and cr(s) must not be higher than the order of the
denominator polynomial d(s).

7.12 Direct Design with Rational Transfer Functions
553
Figure 7.76
Direct transfer-function
formulation
R(s)
-
+
cr(s)
d(s)
1
cy(s)
Dynamic controller  
Y(s)
a(s)
b(s)
©
To carry out the design, we require that the closed-loop transfer func-
tion deﬁned by Eqs. (7.264) and (7.265) be matched to the desired transfer
function
Y(s)
R(s) = cr(s)b(s)
αc(s)αe(s).
(7.266)
Equation (7.266) tells us that the zeros of the plant must be zeros of the
overall system. The only way to change this is to have factors of b(s) appear
in either αc or αe. We combine Eqs. (7.264) and (7.265) to get
a(s)Y(s) = b(s)

−cy(s)
d(s) Y(s) + cr(s)
d(s) R(s)
	
,
(7.267)
which can be rewritten as
[a(s)d(s) + b(s)cy(s)]Y(s) = b(s)cr(s)R(s).
(7.268)
Comparing Eq. (7.266) with Eq. (7.267) we immediately see that the
design can be accomplished if we can solve the Diophantine equation
Diophantine equation
a(s)d(s) + b(s)cy(s) = αc(s)αe(s),
(7.269)
for given arbitrary a, b, αc, and αe. Because each transfer function is a ratio
of polynomials, we can assume that a(s) and d(s) are monic polynomials;
that is, the coefﬁcient of the highest power of s in each polynomial is unity.
The question is, how many equations and how many unknowns are there
if we match coefﬁcients of equal powers of s in Eq. (7.269)? If a(s) is of
degree n (given) and d(s) is of degree m (to be selected), then a direct count
yields 2m + 1 unknowns in d(s) and cy(s) and n + m equations from the
Dimension of the
controller
coefﬁcients of powers of s. Thus the requirement is that
2m + 1 ≥n + m,
or
m ≥n −1.
One possibility for a solution is to choose d(s) of degree n and cy(s) of
degree n −1. In that case, which corresponds to the state-space design for a
full-order estimator, there are 2n equations and 2n unknowns with αcαe of
degree 2n. The resulting equations will then have a solution for arbitrary αi
if and only if a(s) and b(s) have no common factors.21
21If they do have a common factor, it will show up on the left side of Eq. (7.269); for there
to be a solution, the same factor must be on the right side of Eq. (7.269), and thus a factor of
either αc or αe.

554
Chapter 7 State-Space Design
EXAMPLE 7.40
Pole Placement for Polynomial Transfer Functions
Using the polynomial method, design a controller of order n for the third-
order plant in Example 7.29. Note that if the polynomials αc(s) and αe(s)
from Example 7.29 are multiplied, the result is the desired closed-loop
characteristic equation:
αc(s)αe(s) = s6+14s5+122.75s4+585.2s3+1505.64s2+2476.8s+1728.
(7.270)
Solution. Using Eq. (7.269) with b(s) = 10, we ﬁnd that
(d0s3+d1s2+d2s+d3)(s3+10s2+16s)+10(c0s2+c1s+c2) ≡αc(s)αe(s).
(7.271)
We have expanded the polynomial d(s) with coefﬁcients di and the
polynomial cy(s) with coefﬁcients ci.
Now we equate the coefﬁcients of the like powers of s in Eq. (7.271) to
ﬁnd that the parameters must satisfy22
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
0
0
0
0
0
0
10
1
0
0
0
0
0
16
10
1
0
0
0
0
0
16
10
1
0
0
0
0
0
16
10
10
0
0
0
0
0
16
0
10
0
0
0
0
0
0
0
10
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
d0
d1
d2
d3
c0
c1
c2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
14
122.75
585.2
1505.64
2476.8
1728
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
(7.272)
The solution to Eq. (7.272) is
d0 = 1,
c0 = 190.1,
d1 = 4,
c1 = 481.8,
d2 = 66.75,
c2 = 172.8.
d3 = −146.3,
[The solution can be found using x = a\b command in Matlab, where a is
Matlab a\b
the Sylvester matrix and b is the right-hand side in Eq. (7.272).] Hence the
controller transfer function is
cy(s)
d(s) = 190.1s2 + 481.8s + 172.8
s3 + 4s2 + 66.75s −146.3.
(7.273)
Note that the coefﬁcients of Eq. (7.273) are the same as those of the controller
Dc(s) (which we obtained using the state-variable techniques), once the
factors in Dc(s) are multiplied out.
22The matrix on the left side of Eq. (7.272) is called a Sylvester matrix and is nonsingular if
and only if a(s) and b(s) have no common factor.

7.12 Direct Design with Rational Transfer Functions
555
The reduced-order compensator can also be derived using a polynomial
solution.
EXAMPLE 7.41
Reduced-Order Design for a Polynomial Transfer Function
Model
Design a reduced-order controller for the third-order system in Exam-
ple 7.29. The desired characteristic equation is
αc(s)αe(s) = s5 + 12s4 + 74s3 + 207s2 + 378s + 288.
Solution. The equations needed to solve this problem are the same as those
used to obtain Eq. (7.271), except that we take both d(s) and cy(s) to be of
degree n −1. We need to solve
(d0s2 + d1s + d2)(s3 + 10s2 + 16s) + 10(c0s2 + c1s + c2) ≡αc(s)αe(s).
(7.274)
Equating coefﬁcients of like powers of s in Eq. (7.274), we obtain
⎡
⎢⎢⎢⎢⎢⎢⎣
1
0
0
0
0
0
10
1
0
0
0
0
16
10
1
0
0
0
0
16
10
10
0
0
0
0
16
0
10
0
0
0
0
0
0
10
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
d0
d1
d2
c0
c1
c2
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
1
12
74
207
378
288
⎤
⎥⎥⎥⎥⎥⎥⎦
.
(7.275)
The solution is (again using the x = a\b command in Matlab)
Matlab a\b
d0 = 1,
c0 = −20.8,
d1 = 2.0,
c1 = −23.6,
d2 = 38,
c2 = 28.8,
and the resulting controller is
cy(s)
d(s) = −20.8s2 −23.6s + 28.8
s2 + 2.0s + 38
.
(7.276)
Again, Eq. (7.276) is exactly the same as Dcr(s) derived using the state-
variable techniques in Example 7.30, once the polynomials of Dcr(s) are
multiplied out and minor numerical differences are considered.
Notice that the reference input polynomial cr(s) does not enter into the
analysis of Examples 7.40 and 7.41. We can select cr(s) so that it will assign
zeros in the transfer function from R(s) to Y(s). This is the same role played
by γ (s) in Section 7.9. One choice is to select cr(s) to cancel αe(s) so that
the overall transfer function is
Y(s)
R(s) = Ksb(s)
αc(s) .

556
Chapter 7 State-Space Design
This corresponds to the ﬁrst and most common choice of M and ¯N for
introducing the reference input described in Section 7.9.
It is also possible to introduce integral control and, indeed, internal-
Adding integral control to
the polynomial solution
model-based robust tracking control into the polynomial design method.
What is required is that we have error control and that the controller has
poles at the internal model locations. To get error control with the structure
of Fig. 7.76, we need only let cr = cy. To get desired poles into the controller,
we need to require that a speciﬁc factor be part of d(s). For integral control—
the most common case—this is almost trivial. The polynomial d(s) will have
a root at zero if we set the last term, dm, to zero. The resulting equations can
be solved if m = n. For a more general internal model, we deﬁne d(s) to be
the product of a reduced-degree polynomial and a speciﬁed polynomial such
as Eq. (7.247), and match coefﬁcients in the Diophantine equation as before.
The process is straightforward but tedious. Again we caution that, while the
polynomial design method can be effective, the numerical problems of this
method are often much worse than those associated with methods based on
state equations. For higher-order systems, as well as systems with multiple
inputs and outputs, the state-space methods are preferable.
7.13
Design for Systems with Pure Time Delay
In any linear system consisting of lumped elements, the response of the
△
system appears immediately after an excitation of the system. In some feed-
back systems—for example, process control systems, whether controlled by
a human operator in the loop or by computer—there is a pure time delay
Overall transfer function
for a time-delayed system
(also called transportation lag) in the system. As a result of the distributed
nature of these systems, the response remains identically zero until after a
delay of λ seconds. A typical step response is shown in Fig. 7.77(a). The
transfer function of a pure transportation lag is e−λs. We can represent an
overall transfer function of a SISO system with time delay as
GI(s) = G(s)e−λs,
(7.277)
where G(s) has no pure time delay. Because GI(s) does not have a ﬁnite state
description, standard use of state-variable methods is impossible. However,
Smith (1958) showed how to construct a feedback structure that effectively
takes the delay outside the loop and allows a feedback design based on G(s)
alone, which can be done with standard methods. The result of this method
is a design having closed-loop transfer function with delay λ but otherwise
showing the same response as the closed-loop design based on no delay. To
see how the method works, let us consider the feedback structure shown in
Fig. 7.77(b). The overall transfer function is
Y(s)
R(s) = T (s) =
D′
c(s)G(s)e−λs
1 + D′c(s)G(s)e−λs .
(7.278)

7.13 Design for Systems with Pure Time Delay
557
(a)
1
td = l
y(t)
t
D¿c(s)
-
+
R
e-lsG(s)
Y
(b)
Dc(s)
-
+
R
Y
(c)
-
+
G(s) - e-lsG(s)
e-lsG(s)
Compensator D¿c(s)
©
©
©
Figure 7.77
A Smith regulator for systems with pure time delay
Smith suggested that we solve for D′
c(s) by setting up a dummy overall
transfer function in which the controller transfer function Dc(s) is in a loop
with G(s) with no loop delay but with an overall delay of λ:
Y(s)
R(s) = T (s) =
Dc(s)G(s)
1 + Dc(s)G(s)e−λs.
(7.279)
We then equate Eqs. (7.278) and (7.279) to solve for D′
c(s):
The Smith compensator
D′
c(s) =
Dc(s)
1 + Dc(s)[G(s) −G(s)e−λs].
(7.280)
If the plant transfer function and the delay are known, D′
c(s) can be
realized with real components by means of the block diagram shown in
Fig. 7.77(c). With this knowledge, we can design the compensator Dc(s)
in the usual way, based on Eq. (7.279), as if there were no delay, and then
implement it as shown in Fig. 7.77(c). The resulting closed-loop system
would exhibit the behavior of a ﬁnite closed-loop system except for the time
delay λ. This design approach is particularly suitable when the pure delay,
λ, is signiﬁcant as compared to the process time constant, for example, in
pulp and paper process applications.
Notice that, conceptually, the Smith compensator is feeding back a
simulated plant output to cancel the true plant output and then adding in a
simulated plant output without the delay. It can be demonstrated that D′
c(s) in
Fig. 7.77(c) is equivalent to an ordinary regulator in line with a compensator

558
Chapter 7 State-Space Design
that provides signiﬁcant phase lead. To implement such compensators in
analog systems, it is usually necessary to approximate the delay required in
D′
c(s) by a Padé approximant; with digital compensators the delay can be
implemented exactly (see Chapter 8). It is also a fact that the compensator
D′
c(s) is a strong function of G(s), and a small error in the model of the
plant used in the controller could lead to large errors in the closed loop,
perhaps even to instability. This design is very sensitive both to uncertainties
in plant parameters as well as uncertainty in the time delay. If Dc(s) is
implemented as a PI controller, then one could detune (that is, reduce the
gain) to try to ensure stability and reasonable performance. For automatic
tuning of the Smith regulator and an application to Stanford's quiet hydraulic
precision lathe ﬂuid temperature control, the reader is referred to Huang and
DeBra (2000).
EXAMPLE 7.42
Heat Exchanger: Design with Pure Time Delay
Figure 7.78 shows the heat exchanger from Example 2.15. The temperature
of the product is controlled by controlling the ﬂow rate of steam in the
exchanger jacket. The temperature sensor is several meters downstream from
the steam control valve, which introduces a transportation lag into the model.
A suitable model is given by
G(s) =
e−5s
(10s + 1)(60s + 1).
Design a controller for the heat exchanger using the Smith compensator and
pole placement. The control poles are to be at
pc = −0.05 ± 0.087j,
Figure 7.78
A heat exchanger
Steam
Flow
Steam 
Product
Temperature
sensor
Control
valve

7.15 Historical Perspective
559
and the estimator poles are to be at three times the control poles' natural
frequency:
pe = −0.15 ± 0.26j.
Simulate the response of the system with Simulink.
Solution. A suitable set of state-space equations is
˙x(t) =
 −0.017
0.017
0
−0.1
	
x(t) +

0
0.1
	
u(t −5),
y = [ 1
0 ]x,
λ = 5.
For the speciﬁed control pole locations and for the moment ignoring the time
delay, we ﬁnd that the state feedback gain is
K = [5.2 −0.17].
For the given estimator poles, the estimator gain matrix for a full-order
estimator is
L =
 0.18
4.2
	
.
The resulting controller transfer function is
Dc(s) = U(s)
Y(s) = −0.25(s + 1.8)
s + 0.14 ± 0.27j.
If we choose to adjust for unity closed-loop DC gain, then
¯N = 1.2055.
The Simulink23 diagram for the system is shown in Fig. 7.79. The open-
loop and closed-loop step responses of the system and the control effort are
shown in Figs. 7.80 and 7.81, and the root locus of the system (without the
delay) is shown in Fig. 7.82. Note that the time delay of 5 sec in Figs. 7.80
and 7.81 is quite small compared with the response of the system, and is
barely noticeable in this case.
7.14
Solution of State Equations
It is possible to write down the solution to the state equations using the matrix
exponential. See Appendix W7.13.1 available at www.fpe7e.com.
7.15
Historical Perspective
The state-variable approach to solving differential equations in engineering
problems was advocated by R. E. Kalman while attending MIT. This was
revolutionary and rufﬂed some feathers as it was going against the grain.
23Simulink simulation

560
Chapter 7 State-Space Design
Scope1
-
+
-
+
s2 + .28s + .0925
.25s + .45
1.20
Transfer Fcn1
600s2 + 70s + 1
1
Transfer Fcn2
-
+
600s2 + 70s + 1
1
Transfer Fcn
Transport
delay
Transport
delay
u
y
To
workspace1
Scope
Step
To workspace
Figure 7.79
Closed-loop Simulink diagram for a heat exchanger
Figure 7.80
Step response for a heat
exchanger
Output temperature, y
0
50
100
150
200
250
300
Time (sec)
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Closed loop
Open loop
The well-established academics, Kalman's teachers, were well-versed in the
frequency domain techniques and staunch supporters of it. Beginning in the
late 1950s and early 1960s, Kalman wrote a series of seminal papers intro-
ducing the ideas of state-variables, controllability, observability, the Linear
Quadratic (LQ), and the Kalman Filter (LQF). Gunkel and Franklin (1963)
and Joseph and Tou (1961) independently showed the separation theorem,
which made possible the Linear Quadratic Gaussian (LQG) problem now-
days referred to as the H2 formulation. The separation theorem is a special
case of the certainty-equivalence theorem of Simon (1956). The solutions
to both LQ and LQG problems can be expressed in an elegant fashion in

7.15 Historical Perspective
561
Figure 7.81
Control effort for a heat
exchanger
Control, u
0
50
100
150
200
250
300
Time (sec)
-1
0
1
2
3
4
5
6
7
Figure 7.82
Root locus for a heat
exchanger
Re(s)
Im(s)
0.3
0.2
-0.2
-0.3
-0.4
-0.3
-0.2
-0.1
0.1
0.2
0.3
0.4
Closed-loop poles
Closed-loop poles
terms of the solutions to Riccati equations. D. G. Luenberger, who was tak-
ing a course with Kalman at Stanford University, derived the observer and
reduced-order observer over a weekend after hearing Kalman suggesting
the problem in a lecture. Kalman, Bryson, Athans, and others contributed to
the ﬁeld of optimal control theory that was widely employed in aerospace
problems including the Apollo program. The book by Zadeh and Desoer
published in 1962 was also inﬂuential in promoting the state-space method.
In the 1970s the robustness of LQ and LQG methods were studied resulting
in the celebrated and inﬂuential paper of Doyle and Stein in 1981. One of
the most signiﬁcant contributions of Doyle and Safonov was to extend the
idea of frequency domain gain to multi-input multi-output systems using the
singular value decomposition. Others contributing to this research included
G. Zames who introduced the H∞methods that were found to be extensions
to the H2 methods. The resulting design techniques are known as H∞and

562
Chapter 7 State-Space Design
μ-synthesis procedures. During the 1980s reliable numerical methods were
developed for dealing with state-variable designs and computer-aided soft-
ware for control design was developed. The invention of Matlab by Cleve
Moler and its wide distribution by The MathWorks has had a huge impact not
only in the control design ﬁeld but on all interactive scientiﬁc computations.
While the state-variable methods were gaining momentum particularly
in the United States, research groups in Europe especially in England led
by Rosenbrock, MacFarlane, Munro, and others extended the classical tech-
niques to multi-input multi-output systems. Hence root locus and frequency
domain methods such as the (inverse) Nyquist techniques could be used for
multi-input multi-output systems. Eventually in the 1980s there was a real-
ization that the power of both frequency domain and state-variable methods
should be combined for an eclectic control design method employing the
best of both approaches.
We saw in Chapter 7 that in contrast to frequency response methods of
BodeandNyquist, thestate-variablemethodnotonlydealswiththeinputand
output variables of the system but also with the internal physical variables.
The state-variable methods can be used to study linear and nonlinear, as well
as time varying systems. Furthermore, the state-variable method handles the
multi-input multi-output problems and high-order systems with equal ease.
Fromacomputationalperspective, thestate-variablemethodsarefarsuperior
to the frequency domain techniques that require polynomial manipulations.
SUMMARY
•
To every transfer function that has no more zeros than poles, there
corresponds a differential equation in state-space form.
•
State-space descriptions can be in several canonical forms.Among these
are control, observer, and modal canonical forms.
•
Open-loop poles and zeros can be computed from the state description
matrices (A, B, C, D):
Poles: p = eig(A),
det(pI −A) = 0,
Zeros: det
zI −A
−B
C
D
	
= 0.
•
For any controllable system of order n, there exists a state feedback con-
trol law that will place the closed-loop poles at the roots of an arbitrary
control characteristic equation of order n.
•
The reference input can be introduced so as to result in zero steady-state
error to a step command. This property is not expected to be robust to
parameter changes.
•
Good closed-loop pole locations depend on the desired transient
response, the robustness to parameter changes, and a balance between
dynamic performance and control effort.

Summary
563
•
Closed-loop pole locations can be selected to result in a domi-
nant second-order response, or to minimize a quadratic performance
measure.
•
For any observable system of order n, an estimator (or observer) can be
constructed with only sensor inputs and a state that estimates the plant
state. The n poles of the estimator error system can be placed arbitrarily.
•
Every transfer function can be represented by a minimal realization,
that is, a state-space model that is both controllable and observable.
•
A single-input single-output system is completely controllable if and
only if the input excites all the natural frequencies of the system, that
is, there is no cancellation of the poles in the transfer function.
•
The control law and the estimator can be combined into a controller such
that the poles of the closed-loop system are the union of the control-
law-only poles and the estimator-only poles.
•
With the estimator-based controller, the reference input can be intro-
duced in such a way as to permit n arbitrary zeros to be assigned. The
most common choice is to assign the zeros to cancel the estimator poles,
thus not exciting an estimator error.
•
Integralcontrol canbeintroducedtoobtainrobuststeady-statetracking
of a step by augmenting the plant state. The design is also robust with
respect to rejecting constant disturbances.
•
General robust control can be realized by combining the equations of
the plant and the reference model into an error space and designing
a control law for the extended system. Implementation of the robust
design demonstrates the internal model principle. An estimator of the
plant state can be added while retaining the robustness properties.
•
The model-following technique can produce superior tracking proper-
ties but suffers from robustness problems.
•
The estimator can be extended to include estimates of the equivalent
control disturbance and so result in robust tracking and disturbance
rejection.
•
Pole-placement designs, including integral control, can be computed
using the polynomials of the plant transfer function in place of the state
descriptions. Designs using polynomials frequently have problems with
numerical accuracy.
•
Controllers for plants that include a pure time delay can be designed
as if there were no delay, and then a controller can be implemented for
the plant with the delay. The design can be expected to be sensitive to
parameter changes, especially to uncertainty in the delay time.
•
Table 7.3 gives the important equations discussed in this chapter. The
triangles indicate equations taken from optional sections in the text.
•
Determining a model from experimental data, or verifying an ana-
lytically based model by experiment, is an important step in system
design by state-space analysis, a step that is not necessarily needed for
compensator design via frequency-response methods.

564
Chapter 7 State-Space Design
TABLE 7.3
Important Equations in Chapter 7
Name
Equation
Page
Control canonical form
Ac =
⎡
⎢⎢⎢⎢⎢⎢⎣
−a1
−a2
· · ·
· · ·
−an
1
0
· · ·
· · ·
0
0
1
0
· · ·
0
...
...
0
...
0
0
· · ·
1
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Bc =
⎡
⎢⎢⎢⎢⎢⎢⎣
1
0
0
...
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
446
Cc = [
b1
b2
· · ·
· · ·
bn
],
Dc = 0.
State description
˙x = Ax + Bu
449
Output equation
y = Cx + Du
449
Transformation of state
¯A = T−1AT
449
¯B = T−1B
y = CTz + Du = ¯Cz + ¯Du,
where ¯C = CT, ¯D = D
Controllability matrix
C = [B
AB
· · ·
An−1B]
450
Transfer function from
state equations
G(s) = Y(s)
U(s) = C(sI −A)−1B + D
458
Transfer-function poles
det( piI −A) = 0
459
Transfer-function zeros
αz(s) = det
ziI −A
−B
C
D
	
= 0
460
Control characteristic
equation
det[sI −(A −BK)] = 0
465
Ackermann's control formula
for pole placement
K = [0
· · ·
0
1]C−1αc(A)
469
Reference input gains
A
B
C
D
	 Nx
Nu
	
=
0
1
	
474
Control equation with
reference input
u = Nur −K(x −Nxr)
474
= −Kx + (Nu + KNx)r
= −Kx + ¯Nr
Symmetric root locus
1 + ρG0(−s)G0(s) = 0
480
Estimator error
characteristic equation
αe(s) = det[sI −(A −LC)] = 0
490
Observer canonical form
˙x◦= A◦x◦+ B◦u,
493
y = C◦x◦,
where
Ao =
⎡
⎢⎢⎢⎢⎢⎣
−a1
1
0
0
. . .
0
−a2
0
1
0
. . .
...
...
...
...
1
−an
0
0
0
⎤
⎥⎥⎥⎥⎥⎦
,
Bo =
⎡
⎢⎢⎢⎣
b1
b2
...
bn
⎤
⎥⎥⎥⎦,
Co = [ 1
0
0
· · ·
0],

Review Questions
565
TABLE 7.3
Continued
Name
Equation
Page
Observability matrix
O =
⎡
⎢⎢⎢⎢⎣
C
CA
...
CAn−1
⎤
⎥⎥⎥⎥⎦
,
494
Ackermann's estimator
formula
L = αe(A)O−1
⎡
⎢⎢⎢⎣
0
0
...
1
⎤
⎥⎥⎥⎦
494
Compensator transfer
function
Dc(s) = U(s)
Y(s) = −K(sI −A + BK + LC)−1L
503
Reduced-order compensator
transfer function
Dcr(s) = U(s)
Y(s) = Cr(sI −Ar)−1Br + Dr
503
Controller equations
˙ˆx = (A −BK −LC)ˆx + Ly + Mr
516
u = −Kˆx + ¯Nr
Augmented state equations
with integral control
˙xI
˙x
	
=
0
C
0
A
	 xI
x
	
+
0
B
	
u −
1
0
	
r +
 0
B1
	
w
526
△General controller in
polynomial form
U(s) = −cy(s)
d(s) Y(s) + cr(s)
d(s) R(s)
552
△Diophantine equation for
closed-loop characteristic
equation
a(s)d(s) + b(s)cy(s) = αc(s)αe(s)
553
REVIEW QUESTIONS
The following questions are based on a system in state-variable form with matrices
A, B, C, D, input u, output y, and state x.
7.1
Why is it convenient to write dynamic equations in state-variable form?
7.2
Give an expression for the transfer function of this system.
7.3
Give two expressions for the poles of the transfer function of the system.
7.4
Give an expression for the zeros of the system transfer function.
7.5
Under what condition will the state of the system be controllable?
7.6.
Under what conditions will the system be observable from the output y?
7.7
Give an expression for the closed-loop poles if state feedback of the form
u = −Kx is used.
7.8
Under what conditions can the feedback matrix K be selected so that the roots
of αc(s) are arbitrary?

566
Chapter 7 State-Space Design
7.9
What is the advantage of using the LQR or SRL in designing the feedback
matrix K?
7.10
What is the main reason for using an estimator in feedback control?
7.11
If the estimator gain L is used, give an expression for the closed-loop poles
due to the estimator.
7.12
Under what conditions can the estimator gain L be selected so that the roots
of αe(s) = 0 are arbitrary?
7.13
If the reference input is arranged so that the input to the estimator is identical
to the input to the process, what will the overall closed-loop transfer function
be?
7.14
If the reference input is introduced in such a way as to permit the zeros to
be assigned as the roots of γ (s), what will the overall closed-loop transfer
function be?
7.15
What are the three standard techniques for introducing integral control in the
state feedback design method?
PROBLEMS
Problems for Section 7.3: Block Diagrams and State-Space
7.1
Write the dynamic equations describing the circuit in Fig. 7.83. Write the
equations as a second-order differential equation in y(t). Assuming a zero
input, solve the differential equation for y(t) using Laplace transform methods
for the parameter values and initial conditions shown in the ﬁgure. Verify your
answer using the initial command in Matlab.
Figure 7.83
Circuit for Problem 7.1
L = 1 H
R = 2 Æ
C = 1 F
y(t)
u(t)
y(to) = 1 V,  y(to) = 0
7.2
A schematic for the satellite and scientiﬁc probe for the Gravity Probe-B
(GP-B) experiment that was launched on April 30, 2004 is sketched in
Fig. 7.84. Assume that the mass of the spacecraft plus helium tank, m1, is
2000 kg and the mass of the probe, m2, is 1000 kg. A rotor will ﬂoat inside
the probe and will be forced to follow the probe with a capacitive forcing
mechanism. The spring constant of the coupling k is 3.2 × 106. The viscous
damping b is 4.6 × 103.
(a) Writethedynamicequationsofmotionforthesystemconsistingofmasses
m1 and m2 using the inertial position variables, y1 and y2.
(b) The actual disturbance u is a micrometeorite, and the resulting motion is
very small. Therefore, rewrite your equations with the scaled variables
z1 = 106y1, z2 = 106y2, and v = 1000u.

Problems
567
(c) Put the equations in state-variable form using the state x
=
[z1
˙z1 z2
˙z2]T, the output y = z2, and the input an impulse, u =
10−3δ(t) N·sec on mass m1.
(d) Using the numerical values, enter the equations of motion into Matlab in
the form
˙x = Ax + Bv
(7.281)
y = Cx + Dv.
(7.282)
and deﬁne the Matlab system: sysGPB = ss(A,B,C,D). Plot the response of y
caused by the impulse with the Matlab command impulse(sysGPB). This
is the signal the rotor must follow.
(e) Use the Matlab commands p=eig(F) to ﬁnd the poles (or roots) of the
system and z =tzero(A,B,C, D) to ﬁnd the zeros of the system.
Figure 7.84
Schematic diagram of
the GP-B satellite and
probe
m1
m2
y1
y2
Rotor
k
u
b
Problems for Section 7.4: Analysis of the State Equations
7.3
Give the state description matrices in control-canonical form for the following
transfer functions:
(a) G(s) =
1
2s + 1.
(b) G(s) = 6(s/3 + 1)
(s/10 + 1).
(c) G(s) =
8s + 1
s2 + 3 + 2.
(d) G(s) =
s + 7
s(s2 + 2s + 2).
(e) G(s) = (s + 10)(s2 + s + 25)
s2(s + 2)(s2 + s + 36).
7.4
Use the Matlab function tf2ss to obtain the state matrices called for in Problem
7.3.
7.5
Give the state description matrices in modal canonical form for the transfer
functions of Problem 7.3. Make sure that all entries in the state matrices are
real valued by keeping any pairs of complex conjugate poles together, and
realize them as a separate subblock in control canonical form.
7.6
A certain system with state x is described by the state matrices
A =
 −2
1
−2
0
	
,
B =
 1
3
	
,
C =

1
0 
,
D = 0.

568
Chapter 7 State-Space Design
Find the transformation T so that if x = Tz, the state matrices describing the
dynamics of z are in control canonical form. Compute the new matrices ¯A, ¯B,
¯C, and ¯D.
7.7
Show that the transfer function is not changed by a linear transformation of
state.
7.8
Use block-diagram reduction or Mason's rule to ﬁnd the transfer function for
the system in observer canonical form depicted by Fig. 7.31.
7.9
Suppose we are given a system with state matrices A, B, C (D = 0 in this
case). Find the transformation T so that, under Eqs. (7.21) and (7.22), the new
state description matrices will be in observer canonical form.
7.10
Use the transformation matrix in Eq. (7.38) to explicitly multiply out the
equations at the end of Example 7.9.
7.11
Find the state transformation that takes the observer canonical form of
Eq. (7.32) to the modal canonical form.
7.12
(a) Find the transformation T that will keep the description of the tape-drive
system of Example 7.10 in modal canonical form but will convert each
element of the input matrix Bm to unity.
(b) Use Matlab to verify that your transformation does the job.
7.13
(a) Find the state transformation that will keep the description of the tape-
drive system of Example 7.10 in modal canonical form but will cause the
poles to be displayed in Am in order of increasing magnitude.
(b) Use Matlab to verify your result in part (a), and give the complete new
set of state matrices as ¯A, ¯B, ¯C, and ¯D.
7.14
Find the characteristic equation for the modal-form matrix Am of Eq. (7.14a)
using Eq. (7.55).
7.15
Given the system
˙x =
 −5
1
−2
−1
	
x +
 0
1
	
u,
with zero initial conditions, ﬁnd the steady-state value of x for a step input u.
7.16
Consider the system shown in Fig. 7.85:
(a) Find the transfer function from U to Y.
(b) Write state equations for the system using the state-variables indicated.
Figure 7.85
A block diagram for
Problem 7.16
U
©
-
+
G1 = s + 4
1
G2 = 2s
1
H2 = s
1
H1 = s
1
x2
x3
x4
©
 + 
 + 
©
 + 
 + 
Y
x1
7.17
Using the indicated state-variables, write the state equations for each of the
systems shown in Fig. 7.86. Find the transfer function for each system using
both block-diagram manipulation and matrix algebra [as in Eq. (7.45)].

Problems
569
Figure 7.86
Block diagrams for
Problem 7.17
U
s
1
©
 + 
 + 
s + 4
1
s + 3
s + 2
s + 10
1
s + 2
1
s
4
5
Y
©
x1
x2
x3
x1
U
©
 + 
 + 
Y
©
x3
x4
s + 3
1
 + 
 + 
x1
x2
(a)
(b)
 + 
 + 
-
-
7.18
For each of the listed transfer functions, write the state equations in both
control and observer canonical form. In each case, draw a block diagram and
give the appropriate expressions for A, B, and C.
(a) G(s) =
s2 −2
s2(s2 −1) (control of an inverted pendulum by a force on the cart).
(b) G(s) =
3s + 4
s2 + 2s + 2.
7.19
Consider the transfer function
G(s) = Y(s)
U(s) =
s + 6
s2 + 5s + 6.
(7.283)
(a) By rewriting Eq. (7.283) in the form
G(s) = Y(s)
U(s) =
1
s + 3

s + 6
s + 2

ﬁnd a series realization of G(s) as a cascade of two ﬁrst-order systems.
(b) Using a partial-fraction expansion of G(s), ﬁnd a parallel realization of
G(s).
(c) Realize G(s) in control canonical form.
7.20
Show that the impulse response of the system (A, B, C, D) is given by
h(t) = CeAtB + Dδ(t),
where eAt is the matrix exponential deﬁned by
eAt =

I + At + A2t2
2!
+ · · ·

=
∞

k=0
Aktk
k! .

570
Chapter 7 State-Space Design
Problems for Section 7.5: Control Law Design for Full-State
Feedback
7.21
Consider the plant described by
˙x =
 0
1
7
−4
	
x +
 1
2
	
u,
y = [ 1
3 ]x.
(a) Draw a block diagram for the plant with one integrator for each
state-variable.
(b) Find the transfer function using matrix algebra.
(c) Find the closed-loop characteristic equation if the feedback is
(i)
u = −
 K1
K2

x;
(ii) u = −Ky.
7.22
For the system
˙x =

0
1
−6
−5
	
x +
 0
1
	
u,
design a state feedback controller that satisﬁes the following speciﬁcations:
(a) Closed-loop poles have a damping coefﬁcient ζ = 0.707.
(b) Step-response peak time is under 3.14 sec.
Verify your design with Matlab.
7.23
(a) Design a state feedback controller for the following system so that the
closed-loop step response has an overshoot of less than 25% and a 1%
settling time under 0.115 sec:
˙x =
 0
1
0
−10
	
x +
 0
1
	
u.
(b) Use the step command in Matlab to verify that your design meets the
speciﬁcations. If it does not, modify your feedback gains accordingly.
7.24
Consider the system
˙x =
⎡
⎣
−1
−2
−2
0
−1
1
1
0
−1
⎤
⎦x +
⎡
⎣
2
0
1
⎤
⎦u.
(a) Design a state feedback controller for the system so that the closed-loop
step response has an overshoot of less than 5% and a 1% settling time
under 4.6 sec.
(b) Use the step command in Matlab to verify that your design meets the
speciﬁcations. If it does not, modify your feedback gains accordingly.
7.25
Consider the system in Fig. 7.87.
Figure 7.87
System for Problem 7.25
s2 + 4
s
U
Y
(a) Writeasetofequationsthatdescribesthissysteminthestandardcanonical
control form as ˙x = Ax + Bu and y = Cx.

Problems
571
(b) Design a control law of the form
u = −
 K1
K2
  x1
x2
	
,
which will place the closed-loop poles at s = −2 ± 2j.
7.26
OutputControllability. Inmanysituationsacontrolengineermaybeinterested
in controlling the output y rather than the state x. A system is said to be output
controllable if at any time you are able to transfer the output from zero to
any desired output y∗in a ﬁnite time using an appropriate control signal u∗.
Derive necessary and sufﬁcient conditions for a continuous system (A, B, C)
to be output controllable. Are output and state controllability related? If so,
how?
7.27
Consider the system
˙x =
⎡
⎢⎢⎣
0
4
0
0
−1
−4
0
0
5
7
1
15
0
0
3
−3
⎤
⎥⎥⎦x +
⎡
⎢⎢⎣
0
0
1
0
⎤
⎥⎥⎦u.
(a) Find the eigenvalues of this system. (Hint: Note the block-triangular
structure of A.)
(b) Find the controllable and uncontrollable modes of this system.
(c) For each of the uncontrollable modes, ﬁnd a vector v such that
vTB = 0,
vTA = λvT.
(d) Show that there are an inﬁnite number of feedback gains K that will
relocate the modes of the system to −5, −3, −2, and −2.
(e) Find the unique matrix K that achieves these pole locations and pre-
vents initial conditions on the uncontrollable part of the system from ever
affecting the controllable part.
7.28
Two pendulums, coupled by a spring, are to be controlled by two equal
and opposite forces u, which are applied to the pendulum bobs as shown
in Fig. 7.88. The equations of motion are
ml2 ¨θ1 = −ka2(θ1 −θ2) −mglθ1 −lu,
ml2 ¨θ2 = −ka2(θ2 −θ1) −mglθ2 + lu.
Figure 7.88
Coupled pendulums for
Problem 7.28
k
u
u
m
m
u1
u2
a
l

572
Chapter 7 State-Space Design
(a) Show that the system is uncontrollable. Can you associate a physical
meaning with the controllable and uncontrollable modes?
(b) Is there any way that the system can be made controllable?
7.29
The state-space model for a certain application has been given to us with the
following state description matrices:
A =
⎡
⎢⎢⎢⎢⎣
0.174
0
0
0
0
0.157
0.645
0
0
0
0
1
0
0
0
0
0
1
0
0
0
0
0
1
0
⎤
⎥⎥⎥⎥⎦
,
B =
⎡
⎢⎢⎢⎢⎣
−0.207
−0.005
0
0
0
⎤
⎥⎥⎥⎥⎦
,
C = [ 1
0
0
0
0 ].
(a) Draw a block diagram of the realization with an integrator for each state-
variable.
(b) A student has computed det C = 2.3 × 10−7 and claims that the system
is uncontrollable. Is the student right or wrong? Why?
(c) Is the realization observable?
7.30
StaircaseAlgorithm(VanDoorenetal., 1978):Anyrealization(A,B,C)canbe
transformed by an orthogonal similarity transformation to ( ¯A, ¯B, ¯C), where
¯A is an upper Hessenberg matrix (having one nonzero diagonal above the
main diagonal) given by
¯A = TTAT =
⎡
⎢⎢⎢⎢⎣
∗
α1
0
0
∗
∗
...
0
∗
∗
...
αn−1
∗
∗
· · ·
∗
⎤
⎥⎥⎥⎥⎦
,
¯B = TTB =
⎡
⎢⎢⎢⎣
0
...
0
g1
⎤
⎥⎥⎥⎦,
where g1 ̸= 0, and
¯C = CT = [ ¯c1
¯c2
· · ·
¯cn ],
T−1 = TT.
Orthogonal transformations correspond to a rotation of the vectors (rep-
resented by the matrix columns) being transformed with no change in
length.
(a) Prove that if αi = 0 and αi+1,· · · , αn−1 ̸= 0 for some i, then the
controllable and uncontrollable modes of the system can be identiﬁed
after this transformation has been done.
(b) How would you use this technique to identify the observable and
unobservable modes of (A, B, C)?
(c) What advantage does this approach for determining the controllable and
uncontrollable modes have over transforming the system to any other
form?
(d) How can we use this approach to determine a basis for the controllable
and uncontrollable subspaces, as in Problem 7.44?
This algorithm can also be used to design a numerically stable algorithm for
pole placement [see Minimis and Paige (1982)]. The name of the algorithm
comes from the multi-input version in which the αi are the blocks that make
¯A resemble a staircase. Refer to ctrbf, obsvf commands in Matlab.

Problems
573
Problems for Section 7.6: Selection of Pole Locations for Good
Design
7.31
The normalized equations of motion for an inverted pendulum at angle θ on
a cart are
¨θ = θ + u,
¨x = −βθ −u,
where x is the cart position, and the control input u is a force acting on the
cart.
(a) With the state deﬁned as x = [ θ
·
θ
x
·x ]T ﬁnd the feedback gain
K that places the closed-loop poles at s = −1, −1, −1 ± 1j. For parts (b)
through (d), assume that β = 0.5.
(b) Use the SRL to select poles with a bandwidth as close as possible to those
of part (a), and ﬁnd the control law that will place the closed-loop poles
at the points you selected.
(c) Compare the responses of the closed-loop systems in parts (a) and (b) to
an initial condition of θ = 10◦.You may wish to use the initial command
in Matlab.
(d) Compute Nx and Nu for zero steady-state error to a constant command
input on the cart position, and compare the step responses of each of the
two closed-loop systems.
7.32
An asymptotically stable Type I system with input r and output y is described
by the closed-loop system matrices (A, B, C, D = 0). Suppose the input is
given by the ramp r = at, for t > 0. Show that the velocity error coefﬁcient
is given by
Kv =

CA−2B
−1
.
7.33
Prove that the Nyquist plot for LQR design avoids a circle of radius one
centered at the −1 point, as shown in Fig. 7.89. Show that this implies that
1
2 < GM < ∞, the "upward" gain margin is GM = ∞, and there is a
"downward" GM = 1
2, and the phase margin is at least PM = ±60◦. Hence
the LQR gain matrix, K, can be multiplied by a large scalar or reduced by
half with guaranteed closed-loop system stability.
Figure 7.89
Nyquist plot for an
optimal regulator
Im(L(jv))
Re(L(jv))
-2
-1
605
a1

574
Chapter 7 State-Space Design
Problems for Section 7.7: Estimator Design
7.34
Consider the system
A =
 −2
1
1
0
	
, B =
 1
0
	
, C = [ 1
2 ],
and assume that you are using feedback of the form u = −Kx + r, where r is
a reference input signal.
(a) Show that (A, C) is observable.
(b) Show that there exists a K such that (A −BK, C) is unobservable.
(c) Compute a K of the form K = [1, K2] that will make the system unob-
servable as in part (b); that is, ﬁnd K2 so that the closed-loop system is
not observable.
(d) Compare the open-loop transfer function with the transfer function of the
closed-loop system of part (c). What is the unobservability due to?
7.35
Consider a system with the transfer function
G(s) =
9
s2 −9.
(a) Find (Ao, Bo, Co) for this system in observer canonical form.
(b) Is (Ao, Bo) controllable?
(c) Compute K so that the closed-loop poles are assigned to s = −3 ± 3j.
(d) Is the closed-loop system of part (c) observable?
(e) Design a full-order estimator with estimator error poles at s = −12±12j.
(f) Suppose the system is modiﬁed to have a zero:
G1(s) = 9(s + 1)
s2 −9 .
Prove that if u = −Kx + r, there is a feedback gain K that makes the
closed-loop system unobservable. [Again assume an observer canonical
realization for G1(s).]
7.36
Explain how the controllability, observability, and stability properties of a
linear system are related.
7.37
Consider the electric circuit shown in Fig. 7.90.
(a) Write the internal (state) equations for the circuit. The input u(t) is a
current, and the output y is a voltage. Let x1 = iL and x2 = vc.
(b) What condition(s) on R, L, and C will guarantee that the system is
controllable?
Figure 7.90
Electric circuit for
Problem 7.37
-
iL
L
u
R
yc
+
-
C
R
y
+

Problems
575
(c) What condition(s) on R, L, and C will guarantee that the system is
observable?
7.38
The block diagram of a feedback system is shown in Fig. 7.91. The system
state is
x =
 xp
xf
	
,
and the dimensions of the matrices are as follows:
A = n × n,
L = n × 1,
B = n × 1,
x = 2n × 1,
C = 1 × n,
r = 1 × 1,
K = 1 × n,
y = 1 × 1.
Figure 7.91
Block diagram for
Problem 7.38
©
 - 
 + 
r
s
1
K
©
y
 + 
B
B
L
A
 + 
©
 + 
 + 
s
1
A
©
 + 
C
xf
xp
 + 
C
 - 
(a) Write state equations for the system.
(b) Let x = Tz, where
T =
 I
0
I
I
	
.
Show that the system is not controllable.
(c) Find the transfer function of the system from r to y.
7.39
This problem is intended to give you more insight into controllability and
observability. Consider the circuit in Fig. 7.92, with an input voltage source
u(t) and an output current y(t).
(a) Using the capacitor voltage and inductor current as state-variables, write
state and output equations for the system.
Figure 7.92
Electric circuit for
Problem 7.39
u(t)
R1
x1
 + 
 - 
C
R2
y(t)
L
x2
 + 
 - 

576
Chapter 7 State-Space Design
(b) Find the conditions relating R1, R2, C, and L that render the system uncon-
trollable. Find a similar set of conditions that result in an unobservable
system.
(c) Interpret the conditions found in part (b) physically in terms of the time
constants of the system.
(d) Find the transfer function of the system. Show that there is a pole-zero
cancellation for the conditions derived in part (b) (that is, when the system
is uncontrollable or unobservable).
7.40
The linearized dynamic equations of motion for a satellite are
˙x = Ax + Bu,
y = Cx,
where
A =
⎡
⎢⎢⎣
0
1
0
0
3ω2
0
0
2ω
0
0
0
1
0
−2ω
0
0
⎤
⎥⎥⎦,
B =
⎡
⎢⎢⎣
0
0
1
0
0
0
0
1
⎤
⎥⎥⎦,
C =
 1
0
0
0
0
0
1
0
	
,
u =
 u1
u2
	
,
y =
 y1
y2
	
.
The inputs u1 and u2 are the radial and tangential thrusts, the state-variables
x1 and x3 are the radial and angular deviations from the reference (circular)
orbit, and the outputs y1 and y2 are the radial and angular measurements,
respectively.
(a) Show that the system is controllable using both control inputs.
(b) Show that the system is controllable using only a single input. Which one
is it?
(c) Show that the system is observable using both measurements.
(d) Show that the system is observable using only one measurement. Which
one is it?
7.41
Consider the system in Fig. 7.93.
Figure 7.93
Coupled pendulums for
Problem 7.41
k
d
F
F
g
M
Gas jet
K = kd
u1 = -v2u1 - K(u1 - u2) + F/ml
u2 = -v2u2 + K(u1 - u2) - F/ml
u1
u2
M

Problems
577
(a) Writethestate-variableequationsforthesystem, using

θ1
θ2
˙θ1
˙θ2
T
as the state vector and F as the single input.
(b) Show that all the state-variables are observable using measurements of θ1
alone.
(c) Show that the characteristic polynomial for the system is the product of
the polynomials for two oscillators. Do so by ﬁrst writing a new set of
system equations involving the state-variables
⎡
⎢⎢⎣
y1
y2
˙y1
˙y2
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
θ1 + θ2
θ1 −θ2
˙θ1 + ˙θ2
˙θ1 −˙θ2
⎤
⎥⎥⎦.
Hint: If A and D are invertible matrices, then
 A
0
0
D
	−1
=
 A−1
0
0
D−1
	
.
(d) Deduce the fact that the spring mode is controllable with F but the
pendulum mode is not.
7.42
A certain ﬁfth-order system is found to have a characteristic equation with
roots at 0, −1, −2, and −1 ± 1j. A decomposition into controllable and
uncontrollable parts discloses that the controllable part has a characteristic
equation with roots 0 and −1 ± 1j. A decomposition into observable and
nonobservable parts discloses that the observable modes are at 0, −1, and −2.
(a) Where are the zeros of b(s) = Cadj(sI −A)B for this system?
(b) What are the poles of the reduced-order transfer function that includes
only controllable and observable modes?
7.43
Consider the systems shown in Fig. 7.94, employing series, parallel, and
feedback conﬁgurations.
(a) Suppose
we
have
controllable-observable
realizations
for
each
subsystem:
˙xi = Axi + Biui,
yi = Cixi,
where i = 1, 2.
Give a set of state equations for the combined systems in Fig. 7.94.
(b) For each case, determine what condition(s) on the roots of the polynomials
Ni and Di is necessary for each system to be controllable and observable.
Give a brief reason for your answer in terms of pole-zero cancellations.
7.44
Consider the system ¨y + 3˙y + 2y = ˙u + u.
(a) Find the state matrices Ac, Bc, and Cc in control canonical form that
correspond to the given differential equation.
(b) Sketch the eigenvectors of Ac in the (x1, x2) plane, and draw vectors
that correspond to the completely observable (x0) and the completely
unobservable (x¯0) state-variables.
(c) Express x0 and x¯0 in terms of the observability matrix O.
(d) Give the state matrices in observer canonical form and repeat parts (b)
and (c) in terms of controllability instead of observability.

578
Chapter 7 State-Space Design
©
 - 
 + 
r
u1
G1(s) = D1(s)
N1(s)
u = u1
y1 = u2
y1
G2(s) = D2(s)
N2(s)
y
u2
G1(s) = D1(s)
N1(s)
G2(s) = D2(s)
N2(s)
y
u1
G1(s) = D1(s)
N1(s)
G2(s) = D2(s)
N2(s)
y = y1 + y2
©
 + 
 + 
y2
u2
u
(c)
(a)
(b)
Figure 7.94
Block diagrams for Problem 7.43: (a) series; (b) parallel; (c) feedback
7.45
The dynamic equations of motion for a station-keeping satellite (such as a
weather satellite) are
¨x −2ω˙y −3ω2x = 0,
¨y + 2ω˙x = u,
where
x = radial perturbation,
y = longitudinal position perturbation,
u = engine thrust in the y-direction,
as depicted in Fig. 7.95. If the orbit is synchronous with the earth's rotation,
then ω = 2π/(3600 × 24) rad/sec.
(a) Is the state x = [ x
·x
y
·y ]Tobservable?
(b) Choose x = [ x
·x
y
·y ]Tas the state vector and y as the mea-
surement, and design a full-order observer with poles placed at s =
−2ω, −3ω, and −3ω ± 3ωj.
7.46
The linearized equations of motion of the simple pendulum in Fig. 7.96 are
¨θ + ω2θ = u.
(a) Write the equations of motion in state-space form.
(b) Design an estimator (observer) that reconstructs the state of the pendulum
given measurements of ˙θ. Assume ω = 5 rad/sec, and pick the estimator
roots to be at s = −10 ± 10j.

Problems
579
Figure 7.95
Diagram of a
station-keeping
satellite in orbit for
Problem 7.45
Reference
longitude
Desired
location
on orbit
u
y
x
Figure 7.96
Pendulum diagram for
Problem 7.46
u
(c) Write the transfer function of the estimator between the measured value
of ˙θ and the estimated value of θ.
(d) Design a controller (that is, determine the state feedback gain K) so that
the roots of the closed-loop characteristic equation are at s = −4 ± 4j.
7.47
An error analysis of an inertial navigator leads to the set of normalized state
equations
⎡
⎣
˙x1
˙x2
˙x3
⎤
⎦=
⎡
⎣
0
−1
0
1
0
1
0
0
0
⎤
⎦
⎡
⎣
x1
x2
x3
⎤
⎦+
⎡
⎣
0
0
1
⎤
⎦u,
where
x1 = east—velocity error,
x2 = platform tilt about the north axis,
x3 = north—gyro drift,
u = gyro drift rate of change.
Design a reduced-order estimator with y = x1 as the measurement, and place
the observer-error poles at −0.1 and −0.1. Be sure to provide all the relevant
estimator equations.

580
Chapter 7 State-Space Design
Problems for Section 7.8: Compensator Design:
Combined Control Law and Estimator
7.48
A certain process has the transfer function G(s) =
4
(s2−4).
(a) Find A, B, and C for this system in observer canonical form.
(b) If u = −Kx, compute K so that the closed-loop control poles are located
at s = −2 ± 2j.
(c) Compute L so that the estimator error poles are located at s = −10±10j.
(d) Give the transfer function of the resulting controller [for example, using
Eq. (7.174)].
(e) What are the gain and phase margins of the controller and the given
open-loop system?
7.49
The linearized longitudinal motion of a helicopter near hover (see Fig. 7.97)
can be modeled by the normalized third-order system
⎡
⎢⎢⎣
·q
·
θ
·u
⎤
⎥⎥⎦=
⎡
⎣
−0.4
0
−0.01
1
0
0
−1.4
9.8
−0.02
⎤
⎦
⎡
⎣
q
θ
u
⎤
⎦+
⎡
⎣
6.3
0
9.8
⎤
⎦δ,
Figure 7.97
Helicopter for
Problem 7.49
Vertical
Fuselage
reference
axis
Rotor
thrust
Rotor
u
d
u
Suppose our sensor measures the horizontal velocity u as the output; that is,
y = u.
(a) Find the open-loop pole locations.
(b) Is the system controllable?
(c) Find the feedback gain that places the poles of the system at s = −1 ± 1j
and s = −2.
(d) Design a full-order estimator for the system, and place the estimator poles
at −8 and −4 ± 4
√
3j.
(e) Design a reduced-order estimator with both poles at −4. What are the
advantages and disadvantages of the reduced-order estimator compared
with the full-order case?
(f) Compute the compensator transfer function using the control gain and the
full-order estimator designed in part (d), and plot its frequency response

Problems
581
using Matlab. Draw a Bode plot for the closed-loop design, and indicate
the corresponding gain and phase margins.
(g) Repeat part (f) with the reduced-order estimator.
(h) Draw the SRL and select roots for a control law that will give a control
bandwidth matching the design of part (c), and select roots for a full-order
estimator that will result in an estimator error bandwidth comparable to
the design of part (d). Draw the corresponding Bode plot and compare
the pole placement and SRL designs with respect to bandwidth, stability
margins, step response, and control effort for a unit-step rotor-angle input.
Use Matlab for the computations.
7.50
Suppose a DC drive motor with motor current u is connected to the wheels of
a cart in order to control the movement of an inverted pendulum mounted on
the cart. The linearized and normalized equations of motion corresponding to
this system can be put in the form
¨θ = θ + v + u,
˙v = θ −v −u,
where
θ = angle of the pendulum,
v = velocity of the cart.
(a) We wish to control θ by feedback to u of the form
u = −K1θ −K2 ˙θ −K3v.
Find the feedback gains so that the resulting closed-loop poles are located
at −1, −1 ± j
√
3.
(b) Assume that θ and v are measured. Construct an estimator for θ and ˙θ of
the form
˙ˆx = Aˆx + L(y −Cˆx),
where x = [ θ
·
θ ]T and y = θ. Treat both v and u as known. Select L
so that the estimator poles are at −2, and −2.
(c) Give the transfer function of the controller, and draw the Bode plot of the
closed-loop system, indicating the corresponding gain and phase margins.
(d) Using Matlab, plot the response of the system to an initial condition on
θ, and give a physical explanation for the initial motion of the cart.
7.51
Consider the control of
G(s) = Y(s)
U(s) =
10
s(s + 1).
(a) Let y = x1 and x1 = x2, and write state equations for the system.
(b) Find K1 and K2 so that u = −K1x1 −K2x2 yields closed-loop poles with
a natural frequency ωn = 3 and a damping ratio ζ = 0.5.
(c) Design a state estimator that yields estimator error poles with ωn1 = 15
and ζ1 = 0.5.
(d) What is the transfer function of the controller obtained by combining parts
(a) through (c)?

582
Chapter 7 State-Space Design
(e) Sketch the root locus of the resulting closed-loop system as plant gain
(nominally 10) is varied.
7.52
Unstable dynamic equations of motion of the form
¨x = x + u,
arise in situations where the motion of an upside-down pendulum (such as a
rocket) must be controlled.
(a) Let u = −Kx (position feedback alone), and sketch the root locus with
respect to the scalar gain K.
(b) Consider a lead compensator of the form
U(s) = K s + a
s + 10X(s).
Select a and K so that the system will display a rise time of about 2 sec
and no more than 25% overshoot. Sketch the root locus with respect to K.
(c) Sketch the Bode plot (both magnitude and phase) of the uncompensated
plant.
(d) Sketch the Bode plot of the compensated design, and estimate the phase
margin. Design state feedback so that the closed-loop poles are at the
same locations as those of the design in part (b).
(e) Design an estimator for x and ˙x using the measurement of x = y, and
select the observer gain L so that the equation for ˜x has characteristic
roots with a damping ratio ζ = 0.5 and a natural frequency ωn = 8.
(e) Draw a block diagram of your combined estimator and control law, and
indicate where ˆx and ˙x appear. Draw a Bode plot for the closed-loop
system, and compare the resulting bandwidth and stability margins with
those obtained using the design of part (b).
7.53
A simpliﬁed model for the control of a ﬂexible robotic arm is shown in
Fig. 7.98, where
k/M = 900 rad/sec2,
y = output, the mass position,
u = input, the position of the end of the spring.
(a) Write the equations of motion in state-space form.
(b) Design an estimator with roots at s = −100 ± 100j.
(c) Could both state-variables of the system be estimated if only a measure-
ment of ˙y was available?
(d) Design a full-state feedback controller with roots at s = −20 ± 20j.
Figure 7.98
Simple robotic arm for
Problem 7.53
k
y
M
u

Problems
583
(e) Would it be reasonable to design a control law for the system with roots
at s = −200 ± 200j. State your reasons.
(f) Write equations for the compensator, including a command input for y.
Draw a Bode plot for the closed-loop system and give the gain and phase
margins for the design.
7.54
The linearized differential equations governing the ﬂuid-ﬂow dynamics for
the two cascaded tanks in Fig. 7.99 are
δ˙h1 + σδh1 = δu,
δ˙h2 + σδh2 = σδh1,
where
δh1 = deviation of depth in tank 1 from the nominal level,
δh2 = deviation of depth in tank 2 from the nominal level,
δu = deviation in ﬂuid in ﬂow rate to tank 1 (control).
Figure 7.99
Coupled tanks for
Problem 7.54
h1
h2
u
(a) Level Controller for Two Cascaded Tanks: Using state feedback of the
form
δu = −K1δh1 −K2δh2,
choose values of K1 and K2 that will place the closed-loop eigenvalues at
s = −2σ(1 ± j).
(b) Level Estimator for Two Cascaded Tanks: Suppose that only the deviation
in the level of tank 2 is measured (that is, y = δh2). Using this measure-
ment, design an estimator that will give continuous, smooth estimates of
the deviation in levels of tank 1 and tank 2, with estimator error poles at
−8σ(1 ± j).
(c) Estimator/Controller for Two Cascaded Tanks: Sketch a block diagram
(showing individual integrators) of the closed-loop system obtained by
combining the estimator of part (b) with the controller of part (a).
(d) Using Matlab, compute and plot the response at y to an initial offset in
δh1. Assume σ = 1 for the plot.

584
Chapter 7 State-Space Design
7.55
The lateral motions of a ship that is 100 m long, moving at a constant velocity
of 10 m/sec, are described by
⎡
⎣
˙β
˙r
˙ψ
⎤
⎦=
⎡
⎣
−0.0895
−0.286
0
−0.0439
−0.272
0
0
1
0
⎤
⎦
⎡
⎣
β
r
ψ
⎤
⎦+
⎡
⎣
0.0145
−0.0122
0
⎤
⎦δ,
where
β = side slip angle(deg),
ψ = heading angle(deg),
δ = rudder angle(deg),
r = yaw rate (see Fig. 7.100).
Figure 7.100
View of ship from above
for Problem 7.55
Ship
motion
b
c
d
(a) Determine the transfer function from δ to ψ and the characteristic roots
of the uncontrolled ship.
(b) Using complete state feedback of the form
δ = −K1β −K2r −K3(ψ −ψd),
where ψd is the desired heading, determine values of K1, K2, and K3 that
will place the closed-loop roots at s = −0.2, −0.2 ± 0.2j.
(c) Design a state estimator based on the measurement of ψ (obtained from a
gyrocompass, for example). Place the roots of the estimator error equation
at s = −0.8 and −0.8 ± 0.8j.
(d) Give the state equations and transfer function for the compensator Dc(s)
in Fig. 7.101, and plot its frequency response.

Problems
585
Figure 7.101
Ship control block
diagram for Problem
7.55
G
Dc
d
c
cd
(e) Draw the Bode plot for the closed-loop system, and compute the
corresponding gain and phase margins.
(f) Compute the feed-forward gains for a reference input, and plot the step
response of the system to a change in heading of 5◦.
Problem for Section 7.9: Introduction of the Reference Input with
the Estimator
7.56
As mentioned in footnote 11 in Section 7.9.2, a reasonable approach for select-
△
ing the feed-forward gain in Eq. (7.202) is to choose ¯N such that when r and
y are both unchanging, the DC gain from r to u is the negative of the DC gain
from y to u. Derive a formula for ¯N based on this selection rule. Show that if
the plant is Type 1, this choice is the same as that given by Eq. (7.202).
Problems for Section 7.10: Integral Control and Robust Tracking
7.57
Assume that the linearized and time-scaled equation of motion for the ball-
bearing levitation device is ¨x −x = u + w. Here w is a constant bias due to
the power ampliﬁer. Introduce integral error control, and select three control
gains K = [ K1
K2
K3 ] so that the closed-loop poles are at −1 and
−1 ± j and the steady-state error to w and to a (step) position command will
be zero. Let y = x and the reference input r = yref be a constant. Draw a
block diagram of your design showing the locations of the feedback gains Ki.
Assume that both ˙x and x can be measured. Plot the response of the closed-
loop system to a step command input and the response to a step change in the
bias input. Verify that the system is Type 1. Use Matlab (Simulink) software
to simulate the system responses.
7.58
Consider a system with state matrices
A =
 −2
1
0
−3
	
,
B =
 1
1
	
,
C = [ 1
3 ].
(a) Use feedback of the form u(t) = −Kx(t) + ¯Nr(t), where ¯N is a nonzero
scalar, to move the poles to −3 ± 3j.
(b) Choose ¯N so that if r is a constant, the system has zero steady-state error;
that is, y(∞) = r.
(c) Show that if A changes to A + δA, where δA is an arbitrary 2 × 2 matrix,
then your choice of ¯N in part(b) will no longer make y(∞) = r. Therefore,
the system is not robust under changes to the system parameters in A.
(d) The system steady-state error performance can be made robust by aug-
menting the system with an integrator and using unity feedback—that is,

586
Chapter 7 State-Space Design
by setting ·xI = r −y, where xI is the state of the integrator. To see this,
ﬁrst use state feedback of the form u = −Kx −K1xI so that the poles of
the augmented system are at −3, −2 ± j
√
3.
(e) Show that the resulting system will yield y(∞) = r no matter how the
matrices A and B are changed, as long as the closed-loop system remains
stable.
(f) For part (d), use Matlab (Simulink) software to plot the time response of
the system to a constant input. Draw Bode plots of the controller, as well
as the sensitivity function (S) and the complementary sensitivity function
(T ).
7.59
Consider a servomechanism for following the data track on a computer-disk
△
memory system. Because of various unavoidable mechanical imperfections,
the data track is not exactly a centered circle, and thus the radial servo must
follow a sinusoidal input of radian frequency ω0 (the spin rate of the disk).
The state matrices for a linearized model of such a system are
A =
 0
1
0
−1
	
,
B =
 0
1
	
,
C = [ 1
3 ].
The sinusoidal reference input satisﬁes ¨r = −ω2
0r.
(a) Let ω0 = 1, and place the poles of the error system for an internal model
design at
αc(s) = (s + 2 ± j2)(s + 1 ± j1)
and the pole of the reduced-order estimator at
αe(s) = (s + 6).
(b) Draw a block diagram of the system, and clearly show the presence of the
oscillator with frequency ω0 (the internal model) in the controller. Also
verify the presence of the blocking zeros at ±jω0.
(c) Use Matlab (Simulink) software to plot the time response of the system
to a sinusoidal input at frequency ω0 = 1.
(d) Draw a Bode plot to show how this system will respond to sinusoidal
inputs at frequencies different from but near ω0.
7.60
Compute the controller transfer function [from Y(s) to U(s)] in Example 7.38.
△
What is the prominent feature of the controller that allows tracking and
disturbance rejection?
7.61
Consider the pendulum problem with control torque Tc and disturbance
△
torque Td:
¨θ + 4θ = Tc + Td.
(Here g/l = 4.) Assume that there is a potentiometer at the pin that measures
the output angle θ, but with a constant unknown bias b. Thus the measurement
equation is y = θ + b.
(a) Take the "augmented" state vector to be
⎡
⎢⎣
θ
·
θ
w
⎤
⎥⎦,

Problems
587
where w is the input-equivalent bias. Write the system equations in state-
space form. Give values for the matrices A, B, and C.
(b) Using state-variable methods, show that the characteristic equation of the
model is s(s2 + 4) = 0.
(c) Show that w is observable if we assume that y = θ, and write the estimator
equations for
⎡
⎢⎢⎢⎣
∧
θ
∧
·
θ
∧w
⎤
⎥⎥⎥⎦.
Pick estimator gains
 ℓ1
ℓ2
ℓ3
T to place all the roots of the
estimator error characteristic equation at −10.
(d) Using full-state feedback of the estimated (controllable) state-variables,
derive a control law to place the closed-loop poles at −2 ± j2.
(e) Draw a block diagram of the complete closed-loop system (estimator,
plant, and controller) using integrator blocks.
(f) Introduce the estimated bias into the control so as to yield zero steady-
state error to the output bias b. Demonstrate the performance of your
design by plotting the response of the system to a step change in b; that
is, b changes from 0 to some constant value.
Problems for Section 7.10.3: Model-following Design
7.62
Consider the servomechanism problem where we wish to track a ramp
△
reference signal. The plant and the desired model equations are
˙x =
 0
1
0
−1
	
x +
 0
1
	
u,
y =
 1
0 
x
˙xm =
 0
1
0
0
	
xm,
ym =
 1
0 
xm.
Design a model-following control law and demonstrate its tracking perfor-
mance. Place the closed-loop poles at s = −2 ± j2.
7.63
Suppose we wish the closed-loop system to behave like a desired model, called
△
the implicit model
˙z = Amz.
We may minimize a modiﬁed LQR performance index
J =
 ∞
0

(˙y −Amy)TQ1(˙y −Amy) + uTRu

dt.
Show that this performance index is equivalent to the standard one with the
addition of a cross-weighting term between the control and the state of the
form
J =
∞

0

xT  Qx + 2uT Sx + uT Ru

dt,

588
Chapter 7 State-Space Design
where
ˆQ = (CA −AmC)TQ1(CA −AmC),
 S = BTCTQ1(CA −AmC),
 R = R + BTCTQ1CB.
7.64
Explicit Model-Following: Suppose in the LQR problem, we wish the closed-
△
loop system to behave as close as possible to a system of the form
˙z = Amz,
which represents the model of desirable dynamics. We may choose a
performance index of the form
J =
∞

0

(y −z)TQ1(y −z) + uTRu

dt.
(a) Show that this performance index can be converted to the standard one
by augmenting the states of the plant and the model and again choose the
augmented state vector, ξ =

xT
zT T and write down the system
equations to show that
J =
∞

0

ξTQ1ξ + uTRu

dt,
where
Q =

CTQ1C
−CTQ1
−Q1C
Q1
	
.
(b) Which state variables of the system are uncontrollable? Is this result
surprising?
(c) The optimal control is of the form
u = −K1x −K2z,
which means that the model's equations must be implemented as part of
the control law. Suppose we now drive the model as follows
˙z = Amz + Bpup,
where up may be the pilot input in an aircraft system. Show that
Y(s)
Up(s) = −C(sI −A + BK1)−1



Closed−loop dynamics
K2(sI −Am)−1Bp



Feedforward dynamics
.
This indicates that the feedforward dynamics may be used to improve the
transient response of the system.
(d) What are the transmission zeros of the overall system?
(e) What is a possible disadvantage of this scheme compared to the standard
LQR, that is, with no explicit model?

Problems
589
Problem for Section 7.13: Design for Systems with Pure Time Delay
7.65
Consider the system with the transfer function e−TsG(s), where
△
G(s) =
1
s(s + 1)(s + 2).
The Smith compensator for this system is given by
D′
c(s) =
Dc(s)
1 + (1 −e−sT)G(s)Dc(s).
Plot the frequency response of the compensator for T = 5 and Dc(s) = 1,
and draw a Bode plot that shows the gain and phase margins of the system.24
24This problem was given by Åström (1977).

8
Digital Control
A Perspective on Digital Control
Most of the controllers we have studied so far were described by the
Laplace transform or differential equations, which, strictly speaking,
are assumed to be built using analog electronics, such as that in
Fig. 5.31. However, most control systems today use digital comput-
ers (usually microprocessors or microcontrollers) to implement the
controllers. The intent of this chapter is to show how to implement
a control system in a digital computer. The implementation leads to
an average delay of half the sample period and to a phenomenon
called aliasing, both of which need to be addressed in the controller
design.
Analog electronics can integrate and differentiate signals. In
order for a digital computer to accomplish these tasks, the differ-
ential equations describing compensation must be approximated by
reducing them to algebraic equations involving addition, division,
and multiplication. This chapter expands on various ways to make
these approximations. The resulting design can then be tuned up, if
needed, using direct digital analysis. In some cases, it will pay to
perform the design directly in the discrete time domain.
590

8.1 Digitization
591
You should be able to design, analyze, and implement a digital
control system from the material in this chapter. However, our treat-
ment here is a limited version of a complex subject covered in more
detail in Digital Control of Dynamic Systems by Franklin et al. (1998).
Chapter Overview
In Section 8.1 we will describe the basic structure of digital control
systems and introduce the issues that arise due to the sampling. A
digital implementation based on a discrete approximation of a con-
tinuous control law can be evaluated via Simulink to determine the
degradation with respect to the continuous time case. However, to
fully understand the effect of sampling, it is useful to learn about
discrete linear analysis tools. This requires an understanding of the
z-transform, which we discuss in Section 8.2. In Section 8.3 we
build on this understanding to provide a foundation for design using
various discrete equivalents. Generally speaking, the discrete equiv-
alents work well if the sampling rate is sufﬁciently fast. In Sections 8.4
and 8.5, we will discuss hardware characteristics and sample rate
issues, both of which need to be addressed in order to implement a
digital controller.
Discrete analysis also allows us to analytically determine the
performance of the approximate discrete equivalent design without
resorting to a numerical simulation, such as Simulink, as we do in
the early examples. This analysis can then serve as a guide to tune
up the designs, which is described in Section 8.6. It is also possible
to perform a direct digital design (also called discrete design), which
provides an exact design method that is independent of whether
the sample rate is fast or not. Direct digital design is described in
Section 8.7.
8.1
Digitization
Figure 8.1(a) shows the topology of the typical continuous system that we
have been considering in previous chapters. The computation of the error
signal e and the dynamic compensation Dc(s) can all be accomplished in
a digital computer as shown in Fig. 8.1(b). The fundamental differences
between the two implementations are that the digital system operates on
samples of the sensed plant output rather than on the continuous signal and
that the continuous control provided by Dc(s), including any differentia-
tion and integration, must be generated at discrete instances in time and
approximated using numerical methods called difference equations. These
equations are recursive, algebraic calculations because computers are not
capable of performing dynamic functions directly.
Walking through the process in more detail, the analog output of the
plant sensor is sampled and converted to a digital number in the analog-
to-digital (A/D) converter. This device samples a physical variable, most

592
Chapter 8 Digital Control
Plant
©
 + 
 - 
Dc(s)
G(s)
r(t)
u(t)
y(t)
y(t)
1
Continuous controller
e(t)
e(kT)
Sensor
©
 + 
 - 
r(t)
Difference
equations
u(kT)
Plant
G(s)
y(t)
1
Sensor
u(t)
Clock
Sampler
Digital controller
T
T
y(kT)
r(kT)
y(t)
(b)
(a)
D/A and
ZOH hold
A/D
A/D Converter
Figure 8.1
Block diagrams for a basic control system: (a) continuous system; (b) with a digital computer
commonly an electrical voltage, and converts the samples of the analog
signal into a digital binary number that usually consists of 10 to 16 bits.
Conversion from the continuous analog signal y(t) to the discrete digital
samples, y(kT), occurs repeatedly at instants of time, T, apart where T is
the sample period and 1/T is the sample rate. If T is in seconds, 1/T is
Sample period
the sample rate in Hertz, denoted by fs. The sampled signal is y(kT), where
k can take on any integer value. It is often written simply as y(k). We call
this type of variable a discrete signal to distinguish it from a continuous
signal such as y(t), which changes continuously in time. A system having
both discrete and continuous signals is called a sampled data system.
We make the assumption in this book that the sample period is ﬁxed.
In practice, digital control systems sometimes have varying sample periods
and/or different periods in different feedback paths. Usually, the computer
logic includes a clock that supplies a pulse, or interrupt, every T seconds,
and theA/D converter sends a number to the computer each time the interrupt
arrives. An alternative implementation, often referred to as free running,
is to access the A/D converter after each cycle of code execution has been
completed. In the former case the sample period is precisely ﬁxed; in the
latter case the sample period is ﬁxed essentially by the length of the code,
provided that no logic branches are present, which could vary the amount
of code executed. There also may be a sampler and an A/D converter for

8.1 Digitization
593
the input command r(t), which produces the discrete r(kT), from which the
sensed output y(kT) will be subtracted to arrive at the discrete error signal
e(kT).
The continuous compensation Dc(s) is approximated by difference
equations, which are the discrete version of differential equations and can
be made to duplicate the dynamic behavior of Dc(s) accurately if the sample
rate is fast enough. The result of the difference equations is a discrete sig-
nal u(kT) at each sample instant. This signal is converted to a continuous
signal u(t) by the digital-to-analog (D/A) converter and the hold: the D/A
converter changes the digital binary number to an analog voltage, and a
zero-order hold maintains that same voltage throughout the sample period.
Zero-order hold (ZOH)
The resulting control signal u(t) is then applied to the actuator in precisely
the same manner as the continuous implementation. There are two basic
techniques for ﬁnding the difference equations for the digital controller. One
technique, called the discrete equivalent, consists of designing a continuous
Discrete equivalents
compensation Dc(s) using methods described in the previous chapters, then
approximating that Dc(s) using one of the methods described in Section 8.3.
The other technique is discrete design, described in Section 8.7. Here the
difference equations are found directly without designing Dc(s) ﬁrst.
The sample rate required depends on the closed-loop bandwidth of the
system. Generally, sample rates should be at least 20 times the bandwidth
in order to assure that the digital controller will match the performance of
Sample rate selection
the continuous controller. Slower sample rates can be used if some adjust-
ments are made in the digital controller or some performance degradation
is acceptable. Use of the discrete design method allows for a much slower
sample rate if that is desirable to minimize hardware costs; however, best
performance of a digital controller is obtained when the sample rate is greater
than 25 times the bandwidth.
It is worth noting that the single most important impact of implementing
a control system digitally is the delay associated with the hold. Because each
value of u(kT) in Fig. 8.1(b) is held constant until the next value is available
fromthecomputer, thecontinuousvalueofu(t)consistsofsteps(seeFig.8.2)
that, on average, are delayed from a ﬁt to u(kT) by T/2 as shown in the ﬁgure.
Figure 8.2
The delay due to the
hold operation
u
kT
1
2
3
4
5
6
7
8
u(kT)
Average u(t)
from digital
controller
Fit to control samples
u(t) Control from D/A

594
Chapter 8 Digital Control
If we simply incorporate this T/2 delay into a continuous analysis of the
system, an excellent prediction of the effects of sampling results for sample
rates much slower than 20 times bandwidth. We will discuss this further in
Section 8.3.5.
8.2
Dynamic Analysis of Discrete Systems
The z-transform is the mathematical tool for the analysis of linear discrete
systems. It plays the same role for discrete time systems that the Laplace
transform does for continuous time systems. This section will give a short
description of the z-transform, describe its use in analyzing discrete systems,
and shows how it relates to the Laplace transform.
8.2.1
z-Transform
In the analysis of continuous time systems, we use the Laplace transform,
which is deﬁned by
L{ f (t)} = F(s) =
 ∞
0
f (t)e−st dt,
which leads directly to the important property that (with zero initial
conditions)
L{˙f (t)} = sF(s).
(8.1)
Relation (8.1) enables us easily to ﬁnd the transfer function of a linear
continuous time system, given the differential equation description of that
system.
For discrete systems a similar procedure is available. The z-transform
z-transform
is deﬁned by
Z{ f (k)} = F(z) =
∞

k=0
f (k)z−k,
(8.2)
where f (k) is the sampled version of f (t), as shown in Fig. 8.3, and
k = 0, 1, 2, 3, . . . refers to discrete sample times t0, t1, t2, t3, . . . . This leads
directly to a property analogous to Eq. (8.1), speciﬁcally, that
Z{ f (k −1)} = z−1F(z),
(8.3)
Figure 8.3
A continuous, sampled
version of signal f
f(t)
t
f(t)
f(k)
0
T
2T
3T
T

8.2 Dynamic Analysis of Discrete Systems
595
where z−1 represents one sample delay. This relation allows us to easily ﬁnd
the transfer function of a discrete system, given the difference equations of
that system. For example, the general second-order difference equation
y(k) = −a1y(k −1) −a2y(k −2) + b0u(k) + b1u(k −1) + b2u(k −2)
can be converted from this form to the z-transform of the variables y(k),
u(k), . . . by invoking Eq. (8.3) once or twice to arrive at
Y(z) = (−a1z−1 −a2z−2)Y(z) + (b0 + b1z−1 + b2z−2)U(z).
(8.4)
Equation (8.4) then results in the discrete transfer function
Discrete transfer function
Y(z)
U(z) = b0 + b1z−1 + b2z−2
1 + a1z−1 + a2z−2 .
8.2.2
z-Transform Inversion
Table 8.1 relates simple discrete-time functions to their z-transforms and
gives the Laplace transforms for the same time functions.
Given a general z-transform, we could expand it into a sum of elemen-
tary terms using partial-fraction expansion (seeAppendixA.1.2) and ﬁnd the
resulting time series from the table. These procedures are exactly the same
as those used for continuous time systems. However, as with the continu-
ous case, most designers would use a numerical evaluation of the discrete
equations to obtain a time history rather than inverting the z-transform.
A z-transform inversion technique that has no continuous counterpart is
called long division. Given the z-transform
Y(z) = N(z)
Dd(z),
(8.5)
we simply divide the denominator into the numerator using long division.
The result is a series (perhaps with an inﬁnite number of terms) in z−1, from
z-transform inversion:
long division
which the time series can be found using Eq. (8.2).
For example, a ﬁrst-order discrete system described by the difference
equation
y(k) = αy(k −1) + u(k)
(8.6)
yields the discrete transfer function
Y(z)
U(z) =
1
1 −αz−1 .
For a unit-pulse input deﬁned by
u(0) = 1,
u(k) = 0,
k ̸= 0,
the z-transform is then
U(z) = 1,
(8.7)
so
Y(z) =
1
1 −αz−1 .
(8.8)

596
Chapter 8 Digital Control
TABLE 8.1
Laplace Transforms and z-Transforms of Simple Discrete Time Functions
No.
F(s)
f(kT)
F(z)
1
1, k = 0; 0, k ̸= 0
1
2
1, k = ko; 0, k ̸= ko
z−ko
3
1
s
1(kT)
z
z−1
4
1
s2
kT
Tz
(z−1)2
5
1
s3
1
2!(kT)2
T2
2
 z(z+1)
(z−1)3

6
1
s4
1
3! (kT)3
T3
6

z(z2+4z+1)
(z−1)4

7
1
sm
lima→0 (−1)m−1
(m−1)!

∂m−1
∂am−1 e−akT 	
lima→0 (−1)m−1
(m−1)!

∂m−1
∂am−1
z
z−e−aT
	
8
1
s+a
e−akT
z
z−e−aT
9
1
(s+a)2
kTe−akT
Tze−aT
(z−e−aT )2
10
1
(s+a)3
1
2 (kT)2e−akT
T2
2 e−aT z (z+e−aT )
(z−e−aT )3
11
1
(s+a)m
(−1)m−1
(m−1)!

∂m−1
∂am−1 e−akT 	
(−1)m−1
(m−1)!

∂m−1
∂am−1
z
z−e−aT
	
12
a
s(s+a)
1 −e−akT
z(1−e−aT )
(z−1)(z−e−aT )
13
a
s2(s+a)
1
a (akT −1 + e−akT )
z[(aT−1+e−aT )z+(1−e−aT −aTe−aT )]
a(z−1)2(z−e−aT )
14
b−a
(s+a)(s+b)
e−akT −e−bkT
(e−aT −e−bT )z
(z−e−aT )(z−e−bT )
15
s
(s+a)2
(1 −akT)e−akT
z[z−e−aT (1+aT)]
(z−e−aT )2
16
a2
s(s+a)2
1 −e−akT (1 + akT)
z[z(1−e−aT −aTe−aT )+e−2aT −e−aT +aTe−aT ]
(z−1)(z−e−aT )2
17
(b−a)s
(s+a)(s+b)
be−bkT −ae−akT
z[z(b−a)−(be−aT −ae−bT )]
(z−e−aT )(z−e−bT )
18
a
s2+a2
sin akT
z sin aT
z2−(2 cos aT)z+1
19
s
s2+a2
cos akT
z(z−cos aT)
z2−(2 cos aT)z+1
20
s+a
(s+a)2+b2
e−akT cos bkT
z(z−e−aT cos bT)
z2−2e−aT (cos bT)z+e−2aT
21
b
(s+a)2+b2
e−akT sin bkT
ze−aT sin bT
z2−2e−aT (cos bT)z+e−2aT
22
a2+b2
s[(s+a)2+b2]
1 −e−akT (cos bkT + a
b sin bkT)
z(Az+B)
(z−1)[z2−2e−aT (cos bT)z+e−2aT ]
A = 1 −e−aT cos bT −a
b e−aT sin bT
B = e−2aT + a
b e−aT sin bT −e−aT cos bT
F(s) is the Laplace transform of f (t), and F(z) is the z-transform of f (kT).
Note: f (t) = 0 for t = 0.

8.2 Dynamic Analysis of Discrete Systems
597
Therefore, to ﬁnd the time series, we divide the numerator of Eq. (8.8) by
its denominator using long division:
1 + αz−1 + α2z−2 + α3z−3 + · · ·
1 −αz−1

1
1 −αz−1
αz−1 + 0
αz−1 −α2z−2
α2z−2 + 0
α2z−2 −α3z−3
α3z−3
...
This yields the inﬁnite series
Y(z) = 1 + αz−1 + α2z−2 + α3z−3 + · · · .
(8.9)
From Eqs. (8.9) and (8.2) we see that the sampled time history of y is
y(0) = 1,
y(1) = α,
y(2) = α2,
...
...
y(k) = αk,
which could also have been easily calculated for this simple example by
directly evaluating Eq. (8.6).
8.2.3
Relationship Between s and z
For continuous time systems, we saw in Chapter 3 that certain behaviors
result from different pole locations in the s-plane: oscillatory behavior for
poles near the imaginary axis, exponential decay for poles on the negative
real axis, and unstable behavior for poles with a positive real part. A similar
kind of association would also be useful to know when designing discrete
systems. Consider the continuous signal
f (t) = e−at,
t > 0,
which has the Laplace transform
F(s) =
1
s + a,
and corresponds to a pole at s = −a. The z-transform of f (kT) is
F(z) = Z{e−akT}.
(8.10)

598
Chapter 8 Digital Control
From Table 8.1 we can see that Eq. (8.10) is equivalent to
F(z) =
z
z −e−aT ,
which corresponds to a pole at z = e−aT. This means that a pole at s = −a
in the s-plane corresponds to a pole at z = e−aT in the discrete domain. This
is true in general, which is shown in more detail in Franklin et al. (1998).
The important result is:
Relationship between
z-plane and s -plane
characteristics
The equivalent characteristics in the z-plane are related to those in
the s-plane by the expression
z = esT,
(8.11)
where T is the sample period.
Table 8.1 also includes the Laplace transforms, which demonstrates the
z = esT relationship for the roots of the denominators of the table entries for
F(s) and F(z).
Figure 8.4 shows the mapping of lines of constant damping ζ and natu-
ral frequency ωn from the s-plane to the upper half of the z-plane, using
Eq. (8.11). The mapping also has several other important features (see
Problem 8.4):
Re(z)
Im(z)
1.2
-1.0
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1.0
1.0
0.8
0.6
0.4
0.2
0
10T
9p
5T
4p
10T
7p
5T
2p
5T
3p
10T
3p
10T
p
20T
p
vn = 2T
p
vn = T
p
z = 
1.0
z = 0
s = - zvn ;jvnV1 - z2
T = Sampling period
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
z = eTs
5T
1p
Figure 8.4
Natural frequency (solid color) and damping loci (light color) in the z-plane; the portion below the
Re(z)-axis (not shown) is the mirror image of the upper half shown

8.2 Dynamic Analysis of Discrete Systems
599
1. The stability boundary (s = 0 ± jω in the s-plane) becomes the unit
circle |z| = 1 in the z-plane; inside the unit circle is stable, outside is
unstable.
2. The small vicinity around z = +1 in the z-plane is essentially identical
to the vicinity around the origin, s = 0, in the s-plane.
3. The z-plane locations give response information normalized to the
sample rate rather than to time as in the s-plane.
4. The negative real z-axis always represents a frequency of ωs/2, where
ωs = 2π/T = sample rate in radians per second when T is in seconds.
5. Vertical lines in the left half of the s-plane (the constant real part of s or
time constant) map into circles within the unit circle of the z-plane.
6. Horizontal lines in the s-plane (the constant imaginary part of s or
frequency) map into radial lines in the z-plane.
7. Frequencies greater than ωs/2, called the Nyquist frequency1, appear
in the z-plane on the top of corresponding lower frequencies because
of the circular character of the trigonometric functions imbedded in
Eq. (8.11). This overlap is called aliasing or folding. As a result it is
necessary to sample at least twice as fast as a signal's highest frequency
component in order to represent that signal with the samples. (We will
discuss aliasing in greater detail in Section 8.4.3.)
To provide insight into the correspondence between z-plane locations
and the resulting time sequence, Fig. 8.5 sketches time responses that would
result from poles at the indicated locations. This ﬁgure is the discrete
companion of Fig. 3.16.
8.2.4
Final Value Theorem
The Final Value Theorem for continuous time systems, which we discussed
in Section 3.1.6, states that
lim
t→∞x(t) = xss = lim
s→0 sX(s),
(8.12)
as long as all the poles of sX(s) are in the left half-plane (LHP). It is often
used to ﬁnd steady-state system errors and/or steady-state gains of portions of
a control system. We can obtain a similar relationship for discrete systems
by noting that a constant continuous steady-state response is denoted by
X(s) = A/s and leads to the multiplication by s in Eq. (8.12). Therefore,
because the constant steady-state response for discrete systems is
X(z) =
A
1 −z−1 ,
Final Value Theorem for
discrete systems
the discrete Final Value Theorem is
lim
k→∞x(k) = xss = lim
z→1(1 −z−1)X(z),
(8.13)
if all the poles of (1 −z−1)X(z) are inside the unit circle.
1Nyquist frequency = ωs/2

600
Chapter 8 Digital Control
Re(z)
Im(z)
-1
-0.5
1
0.5
Figure 8.5
Time sequences associated with points in the z-plane
For example, to ﬁnd the DC gain of the transfer function
G(z) = X(z)
U(z) = 0.58(1 + z)
z + 0.16 ,
we let u(k) = 1 for k ≥0, so that
U(z) =
1
1 −z−1
and
X(z) =
0.58(1 + z)
(1 −z−1)(z + 0.16).

8.3 Design Using Discrete Equivalents
601
Applying the Final Value Theorem yields
xss = lim
z→1
0.58(1 + z)
z + 0.16

= 1,
so the DC gain of G(z) is unity. To ﬁnd the DC gain of any stable transfer
DC gain
function, wesimplysubstitutez = 1andcomputetheresultinggain. Because
the DC gain of a system should not change whether represented continuously
or discretely, this calculation is an excellent aid to check that an equivalent
discrete controller matches a continuous controller. It is also a good check on
the calculations associated with determining the discrete model of a system.
8.3
Design Using Discrete Equivalents
Design by discrete equivalent, sometimes called emulation, proceeds
Stages in design using
discrete equivalents
through the following stages:
1. Design a continuous compensation as described in Chapters 1 through 7.
2. Find the discrete equivalent that, when implemented with the sys-
tem described by Fig. 8.1(b), best approximates the continuous
compensation.
3. Use discrete analysis, simulation, or experimentation to verify the
design.
Assume that we are given a continuous compensation Dc(s) as shown
in Fig. 8.1(a). We wish to ﬁnd a set of difference equations or Dd(z) for the
digital implementation of that compensation in Fig. 8.1(b). First we rephrase
the problem as one of ﬁnding the best Dd(z) in the digital implementation
shown in Fig. 8.6(a) to match the continuous system represented by Dc(s)
in Fig. 8.6(b). In this section we examine and compare four methods for
solving this problem.
It is important to remember, as stated earlier, that these methods are
approximations; there is no exact solution for all possible inputs because
Dc(s) responds to the complete time history of e(t), whereas Dd(z) has access
to only the samples e(kT). In a sense, the various digitization techniques
simply make different assumptions about what happens to e(t) between the
sample points.
Figure 8.6
Comparison of
(a) digital and;
(b) continuous
implementation
e(kT)
e(t)
T
Dd(z)
u(kT)
ZOH
u(t)
e(t)
Dc(s)
u(t)
(a)
(b)

602
Chapter 8 Digital Control
8.3.1
Tustin's Method
Tustin's method is a digitization technique that approaches the problem as
one of numerical integration. Suppose
U(s)
E(s) = Dc(s) = 1
s ,
which is integration. Therefore,
u(kT) =
 kT−T
0
e(t) dt +
 kT
kT−T
e(t) dt,
(8.14)
which can be rewritten as
u(kT) = u(kT −T) + area under e(t) over last period, T,
(8.15)
where T is the sample period.
For Tustin's method, the task at each step is to use trapezoidal integra-
tion, that is, to approximate e(t) by a straight line between the two samples
(Fig. 8.7). Writing u(kT) as u(k) and u(kT −T) as u(k −1) for short, we
convert Eq. (8.15) to
u(k) = u(k −1) + T
2 [e(k −1) + e(k)],
(8.16)
or, taking the z-transform,
U(z)
E(z) = T
2
1 + z−1
1 −z−1

=
1
2
T

1−z−1
1+z−1
	.
(8.17)
For Dc(s) = a/(s + a), applying the same integration approximation yields
Dd(z) =
a
2
T

1−z−1
1+z−1
	
+ a
.
In fact, substituting
s = 2
T
1 −z−1
1 + z−1

for every occurrence of s in any Dc(s) yields a Dd(z) based on the trape-
zoidal integration formula. This is called Tustin's method or the bilinear
Tustin's method or bilinear
approximation
approximation. Finding Tustin's approximation by hand for even a simple
transfer function requires fairly extensive algebraic manipulations. The c2d
function of Matlab expedites the process, as shown in the next example.
Figure 8.7
Trapezoidal integration
in Tustin's method
t
e(t)
kT - T
kT

8.3 Design Using Discrete Equivalents
603
EXAMPLE 8.1
Digital Controller for Example 6.15 Using Tustin's
Approximation
Determine the difference equations to implement the compensation from
Example 6.15,
Dc(s) = 10 s/2 + 1
s/10 + 1,
at a sample rate of 25 times bandwidth using Tustin's approximation. Com-
pare the performance against the continuous system done in Example 6.15.
Solution.
The bandwidth, ωBW , for Example 6.15 is approximately
10 rad/sec, as can be deduced by observing that the crossover frequency
(ωc) is approximately 5 rad/sec and noting the relationship between ωc and
ωBW in Fig. 6.50. Therefore, the sample frequency should be
ωs = 25 × ωBW = (25)(10) = 250 rad/sec.
Normally, when a frequency is indicated with the units of cycles per second,
or Hz, it is given the symbol f , so with this convention, we have
fs = ωs/(2π) ≃40 Hz,
(8.18)
and the sample period is then
T = 1/fs = 1/40 = 0.025 sec.
The discrete compensation is computed by the Matlab statement
s=tf('s');
sysDc = tf(10*(s/2 + 1)/(s/10 + 1);
T = 0.025;
sysDd = c2d(sysDc,T,'tustin')
which produces
Dd(z) = 45.56 −43.33 z−1
1 −0.7778 z−1 .
(8.19)
We can then write the difference equation by inspecting Eq. (8.19) to get
u(k) = 0.7778u(k −1) + 45.56e(k) −43.33e(k −1),
or,
u(k) = 0.7778u(k −1) + 45.56[e(k) −0.9510e(k −1)].
(8.20)
Equation (8.20) computes the new value of the control, u(k), given the past
value of the control, u(k−1), and the new and past values of the error signal,
e(k) and e(k −1).
In principle, the difference equation is evaluated initially with k = 0,
then k = 1, 2, 3, . . . However, there is usually no requirement that values
for all times be saved in memory. Therefore, the computer need only have

604
Chapter 8 Digital Control
variables deﬁned for the current and past values. The instructions to the
computer to implement the feedback loop in Fig. 8.1(b) with the difference
equation from Eq. (8.20) would call for a continual looping through the
following code:
READ A/D: y, r
e = r −y
u = 0.7778up + 45.56[e −0.9510ep]
OUTPUT D/A: u
up = u (where up will be the past value for the next loop through)
ep = e
go back to READ when T sec have elapsed since last READ.
To evaluate this discrete controller, we use Simulink to compare the two
implementations. Figure 8.8 shows the block diagram for the comparison,
The results of the step responses are shown in Fig. 8.9. Note that sampling at
Figure 8.8
Simulink block diagram
for transient response
of lead-compensation
designs with discrete
and analog
implementations
©
-
+
10
0.1s + 1
0.5s + 1
s
1
s + 1
1
Lead
control
Step
Slider
Kc
Tau 1
Tau 2
©
-
+
10
z - 0.78
4.6z - 4.3
s
1
s + 1
1
Discrete lead
control
Slider
Kd
Tau 1
Tau 2
Ramp
Mux 1
Mux
Output
Figure 8.9
Comparison between
the digital (using
Tustin's) and the
continuous controller
step response with a
sample rate 25 times
bandwidth:
(a) position; (b) control
signal
1
2
1.8
1.6
1.4
1.2
0
0.2
0.4
0.6
0.8
Time (sec)
(b)
-20
-10
0
10
20
30
40
50
Control, u
1
2
1.8
1.6
1.4
1.2
0
0.2
0.4
0.6
0.8
Time (sec)
(a)
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Position, y
Continuous controller
Continuous controller
Digital controller
Digital controller

8.3 Design Using Discrete Equivalents
605
25 times bandwidth causes the digital implementation to match the contin-
uous one quite well. Generally speaking, if you want to match a continuous
system with a digital approximation of the continuous compensation, a con-
servative approach is to sample at approximately 25 times bandwidth or
faster.
8.3.2
Zero-Order Hold (ZOH) Method
Tustin'smethodessentiallyassumedthattheinputtothecontrollervariedlin-
early between the past sample rate and the current one, as shown in Fig. 8.7.
Another assumption is to assume that the input to the controller remains
constant throughout the sample period. In other words, for purposes of this
design approximation, we assume that the Dc(s) in Fig. 8.1(a) is preceded
by a ZOH whose function is to accept the value of e at sample time, k,
and hold that value constant until k + 1. This is not the actual case; rather,
the only ZOH in the system is the one preceding the plant, G(s), as shown
in Fig. 8.1(b). With this assumption, there is an exact discrete equivalent
for this system because the ZOH precisely describes what happens between
samples of e and the output u is dependent only on the input at the sample
times e(k).
For a controller described by Dc(s) preceded by a ZOH, given an input,
e(k), the system is essentially responding to a positive step at sample time,
k, followed by a negative step one cycle delayed. In other words, one input
sample produces a square pulse of height, e, that lasts for one sample period.
For a constant positive step input, e, at time k, E(s) = e(k)/s, so the result
would be,
Dd(z) = Z
Dc(s)
s

,
(8.21)
where Z{ F(s)} is the z-transform of the sampled time series whose Laplace
transform is the expression for F(s), that is, it is given on the same line in
Table8.1. Furthermore, aconstantnegativestep, onecycledelayed, wouldbe
ZOH approximation
Dd(z) = z−1Z
Dc(s)
s

.
(8.22)
Therefore, the discrete transfer function for the square pulse is
ZOH transfer function
Dd(z) = (1 −z−1)Z
Dc(s)
s

.
(8.23)
For a more complete derivation, see Chapter 4 in Franklin et al. (1998).
Equation (8.23) provides us with a discrete approximation to Dc(s) and
determines the difference equations to be used in Fig. 8.1(b).

606
Chapter 8 Digital Control
EXAMPLE 8.2
Digital Controller for Example 6.15 Using the ZOH
Approximation
Again, determine the difference equations to implement the compensation
from Example 6.15,
Dc(s) = 10 s/2 + 1
s/10 + 1,
at a sample rate of 25 times bandwidth using the ZOH approximation. Com-
pare the performance against the continuous system done in Example 6.15
and with the results of Example 8.1.
Solution. The bandwidth is the same as the previous example, so the sample
period is unchanged
T = 0.025 sec.
The discrete compensation is computed by the Matlab statement, but this
time we use the ZOH version of c2d
s = tf('s');
sysDc =10*(s/2 + 1)/(s/10 + 1);
T = 0.025;
sysDd = c2d(sysDc,T,'zoh');
which produces
Dd(z) = (50 −47.79 z−1)
1 −0.7788 z−1 .
(8.24)
We can then write the difference equation by inspecting Eq. (8.24) to get
u(k) = 0.7788u(k −1) + 50e(k) −47.79e(k −1),
or,
u(k) = 0.7788u(k −1) + 50[e(k) −0.9558e(k −1)].
(8.25)
Note the similarity between Eq. (8.25) and Eq. (8.20). There are very small
differences in the zero and pole locations and the overall gain. The difference
equations to be implemented in the digital controller are:
READ A/D: y, r
e = r −y
u = 0.7788up + 50[e −0.9510ep]
OUTPUT D/A: u
up = u (where up will be the past value for the next loop through)
ep = e
go back to READ when T sec have elapsed since last READ.
Use of Simulink to compare the two implementations, in a manner
similar to that used for Example 8.1, yields the step responses shown in
Fig. 8.10. Note, again, that sampling at 25 times bandwidth again causes the

8.3 Design Using Discrete Equivalents
607
Figure 8.10
Comparison between
the digital (using ZOH
approximation) and the
continuous controller
step response with a
sample rate 25 times
bandwidth:
(a) position; (b) control
Control, u
Time (sec)
1.5
1
0.5
00
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Position, y
Time (sec)
60
40
20
0
-200
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Digital controller
Digital controller
Continuous controller
Continuous controller
digital implementation to match the continuous one quite well, although for
this case, use of the Tustin approximation matched slightly better than the
ZOHapproximation. Historically, theadvantageoftheZOHmethodwasthat
it involved simpler algebraic manipulations; however, with the availability of
control software such as Matlab, that advantage is diminished.A comparison
of all the methods is contained in Section 8.3.5.
8.3.3
Matched Pole-Zero (MPZ) Method
Another digitization method, called the matched pole-zero (MPZ) method,
is found by extrapolating from the relationship between the s- and z-planes
stated in Eq. (8.11). If we take the z-transform of a sampled function x(k),
the poles of X(z) are related to the poles of X(s) according to the relation
z = esT. The MPZ technique applies the relation z = esT to the poles
and zeros of a transfer function, even though, strictly speaking, this rela-
tion applies neither to transfer functions nor even to the zeros of a time
sequence. Like all transfer-function digitization methods, the MPZ method
is an approximation; here the approximation is motivated partly by the fact
that z = esT is the correct s to z transformation for the poles of the transform
of a time sequence and partly by the minimal amount of algebra required
to determine the digitized transfer function by hand, in the event that one
wanted to check the computer calculations.
Because physical systems often have more poles than zeros, it is useful
to arbitrarily add zeros at z = −1, resulting in a 1 + z−1 term in Dd(z).
This causes an averaging of the current and past input values, as in Tustin's
method. We select the low-frequency gain of Dd(z) so that it equals that of
Dc(s).

608
Chapter 8 Digital Control
MPZ Method Summary
1. Map poles and zeros according to the relation z = esT.
2. If the numerator is of lower order than the denominator, add powers of
(z + 1) to the numerator until numerator and denominator are of equal
order.
3. Set the DC or low-frequency gain of Dd(z) equal to that of Dc(s).
For example, the MPZ approximation of
Dc(s) = Kc
s + a
s + b
(8.26)
is
Dd(z) = Kd
z −e−aT
z −e−bT ,
(8.27)
where Kd is found by causing the DC gain of Dd(z) to equal the DC gain of
Dc(s) using the continuous and discrete versions of the FinalValue Theorem.
The result is
Kc
a
b = Kd
1 −e−aT
1 −e−bT
or
Kd = Kc
a
b

1 −e−bT
1 −e−aT

.
(8.28)
For a Dc(s) with a higher-order denominator, Step 2 in the method calls
for adding the (z + 1) term. For example,
Dc(s) = Kc
s + a
s(s + b) ⇒Dd(z) = Kd
(z + 1)(z −e−aT)
(z −1)(z −e−bT),
(8.29)
however, because the DC gains of these transfer functions are inﬁnite, it
is necessary to match the low frequency gains instead. This can be accom-
plished by deleting the pure integral terms, that is, the poles at s = 0 and
z = 1, and proceeding as before to match the DC gains of the remaining
transfer functions for the two cases. Doing this, we ﬁnd that
Kd = Kc
a
2b

1 −e−bT
1 −e−aT

.
(8.30)
In the digitization methods described so far, the same power of z appears
in the numerator and denominator of Dd(z). This implies that the difference
equation output at time k will require a sample of the input at time k. For
example, the Dd(z) in Eq. (8.27) can be written
U(z)
E(z) = Dd(z) = Kd
1 −αz−1
1 −βz−1 ,
(8.31)
where α = e−aT and β = e−bT. By inspection we can see that Eq. (8.31)
results in the difference equation
u(k) = βu(k −1) + Kd[e(k) −αe(k −1)].
(8.32)

8.3 Design Using Discrete Equivalents
609
EXAMPLE 8.3
Design of a Space Station Attitude Digital Controller
Using the Matched Pole-Zero Approximation
A very simpliﬁed model of the space station attitude control dynamics has
the plant transfer function
G(s) = 1
s2 .
Design a digital controller to have a closed-loop natural frequency ωn ∼=
0.3 rad/sec and a damping ratio ζ = 0.7.
Solution. The ﬁrst step is to ﬁnd the proper Dc(s) for the system deﬁned in
Fig. 8.11. After some trial and error, we ﬁnd that the speciﬁcations can be
met by the lead compensation
Dc(s) = 0.81s + 0.2
s + 2 .
(8.33)
The root locus in Fig. 8.12 veriﬁes the appropriateness of using
Eq. (8.33).
To digitize this Dc(s), we ﬁrst need to select a sample rate. For a system
with ωn = 0.3 rad/sec, the bandwidth will also be about 0.3 rad/sec. Let's
try a sample rate slightly slower than the previous examples to obtain a sense
of the effect. So let's use approximately 20 times ωn. Thus
ωs = 0.3 × 20 = 6 rad/sec.
A sample rate of 6 rad/sec is about 1 Hertz; therefore, the sample period
shouldbeT = 1sec. TheMPZdigitizationofEq.(8.33), givenbyEqs.(8.27)
and (8.28), yields
Dd(z) = 0.389 z −0.82
z −0.135
= 0.389 −0.319z−1
1 −0.135z−1
.
(8.34)
Figure 8.11
Continuous-design
deﬁnition for
Example 8.3
©
 + 
 - 
R
Dc(s)
s2
1
Y
E
U
Figure 8.12
s-Plane locus with
respect to K
Re(s)
Im(s)
-0.2
-0.2
-2
Selected roots
(Kc = 0.81)

610
Chapter 8 Digital Control
Inspection of Eq. (8.34) gives us the difference equation
u(k) = 0.135u(k −1) + 0.389e(k) −0.319e(k −1),
(8.35)
where
e(k) = r(k) −y(k),
and this completes the digital algorithm design. The complete digital system
is shown in Fig. 8.13.
Thelaststepinthedesignprocessistoverifythedesignbyimplementing
it on the computer. Figure 8.14 compares the step response of the digital
system using T = 1 sec (20×ωBW ) with the step response of the continuous
compensation. Note that there is greater overshoot in the digital system,
which suggests a decrease in the damping due to the digital implementation.
The average T/2 delay shown in Fig. 8.2 is the cause of the reduced damping.
For a better match to the continuous system, it may be prudent to increase
the sample rate. Figure 8.14 also shows the response with sampling that
is twice as fast (40 × ωBW ) and it can be seen that it comes much closer
to the continuous system. Note that the discrete compensation needs to be
recalculated for this faster sample rate according to Eqs. (8.27) and (8.28).
Figure 8.13
A digital control system
that is equivalent to
Fig. 8.11
r(k)
u(t)
u(k)
y(k)
ZOH
s2
1
Sampler (T = 1 sec)
and analog-to-digital
conversion
Plant
Computer
Eq.
(8.35)
y(t)
Figure 8.14
Step responses of the
continuous and digital
implementations using
the MPZ equivalent with
slower sampling
Time (sec)
0
5
10
15
20
25
30
Plant output
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
Continuous design
Discrete equivalent design, T = 1 sec
Discrete equivalent design, T = 0.5 sec

8.3 Design Using Discrete Equivalents
611
All the methods so far required knowing e(k) in order to compute u(k);
however, it is impossible to sample e(k), compute u(k), and then output u(k)
all in zero elapsed time; therefore, Eq. (8.35) is impossible to implement
precisely. However, if the equation is simple enough and/or the computer is
fast enough, a slight computational delay between the e read and the u output
will have a negligible effect on the actual response of the system compared
with that expected from the original design.A rule of thumb would be to keep
the computational delay on the order of 1/10 of T. The real-time code and
hardware can be structured so that this delay is minimized by making sure
that computations between READ A/D and OUTPUT D/A are minimized
and that u is sent to the ZOH immediately after its calculation.
8.3.4
Modiﬁed Matched Pole-Zero (MMPZ) Method
The Dd(z) in Eq. (8.29) would also result in u(k) being dependent on e(k),
the input at the same time point. If the structure of the computer hardware
prohibits minimizing the time between the READ and the OUTPUT, or if the
computations are particularly lengthy, it may be desirable to derive a Dd(z)
that has one less power of z in the numerator than in the denominator; hence,
the computer output u(k) would require only input from the previous time,
that is, e(k −1). To do this, we simply modify Step 2 in the matched pole-
zero procedure so that the numerator is of lower order than the denominator
by 1. For example, if
Dc(s) = Kc
s + a
s(s + b),
we skip Step 2 to get
Dd(z) = Kd
z −e−aT
(z −1)(z −e−bT),
(8.36)
Kd = Kc
a
b

1 −e−bT
1 −e−aT

.
To ﬁnd the difference equation, we multiply the top and bottom of Eq. (8.36)
by z−2 to obtain
Dd(z) = Kd
z−1(1 −e−aTz−1)
1 −z−1(1 + e−bT) + z−2e−bT .
(8.37)
By inspecting Eq. (8.37) we can see that the difference equation is
u(k) = (1 + e−bT)u(k −1) −e−bTu(k −2) + Kd[e(k −1) −e−aTe(k −2)].
In this equation an entire sample period is available to perform the
calculation and to output u(k), because it depends only on e(k −1). A
discrete analysis of this controller would therefore more accurately explain
the behavior of the actual system. However, because this controller is using
data that are one cycle old, it will typically not perform as well as the MPZ
controller in terms of the deviations of the desired system output in the
presence of random disturbances.

612
Chapter 8 Digital Control
8.3.5
Comparison of Digital Approximation Methods
A numerical comparison of the magnitude of the frequency response for a
ﬁrst-order lag,
Dc(s) =
5
s + 5,
is made in Fig. 8.15 for the four approximation techniques at two different
sample rates. The results of the Dd(z) computations used in Fig. 8.15 are
shown in Table 8.2. Note that the MMPZ and ZOH methods are identical in
this example; however, this will not always be the case when there are zeros
and poles. The MPZ andTustin methods also appear to be identical; however,
there are minor differences as you can see from their Dd(z) in Table 8.2. The
major difference between the four approximations is that the two with the
(z + 1) zeros yield a deep notch at ωs/2, which is often a desirable feature.
Figure 8.15 shows that all the approximations are quite good at frequen-
cies below about 1/5 the sample rate, or ωs
5 . If ωs/5 is sufﬁciently faster than
the ﬁlter break-point frequency—that is, if the sampling is fast enough—the
break-point characteristics of the lag will be accurately reproduced. Tustin's
technique and the MPZ method show a notch at ωs/2 because of their zero at
v (rad/sec)
T    =        sec
vs _ 100 rad/sec
vs _ 20 rad/sec
ƒDd(z)ƒ
1
ƒDd(z)ƒ
1
v (rad/sec)
0.5
0.1
0.1
MMPZ
Tustin's,
MPZ
Dc(s)
Dc(s)
MMPZ
Tustin's,
MPZ
5
50
0.5
5
50
115
T    =        sec
1 3
Figure 8.15
A comparison of the frequency response of 3 discrete approximations at two sample rates
TABLE 8.2
Comparing Digital Approximations of Dd(z) for Dc(s) = 5/(s + 5)
ωs
Method
150 rad/sec
750 rad/sec
Matched pole-zero (MPZ)
0.0945
z + 1
z −0.811
0.1715
z + 1
z −0.657
Modiﬁed MPZ (MMPZ)
0.189
1
z −0.811
0.343
1
z −0.657
Tustin's
0.0950
z + 1
z −0.810
0.1735
z + 1
z −0.653
ZOH
0.189
1
z −0.811
0.343
1
z −0.657

8.4 Hardware Characteristics
613
z = −1 from the z + 1 term. Other than the large difference in the vicinity
approaching ωs/2 and higher, which is typically outside the range of interest,
the four methods have similar accuracies.
8.3.6
Applicability Limits of the Discrete Equivalent
Design Method
If we performed an exact discrete analysis or a simulation of a system and
determined the digitization for a wide range of sample rates, the system
could often be unstable for rates slower than approximately 5ωBW, and the
damping would be degraded signiﬁcantly for rates slower than about 10ωBW.
At sample rates ⪆20ωBW, design by discrete equivalents yields reasonable
results, and at sample rates of 25 times the bandwidth or higher, discrete
equivalents can be used with conﬁdence.
As shown by Fig. 8.2, the errors partly come about because the technique
ignores the lagging effect of the ZOH that precedes the plant which, on the
ZOH transfer function
average, is T/2. The other source of error is the behavior of the input signal
between sample times. A method to account for the T/2 delay is to include
an approximation of the delay due to the ZOH:2
GZOH(s) =
2/T
s + 2/T .
(8.38)
Once an initial design is carried out and the sampling rate has been selected,
we could improve on our discrete design by inserting Eq. (8.38) into the
original plant model and adjusting Dc(s) so that a satisfactory response in
the presence of the approximate sampling delay is achieved. Therefore, we
see that use of Eq. (8.38) partially alleviates the approximate nature of using
discrete equivalents.
For sample rates slower than about 10ωBW it is advisable to analyze the
entire system using an exact discrete analysis. If a discrete analysis shows
an unacceptable degradation of performance due to the sampling, the design
can then be reﬁned using exact discrete methods. We cover this approach in
Section 8.6.
8.4
Hardware Characteristics
A digital control system includes several unique components not found in
continuous control systems: an A/D converter is a device to sample the
continuous signal voltage from the sensor and to convert that signal to
a digital word; a D/A converter is a device to convert the digital word
from the computer to an analog voltage, an anti-alias preﬁlter is an analog
device designed to reduce the effects of aliasing, and the computer is the
device where the compensation Dd(z) is programmed and the calculations
are carried out. This section provides a brief description of each of these.
2This is the lowest order Padé approximate to a pure time delay. See Appendix W5.6.3.

614
Chapter 8 Digital Control
8.4.1
Analog-to-Digital (A/D) Converters
As discussed in Section 8.1,A/D converters are devices that convert a voltage
level from a sensor to a digital word usable by the computer. At the most
basic level, all digital words are binary numbers consisting of many bits
that are set to either 1 or 0. Therefore, the task of the A/D converter at each
sample time is to convert a voltage level to the correct bit pattern and often
to hold that pattern until the next sample time.
Of the many A/D conversion techniques that exist, the most common
are based on counting schemes or a successive-approximation technique. In
counting methods the input voltage may be converted to a train of pulses
whose frequency is proportional to the voltage level. The pulses are then
counted over a ﬁxed period using a binary counter, thus resulting in a binary
representation of the voltage level. A variation on this scheme is to start the
count simultaneously with a voltage that is linear in time and to stop the
count when the voltage reaches the magnitude of the input voltage to be
converted.
The successive-approximation technique tends to be much faster than
thecountingmethods. Itisbasedonsuccessivelycomparingtheinputvoltage
to reference levels representing the various bits in the digital word. The input
voltage is ﬁrst compared with a reference value that is half the maximum. If
theinputvoltageisgreater, themostsigniﬁcantbitisset, andthesignalisthen
compared with a reference level that is 3/4 the maximum to determine the
next bit, and so on. One clock cycle is required to set each bit, so an n-bit
converter would require n cycles. At the same clock rate a counter-based
converter might require as many as 2n cycles, which would usually be much
slower.
With either technique, the greater the number of bits, the longer it will
take to perform the conversion. The price of A/D converters generally goes
up with both speed and bit size. In 2013, a 12-bit (resolution of 0.025%)
converter with a high performance capability of 170 million samples per
sec (170 MHz) sold for approximately $20 while a 12-bit converter with a
good performance capability of 1 MHz sold for approximately $2. Also now
becoming common are 16-bit A/D converters (0.0015% resolution). A 16
bit A/D with 500 KHz capability sold for approximately $8 in 2013. The
performance has been improving considerably every year and these numbers
change substantially with each edition of this book!
If more than one channel of data needs to be sampled and converted to
digital words, it is usually accomplished using a multiplexer rather than by
multipleA/D converters. The multiplexer sequentially connects the converter
into the channel being sampled.
8.4.2
Digital-to-Analog Converters
D/A converters, as mentioned in Section 8.1, are used to convert the digital
words from the computer to a voltage level and are sometimes referred to as
Sample and Hold devices. They provide analog outputs from a computer

8.4 Hardware Characteristics
615
for driving actuators or perhaps a recording device such as an oscilloscope or
strip-chart recorder. The basic idea behind their operation is that the binary
bits cause switches (electronic gates) to open or close, thus routing the elec-
triccurrentthroughanappropriatenetworkofresistorstogeneratethecorrect
voltage level. Because no counting or iteration is required for such convert-
ers, they tend to be much faster than A/D converters. In fact, A/D converters
that use the successive-approximation method of conversion include D/A
converters as components. The price of D/A converters is comparable to
A/D converters, but usually somewhat lower.
8.4.3
Anti-Alias Preﬁlters
An analog anti-alias preﬁlter is often placed between the analog sensor
and the A/D converter. Its function is to reduce the higher-frequency noise
components in the analog signal in order to prevent aliasing, that is, having
Analog preﬁlters reduce
aliasing
the noise be modulated to a lower frequency by the sampling process.
An example of aliasing is shown in Fig. 8.16, where a 60 Hertz oscil-
latory signal is being sampled at 50 Hertz. The ﬁgure shows the result from
the samples as a 10 Hertz signal and also shows the mechanism by which the
frequency of the signal is aliased from 60 to 10 Hertz. Aliasing will occur
any time the sample rate is not at least twice as fast as any of the frequencies
in the signal being sampled. Therefore, to prevent aliasing of a 60 Hertz
signal, the sample rate would have to be faster than 120 Hertz, clearly much
higher than the 50 Hertz rate in the ﬁgure.
Aliasing can be explained from the sampling theorem of Nyquist and
Nyquist-Shannon
sampling theorem
Shannon. Their theorem basically states that, for the signal to be accu-
rately reconstructed from the samples, it must have no frequency component
greater than half the sample rate (ωs/2). Another result of their theorem is
that the highest frequency that can be unambiguously represented by discrete
samples is the Nyquist rate of ωs/2, an idea we discussed in Section 8.2.3.
The result of aliasing on a digital control system can be substantial.
In a continuous system, noise components with a frequency much higher
than the control-system bandwidth normally have a small effect because the
system will not respond at the high frequency. However, in a digital system,
Figure 8.16
An example of aliasing
Time (sec)
0.02
0.08
0.1
50-Hertz samples
Aliased signal
from samples
60-Hertz signal

616
Chapter 8 Digital Control
the frequency of the noise can be aliased down to the vicinity of, or less than,
the system bandwidth so that the closed-loop system would respond to the
noise. Thus, the noise in a poorly designed digitally controlled system could
have a substantially greater effect than if the control had been implemented
using analog electronics.
The solution is to place an analog preﬁlter before the sampler. In many
cases a simple ﬁrst-order low-pass ﬁlter will do—that is,
Hp(s) =
a
s + a,
(8.39)
where the break point a is selected to be lower than ωs/2 so that any noise
present with frequencies greater than ωs/2 is attenuated by the preﬁlter. The
lower the break-point frequency selected, the more the noise above ωs/2 is
attenuated. For example, if ωs is chosen to be 25ωBW, the anti-aliasing ﬁlter
breakpoint, a, should be selected lower than ωs/2, so that a = 10ωBW would
be a reasonable choice.A breakpoiont 10 × higher than the bandwidth should
not affect the stability or performance of the closed-loop system; however,
too low a break point may force the designer to reduce the control system's
bandwidth or add more phase lead to the compensation. The preﬁlter does not
completely eliminate the aliasing; however, it does attenuate the magnitude
of the high frequency noise that will be aliased. Through judicious choice
of the preﬁlter break point and the sample rate, the designer has the ability
to reduce the magnitude of the aliased noise to some acceptable level.
8.4.4
The Computer
The computer is the unit that does all the computations. Most digital con-
trollers used today are built around a microcontroller that contains both a
microprocessor and most of the other functions needed, including the A/D
and D/A conversion. For development purposes in a laboratory, a digital
controller could be a desktop-sized workstation or a PC. The relatively low
cost of microprocessor technology has accounted for the large increase in
the use of digital control systems, which started in the 1980s and continues
into the 2010s.
The computer consists of a central processor unit (CPU), which does
the computations and provides the system logic; a clock to synchronize
the system; memory modules for data and instruction storage; and a power
supply to provide the various required voltages. The memory modules come
in three basic varieties:
1. Read-only memory (ROM) is the least expensive, but after its manu-
facture its contents cannot be changed. Most of the memory in products
manufactured in quantity is ROM. It retains its stored values when power
is removed.
2. Random-access memory (RAM) is the most expensive, but its values
can be changed by the CPU. It is required only to store the values that

8.5 Sample-Rate Selection
617
will be changed during the control process and typically represents only
a small fraction of the total memory of a developed product. It loses the
values in memory when power is removed.
3. Programmable read-only memory (EPROM) or Flash Memory is
similar to a ROM, but whose values can be changed. It retains its stored
values when power is removed but values are changed at a slower speed
than RAM. The readout speed is about the same as ROM. Flash memory
is becoming very common and is used in cameras, USB memory sticks,
smart phones, and so on.
Microprocessors for control applications generally come with a digital
word size of 8, 16, or 32 bits, although some have been available with 12 bits.
Larger word sizes give better accuracy, but at an increase in cost. The most
economical solution is often to use an 8-bit microprocessor, but to use two
digital words to store one value (double precision) in the areas of the con-
troller that are critical to the system accuracy. Many digital control systems
use computers originally designed for digital signal-processing applications,
so-called DSP chips, which give the control designer full freedom to imple-
ment computationally advanced control schemes at high sample rates on
the order of MHz. For even higher sample rates, Field Programmable Gate
Arrays are sometimes preferred.
8.5
Sample-Rate Selection
The selection of the best sample rate for a digital control system is the result
of a compromise of many factors. Sampling too fast can cause a loss of
accuracy while the basic motivation for lowering the sample rate ωs is cost,
both of the digital hardware and the sensors.A decrease in sample rate means
more time is available for the control calculations; hence slower computers
can be used for a given control function or more control capability can be
achieved from a given computer. Either way, the cost per function is lowered.
For systems withA/D converters, less demand on conversion speed will also
lower cost. These economic arguments indicate that the best engineering
choice is the slowest possible sample rate that still meets all performance
speciﬁcations.
There are several factors that could provide a lower limit on the
acceptable sample rate:
1. Tracking effectiveness as measured by closed-loop bandwidth or by
time-response requirements, such as rise time and settling time;
2. Regulation effectiveness as measured by the error response to random
plant disturbances; and
3. Error due to measurement noise and the associated preﬁlter.
A ﬁctitious limit occurs when using discrete equivalents. The inherent
approximation in the method may give rise to decreased performance or even
system instabilities as the sample rate is lowered. This can lead the designer

618
Chapter 8 Digital Control
to conclude that a faster sample rate is required. However, there are two
solutions:
1. Sample faster and
2. Recognizethattheapproximationsareinvalidandreﬁnethedesignusing
disrete analysis design methods described in the subsequent sections.
The ease of designing digital control systems with fast sample rates and
the low cost of very capable computers often drives the designer to select
a sample rate that is 40 × ωBW or higher. For computers with ﬁxed-point
arithmetic, very fast sample rates can lead to multiplication errors that have
the potential to produce signiﬁcant offsets or limit cycles in the control (see
Franklin et al., 1998).
8.5.1
Tracking Effectiveness
An absolute lower bound on the sample rate is set by a speciﬁcation to
track a command input with a certain frequency (the system bandwidth).
The sampling theorem (see Section 8.4.3 and Franklin et al., 1998) states
that in order to reconstruct an unknown, band-limited, continuous signal
from samples of that signal, we must sample at least twice as fast as the
highest frequency contained in the signal. Therefore, in order for a closed-
loop system to track an input at a certain frequency, it must have a sample
rate twice as fast; that is, ωs must be at least twice the system bandwidth
(ωs ⇒2 × ωBW ). We also saw from the results of mapping the s-plane into
the z-plane (z = esT) that the highest frequency that can be represented by
a discrete system is ωs/2, which supports the conclusion of the theorem.
For systems with resonances, it is sometimes required to sample fast
enough to provide stabilization of the resonant modes. This topic is covered
in Franklin et al. (1986).
The closed-loop-bandwidth limitation provides the fundamental lower
bound on the sample rate. In practice, however, the theoretical lower bound
of sampling at twice the bandwidth of the reference input signal would not
be judged sufﬁcient in terms of the quality of the desired time responses. For
a system with a rise time on the order of 1 sec (thus yielding a closed-loop
bandwidth on the order of 0.5 Hertz), it is reasonable to insist on a sampling
rate of 10 to 20 Hertz, which is a factor of 20 to 40 times ωBW . The purposes
of choosing a sample rate much greater than the bandwidth are to reduce
the delay between a command and the system response to the command and
also to smooth the system output to the control steps coming out of the ZOH.
8.5.2
Disturbance Rejection
Disturbance rejection is an important—if not the most important—aspect of
any control system. Disturbances enter a system with various frequency char-
acteristics ranging from steps to white noise. For the purpose of sample-rate
selection, the higher-frequency random disturbances are the most inﬂuential.

8.5 Sample-Rate Selection
619
However, the impact of high frequency disturbances is affected by the anti-
aliasing ﬁlter as well as the sample rate. For a very high frequency noise, it
would be foolish to sample fast enough to attenutate the disturbance without
the use of a preﬁlter for reasons discussed in the next subsection.
Assuming the preﬁlter is well designed so that there is little or no aliasing
of noise with a frequency greater than ωs/2, the sample rate selection pretty
much follows the same rule of thumb as Tracking Effectiveness; that is,
sample rates on the order of 25 times ωBW or higher are typical.
8.5.3
Effect of Anti-Alias Preﬁlter
Digital control systems with analog sensors typically include an ana-
log anti-alias preﬁlter between the sensor and the sampler as described
in Section 8.4.3. The preﬁlters are low-pass, and the simplest transfer
function is
Hp(s) =
a
s + a.
(8.40)
so that the noise above the preﬁlter break point a is attenuated. The goal is to
provide enough attenuation at half the sample rate (ωs/2) such that the noise
above ωs/2, when aliased into lower frequencies by the sampler, will not be
detrimental to control system performance.
A conservative design procedure is to select the preﬁlter break point
to be sufﬁciently higher than the system bandwidth that the phase lag from
the preﬁlter does not signiﬁcantly alter the system stability. This procedure
allows the preﬁlter to be ignored in the basic control system design. For
example, selecting a = 10ωBW would be a reasonable choice. Furthermore,
for a good reduction in the high-frequency noise at ωs/2, we might choose a
sample rate that is about 10 times higher than the preﬁlter break point. This
selection would reduce the high frequency noise above ωs/2 that would be
aliased into a lower frequency by at least a factor of 5. The result of this
conservative preﬁlter design example is that the sample rate would be on the
order 100 times faster than the system bandwidth! Using this sort of design
procedure, the preﬁlter inﬂuence will likely provide the lower bound on the
selection of the sample rate. This kind of process was carried out in past
years when one group of a company designed the analog control system,
then gave the design to the digital group to put it in the computer. In fact,
this is still the current practice in some industries where the performance of
the control system is critical.
An alternative design procedure is to allow signiﬁcant phase lag from
the preﬁlter at the system bandwidth. This requires us to include the analog
preﬁlter characteristics in the plant model when carrying out the control
design and requires an integrated design effort between the analog and digital
design groups, or better yet, one group to do it all. It allows the use of lower
sample rates, but at the possible expense of increased complexity in the
compensation because additional phase lead must be provided to counteract

620
Chapter 8 Digital Control
the preﬁlter's phase lag. If this procedure is used and low preﬁlter break
points are allowed, the effect of aliased sensor noise is small, and the preﬁlter
essentially has no effect on the sample rate.
It may seem counterintuitive that placing a lag (the analog preﬁlter) in
one portion of the controller and a counteracting lead [extra lead in Dd(z)] in
another portion of the controller provides a net positive effect on the overall
system. The net gain is a result of the fact that the lag is in the analog part
of the system where high frequencies can exist. The counteracting lead is
in the digital part of the system where frequencies above the Nyquist rate
do not exist. The result is a reduction in the high frequencies before the
sampling which are not reampliﬁed by the counteracting digital lead, thus
producing net reduction in high frequency disturbances. Furthermore, these
high frequencies are particularly insidious with a digital controller because
of the aliasing that would result from the sampling.
8.5.4
Asynchronous Sampling
As noted in the previous paragraphs, divorcing the preﬁlter design from
the control-law design may require using a faster sample rate than other-
wise. This same result may show up in other types of architecture. For
example, a smart sensor with its own computer running asynchronously rel-
ative to the primary control computer will not be amenable to direct digital
design because the overall system transfer function depends on the phasing
between the smart sensor and the primary digital controller. Therefore, if
asynchronous digital subsystems are present, sample rates on the order of
20 × ωBW or slower in any module should be used with caution and the
system performance checked through simulation or experiment.
8.6
Discrete Design
It is possible to obtain an exact discrete model that relates the samples of the
△
continuous plant y(k) to the input control sequence u(k). This plant model
can be used as part of a discrete model of the feedback system including
the compensation Dd(z). Analysis and design using this discrete model is
called discrete design or, alternatively, direct digital design. Once a dis-
crete model of the entire system is obtained, the designer can develop a
discrete controller entirely in the discrete domain. This process is particu-
larly advantageous for systems whose sample rates are constrained to be very
slow compared to their bandwidth, that is, with sample rates (ωs < 10×ωn).
This would normally only occur if the sample rate was limited by the sam-
pling process or sensor characteristics rather than the microcontroller, which
have become very fast and inexpensive. The following subsections will
describe how to ﬁnd the discrete plant model (Section 8.6.1), what the
feedback compensation looks like when designing with a discrete model
(Section 8.6.2), how the design process is carried out (Section 8.6.3), and
how various discrete designs can be analyzed (Section 8.6.4).

8.6 Discrete Design
621
8.6.1
Analysis Tools
The ﬁrst step in performing a discrete analysis of a system with some discrete
elements is to ﬁnd the discrete transfer function of the continuous portion.
For a system similar to that shown in Fig. 8.1(b), we wish to ﬁnd the trans-
fer function between u(kT) and y(kT). This is precisely the case that we
discussed in Section 8.3.2; however, here the ZOH is real so there is no
approximation involved. It is an exact discrete equivalent for this system;
the ZOH precisely describes what happens between samples of u(kT) and
the output y(kT) is dependent only on the input at the sample times u(kT).
For a plant described by G(s) and preceded by a ZOH, the discrete
transfer function was essentially given by Eq. (8.23), and is repeated here
with Dc(s) replaced by G(s).
G(z) = (1 −z−1)Z
G(s)
s

,
(8.41)
where Z{ F(s)} is the z-transform of the sampled time series whose Laplace
The exact discrete
equivalent
transform is the expression for F(s), given on the same line in Table 8.1.
Equation (8.41) allows us to replace the mixed (continuous and discrete)
system shown in Fig. 8.17(a) with the equivalent pure discrete system shown
in Fig. 8.17(b).
The analysis and design of discrete systems is very similar to the analysis
and design of continuous systems; in fact, all the same rules apply. The
closed-loop transfer function of Fig. 8.17(b) is obtained using the same
rules of block-diagram reduction—that is,
Y(z)
R(z) =
Dd(z)G(z)
1 + Dd(z)G(z).
(8.42)
To ﬁnd the characteristic behavior of the closed-loop system, we need to ﬁnd
the factors in the denominator of Eq. (8.42)—that is, the closed-loop poles
or the roots of the discrete characteristic equation
1 + Dd(z)G(z) = 0.
The root-locus techniques used in continuous systems to ﬁnd roots of a poly-
nomial in s apply equally well and without modiﬁcation to the polynomial
in z; however, the interpretation of the results is quite different, as we saw
in Fig. 8.4. A major difference is that the stability boundary is now the unit
circle instead of the imaginary axis.
Dd(z)
©
 - 
 + 
ZOH
R(s)
Y(s)
(a)
Dd(z)
©
 - 
 + 
G(z)
Y(z)
R(z)
(b)
G(s)
Figure 8.17
Comparison of: (a) a mixed system; and (b) its pure discrete equivalent

622
Chapter 8 Digital Control
EXAMPLE 8.4
Discrete Root Locus
For the case in which G(s) in Fig. 8.17(a) is
G(s) =
a
s + a
and Dd(z) = K, draw the root locus with respect to K, and compare your
results with a root locus of a continuous version of the system. Discuss the
implications of your loci.
Solution. It follows from Eq. (8.41) that
G(z) = (1 −z−1)Z

a
s(s + a)

= (1 −z−1)

(1 −e−aT)z−1
(1 −z−1)(1 −e−aTz−1)

= 1 −α
z −α ,
where
α = e−aT.
To analyze the performance of the closed-loop system, standard root-locus
rules apply. The result is shown in Fig. 8.18(a) for the discrete case and in
Fig. 8.18(b) for the continuous case. In contrast to the continuous case, in
which the system remains stable for all values of K, in the discrete case
the system becomes oscillatory with decreasing damping ratio as z goes
from 0 to −1 and eventually becomes unstable. This instability is due to the
lagging effect of the ZOH, which is properly accounted for in the discrete
analysis.
8.6.2
Feedback Properties
In continuous systems, we typically start the design process using the fol-
lowing basic design elements: proportional, derivative, or integral control
Figure 8.18
Root loci for: (a) the
z-plane; and (b) the
s-plane
Re(s)
Im(s)
Re(z)
Im(z)
z = a
z = 0
z = - 1
(a)
(b)
s = - a

8.6 Discrete Design
623
laws, or some combination of these, sometimes with a lag included. The
same ideas can be used in discrete design. Alternatively, the Dd(z) resulting
from the digitization of a continuously designed Dc(s) will produce these
basic design elements, which will then be used as a starting point in a discrete
design. The discrete control laws are as follows:
Proportional
u(k) = Ke(k) ⇒Dd(z) = K.
(8.43)
Derivative
u(k) = KTD[e(k) −e(k −1)],
(8.44)
for which the transfer function is
Dd(z) = KTD(1 −z−1) = KTD
z −1
z
= kD
z −1
z
.
(8.45)
Integral
u(k) = u(k −1) + Kp
TI
e(k),
(8.46)
for which the transfer function is
Dd(z) = K
TI

1
1 −z−1

= K
TI

z
z −1

= kI

z
z −1

.
(8.47)
Lead Compensation
The examples in Section 8.3 showed that a continuous lead compensation
leads to difference equations of the form
u(k + 1) = βu(k) + K[e(k + 1) −αe(k)],
(8.48)
for which the transfer function is
Dd(z) = K 1 −αz−1
1 −βz−1 .
(8.49)
8.6.3
Discrete Design Example
Digital control design consists of using the basic feedback elements of
Eqs. (8.43) to (8.49) and iterating on the design parameters until all
speciﬁcations are met.
EXAMPLE 8.5
Direct Discrete Design of the Space Station Digital Controller
Design a digital controller to meet the same speciﬁcations as in Example 8.3
using discrete design.
Solution.
The discrete model of the 1/s2 plant, preceded by a ZOH, is
found through Eq. (8.41) to be
G(z) = T2
2
 z + 1
(z −1)2

,

624
Chapter 8 Digital Control
which, with T = 1 sec, becomes
G(z) = 1
2
 z + 1
(z −1)2

.
Proportional feedback in the continuous case yields pure oscillatory motion,
so in the discrete case we should expect even worse results. The root locus in
Fig. 8.19 veriﬁes this. For very low values of K (where the locus represents
roots at very low frequencies compared to the sample rate), the locus is
tangent to the unit circle (ζ ∼= 0 indicating pure oscillatory motion), thus
matching the proportional continuous design.
For higher values of K, Fig. 8.19 shows that the locus diverges into
the unstable region because of the effect of the ZOH and sampling. To
compensate for this, we will add a derivative term to the proportional term
so that the control law is
U(z) = K[1 + TD(1 −z−1)]E(z),
(8.50)
which yields compensation of the form
Dd(z) = K z −α
z
,
(8.51)
where the new K and α replace the K and TD in Eq. (8.50). Now the task is
to ﬁnd the values of α and K that yield good performance. The speciﬁcations
for the design are that ωn = 0.3 rad/sec and ζ = 0.7. Figure 8.4 indicates
that this s-plane root location maps into a desired z-plane location of
z = 0.78 ± 0.18j.
Figure 8.20 is the locus with respect to K for α = 0.85. The location of
the zero (at z = 0.85) was determined by trial and error until the locus
passed through the desired z-plane locations. The value of the gain when the
locus passes through z = 0.78 ± 0.18j is K = 0.374. Equation (8.51) now
becomes
Dd(z) = 0.374z −0.85
z
.
(8.52)
Figure 8.19
z-plane root locus for
a 1/s2 plant with
proportional feedback
Re(z)
Im(z)
-1

8.6 Discrete Design
625
Normally, it is not particularly advantageous to match speciﬁc z-plane
root locations; rather it is necessary only to pick K and α (or TD) to obtain
acceptable z-plane roots, a much easier task. In this example, we want to
match a speciﬁc location only so that we can compare the result with the
design in Example 8.3.
The control law that results is
U(z) = 0.374(1 −0.85z−1)E(z),
or
u(k) = 0.374e(k) −0.318e(k −1),
(8.53)
which is similar to the control equation (8.35) obtained previously.
The controller in Eq. (8.53) basically differs from the continuously
designed controller [Eq. (8.35)] only in the absence of the u(k −1) term.
The u(k −1) term in Eq. (8.35) results from the lag term (s + b) in the
compensation [Eq. (8.33)]. The lag term is typically included in analog con-
trollers both because it supplies noise attenuation and because pure analog
differentiators are difﬁcult to build. Some equivalent lag in discrete design
naturally appears as a pole at z = 0 (see Fig. 8.20) and represents the one-
sample delay in computing the derivative by a ﬁrst difference. For more noise
attenuation, we could move the pole to the right of z = 0, thus resulting in
less derivative action and more smoothing, the same trade-off that exists in
continuous control design.
Figure 8.20
z-plane locus for
the 1/s2 plant with
Dd(z) = K(z −0.85)/z
Real axis
-1.0
-0.5
0
0.5
1.0
1.0
0.8
0.6
0.4
0.2
-0.2
-0.4
-0.6
-0.8
-1.0
Imaginary axis
Desired
root
Desired
root

626
Chapter 8 Digital Control
8.6.4
Discrete Analysis of Designs
Any digital controller, whether designed by discrete equivalents or directly
in the z-plane, can be analyzed using discrete analysis, which consists of the
following steps:
1. Find the discrete model of the plant and ZOH using Eq. (8.41).
2. Form the feedback system including Dd(z).
3. Analyze the resulting discrete system.
We can determine the roots of the system using a root locus, as described
in Section 8.6.3, or we can determine the time history (at the sample instants)
of the discrete system.
EXAMPLE 8.6
Damping and Step Response in Digital versus
Continuous Design
Use discrete analysis to determine the equivalent s-plane damping and the
step responses of the digital designs in Examples 8.3 and 8.5, and compare
your results with the damping and step response of the continuous case in
Example 8.3.
Solution. The Matlab statements to evaluate the damping and step response
of the continuous case in Example 8.3 are
s=tf('s');
sysGc = 1/(sˆ2);
sysDc = 0.81*(s+0.2)/(s+2);
sysGDc = series(sysGc,sysDc);
sysCLc = feedback(sysGDc,1,1);
step(sysCLc)
damp(sysCLc)
To analyze the digital control cases, the model of the plant preceded by
the ZOH is found using the statements
T = 1;
sysGz = c2d(sysGc,T,'zoh')
Analysis of the digital control designed using the discrete equivalent
[Eq. (8.35)] in Example 8.3 is performed by the statements
z = tf('z',T);
% speciﬁes z-transform based on input T
sysDz =.389*(z - .82)/(z - .135);
sysDGz = series(sysGz,sysDz);
sysCLz = feedback(sysDGz,1);
step(sysCLz,T)
damp(sysCLz,T)
Likewise, the discrete design of Dd(z) from Eq. (8.52) can be analyzed by
the same sequence.

8.6 Discrete Design
627
Figure 8.21
Step response of the
continuous and digital
systems in Examples 8.3
and 8.6
Time (sec)
0
5
10
15
20
25
30
Plant output
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
Continuous design
Discrete equivalent design
Discrete design
The resulting step responses are shown in Fig. 8.21. The calculated
damping ζ and complex root natural frequencies ωn of the closed-loop
systems are
Continuous case :
ζ = 0.705,
ωn = 0.324;
Discrete equivalent :
ζ = 0.645,
ωn = 0.441;
Discrete design :
ζ = 0.733,
ωn = 0.306.
The ﬁgure shows increased overshoot for the discrete equivalent method that
occurred because of the decreased damping of that case. Very little increased
overshoot occurred in the discrete design, because that compensation was
adjusted speciﬁcally so that the equivalent s-plane damping of the discrete
system was approximately at the desired damping value of ζ = 0.7.
Although the analysis showed some differences between the perfor-
mance of the digital controllers designed by the two methods, neither the
performance nor the control equations [Eqs. (8.35) and (8.53)] are substan-
tially different. This similarity results because the sample rate is fairly fast
compared to ωn—that is, ωs ∼= 20 × ωn. If we were to decrease the sample
rate, the numerical values in the compensations would become increasingly
different and the performance would degrade considerably for the discrete
equivalent case.
As a general rule, discrete design should be used if the sampling fre-
quency is slower than 10×ωn. At the very least, a discrete equivalent design
with slow sampling (ωs < 10 × ωn) should be veriﬁed by a discrete anal-
ysis or by simulation, as described in this Section, and the compensation
adjusted if needed. A simulation of a digital control system is a good idea

628
Chapter 8 Digital Control
in any case. If it properly accounts for all delays and possibly asynchronous
behavior of different modules, it may expose instabilities that are impossi-
ble to detect using continuous or discrete linear analysis. A more complete
discussion regarding the effects of sample rate on the design was discussed
in Section 8.5.
8.7
Discrete State-Space Design Methods
Chapter 7 describes the design options available for carrying out continuous
designs using the state-space description of the system. These methods can
also be applied to discrete models, a subject that is described in SectionW8.7
on our website www.fpe7e.com. It is also discussed in much greater detail
in Franklin, Powell, and Workman, Digital Control of Dynamic Systems, 3e
(1998).
8.8
Historical Perspective
One of the earliest examples of actual control of systems based on sampled
data came with the use of search RADAR in WWII. In that case, the posi-
tion of the target was available only once each revolution of the antenna.
The theory of sampled data systems was developed by the mathematician
W. Hurewicz3 and published as a chapter in H. M. James, N. B. Nichols, and
R. S. Phillips, Theory of Servomechanisms, vol. 25, Rad Lab Series, New
York, McGraw Hill, 1947. The historical perspective for Chapter 5 discussed
the introduction of computers for engineers performing design activities.
The possibility of using computers for direct digital control motivated the
continuation of work on sampled data systems during the 1950s, especially
at Columbia University under Professor J. R. Ragazzini. That work was
published in Ragazzini and Franklin (1958). Early applications were in the
process control industry where the relatively large and expensive computers
available at the time could be justiﬁed. Professor Karl Åström introduced
direct digital control of a paper mill in Sweden in the early 1960s.
In 1961, when President Kennedy announced the goal of sending a
man to the moon, there were no digital autopilots for aerospace vehicles.
In fact, small digital computers suitable for implementing control systems
were virtually nonexistent. The team at the MIT Draper Labs (called the
Instrumentation Lab at that time) in charge of designing and building the
Apollo control systems initially designed the control systems for the lunar
and command modules with conventional analog electronics. However, they
discovered that those systems would be too heavy and complex for the mis-
sion. So the decision was made to design and build the ﬁrst aerospace digital
control system. Bill Widnall, Dick Battin, and Don Fraser were all key
3Hurewicz died in 1956 falling off a ziggurat (a Mexican pyramid) on a conference outing
at the International Symposium on algebraic topology in Mexico. It is suggested that he was
". . . a paragon of absentmindedness, a failing that probably led to his death."

Summary
629
players in the successful design and execution of that system for the Apollo
ﬂights in late 1960s. The group went on to demonstrate a digital autopilot for
NASA's F-8 in the 1970s, and digital autopilots went on to become domi-
nant over the 1980s and beyond. In fact, with the introduction of inexpensive
digital signal processors, most control systems of any kind became digital
by the turn of the century and, today, very few control systems are being
implemented with analog electronics. This evolution has had an effect on
the training for controls engineers. In the past, the ability to design and build
the specialized circuitry for analog electronic controls caused many controls
engineers to have an Electrical Engineering background. Now, with easily
programmable digital computers being readily available, the background of
controls engineers tends more toward the specialties that are most familiar
with the systems being controlled.
SUMMARY
•
The simplest and most expedient digital control design technique is to
transform a continuous controller design to its discrete form—that is,
to use its discrete equivalent.
•
Design using discrete equivalents entails (a) ﬁnding the continuous
compensation Dc(s) using the ideas in Chapters 1 to 7, and (b) approx-
imating Dc(s) with difference equations using a discretization methods
such as Tustin's method, the ZOH method, or the matched-pole-zero
method.
•
In order to analyze a discrete controller design, or any discrete sys-
tem, the z-transform is used to determine the system's behavior. The
z-transform of a time sequence f (k) is given by
Z{ f (k)} = F(z) =
∞

k=0
f (k)z−k,
and has the key property that
Z{ f (k −1)} = z−1F(z).
This property allows us to ﬁnd the discrete transfer function of a differ-
ence equation, which is the digital equivalent of a differential equation
for continuous systems. Analysis using z-transforms closely parallels
that using Laplace transforms.
•
Normally z-transforms are found using the computer (Matlab) or
looking up in Table 8.1.
•
The discrete Final Value Theorem is
lim
k→∞x(k) = lim
z→1(1 −z−1)X(z),
provided that all poles of (1 −z−1)X(z) are inside the unit circle.
•
For a continuous signal f (t) whose samples are f (k), the poles of F(s)
are related to the poles of F(z) by
z = esT.

630
Chapter 8 Digital Control
•
The following are the most common discrete equivalents:
1. Tustin's approximation:
Dd(z) = Dc(s)

s= 2
T

z−1
z+1
	
2. The matched pole-zero (MPZ) approximation:
• Map poles and zeros by z = esT.
• Add powers of z+1 to the numerator until numerator and denom-
inator are of equal order or the numerator is one order less than
the denominator.
• Set the low-frequency gain of Dd(z) equal to that of Dc(s).
•
If designing by discrete equivalents, a minimum sample rate of 20
times the bandwidth is recommended. Typically, even faster sampling
is useful for best performance.
•
Analog preﬁlters are commonly placed before the sampler in order to
attenuate the effects of high-frequency measurement noise. A sampler
aliases all frequencies in the signal that are greater than half the sample
frequency to lower frequencies; therefore, preﬁlter break points should
be selected so that no signiﬁcant frequency content remains above half
the sample rate.
•
The discrete model of the continuous plant G(s) preceded by a ZOH is
G(z) = (1 −z−1)Z
G(s)
s

.
The discrete plant model plus the discrete controller can be analyzed
using the z-transform or simulated using Simulink.
•
Discrete design is an exact design method and avoids the approxima-
tions inherent with discrete equivalents. The design procedure entails
(a) ﬁnding the discrete model of the plant G(s), and (b) using the dis-
crete model to design the compensation directly in its discrete form. The
design process is more cumbersome than discrete equivalent design and
requires that a sample rate be selected before commencing the design. A
practical approach is to commence the design using discrete equivalents,
then tune up the result using discrete design.
•
Discrete design using G(z) closely parallels continuous design, but
the stability boundary and interpretation of z-plane root locations are
different. Figure 8.5 summarizes the response characteristics.
•
If using discrete design, system stability can theoretically be assured
when sampling at a rate as slow as twice the bandwidth. However, for
good transient performance and (random) disturbance rejection, best
results are obtained by sampling at 10 times the closed-loop band-
width or faster. In some cases, for example with troublesome vibrational
modes, it is sometimes useful to sample more than twice as fast as the
vibrational mode.

Problems
631
REVIEW QUESTIONS
8.1
What is the Nyquist rate? What are its characteristics?
8.2
Describe the discrete equivalent design process.
8.3
Describe how to arrive at a Dd(z) if the sample rate is 30 × ωBW .
8.4
For a system with a 1 rad/sec bandwidth, describe the consequences of various
sample rates.
8.5
Give two advantages for selecting a digital processor rather than analog
circuitry to implement a controller.
8.6
Give two disadvantages for selecting a digital processor rather than analog
circuitry to implement a controller.
8.7
Describe how to arrive at a Dd(z) if the sample rate is 5 × ωBW .
△
PROBLEMS
Problems for Section 8.2: Dynamic Analysis of Discrete Systems
8.1
The z-transform of a discrete-time ﬁlter h(k) at a 1 Hertz sample rate is
H(z) =
1 + (1/2)z−1
[1 −(1/2)z−1][1 + (1/3)z−1].
(a) Let u(k) and y(k) be the discrete input and output of this ﬁlter. Find a
difference equation relating u(k) andy(k).
(b) Find the natural frequency and damping coefﬁcient of the ﬁlter's poles.
(c) Is the ﬁlter stable?
8.2
Use the z-transform to solve the difference equation
y(k) −3y(k −1) + 2y(k −2) = 2u(k −1) −2u(k −2),
where
u(k) =
 k,
k ≥0,
0,
k < 0,
y(k) = 0,
k < 0.
8.3
The one-sided z-transform is deﬁned as
F(z) =
∞

0
f (k)z−k.
(a) Show that the one-sided transform of f (k + 1) is Z{ f (k + 1)} =
zF(z) −zf (0).
(b) Use the one-sided transform to solve for the transforms of the Fibonacci
numbers generated by the difference equation u(k+2) = u(k+1)+u(k).
Let u(0) = u(1) = 1. [Hint: You will need to ﬁnd a general expression
for the transform of f (k + 2) in terms of the transform of f (k).]
(c) Compute the pole locations of the transform of the Fibonacci numbers.
(d) Compute the inverse transform of the Fibonacci numbers.

632
Chapter 8 Digital Control
(e) Show that, if u(k) represents the kth Fibonacci number, then the ratio
u(k + 1)/u(k) will approach

1+
√
5
2
	
. This is the golden ratio valued so
highly by the Greeks.
8.4
Prove the seven properties of the s-plane-to-z-plane mapping listed in
Section 8.2.3.
Problems for Section 8.3: Design Using Discrete Equivalents
8.5
A unity feedback system has an open-loop transfer function given by
G(s) =
250
s[(s/10) + 1].
The following lag compensator added in series with the plant yields a phase
margin of 50◦:
Dc(s) = s/1.25 + 1
50s + 1 .
Using the matched pole-zero approximation, determine an equivalent digital
realization of this compensator.
8.6
The following transfer function is a lead network designed to add about 60◦
of phase at ω1 = 3 rad/sec:
H(s) =
s + 1
0.1s + 1.
(a) Assume a sampling period of T = 0.25 sec, and compute and plot in
the z-plane the pole and zero locations of the digital implementations of
H(s) obtained using (1) Tustin's method and (2) pole-zero mapping. For
each case, compute the amount of phase lead provided by the network at
z1 = ejω1T.
(b) Using a log-log scale for the frequency range ω = 0.1 to ω = 100 rad/sec,
plot the magnitude Bode plots for each of the equivalent digital systems
you found in part (a), and compare with H(s). (Hint: Magnitude Bode
plots are given by |H(z)| = |H(ejωT)|.)
8.7
The following transfer function is a lag network designed to introduce a gain
attenuation of 10(−20 db) at ω = 3 rad/sec:
H(s) = 10s + 1
100s + 1.
(a) Assume a sampling period of T = 0.25 sec, and compute and plot in the
z-plane the pole and zero locations of the digital implementations of H(s)
obtained using (1) Tustin's method and (2) pole-zero mapping. For each
case, compute the amount of gain attenuation provided by the network at
z1 = ejω1T.
(b) For each of the equivalent digital systems in part (a), plot the Bode
magnitude curves over the frequency range ω = 0.01 to 10 rad/sec.
Problem for Section 8.5: Sample Rate Selection
8.8
For the system shown in Fig. 8.22, ﬁnd values for K, TD, and TI so that the
closed-loop poles satisfy ζ > 0.5 and ωn > 1 rad/sec. Discretize the PID
controller using

Problems
633
(a) Tustin's method
(b) The matched pole-zero method
Use Matlab to simulate the step response of each of these digital implemen-
tations for sample times of T = 1, 0.1, and 0.01 sec.
Figure 8.22
Control system for
Problem 8.8
©
 + 
 - 
Y
R
E
s(s + 1)
1
K(1 + TDs  + TIs
1 )
U
Problems for Section 8.6: Discrete Design
△
8.9
Consider the system conﬁguration shown in Fig. 8.23, where
G(s) =
40(s + 2)
(s + 10)(s2 −1.4).
(a) Find the transfer function G(z) for T = 1 assuming the system is preceded
by a ZOH.
(b) Use Matlab to draw the root locus of the system with respect to K.
(c) What is the range of K for which the closed-loop system is stable? Com-
pare your results with the case in which an analog controller is used (that
is, where the sampling switch is always closed). Which system has a larger
allowable value of K?
(d) Use Matlab to compute the step response of both the continuous and
discrete systems with K chosen to yield a damping factor of ζ = 0.5 for
the continuous case.
Figure 8.23
Control system for
Problem 8.9
©
 + 
 - 
G(s)
Y
K
R
T
8.10
Single-Axis Satellite Attitude Control: Satellites often require attitude control
for proper orientation of antennas and sensors with respect to Earth. Figure 2.7
shows a communication satellite with a three-axis attitude-control system. To
gain insight into the three-axis problem, we often consider one axis at a time.
Figure 8.24 depicts this case, where motion is allowed only about an axis
perpendicular to the page. The equations of motion of the system are given by
I ¨θ = MC + MD,
where
I = moment of inertia of the satellite about its mass center,
MC = control torque applied by the thrusters,
MD = disturbance torques,

634
Chapter 8 Digital Control
Figure 8.24
Satellite control
schematic for
Problem 8.10
u
Inertial
reference
θ = angle of the satellite axis with respect to an inertial reference
with no angular acceleration.
We normalize the equations of motion by deﬁning
u = MC
I ,
wd = MD
I ,
and obtain
¨θ = u + wd.
Taking the Laplace transform yields
θ(s) = 1
s2 [u(s) + wd(s)],
which, without disturbance, becomes
θ(s)
u(s) = 1
s2 = G1(s).
In the discrete case in which u is applied through a ZOH, we can use the
methods described in this chapter to obtain the discrete transfer function
G1(z) = θ(z)
u(z) = T2
2
 z + 1
(z −1)2

.
(a) Sketch the root locus of this system by hand, assuming proportional
control.
(b) Draw the root locus using Matlab to verify the hand sketch.
(c) Add discrete velocity feedback to your controller so that the dominant
poles correspond to ζ = 0.5 and ωn = 3π/10T.
(d) What is the feedback gain if T = 1 sec? If T = 2 sec?
(e) Plot the closed-loop step response and the associated control time history
for T = 1 sec.
8.11
It is possible to suspend a mass of magnetic material by means of an electro-
magnet whose current is controlled by the position of the mass (Woodson and
Melcher, 1968). The schematic of a possible setup is shown in Fig. 8.25, and

Problems
635
Figure 8.25
Schematic of magnetic
levitation device for
Problem 8.11
a photo of a working system at Stanford University is shown in Fig. 9.2. The
equations of motion are
m¨x = −mg + f (x, I),
where the force on the ball due to the electromagnet is given by f (x, I). At
equilibrium the magnet force balances the gravity force. Suppose we let I0
represent the current at equilibrium. If we write I = I0 +i, where i represents
a deviation from the nominal current, I0, expand f about x = 0 and I = I0,
and neglect higher-order terms, we obtain the linearized equation
m¨x = k1x + k2i.
(8.54)
Reasonable values for the constants in Eq. (8.54) are m = 0.02 kg, k1 =
20 N/m, and k2 = 0.4 N/A.
(a) Compute the transfer function from I to x, and draw the (continuous) root
locus for the simple feedback i = −Kx.
(b) AssumethattheinputispassedthroughaZOH,andletthesamplingperiod
be 0.02 sec. Compute the transfer function of the equivalent discrete-time
plant.
(c) Design a digital control for the magnetic levitation device so that the
closed-loop system meets the following speciﬁcations: tr ≤0.1 sec, ts ≤
0.4 sec, and overshoot ≤20%.
(d) Plot a root locus with respect to k1 for your design, and discuss the
possibility of using your closed-loop system to balance balls of various
masses.
(e) Plot the step response of your design to an initial disturbance displacement
on the ball, and show both x and the control current i. If the sensor can
measure x only over a range of ±1/4 cm and the ampliﬁer can provide
a current of only 1 A, what is the maximum displacement possible for
control, neglecting the nonlinear terms in f (x, I)?
8.12
Repeat Problem 5.27 in Chapter 5 by constructing discrete root loci and
performing the designs directly in the z-plane. Assume that the output y is

636
Chapter 8 Digital Control
sampled, the input u is passed through a ZOH as it enters the plant, and the
sample rate is 15 Hz.
8.13
Design a digital controller for the antenna servo system shown in Figs. 3.60
and 3.61 and described in Problem 3.36. The design should provide a step
response with an overshoot of less than 10% and a rise time of less than
80 sec.
(a) What should the sample rate be?
(b) Use discrete equivalent design with the matched pole-zero method.
(c) Use discrete design and the z-plane root locus.
8.14
The system
G(s) =
1
(s + 0.1)(s + 3)
is to be controlled with a digital controller having a sampling period of T =
0.1 sec. Using a z-plane root locus, design compensation that will respond to
a step with a rise time tr ≤1 sec and an overshoot Mp ≤5%. What can be
done to reduce the steady-state error?
8.15
The discrete transfer function for pure derivative control is
Dd(z) = KTD
z −1
Tz ,
where the pole at z = 0 adds some destabilizing phase lag. Can this phase lag
be removed by using derivative control of the form
Dd(z) = KTD
(z −1)
T
?
Support your answer with the difference equation that would be required and
discuss the requirements to implement it.

9
Nonlinear Systems
A Perspective on Nonlinear Systems
All systems are nonlinear, especially if large signals are considered. On
the other hand, almost all physical systems can be well approximated
by linear models if the signals are small. For example, if θ is small,
then sin(θ) ≈θ and cos(θ) ≈1. Similarly, in analog electronic
devices such as ampliﬁers, the operation will be nearly linear if the
signals are small with respect to the supply voltage. Finally, as we
will consider later in this chapter in an optional section, Lyapunov
showed that if the linear approximation of a system is stable near an
equilibrium point, then the truly nonlinear system will be stable for
some neighborhood of the equilibrium point. For all these reasons,
the analysis and design methods presented thus far in this book have
considered only the enormously powerful techniques available for
linear models. However, if the signals cause a device to saturate or
if the system includes nonlinearities that are active for small signals,
such as certain kinds of friction, then the nonlinear effects must be
taken into account to explain the behavior of the system. In this
chapter, a few of the tools available for this purpose will be described.
637

638
Chapter 9 Nonlinear Systems
Chapter Overview
Becauseeverynonlinearsystemisinmanywaysunique, avastnumber
of approaches are used in nonlinear control design. The approaches to
analysis and design of nonlinear systems that we will describe may be
classiﬁed under four categories. In Section 9.2 methods of reducing
the problem to a linear model are discussed. In most cases, consider-
ing the small signal approximation is adequate. In some cases there
are nonlinearities for which an inverse can be found, and placing the
inverse before the physical nonlinearity results in an overall system
that responds linearly. In yet other cases, some nonlinear models can
be reduced to an exact linear form by the clever use of feedback, in a
technique called "computed torque" in the ﬁeld of robotics.
The second category is a heuristic approach based on considering
the nonlinearity to be a varying gain. In Section 9.3 cases are consid-
ered for which the nonlinearity has no memory as, for example, with
an ampliﬁer whose output saturates when the signal gets large. The
idea is to consider the ampliﬁer as if its gain begins to be reduced as
the signal gets large. Because the root locus is based on evaluating
the system characteristic roots as gain changes, this point of view
leads to a heuristic use of the root locus to predict how such a system
will respond to changing input signal sizes. Section 9.4 treats cases in
which the nonlinearity has dynamics or memory; then the root locus
is not useful. For these cases a technique introduced by Kochenburger
in 1950 known as the describing function can be used. To apply this
method, a sinusoid is applied to the nonlinear part of the system and
the ﬁrst harmonic of the periodic response is computed. The ratio
of the input to the output is taken as if it were a linear but variable
frequency response. Thus the Nyquist plot is the natural domain in
which to consider the system behavior.
While the heuristic approaches may give very useful insight into
the system's behavior, they cannot be used to decide if the system
is guaranteed to be stable. For this, one must turn to the analysis
of stability as studied in control theory. The most famous of these
theories is that of internal stability developed by Lyapunov. As an
introduction to the idea of a system response as a trajectory in space,
Section 9.5 describes analysis in the phase plane and then presents
the stability theory. Examples are given of using the stability theorem
to guide design of a controller so the system is guaranteed to be
stable if the initial assumptions about the system hold. With these
methods, the control engineer is given a start on the path to the
effective understanding and design of real control problems. Finally
Section 9.6 provides a historical perspective for the material in this
chapter.

9.1 Introduction and Motivation: Why Study Nonlinear Systems?
639
9.1
Introduction and Motivation: Why Study
Nonlinear Systems?
It is intuitively clear that at some level of signal strength any physical system
will be nonlinear and that some systems are nonlinear at any and all signal
levels. On the other hand, we began our study by developing linear approx-
imate models, and all our design methods thus far have been based on the
assumption that the plant can be represented by a linear transfer function. In
this chapter we shall give some of the reasons for believing that all the time
spent studying linear techniques was not a waste of time, but we shall also
try to explain why it is very important to understand how to take nonlinear
effects into account in control system design.
We begin by showing that we can combine the root-locus technique,
which plots roots of the characteristic equation as a function of various gain
values, with the observation that many nonlinear elements can be viewed
as a gain that changes as signal level changes. While the method is, at this
point, entirely heuristic, the simulation results are very promising. Many
properties of systems containing such zero-memory nonlinear elements can
be predicted by plotting a root locus versus gain at the point of the non-
linearity. However, the method, as presented, is not on a ﬁrm foundation,
and the designer is left to wonder if there is some unexplored region of the
real state space or the signal spaces where catastrophe awaits. After all, the
model is an approximation, and no matter how extensive the simulation, it
is not possible to cover every situation.
Following the use of the root locus, we turn to methods based on the
frequency response. One of the great advantages of the frequency response
is that in many cases one can obtain the transfer function experimentally on
the real system. In the most basic approach, a sinusoidal signal is applied to
the system and the amplitude and phase of the output sinusoid are measured.
However, noise and inevitable nonlinear effects cause the output to be more
complicated than a simple sinusoid, so the designer extracts the fundamental
component and treats it as if it is the whole story. One gets the same result
if a spectrum analyzer is used to compute a transfer function. The approach
computes what Kochenburger called the describing function. From this
point of view, a describing function can be deﬁned for nonlinear elements,
including those with memory. Again, simulations are promising and many
useful designs are done with this technique but, as with the use of root locus
to design nonlinear systems, this method is also on shaky ground.1
So what is to be made of this situation? The only possibility is to face
up to the facts and take on nonlinear behavior directly. Fortunately, a ﬁrm
foundation in mathematics was established whenA. M. Lyapunov published
1And as we live in California, we know how dangerous it is to be on shaky ground.

640
Chapter 9 Nonlinear Systems
his work on the stability of motion in 1892. This work was translated into
French in 1907 and recovered in a control context by Kalman and Bertram
in 1960. Lyapunov gave two methods for the study of stability. For his
ﬁrst method, he considered stability based on the linear approximation, the
very thing required to justify our concentration on that approach in this
book. He proved the remarkable result that if the linear approximation is
strictly stable, having all roots in the left half-plane (LHP), then the nonlin-
ear system will have a region of stability around the equilibrium point where
the linear approximation applies. Furthermore, he proved that if the linear
approximation has at least one root in the right half-plane (RHP), then the
nonlinear system cannot have any region of stability in the neighborhood
of the equilibrium. The size of the stable region in the state space is not
given by the linear terms but is included in the construction used for the
proof. That construction constituted his second method. Lyapunov's second
method is based on the mathematical equivalent of ﬁnding a scalar func-
tion that describes the internal energy stored in the system. He proved that
if such a function is constructed, and if the derivative of the function is
negative on trajectories of the dynamic equations of the system, then the
function and the state on which it depends will eventually drain away and
the state will come to rest at the equilibrium point. A function having these
properties is called a Lyapunov function. Of course, this simple descrip-
tion omits a great deal of complexity; for example, there are dozens of
deﬁnitions of stability. However, the concept remains that if a Lyapunov
function can be found, then the system on which it is based will be stable.
As described, the theory gives a sufﬁcient condition for stability. If a Lya-
punov function is not found, the designer does not know if one does not
exist or if the search has just been inadequate. A great deal of research has
been directed toward ﬁnding Lyapunov functions for particular classes of
nonlinear systems.
Lyapunov's methods are based on differential equations in normal or
state form and are thus concerned with internal stability. Frequency-response
methods, ontheotherhand, areexternalmeasures, andtherehasbeeninterest
in developing stability results based on the external response of the system.
One such method is the circle criterion, which we will describe in this chapter
also. The method can be described as considering the energy seen at the
terminal of the system and noting if it is always ﬂowing into the terminals.
If so, it is reasonable to assume that eventually all energy will be gone and
the system will be stable. For a formal proof of the method, researchers have
turned to Lyapunov's second method, but the result is expressed in terms
of external properties, such as the Nyquist plot of the linear portion of the
system that faces the nonlinear elements. Again, this tool gives a basis for
setting a ﬁrm foundation under a method of design for a particular class of
nonlinear systems.
As should be clear at this point, the theory of nonlinear control is a vast
and sophisticated topic, and in this book we can give only a brief introduction
to a small part of it. However, the foundation of control design rests on this
theory, and the more the designer understands of the theory, the better he or

9.2 Analysis by Linearization
641
she understands both the limits and the opportunities of problems. It is our
hope that by considering this material, students will be stimulated to further
their proﬁtable study of this fascinating topic.
9.2
Analysis by Linearization
Three methods of reducing some nonlinear systems to a suitable linear model
are presented in this section. The differential equations of motion for almost
all processes selected for control are nonlinear. On the other hand, both
analysis and control design methods we have discussed so far are much
easier for linear than for nonlinear models. Linearization is the process of
ﬁnding a linear model that approximates a nonlinear one. Fortunately, as
Lyapunov proved over 100 years ago, if a small-signal linear model is valid
near an equilibrium and is stable, then there is a region (which may be small,
of course) containing the equilibrium within which the nonlinear system is
stable. So we can safely make a linear model and design a linear control
for it such that, at least in the neighborhood of the equilibrium, our design
will be stable. Since a very important role of feedback control is to maintain
the process variables near equilibrium, such small-signal linear models are
a frequent starting point for control design.
An alternative approach to obtain a linear model for use as the basis
of control system design is to use part of the control effort to cancel the
nonlinear terms and to design the remainder of the control based on linear
theory. This approach—linearization by feedback—is popular in the ﬁeld
of robotics, where it is called the method of computed torque. It is also
a research topic for control of aircraft. Section 9.2.2 takes a brief look at
this method. Finally, some nonlinear functions are such that an inverse
nonlinearity can be found to be placed in series with the nonlinearity so
that the combination is linear. This method is often used to correct mild
nonlinear characteristics of sensors or actuators that have small variations in
use, as discussed in Section 9.2.3.
9.2.1
Linearization by Small-Signal Analysis
For a system with smooth nonlinearities and a continuous derivative, one
can compute a linear model that is valid for small signals. In many cases
these models can be used for design. A nonlinear differential equation is an
equation for which the derivatives of the state have a nonlinear relationship
to the state itself and/or the control. In other words, the differential equations
cannot be written in the form 2
˙x = Ax + Bu,
but must be left in the form
˙x = f(x, u).
(9.1)
2This equation assumes the system is time invariant. A more general expression would be
˙x = f(x, u, t).

642
Chapter 9 Nonlinear Systems
For small-signal linearization we ﬁrst determine equilibrium values of xo,
uo, such that ˙xo = 0 = f(xo, uo), and we let x = xo + δx and u = uo + δu.
We then expand the nonlinear equation in terms of the perturbations from
these equilibrium values, which yields
˙xo + δ˙x ∼= f(xo, uo) + Aδx + Bδu,
where A and B are the best linear ﬁts to the nonlinear function f(x, u) at xo
and uo, computed as
A =
 ∂f
∂x

xo,uo
and
B =
 ∂f
∂u

xo,uo
.
(9.2)
Subtracting out the equilibrium solution, this reduces to
δ˙x = Aδx + Bδu,
(9.3)
which is a linear differential equation approximating the dynamics of the
state about the equilibrium point. Normally, the δ notation is dropped and it
is understood that x and u refer to the deviation from the equilibrium.
In developing the models discussed so far in this book, we have
encountered nonlinear equations on several occasions: the pendulum in
Example 2.5, the hanging crane in Example 2.7, the AC induction motor
in Section 2.3, the tank ﬂow in Example 2.19, and the hydraulic actuator in
Example 2.20. In each case, we assumed either that the motion was small or
that motion from some operating point was small, so that nonlinear functions
were approximated by linear functions. The steps followed in those exam-
ples essentially involved ﬁndingA and B in order to linearize the differential
equations to the form of Eq. (9.3), as illustrated in the next several examples.
The linearization functions in Matlab include linmod and linmod2.
EXAMPLE 9.1
Linearization of Nonlinear Pendulum
Consider the nonlinear equations of motion of the simple pendulum in
Example 2.5. Derive the equilibrium points for the system and determine
the corresponding small-signal linear models.
Solution. The equation of motion is
¨θ + g
ℓsin θ = Tc
mℓ2 .
(9.4)
We can rewrite the equation of motion in state-variable form, with x =
[ x1
x2 ]T = [ θ
˙θ ]T, as
˙x =

x2
−ω2
o sin x1 + u

=
 f1(x, u)
f2(x, u)

= f(x, u),
where ωo =
g
ℓand u = Tc
mℓ2 . To determine the equilibrium state, suppose
that the (normalized) input torque has a nominal value of uo = 0. Then
˙x1 = ˙θ = 0,
˙x2 = ¨θ = −g
ℓsin θ = 0,

9.2 Analysis by Linearization
643
so that the equilibrium conditions correspond to θo = 0, π (that is, the
downward and the inverted pendulum at rest conﬁgurations, respectively).
The equilibrium state and the input are xo = [ θo
0 ]T, uo = 0, and the
state-space matrices are given by
A =
⎡
⎢⎢⎣
∂f1
∂x1
∂f1
∂x2
∂f2
∂x1
∂f2
∂x2
⎤
⎥⎥⎦
xo,uo
=

0
1
−ω2
o cos θo
0

,
B =
⎡
⎢⎢⎣
∂f1
∂u
∂f2
∂u
⎤
⎥⎥⎦
xo,uo
=
 0
1

.
The linear system has eigenvalues of ±jωo and ±ωo corresponding to
θo = 0 and π, respectively, with the latter inverted case being unstable as
expected.
EXAMPLE 9.2
Linearization of Motion in a Ball Levitator
Figure 9.1 shows a magnetic bearing used in large turbo machinery. The
magnet are energized using feedback control methods so that the axle is
always in the center and never touches the magnets, thus keeping friction to
an almost nonexistent level. A simpliﬁed version of a magnetic bearing that
can be built in a laboratory is shown in Fig. 9.2, where one electromagnet
Figure 9.1
A magnetic bearing
Source: Photo courtesy of
Magnetic Bearings, Inc.

644
Chapter 9 Nonlinear Systems
Figure 9.2
Magnetic ball levitator
used in the laboratory
Source: Photo courtesy of Gene
Franklin
Figure 9.3
Model for ball
levitation
x
i
is used to levitate a metal ball. The physical arrangement of the levitator
is depicted in Fig. 9.3. The equation of motion of the ball, derived from
Newton's law, Eq. (2.1), is
m¨x = fm(x, i) −mg,
(9.5)
where the force fm(x, i) is caused by the ﬁeld of the electromagnet. Theo-
retically, the force from an electromagnet falls off with an inverse square
relationship to the distance from the magnet, but the exact relationship for
the laboratory levitator is difﬁcult to derive from physical principles because
its magnetic ﬁeld is so complex. However, the forces can be measured with
a scale. Figure 9.4 shows the experimental curves for a ball with a 1-cm
diameter and a mass of 8.4 × 10−3 kg. For the current of i2 = 600 mA and
the displacement x1 shown in the ﬁgure, the magnetic force fm just cancels
the gravity force, mg = 82×10−3 N. (The mass of the ball is 8.4×10−3 kg,
and the acceleration of gravity is 9.8 m/ sec2.) Therefore, the point (x1, i2)
represents an equilibrium. Using the data, ﬁnd the linearized equations of
motion about the equilibrium point.

9.2 Analysis by Linearization
645
Figure 9.4
Experimentally
determined force curves
1
2
3
4
5
0
40
80
120
6
160
x1
Distance, x (mm)
Force,  fm  (10-3 N)
i1 = 700 mA
i3 = 500 mA
Slope Kx
i2 = 600 mA
200
Solution. First we write, in expanded form, the force in terms of deviations
from the equilibrium values x1 and i2:
fm(x1 + δx, i2 + δi) ∼= fm(x1, i2) + Kxδx + Kiδi.
(9.6)
The linear gains are found as follows: Kx is the slope of the force versus x
along the curve i = i2, as shown in Fig. 9.4, and is found to be about 14 N/m.
Ki is the change of force with current for the value of ﬁxed x = x1. We ﬁnd
that for i = i1 = 700 mA at x = x1, the force is about 122 × 10−3 N, and
at i = i3 = 500 mA at x = x1, it is about 42 × 10−3 N. Thus
Ki ∼= 122 × 10−3 −42 × 10−3
700 −500
= 80 × 10−3 N
200 mA
∼= 400 × 10−3 N/A
∼= 0.4 N/A.
Substituting these values into Eq. (9.6) leads to the following linear
approximation for the force in the neighborhood of equilibrium:
fm ∼= 82 × 10−3 + 14δx + 0.4δi.
Substituting this expression into Eq. (9.5) and using the numerical values
for mass and gravity force, we get for the linearized model
(8.4 × 10−3)¨x = 82 × 10−3 + 14δx + 0.4δi −82 × 10−3.
Because x = x1 + δx, then ¨x = δ¨x. The equation in terms of δx is thus
(8.4 × 10−3)δ¨x = 14δx + 0.4δi,
δ¨x = 1667δx + 47.6δi,
(9.7)

646
Chapter 9 Nonlinear Systems
which is the desired linearized equation of motion about the equilibrium
point. A logical state vector is x = [δx δ˙x]T, which leads to the standard
matrices
A =

0
1
1667
0

and
B =

0
47.6

,
and the control u = δi.
EXAMPLE 9.3
Linearization of the Water Tank Revisited
Repeat the linearization of Example 2.19 using the concepts presented in
this section.
Solution. Equation (2.94) may be written as
˙x = f (x, u),
(9.8)
where x ≜h, u ≜win, and f (x, u) = −
1
RAρ
√p1 −pa +
1
Aρ win =
−
1
RAρ
√ρgh −pa +
1
Aρ win. The linearized equations are of the form
δ˙x = Aδx + Bδu,
(9.9)
where
[A]xo,uo = ∂f
∂x =
∂f
∂h

ho,uo
= ∂
∂h

−1
RAρ

ρgh −pa

ho,uo
(9.10)
= −g
2AR
1
√ρgho −pa
= −g
2AR
1
√po −pa
,
(9.11)
and
[B]xo,uo = ∂f
∂u =
∂f
∂win
= 1
Aρ .
(9.12)
However, note that some ﬂow is required to maintain the system in equi-
librium so that Eq. (9.9) is valid; speciﬁcally, we see from Eq. (2.94)
that
uo = wino = 1
R
√po −pa
for
˙h = 0,
(9.13)
and the δu in Eq. (9.9) is δwin, where win = wino +δwin. Therefore, Eq. (9.9)
becomes
δ˙h = Aδh + Bδwin = Aδh + Bwin −B 1
R
√po −pa
(9.14)
and matches Eq. (2.97) precisely.
9.2.2
Linearization by Nonlinear Feedback
Linearization by feedback is accomplished by subtracting the nonlinear
Nonlinear feedback
terms out of the dynamic equations and adding them to the control. The
result is a linear system, provided that the computer implementing the con-
trol has enough capability to compute the nonlinear terms fast enough and

9.2 Analysis by Linearization
647
the resulting control does not cause the actuator to saturate. A more detailed
understanding of the method is best achieved through an example.
EXAMPLE 9.4
Linearization of the Nonlinear Pendulum
Consider the equation of a simple pendulum developed in Example 2.5
[Eq. (2.22)]. Linearize the system by using nonlinear feedback.
Solution. The equation of motion is
ml2 ¨θ + mgl sin θ = Tc.
(9.15)
If we compute the torque to be
Tc = mgl sin θ + u,
(9.16)
then the motion is described by
ml2 ¨θ = u.
(9.17)
Equation (9.17) is a linear equation no matter how large the angle θ becomes.
We use it as the model for purposes of control design because it enables us
to use linear analysis techniques. The resulting linear control will provide
the value of u based on measurements of θ; however, the value of the torque
actually sent to the equipment would derive from Eq. (9.16). For robots with
two or three rigid links, this computed-torque approach has led to effective
control. It is also being researched for the control of aircraft, where the linear
models change considerably in character with the ﬂight regime.
9.2.3
Linearization by Inverse Nonlinearity
The simplest case of the introduction of nonlinearities into a control design is
that of inverse nonlinearities. It is sometimes possible to reverse the effect
Inverse nonlinearity
of some nonlinearities. For example, suppose we have a system whose output
is the square of the signal of interest:
y = x2.
(9.18)
One clever and rather obvious technique is to undo the nonlinearity by
preceding the physical nonlinearity with a square root nonlinearity,
x =

(.),
(9.19)
as shown in the next example. The overall cascaded system would then be
linear.
EXAMPLE 9.5
Linearization of the Rapid Thermal Processing (RTP) System
Consider the RTP system that uses a nonlinear lamp as an actuator, as shown
in Fig. 9.5. Suppose the input to the lamp is voltage V and the output is power
P and they are related by
P = V2.

648
Chapter 9 Nonlinear Systems
Controller
V¿
©
 - 
Y 
R
Dc(s)
Lamp
RTP plant
G(s) = 
0
P = V2
V
P
0.5
s + 0.08
 + 
Figure 9.5
Linearization through inverse nonlinearity
Design an inverse nonlinearity to linearize the system.
Solution.
We simply precede the lamp input nonlinearity with a square
root nonlinearity
V =
√
V′.
The overall open-loop cascaded system is now linear for any value of the
voltage:
Y = G(s)P = G(s)V2 = G(s)V′.
Thus we can use linear control design techniques for the dynamic compen-
sator, Dc(s). Note that a nonlinear element has been inserted in front of the
square root element to ensure that the input to this block remains nonnegative
at all times. The controller is then implemented as shown in Fig. 9.5. For a
detailed application of this method for control design, we refer the reader to
the RTP case study in Section 10.6.
9.3
Equivalent Gain Analysis Using the Root Locus
As we have tried to make clear, every real control system is nonlinear, and
the linear analysis and design methods we have described so far use linear
approximations to the real models. There is one important category of non-
linear systems for which linearization is not appropriate and for which some
signiﬁcant analysis (and design) can be done. This category comprises sys-
tems in which the nonlinearity has no dynamics and is well approximated as
a gain that varies as the size of its input signal varies, so-called memoryless
nonlinearities. Sketches of a few such nonlinear system elements and their
common names are shown in Fig. 9.6.
The stability of systems with memoryless nonlinearities can be studied
Memoryless nonlinearity
heuristically using the root locus. The technique is to replace the memoryless
nonlinearity by an equivalent gain K, and a root locus is plotted versus this
gain. For a range of input signal amplitudes, the equivalent gain will take
on a range of values, and the closed-loop roots of the system are examined
in this range as if the gain were ﬁxed. This is illustrated by the next several
examples.

9.3 Equivalent Gain Analysis Using the Root Locus
649
Figure 9.6
Nonlinear elements
with no dynamics:
(a) saturation;
(b) relay; (c) relay with
dead zone; (d) gain
with dead zone;
(e) preloaded spring,
or coulomb plus
viscous friction;
(f) quantization
u
y
-N
N
h
-h
u
y
u
y
h
-h
u
y
-N
N
-N
N
h
-h
u
y
-N
N
-q
-2q
2q
q
u
y
(a)
(b)
(c)
(d)
(e)
(f)
Slope K0
Slope K0
Figure 9.7
Dynamic system with
saturation
©
 + 
 - 
r
y
K
0.4
-0.4
-0.4
0.4
Saturation
s2
s + 1
Figure 9.8
Root locus of
(s + 1)2/s2, the system
in Fig. 9.7 with the
saturation removed
Re(s)
Im(s)
-1
K = 1
EXAMPLE 9.6
Changing Overshoot and Saturation Nonlinearity
Consider the system with saturation shown in Fig. 9.7. Determine the
stability properties of the system using the root-locus technique.
Solution.
The root locus of this system versus K with the saturation
removed is given by Fig. 9.8. At K = 1, the damping ratio is ζ = 0.5.
As the gain is reduced, the locus shows that the roots move toward the origin
of the s-plane with less and less damping. Plots of the step responses of this
system were obtained using the Simulink program. A series of step inputs r
with magnitudes r = 2, 4, 6, 8, 10, and 12 was introduced to the system, and

650
Chapter 9 Nonlinear Systems
the results are shown in Fig. 9.9. As long as the signal entering the saturation
remains less than 0.4, the system will be linear and should behave according
to the roots at ζ = 0.5. However, notice that as the input gets larger, the
response has more and more overshoot and slower and slower recovery. This
can be explained by noting that larger and larger input signals correspond
to smaller and smaller effective gain K, as seen in Fig. 9.10. From the root-
locus plot of Fig. 9.8, we see that as K decreases, the closed-loop poles
move closer to the origin and have a smaller damping ζ. This results in the
longer rise and settling times, increased overshoot, and greater oscillatory
response.
EXAMPLE 9.7
Stability of Conditionally Stable System Using the Root Locus
As a second example of a nonlinear response described by signal-dependent
A nonlinear example:
stability depends on input
magnitude
gain, consider the system with a saturation nonlinearity as shown in Fig. 9.11.
Determine whether the system is stable.
Solution. The root locus for the system, excluding the saturation, is plotted
in Fig. 9.12. From this locus we can readily calculate that the imaginary
axis crossing occurs at ω0 = 1 and K = 1
2. Systems such as this, which are
stable for (relatively) large gains but unstable for smaller gains, are called
Figure 9.9
Step responses of
system in Fig. 9.7 for
various input step sizes
20
18
16
14
12
10
8
6
4
2
0
0
5
10
15
20
25
30
Time (sec)
12
8
y
10
6
4
r = 2
Figure 9.10
General shape of the
effective gain of
saturation
ƒuƒ
K
N/a
a
Input magnitude
Gain

9.3 Equivalent Gain Analysis Using the Root Locus
651
Figure 9.11
Block diagram of a
conditionally stable
system
©
 + 
 - 
r
y
K
1
s3
(s + 1)2
1
u
Figure 9.12
Root locus for
G(s) = (s + 1)2/s3 from
system in Fig. 9.11
Imaginary axis
-6
-1
-2
-3
-4
-5
2
0
1
Real axis
-3
-2
-1
0
1
2
3
Figure 9.13
Step responses of the
system in Fig. 9.11
Amplitude
0
20
18
16
14
12
10
8
6
4
2
Time (sec)
r = 3.475
3
2
1
-1
0
1
2
3
4
5
6
7
8
9
conditionally stable systems. If K = 2, which corresponds to ζ = 0.5 on
Conditional stability
the locus, the system would be expected to show responses consistent with
ζ = 0.5 for small reference input signals. However, as the reference input
size gets larger, the equivalent gain would get smaller due to the saturation,
and the system would be expected to become less well damped. Finally,
the system would be expected to become unstable at some point for large
inputs. Step responses from nonlinear simulation of the system with K = 2
for input steps of size r = 1.0, 2.0, 3.0, and 3.4 are shown in Fig. 9.13. These
responses conﬁrm our predictions. Furthermore, the marginally stable case
shows oscillations near 1 rad/sec, which is predicted by the frequency at the
point at which the root locus crosses into the RHP.

652
Chapter 9 Nonlinear Systems
Figure 9.14
Block diagram of a
system with an
oscillatory mode
©
 + 
 - 
r
y
K
0.1
0.1
0.1
s2 + 0.2s + 1
1
s
1
u
EXAMPLE 9.8
Analysis and Design of System with Limit Cycle Using
the Root Locus
The ﬁnal illustration of the use of the root locus to give a qualitative descrip-
A nonlinear example: an
oscillatory system with
saturation
tion of the response of a nonlinear system is based on the block diagram in
Fig. 9.14. Determine whether the system is stable and ﬁnd the amplitude and
the frequency of the limit cycle. Modify the controller design to minimize
the effect of limit-cycle oscillations.
Solution.
This system is typical of electromechanical control problems
in which the designer perhaps at ﬁrst is not aware of the resonant mode
corresponding to the denominator term s2 + 0.2s + 1, (ω = 1, ζ = 0.1).
The root locus for this system versus K, excluding the saturation, is sketched
in Fig. 9.15. The imaginary axis crossing can be veriﬁed to be at ω0 = 1,
K = 0.2; thus a gain of K = 0.5 is enough to force the roots of the resonant
mode into the RHP, as shown by the dots. If the system gain is set at K = 0.5,
our analysis predicts a system that is initially unstable but becomes stable
as the gain decreases. Thus we would expect the response of the system
with the saturation to build up due to the instability until the magnitude is
sufﬁciently large that the effective gain is lowered to K = 0.2 and then stop
growing!
Plots of the step responses with K = 0.5 for three steps of size r = 1, 4,
and 8 are shown in Fig. 9.16(a). The control signal is shown in Fig. 9.16(b)
for r = 1 and a similar saturation situation occurs for the other two cases but
with the onset of the limit cycle later depending on the value of r. Again our
heuristic analysis is exactly correct: The error builds up to a ﬁxed amplitude
and then starts to oscillate at a ﬁxed amplitude. The oscillations have a
frequency of ≈1 rad/sec and hold constant amplitude regardless of the step
sizes of the input. In this case, the response always approaches a periodic
solution of ﬁxed amplitude known as a limit cycle, so-called because the
Limit cycle
response is cyclic and is approached in the limit as time grows large.
We can return to Fig. 9.13 and be easily convinced that the ﬁrst transient
to a step of size 3 is nearly a sinusoid. We can predict that the system is just
on the border of stability for an equivalent gain corresponding to a root-locus
gain of 1/2 when the locus crosses into the RHP. In order to prevent the limit
cycle, the locus has to be modiﬁed by compensation so that no branches
cross into the RHP. One common method of doing this for a lightly damped
oscillatory mode is to place compensation zeros near the poles at a frequency
such that the angle of departure of the root-locus branch from these poles is

9.3 Equivalent Gain Analysis Using the Root Locus
653
Figure 9.15
Root locus for the
system in Fig. 9.14
Image axis
-2
-1.5
-1
-2.5
-0.5
-3
0.5
1
0
Real axis
-1.5
-1
-0.5
0
0.5
1
1.5
K = 0.5
Figure 9.16
(a) Step responses of
the system in Fig. 9.14,
(b) control signal for
r = 1
0
50
100
150
Time (sec)
(a)
0
1
2
3
4
5
6
7
8
9
Amplitude
r = 8
r = 4
r = 1
0
5
10
15
20
25
Time (sec)
30
35
40
45
50
0.15
0.1
0.05
0
-0.05
-0.1
u
(b)

654
Chapter 9 Nonlinear Systems
toward the LHP, a procedure called phase stabilization earlier. Example 5.8
for collocated mechanical motion demonstrated that a pole-zero pair located
in this manner will often cause a locus branch to go from the pole to the
zero, looping to the left, and thus staying away from the RHP. Figure 9.17
shows the root locus for the system, 1/[s(s2 + 0.2s + 1.0)], including a
notch compensation with zeros located as just discussed. In addition, the
compensation also includes two poles to make the compensation physically
realizable. In this case, both poles were placed at s = −10, fast enough
to not cause stability problems with the system, yet slow enough that high-
frequency noise would not be ampliﬁed too much. Thus the compensation
used for the root locus is
Dc(s) = 123s2 + 0.18s + 0.81
(s + 10)2
,
where the gain of 123 has been selected to make the compensation's DC
gain equal to unity. This notch ﬁlter compensation attenuates inputs in the
vicinity of ω2
n = 0.81 or ωn = 0.9 rad/sec, so that any input from the
plant resonance is attenuated and is thus prevented from detracting from the
stability of the system. Figure 9.18 shows the system, including the notch
ﬁlter, and Fig. 9.19 shows the time response for two step inputs. Both inputs,
r = 2 and 4, are sufﬁciently large that the nonlinearity is saturated initially;
however, because the system is unconditionally stable, the saturation results
only in lowering the gain, so the response is slower than predicted by linear
analysis but still stable, as also predicted by our piecewise linear analysis. In
both cases the nonlinearity eventually becomes unsaturated, and the system
stabilizes to its new commanded value of r.
Figure 9.17
Root locus including
compensation
Re(s)
Im(s)
Im(s)
Im(s)
-0.5
-1.0
0.5
-0.5
-10.0
Figure 9.18
Block diagram of the
system with a notch
ﬁlter
©
 + 
 - 
r
y
0.1
0.1
s2 + 0.2s + 1
1
s
1
u
2
1
(s + 10)2
s2 + 0.18s + 0.81
0.81
100

9.3 Equivalent Gain Analysis Using the Root Locus
655
Figure 9.19
Step responses of the
system in Fig. 9.18
25
5
10
15
20
0
35
40
45
50
30
Time (sec)
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Amplitude
r = 4
r = 2
9.3.1
Integrator Antiwindup
In any control system the output of the actuator can saturate because the
dynamic range of all real actuators is limited. For example, a valve saturates
when it is fully open or closed, the control surfaces on an aircraft cannot
be deﬂected beyond certain angles from their nominal positions, electronic
ampliﬁers can produce only ﬁnite voltage outputs, etc. Whenever actuator
saturation happens, the control signal to the process stops changing and
the feedback path is effectively opened. If the error signal continues to be
applied to the integrator input under these conditions, the integrator output
will grow (windup) until the sign of the error changes and the integration
turns around. The result can be a very large overshoot, as the output must
grow to produce the necessary unwinding error, and poor transient response
is the result. In effect, the integrator is an unstable element in open loop and
must be stabilized when saturation occurs.3
Consider the feedback system shown in Fig. 9.20. Suppose a given
reference step is more than large enough to cause the actuator to saturate
at umax. The integrator continues integrating the error e, and the signal uc
keeps growing. However, the input to the plant is stuck at its maximum value,
namely u = umax, so the error remains large until the plant output exceeds
the reference and the error changes sign. The increase in uc is not helpful
since the input to the plant is not changing, but uc may become quite large if
saturation lasts a long time. It will then take a considerable negative error e
and the resulting poor transient response to bring the integrator output back
to within the linear band where the control is not saturated.
The solution to this problem is an integrator antiwindup circuit, which
"turns off" the integral action when the actuator saturates. (This can be done
3In process control, integral control is usually called reset control, and so integrator windup
is often called reset windup. Without integral control, a given setpoint of, say, 10 results in a
response of less value, say, 9.9. The operator must then reset to 10.1 to bring the output to the
desired value of 10. With integral control the controller automatically brings the output to 10
with a setpoint of 10; hence the integrator does automatic reset.

656
Chapter 9 Nonlinear Systems
Figure 9.20
Feedback system with
actuator saturation
©
 + 
 - 
y
s
kI
e1
e
kP
©
 + 
 + 
Plant
uc
uc
u
umax
umin
u
r
quite easily with logic, if the controller is implemented digitally, by including
a statement such as "if |u| = umax, kI = 0"; see Chapter 8.) Two equivalent
antiwindup schemes are shown in Fig. 9.21(a, b) for a PI controller. The
method in Fig. 9.21(a) is somewhat easier to understand, whereas the one
in Fig. 9.21(b) is easier to implement, as it does not require a separate
nonlinearity but uses the saturation itself.4 In these schemes, as soon as the
actuator saturates, the feedback loop around the integrator becomes active
and acts to keep the input to the integrator at e1 small. During this time the
integrator essentially becomes a fast ﬁrst-order lag. To see this, note that
we can redraw the portion of the block diagram in Fig. 9.21(a) from e to
uc as shown in Fig. 9.21(c). The integrator part then becomes the ﬁrst-order
lag shown in Fig. 9.21(d). The antiwindup gain, Ka, should be chosen to
be large enough that the antiwindup circuit keeps the input to the integrator
small under all error conditions.
The effect of the antiwindup is to reduce both the overshoot and the
control effort in the feedback system. Implementation of such antiwindup
schemes is a necessity in any practical application of integral control, and
omission of this technique may lead to serious deterioration of the response.
From the point of view of stability, the effect of the saturation is to open the
feedback loop and leave the open-loop plant with a constant input and the
controller as an open-loop system with the system error as input.
Purpose of antiwindup
The purpose of the antiwindup is to provide local feedback to
make the controller stable alone when the main loop is opened
by signal saturation, and any circuit that does this will perform as
antiwindup.5
4In some cases, especially with mechanical actuators such as an aircraft control surface or a
ﬂow control valve, it is not desirable and may cause damage to have the physical device bang
against its stops. In such cases it is common practice to include an electronic saturation with
lower limits than those of the physical device, so that the system hits the electrical stops just
before the physical device will saturate.
5A more sophisticated scheme might use an antiwindup feedback at a lower level of saturation
than that imposed by the actuator, so PD control continues for a time after integration has been
stopped. Any such scheme needs to be analyzed carefully to evaluate its performance and to
assure stability.

9.3 Equivalent Gain Analysis Using the Root Locus
657
Figure 9.21
Integrator antiwindup
techniques
+
-
u
s
kI
kP
+
+
uc
uI
uc
u
umax
umin
uc
u
umax
Ka
e
+
-
u
s
kI
kP
Ka
+
+
uc
uI
uc
u
umax
umin
e
+
-
+
-
s
kI
kP
Ka
+
+
uc
e
+
+
-
umax
s + KakI
kPs + kI
e
uc
(a)
(b)
(c)
(d)
©
©
©
©
©
©
©
©
EXAMPLE 9.9
Antiwindup Compensation for a PI Controller
Consider a plant with the transfer function for small signals,
G(s) = 1
s ,
and a PI controller,
Dc(s) = kp + kI
s = 2 + 4
s ,
in the unity feedback conﬁguration. The input to the plant is limited to ±1.0.
Study the effect of antiwindup on the response of the system.

658
Chapter 9 Nonlinear Systems
-
+
-
+
+
+
+
-
2
4
10
kp
kI
Ka
Step
Saturation
Integrator
Plant
Output
Control
s
1
s
1
©
©
©
©
Figure 9.22
Simulink diagram for the antiwindup example
Control
Output
-1.2
0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
-0.2
-0.4
-0.6
-0.8
-1.0
1.6
0
1
2
3
4
5
6
7
8
9
10
10
0
1
2
3
4
5
6
7
8
9
Time (sec)
(b)
Time (sec)
(a)
Without antiwindup
With antiwindup
Without antiwindup
With antiwindup
Figure 9.23
Integrator antiwindup: (a) step response; (b) control effort
Solution.
Suppose we use an antiwindup circuit with a feedback gain of
Ka = 10, asshownintheSimulinkblockdiagramofFig.9.22. Figure9.23(a)
shows the step response of the system with and without the antiwindup
element. Figure 9.23(b) shows the corresponding control effort. Note that
the system with antiwindup has substantially less overshoot and less control
effort.
9.4
Equivalent Gain Analysis Using Frequency
Response: Describing Functions
The behavior of systems containing any one of the nonlinearities shown in
Fig. 9.6 can be qualitatively described by considering the nonlinear element
as a varying signal-dependent gain. For example, with the saturation element
(Fig. 9.6a), it is clear that for input signals with magnitudes of less than h,

9.4 Equivalent Gain Analysis Using Frequency Response
659
the nonlinearity is linear with the gain N/h. However, for signals larger
than h, the output size is bounded by N, while the input size can get much
larger than h, so once the input exceeds h, the ratio of output to input goes
down. Thus, saturation has the gain characteristics shown in Fig. 9.10. All
actuators saturate at some level. If they did not, their output would increase
to inﬁnity, which is physically impossible. An important aspect of control
system design is sizing the actuator, which means picking the size, weight,
power required, cost, and saturation level of the device. Generally, higher
saturation levels require bigger, heavier, and more costly actuators. From a
control point of view, the key factor that enters into the sizing is the effect
of the saturation on the control system's performance.
A nonlinear analysis method known as describing functions, based on
the assumption that the input to the nonlinearity is sinusoidal, can be used to
predictthebehaviorofaclassofnonlinearsystems.Anonlinearelementdoes
not have a transfer function. However, for a certain class of nonlinearities, it
is possible to replace the nonlinearity by a frequency-dependent equivalent
gain for analysis purposes. We can then study the properties of the loop, such
as its stability. The describing function method is mostly a heuristic method,
and its aim is to try to ﬁnd something akin to a "transfer function" for a
nonlinearelement. Theideaisthatinresponsetoasinusoidalexcitation, most
nonlinearities will produce a periodic signal (not necessarily sinusoidal)
with frequencies being the harmonics of the input frequency. Hence one
may view the describing function as an extension of the frequency response
to nonlinearities. We can assume that in many cases we may approximate
the output by the ﬁrst harmonic alone, and the rest can be neglected. This
basic assumption means that the plant behaves approximately as a low-pass
ﬁlter, and this is luckily a good assumption in most practical situations. The
other assumptions behind the describing function are that the nonlinearity
is time invariant and that there is a single nonlinear element in the system.
Indeed, the describing function is a special case of the more sophisticated
harmonic balance analysis. Its roots go back to the early studies in the Soviet
Union and elsewhere. The method was introduced by Kochenburger in 1950
in the United States. He proposed that the Fourier series be used to deﬁne
an equivalent gain, Keq (Truxal, 1955, p. 566). This idea has proved to be
very useful in practice. The method is heuristic, but there are attempts at
establishing a theoretical justiﬁcation for the technique (Bergen and Franks,
1971; Khalil, 2002; Sastry, 1999). In fact the method works much better
than is warranted by the existing theory!
Consider the nonlinear element f (u) shown in Fig. 9.24. If the input
signal u(t) is sinusoidal of amplitude a, or
u(t) = a sin(ωt),
(9.20)
Figure 9.24
Nonlinear element
y
f
u

660
Chapter 9 Nonlinear Systems
then the output y(t) will be periodic with a fundamental period equal to that
of the input and consequently with a Fourier series described by
y(t) = a0 +
∞

i=1
ai cos( jωt) + bi sin( jωt),
(9.21)
= a0 +
∞

i=1
Yi sin( jωt + θi),
where
ai = 2
π
 π
0
y(t) cos( jωt) d(ωt),
(9.22)
bi = 2
π
 π
0
y(t) sin( jωt) d(ωt),
(9.23)
Yi =

a2
i + b2
i ,
(9.24)
θi = tan−1
ai
bi

.
(9.25)
Kochenburger suggested that the nonlinear element could be described by
the ﬁrst fundamental component of this series as if it were a linear system
with a gain of Y1 and phase of θ1. If the amplitude is varied, the Fourier
coefﬁcients and the corresponding phases will vary as a function of the
input signal amplitude, due to the nonlinear nature of the element. He called
this approximation a describing function (DF). The describing function is
Describing function
deﬁned as the (complex) quantity that is a ratio of the amplitude of the fun-
damental component of the output of the nonlinear element to the amplitude
of the sinusoidal input signal and is essentially an "equivalent frequency
response" function:
DF = Keq(a, ω) = b1 + ja1
a
= Y1(a, ω)
a
e jθ1 = Y1(a, ω)
a
∠θ1.
(9.26)
Hence the describing function is deﬁned only on the jω axis. In the case of
memoryless nonlinearities that are also an odd function [that is, f (−a) =
−f (a)], then the coefﬁcients of the Fourier series cosine terms are all zeros,
and the describing function is simply
DF = Keq(a) = b1
a ,
(9.27)
and is independent of the frequency ω. This is the usual case in control, and
saturation, relay, and dead-zone nonlinearities all result in such describing
functions. Computation of the describing function for the nonlinear charac-
teristics of Fig. 9.6 is generally straightforward, but tedious. It can be done
either analytically or numerically and may also be determined by an experi-
ment. We will now focus on computation of several describing functions for
some very common nonlinearities.

9.4 Equivalent Gain Analysis Using Frequency Response
661
EXAMPLE 9.10
Describing Function for a Saturation Nonlinearity
A saturation nonlinearity is shown in Fig. 9.25(a) and is the most common
nonlinearity in control systems. The saturation function (sat) is deﬁned as
sat(x) =
⎧
⎨
⎩
+1,
x > 1,
x,
|x| ≤1,
−1,
x < −1.
If the slope of the linear region is k and the ﬁnal saturated values are ±N,
then the function is
y = N sat
 k
N x

.
Find the describing function for this nonlinearity.
Solution. Consider the input and output signals of the saturation element
shown in Fig. 9.25. For an input sinusoid of u = a sin ωt with amplitude
a ≤N
k , the output is such that the DF is just a gain of unity. With a ≥N
k ,
we need to compute the amplitude and phase of the fundamental component
of the output. Since saturation is an odd function, all the cosine terms in
Eq. (9.21) are zeros and a1 = 0. According to Eq. (9.27),
Keq(a) = b1
a ,
so that
b1 = 2
π
 π
0
N sat
 k
N a sin ωt

sin ωt d(ωt),
since the integral for the coefﬁcient b1 over the interval ωt = [0, π] is simply
twice that of the interval ωt = [0, π/2]. Then
b1 = 4N
π

π
2
0
sat
 k
N a sin ωt

sin ωt d(ωt).
Figure 9.25
(a) Saturation
nonlinearity; (b) input
and output signals
u
y
-N
-h
N
h
0
y
y
u
u
t
u, y
-N
t0
t1
t2
N
0
(a)
(b)

662
Chapter 9 Nonlinear Systems
We can now divide the integral into two parts corresponding to the linear
and saturation parts. Let us deﬁne the saturation time ts as the time when
ts = 1
ω sin−1
 N
ak

or
ωts = sin−1
 N
ak

.
(9.28)
Then
b1 = 4Nω
πa
 ωts
0
sat
 k
N a sin ωt

sin ωt dt +

π
2
ωts
sin ωt dt

= 4Nω
πa
 ωts
0
k
N a sin2 ωt dt +

π
2
ωts
sin ωt dt

= 4Nω
πa
 ωts
0
k
2N a(1 −cos 2ωt) dt +

π
2
ωts
sin ωt dt

= 4Nω
πa
 k
2N at |ts
0 −k
2N a sin 2ωt |ts
0 −1
ω(cos π
2 −cos ts)

.
But using Eq. (9.28), we have
sin ωts = N
ka
and
cos ωts =

1 −
 N
ka
2
.
We ﬁnally obtain
Keq(a) =
⎧
⎨
⎩
2
π

k sin−1  N
ak

+ N
a

1 −
 N
ka
2
,
ka
N > 1,
k,
ka
N ≤1.
(9.29)
Figure 9.26 shows a plot of Keq(a) indicating that it is a real function indepen-
dent of frequency and results in no phase shifts. It is seen that the describing
function is initially a constant and then decays essentially as a function of
the reciprocal of the input signal amplitude, a.
Figure 9.26
Describing function for
saturation nonlinearity
with k = N = 1
a
0
1
2
3
4
5
6
7
8
9
10
Keq
1.0
0.8
0.6
0.4
0.2
0

9.4 Equivalent Gain Analysis Using Frequency Response
663
EXAMPLE 9.11
Describing Function for a Relay Nonlinearity
Find the describing function for the relay or sgn function shown in Fig. 9.6(b)
and deﬁned as
sgn(x) =
⎧
⎨
⎩
+1
if x > 0,
0
if x = 0,
−1
if x < 0.
Solution. The output is a square wave of amplitude N for every size input;
thus Y1 =
4N
π
and Keq =
4N
πa. The solution can also be obtained from
Eq. (9.29) if we let k →∞. For small angles,
sin−1
 N
ak

∼= N
ak ,
and thus, from Eq. (9.27), we have
Keq(a) = 2
π

k
 N
ak

+ N
a

= 4N
πa .
(9.30)
The preceding two nonlinearities were memoryless. Next we consider
a nonlinearity with memory. Nonlinearities with memory occur in many
applications, including magnetic recording devices, backlash in mechanical
systems, and in electronic circuits. Consider the bistable electronic circuit
shown in Fig. 9.27 that is called a Schmitt trigger (Sedra and Smith, 1991).
This circuit has memory. Referring to Fig. 9.28, if the circuit is in the state
where vout = +N, then positive values of vin do not change the state. To
"trigger" the circuit into the state vout = −N, we must make vin negative
enough to make v negative. The threshold value is h = NR1
R2 . The Schmitt
trigger is employed commonly in spacecraft control (Bryson, 1994). We next
ﬁnd the describing function for a hysteresis nonlinearity.
EXAMPLE 9.12
Describing Function for a Relay with Hysteresis Nonlinearity
Consider the relay function with hysteresis shown in Fig. 9.29(a). Find the
describing function for this nonlinearity.
Solution. A system with hysteresis tends to stay in its current state. Until the
input to the signum function is past the value h, it is not possible to determine
Figure 9.27
Schmitt trigger circuit
R1
R2
-
+
-
+
yin
yout
y

664
Chapter 9 Nonlinear Systems
Figure 9.28
Hysteresis nonlinearity
for Schmitt trigger
circuit
Vin
Vout
-h
+N
-N
h
0
Figure 9.29
(a) Hysteresis
nonlinearity; (b) input
and output to the
nonlinearity
u
y
-N
-h
h
N
0
y
y
u
u
t
-N
t1
t2
N
(a)
(b)
u, y
the output uniquely without knowing its past history. That implies that we
have a nonlinearity with memory. The output is a square wave with amplitude
N as long as the input amplitude a is greater than the hysteresis level h. From
Fig. 9.29(b), it is seen that the square wave lags the input in time. The lag
time can be computed as the time when
a sin ωt = h
or
ωt = sin−1
h
a

.
(9.31)
Because the phase angle is known for all frequencies,
Keq(a) = 4N
πa ∠−sin−1
h
a

= 4N
πa e
−j sin−1
h
a

,
(9.32)
= 4N
πa
⎛
⎝

1 −
h
a
2
−jh
a
⎞
⎠.
(9.33)
The describing function is then given by
Keq(a) =
⎧
⎪⎨
⎪⎩
4N
πa

1 −

h
a
2
−j h
a

,
a ≥h,
0,
a < h.
(9.34)
The describing function is plotted in Fig. 9.30. The magnitude is proportional
to the reciprocal of the input signal amplitude, and the phase varies between
−90o and 0o.

9.4 Equivalent Gain Analysis Using Frequency Response
665
Figure 9.30
Describing function for
the hysteresis
nonlinearity for h = 0.1
and N = 1: (a)
magnitude; (b) phase
Magnitude, Keq
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
a
0
2
4
6
8
10
12
14
Phase, Keq, deg
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
a
(a)
(b)
-100
-80
-60
-40
-20
0
9.4.1
Stability Analysis Using Describing Functions
The Nyquist theorem can be extended to deal with nonlinear systems whose
nonlinearities have been approximated by describing functions. In the stan-
dard linear system analysis, the characteristic equation is 1+KL = 0, where
the loop gain is L = DcG and
L = −1
K .
(9.35)
As described in Section 6.3, we look at the encirclements of the −1/K point
to determine stability. With a nonlinearity represented by the describing
function, Keq(a), the characteristic equation is of the form 1+Keq(a)L = 0,
and it follows that
L = −
1
Keq(a).
(9.36)
Now we have to look at the intersection of L with a plot of −1/Keq(a).
If the curve L intersects −1/Keq(a), then the system will oscillate at the
crossing amplitude, al, and the corresponding frequency, ωl, keeping in
mind the approximate nature of the describing function. We then look for
encirclementstodecidewhetherthesystemwouldbestableforthatparticular
value of the gain, as if it were a linear system. If so, we deduce that the
nonlinear system is stable. Otherwise, we infer that the nonlinear system is
unstable.
Figure 9.31 shows an example of an otherwise linear system, except for
a single nonlinearity. The nonlinear elements may indeed have a beneﬁcial
effect and may limit the amplitude of oscillations. The describing function
analysis can be used to determine the amplitude and frequency of the limit
cycle. Strictly speaking, a limit cycling system can be considered to be
unstable. In reality, the trajectory of the limit cycling is conﬁned to a ﬁnite
region of the state space. If this region is within allowable performance,

666
Chapter 9 Nonlinear Systems
Figure 9.31
Closed-loop system with
a nonlinearity
f
Nonlinear
element
G(s)
©
 - 
 + 
y
R
Figure 9.32
Nyquist plot and
describing function to
determine limit cycle
0
Im(G)
Re(G)
-0.1j
+0.1j
-0.5
-1
v = 1
a = 0.63
1
Keq(a)
-
1
K
-
q ‹- a
Nyquist plot
then the response is tolerable. In some cases, the limit cycling is a beneﬁcial
effect (see the case study in Section 10.4). The system does not possess
asymptotic stability, since the system does not come to a rest at the origin
of the state space. The describing function can be beneﬁcial in determining
the conditions under which instability results and can even suggest remedies
in eliminating instability, as illustrated in the next example, in which the
Nyquist plot of the linear loop gain, L, as well as the negative reciprocal of
the describing function, −1/Keq(a), are superimposed. The point at which
they cross corresponds to the limit cycle. To determine the amplitude and
frequency of the limit cycle, we can rewrite Eq. (9.36) as follows:
Re{L( jω)}Re{Keq(a)} −Im{L( jω)}Im{Keq(a)} + 1 = 0,
(9.37)
Re{L( jω)}Im{Keq(a)} + Im{L( jω)}Re{Keq(a)} = 0.
We can then solve these two equations for the possible two unknown
values of the limit-cycle frequency, ωl, and the corresponding amplitude, al,
as illustrated in the ensuing examples.
EXAMPLE 9.13
Conditionally Stable System
Consider the feedback system in Fig. 9.14. Determine the amplitude and the
frequency of the limit cycle using the Nyquist plot.
Solution. The Nyquist plot of the system is superimposed on −1/Keq(a) as
shown in Fig. 9.32. Note that the negative of the reciprocal of the describing
function, using Eq. (9.29), is

9.4 Equivalent Gain Analysis Using Frequency Response
667
−
1
Keq(a) = −
1
2
π

k sin−1  N
ak

+ N
a

1 −
 N
ka
2
= −
1
2
π

sin−1  0.1
a

+ 0.1
a

1 −
 0.1
a
2,
which is a straight line that is coincident with the negative real axis and
is parameterized as a function of the input signal amplitude, a. The point
of the intersection of the two curves at −0.5 corresponds to the limit-cycle
frequency of ωl = 1.A plot of the describing function for k = 1 and N = 0.1
is shown in Fig. 9.33, and a magnitude of Keq = 0.2 corresponds to an input
amplitude of al = 0.63.
Alternatively, from the root locus of our example shown in Fig. 9.15,
the gain at the imaginary-axis crossover is 0.2; then, from Eq. (9.29), we
have
Keq = 2
π
⎛
⎝sin−1
0.1
a

+ 0.1
a

1 −
0.1
a
2
⎞
⎠= 0.2.
If we approximate the arcsine function by its argument as
sin−1
0.1
a

≈0.1
a ,
then
2
π
⎛
⎝
0.1
a

+ 0.1
a

1 −
0.1
a
2
⎞
⎠= 0.2,
Figure 9.33
Describing function for
saturation nonlinearity
with N = 0.1 and k = 1
0 0
2
4
a
6
8
10
0.2
0.4
Keq
0.6
0.8
1

668
Chapter 9 Nonlinear Systems
which leads to the polynomial equation
π2a4 −2πa3 + (0.1)2 = 0,
and we ﬁnd the relevant solution to be a = 0.63. By measurement on the
time history of Fig. 9.16, the amplitude of the oscillation is 0.62, which is
in good agreement with our prediction.
For systems with nonlinearities that have memory, we can also use the
Nyquist technique, as illustrated in the next example.
EXAMPLE 9.14
Determination of Stability with a Hysteresis Nonlinearity
Consider the system with a hysteresis nonlinearity shown in Fig. 9.34. Deter-
mine whether the system is stable and ﬁnd the amplitude and the frequency
of the limit cycle.
Solution. The Nyquist plot for the system is shown in Fig. 9.35. The neg-
ative reciprocal of the describing function for the hysteresis nonlinearity is
−
1
Keq(a) = −
1
4N
πa

1 −

h
a
2
−j h
a
 = −π
4N
 
a2 −h2 + jh
!
.
Figure 9.34
Feedback system with
hysteresis nonlinearity
1.0
0.1
©
 + 
 - 
R
Y 
G(s) =
1
s(s + 1)
Figure 9.35
Nyquist plot and DF to
determine limit-cycle
properties
Im(G)
Re(G)
1
Keq(a)
-
v = 2.2
a = 0.24
Nyquist plot
0
-0.0785
-0.1714
a = h = 0.1
q ‹- a

9.4 Equivalent Gain Analysis Using Frequency Response
669
In this case N = 1 and h = 0.1, and we have
−
1
Keq(a) = −π
4
 
a2 −0.01 + j0.1
!
.
This is a straight line parallel to the real axis that is parameterized as a
function of the input signal amplitude a and is also plotted in Fig. 9.35. The
intersection of this curve with the Nyquist plot yields the frequency and the
corresponding amplitude of the stable limit cycle. We can also determine the
limit-cycle information analytically:
−
1
Keq(a) = −π
4
 
a2 −0.01 + j0.1
!
= G( jω) =
1
jω( jω + 1).
Clearing the denominator in the preceding equation, we have
π
4

a2 −0.01ω2 + 0.1π
4
ω −1 + j
0.1π
4
ω2 −π
4

a2 −0.01ω

= 0.
Setting the real and imaginary parts equal to zero yields two equations
and two unknowns. The relevant solution is ωl = 2.2 rad/sec and al = 0.24.
A Simulink implementation of the closed-loop system is shown in Fig. 9.36.
The step response of the system is shown in Fig. 9.37, and the limit cycle
has an amplitude of al = 0.24 and a frequency of ωl = 2.2 rad/sec and is
well predicted by our analysis.
Figure 9.36
Simulink diagram for
system with hysteresis
Transfer fcn
To
workspace
Simout
Step
Scope
Relay
+
-
1
s2 + s
Figure 9.37
Step response
displaying limit-cycle
oscillations
Time (sec)
0
5
10
15
20
25
30
35
40
45
50
Output, y
0.8
0.6
0.4
0.2
0
-0.2
1.0
1.2
1.4

670
Chapter 9 Nonlinear Systems
9.5
Analysis and Design Based on Stability
The central requirement of any control system is stability, and the design
△
methods we have studied are based on this fact. The root locus is a plot
of closed-loop poles in the s-plane, and the designer is always aware of
the fact that if a root strays into the right half of the plane, the system
will be unstable. Designs based on the state representation include pole
placement, where the desired locations of the poles are, of course, selected
to be well within the stable region. In a similar fashion, Nyquist proved
conditions for stability based on the frequency response, and designers are
aware of the encirclement requirements of their plots or, equivalently, of
the gain and phase margins of stability margins in the Bode plots. Prior to
either of these methods, mathematicians studied the stability of ordinary
differential equations (ODE), and these and other sophisticated techniques
are needed to face the problems of nonlinear systems. We begin with a
graphical representation of ODE solutions known as the phase plane and
introduce the methods of Lyapunov and others as an introduction to this area
of control design.
9.5.1
The Phase Plane
Whereas the root locus and the frequency-response methods consider the
system response indirectly via either the poles and zeros of the transfer
function or the gain and phase of the frequency response, the phase plane
considers the time response directly by plotting the trajectory of the state
variables. Although direct visualization restricts the method to second-order
systems having only two state variables, the ability of the method to consider
nonlinearities, as well as to give new insight into linear systems, makes a
quick look at the technique well worthwhile.
To illustrate the ideas of the phase plane, consider a ﬁctional motor
system shown in Fig. 9.38 with the open-loop transfer function
G(s) =
1
s(Ts + 1).
If we assume that T = 1/6 and the ampliﬁer is (for the moment) not
subject to saturation and has gain K where K = 5T, the state equations for
the closed-loop system can be written as
˙x1 = x2,
(9.38)
˙x2 = −5x1 −6x2,
(9.39)
y = x1.
(9.40)
Figure 9.38
An elementary position
feedback system with a
nonlinear actuator
©
 + 
 - 
r
e
s
1
©
 + 
 - 
u
Ts
1
y
x2
x1

9.5 Analysis and Design Based on Stability
671
Because these equations are time invariant, the time can be eliminated by
dividing Eq. (9.38) into Eq. (9.39), with the result that
dx2
dx1
= −5x1 −6x2
x2
.
(9.41)
The solution to this equation gives a plot of x2 versus x1 or, in other words,
a trajectory in the phase plane of coordinates (x1, x2).6 Before plotting
Eq. (9.41), it is useful to consider the system equations ﬁrst in matrix form
as ˙x = Ax for which
A =

0
1
−5
−6

.
If in this equation we assume that x = xoest, where both s and xo are
constants, then ˙x = xosest, and the equation can be reduced as follows:
˙x = Ax,
(9.42)
xosest = Axoest,
(9.43)
[sI −A]xoest = 0,
(9.44)
[sI −A]xo = 0.
(9.45)
Here it should be recognized that Eq. (9.45) is the eigenvector equation for
the matrix A, which, in component form, is
 s
−1
5
s + 6
  x01
x02

=
 0
0

.
(9.46)
As described in Appendix WE (www.fpe7e.com), Eq. (9.46) has a solution
only if the determinant of the coefﬁcient matrix is zero, for which
s(s + 6) + 5 = 0,
(9.47)
(s + 1)(s + 5) = 0.
(9.48)
The two values of s for which the equation has a solution are the eigenvalues
s = −1 and s = −5. If we substitute s = −1 into Eq. (9.46), we obtain
 −1
−1
5
−1 + 6
  x01
x02

=
 0
0

,
(9.49)
6If the slope dx2/dx1 is set to a constant, the relation between x2 and x1 is a straight line. If
the known values of slopes are marked along a set of these lines, the trajectories can be readily
sketched. For example, along the x1 axis, where x2 = 0, the slope is ∞and the trajectories are
vertical. This method is called the method of isoclines.

672
Chapter 9 Nonlinear Systems
from which the solution for the initial state vector is x02 = −x01. This line
in the state space is the eigenvector corresponding to the eigenvalue s = −1.
If we repeat this process with s = −5, the result is
 −5
−1
5
−5 + 6
  x01
x02

=
 0
0

,
(9.50)
and in this case the solution for the eigenvector is x02 = −5x01.
Consider what all this means. We started with the assumption that the
time solution for the state is a constant times an exponential. We found that
this is possible only if the exponential is either e−t or e−5t. In the ﬁrst case,
the state must lie along the vector x02 = −x01, and in the second, the state
must lie along the vector x02 = −5x01. With this knowledge, we compute
the solutions to Eq. (9.38) and Eq. (9.39) for different initial conditions and
plot x1(t) versus x2(t) in Fig. 9.39. In the ﬁgure, the two eigenvectors are
identiﬁed by the thick lines. When we look at these curves, it is clear that all
the paths start parallel to the (fast!) eigenvector corresponding to s = −5 and
quickly move to the (slow!) one corresponding to s = −1. All trajectories
approach the equilibrium point at the origin of the state space.
The plot will be substantially changed if the ampliﬁer saturates. For
example, if the ampliﬁer saturates at a value of u = 0.5, then the velocity,
x2, will rapidly approach this value and will be stuck there until the position
reaches a value that brings the ampliﬁer out of saturation. The new plot is
shown in Fig. 9.40.
Notice that in the linear region the motion is almost entirely along the
slow eigenvector. Finally we note that the phase-plane portrait changes again
when the poles are complex. In that case, the motion of the state variables
are composed of damped sinusoids and the plot of x1 versus x2 is along a
spiral. A collection of trajectories for various initial conditions is shown in
Fig 9.41.
Figure 9.39
Phase-plane plot of a
node with poles at
s = −1 and s = −5
x1
-1.5
-1.0
-0.5
0
0.5
1.0
1.5
x2
0
-0.2
-0.4
-0.6
-0.8
-1.0
0.4
0.2
0.8
0.6
1.0
s = -5
s = -1
x02 = -x01
x02 = -x01

9.5 Analysis and Design Based on Stability
673
Figure 9.40
Phase-plane plot with
saturation
x1
-8
-6
-2
-4
0
4
2
6
8
x2
0
-0.5
-1.0
-1.5
-2.0
1.0
0.5
1.5
2.0
Figure 9.41
Phase-plane plot for a
system with complex
poles
Phase plane for a focus
x2
0
-1
-2
-3
-4
2
1
3
4
x1
-1.5
-1.0
-0.5
0
0.5
1.0
1.5
These few examples just scratch the surface of phase-plane analysis but
give some idea of the use of this format in helping a designer to visualize
dynamic responses. Note that this visualization is mostly useful for systems
with two (dominant) modes. For higher order systems, the concept still holds
but visualization becomes signiﬁcantly more difﬁcult.
Bang-Bang Control
One example of design for a nonlinear system based on the phase plane
is that of optimal minimum time control in the face of control saturation.

674
Chapter 9 Nonlinear Systems
For our purposes here, the simplest version of this widely used technique is
introduced: that of the 1/s2 plant. The equations are
¨y = u,
(9.51)
e = y −yf ,
(9.52)
where y(0) = ˙y(0) = 0, yf is a constant, and the control is constrained to be
|u| ≤1. The problem is to drive the error to be identically zero in minimum
time. If we deﬁne state variables as x1 = e and x2 = ˙e = ˙y, the equations
reduce to
˙x1 = x2,
(9.53)
˙x2 = u,
(9.54)
x1(0) = −yf ,
(9.55)
x1(tf ) = x2(tf ) = 0,
(9.56)
and the problem is to minimize tf . Intuitively, this is the problem of the eager
driver who wishes to speed from one stop to the next in minimum time. She
would put the pedal to the metal for a time and then switch to stand on the
brakes as the car skids to a stop at just the right place. A basic result of the
theory of optimal control conﬁrms this intuitive idea that the solution to this
problem is, if yf > 0, to apply full positive control for a time and then to
switch to full negative control at just the right time to cause the error to reach
the origin and stop there. To study the case, a plot of the trajectories of the
plant in the phase plane for the two cases of u = 1 and u = −1 is given in
Fig. 9.42. For u = +1, the trajectories start in the fourth quadrant and move
up to the ﬁrst. For u = −1, they start in the second quadrant and move down
to the third.
Figure 9.42
Phase-plane of the 1/s2
plant for ±1 controls
-150
-100
-50
0
50
100
150
25
20
15
10
5
0
-5
-10
-15
-20
-25
u = -1
u = + 1
x2
x1

9.5 Analysis and Design Based on Stability
675
Two segments of this family are of particular interest: those that pass
through the origin. Once the path reaches one of these, a constant control
will bring the state to the desired ﬁnal resting place. Therefore, for any initial
condition, once the trajectory reaches one of the two curves going through
the origin, the correct action is to switch the control (u = +1 to −1, or
u = −1 to +1) so that the trajectory will follow that curve to the origin. The
"switching curve" is plotted in Fig. 9.43.
For a second-order plant, the switching curve can be found by reversing
the time in the equations of motion, setting the initial state to zero and
applying the maximum control. The process can be repeated with minimum
control to sweep out the other branch of the curve.
For any initial condition above the curve, u = −1 is applied and for any
initial condition below the curve, u = +1 is used. As described, the result
will be a minimum-time response. Notice that the curve has vertical slope
at the origin; as a result, the implementation is extremely sensitive in this
neighborhood. A modiﬁed version known as the proximate time-optimal
system (PTOS) used in the computer disk drive industry was studied by
Workman (1987). The modiﬁcation consists of shifting the curves a bit and
replacing the inﬁnite slope at the origin with a ﬁnite-slope, linear control
region. The result has been widely used for hard-disk drives and similar
systems and is also called "sliding mode" control.
Typical responses for a time-optimal system and for a PTOS sys-
tem generated with Simulink are given in Figs. 9.44 to 9.46. Notice that
the response times are almost exactly the same, but while the time opti-
mal system control has a violent chatter at the end where the switching
curve has inﬁnite slope, the output of the PTOS system slips into its ﬁnal
value smoothly. For a more exact study, we need to turn to the nonlinear
equations.
Figure 9.43
Switching curve for the
1/s2 plant
-100 -80
-60 -40
-20
0
20
40
60
80
100
15
10
5
0
-5
-10
-15
x2
x1

676
Chapter 9 Nonlinear Systems
Figure 9.44
Response of a
time-optimal system
y
0
1
2
3
4
5
Time (sec)
0
1
2
3
4
5
u
0
1
2
3
5
4
6
Time (sec)
Output for the time-optimal system
Control for the time-optimal system
-1.0
-0.5
0
0.5
1.0
Figure 9.45
Response of a PTOS
system
y
0
1
2
3
4
5
Time (sec)
0
1
2
3
4
u
0
1
2
3
4
5
Time (sec)
Output for the PTOS
Control for the PTOS, r = 0.9
-1.0
-0.5
0
0.5
1.0
Figure 9.46
Simulink diagram for
position
Scope
s
1
Step
Saturation
Integrator1
s
1
Integrator
-
+
-
+
e
u
x2
x1 y
r

9.5 Analysis and Design Based on Stability
677
9.5.2
Lyapunov Stability Analysis
The stability of motion as studied by Lyapunov involves sophisticated mathe-
maticsbeyondthescopeofthistext. Herewewillpresentheuristicarguments
giving the ﬂavor of the theory and state a few of the most basic results. Lya-
punov presented two methods for the study of stability of motion described
by systems of ODEs. His indirect or ﬁrst method is based on linearization
of the equations and drawing conclusions about the stability of the nonlinear
system by considering the stability of the linear approximation. He proved
the results of the ﬁrst method by use of his direct or second method, in
which the nonlinear equations are considered directly. A discussion of the
indirect method serves to introduce both methods. The problem requires a
new deﬁnition of stability suitable for vector-matrix equations. Intuitively,
we say a system is stable if initial conditions of moderate size result in a
response that remains of moderate size. To express this mathematically, ﬁrst
we need a deﬁnition of "size." For this we use the norm of a vector for which
the symbol is ∥x∥. Of the many possible deﬁnitions, the familiar Euclidean
measure is selected and deﬁned by its square as ∥x∥2 = xTx = "n
i=1 x2
i .
With this idea, the deﬁnition of stability used is that if one is given a sphere
of any radius ϵ, one can ﬁnd a smaller sphere of radius δ such that if the
initial state is inside δ, then the trajectory will, for all time, remain inside ϵ.
A bit more formally, the system is stable if, for any given ϵ > 0, one can
Stability in the sense of
Lyapunov
ﬁnd a δ > 0 such that if ||x(0)|| < δ, then ||x(t)|| < ϵ for all t. If the state is
not only stable, but in the limit as t →∞, ||x(t)|| →0, the system is said to
be asymptotically stable. If, for any ϵ, it is possible to select δ arbitrarily
large, then the system is said to be stable in the large.
Study of these matters begins with the time-invariant ODE equation
˙x = f(x),
(9.57)
for which the linear approximation is
˙x = Ax + g(x).
(9.58)
In this equation, it is assumed that all the linear terms are in Ax and higher-
order terms are in g(x), in the sense that when x gets small, g(x) gets small
faster, as expressed by
lim
∥x∥→0
∥g(x)∥
∥x∥
= 0.
(9.59)
Lyapunov's second method begins with the intuitive notion that one measure
of the size of the state of a physical system is the total energy stored in the
system at any instant and the observation that when the stored energy is
no longer changing, the system must be at rest. For an electric circuit, for
example, the electric energy is proportional to the square of the capacitor
voltages and the magnetic energy is proportional to the square of the inductor
currents. Lyapunov extracted the abstract essence of this idea and deﬁned
a scalar function of the state V(x), called a Lyapunov function, having the
following properties:
Lyapunov function
1. V(0) = 0;
2. V(x) > 0, ∥x∦= 0;

678
Chapter 9 Nonlinear Systems
3. V is continuous and has continuous derivatives with respect to all
components of x;
4. ˙V(x) = ∂V
∂x ˙x = ∂V
∂x f(x) ≤0 along trajectories of the equation.
The ﬁrst three conditions ensure that in a neighborhood of the origin
the function is like a smooth bowl sitting at the origin of the state space.
The fourth condition, which obviously depends on the equations of motion,
ensures that if δ is selected so that the initial conditions are deeper in the
bowl than any part of the ball deﬁned by ϵ, the trajectory never climbs higher
on the bowl than it was at the start and so remains within ϵ, and the system
will be stable. Furthermore, if condition 4 is strengthened to be V(x) < 0,
then the value of the function must fall to zero and, by condition 1, the state
also goes to zero. The stability theorem, which is the basis for Lyapunov's
second method, states that
Lyapunov's second
method
If a Lyapunov function can be found for a system, then the motion is
stable and, furthermore, if V(x) < 0, the motion is asymptotically
stable. The second method is to search for a Lyapunov function.
The hard part for the application of this theory is the statement "If a
Lyapunov function can be found." Only in the linear case is a prescription
given for ﬁnding a Lyapunov function; otherwise the theory only gives the
engineer a hunting license to look for such a function. We are now in a
position to consider the indirect method for stability of Eq. (9.58).
Perhaps because energy in simple systems is a sum of the squares of the
variables, for this problem Lyapunov considers a quadratic candidate for V
by supposing that a symmetric positive deﬁnite matrix P can be found and
the function deﬁned as V(x) = xTPx. Clearly the ﬁrst three conditions are
satisﬁed by this function; the fourth condition must be tested before it can
be concluded that we have a Lyapunov function. The calculation of ˙V is
V(x) = xTPx,
(9.60)
˙V(x) = ˙xTPx + xTP˙x
(9.61)
= (Ax + g(x))TPx + xTP(Ax + g(x))
(9.62)
= xT(ATP + PA)x + 2xTPg(x).
(9.63)
A basic matrix result, known as a Lyapunov equation, is
ATP + PA = −Q,
(9.64)
and he showed that if A is a stability matrix having all its eigenvalues in the
LHP, then for any positive deﬁnite matrix Q, the solution P of this equation
will also be positive deﬁnite. The argument from here is to select Q and
solve for P. Then, if the eigenvalues of A are in the LHP, P will be positive
deﬁnite, so V(x) is a possible Lyapunov function and
˙V(x) = −xTQx + 2xTPg.
(9.65)
The ﬁnal part of the argument is to note that, by Eq. (9.59), if x is small
enough, then the ﬁrst term of Eq. (9.65) will dominate, the fourth condition

9.5 Analysis and Design Based on Stability
679
is satisﬁed, V is a Lyapunov function, and the system has been proven to
be stable. Note that the requirement that x be small enough guarantees only
that there is a neighborhood of the origin which is stable. Further conditions
are needed to show that the bowl deﬁned by V extends to ∞in all directions
as ||x|| tends to ∞(and not before!), so that stability holds for all states and
is "in the large."
There is also an instability theorem which shows that if any eigenvalue
of A is in the RHP, then the origin will be unstable. If all the poles of A are in
the LHP except for some simple poles on the imaginary axis, then stability
depends on further properties of the nonlinear terms, g(x). With this result
in hand, the ﬁrst or indirect method of Lyapunov can be stated:
Lyapunov's ﬁrst method
1. Find the linear approximation and compute the eigenvalues of A.
2. If all the eigenvalues are in the LHP, then there is a region of stability
about the origin.
3. If at least one of the eigenvalues is in the RHP, then the origin is unstable.
4. If there are simple eigenvalues on the imaginary axis and all other values
are in the LHP, then no statement about stability can be made based on
this method.
EXAMPLE 9.15
Lyapunov Stability for a Second-Order System
Use Lyapunov's method to ﬁnd conditions for the stability of a second-order
linear system described by the state matrix
A =
 −α
β
−β
−α

.
Solution. For the linear case we can take any positive deﬁnite Q we like;
the simplest is Q = I. The corresponding Lyapunov equation is
 −α
−β
β
−α
  p
q
q
r

+
 p
q
q
r
  −α
β
−β
−α

=
 −1
0
0
−1

.
(9.66)
Multiplying out Eq. (9.66) and equating coefﬁcients, we get
−αp −βq −αp −βq = −1,
(9.67)
−αq −βr + βp −αq = 0,
(9.68)
βq −αr + βq −αr = −1.
(9.69)
Equations (9.67) to (9.69) are readily solved to get p = r = 1/2α, q = 0,
so that
P =

1
2α
0
0
1
2α

,
and the determinants are 1/2α > 0 and 1/4α2 > 0. Thus P > 0, so we
conclude that the system is stable if α > 0.

680
Chapter 9 Nonlinear Systems
For systems with many state variables and nonnumeric parameters,
solution of the Lyapunov equation can be burdensome, but the result is
an equivalent alternative to Routh's method for computing the conditions
for stability in a system with literal parameters.
EXAMPLE 9.16
Lyapunov's Direct Method for a Position Feedback System
Consider the position feedback system modeled in Fig. 9.38. Illustrate the
use of the direct method on this nonlinear system. Simulate the system using
Simulink, assuming that T = 1, and evaluate the step response of the system.
Solution. We assume that the actuator, which is perhaps only an ampliﬁer
in this case, has a signiﬁcant nonlinearity, which is shown in the ﬁgure as a
saturation but is possibly more complex. We will assume only that u = f (e),
where the function lies in the ﬁrst and third quadrants so that
# e
0 f (e) de > 0.
We also assume that f (e) = 0 implies that e = 0, and we will assume that
T > 0, so the system is open-loop stable. The equations of motion are
˙e = −x2,
(9.70a)
˙x2 = −1
T x2 + f (e)
T .
(9.70b)
For a Lyapunov function, consider something like kinetic plus potential
energy:
V = T
2 x2
2 +
 e
0
f (σ) dσ.
(9.71)
Clearly, V = 0 if x2 = e = 0 and, because of the assumptions about f ,
V > 0 if x2
2 + e2 ̸= 0. To see whether the V in Eq. (9.71) is a Lyapunov
function, we compute ˙V as follows:
˙V = Tx2˙x2 + f (e)˙e
= Tx2

−1
T x2 + f (e)
T

+ f (e)(−x2)
= −x2
2.
Hence ˙V ≤0 and the origin is Lyapunov stable. Moreover, ˙V is always
decreasing if x2 ̸= 0, and Eq. (9.70b) indicates that the system has no
trajectory with x2 ≡0, except x2 = 0. Thus we can conclude that the
system is asymptotically stable for every f that satisﬁes two conditions:
(1)
#
f dσ > 0 and (2) f (e) = 0 implies that e = 0. The Simulink diagram
for the system is shown in Fig. 9.46 for T = 1. The step response of the
system is shown in Fig. 9.47.
As we mentioned earlier, the study of the stability of nonlinear systems is
vast, so we have only touched here on some important points and methods.
Further material for study can be found in LaSalle and Lefschetz (1961),
Kalman and Bertram (1960), Vidyasagar (1993), Khalil (2002), and Sastry
(1999).

9.5 Analysis and Design Based on Stability
681
Figure 9.47
Step response for
position control system
Amplitude
0
5
10
15
Time (sec)
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
Output
x2
Figure 9.48
Block diagram of a
simple model reference
adaptive control system
©
Km
1
Ts+1
KcKp
1
Ts+1
-
+
E
ym
yp
R
Lyapunov Redesign of Adaptive Control
One of the classical applications of Lyapunov stability theory to control
is a technique known as Lyapunov redesign. The idea is to construct the
system with some key control parameters unspeciﬁed, propose a candidate
Lyapunov function, and then select the available components to force the
candidatetosucceedandbeanactualLyapunovfunctionfromwhichstability
can be concluded. The method was applied in an early paper by Parks (1966)
to a model reference adaptive control system. A block diagram of the simple
system ﬁrst considered is drawn in Fig. 9.48.
In this system, the model and the plant have the same dynamics but
different gains. The objective is to adjust the control gain, Kc, so that KcKp =
Km, and the plant output, yp, will equal the model output, ym. A proposed
heuristic rule, known as the "MIT" rule, was based on the idea that if we
deﬁne the cost as the square of the instantaneous error and move Kc so as
to make this cost smaller, the result should drive Kc to the right value. If the
gradient of the cost is positive (pointing uphill, so to speak), the gain should
be reduced, and if the gradient is negative, the gain should be increased.
Thus the time derivative of the gain should be proportional to the negative
of the gradient. In equation form,
J = e2,
(9.72)
∂J
∂Kc
= 2e ∂e
∂Kc
,
(9.73)
dKc
dt
= −Be ∂e
∂Kc
,
(9.74)

682
Chapter 9 Nonlinear Systems
where B is the "adaptive gain" to be chosen. From the block diagram,
E(s) = KcKp −Km
Ts + 1
R(s),
(9.75)
∂E
∂Kc
=
Kp
Ts + 1R
(9.76)
= Kp
Km
Ym.
(9.77)
If we substitute the result of Eq. (9.77) into Eq. (9.74), the result is the
MIT rule,
dKc
dt
= −B′eYm,
(9.78)
where there is a new adaptive gain, B′. Unfortunately, the stability of this
rule is not established, and some analysis showed that it could be unstable
under reasonable circumstances, such as if there are unmodeled dynamics
or disturbances. Parks proposed that Lyapunov redesign would be a better
idea and also proposed that, rather than taking ˙Kc given by Eq. (9.74), this
choice be made in a way that guarantees stability. His idea begins with the
differential equations where r = ro is a constant:
T ˙e + e = (KcKp −Km)ro,
(9.79)
˙Kc = −B′eYm.
(9.80)
To simplify things, the deﬁnition is made that x = (KcKp −Km) and ˙x is to
be found. Parks selects V = e2 + λx2 as a candidate Lyapunov function and
computes
˙V = 2e˙e + 2λx˙x
(9.81)
= 2e
xro
T −e
T

+ 2λx˙x.
(9.82)
If ˙x in the last equation is selected to be ˙x = −ero
λT , then ˙V = −2 e2
T , the
conditions for a Lyapunov function are satisﬁed, and stability is assured for
the given assumptions. Working back, we ﬁnd that the new algorithm is
˙Kc = −B′′ero.
(9.83)
Obviously, this result does not answer the questions of unmodeled dynamics
or disturbances, but the principle is clear: Leaving key control equations to
be deﬁned so as to obtain a Lyapunov function can put the stability of a
system on a ﬁrm foundation.
As a second example of Lyapunov redesign, consider the adaptive con-
trol of a motor shown in Fig. 9.49. Deﬁning the model output as ym and the
plant output as yp, the equations are
¨ym + 2ζωn˙ym + ω2
nym = ω2
nr,
(9.84)
¨yp + 2ζωn˙yp + ω2
nyp = KcKpω2
n(r −yp) + ω2
nyp.
(9.85)

9.5 Analysis and Design Based on Stability
683
Figure 9.49
Block diagram of
adaptive control of a
motor
-
+
 - 
 + 
wn^2(s)
s2 + 2*z*wn^2s + wn^2
Model
Kp*wn^2(s)
s2 + 2*z*wn^2s
Kc(s)
1
Plant
Controller
Input
Error
(In the equation for yp the term ω2
nyp has been added to both sides to make the
error equation simpler.) The error is deﬁned as e = ym −yp and an equation
for error can be obtained by subtracting the equation for yp from that for ym.
The result is
¨e + 2ζωn˙e + ω2
nye = ω2
n(1 −KcKp)(r −yp).
(9.86)
The idea now is to ﬁnd an equation for Kc that will result in a Lyapunov
function for the error equation. To simplify the calculation, we deﬁne the
parameter as x = 1 −KcKp, for which ˙x = −Kp ˙Kc and in terms of which
the error equation is
¨ep + 2ζωn˙e + ω2
ne = ω2
nx(r −yp).
(9.87)
At this point, Parks suggests consideration of V = e2 + α˙e2 + βx2 as a
possible function. We need to ﬁnd ˙x so this V will be a Lyapunov function.
The equation for the derivative is
˙V = 2e˙e + 2α˙e¨e + 2βx˙x
(9.88)
= 2e˙e + 2α˙e{−2ζωn˙e −ω2
ne + ω2
nx(r −yp)} + 2βx˙x
(9.89)
= −4αζωn˙e2 + 2e˙e(1 −αω2
n) + x{2α˙eω2
n(r −yp) + 2β˙x}.
(9.90)
If we take 1 −αω2
n = 0 and 2α˙eω2
n(r −yp) + 2β˙x = 0, then the equation
for ˙V simpliﬁes to ˙V = −4αζωn˙e2, which is always negative, and V is a
Lyapunov function and the system is stable. Substituting for x, we get the
adaptive control law
˙Kc = −β′˙e(r −yp),
(9.91)
where β′ is a new constant equal to αω2n
Kpβ .
Clearly, we have only touched on Lyapunov's theory of stability, and
our examples of redesign are ancient history from 1966, but they illus-
trate the principle very well and give a good start to further study of this
important area.
9.5.3
The Circle Criterion
A nonlinear system with only one single-input-single-output nonlinearity
may be represented as shown in Fig. 9.50 by drawing the block diagram
from the points of the input and output of the nonlinearity. In the literature

684
Chapter 9 Nonlinear Systems
Figure 9.50
Block diagram of a
nonlinear system
Time-varying
nonlinearity
G(s)
©
-
+ 
y
y
f(t, y)y
r K 0
Figure 9.51
Output of the
nonlinearity conﬁned in
a sector
f(t, y)y
Slope k2
Slope k1
y
this is referred to as the Lur'e problem after the Soviet scientist who ﬁrst
studied it.
We assume that the system is unforced and thus r ≡0. It is possi-
ble to derive a graphical sufﬁcient condition for stability of such systems.
Even though this method is practical, it may lead to conservative results
in some cases, although extensions exist that yield less conservative results
(see Safonov and Wyetzner 1987). First we deﬁne sector conditions for
memoryless nonlinearities.
Sector Conditions
A function f (x) with a scalar input and a scalar output belongs to the sector
[k1, k2] if, for all inputs x,
k1x2 ≤f (x)x ≤k2x2.
(9.92)
This relationship may be rewritten as
k1 ≤f (x)
x
≤k2,
x ̸= 0.
(9.93)
Basically, the deﬁnition says that the graph of f (x) lies between two straight
lines of slopes k1 and k2 going through the origin, as shown in Fig. 9.51. In
this deﬁnition, k1 and k2 are allowed to be −∞or +∞. Note that the sector
conditions place no limits on the incremental gain or slope of the function
f (x). The ensuing examples illustrate how k1 and k2 are determined.

9.5 Analysis and Design Based on Stability
685
EXAMPLE 9.17
Computation of a Sector for Signum Nonlinearity
Determine a sector that contains the signum function y = f (u) shown in
Fig. 9.6(b).
Solution. Since sgn(0) = 0, we know that the only line going through the
origin that bounds the signum function from above is the y-axis, correspond-
ing to a slope of k2 = ∞. Similarly the line going through the origin that
bounds the signum function from below has a slope of zero and corresponds
to the x-axis; therefore, k1 = 0. Hence the sector for the signum function is
[0, ∞].
EXAMPLE 9.18
Sector for a Saturation Nonlinearity
Consider the saturation nonlinearity shown in Fig. 9.52. Determine a sector
for this function.
Solution. The function is bounded above by a line of slope 1, k2 = 1, and
is bounded below by the x-axis, k1 = 0, as shown in the ﬁgure. Therefore,
the sector for this function is [0, 1].
Circle Criterion
In 1949 the Russian scientistAizermann conjectured that if a Lur'e system is
stable with f replaced by any linear gain between the limits k1 < k < k2, then
the system will be stable, with the gain replaced by a nonlinearity in the sector
[k1, k2]. That means that if a single-loop (strictly proper) continuous-time
feedback system as shown in Fig. 9.50 with a linear forward path (A, B, C) is
stable for all linear ﬁxed feedback gains k in the range k1 < k < k2, such that
Figure 9.52
Sector for saturation
Output
Input
0.1
0.1

686
Chapter 9 Nonlinear Systems
the resultant closed-loop system matrix A+kBC is stable, then the nonlinear
system having a memoryless nonlinear time-varying feedback term f (t, y)
in the sector [k1, k2], shown in Fig. 9.50, is also stable. Unfortunately, this
conjecture is not true as counterexamples exist.7 However, a variation of
Aizermann's conjecture is true and is known as the circle criterion.
Rather than giving a rigorous proof of the criterion, we describe a heuris-
tic argument that gives insight into the problem and motivates the proof. An
electric circuit with a linear impedance, Z( jω) = R(ω)+jX(ω), is described
by Ohm's law as V = IZ(s). We assume that Z is composed of real com-
ponents, which means that the real part R is even and the imaginary part X
is odd; that is R(−ω) = R(ω) and X(−ω) = −X(ω). If R(ω) ⪖δ > 0
for all ω, the impedance is called strictly passive. It will dissipate energy.
The instantaneous power into the circuit is p = v(t)i(t), and the total energy
absorbed by the circuit is e =
# ∞
0
v(t)i(t) dt. Referring to the ﬁgure, Ohm's
law is equivalent to the plant equation Y = UG(s) with Y as voltage, U as
current, and G(s) = R + jX as the impedance. Applying the expression for
energy to the plant equation and using the theorem by Parseval8 to convert
this to the frequency domain yields
 ∞
0
y(t)u(t) dt = 1
2π
 ∞
−∞
U( jω)Y(−jω) dω
(9.94)
= 1
2π
 ∞
−∞
U( jω)U(−jω)G(−jω) dω
(9.95)
= 1
2π
 ∞
−∞
|U( jω)|2 (R −jX) dω
(9.96)
= 1
2π
 ∞
−∞
|U( jω)|2 R(ω) dω.
(9.97)
In the last step, the fact the X is odd was used. At this point, the use of more
or less conventional notation will simplify the equations substantially. We
deﬁne inner products and norms as
 ∞
0
y(t)u(t) dt = < y, u >,
(9.98)
∥u∥2 =
 ∞
0
[u(t)]2 dt =< u, u > .
(9.99)
With this notation, and with the assumption that R ≧δ > 0, Eq. (9.97) is
reduced to
< y, u > ≧δ ∥u∥2 .
(9.100)
7Aizermann's conjecture spurred a lot of research in this area and led to the development of the
Kalman-Yakubovich-Popov lemma, giving state-space conditions for a passive system. The
lemma is used in a proof of the circle criterion.
8See Appendix A.

9.5 Analysis and Design Based on Stability
687
Turning now to the nonlinear component, using the same concept of "energy"
and assuming that f is in the sector [0, K], we have
 ∞
0
y(t)f (y, t) dt =
 ∞
0
[ f (y, t)]2
f ( y, t)
y(t)
dt
(9.101)
≧∥f ( y, t)∥2
K
(9.102)
≧∥u(t)∥2
K
.
(9.103)
The assumption now is that if the total energy given by the sum of
Eq. (9.100) and Eq. (9.102) is positive, then the system must be stable, as
energy is being steadily lost. The actual value of the energy lost would be
equal to the initial energy stored in the elements of the system. From this
one would conclude that if δ∥u∥2 + ∥u(t)∥2
K
> 0, then the system is stable.
Thus the criterion is
δ ∥u∥2 + ∥u(t)∥2
K
> 0,
(9.104)

Re{G( jω)} + 1
K

∥u(t)∥2 > 0,
(9.105)
Re{KG( jω) + 1} > 0.
(9.106)
In deriving Eq. (9.106), the assumption was made that the nonlinearity was
in a zero sector, [0, K]. If the function is actually in the sector [k1, k2], it can
be reduced to a zero sector by adding and subtracting k1 in the block diagram
as shown in Fig. 9.53. With this change, the dynamic system is replaced by
H =
G
1+k1G and the function by f ′ = f −k1, which is in the sector [k2−k1, 0].
With these changes, the stability criterion is transformed to
Re
$
1 + (k2 −k1)
G
1 + k1G
%
> 0,
(9.107)
Figure 9.53
Block diagram
manipulation for sector
+-
u(t)
y(t)
v(t) = f(y)
Function
Gain1
Gain
Transfer fcn
Repeating
sequence stair
1
G(s)
-
+
-
+
k1
k1
f(u)

688
Chapter 9 Nonlinear Systems
Re
&
1 + k1G + (k2 −k1)G
1 + k1G
'
> 0,
(9.108)
Re
$1 + k2G( jω)
1 + k1G( jω)
%
> 0.
(9.109)
It is a fact that a bilinear function such as F = 1 + k2G( jω)
1 + k1G( jω) in Eq. (9.109)
will map a circle in the F plane into another circle in the G plane (see
Appendix WD, www.fpe7e.com). In this case, the acceptable region is
Re{F} > 0, of which the boundary is the imaginary axis, so the map is from
the imaginary axis, a circle of inﬁnite radius, into a ﬁnite circle. Because
the functions are real, the circle must be centered on the real axis and we
need only locate the two points on the real axis. For example, when F = 0,
we have 1 + k2G = 0 or G = −1
k2 . The other point on the real axis is when
the function is inﬁnite, at which point 1 + k1G = 0 or G = −1
k1 . Thus the
circle in the G plane is centered on the real axis and goes through the points
 
−1
k2 , −1
k1
!
as plotted in Fig. 9.54. Since F had to avoid the LHP, if we set
F = −1, which is in the forbidden region, and solve, we ﬁnd that G =
−2
k1+k2 ,
which is inside the circle, from which we conclude that the system will be
stable if the plot of G( jω) avoids this circle.
The actual theorem is as follows:
The nonlinear system described is asymptotically stable given that
1. f (t, y) lies in the sector [k1, k2] with 0 ≤k1 < k2 and
2. the Nyquist plot of the transfer function G( jω) = C( jωI−A)−1B does
not intersect or encircle the "critical circle," which is centered on the
real axis and passes through the two points −1/k1 and −1/k2, as shown
in Fig. 9.54.
In effect, the usual Nyquist "−1" point is replaced by the critical disk.
This result is known as the circle criterion or circle theorem and is due to
Circle criterion
Sandberg (1964) and Zames (1966). Note that these conditions are sufﬁcient
but not necessary, because intersection of the transfer function G(s) with the
circle as deﬁned does not prove instability. The critical circle is centered at
c = 1
2

−1
k1
−1
k2

= −k1 + k2
2k1k2
,
Figure 9.54
Illustration of circle
criterion
Im(L)
Re(L)
1
- k1
1
- k2

9.5 Analysis and Design Based on Stability
689
and has a radius of
k2 −k1
2k1k2
.
If k1 = 0, then the critical circle degenerates into a half plane deﬁned by
Re {G} ≧−1/k2.
The circle criterion and the describing function are related. In fact, for
the case of time-invariant odd nonlinearities that are within a sector and
whose describing functions are real, the describing function satisﬁes the
relationship
k1 ≤Keq(a) ≤k2
for all a,
(9.110)
so that
−1
k1
≤−
1
Keq(a) ≤−1
k2
,
(9.111)
and the plot of the negative reciprocal of the describing function will lie
inside the critical circle. This can be seen by the following lower and upper
bounds:
Keq(a) = 2
πa
 π
0
f (a sin(ωt)) sin(ωt) d(ωt)
≥2k1
π
 π
0
sin2(ωt) d(ωt) = k1,
(9.112)
Keq(a) = 2
πa
 π
0
f (a sin(ωt)) sin(ωt) d(ωt)
≤2k2
π
 π
0
sin2(ωt) d(ωt) = k2.
(9.113)
The equivalent gain analysis and describing functions yield the same
results. If we take the gain of the describing function, then the amplitude
of the limit cycle can be predicted as with the describing functions. Both
equivalent gain techniques can be used to determine stability, but as we have
seen, the circle criterion allows for time-varying nonlinearities.
Figure 9.55
Nyquist plot and circle
criterion
0
Im(G)
Re(G)
-0.1j
+0.1j
-0.5
-1
v =1
a = 0.63
Nyquist plot

690
Chapter 9 Nonlinear Systems
EXAMPLE 9.19
Determination of Stability Using the Circle Criterion
Consider the system in Example 9.7. Determine the stability properties of
the system using the circle criterion.
Solution. The related sector is the same one found in Example 9.18. The
critical circle degenerates into a half plane deﬁned by Re(G) ≤−1, as shown
in Fig. 9.55. Since the Nyquist plot lies entirely to the right of the critical
circle, the system is stable.
9.6
Historical Perspective
Almost all physical dynamic systems are nonlinear; hence it is not surprising
that the study of nonlinear systems has a long and rich history. The study
of nonlinear systems goes back to astronomy and the study of the stability
of the solar system dating back to Torricelli (1608-1647), Laplace, and
Lagrange. The ﬁeld got a jolt of "energy" with the doctoral dissertation of
A. M. Lyapunov in Russia in 1892. He was trying to solve the stability of
rotating bodies of ﬂuids posed by Poincaré and recognized that if he could
show that system-stored energy was always decreasing, then the system
wouldbestableandeventuallycometorest. ThestudyofLyapunovfunctions
was introduced to the control ﬁeld in 1960 by Kalman and Bertram and has
evolved rapidly since then.
Maxwell was the ﬁrst to study stability by linearization about an equi-
librium point by the derivation of the linear model for the Watt's ﬂy-ball
governor and stating that the system will be stable if the characteristic
roots have negative real parts. Kochenburger derived the describing function
method in 1950 in an attempt to handle nonlinearities based on frequency-
response ideas. Lur'e proposed the absolute stability problem in 1944 and
in 1961 Popov developed the circle criterion for nonlinear stability anal-
ysis. Yakubovich (1962) and Kalman (1963) later established connections
between Lur'e and Popov's results.
The study of adaptive control received a lot of attention during the
three decades of the 1960s, 1970s, and 1980s. Adaptive controllers are both
time varying and nonlinear in general. During the 1960s sensitivity methods
and the MIT rule for adaptive adjustments were developed by Draper and
others. Methods to study adaptive systems based on Lyapunov's methods
and passivity were developed in the 1970s. Robust adaptive control methods
were studied in the 1980s. Also, there has been a lot of research on systems,
suchastheweather, whereaminutechangeininitialconditionsorparameters
can cause drastic changes in the response of the system. Such systems are
said to be chaotic. In all recent studies of nonlinear systems, the availability
of powerful computers to solve the equations and to graph the results has
been critical. Development of a general theory of nonlinear control continues
to be a dream of control theorists and is an ongoing quest.

Review Questions
691
SUMMARY
•
The nonlinear equations of motion may be approximated by linear
ones by considering a small-signal linear model that is accurate near
an equilibrium.
•
In many cases, the inverse of a nonlinearity may be used to linearize a
system.
•
Nonlinearities with no dynamics, such as saturation, can be analyzed
using the root locus by considering the nonlinearity to be a variable
gain.
•
The root-locus technique can be used to determine the limit-cycle prop-
erties for memoryless nonlinearities, and yields the same results as the
describing function.
•
The describing function is essentially a heuristic method with the goal
of ﬁnding a frequency-response function for a nonlinear element.
•
The stability of systems with a single nonlinearity can be studied using
the describing function method.
•
The describing function can be used to predict periodic solutions in
feedback systems.
•
The Nyquist plot together with the describing function can be used to
determine limit-cycle properties.
•
The phase plane considers the time response directly by plotting the
trajectory of the state variables and allows nonlinear behavior to be
displayed.
•
The stability of a nonlinear system in state-space description can be
studied by the methods of Lyapunov.
•
The circle criterion provides a sufﬁcient condition for stability.
REVIEW QUESTIONS
9.1
Why do we approximate a physical model of the plant (which is always
nonlinear) with a linear model?
9.2
How would you linearize the nonlinear system equation for radiation heat
transfer ˙T = T4 + T + u?
9.3
A lamp used as a thermal actuator has a nonlinearity such that the experimen-
tally measured output power is related to the input voltage by P = V1.6. How
would you deal with such a nonlinearity in feedback control design?
9.4
What is integrator windup?
9.5
Why is an antiwindup circuit important?
9.6
Using the nonlinear saturation function having gain 1 and limits ±1, sketch
the block diagram of saturation for an actuator that has gain 7 and limits of
±20.
9.7
What is a describing function and how is it related to a transfer function?
9.8
What are the assumptions behind the use of the describing function?
9.9
What is a limit cycle in a nonlinear system?

692
Chapter 9 Nonlinear Systems
9.10
How can one determine the describing function for a nonlinear system in the
laboratory?
9.11
What is the minimum time control strategy for a satellite attitude control with
bounded controls?
9.12
How are the two Lyapunov methods used?
PROBLEMS
Problems for Section 9.2: Analysis by Linearization
9.1
Figure 9.56 shows a simple pendulum system in which a cord is wrapped
around a ﬁxed cylinder. The motion of the system that results is described by
the differential equation
(l + Rθ) ¨θ + g sin θ + R ˙θ2 = 0,
where
l = length of the cord in the vertical (down) position,
R = radius of the cylinder.
Figure 9.56
Motion of cord wrapped
around a ﬁxed cylinder
R u
l
l + Ru
(a) Write the state-variable equations for this system.
(b) Linearize the equation around the point θ = 0, and show that for small
values of θ, the system equation reduces to an equation for a simple
pendulum—that is,
¨θ + (g/ℓ) = 0.
9.2
The circuit shown in Fig. 9.57 has a nonlinear conductance G such that iG =
g(vG) = vG(vG −1)(vG −4). The state differential equations are
di
dt = −i + v,
Figure 9.57
Nonlinear circuit for
Problem 9.2
i
L = 1
iG
R = 1
u
+
-
C = 1
  y
+
-
-
   yG
+
G
'

Problems
693
dv
dt = −i + g(u −v),
where i and v are the state variables and u is the input.
(a) One equilibrium state occurs when u = 1, yielding i1 = v1 = 0. Find the
other two pairs of v and i that will produce equilibrium.
(b) Find the linearized model of the system about the equilibrium point u = 1,
i1 = v1 = 0.
(c) Find the linearized models about the other two equilibrium points.
9.3
Consider the circuit shown in Fig. 9.58; u1 and u2 are voltage and current
sources, respectively, and R1 and R2 are nonlinear resistors with the following
characteristics:
Resistor 1:
i1 = G(v1) = v3
1,
Resistor 2:
v2 = r(i2).
Figure 9.58
A nonlinear circuit
R2
x1
+
-
R1
 y2 +
-
y1 -
+
1 F
u1
(=1 V)
+
-
i1
i2 = x3
+
-
1 H
u2
(= 27 A)
1 F
+ x2  -
'
Here the function r is deﬁned in Fig. 9.59.
Figure 9.59
Nonlinear resistance
i2
y2
1
-1
0
Slope = 1/2
Slope = 1
(a) Show that the circuit equations can be written as
˙x1 = G(u1 −x1) + u2 −x3,
˙x2 = x3,
˙x3 = x1 −x2 −r(x3).
Suppose we have a constant voltage source of 1 volt at u1 and a constant
current source of 27 amps (that is, uo
1 = 1, uo
2 = 27). Find the equilibrium

694
Chapter 9 Nonlinear Systems
state xo =
( xo
1,
xo
2,
xo
3
)Tfor the circuit. For a particular input uo,
an equilibrium state of the system is deﬁned to be any constant state vector
whose elements satisfy the relation
˙x1 = ˙x2 = ˙x3 = 0.
Consequently, any system started in one of its equilibrium states will
remain there indeﬁnitely until a different input is applied.
(b) Due to disturbances, the initial state (capacitance, voltages, and induc-
tor current) is slightly different from the equilibrium and so are the
independent sources; that is,
u(t) = uo + δu(t),
x(t0) = xo(t0) + δx(t0).
Do a small-signal analysis of the network about the equilibrium
found in (a), displaying the equations in the form
δ ·x1 = f11δx1 + f12δx2 + f13δx3 + g1δu1 + g2δu2.
(c) Draw the circuit diagram that corresponds to the linearized model. Give
the values of the elements.
9.4
Consider the nonlinear system
˙x = −x2e−1
x + sin u,
x(0) = 1.
(a) Assume uo = 0 and solve for xo(t).
(b) Find the linearized model about the nominal solution in part (a).
9.5
Linearizing effect of feedback: We have seen that feedback can reduce the
sensitivity of the input-output transfer function with respect to changes in the
plant transfer function, and reduce the effects of a disturbance acting on the
plant. In this problem we explore another beneﬁcial property of feedback: It
can make the input-output response more linear than the open-loop response
of the plant alone. For simplicity, let us ignore all the dynamics of the plant
and assume that the plant is described by the static nonlinearity
y(t) =
$
u,
u ≤1,
u + 1
2
,
u > 1.
(a) Suppose we use proportional feedback
u(t) = r(t) + α(r(t) −y(t)),
where α ≥0 is the feedback gain. Find an expression for y(t) as a function
of r(t) for the closed-loop system. (This function is called the nonlinear
characteristic of the system.) Sketch the nonlinear transfer characteristic
for α = 0 (which is really open loop), α = 1, and α = 2.
(b) Suppose we use integral control:
u(t) = r(t) +
t

0
(r(τ) −y(τ))dτ.

Problems
695
The closed-loop system is therefore nonlinear and dynamic. Show that if
r(t) is a constant, say r, then lim
t→∞y(t) = r. Thus, the integral control
makes the steady-state transfer characteristic of the closed-loop system
exactly linear. Can the closed-loop system be described by a transfer
function from r to y?
9.6
This problem shows that linearization does not always work. Consider the
system
˙x = αx3,
x(0) ̸= 0.
(a) Find the equilibrium point and solve for x(t).
(b) Assume that α = 1. Is the linearized model a valid representation of the
system?
(c) Assume that α = −1. Is the linearized model a valid representation of the
system?
9.7
Consider the object moving in a straight line with constant velocity shown
in Fig. 9.60. The only available measurement is the range to the object. The
system equations are
⎡
⎣
˙x
˙v
˙z
⎤
⎦=
⎡
⎣
0
1
0
0
0
0
0
0
0
⎤
⎦
⎡
⎣
x
v
z
⎤
⎦,
where
z = constant,
˙x = constant = v0,
r =

x2 + z2.
Derive a linear model for this system.
Figure 9.60
Diagram of the moving
object for Problem 9.7
Object
z
x
0
Problems for Section 9.3: Equivalent Gain Analysis Using the Root
Locus
9.8
Consider the third-order system shown in Fig. 9.61.
(a) Sketch the root locus for this system with respect to K, showing your
calculations for the asymptote angles, departure angles, and so on.
(b) Using graphical techniques, locate carefully the point at which the locus
crosses the imaginary axis. What is the value of K at that point?

696
Chapter 9 Nonlinear Systems
Figure 9.61
Control system for
Problem 9.8
Y
-
+
K
R
s3
(s + 1)2
e
u
©
(c) Assume that, due to some unknown mechanism, the ampliﬁer out-
put is given by the following saturation non-linearity (instead of by a
proportional gain K):
u =
⎧
⎨
⎩
e,
|e| ≤1,
1,
e > 1,
−1,
e < −1.
Qualitatively describe how you would expect the system to respond
to a unit-step input.
9.9
Consider the system with the plant transfer function
G(s) =
1
s2 + 1.
We would like to use PID control of the form
Dc(s) = 10

1 + 1
2s + 2s

,
to control this system. It is known that the system's actuator is a saturation
nonlinearity with a slope of unity and |u| ≤10. Compare the system response
for a step input of size 10 with and without antiwindup circuit. Plot both the
step response and the control effort using Simulink. Qualitatively describe the
effect of the antiwindup circuit.
Problems for Section 9.4: Equivalent Gain Analysis
Using Frequency Response: Describing Functions
9.10
Compute the describing function for the relay with dead-zone nonlinearity
shown in Fig. 9.6(c).
9.11
Compute the describing function for gain with dead-zone nonlinearity shown
in Fig. 9.6(d).
9.12
Compute the describing function for the preloaded spring or Coulomb plus
viscous friction nonlinearity shown in Fig. 9.6(e).
9.13
Consider the quantizer function shown in Fig. 9.62 that resembles a stair-
case. Find the describing function for this nonlinearity and write a Matlab .m
function to generate it.
9.14
Derive the describing function for the ideal contactor controller shown in
Fig. 9.63. Is it frequency dependent? Would it be frequency dependent if
it had a time delay or hysteresis? Graphically sketch the time histories of
the output for several amplitudes of the input and determine the describing
function values for those inputs.

Problems
697
Figure 9.62
Quantizer nonlinearity
for Problem 9.13
d1
d2
d3
d4
h
u
q
2q
3q
4q
y
Figure 9.63
Contactor for Problem
9.14
Output
Input
d
T
9.15
A contactor controller of an inertial platform is shown in Fig. 9.64, where
I = 0.1 kg · m2,
I
B = 10 sec,
h
c = 1,
J
c = 0.01 sec,
τL = 0.1 sec,
τf = 0.01 sec,
d = 10−5 rad,
T = 1 N · m.
The required stabilization resolution is approximately 10−6 rad:
Kϕm > d
for
ϕm > 10−6 rad.

698
Chapter 9 Nonlinear Systems
Figure 9.64
Block diagram of the
system for Problem 9.15
Is + B
1
s
1
d
T
Motor and controller
Gimballed
Gyro
w
v
wm
K tLs + 1
tf s + 1
h
cs(    s + 1)
J
c
Discuss the existence, amplitude, and frequency of possible limit cycles as a
function of the gain K and the DF of the controller. Repeat the problem for a
deadband with hysteresis.
9.16
Nonlinear Clegg Integrator: There have been some attempts over the years to
improve upon the linear integrator. A linear integrator has the disadvantage of
having a phase lag of 90◦at all frequencies. In 1958, J. C. Clegg suggested
that we modify the linear integrator to reset its state, x, to zero whenever
the input to the integrator, e, crosses zero (that is, changes sign). The Clegg
integrator has the property that it acts like a linear integrator whenever its
input and output have the same sign. Otherwise, it resets its output to zero.
The Clegg integrator can be described by
x(t) = e(t),
if e(t) ̸= 0,
x(t+) = 0,
if e(t) = 0,
where the latter equation implies that the state of the integrator, x, is reset to
zero immediately after e changes sign. It can be implemented with op-amps
and diodes. A potential disadvantage of the Clegg integrator is that it may
induce oscillations.
(a) Sketch the output of the Clegg integrator if the input is e = a sin(ωt).
(b) Prove that the DF for the Clegg integrator is
N(a, ω) =
4
πω −j 1
ω .
and this amounts to a phase lag of only 38◦.
Problems for Section 9.5: Analysis and Design Based on Stability
△
9.17
Compute and sketch the optimal reversal curve and optimal control for the
minimal time control of the plant
˙x1 = x2,
˙x2 = −x2 + u,
|u| ≤1.
Use the reverse-time method and eliminate the time.
9.18
Sketch the optimal reversal curve for the minimal time control with |u| ≤1
of the linear plant
˙x1 = x2,

Problems
699
˙x2 = −2x1 −3x2 + u.
9.19
Sketch the time-optimal control law for
˙x1 = x2,
˙x2 = −x1 + u,
|u| ≤1,
and show a trajectory for x1(0) = 3 and x2(0) = 0.
9.20
Consider the thermal control system shown in Fig. 9.65. The physical plant
can be a room, an oven, etc.
(a) What is the limit-cycle period?
(b) If Tr is commanded as a slowly increasing function, sketch the output of
the system, T. Show the solution for Tr "large."
Figure 9.65
Thermal system for
Problem 9.20
+
-
y
Tr
T
N
h
e
B
s + a
1
Sensor
©
9.21
Several systems, such as a spacecraft, a spring-mass system with resonant fre-
quency well below the frequency of switching, and a large motor-driven load
with very small friction can be modeled as just an inertia. For an ideal switch-
ing curve, sketch the phase portraits of the system. The switching function is
e = θ +τω. Assume that τ = 10 sec and the control signal = 10−3 rad/ sec2.
Now sketch the results with
(a) deadband,
(b) deadband plus hysteresis,
(c) deadband plus time delay T,
(d) deadband plus a constant disturbance.
9.22
Compute the amplitude of the limit cycle in the case of satellite attitude control
with delay
I ¨θ = N u(t −),
using
u = −sgn(τ ˙θ + θ).
Sketch the phase-plane trajectory of the limit cycle and time history of θ giving
the maximum value of θ.
9.23
Consider the point mass pendulum with zero friction as shown in Fig. 9.66.
Using the method of isoclines as a guide, sketch the phase-plane portrait of the
motion. Pay particular attention to the vicinity of θ = π. Indicate a trajectory
corresponding to spinning of the bob around and around rather than oscillating
back and forth.

700
Chapter 9 Nonlinear Systems
Figure 9.66
Pendulum for Problem
9.23
l
u
M
9.24
Draw the phase trajectory for a system
¨x = 10−6 m/ sec2
between ˙x(0) = 0, x(0) = 0, and x(t) = 1 mm. Find the transition time tf by
graphical means from the parabolic curve by comparing your solution with
two different interval sizes and the exact solution.
9.25
Consider the system with equations of motion
¨θ + ˙θ + sin θ = 0.
(a) What physical system does this correspond to?
(b) Draw the phase portraits for this system.
(c) Show a speciﬁc trajectory for θ(0) = 0.5 rad and ˙θ = 0.
9.26
Considerthenonlinearuprightpendulumwithamotoratitsbaseasanactuator.
Design a feedback controller to stabilize this system.
9.27
Consider the system
˙x = −sin x.
Prove that the origin is an asymptotically stable equilibrium point.
9.28
A ﬁrst-order nonlinear system is described by the equation ˙x = −f (x), where
f (x) is a continuous and differentiable nonlinear function that satisﬁes the
following:
f (0) = 0,
f (x) > 0,
for
x > 0,
f (x) < 0,
for
x < 0.
Use the Lyapunov function V(x) = x2/2 to show that the system is stable
near the origin (x = 0).
9.29
Use the Lyapunov equation
ATP + PA = −Q = −I,
to ﬁnd the range of K for which the system in Fig. 9.67 will be stable. Compare
your answer with the stable values for K obtained using Routh's stability
criterion.
9.30
Consider the system
d
dt
 x1
x2

=

x1 + x2u
x2(x2 + u)

,
y = x1.

Problems
701
Figure 9.67
Control system for
Problem 9.29
+
-
R(s) = 0
(s + 4)(s - 1)
K
Y(s)
©
Find all values of α and β for which the input u(t) = αy(t) + β will achieve
the goal of maintaining the output y(t) near 1.
9.31
Consider the nonlinear autonomous system
d
dt
⎡
⎣
x1
x2
x3
⎤
⎦=
⎡
⎣
x2(x3 −x1)
x2
1 −1
−x1x3
⎤
⎦.
(a) Find the equilibrium point(s).
(b) Find the linearized system about each equilibrium point.
(c) For each case in part (b), what does Lyapunov theory tell us about the
stability of the nonlinear system near the equilibrium point?
9.32
Consider the circuit shown in Fig. 9.68. For what diode characteristics will
this system be stable?
Figure 9.68
Circuit diagram for
Problem 9.32
iC
iC
C
L
iL
V
-
+
9.33
Van der Pol's equation: Consider the system described by the nonlinear
differential equation
¨x + ε(1 + x2)˙x + x = 0
with the constant ε > 0.
(a) Show that the equations can be put in the form [Liénard or (x,y) plane]
˙x = y + ε

x3
3 −x

,
˙y = −x.
(b) Use the Lyapunov function V = 1
2

x2 + ˙x2
, and sketch the region of
stability as predicted by this V in the Liénard plane.
(c) Plot the trajectories of part (b) and show the initial conditions that tend to
theorigin. SimulatethesysteminSimulinkusingvariousinitialconditions
on x(0) and ˙x(0). Consider two cases, with ε = 0.5 and ε = 1.0.
9.34
Dufﬁng's equation: Consider the system described by the nonlinear differen-
tial equation
¨x + k˙x + εx3 = u,

702
Chapter 9 Nonlinear Systems
where u = A cos(t). This equation represents the model of a hard spring where
k is the spring constant and if ε > 0, the spring gets stiffer as the displacement
increases. Let k = 0.05, ϵ = 1, and A = 7.5.
(a) Build a simulation of the system in Simulink. Show that the system
response can be very sensitive to slight perturbations on the initial condi-
tions x(0), ˙x(0) (the system is said to be chaotic). Simulate the response of
the system with x(0) = 3 and ˙x(0) = 4 for t = 30 sec. Repeat the simula-
tion for slightly perturbed initial conditions x(0) = 3.01 and ˙x(0) = 4.01.
Compare the two results.
(b) Consider the unforced Dufﬁng equation (u = 0). Plot the time response of
the system for x(0) = 1, ˙x(0) = 1 for t = 200 sec. Draw the phase-plane
plot for the system. Show that the origin is an equilibrium point.
(c) Now consider the forced Dufﬁng equation (u ̸= 0). Find the solution to
the Dufﬁng equation for x(0) = −1, ˙x(0) = 1 for t = 30 sec. Draw the
phase-plane plot (˙x(t) versus x(t)) for this case.
(d) Repeat part (c) for k = 0.25, ϵ = 1, and A = 8.5.
(e) Repeat part (c) for k = 0.1, ϵ = 1, and A = 11.
(f) We can get more insight into the system by plotting ˙x(tj) versus x(tj) at
several hundred points at 2π periodic observation times. In other words
rather than looking at the system continuously, we "strobe" the system and
plot the behavior at strobe times only. Show that unlike the phase-plane
plots in parts (c)-(e), the points fall on a well-structured plot referred to
as a Poincaré section (also called a strange attractor). Plot the Poincaré
sections for parts (c)-(e). Simulate the system using the initial conditions
x(0) = −1 and ˙x(0) = 1 for t = 10, 000 sec in order to plot the Poincaré
sections.
(g) What can you conclude about the nature of the solution of the Dufﬁng
equation from the results of the previous parts?
(h) Characterize the system behavior in terms of the ranges of the system
parameters k, ϵ, and A.

10
Control System Design:
Principles and Case
Studies
A Perspective on Design Principles
In Chapters 5, 6, and 7 we presented techniques for analyzing and
designing feedback systems based on the root-locus, frequency-
response, and state-variable methods. Thus far we have had to
consider somewhat isolated, idealized aspects of larger systems and
to focus on applying one analysis method at a time. In this chapter
we return to the theme of Chapter 4—the advantages of feedback
control—to reconsider the overall problem of control systems design
with the sophisticated tools developed in Chapters 5 to 7 and 9
in hand. We will apply these tools to several complex, real-world
applications in a case study-type format.
Having an overarching, step-by-step design approach serves
two purposes: It provides a useful starting point for any real-world
controls problem, and it provides meaningful checkpoints once the
design process is underway. This chapter develops just such a general
approach, which will be applied in the case studies.
703

704
Chapter 10 Control System Design: Principles and Case Studies
Chapter Overview
Section 10.1 opens the chapter with a step-by-step design process
that is sufﬁciently general to apply to any control design process, but
which also provides useful deﬁnitions and directions. We then apply
the design process to four practical, complex applications: design of
an attitude control system for a satellite (Section 10.2), lateral and
longitudinal control of a Boeing 747 (Section 10.3), and control of
the fuel-air ratio in an automotive engine (Section 10.4), control of
a disk drive (Section 10.5), and control of a rapid thermal processing
(RTP) system (Section 10.6). The satellite case study is representative
of the control of geosynchronous communications satellite systems.
The study addresses the design of robust control systems in which
the physical parameters are known to vary within a given range. In
this system the control system needs to meet speciﬁcations from
the "beginning-of-life" (BOL) to the "end-of-life" (EOL) that spans a
period of 12-15 years. The satellite's moment of inertia and mass will
vary as fuel is expended for attitude control, and by deployment and
re-orientation of satellite antennas.
The satellite case study illustrates the use of notch compensation
for a system with lightly damped resonances. We will see from this
case study that collocated actuator and sensor systems are much eas-
ier to control than noncollocated systems. The Boeing 747 case study
addresses the familiar ﬂight control system of commercial passenger
aircraft. The nonlinear equations of motion are given and are lin-
earized about a particular ﬂight condition. The rigid body dynamics,
longitudinal and lateral-directional, are each fourth order. Of course,
the ﬂexible modes need also be considered for a more accurate model.
The Boeing 747 lateral-stabilization case study will illustrate the use
offeedbackasaninner-loopdesignedtoaidthepilot, whowillprovide
the primary outer-loop control. The altitude control study will show
how to combine inner-loop feedback with outer-loop compensation
to design a complete control system. The air-to-fuel ratio automotive
case study is a real-world example that includes a nonlinear sensor
and a pure time delay. We will use the describing function method
of Chapter 9 to analyze the behavior of this system. Another famil-
iar problem to every PC user is the control of data stored on a disk
drive. This case study is about position control and bandwidth will be
a key performance parameter. The RTP case study from semiconductor
wafer fabrication is remarkably close to an industrial application. The
problem concerns temperature tracking and disturbance rejection for
a highly nonlinear thermal system. The actuator (lamp) is also nonlin-
ear and we will use the technique from Chapter 9 to try to cancel the
effect of this nonlinearity. Another key aspect of this system is actua-
tor saturation and the fact that the control signal cannot go negative.
In all these case studies the designer needs to be able to use multiple
tools from previous chapters, including the root locus, the frequency

10.1 An Outline of Control Systems Design
705
response, pole placement by state feedback, and (nonlinear) simula-
tion of time responses to obtain a satisfactory design. In Section 10.7
we present a case study from the emerging ﬁeld of systems biology and
describe chemotaxis or how Escherichia coli (E. coli) swims away from
trouble. Section 10.8 provides a historical perspective on applications
of feedback control.
10.1
An Outline of Control Systems Design
Control engineering is an important part of the design process of many
dynamic systems. As suggested in Chapter 4, the deliberate use of feedback
can stabilize an otherwise unstable system, reduce the error due to distur-
bance inputs, reduce the tracking error while following a command input,
and reduce the sensitivity of a closed-loop transfer function to small varia-
tions in internal system parameters. In those situations for which feedback
control is required, it is possible to outline an approach to control systems
design that often leads to a satisfactory solution.
Before describing this approach, we wish to emphasize that the purpose
of control is to aid the product or process—the mechanism, the robot, the
chemical plant, the aircraft, or whatever—to do its job. Engineers engaged
in other areas of the design process are increasingly taking the contribution
of control into account early in their plans. As a result, more and more
systemshavebeendesignedsothattheywillnotworkatallwithoutfeedback.
This is especially signiﬁcant in the design of high-performance aircraft,
where control has taken its place along with structures and aerodynamics as
essential to assure that the craft will even ﬂy at all. It is impossible to give a
description of such overall design in this book, but recognizing the existence
of such cases places in perspective not only the speciﬁc task of control system
design but also the central role this task can play in an enterprise.
Control system design begins with a proposed product or process whose
satisfactory dynamic performance depends on feedback for stability, distur-
bance regulation, tracking accuracy, or reduction of the effects of parameter
variations. We will give an outline of the design process that is general
enough to be useful whether the product is an electronic ampliﬁer or a large
structure to be placed in earth orbit. Obviously, to be so widely applicable,
our outline has to be vague with respect to physical details and speciﬁc only
with respect to the feedback-control problem. To present our results, we will
divide the control design problem into a sequence of characteristic steps.
STEP 1. Understand the process and translate dynamic performance
requirements into time, frequency, or pole-zero speciﬁcations. The impor-
Speciﬁcations
tance of understanding the process, what it is intended to do, how much
system error is permissible, how to describe the class of command and
disturbance signals to be expected, and what the physical capabilities and
limitations are can hardly be overemphasized. Regrettably, in a book such as
this, it is easy to view the process as a linear, time-invariant transfer function
capable of responding to inputs of arbitrary size, and we tend to overlook the

706
Chapter 10 Control System Design: Principles and Case Studies
fact that the linear model is a very limited representation of the real system,
valid only for small signals, short times, and particular environmental con-
ditions. Do not confuse the approximation with reality. You must be able to
use the simpliﬁed model for its intended purpose, and to return to an accurate
model or the actual physical system to really verify the design performance.
Typical results of this step are speciﬁcations that the system have a step
response inside some constraint boundaries (as shown in Fig. 10.1a), an
open-loop frequency response satisfying certain constraints (Fig. 10.1b), or
closed-loop poles to the left of some constraint boundary (Fig. 10.1c).
STEP 2. Select sensors. In sensor selection, consider which variables are
Sensors
important to control and which variables can physically be measured. For
example, in a jet engine there are critical internal temperatures that must be
controlled, but that cannot be measured directly in an operational engine.
Select sensors that indirectly allow a good estimate to be made of these
critical variables. It is important to consider sensors for the disturbance.
Sometimes, especially in chemical processes, it is beneﬁcial to sense a load
disturbance directly, because improved performance can be obtained if this
information is fed forward to the controller.
Following are some factors that inﬂuence sensor selection:
Number of sensors and
locations:
Select minimum required number of sensors and their optimal
locations
Technology:
Electric or magnetic, mechanical, electromechanical, electro-
optical, piezoelectric
Functional
performance:
Linearity, bias, accuracy, bandwidth, resolution, dynamic
range, noise
Physical properties:
Weight, size, strength
Quality factors:
Reliability, durability, maintainability
Cost:
Expense, availability, facilities for testing and maintenance
STEP 3. Select actuators. In order to control a dynamic system, obviously
you must be able to inﬂuence the response. The device that does this is the
y(t)
t
log ƒGƒ
log v
jG
vc
(a)
log v
Im(s)
Re(s)
(b)
(c)
05
-1805
Figure 10.1
Examples of: (a) time-response; (b) frequency-response; and (c) pole-zero speciﬁcations resulting from
Step 10.1

10.1 An Outline of Control Systems Design
707
actuator. Before choosing a speciﬁc actuator, consider which variables can
Actuators
be inﬂuenced. For example, in a ﬂight vehicle many conﬁgurations of mov-
able surfaces are possible, and the inﬂuence these have on the performance
and controllability of the craft can be profound. The locations of jets or other
torque devices are also a major part of the control design of spacecraft.
Having selected a particular variable to control, you may need to
consider other factors:
Number of actuators
and locations:
Select minimum required actuators and their optimal locations
Technology:
Electric, hydraulic, pneumatic, thermal, other
Functional
performance:
Maximum force possible, extent of the linear range, maximum
speed possible, power, efﬁciency, etc.
Physical properties:
Weight, size, strength
Quality factors:
Reliability, durability, maintainability
Cost:
Expense, availability, facilities for testing and maintenance
STEP 4. Construct a linear model. Here you take the best choice for process,
Linearization
actuator, and sensor; identify the equilibrium point of interest; and construct
a small-signal dynamic model valid over the range of frequencies included
in the speciﬁcations of Step 1. You should also validate the model with
experimental data where possible. To be able to make use of all the available
tools, express the model in state-variable and pole-zero form as well as in
frequency-response form. As we have seen, Matlab and other computer-
aided control systems design software packages have the means to perform
the transformations among these forms. Simplify and reduce the order of the
model if necessary. Quantify model uncertainty.
STEP 5. Try a simple proportional-integral-derivative (PID) or lead-lag
design. To form an initial estimate of the complexity of the design problem,
Simple compensation
PID/lead-lag design
sketch a frequency response (Bode plot) and a root locus with respect to plant
gain. If the plant-actuator-sensor model is stable and minimum phase, the
Bode plot will probably be the most useful; otherwise, the root locus shows
very important information with respect to behavior in the right half-plane
(RHP). In any case, try to meet the speciﬁcations with a simple controller of
the lead-lag variety, including integral control if steady-state error response
requires it. Do not overlook feed-forward of the disturbances if the necessary
sensor information is available. Consider the effect of sensor noise, and
compare a lead network to a direct sensor of velocity to see which gives a
better design.
STEP 6. Evaluate/modify plant. Based on the simple control design, evalu-
ate the source of the undesirable characteristics of the system performance.
Reevaluate the speciﬁcations, the physical conﬁguration of the process, and
the actuator and sensor selections in light of the preliminary design, and
return to Step 1 if improvement seems necessary or feasible. For example,
in many motion-control problems, after testing the ﬁrst-pass design, you
might ﬁnd vibrational modes that prevent the design from meeting the initial

708
Chapter 10 Control System Design: Principles and Case Studies
speciﬁcations of the problem. It may be much easier to meet the speciﬁca-
tions by altering the structure of the plant through the addition of stiffening
members or by passive damping than to meet them by control strategies
alone. An alternative solution may be to move a sensor so it is at a node
of a vibration mode, thus providing no feedback of the motion. Also, some
actuator technologies (such as hydraulic) have many more low-frequency
vibrations than others (such as electric) do and changing the actuator tech-
nology may be indicated. In a digital implementation, it may be possible to
revise the sensor-controller-actuator system structure so as to reduce time
delay, which is always a destabilizing element. In thermal systems, it is often
possible to change heat capacity or conductivities by material substitution
that will enhance the control design. It is important to consider all parts of
the design, not only the control logic, to meet the speciﬁcations in the most
cost-effective way. If the plant is modiﬁed, go back to Step 1. If the design
now seems satisfactory, go to Step 8; otherwise try Step 7.
STEP 7. Try an optimal design. If the trial-and-error compensators do not
Optimal design
give entirely satisfactory performance, consider a design based on optimal
control. The symmetric root locus (SRL) will show possible root locations
from which to select locations for the control poles that meet the response
speciﬁcations; you can select locations for the estimator poles that represent
a compromise between sensor and process noise. Plot the corresponding
open-loop frequency response and the root locus to evaluate the stability
margins of this design and its robustness to parameter changes. You can
modify the pole locations until a best compromise results. Returning to the
SRL with different cost measures is often a part of this step, or computations
via the direct functions lqr and lqe can be used. Another variation of optimal
control is to propose a ﬁxed structure controller with unknown parameters,
formulate a performance cost function, and use parameter optimization to
ﬁnd a good set of parameter values.
Compare the optimal design yielding the most satisfactory frequency
response with the transform-method design you derived in Step 5. Select the
better of the two before proceeding to Step 8.
STEP 8. Build a computer model, and compute (simulate) the performance
of the design. After reaching the best compromise among process modiﬁ-
cation, actuator and sensor selection, and controller design choice, run a
computer model of the system. This model should include important nonlin-
earities, such as actuator saturation, realistic noise sources, and parameter
variations you expect to ﬁnd during operation of the system. The simula-
tion will often identify sensitivities that may lead to going back to Step 5
or even Step 2. Design iterations should continue until the simulation con-
ﬁrms acceptable stability and robustness. As part of this simulation you can
often include parameter optimization, in which the computer tunes the free
parameters for best performance. In the early stages of design the model
you simulate will be relatively simple; as the design progresses, you will
study more complete and detailed models. At this step it is also possible to

10.1 An Outline of Control Systems Design
709
compute a digital equivalent of the analog controller as described in Chap-
ters 4 and 8. Some reﬁnement of the controller parameters may be required
to account for the effects of digitization. This allows the ﬁnal design to be
implemented with digital processor logic.
If the results of the simulation prove the design satisfactory, go to Step 9,
otherwise return to Step 1.
STEP 9. Build a prototype. As the ﬁnal test before production, it is com-
Prototype
mon to build and test a prototype. At this point you verify the quality of the
Prototype testing
model, discover unsuspected unmodelled dynamics such as vibration and
other modes, and consider ways to improve the design. Implement the con-
troller using embedded software/hardware. Tune the controller if necessary.
After these tests, you may want to reconsider the sensors, actuators, and
process and return to Step 1—unless time, money, or ideas have run out.
This outline is an approximation of good practice; other engineers will
have variations on these themes. In some cases you may wish to carry out
the steps in a different order, to omit a step, or to add one. The stages of
simulation and prototype construction vary widely, depending on the nature
of the system. For systems for which a prototype is difﬁcult to test and rework
(for example, a satellite) or where a failure is dangerous (for example, active
stabilization of a high-speed centrifuge or landing a human on the moon),
most of the design veriﬁcation is done through simulation of some sort.
It may take the form of a digital numerical simulation, a laboratory scale
model, or a full-size laboratory model with a simulated environment. For
systems that are easy to build and modify (for example, feedback control
for an automotive fuel system), the simulation step is often skipped entirely;
design veriﬁcation and reﬁnement are instead accomplished by working with
prototypes.
One of the issues raised in the preceding discussion (Step 6) was the
important consideration for changing the plant itself. In many cases, proper
plant modiﬁcations can provide additional damping or increase in stiffness,
change in mode shapes, reduction of system response to disturbances, reduc-
tion of Coulomb friction, change in thermal capacity or conductivity, etc. It
is worth elaborating on this by way of speciﬁc examples from the authors'
experiences. In a semiconductor wafer-processing example, the edge ring
holding the wafer was identiﬁed as a limiting factor in closed-loop con-
trol. Modifying the thickness of the edge ring and using a different coating
material reduced the heat losses and, together with relocating one of the
temperature sensors closer to the edge ring, resulted in signiﬁcant improve-
ment in control performance. In another application, thin ﬁlm processing,
simply changing the order of the two incoming ﬂows resulted in signiﬁ-
cant improvement in the mixing of the precursor and oxidizer materials, and
led to improvement in uniformity of the ﬁlm. In an application on physi-
cal vapor deposition using RF-plasma, the shape of the target was modiﬁed
to be curved to counter the geometry effects of the chamber, and yielded
substantial improvements in deposition uniformity. As the last example, in
a hydraulic spindle control problem, adding oil temperature control with

710
Chapter 10 Control System Design: Principles and Case Studies
ceramic insulation and a temperature sink for the bell housing resulted in
several orders of magnitude reduction in disturbances not achievable by
feedback control alone.1 One can also mention aerospace applications for
which the control was an afterthought, and the feedback control problem
became exceedingly difﬁcult and resulted in poor closed-loop performance.
The moral of this discussion is that one must not forget the option of modify-
ing the plant itself to make the control problem easier and provide maximum
closed-loop performance.
The usual approach of designing the system and "throwing it over the
fence" to the control group has proved to be inefﬁcient and ﬂawed. A better
approach that is gaining momentum is to get the control engineer involved
from the onset of a project to provide early feedback on whether or not it
is difﬁcult to control the system. The control engineer can provide valuable
feedback on the choice of actuators and sensors and can even suggest mod-
iﬁcations to the plant. It is often much more efﬁcient to change the plant
design while it is on the drawing board before "any metal has been bent."
Closed-loop performance studies can then be performed on a simple model
of the system early on.
Implicit in the process of design is the well-known fact that designs
within a given category often draw on experience gained from earlier models.
Thus, good designs evolve rather than appear in their best form after the ﬁrst
pass. We will illustrate the method with several cases (Sections 10.2 to 10.6).
For easy reference, we summarize the steps here.
Summary of Control Design Steps
1. Understand the process and its performance requirements.
2. Select the types and number of sensors considering location, technology,
and noise.
3. Select the types and number of actuators considering location, technol-
ogy, noise, and power.
4. Construct a linear model of the process, actuator, and sensor.
5. Try a simple trial design based on the concepts of lead-lag compensation
or PID control. If satisﬁed, go to Step 8.
6. Consider modifying the plant itself for improved closed-loop control.
7. If the performance from the simple compensator in Step 5 is not ade-
quate, perform a trial pole-placement design based on optimal control
or other criteria.
8. Simulate the design, including the effects of nonlinearities, noise, and
parameter variations. If the performance is not satisfactory, return to
Step 1 and repeat. Consider modifying the plant itself for improved
closed-loop control.
9. Build a prototype and test it. If not satisﬁed, return to Step 1 and repeat.
1Our colleague Prof. Daniel DeBra strongly believes in considering modifying the plant itself
as an option for improved control. He cites this particular application to make the point. Of
course, we agree with him!

10.2 Design of a Satellite's Attitude Control
711
10.2
Design of a Satellite's Attitude Control
Our ﬁrst example, taken from the space program, is suggested by the need
to control the pointing direction, or attitude, of a satellite in orbit about the
earth. Figure 10.2(a) shows a picture of a geosynchronous communications
satellite. We will go through each step in our design outline and touch on
some of the factors that might be considered for the control of such a system.
STEP 1. Understand the process and its performance speciﬁcations. A
satellite is sketched in Fig. 10.2(b). We imagine that the vehicle has an astro-
nomical survey mission requiring accurate pointing of a scientiﬁc sensor
package. This package must be maintained in the quietest possible environ-
ment, which entails isolating it from the vibrations and electrical noise of
the main service body and from its power supplies, thrusters, and commu-
nication gear. We model the resulting structure as two masses connected
by a ﬂexible boom. In Fig. 10.2(b), the satellite attitude θ2 is the angle
between the star sensor and the instrument package, and θ1 is the angle of
the main satellite with respect to the star. Figure 10.2(b) shows the equivalent
mechanical system diagram for the satellite, where the sensor is mounted
to the disk associated with θ2. Disturbance torques due to solar pressure,
micrometeorites, and orbit perturbations are computed to be negligible. The
pointing requirement arises when it is necessary to point the unit in another
direction. It can be met by dynamics with a transient settling time of 20 sec
and an overshoot of no more than 15%. The dynamics of the satellite include
Figure 10.2
(a) Picture of the
geosynchronous
communications
satellite IPSTAR;
(b) diagram of a
satellite and its
two-body model
Source: Courtesy Thaicom PLC
and Space Systems/Loral

712
Chapter 10 Control System Design: Principles and Case Studies
parameters that can vary. The control must be satisfactory for any parameter
values in a prespeciﬁed range to be given when the equations are written.
STEP 2. Select sensors. In order to orient the scientiﬁc package, it is nec-
essary to measure the attitude angles of the package. For this purpose we
propose to use a star tracker, a system based on gathering an image of a
speciﬁc star and keeping it centered on the focal plane of a telescope. This
sensor gives a relatively noisy but very accurate (on the average) reading
proportional to θ2, the angle of deviation of the instrument package from
the desired angle. To stabilize the control, we include a rate gyro to give a
clean reading of ˙θ2, because a lead network on the star-tracker signal would
amplify the noise too much. Furthermore, the rate gyro can stabilize large
motions before the star tracker has acquired the target star image.
STEP 3. Select actuators. Major considerations in selecting the actuator are
precision, reliability, weight, power requirements, and lifetime. Alternatives
for applying torque are cold-gas jets, reaction wheels or gyros, magnetic
torquers, and a gravity gradient. The jets have the most power and are the
least accurate. Reaction wheels are precise but can transfer only momentum,
so jets or magnetic torquers are required to "dump" momentum from time
to time. Magnetic torquers provide relatively low levels of torque and are
suitable only for some low-altitude satellite missions.A gravity gradient also
provides a very small torque that limits the speed of response and places
severe restrictions on the shape of the satellite. For purposes of this mission,
we select cold-gas jets as being fast and adequately accurate.
STEP 4. Make a linear model. For the satellite, we assume two masses
connected by a spring with torque constant k and viscous-damping constant b
as shown in Fig. 10.2. The equations of motion are
J1 ¨θ1 + b( ˙θ1 −˙θ2) + k(θ1 −θ2) = Tc,
(10.1a)
J2 ¨θ2 + b( ˙θ2 −˙θ1) + k(θ2 −θ1) = 0,
(10.1b)
where Tc is the control torque on the main body. With inertias J1 = 1
and J2 = 0.1, the transfer function is
G(s) =
10bs + 10k
s2(s2 + 11bs + 11k).
(10.2)
If we choose
x = [ θ2
˙θ2
θ1
˙θ1 ]T,
as the state vector, then, using Eq. (10.1a) and assuming Tc ≡u, we ﬁnd
that the equations of motion in state-variable form are
˙x =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
0
−k
J2
−b
J2
k
J2
b
J2
0
0
0
1
k
J1
b
J1
−k
J1
−b
J1
⎤
⎥⎥⎥⎥⎥⎦
x +
⎡
⎢⎢⎢⎢⎣
0
0
0
1
J1
⎤
⎥⎥⎥⎥⎦
u,
(10.3a)
y =
 1
0
0
0 	
x.
(10.3b)

10.2 Design of a Satellite's Attitude Control
713
Physical analysis of the boom leads us to assume that the parameters k
and b vary as a result of temperature ﬂuctuations but are bounded by
0.09 ≤k ≤0.4,
(10.4a)
0.038

k
10 ≤b ≤0.2

k
10.
(10.4b)
As a result, the vehicle's natural resonance frequency ωn can vary between 1
and 2 rad/sec, and the damping ratio ζ varies between 0.02 and 0.1.
One approach to control design when parameters are subject to variation
Selecting nominal values
for varying parameters
is to select nominal values for the parameters, construct the design for this
model, and then test the controller performance with other parameter values.
In the present case we choose nominal values of ωn = 1 and ζ = 0.02.
The choice is somewhat arbitrary, being based on experience and heuristic
analysis. However, note that these are the lowest values in their respective
ranges and thus correspond to the plant that is probably the most difﬁcult
to control so as to meet the speciﬁcations. We assume that a design for
this model has a good chance to meet the speciﬁcations for other parameter
values as well. (Another choice would be to select a model with average
values for each parameter.) The selected parameter values are k = 0.091
and b = 0.0036; with J1 = 1 and J2 = 0.1, the nominal equations become
˙x =
⎡
⎢⎢⎣
0
1
0
0
−0.91
−0.036
0.91
0.036
0
0
0
1
0.091
0.0036
−0.091
−0.0036
⎤
⎥⎥⎦x +
⎡
⎢⎢⎣
0
0
0
1
⎤
⎥⎥⎦u,
(10.5a)
y = [ 1
0
0
0 ]x.
(10.5b)
The corresponding transfer function, using the Matlab ss2tf function, is then
G(s) =
0.036(s + 25)
s2(s2 + 0.04s + 1).
(10.6)
When a trial design is completed, the computer simulation should be
run with a range of possible parameter values to ensure that the design has
adequate robustness to tolerate these changes. Equations (3.74)-(3.76) tell
us that the dynamic performance speciﬁcations will be met if the closed-loop
poles have a natural frequency of 0.5 rad/sec and a closed-loop damp-
ing ratio of 0.5; these correspond to an open-loop crossover frequency of
ωc ∼= 0.5 rad/sec and a phase margin of about PM = 50◦. We will try to
meet these design criteria.
STEP 5. Try a lead-lag or PID controller. The proportional-gain root locus
for the nominal plant is drawn in Fig. 10.3, and the Bode plot is given in
Fig. 10.4. We can see from Fig. 10.4 that this may be a difﬁcult design
problem because the frequency of the lightly damped resonance is greater
than the crossover-frequency design point by only a factor of 2. This situation
will require that the compensation can correct for the phase lag of the plant
at the resonance frequency. Such a correction is very dependent on knowing
the resonance frequency, which is subject to change in this case. There may
be trouble ahead.

714
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.3
Root locus of KG(s)
-2
-1.5
-1
-0.5
0
1
0.5
2
1.5
Real axis
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
Imaginary axis
Figure 10.4
Open-loop Bode plot of
KG(s) for K = 0.5
-1805
Magnitude, ƒKG(s)ƒ
10
0.01
Phase
1
0.1
v (rad/sec)
-40
db
(a)
-20
0
20
40
0.1
1
10
100
-2005
-2205
-2405
-2605
-2805
-3005
-3205
-3405
-3605
10
1
0.1
v (rad/sec)
(b)

10.2 Design of a Satellite's Attitude Control
715
In order to illustrate some important aspects of compensation design,
we will at ﬁrst ignore the resonance and generate a design that would be
acceptable for the rigid body alone. We take the process transfer function
to be 1/s2, the feedback to be position plus derivative (star tracker plus rate
gyro) or PD control with the transfer function Dc(s) = K(sTD + 1), and the
response objective to be ωn = 0.5 rad/sec and ζ = 0.5. A suitable controller
would be
Dc1(s) = 0.25(2s + 1).
(10.7)
The root locus for the actual plant with Dc1 is shown in Fig. 10.5 and the Bode
plot in Fig. 10.6. From these plots we can see that the low-frequency poles are
reasonable but that the system will be unstable because of the resonance.2 At
this point we take the simple action of reducing our expectation with respect
to bandwidth and we slow the system down by lowering the gain until the
system is stable. With so little damping, we must really go slowly. A bit of
experimentation leads to
Dc2(s) = 0.001(30s + 1),
(10.8)
for which the root locus is drawn in Fig. 10.7 and the Bode plot given in
Fig. 10.8. The Bode plot shows that we have a phase margin of 50◦but a
crossover frequency of only ωc = 0.04 rad/sec. While this is too low to meet
the settling-time speciﬁcation, a low crossover frequency is unavoidable if
we expect to keep the gain at the resonance frequency below unity so that it
is gain stabilized.
An alternative approach to the problem is to place zeros near the lightly
damped poles and use them to hold these poles back from the RHP. Such a
compensation has a frequency response with a very low gain near the fre-
quency of the offending poles and a reasonable gain elsewhere. Because the
Figure 10.5
Root locus of
KDc1(s)G(s)
Re(s)
Im(s)
-1.0
-2.0
1.0
2.0
2.0
-2.0
2If this system were built, the actuator jets would saturate as the response grew. We could
analyze the response using the method described in Section 9.3 for nonlinear systems. From
the analysis we would expect the signal to grow and the equivalent gain of the actuator to fall
until the roots return to the imaginary axis near ωn. The resulting limit cycle would rapidly
deplete the control gas supply.

716
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.6
Bode plot of KDc1(s)G(s)
-1205
Magnitude, ƒKDc1(s)G(s)ƒ
10
0.0001
Phase
1
0.1
v (rad/sec)
-80
db
(a)
-20
0
20
40
0.001
0.01
1
100
-1405
-1605
-1805
-2005
-2205
-2405
-2605
-2805
-3005
10
1
0.1
v (rad/sec)
(b)
-40
-60
0.1
10
Figure 10.7
Root locus of
KDc2(s)G(s)
Re(s)
Im(s)
-0.5
-0.5
0.5

10.2 Design of a Satellite's Attitude Control
717
Figure 10.8
Bode plot of Dc2(s)G(s)
-805
Magnitude, ƒDc2(s)G(s)ƒ
Phase
v (rad/sec)
db
(a)
-20
0
20
10
0.01
v (rad/sec)
(b)
-40
-1205
-1605
-2005
-2405
-2805
-1805
0.1
1
10
0.01
0.1
1
10
1
0.1
0.01
-1005
-1405
-2205
-2605
Figure 10.9
Twin-tee realization
of a notch ﬁlter
+
-
ei
+
-
eo
Notch
frequency response seems to have a dent or notch in it, this compensation is
called a notch ﬁlter. (It is also called a band reject ﬁlter in electric network
Notch ﬁlter
theory.) An RC circuit with a notch characteristic is shown in Fig. 10.9, its
pole-zero pattern in Fig. 10.10, and its frequency response in Fig. 10.11.
The +180◦phase lead of the notch can be used to correct for the 180◦
phase lag of the resonance; if the notch frequency is lower than the plant's
resonance frequency, the system phase is kept above 180◦near resonance.

718
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.10
Notch ﬁlter pole-zero
pattern
Re(s)
Im(s)
0.9
-0.9
-25
Figure 10.11
Bode plot of a notch
ﬁlter
1805
Magnitude
10
0.01
Phase
1
0.1
v (rad/sec)
-40
db
(a)
-20
0
40
60
1
10
100
1000
10
1
0.1
v (rad/sec)
(b)
20
0.1
1605
1405
1205
1005
805
605
405
205
05
-205
With this idea we return to the compensation given by Eq. (10.7) and
add the notch, producing the revised compensator transfer function
Dc3(s) = 0.25(2s + 1) (s/0.9)2 + 1
[(s/25) + 1]2 .
(10.9)
The Bode plot for this case is shown in Fig. 10.12, the root locus in Fig. 10.13,
and the unit step response in Fig. 10.14. The settling time of the design is

10.2 Design of a Satellite's Attitude Control
719
Figure 10.12
Bode plot of KDc3(s)G(s)
605
Magnitude, ƒKDc3(s)G(s)ƒ
10
0.01
Phase
1
0.1
v (rad/sec)
-40
db
(a)
-20
0
20
40
0.1
1
10
100
10
1
0.1
v (rad/sec)
(b)
vc
105
-405
-905
-1405
-1905
vc
PM
too long for the speciﬁcation and the overshoot is too large, but this design
approach seems promising; with iteration it could lead to a satisfactory
compensator.
We now recall that the compensator is expected to provide adequate
performance as the parameters vary over the ranges given by Eq. (10.3a).
An examination of the robustness of the design can be made by looking at
the root locus shown in Fig. 10.15, which is drawn using the compensator
of Eq. (10.9) and the plant with ωn = 2, rather than 1, such that
ˆG(s) =
(s/50 + 1)
s2(s2/4 + 0.02s + 1).
(10.10)
This assumes that the boom is as stiff as possible. Notice that now the low-
frequency poles have a damping ratio of only 0.02. Combining the various
parameter values, we get the frequency response and transient response
shown in Figs. 10.16 and 10.17. We could make a few more trial-and-error
iterations with the notch ﬁlter and rate feedback, but the system is complex
enough that a look at state-space designs now seems reasonable. We go
to Step 7.

720
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.13
Root locus of
KDc3(s)G(s)
Re(s)
Im(s)
-2.0
1.0
2.0
2.0
-2.0
Figure 10.14
Closed-loop step
response of Dc3(s)G(s)
where θ2(0) = 0.2 rad
Time (sec)
Amplitude
1.4
0
5
10
15
20
25
30
35
40
1.2
1.0
0.8
0.6
0.4
0.2
0
Figure 10.15
Root locus of
KDc3(s)ˆG(s)
Re(s)
Im(s)
-7.0
1.0
3.0
-3.0
-1.0
-4.0
-3.0
-1.0
-2.0

10.2 Design of a Satellite's Attitude Control
721
Figure 10.16
Bode plot of KDc3(s)ˆG(s)
1005
Magnitude, ƒKDc3(s)G(s)ƒ
10
0.01
Phase
1
0.1
v (rad/sec)
-40
db
(a)
-20
0
20
40
0.1
1
10
100
10
1
0.1
v (rad/sec)
(b)
505
05
-505
-1005
-1505
-2005
-1805
ˆ
Figure 10.17
Closed-loop step
response of Dc3(s)G(s)
Time (sec)
Amplitude
1.4
0
5
10
15
20
25
30
35
40
1.2
1.0
0.8
0.6
0.4
0.2
0

722
Chapter 10 Control System Design: Principles and Case Studies
STEP 6. Evaluate/modify plant. Refer to the collocated control discussion
after Step 8.
STEP 7. Try an optimal design using pole placement. Using the state-
variable formulation of the equations of motion in Eq. (10.4a), we devise
a controller that will place the closed-loop poles in arbitrary locations. Of
course, used without thought, the method of pole placement can also result
in a design that requires unreasonable levels of control effort or is very sensi-
tive to changes in the plant transfer function. Guidelines for pole placement
are given in Chapter 7; an often successful approach is to derive optimal
pole locations using the SRL. Figure 10.18 shows the SRL for the problem
at hand. To obtain a bandwidth of about 0.5 rad/sec, we select closed-loop
control poles from this locus at −0.45 ± 0.34j and −0.15 ± 1.05j.
If we select αc(s), as discussed earlier, from the SRL, the control
gain using the Matlab function place is
K =
 −0.2788
0.0546
0.6814
1.1655 	
.
(10.11)
Figure 10.19 shows the step responses for the nominal plant parameters
and stiff-spring plant models. The Bode plot of the SRL controller design
Figure 10.18
Symmetric root locus of
the satellite system
Re(s)
Im(s)
-1.0
-2.0
1.0
2.0
2.0
-2.0
Figure 10.19
Closed-loop step
response of the SRL
design
Time (sec)
Amplitude
0
5
10
15
20
1.2
1.0
0.8
0.6
0.4
0.2
0
Stiff spring
Nominal

10.2 Design of a Satellite's Attitude Control
723
with the nominal plant parameters can be computed from the loop transfer
function (by breaking the loop at u)
KX(s)
U(s) = K(sI −A)−1B,
and results in a phase margin of about 60◦, as shown in Fig. 10.20. While the
speed of response of the design meets the speciﬁcations with the nominal
plant, the settling time when the plant has the stiff spring is a bit longer
than the speciﬁcations call for. We might be able to get a better compromise
between the nominal and the stiff-spring cases by selecting another point on
the SRL; at this point we do not know. The designer must face alternatives
such as these and select the best compromise for the problem at hand.
The design of Fig. 10.19 is based on full-state feedback. To complete the
optimal design, we need an estimator. We select the closed-loop estimator
error poles to be about eight times faster than the control poles. The reason
for this is to keep the error poles from reducing the robustness of the design;
a fast estimator will have almost the same effect on the response as no
estimator at all. We choose the error poles from the SRL at −7.7 ± 3.12j
Figure 10.20
Frequency response
of the SRL design from
u to Kx
10
0.1
Phase
1
0.1
v (rad/sec)
db
(a)
-20
0
20
40
1
10
100
10
1
0.1
v (rad/sec)
(b)
-405
-605
-805
-1005
-1205
-1405
-1605
-1805
U(jv)
KX(jv)
Magnitude, 
PM

724
Chapter 10 Control System Design: Principles and Case Studies
and −3.32 ± 7.85j. Pole placement with these values leads to an estimator
(ﬁlter) gain, using the Matlab function place:
L =
⎡
⎢⎢⎣
22
242.3
1515.4
5503.9
⎤
⎥⎥⎦.
(10.12)
After we combine the control gain and estimator, as described in Section 7.8,
the compensator transfer function that results from Eq. (7.177) is
Dc4(s) =
−745(s + 0.3217)(s + 0.0996 ± 0.9137 j)
(s + 3.1195 ± 8.3438 j)(s + 8.4905 ± 3.6333 j).
(10.13)
The frequency response of this compensator (Fig. 10.21) shows that
pole placement has introduced a notch implicitly. The frequency response
andtherootlocusofthecombinedsystemDc4(s)G(s)aregiveninFigs.10.22
and 10.23, while Fig. 10.24 shows the step response for both the nominal and
the stiff-spring plants. Notice that the design almost meets the speciﬁcations.
Figure 10.21
Bode plot of the optimal
compensator Dc4(s)
10
0.1
Phase
1
0.1
v (rad/sec)
db
(a)
-40
0
20
40
10
100
1000
10
1
0.1
v (rad/sec)
(b)
2505
Magnitude, ƒDc4(s)ƒ
-20
1
2005
1505
1005
505
05

10.2 Design of a Satellite's Attitude Control
725
Figure 10.22
Bode plot of the
compensated system
Dc4(s)G(s)
10
0.01
Phase
1
0.1
v (rad/sec)
db
(a)
-40
0
20
40
1
10
100
10
1
0.1
v (rad/sec)
(b)
05
Magnitude, ƒDc4(s)G(s)ƒ
-20
0.1
-505
-1005
-1505
-2005
-2505
-3005
-1805
Figure 10.23
Root locus of Dc4(s)G(s)
Re(s)
Im(s)
-1.0
-2.0
1.0
2.0
2.0
-2.0
STEP 8. Simulate the design, and compare the alternatives. At this point
we have two designs, with differing complexities and different robustness
properties. The notch-ﬁlter design might be improved with further iterations
or by starting with a different nominal case. The SRL design meets the

726
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.24
Closed-loop step
response of Dc4(s)G(s)
Time (sec)
Amplitude
0
5
0.2
0
Stiff
Nominal
10
15
20
25
30
0.4
0.6
0.8
1.0
1.2
speciﬁcations for the nominal plant but is too slow for the stiff-spring case,
although alternative selections for the pole locations might lead to a better
design. In either case, much more extensive studies need to be made to
explore the robustness and noise-response properties. Rather than follow
any of these paths, we consider some aspects of the physical system.
Both designs are strongly inﬂuenced by the presence of the lightly
damped resonant mode caused by the coupled masses. However, the transfer
function of this system is strongly dependent on the fact that the actuator is
on one body and the sensor is on the other (that is, not collocated). Suppose
that, rather than considering pointing the star tracker on the small mass, we
have the mission of pointing the main mass, perhaps toward an Earth station
for communications purposes. For this purpose we can put the sensor on the
same mass that holds the actuator—to give control with a collocated actuator
and sensor. Due to the physics of the situation, the system's transfer func-
Collocated actuator and
sensor
tion now has zeros close to the ﬂexible modes, so control can be achieved
using PD feedback alone, because the plant already has the effect of a notch
compensator. Consider the transfer function of the satellite with collocated
actuator and sensor (to measure θ1) for which the state matrices are
A =
⎡
⎢⎢⎣
0
1
0
0
−0.91
−0.036
0.91
0.036
0
0
0
1
0.091
0.0036
−0.091
−0.0036
⎤
⎥⎥⎦,
B =
⎡
⎢⎢⎣
0
0
0
1
⎤
⎥⎥⎦,
C = [ 0
0
1
0 ].
The transfer function of the system using the Matlab ss2tf function is
Gco(s) = C(sI −A)−1B = (s + 0.018 ± 0.954j)
s2(s + 0.02 ± j)
.
(10.14)

10.2 Design of a Satellite's Attitude Control
727
Notice the presence of the zeros in the vicinity of the complex conjugate
poles. If we now use the same PD feedback as before, namely,
Dc5(s) = 0.25(2s + 1),
(10.15)
then the system will not only be stabilized, but will also have a satisfactory
response (if we consider θ1 as the output), because the resonant poles tend
to be cancelled by the complex conjugate zeros.
Figures 10.25-10.27 show the frequency response, the root locus, and
the step response, respectively, for this system. Note from Fig. 10.27 that
the step response has the excess overshoot associated with the zero of the
compensator in the forward path of the transfer function.
The result is a very simple robust design achieved by moving the sen-
sor from a noncollocated position to one collocated with the actuator. The
result illustrates that, to achieve good feedback control, it is very important
to consider sensor location and other features of the physical problem. How-
ever, this last control design will not do for pointing the star tracker. This is
evident from plotting the output θ2 corresponding to the nice step response
of Fig. 10.27. The result is shown in Fig. 10.28.
Figure 10.25
Bode plot of
Dc5(s)Gco(s)
Magnitude, ƒDc5(s)Gco(s)ƒ
10
0.01
Phase
1
0.1
v (rad/sec)
-40
db
(a)
-20
0
20
40
0.1
1
10
100
10
1
0.1
v (rad/sec)
(b)
-405
-605
-805
-1005
-1205
-1405
-1605
-1805

728
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.26
Root locus for
Dc5(s)Gco(s)
Re(s)
Im(s)
-2.0
1.0
2.0
2.0
-2.0
Figure 10.27
Closed-loop step
response of the system
with collocated control,
Dc5(s)Gco(s) and
Dc5(s)ˆGco(s)
Time (sec)
Amplitude
1.4
0
10
1.2
1.0
0.8
0.6
0.4
0.2
0
20
30
40
50
with nominal plant, Gco
with perturbed plant, Gco
ˆ
Figure 10.28
Response at θ2 of the
collocated design
Time (sec)
Amplitude
2.0
0
100
0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
1.8
20
40
60
80
An architecture suggested by these results is to place a coarse star tracker
on the satellite body to be used for search and initial settling. Then switch
to a star tracker on the instrument package with longer settling time for ﬁne
control.

10.3 Lateral and Longitudinal Control of a Boeing 747
729
10.3
Lateral and Longitudinal Control
of a Boeing 747
The Boeing 747 (Fig. 10.29) is a large wide-body transport jet. A schematic
with the relevant coordinates that move with the airplane is shown in
Fig. 10.30. The linearized equations of (rigid-body) motion3 for the Boe-
ing 747 are of eighth order but are separated into two fourth-order sets
representing the perturbations in longitudinal (U, W, θ, and q in Fig. 10.30)
and lateral (φ, β, r, and p) motion. The longitudinal motion consists of
axial (X), vertical (Z), and pitching (θ, q) motion, while the lateral motion
consists of rolling (φ, p) and yawing (r, β) movement. The side-slip angle β
is a measure of the direction of forward velocity relative to the direction of
the nose of the airplane. The elevator control surfaces and the throttle affect
the longitudinal motion, whereas the aileron and rudder primarily affect lat-
eral motion. Although there is a small amount of coupling of lateral motion
into longitudinal motion, this is usually ignored, so the equations of motion
are treated as two decoupled fourth-order sets for designing the control, or
stability augmentation, for the aircraft.
The nonlinear rigid body equations of motion in body-axis coordinates,
under proper assumptions,4 can be derived as (Bryson, 1994)
m( ˙U + qW −rV) = X −mg sin θ + κT cos θ,
(10.16)
m( ˙V + rU −pW) = Y + mg cos θ sin φ,
m( ˙W + pV −qU) = Z + mg cos θ cos φ −κT sin θ,
Ix ˙p + Ixz˙r + (Iz −Iy)qr + Ixzqp = L,
(10.17)
Iy˙q + (Ix −Iz)pr + Ixz(r2 −p2) = M,
Iz˙r + Ixz˙p + (Iy −Ix)qp −Ixzqr = N,
Figure 10.29
Boeing 747
Source: © 2013 Boeing. Used
by permission. All rights
reserved.
3For derivation of equations of motion for an aircraft, the reader is referred to Bryson (1994),
Etkin and Reid (1996), and McRuer et al. (1973).
4x-z is the body-axis plane of mass symmetry.

730
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.30
Deﬁnition of aircraft
coordinates
x, u
Rudder
dr
y, y
a
b
u, q
Aileron da
Elevators de
f, p
c, r
z, w
Velocity vector
x, y, z = position coordinates
u, y, w = velocity coordinates
p = roll rate
q = pitch rate
r = yaw rate
f = roll angle
u =  pitch angle
c =  yaw angle
b = side-slip angle
a = angle of attack
where
m = mass of the aircraft,
[U, V, W] = body-axis components of the velocity of the center
of mass (c.m.),
β = tan−1
 V
U

,
[Uo, Vo, Wo] = reference velocities,
[p, q, r] = the body-axis components of the angular velocity of the
aircraft,
[X, Y, Z] = the body-axis aerodynamic forces about the c.m.,
[L, M, N] = the body-axis aerodynamic torques about the c.m.,
go = the gravitational force per unit mass,
Ii = the inertias in body axes,
(θ, φ) = the Euler pitch and roll angles of the aircraft body,
Vref = reference ﬂight speed,
T = the propulsive thrust resultant, and
κ = the angle between thrust and body x-axis.
The linearization of these equations can be carried out as follows: In the
steady-state straight, level, and constant speed ﬂight condition, ˙U = ˙V =
˙W = ˙p = ˙q = ˙r = 0. Furthermore, there is no turning in any axis so that
po = qo = ro = 0, and the wings will be level so that φ = 0. However,
there will be an angle of attack in order to provide some lift from the wings
to counteract the aircraft's weight, so θo and Wo ̸= 0, where

10.3 Lateral and Longitudinal Control of a Boeing 747
731
U = Uo + u,
(10.18)
V = Vo + v,
W = Wo + w.
The steady-state velocity body axis components will be
Uo = Vref cos(θo),
(10.19)
Vo = 0 (βo = 0),
Wo = Vref sin(θo),
as depicted in Fig. 10.31. With these conditions, the equilibrium (see
Chapter 9) equations are
0 = X0 −mgo sin θ0 + κT cos θ0,
(10.20)
0 = Y0,
Figure 10.31
Steady-state ﬂight
condition
Relative wind
-b
+dr
+f
Relative wind
z
x
+da
uo
+de
+a
Uo
Vref
Wo
(a)
(b)
(c)

732
Chapter 10 Control System Design: Principles and Case Studies
0 = Z0 + mgo cos θ0 −κT sin θ0,
0 = L0,
0 = M0,
0 = N0.
With the assumptions (Bryson, 1994)
(v2, w2) ≪u2,
(10.21)
(φ2, θ2) ≪1,
(p2, q2, r2) ≪u2
b2 ,
where b denotes the wingspan, many of the nonlinear terms in Eqs. (10.16)
and (10.17) can be neglected. Substitution of Eq. (10.20) in the nonlinear
equations of motion leads to a set of linear perturbational equations that
describe small deviations from constant speed, straight and level ﬂight. The
equations of motion then divide into two uncoupled sets of longitudinal and
lateral equations of motion.
For linearized longitudinal motion, the results are
⎡
⎢⎢⎣
˙u
˙w
˙q
˙θ
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
Xu
Xw
−Wo
−go cos θo
Zu
Zw
Uo
−go sin θo
Mu
Mw
Mq
0
0
0
1
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
u
w
q
θ
⎤
⎥⎥⎦+
⎡
⎢⎢⎣
Xδe
Zδe
Mδe
0
⎤
⎥⎥⎦δe,
(10.22)
where
u = forward velocity perturbation in the aircraft in x direction
(Fig. 10.30),
w = velocity perturbation in the z direction (also proportional to
perturbations in the angle of attack, α = w
U0 ),
q = angular rate about the positive y-axis, or pitch rate,
θ = pitch-angle perturbation from the reference θo value,
Xu,w,δe = partial derivative of the aerodynamic force in x direction with
respect to perturbations in u, w, and δe,5
Zu,w,δe = partial derivative of the aerodynamic force in z direction with
respect to perturbations in u, w, and δe,
Mu,w,q,δe = partial derivative of the aerodynamic (pitching) moment with
respect to perturbations in u, w, q, and δe,
δe = movable tail-section, or "elevator," angle for pitch control.
5X, Z, and M are stability derivatives and are identiﬁed from wind tunnel and ﬂight tests.

10.3 Lateral and Longitudinal Control of a Boeing 747
733
Woq, Uoq terms in the equations are due to the angular velocity of the
body ﬁxed (rotating) reference frame and arise directly from the left-hand
side of Eq. (10.16).
To determine altitude changes, we need to add the following equation
to the longitudinal equations of motion:
˙h = Vref sin θ −w cos θ.
(10.23)
This equation will result in the linearized altitude equation
˙h = Vref θ −w,
(10.24)
which is to be augmented with Eq. (10.22).
For linearized lateral motion, the results are
⎡
⎢⎢⎣
˙β
˙r
˙p
˙φ
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
Yv
−Uo
Vo
go cos θo
Nv
Nr
Np
0
Lv
Lr
Lp
0
0
tan θo
1
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
β
r
p
φ
⎤
⎥⎥⎦+
⎡
⎢⎢⎣
Yδr
Yδa
Nδr
Nδa
Lδr
Lδa
0
0
⎤
⎥⎥⎦
 δr
δa

,
(10.25)
where
β = side-slip angle, deﬁned to be v
Uo
,
r = yaw rate,
p = roll rate,
φ = roll angle,
Yv,δr,δa = partial derivative of the aerodynamic force in the y direction
with respect to perturbations in β, δr, and δa,
Nv,r,p,δr,δa = aerodynamic (yawing) moment stability derivatives,
Lv,r,p,δr,δa = aerodynamic (rolling) moment stability derivatives,
δr = rudder deﬂection,
δa = aileron deﬂection.
We will next discuss the design of a stability-augmentation system for
the lateral dynamics, called a yaw damper, and the autopilot affecting the
longitudinal behavior.
10.3.1
Yaw Damper
STEP 1. Understand the process and its performance speciﬁcations. Swept-
wingaircrafthaveanaturaltendencytobelightlydampedinthelateralmodes
of motion. At typical commercial-aircraft cruising speeds and altitudes, this
dynamic mode is sufﬁciently difﬁcult to control that virtually every swept-
wing aircraft has a feedback system to help the pilot. Therefore, the goal

734
Chapter 10 Control System Design: Principles and Case Studies
of our control system is to modify the natural dynamics so that the plane is
acceptable for the pilot to ﬂy.6 Studies have shown that pilots like natural fre-
quencies in the range of ωn ≲0.5 and damping ratio of ζ ≥0.5.Aircraft with
dynamics that violate these guidelines are generally considered fatiguing to
ﬂy and highly undesirable. With the pilot being a key part of the closed-loop
system, we want to make his or her job as easy as possible. Thus our system
speciﬁcations are to achieve lateral dynamics that meet these constraints.
STEP 2. Select sensors. The easiest measurement of aircraft motion to take
is the angular rate. The side-slip angle can be measured with a wind-vane
device, but it is noisier and less reliable for stabilization. Two angular
rates—roll and yaw—partake in the lateral motion. Study of the lightly
damped lateral mode indicates that it is primarily a yawing phenomenon,
so measurement of the yaw rate is a logical starting point for the design.
Until the early 1980s the measurement was made with a gyroscope with a
small, fast-spinning rotor that can yield an electric output proportional to
the angular yaw rate of the aircraft. Since the early 1980s most new aircraft
systems have relied on a laser device (called a ring-laser gyroscope) for the
measurement. Here, two laser beams traverse a closed path (often a triangle)
in opposite directions. As the triangular device rotates, the detected frequen-
cies of the two beams appear to shift, and this frequency shift is measured,
producing a measure of rotational rate. These devices have fewer moving
parts and are more reliable at less cost than the spinning-rotor variety of
gyroscopes.
STEP 3. Select actuators. Two aerodynamic surfaces typically inﬂuence
the lateral aircraft motion: the rudder and the ailerons (see Fig. 10.30).
The lightly damped yaw mode that will be stabilized by the yaw damper
is most affected by the rudder. Therefore, use of that single control input
is a logical starting point for the design. Hence, it is best to choose the
rudder as our actuator. Hydraulic devices are universally employed in large
aircraft to provide the force that moves the aerodynamic surfaces. No other
kind of device has been developed to provide the combination of high force,
high speed, and light weight desirable for the actuation of the controlling
aerodynamic surfaces. On the other hand, the low-speed ﬂaps, which are
extended slowly prior to landing, are typically actuated by an electric motor
with a worm gear. For small aircraft with no autopilot, no actuator is required
at all; the pilot yoke is directly connected to the aerodynamic surface by
means of wire cables, and all the force required to move the surfaces is
provided by the pilot.
STEP 4. Make a linear model. The lateral-perturbation equations of motion
for a Boeing 747 in horizontal ﬂight at 40,000 ft and nominal forward speed
U0 = 774 ft/sec (Mach 0.8) (Hefﬂey and Jewell, 1972), with the rudder
chosen as the actuator (Step 3), are
6The mode is sufﬁciently difﬁcult to control manually that, if the yaw damper fails in cruise,
the pilot is instructed to descend and slow down where the mode is more manageable.

10.3 Lateral and Longitudinal Control of a Boeing 747
735
⎡
⎢⎢⎣
˙β
˙r
˙p
˙φ
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
−0.0558
−0.9968
0.0802
0.0415
0.598
−0.115
−0.0318
0
−3.05
0.388
−0.4650
0
0
0.0805
1
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
β
r
p
φ
⎤
⎥⎥⎦
+
⎡
⎢⎢⎣
0.00729
−0.475
0.153
0
⎤
⎥⎥⎦δr,
y = [ 0
1
0
0 ]
⎡
⎢⎢⎣
β
r
p
φ
⎤
⎥⎥⎦,
where β and φ are in radians and r and p are in radians per second. The
transfer function, using the Matlab ss2tf function, is
G(s) = r(s)
δr(s) =
−0.475(s + 0.498)(s + 0.012 ± 0.488j)
(s + 0.0073)(s + 0.563)(s + 0.033 ± 0.947j),
(10.26)
so that the system has two stable real poles and a pair of stable complex
poles. Notice ﬁrst that the low-frequency gain is negative, corresponding to
the simple physical fact that a positive or clockwise rudder motion causes a
negative or counterclockwise yaw rate. In other words, turning the rudder left
(clockwise) causes the front of the aircraft to rotate left (counterclockwise).
The natural motion corresponding to the complex poles is referred to as the
Dutch roll; the name comes from the motions of a person skating on the
Dutch roll
frozen canals of the Netherlands. The motion corresponding to the stable real
Spiral mode
poles is referred to as the spiral mode (s1 = −0.0073) and the roll mode
Roll mode
(s2 = −0.563). From looking at the system poles, we see that the offending
mode that needs repair for good pilot handling is the Dutch roll, with the
poles at s = −0.033 ± 0.95j. The roots have an acceptable frequency, but
their damping ratio ζ ∼= 0.03 is far short of the desired value ζ ∼= 0.5.
STEP 5. Try a lead-lag or PID design. As a ﬁrst try at the design, we will
consider proportional feedback of the yaw rate to the rudder. The root locus
with respect to the gain of this feedback is shown in Fig. 10.32, and its
frequency response is shown in Fig. 10.33. The ﬁgures show that ζ ∼= 0.45
is achievable and can be computed to occur at a gain of about 3.0.
This feedback, however, creates an objectionable situation during a
steady turn when the yaw rate is constant: Because the feedback produces a
steady rudder input opposite the yaw rate, the pilot must introduce a much
larger steady command for the same yaw rate than is necessary in the open-
loop case. This dilemma is solved by attenuating the feedback at DC (that
Washout
is, "washing out" the feedback). This is accomplished by inserting
H(s) =
s
s + 1/τ ,

736
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.32
Root locus for yaw
damper with
proportional feedback
Re(s)
Im(s)
-1.0
-2.0
1.0
2.0
2.0
-2.0
Figure 10.33
Bode plot of yaw
damper with
proportional feedback
Magnitude, ƒGƒ
10
0.01
1
0.1
v (rad/sec)
db
(a)
-40
0
20
0.1
1
10
-20
1005
Phase
-1805
10
1
0.1
v (rad/sec)
(b)
-1505
-1005
-505
05
505
in the feedback, which passes the yaw rate feedback at frequencies above
1/τ and provides no feedback at DC. Therefore, in a steady turn, the damper
will provide no correction. Figure 10.34 shows a block diagram of the yaw
damper with the washout.

10.3 Lateral and Longitudinal Control of a Boeing 747
737
Figure 10.34
Yaw damper:
(a) functional block
diagram; (b) block
diagram for analysis
©
Pilot's aileron input to cause roll
Rudder
servo
Pilot's rudder
input to cause
yaw rc
edr
eyrg
dr
Kyrg
+
+
Washout
circuit
Yaw rate
gyro
da
Aircraft
e
r
©
edr
eyrg
dr
+
+
e
rc
r
s + 10
10
s + 1/t
s
Aircraft
(a)
(b)
Figure 10.35
Root locus with washout
circuit, τ = 3
Re(s)
Im(s)
-0.5
1.0
1.0
-1.0
-8.47
-10
-5
For a more complete model, we include the rudder servo, which
represents the actuator dynamics and has the transfer function
A(s) = δr(s)
eδr(s) =
10
s + 10,
which is fast compared with the dynamics of the rest of the system and is
not expected to change the response very much. The root locus, including
actuator dynamics and a washout circuit with τ = 3, is shown in Fig. 10.35.
As seen from the root locus, the addition of the yaw rate feedback, including
the washout, allows the damping ratio to be increased from 0.03 to about
0.35. The associated frequency response of the system is shown in Fig. 10.36.
The response of the closed-loop system to an initial condition of β0 = 1◦is
shown in Fig. 10.37 for a root-locus gain of 2.6. For reference, the response
of yaw rate with no feedback is also given. Although feedback of yaw rate
through the washout circuit results in a considerable improvement over the

738
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.36
Bode plot of yaw
damper, including
washout and actuator
v (rad/sec)
Magnitude, ƒGHAƒ
1505
20
db
0
-20
-40
Phase
1005
505
05
-505
-1005
-1505
-2005
10
1
0.1
0.01
0.1
1
10
(a)
(b)
v (rad/sec)
0.1
a
10
Figure 10.37
Initial condition
response with yaw
damper and washout,
and SRL design, for
β(0) = 1◦
Yaw rate feedback
b (deg)
0
30
25
20
15
10
5
Time (sec)
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
No feedback
SRL
original aircraft control, the response is not as good as originally speciﬁed.
Further iterations, not included here, could include other gain values or more
complex compensations.
STEP 6. Evaluate/modify plant. The solution would be to unsweep the
wings, which would cause a large drag penalty.

10.3 Lateral and Longitudinal Control of a Boeing 747
739
STEP 7. Try an optimal design using pole placement. If we augment the
dynamic model of the system by adding the actuator and washout, we obtain
the state-variable model
⎡
⎢⎢⎢⎢⎢⎢⎣
˙xA
˙β
˙r
˙p
˙φ
˙xwo
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−10
0
0
0
0
0
0.0729
−0.0558
−0.997
0.0802
0.0415
0
−4.75
0.598
−0.1150
−0.0318
0
0
1.53
−3.05
0.388
−0.465
0
0
0
0
0.0805
1
0
0
0
0
1
0
0
−0.333
⎤
⎥⎥⎥⎥⎥⎥⎦
×
⎡
⎢⎢⎢⎢⎢⎢⎣
xA
β
r
p
φ
˙xwo
⎤
⎥⎥⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎢⎢⎣
10
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
eδr,
e = [ 0
0
1
0
0
−0.333 ]
⎡
⎢⎢⎢⎢⎢⎢⎣
xA
β
r
p
φ
xwo
⎤
⎥⎥⎥⎥⎥⎥⎦
,
where eδr is the input to the actuator and e is the output of the washout. The
SRL for the augmented system is as shown in Fig. 10.38. If we select the
state-feedback poles from the SRL so that the complex roots have maximum
damping (ζ = 0.4), we ﬁnd that
pc = [−0.0051; −0.468; 0.279 + 0.628 ∗j; 0.279 −0.628 ∗j;
−1.106; −9.89].
Then we can compute the state-feedback gain, using the Matlab function
place, to be
K = [ 1.059
−0.191
−2.32
0.0992
0.0370
0.486 ].
Note that the third entry in K is larger than the others, so the feedback of
all six state variables is essentially the same as proportional feedback of r.
This is also evident from the similarity of the root locus in Fig. 10.31 and
the SRL of Fig. 10.38. If we select the estimator poles to be ﬁve times faster
than the controller poles, then
pe = [−0.0253; −2.34; −1.39 + 3.14 ∗j; −1.39 −3.14 ∗j; −5.53; −49.5]
and the estimator gain, again using the Matlab function place, is found to be
L =
⎡
⎢⎢⎢⎢⎢⎢⎣
25.0
−2,044
−5,158
−24,843
−40,113
−15,624
⎤
⎥⎥⎥⎥⎥⎥⎦
.

740
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.38
SRL of lateral dynamics,
including washout ﬁlter
and actuator
Re(s)
Im(s)
1
10
2
-1
-10
245
z = 0.4
Poles for maximum damping
The compensator transfer function from Eq. (7.177) is
Dc(s) =
−844(s + 10.0)(s −1.04)(s + 0.974 ± 0.559j)(s + 0.0230)
(s + 0.0272)(s + 0.837 ± 0.671j)(s + 4.07 ± 10.1j)(s + 51.3).
(10.27)
Figure 10.37 also shows the response of the yaw rate to an initial condition of
β0 = 1◦. It is clear from the root locus that the damping can be improved by
the SRL approach, and this is borne out by the reduced oscillatory behavior
in the transient response of the system. However, this improvement has come
at a considerable price. Note that the order of the compensator has increased
from one in the original design (Fig. 10.33) to six and washout in the design
obtained using the controller-estimator-SRL approach.
Aircraft yaw dampers in use today generally employ a proportional
Design trade-off: system
response vs. system
complexity
feedback of yaw rate to rudder through a washout or through minor modiﬁ-
cations to this design. The improved performance achievable with an optimal
design approach utilizing full-state feedback and estimation is not judged to
be worth the increase in complexity.
Perhaps, a more fruitful approach to improving the design would be to
add the aileron surface as a control variable along with the rudder.
STEPS 8 and 9. Verify the design. Linear models of aircraft motion are
reasonably accurate as long as the motion is small enough that the actua-
tors and surfaces do not saturate. Because actuators are sized for safety in
order to handle large transients, such saturation is very rare. Therefore, the
linear-analysis-based design is reasonably accurate, and we will not pur-
sue a nonlinear simulation or further design veriﬁcation. However, aircraft

10.3 Lateral and Longitudinal Control of a Boeing 747
741
manufacturers do carry out extensive nonlinear simulations and ﬂight test-
ing under all possible ﬂight conditions before obtaining Federal Aviation
Administration (FAA) certiﬁcation to carry passengers.
10.3.2
Altitude-Hold Autopilot
STEP 1. Understand the process and its performance speciﬁcations. One
of the pilot's many tasks is to hold a speciﬁc altitude. As an aid to keeping
aircraft from colliding, those craft on an easterly path are required to be on
an odd multiple of 1000 ft and those on a westerly path on an even multiple
of 1000 ft. Therefore, the pilot needs to be able to hold the altitude to less
than a hundred feet. A well-trained, attentive pilot can easily accomplish this
task manually to within ±50 ft, and air-trafﬁc controllers expect pilots to
maintain this kind of tolerance. However, since this task requires the pilot to
be fairly diligent, sophisticated aircraft often have an altitude-hold autopilot
to lessen the pilot's work. This system differs fundamentally from the yaw
damper because its role is to replace the pilot for a certain period, while the
yaw damper's role is to help the pilot ﬂy. Dynamic speciﬁcations, therefore,
need not require that pilots like the craft's "feel" (how it responds to their
handling of the controls); instead, the design should provide the kind of
ride that pilots and passengers like. The damping ratio should still be in the
vicinity of ζ ∼= 0.5, but for a smooth ride the natural frequency should be
much slower than ωn = 1 rad/sec.
STEP 2. Select sensors. Clearly needed is a device to measure altitude, a
task most easily done by measuring the atmospheric pressure. Almost from
the time of the ﬁrst Wright brothers' ﬂight, this basic idea has been used
in a device called a barometric altimeter. Before autopilots, the device
consisted of a bellows whose free end was connected to a needle that directly
indicated altitude on a dial. The same bellows concept is used today for the
altitude display, but the pressure is sensed electrically for the autopilot.
Because the transfer function from the controlling elevator input to the
altitude control consists of ﬁve poles [see Eq. (10.30)], stabilization of the
feedback loop cannot be accomplished by simple proportional feedback.
Therefore the pitch rate q is also used as a stabilizing feedback; it is measured
by a gyroscope or ring-laser gyro identical to that used for yaw-rate mea-
surement. Further stabilization using pitch-angle feedback is also helpful.
It is obtained either from an inertial reference system based on a ring-laser
gyro or from a rate-integrating gyro. The latter is a device similar to the
rate gyro, but structured differently so that its outputs are proportional to the
angles of the aircraft's pitch θ and roll φ.
STEP 3. Select actuators. The only aerodynamic surface typically used
for pitch control on most aircraft is the elevator δe. It is located on the
horizontal tail, well removed from the aircraft's center of gravity, so that
its force produces an angular pitch rate and thus a pitch angle, which acts
to change the lift from the wing. In some high-performance aircraft there
are direct-lift control devices on the wing or perhaps small canard surfaces,
which are like tiny wings forward of the main wing, which produce vertical

742
Chapter 10 Control System Design: Principles and Case Studies
forces on the aircraft that are much faster than elevators on the tail are able
to generate. However, for purposes of our altitude hold, we will consider
only the typical case of an elevator surface on the tail.
As for the rudder, hydraulic actuators are the preferred devices to move
the elevator surface, mainly because of their favorable force-to-weight ratio.
STEP 4. Make a linear model. The longitudinal perturbation equations
of motion for the Boeing 747 in horizontal ﬂight at a nominal speed
U0 = 830 ft/sec at 20,000 ft (Mach 0.8) with a weight of 637,000 lb are
˙x = Ax + Bδe,
(10.28)
⎡
⎢⎢⎢⎢⎣
˙u
˙w
˙q
˙θ
˙h
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎣
−0.00643
0.0263
0
−32.2
0
−0.0941
−0.624
820
0
0
−0.000222
−0.00153
−0.668
0
0
0
0
1
0
0
0
−1
0
830
0
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
u
w
q
θ
h
⎤
⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎣
0
−32.7
−2.08
0
0
⎤
⎥⎥⎥⎥⎦
δe,
where the desired output for an altitude-hold autopilot is
h = Cx,
h = [ 0
0
0
0
1 ]
⎡
⎢⎢⎢⎢⎣
u
w
q
θ
h
⎤
⎥⎥⎥⎥⎦
,
(10.29)
and
h(s)
δe(s) =
32.7(s + 0.0045)(s + 5.645)(s −5.61)
s(s + 0.003 ± 0.0098j)(s + 0.6463 ± 1.1211j).
(10.30)
The system has two pairs of stable complex poles and a pole at s = 0. The
complex pair at −0.003±0.0098j are referred to as the phugoid mode,7 and
Phugoid mode
the poles at −0.6463 ± 1.1211 are the short-period modes, as computed
Short-period modes
using the Matlab eig command.
STEP 5. Try a lead-lag or PID controller. As a ﬁrst step in the design, it is
typically helpful to use an inner-loop feedback of pitch rate q to δe so as to
Inner-loop design
7The name was adopted by F. W. Lanchester (1908), who was the ﬁrst to study the dynamic
stability of aircraft analytically. It is apparently an incorrect version of a Greek word.

10.3 Lateral and Longitudinal Control of a Boeing 747
743
improve the damping of the short-period mode of the aircraft (see Fig. 10.39).
The transfer function from δe to q, using the Matlab ss2tf function, is
q(s)
δe(s) = −
2.08s(s + 0.0105)(s + 0.596)
(s + 0.003 ± 0.0098j)(s + 0.646 ± 1.21j).
(10.31)
The inner loop root locus for q feedback using Eq. (10.31) is as shown
in Fig. 10.40. Because kq is the root-locus parameter, the system matrix
[Eq. (10.28)] is now modiﬁed to
Aq = A + kqBCq,
(10.32)
where A and B are deﬁned in Eq. (10.28) and Cq = [ 0
0
1
0
0 ].
The process of picking a suitable gain kq is an iterative one. The selection
procedure is the same one discussed in Chapter 5. (Recall the tachometer
feedback example in Section 5.6.2.) If we choose kq = 1, then the closed-
loop poles will be located at −0.0039 ± 0.0067j, −1.683 ± 0.277j on the
root locus, and
Aq =
⎡
⎢⎢⎢⎢⎣
−0.00643
0.0263
0
−32.2
0
−0.0941
−0.624
787.3
0
0
−0.000222
−0.00153
−2.75
0
0
0
0
1
0
0
0
−1
0
830
0
⎤
⎥⎥⎥⎥⎦
.
(10.33)
Figure 10.39
Altitude-hold feedback
system
©
+
-
href
h
Compensation
Aircraft
de
Dc(s)
©
+
+
+
ku
kq
q
u
Inner loop
Figure 10.40
Inner-loop root locus
for altitude-hold
dynamics with q
feedback
Re(s)
Im(s)
-1
-2
1
-1
Poles for kq = 1

744
Chapter 10 Control System Design: Principles and Case Studies
Note that only the third column of Aq is different from A. To further improve
the damping, it is useful to feed back the pitch angle of the aircraft. By trial
and error, we select
Kθq = [ 0
0
−0.8
−6
0 ],
in order to feed back θ and q, and the system matrix becomes
Aθq = Aq −BKθq,
=
⎡
⎢⎢⎢⎢⎣
−0.0064
0.0263
0
−32.2
0
−0.0941
−0.624
761
−196.2
0
−0.0002
−0.0015
−4.41
−12.48
0
0
0
1
0
0
0
−1
0
830
0
⎤
⎥⎥⎥⎥⎦
,
with poles at s = 0, −2.25 ± 2.99j, −0.531, −0.0105.
So far, the inner loop of the aircraft has been stabilized signiﬁcantly.
The uncontrolled aircraft has a natural tendency to return to equilibrium in
level ﬂight, as evidenced by the open-loop roots in the LHP. The inner-loop
stabilization is necessary to enable an outer-loop feedback of h and ˙h to be
successful; furthermore, the feedbacks of θ and q can be used by themselves
in an attitude-hold mode of the autopilot, when a pilot wishes to control
θ directly through input command. Figure 10.41 shows the response of the
inner loop to a 2◦(0.035-rad) step command in θ. With the inner loop in place
the transfer function of the system from elevator angle to altitude is now
h(s)
δe(s) =
32.7(s + 0.0045)(s + 5.645)(s −5.61)
s(s + 2.25 ± 2.99j)(s + 0.0105)(s + 0.0531).
(10.34)
Figure 10.41
Response of
altitude-hold autopilot
to a command in θ
0.040
0.035
0.030
0.025
0.020
0.015
0.010
0.005
0.000
u(t) (rad)
0
1
2
3
4
5
6
7
8
9
10

10.3 Lateral and Longitudinal Control of a Boeing 747
745
The root locus for this system, given in Fig. 10.42, shows that proportional
feedback of altitude by itself does not yield an acceptable design. For sta-
bilization we may also feed back the rate of change in the altitude in a PD
controller. The root locus of the system with feedback of both h and ˙h is
shown in Fig. 10.43. After some iteration we ﬁnd that the best ratio of ˙h to
h is 10:1, that is,
Dce(s) = Kh(s + 0.1).
The ﬁnal design is the result of iterations between the q, θ, ˙h, and h
feedback gains, obviously a lengthy process. Although this trial design was
successful, use of the SRL approach promises to expedite the process.
STEP 6. Evaluate/modify plant. Not applicable here.
Figure 10.42
0◦root locus with
feedback of h only
Re(s)
Im(s)
- 2
5.6
4
2
-4
-2
- 6
- 4
- 8
Figure 10.43
SRL for altitude-hold
design
8
4
-2
-4
Re(s)
Im(s)
2
6
-6
-8
1
2
3
4
5
-3 -2 -1
-4
-5

746
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.44
Step response of
altitude-hold autopilot
to a 100-ft step
command
Altitude, h (ft)
100
0
2
4
6
8 10 12 14 16 18 20 22 24 26 28 30
Time (sec)
80
60
40
20
0
Figure 10.45
Control effort for 100-ft
step command in
altitude
05
0
2
4
6
8 10 12 14 16 18 20 22 24 26 28 30
Time (sec)
-15
-25
-35
-45
-55
-65
de
STEP 7. Do an optimal design. The SRL of the system is shown in
Fig. 10.43. If we choose the closed-loop poles at
pc = [−0.0045; −0.145; −0.513; −2.25 −2.98 ∗j; −2.25 + 2.98 ∗j],
then the required feedback gain, using the Matlab function place, is
K = [ −0.0009
0.0016
−1.883
−7.603
−0.001 ].
The step response of the system to a 100-ft step command in h is shown in
Fig. 10.44, and the associated control effort is shown in Fig. 10.45.
This design has been carried out with the assumption that the linear
model is valid for the altitude changes under consideration. We should per-
form simulations to verify this or to determine the range of validity of the
linear model.

10.4 Control of the Fuel-Air Ratio in an Automotive Engine
747
STEPS 8 and 9. Verify the design. The comments in Steps 7 and 8 of
Section 10.3.1 apply to this design as well.
For small airplane autopilots now in production, such as the one
described in Chapter 5, it is interesting to note that, for the inner loop,
some manufacturers employ only θ feedback while others use q feedback.
The use of θ enables faster response, but use of q is less costly. Both, of
course, use the altimeter for h feedback.
10.4
Control of the Fuel-Air Ratio
in an Automotive Engine
Until the 1980s most automobile engines had a carburetor to meter the fuel
so that the ratio of the gasoline-mass ﬂow to air-mass ﬂow, or fuel-to-air
ratio (F/A), remained in the vicinity of 1:15. This device metered the fuel
by relying on a pressure drop produced by the air ﬂowing through a venturi.
The device performed adequately in terms of keeping the engine running
satisfactorily, but it historically allowed excursions of up to 20% in the F/A.
After the implementation of federal exhaust-pollution regulations, this level
of inaccuracy in the F/A was unacceptable because neither excess hydrocar-
bons (HCs) nor excess carbon monoxide (CO) could be accepted. During
the 1970s, automobile companies improved the design and manufacturing
process of the carburetors so that they became more accurate and delivered
a F/A accuracy in the vicinity of 3% to 5%. Through a combination of fac-
tors, this improved F/A accuracy helped lower the exhaust pollution levels.
However, the carburetors were still open-loop devices because the system
did not measure the F/A of the mixture entering the engine for subsequent
feedback into the carburetor. During the 1980s almost all manufacturers
turned to feedback control systems to provide a much-improved level of F/A
accuracy, an action made necessary by the decreasing levels of allowable
exhaust pollutants. In essence, the same scheme is used currently (2014) so
that the catalytic converters attached to the exhaust system can remove the
pollutants from the exhaust and meet the federal standards.
We now turn to the design of a typical feedback system for engine
control, again using the step-by-step design outline given in Section 10.1.
STEP 1. Understand the process and its performance. The method chosen
to meet the exhaust-pollution standards has been to use a catalytic converter
that simultaneously oxidizes excess levels of exhaust carbon monoxide (CO)
and unburned HCs and reduces excess levels of the oxides of nitrogen (NO
and NO2, or NOx). This device is usually referred to as a three-way catalyst
because of its effect on all three pollutants. This catalyst is ineffective when
the F/A is much different from the stoichiometric level of 1:14.7; therefore,
a feedback control system is required to maintain the F/A within ±1% of
that desired level. The system is depicted in Fig. 10.46.
The dynamic phenomena that affect the relationship between the sensed
F/A output from the exhaust and the fuel-metering command in the intake
manifold are (1) intake fuel and air mixing, (2) cycle delays due to the piston

748
Chapter 10 Control System Design: Principles and Case Studies
Engine
Catalytic
converter
Sensor
Air
Intake
manifold
Exhaust
Fuel
Actuator
Figure 10.46
F/A feedback control system
Figure 10.47
Exhaust sensor output
Fuel-air ratio, F/A
1:18
1:14.7
1:12
0.9
0.5
0.1
Sensor output, V
strokes in the engine, and (3) the time required for the exhaust to travel from
the engine to the sensor.All these effects are strongly dependent on the speed
and load of the engine. For example, engine speeds typically vary from 600 to
6000 rpm. The result of these variations is that the time delays in the system
that will affect the feedback control-system behavior will also vary by at least
10:1, depending on the operating condition. The system undergoes transients
as the driver demands more or less power through changes in the accelerator
pedal, with the changes taking place over fractions of a second. Ideally, the
feedback control system should be able to keep up with these transients.
STEP 2. Select sensors. The discovery and development of the exhaust
sensor was the key technological step that made possible this concept of
exhaust-emission reduction by feedback control. The active element in the
device, zirconium oxide, is placed in the exhaust stream, where it yields a
voltage that is a monotonic function of the oxygen content of the exhaust gas.
The F/A is uniquely related to the oxygen level. The voltage of the sensor
is highly nonlinear with respect to F/A (Fig. 10.47); almost all the change
in voltage occurs precisely at the F/A value at which the feedback system
must operate for effective performance of the catalyst. Therefore, the gain
of the sensor will be very high when the F/A is at the desired point (1:14.7)
Nonlinear sensor
but will fall off considerably for F/A excursions away from 1:14.7.
Although other sensors have been under development for possible use in
F/A feedback control, no other cost-effective sensor has so far demonstrated

10.4 Control of the Fuel-Air Ratio in an Automotive Engine
749
the capability to perform adequately. All manufacturers of production-
line automobiles currently use zirconium oxide sensors in their feedback
control systems.
STEP 3. Select actuators. Fuel metering can be accomplished by a carbu-
retor or by fuel injection. Implementing a feedback F/A system requires
the capability of adjusting the fuel metering electrically, because the sensor
used provides an electric output. Initially, carburetors were designed to pro-
vide this capability by including adjustable oriﬁces that modify the primary
fuel ﬂow in response to the electric error signal. However, today manufac-
turers accomplish the metering using fuel injection. Fuel-injection systems
are typically electrical by nature, so they can be used to perform the fuel
adjustment for F/A feedback simply by including the capability of using the
feedback signal from the sensor. Today, fuel injectors are placed at the inlet
to every cylinder (called multipoint injection); in the past, there was one
large injector upstream from all the cylinders (called single-point or throttle
body injection). Multipoint injection offers improved performance because
the fuel is introduced much closer to the engine, with better distribution to
the cylinders. Being closer reduces the time delays and thus yields better
engine response and enables lower exhaust pollution.
STEP 4. Make a linear model. The sensor nonlinearity shown in Fig. 10.47
is severe enough that any design effort based on a linearized model of it
should be used with caution. Figure 10.48 shows a block diagram of the
system, with the sensor shown to have a gain Ks. The time constants τ1
and τ2 indicated for the inlet manifold dynamics represent, respectively, fast
fuel ﬂow in the form of vapor or droplets and slow fuel ﬂow in the form of a
liquid ﬁlm on the manifold walls. The time delay is the sum of (1) the time
it takes the pistons to move through the four strokes from the intake process
until the exhaust process and (2) the time required for the exhaust to travel
Desired
F/A
Exhaust F/A
s
KI
Kp +
t1s + 1
1
uf
t2s + 1
1
0.5
Fast fuel
Slow fuel
0.5
©
+
+
Inlet manifold
Time delay
Sensor lag
ts + 1
1
Sensor
y
Ks
F/A
©
+
-
e
Control law
e-sTd
Figure 10.48
Block diagram of an F/A control system

750
Chapter 10 Control System Design: Principles and Case Studies
from the engine to the sensor located roughly 1 ft away. A sensor lag with
time constant τ is also included in the process to account for the mixing that
occurs in the exhaust manifold. Although the time constants and the delay
time change considerably, primarily as a function of engine load and speed,
we will examine the design at a speciﬁc point where the values are
τ1 = 0.02 sec,
Td = 0.2 sec,
τ2 = 1 sec,
τ = 0.1 sec .
In an actual engine, designs would be carried out for all speed loads.
STEP 5. Try a lead-lag or PID controller. Given the tight error speciﬁca-
tions and the wide variations in the required fuel command uf due to varying
engine-operating conditions, an integral control term is mandatory. With
integral control, any required steady state uf can be provided when the error
signal e = 0. The addition of a proportional term, although not often used,
allows for an increase (doubling) in the bandwidth without degrading steady-
state characteristics. In this example we use a control law that is proportional
plus integral (PI). The output from the control law is a voltage that drives the
injector's pulse former to give a fuel pulse whose duration is proportional to
the voltage. The controller transfer function can be written as
Dc(s) = Kp + KI
s = Kp
s (s + z),
(10.35)
where
z = KI
Kp
,
and z can be chosen as desired.
First, let us assume that the sensor is linear and can be represented by
a gain Ks. Then we can choose z for good stability and good response of
the system. Figure 10.49 shows the frequency response of the system for
KsKp = 1.0 and z = 0.3, while Fig. 10.50 shows a root locus of the system
with respect to KsKp with z = 0.3. Both analyses show that the system
becomes unstable for KsKp ∼= 2.8. Figure 10.49 shows that to achieve a phase
margin of approximately 60◦, the gain KsKp should be ∼2.2. Figure 10.49
also shows that this produces a crossover frequency of 6.0 rad/sec (∼1 Hz).
The root locus in Fig. 10.50 veriﬁes that this candidate design will achieve
acceptable damping (ζ ∼= 0.5).
Although this linear analysis shows that acceptable stability at a rea-
sonable bandwidth (∼1 Hz) can be achieved with a PI controller, a look at
the nonlinear sensor characteristics (Fig. 10.47) shows that this indeed may
Complications of
nonlinearity
not be achievable. Note that the slope of the sensor output is extremely high
near the desired setpoint, thus producing a very high value of Ks. There-
fore, lower values of the controller gain Kp need to be used to maintain the
overall KsKp value of 2.2 when including the effect of the high sensor gain.
On the other hand, a value of Kp low enough to yield a stable system at
F/A = 1 : 14.7 (= 0.068) will yield a very sluggish response to transient

10.4 Control of the Fuel-Air Ratio in an Automotive Engine
751
Figure 10.49
Bode plot of a PI F/A
controller
v (rad/sec)
Magnitude, ƒDcGƒ
0.4
db
Phase
-305
10
1
0.1
0.01
0.1
1
10
100
2
4
20
40
20
0
-20
-40
(a)
v (rad/sec)
0.4
0.1
1
10
100
2
4
20
40
(b)
-605
-905
-1205
-1505
-1805
-2105
2.2
2.8
vc for
PM = 605
Figure 10.50
Root locus of a PI F/A
controller
-5
5
-5
Re(s)
-15
-10
-20
-50
KsKp = 2.2
KsKp = 2.8
1 = 0.5
KsKp = 2.2
KsKp = 2.8
Im(s)

752
Chapter 10 Control System Design: Principles and Case Studies
errors that deviate much from the setpoint, because the effective sensor gain
will be reduced substantially. It is therefore necessary to account for the
sensor nonlinearity in order to obtain satisfactory response characteristics of
the system for anything other than minute disturbances about the setpoint. A
ﬁrst approximation to the sensor is shown in Fig. 10.51. Because the actual
sensor gain at the setpoint is still quite different from its approximation, this
approximation will yield erroneous conclusions regarding stability about the
setpoint; however, it will be useful in a simulation to determine the response
to initial conditions.
STEP 6. Evaluate/modify plant. The nonlinear sensor is undesirable;
however, no suitable linear sensor has been found.
STEP 7. Try an optimal controller. The response of this system is dominated
by the sensor nonlinearity, and any ﬁne tuning of the control needs to account
for that feature. Furthermore, the system dynamics are relatively simple, and
it is unlikely that an optimal design approach will yield any improvement
over the PI controller used. We will thus omit this step.
STEP 8. Simulate design with nonlinearities. The nonlinear closed-loop
simulation of the system implemented in Simulink is shown in Fig. 10.52.
The Matlab function (fas) implements the approximate nonlinear sensor
characteristics of Fig. 10.52,
function y = fas(u)
if u < 0.0606,
y = 0.1 ;
elseif u < 0.0741,
y = 0.1 + (u −0.0606) *20;
else y = 0.9;
end
Figure 10.53(a) is a plot of the system error using the approximate sensor
of Fig. 10.51 and KpKs = 2.0. The slow response is apparent with 12.5 sec
before the error comes out of saturation and a time constant of almost 5 sec
once the linear region is reached. In real automobiles these systems are
operated with much higher gains. To show these effects, a simulation with
Figure 10.51
Sensor approximation
Fuel-air ratio, F/A
1:18
1:14.7
1:12
0.9
0.5
0.1
Sensor output, V
Setpoint
Approximation
Actual sensor

10.4 Control of the Fuel-Air Ratio in an Automotive Engine
753
e
Desired
F/A
Exhaust
F/A
-
+
Step
+
+
Time
delay
Scope1
Scope
s
0.1s + 0.03
Control law
0.5
Gain
0.5
Gain1
0.02s + 1
1
Fast fuel
s + 1
1
Slow fuel
0.1s + 1
1
Sensor lag
Sensor nonlinearity
Matlab
Function
Figure 10.52
Closed-loop nonlinear simulation implemented in Simulink
KpKs = 6.0 is plotted in Fig. 10.53(b, c). At this gain the linear system is
unstable and up until about 5 sec the signals grow. The growth halts after
5 sec due to the fact that, as the input to the sensor nonlinearity gets large, the
effective gain of the sensor decreases due to the saturation, and eventually,
a limit cycle is reached. The frequency of this limit cycle corresponds to
the point at which the root locus crosses the imaginary axis and has an
amplitude such that the total effective gain of KpKs,eq = 2.8. As described
in Section 9.3, the effective gain of a saturation for moderately large inputs
can be computed and is given by the describing function to be approximately
4N/πa, where N is the saturation level and a is the amplitude of the input
signal. Here N = 0.4, and if Kp = 0.1, then Ks,eq = 28. Thus we predict
an input signal amplitude of a = 4(0.4)/28π = 0.018. This value is closely
veriﬁed by the plot of Fig. 10.53(c), the input to the nonlinearity in this case.
The frequency of oscillation is also nearly 10.1 rad/sec, as predicted by the
root locus in Fig. 10.50.
Simulink nonlinear
simulation
In the actual implementation of F/A feedback controllers in automobile
engines, sensor degradation over thousands of miles of use is of primary
concern, because the federal government mandates that the engines meet
the exhaust-pollution standards for the ﬁrst 50,000 mi. In order to reduce
the sensitivity of the average setpoint to changes in the sensor output char-
acteristics, manufacturers typically modify the design discussed here. One
approach is to feed the sensor output into a relay function [see Fig. 9.6(b)],
thus completely eliminating any dependency on the sensor gain at the set-
point. The frequency of the limit cycle is then solely determined by controller
constants and engine characteristics. Average steady-state F/A accuracy is
also improved. The oscillations in the F/A are acceptable because they are not
noticeable to the car's occupants. In fact, the F/A excursions are beneﬁcial
to the catalyst operation in reducing pollutants.

754
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.53
System response with
nonlinear sensor
approximation
Time (sec)
5.0
10.0
15.0
20.0
0
0.4
0.2
0.8
0.4
0
-0.4
(a)
Time (sec)
5.0
10.0
15.0
20.0
0
(b)
0.09
0.06
0.03
Time (sec)
5.0
10.0
15.0
20.0
0
(c)
e
e
F/A
Feedback systems have also been used in many other areas of mod-
ern automobiles. A car's desired inside temperature is set by the passengers
and a feedback system maintains that temperature. Cruise control systems
have been augmented with radar so that the cruise control will maintain a
certain distance behind the car ahead by feedback of that distance to the
cruise control. Systems are being developed whereby trafﬁc lane marking
sensors are being fed back to the steering to maintain a car in the correct lane.
Stability augmentation systems use differential braking based on accelerom-
eter measurements to keep a car upright in violent maneuvers. The list goes
on and on, many of which are described in a book by Ulsoy, Peng, and
Cakmakci (2012). It is possible that platoons of cars on a freeway will be
tightly controlled with small distances between them in order to increase
the capacity of freeways in the future. Such a scheme will be a victory for
feedback control, but could put a tough test on our legal system if there are
serious accidents.

10.5 Control of the Read/Write Head Assembly of a Hard Disk
755
10.5
Control of the Read/Write Head Assembly
of a Hard Disk
The ﬁrst mass storage device based on recording data on hard disks was
introduced by IBM in 1956 as the model 350 RAMAC.8 It consisted of
a stack of ﬁfty 24-inch diameter aluminum disks that were coated with a
magnetic material, and the data were recorded in concentric tracks at 100
bytes per inch with 20 tracks per inch. The disks were rotated at 1200 rpm.
There was a single read/write head assembly mounted on an arm that could
be moved vertically from disk to disk and horizontally across the chosen disk
to reach a desired data track. The heads were held above the disk surface by
an air bearing generated by blowing air through holes in the ﬁxture holding
the heads. The assembly was held on a particular disk by a detent on the
elevator mechanism and held on a particular track by an arm detent. The
entire head assembly was driven by a single electric motor. The system held
5 MB of data, and consideration had to be given to be sure that the ﬁnal
device could be passed through a door 36 in. wide. The technical advances
in this ﬁeld have been such that in the year 2000 Seagate introduced a hard
drivemagneticmemoryconsistingofthreedisks, each2.5inchesindiameter,
rotating at 15,000 rpm designed to be included in a portable laptop computer.
This device could hold 18,350 megabytes of data. The read/write assembly
consisted of a single arm moving a comb of heads, one per surface, in a rotary
motion to move the heads from track to track. The heads are mountable on
a gimbal at the end of the arm and ﬂy above the surfaces of the disks. To
follow a track, the assembly is under active feedback control using samples
of position data recorded between the sectors of user data around each track.
An economic measure of the progress in the ﬁeld is that while the cost of the
RAMAC data was about $10,000 per megabyte, that of a modern drive is less
than 1 cent per megabyte. A brief summary of this remarkable history, with
many references is given inAbramovitch and Franklin (2002), and a table of
a few disk parameters over time is presented in Table 10.1. A large number
of people from both industrial and academic institutions have contributed
to the many technologies involved in the advances in hard-disk memory
devices made over the past 50 years, and one of the enabling technologies
has been feedback control. A picture of a Seagate 4-TB disk drive is shown
in Fig. 10.54. In this brief case study we will point out a number of issues
involving control, but the design example will be concerned only with the
issue of track following. We will follow the outline given in Section 10.1 in
presenting the case.
STEP 1. Understand the process. An exploded view of the track-following
servo problem is given in Fig. 10.55. The mechanism consists of a rotary
voice-coil motor moving an assembly of a light arm supporting gimbal-
mounted sliders that include the magnetoresistive read heads and the light,
thin-ﬁlm inductive write heads. The slider ﬂies above the disk surface on
8Random Access Method of Accounting and Control.

TABLE 10.1
Disk Drive Parameters Over Time
Size
Fly
Seek
No.
Year
Unit
Capacity
(N/d)
tpi
bpi
rpm
Height
Head Type
Sensor Type
Actuator Type
Time
Comment
1
1956
IBM RAMAC
5 MB
50/24"
20
100
1200
20 μ
Air bearing
Detent
dc motor
The ﬁrst hard disk
2
1962
IBM 1301
28 MB
25/24"
50
520
1800
Flying head
Detent
Hydraulic piston
165 ms
3
1971
IBM 3330
100 MB
11/14"
192
4040
1.2 μ
Ferrite,
Dedicated
Linear voice coil
30 ms
The ﬁrst
surface
ﬂying
feedback
4
1973
3340
70 MB
4/14"
270
5600
0.5 μ
Ferrite,
Dedicated
Linear voice coil
Low-mass
Winchester
ﬂying
surface
heads
5
1979
IBM 3370
571 MB
7/14"
635
12,134
2964
0.324 μ
Thin ﬁlm
Dedicated
Linear voice coil
surface
6
1979
IBM 3310
64.5 MB
6/8"
450
8530
Hybrid,
Rotary voice coil
27 ms
sector servo
7
1980
SeagateST506
5 MB
4/5.25"
255
7690
Open loop
Stepper motor
170 ms
5.25" disk for PCs
8
1983
MaxtorXT1140
126 MB
8/5.25"
Sector servo
Rotary voice coil
In-hub spindle
motor
9
1991
IBM Corsair
1 GB
8/3.5"
2238
58,874
MR head
Sector servo
Rotary voice coil
10
1993
Seagate 12550
2.19 GB
10/3.5"
7200
Sector servo
Rotary voice coil
11
1997
IBMTravelstar
4 GB
3/2.5"
12,500
211,000
Sector servo
Rotary voice coil
12
2000
Seagate
18.3 GB
5/2.5"
21.5k
343k
15,000
Thin-ﬁlm/
Sector servo
Rotary voice coil
3.9(r),
First 15,000
ST318451
GMR
4.5(w)
RPM disk drive
13
2003
Seagate
300 GB
4/3.3"
105k
658k
10,000
Thin-ﬁlm/
Sector servo
Micro-actuator
4.9(r),
First micro-
ST3300007
GMR
5.4(w)
actuators
14
2006
Seagate
300 GB
4/2.75"
125k
890k
15,000
Thin-ﬁlm/
Sector servo
Rotary voice coil
3.5(r),
First perpendicular
ST3300655
GMR
4.0(w)
recording drive
15
2014
Seagate
4000 GB
4/3.75"
150k
1090k
7,200
Thin-ﬁlm/
Sector servo
Rotary voice coil
7.4(r),
First SAS drive
Barracuda
TMR
8.5(w)
GMR = giant magnetoresitive head; TMR = tunneling magnetoresistive head.

10.5 Control of the Read/Write Head Assembly of a Hard Disk
757
Figure 10.54
4 TB disk drive
Source: Courtesy of Seagate
Technology, LLC
-
+
+
+
+
Position
sensing
noise
Windage
(air flow)
PES
ADC
noise
ADC
Head position
Motor torque
Arm mechanics
DSP
DAC
noise
DAC
Magnetic
media
Spindle
dynamics
Disk
position
©
©
Figure 10.55
Generalized view of track-following model
an air bearing produced by the disk rotation. The power ampliﬁer is usually
connected as a current ampliﬁer so that the basic motion can be modeled as
simple inertia, described by
Go(s) = A
Js2 ,
(10.36)
where J is the total inertia and A includes both the motor torque constant
and the ampliﬁer gain. The structure is ﬂexible, however, and the detailed
motion is very complex, with many lightly damped modes. It is also subject
to buffeting from the air ﬂow and from vibration caused by housing motion.

758
Chapter 10 Control System Design: Principles and Case Studies
For purposes of control design, a single resonant mode will be included
according to the model
G(s) = A
Js2

2ζ s
ω1 + 1


s2
ω1 + 2ζ s
ω1 + 1
,
(10.37)
where the vibration frequency, ω1, and the damping ratio, ζ, are known only
within bounds.
The motion control of the head assembly is in two modes: the seek
motion to move the head from track to track and the track-follow motion to
maintain the heads over the center of the selected track. In the seek mode
the criterion is minimum time, and theory would call for "on-off"or "bang-
bang"9 control. In order to use the same controller for many units, which
differ in the maximum torque available and other critical parameters, the
method used in disk drives is a bang-curve-follow technique in which the
assembly is accelerated under full torque until the velocity reaches a torque
reversal curve based on the distance to the desired track and deceleration is
under feedback control to follow this curve to reach the desired track with
zero velocity. The curve approximates the optimal minimum time switching
curve with torque discounted to the extent that the weakest motor will have
a reserve of torque adequate to follow the curve. When the selected track is
reached, the control transfers to track-following mode. A scheme to avoid
mode switching when the selected track is approached and to cause the servo
to move seamlessly into track-follow mode has been called the Proximate
Time Optimal Servo or PTOS (see Chapter 9).10
As a mature technology, many trends have inﬂuenced the nature of the
control problem over the years. For example, as the table shows, disks have
become smaller and thus stiffer and smoother. As the arm assembly has
become smaller, it has less inertia to the extent that for very small motions
as in a one- or two-track transfer, friction is more important than inertia. For
recent drives, the width of a track is on the order of 0.2 micron (μ), a value
comparable to the feature dimensions on a modern integrated circuit chip! To
counter this trend, research is exploring ways to add a second actuator, either
on the arm or on the gimbal, to make small moves much as the wrist acts on
the end of a robot arm. Because of the difﬁculty of controlling a very lightly
damped ﬂexibility, consideration is also given to adding a coating to the arm
to increase the damping of the principal modes of vibration. Other proposals
include adding sensors on the arm to allow extra feedback to control the
ﬂexibility. In this case study, we will assume a single voice-coil actuator and
that the ﬂexibility is described as in Eq. (10.37), where ω1 ≥2π ×2.500 and
ζ ≥0.05. Because the details of the actual resonance are not well known,
the resonance will need to be gain stabilized.
9Common names for the case in which the control is saturated with one polarity for half the
time, then reversed for the remaining half.
10Workman (1987), Franklin et al. (1998).

10.5 Control of the Read/Write Head Assembly of a Hard Disk
759
STEP 2. Select sensors. The earliest drives were controlled open loop with
one mechanical detent to hold the assembly on a disk and another detent to
hold the heads on a track. Feedback control was introduced in 1971 using
position information recorded on a special disk surface dedicated to the
servo data. The entire comb of heads was positioned by the servo surface
information. If the comb were to tilt or otherwise be misaligned, the data
would be that much more difﬁcult to read. Such issues limited the number of
disks and the track density possible with this arrangement. The track position
information in modern disks is recorded on each track in a gap between the
sectors of user data. Controls based on this information are called sector
servos, and the data are sampled of necessity. There is a conﬂict between
the desire to record large amounts of data, which calls for fewer and larger
sectors, and the control requirement to have a high sample rate, which calls
for smaller sectors. Each case is a compromise between these conﬂicting
demands. Because the position data are sampled, the controllers are digital
devices to make the best possible use of the position data. Theoretical study
has been given to using a multirate control to apply more than one control
correction for each sensor reading, but the method has not been found to be
costeffectiveyet. Forthecasestudyhere, wewilldesignananalogcontroller.
The position information extracted from data recorded on the disk is
subject to errors caused by run-out in the track path, which means that the
radius of the track is not constant. In general, there is a repeatable component
in each trip around the track, and this element can be estimated, often har-
monic by harmonic, and a signal used as feed-forward to the motor to cancel
it out. The position error signal (PES) also contains random noise from many
sources. These include the buffeting by the airﬂow over the slider, wobble
and vibration of the disks, noise in the signal-processing electronics used
to decode the position information, noise from the power ampliﬁer used
to provide torque to the motor, and errors caused by the analog-to-digital
converters needed in the process.
STEP 3. Select actuators. The RAMAC used a DC motor as actuator, and
later drives used hydraulic actuators. When the 5.25-in. drive was introduced
by Seagate in 1980, the actuator was an electric stepping motor. Each of these
were used in open loop. The ﬁrst feedback control of the head position was
on the IBM 3330 in 1971, and the actuator was a linear-motion voice-coil
motor. In 1979 a rotary voice-coil motor was introduced, and today almost all
hard disk drives use a rotary motion actuator. The power ampliﬁer is usually
connected as a current ampliﬁer to simplify the dynamics. The feedback
from the current-sensing resistor to the ampliﬁer constitutes a "torque loop"
that is designed separately and carefully, so that the dynamics of the motor
can be ignored most of the time in considering the outer loop position control
in track following.
STEP 4. Make a linear model.As mentioned in the discussion of the process,
the linear model has one ﬂexible mode, namely
G(s) = 1
s2
(2ζs/ω1 + 1)

s2
ω1 + 2ζ s
ω1 + 1
,
(10.38)

760
Chapter 10 Control System Design: Principles and Case Studies
where we take ζ = 0.05 and ω1 = 2.5, corresponding to measuring time
in milliseconds rather than seconds. The gain A and the inertia J will be
absorbed in the gain of the compensator. A resonance will always produce
a lightly damped second-order term in the denominator. Depending on the
nature of the structure and the location of the actuator and sensor, there may
or may not be one or two zeros for each resonant mode, as demonstrated by
Examples 2.2 and 2.4. The power ampliﬁer is assumed to be an ideal current
ampliﬁer. Also we are considering only track following, and not seek.
STEP 5. Try a PID or lead-lag design. Because the nominal model is so
simple, the ﬁrst design will be a lead compensation with the objective of
achieving the greatest possible bandwidth subject to having a phase margin
of 50◦and such that it will gain stabilize the resonance with a gain margin of
at least 4. This approach was already published by R. K. Oswald (1974). We
will try two designs and compare them for bandwidth and the quality of their
step responses. In the ﬁrst case, we will use a simple lead compensation,
selected to give 50◦phase margin and a factor of 4 gain margin. To get the
phase margin, the lead will be designed with an α of 0.1, and the crossover
frequency will be placed as high as possible while keeping a gain margin
of 4 at the resonance, which rises by a factor of 1/2ζ = 10 above the Bode
asymptote. Thus the crossover must be located so that the asymptote is a
factor of 10 × 4 = 40 below 1 at ω1 = 5π. The resulting lead transfer
function is
Dc(s) = 0.617 (2.22s + 1)
(0.222s + 1),
(10.39)
and the Bode plot of the lead design is shown in Fig. 10.56.
The gain crossover frequency for this design is ωc = 1.39 rad/msec and
the step response is plotted in Fig. 10.57, which shows a rise time of about
tr = 0.8 msec with an overshoot of about 25%. We have shown before that
a phase margin of 50◦should correspond to a damping of 0.5 and thus an
Figure 10.56
The Bode plot of the
design with a single
lead
Phase (deg)
Magnitude (db)
10-1
102
101
100
v (rad/sec)
-60
-260
-220
-180
-140
-100
-40
-20
0
20
40
60
80
10-1
102
101
100
v (rad/sec)
GM
PM

10.5 Control of the Read/Write Head Assembly of a Hard Disk
761
Figure 10.57
Step response of disk
drive control with
PM = 50◦
Amplitude
0
0.8
1.6
2.4
3.2
4
4.8
5.6
Time (msec)
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Figure 10.58
Bode plot of system
with lead plus roll-off
ﬁlter
Phase (deg)
Magnitude (db)
10-1
102
101
100
v (rad/sec)
-260
-220
-180
-140
-100
-40
0
40
80
10-1
102
101
100
v (rad/sec)
GM
PM
overshoot of about 17%. However, because the zero of the lead is in the
forward path, we get the extra overshoot that goes with such a zero.
As a second design, a roll-off ﬁlter is to be added to try to suppress the
resonance peak in order to gain a bit in speed of response and bandwidth.
The idea is to put the ﬁlter cutoff frequency between the crossover frequency
and the resonance frequency and to give it a damping ratio low enough that it
does not reduce the phase margin too much but high enough that it does not
interfere with the gain margin. After some experimentation, the trial design
Dc(s) = 1.44 (1.48s + 1)
(0.148s + 1),
(10.40)
is tested with a ﬁlter of
F(s) =
1
s2
(10.3)2 + 0.6
s
10.3 + 1
.
(10.41)
For this case the Bode plot is given in Fig. 10.58 and the step response in
Fig. 10.59.

762
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.59
Step response of system
with lead plus roll-off
ﬁlter
Amplitude
0
0.8
1.6
2.4
3.2
4
4.8
5.6
Time (msec)
0
0.2
0.4
0.6
0.8
1
1.2
1.4
In this case the crossover frequency is 2.13, a 35% increase, and the
rise time is 0.3 msec, a 60% reduction from the case without the roll-off
ﬁlter. The overshoot is a bit higher in this case. Although not presented here,
further possibilities for the control compensation might include a notch ﬁlter
rather than the low pass ﬁlter designed here. A notch might be able to further
suppress the resonance and permit further increase in the bandwidth. A
great deal depends on the degree of understanding of the resonance and how
much uncertainty surrounds its behavior. In some cases, it is possible to
phase-stabilize the resonance and to raise the crossover to be higher than the
resonance frequency.
STEP 6. Evaluate/modify plant. Possible changes to the process that involve
major design changes were introduced in the discussion concerning under-
standing the process in Step 1 above. Once the major parameters of the
designhavebeenselected, theremainingpossibilitiesforimprovementmight
include a change in the fabrication of the arm to add stiffness, which will
raise the frequency of the vibration, and to add a damping coating to the
arm to increase the damping ratio of the ﬂexibility. Other possibilities for
improvement concern changes in the PES decoding methodology to reduce
the noise.
STEP 7. Try an optimal controller or adaptive control. A design was done
with the linear quadratic performance measure with the performance index
(loss function) selected to obtain a rise time of about 0.3 msec to match
the classical design. The result is shown in Fig. 10.60. Although further
effort might produce an acceptable design, the clearly oscillatory response
tolerated by this particular technique does not look promising. In particular,
a design that includes a cost on ˙y as well as y should be considered. Such
extensions are considered in more advanced courses.
STEP 8. Simulate the design, and compare the alternatives. Usually done
in parallel with the design.
STEP 9. Build a prototype. Done early in the design process as a bench
model so trial schemes can be tested on hardware as designed.

10.6 Control of RTP Systems in Semiconductor Wafer Manufacturing
763
Figure 10.60
Step response for LQR
design
Amplitude
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Time (msec)
0
0.2
0.4
0.6
0.8
1
1.2
1.4
For digital control design and implementation of disk drive servos, the
reader is referred to Franklin et al. (1998).
10.6
Control of RTP Systems in Semiconductor
Wafer Manufacturing
Figure 10.61 diagrams the major steps in the manufacture of an ultra-large-
scale integrated (ULSI) circuit such as a microprocessor and some of the
associated control aspects. Many of the steps described in this process, such
as chemical vapor deposition or etching, must be done at closely controlled
and timed temperature sequences (Sze, 1988). The standard practice for
many years has been to perform these steps in batches on many wafers (sil-
icon disks that contain many chips) at a time to produce large numbers of
identical chips. In response to the demand for ever smaller critical dimen-
sions of the devices on the chip, and to give more ﬂexibility in the variety
and number of chips to be produced, the makers of the tools for fabrication
of integrated circuits are asked to provide more and more precise control
of temperature and time proﬁles during thermal processing. In response to
these demands, an important trend is to perform the thermal steps on one
wafer at a time in a chamber with cold walls and a ﬂexible heat source called
a rapid thermal processing (RTP) system as shown in Fig. 10.62.
RTP
The demands on an RTP system are illustrated by the requirement that
the temperature of the wafer needs to rapidly increase or decrease according
to a proﬁle such as that shown in Fig. 10.63, where the ramp-up speeds are
at rates of 25◦to 150◦C/sec, and the soak temperatures range from 600◦C
to 1100◦C and last from a few to as many as 120 sec. The ramp-up rates
are limited by the danger of causing damage to the crystal structure if the
temperature gradients become too large. The ability of the RTP system to
change temperature rapidly permits fabrication of devices with very small
critical lengths by being able to stop the processes such as deposition or
etching quickly and accurately. An important performance consideration is

764
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.61
Steps in making an integrated circuit
Source: Courtesy International Sematech
control of temperature uniformity. Hence the actual control is multivariable.
However, we will simplify the situation to a single-input single-output case
for this study.
Figure 10.64 shows a generic RTP reactor with tungsten halogen lamps,
stainless steel walls that are water cooled, and quartz windows. Temperature
measurement can be done by a variety of methods, including thermocouples,

10.6 Control of RTP Systems in Semiconductor Wafer Manufacturing
765
Figure 10.62
Applied Materials'
Radiance RTP system
Source: Courtesy of Applied
Materials
Figure 10.63
Typical RTP temperature
trajectory
Temperature
Time
Warm-up
Low-temperature
soak
High-temperature
soak
Figure 10.64
Generic RTP system
Exit
Wafer
Showerhead
Quartz window
Lamps
Top wall
Bottom wall
Bottom
side wall
Top
side wall
ytop
ylamp
ywin
ysh
ywaf
yexit
r1
dywaf
r2
r3
r4
rexit
rsh
r5
rwall
dlamp
dywin
dysh
Centerline

766
Chapter 10 Control System Design: Principles and Case Studies
RTDs, and pyrometers. For various reasons (particle generation, minimal
disturbance, etc.), it is desirable to use noncontact temperature sensing;
therefore, pyrometric techniques are the most commonly employed. A
pyrometer is a noncontact temperature sensor that measures infrared (IR)
radiation, which is directly a function of the temperature. It is known that
objects emit radiant energy proportional to T4, where T is the temperature
of the object. Among the advantages of pyrometers are that they have very
Pyrometer
fast response time, and can be used to measure the temperature of moving
objects (for example, a rotating semiconductor wafer), and in vacuum for
semiconductor manufacturing.
The selection of the actuator depends on the choice of techniques for
supplying power (tungsten halogen lamps, arc lamps, hot susceptor, etc.) to
Tungsten halogen lamp
heat the wafer. Tungsten halogen lamps are now commonly used in RTP in
semiconductor manufacturing (Emami-Naeini et al., 2003). Figure 10.65(a)
shows a system with two-sided heating by linear tungsten halogen lamps
(typical of systems produced by Mattson). The lamp arrays on the top and
bottom are at right angles to provide more of an axisymmetric conﬁguration.
Fig. 10.65(b) shows one-sided heating with lamps in a honeycomb conﬁg-
uration (typical of the Applied Materials systems). Finally Fig. 10.65(c)
shows a conﬁguration of lamps arranged in concentric rings (typical of the
Stanford-TI MMST chamber, Gyugyi et al., 1993). The lamps do saturate
and, for practical reasons, it is desired to operate them within 5%-95% of
maximum power settings.
To illustrate the design of an RTP system, we present the results of a
speciﬁc design carried out at SC Solutions as a laboratory model constructed
to study problems associated with RTP design and operation (Emami-Naeini
et al., 2003). The laboratory model is shown schematically in Fig. 10.66.
It is made of aluminum. It consists of three standard 35-W 12-V tungsten
halogen lamps heating a rectangular plate that simulates the wafer. The plate
measures 4 in.×1 3
4 in. and is blackened to increase its radiation absorption.
The plate is mounted parallel to the lamps. The lamps are mounted in the
lamp housing. The lamp assembly is mounted on a railing so that the distance
from the lamps to the plate is adjustable.As the lamps are moved out the gain
of the system decreases, but the radiation cross talk (coupling) increases. On
Figure 10.65
Various lamp
geometries for RTP
Source: Norman, 1992
Lamps
Wafer
Window edges
(a)
(b)
(c)
Lamps
Lamps

10.6 Control of RTP Systems in Semiconductor Wafer Manufacturing
767
Figure 10.66
Block diagram of the
RTP laboratory model
PMW
amplifier
Feedback
controller
Ty
Tr
Te
Vcmd
Noise
filter
Reference
generator
Sensor
electronics
©
+
-
Temperature sensors
Tungsten halogen lamps
the other hand, as the lamps are moved closer to the plate, the gain of the
system increases and the coupling is reduced. The nominal distance from
the lamps to the plate is 1 in., but it is adjustable to several inches. The lamps
are driven by a pulse-width modulated (PWM) ampliﬁer driver. There is a
separate power supply unit. There are three dials mounted on the side for
open-loop and manual system operations. There are 14 resistive temperature
detector (RTD) strips mounted vertically behind the back of the plate: 12
on the plate and 2 on each support on either side. There is a noise source
ﬁlter that generates periodic sensor noise at 1.5 Hertz so as to represent wafer
rotation noise seen in real RTP systems. All electronics (that is, sensor signal
processing and PWM ampliﬁer) reside in the enclosure at the bottom of the
unit. Because there is exposure to the outside, the surrounding environment
provides sources of disturbance.
RTP laboratory model
STEP 1. Understand the process and its performance speciﬁcations. RTP
is an inherently dynamic and nonlinear process. Among interesting proper-
ties of the system are multiple time scales (time constants for lamps, wafer,
showerhead, and quartz window are different); nonlinear (radiation dom-
inant) behavior; nonlinear lamps; effects of power supplies; number and
placement of sensors; number, placement, and grouping of lamps; and large
temperature variations. The DC gain in the system (δ temperature/δ power)
decreases with increasing temperature due to the nonlinear increase in radia-
tive losses. Various types of physical models are needed. Detailed physical
models are required for equipment design, but reduced-order models are

768
Chapter 10 Control System Design: Principles and Case Studies
needed for fast evaluation of geometry changes, recipe development, and for
feedback control design. Smooth transition between manual and automatic
control is also required.
STEP 2. Select sensors. This was discussed earlier. For the laboratory
model, the sensors were a set of 14 RTDs, but three (located at the cen-
ter and the support edges of the plate) can be used for feedback and the
rest can be used for temperature monitoring purposes. In our case, we will
use only the center temperature for feedback control. (Another alternative
would be to sum the three temperatures into one signal and control the
average temperature.)
STEP 3. Select actuators. This was also discussed earlier. For the laboratory
model, the actuators were composed of three standard tungsten halogen
lamps previously described. In our case, we shall tie up all three lamps into
a single actuator by applying the same input command to each lamp.
STEP 4. Make a linear model. The laboratory model was built (see Step 9).
The nonlinear system equations involve both conduction (Chapter 2) and
radiation terms (see Emami-Naeini et al., 2003). Nonlinear system identiﬁ-
cation approaches were used to derive a model for the system. Speciﬁcally,
the three lamps were stepped up, held constant, and then stepped down
sequentially, and the three output temperatures were recorded. System iden-
tiﬁcation studies11 resulted in the following nonlinear model for the system
that contains the radiation and conduction terms (Ar and Acon, respectively):
Nonlinear radiation heat
transfer
M ˙T = Ar

T
T∞
4
+ Acon

T
T∞

+ B u.
(10.42)
Here T = [T1 T2 T3]T denote the temperatures, T∞= constant ambient
temperature ( ˙T∞= 0), u = [vcmd1 vcmd2 vcmd3]T are the voltage commands,
and the system matrices are
M−1 =
⎡
⎣
1.000040
0
0
0
5.557443
0
0
0
13.638218
⎤
⎦,
Ar =
⎡
⎣
5.4762e −2
−8.5706e −3
−8.2961e −4
−4.5361e −2
−8.5706e −3
8.5709e −3
−1.6213e −7
−8.9134e −8
−8.2961e −4
−1.6213e −7
8.2998e −4
2.0976e −7
⎤
⎦,
Acon =
⎡
⎣
3.5599e −7
−1.1136e −7
−1.1976e −7
−4.7011e −8
−1.1136e −7
1.1602e −2
−2.5027e −3
−9.0992e −3
−1.9761e −7
−2.5027e −3
6.3736e −3
−3.8707e −3
⎤
⎦,
B =
⎡
⎣
3.4600e −1
1.1772e −1
2.8380e −2
3.8803e −11
8.0249e −2
1.8072e −2
8.0041e −9
2.7216e −3
3.1713e −2
⎤
⎦.
11Performed by Dr. G. van der Linden.

10.6 Control of RTP Systems in Semiconductor Wafer Manufacturing
769
A linear model for the system was derived as
˙T = A3T + B3u,
(10.43)
y = C3T + D3u,
where y = [Ty1 Ty2 Ty3]T and
RTP linear model
A3 =
⎡
⎣
−0.0682
0.0149
0.0000
0.0458
−0.1181
0.0218
0.0000
0.04683
−0.1008
⎤
⎦,
B3 =
⎡
⎣
0.3787
0.1105
0.0229
0.0000
0.4490
0.0735
0.0000
0.0007
0.4177
⎤
⎦,
C3 =
⎡
⎣
1
0
0
0
1
0
0
0
1
⎤
⎦,
D3 =
⎡
⎣
0
0
0
0
0
0
0
0
0
⎤
⎦.
The three open-loop poles are computed from Matlab and are located at
−0.0527, −0.0863, and −0.1482. For our case, because we tied the three
lamps into one actuator and are using only the center temperature for
feedback, the linear model is then
A =
⎡
⎣
−0.0682
0.0149
0.0000
0.0458
−0.1181
0.0218
0.0000
0.04683
−0.1008
⎤
⎦,
B =
⎡
⎣
0.5122
0.5226
0.4185
⎤
⎦,
C =
 0
1
0 	
,
D = [0] ,
resulting in the transfer function
G(s) = Ty2(s)
Vcmd(s) =
0.5226(s + 0.0876)(s + 0.1438)
(s + 0.1482)(s + 0.0527)(s + 0.0863).
STEP 5. Try a lead-lag or PID controller. We may try a simple PI controller
of the form
Dc(s) = (s + 0.0527)
s
,
so as to cancel the effect of one of the slower poles. The linear closed-
loop response is shown in Fig. 10.67(a) and the associated control effort
is shown in Fig. 10.67(b). The system response follows the commanded
trajectory with a time delay of approximately 2 sec and no overshoot. The
lamp has its normal response until 75 sec and goes negative (shown dashed)
to try to follow the sharp drop in commanded temperature. This behavior is
not possible in the system, as there is no means of active cooling and the
lamps do saturate low. Note that there is no explicit means of controlling the
temperature nonuniformity in this approach.
STEP 6. Evaluate/modify plant. This was discussed already in connection
with actuator and sensor selection.
STEP 7. Try an optimal design. We use the error-space approach for inclu-
sion of integral control and employ the linear quadratic Gaussian technique
of Chapter 7. The error system is
 ˙e
˙ξ

=
 0
C
0
A
  e
ξ

+
 D
B

μ,
(10.44)

770
Chapter 10 Control System Design: Principles and Case Studies
Temperature (K)
0
5
15
25
10
20
30
(a) Temperature tracking response
(b) Control effort
100
80
90
70
60
50
40
30
20
10
0
Time (sec)
Lamp voltage
-25
-20
-10
0
-15
-5
5
100
80
90
70
60
50
40
30
20
10
0
Time (sec)
r
y
u
Figure 10.67
Linear closed-loop RTP response for PI controller
where
As =
 0
C
0
A

,
Bs =
 D
B

,
e = y−r, ξ = ˙T, and μ = ˙u. For state feedback design, the LQR formulation
of Chapter 7 is used; that is,
J =
 ∞
0
{zTQ z+ρμ2} dt,
where z = [e ξT]T. Note that J needs to be chosen in such a way as to
penalize the tracking error e and the control u, as well as the differences in
the three temperatures. Therefore, the performance index should include a
term of the form
Temperature uniformity
10

( ˙T1 −˙T2)2 + ( ˙T1 −˙T3)2 + ( ˙T2 −˙T3)2
,
which minimizes a measure of the temperature nonuniformity. The factor
of 10 was determined by trial and error as the relative weighting between
the error state and the plant state. The state and control weighting matrices,
Q and R, respectively, are then
Q =
⎡
⎢⎢⎣
1
0
0
0
0
20
−10
−10
0
−10
20
−10
0
−10
−10
20
⎤
⎥⎥⎦,
R = ρ = 1.
The following Matlab command is used to design the feedback gain:
[K] = lqr(As,Bs,Q,R).

10.6 Control of RTP Systems in Semiconductor Wafer Manufacturing
771
The resulting feedback gain matrix computed from Matlab is
K = [K1 : K0],
where
K1 = 1,
K0 =
 0.1221
2.0788
−0.2140 	
,
which results in the internal model controller of the form
˙xc = Bce,
(10.45)
u = Ccxc −K0T,
with xc denoting the controller state and
Bc = −K1 = −1, Cc = 1.
The resulting state-feedback closed-loop poles computed from Matlab
are at −0.5574 ± 0.4584j, −0.1442, and −0.0877. The full-order estimator
was designed with the process and sensor noise intensities selected as the
estimator design knobs:
Rw = 1,
Rv = 0.001.
The following Matlab command is used to design the estimator:
[L] = lqe(A,B,C,Rw,Rv).
The resulting estimator gain matrix is
L =
⎡
⎣
16.1461
16.4710
13.2001
⎤
⎦,
with estimator error poles at −16.5268, −0.1438, and −0.0876. The
estimator equation is
˙ˆT = A ˆT + Bu+L(y−C ˆT).
(10.46)
With the estimator, the internal model controller equation is modiﬁed as
˙xc = Bce,
(10.47)
u = Ccxc −K0 ˆT.
The closed-loop system equations are given by
˙xcl = Aclxcl + Bclr,
(10.48)
y = Cclxcl + Dclr,
where r is the reference input temperature trajectory, the closed-loop state
vector is xcl = [TT xT
c ˆTT]T and the system matrices are
Acl =
⎡
⎣
A
BCc
−BK0
BcC
0
0
LC
BCc
A −BK0−LC
⎤
⎦,
Bcl =
⎡
⎣
0
−Bc
0
⎤
⎦,
Ccl =
C
0
0	
,
Dcl = [0],

772
Chapter 10 Control System Design: Principles and Case Studies
with closed-loop poles (computed with Matlab) located at −0.5574 ±
0.4584j, −0.1442, −0.0877, −16.5268, −0.1438 and −0.0876 as expected.
The closed-loop control structure is shown in Fig. 10.68.
The closed-loop control system diagram implemented in Simulink
is shown in Fig. 10.69. The linear closed-loop response is shown in
Fig. 10.70(a), and the associated control effort is shown in Fig. 10.70(b).
The commanded temperature trajectory, r, is a ramp from 0◦C to 25◦C, with
a 1◦C/sec slope followed by 50-sec soak time and a drop back to 0◦C. (Note
that the ramp rate is very slow here because we have only three lamps for our
RTP laboratory model, whereas a real RTP system would have hundreds of
lamps, and the much faster ramp rates mentioned earlier would be relevant.)
The system tracks the commanded temperature trajectory—albeit with a time
delay of approximately 2 sec for the ramp and a maximum of 0.089◦C over-
Temperature trajectory
following
shoot. As expected, the system tracks a constant input asymptotically, with
zero steady-state error. The lamp command increases as expected to allow
for tracking the ramp input, reaches a maximum value at 25 sec, and then
©
+
-
©
+
-
R
Y
-Bc
Cc
xc
u
s
1
-Ko
x = Ax + Bu
x = (A - LC) x + Bu + Ly
ˆ
ˆ
Linear plant
Estimator
y = Cx
Figure 10.68
Closed-loop control structure diagram
Scope 1
Scope 2
Scope
-
+
Repeating
sequence
k1 • u
k1
Matrix
gain1
k0 • u
k0
Matrix
gain
-
+
Saturation
Integrator
s
1
y = Cx + Du
x¿ = Ax + Bu
RTP plant
State-space
y = Cx + Du
x¿ = Ax + Bu
Estimator
State-space1
Figure 10.69
Simulink block diagram for RTP closed-loop control

10.6 Control of RTP Systems in Semiconductor Wafer Manufacturing
773
Temperature (K)
-5
0
5
15
25
10
20
30
(a) Temperature tracking response
(b) Control effort
100
80
90
70
60
50
40
30
20
10
0
Time (sec)
Lamp voltage
-14
-12
-10
-6
-8
-4
-2
-0
4
2
6
100
80
90
70
60
50
40
30
20
10
0
Time (sec)
r
y
u
Figure 10.70
Linear closed-loop RTP response for robust servomechanism controller
drops to a steady-state value around 35 sec. The normal response of the lamp
is seen from 0 to 75 sec, followed by a negative commanded voltage for a
few seconds corresponding to fast cooling. Again, the negative control effort
voltage (shown in dashed lines) is physically impossible as there is no active
cooling in the system. Hence, in the nonlinear simulations, commanded
lamp power must be constrained to be strictly nonnegative (Step 8). Note
that the response from 75 to 100 sec is that of the (negative) step response
of the system.
STEP 8. Simulate the design with nonlinearities. The nonlinear closed-
loop system was simulated in Simulink as shown in Fig. 10.71. The model
Simulink nonlinear
simulation
was implemented in temperature units of degrees Kelvin and the ambient
temperature is 301K.12 The nonlinear plant model is the implementation of
Eq.(10.42). Thereisapreﬁlterfollowingthereferencetemperaturetrajectory
Preﬁlter
(to smoothen the sharp corners) with the transfer function
Gpf(s) =
0.2
s + 0.2.
(10.49)
Note that conversion from voltage to power was determined experimentally
to be given by
Lamp nonlinearity
P = V1.6,
(10.50)
and is implemented as a nonlinear block (named VtoPower) in the Simulink
diagram accordingly (Fig. 10.72). The inverse of the static nonlinear lamp
model is also included as a block (named InvLamp):
V = P0.625.
(10.51)
This will cancel the lamp nonlinearity. The voltage range for system oper-
ation is between 1 and 4 volts, as seen from the diagram. A saturation
12[K] = [◦C] + 273.

774
Chapter 10 Control System Design: Principles and Case Studies
VtoPower
In 1
Out 1
Subsystem 1
Scope 2
Scope 1
Scope 3
-
+
Repeating
sequence
K • u
k1
Matrix
Gain 1
K • u
Matrix
Gain 4
K • u
k0
Matrix
Gain
K • u
Matrix
Gain 4
K • u
Antiwindup
Matrix
Gain 2
-
+
Saturation
Integrator s
1
Integrator
xo v 301.35
s
1
InvLamp
In 1
Out 1
Subsystem 2
y = Cx + Du
xœ = Ax + Bu
Estimator
State-space 1
-
+
To workspace 1
r
To workspace 2
u
-+
Scope 4
Nonlinear plant
(a)
(b)
Out 1
In 1
Subsystem
Scope
K • u
Matrix
Gain 3
K • u
Matrix
Gain 5
K • u
Matrix
Gain 5
Lamp
uncertainty
To workspace 2
y
Constant 1
4
Input
flux
K • u
Matrix
Gain
Node temp
Sum
M_inv
Add flux
1
In 1
1
In 2
+
-
-
Math function
uy
Boltzmann
Radiation
K • u
Matrix
Gain 2
Scale temp
Mux 3
K • u
Matrix
Gain 3
Conduction
Mux 2
Constant
301.352135
Figure 10.71
Simulink diagram for nonlinear closed-loop RTP system: (a) nonlinear closed-loop; (b) nonlinear plant

10.6 Control of RTP Systems in Semiconductor Wafer Manufacturing
775
Figure 10.72
Simulink diagram for
nonlinear closed-loop
RTP system:
(a) subsystem to
convert voltage to
power; (b) subsystem
for lamp model
(a)
1
In 1
1
Out 1
Math function
uy
Constant
1
Saturation
-
+
Constant
1
Constant 1
1.6
(b)
1
In 1
1
Out 1
Math function
uy
Constant
1
+
+
Constant
1
Constant 1
0.625
Temperature (K)
310
315
320
330
325
335
(a) Temperature tracking response
(b) Control effort
180
160
140
120
100
80
60
40
20
Time (sec)
180
160
140
120
100
80
60
40
20
Time (sec)
Lamp voltage (V)
0
0.5
1
2.0
1.5
2.5
3
3.5
4
r
y
u
Figure 10.73
Nonlinear closed-loop response for robust servomechanism controller
nonlinearity is included for the lamp as well as integrator antiwindup logic
to deal with lamp saturation. The nonlinear dynamic response is shown in
Fig. 10.73(a) and the control effort is shown in Fig. 10.73(b). Note that the
nonlinear response is in general agreement with the linear response.
A prototype of the RTP laboratory model was designed, built,13 and
demonstrated at the Sematech AEC/APC'98 Conference, in Vail, Col-
orado. Figure 10.74 shows a photograph of the operational system. This
system is really multivariable in nature. The three-input-three-output mul-
tivariable controller used on the prototype system was designed using the
same approach discussed in Step 7, and was implemented on an embedded
controller platform that uses a real-time operating system.
13By Dr. J. L. Ebert.

776
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.74
RTP temperature control
laboratory model
Source: Photo courtesy of
Abbas Emami-Naeini
Figure 10.75
Response of the RTP
temperature control
laboratory model
Vcmd (V)
Temperatlure  (C)
0
140
120
100
80
60
40
20
1
1.5
2
2.5
3
3.5
35
40
45
50
55
60
65
Time (sec)
0
140
120
100
80
60
40
20
Time (sec)
Vcmd2
Vcmd1
Vcmd3
Tr
Ty1
Ty2
Ty3
The continuous controller (that is, the combined internal model
controller and the estimator) is of the form
˙xc = Acxc + Bce,
(10.52)
u = Ccxc,
where xc = [xT
c ˆTT]T,
Ac =
 0
0
BCc
A −BK0−LC

,
Bc =
Bc
L

,
(10.53)
and
Cc =
Cc
−K0
	
.

10.7 Chemotaxis or How E. Coli Swims Away from Trouble
777
The controller was discretized (see Chapter 8) with a sampling period of Ts =
0.1 sec and implemented digitally (with appropriate antiwindup logic) as
xc
k+1 = cxc
k + cek,
(10.54)
uk = Ccxc
k.
The response of the actual system to the reference temperature trajectory,
along with the three lamp voltages, is shown in Fig. 10.75. It is in good
agreement with the nonlinear closed-loop simulation of the system (once
noise is accounted for).
For further information on modeling and control of RTP systems, the
reader is referred to Emami-Naeini et al. (2003), Ebert et al. (1995a,b), de
Roover et al. (1998), and Gyugyi et al. (1993).
10.7
Chemotaxis or How E. Coli Swims Away
from Trouble
Background
The cell is the basic structural and physiological subsystem of all living
organisms and most of the biochemical activities necessary for life are per-
formed in cells. Some organisms, such as the bacteria in Fig. 10.76., consist
of only a single cell. Escherichia coli (E. coli), photographed in Fig. 10.77,
is one of these single-cell organisms that has been extensively studied and
whose interesting motion and control will be described in a highly simpliﬁed
way in this case study. The technical results for the study come from the ﬁeld
of systems biology. Systems biology is an emerging ﬁeld with the goal of
creating dynamic models to describe the incredibly complex processes in
many biological systems. The aim is to determine how shifting variables in
Systems biology
Figure 10.76
(a) A typical bacterium; (b) TEM of bacterium Bacillus coagulans
Source: (a) Campbell and Reece, page 98, 2008. © Pearson Education; (b) © 2014 Stanley C. Holt/Biological Photo Service.

778
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.77
E. coli bacteria
Source: United States
Department of Health and
Human Services, National
Institutes of Health
one part impact the whole. In this case study, a model is presented to suggest
how ideas from control can contribute to this effort. In preparing the study,
we have tried to minimize the use of technical terms from biology and to
deﬁne clearly those found useful and necessary for the presentation. It is
hoped that this simple introduction will inspire control engineers to conduct
direct study of this important ﬁeld. First, a bit of background.
Escherichia coli was discovered by German pediatrician and bacteriolo-
E.coli
gistTheodor Escherich in 1885. The bacterium is a cylindrical organism with
hemispherical endcaps as depicted in Fig.10.77. It is approximately 1 micron
(μ) in diameter and 2 microns (μ) in length and weighs about 1 picogram
(pg). E. coli lives in the large intestine of warm blooded "host" animals,
including humans. The bacterium can help in maintaining the balance of
healthful intestinal ﬂora (that is, the population of microbial organisms) in
the gut and can also synthesize vitamins that beneﬁt its host. E. coli has been
studied extensively by geneticists because of its rather small genome size
and the ease of growth in a laboratory. E. coli grows longer and divides by
binary ﬁssion to create two genetically identical "daughter" bacteria. Under
optimal nutritional and environmental conditions, a population of E. coli
can double every 20 minutes. While most E. coli "strains," or variants of the
E. coli species, are harmless, a particular strain (E. coli O157:H7) can cause
food poisoning in humans if ingested. The entire genome, or the "library"
of inherited genetic information, has been sequenced for different E. coli
strains: for example, "lab strain" E. coli K12 MG1655 contains approxi-
mately 4.64 million of the adenosine-thymine (A-T) and cytosine-guanine
(C-G) DNA base pairs arranged into a total of 4466 predicted genes. These
genes serve as instructions for the synthesis of speciﬁc proteins. Proteins
are the primary tools that cells use to implement biochemical and biophys-
ical processes. Highly regulated networks of Protein-Protein Interactions

10.7 Chemotaxis or How E. Coli Swims Away from Trouble
779
(PPI) give rise to higher order functions essential for the survival of the cell,
including, in the case of E. coli, motility. In 2003 researchers demonstrated
that solitary E. coli cells exhibit "quorum sensing" via positive chemotaxis,
meaning that they are attracted to like cells in order to perform tasks requiring
multiple E. coli, such as the formation of a "bioﬁlm."
Escherichia coli has a set of 6 to 10 rotary motors, each driving a thin
helicalﬁlamentabout10μmlongthroughashort, ﬂexibleandproximalhook
that acts as a universal joint. This entire assembly is called a ﬂagellum (Berg,
2004). The motor runs either clockwise (CW), as seen by an observer outside
of the cell looking down at the hook, or counterclockwise (CCW). When all
the motors rotate CCW, the ﬂagella ﬁlaments bundle together and the cell
swims steadily forward in a "run," as suggested in Fig. 10.78. When one or
more motors switch to CW rotation, the corresponding ﬂagella unbundle and
reorient the cell in a "tumble" resulting in little displacement as shown in Fig.
10.79. The two modes of motion alternate and, in a state of equilibrium with
its environment, the E. coli alternates between both modes with runs lasting
about 1 sec and tumbles about 0.1 sec, resulting in a 3-D random walk.
Through control of tumbling frequency, the bacteria can direct their motion
toward a relatively high concentration of attractant molecules or away from
a relatively high concentration of repellent molecules as suggested in Fig.
10.80.
The Problem
Chemotaxis is the name given to the process by which a motile bacterium
Chemotaxis
senses the changes in its environment and moves toward places with a more
favorable environment. Chemotaxis is important for proper functioning of
the cell. An E. coli bacterium compares the current attractant concentra-
tion with the past attractant concentration. If it detects a positive change in
the attractant concentration, it should move up the gradient. To do so, the
probability of a tumble, and hence its tumbling frequency, is reduced and
the runs are correspondingly longer. In contrast, if it detects an increase
Figure 10.78
Flagella motors turning
CCW resulting in a run
Source: Courtesy Nima Cyrus
Emami
Flagella
"Bundle"
E. coli
Plasma membrane
Cell wall

780
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.79
Flagella motors turning
CW resulting in a tumble
Source: Courtesy Nima Cyrus
Emami
Plasma membrane
Cell wall
Figure 10.80
Escherichia coli
movements resembling
a biased random walk
in repellent concentration, the assumption seems to be that it must have
been swimming in a bad direction; consequently, the bacterium increases
its tumbling frequency and tries to change direction so as to swim away
from the repellents. The dynamics of this chemotaxis are the subject of our
case study.
Several different models of bacterial chemotaxis have been developed
by researchers in systems biology. Our discussion is based on two of these
(Barkai & Libler, 1997; Yi et al., 2000). The different proteins involved
in chemotactic response have been well studied and their interactions have
been characterized in some detail as shown in Fig. 10.81. Biologists have
named the proteins involved in chemotaxis by letters of the alphabet preﬁxed
by "Che" (for example, CheA, CheB). In biology, signal transduction is a
process by which molecular stimuli outside of the cell react with receptor

10.7 Chemotaxis or How E. Coli Swims Away from Trouble
781
CheW
CheA
CheW
CheA
CheB
P
CheR
CheZ
CheB
Cell Membrane
MCP
MCP
CheY
CheY
P
M
Input (attractants)
Output
(tumbling frequency, CW flagellar rotation)
FliM
Figure 10.81
The chemotaxis signal transconduction pathway in E. coli
Source: Courtesy of Nima Cyrus Emami
proteins in the cell membrane, which in turn activate "second messenger"
proteins within the cell to carry out some task (for example, expression of a
gene, and biochemical synthesis). On the surface of the bacterium is a class
of receptor proteins called MCPs, or methyl-accepting chemotaxis proteins.
The MCPs contain extracellular, transmembrane, and intracellular domains,
meaning that they have sub-units which sense chemical stimuli outside of the
cell and subsequently activate proteins inside of the cell. These chemicals
constitute the input to the system and are collectively called ligands. The
Ligand
system is set up to control the frequency of tumbling, which is done by
control of the activity of CheY, the protein that acts directly on the motor of
the ﬂagella.
The MCPs bind CheA and CheW within the cell to form a receptor com-
plex which, through feedback regulation, maintains sensitivity to changes in
attractant binding over a wide range of ligand concentrations. Here the input
and output conditions, PPI, and biochemical transformations that induce this
regulatory process are described. Receptors are considered either active and
awaiting a ligand or are inactive and not accepting any ligand. In biochem-
istry, phosphorylation, or the transfer of a negatively charged phosphate
group (-PO3−
4 ) to a protein, is a common method for activating a protein
for some task by inducing a transformation in its structural and biochem-
ical properties. In chemotaxis, a decrease in attractant binding results in
increased phosphorylation of CheA (denoted by CheA-P), while increased

782
Chapter 10 Control System Design: Principles and Case Studies
attractant binding causes decreased CheA phosphorylation. Receptors with
CheA-P are considered active (more frequent tumbles), while those with
dephosphorylated CheA are inactive (more frequent runs). The mechanism
behind this change in motility is the phosphorylation of CheY: CheA-P
transfers its phosphate group to CheY yielding CheY-P, which binds the
FliM protein in the ﬂagellum basal body (motor) to produce more frequent
tumbling.
As part of the steady-state dynamics of chemotaxis, methyl groups
(-CH3) are regularly being added to the MCP by CheR (methylation) and
equally removed by CheB (demethylation). Because CheA-P also phos-
phorylates CheB and CheB-P more frequently demethylates the MCP, this
balance is upset when a ligand binds to an active receptor complex. If the lig-
and is an attractant, the activity of CheA is reduced (less CheA-P), the action
of CheB in MCP demethylation is reduced (less CheB-P), more receptors
are made active and the activity of CheA slowly returns to the steady-state.
This is the feedback loop in chemotaxis. Meanwhile, CheA reduces its rate
of activating CheY (less CheY-P) and this causes the tumbling frequency
to be reduced. As a consequence, the bacteria swim more and presumably
swim toward the attractant concentration. Now, if the ligand is a repellent,
the activity of CheA is increased, which causes increased rate of CheY activ-
ity and increased frequency of tumbling. The bacterium swims less while
it "looks" for a new direction in order to escape the concentration of repel-
lents. At the same time, in the feedback loop, CheB is also more active,
receptors are made inactive at a greater rate, and again CheA and the tumble
frequency return to their steady-state values. The fact that the activity and the
tumble frequency return to exactly the same value after a change in ligand
concentration is a remarkable property called exact adaptation by system
Exact adaptation
biologists. As we will see, to a control engineer, this is a very common
control method. An experimental plot of chemotaxis is reproduced in Fig.
10.82.
The Model
The problem, then, is to develop a model as a control system block diagram
that will describe the average motion of this chemotaxis situation. We rep-
resent the averages as if they were one receptor complex with the related
proteins acting on the ﬂagella. As the research shows, the equations are
complex and highly nonlinear. Also, the surface of the bacterium contains
hundreds of receptor complexes and these interact as suggested already in
Fig. 10.81. For our study, the variables for the block diagram are selected
as linear, small signal deviations of the averages of the several quantities
away from their equilibrium values. The input is taken to be the concentra-
tion of ligand, with attractors being positive and repellents being negative.
The outputs of the system are the activity of CheA-P and resulting motion
in the single x direction. The parameters of our model were selected so
the responses matched the curves given in Fig. 10 of (Mello et al., 2004).
The mechanics of one-dimensional motion assume that the viscous friction

10.7 Chemotaxis or How E. Coli Swims Away from Trouble
783
Figure 10.82
Experimental data of
E. coli chemotaxis (Berg
and Brown 1972). The
plots are planar
projections of 3-D paths
50 om
AW405
Wild type
29.5s
26 runs
Mean speed 21.2 om/s
dominates the mass so the dynamics are a single integrator. The model is
based on the following facts.
•
It is observed that when a ligand binds to an active receptor site,
the changes in concentrations of CheA-P and resulting CheB-P and
CheY-P are almost instantaneous.
•
However, the CheB phosphorylation only changes the rate of demethy-
lation, not the extent of demethylation itself. The changes in methylation
level take place much more slowly than the changes in tumble rate.
•
Upon insertion of a concentration of attractants, the "activity" as mea-
sured by the concentration of CheA-P drops quickly, then slowly
recovers to exactly the same steady-state level. This property is called
adaptation of activity.
Adaptation
A control block diagram shown in Fig. 10.83 implements these facts,
including the adaptation. As seen, the adaptation result is accomplished
by the standard control scheme of integral control. A Simulink schematic
is shown in Fig. 10.84 and the responses in Figs 10.85-10.87 for ﬁxed
concentrations of CheR. If the value of CheR is changed, the steady-state
intensity of the activity changes and the time constant of the methylation also
changes. Fig. 10.85 shows that if attractant is added at time t = 20 sec, the
tumble activity drops but recovers to its initial value within approximately
5 seconds. Fig. 10.86 shows the corresponding behavior of the methylation
level, and Fig. 10.87 shows the motion response of the chemotaxis model.

784
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.83
Simpliﬁed block
diagram of E. coli
chemotaxis. ℓ
represents ligand, m
the methylation, CheR
the steady-state rate of
methylation, ¯y the
steady-state activity,
and w the steady-state
random walk motion
©
©
©
©
 + 
 + 
 + 
 + 
 - 
 - 
 - 
m
l
CheR
x
y
w
CheB
CheA−P
K
Ka
Kx
Km
s
CheY−P
1
s
0.5
Ligand
Activity
K
Ka
Kx
Motion
Scope
Random
number
Constant
CheR
Integrator
Km
Mo
Methyl
KM
x
-+
-+
-+
++
++
2.0
-K-
0.5
1.0
1.1
.5
0.5
1
s
1
s
Figure 10.84
A Simulink schematic diagram for simulating E. coli chemotaxis
Figure 10.85
Simulated tumble
frequency of the
chemotaxis model
following insertion of
attractant at t = 20 sec
1
0.9
0.8
0.7
0.6
0.5
Tumble Activity
Attractant added
0.4
0.3
0.2
0.1
0
0
5
10
15
20
Time (sec)
25
30
35
40

10.7 Chemotaxis or How E. Coli Swims Away from Trouble
785
Figure 10.86
Methylation of the
chemotaxis model
following insertion of
attractant at t = 20 sec
3
2.8
2.6
2.4
2.2
Methylation level
2
1.80
5
10
15
20
Time (sec)
25
30
35
40
Figure 10.87
Motion response of the
chemotaxis model
following insertion of
attractant at t = 20 sec
0.45
0.4
0.35
0.3
0.25
0.2
Position x
0.15
0.1
0.05
00
5
10
15
20
Time (Sec)
25
30
35
40
In the end, we leave this case study with more questions than answers.
Forexample, oneshouldbeabletoderivethemodelbyasmallsignalanalysis
from the basic chemical and physical equations of the processes. The model
as presented could be modiﬁed to account for changes in the concentration
of CheR, for example. Finally, how would the model be extended to describe
the motion in three dimensions? We hope someone using this book is inspired
to ﬁnd the answers to these questions.
Summary and Recap
For years biologists had been focusing on studying various parts of living
organisms. Recently, the focus has shifted to studying the whole organism's
behavior as a system of interconnected parts. Since the 1970s, it had been
known experimentally that many biological systems adjust to their environ-
ment in an adaptive way. Recently, analytical models have been developed to

786
Chapter 10 Control System Design: Principles and Case Studies
explain this phenomenon as we discussed in this case study. The new analyt-
ical models can explain the inherent properties of the biological system such
as robust perfect adaptation as given by the integral control of the receptor
sensitivity. Control theory methods and interpretations have proved helpful
in increasing the level of our understanding of the behavior and properties
of biological systems. We hope that this simple example helps stimulate
interest in this exciting ﬁeld.
10.8
Historical Perspective
The ﬁrst autopilot was tested on a Curtis ﬂying boat in 1912, just 9 years
after the ﬁrst Wright brothers' ﬂight. It consisted of a gyroscope to measure
theattitudeandservomotorstoactivatethecontrolsurfacesandwasdesigned
by Elmer Sperry. In part, it was a result of the Wright brothers' design to
intentionally make the aircraft slightly unstable in order to make it more
controllable by the pilot. This system gained fame in 1914 when it won
a prize in France by demonstrating its capabilities by ﬂying close to the
ground with the mechanic walking back and forth along the wing with the
pilot, Lawrence Sperry, standing in the cockpit with his hands in the air.14
Autopilot development went underground in 1915 due to military secu-
rity forWWI. The next public display was an adaptation of the Sperry system
forWileyPostinhis1933ﬂightaroundtheworldin"WinnieMae." Theﬂight
would have been near impossible without the autopilot because it allowed
Post to doze off on occasion. It has been reported that Post had a system
consisting of a wrench and string tied to his ﬁnger that would wake him up
if he slept too soundly. The success of this ﬂight led to the development of
an autopilot that included some navigational capabilities as well as attitude
control and, in 1947, theAir Force demonstrated an automatic trans-Atlantic
ﬂight in a DC-3 type airplane from take-off to landing.
Subsequently, airplanes developed swept wings and higher speeds
which required stability augmentation systems to help the pilot control the
aircraft even when not on the autopilot. These systems are on all high-
performance military and commercial airliners today. In 1974, the F-16
became the ﬁrst airplane to have aerodynamically unstable regimes and was,
therefore, highlydependentonthestabilityaugmentationforsustainedﬂight.
This was implemented in order to make the airplane more maneuverable, but
required a "ﬂy-by-wire" and quad redundancy for acceptable reliability.
The ﬁrst spacecraft in the late 1950s had no attitude control since
their only mission was to take measurements and broadcast the informa-
tion back to earth. However, they were followed in the early 1960s with
the Corona spacecraft whose mission was to take photographs of the earth,
which required that the camera be pointed and stabilized very accurately.
At the time, these missions were classiﬁed for military purposes and called
14No mechanical connection from the stick to the control surfaces.

10.8 Historical Perspective
787
Discoverer for public consumption, but since then have been declassiﬁed
and described in some detail.15
The ﬁrst digital autopilots were in theApollo program lunar module and
the command module in the late 1960s. They were developed primarily by
MIT's Instrumentation Lab under the direction of Bill Widnall, Don Fraser,
and Dick Battin. The decision to take the bold step of using digital technology
for the ﬁrst time rather than the traditional analog implementation was made
by NASA in order to handle the complexity required at a reasonable weight.
Prior to 1980, automobile engine control systems consisted of a mechan-
ical arrangement in the distributor to vary the spark timing and a ﬂuidic
system in the carburetor that varied fuel ﬂow in response to the airﬂow rate
or sudden changes in the accelerator pedal position. These were open-loop
systems that essentially programmed the proper control setting based on the
operating condition of the engine. In 1980, cars were required to improve
their polluting characteristics; therefore, it was essential to improve the con-
trols using feedback as described in Section 10.4. These systems still exist
today along with variable valve timing, variable fuel injection timing, tai-
lored high pressure injection, and variable valve opening levels. Large strides
have also been made in the vehicle's control: stability augmentation has
substantially reduced SUV rollovers, cruise control now include radar for
keeping a reasonable distance behind the car in front and sensors to maintain
the car in the lane. A feedback controlled automobile is becoming a reality
(for example, the Google car).
One of the persistently exciting control applications is that of disk drive
servos. From the start in the early 1950s to the massive capacity commod-
ity drives of today, the problem of accessing data on a rotating disk media
has provided a wealth of control challenges to be solved. The basic con-
trol functions have not changed for a while and there are two modes for
control, seek mode and track follow mode, each with their own control sys-
tem. Embedded servo data were introduced in 1995 and remain the same
today with the result that the control system is truly sampled data in nature.
The rotary actuator was introduced in 1985 which improved the mechanical
response and the basic ﬂat coil actuator introduced in 1989 is still in use
today. Dual (two stage) actuator hard disk drives are now in use and track
following accuracy and vibration suppression are the current control system
design issues. The magnetics are designed using 3D software to optimize
torque factor. The goal is to minimize acoustics (except for the ones used
in servers) and cost. The acoustics are reduced by increasing access time
resulting in smoother seek proﬁles. The latest trend in storage is toward the
use of solid state ﬂash drives (SSD), but they are slow and volatile. A hybrid
solution is emerging: a solid state drive ﬂash for buffer in front of a hard
disk drive; the two technologies are complimentary and will coexist for the
foreseeable future. While the demise of the hard disk has been predicted for
a few decades, it is likely to remain alive and well, simply based on storage
15Taubman (2003).

788
Chapter 10 Control System Design: Principles and Case Studies
capacity and cost (the retail price of a 3 terabyte hard disk drive was around
$129 in 2013).
Application of control to semiconductor wafer manufacturing automa-
tion is gaining momentum. Many important process steps such as RTP,
chemical-mechanical planarization, and lithography use advanced real-time
controllers. It is anticipated that during the next decade many more of the
semiconductor fabrication equipment will employ sophisticated in-situ feed-
back control as new sensors become available. This adoption of sophisticated
closed-loop control systems by the semiconductor industry presents new
challenges and opportunities for control system engineers especially for
the upcoming 450-mm diameter wafers. Application of control to magnetic
resonance force microscopy for imaging atomic structure of materials (de
Roover et al., 2008) can fundamentally change our understanding of atomic
structures of devices and enable imaging of biological subsystems.
The emerging ﬁeld of systems biology marks the coming of age of the
life sciences. The usual approach of studying individual components is being
replaced by a new approach focused on understanding the behavior of the
whole biological system. Among the admirable goals are understanding the
behavior of biological systems and discovering cure for diseases such as
cancer, as well as developing novel approaches to discovery of new drugs,
production of antibiotics, and vaccines.
The applications of control theory have never been more exciting than
they are today. Applications of feedback control ideas to biological sys-
tems, network congestion control, and new aerospace systems are emerging.
Applications in genomics treating the human body as a dynamic system are
underway. The Internet has attracted the attention of many control systems
researchers eager to understand the tremendous success of this technology
and how to improve it. Network design and control including Internet mod-
eling, and development of congestion routing and control are under study. A
number of our colleagues are enthusiastic about application of control theory
to the ﬁnancial ﬁeld; however, to date, none of them have proﬁted enough
to quit their day job!
SUMMARY
•
In this chapter we have laid out a basic outline of control systems design
and applied it to six typical case studies. The design outline calls for a
number of explicit steps.
1. Makeasystemmodelanddeterminetherequiredperformancespec-
iﬁcations. The purpose of this step is to answer the question, What
is the system, and what is it supposed to do?
2. Select sensors. A basic rule of control is that if you can't observe
it, you can't control it. Following are some factors to consider in
the selection of sensors:
(a) Number and location of sensors;
(b) Technology to be used;

Summary
789
(c) Performance of the sensor, such as its accuracy;
(d) Physical size and weight;
(e) Quality of the sensor, such as lifetime and robustness to
environment changes; and
(f) Cost.
3. Select actuators. The actuators must be capable of driving the sys-
tem so as to meet the required performance speciﬁcations. The
selection is governed by the same factors that apply to sensor
selection.
4. Make a linear model. All our design methods are based on linear
models. Both small-signal perturbation models and feedback-
linearization methods can be used.
5. Try a simple PID controller. An effort to meet the speciﬁcations
with a PID or its cousin, the lead-lag compensator, may succeed;
in any case such an effort will expose the nature of the control
problem.
6. Evaluate/modify plant.
Evaluate whether plant modiﬁcations
enhance closed-loop performance; if so, return to Step 1 or 4.
7. Try an optimal design. The SRL method for control-law selec-
tion and estimator design based on state equations is guaranteed
to produce a stable control system and can be structured to show
a trade-off between error reduction and control effort. A related
alternative is arbitrary pole placement, which gives the designer
direct control over the dynamic response. Both the SRL and the
pole-placement methods may result in designs that are not robust
to parameter changes.
8. Simulate the design, and verify its performance. All the tools of
analysis should be used here, including the root locus, the frequency
response, GM and PM measurements, and transient responses.
Also, the performance of the design can be tested in simulation
against changes in model parameters and the effects of approxi-
mating the compensator with a discrete model if digital control is
to be used.
9. Build a prototype, and measure the performance with typical input
signals. The proof of the pudding is in the eating, and no control
design is acceptable until it has been tested. No model can include
all the features of a real physical device; so the ﬁnal step before
ﬁxing the design is to try it out on a physical prototype if time and
budget permit.
•
The satellite case study illustrated particularly the use of a notch com-
pensation for a system with lightly damped resonance. It was also shown
that collocated actuator and sensor systems are much easier to control
than noncollocated systems.
•
The Boeing 747 lateral-stabilization case study illustrated the use of
feedback as an inner-loop designed to aid the pilot, who provides the
primary outer-loop control.

790
Chapter 10 Control System Design: Principles and Case Studies
•
The Boeing 747 altitude control showed how to combine inner-loop
feedback with outer-loop compensation to design a complete control
system.
•
The automobile fuel-air ratio control illustrated the use of the Bode plot
to design a system that includes time delay. Simulation of the design
with the nonlinear sensor veriﬁed our heuristic analysis of limit cycles
using the concept of equivalent gain with a root locus.
•
The disk-drive case study illustrated control in an uncertain environ-
ment, where bandwidth is very important.
•
The RTP case study illustrated modeling and control of a nonlinear
thermal system.
•
The E. coli chemotaxis case study illustrated a simple example of the
application of ideas from control theory to the emerging ﬁeld of systems
biology.
•
In all cases the designer needs to be able to use multiple tools, including
therootlocus, thefrequencyresponse, poleplacementbystatefeedback,
and simulation of time responses to get a good design. We promised an
understanding of these tools at the beginning of the text, and we trust
you are now ready to practice the art of control engineering.
REVIEW QUESTIONS
10.1
Why is a collocated actuator and sensor arrangement for a lightly damped
structure such as a robot arm easier to design than a noncollocated setup?
10.2
Why should the control engineer be involved in the design of the process to
be controlled?
10.3
Give examples of an actuator and a sensor for the following control problems:
(a)
Attitude control of a geosynchronous communication satellite.
(b)
Pitch control of a Boeing 747 airliner.
(c)
Track-following control of a CD player.
(d)
Fuel-air ratio control of a spark-ignited automobile engine.
(e)
Position control for an arm of a robot used to paint automobiles.
(f)
Heading control of a ship.
(g)
Attitude control of a helicopter.
PROBLEMS
10.1
Of the three components of the PID controller (proportional, integral, or
derivative), which one is the most effective in reducing the error resulting
from a constant disturbance? Explain.
10.2
Is there a greater chance of instability when the sensor in a feedback con-
trol system for a mechanical structure is not collocated with the actuator?
Explain.

Problems
791
10.3
Consider the plant G(s) = 1/s3. Determine whether it is possible to stabilize
this plant by adding the lead compensator
Dc(s) = K s + a
s + b,
(a < b).
(a) What is the maximum phase margin of the resulting feedback system?
(b) Can a system with this plant, together with any number of lead
compensators, be made unconditionally stable? Explain why or why
not.
10.4
Consider the closed-loop system shown in Fig. 10.88.
(a) What is the phase margin if K = 70, 000?
(b) What is the gain margin if K = 70, 000?
(c) What value of K will yield a phase margin of ∼70◦?
(d) What value of K will yield a phase margin of ∼0◦?
(e) Sketch the root locus with respect to K for the system, and determine
what value of K causes the system to be on the verge of instability.
(f ) If the disturbance w is a constant and K = 10, 000, what is the maximum
allowable value for w if y(∞) is to remain less than 0.1? (Assume r = 0.)
(g) Suppose the speciﬁcations require you to allow larger values of w than
the value you obtained in part (f) but with the same error constraint
[|y(∞)| < 0.1]. Discuss what steps you could take to alleviate the
problem.
Figure 10.88
Control system for
Problem 10.4
s(s + 5)(s + 10)
1
©
 + 
 - 
R(s)
Y(s)
s + 100
K(s + 1)
W(s)
©
 + 
 + 
10.5
Consider the system shown in Fig. 10.89, which represents the attitude rate
control for a certain aircraft.
(a) Design a compensator so that the dominant poles are at −2 ± 2j.
(b) Sketch the Bode plot for your design, and select the compensation so
that the crossover frequency is at least 2
√
2 rad/sec and PM ≥50◦.
(c) Sketch the root locus for your design, and ﬁnd the velocity constant
when ωn > 2
√
2 and ζ ≥0.5.
Figure 10.89
Block diagram for
aircraft-attitude rate
control
©
+
-
R
Y
Compensator
Dc(s)
Hydraulic servo
s2 + 0.1s + 4
2s + 0.1
krg
s
1
Rate gyro
Aircraft

792
Chapter 10 Control System Design: Principles and Case Studies
10.6
Consider the block diagram for the servomechanism drawn in Fig. 10.90.
Which of the following claims are true?
(a) The actuator dynamics (the pole at 1000 rad/sec) must be included in
an analysis to evaluate a usable maximum gain for which the control
system is stable.
(b) The gain K must be negative for the system to be stable.
(c) There exists a value of K for which the control system will oscillate at a
frequency between 4 and 6 rad/sec.
(d) The system is unstable if |K| > 10.
(e) If K must be negative for stability, the control system cannot counteract
a positive disturbance.
(f) A positive constant disturbance will speed up the load, thereby making
the ﬁnal value of e negative.
(g) With only a positive constant command input r, the error signal e must
have a ﬁnal value greater than zero.
(h) For K = −1 the closed-loop system is stable, and the disturbance results
in a speed error whose steady-state magnitude is less than 5 rad/sec.
Figure 10.90
Servomechanism for
Problem 10.6
©
 + 
 - 
R
Amplifier
K
Actuator
Tachometer
e
Disturbance (0.1 N·m)
0.01
s + 1000
1000
s(s2 + 2s + 25)
1000
Æ (rad/sec)
©
 + 
 + 
Load
-
10.7
A stick balancer and its corresponding control block diagram are shown in
Fig. 10.91. The control is a torque applied about the pivot.
(a) Using root-locus techniques, design a compensator Dc(s) that will place
the dominant roots at s = −5 ± 5j (corresponding to ωn = 7 rad/sec,
ζ = 0.707).
(b) Use Bode plotting techniques to design a compensator Dc(s) to meet the
following speciﬁcations:
•
Steady-state θ displacement of less than 0.001 for a constant input
torque Td = 1,
•
Phase margin ≥50◦, and
•
Closed-loop bandwidth ∼= 7 rad/sec.
Figure 10.91
Servomechanism for
Problem 10.7
©
 + 
 - 
(s2 - 64)
1
Dc(s)
u
Td
Td
u

Problems
793
10.8
Consider the standard feedback system drawn in Fig. 10.92.
(a) Suppose
G(s) =
2500K
s(s + 25).
Design a lead compensator so that the phase margin of the system is
more than 45◦; the steady-state error due to a ramp should be less than
or equal to 0.01.
(b) Using the plant transfer function from part (a), design a lead compensator
so that the overshoot is less than 25% and the 1% settling time is less
than 0.1 sec.
(c) Suppose
G(s) =
K
s(s + 1 + 0.1s)(1 + 0.2s),
and let the performance speciﬁcations now be Kv = 100 and PM ⩾
40◦. Is the lead compensation effective for this system? Find a lag
compensator, and plot the root locus of the compensated system.
(d) Using G(s) from part (c), design a lag compensator such that the peak
overshoot is less than 20% and Kv = 100.
(e) Repeat part (c) using a lead-lag compensator.
(f) Find the root locus of the compensated system in part (e), and compare
your ﬁndings with those from part (c).
Figure 10.92
Block diagram of a
standard feedback
control system
G(s)
Y
©
 + 
 - 
R
Dc(s)
e
10.9
Consider the system in Fig. 10.92, where
G(s) =
300
s(s + 0.225)(s + 4)(s + 180).
The compensator Dc(s) is to be designed so that the closed-loop system
satisﬁes the following speciﬁcations:
•
Zero steady-state error for step inputs,
•
PM = 55◦, GM ≥6 db,
•
Gain crossover frequency is not smaller than that of the uncompensated
plant.
(a) What kind of compensation should be used and why?
(b) Design a suitable compensator Dc(s) to meet the speciﬁcations.
10.10
We have discussed three design methods: the root-locus method of Evans, the
frequency-response method of Bode, and the state-variable pole-assignment
method. Explain which of these methods is best described by the following
statements (if you feel more than one method ﬁts a given statement equally
well, say so and explain why):
(a) This method is the one most commonly used when the plant description
must be obtained from experimental data.

794
Chapter 10 Control System Design: Principles and Case Studies
(b) This method provides the most direct control over dynamic response
characteristics such as rise time, percent overshoot, and settling time.
(c) This method lends itself most easily to an automated (computer)
implementation.
(d) This method provides the most direct control over the steady-state error
constants Kp and Kv.
(e) This method is most likely to lead to the least complex controller capable
of meeting the dynamic and static accuracy speciﬁcations.
(f) This method allows the designer to guarantee that the ﬁnal design will
be unconditionally stable.
(g) This method can be used without modiﬁcation for plants that include
transportation lag terms—for example,
G(s) =
e−2s
(s + 3)2 .
10.11
Lead and lag networks are typically employed in designs based on frequency-
response (Bode) methods. Assuming a Type 1 system, indicate the effect
of these compensation networks on each of the listed performance spec-
iﬁcations. In each case, indicate the effect as "an increase," "substantially
unchanged," or "a decrease." Use the second-order plant G(s) = K/[s(s+1)]
to illustrate your conclusions.
(a) Kv,
(b) Phase margin,
(c) Closed-loop bandwidth,
(d) Percent overshoot, and
(e) Settling time.
10.12
Altitude Control of a Hot-Air Balloon: American solo balloonist Steve Fos-
sett landed in the Australian outback aboard Spirit of Freedom on July
3rd, 2002, becoming the ﬁrst solo balloonist to circumnavigate the globe
(see Fig. 10.93). The equations of vertical motion for a hot-air balloon
(Fig. 10.94), linearized about vertical equilibrium, are
δ ˙T + 1
τ1
δT = δq,
τ2¨z
+ ˙z =
aδT + w,
where
δT = deviation of the hot-air temperature from the equilibrium tem-
perature where buoyant force equals weight,
z = altitude of the balloon,
δq = deviation in the burner heating rate from the equilibrium rate
(normalized by the thermal capacity of the hot air),
w = vertical component of wind velocity,
τ1, τ2, a = parameters of the equations.
An altitude-hold autopilot is to be designed for a balloon whose parame-
ters are
τ1 = 250 sec
τ2 = 25 sec
a = 0.3 m/(sec ·◦C).

Problems
795
Figure 10.93
Spirit of Freedom
balloon
Source: Steve Holland/AP
Images
Figure 10.94
Hot-air balloon
Ground
w
Wind
z
Burner
flame
Hot
air

796
Chapter 10 Control System Design: Principles and Case Studies
Only altitude is sensed, so a control law of the form
δq(s) = Dc(s)[zd(s) −z(s)],
will be used, where zd is the desired (commanded) altitude.
(a) Sketch a root locus of the closed-loop eigenvalues with respect to the gain
K for a proportional feedback controller, δq = −K(z−zd). Use Routh's
criterion (or let s = jω and ﬁnd the roots of the characteristic polynomial)
to determine the value of the gain and the associated frequency at which
the system is marginally stable.
(b) Our intuition and the results of part (a) indicate that a relatively large
amount of lead compensation is required to produce a satisfactory
autopilot. Because Steve Fossett was a millionaire, he could afford a
more complex controller implementation. Sketch a root locus of the
closed-loop eigenvalues with respect to the gain K for a double-lead
compensator, δq = Dc(s)(zd −z), where
Dc(s) = K
s + 0.03
s + 0.12
2
.
(c) Sketch the magnitude portions of the Bode plots (straight-line asymp-
totes only) for the open-loop transfer functions of the proportional
feedback and lead-compensated systems.
(d) Select a gain K for the lead-compensated system to give a crossover
frequency of 0.06 rad/sec.
(e) Select a gain K for the lead-compensated system to give a crossover
frequency of 0.06 rad/sec.
(f) If the error in part (e) is too large, how would you modify the com-
pensation to give higher low-frequency gain? (Give a qualitative answer
only.)
10.13
Satellite-attitude control systems often use a reaction wheel to provide
angular motion. The equations of motion for such a system are
Satellite :
I ¨φ = Tc + Tex,
Wheel :
J˙r = −Tc,
Measurement :
˙Z = ˙φ −aZ,
Control :
Tc = −Dc(s)(Z −Zd),
where
J = moment of inertia of the wheel,
r = wheel speed,
Tc = control torque,
Tex = disturbance torque,
φ = angle to be controlled,
Z = measurement from the sensor,
Zd = reference angle,

Problems
797
I = satellite inertia (1000 kg/m2),
a = sensor constant (1 rad/sec),
Dc(s) = compensation.
(a) Suppose Dc(s) = K0, a constant. Draw the root locus with respect to
K0 for the resulting closed-loop system.
(b) For what range of K0 is the closed-loop system stable?
(c) Add a lead network with a pole at s = −1 so that the closed-loop system
has a bandwidth ωBW = 0.04 rad/sec, a damping ratio ζ = 0.5, and
compensation given by
Dc(s) = K1
s + z
s + 1.
Where should the zero of the lead network be located? Draw the root
locus of the compensated system, and give the value of K1 that allows
the speciﬁcations to be met.
(d) For what range of K1 is the system stable?
(e) What is the steady-state error (the difference between Z and some ref-
erence input Zd to a constant disturbance torque Tex for the design of
part (c)?)
(f) What is the type of this system with respect to rejection of Tex?
(g) Draw the Bode plot asymptotes of the open-loop system, with the gain
adjusted for the value of K1 computed in part (c). Add the compensation
of part (c), and compute the phase margin of the closed-loop system.
What is the type of this system with respect to rejection of Tex?
(h) Write state equations for the open-loop system, using the state vari-
ables φ, ˙φ, and Z. Select the gains of a state-feedback controller Tc =
−Kφφ −K ˙φ ˙φ to locate the closed-loop poles at s = −0.02 ± 0.02j
√
3.
10.14
Three alternative designs are sketched in Fig. 10.95 for the closed-loop con-
trol of a system with the plant transfer function G(s) = 1/s(s + 1). The
signal w is the plant noise and may be analyzed as if it were a step; the signal
v is the sensor noise and may be analyzed as if it contained power to very
high frequencies.
(a) Compute values for the parameters K1, a, K2, KT, K3, d, and KD so that
in each case (assuming w = 0 and v = 0),
Y
R =
16
s2 + 4s + 16.
Note that in system III, a pole is to be placed at s = −4.
(b) Complete the following table, expressing the last entries as A/sk to show
how fast noise from v is attenuated at high frequencies:
System
Kv
y
w

s=0
y
v

s→∞
I
II
III

798
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.95
Alternative feedback
structures for
Problem 10.14
©
 + 
 + 
r
y
s + a
s + 1
K1
s(s + 1)
1
s + d
s + 4
K3
s + d
s
KD
w
©
 + 
 + 
©
 + 
 + 
©
 - 
 + 
v
u
III:
©
 + 
 + 
r
y
s(s + 1)
1
K2
KTs
w
©
 + 
 + 
©
 + 
 + 
©
 - 
 + 
v
u
II:
©
 + 
 + 
r
y
s(s + 1)
1
w
©
 + 
 + 
©
 - 
 + 
v
u
I:
(c) Rank the three designs according to the following characteristics (the
best as "1," the poorest as "3"):
Performance
I
II
III
Tracking
Plant-noise rejection
Sensor-noise rejection
10.15
The equations of motion for a cart-stick balancer with state variables of stick
angle, stick angular velocity, and cart velocity are
˙x =
⎡
⎣
0
1
0
31.33
0
0.016
−31.33
0
−0.216
⎤
⎦x +
⎡
⎣
0
−0.649
8.649
⎤
⎦u,
y = [ 10
0
0 ]x,
where the output is stick angle, and the control input is voltage on the motor
that drives the cart wheels.

Problems
799
(a) Compute the transfer function from u to y, and determine the poles and
zeros.
(b) Determine the feedback gain K necessary to move the poles of the system
to the locations −2.832 and −0.521 ± 1.068j, with ωn = 4 rad/sec.
(c) Determine the estimator gain L needed to place the three estimator poles
at −10.
(d) Determine the transfer function of the estimated-state-feedback com-
pensator deﬁned by the gains computed in parts (b) and (c).
(e) Suppose we use a reduced-order estimator with poles at −10 and −10.
What is the required estimator gain?
(f) Repeat part (d) using the reduced-order estimator.
(g) Compute the frequency response of the two compensators.
10.16
A 282-ton Boeing 747 is approaching land at sea level. If we use the state
given in the case study (Section 10.3) and assume a velocity of 221 ft/sec
(Mach 0.198), then the lateral-direction perturbation equations are
⎡
⎢⎢⎣
˙β
˙r
˙p
˙φ
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
−0.0890
−0.989
0.1478
0.1441
0.168
−0.217
−0.166
0
−1.33
0.327
−0.975
0
0
0.149
1
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
β
r
p
φ
⎤
⎥⎥⎦+
⎡
⎢⎢⎣
0.0148
−0.151
0.0636
0
⎤
⎥⎥⎦δr,
y = [ 0
1
0
0 ]
⎡
⎢⎢⎣
β
r
p
φ
⎤
⎥⎥⎦.
The corresponding transfer function is
G(s) = r(s)
δr(s) =
−0.151(s + 1.05)(s + 0.0328 ± 0.414j)
(s + 1.109)(s + 0.0425)(s + 0.0646 ± 0.731j).
(a) Draw the uncompensated root locus [for 1 + KG(s)] and the frequency
response of the system. What type of classical controller could be used
for this system?
(b) Try a state-variable design approach by drawing a SRL for the system.
Choose the closed-loop poles of the system on the SRL to be
αc(s) = (s + 1.12)(s + 0.165)(s + 0.162 ± 0.681j),
and choose the estimator poles to be ﬁve times faster at
αe(s) = (s + 5.58)(s + 0.825)(s + 0.812 ± 3.40j).
(c) Compute the transfer function of the SRL compensator.
(d) Discuss the robustness properties of the system with respect to parameter
variations and unmodeled dynamics.
(e) Note the similarity of this design to the one developed for different ﬂight
conditions earlier in the chapter. What does this suggest about providing
a continuous (nonlinear) control throughout the operating envelope?
10.17
(Contributed by Prof. L. Swindlehurst) The feedback control system shown
in Fig. 10.96 is proposed as a position control system. A key component

800
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.96
A servomechanism with
gears on the motor
shaft and
potentiometer sensors
©
 + 
 - 
Dc
ya
Compensator
Motor
Output
potentiometer
Input
potentiometer
ui
uo
km
Jm
Gears
JL
Eo
Eb
Eb
E
Ei
Ei = voltage from input potentiometer
= Kpui
Eo = voltage from output potentiometer
= Kpuo
E = Ei - Eo = error voltage = Kp(ui - uo)
ya = armature voltage applied to motor
Eb = battery voltage applied the potentiometers
of this system is an armature-controlled DC motor. The input potentiome-
ter produces a voltage Ei that is proportional to the desired shaft position:
Ei = Kpθi. Similarly, the output potentiometer produces a voltage E0 that
is proportional to the actual shaft position: E0 = Kpθ0. Note that we have
assumed that both potentiometers have the same proportionality constant.
The error signal Ei −E0 drives a compensator, which in turn produces an
armature voltage that drives the motor. The motor has an armature resistance
Ra, an armature inductance La, a torque constant Kt, and a back emf con-
stant Ke. The moment of inertia of the motor shaft is Jm, and the rotational
damping due to bearing friction is Bm. Finally, the gear ratio is N : 1, the
moment of inertia of the load is JL, and the load damping is BL.
(a) Write the differential equations that describe the operation of this
feedback system.
(b) Find the transfer function relating θ0 and θi(s) for a general compensator
Dc(s).
(c) The open-loop frequency-response data shown in Table 10.2 were taken
using the armature voltage va of the motor as an input and the output
potentiometer voltage E0 as the output.Assuming that the motor is linear
and minimum-phase, make an estimate of the transfer function of the
motor,
G(s) = θm(s)
Va(s),
where θm is the angular position of the motor shaft.
(d) Determine a set of performance speciﬁcations that are appropriate for a
position control system and will yield good performance. Design Dc(s)
to meet these speciﬁcations.
(e) Verify your design through analysis and simulation using Matlab.
10.18
Design and construct a device to keep a ball centered on a freely swinging
beam. An example of such a device is shown in Fig. 10.97. It uses coils
surrounding permanent magnets as the actuator to move the beam, solar cells
to sense the ball position, and a hall-effect device to sense the beam position.
Research other possible actuators and sensors as part of your design effort.

Problems
801
TABLE 10.2
Frequency-Response Data for Problem 10.17
Frequency

E0(s)
Va(s)
 (db)
Frequency

E0(s)
Va(s)
 (db)
(rad/sec)
(rad/sec)
0.1
60.0
10.0
14.0
0.2
54.0
20.0
2.0
0.3
50.0
40.0
−10.0
0.5
46.0
60.0
−20.0
0.8
42.0
65.0
−21.0
1.0
40.0
80.0
−24.0
2.0
34.0
100.0
−30.0
3.0
30.5
200.0
−48.0
4.0
27.0
300.0
−59.0
5.0
23.0
500.0
−72.0
7.0
19.5
Figure 10.97
Ball-balancer design
example
Source: Photo courtesy of
David Powell
Compare the quality of the control achievable for ball-position feedback only
with that of multiple-loop feedback of both ball and beam position.
10.19
Design and construct the magnetic levitation device shown in Fig. 9.2. You
may wish to use LEGO components in your design.
10.20
Design and build a Sun tracker using an Arduino board and related software.
10.21
Run-to-Run Control: Consider the RTP system shown in Fig. 10.98. We wish
to heat up a semiconductor wafer, and control the wafer surface temperature
accurately using rings of tungsten halogen lamps. The output of the system
is temperature T as a function of time: y = T(t). The system reference input
R is a desired step in temperature (700◦C), and the control input is lamp
power. A pyrometer is used to measure the wafer center temperature. The
model of the system is ﬁrst order, and an integral controller is used as shown
in Fig. 10.98. Normally, there is no sensor bias (b = 0).

802
Chapter 10 Control System Design: Principles and Case Studies
Figure 10.98
RTP system
©
 + 
 - 
©
 + 
 + 
R
y = T
b
s
K
s + a
A
Metrology
Ox
(a) Suppose the system suddenly develops a sensor bias b ̸= 0, where b
is known. What can be done to ensure zero steady-state tracking of
temperature command R, despite the presence of the sensor bias?
(b) Now assume b = 0. In reality, we are trying to control the thickness
of the oxide ﬁlm grown (Ox) on the wafer and not the temperature.
At present, no sensor can measure Ox in real time. The semiconductor
process engineer must use off-line equipment (called metrology) to mea-
sure the thickness of the oxide ﬁlm grown on the wafer. The relationship
between the system output temperature and Ox is nonlinear and given
by the integral of the Arrhenius equation:
Oxide thickness =
tf

0
pe−
c
T(t) dt,
where tf is the process duration, and p and c are known constants. Sug-
gest a scheme in which the center wafer oxide thickness Ox can be
controlled to a desired value (say, Ox = 5000 Å) by employing the
temperature controller and the output of the metrology.
10.22
Develop a nonlinear model for a tungsten halogen lamp and simulate it in
Simulink.
10.23
Develop a nonlinear model for a pyrometer. Show how temperature can be
deduced from the model.
10.24
Repeat the RTP case study design by summing the three sensors to form
a single signal to control the average temperature. Demonstrate the perfor-
mance of the linear design, and validate the performance on the nonlinear
Simulink simulation.
10.25
One of the steps in semiconductor wafer manufacturing during photolithog-
raphy is performed by placement of the wafer on a heated plate for a certain
period of time. Laboratory experiments have shown that the transfer function
from the heater power, u, to the wafer temperature, y, is given by
y(s)
u(s) = G(s) =
0.09
(s + 0.19)(s + 0.78)(s + 0.00018).
(a) Sketch the 180◦root locus for the uncompensated system.
(b) Using the root-locus design techniques, design a dynamic compen-
sator, Dc(s), such that the system meets the following time-domain
speciﬁcations
i. Mp ≤5%,
ii. tr ≤20 sec,

Problems
803
iii. ts ≤60 sec,
iv. Steady-state error to a 1◦C step input command < 0.1◦C.
Draw the 180◦root locus for the compensated system.
10.26
Excitation-Inhibition Model from Systems Biology (Yang and Iglesias, 2005):
In Dictyostelium cells, the activation of key signaling molecules involved
in chemoattractant sensing can be modeled by the following third order
linearized model. The external disturbance to the output transfer function is:
y(s)
w(s) = S(s) =
(1 −α)s
(s + α)(s + 1)(s + γ ),
where, w is the external disturbance signal proportional to chemoattractant
concentration, and y is the output which is the fraction of active response
regulators. Show that there is an alternate representation of the system with
the "plant" transfer function
G(s) =
(1 −α)
s2 + (1 + α + γ )s + (α + γ + αγ ),
and the "feedback regulator"
Dc(s) =
αγ
(1 −α)s.
It is known that α ̸= 1 for this version of the model. Draw the feedback
block diagram of the system showing the locations of the disturbance input
and the output. What is the signiﬁcance of this particular representation of
the system? What hidden system property does it reveal? Is the disturbance
rejection a robust property for this system? Assume the system parameter
values are α = 0.5 and γ = 0.2, then plot the disturbance rejection response
of the system for a unit step disturbance input.

AppendixA
Laplace Transforms
A.1
The L−Laplace Transform
Laplace transforms can be used to study the complete response characteris-
tics of feedback systems, including the transient response. This is in contrast
to Fourier transforms, in which the steady-state response is the main con-
cern. In many applications it is useful to deﬁne the Laplace transform of
f (t), denoted by L−{ f (t)} = F(s), as a function of the complex variable
s = σ1 + jω, where
F(s) ≜
 ∞
0−f (t)e−st dt,
(A.1)
which uses 0−(that is, a value just before t = 0) as the lower limit of integra-
tion and is referred to as the unilateral (or one-sided) Laplace transform.1
A function f (t) will have a Laplace transform if it is of exponential order,
which means that there exists a real number σ1 such that
lim
t→∞| f (t)e−σ1t| = 0.
(A.2)
The decaying exponential term in the integrand in effect provides a built-in
convergence factor. This means that even if f (t) does not vanish as t →∞,
the integrand will vanish for sufﬁciently large values of σ1 if f does not grow
at a faster than exponential rate. For example, aebt is of exponential order,
whereas et2 is not. If F(s) exists for some s0 = σ0 + jω0, then it exists for
all values of s such that
Re(s) ≥σ0.
(A.3)
The smallest value of σ0 for which F(s) exists is called the abscissa of
convergence, and the region to the right of Re(s) ≥σ0 is called the region
ofconvergence. Typically, two-sidedLaplacetransformsexistforaspeciﬁed
range
α < Re(s) < β,
(A.4)
which deﬁnes the strip of convergence. Table A.2 gives some Laplace trans-
form pairs. Each entry in the table follows from direct application of the
transform deﬁnition.2
1Bilateral (or two-sided) Laplace transforms and the so-called L+ transforms, in which the
lower value of integral is 0+, also arise elsewhere.
2As for the one-sided Laplace transform, an astute reader would wonder what happens to
the validity of the Laplace transform for the rest of the s-plane, namely, the region where
Re(s) < σ0. Indeed it would be disappointing if F(s) was only valid for Re(s) ≥σ0 and not
elsewhere in the s-plane. Fortunately, except for some pathological cases (which do not arise
in practice), one can invoke an important result from the theory of complex variables known as
the Analytic Continuation Theorem to extend the region of the validity of F(s) to the whole
s-plane excluding the locations of the poles.
804

A.1 The L−Laplace Transform
805
A.1.1
Properties of Laplace Transforms
In this section we will address and prove each of the signiﬁcant properties
of the Laplace transform as discussed in Chapter 3 and listed in Table A.1.
In addition we show how these properties can be used through examples.
1. Superposition
One of the more important properties of the Laplace transform is that it is
linear. We can prove this as follows:
L{αf1(t) + βf2(t)} =
 ∞
0
[αf1(t) + βf2(t)]e−st dt
(A.5)
= α
 ∞
0
f1(t)e−st dt + β
 ∞
0
f2(t)e−st dt
= αF1(s) + βF2(s).
The scaling property is a special case of linearity; that is,
L{αf (t)} = αF(s).
(A.6)
TABLE A.1
Properties of Laplace Transforms
Number
Laplace Transform
Time Function
Comment
—
F(s)
f (t)
Transform pair
1
αF1(s) + βF2(s)
αf1(t) + βf2(t)
Superposition
2
F(s)e−sλ
f (t −λ)
Time delay (λ ≥0)
3
1
|a|F
 s
a

f (at)
Time scaling
4
F(s + a)
e−atf (t)
Shift in frequency
5
smF(s) −sm−1f (0)
−sm−2˙f (0) −· · · −f (m−1)(0)
f (m)(t)
Differentiation
6
1
s F(s)
 t
0
f (ζ) dζ
Integration
7
F1(s)F2(s)
f1(t) ∗f2(t)
Convolution
8
lim
s→∞sF(s)
f (0+)
Initial Value Theorem
9
lim
s→0 sF(s)
lim
t→∞f (t)
Final Value Theorem
10
1
2πj
 σc+j∞
σc−j∞
F1(ζ)F2(s −ζ)dζ
f1(t)f2(t)
Time product
11
1
2π
 +j∞
−j∞
Y(−jω)U(jω) dω
 ∞
0
y(t)u(t) dt
Parseval's Theorem
12
−d
ds F(s)
tf (t)
Multiplication by time

806
Appendix A Laplace Transforms
TABLE A.2
Table of Laplace Transforms
Number
F(s)
f(t), t ≥0
1
1
δ(t)
2
1/s
1(t)
3
1/s2
t
4
2!/s3
t2
5
3!/s4
t3
6
m!/sm+1
tm
7
1
s + a
e−at
8
1
(s + a)2
te−at
9
1
(s + a)3
1
2! t2e−at
10
1
(s + a)m
1
(m −1)! tm−1e−at
11
a
s(s + a)
1 −e−at
12
a
s2(s + a)
1
a (at −1 + e−at)
13
b −a
(s + a)(s + b)
e−at −e−bt
14
s
(s + a)2
(1 −at)e−at
15
a2
s(s + a)2
1 −e−at(1 + at)
16
(b −a)s
(s + a)(s + b)
be−bt −ae−at
17
a
s2 + a2
sin at
18
s
s2 + a2
cos at
19
s + a
(s + a)2 + b2
e−at cos bt
20
b
(s + a)2 + b2
e−at sin bt
21
a2 + b2
s[(s + a)2 + b2]
1 −e−at 
cos bt + a
b sin bt

EXAMPLE A.1
Sinusoidal Signal
Find the Laplace transform of f (t) = 1 + 2 sin(ωt).
Solution. The Laplace transform of sin(ωt) is
L{sin(ωt)} =
ω
s2 + ω2 .

A.1 The L−Laplace Transform
807
Therefore, using Eq. (A.5) we obtain
F(s) = 1
s +
2ω
s2 + ω2 = s2 + 2ωs + ω2
s3 + ω2s
.
The following commands in Matlab yields the same result,
syms s t w
laplace(1+2*sin(w*t)).
2. Time Delay
Suppose a function f (t) is delayed by λ > 0 units of time. Its Laplace
transform is
F1(s) =
 ∞
0
f (t −λ)e−st dt.
Let us deﬁne t′ = t −λ. Then dt′ = dt, because λ is a constant and f (t) = 0
for t < 0. Thus
F1(s) =
 ∞
−λ
f (t′)e−s(t′+λ) dt′ =
 ∞
0
f (t′)e−s(t′+λ) dt′.
Because e−sλ is independent of time, it can be taken out of the integrand, so
F1(s) = e−sλ
 ∞
0
f (t′)e−st′ dt′ = e−sλF(s).
(A.7)
From this result we see that a time delay of λ corresponds to multiplication
of the transform by e−sλ.
EXAMPLE A.2
Delayed Sinusoidal Signal
Find the Laplace transform of f (t) = A sin(t −td).
Solution. The Laplace transform of sin(t) is
L{sin(t)} =
1
s2 + 1.
Therefore, using Eq. (A.7) we obtain
F(s) =
A
s2 + 1 e−std.
3. Time Scaling
If the time t is scaled by a factor a, then the Laplace transform of the time-
scaled signal is
F1(s) =
 ∞
0
f (at)e−stdt.

808
Appendix A Laplace Transforms
Again, we deﬁne t′ = at. As before, dt′ = a dt and
F1(s) =
 ∞
0
f (t′)e−st′/a
|a|
dt′ = 1
|a|F
 s
a

.
(A.8)
EXAMPLE A.3
Sinusoid with Frequency ω
Find the Laplace transform of f (t) = A sin(ωt).
Solution. The Laplace transform of sin(t) is
L{sin(t)} =
1
s2 + 1.
Therefore, using Eq. (A.8) we obtain
F(s) = 1
|ω|
1
 sω
2 + 1
=
Aω
s2 + ω2 ,
as expected. The following commands in Matlab yields the same result,
syms s t w A
laplace(A*sin(w*t)).
4. Shift in Frequency
Multiplication (modulation) of f (t) by an exponential expression in the time
domain corresponds to a shift in frequency:
F1(s) =
 ∞
0
e−atf (t)e−st dt =
 ∞
0
f (t)e−(s + a)t dt = F(s + a).
(A.9)
EXAMPLE A.4
Exponentially Decaying Sinusoid
Find the Laplace transform of f (t) = A sin(ωt)e−at.
Solution. The Laplace transform of sin(ωt) is
L{sin(ωt)} =
ω
s2 + ω2 .
Therefore, using Eq. (A.9) we obtain
F(s) =
Aω
(s + a)2 + ω2 .

A.1 The L−Laplace Transform
809
5. Differentiation
The transform of the derivative of a signal is related to its Laplace transform
and its initial condition as follows:
L
df
dt
	
=
 ∞
0−

df
dt

e−st dt = e−stf (t)
∞
0−+ s
 ∞
0−f (t)e−st dt. (A.10)
Because f (t) is assumed to have a Laplace transform, e−stf (t) →0 as
t →∞. Thus
L[ ˙f ] = −f (0−) + sF(s).
(A.11)
Another application of Eq. (A.11) leads to
L{ ¨f } = s2F(s) −sf (0−) −˙f (0−).
(A.12)
Repeated application of Eq. (A.11) leads to
L{ f m(t)} = smF(s)−sm−1f (0−)−sm−2˙f (0−)−· · ·−f (m−1)(0−), (A.13)
where f m(t) denotes the mth derivative of f (t) with respect to time.
EXAMPLE A.5
Derivative of Cosine Signal
Find the Laplace transform of g(t) = d
dt f (t), where f (t) = cos(ωt).
Solution. The Laplace transform of cos(ωt) is
F(s) = L{cos(ωt)} =
s
s2 + ω2 .
Using Eq. (A.11) with f (0−) = 1, we have
G(s) = L{g(t)} = s ·
s
s2 + ω2 −1 = −
ω2
s2 + ω2 .
6. Integration
Let us assume that we wish to determine the Laplace transform of the integral
of a time function—that is, to ﬁnd
F1(s) = L
 t
0
f (ξ) dξ
	
=
 ∞
0
 t
0
f (ξ) dξ

e−st dt.
Employing integration by parts, where
u =
 t
0
f (ξ) dξ
and
dν = e−st dt,
we get
F1(s) =

−1
s e−st

 t
0
f (ξ) dξ
∞
0
−
 ∞
0
−1
s e−stf (t) dt = 1
s F(s).
(A.14)

810
Appendix A Laplace Transforms
EXAMPLE A.6
Time Integral of Sinusoidal Signal
Find the Laplace transform of f (t) =
 t
0 sin ωτ dτ.
Solution. The Laplace transform of sin(ωt) is
L{sin(ωt)} =
ω
s2 + ω2 .
Therefore, using Eq. (A.14), then
F(s) =
ω
s3 + ω2s.
7. Convolution
Convolution in the time domain corresponds to multiplication in the fre-
quency domain. Assume that L{ f1(t)} = F1(s) and L{ f2(t)} = F2(s).
Then
L{ f1(t) ∗f2(t)} =
 ∞
0
f1(t) ∗f2(t)e−st dt
=
 ∞
0
 t
0
f1(τ)f2(t −τ) dτ

e−st dt.
We see that t varies from zero to inﬁnity and τ varies from zero to t. With the
aid of Fig. A.1, we reverse the order of integration and change the limits of
integration accordingly so that τ varies from zero to inﬁnity and ∞⩾t ⩾τ,
to yield
L{ f1(t) ∗f2(t)} =
 ∞
0
 ∞
τ
f1(τ)f2(t −τ)e−st dt dτ.
Multiplying by e−sτesτ results in
L{ f1(t) ∗f2(t)} =
 ∞
0
f1(τ)e−sτ
 ∞
τ
f2(t −τ)e−s(t−τ) dt

dτ.
If we change variables t′ ≜t −τ, then
L{ f1(t) ∗f2(t)} =
 ∞
0
f1(τ)e−st dτ
 ∞
0
f2(t′)e−st′ dt′,
L{ f1(t) ∗f2(t)} = F1(s)F2(s).
Figure A.1
Diagram illustrating
reversal of the order of
integration
0
t
t = v
v
v

A.1 The L−Laplace Transform
811
This implies that
L−1{ F1(s)F2(s)} = f1(t) ∗f2(t).
(A.15)
EXAMPLE A.7
Ramp Response of a First-Order System
Find the ramp response of a ﬁrst-order system with a pole at +a.
Solution. Let f1(t) = t be the ramp input and f2(t) = eat be the impulse
response of the ﬁrst-order system. Then, using Eq. (A.15) we ﬁnd that
L−1
 1
s2
1
s −a
	
= f1(t) ∗f2(t)
=
 t
0
f1(τ)f2(t −τ) dτ
=
 t
0
τea(t−τ) dτ
= 1
a2 (eat −at −1).
The following commands in Matlab yields the same result,
syms s t a
ilaplace(1/(sˆ3-a*sˆ2)).
8. Time Product
Multiplication in the time domain corresponds to convolution in the
frequency domain:
L{ f1(t)f2(t)} =
1
2πj
 σc+j∞
σc−j∞
F1(ξ)F2(s −ξ) dξ.
To see this, consider the relation
L{ f1(t)f2(t)} =
 ∞
0
f1(t)f2(t)e−st dt.
Substituting the expression for f1(t) given by Eq. (3.33) yields
L{ f1(t)f2(t)} =
 ∞
0
 1
2πj
 σc+j∞
σc−j∞
F1(ξ)eξt dξ

f2(t)e−st dt.
Changing the order of integration results in
L{ f1(t)f2(t)} =
1
2πj
 σc+j∞
σc−j∞
F1(ξ)
 ∞
0
f2(t)e−(s−ξ)t dt dξ.
Using Eq. (A.9), we get
L{ f1(t)f2(t)} =
1
2πj
 σc+j∞
σc−j∞
F1(ξ)F2(s −ξ) dξ =
1
2πjF1(s) ∗F2(s).
(A.16)

812
Appendix A Laplace Transforms
9. Parseval's Theorem
Parseval's famous theorem is used to compute the "energy" in a signal or
"correlation" between two signals. It tells us that mentioned quantities can
be computed either in the time domain or in the frequency domain. If
 ∞
0
|y(t)|2dt < 1
and
 ∞
0
|u(t)|2 dt < 1
(A.17)
(i.e., y(t) and u(t) are square integrable), then
 ∞
0
y(t)u(t)dt = 1
2π
 ∞
−∞
Y(−jω)U(jω) dω.
(A.18)
Parseval's result involves only a substitution of the transform for the time
functions and an exchange of integration:
 ∞
0
y(t)u(t) dt =
 ∞
0
y(t)
 1
2π
 ∞
−∞
U(jω)e jωt dω

dt
(A.19)
= 1
2π
 ∞
−∞
U(jω)
 ∞
0
y(t)e jωt dt

dω
(A.20)
= 1
2π
 ∞
−∞
U(jω)Y(−jω) dω.
(A.21)
10. Multiplication by Time
Multiplication by time corresponds to differentiation in the frequency
domain. Let us consider
d
dsF(s) = d
ds
 ∞
0
e−stf (t) dt
=
 ∞
0
−te−stf (t) dt
= −
 ∞
0
e−st[tf (t)] dt
= −L{tf (t)}.
Then
L{tf (t)} = −d
dsF(s),
(A.22)
which is the desired result.
EXAMPLE A.8
Time Product of Sinusoidal Signal
Find the Laplace transform of f (t) = t sin ωt.
Solution. The Laplace transform of sin ωt is
L{sin(ωt)} =
ω
s2 + ω2 .
Hence, using Eq. (A.22), we obtain
F(s) = −d
ds

ω
s2 + ω2

=
2ωs
(s2 + ω2)2 .

A.1 The L−Laplace Transform
813
The following commands in Matlab yields the same result,
syms s t w
laplace(t*sin(w*t)).
A.1.2
Inverse Laplace Transform by Partial-Fraction
Expansion
AswesawinChapter3, theeasiestwaytoﬁndf (t)fromitsLaplacetransform
F(s), if F(s) is rational, is to expand F(s) as a sum of simpler terms that
can be found in the tables via partial-fraction expansion. We have already
discussed this method in connection with simple roots in Section 3.1.5. In
this section, we discuss partial-fraction expansion for cases of complex and
repeated roots.
Complex Poles In the case of quadratic factors in the denominator, the
numerator of the quadratic factor is chosen to be ﬁrst order as shown in
Example A.9. Whenever there exists a complex conjugate pair of poles such
as
F(s) =
C1
s −p1
+
C2
s −p∗
1
,
we can show that
C2 = C∗
1
(see Problem 3.1) and that
f (t) = C1ep1t + C∗
1ep∗t
1 = 2Re(C1ep1t).
Assuming that p1 = α + jβ, we may rewrite f (t) in a more compact form as
f (t) = 2Re{C1ep1t} = 2Re{|C1|e j arg(C1)e(α+jβ)t}
(A.23)
= 2|C1|eαt cos[βt + arg(C1)].
EXAMPLE A.9
Partial-Fraction Expansion: Distinct Complex Roots
Find the function f (t) for which the Laplace transform is
F(s) =
1
s(s2 + s + 1).
Solution. We rewrite F(s) as
F(s) = C1
s + C2s + C3
s2 + s + 1.
Using the cover-up method, we ﬁnd that
C1 = sF(s)|s=0 = 1.
Setting C1 = 1 and then equating the numerators in the partial-fraction
expansion relation, we obtain
(s2 + s + 1) + (C2s + C3)s = 1.

814
Appendix A Laplace Transforms
After solving for C2 and C3, we ﬁnd that C2 = −1 and C3 = −1. To make it
more suitable for using the Laplace transform tables, we rewrite the partial
fraction as
F(s) = 1
s −
s + 1
2 + 1
2

s + 1
2
2
+ 3
4
.
From the tables we have,
f (t) =

1 −e−t/2 cos

3
4 t −1
√
3
e−t/2 sin

3
4 t

1(t)
=

1 −2
√
3
e−t/2 cos
√
3
2 t −π
6

1(t).
Alternatively, we may write F(s) as
F(s) = C1
s +
C2
s −p1
+
C∗
2
s −p∗
1
,
(A.24)
where p1 = −1
2 + j
√
3
2 . C1 = 1, as before, and now
C2 = (s −p1)F(s)|s=p1 = −1
2 + j
1
2
√
3
,
C∗
2 = −1
2 −j
1
2
√
3
,
and
f (t) = (1 + 2|C2|eαt cos[βt + arg(C2)])1(t)
=

1 + 2
√
3
e−t/2 cos
√
3
2 t + 5π
6

1(t)
=

1 −2
√
3
e−t/2 cos
√
3
2 t −5π
6

1(t).
The latter partial-fraction expansion can be readily computed using the
Matlab statements
num = 1;
% form numerator
den = conv([1 0],[1 1 1]);
% form denominator
[r,p,k] = residue(num,den)
% compute residues
which yields the result
r = [−0.5000 + 0.2887i −0.5000 −0.2887i 1.0000]′;
p = [−0.5000 + 0.8660i −0.5000 −0.8660i 0]′; k = []

A.1 The L−Laplace Transform
815
and agrees with the previous hand calculations. Note that if we are using the
tables, the ﬁrst method is preferable, while the second method is preferable
for checking Matlab results.
The following commands in Matlab yields the same result for the inverse
Laplace transform,
syms s t
ilaplace(1/(s*(sˆ2+s+1))).
Repeated Poles
For the case in which F(s) has repeated roots, the
procedure to compute the partial-fraction expansion must be modiﬁed. If p1
is repeated three times, we write the partial fraction as
F(s) =
C1
s −p1
+
C2
(s −p1)2 +
C3
(s −p1)3 +
C4
s −p4
+ · · · +
Cn
s −pn
.
We determine the constants C4 through Cn as discussed previously. If we
multiply both sides of the preceding equation by (s −p1)3, we obtain
(s−p1)3F(s) = C1(s−p1)2+C2(s−p1)+C3+· · ·+ Cn(s −p1)3
s −pn
. (A.25)
If we then set s = p1, all the factors on the right side of Eq. (A.25) will go
to zero except C3, which is
C3 = (s −p1)3F(s)|s=p1,
as before. To determine the other factors, we differentiate Eq. (A.25) with
respect to the Laplace variable s:
d
ds[(s−p1)3F(s)] = 2C1(s−p1)+C2 +· · ·+ d
ds
Cn(s −p1)3
s −pn

. (A.26)
Again, if we set s = p1, we have
C2 = d
ds [(s −p1)3F(s)]s=p1.
Similarly, if we differentiate Eq. (A.26) again and set s = p1 a second time,
we get
C1 = 1
2
d2
ds2 [(s −p1)3F(s)]s=p1.
In general, we may compute Ci for a factor with multiplicity k as
Ck−i = 1
i!
 di
dsi [(s −p1)kF(s)]

s=p1
, i = 0, . . . , k −1.
EXAMPLE A.10
Partial-Fraction Expansion: Repeated Real Roots
Find the function f (t) that has the Laplace transform
F(s) =
s + 3
(s + 1)(s + 2)2 .

816
Appendix A Laplace Transforms
Solution. We write the partial fraction as
F(s) =
C1
s + 1 +
C2
s + 2 +
C3
(s + 2)2 .
Then
C1 = (s + 1)F(s)|s=−1 =
s + 3
(s + 2)2

s=−1 = 2,
C2 = d
ds

(s + 2)2F(s)
 
s=−2 = −2,
C3 = (s + 2)2F(s)|s=−2 = s + 3
s + 1

s=−2 = −1.
The function f (t) is
f (t) = (2e−t −2e−2t −te−2t)1(t).
The partial fraction computation can also be carried out using Matlab's
residue function,
num = [1 3];
% form numerator
den = conv([1 1],[1 4 4]);
% form denominator
[r,p,k] = residue(num,den)
% compute residues
which yields the result
r = [−2 −1 2]', p = [−2 −2 −1]', and k = [ ];
and agrees with the hand calculations.
The following commands in Matlab yields the same result for the inverse
Laplace transform,
syms s t
ilaplace((s+3)/((s+1)*(s+2)ˆ2)).
A.1.3
The Initial Value Theorem
We discussed the Final Value Theorem in Chapter 3. A second valuable
Laplace transform theorem is the Initial Value Theorem, which states that
it is always possible to determine the initial value of the time function f (t)
from its Laplace transform. We may also state the theorem in this way:
The Initial Value Theorem
For any Laplace transform pair,
lim
s→∞sF(s) = f (0+).
(A.27)
We may show this as follows.
Using Eq. (A.11), we get
L
df
dt
	
= sF(s) −f (0−) =
 ∞
0−e−st df
dt dt.
(A.28)

A.1 The L−Laplace Transform
817
Let us consider the case in which s →∞and rewrite the integral as
 ∞
0−e−st df (t)
dt
dt =
 ∞
0+ e−st df (t)
dt
dt +
 0+
0−e−st df (t)
dt
dt.
Taking the limit of Eq. (A.28) as s →∞, we get
lim
s→∞[sF(s) −f (0−)] = lim
s→∞
 0+
0−e0 df (t)
dt
dt +
 ∞
0+ e−st df (t)
dt
dt

.
The second term on the right side of the preceding equation approaches
zero as s →∞, because e−st →0. Hence
lim
s→∞[sF(s) −f (0−)] = lim
s→∞[f (0+) −f (0−)] = f (0+) −f (0−)
or
lim
s→∞sF(s) = f (0+).
In contrast with the Final Value Theorem, the Initial Value Theorem can be
applied to any function F(s).
EXAMPLE A.11
Initial Value Theorem
Find the initial value of the signal in Example 3.13.
Solution. From the Initial Value Theorem, we get
y(0+) = lim
s→∞sY(s) = lim
s→∞s
3
s(s −2) = 0,
which checks with the expression for y(t) computed in Example 3.13.
A.1.4
Final Value Theorem
The Final Value Theorem
If all poles of sY(s) are in the left half of the s-plane, then
lim
t→∞y(t) = lim
s→0 sY(s).
(3.54)
Proof of the Final Value Theorem
We may prove this result as follows. The derivative relationship developed
in Eq. (3.41) is
L
dy
dt
	
= sY(s) −y(0−) =
 ∞
0−e−st dy
dt dt.
We assume we are interested in the case where s →0. Then
lim
s→0 [sY(s) −y(0)] = lim
s→0

 ∞
0
e−st dy
dt dt

= lim
t→∞[y(t) −y(0)],

818
Appendix A Laplace Transforms
and we have
lim
t→∞y(t) = lim
s→0 sY(s).
Another way to see this same result is to note that the partial-fraction
expansion of Y(s) [Eq. (3.51)] is
Y(s) =
C1
s −p1
+
C2
s −p2
+ · · · +
Cn
s −pn
.
Let us say that p1 = 0 and all other pi are in the left half-plane so that C1 is
the steady-state value of y(t). Using Eq. (3.53), we see that
C1 = lim
t→∞y(t) = sY(s)|s=0,
which is the same as the previous result.
For a thorough study of Laplace transforms and extensive tables,
see Churchill (1972) and Campbell and Foster (1948); for the two-sided
transform, see Van der Pol and Bremmer (1955).

Appendix B
Solutions to
the Review Questions
Chapter 1
1.1 What are the main components of a feedback control system?
The process, the actuator, the sensor, and the controller.
1.2 What is the purpose of the sensor?
To measure the output variable and, usually, to convert it to an
electrical voltage.
1.3 Give three important properties of a good sensor.
A good sensor is linear (the output is proportional to the input signal)
over a large range of amplitudes and a large range of frequencies at
its input, has low noise, is unbiased, is easy to calibrate, and has low
cost. The relative values of these properties varies with the particular
application.
1.4 What is the purpose of the actuator?
The actuator takes an input, usually electrical, and converts it to a
signal such as a force or torque that causes the process output to move
or change over the required range.
1.5 Give three important properties of a good actuator.
A good actuator has fast response, and adequate power, energy, speed,
torque, and so on, to be able to cause the process output to meet the
design speciﬁcations and is efﬁcient, lightweight, small, cheap, and so
on. As with sensors, the relative value of these properties varies with
the application.
1.6 What is the purpose of the controller? Give the input(s) and output(s)
of the controller.
The controller is to take the sensor output (the input to the controller)
and compute the control signal (the output of the controller) to be sent
to the actuator.
1.7 What physical variable is measured by a tachometer?
A tachometer measures speed of rotation or angular velocity.
1.8 Describe three different techniques for measuring temperature.
In each of the following cases, it is important to realize that the devices
mentioned need to be calibrated and often corrected for nonlinearity
in order to give a reliable, accurate measure of temperature.
819

820
Appendix B Solutions to the Review Questions
(a) An early technique still used in many home thermostats is based on
the bimetallic strip composed of two strips of different metals that
expand with different coefﬁcients with temperature. As a result, the
strip bends with temperature and the resulting motion can be used
as a measure of temperature. This principle was introduced in the
18th century to maintain a constant length to a clock pendulum
for precision time keeping.
(b) A technique related to the bimetallic strip is based on the fact that
metals with different work functions placed in contact will produce
a voltage that is proportional to temperature. Such a device is
called a thermocouple and is the basis of a standard laboratory
technique for measuring temperature.
(c) A number of materials have electrical resistance that is dependent
in a monotonic way on temperature, and a resistance bridge can
be used with one of these to indicate temperature. Such devices
are called thermistors.
(d) For high temperatures, it is well known that the color of the radi-
ation due to heat depends on temperature. A piece of iron placed
in a ﬁre will glow orange, then red, and ﬁnally become white hot
at high temperatures. An instrument for measuring the frequency
of the radiation, and thus the temperature, is a pyrometer.
(e) In ceramic kilns, cones of different materials that melt at different
and known temperatures are placed near the products in the kiln
to indicate when the design temperature has been reached. The
potter watches until the cone of importance begins to sag and then
knows that the products should be removed. These give a quantized
measure of temperature.
1.9 Why do most sensors have an electrical output, regardless of the
physical nature of the variable being measured?
Electricalsignalsarethemosteasilymanipulated; therefore, mostcon-
trollers are electrical devices, either analog or digital. To provide the
signal input to such a device, the sensor needs to produce an electrical
output.
Chapter 2
2.1 What is a "free-body" diagram?
To write the equations of motion of a system of connected bodies, it is
useful to draw each body in turn with the inﬂuence of all other bodies
represented by forces and torques on the body in question. A drawing of
the collection of such isolated bodies is called a "free-body diagram."
2.2 What are the two forms of Newton's law?
Translational motion is described by F = ma. Rotational motion is
described by M = Iα.

Appendix B Solutions to the Review Questions
821
2.3 For a structural process to be controlled, such as a robot arm, what is
the meaning of "collocated control"? "Noncollocated control"?
When the actuator and the sensor are located on the same rigid body,
the control is said to be "collocated." When they are on different bodies
that are connected by springs, the control is "noncollocated."
2.4 State Kirchhoff's current law.
The algebraic sum of all currents entering a junction or circuit is zero.
2.5 State Kirchhoff's voltage law.
The algebraic sum of voltages around a closed path in an electric
circuit is zero.
2.6 When, why, and by whom was the device named an "operational
ampliﬁer"?
In a paper in 1947, Ragazzini, Randall, and Russell named the high-
gain, wide-bandwidth ampliﬁer used in feedback to realize operational
calculus "operations" the operational ampliﬁer.
2.7 What is the major beneﬁt of having zero input current to an operational
ampliﬁer?
With zero input current the ampliﬁer does not load the input circuit;
thus, thetransferfunctiononthedeviceisnotdependentontheampliﬁer
characteristics. Also, theanalysisofthecircuitissimpliﬁedinthiscase.
2.8 Why is it important to have a small value for the armature resistance
Ra of an electric motor?
The armature resistance causes power loss when the armature current
ﬂows and thus reduces the efﬁciency of the motor.
2.9 What are the deﬁnition and units of the electric constant of a motor?
A rotating motor produces a voltage (called the back emf) in its arma-
ture proportional to the rotational speed. The electric constant Ke is
the ratio of this voltage to the speed, so that e = Ke ˙θ. The units are
volt-sec/radians.
2.10 What are the deﬁnition and units of the torque constant of an electric
motor?
When current ia ﬂows in the armature of an electrical motor, a torque
τ is produced that is proportional to the current. The torque constant
Kt is the constant of proportionality, so that τ = Ktia. The units are
Newton-meters/amp.
2.11 Why do we approximate a physical model of the plant (which is always
nonlinear) with a linear model?
Analysis and design of linear models is vastly simpler than with non-
linear models. Furthermore, it has been shown (by Lyapunov) that, if
the linear approximation is stable, then there is at least some region
of stability for the nonlinear model.

822
Appendix B Solutions to the Review Questions
2.12 Give the relationships for (a) heat ﬂow across a substance and (b) heat
△
storage in a substance.
(a) Heat ﬂow is proportional to the temperature difference divided by
the thermal resistance; that is,
q = 1
R (T1 −T2).
(b) The differential equation describing the heat storage is
˙T = 1
C q,
where C is the thermal capacity of the material.
2.13 Name and give the equations for the three relationships governing ﬂuid
△
ﬂow.
Continuity:
˙m = win −wout.
Force equilibrium:
f = pA.
Resistance:
w = 1
R (p1 −p2)1/α.
Chapter 3
3.1 What is the deﬁnition of "transfer function"?
The Laplace transform of the output of a linear, time-invariant system,
Y(s), is proportional to the transform of its input, U(s). The function of
proportionality is the transfer function F(s), so that Y(s) = F(s)U(s).
It is assumed that all initial conditions are zero.
3.2 What are the properties of systems whose responses can be described
by transfer functions?
The system must be both linear (superposition applies) and time
invariant (the parameters do not vary with time).
3.3 What is the Laplace transform of f1(t) = f (t −λ)1(t −λ) if the
transform of f (t) is F(s)?
L{f1(t)} = e−sλF(s).
3.4 State the Final Value Theorem.
If all the poles of sF(s) are in the LHP, then the ﬁnal value of f (t) is
given by lim
t→∞f (t) = lim
s→0 sF(s).
3.5 What is the most common use of the Final Value Theorem in control?
A standard test of a control system is the step response, and the FVT
is used to determine the steady-state error to such an input.
3.6 Given a second-order transfer function with damping ratio ζ and nat-
ural frequency ωn, what is the estimate of the step response rise time?
What is the estimate of the percent overshoot in the step response?
What is the estimate of the settling time?

Appendix B Solutions to the Review Questions
823
These are given by tr ∼= 1.8/ωn, Mp is set by the damping ratio (see
the curve in Fig. 3.24) and ts ∼= 4.6/σ.
3.7 What is the major effect of an extra zero in the LHP on the second-order
step response?
Such a zero causes additional overshoot, and the closer the zero is to
the imaginary axis, the higher the overshoot. If the zero is more than
six times the real part of the complex poles, the effect is negligible.
3.8 What is the most noticeable effect of a zero in the RHP on the step
response of the second-order system?
Such a zero often causes an initial undershoot of the response.
3.9 What is the main effect of an extra real pole on the second-order step
response?
A pole slows down the response and makes the rise time longer. The
closer the pole is to the imaginary axis, the more pronounced is the
effect. If the pole is more than six times the real part of the complex
poles, the effect is negligible.
3.10 Why is stability an important consideration in control system design?
Almost any useful dynamic system must be stable to perform its func-
tion. Feedback around a system that is normally stable can actually
introduce instability, so control designers must be able to assure the
stability of their designs.
3.11 What is the main use of Routh's criterion?
With this method, we can ﬁnd (symbolically) the range of a parameter
such as the loop gain for which the system will be stable.
3.12 Under what conditions might it be important to know how to estimate
a transfer function from experimental data?
In many cases, the equations of motion are either extremely complex or
not known at all. Chemical processes such as a paper-making machine
are often of this kind. In these cases, if one wishes to build a good
control, it is very useful to be able to take transient data or steady-
state frequency-response data and to estimate a transfer function from
these.
Chapter 4
4.1 Give three advantages of feedback in control.
(a) Feedback can reduce the steady-state error in response to
disturbances.
(b) Feedback can reduce the steady-state error in tracking a reference.
(c) Feedback can reduce the sensitivity of a transfer function to
parameter changes.
(d) Feedback can stabilize an unstable process.

824
Appendix B Solutions to the Review Questions
4.2 Give two disadvantages of feedback in control.
(a) Feedback requires a sensor, which can be very expensive and may
introduce additional noise.
(b) Feedback systems are often more difﬁcult to design and operate
than open-loop systems.
4.3 A temperature control system is found to have zero error to a constant
tracking input and an error of 0.5◦C to a tracking input that is linear
in time, rising at the rate of 40◦C/sec. What is the system type of this
control system and what is the relevant error constant (Kp or Kv or Ka)?
The system is Type 1 and the Kv is the ratio of input rate to error or
Kv = 40/0.5 = 80/sec.
4.4 What are the units of Kp, Kv, and Ka?
Kp is dimensionless, Kv is sec−1, and Ka is sec−2.
4.5 What is the deﬁnition of system type with respect to reference inputs?
With only a polynomial of degree k reference input (no disturbances),
the type is the largest value of k for which the steady-state error is a
constant.
4.6 Whatisthedeﬁnitionofsystemtypewithrespecttodisturbanceinputs?
With only a polynomial of degree k disturbance input (no reference),
the type is the largest value of k for which the steady-state error is a
constant.
4.7 Why does system type depend on where the external signal enters the
system?
Because the error depends on where the input enters, so does the type.
4.8 What is the main objective of introducing integral control?
Integral control will make the error to a constant input go to zero. It
removes the effects of process noise bias. It cannot remove the effects
of sensor bias.
4.9 What is the major objective of adding derivative control?
Derivative control typically makes the system better damped and more
stable.
4.10 Why might a designer wish to put the derivative term in the feedback
rather than in the error path?
When a reference input might include sudden changes, including it in
the derivative action might cause unnecessary large controls.
4.11 What is the advantage of having a "tuning rule" for PID controllers?
PID controllers are typically packaged as a unit with knobs on the front
for the several gain constants. These devices are widely installed in
factories and operated by technicians with modest knowledge of con-
trol theory. A tuning rule permits such a person to measure parameters
of the process experimentally and use this data to set the parameters
in such a way as to give good response.

Appendix B Solutions to the Review Questions
825
4.12 Give two reasons to use a digital controller rather than an analog
controller.
(a) The control law is easier to change if the controller is digital.
(b) A digital controller can perform logic and other nonlinear opera-
tions much easier than an analog controller.
(c) The hardware of a digital controller can be ﬁxed in the design
before the details of the actual control design are ﬁnished.
4.13 Give two disadvantages to using a digital controller.
(a) The bandwidth of a digital controller is limited by the possible
sample frequency.
(b) The digital controller introduces noise by the quantization process.
4.14 Give the substitution in the discrete operator z for the Laplace operator
s if the approximation to the integral in Eq. (W4.8) is taken to be the
rectangle of height e(kTs) and base Ts.
s = z −1
Ts
.
Chapter 5
5.1 Give two deﬁnitions for the root locus.
(a) The root locus is the locus of points in the s-plane where the
equation a(s) + Kb(s) = 0 has a solution.
(b) The root locus is the locus of points in the s-plane where the angle
of G(s) = b(s)/a(s) is 180◦.
5.2 Deﬁne the negative root locus.
The negative root locus is the locus of points where the equation a(s)−
Kb(s) = 0 has a solution or where the angle of G(s) = b(s)/a(s) is 0◦.
5.3 Where are the sections of the (positive) root locus on the real axis?
Segments of the real axis to the left of an odd number of zeros and
poles are on the root locus.
5.4 What are the angles of departure from two coincident poles at s = −a
on the real axis? Assume there are no poles or zeros to the right of −a.
The loci depart at ±90◦.
5.5 What are the angles of departure from three coincident poles at s = −a
on the real axis? Assume there are no poles or zeros to the right of −a.
The loci depart at ±60◦and 180◦.
5.6 What is the principal effect of a lead compensation on a root locus?
The lead compensation generally causes the locus to bend toward the
LHP, moving the dominant roots to a place of higher damping.

826
Appendix B Solutions to the Review Questions
5.7 What is the principal effect of a lag compensation on a root locus in
the vicinity of the dominant closed-loop roots?
The lag compensation is normally placed so near the origin that it
has negligible effect on the root locus in the vicinity of the dominant
closed-loop roots.
5.8 What is the principal effect of a lag compensation on the steady-state
error to a reference input?
A lag compensation normally raises the gain at s = 0 and thus lowers
the errors.
5.9 Why is the angle of departure from a pole near the imaginary axis
especially important?
If the locus starts toward the RHP, then feedback will make the system
less stable. On the other hand if the locus departs toward the LHP,
then feedback is going to make the system more stable.
5.10 Deﬁne a conditionally stable system.
A system that becomes unstable as gain is reduced is considered to be
conditionally stable. That is, its stability is conditioned on having an
operating compensator with at least a minimum value of gain.
5.11 Show, with a root locus argument, that a system having three poles at
the origin must be conditionally stable.
With three poles at the origin, the angles of departure ensure that two
poles leave the origin at 180◦, ±60◦, or, if there are poles on the real
axis in the RHP, they may leave at 0◦, ±120◦which is to say that at
least one pole begins by moving into the RHP. As gain is reduced from
the operating level, at least one root must pass into the RHP for gain
low enough; therefore, the system must be conditionally stable.
Chapter 6
6.1 Why did Bode suggest plotting the magnitude of a frequency response
on log-log coordinates?
In log-log coordinates, the plot for a rational transfer function can be
well guided by linear asymptotes and thus easily plotted and visualized.
6.2 Deﬁne a decibel.
If a power ratio is P1/P2,
then the measure in decibels is
10 log(P1/P2). Because power is proportional to voltage squared, and
a transfer function would give a ratio of voltages, then the gain of a
transfer function G(jω) in decibels is Gdb = 20 log |G(jω)|.
6.3 What is the transfer function magnitude if the gain is listed as 14 db?
14 = 20 log M, therefore M = 5.01.
6.4 Deﬁne gain crossover.
The gain crossover ωc is the value of frequency where the magnitude
gain is 1 (or 0 db).

Appendix B Solutions to the Review Questions
827
6.5 Deﬁne phase crossover.
The phase crossover ωcp is the value of the frequency where the phase
crosses −180◦.
6.6 Deﬁne phase margin, PM.
The phase margin PM is a measure of how far in phase the Nyquist
plot is from instability. In the typical case, if the phase of the system at
gain crossover is φ, then the phase margin is 180◦+ φ. For example,
if φ = −150◦, then the phase margin is 30◦.
6.7 Deﬁne gain margin, GM.
The gain margin is a measure of how far the system is from instability by
changes in gain alone. If the gain at phase crossover, where the system
phase is 180◦, is
G(jωcp)
, then the gain margin is GM∗
G(jωcp)
 =
1.0 or PM = 1/
G(jωcp)
.
6.8 What Bode plot characteristic is the best indicator of the closed-loop
step response overshoot?
The phase margin is related to the equivalent closed-loop damping
ratio approximately by ζeq = PM/100. As we saw in Chapter 3, the
step response overshoot is monotonically related to the damping ratio.
6.9 What Bode plot characteristic is the best indicator of the closed-loop
step response rise time?
The rise time is measured by the closed-loop natural frequency, which
in turn is adequately approximated by the gain crossover. Thus the best
indicator of rise time is ωc.
6.10 What is the principal effect of a lead compensation on Bode plot
performance measures?
The lead compensation usually is used to raise the phase margin at a
desired gain crossover frequency.
6.11 What is the principal effect of a lag compensation on Bode plot
performance measures?
The lag compensation is usually used to raise the low-frequency gain
to reduce the steady-state error to polynomial or low-frequency sinu-
soidal inputs. It can also be used to lower the crossover frequency ωc,
where a more favorable phase exists.
6.12 How do you ﬁnd the Kv of a type 1 system from its Bode plot?
The Kv is determined by the low-frequency asymptote, which has a
slope of −1 for a type 1 system and is given by the expression Kv/ω.
The value of the constant may be found either from the frequency where
the asymptote reaches 1.0 (or 0 db) or else as the value of the asymptote
at the frequency of ω = 1.
6.13 Why do we need to know beforehand the number of open-loop unstable
poles in order to tell stability from the Nyquist plot?

828
Appendix B Solutions to the Review Questions
The Nyquist plot encirclements counts the difference in the number of
zeros and the number of poles in the RHP of 1 + KDcG. In order to
know the number of zeros of this function (which are closed-loop poles
and thus unstable poles of the closed loop), we must know the number
of unstable open-loop poles for the plot.
6.14 What is the main advantage in control design of counting the encir-
clements of −1/K of Dc(jω)G(jω) rather than encirclements of −1 of
KDc(jω)G(jω)?
If we plot DcG alone, then the stability depends on the encirclements
of −1/K. The designer can thus easily look at the entire range of real
K and determine the best value of gain for the design without having
to make any more plots.
6.15 Deﬁne a conditionally stable feedback system. How can you identify
one on a Bode plot?
A conditionally stable system becomes unstable as gain is reduced. If
the low-frequency phase drops below −180◦then a reduction in gain
until gain crossover occurs where there is no phase margin, then the
system is almost surely unstable. A look at the Nyquist plot is necessary
to be certain. This condition can also be seen easily from a root locus;
the locus will have segments in the RHP for low values of gain.
6.16 A certain control system is required to follow sinusoids, which may
△
be any frequency in the range 0 ≤ωℓ≤450 rad/sec and have ampli-
tudes up to 5 units with (sinusoidal) steady-state error to be never
more than 0.01. Sketch (or describe) the corresponding performance
function W1(ω).
The magnitude of W1 is given by the ratio |R| /eb = 5/0.01 = 500. The
performance function would then have the value 500 for frequencies
up to 450 rad/sec. The Bode magnitude plot would be required to be
above this curve for these frequencies.
Chapter 7
The following questions are based on a system in state-variable form with
matrices A, B, C, and D, input u, output y, and state x:
7.1 Why is it convenient to write dynamic equations in state-variable form?
It provides a standard way to describe the differential equations for
any dynamic system so that computer-aided analysis can be carried
out more conveniently. It is also more convenient to analyze linear
systems in terms of the standard description matrices.
7.2 Give an expression for the transfer function of this system.
G(s) = C(sI −A)−1B + D.
7.3 Give two expressions for the poles of the transfer function of the
system.

Appendix B Solutions to the Review Questions
829
(a) p = eig(A).
(b) p = roots of det[sI −A] = a(s) = 0.
7.4 Give an expression for the zeros of the system transfer function.
z = roots of det
 sI −A
−B
C
D

= b(s) = 0.
7.5 Under what condition will the state of the system be controllable?
(a) If the pair (A, B) is controllable—that is, if the matrix
C =

B
AB
· · ·
An−1B

is full rank.
(b) If the system can be put into control canonical form.
7.6 Under what conditions will the system be observable from the output y?
(a) If the matrices (A, C) are observable—that is, if the matrix
O =
⎡
⎢⎢⎢⎣
C
CA
...
CA(n−1)
⎤
⎥⎥⎥⎦
has full rank.
(b) If the system can be put into observable canonical form.
7.7 Give an expression for the closed-loop poles if state feedback of the
form u = −Kx is used.
(a) pc= eig( A −B ∗K).
(b) pc = roots of det(sI −A + BK) = αc(s) = 0.
7.8 Under what conditions can the feedback matrix K be selected so that
the roots of αc(s) are placed arbitrarily?
If the system is controllable.
7.9 What is the advantage of using the LQR or symmetrical root locus in
designing the feedback matrix K?
With LQR, the closed-loop system will be more robust to parameter
changes, and the designer has some control over the control effort
used by the closed-loop system.
7.10 What is the main reason for using an estimator in feedback control?
When the state is not available (usually because it is too expensive or
impractical to put sensors on each state variable), then an estimator
using only the output y can give an estimate that can be used in place
of the actual state.

830
Appendix B Solutions to the Review Questions
7.11 If the estimator gain L is used, give an expression for the closed-loop
poles due to the estimator.
(a) pe= eig(A −L ∗C).
(b) pe = roots of det(sI −A + LC) = αe(s) = 0.
7.12 Under what conditions can the estimator gain L be selected so that the
roots of αe(s) = 0 are placed arbitrarily?
If the system is observable.
7.13 If the reference input is arranged so that the input to the estimator is
identical to the input to the process, what will be the overall closed-loop
transfer function?
T (s) = Ks
b(s)
αc(s).
7.14 If the reference input is introduced in such a way as to permit the zeros
to be assigned as the roots of γ (s), what will the overall closed-loop
transfer function be?
T (s) = Ks
γ (s)b(s)
αe(s)αc(s),
usually γ (s) = αe(s).
7.15 What are the three standard techniques for introducing integral control
in the state-feedback design method?
(a) By augmenting the process state to include an integrator state
variable.
(b) By the internal model approach.
(c) By using the extended estimator approach.
Chapter 8
8.1 What is the Nyquist rate? What are its characteristics?
The Nyquist rate is half the sample rate, or = ωs/2. Above this rate,
no frequencies can be represented by a sampled signal.
8.2 Describe the discrete equivalent design process.
The controller for a system is designed as if the controller will be
analog. The resulting controller is then approximated by a digital
equivalent.
8.3 Describe how to arrive at a Dd(z) if the sample rate is 30 × ωBW .
Use the discrete equivalent design method. It typically yields satisfac-
tory results for such a high sample rate. But after using the discrete
equivalent, check the result using a simulation that includes the effect
of sampling or else perform an exact discrete linear analysis. It is best
to use a simulation that includes all known sampling effects and system
delays.

Appendix B Solutions to the Review Questions
831
8.4 For a system with a 1 rad/sec bandwidth, describe the consequences
of various sample rates.
An absolute minimum sample rate is 2 rad/sec (or 0.32 Hz and T =
3 sec). From 2 rad/sec to 10 or 20 rad/sec, the control will be jerky with
noticeable steps in the control and the design needs to be done very
carefully. Between20and30 rad/sec, themagnitudeofthecontrolsteps
become progressively smaller and design using discrete equivalents
works reasonably well. Above 30 rad/sec, the control steps are hardly
noticeable and the discrete equivalent can be used with conﬁdence.
8.5 Give two advantages for selecting a digital processor rather than analog
circuitry to implement a controller.
(a) The physical layout of a digital controller can be done before the
ﬁnal design is complete, often resulting in completing the hardware
implementation in much less time than required to get an analog
controller speciﬁed and constructed.
(b) A digital processor is more ﬂexible in making design changes as
software is easier to reprogram than rewiring and/or adding op-
amps to a printed circuit board.
(c) A digital processor can much more easily include nonlinear terms
and logic decision steps in the overall controller design to permit
adaptive control or gain scheduling, for example.
(d) Many models of the same basic controller can be accommodated
by simply using different PROMS with the same hardware design.
For example, an automobile manufacturer might have one engine
controller hardware design for its entire product line; but have a
different PROM for each engine/vehicle combination.
(e) Digital controllers are less sensitive to temperature variations than
analog controllers.
8.6 Give two disadvantages of selecting a digital processor rather than
analog circuitry to implement a controller.
(a) The ﬁnite sampling rate of the A/D and D/A converters and the
ﬁnite compute speed of the processor limit the bandwidth of the
controller to about 1/10 of the sample frequency.
(b) The ﬁnite accuracy or bit length of the converters introduce extra
noise or offsets into the control loop if using low-end controllers.
(c) Cost. For simple controllers, a digital implementation will typi-
cally be more expensive than an analog implementation.
8.7 Describe how to arrive at a Dd(z) if the sample rate is 5 × ωBW .
△
Start by using the discrete equivalent, but include an approximation
of the effect of the delay in the plant model when carrying out the
analog design. Then check the result via an exact discrete analysis by
converting the plant to its discrete equivalent and combining that with
the discrete controller. If performance is degraded from that desired,

832
Appendix B Solutions to the Review Questions
modify the discrete controller using discrete design methods. Finish by
using a simulation that includes all known sampling effects and system
delays.
Chapter 9
9.1 Why do we approximate a physical model of the plant (which is always
nonlinear) with a linear model?
Analysis and design of linear models is vastly simpler than with non-
linear models. Furthermore, it has been shown (by Lyapunov) that if
the linear approximation is stable, then there is at least some region
of stability for the nonlinear model.
9.2 How would you linearize the nonlinear system equation for radiation
heat transfer ˙T = T4 + T + u?
δ ˙T = (4T3
o + 1)δT + δu,
where To is the nominal operating temperature. (see the RTP case
study in Chapter 10.)
9.3 A lamp used as a thermal actuator has a nonlinearity such that the
experimentally measured output power is related to the input voltage
by P = V1.6. How would you deal with such a nonlinearity in feedback
control design?
We precede the lamp with an inverse nonlinearity—that is, V =
P0.625—so as to linearize the cascaded system (see the RTP case study
in Chapter 10).
9.4 What is integrator windup?
If the plant actuator output signal saturates, then it may take a long
time for the error to be brought back to zero from an initial upset and
during this time the integrator output may grow or "windup" much
more than it would if the system were linear. Special "antiwindup"
circuits are designed to prevent windup.
9.5 Why is an antiwindup circuit important?
When a control includes integral action and is subject to saturation,
large inputs can cause large overshoots and slow recovering unless an
antiwindup circuit is included.
9.6 Using the nonlinear saturation function having gain 1 and limits ±1,
sketch the block diagram of saturation for an actuator that has gain 7
and limits ±20.
If the output of the actuator is uout and its input is uin, the control is
given by
uout = 20 sat
7uin
20

.

Appendix B Solutions to the Review Questions
833
9.7 Whatisadescribingfunctionandhowisitrelatedtoatransferfunction?
The goal of the describing function approach is to ﬁnd something
like a "transfer function" for a nonlinear element. One may view
the describing function as an extension of the frequency response to
nonlinearities.
9.8 What are the assumptions behind the use of the describing function?
The basic assumption is that the plant behaves approximately as a
low-pass ﬁlter. The other assumptions are that the nonlinearity is time
invariant, and there is a single nonlinear element in the system.
9.9 What is a limit cycle in a nonlinear system?
In some nonlinear systems the error builds up and the response
approaches a periodic solution of ﬁxed amplitude, the limit cycle, as
time grows large.
9.10 How can one determine the describing function for a nonlinear system
in the laboratory?
We can inject sinusoidal signals into the system and place a low-pass
ﬁlter with a sharp cutoff at the output of the system to measure the
fundamental component of the output. The describing function is then
computedastheratiooftheamplitudeofthefundamentalcomponentof
the output of the nonlinear system over the amplitude of the sinusoidal
input signal.
9.11 What is the minimum time-control strategy for a satellite attitude
control with bounded controls?
Bang-bang.
9.12 How are the two Lyapunov methods used?
His indirect or ﬁrst method is based on linearization of the equations
of motion and drawing conclusions about the stability of the nonlinear
system by considering the stability of the linear approximation. In
his direct or second method, the nonlinear equations are considered
directly.
Chapter 10
10.1 Why is a collocated actuator and sensor arrangement for a lightly
damped structure such as a robot arm easier to design than a
noncollocated setup?
In the collocated case, the process naturally has zeros near the lightly
damped poles, which keep the root locus in the LHP.
10.2 Why should the control engineer be involved in the design of the
process to be controlled?
In many cases, the characteristics and locations of the actuators and
sensors can have a major impact on the complexity and difﬁculty
in design of the controller. If the needs of control are included in

834
Appendix B Solutions to the Review Questions
the process design, the ﬁnal systems are often more effective (better
closed-loop performance) and less expensive.
10.3 Give examples of an actuator and a sensor for the following control
problems:
(a) Attitude control of a geosynchronous communication satellite.
Actuators: Cold gas-jet thrusters, momentum wheels, magnetic
torquers (coils, torque rod), plasma thruster.
Sensors: Earth sensor (roll, pitch), digital integrated rate
assembly (DIRA) gyro (for rates), star tracker.
(b) Pitch control of a Boeing 747 airliner.
Actuators: Elevator.
Sensors: Pitch rate and/or pitch angle is measured using a gyro
or a ring-laser gyro.
(c) Track-following control of a CD player.
Actuators: DC motor to move the (dual stage sledge) arm
mechanism, magnetic coils (two) for focusing on tracks.
Sensors: Array of photodiodes.
(d) Fuel-air ratio control of a spark-ignited automobile engine.
Actuators: Fuel injection.
Sensors: Zirconium oxide sensor.
(e) Position control for an arm of a robot used to paint automobiles.
Actuators: Hydraulic actuators or electric motors.
Sensors: Encoders to measure arm rotations, pressure sensors,
and force sensors.
(f) Heading control of a ship.
Actuators: Rudder.
Sensors: Gyrocompass.
(g) Attitude control of a helicopter.
Actuators: Moving swash plate (either via direct link or servo)
rotates main blade angle of attack.
Sensors: Same as aircraft (pitot tube, accelerometers, rate gyros).

AppendixC
Matlab Commands
Matlab function
(.m ﬁle) or Variable
Description
Page (s)
\
Backslash or left matrix divide
474, 554, 555
A(:)
Vectorize matrix A
allmargin
All stability margins and crossover
frequencies
abs
Absolute value
acker
Ackermann's formula for pole placement
470, 478, 491, 495
angle
Phase angle
ans
Most recent answer
atan
Inverse tangent
atan2
Four quadrant inverse tangent
axis
Control axis scaling
313, 343, 347
bilin
Bilinear transform
bode
Bode frequency response
97, 313, 328, 371, 397
bodemag
Bode magnitude frequency response
break
Terminate execution of WHILE or FOR
loop
c2d
Continuous-to-discrete conversion
603, 606, 626
canon
State-space canonical forms
456
clear
Clear variables and functions
clf
Clear current ﬁgure
close
Close ﬁgure
close all
Close all ﬁgures
colon(:)
Create vector of indices or reshape
matrices
conj
Complex conjugate
conv
Polynomial multiplication
107
cos
Cosine
cross
Cross product of the vectors
ctrb
Controllability matrix
ctrbf
Staircase canonical form, controllability
572
damp
Damping and natural frequency
626
dcgain
Computes DC gain of LTI system
deconv
Division of polynomials
delete
Delete ﬁle or graphics object
det
Determinant of a matrix
835

836
Appendix C Matlab Commands
Matlab function
(.m ﬁle) or Variable
Description
Page (s)
diag
Diagonal matrix, diagonals of a matrix
diary
Save text of Matlab session
disp
Displays the array
dlyap
Solution to discrete-time Lyapunov equation
dot
Vector dot product
dstep
Step response of a discrete system
d2c
Discrete to continuous-time model
eig
Eigenvalues and eigenvectors
455, 457
eigs
Find a few eigenvalues and eigenvectors
eps
Precision parameter
exp
Exponential
expm
Matrix exponential
eye
Identity matrix
ezplot
Easy to use function plotter
154
feedback
Feedback connection of two systems
123, 278, 626
ﬁgure
Create ﬁgure window
ﬁgure(i)
Make i the current ﬁgure
ﬁnd
Find indices of nonzero elements
format
Set output format
freqresp
Frequency response of LTI systems
function
Add new function
752
gensig
Generate signals
gram
Controllability/observability Gramian
grid
Grid lines
gtext
Place text with mouse
help
Display help text in Command Window
hold
Hold current plot
154
i
√−1
ilaplace
Inverse Laplace transform
811, 815, 816
imag
Complex imaginary part
impulse
Impulse response of LTI system
126, 131, 144, 492
impulseplot
Plot impulse response and return handle
inf
Inﬁnity
input
Prompt for user input
initial
Initial condition response of state space system
492, 498
inv
Matrix inverse
455, 456
j
√−1
kron
Kronecker tensor product
541
laplace
Laplace transform
807, 808, 813
length
Length of vector
linmod
Linearization
642
linmod2
Linearization (advanced)
642

Appendix C Matlab Commands
837
Matlab function
(.m ﬁle) or Variable
Description
Page (s)
line
Create a line
linspace
Linearly spaced vector
load
Load in workspace variables
log
Natural logarithm
log10
Logarithm to the base 10
loglog
Log-log plot
97, 313, 371
logspace
Logarithmically spaced frequency points
97, 550
lqe
Linear Quadratic Estimator design
551
lqr
Linear Quadratic Regulator design
486, 550
lqry
Linear Quadratic Regulator design with
output weighting
lsim
Simulation of LTI system with arbitrary
input
116, 118
ltiview
Opens the LTI viewer GUI
ltru
Loop transfer recovery (LTR)
552
ltry
Loop transfer recovery (LTR)
552
lyap
Solution to continuous-time Lyapunov
equation
margin
Gain and phase margins
371, 417, 551
max
Largest component
397
mean
Average or mean value
median
Median value
min
Smallest component
minreal
Minimal realization of a system
nan
Not-a-number
ngrid
Nichol's chart grid
nichols
Nichol's chart
402, 404
norm
Matrix or vector norm
nyquist
Nyquist plot
340, 343, 347
obsv
Observability matrix
obsvf
Staircase canonical form, observability
ones
Array of ones
116, 118
ord2
Generate continuous second order system
ode23
Solution to non stiff differential equations
ode45
Solution to non stiff differential equations
pade
Pade approximation for time delay
parallel
Parallel connection of two LTI systems
123
pause
Wait for user response
place
Pole placement
472, 495, 499, 504, 508
pi
3.141592653589793
116
pid
Create a PID controller in parallel form
pidstd
Create a PID controller in standard form

838
Appendix C Matlab Commands
Matlab function
(.m ﬁle) or Variable
Description
Page (s)
plot
Plot function
37, 115, 117, 118
pole
Poles of LTI system
poly
Form polynomial from its roots
111
polyﬁt
Fit polynomial to data
polyval
Evaluate polynomial
prescale
Optimal scaling of state-space models
print
Print ﬁgure or model
printsys
Print system in pretty format
113
pzmap
Pole-zero map
124
rand
Uniformly distributed random numbers
randn
Normally distributed random numbers
rank
Matrix rank
real
Complex real part
reshape
Reshape array
residue
Residues in partial fraction expansion
107, 111, 814
return
Return to invoking function
rlocﬁnd
Find Root Locus gain
251, 263
rlocus
Root locus
248, 254, 255, 256
rlocusplot
Plot root locus and return handle
rltool
Interactive Root Locus tool
258, 269
roots
Roots of a polynomial
153, 462, 472
save
Save workspace variables
semilogx
Semi-log plot
97, 313, 371
semilogy
Semi-log plot
series
Series connection of two LTI systems
123, 551, 626
sgrid
s-plane grid lines
shg
Show graph window
sign
Signum function
sin
Sine
sim
Simulate a Simulink model
sisotool
SISO design tool
size
Size of an array
sort
Sort in ascending or descending order
sprintf
Write formatted data to string
sqrt
Square root
533
std
Standard deviation
squeeze
Remove singleton dimensions
97, 313, 328, 371
ss2tf
State space to transfer function conversion
458, 461, 462
ss2zp
State space to pole-zero conversion
444
ss
Conversion to state space
439, 456, 461, 551
ssdata
Create a state space model
456
std
Standard deviation
step
Step response
27, 37, 115, 153, 155

Appendix C Matlab Commands
839
Matlab function
(.m ﬁle) or Variable
Description
Page (s)
subplot
Multiple plots on the same window
sum
Sum of elements
svd
Singular value decomposition
syms
Declaration of symbolic variables
807, 808, 811, 813
tan
Tangent of argument in radians
text
Text annotation
tf2ss
Transfer function to state space
conversion
446
tf2zp
Transfer function to pole-zero
conversion
113, 114, 444
tf
Creation or conversion to transfer
function
27, 37, 97, 155, 603
tfdata
Transfer function data
title
Plot title
tzero
Transmission zeros and gain for
SISO systems
461, 463
var
Variance
what
List Matlab-speciﬁc ﬁles in directory
who
List of current variables
why
Answers any question you may have
whos
List of current variables, long form
xlabel
x-axis label
xlim
x-axis limits
xlsread
Get data from an Excel spreadsheet
ylabel
y-axis label
ylim
y-axis limits
zero
Transmission zeros
zeros
Array of zeros
116, 118
zgrid
z-plane grid lines
zlabel
z-axis label
zlim
z-axis limits
zpk
Zero-pole-gain
zp2ss
Zero-pole to state-space conversion
zp2tf
Zero-pole to transfer function
conversion
113, 116

Bibliography
Abramovitch, D. and G. F. Franklin, "A brief history of disk drive control,"
IEEE Cont. Syst. Mag., Vol. 22, pp. 28-42, June 2002.
Ackermann, J., "Der entwurf linearer regelungssysteme im zustandsraum,"
Regelungstech. Prozess-Datenverarb., Vol. 7, pp. 297-300, 1972.
Airy, G. B., "On the regulator of the clock-work for effecting uniform
movement of equatorials," Mem. R. Astron. Soc., Vol. 11, pp. 249-267,
1840.
Alon, U., An Introduction to Systems Biology. Chapman & Hall/CRC, 2007.
Alon, U., M. G. Surette, N. Barkai, and S. Leibler, "Robustness in bacterial
chemotaxis," Nature, Vol. 397, pp. 168-171, January 1999.
Anderson, B. D. O. and J. B. Moore, Optimal Control: Linear Quadratic
Methods. Upper Saddle River, NJ: Prentice Hall, 1990.
Anderson, E., et al., LAPACK User's Guide. 3rd ed., Philadelphia, PA:
SIAM, 1999.
Åström, K. J., Introduction to Stochastic Control Theory. Princeton, NJ:
Academic Press, 1970.
Åström, K. J., "Frequency domain properties of Otto Smith regulators,"
International Journal of Control, Vol. 26, No. 2, pp. 307-314, 1977.
Åström, K. J. and T. Hägglund, PID Controllers: Theory, Design, and Tun-
ing, 2nd ed., Research Triangle, NC: International Society for Measurement
and Control, 1995.
Åström, K. J. and T. Hägglund, Advanced PID Control. Research Triangle,
NC: International Society for Measurement and Control, 2006.
Athans, M., "A tutorial on the LQG/LTR method," Proceedings of the
American Control Conference, Seattle, WA, pp. 1289-1296, June 1986.
Barkai, N. and S. Leibler, "Robustness in simple biochemical networks,"
Nature, Vol. 387, pp. 913-917, 1997.
Bellman, R. and R. Kalaba, eds., Mathematical Trends in Control Theory.
New York: Dover, 1964.
Berg, H. C., E. coli in Motion. New York: Springer-Verlag, 2004.
Berg, H. C. and D. A. Brown, "Chemotaxis in Escherichia coli analyzed by
three-dimensional tracking," Nature, Vol. 239, pp. 500-504, 1972.
Bergen, A. R. and R. L. Franks, "Justiﬁcation of the describing function
method," SIAM J. Control, Vol. 9, pp. 568-589, 1971.
Blakelock, J. H., Automatic Control of Aircraft and Missiles. 2nd ed., New
York: John Wiley, 1991.
840

Bibliography
841
Bodanis, D., E = MC2: A Biography of the World's Most Famous Equation.
New York: Walker and Co., 2000.
Bode, H. W., Network Analysis and Feedback Ampliﬁer Design. New York:
Van Nostrand, 1945.
—-,"Feedback: The history of an idea," Conference on Circuits and Systems.
New York (1960): Reprinted in Bellman and Kalaba, 1964.
Boyd, S. P. and C. H. Barratt, Linear Controller Design: Limits of
Performance. Upper Saddle River, NJ: Prentice Hall, 1991.
Brennan, R. P., Heisenberg Probably Slept Here. New York: John Wiley &
Sons, 1997.
Brown, J. W. and R. V. Churchill, Complex Variables and Applications.
6th ed., New York: McGraw-Hill, 1996.
Bryson, A. E., Jr., Control of Spacecraft and Aircraft. Princeton, NJ:
Princeton University Press, 1994.
Bryson, A. E., Jr. and W. F. Denham, "A steepest-ascent method for solving
optimum programming problems," J. Appl. Mech., Vol. 29, pp. 247-257,
June 1962.
Bryson, A. E., Jr. and Y. C. Ho, Applied Optimal Control. Waltham, MA:
Blaisdell, 1969.
Callender, A., D. R. Hartree, and A. Porter, "Time lag in a control system,"
Philos. Trans. R. Soc. London A, London: Cambridge University Press,
1936.
Campbell, G. A. and R. N. Foster, Fourier Integrals for Practical Applica-
tions. New York: Van Nostrand, 1948.
Campbell, N. A. and J. B. Reece, Biology. 8th ed., Benjamin Cummings,
2008.
Cannon, R. H., Jr., Dynamics of Physical Systems. NewYork: McGraw-Hill,
1967.
Churchill, R. V., Operational Mathematics. 3rd ed., New York: McGraw-
Hill, 1972.
Clark, R. N., Introduction to Automatic Control Systems. New York: John
Wiley, 1962.
Clegg, J. C., "A nonlinear integrator for servomechanisms," Trans. AIEE,
Pt. II, Vol. 77, pp. 41-42, 1958.
de Roover, D., A. Emami-Naeini, and J. L. Ebert, "Model-based control of
fast-ramp RTP systems," Sixth International Conference on Advanced Ther-
mal Processing of Semiconductors, pp. 177-186, Kyoto, Japan, September
1998.
de Roover, D., L. Porter, A. Emami-Naeini, J. A. Marohn, S. Kuehn,
S. Garner, and D. Smith, "An all-digital cantilever controller for MRFM
and scanned probe microscopy using a combined DSP/FPGA design," Am.
Lab., Vol. 40, No. 8, pp. 12-17, 2008.

842
Bibliography
de Vries, G., T. Hillen, M. Lewis, J. Muller, and B. Schonﬁsch, A Course in
Mathematical Biology. SIAM, 2006.
Dorato, P., Analytic Feedback System Design: An Interpolation Approach,
Paciﬁc Grove. CA: Brooks/Cole, 2000.
Doyle, J. C., "Guaranteed margins for LQG regulators," IEEE Trans. Autom.
Control, Vol. AC-23, pp. 756-757, 1978.
Doyle, J. C. and G. Stein, "Robustness with observers," IEEE Trans. Autom.
Control, Vol. AC-24, pp. 607-611, August 1979.
Doyle, J. C. and G. Stein, "Multivariable feedback design: Concepts for
a classical/ modern synthesis," IEEE Trans. Autom. Control, Vol. AC-26,
No. 1, pp. 4-16, February 1981.
Doyle, J. C., B. A. Francis, and A. Tannenbaum, Feedback Control Theory.
New York: Macmillan, 1992.
Ebert, J. L.,A. Emami-Naeini, and R. L. Kosut, "Thermal Modeling and con-
trol of rapid thermal processing systems," Proceeding 34th IEEE Conference
Decision and Control, pp. 1304-1309, December 1995b.
Ebert, J. L., A. Emami-Naeini, H. Aling, and R. L. Kosut, "Thermal model-
ing of rapid thermal processing systems," Third International RapidThermal
Processing Conference, pp. 343-355, Amsterdam, August 1995a.
Elgerd, O. I., Electric Energy Systems Theory. New York: McGraw-Hill,
1982.
Elgerd, O. I. and W. C. Stephens, "Effect of closed-loop transfer function
pole and zero locations on the transient response of linear control systems,"
Trans. Am. Inst. Electr. Eng. Part 1, Vol. 42, pp. 121-127, 1959.
Emami-Naeini,A., "The shapes of Nyquist plots: Connections with classical
plane curves," IEEE Control Systems Magazine, pp. 102-115, October 2009.
Emami-Naeini,A. and G. F. Franklin, "Zero assignment in the multivariable
robust servomechanism," Proc. IEEE Conf. Dec. Control, Vol. 21, pp. 891-
893, December, 1982.
Emami-Naeini, A., and P. Van Dooren, "Computation of zeros of linear
multivariable systems," Automatica, Vol. 18, No. 4, pp. 415-430, 1982.
—-, "On computation of transmission zeros and transfer functions," Proc.
IEEE Conf. Dec. Control, pp. 51-55, December 1982.
Emami-Naeini, A., J. L. Ebert, D. de Roover, R. L. Kosut, M. Dettori,
L. Porter, and S. Ghosal, "Modeling and control of distributed thermal
systems," Proc. IEEE Trans. Control Systems Technol.. Vol. 11, No. 5,
pp. 668-683, September 2003.
Etkin, B. and L. D. Reid, Dynamics of Flight: Stability and Control. 3rd ed.,
New York: John Wiley, 1996.
Evans, G. W., "Bringing root locus to the classroom," IEEE Control
Systems Magazine, Vol. 24, pp. 74-81, 2004.
Francis, B. A. and W. M. Wonham,"The internal model principle for linear
multivariable regulators," J. Appl. Maths. Optimization, pp.170-194, 1975.

Bibliography
843
Franklin, G. F., J. D. Powell, M. Workman, Digital Control of Dynamic
Systems. 3rd ed., Half Moon Bay, CA: Ellis-Kagle Press, 1998.
Freudenberg, J. S. and D. P. Looze, "Right half plane zeros and design
tradeoffs in feedback systems," IEEE Trans. Autom. Control, Vol. AC-30,
pp. 555-561, June 1985.
Fuller,A. T., "The Early development of control theory," J. Dyn. Syst. Meas.
Control, Vol. 98, pp. 109-118 and 224-235, 1976.
Gardner, M. F. and J. L. Barnes, Transients in Linear Systems. New York:
John Wiley, 1942.
Gunckel, T. L., III and G. F. Franklin, "A general solution for linear sampled
data control," J. Basic Eng., Vol. 85-D, pp. 197-201, 1963.
Gyugyi, P., Y. Cho, G. F. Franklin, and T. Kailath, "Control of rapid ther-
mal processing: A system theoretic approach," Proceedings of IFAC World
Congress, 1993.
Hanselman, D. C. and B. C. Littleﬁeld, Mastering MATLAB 7. Upper Saddle
River. NJ: Prentice Hall, 2005.
Hefﬂey, R. K. and W. F. Jewell, Aircraft Handling Qualities, Technical
Report 1004-1, System Technology, Inc., Hawthorne, CA, May 1972.
Higham, D. J. and N. J. Higham, MATLAB Guide. 2nd ed., Philadelphia,
PA: SIAM, 2005.
Ho, M.-T., A. Datta, and S. P. Bhattacharyya, "An elementary derivation of
the Routh- Hurwitz criterion," IEEE Trans. Autom. Control, Vol. 43, No. 3,
pp. 405-409, 1998.
Horowitz, I. M. and M. Sidi, Quantitative Feedback Theory (QFT), QFT
Publications, 4470 Grinnell Ave., Boulder, Colorado 80303, 1992.
Huang, J-J. and D. B. DeBra, "Automatic tuning of Smith-predictor
design using optimal parameter mismatch," Proc. IEEE Conf. Dec. Contr.,
pp. 3307-3312, December 2000.
Hubbard, M., Jr. and J. D. Powell, "Closed-loop control of internal com-
bustion engine exhaust emissions," SUDAAR No. 473, Department of
Aero/Astro, Stanford University, Stanford, CA, February 1974.
James, H. M., N. B. Nichols, and R. S. Phillips, Theory of Servomecha-
nisms. Radiation Lab. Series, 25. New York: McGraw-Hill, 1947.
Johnson, R. C., Jr., A. S. Foss, G. F. Franklin, R. V. Monopoli, and
G. Stein, "Toward development of a practical benchmark example for adap-
tive control," IEEE Contr. Syst. Mag., Vol. 1, No. 4, pp. 25-28, December
1981.
Joseph, P. D. and J. T. Tou., "On linear control theory," AIEE Transactions,
Vol. 80, pp. 193-196, 1961.
Kailath, T., Linear Systems. Upper Saddle River, NJ: Prentice Hall, 1980.
Kalman, R. E., "A new approach to linear ﬁltering and prediction problems,"
J. Basic Eng., Vol. 85, pp. 34-45, 1960a.

844
Bibliography
Kalman, R. E., "Lyapunov functions for the problem of lur'e in automatic
control," Proc. Nat. Acad. Sci., Vol. 49, pp. 201-205, 1963.
Kalman, R. E. and J. E. Bertram, "Control system analysis and design via the
second method of Lyapunov. II. Discrete Systems," J. Basic Eng., Vol. 82,
pp. 394-400, 1960.
Kalman, R. E., Y. C. Ho, and K. S. Narendra, "Controllability of linear
dynamical systems," Contrib. Diff. Eq., Vol. 1. NewYork: John Wiley, 1962.
Khalil, H. K., Nonlinear Systems. 3rd ed., Upper Saddle River, NJ: Prentice
Hall, 2002.
Kharitonov, V. L., "Asymptotic stability of an equilibrium position of a fam-
ily of systems of linear differential equations," Differential'nye Uraveniya,
Vol. 14, pp. 1483-1485, 1978.
Kochenburger, R. J., "A frequency response method for analyzing and syn-
thesizing contactor servomechanisms," Trans. Am. Inst. Electr. Eng.,Vol. 69,
pp. 270-283, 1950.
Kuo, B. C., ed., Incremental Motion Control, Vol. 2: Step Motors and Control
Systems. Champaign, IL: SRL Publishing, 1980.
—-, Proceedings of the Symposium Incremental Motion Control Systems
and Devices, Part. 1: Step Motors and Controls. Champaign-Urbana, IL:
University of Illinois, 1972.
Lanchester, F. W., Aerodonetics. London: Archibald Constable, 1908.
LaSalle, L. P. and S. Lefschetz, Stability by Lyapunov's Direct Method. New
York: Academic Press, 1961.
Lyapunov, A. M., "Problème général de la stabilité du mouvement," Ann.
Fac. Sci. Univ. Toulouse Sci. Math. Sci. Phys., Vol. 9, pp. 203-474, 1907;
original paper published in 1892 in Commun. Soc. Math. Kharkow, 1892;
reprinted as Vol. 17 in Annals of Math Studies. Princeton, NJ: Princeton
University Press, 1949.
Ljüng, L., System Identiﬁcation: Theory for the User. 2nd ed., Upper Saddle
River, NJ: Prentice Hall, 1999.
Luenberger, D. G., "Observing the state of a linear system," IEEE Trans.
Mil. Electron., Vol. MIL-8, pp. 74-80, 1964.
Mahon, B., The Man who Changed Everything: The Life of James Clerk
Maxwell. UK: Wiley, 2003.
Marsden, J. E. and M. J. Hoffman, Basic Complex Analysis. 3rd ed.,
Freeman, 1999.
Mason, S. J., "Feedback theory: Some properties of signal ﬂow graphs,"
Proc. IRE, Vol. 41, pp. 1144-1156, 1953.
—-, "Feedback theory: Further properties of signal ﬂow graphs," Proc. IRE,
Vol. 44, pp. 920-926, 1956.
Maxwell, J. C., "On governors," Proc. R. Soc. Lond., Vol. 16, pp. 270-283,
1868.

Bibliography
845
Mayr, O., The Origins of Feedback Control. Cambridge, MA: MIT Press,
1970.
McRuer, D.T., I.Askenas, and D. Graham, Aircraft Dynamics andAutomatic
Control. Princeton, NJ: Princeton University Press, 1973.
Mello, B.A., L. Shaw, andY. Tu, "Effects of receptor interaction in bacterial
chemotaxis," Biophys. J., Vol. 87, pp. 1578-1595, September 2004.
Messner, W. C. and D. M. Tilburry, Control Tutorials for MATLAB and
Simulink: A Web-Based Approach, Upper Saddle River, NJ: Prentice Hall,
1999.
Minimis, G. S. and C. C. Paige, "An algorithm for pole assignment of time
invariant systems," Int. J. Control, Vol. 35, No. 2, pp. 341-354, 1982.
Moler, C. B., "Nineteen dubious ways to compute the exponential of a
matrix, twenty-ﬁve years later," SIAM Rev., Vol. 45, No. 1, pp. 3-49, 2003.
—-, Numerical Computing with MATLAB. Philadelphia, PA: SIAM, 2004.
Norman, S. A., "Wafer temperature control in rapid thermal processing,"
Ph.D. Dissertation, Stanford University, Stanford, CA, 1992.
Nyquist, H., "Regeneration theory," Bell Systems Technical. J., Vol. 11,
pp. 126-147, 1932.
Oswald, R. K., "Design of a disk ﬁle head positioning servo," IBM J. Res.
Dev., Vol. 18, pp. 506-512, November 1974.
Parks, P., "Lyapunov redesign of model reference adaptive control systems,"
IEEE Trans. Autom. Control, AC-11, No. 3, 1966.
Perkins, W. R., P. V. Kokotovic, T. Boureret, and J. L. Schiano, "Sensitivity
function methods in control system education," IFAC Conference on Control
Education, June 1991.
Ragazzini, J. R. and G. F. Franklin, Sampled-Data Control Systems. New
York: McGraw-Hill, 1958.
Ragazzini, J. R., R. H. Randall, and F. A. Russell, "Analysis of problems in
dynamics by electronic circuits," Proc. IRE, Vol. 35, No. 5, pp. 442-452,
May 1947.
Reliance Motion Control Corp., DC Motor Speed Controls Servo Systems.
5th ed., Eden Prairie, MN: Reliance Motion Control Corp., 1980.
Routh, E. J., Dynamics of a System of Rigid Bodies. London: MacMillan,
1905.
Saberi, A., B. M. Chen, and P. Sannuti, Loop Transfer Recovery: Analysis
and Design. New York: Springer-Verlag, 1993.
Safonov, M. G. and G. Wyetzner, "Computer-aided stability analysis ren-
ders Popov criterion obsolete," IEEE Trans. Autom. Control, Vol. AC-32,
pp. 1128-1131, 1987.
Sandberg, I. W., "A frequency domain condition for stability of feedback
systems containing a single time varying nonlinear element," Bell Systems
Technical J., Vol. 43, pp. 1581-1599, 1964.

846
Bibliography
Sastry, S. S., Nonlinear Systems; Analysis, Stability, and Control. NewYork:
Springer-Verlag, 1999.
Schmitz, E., "Robotic arm control," Ph.D. Dissertation, Stanford University,
Stanford, CA, 1985.
Sedra, A. S. and K. C. Smith, Microelectronics Circuits. 3rd ed., NewYork:
Oxford University Press, 1991.
Simon,
H. A.,
"Dynamic programming under uncertainty with a
quadratic function,"Econometrica, Vol. 24, pp. 74-81, 1956.
Sinha,N.K.andB.Kuszta, ModelingandIdentiﬁcationofDynamicSystems.
New York: Van Nostrand, 1983.
Smith, O. J. M., Feedback Control Systems. NewYork: McGraw-Hill, 1958.
Sobel, D., Galileo's Daughter. New York: Penguin Books, 2000.
Stein, G. and M. Athans, "The LQG/LTR procedure for multivariable feed-
back control design," IEEETrans. Autom. Control,Vol.AC-32, pp. 105-114,
February 1987.
Strang, G., Linear Algebra and Its Applications. 4th ed., Paciﬁc Grove, CA:
Cengage Learning, 2006.
Swift, J., On Poetry: A Rhapsody, 1733, J. Bartlett, ed., Familiar Quotations,
15th ed., Boston: Little Brown, 1980.
Sze, S. M., ed. VLSI Technology. 2nd ed., New York: McGraw-Hill, 1988.
Taubman, P., Secret Empire: Eisenhower, the CIA, and the Hidden Story of
America's Space Espionage. New York: Simon and Schuster, 2003.
Thomson, W. T. and M. D. Dahleh, Theory of Vibration with Applications.
5th ed., Upper Saddle River, NJ: Prentice Hall, 1998.
Tischler, M. B., Aircraft and Rotorcraft System Identiﬁcation. 2nd ed.,
Reston, VA: AIAA Education Series, 2012.
Trankle, T. L., "Development of WMEC Tampa maneuvering model from
sea trial data," Report MA-RD-760-87201. Palo Alto, CA: Systems Control
Technology, March 1987.
Trankle, T. L. and A. E. Bryson, Jr., "Control Logic to Track The Outputs of
a Command Generator or Randomly Forced Target," Journal of Guidance
and Control, Vol. 1, No. 2, pp. 130-135, 1978.
Truxal, J. G., Control System Synthesis. New York: McGraw-Hill, 1955.
Ulsoy, A. G., H. Peng, and M. Cakmakci, Automotive Control Systems.
New York: Cambridge University Press, 2012.
van der Linden, G., J. L. Ebert, A. Emami-Naeini, and R. L. Kosut "RTP
robust control design: Part II: controller synthesis," Fourth International
Rapid Thermal Processing Conference, pp. 263-271, September 1996.
Van der Pol, B. and H. Bremmer, Operational Calculus. New York:
Cambridge University Press, 1955.

Bibliography
847
Van Dooren, P., A. Emami-Naeini, and L. Silverman, "Stable Extraction of
the Kronecker Structure of Pencils," Proc. IEEE Conf. Dec. Control, San
Diego, CA, pp. 521-524, December 1978.
Vidyasagar, M., Nonlinear Systems Analysis. 2nd ed., Upper Saddle River,
NJ: Prentice Hall, 1993.
Wiener, N., "Generalized harmonic analysis," Acta Math., Vol. 55, pp. 117,
1930.
Woodson, H. H. and J. R. Melcher, Electromechanical Dynamics, Part I:
Discrete Systems. New York: John Wiley, 1968.
Workman, M. L., "Adaptive proximate time-optimal servomechanisms,"
Ph.D. Dissertation, Stanford University, Stanford, CA, 1987.
Yakubovich, V. A., "Solution of certain matrix inequalities in the stability
theory of nonlinear control systems," Dokl. Akad. Nauk. SSSR, Vol. 143, pp.
620-623, 1962.
Yang, L. and P. A. Iglesias, "Feedback induced biphasic response in
the chemotaxis pathway of Dictyostelium," in American Control Conf.
(Portland, OR), pp. 4393-4398, June 2005.
Yi, T.-M.,Y. Huang, M. I. Simon, and J. C. Doyle, "Robust perfect adaptation
in bacterial chemotaxis through integral feedback control," PNAS, Vol. 97,
No. 9, pp. 4649-4653, April 2000.
Zames, G., "On the input-output stability of time-varying nonlinear feedback
systems—Part I: Conditions derived using concepts of loop gain, conicity
and positivity," IEEETrans. Autom. Control,Vol.AC-11, pp. 465-476, 1966.
—-, "On the input-output stability of time-varying nonlinear feedback
systems—Part II: Conditions involving circles in the frequency plane
and sector nonlinearities," IEEE Trans. Autom. Control, Vol. AC-11,
pp. 228-238, 1966.
Ziegler, J. G. and N. B. Nichols, "Optimum settings for automatic con-
trollers," Trans. ASME, Vol. 64, pp. 759-768, 1942.
—-, "Process lags in automatic control circuits," Trans. ASME, Vol. 65,
No. 5, pp. 433-444, July 1943.

Index
A
Abscissa of convergence, 804
Acker.m, 473, 478
Ackermann's formula
in estimator form, 494
pole placement, 469
undamped oscillator, 470-471
AC motor actuators, 55
Activity, E. coli, 777-779
Actuators, 4, 707, 712, 741-742
AC motor, 55-56
DC motor, 52
hard-disk read/write head
assemble of hard disk, control
of, 759
rapid thermal processing (RTP)
system, 768
Actuator saturation, feedback
system with, 655
Adams prize, 15
Adaptation, biological, 783-784
Adaptive control, 681-683, 690
Additional poles effect of, 137,
145-146
Agilent Technologies, 313n1
Aircraft control, 275,729
design procedure, 729
lateral, 733
longitudinal, 741
nonlinear equations, 729
Aircraft coordinates, 730
Aircraft response, 143
Airy, G. B., 14, 215
Aizerman's conjecture, 685
Aliasing, 599, 615
Alternating current (AC)
induction motor, 55-56
Altimeter, 425, 741, 747
Altitude-hold autopilot, 741-747
Amplitude ratio, 96-97, 99-100
Amplitude scaling, 103, 156
Amplitude stabilization, 388
Analog computer compon ents,
443
Analog implementation, 275
Analog preﬁlters, 615, 630
Analog realization, 274-275
Analog-to-digital (A/D)
converters, 591, 614, 759
Analysis tools, 591, 621-622
Analytic continuation, 804
Angular velocity, 56
Anti-alias preﬁlters, 615-616
Anti-windup compensation for PI
controller, 657-658
Apollo, 561, 628-629, 787
Argument principle, 334-335
application of, 335-338
Armature voltage, 53-55
Arrival angles, rule for, 246
Assigned zeros, 521
Åström, Karl, 207n6, 628
Asymptotes
Angle of, 243, 244
center of, 243, 245
for negative locus, 282
Asymtotically stable
Lyapunov, 677
Asynchronous sampling, 620
Athans, M., 548, 561
Attitude hold, 744
Attractant, biological, 779-781
Augmented state equations with
integral control, 565
Automatic control, 1
Automatic landing and collision
avoidance systems, 2
Automobile suspension, 28
Automotive engine, control of
fuel-air ratio in, 747-754
Automotive fuel/air ratio, control
of, 747-754
Autonomous estimator, 516
example, 520, 521
Autopilot design,
via root locus, 275-281
via state-space, 729-747
Auxiliary variable, 467
B
Back emf voltage, 53-54
Bacteria, 777-779
Ball levitator, 644
Band center, 127n10
Band reject ﬁlter, 717
Bandwidth, 45, 362
Bang-bang control, 673-676
Barkai, N., 780
Barometric altimeter, 741
Battin, Dick, 628, 787
Bell, Alexander Graham, 318n3
Bell Laboratories, 318
Bellman, R., 16
Berg, H., 779, 784
Bertram, J. E., 640, 680, 690
BIBO stability, 147
Bilateral Laplace transforms,
804n1
Bilinear approximation, 602
Binary ﬁssion, 778
Biological systems, 778, 785-788
Black, H. S., 15, 216, 405
Block diagram, 4-7, 118-122
Blocking zeros, 534
Bode, H. W., 15-17, 97, 216,
317, 405
Bode.m, 97
Bode plots, 97, 309-314
Plotting techniques, 317-328
For nonminimum phase, 328
Bode's gain-phase relationship,
357-361
Boeing 747, lateral and
longitudinal control of a,
729-747
altitude-hold autopilot, 741-747
equations of motion, 729-730
linearized longitudinal motion
equations, 732
stability augmentation, 729
yaw damper, 733-741
Bounded input-bounded output
(BIBO) stability, 147-148
Boyd, S. P., 551
Brahe, Tycho, 69
Breakaway points, 239, 256-257
Break-in point, 239
Break point, 239
Bremmer, H, 101
Brennan, Richard P., 68
Bridged tee circuit, 47
848

Index
849
Bristol company, The, 215-216
Bryson, A. E., 485, 539, 561, 663
Bryson's rule, 485
Butterworth conﬁguration,
549n20
C
C2d.m, 597, 598, 600
Campbell, G. A., 101
Cancellations, transfer function,
112
Canonical forms, 445-457
Control, 445
Modal, 447
Observer, 451
Canon.m, 456
Capacitor, 148
Carburetor, 747, 749, 787
Cart and stick balancer, 41
Cascaded tanks, 583
Case studies
automotive fuel/air ratio,
control of, 747-754
Boeing 747, control of a,
729-747
E. coli chemotaxis, 777-780
hard-disk read/write head,
755-763
RTP systems in semiconductor
wafer manufacturing,
763-777
Satellite attitude control,
711-728
Catalytic converter, 747
Cauchy's Principle of the
Argument, 334n8
Centrifugal governor. (see
Fly-ball governor)
Centrifugal-pendulum
governor, 14
Characteristic equation, 459
Cheap control, 487-488
Chemotaxis dynamics, 776-786
Chemotaxis model, 782-785
Circle criterion, 683-690
Circuit with a current source,
equations for a, 47-49
Classical control, 17
Clegg integrator, 698
Closed-loop control, 1, 19
Closed-loop cruise control, 8
Closed-loop estimator, 723
Closed-loop frequency-response,
361-363
Closed loop stability, frequency
response determination, 331
Closed-loop system with sensor
dynamics, 193
Closed-loop transfer function,
154, 195, 331
Closed-loop zero of the system,
155, 476, 519
Collocated actuator, 35, 725
Collocated sensor, 35, 725
Command tracking, 10
Communication satellite, 633
Companion form matrix, 469
Compensated open-loop transfer
function, 360
Compensation design using
frequency response, 363-398
design considerations, 387-389
amplitude or gain
stabilization, 388
Bode plot, 396
complementary sensitivity
function, 393
performance frequency, 391
phase stabilization, 389
stability robustness, 391,
394, 396-397
in terms of the sensitivity
function, 389-391,
395-398
uncertainty in a plant model,
394-395
vector margin (VM), 397
water bed effect, 396
lag compensation, 375-377
for DC motor, 379-381
for temperature control
system, 377-378
lead compensation, 364-367
for DC motor, 367-371
for temperature control
system, 371-373
for a type 1 servomechanism
system, 373-374
lead-lag compensator, 381
PD compensation, 363-364
PID compensation, 381
for spacecraft attitude
control, 381-387
proportional-integral (PI)
compensation, 374-375
state-space control design, 464
Complementary sensitivity
function, 187, 538, 548
Complete transient response, 100
Complex margin, 348
Complex mechanical systems, 42
Complex zeros, 142-143
Bode plot of, 327-329
Computed torque, 638, 641, 647
Computer, digital control,
616-617
Computer-aided Bode plot for
complex poles and zeros,
327-329
Computer-aided control design
software, 18
Computer aids, 18
Conditionally stable compensator
design, 507-509
Conditionally stable systems,
354, 651, 666-668
Constant closed loop magnitude,
contours of, 401
Continuation locus, 247
Continuity relation, 62
Contour evaluation, 334
Control canonical form, 445
Control, basic equations of
advantage of feedback, 187
closed-loop system, 182
derivative control (D), 201
feedforward control by plant
model inversion, 212-214
fundamental relationship of
feedback systems, 187
historical perspectives,
215-216
integral control (I), 198-200
open-loop system, 182
proportional control (P),
196-198
proportional plus integral (PI)
control, 201-202
proportional plus integral plus
derivative (PID) control,
202-205
regulation, 185
sensitivity, 186-188
stability, 183-184
steady-state feedback gain, 186
tracking, 184-185

850
Index
Control (continued)
Ziegler-Nichols tuning of PID
controller, 206-212
Control characteristic equation,
465
Controllability, 450
Control responses of analog and
digital implementations, 607,
610
Control theory and practice, 215
Convolution, 90-91, 104-105,
810-811
integral, 89-91
response by, 86-91
Copernicus, Nicholas, 69
Corner frequencies, 365
Cosine signal derivative, 809
Cost function, 488, 708
Cover-up method of determining
coefﬁcients, 106
Crossover frequency, 349
cross over at -1, 396
Cruise control model, 25-28
Cruise control step response,
438-439
Cruise control transfer function
using Matlab, 113
D
D/A converters, 614
Dakota autopilot, 275-276
Damped natural frequency, 127
Damping ratio, 127, 144
Damping response in digital
versus continuous design,
626-628
Damp.m, 626
DC gain of a system, 601
DC gain of transfer function, 600
DC servo system, compensator
design for, 507-514
full-order compensator design
for, 507-509
in observer canonical form, 508
redesign of, 510-512
with reduced-order estimator,
509-510
second-order pole locations,
512-514
using SRL technique, 510-512
Decay ratio, 207-208
Decibel, 312
Delayed sinusoidal signal,
807-808
Demethylation, 782-783
Departure angles, root locus
design for, 257
Derivative, discrete control laws,
623
Derivative control (D), 201
Discrete, 623
Derivative feedback, 201
Derivative gain, 201
Describing functions, 658-669
conditionally stable system,
666-668
deﬁnition, 660
for a relay nonlinearity, 663
for hysteresis nonlinearity,
663-665
for saturation nonlinearity,
661-662
sizing the actuator, 659
stability analysis using,
665-669
Design criterion for spacecraft
attitude control, 359-361
Design synthesis, 135
Desired gain, graphical
calculation of, 250
Desoer, C. A., 561
Detroit Edison Company, 216
Differentiation, 104, 809
Digital autopilot, 628-629, 787
Digital control, 590-630
Digital-to-analog (D/A)
converter, 593, 614-615
Digitization, 591-594
analog-to-digital (A/D)
converter, 591
delay due to hold operation, 593
difference equations, 591
digital-to-analog (D/A)
converter, 593
discrete equivalents, 593
free running, 592
interrupt, 592
sampled data system, 592
Diophantine equation, 553
Dirac, Paul, 89
Direct current (DC) motor, 52
actuators, 52
gain of a system, 108-109
modeling, 53-56
position control, 194-195
reference input with, 475-477
shaft's rotational velocity, 53
sketch of, 53
transfer function, 54-55,
114-115
with unity feedback, 195
Direct design with rational
transfer functions, 552-556
Direct transfer function
formulation, 553
Direct transmission term, 437
Discrete control laws, 623
Discrete controller, 601, 604, 620
Discrete design, 593
analysis tools, 621
damping and step response in
digital versus continuous
design, 626-628
discrete root locus, 622
exact discrete equivalent, 621
example, 623-625
feedback properties, 622-623
Discrete equivalents, 593, 601
Tustin's (bilinear) method, 602
ZOH method, 605
Matched Pole-Zero, 607, 611
Discrete root locus, 622
Discrete signals, 592
Discrete systems
design by discrete equivalents
(emulation), 601
applicability limits, 613
bilinear approximation, 602
comparison of digital
approximation methods,
612-613
matched pole-zero (MPZ)
method, 607-611
modiﬁed matched pole-zero
(MMPZ) method, 611
Tustin's method, 602-605
zero-order hold (ZOH)
method, 605-607
hardware characteristics
analog-to-digital (A/D)
converters, 614
anti-alias preﬁlters, 615-616
computer, 618-619
digital-to-analog converters,
614-615
historical perspective, 628-629

Index
851
long division, for inversion,
595-597
relationship between s and z,
597-599
sample-rate selection
anti-alias preﬁlter, effect of,
619-620
asynchronous sampling, 620
disturbance rejection,
618-619
tracking effectiveness, 618
z-transform, 594-595
z-transform inversion, 595-597
Discrete transfer function, 595
Disk drive servomechanism,
531-535
Distinct real roots, 106-107
Distributed parameter systems,
42-44
Disturbance error transfer
function, 195
Disturbance input, 199
Disturbance rejection, 10
Disturbance-to-error transfer
function, 194
Disturbance to the process, 3
Divide and conquer state space
design, 436
Dominant second order poles,
477-479
Double-integrator plant, 31
Double pendulum, 73
Double precision, 617
Doyle, J. C., 547-548
Drebbel, Cornelis, 11
Drebbel's incubator, 11
Duality of estimation and control,
488
Duality relationships, 494-495
Dutch roll, 735
Dutch roll yaw damper, 427
Dufﬁng's equation, 701
Dynamic equations, 24
Dynamic response
amplitude and time scaling, 156
effects of zeros and additional
poles, 137-146
historical perspective, 156-157
pole locations, effect of,
124-131
stability, 146-156
state equations, 436-442
time-domain speciﬁcations,
131-136
Dynamic system with saturation,
449
E
E. coli, 777
E. coli genome, 778
E. coli motion, 782
Effect of zero using Matlab, 123,
137, 141
Eigenvalues, 453, 457
Eigenvector, 453
Eigenvector/eigenvalue problem,
453
Eigenvectors, 453
Eig.m, 453
Einstein, Albert, 70
Electric circuits, models of,
45-50
Electric power line conductor,
179
Electromagnet, 51
Electromechanical systems,
dynamic models of, 53-56
Electromechanical systems,
models of
gears, 56-57
loudspeakers, 50-52
motors, 52-56
Electronic feedback ampliﬁer, 15
Emulation design, 601
Bilinear, Tustins, 602
MPZ, 607, 611
ZOH, 605
EPROM, 617
Equations for a circuit with a
current source, 47-49
Equations of motion for rigid
bodies, 44-45
Equilibrium, 635, 637
Equivalent gain analysis
using frequency response,
658-669
using root locus, 648-658
Errors
constants, 189, 192
in equations for systems, 30
as a function of system type,
191
in output speed, 8
Error space, 528
Escherichia coli chemotaxis, 784
chemotaxis signal pathway, 781
exact adaptation, 782
importance of, 779-780
ligands, 781
model, 782-785
Estimator design, 489-501
Estimator error characteristic
equation, 490
Estimator equations, 496, 525
Estimator errors
closed-loop matrix for the
third-order case, 493
equation, 499, 516-517
Estimator modes
uncontrollability, 523
Estimator/observer, 464
Estimator pole selection, 499-501
Estimator SRL equation, 500
Euler's relation, 96
Evans, W. R., 16, 234, 287
Evans form of characteristic
equation, 234
Evans method, 287
Exact adaptation of activity, 782
Exact discrete equivalent, 605,
621
Excitation-Inhibition Model, 803
Expensive control, 486-487
Experimental models, 156
Exponentially decaying sinusoid,
808-809
Exponential order, Laplace
transforms, 804
Extra pole, effect of, 145
F
Factored zero-pole form, 113
Faraday, Michael, 69-70
Fast poles, 126
Feedback, ﬁrst analysis of, 6-10
Feedback law with integral
control, 526
Feedback loop, 405, 467, 493,
604
Feedback output error to state
estimate equation, 490
Feedback scheme for autopilot
design, 276
Feedback structure, 181-182, 192

852
Index
Feedback system for testing
stability, 152
Feedback system fundamentals,
10-11
Feedforward, 2
Feedforward control by plant
model inversion, 212-214
for DC motor, 213-214
Fibonacci numbers, 631
Final value theorem, 107-109,
144, 197, 199, 817-818
for discrete systems, 599-601
incorrect use of, 108
Finite zeros, 112, 134, 145
First order system
impulse response, 124
SRL for, 481
First-order system response, 125
step response, 135
First order term, 320
Fixed point arithmetic, 618
Flagellum, 779, 782
Flexible disk read/write
mechanism, 34
Flexible read/write for a disk
drive, 33-35
free-body diagrams of, 35
schematic of, 34
Flexible robot arm, 44
Fluid ﬂow models, 57-68
Fluid ﬂow rate, control of, 11
Fly-ball governor, 12
action of, 12-14
operating parts of a, 14
Fly-by-wire, 786
Folding, 599
z and s-plane, 599
Forced differential equations
solution, 110
Force equilibrium, 62
Fourier, 85, 98, 157
Fourth-order partial differential
equation, 43
Fourth order system in modal
canonical form, 448
Foxboro Company, 215
Franklin, G. F., 560, 591, 598
Fraser, Don, 628, 787
Free-body diagram for cruise
control, 26
Free running, 592
Frequency response, 309-405
Bode plot techniques, 317-328
advantages, 318
for complex poles and zeros,
324-327
composite curve, 322
computer-aided, 327-328
peak amplitude, 322
for real poles and zeros,
323-324
Bode's gain-phase relationship,
357-361
break points, 320
of a capacitor, 312
closed-loop
frequency-response, 361-363
compensation, 363-398
equivalent gain analysis using,
658-669
experimental, 313
frequency-response plot, 311
historical perspective, 404-405
of lag-lead compensation, 521
of lead compensator, 312-317
LTR design, 547
magnitude, 311, 321
neutral stability, 331-333
nonminimum phase, 328
steady-state errors, 330
velocity-error constant,
330-331
Nyquist stability criterion,
333-348
open-loop frequency-response,
350
partial-fraction expansion, 310
phase, 311, 321
plot vs. time, 311
presentation
inverse Nyquist diagram,
404
Nichols chart, 400-404
resonant peak versus phase
margin, 353
spacecraft attitude-control
problem, 359-361
stability margins, 348-357
from Nichols chart for
complex system,
403-404
stability speciﬁcation, 404
time delay, 398-400
Frequency shift, 734
Fuel-air ratio control, 790
Fuel injection, 749
Fuller, 12, 14
Full-order estimator, 489-495
G
Gain margin (GM), 348-349
Gain phase relationship, 357
Gain stabilization, 272
Galilei, Galileo, 69
Gears, 56-57
Golden Nugget airlines, 304, 426
Gyroscope, 734
H
Halley, Edmund, 68
Hanging crane, 40-42
Hard-disk read/write head
assemble of hard disk, control
of, 755-763
actuators, 759
Bode plot of the lead design,
760
lead-lag design, 760
linear model, 759-760
optimal controller or adaptive
control, 762
sensors, 759
step response of, 761
Hardware characteristics of
discrete systems
analog-to-digital (A/D)
converters, 614
anti-alias preﬁlters, 615-616
computer, 616-617
central processor unit
(CPU), 616
DSP chips, 617
programmable read-only
memory (EPROM) or
ﬂash memory, 617
random-access memory
(RAM), 616-617
read-only memory (ROM),
616
digital-to-analog converters,
614-615
Heat and ﬂuid-ﬂow models
heat ﬂow, 58-61
incompressible ﬂuid ﬂow,
61-68
Heat exchanger

Index
853
closed-loop Simulink diagram,
560
control effort for, 561
design with pure time delay,
558-559
root locus for a, 561
tuning of, 209-212
Heaviside, Oliver, 156
operational calculus for solving
differential equations, 156
Helicopter near hover, 295, 580
Hessenberg matrix, 572
High frequency plant uncertainty,
388
Homogeneous differential
equation, 109-110
Hot air balloon, 795
Huygens, Christian, 14
Hydraulic actuators, 65-68
equations of motion, 65-67
linearization and simpliﬁcation
equations, 67-68
Hydraulic piston, 63-64
Hysteresis nonlinearity, 668-669
I
Ideal op-amp, 48
Impulse, 89
Impulse.m, 126
Impulse response, 126-127
Impulse signal, 89
Incompressible ﬂuid ﬂow, 61
Inertial acceleration, 25
Inertial reference frame, 25
Initial value theorem, 816-817
Inner-loop design, 742
Input ﬁlter, 6
Instrument Landing System
(ILS), 10
Integral control (I), 198-200
Discrete, 623
Integral feedback, 198
Integrator, 49-50
Integrator antiwindup circuit,
655-658
feedback system, 656
for a PI controller, 657-658
purpose of, 656
Internal model principle, 532
Internal stability, 149
Interrupt, 592
Inverse Laplace transform, 95,
99, 141
by partial-fraction expansion,
105-107, 813-816
Inverse nonlinearity, 641
Inverse Nyquist diagram, 404
Inverse transform, 98
Inverted pendulum, 41
Inv.m, 455
J
James, H. M., 628
K
Kalman, R. E., 16
Kalman Filter (LQF), 560
Kendall, David, 215
Kepler, Johannes, 69
Keynes, John Maynard, 69
Khalil, H., 659
Kharitonov Theorem, 156
Kirchhoff's current law (KCL),
46-47
Kirchhoff's voltage law (KVL),
46, 95
Kuo, B., 56
L
Lag compensation, 265, 270-272,
523
Lamp nonlinearity, 781
LAPACK, 453
Laplace, Pierre-Simon, 156-157
Laplace transform, 25, 91, 310,
521, 596-597
convolution, 104-105, 810-811
of cosine signal, 809
delayed sinusoidal signal, 807
derivative of a signal, 809
of derivative of a signal, 104
ﬁnal value theorem, 107-109
of the impulse response, 92
of the input, 94
of integral of a time function,
104, 809
inverse, 95, 99
key property of, 98
L-, 101, 804
multiplication by time, 105
one-sided (or unilateral), 101
principle of superposition, 103,
805
procedure for determining, 98
properties of, 103-105,
805-813
ramp response of a ﬁrst-order
system, 811
shift in frequency, 808
shift in the frequency, 104
of a signal f (t), 97
of sinusoid function, 102-103
to solve differential equations,
109-111
of step and ramp functions,
102
table of, 806
time delay, 103, 807
time product, 105, 811
of sinusoidal signal,
812-813
time scaling, 104, 807-808
two-sided, 101
of unit-impulse function, 102
of y(t) and u(t), 98
Law of generators, 52
Law of motors, 50
Lead compensation, 265-270,
364-374
circuit of, 274-275
Lead-lag compensator, 381
Lead ratio, 366
Least common multiple, 544
Ligands, 781
Limit cycle, 652
Linear analysis methods, 37
Linear closed-loop RTP response
for robust servomechanism
controller, 773
Linearization, 641, 707
by inverse nonlinearities, 647
of motion in a ball levitator,
643-646
by nonlinear feedback, 646-647
of nonlinear pendulum,
642-643, 647
of rapid thermal processing
(RTP) system, 647-648
by small-signal analysis,
641-642
of water tank revisited, 646

854
Index
Linear models of aircraft motion,
740-742
Linear Quadratic Gaussian
(LQG) problem, 560
Linear quadratic regulator (LQR)
design, 479, 485-488
limiting behavior of regulator
poles, 486-488
robustness properties, 488
for tape drive, 485-486
Linear system analysis,
112-118
cruise control transfer
function, 113
DC motor transfer function,
114-115
satellite transfer function,
116-118
Linear time-invariant systems
(LTIs), 85, 89, 98, 100
stability of, 148-149
Liquid-level control, 11
L- Laplace transform,
101, 804
Loglog.m, 97, 313
Logspace.m, 97, 313
Loop gain, 9
Loop transfer recovery (LTR),
547-549
frequency response plots for,
550
for nonminimum-phase
systems, 549
plant inversion, 548
for satellite system, 549-550
Simulink block diagram for,
550
use of, 548
Loudspeakers, 50-52
with circuits, 52
equations of motion, 51-52
geometry for a, 51
lqe.m, 549, 551
lqr.m, 485, 486
lsim.m, 116,118
LTR, 547-549
Luenberger, D. G., 561
Lumped parameter model, 44
Lyapunov, A. M., 15-16,
639, 690
Lyapunov function, 640
Lyapunov stability analysis,
677-683
M
Magnetic data storage devices, 2
Magnetic levitation, 299, 644
Magnitude
frequency response, 96, 311
Magnitude condition, 249
Magnitude plot
gain and phase margin, 350
transfer function classes, 319
M and N circles, 400
Manual control, 1
Mason's rule, 123, 467
Matched pole-zero (MPZ)
method, 607-611
Mathematical model, 6
of dynamic response of a
system, 10
Mathematical relationships of a
system in graphical form, 7
Matlab, 18, 96
a\b, 554-555
acker.m, 470,495
axis, 343, 347
aircraft response using,
143-144
bode.m, 97, 371, 551
canon.m, 456
commands, 835-839
computing roots, 153
dynamics of a system, 37
eig(A), 453
ezplot, 154
feedback.m, 123, 278
estimator (ﬁlter) gain, 724
impulse.m, 126, 492, 498
impulse response by, 131
initial.m, 492, 498
inv.m, 455-456
linear system analysis, 112-118
cruise control transfer
function, 113
DC motor transfer function,
114-115
satellite transfer function,
116-118
linmod.m, 642
linmod2.m, 642
loglog, 97, 313
logspace, 371
lqe.m, 551
lqr.m, 485, 550
lsim.m, 116
margin.m, 551
max.m, 397
nichols.m, 402
nyquist.m, 340, 343, 347
ones, 116
parallel, 123
place.m, 472, 495
plot.m, 37, 117
poly.m, 111
printsys, 113
pzmap, 124
residue.m, 107
rlocﬁnd, 418
rlocus, 248, 253-256
rltool, 257-259
roots.m, 154, 462-463
semilogx, 97, 313, 328
series.m, 123
sqrt.m, 533
ss.m, 456, 463
ssdata.m, 456
ss2tf.m, 458, 461
ss2zp.m, 444
step.m 27, 37
transformations using, 115-116
tf.m, 114, 116, 126
tf2ss.m, 446
tf2zp.m, 113, 444
tzero.m, 463
Maxwell, James Clerk, 14-15,
70, 215
Mayr, O., 11
Mechanical systems
combined rotation and
translation, 39-42
complex, 42
rotational motion, 31-39
ﬂexible read/write for a disk
drive, 33-35
satellite attitude control
model, 31-33
simple pendulum, 35-39
translational motion, 24-31
cruise-control model, 25-28
quarter-car model, 28-31
Méchanique céleste (Celestial
Mechanics), 156
Mello, B. A., 782
Memoryless nonlinearity, 648
Method of computed torque, 641
Microphone, 79
Minimum phase systems and
Bode plot, 329

Index
855
MIT rule, 681
Modal canonical form, 447
Model-following design, 539
Modern control, 17
Modes of the system, 112
Modiﬁed matched pole-zero
(MMPZ) method, 611
Moler, Cleve, 288
Monic polynomial, 236
Motors, 52-56
AC, 55
DC, 53
N
Napoleon, 157
Natural frequency of system, 459
Natural mode of system, 459
N circles, 400
Natural response of the system,
124
Negative feedback, 119
Negative root locus, 241
Neutrally stable, 149, 209
Newton, Isaac, 68-69
Newton's law of motion
free-body diagram, 25
to one-dimensional rotational
systems, 31
second, 68
for translational motion, 24
Newton's laws, 41, 53
Newton's laws of motion, 44
Nichols, N. B., 628
Nichols chart, 400-404
Nichols plot, 353
Node analysis, 46
Non-causal system, 91
Noncollacated system, 261
Nonlinear rigid body equations of
motion in body-axis
coordinates, 729-730
Nonlinear systems
changing overshoot and
saturation nonlinearity,
649-650
circle criterion, 683-690
describing functions, 658-669
historical perspective, 690
hysteresis nonlinearity,
668-669
integrator antiwindup circuit,
655-658
Lyapunov stability analysis,
677-683
need to study, 639
with no dynamics, 649
nonlinear characteristics, 641
Nonminimum-phase zero, 140
Nonminimum phase systems
Bode plot, 329
LTR, 548
Notch compensation, 265,
272-275, 654
Notch ﬁlter, 717-720
pole-zero pattern, 718
Nyquist, H., 15, 405
Nyquist frequency, 599
Nyquist rate, 615
Nyquist's frequency-response
stability test, 147
Nyquist-Shannon sampling
theorem, 615
Nyquist stability criterion,
333-348, 392
Nyquist Plot
for an open-loop unstable
system, 344-347
characteristics, 347-348
hysteresis nonlinearity, 668
for LQR design, 483
for a system with multiple
crossover frequencies,
355-357
for a second-order system,
338-341
for a third-order system,
341-344
O
Observability, 494
Observability matrix, 494
Observer canonical form,
451-452
One-sided (or unilateral) Laplace
transform, 101
Op-amp integrator, 49-50
Op-amp simpliﬁed circuit, 49
Op-amp summer, 49
Open loop, 8
Open-loop control system, 1, 7-8
Open-loop output speed, 8
Operational ampliﬁer, 48
Optimal control, 479
Optimal design, 708
Ordinary differential equations
(ODEs), 16-17, 123
Oscillatory time response,
129-131
Oswald, R. K., 760
Output matrix, 437
Overshoot, 132-134
versus damping ratio for the
second-order system, 134
P
Padé approximant, 286, 558
Parseval's theorem, 812
Partial-fraction expansion,
105-107, 148, 310
using cover-up method, 106
Partial-fraction expansion , 124
Passive circuits, 45
Peak amplitude, 316
Peak time, 132-134
Pendulum, 35-39
control law, 466-469
moment of inertia, 36
reduced-order estimator for,
497-498
Simulink numerical
simulation, 40
time history, 37
transfer function, 36
Phase condition, 241
Phase margin (PM), 349,
352-353
Phase stabilization, 273
Phillips, R. S., 628
PhilosophiæNaturalis Principia
Mathematica, 68-69
Phugoid mode, 742
Plant, 5
Plant inversion, 212
Plant transfer function, 191
Plant uncertainty, 388
Poincaré, 702
Pole assignment, 465
Pole locations for a system,
124-131
Poles of a system, 105, 111-112
Pole-zero patterns on dynamic
response, 145-146

856
Index
Pontryagin, L. S., 16
Position error constant, 189, 190
Positive feedback, 119
Positive root locus, 241
Power db, 318
Preﬁlters, 781
Principle of superposition, 86, 103
Process noise, 499
Process reaction curve, 206-207
Proportional control (P), 196-198
Proportional feedback, 196
Proportional gain, 196
Proportional-integral-derivative
(PID) control, 16, 202-203,
714-721
for a DC motor position control,
204-205
of motor speed, 203-204
Ziegler-Nichols tuning of,
206-212
Proportional-integral (PI) control,
154, 201-202
Prototype testing, 709
Proximate Time Optimal Servo
(PTOS), 675-676, 758
Pure time delay, 556-559
Pyrometers, 766
Q
QR algorithm, 453
Quality factor, 412
Quarter-car model, 28-31
Quarter decay ratio, 208-210
R
Ragazzini, J. R., 628
Ramp function, 102
Rapid thermal processing (RTP)
system
actuators, 768
block diagram of, 767
closed-loop system equations,
771
demands on an, 763-764
design of, 766-767
design with nonlinearities,
773-775
feedback gain matrix computed
from Matlab, 771
generic, 765
laboratory model, 767
lamp geometries of, 766
lamp nonlinearity, 775
linear closed-loop RTP
response for PI controller, 770
linear model, 768-769
optimal design, 769-770
performance speciﬁcations,
767-768
sensors, 768
Simulink block diagram,
772-773
temperature control, 776
temperature nonuniformity,
770-771
temperature trajectory, 765, 772
Reference input with full-state
feedback, 473-477
control equation, 474
direct current (DC) motor,
475-477
gain calculation, 474
state-space control design,
520-525
Regulators, 1
Relay nonlinearity, 649
Reset control, 655
Reset windup, 655
Resonant frequency, 401
Ring-laser gyroscope, 734
Rise time, 131-132
RLTOOL, 257-259
Robustness, 11
of integral control, 200
of system type, 192
Robust tracking, 525-539
Robustness constraints, 389-396
Roll mode, 735
Room temperature control
system, component block
diagram of a, 4
Root locus, 714, 725, 728
analog and digital
implementations, 274-275
analysis and design of system
with limit cycle using,
652-655
arrival angles, rule for, 246
asymptotic, 244
of basic feedback system,
235-240
for combined controller and
estimator, 504-505
with complex multiple roots,
263-264
continuation locus, 247
control of a small airplane
using, 275-281
for DC servo pole assignment,
509
departure angles, rule for, 246
dynamic compensation, design
using, 264-275
equivalent gain analysis using,
648-658
Evans's method, 236
guidelines for determining,
240-251
for a heat exchanger, 561
historical perspective, 287-288
of lag-lead compensation, 522
for L(s), 248-249
magnitude condition, 249-250
of a motor position control,
237-239
negative or 0
◦, 241, 281-284
for noncollocated ﬂexibility,
261-263
parameters for, 249-251
phase condition, 241
positive or 180
◦, 241-248
real-axis parts, 243
of a reduced-order controller,
507
with respect to a plant
open-loop pole, 239-240
for satellite attitude control with
PD control, 252-254
for satellite control with a
transition value for pole,
256-257
for satellite control with
collocated ﬂexibility, 259-261
for satellite control with lead
having small value for pole,
255-256
for satellite control with
modiﬁed PD control, 254-255
stability of conditionally stable
system using, 650-651
time delays and, 286-287
using lag compensation,
270-272

Index
857
using lead compensation,
266-270
using notch compensation,
272-275
using two parameters in
succession, 285-286
with washout circuit, 737
of yaw damper, 736
Root-locus form, 237
Root-locus method, 16
Root-mean-square (RMS) value
of the control, 549
Rosenbrock, H. H., 562
Rotational motion, 31
Routh, E. J., 15, 405, 680
Routh array, 150, 152, 154
Routh test, 151-152, 156
Rudder, 730
Run-to-run control, 801
S
Saberi, A., 548
Safonov, M., 561
Sample and Hold devices, 614
Sampled data system, 592
Sample period, 592
Sample rate, 592
Sample rate selection, 593
Sastry, S. S., 680
Satellite attitude control model,
31-33, 205-206
design of, 711-728
historical perspective, 786-788
loop transfer recovery (LTR),
549-550
matched pole-zero (MPZ)
method, 609-611
rotational motion, 31-33
root locus
for satellite attitude control
with PD control,
252-254
for satellite control with a
transition value for pole,
256-257
for satellite control with
collocated ﬂexibility,
259-261
for satellite control with lead
having small value for
pole, 255-256
for satellite control with
modiﬁed PD control,
254-255
schematic of, 32
state-space control design,
504-507
in state-variable form,
437-438
symmetric root locus
(SRL)design, 481-483
Saturation nonlinearity, 649
Scaling, 156
Schmitt trigger circuit, 663
Schmitz, E., 44
Second-order systems, 129-130
Segway, 42
Sensitive changes, 11
Sensitivity function, 187
of time response to parameter
changes, 215
Sensor noise, 499
Sensors
collocated, 725
hard-disk read/write head
assemble of hard disk, control
of, 759
rapid thermal processing (RTP)
system, 768
selection and placement, 5, 706
Servomechanisms, 16
Servo systems, 1
Settling time, 132, 134-136
Short-period modes, 742
Sign errors, 30
Simple compensation
PID/lead-lag design, 707
Simple feedback system, 3-6
Simulink, 18, 33
Simulink diagram
block diagram, 38-39
for the antiwindup, 658
closed-loop, heat exchanger,
560
for nonlinear closed-loop RTP
system, 780, 783
for RTP closed-loop control,
772
simulating E. coli chemotaxis,
784
Simulink nonlinear simulation,
773
Simulink simulations, 534, 549,
649
Single-Input-Single-Output
(SISO) systems, 435
Sinusoid function, 102-103
Slow poles, 126
Smith compensator, 557
Solid state ﬂash drives (SSD), 787
Space station digital controller,
direct discrete design of,
623-625
Speed control, system type for,
191
Speed error, 8
Speedometer, 7
Spiral mode, 735
Spirule, 287
s-plane, 136
s-plane plot, 128
1/s2 plant, 33
S-shape of the step response
curve, 207
Stability, 10, 124, 128, 183-184
allowable region for, 155
analysis and design based on,
14-15
bang-bang control,
673-676
Maxwell's and Routh's
stability problem, 15
phase plane, 670-673
analysis using describing
functions, 665-669
BIBO stability for a capacitor,
147-148
of LTI system, 148-149
Lyapunov stability analysis,
677-683
Lyapunov redesign of
adaptive control,
681-683
Lyapunov's position
feedback system,
680-681
for second-order system,
679-680
necessary condition for,
149-150
Routh, 150-154
versus parameter range,
152-153
Stability margins, 348-357
of a conditionally stable system,
354-355
Stability of motion, 15

858
Index
Standard second-order system
impulse response, 128
Star tracker, 712
State of the system, 437
State-space control design
advantages of, 434-436
analog-computer
implementation, 443-444
block diagrams and, 443-444
control canonical form,
445-456
in modal canonical form,
447
normal modes of the system,
447
classical control design, 435
compensator design
for DC servo system,
507-514
frequency-response plots,
505
poles of combined control
law and estimator,
502-503
reduced-order compensator
transfer function, 503
regulator, 501
for satellite altitude control,
504-507
transfer function, 503-504
direct design with rational
transfer functions, 552-556
Diophantine equation, 553
general controller in
polynomial form, 552
monic polynomials, 553
pole placements, 554-555
polynomial transfer function
model, 555-556
discrete models, 628
equations in state equations,
444-463
characteristic equation, 459
controllability matrix, 450
dynamic response from,
457-463
in modal canonical form,
448-451
observer canonical form,
451-452
state transformations, 449
of tape drive, 461-463
transformation of thermal
system from control to
modal form, 454-455
zero(s) of the thermal
system, 460-461
estimator design approach
duality of estimation and
control, 494-495
full-order estimators,
489-491
left companion matrix, 492
observer canonical form,
492-494
reduced-order estimators,
495-500
selection of estimator pole
locations, 499-501
for simple pendulum,
491-495
SRL estimator design for a
simple pendulum,
500-501
extended estimator, 543-547
full-state feedback, control-law
design for, 463-477
Ackermann's formula, 469
characteristic equation of
closed-loop system, 465
companion form matrix, 469
compensation, 464
control canonical form,
467-468
control law, 464-469,
472-473
estimator/observer, 464
observer canonical form
with a zero, 472-473
reference input with,
473-477
historical perspective,
559-562
integral control, 525-526
of a motor speed system,
526-528
using error-space system,
535-539
model-following design,
539-543
for disk drive, 540-543
as modern control design, 435
normal form, 435
ordinary differential equations
(ODEs) of physical dynamic
systems, 435
phase plane, 435
pole-placement design approach
comments on, 488-489
dominant second-order
poles, 477-479
linear quadratic regulator
(LQR) design, 479,
485-488
symmetric root locus
(SRL)design, 479-485
reference input with estimator
general structure, 515-518
reduced-order
estimator, 520
second-order
servomechanism
system, 520-524
selecting gain, 524-525
robust tracking, 528-535
disk-drive servomechanism,
531-535
in state-variable form, 436
bridged tee circuit, 439-440
cruise control step response,
438-439
DC motor, 441
ﬂexible disk drive, 442
loudspeaker with circuit, 441
satellite attitude control
model, 437-438
system description in,
436-442
for time-delayed system,
556-559
State-variable approach to control
theory, 15
State-variable design, 16
Steady-state behavior of the
system, 93
amplitude ratio, 99
Steady-state error, 193, 367
to polynomial inputs, 188-195
Steady-state tracking and
disturbance rejection,
194-195
of motor speed, 546-547
Steady-state tracking error, 199
Step function, 102
Step-response transform, 128
Step response with Matlab, 27

Index
859
Successive loop closure, 284
Summer circuit, 49
Sylvester equation, 541
Sylvester matrix, 554
Symbols for linear circuit
elements, 45-46
Symmetric root locus (SRL)
design, 479-485, 510-514,
708
for an inverted pendulum,
483-485
closed-loop step response, 722
frequency response, 723
of lateral dynamics, 740
for the satellite system,
481-483
of satellite system, 722
for servo speed control, 481
SRL estimator design for a
simple pendulum, 500-501
System error, 6
System modeling diagrams. (see
Block diagram)
System stability, 146
System type for regulation and
disturbance rejection,
194-195
System type for tracking,
189-193
Systems biology, 777
T
Tape drive, 162
analysis of state equations,
461-463
example, 455-457
LQR design, 478-479
Temperature control, 4
Tachometer feedback, 192-193
Taylor, George, 215
Temperature sensor, 12
Thermostat, 3, 5-6
Time constant, 124
Time-domain speciﬁcations
overshoot, 132-134
peak time, 132-134
rise time, 132
settling time, 132, 134-136
Time invariance, 86-90
Time-invariant systems, 89
output for a general input, 91
Time sequences associated with
z-plane, 600
Tischler, M. B., 356
Torque-speed curves for a servo
motor, 55
Torricelli, 690
Tracking, 1
Trankle, T., 303
Transfer function, 27, 30-31,
35-36, 41-42, 236
for an RC circuit, 95-96
from block diagram, 121-122
Bode form, 319
of a capacitor, 312
of the closed-loop system, 524
compensation with, 265
complex zeros, 142-143
DC gain of, 600
DC gain of the system, 109
direct current (DC) motor,
54-55
frequency response and, 91-101
gears, 57
high-order system with a
characteristic process, 207
pendulum, 467
poles from state equations, 459
of a simple system using
Matlab, 122-123
for the system, 93-95
thermal system, 458-459
Transient response, 98-100
complex zeros, effect of, 143
settling time, 134-136
for the system, 153, 155
zero, effect of, 141
Transportation lag, 556
Transpose, 437
Truxal's formula, 195, 519, 520
Type k system, deﬁnition, 192
Tungsten halogen lamp, 766
Tustin's method, 602-605
Two-mass system, suspension
model, 28-31
Two-sided Laplace transform,
101
U
Ultimate gain, 208
Ultimate period, 208
Ultimate sensitivity
method, 207
Ultra-large-scale integrated
(ULSI) circuit, 763
Uncontrollable systems, 471
Undamped natural
frequency, 127
Uncontrollability of estimator
modes, 517
Uncontrollable system, 471
Unit-impulse function, 102
Unit-step function, 90
Unity feedback system, 120
Unstable, 124
Unstable system, 146, 149
Upper companion form, 469
USCG Cutter Tampa, 304
V
Van der Pol's equation, 701
Vector margin, 348, 353
Velocity error constant, 190
Vidyasagar, M., 680
Voice coil, 51
W
Washout, 735
Water tank height, equations
for, 62
linearization of, 64-65
Watt, James, 12
Watt's ﬂyball governor, 13
Wheel mass, determining, 30
Widnall, Bill, 628
Winnie Mae, 786
Woodson, H. H., 634
Wright brothers, 786
Y
Yakubovich, 686
Yaw damper, 733-741
Young's modulus, 43
Z
Zadeh, L., 561
Zames, G., 561

860
Index
Zero-order hold (ZOH), 593
Zero-order hold (ZOH) method,
605-607
Zeros of a system, 105, 111-112,
123
effects of, 137-146
Zero assignment, 518
Zero degree locus, 281
Ziegler-Nichols tuning of PID
controller, 206-212
Zirconia sensor, 748
z-plane, 598
z Transform, 591

Table of Laplace Transforms
Number
F(s)
f(t), t ≥0
1
1
δ(t)
2
1
s
1(t)
3
1
s2
t
4
2!
s3
t2
5
3!
s4
t3
6
m!
sm+1
tm
7
1
(s + a)
e−at
8
1
(s + a)2
te−at
9
1
(s + a)3
1
2!t2e−at
10
1
(s + a)m
1
(m −1)!tm−1e−at
11
a
s(s + a)
1 −e−at
12
a
s2(s + a)
1
a(at −1 + e−at)
13
b −a
(s + a)(s + b)
e−at −e−bt
14
s
(s + a)2
(1 −at)e−at
15
a2
s(s + a)2
1 −e−at(1 + at)
16
(b −a)s
(s + a)(s + b)
be−bt −ae−at
17
a
(s2 + a2)
sin at
18
s
(s2 + a2)
cos at
19
s + a
(s + a)2 + b2
e−at cos bt
20
b
(s + a)2 + b2
e−at sin bt
21
a2 + b2
s

(s + a)2 + b2
1 −e−at 
cos bt + a
b sin bt


Chronological History of Feedback Control
Automotive stability augmentation systems
Farm tractor auto-steering via GPS
Driverless car
GPS
Unmanned aircraft
High precision disk drive control
Computer-aided control design
Internal model control
Feedback control of automotive engines
Aircraft auto-landing
Apollo digital autopilot
Aircraft stability augmentation
LQG design
Inertial navigation
Microprocessor
Maximum principle
Dynamic programming
Numerical optimization
Optimal filtering
Sampled data systems
Root locus
Nyquist stability
Frequency-response tools
Feedback amplifier
Autopilot
Stability analysis of governor
Routh stability
Fly-ball governor
Incubator
1600s 1700s 1800s
1910
1920
1930
1940
1950
1960
1970
1980
1990
2010
2000

MATLAB Function (.m ﬁle)
Description
Page (s)
acker
Ackermann's formula for pole placement
470, 478, 491, 495
bode
Bode frequency response
97, 313, 371, 397
c2d
Continuous-to-discrete conversion
603, 606, 626
canon
State-space canonical forms
456
conv
Polynomial multiplication
107
damp
Damping and natural frequency
626
eig
Eigenvalues and eigenvectors
455, 457
feedback
Feedback connection of two systems
123, 278, 626
impulse
Impulse response
126, 131, 492
initial
Initial condition response
492, 498
inv
Matrix inverse
455, 456
logspace
Logarithmically spaced frequency points
97, 550
lqe
Linear Quadratic Estimator design
551
lqr
Linear Quadratic Regulator design
486, 550
lsim
Linear system simulation
116, 118
margin
Gain and phase margins
371, 417, 551
nyquist
Nyquist plot
340, 343, 347
pade
Padé approximation for time delay
parallel
Parallel connection of two systems
123
place
Pole placement
472, 495, 499, 504, 508
plot
Plot function
37, 115, 117, 118
poly
Form polynomial from its roots
111
pzmap
Pole-zero map
124
residue
Residues in partial fraction expansion
107, 111, 814
rlocﬁnd
Find root-locus gain
251, 263
rlocus
Root locus
248, 254, 256
rltool
Interactive root-locus tool
258, 269
roots
Roots of a polynomial
153, 462, 472
series
Series connection of two systems
123, 551, 626
sqrt
Square root
533
ss2tf
State space to transfer function
458, 461, 462
ss2zp
State space to pole-zero conversion
444
ss
Conversion to state space
439, 456, 461, 551
ssdata
Create a state-space model
456
step
Step response
27, 37, 115, 153, 155
tf2ss
Transfer function to state space
446
tf2zp
Transfer function to pole-zero conversion
113, 114, 444
tf
Conversion to transfer function
27, 37, 97, 155, 603
tzero
Transmission zeros
461, 463

Design Aids
Closed Loop
t
Mp
tp
ts
tr
1
0.9
0.1
1%
e
r
y/r
Y



R
KG(s)
Amplitude ratio, T(s)
Resonant peak, Mr
db
Bandwidth, vBW
20
0
20
3
10
1
0.1
0.7
v (rad/sec)
Im(s)
Re(s)
u  sin1z
vn
vd
s
Open Loop
Design Relations
W1
W2
1
G
v
v
PM
GM
v1
vc
180
1
G
ts = 4.6
σ
tr = 1.8
ωn
σ = ζωn
ωd = ωn

1 −ζ 2
ess =
1
1 + K0
,
K0 = |G(jω)|ω=0
|E| <
1
1 + W1
, ω < ω1
ωBW = ωc
for PM = 90◦
ωBW = 2ωc
for PM = 45◦
Mr ∼=
1
2 sin(PM/2)
Mp = 5%,
ζ = 0.7
Mp = 15%,
ζ = 0.5
Mp = 35%,
ζ = 0.3
ζ ∼= PM
100
for PM < 70◦

