
Advanced Modern Algebra
by Joseph J. Rotman
Hardcover: 1040 pages
Publisher: Prentice Hall; 1st edition (2002); 2nd printing (2003)
Language: English
ISBN: 0130878685
Book Description
This book's organizing principle is the interplay between groups and rings, 
where "rings" includes the ideas of modules. It contains basic definitions, 
complete and clear theorems (the first with brief sketches of proofs), and 
gives attention to the topics of algebraic geometry, computers, homology, 
and representations. More than merely a succession of definition-theorem-proofs,
this text put results and ideas in context so that students can appreciate why
a certain topic is being studied, and where definitions originate. Chapter 
topics include groups; commutative rings; modules; principal ideal domains; 
algebras; cohomology and representations; and homological algebra. For 
individuals interested in a self-study guide to learning advanced algebra and
its related topics. 
Book Info
Contains basic definitions, complete and clear theorems, and gives attention
to the topics of algebraic geometry, computers, homology, and representations.
For individuals interested in a self-study guide to learning advanced algebra
and its related topics.

To my wife
Marganit
and our two wonderful kids,
Danny and Ella,
whom I love very much


Contents
Second Printing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
viii
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
ix
Etymology
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
xii
Special Notation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
xiii
Chapter 1
Things Past . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1. Some Number Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2. Roots of Unity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
1.3. Some Set Theory
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
Chapter 2
Groups I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
2.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
2.2. Permutations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
2.3. Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
2.4. Lagrange's Theorem
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
2.5. Homomorphisms
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
2.6. Quotient Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
2.7. Group Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
Chapter 3
Commutative Rings I
. . . . . . . . . . . . . . . . . . . . .
116
3.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
116
3.2. First Properties
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
116
3.3. Polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
126
3.4. Greatest Common Divisors . . . . . . . . . . . . . . . . . . . . . . . . . .
131
3.5. Homomorphisms
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
143
3.6. Euclidean Rings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
151
3.7. Linear Algebra
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
158
Vector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
159
Linear Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . .
171
3.8. Quotient Rings and Finite Fields . . . . . . . . . . . . . . . . . . . . . . .
182
v

vi
Contents
Chapter 4
Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
198
4.1. Insolvability of the Quintic . . . . . . . . . . . . . . . . . . . . . . . . . .
198
Formulas and Solvability by Radicals
. . . . . . . . . . . . . . . . . . .
206
Translation into Group Theory . . . . . . . . . . . . . . . . . . . . . . .
210
4.2. Fundamental Theorem of Galois Theory . . . . . . . . . . . . . . . . . . .
218
Chapter 5
Groups II
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
249
5.1. Finite Abelian Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
249
Direct Sums . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
249
Basis Theorem
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
255
Fundamental Theorem
. . . . . . . . . . . . . . . . . . . . . . . . . . .
262
5.2. The Sylow Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
269
5.3. The Jordan-H¬®older Theorem . . . . . . . . . . . . . . . . . . . . . . . . .
278
5.4. Projective Unimodular Groups . . . . . . . . . . . . . . . . . . . . . . . .
289
5.5. Presentations
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
297
5.6. The Nielsen-Schreier Theorem . . . . . . . . . . . . . . . . . . . . . . . .
311
Chapter 6
Commutative Rings II . . . . . . . . . . . . . . . . . . . . .
319
6.1. Prime Ideals and Maximal Ideals . . . . . . . . . . . . . . . . . . . . . . .
319
6.2. Unique Factorization Domains . . . . . . . . . . . . . . . . . . . . . . . .
326
6.3. Noetherian Rings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
340
6.4. Applications of Zorn's Lemma . . . . . . . . . . . . . . . . . . . . . . . .
345
6.5. Varieties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
376
6.6. Gr¬®obner Bases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
399
Generalized Division Algorithm . . . . . . . . . . . . . . . . . . . . . .
400
Buchberger's Algorithm
. . . . . . . . . . . . . . . . . . . . . . . . . .
411
Chapter 7
Modules and Categories
. . . . . . . . . . . . . . . . . . .
423
7.1. Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
423
7.2. Categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
442
7.3. Functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
461
7.4. Free Modules, Projectives, and Injectives . . . . . . . . . . . . . . . . . . .
471
7.5. Grothendieck Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
488
7.6. Limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
498
Chapter 8
Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
520
8.1. Noncommutative Rings . . . . . . . . . . . . . . . . . . . . . . . . . . . .
520
8.2. Chain Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
533
8.3. Semisimple Rings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
550
8.4. Tensor Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
574
8.5. Characters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
605
8.6. Theorems of Burnside and of Frobenius
. . . . . . . . . . . . . . . . . . .
634

Contents
vii
Chapter 9
Advanced Linear Algebra
. . . . . . . . . . . . . . . . . .
646
9.1. Modules over PIDs
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
646
9.2. Rational Canonical Forms . . . . . . . . . . . . . . . . . . . . . . . . . . .
666
9.3. Jordan Canonical Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . .
675
9.4. Smith Normal Forms
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
682
9.5. Bilinear Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
694
9.6. Graded Algebras
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
714
9.7. Division Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
727
9.8. Exterior Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
741
9.9. Determinants
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
756
9.10. Lie Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
772
Chapter 10
Homology . . . . . . . . . . . . . . . . . . . . . . . . . . . .
781
10.1. Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
781
10.2. Semidirect Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
784
10.3. General Extensions and Cohomology . . . . . . . . . . . . . . . . . . . .
794
10.4. Homology Functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
813
10.5. Derived Functors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
830
10.6. Ext and Tor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
852
10.7. Cohomology of Groups
. . . . . . . . . . . . . . . . . . . . . . . . . . .
870
10.8. Crossed Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
887
10.9. Introduction to Spectral Sequences
. . . . . . . . . . . . . . . . . . . . .
893
Chapter 11
Commutative Rings III
. . . . . . . . . . . . . . . . . . .
898
11.1. Local and Global . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
898
11.2. Dedekind Rings
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
922
Integrality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
923
Nullstellensatz Redux . . . . . . . . . . . . . . . . . . . . . . . . . . . .
931
Algebraic Integers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
938
Characterizations of Dedekind Rings . . . . . . . . . . . . . . . . . . . .
948
Finitely Generated Modules over Dedekind Rings . . . . . . . . . . . . .
959
11.3. Global Dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
969
11.4. Regular Local Rings . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
985
Appendix
The Axiom of Choice and Zorn's Lemma
. . . . . . . .
A-1
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
B-1
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
I-1

Second Printing
It is my good fortune that several readers of the Ô¨Årst printing this book apprised me of
errata I had not noticed, often giving suggestions for improvement. I give special thanks to
Nick Loehr, Robin Chapman, and David Leep for their generous such help.
Prentice Hall has allowed me to correct every error found; this second printing is surely
better than the Ô¨Årst one.
Joseph Rotman
May 2003
viii

Preface
Algebra is used by virtually all mathematicians, be they analysts, combinatorists, com-
puter scientists, geometers, logicians, number theorists, or topologists. Nowadays, ev-
eryone agrees that some knowledge of linear algebra, groups, and commutative rings is
necessary, and these topics are introduced in undergraduate courses. We continue their
study.
This book can be used as a text for the Ô¨Årst year of graduate algebra, but it is much more
than that. It can also serve more advanced graduate students wishing to learn topics on
their own; while not reaching the frontiers, the book does provide a sense of the successes
and methods arising in an area. Finally, this is a reference containing many of the standard
theorems and deÔ¨Ånitions that users of algebra need to know. Thus, the book is not only an
appetizer, but a hearty meal as well.
When I was a student, Birkhoff and Mac Lane's A Survey of Modern Algebra was the
text for my Ô¨Årst algebra course, and van der Waerden's Modern Algebra was the text for
my second course. Both are excellent books (I have called this book Advanced Modern
Algebra in homage to them), but times have changed since their Ô¨Årst appearance: Birkhoff
and Mac Lane's book Ô¨Årst appeared in 1941, and van der Waerden's book Ô¨Årst appeared
in 1930. There are today major directions that either did not exist over 60 years ago, or
that were not then recognized to be so important. These new directions involve algebraic
geometry, computers, homology, and representations (A Survey of Modern Algebra has
been rewritten as Mac Lane-Birkhoff, Algebra, Macmillan, New York, 1967, and this
version introduces categorical methods; category theory emerged from algebraic topology,
but was then used by Grothendieck to revolutionize algebraic geometry).
Let me now address readers and instructors who use the book as a text for a beginning
graduate course. If I could assume that everyone had already read my book, A First Course
in Abstract Algebra, then the prerequisites for this book would be plain. But this is not a
realistic assumption; different undergraduate courses introducing abstract algebra abound,
as do texts for these courses. For many, linear algebra concentrates on matrices and vector
spaces over the real numbers, with an emphasis on computing solutions of linear systems
of equations; other courses may treat vector spaces over arbitrary Ô¨Åelds, as well as Jordan
and rational canonical forms. Some courses discuss the Sylow theorems; some do not;
some courses classify Ô¨Ånite Ô¨Åelds; some do not.
To accommodate readers having different backgrounds, the Ô¨Årst three chapters contain
ix

x
Preface
many familiar results, with many proofs merely sketched. The Ô¨Årst chapter contains the
fundamental theorem of arithmetic, congruences, De Moivre's theorem, roots of unity,
cyclotomic polynomials, and some standard notions of set theory, such as equivalence
relations and veriÔ¨Åcation of the group axioms for symmetric groups. The next two chap-
ters contain both familiar and unfamiliar material. "New" results, that is, results rarely
taught in a Ô¨Årst course, have complete proofs, while proofs of "old" results are usually
sketched. In more detail, Chapter 2 is an introduction to group theory, reviewing permuta-
tions, Lagrange's theorem, quotient groups, the isomorphism theorems, and groups acting
on sets. Chapter 3 is an introduction to commutative rings, reviewing domains, fraction
Ô¨Åelds, polynomial rings in one variable, quotient rings, isomorphism theorems, irreducible
polynomials, Ô¨Ånite Ô¨Åelds, and some linear algebra over arbitrary Ô¨Åelds. Readers may use
"older" portions of these chapters to refresh their memory of this material (and also to
see my notational choices); on the other hand, these chapters can also serve as a guide for
learning what may have been omitted from an earlier course (complete proofs can be found
in A First Course in Abstract Algebra). This format gives more freedom to an instructor,
for there is a variety of choices for the starting point of a course of lectures, depending
on what best Ô¨Åts the backgrounds of the students in a class. I expect that most instruc-
tors would begin a course somewhere in the middle of Chapter 2 and, afterwards, would
continue from some point in the middle of Chapter 3. Finally, this format is convenient
for the author, because it allows me to refer back to these earlier results in the midst of a
discussion or a proof. Proofs in subsequent chapters are complete and are not sketched.
I have tried to write clear and complete proofs, omitting only those parts that are truly
routine; thus, it is not necessary for an instructor to expound every detail in lectures, for
students should be able to read the text.
Here is a more detailed account of the later chapters of this book.
Chapter 4 discusses Ô¨Åelds, beginning with an introduction to Galois theory, the inter-
relationship between rings and groups. We prove the insolvability of the general polyno-
mial of degree 5, the fundamental theorem of Galois theory, and applications, such as a
proof of the fundamental theorem of algebra, and Galois's theorem that a polynomial over
a Ô¨Åeld of characteristic 0 is solvable by radicals if and only if its Galois group is a solvable
group.
Chapter 5 covers Ô¨Ånite abelian groups (basis theorem and fundamental theorem), the
Sylow theorems, Jordan-H¬®older theorem, solvable groups, simplicity of the linear groups
PSL(2, k), free groups, presentations, and the Nielsen-Schreier theorem (subgroups of free
groups are free).
Chapter 6 introduces prime and maximal ideals in commutative rings; Gauss's theorem
that R[x] is a UFD when R is a UFD; Hilbert's basis theorem, applications of Zorn's lemma
to commutative algebra (a proof of the equivalence of Zorn's lemma and the axiom of
choice is in the appendix), inseparability, transcendence bases, L¬®uroth's theorem, afÔ¨Åne va-
rieties, including a proof of the Nullstellensatz for uncountable algebraically closed Ô¨Åelds
(the full Nullstellensatz, for varieties over arbitrary algebraically closed Ô¨Åelds, is proved
in Chapter 11); primary decomposition; Gr¬®obner bases. Chapters 5 and 6 overlap two
chapters of A First Course in Abstract Algebra, but these chapters are not covered in most

Preface
xi
undergraduate courses.
Chapter 7 introduces modules over commutative rings (essentially proving that all
R-modules and R-maps form an abelian category); categories and functors, including
products and coproducts, pullbacks and pushouts, Grothendieck groups, inverse and direct
limits, natural transformations; adjoint functors; free modules, projectives, and injectives.
Chapter 8 introduces noncommutative rings, proving Wedderburn's theorem that Ô¨Ånite
division rings are commutative, as well as the Wedderburn-Artin theorem classifying semi-
simple rings. Modules over noncommutative rings are discussed, along with tensor prod-
ucts, Ô¨Çat modules, and bilinear forms. We also introduce character theory, using it to prove
Burnside's theorem that Ô¨Ånite groups of order pmqn are solvable. We then introduce multi-
ply transitive groups and Frobenius groups, and we prove that Frobenius kernels are normal
subgroups of Frobenius groups.
Chapter 9 considers Ô¨Ånitely generated modules over PIDs (generalizing earlier theorems
about Ô¨Ånite abelian groups), and then goes on to apply these results to rational, Jordan, and
Smith canonical forms for matrices over a Ô¨Åeld (the Smith normal form enables one to
compute elementary divisors of a matrix). We also classify projective, injective, and Ô¨Çat
modules over PIDs. A discussion of graded k-algebras, for k a commutative ring, leads to
tensor algebras, central simple algebras and the Brauer group, exterior algebra (including
Grassmann algebras and the binomial theorem), determinants, differential forms, and an
introduction to Lie algebras.
Chapter 10 introduces homological methods, beginning with semidirect products and
the extension problem for groups. We then present Schreier's solution of the extension
problem using factor sets, culminating in the Schur-Zassenhaus lemma. This is followed
by axioms characterizing Tor and Ext (existence of these functors is proved with derived
functors), some cohomology of groups, a bit of crossed product algebras, and an introduc-
tion to spectral sequences.
Chapter 11 returns to commutative rings, discussing localization, integral extensions,
the general Nullstellensatz (using Jacobson rings), Dedekind rings, homological dimen-
sions, the theorem of Serre characterizing regular local rings as those noetherian local
rings of Ô¨Ånite global dimension, the theorem of Auslander and Buchsbaum that regular
local rings are UFDs.
Each generation should survey algebra to make it serve the present time.
It is a pleasure to thank the following mathematicians whose suggestions have greatly
improved my original manuscript: Ross Abraham, Michael Barr, Daniel Bump, Heng Huat
Chan, Ulrich Daepp, Boris A. Datskovsky, Keith Dennis, Vlastimil Dlab, Sankar Dutta,
David Eisenbud, E. Graham Evans, Jr., Daniel Flath, Jeremy J. Gray, Daniel Grayson,
Phillip GrifÔ¨Åth, William Haboush, Robin Hartshorne, Craig Huneke, Gerald J. Janusz,
David Joyner, Carl Jockusch, David Leep, Marcin Mazur, Leon McCulloh, Emma Previato,
Eric Sommers, Stephen V. Ullom, Paul Vojta, William C. Waterhouse, and Richard Weiss.
Joseph Rotman

Etymology
The heading etymology in the index points the reader to derivations of certain mathematical
terms. For the origins of other mathematical terms, we refer the reader to my books Journey
into Mathematics and A First Course in Abstract Algebra, which contain etymologies of
the following terms.
Journey into Mathematics:
œÄ, algebra, algorithm, arithmetic, completing the square, cosine, geometry, irrational
number, isoperimetric, mathematics, perimeter, polar decomposition, root, scalar, secant,
sine, tangent, trigonometry.
A First Course in Abstract Algebra:
afÔ¨Åne, binomial, coefÔ¨Åcient, coordinates, corollary, degree, factor, factorial, group,
induction, Latin square, lemma, matrix, modulo, orthogonal, polynomial, quasicyclic,
September, stochastic, theorem, translation.
xii

Special Notation
A algebraic numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353
An
alternating group on n letters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
Ab category of abelian groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443
Aff(1, k) one-dimensional afÔ¨Åne group over a Ô¨Åeld k . . . . . . . . . . . . . . . . . . . . . 125
Aut(G) automorphism group of a group G . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
Br(k), Br(E/k) Brauer group, relative Brauer group . . . . . . . . . . . . . . . . . . . . . . . 737, 739
C complex numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
C‚Ä¢, (C‚Ä¢, d‚Ä¢) complex with differentiations dn : Cn ‚ÜíCn‚àí1 . . . . . . . . . . . . . . . . . . 815
CG(x) centralizer of an element x in a group G . . . . . . . . . . . . . . . . . . . . . . . 101
D(R) global dimension of a commutative ring R . . . . . . . . . . . . . . . . . . . . . 974
D2n
dihedral group of order 2n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
deg( f ) degree of a polynomial f (x) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
Deg( f ) multidegree of a polynomial f (x1, . . . , xn) . . . . . . . . . . . . . . . . . . . . . 402
det(A) determinant of a matrix A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 757
dimk(V ) dimension of a vector space V over a Ô¨Åeld k . . . . . . . . . . . . . . . . . . . . 167
dim(R) Krull dimension of a commutative ring R . . . . . . . . . . . . . . . . . . . . . . 988
Endk(M) endomorphism ring of a k-module M . . . . . . . . . . . . . . . . . . . . . . . . . . 527
Fq
Ô¨Ånite Ô¨Åeld having q elements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
Frac(R) fraction Ô¨Åeld of a domain R . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
Gal(E/k) Galois group of a Ô¨Åeld extension E/k . . . . . . . . . . . . . . . . . . . . . . . . . 200
GL(V ) automorphisms of a vector space V . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
GL(n, k) n √ó n nonsingular matrices, entries in a Ô¨Åeld k . . . . . . . . . . . . . . . . . . 179
H division ring of real quaternions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 522
Hn, Hn
homology, cohomology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 818, 845
ht(p) height of prime ideal p . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 987
Im
integers modulo m . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
I or In
identity matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
‚àö
I
radical of an ideal I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
Id(A) ideal of a subset A ‚äÜkn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382
im f
image of a function f . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
irr(Œ±, k) minimal polynomial of Œ± over a Ô¨Åeld k . . . . . . . . . . . . . . . . . . . . . . . . . 189
xiii

xiv
Special Notation
k
algebraic closure of a Ô¨Åeld k . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354
K0(R), K0(C) Grothendieck groups, direct sums . . . . . . . . . . . . . . . . . . . . . . . . . 491, 489
K ‚Ä≤(C) Grothendieck group, short exact sequences . . . . . . . . . . . . . . . . . . . . . 492
ker f
kernel of a homomorphism f . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
lD(R) left global dimension of a ring R . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 974
Matn(k) ring of all n √ó n matrices with entries in k . . . . . . . . . . . . . . . . . . . . . . 520
RMod category of left R-modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443
ModR
category of right R-modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 526
N natural numbers = {integers n : n ‚â•0} . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
NG(H) normalizer of a subgroup H in a group G . . . . . . . . . . . . . . . . . . . . . . 101
OE
ring of integers in an algebraic number Ô¨Åeld E . . . . . . . . . . . . . . . . . . 925
O(x) orbit of an element x . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
PSL(n, k) projective unimodular group = SL(n, k)/center . . . . . . . . . . . . . . . . . 292
Q rational numbers
Q quaternion group of order 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
Qn
generalized quaternion group of order 2n . . . . . . . . . . . . . . . . . . . . . . . 298
R real numbers
Sn
symmetric group on n letters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
SX
symmetric group on a set X . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
sgn(Œ±) signum of a permutation Œ± . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
SL(n, k) n √ó n matrices of determinant 1, entries in a Ô¨Åeld k . . . . . . . . . . . . . . . 72
Spec(R) the set of all prime ideals in a commutative ring R . . . . . . . . . . . . . . 398
U(R) group of units in a ring R . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
UT(n, k) unitriangular n √ó n matrices over a Ô¨Åeld k . . . . . . . . . . . . . . . . . . . . . . 274
T
I3 ‚ãäI4, a nonabelian group of order 12 . . . . . . . . . . . . . . . . . . . . . . . . 792
tG
torsion subgroup of an abelian group G . . . . . . . . . . . . . . . . . . . . . . . . 267
tr(A) trace of a matrix A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 610
V four-group . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
Var(I) variety of an ideal I ‚äÜk[x1, . . . , xn] . . . . . . . . . . . . . . . . . . . . . . . . . . . 379
Z integers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
Zp
p-adic integers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 503
Z(G) center of a group G . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
Z(R) center of a ring R . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 523
[G : H] index of a subgroup H ‚â§G . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
[E : k] degree of a Ô¨Åeld extension E/k . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
S ‚äîT
coproduct of objects in a category . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447
S ‚äìT
product of objects in a category . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449
S ‚äïT
external, internal direct sum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
K √ó Q
direct product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
K ‚ãäQ
semidirect product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 790
 Ai
direct sum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
 Ai
direct product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451

Special Notation
xv
lim
‚Üê‚àíAi
inverse limit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 500
lim
‚àí‚ÜíAi
direct limit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 505
G‚Ä≤
commutator subgroup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
Gx
stabilizer of an element x . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
G[m] {g ‚ààG : mg = 0}, where G is an additive abelian group . . . . . . . . . 267
mG
{mg : g ‚ààG}, where G is an additive abelian group . . . . . . . . . . . . . 253
G p
p-primary component of an abelian group G . . . . . . . . . . . . . . . . . . . 256
k[x] polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
k(x) rational functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
k[[x]] formal power series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
k‚ü®X‚ü©polynomials in noncommuting variables . . . . . . . . . . . . . . . . . . . . . . . 724
Rop opposite ring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 529
Ra or (a) principal ideal generated by a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
R√ó nonzero elements in a ring R . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
H ‚â§G
H is a subgroup of a group G . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
H < G
H is a proper subgroup of a group G . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
H ‚úÅG
H is a normal subgroup of a group G . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
A ‚äÜB
A is a submodule (subring) of a module (ring)B . . . . . . . . . . . . . . . . 119
A ‚ääB
A is a proper submodule (subring) of a module (ring)B . . . . . . . . . . 119
1X
identity function on a set X
1X
identity morphism on an object X . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443
f : a ‚Üíb
f (a) = b . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
|X| number of elements in a set X
Y [T ]X
matrix of a linear transformation T relative to bases X and Y . . . . . 173
œáœÉ
character afforded by a representation œÉ . . . . . . . . . . . . . . . . . . . . . . . . 610
œÜ(n) Euler œÜ-function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
n
r

binomial coefÔ¨Åcient n!/r!(n ‚àír)! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
Œ¥i j
Kronecker delta Œ¥i j =

1
if i = j;
0
if i Ã∏= j.
a1, . . . , ai, . . . , an
list a1, . . . , an with ai omitted


1
Things Past
This chapter reviews some familiar material of number theory, complex roots of unity, and
basic set theory, and so most proofs are merely sketched.
1.1 SOME NUMBER THEORY
Let us begin by discussing mathematical induction. Recall that the set of natural numbers
N is deÔ¨Åned by
N = {integers n : n ‚â•0};
that is, N is the set of all nonnegative integers. Mathematical induction is a technique of
proof based on the following property of N:
Least Integer Axiom.1 There is a smallest integer in every nonempty subset C of N.
Assuming the axiom, let us see that if m is any Ô¨Åxed integer, possibly negative, then
there is a smallest integer in every nonempty collection C of integers greater than or equal
to m. If m ‚â•0, this is the least integer axiom. If m < 0, then C ‚äÜ{m, m +1, . . . , ‚àí1}‚à™N
and
C =

C ‚à©{m, m + 1, . . . , ‚àí1}

‚à™

C ‚à©N

.
If the Ô¨Ånite set C ‚à©{m, m + 1, . . . , ‚àí1} Ã∏= ‚àÖ, then it contains a smallest integer that is,
obviously, the smallest integer in C; if C ‚à©{m, m + 1, . . . , ‚àí1} = ‚àÖ, then C is contained
in N, and the least integer axiom provides a smallest integer in C.
DeÔ¨Ånition.
A natural number p is prime if p ‚â•2 and there is no factorization p = ab,
where a < p and b < p are natural numbers.
1This property is usually called the well-ordering principle.
1

2
Things Past
Ch. 1
Proposition 1.1.
Every integer n ‚â•2 is either a prime or a product of primes.
Proof.
Let C be the subset of N consisting of all those n ‚â•2 for which the proposition
is false; we must prove that C = ‚àÖ. If, on the contrary, C is nonempty, then it contains a
smallest integer, say, m. Since m ‚ààC, it is not a prime, and so there are natural numbers
a and b with m = ab, a < m, and b < m. Neither a nor b lies in C, for each of them is
smaller than m, which is the smallest integer in C, and so each of them is either prime or a
product of primes. Therefore, m = ab is a product of (at least two) primes, contradicting
the proposition being false for m.
‚Ä¢
There are two versions of induction.
Theorem 1.2 (Mathematical Induction).
Let S(n) be a family of statements, one for
each integer n ‚â•m, where m is some Ô¨Åxed integer. If
(i) S(m) is true, and
(ii) S(n) is true implies S(n + 1) is true,
then S(n) is true for all integers n ‚â•m.
Proof.
Let C be the set of all integers n ‚â•m for which S(n) is false. If C is empty, we
are done. Otherwise, there is a smallest integer k in C. By (i), we have k > m, and so there
is a statement S(k ‚àí1). But k ‚àí1 < k implies k ‚àí1 /‚ààC, for k is the smallest integer in
C. Thus, S(k ‚àí1) is true. But now (ii) says that S(k) = S([k ‚àí1] + 1) is true, and this
contradicts k ‚ààC [which says that S(k) is false].
‚Ä¢
Theorem 1.3 (Second Form of Induction).
Let S(n) be a family of statements, one for
each integer n ‚â•m, where m is some Ô¨Åxed integer. If
(i) S(m) is true, and
(ii) if S(k) is true for all k with m ‚â§k < n, then S(n) is itself true,
then S(n) is true for all integers n ‚â•m.
Sketch of Proof.
The proof is similar to the proof of the Ô¨Årst form.
‚Ä¢
We now recall some elementary number theory.
Theorem 1.4 (Division Algorithm).
Given integers a and b with a Ã∏= 0, there exist
unique integers q and r with
b = qa + r
and
0 ‚â§r < |a|.
Sketch of Proof.
Consider all nonnegative integers of the form b ‚àína, where n ‚ààZ.
DeÔ¨Åne r to be the smallest nonnegative integer of the form b ‚àína, and deÔ¨Åne q to be the
integer n occurring in the expression r = b ‚àína.
If qa + r = q‚Ä≤a + r‚Ä≤, where 0 ‚â§r‚Ä≤ < |a|, then |(q ‚àíq‚Ä≤)a| = |r‚Ä≤ ‚àír|. Now 0 ‚â§
|r‚Ä≤ ‚àír| < |a| and, if |q ‚àíq‚Ä≤| Ã∏= 0, then |(q ‚àíq‚Ä≤)a| ‚â•|a|. We conclude that both sides
are 0; that is, q = q‚Ä≤ and r = r‚Ä≤.
‚Ä¢

Sec. 1.1
Some Number Theory
3
DeÔ¨Ånition.
If a and b are integers with a Ã∏= 0, then the integers q and r occurring in the
division algorithm are called the quotient and the remainder after dividing b by a.
Warning! The division algorithm makes sense, in particular, when b is negative. A
careless person may assume that b and ‚àíb leave the same remainder after dividing by a,
and this is usually false. For example, let us divide 60 and ‚àí60 by 7.
60 = 7 ¬∑ 8 + 4 and ‚àí60 = 7 ¬∑ (‚àí9) + 3
Thus, the remainders after dividing 60 and ‚àí60 by 7 are different.
Corollary 1.5.
There are inÔ¨Ånitely many primes.
Proof. (Euclid)
Suppose, on the contrary, that there are only Ô¨Ånitely many primes. If
p1, p2, . . . , pk is the complete list of all the primes, deÔ¨Åne M = (p1 ¬∑ ¬∑ ¬∑ pk) + 1. By
Proposition 1.1, M is either a prime or a product of primes. But M is neither a prime
(M > pi for every i) nor does it have any prime divisor pi, for dividing M by pi gives
remainder 1 and not 0. For example, dividing M by p1 gives M = p1(p2 ¬∑ ¬∑ ¬∑ pk) + 1, so
that the quotient and remainder are q = p2 ¬∑ ¬∑ ¬∑ pk and r = 1; dividing M by p2 gives M =
p2(p1 p3 ¬∑ ¬∑ ¬∑ pk) + 1, so that q = p1 p3 ¬∑ ¬∑ ¬∑ pk and r = 1; and so forth. This contradiction
proves that there cannot be only Ô¨Ånitely many primes, and so there must be an inÔ¨Ånite
number of them.
‚Ä¢
DeÔ¨Ånition.
If a and b are integers, then a is a divisor of b if there is an integer d with
b = ad. We also say that a divides b or that b is a multiple of a, and we denote this by
a | b.
There is going to be a shift in viewpoint. When we Ô¨Årst learned long division, we
emphasized the quotient q; the remainder r was merely the fragment left over. Here, we
are interested in whether or not a given number b is a multiple of a number a, but we are
less interested in which multiple it may be. Hence, from now on, we will emphasize the
remainder. Thus, a | b if and only if b has remainder r = 0 after dividing by a.
DeÔ¨Ånition.
A common divisor of integers a and b is an integer c with c | a and c | b.
The greatest common divisoror gcd of a and b, denoted by (a, b), is deÔ¨Åned by
(a, b) =

0 if a = 0 = b
the largest common divisor of a and b otherwise.
Proposition 1.6.
If p is a prime and b is any integer, then
(p, b) =

p
if p | b
1
otherwise.
Sketch of Proof.
A positive common divisor is, in particular, a divisor of the prime p, and
hence it is p or 1.
‚Ä¢

4
Things Past
Ch. 1
Theorem 1.7.
If a and b are integers, then (a, b) = d is a linear combination of a and
b; that is, there are integers s and t with d = sa + tb.
Sketch of Proof.
Let
I = {sa + tb : s, t ‚ààZ}
(the set of all integers, positive and negative, is denoted by Z). If I Ã∏= {0}, let d be the
smallest positive integer in I; as any element of I, we have d = sa + tb for some integers
s and t. We claim that I = (d), the set of all multiples of d. Clearly, (d) ‚äÜI. For the
reverse inclusion, take c ‚ààI. By the division algorithm, c = qd + r, where 0 ‚â§r < d.
Now r = c ‚àíqd ‚ààI, so that the minimality of d is contradicted if r Ã∏= 0. Hence, d | c,
c ‚àà(d), and I = (d). It follows that d is a common divisor of a and b, and it is the largest
such.
‚Ä¢
Proposition 1.8.
Let a and b be integers. A nonnegative common divisor d is their gcd if
and only if c | d for every common divisor c.
Sketch of Proof.
If d is the gcd, then d = sa +tb. Hence, if c | a and c | b, then c divides
sa + tb = d. Conversely, if d is a common divisor with c | d for every common divisor c,
then c ‚â§d for all c, and so d is the largest.
‚Ä¢
Corollary 1.9.
Let I be a subset of Z such that
(i) 0 ‚ààI;
(ii) if a, b ‚ààI, then a ‚àíb ‚ààI;
(iii) if a ‚ààI and q ‚ààZ, then qa ‚ààI.
Then there is a natural number d ‚ààI with I consisting precisely of all the multiples of d.
Sketch of Proof.
These are the only properties of the subset I in Theorem 1.7 that were
used in the proof.
‚Ä¢
Theorem 1.10 (Euclid's Lemma).
If p is a prime and p | ab, then p | a or p | b. More
generally, if a prime p divides a product a1a2 ¬∑ ¬∑ ¬∑ an, then it must divide at least one of the
factors ai.
Sketch of Proof.
If p ‚à§a, then (p, a) = 1 and 1 = sp + ta. Hence, b = spb + tab is a
multiple of p. The second statement is proved by induction on n ‚â•2.
‚Ä¢
DeÔ¨Ånition.
Call integers a and b relatively prime if their gcd (a, b) = 1.
Corollary 1.11.
Let a, b, and c be integers. If c and a are relatively prime and if c | ab,
then c | b.
Sketch of Proof.
Since 1 = sc + ta, we have b = scb + tab.
‚Ä¢

Sec. 1.1
Some Number Theory
5
Proposition 1.12.
If p is a prime, then p

p
j
	
for 0 < j < p.
Sketch of Proof.
By deÔ¨Ånition, the binomial coefÔ¨Åcient
p
j

= p!/j!(p ‚àíj)!, so that
p! = j!(p ‚àíj)!
p
j
	
.
By Euclid's lemma, p ‚à§j!(p ‚àíj)! implies p |
p
j

.
‚Ä¢
If integers a and b are not both 0, Theorem 1.7 identiÔ¨Åes (a, b) as the smallest positive
linear combination of a and b. Usually, this is not helpful in actually Ô¨Ånding the gcd, but
the next elementary result is an exception.
Proposition 1.13.
(i) If a and b are integers, then a and b are relatively prime if and only if there are
integers s and t with 1 = sa + tb.
(ii) If d = (a, b), where a and b are not both 0, then (a/d, b/d) = 1.
Proof.
(i) Necessity is Theorem 1.7. For sufÔ¨Åciency, note that 1 being the smallest posi-
tive integer gives, in this case, 1 being the smallest positive linear combination of a and b,
and hence (a, b) = 1. Alternatively, if c is a common divisor of a and b, then c | sa + tb;
hence, c | 1, and so c = ¬±1.
(ii) Note that d Ã∏= 0 and a/d and b/d are integers, for d is a common divisor. The equation
d = sa + tb now gives 1 = s(a/d) + t(b/d). By part (i), (a/d, b/d) = 1.
‚Ä¢
The next result offers a practical method for Ô¨Ånding the gcd of two integers as well as
for expressing it as a linear combination.
Theorem 1.14 (Euclidean Algorithm).
Let a and b be positive integers. There is an
algorithm that Ô¨Ånds the gcd, d = (a, b), and there is an algorithm that Ô¨Ånds a pair of
integers s and t with d = sa + tb.
Remark.
More details can be found in Theorem 3.40, where this result is proved for
polynomials.
To see how the Greeks discovered this result, see the discussion of antanairesis in
Rotman, A First Course in Abstract Algebra, page 49.
‚óÄ
Sketch of Proof.
This algorithm iterates the division algorithm, as follows. Begin with
b = qa +r, where 0 ‚â§r < a. The second step is a = q‚Ä≤r +r‚Ä≤, where 0 ‚â§r‚Ä≤ < r; the next
step is r = q‚Ä≤‚Ä≤r‚Ä≤ + r‚Ä≤‚Ä≤, where 0 ‚â§r‚Ä≤‚Ä≤ < r‚Ä≤, and so forth. This iteration stops eventually, and
the last remainder is the gcd. Working upward from the last equation, we can write the gcd
as a linear combination of a and b.
‚Ä¢

6
Things Past
Ch. 1
Proposition 1.15.
If b ‚â•2 is an integer, then every positive integer m has an expression
in base b: There are integers di with 0 ‚â§di < b such that
m = dkbk + dk‚àí1bk‚àí1 + ¬∑ ¬∑ ¬∑ + d0;
moreover, this expression is unique if dk Ã∏= 0.
Sketch of Proof.
By the least integer axiom, there is an integer k ‚â•0 with bk ‚â§m <
bk+1, and the division algorithm gives m = dkbk + r, where 0 ‚â§r < bk. The existence of
b-adic digits follows by induction on m ‚â•1. Uniqueness can also be proved by induction
on m, but one must take care to treat all possible cases that may arise.
‚Ä¢
The numbers dk, dk‚àí1, . . . , d0 are called the b-adic digits of m.
Theorem 1.16 (Fundamental Theorem of Arithmetic).
Assume that an integer a ‚â•2
has factorizations
a = p1 ¬∑ ¬∑ ¬∑ pm and a = q1 ¬∑ ¬∑ ¬∑ qn,
where the p's and q's are primes. Then n = m and the q's may be reindexed so that
qi = pi for all i. Hence, there are unique distinct primes pi and unique integers ei > 0
with
a = pe1
1 ¬∑ ¬∑ ¬∑ pen
n .
Proof.
We prove the theorem by induction on ‚Ñì, the larger of m and n.
If ‚Ñì= 1, then the given equation is a = p1 = q1, and the result is obvious. For the
inductive step, note that the equation gives pm | q1 ¬∑ ¬∑ ¬∑ qn. By Euclid's lemma, there is
some i with pm | qi. But qi, being a prime, has no positive divisors other than 1 and
itself, so that qi = pm. Reindexing, we may assume that qn = pm. Canceling, we have
p1 ¬∑ ¬∑ ¬∑ pm‚àí1 = q1 ¬∑ ¬∑ ¬∑ qn‚àí1. By the inductive hypothesis, n ‚àí1 = m ‚àí1 and the q's may
be reindexed so that qi = pi for all i.
‚Ä¢
DeÔ¨Ånition.
A common multiple of integers a and b is an integer c with a | c and b | c.
The least common multiple or lcm of a and b, denoted by [a, b], is deÔ¨Åned by
[a, b] =

0 if a = 0 = b
the smallest positive common multiple of a and b otherwise.
Proposition 1.17.
Let a = pe1
1 ¬∑ ¬∑ ¬∑ pen
n and let b = p f1
1 ¬∑ ¬∑ ¬∑ p fn
n , where ei ‚â•0 and fi ‚â•0
for all i; deÔ¨Åne
mi = min{ei, fi}
and
Mi = max{ei, fi}.
Then the gcd and the lcm of a and b are given by
(a, b) = pm1
1
¬∑ ¬∑ ¬∑ pmn
n
and
[a, b] = pM1
1
¬∑ ¬∑ ¬∑ pMn
n .
Sketch of Proof.
Use the fact that pe1
1 ¬∑ ¬∑ ¬∑ pen
n
| p f1
1 ¬∑ ¬∑ ¬∑ p fn
n
if and only if ei ‚â§fi for
all i.
‚Ä¢

Sec. 1.1
Some Number Theory
7
DeÔ¨Ånition.
Let m ‚â•0 be Ô¨Åxed. Then integers a and b are congruent modulo m, denoted
by
a ‚â°b mod m,
if m | (a ‚àíb).
Proposition 1.18.
If m ‚â•0 is a Ô¨Åxed integer, then for all integers a, b, c,
(i) a ‚â°a mod m;
(ii) if a ‚â°b mod m, then b ‚â°a mod m;
(iii) if a ‚â°b mod m and b ‚â°c mod m, then a ‚â°c mod m.
Remark.
(i) says that congruence is reÔ¨Çexive, (ii) says it is symmetric, and (iii) says it is
transitive.
‚óÄ
Sketch of Proof.
All the items follow easily from the deÔ¨Ånition of congruence.
‚Ä¢
Proposition 1.19.
Let m ‚â•0 be a Ô¨Åxed integer.
(i) If a = qm + r, then a ‚â°r mod m.
(ii) If 0 ‚â§r‚Ä≤ < r < m, then r Ã∏‚â°r‚Ä≤ mod m; that is, r and r‚Ä≤ are not congruent mod m.
(iii) a ‚â°b mod m if and only if a and b leave the same remainder after dividing by m.
(iv) If m ‚â•2, each integer a is congruent mod m to exactly one of 0, 1, . . . , m ‚àí1.
Sketch of Proof.
Items (i) and (iii) are routine; item (ii) follows after noting that
0 < r ‚àír‚Ä≤ < m, and item (iv) follows from (i) and (ii).
‚Ä¢
The next result shows that congruence is compatible with addition and multiplication.
Proposition 1.20.
Let m ‚â•0 be a Ô¨Åxed integer.
(i) If a ‚â°a‚Ä≤ mod m and b ‚â°b‚Ä≤ mod m, then
a + b ‚â°a‚Ä≤ + b‚Ä≤ mod m.
(ii) If a ‚â°a‚Ä≤ mod m and b ‚â°b‚Ä≤ mod m, then
ab ‚â°a‚Ä≤b‚Ä≤ mod m.
(iii) If a ‚â°b mod m, then an ‚â°bn mod m for all n ‚â•1.
Sketch of Proof.
All the items are routine.
‚Ä¢

8
Things Past
Ch. 1
Earlier we divided 60 and ‚àí60 by 7, getting remainders 4 in the Ô¨Årst case and 3 in the
second. It is no accident that 4 + 3 = 7. If a is an integer and m ‚â•0, let a ‚â°r mod m and
‚àía ‚â°r‚Ä≤ mod m. It follows from the proposition that
0 = ‚àía + a ‚â°r‚Ä≤ + r mod m.
The next example shows how one can use congruences. In each case, the key idea is to
solve a problem by replacing numbers by their remainders.
Example 1.21.
(i) Prove that if a is in Z, then a2 ‚â°0, 1, or 4 mod 8.
If a is an integer, then a ‚â°r mod 8, where 0 ‚â§r ‚â§7; moreover, by Proposi-
tion 1.20(iii), a2 ‚â°r2 mod 8, and so it sufÔ¨Åces to look at the squares of the remainders.
r
0
1
2
3
4
5
6
7
r2
0
1
4
9
16
25
36
49
r2 mod 8
0
1
4
1
0
1
4
1
Table 1.1.
Squares mod 8
We see in Table 1.1 that only 0, 1, or 4 can be a remainder after dividing a perfect square
by 8.
(ii) Prove that n = 1003456789 is not a perfect square.
Since 1000 = 8 ¬∑ 125, we have 1000 ‚â°0 mod 8, and so
n = 1003456789 = 1003456 ¬∑ 1000 + 789 ‚â°789 mod 8.
Dividing 789 by 8 leaves remainder 5; that is, n ‚â°5 mod 8. Were n a perfect square, then
n ‚â°0, 1, or 4 mod 8.
(iii) If m and n are positive integers, are there any perfect squares of the form 3m +3n +1?
Again, let us look at remainders mod 8. Now 32 = 9 ‚â°1 mod 8, and so we can evaluate
3m mod 8 as follows: If m = 2k, then 3m = 32k = 9k ‚â°1 mod 8; if m = 2k + 1, then
3m = 32k+1 = 9k ¬∑ 3 ‚â°3 mod 8. Thus,
3m ‚â°

1 mod 8
if m is even;
3 mod 8
if m is odd.
Replacing numbers by their remainders after dividing by 8, we have the following possi-
bilities for the remainder of 3m + 3n + 1, depending on the parities of m and n:
3 + 1 + 1 ‚â°5 mod 8
3 + 3 + 1 ‚â°7 mod 8
1 + 1 + 1 ‚â°3 mod 8
1 + 3 + 1 ‚â°5 mod 8.

Sec. 1.1
Some Number Theory
9
In no case is the remainder 0, 1, or 4, and so no number of the form 3m + 3n + 1 can be a
perfect square, by part (i).
‚óÄ
Proposition 1.22.
A positive integer a is divisible by 3 (or by 9) if and only if the sum of
its (decimal) digits is divisible by 3 (or by 9).
Sketch of Proof.
Observe that 10n ‚â°1 mod 3 (and also that 10n ‚â°1 mod 9).
‚Ä¢
Proposition 1.23.
If p is a prime and a and b are integers, then
(a + b)p ‚â°a p + bp mod p.
Sketch of Proof.
Use the binomial theorem and Proposition 1.12.
‚Ä¢
Theorem 1.24 (Fermat).
If p is a prime, then
a p ‚â°a mod p
for every a in Z. More generally, for every integer k ‚â•1,
a pk ‚â°a mod p.
Sketch of Proof.
If a ‚â•0, use induction on a; the inductive step uses Proposition 1.23.
The second statement follows by induction on k ‚â•1.
‚Ä¢
Corollary 1.25.
Let p be a prime and let n be a positive integer. If m ‚â•0 and if  is the
sum of the p-adic digits of m, then
nm ‚â°n mod p.
Sketch of Proof.
Write m in base p, and use Fermat's theorem.
‚Ä¢
We compute the remainder after dividing 10100 by 7. First, 10100 ‚â°3100 mod 7.
Second, since 100 = 2 ¬∑ 72 + 2, the corollary gives 3100 ‚â°34 = 81 mod 7. Since
81 = 11 √ó 7 + 4, we conclude that the remainder is 4.
Theorem 1.26.
If (a, m) = 1, then, for every integer b, the congruence
ax ‚â°b mod m
can be solved for x; in fact, x = sb, where sa ‚â°1 mod m is one solution. Moreover, any
two solutions are congruent mod m.
Sketch of Proof.
If 1 = sa + tm, then b = sab + tmb. Hence, b ‚â°a(sb) mod m. If,
also, b ‚â°ax mod m, then 0 ‚â°a(x ‚àísb) mod m, so that m | a(x ‚àísb). Since (m, a) = 1,
we have m | (x ‚àísb); hence, x ‚â°sb mod m, by Corollary 1.11.
‚Ä¢

10
Things Past
Ch. 1
Corollary 1.27.
If p is a prime and a is not divisible by p, then the congruence
ax ‚â°b mod p
is always solvable.
Sketch of Proof.
If a is not divisible by p, then (a, p) = 1.
‚Ä¢
Theorem 1.28 (Chinese Remainder Theorem).
If m and m‚Ä≤ are relatively prime, then
the two congruences
x ‚â°b mod m
x ‚â°b‚Ä≤ mod m‚Ä≤
have a common solution, and any two solutions are congruent mod mm‚Ä≤.
Sketch of Proof.
By Theorem 1.26, any solution x to the Ô¨Årst congruence has the form
x = sb + km for some k ‚ààZ (where 1 = sa + tm). Substitute this into the second
congruence and solve for k. Alternatively, there are integers s and s‚Ä≤ with 1 = sm + s‚Ä≤m‚Ä≤,
and a common solution is
x = b‚Ä≤ms + bm‚Ä≤s‚Ä≤.
To prove uniqueness, assume that y ‚â°b mod m and y ‚â°b‚Ä≤ mod m‚Ä≤. Then x ‚àíy ‚â°
0 mod m and x ‚àíy ‚â°0 mod m‚Ä≤; that is, both m and m‚Ä≤ divide x ‚àíy. The result now
follows from Exercise 1.19 on page 13.
‚Ä¢
EXERCISES
1.1 Prove that 12 + 22 + ¬∑ ¬∑ ¬∑ + n2 = 1
6n(n + 1)(2n + 1) = 1
3n3 + 1
2n2 + 1
6n.
1.2 Prove that 13 + 23 + ¬∑ ¬∑ ¬∑ + n3 = 1
4n4 + 1
2n3 + 1
4n2.
1.3 Prove that 14 + 24 + ¬∑ ¬∑ ¬∑ + n4 = 1
5n5 + 1
2n4 + 1
3n3 ‚àí1
30n.
Remark.
There is a general formula that expresses n‚àí1
i=1 ik, for k ‚â•1, as a polynomial in n:
(k + 1)
n‚àí1

i=1
ik = nk+1 +
k

j=1
k + 1
j
	
B jnk+1‚àíj;
the coefÔ¨Åcients involve rational numbers B j, for j ‚â•1, called Bernoulli numbers, deÔ¨Åned by
x
ex ‚àí1 = 1 +

j‚â•1
B j
j! x j;
see Borevich-Shafarevich, Number Theory, page 382.
‚óÄ

Sec. 1.1
Some Number Theory
11
1.4 Derive the formula for n
i=1 i by computing the area (n +1)2 of a square with sides of length
n + 1 using Figure 1.1.
Hint. The triangular areas on either side of the diagonal have equal area.
1
2
3
4
5
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
Figure 1.1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
Figure 1.2
1.5
(i) Derive the formula for n
i=1 i by computing the area n(n + 1) of a rectangle with base
n + 1 and height n, as pictured in Figure 1.2.
(ii) (Alhazen, ca. 965-1039) For Ô¨Åxed k ‚â•1, use Figure 1.3 to prove
(n + 1)
n

i=1
ik =
n

i=1
ik+1 +
n

i=1
 i
‚Ñì=1
‚Ñìk
.
Hint. As indicated in Figure 1.3, a rectangle with height n + 1 and base n
i=1 ik can
be subdivided so that the shaded staircase has area n
i=1 ik+1, whereas the area above
it is
1k + (1k + 2k) + (1k + 2k + 3k) + ¬∑ ¬∑ ¬∑ + (1k + 2k + ¬∑ ¬∑ ¬∑ + nk).
1
2
3
5
4
k
k
k
k
k
1
5
4         +         
k
k
k
1
2
3
5
4
k+1
k+1
k+1
k+1
k+1
1   +  2
3
4
k
k
k
k
3k
1   +  2    k
k
1   +  2     +             +      
k
k
1   +  2     +             +      
k
k
k
3
+
Figure 1.3

12
Things Past
Ch. 1
(iii) Given the formula n
i=1 = 1
2n(n + 1), use part (ii) to derive the formula for n
i=1 i2.
Hint.
In Alhazen's formula, write n
i=1
i
‚Ñì=1 ‚Ñì

= 1
2
n
i=1 i2 + 1
2
n
i=1 i, and
then solve for n
i=1 i2 in terms of the rest.
1.6 (Leibniz) A function f : R ‚ÜíR is called a C‚àû-function if it has an nth derivative f (n) for
every natural number n ( f (0) is deÔ¨Åned to be f ). If f and g are C‚àû-functions, prove that
( f g)(n) =
n

r=0
n
r
	
f (r) ¬∑ g(n‚àír).
1.7 (Double Induction) Let S(m, n) be a doubly indexed family of statements, one for each
m ‚â•1 and n ‚â•1. Suppose that
(i) S(1, 1) is true;
(ii) if S(m, 1) is true, then S(m + 1, 1) is true;
(iii) if S(m, n) is true for all m, then S(m, n + 1) is true for all m.
Prove that S(m, n) is true for all m ‚â•1 and n ‚â•1.
1.8 Use double induction to prove that
(m + 1)n > mn
for all m, n ‚â•1.
1.9 Prove that
‚àö
2 is irrational.
Hint.
If
‚àö
2 is rational, then
‚àö
2 = a/b, and we can assume that (a, b) = 1 (actually, it
is enough to assume that at least one of a and b is odd). Squaring this equation leads to a
contradiction.
1.10 Prove the converse of Euclid's lemma: An integer p ‚â•2, which, whenever it divides a product
necessarily divides one of the factors, must be a prime.
1.11 Let p1, p2, p3, . . . be the list of the primes in ascending order: p1 = 2, p2 = 3, p3 = 5, . . .
DeÔ¨Åne fk = p1 p2 ¬∑ ¬∑ ¬∑ pk + 1 for k ‚â•1. Find the smallest k for which fk is not a prime.
Hint. 19 | f7, but 7 is not the smallest k.
1.12 If d and d‚Ä≤ are nonzero integers, each of which divides the other, prove that d‚Ä≤ = ¬±d.
1.13 Show that every positive integer m can be written as a sum of distinct powers of 2; show,
moreover, that there is only one way in which m can so be written.
Hint. Write m in base 2.
1.14 If (r, a) = 1 = (r‚Ä≤, a), prove that (rr‚Ä≤, a) = 1.
1.15
(i) Prove that if a positive integer n is squarefree (i.e., n is not divisible by the square of
any prime), then ‚àön is irrational.
(ii) Prove that an integer m ‚â•2 is a perfect square if and only if each of its prime factors
occurs an even number of times.
1.16 Prove that 3‚àö
2 is irrational.
Hint. Assume that 3‚àö
2 can be written as a fraction in lowest terms.
1.17 Find the gcd d = (12327, 2409), Ô¨Ånd integers s and t with d = 12327s + 2409t, and put the
fraction 2409/12327 in lowest terms.

Sec. 1.1
Some Number Theory
13
1.18 Assume that d = sa + tb is a linear combination of integers a and b. Find inÔ¨Ånitely many
pairs of integers (sk, tk) with
d = ska + tkb.
Hint. If 2s + 3t = 1, then 2(s + 3) + 3(t ‚àí2) = 1.
1.19 If a and b are relatively prime and if each divides an integer n, then their product ab also
divides n.
1.20 If a > 0, prove that a(b, c) = (ab, ac). [We must assume that a > 0 lest a(b, c) be negative.]
Hint. Show that if k is a common divisor of ab and ac, then k | a(b, c).
DeÔ¨Ånition.
A common divisor of integers a1, a2, . . . , an is an integer c with c | ai for all i; the
largest of the common divisors, denoted by (a1, a2, . . . , an), is called the greatest common divisor.
1.21
(i) Show that if d is the greatest common divisor of a1, a2, . . . , an, then d =  tiai, where
ti is in Z for 1 ‚â§i ‚â§n.
(ii) Prove that if c is a common divisor of a1, a2, . . . , an, then c | d.
1.22
(i) Show that (a, b, c), the gcd of a, b, c, is equal to (a, (b, c)).
(ii) Compute (120, 168, 328).
1.23 A Pythagorean triple is an ordered triple (a, b, c) of positive integers for which
a2 + b2 = c2;
it is called primitive if gcd (a, b, c) = 1.
(i) If q > p are positive integers, prove that
(q2 ‚àíp2, 2qp, q2 + p2)
is a Pythagorean triple. [One can prove that every primitive Pythagorean triple (a, b, c)
is of this type.]
(ii) Show that the Pythagorean triple (9, 12, 15) (which is not primitive) is not of the type
given in part (i).
(iii) Using a calculator that can Ô¨Ånd square roots but that can display only 8 digits, prove that
(19597501, 28397460, 34503301)
is a Pythagorean triple by Ô¨Ånding q and p.
DeÔ¨Ånition.
A common multiple of a1, a2, . . . , an is an integer m with ai | m for all i. The least
common multiple, written lcm and denoted by [a1, a2, . . . , an], is the smallest positive common
multiple if all ai Ã∏= 0, and it is 0 otherwise.
1.24 Prove that an integer M ‚â•0 is the lcm of a1, a2, . . . , an if and only if it is a common multiple
of a1, a2, . . . , an that divides every other common multiple.
1.25 Let a1/b1, . . . , an/bn ‚ààQ, where (ai, bi) = 1 for all i. If M = lcm{b1, . . . , bn}, prove that
the gcd of Ma1/b1, . . . , Man/bn is 1.
1.26
(i) Prove that [a, b](a, b) = ab, where [a, b] is the least common multiple of a and b.
Hint. If neither a nor b is 0, show that ab/(a, b) is a common multiple of a and b that
divides every common multiple c of a and b. Alternatively, use Proposition 1.17.

14
Things Past
Ch. 1
1.27
(i) Find the gcd (210, 48) using factorizations into primes.
(ii) Find (1234, 5678).
1.28 If a and b are positive integers with (a, b) = 1, and if ab is a square, prove that both a and b
are squares.
Hint. The sets of prime divisors of a and b are disjoint.
1.29 Let n = prm, where p is a prime not dividing an integer m ‚â•1. Prove that
p ‚à§
 n
pr
	
.
Hint. Assume otherwise, cross multiply, and use Euclid's lemma.
1.30 Let m be a positive integer, and let m‚Ä≤ be an integer obtained from m by rearranging its (dec-
imal) digits (e.g., take m = 314159 and m‚Ä≤ = 539114). Prove that m ‚àím‚Ä≤ is a multiple
of 9.
1.31 Prove that a positive integer n is divisible by 11 if and only if the alternating sum of its
digits is divisible by 11 (if the digits of a are dk . . . d2d1d0, then their alternating sum is
d0 ‚àíd1 + d2 ‚àí¬∑ ¬∑ ¬∑ ).
Hint. 10 ‚â°‚àí1 mod 11.
1.32
(i) Prove that 10q + r is divisible by 7 if and only if q ‚àí2r is divisible by 7.
(ii) Given an integer a with decimal digits dkdk‚àí1 . . . d0, deÔ¨Åne
a‚Ä≤ = dkdk‚àí1 ¬∑ ¬∑ ¬∑ d1 ‚àí2d0.
Show that a is divisible by 7 if and only if some one of a‚Ä≤, a‚Ä≤‚Ä≤, a‚Ä≤‚Ä≤‚Ä≤,...is divisible by 7.
(For example, if a = 65464, then a‚Ä≤ = 6546 ‚àí8 = 6538, a‚Ä≤‚Ä≤ = 653 ‚àí16 = 637, and
a‚Ä≤‚Ä≤‚Ä≤ = 63 ‚àí14 = 49; we conclude that 65464 is divisible by 7.)
1.33
(i) Show that 1000 ‚â°‚àí1 mod 7.
(ii) Show that if a = r0 + 1000r1 + 10002r2 + ¬∑ ¬∑ ¬∑ , then a is divisible by 7 if and only if
r0 ‚àír1 + r2 ‚àí¬∑ ¬∑ ¬∑ is divisible by 7.
Remark.
Exercises 1.32 and 1.33 combine to give an efÔ¨Åcient way to determine whether large
numbers are divisible by 7. If a = 33456789123987, for example, then a ‚â°0 mod 7 if and only if
987 ‚àí123 + 789 ‚àí456 + 33 = 1230 ‚â°0 mod 7. By Exercise 1.32, 1230 ‚â°123 ‚â°6 mod 7, and so
a is not divisible by 7.
‚óÄ
1.34 Prove that there are no integers x, y, and z such that
x2 + y2 + z2 = 999.
Hint. Use Example 1.21(i).
1.35 Prove that there is no perfect square a2 whose last two digits are 35.
Hint. If the last digit of a2 is 5, then a2 ‚â°5 mod 10; if the last two digits of a2 are 35, then
a2 ‚â°35 mod 100.
1.36 If x is an odd number not divisible by 3, prove that x2 ‚â°1 mod 4.
1.37 Prove that if p is a prime and if a2 ‚â°1 mod p, then a ‚â°¬±1 mod p.
Hint. Use Euclid's lemma.

Sec. 1.2
Roots of Unity
15
1.38 If (a, m) = d, prove that ax ‚â°b mod m has a solution if and only if d | b.
1.39 Solve the congruence x2 ‚â°1 mod 21.
Hint. Use Euclid's lemma with 21 | (a + 1)(a ‚àí1).
1.40 Solve the simultaneous congruences:
(i) x ‚â°2 mod 5 and 3x ‚â°1 mod 8;
(ii) 3x ‚â°2 mod 5 and 2x ‚â°1 mod 3.
1.41
(i) Show that (a + b)n ‚â°an + bn mod 2 for all a and b and for all n ‚â•1.
Hint. Consider the parity of a and of b.
(ii) Show that (a + b)2 Ã∏‚â°a2 + b2 mod 3.
1.42 On a desert island, Ô¨Åve men and a monkey gather coconuts all day, then sleep. The Ô¨Årst man
awakens and decides to take his share. He divides the coconuts into Ô¨Åve equal shares, with
one coconut left over. He gives the extra one to the monkey, hides his share, and goes to sleep.
Later, the second man awakens and takes his Ô¨Åfth from the remaining pile; he, too, Ô¨Ånds one
extra and gives it to the monkey. Each of the remaining three men does likewise in turn. Find
the minimum number of coconuts originally present.
Hint. Try ‚àí4 coconuts.
1.2 ROOTS OF UNITY
Let us now say a bit about the complex numbers C. We deÔ¨Åne a complex number z = a+ib
to be the point (a, b) in the plane; a is called the real part of z and b is called its imaginary
part. The modulus |z| of z = a + ib = (a, b) is the distance from z to the origin:
|z| =

a2 + b2.
Proposition 1.29 (Polar Decomposition).
Every complex number z has a factorization
z = r(cos Œ∏ + i sin Œ∏),
where r = |z| ‚â•0 and 0 ‚â§Œ∏ < 2œÄ.
Proof.
If z = 0, then |z| = 0, and any choice of Œ∏ works. If z = a +ib Ã∏= 0, then |z| Ã∏= 0,
and z/|z| = (a/|z|, b/|z|) has modulus 1, because
(a/|z|)2 + (b/|z|)2 = (a2 + b2)/|z|2 = 1.
Therefore, there is an angle Œ∏ (see Figure 1.4 on page 16) with z/|z| = cos Œ∏ + i sin Œ∏, and
so z = |z|(cos Œ∏ + i sin Œ∏) = r(cos Œ∏ + i sin Œ∏).
‚Ä¢
It follows that every complex number z of modulus 1 is a point on the unit circle, and so
it has coordinates (cos Œ∏, sin Œ∏) (Œ∏ is the angle from the x-axis to the line joining the origin
to (a, b), because cos Œ∏ = a/1 and sin Œ∏ = b/1).
If z = a + ib = r(cos Œ∏ + i sin Œ∏), then (r, Œ∏) are the polar coordinates of z; this is the
reason why Proposition 1.29 is called the polar decomposition of z.
The trigonometric addition formulas for cos(Œ∏ +œà) and sin(Œ∏ +œà) have a lovely trans-
lation into the language of complex numbers.

16
Things Past
Ch. 1
(a, b)
(1, 0)
|z|
Œ∏
=  z
Figure 1.4
Proposition 1.30 (Addition Theorem).
If
z = cos Œ∏ + i sin Œ∏
and
w = cos œà + i sin œà,
then
zw = cos(Œ∏ + œà) + i sin(Œ∏ + œà).
Proof.
zw = (cos Œ∏ + i sin Œ∏)(cos œà + i sin œà)
= (cos Œ∏ cos œà ‚àísin Œ∏ sin œà) + i(sin Œ∏ cos œà + cos Œ∏ sin œà).
The trigonometric addition formulas show that
zw = cos(Œ∏ + œà) + i sin(Œ∏ + œà).
‚Ä¢
The addition theorem gives a geometric interpretation of complex multiplication.
Corollary 1.31.
If z and w are complex numbers with polar coordinates (r, Œ∏) and (s, œà),
respectively, then the polar coordinates of zw are2
(rs, Œ∏ + œà),
and so
|zw| = |z| |w|.
Proof.
If the polar decompositions of z and w are z = r(cos Œ∏ + i sin Œ∏) and w =
s(cos œà + i sin œà), respectively, then
zw = rs[cos(Œ∏ + œà) + i sin(Œ∏ + œà)].
‚Ä¢
2This formula is correct if Œ∏ + œà ‚â§2œÄ; otherwise, the angle should be Œ∏ + œà ‚àí2œÄ.

Sec. 1.2
Roots of Unity
17
In particular, if |z| = 1 = |w|, then |zw| = 1; that is, the product of two complex
numbers on the unit circle also lies on the unit circle.
In 1707, A. De Moivre (1667-1754) proved the following elegant result.
Theorem 1.32 (De Moivre).
For every real number x and every positive integer n,
cos(nx) + i sin(nx) = (cos x + i sin x)n.
Proof.
We prove De Moivre's theorem by induction on n ‚â•1. The base step n = 1 is
obviously true. For the inductive step,
(cos x + i sin x)n+1 = (cos x + i sin x)n(cos x + i sin x)
= (cos(nx) + i sin(nx))(cos x + i sin x)
(inductive hypothesis)
= cos(nx + x) + i sin(nx + x)
(addition formula)
= cos([n + 1]x) + i sin([n + 1]x).
‚Ä¢
Corollary 1.33.
(i)
cos(2x) = cos2 x ‚àísin2 x = 2 cos2 x ‚àí1
sin(2x) = 2 sin x cos x.
(ii)
cos(3x) = cos3 x ‚àí3 cos x sin2 x = 4 cos3 x ‚àí3 cos x
sin(3x) = 3 cos2 x sin x ‚àísin3 x = 3 sin x ‚àí4 sin3 x.
Proof.
(i)
cos(2x) + i sin(2x) = (cos x + i sin x)2
= cos2 x + 2i sin x cos x + i2 sin2 x
= cos2 x ‚àísin2 x + i(2 sin x cos x).
Equating real and imaginary parts gives both double angle formulas.
(ii) De Moivre's theorem gives
cos(3x) + i sin(3x) = (cos x + i sin x)3
= cos3 x + 3i cos2 x sin x + 3i2 cos x sin2 x + i3 sin3 x
= cos3 x ‚àí3 cos x sin2 x + i(3 cos2 x sin x ‚àísin3 x).
Equality of the real parts gives cos(3x) = cos3 x ‚àí3 cos x sin2 x; the second formula for
cos(3x) follows by replacing sin2 x by 1 ‚àícos2 x. Equality of the imaginary parts gives
sin(3x) = 3 cos2 x sin x‚àísin3 x = 3 sin x‚àí4 sin3 x; the second formula arises by replacing
cos2 x by 1 ‚àísin2 x.
‚Ä¢

18
Things Past
Ch. 1
Corollary 1.33 can be generalized. If f2(x) = 2x2 ‚àí1, then
cos(2x) = 2 cos2 x ‚àí1 = f2(cos x),
and if f3(x) = 4x3 ‚àí3x, then
cos(3x) = 4 cos3 x ‚àí3 cos x = f3(cos x).
Proposition 1.34.
For all n ‚â•1, there is a polynomial fn(x) having all coefÔ¨Åcients
integers such that
cos(nx) = fn(cos x).
Proof.
By De Moivre's theorem,
cos(nx) + i sin(nx) = (cos x + i sin x)n
=
n

r=0
n
r
	
cosn‚àír x ir sinr x.
The real part of the left side, cos(nx), must be equal to the real part of the right side. Now
ir is real if and only if r is even, and so
cos(nx) =

r even
n
r
	
cosn‚àír x ir sinr x.
If r = 2k, then ir = i2k = (‚àí1)k, and
cos(nx) =
 n
2


k=0
(‚àí1)k
 n
2k
	
cosn‚àí2k x sin2k x,
where
 n
2

is the largest integer ‚â§n
2. But sin2k x = (sin2 x)k = (1 ‚àícos2 x)k, which is a
polynomial in cos x. This completes the proof.
‚Ä¢
It is not difÔ¨Åcult to show, by induction on n ‚â•2, that fn(x) begins with 2n‚àí1xn. A sine
version of Proposition 1.34 can be found in Exercise 1.49 on page 25.
Euler's Theorem. For all real numbers x,
eix = cos x + i sin x.
The basic idea of the proof, aside from matters of convergence, is to examine the real
and imaginary parts of the power series expansion of eix. Using the fact that the powers of
i repeat in cycles of length 4: 1, i, ‚àí1, ‚àíi, 1 . . ., we have
eix = 1 + ix + (ix)2
2!
+ (ix)3
3!
+ ¬∑ ¬∑ ¬∑
=

1 ‚àíx2
2! + x4
4! + ¬∑ ¬∑ ¬∑

+ i

x ‚àíx3
3! + x5
5! + ¬∑ ¬∑ ¬∑

= cos x + i sin x.

Sec. 1.2
Roots of Unity
19
It is said that Euler was especially pleased with the equation
eœÄi = ‚àí1;
indeed, this formula is inscribed on his tombstone.
As a consequence of Euler's theorem, the polar decomposition can be rewritten in ex-
ponential form: Every complex number z has a factorization
z = reiŒ∏,
where r ‚â•0 and 0 ‚â§Œ∏ < 2œÄ. The addition theorem and De Moivre's theorem can be
restated in complex exponential form. The Ô¨Årst becomes
eixeiy = ei(x+y);
the second becomes
(eix)n = einx.
DeÔ¨Ånition.
If n ‚â•1 is an integer, then an nth root of unity is a complex number Œ∂ with
Œ∂ n = 1.
The geometric interpretation of complex multiplication is particularly interesting when
z and w lie on the unit circle, so that |z| = 1 = |w|. Given a positive integer n, let
Œ∏ = 2œÄ/n and let Œ∂ = eiŒ∏. The polar coordinates of Œ∂ are (1, Œ∏), the polar coordinates of
Œ∂ 2 are (1, 2Œ∏), the polar coordinates of Œ∂ 3 are (1, 3Œ∏),. . . , the polar coordinates of Œ∂ n‚àí1 are
(1, (n ‚àí1)Œ∏), and the polar coordinates of Œ∂ n = 1 are (1, nŒ∏) = (1, 0). Thus, the nth roots
of unity are equally spaced around the unit circle. Figure 1.5 shows the 8th roots of unity
(here, Œ∏ = 2œÄ/8 = œÄ/4).
i
1
‚àí i
‚àí1
‚àö1 2
‚àö1 2(‚àí1 + i)
(1 + i)
(‚àí1 ‚àí i)
(1 ‚àí i)
‚àö1 2
‚àö1 2
Figure 1.5: 8th Roots of Unity

20
Things Past
Ch. 1
Corollary 1.35.
Every nth root of unity is equal to
e2œÄik/n = cos
 2œÄk
n

+ i sin
 2œÄk
n

,
for some k = 0, 1, 2, . . . , n ‚àí1, and hence it has modulus 1.
Proof.
Note that e2œÄi = cos 2œÄ +i sin 2œÄ = 1. By De Moivre's theorem, if Œ∂ = e2œÄi/n =
cos(2œÄ/n) + i sin(2œÄ/n), then
Œ∂ n = (e2œÄi/n)n = e2œÄi = 1,
so that Œ∂ is an nth root of unity. Since Œ∂ n = 1, it follows that (Œ∂ k)n = (Œ∂ n)k = 1k = 1
for all k = 0, 1, 2, . . ., n ‚àí1, so that Œ∂ k = e2œÄik/n is also an nth root of unity. We have
exhibited n distinct nth roots of unity; there can be no others, for it will be proved in
Chapter 3 that a polynomial of degree n with rational coefÔ¨Åcients (e.g., xn ‚àí1) has at most
n complex roots.
‚Ä¢
Just as there are two square roots of a number a, namely, ‚àöa and ‚àí‚àöa, there are n
different nth roots of a, namely, e2œÄik/n n‚àöa for k = 0, 1, . . . , n ‚àí1.
Every nth root of unity is, of course, a root of the polynomial xn ‚àí1. Therefore,
xn ‚àí1 =

Œ∂ n=1
(x ‚àíŒ∂).
If Œ∂ is an nth root of unity, and if n is the smallest positive integer for which Œ∂ n = 1, we
say that Œ∂ is a primitive nth root of unity. Thus, i is an 8th root of unity, but it is not a
primitive 8th root of unity; however, i is a primitive 4th root of unity.
Lemma 1.36.
If an nth root of unity Œ∂ is a primitive dth root of unity, then d must be a
divisor of n.
Proof.
The division algorithm gives n = qd + r, where q are r are integers and the
remainder r satisÔ¨Åes 0 ‚â§r < d. But
1 = Œ∂ n = Œ∂ qd+r = Œ∂ qdŒ∂r = Œ∂r,
because Œ∂ qd = (Œ∂ d)q = 1. If r Ã∏= 0, we contradict d being the smallest exponent for which
Œ∂ d = 1. Hence, n = qd, as claimed.
‚Ä¢
DeÔ¨Ånition.
If d is a positive integer, then the dth cyclotomic3 polynomial is deÔ¨Åned by
d(x) =

(x ‚àíŒ∂),
where Œ∂ ranges over all the primitive dth roots of unity.
The following result is almost obvious.
3The roots of xn ‚àí1 are the nth roots of unity: 1, Œ∂, Œ∂ 2, . . . , Œ∂ n‚àí1, where Œ∂ = e2œÄi/n = cos(2œÄ/n) +
i sin(2œÄ/n). Now these roots divide the unit circle {Œ∂ ‚ààC : |z| = 1} into n equal arcs (see Figure 1.5 on
page 19). This explains the term cyclotomic, for its Greek origin means "circle splitting."

Sec. 1.2
Roots of Unity
21
Proposition 1.37.
For every integer n ‚â•1,
xn ‚àí1 =

d|n
d(x),
where d ranges over all the divisors d of n [in particular, 1(x) and n(x) occur].
Proof.
In light of Corollary 1.35, the proposition follows by collecting, for each divisor d
of n, all terms in the equation xn ‚àí1 = (x ‚àíŒ∂) with Œ∂ a primitive dth root of unity.
‚Ä¢
For example, if p is a prime, then x p ‚àí1 = 1(x)p(x). Since 1(x) = x ‚àí1, it
follows that
p(x) = x p‚àí1 + x p‚àí2 + ¬∑ ¬∑ ¬∑ + x + 1.
DeÔ¨Ånition.
DeÔ¨Åne the Euler œÜ-function as the degree of the nth cyclotomic polynomial:
œÜ(n) = deg(n(x)).
We now give another description of the Euler œÜ-function that does not depend on roots
of unity.
Proposition 1.38.
If n ‚â•1 is an integer, then œÜ(n) is the number of integers k with
1 ‚â§k ‚â§n and (k, n) = 1.
Proof.
It sufÔ¨Åces to prove that e2œÄik/n is a primitive nth root of unity if and only if k and
n are relatively prime.
If k and n are not relatively prime, then n = dr and k = ds, where d, r, and s are
integers, and d > 1; it follows that r < n. Hence, k
n = ds
dr = s
r , so that (e2œÄik/n)r =
(e2œÄis/r)r = 1, and hence e2œÄik/n is not a primitive nth root of unity.
Conversely, suppose that Œ∂ = e2œÄik/n is not a primitive nth root of unity. Lemma 1.36
says that Œ∂ must be a dth root of unity for some divisor d of n with d < n; that is, there is
1 ‚â§m ‚â§d with
Œ∂ = e2œÄik/n = e2œÄim/d = e2œÄimr/dr = e2œÄimr/n.
Since both k and mr are in the range between 1 and n, it follows that k = mr (if 0 ‚â§
x, y < 1 and e2œÄix = e2œÄiy, then x = y); that is, r is a divisor of k and of n, and so k and
n are not relatively prime.
‚Ä¢
Corollary 1.39.
For every integer n ‚â•1, we have
n =

d|n
œÜ(d).
Proof.
Note that œÜ(n) is the degree of n(x), and use the fact that the degree of a product
of polynomials is the sum of the degrees of the factors.
‚Ä¢
Recall that the leading coefÔ¨Åcient of a polynomial f (x) is the coefÔ¨Åcient of the high-
est power of x occurring in f (x); we say that a polynomial f (x) is monic if its leading
coefÔ¨Åcient is 1.

22
Things Past
Ch. 1
Proposition 1.40.
For every positive integer n, the cyclotomic polynomial n(x) is a
monic polynomial all of whose coefÔ¨Åcients are integers.
Proof.
The proof is by induction on n ‚â•1. The base step holds, for 1(x) = x ‚àí1. For
the inductive step, we assume that d(x) is a monic polynomial with integer coefÔ¨Åcients.
From the equation xn ‚àí1 = 
d d(x), we have
xn ‚àí1 = n(x) f (x),
where f (x) is the product of all d(x), where d < n and d is a divisor of n. By the
inductive hypothesis, f (x) is a monic polynomial with integer coefÔ¨Åcients. Because f (x)
is monic, long division (i.e., the division algorithm for polynomials) shows that all the
coefÔ¨Åcients of n(x) = (xn ‚àí1)/f (x) are also integers,4 as desired.
‚Ä¢
The following corollary will be used in Chapter 8 to prove a theorem of Wedderburn.
Corollary 1.41.
If q is a positive integer, and if d is a divisor of an integer n with d < n,
then n(q) is a divisor of both qn ‚àí1 and (qn ‚àí1)/(qd ‚àí1).
Proof.
We have already seen that xn ‚àí1 = n(x) f (x), where f (x) is a monic poly-
nomial with integer coefÔ¨Åcients. Setting x = q gives an equation in integers: qn ‚àí1 =
n(q) f (q); that is, n(q) is a divisor of qn ‚àí1.
If d is a divisor of n and d < n, consider the equation xd ‚àí1 = (x ‚àíŒ∂), where Œ∂
ranges over the dth roots of unity. Notice that each such Œ∂ is an nth root of unity, because
d is a divisor of n. Since d < n, collecting terms in the equation xn ‚àí1 = (x ‚àíŒ∂) gives
xn ‚àí1 = n(x)(xd ‚àí1)g(x),
where g(x) is the product of all the cyclotomic polynomials Œ¥(x) for all divisors Œ¥ of n
with Œ¥ < n and with Œ¥ not a divisor of d. It follows from the proposition that g(x) is a
monic polynomial with integer coefÔ¨Åcients. Therefore, g(q) ‚ààZ and
xn ‚àí1
xd ‚àí1 = n(x)g(x)
gives the result.
‚Ä¢
Here is the simplest way to Ô¨Ånd the reciprocal of a complex number. If z = a +ib ‚ààC,
where a, b ‚ààR, deÔ¨Åne its complex conjugate z = a ‚àíib. Note that zz = a2 + b2 = |z|2,
so that z Ã∏= 0 if and only if zz Ã∏= 0. If z Ã∏= 0, then
z‚àí1 = 1/z = z/zz = (a/zz) ‚àíi(b/zz);
that is,
1
a + ib =

a
a2 + b2
	
‚àíi

b
a2 + b2
	
.
4If this is not clear, look at the proof of the division algorithm on page 131.

Sec. 1.2
Roots of Unity
23
If |z| = 1, then z‚àí1 = z. In particular, if z is a root of unity, then its reciprocal is its
complex conjugate.
Complex conjugation satisÔ¨Åes the following identities:
z + w = z + w;
zw = z w;
z = z;
z = z
if and only if z is real.
We are regarding complex numbers as points in the plane and, as in vector calculus, a
point z is identiÔ¨Åed with the vector represented by the arrow ‚àí‚Üí
Oz from the origin O to z.
Let us deÔ¨Åne the dot product of z = a + ib and w = c + id to be
z ¬∑ w = ac + bd.
Thus, z ¬∑ w = |z||w| cos Œ∏, where Œ∏ is the angle between ‚àí‚Üí
Oz and ‚àí‚Üí
Ow [since cos Œ∏ =
cos(2œÄ ‚àíŒ∏), it makes no difference whether Œ∏ is measured from ‚àí‚Üí
Oz to ‚àí‚Üí
Ow or from ‚àí‚Üí
Ow
to ‚àí‚Üí
Oz]. Note that
z ¬∑ z = |z|2 = zz.
It is clear that z ¬∑ w = w ¬∑ z, and it is easy to check that
z ¬∑ (w + w‚Ä≤) = z ¬∑ w + z ¬∑ w‚Ä≤
for all complex numbers z, w, and w‚Ä≤.
The following result will be used in Chapter 8 to prove a theorem of Burnside.
Proposition 1.42.
If Œµ1, . . . , Œµn are roots of unity, where n ‚â•2, then

n

j=1
Œµ j
 ‚â§
n

j=1
Œµ j
 = n.
Moreover, there is equality if and only if all the Œµ j are equal.
Proof.
The proof of the inequality is by induction on n ‚â•2. The base step follows from
the triangle inequality: for all complex numbers u and v,
|u + v| ‚â§|u| + |v|.
The proof of the inductive step is routine, for roots of unity have modulus 1.
Suppose now that all the Œµ j are equal, say Œµ j = Œµ for all j, then it is clear that there
is equality
n
j=1 Œµ j
 = |nŒµ| = n|Œµ| = n. The proof of the converse is by induction on
n ‚â•2. For the base step, suppose that |Œµ1 + Œµ2| = 2. Using the dot product, we have
4 = |Œµ1 + Œµ2|2
= (Œµ1 + Œµ2) ¬∑ (Œµ1 + Œµ2)
= |Œµ1|2 + 2Œµ1 ¬∑ Œµ2 + |Œµ2|2
= 2 + 2Œµ1 ¬∑ Œµ2.

24
Things Past
Ch. 1
Hence, 2 = 1 + Œµ1 ¬∑ Œµ2, so that
1 = Œµ1 ¬∑ Œµ2
= |Œµ1||Œµ2| cos Œ∏
= cos Œ∏,
where Œ∏ is the angle between ‚àí‚àí‚Üí
OŒµ1 and ‚àí‚àí‚Üí
OŒµ2 (for |Œµ1| = 1 = |Œµ2|). Therefore, Œ∏ = 0 or
Œ∏ = œÄ, so that Œµ2 = ¬±Œµ1. Since Œµ2 = ‚àíŒµ1 gives |Œµ1 + Œµ2| = 0, we must have Œµ2 = Œµ1.
For the inductive step, suppose that
n+1
j=1 Œµ j
 = n + 1. If
n
j=1 Œµ j
 < n, then the
triangle inequality gives

 n

j=1
Œµ j

+ Œµn+1
 ‚â§

n

j=1
Œµ j
 + 1 < n + 1,
contrary to hypothesis. Therefore,
n
j=1 Œµ j
 = n, and so the inductive hypothesis gives
Œµ1, . . . , Œµn all equal, say, to œâ. Hence, n
j=1 Œµ j = nœâ, and so
|nœâ + Œµn+1| = n + 1.
The argument concludes as that of the base step:
(n + 1)2 = (nœâ + Œµn+1) ¬∑ (nœâ + Œµn+1)
= n2 + 2nœâ ¬∑ Œµn+1 + 1,
so that 1 = œâ ¬∑ Œµn+1 = |œâ||Œµn+1| cos Œ∏, where Œ∏ is the angle between ‚àí‚Üí
Oœâ and ‚àí‚àí‚àí‚Üí
OŒµn+1.
Hence, œâ = ¬±Œµn+1, and œâ = Œµn+1.
‚Ä¢
EXERCISES
1.43 Evaluate (cos 3‚ó¶+ i sin 3‚ó¶)40.
1.44
(i) Find (3 + 4i)/(2 ‚àíi).
(ii) If z = reiŒ∏, prove that z‚àí1 = r‚àí1e‚àíiŒ∏.
(iii) Find the values of
‚àö
i.
(iv) Prove that eiŒ∏/n is an nth root of eiŒ∏.
1.45 Find 6(x).
1.46 If Œ± is a number for which cos(œÄŒ±) = 1
3 (where the angle œÄŒ± is in radians), prove that Œ± is
irrational.
Hint. If Œ± = m
n , evaluate cos nœÄŒ± + i sin nœÄŒ± using De Moivre's theorem.
1.47 Let f (x) = a0 + a1x + a2x2 + ¬∑ ¬∑ ¬∑ + anxn be a polynomial with all of its coefÔ¨Åcients real
numbers. Prove that if z is a root of f (x), then z is also a root of f (x).

Sec. 1.3
Some Set Theory
25
1.48
(i) Prove that the quadratic formula holds for quadratic polynomials with complex coefÔ¨Å-
cients.
(ii) Find the roots of x2 + (2 + i)x + 2i. Why aren't the roots complex conjugates of one
another?
1.49 Prove that for every odd integer n ‚â•1, there is a polynomial gn(x) with integer coefÔ¨Åcients,
such that
sin nx = gn(sin x).
1.50 Every Pythagorean triple (a, b, c) determines a right triangle having legs a and b and hy-
potenuse5 c. Call two Pythagorean triples (a, b, c) and (a‚Ä≤, b‚Ä≤, c‚Ä≤) similar if the right triangles
they determine are similar triangles; that is, if corresponding sides are proportional.
(i) Prove that the following statements are equivalent for Pythagorean triples (a, b, c) and
(a‚Ä≤, b‚Ä≤, c‚Ä≤).
(1) (a, b, c) and (a‚Ä≤, b‚Ä≤, c‚Ä≤) are similar.
(2) There are positive integers m and ‚Ñìwith (ma, mb, mc) = (‚Ñìa‚Ä≤, ‚Ñìb‚Ä≤, ‚Ñìc‚Ä≤)
(3) a
c + i b
c = a‚Ä≤
c‚Ä≤ + i b‚Ä≤
c‚Ä≤ .
(ii) Prove that every Pythagorean triple is similar to a primitive Pythagorean triple.
1.51
(i) Call a complex number of modulus 1 rational if both its real and imaginary parts are
rational numbers. If a
c + i b
c is a rational complex number with both a and b nonzero,
prove that (|a|, |b|, |c|) is a Pythagorean triple.
(ii) Prove that the product of two rational complex numbers is also a rational complex num-
ber, and use this fact to deÔ¨Åne a product of two Pythagorean triples (up to similarity).
What is the product of (3, 4, 5) with itself?
(iii) Show that the square of a Pythagorean triple (a, b, c) is (a2 ‚àíb2, 2ab, a2 + b2).
1.3 SOME SET THEORY
Functions are ubiquitous in algebra, as in all of mathematics, and we discuss them now.
A set X is a collection of elements (numbers, points, herring, etc.); we write
x ‚ààX
to denote x belonging to X. Two sets X and Y are deÔ¨Åned to be equal, denoted by
X = Y,
if they are comprised of exactly the same elements; for every element x, we have x ‚ààX if
and only if x ‚ààY.
A subset of a set X is a set S each of whose elements also belongs to X: If s ‚ààS, then
s ‚ààX. We denote S being a subset of X by
S ‚äÜX;
5Hypotenuse comes from the Greek word meaning "to stretch."

26
Things Past
Ch. 1
synonyms are "S is contained in X" and "S is included in X." Note that X ‚äÜX is always
true; we say that a subset S of X is a proper subset of X, denoted by S ‚ääX, if S ‚äÜX and
S Ã∏= X. It follows from the deÔ¨Ånitions that two sets X and Y are equal if and only if each
is a subset of the other:
X = Y
if and only if
X ‚äÜY and Y ‚äÜX.
Because of this remark, many proofs showing that two sets are equal break into two parts,
each half showing that one of the sets is a subset of the other. For example, let
X = {a ‚ààR : a ‚â•0}
and
Y = {r2 : r ‚ààR}.
If a ‚ààX, then a ‚â•0 and a = r2, where r = ‚àöa; hence, a ‚ààY and X ‚äÜY. For the
reverse inclusion, choose r2 ‚ààY. If r ‚â•0, then r2 ‚â•0; if r < 0, then r = ‚àís, where
s > 0, and r2 = (‚àí1)2s2 = s2 ‚â•0. In either case, r2 ‚â•0 and r2 ‚ààX. Therefore, Y ‚äÜX,
and so X = Y.
Calculus books deÔ¨Åne a function f (x) as a "rule" that assigns, to each number a, exactly
one number, namely, f (a). This deÔ¨Ånition is certainly in the right spirit, but it has a defect:
What is a rule? To ask this question another way, when are two rules the same? For
example, consider the functions
f (x) = (x + 1)2
and
g(x) = x2 + 2x + 1.
Is f (x) = g(x)? The evaluation procedures are certainly different: for example, f (6) =
(6+1)2 = 72, while g(6) = 62 +2¬∑6+1 = 36+12+1. Since the term rule has not been
deÔ¨Åned, it is ambiguous, and our question has no answer. Surely the calculus description
is inadequate if we cannot decide whether these two functions are the same.
The graph of a function is a concrete thing [for example, the graph of f (x) = x2 is
a parabola], and the upcoming formal deÔ¨Ånition of a function amounts to saying that a
function is its graph. The informal calculus deÔ¨Ånition of a function as a rule remains, but
we will have avoided the problem of saying what a rule is. In order to give the deÔ¨Ånition, we
Ô¨Årst need an analog of the plane [for we will want to use functions f (x) whose argument
x does not vary over numbers].
DeÔ¨Ånition.
If X and Y are (not necessarily distinct) sets, then their cartesian product
X √ó Y is the set of all ordered pairs (x, y), where x ‚ààX and y ‚ààY.
The plane is R √ó R.
The only thing we need to know about ordered pairs is that
(x, y) = (x‚Ä≤, y‚Ä≤)
if and only if
x = x‚Ä≤ and y = y‚Ä≤
(see Exercise 1.62 on page 37).
Observe that if X and Y are Ô¨Ånite sets, say, |X| = m and |Y| = n (we denote the number
of elements in a Ô¨Ånite set X by |X|), then |X √ó Y| = mn.

Sec. 1.3
Some Set Theory
27
DeÔ¨Ånition.
Let X and Y be (not necessarily distinct) sets. A function f from X to Y,
denoted by6
f : X ‚ÜíY,
is a subset f ‚äÜX √ó Y such that, for each a ‚ààX, there is a unique b ‚ààY with (a, b) ‚ààf .
For each a ‚ààX, the unique element b ‚ààY for which (a, b) ‚ààf is called the value of
f at a, and b is denoted by f (a). Thus, f consists of all those points in X √ó Y of the form
(a, f (a)). When f : R ‚ÜíR, then f is the graph of f (x).
Call X the domain of f , call Y the target (or codomain) of f , and deÔ¨Åne the image (or
range) of f , denoted by im f , to be the subset of Y consisting of all the values of f .
DeÔ¨Ånition.
Two functions f : X ‚ÜíY and g : X‚Ä≤ ‚ÜíY ‚Ä≤ are equal if X = X‚Ä≤, Y = Y ‚Ä≤,
and the subsets f ‚äÜX √ó Y and g ‚äÜX‚Ä≤ √ó Y ‚Ä≤ are equal.
For example, if X is a set, then the identity function 1X : X ‚ÜíX is deÔ¨Åned by 1X(x) =
x for all x ‚ààX; if X = R, then 1R is the line with slope 1 that passes through the origin.
If f : X ‚ÜíY is a function, and if S is a subset of X, then the restriction of f to S is the
function f |S : S ‚ÜíY deÔ¨Åned by ( f |S)(s) = f (s) for all s ‚ààS. If S is a subset of a set X,
deÔ¨Åne the inclusion i : S ‚ÜíX to be the function deÔ¨Åned by i(s) = s for all s ‚ààS. If S is
a proper subset of X, then the inclusion i is not the identity function 1S because its target
is X, not S; it is not the identity function 1X because its domain is S, not X.
A function f : X ‚ÜíY has three ingredients: its domain X, its target Y, and its graph,
and we are saying that two functions are equal if and only if they have the same domains,
the same targets, and the same graphs.
It is plain that the domain and the graph are essential parts of a function. Why should
we care about the target of a function when its image is more important?
As a practical matter, when Ô¨Årst deÔ¨Åning a function, we usually do not know its image.
For example, we say that f : R ‚ÜíR, given by f (x) = x2 + 3x ‚àí8, is a real-valued
function, and we then analyze f to Ô¨Ånd its image. But if targets have to be images, then
we could not even write down f : X ‚ÜíY without having Ô¨Årst found the image of f
(and Ô¨Ånding the precise image is often very difÔ¨Åcult, if not impossible); thus, targets are
convenient to use.
In linear algebra, we consider a vector space V and its dual space V ‚àó= {all linear
functionals on V } (which is also a vector space). Moreover, every linear transformation
T : V ‚ÜíW deÔ¨Ånes a linear transformation
T ‚àó: W ‚àó‚ÜíV ‚àó,
and the domain of T ‚àó, being W ‚àó, is determined by the target W of T . (In fact, if a matrix
for T is A, then a matrix for T ‚àóis At, the transpose of A.) Thus, changing the target of T
changes the domain of T ‚àó, and so T ‚àóis changed in an essential way.
6From now on, we denote a function by f instead of by f (x). The notation f (x) is reserved for the value of
f at x; there are a few exceptions: We will continue to write sin x, ex, and x2, for example.

28
Things Past
Ch. 1
Proposition 1.43.
Let f : X ‚ÜíY and g : X ‚ÜíY be functions. Then f = g if and only
if f (a) = g(a) for every a ‚ààX.
Remark.
This proposition resolves the problem raised by the ambiguous term rule. If f ,
g : R ‚ÜíR are given by f (x) = (x + 1)2 and g(x) = x2 + 2x + 1, then f = g because
f (a) = g(a) for every number a.
‚óÄ
Proof.
Assume that f = g. Functions are subsets of X √ó Y, and so f = g means that
each of f and g is a subset of the other (informally, we are saying that f and g have the
same graph). If a ‚ààX, then (a, f (a)) ‚ààf = g, and so (a, f (a)) ‚ààg. But there is
only one ordered pair in g with Ô¨Årst coordinate a, namely, (a, g(a)) (because the deÔ¨Ånition
of function says that g gives a unique value to a). Therefore, (a, f (a)) = (a, g(a)), and
equality of ordered pairs gives f (a) = g(a), as desired.
Conversely, assume that f (a) = g(a) for every a ‚ààX. To see that f = g, it sufÔ¨Åces
to show that f ‚äÜg and g ‚äÜf . Each element of f has the form (a, f (a)). Since
f (a) = g(a), we have (a, f (a)) = (a, g(a)), and hence (a, f (a)) ‚ààg. Therefore, f ‚äÜg.
The reverse inclusion g ‚äÜf is proved similarly.
‚Ä¢
We continue to regard a function f as a rule sending x ‚ààX to f (x) ‚ààY, but the
precise deÔ¨Ånition is now available whenever we need it, as in the proof of Proposition 1.43.
However, to reinforce our wanting to regard functions f : X ‚ÜíY as dynamic things
sending points in X to points in Y, we often write
f : x ‚Üíy
instead of f (x) = y. For example, we may write f : x ‚Üíx2 instead of f (x) = x2, and
we may describe the identity function by x ‚Üíx for all x.
Instead of saying that values of a function f are unique, we usually say that f is well-
deÔ¨Åned (or single-valued). Does the formula g(a/b) = ab deÔ¨Åne a function g : Q ‚ÜíQ?
There are many ways to write a fraction; since 1
2 = 3
6, we see that g( 1
2) = 1 ¬∑ 2 Ã∏= 3 ¬∑ 6 =
g

3
6

, and so g is not a function because it is not well-deÔ¨Åned. Had we said that the
formula g(a/b) = ab holds whenever a/b is in lowest terms, then g would be a function.
The formula f (a/b) = 3a/b does deÔ¨Åne a function f : Q ‚ÜíQ, for it is well-deÔ¨Åned:
If a/b = a‚Ä≤/b‚Ä≤, we show that
f (a/b) = 3a/b = 3a‚Ä≤/b‚Ä≤ = f (a‚Ä≤/b‚Ä≤):
a/b = a‚Ä≤/b‚Ä≤ gives ab‚Ä≤ = a‚Ä≤b, so that 3ab‚Ä≤ = 3a‚Ä≤b and 3a/b = 3a‚Ä≤/b‚Ä≤. Thus, f is a bona
Ô¨Åde function; that is, f is well-deÔ¨Åned.
Example 1.44.
Our deÔ¨Ånitions allow us to treat a degenerate case. If X is a set, what are the functions
X ‚Üí‚àÖ? Note Ô¨Årst that an element of X √ó ‚àÖis an ordered pair (x, y) with x ‚ààX and
y ‚àà‚àÖ; since there is no y ‚àà‚àÖ, there are no such ordered pairs, and so X √ó ‚àÖ= ‚àÖ. Now

Sec. 1.3
Some Set Theory
29
a function X ‚Üí‚àÖis a subset of X √ó ‚àÖof a certain type; but X √ó ‚àÖ= ‚àÖ, so there is only
one subset, namely ‚àÖ, and hence at most one function, namely, f = ‚àÖ. The deÔ¨Ånition of
function X ‚Üí‚àÖsays that, for each x ‚ààX, there exists a unique y ‚àà‚àÖwith (x, y) ‚ààf .
If X Ã∏= ‚àÖ, then there exists x ‚ààX for which no such y exists (there are no elements y
at all in ‚àÖ), and so f is not a function. Thus, if X Ã∏= ‚àÖ, there are no functions from X
to ‚àÖ. On the other hand, if X = ‚àÖ, then f = ‚àÖis a function. Otherwise, the negation
of the statement " f is a function" begins "there exists x ‚àà‚àÖ, etc." We need not go on;
since ‚àÖhas no elements in it, there is no way to complete the sentence so that it is a true
statement. We conclude that f = ‚àÖis a function ‚àÖ‚Üí‚àÖ, and we declare it to be the
identity function 1‚àÖ.
‚óÄ
The special case when the image of a function is the whole target has a name.
DeÔ¨Ånition.
A function f : X ‚ÜíY is a surjection (or is onto) if
im f = Y.
Thus, f is surjective if, for each y ‚ààY, there is some x ‚ààX (probably depending on y)
with y = f (x).
The following deÔ¨Ånition gives another important property a function may have.
DeÔ¨Ånition.
A function f : X ‚ÜíY is an injection (or is one-to-one) if, whenever a and
a‚Ä≤ are distinct elements of X, then f (a) Ã∏= f (a‚Ä≤). Equivalently (the contrapositive states
that) f is injective if, for every pair a, a‚Ä≤ ‚ààX, we have
f (a) = f (a‚Ä≤) implies a = a‚Ä≤.
The reader should note that being injective is the converse of being well-deÔ¨Åned: f
is well-deÔ¨Åned if a = a‚Ä≤ implies f (a) = f (a‚Ä≤); f is injective if f (a) = f (a‚Ä≤) implies
a = a‚Ä≤.
There are other names for these functions. Surjections are often called epimorphisms
and injections are often called monomorphisms. The notation A ‚Ü†B is used to denote a
surjection, and the notations A ‚ÜíB or A ‚Ü£B are used to denote injections. However,
we shall not use this terminology or these notations in this book.
Example 1.45.
Consider the function f : R ‚ÜíR, given by f (x) = 3x ‚àí4. To see whether f is surjective,
take y ‚ààR and ask whether there is a ‚ààR with y = 3a ‚àí4. We solve to obtain
a = 1
3(y + 4), and we conclude that f is surjective. Also, the function f is injective, for if
3a ‚àí4 = 3b ‚àí4, then a = b.
As a second example, consider the function g : R ‚àí{1} ‚ÜíR given by
g(x) = 3x ‚àí4
x ‚àí1 .

30
Things Past
Ch. 1
Now g is an injection, for if (3a‚àí4)/(a‚àí1) = (3b‚àí4)/(b‚àí1), then cross multiplying
gives a = b. On the other hand, g is not surjective. Given y ‚ààR, is there a ‚ààR with
y = (3a ‚àí4)/(a ‚àí1)? Solving, a = (4 ‚àíy)/(3 ‚àíy). This suggests that y = 3 is not a
value of g, and, indeed, it is not: 3 = (3a ‚àí4)/(a ‚àí1) is not solvable.
‚óÄ
DeÔ¨Ånition.
If f : X ‚ÜíY and g : Y ‚ÜíZ are functions (note that the target of f is equal
to the domain of g), then their composite, denoted by g ‚ó¶f , is the function X ‚ÜíZ given
by
g ‚ó¶f : x ‚Üíg( f (x));
that is, Ô¨Årst evaluate f on x, and then evaluate g on f (x).
The chain rule in calculus is a formula for the derivative (g ‚ó¶f )‚Ä≤ in terms of g‚Ä≤ and f ‚Ä≤:
(g ‚ó¶f )‚Ä≤ =

g‚Ä≤ ‚ó¶f

¬∑ f ‚Ä≤.
For example,
(sin(ln x))‚Ä≤ = cos(ln x) ¬∑ 1
x .
Given a set X, let
F(X) = {all functions X ‚ÜíX}.
We have just seen that the composite of two functions in F(X) is always deÔ¨Åned; moreover,
the composite is again a function in F(X). We may thus regard F(X) as being equipped
with a kind of multiplication. This multiplication is not commutative; that is, f ‚ó¶g and g‚ó¶f
need not be equal. For example, if f (x) = x+1 and g(x) = x2, then f ‚ó¶g : 1 ‚Üí12+1 = 2
while g ‚ó¶f : 1 ‚Üí(1 + 1)2 = 4; therefore, f ‚ó¶g Ã∏= g ‚ó¶f .
Lemma 1.46.
(i) Composition is associative: If
f : X ‚ÜíY,
g : Y ‚ÜíZ,
and
h : Z ‚ÜíW
are functions, then
h ‚ó¶(g ‚ó¶f ) = (h ‚ó¶g) ‚ó¶f.
(ii) If f : X ‚ÜíY, then 1Y ‚ó¶f = f = f ‚ó¶1X.
Sketch of Proof.
Use Proposition 1.43.
‚Ä¢
Are there "reciprocals" in F(X); that is, are there any functions f for which there is
g ‚ààF(X) with f ‚ó¶g = 1X and g ‚ó¶f = 1X?
DeÔ¨Ånition.
A function f : X ‚ÜíY is a bijection (or a one-to-one correspondence) if it is
both an injection and a surjection.

Sec. 1.3
Some Set Theory
31
DeÔ¨Ånition.
A function f : X ‚ÜíY has an inverse if there is a function g : Y ‚ÜíX with
both composites g ‚ó¶f and f ‚ó¶g being identity functions.
Proposition 1.47.
(i) If f : X ‚ÜíY and g : Y ‚ÜíX are functions such that g ‚ó¶f = 1X, then f is injective
and g is surjective.
(ii) A function f : X ‚ÜíY has an inverse g: Y ‚ÜíX if and only if f is a bijection.
Proof.
(i) Suppose that f (x) = f (x‚Ä≤); apply g to obtain g( f (x)) = g( f (x‚Ä≤)); that is,
x = x‚Ä≤ [because g( f (x)) = x], and so f is injective. If x ‚ààX, then x = g( f (x)), so that
x ‚ààim g; hence g is surjective.
(ii) If f has an inverse g, then part (i) shows that f is injective and surjective, for both
composites g ‚ó¶f and f ‚ó¶g are identities.
Assume that f is a bijection. For each y ‚ààY, there is a ‚ààX with f (a) = y, since f
is surjective, and this element a is unique because f is injective. DeÔ¨Åning g(y) = a thus
gives a (well-deÔ¨Åned) function whose domain is Y, and it is plain that g is the inverse of
f ; that is, f (g(y)) = f (a) = y for all y ‚ààY and g( f (a)) = g(y) = a for all a ‚ààX.
‚Ä¢
Remark.
Exercise 1.59 on page 36 shows that if both f and g are injective, then so is
their composite f ‚ó¶g. Similarly, f ‚ó¶g is a surjection if both f and g are surjections. It
follows that the composite of two bijections is itself a bijection.
‚óÄ
Notation.
The inverse of a bijection f is denoted by f ‚àí1 (Exercise 1.54 on page 36 says
that a function cannot have two inverses).
Example 1.48.
Here is an example of two functions f and g one of whose composites g ‚ó¶f is the identity
while the other composite f ‚ó¶g is not the identity; thus, f and g are not inverse functions.
If N = {n ‚ààZ : n ‚â•0}, deÔ¨Åne f , g : N ‚ÜíN as follows:
f (n) = n + 1;
g(n) =

0
if n = 0
n ‚àí1
if n ‚â•1.
The composite g ‚ó¶f = 1N, for g( f (n)) = g(n + 1) = n, because n + 1 ‚â•1. On the other
hand, f ‚ó¶g Ã∏= 1N, because f (g(0)) = f (0) = 1 Ã∏= 0.
Notice that f is an injection but not a surjection, and that g is a surjection but not an
injection.
‚óÄ

32
Things Past
Ch. 1
Two strategies are now available to determine whether or not a given function is a
bijection: (i) use the deÔ¨Ånitions of injection and surjection; (ii) Ô¨Ånd an inverse. For ex-
ample, if R> denotes the positive real numbers, let us show that the exponential function
f : R ‚ÜíR>, deÔ¨Åned by f (x) = ex =  xn/n!, is a bijection. It is simplest to use the
(natural) logarithm g(y) = ln y =
 y
1 dt/t. The usual formulas eln y = y and ln ex = x
say that both composites f ‚ó¶g and g‚ó¶f are identities, and so f and g are inverse functions.
Therefore, f is a bijection, for it has an inverse. (A direct proof that f is an injection would
require showing that if ea = eb, then a = b; a direct proof showing that f is surjective
would involve showing that every positive real number c has the form ea for some a.)
Let us summarize the results just obtained.
Theorem 1.49.
If the set of all the bijections from a set X to itself is denoted by SX, then
composition of functions satisÔ¨Åes the following properties:
(i) if f , g ‚ààSX, then f ‚ó¶g ‚ààSX;
(ii) h ‚ó¶(g ‚ó¶f ) = (h ‚ó¶g) ‚ó¶f for all f, g, h ‚ààSX;
(iii) the identity 1X lies in SX, and 1X ‚ó¶f = f = f ‚ó¶1X for every f ‚ààSX;
(iv) for every f ‚ààSX, there is g ‚ààSX with g ‚ó¶f = 1X = f ‚ó¶g.
Sketch of Proof.
Part (i) follows from Exercise 1.59 on page 36, which shows that the
composite of two bijections is itself a bijection. The other parts of the statement have been
proved above.
‚Ä¢
If X and Y are sets, then a function f : X ‚ÜíY deÔ¨Ånes a "forward motion" carrying
subsets of X into subsets of Y, namely, if S ‚äÜX, then
f (S) = {y ‚ààY : y = f (s) for some s ‚ààS},
and a "backward motion" carrying subsets of Y into subsets of X, namely, if W ‚äÜY, then
f ‚àí1(W) = {x ‚ààX : f (x) ‚ààW}.
We call f ‚àí1(W) the inverse image of W. Formally, denote the family of all the subsets of
a set X by P(X). If f : X ‚ÜíY, then there are functions
f‚àó: P(X) ‚ÜíP(Y),
given by f‚àó: S ‚Üíf (S), and
f ‚àó: P(Y) ‚ÜíP(X),
given by f ‚àó: W ‚Üíf ‚àí1(W). When f is a surjection, then these motions set up a bijection
between all the subsets of Y and some of the subsets of X.

Sec. 1.3
Some Set Theory
33
Proposition 1.50.
Let X and Y be sets, and let f : X ‚ÜíY be a surjection.
(i) If T ‚äÜS are subsets of X, then f (T ) ‚äÜf (S), and if U ‚äÜV are subsets of Y, then
f ‚àí1(U) ‚äÜf ‚àí1(V ).
(ii) If U ‚äÜY, then f f ‚àí1(U) = U.
(iii) The composite f‚àóf ‚àó: P(Y) ‚ÜíP(Y) = 1P(Y), and so f ‚àó: W ‚Üíf ‚àí1(W) is an
injection.
(iv) If S ‚äÜX, then S ‚äÜf ‚àí1 f (S), but strict inclusion is possible.
Remark.
If f is not a surjection, then W ‚Üíf ‚àí1(W) need not be an injection: There is
some y ‚ààY with y /‚ààf (X), and f ‚àí1({y}) = ‚àÖ= f ‚àí1(‚àÖ).
‚óÄ
Proof.
(i) If y ‚ààf (T ), then y = f (t) for some t ‚ààT . But t ‚ààS, because T ‚äÜS, and so
f (t) ‚ààf (S). Therefore, f (T ) ‚äÜf (S). The other inclusion is proved just as easily.
(ii) If u ‚ààU, then f being surjective says that there is x ‚ààX with f (x) = u; hence,
x ‚ààf ‚àí1(U), and so u = f (x) ‚ààf f ‚àí1(U). For the reverse inclusion, let a ‚ààf f ‚àí1(U);
hence, a = f (x‚Ä≤) for some x‚Ä≤ ‚ààf ‚àí1(U). But this says that a = f (x‚Ä≤) ‚ààU, as desired.
(iii) Part (ii) says that f‚àóf ‚àó= 1P(Y), and so Proposition 1.47 says that f ‚àóis an injection.
(iv) If s ‚ààS, then f (s) ‚ààf (S), and so s ‚ààf ‚àí1 f (s) ‚äÜf ‚àí1 f (S).
To see that there may be strict inclusion, let f : R ‚ÜíC be given by x ‚Üíe2œÄix. If
S = {0}, then f (S) = {1} and f ‚àí1 f ({1}) = Z.
‚Ä¢
In Exercise 1.68 on page 37, we will see that if f : X ‚ÜíY, then inverse image behaves
better on subsets than does forward image; for example, f ‚àí1(S ‚à©T ) = f ‚àí1(S)‚à©f ‚àí1(T ),
where S, T ‚äÜY, but for A, B ‚äÜX, it is possible that f (A ‚à©B) Ã∏= f (A) ‚à©f (B).
We will need cartesian products of more than two sets. One may view an element
(x1, x2) ‚ààX1 √ó X2 as the function f : {1, 2} ‚ÜíX1 ‚à™X2 with f (i) = xi ‚ààXi for
i = 1, 2.
DeÔ¨Ånition.
Let I be a set and let {Xi : i ‚ààI} be an indexed family of sets. Then the
cartesian product is the set

i‚ààI
Xi =

f : I ‚Üí

i‚ààI
Xi : f (i) ‚ààXi for all i ‚ààI

.
The elements x ‚àà
i Xi can be viewed as "vectors" x = (xi) whose ith coordinate is
xi = f (i) for all i ‚ààI. If I is Ô¨Ånite, say, I = {1, 2, . . . , n}, then it is not difÔ¨Åcult to see
that 
i Xi = X1 √ó ¬∑ ¬∑ ¬∑ √ó Xn, where the latter set is deÔ¨Åned, inductively, by
X1 √ó ¬∑ ¬∑ ¬∑ √ó Xn+1 =

X1 √ó ¬∑ ¬∑ ¬∑ √ó Xn

√ó Xn+1.
If the index set I is inÔ¨Ånite and all the Xi are nonempty, it is not obvious that 
i‚ààI Xi is
nonempty. Indeed, this assertion is equivalent to the axiom of choice (see the Appendix).
The notion of relation, which generalizes that of a function, is useful.

34
Things Past
Ch. 1
DeÔ¨Ånition.
If X and Y are sets, then a relation from X to Y is a subset R ‚äÜX √ó Y. We
usually write
x R y
to denote (x, y) ‚ààR. If X = Y, then we say that R is a relation on X.
Let us give a concrete illustration to convince the reader that this deÔ¨Ånition is reasonable.
One expects that ‚â§is a relation on R, and let us see that it does, in fact, realize the deÔ¨Ånition
of relation. Let
R = {(x, y) ‚ààR √ó R : (x, y) lies on or above the line y = x}.
The reader should recognize that x R y holds if and only if, in the usual sense, x ‚â§y.
Example 1.51.
(i) Every function f : X ‚ÜíY is a relation.
(ii) Equality is a relation on any set X; it is the diagonal
X = {(x, x) ‚ààX √ó X}.
(iii) The empty set ‚àÖdeÔ¨Ånes a relation on any set, but it is not very interesting.
‚óÄ
DeÔ¨Ånition.
A relation x ‚â°y on a set X is
reÔ¨Çexive: if x ‚â°x for all x ‚ààX;
symmetric: if x ‚â°y implies y ‚â°x for all x, y ‚ààX;
transitive: if x ‚â°y and y ‚â°z imply x ‚â°z for all x, y, z ‚ààX.
A relation that has all three properties‚ÄîreÔ¨Çexivity, symmetry, and transitivity‚Äîis called
an equivalence relation.
Example 1.52.
(i) Equality is an equivalence relation on any set X. We should regard any equivalence
relation as a generalized equality.
(ii) For any integer m ‚â•0, congruence mod m is an equivalence relation on Z.
‚óÄ
An equivalence relation on a set X yields a family of subsets of X.
DeÔ¨Ånition.
Let ‚â°be an equivalence relation on a set X. If a ‚ààX, the equivalence class
of a, denoted by [a], is deÔ¨Åned by
[a] = {x ‚ààX : x ‚â°a} ‚äÜX.
For example, under congruence mod m, the equivalence class [a] of an integer a is called
its congruence class.
The next lemma says that we can replace equivalence by honest equality at the cost of
replacing elements by their equivalence classes.

Sec. 1.3
Some Set Theory
35
Lemma 1.53.
If ‚â°is an equivalence relation on a set X, then x ‚â°y if and only if
[x] = [y].
Proof.
Assume that x ‚â°y. If z ‚àà[x], then z ‚â°x, and so transitivity gives z ‚â°y; hence
[x] ‚äÜ[y]. By symmetry, y ‚â°x, and this gives the reverse inclusion [y] ‚äÜ[x]. Thus,
[x] = [y].
Conversely, if [x] = [y], then x ‚àà[x], by reÔ¨Çexivity, and so x ‚àà[x] = [y]. Therefore,
x ‚â°y.
‚Ä¢
DeÔ¨Ånition.
A family of subsets Ai of a set X is called pairwise disjoint if
Ai ‚à©A j = ‚àÖ
for all i Ã∏= j. A partition of a set X is a family of pairwise disjoint nonempty subsets,
called blocks, whose union is all of X.
Proposition 1.54.
If ‚â°is an equivalence relation on a set X, then the equivalence classes
form a partition of X. Conversely, given a partition {Ai : i ‚ààI} of X, there is an equiva-
lence relation on X whose equivalence classes are the blocks Ai.
Proof.
Assume that an equivalence relation ‚â°on X is given. Each x ‚ààX lies in the
equivalence class [x] because ‚â°is reÔ¨Çexive; it follows that the equivalence classes are
nonempty subsets whose union is X. To prove pairwise disjointness, assume that a ‚àà
[x] ‚à©[y], so that a ‚â°x and a ‚â°y. By symmetry, x ‚â°a, and so transitivity gives x ‚â°y.
Therefore, [x] = [y], by the lemma, and the equivalence classes form a partition of X.
Conversely, let {Ai : i ‚ààI} be a partition of X. If x, y ‚ààX, deÔ¨Åne x ‚â°y if there is
i ‚ààI with both x ‚ààAi and y ‚ààAi. It is plain that ‚â°is reÔ¨Çexive and symmetric. To see
that ‚â°is transitive, assume that x ‚â°y and y ‚â°z; that is, there are i, j ‚ààI with x, y ‚ààAi
and y, z ‚ààA j. Since y ‚ààAi ‚à©A j, pairwise disjointness gives Ai = A j, so that i = j and
x, z ‚ààAi; that is, x ‚â°z. We have shown that ‚â°is an equivalence relation.
It remains to show that the equivalence classes are the Ai's. If x ‚ààX, then x ‚ààAi, for
some i. By deÔ¨Ånition of ‚â°, if y ‚ààAi, then y ‚â°x and y ‚àà[x]; hence, Ai ‚äÜ[x]. For the
reverse inclusion, let z ‚àà[x], so that z ‚â°x. There is some j with x ‚ààA j and z ‚ààA j;
thus, x ‚ààAi ‚à©A j. By pairwise disjointness, i = j, so that z ‚ààAi, and [x] ‚äÜAi. Hence,
[x] = Ai.
‚Ä¢
Example 1.55.
(i) We have just seen that an equivalence relation can be deÔ¨Åned on a set from a partition.
Let I = [0, 1] be the closed unit interval, and deÔ¨Åne a partition of I whose blocks are the 2-
point set {0, 1} and all the 1-point sets {a}, where 0 < a < 1. The family of all the blocks,
that is, of all the equivalence classes, can be viewed as a circle, for we have identiÔ¨Åed the
two endpoints of the interval.

36
Things Past
Ch. 1
Here is another construction of the circle, now from R instead of from I. DeÔ¨Åne a
relation on R by a ‚â°b if a ‚àíb ‚ààZ. It is easy to see that this is an equivalence relation on
R, and the equivalence class of a number a is
[a] = {r ‚ààR : r = a + n for some n ‚ààZ}.
The family of all blocks is again the circle (we have identiÔ¨Åed the endpoints of any interval
of length 1).
(ii) DeÔ¨Åne an equivalence relation on the square I√óI in which the blocks are {(a, 0), (a, 1)},
one for each a ‚ààI, {(0, b), (1, b)}, one for each b ‚ààI, as well as all the singleton sets
{(a, b)} in the interior of the square. The family of all equivalence classes can be viewed
as a torus (the surface of a doughnut): Identifying the left and right sides of the square
gives a cylinder, and further identifying the top and bottom ends of the cylinder gives a
torus.
‚óÄ
EXERCISES
1.52 Let X and Y be sets, and let f : X ‚ÜíY be a function. If S is a subset of X, prove that the
restriction f |S is equal to the composite f ‚ó¶i, where i : S ‚ÜíX is the inclusion map.
Hint. Use Proposition 1.43.
1.53 If f : X ‚ÜíY has an inverse g, show that g is a bijection.
Hint. Does g have an inverse?
1.54 Show that if f : X ‚ÜíY is a bijection, then it has exactly one inverse.
1.55 Show that f : R ‚ÜíR, deÔ¨Åned by f (x) = 3x + 5, is a bijection, and Ô¨Ånd its inverse.
1.56 Determine whether f : Q √ó Q ‚ÜíQ, given by
f (a/b, c/d) = (a + c)/(b + d),
is a function.
1.57 Let X = {x1, . . . , xm} and Y = {y1, . . . , yn} be Ô¨Ånite sets. Show that there is a bijection
f : X ‚ÜíY if and only if |X| = |Y|; that is, m = n.
Hint. If f is a bijection, there are m distinct elements f (x1), . . . , f (xm) in Y, and so m ‚â§n;
using the bijection f ‚àí1 in place of f gives the reverse inequality n ‚â§m.
1.58 If X and Y are Ô¨Ånite sets with the same number of elements, show that the following conditions
are equivalent for a function f : X ‚ÜíY:
(i) f is injective;
(ii) f is bijective;
(iii) f is surjective.
Hint. If A ‚äÜX and |A| = n = |X|, then A = X; after all, how many elements are in X but
not in A?
1.59 Let f : X ‚ÜíY and g: Y ‚ÜíZ be functions.
(i) If both f and g are injective, then g ‚ó¶f is injective.

Sec. 1.3
Some Set Theory
37
(ii) If both f and g are surjective, then g ‚ó¶f is surjective.
(iii) If both f and g are bijective, then g ‚ó¶f is bijective.
(iv) If g ‚ó¶f is a bijection, prove that f is an injection and g is a surjection.
1.60 If f : (‚àíœÄ/2, œÄ/2) ‚ÜíR is deÔ¨Åned by a ‚Üítan a, prove that f has an inverse function g;
indeed, g = arctan.
1.61 If A and B are subsets of a set X, deÔ¨Åne
A ‚àíB = {a ‚ààA : a /‚ààB}.
Prove that A ‚àíB = A ‚à©B‚Ä≤, where B‚Ä≤ = X ‚àíB is the complement of B; that is,
B‚Ä≤ = {x ‚ààX : x /‚ààB}.
1.62 Let A and B be sets, and let a ‚ààA and b ‚ààB. DeÔ¨Åne their ordered pair as follows:
(a, b) = {a, {a, b}}.
If a‚Ä≤ ‚ààA and b‚Ä≤ ‚ààB, prove that (a‚Ä≤, b‚Ä≤) = (a, b) if and only if a‚Ä≤ = a and b‚Ä≤ = b.
Hint. One of the axioms constraining the ‚ààrelation is that the statement
a ‚ààx ‚ààa
is always false.
1.63
(i) What is wrong with the following argument, which claims to prove that a symmetric
and transitive relation R on a set X is reÔ¨Çexive? If x ‚ààX, then take y ‚ààX with x R y.
By symmetry, we have y R x, and by transitivity, we have x R x.
(ii) Give an example of a symmetric and transitive relation on a set that is not reÔ¨Çexive.
1.64
(i) Let X be a set, and let R ‚äÜX √ó X. DeÔ¨Åne R = 
R‚Ä≤‚ààE R‚Ä≤, where E is the family of all
the equivalence relations R‚Ä≤ on X containing R. Prove that R is an equivalence relation
on X (R is called the equivalence relation generated by R).
(ii) Let R be a reÔ¨Çexive and symmetric relation on a set X. Prove that R, the equivalence
relation generated by R, consists of all (x, y) ‚ààX √ó X for which there exist Ô¨Ånitely
many (x, y) ‚ààR, say, (x1, y1), . . . , (xn, yn), with x = x1, yn = y, and yi = xi+1 for
all i ‚â•1.
1.65 Let X = {(a, b) : a, b ‚ààZ and b Ã∏= 0}. Prove that the relation on X, deÔ¨Åned by (a, b) ‚â°(c, d)
if ad = bc, is an equivalence relation on X. What is the equivalence class of (1, 2)?
1.66 DeÔ¨Åne a relation on C by z ‚â°w if |z| = |w|. Prove that this is an equivalence relation on C
whose equivalence classes are the origin and the circles with center the origin.
1.67
(i) Let f : X ‚ÜíY be a function (where X and Y are sets). Prove that the relation on X,
deÔ¨Åned by x ‚â°x‚Ä≤ if f (x) = f (x‚Ä≤), is an equivalence relation.
(ii) DeÔ¨Åne f : R ‚ÜíS1, where S1 ‚äÜC is the unit circle, by f (x) = e2œÄix. What is the
equivalence class of 0 under the equivalence relation in part (i)?
1.68 Let f : X ‚ÜíY be a function and let V, W ‚äÜY.
(i) Prove that
f ‚àí1(V ‚à©W) = f ‚àí1(V ) ‚à©f ‚àí1(W)
and
f ‚àí1(V ‚à™W) = f ‚àí1(V ) ‚à™f ‚àí1(W).

38
Things Past
Ch. 1
(ii) Prove that f (V ‚à™W) = f (V ) ‚à™f (W).
(iii) Give an example showing that f (V ‚à©W) Ã∏= f (V ) ‚à©f (W).
(iv) Prove that f ‚àí1(W ‚Ä≤) = ( f ‚àí1(W)‚Ä≤, where W ‚Ä≤ = {y ‚ààY : y /‚ààW} is the complement of
W, and give an example of a function f such that f (S‚Ä≤) Ã∏= ( f (S))‚Ä≤ for some S ‚äÜX.

2
Groups I
2.1 INTRODUCTION
One of the major open problems, following the discovery of the cubic and quartic formulas
in the 1500s, was to Ô¨Ånd a formula for the roots of polynomials of higher degree, and it
remained open for almost 300 years. For about the Ô¨Årst 100 years, mathematicians recon-
sidered what number means, for understanding the cubic formula forced such questions
as whether negative numbers are numbers and whether complex numbers are legitimate
entities as well. By 1800, P. RufÔ¨Åni claimed that there is no quintic formula (which has
the same form as the quadratic, cubic, and quartic formulas; that is, it uses only arith-
metic operations and nth roots), but his contemporaries did not accept his proof (his ideas
were, in fact, correct, but his proof had gaps). In 1815, A. L. Cauchy introduced the
multiplication of permutations and proved basic properties of what we call the symmetric
group Sn; for example, he introduced the cycle notation and proved the unique factoriza-
tion of permutations into disjoint cycles. In 1824, N. Abel (1802-1829) gave an acceptable
proof that there is no quintic formula; in his proof, Abel constructed permutations of the
roots of a quintic, using certain rational functions introduced by J. L. Lagrange in 1770.
E. Galois (1811-1832), the young wizard who was killed before his 21st birthday, mod-
iÔ¨Åed the rational functions but, more important, he saw that the key to understanding the
problem involved what he called groups: subsets of Sn that are closed under multiplica-
tion - in our language, subgroups of Sn. To each polynomial f (x), he associated such
a group, nowadays called the Galois group of f (x). He recognized conjugation, normal
subgroups, quotient groups, and simple groups, and he proved, in our language, that a
polynomial (over a Ô¨Åeld of characteristic 0) has a formula for its roots, analogous to the
quadratic formula, if and only if its Galois group is a solvable group (solvability being a
property generalizing commutativity). A good case can be made that Galois was one of the
most important founders of modern algebra. For an excellent account of the history of this
problem we recommend the book, Galois' Theory of Algebraic Equations, by J.-P. Tignol.
39

40
Groups I
Ch. 2
Along with results usually not presented in a Ô¨Årst course, this chapter will also review
some familiar results whose proofs will only be sketched.
2.2 PERMUTATIONS
For Galois, groups consisted of certain permutations (of the roots of a polynomial), and
groups of permutations remain important today.
DeÔ¨Ånition.
A permutation of a set X is a bijection from X to itself.
In high school mathematics, a permutation of a set X is deÔ¨Åned as a rearrangement of
its elements. For example, there are six rearrangements of X = {1, 2, 3}:
123;
132;
213;
231;
312;
321.
Now let X = {1, 2, . . . , n}. A rearrangement is a list, with no repetitions, of all the
elements of X. All we can do with such lists is count them, and there are exactly n!
permutations of the n-element set X.
Now a rearrangement i1, i2, . . . , in of X determines a function Œ± : X ‚ÜíX, namely,
Œ±(1) = i1, Œ±(2) = i2, . . . , Œ±(n) = in. For example, the rearrangement 213 determines the
function Œ± with Œ±(1) = 2, Œ±(2) = 1, and Œ±(3) = 3. We use a two-rowed notation to denote
the function corresponding to a rearrangement; if Œ±( j) is the jth item on the list, then
Œ± =
 1
2
. . .
j
. . .
n
Œ±(1)
Œ±(2)
. . .
Œ±( j)
. . .
Œ±(n)
	
.
That a list contains all the elements of X says that the corresponding function Œ± is surjec-
tive, for the bottom row is im Œ±; that there are no repetitions on the list says that distinct
points have distinct values; that is, Œ± is injective. Thus, each list determines a bijection
Œ± : X ‚ÜíX; that is, each rearrangement determines a permutation. Conversely, every per-
mutation Œ± determines a rearrangement, namely, the list Œ±(1), Œ±(2), . . . , Œ±(n) displayed as
the bottom row. Therefore, rearrangement and permutation are simply different ways of
describing the same thing. The advantage of viewing permutations as functions, however,
is that they can now be composed and, by Exercise 1.59 on page 36, their composite is also
a permutation.
DeÔ¨Ånition.
The family of all the permutations of a set X, denoted by SX, is called the
symmetric group on X. When X = {1, 2, . . . , n}, SX is usually denoted by Sn, and it is
called the symmetric group on n letters.
Let us simplify notation by writing Œ≤Œ± instead of Œ≤ ‚ó¶Œ± and (1) instead of 1X.
Notice that composition in S3 is not commutative. Aside from being cumbersome, there
is a major problem with the two-rowed notation for permutations. It hides the answers to
elementary questions such as, Do two permutations commute? Is the square of a permuta-
tion the identity? The special permutations introduced next will remedy this defect.

Sec. 2.2
Permutations
41
DeÔ¨Ånition.
Let i1, i2, . . . , ir be distinct integers in {1, 2, . . . , n}. If Œ± ‚ààSn Ô¨Åxes the other
integers (if any) and if
Œ±(i1) = i2, Œ±(i2) = i3, . . . , Œ±(ir‚àí1) = ir, Œ±(ir) = i1,
then Œ± is called an r-cycle. We also say that Œ± is a cycle of length r, and we denote it by
Œ± = (i1 i2 . . . ir).
A 2-cycle interchanges i1 and i2 and Ô¨Åxes everything else; 2-cycles are also called
transpositions. A 1-cycle is the identity, for it Ô¨Åxes every i; thus, all 1-cycles are equal:
(i) = (1) for all i.
The term cycle comes from the Greek word for circle. Picture the cycle (i1 i2 . . . ir)
as a clockwise rotation of the circle, as in Figure 2.1.
i
i
i
i
r
1
2
3
.
.
.
.
.
.
Figure 2.1
Any i j can be taken as the "starting point," and so there are r different cycle notations for
any r-cycle:
(i1 i2 . . . ir) = (i2 i3 . . . ir i1) = ¬∑ ¬∑ ¬∑ = (ir i1 i2 . . . ir‚àí1).
Let us now give an algorithm to factor a permutation into a product of cycles. For example,
take
Œ± =
1
2
3
4
5
6
7
8
9
6
4
7
2
5
1
8
9
3
	
.
Begin by writing "(1." Now Œ± : 1 ‚Üí6, so write "(1 6." Next, Œ± : 6 ‚Üí1, and so the
parentheses close: Œ± begins "(1 6)." The Ô¨Årst number not having appeared is 2, and so
we write "(1 6)(2." Now Œ± : 2 ‚Üí4, so we write "(1 6)(2 4." Since Œ± : 4 ‚Üí2, the
parentheses close once again, and we write "(1 6)(2 4)." The smallest remaining number
is 3; now 3 ‚Üí7, 7 ‚Üí8, 8 ‚Üí9, and 9 ‚Üí3; this gives the 4-cycle (3 7 8 9). Finally,
Œ±(5) = 5; we claim that
Œ± = (1 6)(2 4)(3 7 8 9)(5).

42
Groups I
Ch. 2
Since multiplication in Sn is composition of functions, our claim is that
Œ±(i) = [(1 6)(2 4)(3 7 8 9)(5)](i)
for every i between 1 and 9 [after all, two functions f and g are equal if and only if
f (i) = g(i) for every i in their domain]. The right side is the composite Œ≤Œ≥ Œ¥, where
Œ≤ = (1 6), Œ≥ = (2 4), and Œ¥ = (3 7 8 9) [we may ignore the 1-cycle (5) when we are
evaluating, for it is the identity function]. Now Œ±(1) = 6; let us evaluate the composite on
the right when i = 1.
Œ≤Œ≥ Œ¥(1) = Œ≤(Œ≥ (Œ¥(1)))
= Œ≤(Œ≥ (1))
Œ¥ = (3 7 8 9) Ô¨Åxes 1
= Œ≤(1)
Œ≥ = (2 4) Ô¨Åxes 1
= 6
Œ≤ = (1 6).
Similarly, Œ±(i) = Œ≤Œ≥ Œ¥(i) for every i, proving the claim.
We multiply permutations from right to left, because multiplication here is composite
of functions; that is, to evaluate Œ±Œ≤(1), we compute Œ±(Œ≤(1)). Here is another example: Let
us compute the product
œÉ = (1 2)(1 3 4 2 5)(2 5 1 3)
in S5. To Ô¨Ånd the two-rowed notation for œÉ, evaluate, starting with the cycle on the right:
œÉ : 1 ‚Üí3 ‚Üí4 ‚Üí4;
œÉ : 2 ‚Üí5 ‚Üí1 ‚Üí2;
œÉ : 3 ‚Üí2 ‚Üí5 ‚Üí5;
œÉ : 4 ‚Üí4 ‚Üí2 ‚Üí1;
œÉ : 5 ‚Üí1 ‚Üí3 ‚Üí3.
Thus,1
œÉ =
1
2
3
4
5
4
2
5
1
3
	
.
The algorithm given earlier, when applied to this two-rowed notation for œÉ, now gives
œÉ = (1 4)(2)(5 3).
In the factorization of a permutation into cycles, given by the preceding algorithm, we
note that the family of cycles is disjoint in the following sense.
1There are authors who multiply permutations differently, so that their Œ±‚ó¶Œ≤ is our Œ≤ ‚ó¶Œ±. This is a consequence
of their putting "functions on the right": Instead of writing Œ±(i) as we do, they write (i)Œ±. Consider the composite
of permutations Œ± and Œ≤ in which we Ô¨Årst apply Œ≤ and then apply Œ±. We write i ‚ÜíŒ≤(i) ‚ÜíŒ±(Œ≤(i)). In the right-
sided notation, i ‚Üí(i)Œ≤ ‚Üí((i)Œ≤)Œ±. Thus, the notational switch causes a switch in the order of multiplication.

Sec. 2.2
Permutations
43
DeÔ¨Ånition.
Two permutations Œ±, Œ≤ ‚ààSn are disjoint if every i moved by one is Ô¨Åxed by
the other: If Œ±(i) Ã∏= i, then Œ≤(i) = i, and if Œ≤( j) Ã∏= j, then Œ±( j) = j. A family Œ≤1 . . . , Œ≤t
of permutations is disjoint if each pair of them is disjoint.
Lemma 2.1.
Disjoint permutations Œ±, Œ≤ ‚ààSn commute.
Proof.
It sufÔ¨Åces to prove that if 1 ‚â§i ‚â§n, then Œ±Œ≤(i) = Œ≤Œ±(i). If Œ≤ moves i, say,
Œ≤(i) = j Ã∏= i, then Œ≤ also moves j [otherwise, Œ≤( j) = j and Œ≤(i) = j contradicts
Œ≤'s being an injection]; since Œ± and Œ≤ are disjoint, Œ±(i) = i and Œ±( j) = j. Hence
Œ≤Œ±(i) = j = Œ±Œ≤(i). The same conclusion holds if Œ± moves i. Finally, it is clear that
Œ±Œ≤(i) = Œ≤Œ±(i) if both Œ± and Œ≤ Ô¨Åx i.
‚Ä¢
Proposition 2.2.
Every permutation Œ± ‚ààSn is either a cycle or a product of disjoint
cycles.
Proof.
The proof is by induction on the number k of points moved by Œ±. The base step
k = 0 is true, for now Œ± is the identity, which is a 1-cycle.
If k > 0, let i1 be a point moved by Œ±. DeÔ¨Åne i2 = Œ±(i1), i3 = Œ±(i2), . . . , ir+1 = Œ±(ir),
where r is the smallest integer for which ir+1 ‚àà{i1, i2, . . . , ir} (since there are only n
possible values, the list i1, i2, i3, . . . , ik, . . . must eventually have a repetition). We claim
that Œ±(ir) = i1. Otherwise, Œ±(ir) = i j for some j ‚â•2; but Œ±(i j‚àí1) = i j, and this
contradicts the hypothesis that Œ± is an injection. Let œÉ be the r-cycle (i1 i2 i3 . . . ir).
If r = n, then Œ± = œÉ. If r < n, then œÉ Ô¨Åxes each point in Y, where Y consists of the
remaining n‚àír points, while Œ±(Y) = Y. DeÔ¨Åne Œ±‚Ä≤ to be the permutation with Œ±‚Ä≤(i) = Œ±(i)
for i ‚ààY that Ô¨Åxes all i /‚ààY, and note that
Œ± = œÉŒ±‚Ä≤.
The inductive hypothesis gives Œ±‚Ä≤ = Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤t, where Œ≤1, . . . , Œ≤t are disjoint cycles. Since
œÉ and Œ±‚Ä≤ are disjoint, Œ± = œÉŒ≤1 ¬∑ ¬∑ ¬∑ Œ≤t is a product of disjoint cycles.
‚Ä¢
Usually we suppress the 1-cycles in this factorization [for 1-cycles equal the identity
(1)]. However, a factorization of Œ± in which we display one 1-cycle for each i Ô¨Åxed by Œ±,
if any, will arise several times.
DeÔ¨Ånition.
A complete factorization of a permutation Œ± is a factorization of Œ± into dis-
joint cycles that contains exactly one 1-cycle (i) for every i Ô¨Åxed by Œ±.
For example, the complete factorization of the 3-cycle Œ± = (1 3 5) in S5 is Œ± =
(1 3 5)(2)(4).
There is a relation between an r-cycle Œ≤ = (i1 i2 . . . ir) and its powers Œ≤k, where
Œ≤k denotes the composite of Œ≤ with itself k times. Note that i2 = Œ≤(i1), i3 = Œ≤(i2) =
Œ≤(Œ≤(i1)) = Œ≤2(i1), i4 = Œ≤(i3) = Œ≤(Œ≤2(i1)) = Œ≤3(i1), and, more generally,
ik+1 = Œ≤k(i1)
for all k < r.

44
Groups I
Ch. 2
Theorem 2.3.
Let Œ± ‚ààSn and let Œ± = Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤t be a complete factorization into disjoint
cycles. This factorization is unique except for the order in which the cycles occur .
Sketch of Proof.
Since every complete factorization of Œ± has exactly one 1-cycle for each
i Ô¨Åxed by Œ±, it sufÔ¨Åces to consider (not complete) factorizations into disjoint cycles of
length ‚â•2. Let Œ± = Œ≥1 ¬∑ ¬∑ ¬∑ Œ≥s be a second such factorization of Œ± into disjoint cycles.
The theorem is proved by induction on ‚Ñì, the larger of t and s. The inductive step begins
by noting that if Œ≤t moves i1, then Œ≤k
t (i1) = Œ±k(i1) for all k ‚â•1. Some Œ≥ j must also move
i1 and, since disjoint cycles commute, we may assume that Œ≥s moves i1. It follows that
Œ≤t = Œ≥s; right multiplying by Œ≤‚àí1
t
gives Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤t‚àí1 = Œ≥1 ¬∑ ¬∑ ¬∑ Œ≥s‚àí1.
‚Ä¢
Every permutation is a bijection; how do we Ô¨Ånd its inverse? In the pictorial representa-
tion of a cycle Œ≤ as a clockwise rotation of a circle, the inverse Œ≤‚àí1 is just a counterclock-
wise rotation. The proof of the next proposition is straightforward.
Proposition 2.4.
(i) The inverse of the cycle Œ± = (i1 i2 . . . ir) is the cycle (ir ir‚àí1 . . . i1):
(i1 i2 . . . ir)‚àí1 = (ir ir‚àí1 . . . i1).
(ii) If Œ≥ ‚ààSn and Œ≥ = Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤k, then
Œ≥ ‚àí1 = Œ≤‚àí1
k
¬∑ ¬∑ ¬∑ Œ≤‚àí1
1 .
DeÔ¨Ånition.
Two permutations Œ±, Œ≤ ‚ààSn have the same cycle structure if their complete
factorizations have the same number of r-cycles for each r.
According to Exercise 2.4 on page 50, there are
(1/r)[n(n ‚àí1) ¬∑ ¬∑ ¬∑ (n ‚àír + 1)]
r-cycles in Sn. This formula can be used to count the number of permutations having any
given cycle structure if we are careful about factorizations having several cycles of the
same length. For example, the number of permutations in S4 of the form (a b)(c d) is
1
2
 1
2(4 √ó 3)

√ó
 1
2(2 √ó 1)

= 3, the "extra" factor 1
2 occurring so that we do not count
(a b)(c d) = (c d)(a b) twice.
Example 2.5.
(i) The types of permutations in G = S4 are counted in Table 2.1.
Cycle Structure
Number
(1)
1
(1 2)
6
(1 2 3)
8
(1 2 3 4)
6
(1 2)(3 4)
3
24
Table 2.1.
Permutations in S4

Sec. 2.2
Permutations
45
(ii) The types of permutations in G = S5 are counted in Table 2.2.
Cycle Structure
Number
(1)
1
(1 2)
10
(1 2 3)
20
(1 2 3 4)
30
(1 2 3 4 5)
24
(1 2)(3 4 5)
20
(1 2)(3 4)
15
120
Table 2.2.
Permutations in S5
‚óÄ
Here is a computational aid. We illustrate its statement in the following example before
stating the general result.
Example 2.6.
If Œ≥ = (1 3)(2 4 7)(5)(6) and Œ± = (2 5 6)(1 4 3), then
Œ±Œ≥ Œ±‚àí1 = (4 1)(5 3 7)(6)(2) = (Œ±1 Œ±3)(Œ±2 Œ±4 Œ±7)(Œ±5)(Œ±6).
‚óÄ
Lemma 2.7.
If Œ≥, Œ± ‚ààSn, then Œ±Œ≥ Œ±‚àí1 has the same cycle structure as Œ≥ . In more detail,
if the complete factorization of Œ≥ is
Œ≥ = Œ≤1Œ≤2 ¬∑ ¬∑ ¬∑ (i1 i2 . . . ) ¬∑ ¬∑ ¬∑ Œ≤t,
then Œ±Œ≥ Œ±‚àí1 is the permutation that is obtained from Œ≥ by applying Œ± to the symbols in the
cycles of Œ≥ .
Proof.
The idea of the proof is that Œ≥ Œ±Œ≥ ‚àí1 : Œ≥ (i1) ‚Üíi1 ‚Üíi2 ‚ÜíŒ≥ (i2). Let œÉ denote
the permutation deÔ¨Åned in the statement.
If Œ≥ Ô¨Åxes i, then œÉ Ô¨Åxes Œ±(i), for the deÔ¨Ånition of œÉ says that Œ±(i) lives in a 1-cycle in
the factorization of œÉ. On the other hand, Œ±Œ≥ Œ±‚àí1 also Ô¨Åxes Œ±(i):
Œ±Œ≥ Œ±‚àí1(Œ±(i)) = Œ±Œ≥ (i) = Œ±(i),
because Œ≥ Ô¨Åxes i.
Assume that Œ≥ moves a symbol i1, say, Œ≥ (i1) = i2, so that one of the cycles in the
complete factorization of Œ≥ is
(i1 i2 . . . ).
By the deÔ¨Ånition of œÉ, one of its cycles is
(k ‚Ñì. . . ),
where Œ±(i1) = k and Œ±(i2) = ‚Ñì; hence, œÉ : k ‚Üí‚Ñì. But Œ±Œ≥ Œ±‚àí1 : k ‚Üíi1 ‚Üíi2 ‚Üí‚Ñì,
and so Œ±Œ≥ Œ±‚àí1(k) = œÉ(k). Therefore, œÉ and Œ±Œ≥ Œ±‚àí1 agree on all symbols of the form
k = Œ±(i1). Since Œ± is surjective, every k is of this form, and so œÉ = Œ±Œ≥ Œ±‚àí1.
‚Ä¢

46
Groups I
Ch. 2
Example 2.8.
In this example, we illustrate that the converse of Lemma 2.7 is true; the next theorem will
prove it in general. In S5, place the complete factorization of a 3-cycle Œ≤ over that of a
3-cycle Œ≥ , and deÔ¨Åne Œ± to be the downward function. For example, if
Œ≤ = (1 2 3)(4)(5)
Œ≥ = (5 2 4)(1)(3),
then
Œ± =
1
2
3
4
5
5
2
4
1
3
	
,
and so Œ± = (1 5 3 4). Now Œ± ‚ààS5 and
Œ≥ = (Œ±1 Œ±2 Œ±3),
so that Œ≥ = Œ±Œ≤Œ±‚àí1, by Lemma 2.7. Note that rewriting the cycles of Œ≤, for example, as
Œ≤ = (1 2 3)(5)(4), gives another choice for Œ±.
‚óÄ
Theorem 2.9.
Permutations Œ≥ and œÉ in Sn have the same cycle structure if and only if
there exists Œ± ‚ààSn with œÉ = Œ±Œ≥ Œ±‚àí1.
Sketch of Proof.
SufÔ¨Åciency was just proved in Lemma 2.7. For the converse, place one
complete factorization over the other so that each cycle below is under a cycle above of the
same length:
Œ≥ = Œ¥1Œ¥2 ¬∑ ¬∑ ¬∑ (i1 i2 ¬∑ ¬∑ ¬∑ ) ¬∑ ¬∑ ¬∑ Œ¥t
Œ±Œ≥ Œ±‚àí1 = Œ∑1Œ∑2 ¬∑ ¬∑ ¬∑ (k ‚Ñì¬∑ ¬∑ ¬∑ ) ¬∑ ¬∑ ¬∑ Œ∑t.
Now deÔ¨Åne Œ± to be the "downward" function, as in the example; hence, Œ±(i1) = k, Œ±(i2) =
‚Ñì, and so forth. Note that Œ± is a permutation, for there are no repetitions of symbols in
the factorization of Œ≥ (the cycles Œ∑ are disjoint). It now follows from the lemma that
œÉ = Œ±Œ≥ Œ±‚àí1.
‚Ä¢
There is another useful factorization of a permutation.
Proposition 2.10.
If n ‚â•2, then every Œ± ‚ààSn is a product of transpositions.
Sketch of Proof.
In light of Proposition 2.2, it sufÔ¨Åces to factor an r-cycle Œ≤ into a product
of transpositions, and this is done as follows:
Œ≤ = (1 2 . . . r) = (1 r)(1 r ‚àí1) ¬∑ ¬∑ ¬∑ (1 3)(1 2).
‚Ä¢

Sec. 2.2
Permutations
47
Every permutation can thus be realized as a sequence of interchanges, but such a fac-
torization is not as nice as the factorization into disjoint cycles. First, the transpositions
occurring need not commute: (1 2 3) = (1 3)(1 2) Ã∏= (1 2)(1 3); second, neither the
factors themselves nor the number of factors are uniquely determined. For example, here
are some factorizations of (1 2 3) in S4:
(1 2 3) = (1 3)(1 2)
= (2 3)(1 3)
= (1 3)(4 2)(1 2)(1 4)
= (1 3)(4 2)(1 2)(1 4)(2 3)(2 3).
Is there any uniqueness at all in such a factorization? We now prove that the parity of
the number of factors is the same for all factorizations of a permutation Œ±; that is, the
number of transpositions is always even or always odd (as suggested by the factorizations
of Œ± = (1 2 3) displayed above).
Example 2.11.
The 15-puzzle has a starting position that is a 4 √ó 4 array of the numbers between 1 and
15 and a symbol #, which we interpret as "blank." For example, consider the following
starting position:
3
15
4
8
10
11
1
9
2
5
13
12
6
7
14
#
A simple move interchanges the blank with a symbol adjacent to it; for example, there
are two beginning simple moves for this starting position: Either interchange # and 14 or
interchange # and 12. We win the game if, after a sequence of simple moves, the starting
position is transformed into the standard array 1, 2, 3, . . ., 15, #.
To analyze this game, note that the given array is really a permutation Œ± ‚ààS16 (if we
now call the blank 16 instead of #). More precisely, if the spaces are labeled 1 through 16,
then Œ±(i) is the symbol occupying the ith square. For example, the given starting position
is
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
3
15
4
8
10
11
1
9
2
5
13
12
6
7
14
16
	
.
Each simple move is a special kind of transposition, namely, one that moves 16 (remember
that the blank is now 16). Moreover, performing a simple move (corresponding to a special
transposition œÑ) from a given position (corresponding to a permutation Œ≤) yields a new
position corresponding to the permutation œÑŒ≤. For example, if Œ± is the position above and
œÑ is the transposition interchanging 14 and 16, then œÑŒ±(16) = œÑ(16) = 14 and œÑŒ±(15) =
œÑ(14) = 16, while œÑŒ±(i) = i for all other i. That is, the new conÔ¨Åguration has all the
numbers in their original positions except for 14 and 16 being interchanged. To win the

48
Groups I
Ch. 2
game, we need special transpositions œÑ1, œÑ2, . . . , œÑm so that
œÑm ¬∑ ¬∑ ¬∑ œÑ2œÑ1Œ± = (1).
It turns out that there are some choices of Œ± for which the game can be won, but there are
others for which it cannot be won, as we shall see in Example 2.15.
‚óÄ
DeÔ¨Ånition.
A permutation Œ± ‚ààSn is even if it can be factored into a product of an even
number of transpositions; otherwise, Œ± is odd. The parity of a permutation is whether it is
even or odd.
It is easy to see that (1 2 3) and (1) are even permutations, for there are factorization
(1 2 3) = (1 3)(1 2) and (1) = (1 2)(1 2) having two transpositions. On the other
hand, we do not yet have any examples of odd permutations! If Œ± is a product of an
odd number of transpositions, perhaps it also has some other factorization into an even
number of transpositions. The deÔ¨Ånition of odd permutation Œ±, after all, says that there is
no factorization of Œ± into an even number of transpositions.
DeÔ¨Ånition.
If Œ± ‚ààSn and Œ± = Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤t is a complete factorization into disjoint cycles,
then signum Œ± is deÔ¨Åned by
sgn(Œ±) = (‚àí1)n‚àít.
Theorem 2.3 shows that sgn is a (well-deÔ¨Åned) function, for the number t is uniquely
determined by Œ±. Notice that sgn(Œµ) = 1 for every 1-cycle Œµ because t = n. If œÑ is a
transposition, then it moves two numbers, and it Ô¨Åxes each of the n ‚àí2 other numbers;
therefore, t = (n ‚àí2) + 1 = n ‚àí1, and so sgn(œÑ) = (‚àí1)n‚àí(n‚àí1) = ‚àí1.
Theorem 2.12.
For all Œ±, Œ≤ ‚ààSn,
sgn(Œ±Œ≤) = sgn(Œ±) sgn(Œ≤).
Sketch of Proof.
If k, ‚Ñì‚â•0 and the letters a, b, ci, d j are all distinct, then
(a b)(a c1 . . . ck b d1 . . . d‚Ñì) = (a c1 . . . ck)(b d1 . . . d‚Ñì);
multiplying this equation on the left by (a b) gives
(a b)(a c1 . . . ck)(b d1 . . . d‚Ñì) = (a c1 . . . ck b d1 . . . d‚Ñì).
These equations are used to prove that sgn(œÑŒ±) = ‚àísgn(Œ±) for every Œ± ‚ààSn, where œÑ
is the transposition (a b). If Œ± ‚ààSn has a factorization Œ± = œÑ1 ¬∑ ¬∑ ¬∑ œÑm, where each œÑi is a
transposition, we now prove, by induction on m, that sgn(Œ±Œ≤) = sgn(Œ±) sgn(Œ≤) for every
Œ≤ ‚ààSn.
‚Ä¢

Sec. 2.2
Permutations
49
Theorem 2.13.
(i) Let Œ± ‚ààSn; if sgn(Œ±) = 1, then Œ± is even, and if sgn(Œ±) = ‚àí1, then Œ± is odd.
(ii) A permutation Œ± is odd if and only if it is a product of an odd number of transposi-
tions.
Proof.
(i) If Œ± = œÑ1 ¬∑ ¬∑ ¬∑ œÑq is a factorization of Œ± into transpositions, then Theorem 2.12
gives sgn(Œ±) = sgn(œÑ1) ¬∑ ¬∑ ¬∑ sgn(œÑq) = (‚àí1)q. Thus, if sgn(Œ±) = 1, then q must always be
even, and if sgn(Œ±) = ‚àí1, then q must always be odd.
(ii) If Œ± is odd, then Œ± is not even, and so sgn(Œ±) Ã∏= 1; that is, sgn(Œ±) = ‚àí1. Now
Œ± = œÑ1 ¬∑ ¬∑ ¬∑ œÑq, where the œÑi are transpositions, so that sgn(Œ±) = ‚àí1 = (‚àí1)q; hence, q is
odd (we have proved more; every factorization of Œ± into transpositions has an odd number
of factors). Conversely, if Œ± = œÑ1 ¬∑ ¬∑ ¬∑ œÑq is a product of transpositions with q odd, then
sgn(Œ±) = ‚àí1; therefore, Œ± is not even and, hence, Œ± is odd.
‚Ä¢
Corollary 2.14.
Let Œ±, Œ≤ ‚ààSn. If Œ± and Œ≤ have the same parity, then Œ±Œ≤ is even, while if
Œ± and Œ≤ have distinct parity, then Œ±Œ≤ is odd.
Example 2.15.
An analysis of the 15-puzzle in Example 2.11 shows that if Œ± ‚ààS16 is the starting position,
then the game can be won if and only if Œ± is an even permutation that Ô¨Åxes 16. For a proof
of this, we refer the reader to McCoy-Janusz, Introduction to Modern Algebra, pages 229-
234. The proof in one direction is fairly clear, however. The blank 16 starts in position 16.
Each simple move takes 16 up, down, left, or right. Thus, the total number m of moves
is u + d + l + r, where u is the number of up moves, and so on. If 16 is to return home,
each one of these must be undone: There must be the same number of up moves as down
moves (i.e., u = d) and the same number of left moves as right moves (i.e., r = l). Thus,
the total number of moves is even: m = 2u + 2r. That is, if œÑm ¬∑ ¬∑ ¬∑ œÑ1Œ± = (1), then m is
even; hence, Œ± = œÑ1 ¬∑ ¬∑ ¬∑ œÑm (because œÑ ‚àí1 = œÑ for every transposition œÑ), and so Œ± is an
even permutation. Armed with this theorem, we see that if the starting position Œ± is odd,
the game starting with Œ± cannot be won. In Example 2.11,
Œ± = (1 3 4 8 9 2 15 14 7)(5 10)(6 11 13)(12)(16)
[(12) and (16) are 1-cycles]. Now sgn(Œ±) = (‚àí1)16‚àí5 = ‚àí1, so that Œ± is an odd permuta-
tion. Therefore, it is impossible to win this game.
‚óÄ
EXERCISES
2.1 Find sgn(Œ±) and Œ±‚àí1, where
Œ± =
1
2
3
4
5
6
7
8
9
9
8
7
6
5
4
3
2
1
	
.

50
Groups I
Ch. 2
2.2 If Œ± ‚ààSn, prove that sgn(Œ±‚àí1) = sgn(Œ±).
2.3 If œÉ ‚ààSn Ô¨Åxes some j, where 1 ‚â§j ‚â§n [that is, œÉ( j) = j], deÔ¨Åne œÉ ‚Ä≤ ‚ààSn‚àí1 by
œÉ ‚Ä≤(i) = œÉ(i) for all i Ã∏= j. Prove that
sgn(œÉ ‚Ä≤) = sgn(œÉ).
Hint. Use the complete factorizations of œÉ and of œÉ ‚Ä≤.
2.4 If 1 ‚â§r ‚â§n, show that there are
1
r [n(n ‚àí1) ¬∑ ¬∑ ¬∑ (n ‚àír + 1)]
r-cycles in Sn.
Hint. There are r cycle notations for any r-cycle.
2.5
(i) If Œ± is an r-cycle, show that Œ±r = (1).
Hint. If Œ± = (i0 . . . ir‚àí1), show that Œ±k(i0) = ik.
(ii) If Œ± is an r-cycle, show that r is the smallest positive integer k such that Œ±k = (1).
Hint. Use Proposition 2.2.
2.6 Show that an r-cycle is an even permutation if and only if r is odd.
2.7 Given X = {1, 2, . . . , n}, let us call a permutation œÑ of X an adjacency if it is a transposition
of the form (i i + 1) for i < n.
(i) Prove that every permutation in Sn, for n ‚â•2, is a product of adjacencies.
(ii) If i < j, prove that (i j) is a product of an odd number of adjacencies.
Hint. Use induction on j ‚àíi.
2.8 DeÔ¨Åne f : {0, 1, 2, . . . , 10} ‚Üí{0, 1, 2, . . . , 10} by
f (n) = the remainder after dividing 4n2 ‚àí3n7 by 11.
(i) Show that f is a permutation.2
(ii) Compute the parity of f .
(iii) Compute the inverse of f .
2.9 If Œ± is an r-cycle and 1 < k < r, is Œ±k an r-cycle?
2.10
(i) Prove that if Œ± and Œ≤ are (not necessarily disjoint) permutations that commute, then
(Œ±Œ≤)k = Œ±kŒ≤k for all k ‚â•1.
Hint. First show that Œ≤Œ±k = Œ±kŒ≤ by induction on k.
(ii) Give an example of two permutations Œ± and Œ≤ for which (Œ±Œ≤)2 Ã∏= Œ±2Œ≤2.
2.11
(i) Prove, for all i, that Œ± ‚ààSn moves i if and only if Œ±‚àí1 moves i.
(ii) Prove that if Œ±, Œ≤ ‚ààSn are disjoint and if Œ±Œ≤ = (1), then Œ± = (1) and Œ≤ = (1).
2.12 Prove that the number of even permutations in Sn is 1
2n!.
Hint. Let œÑ = (1 2), and deÔ¨Åne f : An ‚ÜíOn, where An is the set of all even permutations
in Sn and On is the set of all odd permutations, by
f : Œ± ‚ÜíœÑŒ±.
Show that f is a bijection, so that |An| = |On| and, hence, |An| = 1
2n!.
2If k is a Ô¨Ånite Ô¨Åeld, then a polynomial f (x) with coefÔ¨Åcients in k is called a permutation polynomial if
the evaluation function f : k ‚Üík, deÔ¨Åned by a ‚Üíf (a), is a permutation of k. A theorem of Hermite and
Dickson characterizes permutation polynomials (see Lidl-Niederreiter, Introduction to Finite Fields and Their
Applications).

Sec. 2.3
Groups
51
2.13
(i) How many permutations in S5 commute with Œ± = (1 2 3), and how many even permu-
tations in S5 commute with Œ±?
Hint. There are 6 permutations in S5 commuting with Œ±, only 3 of which are even.
(ii) Same questions for (1 2)(3 4).
Hint. There are 8 permutations in S4 commuting with (1 2)(3 4), and only 4 of them
are even.
2.14 Give an example of Œ±, Œ≤, Œ≥ ‚ààS5, with Œ± Ã∏= (1), such that Œ±Œ≤ = Œ≤Œ±, Œ±Œ≥ = Œ≥ Œ± and Œ≤Œ≥ Ã∏= Œ≥Œ≤.
2.15 If n ‚â•3, show that if Œ± ‚ààSn commutes with every Œ≤ ‚ààSn, then Œ± = (1).
2.16 If Œ± = Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤m is a product of disjoint cycles, prove that Œ≥ = Œ≤e1
1 ¬∑ ¬∑ ¬∑ Œ≤em
m Œ¥ commutes with
Œ±, where ei ‚â•0 for all i, and Œ¥ is disjoint from Œ±.
2.3 GROUPS
Since Galois's time, groups have arisen in many areas of mathematics other than the study
of roots of polynomials, for they are the way to describe the notion of symmetry, as we
shall see.
The essence of a "product" is that two things are combined to form a third thing of the
same kind. For example, ordinary multiplication, addition, and subtraction combine two
numbers to give another number, while composition combines two permutations to give
another permutation.
DeÔ¨Ånition.
A binary operation on a set G is a function
‚àó: G √ó G ‚ÜíG.
In more detail, a binary operation assigns an element ‚àó(x, y) in G to each ordered
pair (x, y) of elements in G. It is more natural to write x ‚àóy instead of ‚àó(x, y); thus,
composition of functions is the function (g, f ) ‚Üíg ‚ó¶f ; multiplication, addition, and
subtraction are, respectively, the functions (x, y) ‚Üíxy, (x, y) ‚Üíx + y, and (x, y) ‚Üí
x ‚àíy. The examples of composition and subtraction show why we want ordered pairs, for
x ‚àóy and y ‚àóx may be distinct. As with any function, a binary operation is well-deÔ¨Åned;
when one says this explicitly, it is usually called the law of substitution:
If x = x‚Ä≤ and y = y‚Ä≤, then x ‚àóy = x‚Ä≤ ‚àóy‚Ä≤.
DeÔ¨Ånition.
A group is a set G equipped with a binary operation ‚àósuch that
(i) the associative law holds: for every x, y, z ‚ààG,
x ‚àó(y ‚àóz) = (x ‚àóy) ‚àóz;
(ii) there is an element e ‚ààG, called the identity, with e ‚àóx = x = x ‚àóe for all x ‚ààG;
(iii) every x ‚ààG has an inverse; there is x‚Ä≤ ‚ààG with x ‚àóx‚Ä≤ = e = x‚Ä≤ ‚àóx.

52
Groups I
Ch. 2
By Theorem 1.49, the set SX of all permutations of a set X, with composition as the
operation and 1X = (1) as the identity, is a group (the symmetric group on X). In Ex-
ercise 2.22 on page 61, the reader will see that some of the equations in the deÔ¨Ånition of
group are redundant. This is a useful observation, for it is more efÔ¨Åcient, when verifying
that a set with an operation is actually a group, to check fewer equations.
We are now at the precise point when algebra becomes abstract algebra. In contrast to
the concrete group Sn consisting of all the permutations of {1, 2, . . . , n}, we have passed
to groups whose elements are unspeciÔ¨Åed. Moreover, products of elements are not ex-
plicitly computable but are, instead, merely subject to certain rules. It will be seen that
this approach is quite fruitful, for theorems now apply to many different groups, and it is
more efÔ¨Åcient to prove theorems once for all instead of proving them anew for each group
encountered. In addition to this obvious economy, it is often simpler to work with the
"abstract" viewpoint even when dealing with a particular concrete group. For example,
we will see that certain properties of Sn are simpler to treat without recognizing that the
elements in question are permutations (see Example 2.26).
DeÔ¨Ånition.
A group G is called abelian3 if it satisÔ¨Åes the commutative law:
x ‚àóy = y ‚àóx
holds for every x, y ‚ààG.
The groups Sn, for n ‚â•3, are not abelian because (1 2) and (1 3) are elements of Sn
that do not commute: (1 2)(1 3) = (1 3 2) and (1 3)(1 2) = (1 2 3).
Lemma 2.16.
Let G be a group.
(i) The cancellation laws hold: If either x ‚àóa = x ‚àób or a ‚àóx = b ‚àóx, then a = b.
(ii) The element e is the unique element in G with e ‚àóx = x = x ‚àóe for all x ‚ààG.
(iii) Each x ‚ààG has a unique inverse: There is only one element x‚Ä≤ ‚ààG with x ‚àóx‚Ä≤ =
e = x‚Ä≤ ‚àóx (henceforth, this element will be denoted by x‚àí1).
(iv) (x‚àí1)‚àí1 = x for all x ‚ààG.
Proof.
(i) Choose x‚Ä≤ with x‚Ä≤ ‚àóx = e = x ‚àóx‚Ä≤; then
a = e ‚àóa = (x‚Ä≤ ‚àóx) ‚àóa = x‚Ä≤ ‚àó(x ‚àóa)
= x‚Ä≤ ‚àó(x ‚àób) = (x‚Ä≤ ‚àóx) ‚àób = e ‚àób = b.
A similar proof works when x is on the right.
(ii) Let e0 ‚ààG satisfy e0 ‚àóx = x = x ‚àóe0 for all x ‚ààG. In particular, setting x = e in
the second equation gives e = e ‚àóe0; on the other hand, the deÔ¨Åning property of e gives
e ‚àóe0 = e0, so that e = e0.
3The reason why commutative groups are called abelian can be found on page 236.

Sec. 2.3
Groups
53
(iii) Assume that x‚Ä≤‚Ä≤ ‚ààG satisÔ¨Åes x ‚àóx‚Ä≤‚Ä≤ = e = x‚Ä≤‚Ä≤ ‚àóx. Multiply the equation e = x ‚àóx‚Ä≤
on the left by x‚Ä≤‚Ä≤ to obtain
x‚Ä≤‚Ä≤ = x‚Ä≤‚Ä≤ ‚àóe = x‚Ä≤‚Ä≤ ‚àó(x ‚àóx‚Ä≤) = (x‚Ä≤‚Ä≤ ‚àóx) ‚àóx‚Ä≤ = e ‚àóx‚Ä≤ = x‚Ä≤.
(iv) By deÔ¨Ånition, (x‚àí1)‚àí1 ‚àóx‚àí1 = e = x‚àí1 ‚àó(x‚àí1)‚àí1. But x ‚àóx‚àí1 = e = x‚àí1 ‚àóx, so
that (x‚àí1)‚àí1 = x, by (iii).
‚Ä¢
From now on, we will usually denote the product x ‚àóy in a group by xy (we have
already abbreviated Œ± ‚ó¶Œ≤ to Œ±Œ≤ in symmetric groups), and we will denote the identity by 1
instead of by e. When a group is abelian, however, we will often use the additive notation
x + y; in this case, we will denote the identity by 0, and we will denote the inverse of an
element x by ‚àíx instead of by x‚àí1.
Example 2.17.
(i) The set Q√ó of all nonzero rationals is an abelian group, where ‚àóis ordinary multiplica-
tion, the number 1 is the identity, and the inverse of r ‚ààQ√ó is 1/r. Similarly, R√ó and C√ó
are multiplicative abelian groups.
Note that the set Z√ó of all nonzero integers is not a multiplicative group, for none of its
elements (aside from ¬±1) has a multiplicative inverse which is an integer.
(ii) The set Z of all integers is an additive abelian group with a ‚àób = a + b, with identity
e = 0, and with the inverse of an integer n being ‚àín. Similarly, we can see that Q, R, and
C are additive abelian groups.
(iii) The circle group,
S1 = {z ‚ààC : |z| = 1},
is the group whose operation is multiplication of complex numbers; this is an operation
because the product of complex numbers of modulus 1 also has modulus 1, by Corol-
lary 1.31. Complex multiplication is associative, the identity is 1 (which has modulus 1),
and the inverse of any complex number of modulus 1 is its complex conjugate, which also
has modulus 1. Therefore, S1 is a group.
(iv) For any positive integer n, let
¬µn =

Œ∂ k : 0 ‚â§k < n

be the set of all the nth roots of unity, where
Œ∂ = e2œÄi/n = cos
 2œÄ
n

+ i sin
 2œÄ
n

.
The reader may use De Moivre's theorem to see that ¬µn is a group with operation multipli-
cation of complex numbers; moreover, the inverse of any nth root of unity is its complex
conjugate, which is also an nth root of unity.

54
Groups I
Ch. 2
(v) The plane R √ó R is a group with operation vector addition; that is, if Œ± = (x, y) and
Œ±‚Ä≤ = (x‚Ä≤, y‚Ä≤), then Œ± + Œ±‚Ä≤ = (x + x‚Ä≤, y + y‚Ä≤). The identity is the origin O = (0, 0), and
the inverse of (x, y) is (‚àíx, ‚àíy).
‚óÄ
Example 2.18.
Let X be a set. If U and V are subsets of X, deÔ¨Åne
U ‚àíV = {x ‚ààU : x /‚ààV }.
The Boolean group B (X) [named after the logician G. Boole (1815-1864)] is the family
of all the subsets of X equipped with addition given by symmetric difference A+ B, where
A + B = (A ‚àíB) ‚à™(B ‚àíA);
symmetric difference is pictured in Figure 2.2.
A
B
Figure 2.2
A
B
C
Figure 2.3
It is plain that A + B = B + A, so that symmetric difference is commutative. The
identity is ‚àÖ, the empty set, and the inverse of A is A itself, for A + A = ‚àÖ. The reader
may verify associativity by showing that both (A + B)+C and A +(B +C) are described
by Figure 2.3.
‚óÄ
Example 2.19.
An n √ó n matrix A with real entries is called nonsingular if it has an inverse; that is, there
is a matrix B with AB = I = B A, where I = [Œ¥i j] (Œ¥i j is the Kronecker delta) is the
n √ó n identity matrix. Since (AB)‚àí1 = B‚àí1A‚àí1, the product of nonsingular matrices is
itself nonsingular. The set GL(n, R) of all n √ó n nonsingular matrices having real entries,
with binary operation matrix multiplication, is a (nonabelian) group, called the general
linear group. [The proof of associativity is routine, though tedious; a "clean" proof of
associativity can be given (Corollary 3.99) once the relation between matrices and linear
transformations is known.]
‚óÄ

Sec. 2.3
Groups
55
A binary operation allows us to multiply two elements at a time; how do we multiply
three elements? There is a choice. Given the expression 2 √ó 3 √ó 4, for example, we can
Ô¨Årst multiply 2 √ó 3 = 6 and then multiply 6 √ó 4 = 24; or, we can Ô¨Årst multiply 3 √ó 4 = 12
and then multiply 2√ó12 = 24; of course, the answers agree, for multiplication of numbers
is associative. Thus, if an operation is associative, the expression abc is not ambiguous.
Not all operations are associative, however. For example, subtraction is not associative: if
c Ã∏= 0, then
a ‚àí(b ‚àíc) Ã∏= (a ‚àíb) ‚àíc,
and so the notation a ‚àíb ‚àíc is ambiguous. The cross product of two vectors in R3 is
another example of a nonassociative operation.
DeÔ¨Ånition.
If G is a group and if a ‚ààG, deÔ¨Åne the powers4 an, for n ‚â•1, inductively:
a1 = a
and
an+1 = aan.
DeÔ¨Åne a0 = 1 and, if n is a positive integer, deÔ¨Åne
a‚àín = (a‚àí1)n.
The reader expects that (a‚àí1)n = (an)‚àí1; this is a special case of the equation in Exer-
cise 2.17 on page 61, but this is not so obvious to prove at this stage. For example, showing
that a‚àí2a2 = 1 amounts to doing the cancellation in the expression (a‚àí1a‚àí1)(aa); but as-
sociativity is given to us only for products having three, not four, factors.
Let us return to powers. The Ô¨Årst and second powers are Ô¨Åne: a1 = a and a2 = aa.
There are two possible cubes: We have deÔ¨Åned a3 = aa2 = a(aa), but there is another
reasonable contender: (aa)a = a2a. If we assume associativity, then these are equal:
a3 = aa2 = a(aa) = (aa)a = a2a.
There are several possible products of a with itself four times; assuming that the operation
is associative, is it obvious that a4 = a3a = a2a2? And what about higher powers?
DeÔ¨Åne an expression a1a2 ¬∑ ¬∑ ¬∑ an to be an n-tuple in G √ó ¬∑ ¬∑ ¬∑ √ó G (n factors). An
expression yields many elements of G by the following procedure. Choose two adjacent
a's, multiply them, and obtain an expression with n ‚àí1 factors: The new product just
formed and n ‚àí2 original factors. In this shorter new expression, choose two adjacent
factors (either an original pair or an original one together with the new product from the Ô¨Årst
step) and multiply them. Repeat this procedure until there is an expression with only two
4The terminology x square and x cube for x2 and x3 is, of course, geometric in origin. Usage of the word
power in this context arises from a mistranslation of the Greek dunamis (from which dynamo derives) used by
Euclid. Power was the standard European rendition of dunamis; for example, the Ô¨Årst English translation of
Euclid, in 1570, by H. Billingsley, renders a sentence of Euclid as, "The power of a line is the square of the same
line." However, contemporaries of Euclid (e.g., Aristotle and Plato) often used dunamis to mean ampliÔ¨Åcation,
and this seems to be a more appropriate translation, for Euclid was probably thinking of a one-dimensional
line sweeping out a two-dimensional square. (I thank Donna Shalev for informing me of the classical usage of
dunamis.)

56
Groups I
Ch. 2
factors; multiply them and obtain an element of G; call this an ultimate product derived
from the expression. For example, consider the expression abcd. We may Ô¨Årst multiply ab,
obtaining (ab)cd, an expression with three factors, namely, ab, c, d. We may now choose
either the pair c, d or the pair ab, c; in either case, multiply these, obtaining expressions
with two factors: (ab)(cd) having factors ab and cd or ((ab)c)d having factors (ab)c
and d. The two factors in either of these last expressions can now be multiplied to give
an ultimate product from abcd. Other ultimate products derived from the expression abcd
arise by multiplying bc or cd as the Ô¨Årst step. It is not obvious whether the ultimate
products derived from a given expression are all equal.
DeÔ¨Ånition.
An expression a1a2 ¬∑ ¬∑ ¬∑ an needs no parentheses if all the ultimate products
it yields are equal; that is, no matter what choices are made of adjacent factors to multiply,
all the resulting products in G are equal.
Theorem 2.20 (Generalized Associativity).
If G is a group and a1, a2, . . . , an ‚ààG,
then the expression a1a2 ¬∑ ¬∑ ¬∑ an needs no parentheses.
Remark.
This result holds in greater generality, for neither the identity element nor
inverses will be used in the proof.
‚óÄ
Proof.
The proof is by (the second form of) induction. The base step n = 3 follows from
associativity. For the inductive step, consider two ultimate products U and V obtained
from an expression a1a2 ¬∑ ¬∑ ¬∑ an after two series of choices:
(a1 ¬∑ ¬∑ ¬∑ ai)(ai+1 ¬∑ ¬∑ ¬∑ an)
and
(a1 ¬∑ ¬∑ ¬∑ a j)(a j+1 ¬∑ ¬∑ ¬∑ an);
the parentheses indicate the last two factors which multiply to give U and V ; there are
many parentheses inside each of these shorter expressions. We may assume that i ‚â§j.
Since each of the four expressions in parentheses has fewer than n factors, the inductive
hypothesis says that each needs no parentheses. It follows that U = V if i = j. If i < j,
then the inductive hypothesis allows the Ô¨Årst expression to be rewritten
U = (a1 ¬∑ ¬∑ ¬∑ ai)

[ai+1 ¬∑ ¬∑ ¬∑ a j][a j+1 ¬∑ ¬∑ ¬∑ an]

and the second to be rewritten
V =

[a1 ¬∑ ¬∑ ¬∑ ai][ai+1 ¬∑ ¬∑ ¬∑ a j]

(a j+1 ¬∑ ¬∑ ¬∑ an),
where each of the expressions a1 ¬∑ ¬∑ ¬∑ ai, ai+1 ¬∑ ¬∑ ¬∑ a j, and a j+1 ¬∑ ¬∑ ¬∑ an needs no parentheses.
Thus, these expressions yield unique elements A, B, and C of G, respectively. The Ô¨Årst
expression yields A(BC), the second yields (AB)C, and these two expressions give the
same element of G, by associativity.
‚Ä¢

Sec. 2.3
Groups
57
Corollary 2.21.
If G is a group and a, b ‚ààG, then
(ab)‚àí1 = b‚àí1a‚àí1.
Proof.
By Lemma 2.16(iii), it sufÔ¨Åces to prove that (ab)(b‚àí1a‚àí1) = 1 = (b‚àí1a‚àí1)(ab).
Using generalized associativity,
(ab)(b‚àí1a‚àí1) = [a(bb‚àí1)]a‚àí1 = (a1)a‚àí1 = aa‚àí1 = 1.
A similar argument proves the other equation.
‚Ä¢
Corollary 2.22.
If G is a group, if a ‚ààG, and if m, n ‚â•1, then
am+n = aman
and
(am)n = amn.
Proof.
In the Ô¨Årst instance, both elements arise from the expression having m + n factors
each equal to a; in the second instance, both elements arise from the expression having mn
factors each equal to a.
‚Ä¢
It follows that any two powers of an element a in a group commute:
aman = am+n = an+m = anam.
Proposition 2.23 (Laws of Exponents).
Let G be a group, let a, b ‚ààG, and let m and
n be (not necessarily positive) integers.
(i) If a and b commute, then (ab)n = anbn.
(ii) (an)m = amn.
(iii) aman = am+n.
Sketch of Proof.
The proofs, while routine, are lengthy double inductions.
‚Ä¢
The notation an is the natural way to denote a ‚àóa ‚àó¬∑ ¬∑ ¬∑ ‚àóa, where a appears n times.
However, if the operation is +, then it is more natural to denote a + a + ¬∑ ¬∑ ¬∑ + a by na.
Let G be a group written additively; if a, b ‚ààG and m and n are (not necessarily positive)
integers, then Proposition 2.23 is usually rewritten:
(i) n(a + b) = na + nb
(ii) m(na) = (mn)a
(iii) ma + na = (m + n)a

58
Groups I
Ch. 2
DeÔ¨Ånition.
Let G be a group and let a ‚ààG. If ak = 1 for some k ‚â•1, then the smallest
such exponent k ‚â•1 is called the order of a; if no such power exists, then one says that a
has inÔ¨Ånite order.
The additive group of integers, Z, is a group, and 3 is an element in it having inÔ¨Ånite
order (because 3 + 3 + ¬∑ ¬∑ ¬∑ + 3 is never 0).
In any group G, the identity has order 1, and it is the only element of order 1; an element
has order 2 if and only if it is equal to its own inverse.
The deÔ¨Ånition of order says that if x has order n and xm = 1 for some positive integer
m, then n ‚â§m. The next theorem says that n must be a divisor of m.
Theorem 2.24.
If a ‚ààG is an element of order n, then am = 1 if and only if n | m.
Proof.
Assume that am = 1. The division algorithm provides integers q and r with
m = nq + r, where 0 ‚â§r < n. It follows that ar = am‚àínq = ama‚àínq = 1. If r > 0, then
we contradict n being the smallest positive integer with an = 1. Hence, r = 0 and n | m.
Conversely, if m = nk, then am = ank = (an)k = 1k = 1.
‚Ä¢
What is the order of a permutation in Sn?
Proposition 2.25.
Let Œ± ‚ààSn.
(i) If Œ± is an r-cycle, then Œ± has order r.
(ii) If Œ± = Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤t is a product of disjoint ri-cycles Œ≤i, then Œ± has order lcm{r1, . . . ,rt}.
(iii) If p is a prime, then Œ± has order p if and only if it is a p-cycle or a product of disjoint
p-cycles.
Proof.
(i) This is Exercise 2.5 on page 50.
(ii) Each Œ≤i has order ri, by (i). Suppose that Œ±M = (1). Since the Œ≤i commute, (1) =
Œ±M = (Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤t)M = Œ≤ M
1 ¬∑ ¬∑ ¬∑ Œ≤ M
t . By Exercise 2.11 on page 50, disjointness of the Œ≤'s
implies that Œ≤ M
i
= (1) for each i, so that Theorem 2.24 gives ri | M for all i; that is, M
is a common multiple of r1, . . . ,rt. On the other hand, if m = lcm{r1, . . . ,rt}, then it is
easy to see that Œ±m = (1). Therefore, Œ± has order m.
(iii) Write Œ± as a product of disjoint cycles and use (ii).
‚Ä¢
For example, a permutation in Sn has order 2 if and only if it is a transposition or a
product of disjoint transpositions.
Example 2.26.
Suppose a deck of cards is shufÔ¨Çed, so that the order of the cards has changed from
1, 2, 3, 4, . . . , 52 to 2, 1, 4, 3, . . . , 52, 51. If we shufÔ¨Çe again in the same way, then the
cards return to their original order. But a similar thing happens for any permutation Œ± of
the 52 cards: If one repeats Œ± sufÔ¨Åciently often, the deck is eventually restored to its orig-
inal order. One way to see this uses our knowledge of permutations. Write Œ± as a product

Sec. 2.3
Groups
59
of disjoint cycles, say, Œ± = Œ≤1Œ≤2 ¬∑ ¬∑ ¬∑ Œ≤t, where Œ≤i is an ri-cycle. By Proposition 2.25, Œ± has
order k, where k is the least common multiple of the ri. Therefore, Œ±k = (1).
Here is a more general result with a simpler proof (abstract algebra can be easier than
algebra): If G is a Ô¨Ånite group and a ‚ààG, then ak = 1 for some k ‚â•1. Consider the
subset {1, a, a2, . . . , an, . . . }. Since G is Ô¨Ånite, there must be a repetition occurring on this
inÔ¨Ånite list: There are integers m > n with am = an, and hence 1 = ama‚àín = am‚àín. We
have shown that there is some positive power of a equal to 1. [Our original argument that
Œ±k = (1) for a permutation Œ± of 52 cards is not worthless, because it gives an algorithm
computing k.]
‚óÄ
Let us state what we have just proved in Example 2.26.
Proposition 2.27.
If G is a Ô¨Ånite group, then every x ‚ààG has Ô¨Ånite order.
Table 2.3 augments the table in Example 2.5(ii).
Cycle Structure
Number
Order
Parity
(1)
1
1
Even
(1 2)
10
2
Odd
(1 2 3)
20
3
Even
(1 2 3 4)
30
4
Odd
(1 2 3 4 5)
24
5
Even
(1 2)(3 4 5)
20
6
Odd
(1 2)(3 4)
15
2
Even
120
Table 2.3.
Permutations in S5
Here are some geometric examples of groups.
DeÔ¨Ånition.
A motion is a distance preserving bijection œï : R2 ‚ÜíR2 [it can be shown
that œï is a linear transformation if œï(0) = 0]. If œÄ is a polygon in the plane, then its
symmetry group (œÄ) consists of all the motions œï for which œï(œÄ) = œÄ. The elements of
(œÄ) are called symmetries of œÄ.
Example 2.28.
(i) Let œÄ4 be a square having sides of length 1 and vertices {v1, v2, v3, v4}; draw œÄ4 in
the plane so that its center is at the origin O and its sides are parallel to the axes. It can
be shown that every œï ‚àà(œÄ4) permutes the vertices; indeed, a symmetry œï of œÄ4 is
determined by {œï(vi) : 1 ‚â§i ‚â§4}, and so there are at most 24 = 4! possible symmetries.
Not every permutation in S4 arises from a symmetry of œÄ4, however. If vi and v j are
adjacent, then ‚à•vi ‚àív j‚à•= 1, but ‚à•v1 ‚àív3‚à•=
‚àö
2 = ‚à•v2 ‚àív4‚à•; it follows that œï must
preserve adjacency (for motions preserve distance). The reader may now check that there
are only eight symmetries of œÄ4. Aside from the identity and the three rotations about O

60
Groups I
Ch. 2
by 90‚ó¶, 180‚ó¶, and 270‚ó¶, there are four reÔ¨Çections, respectively, in the lines v1v3, v2v4, the
x-axis, and the y-axis (for a generalization to come, note that the y-axis is Om1, where m1
is the midpoint of v1v2, and the x-axis is Om2, where m2 is the midpoint of v2v3). The
group (œÄ4) is called the dihedral group5 with 8 elements, and it is denoted by D8.
m
v
v
v
v
m
1
1
2
2
3
4
O
Figure 2.4
m
v
v
v
v
m
1
1
2
2
3
4
O
v5
m 3
m 4
m 5
Figure 2.5
(ii) The symmetry group (œÄ5) of a regular pentagon œÄ5 with vertices v1, . . . , v5 and
center O has 10 elements: the rotations about the origin of (72 j)‚ó¶, where 0 ‚â§j ‚â§4, as
well as the reÔ¨Çections in the lines Ovk for 1 ‚â§k ‚â§5. The symmetry group (œÄ5) is
called the dihedral group with 10 elements, and it is denoted by D10.
‚óÄ
m
v
v
v
v
m
1
1
2
2
3
4
O
v5
m 3
v6
Figure 2.6
5F. Klein was investigating those Ô¨Ånite groups occurring as subgroups of the group of motions of R3. Some of
these occur as symmetry groups of regular polyhedra (from the Greek poly meaning "many" and hedron meaning
"two-dimensional side"). He invented a degenerate polyhedron that he called a dihedron, from the Greek words di
meaning "two" and hedron, which consists of two congruent regular polygons of zero thickness pasted together.
The symmetry group of a dihedron is thus called a dihedral group. For our purposes, it is more natural to describe
these groups as in the text.

Sec. 2.3
Groups
61
DeÔ¨Ånition.
If œÄn is a regular polygon with n vertices v1, v2, . . . , vn and center O, then the
symmetry group (œÄn) is called the dihedral group with 2n elements, and it is denoted6
by D2n.
The dihedral group D2n contains the n rotations œÅ j about the center by (360 j/n)‚ó¶,
where 0 ‚â§j ‚â§n ‚àí1. The description of the other n elements depends on the parity of n.
If n is odd (as in the case of the pentagon; see Figure 2.5), then the other n symmetries are
reÔ¨Çections in the distinct lines Ovi, for i = 1, 2, . . . , n. If n = 2q is even (see the square in
Figure 2.4 or the regular hexagon in Figure 2.6), then each line Ovi coincides with the line
Ovq+i, giving only q such reÔ¨Çections; the remaining q symmetries are reÔ¨Çections in the
lines Omi for i = 1, 2, . . . , q, where mi is the midpoint of the edge vivi+1. For example,
the six lines of symmetry of œÄ6 are Ov1, Ov2, and Ov3, and Om1, Om2, and Om3.
EXERCISES
2.17 If a1, a2, . . . , at‚àí1, at are elements in a group G, prove that
(a1a2 ¬∑ ¬∑ ¬∑ at‚àí1at)‚àí1 = a‚àí1
t
a‚àí1
t‚àí1 ¬∑ ¬∑ ¬∑ a‚àí1
2 a‚àí1
1 .
2.18 Assume that G is a set with an associative binary operation. Prove that (ab)(cd) = a[(bc)d]
without using generalized associativity.
2.19
(i) Compute the order, inverse, and parity of
Œ± = (1 2)(4 3)(1 3 5 4 2)(1 5)(1 3)(2 3).
(ii) What are the respective orders of the permutations in Exercises 2.1 on page 49 and 2.8
on page 50?
2.20
(i) How many elements of order 2 are there in S5 and in S6?
(ii) How many elements of order 2 are there in Sn?
Hint. You may express your answer as a sum.
2.21 If G is a group, prove that the only element g ‚ààG with g2 = g is 1.
2.22 This exercise gives a shorter list of axioms deÔ¨Åning a group. Let H be a set containing an
element e, and assume that there is an associative binary operation ‚àóon H satisfying the
following properties:
1. e ‚àóx = x for all x ‚ààH;
2. for every x ‚ààH, there is x‚Ä≤ ‚ààH with x‚Ä≤ ‚àóx = e.
(i) Prove that if h ‚ààH satisÔ¨Åes h ‚àóh = h, then h = e.
Hint. If h‚Ä≤ ‚àóh = e, evaluate h‚Ä≤ ‚àóh ‚àóh in two ways.
(ii) For all x ‚ààH, prove that x ‚àóx‚Ä≤ = e.
Hint. Consider (x ‚àóx‚Ä≤)2.
(iii) For all x ‚ààH, prove that x ‚àóe = x.
Hint. Evaluate x ‚àóx‚Ä≤ ‚àóx in two ways.
6Some authors denote D2n by Dn.

62
Groups I
Ch. 2
(iv) Prove that if e‚Ä≤ ‚ààH satisÔ¨Åes e‚Ä≤ ‚àóx = x for all x ‚ààH, then e‚Ä≤ = e.
Hint. Show that (e‚Ä≤)2 = e‚Ä≤.
(v) Let x ‚ààH. Prove that if x‚Ä≤‚Ä≤ ‚ààH satisÔ¨Åes x‚Ä≤‚Ä≤ ‚àóx = e, then x‚Ä≤‚Ä≤ = x‚Ä≤.
Hint. Evaluate x‚Ä≤ ‚àóx ‚àóx‚Ä≤‚Ä≤ in two ways.
(vi) Prove that H is a group.
2.23 Let y be a group element of order m; if m = pt for some prime p, prove that yt has order p.
Hint.
Clearly, (yt)p = 1. Use Theorem 2.24 to show that no smaller power of yt is equal
to 1.
2.24 Let G be a group and let a ‚ààG have order k. If p is a prime divisor of k, and if there is x ‚ààG
with x p = a, prove that x has order pk.
2.25 Let G = GL(2, Q), and let
A =
0
‚àí1
1
0

and
B =
 0
1
‚àí1
1

.
Show that A4 = I = B6, but that (AB)n Ã∏= I for all n > 0, where I =
 1 0
0 1

is the 2 √ó 2
identity matrix. Conclude that AB can have inÔ¨Ånite order even though both factors A and B
have Ô¨Ånite order (this cannot happen in a Ô¨Ånite group).
2.26 If G is a group in which x2 = 1 for every x ‚ààG, prove that G must be abelian. [The Boolean
groups B(X) of Example 2.18 are such groups.]
2.27 If G is a group with an even number of elements, prove that the number of elements in G of
order 2 is odd. In particular, G must contain an element of order 2.
Hint. Pair each element with its inverse.
2.28 What is the largest order of an element in Sn, where n = 1, 2, . . . , 10? (We remark that no
general formula is known for arbitrary n, although, in 1903, E. Landau found the asymptotic
behavior.)
2.4 LAGRANGE'S THEOREM
A subgroup H of a group G is a group contained in G so that if h, h‚Ä≤ ‚ààH, then the product
hh‚Ä≤ in H is the same as the product hh‚Ä≤ in G. The formal deÔ¨Ånition of subgroup, however,
is more convenient to use.
DeÔ¨Ånition.
A subset H of a group G is a subgroup if
(i) 1 ‚ààH;
(ii) if x, y ‚ààH, then xy ‚ààH;
(iii) if x ‚ààH, then x‚àí1 ‚ààH.
If H is a subgroup of G, we write H ‚â§G; if H is a proper subgroup of G, that is, H Ã∏= G,
then we write H < G.

Sec. 2.4
Lagrange's Theorem
63
Observe that {1} and G are always subgroups of a group G, where {1} denotes the
subset consisting of the single element 1. More interesting examples will be given soon.
A subgroup H Ã∏= G is called a proper subgroup.
Let us see that every subgroup H ‚â§G is itself a group. Property (ii) shows that H
is closed; that is, H has a binary operation. Associativity (xy)z = x(yz) holds for all
x, y, z ‚ààG, and so this equation holds, in particular, for all x, y, z ‚ààH. Finally, (i) gives
the identity, and (iii) gives inverses.
It is easier to check that a subset H of a group G is a subgroup (and hence that it is a
group in its own right) than to verify the group axioms for H: Associativity is inherited
from the operation on G and hence it need not be veriÔ¨Åed again.
Example 2.29.
(i) The four permutations
V =

(1), (1 2)(3 4), (1 3)(2 4), (1 4)(2 3)

form a group, because V is a subgroup of S4 : (1) ‚ààV; Œ±2 = (1) for each Œ± ‚ààV,
and so Œ±‚àí1 = Œ± ‚ààV; the product of any two distinct permutations in V ‚àí{(1)} is the
third one. The group V is called the four-group (V abbreviates the original German term
Vierergruppe).
Consider what verifying associativity a(bc) = (ab)c would involve: There are 4 choices
for each of a, b, and c, and so there are 43 = 64 equations to be checked. Plainly, the best
way to prove that V is a group is to show that it is a subgroup of S4.
(ii) If R2 is the plane considered as an (additive) abelian group, then any line L through
the origin is a subgroup. The easiest way to see this is to choose a point (a, b) Ã∏= (0, 0) on
L and then note that L consists of all the scalar multiples (ra,rb). The reader may now
verify that the axioms in the deÔ¨Ånition of subgroup do hold for L.
‚óÄ
We can shorten the list of items needed to verify that a subset is, in fact, a subgroup.
Proposition 2.30.
A subset H of a group G is a subgroup if and only if H is nonempty
and, whenever x, y ‚ààH, then xy‚àí1 ‚ààH.
Proof.
Necessity is clear. For sufÔ¨Åciency, take x ‚ààH (which exists because H Ã∏= ‚àÖ);
by hypothesis, 1 = xx‚àí1 ‚ààH. If y ‚ààH, then y‚àí1 = 1y‚àí1 ‚ààH and, if x, y ‚ààH, then
xy = x(y‚àí1)‚àí1 ‚ààH.
‚Ä¢
Of course, the simplest way to check that a candidate H for a subgroup is nonempty is
to check whether 1 ‚ààH.
Note that if the operation in G is addition, then the condition in the proposition is that
H is a nonempty subset such that x, y ‚ààH implies x ‚àíy ‚ààH.
Proposition 2.31.
A nonempty subset H of a Ô¨Ånite group G is a subgroup if and only if
H is closed; that is, if a, b ‚ààH, then ab ‚ààH. In particular, a nonempty subset of Sn is a
subgroup if and only if it is closed.

64
Groups I
Ch. 2
Sketch of Proof.
Since G is Ô¨Ånite, Proposition 2.27 says that each x ‚ààG has Ô¨Ånite order.
Hence, if xn = 1, then 1 ‚ààH and x‚àí1 = xn‚àí1 ‚ààH.
‚Ä¢
This last proposition can be false when G is an inÔ¨Ånite group. For example, let G be
the additive group Z; the subset H = N is closed, but it is not a subgroup of Z.
For Galois, in 1830, a group was just a subset H of Sn that is closed under composition;
that is, if Œ±, Œ≤ ‚ààH, then Œ±Œ≤ ‚ààH. A. Cayley, in 1854, was the Ô¨Årst to deÔ¨Åne an abstract
group, mentioning associativity, inverses, and identity explicitly. He then proved (see Cay-
ley's theorem) that every abstract group with n elements is, essentially, a subgroup of Sn
(the notion of isomorphism, introduced in the next section, will enable us to state this more
precisely).
Example 2.32.
The subset An of Sn, consisting of all the even permutations, is a subgroup because it is
closed under multiplication: even ‚ó¶even = even. This subgroup An ‚â§Sn is called the
alternating7 group on n letters.
‚óÄ
DeÔ¨Ånition.
If G is a group and a ‚ààG, write
‚ü®a‚ü©= {an : n ‚ààZ} = {all powers of a};
‚ü®a‚ü©is called the cyclic subgroup of G generated by a. A group G is called cyclic if there
exists a ‚ààG with G = ‚ü®a‚ü©, in which case a is called a generator of G.
It is easy to see that ‚ü®a‚ü©is, in fact, a subgroup: 1 = a0 ‚àà‚ü®a‚ü©; anam = an+m ‚àà‚ü®a‚ü©;
a‚àí1 ‚àà‚ü®a‚ü©. Example 2.17(iv) shows, for every n ‚â•1, that the multiplicative group ¬µn of
all nth roots of unity is a cyclic group with the primitive nth root of unity Œ∂ = e2œÄi/n as a
generator.
No doubt, the reader has seen the example of the integers modulo m in an earlier course.
We merely recall the deÔ¨Ånition. Given m ‚â•0 and a ‚ààZ, the congruence class [a] of a
mod m was deÔ¨Åned on page 34:
[a] = {b ‚ààZ : b ‚â°a mod m}
= {a + km : k ‚ààZ}
= {. . . , a ‚àí2m, a ‚àím, a, a + m, a + 2m, . . . }.
7The alternating group Ô¨Årst arose in studying polynomials. If
f (x) = (x ‚àíu1)(x ‚àíu2) ¬∑ ¬∑ ¬∑ (x ‚àíun),
then the number D = 
i< j(ui ‚àíu j) can change sign when the roots are permuted: If Œ± is a permutation of
{u1, u2, . . . , un}, then it is easy to see that 
i< j[Œ±(ui) ‚àíŒ±(u j)] = ¬±D. Thus, the sign of the product alternates
as various permutations Œ± are applied to its factors. The sign does not change for those Œ± in the alternating group,
and this last fact can be used to give another proof of Theorem 2.13(ii).

Sec. 2.4
Lagrange's Theorem
65
DeÔ¨Ånition.
The integers mod m, denoted8 by Im, is the family of all congruence classes
mod m.
Recall that [a] = [b] in Im if and only if a ‚â°b mod m. In particular, [a] = [0] in
Im if and only if a ‚â°0 mod m; that is, [a] = [0] in Im if and only if m is a divisor of a.
The deÔ¨Ånition of congruence mod m makes sense for all m ‚â•0, but the cases m = 0 and
m = 1 are not very interesting: a ‚â°b mod 0 means 0 | (a ‚àíb), which says that a = b;
a ‚â°b mod 1 means 1 | (a ‚àíb), which says that a and b are always congruent; that is,
there is only one congruence class mod 1. Recall Proposition 1.19, which we now rewrite
in the bracket notation.
Proposition 1.19. Let m ‚â•2 be a Ô¨Åxed integer.
(i) If a ‚ààZ, then [a] = [r] for some r with 0 ‚â§r < m.
(ii) If 0 ‚â§r‚Ä≤ < r < m, then [r‚Ä≤] Ã∏= [r].
(iii) Im has exactly m elements, namely, [0], [1], . . . , [m ‚àí1].
For every m ‚â•2, Im is an (additive) cyclic group, where
[a] + [b] = [a + b];
the identity is [0], the inverse of [a] is [‚àía], and a generator is [1]. Part (iii) shows that Im
has order m.
A cyclic group can have several different generators. For example, ‚ü®a‚ü©=

a‚àí1 
.
Theorem 2.33.
(i) If G = ‚ü®a‚ü©is a cyclic group of order n, then ak is a generator of G if and only if
(k, n) = 1.
(ii) If G is a cyclic group of order n and gen(G) = {all generators of G}, then
|gen(G)| = œÜ(n),
where œÜ is the Euler œÜ-function.
Proof.
(i) If ak generates G, then a ‚àà‚ü®ak‚ü©, so that a = akt for some t ‚ààZ. Hence,
akt‚àí1 = 1; by Theorem 2.24, n | (kt ‚àí1), so there is v ‚ààZ with nv = kt ‚àí1. Therefore,
1 is a linear combination of k and m, and so (k, n) = 1.
Conversely, if (k, n) = 1, then nt + ku = 1 for t, u ‚ààZ; hence
a = ant+ku = antaku = aku ‚àà‚ü®ak‚ü©.
Therefore, every power of a also lies in ‚ü®ak‚ü©and G = ‚ü®ak‚ü©.
(ii) Proposition 1.38 says that œÜ(n) = |{k ‚â§n : (k, n) = 1}|. The next proposition shows
that G = {1, a, . . . , an‚àí1}, and so this result follows from part (i).
‚Ä¢
8We introduce this new notation because there is no commonly agreed one; the most popular contenders are
Zm and Z/mZ. We have chosen Im because I is the initial letter of integers. The usual notation Z for the integers
(it is the initial letter of the German Zahlen) is almost universally accepted, and so a change from Z to I would be
consistent but too distracting.

66
Groups I
Ch. 2
Proposition 2.34.
Let G be a Ô¨Ånite group and let a ‚ààG. Then the order of a is |‚ü®a‚ü©|, the
number of elements in ‚ü®a‚ü©.
Proof.
Since G is Ô¨Ånite, there is an integer k ‚â•1 with 1, a, a2, . . . , ak‚àí1 consisting of k
distinct elements, while 1, a, a2, . . . , ak has a repetition; hence ak ‚àà{1, a, a2, . . . , ak‚àí1};
that is, ak = ai for some i with 0 ‚â§i < k. If i ‚â•1, then ak‚àíi = 1, contradicting the
original list having no repetitions. Therefore, ak = a0 = 1, and k is the order of a (being
the smallest positive such k).
If H = {1, a, a2, . . . , ak‚àí1}, then |H| = k; it sufÔ¨Åces to show that H = ‚ü®a‚ü©. Clearly,
H ‚äÜ‚ü®a‚ü©. For the reverse inclusion, take ai ‚àà‚ü®a‚ü©. By the division algorithm, i = qk + r,
where 0 ‚â§r < k. Hence ai = aqk+r = aqkar = (ak)qar = ar ‚ààH; this gives ‚ü®a‚ü©‚äÜH,
and so ‚ü®a‚ü©= H.
‚Ä¢
DeÔ¨Ånition.
If G is a Ô¨Ånite group, then the number of elements in G, denoted by |G|, is
called the order of G.
The word order is used in two senses: the order of an element a ‚ààG and the order |G|
of a group G. Proposition 2.34 shows that the order of a group element a is equal to | ‚ü®a‚ü©|.
Proposition 2.35.
The intersection 
i‚ààI Hi of any family of subgroups of a group G is
again a subgroup of G. In particular, if H and K are subgroups of G, then H ‚à©K is a
subgroup of G.
Sketch of Proof.
This follows easily from the deÔ¨Ånitions.
‚Ä¢
Corollary 2.36.
If X is a subset of a group G, then there is a subgroup ‚ü®X‚ü©of G con-
taining X that is smallest in the sense that ‚ü®X‚ü©‚â§H for every subgroup H of G that
contains X.
Proof.
There exist subgroups of G that contain X; for example, G itself contains X.
DeÔ¨Åne ‚ü®X‚ü©= 
X‚äÜH H, the intersection of all the subgroups H of G that contain X. By
Proposition 2.35, ‚ü®X‚ü©is a subgroup of G; of course, ‚ü®X‚ü©contains X because every H
contains X. Finally, if H is any subgroup containing X, then H is one of the subgroups
whose intersection is ‚ü®X‚ü©; that is, ‚ü®X‚ü©‚â§H.
‚Ä¢
Note that there is no restriction on the subset X in the last corollary; in particular, X = ‚àÖ
is allowed. Since the empty set is a subset of every set, we have ‚àÖ‚äÜH for every subgroup
H of G. Thus, ‚ü®‚àÖ‚ü©is the intersection of all the subgroups of G; in particular, ‚ü®‚àÖ‚ü©‚â§{1},
and so ‚ü®‚àÖ‚ü©= {1}.
DeÔ¨Ånition.
If X is a subset of a group G, then ‚ü®X‚ü©is called the subgroup generated
by X.
If X is a nonempty subset of a group G, deÔ¨Åne a word 9 on X to be an element g ‚ààG
of the form g = xe1
1 ¬∑ ¬∑ ¬∑ xen
n , where xi ‚ààX and ei = ¬±1 for all i.
9This term will be modiÔ¨Åed a bit when we discuss free groups.

Sec. 2.4
Lagrange's Theorem
67
Proposition 2.37.
If X is a nonempty subset of a group G, then ‚ü®X‚ü©is the set of all the
words on X.
Proof.
We claim that W(X), the set of all the words on X, is a subgroup. If x ‚ààX, then
1 = xx‚àí1 ‚ààW(X); the product of two words on X is also a word on X; the inverse of a
word on X is a word on X. It now follows that ‚ü®X‚ü©‚â§W(X), for W(X) obviously contains
X (and ‚ü®X‚ü©is the intersection of all the subgroups of G containing X). On the other hand,
any subgroup of G containing X must also contain W(X), and so ‚ü®X‚ü©= W(X).
‚Ä¢
Example 2.38.
(i) If G = ‚ü®a‚ü©is a cyclic group with generator a, then G is generated by the subset X = {a}.
(ii) The dihedral group D2n, the symmetry group of a regular n-gon, is generated by œÅ, œÉ,
where œÅ is a rotation by (360/n)‚ó¶and œÉ is a reÔ¨Çection. Note that these generators satisfy
the equations œÅn = 1, œÉ 2 = 1, and œÉœÅœÉ = œÅ‚àí1.
‚óÄ
Perhaps the most fundamental fact about subgroups H of a Ô¨Ånite group G is that their
orders are constrained. Certainly, we have |H| ‚â§|G|, but it turns out that |H| must be a
divisor of |G|. To prove this, we introduce the notion of coset.
DeÔ¨Ånition.
If H is a subgroup of a group G and a ‚ààG, then the coset aH is the subset
aH of G, where
aH = {ah : h ‚ààH}.
The cosets deÔ¨Åned are often called left cosets; there are also right cosets of H, namely,
subsets of the form Ha = {ha : h ‚ààH}. In general, left cosets and right cosets may be
different, as we shall soon see.
If we use the ‚àónotation for the operation in a group G, then we denote the coset aH by
a ‚àóH, where
a ‚àóH = {a ‚àóh : h ‚ààH}.
In particular, if the operation is addition, then the coset is denoted by
a + H = {a + h : h ‚ààH}.
Of course, a = a1 ‚ààaH. Cosets are usually not subgroups. For example, if a /‚ààH,
then 1 /‚ààaH (otherwise 1 = ah for some h ‚ààH, and this gives the contradiction a =
h‚àí1 ‚ààH).
Example 2.39.
(i) Consider the plane R2 as an (additive) abelian group and let L be a line through the
origin O (see Figure 2.7 on page 68); as in Example 2.29(ii), the line L is a subgroup of
R2. If Œ≤ ‚ààR2, then the coset Œ≤ + L is the line L‚Ä≤ containing Œ≤ that is parallel to L, for if
rŒ± ‚ààL, then the parallelogram law gives Œ≤ + rŒ± ‚ààL‚Ä≤.

68
Groups I
Ch. 2
L
L' = Œ≤ + L
r Œ±
Œ≤
Œ≤ + r Œ±
Figure 2.7
(ii) Let A be an m √ón matrix with real entries, and let Ax = b be a consistent linear system
of equations; that is, there is a column vector s ‚ààRn with As = b. The solution space
S = {x ‚ààRn : Ax = 0} of the homogeneous system Ax = 0 is an additive subgroup of
Rn, and the solution set {x ‚ààRn : Ax = b} of the original inhomogeneous system is the
coset s + S.
(iii) If G = S3 and H = ‚ü®(1 2)‚ü©, there are exactly three left cosets of H, namely
H =
{(1), (1 2)} = (1 2)H,
(1 3)H = {(1 3), (1 2 3)} = (1 2 3)H,
(2 3)H = {(2 3), (1 3 2)} = (1 3 2)H,
each of which has size 2. Note that these cosets are also "parallel;" that is, distinct cosets
are disjoint.
Consider the right cosets of H = ‚ü®(1 2)‚ü©in S3:
H =
{(1), (1 2)} = H(1 2),
H(1 3) = {(1 3), (1 3 2)} = H(1 3 2),
H(2 3) = {(2 3), (1 2 3)} = H(1 2 3).
Again, we see that there are exactly 3 (right) cosets, each of which has size 2. Note that
these cosets are "parallel"; that is, distinct (right) cosets are disjoint.
‚óÄ
Lemma 2.40.
Let H be a subgroup of a group G, and let a, b ‚ààG.
(i) aH = bH if and only if b‚àí1a ‚ààH. In particular, aH = H if and only if a ‚ààH.
(ii) If aH ‚à©bH Ã∏= ‚àÖ, then aH = bH.
(iii) |aH| = |H| for all a ‚ààG.

Sec. 2.4
Lagrange's Theorem
69
Remark.
In Exercise 2.29 on page 72, it is shown that Ha = Hb if and only if ab‚àí1 ‚ààH,
and hence Ha = H if and only if a ‚ààH.
‚óÄ
Sketch of Proof.
The Ô¨Årst two statements follow from observing that the relation on G,
deÔ¨Åned by a ‚â°b if b‚àí1a ‚ààH, is an equivalence relation whose equivalence classes are
the cosets; it follows from Proposition 1.54 that the cosets of H partition G. The third
statement is true because h ‚Üíah is a bijection H ‚ÜíaH.
‚Ä¢
The next theorem is named after J. L. Lagrange, who saw, in 1770, that the order of
certain subgroups of Sn are divisors of n!. The notion of group was invented by Galois 60
years afterward, and it was probably Galois who Ô¨Årst proved the theorem in full.
Theorem 2.41 (Lagrange's Theorem).
If H is a subgroup of a Ô¨Ånite group G, then |H|
is a divisor of |G|.
Proof.
Let {a1H, a2H, . . . , at H} be the family of all the distinct cosets of H in G. Then
G = a1H ‚à™a2H ‚à™¬∑ ¬∑ ¬∑ ‚à™at H,
because each g ‚ààG lies in the coset gH, and gH = ai H for some i.
Moreover,
Lemma 2.40(ii) shows that the cosets partition G into pairwise disjoint subsets. It follows
that
|G| = |a1H| + |a2H| + ¬∑ ¬∑ ¬∑ + |at H|.
But |ai H| = |H| for all i, by Lemma 2.40(iii), so that |G| = t|H|, as desired.
‚Ä¢
DeÔ¨Ånition.
The index of a subgroup H in G, denoted by [G : H], is the number of left10
cosets of H in G.
The index [G : H] is the number t in the formula |G| = t|H| in the proof of Lagrange's
theorem, so that
|G| = [G : H]|H|;
this formula shows that the index [G : H] is also a divisor of |G|; moreover,
[G : H] = |G|/|H|.
Example 2.42.
Recall that the dihedral group D2n = (œÄn), the group of symmetries of the regular n-gon
œÄn, has order 2n and it contains a cyclic subgroup of order n generated by a rotation œÅ. The
subgroup ‚ü®œÅ‚ü©has index [D2n : ‚ü®œÅ‚ü©] = 2. Thus, there are two cosets: ‚ü®œÅ‚ü©and œÉ ‚ü®œÅ‚ü©, where
œÉ is any reÔ¨Çection outside of ‚ü®œÅ‚ü©. It follows that every element Œ± ‚ààD2n has a factorization
Œ± = œÉ iœÅ j, where i = 0, 1 and 0 ‚â§j < n.
‚óÄ
10Exercise 2.37 on page 72 shows that the number of left cosets of a subgroup is equal to the number of its
right cosets.

70
Groups I
Ch. 2
Corollary 2.43.
If G is a Ô¨Ånite group and a ‚ààG, then the order of a is a divisor of |G|.
Proof.
This follows at once from Proposition 2.34, for the order of a is | ‚ü®a‚ü©|.
‚Ä¢
Corollary 2.44.
If G is a Ô¨Ånite group, then a|G| = 1 for all a ‚ààG.
Proof.
If a has order d, then |G| = dm for some integer m, by the previous corollary,
and so a|G| = adm = (ad)m = 1.
‚Ä¢
Corollary 2.45.
If p is a prime, then every group G of order p is cyclic.
Proof.
If a ‚ààG and a Ã∏= 1, then a has order d > 1, and d is a divisor of p. Since p is
prime, d = p, and so G = ‚ü®a‚ü©.
‚Ä¢
We have seen that Im, under addition, is a cyclic group of order m. Now multiplication
¬µ : Im √ó Im ‚ÜíIm, given by
[a][b] = [ab],
is also a binary operation on Im (which is well-deÔ¨Åned, by Proposition 1.20); it is associa-
tive, commutative, and [1] is an identity element. However, Im is not a group under this
operation because inverses may not exist; for example, [0] has no multiplicative inverse.
Proposition 2.46.
The set U(Im), deÔ¨Åned by
U(Im) = { [r] ‚ààIm : (r, m) = 1},
is a multiplicative group of order œÜ(m), where œÜ is the Euler œÜ-function. In particular, if p
is a prime, then U(Ip) = I√ó
p , the nonzero elements of Ip, is a multiplicative group of order
p ‚àí1.
Proof.
By Exercise 1.14 on page 12, (r, m) = 1 = (r‚Ä≤, m) implies (rr‚Ä≤, m) = 1; hence
U(Im) is closed under multiplication. We have already mentioned that multiplication is
associative and that [1] is the identity. If (a, m) = 1, then [a][x] = [1] can be solved for
[x] in Im. Now (x, m) = 1, for rx + sm = 1 for some integer s, and so Proposition 1.13
on page 5 gives (x, m) = 1; therefore, [x] ‚ààU(Im), and so each [r] ‚ààU(Im) has an
inverse. Therefore, U(Im) is a group; the deÔ¨Ånition of the Euler œÜ-function shows that
|U(Im)| = œÜ(m).
The last statement follows from œÜ(p) = p ‚àí1 when p is a prime.
‚Ä¢
In Chapter 3, we will prove, for every prime p, that I√ó
p is a cyclic group.
Here is a group-theoretic proof of Theorem 1.24, Fermat's theorem. Our earlier proof
used binomial coefÔ¨Åcients and the fact that p |
p
r

for 0 < r < p.
Corollary 2.47 (Fermat).
If p is a prime and a ‚ààZ, then
a p ‚â°a mod p.

Sec. 2.4
Lagrange's Theorem
71
Proof.
It sufÔ¨Åces to show that [a p] = [a] in Ip. If [a] = [0], then [a p] = [a]p = [0]p =
[0] = [a]. If [a] Ã∏= [0], then [a] ‚ààI√ó
p , the multiplicative group of nonzero elements in Ip.
By Corollary 2.44 to Lagrange's theorem, [a]p‚àí1 = [1], because |I√ó
p | = p‚àí1. Multiplying
by [a] gives the desired result [a p] = [a]p = [a]. Therefore, a p ‚â°a mod p.
‚Ä¢
We now give a generalization of Fermat's theorem due to Euler.
Theorem 2.48 (Euler).
If (r, m) = 1, then
rœÜ(m) ‚â°1 mod m.
Proof.
Since |U(Im)| = œÜ(m), Corollary 2.44 (essentially Lagrange's theorem) gives
[r]œÜ(m) = [1] for all [r] ‚ààU(Im). In congruence notation, this says that if (r, m) = 1, then
rœÜ(m) ‚â°1 mod m.
‚Ä¢
Example 2.49.
It is easy to see that
U(I8) =

[1], [3], [5], [7]

is a group (resembling the four-group V) in which the square of each element is [1], while
U(I10) =

[1], [3], [7], [9]

is a cyclic group of order 4 [after we introduce isomorphisms in the next section, we will
say that U(I8) is isomorphic to V and U(I10) is isomorphic to I4].
‚óÄ
Theorem 2.50 (Wilson's Theorem).
An integer p is a prime if and only if
(p ‚àí1)! ‚â°‚àí1 mod p.
Proof.
Assume that p is a prime. If a1, a2, . . . , an is a list of all the elements of a Ô¨Ånite
abelian group G, then the product a1a2 . . . an is the same as the product of all elements
a with a2 = 1, for any other element cancels against its inverse. Since p is prime, Ex-
ercise 1.37 on page 14 implies that I√ó
p has only one element of order 2, namely, [‚àí1]. It
follows that the product of all the elements in I√ó
p , namely, [(p ‚àí1)!], is equal to [‚àí1];
therefore, (p ‚àí1)! ‚â°‚àí1 mod p.
Conversely, assume that m is composite: there are integers a and b with m = ab and
1 < a ‚â§b < m. If a < b, then m = ab is a divisor of (m‚àí1)!, and so (m‚àí1)! ‚â°0 mod m.
If a = b, then m = a2. If a = 2, then (a2 ‚àí1)! = 3! = 6 ‚â°2 mod 4 and, of course,
2 Ã∏‚â°‚àí1 mod 4. If 2 < a, then 2a < a2, and so a and 2a are factors of (a2 ‚àí1)!; therefore,
(a2 ‚àí1)! ‚â°0 mod a2. Thus, (a2 ‚àí1)! Ã∏‚â°‚àí1 mod a2, and the proof is complete.
‚Ä¢

72
Groups I
Ch. 2
Remark.
We can generalize Wilson's theorem in the same way that Euler's theorem
generalizes Fermat's theorem: Replace U(Ip) by U(Im). For example, for all m ‚â•3, it
can be proved that U(I2m) has exactly 3 elements of order 2, namely, [‚àí1], [1+2m‚àí1], and
[‚àí(1+2m‚àí1)]. It now follows that the product of all the odd numbers r, where 1 ‚â§r < 2m
is congruent to 1 mod 2m, because
(‚àí1)(1 + 2m‚àí1)(‚àí1 ‚àí2m‚àí1) = (1 + 2m‚àí1)2
= 1 + 2m + 22m‚àí2 ‚â°1 mod 2m.
‚óÄ
EXERCISES
2.29 Let H be a subgroup of a group G.
(i) Prove that right cosets Ha and Hb are equal if and only if ab‚àí1 ‚ààH.
(ii) Prove that the relation a ‚â°b if ab‚àí1 ‚ààH is an equivalence relation on G whose
equivalence classes are the right cosets of H.
2.30
(i) DeÔ¨Åne the special linear group by
SL(2, R) = {A ‚ààGL(2, R) : det(A) = 1}.
Prove that SL(2, R) is a subgroup of GL(2, R).
(ii) Prove that GL(2, Q) is a subgroup of GL(2, R).
2.31
(i) Give an example of two subgroups H and K of a group G whose union H ‚à™K is not a
subgroup of G.
Hint. Let G be the four-group V.
(ii) Prove that the union H ‚à™K of two subgroups is itself a subgroup if and only if either H
is a subset of K or K is a subset of H.
2.32 Let G be a Ô¨Ånite group with subgroups H and K. If H ‚â§K, prove that
[G : H] = [G : K][K : H].
2.33 If H and K are subgroups of a group G and if |H| and |K| are relatively prime, prove that
H ‚à©K = {1}.
Hint. If x ‚ààH ‚à©K, then x|H| = 1 = x|K|.
2.34 Prove that every subgroup S of a cyclic group G = ‚ü®a‚ü©is itself cyclic.
Hint. If S Ã∏= 1, choose k to be the smallest positive integer with ak ‚ààS.
2.35 Prove that a cyclic group G of order n has a subgroup of order d for every d dividing n.
Hint. If G = ‚ü®a‚ü©and n = dk, consider

ak 
.
2.36 Let G be a group of order 4. Prove that either G is cyclic or x2 = 1 for every x ‚ààG.
Conclude, using Exercise 2.26 on page 62, that G must be abelian.
2.37 If H is a subgroup of a group G, prove that the number of left cosets of H in G is equal to the
number of right cosets of H in G.
Hint. The function œï : aH ‚ÜíHa‚àí1 is a bijection from the family of all left cosets of H to
the family of all right cosets of H.

Sec. 2.5
Homomorphisms
73
2.38 Let p be an odd prime, and let a1, . . . , ap‚àí1 be a permutation of {1, 2, . . . , p ‚àí1}. Prove that
there exist i Ã∏= j with iai ‚â°ja j mod p.
Hint. Use Wilson's theorem.
2.5 HOMOMORPHISMS
An important problem is determining whether two given groups G and H are somehow
the same. For example, we have investigated S3, the group of all permutations of X =
{1, 2, 3}. The group SY of all the permutations of Y = {a, b, c} is a group different from
S3 because permutations of {1, 2, 3} are different than permutations of {a, b, c}. But even
though S3 and SY are different, they surely bear a strong resemblance to each other (see
Example 2.51). A more interesting example is the strong resemblance between S3 and D6,
the symmetries of an equilateral triangle. The notions of homomorphism and isomorphism
allow us to compare different groups, as we shall see.
DeÔ¨Ånition.
If (G, ‚àó) and (H, ‚ó¶) are groups (we have displayed the operation in each),
then a function f : G ‚ÜíH is a homomorphism11 if
f (x ‚àóy) = f (x) ‚ó¶f (y)
for all x, y ‚ààG. If f is also a bijection, then f is called an isomorphism. Two groups G
and H are called isomorphic, denoted by G ‚àº= H, if there exists an isomorphism f : G ‚Üí
H between them.
A multiplication table of a group G displays every product ab for a, b ‚ààG.
G
a1
a2
¬∑ ¬∑ ¬∑
a j
¬∑ ¬∑ ¬∑
an
a1
a1a1
a1a2
¬∑ ¬∑ ¬∑
a1a j
¬∑ ¬∑ ¬∑
a1an
a2
a2a1
a2a2
¬∑ ¬∑ ¬∑
a2a j
¬∑ ¬∑ ¬∑
a2an
ai
aia1
aia2
¬∑ ¬∑ ¬∑
aia j
¬∑ ¬∑ ¬∑
aian
an
ana1
ana2
¬∑ ¬∑ ¬∑
ana j
¬∑ ¬∑ ¬∑
anan
DeÔ¨Ånition.
Let a1, a2, . . . , an be a list with no repetitions of all the elements of a group
G. A multiplication table for G is an n √ó n array whose i j entry is aia j.
11The word homomorphism comes from the Greek homo meaning "same" and morph meaning "shape" or
"form." Thus, a homomorphism carries a group to another group (its image) of similar form. The word isomor-
phism involves the Greek iso meaning "equal," and isomorphic groups have identical form.

74
Groups I
Ch. 2
A multiplication table of a group G of order n depends on how we list the elements of
G, and so G has n! different multiplication tables. (Thus, the task of determining whether
a multiplication table of a group G is the same as some multiplication table of another
group H is a daunting one: It involves about n! comparisons, each of which involves com-
paring n2 entries.) If a1, a2, . . . , an is a list of all the elements of G with no repetitions,
and if f : G ‚ÜíH is a bijection, then f (a1), f (a2), . . . , f (an) is a list of all the ele-
ments of H with no repetitions, and this latter list determines a multiplication table for
H. That f is an isomorphism says that if we superimpose the given multiplication table
for G (determined by a1, a2, . . . , an) upon the multiplication table for H [determined by
f (a1), f (a2), . . . , f (an)], then the tables match: If aia j is the i j entry in the given multi-
plication table of G, then f (ai) f (a j) = f (aia j) is the i j entry of the multiplication table
of H. In this sense, isomorphic groups have the same multiplication table. Thus, isomor-
phic groups are essentially the same, differing only in the notation for the elements and the
operations.
Example 2.51.
Let us show that G = S3, the symmetric group permuting {1, 2, 3}, and H = SY , the
symmetric group of all the permutations of Y = {a, b, c}, are isomorphic. First, enumerate
G:
(1),
(1 2),
(1 3),
(2 3),
(1 2 3),
(1 3 2).
We deÔ¨Åne the obvious function œï : S3 ‚ÜíSY that replaces numbers by letters:
(1),
(a b),
(a c),
(b c),
(a b c),
(a c b).
Compare the multiplication table for S3 arising from this list of its elements with the mul-
tiplication table for SY arising from the corresponding list of its elements. The reader
should write out the complete tables of each and superimpose one on the other to see that
they do match. We will check only one entry. The 4,5 position in the table for S3 is the
product (2 3)(1 2 3) = (1 3), while the 4,5 position in the table for SY is the product
(b c)(a b c) = (a c).
This result is generalized in Exercise 2.39 on page 80.
‚óÄ
Lemma 2.52.
Let f : G ‚ÜíH be a homomorphism of groups.
(i) f (1) = 1
(ii) f (x‚àí1) = f (x)‚àí1
(iii) f (xn) = f (x)n for all n ‚ààZ
Sketch of Proof.
(i) 1 ¬∑ 1 = 1 implies f (1) f (1) = f (1).
(ii) 1 = xx‚àí1 implies 1 = f (1) = f (x) f (x‚àí1).
(iii) Use induction to show that f (xn) = f (x)n for all n ‚â•0. Then observe that x‚àín =
(x‚àí1)n, and use part (ii).
‚Ä¢

Sec. 2.5
Homomorphisms
75
Example 2.53.
If G and H are cyclic groups of the same order m, then G and H are isomorphic. (It follows
from Corollary 2.45 that any two groups of prime order p are isomorphic.) Although
this is not difÔ¨Åcult, it requires some care. We have G = {1, a, a2, . . . , am‚àí1} and H =
{1, b, b2, . . . , bm‚àí1}, and the obvious choice for an isomorphism is the bijection f : G ‚Üí
H given by f (ai) = bi. To check that f is an isomorphism, that is, f (aia j) = bi+ j,
involves two cases: i + j ‚â§m ‚àí1; i + j > m ‚àí1. We give a less computational proof in
Example 2.71.
‚óÄ
A property of a group G that is shared by any other group isomorphic to it is called an
invariant of G. For example, the order |G| is an invariant of G, for isomorphic groups
have the same orders. Being abelian is an invariant [if f is an isomorphism and a and b
commute, then ab = ba and
f (a) f (b) = f (ab) = f (ba) = f (b) f (a);
hence, f (a) and f (b) commute]. Thus, I6 and S3 are not isomorphic, for I6 is abelian and
S3 is not. In general, it is a challenge to decide whether two given groups are isomorphic.
See Exercise 2.42 on page 80 for more examples of invariants.
Example 2.54.
We present two nonisomorphic abelian groups of the same order.
As in Example 2.29(i), let V be the four-group consisting of the following four permu-
tations:
V =

(1), (1 2)(3 4), (1 3)(2 4), (1 4)(2 3)

,
and let ¬µ4 = ‚ü®i‚ü©= {1, i, ‚àí1, ‚àíi} be the multiplicative cyclic group of fourth roots of
unity, where i2 = ‚àí1. If there were an isomorphism f : V ‚Üí¬µ4, then surjectivity
of f would provide some x ‚ààV with i = f (x). But x2 = (1) for all x ‚ààV, so that
i2 = f (x)2 = f (x2) = f ((1)) = 1, contradicting i2 = ‚àí1. Therefore, V and ¬µ4 are not
isomorphic.
There are other ways to prove this result. For example, ¬µ4 is cyclic and V is not; ¬µ4
has an element of order 4 and V does not; ¬µ4 has a unique element of order 2, but V
has 3 elements of order 2. At this stage, you should really believe that ¬µ4 and V are not
isomorphic!
‚óÄ
DeÔ¨Ånition.
If f : G ‚ÜíH is a homomorphism, deÔ¨Åne
kernel12 f = {x ‚ààG : f (x) = 1}
and
image f = {h ‚ààH : h = f (x) for some x ‚ààG}.
We usually abbreviate kernel f to ker f and image f to im f .
12Kernel comes from the German word meaning "grain" or "seed" (corn comes from the same word). Its usage
here indicates an important ingredient of a homomorphism.

76
Groups I
Ch. 2
Example 2.55.
(i) If ¬µ2 is the multiplicative group ¬µ2 = {¬±1}, then sgn: Sn ‚Üí¬µ2 is a homomorphism,
by Theorem 2.12. The kernel of sgn is the alternating group An, the set of all even permu-
tations.
(ii) Determinant is a surjective homomorphism det: GL(n, R) ‚ÜíR√ó, the multiplicative
group of nonzero real numbers, whose kernel is the special linear group SL(n, R) of all
n √ó n matrices of determinant 1.
‚óÄ
Proposition 2.56.
Let f : G ‚ÜíH be a homomorphism.
(i) ker f is a subgroup of G and im f is a subgroup of H.
(ii) If x ‚ààker f and if a ‚ààG, then axa‚àí1 ‚ààker f .
(iii) f is an injection if and only if ker f = {1}.
Sketch of Proof.
(i) Routine.
(ii) f (axa‚àí1) = f (a)1 f (a)‚àí1 = 1.
(iii) f (a) = f (b) if and only if f (b‚àí1a) = 1.
‚Ä¢
DeÔ¨Ånition.
A subgroup K of a group G is called a normal subgroup if k ‚ààK and g ‚ààG
imply gkg‚àí1 ‚ààK. If K is a normal subgroup of G, we write K ‚úÅG.
The proposition thus says that the kernel of a homomorphism is always a normal sub-
group. If G is an abelian group, then every subgroup K is normal, for if k ‚ààK and g ‚ààG,
then gkg‚àí1 = kgg‚àí1 = k ‚ààK. The converse of this last statement is false: In Exam-
ple 2.63, we shall show that there is a nonabelian group (the quaternions), each of whose
subgroups is normal.
The cyclic subgroup H = ‚ü®(1 2)‚ü©of S3, consisting of the two elements (1) and (1 2), is
not a normal subgroup of S3: If Œ± = (1 2 3), then Œ±‚àí1 = (3 2 1), and
Œ±(1 2)Œ±‚àí1 = (1 2 3)(1 2)(3 2 1) = (2 3) /‚ààH
[by Theorem 2.9, Œ±(1 2)Œ±‚àí1 = (Œ±1 Œ±2) = (2 3)]. On the other hand, the cyclic subgroup
K = ‚ü®(1 2 3)‚ü©of S3 is a normal subgroup, as the reader should verify.
It follows from Examples 2.55(i) and 2.55(ii) that An is a normal subgroup of Sn and
SL(n, R) is a normal subgroup of GL(n, R) (however, it is also easy to prove these facts
directly).
DeÔ¨Ånition.
If G is a group and a ‚ààG, then a conjugate of a is any element in G of the
form
gag‚àí1,
where g ‚ààG.
It is clear that a subgroup K ‚â§G is a normal subgroup if and only if K contains all the
conjugates of its elements: If k ‚ààK, then gkg‚àí1 ‚ààK for all g ‚ààG.

Sec. 2.5
Homomorphisms
77
Example 2.57.
(i) Theorem 2.9 states that two permutations in Sn are conjugate if and only if they have
the same cycle structure.
(ii) In linear algebra, two matrices A, B ‚ààGL(n, R) are called similar if they are conju-
gate; that is, if there is a nonsingular matrix P with B = P AP‚àí1.
‚óÄ
DeÔ¨Ånition.
If G is a group and g ‚ààG, deÔ¨Åne conjugation Œ≥g : G ‚ÜíG by
Œ≥g(a) = gag‚àí1
for all a ‚ààG.
Proposition 2.58.
(i) If G is a group and g ‚ààG, then conjugation Œ≥g : G ‚ÜíG is an isomorphism.
(ii) Conjugate elements have the same order.
Proof.
(i) If g, h ‚ààG, then
(Œ≥g ‚ó¶Œ≥h)(a) = Œ≥g(hah‚àí1) = g(hah‚àí1)g‚àí1 = (gh)a(gh)‚àí1 = Œ≥gh(a);
that is,
Œ≥g ‚ó¶Œ≥h = Œ≥gh.
It follows that each Œ≥g is a bijection, for Œ≥g ‚ó¶Œ≥g‚àí1 = Œ≥1 = 1 = Œ≥g‚àí1 ‚ó¶Œ≥g. We now show
that Œ≥g is an isomorphism: if a, b ‚ààG,
Œ≥g(ab) = g(ab)g‚àí1 = ga(g‚àí1g)bg‚àí1 = Œ≥g(a)Œ≥g(b).
(ii) To say that a and b are conjugate is to say that there is g ‚ààG with b = gag‚àí1; that is,
b = Œ≥g(a). But Œ≥g is an isomorphism, and so Exercise 2.42 on page 80 shows that a and
b = Œ≥g(a) have the same order.
‚Ä¢
Example 2.59.
DeÔ¨Åne the center of a group G, denoted by Z(G), to be
Z(G) = {z ‚ààG : zg = gz for all g ‚ààG};
that is, Z(G) consists of all elements commuting with everything in G.
It is easy to see that Z(G) is a subgroup of G; it is a normal subgroup because if
z ‚ààZ(G) and g ‚ààG, then
gzg‚àí1 = zgg‚àí1 = z ‚ààZ(G).
A group G is abelian if and only if Z(G) = G. At the other extreme are centerless groups
G for which Z(G) = {1}; for example, Z(S3) = {1}; indeed, all large symmetric groups
are centerless, for Exercise 2.15 on page 51 shows that Z(Sn) = {1} for all n ‚â•3.
‚óÄ

78
Groups I
Ch. 2
Example 2.60.
If G is a group, then an automorphism of G is an isomorphism f : G ‚ÜíG. For example,
every conjugation Œ≥g is an automorphism of G (it is called an inner automorphism), for
its inverse is conjugation by g‚àí1. The set Aut(G) of all the automorphisms of G is itself a
group, under composition, and the set of all conjugations,
Inn(G) = {Œ≥g : g ‚ààG},
is a subgroup of Aut(G). Exercise 2.64 on page 82 says that the function ! : G ‚ÜíAut(G),
given by g ‚ÜíŒ≥g, is a homomorphism with im ! = Inn(G) and ker ! = Z(G); moreover,
Inn(G) ‚úÅAut(G).
‚óÄ
Example 2.61.
The four-group V is a normal subgroup of S4. Recall that the elements of V are
V =

(1), (1 2)(3 4), (1 3)(2 4), (1 4)(2 3)

.
By Theorem 2.9, every conjugate of a product of two transpositions is another such. But
we saw, in Example 2.5(i), that only 3 permutations in S4 have this cycle structure, and so
V is a normal subgroup of S4.
‚óÄ
Proposition 2.62.
(i) If H is a subgroup of index 2 in a group G, then g2 ‚ààH for every g ‚ààG.
(ii) If H is a subgroup of index 2 in a group G, then H is a normal subgroup of G.
Proof.
(i) Since H has index 2, there are exactly two cosets, namely, H and aH, where
a /‚ààH. Thus, G is the disjoint union G = H ¬∑‚à™aH. Take g ‚ààG with g /‚ààH, so that
g = ah for some h ‚ààH. If g2 /‚ààH, then g2 = ah‚Ä≤, where h‚Ä≤ ‚ààH. Hence,
g = g‚àí1g2 = h‚àí1a‚àí1ah‚Ä≤ = h‚àí1h‚Ä≤ ‚ààH,
and this is a contradiction.
(ii) 13 It sufÔ¨Åces to prove that if h ‚ààH, then the conjugate ghg‚àí1 ‚ààH for every g ‚ààG.
Since H has index 2, there are exactly two cosets, namely, H and aH, where a /‚ààH. Now,
either g ‚ààH or g ‚ààaH. If g ‚ààH, then ghg‚àí1 ‚ààH, because H is a subgroup. In
the second case, write g = ax, where x ‚ààH. Then ghg‚àí1 = a(xhx‚àí1)a‚àí1 = ah‚Ä≤a‚àí1,
where h‚Ä≤ = xhx‚àí1 ‚ààH (for h‚Ä≤ is a product of three elements in H). If ghg‚àí1 /‚ààH, then
ghg‚àí1 = ah‚Ä≤a‚àí1 ‚ààaH; that is, ah‚Ä≤a‚àí1 = ay for some y ‚ààH. Canceling a, we have
h‚Ä≤a‚àí1 = y, which gives the contradiction a = y‚àí1h‚Ä≤ ‚ààH. Therefore, if h ‚ààH, every
conjugate of h also lies in H; that is, H is a normal subgroup of G.
‚Ä¢
13Another proof of this is given in Exercise 2.50 on page 81.

Sec. 2.5
Homomorphisms
79
DeÔ¨Ånition.
The group of quaternions14 is the group Q of order 8 consisting of the fol-
lowing matrices in GL(2, C):
Q = { I, A, A2, A3, B, B A, B A2, B A3 },
where I is the identity matrix,
A =
 0
1
‚àí1
0

, and B =
0
i
i
0

.
The element A ‚ààQ has order 4, so that ‚ü®A‚ü©is a subgroup of order 4 and hence of
index 2; the other coset is B ‚ü®A‚ü©= {B, B A, B A2, B A3 }. Thus, every element in Q has an
expression of the form Bi A j, where i = 0, 1 and j = 0, 1, 2, 3.
Example 2.63.
In Exercise 2.59 on page 81, the reader will check that Q is a nonabelian group of order 8
having exactly one element of order 2, and hence only one subgroup of order 2, namely,
‚ü®‚àíI‚ü©. We claim that every subgroup of Q is normal. Lagrange's theorem says that every
subgroup of Q has order a divisor of 8, and so the only possible orders of subgroups are
1, 2, 4, or 8. Clearly, the subgroup {I} and the subgroup of order 8 (namely, Q itself) are
normal subgroups. By Proposition 2.62(ii), any subgroup of order 4 must be normal, for it
has index 2. Finally, the subgroup ‚ü®‚àíI‚ü©is normal, for it is the center, Z(Q).
‚óÄ
Example 2.63 shows that Q is a nonabelian group that is like abelian groups in that
every subgroup is normal. This is essentially the only such example. A nonabelian Ô¨Ånite
group is called hamiltonian if every subgroup is normal; every hamiltonian group has the
form Q √ó A, where A is an abelian group with no elements of order 4 (direct products
will be introduced in the next section). A proof of this result can be found in Robinson, A
Course in the Theory of Groups, page 139.
Lagrange's theorem states that the order of a subgroup of a Ô¨Ånite group G must be a
divisor of |G|. This suggests the question, given a divisor d of |G|, whether G must contain
a subgroup of order d. The next result shows that there need not be such a subgroup.
Proposition 2.64.
The alternating group A4 is a group of order 12 having no subgroup
of order 6.
Proof.
First, |A4| = 12, by Exercise 2.12 on page 50. If A4 contains a subgroup H of
order 6, then H has index 2, and so Œ±2 ‚ààH for every Œ± ‚ààA4, by Corollary 2.62(i). If Œ± is
a 3-cycle, however, then Œ± has order 3, so that Œ± = Œ±4 = (Œ±2)2. Thus, H contains every
3-cycle. This is a contradiction, for there are 8 3-cycles in A4.
‚Ä¢
14W. R. Hamilton invented a system having two operations, addition and multiplication, that he called quater-
nions, for it was four-dimensional. The group of quaternions consists of 8 special elements in that system; see
Exercise 2.60 on page 82.

80
Groups I
Ch. 2
EXERCISES
2.39 Show that if there is a bijection f : X ‚ÜíY (that is, if X and Y have the same number of
elements), then there is an isomorphism œï : SX ‚ÜíSY .
Hint. If Œ± ‚ààSX, deÔ¨Åne œï(Œ±) = f ‚ó¶Œ± ‚ó¶f ‚àí1. In particular, show that if |X| = 3, then œï takes
a cycle involving symbols 1, 2, 3 into a cycle involving a, b, c, as in Example 2.51.
2.40
(i) Show that the composite of homomorphisms is itself a homomorphism.
(ii) Show that the inverse of an isomorphism is an isomorphism.
(iii) Show that two groups that are isomorphic to a third group are isomorphic to each other.
(iv) Prove that isomorphism is an equivalence relation on any set of groups.
2.41 Prove that a group G is abelian if and only if the function f : G ‚ÜíG, given by f (a) = a‚àí1,
is a homomorphism.
2.42 This exercise gives some invariants of a group G. Let f : G ‚ÜíH be an isomorphism.
(i) Prove that if a ‚ààG has inÔ¨Ånite order, then so does f (a), and if a has Ô¨Ånite order n, then
so does f (a). Conclude that if G has an element of some order n and H does not, then
G Ã∏‚àº= H.
(ii) Prove that if G ‚àº= H, then, for every divisor d of |G|, both G and H have the same
number of elements of order d.
2.43 Prove that A4 and D12 are nonisomorphic groups of order 12.
2.44
(i) Find a subgroup H of S4 with H Ã∏= V and H ‚àº= V.
(ii) Prove that the subgroup H in part (i) is not a normal subgroup.
2.45 Show that every group G with |G| < 6 is abelian.
2.46 Let G = { f : R ‚ÜíR : f (x) = ax + b, where a Ã∏= 0}. Prove that G is a group under
composition that is isomorphic to the subgroup of GL(2, R) consisting of all matrices of the
form
a
b
0
1

.
2.47
(i) If f : G ‚ÜíH is a homomorphism and x ‚ààG has order k, prove that f (x) ‚ààH has
order m, where m | k.
(ii) If f : G ‚ÜíH is a homomorphism and if (|G|, |H|) = 1, prove that f (x) = 1 for all
x ‚ààG.
2.48
(i) Prove that
cos Œ∏
‚àísin Œ∏
sin Œ∏
cos Œ∏
k
=
cos kŒ∏
‚àísin kŒ∏
sin kŒ∏
cos kŒ∏

.
Hint. Use induction on k ‚â•1.
(ii) Prove that the special orthogonal group SO(2, R), consisting of all 2 √ó 2 orthogonal
matrices of determinant 1, is isomorphic to the circle group S1.
Hint. Consider œï :
cos Œ±
‚àísin Œ±
sin Œ±
cos Œ±

‚Üí(cos Œ±, sin Œ±).
2.49 Let G be the additive group of all polynomials in x with coefÔ¨Åcients in Z, and let H be the
multiplicative group of all positive rationals. Prove that G ‚àº= H.
Hint. List the prime numbers p0 = 2, p1 = 3, p2 = 5, . . . , and deÔ¨Åne
œï(e0 + e1x + e2x2 + ¬∑ ¬∑ ¬∑ + enxn) = pe0
0 ¬∑ ¬∑ ¬∑ pen
n .

Sec. 2.5
Homomorphisms
81
2.50
(i) Show that if H is a subgroup with bH = Hb = {hb : h ‚ààH} for every b ‚ààG, then H
must be a normal subgroup.
(ii) Use part (i) to give a second proof of Proposition 2.62(ii): If H ‚â§G has index 2, then
H ‚úÅG.
Hint. If a /‚ààH, then aH = H‚Ä≤ = Ha, where H‚Ä≤ is the complement of H.
2.51
(i) Prove that if Œ± ‚ààSn, then Œ± and Œ±‚àí1 are conjugate.
(ii) Give an example of a group G containing an element x for which x and x‚àí1 are not
conjugate.
2.52 Prove that the intersection of any family of normal subgroups of a group G is itself a normal
subgroup of G.
2.53 DeÔ¨Åne W = ‚ü®(1 2)(3 4)‚ü©, the cyclic subgroup of S4 generated by (1 2)(3 4). Show that W is
a normal subgroup of V, but that W is not a normal subgroup of S4. Conclude that normality
is not transitive: W ‚úÅV and V ‚úÅG do not imply W ‚úÅG.
2.54 Let G be a Ô¨Ånite abelian group written multiplicatively. Prove that if |G| is odd, then every
x ‚ààG has a unique square root; that is, there exists exactly one g ‚ààG with g2 = x.
Hint. Show that squaring is an injective function G ‚ÜíG, and use Exercise 1.58 on page 36.
2.55 Give an example of a group G, a subgroup H ‚â§G, and an element g ‚ààG with [G : H] = 3
and g3 /‚ààH.
Hint. Take G = S3, H = ‚ü®(1 2)‚ü©, and g = (2 3).
2.56 Show that the center of GL(2, R) is the set of all scalar matrices aI with a Ã∏= 0.
Hint.
Show that if A is a matrix that is not a scalar matrix, then there is some nonsingular
matrix that does not commute with A. (The generalization of this to n √ó n matrices is true.)
2.57 Let Œ∂ = e2œÄi/n be a primitive nth root of unity, and deÔ¨Åne
A =
Œ∂
0
0
Œ∂ ‚àí1

and B =
0
1
1
0

.
(i) Prove that A has order n and that B has order 2.
(ii) Prove that B AB = A‚àí1.
(iii) Prove that the matrices of the form Ai and B Ai, for 0 ‚â§i < n, form a multiplicative
subgroup G ‚â§GL(2, C).
Hint. Consider cases Ai A j, Ai B A j, B Ai A j, and (B Ai)(B A j).
(iv) Prove that each matrix in G has a unique expression of the form Bi A j, where i = 0, 1
and 0 ‚â§j < n. Conclude that |G| = 2n.
(v) Prove that G ‚àº= D2n.
Hint. DeÔ¨Åne a function G ‚ÜíD2n using the unique expression of elements in G in the
form Bi A j.
2.58
(i) Prove that every subgroup of Q √ó I2 is normal.
(ii) Prove that there exists a nonnormal subgroup of Q √ó I4.
2.59 Recall that the group of quaternions Q consists of the 8 matrices in GL(2, C)
Q = { I, A, A2, A3, B, B A, B A2, B A3 },

82
Groups I
Ch. 2
where
A =
 0
1
‚àí1
0

and B =
0
i
i
0

.
(i) Prove that ‚àíI is the only element in Q of order 2, and that all other elements M Ã∏= I
satisfy M2 = ‚àíI.
(ii) Prove that Q is a nonabelian group with operation matrix multiplication.
Hint. Note that A2 = ‚àíI = B2.
(iii) Prove that Q has a unique subgroup of order 2, and it is the center of Q.
2.60 Assume that there is a group G of order 8 whose elements
¬±1, ¬±i, ¬±j, ¬±k
satisfy
i2 = j2 = k2 = ‚àí1,
ij = k,
jk = i,
ki = j,
ij = ‚àíji,
ik = ‚àíki,
jk = ‚àíkj.
Prove that G ‚àº= Q and, conversely, that Q is such a group.
2.61 Prove that the quaternions Q and the dihedral group D8 are nonisomorphic groups of order 8.
Hint. Use Exercise 2.42 on page 80.
2.62 Prove that A4 is the only subgroup of S4 of order 12.
Hint. Use Proposition 2.62(ii).
2.63 Prove that the symmetry group (œÄn), where œÄn is a regular polygon with n vertices, is
isomorphic to a subgroup of Sn.
Hint. The vertices X = {v1, . . . , vn} of œÄn are permuted by every motion œÉ ‚àà(œÄn).
2.64
(i) For every group G, show that the function ! : G ‚ÜíAut(G), given by g ‚ÜíŒ≥g (where
Œ≥x is conjugation by g), is a homomorphism.
(ii) Prove that ker ! = Z(G) and im ! = Inn(G); conclude that Inn(G) is a subgroup of
Aut(G).
(iii) Prove that Inn(G) ‚úÅAut(G).
2.6 QUOTIENT GROUPS
The construction of the additive group of integers modulo m is the prototype of a more
general way of building new groups from given groups, called quotient groups. The homo-
morphism œÄ : Z ‚ÜíIm, deÔ¨Åned by œÄ : a ‚Üí[a], is surjective, so that Im is equal to im œÄ.
Thus, every element of Im has the form œÄ(a) for some a ‚ààZ, and œÄ(a)+œÄ(b) = œÄ(a+b).
This description of the additive group Im in terms of the additive group Z can be general-
ized to arbitrary, not necessarily abelian, groups. Suppose that f : G ‚ÜíH is a surjective
homomorphism between groups G and H. Since f is surjective, each element of H has the
form f (a) for some a ‚ààG, and the operation in H is given by f (a) f (b) = f (ab), where

Sec. 2.6
Quotient Groups
83
a, b ‚ààG. Now K = ker f is a normal subgroup of G, and we are going to reconstruct
H = im f (as well as a surjective homomorphism œÄ : G ‚ÜíH) from G and K alone.
We begin by introducing an operation on the set
S(G)
of all nonempty subsets of a group G. If X, Y ‚ààS(G), deÔ¨Åne
XY = {xy : x ‚ààX and y ‚ààY}.
This multiplication is associative: X(Y Z) is the set of all x(yz), where x ‚ààX, y ‚ààY, and
z ‚ààZ, (XY)Z is the set of all such (xy)z, and these are the same because of associativity
in G.
An instance of this multiplication is the product of a one-point subset {a} and a subgroup
K ‚â§G, which is the coset aK.
As a second example, we show that if H is any subgroup of G, then
HH = H.
If h, h‚Ä≤ ‚ààH, then hh‚Ä≤ ‚ààH, because subgroups are closed under multiplication, and so
HH ‚äÜH. For the reverse inclusion, if h ‚ààH, then h = h1 ‚ààHH (because 1 ‚ààH), and
so H ‚äÜHH.
It is possible for two subsets X and Y in S(G) to commute even though their constituent
elements do not commute. For example, let G = S3 and K = ‚ü®(1 2 3)‚ü©. Now (1 2) does
not commute with (1 2 3) ‚ààK, but we claim that (1 2)K = K(1 2). In fact, here is the
converse of Exercise 2.50 on page 81.
Lemma 2.65.
A subgroup K of a group G is a normal subgroup if and only if
gK = Kg
for every g ‚ààG. Thus, every right coset of a normal subgroup is also a left coset.
Proof.
Let gk ‚ààgK. Since K is normal, gkg‚àí1 ‚ààK, say gkg‚àí1 = k‚Ä≤ ‚ààK, so that
gk = (gkg‚àí1)g = k‚Ä≤g ‚ààKg, and so gK ‚äÜKg. For the reverse inclusion, let kg ‚ààKg.
Since K is normal, (g‚àí1)k(g‚àí1)‚àí1 = g‚àí1kg ‚ààK, say g‚àí1kg = k‚Ä≤‚Ä≤ ‚ààK. Hence,
kg = g(g‚àí1kg) = gk‚Ä≤‚Ä≤ ‚ààgK and Kg ‚äÜgK. Therefore, gK = Kg when K ‚úÅG.
Conversely, if gK = Kg for every g ‚ààG, then for each k ‚ààK, there is k‚Ä≤ ‚ààK with
gk = k‚Ä≤g; that is, gkg‚àí1 ‚ààK for all g ‚ààG, and so K ‚úÅG.
‚Ä¢
A natural question is whether HK is a subgroup when both H and K are subgroups. In
general, HK need not be a subgroup. For example, let G = S3, let H = ‚ü®(1 2)‚ü©, and let
K = ‚ü®(1 3)‚ü©. Then
HK = {(1), (1 2), (1 3), (1 3 2)}
is not a subgroup lest we contradict Lagrange's theorem, for 4 ‚à§6.

84
Groups I
Ch. 2
Proposition 2.66.
(i) If H and K are subgroups of a group G, and if one of them is a normal subgroup,
then HK is a subgroup of G; moreover, HK = KH in this case.
(ii) If both H and K are normal subgroups, then HK is a normal subgroup.
Remark.
Exercise 2.72 on page 95 shows that if H and K are subgroups of a group G,
then H K is a subgroup if and only if H K = K H.
‚óÄ
Proof.
(i) Assume Ô¨Årst that K ‚úÅG. We claim that HK = KH. If hk ‚ààHK, then
k‚Ä≤ = hkh‚àí1 ‚ààK, because K ‚úÅG, and
hk = hkh‚àí1h = k‚Ä≤h ‚ààKH.
Hence, HK ‚äÜKH. For the reverse inclusion, write kh = hh‚àí1kh = hk‚Ä≤‚Ä≤ ‚ààHK. (Note that
the same argument shows that HK = KH if H ‚úÅG.)
We now show that HK is a subgroup. Since 1 ‚ààH and 1 ‚ààK, we have 1 = 1 ¬∑ 1 ‚ààHK;
if hk ‚ààHK, then (hk)‚àí1 = k‚àí1h‚àí1 ‚ààKH = HK; if hk, h1k1 ‚ààHK, then hkh1k1 ‚àà
H K H K = H H K K = H K.
(ii) If g ‚ààG, then Lemma 2.65 gives gH K = HgK = H Kg, and the same lemma now
gives H K ‚úÅG.
‚Ä¢
Here is a fundamental construction of a new group from a given group.
Theorem 2.67.
Let G/K denote the family of all the left cosets of a subgroup K of G. If
K is a normal subgroup, then
aKbK = abK
for all a, b ‚ààG, and G/K is a group under this operation.
Remark.
The group G/K is called the quotient group G mod K; when G is Ô¨Ånite, its
order |G/K| is the index [G : K] = |G|/|K| (presumably, this is the reason why quotient
groups are so called).
‚óÄ
Proof.
The product of two cosets (aK)(bK) can also be viewed as the product of 4 ele-
ments in S(G). Hence, associativity in S(G) gives
(aK)(bK) = a(Kb)K = a(bK)K = abK K = abK,
for normality of K gives Kb = bK for all b ‚ààK, by Lemma 2.65, while KK = K
because K is a subgroup. Thus, the product of two cosets of K is again a coset of K, and
so an operation on G/K has been deÔ¨Åned. Because multiplication in S(G) is associative,
equality X(Y Z) = (XY)Z holds, in particular, when X, Y, and Z are cosets of K, so that
the operation on G/K is associative. The identity is the coset K = 1K, for (1K)(bK) =
1bK = bK = b1K = (bK)(1K), and the inverse of aK is a‚àí1K, for (a‚àí1K)(aK) =
a‚àí1aK = K = aa‚àí1K = (aK)(a‚àí1K). Therefore, G/K is a group.
‚Ä¢

Sec. 2.6
Quotient Groups
85
It is important to remember what we have just proved: The product aKbK = abK
in G/K does not depend on the particular representatives of the cosets, and the law of
substitution holds: If aK = a‚Ä≤K and bK = b‚Ä≤K, then
aKbK = abK = a‚Ä≤b‚Ä≤K = a‚Ä≤Kb‚Ä≤K.
Example 2.68.
We show that the quotient group G/K is precisely Im when G is the additive group Z and
K = ‚ü®m‚ü©, the (cyclic) subgroup of all the multiples of a positive integer m. Since Z is
abelian, ‚ü®m‚ü©is necessarily a normal subgroup. The sets Z/ ‚ü®m‚ü©and Im coincide because
they are comprised of the same elements: The coset a + ‚ü®m‚ü©is the congruence class [a]:
a + ‚ü®m‚ü©= {a + km : k ‚ààZ} = [a].
The operations also coincide: Addition in Z/ ‚ü®m‚ü©is given by
(a + ‚ü®m‚ü©) + (b + ‚ü®m‚ü©) = (a + b) + ‚ü®m‚ü©;
since a + ‚ü®m‚ü©= [a], this last equation is just [a] + [b] = [a + b], which is the sum in Im.
Therefore, Im is equal to the quotient group Z/ ‚ü®m‚ü©.
‚óÄ
There is another way to regard quotient groups. After all, we saw, in the proof of
Lemma 2.40, that the relation ‚â°on G, deÔ¨Åned by a ‚â°b if b‚àí1a ‚ààK, is an equivalence
relation whose equivalence classes are the cosets of K. Thus, we can view the elements of
G/K as equivalence classes, with the multiplication aKbK = abK being independent of
the choice of representative.
We remind the reader of Lemma 2.40(i): If K is a subgroup of G, then two cosets aK
and bK are equal if and only if b‚àí1a ‚ààK. In particular, if b = 1, then aK = K if and
only if a ‚ààK.
We can now prove the converse of Proposition 2.56(ii).
Corollary 2.69.
Every normal subgroup K ‚úÅG is the kernel of some homomorphism.
Proof.
DeÔ¨Åne the natural map œÄ : G ‚ÜíG/K by œÄ(a) = aK. With this notation, the
formula aKbK = abK can be rewritten as œÄ(a)œÄ(b) = œÄ(ab); thus, œÄ is a (surjective)
homomorphism. Since K is the identity element in G/K,
ker œÄ = {a ‚ààG : œÄ(a) = K} = {a ‚ààG : aK = K} = K,
by Lemma 2.40(i).
‚Ä¢
The next theorem shows that every homomorphism gives rise to an isomorphism and
that quotient groups are merely constructions of homomorphic images. E. Noether (1882-
1935) emphasized the fundamental importance of this fact.
Theorem 2.70 (First Isomorphism Theorem).
If f : G ‚ÜíH is a homomorphism, then
ker f ‚úÅG
and
G/ ker f ‚àº= im f.
In more detail, if ker f = K and œï : G/K ‚Üíim f ‚â§H is given by œï : aK ‚Üíf (a), then
œï is an isomorphism.

86
Groups I
Ch. 2
Remark.
The following diagram describes the proof of the Ô¨Årst isomorphism theorem,
where œÄ : G ‚ÜíG/K is the natural map œÄ : a ‚ÜíaK.
G
f

œÄ








H
G/K
œï








‚óÄ
Proof.
We have already seen, in Proposition 2.56(ii), that K = ker f is a normal sub-
group of G. Now œï is well-deÔ¨Åned: If aK = bK, then a = bk for some k ‚ààK, and so
f (a) = f (bk) = f (b) f (k) = f (b), because f (k) = 1.
Let us now see that œï is a homomorphism. Since f is a homomorphism and œï(aK) =
f (a),
œï(aKbK) = œï(abK) = f (ab) = f (a) f (b) = œï(aK)œï(bK).
It is clear that im œï ‚â§im f . For the reverse inclusion, note that if y ‚ààim f , then
y = f (a) for some a ‚ààG, and so y = f (a) = œï(aK). Thus, œï is surjective.
Finally, we show that œï is injective. If œï(aK) = œï(bK), then f (a) = f (b). Hence,
1 = f (b)‚àí1 f (a) = f (b‚àí1a), so that b‚àí1a ‚ààker f = K. Therefore, aK = bK,
by Lemma 2.40(i), and so œï is injective. We have proved that œï : G/K ‚Üíim f is an
isomorphism.
‚Ä¢
Given any homomorphism f : G ‚ÜíH, we should immediately ask for its kernel and
image; the Ô¨Årst isomorphism theorem will then provide an isomorphism G/ ker f ‚àº= im f .
Since there is no signiÔ¨Åcant difference between isomorphic groups, the Ô¨Årst isomorphism
theorem also says that there is no signiÔ¨Åcant difference between quotient groups and ho-
momorphic images.
Example 2.71.
Let us revisit Example 2.53, which showed that any two cyclic groups of order m are
isomorphic. Let G = ‚ü®a‚ü©be a cyclic group of order m. DeÔ¨Åne a function f : Z ‚ÜíG by
f (n) = an for all n ‚ààZ. Now f is easily seen to be a homomorphism; it is surjective
(because a is a generator of G), while ker f = {n ‚ààZ : an = 1} = ‚ü®m‚ü©, by Theorem 2.24.
The Ô¨Årst isomorphism theorem gives an isomorphism Z/ ‚ü®m‚ü©‚àº= G. We have shown that
every cyclic group of order m is isomorphic to Z/ ‚ü®m‚ü©, and hence that any two cyclic groups
of order m are isomorphic to each other. Of course, Example 2.68 shows that Z/ ‚ü®m‚ü©= Im,
so that every cyclic group of order m is isomorphic to Im.
We point out that any two inÔ¨Ånite cyclic groups are isomorphic to Z; the reader should
have no difÔ¨Åculty proving this.
‚óÄ
Example 2.72.
What is the quotient group R/Z? DeÔ¨Åne f : R ‚ÜíS1, where S1 is the circle group, by
f : x ‚Üíe2œÄix.

Sec. 2.6
Quotient Groups
87
Now f is a homomorphism; that is, f (x + y) = f (x) f (y), by the addition formulas
for sine and cosine. The map f is surjective, and ker f consists of all x ‚ààR for which
e2œÄix = cos 2œÄx + i sin 2œÄx = 1; that is, cos 2œÄx = 1 and sin 2œÄx = 0. But cos 2œÄx = 1
forces x to be an integer; since 1 ‚ààker f , we have ker f = Z. The Ô¨Årst isomorphism
theorem now gives
R/Z ‚àº= S1.
This is the group-theoretic version of Example 1.55(i).
‚óÄ
Here is a useful counting result.
Proposition 2.73 (Product Formula).
If H and K are subgroups of a Ô¨Ånite group G,
then
|HK||H ‚à©K| = |H||K|,
where HK = {hk : h ‚ààH and k ‚ààK}.
Remark.
The subset HK need not be a subgroup of G; however, Proposition 2.66 shows
that if either H ‚úÅG or K ‚úÅG, then HK is a subgroup (see also Exercise 2.72 on page 95).
‚óÄ
Proof.
DeÔ¨Åne a function f : H√óK ‚ÜíHK by f : (h, k) ‚Üíhk. Clearly, f is a surjection.
It sufÔ¨Åces to show, for every x ‚ààHK, that | f ‚àí1(x)| = |H ‚à©K|, where f ‚àí1(x) = {(h, k) ‚àà
H √ó K : hk = x}, [because H √ó K is the disjoint union !
x‚ààHK f ‚àí1(x)].
We claim that if x = hk, then
f ‚àí1(x) = {(hd, d‚àí1k) : d ‚ààH ‚à©K}.
Each (hd, d‚àí1k) ‚ààf ‚àí1(x), for f (hd, d‚àí1k) = hdd‚àí1k = hk = x. For the reverse
inclusion, let (h‚Ä≤, k‚Ä≤) ‚ààf ‚àí1(x), so that h‚Ä≤k‚Ä≤ = hk. Then h‚àí1h‚Ä≤ = kk‚Ä≤‚àí1 ‚ààH ‚à©K; call this
element d. Then h‚Ä≤ = hd and k‚Ä≤ = d‚àí1k, and so (h‚Ä≤, k‚Ä≤) lies in the right side. Therefore,
| f ‚àí1(x)| = |{(hd, d‚àí1k) : d ‚ààH ‚à©K}| = |H ‚à©K|,
because d ‚Üí(hd, d‚àí1k) is a bijection.
‚Ä¢
The next two results are consequences of the Ô¨Årst isomorphism theorem.
Theorem 2.74 (Second Isomorphism Theorem).
If H and K are subgroups of a group
G with H ‚úÅG, then HK is a subgroup, H ‚à©K ‚úÅK, and
K/(H ‚à©K) ‚àº= HK/H.
Proof.
Since H ‚úÅG, Proposition 2.66 shows that HK is a subgroup. Normality of H in
HK follows from a more general fact: If H ‚â§S ‚â§G and if H is normal in G, then H
is normal in S (if ghg‚àí1 ‚ààH for every g ‚ààG, then, in particular, ghg‚àí1 ‚ààH for every
g ‚ààS).

88
Groups I
Ch. 2
We now show that every coset x H ‚ààHK/H has the form kH for some k ‚ààK. Of
course, x H = hkH, where h ‚ààH and k ‚ààK. But hk = kk‚àí1hk = kh‚Ä≤ for some
h‚Ä≤ ‚ààH, so that hkH = kh‚Ä≤H = kH. It follows that the function f : K ‚ÜíHK/H, given
by f : k ‚ÜíkH, is surjective. Moreover, f is a homomorphism, for it is the restriction
of the natural map œÄ : G ‚ÜíG/H. Since ker œÄ = H, it follows that ker f = H ‚à©K,
and so H ‚à©K is a normal subgroup of K. The Ô¨Årst isomorphism theorem now gives
K/(H ‚à©K) ‚àº= HK/H.
‚Ä¢
The second isomorphism theorem gives the product formula in the special case when
one of the subgroups is normal: If K/(H ‚à©K) ‚àº= H K/H, then |K/(H ‚à©K)| = |H K/H|,
and so |H K||H ‚à©K| = |H||K|.
Theorem 2.75 (Third Isomorphism Theorem).
If H and K are normal subgroups of
a group G with K ‚â§H, then H/K ‚úÅG/K and
(G/K)/(H/K) ‚àº= G/H.
Proof.
DeÔ¨Åne f : G/K ‚ÜíG/H by f : aK ‚ÜíaH. Note that f is a (well-deÔ¨Åned)
function, for if a‚Ä≤ ‚ààG and a‚Ä≤K = aK, then a‚àí1a‚Ä≤ ‚ààK ‚â§H, and so aH = a‚Ä≤H. It is
easy to see that f is a surjective homomorphism.
Now ker f = H/K, for aH = H if and only if a ‚ààH, and so H/K is a normal
subgroup of G/K. Since f is surjective, the Ô¨Årst isomorphism theorem gives
(G/K)/(H/K) ‚àº= G/H.
‚Ä¢
The third isomorphism theorem is easy to remember: In the fraction (G/K)/(H/K),
the K's can be canceled. We can better appreciate the Ô¨Årst isomorphism theorem after
having proved the third one. The quotient group (G/K)/(H/K) consists of cosets (of
H/K) whose representatives are themselves cosets (of G/K). A direct proof of the third
isomorphism theorem could be nasty.
The next result, which can be regarded as a fourth isomorphism theorem, describes the
subgroups of a quotient group G/K.
Proposition 2.76 (Correspondence Theorem).
Let G be a group, let K ‚úÅG, and let
œÄ : G ‚ÜíG/K be the natural map. Then
S ‚ÜíœÄ(S) = S/K
is a bijection between Sub(G; K), the family of all those subgroups S of G that contain K,
and Sub(G/K), the family of all the subgroups of G/K. If we denote S/K by S‚àó, then
T ‚â§S ‚â§G if and only if
T ‚àó‚â§S‚àó, in which case [S : T ] = [S‚àó: T ‚àó],
and
T ‚úÅS
if and only if
T ‚àó‚úÅS‚àó, in which case S/T ‚àº= S‚àó/T ‚àó.

Sec. 2.6
Quotient Groups
89
Remark.
The following diagram is a way to remember this theorem.
G















S














G/K
T














S/K = S‚àó
K
















T/K = T ‚àó
{1}
‚óÄ
Proof.
DeÔ¨Åne : Sub(G; K) ‚ÜíSub(G/K) by : S ‚ÜíS/K (it is routine to check that
if S is subgroup of G containing K, then S/K is a subgroup of G/K).
To see that  is injective, we begin by showing that if K ‚â§S ‚â§G, then œÄ‚àí1œÄ(S) = S.
As always, S ‚äÜœÄ‚àí1œÄ(S), by Proposition 1.50(iv). For the reverse inclusion, let a ‚àà
œÄ‚àí1œÄ(S), so that œÄ(a) = œÄ(s) for some s ‚ààS. It follows that as‚àí1 ‚ààker œÄ = K, so that
a = sk for some k ‚ààK. But K ‚â§S, and so a = sk ‚ààS.
Assume now that œÄ(S) = œÄ(S‚Ä≤), where S and S‚Ä≤ are subgroups of G containing K.
Then œÄ‚àí1œÄ(S) = œÄ‚àí1œÄ(S‚Ä≤), and so S = S‚Ä≤ as we have just proved in the preceding
paragraph; hence,  is injective.
To see that  is surjective, let U be a subgroup of G/K. Now œÄ‚àí1(U) is a subgroup of
G containing K = œÄ‚àí1({1}), and œÄ(œÄ‚àí1(U)) = U, by Proposition 1.50(ii).
Proposition 1.50(i) shows that T ‚â§S ‚â§G implies T/K = œÄ(T ) ‚â§œÄ(S) = S/K.
Conversely, assume that T/K ‚â§S/K. If t ‚ààT , then t K ‚ààT/K ‚â§S/K and so t K = sK
for some s ‚ààS. Hence, t = sk for some k ‚ààK ‚â§S, and so t ‚ààS.
To prove that [S : T ] = [S‚àó: T ‚àó], it sufÔ¨Åces to show that there is a bijection from the
family of all cosets of the form sT , where s ‚ààS, and the family of all cosets of the form
s‚àóT ‚àó, where s‚àó‚ààS‚àó, and the reader may check that sT ‚ÜíœÄ(s)T ‚àóis such a bijection.
When G is Ô¨Ånite, we may prove [S : T ] = [S‚àó: T ‚àó] as follows:
[S‚àó: T ‚àó] = |S‚àó|/|T ‚àó|
= |S/K|/|T/K|
= (|S|/|K|) / (|T |/|K|)
= |S|/|T |
= [S : T ].

90
Groups I
Ch. 2
If T ‚úÅS, then T/K ‚úÅS/K and (S/K)/(T/K) ‚àº= S/T , by the third isomorphism theorem;
that is, S‚àó/T ‚àó‚àº= S/T . It remains to show that if T ‚àó‚úÅS‚àó, then T ‚úÅS; that is, if t ‚ààT and
s ‚ààS, then sts‚àí1 ‚ààT . Now
œÄ(sts‚àí1) = œÄ(s)œÄ(t)œÄ(s)‚àí1 ‚ààœÄ(s)T ‚àóœÄ(s)‚àí1 = T ‚àó,
so that sts‚àí1 ‚ààœÄ‚àí1(T ‚àó) = T .
‚Ä¢
When dealing with quotient groups, we usually say, without mentioning the correspon-
dence theorem explicitly, that every subgroup of G/K has the form S/K for a unique
subgroup S ‚â§G containing K.
Example 2.77.
Let G = ‚ü®a‚ü©be a cyclic group of order 30. If œÄ : Z ‚ÜíG is deÔ¨Åned by œÄ(n) = an, then
ker œÄ = ‚ü®30‚ü©. The subgroups ‚ü®30‚ü©‚â§‚ü®15‚ü©‚â§‚ü®5‚ü©‚â§Z correspond to the subgroups
{1} = ‚ü®a30‚ü©‚â§‚ü®a15‚ü©‚â§‚ü®a5‚ü©‚â§‚ü®a‚ü©.
Moreover, the quotient groups are
‚ü®a15‚ü©
‚ü®a30‚ü©
‚àº= ‚ü®15‚ü©
‚ü®30‚ü©
‚àº= I2,
‚ü®a5‚ü©
‚ü®a15‚ü©
‚àº= ‚ü®5‚ü©
‚ü®15‚ü©
‚àº= I3,
and
‚ü®a‚ü©
‚ü®a5‚ü©
‚àº= Z
‚ü®5‚ü©
‚àº= I5.
‚óÄ
Proposition 2.78.
If G is a Ô¨Ånite abelian group and d is a divisor of |G|, then G contains
a subgroup of order d.
Proof.
We prove the result by induction on n = |G| for a prime divisor p of |G|. The
base step n = 1 is true, for there are no prime divisors of 1. For the inductive step, choose
a ‚ààG of order k > 1. If p | k, say k = p‚Ñì, then Exercise 2.23 on page 62 says that a‚Ñì
has order p. If p ‚à§k, consider the cyclic subgroup H = ‚ü®a‚ü©. Now H ‚úÅG, because G is
abelian, and so the quotient group G/H exists. Note that |G/H| = n/k is divisible by p,
and so the inductive hypothesis gives an element bH ‚ààG/H of order p. If b has order m,
then Exercise 2.47(i) on page 80 gives p | m. We have returned to the Ô¨Årst case.
Let d be any divisor of |G|, and let p be a prime divisor of d. We have just seen that
there is a subgroup S ‚â§G of order p. Now S ‚úÅG, because G is abelian, and G/S is
a group of order n/p. By induction on |G|, G/S has a subgroup H‚àóof order d/p. The
correspondence theorem gives H‚àó= H/S for some subgroup H of G containing S, and
|H| = |H‚àó||S| = d.
‚Ä¢
Here is a construction of a new group from two given groups.
DeÔ¨Ånition.
If H and K are groups, then their direct product, denoted by H √ó K, is the
set of all ordered pairs (h, k) with h ‚ààH and k ‚ààK equipped with the operation
(h, k)(h‚Ä≤, k‚Ä≤) = (hh‚Ä≤, kk‚Ä≤).
It is easy to check that the direct product H √ó K is a group [the identity is (1, 1) and
(h, k)‚àí1 = (h‚àí1, k‚àí1)].
We now apply the Ô¨Årst isomorphism theorem to direct products.

Sec. 2.6
Quotient Groups
91
Proposition 2.79.
Let G and G‚Ä≤ be groups, and let K ‚úÅG and K ‚Ä≤ ‚úÅG‚Ä≤ be normal
subgroups. Then K √ó K ‚Ä≤ ‚úÅG √ó G‚Ä≤, and there is an isomorphism
(G √ó G‚Ä≤)/(K √ó K ‚Ä≤) ‚àº= (G/K) √ó (G‚Ä≤/K ‚Ä≤).
Proof.
Let œÄ : G ‚ÜíG/K and œÄ‚Ä≤ : G‚Ä≤ ‚ÜíG‚Ä≤/K ‚Ä≤ be the natural maps. It is routine to
check that f : G √ó G‚Ä≤ ‚Üí(G/K) √ó (G‚Ä≤/K ‚Ä≤), given by
f : (g, g‚Ä≤) ‚Üí(œÄ(g), œÄ‚Ä≤(g‚Ä≤)) = (gK, g‚Ä≤K ‚Ä≤)
is a surjective homomorphism with ker f = K √ó K ‚Ä≤. The Ô¨Årst isomorphism theorem now
gives the desired isomorphism.
‚Ä¢
Proposition 2.80.
If G is a group containing normal subgroups H and K with H ‚à©K =
{1} and H K = G, then G ‚àº= H √ó K.
Proof.
We show Ô¨Årst that if g ‚ààG, then the factorization g = hk, where h ‚ààH and
k ‚ààK, is unique. If hk = h‚Ä≤k‚Ä≤, then h‚Ä≤‚àí1h = k‚Ä≤k‚àí1 ‚ààH ‚à©K = {1}. Therefore, h‚Ä≤ = h
and k‚Ä≤ = k. We may now deÔ¨Åne a function œï : G ‚ÜíH √ó K by œï(g) = (h, k), where
g = hk, h ‚ààH, and k ‚ààK. To see whether œï is a homomorphism, let g‚Ä≤ = h‚Ä≤k‚Ä≤, so that
gg‚Ä≤ = hkh‚Ä≤k‚Ä≤. Hence, œï(gg‚Ä≤) = œï(hkh‚Ä≤k‚Ä≤), which is not in the proper form for evaluation.
If we knew that if h ‚ààH and k ‚ààK, then hk = kh, then we could continue:
œï(hkh‚Ä≤k‚Ä≤) = œï(hh‚Ä≤kk‚Ä≤)
= (hh‚Ä≤, kk‚Ä≤)
= (h, k)(h‚Ä≤, k‚Ä≤)
= œï(g)œï(g‚Ä≤).
Let h ‚ààH and k ‚ààK. Since K is a normal subgroup, (hkh‚àí1)k‚àí1 ‚ààK; since H is a
normal subgroup, h(kh‚àí1k‚àí1) ‚ààH. But H ‚à©K = {1}, so that hkh‚àí1k‚àí1 = 1 and hk =
kh. Finally, we show that the homomorphism œï is an isomorphism. If (h, k) ‚ààH √ó K,
then the element g ‚ààG deÔ¨Åned by g = hk satisÔ¨Åes œï(g) = (h, k); hence œï is surjective.
If œï(g) = (1, 1), then g = 1, so that ker œï = 1 and œï is injective. Therefore, œï is an
isomorphism.
‚Ä¢
Remark.
We must assume that both subgroups H and K are normal. For example, S3 has
subgroups H = ‚ü®(1 2 3)‚ü©and K = ‚ü®(1 2)‚ü©. Now H ‚úÅS3, H ‚à©K = {1}, and H K = S3,
but S3 Ã∏‚àº= H √ó K (because the direct product is abelian). Of course, K is not a normal
subgroup of S3.
‚óÄ
Theorem 2.81.
If m and n are relatively prime, then
Imn ‚àº= Im √ó In.

92
Groups I
Ch. 2
Proof.
If a ‚ààZ, denote its congruence class in Im by [a]m. The reader can show that the
function f : Z ‚ÜíIm √ó In, given by a ‚Üí([a]m, [a]n), is a homomorphism. We claim
that ker f = ‚ü®mn‚ü©. Clearly, ‚ü®mn‚ü©‚â§ker f . For the reverse inclusion, if a ‚ààker f , then
[a]m = [0]m and [a]n = [0]n; that is, a ‚â°0 mod m and a ‚â°0 mod n; that is, m | a and
n | a. Since m and n are relatively prime, mn | a, and so a ‚àà‚ü®mn‚ü©, that is, ker f ‚â§‚ü®mn‚ü©
and ker f = ‚ü®mn‚ü©. The Ô¨Årst isomorphism theorem now gives Z/ ‚ü®mn‚ü©‚àº= im f ‚â§Im √ó In.
But Z/ ‚ü®mn‚ü©‚àº= Imn has mn elements, as does Im √óIn. We conclude that f is surjective. ‚Ä¢
For example, it follows that I6 ‚àº= I2 √ó I3. Note that there is no isomorphism if m and n
are not relatively prime. For example, I4 Ã∏‚àº= I2 √ó I2, for I4 has an element of order 4 and
the direct product (which is isomorphic to the four-group V) has no such element.
In light of Proposition 2.34, we may say that an element a ‚ààG has order n if ‚ü®a‚ü©‚àº= In.
Theorem 2.81 can now be interpreted as saying that if a and b are commuting elements
having relatively prime orders m and n, then ab has order mn. Let us give a direct proof of
this result.
Proposition 2.82.
Let G be a group, and let a, b ‚ààG be commuting elements of orders
m and n, respectively. If (m, n) = 1, then ab has order mn.
Proof.
Since a and b commute, we have (ab)r = arbr for all r, so that (ab)mn =
amnbmn = 1. It sufÔ¨Åces to prove that if (ab)k = 1, then mn | k. If 1 = (ab)k = akbk,
then ak = b‚àík. Since a has order m, we have 1 = amk = b‚àímk. Since b has order n,
Theorem 2.24 gives n | mk. As (m, n) = 1, however, Corollary 1.11 gives n | k; a similar
argument gives m | k. Finally, Exercise 1.19 on page 13 shows that mn | k. Therefore,
mn ‚â§k, and mn is the order of ab.
‚Ä¢
Corollary 2.83.
If (m, n) = 1, then œÜ(mn) = œÜ(m)œÜ(n), where œÜ is the Euler œÜ-function.
Proof. 15 Theorem 2.81 shows that the function f : Imn ‚ÜíIm √ó In, given by [a] ‚Üí
([a]m, [a]n), is an isomorphism. The result will follow if we prove that f (U(Imn)) =
U(Im) √ó U(In), for then
œÜ(mn) = |U(Imn)| = | f (U(Imn))|
= |U(Im) √ó U(In)| = |U(Im)| ¬∑ |U(In)| = œÜ(m)œÜ(n).
If [a] ‚ààU(Imn), then [a][b] = [1] for some [b] ‚ààImn, and
f ([ab]) = ([ab]m, [ab]n) = ([a]m[b]m, [a]n[b]n)
= ([a]m, [a]n)([b]m, [b]n) = ([1]m, [1]n).
Hence, [1]m = [a]m[b]m and [1]n = [a]n[b]n, so that f ([a]) = ([a]m, [a]n) ‚ààU(Im) √ó
U(In), and f (U(Imn)) ‚äÜU(Im) √ó U(In).
For the reverse inclusion, if f ([c]) = ([c]m, [c]n) ‚ààU(Im)√óU(In), then we must show
that [c] ‚ààU(Imn). There is [d]m ‚ààIm with [c]m[d]m = [1]m, and there is [e]n ‚ààIn with
15See Exercise 3.50 on page 150 for a less cluttered proof.

Sec. 2.6
Quotient Groups
93
[c]n[e]n = [1]n. Since f is surjective, there is b ‚ààZ with ([b]m, [b]n) = ([d]m, [e]n), so
that
f ([1]) = ([1]m, [1]n) = ([c]m[b]m, [c]n[b]n) = f ([c][b]).
Since f is an injection, [1] = [c][b] and [c] ‚ààU(Imn).
‚Ä¢
Corollary 2.84.
(i) If p is a prime, then œÜ(pe) = pe ‚àípe‚àí1 = pe 
1 ‚àí1
p

.
(ii) If n = pe1
1 ¬∑ ¬∑ ¬∑ pet
t is the prime factorization of n, then
œÜ(n) = n

1 ‚àí1
p1

¬∑ ¬∑ ¬∑

1 ‚àí1
pt

.
Sketch of Proof.
Part (i) holds because (k, pe) = 1 if and only if p ‚à§k, while part (ii)
follows from Corollary 2.83.
‚Ä¢
Lemma 2.85.
A cyclic group of order n has a unique subgroup of order d, for each
divisor d of n, and this subgroup is cyclic.
Proof.
Let G = ‚ü®a‚ü©. If n = cd, we show that ac has order d (and so ‚ü®ac‚ü©is a subgroup
of order d). Clearly (ac)d = acd = an = 1; we claim that d is the smallest such power.
If (ac)r = 1, then n | cr [Theorem 2.24]; hence cr = ns = dcs for some integer s, and
r = ds ‚â•d.
To prove uniqueness, assume that ‚ü®x‚ü©is a subgroup of order d (recall that every sub-
group of a cyclic group is cyclic, by Exercise 2.34 on page 72). Now x = am and 1 =
xd = amd; hence md = nk for some integer k. Therefore, x = am = (an/d)k = (ac)k, so
that ‚ü®x‚ü©‚â§‚ü®ac‚ü©. Since both subgroups have the same order d, it follows that ‚ü®x‚ü©= ‚ü®ac‚ü©. ‚Ä¢
DeÔ¨Åne an equivalence relation on a group G by x ‚â°y if ‚ü®x‚ü©= ‚ü®y‚ü©; that is, x and y
are equivalent if they are generators of the same cyclic subgroup. Denote the equivalence
class containing an element x by gen(C), where C = ‚ü®x‚ü©; thus, gen(C) consists of all the
generators of C. As usual, equivalence classes form a partition, and so G is the disjoint
union:
G =

C
gen(C),
where C ranges over all cyclic subgroups of G. In Theorem 2.33(ii), we proved that
|gen(C)| = œÜ(n),
where œÜ is the Euler œÜ-function.
The next theorem will be used later to prove that the multiplicative group I√ó
p is cyclic.
Theorem 2.86.
A group G of order n is cyclic if and only if, for each divisor d of n,
there is at most one cyclic subgroup of order d.

94
Groups I
Ch. 2
Proof.
If G is cyclic, then the result follows from Lemma 2.85. Conversely, write G as a
disjoint union:
G =

C
gen(C).
Hence, n = |G| =  |gen(C)|, where the summation is over all cyclic subgroups C of G:
n =

C
|gen(C)| =

C
œÜ(|C|).
By hypothesis, for any divisor d of n, the group G has at most one cyclic subgroup of order
d. Therefore,
n =

C
|gen(C)| =

C
œÜ(|C|) ‚â§

d|n
œÜ(d) = n,
the last equality being Corollary 1.39. Hence, for every divisor d of n, we must have œÜ(d)
arising as |gen(C)| for some cyclic subgroup C of G of order d. In particular, œÜ(n) arises;
there is a cyclic subgroup of order n, and so G is cyclic.
‚Ä¢
Here is a proof of the abelian case of the preceding theorem (shown to me by D. Leep).
Theorem.
If G is an abelian group of order n having at most one cyclic subgroup of
order p for each prime divisor p of n, then G is cyclic.
Proof.
The proof is by induction on n = |G|, with the base step n = 1 obviously true.
For the inductive step, note Ô¨Årst that the hypothesis is inherited by subgroups of G. We
claim that there is some element x in G whose order is a prime divisor p of |G|. Choose
y ‚ààG with y Ã∏= 1; its order k is a divisor of |G|, by Lagrange's theorem, and so k =
pm for some prime p. By Exercise 2.23 on page 62, the element x = ym has order p.
DeÔ¨Åne Œ∏ : G ‚ÜíG by Œ∏ : g ‚Üíg p (Œ∏ is a homomorphism because G is abelian). Now
x ‚ààker Œ∏, so that | ker Œ∏| ‚â•p. If | ker Œ∏| > p, then there would be more than p elements
g ‚ààG satisfying g p = 1, and this would force more than one subgroup of order p in G.
Therefore, | ker Œ∏| = p. By the Ô¨Årst isomorphism theorem, G/ ker Œ∏ ‚àº= im Œ∏ ‚â§G. Thus,
im Œ∏ is a subgroup of G of order n/p satisfying the inductive hypothesis, so there is an
element z ‚ààim Œ∏ with im Œ∏ = ‚ü®z‚ü©. Moreover, since z ‚ààim Œ∏, there is b ‚ààG with z = bp.
There are now two cases. If p ‚à§n/p, then xz has order p ¬∑ n/p = n, by Proposition 2.82,
and so G = ‚ü®xz‚ü©. If p | n/p, then Exercise 2.24 on page 62 shows that b has order n, and
G = ‚ü®b‚ü©.
‚Ä¢
EXERCISES
2.65 Prove that U(I9) ‚àº= I6 and U(I15) ‚àº= I4 √ó I2.
2.66
(i) Let H and K be groups. Without using the Ô¨Årst isomorphism theorem, prove that H‚àó=
{(h, 1) : h ‚ààH} and K ‚àó= {(1, k) : k ‚ààK} are normal subgroups of H √ó K with

Sec. 2.6
Quotient Groups
95
H ‚àº= H‚àóand K ‚àº= K ‚àó, and f : H ‚Üí(H √ó K)/K ‚àó, deÔ¨Åned by f (h) = (h, 1)K ‚àó, is
an isomorphism.
(ii) Use the Ô¨Årst isomorphism theorem to prove that K ‚àó‚úÅH √ó K and that
(H √ó K)/K ‚àó‚àº= H.
Hint. Consider the function f : H √ó K ‚ÜíH deÔ¨Åned by f : (h, k) ‚Üíh.
2.67
(i) Prove that Aut(V) ‚àº= S3 and that Aut(S3) ‚àº= S3. Conclude that nonisomorphic groups
can have isomorphic automorphism groups.
(ii) Prove that Aut(Z) ‚àº= I2. Conclude that an inÔ¨Ånite group can have a Ô¨Ånite automorphism
group.
2.68 If G is a group for which Aut(G) = {1}, prove that |G| ‚â§2.
2.69 Prove that if G is a group for which G/Z(G) is cyclic, where Z(G) denotes the center of G,
then G is abelian.
Hint.
If G/Z(G) is cyclic, prove that a generator gives an element outside of Z(G) which
commutes with each element of G.
2.70
(i) Prove that Q/Z(Q) ‚àº= V, where Q is the group of quaternions and V is the four-group;
conclude that the quotient of a group by its center can be abelian.
(ii) Prove that Q has no subgroup isomorphic to V. Conclude that the quotient Q/Z(Q) is
not isomorphic to a subgroup of Q.
2.71 Let G be a Ô¨Ånite group with K ‚úÅG. If (|K|, [G : K]) = 1, prove that K is the unique
subgroup of G having order |K|.
Hint. If H ‚â§G and |H| = |K|, what happens to elements of H in G/K?
2.72 If H and K are subgroups of a group G, prove that H K is a subgroup of G if and only if
H K = K H.
Hint. Use the fact that H ‚äÜH K and K ‚äÜH K.
2.73 Let G be a group and regard G √ó G as the direct product of G with itself. If the multiplication
¬µ: G √ó G ‚ÜíG is a group homomorphism, prove that G must be abelian.
2.74 Generalize Theorem 2.81 as follows. Let G be a Ô¨Ånite (additive) abelian group of order mn,
where (m, n) = 1. DeÔ¨Åne
Gm = {g ‚ààG : order (g) | m} and Gn = {h ‚ààG : order (h) | n}.
(i) Prove that Gm and Gn are subgroups with Gm ‚à©Gn = {0}.
(ii) Prove that G = Gm + Gn = {g + h : g ‚ààGm and h ‚ààGn}.
(iii) Prove that G ‚àº= Gm √ó Gn.
2.75 Let G be a Ô¨Ånite group, let p be a prime, and let H be a normal subgroup of G. Prove that if
both |H| and |G/H| are powers of p, then |G| is a power of p.
2.76 If H and K are normal subgroups of a group G with H K = G, prove that
G/(H ‚à©K) ‚àº= (G/H) √ó (G/K).
Hint.
If œï : G ‚Üí(G/H) √ó (G/K) is deÔ¨Åned by x ‚Üí(x H, x K), then ker œï = H ‚à©K;
moreover, we have G = H K, so that

a
aH = H K =

b
bK.

96
Groups I
Ch. 2
DeÔ¨Ånition.
If H1, . . . , Hn are groups, then their direct product
H1 √ó ¬∑ ¬∑ ¬∑ √ó Hn
is the set of all n-tuples (h1, . . . , hn), where hi ‚ààHi for all i, with coordinatewise multiplication:
(h1, . . . , hn)(h‚Ä≤
1, . . . , h‚Ä≤
n) = (h1h‚Ä≤
1, . . . , hnh‚Ä≤
n).
2.77
(i) Generalize Theorem 2.81 by proving that if the prime factorization of an integer m is
m = pe1
1 ¬∑ ¬∑ ¬∑ pen
n , then
Im ‚àº= Ipe1
1 √ó ¬∑ ¬∑ ¬∑ √ó Ipen
n .
(ii) Generalize Corollary 2.83 by proving that if the prime factorization of an integer m is
m = pe1
1 ¬∑ ¬∑ ¬∑ pen
n , then
U(Im) ‚àº= U(Ipe1
1 ) √ó ¬∑ ¬∑ ¬∑ √ó U(Ipen
n ).
2.7 GROUP ACTIONS
Groups of permutations led us to abstract groups; the next result, due to A. Cayley, shows
that abstract groups are not so far removed from permutations.
Theorem 2.87 (Cayley).
Every group G is isomorphic to a subgroup of the symmetric
group SG. In particular, if |G| = n, then G is isomorphic to a subgroup of Sn.
Proof.
For each a ‚ààG, deÔ¨Åne "translation" œÑa : G ‚ÜíG by œÑa(x) = ax for every x ‚ààG
(if a Ã∏= 1, then œÑa is not a homomorphism). For a, b ‚ààG, (œÑa ‚ó¶œÑb)(x) = œÑa(œÑb(x)) =
œÑa(bx) = a(bx) = (ab)x, by associativity, so that
œÑaœÑb = œÑab.
It follows that each œÑa is a bijection, for its inverse is œÑa‚àí1:
œÑaœÑa‚àí1 = œÑaa‚àí1 = œÑ1 = 1G = œÑa‚àí1a,
and so œÑa ‚ààSG.
DeÔ¨Åne œï : G ‚ÜíSG by œï(a) = œÑa. Rewriting,
œï(a)œï(b) = œÑaœÑb = œÑab = œï(ab),
so that œï is a homomorphism. Finally, œï is an injection. If œï(a) = œï(b), then œÑa = œÑb, and
hence œÑa(x) = œÑb(x) for all x ‚ààG; in particular, when x = 1, this gives a = b, as desired.
The last statement follows from Exercise 2.39 on page 80, which says that if X is a set
with |X| = n, then SX ‚àº= Sn.
‚Ä¢
The reader may note, in the proof of Cayley's theorem, that the permutation œÑa is just
the ath row of the multiplication table of G.
To tell the truth, Cayley's theorem itself is only mildly interesting. However, the identi-
cal proof works in a larger setting that is more interesting.

Sec. 2.7
Group Actions
97
Theorem 2.88 (Representation on Cosets).
Let G be a group, and let H be a subgroup
of G having Ô¨Ånite index n. Then there exists a homomorphism œï : G ‚ÜíSn with ker œï ‚â§H.
Proof.
Even though H may not be a normal subgroup, we still denote the family of all
the cosets of H in G by G/H.
For each a ‚ààG, deÔ¨Åne "translation" œÑa : G/H ‚ÜíG/H by œÑa(x H) = ax H for every
x ‚ààG. For a, b ‚ààG,
(œÑa ‚ó¶œÑb)(x H) = œÑa(œÑb(x H)) = œÑa(bx H) = a(bx H) = (ab)x H,
by associativity, so that
œÑaœÑb = œÑab.
It follows that each œÑa is a bijection, for its inverse is œÑa‚àí1:
œÑaœÑa‚àí1 = œÑaa‚àí1 = œÑ1 = 1G/H = œÑa‚àí1œÑa,
and so œÑa ‚ààSG/H. DeÔ¨Åne œï : G ‚ÜíSG/H by œï(a) = œÑa. Rewriting,
œï(a)œï(b) = œÑaœÑb = œÑab = œï(ab),
so that œï is a homomorphism. Finally, if a ‚ààker œï, then œï(a) = 1G/H, so that œÑa(x H) =
x H for all x ‚ààG; in particular, when x = 1, this gives aH = H, and a ‚ààH, by
Lemma 2.40(i). The result follows from Exercise 2.39 on page 80, for |G/H| = n, and so
SG/H ‚àº= Sn.
‚Ä¢
When H = {1}, this is the Cayley theorem.
We are now going to classify all groups of order up to 7. By Example 2.53, every group
of prime order p is isomorphic to Ip, and so, to isomorphism, there is just one group of
order p. Of the possible orders through 7, four of them, 2, 3, 5, and 7, are primes, and so
we need look only at orders 4 and 6.
Proposition 2.89.
Every group G of order 4 is isomorphic to either I4 or the four-group
V. Moreover, I4 and V are not isomorphic.
Proof.
By Lagrange's theorem, every element in G, other than 1, has order either 2 or 4.
If there is an element of order 4, then G is cyclic. Otherwise, x2 = 1 for all x ‚ààG, so that
Exercise 2.26 on page 62 shows that G is abelian.
If distinct elements x and y in G are chosen, neither being 1, then we quickly check that
xy /‚àà{1, x, y}; hence,
G = {1, x, y, xy}.
It is easy to see that the bijection f : G ‚ÜíV, deÔ¨Åned by f (1) = 1, f (x) = (1 2)(3 4),
f (y) = (1 3)(2 4), and f (xy) = (1 4)(2 3), is an isomorphism.
We have already seen, in Example 2.54, that I4 Ã∏‚àº= V.
‚Ä¢

98
Groups I
Ch. 2
Proposition 2.90.
If G is a group of order 6, then G is isomorphic to either I6 or S3.
Moreover, I6 and S3 are not isomorphic.16
Proof.
By Lagrange's theorem, the only possible orders of nonidentity elements are 2, 3,
and 6. Of course, G ‚àº= I6 if G has an element of order 6. Now Exercise 2.27 on page 62
shows that G must contain an element of order 2, say, t. We now consider the cases G
abelian and G nonabelian separately.
Case 1. G is abelian.
If there is a second element of order 2, say, a, then it is easy to see, using at = ta, that
H = {1, a, t, at} is a subgroup of G. This contradicts Lagrange's theorem, because 4 is
not a divisor of 6. It follows that G must contain an element b of order 3. But tb has order
6, by Proposition 2.82. Therefore, G is cyclic if it is abelian.
Case 2. G is not abelian.
If G has no elements of order 3, then x2 = 1 for all x ‚ààG, and G is abelian, by
Exercise 2.26 on page 62. Therefore, G contains an element s of order 3 as well as the
element t of order 2.
Now | ‚ü®s‚ü©| = 3, so that [G : ‚ü®s‚ü©] = |G|/| ‚ü®s‚ü©| = 6/3 = 2, and so ‚ü®s‚ü©is a normal
subgroup of G, by Proposition 2.62(ii). Since t = t‚àí1, we have tst ‚àà‚ü®s‚ü©; hence, tst = si
for i = 0, 1 or 2. Now i Ã∏= 0, for tst = s0 = 1 implies s = 1. If i = 1, then s and t
commute, and this gives st of order 6, as in Case 1 (which forces G to be cyclic, hence
abelian, contrary to our present hypothesis). Therefore, tst = s2 = s‚àí1.
We now use Theorem 2.88 to construct an isomorphism G ‚ÜíS3. Let H = ‚ü®t‚ü©, and
consider the homomorphism œï : G ‚ÜíSG/‚ü®t‚ü©given by
œï(g) : x ‚ü®t‚ü©‚Üígx ‚ü®t‚ü©.
By the theorem, ker œï ‚â§‚ü®t‚ü©, so that either ker œï = {1} (and œï is injective), or ker œï = ‚ü®t‚ü©.
Now G/ ‚ü®t‚ü©= {‚ü®t‚ü©, s ‚ü®t‚ü©, s2 ‚ü®t‚ü©}, and, in two-rowed notation,
œï(t) =
 ‚ü®t‚ü©
s ‚ü®t‚ü©
s2 ‚ü®t‚ü©
t ‚ü®t‚ü©
ts ‚ü®t‚ü©
ts2 ‚ü®t‚ü©
	
.
If œï(t) is the identity permutation, then ts ‚ü®t‚ü©= s ‚ü®t‚ü©, so that s‚àí1ts ‚àà‚ü®t‚ü©= {1, t}, by
Lemma 2.40. But now s‚àí1ts = t (it cannot be 1), hence ts = st, contradicting t and s
not commuting. Therefore, t /‚ààker œï, and œï : G ‚ÜíSG/‚ü®t‚ü©‚àº= S3 is an injective homomor-
phism. Since both G and S3 have order 6, œï must be a bijection, and so G ‚àº= S3.
It is clear that I6 and S3 are not isomorphic, for one is abelian and the other is not.
‚Ä¢
16Cayley states this proposition in an article he wrote in 1854. However, in 1878, in the American Journal of
Mathematics, he wrote, "The general problem is to Ô¨Ånd all groups of a given order n; . . . if n = 6, there are three
groups; a group
1, Œ±, Œ±2, Œ±3, Œ±4, Œ±5
(Œ±6 = 1),
and two more groups
1, Œ≤, Œ≤2, Œ±, Œ±Œ≤, Œ±Œ≤2
(Œ±2 = 1, Œ≤3 = 1),
viz., in the Ô¨Årst of these Œ±Œ≤ = Œ≤Œ± while in the other of them, we have Œ±Œ≤ = Œ≤2Œ±, Œ±Œ≤2 = Œ≤Œ±." Cayley's list is I6,
I2 √ó I3, and S3. Of course, I2 √ó I3 ‚àº= I6; even Homer nods.

Sec. 2.7
Group Actions
99
One consequence of this result is another proof that I6 ‚àº= I2 √ó I3 (see Theorem 2.81).
Classifying groups of order 8 is more difÔ¨Åcult, for we have not yet developed enough
theory. It turns out that there are 5 nonisomorphic groups of order 8: Three are abelian:
I8; I4 √ó I2; I2 √ó I2 √ó I2; two are nonabelian: D8; Q.
We can continue this discussion for larger orders, but things soon get out of hand, as
Table 2.4 shows. Making a telephone directory of groups is not the way to study them.
Order of Group
Number of Groups
2
1
4
2
8
5
16
14
32
51
64
267
128
2, 328
256
56, 092
512
10, 494, 213
1024
49, 487, 365, 422
Table 2.4.
Groups arose by abstracting the fundamental properties enjoyed by permutations. But
there is an important feature of permutations that the axioms do not mention: Permutations
are functions. We shall see that there are interesting consequences when this feature is
restored.
DeÔ¨Ånition.
If X is a set and G is a group, then G acts on X if there is a function G√óX ‚Üí
X, denoted by (g, x) ‚Üígx, such that
(i) (gh)x = g(hx) for all g, h ‚ààG and x ‚ààX;
(ii) 1x = x for all x ‚ààX, where 1 is the identity in G.
We also call X a G-set if G acts on X.
If a group G acts on a set X, then Ô¨Åxing the Ô¨Årst variable, say g, gives a function
Œ±g : X ‚ÜíX, namely, Œ±g : x ‚Üígx. This function is a permutation of X, for its inverse
is Œ±g‚àí1:
Œ±gŒ±g‚àí1 = Œ±1 = 1X = Œ±g‚àí1Œ±g.
It is easy to see that Œ± : G ‚ÜíSX, deÔ¨Åned by Œ± : g ‚ÜíŒ±g, is a homomorphism. Conversely,
given any homomorphism œï : G ‚ÜíSX, deÔ¨Åne gx = œï(g)(x). Thus, an action of a group
G on a set X is another way of viewing a homomorphism G ‚ÜíSX.
Cayley's theorem says that a group G acts on itself by (left) translation, and its general-
ization, Theorem 2.88, shows that G also acts on the family of cosets of a subgroup H by
(left) translation.

100
Groups I
Ch. 2
Example 2.91.
We show that G acts on itself by conjugation: that is, for each g ‚ààG, deÔ¨Åne Œ±g : G ‚ÜíG
to be conjugation
Œ±g(x) = gxg‚àí1.
To verify axiom (i), note that for each x ‚ààG,
(Œ±g ‚ó¶Œ±h)(x) = Œ±g(Œ±h(x))
= Œ±g(hxh‚àí1)
= g(hxh‚àí1)g‚àí1
= (gh)x(gh)‚àí1
= Œ±gh(x).
Therefore, Œ±g ‚ó¶Œ±h = Œ±gh.
To prove axiom (ii), note that for each x ‚ààG,
Œ±1(x) = 1x1‚àí1 = x,
and so Œ±1 = 1G.
‚óÄ
The following two deÔ¨Ånitions are fundamental.
DeÔ¨Ånition.
If G acts on X and x ‚ààX, then the orbit of x, denoted by O(x), is the subset
of X
O(x) = {gx : g ‚ààG} ‚äÜX;
the stabilizer of x, denoted by Gx, is the subgroup
Gx = {g ‚ààG : gx = x} ‚â§G.
If G acts on a set X, deÔ¨Åne a relation on X by x ‚â°y in case there exists g ‚ààG with
y = gx. It is easy to see that this is an equivalence relation whose equivalence classes are
the orbits.
Let us Ô¨Ånd some orbits and stabilizers.
Example 2.92.
(i) Cayley's theorem says that G acts on itself by translations: œÑg : a ‚Üíga. If a ‚ààG, then
the orbit O(a) = G, for if b ‚ààG, then b = (ba‚àí1)a = œÑba‚àí1(a). The stabilizer Ga of
a ‚ààG is {1}, for if a = œÑg(a) = ga, then g = 1. We say that G acts transitively on X if
there is only one orbit.
(ii) When G acts on G/H (the family of cosets of a subgroup H) by translations œÑg :
aH ‚ÜígaH, then the orbit O(aH) = G/H, for if bH ‚ààG/H, then œÑba‚àí1 : aH ‚ÜíbH.
Thus, G acts transitively on G/H. The stabilizer GaH of aH is aHa‚àí1, for gaH = aH
if and only if a‚àí1ga ‚ààH if and only if g ‚ààaHa‚àí1.
‚óÄ

Sec. 2.7
Group Actions
101
Example 2.93.
When a group G acts on itself by conjugation, then the orbit O(x) is
{y ‚ààG : y = axa‚àí1 for some a ‚ààG};
in this case, O(x) is called the conjugacy class of x, and it is commonly denoted by xG.
For example, Theorem 2.9 shows that if Œ± ‚ààSn, then the conjugacy class of Œ± consists of
all the permutations in Sn having the same cycle structure as Œ±. As a second example, an
element z lies in the center Z(G) if and only if zG = {z}; that is, no other elements in G
are conjugate to z.
If x ‚ààG, then the stabilizer Gx of x is
CG(x) = {g ‚ààG : gxg‚àí1 = x}.
This subgroup of G, consisting of all g ‚ààG that commute with x, is called the centralizer
of x in G.
‚óÄ
Example 2.94.
Every group G acts on the set X of all its subgroups, by conjugation: If a ‚ààG, then a acts
by H ‚ÜíaHa‚àí1, where H ‚â§G.
If H is a subgroup of a group G, then a conjugate of H is a subgroup of G of the form
aHa‚àí1 = {aha‚àí1 : h ‚ààH},
where a ‚ààG.
Since conjugation h ‚Üíaha‚àí1 is an injection H ‚ÜíG with image aHa‚àí1, it follows
that conjugate subgroups of G are isomorphic. For example, in S3, all cyclic subgroups of
order 2 are conjugate (for their generators are conjugate).
The orbit of a subgroup H consists of all its conjugates; notice that H is the only element
in its orbit if and only if H ‚úÅG; that is, aHa‚àí1 = H for all a ‚ààG. The stabilizer of H is
NG(H) = {g ‚ààG : gHg‚àí1 = H}.
This subgroup of G is called the normalizer of H in G.
‚óÄ
Example 2.95.
Let X = the vertices {v1, v2, v3, v4} of a square, and let G be the dihedral group D8
acting on X, as in Figure 2.8 on page 102 (for clarity, the vertices in the Ô¨Ågure are labeled
1, 2, 3, 4 instead of v1, v2, v3, v4).
G = {rotations : (1), (1 2 3 4), (1 3)(2 4), (1 4 3 2);
reÔ¨Çections : (2 4), (1 3), (1 2)(3 4), (1 4)(2 3)}.
For each vertex vi ‚ààX, there is some g ‚ààG with gv1 = vi; therefore, O(v1) = X and
D8 acts transitively.
What is the stabilizer Gv1 of v1? Aside from the identity, there is only one g ‚ààD8
Ô¨Åxing v1, namely, g = (2 4); therefore Gv1 is a subgroup of order 2. (This example can be
generalized to the dihedral group D2n acting on a regular n-gon.)
‚óÄ

102
Groups I
Ch. 2
1
2
3
4
1
2
3
4
1
2
3
4
1
4
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
3
2
Figure 2.8
Example 2.96.
Let X = {1, 2, . . . , n}, let Œ± ‚ààSn, and regard the cyclic group G = ‚ü®Œ±‚ü©as acting on X. If
i ‚ààX, then
O(i) = {Œ±k(i) : k ‚ààZ}.
Let the complete factorization of Œ± be Œ± = Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤t(Œ±), and let i = i1 be moved by Œ±. If
the cycle involving i1 is Œ≤ j = (i1 i2 . . . ir), then the proof of Theorem 2.3 shows that
ik+1 = Œ±k(i1) for all k < r. Therefore,
O(i) = {i1, i2, . . . , ir},
where i = i1. It follows that |O(i)| = r. The stabilizer G‚Ñìof a number ‚Ñìis G if Œ± Ô¨Åxes
‚Ñì; however, if Œ± moves ‚Ñì, then G‚Ñìdepends on the size of the orbit O(‚Ñì). For example, if
Œ± = (1 2 3)(4 5)(6), then G6 = G, G1 =

Œ±3 
, and G4 =

Œ±2 
.
‚óÄ
Proposition 2.97.
If G acts on a set X, then X is the disjoint union of the orbits. If X is
Ô¨Ånite, then
|X| =

i
|O(xi)|,
where one xi is chosen from each orbit.
Proof.
As we have mentioned earlier, the relation on X, given by x ‚â°y if there exists
g ‚ààG with y = gx, is an equivalence relation whose equivalence classes are the orbits.
Therefore, the orbits partition X.
The count given in the second statement is correct: Since the orbits are disjoint, no
element in X is counted twice.
‚Ä¢
Here is the connection between orbits and stabilizers.
Theorem 2.98.
If G acts on a set X and x ‚ààX, then
|O(x)| = [G : Gx]
the index of the stabilizer Gx in G.

Sec. 2.7
Group Actions
103
Proof.
Let G/Gx denote the family of all the left cosets of Gx in G. We will exhibit
a bijection œï : G/Gx ‚ÜíO(x), and this will give the result, since |G/Gx| = [G : Gx].
DeÔ¨Åne œï : gGx ‚Üígx. Now œï is well-deÔ¨Åned: If gGx = hGx, then h = g f for some
f ‚ààGx; that is, f x = x; hence, hx = g f x = gx. Now œï is an injection: if gx =
œï(gGx) = œï(hGx) = hx, then h‚àí1gx = x; hence, h‚àí1g ‚ààGx, and gGx = hGx. Lastly,
œï is a surjection: if y ‚ààO(x), then y = gx for some g ‚ààG, and so y = œï(gGx).
‚Ä¢
In Example 2.95, D8 acting on the four corners of a square, we saw that |O(v1)| = 4,
|Gv1| = 2, and [G : Gv1] = 8/2 = 4. In Example 2.96, G = ‚ü®Œ±‚ü©‚â§Sn acting on
X = {1, 2, . . . , n}, we saw that if, in the complete factorization of Œ± into disjoint cycles
Œ± = Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤t(Œ±), the r-cycle Œ≤ j moves ‚Ñì, then r = |O(‚Ñì)| for any ‚Ñìoccurring in Œ≤ j.
Theorem 2.98 says that r is a divisor of the order k of Œ±. (But Theorem 2.25 tells us more:
k is the lcm of the lengths of the cycles occurring in the factorization.)
Corollary 2.99.
If a Ô¨Ånite group G acts on a set X, then the number of elements in any
orbit is a divisor of |G|.
Proof.
This follows at once from Lagrange's theorem.
‚Ä¢
In Example 2.5(i), there is a table displaying the number of permutations in S4 of each
cycle structure; these numbers are 1, 6, 8, 6, 3. Note that each of these numbers is a divisor
of |S4| = 24, In Example 2.5(ii), we saw that the corresponding numbers are 1, 10, 20, 30,
24, 20, and 15, and these are all divisors of |S5| = 120. We now recognize these subsets
as being conjugacy classes, and the next corollary explains why these numbers divide the
group order.
Corollary 2.100.
If x lies in a Ô¨Ånite group G, then the number of conjugates of x is the
index of its centralizer:
|xG| = [G : CG(x)],
and hence it is a divisor of |G|.
Proof.
As in Example 2.93, the orbit of x is its conjugacy class xG, and the stabilizer Gx
is the centralizer CG(x).
‚Ä¢
Proposition 2.101.
If H is a subgroup of a Ô¨Ånite group G, then the number of conjugates
of H in G is [G : NG(H)].
Proof.
As in Example 2.94, the orbit of H is the family of all its conjugates, and the
stabilizer is its normalizer NG(H).
‚Ä¢
There are some interesting applications of group actions to counting problems, which
we will give at the end of this section. Let us Ô¨Årst apply group actions to group theory.
When we began classifying groups of order 6, it would have been helpful to be able to
assert that any such group has an element of order 3 (we were able to use an earlier exercise
to assert the existence of an element of order 2). We now prove that if p is a prime divisor
of |G|, where G is a Ô¨Ånite group G, then G contains an element of order p.

104
Groups I
Ch. 2
Theorem 2.102 (Cauchy).
If G is a Ô¨Ånite group whose order is divisible by a prime p,
then G contains an element of order p.
Proof.
We prove the theorem by induction on m ‚â•1, where |G| = pm. The base step
m = 1 is true, for Lagrange's theorem shows that every nonidentity element in a group of
order p has order p.
Let us now prove the inductive step. If x ‚ààG, then the number of conjugates of x
is |xG| = [G : CG(x)], where CG(x) is the centralizer of x in G. As noted earlier, if
x /‚ààZ(G), then xG has more than one element, and so |CG(x)| < |G|. If p | |CG(x)|
for some noncentral x, then the inductive hypothesis says there is an element of order p
in CG(x) ‚â§G, and we are done. Therefore, we may assume that p ‚à§|CG(x)| for all
noncentral x ‚ààG. Better, since p is a prime and |G| = [G : CG(x)]|CG(x)|, Euclid's
lemma gives
p | [G : CG(x)].
After recalling that Z(G) consists of all those elements x ‚ààG with |xG| = 1, we may
use Proposition 2.97 to see
|G| = |Z(G)| +

i
[G : CG(xi)],
where one xi is selected from each conjugacy class having more than one element. Since
|G| and all [G : CG(xi)] are divisible by p, it follows that |Z(G)| is divisible by p. But
Z(G) is abelian, and so Proposition 2.78 says that Z(G), and hence G, contains an element
of order p.
‚Ä¢
DeÔ¨Ånition.
The class equation of a Ô¨Ånite group G is
|G| = |Z(G)| +

i
[G : CG(xi)],
where one xi is selected from each conjugacy class having more than one element.
DeÔ¨Ånition.
If p is a prime, then a Ô¨Ånite group G is called a p-group if |G| = pn for some
n ‚â•0. (See Exercise 2.81 on page 112 for the deÔ¨Ånition of an inÔ¨Ånite p-group.)
We have seen examples of groups whose center is trivial; for example, Z(S3) = {1}.
For p-groups, however, this is never true.
Theorem 2.103.
If p is a prime and G is a p-group, then Z(G) Ã∏= {1}.
Proof.
Consider the class equation
|G| = |Z(G)| +

i
[G : CG(xi)].
Each CG(xi) is a proper subgroup of G, for xi /‚ààZ(G). Since G is a p-group, [G : CG(xi)]
is a divisor of |G|, hence is itself a power of p. Thus, p divides each of the terms in the
class equation other than |Z(G)|, and so p | |Z(G)| as well. Therefore, Z(G) Ã∏= {1}.
‚Ä¢

Sec. 2.7
Group Actions
105
Corollary 2.104.
If p is a prime, then every group G of order p2 is abelian.
Proof.
If G is not abelian, then its center Z(G) is a proper subgroup, so that |Z(G)| = 1
or p, by Lagrange's theorem. But Theorem 2.103 says that Z(G) Ã∏= {1}, and so |Z(G)| =
p. The center is always a normal subgroup, so that the quotient G/Z(G) is deÔ¨Åned; it has
order p, and hence G/Z(G) is cyclic. This contradicts Exercise 2.69 on page 95.
‚Ä¢
Example 2.105.
Who would have guessed that Cauchy's theorem (if G is a group whose order is a multiple
of a prime p, then G has an element of order p) and Fermat's theorem (if p is prime,
then a p ‚â°a mod p) are special cases of some common theorem? The elementary yet
ingenious proof of Cauchy's theorem is due to J. H. McKay in 1959 (see Montgomery
and Ralston, Selected Papers in Algebra); A. Mann showed me that McKay's argument
also proves Fermat's theorem. If G is a Ô¨Ånite group and p is a prime, denote the cartesian
product of p copies of G by G p, and deÔ¨Åne
X = {(a0, a1, . . . , ap‚àí1) ‚ààG p : a0a1 . . . ap‚àí1 = 1}.
Note that |X| = |G|p‚àí1, for having chosen the last p ‚àí1 entries arbitrarily, the 0th entry
must equal (a1a2 ¬∑ ¬∑ ¬∑ ap‚àí1)‚àí1. Introduce an action of Ip on X by deÔ¨Åning, for 0 ‚â§i ‚â§
p ‚àí1,
[i](a0, a1, . . . , ap‚àí1) = (ai, ai+1, . . . , ap‚àí1, a0, a1, . . . , ai).
The product of the entries in the new p-tuple is a conjugate of a0a1 ¬∑ ¬∑ ¬∑ ap‚àí1:
aiai+1 ¬∑ ¬∑ ¬∑ ap‚àí1a0a1 ¬∑ ¬∑ ¬∑ ai = (a0a1 ¬∑ ¬∑ ¬∑ ai)‚àí1(a0a1 ¬∑ ¬∑ ¬∑ ap‚àí1)(a0a1 ¬∑ ¬∑ ¬∑ ai).
This conjugate is 1 (for g‚àí11g = 1), and so [i](a0, a1, . . . , ap‚àí1) ‚ààX. By Corollary 2.99,
the size of every orbit of X is a divisor of |Ip| = p; since p is prime, these sizes are either
1 or p. Now orbits with just one element consist of a p-tuple all of whose entries ai are
equal, for all cyclic permutations of the p-tuple are the same. In other words, such an orbit
corresponds to an element a ‚ààG with a p = 1. Clearly, (1, 1, . . . , 1) is such an orbit; if it
were the only such, then we would have
|G|p‚àí1 = |X| = 1 + kp
for some k ‚â•0; that is, |G|p‚àí1 ‚â°1 mod p. If p is a divisor of |G|, then we have a
contradiction, for |G|p‚àí1 ‚â°0 mod p. We have thus proved Cauchy's theorem: If a prime
p is a divisor of |G|, then G has an element of order p.
Suppose now that G is a group of order n, say, G = In, and that p is not a divisor of
n. By Lagrange's theorem, G has no elements of order p, so that if a p = 1, then a = 1.
Therefore, the only orbit in G p of size 1 is (1, 1, . . . , 1), and so
n p‚àí1 = |G|p‚àí1 = |X| = 1 + kp;
that is, if p is not a divisor of n, then n p‚àí1 ‚â°1 mod p. Multiplying both sides by n, we
have n p ‚â°n mod p, a congruence also holding when p is a divisor of n; this is Fermat's
theorem.
‚óÄ

106
Groups I
Ch. 2
We have seen, in Proposition 2.64, that A4 is a group of order 12 having no subgroup
of order 6. Thus, the assertion that if d is a divisor of |G|, then G must have a subgroup of
order d, is false. However, this assertion is true when G is a p-group.
Proposition 2.106.
If G is a group of order |G| = pe, then G has a normal subgroup of
order pk for every k ‚â§e.
Proof.
We prove the result by induction on e ‚â•0. The base step is obviously true, and so
we proceed to the inductive step. By Theorem 2.103, the center of G is a nontrivial normal
subgroup: Z(G) Ã∏= {1}. Let Z ‚â§Z(G) be a subgroup of order p; as any subgroup of
Z(G), the subgroup Z is a normal subgroup of G. If k ‚â§e, then pk‚àí1 ‚â§pe‚àí1 = |G/Z|.
By induction, G/Z has a normal subgroup H‚àóof order pk‚àí1. The correspondence theorem
says there is a subgroup H of G containing Z with H‚àó= H/Z; moreover, H‚àó‚úÅG/Z
implies H ‚úÅG. But |H/Z| = pk‚àí1 implies |H| = pk, as desired.
‚Ä¢
Abelian groups (and the quaternions) have the property that every subgroup is normal.
At the opposite pole are groups having no normal subgroups other than the two obvious
ones: {1} and G.
DeÔ¨Ånition.
A group G Ã∏= {1} is called simple if G has no normal subgroups other than
{1} and G itself.
Proposition 2.107.
An abelian group G is simple if and only if it is Ô¨Ånite and of prime
order.
Proof.
If G is Ô¨Ånite of prime order p, then G has no subgroups H other than {1} and
G, otherwise Lagrange's theorem would show that |H| is a divisor of p. Therefore, G is
simple.
Conversely, assume that G is simple. Since G is abelian, every subgroup is normal, and
so G has no subgroups other than {1} and G. Choose x ‚ààG with x Ã∏= 1. Since ‚ü®x‚ü©is a
subgroup, we have ‚ü®x‚ü©= G. If x has inÔ¨Ånite order, then all the powers of x are distinct,
and so

x2 
< ‚ü®x‚ü©is a forbidden subgroup of ‚ü®x‚ü©, a contradiction. Therefore, every x ‚ààG
has Ô¨Ånite order. If x has (Ô¨Ånite) order m and if m is composite, say m = k‚Ñì, then

xk 
is a
proper nontrivial subgroup of ‚ü®x‚ü©, a contradiction. Therefore, G = ‚ü®x‚ü©has prime order. ‚Ä¢
We are now going to show that A5 is a nonabelian simple group (indeed, it is the smallest
such; there is no nonabelian simple group of order less than 60).
Suppose that an element x ‚ààG has k conjugates; that is
|xG| = |{gxg‚àí1 : g ‚ààG}| = k.
If there is a subgroup H ‚â§G with x ‚ààH ‚â§G, how many conjugates does x have in H?
Since
x H = {hxh‚àí1 : h ‚ààH} ‚äÜ{gxg‚àí1 : g ‚ààG} = xG,

Sec. 2.7
Group Actions
107
we have |x H| ‚â§|xG|. It is possible that there is strict inequality |x H| < |xG|. For example,
take G = S3, x = (1 2), and H = ‚ü®x‚ü©. We know that |xG| = 3 (because all transpositions
are conjugate), whereas |x H| = 1 (because H is abelian).
Now let us consider this question, in particular, for G = S5, x = (1 2 3), and H = A5.
Lemma 2.108.
All 3-cycles are conjugate in A5.
Proof.
Let G = S5, Œ± = (1 2 3), and H = A5. We know that |Œ±S5| = 20, for there
are twenty 3-cycles in S5, as we saw in Example 2.5(ii). Therefore, 20 = |S5|/|CS5(Œ±)| =
120/|CS5(Œ±)|, by Corollary 2.100, so that |CS5(Œ±)| = 6; that is, there are exactly six
permutations in S5 that commute with Œ±. Here they are:
(1), (1 2 3), (1 3 2), (4 5), (4 5)(1 2 3), (4 5)(1 3 2).
The last three of these are odd permutations, so that |CA5(Œ±)| = 3. We conclude that
|Œ± A5| = |A5|/|CA5(Œ±)| = 60/3 = 20;
that is, all 3-cycles are conjugate to Œ± = (1 2 3) in A5.
‚Ä¢
This lemma can be generalized from A5 to all An for n ‚â•5; see Exercise 2.91 on
page 113.
Lemma 2.109.
If n ‚â•3, every element in An is a 3-cycle or a product of 3-cycles.
Proof.
If Œ± ‚ààAn, then Œ± is a product of an even number of transpositions:
Œ± = œÑ1œÑ2 ¬∑ ¬∑ ¬∑ œÑ2q‚àí1œÑ2q.
Of course, we may assume that adjacent œÑ's are distinct. As the transpositions may be
grouped in pairs œÑ2i‚àí1œÑ2i, it sufÔ¨Åces to consider products œÑœÑ ‚Ä≤, where œÑ and œÑ ‚Ä≤ are transpo-
sitions. If œÑ and œÑ ‚Ä≤ are not disjoint, then œÑ = (i j), œÑ ‚Ä≤ = (i k), and œÑœÑ ‚Ä≤ = (i k j); if œÑ and
œÑ ‚Ä≤ are disjoint, then œÑœÑ ‚Ä≤ = (i j)(k ‚Ñì) = (i j)( j k)( j k)(k ‚Ñì) = (i j k)( j k ‚Ñì).
‚Ä¢
Theorem 2.110.
A5 is a simple group.
Proof.
We shall show that if H is a normal subgroup of A5 and H Ã∏= {(1)}, then H = A5.
Now if H contains a 3-cycle, then normality forces H to contain all its conjugates. By
Lemma 2.108, H contains every 3-cycle, and by Lemma 2.109, H = A5. Therefore, it
sufÔ¨Åces to prove that H contains a 3-cycle.
As H Ã∏= {(1)}, it contains some œÉ Ã∏= (1). We may assume, after a harmless relabeling,
that either œÉ = (1 2 3), œÉ = (1 2)(3 4), or œÉ = (1 2 3 4 5). As we have just remarked, we
are done if œÉ is a 3-cycle.
If œÉ = (1 2)(3 4), deÔ¨Åne œÑ = (1 2)(3 5). Now H contains (œÑœÉœÑ ‚àí1)œÉ ‚àí1, because
it is a normal subgroup, and œÑœÉœÑ ‚àí1œÉ ‚àí1 = (3 5 4), as the reader should check. If œÉ =
(1 2 3 4 5), deÔ¨Åne œÅ = (1 3 2); now H contains œÅœÉœÅ‚àí1œÉ ‚àí1 = (1 3 4), as the reader
should also check.
We have shown, in all cases, that H contains a 3-cycle. Therefore, the only normal
subgroups in A5 are {(1)} and A5 itself, and so A5 is simple.
‚Ä¢

108
Groups I
Ch. 2
Theorem 2.110 turns out to be the basic reason why the quadratic formula has no gen-
eralization giving the roots of polynomials of degree 5 or higher (see Theorem 4.27).
Without much more effort, we can prove that the alternating groups An are simple for
all n ‚â•5. Observe that A4 is not simple, for the four-group V is a normal subgroup of A4.
Lemma 2.111.
A6 is a simple group.
Proof.
Let H Ã∏= {(1)} be a normal subgroup of A6; we must show that H = A6. Assume
that there is some Œ± ‚ààH with Œ± Ã∏= (1) that Ô¨Åxes some i, where 1 ‚â§i ‚â§6. DeÔ¨Åne
F = {œÉ ‚ààA6 : œÉ(i) = i}.
Note that Œ± ‚ààH ‚à©F, so that H ‚à©F Ã∏= {(1)}. The second isomorphism theorem gives
H ‚à©F ‚úÅF. But F is simple, for F ‚àº= A5, and so the only normal subgroups in F are {(1)}
and F. Since H ‚à©F Ã∏= {(1)}, we have H ‚à©F = F; that is, F ‚â§H. It follows that H
contains a 3-cycle, and so H = A6, by Exercise 2.91 on page 113.
We may now assume that there is no Œ± ‚ààH with Œ± Ã∏= (1) that Ô¨Åxes some i with
1 ‚â§i ‚â§6. If we consider the cycle structures of permutations in A6, however, any such
Œ± must have cycle structure (1 2)(3 4 5 6) or (1 2 3)(4 5 6). In the Ô¨Årst case, Œ±2 ‚ààH
is a nontrivial permutation that Ô¨Åxes 1 (and also 2), a contradiction. In the second case, H
contains Œ±(Œ≤Œ±‚àí1Œ≤‚àí1), where Œ≤ = (2 3 4), and it is easily checked that this is a nontrivial
element in H which Ô¨Åxes 1, another contradiction. Therefore, no such normal subgroup H
can exist, and so A6 is a simple group.
‚Ä¢
Theorem 2.112.
An is a simple group for all n ‚â•5.
Proof.
If H is a nontrivial normal subgroup of An, that is, H Ã∏= {(1)}, then we must show
that H = An; by Exercise 2.91 on page 113, it sufÔ¨Åces to prove that H contains a 3-cycle.
If Œ≤ ‚ààH is nontrivial, then there exists some i that Œ≤ moves; say, Œ≤(i) = j Ã∏= i. Choose
a 3-cycle Œ± that Ô¨Åxes i and moves j. The permutations Œ± and Œ≤ do not commute: Œ≤Œ±(i) =
Œ≤(i) = j, while Œ±Œ≤(i) = Œ±( j) Ã∏= j. It follows that Œ≥ = (Œ±Œ≤Œ±‚àí1)Œ≤‚àí1 is a nontrivial
element of H. But Œ≤Œ±‚àí1Œ≤‚àí1 is a 3-cycle, by Theorem 2.9, and so Œ≥ = Œ±(Œ≤Œ±‚àí1Œ≤‚àí1) is a
product of two 3-cycles. Hence, Œ≥ moves at most 6 symbols, say, i1, . . . , i6 (if Œ≥ moves
fewer than 6 symbols, just adjoin others so we have a list of 6). DeÔ¨Åne
F = {œÉ ‚ààAn : œÉ Ô¨Åxes all i Ã∏= i1, . . . , i6}.
Now F ‚àº= A6 and Œ≥ ‚ààH ‚à©F. Hence, H ‚à©F is a nontrivial normal subgroup of F. But
F is simple, being isomorphic to A6, and so H ‚à©F = F; that is, F ‚â§H. Therefore, H
contains a 3-cycle, and so H = An; the proof is complete.
‚Ä¢
We now use groups to solve some difÔ¨Åcult counting problems.

Sec. 2.7
Group Actions
109
Theorem 2.113 (Burnside's Lemma17).
Let G act on a Ô¨Ånite set X. If N is the number
of orbits, then
N =
1
|G|

œÑ‚ààG
Fix(œÑ),
where Fix(œÑ) is the number of x ‚ààX Ô¨Åxed by œÑ.
Proof.
List the elements of X as follows: Choose x1 ‚ààX, and then list all the ele-
ments x1, x2, . . . , xr in the orbit O(x1); then choose xr+1 /‚ààO(x1), and list the elements
xr+1, xr+2, . . . in O(xr+1); continue this procedure until all the elements of X are listed.
Now list the elements œÑ1, œÑ2, . . . , œÑn of G, and form the following array, where
fi, j =

1
if œÑi Ô¨Åxes x j
0
if œÑi moves x j.
x1
x2
¬∑ ¬∑ ¬∑
xr+1
xr+2
¬∑ ¬∑ ¬∑
œÑ1
f1,1
f1,2
¬∑ ¬∑ ¬∑
f1,r+1
f1,r+2
¬∑ ¬∑ ¬∑
œÑ2
f2,1
f2,2
¬∑ ¬∑ ¬∑
f2,r+1
f2,r+2
¬∑ ¬∑ ¬∑
œÑi
fi,1
fi,2
¬∑ ¬∑ ¬∑
fi,r+1
fi,r+2
¬∑ ¬∑ ¬∑
œÑn
fn,1
fn,2
¬∑ ¬∑ ¬∑
fn,r+1
fn,r+2
¬∑ ¬∑ ¬∑
Now Fix(œÑi), the number of x Ô¨Åxed by œÑi, is the number of 1's in the ith row of the
array; therefore, 
œÑ‚ààG Fix(œÑ) is the total number of 1's in the array. Let us now look at
the columns. The number of 1's in the Ô¨Årst column is the number of œÑi that Ô¨Åx x1; by
deÔ¨Ånition, these œÑi comprise Gx1. Thus, the number of 1's in column 1 is |Gx1|. Similarly,
the number of 1's in column 2 is |Gx2|. By Exercise 2.99 on page 114, |Gx1| = |Gx2|. By
Theorem 2.98, the number of 1's in the r columns labeled by the xi ‚ààO(x1) is thus
r|Gx1| = |O(x1)| ¬∑ |Gx1| =

|G|/|Gx1|

|Gx1| = |G|.
The same is true for any other orbit: Its columns contain exactly |G| 1's. Therefore, if
there are N orbits, there are N|G| 1's in the array. We conclude that

œÑ‚ààG
Fix(œÑ) = N|G|.
‚Ä¢
We are going to use Burnside's lemma to solve problems of the following sort. How
many striped Ô¨Çags are there having six stripes (of equal width) each of which can be colored
red, white, or blue? Clearly, the two Ô¨Çags in Figure 2.9 are the same: The bottom Ô¨Çag is
just the top one turned over.
17Burnside himself attributed this lemma to F. G. Frobenius. To avoid the confusion that would be caused by
changing a popular name, P. M. Neumann has suggested that it be called "not-Burnside's lemma." W. Burnside
was a Ô¨Åne mathematician, and there do exist theorems properly attributed to him. For example, Burnside proved
that if p and q are primes, then there are no simple groups of order pmqn.

110
Groups I
Ch. 2
r
w
b
r
w
b
b
w
r
b
w
r
Figure 2.9
Let X be the set of all 6-tuples of colors; if x ‚ààX, then
x = (c1, c2, c3, c4, c5, c6),
where each ci denotes either red, white, or blue. Let œÑ be the permutation that reverses all
the indices:
œÑ =
1
2
3
4
5
6
6
5
4
3
2
1
	
= (1 6)(2 5)(3 4)
(thus, œÑ "turns over" each 6-tuple x of colored stripes). The cyclic group G = ‚ü®œÑ‚ü©acts
on X; since |G| = 2, the orbit of any 6-tuple x consists of either 1 or 2 elements: Either
œÑ Ô¨Åxes x or it does not. Since a Ô¨Çag is unchanged by turning it over, it is reasonable to
identify a Ô¨Çag with an orbit of a 6-tuple. For example, the orbit consisting of the 6-tuples
(r, w, b,r, w, b)
and
(b, w,r, b, w,r)
describes the Ô¨Çag in Figure 2.9. The number of Ô¨Çags is thus the number N of orbits; by
Burnside's lemma, N = 1
2[Fix((1)) + Fix(œÑ)]. The identity permutation (1) Ô¨Åxes every
x ‚ààX, and so Fix((1)) = 36 (there are 3 colors). Now œÑ Ô¨Åxes a 6-tuple x if it is a
"palindrome," that is, if the colors in x read the same forward as backward. For example,
x = (r,r, w, w,r,r)
is Ô¨Åxed by œÑ. Conversely, if
x = (c1, c2, c3, c4, c5, c6)
is Ô¨Åxed by œÑ = (1 6)(2 5)(3 4), then c1 = c6, c2 = c5, and c3 = c4; that is, x is a
palindrome. It follows that Fix(œÑ) = 33, for there are 3 choices for each of c1, c2, and c3.
The number of Ô¨Çags is thus
N = 1
2(36 + 33) = 378.
Let us make the notion of coloring more precise.
DeÔ¨Ånition.
If a group G acts on X = {1, . . . , n}, and if C is a set of q colors, then G acts
on the set Cn of all n-tuples of colors by
œÑ(c1, . . . , cn) = (cœÑ1, . . . , cœÑn)
for all œÑ ‚ààG.
An orbit of (c1, . . . , cn) ‚ààCn is called a (q, G)-coloring of X.

Sec. 2.7
Group Actions
111
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
13
9
5
1
14
10
6
2
15
11
7
3
16
12
8
4
Figure 2.10
Example 2.114.
Color each square in a 4 √ó 4 grid red or black (adjacent squares may have the same color;
indeed, one possibility is that all the squares have the same color).
If X consists of the 16 squares in the grid and if C consists of the two colors red and
black, then the cyclic group G = ‚ü®R‚ü©of order 4 acts on X, where R is clockwise rotation
by 90‚ó¶; Figure 2.10 shows how R acts: The right square is R's action on the left square. In
cycle notation,
R = (1, 4, 16, 13)(2, 8, 15, 9)(3, 12, 14, 5)(6, 7, 11, 10),
R2 = (1, 16)(4, 13)(2, 15)(8, 9)(3, 14)(12, 5)(6, 11)(7, 10),
R3 = (1, 13, 16, 4)(2, 9, 15, 8)(3, 5, 14, 12)(6, 10, 11, 7).
A red-and-black chessboard does not change when it is rotated; it is merely viewed from a
different position. Thus, we may regard a chessboard as a 2-coloring of X; the orbit of a
16-tuple corresponds to the four ways of viewing the board.
By Burnside's lemma, the number of chessboards is
1
4

Fix((1)) + Fix(R) + Fix(R2) + Fix(R3)

.
Now Fix((1)) = 216, for every 16-tuple is Ô¨Åxed by the identity. To compute Fix(R), note
that squares 1, 4, 16, 13 must all have the same color in a 16-tuple Ô¨Åxed by R. Similarly,
squares 2, 8, 15, 9 must have the same color, squares 3, 12, 14, 5 must have the same color,
and squares 6, 7, 11, 10 must have the same color. We conclude that Fix(R) = 24; note
that the exponent 4 is the number of cycles in the complete factorization of R. A similar
analysis shows that Fix(R2) = 28, for the complete factorization of R2 has 8 cycles, and
Fix(R3) = 24, because the cycle structure of R3 is the same as that of R. Therefore, the
number N of chessboards is
N = 1
4

216 + 24 + 28 + 24
= 16,456.
‚óÄ

112
Groups I
Ch. 2
We now show, as in Example 2.114, that the cycle structure of a permutation œÑ allows
one to calculate Fix(œÑ).
Lemma 2.115.
Let C be a set of q colors, and let G be a subgroup of Sn. If œÑ ‚ààG, then
Fix(œÑ) = qt(œÑ),
where t(œÑ) is the number of cycles in the complete factorization of œÑ.
Proof.
Since œÑ(c1, . . . , cn) = (cœÑ1, . . . , cœÑn) = (c1, . . . , cn), we see that cœÑi = ci for all
i, and so œÑi has the same color as i. It follows, for all k, that œÑ ki has the same color as
i, that is, all points in the orbit of i acted on by ‚ü®œÑ‚ü©have the same color. If the complete
factorization of œÑ is œÑ = Œ≤1 ¬∑ ¬∑ ¬∑ Œ≤t(œÑ), and if i occurs in Œ≤ j, then Example 2.96 shows that
the orbit containing i is the set of symbols occurring in Œ≤ j. Thus, for an n-tuple to be Ô¨Åxed
by œÑ, all the symbols involved in each of the t(œÑ) cycles must have the same color; as there
are q colors, there are thus qt(œÑ)n-tuples Ô¨Åxed by œÑ.
‚Ä¢
Corollary 2.116.
Let G act on a Ô¨Ånite set X. If N is the number of (q, G)-colorings of
X, then
N =
1
|G|

œÑ‚ààG
qt(œÑ),
where t(œÑ) is the number of cycles in the complete factorization of œÑ.
There is a generalization of this technique, due to G. P¬¥olya (see Biggs, Discrete Math-
ematics), giving a formula, for example, that counts the number of red, white, blue, and
green Ô¨Çags having 20 stripes exactly 7 of which are red and 5 of which are blue.
EXERCISES
2.78 If a and b are elements in a group G, prove that ab and ba have the same order.
Hint. Use a conjugation.
2.79 Prove that if G is a Ô¨Ånite group of odd order, then no x ‚ààG, other than x = 1, is conjugate to
its inverse.
Hint. If x is conjugate to x‚àí1, how many elements are in xG?
2.80 Prove that no pair of the following groups of order 8,
I8; I4 √ó I2; I2 √ó I2 √ó I2; D8; Q,
are isomorphic.
2.81 Prove that if p is a prime and G is a Ô¨Ånite group in which every element has order a power
of p, then G is a p-group. (A possibly inÔ¨Ånite group G is called a p-group if every element in
G has order a power of p.)
Hint. Use Cauchy's theorem.

Sec. 2.7
Group Actions
113
2.82 DeÔ¨Åne the centralizer CG(H) of a subgroup H ‚â§G to be
CG(H) = {x ‚ààG : xh = hx for all h ‚ààH}.
(i) For every subgroup H ‚â§G, prove that CG(H) ‚úÅNG(H).
(ii) For every subgroup H ‚â§G, prove that NG(H)/CG(H) is isomorphic to a subgroup of
Aut(H).
Hint. Generalize the homomorphism ! in Exercise 2.64 on page 82.
2.83 Show that S4 has a subgroup isomorphic to D8.
2.84 Prove that S4/V ‚àº= S3.
Hint. Use Proposition 2.90.
2.85
(i) Prove that A4 Ã∏‚àº= D12.
Hint. Recall that A4 has no element of order 6.
(ii) Prove that D12 ‚àº= S3 √ó I2.
Hint.
Each element x ‚ààD12 has a unique factorization of the form x = bia, where
b6 = 1 and a2 = 1.
2.86
(i) If G is a group, then a normal subgroup H ‚úÅG is called a maximal normal subgroup
if there is no normal subgroup K of G with H < K < G. Prove that a normal subgroup
H is a maximal normal subgroup of G if and only if G/H is a simple group.
(ii) Prove that every Ô¨Ånite abelian group G has a subgroup of prime index.
Hint. Use Proposition 2.107.
(iii) Prove that A6 has no subgroup of prime index.
2.87 Prove that H ‚úÅNG(H) and that NG(H) is the largest subgroup of G containing H as a normal
subgroup.
2.88 Find NG(H) if G = S4 and H = ‚ü®(1 2 3)‚ü©.
2.89
(i) If H is a subgroup of G and if x ‚ààH, prove that
CH(x) = H ‚à©CG(x).
(ii) If H is a subgroup of index 2 in a Ô¨Ånite group G and if x ‚ààH, prove that |x H| = |xG|
or |x H| = 1
2|xG|, where x H is the conjugacy class of x in H.
Hint. Use the second isomorphism theorem.
(iii) Prove that there are two conjugacy classes of 5-cycles in A5, each of which has 12
elements.
Hint.
If Œ± = (1 2 3 4 5), then
CS5(Œ±)
 = 5 because 24 =
120
|CS5(Œ±)|; hence
CS5(Œ±) = ‚ü®Œ±‚ü©. What is CA5(Œ±)?
(iv) Prove that the conjugacy classes in A5 have sizes 1, 12, 12, 15, and 20.
2.90
(i) Prove that every normal subgroup H of a group G is a union of conjugacy classes of G,
one of which is {1}.
(ii) Use part (i) and Exercise 2.89 to give a second proof of the simplicity of A5.
2.91
(i) For all n ‚â•5, prove that all 3- cycles are conjugate in An.
Hint.
Show that (1 2 3) and (i j k) are conjugate, in two steps: First, if they are not
disjoint (so the permutations move at most 5 letters); then, if they are disjoint.

114
Groups I
Ch. 2
(ii) Prove that if a normal subgroup H ‚úÅAn contains a 3-cycle, where n ‚â•5, then H = An.
(Remark. We have proved this in Lemma 2.109 when n = 5.)
2.92 Prove that the only normal subgroups of S4 are {(1)}, V, A4, and S4.
Hint. Use Theorem 2.9, checking the various cycle structures one at a time.
2.93 Prove that A5 is a group of order 60 that has no subgroup of order 30.
Hint. Use Proposition 2.62(ii).
2.94
(i) Prove, for all n ‚â•5, that the only normal subgroups of Sn are {(1)}, An, and Sn.
(ii) Prove that if n ‚â•3, then An is the only subgroup of Sn of order 1
2n!.
Hint.
If H is a second such subgroup, then H is normal in Sn and hence H ‚à©An is
normal in An.
(iii) Prove that S5 has no subgroup of order 30.
Hint. Use the representation on the cosets of a supposed subgroup of order 30, as well
as the simplicity of A5.
(iv) Prove that S5 contains no subgroup of order 40.
2.95 Let G be a subgroup of Sn.
(i) If G ‚à©An = {1}, prove that |G| ‚â§2.
(ii) If G is a simple group with more than 2 elements, prove that G ‚â§An.
2.96
(i) If n ‚â•5, prove that Sn has no subgroup of index r, where 2 < r < n.
(ii) Prove that if n ‚â•5, then An has no subgroup of index r, where 2 ‚â§r < n.
2.97
(i) Prove that if a simple group G has a subgroup of index n > 1, then G is isomorphic to
a subgroup of Sn.
Hint. Kernels are normal subgroups.
(ii) Prove that an inÔ¨Ånite simple group (such do exist) has no subgroups of Ô¨Ånite index
n > 1.
Hint. Use part (i).
2.98 Let G be a group with |G| = mp, where p is a prime and 1 < m < p. Prove that G is not
simple.
Hint.
Show that G has a subgroup H of order p, and use the representation of G on the
cosets of H.
Remark.
Of all the numbers smaller than 60, we can now show that all but 11 are not
orders of nonabelian simple groups (namely, 12, 18, 24, 30, 36, 40, 45, 48, 50, 54, 56).
Theorem 2.103 eliminates all prime powers (for the center is always a normal subgroup), and
this exercise eliminates all numbers of the form mp, where p is a prime and m < p. (We
can complete the proof that there are no nonabelian simple groups of order less than 60 using
Sylow's theorem; see Proposition 5.41.)
‚óÄ
2.99
(i) Let a group G act on a set X, and suppose that x, y ‚ààX lie in the same orbit: y = gx
for some g ‚ààG. Prove that Gy = gGx g‚àí1.
(ii) Let G be a Ô¨Ånite group acting on a set X; prove that if x, y ‚ààX lie in the same orbit,
then |Gx| = |Gy|.
2.100 How many Ô¨Çags are there with n stripes each of which can be colored any one of q given
colors?
Hint. The parity of n is relevant.

Sec. 2.7
Group Actions
115
2.101 Let X be the squares in an n √ó n grid, and let œÅ be a rotation by 90‚ó¶. DeÔ¨Åne a chessboard
to be a (q, G)-coloring, where the cyclic group G = ‚ü®œÅ‚ü©of order 4 is acting. Show that the
number of chessboards is
1
4

qn2 + q‚åä(n2+1)/2‚åã+ 2q‚åä(n2+3)/4‚åã
,
where ‚åäx‚åãis the greatest integer in the number x.
2.102 Let X be a disk divided into n congruent circular sectors, and let œÅ be a rotation by (360/n)‚ó¶.
DeÔ¨Åne a roulette wheel to be a (q, G)-coloring, where the cyclic group G = ‚ü®œÅ‚ü©of order n is
acting. Prove that if n = 6, then there are 1
6(2q + 2q2 + q3 + q6) roulette wheels having 6
sectors.
The formula for the number of roulette wheels with n sectors is
1
n

d|n
œÜ(n/d)qd,
where œÜ is the Euler œÜ-function.
2.103 Let X be the vertices of a regular n-gon, and let the dihedral group G = D2n act (as the
usual group of symmetries [see Example 2.28]). DeÔ¨Åne a bracelet to be a (q, G)-coloring of a
regular n-gon, and call each of its vertices a bead. (Not only can we rotate a bracelet, we can
also Ô¨Çip it: that is, turn it upside down by rotating it in space about a line joining two beads.)
(i) How many bracelets are there having 5 beads, each of which can be colored any one of
q available colors?
Hint. The group G = D10 is acting. Use Example 2.28 to assign to each symmetry a
permutation of the vertices, and then show that the number of bracelets is
1
10

q5 + 4q + 5q3
.
(ii) How many bracelets are there having 6 beads, each of which can be colored any one of
q available colors?
Hint. The group G = D12 is acting. Use Example 2.28 to assign to each symmetry a
permutation of the vertices, and then show that the number of bracelets is
1
12

q6 + 2q4 + 4q3 + 3q2 + 2q

.

3
Commutative Rings I
3.1 INTRODUCTION
As in Chapters 1 and 2, this chapter contains some material usually found in an earlier
course; proofs of such results are only sketched, but other theorems are proved in full.
We begin by introducing commutative rings, the most prominent examples being Z, Q,
R, and C, as well as Im, polynomials, real-valued functions, and Ô¨Ånite Ô¨Åelds. We will
also give some of the Ô¨Årst results about vector spaces (with scalars in any Ô¨Åeld) and linear
transformations. Canonical forms, which classify similar matrices, will be discussed in
Chapter 9.
3.2 FIRST PROPERTIES
We begin with the deÔ¨Ånition of commutative ring.
DeÔ¨Ånition.
A commutative ring1 R is a set with two binary operations, addition and
multiplication, such that
(i) R is an abelian group under addition;
(ii) (commutativity) ab = ba for all a, b ‚ààR;
(iii) (associativity) a(bc) = (ab)c for every a, b, c ‚ààR;
1This term was probably coined by D. Hilbert, in 1897, when he wrote Zahlring. One of the meanings of the
word ring, in German as in English, is collection, as in the phrase "a ring of thieves." (It has also been suggested
that Hilbert used this term because, for a ring of algebraic integers, an appropriate power of each element "cycles
back" to being a linear combination of lower powers.)
116

Sec. 3.2
First Properties
117
(iv) there is an element 1 ‚ààR with 1a = a for every a ‚ààR;2
(v) (distributivity) a(b + c) = ab + ac for every a, b, c ‚ààR.
The element 1 in a ring R has several names; it is called one, the unit of R, or the
identity in R.
Addition and multiplication in a commutative ring R are binary operations, so there are
functions
Œ± : R √ó R ‚ÜíR
with
Œ±(r,r‚Ä≤) = r + r‚Ä≤ ‚ààR
and
¬µ : R √ó R ‚ÜíR
with
¬µ(r,r‚Ä≤) = rr‚Ä≤ ‚ààR
for all r,r‚Ä≤ ‚ààR. The law of substitution holds here, as it does for any operation: If r = r‚Ä≤
and s = s‚Ä≤, then r + s = r‚Ä≤ + s‚Ä≤ and rs = r‚Ä≤s‚Ä≤.
Example 3.1.
(i) Z, Q, R, and C are commutative rings with the usual addition and multiplication (the
ring axioms are veriÔ¨Åed in courses in the foundations of mathematics).
(ii) Im, the integers mod m, is a commutative ring.
(iii) Let Z[i] be the set of all complex numbers of the form a + bi, where a, b ‚ààZ and
i2 = ‚àí1. It is a boring exercise to check that Z[i] is, in fact, a commutative ring (this
exercise will be signiÔ¨Åcantly shortened, in Exercise 3.8 on page 124, once the notion of
subring has been introduced). Z[i] is called the ring of Gaussian integers.
(iv) Consider the set R of all real numbers x of the form
x = a + bœâ,
where a, b ‚ààQ and œâ =
3‚àö
2. It is easy to see that R is closed under ordinary addition.
However, if R is closed under multiplication, then œâ2 ‚ààR, and there are rationals a and b
with
œâ2 = a + bœâ.
Multiplying both sides by œâ and by b gives the equations
2 = aœâ + bœâ2
bœâ2 = ab + b2œâ.
Hence, 2 ‚àíaœâ = ab + b2œâ, and so
2 ‚àíab = (b2 + a)œâ.
If b2 + a Ã∏= 0, then œâ =
3‚àö
2 is rational; if b2 + a = 0, then this coupled with 2 ‚àíab = 0
yields 2 = (‚àíb)3. Thus, either case forces
3‚àö
2 rational, and this contradiction shows that
R is not a commutative ring.
‚óÄ
2Some authors do not demand that commutative rings have 1. For them, the set of all even integers is a
commutative ring, but we do not recognize it as such.

118
Commutative Rings I
Ch. 3
Remark.
There are noncommutative rings; that is, sets having an addition and a mul-
tiplication satisfying all the axioms of a commutative ring except the axiom: ab = ba.
[Actually, the deÔ¨Ånition replaces the axiom 1a = a by 1a = a = a1, and it replaces the
distributive law by two distributive laws, one on either side: a(b + c) = ab + ac and
(b + c)a = ba + ca.] For example, it is easy to see that the set of all n √ó n real matrices,
equipped with the usual addition and multiplication, satisÔ¨Åes all the new ring axioms. We
shall study noncommutative rings in Chapter 8.
‚óÄ
Here are some elementary results.
Proposition 3.2.
Let R be a commutative ring.
(i) 0 ¬∑ a = 0 for every a ‚ààR.
(ii) If 1 = 0, then R consists of the single element 0. In this case, R is called the zero
ring.3
(iii) If ‚àía is the additive inverse of a, then (‚àí1)(‚àía) = a.
(iv) (‚àí1)a = ‚àía for every a ‚ààR.
(v) If n ‚ààN and n1 = 0, then na = 0 for all a ‚ààR.
(vi) The binomial theorem holds: If a, b ‚ààR, then
(a + b)n =
n

r=0
n
r
	
arbn‚àír.
Sketch of Proof.
(i) 0 ¬∑ a = (0 + 0) ¬∑ a = 0 ¬∑ a + 0 ¬∑ a.
(ii) a = 1 ¬∑ a = 0 ¬∑ a = 0.
(iii) 0 = (‚àí1 + 1)(‚àía) = (‚àí1)(‚àía) + (‚àía).
(iv) Since (‚àí1)(‚àía) = a, we have (‚àí1)(‚àí1)(‚àía) = (‚àí1)a. But (‚àí1)(‚àí1) = 1.
(v) In Chapter 2, we deÔ¨Åned the powers an of an element in a group, where n ‚â•0. In an
additive group, na is a more appropriate notation than an, and the notation na, for n ‚ààZ
and a ‚ààR, has this meaning in R; that is, na is the sum of a with itself n times.
If a ‚ààR and n ‚ààZ is positive, then n1 = 0 implies
na = n(1a) = (n1)a = 0a = 0.
(vi) Induction on n ‚â•0 using the identity
n+1
r

=
 n
r‚àí1

+
n
r

for 0 < r < n + 1. (We
agree that a0 = 1 for all a ‚ààR, even for a = 0.)
‚Ä¢
A subring S of a commutative ring R is a commutative ring contained in a larger com-
mutative ring R so that S and R have the same addition, multiplication, and unit.
3The zero ring is not a very interesting ring, but it does arise occasionally.

Sec. 3.2
First Properties
119
DeÔ¨Ånition.
A subset S of a commutative ring R is a subring of R if
(i) 1 ‚ààS;4
(ii) if a, b ‚ààS, then a ‚àíb ‚ààS;
(iii) if a, b ‚ààS, then ab ‚ààS.
Notation.
In contrast to the usage H ‚â§G for a subgroup, the tradition in ring theory is
to write S ‚äÜR for a subring. We shall also write S ‚ääR to denote a proper subring; that
is, S ‚äÜR and S Ã∏= R.
Proposition 3.3.
A subring S of a commutative ring R is itself a commutative ring.
Sketch of Proof.
The Ô¨Årst condition says that S is a subgroup of the additive group R. The
other conditions are identities that hold for all elements in R, and hence hold, in particular,
in S. For example, associativity a(bc) = (ab)c holds for all a, b, c ‚ààR, and so it holds, in
particular, for all a, b, c ‚ààS ‚äÜR.
‚Ä¢
Of course, one advantage of the notion of subring is that fewer ring axioms need to be
checked to determine whether a subset of a commutative ring is itself a commutative ring.
Exercise 3.4 on page 124 gives a natural example of a commutative ring S contained in
a commutative ring R in which both S and R have the same addition and multiplication,
but whose units are distinct (and so S is not a subring of R).
Example 3.4.
If n ‚â•3 is an integer, let Œ∂n = e2œÄi/n be a primitive nth root of unity, and deÔ¨Åne
Z[Œ∂n] = {z ‚ààC : z = a0 + a1Œ∂n + a2Œ∂ 2
n + ¬∑ ¬∑ ¬∑ + an‚àí1Œ∂ n‚àí1
n
, all ai ‚ààZ}.
(When n = 4, then Z[Œ∂4] is the Gaussian integers Z[i].) It is easy to check that Z[Œ∂n] is a
subring of C (to prove that Z[Œ∂n] is closed under multiplication, note that if m ‚â•n, then
m = qn + r, where 0 ‚â§r < n, and Œ∂ m
n = Œ∂r
n ).
‚óÄ
DeÔ¨Ånition.
A domain (often called an integral domain) is a commutative ring R that
satisÔ¨Åes two extra axioms: Ô¨Årst,
1 Ã∏= 0;
second, the cancellation law for multiplication: For all a, b, c ‚ààR,
if ca = cb and c Ã∏= 0, then a = b.
The familiar examples of commutative rings, Z, Q, R, and C, are domains; the zero ring
is not a domain.
4The even integers do not form a subring of Z because 1 is not even. Their special structure will be recognized
when ideals are introduced.

120
Commutative Rings I
Ch. 3
Proposition 3.5.
A nonzero commutative ring R is a domain if and only if the product of
any two nonzero elements of R is nonzero.
Sketch of Proof.
ab = ac if and only if a(b ‚àíc) = 0.
‚Ä¢
Proposition 3.6.
The commutative ring Im is a domain if and only if m is a prime.
Proof.
If m = ab, where 1 < a, b < m, then [a] Ã∏= [0] and [b] Ã∏= [0] in Im, yet
[a][b] = [m] = [0].
Conversely, if m is prime and [a][b] = [ab] = [0], then m | ab, and Euclid's lemma
gives m | a or m | b.
‚Ä¢
Example 3.7.
(i) Let F(R) be the set of all the functions R ‚ÜíR equipped with the operations of point-
wise addition and pointwise multiplication: Given f, g ‚ààF(R), deÔ¨Åne functions f + g
and f g by
f + g : a ‚Üíf (a) + g(a)
and
f g : a ‚Üíf (a)g(a)
(notice that f g is not their composite).
We claim that F(R) with these operations is a commutative ring. VeriÔ¨Åcation of the
axioms is left to the reader with the following hint: The zero element in F(R) is the
constant function z with value 0 [that is, z(a) = 0 for all a ‚ààR] and the unit is the
constant function Œµ with Œµ(a) = 1 for all a ‚ààR. We now show that F(R) is not a domain.
x
x
y
f
g
y
Figure 3.1
DeÔ¨Åne f and g as drawn in Figure 3.1:
f (a) =

a
if a ‚â§0
0
if a ‚â•0;
g(a) =

0
if a ‚â§0
a
if a ‚â•0.
Clearly, neither f nor g is zero (i.e., f Ã∏= z and g Ã∏= z). On the other hand, for each a ‚ààR,
f g : a ‚Üíf (a)g(a) = 0, because at least one of the factors f (a) or g(a) is the number
zero. Therefore, f g = z, by Proposition 1.43, and F(R) is not a domain.

Sec. 3.2
First Properties
121
(ii) All differentiable functions f : R ‚ÜíR form a subring of F(R). The identity Œµ is
a constant function, hence is differentiable, while the sum and product of differentiable
functions are also differentiable. Hence, the differentiable functions form a commutative
ring.
‚óÄ
Many theorems of ordinary arithmetic, that is, properties of the commutative ring Z,
hold in more generality. We now generalize some familiar deÔ¨Ånitions from Z to arbitrary
commutative rings.
DeÔ¨Ånition.
Let a and b be elements of a commutative ring R. Then a divides b in R (or
a is a divisor of b or b is a multiple of a), denoted by a | b, if there exists an element c ‚ààR
with b = ca.
As an extreme example, if 0 | a, then a = 0 ¬∑ b for some b ‚ààR. Since 0 ¬∑ b = 0,
however, we must have a = 0. Thus, 0 | a if and only if a = 0.
Notice that whether a | b depends not only on the elements a and b but on the ambient
ring R as well. For example, 3 does divide 2 in Q, for 2 = 3 √ó 2
3, and 2
3 ‚ààQ; on the other
hand, 3 does not divide 2 in Z, because there is no integer c with 3c = 2.
DeÔ¨Ånition.
An element u in a commutative ring R is called a unit if u | 1 in R, that is,
if there exists v ‚ààR with uv = 1; the element v is called the inverse of u and v is often
denoted by u‚àí1.
Units are of interest because we can always divide by them: If a ‚ààR and u is a unit in
R (so there is v ‚ààR with uv = 1), then
a = u(va)
is a factorization of a in R, for va ‚ààR; thus, it is reasonable to deÔ¨Åne the quotient a/u as
va = u‚àí1a.
Given elements a and b, whether a | b depends not only on these elements but also
on the ambient ring R; similarly, whether an element u ‚ààR is a unit also depends on the
ambient ring R (for it is a question whether u | 1 in R). For example, the number 2 is a
unit in Q, for 1
2 lies in Q and 2 √ó 1
2 = 1, but 2 is not a unit in Z, because there is no integer
v with 2v = 1. In fact, the only units in Z are 1 and ‚àí1.
Proposition 3.8.
Let R be a domain, and let a, b ‚ààR be nonzero. Then a | b and b | a if
and only if b = ua for some unit u ‚ààR.
Sketch of Proof.
If b = ua and a = vb, then b = ua = uvb.
‚Ä¢
There exist examples of commutative rings in which Proposition 3.8 is false, and so the
hypothesis that R be a domain is needed.
What are the units in Im?

122
Commutative Rings I
Ch. 3
Proposition 3.9.
If a is an integer, then [a] is a unit in Im if and only if a and m are
relatively prime. In fact, if sa + tm = 1, then [a]‚àí1 = [s].
Sketch of Proof.
sa ‚â°1 mod m if and only if sa + tm = 1 for some integer t.
‚Ä¢
Corollary 3.10.
If p is a prime, then every nonzero [a] in Ip is a unit.
Sketch of Proof.
If 1 ‚â§a < p, then (a, p) = 1.
‚Ä¢
DeÔ¨Ånition.
If R is a commutative ring, then the group of units of R is
U(R) = {all units in R}.
It is easy to check that U(R) is a multiplicative group. It follows that a unit u in R has
exactly one inverse in R, for each element in a group has a unique inverse.
There is an obvious difference between Q and Z: every nonzero element of Q is a unit.
DeÔ¨Ånition.
A Ô¨Åeld5 F is a commutative ring in which 1 Ã∏= 0 and every nonzero element
a is a unit; that is, there is a‚àí1 ‚ààF with a‚àí1a = 1.
The Ô¨Årst examples of Ô¨Åelds are Q, R, and C.
The deÔ¨Ånition of Ô¨Åeld can be restated in terms of the group of units; a commutative ring
R is a Ô¨Åeld if and only if U(R) = R√ó, the nonzero elements of R. To say this another way,
R is a Ô¨Åeld if and only if R√ó is a multiplicative group [note that U(R√ó) Ã∏= ‚àÖbecause we
are assuming that 1 Ã∏= 0].
Proposition 3.11.
Every Ô¨Åeld F is a domain.
Sketch of Proof.
If ab = ac and a Ã∏= 0, then b = a‚àí1(ab) = a‚àí1(ac) = c.
‚Ä¢
The converse of this proposition is false, for Z is a domain that is not a Ô¨Åeld.
Proposition 3.12.
The commutative ring Im is a Ô¨Åeld if and only if m is prime.
Sketch of Proof.
Corollary 3.10.
‚Ä¢
In Theorem 3.127, we shall see that there are Ô¨Ånite Ô¨Åelds having exactly pn elements,
whenever p is prime and n ‚â•1; in Exercise 3.14 on page 125, we construct a Ô¨Åeld with
four elements.
Every subring of a domain is itself a domain. Since Ô¨Åelds are domains, it follows that
every subring of a Ô¨Åeld is a domain. The converse of this exercise is true, and it is much
more interesting: Every domain is a subring of a Ô¨Åeld.
5The derivation of the mathematical usage of the English term Ô¨Åeld (Ô¨Årst used by E. H. Moore in 1893 in
his article classifying the Ô¨Ånite Ô¨Åelds) as well as the German term K¬®orper and the French term corps is probably
similar to the derivation of the words group and ring: Each word denotes a "realm" or a "collection of things." The
word domain abbreviates the usual English translation integral domain of the German word Integret¬®atsbereich, a
collection of integers.

Sec. 3.2
First Properties
123
Given four elements a, b, c, and d in a Ô¨Åeld F with b Ã∏= 0 and d Ã∏= 0, assume that
ab‚àí1 = cd‚àí1. Multiply both sides by bd to obtain ad = bc. In other words, were
ab‚àí1 written as a/b, then we have just shown that a/b = c/d implies ad = bc; that is,
"cross-multiplication" is valid. Conversely, if ad = bc and both b and d are nonzero, then
multiplication by b‚àí1d‚àí1 gives ab‚àí1 = cd‚àí1, that is, a/b = c/d.
The proof of the next theorem is a straightforward generalization of the usual construc-
tion of the Ô¨Åeld of rational numbers Q from the domain of integers Z.
Theorem 3.13.
If R is a domain, then there is a Ô¨Åeld F containing R as a subring.
Moreover, F can be chosen so that, for each f ‚ààF, there are a, b ‚ààR with b Ã∏= 0 and
f = ab‚àí1.
Sketch of Proof.
Let X = {(a, b) ‚ààR √ó R : b Ã∏= 0}, and deÔ¨Åne a relation ‚â°on X by
(a, b) ‚â°(c, d) if ad = bc. We claim that ‚â°is an equivalence relation. VeriÔ¨Åcations of
reÔ¨Çexivity and symmetry are straightforward; here is the proof of transitivity. If (a, b) ‚â°
(c, d) and (c, d) ‚â°(e, f ), then ad = bc and cf = de. But ad = bc gives ad f = b(cf ) =
bde. Canceling d, which is nonzero, gives af = be; that is, (a, b) ‚â°(e, f ).
Denote the equivalence class of (a, b) by [a, b], deÔ¨Åne F as the set of all equivalence
classes [a, b], and equip F with the following addition and multiplication (if we pretend
that [a, b] is the fraction a/b, then these are just the usual formulas):
[a, b] + [c, d] = [ad + bc, bd]
and
[a, b][c, d] = [ac, bd].
First, since b Ã∏= 0 and d Ã∏= 0, we have bd Ã∏= 0, because R is a domain, and so the
formulas make sense. Let us show that addition is well-deÔ¨Åned. If [a, b] = [a‚Ä≤, b‚Ä≤] (that is,
ab‚Ä≤ = a‚Ä≤b) and [c, d] = [c‚Ä≤, d‚Ä≤] (that is, cd‚Ä≤ = c‚Ä≤d), then we must show that [ad+bc, bd] =
[a‚Ä≤d‚Ä≤ + b‚Ä≤c‚Ä≤, b‚Ä≤d‚Ä≤]. But this is true:
(ad + bc)b‚Ä≤d‚Ä≤ = ab‚Ä≤dd‚Ä≤ + bb‚Ä≤cd‚Ä≤ = a‚Ä≤bdd‚Ä≤ + bb‚Ä≤c‚Ä≤d = (a‚Ä≤d‚Ä≤ + b‚Ä≤c‚Ä≤)bd.
A similar argument shows that multiplication is well-deÔ¨Åned.
The veriÔ¨Åcation that F is a commutative ring is now routine: The zero element is [0, 1],
the one is [1, 1], and the additive inverse of [a, b] is [‚àía, b]. It is easy to see that the family
R‚Ä≤ = {[a, 1] : a ‚ààR} is a subring of F, and we identify a ‚ààR with [a, 1] ‚ààR‚Ä≤.
To see that F is a Ô¨Åeld, observe that if [a, b] Ã∏= [0, 1], then a Ã∏= 0, and the inverse of
[a, b] is [b, a].
Finally, if b Ã∏= 0, then [1, b] = [b, 1]‚àí1, and so [a, b] = [a, 1][b, 1]‚àí1.
‚Ä¢
DeÔ¨Ånition.
The Ô¨Åeld F constructed from R in Theorem 3.13 is called the fraction Ô¨Åeld
of R; we denote it by Frac(R), and we denote [a, b] ‚ààFrac(R) by a/b; in particular, the
elements [a, 1] of R‚Ä≤ are denoted by a/1 or, more simply, by a.
Notice that the fraction Ô¨Åeld of Z is Q; that is, Frac(Z) = Q.

124
Commutative Rings I
Ch. 3
DeÔ¨Ånition.
A subÔ¨Åeld of a Ô¨Åeld K is a subring k of K that is also a Ô¨Åeld.
It is easy to see that a subset k of a Ô¨Åeld K is a subÔ¨Åeld if and only if k is a subring that
is closed under inverses; that is, if a ‚ààk and a Ã∏= 0, then a‚àí1 ‚ààk. It is also routine to see
that any intersection of subÔ¨Åelds of K is itself a subÔ¨Åeld of K (note that the intersection is
not equal to {0} because 1 lies in every subÔ¨Åeld).
EXERCISES
3.1 Prove that a commutative ring R has a unique 1.
3.2
(i) Prove that subtraction in Z is not an associative operation.
(ii) Give an example of a commutative ring R in which subtraction is associative.
3.3
(i) If R is a domain and a ‚ààR satisÔ¨Åes a2 = a, prove that either a = 0 or a = 1.
(ii) Show that the commutative ring F(R) in Example 3.7 contains inÔ¨Ånitely many elements
f Ã∏= 0, 1 with f 2 = f .
3.4
(i) If X is a set, prove that the Boolean group B(X) in Example 2.18 with elements the
subsets of X and with addition given by
U + V = (U ‚àíV ) ‚à™(V ‚àíU),
where U ‚àíV = {x ‚ààU : x /‚ààV }, is a commutative ring if one deÔ¨Ånes multiplication
UV = U ‚à©V.
We call B(X) a Boolean ring.
Hint.
You may use some standard facts of set theory:
the distributive law:
U ‚à©(V ‚à™W) = (U ‚à©V ) ‚à™(U ‚à©W); if V ‚Ä≤ denotes the complement of V , then
U ‚àíV = U ‚à©V ‚Ä≤; and the De Morgan law: (U ‚à©V )‚Ä≤ = U‚Ä≤ ‚à™V ‚Ä≤.
(ii) Prove that B(X) contains exactly one unit.
(iii) If Y is a proper subset of X (that is, Y ‚ääX), show that the unit in B(Y) is distinct from
the unit in B(X). Conclude that B(Y) is not a subring of B(X).
3.5 Show that U(Im) = {[k] ‚ààIm : (k, m) = 1}.
3.6 Find all the units in the commutative ring F(R) deÔ¨Åned in Example 3.7.
3.7 Generalize the construction of F(R) to arbitrary commutative rings R: Let F(R) be the set of
all functions from R to R, with pointwise addition, f + g: r ‚Üíf (r) + g(r), and pointwise
multiplication, f g: r ‚Üíf (r)g(r) for r ‚ààR.
(i) Show that F(R) is a commutative ring.
(ii) Show that F(R) is not a domain.
(iii) Show that F(I2) has exactly four elements, and that f + f = 0 for every f ‚ààF(I2).
3.8
(i) If R is a domain and S is a subring of R, then S is a domain.
(ii) Prove that C is a domain, and conclude that the ring of Gaussian integers is a domain.
3.9 Prove that the only subring of Z is Z itself.
Hint. Every subring R of Z contains 1.

Sec. 3.2
First Properties
125
3.10
(i) Prove that R = {a + b
‚àö
2 : a, b ‚ààZ} is a domain.
(ii) Prove that R = { 1
2(a + b
‚àö
2) : a, b ‚ààZ} is not a domain.
(iii) Using the fact that Œ± = 1
2(1 +
‚àö
‚àí19) is a root of x2 ‚àíx + 5, prove that R = {a + bŒ± :
a, b ‚ààZ} is a domain.
3.11 Prove that the set of all C‚àû-functions is a subring of F(R). (A function f : R ‚ÜíR is a
C‚àû-function if it has an nth derivative f (n) for every n ‚â•1.)
Hint. Use the Leibniz rule (see Exercise 1.6 on page 12).
3.12
(i) If R is a commutative ring, deÔ¨Åne the circle operation a ‚ó¶b by
a ‚ó¶b = a + b ‚àíab.
Prove that the circle operation is associative and that 0 ‚ó¶a = a for all a ‚ààR.
(ii) Prove that a commutative ring R is a Ô¨Åeld if and only if {r ‚ààR : r Ã∏= 1} is an abelian
group under the circle operation.
Hint. If a Ã∏= 0, then a + 1 Ã∏= 1.
3.13 Find the inverses of the nonzero elements of I11.
3.14 (R. A. Dean) DeÔ¨Åne F4 to be all 2 √ó 2 matrices of the form
a
b
b
a + b

,
where a, b ‚ààI2.
(i) Prove that F4 is a commutative ring under the usual matrix operations of addition and
multiplication.
(ii) Prove that F4 is a Ô¨Åeld with exactly four elements.
3.15 Prove that every domain R with a Ô¨Ånite number of elements must be a Ô¨Åeld. (Using Proposi-
tion 3.6, this gives a new proof of sufÔ¨Åciency in Proposition 3.12.)
Hint.
If R√ó denotes the set of nonzero elements of R, prove that multiplication by r is an
injection R√ó ‚ÜíR√ó, where r ‚ààR√ó.
3.16 Show that F = {a + b
‚àö
2 : a, b ‚ààQ} is a Ô¨Åeld.
3.17
(i) Show that F = {a + bi : a, b ‚ààQ} is a Ô¨Åeld.
(ii) Show that F is the fraction Ô¨Åeld of the Gaussian integers.
3.18 If R is a commutative ring, deÔ¨Åne a relation ‚â°on R by a ‚â°b if there is a unit u ‚ààR with
b = ua. Prove that if a ‚â°b, then (a) = (b), where (a) = {ra : r ‚ààR}. Conversely, prove
that if R is a domain, then (a) = (b) implies a ‚â°b.
3.19
(i) For any Ô¨Åeld k, prove that stochastic group (2, k), the set of all nonsingular 2 √ó 2 ma-
trices with entries in k whose column sums are 1, is a group under matrix multiplication.
(ii) DeÔ¨Åne the afÔ¨Åne group Aff(1, k) to be the set of all f : k ‚Üík of the form f (x) =
ax + b, where a, b ‚ààk and a Ã∏= 0. Prove that (2, k) ‚àº= Aff(1, k). (See Exercise 2.46
on page 80.)
(iii) If k is a Ô¨Ånite Ô¨Åeld with q elements, prove that |(2, k)| = q(q ‚àí1).
(iv) Prove that (2, I3) ‚àº= S3.

126
Commutative Rings I
Ch. 3
3.3 POLYNOMIALS
Even though the reader is familiar with polynomials, we now introduce them carefully. The
key observation is that one should pay attention to where the coefÔ¨Åcients of polynomials
live.
DeÔ¨Ånition.
If R is a commutative ring, then a sequence œÉ in R is
œÉ = (s0, s1, s2, . . . , si, . . . );
the entries si ‚ààR, for all i ‚â•0, are called the coefÔ¨Åcients of œÉ.
To determine when two sequences are equal, let us recognize that a sequence œÉ is really
a function œÉ : N ‚ÜíR, where N is the set of natural numbers, with œÉ(i) = si for all i ‚â•0.
Thus, if œÑ = (t0, t1, t2, . . . , ti, . . . ) is a sequence, then œÉ = œÑ if and only if œÉ(i) = œÑ(i)
for all i ‚â•0; that is, œÉ = œÑ if and only if si = ti for all i ‚â•0.
DeÔ¨Ånition.
A sequence œÉ = (s0, s1, . . . , si, . . . ) in a commutative ring R is called a
polynomial if there is some integer m ‚â•0 with si = 0 for all i > m; that is,
œÉ = (s0, s1, . . . , sm, 0, 0, . . . ).
A polynomial has only Ô¨Ånitely many nonzero coefÔ¨Åcients.
The zero polynomial,
denoted by œÉ = 0, is the sequence œÉ = (0, 0, 0, . . . ).
DeÔ¨Ånition.
If œÉ = (s0, s1, . . . , sn, 0, 0, . . . ) Ã∏= 0 is a polynomial, then there is sn Ã∏= 0
with si = 0 for all i > n. We call sn the leading coefÔ¨Åcient of œÉ, we call n the degree of
œÉ, and we denote the degree n by deg(œÉ).
The zero polynomial 0 does not have a degree because it has no nonzero coefÔ¨Åcients.
Some authors deÔ¨Åne deg(0) = ‚àí‚àû, and this is sometimes convenient, for ‚àí‚àû< n for
every integer n. On the other hand, we choose not to assign a degree to 0 because it is often
a genuinely different case that must be dealt with separately.
Notation.
If R is a commutative ring, then the set of all polynomials with coefÔ¨Åcients in
R is denoted by R[x].
Proposition 3.14.
If R is a commutative ring, then R[x] is a commutative ring that
contains R as a subring.
Sketch of Proof.
DeÔ¨Åne addition and multiplication of polynomials as follows: If œÉ =
(s0, s1, . . .) and œÑ = (t0, t1, . . .), then
œÉ + œÑ = (s0 + t0, s1 + t1, . . . , sn + tn, . . .)
and
œÉœÑ = (c0, c1, c2, . . .),

Sec. 3.3
Polynomials
127
where ck = 
i+ j=k sit j = k
i=0 sitk‚àíi. VeriÔ¨Åcation of the axioms in the deÔ¨Ånition of
commutative ring is routine. The subset {(r, 0, 0, . . .) : r ‚ààR} is a subring of R[x] that we
identify with R.
‚Ä¢
Lemma 3.15.
Let R be a commutative ring and let œÉ, œÑ ‚ààR[x] be nonzero polynomials.
(i) Either œÉœÑ = 0 or deg(œÉœÑ) ‚â§deg(œÉ) + deg(œÑ).
(ii) If R is a domain, then œÉœÑ Ã∏= 0 and
deg(œÉœÑ) = deg(œÉ) + deg(œÑ).
(iii) If R is a domain, then R[x] is a domain.
Sketch of Proof.
Let œÉ = (s0, s1, . . .) and œÑ = (t0, t1, . . .) have degrees m and n, respec-
tively.
(i) If k > m + n, then each term in 
i sitk‚àíi is 0 (for either si = 0 or tk‚àíi = 0).
(ii) Each term in 
i sitm+n‚àíi is 0, with the possible exception of smtn. Since R is a
domain, sm Ã∏= 0 and tn Ã∏= 0 imply smtn Ã∏= 0.
(iii) This follows from part (ii) because the product of two nonzero polynomials is now
nonzero.
‚Ä¢
DeÔ¨Ånition.
If R is a commutative ring, then R[x] is called the ring of polynomials
over R.
Here is the link between this discussion and the usual notation.
DeÔ¨Ånition.
DeÔ¨Åne the element x ‚ààR[x] by
x = (0, 1, 0, 0, . . . ).
Lemma 3.16.
(i) If œÉ = (s0, s1, . . . ), then
xœÉ = (0, s0, s1, . . . );
that is, multiplying by x shifts each coefÔ¨Åcient one step to the right.
(ii) If n ‚â•1, then xn is the polynomial having 0 everywhere except for 1 in the nth
coordinate.
(iii) If r ‚ààR, then
(r, 0, 0, . . . )(s0, s1, . . . , s j, . . . ) = (rs0,rs1, . . . ,rs j, . . . ).
Sketch of Proof.
Each is a routine computation using the deÔ¨Ånition of polynomial multi-
plication.
‚Ä¢

128
Commutative Rings I
Ch. 3
If we identify (r, 0, 0, . . . ) with r, then Lemma 3.16(iii) reads
r(s0, s1, . . . , si, . . . ) = (rs0,rs1, . . . ,rsi, . . . ).
We can now recapture the usual notation.
Proposition 3.17.
If œÉ = (s0, s1, . . . , sn, 0, 0, . . . ), then
œÉ = s0 + s1x + s2x2 + ¬∑ ¬∑ ¬∑ + snxn,
where each element s ‚ààR is identiÔ¨Åed with the polynomial (s, 0, 0, . . . ).
Proof.
œÉ = (s0, s1, . . . , sn, 0, 0, . . . )
= (s0, 0, 0, . . . ) + (0, s1, 0, . . . ) + ¬∑ ¬∑ ¬∑ + (0, 0, . . . , sn, 0, . . . )
= s0(1, 0, 0, . . . ) + s1(0, 1, 0, . . . ) + ¬∑ ¬∑ ¬∑ + sn(0, 0, . . . , 1, 0, . . . )
= s0 + s1x + s2x2 + ¬∑ ¬∑ ¬∑ + snxn.
‚Ä¢
We shall use this familiar (and standard) notation from now on. As is customary, we
shall write
f (x) = s0 + s1x + s2x2 + ¬∑ ¬∑ ¬∑ + snxn
instead of œÉ = (s0, s1, . . . , sn, 0, 0, . . . ).
Here is some standard vocabulary associated with polynomials. If f (x) = s0 + s1x +
s2x2 +¬∑ ¬∑ ¬∑+snxn, where sn Ã∏= 0, then s0 is called its constant term and, as we have already
said, sn is called its leading coefÔ¨Åcient. If its leading coefÔ¨Åcient sn = 1, then f (x) is called
monic. Every polynomial other than the zero polynomial 0 (having all coefÔ¨Åcients 0) has
a degree. A constant polynomial is either the zero polynomial or a polynomial of degree
0. Polynomials of degree 1, namely, a + bx with b Ã∏= 0, are called linear, polynomials of
degree 2 are quadratic,6 degree 3's are cubic, then quartics, quintics, and so on.
Corollary 3.18.
Polynomials f (x) = s0 + s1x + s2x2 + ¬∑ ¬∑ ¬∑ + snxn and g(x) = t0 +
t1x + t2x2 + ¬∑ ¬∑ ¬∑ + tmxm of degrees n and m, respectively, are equal if and only if n = m
and si = ti for all i.
Proof.
This is merely a restatement of the deÔ¨Ånition of equality of sequences, rephrased
in the usual notation for polynomials.
‚Ä¢
6Quadratic polynomials are so called because the particular quadratic x2 gives the area of a square (quadratic
comes from the Latin word meaning "four," which is to remind us of the four-sided Ô¨Ågure); similarly, cubic
polynomials are so called because x3 gives the volume of a cube. Linear polynomials are so called because the
graph of a linear polynomial in R[x] is a line.

Sec. 3.3
Polynomials
129
We can now describe the usual role of x in f (x) as a variable. If R is a commutative ring,
each polynomial f (x) = s0+s1x+s2x2+¬∑ ¬∑ ¬∑+snxn ‚ààR[x] deÔ¨Ånes a polynomial function
f : R ‚ÜíR by evaluation: If a ‚ààR, deÔ¨Åne f (a) = s0 + s1a + s2a2 + ¬∑ ¬∑ ¬∑ + snan ‚ààR. The
reader should realize that polynomials and polynomial functions are distinct objects. For
example, if R is a Ô¨Ånite ring (e.g., R = Im), then there are only Ô¨Ånitely many functions from
R to itself, and so there are only Ô¨Ånitely many polynomial functions. On the other hand,
there are inÔ¨Ånitely many polynomials: for example, all the powers 1, x, x2, . . . , xn, . . . are
distinct, by Corollary 3.18.
DeÔ¨Ånition.
Let k be a Ô¨Åeld. The fraction Ô¨Åeld of k[x], denoted by k(x), is called the Ô¨Åeld
of rational functions over k.
Proposition 3.19.
If k is a Ô¨Åeld, then the elements of k(x) have the form f (x)/g(x),
where f (x), g(x) ‚ààk[x] and g(x) Ã∏= 0.
Sketch of Proof.
Theorem 3.13.
‚Ä¢
Proposition 3.20.
If p is a prime, then the Ô¨Åeld of rational functions Ip(x) is an inÔ¨Ånite
Ô¨Åeld containing Ip as a subÔ¨Åeld.7
Proof.
By Lemma 3.15(iii), Ip[x] is an inÔ¨Ånite domain, for the powers xn, for n ‚ààN,
are distinct. Thus, its fraction Ô¨Åeld, Ip(x), is an inÔ¨Ånite Ô¨Åeld containing Ip[x] as a subring.
But Ip[x] contains Ip as a subring, by Proposition 3.14.
‚Ä¢
In spite of the difference between polynomials and polynomial functions (we shall see,
in Corollary 3.28, that these objects coincide when the coefÔ¨Åcient ring R is an inÔ¨Ånite
Ô¨Åeld), R[x] is often called the ring of all polynomials over R in one variable. If we write
A = R[x], then the polynomial ring A[y] is called the ring of all polynomials over R
in two variables x and y, and it is denoted by R[x, y]. For example, the quadratic poly-
nomial ax2 + bxy + cy2 + dx + ey + f can be written cy2 + (bx + e)y + (ax2 +
dx + f ), a polynomial in y with coefÔ¨Åcients in R[x]. By induction, we can form the
commutative ring R[x1, x2, . . . , xn] of all polynomials in n variables with coefÔ¨Åcients
in R. Lemma 3.15(iii) can now be generalized, by induction on n, to say that if R is
a domain, then so is R[x1, x2, . . . , xn]. Moreover, when k is a Ô¨Åeld, we can describe
Frac(k[x1, x2, . . . , xn]) as all rational functions in n variables; its elements have the form
f (x1, x2, . . . , xn)/g(x1, x2, . . . , xn), where f and g lie in k[x1, x2, . . . , xn].
EXERCISES
3.20 Show that if R is a commutative ring, then R[x] is never a Ô¨Åeld.
Hint. If x‚àí1 exists, what is its degree?
7In the future, we will denote Ip by Fp when it is to be viewed as a Ô¨Åeld.

130
Commutative Rings I
Ch. 3
3.21
(i) If R is a domain, show that if a polynomial in R[x] is a unit, then it is a nonzero constant
(the converse is true if R is a Ô¨Åeld).
Hint. Compute degrees.
(ii) Show that (2x + 1)2 = 1 in I4[x]. Conclude that the hypothesis in part (i) that R be a
domain is necessary.
3.22 Show that the polynomial function deÔ¨Åned by f (x) = x p ‚àíx ‚ààIp[x] is identically zero.
Hint. Use Fermat's theorem.
3.23 If R is a commutative ring and f (x) =  n
i=0 si xi ‚ààR[x] has degree n ‚â•1, deÔ¨Åne its
derivative f ‚Ä≤(x) ‚ààR[x] by
f ‚Ä≤(x) = s1 + 2s2x + 3s3x2 + ¬∑ ¬∑ ¬∑ + nsnxn‚àí1;
if f (x) is a constant polynomial, deÔ¨Åne its derivative to be the zero polynomial. Prove that the
usual rules of calculus hold:
( f + g)‚Ä≤ = f ‚Ä≤ + g‚Ä≤;
(r f )‚Ä≤ = r( f ‚Ä≤)
if r ‚ààR;
( f g)‚Ä≤ = f g‚Ä≤ + f ‚Ä≤g;
( f n)‚Ä≤ = nf n‚àí1 f ‚Ä≤
for all n ‚â•1.
3.24 Let R be a commutative ring and let f (x) ‚ààR[x].
(i) Prove that if (x ‚àía)2 | f (x), then x ‚àía | f ‚Ä≤(x) in R[x].
(ii) Prove that if x ‚àía | f (x) and x ‚àía | f ‚Ä≤(x), then (x ‚àía)2 | f (x).
3.25
(i) If f (x) = ax2p + bx p + c ‚ààIp[x], prove that f ‚Ä≤(x) = 0.
(ii) Prove that a polynomial f (x) ‚ààIp[x] has f ‚Ä≤(x) = 0 if and only if there is a polynomial
g(x) =  anxn with f (x) = g(x p); that is, f (x) =  anxnp ‚ààIp[x p].
3.26 If R is a commutative ring, deÔ¨Åne R[[x]] to be the set of all sequences (s0, s1, . . .) with si ‚ààR
for all i (we do not assume here that si = 0 for large i).
(i) Show that the formulas deÔ¨Åning addition and multiplication on R[x] make sense for
R[[x]], and prove that R[[x]] is a commutative ring under these operations (R[[x]] is
called the ring of formal power series over R.)
(ii) Prove that R[x] is a subring of R[[x]].
(iii) Prove that if R is a domain, then R[[x]] is a domain.
Hint.
If œÉ = (s0, s1, . . . ) ‚ààR[[x]] is nonzero, deÔ¨Åne the order of œÉ, denoted by
ord(œÉ), to be the smallest n ‚â•0 for which sn Ã∏= 0. If R is a domain and œÉ, œÑ ‚ààR[[x]]
are nonzero, prove that ord(œÉœÑ) = ord(œÉ) + ord(œÑ) Ã∏= 0, and hence œÉœÑ Ã∏= 0.
3.27
(i) Denote a formal power series œÉ = (s0, s1, s2, . . . , sn, . . . ) by
œÉ = s0 + s1x + s2x2 + ¬∑ ¬∑ ¬∑ .
Prove that if œÉ = 1+ x + x2 +¬∑ ¬∑ ¬∑ , then œÉ = 1/(1‚àíx) in R[[x]]; that is, (1‚àíx)œÉ = 1.
(ii) Prove that if k is a Ô¨Åeld, then a formal power series œÉ ‚ààk[[x]] is a unit if and only if its
constant term is nonzero; that is, ord(œÉ) = 0.
(iii) Prove that if œÉ ‚ààk[[x]] and ord(œÉ) = n, then
œÉ = xnu,
where u is a unit in k[[x]].

Sec. 3.4
Greatest Common Divisors
131
3.4 GREATEST COMMON DIVISORS
We are now going to see that, when k is a Ô¨Åeld, virtually all the familiar theorems proved
for Z have polynomial analogs in k[x]; moreover, we shall see that the familiar proofs can
be translated into proofs here.
The division algorithm for polynomials with coefÔ¨Åcients in a Ô¨Åeld says that long division
is possible.
Theorem 3.21 (Division Algorithm).
Assume that k is a Ô¨Åeld and that f (x), g(x) ‚àà
k[x] with f (x) Ã∏= 0. Then there are unique polynomials q(x), r(x) ‚ààk[x] with
g(x) = q(x) f (x) + r(x)
and either r(x) = 0 or deg(r) < deg( f ).
Proof.
We Ô¨Årst prove the existence of such q and r. If f | g, then g = q f for some
q; deÔ¨Åne the remainder r = 0, and we are done. If f ‚à§g, then consider all (necessarily
nonzero) polynomials of the form g ‚àíq f as q varies over k[x]. The least integer axiom
provides a polynomial r = g ‚àíq f having least degree among all such polynomials. Since
g = q f +r, it sufÔ¨Åces to show that deg(r) < deg( f ). Write f (x) = snxn + ¬∑ ¬∑ ¬∑ + s1x + s0
and r(x) = tmxm + ¬∑ ¬∑ ¬∑ + t1x + t0. Now sn Ã∏= 0 implies that sn is a unit, because k is a
Ô¨Åeld, and so s‚àí1
n
exists in k. If deg(r) ‚â•deg( f ), deÔ¨Åne
h(x) = r(x) ‚àítms‚àí1
n xm‚àín f (x);
that is, if LT( f ) = snxn, where LT abbreviates leading term, then
h = r ‚àíLT(r)
LT( f ) f ;
note that h = 0 or deg(h) < deg(r). If h = 0, then r = [LT(r)/LT( f )] f and
g = q f + r
= q f + LT(r)
LT( f ) f
=

q + LT(r)
LT( f )

f,
contradicting f ‚à§g. If h Ã∏= 0, then deg(h) < deg(r) and
g ‚àíq f = r = h + LT(r)
LT( f ) f.
Thus, g ‚àí

q + LT(r)/LT( f )

f = h, contradicting r being a polynomial of least degree
having this form. Therefore, deg(r) < deg( f ).

132
Commutative Rings I
Ch. 3
To prove uniqueness of q(x) and r(x), assume that g = q‚Ä≤ f + r‚Ä≤, where deg(r‚Ä≤) <
deg( f ). Then
(q ‚àíq‚Ä≤) f = r‚Ä≤ ‚àír.
If r‚Ä≤ Ã∏= r, then each side has a degree. But deg((q ‚àíq‚Ä≤) f ) = deg(q ‚àíq‚Ä≤) + deg( f ) ‚â•
deg( f ), while deg(r‚Ä≤ ‚àír) ‚â§max{deg(r‚Ä≤), deg(r)} < deg( f ), a contradiction. Hence,
r‚Ä≤ = r and (q ‚àíq‚Ä≤) f = 0. As k[x] is a domain and f Ã∏= 0, it follows that q ‚àíq‚Ä≤ = 0 and
q = q‚Ä≤.
‚Ä¢
DeÔ¨Ånition.
If f (x) and g(x) are polynomials in k[x], where k is a Ô¨Åeld, then the poly-
nomials q(x) and r(x) occurring in the division algorithm are called the quotient and the
remainder after dividing g(x) by f (x).
The hypothesis that k is a Ô¨Åeld is much too strong; long division can be carried out in
R[x] for every commutative ring R as long as the leading coefÔ¨Åcient of f (x) is a unit in
R; in particular, long division is always possible when f (x) is a monic polynomial.
Corollary 3.22.
Let R be a commutative ring, and let f (x) ‚ààR[x] be a monic polyno-
mial. If g(x) ‚ààR[x], then there exist q(x),r(x) ‚ààR[x] with
g(x) = q(x) f (x) + r(x),
where either r(x) = 0 or deg(r) < deg( f ).
Sketch of Proof.
The proof of the division algorithm can be repeated here, once we ob-
serve that LT(r)/LT( f ) ‚ààR because f (x) is monic.
‚Ä¢
We now turn our attention to roots of polynomials.
DeÔ¨Ånition.
If f (x) ‚ààk[x], where k is a Ô¨Åeld, then a root of f (x) in k is an element
a ‚ààk with f (a) = 0.
Remark.
The polynomial f (x) = x2 ‚àí2 has its coefÔ¨Åcients in Q, but we usually say
that
‚àö
2 is a root of f (x) even though
‚àö
2 is irrational; that is,
‚àö
2 /‚ààQ. We shall see later,
in Theorem 3.123, that for every polynomial f (x) ‚ààk[x], where k is any Ô¨Åeld, there is
a larger Ô¨Åeld E that contains k as a subÔ¨Åeld and that contains all the roots of f (x). For
example, x2 ‚àí2 ‚ààI3[x] has no root in I3, but we shall see that a version of
‚àö
2 does exist
in some (Ô¨Ånite) Ô¨Åeld containing I3.
‚óÄ
We will use the following elementary exercise in the proof of the next lemma.
If
f (x), g(x) ‚ààR[x], where R is a commutative ring, write
a(x) = f (x) + g(x)
and
m(x) = f (x)g(x);
evaluating at u ‚ààR gives a(u) = f (u) + g(u) and m(u) = f (u)g(u).

Sec. 3.4
Greatest Common Divisors
133
Lemma 3.23.
Let f (x) ‚ààk[x], where k is a Ô¨Åeld, and let u ‚ààk. Then there is q(x) ‚ààk[x]
with
f (x) = q(x)(x ‚àíu) + f (u).
Proof.
The division algorithm gives
f (x) = q(x)(x ‚àíu) + r;
the remainder r is a constant because x ‚àíu has degree 1. Now evaluate:
f (u) = q(u)(u ‚àíu) + r,
and so r = f (u).
‚Ä¢
There is a connection between roots and factoring.
Proposition 3.24.
If f (x) ‚ààk[x], where k is a Ô¨Åeld, then a is a root of f (x) in k if and
only if x ‚àía divides f (x) in k[x].
Proof.
If a is a root of f (x) in k, then f (a) = 0 and the lemma gives f (x) = q(x)(x‚àía).
Conversely, if f (x) = g(x)(x ‚àía), then evaluating at a gives f (a) = g(a)(a‚àía) = 0. ‚Ä¢
Theorem 3.25.
Let k be a Ô¨Åeld and let f (x) ‚ààk[x]. If f (x) has degree n, then f (x) has
at most n roots in k.
Proof.
We prove the statement by induction on n ‚â•0. If n = 0, then f (x) is a nonzero
constant, and so the number of its roots in k is zero. Now let n > 0. If f (x) has no roots
in k, then we are done, for 0 ‚â§n. Otherwise, we may assume that there is a ‚ààk with a a
root of f (x); hence, by Proposition 3.24,
f (x) = q(x)(x ‚àía);
moreover, q(x) ‚ààk[x] has degree n ‚àí1. If there is a root b ‚ààk with b Ã∏= a, then
0 = f (b) = q(b)(b ‚àía).
Since b ‚àía Ã∏= 0, we have q(b) = 0 (because k is a Ô¨Åeld, hence is a domain), so that b is a
root of q(x). Now deg(q) = n ‚àí1, so that the inductive hypothesis says that q(x) has at
most n ‚àí1 roots in k. Therefore, f (x) has at most n roots in k.
‚Ä¢
Example 3.26.
Theorem 3.25 is not true for polynomials with coefÔ¨Åcients in an arbitrary commutative
ring R. For example, if R = I8, then the quadratic polynomial x2 ‚àí1 ‚ààI8[x] has 4 roots:
[1], [3], [5], and [7].
‚óÄ

134
Commutative Rings I
Ch. 3
Corollary 3.27.
Every nth root of unity in C is equal to
e2œÄik/n = cos

2œÄk
n

+ i sin

2œÄk
n

,
where k = 0, 1, 2, . . . , n ‚àí1.
Proof.
We have seen, in Corollary 1.35, that each of the n different complex numbers
e2œÄik/n is an nth root of unity; that is, each is a root of xn ‚àí1. By Theorem 3.25, there can
be no other complex roots.
‚Ä¢
Recall that every polynomial f (x) ‚ààk[x] determines the polynomial function k ‚Üík
that sends a into f (a) for all a ‚ààk. In Exercise 3.22 on page 130, however, we saw that a
nonzero polynomial in Ip[x] (e.g., x p ‚àíx) can determine the constant function zero. This
pathology vanishes when the Ô¨Åeld k is inÔ¨Ånite.
Corollary 3.28.
Let k be an inÔ¨Ånite Ô¨Åeld and let f (x) and g(x) be polynomials in k[x]. If
f (x) and g(x) determine the same polynomial function [i.e., if f (a) = g(a) for all a ‚ààk],
then f (x) = g(x).
Proof.
If f (x) Ã∏= g(x), then the polynomial h(x) = f (x) ‚àíg(x) is nonzero, so that it
has some degree, say, n. Now every element of k is a root of h(x); since k is inÔ¨Ånite, h(x)
has more than n roots, and this contradicts the theorem.
‚Ä¢
This proof yields a more general result.
Corollary 3.29.
Let k be any Ô¨Åeld, perhaps Ô¨Ånite. If f (x), g(x) ‚ààk[x], if deg( f ) ‚â§
deg(g) ‚â§n, and if f (a) = g(a) for n + 1 elements a ‚ààk, then f (x) = g(x).
Sketch of Proof.
If f Ã∏= g, then deg( f ‚àíg) is deÔ¨Åned and deg( f ‚àíg) ‚â§n.
‚Ä¢
Here is another nice application of Theorem 3.25.
Theorem 3.30.
If k is a Ô¨Åeld and G is a Ô¨Ånite subgroup of the multiplicative group k√ó,
then G is cyclic. In particular, if k itself is Ô¨Ånite (e.g., k = Ip), then k√ó is cyclic.
Proof.
Let d be a divisor of |G|. If there are two subgroups of G of order d, say, S and
T , then |S ‚à™T | > d. But each a ‚ààS ‚à™T satisÔ¨Åes ad = 1, by Lagrange's theorem, and
hence it is a root of xd ‚àí1. This contradicts Theorem 3.25, for this polynomial now has
too many roots in k. Thus, G is cyclic, by Theorem 2.86.
‚Ä¢
DeÔ¨Ånition.
If k is a Ô¨Ånite Ô¨Åeld, a generator of the cyclic group k√ó is called a primitive
element of k.
Although the multiplicative groups I√ó
p are cyclic, no explicit formula giving a primitive
element of each of them is known. For example, Ô¨Ånding a primitive element of F257 essen-
tially involves checking the powers of each [i], where 1 < i < 257, until one is found for
which im Ã∏‚â°1 mod 257 for all positive integers m < 256.
The deÔ¨Ånition of a greatest common divisor of polynomials is essentially the same as
the corresponding deÔ¨Ånition for integers.

Sec. 3.4
Greatest Common Divisors
135
DeÔ¨Ånition.
If f (x) and g(x) are polynomials in k[x], where k is a Ô¨Åeld, then a common
divisor is a polynomial c(x) ‚ààk[x] with c(x) | f (x) and c(x) | g(x). If f (x) and g(x) in
k[x] are not both 0, deÔ¨Åne their greatest common divisor, abbreviated gcd, to be the monic
common divisor having largest degree. If f (x) = 0 = g(x), deÔ¨Åne their gcd = 0. The
gcd of f (x) and g(x) [which is uniquely determined by f (x) and g(x)] is often denoted
by ( f, g).
Theorem 3.31.
If k is a Ô¨Åeld and f (x), g(x) ‚ààk[x], then their gcd d(x) is a linear
combination of f (x) and g(x); that is, there are s(x), t(x) ‚ààk[x] with
d(x) = s(x) f (x) + t(x)g(x).
Sketch of Proof.
This proof is very similar to the corresponding result in Z; indeed, once
we introduce principal ideal domains, we will prove this theorem and its analog in Z si-
multaneously (see Theorem 3.57).
‚Ä¢
Corollary 3.32.
Let k be a Ô¨Åeld and let f (x), g(x) ‚ààk[x]. A monic common divisor
d(x) is the gcd if and only if d(x) is divisible by every common divisor; that is, if c(x) is a
common divisor, then c(x) | d(x).
Moreover, f (x) and g(x) have a unique gcd.
Sketch of Proof.
Analogous to the proof of Proposition 1.8.
‚Ä¢
Every polynomial f (x) is divisible by u and by u f (x), where u is a unit. The analog of
a prime number is a polynomial having only divisors of these trivial sorts.
DeÔ¨Ånition.
An element p in a domain R is irreducible if p is neither 0 nor a unit and, in
any factorization p = uv in R, either u or v is a unit. Elements a, b ‚ààR are associates if
there is a unit u ‚ààR with b = ua.
For example, a prime p ‚ààZ is an irreducible element, as is ‚àíp. We now describe
irreducible polynomials p(x) ‚ààk[x], when k is a Ô¨Åeld.
Proposition 3.33.
If k is a Ô¨Åeld, then a polynomial p(x) ‚ààk[x] is irreducible if and only
if deg(p) = n ‚â•1 and there is no factorization in k[x] of the form p(x) = g(x)h(x) in
which both factors have degree smaller than n.
Proof.
We show Ô¨Årst that h(x) ‚ààk[x] is a unit if and only if deg(h) = 0. If h(x)u(x) = 1,
then deg(h) + deg(u) = deg(1) = 0; since degrees are nonnegative, we have deg(h) = 0.
Conversely, if deg(h) = 0, then h(x) is a nonzero constant; that is, h ‚ààk; since k is a Ô¨Åeld,
h has an inverse.
If p(x) is irreducible, then its only factorizations are of the form p(x) = g(x)h(x),
where g(x) or h(x) is a unit; that is, where either deg(g) = 0 or deg(h) = 0. Therefore,
p(x) has no factorization in which both factors have smaller degree.
Conversely, if p(x) is not irreducible, then it has a factorization p(x) = g(x)h(x) in
which neither g(x) nor h(x) is a unit; that is, neither g(x) nor h(x) has degree 0. Therefore,
p(x) has a factorization as a product of polynomials of smaller degree.
‚Ä¢

136
Commutative Rings I
Ch. 3
If k is not a Ô¨Åeld, however, then this characterization of irreducible polynomials no
longer holds. For example, 2x + 2 = 2(x + 1) is not irreducible in Z[x], even though,
in any factorization, one factor has degree 0 and the other degree 1 (when k is a Ô¨Åeld, the
units are the nonzero constants, but this is no longer true for more general coefÔ¨Åcients).
As the deÔ¨Ånition of divisibility depends on the ambient ring, so irreducibility of a poly-
nomial p(x) ‚ààk[x] also depends on the commutative ring k[x] and hence on the Ô¨Åeld
k. For example, p(x) = x2 + 1 is irreducible in R[x], but it factors as (x + i)(x ‚àíi) in
C[x]. On the other hand, a linear polynomial f (x) is always irreducible [if f = gh, then
1 = deg( f ) = deg(g) + deg(h), and so one of g or h must have degree 0 while the other
has degree 1 = deg( f )].
Corollary 3.34.
Let k be a Ô¨Åeld and let f (x) ‚ààk[x] be a quadratic or cubic polynomial.
Then f (x) is irreducible in k[x] if and only if f (x) does not have a root in k.
Sketch of Proof.
If f (x) = g(x)h(x) and neither g nor h is constant, then deg( f ) =
deg(g) + deg(h) implies that at least one of the factors has degree 1.
‚Ä¢
It is easy to see that Corollary 3.34 can be false if deg( f ) ‚â•4. For example, consider
f (x) = x4 + 2x2 + 1 = (x2 + 1)2 in R[x].
Example 3.35.
(i) We determine the irreducible polynomials in I2[x] of small degree.
As always, the linear polynomials x and x + 1 are irreducible.
There are four quadratics: x2; x2 + x; x2 + 1; x2 + x + 1 (more generally, there
are pn monic polynomials of degree n in Ip[x], for there are p choices for each of the n
coefÔ¨Åcients a0, . . . , an‚àí1). Since each of the Ô¨Årst three has a root in I2, there is only one
irreducible quadratic.
There are eight cubics, of which four are reducible because their constant term is 0. The
remaining polynomials are
x3 + 1;
x3 + x + 1;
x3 + x2 + 1;
x3 + x2 + x + 1.
Since 1 is a root of the Ô¨Årst and fourth, the middle two are the only irreducible cubics.
There are 16 quartics, of which eight are reducible because their constant term is 0. Of
the eight with nonzero constant term, those having an even number of nonzero coefÔ¨Åcients
have 1 as a root. There are now only four surviving polynomials f (x), and each of them
has no roots in I2; i.e., they have no linear factors. If f (x) = g(x)h(x), then both g(x) and
h(x) must be irreducible quadratics. But there is only one irreducible quadratic, namely,
x2 + x + 1, and so (x2 + x + 1)2 = x4 + x2 + 1 is reducible while the other three quartics
are irreducible. The following list summarizes these observations.
Irreducible Polynomials of Low Degree over I2
degree 2:
x2 + x + 1.
degree 3:
x3 + x + 1;
x3 + x2 + 1.
degree 4:
x4 + x3 + 1;
x4 + x + 1;
x4 + x3 + x2 + x + 1.

Sec. 3.4
Greatest Common Divisors
137
(ii) Here is a list of the monic irreducible quadratics and cubics in I3[x]. The reader can
verify that the list is correct by Ô¨Årst enumerating all such polynomials; there are 6 monic
quadratics having nonzero constant term, and there are 18 monic cubics having nonzero
constant term. It must then be checked which of these have 1 or ‚àí1 as a root (it is more
convenient to write ‚àí1 instead of 2).
Monic Irreducible Quadratics and Cubics over I3
degree 2:
x2 + 1;
x2 + x ‚àí1;
x2 ‚àíx ‚àí1.
degree 3:
x3 ‚àíx + 1;
x3 + x2 ‚àíx + 1;
x3 ‚àíx2 + 1;
x3 ‚àíx2 + x + 1;
x3 ‚àíx ‚àí1;
x3 + x2 ‚àí1;
x3 + x2 + x ‚àí1;
x3 ‚àíx2 ‚àíx ‚àí1.
‚óÄ
It is easy to see that if p(x) and q(x) are irreducible polynomials, then p(x) | q(x) if
and only if there is a unit u with q(x) = up(x). If, in addition, both p(x) and q(x) are
monic, then p(x) | q(x) implies p(x) = q(x).
Lemma 3.36.
Let k be a Ô¨Åeld, let p(x), f (x) ‚ààk[x], and let d(x) = (p, f ) be their gcd.
If p(x) is a monic irreducible polynomial, then
d(x) =

1
if p(x) ‚à§f (x)
p(x)
if p(x) | f (x).
Sketch of Proof.
Since d(x) | p(x), we have d(x) = 1 or d(x) = p(x).
‚Ä¢
Theorem 3.37 (Euclid's Lemma).
Let k be a Ô¨Åeld and let f (x), g(x) ‚ààk[x]. If p(x)
is an irreducible polynomial in k[x], and p(x) | f (x)g(x), then either
p(x) | f (x)
or
p(x) | g(x).
More generally, if p(x) | f1(x) ¬∑ ¬∑ ¬∑ fn(x), then p(x) | fi(x) for some i.
Sketch of Proof.
Assume that p | f g but that p ‚à§f . Since p is irreducible, (p, f ) = 1,
and so 1 = sp + t f for some polynomials s and t. Therefore,
g = spg + t f g.
But p | f g, by hypothesis, and so p | g.
‚Ä¢
DeÔ¨Ånition.
Two polynomials f (x), g(x) ‚ààk[x], where k is a Ô¨Åeld, are called relatively
prime if their gcd is 1.

138
Commutative Rings I
Ch. 3
Corollary 3.38.
Let f (x), g(x), h(x) ‚ààk[x], where k is a Ô¨Åeld, and let h(x) and f (x)
be relatively prime. If h(x) | f (x)g(x), then h(x) | g(x).
Sketch of Proof.
The proof of Euclid's lemma also works here: Since (h, f ) = 1, we
have 1 = sh + t f , and so g = shg + t f g.
‚Ä¢
DeÔ¨Ånition.
If k is a Ô¨Åeld, then a rational function f (x)/g(x) ‚ààk(x) is in lowest terms if
f (x) and g(x) are relatively prime.
Proposition 3.39.
If k is a Ô¨Åeld, every nonzero f (x)/g(x) ‚ààk(x) can be put in lowest
terms.
Sketch of Proof.
If f = d f ‚Ä≤ and g = dg‚Ä≤, where d = ( f, g), then f ‚Ä≤ and g‚Ä≤ are relatively
prime, and so f ‚Ä≤/g‚Ä≤ is in lowest terms.
‚Ä¢
The next result allows us to compute gcds.
Theorem 3.40 (Euclidean Algorithm).
If k is a Ô¨Åeld and f (x), g(x) ‚ààk[x], then there
are algorithms for computing the gcd ( f, g), as well as for Ô¨Ånding a pair of polynomials
s(x) and t(x) with
( f, g) = s(x) f (x) + t(x)g(x).
Proof.
The proof is essentially a repetition of the proof of the euclidean algorithm in Z;
just iterate the division algorithm:
g = q1 f + r1
f = q2r1 + r2
r1 = q3r2 + r3
...
rn‚àí4 = qn‚àí2rn‚àí3 + rn‚àí2
rn‚àí3 = qn‚àí1rn‚àí2 + rn‚àí1
rn‚àí2 = qnrn‚àí1 + rn
rn‚àí1 = qn+1rn.
Since the degrees of the remainders are strictly decreasing, this procedure must stop after
a Ô¨Ånite number of steps. The claim is that d = rn is the gcd, once it is made monic. We
see that d is a common divisor of f and g by back substitution: work from the bottom up.
To see that d is the gcd, work from the top down to show that if c is any common divisor
of f and g, then c | ri for every i. Finally, to Ô¨Ånd s and t with d = s f + tg, again work

Sec. 3.4
Greatest Common Divisors
139
from the bottom up.
rn = rn‚àí2 ‚àíqnrn‚àí1
= rn‚àí2 ‚àíqn(rn‚àí3 ‚àíqn‚àí1rn‚àí2)
= (1 + qn‚àí1)rn‚àí2 ‚àíqnrn‚àí3
= (1 + qn‚àí1)(rn‚àí4 ‚àíqn‚àí2rn‚àí3) ‚àíqnrn‚àí3
= (1 + qn‚àí1)rn‚àí4 ‚àí[(1 + qn‚àí1)qn‚àí2 + qn]rn‚àí3
...
= s f + tg
‚Ä¢
Here is an unexpected bonus from the euclidean algorithm.
Corollary 3.41.
Let k be a subÔ¨Åeld of a Ô¨Åeld K, so that k[x] is a subring of K[x]. If
f (x), g(x) ‚ààk[x], then their gcd in k[x] is equal to their gcd in K[x].
Proof.
The division algorithm in K[x] gives
g(x) = Q(x) f (x) + R(x),
where Q(x), R(x) ‚ààK[x]; since f (x), g(x) ‚ààk[x], the division algorithm in k[x] gives
g(x) = q(x) f (x) + r(x),
where q(x),r(x) ‚ààk[x]. But the equation g(x) = q(x) f (x) + r(x) also holds in K[x]
because k[x] ‚äÜK[x], so that the uniqueness of quotient and remainder in the division
algorithm in K[x] gives Q(x) = q(x) ‚ààk[x] and R(x) = r(x) ‚ààk[x]. Therefore, the list
of equations occurring in the euclidean algorithm in K[x] is exactly the same list occurring
in the euclidean algorithm in the smaller ring k[x], and so the same gcd is obtained in both
polynomial rings.
‚Ä¢
For example, the gcd of x3 ‚àíx2 + x ‚àí1 and x4 ‚àí1 is x2 + 1, whether computed in
R[x] or in C[x], in spite of the fact that there are more divisors with complex coefÔ¨Åcients.
Here is the analog for polynomials of the fundamental theorem of arithmetic; it shows
that irreducible polynomials are "building blocks" of arbitrary polynomials in the same
sense that primes are building blocks of arbitrary integers. To avoid long sentences, let us
agree that a "product" may have only one factor. Thus, when we say that a polynomial
f (x) is a product of irreducibles, we allow the possibility that the product has only one
factor, that is, that f (x) is itself irreducible.
Theorem 3.42 (Unique Factorization).
If k is a Ô¨Åeld, then every polynomial f (x) ‚àà
k[x] of degree ‚â•1 is a product of a nonzero constant and monic irreducibles. Moreover, if
f (x) has two such factorizations
f (x) = ap1(x) ¬∑ ¬∑ ¬∑ pm(x)
and
f (x) = bq1(x) ¬∑ ¬∑ ¬∑ qn(x),

140
Commutative Rings I
Ch. 3
that is, a and b are nonzero constants and the p's and q's are monic irreducibles, then
a = b, m = n, and the q's may be reindexed so that qi = pi for all i.
Proof.
We prove the existence of a factorization for a polynomial f (x) by (the second
form of) induction on deg( f ) ‚â•1. If deg( f ) = 1, then f (x) = ax +c = a(x +a‚àí1c). As
every linear polynomial, x + a‚àí1c is irreducible, and so it is a product of irreducibles in
our present usage of "product." Assume now that deg( f ) ‚â•1. If f (x) is irreducible and
its leading coefÔ¨Åcient is a, write f (x) = a(a‚àí1 f (x)); we are done, for a‚àí1 f (x) is monic.
If f (x) is not irreducible, then f (x) = g(x)h(x), where deg(g) < deg( f ) and deg(h) <
deg( f ). By the inductive hypothesis, there are factorizations g(x) = bp1(x) ¬∑ ¬∑ ¬∑ pm(x) and
h(x) = cq1(x) ¬∑ ¬∑ ¬∑ qn(x), where the p's and q's are monic irreducibles. It follows that
f (x) = (bc)p1(x) ¬∑ ¬∑ ¬∑ pm(x)q1(x) ¬∑ ¬∑ ¬∑ qn(x),
as desired.
We now prove, by induction on M = max{m, n} ‚â•1, that if there is an equation
ap1(x) ¬∑ ¬∑ ¬∑ pm(x) = bq1(x) ¬∑ ¬∑ ¬∑ qn(x)
in which a and b are nonzero constants and the p's and q's are monic irreducibles, then
a = b, m = n, and the q's may be reindexed so that qi = pi for all i. For the base step
M = 1, the hypothesis gives a polynomial, call it g(x), with g(x) = ap1(x) = bq1(x).
Now a is the leading coefÔ¨Åcient of g(x), because p1(x) is monic; similarly, b is the
leading coefÔ¨Åcient of g(x) because q1(x) is monic. Therefore, a = b, and canceling
gives p1(x) = q1(x). For the inductive step, the given equation shows that pm(x) |
q1(x) ¬∑ ¬∑ ¬∑ qn(x). By Euclid's lemma for polynomials, there is some i with pm(x) | qi(x).
But qi(x), being monic irreducible, has no monic divisors other than 1 and itself, so that
qi(x) = pm(x). Reindexing, we may assume that qn(x) = pm(x). Canceling this factor,
we have ap1(x) ¬∑ ¬∑ ¬∑ pm‚àí1(x) = bq1(x) ¬∑ ¬∑ ¬∑ qn‚àí1(x). By the inductive hypothesis, a = b,
m ‚àí1 = n ‚àí1 (hence m = n), and after possible reindexing, qi = pi for all i.
‚Ä¢
Let k be a Ô¨Åeld, and assume that there are a,r1, . . . ,rn ‚ààk with
f (x) = a
n

i=1
(x ‚àíri).
If r1, . . . ,rs, where s ‚â§n, are the distinct roots of f (x), then collecting terms gives
f (x) = a(x ‚àír1)e1(x ‚àír2)e2 ¬∑ ¬∑ ¬∑ (x ‚àírs)es,
where the r j are distinct and e j ‚â•1 for all j. We call e j the multiplicity of the root r j. As
linear polynomials are always irreducible, unique factorization shows that multiplicities of
roots are well-deÔ¨Åned.
Although there are some techniques to help decide whether an integer is prime, the
general problem is a very difÔ¨Åcult one. It is also very difÔ¨Åcult to determine whether a
polynomial is irreducible, but we now present some useful techniques that frequently work.

Sec. 3.4
Greatest Common Divisors
141
We know that if f (x) ‚ààk[x] and r is a root of f (x) in a Ô¨Åeld k, then there is a
factorization f (x) = (x ‚àír)g(x) in k[x], so that f (x) is not irreducible. In Corollary 3.34,
we saw that this decides the matter for quadratic and cubic polynomials in k[x]: such
polynomials are irreducible in k[x] if and only if they have no roots in k. This is no longer
true for polynomials of degree ‚â•4.
Theorem 3.43.
Let f (x) = a0 + a1x + ¬∑ ¬∑ ¬∑ + anxn ‚ààZ[x] ‚äÜQ[x]. Every rational root
r of f (x) has the form b/c, where b | a0 and c | an.
Proof.
We may assume that r = b/c is in lowest terms, that is, (b, c) = 1. Substituting r
into f (x) gives
0 = f (b/c) = a0 + a1b/c + ¬∑ ¬∑ ¬∑ + anbn/cn,
and multiplying through by cn gives
0 = a0cn + a1bcn‚àí1 + ¬∑ ¬∑ ¬∑ + anbn.
Hence, a0cn = b(‚àía1cn‚àí1 ‚àí¬∑ ¬∑ ¬∑ ‚àíanbn‚àí1), that is, b | a0cn. Since b and c are relatively
prime, it follows that b and cn are relatively prime, and so Euclid's lemma in Z gives b | a0.
Similarly, anbn = c(‚àían‚àí1bn‚àí1 ‚àí¬∑ ¬∑ ¬∑ ‚àía0cn‚àí1), c | anbn, and c | an.
‚Ä¢
DeÔ¨Ånition.
A complex number Œ± is called an algebraic integer if Œ± is a root of a monic
f (x) ‚ààZ[x].
We note that it is crucial, in the deÔ¨Ånition of algebraic integer, that f (x) ‚ààZ[x] be
monic. Every algebraic number z, that is, every complex number z that is a root of some
polynomial g(x) ‚ààQ[x], is necessarily a root of some polynomial h(x) ‚ààZ[x]; just clear
the denominators of the coefÔ¨Åcients of g(x).
Of course, every ordinary integer is an algebraic integer. To contrast ordinary integers
with more general algebraic integers, elements of Z may be called rational integers.
Corollary 3.44.
A rational number z that is an algebraic integer must lie in Z. More
precisely, if f (x) ‚ààZ[x] ‚äÜQ[x] is a monic polynomial, then every rational root of f (x)
is an integer that divides the constant term.
Proof.
If f (x) = a0 +a1x +¬∑ ¬∑ ¬∑+anxn is monic, then an = 1, and Theorem 3.43 applies
at once.
‚Ä¢
For example, consider f (x) = x3 + 4x2 ‚àí2x ‚àí1 ‚ààQ[x]. By Corollary 3.34, this
cubic is irreducible if and only if it has no rational root. As f (x) is monic, the candidates
for rational roots are ¬±1, for these are the only divisors of ‚àí1 in Z. But f (1) = 2 and
f (‚àí1) = 4, so that neither 1 nor ‚àí1 is a root. Thus, f (x) has no roots in Q, and hence
f (x) is irreducible in Q[x].
This corollary gives a new solution of Exercise 1.15(i) on page 12. If m is an integer
that is not a perfect square, then the polynomial x2 ‚àím has no integer roots, and so ‚àöm is
irrational. Indeed, the reader can now generalize to nth roots: If m is not an nth power of
an integer, then
n‚àöm is irrational, for any rational root of xn ‚àím must be an integer.

142
Commutative Rings I
Ch. 3
EXERCISES
3.28 Find the gcd of x2 ‚àíx ‚àí2 and x3 ‚àí7x + 6 in I5[x], and express it as a linear combination of
them.
Hint. The answer is x ‚àí2.
3.29 Let R be a domain. If f (x) ‚ààR[x] has degree n, prove that f (x) has at most n roots in R.
Hint. Use Frac(R).
3.30 Show that the following pseudocode implements the euclidean algorithm Ô¨Ånding the gcd f (x)
and g(x) in I3[x], where f (x) = x2 + 1 and g(x) = x3 + x + 1.
Input: g, f
Output: d
d := f ; s := g
WHILE s Ã∏= 0 DO
rem := remainder(h, s)
h := s
s := rem
END WHILE
3.31 Prove the converse of Euclid's lemma. Let k be a Ô¨Åeld and let f (x) ‚ààk[x] be a polynomial
of degree ‚â•1; if, whenever f (x) divides a product of two polynomials, it necessarily divides
one of the factors, then f (x) is irreducible.
3.32 Let f (x), g(x) ‚ààR[x], where R is a domain. If the leading coefÔ¨Åcient of f (x) is a unit in R,
then the division algorithm gives a quotient q(x) and a remainder r(x) after dividing g(x) by
f (x). Prove that q(x) and r(x) are uniquely determined by g(x) and f (x).
Hint. Use Frac(R).
3.33 Let k be a Ô¨Åeld, and let f (x), g(x) ‚ààk[x] be relatively prime. If h(x) ‚ààk[x], prove that
f (x) | h(x) and g(x) | h(x) imply f (x)g(x) | h(x).
Hint. See Exercise 1.19 on page 13.
3.34 If k is a Ô¨Åeld, prove that

1 ‚àíx2 /‚ààk(x), where k(x) is the Ô¨Åeld of rational functions.
Hint. Mimic a proof that
‚àö
2 is irrational.
3.35
(i) In R[x], where R is a Ô¨Åeld, let f = pe1
1 ¬∑ ¬∑ ¬∑ pem
m and g = pŒµ1
1 ¬∑ ¬∑ ¬∑ pŒµm
m , where the pi's
are distinct monic irreducibles and ei, Œµi ‚â•0 for all i (as with integers, the device
of allowing zero exponents allows us to have the same irreducible factors in the two
factorizations). Prove that f | g if and only if ei ‚â§Œµi for all i.
(ii) Use the (unique) factorization into irreducibles to give formulas for the gcd and lcm of
two polynomials analogous to the formulas in Proposition 1.17.
3.36 If p is a prime, prove that there are exactly 1
3(p3 ‚àíp) monic irreducible cubic polynomials
in Ip[x]. (A formula for the number of monic irreducible polynomials of degree n in Ip[x] is
given on page 194.)
3.37
(i) Let f (x) = (x ‚àía1) ¬∑ ¬∑ ¬∑ (x ‚àían) ‚ààk[x], where k is a Ô¨Åeld. Show that f (x) has
no repeated roots (that is, all the ai are distinct elements of k) if and only if the gcd
( f, f ‚Ä≤) = 1, where f ‚Ä≤(x) is the derivative of f .
Hint. Use Exercise 3.24 on page 130.
(ii) Prove that if p(x) ‚ààQ[x] is an irreducible polynomial, then p(x) has no repeated roots
in C.

Sec. 3.5
Homomorphisms
143
Hint. Corollary 3.41.
3.38 Let Œ∂ = e2œÄi/n.
(i) Prove that
xn ‚àí1 = (x ‚àí1)(x ‚àíŒ∂)(x ‚àíŒ∂ 2) ¬∑ ¬∑ ¬∑ (x ‚àíŒ∂ n‚àí1)
and, if n is odd, that
xn + 1 = (x + 1)(x + Œ∂)(x + Œ∂ 2) ¬∑ ¬∑ ¬∑ (x + Œ∂ n‚àí1).
Hint. Use Corollary 3.29.
(ii) For numbers a and b, prove that
an ‚àíbn = (a ‚àíb)(a ‚àíŒ∂b)(a ‚àíŒ∂ 2b) ¬∑ ¬∑ ¬∑ (a ‚àíŒ∂ n‚àí1b)
and, if n is odd, that
an + bn = (a + b)(a + Œ∂b)(a + Œ∂ 2b) ¬∑ ¬∑ ¬∑ (a + Œ∂ n‚àí1b).
Hint. Set x = a/b if b Ã∏= 0.
3.5 HOMOMORPHISMS
Just as homomorphisms are used to compare groups, so are homomorphisms used to com-
pare commutative rings.
DeÔ¨Ånition.
If A and R are (commutative) rings, a (ring) homomorphism is a function
f : A ‚ÜíR such that
(i) f (1) = 1;
(ii) f (a + a‚Ä≤) = f (a) + f (a‚Ä≤) for all a, a‚Ä≤ ‚ààA;
(iii) f (aa‚Ä≤) = f (a) f (a‚Ä≤) for all a, a‚Ä≤ ‚ààA.
A homomorphism that is also a bijection is called an isomorphism. Commutative rings A
and R are called isomorphic, denoted by A ‚àº= R, if there is an isomorphism f : A ‚ÜíR.
Example 3.45.
(i) Let R be a domain and let F = Frac(R) denote its fraction Ô¨Åeld. In Theorem 3.13
we said that R is a subring of F, but that is not the truth; R is not even a subset of F.
We did Ô¨Ånd a subring R‚Ä≤ of F, however, that has a very strong resemblance to R, namely,
R‚Ä≤ = {[a, 1] : a ‚ààR} ‚äÜF. The function f : R ‚ÜíR‚Ä≤, given by f (a) = [a, 1], is easily
seen to be an isomorphism.
(ii) When an element in a commutative ring R was "identiÔ¨Åed" with a constant polynomial
[in the proof of Lemma 3.16(iii)], that is, r was identiÔ¨Åed with (r, 0, 0, . . . ), we implied
that R is a subring of R[x]. The subset R‚Ä≤ = {(r, 0, 0, . . . ) : r ‚ààR} is a subring of R[x],

144
Commutative Rings I
Ch. 3
and it is easy to see that the function f : R ‚ÜíR‚Ä≤, deÔ¨Åned by f (r) = (r, 0, 0, . . . ), is an
isomorphism.
(iii) If S is a subring of a commutative ring R, then the inclusion i : S ‚ÜíR is a ring homo-
morphism because we have insisted that the identity 1 of R lies in S. [See Exercise 3.4(iii)
on page 124.]
‚óÄ
Example 3.46.
(i) Complex conjugation z = a + ib ‚Üíz = a ‚àíib is an isomorphism C ‚ÜíC because
1 = 1, z + w = z + w, and zw = z w
(ii) Here is an example of a homomorphism of rings that is not an isomorphism. Choose
m ‚â•2 and deÔ¨Åne f : Z ‚ÜíIm by f (n) = [n]. Notice that f is surjective (but not injective).
(iii) The preceding example can be generalized. If R is a commutative ring with its "one"
denoted by Œµ, then the function œá : Z ‚ÜíR, deÔ¨Åned by œá(n) = nŒµ, is a ring homomor-
phism.8
(iv) Let R be a commutative ring, and let a ‚ààR. DeÔ¨Åne the evaluation homomorphism
ea : R[x] ‚ÜíR by ea( f (x)) = f (a); that is, if f (x) = ri xi, then f (a) = riai. We
let the reader check that ea is a ring homomorphism.
‚óÄ
Certain properties of a ring homomorphism f : A ‚ÜíR follow from its being a ho-
momorphism between the additive groups A and R. For example, f (0) = 0, f (‚àía) =
‚àíf (a), and f (na) = nf (a) for all n ‚ààZ.
Lemma 3.47.
If f : A ‚ÜíR is a ring homomorphism, then, for all a ‚ààA,
(i) f (an) = f (a)n for all n ‚â•0;
(ii) if a is a unit, then f (a) is a unit and f (a‚àí1) = f (a)‚àí1; in fact, if a is a unit, then
f (a‚àín) = f (a)‚àín for all n ‚â•1;
(iii) if f : A ‚ÜíR is a ring homomorphism, then
f (U(A)) ‚â§U(R),
where U(A) is the group of units of A; if f is an isomorphism, then
U(A) ‚àº= U(R).
Sketch of Proof.
(i) Induction on n ‚â•0.
(ii) If ab = 1, then 1 = f (ab) = f (a) f (b). The last statement follows by induction on
n ‚â•1.
(iii) Immediate, from part (ii).
‚Ä¢
8Recall that if a ‚ààR and n is a positive integer, then na is the additive version of the multiplicative notation
an; that is, na is the sum of a with itself n times.

Sec. 3.5
Homomorphisms
145
Proposition 3.48.
If R and S are commutative rings and œï : R ‚ÜíS is a ring homomor-
phism, then there is a ring homomorphism œï‚àó: R[x] ‚ÜíS[x] given by
œï‚àó: r0 + r1x + r2x2 + ¬∑ ¬∑ ¬∑ ‚Üíœï(r0) + œï(r1)x + œï(r2)x2 + ¬∑ ¬∑ ¬∑ .
Sketch of Proof.
It is clear that œï‚àóis well-deÔ¨Åned, and a routine calculation shows that it
is a ring homomorphism.
‚Ä¢
DeÔ¨Ånition.
If f : A ‚ÜíR is a ring homomorphism, then its kernel is
ker f = {a ‚ààA with f (a) = 0},
and its image is
im f = {r ‚ààR : r = f (a) for some a ‚ààR}.
Notice that if we forget their multiplications, then the rings A and R are additive abelian
groups and these deÔ¨Ånitions coincide with the group-theoretic ones.
Let k be a commutative ring, let a ‚ààk, and, as in Example 3.46(iv), consider the
evaluation homomorphism ea : k[x] ‚Üík sending f (x) ‚Üíf (a). Now ea is always
surjective, for if b ‚ààk, then b = ea( f ), where f (x) = x ‚àía + b. By deÔ¨Ånition, ker ea
consists of all those polynomials g(x) for which g(a) = 0; that is, ker ea consists of all the
polynomials in k[x] having a as a root.
The kernel of a group homomorphism is not merely a subgroup; it is a normal subgroup;
that is, it is also closed under conjugation by any element in the ambient group. Similarly,
if R is not the zero ring, the kernel of a ring homomorphism f : A ‚ÜíR is almost a subring
[ker f is not a subring because it never contains 1: f (1) = 1 Ã∏= 0], and we shall see that it
is closed under multiplication by any element in the ambient ring.
DeÔ¨Ånition.
An ideal in a commutative ring R is a subset I of R such that
(i) 0 ‚ààI;
(ii) if a, b ‚ààI, then a + b ‚ààI;9
(iii) if a ‚ààI and r ‚ààR, then ra ‚ààI.
The ring R itself and the subset consisting of 0 alone, which we denote by {0}, are
always ideals in a commutative ring R. An ideal I Ã∏= R is called a proper ideal.
Example 3.49.
If b1, b2, . . . , bn lie in R, then the set of all linear combinations
I =

r1b1 + r2b2 + ¬∑ ¬∑ ¬∑ + rnbn : ri ‚ààR for all i

9In contrast to the deÔ¨Ånition of subring, it sufÔ¨Åces to assume that a + b ‚ààI instead of a ‚àíb ‚ààI. If I is an
ideal and b ‚ààI, then (‚àí1)b ‚ààI, and so a ‚àíb = a + (‚àí1)b ‚ààI.

146
Commutative Rings I
Ch. 3
is an ideal in R. We write I = (b1, b2, . . . , bn) in this case, and we call I the ideal
generated by b1, b2, . . . , bn. In particular, if n = 1, then
I = (b) = {rb : r ‚ààR}
is an ideal in R; (b) consists of all the multiples of b, and it is called the principal ideal
generated by b. Notice that R and {0} are always principal ideals: R = (1) and {0} = (0).
In Z, the even integers form the principal ideal (2).
‚óÄ
Proposition 3.50.
If f : A ‚ÜíR is a ring homomorphism, then ker f is an ideal in A
and im f is a subring of R. Moreover, if A and R are not zero rings, then ker f is a proper
ideal.
Sketch of Proof.
ker f is an additive subgroup of A; moreover, if u ‚ààker f and a ‚ààA,
then f (au) = f (a) f (u) = f (a) ¬∑ 0 = 0. Hence, ker f is an ideal. If R is not the zero
ring, then 1 Ã∏= 0; hence, the identity 1 ‚ààA does not lie in ker f , because f (1) = 1 Ã∏= 0 in
R, and so ker f is a proper ideal. It is routine to check that im f is a subring of R.
‚Ä¢
Example 3.51.
(i) If an ideal I in a commutative ring R contains 1, then I = R, for now I contains r = r1
for every r ‚ààR. Indeed, if I contains a unit u, then I = R, for then I contains u‚àí1u = 1.
(ii) It follows from (i) that if R is a Ô¨Åeld, then the only ideals I in R are {0} and R itself: if
I Ã∏= {0}, it contains some nonzero element, and every nonzero element in a Ô¨Åeld is a unit.
Conversely, assume that R is a nonzero commutative ring whose only ideals are R itself
and {0}. If a ‚ààR and a Ã∏= 0, then the principal ideal (a) = R, for (a) Ã∏= 0, and so
1 ‚ààR = (a). There is thus r ‚ààR with 1 = ra; that is, a has an inverse in R, and so R is a
Ô¨Åeld.
‚óÄ
Proposition 3.52.
A ring homomorphism f : A ‚ÜíR is an injection if and only if ker f =
{0}.
Sketch of Proof.
This follows from the corresponding result for group homomorphisms,
because f is a homomorphism from the additive group of A to the additive group of R. ‚Ä¢
Corollary 3.53.
If f : k ‚ÜíR is a ring homomorphism, where k is a Ô¨Åeld and R is not
the zero ring, then f is an injection.
Proof.
The only proper ideal in k is {0}.
‚Ä¢
Theorem 3.54.
If k is a Ô¨Åeld, then every ideal I in k[x] is a principal ideal. Moreover, if
I Ã∏= {0}, there is a monic polynomial that generates I.
Sketch of Proof.
If k is a Ô¨Åeld, then k[x] is an example of a euclidean ring. In Theo-
rem 3.60, we will prove that every ideal in a euclidean ring is a principal ideal.
‚Ä¢

Sec. 3.5
Homomorphisms
147
DeÔ¨Ånition.
A domain R is a principal ideal domain if every ideal in R is a principal
ideal. This name is often abbreviated to PID.
Example 3.55.
(i) The ring of integers is a PID.
(ii) Every Ô¨Åeld is a PID, by Example 3.51(ii).
(iii) If k is a Ô¨Åeld, then the polynomial ring k[x] is a PID, by Theorem 3.54.
(iv) There are rings other than Z and k[x], where k is a Ô¨Åeld, that have a division algorithm;
they are called euclidean rings, and they, too, are PIDs. We shall consider them in the next
section.
‚óÄ
It is not true that ideals in arbitrary commutative rings are always principal ideals.
Example 3.56.
Let R = Z[x], the commutative ring of all polynomials over Z. It is easy to see that the set
I of all polynomials with even constant term is an ideal in Z[x]. We show that I is not a
principal ideal.
Suppose there is d(x) ‚ààZ[x] with I = (d(x)). The constant 2 ‚ààI, so that there
is f (x) ‚ààZ[x] with 2 = d(x) f (x). Since the degree of a product is the sum of the
degrees of the factors, 0 = deg(2) = deg(d) + deg( f ). Since degrees are nonnegative, it
follows that deg(d) = 0 [i.e., d(x) is a nonzero constant]. As constants here are integers,
the candidates for d(x) are ¬±1 and ¬±2. Suppose d(x) = ¬±2; since x ‚ààI, there is
g(x) ‚ààZ[x] with x = d(x)g(x) = ¬±2g(x). But every coefÔ¨Åcient on the right side is even,
while the coefÔ¨Åcient of x on the left side is 1. This contradiction gives d(x) = ¬±1. By
Example 3.51(ii), I = Z[x], another contradiction. Therefore, no such d(x) exists, that is,
the ideal I is not a principal ideal.
‚óÄ
Certain theorems holding in Z carry over to PIDs once the standard deÔ¨Ånitions are
generalized; the notion of divisor has already been generalized.
DeÔ¨Ånition.
An element Œ¥ in a commutative ring R is a greatest common divisor, gcd, of
elements Œ±, Œ≤ ‚ààR if
(i) Œ¥ is a common divisor of Œ± and Œ≤;
(ii) if Œ≥ is any common divisor of Œ± and Œ≤, then Œ≥ | Œ¥.
Greatest common divisors, when they exist, need not be unique; for example, it is easy
to see that if c is a greatest common divisor of f and g, then so is uc for any unit u ‚ààR.
In the special case R = Z, we force uniqueness of the gcd by requiring it to be positive; if
R = k[x], where k is a Ô¨Åeld, then we force uniqueness of the gcd by further requiring it to
be monic.

148
Commutative Rings I
Ch. 3
Remark.
Let R be a PID and let œÄ, Œ± ‚ààR with œÄ irreducible. A gcd Œ¥ of œÄ and Œ± is, in
particular, a divisor of œÄ. Hence, œÄ = Œ¥Œµ, and irreducibility of œÄ forces either Œ¥ or Œµ to be
a unit. Now Œ± = Œ¥Œ≤. If Œ¥ is not a unit, then Œµ is a unit, and so
Œ± = Œ¥Œ≤ = œÄŒµ‚àí1Œ≤;
that is, œÄ | Œ±. We conclude that if œÄ ‚à§Œ±, then Œ¥ is a unit; that is, 1 is a gcd of œÄ and Œ±.
‚óÄ
For an example of a domain in which a pair of elements does not have a gcd, see
Exercise 3.60 on page 158.
Theorem 3.57.
Let R be a PID.
(i) Every Œ±, Œ≤ ‚ààR has a gcd, Œ¥, which is a linear combination of Œ± and Œ≤:
Œ¥ = œÉŒ± + œÑŒ≤,
where œÉ, œÑ ‚ààR.
(ii) If an irreducible element œÄ ‚ààR divides a product Œ±Œ≤, then either œÄ | Œ± or œÄ | Œ≤.
Proof.
(i) We may assume that at least one of Œ± and Œ≤ is not zero (otherwise, the gcd is 0
and the result is obvious). Consider the set I of all the linear combinations:
I = {œÉŒ± + œÑŒ≤ : œÉ, œÑ in R}.
Now Œ± and Œ≤ are in I (take œÉ = 1 and œÑ = 0 or vice versa). It is easy to check that I is an
ideal in R, and so there is Œ¥ ‚ààI with I = (Œ¥), because R is a PID; we claim that Œ¥ is a gcd
of Œ± and Œ≤.
Since Œ± ‚ààI = (Œ¥), we have Œ± = œÅŒ¥ for some œÅ ‚ààR; that is, Œ¥ is a divisor of Œ±;
similarly, Œ¥ is a divisor of Œ≤, and so Œ¥ is a common divisor of Œ± and Œ≤.
Since Œ¥ ‚ààI, it is a linear combination of Œ± and Œ≤: There are œÉ, œÑ ‚ààR with
Œ¥ = œÉŒ± + œÑŒ≤.
Finally, if Œ≥ is any common divisor of Œ± and Œ≤, then Œ± = Œ≥ Œ±‚Ä≤ and Œ≤ = Œ≥Œ≤‚Ä≤, so that Œ≥
divides Œ¥, for Œ¥ = œÉŒ± + œÑŒ≤ = Œ≥ (œÉŒ±‚Ä≤ + œÑŒ≤‚Ä≤). We conclude that Œ¥ is a gcd.
(ii) If œÄ | Œ±, we are done. If œÄ ‚à§Œ±, then the remark says that 1 is a gcd of œÄ and Œ±. There
are thus elements œÉ, œÑ ‚ààR with 1 = œÉœÄ + œÑŒ±, and so
Œ≤ = œÉœÄŒ≤ + œÑŒ±Œ≤.
Since œÄ | Œ±Œ≤, it follows that œÄ | Œ≤, as desired.
‚Ä¢
Example 3.58.
If I and J are ideals in a commutative ring R, we now show that I ‚à©J is also an ideal in R.
Since 0 ‚ààI and 0 ‚ààJ, we have 0 ‚ààI ‚à©J. If a, b ‚ààI ‚à©J, then a ‚àíb ‚ààI and a ‚àíb ‚ààJ,
for each is an ideal, and so a ‚àíb ‚ààI ‚à©J. If a ‚ààI ‚à©J and r ‚ààR, then ra ‚ààI and ra ‚ààJ,
hence ra ‚ààI ‚à©J. Therefore, I ‚à©J is an ideal. With minor alterations, this argument also
proves that the intersection of any family of ideals in R is also an ideal in R.
‚óÄ

Sec. 3.5
Homomorphisms
149
DeÔ¨Ånition.
If f and g are elements in a commutative ring R, then a common multiple
is an element m ‚ààR with f | m and g | m. If f and g in R are not both 0, deÔ¨Åne their
least common multiple, abbreviated lcm, to be a common multiple c of them with c | m
for every common multiple m. If f = 0 = g, deÔ¨Åne their lcm = 0. The lcm of f and g is
often denoted by [ f, g].
Least common multiples, when they exist, need not be unique; for example, it is easy
to see that if c is a least common multiple of f and g, then so is uc for any unit u ‚ààR. In
the special case R = Z, we force uniqueness of the lcm by requiring it to be positive; if
R = k[x], where k is a Ô¨Åeld, then we force uniqueness of the lcm by further requiring it to
be monic.
EXERCISES
3.39
(i) Let œï : A ‚ÜíR be an isomorphism, and let œà : R ‚ÜíA be its inverse. Show that œà is
an isomorphism.
(ii) Show that the composite of two homomorphisms (isomorphisms) is again a homomor-
phism (isomorphism).
(iii) Show that A ‚àº= R deÔ¨Ånes an equivalence relation on the class of all commutative rings.
3.40 Let R be a commutative ring and let F(R) be the commutative ring of all functions f : R ‚ÜíR
with pointwise operations.
(i) Show that R is isomorphic to the subring of F(R) consisting of all the constant func-
tions.
(ii) If f (x) ‚ààR[x], let œï f : R ‚ÜíR be deÔ¨Åned by r ‚Üíf (r) [thus, œï f is the polynomial
function associated to f (x)]. Show that the function œï : R[x] ‚ÜíF(R), deÔ¨Åned by
œï( f (x)) = œï f , is a ring homomorphism.
(iii) Show that œï is injective if R is an inÔ¨Ånite Ô¨Åeld.
3.41 Let I and J be nonzero ideals in a commutative ring R. If R is a domain, prove that I ‚à©J Ã∏=
{0}.
3.42 Let R be a commutative ring. Show that the function Œµ: R[x] ‚ÜíR, deÔ¨Åned by
Œµ: a0 + a1x + a2x + ¬∑ ¬∑ ¬∑ + anxn ‚Üía0,
is a homomorphism. Describe ker Œµ in terms of roots of polynomials.
3.43 If R is a commutative ring and c ‚ààR, prove that the function œï : R[x] ‚ÜíR[x], deÔ¨Åned by
f (x) ‚Üíf (x + c), is an isomorphism. In more detail, œï(
i si xi) = 
i si(x + c)i.
Hint. This is a routine but long calculation.
3.44
(i) Prove that F, the Ô¨Åeld with four elements (see Exercise 3.14 on page 125), and I4 are
not isomorphic commutative rings.
(ii) Prove that any two Ô¨Åelds having exactly four elements are isomorphic.
Hint. First prove that 1+1 = 0, and then show that the nonzero elements form a cyclic
group of order 3 under multiplication.
3.45
(i) Show that every element a ‚ààIp has a pth root (i.e., there is b ‚ààIp with a = bp).
(ii) Let k be a Ô¨Åeld that contains Ip as a subÔ¨Åeld [e.g., k = Ip(x)]. For every positive integer
n, show that the function œïn : k ‚Üík, given by œï(a) = a pn, is a ring homomorphism.

150
Commutative Rings I
Ch. 3
3.46 If R is a Ô¨Åeld, show that R ‚àº= Frac(R).
More precisely, show that the homomorphism
f : R ‚ÜíFrac(R) in Example 3.45(i), namely, r ‚Üí[r, 1], is an isomorphism.
3.47
(i) If A and R are domains and œï : A ‚ÜíR is a ring isomorphism, prove that
[a, b] ‚Üí[œï(a), œï(b)]
is a ring isomorphism Frac(A) ‚ÜíFrac(R).
(ii) Prove that if a Ô¨Åeld k contains an isomorphic copy of Z as a subring, then k must contain
an isomorphic copy of Q.
(iii) Let R be a domain and let œï : R ‚Üík be an injective ring homomorphism, where k is a
Ô¨Åeld. Prove that there exists a unique ring homomorphism : Frac(R) ‚Üík extending
œï; that is, |R = œï.
3.48 Let R be a domain with fraction Ô¨Åeld F = Frac(R).
(i) Prove that Frac(R[x]) ‚àº= F(x).
(ii) Prove that Frac(R[x1, x2, . . . , xn]) ‚àº= F(x1, x2, . . . , xn) (see page 129).
3.49
(i) If R and S are commutative rings, show that their direct product R √ó S is also a com-
mutative ring, where addition and multiplication in R √ó S are deÔ¨Åned "coordinatewise":
(r, s) + (r‚Ä≤, s‚Ä≤) = (r + r‚Ä≤, s + s‚Ä≤)
and
(r, s)(r‚Ä≤, s‚Ä≤) = (rr‚Ä≤, ss‚Ä≤).
(ii) Show that if m and n are relatively prime, then Imn ‚àº= Im √ó In as rings.
Hint. See Theorem 2.81.
(iii) Show that if neither R nor S is the zero ring, then R √ó S is not a domain.
(iv) Show that R √ó {0} is an ideal in R √ó S.
(v) Show that R √ó {0} is a ring isomorphic to R, but it is not a subring of R √ó S.
3.50
(i) If R and S are nonzero commutative rings, prove that
U(R √ó S) = U(R) √ó U(S),
where U(R) is the group of units of R.
Hint. Show that (r, s) is a unit in R √ó S if and only if r is a unit in R and s is a unit in
S.
(ii) Redo Exercise 2.65 on page 94 using part (i).
(iii) Use part (i) to give another proof of Corollary 2.83.
3.51 Let F be the set of all 2 √ó 2 real matrices of the form
A =
 a
b
‚àíb
a

.
Prove that F is a Ô¨Åeld (with operations matrix addition and matrix multiplication), and prove
that there is an isomorphism œï : F ‚ÜíC with det(A) = œï(A)œï(A).
Hint. DeÔ¨Åne œï : F ‚ÜíC by œï(A) = a + ib.
3.52 If k is a Ô¨Åeld and [ f, g] denotes the lcm of monic polynomials f (x), g(x) ‚ààk[x], show that
[ f, g]( f, g) = f g.
Hint. See Exercise 1.26 on page 13. By deÔ¨Ånition, lcm's are monic.

Sec. 3.6
Euclidean Rings
151
3.53 If R is a PID and a, b ‚ààR, prove that their lcm exists.
3.54
(i) If k is a Ô¨Åeld, prove that the ring of formal power series k[[x]] is a PID.
Hint.
If I is a nonzero ideal, choose œÑ ‚ààI of smallest order. Use Exercise 3.27 on
page 130 to prove that I = (œÑ).
(ii) Prove that every nonzero ideal in k[[x]] is equal to (xn) for some n ‚â•0.
3.55 If k is a Ô¨Åeld, show that the ideal (x, y) in k[x, y] is not a principal ideal (see page 129).
3.56 For every m ‚â•1, prove that every ideal in Im is a principal ideal. (If m is composite, then Im
is not a PID because it is not a domain.)
3.6 EUCLIDEAN RINGS
There are rings other than Z and k[x], where k is a Ô¨Åeld, that have a division algorithm. In
particular, we present an example of such a ring in which the quotient and remainder are
not unique. We begin by generalizing a property shared by both Z and k[x].
DeÔ¨Ånition.
A euclidean ring is a domain R that is equipped with a function
‚àÇ: R ‚àí{0} ‚ÜíN,
called a degree function, such that
(i) ‚àÇ( f ) ‚â§‚àÇ( f g) for all f , g ‚ààR with f , g Ã∏= 0;
(ii) for all f , g ‚ààR with f Ã∏= 0, there exist q, r ‚ààR with
g = q f + r,
where either r = 0 or ‚àÇ(r) < ‚àÇ( f ).
Note that if R has a degree function ‚àÇthat is identically 0, then condition (ii) forces
r = 0 always; taking g = 1 shows that R is a Ô¨Åeld in this case.
Example 3.59.
(i) The integers Z is a euclidean ring with degree function ‚àÇ(m) = |m|. In Z, we have
‚àÇ(mn) = |mn| = |m||n| = ‚àÇ(m)‚àÇ(n).
(ii) When k is a Ô¨Åeld, the domain k[x] is a euclidean ring with degree function the usual
degree of a nonzero polynomial. In k[x], we have
‚àÇ( f g) = deg( f g)
= deg( f ) + deg(g)
= ‚àÇ( f ) + ‚àÇ(g).

152
Commutative Rings I
Ch. 3
Since ‚àÇ(mn) = ‚àÇ(m)‚àÇ(n) in Z, the behavior of the degree of a product is not determined
by the axioms in the deÔ¨Ånition of a degree function. If a degree function ‚àÇis multiplicative,
that is, if
‚àÇ( f g) = ‚àÇ( f )‚àÇ(g),
then ‚àÇis called a norm.
(iii) The Gaussian10 integers Z[i] form a euclidean ring whose degree function
‚àÇ(a + bi) = a2 + b2
is a norm. One reason for showing that Z[i] is a euclidean ring is that it is then a PID, and
hence it has unique factorization of its elements into products of irreducibles; Gauss used
this fact in his proof that if an odd prime p is sum of two squares, say p = a2 + b2, where
a and b are natural numbers, then the pair a, b is unique (see Theorem 3.66).
To see that ‚àÇis a multiplicative degree function, note Ô¨Årst that if Œ± = a + bi, then
‚àÇ(Œ±) = Œ±Œ±,
where Œ± = a ‚àíbi is the complex conjugate of Œ±. It follows that ‚àÇ(Œ±Œ≤) = ‚àÇ(Œ±)‚àÇ(Œ≤) for all
Œ±, Œ≤ ‚ààZ[i], because
‚àÇ(Œ±Œ≤) = Œ±Œ≤Œ±Œ≤ = Œ±Œ≤Œ±Œ≤ = Œ±Œ±Œ≤Œ≤ = ‚àÇ(Œ±)‚àÇ(Œ≤);
indeed, this is even true for all Œ±, Œ≤ ‚ààQ[i] = {x + yi : x, y ‚ààQ}, by Corollary 1.31.
We now show that ‚àÇsatisÔ¨Åes the Ô¨Årst property of a degree function. If Œ≤ = c+id ‚ààZ[i]
and Œ≤ Ã∏= 0, then
1 ‚â§‚àÇ(Œ≤),
for ‚àÇ(Œ≤) = c2 + d2 is a positive integer; it follows that if Œ±, Œ≤ ‚ààZ[i] and Œ≤ Ã∏= 0, then
‚àÇ(Œ±) ‚â§‚àÇ(Œ±)‚àÇ(Œ≤) = ‚àÇ(Œ±Œ≤).
Let us show that ‚àÇalso satisÔ¨Åes the second desired property. Given Œ±, Œ≤ ‚ààZ[i] with
Œ≤ Ã∏= 0, regard Œ±/Œ≤ as an element of C. Rationalizing the denominator gives Œ±/Œ≤ =
Œ±Œ≤/Œ≤Œ≤ = Œ±Œ≤/‚àÇ(Œ≤), so that
Œ±/Œ≤ = x + yi,
where x, y ‚ààQ. Write x = a + u and y = b + v, where a, b ‚ààZ are integers closest
to x and y, respectively; thus, |u|, |v| ‚â§1
2. (If x or y has the form m + 1
2, where m is an
integer, then there is a choice of nearest integer: x = m + 1
2 or x = (m + 1) ‚àí1
2; a similar
choice arises if x or y has the form m ‚àí1
2.) It follows that
Œ± = Œ≤(a + bi) + Œ≤(u + vi).
10The Gaussian integers are so called because Gauss tacitly used Z[i] and its norm ‚àÇto investigate biquadratic
residues.

Sec. 3.6
Euclidean Rings
153
Notice that Œ≤(u + vi) ‚ààZ[i], for it is equal to Œ± ‚àíŒ≤(a + bi). Finally, we have
‚àÇ

Œ≤(u + vi)

= ‚àÇ(Œ≤)‚àÇ(u + vi),
and so ‚àÇwill be a degree function if ‚àÇ(u + vi) < 1. And this is so, for the inequalities
|u| ‚â§1
2 and |v| ‚â§1
2 give u2 ‚â§1
4 and v2 ‚â§1
4, and hence ‚àÇ(u + vi) = u2 + v2 ‚â§1
4 + 1
4 =
1
2 < 1. Therefore, ‚àÇ(Œ≤(u + vi)) < ‚àÇ(Œ≤), and so Z[i] is a euclidean ring whose degree
function is a norm.
We now show that quotients and remainders may not be unique (because of the choices
noted previously). For example, let Œ± = 3 + 5i and Œ≤ = 2. Then Œ±/Œ≤ = 3
2 + 5
2i; the
choices are
a = 1 and u = 1
2
or
a = 2 and u = ‚àí1
2;
b = 2 and v = 1
2
or
b = 3 and v = ‚àí1
2.
There are four quotients and remainders after dividing 3 + 5i by 2 in Z[i], for each of the
remainders (e.g., 1 + i) has degree 2 < 4 = ‚àÇ(2):
3 + 5i = 2(1 + 2i) + (1 + i);
= 2(1 + 3i) + (1 ‚àíi);
= 2(2 + 2i) + (‚àí1 + i);
= 2(2 + 3i) + (‚àí1 ‚àíi).
‚óÄ
Theorem 3.60.
Every euclidean ring R is a PID.
Proof.
Let I be an ideal in R. If I = {0}, then I = (0) is principal; therefore, we may
assume that I Ã∏= (0). By the least integer axiom, the set of all degrees of nonzero elements
in I has a smallest element, say, n; choose d ‚ààI with ‚àÇ(d) = n. Clearly, (d) ‚äÜI, and so
it sufÔ¨Åces to prove the reverse inclusion. If a ‚ààI, then there are q,r ‚ààR with a = qd +r,
where either r = 0 or ‚àÇ(r) < ‚àÇ(d). But r = a ‚àíqd ‚ààI, and so d having least degree
implies that r = 0. Hence, a = qd ‚àà(d), and I = (d).
‚Ä¢
Corollary 3.61.
The ring of Gaussian integers Z[i] is a principal ideal domain.
The converse of Theorem 3.60 is false: There are PIDs that are not euclidean rings, as
we see in the next example.
Example 3.62.
It is shown in algebraic number theory that the ring
R = {a + bŒ± : a, b ‚ààZ},
where Œ± = 1
2(1 +
‚àö
‚àí19), is a PID [R is the ring of algebraic integers in the quadratic
number Ô¨Åeld Q(
‚àö
‚àí19)]. In 1949, T. S. Motzkin showed that R is not a euclidean ring by
showing that it does not have a certain property of euclidean rings that does not mention
its degree function.

154
Commutative Rings I
Ch. 3
DeÔ¨Ånition.
An element u in a domain R is a universal side divisor if u is not a unit and,
for every x ‚ààR, either u | x or there is a unit z ‚ààR with u | (x + z).
Proposition 3.63.
If R is a euclidean ring but not a Ô¨Åeld, then R has a universal side
divisor.
Proof.
DeÔ¨Åne
S = {‚àÇ(v) : v Ã∏= 0 and v is not a unit},
where ‚àÇis the degree function on R. Since R is not a Ô¨Åeld, by hypothesis, S is a nonempty
subset of the natural numbers. By the least integer axiom, S has a smallest element, say,
‚àÇ(u). We claim that u is a universal side divisor. If x ‚ààR, there are elements q and r with
x = qu + r, where either r = 0 or ‚àÇ(r) < ‚àÇ(u). If r = 0, then u | x; if r Ã∏= 0, then r must
be a unit, otherwise its existence contradicts ‚àÇ(u) being the smallest number in S. We have
shown that u is a universal side divisor.
‚Ä¢
Motzkin then showed that the ring {a + bŒ± : a, b ‚ààZ}, where Œ± = 1
2(1 +
‚àö
‚àí19),
has no universal side divisors, concluding that this PID is not a euclidean ring. For details,
we refer the reader to K. S. Williams, "Note on Non-euclidean Principal Ideal Domains,"
Math. Mag. 48 (1975), 176-177.
‚óÄ
What are the units in the Gaussian integers?
Proposition 3.64.
(i) Let R be a euclidean ring R that is not a Ô¨Åeld. If the degree function ‚àÇis a norm,
then Œ± is a unit if and only if ‚àÇ(Œ±) = 1.
(ii) Let R be a euclidean ring R that is not a Ô¨Åeld. If the degree function ‚àÇis a norm and
if ‚àÇ(Œ±) = p, where p is a prime number, then Œ± is irreducible.
(iii) The only units in the ring Z[i] of Gaussian integers are ¬±1 and ¬±i.
Proof.
(i) Since 12 = 1, we have ‚àÇ(1)2 = ‚àÇ(1), so that ‚àÇ(1) = 0 or ‚àÇ(1) = 1. If
‚àÇ(1) = 0, then ‚àÇ(a) = ‚àÇ(1a) = ‚àÇ(1)‚àÇ(a) = 0 for all a ‚ààR. But R is not a Ô¨Åeld, and so ‚àÇ
is not identically zero. We conclude that ‚àÇ(1) = 1.
If Œ± ‚ààR is a unit, then there is Œ≤ ‚ààR with Œ±Œ≤ = 1. Therefore, ‚àÇ(Œ±)‚àÇ(Œ≤) = 1. Since
the values of ‚àÇare nonnegative integers, ‚àÇ(Œ±) = 1.
For the converse, we begin by showing that there is no element Œ≤ ‚ààR with ‚àÇ(Œ≤) = 0.
If such an element existed, the division algorithm would give 1 = qŒ≤ + r, where q,r ‚ààR
and either r = 0 or ‚àÇ(r) < ‚àÇ(Œ≤) = 0. The inequality cannot occur, and so r = 0; that is,
Œ≤ is a unit. But if Œ≤ is a unit, then ‚àÇ(Œ≤) = 1, as we have just proved, and this contradicts
‚àÇ(Œ≤) = 0.
Assume now that ‚àÇ(Œ±) = 1. The division algorithm gives q,r ‚ààR with
Œ± = qŒ±2 + r,

Sec. 3.6
Euclidean Rings
155
where r = 0 or ‚àÇ(r) < ‚àÇ(Œ±2). As ‚àÇ(Œ±2) = ‚àÇ(Œ±)2 = 1, either r = 0 or ‚àÇ(r) = 0. But
we have just seen that ‚àÇ(r) = 0 cannot occur, so that r = 0 and Œ± = qŒ±2. It follows that
1 = qŒ±, and so Œ± is a unit.
(ii) If, on the contrary, Œ± = Œ≤Œ≥ , where neither Œ≤ nor Œ≥ is a unit, then p = ‚àÇ(Œ±) =
‚àÇ(Œ≤)‚àÇ(Œ≥ ). As p is a prime, either ‚àÇ(Œ≤) = 1 or ‚àÇ(Œ≥ ) = 1. By part (i), either Œ≤ or Œ≥ is a
unit; that is, Œ± is irreducible.
(iii) If Œ± = a + bi ‚ààZ[i] is a unit, then 1 = ‚àÇ(Œ±) = a2 + b2. This can happen if and only
if a2 = 1 and b2 = 0 or a2 = 0 and b2 = 1; that is, Œ± = ¬±1 or Œ± = ¬±i.
‚Ä¢
If n is an odd number, then either n ‚â°1 mod 4 or n ‚â°3 mod 4; consequently, the odd
prime numbers are divided into two classes. For example, 5, 13, 17 are congruent to 1 mod
4, while 3, 7, 11 are congruent to 3 mod 4.
Lemma 3.65.
If p is a prime and p ‚â°1 mod 4, then there is an integer m with
m2 ‚â°‚àí1 mod p.
Proof.
If G = (Ip)√ó is the multiplicative group of nonzero elements in Ip, then |G| =
p ‚àí1 ‚â°0 mod 4; that is, 4 is a divisor of |G|. By Proposition 2.78, G contains a subgroup
S of order 4. By Exercise 2.36 on page 72, either S is cyclic or a2 = 1 for all a ‚ààS.
Since Ip is a Ô¨Åeld, however, it cannot contain four roots of the quadratic x2 ‚àí1. Therefore,
S is cyclic,11 say, S = ‚ü®[m]‚ü©, where [m] is the congruence class of m mod p. Since [m]
has order 4, we have [m4] = [1]. Moreover, [m2] Ã∏= [1] (lest [m] have order ‚â§2 < 4),
and so [m2] = [‚àí1], for [‚àí1] is the unique element in S of order 2. Therefore, m2 ‚â°
‚àí1 mod p.
‚Ä¢
Theorem 3.66 (Fermat's12 Two-Squares Theorem).
An odd prime p is a sum of two
squares,
p = a2 + b2,
where a and b are integers, if and only if p ‚â°1 mod 4.
Proof.
Assume that p = a2 + b2. Since p is odd, a and b have different parity; say, a is
even and b is odd. Hence, a = 2m and b = 2n + 1, and
p = a2 + b2 = 4m2 + 4n2 + 4n + 1 ‚â°1 mod 4.
Conversely, assume that p ‚â°1 mod 4. By the lemma, there is an integer m such that
p | (m2 + 1).
11Theorem 3.30 says that G is a cyclic group, which implies that S is cyclic, for every subgroup of a cyclic
group is itself cyclic. We choose to avoid this theorem here, for the proof just given is more elementary.
12Fermat was the Ô¨Årst to state this theorem, but the Ô¨Årst published proof is due to Euler. Gauss proved that
there is only one pair of natural numbers a and b with p = a2 + b2.

156
Commutative Rings I
Ch. 3
In Z[i], there is a factorization m2 + 1 = (m + i)(m ‚àíi), and so
p | (m + i)(m ‚àíi) in Z[i].
If p | (m ¬± i) in Z[i], then there are integers u and v with m ¬± i = p(u + iv). Comparing
the imaginary parts gives pv = 1, a contradiction. We conclude that p does not satisfy
the analog of Euclid's lemma in Theorem 3.57 (recall that Z[i] is a PID); it follows from
Exercise 3.62 on page 158 that p is not an irreducible element in Z[i]. Hence, there is a
factorization
p = Œ±Œ≤ in Z[i]
in which neither Œ± = a + ib nor Œ≤ = c + id is a unit. Therefore, taking norms gives an
equation in Z:
p2 = ‚àÇ(p)
= ‚àÇ(Œ±Œ≤)
= ‚àÇ(Œ±)‚àÇ(Œ≤)
= (a2 + b2)(c2 + d2).
By Proposition 3.64, the only units in Z[i] are ¬±1 and ¬±i, so that any nonzero Gaussian
integer that is not a unit has norm > 1; therefore, a2 + b2 Ã∏= 1 and c2 + d2 Ã∏= 1. Euclid's
lemma now gives p | (a2 + b2) or p | (c2 + d2); the fundamental theorem of arithmetic
gives p = a2 + b2 (and p = c2 + d2), as desired.
‚Ä¢
We are going to determine all the irreducible elements in Z[i], but we Ô¨Årst prove a
lemma.
Lemma 3.67.
If Œ± ‚ààZ[i] is irreducible, then there is a unique prime number p with
Œ± | p in Z[i].
Proof.
Note that if Œ± ‚ààZ[i], then Œ± ‚ààZ[i]; since ‚àÇ(Œ±) = Œ±Œ±, we have Œ± | ‚àÇ(Œ±). Now
‚àÇ(Œ±) = p1 ¬∑ ¬∑ ¬∑ pn, where the pi are prime numbers. As Z[i] is a PID, Exercise 3.62 on
page 158 gives Œ± | pi for some i (for Œ± is irreducible). If Œ± | q for some prime q Ã∏= pi,
then Œ± | (q, pi) = 1, forcing Œ± to be a unit. This contradiction shows that pi is the unique
prime number divisible by Œ±.
‚Ä¢
Proposition 3.68.
Let Œ± = a + bi ‚ààZ[i] be neither 0 nor a unit. Then Œ± is irreducible if
and only if
(i) Œ± is an associate of a prime p in Z of the form p = 4m + 3; or
(ii) Œ± is an associate of 1 + i or its conjugate 1 ‚àíi; or
(iii) ‚àÇ(Œ±) = a2 + b2 is a prime in Z of the form 4m + 1.

Sec. 3.6
Euclidean Rings
157
Proof.
By Lemma 3.67, there is a unique prime number p divisible by Œ± in Z[i]. Since
Œ± | p, we have ‚àÇ(Œ±) | ‚àÇ(p) = p2 in Z, so that ‚àÇ(Œ±) = p or ‚àÇ(Œ±) = p2; that is,
a2 + b2 = p
or
a2 + b2 = p2,
Looking at p mod 4, we see that there are three possibilities (for p ‚â°0 mod 4 cannot
occur).
(i) p ‚â°3 mod 4.
In this case, a2 + b2 = p cannot occur, by (the easy direction of) Theorem 3.66, so
that ‚àÇ(Œ±) = a2 + b2 = p2. Now p is divisible by Œ±, so there is Œ≤ with Œ±Œ≤ = p. Hence,
‚àÇ(Œ±)‚àÇ(Œ≤) = ‚àÇ(p). Since p ‚ààZ, we have ‚àÇ(p) = p2, so that p2‚àÇ(Œ≤) = p2. Thus,
‚àÇ(Œ≤) = 1, Œ≤ is a unit, by Proposition 3.64(i), and p is irreducible in Z[i].
(ii) p ‚â°2 mod 4.
In this case, p = 2, and so a2 + b2 = 2 or a2 + b2 = 4. The latter case cannot occur
(because a and b are integers), and the Ô¨Årst case gives Œ± = 1 ¬± i (up to multiplication
by units). The reader should check that both 1 + i and 1 ‚àíi are, indeed, irreducible
elements.
(iii) p ‚â°1 mod 4.
If ‚àÇ(Œ±) is a prime p (with p ‚â°1 mod 4), then Œ± is irreducible, by Proposition 3.64(ii).
Conversely, suppose Œ± is irreducible. As ‚àÇ(Œ±) = p or ‚àÇ(Œ±) = p2, it sufÔ¨Åces to eliminate
the latter possibility. Since Œ± | p, we have p = Œ±Œ≤ for some Œ≤ ‚ààZ[i]; hence, as in
case (i), ‚àÇ(Œ±) = p2 implies that Œ≤ is a unit. Now Œ±Œ± = p2 = (Œ±Œ≤)2, so that Œ± = Œ±Œ≤2. But
Œ≤2 = ¬±1, by Proposition 3.64(iii), contradicting Œ± Ã∏= ¬±Œ±. Therefore, ‚àÇ(Œ±) = p.
‚Ä¢
For example, 3 is an irreducible element of the Ô¨Årst type, and 2 + i is an irreducible
element of the third type. We should remember that there are interesting connections be-
tween prime numbers and irreducible Gaussian integers, that knowing the Gaussian units
is valuable, and that the norm is a useful tool in proving results. The ring of Gaussian
integers is an instance of a ring of algebraic integers, and these comments remain true for
these rings as well.
EXERCISES
DeÔ¨Ånition.
Let k be a Ô¨Åeld. A common divisor of a1(x), a2(x), . . . , an(x) in k[x] is a polynomial
c(x) ‚ààk[x] with c(x) | ai(x) for all i; the greatest common divisor is the monic common divisor of
largest degree. We write c(x) = (a1, a2, . . . , an).
3.57 Let k be a Ô¨Åeld, and let polynomials a1(x), a2(x), . . . , an(x) in k[x] be given.
(i) Show that the greatest common divisor d(x) of these polynomials has the form
 ti(x)ai(x), where ti(x) ‚ààk[x] for 1 ‚â§i ‚â§n.
Hint. Example 3.49.
(ii) Prove that c(x) | d(x) for every monic common divisor c(x) of the ai(x).

158
Commutative Rings I
Ch. 3
3.58
(i) Show that x, y ‚ààk[x, y] are relatively prime, but that 1 is not a linear combination of
them [i.e., there do not exist s(x, y), t(x, y) ‚ààk[x, y] with 1 = xs(x, y) + yt(x, y)].
Hint. Use a degree argument.
(ii) Show that 2 and x are relatively prime in Z[x], but that 1 is not a linear combination of
them; that is, there do not exist s(x), t(x) ‚ààZ[x] with 1 = 2s(x) + xt(x).
3.59 A student claims that x ‚àí1 is not irreducible because x ‚àí1 = (‚àöx + 1)(‚àöx ‚àí1) is a
factorization. Explain the error of his ways.
Hint. Show that ‚àöx + 1 is not a polynomial.
3.60 Prove that there are domains R containing a pair of elements having no gcd. (See the deÔ¨Ånition
on page 147.)
Hint.
Let k be a Ô¨Åeld and let R be the subring of k[x] consisting of all polynomials having
no linear term; that is, f (x) ‚ààR if and only if
f (x) = s0 + s2x2 + s3x3 + ¬∑ ¬∑ ¬∑ .
Show that x5 and x6 have no gcd in R.
3.61 Prove that R = Z[
‚àö
2] = {a + b
‚àö
2 : a, b ‚ààZ} is a euclidean ring with ‚àÇ(a + b
‚àö
2) =
|a2 ‚àí2b2|.
3.62 If R is a euclidean ring and œÄ ‚ààR is irreducible, prove that œÄ | Œ±Œ≤ implies œÄ | Œ± or œÄ | Œ≤.
3.63 Let ‚àÇbe the degree function of a euclidean ring R. If m, n ‚ààN and m ‚â•1, prove that ‚àÇ‚Ä≤ is
also a degree function on R, where
‚àÇ‚Ä≤(x) = m‚àÇ(x) + n
for all x ‚ààR. Conclude that a euclidean ring may have no elements of degree 0 or degree 1.
3.64 Let R be a euclidean ring with degree function ‚àÇ.
(i) Prove that ‚àÇ(1) ‚â§‚àÇ(a) for all nonzero a ‚ààR.
(ii) Prove that a nonzero u ‚ààR is a unit if and only if ‚àÇ(u) = ‚àÇ(1).
Hint. A proof can be generalized from the special case of polynomials.
3.65 Let R be a euclidean ring, and assume that b ‚ààR is neither zero nor a unit. Prove, for every
i ‚â•0, that ‚àÇ(bi) < ‚àÇ(bi+1).
Hint. There are q,r ‚ààR with bi = qbi+1 + r.
3.66 If p is a prime and p ‚â°3 mod 4, prove that one of the congruences a2 ‚â°2 mod p or
a2 ‚â°‚àí2 mod p is solvable.
Hint. Show that I√óp ‚àº= ‚ü®‚àí1‚ü©√ó H, where H is a group of odd order m, say, and observe that
either 2 or ‚àí2 lies in H because
I2 √ó Im = ({1} √ó H) ‚à™({‚àí1} √ó H) .
Finally, use Exercise 2.54 on page 81.
3.7 LINEAR ALGEBRA
We interrupt the exposition to discuss some linear algebra, for it is a necessary tool in
further investigation of commutative rings.

Sec. 3.7
Linear Algebra
159
Vector Spaces
Linear algebra is the study of vector spaces and their homomorphisms, with applications
to systems of linear equations. From now on, we are going to assume that most readers
have had some course involving matrices, perhaps only with real entries or with complex
entries. Such courses often deal mainly with computational aspects of the subject, such as
Gaussian elimination, and Ô¨Ånding inverses, determinants, eigenvalues, and characteristic
polynomials of matrices, but here we do not emphasize this important aspect of linear
algebra. Instead, we discuss more theoretical properties of vector spaces (with scalars in
any Ô¨Åeld) and linear transformations (which are homomorphisms between vector spaces).
Dimension is a rather subtle idea. We think of a curve in the plane, that is, the image
of a continuous function f : R ‚ÜíR2, as a one-dimensional subset of a two-dimensional
ambient space. Imagine the confusion at the end of the nineteenth century when a "space-
Ô¨Ålling curve" was discovered: There exists a continuous function f : R ‚ÜíR2 with image
the whole plane! We are going to describe a way of deÔ¨Åning dimension that works for
analogs of euclidean space, called vector spaces (there are topological ways of deÔ¨Åning
dimension of more general spaces).
DeÔ¨Ånition.
If k is a Ô¨Åeld, then a vector space over k is an (additive) abelian group V
equipped with a scalar multiplication; that is, there is a function k √ó V ‚ÜíV , denoted by
(a, v) ‚Üíav, such that, for all a, b, 1 ‚ààk and all u, v ‚ààV ,
(i) a(u + v) = au + av;
(ii) (a + b)v = av + bv;
(iii) (ab)v = a(bv);
(iv) 1v = v.
The elements of V are called vectors and the elements of k are called scalars.13
Example 3.69.
(i) Euclidean space V = Rn is a vector space over R. Vectors are n-tuples (a1, . . . , an),
where ai ‚ààR for all i. Picture a vector v as an arrow from the origin to the point having
coordinates (a1, . . . , an). Addition is given by
(a1, . . . , an) + (b1, . . . , bn) = (a1 + b1, . . . , an + bn);
geometrically, the sum of two vectors is described by the parallelogram law.
Scalar multiplication is given by
av = a(a1, . . . , an) = (aa1, . . . , aan).
13The word vector comes from the Latin word meaning "to carry"; vectors in euclidean space carry the data of
length and direction. The word scalar comes from regarding v ‚Üíav as a change of scale. The terms scale and
scalar come from the Latin word meaning "ladder," for the rungs of a ladder are evenly spaced.

160
Commutative Rings I
Ch. 3
Scalar multiplication v ‚Üíav "stretches" v by a factor |a|, reversing its direction when a
is negative (we put quotes around stretches because av is shorter than v when |a| < 1).
(ii) The example in part (i) can be generalized. If k is any Ô¨Åeld, deÔ¨Åne V = kn, the set of
all n-tuples v = (a1, . . . , an), where ai ‚ààk for all i. Addition is given by
(a1, . . . , an) + (b1, . . . , bn) = (a1 + b1, . . . , an + bn),
and scalar multiplication is given by
av = a(a1, . . . , an) = (aa1, . . . , aan).
(iii) If R is a commutative ring and k is a subring that is a Ô¨Åeld, then R is a vector space
over k. Regard the elements of R as vectors and the elements of k as scalars; deÔ¨Åne scalar
multiplication av, where a ‚ààk and v ‚ààR, to be the given product of two elements in R.
Notice that the axioms in the deÔ¨Ånition of vector space are just particular cases of some of
the axioms holding in the commutative ring R.
For example, if k is a Ô¨Åeld, then the polynomial ring R = k[x] is a vector space over k.
Vectors are polynomials f (x), scalars are elements a ‚ààk, and scalar multiplication gives
the polynomial af (x); that is, if
f (x) = bnxn + ¬∑ ¬∑ ¬∑ + b1x + b0,
then
af (x) = abnxn + ¬∑ ¬∑ ¬∑ + ab1x + ab0.
In particular, if a Ô¨Åeld k is a subÔ¨Åeld of a larger Ô¨Åeld E, then E is a vector space
over k.
‚óÄ
A subspace of a vector space V is a subset of V that is a vector space under the addition
and scalar multiplication in V .
DeÔ¨Ånition.
If V is a vector space over a Ô¨Åeld k, then a subspace of V is a subset U of V
such that
(i) 0 ‚ààU;
(ii) u, u‚Ä≤ ‚ààU imply u + u‚Ä≤ ‚ààU;
(iii) u ‚ààU and a ‚ààk imply au ‚ààU.
Example 3.70.
(i) The extreme cases U = V and U = {0} (where {0} denotes the subset consisting of
the zero vector alone) are always subspaces of a vector space. A subspace U ‚äÜV with
U Ã∏= V is called a proper subspace of V ; we may write U ‚ääV to denote U being a proper
subspace of V .

Sec. 3.7
Linear Algebra
161
(ii) If v = (a1, . . . , an) is a nonzero vector in Rn, then the line through the origin
‚Ñì= {av : a ‚ààR}
is a subspace of Rn.
Similarly, a plane through the origin consists of all vectors of the form av1 +bv2, where
v1, v2 is a Ô¨Åxed pair of noncollinear vectors, and a, b vary over R. It is easy to check that
planes through the origin are subspaces of Rn.
(iii) If m ‚â§n and Rm is regarded as the set of all those vectors in Rn whose last n ‚àím
coordinates are 0, then Rm is a subspace of Rn. For example, we may regard the plane R2
as all points (x, y, 0) in R3.
(iv) If k is a Ô¨Åeld, then a homogeneous linear system over k of m equations in n unknowns
is a set of equations
a11x1 + ¬∑ ¬∑ ¬∑ + a1nxn = 0
a21x1 + ¬∑ ¬∑ ¬∑ + a2nxn = 0
...
...
am1x1 + ¬∑ ¬∑ ¬∑ + amnxn = 0,
where a ji ‚ààk. A solution of this system is a vector (c1, . . . , cn) ‚ààkn, where 
i a jici = 0
for all j; a solution (c1, . . . , cn) is nontrivial if some ci Ã∏= 0. The set of all solutions forms
a subspace of kn, called the solution space (or nullspace) of the system.
In particular, we can solve systems of linear equations over Ip, where p is a prime. This
says that we can treat a system of congruences mod p just as one treats an ordinary system
of equations.
For example, the system of congruences
3x ‚àí2y + z ‚â°1 mod 7
x + y ‚àí2z ‚â°0 mod 7
‚àíx + 2y + z ‚â°4 mod 7
can be regarded as a system of equations over the Ô¨Åeld I7. This system can be solved
just as in high school, for inverses mod 7 are now known: [2][4] = [1]; [3][5] = [1];
[6][6] = [1]. The solution is
(x, y, z) = ([5], [4], [1]).
‚óÄ
DeÔ¨Ånition.
A list in a vector space V is an ordered set v1, . . . , vn of vectors in V .
More precisely, we are saying that there is some n ‚â•1 and some function
œï : {1, 2, . . . , n} ‚ÜíV,
with œï(i) = vi for all i. Thus, X = im œï; note that X is ordered in the sense that there is
a Ô¨Årst vector v1, a second vector v2, and so forth. A vector may appear several times on a
list; that is, œï need not be injective.

162
Commutative Rings I
Ch. 3
DeÔ¨Ånition.
Let V be a vector space over a Ô¨Åeld k. A k-linear combination of a list
v1, . . . , vn in V is a vector v of the form
v = a1v1 + ¬∑ ¬∑ ¬∑ + anvn,
where ai ‚ààk for all i.
DeÔ¨Ånition.
If X = v1, . . . , vm is a list in a vector space V , then
‚ü®v1, . . . , vm‚ü©,
the set of all the k-linear combinations of v1, . . . , vm, is called the subspace spanned by
X. We also say that v1, . . . , vm spans ‚ü®v1, . . . , vm‚ü©.
Lemma 3.71.
Let V be a vector space over a Ô¨Åeld k.
(i) Every intersection of subspaces of V is itself a subspace.
(ii) If X = v1, . . . , vm is a list in V , then the intersection of all the subspaces of V con-
taining X is ‚ü®v1, . . . , vm‚ü©, the subspace spanned by v1, . . . , vm, and so ‚ü®v1, . . . , vm‚ü©
is the smallest subspace of V containing X.
Sketch of Proof.
Part (i) is routine. Let X = {v1, . . . , vm}, and let S denote the family of
all the subspaces of V containing X; we claim that
"
S‚ààS
S = ‚ü®v1, . . . , vm‚ü©.
The inclusion ‚äÜis clear, because ‚ü®v1, . . . , vm‚ü©‚ààS. For the reverse inclusion, note that if
S ‚ààS, then S contains v1, . . . , vm, and so it contains the set of all linear combination of
v1, . . . , vm, namely, ‚ü®v1, . . . , vm‚ü©.
‚Ä¢
It follows from the second part of the lemma that the subspace spanned by a list X =
v1, . . . , vm does not depend on the ordering of the vectors, but only on the set of vectors
themselves. Were all terminology in algebra consistent, we would call ‚ü®v1, . . . , vm‚ü©the
subspace generated by X. The reason for the different terms is that the theories of groups,
rings, and vector spaces developed independently of each other.
If X = ‚àÖ, then ‚ü®X‚ü©= 
S‚ààS S, where S is the family of all the subspaces of V
containing X. As every subspace contains X = ‚àÖ, {0} itself is one of the subspaces
occurring in the intersection of all the subspaces of V , and so ‚ü®‚àÖ‚ü©= 
S‚äÜV S = {0}.
Example 3.72.
(i) Let V = R2, let e1 = (1, 0), and let e2 = (0, 1). Now V = ‚ü®e1, e2‚ü©, for if v = (a, b) ‚àà
V , then
v = (a, 0) + (0, b)
= a(1, 0) + b(0, 1)
= ae1 + be2 ‚àà‚ü®e1, e2‚ü©.

Sec. 3.7
Linear Algebra
163
(ii) If k is a Ô¨Åeld and V = kn, deÔ¨Åne ei as the n-tuple having 1 in the ith coordinate and 0's
elsewhere. The reader may adapt the argument in part (i) to show that e1, . . . , en spans kn.
(iii) A vector space V need not be spanned by a Ô¨Ånite list. For example, let V = k[x], and
suppose that X = f1(x), . . . , fm(x) is a Ô¨Ånite list in V . If d is the largest degree of any
of the fi(x), then every (nonzero) k-linear combination of f1(x), . . . , fm(x) has degree at
most d. Thus, xd+1 is not a k-linear combination of vectors in X, and so X does not span
k[x].
‚óÄ
The following deÔ¨Ånition makes sense even though we have not yet deÔ¨Åned dimension.
DeÔ¨Ånition.
A vector space V is called Ô¨Ånite-dimensional if it is spanned by a Ô¨Ånite list;
otherwise, V is called inÔ¨Ånite-dimensional.
Example 3.72(ii) shows that kn is Ô¨Ånite-dimensional, while part (iii) of this Example
shows that k[x] is inÔ¨Ånite-dimensional. By Example 3.69(iii), both R and C are vector
spaces over Q, and they are both inÔ¨Ånite-dimensional.
Notation.
If v1, . . . , vm is a list, then v1, . . . , vi . . . , vm is the shorter list with vi deleted.
Proposition 3.73.
If V is a vector space, then the following conditions on a list X =
v1, . . . , vm spanning V are equivalent:
(i) X is not a shortest spanning list;
(ii) some vi is in the subspace spanned by the others; that is,
vi ‚àà‚ü®v1, . . . , vi, . . . , vm‚ü©;
(iii) there are scalars a1, . . . , am, not all zero, with
m

‚Ñì=1
a‚Ñìv‚Ñì= 0.
Sketch of Proof.
(i) ‚áí(ii). If X is not a shortest spanning list, then one of the vectors in
X can be thrown out, and the shorter list still spans.
(ii) ‚áí(iii). If vi = 
jÃ∏=i c jv j, then deÔ¨Åne ai = ‚àí1 Ã∏= 0 and a j = c j for all j Ã∏= i.
(iii) ‚áí(i). The given equation implies that one of the vectors, say, vi, is a linear combi-
nation of the others. Deleting vi gives a shorter list, which still spans: If v ‚ààV is a linear
combination of all the v j (including vi), just substitute the expression for vi as a linear
combination of the other v j and collect terms.
‚Ä¢

164
Commutative Rings I
Ch. 3
DeÔ¨Ånition.
A list X = v1, . . . , vm in a vector space V is linearly dependent if there
are scalars a1, . . . , am, not all zero, with m
‚Ñì=1 a‚Ñìv‚Ñì= 0; otherwise, X is called linearly
independent.
The empty set ‚àÖis deÔ¨Åned to be linearly independent (we may interpret ‚àÖas a list of
length 0).
Example 3.74.
(i) Any list X = v1, . . . , vm containing the zero vector is linearly dependent.
(ii) A list v1 of length 1 is linearly dependent if and only if v1 = 0; hence, a list v1 of
length 1 is linearly independent if and only if v1 Ã∏= 0.
(iii) A list v1, v2 is linearly dependent if and only if one of the vectors is a scalar multiple
of the other.
(iv) If there is a repetition in the list v1, . . . , vm (that is, if vi = v j for some i Ã∏= j), then
v1, . . . , vm is linearly dependent: DeÔ¨Åne ci = 1, c j = ‚àí1, and all other c = 0. Therefore,
if v1, . . . , vm is linearly independent, then all the vectors vi are distinct.
‚óÄ
The contrapositive of Proposition 3.73 is worth stating.
Corollary 3.75.
If X = v1, . . . , vm is a list spanning a vector space V , then X is a
shortest spanning list if and only if X is linearly independent.
Linear independence has been deÔ¨Åned indirectly, as not being linearly dependent. Be-
cause of the importance of linear independence, let us deÔ¨Åne it directly. A list X =
v1, . . . , vm is linearly independent if, whenever a k-linear combination m
‚Ñì=1 a‚Ñìv‚Ñì= 0,
then every ai = 0. It follows that every sublist of a linearly independent list is itself linearly
independent (this is one reason for decreeing that ‚àÖbe linearly independent).
We have arrived at the notion we have been seeking.
DeÔ¨Ånition.
A basis of a vector space V is a linearly independent list that spans V .
Thus, bases are shortest spanning lists. Of course, all the vectors in a linearly indepen-
dent list v1, . . . , vn are distinct, by Example 3.74(iv).
Example 3.76.
In Example 3.72(ii), we saw that X = e1, . . . , en spans kn, where ei is the n-tuple having 1
in the ith coordinate and 0's elsewhere. We can easily prove that X is linearly independent,
and hence it is a basis; it is called the standard basis of kn.
‚óÄ
Proposition 3.77.
Let X = v1, . . . , vn be a list in a vector space V over a Ô¨Åeld k. Then X
is a basis if and only if each vector in V has a unique expression as a k-linear combination
of vectors in X.

Sec. 3.7
Linear Algebra
165
Sketch of Proof.
If a vector v =  aivi =  bivi, then (ai ‚àíbi)vi = 0, and so
independence gives ai = bi for all i; that is, the expression is unique.
Conversely, existence of an expression shows that the list of vi spans. Moreover, if
0 =  civi with not all ci = 0, then the vector 0 does not have a unique expression as a
linear combination of the vi.
‚Ä¢
DeÔ¨Ånition.
If X = v1, . . . , vn is a basis of a vector space V and if v ‚ààV , then there
are unique scalars a1, . . . , an with v = n
i=1 aivi. The n-tuple (a1, . . . , an) is called the
coordinate set of a vector v ‚ààV relative to the basis X.
Observe that if v1, . . . , vn is the standard basis of V = kn, then this coordinate set
coincides with the usual coordinate set.
If v1, . . . , vn is a basis of a vector space V over a Ô¨Åeld k, then each vector v ‚ààV has a
unique expression
v = a1v1 + a2v2 + ¬∑ ¬∑ ¬∑ + anvn,
where ai ‚ààk for all i. Since there is a Ô¨Årst vector v1, a second vector v2, and so forth, the
coefÔ¨Åcients in this k-linear combination determine a unique n-tuple (a1, a2, . . . , an). Were
a basis merely a subset of V and not a list (i.e., an ordered subset), then there would be n!
coordinate sets for every vector.
We are going to deÔ¨Åne the dimension of a vector space V to be the number of vectors
in a basis. Two questions arise at once.
(i) Does every vector space have a basis?
(ii) Do all bases of a vector space have the same number of elements?
The Ô¨Årst question is easy to answer; the second needs some thought.
Theorem 3.78.
Every Ô¨Ånite-dimensional vector space V has a basis.
Sketch of Proof.
A Ô¨Ånite spanning list X exists, since V is Ô¨Ånite-dimensional. If it is
linearly independent, it is a basis; if not, X can be shortened to a spanning sublist X‚Ä≤, by
Proposition 3.73. If X‚Ä≤ is linearly independent, it is a basis; if not, X‚Ä≤ can be shortened
to a spanning sublist X‚Ä≤‚Ä≤. Eventually, we arrive at a shortest spanning sublist, which is
independent and hence is a basis.
‚Ä¢
The deÔ¨Ånitions of spanning and linear independence can be extended to inÔ¨Ånite lists in a
vector space, and we can then prove that inÔ¨Ånite-dimensional vector spaces also have bases
(see Theorem 6.48). For example, it turns out that a basis of k[x] is 1, x, x2, . . . , xn, . . . .
We can now prove invariance of dimension, one of the most important results about
vector spaces.
Lemma 3.79.
Let u1, . . . , un be elements in a vector space V , and let v1, . . . , vm ‚àà
‚ü®u1, . . . , un‚ü©. If m > n, then v1, . . . , vm is a linearly dependent list.

166
Commutative Rings I
Ch. 3
Proof.
The proof is by induction on n ‚â•1.
Base Step. If n = 1, then there are at least two vectors v1, v2 and v1 = a1u1 and v2 = a2u2.
If u1 = 0, then v1 = 0 and the list of v's is linearly dependent. Suppose u1 Ã∏= 0. We may
assume that v1 Ã∏= 0, or we are done; hence, a1 Ã∏= 0. Therefore, v1, v2 is linearly dependent,
for v2 ‚àía2a‚àí1
1 v1 = 0, and hence the larger list v1, . . . , vm is linearly dependent.
Inductive Step. There are equations, for i = 1, . . . , m,
vi = ai1u1 + ¬∑ ¬∑ ¬∑ + ainun.
We may assume that some ai1 Ã∏= 0, otherwise v1, . . . , vm ‚àà‚ü®u2, . . . , un‚ü©, and the inductive
hypothesis applies. Changing notation if necessary (that is, by re-ordering the v's), we may
assume that a11 Ã∏= 0. For each i ‚â•2, deÔ¨Åne
v‚Ä≤
i = vi ‚àíai1a‚àí1
11 v1 ‚àà‚ü®u2, . . . , un‚ü©
(writing v‚Ä≤
i as a linear combination of the u's, the coefÔ¨Åcient of u1 is ai1‚àí(ai1a‚àí1
11 )a11 = 0).
Since m ‚àí1 > n ‚àí1, the inductive hypothesis gives scalars b2, . . . , bm, not all 0, with
b2v‚Ä≤
2 + ¬∑ ¬∑ ¬∑ + bmv‚Ä≤
m = 0.
Rewrite this equation using the deÔ¨Ånition of v‚Ä≤
i:

‚àí

i‚â•2
biai1a‚àí1
11

v1 + b2v2 + ¬∑ ¬∑ ¬∑ + bmvm = 0.
Not all the coefÔ¨Åcients are 0, and so v1, . . . , vm is linearly dependent.
‚Ä¢
The following familiar fact illustrates the intimate relation between linear algebra and
systems of linear equations.
Corollary 3.80.
A homogeneous system of linear equations, over a Ô¨Åeld k, with more
unknowns than equations has a nontrivial solution.
Proof.
An n-tuple (Œ≤1, . . . , Œ≤n) is a solution of a system
Œ±11x1 + ¬∑ ¬∑ ¬∑ + Œ±1nxn = 0
...
...
...
Œ±m1x1 + ¬∑ ¬∑ ¬∑ + Œ±mnxn = 0
if Œ±i1Œ≤1 + ¬∑ ¬∑ ¬∑ + Œ±inŒ≤n = 0 for all i. In other words, if c1, . . . , cn are the columns of the
m √ó n coefÔ¨Åcient matrix A = [Œ±i j], then
Œ≤1c1 + ¬∑ ¬∑ ¬∑ + Œ≤ncn = 0.
Note that ci ‚ààkm. Now km can be spanned by m vectors (the standard basis, for example).
Since n > m, by hypothesis, Lemma 3.79 shows that the list c1, . . . , cn is linearly depen-
dent; there are scalars Œ≥1, . . . , Œ≥n, not all zero, with Œ≥1c1 + ¬∑ ¬∑ ¬∑ + Œ≥ncn = 0. Therefore,
(Œ≥1, . . . , Œ≥n) is a nontrivial solution of the system.
‚Ä¢

Sec. 3.7
Linear Algebra
167
Theorem 3.81 (Invariance of Dimension).
If X = x1, . . . , xn and Y = y1, . . . , ym are
bases of a vector space V , then m = n.
Proof.
If m Ã∏= n, then either n < m or m < n.
In the Ô¨Årst case, y1, . . . , ym ‚àà
‚ü®x1, . . . , xn‚ü©, because X spans V , and Lemma 3.79 gives Y linearly dependent, a con-
tradiction. A similar contradiction arises if m < n, and so we must have m = n.
‚Ä¢
It is now permissible to make the following deÔ¨Ånition.
DeÔ¨Ånition.
If V is a Ô¨Ånite-dimensional vector space over a Ô¨Åeld k, then its dimension,
denoted by dimk(V ) or dim(V ), is the number of elements in a basis of V .
Example 3.82.
(i) Example 3.76 shows that kn has dimension n, which agrees with our intuition when
k = R. Thus, the plane R √ó R is two-dimensional!
(ii) If V = {0}, then dim(V ) = 0, for there are no elements in its basis ‚àÖ. (This is a good
reason for deÔ¨Åning ‚àÖto be linearly independent.)
(iii) Let X = {x1, . . . , xn} be a Ô¨Ånite set. DeÔ¨Åne
k X = {functions f : X ‚Üík}.
Now k X is a vector space if we deÔ¨Åne addition f + f ‚Ä≤ to be
f + f ‚Ä≤ : x ‚Üíf (x) + f ‚Ä≤(x)
and scalar multiplication af , for a ‚ààk and f : X ‚Üík, by
af : x ‚Üíaf (x).
It is easy to check that the set of n functions of the form fx, where x ‚ààX, deÔ¨Åned by
fx(y) =

1
if y = x;
0
if y Ã∏= x,
form a basis, and so dim(k X) = n = |X|.
The reader should note that this is not a new example: An n-tuple (a1, . . . , an) is really
a function f : {1, . . . , n} ‚Üík with f (i) = ai for all i. Thus, the functions fx comprise
the standard basis.
‚óÄ
Here is a second proof of invariance of dimension; it will be used, in Chapter 6, to
generalize the notion of dimension to the notion of transcendence degree. We begin with
a modiÔ¨Åcation of the proof of Proposition 3.73.
Lemma 3.83.
If X = v1, . . . , vn is a linearly dependent list of vectors in a vector space
V , then there exists vr with r ‚â•1 with vr ‚àà‚ü®v1, v2, . . . , vr‚àí1‚ü©[when r = 1, we interpret
‚ü®v1, . . . , vr‚àí1‚ü©to mean {0}].

168
Commutative Rings I
Ch. 3
Remark.
Let us compare Proposition 3.73 with this one. The earlier result says that if
v1, v2, v3 is linearly dependent, then either v1 ‚àà‚ü®v2, v3‚ü©, v2 ‚àà‚ü®v1, v3‚ü©, or v3 ‚àà‚ü®v1, v2‚ü©.
This lemma says that either v1 ‚àà{0}, v2 ‚àà‚ü®v1‚ü©, or v3 ‚àà‚ü®v1, v2‚ü©.
‚óÄ
Proof.
Let r be the largest integer for which v1, . . . , vr‚àí1 is linearly independent. If
v1 = 0, then v1 ‚àà{0}, and we are done. If v1 Ã∏= 0, then r ‚â•2; since v1, v2, . . . , vn is
linearly dependent, we have r ‚àí1 < n. As r ‚àí1 is largest, the list v1, v2, . . . , vr is linearly
dependent. There are thus scalars a1, . . . , ar, not all zero, with a1v1 + ¬∑ ¬∑ ¬∑ + arvr = 0.
In this expression, we must have ar Ã∏= 0, for otherwise v1, . . . , vr‚àí1 would be linearly
dependent. Therefore,
vr =
r‚àí1

i=1
(‚àía‚àí1
r )aivi ‚àà‚ü®v1, . . . , vr‚àí1‚ü©.
‚Ä¢
Lemma 3.84 (Exchange Lemma).
If X = x1, . . . , xm is a basis of a vector space V
and y1, . . . , yn is a linearly independent subset of V , then n ‚â§m.
Proof.
We begin by showing that one of the x's in X can be replaced by yn so that the
new list still spans V . Now yn ‚àà‚ü®X‚ü©, since X spans V , so that the list
yn, x1, . . . , xm
is linearly dependent, by Proposition 3.73. Since the list y1, . . . , yn is linearly independent,
yn /‚àà{0}. By Lemma 3.83, there is some i with xi = ayn + 
j<i a j x j. Throwing out xi
and replacing it by yn gives a spanning list
X‚Ä≤ = yn, x1, . . . , xi, . . . , xm :
If v = m
j=1 b j x j, then (as in the proof of Proposition 3.73), replace xi by its expression
as a k-linear combination of the other x's and yn, and then collect terms.
Now repeat this argument for the spanning list yn‚àí1, yn, x1, . . . ,xi, . . . , xm. The options
offered by Lemma 3.83 for this linearly dependent list are yn ‚àà‚ü®yn‚àí1‚ü©, x1 ‚àà‚ü®yn‚àí1, yn‚ü©,
x2 ‚àà‚ü®yn‚àí1, yn, x1‚ü©, and so forth. Since Y is linearly independent, so is its sublist yn‚àí1, yn,
and the Ô¨Årst option yn ‚àà‚ü®yn‚àí1‚ü©is not feasible. It follows that the disposable vector
(provided by Lemma 3.83) must be one of the remaining x's, say x‚Ñì. After throwing out
x‚Ñì, we have a new spanning list X‚Ä≤‚Ä≤. Repeat this construction of spanning lists; each time a
new y is adjoined as the Ô¨Årst vector, an x is thrown out, for the option yi ‚àà‚ü®yi+1, . . . , yn‚ü©
is not feasible. If n > m, that is, if there are more y's than x's, then this procedure ends
with a spanning list consisting of m
y's (one for each of the m
x's thrown out) and
no x's. Thus a proper sublist of Y = y1, . . . , yn spans V , and this contradicts the linear
independence of Y. Therefore, n ‚â§m.
‚Ä¢

Sec. 3.7
Linear Algebra
169
Theorem 3.85 (Invariance of Dimension).
If X = x1, . . . , xm and Y = y1, . . . , yn are
bases of a vector space V , then m = n.
Proof.
By Lemma 3.84, viewing X as a basis with m elements and and Y as a linearly
independent list with n elements gives the inequality n ‚â§m; viewing Y a basis and X
as a linearly independent list gives the reverse inequality m ‚â§n. Therefore, m = n, as
desired.
‚Ä¢
DeÔ¨Ånition.
A longest (or a maximal) linearly independent list u1, . . . , um is a linearly
independent list for which there is no vector v ‚ààV such that u1, . . . , um, v is linearly
independent.
Lemma 3.86.
If V is a Ô¨Ånite-dimensional vector space, then a longest linearly indepen-
dent list v1, . . . , vn is a basis of V .
Sketch of Proof.
If the list is not a basis, then it does not span: There is w ‚ààV with
w /‚àà‚ü®v1, . . . , vn‚ü©. But the longer list with w adjoined is linearly independent, by Proposi-
tion 3.73.
‚Ä¢
It is not obvious that there are any longest linearly independent lists; that they do exist
follows from the next result, which is quite useful in its own right.
Proposition 3.87.
Let Z = u1, . . . , um be a linearly independent list in an n-dimensional
vector space V . Then Z can be extended to a basis; i.e., there are vectors vm+1, . . . , vn so
that u1, . . . , um, vm+1, . . . , vn is a basis of V .
Sketch of Proof.
If the linearly independent list Z does not span V , there is w1 ‚ààV
with w1 /‚àà‚ü®Z‚ü©, and the longer list Z, w1 is linearly independent, by Proposition 3.73. If
Z, w1 does not span V , there is w2 ‚ààV with w2 /‚àà‚ü®Z, w1‚ü©. Since dim(V ) = n, the
length of these lists can never exceed n. Otherwise, compare a linearly independent list
with n + 1 elements with a basis, and reach a contradiction using the exchange lemma,
Lemma 3.84.
‚Ä¢
Corollary 3.88.
If dim(V ) = n, then any list of n + 1 or more vectors is linearly depen-
dent.
Sketch of Proof.
Otherwise, such a list could be extended to a basis having too many
elements.
‚Ä¢
Corollary 3.89.
Let V be a vector space with dim(V ) = n.
(i) A list of n vectors that spans V must be linearly independent.
(ii) Any linearly independent list of n vectors must span V .

170
Commutative Rings I
Ch. 3
Sketch of Proof.
(i) Were it linearly dependent, then the list could be shortened to give a
basis, and this basis is too small.
(ii) If the list does not span, the it could be lengthened to give a basis, and this basis is too
large.
‚Ä¢
Corollary 3.90.
Let U be a subspace of a vector space V of dimension n.
(i) U is Ô¨Ånite-dimensional and dim(U) ‚â§dim(V ).
(ii) If dim(U) = dim(V ), then U = V .
Sketch of Proof.
(i) Take u1 ‚ààU. If U = ‚ü®u1‚ü©, then U is Ô¨Ånite-dimensional. Otherwise,
there is u2 /‚àà‚ü®u1‚ü©. By Proposition 3.73, u1, u2 is linearly independent. If U = ‚ü®u1, u2‚ü©,
we are done. This process cannot be repeated n + 1 times, for then u1, . . . , un+1 would be
a linearly independent list in U ‚äÜV , contradicting Corollary 3.88.
A basis of U is linearly independent, and so it can be extended to a basis of V .
(ii) If dim(U) = dim(V ), then a basis of U is already a basis of V (otherwise it could be
extended to a basis of V that would be too large).
‚Ä¢
EXERCISES
3.67 If the only subspaces of a vector space V are {0} and V itself, prove that dim(V ) ‚â§1.
3.68 Prove, in the presence of all the other axioms in the deÔ¨Ånition of vector space, that the com-
mutative law for vector addition is redundant; that is, if V satisÔ¨Åes all the other axioms, then
u + v = v + u for all u, v ‚ààV .
Hint. If u, v ‚ààV , evaluate ‚àí[(‚àív) + (‚àíu)] in two ways.
3.69 If V is a vector space over I2 and if v1 Ã∏= v2 are nonzero vectors in V , prove that v1, v2 is
linearly independent. Is this true for vector spaces over any other Ô¨Åeld?
3.70 Prove that the columns of an m √ó n matrix A over a Ô¨Åeld k are linearly dependent in km if and
only if the homogeneous system Ax = 0 has a nontrivial solution.
3.71 If U is a subspace of a vector space V over a Ô¨Åeld k, deÔ¨Åne a scalar multiplication on the
quotient group V/U by
Œ±(v + U) = Œ±v + U,
where Œ± ‚ààk and v ‚ààV . Prove that this is a well-deÔ¨Åned function that makes V/U into a
vector space over k (V/U is called a quotient space).
3.72 If V is a Ô¨Ånite-dimensional vector space and U is a subspace, prove that
dim(U) + dim(V/U) = dim(V ).
Hint. Prove that if v1 + U, . . . , vr + U is a basis of V/U, then the list v1, . . . , vr is linearly
independent.

Sec. 3.7
Linear Algebra
171
DeÔ¨Ånition.
If U and W are subspaces of a vector space V , deÔ¨Åne
U + W = {u + w : u ‚ààU and w ‚ààW}.
3.73
(i) Prove that U + W is a subspace of V .
(ii) If U and U‚Ä≤ are subspaces of a Ô¨Ånite-dimensional vector space V , prove that
dim(U) + dim(U‚Ä≤) = dim(U ‚à©U‚Ä≤) + dim(U + U‚Ä≤).
Hint. Take a basis of U ‚à©U‚Ä≤ and extend it to bases of U and of U‚Ä≤.
DeÔ¨Ånition.
If U and W are vector spaces over a Ô¨Åeld k, then their direct sum is the set of all ordered
pairs,
U ‚äïW = {(u, w) : u ‚ààU and w ‚ààW},
with addition
(u, w) + (u‚Ä≤, w‚Ä≤) = (u + u‚Ä≤, w + w‚Ä≤)
and scalar multiplication
Œ±(u, w) = (Œ±u, Œ±w).
3.74 If U and W are Ô¨Ånite-dimensional vector spaces over a Ô¨Åeld k, prove that
dim(U ‚äïW) = dim(U) + dim(W).
Linear Transformations
Homomorphisms between vector spaces are called linear transformations.
DeÔ¨Ånition.
If V and W are vector spaces over a Ô¨Åeld k, then a function T : V ‚ÜíW is a
linear transformation if, for all vectors u, v ‚ààV and all scalars a ‚ààk,
(i) T (u + v) = T (u) + T (v);
(ii) T (av) = aT (v).
We say that a linear transformation T is nonsingular (or is an isomorphism) if T is a
bijection. Two vector spaces V and W over k are isomorphic, denoted by V ‚àº= W, if there
is a nonsingular linear transformation T : V ‚ÜíW.
If we forget the scalar multiplication, then a vector space is an (additive) abelian group
and a linear transformation T is a group homomorphism. It is easy to see that T preserves
all k-linear combinations:
T (a1v1 + ¬∑ ¬∑ ¬∑ + amvm) = a1T (v1) + ¬∑ ¬∑ ¬∑ + amT (vm).

172
Commutative Rings I
Ch. 3
Example 3.91.
(i) The identity function 1V : V ‚ÜíV on any vector space V is a nonsingular linear trans-
formation.
(ii) If Œ∏ is an angle, then rotation about the origin by Œ∏ is a linear transformation RŒ∏ : R2 ‚Üí
R2. The function RŒ∏ preserves addition because it takes parallelograms to parallelograms,
and it preserves scalar multiplication because it preserves the lengths of arrows.
(iii) If V and W are vector spaces over a Ô¨Åeld k, write Homk(V, W) for the set of all linear
transformations V ‚ÜíW. DeÔ¨Åne addition S + T by v ‚ÜíS(v) + T (v) for all v ‚ààV ,
and deÔ¨Åne scalar multiplication Œ±T : V ‚ÜíW, where Œ± ‚ààk, by v ‚ÜíŒ±T (v) for all
v ‚ààV . Both S + T and Œ±T are linear transformations, and Homk(V, W) is a vector space
over k.
‚óÄ
DeÔ¨Ånition.
If V is a vector space over a Ô¨Åeld k, then the general linear group, denoted
by GL(V ), is the set of all nonsingular linear transformations V ‚ÜíV .
A composite ST of linear transformations S and T is again a linear transformation,
and ST is nonsingular if both S and T are; moreover, the inverse of a nonsingular linear
transformation is again nonsingular. It follows that GL(V ) is a group with composition as
operation, for composition of functions is always associative.
We now show how to construct linear transformations T : V ‚ÜíW, where V and W are
vector spaces over a Ô¨Åeld k. The next theorem says that there is a linear transformation that
does anything to a basis.
Theorem 3.92.
Let v1, . . . , vn be a basis of a vector space V over a Ô¨Åeld k. If W is
a vector space over k and u1, . . . , un is a list in W, then there exists a unique linear
transformation T : V ‚ÜíW with T (vi) = ui for all i.
Proof.
By Theorem 3.77, each v ‚ààV has a unique expression of the form v = 
i aivi,
and so T : V ‚ÜíW, given by T (v) =  aiui, is a (well-deÔ¨Åned!) function. It is now a
routine veriÔ¨Åcation to check that T is a linear transformation.
To prove uniqueness of T , assume that S : V ‚ÜíW is a linear transformation with
S(vi) = ui = T (vi)
for all i. If v ‚ààV , then v =  aivi and
S(v) = S

aivi

=

S(aivi)
=

ai S(vi)
=

aiT (vi) = T (v).
Since v is arbitrary, S = T .
‚Ä¢

Sec. 3.7
Linear Algebra
173
Corollary 3.93.
If two linear transformations S, T : V ‚ÜíW agree on a basis, then
S = T .
Proof.
This follows at once from the uniqueness of the deÔ¨Åned linear transformation.
‚Ä¢
Linear transformations deÔ¨Åned on kn are easy to describe.
Proposition 3.94.
If T : kn ‚Üíkm is a linear transformation, then there exists an m √ó n
matrix A such that
T (y) = Ay
for all y ‚ààkn (here, y is an n √ó 1 column matrix and Ay is matrix multiplication).
Sketch of Proof.
If e1, . . . , en is the standard basis of kn and e‚Ä≤
1, . . . , e‚Ä≤
m is the standard
basis of km, deÔ¨Åne A = [ai j] to be the matrix whose jth column is the coordinate set of
T (e j). If S : kn ‚Üíkm is deÔ¨Åned by S(y) = Ay, then S = T because both agree on a
basis: T (e j) = 
i ai jei = Ae j.
‚Ä¢
Theorem 3.92 establishes the connection between linear transformations and matrices,
and the deÔ¨Ånition of matrix multiplication arises from applying this construction to the
composite of two linear transformations.
DeÔ¨Ånition.
Let X = v1, . . . , vn be a basis of V and let Y = w1, . . . , wm be a basis of
W. If T : V ‚ÜíW is a linear transformation, then the matrix of T is the m √ó n matrix
A = [ai j] whose jth column a1 j, a2 j, . . . , amj is the coordinate set of T (v j) determined
by the w's: T (v j) = m
i=1 ai jwi. The matrix A does depend on the choice of bases X
and Y; we will write
A = Y [T ]X
when it is necessary to display them.
In case V = W, we often let the bases X = v1, . . . , vn and w1, . . . , wm coincide. If
1V : V ‚ÜíV , given by v ‚Üív, is the identity linear transformation, then X[1V ]X is the
n √ó n identity matrix In (usually, the subscript n is omitted), deÔ¨Åned by
I = [Œ¥i j],
where Œ¥i j is the Kronecker delta. Thus, I has 1's on the diagonal and 0's elsewhere. On
the other hand, if X and Y are different bases, then Y [1V ]X is not the identity matrix; its
columns are the coordinate sets of the x's with respect to the basis Y.
Example 3.95.
Let T : V ‚ÜíW be a linear transformation, and let X = v1, . . . , vn and Y = w1, . . . , wm
be bases of V and W, respectively. The matrix for T is set up from the equation
T (v j) = a1 jw1 + a2 jw2 + ¬∑ ¬∑ ¬∑ + amjwm.

174
Commutative Rings I
Ch. 3
Why are the indices reversed? Why not write
T (v j) = a j1w1 + a j2w2 + ¬∑ ¬∑ ¬∑ + a jmwm?
Consider the following example. Let A be an m √ó n matrix over a Ô¨Åeld k. The function
T : kn ‚Üíkm, deÔ¨Åned by T (X) = AX, where X is an n √ó 1 column vector, is a linear
transformation. If e1, . . . , en and e‚Ä≤
1, . . . , e‚Ä≤
m are the standard bases of kn and km, respec-
tively, then the deÔ¨Ånition of matrix multiplication says that T (e j) = Ae j is the jth column
of A. But
Ae j = a1 je‚Ä≤
1 + a2 je‚Ä≤
2 + ¬∑ ¬∑ ¬∑ + amje‚Ä≤
m.
Therefore, the matrix associated to T is the original matrix A.
In Proposition 3.98, we shall prove that matrix multiplication arises from composition
of linear transformations. If T : V ‚ÜíW has matrix A and S : W ‚ÜíU has matrix B, then
the linear transformation ST : V ‚ÜíU has matrix B A. Had we deÔ¨Åned matrices of linear
transformations by making coordinate sets rows instead of columns, then the matrix of ST
would have been AB.
‚óÄ
Example 3.96.
(i) Let T : R2 ‚ÜíR2 be rotation by 90‚ó¶. The matrix of T relative to the standard basis
X = (1, 0), (0, 1) is
X[T ]X =
0
‚àí1
1
0

.
However, if Y = (0, 1), (1, 0), then
Y [T ]Y =
 0
1
‚àí1
0

.
(ii) Let k be a Ô¨Åeld, let T : V ‚ÜíV be a linear transformation on a two-dimensional
vector space, and assume that there is some vector v ‚ààV with T (v) not a scalar multiple
of v. The assumption on v says that the list X = v, T (v) is linearly independent, by
Example 3.74(iii), and hence it is a basis of V [because dim(V ) = 2]. Write v1 = v and
v2 = T v.
We compute X[T ]X.
T (v1) = v2
and
T (v2) = av1 + bv2
for some a, b ‚ààk. We conclude that
X[T ]X =
0
a
1
b

.
‚óÄ
The following proposition is a paraphrase of Theorem 3.92.
Proposition 3.97.
Let V and W be vector spaces over a Ô¨Åeld k, and let X = v1, . . . , vn
and Y = w1, . . . , wm be bases of V and W, respectively. If Homk(V, W) denotes the set
of all linear transformations T : V ‚ÜíW, and Matm√ón(k) denotes the set of all m √ó n
matrices with entries in k, then the function T ‚ÜíY [T ]X is a bijection Homk(V, W) ‚Üí
Matm√ón(k).

Sec. 3.7
Linear Algebra
175
Proof.
Given a matrix A, its columns deÔ¨Åne vectors in W; in more detail, if the jth
column of A is (a1 j, . . . , amj), deÔ¨Åne z j = m
i=1 ai jwi. By Theorem 3.92, there exists
a linear transformation T : V ‚ÜíW with T (v j) = z j and Y [T ]X = A. Therefore, ¬µ is
surjective.
To see that ¬µ is injective, suppose that Y [T ]X = A = Y [S]X. Since the columns of A
determine T (v j) and S(v j) for all j, Corollary 3.93 gives S = T .
‚Ä¢
The next proposition shows where the deÔ¨Ånition of matrix multiplication comes from:
the product of two matrices is the matrix of a composite.
Proposition 3.98.
Let T : V ‚ÜíW and S : W ‚ÜíU be linear transformations. Choose
bases X = x1, . . . , xn of V , Y = y1, . . . , ym of W, and Z = z1, . . . , z‚Ñìof U. Then
Z[S ‚ó¶T ]X =

Z[S]Y

Y [T ]X

.
Proof.
Let Y [T ]X = [ai j], so that T (x j) = 
p apj yp, and let Z[S]Y = [bqp], so that
S(yp) = 
q bqpzq. Then
ST (x j) = S(T (x j)) = S

p
apj yp

=

p
apj S(yp) =

p

q
apjbqpzq =

q
cqjzq,
where cqj = 
p bqpapj. Therefore,
Z[ST ]X = [cqj] = Z[S]Y Y [T ]X.
‚Ä¢
Corollary 3.99.
Matrix multiplication is associative.
Proof.
Let A be an m √ó n matrix, let B be an n √ó p matrix, and let C be a p √ó q matrix.
By Theorem 3.92, there are linear transformations
kq
T‚Üík p
S‚Üíkn
R‚Üíkm
with C = [T ], B = [S], and A = [R].
Then
[R ‚ó¶(S ‚ó¶T )] = [R][S ‚ó¶T ] = [R]([S][T ]) = A(BC).
On the other hand,
[(R ‚ó¶S) ‚ó¶T ] = [R ‚ó¶S][T ] = ([R][S])[T ] = (AB)C.
Since composition of functions is associative,
R ‚ó¶(S ‚ó¶T ) = (R ‚ó¶S) ‚ó¶T,
and so
A(BC) = [R ‚ó¶(S ‚ó¶T )] = [(R ‚ó¶S) ‚ó¶T ] = (AB)C.
‚Ä¢
We can prove Corollary 3.99 directly, although it is rather tedious, but the connection
with composition of linear transformations is the real reason why matrix multiplication is
associative.

176
Commutative Rings I
Ch. 3
Corollary 3.100.
Let T : V ‚ÜíW be a linear transformation of vector spaces V over a
Ô¨Åeld k, and let X and Y be bases of V and W, respectively. If T is nonsingular, then the
matrix of T ‚àí1 is the inverse of the matrix of T :
X[T ‚àí1]Y = (Y [T ]X)‚àí1.
Proof.
I = Y [1W]Y = Y [T ]X X[T ‚àí1]Y and I = X[1V ]X = X[T ‚àí1]Y Y [T ]X.
‚Ä¢
The next corollary determines all the matrices arising from the same linear transforma-
tion.
Corollary 3.101.
Let T : V ‚ÜíV be a linear transformation on a vector space V over a
Ô¨Åeld k. If X and Y are bases of V , then there is a nonsingular matrix P with entries in k
so that
Y [T ]Y = P

X[T ]X

P‚àí1.
Conversely, if B = P AP‚àí1, where B, A, and P are n √ó n matrices with entries in k and
P is nonsingular, then there is a linear transformation T : kn ‚Üíkn and bases X and Y of
kn such that B = Y [T ]Y and A = X[T ]X.
Proof.
The Ô¨Årst statement follows from Proposition 3.98 and associativity:
Y [T ]Y = Y [1V T 1V ]Y = (Y [1V ]X)(X[T ]X)(X[1V ]Y ).
Set P = Y [1V ]X, and note that Corollary 3.100 gives P‚àí1 = X[1V ]Y .
For the converse, let E = e1, . . . , en be the standard basis of kn, and deÔ¨Åne T : kn ‚Üíkn
by T (e j) = Ae j (remember that vectors in kn are column vectors, so that Ae j is matrix
multiplication; indeed, Ae j is the jth column of A). It follows that A = E[T ]E. Now
deÔ¨Åne a basis Y = y1, . . . , yn by y j = P‚àí1e j; that is, the vectors in Y are the columns
of P‚àí1. Note that Y is a basis because P‚àí1 is nonsingular. It sufÔ¨Åces to prove that B =
Y [T ]Y ; that is, T (y j) = 
i bi j yi, where B = [bi j].
T (y j) = Ay j
= AP‚àí1e j
= P‚àí1Be j
= P‚àí1 
i
bi jei
=

i
bi j P‚àí1ei
=

i
bi j yi
‚Ä¢

Sec. 3.7
Linear Algebra
177
DeÔ¨Ånition.
Two n √ó n matrices B and A with entries in a Ô¨Åeld k are similar if there is a
nonsingular matrix P with entries in k with B = P AP‚àí1.
Corollary 3.101 says that two matrices arise from the same linear transformation on a
vector space V (from different choices of basis) if and only if they are similar. In Chapter
9, we will see how to determine whether two given matrices are similar.
Just as for group homomorphisms and ring homomorphisms, we can deÔ¨Åne the kernel
and image of linear transformations.
DeÔ¨Ånition.
If T : V ‚ÜíW is a linear transformation, then the kernel (or the null space)
of T is
ker T = {v ‚ààV : T (v) = 0},
and the image of T is
im T = {w ‚ààW : w = T (v) for some v ‚ààV }.
As in Proposition 3.94, an m √ó n matrix A with entries in a Ô¨Åeld k determines a linear
transformation kn ‚Üíkm, namely, y ‚ÜíAy, where y is an n √ó 1 column vector. The
kernel of this linear transformation is usually called the solution space of A [see Exam-
ple 3.70(iv)].
The proof of the next proposition is routine.
Proposition 3.102.
Let T : V ‚ÜíW be a linear transformation.
(i) ker T is a subspace of V and im T is a subspace of W.
(ii) T is injective if and only if ker T = {0}.
We can now interpret the fact that a homogeneous system over a Ô¨Åeld k with r equations
in n unknowns has a nontrivial solution if r < n. If A is the r √ó n coefÔ¨Åcient matrix of
the system, then œï : x ‚ÜíAx is a linear transformation œï : kn ‚Üíkr. If there is only the
trivial solution, then ker œï = {0}, so that kn is isomorphic to a subspace of kr, contradicting
Corollary 3.90(i).
Lemma 3.103.
Let T : V ‚ÜíW be a linear transformation.
(i) If T is nonsingular, then for every basis X = v1, v2, . . . , vn of V , we have T (X) =
T (v1), T (v2), . . . , T (vn) a basis of W.
(ii) Conversely, if there exists some basis X = v1, v2, . . . , vn of V for which T (X) =
T (v1), T (v2), . . . , T (vn) is a basis of W, then T is nonsingular.
Proof.
(i) If  ciT (vi) = 0, then T ( civi) = 0, and so  civi ‚ààker T = {0}. Hence
each ci = 0, because X is linearly independent. If w ‚ààW, then the surjectivity of T
provides v ‚ààV with w = T (v). But v =  aivi, and so w = T (v) = T ( aivi) =
 aiT (vi). Therefore, T (X) is a basis of W.

178
Commutative Rings I
Ch. 3
(ii) Let w ‚ààW. Since T (v1), . . . , T (vn) is a basis of W, we have w =  ciT (vi) =
T ( civi), and so T is surjective. If  civi ‚ààker T , then  ciT (vi) = 0, and so linear
independence gives all ci = 0; hence,  civi = 0 and ker T = {0}. Therefore, T is
nonsingular.
‚Ä¢
Theorem 3.104.
If V is an n-dimensional vector space over a Ô¨Åeld k, then V is isomor-
phic to kn.
Proof.
Choose a basis v1, . . . , vn of V . If e1, . . . , en is the standard basis of kn, then
Theorem 3.92 says that there is a linear transformation T : V ‚Üíkn with T (vi) = ei for
all i; by Lemma 3.103, T is nonsingular.
‚Ä¢
Theorem 3.104 does more than say that every Ô¨Ånite-dimensional vector space is es-
sentially the familiar vector space of all n-tuples. It says that a choice of basis in V is
tantamount to a choice of coordinate set for each vector in V . We want the freedom to
change coordinates because the usual coordinates may not be the most convenient ones for
a given problem, as the reader has probably seen (in a calculus course) when rotating axes
to simplify the equation of a conic section.
Corollary 3.105.
Two Ô¨Ånite-dimensional vector spaces V and W over a Ô¨Åeld k are iso-
morphic if and only if dim(V ) = dim(W).
Remark.
In Theorem 6.51, we will see that this corollary remains true for inÔ¨Ånite-
dimensional vector spaces.
‚óÄ
Proof.
Assume that there is a nonsingular T : V ‚ÜíW. If X = v1, . . . , vn is a basis of
V , then Lemma 3.103 says that T (v1), . . . , T (vn) is a basis of W. Therefore, dim(W) =
|X| = dim(V ).
If n = dim(V ) = dim(W), then there are isomorphisms T : V ‚Üíkn and S : W ‚Üíkn,
by Theorem 3.104. It follows that the composite S‚àí1T : V ‚ÜíW is nonsingular.
‚Ä¢
Proposition 3.106.
Let V be a Ô¨Ånite-dimensional vector space with dim(V ) = n, and let
T : V ‚ÜíV be a linear transformation. The following statements are equivalent:
(i) T is an isomorphism;
(ii) T is surjective;
(iii) T is injective.
Proof.
(i) ‚áí(ii) This implication is obvious.
(ii) ‚áí(iii) Let v1, . . . , vn be a basis of V . Since T is surjective, there are vectors u1, . . . , un
with T ui = vi for all i. We claim that u1, . . . , un is linearly independent. If there are
scalars c1, . . . , cn, not all zero, with  ciui = 0, then we obtain a dependency relation

Sec. 3.7
Linear Algebra
179
0 =  ciT (ui) =  civi, a contradiction. By Corollary 3.89(ii), u1, . . . , un is a basis
of V . To show that T is injective, it sufÔ¨Åces to show that ker T = {0}. Suppose that
T (v) = 0. Now v =  ciui, and so 0 = T  ciui =  civi; hence, linear independence
of v1, . . . , vn gives all ci = 0, and so v = 0. Therefore, T is injective.
(iii) ‚áí(i) Let v1, . . . , vn be a basis of V . If c1, . . . , cn are scalars, not all 0, then  civi Ã∏=
0, for a basis is linearly independent. Since T is injective, it follows that  ciT vi Ã∏= 0,
and so T v1, . . . , T vn is linearly independent. Therefore, Lemma 3.103(ii) shows that T is
an isomorphism.
‚Ä¢
Recall that an n √ó n matrix A with entries in a Ô¨Åeld k is nonsingular if there is a matrix
B with entries in k (its inverse), with AB = I = B A. The next corollary shows that
"one-sided inverses" are enough.
Corollary 3.107.
If A and B are n √ó n matrices with AB = I, then B A = I. Therefore,
A is nonsingular with inverse B.
Proof.
There are linear transformations T, S : kn ‚Üíkn with [T ] = A and [S] = B, and
AB = I gives
[T S] = [T ][S] = [1kn].
Since T ‚Üí[T ] is a bijection, by Proposition 3.97, it follows that T S = 1kn. By Propo-
sition 1.47, T is a surjection and S is an injection.
But Proposition 3.106 says that
both T and S are isomorphisms, so that S = T ‚àí1 and T S = 1kn = ST . Therefore,
I = [ST ] = [S][T ] = B A, as desired.
‚Ä¢
DeÔ¨Ånition.
The set of all nonsingular n √ó n matrices with entries in k is denoted by
GL(n, k).
Now that we have proven associativity, it is easy to prove that GL(n, k) is a group under
matrix multiplication.
A choice of basis gives an isomorphism between the general linear group and the group
of nonsingular matrices.
Proposition 3.108.
Let V be an n-dimensional vector space over a Ô¨Åeld k, and let X =
v1, . . . , vn be a basis of V . Then ¬µ: GL(V ) ‚ÜíGL(n, k), deÔ¨Åned by T ‚Üí[T ] = X[T ]X,
is an isomorphism.
Proof.
By Proposition 3.97, the function ¬µ‚Ä≤ : T ‚Üí[T ] = X[T ]X is a bijection
Homk(V, V ) ‚ÜíMatn(k),
where Homk(V, V ) denotes the set of all linear transformations on V and Matn(k) denotes
the set of all n √ó n matrices with entries in k. Moreover, Proposition 3.98 says that [T S] =
[T ][S] for all T, S ‚ààHomk(V, V ).
If T ‚ààGL(V ), then [T ] is a nonsingular matrix, by Corollary 3.100; that is, if ¬µ is the
restriction of ¬µ‚Ä≤, then ¬µ: GL(V ) ‚ÜíGL(n, k) is an injective homomorphism.

180
Commutative Rings I
Ch. 3
It remains to prove that ¬µ is surjective. If A ‚ààGL(n, k), then A = [T ] for some
T : V ‚ÜíV . It sufÔ¨Åces to show that T is an isomorphism; that is, T ‚ààGL(V ). Since
[T ] is a nonsingular matrix, there is a matrix B with [T ]B = I. Now B = [S] for some
S : V ‚ÜíV , and
[T S] = [T ][S] = I = [1V ].
Therefore, T S = 1V , since ¬µ is a bijection, and so T ‚ààGL(V ), by Corollary 3.107.
‚Ä¢
The center of the general linear group is easily identiÔ¨Åed; we now generalize Exer-
cise 2.56 on page 81.
DeÔ¨Ånition.
A linear transformation T : V ‚ÜíV is a scalar transformation if there is
c ‚ààk with T (v) = cv for all v ‚ààV ; that is, T = c1V . A scalar matrix is a matrix of the
form cI, where c ‚ààk and I is the identity matrix.
A scalar transformation T = c1V is nonsingular if and only if c Ã∏= 0 (its inverse is
c‚àí11V ).
Corollary 3.109.
(i) The center of the group GL(V ) consists of all the nonsingular scalar transforma-
tions.
(ii) The center of the group GL(n, k) consists of all the nonsingular scalar matrices.
Proof.
(i) If T ‚ààGL(V ) is not scalar, then Example 3.96(ii) shows that there exists v ‚ààV
with v, T (v) linearly independent. By Proposition 3.87, there is a basis v, T (v), u3,. . ., un
of V . It is easy to see that v, v + T (v), u3, . . . , un is also a basis of V , and so there is a
nonsingular linear transformation S with S(v) = v, S(T (v)) = v + T (v), and S(ui) = ui
for all i. Now S and T do not commute, for ST (v) = v + T (v) while T S(v) = T (v).
Therefore, T is not in the center of GL(V ).
(ii) If f : G ‚ÜíH is any group isomorphism between groups G and H, then f (Z(G)) =
Z(H). In particular, if T = c1V is a nonsingular scalar transformation, then [T ] is in the
center of GL(n, k). But it is easily checked that [T ] = cI is a scalar matrix.
‚Ä¢
EXERCISES
3.75 Let V and W be vector spaces over a Ô¨Åeld k, and let S, T : V ‚ÜíW be linear transformations.
(i) If V and W are Ô¨Ånite-dimensional, prove that
dim(Homk(V, W)) = dim(V ) dim(W).
(ii) The dual space V ‚àóof a vector space V over k is deÔ¨Åned by
V ‚àó= Homk(V, k).
If dim(V ) = n, prove that dim(V ‚àó) = n, and hence that V ‚àó‚àº= V .

Sec. 3.7
Linear Algebra
181
(iii) If X = v1, . . . , vn is a basis of V , deÔ¨Åne Œ¥1, . . . , Œ¥n ‚ààV ‚àóby
Œ¥i(v j) =

0
if j Ã∏= i
1
if j = i.
Prove that Œ¥1, . . . , Œ¥n is a basis of V ‚àó(it is called the dual basis arising from v1, . . . , vn).
3.76 If A =
a
b
c
d

, deÔ¨Åne det(A) = ad ‚àíbc. If V is a vector space with basis X = v1, v2, deÔ¨Åne
T : V ‚ÜíV by T (v1) = av1 + bv2 and T (v2) = cv1 + dv2. Prove that T is a nonsingular
linear transformation if and only if det(X[T ]X) Ã∏= 0.
Hint.
You may assume the following (easily proved) fact of linear algebra: Given a system
of linear equations with coefÔ¨Åcients in a Ô¨Åeld,
ax + by = p
cx + dy = q,
then there exists a unique solution if and only if ad ‚àíbc Ã∏= 0.
3.77 Let U be a subspace of a vector space V .
(i) Prove that the natural map œÄ : V ‚ÜíV/U, given by v ‚Üív + U, is a linear transfor-
mation with kernel U. (Quotient spaces were deÔ¨Åned in Exercise 3.71 on page 170.)
(ii) State and prove the Ô¨Årst isomorphism theorem for vector spaces.
Hint. Here is the statement. If f : V ‚ÜíW is a linear transformation with ker f = U,
then U is a subspace of V and there is an isomorphism œï : V/U ‚àº= im f , namely,
œï(v + U) = f (v).
3.78 Let V be a Ô¨Ånite-dimensional vector space over a Ô¨Åeld k, and let B denote the family of all the
bases of V . Prove that B is a transitive GL(V )-set.
Hint. Use Theorem 3.92.
3.79
(i) If U and W are subspaces of a vector space V such that U ‚à©W = {0} and U + W = V ,
prove that V ‚àº= U ‚äïW (see the deÔ¨Ånition of direct sum on page 171).
(ii) A subspace U of a vector space V is a direct summand if there is a subspace W of V
with U ‚à©W = {0} and U + W = V . If V is a Ô¨Ånite-dimensional vector space over a
Ô¨Åeld k, prove that every subspace U is a direct summand.
Hint. Take a basis X of U, extend it to a basis X‚Ä≤ of V , and deÔ¨Åne W =

X‚Ä≤ ‚àíX
 
.
3.80 If T : V ‚ÜíW is a linear transformation between vector spaces over a Ô¨Åeld k, deÔ¨Åne
rank(T ) = dim(im T ).
(i) Regard the columns of an m√ón matrix A as m-tuples, and deÔ¨Åne the column space of A
to be the subspace of km spanned by the columns; deÔ¨Åne rank(A) to be the dimension of
the column space. If T : kn ‚Üíkm is the linear transformation deÔ¨Åned by T (X) = AX,
where X is an n √ó 1 vector, prove that
rank(A) = rank(T ).
(ii) If A is an m √ó n matrix and B is an p √ó m matrix, prove that
rank(B A) ‚â§rank(A).
(iii) Prove that similar n √ó n matrices have the same rank.

182
Commutative Rings I
Ch. 3
3.8 QUOTIENT RINGS AND FINITE FIELDS
Let us return to commutative rings. The fundamental theorem of algebra (Theorem 4.49)
states that every nonconstant polynomial in C[x] is a product of linear polynomials in
C[x], that is, C contains all the roots of every polynomial in C[x]. We are going to prove
a "local" analog of the fundamental theorem of algebra for polynomials over an arbitrary
Ô¨Åeld k: Given a polynomial f (x) ‚ààk[x], then there is some Ô¨Åeld K containing k that
also contains all the roots of f (x) (we call this a local analog for even though the larger
Ô¨Åeld K contains all the roots of the polynomial f (x), it may not contain roots of other
polynomials in k[x]). The main idea behind the construction of K involves quotient rings,
a construction akin to quotient groups.
Let I be an ideal in a commutative ring R. If we forget the multiplication, then I is a
subgroup of the additive group R; since R is an abelian group, the subgroup I is necessarily
normal, and so the quotient group R/I is deÔ¨Åned, as is the natural map œÄ : R ‚ÜíR/I
given by œÄ(a) = a + I. Recall Lemma 2.40(i), which we now write in additive notation:
a + I = b + I in R/I if and only if a ‚àíb ‚ààI.
Theorem 3.110.
If I is an ideal in a commutative ring R, then the additive abelian group
R/I can be made into a commutative ring in such a way that the natural map œÄ : R ‚ÜíR/I
is a surjective ring homomorphism.
Sketch of Proof.
DeÔ¨Åne multiplication on the additive abelian group R/I by
(a + I)(b + I) = ab + I.
To see that this is a well-deÔ¨Åned function R/I √ó R/I ‚ÜíR/I, assume that a + I = a‚Ä≤ + I
and b+ I = b‚Ä≤ + I, that is, a‚àía‚Ä≤ ‚ààI and b‚àíb‚Ä≤ ‚ààI. We must show that (a‚Ä≤ + I)(b‚Ä≤ + I) =
a‚Ä≤b‚Ä≤ + I = ab + I, that is, ab ‚àía‚Ä≤b‚Ä≤ ‚ààI. But
ab ‚àía‚Ä≤b‚Ä≤ = ab ‚àía‚Ä≤b + a‚Ä≤b ‚àía‚Ä≤b‚Ä≤
= (a ‚àía‚Ä≤)b + a‚Ä≤(b ‚àíb‚Ä≤) ‚ààI,
as desired.
To verify that R/I is a commutative ring, it now sufÔ¨Åces to show associativity and com-
mutativity of multiplication, distributivity, and that one is 1 + I. Proofs of these properties
are routine, for they are inherited from the corresponding property in R. For example,
multiplication in R/I is commutative because
(a + I)(b + I) = ab + I = ba + I = (b + I)(a + I).
Rewriting the equation (a + I)(b + I) = ab + I using the deÔ¨Ånition of œÄ, namely,
a + I = œÄ(a), gives œÄ(a)œÄ(b) = œÄ(ab). Since œÄ(1) = 1 + I, it follows that œÄ is a
ring homomorphism. Finally, œÄ is surjective because a + I = œÄ(a).
‚Ä¢
DeÔ¨Ånition.
The commutative ring R/I constructed in Theorem 3.110 is called the
quotient ring14 of R modulo I (brieÔ¨Çy, R mod I).
14Presumably, quotient rings are so called in analogy with quotient groups.

Sec. 3.8
Quotient Rings and Finite Fields
183
We saw in Example 2.68 that the additive abelian group Z/(m) is identical to Im. They
have the same elements: the coset a+(m) and the congruence class [a] are the same subset
of Z; they have the same addition:
a + (m) + b + (m) = a + b + (m) = [a + b] = [a] + [b].
We can now see that the quotient ring Z/(m) coincides with the commutative ring Im, for
the two multiplications coincide as well:
(a + (m))(b + (m)) = ab + (m) = [ab] = [a][b].
We can now prove a converse to Proposition 3.50.
Corollary 3.111.
If I is an ideal in a commutative ring R, then there are a commutative
ring A and a ring homomorphism œÄ : R ‚ÜíA with I = ker œÄ.
Proof.
If we forget the multiplication, then the natural map œÄ : R ‚ÜíR/I is a homomor-
phism between additive groups and, by Corollary 2.69,
I = ker œÄ = {r ‚ààR : œÄ(a) = 0 + I = I}.
Now remember the multiplication: (a + I)(b + I) = ab + I; that is, œÄ(a)œÄ(b) = œÄ(ab).
Therefore, œÄ is a ring homomorphism, and ker œÄ is equal to I whether the function œÄ is
regarded as a ring homomorphism or as a homomorphism of additive groups.
‚Ä¢
Theorem 3.112 (First Isomorphism Theorem).
If f : R ‚ÜíA is a homomorphism of
rings, then ker f is an ideal in R, im f is a subring of A, and
R/ ker f ‚àº= im f.
Proof.
Let I = ker f . We have already seen, in Proposition 3.50, that I is an ideal in R
and that im f is a subring of A.
If we forget the multiplication in the rings, then the proof of Theorem 2.70 shows that
the function œï : R/I ‚ÜíA, given by œï(r + I) = f (r), is an isomorphism of additive
groups. Since œï(1+I) = f (1) = 1, it now sufÔ¨Åces to prove that œï preserves multiplication.
But œï

(r + I)(s + I)

= œï(rs + I) = f (rs) = f (r) f (s) = œï(r + I)œï(s + I). Therefore,
œï is a ring isomorphism.
‚Ä¢
For rings as for groups, the Ô¨Årst isomorphism theorem creates an isomorphism from a
homomorphism once we know its kernel and image. It also says that there is no signif-
icant difference between a quotient ring and the image of a homomorphism. There are
analogs for commutative rings of the second and third isomorphism theorems for groups
(see Exercise 3.82 on page 196 for the third isomorphism theorem; the second isomor-
phism theorem is better stated in the context of modules; see Theorem 7.9), but they are
less useful for rings than are their group analogs. However, there is a useful analog of the
correspondence theorem, which we will prove later (see Proposition 6.1).

184
Commutative Rings I
Ch. 3
DeÔ¨Ånition.
If k is a Ô¨Åeld, the intersection of all the subÔ¨Åelds of k is called the prime Ô¨Åeld
of k.
Every subÔ¨Åeld of C contains Q, and so the prime Ô¨Åeld of C and of R is Q. The prime
Ô¨Åeld of a Ô¨Ånite Ô¨Åeld is just the integers mod p, as we show next.
Notation.
From now on, we will denote Ip by Fp when we are regarding it as a Ô¨Åeld.
Borrowing terminology from group theory, call the intersection of all the subÔ¨Åelds of
a Ô¨Åeld containing a subset X the subÔ¨Åeld generated by X; it is the smallest subÔ¨Åeld con-
taining X in the sense that if F is any subÔ¨Åeld containing X, then F contains the subÔ¨Åeld
generated by X. The prime Ô¨Åeld is the subÔ¨Åeld generated by 1, and the prime Ô¨Åeld of Fp(x)
is Fp.
Proposition 3.113.
If k is a Ô¨Åeld, then its prime Ô¨Åeld is isomorphic to Q or to Fp for some
prime p.
Proof.
Consider the ring homomorphism œá : Z ‚Üík, deÔ¨Åned by œá(n) = nŒµ, where we
denote the one in k by Œµ. Since every ideal in Z is principal, there is an integer m with
ker œá = (m). If m = 0, then œá is an injection, and so there is an isomorphic copy of Z that
is a subring of k. By Exercise 3.47(ii) on page 150, there is a Ô¨Åeld Q ‚àº= Frac(Z) = Q with
im œá ‚äÜQ ‚äÜk. Now Q is the prime Ô¨Åeld of k, for every subÔ¨Åeld of k contains 1, hence
contains im œá, and hence it contains Q, for Q ‚àº= Q has no proper subÔ¨Åelds. If m Ã∏= 0,
the Ô¨Årst isomorphism theorem gives Im = Z/(m) ‚àº= im œá ‚äÜk. Since k is a Ô¨Åeld, im œá
is a domain, and so Proposition 3.6 gives m prime. If we now write p instead of m, then
im œá = {0, Œµ, 2Œµ, . . . , (p ‚àí1)Œµ} is a subÔ¨Åeld of k isomorphic to Fp. Clearly, im œá is the
prime Ô¨Åeld of k, for every subÔ¨Åeld contains Œµ, hence contains im œá.
‚Ä¢
This last result is the Ô¨Årst step in classifying different types of Ô¨Åelds.
DeÔ¨Ånition.
A Ô¨Åeld k has characteristic 0 if its prime Ô¨Åeld is isomorphic to Q; a Ô¨Åeld k
has characteristic p if its prime Ô¨Åeld is isomorphic to Fp for some prime p.
The Ô¨Åelds Q, R, C have characteristic 0, as does any subÔ¨Åeld of them; every Ô¨Ånite Ô¨Åeld
has characteristic p for some prime p, as does Fp(x), the ring of all rational functions
over Fp.
Proposition 3.114.
If k is a Ô¨Åeld of characteristic p > 0, then pa = 0 for all a ‚ààk.
Proof.
Since k has characteristic p, we have p ¬∑ 1 = 0, where 1 is the one in k. The result
now follows from Proposition 3.2(v).
‚Ä¢
Proposition 3.115.
If k is a Ô¨Ånite Ô¨Åeld, then |k| = pn for some prime p and some n ‚â•1.
Proof.
The prime Ô¨Åeld P of k cannot be the inÔ¨Ånite Ô¨Åeld Q, and so P ‚àº= Fp for some
prime p. Now k is a vector space over P, and so it is a vector space over Fp. Clearly, k is
Ô¨Ånite-dimensional, and if dimFp(k) = n, then |k| = pn.
‚Ä¢

Sec. 3.8
Quotient Rings and Finite Fields
185
Remark.
Here is a proof of the last proposition using group theory. Assume that k is a
Ô¨Ånite Ô¨Åeld whose order |k| is divisible by distinct primes p and q. By Proposition 2.78,
Cauchy's theorem for abelian groups, there are elements a and b in k having orders p and
q, respectively. If Œµ denotes one in k, then the elements pŒµ (the sum of Œµ with itself p
times) and qŒµ satisfy (pŒµ)a = 0 and (qŒµ)b = 0. Since k is a Ô¨Åeld, it is a domain, and so
pŒµ = 0 = qŒµ.
But (p, q) = 1, so there are integers s and t with sp+tq = 1. Hence, Œµ = s(pŒµ)+t(qŒµ) =
0, and this is a contradiction. Therefore, |k| has only one prime divisor, say, p, and so |k|
is a power of p.
‚óÄ
Proposition 3.116.
If k is a Ô¨Åeld and I = (p(x)), where p(x) is a nonzero polynomial in
k[x], then the following are equivalent: p(x) is irreducible; k[x]/I is a Ô¨Åeld; k[x]/I is a
domain.
Proof.
Assume that p(x) is irreducible. Note that I = (p(x)) is a proper ideal, so that the
one in k[x]/I, namely, 1 + I, is not zero. If f (x) + I ‚ààk[x]/I is nonzero, then f (x) /‚ààI,
that is, f (x) is not a multiple of p(x) or, to say it another way, p ‚à§f . By Lemma 3.36, p
and f are relatively prime, and so there are polynomials s and t with s f + tp = 1. Thus,
s f ‚àí1 ‚ààI, and so 1 + I = s f + I = (s + I)( f + I). Therefore, every nonzero element
of k[x]/I has an inverse, and so k[x]/I is a Ô¨Åeld.
Of course, every Ô¨Åeld is a domain.
If k[x]/I is a domain. If p(x) is not an irreducible polynomial in k[x], there is a
factorization p(x) = g(x)h(x) in k[x] with deg(g) < deg(p) and deg(h) < deg(p). It
follows that neither g(x) + I nor h(x) + I is zero in k[x]/I. After all, the zero in k[x]/I
is 0 + I = I, and g(x) + I = I if and only if g(x) ‚ààI = (p(x)); but if this were so, then
p(x) | g(x), giving the contradiction deg(p) ‚â§deg(g). The product
(g(x) + I)(h(x) + I) = p(x) + I = I
is zero in the quotient ring, and this contradicts k[x]/I being a domain. Therefore, p(x)
must be an irreducible polynomial.
‚Ä¢
The structure of R/I can be rather complicated, but for special choices of R and I,
the commutative ring R/I can be easily described. For example, when p(x) is an irre-
ducible polynomial, the following proposition gives a complete description of the Ô¨Åeld
k[x]/(p(x)).
Proposition 3.117.
Let k be a Ô¨Åeld, let p(x) ‚ààk[x] be a monic irreducible polynomial
of degree d, let K = k[x]/I, where I = (p(x)), and let Œ≤ = x + I ‚ààK.
(i) K is a Ô¨Åeld and k‚Ä≤ = {a + I : a ‚ààk} is a subÔ¨Åeld of K isomorphic to k. Therefore,
if k‚Ä≤ is identiÔ¨Åed with k, then k is a subÔ¨Åeld of K.
(ii) Œ≤ is a root of p(x) in K.

186
Commutative Rings I
Ch. 3
(iii) If g(x) ‚ààk[x] and Œ≤ is a root of g(x), then p(x) | g(x) in k[x].
(iv) p(x) is the unique monic irreducible polynomial in k[x] having Œ≤ as a root.
(v) The list 1, Œ≤, Œ≤2, . . . , Œ≤d‚àí1 is a basis of K as a vector space over k, and so
dimk(K) = d.
Proof.
(i) The quotient ring K = k[x]/I is a Ô¨Åeld, by Proposition 3.116, because p(x) is
irreducible. It is easy to see, using Corollary 3.53, that the restriction of the natural map,
œï = œÄ|k : k ‚ÜíK, deÔ¨Åned by œï(a) = a + I, is an isomorphism from k ‚Üík‚Ä≤.
(ii) Let p(x) = a0 + a1x + ¬∑ ¬∑ ¬∑ + ad‚àí1xd‚àí1 + xd, where ai ‚ààk for all i. In K = k[x]/I,
we have
p(Œ≤) = (a0 + I) + (a1 + I)Œ≤ + ¬∑ ¬∑ ¬∑ + (1 + I)Œ≤d
= (a0 + I) + (a1 + I)(x + I) + ¬∑ ¬∑ ¬∑ + (1 + I)(x + I)d
= (a0 + I) + (a1x + I) + ¬∑ ¬∑ ¬∑ + (1xd + I)
= a0 + a1x + ¬∑ ¬∑ ¬∑ + xd + I
= p(x) + I = I,
because p(x) ‚ààI = (p(x)). But I = 0 + I is the zero element of K = k[x]/I, and so Œ≤
is a root of p(x).
(iii) If p(x) ‚à§g(x) in k[x], then their gcd is 1, because p(x) is irreducible. Therefore, there
are s(x), t(x) ‚ààk[x] with 1 = s(x)p(x) + t(x)g(x). Since k[x] ‚äÜK[x], we may regard
this as an equation in K[x]. Evaluating at Œ≤ gives the contradiction 1 = 0.
(iv) Let h(x) ‚ààk[x] be a monic irreducible polynomial having Œ≤ as a root. By part (iii),
we have p(x) | h(x). Since h(x) is irreducible, we have h(x) = cp(x) for some constant
c; since h(x) and p(x) are monic, we have c = 1 and h(x) = p(x).
(v) Every element of K has the form f (x) + I, where f (x) ‚ààk[x]. By the division
algorithm, there are polynomials q(x),r(x) ‚ààk[x] with f (x) = q(x)p(x) + r(x) and
either r(x) = 0 or deg(r) < d = deg(p). Since f ‚àír = qp ‚ààI, it follows that
f (x) + I = r(x) + I. If r(x) = b0 + b1x + ¬∑ ¬∑ ¬∑ + bd‚àí1xd‚àí1, where bi ‚ààk for all i, then
we see, as in the proof of part (ii), that r(x) + I = b0 + b1Œ≤ + ¬∑ ¬∑ ¬∑ + bd‚àí1Œ≤d‚àí1. Therefore,
1, Œ≤, Œ≤2, . . . , Œ≤d‚àí1 spans K.
To prove uniqueness, suppose that
b0 + b1Œ≤ + ¬∑ ¬∑ ¬∑ + bd‚àí1Œ≤n‚àí1 = c0 + c1Œ≤ + ¬∑ ¬∑ ¬∑ + cd‚àí1Œ≤d‚àí1.
DeÔ¨Åne g(x) ‚ààk[x] by g(x) = d‚àí1
i=0 (bi ‚àíci)xi; if g(x) = 0, we are done. If g(x) Ã∏= 0,
then deg(g) is deÔ¨Åned, and deg(g) < d = deg(p). On the other hand, Œ≤ is a root of g(x),
and so part (iii) gives p(x) | g(x); hence, deg(p) ‚â§deg(g), and this is a contradiction.
It follows that 1, Œ≤, Œ≤2, . . . , Œ≤d‚àí1 is a basis of K as a vector space over k, and this gives
dimk(K) = d.
‚Ä¢

Sec. 3.8
Quotient Rings and Finite Fields
187
DeÔ¨Ånition.
If K is a Ô¨Åeld containing k as a subÔ¨Åeld, then K is called a (Ô¨Åeld) extension
of k, and we write "K/k is a Ô¨Åeld extension."15
An extension Ô¨Åeld K of a Ô¨Åeld k is a Ô¨Ånite extension of k if K is a Ô¨Ånite-dimensional
vector space over k. The dimension of K, denoted by [K : k], is called the degree of K/k.
Proposition 3.117(v) shows why [K : k] is called the degree of the extension K/k.
Example 3.118.
The polynomial x2+1 ‚ààR[x] is irreducible, and so K = R[x]/(x2+1) is a Ô¨Åeld extension
K/R of degree 2. If Œ≤ is a root of x2 + 1, then Œ≤2 = ‚àí1; moreover, every element of K
has a unique expression of the form a + bŒ≤, where a, b ‚ààR. Clearly, this is another
construction of C (which we have been viewing as the points in the plane equipped with a
certain addition and multiplication).
Here is a natural way to construct an isomorphism K ‚ÜíC. Consider the evaluation
map œï : R[x] ‚ÜíC given by œï : f (x) ‚Üíf (i). First, œï is surjective, for a + ib =
œï(a + bx) ‚ààim œï. Second, ker œï = { f (x) ‚ààR[x] : f (i) = 0}, the set of all polynomials
in R[x] having i as a root. We know that x2 + 1 ‚ààker œï, so that (x2 + 1) ‚äÜker œï. For the
reverse inclusion, take g(x) ‚ààker œï. Now i is a root of g(x), and so gcd (g, x2 + 1) Ã∏= 1
in C[x]; therefore, gcd (g, x2 + 1) Ã∏= 1 in R[x]. Irreducibility of x2 + 1 in R[x] gives
x2 + 1 | g(x), and so g(x) ‚àà(x2 + 1), Therefore, ker œï = (x2 + 1). The Ô¨Årst isomorphism
theorem now gives R[x]/(x2 + 1) ‚àº= C.
‚óÄ
The easiest way to multiply in C is to Ô¨Årst treat i as a variable and then to impose the
condition i2 = ‚àí1. To compute (a + bi)(c + di), Ô¨Årst write ac + (ad + bc)i + bdi2, and
then observe that i2 = ‚àí1. More generally, if Œ≤ is a root of an irreducible p(x) ‚ààk[x],
then the proper way to multiply
(b0 + b1Œ≤ + ¬∑ ¬∑ ¬∑ + bn‚àí1Œ≤n‚àí1)(c0 + c1Œ≤ + ¬∑ ¬∑ ¬∑ + cn‚àí1Œ≤n‚àí1)
in the quotient ring k[x]/(p(x)) is to regard the factors as polynomials in Œ≤, multiply them,
and then impose the condition that p(Œ≤) = 0.
A Ô¨Årst step in classifying Ô¨Åelds involves their characteristic; that is, describing prime
Ô¨Åelds. A next step considers whether the elements are algebraic over the prime Ô¨Åeld.
DeÔ¨Ånition.
Let K/k be a Ô¨Åeld extension. An element Œ± ‚ààK is algebraic over k if there is
some nonzero polynomial f (x) ‚ààk[x] having Œ± as a root; otherwise, Œ± is transcendental
over k. An extension K/k is algebraic if every Œ± ‚ààK is algebraic over k.
When a real number is called transcendental, it usually means that it is transcendental
over Q.
Proposition 3.119.
If K/k is a Ô¨Ånite Ô¨Åeld extension, then K/k is an algebraic extension.
15This notation should not be confused with the notation for a quotient ring, for a Ô¨Åeld K has no interesting
ideals; in particular, if k ‚ääK, then k is not an ideal in K.

188
Commutative Rings I
Ch. 3
Proof.
By deÔ¨Ånition, K/k Ô¨Ånite means that [K : k] = n < ‚àû; that is, K has dimension
n as a vector space over k. By Corollary 3.88, the list of n + 1 vectors 1, Œ±, Œ±2, . . . , Œ±n
is dependent. Thus, there are c0, c1, . . . , cn ‚ààk, not all 0, with  ciŒ±i = 0. Thus, the
polynomial f (x) =  ci xi is not the zero polynomial, and Œ± is a root of f (x). Therefore,
Œ± is algebraic over k.
‚Ä¢
The converse of this last proposition is not true. We shall see, in Example 6.55, that the
set A of all complex numbers algebraic over Q is an algebraic extension of Q that is not a
Ô¨Ånite extension.
DeÔ¨Ånition.
If K/k is an extension and Œ± ‚ààK, then k(Œ±) is the intersection of all those
subÔ¨Åelds of K that contain k and Œ±; we call k(Œ±) the subÔ¨Åeld of K obtained by adjoining
Œ± to k.
More generally, if A is a (possibly inÔ¨Ånite) subset of K, deÔ¨Åne k(A) to be the intersec-
tion of all the subÔ¨Åelds of K that contain k ‚à™A; we call k(A) the subÔ¨Åeld of K obtained by
adjoining A to k. In particular, if A = {z1, . . . , zn} is a Ô¨Ånite subset, then we may denote
k(A) by k(z1, . . . , zn).
It is clear that k(A) is the smallest subÔ¨Åeld of K containing k and A; that is, if B is any
subÔ¨Åeld of K containing k and A, then k(A) ‚äÜB.
We now show that the Ô¨Åeld k[x]/(p(x)), where p(x) ‚ààk[x] is irreducible, is intimately
related to adjunction.
Theorem 3.120.
(i) If K/k is an extension and Œ± ‚ààK is algebraic over k, then there is a unique monic
irreducible polynomial p(x) ‚ààk[x] having Œ± as a root. Moreover, if I = (p(x)),
then k[x]/I ‚àº= k(Œ±); indeed, there exists an isomorphism
œï : k[x]/I ‚Üík(Œ±)
with œï(x + I) = Œ± and œï(c + I) = c for all c ‚ààk.
(ii) If Œ±‚Ä≤ ‚ààK is another root of p(x), then there is an isomorphism
Œ∏ : k(Œ±) ‚Üík(Œ±‚Ä≤)
with Œ∏(Œ±) = Œ±‚Ä≤ and Œ∏(c) = c for all c ‚ààk.
Proof.
(i) Consider evaluation, the ring homomorphism œï : k[x] ‚ÜíK deÔ¨Åned by
œï : f (x) ‚Üíf (Œ±).
Now im œï is the subring of K consisting of all polynomials in Œ±; that is, all elements of
the form f (Œ±) with f (x) ‚ààk[x]. Now ker œï is the ideal in k[x] consisting of all those
f (x) ‚ààk[x] having Œ± as a root. Since every ideal in k[x] is a principal ideal, we have
ker œï = (p(x)) for some monic polynomial p(x) ‚ààk[x]. But k[x]/(p(x)) ‚àº= im œï, which

Sec. 3.8
Quotient Rings and Finite Fields
189
is a domain, and so p(x) is irreducible, by Proposition 3.116. This same proposition says
that k[x]/(p(x)) is a Ô¨Åeld, and so the Ô¨Årst isomorphism theorem gives k[x]/(p(x)) ‚àº= im œï;
that is, im œï is a subÔ¨Åeld of K containing k and Œ±. Since every subÔ¨Åeld of K that contains
k and Œ± must contain im œï, we have im œï = k(Œ±). We have proved everything in the
statement except the uniqueness of p(x); but this now follows from Proposition 3.117(iv).
(ii) As in part (i), there are isomorphisms œï : k[x]/I ‚Üík(Œ±) and œà : k[x]/I ‚Üík(Œ±‚Ä≤) with
œï(c+ I) = c and œà(c) = c+ I for all c ‚ààk; moreover, œï : x + I ‚ÜíŒ± and œà : x + I ‚ÜíŒ±‚Ä≤.
The composite Œ∏ = œàœï‚àí1 is the desired isomorphism.
‚Ä¢
DeÔ¨Ånition.
If K/k is a Ô¨Åeld extension and Œ± ‚ààK is algebraic over k, then the unique
monic irreducible polynomial p(x) ‚ààk[x] having Œ± as a root is called the minimal poly-
nomial of Œ± over k, and it is denoted by
irr(Œ±, k) = p(x).
The minimal polynomial irr(Œ±, k) does depend on k. For example, irr(i, R) = x2 + 1,
while irr(i, C) = x ‚àíi.
The following formula is quite useful, especially when proving a theorem by induction
on degrees.
Theorem 3.121.
Let k ‚äÜE ‚äÜK be Ô¨Åelds, with E a Ô¨Ånite extension of k and K a Ô¨Ånite
extension of E. Then K is a Ô¨Ånite extension of k, and
[K : k] = [K : E][E : k].
Proof.
If A = a1, . . . , an is a basis of E over k and if B = b1, . . . , bm is a basis of K
over E, then it sufÔ¨Åces to prove that a list X of all aib j is a basis of K over k.
To see that X spans K, take u ‚ààK. Since B is a basis of K over E, there are scalars
Œª j ‚ààE with u = 
j Œª jb j. Since A is a basis of E over k, there are scalars ¬µ ji ‚ààk with
Œª j = 
i ¬µ jiai. Therefore, u = 
i j ¬µ jiaib j, and X spans K over k.
To prove that X is linearly independent over k, assume that there are scalars ¬µ ji ‚ààk
with 
i j ¬µ jiaib j = 0. If we deÔ¨Åne Œª j = 
i ¬µ jiai, then Œª j ‚ààE and 
j Œª jb j = 0.
Since B is linearly independent over E, it follows that
0 = Œª j =

i
¬µ jiai
for all j. Since A is linearly independent over k, it follows that ¬µ ji = 0 for all j and i, as
desired.
‚Ä¢
There are several classical problems in euclidean geometry: trisecting an angle; dupli-
cating the cube (given a cube with side length 1, construct a cube whose volume is 2);
squaring the circle (given a circle of radius 1, construct a square whose area is equal to the
area of the circle). In short, the problems ask whether geometric constructions can be made

190
Commutative Rings I
Ch. 3
using only a straightedge (ruler) and compass according to certain rules. Theorem 3.121
has a beautiful application in proving the unsolvability of these classical problems. For a
discussion of these results, the reader may see my book, A First Course in Abstract Alge-
bra, pages 332-344.
Example 3.122.
Let f (x) = x4 ‚àí10x2 + 1 ‚ààQ[x]. If Œ≤ is a root of f (x), then the quadratic formula gives
Œ≤2 = 5 ¬± 2
‚àö
6. But the identity a + 2
‚àö
ab + b =
‚àöa +
‚àö
b
2 gives Œ≤ = ¬±(
‚àö
2 +
‚àö
3).
Similarly, 5 ‚àí2
‚àö
6 =
‚àö
2 ‚àí
‚àö
3
2, so that the roots of f (x) are
‚àö
2 +
‚àö
3,
‚àí
‚àö
2 ‚àí
‚àö
3,
‚àö
2 ‚àí
‚àö
3,
‚àí
‚àö
2 +
‚àö
3.
By Theorem 3.43, the only possible rational roots of f (x) are ¬±1, and so we have just
proved that these roots are irrational.
We claim that f (x) is irreducible in Q[x]. If g(x) is a quadratic factor of f (x) in Q[x],
then
g(x) =

x ‚àía
‚àö
2 ‚àíb
‚àö
3

x ‚àíc
‚àö
2 ‚àíd
‚àö
3

,
where a, b, c, d ‚àà{1, ‚àí1}. Multiplying,
g(x) = x2 ‚àí

(a + c)
‚àö
2 + (b + d)
‚àö
3

x + 2ac + 3bd + (ad + bc)
‚àö
6.
We check easily that (a + c)
‚àö
2 + (b + d)
‚àö
3 is rational if and only if a + c = 0 = b + d;
but these equations force ad + bc Ã∏= 0, and so the constant term of g(x) is not rational.
Therefore, g(x) /‚ààQ[x], and so f (x) is irreducible in Q[x]. If Œ≤ =
‚àö
2 +
‚àö
3, then
f (x) = irr(Œ≤, Q).
Consider the Ô¨Åeld E = Q(Œ≤) = Q
‚àö
2 +
‚àö
3

. There is a tower of Ô¨Åelds Q ‚äÜE ‚äÜF,
where F = Q(
‚àö
2,
‚àö
3), and so
[F : Q] = [F : E][E : Q],
by Theorem 3.121. Since E = Q(Œ≤) and Œ≤ is a root of an irreducible polynomial of degree
4, namely, f (x), we have [E : Q] = 4. On the other hand,
[F : Q] = [F : Q
‚àö
2

][Q
‚àö
2

: Q].
Now [Q
‚àö
2

: Q] = 2, because
‚àö
2 is a root of the irreducible quadratic x2 ‚àí2 in Q[x].
We claim that [F : Q
‚àö
2

] ‚â§2. The Ô¨Åeld F arises by adjoining
‚àö
3 to Q
‚àö
2

; either
‚àö
3 ‚ààQ
‚àö
2

, in which case the degree is 1, or x2 ‚àí3 is irreducible in Q
‚àö
2

[x], in
which case the degree is 2 (in fact, the degree is 2). It follows that [F : Q] ‚â§4, and so the
equation [F : Q] = [F : E][E : Q] gives [F : E] = 1; that is, F = E.
Let us note that F arises from Q by adjoining all the roots of f (x), and it also arises
from Q by adjoining all the roots of g(x) = (x2 ‚àí2)(x2 ‚àí3).
‚óÄ
We now prove two important results: The Ô¨Årst, due to L. Kronecker, says that if f (x) ‚àà
k[x], where k is any Ô¨Åeld, then there is some larger Ô¨Åeld E that contains k and all the roots
of f (x); the second, due to E. Galois, constructs Ô¨Ånite Ô¨Åelds other than Fp.

Sec. 3.8
Quotient Rings and Finite Fields
191
Theorem 3.123 (Kronecker).
If k is a Ô¨Åeld and f (x) ‚ààk[x], then there exists a Ô¨Åeld K
containing k as a subÔ¨Åeld and with f (x) a product of linear polynomials in K[x].
Proof.
The proof is by induction on deg( f ). If deg( f ) = 1, then f (x) is linear and we
can choose K = k. If deg( f ) > 1, write f (x) = p(x)g(x), where p(x) is irreducible.
Now Proposition 3.117(i) provides a Ô¨Åeld F containing k and a root z of p(x). Hence, in
F[x], we have p(x) = (x ‚àíz)h(x) and f (x) = (x ‚àíz)h(x)g(x). By induction, there
is a Ô¨Åeld K containing F (and hence k) so that h(x)g(x), and hence f (x), is a product of
linear factors in K[x].
‚Ä¢
For the familiar Ô¨Åelds Q, R, and C, Kronecker's theorem offers nothing new. The
fundamental theorem of algebra, Ô¨Årst proved by Gauss in 1799 (completing earlier attempts
of Euler and of Lagrange), says that every nonconstant f (x) ‚ààC[x] has a root in C; it
follows, by induction on the degree of f (x), that all the roots of f (x) lie in C; that is,
f (x) = a(x ‚àír1) . . . (x ‚àírn), where a ‚ààC and r j ‚ààC for all j. On the other hand,
if k = Fp or k = C(x) = Frac(C[x]), then the fundamental theorem does not apply;
but Kronecker's theorem does apply to tell us, for any given f (x), that there is always
some larger Ô¨Åeld E that contains all the roots of f (x). For example, there is some Ô¨Åeld
containing C(x) and ‚àöx. There is a general version of the fundamental theorem that we
give in Chapter 6: Every Ô¨Åeld k is a subÔ¨Åeld of an algebraically closed Ô¨Åeld K, that is, K
is a Ô¨Åeld containing k such that every f (x) ‚ààK[x] is a product of linear polynomials in
K[x]. In contrast, Kronecker's theorem gives roots of just one polynomial at a time.
The deÔ¨Ånition of k(A), the Ô¨Åeld obtained by adjoining a set A to k, assumes that A is
a subset of a Ô¨Åeld extension K of k. In light of Kronecker's theorem, we may now speak
of a Ô¨Åeld extension k(z1, . . . , zn) obtained by adjoining all the roots of some f (x) ‚ààk[x]
without having to wonder whether such an extension K/k exists.
DeÔ¨Ånition.
Let k be a subÔ¨Åeld of a Ô¨Åeld K, and let f (x) ‚ààk[x]. We say that f (x) splits
over K if
f (x) = a(x ‚àíz1) ¬∑ ¬∑ ¬∑ (x ‚àízn),
where z1, . . . , zn are in K and a ‚ààk is nonzero.
If f (x) ‚ààk[x] is a polynomial, then a Ô¨Åeld extension E/k is called a splitting Ô¨Åeld of
f (x) over k if f (x) splits over E, but f (x) does not split over any proper subÔ¨Åeld of E.
For example, consider f (x) = x2 + 1 ‚ààQ[x]. The roots of f (x) are ¬±i, and so f (x)
splits over C; that is, f (x) = (x ‚àíi)(x + i) is a product of linear polynomials in C[x].
However, C is not a splitting Ô¨Åeld over Q, for C is not the smallest Ô¨Åeld containing Q and
all the roots of f (x). The splitting Ô¨Åeld of f (x) ‚ààk[x] depends on k as well as on f (x):
Here, the splitting Ô¨Åeld over Q is Q(i); the splitting Ô¨Åeld over R is R(i) = C.
In Example 3.122, we proved that E = Q
‚àö
2 +
‚àö
3

is a splitting Ô¨Åeld of f (x) =
x4 ‚àí10x2 + 1, as well as a splitting Ô¨Åeld of g(x) = (x2 ‚àí2)(x2 ‚àí3).
The existence of splitting Ô¨Åelds is an easy consequence of Kronecker's theorem.
Corollary 3.124.
Let k be a Ô¨Åeld, and let f (x) ‚ààk[x]. Then a splitting Ô¨Åeld of f (x) over
k exists.

192
Commutative Rings I
Ch. 3
Proof.
By Kronecker's theorem, there is a Ô¨Åeld extension K/k such that f (x) splits in
K[x]; say, f (x) = a(x ‚àíŒ±1) ¬∑ ¬∑ ¬∑ (x ‚àíŒ±n). The subÔ¨Åeld E = k(Œ±1, . . . , Œ±n) of K is a
splitting Ô¨Åeld of f (x) over k.
‚Ä¢
Thus, a splitting Ô¨Åeld of f (x) ‚ààk[x] is the smallest subÔ¨Åeld E of K containing k and
all the roots of f (x). The reason we say "a" splitting Ô¨Åeld instead of "the" splitting Ô¨Åeld is
that the deÔ¨Ånition involves not only f (x) and k, but the larger Ô¨Åeld K as well. Analysis of
this technical point will enable us to prove Corollary 3.132: Any two Ô¨Ånite Ô¨Åelds with the
same number of elements are isomorphic.
Example 3.125.
Let k be a Ô¨Åeld and let E = k(y1, . . . , yn) be the rational function Ô¨Åeld in n variables
y1, . . . , yn over k; that is, E = Frac(k[y1, . . . , yn]), the fraction Ô¨Åeld of the ring of poly-
nomials in n variables. The general polynomial of degree n over k is deÔ¨Åned to be
f (x) =

i
(x ‚àíyi) ‚ààFrac(k[y1, . . . , yn])[x].
The coefÔ¨Åcients of f (x) = (x ‚àíy1)(x ‚àíy2) ¬∑ ¬∑ ¬∑ (x ‚àíyn), which we denote by ai, can be
given explicitly [see Eqs. (1) on page 198] in terms of the y's. Notice that E is a splitting
Ô¨Åeld of f (x) over the Ô¨Åeld K = k(a0, . . . , an‚àí1), for it arises from K by adjoining to it all
the roots of f (x), namely, all the y's.
‚óÄ
Here is another application of Kronecker's theorem.
Proposition 3.126.
Let p be a prime, and let k be a Ô¨Åeld. If f (x) = x p ‚àíc ‚ààk[x] and
Œ± is a pth root of c (in some splitting Ô¨Åeld), then either f (x) is irreducible in k[x] or c has
a pth root in k. In either case, if k contains the pth roots of unity, then k(Œ±) is a splitting
Ô¨Åeld of f (x).
Proof.
By Kronecker's theorem, there exists a Ô¨Åeld extension K/k that contains all the
roots of f (x); that is, K contains all the pth roots of c. If Œ± p = c, then every such root has
the form œâŒ±, where œâ is a pth root of unity; that is, œâ is a root of x p ‚àí1.
If f (x) is not irreducible in k[x], then there is a factorization f (x) = g(x)h(x) in k[x]
with g(x) a nonconstant polynomial with d = deg(g) < deg( f ) = p. Now the constant
term b of g(x) is, up to sign, the product of some of the roots of f (x):
¬±b = Œ±dœâ,
where œâ, which is a product of d pth roots of unity, is itself a pth root of unity. It follows
that
(¬±b)p = (Œ±dœâ)p = Œ±dp = cd.
But p being prime and d < p forces (d, p) = 1; hence, there are integers s and t with
1 = sd + tp. Therefore,
c = csd+tp = csdctp = (¬±b)psctp = [(¬±b)sct]p.

Sec. 3.8
Quotient Rings and Finite Fields
193
Therefore, c has a pth root in k.
If Œ± ‚ààK is a pth root of c, then f (x) = 
œâ(x ‚àíœâŒ±), where œâ ranges over the pth roots
of unity. Since we are now assuming that all œâ lie in k, it follows that k(Œ±) is a splitting
Ô¨Åeld of f (x).
‚Ä¢
It follows, for every prime p, that x p ‚àí2 is irreducible in Q[x].
We are now going to construct the Ô¨Ånite Ô¨Åelds. My guess is that Galois knew that C can
be constructed by adjoining a root of a polynomial, namely, x2 + 1, to R, and so it was
natural for him to adjoin a root of a polynomial to Fp. Note, however, that Kronecker's
theorem was not proved until a half century after Galois's death.
Theorem 3.127 (Galois).
If p is a prime and n is a positive integer, then there is a Ô¨Åeld
having exactly pn elements.
Proof.
Write q = pn, and consider the polynomial
g(x) = xq ‚àíx ‚ààFp[x].
By Kronecker's theorem, there is a Ô¨Åeld K containing Fp such that g(x) is a product of
linear factors in K[x]. DeÔ¨Åne
E = {Œ± ‚ààK : g(Œ±) = 0};
thus, E is the set of all the roots of g(x). Since the derivative g‚Ä≤(x) = qxq‚àí1 ‚àí1 =
pnxq‚àí1 ‚àí1 = ‚àí1 (see Exercise 3.23 on page 130), it follows that the gcd(g, g‚Ä≤) is 1. By
Exercise 3.37 on page 142, all the roots of g(x) are distinct; that is, E has exactly q = pn
elements.
We claim that E is a subÔ¨Åeld of K, and this will complete the proof. If a, b ‚ààE, then
aq = a and bq = b. Therefore, (ab)q = aqbq = ab, and ab ‚ààE. By Exercise 3.45 on
page 149(iii), (a ‚àíb)q = aq ‚àíbq = a ‚àíb, so that a ‚àíb ‚ààE. Finally, if a Ã∏= 0, then the
cancellation law applied to aq = a gives aq‚àí1 = 1, and so the inverse of a is aq‚àí2 (which
lies in E because E is closed under multiplication).
‚Ä¢
We will soon see that any two Ô¨Ånite Ô¨Åelds with the same number of elements are iso-
morphic.
Recall Theorem 3.30: The multiplicative group of a Ô¨Ånite Ô¨Åeld k is a cyclic group; a
generator Œ± of this group is called a primitive element; that is, every nonzero element of k
is a power of Œ±.
Notation.
Denote a Ô¨Ånite Ô¨Åeld having q = pn elements (where p is a prime) by
Fq.
Corollary 3.128.
For every prime p and every integer n ‚â•1, there exists an irreducible
polynomial g(x) ‚ààFp[x] of degree n. In fact, if Œ± is a primitive element of Fpn, then its
minimal polynomial g(x) = irr(Œ±, Fp) has degree n.

194
Commutative Rings I
Ch. 3
Remark.
An easy modiÔ¨Åcation of the proof replaces Fp by any Ô¨Ånite Ô¨Åeld.
‚óÄ
Proof.
Let E/Fp be a Ô¨Åeld extension with pn elements, and let Œ± ‚ààE be a primitive ele-
ment. Clearly, Fp(Œ±) = E, for it contains every power of Œ±, hence every nonzero element
of E. By Theorem 3.120(i), g(x) = irr(Œ±, Fp) ‚ààFp[x] is an irreducible polynomial hav-
ing Œ± as a root. If deg(g) = d, then Proposition 3.117(v) gives [Fp[x]/(g(x)) : Fp] = d;
but Fp[x]/(g(x)) ‚àº= Fp(Œ±) = E, by Theorem 3.120(i), so that [E : Fp] = n. Therefore,
n = d, and so g(x) is an irreducible polynomial of degree n.
‚Ä¢
This corollary can also be proved by counting. If m = pe1
1 ¬∑ ¬∑ ¬∑ pen
n , deÔ¨Åne the M¬®obius
function by
¬µ(m) =
Ô£±
Ô£¥Ô£≤
Ô£¥Ô£≥
1
if m = 1;
0
if any ei > 1;
(‚àí1)n if 1 = e1 = e2 = ¬∑ ¬∑ ¬∑ = en.
If Nn is the number of irreducible polynomials in Fp[x] of degree n, then
Nn = 1
n

d|n
¬µ(d)pn/d.
An elementary proof can be found in G. J. Simmons, "The Number of Irreducible Polyno-
mials of Degree n over GF(p)," American Mathematical Monthly 77 (1970), pages 743-
745.
Example 3.129.
(i) In Exercise 3.14 on page 125, we constructed a Ô¨Åeld k with four elements:
k =
'a
b
b
a + b

: a, b ‚ààI2
(
.
On the other hand, we may construct a Ô¨Åeld of order 4 as the quotient F = F2[x]/(q(x)),
where q(x) ‚ààF2[x] is the irreducible polynomial x2+x +1. By Proposition 3.117(v), F is
a Ô¨Åeld consisting of all a + bz, where z = x + (q(x)) is a root of q(x) and a, b ‚ààI2. Since
z2+z+1 = 0, we have z2 = ‚àíz‚àí1 = z+1; moreover, z3 = zz2 = z(z+1) = z2+z = 1.
It is now easy to see that there is a ring isomorphism œï : k ‚ÜíF with œï
a
b
b
a + b
	
=
a + bz.
(ii) According to the table in Example 3.35(ii) on page 137, there are three monic irre-
ducible quadratics in F3[x], namely,
p(x) = x2 + 1,
q(x) = x2 + x ‚àí1, and r(x) = x2 ‚àíx ‚àí1;
each gives rise to a Ô¨Åeld with 9 = 32 elements. Let us look at the Ô¨Årst two in more detail.
Proposition 3.117(v) says that E = F3[x]/(p(x)) is given by
E = {a + bŒ± : where Œ±2 + 1 = 0}.

Sec. 3.8
Quotient Rings and Finite Fields
195
Similarly, if F = F3[x]/(q(x)), then
F = {a + bŒ≤ : where Œ≤2 + Œ≤ ‚àí1 = 0}.
These two Ô¨Åelds are isomorphic, for the map œï : E ‚ÜíF (found by trial and error), deÔ¨Åned
by
œï(a + bŒ±) = a + b(1 ‚àíŒ≤),
is an isomorphism.
Now F3[x]/(x2 ‚àíx ‚àí1) is also a Ô¨Åeld with nine elements, and it can shown that it is
isomorphic to both of the two Ô¨Åelds E and F just given (see Corollary 3.132).
(iii) In Example 3.35(ii) on page 137, we exhibited eight monic irreducible cubics p(x) ‚àà
F3[x]; each of them gives rise to a Ô¨Åeld F3[x]/(p(x)) having 27 = 33 elements.
‚óÄ
We are now going to solve the isomorphism problem for Ô¨Ånite Ô¨Åelds.
Lemma 3.130.
Let f (x) ‚ààk[x], where k is a Ô¨Åeld, and let E be a splitting Ô¨Åeld of
f (x) over k. Let œï : k ‚Üík‚Ä≤ be an isomorphism of Ô¨Åelds, let œï‚àó: k[x] ‚Üík‚Ä≤[x] be the
isomorphism
g(x) = a0 + a1x + ¬∑ ¬∑ ¬∑ + anxn ‚Üíg‚àó(x) = œï(a0) + œï(a1)x + ¬∑ ¬∑ ¬∑ + œï(an)xn,
and let E‚Ä≤ be a splitting Ô¨Åeld of f ‚àó(x) over k‚Ä≤.
Then there is an isomorphism
: E ‚ÜíE‚Ä≤ extending œï.
E

 E‚Ä≤
k
œï
 k‚Ä≤
Proof.
The proof is by induction on d = [E : k]. If d = 1, then f (x) is a product
of linear polynomials in k[x], and it follows easily that f ‚àó(x) is also a product of linear
polynomials in k‚Ä≤[x]. Therefore, E‚Ä≤ = k‚Ä≤, and we may set  = œï.
For the inductive step, choose a root z of f (x) in E that is not in k, and let p(x) =
irr(z, k) be the minimal polynomial of z over k (Proposition 3.117). Now deg(p) > 1,
because z /‚ààk; moreover, [k(z) : k] = deg(p), by Theorem 3.117. Let z‚Ä≤ be a root of
p‚àó(x) in E‚Ä≤, and let p‚àó(x) = irr(z‚Ä≤, k‚Ä≤) be the corresponding monic irreducible polynomial
in k‚Ä≤[x].
By a straightforward generalization16 of Proposition 3.120(ii), there is an isomorphism
œï : k(z) ‚Üík‚Ä≤(z‚Ä≤) extending œï with œï : z ‚Üíz‚Ä≤. We may regard f (x) as a polynomial with
16Proving the generalization earlier would have involved introducing all the notation in the present hypothe-
sis, and so it would have made a simple result appear complicated. The isomorphism œï : k ‚Üík‚Ä≤ induces an
isomorphism œï‚àó: k[x] ‚Üík‚Ä≤[x], which takes p(x) to some polynomial p‚àó(x), and œï‚àóinduces an isomorphism
k[x]/(p(x)) ‚Üík‚Ä≤[x]/(p‚àó(x)).

196
Commutative Rings I
Ch. 3
coefÔ¨Åcients in k(z) (for k ‚äÜk(z) implies k[x] ‚äÜk(z)[x]). We claim that E is a splitting
Ô¨Åeld of f (x) over k(z); that is,
E = k(z)(z1, . . . , zn),
where z1, . . . , zn are the roots of f (x)/(x ‚àíz); after all,
E = k(z, z1, . . . , zn) = k(z)(z1, . . . , zn).
Similarly, E‚Ä≤ is a splitting Ô¨Åeld of f ‚àó(x) over k‚Ä≤(z‚Ä≤). But [E : k(z)] < [E : k], by
Theorem 3.121, so that the inductive hypothesis gives an isomorphism : E ‚ÜíE‚Ä≤ that
extends œï, and hence œï.
‚Ä¢
Theorem 3.131.
If k is a Ô¨Åeld and f (x) ‚ààk[x], then any two splitting Ô¨Åelds of f (x) over
k are isomorphic via an isomorphism that Ô¨Åxes k pointwise.
Proof.
Let E and E‚Ä≤ be splitting Ô¨Åelds of f (x) over k. If œï is the identity, then the
theorem applies at once.
‚Ä¢
It is remarkable that the next theorem was not proved until the 1890s, 60 years after
Galois discovered Ô¨Ånite Ô¨Åelds.
Corollary 3.132 (E. H. Moore).
Any two Ô¨Ånite Ô¨Åelds having exactly pn elements are
isomorphic.
Proof.
If E is a Ô¨Åeld with q = pn elements, then Lagrange's theorem applied to the
multiplicative group E√ó shows that aq‚àí1 = 1 for every a ‚ààE√ó. It follows that every
element of E is a root of f (x) = xq ‚àíx ‚ààFp[x], and so E is a splitting Ô¨Åeld of f (x)
over Fp.
‚Ä¢
E. H. Moore (1862-1932) began his mathematical career as an algebraist, but he did
important work in many other parts of mathematics as well; for example, Moore-Smith
convergence is named in part after him.
Finite Ô¨Åelds are often called Galois Ô¨Åelds in honor of their discoverer. In light of Corol-
lary 3.132, we may speak of the Ô¨Åeld with q elements, where q = pn is a power of a
prime p.
EXERCISES
3.81 Prove that if I = {0}, then R/I ‚àº= R.
3.82 (Third Isomorphism Theorem for Rings) If R is a commutative ring having ideals I ‚äÜJ,
then J/I is an ideal in R/I and there is a ring isomorphism (R/I)/(J/I) ‚àº= R/J.
3.83 For every commutative ring R, prove that R[x]/(x) ‚àº= R.
3.84 Prove that F3[x]/(x3 ‚àíx2 + 1) ‚àº= F3[x]/(x3 ‚àíx2 + x + 1).

Sec. 3.8
Quotient Rings and Finite Fields
197
3.85 If X is a subset of a commutative ring R, deÔ¨Åne I(X) to be the intersection of all those ideals
I in R that contain X. Prove that I(X) is the set of all a ‚ààR for which there exist Ô¨Ånitely
many elements x1, . . . , xn ‚ààX and elements ri ‚ààR with a = r1x1 + ¬∑ ¬∑ ¬∑ + rnxn.
3.86 Let h(x), p(x) ‚ààk[x] be monic polynomials, where k is a Ô¨Åeld. If p(x) is irreducible and if
every root of h(x) (in an appropriate splitting Ô¨Åeld) is also a root of p(x), prove that h(x) =
p(x)m for some integer m ‚â•1.
Hint. Use induction on deg(h).
3.87 Chinese Remainder Theorem.
(i) Prove that if k is a Ô¨Åeld and f (x), f ‚Ä≤(x) ‚ààk[x] are relatively prime, then given
b(x), b‚Ä≤(x) ‚ààk[x], there exists c(x) ‚ààk[x] with
c ‚àíb ‚àà( f ) and c ‚àíb‚Ä≤ ‚àà( f ‚Ä≤);
moreover, if d(x) is another common solution, then c ‚àíd ‚àà( f f ‚Ä≤).
Hint.
Adapt the proof of Theorem 1.28. This exercise is generalized to commutative
rings in Exercise 6.11(iii) on page 325.
(ii) Prove that if k is a Ô¨Åeld and f (x), g(x) ‚ààk[x] are relatively prime, then
k[x]/( f (x)g(x)) ‚àº= k[x]/( f (x)) √ó k[x]/(g(x)).
Hint. See the proof of Theorem 2.81.
3.88
(i) Prove that a Ô¨Åeld K cannot have subÔ¨Åelds k‚Ä≤ and k‚Ä≤‚Ä≤ with k‚Ä≤ ‚àº= Q and k‚Ä≤‚Ä≤ ‚àº= Fp for some
prime p.
(ii) Prove that a Ô¨Åeld K cannot have subÔ¨Åelds k‚Ä≤ and k‚Ä≤‚Ä≤ with k‚Ä≤ ‚àº= Fp and k‚Ä≤‚Ä≤ ‚àº= Fq, where
p Ã∏= q are primes.
3.89 Prove that the stochastic group (2, F4) ‚àº= A4.
Hint. See Exercise 3.19 on page 125.
3.90 Let f (x) = s0 + s1x + ¬∑ ¬∑ ¬∑ + sn‚àí1xn‚àí1 + xn ‚ààk[x], where k is a Ô¨Åeld, and suppose that
f (x) = (x ‚àíŒ±1)(x ‚àíŒ±2) ¬∑ ¬∑ ¬∑ (x ‚àíŒ±n). Prove that sn‚àí1 = ‚àí(Œ±1 + Œ±2 + ¬∑ ¬∑ ¬∑ + Œ±n) and that
s0 = (‚àí1)nŒ±1Œ±2 ¬∑ ¬∑ ¬∑ Œ±n. Conclude that the sum and product of all the roots of f (x) lie in k.
3.91 Write addition and multiplication tables for the Ô¨Åeld F8 with eight elements.
Hint. Use an irreducible cubic over F2.
3.92 Let k ‚äÜK ‚äÜE be Ô¨Åelds. Prove that if E is a Ô¨Ånite extension of k, then E is a Ô¨Ånite extension
of K and K is a Ô¨Ånite extension of k.
Hint. Use Corollary 3.90(ii).
3.93 Let k ‚äÜF ‚äÜK be a tower of Ô¨Åelds, and let z ‚ààK. Prove that if k(z)/k is Ô¨Ånite, then
[F(z) : F] ‚â§[k(z) : k]. In particular, [F(z) : F] is Ô¨Ånite.
Hint. Use Proposition 3.117 to obtain an irreducible polynomial p(x) ‚ààk[x]; the polynomial
p(x) may factor in K[x].
3.94
(i) Is F4 a subÔ¨Åeld of F8?
(ii) For any prime p, prove that if Fpn is a subÔ¨Åeld of Fpm , then n | m (the converse is also
true, as we shall see later).
Hint. View Fpm as a vector space over Fpn.
3.95 Let K/k be a Ô¨Åeld extension. If A ‚äÜK and u ‚ààk(A), prove that there are a1, . . . , an ‚ààA
with u ‚ààk(a1, . . . , an).

4
Fields
4.1 INSOLVABILITY OF THE QUINTIC
This chapter will discuss what is nowadays called Galois theory (it was originally called
theory of equations), the interrelation between Ô¨Åeld extensions and certain groups asso-
ciated to them, called Galois groups. This theory will enable us to prove the theorem of
Abel-RufÔ¨Åni as well as Galois's theorem describing precisely when the quadratic formula
can be generalized to polynomials of higher degree. Another corollary of this theory is a
proof of the fundamental theorem of algebra.
By Kronecker's theorem, Theorem 3.123, for each monic f (x) ‚ààk[x], where k is a
Ô¨Åeld, there is a Ô¨Åeld K containing k and (not necessarily distinct) roots z1, . . . , zn with
f (x) = xn + an‚àí1xn‚àí1 + ¬∑ ¬∑ ¬∑ + a1x + a0 = (x ‚àíz1) ¬∑ ¬∑ ¬∑ (x ‚àízn).
By induction on n ‚â•1, we can easily generalize1 Exercise 3.90 on page 197:
Ô£±
Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£≥
an‚àí1 = ‚àí

i
zi
an‚àí2 =

i< j
ziz j
an‚àí3 = ‚àí

i< j<k
ziz jzk
...
a0 = (‚àí1)nz1z2 ¬∑ ¬∑ ¬∑ zn.
(1)
1The coefÔ¨Åcients ai may be viewed as polynomials in z1, . . . , zn; as such, they are called the elementary
symmetric polynomials, for they are unchanged if the z's are permuted.
198

Sec. 4.1
Insolvability of the Quintic
199
Notice that ‚àían‚àí1 is the sum of the roots and that ¬±a0 is the product of the roots. Given the
coefÔ¨Åcients of f (x), can we Ô¨Ånd its roots; that is, given the a's, can we solve the system
(1) of n equations in n unknowns? If n = 2, the answer is yes: The quadratic formula
works. If n = 3 or 4, the answer is still yes, for the cubic and quartic formulas work. But
if n ‚â•5, we shall see that no analogous solution exists.
We did not say that no solution of system (1) exists if n ‚â•5; we said that no solution
analogous to the solutions of the classical formulas exists. It is quite possible that there
is some way of Ô¨Ånding the roots of a quintic polynomial if we do not limit ourselves to
Ô¨Åeld operations and extraction of roots only. Indeed, we can Ô¨Ånd the roots by Newton's
method: if r is a real root of a polynomial f (x) and if x0 is a "good" approximation to r,
then r = limn‚Üí‚àûxn, where xn is deÔ¨Åned recursively by xn+1 = xn ‚àíf (xn)/f ‚Ä≤(xn) for
all n ‚â•0. There is a method of Hermite Ô¨Ånding roots of quintics using elliptic modular
functions, and there are methods for Ô¨Ånding the roots of many polynomials of higher degree
using hypergeometric functions.
We are going to show, if n ‚â•5, that there is no solution "by radicals" (we will deÔ¨Åne
this notion more carefully later). The key observation is that symmetry is present. Recall
from Chapter 2 that if $ is a polygon in the plane R2, then its symmetry group ($)
consists of all those motions œï : R2 ‚ÜíR2 of the plane for which œï($) = $. Moreover,
motions œï ‚àà($) are completely determined by their values on the vertices of ; indeed,
if $ has n vertices, then ($) is isomorphic to a subgroup of Sn.
We are going to set up an analogy with symmetry groups in which polynomials play the
role of polygons, a splitting Ô¨Åeld of a polynomial plays the role of the plane R2, and an
automorphism Ô¨Åxing k plays the role of a motion.
DeÔ¨Ånition.
Let E be a Ô¨Åeld containing a subÔ¨Åeld k. An automorphism2 of E is an
isomorphism œÉ : E ‚ÜíE; we say that œÉ Ô¨Åxes k if œÉ(a) = a for every a ‚ààk.
For example, consider f (x) = x2 + 1 ‚ààQ[x]. A splitting Ô¨Åeld of f (x) over Q is
E = Q(i), and complex conjugation œÉ : a ‚Üía is an example of an automorphism of E
Ô¨Åxing Q.
Proposition 4.1.
Let k be a subÔ¨Åeld of a Ô¨Åeld K, let
f (x) = xn + an‚àí1xn‚àí1 + ¬∑ ¬∑ ¬∑ + a1x + a0 ‚ààk[x],
and let E = k(z1, . . . , zn) ‚äÜK be a splitting Ô¨Åeld. If œÉ : E ‚ÜíE is an automorphism
Ô¨Åxing k, then œÉ permutes the set of roots {z1, . . . , zn} of f (x).
Proof.
If r is a root of f (x), then
0 = f (r) = rn + an‚àí1rn‚àí1 + ¬∑ ¬∑ ¬∑ + a1r + a0.
2The word automorphism is made up of two Greek roots: auto, meaning "self," and morph, meaning "shape"
or "form." Just as an isomorphism carries one group onto an identical replica, an automorphism carries a group
onto itself.

200
Fields
Ch. 4
Applying œÉ to this equation gives
0 = œÉ(r)n + œÉ(an‚àí1)œÉ(r)n‚àí1 + ¬∑ ¬∑ ¬∑ + œÉ(a1)œÉ(r) + œÉ(a0)
= œÉ(r)n + an‚àí1œÉ(r)n‚àí1 + ¬∑ ¬∑ ¬∑ + a1œÉ(r) + a0
= f (œÉ(r)),
because œÉ Ô¨Åxes k. Therefore, œÉ(r) is a root of f (x); thus, if Z is the set of all the roots,
then œÉ|Z : Z ‚ÜíZ, where œÉ|Z is the restriction. But œÉ|Z is injective (because œÉ is), so
that Exercise 1.58 on page 36 says that œÉ|Z is a permutation of Z.
‚Ä¢
Here is the analog of the symmetry group ($) of a polygon $.
DeÔ¨Ånition.
Let k be a subÔ¨Åeld of a Ô¨Åeld E. The Galois group of E over k, denoted by
Gal(E/k), is the set of all those automorphisms of E that Ô¨Åx k. If f (x) ‚ààk[x], and if
E = k(z1, . . . , zn) is a splitting Ô¨Åeld, then the Galois group of f (x) over k is deÔ¨Åned to
be Gal(E/k).
It is easy to check that Gal(E/k) is a group with operation composition of functions.
This deÔ¨Ånition is due to E. Artin (1898-1962), in keeping with his and E. Noether's em-
phasis on "abstract" algebra. Galois's original version (a group isomorphic to this one) was
phrased, not in terms of automorphisms, but in terms of certain permutations of the roots of
a polynomial (see Tignol, Galois' Theory of Algebraic Equations, pages 306-331). Note
that Gal(E/k) is independent of the choice of splitting Ô¨Åeld E, by Theorem 3.131.
The following lemma will be used several times.
Lemma 4.2.
Let E = k(z1, . . . , zn). If œÉ : E ‚ÜíE is an automorphism Ô¨Åxing k, that is,
if œÉ ‚ààGal(E/k), and if œÉ(zi) = zi for all i, then œÉ is the identity 1E.
Proof.
We prove the lemma by induction on n ‚â•1. If n = 1, then each u ‚ààE has the
form u = f (z1)/g(z1), where f (x), g(x) ‚ààk[x] and g(z1) Ã∏= 0. But œÉ Ô¨Åxes z1 as well
as the coefÔ¨Åcients of f (x) and of g(x), so that œÉ Ô¨Åxes all u ‚ààE. For the inductive step,
write K = k(z1, . . . , zn‚àí1), and note that E = K(zn) [for K(zn) is the smallest subÔ¨Åeld
containing k and z1, . . . , zn‚àí1, zn]. Having noted this, the inductive step is just a repetition
of the base step with k replaced by K.
‚Ä¢
Theorem 4.3.
If f (x) ‚ààk[x] has degree n, then its Galois group Gal(E/k) is isomorphic
to a subgroup of Sn.
Proof.
Let X = {z1, . . . , zn}. If œÉ ‚ààGal(E/k), then Proposition 4.1 shows that its
restriction œÉ|X is a permutation of X; that is, œÉ|X ‚ààSX. DeÔ¨Åne œï : Gal(E/k) ‚ÜíSX
by œï : œÉ ‚ÜíœÉ|X. To see that œï is a homomorphism, note that both œï(œÉœÑ) and œï(œÉ)œï(œÑ)
are functions X ‚ÜíX, and hence they are equal if they agree on each zi ‚ààX. But
œï(œÉœÑ): zi ‚Üí(œÉœÑ)(zi), while œï(œÉ)œï(œÑ): zi ‚ÜíœÉ(œÑ(zi)), and these are the same.
The image of œï is a subgroup of SX ‚àº= Sn. The kernel of œï is the set of all œÉ ‚ààGal(E/k)
such that œÉ is the identity permutation on X; that is, œÉ Ô¨Åxes each of the roots zi. As œÉ also
Ô¨Åxes k, by deÔ¨Ånition of the Galois group, Lemma 4.2 gives ker œï = {1}. Therefore, œï is
injective, giving the theorem.
‚Ä¢

Sec. 4.1
Insolvability of the Quintic
201
If f (x) = x2 + 1 ‚ààQ[x], then complex conjugation œÉ is an automorphism of its split-
ting Ô¨Åeld Q(i) which Ô¨Åxes Q (and interchanges the roots i and ‚àíi). Since Gal(Q(i)/Q) is
a subgroup of the symmetric group S2, which has order 2, it follows that Gal(Q(i)/Q) =
‚ü®œÉ‚ü©‚àº= I2. We should regard the elements of any Galois group Gal(E/k) as generalizations
of complex conjugation.
We are going to compute the order of the Galois group, but we Ô¨Årst obtain some infor-
mation about Ô¨Åeld isomorphisms and automorphisms.
Lemma 4.4.
If k is a Ô¨Åeld of characteristic 0, then every irreducible polynomial p(x) ‚àà
k[x] has no repeated roots.
Proof.
In Exercise 3.37 on page 142, we saw, for any (not necessarily irreducible) poly-
nomial f (x) with coefÔ¨Åcients in any Ô¨Åeld, that f (x) has no repeated roots if and only if
the gcd ( f, f ‚Ä≤) = 1, where f ‚Ä≤(x) is the derivative of f (x).
Now consider p(x) ‚ààk[x]. Either p‚Ä≤(x) = 0 or deg(p‚Ä≤) < deg(p). Since p(x) is
irreducible, it is not constant, and so it has some nonzero monomial ai xi, where i ‚â•1.
Therefore, iai xi‚àí1 is a nonzero monomial in p‚Ä≤(x), because k has characteristic 0, and so
p‚Ä≤(x) Ã∏= 0. Finally, since p(x) is irreducible, its only divisors are constants and associates;
as p‚Ä≤(x) has smaller degree, it is not an associate of p(x), and so the gcd (p‚Ä≤, p) = 1.
‚Ä¢
Recall Theorem 3.120(i): If E/k is an extension and Œ± ‚ààE is algebraic over k, then
there is a unique monic irreducible polynomial irr(Œ±, k) ‚ààk[x], called its minimal polyno-
mial, having Œ± as a root.
DeÔ¨Ånition.
Let E/k be an algebraic extension. An irreducible polynomial p(x) is sepa-
rable if it has no repeated roots. An arbitrary polynomial f (x) is separable if each of its
irreducible factors has no repeated roots.
An element Œ± ‚ààE is called separable if either Œ± is transcendental over k or if Œ± is
algebraic over k and its minimal polynomial irr(Œ±, k) has no repeated roots; that is, irr(Œ±, k)
is a separable polynomial.
A Ô¨Åeld extension E/k is called a separable extension if each of its elements is separa-
ble; E/k is inseparable if it is not separable.
Lemma 4.4 shows that every extension of a Ô¨Åeld of characteristic 0 is a separable exten-
sion. If E is a Ô¨Ånite Ô¨Åeld with pn elements, then Lagrange's theorem (for the multiplicative
group E√ó) shows that every element of E is a root of x pn ‚àíx. We saw, in the proof of
Theorem 3.127 (the existence of Ô¨Ånite Ô¨Åelds with pn elements), that x pn ‚àíx has no re-
peated roots. It follows that if k ‚äÜE, then E/k is a separable extension, for if Œ± ‚ààE, then
irr(Œ±, k) is a divisor of x pn ‚àíx.
Example 4.5.
Here is an example of an inseparable extension. Let k = Fp(t) = Frac(Fp[t]), and let
E = k(Œ±), where Œ± is a root of f (x) = x p ‚àít; that is, Œ± p = t. In E[x], we have
f (x) = x p ‚àít = x p ‚àíŒ± p = (x ‚àíŒ±)p.

202
Fields
Ch. 4
If we show that Œ± /‚ààk, then f (x) is irreducible, by Proposition 3.126, and so f (x) =
irr(Œ±, k) is an inseparable polynomial. Therefore, E/k is an inseparable extension.
It remains to show that Œ± /‚ààk. Otherwise, there are g(t), h(t) ‚ààFp[t] with Œ± =
g(t)/h(t). Hence, g = Œ±h and g p = Œ± ph p = th p, so that
deg(g p) = deg(th p) = 1 + deg(h p).
But p | deg(g p) and p | deg(h p), and this gives a contradiction.
‚óÄ
We will study separability and inseparability more thoroughly in Chapter 6.
Example 4.6.
Let m be a positive integer, let k be a Ô¨Åeld, and let f (x) = xm ‚àí1 ‚ààk[x]. If the
characteristic of k does not divide m, then mxm‚àí1 Ã∏= 0 and the gcd ( f, f ‚Ä≤) = 1; hence,
f (x) has no repeated roots. Therefore, any splitting Ô¨Åeld E/k of f (x) contains m distinct
mth roots of unity. Moreover, the set of these roots of unity is a (multiplicative) subgroup
of E√ó of order m that is cyclic, by Theorem 3.30. We have proved that if characteristic
k ‚à§m, then there exists a primitive mth root of unity œâ in some extension Ô¨Åeld of k, and œâ
is a separable element.
On the other hand, if pe is a prime power and k has characteristic p, then x pe ‚àí1 =
(x ‚àí1)pe, and so there is only one peth root of unity, namely, 1.
‚óÄ
Separability of E/k allows us to Ô¨Ånd the order of Gal(E/k).
Theorem 4.7.
(i) Let E/k be a splitting Ô¨Åeld of a separable polynomial f (x) ‚ààk[x], let œï : k ‚Üík‚Ä≤
be a Ô¨Åeld isomorphism, and let E‚Ä≤/k‚Ä≤ be a splitting Ô¨Åeld of f ‚àó(x) ‚ààk‚Ä≤[x] [where
f ‚àó(x) is obtained from f (x) by applying œï to its coefÔ¨Åcients].
E

 E‚Ä≤
k
œï
 k‚Ä≤
Then there are exactly [E : k] isomorphisms : E ‚ÜíE‚Ä≤ that extend œï.
(ii) If E/k is a splitting Ô¨Åeld of a separable f (x) ‚ààk[x], then
| Gal(E/k)| = [E : k].
Proof.
(i) The proof, by induction on [E : k], modiÔ¨Åes that of Lemma 3.130. If [E : k] =
1, then E = k and there is only one extension  of œï, namely, œï itself. If [E : k] > 1, let
f (x) = p(x)g(x), where p(x) is an irreducible factor of largest degree, say, d. We may
assume that d > 1, otherwise f (x) splits over k and [E : k] = 1. Choose a root Œ± of p(x)
(note that Œ± ‚ààE because E is a splitting Ô¨Åeld of f (x) = p(x)g(x)). If œï : k(Œ±) ‚ÜíE‚Ä≤

Sec. 4.1
Insolvability of the Quintic
203
is any extension of œï, then œï(Œ±) is a root Œ±‚Ä≤ of p‚àó(x), by Proposition 4.1; since f ‚àó(x) is
separable, p‚àó(x) has exactly d roots Œ±‚Ä≤ ‚ààE‚Ä≤; by Lemma 4.2 and Theorem 3.120(ii), there
are exactly d isomorphisms œï : k(Œ±) ‚Üík‚Ä≤(Œ±‚Ä≤) extending œï, one for each Œ±‚Ä≤. Now E is
also a splitting Ô¨Åeld of f (x) over k(Œ±), because adjoining all the roots of f (x) to k(Œ±) still
produces E, and E‚Ä≤ is a splitting Ô¨Åeld of f ‚àó(x) over k‚Ä≤(Œ±‚Ä≤). Since [E : k(Œ±)] = [E : k]/d,
induction shows that each of the d isomorphisms œï has exactly [E : k]/d extensions
: E ‚ÜíE‚Ä≤. Thus, we have constructed [E : k] isomorphisms extending œï. But there are
no others, because every œÑ extending œï has œÑ|k(Œ±) = œï for some œï : k(Œ±) ‚Üík‚Ä≤(Œ±‚Ä≤).
(ii) In part (i), take k = k‚Ä≤, E = E‚Ä≤, and œï = 1k.
‚Ä¢
Example 4.8.
The separability hypothesis in Theorem 4.7(ii) is necessary. In Example 4.5, we saw that
if k = Fp(t) and Œ± is a root of x p ‚àít, then E = k(Œ±) is an inseparable extension.
Moreover, x p ‚àít = (x ‚àíŒ±)p, so that Œ± is the only root of this polynomial. Therefore, if
œÉ ‚ààGal(E/k), then Proposition 4.1 shows that œÉ(Œ±) = Œ±. Therefore, Gal(E/k) = {1},
by Lemma 4.2, and so | Gal(E/k)| < [E : k] = p in this case.
‚óÄ
Corollary 4.9.
Let E/k be a splitting Ô¨Åeld of a separable polynomial f (x) ‚ààk[x] of
degree n. If f (x) is irreducible, then n | | Gal(E/k)|.
Proof.
By the theorem, | Gal(E/k)| = [E : k]. Let Œ± ‚ààE be a root of f (x). Since f (x)
is irreducible, [k(Œ±) : k] = n, and
[E : k] = [E : k(Œ±)][k(Œ±) : k] = n[E : k(Œ±)].
‚Ä¢
We shall see, in Proposition 4.38, that if E/k is a splitting Ô¨Åeld of a separable polyno-
mial, then E/k is a separable extension.
Here are some computations of Galois groups of speciÔ¨Åc polynomials in Q[x].
Example 4.10.
(i) Let f (x) = x3 ‚àí1 ‚ààQ[x]. Now f (x) = (x ‚àí1)(x2 + x + 1), where x2 + x + 1
is irreducible (the quadratic formula shows that its roots œâ and œâ, do not lie in Q). The
splitting Ô¨Åeld of f (x) is Q(œâ), for œâ2 = œâ, and so [Q(œâ) : Q] = 2.
Therefore,
| Gal(Q(œâ)/Q)| = 2, by Theorem 4.7(ii), and it is cyclic of order 2. Its nontrivial ele-
ment is complex conjugation.
(ii) Let f (x) = x2 ‚àí2 ‚ààQ[x]. Now f (x) is irreducible with roots ¬±
‚àö
2, so that E =
Q(
‚àö
2) is a splitting Ô¨Åeld. By Theorem 4.7(ii), | Gal(E/Q)| = 2. Now every element of E
has a unique expression of the form a + b
‚àö
2, where a, b ‚ààQ [Theorem 3.117(v)], and it
is easily seen that œÉ : E ‚ÜíE, deÔ¨Åned by œÉ : a + b
‚àö
2 ‚Üía ‚àíb
‚àö
2, is an automorphism
of E Ô¨Åxing Q. Therefore, Gal(E/Q) = ‚ü®œÉ‚ü©, where œÉ interchanges
‚àö
2 and ‚àí
‚àö
2.
(iii) Let g(x) = x3 ‚àí2 ‚ààQ[x]. The roots of g(x) are Œ±, œâŒ±, and œâ2Œ±, where Œ± =
3‚àö
2, the
real cube root of 2, and œâ is a primitive cube root of unity. It is easy to see that the splitting
Ô¨Åeld of g(x) is E = Q(Œ±, œâ). Note that
[E : Q] = [E : Q(Œ±)][Q(Œ±) : Q] = 3[E : Q(Œ±)],

204
Fields
Ch. 4
for g(x) is irreducible over Q (it is a cubic having no rational roots). Now E Ã∏= Q(Œ±),
for every element in Q(Œ±) is real, while the complex number œâ is not real. Therefore,
[E : Q] = | Gal(E/Q)| > 3. On the other hand, we know that Gal(E/Q) is isomorphic to
a subgroup of S3, and so we must have Gal(E/Q) ‚àº= S3.
(iv) We examined f (x) = x4 ‚àí10x2 + 1 ‚ààQ[x] in Example 3.122, when we saw that
f (x) is irreducible; in fact, f (x) = irr(Œ≤, Q), where Œ≤ =
‚àö
2 +
‚àö
3. If E = Q(Œ≤),
then [E : Q] = 4; moreover, E is a splitting Ô¨Åeld of f (x), where the other roots of
f (x) are ‚àí
‚àö
2 ‚àí
‚àö
3, ‚àí
‚àö
2 +
‚àö
3, and
‚àö
2 ‚àí
‚àö
3. It follows from Theorem 4.7(ii) that if
G = Gal(E/Q), then |G| = 4; hence, either G ‚àº= I4 or G ‚àº= V.
We also saw, in Example 3.122, that E contains
‚àö
2 and
‚àö
3. If œÉ is an automorphism
of E Ô¨Åxing Q, then œÉ(
‚àö
2) = u
‚àö
2, where u = ¬±1, because (œÉ(
‚àö
2)2 = 2. Therefore,
œÉ 2(
‚àö
2) = œÉ(u
‚àö
2) = uœÉ(
‚àö
2) = u2‚àö
2 =
‚àö
2; similarly, œÉ 2(
‚àö
3) =
‚àö
3. If Œ± is a root of
f (x), then Œ± = u
‚àö
2 + v
‚àö
3, where u, v = ¬±1. Hence,
œÉ 2(Œ±) = uœÉ 2(
‚àö
2) + vœÉ 2(
‚àö
3) = u
‚àö
2 + v
‚àö
3 = Œ±.
Lemma 4.2 gives œÉ 2 = 1E for all œÉ ‚ààGal(E/Q), and so Gal(E/Q) ‚àº= V.
Here is another way to compute G = Gal(E/Q). We saw in Example 3.122 that E =
Q(
‚àö
2+
‚àö
3) = Q(
‚àö
2,
‚àö
3) is also a splitting Ô¨Åeld of g(x) = (x2 ‚àí2)(x2 ‚àí3) over Q. By
Proposition 3.120(ii), there is an automorphism œï : Q(
‚àö
2) ‚ÜíQ(
‚àö
2) taking
‚àö
2 ‚Üí‚àí
‚àö
2.
But
‚àö
3 /‚ààQ(
‚àö
2), as we noted in Example 3.122, so that x2 ‚àí3 is irreducible over
Q(
‚àö
2). Lemma 3.130 shows that œï extends to an automorphism : E ‚ÜíE; of course,
 ‚ààGal(E/Q). There are two possibilites: (
‚àö
3) = ¬±
‚àö
3. Indeed, it is now easy to see
that the elements of Gal(E/Q) correspond to the four-group, consisting of the identity and
the permutations (in cycle notation)
‚àö
2, ‚àí
‚àö
2
‚àö
3,
‚àö
3

,
‚àö
2, ‚àí
‚àö
2
‚àö
3, ‚àí
‚àö
3

,
‚àö
2,
‚àö
2
‚àö
3, ‚àí
‚àö
3

.
‚óÄ
Here are two more general computations of Galois groups.
Proposition 4.11.
If m is a positive integer, if k is a Ô¨Åeld, and if E is a splitting Ô¨Åeld of
xm ‚àí1 over k, then Gal(E/k) is abelian; in fact, Gal(E/k) is isomorphic to a subgroup
of the multiplicative group U(Im) of all [i] with (i, m) = 1.
Proof.
Assume Ô¨Årst that the characteristic of k does not divide m. By Example 4.6, E
contains a primitive mth root of unity, œâ, and so E = k(œâ). The group of all roots of
xm ‚àí1 in E is cyclic, say, with generator œâ, so that if œÉ ‚ààGal(E/k), then its restriction is
an automorphism of the cyclic group ‚ü®œâ‚ü©. Hence, œÉ(œâ) = œâi must also be a generator of
‚ü®œâ‚ü©; that is, (i, m) = 1, by Theorem 2.33(i). It is easy to see that i is uniquely determined
mod m, so that the function œï : Gal(k(œâ)/k) ‚ÜíU(Im), given by œï(œÉ) = [i] if œÉ(œâ) =
œâi, is well-deÔ¨Åned. Now œï is a homomorphism, for if œÑ(œâ) = œâ j, then
œÑœÉ(œâ) = œÑ(œâi) = (œâi) j = œâi j.
Finally, Lemma 4.2 shows that œï is injective.

Sec. 4.1
Insolvability of the Quintic
205
Suppose now that k has characteristic p and that m = pen, where p ‚à§n. By Exam-
ple 4.6, there is a primitive nth root of unity œâ, and we claim that E = k(œâ) is a splitting
Ô¨Åeld of xm ‚àí1. If Œ∂ m = 1, then 1 = Œ∂ pen = (Œ∂ n)pe. But the only peth root of unity is
1, since k has characteristic p, and so Œ∂ n = 1; that is, Œ∂ ‚ààk(œâ). We have reduced to the
case of the Ô¨Årst paragraph. [In fact, more is true in this case: Gal(E/k) is isomorphic to a
subgroup of the multiplicative group U(In).]
‚Ä¢
Remark.
We cannot conclude more from the proposition; given any Ô¨Ånite abelian group
G, there is some integer m with G isomorphic to a subgroup of U(Im).
‚óÄ
Theorem 4.12.
If p is a prime, then
Gal(Fpn/Fp) ‚àº= In,
and a generator is the Frobenius F : u ‚Üíu p.
Proof.
Let q = pn, and let G = Gal(Fq/Fp). Since Fq has characteristic p, we have
(a + b)p = a p + bp, and so the Frobenius F is a homomorphism of Ô¨Åelds. As any
homomorphism of Ô¨Åelds, F is injective; as Fq is Ô¨Ånite, F must be an automorphism, by
Exercise 1.58 on page 36; that is, F ‚ààG.
If œÄ ‚ààFq is a primitive element, then d(x) = irr(œÄ, Fp) has degree n, by Corol-
lary 3.128, and so |G| = n, by Theorem 4.7(ii). It sufÔ¨Åces to prove that the order j of F is
not less than n. But if F j = 1Fq for j < n, then u p j = u for all of the q = pn elements
u ‚ààFq, giving too many roots of the polynomial x p j ‚àíx.
‚Ä¢
The following nice corollary of Lemma 3.130 says, in our analogy between Galois the-
ory and symmetry of polygons, that irreducible polynomials correspond to regular poly-
gons.
Proposition 4.13.
Let k be a Ô¨Åeld and let p(x) ‚ààk[x] have no repeated roots. If E/k is
a splitting Ô¨Åeld of p(x), then p(x) is irreducible if and only if Gal(E/k) acts transitively
on the roots of p(x).
Proof.
Assume that p(x) is irreducible, and let Œ±, Œ≤ ‚ààE be roots of p(x). By Theo-
rem 3.120(i), there is an isomorphism œï : k(Œ±) ‚Üík(Œ≤) with œï(Œ±) = Œ≤ and which Ô¨Åxes
k. Lemma 3.130 shows that œï extends to an automorphism  of E that Ô¨Åxes k; that is,
 ‚ààGal(E/k). Now (Œ±) = œï(Œ±) = Œ≤, and so Gal(E/k) acts transitively on the roots.
Conversely, assume that Gal(E/k) acts transitively on the roots of p(x). If p(x) =
q1(x) ¬∑ ¬∑ ¬∑ qt(x) is a factorization into irreducibles in k[x], where t ‚â•2, choose a root
Œ± ‚ààE of q1(x) and choose a root Œ≤ ‚ààE of q2(x). By hypothesis, there is œÉ ‚ààGal(E/k)
with œÉ(Œ±) = Œ≤. Now œÉ permutes the roots of q1(x), by Proposition 4.1. However, Œ≤ is not
a root of q1(x), because p(x) has no repeated roots, and this is a contradiction. Therefore,
t = 1; that is, p(x) is irreducible.
‚Ä¢

206
Fields
Ch. 4
We can now give another proof of Corollary 4.9. Theorem 2.98 says that if X is a G-set,
then |G| = |O(x)||Gx|, where O(x) is the orbit of x ‚ààX. In particular, if X is a transitive
G-set, then |X| is a divisor of |G|. Let f (x) ‚ààk[x] be a separable irreducible polynomial
of degree n, and let E/k be its splitting Ô¨Åeld. If X is the set of roots of f (x), then X is
a transitive Gal(E/k)-set, by Proposition 4.13, and so n = deg( f ) = |X| is a divisor of
| Gal(E/k)|.
The analogy3 is complete.
Polygon $ . . . . . . . . . . . . . . . . . . . . . . polynomial f (x) ‚ààk[x]
Regular polygon . . . . . . . . . . . . . . . . . irreducible polynomial
Vertices of $ . . . . . . . . . . . . . . . . . . . . roots of f (x)
Plane . . . . . . . . . . . . . . . . . . . . . . . . . . . splitting Ô¨Åeld E of f (x)
Motion. . . . . . . . . . . . . . . . . . . . . . . . . .automorphism Ô¨Åxing k
Symmetry group ($) . . . . . . . . . . . Galois group Gal(E/k)
Here is the basic strategy. First, we will translate the classical formulas (giving the
roots of polynomials of degree at most 4) in terms of subÔ¨Åelds of a splitting Ô¨Åeld E over k.
Second, this translation into the language of Ô¨Åelds will itself be translated into the language
of groups: If there is a formula for the roots of f (x), then Gal(E/k) must be a solvable
group (which we will soon deÔ¨Åne). Finally, polynomials of degree at least 5 can have
Galois groups that are not solvable. The conclusion is that there are polynomials of degree
5 for which there is no formula, analogous to the classical formulas, giving their roots.
Formulas and Solvability by Radicals
Without further ado, here is the translation of the existence of a formula for the roots of a
polynomial in terms of subÔ¨Åelds of a splitting Ô¨Åeld.
DeÔ¨Ånition.
A pure extension of type m is an extension k(u)/k, where um ‚ààk for some
m ‚â•1. An extension K/k is a radical extension if there is a tower of Ô¨Åelds
k = K0 ‚äÜK1 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜKt = K
in which each Ki+1/Ki is a pure extension.
If um = a ‚ààk, then k(u) arises from k by adjoining an mth root of a. If k ‚äÜC, there
are m different mth roots of a, namely, u, œâu, œâ2u, . . . , œâm‚àí1u, where œâ = e2œÄi/m is a
primitive mth root of unity. More generally, if k contains the mth roots of unity, then a pure
extension k(u) of type m, that is, um = a ‚ààk, then k(u) is a splitting Ô¨Åeld of xm ‚àía. Not
every subÔ¨Åeld k of C contains all the roots of unity; for example, 1 and ‚àí1 are the only
roots of unity in Q. Since we seek formulas involving extraction of roots, it will eventually
be convenient to assume that k contains appropriate roots of unity.
3Actually, a better analogy would involve polyhedra in euclidean space Rn instead of only polygons in the
plane.

Sec. 4.1
Insolvability of the Quintic
207
When we say that there is a formula for the roots of a polynomial f (x) analogous to the
quadratic formula, we mean that there is some expression giving the roots of f (x) in terms
of the coefÔ¨Åcients of f (x). The expression may involve the Ô¨Åeld operations, constants,
and extraction of roots, but it should not involve any other operations involving cosines,
deÔ¨Ånite integrals, or limits, for example. We maintain that a formula as we informally
described exists precisely when f (x) is solvable by radicals, which we now deÔ¨Åne.
DeÔ¨Ånition.
Let f (x) ‚ààk[x] have a splitting Ô¨Åeld E. We say that f (x) is solvable by
radicals if there is a radical extension
k = K0 ‚äÜK1 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜKt
with E ‚äÜKt.
Actually, there is a nontrivial result of Gauss that we are assuming. It is true, but not
obvious, that xn ‚àí1 is solvable by radicals in the sense that there is the desired sort of
expression for
e2œÄi/n = cos

2œÄ
n

+ i sin

2œÄ
n

(see van der Waerden, Modern Algebra I, pages 163-168, or Tignol, Galois' Theory of
Algebraic Equations, pages 252-256). This theorem of Gauss is what enabled him to
construct a regular 17-gon with ruler and compass.
Let us illustrate this deÔ¨Ånition by considering the classical formulas for polynomials of
small degree.
Quadratics
If f (x) = x2 + bx + c, then the quadratic formula gives its roots as
1
2

‚àíb ¬±

b2 ‚àí4c

.
Let k = Q(b, c). DeÔ¨Åne K1 = k(u), where u =
‚àö
b2 ‚àí4c. Then K1 is a radical extension
of k, for u2 ‚ààk. Moreover, the quadratic formula implies that K1 is the splitting Ô¨Åeld of
f (x), and so f (x) is solvable by radicals.
Cubics
Let f (X) = X3 + bX2 + cX + d, and let k = Q(b, c, d). The change of variable
X = x ‚àí1
3b yields a new polynomial f (x) = x3 + qx + r ‚ààk[x] having the same
splitting Ô¨Åeld E [for if u is a root of f (x), then u ‚àí1
3b is a root of f (x)]; it follows that
f (x) is solvable by radicals if and only if f (x) is. Special cases of the cubic formula were
discovered by Scipio del Ferro around 1515, and the remaining cases were completed by
Niccol`o Fontana (Tartaglia) in 1535 and by Giralamo Cardano in 1545. The formula gives
the roots of f (x) as
g + h,
œâg + œâ2h,
and
œâ2g + œâh,

208
Fields
Ch. 4
where g3 = 1
2

‚àír +
‚àö
R

, h = ‚àíq/3g, R = r2+ 4
27q3, and œâ = ‚àí1
2 +i
‚àö
3
2 is a primitive
cube root of unity.
The cubic formula is derived as follows. If u is a root of f (x) = x3 + qx + r, write
u = g + h,
and substitute:
0 = f (u) = f (g + h) = g3 + h3 + (3gh + q)u + r.
Now the quadratic formula can be rephrased to say, given any pair of numbers u and v, that
there are (possibly complex) numbers g and h with u = g + h and v = gh. Therefore, we
can further assume that 3gh + q = 0; that is,
g3 + h3 = ‚àír
and
gh = ‚àí1
3q.
After cubing the latter, the resulting pair of equations is
g3 + h3 = ‚àír
g3h3 = ‚àí1
27q3,
giving the quadratic in g3:
g6 + rg3 ‚àí1
27q3 = 0.
The quadratic formula gives
g3 = 1
2

‚àír +
)
r2 + 4
27q3

= 1
2

‚àír +
‚àö
R

[note that h3 is also a root of this quadratic, so that h3 = 1
2

‚àír ‚àí
‚àö
R

]. There are three
cube roots of g3: g, œâg, and œâ2g. Because of the constraint gh = ‚àí1
3q, each of these has
a "mate," namely, h = ‚àíq/(3g), ‚àíq/(3œâg) = œâ2h, and ‚àíq/(3œâ2g) = œâh.
Let us now see that f (x) is solvable by radicals. DeÔ¨Åne K1 = k(
‚àö
R), where R =
r2 + 4
27q3, and deÔ¨Åne K2 = K1(Œ±), where Œ±3 = 1
2(‚àír +
‚àö
R). The cubic formula shows
that K2 contains the root Œ± + Œ≤ of f (x), where Œ≤ = ‚àíq/3Œ±. Finally, deÔ¨Åne K3 = K2(œâ),
where œâ3 = 1. The other roots of f (x) are œâŒ± + œâ2Œ≤ and œâ2Œ± + œâŒ≤, both of which lie in
K3, and so E ‚äÜK3.
A splitting Ô¨Åeld E need not equal K3, for if all the roots of f (x) are real, then E ‚äÜ
R, whereas K3 Ã∏‚äÜR. An interesting aspect of the cubic formula is the so-called casus
irreducibilis; the formula for the roots of an irreducible cubic in Q[x] having all roots real
requires the presence of complex numbers (see Rotman, Galois Theory, 2d ed., page 99).
Casus Irreducibilis.
If f (x) = x3 + qx + r ‚ààQ[x] is an irreducible polynomial having
three real roots, then any radical extension Kt/Q containing the splitting Ô¨Åeld of f (x) is
not real; that is, Kt Ã∏‚äÜR.

Sec. 4.1
Insolvability of the Quintic
209
Example 4.14.
If f (x) = x3 ‚àí15x ‚àí126, then q = ‚àí15, r = ‚àí126, R = 15376, and
‚àö
R = 124. Hence,
g3 = 125, so that g = 5. Thus, h = ‚àíq/(3g) = 1. Therefore, the roots of f (x) are
6,
5œâ + œâ2 = ‚àí3 + 2i
‚àö
3,
5œâ2 + œâ = ‚àí3 ‚àí2i
‚àö
3.
Alternatively, having found one root to be 6, the other two roots can be found as the roots
of the quadratic f (x)/(x ‚àí6) = x2 + 6x + 21.
‚óÄ
Example 4.15.
The cubic formula is not very useful because it often gives the roots in unrecognizable
form. For example, let
f (x) = (x ‚àí1)(x ‚àí2)(x + 3) = x3 ‚àí7x + 6.
The cubic formula gives
g + h =
3
*
1
2

‚àí6 +
)
‚àí400
27

+
3
*
1
2

‚àí6 ‚àí
)
‚àí400
27

.
It is not at all obvious that g + h is a real number, let alone an integer. There is another
version of the cubic formula, due to F. Vi`ete, which gives the roots in terms of trigonometric
functions instead of radicals (see my book, A First Course in Abstract Algebra, pp. 360-
362).
‚óÄ
Quartics
Let f (X) = X4 +bX3 +cX2 +d X +e, and let k = Q(b, c, d, e). The change of variable
X = x ‚àí1
4b yields a new polynomial f (x) = x4 + qx2 + rx + s ‚ààk[x]; moreover, the
splitting Ô¨Åeld E of f (x) is equal to the splitting Ô¨Åeld of f (x), for if u is a root of f (x),
then u ‚àí1
4b is a root of f (x). The quartic formula was found by Luigi Ferrari in 1545, but
here is the version presented by R. Descartes in 1637. Factor f (x) in C[x]:
f (x) = x4 + qx2 + rx + s = (x2 + jx + ‚Ñì)(x2 ‚àíjx + m),
and determine j, ‚Ñìand m. Expanding and equating like coefÔ¨Åcients gives the equations
‚Ñì+ m ‚àíj2 = q;
j(m ‚àí‚Ñì) = r;
‚Ñìm = s.
The Ô¨Årst two equations give
2m = j2 + q + r/j;
2‚Ñì= j2 + q ‚àír/j.

210
Fields
Ch. 4
Substituting these values for m and ‚Ñìinto the third equation yields the resolvent cubic:
( j2)3 + 2q( j2)2 + (q2 ‚àí4s) j2 ‚àír2.
The cubic formula gives j2, from which we can determine m and ‚Ñì, and hence the roots of
the quartic.
DeÔ¨Åne pure extensions
k = K0 ‚äÜK1 ‚äÜK2 ‚äÜK3,
as in the cubic case, so that j2 ‚ààK3. DeÔ¨Åne K4 = K3( j) (so that ‚Ñì, m ‚ààK4). Finally,
deÔ¨Åne K5 = K4

j2 ‚àí4‚Ñì

and K6 = K5

j2 ‚àí4m

[giving roots of the quadratic
factors x2 + jx + ‚Ñìand x2 ‚àíjx + m of f (x)]. The quartic formula gives E ‚äÜK6.
We have just seen that quadratics, cubics, and quartics are solvable by radicals. Con-
versely, if f (x) is a polynomial that is solvable by radicals, then there is a formula of the
desired kind that expresses its roots in terms of its coefÔ¨Åcients. For suppose that
k = K0 ‚äÜK1 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜKt
is a radical extension with splitting Ô¨Åeld E ‚äÜKt. Let z be a root of f (x). Now Kt =
Kt‚àí1(u), where u is an mth root of some element Œ± ‚ààKt‚àí1; hence, z can be expressed in
terms of u and Kt‚àí1; that is, z can be expressed in terms of
m‚àöŒ± and Kt‚àí1. But Kt‚àí1 =
Kt‚àí2(v), where some power of v lies in Kt‚àí2. Hence, z can be expressed in terms of u,
v, and Kt‚àí2. Ultimately, z is expressed by a formula analogous to those of the classical
formulas.
Translation into Group Theory
The second stage of the strategy involves investigating the effect of f (x) being solvable by
radicals on its Galois group.
Suppose that k(u)/k is a pure extension of type 6; that is, u6 ‚ààk. Now k(u3)/k is a
pure extension of type 2, for (u3)2 = u6 ‚ààk, and k(u)/k(u3) is obviously a pure extension
of type 3. Thus, k(u)/k can be replaced by a tower of pure extensions k ‚äÜk(u3) ‚äÜk(u)
of types 2 and 3. More generally, we may assume, given a tower of pure extensions, that
each Ô¨Åeld is of prime type over its predecessor: If k ‚äÜk(u) is of type m, then factor
m = p1 ¬∑ ¬∑ ¬∑ pq, where the p's are (not necessarily distinct) primes, and replace k ‚äÜk(u)
by
k ‚äÜk(um/p1) ‚äÜk(um/p1 p2) ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜk(u).
Here is a key result allowing us to translate solvability by radicals into the language of
Galois groups.
Theorem 4.16.
Let k ‚äÜB ‚äÜE be a tower of Ô¨Åelds, let f (x), g(x) ‚ààk[x], let B be a
splitting Ô¨Åeld of f (x) over k, and let E be a splitting Ô¨Åeld of g(x) over k. Then Gal(E/B)
is a normal subgroup of Gal(E/k), and
Gal(E/k)/ Gal(E/B) ‚àº= Gal(B/k).

Sec. 4.1
Insolvability of the Quintic
211
Proof.
Let B = k(z1, . . . , zt), where z1, . . . , zt are the roots of f (x) in E. If œÉ ‚àà
Gal(E/k), then œÉ permutes z1, . . . , zt, by Proposition 4.1(i) (for œÉ Ô¨Åxes k), and so œÉ(B) =
B. DeÔ¨Åne œÅ : Gal(E/k) ‚ÜíGal(B/k) by œÉ ‚ÜíœÉ|B. It is easy to see, as in the proof of
Theorem 4.3, that œÅ is a homomorphism and that ker œÅ = Gal(E/B). It follows that
Gal(E/B) is a normal subgroup of Gal(E/k). But œÅ is surjective: If œÑ ‚ààGal(B/k), then
Lemma 3.130 applies to show that there is œÉ ‚ààGal(E/k) extending œÑ [i.e., œÅ(œÉ) = œÉ|B =
œÑ]. The Ô¨Årst isomorphism theorem completes the proof.
‚Ä¢
The next technical result will be needed when we apply Theorem 4.16.
Lemma 4.17.
(i) If B = k(Œ±1, . . . , Œ±n) is a Ô¨Ånite extension of a Ô¨Åeld k, then there is a Ô¨Ånite extension
E/B that is a splitting Ô¨Åeld of some polynomial f (x) ‚ààk[x] (such an extension
of smallest degree is called a normal4 closure of B/k). Moreover, if each Œ±i is
separable over k, then f (x) can be chosen to be a separable polynomial.
(ii) If B is a radical extension of k, then the extension E/B in part (i) is a radical
extension of k.
Proof.
(i) By Theorem 3.120(i), there is an irreducible polynomial pi(x) = irr(Œ±i, k)
in k[x], for each i, with pi(Œ±i) = 0, and a splitting Ô¨Åeld E of f (x) = p1(x) ¬∑ ¬∑ ¬∑ pn(x)
containing B. If each Œ±i is separable over k, then each pi(x) is a separable polynomial,
and hence f (x) is a separable polynomial.
(ii) For each pair of roots Œ± and Œ±‚Ä≤ of any pi(x), there is an isomorphism Œ≥ : k(Œ±) ‚Üí
k(Œ±‚Ä≤) which Ô¨Åxes k and which takes Œ± ‚ÜíŒ±‚Ä≤, for both k(Œ±) and k(Œ±‚Ä≤) are isomorphic
to k[x]/(pi(x)). By Lemma 3.130, each such Œ≥ extends to an automorphism œÉ ‚ààG =
Gal(E/k). It follows that E = k(œÉ(u1), . . . , œÉ(ut) : œÉ ‚ààG).
If B/k is a radical extension, then
k ‚äÜk(u1) ‚äÜk(u1, u2) ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜk(u1, . . . , ut) = B,
where each k(u1, . . . , ui+1) is a pure extension of k(u1, . . . , ui); of course, œÉ(B) =
k(œÉ(u1), . . . , œÉ(ut)) is a radical extension of k for every œÉ ‚ààG. We now show that E
is a radical extension of k. DeÔ¨Åne
B1 = k(œÉ(u1) : œÉ ‚ààG).
Now if G = {1, œÉ, œÑ, . . .}, then the tower
k ‚äÜk(u1) ‚äÜk(u1, œÉ(u1)) ‚äÜk(u1, œÉ(u1), œÑ(u1)) ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜB1
displays B1 as a radical extension of k. For example, if um
1 lies in k, then œÑ(u1)m = œÑ(um
1 )
lies in œÑ(k) = k, and hence œÑ(u1)m lies in k ‚äÜk(u1, œÉ(u1)). Assuming, by induction, that
4We often call an extension E/k a normal extension if it is the splitting Ô¨Åeld of some set of polynomials in
k[x].

212
Fields
Ch. 4
a radical extension Bi/k containing {œÉ(u j) : œÉ ‚ààG} for all j ‚â§i has been constructed,
deÔ¨Åne
Bi+1 = Bi(œÉ(ui+1) : œÉ ‚ààG).
It is easy to see that Bi+1/Bi is a radical extension: If um
i+1 ‚ààk(u1, . . . , ui), then
œÑ(ui+1)m ‚ààk(œÑ(u1), . . . , œÑ(ui)) ‚äÜBi; it follows that Bi+1 is a radical extension of k.
Finally, since E = Bt, we have shown that E is a radical extension of k.
‚Ä¢
We can now give the heart of the translation we have been seeking.
Lemma 4.18.
Let
K0 ‚äÜK1 ‚äÜK2 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜKt
be a radical extension of a Ô¨Åeld K0. Assume, for each i ‚â•1, that each Ki is a pure
extension of prime type pi over Ki‚àí1, where pi Ã∏= char(K0), and that K0 contains all the
pith roots of unity. If Kt is a splitting Ô¨Åeld over K0, then there is a sequence of subgroups
Gal(Kt/K0) = G0 ‚â•G1 ‚â•G2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gt = {1},
with each Gi+1 a normal subgroup of Gi and with Gi/Gi+1 cyclic of prime order pi+1.
Proof.
For each i, deÔ¨Åne Gi = Gal(Kt/Ki). It is clear that
Gal(Kt/K0) = G0 ‚â•G1 ‚â•G2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gt = {1}
is a sequence of subgroups. Since K1 = K0(u), where u p1 ‚ààK0, the assumptions that
char(K0) Ã∏= p1 and that K0 contains all the p1th roots of unity implies that K0 contains
a primitive p1th root of unity œâ; hence, K1 is a splitting Ô¨Åeld of the separable polynomial
x p1 ‚àíu p1, for the roots are u, œâu, . . . , œâp1‚àí1u. We may thus apply Theorem 4.16 to see
that G1 = Gal(Kt/K1) is a normal subgroup of G0 = Gal(Kt/K0) and that G0/G1 ‚àº=
Gal(K1/K0). By Theorem 4.7(ii), G0/G1 ‚àº= Ip1. This argument can be repeated for
each i.
‚Ä¢
We have been led to the following deÔ¨Ånition.
DeÔ¨Ånition.
A normal series5 of a group G is a sequence of subgroups
G = G0 ‚â•G1 ‚â•G2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gt = {1}
with each Gi+1 a normal subgroup of Gi; the factor groups of this series are the quotient
groups
G0/G1, G1/G2, . . . , Gn‚àí1/Gn.
A Ô¨Ånite group G is called solvable if it has a normal series each of whose factor groups has
prime order (see the deÔ¨Ånition of inÔ¨Ånite solvable groups on page 286).
5This terminology is not quite standard. We know that normality is not transitive; that is, if H ‚â§K are
subgroups of a group G, then H ‚úÅK and K ‚úÅG does not force H ‚úÅG. A subgroup H ‚â§G is called a
subnormal subgroup if there is a chain
G = G0 ‚â•G1 ‚â•G2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gt = H
with Gi ‚úÅGi‚àí1 for all i ‚â•1. Normal series as deÔ¨Åned in the text are called subnormal series by some authors;
they reserve the name normal series for those series in which each Gi is a normal subgroup of the big group G.

Sec. 4.1
Insolvability of the Quintic
213
In this language, Lemma 4.18 says that Gal(Kt/K0) is a solvable group if Kt is a radical
extension of K0 and K0 contains appropriate roots of unity.
Example 4.19.
(i) By Exercise 2.86(ii) on page 113, every Ô¨Ånite abelian group G has a (necessarily normal)
subgroup of prime index. It follows, by induction on |G|, that every Ô¨Ånite abelian group is
solvable.
(ii) Let us see that S4 is a solvable group. Consider the chain of subgroups
S4 ‚â•A4 ‚â•V ‚â•W ‚â•{1},
where V is the four-group and W is any subgroup of V of order 2. Note, since V is
abelian, that W is a normal subgroup of V. Now |S4/A4| = |S4|/|A4| = 24/12 = 2,
|A4/V| = |A4|/|V| = 12/4 = 3, |V/W| = |V|/|W| = 4/2 = 2, and |W/{1}| = |W| = 2.
Since each factor group has prime order, S4 is solvable.
(iii) A nonabelian simple group G, for example, G = A5, is not solvable, for its only
proper normal subgroup is {1}, and G/{1} ‚àº= G is not cyclic of prime order.
‚óÄ
The awkward hypothesis in the next lemma, about roots of unity, will soon be removed.
Lemma 4.20.
Let k be a Ô¨Åeld and let f (x) ‚ààk[x] be solvable by radicals, so there is
a radical extension k = K0 ‚äÜK1 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜKt with Kt containing a splitting Ô¨Åeld E of
f (x). If each Ki/Ki‚àí1 is a pure extension of prime type pi, where pi Ã∏= char(k), and if
k contains all the pith roots of unity, then the Galois group Gal(E/k) is a quotient of a
solvable group.
Proof.
There is a tower of pure extensions of prime type
k = K0 ‚äÜK1 ‚äÜK2 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜKt
with E ‚äÜKt; by Lemma 4.17, we may assume that Kt is also a splitting Ô¨Åeld of some poly-
nomial in k[x]. The hypothesis on k allows us to apply Lemma 4.18 to see that Gal(Kt/k)
is a solvable group. Since E and Kt are splitting Ô¨Åelds over k, Theorem 4.16 shows that
Gal(Kt/k)/ Gal(Kt/E) ‚àº= Gal(E/k), as desired.
‚Ä¢
Proposition 4.21.
Every quotient G/N of a solvable group G is itself a solvable group.
Proof.
Let G = G0 ‚â•G1 ‚â•G2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gt = {1} be a sequence of subgroups as in the
deÔ¨Ånition of solvable group. Since N ‚úÅG, we have NGi a subgroup of G for all i, and so
there is a sequence of subgroups
G = G0N ‚â•G1N ‚â•¬∑ ¬∑ ¬∑ ‚â•Gt N = N ‚â•{1}.
This is a normal series: With obvious notation,
(gin)Gi+1N(gin)‚àí1 ‚â§giGi+1Ng‚àí1
i
= giGi+1g‚àí1
i
N ‚â§Gi+1N;

214
Fields
Ch. 4
the Ô¨Årst inequality holds because n(Gi+1N)n‚àí1 ‚â§NGi+1N ‚â§(Gi+1N)(Gi+1N) =
Gi+1N (for Gi+1N is a subgroup); the equality holds because Ng‚àí1
i
= g‚àí1
i
N (for N ‚úÅG,
and so its right cosets coincide with its left cosets); the last inequality holds because
Gi+1 ‚úÅGi.
The second isomorphism theorem gives
Gi
Gi ‚à©(Gi+1N)
‚àº= Gi(Gi+1N)
Gi+1N
=
Gi N
Gi+1N ,
the last equation holding because GiGi+1 = Gi. Since Gi+1 ‚úÅGi ‚à©Gi+1N, the third
isomorphism theorem gives a surjection Gi/Gi+1 ‚ÜíGi/[Gi ‚à©Gi+1N], and so the com-
posite is a surjection Gi/Gi+1 ‚ÜíGi N/Gi+1N. As Gi/Gi+1 is cyclic of prime order, its
image is either cyclic of prime order or trivial. Therefore, G/N is a solvable group.
‚Ä¢
Proposition 4.22.
Every subgroup H of a solvable group G is itself a solvable group.
Proof.
Since G is solvable, there is a sequence of subgroups
G = G0 ‚â•G1 ‚â•G2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gt = {1}
with Gi normal in Gi‚àí1 and Gi‚àí1/Gi cyclic, for all i. Consider the sequence of subgroups
H = H ‚à©G0 ‚â•H ‚à©G1 ‚â•H ‚à©G2 ‚â•¬∑ ¬∑ ¬∑ ‚â•H ‚à©Gt = {1}.
This is a normal series: If hi+1 ‚ààH ‚à©Gi+1 and gi ‚ààH ‚à©Gi, then gihi+1g‚àí1
i
‚ààH,
for gi, hi+1 ‚ààH; also, gihi+1g‚àí1
i
‚ààGi+1 because Gi+1 is normal in Gi. Therefore,
gihi+1g‚àí1
i
‚ààH ‚à©Gi+1, and so H ‚à©Gi+1 ‚úÅH ‚à©Gi. Finally, the second isomorphism
theorem gives
(H ‚à©Gi)/(H ‚à©Gi+1) = (H ‚à©Gi)/[(H ‚à©Gi) ‚à©Gi+1]
‚àº= Gi+1(H ‚à©Gi)/Gi+1.
But the last (quotient) group is a subgroup of Gi/Gi+1. Since the only subgroups of a
cyclic group C of prime order are C and {1}, it follows that the nontrivial factor groups
(H ‚à©Gi)/(H ‚à©Gi+1) are cyclic of prime order. Therefore, H is a solvable group.
‚Ä¢
Example 4.23.
In Example 4.19(ii), we showed that S4 is a solvable group. However, if n ‚â•5, the
symmetric group Sn is not a solvable group. If, on the contrary, Sn were solvable, then
so would each of its subgroups be solvable. But A5 ‚â§S5 ‚â§Sn, and A5 is not solvable
because it is a nonabelian simple group.
‚óÄ
Proposition 4.24.
If H ‚úÅG and if both H and G/H are solvable groups, then G is
solvable.
Proof.
Since G/H is solvable, there is a normal series
G/H ‚â•K ‚àó
1 ‚â•K ‚àó
2 ‚â•¬∑ ¬∑ ¬∑ K ‚àó
m = {1}

Sec. 4.1
Insolvability of the Quintic
215
having factor groups of prime order. By the correspondence theorem for groups, there are
subgroups Ki of G,
G ‚â•K1 ‚â•K2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Km = H,
with Ki/H = K ‚àó
i and Ki+1 ‚úÅKi for all i. By the third isomorphism theorem,
K ‚àó
i /K ‚àó
i+1 ‚àº= Ki/Ki+1
for all i, and so Ki/Ki+1 is cyclic of prime order for all i.
Since H is solvable, there is a normal series
H ‚â•H1 ‚â•H2 ‚â•¬∑ ¬∑ ¬∑ Hq = {1}
having factor groups of prime order. Splice these two series together,
G ‚â•K1 ‚â•K2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Km ‚â•H1 ‚â•H2 ‚â•¬∑ ¬∑ ¬∑ Hq = {1},
to obtain a normal series of G having factor groups of prime order.
‚Ä¢
Corollary 4.25.
If H and K are solvable groups, then H √ó K is solvable.
Proof.
Since (H √ó K)/H ‚àº= K, the result follows at once from Proposition 4.24.
‚Ä¢
We return to Ô¨Åelds, for we can now give the main criterion that a polynomial be solvable
by radicals.
Theorem 4.26 (Galois).
Let f (x) ‚ààk[x], where k is a Ô¨Åeld, and let E be a splitting
Ô¨Åeld of f (x) over k. If f (x) is solvable by radicals, then its Galois group Gal(E/k) is a
solvable group.
Remark.
The converse of this theorem is false if k has characteristic p > 0 (see Propo-
sition 4.56), but it is true when k has characteristic 0 (see Theorem 4.53).
‚óÄ
Proof.
In the proof of Lemma 4.20, we assumed that the ground Ô¨Åeld contained certain
pith roots of unity (the primes pi were types of pure extensions). DeÔ¨Åne m to be the
product of all these pi, deÔ¨Åne E‚àóto be a splitting Ô¨Åeld of xm ‚àí1 over E, and deÔ¨Åne
k‚àó= k($), where $ is the set of all mth roots of unity in E‚àó. Now E‚àóis a splitting Ô¨Åeld
of f (x) over k‚àó, and so Gal(E‚àó/k‚àó) is solvable, by Proposition 4.21.
E‚àó
E

k‚àó
k


216
Fields
Ch. 4
Consider the tower k ‚äÜk‚àó‚äÜE‚àó; we have Gal(E‚àó/k‚àó)‚úÅGal(E‚àó/k), by Theorem 4.16,
and
Gal(E‚àó/k)/ Gal(E‚àó/k‚àó) ‚àº= Gal(k‚àó/k).
Now Gal(E‚àó/k‚àó) is solvable, while Gal(k‚àó/k) is abelian, hence solvable, by Proposi-
tion 4.11; therefore, Gal(E‚àó/k) is solvable, by Proposition 4.24. Finally, we may use
Theorem 4.16 once again, for the tower k ‚äÜE ‚äÜE‚àósatisÔ¨Åes the hypothesis that both E
and E‚àóare splitting Ô¨Åelds of polynomials in k[x] [E‚àóis a splitting Ô¨Åeld of (xm ‚àí1) f (x)].
It follows that Gal(E‚àó/k)/ Gal(E‚àó/E) ‚àº= Gal(E/k), and so Gal(E/k) is solvable, for it is
a quotient of a solvable group.
‚Ä¢
Recall that if k is a Ô¨Åeld and E = k(y1, . . . , yn) = Frac(k[y1, . . . , yn]) is the Ô¨Åeld of
rational functions, then the general polynomial of degree n over k is
(x ‚àíy1)(x ‚àíy2) ¬∑ ¬∑ ¬∑ (x ‚àíyn).
Galois's theorem is strong enough to prove that there is no generalization of the quadratic
formula for the general quintic polynomial.
Theorem 4.27 (Abel-RufÔ¨Åni).
If n ‚â•5, the general polynomial of degree n
f (x) = (x ‚àíy1)(x ‚àíy2) ¬∑ ¬∑ ¬∑ (x ‚àíyn)
over a Ô¨Åeld k is not solvable by radicals.
Proof.
In Example 3.125, we saw that if E = k(y1, . . . , yn) is the Ô¨Åeld of all rational
functions in n variables with coefÔ¨Åcients in a Ô¨Åeld k, and if F = k(a0, . . . , an‚àí1), where
the ai are the coefÔ¨Åcients of f (x), then E is the splitting Ô¨Åeld of f (x) over F.
We claim that Gal(E/F) ‚àº= Sn. Exercise 3.47(i) on page 150 says that if A and R
are domains and œï : A ‚ÜíR is an isomorphism, then a/b ‚Üíœï(a)/œï(b) is an isomor-
phism Frac(A) ‚ÜíFrac(R). In particular, if œÉ ‚ààSn, then there is an automorphism œÉ of
k[y1, . . . , yn] deÔ¨Åned by œÉ : f (y1, . . . , yn) ‚Üíf (yœÉ1, . . . , yœÉn); that is, œÉ just permutes
the variables, and œÉ extends to an automorphism œÉ ‚àóof E = Frac(k[y1, . . . , yn]). Equa-
tions (1) on page 198 show that œÉ ‚àóÔ¨Åxes F, and so œÉ ‚àó‚ààGal(E/F). Using Lemma 4.2, it is
easy to see that œÉ ‚ÜíœÉ ‚àóis an injection Sn ‚ÜíGal(E/F), so that |Sn| ‚â§| Gal(E/F)|. On
the other hand, Theorem 4.3 shows that Gal(E/F) can be imbedded in Sn, giving the re-
verse inequality | Gal(E/F)| ‚â§|Sn|. Therefore, Gal(E/F) ‚àº= Sn. But Sn is not a solvable
group if n ‚â•5, by Example 4.23, and so Theorem 4.26 shows that f (x) is not solvable by
radicals.
‚Ä¢
We know that some quintics in Q[x] are solvable by radicals; for example, x5 ‚àí1 is
solvable by radicals, for its Galois group is abelian, by Proposition 4.11. On the other
hand, we can give speciÔ¨Åc quintics in Q[x] that are not solvable by radicals. For example,
f (x) = x5 ‚àí4x + 2 ‚ààQ[x] is not solvable by radicals, for it can be shown that its Galois
group is isomorphic to S5 (see Exercise 4.13 on page 218).

Sec. 4.1
Insolvability of the Quintic
217
EXERCISES
4.1 Given u, v ‚ààC, prove that there exist g, h ‚ààC with u = g + h and v = gh.
4.2 Show that the quadratic formula does not hold for ax2 + bx + c ‚ààk[x] when characteristic(k)
= 2.
4.3
(i) Find the roots of f (x) = x3 ‚àí3x + 1 ‚ààQ[x].
(ii) Find the roots of f (x) = x4 ‚àí2x2 + 8x ‚àí3 ‚ààQ[x].
4.4 Let f (x) ‚ààE[x], where E is a Ô¨Åeld, and let œÉ : E ‚ÜíE be an automorphism. If f (x) splits
and œÉ Ô¨Åxes every root of f (x), prove that œÉ Ô¨Åxes every coefÔ¨Åcient of f (x).
4.5 (Accessory Irrationalities) Let E/k be a splitting Ô¨Åeld of f (x) ‚ààk[x] with Galois group
G = Gal(E/k). Prove that if k‚àó/k is a Ô¨Åeld extension and E‚àóis a splitting Ô¨Åeld
E‚àó
E

k‚àó
k

of f (x) over k‚àó, then restriction, œÉ ‚ÜíœÉ|E, is an injective homomorphism
Gal(E‚àó/k‚àó) ‚ÜíGal(E/k).
Hint. If œÉ ‚ààGal(E‚àó/k‚àó), then œÉ permutes the roots of f (x), so that œÉ|E ‚ààGal(E/k).
4.6
(i) Let K/k be a Ô¨Åeld extension, and let f (x) ‚ààk[x] be a separable polynomial. Prove that
f (x) is a separable polynomial when viewed as a polynomial in K[x].
(ii) Let k be a Ô¨Åeld, and let f (x), g(x) ‚ààk[x]. Prove that if both f (x) and g(x) are separable
polynomials, then their product f (x)g(x) is also a separable polynomial.
4.7 Let k be a Ô¨Åeld and let f (x) ‚ààk[x] be a separable polynomial. If E/k is a splitting Ô¨Åeld of
f (x), prove that every root of f (x) in E is a separable element over k.
4.8 Let K/k be a Ô¨Åeld extension that is a splitting Ô¨Åeld of a polynomial f (x) ‚ààk[x]. If p(x) ‚àà
k[x] is a monic irreducible polynomial with no repeated roots, and if
p(x) = g1(x) ¬∑ ¬∑ ¬∑ gr(x)
in
K[x],
where the gi(x) are monic irreducible polynomials in K[x], prove that all the gi(x) have the
same degree. Conclude that deg(p) = r deg(gi).
Hint.
In some splitting Ô¨Åeld E/K of p(x) f (x), let Œ± be a root of gi(x) and Œ≤ be a root of
g j(x), where i Ã∏= j. There is an isomorphism œï : k(Œ±) ‚Üík(Œ≤) with œï(Œ±) = Œ≤, which Ô¨Åxes k
and which admits an extension to : E ‚ÜíE. Show that |K induces an automorphism of
K[x] taking gi(x) to g j(x).
4.9
(i) Give an example of a group G having a subnormal subgroup that is not a normal sub-
group.
(ii) Give an example of a group G having a subgroup that is not a subnormal subgroup.

218
Fields
Ch. 4
4.10 Prove that the following statements are equivalent for a quadratic f (x) = ax2 + bx + c ‚àà
Q[x].
(i) f (x) is irreducible in Q[x].
(ii)

b2 ‚àí4ac is not rational.
(iii) Gal(Q(

b2 ‚àí4ac), Q) has order 2.
4.11 Let k be a Ô¨Åeld, let f (x) ‚ààk[x] be a polynomial of degree p, where p is prime, and let E/k
be a splitting Ô¨Åeld. Prove that if Gal(E/k) ‚àº= Ip, then f (x) is irreducible.
Hint. Show that f (x) has no repeated roots.
4.12
(i) Prove that if œÉ is a 5-cycle and œÑ is a transposition, then S5 is generated by {œÉ, œÑ}.
Hint. Use Exercise 2.94(iii) on page 114.
(ii) Give an example showing that Sn, for some n, contains an n-cycle œÉ and a transposition
œÑ such that ‚ü®œÉ, œÑ‚ü©Ã∏= Sn.
4.13 Let f (x) = x5 ‚àí4x + 2 ‚ààQ[x] and let G be its Galois group.
(i) Assuming that f (x) is an irreducible polynomial, prove that |G| is a multiple of 5.
[We can prove that f (x) is irreducible using Eisenstein's criterion, Theorem 6.34 on
page 337.]
(ii) Prove that f (x) has three real roots and two complex roots, which are, of course, com-
plex conjugates. Conclude that if the Galois group G of f (x) is viewed as a subgroup of
S5, then G contains complex conjugation, which is a transposition of the roots of f (x).
(iii) Prove that G ‚àº= S5, and conclude that f (x) is not solvable by radicals.
Hint. Use Exercise 4.12.
4.2 FUNDAMENTAL THEOREM OF GALOIS THEORY
Galois theory analyzes the connection between algebraic extensions E of a Ô¨Åeld k and
the corresponding Galois groups Gal(E/k). This connection will enable us to prove the
converse of Galois's theorem: If k is a Ô¨Åeld of characteristic 0, and if f (x) ‚ààk[x] has
a solvable Galois group, then f (x) is solvable by radicals. The fundamental theorem of
algebra is also a consequence of this analysis.
We have already seen several theorems about Galois groups whose hypothesis involves
an extension being a splitting Ô¨Åeld of some polynomial. Let us begin by asking whether
there is some intrinsic property of an extension E/k that characterizes its being a splitting
Ô¨Åeld, without referring to any particular polynomial in k[x]. It turns out that the way to
understand splitting Ô¨Åelds E/k is to examine them in the context of both separability and
the action of the Galois group Gal(E/k) on E.
Let E be a Ô¨Åeld and let Aut(E) be the group of all (Ô¨Åeld) automorphisms of E. If k is
any subÔ¨Åeld of E, then Gal(E/k) is a subgroup of Aut(E), and so it acts on E. Whenever
a group acts on a set, we are interested in its orbits and stabilizers, but we now ask for those
elements of E stabilized by every œÉ in some subset H of Aut(E).
DeÔ¨Ånition.
If E is a Ô¨Åeld and H is a subset of Aut(E), then the Ô¨Åxed Ô¨Åeld of H is deÔ¨Åned
by
E H = {a ‚ààE : œÉ(a) = a for all œÉ ‚ààH}.

Sec. 4.2
Fundamental Theorem of Galois Theory
219
The most important instance of a Ô¨Åxed Ô¨Åeld E H arises when H is a subgroup of Aut(E),
but we will meet a case in which it is merely a subset.
It is easy to see that if œÉ ‚ààAut(E), then EœÉ = {a ‚ààE : œÉ(a) = a} is a subÔ¨Åeld of E;
it follows that E H is a subÔ¨Åeld of E, for
E H =
"
œÉ‚ààH
EœÉ.
In Example 3.125, we considered E = k(y1, . . . , yn), the rational function Ô¨Åeld in n
variables with coefÔ¨Åcients in a Ô¨Åeld k, and its subÔ¨Åeld K = k(a0, . . . , an‚àí1), where
f (x) = (x ‚àíy1)(x ‚àíy2) ¬∑ ¬∑ ¬∑ (x ‚àíyn) = a0 + a1x + ¬∑ ¬∑ ¬∑ + an‚àí1xn‚àí1 + xn
is the general polynomial of degree n over k. We saw that E is a splitting Ô¨Åeld of f (x)
over K, for it arises from K by adjoining to it all the roots of f (x), namely, all the y's.
Now the symmetric group Sn ‚â§Aut(E), for every permutation of y1, . . . , yn extends to an
automorphism of E, and it turns out that K = E Sn. The elements of K are usually called
the symmetric functions in n variables over k.
DeÔ¨Ånition.
A rational function g(x1, . . . , xn)/h(x1, . . . , xn) ‚ààk(x1, . . . , xn) is a sym-
metric function if it is unchanged by permuting its variables: For every œÉ ‚ààSn, we have
g(xœÉ1, . . . , xœÉn)/h(xœÉ1, . . . , xœÉn) = g(x1, . . . , xn)/h(x1, . . . , xn).
The various polynomials in Eqs. (1) on page 198 deÔ¨Åne examples of symmetric func-
tions; they are called the elementary symmetric functions.
The proof of the following proposition is almost obvious.
Proposition 4.28.
If E is a Ô¨Åeld, then the function H ‚ÜíE H, from subsets H of Aut(E)
to subÔ¨Åelds of E, is order-reversing: If H ‚â§L ‚â§Aut(E), then E L ‚äÜE H.
Proof.
If a ‚ààE L, then œÉ(a) = a for all œÉ ‚ààL. Since H ‚â§L, it follows, in particular,
that œÉ(a) = a for all œÉ ‚ààH. Hence, E L ‚äÜE H.
‚Ä¢
Example 4.29.
Suppose now that k is a subÔ¨Åeld of E and that G = Gal(E/k). It is obvious that k ‚äÜEG,
but the inclusion can be strict. For example, let E = Q(
3‚àö
2). If œÉ ‚ààG = Gal(E/Q),
then œÉ must Ô¨Åx Q, and so it permutes the roots of f (x) = x3 ‚àí2. But the other two roots
of f (x) are not real, so that œÉ(
3‚àö
2) =
3‚àö
2. It now follows from Lemma 4.2 that œÉ is the
identity; that is, EG = E. Note that E is not a splitting Ô¨Åeld of f (x).
‚óÄ
Our immediate goal is to determine the degree [E : EG], where G ‚â§Aut(E). To this
end, we introduce the notion of characters.

220
Fields
Ch. 4
DeÔ¨Ånition.
A character6 of a group G in a Ô¨Åeld E is a (group) homomorphism
œÉ : G ‚ÜíE√ó, where E√ó denotes the multiplicative group of nonzero elements of the
Ô¨Åeld E.
If œÉ ‚ààAut(E), then its restriction œÉ|E√ó : E√ó ‚ÜíE√ó is a character in E.
DeÔ¨Ånition.
If E is a Ô¨Åeld and G ‚â§Aut(E), then a list œÉ1, . . . , œÉn of characters of G in
E is independent if, whenever c1, . . . , cn ‚ààE and

i
ciœÉi(x) = 0
for all x ‚ààG,
then all the ci = 0.
In Example 3.82(iii), we saw that the set E X of all the functions from a set X to a Ô¨Åeld
E is a vector space over E, where addition of functions is deÔ¨Åned by
œÉ + œÑ : x ‚ÜíœÉ(x) + œÑ(x),
and scalar multiplication is deÔ¨Åned, for c ‚ààE, by
cœÉ : x ‚ÜícœÉ(x).
Independence of characters, as just deÔ¨Åned, is linear independence in the vector space E X
when X is the group G.
Proposition 4.30 (Dedekind).
Every list œÉ1, . . . , œÉn of distinct characters of a group G
in a Ô¨Åeld E is independent.
Proof.
The proof is by induction on n ‚â•1. The base step n = 1 is true, for if cœÉ(x) = 0
for all x ‚ààG, then either c = 0 or œÉ(x) = 0; but œÉ(x) Ã∏= 0, because im œÉ ‚äÜE√ó.
Assume that n > 1; if the characters are not independent, there are ci ‚ààE, not all zero,
with
c1œÉ1(x) + ¬∑ ¬∑ ¬∑ + cn‚àí1œÉn‚àí1(x) + cnœÉn(x) = 0
(2)
for all x ‚ààG. We may assume that all ci Ã∏= 0, or we may invoke the inductive hypothesis
and reach a contradiction, as desired. Multiplying by c‚àí1
n
if necessary, we may assume that
cn = 1. Since œÉn Ã∏= œÉ1, there exists y ‚ààG with œÉ1(y) Ã∏= œÉn(y). In Eq. (2), replace x by
yx to obtain
c1œÉ1(y)œÉ1(x) + ¬∑ ¬∑ ¬∑ + cn‚àí1œÉn‚àí1(y)œÉn‚àí1(x) + œÉn(y)œÉn(x) = 0,
6This deÔ¨Ånition is a special case of character in representation theory: If œÉ : G ‚ÜíGL(n, E) is a homomor-
phism, then its character œáœÉ : G ‚ÜíE is deÔ¨Åned, for x ‚ààG, by
œáœÉ (x) = trace(œÉ(x)),
where the trace of an n √ó n matrix is the sum of its diagonal entries. When n = 1, then GL(1, E) = E√ó and
œáœÉ (x) = œÉ(x) is called a linear character.

Sec. 4.2
Fundamental Theorem of Galois Theory
221
for œÉi(yx) = œÉi(y)œÉi(x). Now multiply this equation by œÉn(y)‚àí1 to obtain the equation
c1œÉn(y)‚àí1œÉ1(y)œÉ1(x) + ¬∑ ¬∑ ¬∑ + cn‚àí1œÉn(y)‚àí1œÉn‚àí1(y)œÉn‚àí1(x) + œÉn(x) = 0.
Subtract this last equation from Eq. (2) to obtain a sum of n ‚àí1 terms:
c1[1 ‚àíœÉn(y)‚àí1œÉ1(y)]œÉ1(x) + c2[1 ‚àíœÉn(y)‚àí1œÉ2(y)]œÉ2(x) + ¬∑ ¬∑ ¬∑ = 0.
By induction, each of the coefÔ¨Åcients ci[1 ‚àíœÉn(y)‚àí1œÉi(y)] = 0. Now ci Ã∏= 0, and so
œÉn(y)‚àí1œÉi(y) = 1 for all i < n. In particular, œÉn(y) = œÉ1(y), contradicting the deÔ¨Ånition
of y.
‚Ä¢
Lemma 4.31.
If G = {œÉ1, . . . , œÉn} is a set of n distinct automorphisms of a Ô¨Åeld E, then
[E : EG] ‚â•n.
Proof.
Suppose, on the contrary, that [E : EG] = r < n, and let Œ±1, . . . , Œ±r be a basis of
E/EG. Consider the homogeneous linear system over E of r equations in n unknowns:
œÉ1(Œ±1)x1 + ¬∑ ¬∑ ¬∑ + œÉn(Œ±1)xn = 0
œÉ1(Œ±2)x1 + ¬∑ ¬∑ ¬∑ + œÉn(Œ±2)xn = 0
...
...
...
œÉ1(Œ±r)x1 + ¬∑ ¬∑ ¬∑ + œÉn(Œ±r)xn = 0.
Since r < n, there are fewer equations than variables, and so there is a nontrivial solution
(c1, . . . , cn) in En.
We are now going to show that œÉ1(Œ≤)c1 + ¬∑ ¬∑ ¬∑ + œÉn(Œ≤)cn = 0 for any Œ≤ ‚ààE√ó, which
will contradict the independence of the characters œÉ1|E√ó, . . . , œÉn|E√ó. Since Œ±1, . . . , Œ±r is
a basis of E over EG, every Œ≤ ‚ààE can be written
Œ≤ =

biŒ±i,
where bi ‚ààEG. Multiply the ith row of the system by œÉ1(bi) to obtain the system with ith
row:
œÉ1(bi)œÉ1(Œ±i)c1 + ¬∑ ¬∑ ¬∑ + œÉ1(bi)œÉn(Œ±i)cn = 0.
But œÉ1(bi) = bi = œÉ j(bi) for all i, j, because bi ‚ààEG. Thus, the system has ith row:
œÉ1(biŒ±i)c1 + ¬∑ ¬∑ ¬∑ + œÉn(biŒ±i)cn = 0.
Adding all the rows gives
œÉ1(Œ≤)c1 + ¬∑ ¬∑ ¬∑ + œÉn(Œ≤)cn = 0,
which contradicts the independence of the characters œÉ1, . . . , œÉn.
‚Ä¢

222
Fields
Ch. 4
Proposition 4.32.
If G = {œÉ1, . . . , œÉn} is a subgroup of Aut(E), then
[E : EG] = |G|.
Proof.
In light of Lemma 4.31, it sufÔ¨Åces to prove [E : EG] ‚â§|G|. If, on the contrary,
[E : EG] > n, let {œâ1, . . . , œân+1} be a linearly independent list of vectors in E over EG.
Consider the system of n equations in n + 1 unknowns:
œÉ1(œâ1)x1 + ¬∑ ¬∑ ¬∑ + œÉ1(œân+1)xn+1 = 0
...
...
œÉn(œâ1)x1 + ¬∑ ¬∑ ¬∑ + œÉn(œân+1)xn+1 = 0.
There is a nontrivial solution (Œ±1, . . . , Œ±n+1) over E; we proceed to normalize it. Choose
a solution (Œ≤1, . . . , Œ≤r, 0, . . . , 0) having the smallest number r of nonzero components (by
reindexing the œâi, we may assume that all nonzero components come Ô¨Årst). Note that
r Ã∏= 1, lest œÉ1(œâ1)Œ≤1 = 0 imply Œ≤1 = 0. Multiplying by its inverse if necessary, we may
assume that Œ≤r = 1. Not all Œ≤i ‚ààEG, lest the row corresponding to œÉ = 1E violates
the linear independence of {œâ1, . . . , œân+1}. Our last assumption is that Œ≤1 does not lie
in EG (this, too, can be accomplished by reindexing the œâi). There thus exists œÉk with
œÉk(Œ≤1) Ã∏= Œ≤1. Since Œ≤r = 1, the original system has jth row
œÉ j(œâ1)Œ≤1 + ¬∑ ¬∑ ¬∑ + œÉ j(œâr‚àí1)Œ≤r‚àí1 + œÉ j(œâr) = 0.
(3)
Apply œÉk to this system to obtain
œÉkœÉ j(œâ1)œÉk(Œ≤1) + ¬∑ ¬∑ ¬∑ + œÉkœÉ j(œâr‚àí1)œÉk(Œ≤r‚àí1) + œÉkœÉ j(œâr) = 0.
Since G is a group, œÉkœÉ1, . . . , œÉkœÉn is just a permutation of œÉ1, . . . , œÉn. Setting œÉkœÉ j = œÉi,
the system has ith row
œÉi(œâ1)œÉk(Œ≤1) + ¬∑ ¬∑ ¬∑ + œÉi(œâr‚àí1)œÉk(Œ≤r‚àí1) + œÉi(œâr) = 0.
Subtract this from the ith row of Eq. (3) to obtain a new system with ith row:
œÉi(œâ1)[Œ≤1 ‚àíœÉk(Œ≤1)] + ¬∑ ¬∑ ¬∑ + œÉi(œâr‚àí1)[Œ≤r‚àí1 ‚àíœÉk(Œ≤r‚àí1)] = 0.
Since Œ≤1 ‚àíœÉk(Œ≤1) Ã∏= 0, we have found a nontrivial solution of the original system having
fewer than r nonzero components, a contradiction.
‚Ä¢
These ideas give a result needed in the proof of the fundamental theorem of Galois
theory.
Theorem 4.33.
If G and H are Ô¨Ånite subgroups of Aut(E) with EG = E H, then G = H.

Sec. 4.2
Fundamental Theorem of Galois Theory
223
Proof.
We Ô¨Årst show that if œÉ ‚ààAut(E), then œÉ Ô¨Åxes EG if and only if œÉ ‚ààG. Clearly,
œÉ Ô¨Åxes EG if œÉ ‚ààG. Suppose, conversely, that œÉ Ô¨Åxes EG but œÉ /‚ààG. If |G| = n, then
n = |G| = [E : EG],
by Proposition 4.32. Since œÉ Ô¨Åxes EG, we have EG ‚äÜEG‚à™{œÉ}. But the reverse inequality
always holds, by Proposition 4.28, so that EG = EG‚à™{œÉ}. Hence,
n = [E : EG] = [E : EG‚à™{œÉ}] ‚â•|G ‚à™{œÉ}| = n + 1,
by Lemma 4.31, giving the contradiction n ‚â•n + 1.
If œÉ ‚ààH, then œÉ Ô¨Åxes E H = EG, and hence œÉ ‚ààG; that is, H ‚â§G; the reverse
inclusion is proved the same way, and so H = G.
‚Ä¢
We can now give the characterization of splitting Ô¨Åelds we have been seeking.
Theorem 4.34.
If E/k is a Ô¨Ånite extension with Galois group G = Gal(E/k), then the
following statements are equivalent.
(i) E is a splitting Ô¨Åeld of some separable polynomial f (x) ‚ààk[x].
(ii) k = EG.
(iii) Every irreducible p(x) ‚ààk[x] having one root in E is separable and splits in E[x].
Proof.
(i) ‚áí(ii) By Theorem 4.7(ii), |G| = [E : k]. But Proposition 4.32 gives |G| =
[E : EG], so that
[E : k] = [E : EG].
Since k ‚â§EG, we have [E : k] = [E : EG][EG : k], so that [EG : k] = 1 and k = EG.
(ii) ‚áí(iii) Let p(x) ‚ààk[x] be an irreducible polynomial having a root Œ± in E, and let the
distinct elements of the set {œÉ(Œ±): œÉ ‚ààG} be Œ±1, . . . , Œ±n. DeÔ¨Åne g(x) ‚ààE[x] by
g(x) =

(x ‚àíŒ±i).
Now each œÉ ‚ààG permutes the Œ±i, so that each œÉ Ô¨Åxes each of the coefÔ¨Åcients of g(x);
that is, the coefÔ¨Åcients of g(x) lie in EG = k. Hence g(x) is a polynomial in k[x] having
no repeated roots. Now p(x) and g(x) have a common root in E, and so their gcd in
E[x] is not 1; it follows from Corollary 3.41 that their gcd is not 1 in k[x]. Since p(x) is
irreducible, it must divide g(x). Therefore, p(x) has no repeated roots, hence is separable,
and it splits over E.
(iii) ‚áí(i) Choose Œ±1 ‚ààE with Œ±1 Ã∏‚ààk. Since E/k is a Ô¨Ånite extension, Œ±1 must be
algebraic over k; let p1(x) = irr(Œ±1, k) ‚ààk[x] be its minimal polynomial. By hypothesis,
p1(x) is a separable polynomial that splits over E; let K1 ‚äÜE be its splitting Ô¨Åeld. If
K1 = E, we are done. Otherwise, choose Œ±2 ‚ààE with Œ±2 Ã∏‚ààK1. By hypothesis, there
is a separable irreducible p2(x) ‚ààk[x] having Œ±2 as a root. Let K2 ‚äÜE be the splitting
Ô¨Åeld of p1(x)p2(x), a separable polynomial. If K2 = E, we are done; otherwise, repeat
this construction. This process must end with Km = E for some m because E/k is Ô¨Ånite.
Thus, E is a splitting Ô¨Åeld of the separable polynomial p1(x) ¬∑ ¬∑ ¬∑ pm(x).
‚Ä¢

224
Fields
Ch. 4
DeÔ¨Ånition.
A Ô¨Åeld extension E/k is a Galois extension if it satisÔ¨Åes any of the equivalent
conditions in Theorem 4.34.
Example 4.35.
If E/k is a Ô¨Ånite separable extension, then the radical extension of E constructed in
Lemma 4.17 is a Galois extension.
‚óÄ
Corollary 4.36.
If E/k is a Galois extension and if B is an intermediate Ô¨Åeld, that is, a
subÔ¨Åeld B with k ‚äÜB ‚äÜE, then E/B is a Galois extension.
Proof.
We know that E is a splitting Ô¨Åeld of some separable polynomial f (x) ‚ààk[x];
that is, E = k(Œ±1, . . . , Œ±n), where Œ±1, . . . , Œ±n are the roots of f (x). Since k ‚äÜB ‚äÜE, we
have f (x) ‚ààB[x] and E = B(Œ±1, . . . , Œ±n).
‚Ä¢
Recall that the elementary symmetric functions of n variables are the polynomials, for
j = 1, . . . , n,
e j(x1, . . . , xn) =

i1<¬∑¬∑¬∑<i j
xi1 ¬∑ ¬∑ ¬∑ xi j .
If z1, . . . , zn are the roots of xn+an‚àí1xn‚àí1+¬∑ ¬∑ ¬∑+a0, then e j(z1, . . . , zn) = (‚àí1) jan‚àíj.
Theorem 4.37 (Fundamental Theorem of Symmetric Functions).
If k is a Ô¨Åeld, every
symmetric function in k(x1, . . . , xn) is a rational function in the elementary symmetric
functions e1, . . . , en.
Proof.
Let F be the smallest subÔ¨Åeld of E = k(x1, . . . , xn) containing the elementary
symmetric functions. As we saw in Example 3.125, E is the splitting Ô¨Åeld of the general
polynomial f (t) of degree n:
f (t) =
n

i=1
(t ‚àíxi).
As f (t) is a separable polynomial, E/F is a Galois extension. We saw, in the proof of
Theorem 4.27, the Abel-RufÔ¨Åni theorem, that Gal(E/F) ‚àº= Sn. Therefore, E Sn = F, by
Theorem 4.34. But to say that Œ∏(x) = g(x1, . . . , xn)/h(x1, . . . , xn) lies in E Sn is to say
that it is unchanged by permuting its variables; that is, Œ∏(x) is a symmetric function.
‚Ä¢
Exercise 6.84 on page 410 shows that every symmetric polynomial in k[x1, . . . , xn] lies
in k[e1, . . . , en].
DeÔ¨Ånition.
If A and B are subÔ¨Åelds of a Ô¨Åeld E, then their compositum, denoted by
A ‚à®B, is the intersection of all the subÔ¨Åelds of E that contain A ‚à™B.
It is easy to see that A ‚à®B is the smallest subÔ¨Åeld of E containing both A and B. For
example, if E/k is an extension with intermediate Ô¨Åelds A = k(Œ±1, . . . , Œ±n) and B =
k(Œ≤1, . . . , Œ≤m), then their compositum is
k(Œ±1, . . . , Œ±n) ‚à®k(Œ≤1, . . . , Œ≤m) = k(Œ±1, . . . , Œ±n, Œ≤1, . . . , Œ≤m).

Sec. 4.2
Fundamental Theorem of Galois Theory
225
Proposition 4.38.
(i) Every Galois extension E/k is a separable extension of k.
(ii) If E/k is an algebraic Ô¨Åeld extension and S ‚äÜE is any, possibly inÔ¨Ånite,7 set of
separable elements, then k(S)/k is a separable extension.
(iii) Let E/k be an algebraic extension, where k is a Ô¨Åeld, and let B and C be interme-
diate Ô¨Åelds. If both B/k and C/k are separable extensions, then their compositum
B ‚à®C is also a separable extension of k.
Proof.
(i) If Œ≤ ‚ààE, then p(x) = irr(Œ≤, k) ‚ààk[x] is an irreducible polynomial in k[x]
having a root in E. By Theorem 4.34(iii), p(x) is a separable polynomial (which splits in
E[x]). Therefore, Œ≤ is separable over k, and E/k is a separable extension.
(ii) Let us Ô¨Årst consider the case when S is Ô¨Ånite; that is, B = k(Œ±1, . . . , Œ±t) is a Ô¨Ånite
extension, where each Œ±i is separable over k. By Lemma 4.17(i), there is an extension E/B
that is a splitting Ô¨Åeld of some separable polynomial f (x) ‚ààk[x]; hence, E/k is a Galois
extension, by Theorem 4.34(i). By part (i) of this proposition, E/k is a separable extension;
that is, for all Œ± ‚ààE, the polynomial irr(Œ±, k) has no repeated roots. In particular, irr(Œ±, k)
has no repeated roots for all Œ± ‚ààB, and so B/k is a separable extension.
We now consider the general case. If Œ± ‚ààk(S), then Exercise 3.95 on page 197 says
that there are Ô¨Ånitely many elements Œ±1, . . . , Œ±n ‚ààS with Œ± ‚ààB = k(Œ±1, . . . , Œ±n). As
we have just seen, B/k is a separable extension, and so Œ± is separable over k. As Œ± is an
arbitrary element of k(S), it follows that k(S)/k is a separable extension.
(iii) Apply part (i) to the subset S = B ‚à™C, for B ‚à®C = k(B ‚à™C).
‚Ä¢
Query: If E/k is a Galois extension and B is an intermediate Ô¨Åeld, is B/k a Galois
extension? The answer is no; in Example 4.29, we saw that E = Q(
3‚àö
2, œâ) is a splitting
Ô¨Åeld of x3 ‚àí2 over Q, where œâ is a primitive cube root of unity, and so it is a Galois
extension. However, the intermediate Ô¨Åeld B = Q(
3‚àö
2) is not a Galois extension, for
x3 ‚àí2 is an irreducible polynomial having a root in B, yet it does not split in B[x].
The following proposition determines when an intermediate Ô¨Åeld B does give a Galois
extension.
DeÔ¨Ånition.
If E/k is a Galois extension and if B is an intermediate Ô¨Åeld, then a conjugate
of B is an intermediate Ô¨Åeld of the form
BœÉ = {œÉ(b) : b ‚ààB}
for some œÉ ‚ààGal(E/k).
7This result is true if Ô¨Ånitely many transcendental elements are adjoined (remember that transcendental el-
ements are always separable, by deÔ¨Ånition), but it may be false if inÔ¨Ånitely many transcendental elements are
adjoined.

226
Fields
Ch. 4
Proposition 4.39.
If E/k is a Galois extension, then an intermediate Ô¨Åeld B has no
conjugates other than B itself if and only if B/k is a Galois extension.
Proof.
Assume that BœÉ = B for all œÉ ‚ààG, where G = Gal(E/k). Let p(x) ‚ààk[x] be
an irreducible polynomial having a root Œ≤ in B. Since B ‚äÜE and E/k is Galois, p(x)
is a separable polynomial and it splits in E[x]. If Œ≤‚Ä≤ ‚ààE is another root of p(x), there
exists an isomorphism œÉ ‚ààG with œÉ(Œ≤) = Œ≤‚Ä≤ (for G acts transitively on the roots of an
irreducible polynomial, by Proposition 4.13). Therefore, Œ≤‚Ä≤ = œÉ(Œ≤) ‚ààBœÉ = B, so that
p(x) splits in B[x]. Therefore, B/k is a Galois extension.
Conversely, since B/k is a splitting Ô¨Åeld of some polynomial f (x) over k, we have
B = k(Œ±1, . . . , Œ±n), where Œ±1, . . . , Œ±n are all the roots of f (x). Since every œÉ ‚ààGal(E/k)
must permute the roots of f (x), it follows that œÉ must send B to itself.
‚Ä¢
We are now going to show, when E/k is a Galois extension, that the intermediate Ô¨Åelds
are classiÔ¨Åed by the subgroups of Gal(E/k).
We begin with some general deÔ¨Ånitions.
DeÔ¨Ånition.
A set X is a partially ordered set if it has a binary relation x ‚™Øy deÔ¨Åned on
it that satisÔ¨Åes, for all x, y, z ‚ààX,
(i) ReÔ¨Çexivity: x ‚™Øx;
(ii) Antisymmetry: If x ‚™Øy, and y ‚™Øx, then x = y;
(iii) Transitivity: If x ‚™Øy and y ‚™Øz, then x ‚™Øz.
An element c in a partially ordered set X is an upper bound of a, b ‚ààX if a ‚™Øc and
b ‚™Øc; an element d ‚ààX is a least upper bound of a, b if d is an upper bound and if d ‚™Øc
for every upper bound c of a and b. Lower bounds and greatest lower bounds are deÔ¨Åned
similarly, everywhere reversing the inequalities.
We will discuss partially ordered sets more thoroughly in the Appendix. Here, we are
more interested in special partially ordered sets called lattices.
DeÔ¨Ånition.
A lattice is a partially ordered set L in which every pair of elements a, b ‚ààL
has a greatest lower bound a ‚àßb and a least upper bound a ‚à®b.
Example 4.40.
(i) If U is a set, deÔ¨Åne L to be the family of all the subsets of U, and deÔ¨Åne A ‚™ØB to mean
A ‚äÜB. Then L is a lattice, where A ‚àßB = A ‚à©B and A ‚à®B = A ‚à™B.
(ii) If G is a group, deÔ¨Åne L = Sub(G) to be the family of all the subgroups of G, and
deÔ¨Åne A ‚™ØB to mean A ‚â§B; that is, A is a subgroup of B. Then L is a lattice, where
A ‚àßB = A ‚à©B and A ‚à®B is the subgroup generated by A ‚à™B.
(iii) If E/k is a Ô¨Åeld extension, deÔ¨Åne L = Int(E/k) to be the family of all the intermediate
Ô¨Åelds, and deÔ¨Åne K ‚™ØB to mean K ‚äÜB; that is, K is a subÔ¨Åeld of B. Then L is a lattice,
where K ‚àßB = K ‚à©B and K ‚à®B is the compositum of K and B.

Sec. 4.2
Fundamental Theorem of Galois Theory
227
(iv) If n is a positive integer, deÔ¨Åne Div(n) to be the set of all the positive divisors of
n. Then Div(n) is a partially ordered set if one deÔ¨Ånes d ‚™Ød‚Ä≤ to mean d | d‚Ä≤. Here,
d ‚àßd‚Ä≤ = gcd(d, d‚Ä≤) and d ‚à®d‚Ä≤ = lcm(d, d‚Ä≤).
‚óÄ
DeÔ¨Ånition.
If L and L‚Ä≤ are lattices, a function f : L ‚ÜíL‚Ä≤ is called order-reversing if
a ‚™Øb in L implies f (b) ‚™Øf (a) in L‚Ä≤.
Example 4.41.
There exist lattices L and L‚Ä≤ and an order-reversing bijection œï : L ‚ÜíL‚Ä≤ whose inverse
œï‚àí1 : L‚Ä≤ ‚ÜíL is not order-reversing. For example, consider the lattices
a







4
L
=
b
c
and
L‚Ä≤
=
3
d







2
1
The bijection œï : L ‚ÜíL‚Ä≤, deÔ¨Åned by
œï(a) = 1,
œï(b) = 2,
œï(c) = 3,
œï(d) = 4,
is an order-reversing bijection, but its inverse œï‚àí1 : L‚Ä≤ ‚ÜíL is not order-reversing, because
2 ‚™Ø3 but c = œï‚àí1(3) Ã∏‚™Øœï‚àí1(2) = b.
‚óÄ
The De Morgan laws say that if A and B are subsets of a set X, and if A‚Ä≤ denotes the
complement of A, then
(A ‚à©B)‚Ä≤ = A‚Ä≤ ‚à™B‚Ä≤
and
(A ‚à™B)‚Ä≤ = A‚Ä≤ ‚à©B‚Ä≤.
These identities are generalized in the next lemma.
Lemma 4.42.
Let L and L‚Ä≤ be lattices, and let œï : L ‚ÜíL‚Ä≤ be a bijection such that both
œï and œï‚àí1 are order-reversing. Then
œï(a ‚àßb) = œï(a) ‚à®œï(b)
and
œï(a ‚à®b) = œï(a) ‚àßœï(b).
Proof.
Since a, b ‚™Øa ‚à®b, we have œï(a ‚à®b) ‚™Øœï(a), œï(b); that is, œï(a ‚à®b) is a lower
bound of œï(a), œï(b). It follows that œï(a ‚à®b) ‚™Øœï(a) ‚àßœï(b).
For the reverse inequality, surjectivity of œï gives c ‚ààL with œï(a) ‚àßœï(b) = œï(c). Now
œï(c) = œï(a) ‚àßœï(b) ‚™Øœï(a), œï(b). Applying œï‚àí1, which is also order-reversing, we have
a, b ‚™Øc. Hence, c is an upper bound of a, b, so that a ‚à®b ‚™Øc. Therefore, œï(a ‚à®b) ‚™∞
œï(c) = œï(a) ‚àßœï(b). A similar argument proves the other half of the statement.
‚Ä¢

228
Fields
Ch. 4
Theorem 4.43 (Fundamental Theorem of Galois Theory).
Let E/k be a Ô¨Ånite Galois
extension with Galois group G = Gal(E/k).
(i) The function Œ≥ : Sub(Gal(E/k)) ‚ÜíInt(E/k), deÔ¨Åned by
Œ≥ : H ‚ÜíE H,
is an order-reversing bijection whose inverse, Œ¥ : Int(E/k) ‚ÜíSub(Gal(E/k)), is
the order-reversing bijection
Œ¥ : B ‚ÜíGal(E/B).
(ii) For every B ‚ààInt(E/k) and H ‚ààSub(Gal(E/k)),
EGal(E/B) = B
and
Gal(E/E H) = H.
(iii) For every H, K ‚ààSub(Gal(E/k)) and B, C ‚ààInt(E/k),
E H‚à®K = E H ‚à©E K ;
E H‚à©K = E H ‚à®E K ;
Gal(E/(B ‚à®C)) = Gal(E/B) ‚à©Gal(E/C);
Gal(E/(B ‚à©C)) = Gal(E/B) ‚à®Gal(E/C).
(iv) For every B ‚ààInt(E/k) and H ‚ààSub(Gal(E/k)),
[B : k] = [G : Gal(E/B)]
and
[G : H] = [E H : k].
(v) If B ‚ààInt(E/k), then B/k is a Galois extension if and only if Gal(E/B) is a normal
subgroup of G.
Proof.
(i) Proposition 4.28 proves that Œ≥ is order-reversing, and it is also easy to prove
that Œ¥ is order-reversing. Now injectivity of Œ≥ is proved in Theorem 4.33, so that Propo-
sition 1.47 shows that it sufÔ¨Åces to prove that Œ≥ Œ¥ : Int(E/k) ‚ÜíInt(E/k) is the iden-
tity; it will follow that Œ≥ is a bijection with inverse Œ¥.
If B is an intermediate Ô¨Åeld,
then Œ¥Œ≥ : B ‚ÜíEGal(E/B). But E/E B is a Galois extension, by Corollary 4.36, and so
EGal(E/B) = B, by Theorem 4.34.
(ii) This is just the statement that Œ≥ Œ¥ and Œ¥Œ≥ are identity functions.
(iii) These statements follow from Lemma 4.42.
(iv) By Theorem 4.7(ii) and the fact that E/B is a Galois extension,
[B : k] = [E : k]/[E : B] = |G|/| Gal(E/B)| = [G : Gal(E/B)].
Thus, the degree of B/k is the index of its Galois group in G. The second equation follows
from this one; take B = E H, noting that (ii) gives Gal(E/E H) = H:
[E H : k] = [G : Gal(E/E H)] = [G : H].

Sec. 4.2
Fundamental Theorem of Galois Theory
229
(v) It follows from Theorem 4.16 that Gal(E/B) ‚úÅG when B/k is a Galois extension
(both B/k and E/k are splitting Ô¨Åelds of polynomials in k[x]). For the converse, let
H = Gal(E/B), and assume that H ‚úÅG. Now E H = EGal(E/B) = B, by (ii), and so
it sufÔ¨Åces to prove that (E H)œÉ = E H for every œÉ ‚ààG, by Proposition 4.39. Suppose
now that a ‚ààE H; that is, Œ∑(a) = a for all Œ∑ ‚ààH. If œÉ ‚ààG, then we must show that
Œ∑(œÉ(a)) = œÉ(a) for all Œ∑ ‚ààH. Now H ‚úÅG says that if Œ∑ ‚ààH and œÉ ‚ààG, then there is
Œ∑‚Ä≤ ‚ààH with Œ∑œÉ = œÉŒ∑‚Ä≤ (of course, Œ∑‚Ä≤ = œÉ ‚àí1Œ∑œÉ). But
Œ∑œÉ(a) = œÉŒ∑‚Ä≤(a) = œÉ(a),
because Œ∑‚Ä≤(a) = a, as desired. Therefore, B/k = E H/k is Galois.
‚Ä¢
Here are some corollaries.
Theorem 4.44.
If E/k is a Galois extension whose Galois group is abelian, then every
intermediate Ô¨Åeld is a Galois extension.
Proof.
Every subgroup of an abelian group is a normal subgroup.
‚Ä¢
Corollary 4.45.
A Galois extension E/k has only Ô¨Ånitely many intermediate Ô¨Åelds.
Proof.
The Ô¨Ånite group Gal(E/k) has only Ô¨Ånitely many subgroups.
‚Ä¢
DeÔ¨Ånition.
A Ô¨Åeld extension E/k is a simple extension if there is u ‚ààE with E = k(u).
The following theorem of E. Steinitz characterizes simple extensions.
Theorem 4.46 (Steinitz).
A Ô¨Ånite extension E/k is simple if and only if it has only
Ô¨Ånitely many intermediate Ô¨Åelds.
Proof.
Assume that E/k is a simple extension, so that E = k(u); let p(x) = irr(u, k) ‚àà
k[x] be its minimal polynomial. If B is any intermediate Ô¨Åeld, let
q(x) = irr(u, B) = b0 + b1x + ¬∑ ¬∑ ¬∑ + bn‚àí1xn‚àí1 + xn ‚ààB[x]
be the monic irreducible polynomial of u over B, and deÔ¨Åne
B‚Ä≤ = k(b0, . . . , bn‚àí1) ‚äÜB.
Note that q(x) is an irreducible polynomial over the smaller Ô¨Åeld B‚Ä≤. Now
E = k(u) ‚äÜB‚Ä≤(u) ‚äÜB(u) ‚äÜE,
so that B‚Ä≤(u) = E = B(u). Hence, [E : B] = [B(u) : B] and [E : B‚Ä≤] = [B‚Ä≤(u) : B‚Ä≤].
But each of these is equal to deg(q), by Proposition 3.117(v), so that [E : B] = deg(q) =
[E : B‚Ä≤]. Since B‚Ä≤ ‚äÜB, it follows that [B : B‚Ä≤] = 1; that is,
B = B‚Ä≤ = k(b0, . . . , bn‚àí1).

230
Fields
Ch. 4
We have characterized B in terms of the coefÔ¨Åcients of q(x), a monic divisor of p(x) =
irr(u, k) in E[x]. But p(x) has only Ô¨Ånitely many monic divisors, and hence there are only
Ô¨Ånitely many intermediate Ô¨Åelds.
Conversely, assume that E/k has only Ô¨Ånitely many intermediate Ô¨Åelds. If k is a Ô¨Ånite
Ô¨Åeld, then we know that E/k is a simple extension (take u to be a primitive element);
therefore, we may assume that k is inÔ¨Ånite. Since E/k is a Ô¨Ånite extension, there are
elements u1, . . . , un with E = k(u1, . . . , un). By induction on n ‚â•1, it sufÔ¨Åces to prove
that E = k(a, b) is a simple extension. Now there are inÔ¨Ånitely many elements c ‚ààE of
the form c = a + tb, where t ‚ààk, for k is now inÔ¨Ånite. Since there are only Ô¨Ånitely many
intermediate Ô¨Åelds, there are, in particular, only Ô¨Ånitely many Ô¨Åelds of the form k(c). By
the pigeonhole principle,8 there exist distinct elements t, t‚Ä≤ ‚ààk with k(c) = k(c‚Ä≤), where
c‚Ä≤ = a + t‚Ä≤b. Clearly, k(c) ‚äÜk(a, b). For the reverse inclusion, the Ô¨Åeld k(c) = k(c‚Ä≤)
contains c ‚àíc‚Ä≤ = (t ‚àít‚Ä≤)b, so that b ‚ààk(c) (because t ‚àít‚Ä≤ Ã∏= 0). It follows that
a = c ‚àítb ‚ààk(c), and so k(c) = k(a, b).
‚Ä¢
An immediate consequence is that every Galois extension is simple; in fact, even more
is true.
Theorem 4.47 (Theorem of the Primitive Element).
If B/k is a Ô¨Ånite separable
extension, then there is u ‚ààB with B = k(u). In particular, if k has characteristic 0, then
every Ô¨Ånite extension B/k is a simple extension.
Proof.
By Example 4.35, the radical extension E/k constructed in Lemma 4.17 is a Ga-
lois extension having B as an intermediate Ô¨Åeld, so that Corollary 4.45 says that the exten-
sion E/k has only Ô¨Ånitely many intermediate Ô¨Åelds. It follows at once that the extension
B/k has only Ô¨Ånitely many intermediate Ô¨Åelds, and so Steinitz's theorem says that B/k
has a primitive element.
‚Ä¢
The theorem of the primitive element was known by Lagrange, and Galois used a mod-
iÔ¨Åcation of it in order to construct the original version of the Galois group.
We now turn to Ô¨Ånite Ô¨Åelds.
Theorem 4.48.
The Ô¨Ånite Ô¨Åeld Fq, where q = pn, has exactly one subÔ¨Åeld of order pd
for every divisor d of n, and no others.
Proof.
First, Fq/Fp is a Galois extension, for it is a splitting Ô¨Åeld of the separable poly-
nomial xq ‚àíx. Now G = Gal(Fq/Fp) is cyclic of order n, by Theorem 4.12. Since a
cyclic group of order n has exactly one subgroup of order d for every divisor d of n, by
Lemma 2.85, it follows that G has exactly one subgroup H of index n/d. Therefore, there
is only one intermediate Ô¨Åeld, namely, E H, with [E H : Fp] = [G : H] = n/d, and
E H = Fpn/d.
‚Ä¢
We now give two algebraic proofs of the fundamental theorem of algebra, proved by
Gauss (1799): The Ô¨Årst, due to P. Samuel (which he says is "by a method essentially due
8If there is an inÔ¨Ånite number of pigeons in only Ô¨Ånitely many pigeonholes, then at least one of the holes
contains an inÔ¨Ånite number of pigeons.

Sec. 4.2
Fundamental Theorem of Galois Theory
231
to Lagrange"), uses the fundamental theorem of symmetric functions; the second uses the
fundamental theorem of Galois theory, as well as a Sylow theorem which we will prove in
Chapter 5.
Assume that R satisÔ¨Åes a weak form of the intermediate value theorem: If f (x) ‚ààR[x]
and there exist a, b ‚ààR such that f (a) > 0 and f (b) < 0, then f (x) has a real root. Here
are some preliminary consequences.
(i) Every positive real number r has a real square root.
If f (x) = x2 ‚àír, then
f (1 + r) = (1 + r)2 ‚àír = 1 + r + r2 > 0,
and f (0) = ‚àír < 0.
(ii) Every quadratic g(x) ‚ààC[x] has a complex root.
First, every complex number z has a complex square root: When z is written in polar
form z = reiŒ∏, where r ‚â•0, then ‚àöz = ‚àöreiŒ∏/2. The quadratic formula gives the
(complex) roots of g(x).
(iii) The Ô¨Åeld C has no extensions of degree 2.
Such an extension would contain an element whose minimal polynomial is an irre-
ducible quadratic in C[x]; but Item (ii) shows that no such polynomial exists.
(iv) Every f (x) ‚ààR[x] having odd degree has a real root.
Let f (x) = a0 + a1x + ¬∑ ¬∑ ¬∑ + an‚àí1xn‚àí1 + xn ‚ààR[x]. DeÔ¨Åne t = 1 +  |ai|. Now
|ai| ‚â§t ‚àí1 for all i and, if h(x) = f (x) ‚àíxn, then
|h(t)| =
a0 + a1t + ¬∑ ¬∑ ¬∑ + an‚àí1tn‚àí1
‚â§(t ‚àí1)

1 + t + . . . + tn‚àí1
= tn ‚àí1
< tn.
Therefore, ‚àítn < h(t) and 0 = ‚àítn + tn < h(t) + tn = f (t).
A similar argument shows that |h(‚àít)| < tn, so that
f (‚àít) = h(‚àít) + (‚àít)n < tn + (‚àít)n.
When n is odd, (‚àít)n = ‚àítn, and so f (‚àít) < tn ‚àítn = 0. Therefore, the
intermediate value theorem provides a real number r with f (r) = 0; that is, f (x)
has a real root.
(v) There is no Ô¨Åeld extension E/R of odd degree > 1.
If u ‚ààE, then its minimal polynomial irr(u, R) must have even degree, by Item (iv),
so that [R(u) : R] is even. Hence [E : R] = [E : R(u)][R(u) : R] is even.

232
Fields
Ch. 4
Theorem 4.49 (Fundamental Theorem of Algebra).
If f (x) ‚ààC[x] has degree n ‚â•1,
then f (x) has a complex root, and hence f (x) splits: There are c, u1, . . . , un ‚ààC with
f (x) = c(x ‚àíu1) ¬∑ ¬∑ ¬∑ (x ‚àíun).
Proof.
We show that f (x) =  ai xi ‚ààC[x] has a complex root. DeÔ¨Åne f (x) =
 ai xi, where ai is the complex conjugate of ai. Now f (x) f (x) =  ckxk, where
ck = 
i+ j=k aia j; hence, ck = ck, so that f (x) f (x) ‚ààR[x]. If f (x) has a complex root
z, then z is a root of f (x) f (x). Conversely, if z is a complex root of f (x) f (x), then z is a
root of either f (x) or f (x). But if z is a root of f (x), then z is a root of f (x). Therefore,
f (x) has a complex root if and only if f (x) f (x) has a complex root, and so it sufÔ¨Åces to
prove that every real polynomial has a complex root.
To summarize, it sufÔ¨Åces to prove that every nonconstant monic f (x) ‚ààR[x] has a
complex root. Let deg( f ) = 2km, where m is odd; we prove the result by induction on
k ‚â•0. The base step k = 0 is proved in Item (iv), and so we may assume that k ‚â•1. Let
Œ±1, . . . , Œ±n be the roots of f (x) in some splitting Ô¨Åeld of f (x). For Ô¨Åxed t ‚ààR, deÔ¨Åne
gt(x) =

{i, j}
(x ‚àíŒ≤i j),
where Œ≤i j = Œ±i+Œ± j +tŒ±iŒ± j and {i, j} varies over all the two-element subsets of {1, . . . , n}.
First,
deg(gt) = 1
2n(n ‚àí1) = 2k‚àí1m(n ‚àí1).
Now n = 2km is even, because k ‚â•1, so that n ‚àí1 is odd; hence, m(n ‚àí1) is odd. Thus,
the inductive hypothesis will apply if gt(x) ‚ààR[x].
For each coefÔ¨Åcient c of gt(x), there is an elementary symmetric function
e(. . . , yi j, . . .) ‚ààR[. . . , yi j, . . .]
with c = e(. . . , Œ≤i j, . . .). If we deÔ¨Åne
h(x1, . . . , xn) = e(. . . , xi + x j + txi x j, . . .),
then
c = e(. . . , Œ±i + Œ± j + tŒ±iŒ± j, . . .) = h(Œ±1, . . . , Œ±n).
Each œÉ ‚ààSn acts on R[x1, . . . , xn] via œÉ : xi + x j + txi x j ‚ÜíxœÉi + xœÉ j + txœÉi xœÉ j, and
hence it permutes the set of polynomials of this form. Since the elementary symmetric
function e(. . . , yi j, . . .) is invariant under every permutation of the variables yi j, it follows
that h(x1, . . . , xn) = E(. . . , xi + x j + txi x j, . . .) is a symmetric function of x1, . . . , xn.
By the fundamental theorem of symmetric polynomials (Exercise 6.84 on page 410), there
is a polynomial œï(x) ‚ààR[x1, . . . , xn] with
h(x1, . . . , xn) = œï(e1(x1, . . . , xn), . . . , en(x1, . . . , xn)).

Sec. 4.2
Fundamental Theorem of Galois Theory
233
The evaluation (x1, . . . , xn) ‚Üí(Œ±1, . . . , Œ±n) gives
c = h(Œ±1, . . . , Œ±n) = œï(e1(Œ±1, . . . , Œ±n), . . . , en(Œ±1, . . . , Œ±n)).
But er(Œ±1, . . . , Œ±n) is just the rth coefÔ¨Åcient of f (x), which is real, and so c is real; that is,
gt(x) ‚ààR[x].
By induction, gt(x) has a complex root for each t ‚ààR. There are inÔ¨Ånitely many t ‚ààR
and only Ô¨Ånitely many two-element subsets {i, j}. By the pigeonhole principle, there exists
a subset {i, j} and distinct reals t and s with both Œ±i + Œ± j + tŒ±iŒ± j and Œ±i + Œ± j + sŒ±iŒ± j
complex [for the Œ≤i j are the roots of gt(x)]. Subtracting, (t ‚àís)Œ±iŒ± j ‚ààC; as t Ã∏= s, we
have Œ±iŒ± j ‚ààC; say, Œ±iŒ± j = u. Since Œ±i +Œ± j +tŒ±iŒ± j ‚ààC, it follows that Œ±i +Œ± j ‚ààC; say,
Œ±i + Œ± j = v. Therefore, Œ±i is a root of x2 ‚àívx + u, and the quadratic formula, Item (ii),
gives Œ±i ‚ààC, as desired. That f (x) splits now follows by induction on n ‚â•1.
‚Ä¢
Here is a second proof.
Theorem (Fundamental Theorem of Algebra).
Every nonconstant f (x) ‚ààC[x] has a
complex root.
Proof.
As in the proof just given, it sufÔ¨Åces to prove that every nonconstant f (x) ‚ààR[x]
has a complex root. Let E/R be a splitting Ô¨Åeld of (x2 + 1) f (x) that contains C. Since
R has characteristic 0, E/R is a Galois extension; let G = Gal(E/R) be its Galois group.
Now |G| = 2mk, where m ‚â•0 and k is odd. By the Sylow theorem (Theorem 5.36),
G has a subgroup H of order 2m; let B = E H be the corresponding intermediate Ô¨Åeld.
By the fundamental theorem of Galois theory, the degree [B : R] is equal to the index
[G : H] = k. But we have seen, in Item (v), that R has no extension of odd degree
greater than 1; hence k = 1 and G is a 2-group. Now E/C is also a Galois extension, and
Gal(E/C) ‚â§G is also a 2-group. If this group is nontrivial, then it has a subgroup K of
index 2. By the fundamental theorem once again, the intermediate Ô¨Åeld E K is an extension
of C of degree 2, and this contradicts Item (iii). We conclude that [E : C] = 1; that is,
E = C. But E is a splitting Ô¨Åeld of f (x) over C, and so f (x) has a complex root.
‚Ä¢
We now prove the converse of Galois's theorem (which holds only in characteristic 0):
Solvability of the Galois group implies solvability by radicals of the polynomial. It will
be necessary to prove that a certain Ô¨Åeld extension is a pure extension, and we will use the
norm (which arises quite naturally in algebraic number theory; for example, it was used in
the proof of Theorem 3.66, Fermat's two-squares theorem).
DeÔ¨Ånition.
If E/k is a Galois extension and u ‚ààE√ó, deÔ¨Åne its norm N(u) by
N(u) =

œÉ‚ààGal(E/k)
œÉ(u).
Here are some preliminary properties of the norm, whose simple proofs are left as ex-
ercises.
(i) If u ‚ààE√ó, then N(u) ‚ààk√ó (because N(u) ‚ààEG = k).

234
Fields
Ch. 4
(ii) N(uv) = N(u)N(v), so that N : E√ó ‚Üík√ó is a homomorphism.
(iii) If a ‚ààk, then N(a) = an, where n = [E : k].
(iv) If œÉ ‚ààG and u ‚ààE√ó, then N(œÉ(u)) = N(u).
Given a homomorphism, we ask about its kernel and image. The image of the norm is
not easy to compute; the next result (which was the ninetieth theorem in an 1897 exposition
of Hilbert on algebraic number theory) computes the kernel of the norm in a special case.
Theorem 4.50 (Hilbert's Theorem 90).
Let E/k be a Galois extension whose Galois
group G = Gal(E/k) is cyclic of order n, say, with generator œÉ. If u ‚ààE√ó, then N(u) = 1
if and only if there exists v ‚ààE√ó with u = vœÉ(v)‚àí1.
Proof.
If u = vœÉ(v)‚àí1, then
N(u) = N(vœÉ(v)‚àí1)
= N(v)N(œÉ(v)‚àí1)
= N(v)N(œÉ(v))‚àí1
= N(v)N(v)‚àí1 = 1.
Conversely, let N(u) = 1. DeÔ¨Åne "partial norms" in E√ó:
Œ¥0 = u,
Œ¥1 = uœÉ(u),
Œ¥2 = uœÉ(u)œÉ 2(u),
...
Œ¥n‚àí1 = uœÉ(u) ¬∑ ¬∑ ¬∑ œÉ n‚àí1(u).
Note that Œ¥n‚àí1 = N(u) = 1. It is easy to see that
uœÉ(Œ¥i) = Œ¥i+1 for all 0 ‚â§i ‚â§n ‚àí2.
(4)
By independence of the characters 1, œÉ, œÉ 2, . . . , œÉ n‚àí1, there exists y ‚ààE with
Œ¥0y + Œ¥1œÉ(y) + ¬∑ ¬∑ ¬∑ + Œ¥n‚àí2œÉ n‚àí2(y) + œÉ n‚àí1(y) Ã∏= 0;
call this sum z. Using Eq. (4), we easily check that
œÉ(z) = œÉ(Œ¥0)œÉ(y) + œÉ(Œ¥1)œÉ 2(y) + ¬∑ ¬∑ ¬∑ + œÉ(Œ¥n‚àí2)œÉ n‚àí1(y) + œÉ n(y)
= u‚àí1Œ¥1œÉ(y) + u‚àí1Œ¥2œÉ 2(y) + ¬∑ ¬∑ ¬∑ + u‚àí1Œ¥n‚àí1œÉ n‚àí1(y) + y
= u‚àí1
Œ¥1œÉ(y) + Œ¥2œÉ 2(y) + ¬∑ ¬∑ ¬∑ + Œ¥n‚àí1œÉ n‚àí1(y)

+ u‚àí1Œ¥0y
= u‚àí1z.
‚Ä¢

Sec. 4.2
Fundamental Theorem of Galois Theory
235
Corollary 4.51.
Let E/k be a Galois extension of prime degree p. If k contains a prim-
itive pth root of unity œâ, then E = k(z), where z p ‚ààk, and so E/k is a pure extension of
type p.
Proof.
The Galois group G = Gal(E/k) has order p, hence is cyclic; let œÉ be a generator.
Observe that N(œâ) = œâp = 1, because œâ ‚ààk. By Hilbert's Theorem 90, we have
œâ = zœÉ(z)‚àí1 for some z ‚ààE. Hence œÉ(z) = œâ‚àí1z. Thus, œÉ(z p) = (œâ‚àí1z)p = z p, and so
z p ‚ààEG, because œÉ generates G; since E/k is Galois, however, we have EG = k, so that
z p ‚ààk. Note that z Ã∏‚ààk, lest œâ = 1, so that k(z) Ã∏= k is an intermediate Ô¨Åeld. Therefore
E = k(z), because [E : k] = p is prime, and hence E has no proper intermediate Ô¨Åelds. ‚Ä¢
We confess that we have presented Hilbert's Theorem 90, not only because of its corol-
lary, which will be used to prove Galois's theorem, but also because it is a well-known
result that is an early instance of homological algebra (see Corollary 10.129). Here is an
elegant proof of Corollary 4.51 due to E. Houston (we warn the reader that it uses eigen-
values, a topic we have not yet introduced).
Proposition 4.52.
Let E/k be a Galois extension of prime degree p. If k contains a
primitive pth root of unity œâ, then E = k(z), where z p ‚ààk, and so E/k is a pure extension
of type p.
Proof.
Since E/k is a Galois extension of degree p, its Galois group G = Gal(E/k) has
order p, and hence it is cyclic: G = ‚ü®œÉ‚ü©. View E as a vector space over k. If a ‚ààk and
u ‚ààE, then œÉ(au) = œÉ(a)œÉ(u) = aœÉ(u), because œÉ ‚ààGal(E/k) (so that it Ô¨Åxes k), and
so we may view œÉ : E ‚ÜíE as a linear transformation. Now œÉ satisÔ¨Åes the polynomial
x p‚àí1, because œÉ p = 1E, by Lagrange's theorem. But œÉ satisÔ¨Åes no polynomial of smaller
degree, lest we contradict independence of the characters 1, œÉ, œÉ 2, . . . , œÉ p‚àí1. Therefore,
x p‚àí1 is the minimum polynomial of œÉ, and so every pth root of unity œâ is an eigenvalue of
œÉ. Since œâ‚àí1 ‚ààk, by hypothesis, there is some eigenvector z ‚ààE of œÉ with œÉ(z) = œâ‚àí1z
(note that z /‚ààk because it is not Ô¨Åxed by œÉ). Hence, œÉ(z p) = (œÉ(z))p = (œâ‚àí1)pz p = z p,
from which it follows that z p ‚ààEG = k. Now p = [E : k] = [E : k(z)][k(z) : k]; since
p is prime and [k(z) : k] Ã∏= 1, we have [E : k(z)] = 1; that is, E = k(z), and so E/k is a
pure extension.
‚Ä¢
Theorem 4.53 (Galois).
Let k be a Ô¨Åeld of characteristic 0, let E/k be a Galois exten-
sion, and let G = Gal(E/k) be a solvable group. Then E can be imbedded in a radical
extension of k.
Therefore, the Galois group of a polynomial over a Ô¨Åeld of characteristic 0 is a solvable
group if and only if the polynomial is solvable by radicals.
Remark.
A counterexample in characteristic p is given in Proposition 4.56.
‚óÄ
Proof.
Since G is solvable, it has a normal subgroup H of prime index, say, p. Let
œâ be a primitive pth root of unity, which exists in some extension Ô¨Åeld, because k has
characteristic 0. We distinguish two cases.

236
Fields
Ch. 4
Case (i): œâ ‚ààk.
We prove the statement by induction on [E : k]. The base step is obviously true, for
k = E is a radical extension of itself. For the inductive step, consider the intermediate Ô¨Åeld
E H. Now E/E H is a Galois extension, by Corollary 4.36, and Gal(E/E H) is solvable,
being a subgroup of the solvable group G. Since [E : E H] < [E : k], the inductive
hypothesis gives a radical tower E H ‚äÜR1 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜRt, where E ‚äÜRt. Now E H/k
is a Galois extension, because H ‚úÅG, and its index [G : H] = p = [E H : k], by the
fundamental theorem. Corollary 4.51 (or Proposition 4.52) now applies to give E H = k(z),
where z p ‚ààk; that is, E H/k is a pure extension. Hence, the radical tower above can be
lengthened by adding the preÔ¨Åx k ‚äÜE H, thus displaying Rt/k as a radical extension.
Case (ii): General case.
Let k‚àó= k(œâ), and deÔ¨Åne E‚àó= E(œâ). We claim that E‚àó/k is a Galois extension.
Since E/k is a Galois extension, it is the splitting Ô¨Åeld of some separable f (x) ‚ààk[x],
and so E‚àóis a splitting Ô¨Åeld over k of f (x)(x p ‚àí1). But x p ‚àí1 is separable, because
k has characteristic 0, and so E‚àó/k is a Galois extension. Therefore, E‚àó/k‚àóis also a
Galois extension, by Corollary 4.36. Let G‚àó= Gal(E‚àó/k‚àó). By Exercise 4.5 on page 217,
accessory irrationalities, there is an injection œà : G‚àó‚ÜíG = Gal(E/k), so that G‚àóis
solvable, being isomorphic to a subgroup of a solvable group. Since œâ ‚ààk‚àó, the Ô¨Årst case
says that there is a radical tower k‚àó‚äÜR‚àó
1 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜR‚àó
m with E ‚äÜE‚àó‚äÜR‚àó
m. But k‚àó= k(œâ)
is a pure extension, so that this last radical tower can be lengthened by adding the preÔ¨Åx
k ‚äÜk‚àó, thus displaying R‚àó
m/k as a radical extension.
‚Ä¢
We now have another proof of the existence of the classical formulas.
Corollary 4.54.
If k has characteristic 0, then every f (x) ‚ààk[x] with deg( f ) ‚â§4 is
solvable by radicals.
Proof.
If G is the Galois group of f (x), then G is isomorphic to a subgroup of S4. But
S4 is a solvable group, and so every subgroup of S4 is also solvable. By Galois's theorem,
f (x) is solvable by radicals.
‚Ä¢
Suppose we know the Galois group G of a polynomial f (x) ‚ààQ[x] and that G is
solvable. Can we use this information to Ô¨Ånd the roots of f (x)? The answer is afÔ¨Årmative;
we suggest the reader look at the book by Gaal, Classical Galois Theory with Examples,
to see how this is done.
In 1827, N. H. Abel proved that if the Galois group of a polynomomial f (x) is commu-
tative, then f (x) is solvable by radicals (of course, Galois groups had not yet been deÔ¨Åned).
This result was superseded by Galois's theorem, proved in 1830, but it is the reason why
abelian groups are so called.
A deep theorem of W. Feit and J. G. Thompson (1963) says that every group of odd
order is solvable. It follows that if k is a Ô¨Åeld of characteristic 0 and f (x) ‚ààk[x] is a
polynomial whose Galois group has odd order, equivalently, whose splitting Ô¨Åeld has odd
degree over k, then f (x) is solvable by radicals.

Sec. 4.2
Fundamental Theorem of Galois Theory
237
The next proposition gives an example showing that the converse of Galois's theorem
is false in prime characteristic.
Lemma 4.55.
If k = Fp(t), the Ô¨Åeld of rational functions over Fp, then f (x) = x p‚àíx‚àít
has no roots in k.
Proof.
If there is a root Œ± of f (x) lying in k, then there are g(t), h(t) ‚ààFp[t] with
Œ± = g(t)/h(t); we may assume that (g, h) = 1. Since Œ± is a root of f (x), we have
(g/h)p ‚àí(g/h) = t; clearing denominators, there is an equation g p ‚àíh p‚àí1g = th p in
Fp[t]. Hence, g | th p. Since (g, h) = 1, we have g | t, so that g(t) = at or g(t) is a
constant, say, g(t) = b, where a, b ‚ààFp. Transposing h p‚àí1g in the displayed equation
shows that h | g p; but (g, h) = 1 forces h to be a constant. We conclude that if Œ± = g/h,
then Œ± = at or Œ± = b. In the Ô¨Årst case,
0 = Œ± p ‚àíŒ± ‚àít
= (at)p ‚àí(at) ‚àít
= a pt p ‚àíat ‚àít
= at p ‚àíat ‚àít
by Fermat's theorem in Fp
= t(at p‚àí1 ‚àía ‚àí1).
It follows that at p‚àí1 ‚àía ‚àí1 = 0. But a Ã∏= 0, and this contradicts t being transcendental
over Fp. In the second case, Œ± = b ‚ààFp. But b is not a root of f (x), for f (b) =
bp ‚àíb ‚àít = ‚àít, by Fermat's theorem. Thus, no root Œ± of f (x) can lie in k.
‚Ä¢
Proposition 4.56.
Let p be a prime, and let k = Fp(t). The Galois group of f (x) =
x p ‚àíx ‚àít over k is cyclic of order p, but f (x) is not solvable by radicals over k.
Proof.
Let Œ± be a root of f (x). It is easy to see that the roots of f (x) are Œ± + i, where
0 ‚â§i < p, for Fermat's theorem gives i p = i in Fp, and so
(Œ± + i)p ‚àí(Œ± + i) ‚àít = Œ± p + i p ‚àíŒ± ‚àíi ‚àít = Œ± p ‚àíŒ± ‚àít = 0.
It follows that f (x) is a separable polynomial and that k(Œ±) is a splitting Ô¨Åeld of f (x)
over k. We claim that f (x) is irreducible in k[x]. Suppose that f (x) = g(x)h(x), where
g(x) = xd + cd‚àí1xd‚àí1 + ¬∑ ¬∑ ¬∑ + c0 ‚ààk[x]
and 0 < d < deg( f ) = p; then g(x) is a product of d factors of the form Œ± + i.
Now ‚àícd‚àí1 ‚ààk is the sum of the roots: ‚àícd‚àí1 = dŒ± + j, where j ‚ààFp, and so
dŒ± ‚ààk. Since 0 < d < p, however, d Ã∏= 0 in k, and this forces Œ± ‚ààk, contradicting the
lemma. Therefore, f (x) is an irreducible polynomial in k[x]. Since deg( f ) = p, we have
[k(Œ±) : k] = p and, since f (x) is separable, we have | Gal(k(Œ±)/k)| = [k(Œ±) : k] = p.
Therefore, Gal(k(Œ±)/k) ‚àº= Ip.
It will be convenient to have certain roots of unity available. Let $ be the set of all
qth roots of unity, where q < p is a prime divisor of p!. We claim that Œ± /‚ààk($). On

238
Fields
Ch. 4
the one hand, if n = 
q<p q, then $ is contained in the splitting Ô¨Åeld of xn ‚àí1, and so
[k($) : k] | n!, by Theorem 4.3. It follows that p ‚à§[k($) : k]. On the other hand, if
Œ± ‚ààk($), then k(Œ±) ‚äÜk($) and [k($) : k] = [k($) : k(Œ±)][k(Œ±) : k] = p[k($) : k(Œ±)].
Hence, p | [k($) : k], and this is a contradiction.
If f (x) were solvable by radicals over k($), there would be a radical extension
k($) = B0 ‚äÜB1 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜBr
with k($, Œ±) ‚äÜBr. We may assume, for each i ‚â•1, that Bi/Bi‚àí1 is of prime type;
that is, Bi = Bi‚àí1(ui), where uqi
i
‚ààBi‚àí1 and qi is prime. There is some j ‚â•1 with
Œ± ‚ààB j but Œ± /‚ààB j‚àí1. Simplifying notation, we set u j = u, q j = q, B j‚àí1 = B,
and B j = B‚Ä≤. Thus, B‚Ä≤ = B(u), uq = b ‚ààB, Œ± ‚ààB‚Ä≤, and Œ±, u /‚ààB. We claim
that f (x) = x p ‚àíx ‚àít, which we know to be irreducible in k[x], is also irreducible in
B[x]. By accessory irrationalities, Exercise 4.5 on page 217, restriction gives an injection
Gal(B(Œ±)/B) ‚ÜíGal(k(Œ±)/k)) ‚àº= Ip. If Gal(B(Œ±)/B) = {1}, then B(Œ±) = B and
Œ± ‚ààB, a contradiction. Therefore, Gal(B(Œ±)/B) ‚àº= Ip, and f (x) is irreducible in B[x],
by Exercise 4.11 on page 218.
Since u /‚ààB‚Ä≤ and B contains all the qth roots of unity, Proposition 3.126 shows that
xq ‚àíb is irreducible in B[x], for it does not split in B[x]. Now B‚Ä≤ = B(u) is a splitting
Ô¨Åeld of xq ‚àíb, and so [B‚Ä≤ : B] = q. We have B ‚ääB(Œ±) ‚äÜB‚Ä≤, and
q = [B‚Ä≤ : B] = [B‚Ä≤ : B(Œ±)][B(Œ±) : B].
Since q is prime, [B‚Ä≤ : B(Œ±)] = 1; that is, B‚Ä≤ = B(Œ±), and so q = [B‚Ä≤ : B]. As Œ± is a root
of the irreducible polynomial f (x) = x p ‚àíx ‚àít ‚ààB[x], we have [B(Œ±) : B] = p; there-
fore, q = p. Now B(u) = B‚Ä≤ = B(Œ±) is a separable extension, by Proposition 4.38, for
Œ± is a separable element. It follows that u ‚ààB‚Ä≤ is also a separable element, contradicting
irr(u, B) = xq ‚àíb = x p ‚àíb = (x ‚àíu)p having repeated roots.
We have shown that f (x) is not solvable by radicals over k($). It follows that f (x) is
not solvable by radicals over k, for if there were a radical extension k = R0 ‚äÜR1 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜ
Rt with k(Œ±) ‚äÜRt, then k($) = R0($) ‚äÜR1($) ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜRt($) would show that f (x)
is solvable by radicals over k($), a contradiction.
‚Ä¢
The discriminant of a polynomial is useful in computing its Galois group.
DeÔ¨Ånition.
If f (x) = 
i(x ‚àíŒ±i) ‚ààk[x], where k is a Ô¨Åeld, deÔ¨Åne
 =

i< j
(Œ±i ‚àíŒ± j),
and deÔ¨Åne the discriminant to be D = D( f ) = 2 = 
i< j(Œ±i ‚àíŒ± j)2.
It is clear that f (x) has repeated roots if and only if its discriminant D = 0.
The product  = 
i< j(Œ±i ‚àíŒ± j) has one factor Œ±i ‚àíŒ± j for each distinct pair of indices
(i, j) (the restriction i < j prevents a pair of indices from occurring twice). If E/k is a
splitting Ô¨Åeld of f (x) and if G = Gal(E/k), then each œÉ ‚ààG permutes the roots, and so

Sec. 4.2
Fundamental Theorem of Galois Theory
239
œÉ permutes all the distinct pairs. However, it may happen that i < j while the subscripts
involved in œÉ(Œ±i) ‚àíœÉ(Œ± j) are in reverse order. For example, suppose the roots of a cubic
are Œ±1, Œ±2, and Œ±3, and suppose there is œÉ ‚ààG with œÉ(Œ±1) = Œ±2, œÉ(Œ±2) = Œ±1, and
œÉ(Œ±3) = Œ±3. Then
œÉ() =

œÉ(Œ±1) ‚àíœÉ(Œ±2)

œÉ(Œ±1) ‚àíœÉ(Œ±3)

œÉ(Œ±2) ‚àíœÉ(Œ±3)

= (Œ±2 ‚àíŒ±1)(Œ±2 ‚àíŒ±3)(Œ±1 ‚àíŒ±3)
= ‚àí(Œ±1 ‚àíŒ±2)(Œ±2 ‚àíŒ±3)(Œ±1 ‚àíŒ±3)
= ‚àí.
In general, each term Œ±i ‚àíŒ± j occurs in œÉ() with a possible sign change. We conclude,
for all œÉ ‚ààGal(E/k), that œÉ() = ¬±. It is natural to consider 2 rather than , for
 depends not only on the roots of f (x), but also on the order in which they are listed,
whereas D = 2 does not depend on the listing of the roots. For a connection between
discriminants and the alternating group An, see Proposition 4.59(ii) on page 241.
Proposition 4.57.
If f (x) ‚ààk[x] is a separable polynomial, then its discriminant D lies
in k.
Proof.
Let E/k be a splitting Ô¨Åeld of f (x); since f (x) is separable, Theorem 4.34 applies
to show that E/k is a Galois extension. Each œÉ ‚ààGal(E/k) permutes the roots u1, . . . , un
of f (x), and œÉ() = ¬±, as we have just seen. Therefore,
œÉ(D) = œÉ(2) = œÉ()2 = (¬±)2 = D,
so that D ‚ààEG. Since E/k is a Galois extension, we have EG = k, and so D ‚ààk.
‚Ä¢
If f (x) = x2 + bx + c, then the quadratic formula gives the roots of f (x):
Œ± = 1
2

‚àíb +
‚àö
b2 ‚àí4c

and
Œ≤ = 1
2

‚àíb ‚àí
‚àö
b2 ‚àí4c

.
It follows that
D = 2 = (Œ± ‚àíŒ≤)2 = b2 ‚àí4c.
If f (x) is a cubic with roots Œ±, Œ≤, Œ≥ , then
D = 2 = (Œ± ‚àíŒ≤)2(Œ± ‚àíŒ≥ )2(Œ≤ ‚àíŒ≥ )2;
it is not obvious how to compute the discriminant D from the coefÔ¨Åcients of f (x).
DeÔ¨Ånition.
A polynomial f (x) = xn+cn‚àí1xn‚àí1+¬∑ ¬∑ ¬∑+c0 ‚ààk[x] is reduced if cn‚àí1 = 0.
If f (x) is a monic polynomial of degree n and if cn‚àí1 Ã∏= 0 in k, where char(k) = 0, then
its associated reduced polynomial is
f (x) = f (x ‚àí1
n cn‚àí1).
If f (x) = xn + cn‚àí1xn‚àí1 + ¬∑ ¬∑ ¬∑ + c0 ‚ààk[x] and Œ≤ ‚ààk is a root of f (x), then
0 = f (Œ≤) = f (Œ≤ ‚àí1
n cn‚àí1).
Hence, Œ≤ is a root of f (x) if and only if Œ≤ ‚àí1
n cn‚àí1 is a root of f (x).

240
Fields
Ch. 4
Theorem 4.58.
Let k be a Ô¨Åeld of characteristic 0.
(i) A polynomial f (x) ‚ààk[x] and its associated reduced polynomial f (x) have the
same discriminant.
(ii) The discriminant of a reduced cubic f (x) = x3 + qx + r is
D = ‚àí4q3 ‚àí27r2.
Proof.
(i) If the roots of f (x) =  ci xi are Œ±1, . . . , Œ±n, then the roots of f (x) are
Œ≤1,. . .,Œ≤n, where Œ≤i = Œ±i + 1
n cn‚àí1. Therefore, Œ≤i ‚àíŒ≤ j = Œ±i ‚àíŒ± j for all i, j,

i< j
(Œ±i ‚àíŒ± j) =

i< j
(Œ≤i ‚àíŒ≤ j),
and so the discriminants, which are the squares of these, are equal.
(ii) The cubic formula gives the roots of f (x) as
Œ± = g + h,
Œ≤ = œâg + œâ2h,
and
Œ≥ = œâ2g + œâh,
where g =
 1
2

‚àír +
‚àö
R
1/3, h = ‚àíq/3g, R = r2 + 4
27q3, and œâ is a cube root of unity.
Because œâ3 = 1, we have
Œ± ‚àíŒ≤ = (g + h) ‚àí(œâg + œâ2h)
= (g ‚àíœâ2h) ‚àí(œâg ‚àíh)
= (g ‚àíœâ2h) ‚àí(g ‚àíœâ2h)œâ
= (g ‚àíœâ2h)(1 ‚àíœâ).
Similar calculations give
Œ± ‚àíŒ≥ = (g + h) ‚àí(œâ2g + œâh) = (g ‚àíœâh)(1 ‚àíœâ2)
and
Œ≤ ‚àíŒ≥ = (œâg + œâ2h) ‚àí(œâ2g + œâh) = (g ‚àíh)œâ(1 ‚àíœâ).
It follows that
 = (g ‚àíh)(g ‚àíœâh)(g ‚àíœâ2h)œâ(1 ‚àíœâ2)(1 ‚àíœâ)2.
By Exercise 4.14 on page 246, we have œâ(1‚àíœâ2)(1‚àíœâ)2 = 3i
‚àö
3; moreover, the identity
x3 ‚àí1 = (x ‚àí1)(x ‚àíœâ)(x ‚àíœâ2),
with x = g/h, gives
(g ‚àíh)(g ‚àíœâh)(g ‚àíœâ2h) = g3 ‚àíh3 =
‚àö
R
(we saw on page 208 that g3 ‚àíh3 =
‚àö
R). Therefore,  = 3i
‚àö
3
‚àö
R, and
D = 2 = ‚àí27R = ‚àí27r2 ‚àí4q3.
‚Ä¢

Sec. 4.2
Fundamental Theorem of Galois Theory
241
Remark.
Let k be a Ô¨Åeld, and let f (x) = amxm + am‚àí1xm‚àí1 + ¬∑ ¬∑ ¬∑ + a1x + a0 and
g(x) = bnxn + bn‚àí1xn‚àí1 + ¬∑ ¬∑ ¬∑ + b1x + b0 ‚ààk[x]. Their resultant is deÔ¨Åned as
Res( f, g) = det(M),
where M = M( f, g) is the (m + n) √ó (m + n) matrix
M =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
am
am‚àí1
¬∑ ¬∑ ¬∑
a1
a0
am
am‚àí1
¬∑ ¬∑ ¬∑
a1
a0
am
am‚àí1
¬∑ ¬∑ ¬∑
a1
a0
¬∑ ¬∑ ¬∑
bn
bn‚àí1
¬∑ ¬∑ ¬∑
b1
b0
bn
bn‚àí1
¬∑ ¬∑ ¬∑
b1
b0
bn
bn‚àí1
¬∑ ¬∑ ¬∑
b1
b0
¬∑ ¬∑ ¬∑
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
;
there are n rows for the coefÔ¨Åcients ai of f (x) and m rows for the coefÔ¨Åcients b j of
g(x); all the entries other than those shown are assumed to be 0. It can be proved that
Res( f, g) = 0 if and only if f and g have a nonconstant common divisor. We mention the
resultant here because the discriminant can be computed in terms of it:
D( f ) = (‚àí1)n(n‚àí1)/2Res( f, f ‚Ä≤),
where f ‚Ä≤(x) is the derivative of f (x). See the exercises in Dummit and Foote, Abstract
Algebra, pages 600-602.
‚óÄ
Here is a way to use the discriminant in computing Galois groups.
Proposition 4.59.
Let k be a Ô¨Åeld with characteristic Ã∏= 2, let f (x) ‚ààk[x] be a polyno-
mial of degree n with no repeated roots, and let D = 2 be its discriminant. Let E/k be
a splitting Ô¨Åeld of f (x), and let G = Gal(E/k) be regarded as a subgroup of Sn (as in
Theorem 4.3).
(i) If H = An ‚à©G, then E H = k().
(ii) G is a subgroup of An if and only if
‚àö
D ‚ààk.
Proof.
(i) The second isomorphism theorem gives H = (G ‚à©An) ‚úÅG and
[G : H] = [G : An ‚à©G] = [AnG : An] ‚â§[Sn : An] = 2.
By the fundamental theorem of Galois theory (which applies because f (x) has no repeated
roots, hence is separable), [E H : k] = [G : H], so that [E H : k] = [G : H] ‚â§2. By
Exercise 4.25 on page 248, we have k() ‚äÜE An, and so k() ‚äÜE H. Therefore,
[E H : k] = [E H : k()][k() : k] ‚â§2.
(5)

242
Fields
Ch. 4
There are two cases. If [E H : k] = 1, then each factor in Eq. (5) is 1; in particular,
[E H : k()] = 1 and E H = k(). If [E H : k] = 2, then [G : H] = 2 and there
exists œÉ ‚ààG, œÉ Ã∏‚ààAn, so that œÉ() = ‚àí. Now  Ã∏= 0, because f (x) has no repeated
roots, and ‚àí Ã∏= , because k does not have characteristic 2. Hence,  Ã∏‚ààEG = k and
[k() : k] > 1. It follows from Eq. (5) that [E H : k()] = 1 and E H = k().
(ii) The following are equivalent: G ‚â§An; H = G ‚à©An = G; E H = EG = k. Since
E H = k(), by part (i), E H = k is equivalent to k() = k; that is,  =
‚àö
D ‚ààk.
‚Ä¢
We now show how to compute Galois groups of polynomials over Q of low degree.
If f (x) ‚ààQ[x] is quadratic, then its Galois group has order either 1 or 2 (because the
symmetric group S2 has order 2). The Galois group has order 1 if f (x) splits; it has order 2
if f (x) does not split; that is, if f (x) is irreducible.
If f (x) ‚ààQ[x] is a cubic having a rational root, then its Galois group G is the same as
that of its quadratic factor. Otherwise f (x) is irreducible; since |G| is now a multiple of 3,
by Corollary 4.9, and G ‚â§S3, it follows that either G ‚àº= A3 ‚àº= I3 or G ‚àº= S3.
Proposition 4.60.
Let f (x) ‚ààQ[x] be an irreducible cubic with Galois group G and
discriminant D.
(i) f (x) has exactly one real root if and only if D < 0, in which case G ‚àº= S3.
(ii) f (x) has three real roots if and only if D > 0. In this case, either
‚àö
D ‚ààQ and
G ‚àº= I3, or
‚àö
D Ã∏‚ààQ and G ‚àº= S3.
Proof.
Note Ô¨Årst that D Ã∏= 0: Since Q has characteristic 0, irreducible polynomials over
Q have no repeated roots. If f (x) has three real roots, then  is real and D = 2 > 0.
The other possibility is that f (x) has one real root Œ± and two complex roots: Œ≤ = u + iv
and Œ≤ = u ‚àíiv. Since Œ≤ ‚àíŒ≤ = 2iv and Œ± = Œ±, we have
 = (Œ± ‚àíŒ≤)(Œ± ‚àíŒ≤)(Œ≤ ‚àíŒ≤)
= (Œ± ‚àíŒ≤)(Œ± ‚àíŒ≤)(Œ≤ ‚àíŒ≤)
= |Œ± ‚àíŒ≤|2(2iv),
and so D = 2 = ‚àí4v2|Œ± ‚àíŒ≤|4 < 0.
Let E/Q be the splitting Ô¨Åeld of f (x). If f (x) has exactly one real root Œ±, then E Ã∏=
Q(Œ±). Hence |G| > 3 and G ‚àº= S3. If f (x) has three real roots, then D > 0 and
‚àö
D is
real. By Proposition 4.59(ii), G ‚àº= A3 ‚àº= I3 if and only if
‚àö
D is rational; hence G ‚àº= S3 if
‚àö
D is irrational.
‚Ä¢
Example 4.61.
The polynomial f (x) = x3 ‚àí2 ‚ààQ[x] is irreducible, by Theorem 3.43. Its discriminant
is D = ‚àí108, and so it has one real root; since
‚àö
‚àí108 /‚ààQ (it is not even real), the Galois
group of f (x) is not contained in A3. Thus, the Galois group is S3.

Sec. 4.2
Fundamental Theorem of Galois Theory
243
The polynomial x3 ‚àí4x + 2 ‚ààQ[x] is irreducible, by Theorem 3.43 or by Eisenstein's
criterion; its discriminant is D = 148, and so it has 3 real roots. Since
‚àö
148 is irrational,
the Galois group is S3.
The polynomial f (x) = x3 ‚àí48x + 64 ‚ààQ[x] is irreducible, by Theorem 3.43; the
discriminant is D = 21234, and so f (x) has 3 real roots. Since
‚àö
D is rational, the Galois
group is A3 ‚àº= I3.
‚óÄ
Before examining quartics, let us note that if d is a divisor of |S4| = 24, then it is known
that S4 has a subgroup of order d (see Exercise 5.23 on page 277). If d = 4, then V and
I4 are nonisomorphic subgroups of order d; for any other divisor d, any two subgroups of
order d are isomorphic. We conclude that the Galois group G of a quartic is determined to
isomorphism by its order unless |G| = 4.
Consider a (reduced) quartic f (x) = x4 +qx2 +rx +s ‚ààQ[x]; let E/Q be its splitting
Ô¨Åeld and let G = Gal(E/Q) be its Galois group. [By Exercise 4.15 on page 246, there is
no loss in generality in assuming that f (x) is reduced.] If f (x) has a rational root Œ±, then
f (x) = (x ‚àíŒ±)c(x), and its Galois group is the same as that of the cubic factor c(x); but
Galois groups of cubics have already been discussed. Suppose that f (x) = h(x)‚Ñì(x) is the
product of two irreducible quadratics; let Œ± be a root of h(x) and let Œ≤ be a root of ‚Ñì(x). If
Q(Œ±) ‚à©Q(Œ≤) = Q, then Exercise 4.17(iv) on page 246 shows that G ‚àº= V, the four group;
otherwise, Œ± ‚ààQ(Œ≤), so that Q(Œ≤) = Q(Œ±, Œ≤) = E, and G has order 2.
We are left with the case f (x) irreducible. The basic idea now is to compare G with the
four group V, namely, the normal subgroup of S4
V =

(1), (1 2)(3 4), (1 3)(2 4), (1 4)(2 3)

,
so that we can identify the Ô¨Åxed Ô¨Åeld of V ‚à©G. If the four (necessarily distinct) roots of
f (x) are Œ±1, Œ±2, Œ±3, Œ±4, consider the numbers [which are distinct, by Proposition 4.63(ii)]:
Ô£±
Ô£¥Ô£≤
Ô£¥Ô£≥
u = (Œ±1 + Œ±2)(Œ±3 + Œ±4),
v = (Œ±1 + Œ±3)(Œ±2 + Œ±4),
w = (Œ±1 + Œ±4)(Œ±2 + Œ±3).
(6)
It is clear that if œÉ ‚ààV ‚à©G, then œÉ Ô¨Åxes u, v, and w. Conversely, if œÉ ‚ààS4 Ô¨Åxes
u = (Œ±1 + Œ±2)(Œ±3 + Œ±4), then
œÉ ‚ààV ‚à™

(1 2), (3 4), (1 3 2 4), (1 4 2 3)

.
However, none of the last four permutations Ô¨Åxes both v and w, and so œÉ ‚ààG Ô¨Åxes each
of u, v, w if and only if œÉ ‚ààV ‚à©G. Therefore,
EV‚à©G = Q(u, v, w).
DeÔ¨Ånition.
The resolvent cubic of f (x) = x4 + qx2 + rx + s is
g(x) = (x ‚àíu)(x ‚àív)(x ‚àíw),
where u, v, w are the numbers deÔ¨Åned in Eqs. (6).

244
Fields
Ch. 4
Proposition 4.62.
The resolvent cubic of f (x) = x4 + qx2 + rx + s is
g(x) = x3 ‚àí2qx2 + (q2 ‚àí4s)x + r2.
Proof.
If f (x) = (x2 + jx + ‚Ñì)(x2 ‚àíjx + m), then we saw, in our discussion of the
quartic formula on page 209, that j2 is a root of
h(x) = x3 + 2qx2 + (q2 ‚àí4s)x ‚àír2,
a polynomial differing from the claimed expression for g(x) only in the sign of its quadratic
and constant terms. Thus, a number Œ≤ is a root of h(x) if and only if ‚àíŒ≤ is a root of g(x).
Let the four roots Œ±1, Œ±2, Œ±3, Œ±4 of f (x) be indexed so that Œ±1, Œ±2 are roots of x2+ jx+‚Ñì
and Œ±3, Œ±4 are roots of x2‚àíjx+m. Then j = ‚àí(Œ±1+Œ±2) and ‚àíj = ‚àí(Œ±3+Œ±4); therefore,
u = (Œ±1 + Œ±2)(Œ±3 + Œ±4) = ‚àíj2
and ‚àíu is a root of h(x) since h( j2) = 0.
Now factor f (x) into two quadratics, say,
f (x) = (x2 + Àújx + Àú‚Ñì)(x2 ‚àíÀújx + Àúm),
where Œ±1, Œ±3 are roots of the Ô¨Årst factor and Œ±2, Œ±4 are roots of the second. The same
argument as before now shows that
v = (Œ±1 + Œ±3)(Œ±2 + Œ±4) = ‚àíÀúj2;
hence ‚àív is a root of h(x). Similarly, ‚àíw = ‚àí(Œ±1 + Œ±4)(Œ±2 + Œ±3) is a root of h(x).
Therefore,
h(x) = (x + u)(x + v)(x + w),
and so
g(x) = (x ‚àíu)(x ‚àív)(x ‚àíw)
is obtained from h(x) by changing the sign of the quadratic and constant terms.
‚Ä¢
Proposition 4.63.
(i) The discriminant D( f ) of a quartic polynomial f (x) ‚ààQ[x] is equal to the dis-
criminant D(g) of its resolvent cubic g(x).
(ii) If f (x) is irreducible, then g(x) has no repeated roots.
Proof.
(i) One checks easily that
u ‚àív = Œ±1Œ±3 + Œ±2Œ±4 ‚àíŒ±1Œ±2 ‚àíŒ±3Œ±4 = ‚àí(Œ±1 ‚àíŒ±4)(Œ±2 ‚àíŒ±3).
Similarly,
u ‚àíw = ‚àí(Œ±1 ‚àíŒ±3)(Œ±2 ‚àíŒ±4)
and
v ‚àíw = (Œ±1 ‚àíŒ±2)(Œ±3 ‚àíŒ±4).
We conclude that D(g) = [(u ‚àív)(u ‚àíw)(v ‚àíw)]2 =

‚àí
i< j(Œ±i ‚àíŒ± j)
2 = D( f ).
(ii) If f (x) is irreducible, then it has no repeated roots (for it is separable because Q has
characteristic 0), and so D( f ) Ã∏= 0. Therefore, D(g) = D( f ) Ã∏= 0, and so g(x) has no
repeated roots.
‚Ä¢

Sec. 4.2
Fundamental Theorem of Galois Theory
245
In the notation of Eqs. (6), if f (x) is an irreducible quartic, then u, v, w are distinct.
Proposition 4.64.
Let f (x) ‚ààQ[x] be an irreducible quartic with Galois group G with
discriminant D, and let m be the order of the Galois group of its resolvent cubic g(x).
(i) If m = 6, then G ‚àº= S4. In this case, g(x) is irreducible and
‚àö
D is irrational.
(ii) If m = 3, then G ‚àº= A4. In this case, g(x) is irreducible and
‚àö
D is rational.
(iii) If m = 1, then G ‚àº= V. In this case, g(x) splits in Q[x].
(iv) If m = 2, then G ‚àº= D8 or G ‚àº= I4. In this case, g(x) has an irreducible quadratic
factor.
Proof.
We have seen that EV‚à©G = Q(u, v, w). By the fundamental theorem of Galois
theory,
[G : V ‚à©G] = [EV‚à©G : Q]
= [Q(u, v, w) : Q]
= | Gal(Q(u, v, w)/Q)|
= m.
Since f (x) is irreducible, |G| is divisible by 4, by Corollary 4.9, and the group-theoretic
statements follow from Exercise 4.28 on page 248 and Exercise 4.29 on page 248. Finally,
in the Ô¨Årst two cases, |G| is divisible by 12, and Proposition 4.59(ii) decides whether
G ‚àº= S4 or G ‚àº= A4. The conditions on g(x) in the last two last two cases are easy to
see.
‚Ä¢
We have seen that the resolvent cubic has much to say about the Galois group of the
irreducible quartic from which it comes.
Example 4.65.
(i) Let f (x) = x4 ‚àí4x + 2 ‚ààQ[x]; f (x) is irreducible [the best way to see this is with
Eisenstein's criterion, Theorem 6.34, but we can also see that f (x) has no rational roots,
using Theorem 3.43, and then showing that f (x) has no irreducible quadratic factors by
examining conditions imposed on its coefÔ¨Åcients]. By Proposition 4.62, the resolvent cubic
is
g(x) = x3 ‚àí8x + 16.
Now g(x) is irreducible (again, the best way to see this uses some results of Chapter 6:
speciÔ¨Åcally, Theorem 6.30, for if we reduce mod 5, we obtain x3 + 2x + 1, and this poly-
nomial is irreducible over I5 because it has no roots). The discriminant of g(x) is ‚àí4864,
so that Theorem 4.60 shows that the Galois group of g(x) is S3, hence has order 6. Theo-
rem 4.64 now shows that G ‚àº= S4.
(ii) Let f (x) = x4 ‚àí10x2 + 1 ‚ààQ[x]; f (x) is irreducible, by Exercise 6.23(viii) on
page 339. By Proposition 4.62, the resolvent cubic is
x3 + 20x2 + 96x = x(x + 8)(x + 12).

246
Fields
Ch. 4
In this case, Q(u, v, w) = Q and m = 1. Therefore, G ‚àº= V. [This should not be a surprise
if we recall Example 3.122, where we saw that f (x) arises as the irreducible polynomial
of Œ± =
‚àö
2 +
‚àö
3, where Q(Œ±) = Q(
‚àö
2,
‚àö
3).]
‚óÄ
An interesting open question is the inverse Galois problem: Which Ô¨Ånite abstract
groups G are isomorphic to Gal(E/Q), where E/Q is a Galois extension? D. Hilbert
proved that the symmetric groups Sn are such Galois groups, and I. Shafarevich proved
that every solvable group is a Galois group (see Neukirch-Schmidt-Wingberg, Cohomol-
ogy of Number Fields). After the classiÔ¨Åcation of the Ô¨Ånite simple groups in the 1980s, it
was shown that most simple groups are Galois groups. For more information, the reader is
referred to Malle-Matzat, Inverse Galois Theory.
EXERCISES
4.14 Prove that œâ(1 ‚àíœâ2)(1 ‚àíœâ)2 = 3i
‚àö
3, where œâ = e2œÄi/3.
4.15
(i) Prove that if a Ã∏= 0, then f (x) and af (x) have the same discriminant and the same
Galois group. Conclude that it is no loss in generality to restrict attention to monic
polynomials when computing Galois groups.
(ii) Let k be a Ô¨Åeld of characteristic 0. Prove that a polynomial f (x) ‚ààk[x] and its associ-
ated reduced polynomial f (x) have the same Galois group.
4.16
(i) Let k be a Ô¨Åeld of characteristic 0. If f (x) = x3 + ax2 + bx + c ‚ààk[x], then its
associated reduced polynomial is x3 + qx + r, where
q = b ‚àí1
3a2
and
r = 2
27a3 ‚àí1
3ab + c.
(ii) Show that the discriminant of f (x) is
D = a2b2 ‚àí4b3 ‚àí4a3c ‚àí27c2 + 18abc.
4.17 Let k be a Ô¨Åeld, let f (x) ‚ààk[x] be a separable polynomial, and let E/k be a splitting Ô¨Åeld of
f (x). Assume further that there is a factorization
f (x) = g(x)h(x)
in k[x], and that B/k and C/k are intermediate Ô¨Åelds that are splitting Ô¨Åelds of g(x) and h(x),
respectively.
(i) Prove that Gal(E/B) and Gal(E/C) are normal subgroups of Gal(E/k).
(ii) Prove that Gal(E/B) ‚à©Gal(E/C) = {1}.
(iii) If B ‚à©C = k, prove that Gal(E/B) Gal(E/C) = Gal(E/k). (Intermediate Ô¨Åelds B and
C are called linearly disjoint if B ‚à©C = k.)
(iv) Use Proposition 2.80 and Theorem 4.16 to show, in this case, that
Gal(E/k) ‚àº= Gal(B/k) √ó Gal(C/k).
(Note that Gal(B/k) is not a subgroup of Gal(E/k).)
(v) Use (iv) to give another proof that Gal(E/Q) ‚àº= V, where E = Q(
‚àö
2 +
‚àö
3) [see
Example 3.122 on page 190].

Sec. 4.2
Fundamental Theorem of Galois Theory
247
(vi) Let f (x) = (x3 ‚àí2)(x3 ‚àí3) ‚ààQ[x]. If B/Q and C/Q are the splitting Ô¨Åelds of x3 ‚àí2
and x3 ‚àí3 inside C, prove that Gal(E/Q) Ã∏‚àº= Gal(B/Q) √ó Gal(C/Q), where E is the
splitting Ô¨Åeld of f (x) contained in C.
4.18 Let k be a Ô¨Åeld of characteristic 0, and let f (x) ‚ààk[x] be a polynomial of degree 5 with
splitting Ô¨Åeld E/k. Prove that f (x) is solvable by radicals if and only if [E : k] < 60.
4.19
(i) If L and L‚Ä≤ are lattices, a function f : L ‚ÜíL‚Ä≤ is called order-preserving if a ‚™Øb in
L implies f (a) ‚™Øf (b) in L‚Ä≤. Prove that if L and L‚Ä≤ are lattices and œï : L ‚ÜíL‚Ä≤ is a
bijection such that both œï and œï‚àí1 are order-preserving, then
œï(a ‚àßb) = œï(a) ‚àßœï(b)
and
œï(a ‚à®b) = œï(a) ‚à®œï(b).
Hint. Adapt the proof of Lemma 4.42.
(ii) Let E/k be a Galois extension with Gal(E/k) cyclic of order n. Prove that
œï : Int(E/k) ‚ÜíDiv(n),
[see Example 4.40(iv)] deÔ¨Åned by œï(L) = [L : k], is an order-preserving lattice iso-
morphism.
(iii) Prove that if L and K are subÔ¨Åelds of Fpn, then
[L ‚à®K : Fp] = lcm

[L : Fp], [K : Fp]

and
[L ‚à©K : Fp] = gcd

[L : Fp], [K : Fp]

.
4.20 Find all Ô¨Ånite Ô¨Åelds k whose subÔ¨Åelds form a chain; that is, if k‚Ä≤ and k‚Ä≤‚Ä≤ are subÔ¨Åelds of k, then
either k‚Ä≤ ‚äÜk‚Ä≤‚Ä≤ or k‚Ä≤‚Ä≤ ‚äÜk‚Ä≤.
4.21
(i) Let k be an inÔ¨Ånite Ô¨Åeld, let f (x) ‚ààk[x] be a separable polynomial, and let E =
k(Œ±1, . . . , Œ±n), where Œ±1, . . . , Œ±n are the roots of f (x). Prove that there are ci ‚ààk so
that E = k(Œ≤), where Œ≤ = c1Œ±1 + ¬∑ ¬∑ ¬∑ + cnŒ±n.
Hint. Use the proof of Steinitz's theorem.
(ii) (Janusz). Let k be a Ô¨Ånite Ô¨Åeld and let E = k(Œ±, Œ≤). Prove that if k(Œ±) and k(Œ≤) are
linearly disjoint [that is, if k(Œ±) ‚à©k(Œ≤) = k], then E = k(Œ± + Œ≤). (This result is false in
general. For example, N. Boston used the computer algebra system MAGMA to show
that there is a primitive element Œ± of F26 and a primitive element Œ≤ of F210 such that
F2(Œ±, Œ≤) = F230 while F2(Œ± + Œ≤) = F215.)
Hint. Use Exercise 4.19(iii) and Exercise 1.26 on page 13.
4.22 Let E/k be a Galois extension with Galois group G = Gal(E/k). DeÔ¨Åne the trace T : E ‚ÜíE
by
T (u) =

œÉ‚ààG
œÉ(u).
(i) Prove that im T ‚äÜk and that T (u + v) = T (u) + T (v) for all u, v ‚ààE.
(ii) Use independence of characters to prove that T is not identically zero.
4.23 Let E/k be a Galois extension with [E : k] = n and with cyclic Galois group G = Gal(E/k),
say, G = ‚ü®œÉ‚ü©.
(i) DeÔ¨Åne œÑ = œÉ ‚àí1E, and prove that ker T = ker œÑ.
Hint. Show that ker œÑ = k, so that dim(im œÑ) = n ‚àí1 = dim(ker T ).

248
Fields
Ch. 4
(ii) Trace Theorem: Prove that if E/k is a Galois extension with cyclic Galois group
Gal(E/k) = ‚ü®œÉ‚ü©, then
ker T = {a ‚ààE : a = œÉ(u) ‚àíu for some u ‚ààE}.
4.24 Let k be a Ô¨Åeld of characteristic p > 0, and let E/k be a Galois extension having a cyclic
Galois group G = ‚ü®œÉ‚ü©of order p. Using the trace theorem, prove that there is an element u ‚àà
E with œÉ(u)‚àíu = 1. Prove that E = k(u) and that there is c ‚ààk with irr(u, k) = x p ‚àíx ‚àíc.
4.25 If œÉ ‚ààSn and f (x1, . . . , xn) ‚ààk[x1, . . . , xn], where k is a Ô¨Åeld, deÔ¨Åne
(œÉ f )(x1, . . . , xn) = f (xœÉ1, . . . , xœÉn).
(i) Prove that (œÉ, f (x1, . . . , xn) ‚ÜíœÉ f deÔ¨Ånes an action of Sn on k[x1, . . . , xn].
(ii) Let  = (x1, . . . , xn) = 
i< j(xi ‚àíx j) (on page 239, we saw that œÉ = ¬± for all
œÉ ‚ààSn). If œÉ ‚ààSn, prove that œÉ ‚ààAn if and only if œÉ = .
Hint. DeÔ¨Åne œï : Sn ‚ÜíG, where G is the multiplicative group {1, ‚àí1}, by
œï(œÉ) =

1
if œÉ = ;
‚àí1
if œÉ = ‚àí.
Prove that œï is a homomorphism, and that ker œï = An.
4.26 Prove that if f (x) ‚ààQ[x] is an irreducible quartic whose discriminant is rational, then its
Galois group has order 4 or 12.
4.27 Let f (x) = x4 + rx + s ‚ààQ[x] have Galois group G.
(i) Prove that the discriminant of f (x) is ‚àí27r4 + 256s3.
(ii) Prove that if s < 0, then G is not isomorphic to a subgroup of A4.
(iii) Prove that f (x) = x4 + x + 1 is irreducible and that G ‚àº= S4.
4.28 Let G be a subgroup of S4 with |G| a multiple of 4, and deÔ¨Åne m = |G/(G ‚à©V)|.
(i) Prove that m is a divisor of 6.
(ii) If m = 6, then G = S4; if m = 3, then G = A4; if m = 1, then G = V; if m = 2, then
G ‚àº= D8, G ‚àº= I4, or G ‚àº= V.
4.29 Let G be a subgroup of S4. If G acts transitively on X = {1, 2, 3, 4} and |G/(V ‚à©G)| = 2,
then G ‚àº= D8 or G ‚àº= I4. [If we merely assume that G acts transitively on X, then |G| is a
multiple of 4 (Corollary 4.9). The added hypothesis |G/(V ‚à©G)| = 2 removes the possibility
G ‚àº= V when m = 2 in Exercise 4.28.]
4.30 Compute the Galois group over Q of x4 + x2 ‚àí6.
4.31 Compute the Galois group over Q of f (x) = x4 + x2 + x + 1.
Hint.
Use Example 3.35(ii) to prove irreducility of f (x), and prove irreducibility of the
resolvent cubic by reducing mod 2.
4.32 Compute the Galois group over Q of f (x) = 4x4 + 12x + 9.
Hint.
Prove that f (x) is irreducible in two steps: First show that it has no rational roots,
and then use Descartes's method (on page 209) to show that f (x) is not the product of two
quadratics over Q.

5
Groups II
We now seek some structural information about groups. Finite abelian groups turn out to
be rather uncomplicated: They are direct sums of cyclic groups. Returning to nonabelian
groups, the Sylow theorems show, for any prime p, that Ô¨Ånite groups G have subgroups of
order pe, where pe is the largest power of p dividing |G|, and any two such are isomorphic.
The ideas of normal series and solvability that arose in Galois theory yield invariants of
groups (the Jordan-H¬®older theorem), showing that simple groups are, in a certain sense,
building blocks of Ô¨Ånite groups. Consequently, we display more examples of simple groups
to accompany the alternating groups An, for n ‚â•5, which we have already proved to be
simple. This chapter concludes by investigating free groups and presentations, for they are
useful in constructing and describing arbitrary groups. The chapter ends with a proof that
every subgroup of a free group is itself a free group.
5.1 FINITE ABELIAN GROUPS
We continue our study of groups by classifying all Ô¨Ånite abelian groups; as is customary,
we use the additive notation for the binary operation in these groups. We are going to prove
that every Ô¨Ånite abelian group is a direct sum of cyclic groups and that this decomposition
is unique in a strong sense.
Direct Sums
Groups in this subsection are arbitrary, possibly inÔ¨Ånite, abelian groups.
Let us say at the outset that there are two ways to describe the direct sum of abelian
groups S1, . . . , Sn. The easiest version is sometimes called their external direct sum,
which we denote by S1 √ó¬∑ ¬∑ ¬∑√ó Sn; its elements are the n-tuples (s1, . . . , sn), where si ‚ààSi
for all i, and its binary operation is
(s1, . . . , sn) + (s‚Ä≤
1, . . . , s‚Ä≤
n) = (s1 + s‚Ä≤
1, . . . , sn + s‚Ä≤
n).
249

250
Groups II
Ch. 5
However, the most useful version, isomorphic to S1 √ó ¬∑ ¬∑ ¬∑ √ó Sn, is sometimes called their
internal direct sum; it involves subgroups Si of a given group G with G ‚àº= S1 √ó ¬∑ ¬∑ ¬∑ √ó Sn.
We will usually omit the adjectives external and internal.
The deÔ¨Ånition of the direct sum of two subgroups is the additive version of the statement
of Proposition 2.80.
DeÔ¨Ånition.
If S and T are subgroups of an abelian group G, then G is the direct sum,
denoted by
G = S ‚äïT,
if S + T = G (i.e., for each a ‚ààG, there are s ‚ààS and t ‚ààT with a = s + t) and
S ‚à©T = {0}.
Here are several characterizations of a direct sum.
Proposition 5.1.
The following statements are equivalent for an abelian group G and
subgroups S and T of G.
(i) G = S ‚äïT.
(ii) Every g ‚ààG has a unique expression of the form
g = s + t,
where s ‚ààS and t ‚ààT .
(iii) There are homomorphisms p: G ‚ÜíS and q : G ‚ÜíT , called projections, and
i : S ‚ÜíG and j : T ‚ÜíG, called injections, such that
pi = 1S,
qj = 1T ,
pj = 0,
qi = 0,
and
ip + jq = 1G.
Remark.
The equations pi = 1S and qj = 1T imply that the maps i and j must be
injections and the maps p and q must be surjections.
‚óÄ
Proof.
(i) ‚áí(ii) By hypothesis, G = S + T , so that each g ‚ààG has an expression
of the form g = s + t with s ‚ààS and t ‚ààT . To see that this expression is unique,
suppose also that g = s‚Ä≤ + t‚Ä≤, where s‚Ä≤ ‚ààS and t‚Ä≤ ‚ààT . Then s + t = s‚Ä≤ + t‚Ä≤ gives
s ‚àís‚Ä≤ = t‚Ä≤ ‚àít ‚ààS ‚à©T = {0}. Therefore, s = s‚Ä≤ and t = t‚Ä≤, as desired.
(ii) ‚áí(iii) If g ‚ààG, then there are unique s ‚ààS and t ‚ààT with g = s + t. The functions
p and q, given by
p(g) = s and q(g) = t,
are well-deÔ¨Åned because of the uniqueness hypothesis. It is routine to check that p and q
are homomorphisms and that all the equations in the statement hold.
(iii) ‚áí(i) If g ‚ààG, the equation 1G = ip + jq gives
g = ip(g) + jq(g) ‚ààS + T,
because S = im i and T = im j.

Sec. 5.1
Finite Abelian Groups
251
If g ‚ààS, then g = ig and pg = pig = g; if g ‚ààT , then g = jg and pg = pjg = 0.
Therefore, if g ‚ààS ‚à©T , then g = 0. Hence, S ‚à©T = {0}, S + T = G, and G = S ‚äïT . ‚Ä¢
The next result shows that there is no essential difference between internal and external
direct sums.
Corollary 5.2.
Let S and T be subgroups of an abelian group G. If G = S ‚äïT , then
S ‚äïT ‚àº= S √ó T .
Conversely, given abelian groups S and T , deÔ¨Åne subgroups S‚Ä≤ ‚àº= S and T ‚Ä≤ ‚àº= T of
S √ó T by
S‚Ä≤ = {(s, 0) : s ‚ààS} and T ‚Ä≤ = {(0, t) : t ‚ààT };
then S √ó T = S‚Ä≤ ‚äïT ‚Ä≤.
Proof.
DeÔ¨Åne f : S ‚äïT ‚ÜíS √óT as follows. If a ‚ààS ‚äïT , then the proposition says that
there is a unique expression of the form a = s + t, and so f : a ‚Üí(s, t) is a well-deÔ¨Åned
function. It is routine to check that f is an isomorphism.
Conversely, if g = (s, t) ‚ààS √ó T , then g = (s, 0) + (0, t) ‚ààS‚Ä≤ + T ‚Ä≤ and S‚Ä≤ ‚à©T ‚Ä≤ =
{(0, 0)}. Hence, S √ó T = S‚Ä≤ ‚äïT ‚Ä≤.
‚Ä¢
DeÔ¨Ånition.
If S1, S2, . . . , Sn, . . . are subgroups of an abelian group G, deÔ¨Åne the Ô¨Ånite
direct sum S1 ‚äïS2 ‚äï¬∑ ¬∑ ¬∑ ‚äïSn using induction on n ‚â•2:
S1 ‚äïS2 ‚äï¬∑ ¬∑ ¬∑ ‚äïSn+1 =

S1 ‚äïS2 ‚äï¬∑ ¬∑ ¬∑ ‚äïSn

‚äïSn+1.
We will also denote the direct sum by
n

i=1
Si = S1 ‚äïS2 ‚äï¬∑ ¬∑ ¬∑ ‚äïSn.
Given S1, S2, . . . , Sn subgroups of an abelian group G, when is the subgroup they gen-
erate, ‚ü®S1, S2, . . . , Sn‚ü©, equal to their direct sum? A common mistake is to say that it is
enough to assume that Si ‚à©Sj = {0} for all i Ã∏= j, but the following example shows that
this is not enough.
Example 5.3.
Let V be a two-dimensional vector space over a Ô¨Åeld k, which we view as an additive
abelian group, and let x, y be a basis. It is easy to check that the intersection of any
two of the subspaces ‚ü®x‚ü©, ‚ü®y‚ü©, and ‚ü®x + y‚ü©is {0}. On the other hand, we do not have
V = [‚ü®x‚ü©‚äï‚ü®y‚ü©] ‚äï‚ü®x + y‚ü©because [‚ü®x‚ü©‚äï‚ü®y‚ü©] ‚à©‚ü®x + y‚ü©Ã∏= {0}.
‚óÄ
In the context of abelian groups, we shall write S ‚äÜG to denote S being a subgroup
of G, as we do when denoting subrings and ideals; in the context of general, possibly
nonabelian, groups, we will continue to write S ‚â§G to denote a subgroup.

252
Groups II
Ch. 5
Proposition 5.4.
Let G = S1 + S2 + ¬∑ ¬∑ ¬∑ + Sn, where the Si are subgroups; that is, for
each a ‚ààG, there are si ‚ààSi for all i, with
a = s1 + s2 + ¬∑ ¬∑ ¬∑ + sn.
Then the following conditions are equivalent.
(i) G = S1 ‚äïS2 ‚äï¬∑ ¬∑ ¬∑ ‚äïSn.
(ii) Every a ‚ààG has a unique expression of the form a = s1 + s2 + ¬∑ ¬∑ ¬∑ + sn, where
si ‚ààSi for all i.
(iii) For each i,
Si ‚à©(S1 + S2 + ¬∑ ¬∑ ¬∑ + Si + ¬∑ ¬∑ ¬∑ + Sn) = {0},
where Si means that the term Si is omitted from the sum.
Proof.
(i) ‚áí(ii) The proof is by induction on n ‚â•2. The base step is Proposition 5.1.
For the inductive step, deÔ¨Åne T = S1 + S2 + ¬∑ ¬∑ ¬∑ + Sn, so that G = T ‚äïSn+1. If a ‚ààG,
then a has a unique expression of the form a = t + sn+1, where t ‚ààT and sn+1 ‚ààSn+1
(by the proposition). But the inductive hypothesis says that t has a unique expression of
the form t = s1 + ¬∑ ¬∑ ¬∑ + sn, where si ‚ààSi for all i ‚â§n, as desired.
(ii) ‚áí(iii) Suppose that
x ‚ààSi ‚à©

S1 + S2 + ¬∑ ¬∑ ¬∑ + Si + ¬∑ ¬∑ ¬∑ + Sn

.
Then x = si ‚ààSi and si = 
jÃ∏=i s j, where s j ‚ààSj. Unless all the s j = 0, the element 0
has two distinct expressions: 0 = ‚àísi + 
jÃ∏=i s j and 0 = 0 + 0 + ¬∑ ¬∑ ¬∑ + 0. Therefore, all
s j = 0 and x = si = 0.
(iii) ‚áí(i) Since Sn+1 ‚à©

S1 + S2 + ¬∑ ¬∑ ¬∑ + Sn

= {0}, we have
G = Sn+1 ‚äï

S1 + S2 + ¬∑ ¬∑ ¬∑ + Sn

.
The inductive hypothesis gives S1 + S2 + ¬∑ ¬∑ ¬∑ + Sn = S1 ‚äïS2 ‚äï¬∑ ¬∑ ¬∑ ‚äïSn, because, for all
j ‚â§n, we have
Sj ‚à©

S1 + ¬∑ ¬∑ ¬∑ + Sj + ¬∑ ¬∑ ¬∑ + Sn

‚äÜSj ‚à©

S1 + ¬∑ ¬∑ ¬∑ + Sj + ¬∑ ¬∑ ¬∑ + Sn + Sn+1

= {0}.
‚Ä¢
Corollary 5.5.
Let G = ‚ü®y1, . . . , yn‚ü©. If, for all mi ‚ààZ, we have 
i mi yi = 0 implies
mi yi = 0; then
G = ‚ü®y1‚ü©‚äï¬∑ ¬∑ ¬∑ ‚äï‚ü®yn‚ü©.
Proof.
By Proposition 5.4(ii), it sufÔ¨Åces to prove that if 
i ki yi = 
i ‚Ñìi yi, then ki yi =
‚Ñìi yi for all i. But this is clear, for 
i(ki ‚àí‚Ñìi)yi = 0 implies (ki ‚àí‚Ñìi)yi = 0 for all i.
‚Ä¢

Sec. 5.1
Finite Abelian Groups
253
Example 5.6.
Let V be an n-dimensional vector space over a Ô¨Åeld k, which we view as an additive abelian
group. If v1, . . . , vn is a basis, then
V = ‚ü®v1‚ü©‚äï‚ü®v2‚ü©‚äï¬∑ ¬∑ ¬∑ ‚äï‚ü®vn‚ü©,
where ‚ü®vi‚ü©= {rvi : r ‚ààk} is the one-dimensional subspace spanned by vi. Each v ‚ààV
has a unique expression of the form v = s1 + ¬∑ ¬∑ ¬∑ + sn, where si = rivi ‚àà‚ü®vi‚ü©, because
v1, . . . , vn is a basis.
‚óÄ
Now that we have examined Ô¨Ånite direct sums, we can generalize Proposition 2.79 from
two summands to a Ô¨Ånite number of summands. Although we state the result for abelian
groups, it should be clear that the proof works for nonabelian groups as well if we assume
that the subgroups Hi are normal subgroups (see Exercise 5.1 on page 267).
Proposition 5.7.
If G1, G2, . . . , Gn are abelian groups and Hi ‚äÜGi are subgroups,
then
(G1 ‚äï¬∑ ¬∑ ¬∑ ‚äïGn)/(H1 ‚äï¬∑ ¬∑ ¬∑ ‚äïHn) ‚àº= (G1/H1) √ó ¬∑ ¬∑ ¬∑ √ó (Gn/Hn).
Proof.
DeÔ¨Åne f : G1 ‚äï¬∑ ¬∑ ¬∑ ‚äïGn ‚Üí(G1/H1) ‚äï¬∑ ¬∑ ¬∑ ‚äï(Gn/Hn) by
(g1, . . . , gn) ‚Üí(g1 + H1, . . . , gn + Hn).
Since f is a surjective homomorphism with ker f = H1 ‚äï¬∑ ¬∑ ¬∑ ‚äïHn, the Ô¨Årst isomorphism
theorem gives the result.
‚Ä¢
If G is an abelian group and m is an integer, let us write
mG = {ma : a ‚ààG}.
It is easy to see that mG is a subgroup of G.
Proposition 5.8.
If G is an abelian group and p is a prime, then G/pG is a vector space
over Fp.
Proof.
If [r] ‚ààFp and a ‚ààG, deÔ¨Åne scalar multiplication
[r](a + pG) = ra + pG.
This formula is well-deÔ¨Åned, for if k ‚â°r mod p, then k = r + pm for some integer m,
and so
ka + pG = ra + pma + pG = ra + pG,
because pma ‚ààpG. It is now routine to check that the axioms for a vector space do
hold.
‚Ä¢

254
Groups II
Ch. 5
Direct sums of copies of Z arise often enough to have their own name.
DeÔ¨Ånition.
Let F = ‚ü®x1, . . . , xn‚ü©be an abelian group. If
F = ‚ü®x1‚ü©‚äï¬∑ ¬∑ ¬∑ ‚äï‚ü®xn‚ü©,
where each ‚ü®xi‚ü©‚àº= Z, then F is called a (Ô¨Ånitely generated) free abelian group with basis
x1, . . . , xn. More generally, any group isomorphic to F is called a free abelian group.
For example, Zm = Z √ó ¬∑ ¬∑ ¬∑ √ó Z, the group of all m-tuples (n1, . . . , nm) of integers, is
a free abelian group.
Proposition 5.9.
If Zm denotes the direct sum of m copies of Z, then Zm ‚àº= Zn if and
only if m = n.
Proof.
Only necessity needs proof. Note Ô¨Årst, for any abelian group G, that if G =
G1 ‚äï¬∑ ¬∑ ¬∑ ‚äïGn, then 2G = 2G1 ‚äï¬∑ ¬∑ ¬∑ ‚äï2Gn. It follows from Proposition 5.7 that
G/2G ‚àº= (G1/2G1) ‚äï¬∑ ¬∑ ¬∑ ‚äï(Gn/2Gn),
so that |G/2G| = 2n. Similarly, if H = Zm, then |H/2H| = 2m. Finally, if G = Zn ‚àº=
Zm = H, then G/2G ‚àº= H/2H and 2n = 2m. We conclude that n = m.
‚Ä¢
Corollary 5.10.
If F is a (Ô¨Ånitely generated) free abelian group, then any two bases of F
have the same number of elements.
Proof.
If x1, . . . , xn is a basis of F, then F ‚àº= Zn, and if y1, . . . , ym is another basis of
F, then F ‚àº= Zm. By the proposition, m = n.
‚Ä¢
DeÔ¨Ånition.
If F is a free abelian group with basis x1, . . . , xn, then n is called the rank
of F, and we write rank(F) = n.
Corollary 5.10 says that rank(F) is well-deÔ¨Åned; that is, it does not depend on the
choice of basis. In this language, Proposition 5.9 says that two Ô¨Ånitely generated free
abelian groups are isomorphic if and only if they have the same rank; that is, the rank of
a free abelian group plays the same role as the dimension of a vector space. Comparing
the next theorem with Theorem 3.92 shows that a basis of a free abelian group behaves as
does a basis of a vector space.
Theorem 5.11.
Let F be a free abelian group with basis X = {x1, . . . , xn}. If G is any
abelian group and if Œ≥ : X ‚ÜíG is any function, then there exists a unique homomorphism
g : F ‚ÜíG with g(xi) = Œ≥ (xi) for all xi.
F
g

X

Œ≥
 G

Sec. 5.1
Finite Abelian Groups
255
Proof.
Every element a ‚ààF has a unique expression of the form
a =
n

i=1
mi xi,
where mi ‚ààZ. DeÔ¨Åne g : F ‚ÜíG by
g(a) =
n

i=1
miŒ≥ (xi).
If h : F ‚ÜíG is a homomorphism with h(xi) = g(xi) for all i, then h = g, for two
homomorphisms that agree on a set of generators must be equal.
‚Ä¢
Theorem 5.11 characterizes free abelian groups.
Proposition 5.12.
Let A be an abelian group containing a subset X = {x1, . . . , xn}, and
let A have the property in Theorem 5.11: For every abelian group G and every function
Œ≥ : X ‚ÜíG, there exists a unique homomorphism g: A ‚ÜíG with g(xi) = Œ≥ (xi) for all
xi. Then A ‚àº= Zn; that is, A is a free abelian group of rank n.
Proof.
Consider the diagrams
A
g

X
p

q
 Zn
Zn
h

X
and
q

p
 A,
where p: X ‚ÜíA and q : X ‚ÜíZn are inclusions. The Ô¨Årst diagram arises from the given
property of A, and so gp = q; the second arises from Theorem 5.11, which shows that Zn
enjoys the same property; hence, hq = p. We claim that the composite g : A ‚ÜíZn is an
isomorphism. To see this, consider the diagram
A
hg

X
p

p
 A.
Now hgp = hq = p. By hypothesis, hg is the unique such homomorphism. But 1A
is another such, and so hg = 1A. A similar diagram shows that the other composite
gh = 1Zn, and so g is an isomorphism.
‚Ä¢
Basis Theorem
It will be convenient to analyze Ô¨Ånite abelian groups "one prime at a time."
Recall that a p-group is a Ô¨Ånite group G of order pk for some k ‚â•0. When working
wholly in the context of abelian groups, p-groups are called p-primary groups.

256
Groups II
Ch. 5
DeÔ¨Ånition.
If p is a prime, then an abelian group G is p-primary if, for each a ‚ààG, there
is n ‚â•1 with pna = 0.
If G is any abelian group, then its p-primary component is
G p = {a ‚ààG : pna = 0 for some n ‚â•1}.
It is easy to see, for every prime p, that G p is a subgroup of G (this is not the case when
G is not abelian; for example, G2 is not a subgroup if G = S3).
If we do not want to specify the prime p, we may write that an abelian group is primary
(instead of p-primary).
Theorem 5.13 (Primary Decomposition).
(i) Every Ô¨Ånite abelian group G is a direct sum of its p-primary components:
G = G p1 ‚äï¬∑ ¬∑ ¬∑ ‚äïG pn.
(ii) Two Ô¨Ånite abelian groups G and G‚Ä≤ are isomorphic if and only if G p ‚àº= G‚Ä≤
p for
every prime p.
Proof.
(i) Let x ‚ààG be nonzero, and let its order be d. By the fundamental theorem of
arithmetic, there are distinct primes p1, . . . , pn and positive exponents e1, . . . , en with
d = pe1
1 ¬∑ ¬∑ ¬∑ pen
n .
DeÔ¨Åne ri = d/pei
i , so that pei
i ri = d. It follows that ri x ‚ààG pi for each i (because
dx = 0). But the gcd d of r1, . . . ,rn is 1 (the only possible prime divisors of d are
p1, . . . , pn; but no pi is a common divisor because pi ‚à§ri); hence, there are integers
s1, . . . , sn with 1 = 
i siri. Therefore,
x =

i
siri x ‚ààG p1 + ¬∑ ¬∑ ¬∑ + G pn.
Write Hi = G p1 + G p2 + ¬∑ ¬∑ ¬∑ + 
G pi + ¬∑ ¬∑ ¬∑ + G pn. By Proposition 5.4, it sufÔ¨Åces to
prove that if
x ‚ààG pi ‚à©Hi,
then x = 0 . Since x ‚ààG pi , we have p‚Ñì
i x = 0 for some ‚Ñì‚â•0; since x ‚ààHi, we have
x = 
jÃ∏=i y j, where p
g j
j y j = 0; hence, ux = 0, where u = 
jÃ∏=i p
g j
j . But p‚Ñì
i and u are
relatively prime, so there exist integers s and t with 1 = sp‚Ñì
i + tu. Therefore,
x = (sp‚Ñì
i + tu)x = sp‚Ñì
i x + tux = 0.
(ii) If f : G ‚ÜíG‚Ä≤ is a homomorphism, then f (G p) ‚äÜG‚Ä≤
p for every prime p, for if
p‚Ñìa = 0, then 0 = f (p‚Ñìa) = p‚Ñìf (a). If f is an isomorphism, then f ‚àí1 : G‚Ä≤ ‚ÜíG is
also an isomorphism [so that f ‚àí1(G‚Ä≤
p) ‚äÜG p for all p]. It follows that each restriction
f |G p : G p ‚ÜíG‚Ä≤
p is an isomorphism, with inverse f ‚àí1|G‚Ä≤
p.
Conversely, if there are isomorphisms f p : G p ‚ÜíG‚Ä≤
p for all p, then there is an isomor-
phism œï : 
p G p ‚Üí
p G‚Ä≤
p given by 
p ap ‚Üí
p f p(ap).
‚Ä¢

Sec. 5.1
Finite Abelian Groups
257
The next type of subgroup will play an important role.
DeÔ¨Ånition.
Let p be a prime and let G be a p-primary abelian group.1 A subgroup S ‚äÜG
is a pure2 subgroup if, for all n ‚â•0,
S ‚à©pnG = pnS.
The inclusion S ‚à©pnG ‚â•pnS is true for every subgroup S ‚äÜG, and so it is only
the reverse inclusion S ‚à©pnG ‚äÜpnS that is signiÔ¨Åcant. It says that if s ‚ààS satisÔ¨Åes an
equation s = pna for some a ‚ààG, then there exists s‚Ä≤ ‚ààS with s = pns‚Ä≤.
Example 5.14.
(i) Every direct summand S of G is a pure subgroup. If G = S ‚äïT and (s, 0) = pn(u, v),
where u ‚ààS and v ‚ààT , then it is clear that (s, 0) = pn(u, 0). (The converse: "Every
pure subgroup S is a direct summand" is true when S is Ô¨Ånite, but it may be false when S
is inÔ¨Ånite.)
(ii) If G = ‚ü®a‚ü©is a cyclic group of order p2, where p is a prime, then S = ‚ü®pa‚ü©is not a
pure subgroup of G, for if s = pa ‚ààS, then there is no element s‚Ä≤ ‚ààS with s = pa = ps‚Ä≤.
‚óÄ
Lemma 5.15.
If p is a prime and G is a Ô¨Ånite p-primary abelian group, then G has a
nonzero pure cyclic subgroup.
Proof.
Since G is Ô¨Ånite, we may choose an element y ‚ààG of largest order, say, p‚Ñì. We
claim that S = ‚ü®y‚ü©is a pure subgroup of G.
Suppose that s ‚ààS, so that s = mpt y, where t ‚â•0 and p ‚à§m, and let
s = pna
for some a ‚ààG; an element s‚Ä≤ ‚ààS must be found with s = pns‚Ä≤. We may assume that
n < ‚Ñì: otherwise, s = pna = 0 (for p‚Ñìg = 0 for all g ‚ààG because y has largest order
p‚Ñì), and we may choose s‚Ä≤ = 0.
If t ‚â•n, deÔ¨Åne s‚Ä≤ = mpt‚àíny ‚ààS, and note that
pns‚Ä≤ = pnmpt‚àíny = mpt y = s.
If t < n, then
p‚Ñìa = p‚Ñì‚àín pna = p‚Ñì‚àíns = p‚Ñì‚àínmpt y = mp‚Ñì‚àín+t y.
But p ‚à§m and ‚Ñì‚àín + t < ‚Ñì, because ‚àín + t < 0, and so p‚Ñìa Ã∏= 0. This contradicts y
having largest order, and so this case cannot occur.
‚Ä¢
1If G is not a primary group, then a pure subgroup S ‚äÜG is deÔ¨Åned to be a subgroup that satisÔ¨Åes S ‚à©mG =
mS for all m ‚ààZ (see Exercises 5.2 and 5.3 on page 267).
2Recall that pure extensions k(u)/k arose in our discussion of solvability by radicals on page 206; in such an
extension, the adjoined element u satisÔ¨Åes the equation un = a for some a ‚ààk. Pure subgroups are deÔ¨Åned in
terms of similar equations (written additively), and they are probably so called because of this.

258
Groups II
Ch. 5
DeÔ¨Ånition.
If p is a prime and G is a Ô¨Ånite p-primary abelian group, then
d(G) = dim(G/pG).
Observe that d is additive over direct sums,
d(G ‚äïH) = d(G) + d(H),
for Proposition 2.79 gives
(G ‚äïH)/p(G ‚äïH) = (G ‚äïH)/(pG ‚äïpH)
‚àº= (G/pG) ‚äï(H/pH).
The dimension of the left side is d(G ‚äïH) and the dimension of the right-hand side
is d(G) + d(H), for the union of a basis of G/pG and a basis of H/pH is a basis of
(G/pG) ‚äï(H/pH).
The nonzero abelian groups G with d(G) = 1 are easily characterized.
Lemma 5.16.
If G Ã∏= {0} is p-primary, then d(G) = 1 if and only if G is cyclic.
Proof.
If G is cyclic, then so is any quotient of G; in particular, G/pG is cyclic, and so
dim(G/pG) = 1.
Conversely, if G/pG = ‚ü®z + pG‚ü©, then G/pG ‚àº= Ip. Since Ip is a simple group, the
correspondence theorem says that pG is a maximal proper subgroup of G; we claim that
pG is the only maximal proper subgroup of G. If L ‚äÜG is any maximal proper subgroup,
then G/L ‚àº= Ip, for G/L is a simple abelian group of order a power of p, hence has order
p (by Proposition 2.107, the abelian simple groups are precisely the cyclic groups of prime
order). Thus, if a ‚ààG, then p(a + L) = 0 in G/L, so that pa ‚ààL; hence pG ‚äÜL. But
pG is maximal, and so pG = L. It follows that every proper subgroup of G is contained
in pG (for every proper subgroup is contained in some maximal proper subgroup). In
particular, if ‚ü®z‚ü©is a proper subgroup of G, then ‚ü®z‚ü©‚äÜpG, contradicting z + pG being a
generator of G/pG. Therefore, G = ‚ü®z‚ü©, and so G is cyclic.
‚Ä¢
Lemma 5.17.
Let G be a Ô¨Ånite p-primary abelian group.
(i) If S ‚äÜG, then d(G/S) ‚â§d(G).
(ii) If S is a pure subgroup of G, then
d(G) = d(S) + d(G/S).
Proof.
(i) By the correspondence theorem, p(G/S) = (pG + S)/S, so that
(G/S)/p(G/S) = (G/S)/[(pG + S)/S] ‚àº= G/(pG + S),
by the third isomorphism theorem. Since pG ‚äÜpG + S, there is a surjective homomor-
phism (of vector spaces over Fp),
G/pG ‚ÜíG/(pG + S),

Sec. 5.1
Finite Abelian Groups
259
namely, g + pG ‚Üíg + (pG + S). Hence, dim(G/pG) ‚â•dim(G/(pG + S)); that is,
d(G) ‚â•d(G/S).
(ii) We now analyze (pG + S)/pG, the kernel of G/pG ‚ÜíG/(pG + S). By the second
isomorphism theorem,
(pG + S)/pG ‚àº= S/(S ‚à©pG).
Since S is a pure subgroup, S ‚à©pG = pS; therefore,
(pG + S)/pG ‚àº= S/pS,
and so dim[(pG + S)/pG] = d(S). But if W is a subspace of a Ô¨Ånite-dimensional vector
space V , then dim(V ) = dim(W) + dim(V/W), by Exercise 3.72 on page 170. Hence, if
V = G/pG and W = (pG + S)/pG, we have
d(G) = d(S) + d(G/S).
‚Ä¢
Theorem 5.18 (Basis Theorem).
Every Ô¨Ånite abelian group G is a direct sum of cyclic
groups of prime power orders.
Proof.
By the primary decomposition, Theorem 5.13, we may assume that G is p-primary
for some prime p. We prove that G is a direct sum of cyclic groups by induction on
d(G) ‚â•1. The base step is easy, for Lemma 5.16 shows that G must be cyclic in this case.
To prove the inductive step, we begin by using Lemma 5.15 to Ô¨Ånd a nonzero pure cyclic
subgroup S ‚äÜG. By Lemma 5.17, we have
d(G/S) = d(G) ‚àíd(S) = d(G) ‚àí1 < d(G).
By induction, G/S is a direct sum of cyclic groups, say,
G/S =
q

i=1
‚ü®xi‚ü©,
where xi = xi + S.
Let x ‚ààG and let x have order p‚Ñì, where x = x + S. We claim that there is z ‚ààG with
z + S = x = x + S such that
order z = order (x).
Now x has order pn, where n ‚â•‚Ñì. But p‚Ñì(x + S) = p‚Ñìx = 0 in G/S, so there is some
s ‚ààS with p‚Ñìx = s. By purity, there is s‚Ä≤ ‚ààS with p‚Ñìx = p‚Ñìs‚Ä≤. If we deÔ¨Åne z = x ‚àís‚Ä≤,
then p‚Ñìz = 0 and z + S = x + S = x. If z has order pm, then m ‚â•‚Ñìbecause z ‚Üíx;
since p‚Ñìz = 0, the order of z equals p‚Ñì.
For each i, choose zi ‚ààG with zi + S = xi = xi + S and with order zi = order xi;
deÔ¨Åne T by
T = ‚ü®z1, . . . , zq‚ü©.

260
Groups II
Ch. 5
Now S + T = G, because G is generated by S and the zi's. To see that G = S ‚äïT , it now
sufÔ¨Åces to prove that S ‚à©T = {0}. If y ‚ààS ‚à©T , then y = 
i mizi, where mi ‚ààZ. Now
y ‚ààS, and so 
i mi xi = 0 in G/S. Since this is a direct sum, each mi xi = 0; after all,
for each i,
‚àími xi =

jÃ∏=i
m j x j ‚àà‚ü®xi‚ü©‚à©

‚ü®x1‚ü©+ ¬∑ ¬∑ ¬∑ + 1
‚ü®xi‚ü©+ ¬∑ ¬∑ ¬∑ + ‚ü®xq‚ü©

= {0}.
Therefore, mizi = 0 for all i, and hence y = 0.
Finally, G = S ‚äïT implies d(G) = d(S) + d(T ) = 1 + d(T ), so that d(T ) < d(G).
By induction, T is a direct sum of cyclic groups, and this completes the proof.
‚Ä¢
The shortest proof of the basis theorem that I know is due to G. Navarro, American
Mathematical Monthly 110 (2003), pages 153-154.
Lemma 5.19.
A Ô¨Ånite p-primary abelian group G is cyclic if and only if it has a unique
subgroup of order p.
Proof.
Recall the unnumbered theorem on page 94: If G is an abelian group of order n
having at most one cyclic subgroup of order p for every prime divisor p of n, then G is
cyclic. The lemma follows at once when n is a power of p. The converse is Lemma 2.85. ‚Ä¢
Remark.
We cannot remove the hypothesis that G be abelian, for the group Q of quater-
nions is a 2-group having a unique subgroup of order 2. However, if G is a (possibly
nonabelian) Ô¨Ånite p-group having a unique subgroup of order p, then G is either cyclic
or generalized quaternion (the latter groups are deÔ¨Åned on page 298). A proof of this last
result can be found in Rotman, An Introduction to the Theory of Groups, pages 121-122.
One cannot remove the Ô¨Åniteness hypothesis, for Proposition 9.25(iii) shows that the
inÔ¨Ånite p-primary group Z(p‚àû) has a unique subgroup of order p.
‚óÄ
Lemma 5.20.
If G is a Ô¨Ånite p-primary abelian group and if a is an element of largest
order in G, then A = ‚ü®a‚ü©is a direct summand of G.
Proof.
The proof is by induction on |G| ‚â•1; the base step is trivially true. We may as-
sume that G is not cyclic, for any group is a direct summand of itself (with complementary
summand {0}). Now A has a unique subgroup of order p; call it C. By Lemma 5.19, G
contains another subgroup of order p, say C‚Ä≤. Of course, A ‚à©C‚Ä≤ = {0}. By the second
isomorphism theorem, (A +C‚Ä≤)/C‚Ä≤ ‚àº= A/(A ‚à©C‚Ä≤) ‚àº= A is a cyclic subgroup of G/C‚Ä≤. But
no homomorphic image of G can have a cyclic subgroup of order greater than |A| (for no
element of an image can have order larger than the order of a). Therefore, (A + C‚Ä≤)/C‚Ä≤ is
a cyclic subgroup of G/C‚Ä≤ of largest order and, by the inductive hypothesis, it is a direct
summand: There is a subgroup B/C‚Ä≤, where C‚Ä≤ ‚äÜB ‚äÜG, with
G/C‚Ä≤ =

(A + C‚Ä≤)/C‚Ä≤
‚äï

B/C‚Ä≤
.
We claim that G = A ‚äïB. Clearly, G = A + C‚Ä≤ + B = A + B (for C‚Ä≤ ‚äÜB), while
A ‚à©B ‚äÜA ‚à©

(A + C‚Ä≤) ‚à©B

= A ‚à©C‚Ä≤ = {0}.
‚Ä¢

Sec. 5.1
Finite Abelian Groups
261
Theorem 5.21 (Basis Theorem).
Every Ô¨Ånite abelian group G is a direct sum of cyclic
groups.
Proof.
The proof is by induction on |G| ‚â•1, and the base step is obviously true. To
prove the inductive step, let p be a prime divisor of |G|. Now G = G p ‚äïH, where p ‚à§|H|
(either we can invoke the primary decomposition or reprove this special case of it). By
induction, H is a direct sum of cyclic groups. If G p is cyclic, we are done. Otherwise,
Lemma 5.20 applies to write G p = A‚äïB, where A is cyclic. By the inductive hypothesis,
B is a direct sum of cyclic groups, and the theorem is proved.
‚Ä¢
Another short proof of the basis theorem is due to R. Rado, Journal London Mathemat-
ical Society 26 (1951), pages 75-76 and 160. We merely sketch the proof.
Let G be an additive abelian group, and let x1, . . . , xn be elements of G. Form the
1 √ó n matrix X whose jth entry is x j. If U is an n √ó n matrix with entries in Z, then
XU is another 1 √ó n matrix with entries in G, for its entries are Z-linear combinations of
x1, . . . , xn. It is easy to check associativity: If U and V are n √ó n matrices with entries in
Z, then X(UV ) = (XU)V . Moreover, there is an obvious relation between the subgroups
generated by XU and by X; namely, ‚ü®XU‚ü©‚äÜ‚ü®X‚ü©.
Lemma A. Let G be an additive abelian group, let x1, . . . , xn be elements of G, let X be
the 1 √ó n matrix X whose jth entry is x j, and let U be an n √ó n matrix with entries in Z.
If det(U) = 1, then ‚ü®XU‚ü©= ‚ü®X‚ü©.
DeÔ¨Ånition.
An n √ó 1 matrix [a1, . . . , an] with entries in a PID R is called a unimodular
column if gcd (a1, . . . , an) = 1.
Lemma B. If R is a PID, then every unimodular column [a1, . . . , an] is the Ô¨Årst column of
some n √ó n matrix U over R with det(U) = 1.
Sketch of Proof.
The proof is by induction on n ‚â•2. If n = 2, then there are elements
s and t in R with ta1 + sa2 = 1, and U =
a1
‚àís
a2
t

is a matrix of determinant 1.
The inductive step begins by setting d = gcd(a1, . . . , an‚àí1) and deÔ¨Åning bi = ai/d for
i ‚â§n ‚àí1. Since [b1, . . . , bn‚àí1] is a unimodular column, the inductive hypothesis says it
is the Ô¨Årst column of an (n ‚àí1) √ó (n ‚àí1) matrix U ‚Ä≤ of determinant 1. Now (an, d) = 1,
since [a1, . . . , an] is a unimodular column, and so there are s, t ‚ààR with td + san = 1.
These data are used, in a clever way, to modify U ‚Ä≤ and then augment it to form an n √ó n
unimodular matrix with Ô¨Årst column [a1, . . . , an].
‚Ä¢
Theorem. (i) If an abelian group G = ‚ü®x1, . . . , xn‚ü©and if [a1, . . . , an] is a unimodular
column, then there is a set of n generators of G one of whose elements is a1x1 +¬∑ ¬∑ ¬∑+anxn.
(ii)If G = ‚ü®x1, . . . , xn‚ü©is a Ô¨Ånite abelian group, then G is a direct sum of cyclic groups.
Proof.
(i) By Lemma B, there is an n √ó n matrix U with det(U) = 1 whose Ô¨Årst column
is [a1, . . . , an]. Since det(U) = 1, Lemma A applies to say that the elements of XU, the
Ô¨Årst of which is a1x1 + ¬∑ ¬∑ ¬∑ + anxn, generate G.

262
Groups II
Ch. 5
(ii) Let n be the smallest cardinal of any generating set of G, and call such a generating
set a minimal generating set. The proof is by induction on the number n of elements in a
minimal generating set. If n = 1, then G is cyclic, and we are done. Of all the elements
in minimal generating sets, choose one, say x, having smallest order, say k (so no minimal
generating set contains an element of order less than k). Choose a minimal generating set
{x1, . . . , xn‚àí1, x} containing x, and deÔ¨Åne xn = x. Now H = ‚ü®x1, . . . , xn‚àí1‚ü©is a proper
subgroup of G, by minimality of n, and H is a direct sum of cyclic groups, by the inductive
hypothesis. It sufÔ¨Åces to prove that H ‚à©‚ü®xn‚ü©= {0}, for then G = H + ‚ü®xn‚ü©= H ‚äï‚ü®xn‚ü©,
as desired. If, on the contrary, ‚ü®xn‚ü©‚à©H Ã∏= {0}, then there are integers a1, . . . , an with
anxn Ã∏= 0 and anxn = n‚àí1
i=1 ai xi ‚ààH (of course, we may assume that 0 < an < k). Let
d = gcd(a1, . . . , an). Now [a1/d, . . . , an/d] is a unimodular column, and so the element
g = ‚àí(an/d)xn + n‚àí1
i=1 (ai/d)xi is part of a minimal generating set of G, by part (i).
But dg = 0, and so the order of g is a divisor of d; hence, g is an element of a minimal
generating set that has order smaller than k, a contradiction. Therefore, ‚ü®xn‚ü©‚à©H = {0},
and so G is a direct sum of cyclic groups.
‚Ä¢
Fundamental Theorem
When are two Ô¨Ånite abelian groups G and G‚Ä≤ isomorphic? By the basis theorem, such
groups are direct sums of cyclic groups, and so our Ô¨Årst guess is that G ‚àº= G‚Ä≤ if they
have the same number of cyclic summands of each type. But this hope is dashed by Theo-
rem 2.81, which says that if m and n are relatively prime, then Imn ‚àº= Im √óIn; for example,
I6 ‚àº= I2 √ó I3. Thus, we retreat and try to count primary cyclic summands. But how can we
do this? As in the fundamental theorem of arithmetic, we must ask whether there is some
kind of unique factorization theorem here.
Before stating the next lemma, recall that we have deÔ¨Åned
d(G) = dim(G/pG).
In particular, d(pG) = dim(pG/p2G) and, more generally,
d(pnG) = dim(pnG/pn+1G).
Lemma 5.22.
Let G be a Ô¨Ånite p-primary abelian group, where p is a prime, and let
G = 
j C j, where each C j is cyclic. If bn ‚â•0 is the number of summands C j having
order pn, then there is some t ‚â•1 with
d(pnG) = bn+1 + bn+2 + ¬∑ ¬∑ ¬∑ + bt.
Proof.
Let Bn be the direct sum of all C j, if any, with order pn. Thus,
G = B1 ‚äïB2 ‚äï¬∑ ¬∑ ¬∑ ‚äïBt
for some t. Now
pnG = pn Bn+1 ‚äï¬∑ ¬∑ ¬∑ ‚äïpn Bt,

Sec. 5.1
Finite Abelian Groups
263
because pn B j = {0} for all j ‚â§n. Similarly,
pn+1G = pn+1Bn+2 ‚äï¬∑ ¬∑ ¬∑ ‚äïpn+1Bt.
Now Proposition 5.7 shows that pnG/pn+1G is isomorphic to

pn Bn+1/pn+1Bn+1

‚äï

pn Bn+2/pn+1Bn+2

‚äï¬∑ ¬∑ ¬∑ ‚äï

pn Bt/pn+1Bt

.
Exercise 5.7 on page 267 gives d(pn Bm/pn+1Bm) = dim(pn Bm) = bm for all n < m;
since d is additive over direct sums, we have
d(pnG) = bn+1 + bn+2 + ¬∑ ¬∑ ¬∑ + bt.
‚Ä¢
The numbers bn can now be described in terms of G.
DeÔ¨Ånition.
Let G be a Ô¨Ånite p-primary abelian group, where p is a prime. For n ‚â•0,
deÔ¨Åne
Up(n, G) = d(pnG) ‚àíd(pn+1G).
Lemma 5.22 shows that
d(pnG) = bn+1 + ¬∑ ¬∑ ¬∑ + bt
and
d(pn+1G) = bn+2 + ¬∑ ¬∑ ¬∑ + bt,
so that Up(n, G) = bn+1.
Theorem 5.23.
If p is a prime, then any two decompositions of a Ô¨Ånite p-primary abelian
group G into direct sums of cyclic groups have the same number of cyclic summands of
each type. More precisely, for each n ‚â•0, the number of cyclic summands having order
pn+1 is Up(n, G).
Proof.
By the basis theorem, there exist cyclic subgroups Ci with G = 
i Ci. The
lemma shows, for each n ‚â•0, that the number of Ci having order pn+1 is Up(n, G), a
number that is deÔ¨Åned without any mention of the given decomposition of G into a direct
sum of cyclics. Thus, if G = 
j D j is another decomposition of G, where each D j is
cyclic, then the number of D j having order pn+1 is also Up(n, G), as desired.
‚Ä¢
Corollary 5.24.
If G and G‚Ä≤ are Ô¨Ånite p-primary abelian groups, then G ‚àº= G‚Ä≤ if and
only if Up(n, G) = Up(n, G‚Ä≤) for all n ‚â•0.
Proof.
If œï : G ‚ÜíG‚Ä≤ is an isomorphism, then œï(pnG) = pnG‚Ä≤ for all n ‚â•0, and
so œï induces isomorphisms of the Fp-vector spaces pnG/pn+1G ‚àº= pnG‚Ä≤/pn+1G‚Ä≤ for all
n ‚â•0 by png + pn+1G ‚Üípnœï(g) + pn+1G‚Ä≤. Thus, their dimensions are the same; that
is, Up(n, G) = Up(n, G‚Ä≤).
Conversely, assume that Up(n, G) = Up(n, G‚Ä≤) for all n ‚â•0. If G = 
i Ci and
G‚Ä≤ = 
j C‚Ä≤
j, where the Ci and C‚Ä≤
j are cyclic, then Lemma 5.22 shows that there are
the same number of summands of each type, and so it is a simple matter to construct an
isomorphism G ‚ÜíG‚Ä≤.
‚Ä¢

264
Groups II
Ch. 5
DeÔ¨Ånition.
If G is a p-primary abelian group, then its elementary divisors are the num-
bers in the sequence having Up(0, G) p's, Up(1, G) p2's, . . ., Up(t ‚àí1, G) pt's, where
pt is the largest order of a cyclic summand of G.
If G is a Ô¨Ånite abelian group, then its elementary divisors are the elementary divisors of
all its primary components.
Theorem 5.25 (Fundamental Theorem of Finite Abelian Groups).
Two Ô¨Ånite abelian
groups G and G‚Ä≤ are isomorphic if and only if they have the same elementary divisors; that
is, any two decompositions of G and G‚Ä≤ into direct sums of primary cyclic groups have the
same number of summands of each order.
Proof.
By the primary decomposition, Theorem 5.13(ii), G ‚àº= G‚Ä≤ if and only if, for each
prime p, their primary components are isomorphic: G p ‚àº= G‚Ä≤
p. The result now follows
from Corollary 5.24.
‚Ä¢
Example 5.26.
How many abelian groups are there of order 72? Now 72 = 2332, so that any abelian group
of order 72 is the direct sum of groups of order 8 and order 9. There are three groups of
order 8, described by the elementary divisors
(2, 2, 2),
(2, 4),
and
(8);
there are two groups of order 9, described by the elementary divisors
(3, 3)
and
(9).
Therefore, to isomorphism, there are six abelian groups of order 72.
‚óÄ
Here is a second type of decomposition of a Ô¨Ånite abelian group into a direct sum of
cyclics that does not mention primary groups.
Proposition 5.27.
Every Ô¨Ånite abelian group G is a direct sum of cyclic groups
G = S(c1) ‚äïS(c2) ‚äï¬∑ ¬∑ ¬∑ ‚äïS(ct),
where t ‚â•1, S(ci) is a cyclic group of order ci, and
c1 | c2 | ¬∑ ¬∑ ¬∑ | ct.
Proof.
Let p1, . . . , pn be the prime divisors of |G|. By the basis theorem, we have, for
each pi,
G pi = S(pei1
i ) ‚äïS(pei2
i ) ‚äï¬∑ ¬∑ ¬∑ ‚äïS(peit
i ).
We may assume that 0 ‚â§ei1 ‚â§ei2 ‚â§¬∑ ¬∑ ¬∑ ‚â§eit; moreover, we may allow "dummy"
exponents ei j = 0 so that the same last index t can be used for all i. DeÔ¨Åne
c j = p
e1 j
1
p
e2 j
2
¬∑ ¬∑ ¬∑ p
enj
n .

Sec. 5.1
Finite Abelian Groups
265
It is plain that c1 | c2 | ¬∑ ¬∑ ¬∑ | ct. Finally, Theorem 2.81 shows that
S(p
e1 j
1 ) ‚äïS(p
e2 j
2 ) ‚äï¬∑ ¬∑ ¬∑ ‚äïS(p
enj
n ) ‚àº= S(c j)
for every j.
‚Ä¢
DeÔ¨Ånition.
If G is an abelian group, then its exponent is the smallest positive integer m
for which mG = {0}.
Corollary 5.28.
If G is a Ô¨Ånite abelian group and G = S(c1)‚äïS(c2)‚äï¬∑ ¬∑ ¬∑‚äïS(ct), S(ci)
is a cyclic group of order ci and c1 | c2 | ¬∑ ¬∑ ¬∑ | ct, then ct is the exponent of G.
Proof.
Since ci | ct for all i, we have ct S(ci) = 0 for all i, and so ctG = {0}. On the
other hand, there is no number e with 1 ‚â§e < ct with eS(ct) = {0}, and so ct is the
smallest positive integer annihilating G.
‚Ä¢
Corollary 5.29.
Every noncyclic Ô¨Ånite abelian group G has a subgroup isomorphic to
Ic ‚äïIc for some c > 1.
Proof.
By Proposition 5.27, G = Ic1 ‚äïIc2 ‚äï¬∑ ¬∑ ¬∑ ‚äïIct , where t ‚â•2, because G is not
cyclic. Since c1 | c2, the cyclic group Ic2 contains a subgroup isomorphic to Ic1, and so G
has a subgroup isomorphic to Ic1 ‚äïIc1.
‚Ä¢
Let us return to the structure of Ô¨Ånite abelian groups.
DeÔ¨Ånition.
If G is a Ô¨Ånite abelian group, and if
G = S(c1) ‚äïS(c2) ‚äï¬∑ ¬∑ ¬∑ ‚äïS(ct),
where t ‚â•1, S(c j) is a cyclic group of order c j > 1, and c1 | c2 | ¬∑ ¬∑ ¬∑ | ct, then
c1, c2, . . . , ct are called the invariant factors of G.
Corollary 5.30.
If G is a Ô¨Ånite abelian group with invariant factors c1, . . . , ct and ele-
mentary divisors {p
ei j
i }, then |G| = t
j=1 c j = 
i j p
ei j
i , and its exponent is ct.
Proof.
We have
G ‚àº= Z/(c1) ‚äï¬∑ ¬∑ ¬∑ ‚äïZ/(ct)
‚àº= Ic1 ‚äï¬∑ ¬∑ ¬∑ ‚äïIct .
Since the underlying set of a direct sum is the cartesian product, we have |G| = t
j=1 c j
and |G| = 
i j p
ei j
i . That ct is the exponent was proved in Corollary 5.28.
‚Ä¢

266
Groups II
Ch. 5
Example 5.31.
In Example 5.26, we displayed the elementary divisors of abelian groups of order 72; here
are their invariant factors.
elementary divisors ‚Üîinvariant factors
(2, 2, 2, 3, 3) = (2, 2, 2, 1, 3, 3) ‚Üî2 | 6 | 6
(2, 4, 3, 3) ‚Üî6 | 12
(8, 3, 3) = (1, 8, 3, 3) ‚Üî3 | 24
(2, 2, 2, 9) = (2, 2, 2, 1, 1, 9) ‚Üî2 | 2 | 18
(2, 4, 9) = (2, 4, 1, 9) ‚Üî2 | 36
(8, 9) ‚Üî72
‚óÄ
Theorem 5.32 (Invariant Factors).
Two Ô¨Ånite abelian groups are isomorphic if and
only they have the same invariant factors.
Proof.
Given the elementary divisors of G, we can construct invariant factors, as in the
proof of Proposition 5.27:
c j = p
e1 j
1
p
e2 j
2
¬∑ ¬∑ ¬∑ p
enj
n ,
where those factors pei1
i , pei2
i , ¬∑ ¬∑ ¬∑ not equal to p0
i = 1 are the elementary divisors of the
pi-primary component of G. Thus, the invariant factors depend only on G because they
are deÔ¨Åned in terms of the elementary divisors.
To prove isomorphism, it sufÔ¨Åces, by the fundamental theorem, to prove that the ele-
mentary divisors can be computed from the invariant factors. Since c j = p
e1 j
1
p
e2 j
2
¬∑ ¬∑ ¬∑ p
enj
n ,
the fundamental theorem of arithmetic shows that c j determines all those prime powers
p
ei j
i
which are distinct from 1; that is, the invariant factors c j determine the elementary
divisors.
‚Ä¢
In Example 5.31, we started with elementary divisors and computed invariant factors.
Let us now start with invariant factors and compute elementary divisors.
invariant factors ‚Üîelementary divisors
2 | 6 | 6 = 2 | 2 ¬∑ 3 | 2 ¬∑ 3 ‚Üî(2, 2, 2, 3, 3)
6 | 12 = 2 ¬∑ 3 | 22 ¬∑ 3 ‚Üî(2, 4, 3, 3)
3 | 24 = 3 | 23 ¬∑ 3 ‚Üî(8, 3, 3)
2 | 2 | 18 = 2 | 2 | 2 ¬∑ 32 ‚Üî(2, 2, 2, 9)
2 | 36 = 2 | 22 ¬∑ 32 ‚Üî(2, 4, 9)
72 = 23 ¬∑ 32 ‚Üî(8, 9).
The results of this section will be generalized, in Chapter 9, from Ô¨Ånite abelian groups
to Ô¨Ånitely generated abelian groups, where an abelian group G is Ô¨Ånitely generated if there
are Ô¨Ånitely many elements a1, . . . , an ‚ààG so that every x ‚ààG is a linear combination

Sec. 5.1
Finite Abelian Groups
267
of them: x = 
i miai, where mi ‚ààZ for all i. The basis theorem generalizes: Every
Ô¨Ånitely generated abelian group G is a direct sum of cyclic groups, each of which is a
Ô¨Ånite primary group or an inÔ¨Ånite cyclic group; the fundamental theorem also generalizes:
Given two decompositions of G into a direct sum of cyclic groups (as in the basis theorem),
the number of cyclic summands of each type is the same in both decompositions. The basis
theorem is no longer true for abelian groups that are not Ô¨Ånitely generated; for example,
the additive group Q of rational numbers is not a direct sum of cyclic groups.
EXERCISES
5.1
(i) Let G be an arbitrary, possibly nonabelian, group, and let S and T be normal subgroups
of G. Prove that if S ‚à©T = {1}, then st = ts for all s ‚ààS and t ‚ààT .
Hint. Show that sts‚àí1t‚àí1 ‚ààS ‚à©T .
(ii) Prove that Proposition 5.4 holds for nonabelian groups G if we assume that all the
subgroups Si are normal subgroups.
5.2 Let G be an abelian group, not necessarily primary. DeÔ¨Åne a subgroup S ‚äÜG to be a pure
subgroup if, for all m ‚ààZ,
S ‚à©mG = mS.
Prove that if G is a p-primary abelian group, then a subgroup S ‚äÜG is pure as just deÔ¨Åned if
and only if S ‚à©pnG = pnS for all n ‚â•0 (the deÔ¨Ånition in the text).
5.3 Let G be a possibly inÔ¨Ånite abelian group.
(i) Prove that every direct summand S of G is a pure subgroup.
DeÔ¨Åne the torsion3 subgroup tG of G as
tG = {a ‚ààG : a has Ô¨Ånite order}.
(ii) Prove that tG is a pure subgroup of G. [There exist abelian groups G whose torsion
subgroup tG is not a direct summand (see Exercise 9.1(iii) on page 663); hence, a pure
subgroup need not be a direct summand.]
(iii) Prove that G/tG is an abelian group in which every nonzero element has inÔ¨Ånite order.
5.4 Let p be a prime and let q be relatively prime to p. Prove that if G is a p-group and g ‚ààG,
then there exists x ‚ààG with qx = g.
5.5 Let G = ‚ü®a‚ü©be a cyclic group of Ô¨Ånite order m. Prove that G/nG is a cyclic group of order
d, where d = (m, n).
5.6 For a group G and a positive integer n, deÔ¨Åne
G[n] = {g ‚ààG : gn = 1}.
Prove that G[n] =

am/d 
, where d = (m, n), and conclude that G[n] ‚àº= Id.
5.7 Prove that if B = Bm = ‚ü®x1‚ü©‚äï¬∑ ¬∑ ¬∑ ‚äï‚ü®xbm ‚ü©is a direct sum of bm cyclic groups of order pm,
and if n < m, then the cosets pnxi + pn+1B, for 1 ‚â§i ‚â§bm are a basis for pn B/pn+1B.
Conclude that d(pn Bm) = bm when n < m. [Recall that if G is a Ô¨Ånite abelian group, then
G/pG is a vector space over Fp and d(G) = dim(G/pG).]
3This terminology comes from algebraic topology. To each space X, a sequence of abelian groups is assigned,
called homology groups, and if X is "twisted," then there are elements of Ô¨Ånite order in some of these groups.

268
Groups II
Ch. 5
5.8
(i) If G is a Ô¨Ånite p-primary abelian group, where p is a prime, and if x ‚ààG has largest
order, prove that ‚ü®x‚ü©is a direct summand of G.
(ii) Prove that if G is a Ô¨Ånite abelian group and x ‚ààG has maximal order (that is, there is
no element in G having larger order), then ‚ü®x‚ü©is a direct summand of G.
5.9 Prove that a subgroup of a Ô¨Ånite abelian group is a direct summand if and only if it is a pure
subgroup.
Hint. Modify the proof of the basis theorem, Theorem 5.18.
5.10
(i) If G and H are Ô¨Ånite abelian groups, prove, for all primes p and all n ‚â•0, that
Up(n, G ‚äïH) = Up(n, G) + Up(n, H).
(ii) If A, B, and C are Ô¨Ånite abelian groups, prove that A ‚äïB ‚àº= A ‚äïC implies B ‚àº= C.
(iii) If A and B are Ô¨Ånite abelian groups, prove that A ‚äïA ‚àº= B ‚äïB implies A ‚àº= B.
5.11 If n is a positive integer, then a partition of n is a sequence of positive integers i1 ‚â§i2 ‚â§
¬∑ ¬∑ ¬∑ ‚â§ir with i1 + i2 + ¬∑ ¬∑ ¬∑ + ir = n. If p is a prime, prove that the number of nonisomorphic
abelian groups of order pn is equal to the number of partitions of n.
5.12 Prove that there are, to isomorphism, exactly 14 abelian groups of order 288.
5.13 Prove the uniqueness assertion in the fundamental theorem of arithmetic by applying the fun-
damental theorem of Ô¨Ånite abelian groups to G = In.
5.14
(i) If G is a Ô¨Ånite abelian group, deÔ¨Åne
ŒΩk(G) = the number of elements in G of order k.
Prove that two Ô¨Ånite abelian groups G and G‚Ä≤ are isomorphic if and only if ŒΩk(G) =
ŒΩk(G‚Ä≤) for all integers k.
Hint.
If B is a direct sum of k copies of a cyclic group of order pn, then how many
elements of order pn are in B?
(ii) Give an example of two nonisomorphic not necessarily abelian Ô¨Ånite groups G and G‚Ä≤
for which ŒΩk(G) = ŒΩk(G‚Ä≤) for all integers k.
Hint. Take G of order p3.
5.15 Prove that the additive group Q is not a direct sum: Q Ã∏‚àº= A ‚äïB, where A and B are nonzero
subgroups.
Hint. If a, b ‚ààQ are not zero, then there is c ‚ààQ with a, b ‚àà‚ü®c‚ü©.
5.16 Let G = B1 ‚äïB2 ‚äï¬∑ ¬∑ ¬∑ ‚äïBt, where the Bi are subgroups.
(i) Prove that G[p] = B1[p] ‚äïB2[p] ‚äï¬∑ ¬∑ ¬∑ ‚äïBt[p].
(ii) Prove, for all n ‚â•0 that
pnG ‚à©G[p] =

pnG ‚à©B1[p]

‚äï

pnG ‚à©B2[p]

‚äï¬∑ ¬∑ ¬∑ ‚äï

pnG ‚à©Bt[p]

=

pn B1 ‚à©B1[p]

‚äï

pn B2 ‚à©B2[p]

‚äï¬∑ ¬∑ ¬∑ ‚äï

pn Bt ‚à©Bt[p]

.
(iii) If G is a p-primary abelian group, prove, for all n ‚â•0, that
Up(n, G) = dim
 pnG ‚à©G[p]
pn+1G ‚à©G[p]
	
.

Sec. 5.2
The Sylow Theorems
269
5.2 THE SYLOW THEOREMS
We return to nonabelian groups, and so we revert to the multiplicative notation. The Sylow
theorems are analogs, for Ô¨Ånite nonabelian groups, of the primary components of Ô¨Ånite
abelian groups.
Recall that a group G Ã∏= {1} is called simple if it has no normal subgroups other than {1}
and G itself. We saw, in Proposition 2.107, that the abelian simple groups are precisely the
cyclic groups Ip of prime order p, and we saw, in Theorem 2.112, that An is a nonabelian
simple group for all n ‚â•5. In fact, A5 is the nonabelian simple group of smallest order.
How can we prove that a nonabelian group G of order less than 60 = |A5| is not simple?
Exercise 2.98 on page 114 states that if G is a group of order |G| = mp, where p is prime
and 1 < m < p, then G is not simple. This exercise shows that many of the numbers less
than 60 are not orders of simple groups. After throwing out all prime powers (p-groups
are never nonabelian simple), the only remaining possibilities are
12, 18, 24, 30, 36, 40, 45, 48, 50, 54, 56.
The solution to the exercise uses Cauchy's theorem, which says that G has a subgroup of
order p. We shall see that if G has a subgroup of order pe instead of p, then Exercise 2.98
can be generalized, and the list of candidates can be shortened. What proper subgroups of
G do we know other than cyclic subgroups? The center Z(G) of a group G is a possible
candidate, but this subgroup might not be proper or it might be trivial: if G is abelian, then
Z(G) = G; if G = S3, then Z(G) = {1}. Hence, Z(G) cannot be used to generalize the
exercise.
Trait¬¥e des Substitutions et des ¬¥Equations Alg¬¥ebriques, by C. Jordan, published in 1870,
was the Ô¨Årst book on group theory (more than half of it is devoted to Galois theory, then
called the theory of equations). At about the same time, but too late for publication in
Jordan's book, three fundamental theorems were discovered. In 1868, E. Schering proved
the basis theorem: Every Ô¨Ånite abelian group is a direct product of cyclic groups, each of
prime power order; in 1870, L. Kronecker, unaware of Schering's proof, also proved this
result. In 1878, F. G. Frobenius and L. Stickelberger proved the fundamental theorem of Ô¨Å-
nite abelian groups. In 1872, L. Sylow showed, for every Ô¨Ånite group G and every prime p,
that if pe is the largest power of p dividing |G|, then G has a subgroup of order pe, nowa-
days called a Sylow subgroup; we will use such subgroups to generalize Exercise 2.98. Our
strategy for proving the Sylow theorems works best if we adopt the following deÔ¨Ånition.
DeÔ¨Ånition.
Let p be a prime. A Sylow p-subgroup of a Ô¨Ånite group G is a maximal
p-subgroup P.
Maximality means that if Q is a p-subgroup of G and P ‚â§Q, then P = Q.
It follows from Lagrange's theorem that if pe is the largest power of p dividing |G|,
then a subgroup of order pe, should it exist, is a maximal p-subgroup of G. One virtue
of the present deÔ¨Ånition is that maximal p-subgroups always exist: indeed, we now show

270
Groups II
Ch. 5
that if S is any p-subgroup of G (perhaps S = {1}), then there exists a Sylow p-subgroup
P containing S. If there is no p-subgroup strictly containing S, then S itself is a Sylow
p-subgroup. Otherwise, there is a p-subgroup P1 with S < P1. If P1 is maximal, it is
Sylow, and we are done. Otherwise, there is some p-subgroup P2 with P1 < P2. This
procedure of producing larger and larger p-subgroups Pi must end after a Ô¨Ånite number of
steps, for |Pi| ‚â§|G| for all i; the largest Pi must, therefore, be a Sylow p-subgroup.
Recall that a conjugate of a subgroup H ‚â§G is a subgroup of G of the form
aHa‚àí1 = {aha‚àí1 : h ‚ààH},
where a ‚ààG. The normalizer of H in G is the subgroup
NG(H) = {a ‚ààG : aHa‚àí1 = H},
and Proposition 2.101 states that if H is a subgroup of a Ô¨Ånite group G, then the number
of conjugates of H in G is [G : NG(H)].
It is obvious that H ‚úÅNG(H), and so the quotient group NG(H)/H is deÔ¨Åned.
Lemma 5.33.
Let P be a Sylow p-subgroup of a Ô¨Ånite group G.
(i) Every conjugate of P is also a Sylow p-subgroup of G.
(ii) |NG(P)/P| is prime to p.
(iii) If a ‚ààG has order some power of p and if aPa‚àí1 = P, then a ‚ààP.
Proof.
(i) If a ‚ààG, then aPa‚àí1 is a p-subgroup of G; if it is not a maximal p-subgroup,
then there is a p-subgroup Q with aPa‚àí1 < Q. Hence, P < a‚àí1Qa, contradicting the
maximality of P.
(ii) If p divides |NG(P)/P|, then Cauchy's theorem shows that NG(P)/P contains an
element aP of order p, and hence NG(P)/P contains a subgroup S‚àó= ‚ü®aP‚ü©of order
p. By the correspondence theorem (Theorem 2.76), there is a subgroup S with P ‚â§S ‚â§
NG(P) such that S/P ‚àº= S‚àó. But S is a p-subgroup of NG(P) ‚â§G (by Exercise 2.75 on
page 95) strictly larger than P, and this contradicts the maximality of P. We conclude that
p does not divide |NG(P)/P|.
(iii) By the deÔ¨Ånition of normalizer, the element a lies in NG(P). If a /‚ààP, then the coset
aP is a nontrivial element of NG(P)/P having order some power of p; in light of part (ii),
this contradicts Lagrange's theorem.
‚Ä¢
Since every conjugate of a Sylow p-subgroup is a Sylow p-subgroup, it is reasonable
to let G act by conjugation on the Sylow p-subgroups.
Theorem 5.34 (Sylow).
Let G be a Ô¨Ånite group of order pe1
1 ¬∑ ¬∑ ¬∑ pet
t , and let P be a Sylow
p-subgroup of G for some prime p = p j.
(i) Every Sylow p-subgroup is conjugate to P.

Sec. 5.2
The Sylow Theorems
271
(ii) If there are r j Sylow p j-subgroups, then r j is a divisor of |G|/p
e j
j and
r j ‚â°1 mod p j.
Proof.
Let X = {P1, . . . , Pr j } be the set of all the conjugates of P, where we have
denoted P by P1. If Q is any Sylow p-subgroup of G, then Q acts on X by conjugation:
If a ‚ààQ, then it sends
Pi = gi Pg‚àí1
i
‚Üía

gi Pg‚àí1
i

a‚àí1 = (agi)P(agi)‚àí1 ‚ààX.
By Corollary 2.99, the number of elements in any orbit is a divisor of |Q|; that is, every
orbit has size some power of p (because Q is a p-group). If there is an orbit of size 1, then
there is some Pi with aPia‚àí1 = Pi for all a ‚ààQ. By Lemma 5.33, we have a ‚ààPi for
all a ‚ààQ; that is, Q ‚â§Pi. But Q, being a Sylow p-subgroup, is a maximal p-subgroup
of G, and so Q = Pi. In particular, if Q = P1, then there is only one orbit of size 1,
namely, {P1}, and all the other orbits have sizes that are honest powers of p. We conclude
that |X| = r j ‚â°1 mod p.
Suppose now that there is some Sylow p-subgroup Q that is not a conjugate of P; thus,
Q Ã∏= Pi for any i. Again, we let Q act on X, and again, we ask if there is an orbit of
size 1, say, {Pk}. As in the previous paragraph, this implies Q = Pk, contrary to our
present assumption that Q /‚ààX. Hence, there are no orbits of size 1, which says that each
orbit has size an honest power of p. It follows that |X| = r j is a multiple of p; that is,
r j ‚â°0 mod p, which contradicts the congruence r j ‚â°1 mod p. Therefore, no such Q
can exist, and so all Sylow p-subgroups are conjugate to P.
Finally, since all Sylow p-subgroups are conjugate, we have r j = [G : NG(P)], and so
r j is a divisor of |G|. But r j ‚â°1 mod p j implies (r j, p
e j
j ) = 1, so that Euclid's lemma
gives r j | |G|/p
e j
j .
‚Ä¢
Corollary 5.35.
A Ô¨Ånite group G has a unique Sylow p-subgroup P, for some prime p,
if and only if P ‚úÅG.
Proof.
Assume that P, a Sylow p-subgroup of G, is unique. For each a ‚ààG, the conju-
gate aPa‚àí1 is also a Sylow p-subgroup; by uniqueness, aPa‚àí1 = P for all a ‚ààG, and
so P ‚úÅG.
Conversely, assume that P ‚úÅG. If Q is any Sylow p-subgroup, then Q = aPa‚àí1 for
some a ‚ààG; but aPa‚àí1 = P, by normality, and so Q = P.
‚Ä¢
The following result gives the order of a Sylow subgroup.
Theorem 5.36 (Sylow).
If G is a Ô¨Ånite group of order pem, where p is a prime and
p ‚à§m, then every Sylow p-subgroup P of G has order pe.
Proof.
We Ô¨Årst show that p ‚à§[G : P]. Now
[G : P] = [G : NG(P)][NG(P) : P].

272
Groups II
Ch. 5
The Ô¨Årst factor, [G : NG(P)] = r, is the number of conjugates of P in G, and so p
does not divide [G : NG(P)] because r ‚â°1 mod p. The second factor, [NG(P) : P] =
|NG(P)/P|, is also not divisible by p, by Lemma 5.33. Therefore, p does not divide
[G : P], by Euclid's lemma.
Now |P| = pk for some k ‚â§e, and so
[G : P] = |G|/|P| = pem/pk = pe‚àíkm.
Since p does not divide [G : P], we must have k = e; that is, |P| = pe.
‚Ä¢
Example 5.37.
(i) Let G = S4. Now |S4| = 24 = 233. Thus, a Sylow 2-subgroup of S4 has order 8.
We have seen, in Exercise 2.83 on page 113, that S4 contains a copy of the dihedral group
D8 consisting of the symmetries of a square. The Sylow theorem says that all subgroups
of order 8 are conjugate, hence isomorphic, to D8. Moreover, the number r of Sylow 2-
subgroups is a divisor of 24 congruent to 1 mod 2; that is, r is an odd divisor of 24. Since
r Ã∏= 1 (see Exercise 5.17 on page 277), there are exactly three Sylow 2-subgroups.
(ii) If G is a Ô¨Ånite abelian group, then a Sylow p-subgroup is just its p-primary component
(since G is abelian, every subgroup is normal, and so there is a unique Sylow p-subgroup
for every prime p).
‚óÄ
Here is a second proof of the last Sylow theorem, due to H. Wielandt.
Theorem 5.38.
If G is a Ô¨Ånite group of order pem, where p is a prime and p ‚à§m, then
G has a subgroup of order pe.
Proof.
If X is the family of all those subsets of G having exactly pe elements, then
|X| =
pem
pe

; by Exercise 1.29 on page 14, p ‚à§|X|. Now G acts on X: deÔ¨Åne gB, for
g ‚ààG and B ‚ààX, by
gB = {gb : b ‚ààB}.
If p divides |O(B)| for every B ‚ààX, where O(B) is the orbit of B, then p is a divisor
of |X|, for X is the disjoint union of orbits, by Proposition 2.97. As p ‚à§|X|, there exists
a subset B with |B| = pe and with |O(B)| not divisible by p. If G B is the stabilizer of
this subset B, then Theorem 2.98 gives [G : G B] = |O(B)|, and so |G| = |G B| ¬∑ |O(B)|.
Since pe | |G| and p ‚à§O(B)|, repeated application of Euclid's lemma gives pe | |G B|.
Therefore, pe ‚â§|G B|.
For the reverse inequality, choose an element b ‚ààB and deÔ¨Åne a function œÑ : G B ‚ÜíB
by g ‚Üígb. Note that œÑ(g) = gb ‚ààgB = B, for g ‚ààG B, the stabilizer of B. If g,
h ‚ààG B and h Ã∏= g, then œÑ(h) = hb Ã∏= gb = œÑ(g); that is, œÑ is an injection. We conclude
that |G B| ‚â§|B| = pe, and so G B is a subgroup of G of order pe.
‚Ä¢

Sec. 5.2
The Sylow Theorems
273
Proposition 5.39.
A Ô¨Ånite group G all of whose Sylow subgroups are normal is the direct
product of its Sylow subgroups.
Proof.
Let |G| = pe1
1 ¬∑ ¬∑ ¬∑ pet
t and let G pi be the Sylow pi-subgroup of G. We use Ex-
ercise 5.1 on page 267, the generalization of Proposition 5.4 to nonabelian groups. The
subgroup S generated by all the Sylow subgroups is G, for pei
i
| |S| for all i. Finally, if
x ‚ààG pi
‚ü®!
jÃ∏=i G p j ‚ü©, then x = si ‚ààG pi and x = 
jÃ∏=i s j, where s j ‚ààG p j . Now
x pn
i = 1 for some n ‚â•1. On the other hand, there is some power of p j, say q j, with
s
q j
j
= 1 for all j. Since the s j commute with each other, by Exercise 5.1 on page 267, we
have 1 = xq = (
jÃ∏=i s j)q, where q = 
jÃ∏=i q j. Since (pn
i , q) = 1, there are integers
u and v with 1 = upn
i + vq, and so x = x1 = xupn
i xvq = 1. Therefore, G is the direct
product of its Sylow subgroups.
‚Ä¢
We can now generalize Exercise 2.98 on page 114 and its solution.
Lemma 5.40.
There is no nonabelian simple group G of order |G| = pem, where p is
prime, p ‚à§m, and pe ‚à§(m ‚àí1)!.
Proof.
We claim that if p is a prime, then every p-group G with |G| > p is not sim-
ple. Theorem 2.75 says that the center, Z(G), is nontrivial. But Z(G) ‚úÅG, so that if
Z(G) is a proper subgroup, then G is not simple. If Z(G) = G, then G is abelian, and
Proposition 2.78 says that G is not simple unless |G| = p.
Suppose that such a simple group G exists. By Sylow's theorem, G contains a subgroup
P of order pe, hence of index m. We may assume that m > 1, for nonabelian p-groups are
never simple. By Theorem 2.88, there exists a homomorphism œï : G ‚ÜíSm with ker œï ‚â§
P. Since G is simple, however, it has no proper normal subgroups; hence ker œï = {1} and
œï is an injection; that is, G ‚àº= œï(G) ‚â§Sm. By Lagrange's theorem, pem | m!, and so
pe | (m ‚àí1)!, contrary to the hypothesis.
‚Ä¢
Proposition 5.41.
There are no nonabelian simple groups of order less than 60.
Proof.
The reader may now check that the only integers n between 2 and 59, neither a
prime power nor having a factorization of the form n = pem as in the statement of the
lemma, are n = 30, 40, and 56. By the lemma, these three numbers are the only candidates
for orders of nonabelian simple groups of order < 60.
Assume there is a simple group G of order 30. Let P be a Sylow 5-subgroup of G,
so that |P| = 5. The number r5 of conjugates of P is a divisor of 30 and r5 ‚â°1 mod 5.
Now r5 Ã∏= 1 lest P ‚úÅG, so that r5 = 6. By Lagrange's theorem, the intersection of
any two of these is trivial (intersections of Sylow subgroups can be more complicated;
see Exercise 5.18 on page 277). There are four nonidentity elements in each of these
subgroups, and so there are 6 √ó 4 = 24 nonidentity elements in their union. Similarly,
the number r3 of Sylow 3-subgroups of G is 10 (for r3 Ã∏= 1, r3 is a divisor of 30, and
r3 ‚â°1 mod 3). There are two nonidentity elements in each of these subgroups, and so the
union of these subgroups has 20 nonidentity elements. We have exceeded the number of
elements in G, and so G cannot be simple.

274
Groups II
Ch. 5
Let G be a group of order 40, and let P be a Sylow 5-subgroup of G. If r is the number
of conjugates of P, then r | 40 and r ‚â°1 mod 5. These conditions force r = 1, so that
P ‚úÅG; therefore, no simple group of order 40 can exist.
Finally, assume there is a simple group G of order 56. If P is a Sylow 7-subgroup of
G, then P must have r7 = 8 conjugates (for r7 | 56 and r7 ‚â°1 mod 7). Since these
groups are cyclic of prime order, the intersection of any pair of them is {1}, and so there
are 48 nonidentity elements in their union. Thus, adding the identity, we have accounted
for 49 elements of G. Now a Sylow 2-subgroup Q has order 8, and so it contributes seven
more nonidentity elements, giving 56 elements. But there is a second Sylow 2-subgroup,
lest Q ‚úÅG, and we have exceeded our quota. Therefore, there is no simple group of
order 56.
‚Ä¢
The "converse" of Lagrange's theorem is false: If G is a Ô¨Ånite group of order n, and
if d | n, then G may not have a subgroup of order d. For example, we proved, in Propo-
sition 2.64, that the alternating group A4 is a group of order 12 having no subgroup of
order 6.
Proposition 5.42.
Let G be a Ô¨Ånite group. If p is a prime and if pk divides |G|, then G
has a subgroup of order pk.
Proof.
If |G| = pem, where p ‚à§m, then a Sylow p-subgroup P of G has order pe.
Hence, if pk divides |G|, then pk divides |P|. By Proposition 2.106, P has a subgroup of
order pk; a fortiori, G has a subgroup of order pk.
‚Ä¢
What examples of p-groups have we seen? Of course, cyclic groups of order pn are
p-groups, as is any direct product of copies of these. By the fundamental theorem, this
describes all (Ô¨Ånite) abelian p-groups. The only nonabelian examples we have seen so
far are the dihedral groups D2n (which are 2-groups when n is a power of 2) and the
quaternions Q of order 8 (of course, for every 2-group A, the direct products D8 √ó A and
Q √ó A are also nonabelian 2-groups). Here are some new examples.
DeÔ¨Ånition.
A unitriangular matrix over a Ô¨Åeld k is an upper triangular matrix each of
whose diagonal terms is 1. DeÔ¨Åne UT(n, k) to be the set of all n √ón unitriangular matrices
over k.
Remark.
We can generalize this deÔ¨Ånition by allowing k to be any commutative ring.
For example, the group UT(n, Z) is an interesting group.
‚óÄ
Proposition 5.43.
If k is a Ô¨Åeld, then UT(n, k) is a subgroup of GL(n, k).
Proof.
Of course, the identity I is unitriangular, so that I ‚ààUT(n, k). If A ‚ààUT(n, k),
then A = I + N, where N is strictly upper triangular; that is, N is an upper triangular
matrix having only 0's on its diagonal. Note that the sum and product of strictly upper
triangular matrices is again strictly upper triangular.

Sec. 5.2
The Sylow Theorems
275
Let e1, . . . , en be the standard basis of kn. If N is strictly upper triangular, deÔ¨Åne
T : kn ‚Üíkn by T (ei) = Nei, where ei is regarded as a column matrix. Now T satisÔ¨Åes
the equations, for all i,
T (e1) = 0
and
T (ei+1) ‚àà‚ü®e1, . . . , ei‚ü©.
It is easy to see, by induction on i, that
T i(e j) = 0 for all j ‚â§i.
It follows that T n = 0 and, hence, that N n = 0. Thus, if A ‚ààUT(n, k), then A = I + N,
where N n = 0.
To see that UT(n, k) is a subgroup of GL(n, k), Ô¨Årst note that (I + N)(I + M) =
I + (N + M + N M) is unitriangular. Second, we show that if A is unitriangular, then
it is nonsingular and that its inverse is also unitriangular. In analogy to the power series
expansion 1/(1 + x) = 1 ‚àíx + x2 ‚àíx3 + ¬∑ ¬∑ ¬∑ , we deÔ¨Åne the inverse of A = I + N to be
B = I ‚àíN + N 2 ‚àíN 3 +¬∑ ¬∑ ¬∑ (note that this series stops after n ‚àí1 terms because N n = 0),
The reader may now check that B A = I = AB, so that B = A‚àí1. Moreover, N strictly
upper triangular implies that ‚àíN + N 2 ‚àíN 3 +¬∑ ¬∑ ¬∑¬± N n‚àí1 is also strictly upper triangular,
and so A‚àí1 is unitriangular. (Alternatively, for readers familiar with linear algebra, we
know that A is nonsingular, because its determinant is 1, and the formula for A‚àí1 in terms
of its adjoint [the matrix of cofactors] shows that A‚àí1 is unitriangular.) Hence, UT(n, k)
is a subgroup of GL(n, k).
‚Ä¢
Proposition 5.44.
Let q = pe, where p is a prime. For each n ‚â•2, UT(n, Fq) is a
p-group of order q(n
2) = qn(n‚àí1)/2.
Proof.
The number of entries in an n √ó n unitriangular matrix lying strictly above the
diagonal is
n
2

= 1
2n(n ‚àí1) (throw away n diagonal entries from the total of n2 entries;
half of the remaining n2 ‚àín entries are above the diagonal). Since each of these entries
can be any element of Fq, there are exactly q(n
2) n √ó n unitriangular matrices over Fq, and
so this is the order of UT(n, Fq).
‚Ä¢
Recall Exercise 2.26 on page 62: If G is a group and x2 = 1 for all x ‚ààG, then G is
abelian. We now ask whether a group G satisfying x p = 1 for all x ‚ààG, where p is an
odd prime, must also be abelian.
Proposition 5.45.
If p is an odd prime, then there exists a nonabelian group G of order
p3 with x p = 1 for all x ‚ààG.
Proof.
If G = UT(3, Fp), then |G| = p3. Now G is not abelian; for example, the
matrices
Ô£Æ
Ô£∞
1
1
0
0
1
1
0
0
1
Ô£π
Ô£ª
and
Ô£Æ
Ô£∞
1
0
1
0
1
1
0
0
1
Ô£π
Ô£ª

276
Groups II
Ch. 5
do not commute. If A ‚ààG, then A = I + N; since p is an odd prime, p ‚â•3, and so N p =
0. The set of all matrices of the form a0I + a1N + ¬∑ ¬∑ ¬∑ + am N m, where ai ‚ààFp, is easily
seen to be a commutative ring in which pM = 0 for all M. But Proposition 3.2(vi) says
that the binomial theorem holds in every commutative ring; since p |
p
i

when 1 < i < p,
by Proposition 1.12, we have
Ap = (I + N)p = I p + N p = I.
‚Ä¢
Theorem 5.46.
Let Fq denote the Ô¨Ånite Ô¨Åeld with q elements. Then
|GL(n, Fq)| = (qn ‚àí1)(qn ‚àíq)(qn ‚àíq2) ¬∑ ¬∑ ¬∑ (qn ‚àíqn‚àí1).
Proof.
Let V be an n-dimensional vector space over Fq. We show Ô¨Årst that there is a
bijection : GL(n, Fq) ‚ÜíB, where B is the set of all bases of V . Choose, once for all, a
basis e1, . . . , en of V . If T ‚ààGL(n, Fq), deÔ¨Åne
(T ) = T e1, . . . , T en.
By Lemma 3.103, (T ) ‚ààB because T , being nonsingular, carries a basis into a basis.
But  is a bijection, for given a basis v1, . . . , vn, there is a unique linear transformation S,
necessarily nonsingular (by Lemma 3.103), with Sei = vi for all i (by Theorem 3.92).
Our problem now is to count the number of bases v1, . . . , vn of V . There are qn vectors
in V , and so there are qn ‚àí1 candidates for v1 (the zero vector is not a candidate). Having
chosen v1, we see that the candidates for v2 are those vectors not in ‚ü®v1‚ü©, the subspace
spanned by v1; there are thus qn ‚àíq candidates for v2. More generally, having chosen a
linearly independent list v1, . . . , vi, then vi+1 can be any vector not in ‚ü®v1, . . . , vi‚ü©. Thus,
there are qn ‚àíqi candidates for vi+1. The result follows by induction on n.
‚Ä¢
Theorem 5.47.
If p is a prime and q = pm, then the unitriangular group UT(n, Fq) is a
Sylow p-subgroup of GL(n, Fq).
Proof.
Since qn ‚àíqi = qi(qn‚àíi ‚àí1), the highest power of p dividing | GL(n, Fq)| is
qq2q3 ¬∑ ¬∑ ¬∑ qn‚àí1 = q(n
2).
But |UT(n, Fq)| = q(n
2), and so it must be a Sylow p-subgroup.
‚Ä¢
Corollary 5.48.
If p is a prime and G is a Ô¨Ånite p-group, then G is isomorphic to a
subgroup of the unitriangular group UT(|G|, Fp).
Proof.
We show Ô¨Årst, for every m ‚â•1, that the symmetric group Sm can be imbedded
in GL(m, k), where k is a Ô¨Åeld. Let V be an m-dimensional vector space over k, and
let v1, . . . , vm be a basis of V . DeÔ¨Åne a function œï : Sm ‚ÜíGL(V ) by œÉ ‚ÜíTœÉ, where
TœÉ : vi ‚ÜívœÉ(i) for all i. It is easy to see that œï is an injective homomorphism. By Cayley's

Sec. 5.2
The Sylow Theorems
277
theorem, G can be imbedded in SG; hence, G can be imbedded in GL(m, Fp), where
m = |G|. Now G is contained in some Sylow p-subgroup P of GL(m, Fp), for every
p-subgroup lies in some Sylow p-subgroup. Since all Sylow p-subgroups are conjugate,
there is a ‚ààGL(m, Fp) with P = a

UT(m, Fp)

a‚àí1. Therefore,
G ‚àº= a‚àí1Ga ‚â§a‚àí1Pa ‚â§UT(m, Fp).
‚Ä¢
A natural question is to Ô¨Ånd the Sylow subgroups of symmetric groups. This can be
done, and the answer is in terms of a construction called wreath product (see Rotman, An
Introduction to the Theory of Groups, page 176).
EXERCISES
5.17 How many Sylow 2-subgroups does S4 have?
5.18 Give an example of a Ô¨Ånite group G having Sylow p-subgroups (for some prime p) P, Q and
R such that P ‚à©Q = {1} and P ‚à©R Ã∏= {1}.
Hint. Consider S3 √ó S3.
5.19 A subgroup H of a group G is called characteristic if œï(H) ‚â§H for every isomorphism
œï : G ‚ÜíG. A subgroup S of a group G is called fully invariant if œï(S) ‚â§S for every
homomorphism œï : G ‚ÜíG.
(i) Prove that every fully invariant subgroup is a characteristic subgroup, and that every
characteristic subgroup is a normal subgroup.
(ii) Prove that the commutator subgroup, G‚Ä≤, is a normal subgroup of G by showing that it
is a fully invariant subgroup.
(iii) Give an example of a group G having a normal subgroup H that is not a characteristic
subgroup.
(iv) Prove that Z(G), the center of a group G, is a characteristic subgroup (and so Z(G)‚úÅG),
but that it need not be a fully invariant subgroup.
Hint. Let G = S3 √ó I2.
(v) For any group G, prove that if H ‚úÅG, then Z(H) ‚úÅG.
5.20 If G is an abelian group, prove, for all positive integers m, that mG and G[m] are fully invari-
ant subgroups.
5.21 (Frattini Argument). Let K be a normal subgroup of a Ô¨Ånite group G. If P is a Sylow
p-subgroup of K for some prime p, prove that
G = K NG(P),
where K NG(P) = {ab : a ‚ààK and b ‚ààNG(P)}.
Hint. If g ‚ààG, then gPg‚àí1 is a Sylow p-subgroup of K, and so it is conjugate to P in K.
5.22 Prove that UT(3, 2) ‚àº= D8, and conclude that D8 is a Sylow 2-subgroup of GL(3, 2).
Hint. You may use the fact that the only nonabelian groups of order 8 are D8 and Q.
5.23
(i) Prove that if d is a positive divisor of 24, then S4 has a subgroup of order d.
(ii) If d Ã∏= 4, prove that any two subgroups of S4 having order d are isomorphic.

278
Groups II
Ch. 5
5.24
(i) Find a Sylow 3-subgroup of S6.
Hint. {1, 2, 3, 4, 5, 6} = {1, 2, 3} ‚à™{4, 5, 6}.
(ii) Show that a Sylow 2-subgroup of S6 is isomorphic to D8 √ó I2.
Hint. {1, 2, 3, 4, 5, 6} = {1, 2, 3, 4} ‚à™{5, 6}.
5.25 Let Q be a normal p-subgroup of a Ô¨Ånite group G. Prove that Q ‚â§P for every Sylow
p-subgroup P of G.
Hint. Use the fact that any other Sylow p-subgroup of G is conjugate to P.
5.26
(i) Let G be a Ô¨Ånite group and let P be a Sylow p-subgroup of G. If H ‚úÅG, prove that
H P/H is a Sylow p-subgroup of G/H and H ‚à©P is a Sylow p-subgroup of H.
Hint. Show that [G/H : H P/H] and [H : H ‚à©P] are prime to p.
(ii) Let P be a Sylow p-subgroup of a Ô¨Ånite group G. Give an example of a subgroup H of
G with H ‚à©P not a Sylow p-subgroup of H.
Hint. Choose a subgroup H of S4 with H ‚àº= S3, and Ô¨Ånd a Sylow 3-subgroup P of S4
with H ‚à©P = {1}.
5.27 Prove that a Sylow 2-subgroup of A5 has exactly Ô¨Åve conjugates.
5.28 Prove that there are no simple groups of order 96, 120, 300, 312, or 1000.
Hint. Some of these are not tricky.
5.29 Let G be a group of order 90.
(i) If a Sylow 5-subgroup P of G is not normal, prove that it has six conjugates.
Hint. If P has 18 conjugates, there are 72 elements in G of order 5. Show that G has
more than 18 other elements.
(ii) Prove that G is not simple.
Hint. Use Exercises 2.95(ii) and 2.96(ii) on page 114.
5.30 Prove that there is no simple group of order 120.
5.31 Prove that there is no simple group of order 150.
5.32 If H is a proper subgroup of a Ô¨Ånite group G, prove that G is not the union of all the conjugates
of H: that is, G Ã∏= !
x‚ààG x Hx‚àí1.
5.3 THE JORDAN-H ¬®OLDER THEOREM
Galois introduced groups to investigate polynomials in k[x], where k is a Ô¨Åeld of charac-
teristic 0, and he saw that such a polynomial is solvable by radicals if and only if its Galois
group is a solvable group. Solvable groups are an interesting family of groups in their own
right, and we now examine them a bit more.
Recall that a normal series of a group G is a Ô¨Ånite sequence of subgroups, G =
G0, G1, G2, . . . , Gn = {1}, with
G = G0 ‚â•G1 ‚â•G2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gn = {1}
and Gi+1‚úÅGi for all i. The factor groups of the series are the groups G0/G1, G1/G2, . . .,
Gn‚àí1/Gn, the length of the series is the number of strict inclusions (equivalently, the length

Sec. 5.3
The Jordan-H¬®older Theorem
279
is the number of nontrivial factor groups), and G is solvable if it has a normal series whose
factor groups are cyclic of prime order.
We begin with a technical result that generalizes the second isomorphism theorem, for
we will want to compare different normal series of a group.
Lemma 5.49 (Zassenhaus Lemma).
Given four subgroups A ‚úÅA‚àóand B ‚úÅB‚àóof a
group G, then A(A‚àó‚à©B) ‚úÅA(A‚àó‚à©B‚àó), B(B‚àó‚à©A) ‚úÅB(B‚àó‚à©A‚àó), and there is an
isomorphism
A(A‚àó‚à©B‚àó)
A(A‚àó‚à©B)
‚àº= B(B‚àó‚à©A‚àó)
B(B‚àó‚à©A) .
Remark.
The Zassenhaus lemma is sometimes called the butterÔ¨Çy lemma because of the
following picture. I confess that I have never liked this picture; it doesn't remind me of a
butterÔ¨Çy, and it doesn't help me understand or remember the proof.
A(A‚àó‚à©B‚àó)












B(A‚àó‚à©B‚àó)

A‚àó‚à©B‚àó
A(A‚àó‚à©B)









B(A ‚à©B‚àó)

A
D = (A‚àó‚à©B)(A ‚à©B‚àó)











B
A ‚à©B‚àó
A‚àó‚à©B
The isomorphism is symmetric in the sense that the right side is obtained from the left
by interchanging the symbols A and B.
‚óÄ
Proof.
We claim that (A ‚à©B‚àó)‚úÅ(A‚àó‚à©B‚àó): that is, if c ‚ààA ‚à©B‚àóand x ‚ààA‚àó‚à©B‚àó, then
xcx‚àí1 ‚ààA ‚à©B‚àó. Now xcx‚àí1 ‚ààA because c ‚ààA, x ‚ààA‚àó, and A ‚úÅA‚àó; but also xcx‚àí1 ‚àà
B‚àó, because c, x ‚ààB‚àó. Hence, (A ‚à©B‚àó) ‚úÅ(A‚àó‚à©B‚àó); similarly, (A‚àó‚à©B) ‚úÅ(A‚àó‚à©B‚àó).
Therefore, the subset D, deÔ¨Åned by D = (A ‚à©B‚àó)(A‚àó‚à©B), is a normal subgroup of
A‚àó‚à©B‚àó, because it is generated by two normal subgroups.
Using the symmetry in the remark, it sufÔ¨Åces to show that there is an isomorphism
A(A‚àó‚à©B‚àó)
A(A‚àó‚à©B) ‚ÜíA‚àó‚à©B‚àó
D
.
DeÔ¨Åne œï : A(A‚àó‚à©B‚àó) ‚Üí(A‚àó‚à©B‚àó)/D by œï : ax ‚Üíx D, where a ‚ààA and x ‚ààA‚àó‚à©B‚àó.
Now œï is well-deÔ¨Åned: if ax = a‚Ä≤x‚Ä≤, where a‚Ä≤ ‚ààA and x‚Ä≤ ‚ààA‚àó‚à©B‚àó, then (a‚Ä≤)‚àí1a =
x‚Ä≤x‚àí1 ‚ààA ‚à©(A‚àó‚à©B‚àó) = A ‚à©B‚àó‚â§D; also, œï is a homomorphism: axa‚Ä≤x‚Ä≤ = a‚Ä≤‚Ä≤xx‚Ä≤,
where a‚Ä≤‚Ä≤ = a(xa‚Ä≤x‚àí1) ‚ààA (because A ‚úÅA‚àó), and so œï(axa‚Ä≤x‚Ä≤) = œï(a‚Ä≤‚Ä≤xx‚Ä≤) = xx‚Ä≤D =
œï(ax)œï(a‚Ä≤x‚Ä≤). It is routine to check that œï is surjective and that ker œï = A(A‚àó‚à©B). The
Ô¨Årst isomorphism theorem completes the proof.
‚Ä¢
The reader should check that the Zassenhaus lemma implies the second isomorphism
theorem: If S and T are subgroups of a group G with T ‚úÅG, then T S/T ‚àº= S/(S ‚à©T );
set A‚àó= G, A = T , B‚àó= S, and B = S ‚à©T .

280
Groups II
Ch. 5
DeÔ¨Ånition.
A composition series is a normal series all of whose nontrivial factor groups
are simple. The nontrivial factor groups of a composition series are called composition
factors of G.
A group need not have a composition series; for example, the abelian group Z has no
composition series. However, every Ô¨Ånite group does have a composition series.
Proposition 5.50.
Every Ô¨Ånite group G has a composition series.
Proof.
If the proposition is false, let G be a least criminal; that is, G is a Ô¨Ånite group of
smallest order that does not have a composition series. Now G is not simple, otherwise
G > {1} is a composition series. Hence, G has a proper normal subgroup H; we may
assume that H is a maximal normal subgroup, so that G/H is a simple group. But |H| <
|G|, so that H does have a composition series: say, H = H0 > H1 > ¬∑ ¬∑ ¬∑ > {1}, and
G > H0 > H1 > ¬∑ ¬∑ ¬∑ > {1} is a composition series for G, a contradiction.
‚Ä¢
A group G is solvable if it has a normal series with factor groups cyclic of prime order.
As cyclic groups of prime order are simple groups, a normal series as in the deÔ¨Ånition of
solvable group is a composition series, and so composition factors of G are cyclic groups
of prime order.
Here are two composition series of G = ‚ü®a‚ü©, a cyclic group of order 30 (note that
normality of subgroups is automatic because G is abelian). The Ô¨Årst is
G = ‚ü®a‚ü©‚â•‚ü®a2‚ü©‚â•‚ü®a10‚ü©‚â•{1};
the factor groups of this series are ‚ü®a‚ü©/‚ü®a2‚ü©‚àº= I2, ‚ü®a2‚ü©/‚ü®a10‚ü©‚àº= I5, and ‚ü®a10‚ü©/{1} ‚àº=
‚ü®a10‚ü©‚àº= I3. Another normal series is
G = ‚ü®a‚ü©‚â•‚ü®a5‚ü©‚â•‚ü®a15‚ü©‚â•{1};
the factor groups of this series are ‚ü®a‚ü©/‚ü®a5‚ü©‚àº= I5, ‚ü®a5‚ü©/‚ü®a15‚ü©‚àº= I3, and ‚ü®a15‚ü©/{1} ‚àº=
‚ü®a15‚ü©‚àº= I2. Notice that the same factor groups arise, although the order in which they arise
is different. We will see that this phenomenon always occurs: Different composition series
of the same group have the same factor groups. This is the Jordan-H¬®older theorem, and
the next deÔ¨Ånition makes its statement more precise.
DeÔ¨Ånition.
Two normal series of a group G are equivalent if there is a bijection be-
tween the sets of nontrivial factor groups of each so that corresponding factor groups are
isomorphic.
The Jordan-H¬®older theorem says that any two composition series of a group are equiv-
alent. It will be more efÔ¨Åcient to prove a more general theorem, due to Schreier.
DeÔ¨Ånition.
A reÔ¨Ånement of a normal series is a normal series G = N0, N1, . . ., Nk = {1}
having the original series as a subsequence.

Sec. 5.3
The Jordan-H¬®older Theorem
281
In other words, a reÔ¨Ånement of a normal series is a new normal series obtained from the
original by inserting more subgroups.
Notice that a composition series admits only insigniÔ¨Åcant reÔ¨Ånements; one can merely
repeat terms (if Gi/Gi+1 is simple, then it has no proper nontrivial normal subgroups and,
hence, there is no intermediate subgroup L with Gi > L > Gi+1 and L ‚úÅGi). Therefore,
any reÔ¨Ånement of a composition series is equivalent to the original composition series.
Theorem 5.51 (Schreier ReÔ¨Ånement Theorem).
Any two normal series
G = G0 ‚â•G1 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gn = {1}
and
G = N0 ‚â•N1 ‚â•¬∑ ¬∑ ¬∑ ‚â•Nk = {1}
of a group G have equivalent reÔ¨Ånements.
Proof.
We insert a copy of the second series between each pair of adjacent terms in the
Ô¨Årst series. In more detail, for each i ‚â•0, deÔ¨Åne
Gi j = Gi+1(Gi ‚à©N j)
(this is a subgroup because Gi+1 ‚úÅGi). Note that
Gi0 = Gi+1(Gi ‚à©N0) = Gi+1Gi = Gi,
because N0 = G, and that
Gik = Gi+1(Gi ‚à©Nk) = Gi+1,
because Nk = {1}. Therefore, the series of Gi j is a subsequence of the series of Gi:
¬∑ ¬∑ ¬∑ ‚â•Gi = Gi0 ‚â•Gi1 ‚â•Gi2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gik = Gi+1 ‚â•¬∑ ¬∑ ¬∑ .
Similarly, there is a subsequence of the second series arising from subgroups
Npq = Np+1(Np ‚à©Gq).
Both subsequences have nk terms. For each i, j, the Zassenhaus lemma, for the four
subgroups Gi+1 ‚úÅGi and N j+1 ‚úÅN j, says both subsequences are normal series, hence
are reÔ¨Ånements, and there is an isomorphism
Gi+1(Gi ‚à©N j)
Gi+1(Gi ‚à©N j+1)
‚àº=
N j+1(N j ‚à©Gi)
N j+1(N j ‚à©Gi+1);
that is,
Gi, j/Gi, j+1 ‚àº= N j,i/N j,i+1.
The association Gi, j/Gi, j+1 ‚ÜíN j,i/N j,i+1 is a bijection showing that the two reÔ¨Åne-
ments are equivalent.
‚Ä¢

282
Groups II
Ch. 5
Theorem 5.52 (Jordan-H¬®older4 Theorem).
Any two composition series of a group G
are equivalent. In particular, the length of a composition series, if one exists, is an invariant
of G.
Proof.
As we remarked earlier, any reÔ¨Ånement of a composition series is equivalent to
the original composition series. It now follows from Schreier's theorem that any two com-
position series are equivalent.
‚Ä¢
Here is a new proof of the fundamental theorem of arithmetic.
Corollary 5.53.
Every integer n ‚â•2 has a factorization into primes, and the prime
factors are uniquely determined by n.
Proof.
Since the group In is Ô¨Ånite, it has a composition series; let S1, . . . , St be the factor
groups. Now an abelian group is simple if and only if it is of prime order, by Proposi-
tion 2.107; since n = |In| is the product of the orders of the factor groups (see Exercise 5.36
on page 287), we have proved that n is a product of primes. Moreover, the Jordan-H¬®older
theorem gives the uniqueness of the (prime) orders of the factor groups.
‚Ä¢
Example 5.54.
(i) Nonisomorphic groups can have the same composition factors. For example, both I4
and V have composition series whose factor groups are I2, I2.
(ii) Let G = GL(2, F4) be the general linear group of all 2 √ó 2 nonsingular matrices with
entries in the Ô¨Åeld F4 with four elements. Now det: G ‚Üí(F4)√ó, where (F4)√ó ‚àº= I3 is
the multiplicative group of nonzero elements of F4. Since ker det = SL(2, F4), the special
linear group consisting of those matrices of determinant 1, there is a normal series
G = GL(2, F4) ‚â•SL(2, F4) ‚â•{1}.
The factor groups of this normal series are I3 and SL(2, F4). It is true that SL(2, F4)
is a nonabelian simple group [in fact, Corollary 5.68 says that SL(2, F4) ‚àº= A5], and so
this series is a composition series. We cannot yet conclude that G is not solvable, for the
deÔ¨Ånition of solvability requires that there be some composition series, not necessarily this
one, having factor groups of prime order. However, the Jordan-H¬®older theorem says that
if one composition series of G has all its factor groups of prime order, then so does every
other composition series. We may now conclude that GL(2, F4) is not a solvable group. ‚óÄ
We now discuss the importance of the Jordan-H¬®older theorem in group theory.
DeÔ¨Ånition.
If G is a group and K ‚úÅG, then G is called an extension of K by G/K.
4In 1868, C. Jordan proved that the orders of the factor groups of a composition series depend only on G and
not upon the composition series; in 1889, O. H¬®older proved that the factor groups themselves, to isomorphism,
do not depend upon the composition series.

Sec. 5.3
The Jordan-H¬®older Theorem
283
With this terminology, Exercise 2.75 on page 95 says that an extension of one p-group
by another p-group is itself a p-group, and Proposition 4.24 says that any extension of one
solvable group by another is itself a solvable group.
The study of extensions involves the inverse question: How much of G can be recovered
from a normal subgroup K and the quotient Q = G/K? For example, we do know that if
K and Q are Ô¨Ånite, then |G| = |K||Q|.
Example 5.55.
(i) The direct product K √ó Q is an extension of K by Q (and K √ó Q is an extension of Q
by K).
(ii) Both S3 and I6 are extensions of I3 by I2. On the other hand, I6 is an extension of I2
by I3, but S3 is not, for S3 contains no normal subgroup of order 2.
‚óÄ
We have just seen, for any given pair of groups K and Q, that an extension of K by
Q always exists (the direct product), but there may be nonisomorphic such extensions.
Hence, if we view an extension of K by Q as a "product" of K and Q, then this product is
not single-valued. The extension problem is to classify all possible extensions of a given
pair of groups K and Q.
Suppose that a group G has a normal series
G = K0 ‚â•K1 ‚â•K2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Kn‚àí1 ‚â•Kn = {1}
with factor groups Q1, . . . , Qn, where
Qi = Ki‚àí1/Ki
for all i ‚â•1. Now Kn = {1}, so that Kn‚àí1 = Qn, but something more interesting occurs
next: Kn‚àí2/Kn‚àí1 = Qn‚àí1, so that Kn‚àí2 is an extension of Kn‚àí1 by Qn‚àí1. If we could
solve the extension problem, then we could recapture Kn‚àí2 from Kn‚àí1 and Qn‚àí1‚Äîthat is,
from Qn and Qn‚àí1. Next, observe that Kn‚àí3/Kn‚àí2 = Qn‚àí2, so that Kn‚àí3 is an extension
of Kn‚àí2 by Qn‚àí2. If we could solve the extension problem, then we could recapture
Kn‚àí3 from Kn‚àí2 and Qn‚àí2; that is, we could recapture Kn‚àí3 from Qn, Qn‚àí1, and Qn‚àí2.
Climbing up the composition series in this way, we end with G = K0 being recaptured
from Qn, Qn‚àí1, . . . , Q1. Thus, G is a "product" of the factor groups. If the normal
series is a composition series, then the Jordan-H¬®older theorem says that the factors in this
product (that is, the composition factors of G) are uniquely determined by G. Therefore,
we could survey all Ô¨Ånite groups if we knew the Ô¨Ånite simple groups and if we could solve
the extension problem. Now all the Ô¨Ånite simple groups were classiÔ¨Åed in the 1980s; this
theorem, one of the deepest theorems in mathematics, gives a complete list of all the Ô¨Ånite
simple groups, along with interesting properties of them. In a sense, the extension problem
has also been solved. In Chapter 10, we will give a solution to the extension problem, due
to Schreier, which describes all possible multiplication tables for extensions; this study
leads to cohomology of groups and the Schur-Zassenhaus theorem. On the other hand, the
extension problem is unsolved in that no one knows a way, given K and Q, to compute the
exact number of nonisomorphic extensions of K by Q.

284
Groups II
Ch. 5
We now pass from general groups (whose composition factors are arbitrary simple
groups) to solvable groups (whose composition factors are cyclic groups of prime order;
cyclic groups of prime order are simple in every sense of the word). Even though solv-
able groups arose in determining those polynomials that are solvable by radicals, there
are purely group-theoretic theorems about solvable groups making no direct reference to
Galois theory and polynomials. For example, a theorem of P. Hall generalizes the Sylow
theorems as follows: If G is a solvable group of order ab, where a and b are relatively
prime, then G contains a subgroup of order a; moreover, any two such subgroups are con-
jugate. A theorem of W. Burnside says that if |G| = pmqn, where p and q are prime,
then G is solvable. The remarkable Feit-Thompson theorem states that every group of odd
order must be solvable.
Solvability of a group is preserved by standard group-theoretic constructions. For ex-
ample, we have seen, in Proposition 4.21, that every quotient G/N of a solvable group G
is itself a solvable group, while Proposition 4.22 shows that every subgroup of a solvable
group is itself solvable. Proposition 4.24 shows that an extension of one solvable group by
another is itself solvable: If H ‚úÅG and both H and G/H are solvable, then G is solvable,
and Corollary 4.25 shows that a direct product of solvable groups is itself solvable.
Proposition 5.56.
Every Ô¨Ånite p-group G is solvable.
Proof.
If G is abelian, then G is solvable. Otherwise, its center, Z(G), is a proper non-
trivial normal abelian subgroup, by Theorem 2.103. Now Z(G) is solvable, because it is
abelian, and G/Z(G) is solvable, by induction on |G|, and so G is solvable, by Proposi-
tion 4.24.
‚Ä¢
It follows, of course, that a direct product of Ô¨Ånite p-groups is solvable.
DeÔ¨Ånition.
If G is a group and x, y ‚ààG, then their commutator [x, y] is the element
[x, y] = xyx‚àí1y‚àí1.
If X and Y are subgroups of a group G, then [X, Y] is deÔ¨Åned by
[X, Y] =

[x, y] : x ‚ààX and y ‚ààY
 
.
In particular, the commutator subgroup G‚Ä≤ of a group G is
G‚Ä≤ = [G, G],
the subgroup generated by all the commutators.5
It is clear that two elements x and y in a group G commute if and only if their commu-
tator [x, y] is 1. The next proposition generalizes this observation.
5The subset consisting of all the commutators need not be closed under products, and so the set of all com-
mutators may not be a subgroup. The smallest group in which a product of two commutators is not a commutator
has order 96. Also, see Carmichael's exercise on page 297.

Sec. 5.3
The Jordan-H¬®older Theorem
285
Proposition 5.57.
Let G be a group.
(i) The commutator subgroup G‚Ä≤ is a normal subgroup of G, and G/G‚Ä≤ is abelian.
(ii) If H ‚úÅG and G/H is abelian, then G‚Ä≤ ‚â§H.
Proof.
(i) The inverse of a commutator xyx‚àí1y‚àí1 is itself a commutator: [x, y]‚àí1 =
yxy‚àí1x‚àí1 = [y, x]. Therefore, each element of G‚Ä≤ is a product of commutators. But any
conjugate of a commutator (and hence, a product of commutators) is another such:
a[x, y]a‚àí1 = a(xyx‚àí1y‚àí1)a‚àí1
= axa‚àí1aya‚àí1ax‚àí1a‚àí1ay‚àí1a‚àí1
= [axa‚àí1, aya‚àí1].
Therefore, G‚Ä≤ ‚úÅG. (Alternatively, G‚Ä≤ is a fully invariant subgroup of G, for if œï : G ‚ÜíG
is a homomorphism, then œï([x, y]) = [œï(x), œï(y)] ‚ààG‚Ä≤.)
If aG‚Ä≤, bG‚Ä≤ ‚ààG/G‚Ä≤, then
aG‚Ä≤bG‚Ä≤(aG‚Ä≤)‚àí1(bG‚Ä≤)‚àí1 = aba‚àí1b‚àí1G‚Ä≤ = [a, b]G‚Ä≤ = G‚Ä≤,
and so G/G‚Ä≤ is abelian.
(ii) Suppose that H ‚úÅG and G/H is abelian. If a, b ‚ààG, then aHbH = bHaH; that is,
abH = baH, and so b‚àí1a‚àí1ba ‚ààH. As every commutator has the form b‚àí1a‚àí1ba, we
have G‚Ä≤ ‚â§H.
‚Ä¢
Example 5.58.
(i) A group G is abelian if and only if G‚Ä≤ = {1}.
(ii) If G is a simple group, then G‚Ä≤ = {1} or G‚Ä≤ = G, for G‚Ä≤ is a normal subgroup. The
Ô¨Årst case occurs when G has prime order; the second case occurs otherwise. In particular,
(An)‚Ä≤ = An for all n ‚â•5.
(iii) We show that (Sn)‚Ä≤ = An for all n ‚â•5. Since Sn/An ‚àº= I2 is abelian, Proposition 5.57
shows that (Sn)‚Ä≤ ‚â§An. For the reverse inclusion, note that (Sn)‚Ä≤ ‚à©An ‚úÅAn, so that the
simplicity of An gives this intersection trivial or An. Clearly, (Sn)‚Ä≤ ‚à©An Ã∏= {(1)}, and so
An ‚â§(Sn)‚Ä≤.
‚óÄ
Let us iterate the formation of the commutator subgroup.
DeÔ¨Ånition.
The derived series of G is
G = G(0) ‚â•G(1) ‚â•G(2) ‚â•¬∑ ¬∑ ¬∑ ‚â•G(i) ‚â•G(i+1) ‚â•¬∑ ¬∑ ¬∑ ,
where G(0) = G, G(1) = G‚Ä≤, and, more generally, G(i+1) = (G(i))‚Ä≤ = [G(i), G(i)] for all
i ‚â•0.

286
Groups II
Ch. 5
It is easy to prove by induction on i ‚â•0, that G(i) is fully invariant, which implies that
G(i) ‚úÅG; it follows that G(i+1) ‚úÅG(i), and so the derived series is a normal series. The
derived series can be used to give a characterization of solvability: G is solvable if and
only if the derived series reaches {1}.
Proposition 5.59.
(i) A Ô¨Ånite group G is solvable if and only if it has a normal series with abelian factor
groups.
(ii) A Ô¨Ånite group G is solvable if and only if there is some n with
G(n) = {1}.
Proof.
(i) If G is solvable, then it has a normal series whose factor groups Gi/Gi+1 are
all cyclic of prime order, hence are abelian.
Conversely, if G has a normal series with abelian factor groups, then the factor groups
of any reÔ¨Ånement are also abelian. In particular, the factor groups of a composition series
of G, which exists because G is Ô¨Ånite, are abelian simple groups; hence, they are cyclic of
prime order, and so G is solvable.
(ii) Assume that G is solvable, so there is a normal series
G ‚â•G1 ‚â•G2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gn = {1}
whose factor groups Gi/Gi+1 are abelian. We show, by induction on i ‚â•0, that G(i) ‚â§
Gi. Since G(0) = G = G0, the base step is obviously true. For the inductive step, since
Gi/Gi+1 is abelian, Proposition 5.57 gives (Gi)‚Ä≤ ‚â§Gi+1. On the other hand, the inductive
hypothesis gives G(i) ‚â§Gi, which implies that
G(i+1) = (G(i))‚Ä≤ ‚â§(Gi)‚Ä≤ ‚â§Gi+1.
In particular, G(n) ‚â§Gn = {1}, which is what we wished to show.
Conversely, if G(n) = {1}, then the derived series is a normal series (a normal series
must end with {1}) with abelian factor groups, and so part (i) gives G solvable.
‚Ä¢
For example, the derived series of G = S4 is easily seen to be
S4 > A4 > V > {(1)}.
Our earlier deÔ¨Ånition of solvability applies only to Ô¨Ånite groups, whereas the character-
ization in the proposition makes sense for all groups, possibly inÔ¨Ånite. Nowadays, most
authors deÔ¨Åne a group to be solvable if its derived series reaches {1} after a Ô¨Ånite number
of steps; with this new deÔ¨Ånition, every abelian group is solvable, whereas it is easy to see
that abelian groups are solvable in the sense of the original deÔ¨Ånition if and only if they are
Ô¨Ånite. In Exercise 5.38 on page 287, the reader will be asked to prove, using the criterion
in Proposition 5.59, that subgroups, quotient groups, and extensions of solvable groups are
also solvable (in the new, generalized, sense).
There are other interesting classes of groups deÔ¨Åned in terms of normal series. One of
the most interesting such consists of nilpotent groups.

Sec. 5.3
The Jordan-H¬®older Theorem
287
DeÔ¨Ånition.
The descending central series of a group G is
G = Œ≥1(G) ‚â•Œ≥2(G) ‚â•¬∑ ¬∑ ¬∑ ,
where Œ≥i+1(G) = [Œ≥i(G), G]. A group G is called nilpotent if the lower central series
reaches {1}; that is, if Œ≥n(G) = {1} for some n.
Note that Œ≥2(G) = G‚Ä≤, but the derived series and the lower central series may differ
afterward; for example, Œ≥3(G) = [G‚Ä≤, G] ‚â•G(2), with strict inequality possible.
Finite nilpotent groups can be characterized by Proposition 5.39: they are the groups
that are direct products of their Sylow subgroups, and so one regards Ô¨Ånite nilpotent groups
as generalized p-groups. Examples of nilpotent groups are UT(n, Fq), UT(n, Z) (unitrian-
gular groups over Z), the Frattini subgroup (G) (deÔ¨Åned in Exercise 5.46 on page 288)
of a Ô¨Ånite group G, and certain automorphism groups arising from a normal series of a
group. We can prove results, for inÔ¨Ånite nilpotent groups as well as for Ô¨Ånite ones, such as
those in Exercise 5.47 on page 288: Every subgroup and every quotient of a Ô¨Ånite nilpotent
group G is again nilpotent; if G/Z(G) is nilpotent, then so is G; every normal subgroup
H intersects Z(G) nontrivially.
EXERCISES
5.33 Let p be a prime and let G be a nonabelian group of order p3. Prove that Z(G) = G‚Ä≤.
Hint. Show Ô¨Årst that both subgroups have order p.
5.34 Prove that if H is a subgroup of a group G and G‚Ä≤ ‚â§H, then H ‚úÅG.
Hint. Use the correspondence theorem.
5.35
(i) Prove that (Sn)‚Ä≤ = An for n = 2, 3, 4 [see Example 5.58(iii) for n ‚â•5].
(ii) Prove that (GL(n, k))‚Ä≤ ‚â§SL(n, k). (The reverse inclusion is also true; see Exercise 5.56
on page 296 for the case n = 2.)
5.36 If G is a Ô¨Ånite group and
G = G0 ‚â•G1 ‚â•¬∑ ¬∑ ¬∑ ‚â•Gn = {1}
is a normal series, prove that the order of G is the product of the orders of the factor groups:
|G| =
n‚àí1

i=0
|Gi/Gi+1|.
5.37 Prove that any two Ô¨Ånite solvable groups of the same order have the same composition factors.
5.38 Let G be an arbitrary, possibly inÔ¨Ånite group.
(i) Prove that if H ‚â§G, then H(i) ‚â§G(i) for all i. Conclude, using Proposition 5.59, that
every subgroup of a solvable group is solvable.
(ii) Prove that if f : G ‚ÜíK is a surjective homomorphism, then
f (G(i)) = K (i)
for all i. Conclude, using Proposition 5.59, that every quotient of a solvable group is
also solvable.

288
Groups II
Ch. 5
(iii) For every group G, prove, by double induction, that
G(m+n) = (G(m))(n).
(iv) Prove, using Proposition 5.59, that if H ‚úÅG and both H and G/H are solvable, then G
is solvable.
5.39 Let p and q be primes.
(i) Prove that every group of order pq is solvable.
Hint.
If p = q, then G is abelian. If p < q, then a divisor r of pq for which
r ‚â°1 mod q must equal 1.
(ii) Prove that every group G of order p2q is solvable.
Hint.
If G is not simple, use Proposition 4.24. If p > q, then r ‚â°1 mod p forces
r = 1. If p < q, then r = p2 and there are more than p2q elements in G.
5.40 Show that the Feit-Thompson theorem‚Äî"Every Ô¨Ånite group of odd order is solvable," is
equivalent to "Every nonabelian Ô¨Ånite simple group has even order."
Hint. For sufÔ¨Åciency, choose a "least criminal": a nonsolvable group G of smallest odd order.
By hypothesis, G is not simple, and so it has a proper nontrivial normal subgroup.
5.41
(i) Prove that the inÔ¨Ånite cyclic group Z does not have a composition series.
(ii) Prove that an abelian group G has a composition series if and only if G is Ô¨Ånite.
5.42 Prove that if G is a Ô¨Ånite group and H ‚úÅG, then there is a composition series of G one of
whose terms is H.
Hint. Use Schreier's theorem.
5.43
(i) Prove that if S and T are solvable subgroups of a group G and S ‚úÅG, then ST is a
solvable subgroup of G.
Hint. The subgroup ST is a homomorphic image of S √ó T .
(ii) If G is a Ô¨Ånite group, deÔ¨Åne S(G) to be the subgroup of G generated by all normal solv-
able subgroups of G. Prove that S(G) is the unique maximal normal solvable subgroup
of G and that G/S(G) has no nontrivial normal solvable subgroups.
5.44
(i) Prove that the dihedral groups D2n are solvable.
(ii) Give a composition series for D2n.
5.45 (Rosset). Let G be a group containing elements x and y such that the orders of x, y, and xy
are pairwise relatively prime; prove that G is not solvable.
5.46
(i) If G is a Ô¨Ånite group, then its Frattini subgroup, denoted by (G), is deÔ¨Åned to be
the intersection of all the maximal subgroups of G. Prove that (G) is a characteristic
subgroup, and hence it is a normal subgroup of G.
(ii) Prove that if p is a prime and G is a Ô¨Ånite abelian p-group, then (G) = pG. The
Burnside basis theorem says that if G is any (not necessarily abelian) Ô¨Ånite p-group,
then G/(G) is a vector space over Fp, and its dimension is the minimum number of
generators of G (see Rotman, An Introduction to the Theory of Groups, page 124).
5.47
(i) If G is a nilpotent group, prove that its center Z(G) Ã∏= {1}.
(ii) If G is a group with G/Z(G) nilpotent, prove that G is nilpotent.
(iii) If G is a nilpotent group, prove that every subgroup and every quotient group of G is
also nilpotent.

Sec. 5.4
Projective Unimodular Groups
289
(iv) Let G be a group and let H ‚úÅG. Give an example in which both H and G/H are
nilpotent and yet G is not nilpotent.
(v) If G is a Ô¨Ånite p-group and if H ‚úÅG, prove that H ‚à©Z(G) Ã∏= {1}. (The generalization
of this result to Ô¨Ånite nilpotent groups is true.)
5.48 Let A denote the class of all abelian groups, N the class of all nilpotent groups, and S the
class of all solvable groups.
(i) Prove that A ‚äÜN ‚äÜS.
(ii) Show that each of the inclusions in part (i) is strict; that is, there is a nilpotent group that
is not abelian, and there is a solvable group that is not nilpotent.
5.49 If G is a group and g, x ‚ààG, write gx = xgx‚àí1.
(i) Prove, for all x, y, z ‚ààG, that [x, yz] = [x, y][x, z]y and [xy, z] = [y, z]x[x, z].
(ii) (Jacobi Identity) If x, y, z ‚ààG are elements in a group G, deÔ¨Åne
[x, y, z] = [x, [y, z]].
Prove that
[x, y‚àí1, z]y[y, z‚àí1, x]z[z, x‚àí1, y]x = 1.
5.50 If H, K, L are subgroups of a group G, deÔ¨Åne
[H, K, L] = ‚ü®

[h, k, ‚Ñì] : h ‚ààH, k ‚ààK, ‚Ñì‚ààL

‚ü©.
(i) Prove that if [H, K, L] = {1} = [K, L, H], then [L, H, K] = {1}.
(ii) (Three subgroups lemma) If N ‚úÅG and [H, K, L][K, L, H] ‚â§N, prove that
[L, H, K] ‚â§N.
(iii) Prove that if G is a group with G = G‚Ä≤, then G/Z(G) is centerless.
Hint.
If œÄ : G ‚ÜíG/Z(G) is the natural map, deÔ¨Åne Œ∂ 2(G) = œÄ‚àí1(Z(G/Z(G))).
Use the three subgroups lemma with L = Œ∂ 2(G) and H = K = G.
(iv) Prove, for all i, j, that [Œ≥i(G), Œ≥ j(G)] ‚â§Œ≥i+ j(G).
5.4 PROJECTIVE UNIMODULAR GROUPS
The Jordan-H¬®older theorem associates a family of simple groups to every Ô¨Ånite group, and
it can be used to reduce many problems about Ô¨Ånite groups to problems about Ô¨Ånite simple
groups. This empirical fact says that a knowledge of simple groups is very useful. The
only simple groups we have seen so far are cyclic groups of prime order and the alternating
groups An for n ‚â•5. We will now show that certain Ô¨Ånite groups of matrices are simple,
and we begin by considering some matrices that will play the same role for 2 √ó 2 linear
groups as the 3-cycles played for the alternating groups.

290
Groups II
Ch. 5
DeÔ¨Ånition.
A transvection6 over a Ô¨Åeld k is a matrix of the form
B12(r) =
1
r
0
1

or
B21(r) =
1
0
r
1

,
where r ‚ààk and r Ã∏= 0.
Let A be a 2 √ó 2 matrix. It is easy to see that B12(r)A is the matrix obtained from A by
replacing Row(1) by Row(1) + rRow(2), and that B21(r)A is the matrix obtained from A
by replacing Row(2) by Row(2) + rRow(1).
Lemma 5.60.
If k is a Ô¨Åeld and A ‚ààGL(2, k), then
A = U D,
where U is a product of transvections and D = diag{1, d} =
1
0
0
d

, where d = det(A).
Proof.
Let
A =
p
q
r
s

.
We may assume that r Ã∏= 0; otherwise, p Ã∏= 0 (because A is nonsingular), and replacing
Row(2) by Row(2)+Row(1) puts p in the 21 position. Next, replace Row(1) by Row(1)+
r‚àí1(1 ‚àíp)Row(2), so that 1 is in the upper left corner. Now continue multiplying by
transvections:
1
x
r
s

‚Üí
1
x
0
y

‚Üí
1
0
0
d

.
Thus, W A = D, where W is a product of transvections and D = diag{1, d}. Since
transvections have determinant 1, we have det(W) = 1, and so
det(A) = det(D) = d.
As the inverse of a transvection is also a transvection, we have A = W ‚àí1D, which is the
factorization we seek.
‚Ä¢
Recall that SL(2, k) is the subgroup of GL(2, k) consisting of all matrices of determi-
nant 1.7 If k is a Ô¨Ånite Ô¨Åeld, then k ‚àº= Fq, where q = pn and p is a prime; we may denote
GL(2, Fq) by GL(2, q) and, similarly, we may denote SL(2, Fq) by SL(2, q).
6Most group theorists deÔ¨Åne a 2 √ó 2 transvection as a matrix that is similar to B12(r) or B21(r) [that is, a
conjugate of B12(r) or B21(r) in GL(2, k)]. The word transvection is a synonym for transporting, and its usage
in this context is probably due to E. Artin, who gives the following deÔ¨Ånition in his book Geometric Algebra: "An
element œÑ ‚ààGL(V ), where V is an n-dimensional vector space, is called a transvection if it keeps every vector
of some hyperplane H Ô¨Åxed and moves any vector x ‚ààV by some vector of H; that is, œÑ(x) ‚àíx ‚ààH." In our
case, B12(r) Ô¨Åxes the "x-axis" and B21(r) Ô¨Åxes the "y-axis."
7GL abbreviates general linear and SL abbreviates special linear.

Sec. 5.4
Projective Unimodular Groups
291
Proposition 5.61.
(i) If k is a Ô¨Åeld, then SL(2, k) is generated by transvections.
(ii) If k is a Ô¨Åeld, then GL(2, k)/SL(2, k) ‚àº= k√ó, where k√ó is the multiplicative group of
nonzero elements of k.
(iii) If k = Fq, then
|SL(2, Fq)| = (q + 1)q(q ‚àí1).
Proof.
(i) If A ‚ààSL(2, k), then Lemma 5.60 gives a factorization A = U D, where U is
a product of transvections and D = diag{1, d}, where d = det(A). Since A ‚ààSL(2, k),
we have det(A) = 1, and so A = U.
(ii) If a ‚ààk√ó, then the matrix diag{1, a} has determinant a, hence is nonsingular, and so
the map det: GL(2, k) ‚Üík√ó is surjective. The deÔ¨Ånition of SL(2, k) shows that it is the
kernel of det, and so the Ô¨Årst isomorphism theorem gives the result.
(iii) If H is a normal subgroup of a Ô¨Ånite group G, then Lagrange's theorem gives |H| =
|G|/|G/H|. In particular,
|SL(2, Fq)| = | GL(2, Fq)|/|F√ó
q |.
But | GL(2, Fq)| = (q2 ‚àí1)(q2 ‚àíq), by Theorem 5.46, and |F√ó
q | = q ‚àí1. Hence,
|SL(2, Fq)| = (q + 1)q(q ‚àí1).
‚Ä¢
We now compute the center of these matrix groups. If V is a two-dimensional vector
space over k, then we proved, in Proposition 3.108, that GL(2, k) ‚àº= GL(V ), the group of
all nonsingular linear transformations on V . Moreover, Proposition 3.109(i) identiÔ¨Åes the
center with the scalar transformations.
Proposition 5.62.
The center of SL(2, k), denoted by SZ(2, k), consists of all scalar
matrices
a
0
0
a

with a2 = 1.
Remark.
Here we see that SZ = SL ‚à©Z(GL), but it is not true in general that if H ‚â§G,
then Z(H) = H ‚à©Z(G) (indeed, this equality may not hold even when H is normal). We
always have H ‚à©Z(G) ‚â§Z(H), but the inclusion may be strict. For example, if G = S3
and H = A3 ‚àº= I3, then Z(A3) = A3 while A3 ‚à©Z(S3) = {1}.
‚óÄ
Proof.
It is more convenient here to use linear transformations than matrices. Assume that
T ‚ààSL(2, k) is not a scalar transformation. Therefore, there is a nonzero vector v ‚ààV
with T v not a scalar multiple of v. It follows that the list v, T v is linearly independent
and, since dim(V ) = 2, that it is a basis of V . DeÔ¨Åne S : V ‚ÜíV by S(v) = v and
S(T v) = v + T v. Notice, relative to the basis v, T v, that S has matrix B12(1), so that
det(S) = 1. Now T and S do not commute, for T S(v) = T v while ST (v) = v + T v. It
follows that the center must consist of scalar transformations. In matrix terms, the center
consists of scalar matrices A = diag{a, a}, and a2 = det(A) = 1.
‚Ä¢

292
Groups II
Ch. 5
DeÔ¨Ånition.
The projective unimodular8 group is the quotient group
PSL(2, k) = SL(2, k)/SZ(2, k).
Note that if c2 = 1, where c is in a Ô¨Åeld k, then c = ¬±1. If k = Fq, where q is a power
of 2, then Fq has characteristic 2, so that c2 = 1 implies c = 1. Therefore, in this case,
SZ(2, Fq) = {I} and so PSL(2, F2n) = SL(2, F2n).
Proposition 5.63.
|PSL(2, Fq)| =

1
2(q + 1)q(q ‚àí1)
if q = pn and p is an odd prime;
(q + 1)q(q ‚àí1)
if q = 2n.
Proof.
Proposition 5.61(iii) gives |PSL(2, Fq)| = (q + 1)q(q ‚àí1)/|SZ(2, Fq)| and,
Proposition 5.62 gives
|SZ(2, Fq)| = |{a ‚ààFq : a2 = 1}|.
Now F√ó
q is a cyclic group of order q ‚àí1, by Theorem 3.30. If q is odd, then q ‚àí1 is
even, and the cyclic group F√ó
q has a unique subgroup of order 2; if q is a power of 2, then
we noted, just before the statement of this proposition, that SZ(2, Fq) = {I}. Therefore,
|SZ(2, q)| = 2 if q is a power of an odd prime, and |SZ(2, q)| = 1 if q is a power of 2. ‚Ä¢
We are now going to prove that the groups PSL(2, Fq) are simple for all prime pow-
ers q ‚â•4. As we said earlier, the transvections will play the role of the 3-cycles (see
Exercise 2.91 on page 113).
Lemma 5.64.
If H is a normal subgroup of SL(2, Fq) containing a transvection B12(r)
or B21(r), then H = SL(2, Fq).
Proof.
Note Ô¨Årst that if
U =
0
‚àí1
1
0

,
then det(U) = 1 and U ‚ààSL(2, Fq); since H is a normal subgroup, U B12(r)U ‚àí1 also lies
in H. But U B12(r)U ‚àí1 = B21(‚àír), from which it follows that H contains a transvection
of the form B12(r) if and only if it contains a transvection of the form B21(‚àír). Since
SL is generated by the transvections, it sufÔ¨Åces to show that every transvection B12(r) lies
in H.
The following conjugate of B12(r) lies in H because H is normal:
Œ±
Œ≤
0
Œ±‚àí1
 1
r
0
1
 
Œ±‚àí1
‚àíŒ≤
0
Œ±

=

1
rŒ±2
0
1

= B12(rŒ±2).
DeÔ¨Åne
G = {0} ‚à™{u ‚ààFq : B12(u) ‚ààH}.
8A matrix is called unimodular if it has determinant 1. The adjective projective arises because this group turns
out to consist of automorphisms of a projective plane.

Sec. 5.4
Projective Unimodular Groups
293
We have just shown that rŒ±2 ‚ààG for all Œ± ‚ààFq. It is easy to check that G is a subgroup of
the additive group of Fq and, hence, it contains all the elements of the form u = r(Œ±2‚àíŒ≤2),
where Œ±, Œ≤ ‚ààk. We claim that G = Fq, which will complete the proof.
If q is odd, then each w ‚ààFq is a difference of squares:
w = [ 1
2(w + 1)]2 ‚àí[ 1
2(w ‚àí1)]2.
Hence, if u ‚ààFq, there are Œ±, Œ≤ ‚ààFq with r‚àí1u = Œ±2 ‚àíŒ≤2, and so u = r(Œ±2 ‚àíŒ≤2) ‚ààG;
therefore, G = Fq. If q = 2m, then the function u ‚Üíu2 is an injection Fq ‚ÜíFq (for
if u2 = v2, then 0 = u2 ‚àív2 = (u ‚àív)2, and u = v). It follows from Exercise 1.58
on page 36 (an injection from a Ô¨Ånite set to itself must be a bijection) that this function is
surjective, and so every element u has a square root in Fq. In particular, there is Œ± ‚ààFq
with r‚àí1u = Œ±2, and u = rŒ±2 ‚ààG.
‚Ä¢
We need a short technical lemma before giving the main result.
Lemma 5.65.
Let H be a normal subgroup of SL(2, Fq). If A ‚ààH is similar to
R =
Œ±
Œ≤
Œ≥
Œ¥

,
where R ‚ààGL(2, Fq), then there is u ‚ààFq so that H contains

Œ±
u‚àí1Œ≤
uŒ≥
Œ¥

.
Proof.
By hypothesis, there is a matrix P ‚ààGL(2, Fq) with R = P AP‚àí1. There is a
matrix U ‚ààSL and a diagonal matrix D = diag{1, u} with P‚àí1 = U D, by Lemma 5.60.
Therefore, A = U DRD‚àí1U ‚àí1; since H ‚úÅSL, we have DRD‚àí1 = U ‚àí1AU ‚ààH. But
DRD‚àí1 =
1
0
0
u
 Œ±
Œ≤
Œ≥
Œ¥
 1
0
0
u‚àí1

=

Œ±
u‚àí1Œ≤
uŒ≥
Œ¥

.
‚Ä¢
The next theorem was proved by C. Jordan in 1870 for q prime. In 1893, after F. Cole
had discovered a simple group of order 504, E. H. Moore recognized Cole's group as
PSL(2, F8), and he then proved the simplicity of PSL(2, Fq) for all prime powers q ‚â•4.
We can deÔ¨Åne PSL(m, Fq) for all m ‚â•3 as SL(m, Fq)/SZ(m, Fq), and Jordan proved, for
all m ‚â•3, that PSL(m, Fp) is simple for all primes p. In 1897, L. E. Dickson proved that
PSL(m, Fq) is simple for all prime powers q.
We are going to use Corollary 3.101: Two n √ó n matrices A and B over a Ô¨Åeld k are
similar (that is, there exists a nonsingular matrix P with B = P AP‚àí1) if and only if they
both arise from a single linear transformation œï : kn ‚Üíkn relative to two choices of bases
of kn. Of course, two nonsingular n √ó n matrices A and B over a Ô¨Åeld k are similar if and
only if they are conjugate elements in the group GL(n, k).

294
Groups II
Ch. 5
Theorem 5.66 (Jordan-Moore).
The groups PSL(2, Fq) are simple for all prime pow-
ers q ‚â•4.
Remark.
By Proposition 5.63, |PSL(2, F2)| = 6 and |PSL(2, F3)| = 12, so that neither
of these groups is simple.
It is true that PSL(2, k) is a simple group for every inÔ¨Ånite Ô¨Åeld k.
‚óÄ
Proof.
It sufÔ¨Åces to prove that a normal subgroup H of SL(2, Fq) that contains a matrix
not in the center SZ(2, Fq) must be all of SL(2, Fq).
Suppose, Ô¨Årst, that H contains a matrix
A =
Œ±
0
Œ≤
Œ±‚àí1

,
where Œ± Ã∏= ¬±1; that is, Œ±2 Ã∏= 1. If B = B21(1), then H contains the commutator
B AB‚àí1A‚àí1 = B21(1 ‚àíŒ±‚àí2), which is a transvection because 1 ‚àíŒ±‚àí2 Ã∏= 0. Therefore,
H = SL(2, Fq), by Lemma 5.64.
To complete the proof, we need only show that H contains a matrix whose top row is
[Œ± 0], where Œ± Ã∏= ¬±1. By hypothesis, there is some matrix M ‚ààH that is not a scalar
matrix. Let œï : k2 ‚Üík2 be the linear transformation given by œï(v) = Mv, where v is a
2 √ó 1 column vector. If œï(v) = cvv for all v, where cv ‚ààk, then the matrix [œï] relative
to any basis of k2 is a diagonal matrix. In this case, M is similar to a diagonal matrix
D = diag{Œ±, Œ≤}, and Lemma 5.65 says that D ‚ààH. Since M /‚ààSZ(2, Fq), we must have
Œ± Ã∏= Œ≤. But Œ±Œ≤ = det(M) = 1, and so Œ± Ã∏= ¬±1. Therefore, D is a matrix in H of the
desired form.
In the remaining case, there is a vector v with œï(v) not a scalar multiple of v, and we
saw in Example 3.96(ii) that M is similar to a matrix of the form
0
‚àí1
1
b

(the matrix has this form because it has determinant 1). Lemma 5.65 now says that there is
some u ‚ààk with
D =

0
‚àíu‚àí1
u
b

‚ààH.
If T = diag{Œ±, Œ±‚àí1} (where Œ± will be chosen in a moment), then the commutator
V = (T DT ‚àí1)D‚àí1 =

Œ±2
0
ub(Œ±‚àí2 ‚àí1)
Œ±‚àí2

‚ààH.
We are done if Œ±2 Ã∏= ¬±1; that is, if there is some nonzero Œ± ‚ààk with Œ±4 Ã∏= 1. If q > 5,
then such an element Œ± exists, for the polynomial x4 ‚àí1 has at most four roots in a Ô¨Åeld.
If q = 4, then every Œ± ‚ààF4 is a root of the equation x4 ‚àíx, and so Œ± Ã∏= 1 implies Œ±4 Ã∏= 1.

Sec. 5.4
Projective Unimodular Groups
295
Only the case q = 5 remains. The entry b in D shows up in the lower left corner
v = ub(Œ±‚àí2 ‚àí1) of the commutator V . There are two subcases depending on whether
b Ã∏= 0 or b = 0. In the Ô¨Årst subcase, choose Œ± = 2 so that Œ±‚àí2 = 4 = Œ±2 and v =
(4 ‚àí1)ub = 3ub Ã∏= 0. Now H contains V 2 = B21(‚àí2v), which is a transvection because
‚àí2v = ‚àí6ub = 4ub Ã∏= 0. Finally, if b = 0, then D has the form
D =

0
‚àíu‚àí1
u
0

.
Conjugating D by B12(y) for y ‚ààF5 gives a matrix B12(y)DB12(‚àíy) ‚ààH whose top row
is
[uy
‚àíuy2 ‚àíu‚àí1].
If we choose y = 2u‚àí1, then the top row is [2 0], and the proof is complete.
‚Ä¢
Here are the Ô¨Årst few orders of these simple groups:
| PSL(2, F4)| =
60;
| PSL(2, F5)| =
60;
| PSL(2, F7)| = 168;
| PSL(2, F8)| = 504;
| PSL(2, F9)| = 360;
| PSL(2, F11)| = 660.
It can be shown that there is no nonabelian simple group whose order lies between 60 and
168. Indeed, these are all the nonabelian simple groups of order less than 1000.
Some of the orders in the table, namely, 60 and 360, coincide with orders of alternating
groups. There do exist nonisomorphic simple groups of the same order; for example, A8
and PSL(3, F4) are nonisomorphic simple groups of order 1
28! = 20,160. The next result
shows that any two simple groups of order 60 are isomorphic [Exercise 5.53 on page 296
shows that PSL(2, F9) ‚àº= A6].
Proposition 5.67.
If G is a simple group of order 60, then G ‚àº= A5.
Proof.
It sufÔ¨Åces to show that G has a subgroup H of index 5, for then Theorem 2.88, the
representation on the cosets of H, provides a homomorphism œï : G ‚ÜíS5 with ker œï ‚â§H.
As G is simple, the proper normal subgroup ker œï is equal to {1}, and so G is isomorphic
to a subgroup of S5 of order 60. By Exercise 2.94(ii) on page 114, A5 is the only subgroup
of S5 of order 60, and so G ‚àº= A5.
Suppose that P and Q are Sylow 2-subgroups of G with P‚à©Q Ã∏= {1}; choose x ‚ààP‚à©Q
with x Ã∏= 1. Now P has order 4, hence is abelian, and so 4 | |CG(x)|, by Lagrange's
theorem. Indeed, since both P and Q are abelian, the subset P ‚à™Q is contained in CG(x),
so that |CG(x)| ‚â•|P ‚à™Q| > 4. Therefore, |CG(x)| is a proper multiple of 4 which is also
a divisor of 60: either |CG(x)| = 12, |CG(x)| = 20, or |CG(x)| = 60. The second case

296
Groups II
Ch. 5
cannot occur lest CG(x) have index 3, and representing G on its cosets would show that
G is isomorphic to a subgroup of S3; the third case cannot occur lest x ‚ààZ(G) = {1}.
Therefore, CG(x) is a subgroup of G of index 5, and we are done in this case. We may
now assume that every pair of Sylow 2-subgroups of G intersect in {1}.
A Sylow 2-subgroup P of G has r = [G : NG(P)] conjugates, where r = 3, 5, or
15. Now r Ã∏= 3 (G has no subgroup of index 3). We show that r = 15 is not possible
by counting elements. Each Sylow 2-subgroup contains three nonidentity elements. Since
any two Sylow 2-subgroups intersect trivially (as we saw above), their union contains
15 √ó 3 = 45 nonidentity elements. Now a Sylow 5-subgroup of G must have 6 conjugates
(the number r5 of them is a divisor of 60 satisfying r5 ‚â°1 mod 5). But Sylow 5-subgroups
are cyclic of order 5, so that the intersection of any pair of them is {1}, and so the union of
them contains 6√ó4 = 24 nonidentity elements. We have exceeded the number of elements
in G, and so this case cannot occur.
‚Ä¢
Corollary 5.68.
PSL(2, F4) ‚àº= A5 ‚àº= PSL(2, F5).
Proof.
All three groups are simple and have order 60.
‚Ä¢
There are other inÔ¨Ånite families of simple matrix groups (in addition to the cyclic groups
of prime order, the alternating groups, and the projective unimodular groups), as well as 26
sporadic simple groups belonging to no inÔ¨Ånite family, the largest of which is the "mon-
ster" of order approximately 8.08 √ó 1053. We refer the interested reader to the books by E.
Artin, by R. Carter, and by J. Dieudonn¬¥e. In fact, all Ô¨Ånite simple groups were classiÔ¨Åed
in the 1980's, and an excellent description of this classiÔ¨Åcation can be found in Conway et
al, ATLAS of Finite Groups.
EXERCISES
5.51 Give a composition series for GL(2, F5) and list its factor groups.
5.52
(i) Prove that PSL(2, F2) ‚àº= S3.
(ii) Prove that PSL(2, F3) ‚àº= A4.
5.53 Prove that PSL(2, F9) ‚àº= A6.
Hint.
Let A =

0 ‚àí1
1
0

and B =

1 1+u
0
1

, where u ‚ààF9 satisÔ¨Åes u2 = ‚àí1. If A and B
represent elements a and b in PSL(2, F9), prove that ab has order 5 and |‚ü®a, b‚ü©| = 60.
5.54
(i) Prove that SL(2, F5) is not solvable.
(ii) Show that a Sylow 2-subgroup of SL(2, F5) is isomorphic to the quaternions Q.
(iii) Prove that the Sylow p-subgroups of SL(2, F5) are cyclic if p is an odd prime. Con-
clude, for every prime p, that all the Sylow p-subgroups of SL(2, F5) have a unique
subgroup of order p.
5.55 Prove that GL(2, F7) is not solvable.
5.56
(i) Prove that SL(2, Fq) is the commutator subgroup of GL(2, Fq) for all prime powers
q ‚â•4.
(ii) What is the commutator subgroup of GL(2, Fq) when q = 2 and when q = 3?

Sec. 5.5
Presentations
297
5.57 Let œÄ be a primitive element of F8.
(i) What is the order of A =
œÄ
0
1
œÄ

considered as an element of GL(2, F8)?
(ii) What is the order of A =
Ô£Æ
Ô£∞
œÄ
0
0
1
œÄ
0
0
1
œÄ
Ô£π
Ô£ªconsidered as an element of GL(3, F8)?
Hint. Show that if N =
Ô£Æ
Ô£∞
0
0
0
1
0
0
0
1
0
Ô£π
Ô£ª, then N2 =
Ô£Æ
Ô£∞
0
0
0
0
0
0
1
0
0
Ô£π
Ô£ªand N3 = 0, and use
the binomial theorem to show that Am = œÄm I + mœÄm‚àí1N +
m
2

œÄm‚àí2N2.
5.5 PRESENTATIONS
How can we describe a group? By Cayley's theorem, a Ô¨Ånite group G is isomorphic to a
subgroup of the symmetric group Sn, where n = |G|, and so G can always be deÔ¨Åned as a
subgroup of Sn generated by certain permutations. An example of this kind of construction
occurs in the following exercise from Carmichael's group theory book9:
Let G be the subgroup of S16 generated by the following permutations:
(a c)(b d);
(e g)( f h);
(i k)( j ‚Ñì);
(m o)(n p)
(a c)(e g)(i k);
(a b)(c d)(m o);
(e f )(g h)(m n)(o p);
(i j)(k ‚Ñì).
Prove that |G| = 256, |G‚Ä≤| = 16,
Œ± = (i k)( j ‚Ñì)(m o)(n p) ‚ààG‚Ä≤,
but Œ± is not a commutator.
A second way of describing a group is by replacing Sn by GL(n, k) for some n ‚â•2
and some Ô¨Åeld k [remember that all the n √ó n permutation matrices form a subgroup of
GL(n, k) isomorphic to Sn, and so every group of order n can be imbedded in GL(n, k)].
We have already described some groups in terms of matrices; for example, we deÔ¨Åned
the quaternion group Q in this way. For relatively small groups, descriptions in terms of
permutations or matrices are useful, but when n is large, such descriptions are cumbersome.
We can also describe groups as being generated by elements subject to certain relations.
For example, the dihedral group D2n could be described as a group of order 2n that can be
generated by two elements a and b, such that an = 1 = b2 and bab = a‚àí1. Consider the
following deÔ¨Ånition.
9Carmichael posed this exercise in the 1930s, before the era of high-speed computers, and he was able to
solve it by hand.

298
Groups II
Ch. 5
DeÔ¨Ånition.
The group of generalized quaternions Qn, where n ‚â•3, is a group of order
2n that is generated by two elements a and b such that
a2n‚àí1 = 1,
bab‚àí1 = a‚àí1, and
b2 = a2n‚àí2.
When n = 3, this is the group Q of order 8. An obvious defect in this deÔ¨Ånition is that
the existence of such a group is left in doubt; for example, is there such a group of order
16? Notice that it is not enough to Ô¨Ånd a group G = ‚ü®a, b‚ü©in which a8 = 1, bab‚àí1 = a‚àí1,
and b2 = a4. For example, the group G = ‚ü®a, b‚ü©in which a2 = 1 and b = 1 (which is, of
course, cyclic of order 2) satisÔ¨Åes all of the equations.
It was W. von Dyck, in the 1880s, who invented free groups in order to make such
descriptions rigorous.
Here is a modern deÔ¨Ånition of a free group.
DeÔ¨Ånition.
If X is a subset of a group F, then F is a free group with basis X if, for every
group G and every function f : X ‚ÜíG, there exists a unique homomorphism œï : F ‚ÜíG
with œï(x) = f (x) for all x ‚ààX.
F
œï

X

f
 G
This deÔ¨Ånition is modeled on a fundamental result in linear algebra, Theorem 3.92,
which is the reason why it is possible to describe linear transformations by matrices.
Theorem.
Let X = v1, . . . , vn be a basis of a vector space V . If W is a vector space
and u1, . . . , un is a list in W, then there exists a unique linear transformation T : V ‚ÜíW
with T (vi) = ui for all i.
We may draw a diagram of this theorem after we note that giving a list u1, . . . , un of
vectors in W is the same thing as giving a function f : X ‚ÜíW, where f (vi) = ui; after
all, a function f : X ‚ÜíW is determined by its values on vi ‚ààX.
V
T

X

f
 W
If we knew that free groups exist, then we could deÔ¨Åne Qn as follows. Let F be
the free group with basis X = {x, y}, let R be the normal subgroup of F generated by

x2n‚àí1, yxy‚àí1x, y‚àí2x2n‚àí2
, and deÔ¨Åne Qn = F/R. It is clear that F/R is a group gener-
ated by two elements a = x R and b = yR that satisfy the relations in the deÔ¨Ånition; what
is not clear is that F/R has order 2n, and this needs proof (see Proposition 5.80).

Sec. 5.5
Presentations
299
The Ô¨Årst question, then, is whether free groups exist. The idea of the construction is
simple and natural, but checking the details is a bit fussy. We begin by describing the
ingredients of a free group.
Let X be a nonempty set, and let X‚àí1 be a disjoint replica of X; that is, X and X‚àí1
are disjoint and there is a bijection X ‚ÜíX‚àí1, which we denote by x ‚Üíx‚àí1. DeÔ¨Åne the
alphabet on X to be
X ‚à™X‚àí1.
If n is a positive integer, we deÔ¨Åne a word on X of length n ‚â•1 to be a function
w: {1, 2, . . . , n} ‚ÜíX ‚à™X‚àí1. In practice, we shall write a word w of length n as fol-
lows: if w(i) = xei
i , then
w = xe1
1 ¬∑ ¬∑ ¬∑ xen
n ,
where xi ‚ààX and ei = ¬±1. The length n of a word w will be denoted by |w|. For example,
|xx‚àí1| = 2. The empty word, denoted by 1, is a new symbol; the length of the empty word
is deÔ¨Åned to be 0.
The deÔ¨Ånition of equality of functions reads here as follows. If u = xe1
1 ¬∑ ¬∑ ¬∑ xen
n and
v = yd1
1 ¬∑ ¬∑ ¬∑ ydm
m are words, where xi, y j ‚ààX for all i, j, then u = v if and only if m = n,
xi = yi, and ei = di for all i; thus, every word has a unique spelling.
DeÔ¨Ånition.
A subword of a word w = xe1
1 ¬∑ ¬∑ ¬∑ xen
n is either the empty word or a word of
the form u = xer
r ¬∑ ¬∑ ¬∑ xes
s , where 1 ‚â§r ‚â§s ‚â§n. The inverse of a word w = xe1
1 ¬∑ ¬∑ ¬∑ xen
n is
w‚àí1 = x‚àíen
n
¬∑ ¬∑ ¬∑ x‚àíe1
1
.
It follows that (w‚àí1)‚àí1 = w for every word w.
The most important words are reduced words.
DeÔ¨Ånition.
A word w on X is reduced if w = 1 or if w has no subwords of the form
xx‚àí1 or x‚àí1x, where x ‚ààX.
Any two words on X can be multiplied.
DeÔ¨Ånition.
If u = xe1
1 xe2
2 ¬∑ ¬∑ ¬∑ xen
n and v = yd1
1 ¬∑ ¬∑ ¬∑ ydm
m are words on X, then their juxta-
position is the word
uv = xe1
1 ¬∑ ¬∑ ¬∑ xen
n yd1
1 ¬∑ ¬∑ ¬∑ ydm
m .
If 1 is the empty word, then 1v = v and u1 = u.
Let us try to deÔ¨Åne a free group as the set of all words on X with operation juxtaposition,
with the identity being the empty word 1, and with the inverse of w = xe1
1 ¬∑ ¬∑ ¬∑ xen
n being
w‚àí1 = x‚àíen
n
¬∑ ¬∑ ¬∑ x‚àíe1
1
. There is a problem: If x ‚ààX, then we want x‚àí1x = 1, but this is not
true; x‚àí1x has length 2, not length 0. We can try to remedy this by restricting the elements
of F to be reduced words on X; but, even if u and v are reduced, their juxtaposition uv
may not be reduced. Of course, we can do all the cancellation to convert uv into a reduced
word, but now it is tricky to prove associativity. We solve this problem as follows. Since
words such as zx‚àí1xyzx‚àí1 and zyzx‚àí1, for example, must be identiÔ¨Åed, it is reasonable to

300
Groups II
Ch. 5
impose an equivalence relation on the set of all the words on X. If we deÔ¨Åne the elements
of F to be the equivalence classes, then associativity can be proved without much difÔ¨Åculty,
and it turns out that there is a unique reduced word in each equivalence class. Therefore,
we can regard the elements of F as reduced words and the product of two elements as their
juxtaposition followed by reduction.
The casual reader may accept the existence of free groups as just described and proceed
to Proposition 5.73 on page 304; here are the details for everyone else.
DeÔ¨Ånition.
Let A and B be words on X, possibly empty, and let w = AB. An elementary
operation is either an insertion, changing w = AB to Aaa‚àí1B for some a ‚ààX ‚à™X‚àí1, or
a deletion of a subword of w of the form aa‚àí1, changing w = Aaa‚àí1B to AB.
DeÔ¨Ånition.
We write
w ‚Üíw‚Ä≤
to denote w‚Ä≤ arising from w by an elementary operation. Two words u and v on X are
equivalent, denoted by u ‚àºv, if there are words u = w1, w2, . . . , wn = v and elementary
operations
u = w1 ‚Üíw2 ‚Üí¬∑ ¬∑ ¬∑ ‚Üíwn = v.
Denote the equivalence class of a word w by [w].
Note that xx‚àí1 ‚àº1 and x‚àí1x ‚àº1; that is, [xx‚àí1] = [1] = [x‚àí1x].
We construct free groups in two stages.
DeÔ¨Ånition.
A semigroup is a set having an associative operation; a monoid is a semigroup
S having an identity element 1; that is, 1s = s = s1 for all s ‚ààS. If S and S‚Ä≤ are
semigroups, then a homomorphism is a function f : S ‚ÜíS‚Ä≤ such that f (xy) = f (x) f (y);
if S and S‚Ä≤ are monoids, then a homomorphism f : S ‚ÜíS‚Ä≤ must also satisfy f (1) = 1.
Of course, every group is a monoid, and a homomorphism between groups is a homo-
morphism of them qua monoids.
Example 5.69.
(i) The set of natural numbers N is a commutative monoid under addition.
(ii) A direct product of monoids is again a monoid (with cooordinatewise operation). In
particular, the set Nn of all n-tuples of natural numbers is a commutative additive monoid.
‚óÄ
Here is an example of a noncommutative monoid.
Lemma 5.70.
Let X be a set, and let W(X) be the set of all words on X [if X = ‚àÖ, then
W(X) consists of only the empty word].
(i) W(X) is a monoid under juxtaposition.

Sec. 5.5
Presentations
301
(ii) If u ‚àºu‚Ä≤ and v ‚àºv‚Ä≤, then uv ‚àºu‚Ä≤v‚Ä≤.
(iii) If G is a group and f : X ‚ÜíG is a function, then there is a homomorphism
f : W(X) ‚ÜíG extending f such that w ‚àºw‚Ä≤ implies f (w) = f (w‚Ä≤) in G.
Proof.
(i) Associativity of juxtaposition is obvious once we note that there is no cancel-
lation in W(X).
(ii) The elementary operations that take u to u‚Ä≤, when applied to the word uv, give a chain
taking uv to u‚Ä≤v; the elementary operations that take v to v‚Ä≤, when applied to the word u‚Ä≤v,
give a chain taking u‚Ä≤v to u‚Ä≤v‚Ä≤. Hence, uv ‚àºu‚Ä≤v‚Ä≤.
(iii) If w = xe1
1 ¬∑ ¬∑ ¬∑ xen
n , then deÔ¨Åne
f (w) = f (x1)e1 f (x2)e2 ¬∑ ¬∑ ¬∑ f (xn)en.
That w has a unique spelling shows that f is a well-deÔ¨Åned function, and it is obvious that
f : W(X) ‚ÜíG is a homomorphism.
Let w ‚àºw‚Ä≤. We prove, by induction on the number of elementary operations in a chain
from w to w‚Ä≤, that f (w) = f (w‚Ä≤) in G. Consider the deletion w = Aaa‚àí1B ‚ÜíAB,
where A and B are subwords of w. That f is a homomorphism gives
f (Aaa‚àí1B) = f (A) f (a) f (a)‚àí1 f (B).
But
f (A) f (a) f (a)‚àí1 f (B) = f (A) f (B) in G,
because there is cancellation in the group G, so that f (Aaa‚àí1B) = f (AB). A similar
argument holds for insertions.
‚Ä¢
The next proposition will be used to prove that each element in a free group has a normal
form.
Proposition 5.71.
Every word w on a set X is equivalent to a unique reduced word.
Proof.
If X = ‚àÖ, then there is only one word on X, the empty word 1, and 1 is reduced.
If X Ã∏= ‚àÖ, we show Ô¨Årst that there exists a reduced word equivalent to w. If w has no
subword of the form aa‚àí1, where a ‚ààX ‚à™X‚àí1, then w is reduced. Otherwise, delete the
Ô¨Årst such pair, producing a new word w1, which may be empty, with |w1| < |w|. Now
repeat: If w1 is reduced, stop; if there is a subword of w1 of the form aa‚àí1, then delete it,
producing a shorter word w2. Since the lengths are strictly decreasing, this process ends
with a reduced word that is equivalent to w.
To prove uniqueness, suppose, on the contrary, that u and v are distinct reduced words
and there is a chain of elementary operations
u = w1 ‚Üíw2 ‚Üí¬∑ ¬∑ ¬∑ ‚Üíwn = v;
we may assume that n is minimal. Since u and v are both reduced, the Ô¨Årst elementary
operation is an insertion, while the last elementary operation is a deletion, and so there must

302
Groups II
Ch. 5
be a Ô¨Årst deletion, say, wi ‚Üíwi+1. Thus, the elementary operation wi‚àí1 ‚Üíwi inserts
aa‚àí1 while the elementary operation wi ‚Üíwi+1 deletes bb‚àí1, where a, b ‚ààX ‚à™X‚àí1.
There are three cases. If the subwords aa‚àí1 and bb‚àí1 of wi coincide, then wi‚àí1 =
wi+1, for wi+1 is obtained from wi‚àí1 by Ô¨Årst inserting aa‚àí1 and then deleting it; hence,
the chain
u = w1 ‚Üíw2 ‚Üí¬∑ ¬∑ ¬∑ ‚Üíwi‚àí1 = wi+1 ‚Üí¬∑ ¬∑ ¬∑ ‚Üíwn = v
is shorter than the original shortest chain. The second case has aa‚àí1 and bb‚àí1 overlapping
subwords of wi; this can happen in two ways. One way is
wi = Aaa‚àí1b‚àí1C,
where A, C are subwords of wi and a‚àí1 = b; hence, a = b‚àí1 and
wi = Aaa‚àí1aC.
Therefore, wi‚àí1 = AaC, because we are inserting aa‚àí1, and wi+1 = AaC, because we
are deleting bb‚àí1 = a‚àí1a. Thus, wi‚àí1 = wi+1, and removing wi gives a shorter chain.
The second way an overlap can happen is wi = Aa‚àí1aa‚àí1C, where b‚àí1 = a. As in the
Ô¨Årst way, this leads to wi‚àí1 = wi+1.
Finally, suppose that the subwords aa‚àí1 and bb‚àí1 do not overlap:
wi = A‚Ä≤aa‚àí1 A‚Ä≤‚Ä≤bb‚àí1C and wi+1 = A‚Ä≤aa‚àí1 A‚Ä≤‚Ä≤C.
Now bb‚àí1 became a subword of wi by an earlier insertion of either bb‚àí1 or b‚àí1b to
some word w j‚àí1 = XY with j < i; that is, w j‚àí1 ‚Üíw j, where w j = Xbb‚àí1Y or
w j = Xb‚àí1bY. In the Ô¨Årst instance, the subchain w j‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚Üíwi+1 looks like
XY ‚ÜíXbb‚àí1Y ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíAbb‚àí1C ‚ÜíA‚Ä≤aa‚àí1 A‚Ä≤‚Ä≤bb‚àí1C ‚ÜíA‚Ä≤aa‚àí1 A‚Ä≤‚Ä≤C,
where A = A‚Ä≤A‚Ä≤‚Ä≤. But we can shorten this chain by not inserting bb‚àí1:
XY ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíAC ‚ÜíA‚Ä≤aa‚àí1 A‚Ä≤‚Ä≤C.
The only ways the deletion of bb‚àí1 can occur in the second instance is if, in w j‚àí1 = XY,
we have X = X‚Ä≤b or Y = b‚àí1Y ‚Ä≤. If X = X‚Ä≤b, then w j‚àí1 = X‚Ä≤bY and w j = X‚Ä≤bb‚àí1bY
(and it will be the subword bb‚àí1 that will be deleted by the elementary operation wi ‚Üí
wi+1). As with the Ô¨Årst possibility, we do not need the insertion. In more detail, the chain
X‚Ä≤bY ‚ÜíX‚Ä≤bb‚àí1bY ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíAbb‚àí1C ‚ÜíA‚Ä≤aa‚àí1 A‚Ä≤‚Ä≤bb‚àí1C ‚ÜíA‚Ä≤aa‚àí1A‚Ä≤‚Ä≤C,
where the processes X‚Ä≤ ‚ÜíA and bY ‚ÜíC involve insertions only, can be shortened by
removing the insertion of b‚àí1b:
X‚Ä≤bY ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíAC ‚ÜíA‚Ä≤aa‚àí1 A‚Ä≤‚Ä≤C.
The second case, Y = b‚àí1Y ‚Ä≤, is treated in the same way. Therefore, in all cases, we are
able to shorten the shortest chain, and so no such chain can exist.
‚Ä¢

Sec. 5.5
Presentations
303
Theorem 5.72.
If X is a set, then the set F of all equivalence classes of words on X
with operation [u][v] = [uv] is a free group with basis {[x] : x ‚ààX}.
Moreover, every element in F has a normal form: For each [u] ‚ààF, there is a unique
reduced word w with [u] = [w].
Proof.
If X = ‚àÖ, then W(‚àÖ) consists only of the empty word 1, and so F = {1}. The
reader may show that this is, indeed, a free group on ‚àÖ.
Assume now that X Ã∏= ‚àÖ. We have already seen, in Lemma 5.70(ii), that juxtaposition
is compatible with the equivalence relation, and so the operation on F is well-deÔ¨Åned. The
operation is associative, because of associativity in W(X):
[u]([v][w]) = [u][vw]
= [u(vw)]
= [(uv)w]
= [uv][w]
= ([u][v])[w].
The identity is the class [1], the inverse of [w] is [w‚àí1], and so F is a group.
If [w] ‚ààF, then
[w] = [xe1
1 ¬∑ ¬∑ ¬∑ xen
n ] = [xe1
1 ][xe2
2 ] ¬∑ ¬∑ ¬∑ [xen
n ],
where ei = ¬±1 for all i, so that F is generated by X (if we identify each x ‚ààX with [x]).
It follows from Proposition 5.71 that for every [w], there is a unique reduced word u with
[w] = [u].
To prove that F is free with basis X, suppose that f : X ‚ÜíG is a function, where G is
a group. DeÔ¨Åne œï : F ‚ÜíG by
œï : [xe1
1 ][xe2
2 ] ¬∑ ¬∑ ¬∑ [xen
n ] ‚Üíf (x1)e1 f (x2)e2 ¬∑ ¬∑ ¬∑ f (xn)en,
where xe1
1 ¬∑ ¬∑ ¬∑ xen
n is reduced. Uniqueness of the reduced expression of a word shows that
œï is a well-deÔ¨Åned function (which obviously extends f ). Take note of the relation of œï to
the homomorphism f : W(X) ‚ÜíG in Lemma 5.70: When w is reduced,
œï([w]) = f (w).
It remains to prove that œï is a homomorphism (if so, it is the unique homomorphism
extending f , because the subset X generates F). Let [u], [v] ‚ààF, where u and v are
reduced words, and let uv ‚àºw, where w is reduced. Now
œï([u][v]) = œï([w]) = f (w),
because w is reduced, and
œï([u])œï([v]) = f (u) f (v),
because u and v are reduced. Finally, f (u) f (v) = f (w), by Lemma 5.70(iii), and so
œï([u][v]) = œï([u])œï([v]).
‚Ä¢

304
Groups II
Ch. 5
Remark.
There is a less fussy proof of the existence of the free group F with basis a
given set X, due to M. Barr (see Montgomery-Ralston, Selected Papers in Algebra). We
have not given this proof here because it does not describe the elements of F, and this
description is often needed when using free groups.
‚óÄ
We have proved, for every set X, that there exists a free group that is free with basis X.
Moreover, the elements of a free group F on X may be regarded as reduced words and the
operation may be regarded as juxtaposition followed by reduction; brackets are no longer
used, and the elements [w] of F are written as w.
The free group F with basis X that we have just constructed is generated by X. Are any
two free groups with basis X isomorphic?
Proposition 5.73.
(i) Let X1 be a basis of a free group F1 and let X2 be a basis of a free group F2. If there
is a bijection f : X1 ‚ÜíX2, then there is an isomorphism œï : F1 ‚ÜíF2 extending f .
(ii) If F is a free group with basis X, then F is generated by X.
Proof.
(i) The following diagram, in which the vertical arrows are inclusions, will help
the reader follow the proof.
F1
œï1
 F2
œï2

X1

f
 X2.

f ‚àí1

We may regard f as having target F2, because X2 ‚äÜF2; since F1 is a free group with basis
X1, there is a homomorphism œï1 : F1 ‚ÜíF2 extending f . Similarly, there exists a homo-
morphism œï2 : F2 ‚ÜíF1 extending f ‚àí1. It follows that the composite œï2œï1 : F1 ‚ÜíF1 is
a homomorphism extending 1X. But the identity 1F1 also extends 1X, so that uniqueness
of the extension gives œï2œï1 = 1F1. In the same way, we see that the other composite
œï1œï2 = 1F2, and so œï1 is an isomorphism.
(ii) Let there be a bijection f : X1 ‚ÜíX for some set X1. If F1 is the free group with basis
X1 constructed in Theorem 5.72, then X1 generates F1. By part (i), there is an isomorphism
œï : F1 ‚ÜíF with œï(X1) = X. But if X1 generates F1, then œï(X1) generates im œï; that is,
X generates F.
‚Ä¢
There is a notion of rank for free groups, but we must Ô¨Årst check that all bases in a free
group have the same number of elements.
Lemma 5.74.
If F is a free group with basis X = x1, . . . , xn, then F/F‚Ä≤ is a free abelian
group with basis X‚Ä≤ = x1F‚Ä≤, . . . , xn F‚Ä≤, where F‚Ä≤ is the commutator subgroup of F.

Sec. 5.5
Presentations
305
Proof.
We begin by noting that X‚Ä≤ generates F/F‚Ä≤; this follows from Proposition 5.73(ii),
which says that X generates F. We prove that F/F‚Ä≤ is a free abelian group with basis X‚Ä≤
by using the criterion in Proposition 5.12. Consider the following diagram.
F
œÄ

g

F/F‚Ä≤
g‚Ä≤
	
G
X
p

Œ≥ ŒΩ

	
	
	
	
	
	
	
ŒΩ
 X‚Ä≤
Œ≥








p‚Ä≤

Here, G is an arbitrary abelian group, p and p‚Ä≤ are inclusions, œÄ is the natural map, ŒΩ : x ‚Üí
x F‚Ä≤, and Œ≥ : X‚Ä≤ ‚ÜíG is a function. Let g : F ‚ÜíG be the unique homomorphism with
gp = Œ≥ ŒΩ given by the deÔ¨Ånition of free group (for Œ≥ ŒΩ : X ‚ÜíG is a function), and deÔ¨Åne
g‚Ä≤ : F/F‚Ä≤ ‚ÜíG by wF‚Ä≤ ‚Üíg(w) (g‚Ä≤ is well-deÔ¨Åned because G abelian forces F‚Ä≤ ‚â§ker g).
Now g‚Ä≤ p‚Ä≤ = Œ≥ , for
g‚Ä≤ p‚Ä≤ŒΩ = g‚Ä≤œÄp = gp = Œ≥ ŒΩ;
since ŒΩ is a surjection, it follows that g‚Ä≤ p‚Ä≤ = Œ≥ . Finally, g‚Ä≤ is the unique such map, for if g‚Ä≤‚Ä≤
satisÔ¨Åes g‚Ä≤‚Ä≤ p‚Ä≤ = Œ≥ , then g‚Ä≤ and g‚Ä≤‚Ä≤ agree on the generating set X‚Ä≤, hence they are equal.
‚Ä¢
Proposition 5.75.
Let F be the free group with basis X. If |X| = n, then every basis of
F has n elements.
Proof.
By the lemma, F/F‚Ä≤ is a free abelian group of rank n. On the other hand, if
y1, . . . , ym is another basis of F, then F/F‚Ä≤ is a free abelian group of rank m. By Propo-
sition 5.9, we have m = n.
‚Ä¢
The following deÔ¨Ånition now makes sense.
DeÔ¨Ånition.
The rank of a free group F, denoted by rank(F), is the number of elements
in a basis.
Proposition 5.73(i) can now be restated: two free groups of Ô¨Ånite rank are isomorphic
if and only if they have the same rank.
Proposition 5.76.
Every group G is a quotient of a free group.
Proof.
Let X be a set for which there exists a bijection f : X ‚ÜíG (for example, we
could take X to be the underlying set of G and f = 1G), and let F be the free group
with basis X. There exists a homomorphism œï : F ‚ÜíG extending f , and œï is surjective
because f is. Therefore, G ‚àº= F/ ker œï.
‚Ä¢
Let us return to describing groups.

306
Groups II
Ch. 5
DeÔ¨Ånition.
A presentation of a group G is an ordered pair
G = (X | R),
where X is a set, R is a set of words on X, and G = F/N, where F is the free group with
basis X and N is the normal subgroup generated by R, that is, the subgroup generated by
all conjugates of elements of R. We call the set X generators10 and the set R relations.
Proposition 5.76 says that every group has a presentation.
DeÔ¨Ånition.
A group G is Ô¨Ånitely generated if it has a presentation (X | R) with X Ô¨Ånite.
A group G is called Ô¨Ånitely presented if it has a presentation (X | R) in which both X and
R are Ô¨Ånite.
It is easy to see that a group G is Ô¨Ånitely generated if and only if there exists a Ô¨Ånite
subset A ‚äÜG with G = ‚ü®A‚ü©. There do exist Ô¨Ånitely generated groups that are not Ô¨Ånitely
presented (see my book, An Introduction to the Theory of Groups, page 417).
Remark.
There are interesting connections between group theory and algebraic topology.
If X is a topological space, then its fundamental group œÄ1(X) is deÔ¨Åned to be the set of
all homotopy classes of continuous functions S1 ‚ÜíX, where S1 is the unit circle. A Ô¨Ånite
simplicial complex is a topological space that can be triangulated in the sense that it is the
union of Ô¨Ånitely many vertices, edges, triangles, tetrahedra, and so forth. We can prove
that a group G is Ô¨Ånitely presented if and only if there is a Ô¨Ånite simplicial complex X with
G ‚àº= œÄ1(X).
Quite often, a group is known only by some presentation of it. For example, suppose
that X is a simplicial complex containing subcomplexes Y1 and Y2 such that Y1 ‚à™Y2 = X
and Y1 ‚à©Y2 is connected. Then van Kampen's theorem says that a presentation of œÄ1(X)
can be given if we know presentations of œÄ1(Y1) and œÄ1(Y2).
‚óÄ
Example 5.77.
(i) A group has many presentations. For example, G = I6 has presentations
(x | x6)
as well as
(a, b | a3, b2, aba‚àí1b‚àí1).
A fundamental problem is how to determine whether two presentations give isomorphic
groups. It can be proved that no algorithm can exist that solves this problem (see Rotman,
An Introduction to the Theory of Groups, page 469).
(ii) The free group with basis X has a presentation
(X | ‚àÖ).
A free group is so called precisely because it has a presentation with no relations.
‚óÄ
10The term generators is now being used in a generalized sense, for X is not a subset of G. The subset
{x N : x ‚ààX} of G = F/N does generate G in the usual sense.

Sec. 5.5
Presentations
307
A word on notation. Often, we write the relations in a presentation as equations. Thus,
the relations
a3,
b2,
aba‚àí1b‚àí1
in the second presentation of I6 may also be written
a3 = 1,
b2 = 1,
ab = ba.
If r is a word on x1, . . . , xn, we may write r = r(x1, . . . , xn). If H is a group and
h1, . . . , hn ‚ààH, then r(h1, . . . , hn) denotes the element in H obtained from r by replacing
each xi by hi.
The next, elementary, result is quite useful; we state only the Ô¨Ånitely generated case
of it.
Theorem 5.78 (von Dyck's Theorem).
Let a group G have a presentation
G = (x1, . . . , xn | r j, j ‚ààJ);
that is, G = F/N, where F is free on {x1, . . . , xn} and N is the normal subgroup
of F generated by all r j = r j(x1, . . . , xn).
If H = ‚ü®h1, . . . , hn‚ü©is a group and if
r j(h1, . . . , hn) = 1 in H for all j ‚ààJ, then there is a surjective homomorphism G ‚ÜíH
with xi N ‚Üíhi for all i.
Proof.
If F is the free group with basis {x1, . . . , xn}, then there is a homomorphism
œï : F ‚ÜíH with œï(xi) = hi for all i. Since r j(h1, . . . , hn) = 1 in H for all j ‚ààJ,
we have r j ‚ààker œï for all j ‚ààJ, which implies N ‚â§ker œï. Therefore, œï induces a
(well-deÔ¨Åned) homomorphism G = F/N ‚ÜíH with xi N ‚Üíhi for all i.
‚Ä¢
The next proposition will show how von Dyck's theorem enters into the analysis of
presentations, but we begin with the construction of a concrete group of matrices.
Example 5.79.
We are going to construct a group Hn that is a good candidate to be the generalized quater-
nion group Qn for n ‚â•3 deÔ¨Åned on page 298. Consider the complex matrices
A =
œâ
0
0
œâ‚àí1

and
B =
 0
1
‚àí1
0

,
where œâ is a primitive 2n‚àí1th root of unity, and let Hn = ‚ü®A, B‚ü©‚â§GL(2, C). We claim
that A and B satisfy the relations in the deÔ¨Ånition of the generalized quaternion group. For
all i ‚â•1,
A2i =

œâ2i
0
0
œâ‚àí2i

,
so that A2n‚àí1 = I; indeed, A has order 2n‚àí1. Moreover,
B2 =
‚àí1
0
0
‚àí1

= A2n‚àí2
and
B AB‚àí1 =

œâ‚àí1
0
0
œâ

= A‚àí1.

308
Groups II
Ch. 5
Notice that A and B do not commute; hence, B /‚àà‚ü®A‚ü©, and so the cosets ‚ü®A‚ü©and B‚ü®A‚ü©are
distinct. Since A has order 2n‚àí1, it follows that
|Hn| ‚â•|‚ü®A‚ü©‚à™B‚ü®A‚ü©| = 2n‚àí1 + 2n‚àí1 = 2n.
The next theorem will show that |Hn| = 2n.
‚óÄ
Proposition 5.80.
For every n ‚â•3, the generalized quaternion group Qn exists.
Proof.
Let Gn be the group deÔ¨Åned by the presentation
Gn =

a, b | a2n‚àí1 = 1, bab‚àí1 = a‚àí1, b2 = a2n‚àí2
.
The group Gn satisÔ¨Åes all the requirements in the deÔ¨Ånition of the generalized quaternions
with one possible exception: We do not yet know that its order is 2n. By von Dyck's
theorem, there is a surjective homomorphism Gn ‚ÜíHn, where Hn is the group just
constructed in Example 5.79. Hence, |Gn| ‚â•2n.
On the other hand, the cyclic subgroup ‚ü®a‚ü©in Gn has order at most 2n‚àí1, because
a2n‚àí1 = 1. The relation bab‚àí1 = a‚àí1 implies that ‚ü®a‚ü©‚úÅGn = ‚ü®a, b‚ü©, so that Gn/‚ü®a‚ü©is
generated by the image of b. Finally, the relation b2 = a2n‚àí2 shows that |Gn/‚ü®a‚ü©| ‚â§2.
Hence,
|Gn| ‚â§|‚ü®a‚ü©||Gn/‚ü®a‚ü©| ‚â§2n‚àí1 ¬∑ 2 = 2n.
Therefore, |Gn| = 2n, and so Gn ‚àº= Qn.
‚Ä¢
It now follows that the group Hn in Example 5.79 is isomorphic to Qn.
In Exercise 2.57 on page 81, we gave a concrete construction of the dihedral group D2n,
and we can use that group‚Äîas in the proof just given‚Äî to give a presentation.
Proposition 5.81.
The dihedral group D2n has a presentation
D2n = (a, b | an = 1, b2 = 1, bab = a‚àí1).
Proof.
Let C2n denote the group deÔ¨Åned by the presentation, and let D2n be the group
of order 2n constructed in Exercise 2.57 on page 81. By von Dyck's theorem, there is
a surjective homomorphism f : C2n ‚ÜíD2n, and so |C2n| ‚â•2n. To see that f is an
isomorphism, we prove the reverse inequality. The cyclic subgroup ‚ü®a‚ü©in C2n has order
at most n, because an = 1. The relation bab‚àí1 = a‚àí1 implies that ‚ü®a‚ü©‚úÅC2n = ‚ü®a, b‚ü©,
so that C2n/‚ü®a‚ü©is generated by the image of b. Finally, the relation b2 = 1 shows that
|C2n/‚ü®a‚ü©| ‚â§2. Hence,
|C2n| ‚â§|‚ü®a‚ü©||C2n/‚ü®a‚ü©| ‚â§2n.
Therefore, |C2n| = 2n, and so C2n ‚àº= D2n.
‚Ä¢
In Chapter 2, we classiÔ¨Åed the groups of order 7 or less. Since groups of prime order
are cyclic, it was only a question of classifying the groups of orders 4 and 6. The proof
we gave, in Proposition 2.90, that every nonabelian group of order 6 is isomorphic to S3
was rather complicated, analyzing the representation of a group on the cosets of a cyclic
subgroup. Here is a proof in the present spirit.

Sec. 5.5
Presentations
309
Proposition 5.82.
If G is a nonabelian group of order 6, then G ‚àº= S3.
Proof.
As in the proof of Proposition 2.90, G must contain elements a and b of orders
3 and 2, respectively. Now ‚ü®a‚ü©‚úÅG, because it has index 2, and so either bab‚àí1 = a or
bab‚àí1 = a‚àí1. The Ô¨Årst possibility cannot occur, because G is not abelian. Therefore, G
satisÔ¨Åes the conditions in the presentation of D6 ‚àº= S3, and so von Dyck's theorem gives
a surjective homomorphism D6 ‚ÜíG. Since both groups have the same order, this map
must be an isomorphism.
‚Ä¢
We can now classify the groups of order 8.
Theorem 5.83.
Every group G of order 8 is isomorphic to
D8,
Q,
I8,
I4 ‚äïI2,
or I2 ‚äïI2 ‚äïI2.
Moreover, no two of the displayed groups are isomorphic.
Proof.
If G is abelian, then the basis theorem shows that G is a direct sum of cyclic
groups, and the fundamental theorem shows that the only such groups are those listed.
Therefore, we may assume that G is not abelian.
Now G cannot have an element of order 8, lest it be cyclic, hence abelian; moreover,
not every nonidentity element can have order 2, lest G be abelian, by Exercise 2.26 on
page 62. We conclude that G must have an element a of order 4; hence, ‚ü®a‚ü©has index 2,
and so ‚ü®a‚ü©‚úÅG. Choose b ‚ààG with b /‚àà‚ü®a‚ü©; note that G = ‚ü®a, b‚ü©because ‚ü®a‚ü©has index
2, hence is a maximal subgroup. Now b2 ‚àà‚ü®a‚ü©, because G/‚ü®a‚ü©is a group of order 2, and
so b2 = ai, where 0 ‚â§i ‚â§3. We cannot have b2 = a or b2 = a3 = a‚àí1 lest b have order
8. Therefore, either
b2 = a2
or
b2 = 1.
Furthermore, bab‚àí1 ‚àà‚ü®a‚ü©, by normality, and so bab‚àí1 = a or bab‚àí1 = a‚àí1 (for bab‚àí1
has the same order as a). Now bab‚àí1 = a says that a and b commute, which implies that
G is abelian. We conclude that bab‚àí1 = a‚àí1. Therefore, there are only two possibilities:
a4 = 1,
b2 = a2, and bab‚àí1 = a‚àí1,
or
a4 = 1,
b2 = 1, and bab‚àí1 = a‚àí1.
By the lemma, the Ô¨Årst equations give relations of a presentation for Q, while Proposi-
tion 5.81 shows that the second equations give relations of a presentation of D8. By von
Dyck's theorem, there is a surjective homomorphism Q ‚ÜíG or D8 ‚ÜíG; as |G| = 8,
however, this homomorphism must be an isomorphism.
Finally, Exercise 2.61 on page 82 shows that Q and D8 are not isomorphic (for example,
Q has a unique element of order 2 while D8 has several such elements).
‚Ä¢
The reader may continue this classiÔ¨Åcation of the groups G of small order, say, |G| ‚â§
15. Here are the results. By Corollary 2.104, every group of order p2, where p is a prime,
is abelian, and so every group of order 9 is abelian; by the fundamental theorem of Ô¨Ånite

310
Groups II
Ch. 5
abelian groups, there are only two such groups: I9 and I3 √ó I3. If p is a prime, then every
group of order 2p is either cyclic or dihedral (see Exercise 5.63). Thus, there are only two
groups of order 10 and only two groups of order 14. There are 5 groups of order 12, two of
which are abelian. The nonabelian groups of order 12 are D12 ‚àº= S3 √ó I2, A4, and a group
T having the presentation
T =

a, b | a6 = 1, b2 = a3 = (ab)2
;
see Exercise 5.64, which realizes T as a group of matrices. The group11 T is an example
of a semidirect product, a construction that will be discussed in Chapter 10. A group of
order pq, where p < q are primes and q Ã∏‚â°1 mod p, must be cyclic, and so there is only
one group of order 15 [see Exercise 10.11(ii) on page 794], There are 14 nonisomorphic
groups of order 16, and so this is a good place to stop.
EXERCISES
5.58 Let F be a free group with basis X and let A ‚äÜX. Prove that if N is the normal subgroup of
F generated by A, then F/N is a free group.
5.59 Let F be a free group.
(i) Prove that F has no elements (other than 1) of Ô¨Ånite order.
(ii) Prove that a free group F is abelian if and only if rank(F) ‚â§1.
Hint. Map a free group of rank ‚â•2 onto a nonabelian group.
(iii) Prove that if rank(F) ‚â•2, then Z(F) = {1}, where Z(F) is the center of F,
5.60 Prove that a free group is solvable if and only if it is inÔ¨Ånite cyclic (see page 286).
5.61
(i) If G is a Ô¨Ånitely generated group and n is a positive integer, prove that G has only
Ô¨Ånitely many subgroups of index n.
Hint. Consider homomorphisms G ‚ÜíSn.
(ii) If H and K are subgroups of Ô¨Ånite index in a group G, prove that H ‚à©K also has Ô¨Ånite
index in G.
5.62
(i) Prove that each of the generalized quaternion groups Qn has a unique subgroup of order
2, namely, ‚ü®b2‚ü©, and this subgroup is the center Z(Qn).
(ii) Prove that Qn/Z(Qn) ‚àº= D2n‚àí1.
5.63 If p is a prime, prove that every group G of order 2p is either cyclic or isomorphic to D2p.
Hint. By Cauchy's theorem, G must contain an element a of order p, and ‚ü®a‚ü©‚úÅG because
it has index 2.
5.64 Let G be the subgroup of GL(2, C) generated by
œâ
0
0
œâ2

and
0
i
i
0

,
where œâ = e2œÄi/3 is a primitive cube root of unity.
(i) Prove that G is a group of order 12 that is not isomorphic to A4 or to D12.
11The group T is called a dicyclic group of type (2, 2, 3) in Coxeter and Moser, Generators and Relations for
Discrete Groups, but this terminology in not generally accepted.

Sec. 5.6
The Nielsen-Schreier Theorem
311
(ii) Prove that G is isomorphic to the group T on page 310.
5.65 Prove that every Ô¨Ånite group is Ô¨Ånitely presented.
5.66 Compute the order of the group G with the presentation
G =

a, b, c, d | bab‚àí1 = a2, bdb‚àí1 = d2, c‚àí1ac = b2, dcd‚àí1 = c2, bd = db

.
5.67 If X is a nonempty set, deÔ¨Åne $(X) to be the set of all positive words w on X; that is, $(X)
is the subset of W(X) consisting of all xe1
1 ¬∑ ¬∑ ¬∑ xen
n with all ei = 1. DeÔ¨Åne a free monoid, and
prove that $(X) is the free monoid with basis X.
5.6 THE NIELSEN-SCHREIER THEOREM
We are now going to prove one of the most fundamental results about free groups: Every
subgroup is also free. This theorem was Ô¨Årst proved by J. Nielsen, in 1921, for Ô¨Ånitely
generated subgroups; the Ô¨Åniteness hypothesis was removed by O. Schreier, in 1926, and
so the theorem is now called the Nielsen-Schreier theorem. Nielsen's method actually
provides an algorithm, analogous to Gaussian elimination in linear algebra, which replaces
a generating set A of a free group F with a basis of ‚ü®A‚ü©.12 In particular, if S is a Ô¨Ånitely
generated subgroup of a free group F, then Nielsen's algorithm replaces any generating
set of S with a basis of S, thereby proving that S is free. For an exposition of this proof,
we refer the reader to the book of Lyndon and Schupp, pages 4-13.
A second type of proof was found by R. Baer and F. Levi in 1933. It uses a connection,
analogous to the correspondence between Galois groups and intermediate Ô¨Åelds, between
covering spaces ÀúX of a topological space X and subgroups of its fundamental group œÄ1(X).
In particular, if X is a graph (a space constructed of edges and vertices), then it can be
shown that every covering space is also a graph. It turns out that œÄ1( ÀúX) is isomorphic to
a subgroup of œÄ1(X). Conversely, given any subgroup S ‚â§œÄ1(X), there exists a covering
space ÀúXS of X for which œÄ1( ÀúXS) is isomorphic to S. Moreover, œÄ1(X) is a free group
whenever X is a graph. Once all these facts are established, the proof proceed as follows.
Given a free group F, there is a graph X (a "bouquet of circles") with F ‚àº= œÄ1(X); given a
subgroup S ‚â§F, we know that S ‚àº= œÄ1( ÀúXS). But ÀúXS is also a graph, so that œÄ1( ÀúXS), and
hence S, is free. There are versions of this proof that avoid topology; for example, there is
an exposition of such a proof in my book, An Introduction to the Theory of Groups, pages
377-384. Interesting variations of this idea are due to J.-P. Serre, in his book Trees, who
characterized free groups by their action on trees (trees arise as certain universal covering
spaces of connected graphs), and by P. J. Higgins, who used groupoids.
We give A. J. Weir's proof ["The Reidemeister-Schreier and KuroÀás Subgroup Theo-
rems," Mathematika 3 (1956), 47-55] of the subgroup theorem because it requires less
preparation than the others. The idea arises from a proof of the Reidemeister-Schreier
12This theoretical algorithm has evolved into the Schreier-Sims algorithm, an efÔ¨Åcient way to compute the
order of a subgroup H ‚â§Sn when a generating set of H is given; it also can determine whether a speciÔ¨Åc
permutation lies in H.

312
Groups II
Ch. 5
theorem, which gives a presentation of a subgroup of a group G in terms of a given pre-
sentation of G.
DeÔ¨Ånition.
Let S be a subgroup of a group G. A transversal ‚Ñìof S in G is a subset of G
consisting of exactly one element ‚Ñì(Sb) ‚ààSb from every coset Sb, and with ‚Ñì(S) = 1.
Let F be a free group with basis X, and let S be a subgroup of F. Given a transversal ‚Ñì
of S in F, then for each x ‚ààX, both ‚Ñì(Sb)x and ‚Ñì(Sbx) lie in the coset Sbx, and so
tSb,x = ‚Ñì(Sb)x‚Ñì(Sbx)‚àí1
lies in S. We are going to prove that if the transversal ‚Ñìis chosen wisely, then the set of all
tSb,x that are not 1 form a basis of S, so that S is free.
Let ‚Ñìbe a transversal of a subgroup S of a free group F, let the elements tSb,x be as
above, and deÔ¨Åne Y to be the free group on symbols ySb,x so that ySb,x ‚ÜítSb,x is a
bijection. DeÔ¨Åne œï : Y ‚ÜíS to be the homomorphism with
œï : ySb,x ‚ÜítSb,x = ‚Ñì(Sb)x‚Ñì(Sbx)‚àí1.
We begin by deÔ¨Åning coset functions F ‚ÜíY, one for each coset Sb, which we denote by
u ‚ÜíuSb. These functions are not homomorphisms, and we deÔ¨Åne them all simultaneously
by induction on |u| ‚â•0, where u is a reduced word on X. For all x ‚ààX and all cosets Sb,
deÔ¨Åne
1Sb = 1,
x Sb = ySb,x,
and
(x‚àí1)Sb = (x Sbx‚àí1)‚àí1.
If u = xŒµv is a reduced word of length n + 1, where Œµ = ¬±1 and |v| = n, deÔ¨Åne
uSb = (xŒµ)SbvSbxŒµ.
Lemma 5.84.
(i) For all u, v ‚ààF, the coset functions satisfy (uv)Sb = uSbvSbu.
(ii) For all u ‚ààF, (u‚àí1)Sb = (uSbu‚àí1)‚àí1.
(iii) If œï : Y ‚ÜíS is the homomorphism œï : ySb,x ‚ÜítSb,x = ‚Ñì(Sb)x‚Ñì(Sbx)‚àí1, then, for
all u ‚ààF, œï(uSb) = ‚Ñì(Sb)u‚Ñì(Sbu)‚àí1.
(iv) The function Œ∏ : S ‚ÜíY, given by Œ∏ : u ‚ÜíuS, is a homomorphism, and œïŒ∏ = 1S.
Proof.
(i) The proof is by induction on |u|, where u is reduced. If |u| = 0, then u = 1
and (uv)Sb = vSb; on the other hand, 1SbvSb1 = vSb.
For the inductive step, write u = xŒµw. Then
(uv)Sb = (xŒµ)Sb(wv)SbxŒµ
(deÔ¨Ånition of coset functions)
= (xŒµ)SbwSbxŒµvSbxŒµw
(inductive hypothesis)
= (xŒµ)SbwSbxŒµvSbu
= (xŒµw)SbvSbu
= uSbvSbu.

Sec. 5.6
The Nielsen-Schreier Theorem
313
(ii) The result follows from
1 = 1Sb = (u‚àí1u)Sb = (u‚àí1)SbuSbu‚àí1.
(iii) Note that œï does deÔ¨Åne a homomorphism because Y is the free group with basis
all ySb,x. This proof is also an induction on |u| ‚â•0. First, œï(1Sb) = œï(1) = 1, while
‚Ñì(S)1‚Ñì(S1)‚àí1 = 1.
For the inductive step, write u = xŒµv, where u is reduced. Then
œï(uSb) = œï((xŒµv)Sb) = œï((xŒµ)SbvSbxŒµ)
= œï((xŒµ)Sb)œï(vSbxŒµ)
= œï((xŒµ)Sb)‚Ñì(SbxŒµ)v‚Ñì(SbxŒµv)‚àí1,
the last equation following from the inductive hypothesis. There are now two cases, de-
pending on the sign Œµ. If Œµ = +1, then
œï(uSb) = ‚Ñì(Sb)x‚Ñì(Sbx)‚àí1‚Ñì(Sbx)v‚Ñì(Sbxv)‚àí1
= ‚Ñì(Sb)xv‚Ñì(Sbxv)‚àí1
= ‚Ñì(Sb)u‚Ñì(Sbu)‚àí1.
If Œµ = ‚àí1, then
œï(uSb) = œï((ySbx‚àí1,x)‚àí1)‚Ñì(Sbx‚àí1)v‚Ñì(Sbx‚àí1v)‚àí1
=

‚Ñì(Sbx‚àí1)x‚Ñì(Sbx‚àí1x)‚àí1‚àí1
‚Ñì(Sbx‚àí1)v‚Ñì(Sbx‚àí1v)‚àí1
= ‚Ñì(Sb)x‚àí1‚Ñì(Sbx‚àí1)‚àí1‚Ñì(Sbx‚àí1)v‚Ñì(Sbx‚àí1v)‚àí1
= ‚Ñì(Sb)x‚àí1v‚Ñì(Sbx‚àí1v)‚àí1
= ‚Ñì(Sb)u‚Ñì(Sbu)‚àí1.
(iv) For u ‚ààS, deÔ¨Åne Œ∏ : S ‚ÜíY by
Œ∏ : u ‚ÜíuS
(of course, Œ∏ is the restriction to S of the coset function u ‚ÜíuSb when b = 1). Now, if
u, v ‚ààS, then
Œ∏(uv) = (uv)S = uSvSu = uSvS = Œ∏(u)Œ∏(v),
because Su = S when u ‚ààS. Therefore, Œ∏ is a homomorphism. Moreover, if u ‚ààS, then
part (iii) gives
œïŒ∏(u) = œï(uS) = ‚Ñì(S1)u‚Ñì(S1u)‚àí1 = u.
‚Ä¢

314
Groups II
Ch. 5
Corollary 5.85.
If S is a subgroup of a free group F and if ‚Ñìis a transversal of S in F,
then the set of all tSb,x that are distinct from 1 generates S.
Proof.
Since the composite œïŒ∏ = 1S, the function œï : Y ‚ÜíS is surjective; hence, the
images tSb,x of the generators ySb,x of Y generate im œï = S. Of course, we may delete any
occurrences of 1 from a generating set.
‚Ä¢
The next lemma shows that we have a presentation of S, namely,
S = (ySb,x, all x ‚ààX, all cosets Sb | ‚Ñì(Sb)S, all cosets Sb).
Lemma 5.86.
If ‚Ñìis a transversal of S in F, then ker œï is the normal subgroup of Y
generated by all ‚Ñì(Sb)S.
Proof.
Let N be the normal subgroup of Y generated by all ‚Ñì(Sb)S, and let K = ker œï. By
Lemma 5.84(iv), Œ∏ : S ‚ÜíY is a homomorphism with œïŒ∏ = 1S (where œï : ySb,x ‚ÜítSb,x
and Œ∏ : u ‚ÜíuS). It follows from Exercise 5.72(ii) on page 318 that K is the normal
subgroup of Y generated by {y‚àí1œÅ(y) : y ‚ààY}, where œÅ = Œ∏œï. By Lemma 5.84(i),
y‚àí1
Sb,xœÅ(ySb,x) = y‚àí1
Sb,x

‚Ñì(Sb)x‚Ñì(Sbx)‚àí1S
= y‚àí1
Sb,x‚Ñì(Sb)Sx Sb 
‚Ñì(Sbx)‚àí1Sbx
=

y‚àí1
Sb,x‚Ñì(Sb)SySb,x
 
‚Ñì(Sbx)‚àí1Sbx
,
for x Sb = ySb,x is part of the deÔ¨Ånition of the coset function u ‚ÜíuSb. Therefore,
y‚àí1
Sb,xœÅ(ySb,x) =

y‚àí1
Sb,x‚Ñì(Sb)SySb,x
 
‚Ñì(Sbx)S‚àí1
,
(1)
because Lemma 5.84(ii) gives (‚Ñì(Sbx)‚àí1)Sbx = (‚Ñì(Sbx)S)‚àí1. It follows from Eq. (1) that
y‚àí1
Sb,xœÅ(ySb,x) ‚ààN, and so K ‚â§N. For the reverse inclusion, Eq. (1) says that ‚Ñì(Sb)S ‚ààK
if and only if ‚Ñì(Sbx)S ‚ààK. Therefore, the desired inclusion can be proved by induction
on |‚Ñì(Sb)|, and so K = N, as desired.
‚Ä¢
We now choose a special transversal.
DeÔ¨Ånition.
Let F be a free group with basis X and let S be a subgroup of F. A Schreier
transversal is a transversal ‚Ñìwith the property that if ‚Ñì(Sb) = xŒµ1
1 xŒµ2
2 ¬∑ ¬∑ ¬∑ xŒµn
n is a reduced
word, then every initial segment xŒµ1
1 xŒµ2
2 ¬∑ ¬∑ ¬∑ xŒµk
k , for 1 ‚â§k ‚â§n, is also in the transversal.
Lemma 5.87.
A Schreier transversal exists for every subgroup S of F.
Proof.
DeÔ¨Åne the length of a coset Sb, denoted by |Sb|, to be the minimum length of
the elements sb ‚ààSb. We prove, by induction on |Sb|, that there is a representative
‚Ñì(Sb) ‚ààSb such that all its initial segments are representatives of cosets of shorter length.

Sec. 5.6
The Nielsen-Schreier Theorem
315
Begin by deÔ¨Åning ‚Ñì(S) = 1. For the inductive step, let |Sz| = n + 1 and let uxŒµ ‚ààSz,
where Œµ = ¬±1 and |uxŒµ| = n + 1. Now |Su| = n, for if its length were m < n, it
would have a representative v of length m, and then vxŒµ would be a representative of Sz
of length < n + 1. By induction, b = ‚Ñì(Su) exists such that every initial segment is also a
representative. DeÔ¨Åne ‚Ñì(Sz) = bxŒµ.
‚Ä¢
Here is the result we have been seeking.
Theorem 5.88 (Nielsen-Schreier).
Every subgroup S of a free group F is free. In fact,
if X is a basis of F and if ‚Ñìis a Schreier transversal of S in F, then a basis for S consists
of all tSb,x = ‚Ñì(Sb)x‚Ñì(Sbx)‚àí1 that are not 1.
Proof.
Recall that S ‚àº= Y/K, where Y is the free group with basis all symbols ySb,x and
K = ker œï; by Lemma 5.86, K is equal to the normal subgroup generated by all ‚Ñì(Sb)S.
By Exercise 5.58 on page 310, it sufÔ¨Åces to show that K is equal to the normal subgroup T
of Y generated by all special ySb,x; that is, by those ySb,x for which œï(ySb,x) = tSb,x = 1.
Clearly, T ‚â§K = ker œï, and so it sufÔ¨Åces to prove the reverse inclusion. We prove, by
induction on |‚Ñì(Sv)|, that ‚Ñì(Sv)S is a word on the special ySb,x. If |‚Ñì(Sv)| = 0, then
‚Ñì(Sv) = ‚Ñì(S) = 1, which is a word on the special ySb,x. If |‚Ñì(Sv)| > 0, then ‚Ñì(Sv) =
uxŒµ, where Œµ = ¬±1 and |u| < |‚Ñì(Sv)|. Since ‚Ñìis a Schreier transversal, u is also a
representative: u = ‚Ñì(Su). By Lemma 5.84(i),
‚Ñì(Sv)S = uS(xŒµ)Su.
By induction, uS is a word on the special ySb,x, and hence uS ‚ààT .
It remains to prove that (xŒµ)Su is a word on the special ySb,x. If Œµ = +1, then (xŒµ)Su =
x Su = ySu,x. But ‚Ñì(Sux) = ux, because v = ux and ‚Ñìis a Schreier transversal, so that
œï(ySu,x) = tSu,x = ‚Ñì(Su)x‚Ñì(Sux)‚àí1 = ux(ux)‚àí1 = 1.
Therefore, ySu,x is special and x Su lies in T . If Œµ = ‚àí1, then the deÔ¨Ånition of coset
functions gives
(x‚àí1)Su = (x Sux‚àí1)‚àí1 = (ySux‚àí1,x)‚àí1.
Hence,
œï((x‚àí1)Su) = (tSux‚àí1,x)‚àí1 = [‚Ñì(Sux‚àí1)x‚Ñì(Sux‚àí1x)]‚àí1 = [‚Ñì(Sux‚àí1)x‚Ñì(Su)]‚àí1.
Since ‚Ñìis a Schreier transversal, we have ‚Ñì(Su) = u and ‚Ñì(Sux‚àí1) = ‚Ñì(Sv) = v = ux‚àí1.
Hence,
œï((x‚àí1)Su) = [(ux‚àí1)xu‚àí1]‚àí1 = 1.
Therefore, ySux‚àí1,x is special, (x‚àí1)Su ‚ààT , and the proof is complete.
‚Ä¢
Here is a nice application of the Nielsen-Schreier theorem.

316
Groups II
Ch. 5
Corollary 5.89.
Let F be a free group, and let u, v ‚ààF. Then u and v commute if and
only if there is z ‚ààF with u, v ‚àà‚ü®z‚ü©.
Proof.
SufÔ¨Åciency is obvious; if both u, v ‚àà‚ü®z‚ü©, then they lie in an abelian subgroup, and
hence they commute.
Conversely, the Nielsen-Schreier theorem says that the subgroup ‚ü®u, v‚ü©is free. On the
other hand, the condition that u and v commute says that ‚ü®u, v‚ü©is abelian. But an abelian
free group is cyclic, by Exercise 5.59(ii) on page 310: therefore, ‚ü®u, v‚ü©‚àº= Z, as desired. ‚Ä¢
The next result shows, in contrast to abelian groups, that a subgroup of a Ô¨Ånitely gener-
ated group need not be Ô¨Ånitely generated.
Corollary 5.90.
If F is a free group of rank 2, then its commutator subgroup F‚Ä≤ is a free
group of inÔ¨Ånite rank.
Proof.
Let {x, y} be a basis of F. Since F/F‚Ä≤ is free abelian with basis {x F‚Ä≤, yF‚Ä≤},
by Lemma 5.74, every coset F‚Ä≤b has a unique representative of the form xm yn, where
m, n ‚ààZ; it follows that the transversal choosing ‚Ñì(F‚Ä≤b) = xm yn is a Schreier transversal,
for every subword of xm yn is a word of the same form. If n > 0, then ‚Ñì(F‚Ä≤yn) = yn,
but ‚Ñì(F‚Ä≤ynx) = xyn Ã∏= ynx. Therefore, there are inÔ¨Ånitely many elements tSyn,x =
‚Ñì(F‚Ä≤yn)x‚Ñì(F‚Ä≤ynx)‚àí1 Ã∏= 1, and so the result follows from the Nielsen-Schreier theorem. ‚Ä¢
Even though an arbitrary subgroup of a Ô¨Ånitely generated free group need not be Ô¨Ånitely
generated, a subgroup of Ô¨Ånite index must be Ô¨Ånitely generated.
Corollary 5.91.
If F is a free group of Ô¨Ånite rank n, then every subgroup S of F having
Ô¨Ånite index j is also Ô¨Ånitely generated. In fact, rank(S) = jn ‚àíj + 1.
Proof.
Let X = {x1, . . . , xn} be a basis of F, and let ‚Ñì= {‚Ñì(Sb)} be a Schreier transver-
sal. By Theorem 5.88, a basis of S consists of all those elements tSb,x not equal to 1, where
x ‚ààX. There are j choices for Sb and n choices for x, and so there are at most jn elements
in a basis of S. Therefore, rank(S) ‚â§jn, and so S is Ô¨Ånitely generated.
Call an ordered pair (Sb, x) trivial if tSb,x = 1; that is, if ‚Ñì(Sb)x = ‚Ñì(Sbx). We will
show that there is a bijection œà between the family of cosets {Sb Ã∏= S} and the trivial
ordered pairs, so that there are j ‚àí1 trivial ordered pairs. It will then follow that
rank(S) = jn ‚àí( j ‚àí1) = jn ‚àíj + 1.
Since Sb Ã∏= S, we have ‚Ñì(Sb) = b = uxŒµ; since ‚Ñìis a Schreier transversal, we have
u ‚àà‚Ñì. DeÔ¨Åne œà(Sb) as follows.
œà(SuxŒµ) =

(Su, x)
if Œµ = +1;
(Sux‚àí1, x)
if Œµ = ‚àí1.
Note that œà(SuxŒµ) is a trivial ordered pair. If Œµ = +1, then ‚Ñì(Sux) = ‚Ñì(Sb) = b = ux,
so that ‚Ñì(Su)x = ux and tSu,x = 1. If Œµ = ‚àí1, then ‚Ñì(Sbx) = ‚Ñì(Sux‚àí1x) = ‚Ñì(Su) = u,
so that ‚Ñì(Sb)x = bx = ux‚àí1x = u and tSb,x = 1.

Sec. 5.6
The Nielsen-Schreier Theorem
317
To see that œà is injective, suppose that œà(Sb) = œà(Sc), where b = uxŒµ and c = vyŒ∑;
we assume that x, y lie in the given basis of F and that Œµ = ¬±1 and Œ∑ = ¬±1. There are
four possibilities, depending on the signs of Œµ and Œ∑.
(Su, x) = (Sv, y); (Su, x) = (Svy‚àí1, y); (Sux‚àí1, x) = (Sv, y); (Su, x) = (Svy‚àí1, y).
In every case, equality of ordered pairs gives x = y. If (Su, x) = (Sv, x), then Su =
Sv, hence, Sb = Sux = Svx = Sc, as desired. If (Su, x) = (Svx‚àí1, x), then Su =
Svx‚àí1 = Sc, and so ‚Ñì(Su) = ‚Ñì(Sc) = c. But ‚Ñì(Su)x = ‚Ñì(Sux) = b, because (Su, x) is
a trivial ordered pair. Hence, b = ‚Ñì(Su)x = cx = vx‚àí1x, contradicting b (as any element
of a Schreier transveral) being reduced. A similar contradiction shows that we cannot
have (Sux‚àí1, x) = (Sv, x). Finally, if (Sux‚àí1, x) = S(vx‚àí1, x), then Sb = Sux‚àí1 =
Svx‚àí1 = Sc.
To see that œà is surjective, take a trivial ordered pair (Sw, x); that is, ‚Ñì(Sw)x = wx =
‚Ñì(Swx). Now w = uxŒµ, where u ‚àà‚Ñìand Œµ = ¬±1. If Œµ = +1, then w does not
end with x‚àí1, and œà(Swx) = (Sw, x). If Œµ = ‚àí1, then w does end with x‚àí1, and so
œà(Su) = (Sux‚àí1, x) = (Sw, x).
‚Ä¢
Corollary 5.92.
There exist nonisomorphic Ô¨Ånitely generated groups G and H each of
which is isomorphic to a subgroup of the other.
Proof.
If G is a free group of rank 2 and H is a free group of rank 3, then G Ã∏‚àº= H.
Clearly, G is isomorphic to a subgroup of H. On the other hand, the commutator subgroup
G‚Ä≤ is free of inÔ¨Ånite rank, and so G‚Ä≤, hence G, contains a free subgroup of rank 3; that is,
H is isomorphic to a subgroup of G.
‚Ä¢
We are at the very beginning of a rich subject called combinatorial group theory, which
investigates how much can be said about a group given a presentation of it. One of the most
remarkable results is the unsolvability of the word problem. A group G has a solvable word
problem if it has a presentation G = (X | R) for which there exists an algorithm to deter-
mine whether an arbitrary word w on X is equal to the identity element in G (if X and R
are Ô¨Ånite, it can be proved that this property is independent of the choice of presentation).
In the late 1950s, P. S. Novikov and W. W. Boone, independently, proved that there exists
a Ô¨Ånitely presented group G that does not have a solvable word problem (see Rotman,
An Introduction to the Theory of Groups, Chapter 12). Other problems involve Ô¨Ånding pre-
sentations for known groups, as we have done for Qn and D2n; an excellent reference for
such questions is Coxeter-Moser, Generators and Relations for Discrete Groups. Another
problem is whether a group deÔ¨Åned by a presentation is Ô¨Ånite or inÔ¨Ånite. For example,
Burnside's problem asks whether a Ô¨Ånitely generated group G of Ô¨Ånite exponent m, that
is, xm = 1 for all x ‚ààG, must be Ô¨Ånite [W. Burnside had proved that if such a group G
happens to be a subgroup of GL(n, C) for some n, then G is Ô¨Ånite]. The answer in general,
however, is negative; such a group can be inÔ¨Ånite. This was Ô¨Årst proved, for m odd and
large, by P. S. Novikov and S. I. Adyan, in a long and complicated paper. Using a ge-
ometric technique involving van Kampen diagrams (see Lyndon-Schupp, Combinatorial
Group Theory, for an introduction to this subject), A. Yu. Ol'shanskii gave a much shorter

318
Groups II
Ch. 5
and simpler proof. Finally, S. V. Ivanov was able to complete the solution by showing that
the presented group can be inÔ¨Ånite when m is even and large. Another geometric technique
involves a Cayley graph of a Ô¨Ånitely generated group G, which is a graph depending on
a given Ô¨Ånite generating set; it can be proved that G is free if and only if it has a Cay-
ley graph that is a tree (see Serre, Trees). Finally, the interaction between presentations
and algorithms is both theoretical and practical. A theorem of G. Higman (see Rotman,
An Introduction to the Theory of Groups, Chapter 12) states that a Ô¨Ånitely generated group
G can be imbedded as a subgroup of a Ô¨Ånitely presented group H (that is, H has a presen-
tation with a Ô¨Ånite number of generators and a Ô¨Ånite number of relations) if and only if G
is recursively presented: there is a presentation of G whose relations can be given by an
algorithm. On the practical side, many efÔ¨Åcient algorithms solving group-theoretic prob-
lems have been implemented; see Sims, Computation with Finitely Presented Groups. The
Ô¨Årst such algorithm was coset enumeration (see Lyndon-Schupp, Combinatorial Group
Theory, pages 163-167), which computes the order of a group G, deÔ¨Åned by a presenta-
tion, provided that |G| is Ô¨Ånite (unfortunately, there can be no algorithm to determine, in
advance, whether G is Ô¨Ånite).
EXERCISES
5.68 Let G be a Ô¨Ånitely generated group, and let H ‚â§G have Ô¨Ånite index. Prove that H is Ô¨Ånitely
generated.
5.69 Prove that if F is free of Ô¨Ånite rank n ‚â•2, then its commutator subgroup F‚Ä≤ is free of inÔ¨Ånite
rank.
5.70 Let G be a Ô¨Ånite group that is not cyclic. If G ‚àº= F/S, where F is a free group of Ô¨Ånite rank,
prove that rank(S) > rank(F).
5.71
(i) Prove that if G is a Ô¨Ånite group generated by two elements a, b having order 2, then
G ‚àº= D2n for some n ‚â•2.
(ii) Let G = ‚ü®A, B‚ü©‚â§GL(2, Q), where
A =
0
0
1
1

and
B =
‚àí1
1
0
1

.
Show that A2 = I = B2, but that AB has inÔ¨Ånite order. (Exercise prefex:modular
group gives another example of a group in which the product of two elements of Ô¨Ånite
order has inÔ¨Ånite order.) The group G is usually denoted by D‚àû, and it is called the
inÔ¨Ånite dihedral group.
5.72 Let Y and S be groups, and let œï : Y ‚ÜíS and Œ∏ : S ‚ÜíY be homomorphisms with œïŒ∏ = 1S.
(i) If œÅ : Y ‚ÜíY is deÔ¨Åned by œÅ = Œ∏œï, prove that œÅœÅ = œÅ and œÅ(a) = a for every a ‚ààim Œ∏.
(The homomorphism œÅ is called a retraction.)
(ii) If K is the normal subgroup of Y generated by all y‚àí1œÅ(y) for y ‚ààY, prove that
K = ker œï.
Hint.
Note that ker œï = ker œÅ because Œ∏ is an injection. Use the equation y =
œÅ(y)(œÅ(y)‚àí1)y for all y ‚ààY.

6
Commutative Rings II
Our main interest in this chapter is the study of polynomials in several variables. As usual,
it is simpler to begin by looking at the more general setting‚Äîin this case, commutative
rings‚Äîbefore getting involved with polynomial rings. It turns out that the nature of the
ideals in a commutative ring is important: for example, we have already seen that gcds
exist in PIDs and that they are linear combinations, while these properties may not be
enjoyed by other commutative rings. Three special types of ideals‚Äîprime ideals, max-
imal ideals, and Ô¨Ånitely generated ideals‚Äîare the most interesting. A commutative ring
is called noetherian if every ideal is Ô¨Ånitely generated, and Hilbert's basis theorem shows
that k[x1, . . . , xn], where k is a Ô¨Åeld, is noetherian. Next, we collect several interesting
applications of Zorn's lemma (which is discussed in the Appendix), such as the existence
of maximal ideals, a theorem of I. S. Cohen saying that a commutative ring is noetherian if
and only if every prime ideal is Ô¨Ånitely generated, the existence and uniqueness of the alge-
braic closures of Ô¨Åelds, the existence of transcendence bases (as well as L¬®uroth's theorem),
and the existence of maximal separable extensions. The next step introduces a geometric
viewpoint in which ideals correspond to certain afÔ¨Åne subsets called varieties; this dis-
cussion involves the Nullstellensatz as well as primary decompositions. Finally, the last
section introduces the idea of Gr¬®obner bases, which extends the division algorithm from
k[x] to k[x1, . . . , xn] and which yields a practical algorithm for deciding many problems
that can be encoded in terms of polynomials in several variables.
6.1 PRIME IDEALS AND MAXIMAL IDEALS
A great deal of the number theory we have presented involves divisibility: Given two
integers a and b, when does a | b ; that is, when is a a divisor of b? This question
translates into a question about principal ideals, for a | b if and only if (b) ‚äÜ(a). We
now introduce two especially interesting types of ideals: prime ideals, which are related to
Euclid's lemma, and maximal ideals.
Let us begin with the analog of Theorem 2.76, the correspondence theorem for groups.
319

320
Commutative Rings II
Ch. 6
Proposition 6.1 (Correspondence Theorem for Rings).
If I is a proper ideal in a
commutative ring R, then there is an inclusion-preserving bijection œï from the set of all
intermediate ideals J containing I, that is, I ‚äÜJ ‚äÜR, to the set of all the ideals in R/I,
given by
œï : J ‚ÜíœÄ(J) = J/I = {a + I : a ‚ààJ},
where œÄ : R ‚ÜíR/I is the natural map.
R













J ‚Ä≤













R/I
J













J ‚Ä≤/I
I














J/I
{0}
Proof.
If we forget its multiplication, the commutative ring R is merely an additive
abelian group and its ideal I is a (normal) subgroup. The correspondence theorem for
groups, Theorem 2.76, now applies, and it gives an inclusion-preserving bijection
 : {all subgroups of R containing I} ‚Üí{all subgroups of R/I},
where (J) = œÄ(J) = J/I.
If J is an ideal, then (J) is also an ideal, for if r ‚ààR and a ‚ààJ, then ra ‚ààJ, and so
(r + I)(a + I) = ra + I ‚ààJ/I.
Let œï be the restriction of  to the set of intermediate ideals; œï is an injection because 
is a bijection. To see that œï is surjective, let J ‚àóbe an ideal in R/I. Now œÄ‚àí1(J ‚àó) is an
intermediate ideal in R [it contains I = œÄ‚àí1({0})], and œï(œÄ‚àí1(J ‚àó)) = œÄ(œÄ‚àí1(J ‚àó)) = J ‚àó,
by Proposition 1.50(ii).
‚Ä¢
In practice, the correspondence theorem is invoked, tacitly, by saying that every ideal in
the quotient ring R/I has the form J/I for some unique ideal J with I ‚äÜJ ‚äÜR.
Example 6.2.
Let I = (m) be a nonzero ideal in Z. If J is an ideal in Z containing I, then J = (a) for
some a ‚ààZ, because Z is a PID, and (m) ‚äÜ(a) if and only if a | m. The correspondence
theorem now shows that every ideal in the ring Im has the form ([a]) for some divisor a of
m, for J/I = ([a]).
‚óÄ

Sec. 6.1
Prime Ideals and Maximal Ideals
321
DeÔ¨Ånition.
An ideal I in a commutative ring R is called a prime ideal if it is a proper
ideal, that is, I Ã∏= R, and ab ‚ààI implies a ‚ààI or b ‚ààI.
Example 6.3.
(i) Recall that a nonzero commutative ring R is a domain if and only if ab = 0 in R
implies a = 0 or b = 0. Thus, the ideal (0) = {0} in R is a prime ideal if and only if R is a
domain.
(ii) We claim that the prime ideals in Z are precisely the ideals (p), where either p = 0
or p is a prime. Since m and ‚àím generate the same principal ideal, we may restrict our
attention to nonnegative generators. If p = 0, then the result follows from item (i), for Z is
a domain. If p > 0, we show Ô¨Årst that (p) is a proper ideal; otherwise, 1 ‚àà(p), and there
would be an integer a with ap = 1, a contradiction. Next, if ab ‚àà(p), then p | ab. By
Euclid's lemma, either p | a or p | b; that is, either a ‚àà(p) or b ‚àà(p). Therefore, (p) is
a prime ideal.
Conversely, if m > 1 is not a prime, then it has a factorization m = ab with 0 < a < m
and 0 < b < m; thus, neither a nor b is a multiple of m, and so neither lies in (m). But
ab = m ‚àà(m), and so (m) is not a prime ideal.
‚óÄ
Proposition 6.4.
An ideal I in a commutative ring R is a prime ideal if and only if R/I
is a domain.
Proof.
Let I be a prime ideal. Since I is a proper ideal, we have 1 /‚ààI and so 1+I Ã∏= 0+I
in R/I. If 0 = (a + I)(b + I) = ab + I, then ab ‚ààI. Since I is a prime ideal, either a ‚ààI
or b ‚ààI; that is, either a + I = 0 or b + I = 0. Hence, R/I is a domain. The converse is
just as easy.
‚Ä¢
The characterization of prime numbers in Example 6.3(ii) extends to polynomials with
coefÔ¨Åcients in a Ô¨Åeld.
Proposition 6.5.
If k is a Ô¨Åeld, then a nonzero polynomial p(x) ‚ààk[x] is irreducible if
and only if (p(x)) is a prime ideal.
Proof.
Suppose that p(x) is irreducible. First, (p) is a proper ideal; otherwise, k[x] = (p)
and hence 1 ‚àà(p), so there is a polynomial f (x) with 1 = p(x) f (x). But p(x) has degree
at least 1, whereas
0 = deg(1) = deg(pf ) = deg(p) + deg( f ) ‚â•deg(p) ‚â•1.
This contradiction shows that (p) is a proper ideal. Second, if ab ‚àà(p), then p | ab, and
so Euclid's lemma in k[x] gives p | a or p | b. Thus, a ‚àà(p) or b ‚àà(p). It follows that
(p) is a prime ideal.
Conversely, if (p(x)) is a prime ideal, then f g ‚àà(p) implies f ‚àà(p) or g ‚àà(p); that
is, p | f or p | g. Therefore, Euclid's lemma holds for p, and Exercise 3.31 on page 142
shows that p is irreducible.
‚Ä¢

322
Commutative Rings II
Ch. 6
If I is an ideal in a commutative ring R, we may write I ‚ääR if I is a proper ideal.
More generally, if I and J are ideals, we may write I ‚ääJ if I ‚äÜJ and I Ã∏= J.
Here is a second interesting type of ideal.
DeÔ¨Ånition.
An ideal I in a commutative ring R is a maximal ideal if it is a proper ideal
and there is no ideal J with I ‚ääJ ‚ääR.
Thus, if I is a maximal ideal in a commutative ring R and if J is a proper ideal with
I ‚äÜJ, then I = J. Does every commutative ring R contain a maximal ideal? The (posi-
tive) answer to this question involves Zorn's lemma, which we will discuss in Section 6.4.
Example 6.6.
The ideal {0} is a maximal ideal in a commutative ring R if and only if R is a Ô¨Åeld. It is
shown in Example 3.51(ii) that every nonzero ideal I in R is equal to R itself if and only
if every nonzero element in R is a unit. That is, {0} is a maximal ideal if and only if R is a
Ô¨Åeld.
‚óÄ
Proposition 6.7.
A proper ideal I in a nonzero commutative ring R is a maximal ideal if
and only if R/I is a Ô¨Åeld.
Proof.
The correspondence theorem for rings shows that I is a maximal ideal if and only
if R/I has no ideals other than {0} and R/I itself; Example 6.6 shows that this property
holds if and only if R/I is a Ô¨Åeld. (Note that since 1 Ã∏= 0 in a Ô¨Åeld, I must be a proper
ideal.)
‚Ä¢
Corollary 6.8.
Every maximal ideal I in a commutative ring R is a prime ideal.
Proof.
If I is a maximal ideal, then R/I is a Ô¨Åeld. Since every Ô¨Åeld is a domain, R/I is
a domain, and so I is a prime ideal.
‚Ä¢
The prime ideals in the polynomial ring k[x1, . . . , xn] can be quite complicated, but
when k is an algebraically closed Ô¨Åeld, Theorem 6.101 shows that every maximal ideal
has the form (x1 ‚àía1, . . . , xn ‚àían) for some point (a1, . . . , an) ‚ààkn; that is, when k is
algebraically closed, there is a bijection between kn and the set of all maximal ideals in
k[x1, . . . , xn].
Example 6.9.
The converse of Corollary 6.8 is false. For example, consider the principal ideal (x) in
Z[x]. By Exercise 3.83 on page 196, we have
Z[x]/(x) ‚àº= Z;
since Z is a domain, (x) is a prime ideal; since Z is not a Ô¨Åeld, (x) is not a maximal ideal.
It is not difÔ¨Åcult to exhibit a proper ideal J strictly containing (x); let
J = { f (x) ‚ààZ[x]: f (x) has even constant term}.
Since Z[x]/J ‚àº= F2 is a Ô¨Åeld, it follows that J is a maximal ideal containing (x).
‚óÄ

Sec. 6.1
Prime Ideals and Maximal Ideals
323
Example 6.10.
Let k be a Ô¨Åeld, and let a = (a1, . . . , an) ‚ààkn. DeÔ¨Åne the evaluation map
ea : k[x1, . . . , xn] ‚Üík
by
ea : f (x1, . . . , xn) ‚Üíf (a) = f (a1, . . . , an).
We have seen, in Example 3.46(iv), that ea is a surjective ring homomorphism, and so
ker ea is a maximal ideal. Now (x1 ‚àía1, . . . , xn ‚àían) ‚äÜker ea. In Exercise 6.6(i) on
page 325, however, we shall see that (x1 ‚àía1, . . . , xn ‚àían) is a maximal ideal, and so it
must be equal to ker ea.
‚óÄ
The converse of Corollary 6.8 is true when R is a PID.
Theorem 6.11.
If R is a principal ideal domain, then every nonzero prime ideal I is a
maximal ideal.
Proof.
Assume that there is a proper ideal J with I ‚äÜJ. Since R is a PID, I = (a) and
J = (b) for some a, b ‚ààR. Now a ‚ààJ implies that a = rb for some r ‚ààR, and so
rb ‚ààI; but I is a prime ideal, so that r ‚ààI or b ‚ààI. If r ‚ààI, then r = sa for some s ‚ààR,
and so a = rb = sab. Since R is a domain, 1 = sb, and Exercise 3.18 on page 125 gives
J = (b) = R, contradicting the hypothesis that J is a proper ideal. If b ‚ààI, then J ‚äÜI,
and so J = I. Therefore, I is a maximal ideal.
‚Ä¢
We can now give a second proof of Proposition 3.116.
Corollary 6.12.
If k is a Ô¨Åeld and p(x) ‚ààk[x] is irreducible, then the quotient ring
k[x]/(p(x)) is a Ô¨Åeld.
Proof.
Since p(x) is irreducible, the principal ideal I = (p(x)) is a nonzero prime ideal;
since k[x] is a PID, I is a maximal ideal, and so k[x]/I is a Ô¨Åeld.
‚Ä¢
Here are some ways that prime ideals can be used.
Proposition 6.13.
Let P be a prime ideal in a commutative ring R. If I and J are ideals
with I J ‚äÜP, then I ‚äÜP or J ‚äÜP.
Proof.
Suppose, on the contrary, that I Ã∏‚äÜP and J Ã∏‚äÜP; thus, there are a ‚ààI and b ‚ààJ
with a, b /‚ààP. But ab ‚ààI J ‚äÜP, contradicting P being prime.
‚Ä¢
The next result is taken from Kaplansky, Commutative Rings.
Proposition 6.14.
Let B be a subset of a commutative ring R which is closed under
addition and multiplication.
(i) Let J1, . . . , Jn be ideals in R, at least n ‚àí2 of which are prime. If B ‚äÜJ1 ‚à™¬∑ ¬∑ ¬∑‚à™Jn,
then B is contained in some Ji.

324
Commutative Rings II
Ch. 6
(ii) Let I be an ideal in R with I ‚ääB. If there are prime ideals P1, . . . , Pn such that
B ‚àíI ‚äÜP1 ‚à™¬∑ ¬∑ ¬∑‚à™Pn (where B ‚àíI is the set-theoretic complement of I in B), then
B ‚äÜPi for some i.
Proof.
(i) The proof is by induction on n ‚â•2. For the base step n = 2, neither of the
ideals J1 or J2 need be prime. If B Ã∏‚äÜJ2, then there is b1 ‚ààB with b1 /‚ààJ2; since
B ‚äÜJ1 ‚à™J2, we must have b1 ‚ààJ1. Similarly, if B Ã∏‚äÜJ1, there is b2 ‚ààB with b2 /‚ààJ1
and b2 ‚ààJ2. However, if y = b1 + b2, then y /‚ààJ1: otherwise, b2 = y ‚àíb1 ‚ààJ1 (because
both y and b1 are in J1), a contradiction. Similarly, y /‚ààJ2, contradicting B ‚äÜJ1 ‚à™J2.
For the inductive step, assume that B ‚äÜJ1‚à™¬∑ ¬∑ ¬∑‚à™Jn+1, where at least n‚àí1 = (n+1)‚àí2
of the Ji are prime ideals. Let
Di = J1 ‚à™. . . ‚à™Ji ‚à™¬∑ ¬∑ ¬∑ ‚à™Jn+1.
Since Di is a union of n ideals at least (n‚àí1)‚àí1 = n‚àí2 of which are prime, the inductive
hypothesis allows us to assume that B Ã∏‚äÜDi for all i. Hence, for all i, there exists bi ‚ààB
with bi /‚ààDi; since B ‚äÜDi ‚à™Ji, we must have bi ‚ààJi. Now n ‚â•3, so that at least one
of the Ji is a prime ideal; for notation, assume that J1 is prime. Consider the element
y = b1 + b2b3 ¬∑ ¬∑ ¬∑ bn+1.
Since all bi ‚ààB and B is closed under addition and multiplication, y ‚ààB. Now y /‚ààJ1;
otherwise, b2b3 ¬∑ ¬∑ ¬∑ bn+1 = y ‚àíb1 ‚ààJ1. Since J1 is prime, some bi ‚ààJ1. This is a
contradiction, for bi /‚ààDi ‚äáJ1. If i > 1 and y ‚ààJi, then b2b3 ¬∑ ¬∑ ¬∑ bn+1 ‚ààJi, because
Ji is an ideal, and so b1 = y ‚àíb2b3 ¬∑ ¬∑ ¬∑ bn+1 ‚ààJi. This cannot be, for b1 /‚ààD1 ‚äáJi.
Therefore, y /‚ààJi for any i, contradicting B ‚äÜJ1 ‚à™¬∑ ¬∑ ¬∑ ‚à™Jn+1.
(ii) The hypothesis gives B ‚äÜI ‚à™P1 ‚à™¬∑ ¬∑ ¬∑ ‚à™Pn, so that part (i) gives B ‚äÜI or B ‚äÜPi.
Since I is a proper subset of B, the Ô¨Årst possibility cannot occur.
‚Ä¢
EXERCISES
6.1
(i) Find all the maximal ideals in Z.
(ii) Find all the maximal ideals in R[x]; that is, describe those g(x) ‚ààR[x] for which (g) is
a maximal ideal.
(iii) Find all the maximal ideals in C[x].
6.2 Let I be an ideal in a commutative ring R. If J‚àóand L‚àóare ideals in R/I, prove that there exist
ideals J and L in R containing I such that J/I = J‚àó, L/I = L‚àó, and (J ‚à©L)/I = J‚àó‚à©L‚àó.
Conclude that if J‚àó‚à©L‚àó= {0}, then J ‚à©L = I.
Hint. Use the correspondence theorem.
6.3
(i) Give an example of a commutative ring containing two prime ideals P and Q for which
P ‚à©Q is not a prime ideal.
(ii) If P1 ‚äáP2 ‚äá¬∑ ¬∑ ¬∑ Pn ‚äáPn+1 ‚äá¬∑ ¬∑ ¬∑ is a decreasing sequence of prime ideals in a
commutative ring R, prove that 
n‚â•1 Pn is a prime ideal.

Sec. 6.1
Prime Ideals and Maximal Ideals
325
6.4 Let f : A ‚ÜíR be a ring homomorphism, where A and R are commutative nonzero rings.
Give an example of a prime ideal P in A with f (P) not a prime ideal in R.
6.5 Let f : A ‚ÜíR be a ring homomorphism. If Q is a prime ideal in R, prove that f ‚àí1(Q) is a
prime ideal in A. Conclude that if J/I is a prime ideal in R/I, where I ‚äÜJ ‚äÜR, then J is a
prime ideal in R.
6.6
(i) Let k be a Ô¨Åeld, and let a1, . . . , an ‚ààk. Prove that (x1 ‚àía1, . . . , xn ‚àían) is a maximal
ideal in k[x1, . . . , xn].
(ii) Prove that if xi ‚àíb ‚àà(x1 ‚àía1, . . . , xn ‚àían) for some i, where b ‚ààk, then b = ai.
(iii) Prove that ¬µ: kn ‚Üí

maximal ideals in k[x1, . . . , xn]

, given by
¬µ: (a1, . . . , an) ‚Üí(x1 ‚àía1, . . . , xn ‚àían),
is an injection, and give an example of a Ô¨Åeld k for which ¬µ is not a surjection.
6.7 Prove that if P is a prime ideal in a commutative ring R and if rn ‚ààP for some r ‚ààR and
n ‚â•1, then r ‚ààP.
6.8 Prove that the ideal (x2 ‚àí2, y2 + 1, z) in Q[x, y, z] is a proper ideal.
6.9
(i) Call a nonempty subset S of a commutative ring R multiplicatively closed if 0 /‚ààS and,
if s, s‚Ä≤ ‚ààS, then ss‚Ä≤ ‚ààS. Prove that an ideal J which is maximal with the property that
J ‚à©S = ‚àÖis a prime ideal. (The existence of such an ideal J is proved, using Zorn's
lemma, in Exercise 6.48 on page 374.)
(ii) Let S be a multiplicatively closed subset of a commutative ring R, and suppose that
there is an ideal I with I ‚à©S = ‚àÖ. If P is an ideal maximal such that I ‚äÜP and
P ‚à©S = ‚àÖ, prove that P is a prime ideal.
6.10
(i) If I and J are ideals in a commutative ring R, deÔ¨Åne
I J =

all Ô¨Ånite sums

‚Ñì
a‚Ñìb‚Ñì: a‚Ñì‚ààI and b‚Ñì‚ààJ

.
Prove that I J is an ideal in R and that I J ‚äÜI ‚à©J.
(ii) If I = (2) is the ideal of even integers in Z, prove that I 2 = I J ‚ääI ‚à©J = I.
(iii) Let P be a prime ideal and let Q1, . . . Qr be ideals. Prove that if Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr ‚äÜP,
then Qi ‚äÜP for some i.
6.11 Let I and J be ideals in a commutative ring R.
(i) Prove that the map R/(I ‚à©J) ‚ÜíR/I √ó R/J, given by œï : r ‚Üí(r + I,r + J), is an
injection.
(ii) Call I and J coprime if I + J = R. Prove that if I and J are coprime, then the ring
homomorphism œï : R/(I ‚à©J) ‚ÜíR/I √ó R/J in part (i) is a surjection.
Hint. If I and J are coprime, there are a ‚ààI and b ‚ààJ with 1 = a + b. If r,r‚Ä≤ ‚ààR,
prove that(d + I, d + J) = (r + I,r‚Ä≤ + J) ‚ààR/I √ó R/J, where d = r‚Ä≤a + rb.
(iii) Generalize the Chinese remainder theorem as follows. Let R be a commutative ring
and let I1, . . . , In be pairwise coprime ideals; that is, Ii and I j are coprime for all i Ã∏= j.
Prove that if a1, . . . , an ‚ààR, then there exists r ‚ààR with r + Ii = ai + Ii for all i.
6.12 If I and J are coprime ideals in a commutative ring R, prove that
I ‚à©J = I J.

326
Commutative Rings II
Ch. 6
6.13 If I is an ideal in a commutative ring R and if S is a subset of R, deÔ¨Åne the colon ideal1
(I : S) = {r ‚ààR : rs ‚ààI for all s ‚ààS}.
(i) Prove that (I : S) is an ideal.
(ii) If J = (S) is the ideal generated by S, prove that (I : S) = (I : J).
(iii) Let R be a domain and let a, b ‚ààR, where b Ã∏= 0. If I = (ab) and J = (b), prove that
(I : J) = (a).
6.14
(i) Let I and J be ideals in a commutative ring R. Prove that I ‚äÜ(I : J) and that
J(I : J) ‚äÜI.
(ii) Prove that if I = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr, then
(I : J) = (Q1 : J) ‚à©¬∑ ¬∑ ¬∑ ‚à©(Qr : J).
(iii) If I is an ideal in a commutative ring R, and if J = J1 + ¬∑ ¬∑ ¬∑ + Jn is a sum of ideals,
prove that
(I : J) = (I : J1) ‚à©¬∑ ¬∑ ¬∑ ‚à©(I : Jn).
6.15 A Boolean ring is a commutative ring R in which a2 = a for all a ‚ààR. Prove that every
prime ideal in a Boolean ring is a maximal ideal. (See Exercise 8.21 on page 533.)
Hint. When is a Boolean ring a domain?
6.16 A commutative ring R is called a local ring if it has a unique maximal ideal.
(i) If p is a prime, prove that the ring of p-adic fractions,
Z(p) = {a/b ‚ààQ: p ‚à§b},
is a local ring.
(ii) If R is a local ring with unique maximal ideal m, prove that a ‚ààR is a unit if and only
if a /‚ààm.
Hint. You may assume that every nonunit in a commutative ring lies in some maximal
ideal (this result is proved using Zorn's lemma).
6.2 UNIQUE FACTORIZATION DOMAINS
We have proved unique factorization theorems in Z and in k[x], where k is a Ô¨Åeld. We
are now going to prove a common generalization: Every PID has a unique factorization
theorem. We will then prove a theorem of Gauss: If R has unique factorization, then so
does R[x]. A corollary is that there is unique factorization in the ring k[x1, . . . , xn] of all
polynomials in several variables over a Ô¨Åeld k. One immediate consequence is that any
two polynomials in several variables have a gcd.
We begin by generalizing some earlier deÔ¨Ånitions.
1This ideal is also called the ideal quotient.

Sec. 6.2
Unique Factorization Domains
327
DeÔ¨Ånition.
Elements a and b in a commutative ring R are associates if there exists a unit
u ‚ààR with b = ua.
For example, in Z, the units are ¬±1, and so the only associates of an integer m are ¬±m;
in k[x], where k is a Ô¨Åeld, the units are the nonzero constants, and so the only associates
of a polynomial f (x) ‚ààk[x] are the polynomials u f (x), where u ‚ààk and u Ã∏= 0. The
only units in Z[x] are ¬±1 (see Exercise 6.19 on page 339), and so the only associates of a
polynomial f (x) ‚ààZ[x] are ¬± f (x).
In any commutative ring R, associates a and b generate the same principal ideal; the
converse may be false if R is not a domain.
Proposition 6.15.
Let R be a domain and let a, b ‚ààR.
(i) a | b and b | a if and only if a and b are associates.
(ii) The principal ideals (a) and (b) are equal if and only if a and b are associates.
Proof.
(i) If a | b and b | a, there are r, s ‚ààR with b = ra and a = sb, and so
b = ra = rsb. If b = 0, then a = 0 (because b | a); if b Ã∏= 0, then we may cancel it (R
is a domain) to obtain 1 = rs. Hence, r and s are units, and a and b are associates. The
converse is obvious.
(ii) If (a) = (b), then a ‚àà(b); hence, a = rb for some r ‚ààR, and so b | a. Similarly,
b ‚àà(a) implies a | b, and so (i) shows that a and b are associates.
Conversely, if a = ub, where u is a unit, then a ‚àà(b) and (a) ‚äÜ(b). Similarly,
b = u‚àí1a implies (b) ‚äÜ(a), and so (a) = (b).
‚Ä¢
Recall that an element p in a domain R is irreducible if it is neither 0 nor a unit and
if its only factors are units or associates of p. For example, the irreducibles in Z are
the numbers ¬±p, where p is a prime, and the irreducibles in k[x], where k is a Ô¨Åeld,
are the irreducible polynomials p(x); that is, deg(p) ‚â•1 and p(x) has no factorization
p(x) = f (x)g(x) where deg( f ) < deg(p) and deg(g) < deg(p). This characterization of
irreducible polynomials does not persist in rings R[x] when R is not a Ô¨Åeld. For example,
in Z[x], the polynomial f (x) = 2x + 2 cannot be factored into two polynomials, each
having degree smaller than deg( f ) = 1, yet f (x) is not irreducible, for in the factorization
2x + 2 = 2(x + 1), neither 2 nor x + 1 is a unit.
Corollary 6.16.
If R is a PID and p ‚ààR is irreducible, then (p) is a prime ideal.
Proof.
Let I be an ideal with (p) ‚äÜI. Since R is a PID, there is q ‚ààR with I = (q).
Hence, p ‚àà(q), and so p = rq for some r ‚ààR. Irreducibility of p says that q is either
an associate of p or a unit. In the Ô¨Årst case, (p) = (q), by Proposition 6.15; in the second
case, (q) = R. It follows that (p) is a maximal ideal, and hence it is a prime ideal, by
Corollary 6.8.
‚Ä¢
Here is the deÔ¨Ånition we have been seeking.

328
Commutative Rings II
Ch. 6
DeÔ¨Ånition.
A domain R is a unique factorization domain (UFD) if
(i) every r ‚ààR, neither 0 nor a unit, is a product2 of irreducibles;
(ii) if up1 ¬∑ ¬∑ ¬∑ pm = vq1 ¬∑ ¬∑ ¬∑ qn, where u and v are units and all pi and q j are irreducible,
then m = n and there is a permutation œÉ ‚ààSn with pi and qœÉ(i) associates for all i.
When we proved that Z and k[x], for k a Ô¨Åeld, have unique factorization into irre-
ducibles, we did not mention associates because, in each case, irreducible elements were
always replaced by favorite choices of associates: In Z, positive irreducibles (i.e., primes)
are chosen; in k[x], monic irreducible polynomials are chosen. The reader should see, for
example, that the statement: "Z is a UFD" is just a restatement of the fundamental theorem
of arithmetic.
Proposition 6.17.
Let R be a domain in which every r ‚ààR, neither 0 nor a unit, is a
product of irreducibles. Then R is a UFD if and only if (p) is a prime ideal in R for every
irrreducible element p ‚ààR.3
Proof.
Assume that R is a UFD. If a, b ‚ààR and ab ‚àà(p), then there is r ‚ààR with
ab = rp.
Factor each of a, b, and r into irreducibles; by unique factorization, the left side of the
equation must involve an associate of p. This associate arose as a factor of a or b, and
hence a ‚àà(p) or b ‚àà(p).
The proof of the converse is merely an adaptation of the proof of the fundamental theo-
rem of arithmetic. Assume that
up1 ¬∑ ¬∑ ¬∑ pm = vq1 ¬∑ ¬∑ ¬∑ qn,
where pi and q j are irreducible elements and u, v are units. We prove, by induction on
max{m, n} ‚â•1, that n = m and the q's can be reindexed so that qi and pi are associates
for all i. If max{m, n} = 1, then up1 = vq1, up1 = v, or u = vq1. The latter two
cases cannot occur, for irreducible elements are not units, and so the base step is true. For
the inductive step, the given equation shows that p1 | q1 ¬∑ ¬∑ ¬∑ qn. By hypothesis, (p1) is a
prime ideal (which is the analog of Euclid's lemma), and so there is some q j with p1 | q j.
But q j, being irreducible, has no divisors other than units and associates, so that q j and
p1 are associates: q j = up1 for some unit u. Canceling p1 from both sides, we have
p2 ¬∑ ¬∑ ¬∑ pm = uq1 ¬∑ ¬∑ ¬∑ 
q j ¬∑ ¬∑ ¬∑ qn. By the inductive hypothesis, m ‚àí1 = n ‚àí1 (so that m = n),
and, after possible reindexing, qi and pi are associates for all i.
‚Ä¢
The proofs we have given that Z and k[x], where k is a Ô¨Åeld, are UFDs involve the
division algorithm; as a consequence, it is not difÔ¨Åcult to generalize them to prove that
every euclidean ring is a UFD. We now show that every PID is, in fact, a UFD; the proof
uses a new idea: chains of ideals.
2To avoid long phrases, we allow a product of irreducibles to have only one factor; that is, an irreducible
element is regarded as a product of irreducibles.
3An element p for which (p) is a nonzero prime ideal is often called a prime element. Such elements have
the property that p | ab implies p | a or p | b.

Sec. 6.2
Unique Factorization Domains
329
Lemma 6.18.
(i) If R is a commutative ring and
I1 ‚äÜI2 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜIn ‚äÜIn+1 ‚äÜ¬∑ ¬∑ ¬∑
is an ascending chain of ideals in R, then J = !
n‚â•1 In is an ideal in R.
(ii) If R is a PID, then it has no inÔ¨Ånite strictly ascending chain of ideals
I1 ‚ääI2 ‚ää¬∑ ¬∑ ¬∑ ‚ääIn ‚ääIn+1 ‚ää¬∑ ¬∑ ¬∑ .
(iii) Let R be a PID. If r ‚ààR is neither 0 nor a unit, then r is a product of irreducibles.
Proof.
(i) We claim that J is an ideal. If a ‚ààJ, then a ‚ààIn for some n; if r ‚ààR, then
ra ‚ààIn, because In is an ideal; hence, ra ‚ààJ. If a, b ‚ààJ, then there are ideals In and Im
with a ‚ààIn and b ‚ààIm; since the chain is ascending, we may assume that In ‚äÜIm, and so
a, b ‚ààIm. As Im is an ideal, a + b ‚ààIm and, hence, a + b ‚ààJ. Therefore, J is an ideal.
(ii) If, on the contrary, an inÔ¨Ånite strictly ascending chain exists, then deÔ¨Åne J = !
n‚â•1 In.
By (i), J is an ideal; since R is a PID, we have J = (d) for some d ‚ààJ. Now d got into J
by being in In for some n. Hence
J = (d) ‚äÜIn ‚ääIn+1 ‚äÜJ,
and this is a contradiction.
(iii) A divisor r of an element a ‚ààR is called a proper divisor of a if r is neither a unit
nor an associate of a. If r is a divisor of a, then (a) ‚äÜ(r); if r is a proper divisor, then
(a) ‚ää(r), for if the inequality is not strict, then (a) = (r), and this forces a and r to be
associates, by Proposition 6.15.
Call a nonzero nonunit a ‚ààR good if it is a product of irreducibles; otherwise, call a
bad. We must show that there are no bad elements. If a is bad, it is not irreducible, and so
a = rs, where both r and s are proper divisors. But the product of good elements is good,
and so at least one of the factors, say r, is bad. The Ô¨Årst paragraph shows that (a) ‚ää(r).
It follows, by induction, that there exists a sequence a1 = a, a2 = r, a3, . . . , an, . . . of
bad elements with each an+1 a proper divisor of an, and this sequence yields a strictly
ascending chain
(a1) ‚ää(a2) ‚ää¬∑ ¬∑ ¬∑ ‚ää(an) ‚ää(an+1) ‚ää¬∑ ¬∑ ¬∑ ,
contradicting part (i) of this lemma.
‚Ä¢
Theorem 6.19.
If R is a PID, then R is a UFD. In particular, every euclidean ring is a
UFD.
Proof.
In view of the last two results, it sufÔ¨Åces to prove that (p) is a prime ideal whenever
p is irreducible. Since R is a PID, Proposition 6.16 shows that (p) is a prime ideal.
‚Ä¢

330
Commutative Rings II
Ch. 6
The notion of gcd can be deÔ¨Åned in any commutative ring R. Example 6.21 shows that
there exist domains R containing a pair of elements having no gcd. If a1, . . . , an ‚ààR,
then a common divisor of a1, . . . , an is an element c ‚ààR with c | ai for all i. A greatest
common divisor or gcd of a1, . . . , an is a common divisor d with c | d for every common
divisor c. Even in the familiar examples of Z and k[x], gcd's are not unique unless an extra
condition is imposed. For example, in k[x], where k is a Ô¨Åeld, we impose the condition
that nonzero gcd's are monic polynomials. In a general PID, however, elements may not
have favorite associates.
If R is a domain, then it is easy to see that if d and d‚Ä≤ are gcd's of elements a1, . . . , an,
then d | d‚Ä≤ and d‚Ä≤ | d. It follows from Proposition 6.15 that d and d‚Ä≤ are associates and,
hence, that (d) = (d‚Ä≤). Thus, gcd's are not unique, but they all generate the same principal
ideal.
The idea in Proposition 1.17 carries over to show that gcd's do exist in UFDs.
Proposition 6.20.
If R is a UFD, then a gcd of any Ô¨Ånite set of elements a1, . . . , an in R
exists.
Proof.
It sufÔ¨Åces to prove that a gcd of two elements a and b exists; the general result
follows by induction on the number of elements.
There are units u and v and distinct irreducibles p1, . . . , pt with
a = upe1
1 pe2
2 ¬∑ ¬∑ ¬∑ pet
t
and
b = vp f1
1 p f2
2 ¬∑ ¬∑ ¬∑ p ft
t ,
where ei ‚â•0 and fi ‚â•0 for all i. It is easy to see that if c | a, then the factorization of c
into irreducibles is c = wpg1
1 pg2
2 ¬∑ ¬∑ ¬∑ pgt
t , where w is a unit and 0 ‚â§gi ‚â§ei for all i. Thus,
c is a common divisor of a and b if and only if gi ‚â§mi for all i, where
mi = min{ei, fi}.
It is now clear that pm1
1 pm2
2
¬∑ ¬∑ ¬∑ pmt
t
is a gcd of a and b.
‚Ä¢
It is not difÔ¨Åcult to see that if ai = ui pei1
1 pei2
2 ¬∑ ¬∑ ¬∑ peit
t , where ei j ‚â•0, ui are units, and
i = 1, . . . , n, then
d = p¬µ1
1 p¬µ2
2 ¬∑ ¬∑ ¬∑ p¬µt
t
is a gcd of a1, . . . , an, where ¬µ j = min{e1 j, e2 j, . . . , enj}.
We caution the reader that we have not proved that a gcd of elements a1, . . . , an is a
linear combination of them; indeed, this may not be true (see Exercise 6.21 on page 339).
Example 6.21.
Let k be a Ô¨Åeld and let R be the subring of k[x] consisting of all polynomials f (x) ‚ààk[x]
having no linear term; that is, f (x) = a0+a2x2+¬∑ ¬∑ ¬∑+anxn. In Exercise 3.60 on page 158,
we showed that x5 and x6 have no gcd in R. It now follows from Proposition 6.20 that R
is not a UFD. [Another example of a domain that is not a UFD is given in Exercise 6.31(ii)
on page 340.]
‚óÄ

Sec. 6.2
Unique Factorization Domains
331
DeÔ¨Ånition.
Elements a1, . . . , an in a UFD R are called relatively prime if their gcd is a
unit; that is, if every common divisor of a1, . . . , an is a unit.
We are now going to prove that if R is a UFD, then so is R[x]. Recall Exercise 3.21 on
page 130: If R is a domain, then the units in R[x] are the units in R.
DeÔ¨Ånition.
A polynomial f (x) = anxn + ¬∑ ¬∑ ¬∑ + a1x + a0 ‚ààR[x], where R is a UFD, is
called primitive if its coefÔ¨Åcients are relatively prime; that is, the only common divisors of
an, . . . , a1, a0 are units.
Of course, every monic polynomial is primitive. Observe that if f (x) is not primitive,
then there exists an irreducible q ‚ààR that divides each of its coefÔ¨Åcients: If the gcd is a
nonunit d, then take for q any irreducible factor of d.
Example 6.22.
We now show, for a UFD R, that every irreducible p(x) ‚ààR[x] of positive degree is
primitive. If not, then there is an irreducible q ‚ààR with p(x) = qg(x); note that deg(q) =
0 because q ‚ààR. Since p(x) is irreducible, its only factors are units and associates, and so
q must be an associate of p(x). But every unit in R[x] has degree 0 [i.e., is a constant (for
uv = 1 implies deg(u) + deg(v) = deg(1) = 0)]; hence, associates in R[x] have the same
degree. Therefore, q is not an associate of p(x), because the latter has positive degree, and
so p(x) is primitive.
‚óÄ
We begin with a technical lemma.
Lemma 6.23 (Gauss's Lemma).
If R is a UFD and f (x), g(x) ‚ààR[x] are both primi-
tive, then their product f (x)g(x) is also primitive.
Proof.
If œÄ : R ‚ÜíR/(p) is the natural map œÄ : a ‚Üía + (p), then Proposition 3.48
shows that the function œÄ : R[x] ‚Üí(R/(p)) [x], which replaces each coefÔ¨Åcient c of
a polynomial by œÄ(c), is a ring homomorphism. If a polynomial h(x) ‚ààR[x] is not
primitive, there is some irreducible p such that all the coefÔ¨Åcients of œÄ(h) are 0 in R/(p);
that is, œÄ(h) = 0 in (R/(p)) [x]. Thus, if the product f (x)g(x) is not primitive, there is
some irreducible p with 0 = œÄ( f g) = œÄ( f )œÄ(g) in (R/(p)) [x]. Since (p) is a prime
ideal, R/(p) is a domain, and hence (R/(p)) [x] is also a domain. But, neither œÄ( f ) nor
œÄ(g) is 0 in (R/(p)) [x], because f and g are primitive, and this contradicts (R/(p)) [x]
being a domain.
‚Ä¢
Lemma 6.24.
Let R be a UFD, let Q = Frac(R), and let f (x) ‚ààQ[x] be nonzero.
(i) There is a factorization
f (x) = c( f ) f ‚àó(x),
where c( f ) ‚ààQ and f ‚àó(x) ‚ààR[x] is primitive. This factorization is unique in the
sense that if f (x) = qg‚àó(x), where q ‚ààQ and g‚àó(x) ‚ààR[x] is primitive, then there
is a unit w ‚ààR with q = wc( f ) and g‚àó(x) = w‚àí1 f ‚àó(x).

332
Commutative Rings II
Ch. 6
(ii) If f (x), g(x) ‚ààR[x], then c( f g) and c( f )c(g) are associates in R and ( f g)‚àóand
f ‚àóg‚àóare associates in R[x].
(iii) Let f (x) ‚ààQ[x] have a factorization f (x) = qg‚àó(x), where q ‚ààQ and g‚àó(x) ‚àà
R[x] is primitive. Then f (x) ‚ààR[x] if and only if q ‚ààR.
(iv) Let g‚àó(x), f (x) ‚ààR[x]. If g‚àó(x) is primitive and g‚àó(x) | bf (x), where b ‚ààR and
b Ã∏= 0, then g‚àó(x) | f (x).
Proof.
(i) Clearing denominators, there is b ‚ààR with bf (x) ‚ààR[x]. If d is the gcd of
the coefÔ¨Åcients of bf (x), then (b/d) f (x) ‚ààR[x] is a primitive polynomial. If we deÔ¨Åne
c( f ) = d/b and f ‚àó(x) = c( f ) f (x), then f ‚àó(x) is primitive and f (x) = c( f ) f ‚àó(x).
To prove uniqueness, suppose that c( f ) f ‚àó(x) = f (x) = qg‚àó(x), where c( f ), q ‚ààQ
and f ‚àó(x), g‚àó(x) ‚ààR[x] are primitive. Exercise 6.17 on page 339 allows us to write
q/c( f ) in lowest terms: q/c( f ) = u/v, where u and v are relatively prime elements of R.
The equation vf ‚àó(x) = ug‚àó(x) holds in R[x]; equating like coefÔ¨Åcients, v is a common
divisor of each coefÔ¨Åcient of ug‚àó(x). Since u and v are relatively prime, Exercise 6.18(i)
on page 339 gives v a common divisor of the coefÔ¨Åcients of g‚àó(x). But g‚àó(x) is primitive,
and so v is a unit. A similar argument shows that u is a unit. Therefore, q/c( f ) = u/v is
a unit in R, call it w; we have wc( f ) = q and f ‚àó(x) = wg‚àó(x), as desired.
(ii) There are two factorizations of f (x)g(x) in R[x]: f (x)g(x) = c( f g)( f (x)g(x))‚àóand
f (x)g(x) = c( f ) f ‚àó(x)c(g)g‚àó(x) = c( f )c(g) f ‚àó(x)g‚àó(x). Since the product of primitive
polynomials is primitive, each of these is a factorization as in part (i), and the uniqueness
assertion there gives c( f g) an associate of c( f )c(g) and ( f g)‚àóan associate of f ‚àóg‚àó.
(iii) If q ‚ààR, then it is obvious that f (x) = qg‚àó(x) ‚ààR[x]. Conversely, if f (x) ‚ààR[x],
then there is no need to clear denominators, and so c( f ) = d ‚ààR, where d is the gcd of
the coefÔ¨Åcients of f (x). Thus, f (x) = d f ‚àó(x). By uniqueness, there is a unit w ‚ààR with
q = wd ‚ààR.
(iv) Since bf = hg‚àó, we have bc( f ) f ‚àó= c(h)h‚àóg‚àó= c(h)(hg)‚àó. By uniqueness, f ‚àó,
(hg)‚àó, and h‚àóg‚àóare associates, and so g‚àó| f ‚àó. But f = c( f ) f ‚àó, and so g‚àó| f .
‚Ä¢
DeÔ¨Ånition.
Let R be a UFD with Q = Frac(R). If f (x) ‚ààQ[x], there is a factorization
f (x) = c( f ) f ‚àó(x), where c( f ) ‚ààQ and f ‚àó(x) ‚ààR[x] is primitive. We call c( f ) the
content of f (x) and f ‚àó(x) the associated primitive polynomial.
In light of Lemma 6.24(i), both c( f ) and f ‚àó(x) are essentially unique, differing only
by a unit in R.
Theorem 6.25 (Gauss).
If R is a UFD, then R[x] is also a UFD.
Proof.
We show Ô¨Årst, by induction on deg( f ), that every f (x) ‚ààR[x], neither zero
nor a unit, is a product of irreducibles. If deg( f ) = 0, then f (x) is a constant, hence
lies in R. Since R is a UFD, f is a product of irreducibles. If deg( f ) > 0, then f (x) =

Sec. 6.2
Unique Factorization Domains
333
c( f ) f ‚àó(x), where c( f ) ‚ààR and f ‚àó(x) is primitive. Now c( f ) is either a unit or a product
of irreducibles, by the base step. If f ‚àó(x) is irreducible, we are done. Otherwise, f ‚àó(x) =
g(x)h(x), where neither g nor h is a unit. Since f ‚àó(x) is primitive, however, neither g nor
h is a constant; therefore, each of these has degree less than deg( f ‚àó) = deg( f ), and so
each is a product of irreducibles, by the inductive hypothesis.
Proposition 6.17 now applies: R[x] is a UFD if (p(x)) is a prime ideal for every ir-
reducible p(x) ‚ààR[x]; that is, if p | f g, then p | f or p | g. Let us assume that
p(x) ‚à§f (x).
Case (i). Suppose that deg(p) = 0. Write
f (x) = c( f ) f ‚àó(x) and g(x) = c(g)g‚àó(x),
where c( f ), c(g) ‚ààR, and f ‚àó(x), g‚àó(x) are primitive. Now p | f g, so that
p | c( f )c(g) f ‚àó(x)g‚àó(x).
Since f ‚àó(x)g‚àó(x) is primitive, Lemma 6.24(ii) says that c( f )c(g) an associate of c( f g).
However, if p | f (x)g(x), then p divides each coefÔ¨Åcient of f g; that is, p is a common
divisor of all the coefÔ¨Åcients of f g, and hence in R, which is a UFD, p divides the asso-
ciates c( f g) and c( f )c(g). But Proposition 6.17 says that (p) is a prime ideal in R, and
so p | c( f ) or p | c(g). If p | c( f ), then p divides c( f ) f ‚àó(x) = f (x), a contradiction.
Therefore, p | c(g) and, hence, p | g(x), as desired.
Case (ii). Suppose that deg(p) > 0. Let
(p, f ) =

s(x)p(x) + t(x) f (x): s(x), t(x) ‚ààR[x]

;
of course, (p, f ) is an ideal containing p(x) and f (x). Choose m(x) ‚àà(p, f ) of minimal
degree. If Q = Frac(R) is the fraction Ô¨Åeld of R, then the division algorithm in Q[x] gives
polynomials q‚Ä≤(x),r‚Ä≤(x) ‚ààQ[x] with
f (x) = m(x)q‚Ä≤(x) + r‚Ä≤(x),
where either r‚Ä≤(x) = 0 or deg(r‚Ä≤) < deg(m). Clearing denominators, there are polynomials
q(x),r(x) ‚ààR[x] and a constant b ‚ààR with
bf (x) = q(x)m(x) + r(x),
where r(x) = 0 or deg(r) < deg(m). Since m ‚àà(p, f ), there are polynomials s(x), t(x) ‚àà
R[x] with m(x) = s(x)p(x) + t(x) f (x); hence r = bf ‚àíqm ‚àà(p, f ). Since m has
minimal degree in (p, f ), we must have r = 0; that is, bf (x) = m(x)q(x), and so bf (x) =
c(m)m‚àó(x)q(x). But m‚àó(x) is primitive, and m‚àó(x) | bf (x), so that m‚àó(x) | f (x), by
Lemma 6.24(iv). A similar argument, replacing f (x) by p(x) (that is, beginning with an
equation b‚Ä≤‚Ä≤ p(x) = q‚Ä≤‚Ä≤(x)m(x) + r‚Ä≤‚Ä≤(x) for some constant b‚Ä≤‚Ä≤), gives m‚àó(x) | p(x). Since
p(x) is irreducible, its only factors are units and associates. If m‚àó(x) were an associate of
p(x), then p(x) | f (x) (because p(x) | m‚àó(x) | f (x)), contrary to the hypothesis. Hence,

334
Commutative Rings II
Ch. 6
m‚àó(x) must be a unit; that is, m(x) = c(m) ‚ààR, and so (p, f ) contains the nonzero
constant c(m). Now c(m) = sp + t f , and so
c(m)g(x) = s(x)p(x)g(x) + t(x) f (x)g(x).
Since p(x) | f (x)g(x), we have p(x) | c(m)g(x). But p(x) is primitive, because it is
irreducible, by Example 6.22, and so Lemma 6.24(iv) gives p(x) | g(x).
‚Ä¢
Corollary 6.26.
If k is a Ô¨Åeld, then k[x1, . . . , xn] is a UFD.
Proof.
The proof is by induction on n ‚â•1. We proved, in Chapter 3, that the polynomial
ring k[x1] in one variable is a UFD. For the inductive step, recall that k[x1, . . . , xn, xn+1] =
R[xn+1], where R = k[x1, . . . , xn]. By induction, R is a UFD, and by Corollary 6.25, so
is R[xn+1].
‚Ä¢
Proposition 6.20 shows that if k is a Ô¨Åeld, then gcd's exist in k[x1, . . . , xn].
Corollary 6.27 (Gauss).
Let R be a UFD, let Q = Frac(R), and let f (x) ‚ààR[x]. If
f (x) = G(x)H(x) in Q[x],
then there is a factorization
f (x) = g(x)h(x) in R[x],
where deg(g) = deg(G) and deg(h) = deg(H); in fact, G(x) is a constant multiple of
g(x) and H(x) is a constant multiple of h(x). Therefore, if f (x) does not factor into
polynomials of smaller degree in R[x], then f (x) is irreducible in Q[x].
Proof.
By Lemma 6.24(i), the factorization f (x) = G(x)H(x) in Q[x] gives q, q‚Ä≤ ‚ààQ
with
f (x) = qG‚àó(x)q‚Ä≤H‚àó(x) in Q[x],
where G‚àó(x), H‚àó(x) ‚ààR[x] are primitive. But G‚àó(x)H‚àó(x) is primitive, by Gauss's
lemma. Since f (x) ‚ààR[x], Lemma 6.24(iii) applies to say that the equation f (x) =
qq‚Ä≤[G‚àó(x)H‚àó(x)] forces qq‚Ä≤ ‚ààR. Therefore, qq‚Ä≤G‚àó(x) ‚ààR[x], and a factorization of
f (x) in R[x] is f (x) = [qq‚Ä≤G‚àó(x)]H‚àó(x).
‚Ä¢
The special case R = Z and Q = Q is, of course, important.
Example 6.28.
We claim that f (x, y) = x2 + y2 ‚àí1 ‚ààk[x, y] is irreducible, where k is a Ô¨Åeld. Write
Q = k(y) = Frac(k[y]), and view f (x, y) ‚ààQ[x]. Now the quadratic g(x) = x2 +
(y2 ‚àí1) is irreducible in Q[x] if and only if it has no roots in Q = k(y), and this is so, by
Exercise 3.34 on page 142.
It follows from Proposition 6.17 that (x2+y2‚àí1) is a prime ideal because it is generated
by an irreducible polynomial.
‚óÄ
Recall that a complex number is an algebraic integer if it is a root of a monic polynomial
in Z[x]. Each algebraic integer has an irreducible polynomial associated with it.

Sec. 6.2
Unique Factorization Domains
335
Corollary 6.29.
If Œ± is an algebraic integer, then irr(Œ±, Q) lies in Z[x].
Proof.
Let p(x) ‚ààZ[x] be the monic polynomial of least degree having Œ± as a root. If
p(x) = G(x)H(x) in Q[x], where deg(G) < deg(p) and deg(H) < deg(p), then Œ± is a
root of either G(x) or H(x). By Gauss's theorem, there is a factorization p(x) = g(x)h(x)
in Z[x] with deg(g) = deg(G) and deg(h) = deg(H); in fact, there are rationals c and d
with g(x) = cG(x) and h(x) = d H(x). If a is the leading coefÔ¨Åcient of g(x) and b is the
leading coefÔ¨Åcient of h(x), then ab = 1, for p(x) is monic. Therefore, we may assume
that a = 1 = b, for a, b ‚ààZ; that is, we may assume that both g(x) and h(x) are monic.
Since Œ± is a root of g(x) or h(x), we have contradicted p(x) being a monic polynomial in
Z[x] of least degree having Œ± as a root. It follows that p(x) = irr(Œ±, Q), for the latter is
the unique monic irreducible polynomial in Q[x] having Œ± as a root.
‚Ä¢
DeÔ¨Ånition.
If Œ± is an algebraic integer, then its minimal polynomial is the monic poly-
nomial in Z[x] of least degree having Œ± as a root.
Corollary 6.29 shows that every algebraic integer Œ± has a unique minimal polynomial
m(x) ‚ààZ[x], namely, m(x) = irr(Œ±, Q), and m(x) is irreducible in Q[x].
Remark.
We deÔ¨Åne the (algebraic) conjugates of Œ± to be the roots of irr(Œ±, Q), and we
deÔ¨Åne the norm of Œ± to be the absolute value of the product of the conjugates of Œ±. Of
course, the norm of Œ± is just the absolute value of the constant term of irr(Œ±, Q), and so it is
an (ordinary) integer. Norms are very useful in algebraic number theory, as we have seen in
the proof of Theorem 3.66: Fermat's two-squares theorem. We have also considered them
in the proof of Hilbert's Theorem 90, which was used to prove that if the Galois group of a
polynomial f (x) ‚ààk[x] is solvable, where k has characteristic 0, then f (x) is solvable by
radicals.
‚óÄ
The next criterion uses the integers mod p.
Theorem 6.30.
Let f (x) = a0 + a1x + a2x2 + ¬∑ ¬∑ ¬∑ + xn ‚ààZ[x] be monic, and let p be
a prime. If f (x) is irreducible mod p, that is, if
f (x) = [a0] + [a1]x + [a2]x2 + ¬∑ ¬∑ ¬∑ + xn ‚ààFp[x],
is irreducible, then f (x) is irreducible in Q[x].
Proof.
By Proposition 3.48, the natural map œï : Z ‚ÜíFp deÔ¨Ånes a homomorphism
œï : Z[x] ‚ÜíFp[x] by
œï(b0 + b1x + b2x2 + ¬∑ ¬∑ ¬∑ ) = [b0] + [b1]x + [b2]x2 + ¬∑ ¬∑ ¬∑ ;
that is, just reduce all the coefÔ¨Åcients mod p. If g(x) ‚ààZ[x], denote its image œï(g(x)) ‚àà
Fp[x] by g(x). Suppose that f (x) factors in Z[x]; say, f (x) = g(x)h(x), where deg(g) <
deg( f ) and deg(h) < deg( f ); of course, deg( f ) = deg(g) + deg(h). Now f (x) =
g(x)h(x), because œï is a ring homomorphism, so that deg( f ) = deg(g) + deg(h). Since

336
Commutative Rings II
Ch. 6
f (x) is monic, f (x) is also monic, and so deg( f ) = deg( f ). Thus, both g(x) and h(x)
have degrees less than deg( f ), contradicting the irreducibility of f (x). Therefore, f (x)
is irreducible in Z[x], and, by Gauss's theorem, Corollary 6.27, f (x) is irreducible in
Q[x].
‚Ä¢
Example 6.31.
The converse of Theorem 6.30 is false. It is easy to Ô¨Ånd an irreducible polynomial f (x) ‚àà
Z[x] ‚äÜQ[x] with f (x) factoring mod p for some prime p, but we now show that f (x) =
x4 + 1 is an irreducible polynomial in Z[x] that factors mod p for every prime p.
First, f (x) is irreducible in Q[x]. By Corollary 3.44, f (x) has no rational roots, and so
the only possible factorization in Q[x] has the form
x4 + 1 = (x2 + ax + b)(x2 ‚àíax + c).
Multiplying out and equating like coefÔ¨Åcients gives
c + b ‚àía2 = 0
a(c ‚àíb) = 0
bc = 1.
The second equation forces a = 0 or c = b, and it is quickly seen that either possibility
leads to a contradiction.
We now show, for all primes p, that x4 + 1 is not irreducible in Fp[x]. If p = 2,
then x4 + 1 = (x + 1)4, and so we may assume that p is an odd prime. As we saw in
Example 1.21(i), every square is congruent to 0, 1, or 4 mod 8; since p is odd, we must
have p2 ‚â°1 mod 8. Therefore, |(Fp2)√ó| = p2 ‚àí1 is divisible by 8. But (Fp2)√ó is a cyclic
group, and so it has a (cyclic) subgroup of order 8, by Lemma 2.85. It follows that Fp2
contains all the 8th roots of unity; in particular, Fp2 contains all the roots of x4 +1. Hence,
the splitting Ô¨Åeld E p of x4 + 1 over Fp is Fp2, and so [E p : Fp] = 2. But if x4 + 1 were
irreducible in Fp[x], then 4 | [E p : Fp], by Corollary 4.9. Therefore, x4 + 1 factors in
Fp[x] for every prime p.
‚óÄ
Theorem 6.30 says that if we can Ô¨Ånd a prime p with f (x) irreducible in Fp[x], then
f (x) is irreducible in Q[x]. Until now, the Ô¨Ånite Ô¨Åelds Fp have been oddities; Fp has
appeared only as a curious artiÔ¨Åcial construct. Now the Ô¨Åniteness of Fp is a genuine
advantage, for there are only a Ô¨Ånite number of polynomials in Fp[x] of any given degree.
In Examples 3.35(i) and 3.35(ii), we displayed all the monic irreducible polynomials over
F2 and over F3 of degree ‚â§3. In principle, then, we can test whether a polynomial of
degree n in Fp[x] is irreducible by just looking at all the possible factorizations of it.
Example 6.32.
(i) We show that f (x) = x4 ‚àí5x3 + 2x + 3 is an irreducible polynomial in Q[x].
By Corollary 3.44, the only candidates for rational roots of f (x) are 1, ‚àí1, 3, ‚àí3, and
the reader may check that none of these is a root. Since f (x) is a quartic, we cannot yet
conclude that f (x) is irreducible, for it might be a product of (irreducible) quadratics.

Sec. 6.2
Unique Factorization Domains
337
Let us try the criterion of Theorem 6.30. Since f (x) = x4 + x3 + 1 in F2[x] is ir-
reducible, by Example 3.35(i), it follows that f (x) is irreducible in Q[x]. [It was not
necessary to check that f (x) has no rational roots; the irreducibility of f (x) is enough to
conclude the irreducibility of f (x).]
(ii) Let 5(x) = x4 + x3 + x2 + x + 1 ‚ààQ[x].
In Example 3.35(i), we saw that 5(x) = x4 + x3 + x2 + x + 1 is irreducible in F2[x],
and so 5(x) is irreducible in Q[x].
‚óÄ
Recall that if n is a positive integer, then the nth cyclotomic polynomial is
n(x) =

(x ‚àíŒ∂),
where Œ∂ ranges over all the primitive nth roots of unity.
By Proposition 1.37, for every integer n ‚â•1,
xn ‚àí1 =

d|n
d(x),
where d ranges over all the divisors d of n. Now 1(x) = x ‚àí1. When p is prime, then
x p ‚àí1 = 1(x)p(x) = (x ‚àí1)p(x),
and so
p(x) = (x p ‚àí1)/(x ‚àí1) = x p‚àí1 + x p‚àí2 + ¬∑ ¬∑ ¬∑ + x + 1.
As any linear polynomial, 2(x) = x + 1 is irreducible in Q[x]; the cyclotomic poly-
nomial 3(x) = x2 + x +1 is irreducible in Q[x] because it has no rational roots; we have
just seen that 5(x) is irreducible in Q[x]. Let us introduce another irreducibility criterion
in order to prove that p(x) is irreducible in Q[x] for all primes p.
Lemma 6.33.
Let g(x) ‚ààZ[x]. If there is c ‚ààZ with g(x + c) irreducible in Z[x], then
g(x) is irreducible in Q[x].
Proof.
By Exercise 3.43 on page 149, the function œï : Z[x] ‚ÜíZ[x], given by f (x) ‚Üí
f (x + c), is an isomorphism. If g(x) = s(x)t(x), then g(x + c) = œï(g(x)) = œï(st) =
œï(s)œï(t) is a forbidden factorization of g(x + c). Therefore, g(x) is irreducible in Z[x]
and hence, by Gauss's theorem, Corollary 6.27, g(x) is irreducible in Q[x].
‚Ä¢
The next result was found by G. Eisenstein. The following elegant proof of Eisenstein's
criterion is in a 1969 paper of R. Singer; see Montgomery-Ralston, Selected Papers in
Algebra.
Theorem 6.34 (Eisenstein Criterion).
Let R be a UFD with Q = Frac(R), and let
f (x) = a0 +a1x +¬∑ ¬∑ ¬∑+anxn ‚ààR[x]. If there is an irreducible element p ‚ààR with p | ai
for all i < n but with p ‚à§an and p2 ‚à§a0, then f (x) is irreducible in Q[x].

338
Commutative Rings II
Ch. 6
Proof.
Let œï : Z[x] ‚ÜíFp[x] be the ring homomorphism that reduces coefÔ¨Åcients mod p,
and let f (x) denote œï( f (x)). If f (x) is not irreducible in Q[x], then Gauss's theorem,
Corollary 6.27, gives polynomials g(x), h(x) ‚ààZ[x] with f (x) = g(x)h(x), where
g(x) = b0 + b1x + ¬∑ ¬∑ ¬∑ + bmxm and h(x) = c0 + c1x + ¬∑ ¬∑ ¬∑ + ckxk. There is thus an
equation f (x) = g(x)h(x) in Fp[x].
Since p does not divide an, we have f (x) Ã∏= 0; in fact, f (x) = uxn for some unit u ‚àà
Fp, because all its coefÔ¨Åcients aside from its leading coefÔ¨Åcient are 0. By Theorem 3.42,
unique factorization in Fp[x], we must have g(x) = vxm, where v is a unit in Fp, for
any irreducible factor of g(x) is an irreducible factor of f (x); similarly, h(x) = wxk,
where w is a unit in Fp. It follows that each of g(x) and h(x) has constant term 0; that is,
[b0] = 0 = [c0] in Fp; equivalently, p | b0 and p | c0. But a0 = b0c0, and so p2 | a0, a
contradiction. Therefore, f (x) is irreducible in Q[x].
‚Ä¢
Of course, Eisenstein's criterion holds for polynomials in Z[x]. The generalization from
Z to PIDs is instantaneous.
Corollary 6.35 (Gauss).
For every prime p, the pth cyclotomic polynomial p(x) is
irreducible in Q[x].
Proof.
Since p(x) = (x p ‚àí1)/(x ‚àí1), we have
p(x + 1) = [(x + 1)p ‚àí1]/x
= x p‚àí1 +
p
1
	
x p‚àí2 +
p
2
	
x p‚àí3 + ¬∑ ¬∑ ¬∑ + p.
Since p is prime, Proposition 1.12 shows that Eisenstein's criterion applies; we conclude
that p(x + 1) is irreducible in Q[x]. By Lemma 6.33, p(x) is irreducible in Q[x].
‚Ä¢
We do not say that xn‚àí1 + xn‚àí2 + ¬∑ ¬∑ ¬∑ + x + 1 is irreducible when n is not prime. For
example, x3 + x2 + x + 1 = (x + 1)(x2 + 1).
Irreducibility of a polynomial in several variables is more difÔ¨Åcult to determine than
irreducibility of a polynomial of one variable, but here is one criterion.
Proposition 6.36.
Let k be a Ô¨Åeld and let f (x1, . . . , xn) be a primitive polynomial in
R[xn], where R = k[x1, . . . , xn‚àí1]. If f cannot be factored into two polynomials of lower
degree in R[xn], then f is irreducible in k[x1, . . . , xn].
Proof.
Let us write f (x1, . . . , xn) = F(xn) if we wish to view f as a polynomial in
R[xn] (of course, the coefÔ¨Åcients of F are polynomials in k[x1, . . . , xn‚àí1]). Suppose that
F(xn) = G(xn)H(xn); by hypothesis, the degrees of G and H (in xn) cannot both be
less than deg(F), and so one of them, say, G, has degree 0. It follows, because F is
primitive, that G is a unit in k[x1, . . . , xn‚àí1]. Therefore, f (x1, . . . , xn) is irreducible in
R[xn] = k[x1, . . . , xn].
‚Ä¢
Of course, the proposition applies to any variable xi, not just to xn.

Sec. 6.2
Unique Factorization Domains
339
Corollary 6.37.
If k is a Ô¨Åeld and g(x1, . . . , xn), h(x1, . . . , xn) ‚ààk[x1, . . . , xn] are
relatively prime, then f (x1, . . . , xn, y) = yg(x1, . . . , xn) + h(x1, . . . , xn) is irreducible in
k[x1, . . . , xn, y].
Proof.
Let R = k[x1, ¬∑ ¬∑ ¬∑ , xn]. Note that f is primitive in R[y], because (g, h) = 1
forces any divisor of its coefÔ¨Åcients g, h to be a unit. Since f is linear in y, it is not the
product of two polynomials in R[y] of smaller degree, and hence Proposition 6.36 shows
that f is irreducible in R[y] = k[x1, . . . , xn, y].
‚Ä¢
For example, xy2 + z is an irreducible polynomial in k[x, y, z] because it is a primitive
polynomial that is linear in x.
EXERCISES
6.17 Let R be a UFD and let Q = Frac(R) be its fraction Ô¨Åeld. Prove that each nonzero a/b ‚ààQ
has an expression in lowest terms; that is, a and b are relatively prime.
6.18 Let R be a UFD.
(i) If a, b, c ‚ààR and a and b are relatively prime, prove that a | bc implies a | c.
(ii) If a, c1, . . . , cn ‚ààR and ci | a for all i, prove that c | a, where c = lcm{c1, . . . , cn}.
6.19 If R is a domain, prove that the only units in R[x1, . . . , xn] are units in R. On the other hand,
prove that 2x + 1 is a unit in I4[x].
6.20 Prove that a UFD R is a PID if and only if every nonzero prime ideal is a maximal ideal.
6.21
(i) Prove that x and y are relatively prime in k[x, y], where k is a Ô¨Åeld.
(ii) Prove that 1 is not a linear combination of x and y in k[x, y].
6.22
(i) Prove that Z[x1, . . . , xn] is a UFD for all n ‚â•1.
(ii) If R is a Ô¨Åeld, prove that the ring of polynomials in inÔ¨Ånitely many variables, R =
k[x1, x2, . . . , xn. . . .], is also a UFD.
Hint.
We have not given a formal deÔ¨Ånition of R (it will be given in Chapter 8),
but, for the purposes of this exercise, regard R as the union of the ascending chain
k[x1] ‚ääk[x1, x2] ‚ää¬∑ ¬∑ ¬∑ ‚ääk[x1, x2, . . . , xn] ‚ää¬∑ ¬∑ ¬∑ .
6.23 Determine whether the following polynomials are irreducible in Q[x].
(i) f (x) = 3x2 ‚àí7x ‚àí5.
(ii) f (x) = 2x3 ‚àíx ‚àí6.
(iii) f (x) = 8x3 ‚àí6x ‚àí1.
(iv) f (x) = x3 + 6x2 + 5x + 25.
(v) f (x) = x4 + 8x + 12.
Hint. In F5[x], f (x) = (x + 1)g(x), where g(x) is irreducible.
(vi) f (x) = x5 ‚àí4x + 2.
(vii) f (x) = x4 + x2 + x + 1.
Hint. Show that f (x) has no roots in F3 and that a factorization of f (x) as a product
of quadratics would force impossible restrictions on the coefÔ¨Åcients.
(viii) f (x) = x4 ‚àí10x2 + 1.
Hint. Show that f (x) has no rational roots and that a factorization of f (x) as a product
of quadratics would force impossible restrictions on the coefÔ¨Åcients.

340
Commutative Rings II
Ch. 6
6.24 Is x5 + x + 1 irreducible in F2[x]?
Hint. Use Example 3.35(i).
6.25 Let f (x) = (x p ‚àí1)/(x ‚àí1), where p is prime. Using the identity
f (x + 1) = x p‚àí1 + pq(x),
where q(x) ‚ààZ[x] has constant term 1, prove that x pn(p‚àí1) + ¬∑ ¬∑ ¬∑ + x pn + 1 is irreducible in
Q[x] for all n ‚â•0.
6.26
(i) If a is a squarefree integer, prove that xn ‚àía is irreducible in Q[x] for every n ‚â•1.
Conclude that there are irreducible polynomials in Q[x] of every degree n ‚â•1.
Hint. Use the Eisenstein criterion.
(ii) If a is a squarefree integer, prove that n‚àöa is irrational for all n ‚â•2.
6.27 Let k be a Ô¨Åeld, and let f (x) = a0 + a1x + ¬∑ ¬∑ ¬∑ + anxn ‚ààk[x] have degree n and nonzero
constant term a0. Prove that if f (x) is irreducible, then so is an + an‚àí1x + ¬∑ ¬∑ ¬∑ + a0xn.
6.28 Let k be a Ô¨Åeld and let f (x1, . . . , xn) ‚ààk[x1, . . . , xn] be a primitive polynomial in R[xn],
where R = k[x1, . . . , xn‚àí1]. If f is either quadratic or cubic in xn, prove that f is irreducible
in k[x1, . . . , xn] if and only if f has no roots in k(x1, . . . , xn‚àí1).
6.29 Let R be a UFD with Q = Frac(R). If f (x) ‚ààR[x], prove that f (x) is irreducible in R[x] if
and only if f (x) is primitive and f (x) is irreducible in Q[x].
6.30 Prove that
f (x, y) = xy3 + x2y2 ‚àíx5y + x2 + 1
is an irreducible polynomial in R[x, y].
6.31 Let D = det
x
y
z
w
	
, so that D lies in the polynomial ring Z[x, y, z, w].
(i) Prove that (D) is a prime ideal in Z[x, y, z, w].
Hint. Prove Ô¨Årst that D is an irreducible element.
(ii) Prove that Z[x, y, z, w]/(D) is not a UFD. Another example of a domain which is not
a UFD is given in Example 6.21.
6.3 NOETHERIAN RINGS
One of the most important properties of k[x1, . . . , xn], when k is a Ô¨Åeld, is that every ideal
in it can be generated by a Ô¨Ånite number of elements. This property is intimately related to
chains of ideals, which we have already seen in the course of proving that PIDs are UFDs
(I apologize for so many acronyms, but here comes another one!).
DeÔ¨Ånition.
A commutative ring R satisÔ¨Åes the ACC, the ascending chain condition, if
every ascending chain of ideals
I1 ‚äÜI2 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜIn ‚äÜ¬∑ ¬∑ ¬∑
stops; that is, the sequence is constant from some point on: there is an integer N with
IN = IN+1 = IN+2 = ¬∑ ¬∑ ¬∑ .

Sec. 6.3
Noetherian Rings
341
Lemma 6.18(ii) shows that every PID satisÔ¨Åes the ACC.
Here is an important type of ideal.
DeÔ¨Ånition.
If X is a subset of a commutative ring R, then the ideal generated by X is
the set of all Ô¨Ånite linear combinations
I = (X) =

Ô¨Ånite
riai : ri ‚ààR and xi ‚ààX

.
We say that I is Ô¨Ånitely generated, often abbreviated to f.g., if X = {a1, . . . , an}; that is,
every element in I is an R-linear combination of the ai. We write
I = (a1, . . . , an),
and we call I the ideal generated by a1, . . . , an.
A set of generators a1, . . . , an of an ideal I is sometimes called a basis of I (even
though this is a weaker notion than that of a basis of a vector space, for we do not assume
that the coefÔ¨Åcients ri in the expression c = riai are uniquely determined by c).
Of course, every ideal I in a PID is Ô¨Ånitely generated, for it can be generated by one
element.
Proposition 6.38.
The following conditions are equivalent for a commutative ring R.
(i) R has the ACC.
(ii) R satisÔ¨Åes the maximum condition: Every nonempty family F of ideals in R has a
maximal element; that is, there is some I0 ‚ààF for which there is no I ‚ààF with
I0 ‚ääI.
(iii) Every ideal in R is Ô¨Ånitely generated.
Proof.
(i) ‚áí(ii): Let F be a family of ideals in R, and assume that F has no maximal
element. Choose I1 ‚ààF. Since I1 is not a maximal element, there is I2 ‚ààF with
I1 ‚ääI2. Now I2 is not a maximal element in F, and so there is I3 ‚ààF with I2 ‚ääI3.
Continuing in this way, we can construct an ascending chain of ideals in R that does not
stop, contradicting the ACC.
(ii) ‚áí(iii): Let I be an ideal in R, and deÔ¨Åne F to be the family of all the Ô¨Ånitely
generated ideals contained in I; of course, F Ã∏= ‚àÖ(for {0} ‚ààF). By hypothesis, there
exists a maximal element M ‚ààF. Now M ‚äÜI because M ‚ààF. If M ‚ääI, then there is
a ‚ààI with a /‚ààM. The ideal
J = {m + ra : m ‚ààM and r ‚ààR} ‚äÜI
is Ô¨Ånitely generated, and so J ‚ààF; but M ‚ääJ, and this contradicts the maximality of M.
Therefore, M = I, and so I is Ô¨Ånitely generated.
(iii) ‚áí(i): Assume that every ideal in R is Ô¨Ånitely generated, and let
I1 ‚äÜI2 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜIn ‚äÜ¬∑ ¬∑ ¬∑

342
Commutative Rings II
Ch. 6
be an ascending chain of ideals in R. By Lemma 6.18(i), the ascending union J = !
n‚â•1 In
is an ideal.
By hypothesis, there are elements ai ‚ààJ with J = (a1, . . . , aq). Now ai got into J by
being in Ini for some ni. If N is the largest ni, then Ini ‚äÜIN for all i; hence, ai ‚ààIN for
all i, and so
J = (a1, . . . , aq) ‚äÜIN ‚äÜJ.
It follows that if n ‚â•N, then J = IN ‚äÜIn ‚äÜJ, so that In = J; therefore, the chain stops,
and R has the ACC.
‚Ä¢
We now give a name to a commutative ring that satisÔ¨Åes any of the three equivalent
conditions in the proposition.
DeÔ¨Ånition.
A commutative ring R is called noetherian4 if every ideal in R is Ô¨Ånitely
generated.
We shall soon see that k[x1, . . . , xn] is noetherian whenever k is a Ô¨Åeld. On the other
hand, here is an example of a commutative ring that is not noetherian.
Example 6.39.
Let R = F(R) be the ring of all real-valued functions on the reals, under pointwise opera-
tions (see Example 3.7). It is easy to see, for every positive integer n, that
In = { f : R ‚ÜíR : f (x) = 0 for all x ‚â•n}
is an ideal and that In ‚ääIn+1 for all n. Therefore, R does not satisfy the ACC, and so R is
not noetherian.
‚óÄ
Here is an application of the maximum condition.
Corollary 6.40.
If I is a proper ideal in a noetherian ring R, then there exists a maximal
ideal M in R containing I. In particular, every noetherian ring has maximal ideals.5
Proof.
Let F be the family of all those proper ideals in R which contain I; note that
F Ã∏= ‚àÖbecause I ‚ààF. Since R is noetherian, the maximum condition gives a maximal
element M in F. We must still show that M is a maximal ideal in R (that is, that M is a
maximal element in the larger family F‚Ä≤ consisting of all the proper ideals in R). Suppose
there is a proper ideal J with M ‚äÜJ. Then I ‚äÜJ, and so J ‚ààF; therefore, maximality
of M gives M = J, and so M is a maximal ideal in R.
‚Ä¢
Here is one way to construct a new noetherian ring from an old one.
4This name honors Emmy Noether (1882-1935), who introduced chain conditions in 1921.
5This corollary is true without assuming R is noetherian, but the proof of the general result needs Zorn's
lemma; see Theorem 6.46.

Sec. 6.3
Noetherian Rings
343
Corollary 6.41.
If R is a noetherian ring and I is an ideal in R, then R/I is also noethe-
rian.
Proof.
If A is an ideal in R/I, then the correspondence theorem provides an ideal J
in R with J/I = A. Since R is noetherian, the ideal J is Ô¨Ånitely generated, say, J =
(b1, . . . , bn), and so A = J/I is also Ô¨Ånitely generated (by the cosets b1 + I, . . . , bn + I).
Therefore, R/I is noetherian.
‚Ä¢
The following anecdote is well known. Around 1890, Hilbert proved the famous Hilbert
basis theorem, showing that every ideal in C[x1, . . . , xn] is Ô¨Ånitely generated. As we
will see, the proof is nonconstructive in the sense that it does not give an explicit set of
generators of an ideal. It is reported that when P. Gordan, one of the leading algebraists
of the time, Ô¨Årst saw Hilbert's proof, he said, "This is not mathematics, but theology!" On
the other hand, Gordan said, in 1899 when he published a simpliÔ¨Åed proof of Hilbert's
theorem, "I have convinced myself that theology also has its advantages."
The proof of the Hilbert basis theorem given next is due to H. Sarges (1976).
Theorem 6.42 (Hilbert Basis Theorem).
If R is a commutative noetherian ring, then
R[x] is also noetherian.
Proof.
Assume that I is an ideal in R[x] that is not Ô¨Ånitely generated; of course, I Ã∏= {0}.
DeÔ¨Åne f0(x) to be a polynomial in I of minimal degree and deÔ¨Åne, inductively, fn+1(x)
to be a polynomial of minimal degree in I ‚àí( f0, . . . , fn). It is clear that
deg( f0) ‚â§deg( f1) ‚â§deg( f2) ‚â§¬∑ ¬∑ ¬∑ .
Let an denote the leading coefÔ¨Åcient of fn(x). Since R is noetherian, Exercise 6.32 on
page 344 applies to give an integer m with am+1 ‚àà(a0, . . . , am); that is, there are ri ‚ààR
with am+1 = r0a0 + ¬∑ ¬∑ ¬∑ + rmam. DeÔ¨Åne
f ‚àó(x) = fm+1(x) ‚àí
m

i=0
xdm+1‚àídiri fi(x),
where di = deg( fi).
Now f ‚àó(x) ‚ààI ‚àí( f0(x), . . . , fm(x)), otherwise fm+1(x) ‚àà
( f0(x), . . . , fm(x)). It sufÔ¨Åces to show that deg( f ‚àó) < deg( fm+1), for this contradicts
fm+1(x) having minimal degree among polynomials in I that are not in ( f0, . . . , fm). If
fi(x) = ai xdi + lower terms, then
f ‚àó(x) = fm+1(x) ‚àí
m

i=0
xdm+1‚àídiri fi(x)
= (am+1xdm+1 + lower terms) ‚àí
m

i=0
xdm+1‚àídiri(ai xdi + lower terms).
The leading term being subtracted is thus m
i=0 riai xdm+1 = am+1xdm+1.
‚Ä¢

344
Commutative Rings II
Ch. 6
Corollary 6.43.
(i) If k is a Ô¨Åeld, then k[x1, . . . , xn] is noetherian.
(ii) The ring Z[x1, . . . , xn] is noetherian.
(iii) For any ideal I in k[x1, . . . , xn], where k = Z or k is a Ô¨Åeld, the quotient ring
k[x1, . . . , xn]/I is noetherian.
Proof.
The proofs of the Ô¨Årst two items are by induction on n ‚â•1, using the theorem,
while the proof of item (iii) follows from Corollary 6.41.
‚Ä¢
EXERCISES
6.32 Let R be a commutative ring. Prove that R is noetherian if and only if, for every sequence
a1,a2,. . ., an, . . . of elements in R, there is an integer m ‚â•1 with am+1 an R-linear combina-
tion of its predecessors; that is, there are r1, . . . ,rm ‚ààR with am+1 = r1a1 + ¬∑ ¬∑ ¬∑ + rmam.
6.33
(i) Give an example of a noetherian ring R containing a subring that is not noetherian.
(ii) Give an example of a commutative ring R containing proper ideals I ‚ääJ ‚ääR with J
Ô¨Ånitely generated but with I not Ô¨Ånitely generated.
6.34 Let R be a noetherian domain such that every a, b ‚ààR has a gcd that is an R-linear combi-
nation of a and b. Prove that R is a PID. (The noetherian hypothesis is necessary, for there
exist non-noetherian domains, called B¬¥ezout rings, in which every Ô¨Ånitely generated ideal is
principal.)
Hint. Use induction on the number of generators of an ideal.
6.35 Give a proof that every nonempty family F of ideals in a PID R has a maximal element
without using Proposition 6.38.
6.36 Example 6.39 shows that R = F(R), the ring of all functions on R under pointwise operations,
does not satisfy the ACC.
(i) Show that the family of ideals {In : n ‚â•1} in that example does not have a maximal
element.
(ii) DeÔ¨Åne
fn(x) =

1
if x < n
0
if x ‚â•n,
and deÔ¨Åne Jn = ( f1, . . . , fn). Prove that J‚àó= !
n‚â•1 Jn is an ideal that is not Ô¨Ånitely
generated.
6.37 If R is a commutative ring, deÔ¨Åne the ring of formal power series in several variables induc-
tively:
R[[x1, . . . , xn+1]] = A[[xn+1]],
where A = R[[x1, . . . , xn]].
Prove that if R is a noetherian ring, then R[[x1, . . . , xn]], is also a noetherian ring.
Hint. Use Exercise 3.54(i) on page 151 if n = 1; use the proof of the Hilbert basis theorem
when n ‚â•1, but replace the degree of a polynomial by the order of a power series (where the
order of a nonzero power series  ci xi is n if n is the smallest i with ci Ã∏= 0).

Sec. 6.4
Applications of Zorn's Lemma
345
6.38 Let
S2 = {(a, b, c) ‚ààR3 : a2 + b2 + c2 = 1}
be the unit sphere in R3, and let
I = { f (x, y, z) ‚ààR[x, y, z]: f (a, b, c) = 0 for all (a, b, c) ‚ààS2}.
Prove that I is a Ô¨Ånitely generated ideal in R[x, y, z].
6.39 If R and S are noetherian, prove that their direct product R √ó S is also noetherian.
6.40 If R is a commutative ring that is also a vector space over a Ô¨Åeld k, then R is called a commu-
tative k-algebra if
(Œ±u)v = Œ±(uv) = u(Œ±v)
for all Œ± ‚ààk and u, v ‚ààR. Prove that every commutative k-algebra that is Ô¨Ånite-dimensional
over k is noetherian.
6.4 APPLICATIONS OF ZORN'S LEMMA
Dealing with inÔ¨Ånite sets may require some appropriate tools of set theory.
DeÔ¨Ånition.
If A is a set, let P(A)# denote the family of all its nonempty subsets. The
axiom of choice states that if A is a nonempty set, then there exists a function Œ≤ : P(A)# ‚Üí
A with Œ≤(S) ‚ààS for every nonempty subset S of A. Such a function Œ≤ is called a choice
function.
Informally, the axiom of choice is a harmless looking statement; it says that we can
simultaneously choose one element from each nonempty subset of a set.
The axiom of choice is easy to accept, and it is one of the standard axioms of set theory.
Indeed, the axiom of choice is equivalent to the statement that the cartesian product of
nonempty sets is itself nonempty (see Proposition A.1 in the Appendix). However, the
axiom is not convenient to use as it stands. There are various equivalent forms of it that are
more useful, the most popular of which are Zorn's lemma and the well-ordering principle.
Recall that a set X is a partially ordered set if there is a relation x ‚™Øy deÔ¨Åned on X
that is reÔ¨Çexive, antisymmetric, and transitive.
We introduce some deÔ¨Ånitions to enable us to state the well-ordering principle.
DeÔ¨Ånition.
A partially ordered set X is well-ordered if every nonempty subset S of X
contains a smallest element; that is, there is s0 ‚ààS with
s0 ‚™Øs for all s ‚ààS.
The set of natural numbers N is well-ordered (this is precisely what the least integer
axiom in Chapter 1 states), but the set Z of all integers is not well-ordered because Z itself
is a subset having no smallest element.
Well-ordering principle.
Every set X has some well-ordering of its elements.

346
Commutative Rings II
Ch. 6
If X happens to be a partially ordered set, then a well-ordering, whose existence is
asserted by the well-ordering principle, may have nothing to do with the original partial
ordering. For example, Z can be well-ordered:
0 ‚™Ø1 ‚™Ø‚àí1 ‚™Ø2 ‚™Ø‚àí2 ‚™Ø¬∑ ¬∑ ¬∑ .
We will be able to state Zorn's lemma after the following deÔ¨Ånitions.
DeÔ¨Ånition.
An element m in a partially ordered set X is a maximal element if there is no
x ‚ààX for which m ‚â∫x; that is,
if m ‚™Øx, then m = x.
Recall that an upper bound of a nonempty subset Y of a partially ordered set X is an
element x0 ‚ààX, not necessarily in Y, with y ‚™Øx0 for every y ‚ààY.
Example 6.44.
(i) A partially ordered set may have no maximal elements. For example, R, with its usual
ordering, has no maximal elements.
(ii) A partially ordered set may have many maximal elements. For example, if X is the
partially ordered set of all the proper subsets of a set U, then a subset S is a maximal
element if and only if S = U ‚àí{u} for some u ‚ààU; that is, S is the complement of a
point.
(iii) If X is the family of all the proper ideals in a commutative ring R, partially ordered by
inclusion, then a maximal element in X is a maximal ideal.
‚óÄ
Zorn's lemma gives a condition that guarantees the existence of maximal elements.
DeÔ¨Ånition.
A partially ordered set X is a chain if, for all x, y ‚ààX, either x ‚™Øy or
y ‚™Øx.
The set of real numbers R is a chain if one takes x ‚™Øy to be the usual inequality x ‚â§y.
Zorn's lemma.
If X is a nonempty partially ordered set in which every chain has an
upper bound in X, then X has a maximal element.
Theorem.
The following statements are equivalent:
(i) Zorn's lemma.
(ii) The well-ordering principle.
(iii) The axiom of choice.
Proof.
See the Appendix.
‚Ä¢
Henceforth, we shall assume, unashamedly, that all these statements are true, and we
will use any of them whenever convenient.
The next proposition is frequently used when verifying that the hypothesis of Zorn's
lemma does hold.

Sec. 6.4
Applications of Zorn's Lemma
347
Proposition 6.45.
If C is a chain and S = {x1, . . . , xn} ‚äÜC, then there exists some xi,
for 1 ‚â§i ‚â§n, with x j ‚™Øxi for all x j ‚ààS.
Proof.
The proof is by induction on n ‚â•1. The base step is trivially true. Let S =
{x1, . . . , xn+1}, and deÔ¨Åne S‚Ä≤ = {x1, . . . , xn}. The inductive hypothesis provides xi, for
1 ‚â§i ‚â§n, with x j ‚™Øxi for all x j ‚ààS‚Ä≤. Since C is a chain, either xi ‚™Øxn+1 or xn+1 ‚™Øxi.
Either case provides a largest element of S.
‚Ä¢
Here is our Ô¨Årst application of Zorn's lemma.
Theorem 6.46.
If R is a nonzero commutative ring, then R has a maximal ideal. Indeed,
every proper ideal I in R is contained in a maximal ideal.
Proof.
The second statement implies the Ô¨Årst, for if R is a nonzero ring, then the ideal
(0) is a proper ideal, and so there exists a maximal ideal in R containing it.
Let X be the family of all the proper ideals containing I (note that X
Ã∏= ‚àÖbecause
I ‚ààX), and partially order X by inclusion. It is easy to see that a maximal element of X
is a maximal ideal in R: There is no proper ideal strictly containing it.
Let C be a chain of X; thus, given I, J ‚ààC, either I ‚äÜJ or J ‚äÜI. We claim that
I ‚àó= !
I‚ààC I is an upper bound of C. Clearly, I ‚äÜI ‚àófor all I ‚ààC, so that it remains
to prove that I ‚àóis a proper ideal. The argument that I ‚àóis an ideal is, by now, familiar.
Finally, we show that I ‚àóis a proper ideal. If I ‚àó= R, then 1 ‚ààI ‚àó; now 1 got into I ‚àó
because 1 ‚ààI for some I ‚ààC, and this contradicts I being a proper ideal.
We have veriÔ¨Åed that every chain of X has an upper bound. Hence, Zorn's lemma
provides a maximal element, as desired.
‚Ä¢
Remark.
Theorem 6.46 would be false if the deÔ¨Ånition of ring R did not insist on R
containing 1. An example of such a "ring without unit" is any additive abelian group G
with multiplication deÔ¨Åned by ab = 0 for all a, b ‚ààG. The usual deÔ¨Ånition of ideal
makes sense, and it is easy to see that the ideals in G are its subgroups. Thus, a maximal
ideal I is just a maximal subgroup, which means that G/I has no proper subgroups, by
the correspondence theorem. Thus, G/I is a simple abelian group; that is, G/I is a Ô¨Ånite
group of prime order. In particular, take G = Q as an additive abelian group, and equip
it with the zero multiplication. The reader can show that Q has no nonzero Ô¨Ånite quotient
groups, so that it has no maximal subgroups. Therefore, this "ring without unit" has no
maximal ideals.
‚óÄ
We emphasize the necessity of checking, when applying Zorn's lemma to a partially
ordered set X, that X be nonempty. For example, a careless person might claim that Zorn's
lemma can be used to prove that there is a maximal uncountable subset of Z. DeÔ¨Åne X to
be the set of all the uncountable subsets of Z, and partially order X by inclusion. If C is a
chain in X, then it is clear that the uncountable subset S‚àó= !
S‚äÜC S is an upper bound of
C, for S ‚äÜS‚àófor every S ‚ààC. Therefore, Zorn's lemma provides a maximal element of
X, which must be a maximal uncountable subset of Z. The Ô¨Çaw, of course, is that X = ‚àÖ
(for every subset of a countable set is itself countable).

348
Commutative Rings II
Ch. 6
Here is our second application of Zorn's lemma. We begin by generalizing the usual def-
inition of a basis of a vector space so that it applies to all, not necessarily Ô¨Ånite-dimensional,
vector spaces.
DeÔ¨Ånition.
Let V be a vector space over some Ô¨Åeld k, and let Y ‚äÜV be an inÔ¨Ånite
subset.6
(i) Y is linearly independent if every Ô¨Ånite subset of Y is linearly independent.
(ii) Y spans V if each v ‚ààV is a linear combination of Ô¨Ånitely7 many elements of Y. We
write V = ‚ü®Y‚ü©when V is spanned by Y.
(iii) A basis of a vector space V is a linearly independent subset that spans V .
Thus, an inÔ¨Ånite subset Y = {yi : i ‚ààI} is linearly independent if, whenever  ai yi =
0 (where only Ô¨Ånitely many ai Ã∏= 0), then ai = 0 for all i.
Example 6.47.
Let k be a Ô¨Åeld, and let V = k[x] regarded as a vector space over k. We claim that
Y = {1, x, x2, . . . , xn, . . .}
is a basis of V . Now Y spans V , for any polynomial of degree d is a k-linear combi-
nation of 1, x, x2, . . . , xd. Also, Y is linearly independent, because there are no scalars
a0, a1, . . . , an, not all 0, with n
i=0 ai xi = 0 (a polynomial is the zero polynomial pre-
cisely if all its coefÔ¨Åcients are 0). Therefore, Y is a basis of V .
‚óÄ
Theorem 6.48.
Every vector space V over a Ô¨Åeld F has a basis. Indeed, every linearly
independent subset B of V is contained in a basis of V ; that is, there is a subset B‚Ä≤ so that
B ‚à™B‚Ä≤ is a basis of V .
Proof.
Note that the Ô¨Årst statement follows from the second, for B = ‚àÖis a linearly
independent subset contained in a basis.
Let X be the family of all the linearly independent subsets of V that contain B. The
family X is nonempty, for B ‚ààX. Partially order X by inclusion. We use Zorn's lemma
to prove the existence of a maximal element in X. Let B = {B j : j ‚ààJ} be a chain of
X. Thus, each B j is a linearly independent subset containing B and, for all i, j ‚ààJ, either
B j ‚äÜBi or Bi ‚äÜB j. It follows from Proposition 6.45 that if B j1, . . . , B jn is any Ô¨Ånite
family of B j's, then one contains all of the others.
Let B‚àó= !
j‚ààJ B j. Clearly, B‚àócontains B and B j ‚äÜB‚àófor all j ‚ààJ. Thus, B‚àóis
an upper bound of B if it belongs to X; that is, if B‚àóis a linearly independent subset of
V . If B‚àóis not linearly independent, then it has a Ô¨Ånite subset yi1, . . . , yim that is linearly
dependent. How did yik get into B‚àó? Answer: yik ‚ààB jk for some index jk. Since there are
only Ô¨Ånitely many yik, there exists B j0 containing all the Bik; that is, yi1, . . . , yim ‚ààB j0.
6When dealing with inÔ¨Ånite bases, it is more convenient to work with subsets instead of lists.
7Only Ô¨Ånite sums of elements in V are allowed. Without limits, convergence of inÔ¨Ånite series does not make
sense, and so a sum with inÔ¨Ånitely many nonzero terms is not deÔ¨Åned.

Sec. 6.4
Applications of Zorn's Lemma
349
But B j0 is linearly independent, by hypothesis, and this is a contradiction. Therefore, B‚àó
is an upper bound of the simply ordered subset B. We have veriÔ¨Åed that every chain of X
has an upper bound. Hence, Zorn's lemma applies to say that there is a maximal element
in X.
Let M be a maximal element in X. Since M is linearly independent, it sufÔ¨Åces to
show that it spans V (for then M is a basis of V containing B). If M does not span
V , then there is v0 ‚ààV with v0 /‚àà‚ü®M‚ü©, the subspace spanned by M. Consider the subset
M‚àó= M‚à™{v0}. Clearly, M ‚ääM‚àó. Now M‚àóis linearly independent: if a0v0+ ai yi = 0,
where yi ‚ààM and a0, ai ‚ààF are not all 0, then a0 Ã∏= 0 (otherwise the collection of yi
appearing in the equation would be linearly dependent, a contradiction). But if a0 Ã∏= 0,
then v0 = ‚àía‚àí1
0
 ai yi, contradicting v0 /‚àà‚ü®M‚ü©. Therefore, M is a basis of V . The last
statement follows if we deÔ¨Åne B‚Ä≤ = M ‚àíB.
‚Ä¢
Recall that a subspace W of a vector space V is a direct summand if there is a subspace
W ‚Ä≤ of V with {0} = W ‚à©W ‚Ä≤ and V = W +W ‚Ä≤ (i.e., each v ‚ààV can be written v = w+w‚Ä≤,
where w ‚ààW and w‚Ä≤ ‚ààW ‚Ä≤). We say that V is the direct sum of W and W ‚Ä≤, and we write
V = W ‚äïW ‚Ä≤.
Corollary 6.49.
Every subspace W of a vector space V is a direct summand.
Proof.
Let B be a basis of W. By the theorem, there is a subset B‚Ä≤ with B ‚à™B‚Ä≤ a basis
of V . It is straightforward to check that V = W ‚äï

B‚Ä≤ 
, where

B‚Ä≤ 
denotes the subspace
spanned by B‚Ä≤.
‚Ä¢
The ring of real numbers R is a vector space over Q; a basis is usually called a Hamel
basis, and it is useful in constructing analytic counterexamples. For example, we may use
a Hamel basis to prove the existence of a discontinuous function f : R ‚ÜíR that satisÔ¨Åes
the functional equation f (x + y) = f (x) + f (y).8
Example 6.50.
An inner product on a vector space V over a Ô¨Åeld k is a function
V √ó V ‚Üík,
whose values are denoted by (v, w), such that
(i) (v + v‚Ä≤, w) = (v, w) + (v‚Ä≤, w)
for all v, v‚Ä≤, w ‚ààV ;
8Here is a sketch of a proof, using inÔ¨Ånite cardinal numbers, that such discontinuous functions f exist. As
in the Ô¨Ånite-dimensional case, if B is a basis of a vector space V , then any function f : B ‚ÜíV extends to a
linear transformation F : V ‚ÜíV (see Proposition 7.49); namely, F(ribi) = ri f (bi). A Hamel basis has
cardinal c = |R|, and so there are cc = 2c > c functions f : R ‚ÜíR satisfying the functional equation, for
every linear transformation is additive. On the other hand, every continuous function on R is determined by its
values on Q, which is countable. It follows that there are only c continuous functions on R. Therefore, there exist
discontinuous functions f : R ‚ÜíR satisfying the functional equation f (x + y) = f (x) + f (y).
We have just proved that there exists a discontinuous f : R ‚ÜíR such that f (x + y) = f (x) + f (y) for all
x, y ‚ààR; that is, there is some a ‚ààR with f discontinuous at a. Thus, there is some œµ > 0 such that, for every
Œ¥ > 0, there is a b ‚ààR with |b‚àía| < Œ¥ and | f (b)‚àíf (a)| ‚â•œµ. Let us show that f is discontinuous at every c ‚ààR.
The identity b‚àía = (b+c‚àía)‚àíc gives |(b+c‚àía)‚àíc| < Œ¥, and the identity f (b+c‚àía)‚àíf (c) = f (b)‚àíf (a)
gives | f (b + c ‚àía) ‚àíf (c)| ‚â•œµ.

350
Commutative Rings II
Ch. 6
(ii) (Œ±v, w) = Œ±(v, w)
for all v, w ‚ààV and Œ± ‚ààk;
(iii) (v, w) = (w, v)
for all v, w ‚ààV .
We say that the inner product is deÔ¨Ånite if (v, v) Ã∏= 0 whenever v Ã∏= 0.
We are now going to use a Hamel basis to give a deÔ¨Ånite inner product on R all of
whose values are rational. Regard R as a vector space over Q, and let Y be a basis. Using
0 coefÔ¨Åcients if necessary, for each v, w ‚ààR, there are yi ‚ààY and rationals ai and bi with
v =  ai yi and w =  bi yi (the nonzero ai and nonzero bi are uniquely determined by
v and w, respectively). DeÔ¨Åne
(v, w) =

aibi;
note that the sum has only Ô¨Ånitely many nonzero terms. It is routine to check that we have
deÔ¨Åned a deÔ¨Ånite inner product.
‚óÄ
There is a notion of dimension for inÔ¨Ånite-dimensional vector spaces; of course, dimen-
sion will now be a cardinal number. In the following proof, we shall cite and use several
facts about cardinals. We denote the cardinal number of a set X by |X|.
Fact I.
Let X and Y be sets, and let f : X ‚ÜíY be a function. If f ‚àí1(y) is Ô¨Ånite for
every y ‚ààY, then |X| ‚â§‚Ñµ0|Y|; hence, if Y is inÔ¨Ånite, then |X| ‚â§|Y|.
See Kaplansky, Set Theory and Metric Spaces; since X is the disjoint union X =
!
y‚ààY f ‚àí1(y), this result follows from Theorem 16 on page 43.
Fact II.
If X is an inÔ¨Ånite set and Fin(X) is the family of all its Ô¨Ånite subsets, then
|Fin(X)| = |X|.
See Kaplansky, Set Theory and Metric Spaces; this result also follows from Theorem 16
on page 43.
Fact III (Schroeder-Bernstein Theorem).
If X and Y are sets with |X| ‚â§|Y| and
|Y| ‚â§|X|, then |X| = |Y|.
See Birkhoff-Mac Lane, A Survey of Modern Algebra, page 387.
Theorem 6.51.
Let k be a Ô¨Åeld and let V be a vector space over k.
(i) Any two bases of V have the same number of elements (that is, they have the same
cardinal number); this cardinal is called the dimension of V and it is denoted by
dim(V ).
(ii) Vector spaces V and V ‚Ä≤ over k are isomorphic if and only if dim(V ) = dim(V ‚Ä≤).
Proof.
(i) Let B and B‚Ä≤ be bases of V . If B is Ô¨Ånite, then V is Ô¨Ånite-dimensional, and
hence B‚Ä≤ is also Ô¨Ånite (Corollary 3.90); moreover, we have proved, in Theorem 3.85, that
|B| = |B‚Ä≤|. Therefore, we may assume that both B and B‚Ä≤ are inÔ¨Ånite.
Each v ‚ààV has a unique expression of the form v = 
b‚ààB Œ±bb, where Œ±b ‚ààk and
almost all Œ±b = 0. DeÔ¨Åne the support of v (with respect to B) by
supp(v) = {b ‚ààB : Œ±b Ã∏= 0};

Sec. 6.4
Applications of Zorn's Lemma
351
thus, supp(v) is a Ô¨Ånite subset of B for every v ‚ààV . DeÔ¨Åne f : B‚Ä≤ ‚ÜíFin(B) by f (b‚Ä≤) =
supp(b‚Ä≤). Note that if supp(b‚Ä≤) = {b1, . . . , bn}, then b‚Ä≤ ‚àà‚ü®b1, . . . , bn‚ü©=

supp(b‚Ä≤)
 
, the
subspace spanned by supp(b‚Ä≤). Since

supp(b‚Ä≤)
 
has dimension n, it contains at most n
elements of B‚Ä≤, because B‚Ä≤ is independent (Corollary 3.88). Therefore, f ‚àí1(T ) is Ô¨Ånite
for every Ô¨Ånite subset T of B [of course, f ‚àí1(T ) = ‚àÖis possible]. By Fact I, we have
|B‚Ä≤| ‚â§|Fin(B)|, and by Fact II, we have |B‚Ä≤| ‚â§|B|. Interchanging the roles of B and B‚Ä≤
gives the reverse inequality |B| ‚â§|B‚Ä≤|, and so Fact III gives |B| = |B‚Ä≤|.
(ii) Adapt the proof of Corollary 3.105, the Ô¨Ånite-dimensional version.
‚Ä¢
The next application is a characterization of noetherian rings in terms of their prime
ideals.
Lemma 6.52.
Let R be a commutative ring and let F be the family of all those ideals in
R that are not Ô¨Ånitely generated. If F Ã∏= ‚àÖ, then F has a maximal element.
Proof.
Partially order F by inclusion. It sufÔ¨Åces, by Zorn's lemma, to prove that if
C is a chain in F, then I ‚àó= !
I‚ààC I is not Ô¨Ånitely generated.
If, on the contrary,
I ‚àó= (a1, . . . , an), then a j ‚ààI j for some I j ‚ààC. But C is a chain, and so one of
the ideals I1, . . . , In, call it I0, contains the others, by Proposition 6.45. It follows that
I ‚àó= (a1, . . . , an) ‚äÜI0. The reverse inclusion is clear, for I ‚äÜI ‚àófor all I ‚ààC. There-
fore, I0 = I ‚àóis Ô¨Ånitely generated, contradicting I0 ‚ààF.
‚Ä¢
Theorem 6.53 (I. S. Cohen).
A commutative ring R is noetherian if and only if every
prime ideal in R is Ô¨Ånitely generated.
Proof.
Only sufÔ¨Åciency needs proof. Assume that every prime ideal is Ô¨Ånitely generated.
Let F be the family of all ideals in R that are not Ô¨Ånitely generated. If F Ã∏= ‚àÖ, then the
lemma provides an ideal I that is not Ô¨Ånitely generated and that is maximal such. We will
show that I is a prime ideal; with the hypothesis that every prime ideal is Ô¨Ånitely generated,
this contradiction will show that F = ‚àÖ; that is, that R is noetherian.
Suppose that ab ‚ààI but a /‚ààI and b /‚ààI. Since a /‚ààI, the ideal I + Ra is strictly
larger than I, and so I + Ra is Ô¨Ånitely generated; indeed, we may assume that
I + Ra = (i1 + r1a, . . . , in + rna),
where ik ‚ààI and rk ‚ààR for all k. Consider J = (I : a) = {x ‚ààR : xa ‚ààI}.
Now I + Rb ‚äÜJ; since b /‚ààI, we have I ‚ääJ, and so J is Ô¨Ånitely generated. We
claim that I = (i1, . . . , in, Ja). Clearly, (i1, . . . , in, Ja) ‚äÜI, for every ik ‚ààI and
Ja ‚äÜI. For the reverse inclusion, if z ‚ààI ‚äÜI + Ra, there are uk ‚ààR with z =

k uk(ik + rka). Then (
k ukrk)a = z ‚àí
k ukik ‚ààI, so that 
k ukrk ‚ààJ. Hence,
z = 
k ukik + (
k ukrk)a ‚àà(i1, . . . , in, Ja). It follows that I = (i1, . . . , in, Ja) is
Ô¨Ånitely generated, a contradiction, and so I is a prime ideal.
‚Ä¢
W. Krull has proved that every noetherian ring has the DCC on prime ideals (see Corol-
lary 11.163).

352
Commutative Rings II
Ch. 6
Our next application involves algebraic closures of Ô¨Åelds. Recall that a Ô¨Åeld extension
K/k is algebraic if every a ‚ààK is a root of some nonzero polynomial f (x) ‚ààk[x]; that
is, K/k is an algebraic extension if every element a ‚ààK is algebraic over k.
We have already discussed algebraic extensions in Proposition 3.117 on page 185, and
the following proposition will add a bit more.
Proposition 6.54.
Let K/k be an extension.
(i) If z ‚ààK, then z is algebraic over k if and only if k(z)/k is Ô¨Ånite.
(ii) If z1, z2, . . . , zn ‚ààK are algebraic over k, then k(z1, z2, . . . , zn)/k is a Ô¨Ånite exten-
sion.
(iii) If y, z ‚ààK are algebraic over k, then y + z, yz, and y‚àí1 (for y Ã∏= 0) are also
algebraic over k.
(iv) DeÔ¨Åne
Kalg = {z ‚ààK : z is algebraic over k}.
Then Kalg is a subÔ¨Åeld of K.
Proof.
(i) If k(z)/k is Ô¨Ånite, then Proposition 3.117(i) shows that z is algebraic over k.
Conversely, if z is algebraic over k, then Proposition 3.117(v) shows that k(z)/k is Ô¨Ånite.
(ii) We prove this by induction on n ‚â•1; the base step is part (i). For the inductive step,
there is a tower of Ô¨Åelds
k ‚äÜk(z1) ‚äÜk(z1, z2) ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜk(z1, . . . , zn) ‚äÜk(z1, . . . , zn+1).
Now [k(zn+1) : k] is Ô¨Ånite, and we have [k(z1, . . . , zn) : k] Ô¨Ånite, by the inductive hypoth-
esis. Indeed, [k(zn+1) : k] = d, where d is the degree of the monic irreducible polynomial
in k[x] having zn+1 as a root (by Proposition 3.117). But if zn+1 satisÔ¨Åes a polynomial
of degree d over k, then it satisÔ¨Åes a polynomial of degree d‚Ä≤ ‚â§d over the larger Ô¨Åeld
F = k(z1, . . . , zn). We conclude that
[k(z1, . . . , zn+1) : k(z1, . . . , zn)] = [F(zn+1) : F] ‚â§[k(zn+1) : k].
Therefore,
[k(z1, . . . , zn+1) : k] = [F(zn+1) : k] = [F(zn+1) : F][F : k]
is Ô¨Ånite.
(iii) Now k(y, z)/k is Ô¨Ånite, by part (ii). Therefore, k(y + z) ‚äÜk(y, z) and k(yz) ‚äÜ
k(y, z) are also Ô¨Ånite, for any subspace of a Ô¨Ånite-dimensional vector space is itself Ô¨Ånite-
dimensional [Corollary 3.90(i)].
By part (i), y + z, yz, and y‚àí1 are algebraic
over k.
(iv) This follows at once from part (iii).
‚Ä¢

Sec. 6.4
Applications of Zorn's Lemma
353
DeÔ¨Ånition.
Given the extension C/Q, deÔ¨Åne the algebraic numbers by
A = C alg.
Thus, A consists of all those complex numbers that are roots of nonzero polynomials in
Q[x], and the proposition shows that A is a subÔ¨Åeld of C that is algebraic over Q.
Example 6.55.
We claim that A/Q is an algebraic extension that is not Ô¨Ånite. Suppose, on the contrary, that
[A : Q] = n, for some integer n. Now there exists an irreducible polynomial p(x) ‚ààQ[x]
of degree n + 1; for example, take p(x) = xn+1 ‚àí2. If Œ± is a root of p(x), then Œ± ‚ààA,
and so Q(Œ±) ‚äÜA. Thus, A is an n-dimensional vector space over Q containing an (n +1)-
dimensional subspace, and this is a contradiction.
‚óÄ
Lemma 6.56.
(i) If k ‚äÜK ‚äÜE is a tower of Ô¨Åelds with E/K and K/k algebraic, then E/k is also
algebraic.
(ii) Let
K0 ‚äÜK1 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜKn ‚äÜKn+1 ‚äÜ¬∑ ¬∑ ¬∑
be an ascending tower of Ô¨Åelds; if Kn+1/Kn is algebraic for all n ‚â•0, then K ‚àó=
!
n‚â•0 Kn is a Ô¨Åeld that is algebraic over K0.
(iii) Let K = k(A); that is, K is obtained from k by adjoining the elements in a set A. If
each element a ‚ààA is algebraic over k, then K/k is an algebraic extension.
Proof.
(i) Let e ‚ààE; since E/K is algebraic, there is some f (x) =  n
i=0 ai xi ‚àà
K[x] having e as a root.
If F = k(a0, . . . , an), then e is algebraic over F, and so
k(a0, . . . , an, e) = F(e) is a Ô¨Ånite extension of F; that is, [F(e) :
F] is Ô¨Ånite. Since
K/k is an algebraic extension, each ai is algebraic over k, and Corollary 3.90 on page 170
shows that the intermediate Ô¨Åeld F is Ô¨Ånite-dimensional over k; that is, [F : k] is Ô¨Ånite.
[k(a0, . . . , an, e) : k] = [F(e) : k] = [F(e) : F][F : k]
is Ô¨Ånite, and so e is algebraic over k, by Proposition 6.54(i). We conclude that E/k is
algebraic.
(ii) If y, z ‚ààK ‚àó, then they are there because y ‚ààKm and z ‚ààKn; we may assume that
m ‚â§n, so that both y, z ‚ààKn ‚äÜK ‚àó. Since Kn is a Ô¨Åeld, it contains y + z, yz, and y‚àí1 if
y Ã∏= 0. Therefore, K ‚àóis a Ô¨Åeld.
If z ‚ààK ‚àó, then z must lie in Kn for some n. But Kn/K0 is algebraic, by an obvious
inductive generalization of part (i), and so z is algebraic over K0. Since every element of
K ‚àóis algebraic over K0, the extension K ‚àó/K0 is algebraic.
(iii) Let z ‚ààk(A); by Exercise 3.95 on page 197, there is an expression for z involv-
ing k and Ô¨Ånitely many elements of A; say, a1, . . . , am. Hence, z ‚ààk(a1, . . . , am). By
Proposition 6.54(ii), k(z)/k is Ô¨Ånite and hence z is algebraic over k.
‚Ä¢

354
Commutative Rings II
Ch. 6
DeÔ¨Ånition.
A Ô¨Åeld K is algebraically closed if every nonconstant f (x) ‚ààK[x] has a root
in K. An algebraic closure of a Ô¨Åeld k is an algebraic extension k of k that is algebraically
closed.
The algebraic closure of Q turns out to be the algebraic numbers: Q = A. The funda-
mental theorem of algebra says that C is algebraically closed; moreover, C is an algebraic
closure of R. We have already given an algebraic proof, Theorem 4.49, but perhaps the sim-
plest proof of this theorem is by Liouville's theorem in complex variables: Every bounded
entire function is constant. If f (x) ‚ààC[x] had no roots, then 1/f (x) would be a bounded
entire function that is not constant.
There are two main results here. First, every Ô¨Åeld has an algebraic closure; second, any
two algebraic closures of a Ô¨Åeld are isomorphic. Our proof of existence will make use of a
"big" polynomial ring: We assume that if k is a Ô¨Åeld and T is an inÔ¨Ånite set, then there is
a polynomial ring k[T ] having one variable for each t ‚ààT . (We have already constructed
k[T ] when T is Ô¨Ånite, and the inÔ¨Ånite case is essentially a union of k[U], where U ranges
over all the Ô¨Ånite subsets of T . A construction of k[T ] for inÔ¨Ånite T will be given in
Exercise 9.93 on page 756.)
Lemma 6.57.
Let k be a Ô¨Åeld, and let k[T ] be the polynomial ring in a set T of variables.
If t1, . . . , tn ‚ààT are distinct and if fi(ti) ‚ààk[ti] ‚äÜk[T ] are nonconstant polynomials,
then the ideal I = ( f1(t1), . . . , fn(tn)) in k[T ] is a proper ideal.
Remark.
If n = 2, then f1(t1) and f2(t2) are relatively prime, and this lemma says that
1 is not a linear combination of them.
‚óÄ
Proof.
If I is not a proper ideal in k[T ], then there exist hi(T ) ‚ààk[T ] with
1 = h1(T ) f1(t1) + ¬∑ ¬∑ ¬∑ + hn(T ) fn(tn).
Consider the Ô¨Åeld extension k(Œ±1, . . . , Œ±n), where Œ±i is a root of fi(ti) for i = 1, . . . , n
(the fi are not constant). Denote the variables involved in the hi(T ) other than t1, . . . , tn, if
any, by tn+1, . . . , tm. Evaluating when ti = Œ±i if i ‚â§n and ti = 0 if i ‚â•n + 1 (evaluation
is a ring homomorphism k[T ] ‚Üík(Œ±1, . . . , Œ±n)), the right side is 0, and we have the
contradiction 1 = 0.
‚Ä¢
Theorem 6.58.
Given a Ô¨Åeld k, there exists an algebraic closure k of k.
Proof.
Let T be a set in bijective correspondence with the family of nonconstant poly-
nomials in k[x]. Let R = k[T ] be the big polynomial ring, and let I be the ideal in R
generated by all elements of the form f (t f ), where t f ‚ààT ; that is, if
f (x) = xn + an‚àí1xn‚àí1 + ¬∑ ¬∑ ¬∑ + a0,
where ai ‚ààk, then
f (t f ) = (t f )n + an‚àí1(t f )n‚àí1 + ¬∑ ¬∑ ¬∑ + a0.

Sec. 6.4
Applications of Zorn's Lemma
355
We claim that the ideal I is proper; if not, 1 ‚ààI, and there are distinct t1, . . . , tn ‚ààT
and polynomials h1(T ), . . . , hn(T ) ‚ààk[T ] with 1 = h1(T ) f1(t1) + ¬∑ ¬∑ ¬∑ + hn(T ) fn(tn),
contradicting the lemma. Therefore, there is a maximal ideal M in R containing I, by
Theorem 6.46. DeÔ¨Åne K = R/M. The proof is now completed in a series of steps.
(i) K/k is a Ô¨Åeld extension.
We know that K = R/M is a Ô¨Åeld because M is a maximal ideal. Moreover, the ring
map Œ∏, which is the composite
k
i‚Üík[T ] = R
nat
‚àí‚ÜíR/M = K,
(where i is the inclusion) is not identically 0 because 1 ‚Üí1, and hence Œ∏ is injective, by
Corollary 3.53. We identify k with im Œ∏ ‚äÜK.
(ii) Every nonconstant f (x) ‚ààk[x] splits in K[x].
By deÔ¨Ånition, there is t f ‚ààT with f (t f ) ‚ààI ‚äÜM, and the coset t f + M ‚ààR/M = K
is a root of f (x). It now follows by induction on degree that f (x) splits over K.
(iii) The extension K/k is algebraic.
By Lemma 6.56(iii), it sufÔ¨Åces to show that each t f + M is algebraic over k [for K =
k(all t f + M)]; but this is obvious, for t f is a root of f (x) ‚ààk[x].
(iv) K is algebraically closed
Let g(x) ‚ààK[x] and let E = K(Œ±1, . . . , Œ±m) be a splitting Ô¨Åeld of g(x) over K. We
have a tower of Ô¨Åelds k ‚äÜK ‚äÜE in which K/k and E/K are algebraic extensions. By
Lemma 6.56(i), E/k is an algebraic extension. Hence, p(x) = irr(Œ±1, k) ‚ààk[x]. By
item (ii), p(x) splits over K, so that {Œ±1, . . . , Œ±m} ‚äÜK; that is, E ‚äÇK. Therefore, g(x)
splits in K[x], and so K is algebraically closed.
‚Ä¢
Corollary 6.59.
If k is a countable Ô¨Åeld, then it has a countable algebraic closure. In
particular, an algebraic closure of Q or of Fp is countable.
Proof.
If k is countable, then the set T of all nonconstant polynomials is countable, say,
T = {t1, t2, . . .}, because k[x] is countable. Hence, k[T ] = !
‚Ñì‚â•1 k[t1, . . . , t‚Ñì] is count-
able, as is its quotient k1 (in the proof of Theorem 6.58). It follows, by induction on n ‚â•0,
that every kn is countable. Finally, a countable union of countable sets is itself countable,
so that an algebraic closure of k is countable.
‚Ä¢
We are now going to prove the uniqueness of an algebraic closure.
DeÔ¨Ånition.
If F/k and K/k are extensions, then a k-map is a ring homomorphism
œï : F ‚ÜíK that Ô¨Åxes k pointwise.
We note that if K/k is an extension, if œï : K ‚ÜíK is a k-map, and if a ‚ààK is
a root of some irreducible polynomial p(x) ‚ààk[x], then œï permutes all the roots {a =
a1, a2, . . . , ar} of p(x) that lie in K. If p(x) = xn + cn‚àí1xn‚àí1 + ¬∑ ¬∑ ¬∑ + c0, then
0 = p(ai) = an
i + cn‚àí1an‚àí1
i
+ ¬∑ ¬∑ ¬∑ + c0,

356
Commutative Rings II
Ch. 6
and so
0 = [œï(ai)]n + œï(cn‚àí1)[œï(ai)]n‚àí1 + ¬∑ ¬∑ ¬∑ + œï(c0)
= [œï(ai)]n + cn‚àí1[œï(ai)]n‚àí1 + ¬∑ ¬∑ ¬∑ + c0,
because œï Ô¨Åxes all ci ‚ààk. Therefore, œï(ai) is a root of p(x) lying in K. Finally, since œï is
injective and {a1, . . . , ar} is Ô¨Ånite, œï is a permutation of these roots.
Lemma 6.60.
If K/k is an algebraic extension, then every k-map œï : K ‚ÜíK is an
automorphism of K.
Proof.
By Corollary 3.53, the k-map œï is injective. To see that œï is surjective, let a ‚ààK.
Since K/k is algebraic, there is an irreducible polynomial p(x) ‚ààk[x] having a as a root.
As we remarked earlier, œï being a k-map implies that it permutes the set of those roots of
p(x) that lie in K. Therefore, a ‚ààim œï because a = œï(ai) for some i.
‚Ä¢
The next lemma will use Zorn's lemma by partially ordering a family of functions.
Since a function is essentially a set, its graph, it is reasonable to take a union of functions
in order to obtain an upper bound; we give details below.
Lemma 6.61.
If k/k is an algebraic closure, and if F/k is an algebraic extension, then
there is an injective k-map œà : F ‚Üík.
Proof.
If E is an intermediate Ô¨Åeld, k ‚äÜE ‚äÜF, let us call an ordered pair (E, f ) an
"approximation" if f : E ‚Üík is a k-map. In the following diagram, all arrows other than
f are inclusions.
k
k

 E

f

F
DeÔ¨Åne
X = {approximations (E, f )}.
Note that X Ã∏= ‚àÖbecause (k, 1k) ‚ààX. Partially order X by
(E, f ) ‚™Ø(E‚Ä≤, f ‚Ä≤)
if
E ‚äÜE‚Ä≤ and f ‚Ä≤|E = f.
That the restriction f ‚Ä≤|E is f means that f ‚Ä≤ extends f ; that is, both functions agree when-
ever possible: f ‚Ä≤(u) = f (u) for all u ‚ààE.
It is easy to see that an upper bound of a chain
S = {(E j, f j) : j ‚ààJ}
is given by (! E j, ! f j). That ! E j is an intermediate Ô¨Åeld is, by now, a routine argu-
ment. We can take the union of the graphs of the f j's, but here is a more down-to-earth
description of  = ! f j: If u ‚àà! E j, then u ‚ààE j0 for some j0, and : u ‚Üíf j0(u).

Sec. 6.4
Applications of Zorn's Lemma
357
Note that  is well-deÔ¨Åned: If u ‚ààE j1, we may assume, for notation, that E j0 ‚äÜE j1, and
then f j1(u) = f j0(u) because f j1 extends f j0. The reader may check that  is a k-map.
By Zorn's lemma, there exists a maximal element (E0, f0) in X. We claim that E0 = F,
and this will complete the proof (take œà = f0). If E0 ‚ääF, then there is a ‚ààF with
a /‚ààE0. Since F/k is algebraic, we have F/E0 algebraic, and there is an irreducible
p(x) ‚ààE0[x] having a as a root; since k/k is algebraic and k is algebraically closed, we
have a factorization in k[x]:
f ‚àó
0 (p(x)) =
n

i=1
(x ‚àíbi),
where f ‚àó
0 : E0[x] ‚Üík[x] is the map induced by f0. If all the bi lie in f0(E0) ‚äÜk,
then f ‚àí1
0
(bi) ‚ààE0 ‚äÜF for all i, and there is a factorization of p(x) in F[x], namely,
p(x) = n
i=1[x ‚àíf ‚àí1
0
(bi)]. But a /‚ààE0 implies a Ã∏= f ‚àí1
0
(bi) for any i. Thus, x ‚àía is
another factor of p(x) in F[x], contrary to unique factorization. We conclude that there is
some bi /‚ààim f0. By Theorem 3.120(ii), we may deÔ¨Åne f1 : E0(a) ‚Üík by
c0 + c1a + c2a2 + ¬∑ ¬∑ ¬∑ ‚Üíf0(c0) + f0(c1)bi + f0(c2)b2
i + ¬∑ ¬∑ ¬∑ .
A straightforward check shows that f1 is a (well-deÔ¨Åned) k-map extending f0. Hence,
(E0, f0) ‚â∫(E0(a), f1), contradicting the maximality of (E0, f0). This completes the
proof.
‚Ä¢
Theorem 6.62.
Any two algebraic closures of a Ô¨Åeld k are isomorphic via a k-map.
Proof.
Let K and L be two algebraic closures of a Ô¨Åeld k. By Lemma 6.61, there are
k-maps œà : K ‚ÜíL and Œ∏ : L ‚ÜíK. By Lemma 6.60, both composites Œ∏œà : K ‚ÜíK and
œàŒ∏ : L ‚ÜíL are automorphisms. It follows that œà (and Œ∏) is a k-isomorphism.
‚Ä¢
It is now permissible to speak of the algebraic closure of a Ô¨Åeld.
In the remainder of this section, we investigate the structure of arbitrary Ô¨Åelds; we begin
with simple transcendental extensions k(x), where k is a Ô¨Åeld and x is transcendental over
k; that is, we examine the function Ô¨Åeld k(x).
DeÔ¨Ånition.
If œï ‚ààk(x), then there are polynomials g(x), h(x) ‚ààk[x] with (g, h) = 1
and œï = g(x)/h(x). DeÔ¨Åne the degree of œï by
degree(œï) = max{deg(g), deg(h)}.

358
Commutative Rings II
Ch. 6
A rational function œï ‚ààk(x) is called a linear fractional transformation if
œï = ax + b
cx + d ,
where a, b, c, d ‚ààk and ad ‚àíbc Ã∏= 0.
Now œï ‚ààk(x) has degree 0 if and only if œï is a constant (that is, œï ‚ààk), while
Exercise 6.56 on page 375 says that œï ‚ààk(x) has degree 1 if and only if œï is a linear
fractional transformation. If A =
 a b
c d

‚ààGL(2, k), write ‚ü®A‚ü©= (ax + b)/(cx + d).
If we deÔ¨Åne ‚ü®A‚Ä≤‚ü©‚ü®A‚ü©= ‚ü®A‚Ä≤A‚ü©, then it is easily checked that the set LF(k) of all linear
fractional transformations with entries in k is a group under this operation. In Exercise 6.57
on page 375, the reader will prove that LF(k) ‚àº= PGL(2, k) = GL(2, k)/Z(2, k), where
Z(2, k) is the (normal) subgroup of all 2 √ó 2 (nonzero) scalar matrices.
Proposition 6.63.
If œï ‚ààk(x) is nonconstant, then œï is transcendental over k and
k(x)/k(œï) is a Ô¨Ånite extension with
[k(x) : k(œï)] = degree(œï).
Moreover, if œï = g(x)/h(x) and (g, h) = 1, then
irr(x, k(œï)) = g(y) ‚àíœïh(y).
Proof.
Let g(x) =  ai xi and h(x) =  bi xi ‚ààk[x]. Now Œ∏(y) = g(y) ‚àíœïh(y) is a
polynomial in k(œï)[y]:
Œ∏(y) =

ai yi ‚àíœï

bi yi =

(ai ‚àíœïbi)yi.
If Œ∏(y) were the zero polynomial, then all its coefÔ¨Åcients would be 0. But if bi is a nonzero
coefÔ¨Åcient of h(y), then ai ‚àíœïbi = 0 gives œï = ai/bi, contradicting the assumption that
œï is not a constant; that is, œï /‚ààk. It follows that
deg(Œ∏) = deg(g(y) ‚àíœïh(y)) = max{deg(g), deg(h)} = degree(œï).
Since x is a root of Œ∏(y), we have x algebraic over k(œï). If œï were algebraic over k, then
k(œï)/k would be Ô¨Ånite, giving [k(x) : k] = [k(x) : k(œï)][k(œï) : k] Ô¨Ånite, a contradiction.
Therefore, œï is transcendental over k.
We claim that Œ∏(y) is an irreducible polynomial in k(œï)[y]. If not, then Œ∏(y) factors
in k[œï][y], by Gauss's Corollary 6.27. But Œ∏(y) = g(y) ‚àíœïh(y) is linear in œï, and so
Corollary 6.37 shows that Œ∏(y) is irreducible. Finally, since deg(Œ∏) = degree(œï), we have
[k(x) : k(œï)] = degree(œï).
‚Ä¢
Corollary 6.64.
Let œï ‚ààk(x), where k(x) is the Ô¨Åeld of rational functions over a Ô¨Åeld k.
Then k(œï) = k(x) if and only if œï is a linear fractional transformation.
Proof.
By Proposition 6.63, k(œï) = k(x) if and only if degree(œï) = 1; that is, œï is a
linear fractional transformation.
‚Ä¢

Sec. 6.4
Applications of Zorn's Lemma
359
Corollary 6.65.
If k(x) is the Ô¨Åeld of rational functions over a Ô¨Åeld k, then
Gal(k(x)/k) ‚àº= LF(k),
the group of all linear fractional transformations over k.
Proof.
Let œÉ : k(x) ‚Üík(x) be an automorphism of k(x) Ô¨Åxing k. Now œÉ : x ‚ÜíxœÉ,
where xœÉ ‚ààk(x); since œÉ is surjective, we must have k(xœÉ) = k(x), and so xœÉ is a
linear fractional transformation, by Corollary 6.64. DeÔ¨Åne Œ≥ : Gal(k(x)/k) ‚ÜíLF(k) by
Œ≥ : œÉ ‚ÜíxœÉ. The reader may check that Œ≥ is a homomorphism (xœÉœÑ = xœÑ xœÉ); Œ≥ is an
isomorphism because Œ≥ ‚àí1 is the function assigning, to any linear fractional transformation
œï = (ax + b)/(cx + d), the automorphism of k(x) that sends x to œï.
‚Ä¢
Theorem 6.66 (L¬®uroth's Theorem).
If k(x) is a simple transcendental extension, then
every intermediate Ô¨Åeld B is also a simple transcendental extension of k: There is œï ‚ààB
with B = k(œï).
Proof.
If Œ≤ ‚ààB is not constant, then [k(x) : k(Œ≤)] = [k(x) : B][B : k(Œ≤)] is Ô¨Ånite,
by Proposition 6.63; hence, [k(x) : B] is Ô¨Ånite and x is algebraic over B. The proof of
Proposition 6.63 shows that if œï ‚ààk(x), then œï is a coefÔ¨Åcient of irr(x, k(œï)); the proof of
L¬®uroth's theorem is a converse, showing that B = k(œï) for some coefÔ¨Åcient œï of irr(x, B).
Now
irr(x, B) = yn + Œ≤n‚àí1yn‚àí1 + ¬∑ ¬∑ ¬∑ + Œ≤0 ‚ààB[y].
Each coefÔ¨Åcient Œ≤‚Ñì‚ààB ‚äÜk(x) is a rational function, which we write in lowest terms:
Œ≤‚Ñì= g‚Ñì(x)/h‚Ñì(x), where g‚Ñì(x), h‚Ñì(x) ‚ààk[x] and (g‚Ñì, h‚Ñì) = 1. As in Lemma 6.24(i), the
content c(irr) = d(x)/b(x), where b(x) is the product of the h‚Ñìand d(x) is their gcd. It is
easy to see that f (x), deÔ¨Åned by f (x) = b(x)/d(x), lies in k[x]; in fact, the reader may
generalize Exercise 1.26 on page 13 to show that f (x) is the lcm of the h‚Ñì. DeÔ¨Åne
i(x, y) = f (x) irr(x, B),
the associated primitive polynomial in k[x][y] (of course, k[x][y] = k[x, y], but we wish
to view it as polynomials in y with coefÔ¨Åcients in k[x]). If we denote the highest exponent
of y occurring in a polynomial a(x, y) by degy(a), then n = degy(i); let m = degx(i).
Since i(x, y) = f (x)yn + n‚àí1
‚Ñì=0 f (x)Œ≤‚Ñìy‚Ñì, we have m = max‚Ñì{deg( f ), deg( fŒ≤‚Ñì)}. Now
h‚Ñì(x) | f (x) for all ‚Ñì, so that deg(h‚Ñì) ‚â§deg( f ) ‚â§m [because f (x) is one of the
coefÔ¨Åcients of i(x, y)]. Also,
fŒ≤‚Ñì= h0 ¬∑ ¬∑ ¬∑ hn‚àí1
d
¬∑ g‚Ñì
h‚Ñì
= h0 ¬∑ ¬∑ ¬∑h‚Ñì¬∑ ¬∑ ¬∑ hn‚àí1
d
g‚Ñì.
Since (h0 ¬∑ ¬∑ ¬∑h‚Ñì¬∑ ¬∑ ¬∑ hn‚àí1)/d ‚ààk[x], we have deg(g‚Ñì) ‚â§deg( fŒ≤‚Ñì) ‚â§m. We conclude that
deg(g‚Ñì) ‚â§m and deg(h‚Ñì) ‚â§m.

360
Commutative Rings II
Ch. 6
Some coefÔ¨Åcient Œ≤ j of irr(x, B) is not constant, lest x be algebraic over k. Omit the
subscripts j, write Œ≤ j = g(x)/h(x), and deÔ¨Åne
œï = Œ≤ j = g(x)/h(x) ‚ààB.
Now g(y) ‚àíœïh(y) = g(y) ‚àíg(x)h(x)‚àí1h(y) ‚ààB[y] has x as a root, and so irr(x, B)
divides g(y) ‚àíœïh(y) in B[y] ‚äÜk(x)[y]. Therefore, there is q(x, y) ‚ààk(x)[y] with
irr(x, B)q(x, y) = g(y) ‚àíœïh(y).
(1)
Since g(y) ‚àíœïh(y) = h(x)‚àí1
h(x)g(y) ‚àíg(x)h(y)

, the content c

g(y) ‚àíœïh(y)

is
h(x)‚àí1 and the associated primitive polynomial is
(x, y) = h(x)g(y) ‚àíg(x)h(y).
Notice that (x, y) ‚ààk[x][y] and that (y, x) = ‚àí(x, y).
Rewrite Eq. (1), where c(q) ‚ààk(x) is the content of q(x, y):
f (x)‚àí1i(x, y)c(q)q(x, y)‚àóh(x) = (x, y)
(remember that f (x)‚àí1 is the content of irr(x, B) and i(x, y) is its associated primitive
polynomial).
The product i(x, y)q(x, y)‚àóis primitive, by Gauss's Lemma 6.23.
But
(x, y) ‚ààk[x][y], so that Lemma 6.24(iii) gives f (x)‚àí1c(q)h(x) ‚ààk[x]. We now deÔ¨Åne
q‚àó‚àó(x, y) = f (x)‚àí1c(q)h(x)q(x, y), so that q‚àó‚àó(x, y) ‚ààk[x, y] and
i(x, y)q‚àó‚àó(x, y) = (x, y)
in k[x, y].
(2)
Let us compute degrees in Eq. (2): the degree in x of the left hand side is
degx(iq‚àó‚àó) = degx(i) + degx(q‚àó‚àó) = m + degx(q‚àó‚àó),
(3)
while the degree in x of the right hand side is
degx() = max{deg(g), deg(h)} ‚â§m,
(4)
as we saw above. We conclude that m + degx(q‚àó‚àó) ‚â§m, so that degx(q‚àó‚àó) = 0; that
is, q‚àó‚àó(x, y) is a function of y alone. But (x, y) is a primitive polynomial in x, and
hence the symmetry (y, x) = ‚àí(x, y) shows that it is also a primitive polynomial
in y. Thus, q‚àó‚àóis a constant, and so i(x, y) and (x, y) are associates in k[x, y]; hence,
degx() = degx(i) = m. With Eq. (4), this equality gives
m = degx() = max{deg(g), deg(h)}.
Symmetry of  also gives degy() = degx(), and so
n = degy() = degx() = m = max{deg(g), deg(h)}.
By deÔ¨Ånition, degree(œï) = max{deg(g), deg(h)} = m; hence, Proposition 6.63 gives
[k(x) : k(œï)] = m. Finally, since œï ‚ààB, we have [k(x) : k(œï)] = [k(x) : B][B : k(œï)].
As [k(x) : B] = n = m, this forces [B : k(œï)] = 1; that is, B = k(œï).
‚Ä¢
There are examples of intermediate Ô¨Åelds B with k ‚äÜB ‚äÜk(x1, . . . , xn), for n > 1,
that are not so easily described.
We now consider more general Ô¨Åeld extensions.

Sec. 6.4
Applications of Zorn's Lemma
361
DeÔ¨Ånition.
Let E/k be a Ô¨Åeld extension. A subset U of E is algebraically depen-
dent over k if there exists a Ô¨Ånite subset {u1, . . . , un} ‚äÜU and a nonzero polynomial
f (x1, . . . , xn) ‚ààk[x1, . . . , xn] with f (u1, . . . , un) = 0. A subset B of E is algebraically
independent if it is not algebraically dependent.
Let E/k be a Ô¨Åeld extension, let u1, . . . , un ‚ààE, and let œï : k[x1, . . . , xn] ‚ÜíE be the
evaluation map; that is, œï is the homomorphism sending f (x1, . . . , xn) to f (u1, . . . , un)
for all f (x1, . . . , xn) ‚ààk[x1, . . . , xn]. Now {u1, . . . , un} is algebraically dependent if and
only if ker œï Ã∏= {0}. If {u1, . . . , un} is algebraically independent, then œï extends to an
isomorphism k(x1, . . . , xn) ‚àº= k(u1, . . . , un) ‚äÜ
E, where k(x1, . . . , xn) is the Ô¨Åeld of
rational functions Frac(k[x1, . . . , xn]). In particular, {x1, . . . , xn} ‚äÜE = k(x1, . . . , xn) is
algebraically independent, for œï is the identity map in this case.
Since algebraically dependent subsets are necessarily nonempty, it follows that the
empty subset ‚àÖis algebraically independent. A singleton {e} ‚äÜE is algebraically de-
pendent if e is algebraic over k; that is, e is a root of a nonconstant polynomial over k, and
it is algebraically independent if e is transcendental over k, in which case k(e) ‚àº= k(x).
Proposition 6.67.
Let E/k be a Ô¨Åeld extension. and let U ‚äÜE. Then U is algebraically
dependent over k if and only if there is u ‚ààU with u algebraic over k(U ‚àí{u}).
Proof.
If U is algebraically dependent over k, then there is a Ô¨Ånite algebraically depen-
dent subset U ‚Ä≤ = {u1, . . . , un} ‚äÜU. We prove, by induction on n ‚â•1, that some ui
is algebraic over k(U ‚Ä≤ ‚àí{ui}). If n = 1, then there is some nonzero f (x) ‚ààk[x] with
f (u1) = 0; that is, u1 is algebraic over k. But U ‚Ä≤ ‚àí{u1} = ‚àÖ, and so u1 is algebraic
over k(U ‚Ä≤ ‚àí{u1}) = k(‚àÖ) = k. For the inductive step, let U ‚Ä≤ = {u1, . . . , un+1} be
algebraically dependent. We may assume that {u1, . . . , un} is algebraically independent;
otherwise, the inductive hypothesis gives some u j, for 1 ‚â§j ‚â§n, which is algebraic
over k(u1, . . . ,u j, . . . , un), and hence, algebraic over k(U ‚Ä≤ ‚àí{u j}). Since U ‚Ä≤ is alge-
braically dependent, there is a nonzero f (X, y) ‚ààk[x1, . . . , xn, y] with f (‚Éóu, un+1) = 0,
where X = (x1, . . . , xn), y is a new variable, and ‚Éóu = (u1, . . . , un). We may write
f (X, y) = 
i gi(X)yi, where gi(X) ‚ààk[X] (because k[X, y] = k[X][y]).
Since
f (X, y) Ã∏= 0, some gi(X) Ã∏= 0, and it follows from the algebraic independence of
{u1, . . . , un} that gi(‚Éóu) Ã∏= 0. Therefore, h(y) = 
i gi(‚Éóu)yi ‚ààk(U)[y] is not the zero
polynomial. But 0 = f (‚Éóu, un+1) = h(un+1), so that un+1 is algebraic over k(u1, . . . , un).
For the converse, assume that u is algebraic over k(U ‚àí{u}). We may assume that
U ‚àí{u} is Ô¨Ånite, say, U ‚àí{u} = {u1, . . . , un}, where n ‚â•0 (if n = 0, we mean that
U ‚àí{u} = ‚àÖ). We prove, by induction on n ‚â•0, that U is algebraically dependent. If
n = 0, then u is algebraic over k, and so {u} is algebraically dependent. For the inductive
step, let U ‚àí{un+1} = {u1, . . . , un}. We may assume that U ‚àí{un+1} = {u1, . . . , un}
is algebraically independent, for otherwise U ‚àí{un+1}, and hence its superset U, is al-
gebraically dependent. By hypothesis, there is a nonzero polynomial f (y) = 
i ci yi ‚àà
k(u1, . . . , un)[y] with f (un+1) = 0. As f (y) Ã∏= 0, we may assume that one of its terms,
say, c j Ã∏= 0. Now ci ‚ààk(u1, . . . , un) for each i, and so there are rational functions
ci(x1, . . . , xn) with ci(‚Éóu) = ci, where ‚Éóu = (u1, . . . , un). Since f (un+1) = 0, we may
clear denominators and assume that each ci(x1, . . . , xn) is a polynomial in k[x1, . . . , xn].

362
Commutative Rings II
Ch. 6
Moreover, c j(‚Éóu) Ã∏= 0 implies c j(x1, . . . , xn) Ã∏= 0, and so
g(x1, . . . , y) =

i
ci(x1, . . . , xn)yi
is nonzero. Therefore, {u1, . . . , un+1} is algebraically dependent.
‚Ä¢
DeÔ¨Ånition.
A Ô¨Åeld extension E/k is purely transcendental if either E = k or E contains
an algebraically independent subset B and E = k(B).
If X = {x1, . . . , xn} is a Ô¨Ånite set, then
k(X) = k(x1, . . . , xn) = Frac

k[x1, . . . , xn]

is called the function Ô¨Åeld in n variables.
We are going to prove that if E/k is a Ô¨Åeld extension, then there exists an intermediate
Ô¨Åeld F with F/k purely transcendental and E/F algebraic. In fact, F = k(B), where B
is a maximal algebraically independent subset of E/k, and any two such subsets have the
same cardinal. The proof is essentially the same as a proof of the invariance of dimension
of a vector space, and so we axiomatize that proof.
Recall that a relation R from a set Y to a set Z is a subset R ‚äÜY √ó Z: we write y R z
instead of (y, z) ‚ààR. In particular, if $ is a set, P($) is the family of all its subsets, and
‚™Øis a relation from $ to P($), then we write
x ‚™ØS
instead of (x, S) ‚àà‚™Ø.
DeÔ¨Ånition.
A dependency relation on a set $ is a relation ‚™Øfrom $ to P($) that satisÔ¨Åes
the following axioms:
(i) if x ‚ààS, then x ‚™ØS;
(ii) if x ‚™ØS, then there exists a Ô¨Ånite subset S‚Ä≤ ‚äÜS with x ‚™ØS‚Ä≤;
(iii) (Transitivity) if x ‚™ØS and if, for some T ‚äÜ$, we have s ‚™ØT for every s ‚ààS, then
x ‚™ØT ;
(iv) (Exchange Axiom) if x ‚™ØS and x Ã∏‚™ØS ‚àí{y}, then y ‚™Ø(S ‚àí{y}) ‚à™{x}.
The transitivity axiom says that if x is dependent on a set S, and if each element of S is
dependent on another set T , then x is dependent on T .
Example 6.68.
If $ is a vector space, then deÔ¨Åne x ‚™ØS to mean x ‚àà‚ü®S‚ü©, the subspace spanned by S. We
claim that ‚™Øis a dependency relation. The Ô¨Årst three axioms are easily checked. We verify
the exchange axiom. If x ‚™ØS and x Ã∏‚™ØS ‚àí{y}, then S = S‚Ä≤ ‚à™{y} with y /‚ààS‚Ä≤. There are
scalars ai, a with x = ay + 
i aisi, where si ‚ààS‚Ä≤; since x /‚àà‚ü®S‚Ä≤‚ü©, we must have a Ã∏= 0.
Therefore, y = a‚àí1(x ‚àí
i aisi) ‚àà‚ü®S‚Ä≤, x‚ü©, and so y ‚™ØS‚Ä≤ ‚à™{x}.
‚óÄ

Sec. 6.4
Applications of Zorn's Lemma
363
Lemma 6.69.
If E/k is a Ô¨Åeld extension, then Œ± ‚™ØS, deÔ¨Åned by Œ± is algebraic over k(S),
is a dependency relation.
Proof.
It is easy to check the Ô¨Årst two axioms in the deÔ¨Ånition of dependency relation,
and we now verify axiom (iii): If x ‚™ØS and if, for some T ‚äÜ$, we have s ‚™ØT for every
s ‚ààS, then x ‚™ØT . If F is an intermediate Ô¨Åeld, denote the Ô¨Åeld of all e ‚ààE that are
algebraic over F by F. Using this notation, x ‚™ØS if and only if x ‚ààk(S). Moreover,
s ‚™ØT for every s ‚ààS says that S ‚äÜk(T ). It follows that x ‚ààk(T ), by Lemma 6.56(i),
and so x ‚™ØT .
The exchange axiom says, If u ‚™ØS and u Ã∏‚™ØS ‚àí{v}, then v ‚™Ø(S ‚àí{v}) ‚à™{u}.
Write S‚Ä≤ = S ‚àí{v}, so that u is algebraic over k(S) and u is transcendental over k(S‚Ä≤).
Now {u, v} is algebraically dependent over k(S‚Ä≤), by Proposition 6.67, and so there is a
nonzero polynomial f (x, y) ‚ààk(S‚Ä≤)[x, y] with f (u, v) = 0. In more detail, f (x, y) =
g0(x) + g1(x)y + ¬∑ ¬∑ ¬∑ + gn(x)yn, where gn(x) is nonzero. Since u is transcendental over
k(S‚Ä≤), we must have gn(u) Ã∏= 0. Therefore, h(y) = f (u, y) ‚ààk(S‚Ä≤, u)[y] is a nonzero
polynomial. But h(v) = f (u, v) = 0, and so v is algebraic over k(S‚Ä≤, u); that is, v ‚™Ø
S‚Ä≤ ‚à™{u} = (S ‚àí{v}) ‚à™{u}.
‚Ä¢
Example 6.68 suggests the following terminology.
DeÔ¨Ånition.
Let ‚™Øbe a dependency relation on a set $. Call a subset S ‚äÜ$ dependent
if there exists s ‚ààS with s ‚™ØS ‚àí{s}; call S independent if it is not dependent. We say
that a subset S generates $ if x ‚™ØS for all x ‚àà$. A basis of $ is an independent subset
that generates $.
Note that ‚àÖis independent, for dependent subsets have elements. If S Ã∏= ‚àÖ, then S
is independent if and only if s Ã∏‚™ØS ‚àí{s} for all s ‚ààS. It follows that every subset
of an independent set is itself independent. By Proposition 6.67, algebraic independence
deÔ¨Åned on page 361 coincides with independence just deÔ¨Åned for the dependency relation
in Lemma 6.69.
Lemma 6.70.
Let ‚™Øbe a dependency relation on a set $. If T ‚äÜ$ is independent and
z Ã∏‚™ØT for some z ‚àà$, then T ‚à™{z} ‚äãT is a strictly larger independent subset.
Proof.
Since z Ã∏‚™ØT , axiom (i) gives z /‚ààT , and so T ‚ääT ‚à™{z}; it follows that (T ‚à™{z})‚àí
{z} = T . If T ‚à™{z} is dependent, then there exists t ‚ààT ‚à™{z} with t ‚™Ø(T ‚à™{z}) ‚àí{t}.
If t = z, then z ‚™ØT ‚à™{z} ‚àí{z} = T , contradicting z Ã∏‚™ØT . Therefore, t ‚ààT . Since T is
independent, t Ã∏‚™ØT ‚àí{t}. If we set S = T ‚à™{z} ‚àí{t}, t = x, and y = z in the exchange
axiom, we conclude that z ‚™Ø(T ‚à™{z} ‚àí{t}) ‚àí{z} ‚à™{t} = T , contradicting the hypothesis
z Ã∏‚™ØT . Therefore, T ‚à™{z} is independent.
‚Ä¢
We now generalize the proof of the exchange lemma, Lemma 3.84, and its application
to invariance of dimension, Theorem 3.85.
Theorem 6.71.
If ‚™Øis a dependency relation on a set $, then $ has a basis. In fact,
every independent subset B of $ is part of a basis.
Proof.
Since the empty set ‚àÖis independent, the second statement implies the Ô¨Årst.

364
Commutative Rings II
Ch. 6
We use Zorn's lemma to prove the existence of maximal independent subsets of $
containing B. Let X be the family of all independent subsets of $ containing B, partially
ordered by inclusion. Note that X is nonempty, for B ‚ààX. Suppose that C is a chain
in X. It is clear that C‚àó= !
C‚ààC is an upper bound of C if it lies in X; that is, if C‚àóis
independent. If, on the contrary, C‚àóis dependent, then there is y ‚ààC‚àówith y ‚™ØC‚àó‚àí{y}.
By axiom (ii), there is a Ô¨Ånite subset {x1, . . . , xn} ‚äÜC‚àó‚àí{y} with y ‚™Ø{x1, . . . , xn}‚àí{y}.
Now there is C0 ‚ààC with y ‚ààC0, and, for each i, there is Ci ‚ààC with xi ‚ààCi.
Since C is a chain, one of these, call it C‚Ä≤, contains all the others, and the dependent set
{y, x1, . . . , xn} is contained in C‚Ä≤. But since C‚Ä≤ is independent, so are its subsets, and this
is a contradiction. Zorn's lemma now provides a maximal element M of X; that is, M is
a maximal independent subset of $ containing B. If M is not a basis, then there exists
x ‚àà$ with x Ã∏‚™ØM. By Lemma 6.70, M ‚à™{x} is an independent set strictly larger than M,
contradicting the maximality of M. Therefore, bases exist.
‚Ä¢
Theorem 6.72.
If $ is a set with a dependency relation ‚™Ø, then any two bases B and C
have the same cardinality.
Proof.
If B = ‚àÖ, we claim that C = ‚àÖ. Otherwise, there exists y ‚ààC and, since C is
independent, y Ã∏‚™ØC ‚àí{y}. But y ‚™ØB = ‚àÖand ‚àÖ‚äÜC ‚àí{y}, so that axiom (iii) gives
y ‚™ØC ‚àí{y}, a contradiction. Therefore, we may assume that both B and C are nonempty.
Now assume that B is Ô¨Ånite; say, B = {x1, . . . , xn}. We prove, by induction on k ‚â•0,
that there exists {y1, . . . , yk‚àí1} ‚äÜC with
Bk = {y1, . . . , yk‚àí1, xk, . . . , xn}
a basis: The elements x1 . . . , xk‚àí1 in B can be replaced by elements y1, . . . , yk‚àí1 ‚ààC so
that Bk is a basis. We deÔ¨Åne B0 = B, and we interpret the base step to mean that if none
of the elements of B are replaced, then B = B0 is a basis; this is obviously true. For the
inductive step, assume that Bk = {y1, . . . , yk‚àí1, xk, . . . , xn} is a basis. We claim that there
is y ‚ààC with y Ã∏‚™ØBk ‚àí{xk}. Otherwise, y ‚™ØBk ‚àí{xk} for all y ‚ààC. But xk ‚™ØC, because
C is a basis, and so axiom (iii) gives xk ‚™ØBk ‚àí{xk}, contradicting the independence of
Bk. Hence, we may choose yk ‚ààC with yk Ã∏‚™ØBk ‚àí{xk}. By Lemma 6.70, the set Bk+1,
deÔ¨Åned by
Bk+1 = (Bk ‚àí{xk}) ‚à™{yk} = {y1, . . . , yk, xk+1, . . . , xn},
is independent. To see that Bk+1 is a basis, it sufÔ¨Åces to show that it generates $. Now
yk ‚™ØBk (because Bk is a basis), and yk Ã∏‚™ØBk ‚àí{xk}; the exchange axiom gives xk ‚™Ø
(Bk ‚àí{xk}) ‚à™{yk} = Bk+1. By axiom (i), all the other elements of Bk are dependent on
Bk+1. Now each element of $ is dependent on Bk, and each element of Bk is dependent
on Bk+1. By axiom (iii), Bk+1 generates $.
If |C| > n = |B|, that is, if there are more y's than x's, then Bn ‚ääC. Thus a proper
subset of C generates $, and this contradicts the independence of C. Therefore, |C| ‚â§|B|.
It follows that C is Ô¨Ånite, and so the preceding argument can be repeated, interchanging
the roles of B and C. Hence, |B| ‚â§|C|, and we conclude that |B| = |C| if $ has a Ô¨Ånite
basis.

Sec. 6.4
Applications of Zorn's Lemma
365
When B is inÔ¨Ånite, the reader may complete the proof by adapting the proof of The-
orem 6.51. In particular, replace supp(v) in that proof by axiom (ii) in the deÔ¨Ånition of
dependency relation.
‚Ä¢
We now apply this general result to algebraic dependence.
DeÔ¨Ånition.
If E/k is a Ô¨Åeld extension, then a transcendence basis is a maximal alge-
braically independent subset of E over k, and the transcendence degree of E/k is deÔ¨Åned
by
tr. deg(E/k) = |B|.
The next theorem shows that transcendence degree is well-deÔ¨Åned.
Theorem 6.73.
If E/k is a Ô¨Åeld extension, then there exists a transcendence basis B. If
F = k(B), then F/k is purely transcendental and E/F is algebraic. Moreover, if B and
C are maximal algebraically independent subsets, then |B| = |C|.
Proof.
In Lemma 6.69, we saw that Œ± ‚™ØS, deÔ¨Åned by Œ± being algebraic over k(S), is a
dependency relation. By Theorems 6.71 and 6.72, transcendence bases exist, and any two
of them have the same cardinality; that is, transcendence degree is well-deÔ¨Åned. It remains
to show that if B is a transcendence basis, then E/k(B) is algebraic. If not, then there
exists Œ± ‚ààE with Œ± transcendental over k(B). By Lemma 6.70, B ‚à™{Œ±} is algebraically
independent, and this contradicts the maximality of B.
‚Ä¢
Example 6.74.
(i) Intermediate Ô¨Åelds F, as in the statement of Theorem 6.73, need not be unique. For
example, if E = Q(œÄ), then Q(œÄ4) and Q(œÄ2) are such intermediate Ô¨Åelds.
(ii) If E = k(x1, . . . , xn) is the Ô¨Åeld of rational functions in n variables over a Ô¨Åeld k, then
tr. deg(E/k) = n, for {x1, . . . , xn} is a transcendence basis of E.
(iii) If E/k is a Ô¨Åeld extension, then E/k is algebraic if and only if tr. deg(E/k) = 0.
‚óÄ
Here is a small application of transcendence degree.
Proposition 6.75.
There are nonisomorphic Ô¨Åelds each of which is isomorphic to a sub-
Ô¨Åeld of the other.
Proof.
Clearly, C is isomorphic to a subÔ¨Åeld of C(x). However, we claim that C(x) is
isomorphic to a subÔ¨Åeld of C. Let B be a transcendence basis of C over Q, and discard
one of its elements, say, b. The algebraic closure F of Q(B ‚àí{b}) is a proper subÔ¨Åeld of
C, for b /‚ààF; in fact, b is transcendental over F, by Proposition 6.67. Therefore, F ‚àº= C,
by Exercise 6.54 on page 375, and so F(b) ‚àº= C(x). Therefore, each of C and C(x) is
isomorphic to a subÔ¨Åeld of the other. On the other hand C(x) Ã∏‚àº= C, because C(x) is not
algebraically closed.
‚Ä¢
We continue our investigation into the structure of Ô¨Åelds by considering separability in
more detail. Recall that if E/k is a Ô¨Åeld extension, then an element Œ± ‚ààE is separable

366
Commutative Rings II
Ch. 6
over k if either Œ± is transcendental over k or irr(Œ±, k) is a separable polynomial9; that is,
irr(Œ±, k) has no repeated roots. An extension E/k is separable if every Œ± ‚ààE is separable
over k; otherwise, it is inseparable.
Proposition 6.76.
Let f (x) ‚ààk[x], where k is a Ô¨Åeld, and let f ‚Ä≤(x) be its derivative.
(i) f (x) has repeated roots if and only if ( f, f ‚Ä≤) Ã∏= 1.
(ii) If k is a Ô¨Åeld of characteristic p > 0, then f ‚Ä≤(x) = 0 if and only if f (x) ‚ààk[x p].
(iii) If k is a Ô¨Åeld of characteristic p > 0 and if f ‚Ä≤(x) = 0, then f (x) has no repeated
roots. Conversely, if f (x) is an irreducible polynomial in k[x], then the conditions
in parts (i) and (ii) are all equivalent.
Proof.
(i) If f (x) has repeated roots, then f (x) = (x ‚àíŒ±)2g(x) in k[x], so that f ‚Ä≤(x) =
2(x ‚àíŒ±)g(x) + (x ‚àíŒ±)2g‚Ä≤(x). Therefore, x ‚àíŒ± is a common divisor of f (x) and f ‚Ä≤(x),
and so ( f, f ‚Ä≤) Ã∏= 1.
Conversely, it sufÔ¨Åces to work in a splitting Ô¨Åeld of f (x), by Corollary 3.41. If x ‚àíŒ± is
a divisor of ( f, f ‚Ä≤), then f (x) = (x ‚àíŒ±)u(x) and f ‚Ä≤(x) = (x ‚àíŒ±)v(x). The product rule
gives f ‚Ä≤(x) = u(x) + (x ‚àíŒ±)u‚Ä≤(x), so that u(x) = (x ‚àíŒ±)(v(x) ‚àíu‚Ä≤(x)). Therefore,
f (x) = (x ‚àíŒ±)u(x) = (x ‚àíŒ±)2(v(x) ‚àíu‚Ä≤(x)),
and so f (x) has a repeated root.
(ii) Assume that f (x) = 
i ai xi and f ‚Ä≤(x) = 0 = 
i iai xi‚àí1. If the coefÔ¨Åcient ai Ã∏= 0,
then iai xi‚àí1 = 0 if and only if iai = 0; this happens only if p | i. Therefore, the only
nonzero coefÔ¨Åcents of f (x) must be of the form ai for p | i; that is, f (x) ‚ààk[x p].
If f (x) ‚ààk[x p], then f (x) = 
j apj x pj and f ‚Ä≤(x) = 
j pjapj x pj‚àí1 = 0.
(iii) If f ‚Ä≤(x) = 0, then ( f, f ‚Ä≤) = ( f, 0) = f ; hence, if f (x) is not constant [in particular,
if f (x) is irreducible], then ( f, f ‚Ä≤) Ã∏= 1.
Conversely, if f (x) is irreducible, then ( f, f ‚Ä≤) = 1 or ( f, f ‚Ä≤) = f . Now ( f, f ‚Ä≤) Ã∏= 1,
so that ( f, f ‚Ä≤) = f and, hence, f | f ‚Ä≤. We claim that f ‚Ä≤(x) = 0. If, on the contrary,
f ‚Ä≤(x) Ã∏= 0, then f ‚Ä≤(x) has a degree and deg( f ‚Ä≤) < deg( f ). But f | f ‚Ä≤ implies deg( f ) ‚â§
deg( f ‚Ä≤), and this is a contradiction. Hence, f ‚Ä≤(x) = 0.
‚Ä¢
Corollary 6.77.
If k is a Ô¨Åeld of characteristic p > 0 and f (x) ‚ààk[x], then there exists
e ‚â•0 and a polynomial g(x) ‚ààk[x] with g(x) /‚ààk[x p] and f (x) = g(x pe). Moreover, if
f (x) is irreducible, then g(x) is separable.
Proof.
If f (x) /‚ààk[x p], deÔ¨Åne g(x) = f (x); if f (x) ‚ààk[x p], there is f1(x) ‚àà[x] with
f (x) = f1(x p). Note that deg( f ) = p deg( f1). If f1(x) /‚ààk[x p], deÔ¨Åne g(x) = f1(x);
otherwise, there is f2(x) ‚ààk[x] with f1(x) = f2(x p); that is,
f (x) = f1(x p) = f2(x p2).
9Recall that an irreducible polynomial is separable if it has no repeated roots, and an arbitrary polynomial is
separable if each of its irreducible factors has no repeated roots.

Sec. 6.4
Applications of Zorn's Lemma
367
Since deg( f ) > deg( f1) > ¬∑ ¬∑ ¬∑ , iteration of this procedure must end after a Ô¨Ånite number e
of steps. Thus, f (x) = g(x pe), where g(x), deÔ¨Åned by g(x) = fe(x), does not lie in k[x p].
If, now, f (x) is irreducible, then f1(x) is irreducible, for a factorization of f1(x) would
give a factorization of f (x). It follows that fi(x) is irreducible for all i. In particular, fe(x)
is irreducible, and so it is separable, by Proposition 6.76(iii).
‚Ä¢
DeÔ¨Ånition.
Let k be a Ô¨Åeld of characteristic p > 0, and let f (x) ‚ààk[x]. If f (x) =
g(x pe), where g(x) ‚ààk[x] but g(x) /‚ààk[x p], then
deg( f ) = pe deg(g).
We call pe the degree of inseparability of f (x), and we call deg(g) the reduced degree of
f (x).
Example 6.78.
Let f (x) = x p3 + x p + t ‚ààFp(t)[x]. If g(x) = x p2 + x + t, then g(x) is separable (for
g‚Ä≤(x) = 1 Ã∏= 0). Therefore, f (x) has degree of inseparability p and reduced degree p2.
‚óÄ
If k is a Ô¨Åeld of prime characteric p > 0, then the Frobenius map F : k ‚Üík, deÔ¨Åned by
F : Œ± ‚ÜíŒ± p, is a homomorphism [because (Œ± + Œ≤)p = Œ± p + Œ≤ p]. As any homomorphism
of Ô¨Åelds, F is an injection. Denote im F by k p, so that k p is the subÔ¨Åeld of k consisting of
all the pth powers of elements in k:
k p = im F = {a p : a ‚ààk}.
To say that F is surjective, that is, k = k p, is to say that every element in k has a pth root
in k.
DeÔ¨Ånition.
A Ô¨Åeld k is called perfect if either k has characteristic 0 or if k has character-
istic p > 0 and k = k p.
Existence of pth roots in k is closely related to separability.
Proposition 6.79.
(i) A Ô¨Åeld k is perfect if and only if every polynomial in k[x] is separable.
(ii) If k is a perfect Ô¨Åeld, then every algebraic extension E/k is a separable extension.
(iii) Every Ô¨Ånite Ô¨Åeld k is perfect, and every algebraic extension E/k is separable. In
particular, if Fp is the algebraic closure of Fp, then Fp/Fp is a separable extension.
Proof.
(i) If k has characteristic 0, then Lemma 4.4 shows that every polynomial in k[x] is
separable. Assume now that k has characteristic p > 0 and that f (x) ‚ààk[x] is inseparable.
By Proposition 6.76, f (x) ‚ààk[x p], so that f (x) = 
i ai x pi. If every element in k has a
pth root, then ai = bp
i for bi ‚ààk. Hence,
f (x) =

i
bp
i x pi =

i
bi xip,

368
Commutative Rings II
Ch. 6
and so f (x) is not irreducible. In other words, if k = k p, then every irreducible polynomial
in k[x] is separable and, hence, every polynomial is separable.
Conversely, assume that every polynomial in k[x] is separable. If k has characteristic
0, there is nothing to prove. If k has characteristic p > 0 and if a ‚ààk, then x p ‚àía has
repeated roots; since our hypothesis says that irreducible polynomials are separable, x p ‚àía
factors. Proposition 3.126 now says that a has a pth root in k; that is, a ‚ààk p. Therefore,
k = k p, and so k is perfect.
(ii) If E/k is an algebraic extension, then every Œ± ‚ààE has a minimum polynomial irr(Œ±, k);
since irr(Œ±, k) is a separable polynomial, by part (i), Œ± is separable over k, and so E/k is a
separable extension.
(iii) As any homomorphism of Ô¨Åelds, the Frobenius F : k ‚Üík is injective. If k is a
Ô¨Ånite Ô¨Åeld of characteristic p > 0, then Exercise 1.58 on page 36 shows that F must also
be surjective; that is, k = k p. Therefore, k is perfect, and part (ii) gives the rest of the
statement.
‚Ä¢
We will soon need a variant of Proposition 3.126.
Lemma 6.80.
Let p be a prime, let e ‚â•0, and let k be a Ô¨Åeld of characteristic p > 0. If
c ‚ààk and c /‚ààk p, then f (x) = x pe ‚àíc is irreducible in k[x].
Proof.
The proof is by induction on e ‚â•0, the base step being true because every linear
polynomial is irreducible. For the inductive step, suppose the statement is false. Let g(x) ‚àà
k[x] be irreducible, and let g(x)m, for m ‚â•1, be the highest power of g(x) dividing f (x):
x pe ‚àíc = g(x)mh(x),
where (g(x), h(x)) = 1. Take the derivative, 0 = mg(x)m‚àí1g‚Ä≤(x)h(x) + g(x)mh‚Ä≤(x), and
divide by g(x)m‚àí1,
0 = mg‚Ä≤(x)h(x) + g(x)h‚Ä≤(x).
Therefore, h(x) | h‚Ä≤(x), because (g, h) = 1. If h‚Ä≤(x) Ã∏= 0, then deg(h‚Ä≤) is deÔ¨Åned and
deg(h‚Ä≤) < deg(h), a contradiction; thus, h‚Ä≤(x) = 0. Proposition 6.76 gives
h(x) = h1(x p),
where h1(x) ‚ààk[x].
Now mg‚Ä≤(x)h(x) = 0 gives
mg‚Ä≤(x) = 0,
(5)
for h(x) Ã∏= 0, and this implies that (gm(x))‚Ä≤ = 0. Hence, Proposition 6.76 gives
gm(x) = g1(x p),
where g1(x) ‚ààk[x].
Therefore,
x pe ‚àíc = g(x)mh(x) = g1(x p)h1(x p),

Sec. 6.4
Applications of Zorn's Lemma
369
and so, replacing x p by x, we have
x pe‚àí1 ‚àíc = g1(x)h1(x).
Since x pe‚àí1 ‚àíc is irreducible, by the inductive hypothesis, one of g1, h1 must be constant.
But if g1(x) is constant, then g1(x p) is constant and gm(x) is constant, a contradiction.
Therefore, h1(x) is constant; absorbing it into g1(x), we have x pe‚àí1 ‚àíc = g1(x) and
x pe ‚àíc = g1(x p) = g(x)m.
If p | m, then x pe ‚àíc = (g(x)p)m/p, and so all the coefÔ¨Åcients lie in k p, contradicting
c /‚ààk p; therefore, p ‚à§m. Eq. (5) now gives g‚Ä≤(x) = 0, so that g(x) ‚ààk[x p]; say,
g(x) = g2(x p). This forces m = 1, because x pe ‚àíc = g(x)m gives x pe‚àí1 ‚àíc = g2(x)m,
which is a forbidden factorization of the irreducible x pe‚àí1 ‚àíc.
‚Ä¢
If E/k is a Ô¨Åeld extension, where k has characteristic p, then k p ‚äÜE p, but we do not
know whether k ‚äÜE p; that is, E p may not be an intermediate Ô¨Åeld of E/k (for example,
take E = k). Denote the subÔ¨Åeld of E obtained by adjoining E p to k by k(E p).
Proposition 6.81.
(i) Let k ‚äÜB ‚äÜE be a tower of Ô¨Åelds with E/k algebraic. If E/k is separable, then
E/B is separable.
(ii) Let E/k be an algebraic Ô¨Åeld extension, where k has characteristic p > 0. If E/k is
a separable extension, then E = k(E p). Conversely, if E/k is Ô¨Ånite and E = k(E p),
then E/k is separable.
Proof.
(i) If Œ± ‚ààE, then Œ± is algebraic over B, and irr(Œ±, B) | irr(Œ±, k) in B[x], for their
gcd is not 1 and irr(Œ±, B) is irreducible. Since irr(Œ±, k) has no repeated roots, irr(Œ±, B)
has no repeated roots, and hence irr(Œ±, B) is a separable polynomial. Therefore, E/B is a
separable extension.
(ii) Let E/k be a separable extension. Now k(E p) ‚äÜE, and so E/k(E p) is a separable
extension, by part (i). But if Œ≤ ‚ààE, then Œ≤ p ‚ààE p ‚äÜk(E p); say, Œ≤ p = Œ±. Hence,
irr(Œ≤, k(E p)) | (x p ‚àíŒ±) in

k(E p)

[x], and so this polynomial is not separable because it
divides x p ‚àíŒ± = (x ‚àíŒ≤)p. We conclude that Œ≤ ‚ààk(E p); that is, E = k(E p).
Conversely, suppose that E = k(E p). We begin by showing that if Œ≤1, . . . , Œ≤s is a
linearly independent list in E (where E is now viewed only as a vector space over k), then
Œ≤ p
1 , . . . , Œ≤ p
s is also linearly independent over k. Extend Œ≤1, . . . , Œ≤s to a basis Œ≤1, . . . , Œ≤n of
E, where n = [E : k]. Now Œ≤ p
1 , . . . , Œ≤ p
n spans E p over k p, for if Œ∑ ‚ààE, then Œ∑ = 
i aiŒ≤i,
where ai ‚ààk, and hence Œ∑p = 
i a p
i Œ≤ p
i . Now take any element Œ≥ ‚ààE. Since E = k(E p),
we have Œ≥ = 
j c jŒ∑ j, where c j ‚ààk and Œ∑ j ‚ààE p. But Œ∑ j = 
i a p
jiŒ≤ p
i for a ji ‚ààk, as
we have just seen, so that Œ≥ = 
i

j c ja p
ji

Œ≤ p
i ; that is, Œ≤ p
1 , . . . , Œ≤ p
n spans E over k.
Since dimk(E) = n, this list is a basis, and hence its sublist Œ≤ p
1 , . . . , Œ≤ p
s must be linearly
independent over k.

370
Commutative Rings II
Ch. 6
Since E/k is Ô¨Ånite, each Œ± is algebraic over k. If irr(Œ±, k) has degree m, then 1, Œ±,
Œ±2,. . .,Œ±m is linearly dependent over k, while 1, Œ±, Œ±2, . . . , Œ±m‚àí1 is linearly independent.
If Œ± is inseparable, then irr(Œ±, k) = fe(x pe) and m = per where r is the reduced degree of
irr(Œ±, k). Since r = m/pe < m, we have 1, Œ±, Œ±2, . . . , Œ±r linearly independent over k. But
Œ± pe is a root of fe(x), so there is a nontrivial dependency relation on 1, Œ± pe, Œ±2pe, . . . , Œ±rpe
(for rpe = m). We have seen, in the preceding paragraph, that linear independence of
1, Œ±, Œ±2, . . . , Œ±r implies linear independence of 1, Œ± pe, Œ±2pe, . . . , Œ±rpe. This contradiction
shows that Œ± must be separable over k.
‚Ä¢
Corollary 6.82.
Let E/k be a Ô¨Ånite separable extension, where k is a Ô¨Åeld of character-
istic p. If a list Œ≤1, . . . , Œ≤r in E is linearly independent over k, then for all e ‚â•1, the list
Œ≤ pe
1 , . . . , Œ≤ pe
r
is also linearly independent over k.
Proof.
The proof is by induction on e ‚â•1, with the hypothesis of separability used in the
form E = k(E p), as in the proof of Proposition 6.81(ii).
‚Ä¢
Corollary 6.83.
If k ‚äÜB ‚äÜE is a tower of algebraic extensions, then B/k and E/B
are separable extensions if and only if E/k is a separable extension.
Proof.
Since B/k and E/B are separable, Proposition 6.81(ii) gives B = k(B p) and
E = B(E p). Therefore,
E = B(E p) = k(B p)(E p) = k(B p ‚à™E p) = k(E p) ‚äÜE,
because B p ‚äÜE p. Therefore, E/k is separable, by Proposition 6.81(ii).
Conversely, if every element of E is separable over k, we have, in particular, that each
element of B is separable over k; hence, B/k is a separable extension. Finally, Proposi-
tion 6.81(i) shows that E/B is a separable extension.
‚Ä¢
Proposition 6.84.
If E/K is an algebraic extension, deÔ¨Åne
Es =

Œ± ‚ààE : Œ± is separable over k

;
then Es is an intermediate Ô¨Åeld that is the unique maximal separable extension of k con-
tained in E.
Proof.
This follows from Proposition 4.38(ii), for if Œ±, Œ≤ are separable over k, then
k(Œ±, Œ≤)/k is separable, and hence Œ± + Œ≤, Œ±Œ≤, and Œ±‚àí1 are all separable over k.
‚Ä¢
Not surprisingly, if E/k is an algebraic extension, then the extension E/Es has a special
property. Of course, Es is of interest only when k has characteristic p > 0 (otherwise,
Es = E).
The next type of extension is "complementary" to separable extensions.

Sec. 6.4
Applications of Zorn's Lemma
371
DeÔ¨Ånition.
Let E/k be a Ô¨Åeld extension, where k has characteristic p > 0. Then E/k
is a purely inseparable extension if E/k is algebraic and, for every Œ± ‚ààE, there is e ‚â•0
with Œ± pe ‚ààk.
If E/k is a purely inseparable extension and B is an intermediate Ô¨Åeld, then it is clear
that E/B is purely inseparable.
Proposition 6.85.
If E/k is an algebraic Ô¨Åeld extension, where k has characteristic
p > 0, then E/Es is a purely inseparable extension; moreover, if Œ± ‚ààE, then irr(Œ±, Es) =
x pm ‚àíc for some m ‚â•0.
Proof.
If Œ± ‚ààE, write irr(Œ±, k) = fe(x pe), where e ‚â•0 and fe(x) ‚ààk[x] is a separable
polynomial. It follows that Œ± pe is separable over k and Œ± pe ‚ààEs. If Œ± /‚ààEs, choose
m minimal with Œ± pm ‚ààEs. Now Œ± is a root of x pm ‚àíŒ± pm, which is irreducible, by
Lemma 6.80, and so irr(Œ±, Es) = x pm ‚àíc, where c = Œ± pm.
‚Ä¢
DeÔ¨Ånition.
If E/k is a Ô¨Ånite extension, deÔ¨Åne the separability degree by [E : k]s =
[Es : k], and deÔ¨Åne the inseparability degree by [E : k]i = [E : Es].
Note that E/k is separable if and only if [E : k]i = 1. It is clear that
[E : k] = [E : k]s[E : k]i.
Proposition 6.86.
Let E/k be a Ô¨Ånite extension, where k is a Ô¨Åeld of characteristic p > 0.
If E/k is purely inseparable, then [E : k] = pe for some e ‚â•0. Hence, for some e ‚â•0,
[E : k]i = [E : Es] = pe.
Proof.
If Œ± ‚ààE, then Œ± is purely inseparable over k; if Œ± is not constant, then irr(Œ±, Es) =
x pm ‚àíc for some c ‚ààk, where m ‚â•1. Therefore,
[E : k] = [E : k(Œ±)][k(Œ±) : k] = [E : k(Œ±)]pm.
Now [E : k(Œ±)] < [E : k]; since E/k(Œ±) is purely inseparable, the proof can be com-
pleted by induction. The second statement follows from Proposition 6.85, for E is purely
inseparable over Es.
‚Ä¢
Proposition 6.87.
If k ‚äÜB ‚äÜE is a tower of Ô¨Ånite extensions, where k is a Ô¨Åeld of
characteristic p > 0, then
[E : k]s = [E : B]s[B : k]s
and
[E : k]i = [E : B]i[B : k]i.
Proof.
In light of the equation [E : k] = [E : k]s[E : k]i, it sufÔ¨Åces to prove [E : k]s =
[E : B]s[B : k]s.

372
Commutative Rings II
Ch. 6
The notation Bs is unambiguous, but the notation Es here is ambiguous. We write Es to
denote the intermediate Ô¨Åeld consisting of all those elements of E that are separable over
k, and we write
EB = {Œ± ‚ààE : Œ± is separable over B}.
We have k ‚äÜBs ‚äÜEs ‚äÜEB ‚äÜE; let us see that Es ‚äÜEB. If Œ± ‚ààE is separable over
k, then irr(Œ±, k) has no repeated roots; hence, Œ± is separable over B, because irr(Œ±, B) |
irr(Œ±, k) in B[x], and so Œ± ‚ààEB. With this notation,
[E : k]s = [Es : k],
[E : B]s = [EB : B],
and
[B : k]s = [Bs : k].
Now
[E : k]s = [Es : k] = [Es : Bs][Bs : k] = [Es : Bs][B : k]s.
Thus, it sufÔ¨Åces to prove
[Es : Bs] = [EB : B],
for [EB : B] = [E : B]s.
We show that [Es : Bs] ‚â§[EB : B] by proving that a list Œ≤1, . . . , Œ≤r in Es ‚äÜEB
linearly independent over Bs is also linearly independent over B. Suppose that  biŒ≤i =
0, where bi ‚ààB are not all 0. For all e ‚â•0, we have 0 = ( biŒ≤i)pe =  bpe
i Œ≤ pe
i . But
there is e ‚â•0 with bpe
i
‚ààBs for all i, because B/Bs is purely inseparable, and so the
list Œ≤ pe
1 , . . . , Œ≤ pe
r
is linearly dependent over Bs, contradicting Corollary 6.82 (for Es/Bs
is a separable extension). For the reverse inequality [Es : Bs] ‚â•[EB : B], take a list
Œ≥1, . . . , Œ≥t in EB that is linearly independent over B. Since EB/Es is purely inseparable
(it is an intermediate Ô¨Åeld of E/Es), there is e ‚â•0 with Œ≥ pe
i
‚ààEs for all i. But Es/B
is a separable extension, so that Corollary 6.82 gives Œ≥ pe
1 , . . . , Œ≥ pe
t
linearly independent
over B; a fortiori, Œ≥ pe
1 , . . . , Œ≥ pe
t
is linearly independent over Bs. Therefore, [Es : Bs] =
[EB : B].
‚Ä¢
We merely state some further results about separability.
DeÔ¨Ånition.
If A and B are intermediate Ô¨Åelds of a Ô¨Åeld extension E/k, then A and B are
linearly disjoint if every Ô¨Ånite list Œ±1, . . . , Œ±n in A that is linearly independent over k is
linearly independent over B. That is, if 
i ciŒ±i = 0 implies all ci = 0 whenever ci ‚ààk,
then 
i Œ≤iŒ±i = 0 implies all Œ≤i = 0 whenever Œ≤i ‚ààB.
This condition on A and B can be shown to be symmetric; that is, every Ô¨Ånite list in
B that is linearly independent over k is also linearly independent over A. In Chapter 4,
we deÔ¨Åned two intermediate Ô¨Åelds A and B to be linearly disjoint if A ‚à©B = k. This
new deÔ¨Ånition is stronger than the old one: If Œ± ‚ààA and Œ± /‚ààk, then 1, Œ± is linearly
independent over k. If Œ± ‚ààA ‚à©B, then ‚àíŒ± ¬∑ 1 + 1 ¬∑ Œ± = 0 is a dependency relation
over B (for ‚àíŒ±, 1 ‚ààB). However, there are examples of intermediate Ô¨Åelds A and B with
A ‚à©B = k that are not linearly disjoint in this new sense.

Sec. 6.4
Applications of Zorn's Lemma
373
DeÔ¨Ånition.
Let k be a Ô¨Åeld of characteristic p; for n ‚â•1, deÔ¨Åne
k1/p = {Œ± ‚ààk : Œ± p ‚ààk},
where k is the algebraic closure of k.
Theorem.
An algebraic Ô¨Åeld extension E/k is separable if and only if k1/p and E are
linearly disjoint (as intermediate Ô¨Åelds of E/k, where E is the algebraic closure of E).
Proof.
See Zariski-Samuel, Commutative Algebra I, page 109.
‚Ä¢
If we do not assume that a Ô¨Åeld extension E/k is algebraic, are the generalizations of
Propositions 6.81(ii) through 6.85 still true?
DeÔ¨Ånition.
A separating transcendence basis of a Ô¨Åeld extension E/k is a transcendence
basis B with E/k(B) a separable extension.
Not every extension E/k has a separating transcendence basis. For example, if E/k is
an inseparable algebraic extension, then the only transcendence basis is ‚àÖ; but k(‚àÖ) = k,
and E/k(‚àÖ) is inseparable.
Theorem (Mac Lane).
If a Ô¨Åeld extension E/k has a separating transcendence basis,
then E and k1/p are linearly disjoint intermediate Ô¨Åelds of E, the algebraic closure of
E. Conversely, if E and k1/p are linearly disjoint and E/k is Ô¨Ånitely generated, that is,
E = k(u1, . . . , un), then E/k has a separating transcendence basis.
Proof.
See Jacobson, Basic Algebra II, page 519.
‚Ä¢
The following example shows why one assumes, in Mac Lane's theorem, that E/k is
Ô¨Ånitely generated.
Example 6.88.
Let k be a perfect Ô¨Åeld of characteristic p, let k(x) be the function Ô¨Åeld, and deÔ¨Åne
E = k({un, for n ‚â•1 : u pn
n
= x}).
Since k is perfect, every extension of k is separable, and so E ‚à©k1/p = k. However,
we claim that E/k does not have a separating transcendence basis. By Exercise 6.52 on
page 375, tr. deg(E/k) = 1, because any pair x1/pn and x1/pm are algebraically depen-
dent; let {Œ≤} be a transcendence basis. Now k(Œ≤) Ã∏= E, and so there exists some un with
un /‚ààk(Œ≤); choose n minimal. Consider the tower k(Œ≤) ‚äÜk(Œ≤, un) ‚äÜE. If {Œ≤} were a sep-
arating transcendence basis, then E/k(Œ≤, un) would be separable, by Proposition 6.81(i).
But irr(un, k(Œ≤)) is a nonlinear divisor of y pn ‚àíx pn, because un /‚ààk(Œ≤), and hence it has
repeated roots; therefore, E/k(Œ≤, un) is inseparable, a contradiction.
‚óÄ

374
Commutative Rings II
Ch. 6
EXERCISES
6.41 Let k be a Ô¨Åeld of characteristic p > 0, and let f (x) = x2p ‚àíx p + t ‚ààk(t)[x].
(i) Prove that f (x) is an irreducible polynomial in k(t)[x].
(ii) Prove that f (x) is inseparable.
(iii) Prove that there exists an algebraic extension E/k(t) for which there is no intermedi-
ate Ô¨Åeld Ei with Ei/k purely inseparable and E/Ei separable. (Compare with Corol-
lary 6.85 and Proposition 4.38.)
6.42 Let m be a positive integer, and let X be the set of all its (positive) divisors. Prove that X is a
partially ordered set if one deÔ¨Ånes a ‚™Øb to mean a | b.
6.43 Recall that if S is a subset of a partially ordered set X, then the least upper bound of S (should
it exist) is an upper bound m of S such that m ‚™Øu for every upper bound u of S. If X is the
following partially ordered set (in which d ‚™Øa is indicated by a joining with a line and having
a higher than d),
a

b

c
d
prove that the subset S = {c, d} has an upper bound but no least upper bound.
6.44 Let G be an abelian group, and let S ‚äÜG be a subgroup.
(i) Prove that there exists a subgroup H of G maximal with the property that H ‚à©S = {0}.
Is this true if G is not abelian?
(ii) If H is maximal with H ‚à©S = {0}, prove that G/(H + S) is torsion.
6.45 Call a subset C of a partially ordered set X coÔ¨Ånal if, for each x ‚ààX, there exists c ‚ààC with
x ‚™Øc.
(i) Prove that Q and Z are coÔ¨Ånal subsets of R.
(ii) Prove that every chain X contains a well-ordered coÔ¨Ånal subset.
Hint. Use Zorn's lemma on the family of all the well-ordered subsets of X.
(iii) Prove that every well-ordered subset in X has an upper bound if and only if every chain
in X has an upper bound.
6.46
(i) Give an example of a commutative ring containing two prime ideals P and Q for which
P ‚à©Q is not a prime ideal.
(ii) If P1 ‚äáP2 ‚äá¬∑ ¬∑ ¬∑ Pn ‚äáPn+1 ¬∑ ¬∑ ¬∑ is a decreasing sequence of prime ideals in a commu-
tative ring R, prove that 
n‚â•1 Pn is a prime ideal.
(iii) Prove that every commutative ring R has a minimal prime ideal; that is, a prime ideal I
for which there is no prime ideal P with P ‚ääI.
Hint.
Partially order the set of all prime ideals by reverse inclusion: P ‚™ØQ means
P ‚äáQ.
6.47 Let V be a vector space, and let S be a subspace of V . Prove that there exists a subspace W of
V maximal with the property that W ‚à©S = 0 and that V = S ‚äïW.
6.48 Recall that a subset S of a commutative ring R is called multiplicatively closed if 0 /‚ààS
and s, s‚Ä≤ ‚ààS implies ss‚Ä≤ ‚ààS. Complete Exercise 6.9 on page 325 by proving that if S is

Sec. 6.4
Applications of Zorn's Lemma
375
a multiplicatively closed set with S ‚à©I = ‚àÖ, then there exists an ideal J maximal with the
property that J contains I and J ‚à©S = ‚àÖ.
6.49 Prove that every nonunit in a commutative ring lies in some maximal ideal. [This result was
used to solve Exercise 6.16(ii) on page 326.]
6.50 If p1, . . . , pn are distinct primes in Z, prove that ‚àöp1, . . . , ‚àöpn is a linearly independent list
over Q.
6.51 Prove that a Ô¨Åeld extension E/k may not have an intermediate Ô¨Åeld K with K/k algebraic
and E/K purely transcendental.
Hint.
Prove that there is no intermediate Ô¨Åeld K with Q ‚äÜK ‚ääC with C/K purely
transcendental.
6.52 If E = k(X) is an extension of a Ô¨Åeld k, and if every pair u, v ‚ààX is algebraically dependent,
prove that tr. deg(E/k) ‚â§1. Conclude that if
k ‚äÜk1 ‚äÜk2 ‚äÜ¬∑ ¬∑ ¬∑
is a tower of Ô¨Åelds with tr. deg(kn/k) = 1 for all n ‚â•1, then tr. deg(k‚àó/k) = 1, where
k‚àó= !
n‚â•1 kn.
6.53 Prove that if k is the prime Ô¨Åeld of a Ô¨Åeld E and if tr. deg(E/k) ‚â§‚Ñµ0, then E is countable.
6.54 Prove that two algebraically closed Ô¨Åelds of the same characteristic are isomorphic if and only
if they have the same transcendence degree over their prime Ô¨Åelds.
Hint. Use Lemma 6.61.
6.55
(i) If k ‚äÜB ‚äÜE is a tower of Ô¨Åelds, prove that
tr. deg(E/k) = tr. deg(E/B) + tr. deg(B/k).
Hint. Prove that if X is a transcendence basis of B/k and Y is a transcendence basis of
E/B, then X ‚à™Y is a transcendence basis for E/k.
(ii) Let E/k be a Ô¨Åeld extension, and let B and C be intermediate Ô¨Åelds. Prove that
tr. deg(B ‚à®C) + tr. deg(B ‚à©C) = tr. deg(B) + tr. deg((C),
where B ‚à®C is the compositum.
Hint.
Extend a transcendence basis of B ‚à©C to a transcendence basis of B and to a
transcendence basis of C.
6.56 Prove that œï ‚ààk(x) has degree 1 if and only if œï is a linear fractional transformation.
6.57 Prove, for any Ô¨Åeld k, that PGL(2, k) ‚àº= LF(k), where PGL(2, k) = GL(2, k)/Z(2, k) and
Z(2, k) is the (normal) subgroup of GL(2, k) consisting of all the (nonzero) scalar matrices
[Z(2, k) is the center of GL(2, k)].
6.58 Prove that if E/k is an algebraic extension and Œ≤ ‚ààE is both separable and purely inseparable,
then Œ≤ ‚ààk.
6.59 Give an example of two intermediate Ô¨Åelds A and B of an extension E/k with A ‚à©B = k but
that are not linearly disjoint in the sense of the deÔ¨Ånition on page 372.

376
Commutative Rings II
Ch. 6
6.5 VARIETIES
Analytic geometry gives pictures of equations.
For example, we picture a function
f : R ‚ÜíR as its graph, which consists of all the ordered pairs (a, f (a)) in the plane;
that is, f is the set of all the solutions (a, b) ‚ààR2 of
g(x, y) = y ‚àíf (x) = 0.
We can also picture equations that are not graphs of functions. For example, the set of all
the zeros of the polynomial
h(x, y) = x2 + y2 ‚àí1
is the unit circle. We can also picture simultaneous solutions in R2 of several polyno-
mials of two variables, and, indeed, we can picture simultaneous solutions in Rn of sev-
eral polynomials of n variables. But there is a very strong connection between the rings
k[x1, . . . , xn] = k[X] and the geometry of subsets of kn going far beyond this. Given a set
of polynomials f1(X), . . . , ft(X) in n variables, call the subset V ‚äÜkn consisting of their
common zeros a variety. Of course, we can study varieties because solutions of systems
of polynomial equations (an obvious generalization of systems of linear equations) are in-
trinsically interesting. On the other hand, some systems are more interesting than others;
investigating a problem may lead to a variety, and understanding the variety and its prop-
erties (e.g., irreducibility, dimension, genus, singularities, and so forth) may contribute
to an understanding of the original problem. For example, Leibniz raised the question
of determining those functions that could be integrated explicitly in terms of "elementary
functions:" algebraic combinations of polynomials, trigonometric and inverse trigonomet-
ric functions, exponentials, and logarithms. In 1694, John Bernoulli conjectured that the
integral arising from the arclength of an ellipse could not be so integrated. Similar integrals
arise in Ô¨Ånding periods of pendulums, as well as in other problems in mechanics, and all
of them can be reduced to the form
2 x
0
dt
‚àöp(t),
where p(t) is either a cubic or quartic polynomial; that is, the polynomial y2 ‚àíp(x) in
R[x, y] has arisen. In analogy to
sin‚àí1 x =
2 x
0
dt
‚àö
1 ‚àít2 ,
Jacobi introduced the inverse function
u‚àí1(x) =
2 x
0
dt
‚àöp(t),
and he called u(x) an elliptic function. Just as sin x determines the unit circle via the
parametrization (sin x, cos x), so, too, does an elliptic function determine a curve via the

Sec. 6.5
Varieties
377
parametrization (u(x), u‚Ä≤(x)), where u‚Ä≤(x) is the derivative of u(x). It was also noted that
elliptic functions are periodic (as is sin x); that is, there is some number q with u(x+mq) =
u(x) for all real x and all m ‚ààZ. With the development of integration of functions of a
complex variable, Gauss viewed elliptic functions as
u‚àí1(z) =
2 z
0
dw
‚àöp(w),
where p(w) is either a cubic or quartic polynomial in C[w]; that is, the polynomial
u2 ‚àíp(z) in C[z, u] has arisen. In viewing elliptic functions in this way, he saw that
they are doubly periodic; that is, there are (complex) numbers q and r so that
u(z + mq + nr) = u(z)
for all complex z and all m, n ‚ààZ. Moreover, u(z) determines a complex curve (called an
elliptic curve) consisting of all (u(z), u‚Ä≤(z)). A one-dimensional complex space is a two-
dimensional real space, and double periodicity says that this complex curve is a torus; that
is, the surface of a doughnut, possibly having several holes. One consequence is that the
behavior of an elliptic function depends on whether the associated curve is nonsingular;
that is, whether it has an appropriate tangent space at every point. The subject was further
enriched when Riemann introduced Riemann surfaces into the study of elliptic functions
and elliptic curves. This is the beginning of a very rich subject10; indeed, further deep
investigations of such matters were essential in A. Wiles's proof of Fermat's last theorem,
in which he proves elliptic curves have certain sophisticated properties. More generally,
the interplay between k[x1, . . . , xn] and varieties has evolved into what is nowadays called
algebraic geometry, and this section may be regarded as an introduction to this subject.
Notation.
Let k be a Ô¨Åeld and let kn denote the set of all n-tuples
kn =

a = (a1, . . . , an): ai ‚ààk for all i

.
The polynomial ring k[x1, . . . , xn] in several variables may be denoted by k[X], where X
is the abbreviation
X = (x1, . . . , xn).
In particular, f (X) ‚ààk[X] may abbreviate f (x1, . . . , xn) ‚ààk[x1, . . . , xn].
In what follows, we regard polynomials f (x1, . . . , xn) ‚ààk[x1, . . . , xn] as functions of
n variables kn ‚Üík. Here is the precise deÔ¨Ånition.
DeÔ¨Ånition.
If f (X) ‚ààk[X] deÔ¨Åne its polynomial function f ‚ô≠: kn ‚Üík by evaluation:
If (a1, . . . , an) ‚ààkn, then
f ‚ô≠: (a1, . . . , an) ‚Üíf (a1, . . . , an).
The next proposition generalizes Corollary 3.28 from one variable to several variables.
10For a leisurely and more detailed account of the development of elliptic functions, see Chapters 14 and 15 of
Stillwell, Mathematics and Its History.

378
Commutative Rings II
Ch. 6
Proposition 6.89.
Let k be an inÔ¨Ånite Ô¨Åeld and let k[X] = k[x1, . . . , xn]. If f (X), g(X) ‚àà
k[X] satisfy f ‚ô≠= g‚ô≠, then f (x1, . . . , xn) = g(x1, . . . , xn).
Proof.
The proof is by induction on n ‚â•1; the base step is Corollary 3.28. For the
inductive step, write
f (X, y) =

i
pi(X)yi
and
g(X, y) =

i
qi(X)yi,
where X denotes (x1, . . . , xn). If f ‚ô≠= g‚ô≠, then we have f (a, Œ≤) = g(a, Œ≤) for every
a ‚ààkn and every Œ≤ ‚ààk. For Ô¨Åxed a ‚ààkn, deÔ¨Åne Fa(y) = 
i pi(a)yi and Ga(y) =

i qi(a)yi. Since both Fa(y) and Ga(y) are in k[y], the base step gives pi(a) = qi(a) for
all a ‚ààkn. By the inductive hypothesis, pi(X) = qi(X) for all i, and hence
f (X, y) =

i
pi(X)yi =

i
qi(X)yi = g(X, y),
as desired.
‚Ä¢
As a consequence of this last proposition, we drop the f ‚ô≠notation and identify polyno-
mials with their polynomial functions when k is inÔ¨Ånite.
DeÔ¨Ånition.
If f (X) ‚ààk[X] = k[x1, . . . , xn] and f (a) = 0, where a ‚ààkn, then a is
called a zero of f (X). [If f (x) is a polynomial in one variable, then a zero of f (x) is also
called a root of f (x).]
Proposition 6.90.
If k is an algebraically closed Ô¨Åeld and f (X) ‚ààk[X] is not a constant,
then f (X) has a zero.
Proof.
We prove the result by induction on n ‚â•1, where X = (x1, . . . , xn). The base
step follows at once from our assuming that k1 = k is algebraically closed. As in the
previous proof, write
f (X, y) =

i
gi(X)yi.
For each a ‚ààkn, deÔ¨Åne fa(y) = 
i gi(a)yi. If f (X, y) has no zeros, then each fa(y) ‚àà
k[y] has no zeros, and the base step says that fa(y) is a nonzero constant for all a ‚àà
kn. Thus, gi(a) = 0 for all i > 0 and all a ‚ààkn. By Proposition 6.89, which applies
because algebraically closed Ô¨Åelds are inÔ¨Ånite, gi(X) = 0 for all i > 0, and so f (X, y) =
g0(X)y0 = g0(X). By the inductive hypothesis, g0(X) is a nonzero constant, and the proof
is complete.
‚Ä¢
We now give some general deÔ¨Ånitions describing solution sets of polynomials.

Sec. 6.5
Varieties
379
DeÔ¨Ånition.
If F is a subset of k[X] = k[x1, . . . , xn], then the variety 11,12 deÔ¨Åned by F
is
Var(F) = {a ‚ààkn : f (a) = 0 for every f (X) ‚ààF};
thus, Var(F) consists of all those a ‚ààkn which are zeros of every f (X) ‚ààF.
Example 6.91.
(i) If k is algebraically closed, then Proposition 6.90 says that if f (X) ‚ààk[X] is not
constant, then Var( f (X)) Ã∏= ‚àÖ.
(ii) Here are some varieties deÔ¨Åned by two equations:
Var(x, y) = {(a, b) ‚ààk2 : x = 0 and y = 0} = {(0, 0)}
and
Var(xy) = x-axis ‚à™y-axis.
(iii) Here is an example in higher-dimensional space. Let A be an m√ón matrix with entries
in k. A system of m equations in n unknowns,
AX = B,
where B is an n √ó 1 column matrix, deÔ¨Ånes a variety, Var(AX = B), which is a subset of
kn. Of course, AX = B is really shorthand for a set of m linear equations in n variables,
and Var(AX = B) is usually called the solution set of the system AX = B; when this
system is homogeneous, that is, when B = 0, then Var(AX = 0) is a subspace of kn,
called the solution space of the system.
‚óÄ
The next result shows that, as far as varieties are concerned, we may just as well assume
that the subsets F of k[X] are ideals of k[X].
11There is some disagreement about the usage of this term. Some call this an afÔ¨Åne variety, in contrast to the
analogous projective variety. Some insist that varieties should be irreducible, which we will deÔ¨Åne later in this
section.
12The term variety arose as a translation by E. Beltrami (inspired by Gauss) of the German term Mannig-
faltigkeit used by Riemann; nowadays, this term is usually translated as manifold. The following correspondence,
from Aldo Brigaglia to Steven Kleiman, contains more details.
"I believe the usage of the word variet`a by Italian geometers arose from the (unpublished) Italian translation
of Riemann's Habilitationsvortrag, which was later translated into French by J. Ho¬®uel and published in the Italian
journal Annali. Indeed, Beltrami wrote to Ho¬®uel on 8 January, 1869:
J'ai traduit Mannigfaltigkeit par variet`a, dans le sens de multitudo variarum rerum...
And later, on 14 February, 1869, he wrote
Je croirais toujours convenable de traduire Mannigfaltigkeit par vari¬¥et¬¥e: j'ai remarqu¬¥e que Gauss,
dans ses M¬¥emoires sur les r¬¥esidus biquadratiques appelle en latin varietas la mÀÜeme chose qui, dans
les comptes-rendus r¬¥edig¬¥es par lui mÀÜeme en allemand dans les Gelehrte Anzeige, est d¬¥esign¬¥ee par
Mannigfaltigkeit.
The correspondence of Beltrami and Ho¬®uel can be found in the beautiful book La d¬¥ecouverte de la g¬¥eom¬¥etrie non
euclidienne sur la pseudosph`ere: les lettres d'Eugenio Beltrami `a Jules Ho¬®uel (1868-1881), edited by L. Boi, L.
Giacardi, and R. Tazzioli, and published by Blanchard, Paris, 1998."

380
Commutative Rings II
Ch. 6
Proposition 6.92.
Let k be a Ô¨Åeld, and let F and G be subsets of k[X].
(i) If F ‚äÜG ‚äÜk[X], then Var(G) ‚äÜVar(F).
(ii) If F ‚äÜk[X] and I = (F) is the ideal generated by F, then
Var(F) = Var(I).
Proof.
(i) If a ‚ààVar(G), then g(a) = 0 for all g(X) ‚ààG; since F ‚äÜG, it follows, in
particular, that f (a) = 0 for all f (X) ‚ààF.
(ii) Since F ‚äÜ(F) = I, we have Var(I) ‚äÜVar(F), by part (i). For the reverse inclusion,
let a ‚ààVar(F), so that f (a) = 0 for every f (X) ‚ààF. If g(X) ‚ààI, then g(X) =

i ri(X) fi(X), where ri(X) ‚ààk[X] and fi(X) ‚ààF; hence, g(a) = 
i ri(a) fi(a) = 0
and a ‚ààVar(I).
‚Ä¢
It follows that not every subset of kn is a variety. For example, if n = 1, then k[x] is a
PID. Hence, if F is a subset of k[x], then (F) = (g(x)) for some g(x) ‚ààk[x], and so
Var(F) = Var((F)) = Var((g(x))) = Var(g(x)).
But if g(x) Ã∏= 0, then it has only a Ô¨Ånite number of roots, and so Var(F) is Ô¨Ånite. If k
is algebraically closed, then it is an inÔ¨Ånite Ô¨Åeld, and so most subsets of k1 = k are not
varieties.
In spite of our wanting to draw pictures in the plane, there is a major defect with k = R:
Some polynomials have no zeros. For example, f (x) = x2 + 1 has no real roots, and so
Var(x2 + 1) = ‚àÖ. More generally, g(x1, . . . , xn) = x2
1 + ¬∑ ¬∑ ¬∑ + x2
n + 1 has no zeros in Rn,
and so Var(g(X)) = ‚àÖ. Since we are dealing with (not necessarily linear) polynomials, it
is a natural assumption to want all their zeros available. For polynomials in one variable,
this amounts to saying that k is algebraically closed and, in light of Proposition 6.90, we
know that Var( f (X)) Ã∏= ‚àÖfor every nonconstant f (X) ‚ààk[X] if k is algebraically closed.
Of course, varieties are of interest for all Ô¨Åelds k, but it makes more sense to consider the
simplest case before trying to understand more complicated problems. On the other hand,
many of the Ô¨Årst results are valid for any Ô¨Åeld k. Thus, we will state the hypothesis needed
for each proposition, but the reader should realize that the most important case is when k
is algebraically closed.
Here are some elementary properties of Var.
Proposition 6.93.
Let k be a Ô¨Åeld.
(i) Var(1) = ‚àÖand Var(0) = kn, where 0 is the zero polynomial.
(ii) If I and J are ideals in k[X], then
Var(I J) = Var(I ‚à©J) = Var(I) ‚à™Var(J),
where I J =

i fi(X)gi(X): fi(X) ‚ààI and gi(X) ‚ààJ

.

Sec. 6.5
Varieties
381
(iii) If {I‚Ñì: ‚Ñì‚ààL} is a family of ideals in k[X], then
Var

‚Ñì
I‚Ñì

=
"
‚Ñì
Var(I‚Ñì),
where 
‚ÑìI‚Ñìis the set of all Ô¨Ånite sums of the form r‚Ñì1 + ¬∑ ¬∑ ¬∑ + r‚Ñìq with r‚Ñìi ‚ààI‚Ñìi .
Proof.
(i) That Var(1) = ‚àÖis clear, for the constant polynomial 1 has no zeros. That
Var(0) = kn is clear, for every point a is a zero of the zero polynomial.
(ii) Since I J ‚äÜI ‚à©J, it follows that Var(I J) ‚äáVar(I ‚à©J); since I J ‚äÜI, it follows that
Var(I J) ‚äáVar(I). Hence,
Var(I J) ‚äáVar(I ‚à©J) ‚äáVar(I) ‚à™Var(J).
To complete the proof, it sufÔ¨Åces to show that Var(I J) ‚äÜVar(I) ‚à™Var(J). If a /‚àà
Var(I) ‚à™Var(J), then there exist f (X) ‚ààI and g(X) ‚ààJ with f (a) Ã∏= 0 and g(a) Ã∏= 0.
But f (X)g(X) ‚ààI J and ( f g)(a) = f (a)g(a) Ã∏= 0, because k is a domain. Therefore,
a /‚ààVar(I J), as desired.
(iii) For each ‚Ñì, the inclusion I‚Ñì‚äÜ
‚ÑìI‚Ñìgives Var

‚ÑìI‚Ñì

‚äÜVar(I‚Ñì), and so
Var

‚Ñì
I‚Ñì

‚äÜ
"
‚Ñì
Var(I‚Ñì).
For the reverse inclusion, if g(X) ‚àà
‚ÑìI‚Ñì, then there are Ô¨Ånitely many ‚Ñìwith g(X) =

‚Ñìf‚Ñì, where f‚Ñì(X) ‚ààI‚Ñì. Therefore, if a ‚àà
‚ÑìVar(I‚Ñì), then f‚Ñì(a) = 0 for all ‚Ñì, and so
g(a) = 0; that is, a ‚ààVar

‚ÑìI‚Ñì

.
‚Ä¢
DeÔ¨Ånition.
A topological space is a set X together with a family F of subsets of X,
called closed sets,13 which satisfy the following axioms:
(i) ‚àÖ‚ààF and X ‚ààF;
(ii) if F1, F2 ‚ààF, then F1 ‚à™F2 ‚ààF; that is, the union of two closed sets is closed;
(iii) if {F‚Ñì: ‚Ñì‚ààL} ‚äÜF, then 
‚ÑìF‚Ñì‚ààF; that is, any intersection of closed sets is also
closed.
Proposition 6.93 shows that the family of all varieties are the closed sets that make kn
a topological space. Varieties are called Zariski closed sets, and they are very useful in
the deeper study of k[X]. The usual way of regarding R as a topological space has many
closed sets; for example, every closed interval is a closed set. In contrast, the only Zariski
closed sets in R, aside from R itself, are Ô¨Ånite.
DeÔ¨Ånition.
A hypersurface in kn is a subset of the form Var( f ) for some nonconstant
f (X) ‚ààk[X].
13We can also deÔ¨Åne a topological space by specifying its open subsets which are deÔ¨Åned as complements of
closed sets.

382
Commutative Rings II
Ch. 6
Corollary 6.94.
Every variety Var(I) in kn is the intersection of Ô¨Ånitely many hypersur-
faces.
Proof.
By the Hilbert basis theorem, there are f1(X), . . . , ft(X) ‚ààk[X] with I =
( f1, . . . , ft) = 
i( fi). By Proposition 6.93(iii), we have Var(I) = 
i Var( fi).
‚Ä¢
Given an ideal I in k[X], we have just deÔ¨Åned its variety Var(I) ‚äÜkn. We now reverse
direction: Given a subset A ‚äÜkn, we assign an ideal in k[X] to it; in particular, we assign
an ideal to every variety.
DeÔ¨Ånition.
If A ‚äÜkn, deÔ¨Åne its coordinate ring k[A] to be the commutative ring
k[A] = { f ‚ô≠|A : f (X) ‚ààk[X]}
under pointwise operations [recall that f ‚ô≠: kn ‚Üík is the polynomial function arising from
f (X)].
The polynomial f (x1, . . . , xn) = xi ‚ààk[X], when regarded as a polynomial function,
is deÔ¨Åned by
xi : (a1, . . . , an) ‚Üíai;
that is, xi picks out the ith coordinate of a point in kn. The reason for the name coordinate
ring is that if a ‚ààV , then (x1(a), . . . , xn(a)) describes a.
There is an obvious ring homomorphism res: k[X] ‚Üík[A], given by f (X) ‚Üíf ‚ô≠|A,
and the kernel of this restriction map is an ideal in k[X]. We will assume, from now on,
that all Ô¨Åelds k are inÔ¨Ånite, and so we will drop the notation f ‚ô≠.
DeÔ¨Ånition.
If A ‚äÜkn, deÔ¨Åne
Id(A) = { f (X) ‚ààk[X] = k[x1, . . . , xn]: f (a) = 0 for every a ‚ààA}.
The Hilbert basis theorem tells us that Id(A) is always a Ô¨Ånitely generated ideal.
Proposition 6.95.
If A ‚äÜkn, then there is an isomorphism
k[X]/ Id(A) ‚àº= k[A],
where k[A] is the coordinate ring of A.
Proof.
The restriction map res: k[X] ‚Üík[A] is a surjection with kernel Id(A), and so
the result follows from the Ô¨Årst isomorphism theorem. Note that two polynomials agreeing
on A lie in the same coset of Id(A).
‚Ä¢
Although the deÔ¨Ånition of Var(F) makes sense for any subset F of k[X], it is most
interesting when F is an ideal. Similarly, although the deÔ¨Ånition of Id(A) makes sense
for any subset A of kn, it is most interesting when A is a variety. After all, varieties are
comprised of solutions of (polynomial) equations, which is what we care about.

Sec. 6.5
Varieties
383
Proposition 6.96.
Let k be a Ô¨Åeld.
(i) Id(‚àÖ) = k[X] and, if k is inÔ¨Ånite, Id(kn) = {0}.
(ii) If A ‚äÜB are subsets of kn, then Id(B) ‚äÜId(A).
(iii) If {A‚Ñì: ‚Ñì‚ààL} is a family of subsets of kn, then
Id

‚Ñì
A‚Ñì

=
"
‚Ñì
Id(A‚Ñì).
Proof.
(i) By deÔ¨Ånition, f (X) ‚ààId(A) for some subset A ‚äÜkn if and only if f (a) = 0
for all a ‚ààA; hence, if f (X) /‚ààId(A), then there exists a ‚ààA with f (a) Ã∏= 0. In
particular, if A = ‚àÖ, every f (X) ‚ààk[X] must lie in Id(‚àÖ), for there are no elements
a ‚àà‚àÖ. Therefore, Id(‚àÖ) = k[X].
If f (X) ‚ààId(kn), then f ‚ô≠= 0‚ô≠, and so f (X) = 0, by Proposition 6.89, because k is
inÔ¨Ånite.
(ii) If f (X) ‚ààId(B), then f (b) = 0 for all b ‚ààB; in particular, f (a) = 0 for all a ‚ààA,
because A ‚äÜB, and so f (X) ‚ààId(A).
(iii) Since A‚Ñì‚äÜ!
‚ÑìA‚Ñì, we have Id(A‚Ñì) ‚äáId
!
‚ÑìA‚Ñì

for all ‚Ñì; hence, 
‚ÑìId(A‚Ñì) ‚äá
Id
!
‚ÑìA‚Ñì

. For the reverse inclusion, suppose that f (X) ‚àà
‚ÑìId(A‚Ñì); that is, f (a‚Ñì) = 0
for all ‚Ñìand all a‚Ñì‚ààA‚Ñì. If b ‚àà!
‚ÑìA‚Ñì, then b ‚ààA‚Ñìfor some ‚Ñì, and hence f (b) = 0;
therefore, f (X) ‚ààId
!
‚ÑìA‚Ñì

.
‚Ä¢
We would like to have a formula for Id(A‚à©B). Certainly, it is not true that Id(A‚à©B) =
Id(A) ‚à™Id(B), for the union of two ideals is almost never an ideal.
The next idea arises in characterizing those ideals of the form Id(V ) when V is a variety.
DeÔ¨Ånition.
If I is an ideal in a commutative ring R, then its radical, denoted by
‚àö
I, is
‚àö
I = {r ‚ààR : rm ‚ààI for some integer m ‚â•1}.
An ideal I is called a radical ideal 14 if
‚àö
I = I.
Exercise 6.62 on page 397 asks you to prove that
‚àö
I is an ideal. It is easy to see that
I ‚äÜ
‚àö
I, and so an ideal I is a radical ideal if and only if
‚àö
I ‚äÜI. For example, every
prime ideal P is a radical ideal, for if f n ‚ààP, then f ‚ààP. Here is an example of an ideal
that is not radical. Let b ‚ààk and let I = ((x ‚àíb)2). Now I is not a radical ideal, for
(x ‚àíb)2 ‚ààI while x ‚àíb /‚ààI.
DeÔ¨Ånition.
An element a in a commutative ring R is called nilpotent if a Ã∏= 0 and there
is some n ‚â•1 with an = 0.
Note that I is a radical ideal in a commutative ring R if and only if R/I has no nonzero
nilpotent elements. A commutative ring having no nilpotent elements is called reduced.
14This term is appropriate, for if rm ‚ààI, then its mth root r also lies in I.

384
Commutative Rings II
Ch. 6
Proposition 6.97.
If an ideal I = Id(A) for some A ‚äÜkn, then it is a radical ideal.
Hence, the coordinate ring k[A] has no nonzero nilpotent elements.
Proof.
Since I ‚äÜ
‚àö
I is always true, it sufÔ¨Åces to check the reverse inclusion. By hy-
pothesis, I = Id(A) for some A ‚äÜkn; hence, if f ‚àà
‚àö
I, then f m ‚ààId(A); that is,
f (a)m = 0 for all a ‚ààA. But the values of f (a)m lie in the Ô¨Åeld k, and so f (a)m = 0
implies f (a) = 0; that is, f ‚ààId(A) = I.
‚Ä¢
Proposition 6.98.
(i) If I and J are ideals, then
‚àö
I ‚à©J =
‚àö
I ‚à©
‚àö
J.
(ii) If I and J are radical ideals, then I ‚à©J is a radical ideal.
Proof.
(i) If f ‚àà
‚àö
I ‚à©J, then f m ‚ààI ‚à©J for some m ‚â•1. Hence, f m ‚ààI and f m ‚ààJ,
and so f ‚àà
‚àö
I and f ‚àà
‚àö
J; that is, f ‚àà
‚àö
I ‚à©
‚àö
J.
For the reverse inclusion, assume that f ‚àà
‚àö
I ‚à©
‚àö
J, so that f m ‚ààI and f q ‚ààJ. We
may assume that m ‚â•q, and so f m ‚ààI ‚à©J; that is, f ‚àà
‚àö
I ‚à©J.
(ii) If I and J are radical ideals, then I =
‚àö
I and J =
‚àö
J and
I ‚à©J ‚äÜ
‚àö
I ‚à©J =
‚àö
I ‚à©
‚àö
J = I ‚à©J.
‚Ä¢
We are now going to prove Hilbert's Nullstellensatz for C[X]. The reader will see
that the proof we will give generalizes to any uncountable algebraically closed Ô¨Åeld. The
theorem is actually true for all algebraically closed Ô¨Åelds (we shall prove it in Chapter 11),
and so the proof here does not, alas, cover the algebraic closures of the prime Ô¨Åelds, for
example, which are countable.
Lemma 6.99.
Let k be a Ô¨Åeld and let œï : k[X] ‚Üík be a surjective ring homomorphism
which Ô¨Åxes k pointwise. If J = ker œï, then Var(J) Ã∏= ‚àÖ.
Proof.
Let œï(xi) = ai ‚ààk and let a = (a1, . . . , an) ‚ààkn. If
f (X) =

Œ±1,...,Œ±n
cŒ±1,...,Œ±n xŒ±1
1 ¬∑ ¬∑ ¬∑ xŒ±n
n
‚ààk[X],
then
œï( f (X)) =

Œ±1,...,Œ±n
cŒ±1,...,Œ±nœï(x1)Œ±1 ¬∑ ¬∑ ¬∑ œï(xn)Œ±n
=

Œ±1,...,Œ±n
cŒ±1,...,Œ±naŒ±1
1 ¬∑ ¬∑ ¬∑ aŒ±n
n
= f (a1, . . . , an)
= f (a).
Hence, if f (X) ‚ààJ = ker œï, then f (a) = 0, and so a ‚ààVar(J).
‚Ä¢
The next proof will use a bit of cardinality.

Sec. 6.5
Varieties
385
Theorem 6.100 (Weak Nullstellensatz15 over C).
If f1(X), . . . , ft(X) ‚ààC[X], then
I = ( f1, . . . , ft) is a proper ideal in C[X] if and only if Var( f1, . . . , ft) Ã∏= ‚àÖ.
Remark.
The reader should note that the only properties of C used in the proof are that
it is an uncountable algebraically closed Ô¨Åeld.
‚óÄ
Proof.
It is clear that if Var(I) Ã∏= ‚àÖ, then I is a proper ideal, because Var(C[X]) = ‚àÖ.
For the converse, suppose that I is a proper ideal. By Corollary 6.40, there is a maximal
ideal M containing I, and so K = C[X]/M is a Ô¨Åeld. It is plain that the natural map
C[X] ‚ÜíC[X]/M = K carries C to itself, so that K/C is an extension Ô¨Åeld; it follows that
K is a vector space over C. Now C[X] has countable dimension, as a C-space, for a basis
consists of all the monic monomials 1, x, x2, x3, . . .. Therefore, dimC(K) is countable
(possibly Ô¨Ånite), for it is a quotient of C[X].
Suppose that K is a proper extension of C; that is, there is some t ‚ààK with t /‚ààC.
Since C is algebraically closed, t cannot be algebraic over C, and so it is transcendental.
Consider the subset B of K,
B = {1/(t ‚àíc): c ‚ààC}
(note that t ‚àíc Ã∏= 0 because t /‚ààC). The set B is uncountable, for it is indexed by the
uncountable set C. We claim that B is linearly independent over C; if so, then the fact
that dimC(K) is countable is contradicted, and we will conclude that K = C. If B is
linearly dependent, there are nonzero a1, . . . , ar ‚ààC and distinct c1, . . . , cr ‚ààC with
r
i=1 ai/(t ‚àíci) = 0. Clearing denominators, we have a polynomial h(t) ‚ààC[t]:
h(t) =

i
ai(t ‚àíc1) ¬∑ ¬∑ ¬∑ 
(t ‚àíci) ¬∑ ¬∑ ¬∑ (t ‚àícr) = 0.
Now h(c1) = a1(c1‚àíc2) ¬∑ ¬∑ ¬∑ (c1‚àícr) Ã∏= 0, so that h(t) is not the zero polynomial. But this
contradicts t being transcendental; therefore, K = C. Lemma 6.99 now applies to show
that Var(M) Ã∏= ‚àÖ. But Var(M) ‚äÜVar(I), and this completes the proof.
‚Ä¢
Consider the special case of this theorem for I = ( f (x)) ‚äÜC[x], where f (x) is not
a constant. To say that Var( f ) ‚äÜC is nonempty is to say that f (x) has a complex root.
Thus, the weak Nullstellensatz is a generalization to several variables of the fundamental
theorem of algebra.
Theorem 6.101.
If k is an (uncountable) algebraically closed Ô¨Åeld, then every maximal
ideal M in k[x1, . . . , xn] has the form
M = (x1 ‚àía1, . . . , xn ‚àían),
where a = (a1, . . . , an) ‚ààkn, and so there is a bijection between kn and the maximal
ideals in k[x1, . . . , xn].
15The German word Nullstelle means root. In the context of polynomials of several variables, we may translate
it as zero, and so Nullstellensatz means the theorem of zeros.

386
Commutative Rings II
Ch. 6
Remark.
The uncountability hypothesis will be removed in Chapter 11.
‚óÄ
Proof.
Since k[X]/M ‚àº= k, Lemma 6.99 gives Var(M) Ã∏= ‚àÖ. As in the proof of that
lemma, there are constants ai ‚ààk with xi + M = ai + M for all i, and so xi ‚àíai ‚ààM.
Therefore, there is an inclusion of ideals
(x1 ‚àía1, . . . , xn ‚àían) ‚äÜM.
But (x1 ‚àía1, . . . , xn ‚àían) is a maximal ideal, by Exercise 6.6(i) on page 325, and so
M = (x1 ‚àía1, . . . , xn ‚àían).
‚Ä¢
The following proof of Hilbert's Nullstellensatz uses the "Rabinowitch trick" of imbed-
ding a polynomial ring in n variables into a polynomial ring in n + 1 variables. Again,
uncountability is not needed, and we assume it only because our proof of the weak Null-
stellensatz uses this hypothesis.
Theorem 6.102 (Nullstellensatz).
Let k be an (uncountable) algebraically closed Ô¨Åeld.
If I is an ideal in k[X], then Id(Var(I)) =
‚àö
I. Thus, f vanishes on Var(I) if and only if
f m ‚ààI for some m ‚â•1.
Proof.
The inclusion Id(Var(I)) ‚äá
‚àö
I is obviously true, for if f m(a) = 0 for some
m ‚â•1 and all a ‚ààVar(I), then f (a) = 0 for all a, because f (a) ‚ààk.
For the converse, assume that h ‚ààId(Var(I)), where I = ( f1, . . . , ft); that is, if
fi(a) = 0 for all i, where a ‚ààkn, then h(a) = 0. We must show that some power of h lies
in I. Of course, we may assume that h is not the zero polynomial. Let us regard
k[x1, . . . , xn] ‚äÜk[x1, . . . , xn, y];
thus, every fi(x1, . . . , xn) is regarded as a polynomial in n + 1 variables that does not
depend on the last variable y. We claim that the polynomials
f1, . . . , ft, 1 ‚àíyh
in k[x1, . . . , xn, y] have no common zeros. If (a1, . . . , an, b) ‚ààkn+1 is a common zero,
then a = (a1, . . . , an) ‚ààkn is a common zero of f1, . . . , ft, and so h(a) = 0. But
now 1 ‚àíbh(a) = 1 Ã∏= 0. The weak Nullstellensatz now applies to show that the ideal
( f1, . . . , ft, 1 ‚àíyh) in k[x1, . . . , xn, y] is not a proper ideal. Therefore, there are g1, . . .,
gt+1 ‚ààk[x1, . . . , xn, y] with
1 = f1g1 + ¬∑ ¬∑ ¬∑ + ftgt + (1 ‚àíyh)gt+1.
Make the substitution y = 1/h, so that the last term involving gt+1 vanishes. Rewriting,
gi(X, y) = di
j=0 u j(X)y j, and so gi(X, h‚àí1) = di
j=0 u j(X)h‚àíj. It follows that
hdi gi(X, h‚àí1) ‚ààk[X].
Therefore, if m = max{d1, . . . , dt}, then
hm = (hmg1) f1 + ¬∑ ¬∑ ¬∑ + (hmgt) ft ‚ààI.
‚Ä¢

Sec. 6.5
Varieties
387
We continue the study of the operators Var and Id.
Proposition 6.103.
Let k be any Ô¨Åeld.
(i) For every subset F ‚äÜkn,
Var(Id(F)) ‚äáF.
(ii) For every ideal I ‚äÜk[X],
Id(Var(I)) ‚äáI.
(iii) If V is a variety of kn, then Var(Id(V )) = V .
(iv) If F is subset of kn, then F, the intersection of all those varieties that contain F, is
equal to Var(Id(F)). One calls F the Zariski closure16 of F.
(v) If V ‚äÜV ‚àó‚äÜkn are varieties, then
V ‚àó= V ‚à™V ‚àó‚àíV ,
the Zariski closure of V ‚àó‚àíV .
Proof.
(i) This result is almost a tautology. If a ‚ààF, then g(a) = 0 for all g(X) ‚ààId(F).
But every g(X) ‚ààId(F) annihilates F, by deÔ¨Ånition of Id(F), and so a ‚ààVar(Id(F)).
Therefore, Var(Id(F)) ‚äáF.
(ii) Again, we merely look at the deÔ¨Ånitions. If f (X) ‚ààI, then f (a) = 0 for all a ‚àà
Var(I); hence, f (X) is surely one of the polynomials annihilating Var(I).
(iii) If V is a variety, then V = Var(J) for some ideal J in k[X]. Now
Var(Id(Var(J))) ‚äáVar(J),
by part (i). Also, part (ii) gives Id(Var(J)) ‚äáJ, and applying Proposition 6.92(i) gives the
reverse inclusion
Var(Id(Var(J))) ‚äÜVar(J).
Therefore, Var(Id(Var(J))) = Var(J); that is, Var(Id(V )) = V .
(iv) By Proposition 6.93(iii), F = 
V ‚äáF V is a variety containing F. Since Var(Id(F))
is a variety containing F, it is one of varieties V being intersected to form F, and so F ‚äÜ
Var(Id(F)). For the reverse inclusion, it sufÔ¨Åces to prove that if V is any variety containing
F, then V ‚äáVar(Id(F)). If V ‚äáF, then Id(V ) ‚äÜId(F), and V = Var(Id(V )) ‚äá
Var(Id(F)).
(v) Since V ‚àó‚àíV ‚äÜV ‚àó, we have V ‚àó‚àíV ‚äÜV ‚àó= V ‚àó. By hypothesis, V ‚äÜV ‚àó,
and so V ‚à™V ‚àó‚àíV ‚äÜV ‚àó. For the reverse inclusion, there is an equation of subsets,
V ‚àó= V ‚à™(V ‚àó‚àíV ). Taking closures,
V ‚àó= V ‚àó= V ‚à™V ‚àó‚àíV = V ‚à™V ‚àó‚àíV ,
because V = V .
‚Ä¢
16If F is a subset of a topological space X, then its closure is deÔ¨Åned as the intersection of all the closed sets
in X that contain F.

388
Commutative Rings II
Ch. 6
Corollary 6.104.
(i) If V1 and V2 are varieties and Id(V1) = Id(V2), then V1 = V2.
(ii) Let k be an (uncountable) algebraically closed Ô¨Åeld. If I1 and I2 are radical ideals
and Var(I1) = Var(I2), then I1 = I2.
Proof.
(i) If Id(V1) = Id(V2), then Var(Id(V1)) = Var(Id(V2)); it now follows from
Proposition 6.103(iii) that V1 = V2.
(ii) If Var(I1) = Var(I2), then Id(Var(I1)) = Id(Var(I2)). By the Nullstellensatz, which
holds because k is an (uncountable) algebraically closed Ô¨Åeld, ‚àöI1 = ‚àöI2. Since I1 and
I2 are radical ideals, by hypothesis, we have I1 = I2.
‚Ä¢
Can a variety be decomposed into simpler subvarieties?
DeÔ¨Ånition.
A variety V is irreducible if it is not a union of two proper subvarieties; that
is, V Ã∏= W ‚Ä≤ ‚à™W ‚Ä≤‚Ä≤, where both W ‚Ä≤ and W ‚Ä≤‚Ä≤ are varieties that are proper subsets of V .
Proposition 6.105.
Every variety V in kn is a union of Ô¨Ånitely many irreducible subvari-
eties:
V = V1 ‚à™V2 ‚à™¬∑ ¬∑ ¬∑ ‚à™Vm.
Proof.
Call a variety W ‚ààkn good if it is irreducible or a union of Ô¨Ånitely many irre-
ducible subvarieties; otherwise, call W bad. We must show that there are no bad varieties.
If W is bad, it is not irreducible, and so W = W ‚Ä≤ ‚à™W ‚Ä≤‚Ä≤, where both W ‚Ä≤ and W ‚Ä≤‚Ä≤ are proper
subvarieties. But a union of good varieties is good, and so at least one of W ‚Ä≤ and W ‚Ä≤‚Ä≤ is
bad; say, W ‚Ä≤ is bad, and rename it W ‚Ä≤ = W1. Repeat this construction for W1 to get a bad
subvariety W2. It follows by induction that there exists a strictly descending sequence
W ‚äãW1 ‚äã¬∑ ¬∑ ¬∑ ‚äãWn ‚äã¬∑ ¬∑ ¬∑
of bad subvarieties. Since the operator Id reverses inclusions, there is a strictly increasing
chain of ideals
Id(W) ‚ääId(W1) ‚ää¬∑ ¬∑ ¬∑ ‚ääId(Wn) ‚ää¬∑ ¬∑ ¬∑
[the inclusions are strict because of Corollary 6.104(i)], and this contradicts the Hilbert
basis theorem. We conclude that every variety is good.
‚Ä¢
Irreducible varieties have a nice characterization.
Proposition 6.106.
A variety V in kn is irreducible if and only if Id(V ) is a prime ideal
in k[X]. Hence, the coordinate ring k[V ] of an irreducible variety V is a domain.
Proof.
Assume that V is an irreducible variety. It sufÔ¨Åces to show that if f1(X), f2(X) /‚àà
Id(V ), then f1(X) f2(X) /‚ààId(V ). DeÔ¨Åne, for i = 1, 2,
Wi = V ‚à©Var( fi(X)).

Sec. 6.5
Varieties
389
Note that each Wi is a subvariety of V , for it is the intersection of two varieties; moreover,
since fi(X) /‚ààId(V ), there is some ai ‚ààV with fi(ai) Ã∏= 0, and so Wi is a proper
subvariety of V . Since V is irreducible, we cannot have V = W1 ‚à™W2. Thus, there is
some b ‚ààV that is not in W1‚à™W2; that is, f1(b) Ã∏= 0 Ã∏= f2(b). Therefore, f1(b) f2(b) Ã∏= 0,
hence f1(X) f2(X) /‚ààId(V ), and so Id(V ) is a prime ideal.
Conversely, assume that Id(V ) is a prime ideal. Suppose that V = V1 ‚à™V2, where V1
and V2 are subvarieties. If V2 ‚ääV , then we must show that V = V1. Now
Id(V ) = Id(V1) ‚à©Id(V2) ‚äáId(V1) Id(V2);
the equality is given by Proposition 6.96, and the inequality is given by Exercise 6.10 on
page 325. Since Id(V ) is a prime ideal, Proposition 6.13 says that Id(V1) ‚äÜId(V ) or
Id(V2) ‚äÜId(V ). But V2 ‚ääV implies Id(V2) ‚äãId(V ), and we conclude that Id(V1) ‚äÜ
Id(V ). Now the reverse inequality Id(V1) ‚äáId(V ) holds as well, because V1 ‚äÜV , and so
Id(V1) = Id(V ). Therefore, V1 = V , by Corollary 6.104, and so V is irreducible.
‚Ä¢
We now consider whether the irreducible subvarieties in the decomposition of a variety
into a union of irreducible varieties are uniquely determined. There is one obvious way to
arrange nonuniqueness. If P ‚ääQ in k[X] are two prime ideals (for example, (x) ‚ää(x, y)
are such prime ideals in k[x, y]), then Var(Q) ‚ääVar(P); if Var(P) is a subvariety of a
variety V , say, V = Var(P) ‚à™V2 ‚à™¬∑ ¬∑ ¬∑ ‚à™Vm, then Var(Q) can be one of the Vi or it can be
left out.
DeÔ¨Ånition.
A decomposition V = V1 ‚à™¬∑ ¬∑ ¬∑ ‚à™Vm is an irredundant union if no Vi can
be omitted; that is, for all i,
V Ã∏= V1 ‚à™¬∑ ¬∑ ¬∑ ‚à™
Vi ‚à™¬∑ ¬∑ ¬∑ ‚à™Vm.
Proposition 6.107.
Every variety V is an irredundant union of irreducible subvarieties
V = V1 ‚à™¬∑ ¬∑ ¬∑ ‚à™Vm;
moreover, the irreducible subvarieties Vi are uniquely determined by V .
Proof.
By Proposition 6.105, V is a union of Ô¨Ånitely many irreducible subvarieties; say,
V = V1 ‚à™¬∑ ¬∑ ¬∑ ‚à™Vm. If m is chosen minimal, then this union must be irredundant.
We now prove uniqueness. Suppose that V = W1 ‚à™¬∑ ¬∑ ¬∑ ‚à™Ws is an irredundant union of
irreducible subvarieties. Let X = {V1, . . . , Vm} and let Y = {W1, . . . , Ws}; we shall show
that X = Y. If Vi ‚ààX, we have
Vi = Vi ‚à©V =

j
(Vi ‚à©W j).
Now Vi ‚à©W j Ã∏= ‚àÖfor some j; since Vi is irreducible, there is only one such W j. Therefore,
Vi = Vi ‚à©W j, and so Vi ‚äÜW j. The same argument applied to W j shows that there is
exactly one V‚Ñìwith W j ‚äÜV‚Ñì. Hence,
Vi ‚äÜW j ‚äÜV‚Ñì.

390
Commutative Rings II
Ch. 6
Since the union V1‚à™¬∑ ¬∑ ¬∑‚à™Vm is irredundant, we must have Vi = V‚Ñì, and so Vi = W j = V‚Ñì;
that is, Vi ‚ààY and X ‚äÜY. The reverse inclusion is proved in the same way.
‚Ä¢
DeÔ¨Ånition.
An intersection I = J1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Jm is irredundant if no Ji can be omitted;
that is, for all i,
I Ã∏= J1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Ji ‚à©¬∑ ¬∑ ¬∑ ‚à©Jm.
Corollary 6.108.
Every radical ideal J in k[X] is an irredundant intersection of prime
ideals,
J = P1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Pm;
moreover, the prime ideals Pi are uniquely determined by J.
Remark.
This corollary is generalized in Exercise 6.72 on page 399: An ideal in an
arbitrary commutative noetherian ring is a radical ideal if and only if it is an intersection
of Ô¨Ånitely many prime ideals.
‚óÄ
Proof.
Since J is a radical ideal, there is a variety V with J = Id(V ). Now V is an
irredundant union of irreducible subvarieties,
V = V1 ‚à™¬∑ ¬∑ ¬∑ ‚à™Vm,
so that
J = Id(V ) = Id(V1) ‚à©¬∑ ¬∑ ¬∑ ‚à©Id(Vm).
By Proposition 6.106, Vi irreducible implies Id(Vi) is prime, and so J is an intersection
of prime ideals. This is an irredundant intersection, for if there is ‚Ñìwith J = Id(V ) =

jÃ∏=‚ÑìId(Vj), then
V = Var(Id(V )) =

jÃ∏=‚Ñì
Var(Id(Vj)) =

jÃ∏=‚Ñì
Vj,
contradicting the given irredundancy of the union.
Uniqueness is proved similarly. If J = Id(W1) ‚à©¬∑ ¬∑ ¬∑ ‚à©Id(Ws), where each Id(Wi) is a
prime ideal (hence is a radical ideal), then each Wi is an irreducible variety. Applying Var
expresses V = Var(Id(V )) = Var(J) as an irredundant union of irreducible subvarieties,
and the uniqueness of this decomposition gives the uniqueness of the prime ideals in the
intersection.
‚Ä¢
Given an ideal I in k[x1, . . . , xn], how can we Ô¨Ånd the irreducible components Ci of
Var(I)? To ask the question another way, what are the prime ideals Pi with Ci = Var(Pi)?
The Ô¨Årst guess is that I = P1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Pr, but this is easily seen to be incorrect: There
are ideals I that are not an intersection of prime ideals. For example, in k[x], the ideal
((x ‚àí1)2) is not an intersection of prime ideals. In light of the Nullstellensatz, we can
replace the prime ideals Pi by ideals Qi with ‚àöQi = Pi, for Var(Pi) = Var(Qi). We are

Sec. 6.5
Varieties
391
led to the notion of primary ideal, deÔ¨Åned soon, and the primary decomposition theorem,
which states that every ideal in a commutative noetherian ring, not merely in k[X], is an
intersection of primary ideals.
We can now give a geometric interpretation of the colon ideal.
Proposition 6.109.
Let k be an (uncountable) algebraically closed Ô¨Åeld, and let I be a
radical ideal in k[X]. Then, for every ideal J,
Var((I : J)) = Var(I) ‚àíVar(J).
Proof.
We Ô¨Årst show that Var((I : J)) ‚äáVar(I) ‚àíVar(J). If f ‚àà(I : J), then f g ‚ààI
for all g ‚ààJ. Hence, if x ‚ààVar(I), then f (x)g(x) = 0 for all g ‚ààJ. However,
if x /‚ààVar(J), then there is g ‚ààJ with g(x) Ã∏= 0. Since k[X] is a domain, we have
f (x) = 0 for all x ‚ààVar(I) ‚àíVar(J); that is, f ‚ààId(Var(I) ‚àíVar(J)). Thus, (I : J) ‚äÜ
Id(Var(I) ‚àíVar(J)), and so
Var((I : J)) ‚äáVar(Id(Var(I) ‚àíVar(J))) = Var(I) ‚àíVar(J),
by Proposition 6.103(iv).
For the reverse inclusion, take x ‚ààVar((I : J)). Thus, if f ‚àà(I : J), then f (x) = 0;
that is,
if f g ‚ààI for all g ‚ààJ, then f (x) = 0.
Suppose now that h ‚ààId(Var(I)‚àíVar(J)). If g ‚ààJ, then hg vanishes on Var(J) (because
g does); on the other hand, hg vanishes on Var(I) ‚àíVar(J) (because h does). It follows
that hg vanishes on Var(J) ‚à™(Var(I) ‚àíVar(J)) = Var(I); hence, hg ‚àà
‚àö
I = I for
all g ‚ààJ, because I is a radical ideal, and so h ‚àà(I : J). Therefore, h(x) = 0 for all
h ‚àà(I : J), which gives x ‚ààVar(Id(Var(I)‚àíVar(J))) = Var(I) ‚àíVar(J), as desired. ‚Ä¢
DeÔ¨Ånition.
An ideal Q in a commutative ring R is primary if it is a proper ideal and if
ab ‚ààQ (where a, b ‚ààR) and b /‚ààQ, then an ‚ààQ for some n ‚â•1.
It is clear that every prime ideal is primary. Moreover, in Z, the ideal (pe), where p is
prime and e ‚â•2, is a primary ideal that is not a prime ideal. Example 6.114 shows that
this example is misleading: There are primary ideals that are not powers of prime ideals;
there are powers of prime ideals which are not primary ideals.
Proposition 6.110.
If Q is a primary ideal, then its radical P = ‚àöQ is a prime ideal.
Moreover, if Q is primary, then ab ‚ààQ and a /‚ààQ implies b ‚ààP.
Proof.
Assume that ab ‚àà‚àöQ, so that (ab)m = ambm ‚ààQ for some m ‚â•1. If a /‚àà‚àöQ,
then am /‚ààQ. Since Q is primary, it follows that some power of bm, say, bmn ‚ààQ; that is,
b ‚àà‚àöQ. We have proved that ‚àöQ is prime, as well as the second statement.
‚Ä¢
If Q is primary and P = ‚àöQ, then we often call Q a P-primary ideal, and we say that
Q and P belong to each other.
We now prove that the properties in Proposition 6.110 characterize primary ideals.

392
Commutative Rings II
Ch. 6
Proposition 6.111.
Let J and T be ideals in a commutative ring.
If (i) J ‚äÜT ,
(ii) t ‚ààT implies there is some m ‚â•1 with tm ‚ààJ, and (iii) if ab ‚ààJ and a /‚ààJ,
then b ‚ààT , then J is a primary ideal with radical T .
Proof.
First, J is a primary ideal, for if ab ‚ààJ and a /‚ààJ, then axiom (iii) gives b ‚ààT ,
and axiom (ii) gives bm ‚ààJ. It remains to prove that T =
‚àö
J. Now axiom (ii) gives
T ‚äÜ
‚àö
J. For the reverse inclusion, if r ‚àà
‚àö
J, then rm ‚ààJ; choose m minimal. If m = 1,
then axiom (i) gives r ‚ààJ ‚äÜT , as desired. If m > 1, then rrm‚àí1 ‚ààJ; since rm‚àí1 /‚ààJ,
axiom (iii) gives r ‚ààT . Therefore, T =
‚àö
J.
‚Ä¢
Let R be a commutative ring, and let M be an ideal. Each a ‚ààR deÔ¨Ånes an R-map
aM : M ‚ÜíM by aM : m ‚Üíam.
Lemma 6.112.
Let Q be an ideal in a commutative ring R. Then Q is a primary ideal if
and only if, for each a ‚ààR, the map aR/Q : R/Q ‚ÜíR/Q, given by r + Q ‚Üíar + Q, is
either an injection or is nilpotent [(aR/Q)n = 0 for some n ‚â•1].
Proof.
Assume that Q is primary. If a ‚ààR and aR/Q is not an injection, then there is
b ‚ààR with b /‚ààQ and aR/Q(b + Q) = ab + Q = Q; that is, ab ‚ààQ. We must prove that
aR/Q is nilpotent. Since Q is primary, there is n ‚â•1 with an ‚ààQ; hence, anr ‚ààQ for all
r ‚ààR, because Q is an ideal. Thus, (aR/Q)n(r + Q) = anr + Q = Q for all r ‚ààR, and
(aR/Q)n = 0; that is, aR/Q is nilpotent.
Conversely, assume that every aR/Q is either injective or nilpotent. Suppose that ab ‚ààQ
and a /‚ààQ. Then bR/Q is not injective, for a + Q ‚ààker bR/Q. By hypothesis, (bR/Q)n = 0
for some n ‚â•1; that is, bnr ‚ààQ for all r ‚ààR. Setting r = 1 gives bn ‚ààQ, and so Q is
primary.
‚Ä¢
The next result gives a way of constructing primary ideals.
Proposition 6.113.
If P is a maximal ideal in a commutative ring R, and if Q is an ideal
with Pe ‚äÜQ ‚äÜP for some e ‚â•0, then Q is a P-primary ideal. In particular, every
power of a maximal ideal is primary.
Proof.
We show, for each a ‚ààR, that aR/Q is either nilpotent or injective. Suppose Ô¨Årst
that a ‚ààP. In this case, ae ‚ààPe ‚äÜQ; hence, aeb ‚ààQ for all b ‚ààR, and so (aR/Q)e = 0;
that is, aR/Q is nilpotent. Now assume that a /‚ààP; we are going to show that a + Q is
a unit in R/Q, which implies that aR/Q is injective. Since P is a maximal ideal, the ring
R/P is a Ô¨Åeld; since a /‚ààP, the element a + P is a unit in R/P: there is a‚Ä≤ ‚ààR and z ‚ààP
with aa‚Ä≤ = 1 ‚àíz. Now z + Q is a nilpotent element of R/Q, for ze ‚ààPe ‚äÜQ. Thus,
1‚àíz + Q is a unit in R/Q (its inverse is 1 + z +¬∑ ¬∑ ¬∑ + ze‚àí1). It follows that a + Q is a unit
in R/Q, for aa‚Ä≤ + Q = 1 ‚àíz + Q. The result now follows from Lemma 6.112. Finally, Q
belongs to P, for P =
‚àö
Pe ‚äÜ‚àöQ ‚äÜ
‚àö
P = P.
‚Ä¢
Example 6.114.
(i) We now show that a power of a prime ideal need not be primary. Suppose that R is a
commutative ring containing elements a, b, c such that ab = c2, P = (a, c) is a prime

Sec. 6.5
Varieties
393
ideal, a /‚ààP2, and b /‚ààP. Now ab = c2 ‚ààP2; were P2 primary, then a /‚ààP2 would
imply that b ‚àà
‚àö
P2 = P, and this is not so. We construct such a ring R as follows.
Let k be a Ô¨Åeld, and deÔ¨Åne R = k[x, y, z]/(xy ‚àíz2) (note that R is noetherian). DeÔ¨Åne
a, b, c ‚ààR to be the cosets of x, y, z, respectively. Now P = (a, c) is a prime ideal, for
the third isomorphism theorem for rings, Exercise 3.82 on page 196, gives
R/(a, c) = k[x, y, z]/(xy ‚àíz2)
(x, z)/(xy ‚àíz2)
‚àº= k[x, y, z]
(x, z)
‚àº= k[y],
which is a domain. The equation ab = c2 obviously holds in R. Were a ‚ààP2, then lifting
this relation to k[x, y, z] would yield an equation
x = f (x, y, z)x2 + g(x, y, z)xz + h(x, y, z)z2 + ‚Ñì(x, y, z)(xy ‚àíz2).
Setting y = 0 = z (i.e., using the evaluation homomorphism k[x, y, z] ‚Üík[x]) gives the
equation x = f (x, 0, 0)x2 in k[x], a contradiction. A similar argument shows that b /‚ààP.
(ii) We use Proposition 6.113 to show that there are primary ideals Q that are not powers
of prime ideals. Let R = k[x, y], where k is a Ô¨Åeld. The ideal P = (x, y) is maximal,
hence prime (for R/P ‚àº= k); moreover,
P2 ‚ää(x2, y) ‚ää(x, y) = P
[the strict inequalities follow from x /‚àà(x2, y) and y /‚ààP2]. Thus, Q = (x2, y) is not a
power of P; indeed, we show that Q Ã∏= Le, where L is a prime ideal. If Q = Le, then
P2 ‚äÜLe ‚äÜP, hence
‚àö
P2 ‚äÜ
‚àö
Le ‚äÜ
‚àö
P, and so P ‚äÜL ‚äÜP, a contradiction.
‚óÄ
We now generalize Corollary 6.108 by proving that every ideal in a noetherian ring, in
particular, in k[X] for k a Ô¨Åeld, is an intersection of primary ideals. This result, along with
uniqueness properties, was Ô¨Årst proved by E. Lasker; his proof was later simpliÔ¨Åed by E.
Noether. Note that we will be working in arbitrary noetherian rings, not merely in k[X].
DeÔ¨Ånition.
A primary decomposition of an ideal I in a commutative ring R is a Ô¨Ånite
family of primary ideals Q1, . . . , Qr with
I = Q1 ‚à©Q2 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr.
Theorem 6.115 (Lasker-Noether I).
If R is a commutative noetherian ring, then every
proper ideal I in R has a primary decomposition.
Proof.
Let F be the family of all those proper ideals in R that do not have a primary
decomposition; we must show that F is empty. Since R is noetherian, if F Ã∏= ‚àÖ, then it
has a maximal element, say, J. Of course, J is not primary, and so there exists a ‚ààR with
aR/J : R/J ‚ÜíR/J neither injective nor nilpotent. The ascending chain of ideals of R/J,
ker aR/J ‚äÜker (aR/J)2 ‚äÜker (aR/J)3 ‚äÜ¬∑ ¬∑ ¬∑ ,

394
Commutative Rings II
Ch. 6
must stop (because R/J, being a quotient of the noetherian ring R, is itself noetherian);
there is m ‚â•1 with ker(a‚Ñì
R/J) = ker(am
R/J) for all ‚Ñì‚â•m. Denote (aR/J)m by œï, so that
ker(œï2) = ker œï. Note that ker œï Ã∏= {0}, because {0} ‚ääker aR/J ‚äÜker(aR/J)m = ker œï,
and that im œï = im(aR/J)m Ã∏= {0}, because aR/J is not nilpotent. We claim that
ker œï ‚à©im œï = {0}.
If x ‚ààker œï ‚à©im œï, then œï(x) = 0 and x = œï(y) for some y ‚ààR/J. But œï(x) =
œï(œï(y)) = œï2(y), so that y ‚ààker(œï2) = ker œï and x = œï(y) = 0.
If œÄ : R ‚ÜíR/J is the natural map, then A = œÄ‚àí1(ker œï) and A‚Ä≤ = œÄ‚àí1(im œï) are
ideals of R with A ‚à©A‚Ä≤ = J. It is obvious that A is a proper ideal; we claim that A‚Ä≤ is
also proper. Otherwise, A‚Ä≤ = R, so that A ‚à©A‚Ä≤ = A; but A ‚à©A‚Ä≤ = J, as we saw above,
and A Ã∏= J, a contradiction. Since A and A‚Ä≤ are strictly larger than J, neither of them lies
in F: There are primary decompositions A = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qm and A‚Ä≤ = Q‚Ä≤
1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Q‚Ä≤
n.
Therefore,
J = A ‚à©A‚Ä≤ = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qm ‚à©Q‚Ä≤
1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Q‚Ä≤
n,
contradicting J not having a primary decomposition (for J ‚ààF).
‚Ä¢
DeÔ¨Ånition.
A primary decomposition I = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr is irredundant if no Qi can
be omitted; for all i,
I Ã∏= Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©3
Qi ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr.
The prime ideals P1 = ‚àöQ1, . . . , Pr = ‚àöQr are called the associated prime ideals of the
irredundant primary decomposition.
It is clear that any primary decomposition can be made irredundant by throwing away,
one at a time, any primary ideals that contain the intersection of the others.
Theorem 6.116 (Lasker-Noether II).
If I is an ideal in a noetherian ring R, then any
two irredundant primary decompositions of I have the same set of associated prime ideals.
Hence, the associated prime ideals are uniquely determined by I.
Proof.
Let I = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr be an irredundant primary decomposition, and let Pi =
‚àöQi. We are going to prove that a prime ideal P in R is equal to some Pi if and only if
there is c /‚ààI with (I : c) a P-primary ideal; this will sufÔ¨Åce, for the colon ideal (I : c) is
deÔ¨Åned solely in terms of I and not in terms of any primary decomposition.
Given Pi, there exists c ‚àà
jÃ∏=i Q j with c /‚ààQi, because of irredundancy; we show
that (I : ci) is Pi-primary. Recall Proposition 6.111: If the following three conditions
hold: (i) (I : c) ‚äÜPi; (ii) b ‚ààPi implies there is some m ‚â•1 with bm ‚àà(I : c); and (iii)
if ab ‚àà(I : c) and a /‚àà(I : c), then b ‚ààPi and (I : c) is Pi-primary.
To see (i), if u ‚àà(I : c), then uc ‚ààI ‚äÜPi. As c /‚ààQi, we have u ‚ààPi, by
Proposition 6.110. To prove (ii), we Ô¨Årst show that Qi ‚äÜ(I : c). If a ‚ààQi, then
ca ‚ààQi, since Qi is an ideal. If j Ã∏= i, then c ‚ààQ j, and so ca ‚ààQ j. Therefore,

Sec. 6.5
Varieties
395
ca ‚ààQ1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr = I, and so a ‚àà(I : c). If, now, b ‚ààPi, then bm ‚ààQi ‚äÜ(I : c).
Finally, we establish (iii) by proving its contrapositive: If xy ‚àà(I : c) and x /‚ààPi, then
y ‚àà(I : c). Thus, assume that xyc ‚ààI; since I ‚äÜQi and x /‚ààPi = ‚àöQi, we have
yc ‚ààQi. But yc ‚ààQ j for all j Ã∏= i, for c ‚ààQ j. Therefore, yc ‚ààQ1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr = I, and
so y ‚àà(I : c). We conclude that (I : c) is Pi-primary.
Conversely, assume that there is an element c /‚ààI and a prime ideal P such that (I : c)
is P-primary. We must show that P = Pi for some i. Exercise 6.14(ii) on page 326 gives
(I : c) = (Q1 : c) ‚à©¬∑ ¬∑ ¬∑ ‚à©(Qr : c). Therefore, by Proposition 6.98,
P =

(I : c) =

(Q1 : c) ‚à©¬∑ ¬∑ ¬∑ ‚à©

(Qr : c).
If c ‚ààQi, then (Qi : c) = R; if c /‚ààQi, then we saw, in Ô¨Årst part of this proof, that
(Qi : c) is Pi-primary. Thus, there is s ‚â§r with
P =

(Qi1 : c) ‚à©¬∑ ¬∑ ¬∑ ‚à©

(Qis : c) = Pi1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Pis.
Of course, P ‚äÜPi j for all j. On the other hand, Exercise 6.10(iii) on page 325 gives
Pi j ‚äÜP for some j, and so P = Pi j , as desired.
‚Ä¢
Example 6.117.
(i) Let R = Z, let (n) be a nonzero proper ideal, and let n = pe1
1 ¬∑ ¬∑ ¬∑ pet
t
be the prime
factorization. Then
(n) = (pe1
1 ) ‚à©¬∑ ¬∑ ¬∑ ‚à©(pet
t )
is an irredundant primary decomposition.
(ii) Let R = k[x, y], where k is a Ô¨Åeld. DeÔ¨Åne Q1 = (x) and Q2 = (x, y)2. Note that Q1
is prime, and hence Q1 is P1-primary for P1 = Q1. Also, P2 = (x, y) is a maximal ideal,
and so Q2 = P2
2 is P2-primary, by Proposition 6.113. DeÔ¨Åne I = Q1 ‚à©Q2. This primary
decompostion of I is irredundant. The associated primes of I are thus {P1, P2}.
‚óÄ
There is a second uniqueness result that describes a normalized primary decomposition,
but we precede it by a lemma.
Lemma 6.118.
If P is a prime ideal and Q1, . . . , Qn are P-primary ideals, then
Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qn is also a P-primary ideal.
Proof.
We verify that the three items in the hypothesis of Proposition 6.111 hold for
I = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qn. Clearly, I ‚äÜP. Second, if b ‚ààP, then bmi ‚ààQi for all i, because Qi
is P-primary. Hence, bm ‚ààI, where m = max{m1, . . . , mn}. Finally, assume that ab ‚ààI.
If a /‚ààI, then a /‚ààQi for some i. As Qi is P-primary, ab ‚ààI ‚äÜQi and a /‚ààQi imply
b ‚ààP. Therefore, I is P-primary.
‚Ä¢
DeÔ¨Ånition.
A primary decomposition I = Q1 ‚à©. . . ‚à©Qr is normal if it is irredundant
and if all the prime ideals Pi = ‚àöQi are distinct.

396
Commutative Rings II
Ch. 6
Corollary 6.119.
If R is a noetherian ring, then every proper ideal in R has a normal
primary decomposition.
Proof.
By Theorem 6.115, every proper ideal I has a primary decomposition, say,
I = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr,
where Qi is Pi-primary. If Pr = Pi for some i < r, then Qi and Qr can be replaced
by Q‚Ä≤ = Qi ‚à©Qr, which is primary, by Lemma 6.118. Iterating, we eventually arrive
at a primary decomposition with all prime ideals distinct. If this decomposition is not
irredundant, remove primary ideals from it, one at a time, to obtain a normal primary
decomposition.
‚Ä¢
DeÔ¨Ånition.
If I = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr is a normal primary decomposition, then the minimal
prime ideals Pi = ‚àöQi are called isolated prime ideals; the other prime ideals, if any, are
called embedded.
In Example 6.117(ii), we gave an irredundant primary decomposition of I = (x) ‚à©
(x, y)2 in k[x, y], where k is a Ô¨Åeld. The associated primes are (x) and (x, y), so that (x)
is an isolated prime and (x, y) is an embedded prime.
DeÔ¨Ånition.
A prime ideal P is minimal over an ideal I if I ‚äÜP and there is no prime
ideal P‚Ä≤ with I ‚äÜP‚Ä≤ ‚ääP.
Corollary 6.120.
Let I be an ideal in a noetherian ring R.
(i) Any two normal primary decompositions of I have the same set of isolated prime
ideals, and so the isolated prime ideals are uniquely determined by I.
(ii) I has only Ô¨Ånitely many minimal prime ideals.
(iii) A noetherian ring has only Ô¨Ånitely many minimal prime ideals.
Proof.
(i) Let I = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qn be a normal primary decomposition. If P is any prime
ideal containing I, then
P ‚äáI = Q1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Qn ‚äáQ1 ¬∑ ¬∑ ¬∑ Qn.
Now P ‚äáQi for some i, by Proposition 6.13, and so P ‚äá‚àöQi = Pi. In other words,
any prime ideal containing I must contain an isolated associated prime ideal. Hence, the
isolated primes are the minimal elements in the set of associated primes of I; by Theo-
rem 6.116, they are uniquely determined by I.
(ii) As in part (i), any prime ideal P containing I must contain an isolated prime of I.
Hence, if P is minimal over I, then P must equal an isolated prime ideal of I. The result
follows, for I has only Ô¨Ånitely many isolated prime ideals.
(iii) This follows from part (ii) taking I = {0}.
‚Ä¢

Sec. 6.5
Varieties
397
Here are some natural problems arising as these ideas are investigated further. First,
what is the dimension of a variety? There are several candidates, and it turns out that
prime ideals are the key. If V is a variety, then its dimension is the length of a longest
chain of prime ideals in its coordinate ring k[V ] (which, by the correspondence theorem,
is the length of a longest chain of prime ideals above Id(V ) in k[X]).
It turns out to be more convenient to work in a larger projective space arising from kn by
adjoining a "hyperplane at inÔ¨Ånity." For example, a projective plane arises from the usual
plane by adjoining a line at inÔ¨Ånity (it is the "horizon" where all parallel lines meet). To
distinguish it from projective space, kn is called afÔ¨Åne space, for it consists of the "Ô¨Ånite
points"‚Äîthat is, not the points at inÔ¨Ånity. If we study varieties in projective space, now
deÔ¨Åned as zeros of a set of homogeneous polynomials, then it is often the case that many
separate afÔ¨Åne cases become part of one simpler projective formula. For example, deÔ¨Åne
the deg(C) to be the largest number of points in C ‚à©‚Ñì, where ‚Ñìis a line. If C = Var( f )
is a curve arising from a polynomial of degree d, we want deg(C) = d, but there are
several problems here. First, we must demand that the coefÔ¨Åcient Ô¨Åeld be algebraically
closed, lest Var( f ) = ‚àÖcause a problem. Second, there may be multiple roots, and so
some intersections may have to be counted with a certain multiplicity. B¬¥ezout's theorem
states that if C and C‚Ä≤ are two curves, then |C ‚à©C‚Ä≤| = deg(C) deg(C‚Ä≤). This formula
holds in projective space, but it can be false in afÔ¨Åne varieties. DeÔ¨Åning multiplicities for
intersections of higher-dimensional varieties is very subtle.
Finally, there is a deep analogy between differentiable manifolds and varieties. A man-
ifold is a subspace of Rn that is a union of open replicas of euclidean space. For example,
a torus T (i.e., a doughnut) is a subspace of R3, and each point of T has a neighborhood
looking like an open disk (which is homeomorphic to the plane). We say that T is "locally
euclidean"; it is obtained by gluing copies of R2 together in a coherent way. That a man-
ifold is differentiable says there is a tangent space at each of its points. A variety V can
be viewed as its coordinate ring k[V ], and neighborhoods of its points can be described
"locally", using what is called a sheaf of local rings. If we "glue" sheaves together along
open subsets having isomorphic sheaves of local rings, we obtain a scheme, and schemes
seem to be the best way to study varieties. Two of the most prominent mathematicians
involved in this circle of ideas are A. Grothendieck and J.-P. Serre.
EXERCISES
6.60 Prove that every algebraically closed Ô¨Åeld is inÔ¨Ånite.
6.61 Prove that if an element a in a commutative ring R is nilpotent, then 1 + a is a unit.
Hint.
The power series for 1/(1 + a) stops after a Ô¨Ånite number of terms because a is
nilpotent.
6.62 If I is an ideal in a commutative ring R, prove that its radical,
‚àö
I, is an ideal.
Hint. If f r ‚ààI and gs ‚ààI, prove that ( f + g)r+s ‚ààI.
6.63 If R is a commutative ring, then its nilradical nil(R) is deÔ¨Åned to be the intersection of all the
prime ideals in R. Prove that nil(R) is the set of all the nilpotent elements in R:
nil(R) = {r ‚ààR : rm = 0 for some m ‚â•1}.

398
Commutative Rings II
Ch. 6
Hint. If r ‚ààR is not nilpotent, use Exercise 6.9 on page 325 to show that there is some prime
ideal not containing r.
6.64
(i) Show that x2 + y2 is irreducible in R[x, y], and conclude that (x2 + y2) is a prime,
hence radical, ideal in R[x, y].
(ii) Prove that Var(x2 + y2) = {(0, 0)}.
(iii) Prove that Id(Var(x2 + y2)) ‚äã(x2 + y2), and conclude that the radical ideal (x2 + y2)
in R[x, y] is not of the form Id(V ) for some variety V . Conclude that the Nullstellensatz
may fail in k[X] if k is not algebraically closed.
(iv) Prove that (x2 + y2) = (x + iy) ‚à©(x ‚àíiy) in C[x, y].
(v) Prove that Id(Var(x2 + y2)) = (x2 + y2) in C[x, y].
6.65 Prove that if k is an (uncountable) algebraically closed Ô¨Åeld and f1, . . . , ft ‚ààk[X], then
Var( f1, . . . , ft) = ‚àÖif and only if there are h1, . . . , ht ‚ààk[X] such that
1 =
t
i=1
hi(X) fi(X).
6.66 Let k be an (uncountable) algebraically closed Ô¨Åeld, and let I = ( f1, . . . , ft) ‚äÜk[X]. If
g(X) ‚ààk[X], prove that g ‚àà
‚àö
I ‚äÜk[X] if and only if ( f1, . . . , ft, 1 ‚àíyg) is not a proper
ideal in k[X, y].
Hint. Use the Rabinowitch trick.
6.67 Let R be a commutative ring, and let Spec(R) denote the set of all the prime ideals in R. If I
is an ideal in R, deÔ¨Åne
I = {all the prime ideals in R containing I}.
Prove the following:
(i) {0} = Spec(R).
(ii) R = ‚àÖ.
(iii) 
‚ÑìI‚Ñì= 
‚ÑìI‚Ñì.
(iv) I ‚à©J = I J = I ‚à™J.
Conclude that Spec(R) is a topological space whose closed subsets are the Zariski closed sets:
those sets of of the form I, where I varies over the ideals in R.
6.68 Prove that an ideal P in Spec(R) is closed (that is, the one-point set {P} is a Zariski closed
set) if and only if P is a maximal ideal.
6.69 If X and Y are topological spaces, then a function g: X ‚ÜíY is continuous if, for each closed
subset Q of Y, the inverse image g‚àí1(Q) is a closed subset of X.
Let f : R ‚ÜíA be a ring homomorphism, and deÔ¨Åne f ‚àó: Spec(A) ‚ÜíSpec(R) by
f ‚àó(Q) = f ‚àí1(Q), where Q is any prime ideal in A. Prove that f ‚àóis a continuous func-
tion. [Recall that f ‚àí1(Q) is a prime ideal, by Exercise 6.5 on page 325.]
6.70 Prove that the function œï : kn ‚ÜíSpec(k[x1, . . . , xn]) [where k is an (uncountable) alge-
braically closed Ô¨Åeld], deÔ¨Åned by œï : (a1, . . . , an) ‚Üí(x1 ‚àía1, . . . , xn ‚àían), is a continous
injection (where both kn and Spec(k[x1, . . . , xn]) are equipped with the Zariski topology; the
Zariski topology on kn was deÔ¨Åned just after Proposition 6.93).

Sec. 6.6
Gr¬®obner Bases
399
6.71 Prove that any descending chain
F1 ‚äáF2 ‚äá¬∑ ¬∑ ¬∑ ‚äáFm ‚äáFm+1 ‚äá¬∑ ¬∑ ¬∑
of closed sets in kn stops; there is some t with Ft = Ft+1 = ¬∑ ¬∑ ¬∑ .
6.72 If R is a commutative noetherian ring, prove that an ideal I in R is a radical ideal if and only
if I = P1 ‚à©¬∑ ¬∑ ¬∑ ‚à©Pr, where the Pi are prime ideals.
6.73 Prove that there is an ideal I in a commutative ring R with I not primary and with
‚àö
I prime.
Hint. Take R = k[x, y], where k is a Ô¨Åeld, and I = (x2, xy).
6.74 Let R = k[x, y], where k is a Ô¨Åeld, and let I = (x2, y). For each a ‚ààk, prove that I =
(x) ‚à©(y + ax, x2) is an irredundant primary decomposition. Conclude that the primary ideals
in an irredundant primary decomposition of an ideal need not be unique.
6.6 GR ¬®OBNER BASES
There is a canard that classical Greek philosophers were reluctant to perform experiments,
preferring pure reason. Rather than looking in one's mouth and counting, for example, they
would speculate about how many teeth a person needs, deciding that every man should
have, say, 28 teeth. Young mathematicians also prefer pure reasoning, but they, too, should
count teeth. Computations and algorithms are useful, if for no other reason than to serve
as data from which we might conjecture theorems. In this light, consider the problem of
Ô¨Ånding the irreducible components of a variety Var(I); algebraically, this problem asks for
the associated primes of I. The primary decomposition theorem says that we should seek
primary ideals Qi containing I, and the desired components are Var(‚àöQi). In the proof
of Theorem 6.116, however, we saw that if I = Qi ‚à©¬∑ ¬∑ ¬∑ ‚à©Qr is an irredundant primary
decomposition, where Qi is Pi-primary, then Pi = ‚àö(I : ci), where ci ‚àà
jÃ∏=i Q j with
c /‚ààQi. Taking an honest look at the teeth involves the following question. Given a set
of generators of I, can we Ô¨Ånd generators of Pi explicitly? The difÔ¨Åculty lies in Ô¨Ånding
the elements ci, for we will show, in this section, how to Ô¨Ånd generators of ‚àö(I : c).
Having made this point, we must also say that algorithms can do more than provide data
in particular cases. For example, the euclidean algorithm is used in an essential way in
proving that if K/k is a Ô¨Åeld extension, and if f (x), g(x) ‚ààk[x], then their gcd in K[x] is
equal to their gcd in k[x].
Given two polynomials f (x), g(x) ‚ààk[x] with g(x) Ã∏= 0, where k is a Ô¨Åeld, when is
g(x) a divisor of f (x)? The division algorithm gives unique polynomials q(x),r(x) ‚ààk[x]
with
f (x) = q(x)g(x) + r(x),
where r = 0 or deg(r) < deg(g), and g | f if and only if the remainder r = 0. Let us look
at this formula from a different point of view. To say that g | f is to say that f ‚àà(g), the
principal ideal generated by g(x). Thus, the remainder r is the obstruction to f lying in
this ideal; that is, f ‚àà(g) if and only if r = 0.

400
Commutative Rings II
Ch. 6
Consider a more general problem. Given polynomials
f (x), g1(x), . . . , gm(x) ‚ààk[x],
where k is a Ô¨Åeld, when is d(x) = gcd{g1(x), . . . , gm(x)} a divisor of f ? The euclidean
algorithm Ô¨Ånds d, and the division algorithm determines whether d | f . From another
viewpoint, the two classical algorithms combine to give an algorithm determining whether
f ‚àà(g1, . . . , gm) = (d).
We now ask whether there is an algorithm in k[x1, . . . , xn] = k[X] to determine, given
f (X), g1(X), . . . , gm(X) ‚ààk[X], whether f ‚àà(g1, . . . , gm). A generalized division
algorithm in k[X] should be an algorithm yielding
r(X), a1(X), . . . , am(X) ‚ààk[X],
with r(X) unique, such that
f = a1g1 + ¬∑ ¬∑ ¬∑ + amgm + r
and f ‚àà(g1, . . . , gm) if and only if r = 0. Since (g1, . . . , gm) consists of all the linear
combinations of the g's, such an algorithm would say that the remainder r is the obstruction
to f lying in (g1, . . . , gm).
We are going to show that both the division algorithm and the euclidean algorithm can
be extended to polynomials in several variables. Even though these results are elementary,
they were discovered only recently, in 1965, by B. Buchberger. Algebra has always dealt
with algorithms, but the power and beauty of the axiomatic method has dominated the
subject ever since Cayley and Dedekind in the second half of the nineteenth century. After
the invention of the transistor in 1948, high-speed calculation became a reality, and old
complicated algorithms, as well as new ones, could be implemented; a higher order of
computing had entered algebra. Most likely, the development of computer science is a
major reason why generalizations of the classical algorithms, from polynomials in one
variable to polynomials in several variables, are only now being discovered. This is a
dramatic illustration of the impact of external ideas on mathematics.
Generalized Division Algorithm
The most important feature of the division algorithm in k[x] is that the remainder r(x)
has small degree. Without the inequality deg(r) < deg(g), the result would be virtually
useless; after all, given any Q(x) ‚ààk[x], there is an equation
f (x) = Q(x)g(x) + [ f (x) ‚àíQ(x)g(x)].
Now polynomials in several variables are sums of monomials cxŒ±1
1 ¬∑ ¬∑ ¬∑ xŒ±n
n , where c ‚ààk
and Œ±i ‚â•0 for all i. Here are two degrees that we can assign to a monomial.

Sec. 6.6
Gr¬®obner Bases
401
DeÔ¨Ånition.
The multidegree of a monomial cxŒ±1
1 ¬∑ ¬∑ ¬∑ xŒ±n
n
‚ààk[x1, . . . , xn], where c ‚ààk
is nonzero and Œ±i ‚â•0 for all i, is the n-tuple Œ± = (Œ±1, . . . , Œ±n); its weight is the sum
|Œ±| = Œ±1 + ¬∑ ¬∑ ¬∑ + Œ±n.
When dividing f (x) by g(x) in k[x], we usually arrange the monomials in f (x) in
descending order, according to degree:
f (x) = cnxn + cn‚àí1xn‚àí1 + ¬∑ ¬∑ ¬∑ + c2x2 + c1x + c0.
A polynomial in several variables,
f (X) = f (x1, . . . , xn) =

c(Œ±1,...,Œ±n)xŒ±1
1 ¬∑ ¬∑ ¬∑ xŒ±n
n ,
can be written more compactly as
f (X) =

Œ±
cŒ± XŒ±
if we abbreviate (Œ±1, . . . , Œ±n) to Œ± and xŒ±1
1 ¬∑ ¬∑ ¬∑ xŒ±n
n
to XŒ±. We will arrange the monomials
involved in f (X) in a reasonable way by ordering their multidegrees.
In Example 5.69(ii), we saw that N n, the set of all n-tuples Œ± = (Œ±1, . . . , Œ±n) of natural
numbers, is a monoid under addition:
Œ± + Œ≤ = (Œ±1, . . . , Œ±n) + (Œ≤1, . . . , Œ≤n) = (Œ±1 + Œ≤1, . . . , Œ±n + Œ≤n).
This monoid operation is related to the multiplication of monomials:
XŒ± XŒ≤ = XŒ±+Œ≤.
Recall that a partially ordered set is a set X equipped with a relation ‚™Øthat is reÔ¨Çexive,
antisymmetric, and transitive. Of course, we may write x ‚â∫y if x ‚™Øy and x Ã∏= y, and
we may write y ‚™∞x (or y ‚âªx) instead of x ‚™Øy (or x ‚â∫y). A partially ordered set X
is well-ordered if every nonempty subset S ‚äÜX contains a smallest element; that is, there
exists s0 ‚ààS with s0 ‚™Øs for all s ‚ààS. For example, the least integer axiom says that the
natural numbers N with the usual inequality ‚â§is well-ordered.
Proposition A.3 in the Appendix proves that every strictly decreasing sequence in a
well-ordered set must be Ô¨Ånite. This property of well-ordered sets can be used to show
that an algorithm eventually stops. For example, in the proof of the division algorithm
for polynomials in one variable, we associated a natural number to each step: the degree
of a remainder. Moreover, if the algorithm does not stop at a given step, then the natural
number associated to the next step‚Äîthe degree of its remainder‚Äîis strictly smaller. Since
the natural numbers are well-ordered by the usual inequality ‚â§, this strictly decreasing
sequence of natural numbers must be Ô¨Ånite; that is, the algorithm must stop after a Ô¨Ånite
number of steps.
We are interested in orderings of multidegrees that are compatible with multiplication
of monomials‚Äîthat is, with addition in the monoid N n.

402
Commutative Rings II
Ch. 6
DeÔ¨Ånition.
A monomial order is a well-ordering of N n such that
Œ± ‚™ØŒ≤
implies
Œ± + Œ≥ ‚™ØŒ≤ + Œ≥
for all Œ±, Œ≤, Œ≥ ‚ààN n.
A monomial order will be used as follows. If X = (x1, . . . , xn), then we deÔ¨Åne XŒ± ‚™Ø
XŒ≤ in case Œ± ‚™ØŒ≤; that is, monomials are ordered according to their multidegrees.
DeÔ¨Ånition.
If N n is equipped with a monomial order, then every f (X) ‚ààk[X] =
k[x1, . . . , xn] can be written with its largest term Ô¨Årst, followed by its other, smaller, terms
in descending order:
f (X) = cŒ± XŒ± + lower terms.
DeÔ¨Åne its leading term to be LT( f ) = cŒ± XŒ± and its Degree to be Deg( f ) = Œ±. Call
f (X) monic if LT( f ) = XŒ±; that is, if cŒ± = 1.
Note that Deg( f ) and LT( f ) depend on the monomial order.
There are many examples of monomial orders, but we shall give only the two most
popular ones.
DeÔ¨Ånition.
The lexicographic order on N n is deÔ¨Åned by Œ± ‚™Ølex Œ≤ if either Œ± = Œ≤ or the
Ô¨Årst nonzero coordinate in Œ≤ ‚àíŒ± is positive.17
The term lexicographic refers to the standard ordering of words in a dictionary. For
example, the following German words are increasing in lexicographic order (the letters are
ordered a < b < c < ¬∑ ¬∑ ¬∑ < z):
ausgehen
ausladen
auslagen
auslegen
bedeuten
If Œ± ‚â∫lex Œ≤, then they agree for the Ô¨Årst i ‚àí1 coordinates (for some i ‚â•1), that is,
Œ±1 = Œ≤1, . . . , Œ±i‚àí1 = Œ≤i‚àí1, and there is strict inequality: Œ±i < Œ≤i.
Proposition 6.121.
The lexicographic order ‚™Ølex is a monomial order on N n.
Proof.
First, we show that the lexicographic order is a partial order. The relation ‚™Ølex
is reÔ¨Çexive, for its deÔ¨Ånition shows that Œ± ‚™Ølex Œ±. To prove antisymmetry, assume that
Œ± ‚™Ølex Œ≤ and Œ≤ ‚™Ølex Œ±. If Œ± Ã∏= Œ≤, there is a Ô¨Årst coordinate, say the ith, where they
disagree. For notation, we may assume that Œ±i < Œ≤i. But this contradicts Œ≤ ‚™Ølex Œ±.
17The difference Œ≤ ‚àíŒ± may not lie in N n, but it does lie in Zn.

Sec. 6.6
Gr¬®obner Bases
403
To prove transitivity, suppose that Œ± ‚â∫lex Œ≤ and Œ≤ ‚â∫lex Œ≥ (it sufÔ¨Åces to consider strict
inequality). Now Œ±1 = Œ≤1, . . . , Œ±i‚àí1 = Œ≤i‚àí1 and Œ±i < Œ≤i. Let Œ≥p be the Ô¨Årst coordinate
with Œ≤p < Œ≥p. If p < i, then
Œ≥1 = Œ≤1 = Œ±1, . . . , Œ≥p‚àí1 = Œ≤p‚àí1 = Œ±p‚àí1, Œ±p = Œ≤p < Œ≥p;
if p ‚â•i, then
Œ≥1 = Œ≤1 = Œ±1, . . . , Œ≥i‚àí1 = Œ≤i‚àí1 = Œ±i‚àí1, Œ±i < Œ≤i = Œ≥i.
In either case, the Ô¨Årst nonzero coordinate of Œ≥ ‚àíŒ± is positive; that is, Œ± ‚â∫lex Œ≥ .
Next, we show that the lexicographic order is a well-order. If S is a nonempty subset of
N n, deÔ¨Åne
C1 = {all Ô¨Årst coordinates of n-tuples in S},
and deÔ¨Åne Œ¥1 to be the smallest number in C1 (note that C1 is a nonempty subset of the
well-ordered set N). DeÔ¨Åne
C2 = {all second coordinates of n-tuples (Œ¥1, Œ±2, . . . , Œ±n) ‚ààS}.
Since C2 Ã∏= ‚àÖ, it contains a smallest number, Œ¥2. Similarly, for all i < n, deÔ¨Åne Ci+1 as all
the (i +1)th coordinates of those n-tuples in S whose Ô¨Årst i coordinates are (Œ¥1, Œ¥2, . . . , Œ¥i),
and deÔ¨Åne Œ¥i+1 to be the smallest number in Ci+1. By construction, the n-tuple Œ¥ =
(Œ¥1, Œ¥2, . . . , Œ¥n) lies in S; moreover, if Œ± = (Œ±1, Œ±2, . . . , Œ±n) ‚ààS, then
Œ± ‚àíŒ¥ = (Œ±1 ‚àíŒ¥1, Œ±2 ‚àíŒ¥2, . . . , Œ±n ‚àíŒ¥n)
has its Ô¨Årst nonzero coordinate, if any, positive, and so Œ¥ ‚â∫lex Œ±. Therefore, the lexico-
graphic order is a well-order.
Assume that Œ± ‚™Ølex Œ≤; we claim that
Œ± + Œ≥ ‚™Ølex Œ≤ + Œ≥
for all Œ≥ ‚ààN. If Œ± = Œ≤, then Œ± +Œ≥ = Œ≤ +Œ≥ . If Œ± ‚â∫lex Œ≤, then the Ô¨Årst nonzero coordinate
of Œ≤ ‚àíŒ± is positive. But
(Œ≤ + Œ≥ ) ‚àí(Œ± + Œ≥ ) = Œ≤ ‚àíŒ±,
and so Œ± + Œ≥ ‚â∫lex Œ≤ + Œ≥ . Therefore, ‚™Ølex is a monomial order.
‚Ä¢
In the lexicographic order, x1 ‚âªx2 ‚âªx3 ‚âª¬∑ ¬∑ ¬∑ , for
(1, 0, . . . , 0) ‚âª(0, 1, 0, . . . , 0) ‚âª¬∑ ¬∑ ¬∑ ‚âª(0, 0, . . . , 1).
Any permutation of the variables xœÉ(1), . . . , xœÉ(n) yields a different lexicographic order
on N n.

404
Commutative Rings II
Ch. 6
Remark.
If X is any well-ordered set with order ‚™Ø, then the lexicographic order on
Xn can be deÔ¨Åned by a = (a1, . . . , an) ‚™Ølex b = (b1, . . . , bn) in case a = b or if
they Ô¨Årst disagree in the ith coordinate and ai ‚â∫bi. It is a simple matter to generalize
Proposition 6.121 by replacing N with X.
‚óÄ
In Lemma 5.70 we constructed, for any set X, a monoid W(X): its elements are the
empty word together with all the words xe1
1 ¬∑ ¬∑ ¬∑ xep
p on a set X, where p ‚â•1 and ei = ¬±1
for all i; its operation is juxtaposition. In contrast to N n, in which all words have length n,
the monoid W(X) has words of different lengths. Of more interest here is the submonoid
W+(X) of W(X) consisting of all the "positive" words on X:
W+(X) = {x1 ¬∑ ¬∑ ¬∑ x p ‚ààW(X) : xi ‚ààX and p ‚â•0}.
Corollary 6.122.
If X is a well-ordered set, then W+(X) is well-ordered in the lexico-
graphic order (which we also denote by ‚™Ølex).
Proof.
We will only give a careful deÔ¨Ånition of the lexicographic order here; the proof
that it is a well-order is left to the reader. First, deÔ¨Åne 1 ‚™Ølex w for all w ‚ààW+(X). Next,
given words u = x1 ¬∑ ¬∑ ¬∑ x p and v = y1 ¬∑ ¬∑ ¬∑ yq in W+(X), make them the same length by
adjoining 1's at the end of the shorter word, and rename them u‚Ä≤ and v‚Ä≤ in W+(X). If
m ‚â•max{p, q}, we may regard u‚Ä≤, v‚Ä≤, ‚ààXm, and we deÔ¨Åne u ‚™Ølex v if u‚Ä≤ ‚™Ølex v‚Ä≤ in Xm.
(This is the word order commonly used in dictionaries, where a blank precedes any letter:
for example, muse precedes museum.)
‚Ä¢
Lemma 6.123.
Given a monomial order on N n, any sequence of steps of the form
f (X) ‚Üíf (X) ‚àícŒ≤ XŒ≤ + g(X), where cŒ≤ XŒ≤ is a nonzero term of f (X) and Deg(g) ‚â∫Œ≤,
must be Ô¨Ånite.
Proof.
Each polynomial
f (X) =

Œ±
cŒ± XŒ± ‚ààk[X] = k[x1, . . . , xn]
can be written with the multidegrees of its terms in descending order: Œ±1 ‚âªŒ±2 ‚âª¬∑ ¬∑ ¬∑ ‚âªŒ±p.
DeÔ¨Åne
multiword( f ) = Œ±1 ¬∑ ¬∑ ¬∑ Œ±p ‚ààW+(N n).
Let cŒ≤ XŒ≤ be a nonzero term in f (X), let g(X) ‚ààk[X] have Deg(g) ‚â∫Œ≤, and write
f (X) = h(X) + cŒ≤ XŒ≤ + ‚Ñì(X),
where h(X) is the sum of all terms in f (X) of multidegree ‚âªŒ≤ and ‚Ñì(X) is the sum of all
terms in f (X) of multidegree ‚â∫Œ≤. We claim that
multiword( f (X) ‚àícŒ≤ XŒ≤ + g(X)) ‚™Ølex multiword(h + ‚Ñì+ g)
‚â∫lex multiword( f ) in W+(X).

Sec. 6.6
Gr¬®obner Bases
405
The sum of the terms in f (X) ‚àícŒ≤ XŒ≤ + g(X) with multidegree ‚âªŒ≤ is h(X), while
the sum of the lower terms is ‚Ñì(X) + g(X). But Deg(‚Ñì+ g) ‚â∫Œ≤, by Exercise 6.79 on
page 410. Therefore, the initial terms of f (X) and f (X) ‚àícŒ≤ XŒ≤ + g(X) agree, while
the next term of f (X) ‚àícŒ≤ XŒ≤ + g(X) has multidegree ‚â∫Œ≤, and this proves the claim.
Since W+(N n) is well-ordered, it follows that any sequence of steps of the form f (X) ‚Üí
f (X) ‚àícŒ≤ XŒ≤ + g(X) must be Ô¨Ånite.
‚Ä¢
Here is the second popular monomial order. Recall that if Œ± = (Œ±1, . . . , Œ±n) ‚ààN n, then
|Œ±| = Œ±1 + ¬∑ ¬∑ ¬∑ + Œ±n denotes its weight.
DeÔ¨Ånition.
The degree-lexicographic order on N n is deÔ¨Åned by Œ± ‚™Ødlex Œ≤ if either
Œ± = Œ≤ or
|Œ±| =
n

i=1
Œ±i <
n

i=1
Œ≤i = |Œ≤|,
or, if |Œ±| = |Œ≤|, then the Ô¨Årst nonzero coordinate in Œ≤ ‚àíŒ± is positive.
In other words, given Œ± = (Œ±1, . . . , Œ±n) and Œ≤ = (Œ≤1, . . . , Œ≤n), Ô¨Årst check weights: if
|Œ±| < |Œ≤|, then Œ± ‚™Ødlex Œ≤; if there is a tie, that is, if Œ± and Œ≤ have the same weight, then or-
der them lexicographically. For example, (1, 2, 3, 0) ‚â∫dlex (0, 2, 5, 0) and (1, 2, 3, 4) ‚â∫dlex
(1, 2, 5, 2).
Proposition 6.124.
The degree-lexicographic order ‚™Ødlex is a monomial order on N n.
Proof.
It is routine to show that ‚™Ødlex is a partial order on N n. To see that it is a well-order,
let S be a nonempty subset of N n. The weights of elements in S form a nonempty subset of
N, and so there is a smallest such, say, t. The nonempty subset of all Œ± ‚ààS having weight
t has a smallest element, because the degree-lexicographic order ‚™Ødlex coincides with the
lexicographic order ‚™Ølex on this subset. Therefore, there is a smallest element in S in the
degree-lexicographic order.
Assume that Œ± ‚™Ødlex Œ≤ and Œ≥ ‚ààN n. Now |Œ± + Œ≥ | = |Œ±| + |Œ≥ |, so that |Œ±| = |Œ≤|
implies |Œ± + Œ≥ | = |Œ≤ + Œ≥ | and |Œ±| < |Œ≤| implies |Œ± + Œ≥ | < |Œ≤ + Œ≥ |; in the latter case,
Proposition 6.121 shows that Œ± + Œ≥ ‚™Ødlex Œ≤ + Œ≥ .
‚Ä¢
The next proposition shows, with respect to a monomial order, that polynomials in
several variables behave like polynomials in a single variable.
Proposition 6.125.
Let ‚™Øbe a monomial order on N n, and let f (X), g(X), h(X) ‚àà
k[X] = k[x1, . . . , xn], where k is a Ô¨Åeld.
(i) If Deg( f ) = Deg(g), then LT(g) | LT( f ).
(ii) LT(hg) = LT(h)LT(g).
(iii) If Deg( f ) = Deg(hg), then LT(g) | LT( f ).

406
Commutative Rings II
Ch. 6
Proof.
(i) If Deg( f ) = Œ± = Deg(g), then LT( f ) = cXŒ± and LT(g) = d XŒ±. Hence,
LT(g) | LT( f ), because c Ã∏= 0 and so c is a unit in k [note that LT( f ) | LT(g) as well].
(ii) Let h(X) = cXŒ≥ + lower terms and let g(X) = bXŒ≤ + lower terms, so that LT(h) =
cXŒ≥ and LT(g) = bXŒ≤. Clearly, cbXŒ≥ +Œ≤ is a nonzero term of h(X)g(X). To see that it
is the leading term, let c¬µX¬µ be a term of h(X) with ¬µ ‚™ØŒ≥ , and let bŒΩ XŒΩ be a term of
g(X) with ŒΩ ‚™ØŒ≤ (with at least one strict inquality). Now Deg(c¬µX¬µbŒΩ XŒΩ) = ¬µ+ŒΩ; since
‚™Øis a monomial order, we have ¬µ + ŒΩ ‚â∫Œ≥ + ŒΩ ‚â∫Œ≥ + Œ≤. Thus, cbXŒ≥ +Œ≤ is the term in
h(X)g(X) with largest multidegree.
(iii) Since Deg( f ) = Deg(hg), part (i) gives LT(hg) | LT( f ), and LT(h)LT(g) = LT(hg),
by part (ii); hence, LT(g) | LT( f ).
‚Ä¢
DeÔ¨Ånition.
Let ‚™Øbe a monomial order on N n and let f (X), g(X) ‚ààk[X], where k[X] =
k[x1, . . . , xn]. If there is a nonzero term cŒ≤ XŒ≤ in f (X) with LT(g) | cŒ≤ XŒ≤ and
h(X) = f (X) ‚àícŒ≤ XŒ≤
LT(g)g(X),
then the reduction f
g‚Üíh is the replacement of f by h.
Reduction is precisely the usual step involved in long division of polynomials in one
variable. Of course, a special case of reduction is when cŒ≤ XŒ≤ = LT( f ).
Proposition 6.126.
Let ‚™Øbe a monomial order on N n, let f (X), g(X) ‚ààk[X] =
k[x1, . . . , xn], and assume that f
g‚Üíh; that is, there is a nonzero term cŒ≤ XŒ≤ in f (X)
with LT(g) | cŒ≤ XŒ≤ and h(X) = f (X) ‚àícŒ≤ XŒ≤
LT(g)g(X). Then
Deg
 cŒ≤ XŒ≤
LT(g)g(X)

‚™ØDeg( f ).
Moreover, if Œ≤ = Deg( f ) [i.e., if cŒ≤ XŒ≤ = LT( f )], then either
h(X) = 0
or
Deg(h) ‚â∫Deg( f ),
and if Œ≤ ‚â∫Deg( f ), then Deg(h) = Deg( f ).
Proof.
Let us write
f (X) = LT( f ) + cŒ∫ XŒ∫ + lower terms,
where cŒ∫ XŒ∫ = LT( f ‚àíLT( f )); since cŒ≤ XŒ≤ is a term of f (X), we have Œ≤ ‚™ØDeg( f ).
Similarly, if LT(g) = aŒ≥ XŒ≥ , so that Deg(g) = Œ≥ , let us write
g(X) = aŒ≥ XŒ≥ + aŒªXŒª + lower terms,

Sec. 6.6
Gr¬®obner Bases
407
where aŒªXŒª = LT(g ‚àíLT(g)). Hence,
h(X) = f (X) ‚àícŒ≤ XŒ≤
LT(g)g(X)
= f (X) ‚àícŒ≤ XŒ≤
LT(g)

LT(g) + aŒªXŒª + ¬∑ ¬∑ ¬∑

=

f (X) ‚àícŒ≤ XŒ≤
‚àícŒ≤ XŒ≤
LT(g)

aŒªXŒª + ¬∑ ¬∑ ¬∑

.
Now LT(g) | cŒ≤ XŒ≤ says that Œ≤ ‚àíŒ≥ ‚ààN n. We claim that
Deg

‚àícŒ≤ XŒ≤
LT(g)

aŒªXŒª + ¬∑ ¬∑ ¬∑

= Œª + Œ≤ ‚àíŒ≥ ;
that is, Œª+Œ≤ ‚àíŒ≥ = Deg

‚àícŒ≤ XŒ≤
LT(g)aŒªXŒª
is the largest multidegree occurring. Suppose that
aŒ∑XŒ∑ is a lower term in g(X) (i.e., Œ∑ ‚â∫Œª); since ‚™Øis a monomial order,
Œ∑ + (Œ≤ ‚àíŒ≥ ) ‚â∫Œ≥ + (Œª ‚àíŒ≥ ) = Œª.
Now Œª ‚â∫Œ≥ implies Œª + (Œ≤ ‚àíŒ≥ ) ‚â∫Œ≥ + (Œ≤ ‚àíŒ≥ ) = Œ≤, and so
Deg

‚àí
 cŒ≤ XŒ≤
LT(g)

g(X)

‚â∫Œ≤ ‚™ØDeg( f ).
(6)
Therefore, if h(X) Ã∏= 0, then Exercise 6.79 on page 410 gives
Deg(h) ‚™Ømax

Deg

f (X) ‚àícŒ≤ XŒ≤
, Deg

‚àí
 cŒ≤ XŒ≤
LT(g)

g(X)
	 
.
Now if Œ≤ = Deg( f ), then cŒ≤ XŒ≤ = LT( f ),
f (X) ‚àícŒ≤ XŒ≤ = f (X) ‚àíLT( f ) = cŒ∫ XŒ∫ + lower terms,
and, hence, Deg( f (X) ‚àícŒ≤ XŒ≤) = Œ∫ ‚â∫Deg( f ) in this case. If Œ≤ ‚â∫Deg( f ), then
Deg( f (X) ‚àícŒ≤ XŒ≤) = Deg( f ), while Deg

‚àí
 cŒ≤ XŒ≤
LT(g)

g(X)

‚â∫Deg( f ), by Eq. (6), and
so Deg(h) = Deg( f ) in this case.
The last inequality is clear, for
cŒ≤ XŒ≤
LT(g)g(X) = cŒ≤ XŒ≤ + cŒ≤ XŒ≤
LT(g)

aŒªXŒª + ¬∑ ¬∑ ¬∑

.
Since the latter part of the polynomial has Degree Œª + Œ≤ ‚àíŒ≥ ‚â∫Œ≤, we see that
Deg
 cŒ≤ XŒ≤
LT(g)g(X)

= Œ≤ ‚™ØDeg( f ).
‚Ä¢

408
Commutative Rings II
Ch. 6
DeÔ¨Ånition.
Let {g1(X), . . . , gm(X)} be a set of polynomials in k[X]. A polynomial r(X)
is reduced mod {g1, . . . , gm} if either r(X) = 0 or no LT(gi) divides any nonzero term of
r(X).
Here is the division algorithm for polynomials in several variables. Because the algo-
rithm requires the "divisor polynomials" {g1, . . . , gm} to be used in a speciÔ¨Åc order (after
all, an algorithm must give explicit directions), we will be using an m-tuple of polynomi-
als instead of a subset of polynomials. We denote the m-tuple whose ith entry is gi by
[g1, . . . , gm], because the usual notation (g1, . . . , gm) would be confused with the ideal
(g1, . . . , gm) generated by the gi.
Theorem 6.127 (Division Algorithm in k[X]).
Let ‚™Øbe a monomial order on N n, and
let k[X] = k[x1, . . . , xn]. If f (X) ‚ààk[X] and G = [g1(X), . . . , gm(X)] is an m-tuple
of polynomials in k[X], then there is an algorithm giving polynomials r(X), a1(X), . . .,
am(X) ‚ààk[X] with
f = a1g1 + ¬∑ ¬∑ ¬∑ + amgm + r,
where r is reduced mod {g1, . . . , gm}, and
Deg(aigi) ‚™ØDeg( f )
for all i.
Proof.
Once a monomial order is chosen, so that leading terms are deÔ¨Åned, the algorithm
is a straightforward generalization of the division algorithm in one variable. First, reduce
mod g1 as many times as possible, then reduce mod g2 as many times as possible, and then
reduce again mod g1; more generally, once a polynomial is reduced mod [g1, . . . , gi] for
any i, then reduce mod [g1 . . . , gi, gi+1]. Here is a pseudocode describing the algorithm
more precisely.
Input: f (X) = 
Œ≤ cŒ≤ XŒ≤,
[g1, . . . , gm]
Output: r, a1, . . . , am
r := f ;
ai := 0
WHILE f is not reduced mod {g1, . . . , gm} DO
select smallest i with LT(gi) | cŒ≤ XŒ≤ for some Œ≤
f ‚àí[cŒ≤ XŒ≤/LT(gi)]gi := f
ai + [cŒ≤ XŒ≤/LT(gi)] := ai
END WHILE
At each step h j
gi‚Üíh j+1 of the algorithm, we have
multiword(h j) ‚âªlex multiword(h j+1)
in W+(N n), by Lemma 6.123, and so the algorithm does stop, because ‚â∫lex is a well-order
on W+(N n). Obviously, the output r(X) is reduced mod {g1, . . . , gm}, for if it has a term
divisible by some LT(gi), then one further reduction is possible.
Finally, each term of ai(X) has the form cŒ≤ XŒ≤/LT(gi) for some intermediate out-
put h(X) (as we see in the pseudocode). It now follows from Proposition 6.126 that
Deg(aigi) ‚™ØDeg( f ).
‚Ä¢

Sec. 6.6
Gr¬®obner Bases
409
DeÔ¨Ånition.
Given a monomial order on N n, a polynomial f (X) ‚ààk[X], and an m-tuple
G = [g1, . . . , gm], we call the output r(X) of the division algorithm the remainder of
f (X) mod G.
Note that the remainder r of f mod G is reduced mod {g1, . . . , gm} and f ‚àír ‚ààI =
(g1, . . . , gm). The algorithm requires that G be an m-tuple, because of the command
select smallest i with LT(gi) | cŒ≤ XŒ≤ for some Œ≤
specifying the order of reductions.
The next example shows that the remainder may depend not only on the set of poly-
nomials {g1, . . . , gm} but also on the ordering of the coordinates in the m-tuple G =
[g1, . . . , gm]. That is, if œÉ ‚ààSm is a permutation and GœÉ = [gœÉ(1), . . . , gœÉ(m)], then
the remainder rœÉ of f mod GœÉ may not be the same as the remainder r of f mod G. Even
worse, it is possible that r Ã∏= 0 and rœÉ = 0, so that the remainder mod G is not the ob-
struction to f being in the ideal (g1, . . . , gm). We illustrate this phenomenon in the next
example, and we will deal with it in the next subsection.
Example 6.128.
Let f (x, y, z) = x2y2 + xy, and let G = [g1, g2, g3], where
g1 = y2 + z2
g2 = x2y + yz
g3 = z3 + xy.
We use the degree-lexicographic order on N 3. Now y2 = LT(g1) | LT( f ) = x2y2, and so
f
g1
‚Üíh, where
h = f ‚àíx2y2
y2 (y2 + z2) = ‚àíx2z2 + xy.
The polynomial ‚àíx2z2 + xy is reduced mod G, because neither ‚àíx2z2 nor xy is divisible
by any of the leading terms LT(g1) = y2, LT(g2) = x2y, or LT(g3) = z3.
Let us now apply the division algorithm using the 3-tuple G‚Ä≤ = [g2, g1, g3]. The Ô¨Årst
reduction gives f
g2
‚Üíh‚Ä≤, where
h‚Ä≤ = f ‚àíx2y2
x2y (x2y + yz) = ‚àíy2z + xy.
Now h‚Ä≤ is not reduced, and reducing mod g1 gives
h‚Ä≤ ‚àí‚àíy2z
y2 (y2 + z2) = z3 + xy.
But z3 + xy = g3, and so z3 + xy
g3
‚Üí0. Thus, the remainder depends on the ordering of
the divisor polynomials gi in the m-tuple.
For a simpler example of different remainders (but with neither remainder being 0), see
Exercise 6.78.
‚óÄ

410
Commutative Rings II
Ch. 6
EXERCISES
6.75
(i) Let (X, ‚™Ø) and (Y, ‚™Ø‚Ä≤) be well-ordered sets, where X and Y are disjoint. DeÔ¨Åne a binary
relation ‚â§on X ‚à™Y by
x1 ‚â§x2
if x1, x2 ‚ààX and x1 ‚™Øx2,
y1 ‚â§y2
if y1, y2 ‚ààY and y1 ‚™Ø‚Ä≤ y2,
x ‚â§y
if x ‚ààX and y ‚ààY.
Prove that (X ‚à™Y, ‚â§) is a well-ordered set.
(ii) If r ‚â§n, we may regard Nr as the subset of N n consisting of all n-tuples of the form
(n1, . . . , nr, 0, . . . , 0), where ni ‚ààN for all i ‚â§r. Prove that there exists a monomial
order on N n in which a ‚â∫b whenever Œ± ‚ààNr and Œ≤ ‚ààN n ‚àíNr.
Hint. Consider the lex order on k[x1, . . . , xn] in which x1 ‚â∫x2 ‚â∫¬∑ ¬∑ ¬∑ ‚â∫xn.
6.76
(i) Write the Ô¨Årst 10 monic monomials in k[x, y] in lexicographic order and in degree-
lexicographic order.
(ii) Write all the monic monomials in k[x, y, z] of weight at most 2 in lexicographic order
and in degree-lexicographic order.
6.77 Give an example of a well-ordered set X containing an element u having inÔ¨Ånitely many
predecessors; that is, {x ‚ààX : x ‚™Øu} is inÔ¨Ånite.
6.78 Let G = [x ‚àíy, x ‚àíz] and G‚Ä≤ = [x ‚àíz, x ‚àíy]. Show that the remainder of x mod G (in
degree-lexicographic order) is distinct from the remainder of x mod G‚Ä≤.
6.79 Let ‚™Øbe a monomial order on N n, and let f (X), g(X) ‚ààk[X] = k[x1, . . . , xn] be nonzero.
(i) Prove that if f + g Ã∏= 0, then Deg( f + g) ‚™Ømax{Deg( f ), Deg(g)}, and that strict
inequality can occur only if Deg( f ) = Deg(g).
(ii) Prove that Deg( f g) = Deg( f ) + Deg(g), and Deg( f m) = m Deg( f ) for all m ‚â•1.
6.80 Use the degree-lexicographic order in this exercise.
(i) Find the remainder of x7y2 + x3y2 ‚àíy + 1 mod [xy2 ‚àíx, x ‚àíy3].
(ii) Find the remainder of x7y2 + x3y2 ‚àíy + 1 mod [x ‚àíy3, xy2 ‚àíx].
6.81 Use the degree-lexicographic order in this exercise.
(i) Find the remainder of x2y + xy2 + y2 mod [y2 ‚àí1, xy ‚àí1].
(ii) Find the remainder of x2y + xy2 + y2 mod [xy ‚àí1, y2 ‚àí1].
6.82 Let cŒ± XŒ± be a nonzero monomial, and let f (X), g(X) ‚ààk[X] be polynomials none of whose
terms is divisible by cŒ± XŒ±. Prove that none of the terms of f (X)‚àíg(X) is divisible by cŒ± XŒ±.
6.83 An ideal I in k[X] that is generated by monomials, say, I = (XŒ±(1), . . . , XŒ±(q)), is called a
monomial ideal.
(i) Prove that f (X) ‚ààI if and only if each term of f (X) is divisible by some XŒ±(i).
(ii) Prove that if G = [g1, . . . , gm] and r is reduced mod G, then r does not lie in the
monomial ideal (LT(g1), . . . , LT(gm)).
6.84 Let f (X) = 
Œ± cŒ± XŒ± ‚ààk[X] be symmetric, where k is a Ô¨Åeld and X = (x1, . . . , xn).
Assume that N n is equipped with the degree-lexicographic order and that Deg( f ) = Œ≤ =
(Œ≤1, . . . , Œ≤n).
(i) Prove that if cŒ±xŒ±1
1 ¬∑ ¬∑ ¬∑ xŒ±n
n
occurs with nonzero coefÔ¨Åcient cŒ±, then every monomial
xŒ±1
œÉ1 ¬∑ ¬∑ ¬∑ xŒ±n
œÉn also occurs in f (X) with nonzero coefÔ¨Åcient, where œÉ ‚ààSn.

Sec. 6.6
Gr¬®obner Bases
411
(ii) Prove that Œ≤1 ‚â•Œ≤2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Œ≤n.
(iii) If e1, . . . , en are the elementary symmetric polynomials, prove that
Deg(ei) = (1, . . . , 1, 0, . . . , 0),
where there are i 1's.
(iv) Let (Œ≥1, . . . , Œ≥n) = (Œ≤1‚àíŒ≤2, Œ≤2‚àíŒ≤3, . . . , Œ≤n‚àí1‚àíŒ≤n, Œ≤n). Prove that if g(x1, . . . , xn) =
xŒ≥1
1 ¬∑ ¬∑ ¬∑ xŒ≥n
n , then g(e1, . . . , en) is symmetric and Deg(g) = Œ≤.
(v) Fundamental Theorem of Symmetric Polynomials. Prove that if k is a Ô¨Åeld, then
every symmetric polynomial f (X) ‚ààk[X] is a polynomial in the elementary symmetric
functions e1, . . . , en. (Compare with Theorem 4.37.)
Hint. Prove that h(X) = f (X) ‚àícŒ≤g(e1, . . . , en) is symmetric, and that Deg(h) < Œ≤.
Buchberger's Algorithm
For the remainder of this section we will assume that N n is equipped with some monomial
order (the reader may use the degree-lexicographic order), so that LT( f ) is deÔ¨Åned and the
division algorithm makes sense.
We have seen that the remainder of f mod [g1, . . . , gm] obtained from the division al-
gorithm can depend on the order in which the gi are listed. Informally, a Gr¬®obner basis
{g1, . . . , gm} of the ideal I = (g1, . . . , gm) is a generating set such that, for every m-tuple
GœÉ = [gœÉ(1), . . . , gœÉ(m)] formed from the gi, where œÉ ‚ààSm is a permutation, the remain-
der of f mod GœÉ is always the obstruction to whether f lies in I. We deÔ¨Åne Gr¬®obner bases
using a property that is more easily checked, and we then show, in Proposition 6.129, that
they are characterized by the more interesting obstruction propery just mentioned.
DeÔ¨Ånition.
A set of polynomials {g1, . . . , gm} is a Gr¬®obner basis18 of the ideal I =
(g1, . . . , gm) if, for each nonzero f ‚ààI, there is some gi with LT(gi) | LT( f ).
Note that a Gr¬®obner basis is a set of polynomials, not an m-tuple of polynomials. Ex-
ample 6.128 shows that
{y2 + z2, x2y + yz, z3 + xy}
is not a Gr¬®obner basis of the ideal (y2 + z2, x2y + yz, z3 + xy).
Proposition 6.129.
A set {g1, . . . , gm} of polynomials is a Gr¬®obner basis of an ideal
I = (g1, . . . , gm) if and only if, for each m-tuple GœÉ = [gœÉ(1), . . . , gœÉ(m)], where œÉ ‚ààSm,
every f ‚ààI has remainder 0 mod GœÉ.
Proof.
Assume there is some permutation œÉ ‚ààSm and some f ‚ààI whose remainder
mod GœÉ is not 0. Among all such polynomials, choose f of minimal Degree. Since
{g1, . . . , gm} is a Gr¬®obner basis, LT(gi) | LT( f ) for some i; select the smallest œÉ(i) for
18B. Buchberger has written in his article in Buchberger-Winkler, Gr¬®obner Bases and Applications, "The early
paper of Gr¬®obner in 1954, although not yet containing the essential ingredients of Gr¬®obner basis theory, pointed
in the right direction and motivated me, in 1976, to assign the name of W. Gr¬®obner (1899-1980) to the theory."

412
Commutative Rings II
Ch. 6
which there is a reduction f
gœÉ(i)
‚Üíh, and note that h ‚ààI. Since Deg(h) ‚â∫Deg( f ), by
Proposition 6.126, the division algorithm gives a sequence of reductions h = h0 ‚Üíh1 ‚Üí
h2 ‚Üí¬∑ ¬∑ ¬∑ ‚Üíh p = 0. But the division algorithm for f adjoins f ‚Üíh at the front,
showing that 0 is the remainder of f mod GœÉ, a contradiction.
Conversely, assume that every f ‚ààI has remainder 0 mod GœÉ but that {g1, . . . , gm} is
not a Gr¬®obner basis of I = (g1, . . . , gm). If there is a nonzero f ‚ààI with LT(gi) ‚à§LT( f )
for every i, then in any reduction f
gi‚Üí
h, we have LT(h) = LT( f ). Hence, if G =
[g1, . . . , gm], the division algorithm mod G gives reductions f ‚Üíh1 ‚Üíh2 ‚Üí¬∑ ¬∑ ¬∑ ‚Üí
h p = r in which LT(r) = LT( f ). Therefore, r Ã∏= 0; that is, the remainder of f mod G is
not zero, and this is a contradiction.
‚Ä¢
Corollary 6.130.
If {g1, . . . , gm} is a Gr¬®obner basis of the ideal I = (g1, . . . , gm), and
if G = [g1, . . . , gm] is any m-tuple formed from the gi, then for every f (X) ‚ààk[X], there
is a unique r(X) ‚ààk[X], which is reduced mod {g1, . . . , gm}, such that f ‚àír ‚ààI; in
fact, r is the remainder of f mod G.
Proof.
The division algorithm gives a polynomial r, reduced mod {g1, . . . , gm}, and poly-
nomials a1, . . . , am with f = a1g1+¬∑ ¬∑ ¬∑+amgm+r; clearly, f ‚àír = a1g1+¬∑ ¬∑ ¬∑+amgm ‚ààI.
To prove uniqueness, suppose that r and r‚Ä≤ are reduced mod {g1, . . . , gm} and that
f ‚àír and f ‚àír‚Ä≤ lie in I, so that ( f ‚àír‚Ä≤) ‚àí( f ‚àír) = r ‚àír‚Ä≤ ‚ààI. Since r and r‚Ä≤ are
reduced mod {g1, . . . , gm}, none of their terms is divisible by any LT(gi). If r ‚àír‚Ä≤ Ã∏= 0,
then Exercise 6.82 on page 410 says that no term of r ‚àír‚Ä≤ is divisible by any LT(gi); in
particular, LT(r ‚àír‚Ä≤) is not divisible by any LT(gi), and this contradicts Proposition 6.129.
Therefore, r = r‚Ä≤.
‚Ä¢
The next corollary shows that Gr¬®obner bases resolve the problem of different remainders
in the division algorithm arising from different m-tuples.
Corollary 6.131.
Let {g1, . . . , gm} be a Gr¬®obner basis of the ideal I = (g1, . . . , gm),
and let G = [g1, . . . , gm].
(i) If f (X) ‚ààk[X] and GœÉ = [gœÉ(1), . . . , gœÉ(m)], where œÉ ‚ààSm is a permutation, then
the remainder of f mod G is equal to the remainder of f mod GœÉ.
(ii) A polynomial f ‚ààI if and only if f has remainder 0 mod G.
Proof.
(i) If r is the remainder of f mod G, then Corollary 6.130 says that r is the unique
polynomial, reduced mod {g1, . . . , gm}, with f ‚àír ‚ààI; similarly, the remainder rœÉ of f
mod GœÉ is the unique polynomial, reduced mod {g1, . . . , gm}, with f ‚àírœÉ ‚ààI. The
uniqueness assertion in Corollary 6.130 gives r = rœÉ.
(ii) Proposition 6.129 shows that if f ‚ààI, then its remainder is 0. For the converse, if r is
the remainder of f mod G, then f = q + r, where q ‚ààI. Hence, if r = 0, then f ‚ààI. ‚Ä¢
There are several obvious questions. Do Gr¬®obner bases exist and, if they do, are they
unique? Given an ideal I in k[X], is there an algorithm to Ô¨Ånd a Gr¬®obner basis of I?

Sec. 6.6
Gr¬®obner Bases
413
The notion of S-polynomial will allow us to recognize a Gr¬®obner basis, but we Ô¨Årst
introduce some notation.
DeÔ¨Ånition.
If Œ± = (Œ±1, . . . , Œ±n) and Œ≤ = (Œ≤1, . . . , Œ≤n) are in N n, deÔ¨Åne
Œ± ‚à®Œ≤ = ¬µ,
where ¬µi = max{Œ±i, Œ≤i} and ¬µ = (¬µ1, . . . , ¬µn).
Note that XŒ±‚à®Œ≤ is the least common multiple of the monomials XŒ± and XŒ≤.
DeÔ¨Ånition.
Let f (X), g(X) ‚ààk[X], where LT( f ) = aŒ± XŒ± and LT(g) = bŒ≤ XŒ≤. DeÔ¨Åne
L( f, g) = XŒ±‚à®Œ≤.
The S-polynomial S( f, g) is deÔ¨Åned by
S( f, g) = L( f, g)
LT( f ) f ‚àíL( f, g)
LT(g) g;
that is, if ¬µ = Œ± ‚à®Œ≤, then
S( f, g) = a‚àí1
Œ± X¬µ‚àíŒ± f (X) ‚àíb‚àí1
Œ≤ X¬µ‚àíŒ≤g(X).
Note that S( f, g) = ‚àíS(g, f ).
Example 6.132.
(i) If f (x, y) = 3x2y and g(x, y) = 5xy3 ‚àíy (in degree-lexicographic order), then
L( f, g) = x2y3 and
S( f, g) = x2y3
3x2y 3x2y ‚àíx2y3
5xy3 (5xy3 ‚àíy) = 1
5xy.
(ii) If f (X) and g(X) are monomials, say, f (X) = aŒ± XŒ± and g(X) = bŒ≤ XŒ≤, then
S( f, g) = XŒ±‚à®Œ≤
aŒ± XŒ± aŒ± XŒ± ‚àíXŒ±‚à®Œ≤
bŒ≤ XŒ≤ bŒ≤ XŒ≤ = 0.
‚óÄ
The following technical lemma indicates why S-polynomials are relevant. It says that if
Deg(
j a jg j) ‚â∫Œ¥, where the a j are monomials, while Deg(a jg j) = Œ¥ for all j, then any
polynomial of multidegree ‚â∫Œ¥ can be rewritten as a linear combination of S-polynomials,
with monomial coefÔ¨Åcents, each of whose terms has multidegree strictly less than Œ¥.

414
Commutative Rings II
Ch. 6
Lemma 6.133.
Given g1(X), . . . , g‚Ñì(X) ‚ààk[X] and monomials c j XŒ±( j), let h(X) =
‚Ñì
j=1 c j XŒ±( j)g j(X).
Let Œ¥ be a multidegree. If Deg(h) ‚â∫Œ¥ and Deg(c j XŒ±( j)g j(X)) = Œ¥ for all j ‚â§‚Ñì, then
there are d j ‚ààk with
h(X) =

j
d j XŒ¥‚àí¬µ( j)S(g j, g j+1),
where ¬µ( j) = Deg(g j) ‚à®Deg(g j+1), and for all j < ‚Ñì,
Deg

XŒ¥‚àí¬µ( j)S(g j, g j+1)

‚â∫Œ¥.
Proof.
Let LT(g j) = b j XŒ≤( j), so that LT(c j XŒ±( j)g j(X)) = c jb j XŒ¥. The coefÔ¨Åcient of
XŒ¥ in h(X) is thus 
j c jb j. Since Deg(h) ‚â∫Œ¥, we must have 
j c jb j = 0. DeÔ¨Åne
monic polynomials
u j(X) = b‚àí1
j XŒ±( j)g j(X).
There is a telescoping sum
h(X) =
‚Ñì

j=1
c j XŒ±( j)g j(X)
=
‚Ñì

j=1
c jb ju j
= c1b1(u1 ‚àíu2) + (c1b1 + c2b2)(u2 ‚àíu3) + ¬∑ ¬∑ ¬∑
+ (c1b1 + ¬∑ ¬∑ ¬∑ + c‚Ñì‚àí1b‚Ñì‚àí1)(u‚Ñì‚àí1 ‚àíu‚Ñì)
+ (c1b1 + ¬∑ ¬∑ ¬∑ + c‚Ñìb‚Ñì)u‚Ñì.
The last term (c1b1+¬∑ ¬∑ ¬∑+c‚Ñìb‚Ñì)u‚Ñì= 0, for 
j c jb j = 0. Since Œ¥ = Deg(c j XŒ±( j)g j(X)),
we have Œ±( j) + Œ≤( j) = Œ¥, so that XŒ≤( j) | XŒ¥ for all j. Hence, for all j < ‚Ñì, we have
lcm{XŒ≤( j), XŒ≤( j+1)} = XŒ≤( j)‚à®Œ≤( j+1) | XŒ¥; that is, if we write ¬µ( j) = Œ≤( j) ‚à®Œ≤( j + 1),
then Œ¥ ‚àí¬µ( j) ‚ààN n. But
XŒ¥‚àí¬µ( j)S(g j, g j+1) = XŒ¥‚àí¬µ( j) X¬µ( j)
LT(g j)g j(X) ‚àí
X¬µ( j)
LT(g j+1)g j+1(X)

=
XŒ¥
LT(g j)g j(X) ‚àí
XŒ¥
LT(g j+1)g j+1(X)
= b‚àí1
j XŒ±( j)g j ‚àíb‚àí1
j+1XŒ±( j+1)g j+1
= u j ‚àíu j+1.
Substituting this equation into the telescoping sum gives a sum of the desired form, where
d j = c1b1 + ¬∑ ¬∑ ¬∑ + c jb j:
h(X) = c1b1XŒ¥‚àí¬µ(1)S(g1, g2) + (c1b1 + c2b2)XŒ¥‚àí¬µ(2)S(g2, g3) + ¬∑ ¬∑ ¬∑
+ (c1b1 + ¬∑ ¬∑ ¬∑ + c‚Ñì‚àí1b‚Ñì‚àí1)XŒ¥‚àí¬µ(‚Ñì‚àí1)S(g‚Ñì‚àí1, g‚Ñì).

Sec. 6.6
Gr¬®obner Bases
415
Finally, since both u j and u j+1 are monic with leading term of multidegree Œ¥, we have
Deg(u j ‚àíu j+1) ‚â∫Œ¥. But we have shown that u j ‚àíu j+1 = XŒ¥‚àí¬µ( j)S(g j, g j+1), and so
Deg(XŒ¥‚àí¬µ( j)S(g j, g j+1)) ‚â∫Œ¥, as desired.
‚Ä¢
By Proposition 6.129, {g1, . . . , gm} is a Gr¬®obner basis of I = (g1, . . . , gm) if every
f ‚ààI has remainder 0 mod G (where G is any m-tuple formed by ordering the gi).
The importance of the next theorem lies in its showing that it is necessary to compute the
remainders of only Ô¨Ånitely many polynomials, namely, the S-polynomials, to determine
whether {g1, . . . , gm} is a Gr¬®obner basis.
Theorem 6.134 (Buchberger).
A set {g1, . . . , gm} is a Gr¬®obner basis of an ideal I =
(g1, . . . , gm) if and only if S(gp, gq) has remainder 0 mod G for all p, q, where G =
[g1, . . . , gm].
Proof.
Clearly, S(gp, gq), being a linear combination of gp and gq, lies in I. Hence, if
G = {g1, . . . , gm} is a Gr¬®obner basis, then S(gp, gq) has remainder 0 mod G, by Proposi-
tion 6.129.
Conversely, assume that S(gp, gq) has remainder 0 mod G for all p, q; we must show
that every f ‚ààI has remainder 0 mod G. By Proposition 6.129, it sufÔ¨Åces to show that
if f ‚ààI, then LT(gi) | LT( f ) for some i. Since f ‚ààI = (g1, . . . , gm), we may write
f = 
i higi, and so
Deg( f ) ‚™Ømax
i {Deg(higi)}.
If there is equality, then Deg( f ) = Deg(higi) for some i, and so Proposition 6.125 gives
LT(gi) | LT( f ), as desired. Therefore, we may assume strict inequality: Deg( f ) ‚â∫
maxi{Deg(higi)}.
The polynomial f may be written as a linear combination of the gi in many ways. Of
all the expressions of the form f = 
i higi, choose one in which Œ¥ = maxi{Deg(higi)}
is minimal (which is possible because ‚™Øis a well-order). If Deg( f ) = Œ¥, we are done, as
we have seen; therefore, we may assume that there is strict inequality: Deg( f ) ‚â∫Œ¥. Write
f =

j
Deg(h j g j)=Œ¥
h jg j +

‚Ñì
Deg(h‚Ñìg‚Ñì)‚â∫Œ¥
h‚Ñìg‚Ñì.
(7)
If Deg(
j h jg j) = Œ¥, then Deg( f ) = Œ¥, a contradiction; hence, Deg(
j h jg j) ‚â∫Œ¥. But
the coefÔ¨Åcient of XŒ¥ in this sum is obtained from its leading terms, so that
Deg

j
LT(h j)g j

‚â∫Œ¥.
Now 
j LT(h j)g j is a polynomial satisfying the hypotheses of Lemma 6.133, and so there
are constants d j and multidegrees ¬µ( j) so that

j
LT(h j)g j =

j
d j XŒ¥‚àí¬µ( j)S(g j, g j+1),
(8)

416
Commutative Rings II
Ch. 6
where Deg

XŒ¥‚àí¬µ( j)S(g j, g j+1)

‚â∫Œ¥.19
Since each S(g j, g j+1) has remainder 0 mod G, the division algorithm gives a ji(X) ‚àà
k[X] with S(g j, g j+1) = 
i a jigi, where Deg(a jigi) ‚™ØDeg(S(g j, g j+1)) for all j, i. It
follows that
XŒ¥‚àí¬µ( j)S(g j, g j+1) =

i
XŒ¥‚àí¬µ( j)a jigi.
Therefore, Lemma 6.133 gives
Deg(XŒ¥‚àí¬µ( j)a jigi) ‚™ØDeg(XŒ¥‚àí¬µ( j)S(g j, g j+1)) ‚â∫Œ¥.
(9)
Substituting into Eq. (8), we have

j
LT(h j)g j =

j
d j XŒ¥‚àí¬µ( j)S(g j, g j+1)
=

j
d j

i
XŒ¥‚àí¬µ( j)a jigi

=

i

j
d j XŒ¥‚àí¬µ( j)a ji

gi.
If we denote 
j d j XŒ¥‚àí¬µ( j)a ji by h‚Ä≤
i, then

j
LT(h j)g j =

i
h‚Ä≤
igi,
(10)
where, by Eq. (9), Deg(h‚Ä≤
igi) ‚â∫Œ¥ for all i.
Finally, we substitute the expression in Eq. (10) into Eq. (7):
f =

j
Deg(h j g j)=Œ¥
h jg j +

‚Ñì
Deg(h‚Ñìg‚Ñì)‚â∫Œ¥
h‚Ñìg‚Ñì
=

j
Deg(h j g j)=Œ¥
LT(h j)g j +

j
Deg(h j g j)=Œ¥
[h j ‚àíLT(h j)]g j +

‚Ñì
Deg(h‚Ñìg‚Ñì)‚â∫Œ¥
h‚Ñìg‚Ñì
=

i
h‚Ä≤
igi +

j
Deg(h j g j)=Œ¥
[h j ‚àíLT(h j)]g j +

‚Ñì
Deg(h‚Ñìg‚Ñì)‚â∫Œ¥
h‚Ñìg‚Ñì.
We have rewritten f as a linear combination of the gi in which each term has multidegree
strictly smaller than Œ¥, contradicting the minimality of Œ¥. This completes the proof.
‚Ä¢
19The reader may wonder why we consider all S-polynomials S(gp, gq) instead of only those of the form
S(gi, gi+1). The answer is that the remainder condition is applied only to those h j g j for which Deg(h j g j) = Œ¥,
and so the indices viewed as i's need not be consecutive.

Sec. 6.6
Gr¬®obner Bases
417
Corollary 6.135.
If I = ( f1, . . . , fs) in k[X], where each fi is a monomial (that is, if I
is a monomial ideal), then { f1, . . . , fs} is a Gr¬®obner basis of I.
Proof.
By Example 6.132(ii), the S-polynomial of any pair of monomials is 0.
‚Ä¢
Here is the main result: A Gr¬®obner basis of ( f1, . . . , fs) can obtained by adjoining
remainders of S-polynomials.
Theorem 6.136 (Buchberger's Algorithm).
Every ideal I = ( f1, . . . , fs) in k[X] has
a Gr¬®obner basis20 that can be computed by an algorithm.
Proof.
Here is a pseudocode for an algorithm.
Input : B = { f1, . . . , fs}
G = [ f1, . . . , fs]
Output : a Gr¬®obner basis B = {g1, . . . , gm} containing { f1, . . . , fs}
B := { f1, . . . , fs}
G := [ f1, . . . , fs]
REPEAT
B‚Ä≤ := B
G‚Ä≤ := G
FOR each pair g, g‚Ä≤ with g Ã∏= g‚Ä≤ ‚ààB‚Ä≤ DO
r := remainder of S(g, g‚Ä≤) mod G‚Ä≤
IF r Ã∏= 0
THEN B := B ‚à™{r} and G‚Ä≤ = [g1, . . . , gm,r]
UNTIL B = B‚Ä≤
Now each loop of the algorithm enlarges a subset B ‚äÜI = (g1, . . . , gm) by adjoining the
remainder mod G of one of its S-polynomials S(g, g‚Ä≤). As g, g‚Ä≤ ‚ààI, the remainder r of
S(g, g‚Ä≤) lies in I, and so the larger set B ‚à™{r} is contained in I.
The only obstruction to the algorithm's stopping at some B‚Ä≤ is if some S(g, g‚Ä≤) does not
have remainder 0 mod G‚Ä≤. Thus, if the algorithm stops, then Theorem 6.134 shows that B‚Ä≤
is a Gr¬®obner basis.
To see that the algorithm does stop, suppose a loop starts with B‚Ä≤ and ends with B.
Since B‚Ä≤ ‚äÜB, we have an inclusion of monomial ideals

LT(g‚Ä≤): g‚Ä≤ ‚ààB‚Ä≤
‚äÜ(LT(g): g ‚ààB) .
We claim that if B‚Ä≤ ‚ääB, then there is also a strict inclusion of ideals. Suppose that r is a
(nonzero) remainder of some S-polynomial mod B‚Ä≤, and that B = B‚Ä≤ ‚à™{r}. By deÔ¨Ånition,
the remainder r is reduced mod G‚Ä≤, and so no term of r is divisible by LT(g‚Ä≤) for any g‚Ä≤ ‚àà
B‚Ä≤; in particular, LT(r) is not divisible by any LT(g‚Ä≤). Hence, LT(r) /‚àà(LT(g‚Ä≤): g‚Ä≤ ‚ààB‚Ä≤),
by Exercise 6.83 on page 410. On the other hand, we do have LT(r) ‚àà(LT(g): g ‚ààB).
Therefore, if the algorithm does not stop, there is an inÔ¨Ånite strictly ascending chain of
ideals in k[X], and this contradicts the Hilbert basis theorem, for k[X] has the ACC.
‚Ä¢
20A nonconstructive proof of the existence of a Gr¬®obner basis can be given using the proof of the Hilbert basis
theorem; for example, see Section 2.5 of Cox-Little-O'Shea, Ideals, Varieties, and Algorithms (they also give a
constructive proof in Section 2.7).

418
Commutative Rings II
Ch. 6
Example 6.137.
The reader may show that B‚Ä≤ = {y2 + z2, x2y + yz, z3 + xy} is not a Gr¬®obner basis
because S(y2 + z2, x2y + yz) = x2z2 ‚àíy2z does not have remainder 0 mod G‚Ä≤. However,
adjoining x2z2 ‚àíy2z does give a Gr¬®obner basis B because all the S-polynomials in B
[there are
4
2

= 6 of them] have remainder 0 mod B‚Ä≤.
‚óÄ
Theoretically, Buchberger's algorithm computes a Gr¬®obner basis, but the question arises
how practical it is. In very many cases, it does compute in a reasonable amount of time;
on the other hand, there are examples in which it takes a very long time to produce its
output. The efÔ¨Åciency of Buchberger's algorithm is discussed in Section 2.9 of Cox-Little-
O'Shea, Ideals, Varieties, and Algorithms.
Corollary 6.138.
(i) If I = ( f1, . . . , ft) is an ideal in k[X], then there is an algorithm to determine
whether a polynomial h(X) ‚ààk[X] lies in I.
(ii) If I = ( f1, . . . , ft) ‚äÜk[X], then there is an algorithm to determine whether a
polynomial g(X) ‚ààk[X] lies in
‚àö
I.
(iii) If I = ( f1, . . . , ft) and I ‚Ä≤ = ( f ‚Ä≤
1, . . . , f ‚Ä≤
s) are ideals in k[X], then there is an
algorithm to determine whether I = I ‚Ä≤.
Proof.
(i) Use Buchberger's algorithm to Ô¨Ånd a Gr¬®obner basis B of I, and then use the
division algorithm to compute the remainder of h mod G (where G is any m-tuple arising
from ordering the polynomials in B). By Corollary 6.131(ii), h ‚ààI if and only if r = 0.
(ii) Use Exercise 6.66 on page 398 and then use Buchberger's algorithm to Ô¨Ånd a Gr¬®obner
basis of ( f1, . . . , ft, 1 ‚àíyg) in k[X, y].
(iii) Use Buchberger's algorithm to Ô¨Ånd Gr¬®obner bases {g1, . . . , gm} and {g‚Ä≤
1, . . . , g‚Ä≤
m} of
I and I ‚Ä≤, respectively. By part (i), there is an algorithm to determine whether each g‚Ä≤
j ‚ààI,
and I ‚Ä≤ ‚äÜI if each g‚Ä≤
j ‚ààI. Similarly, there is an algorithm to determine the reverse
inclusion, and so there is an algorithm to determine whether I = I ‚Ä≤.
‚Ä¢
A Gr¬®obner basis B = {g1, . . . , gm} can be too large. For example, it follows from the
very deÔ¨Ånition of Gr¬®obner basis that if f ‚ààI, then B ‚à™{ f } is also a Gr¬®obner basis of I;
thus, we may seek Gr¬®obner bases that are, in some sense, minimal.
DeÔ¨Ånition.
A basis {g1, . . . , gm} of an ideal I is reduced if
(i) each gi is monic;
(ii) each gi is reduced mod {g1, . . . , gi, . . . , gm}.
Exercise 6.90 on page 421 gives an algorithm for computing a reduced basis for every
ideal ( f1, . . . , ft). When combined with the algorithm in Exercise 6.93 on page 422,

Sec. 6.6
Gr¬®obner Bases
419
it shrinks a Gr¬®obner basis to a reduced Gr¬®obner basis. It can be proved that a reduced
Gr¬®obner basis of an ideal is unique. In the special case when each fi(X) is linear, that is,
fi(X) = ai1x1 + ¬∑ ¬∑ ¬∑ + ainxn.
then the common zeros Var( f1, . . . , ft) are the solutions of a homogeneous system of t
equations in n unknowns. If A = [ai j] is the t √ó n matrix of coefÔ¨Åcients, then it can be
shown that the reduced Gr¬®obner basis corresponds to the row-reduced echelon form for
the matrix A (see Section 10.5 of Becker-Weispfenning, Gr¬®obner Bases). Another special
case occurs when when f1, . . . , ft are polynomials in one variable. The reduced Gr¬®obner
basis obtained from { f1, . . . , ft} turns out to be their gcd, and so the euclidean algorithm
has been generalized to polynomials in several variables.
Corollary 6.138 does not begin by saying "If I is an ideal in k[X]"; instead, it speciÔ¨Åes
a basis: I = ( f1, . . . , ft). The reason, of course, is that Buchberger's algorithm requires a
basis as input. For example, if J = (h1, . . . , hs), then the algorithm cannot be used directly
to check whether a polynomial f (X) lies in the radical
‚àö
J, for we do not have a basis of
‚àö
J. The book of Becker-Weispfenning, Gr¬®obner Bases, gives an algorithm computing a
basis of
‚àö
J (page 393) when k satisÔ¨Åes certain conditions. There is no algorithm known
that computes the associated primes of an ideal, although there are algorithms to do some
special cases of this general problem. As we mentioned at the beginning of this section, if
an ideal I has a primary decomposition I = Q1‚à©¬∑ ¬∑ ¬∑‚à©Qr, then the associated prime Pi has
the form ‚àö(I : ci) for any ci ‚àà
jÃ∏=i Q j and ci /‚ààQi. There is an algorithm computing
a basis of colon ideals (Becker-Weispfenning, Gr¬®obner Bases, page 266). Thus, we could
compute Pi if there were an algorithm Ô¨Ånding elements ci. For a survey of applications of
Gr¬®obner bases to various parts of mathematics, the reader should see Buchberger-Winkler,
Gr¬®obner Bases and Applications.
We end this chapter by showing how to Ô¨Ånd a basis of an intersection of ideals.
Given a system of polynomial equations in several variables, one way to Ô¨Ånd solutions
is to eliminate variables (van der Waerden, Modern Algebra II, Chapter XI). Given an ideal
I ‚äÜk[X], we are led to an ideal in a subset of the indeterminates, which is essentially the
intersection of Var(I) with a lower-dimensional plane.
DeÔ¨Ånition.
Let k be a Ô¨Åeld and let I ‚äÜk[X, Y] be an ideal, where k[X, Y] is the poly-
nomial ring in disjoint sets of variables X ‚à™Y. The elimination ideal is
IX = I ‚à©k[X].
For example, if I = (x2, xy), then a Gr¬®obner basis is {x2, xy} (they are monomials, so
that Corollary 6.135 applies), and Ix = (x2) ‚äÜk[x], while Iy = {0}.
Proposition 6.139.
Let k be a Ô¨Åeld and let k[X] = k[x1, . . . , xn] have a monomial order
for which x1 ‚âªx2 ‚âª¬∑ ¬∑ ¬∑ ‚âªxn (for example, the lexicographic order) and, for Ô¨Åxed p > 1,
let Y = x p, . . . , xn. If I ‚äÜk[X] has a Gr¬®obner basis G = {g1, . . . , gm}, then G ‚à©IY is a
Gr¬®obner basis for the elimination ideal IY = I ‚à©k[x p, . . . , xn].

420
Commutative Rings II
Ch. 6
Proof.
Recall that {g1, . . . , gm} being a Gr¬®obner basis of I = (g1, . . . , gm) means that for
each nonzero f ‚ààI, there is gi with LT(gi) | LT( f ). Let f (x p, . . . , xn) ‚ààIY be nonzero.
Since IY ‚äÜI, there is some gi(X) with LT(gi) | LT( f ); hence, LT(gi) involves only
the "later" variables x p, . . . , xn. Let Deg(LT(gi)) = Œ≤. If gi has a term cŒ± XŒ± involving
"early" variables xi with i < p, then Œ± ‚âªŒ≤, because x1 ‚âª¬∑ ¬∑ ¬∑ ‚âªx p ‚âª¬∑ ¬∑ ¬∑ ‚âªxn. This is a
contradiction, for Œ≤, the Degree of the leading term of gi, is greater than the Degree of any
other term of gi. It follows that gi ‚ààk[x p, . . . , xn]. Exercise 6.92 on page 422 now shows
that G ‚à©k[x p, . . . , xn] is a Gr¬®obner basis for IY = I ‚à©k[x p, . . . , xn].
‚Ä¢
We can now give Gr¬®obner bases of intersections of ideals.
Proposition 6.140.
Let k be a Ô¨Åeld, and let I1, . . . , It be ideals in k[X], where X =
x1, . . . , xn.
(i) Consider the polynomial ring k[X, y1, . . . , yt] having a new variable y j for each j
with 1 ‚â§j ‚â§t. If J is the ideal in k[X, y1, . . . , yt] generated by 1 ‚àí(y1 + ¬∑ ¬∑ ¬∑ + yt)
and y j I j, for all j, then  t
j=1 I j = JX.
(ii) Given Gr¬®obner bases of I1, . . . , It, a Gr¬®obner basis of  t
j=1 I j can be computed.
Proof.
(i) If f = f (X) ‚ààJX = J ‚à©k[X], then f ‚ààJ, and so there is an equation
f (X) = g(X, Y)(1 ‚àí

y j) +

j
h j(X, y1, . . . , yt)y jq j(X),
where g, h j ‚ààk[X, Y] and q j ‚ààI j. Setting y j = 1 and the other y's equal to 0 gives f =
h j(X, 0, . . . , 1, . . . , 0)q j(X). Note that h j(X, 0, . . . , 1, . . . , 0) ‚ààk[X], and so f ‚ààI j.
As j was arbitrary, we have f ‚àà I j, and so JX ‚äÜ I j.
For the reverse inclusion, if f ‚àà I j, then the equation
f = f (1 ‚àí

y j) +

j
y j f
shows that f ‚ààJX, as desired.
(ii) This follows from part (i) and Proposition 6.139 if we use a monomial order in which
all the variables in X precede the variables in Y.
‚Ä¢
Example 6.141.
Consider the ideal I = (x) ‚à©(x2, xy, y2) ‚äÜk[x, y], where k is a Ô¨Åeld, that we considered
in Example 6.117(ii). Even though it is not difÔ¨Åcult to Ô¨Ånd a basis of I by hand, we shall
use Gr¬®obner bases to illustrate Proposition 6.140. Let u and v be new variables, and deÔ¨Åne
J = (1 ‚àíu ‚àív, ux, vx2, vxy, vy2) ‚äÜk[x, y, u, v].
The Ô¨Årst step is to Ô¨Ånd a Gr¬®obner basis of J; we use the lex monomial order with x ‚â∫y ‚â∫
u ‚â∫v. Since the S-polynomial of two monomials is 0, Buchberger's algorithm quickly

Sec. 6.6
Gr¬®obner Bases
421
gives a Gr¬®obner basis21 G of J:
G = {v + u ‚àí1, x2, yx, ux, uy2 ‚àíy2}.
It follows from Proposition 6.139 that a Gr¬®obner basis of I is G‚à©k[x, y]: all those elements
of G that do not involve the variables u and v. Thus,
I = (x) ‚à©(x2, xy, y2) = (x2, xy).
‚óÄ
We mention that Gr¬®obner bases can be adapted to noncommutative rings. A. I. Shirsov
began investigating whether there are analogs holding for rings of polynomials in several
noncommuting variables, with the aim of implementing algorithms to solve problems in
Lie algebras.
EXERCISES
Use the degree-lexicographic monomial order in the following exercises.
6.85 Let I = (y ‚àíx2, z ‚àíx3).
(i) Order x ‚â∫y ‚â∫z, and let ‚™Ølex be the corresponding monomial order on N 3. Prove that
[y ‚àíx2, z ‚àíx3] is not a Gr¬®obner basis of I.
(ii) Order y ‚â∫z ‚â∫x, and let ‚™Ølex be the corresponding monomial order on N 3. Prove that
[y ‚àíx2, z ‚àíx3] is a Gr¬®obner basis of I.
6.86 Find a Gr¬®obner basis of I = (x2 ‚àí1, xy2 ‚àíx).
6.87 Find a Gr¬®obner basis of I = (x2 + y, x4 + 2x2y + y2 + 3).
6.88 Find a Gr¬®obner basis of I = (xz, xy ‚àíz, yz ‚àíx). Does x3 + x + 1 lie in I?
6.89 Find a Gr¬®obner basis of I = (x2 ‚àíy, y2 ‚àíx, x2y2 ‚àíxy). Does x4 + x + 1 lie in I?
6.90 Show that the following pseudocode gives a reduced basis Q of an ideal I = ( f1, . . . , ft).
Input: P = [ f1, . . . , ft]
Output: Q = [q1, . . . , qs]
Q := P
WHILE there is q ‚ààQ which is
not reduced mod Q ‚àí{q} DO
select q ‚ààQ which is not reduced mod Q ‚àí{q}
Q := Q ‚àí{q}
h := the remainder of q mod Q
IF h Ã∏= 0 THEN
Q := Q ‚à™{h}
END IF
END WHILE
make all q ‚ààQ monic
21This is actually the reduced Gr¬®obner basis given by Exercise 6.93 on page 422.

422
Commutative Rings II
Ch. 6
6.91 If G is a Gr¬®obner basis of an ideal I, and if Q is the basis of I obtained from the algorithm in
Exercise 6.90, prove that Q is also a Gr¬®obner basis of I.
6.92 Let I be an ideal in k[X], where k is a Ô¨Åeld and k[X] has a monomial order. Prove that if a set
of polynomials {g1, . . . , gm} ‚äÜI has the property that, for each nonzero f ‚ààI, there is some
gi with LT(gi) | LT( f ), then I = (g1, . . . , gm). Conclude, in the deÔ¨Ånition of Gr¬®obner basis,
that one need not assume that I is generated by g1, . . . , gm.
6.93 Show that the following pseudocode replaces a Gr¬®obner basis G with a reduced Gr¬®obner ba-
sis H.
Input: G = {g1, . . . , gm}
Output: H
H := ‚àÖ;
F := G
WHILE F Ã∏= ‚àÖDO
select f ‚Ä≤ from F
F := F ‚àí{ f ‚Ä≤}
IF LT( f ) ‚à§LT( f ‚Ä≤) for all f ‚ààF AND
LT(h) ‚à§LT( f ‚Ä≤) for all h ‚ààH THEN
H := H ‚à™{ f ‚Ä≤}
END IF
END WHILE
apply the algorithm in Exercise 6.90 to H

7
Modules and Categories
We now introduce R-modules, where R is a commutative ring; formally, they generalize
vector spaces in the sense that scalars are allowed to be in R instead of a Ô¨Åeld. If R is a
PID, then we shall see, in Chapter 9, that classiÔ¨Åcation of Ô¨Ånitely generated R-modules
simultaneously gives a classiÔ¨Åcation of all Ô¨Ånitely generated abelian groups as well as a
classiÔ¨Åcation of all linear transformations on a Ô¨Ånite-dimensional vector space by canonical
forms. After introducing noncommutative rings in Chapter 8, we will deÔ¨Åne modules over
these rings, and they will be used, in an essential way, to prove that every Ô¨Ånite group of
order pmqn, where p and q are primes, is a solvable group.
Categories and functors Ô¨Årst arose in algebraic topology, where topological spaces and
continuous maps are studied by means of certain algebraic systems (homology groups,
cohomology rings, homotopy groups) associated to them. Categorical notions have proven
to be valuable in purely algebraic contexts as well; indeed, it is fair to say that the recent
great strides in algebraic geometry could not have occurred outside a categorical setting.
7.1 MODULES
An R-module is just a "vector space over a ring R"; that is, in the deÔ¨Ånition of vector
space, allow the scalars to be in R instead of in a Ô¨Åeld.
DeÔ¨Ånition.
Let R be a commutative ring. An R-module is an (additive) abelian group M
equipped with a scalar multiplication R √ó M ‚ÜíM, denoted by
(r, m) ‚Üírm,
such that the following axioms hold for all m, m‚Ä≤ ‚ààM and all r,r‚Ä≤, 1 ‚ààR:
(i) r(m + m‚Ä≤) = rm + rm‚Ä≤;
(ii) (r + r‚Ä≤)m = rm + r‚Ä≤m;
(iii) (rr‚Ä≤)m = r(r‚Ä≤m);
(iv) 1m = m.
423

424
Modules and Categories
Ch. 7
Remark.
This deÔ¨Ånition also makes sense for noncommutative rings R, in which case
M is called a left R-module.
‚óÄ
Example 7.1.
(i) Every vector space over a Ô¨Åeld k is a k-module.
(ii) By the laws of exponents, Proposition 2.23, every abelian group is a Z-module.
(iii) Every commutative ring R is a module over itself if we deÔ¨Åne scalar multiplication
R √ó R ‚ÜíR to be the given multiplication of elements of R. More generally, every ideal
I in R is an R-module, for if i ‚ààI and r ‚ààR, then ri ‚ààI.
(iv) If S is a subring of a commutative ring R, then R is an S-module, where scalar multi-
plication S √ó R ‚ÜíR is just the given multiplication (s,r) ‚Üísr. For example, if k is a
commutative ring, then k[X] is a k-module.
(v) Let T : V ‚ÜíV be a linear transformation, where V is a Ô¨Ånite-dimensional vector space
over a Ô¨Åeld k. The vector space V can be made into a k[x]-module if scalar multiplication
k[x] √ó V ‚ÜíV is deÔ¨Åned as follows: If f (x) = m
i=0 ci xi lies in k[x], then
f (x)v =
 m

i=0
ci xi
v =
m

i=0
ciT i(v),
where T 0 is the identity map 1V , and T i is the composite of T with itself i times if i ‚â•1.
We denote V viewed as a k[x]-module by V T .
Here is a special case of this construction. Let A be an n √ó n matrix with entries in k,
and let T : kn ‚Üíkn be the linear transformation T (w) = Aw, where w is an n √ó1 column
vector and Aw is matrix multiplication. Now the vector space kn is a k[x]-module if we
deÔ¨Åne scalar multiplication k[x] √ó kn ‚Üíkn as follows: If f (x) = m
i=0 ci xi ‚ààk[x], then
f (x)w =
 m

i=0
ci xi
w =
m

i=0
ci Aiw,
where A0 = I is the identity matrix, and Ai is the ith power of A if i ‚â•1. We now
show that (kn)T = (kn)A. Both modules are comprised of the same elements (namely,
all n-tuples), and the scalar multiplications coincide: In (kn)T , we have xw = T (w); in
(kn)A, we have xw = Aw; these are the same because T (w) = Aw.
‚óÄ
Here is the appropriate notion of homomorphism.
DeÔ¨Ånition.
If R is a ring and M and N are R-modules, then a function f : M ‚ÜíN is an
R-homomorphism (or R-map) if, for all m, m‚Ä≤ ‚ààM and all r ‚ààR,
(i) f (m + m‚Ä≤) = f (m) + f (m‚Ä≤);
(ii) f (rm) = r f (m).

Sec. 7.1
Modules
425
If an R-homomorphism is a bijection, then it is called an R-isomorphism; R-modules
M and N are called isomorphic, denoted by M ‚àº= N, if there is some R-isomorphism
f : M ‚ÜíN.
Note that the composite of R-homomorphisms is an R-homomorphism and, if f is an
R-isomorphism, then its inverse function f ‚àí1 is also an R-isomorphism.
Example 7.2.
(i) If R is a Ô¨Åeld, then R-modules are vector spaces and R-maps are linear transformations.
Isomorphisms here are nonsingular linear transformations.
(ii) By Example 7.1(ii), Z-modules are just abelian groups, and Lemma 2.52 shows that
every homomorphism of (abelian) groups is a Z-map.
(iii) If M is an R-module and r ‚ààR, then multiplication by r (or homothety by r) is the
function ¬µr : M ‚ÜíM given by m ‚Üírm.
The functions ¬µr are R-maps because R is commutative: If a ‚ààR and m ‚ààM, then
¬µr(am) = ram while a¬µr(m) = arm.
(iv) Let T : V ‚ÜíV be a linear transformation on a vector space V over a Ô¨Åeld k, let
v1, . . . , vn be a basis of V , and let A be the matrix of T relative to this basis. We now show
that the two k[x]-modules V T and (kn)A are isomorphic.
DeÔ¨Åne œï : V ‚Üíkn by œï(vi) = ei, where e1, . . . , en is the standard basis of kn; the
linear transformation œï is an isomorphism of vector spaces. To see that œï is a k[x]-map, it
sufÔ¨Åces to prove that œï( f (x)v) = f (x)œï(v) for all f (x) ‚ààk[x] and all v ‚ààV . Now
œï(xvi) = œï(T (vi))
= œï

a jiv j

=

a jiœï(v j)
=

a jie j,
which is the ith column of A. On the other hand,
xœï(vi) = Aœï(vi) = Aei,
which is also the ith column of A. It follows that œï(xv) = xœï(v) for all v ‚ààV , and we
can easily prove, by induction on deg( f ), that œï( f (x)v) = f (x)œï(v) for all f (x) ‚ààk[x]
and all v ‚ààV .
‚óÄ
The next proposition generalizes the last example.
Proposition 7.3.
Let V be a vector space over a Ô¨Åeld k, and let T, S : V ‚ÜíV be
linear transformations. Then the k[x]-modules V T and V S in Example 7.1(v) are k[x]-
isomorphic if and only if there is a vector space isomorphism œï : V ‚ÜíV with
S = œïT œï‚àí1.

426
Modules and Categories
Ch. 7
Proof.
If œï : V T ‚ÜíV S is a k[x]-isomorphism, then œï : V ‚ÜíV is an isomorphism of
vector spaces with
œï( f (x)v) = f (x)œï(v)
for all v ‚ààV and all f (x) ‚ààk[x]. In particular, if f (x) = x, then
œï(xv) = xœï(v).
But the deÔ¨Ånition of scalar multiplication in V T is xv = T (v), while the deÔ¨Ånition of
scalar multiplication in V S is xv = S(v). Hence, for all v ‚ààV , we have
œï(T (v)) = S(œï(v)).
Therefore,
œïT = Sœï.
As œï is an isomorphism, we have the desired equation S = œïT œï‚àí1.
Conversely, we may assume œï( f (x)v) = f (x)œï(v) in the special cases deg( f ) ‚â§1:
œï(xv) = œïT (v) = Sœï(v) = xœï(v).
Next, an easy induction shows that œï(xnv) = xnœï(v), and a second easy induction, on
deg( f ), shows that œï( f (x)v) = f (x)œï(v).
‚Ä¢
It is worthwhile making a special case of the proposition explicit. The next corollary
shows how comfortably similarity of matrices Ô¨Åts into the language of modules (and we
will see, in Chapter 9, how this contributes to Ô¨Ånding canonical forms).
Corollary 7.4.
Let k be a Ô¨Åeld, and let A and B be n √ón matrices with entries in k. Then
the k[x]-modules (kn)A and (kn)B in Example 7.1(v) are k[x]-isomorphic if and only if
there is a nonsingular matrix P with
B = P AP‚àí1.
Proof.
DeÔ¨Åne T : kn ‚Üíkn by T (y) = Ay, where y ‚ààkn is a column; by Example 7.1(v),
the k[x]-module (kn)T = (kn)A. Similarly, deÔ¨Åne S : kn ‚Üíkn by S(y) = By, and denote
the corresponding k[x]-module by (kn)B. The proposition now gives an isomorphism
œï : V T ‚ÜíV S with
œï(Ay) = Bœï(y).
By Proposition 3.94, there is an n √ó n matrix P with œï(y) = Py for all y ‚ààkn (which is
nonsingular because œï is an isomorphism). Therefore,
P Ay = B Py
for all y ‚ààkn, and so
P A = B P;
hence, B = P AP‚àí1.
Conversely, the nonsingular matrix P gives an isomorphism œï : kn ‚Üíkn by œï(y) = Py
for all y ‚ààkn. The proposition now shows that œï : (kn)A ‚Üí(kn)B is a k[x]-module
isomorphism.
‚Ä¢
Homomorphisms can be added.

Sec. 7.1
Modules
427
DeÔ¨Ånition.
If M and N are R-modules, then
HomR(M, N) = {all R-homomorphisms M ‚ÜíN}.
If f, g ‚ààHomR(M, N), then deÔ¨Åne f + g : M ‚ÜíN by
f + g : m ‚Üíf (m) + g(m).
Proposition 7.5.
If M and N are R-modules, where R is a commutative ring, then
HomR(M, N) is an R-module, where addition has just been deÔ¨Åned, and scalar multi-
plication is given by
r f : m ‚Üíf (rm).
Moreover, there are distributive laws: If p: M‚Ä≤ ‚ÜíM and q : N ‚ÜíN ‚Ä≤, then
( f + g)p = f p + gp
and
q( f + g) = q f + qg
for all f, g ‚ààHomR(M, N).
Proof.
VeriÔ¨Åcation of the axioms in the deÔ¨Ånition of R-module is straightforward, but we
present the proof of
(rr‚Ä≤) f = r(r‚Ä≤ f )
because it uses commutativity of R.
If m ‚ààM, then (rr‚Ä≤) f : m ‚Üíf (rr‚Ä≤m). On the other hand, r(r‚Ä≤ f ): m ‚Üí(r‚Ä≤ f )(rm) =
f (r‚Ä≤rm). Since R is commutative, rr‚Ä≤ = r‚Ä≤r, and so (rr‚Ä≤) f = r(r‚Ä≤ f ).
‚Ä¢
Example 7.6.
In linear algebra, a linear functional on a vector space V over a Ô¨Åeld k is a linear trans-
formation œï : V ‚Üík [after all, k is a (one-dimensional) vector space over itself]. For
example, if
V = {continuous f : [0, 1] ‚ÜíR},
then integration, f ‚Üí
 1
0 f (t) dt, is a linear functional on V .
If V is a vector space over a Ô¨Åeld k, then its dual space is the set of all linear functionals
on V :
V ‚àó= Homk(V, k).
By the proposition, V ‚àóis also a k-module; that is, V ‚àóis a vector space over k.
‚óÄ
We now show that constructions made for abelian groups and for vector spaces can also
be made for modules. A submodule S is an R-module contained in a larger R-module M
such that if s, s‚Ä≤ ‚ààS and r ‚ààR, then s + s‚Ä≤ and rs have the same meaning in S as in M.
DeÔ¨Ånition.
If M is an R-module, then a submodule N of M, denoted by N ‚äÜM, is an
additive subgroup N of M closed under scalar multiplication: rn ‚ààN whenever n ‚ààN
and r ‚ààR.

428
Modules and Categories
Ch. 7
Example 7.7.
(i) Both {0} and M are submodules of a module M. A proper submodule of M is a
submodule N ‚äÜM with N Ã∏= M. In this case, we may write N ‚ääM.
(ii) If a commutative ring R is viewed as a module over itself, then a submodule of R is an
ideal; I is a proper submodule when it is a proper ideal.
(iii) A submodule of a Z-module (i.e., of an abelian group) is a subgroup, and a submodule
of a vector space is a subspace.
(iv) A submodule W of V T , where T : V ‚ÜíV is a linear transformation, is a subspace W
of V with T (W) ‚äÜW (it is clear that a submodule has this property; the converse is left as
an exercise for the reader). Such a subspace is called an invariant subspace.
(v) If M is an R-module and r ‚ààR, then
r M = {rm : m ‚ààM}
is a submodule of M.
Here is a related construction. If J is an ideal in R and M is an R-module, then
J M =

i
jimi : ji ‚ààJ and mi ‚ààM

is a submodule of M.
(vi) If S and T are submodules of a module M, then
S + T = {s + t : s ‚ààS and t ‚ààT }
is a submodule of M which contains S and T .
(vii) If {Si : i ‚ààI} is a family of submodules of a module M, then 
i‚ààI Si is a submodule
of M.
(viii) If M is an R-module and m ‚ààM, then the cyclic submodule generated by m, denoted
by ‚ü®m‚ü©, is
‚ü®m‚ü©= {rm : r ‚ààR}.
More generally, if X is a subset of an R-module M, then
‚ü®X‚ü©=

Ô¨Ånite
ri xi : ri ‚ààR and xi ‚ààX

,
the set of all R-linear combinations of elements in X. We call ‚ü®X‚ü©the submodule gener-
ated by X. See Exercise 7.2 on page 440.
‚óÄ
DeÔ¨Ånition.
A module M is Ô¨Ånitely generated if M is generated by a Ô¨Ånite set; that is, if
there is a Ô¨Ånite subset X = {x1, . . . , xn} with M = ‚ü®X‚ü©.
For example, a vector space is Ô¨Ånitely generated if and only if it is Ô¨Ånite-dimensional.
We continue extending deÔ¨Ånitions from abelian groups and vector spaces to modules.

Sec. 7.1
Modules
429
DeÔ¨Ånition.
If f : M ‚ÜíN is an R-map between R-modules, then
kernel f = ker f = {m ‚ààM : f (m) = 0}
and
image f = im f = {n ‚ààN : there exists m ‚ààM with n = f (m)}.
It is routine to check that ker f is a submodule of M and that im f is a submodule of
N. Suppose that M = ‚ü®X‚ü©; that is, M is generated by a subset X. Suppose further that N
is a module and that f, g : M ‚ÜíN are R-homomorphisms. If f and g agree on X [that
is, if f (x) = g(x) for all x ‚ààX], then f = g. The reason is that f ‚àíg : M ‚ÜíN, deÔ¨Åned
by f ‚àíg : m ‚Üíf (m) ‚àíg(m), is an R-homomorphism with X ‚äÜker( f ‚àíg). Therefore,
M = ‚ü®X‚ü©‚äÜker( f ‚àíg), and so f ‚àíg is identically zero; that is, f = g.
DeÔ¨Ånition.
If N is a submodule of an R-module M, then the quotient module is the
quotient group M/N (remember that M is an abelian group and N is a subgroup) equipped
with the scalar multiplication
r(m + N) = rm + N.
The natural map. œÄ : M ‚ÜíM/N, given by m ‚Üím + N, is easily seen to be an R-map.
Scalar multiplication in the deÔ¨Ånition of quotient module is well-deÔ¨Åned: If m + N =
m‚Ä≤ + N, then m ‚àím‚Ä≤ ‚ààN, hence r(m ‚àím‚Ä≤) ‚ààN (because N is a submodule), and so
rm ‚àírm‚Ä≤ ‚ààN and rm + N = rm‚Ä≤ + N.
Theorem 7.8 (First Isomorphism Theorem).
If f : M ‚ÜíN is an R-map of modules,
then there is an R-isomorphism
œï : M/ ker f ‚Üíim f
given by
œï : m + ker f ‚Üíf (m).
Proof.
If we view M and N only as abelian groups, then the Ô¨Årst isomorphism theorem
for groups says that œï : M/ ker f ‚Üíim f is an isomorphism of abelian groups. But œï
is an R-map: œï(r(m + N)) = œï(rm + N) = f (rm); since f is an R-map, however,
f (rm) = r f (m) = rœï(m + N), as desired.
‚Ä¢
The second and third isomorphism theorems are corollaries of the Ô¨Årst one.
Theorem 7.9 (Second Isomorphism Theorem).
If S and T are submodules of a module
M, then there is an R-isomorphism
S/(S ‚à©T ) ‚Üí(S + T )/T.
Proof.
Let œÄ : M ‚ÜíM/T be the natural map, so that ker œÄ = T ; deÔ¨Åne h = œÄ|S, so
that h : S ‚ÜíM/T . Now
ker h = S ‚à©T

430
Modules and Categories
Ch. 7
and
im h = (S + T )/T
[for (S + T )/T consists of all those cosets in M/T having a representative in S]. The Ô¨Årst
isomorphism theorem now applies.
‚Ä¢
Theorem 7.10 (Third Isomorphism Theorem).
If T ‚äÜS ‚äÜM is a tower of submod-
ules, then there is an R-isomorphism
(M/T )/(S/T ) ‚ÜíM/S.
Proof.
DeÔ¨Åne the map g : M/T ‚ÜíM/S to be coset enlargement; that is,
g : m + T ‚Üím + S.
Now g is well-deÔ¨Åned: If m + T = m‚Ä≤ + T , then m ‚àím‚Ä≤ ‚ààT ‚äÜS and m + S = m‚Ä≤ + S.
Moreover,
ker g = S/T
and
im g = M/S.
Again, the Ô¨Årst isomorphism theorem completes the proof.
‚Ä¢
If f : M ‚ÜíN is a map of modules and if S ‚äÜN, then the reader may check that
f ‚àí1(S) = {m ‚ààM : f (m) ‚ààS}
is a submodule of M containing ker f .
Theorem 7.11 (Correspondence Theorem).
If T is a submodule of a module M, then
there is a bijection
œï : {intermediate submodules T ‚äÜS ‚äÜM} ‚Üí{submodules of M/T }
given by
S ‚ÜíS/T.
Moreover, S ‚äÜS‚Ä≤ in M if and only if S/T ‚äÜS‚Ä≤/T in M/T .

Sec. 7.1
Modules
431
M













S‚Ä≤













M/T
S













S‚Ä≤/T
T














S/T
{0}
Proof.
Since every module is an additive abelian group, every submodule is a subgroup,
and so the correspondence theorem for groups, Theorem 2.76, shows that œï is an injection
that preserves inclusions: S ‚äÜS‚Ä≤ in M if and only if S/T ‚äÜS‚Ä≤/T in M/T . The remainder
of this proof is a straightforward adaptation of the proof of Proposition 6.1; we need check
only that additive homomorphisms are now R-maps.
‚Ä¢
Proposition 7.12.
An R-module M is cyclic if and only if M ‚àº= R/I for some ideal I.
Proof.
If M is cyclic, then M = ‚ü®m‚ü©for some m ‚ààM. DeÔ¨Åne f : R ‚ÜíM by f (r) =
rm. Now f is surjective, since M is cyclic, and its kernel is some ideal I. The Ô¨Årst
isomorphism theorem gives R/I ‚àº= M.
Conversely, R/I is cyclic with generator 1 + I, and any module isomorphic to a cyclic
module is itself cyclic.
‚Ä¢
DeÔ¨Ånition.
A module M is simple (or irreducible) if M Ã∏= {0} and M has no proper
nonzero submodules; that is, the only submodules of M are {0} and M.
Example 7.13.
By Proposition 2.107, an abelian group G is simple if and only if G ‚àº= Ip for some
prime p.
‚óÄ
Corollary 7.14.
An R-module M is simple if and only if M ‚àº= R/I, where I is a maximal
ideal.
Proof.
This follows from the correspondence theorem.
‚Ä¢

432
Modules and Categories
Ch. 7
Thus, the existence of maximal ideals guarantees the existence of simple modules.
The notion of direct sum, already discussed for vector spaces and for abelian groups,
extends to modules. Recall that an abelian group G is an internal direct sum of subgroups
S and T if S + T = G and S ‚à©T = {0}, while an external direct sum is the abelian
group whose underlying set is the cartesian product S √ó T and whose binary operation is
pointwise addition; both versions give isomorphic abelian groups. The internal-external
viewpoints persist for modules.
DeÔ¨Ånition.
If S and T are R-modules, where R is a commutative1 ring, then their direct
sum, denoted2 by S ‚äîT , is the cartesian product S √ó T with coordinatewise operations:
(s, t) + (s‚Ä≤, t‚Ä≤) = (s + s‚Ä≤, t + t‚Ä≤);
r(s, t) = (rs,rt),
where s, s‚Ä≤ ‚ààS, t, t‚Ä≤ ‚ààT , and r ‚ààR.
There are injective R-maps ŒªS : S ‚ÜíS ‚äîT and ŒªT : T ‚ÜíS ‚äîT given, respectively,
by ŒªS : s ‚Üí(s, 0) and ŒªT : t ‚Üí(0, t).
Proposition 7.15.
The following statements are equivalent for R-modules M, S, and T .
(i) S ‚äîT ‚àº= M.
(ii) There exist injective R-maps i : S ‚ÜíM and j : T ‚ÜíM such that
M = im i + im j
and
im i ‚à©im j = {0}.
(iii) There exist R-maps i : S ‚ÜíM and j : T ‚ÜíM such that, for every m ‚ààM, there
are unique s ‚ààS and t ‚ààT with
m = is + jt.
(iv) There are R-maps i : S ‚ÜíM, j : T ‚ÜíM, p: M ‚ÜíS, and q : M ‚ÜíT such that
pi = 1S,
qj = 1T ,
pj = 0,
qi = 0, and
ip + jq = 1M.
Remark.
The maps i and j are called injections, and the maps p and q are called projec-
tions. The equations pi = 1S and qj = 1T show that the maps i and j must be injective
(so that im i ‚àº= S and im j ‚àº= T ) and the maps p and q must be surjective.
‚óÄ
1Modules over noncommutative rings are deÔ¨Åned in the next chapter.
2Other common notations are S ‚äïT and S √ó T .

Sec. 7.1
Modules
433
Proof.
(i) ‚áí(ii) Let œï : S ‚äîT ‚ÜíM be an isomorphism, and deÔ¨Åne i = œïŒªS [where
ŒªS : s ‚Üí(s, 0)] and j = œïŒªT [where ŒªT : t ‚Üí(0, t)]. Both i and j are injections, being
the composites of injections. If m ‚ààM, there is a unique ordered pair (s, t) ‚ààS ‚äîT with
m = œï((s, t)). Hence,
m = œï((s, t)) = œï((s, 0) + (0, t)) = œïŒªS(s) + œïŒªT (t) = is + jt ‚ààim i + im j.
If x ‚ààim i ‚à©im j, then is = jt for s ‚ààS and t ‚ààT ; that is, œïŒªS(s) = œïŒªT (t). Since œï is
an isomorphism, we have (s, 0) = ŒªS(s) = ŒªT (t) = (0, t) in S ‚äîT . Therefore, s = 0 = t,
x = 0, and im i ‚à©im j = {0}.
(ii) ‚áí(iii) Given m ‚ààM, an expression of the form m = is + jt exists, by part (ii), and
so we need prove only uniqueness. If also m = is‚Ä≤ + jt‚Ä≤, then i(s ‚àís‚Ä≤) = j(t‚Ä≤ ‚àít) ‚àà
im i ‚à©im j = {0}. Therefore, i(s ‚àís‚Ä≤) = 0 and j(t ‚àít‚Ä≤) = 0. Since i and j are injections,
we have s = s‚Ä≤ and t = t‚Ä≤.
(iii) ‚áí(iv) If m ‚ààM, then there are unique s ‚ààS and t ‚ààT with m = is + jt. The
functions p and q, deÔ¨Åned by
p(m) = s
and
q(m) = t,
are thus well-deÔ¨Åned. It is routine to check that p and q are R-maps and that the Ô¨Årst four
equations in the statement hold (they follow from the deÔ¨Ånitions of p and q). For the last
equation, if m ‚ààM, then m = is + jt, and ip(m) + jq(m) = is + jt = m.
(iv) ‚áí(i) DeÔ¨Åne œï : S ‚äîT ‚ÜíM by œï : (s, t) ‚Üíis + jt. It is easy to see that œï is an
R-map; œï is surjective because 1M = ip + jq. To see that œï is injective, suppose that
œï((s, t)) = 0, so that is = ‚àíjt. Now s = pis = ‚àípjt = 0 and ‚àít = ‚àíqjt = qis = 0,
as desired.
‚Ä¢
Internal direct sum is probably the most important instance of a module isomorphic to
a direct sum.
DeÔ¨Ånition.
If S and T are submodules of a module M, then M is their internal direct
sum if M ‚àº= S ‚äîT with i : S ‚ÜíM and j : T ‚ÜíM the inclusions. We denote an internal
direct sum by
M = S ‚äïT.
In this chapter only, we will use the notation S ‚äîT to denote the external direct sum
(underlying set the cartesian product of all ordered pairs) and the notation M = S ‚äïT to
denote the internal direct sum (S and T submodules of M as just deÔ¨Åned). Later, we shall
write as the mathematical world writes: The same notation S ‚äïT is used for either version
of direct sum.
Here is a restatement of Proposition 7.15 for internal direct sums.
Corollary 7.16.
The following conditions are equivalent for an R-module M with sub-
modules S and T .
(i) M = S ‚äïT .

434
Modules and Categories
Ch. 7
(ii) S + T = M and S ‚à©T = {0}.
(iii) Each m ‚ààM has a unique expression of the form m = s + t for s ‚ààS and t ‚ààT .
Proof.
This follows at once from Proposition 7.15 by taking i and j to be inclusions.
‚Ä¢
DeÔ¨Ånition.
A submodule S of a module M is a direct summand of M if there exists a
submodule T of M with M = S ‚äïT .
The next corollary will connect direct summands with a special type of homomorphism.
DeÔ¨Ånition.
If S is a submodule of an R-module M, then S is a retract of M if there exists
an R-homomorphism œÅ : M ‚ÜíS, called a retraction, with œÅ(s) = s for all s ‚ààS.
Retractions in nonabelian groups arose in Exercise 5.72 on page 318.
Corollary 7.17.
A submodule S of a module M is a direct summand if and only if there
exists a retraction œÅ : M ‚ÜíS.
Proof.
In this case, we let i : S ‚ÜíM be the inclusion. We show that M = S ‚äïT , where
T = ker œÅ. If m ‚ààM, then m = (m ‚àíœÅm) + œÅm. Plainly, œÅm ‚ààim œÅ = S. On the other
hand, œÅ(m ‚àíœÅm) = œÅm ‚àíœÅœÅm = 0, because œÅm ‚ààS and so œÅœÅm = œÅm. Therefore,
M = S + T .
If m ‚ààS, then œÅm = m; if m ‚ààT = ker œÅ, then œÅm = 0. Hence, if m ‚ààS ‚à©T , then
m = 0. Therefore, S ‚à©T = {0}, and M = S ‚äïT .
For the converse, if M = S ‚äïT , then each m ‚ààM has a unique expression of the form
m = s + t, where s ‚ààS and t ‚ààT , and it is easy to check that œÅ : M ‚ÜíS, deÔ¨Åned by
œÅ : s + t ‚Üís, is a retraction M ‚ÜíS.
‚Ä¢
Corollary 7.18.
If M = S ‚äïT and S ‚äÜA ‚äÜM, then A = S ‚äï(A ‚à©T ).
Proof.
Let œÅ : M ‚ÜíS be the retraction s + t ‚Üís. Since S ‚äÜA, the restriction
œÅ|A: A ‚ÜíS is a retraction with ker œÅ|A = A ‚à©T .
‚Ä¢
The direct sum construction can be extended to Ô¨Ånitely many submodules. There is an
external and internal version.
DeÔ¨Ånition.
Let S1, . . . , Sn be R-modules. DeÔ¨Åne the external direct sum
S1 ‚äî¬∑ ¬∑ ¬∑ ‚äîSn
to be the R-module whose underlying set is the cartesian product S1 √ó ¬∑ ¬∑ ¬∑ √ó Sn and whose
operations are
(s1, . . . , sn) + (s‚Ä≤
1, . . . , s‚Ä≤
n) = (s1 + s‚Ä≤
1, . . . , sn + s‚Ä≤
n)
r(s1, . . . , sn) = (rs1, . . . ,rsn).

Sec. 7.1
Modules
435
Let M be a module, and let S1, . . . , Sn be submodules of M. DeÔ¨Åne M to be the internal
direct sum
M = S1 ‚äï¬∑ ¬∑ ¬∑ ‚äïSn
if each m ‚ààM has a unique expression of the form m = s1 + ¬∑ ¬∑ ¬∑ + sn, where si ‚ààSi for
all i = 1, . . . , n.
We let the reader prove that both internal and external versions, when the former is
deÔ¨Åned, are isomorphic.
For example, if V is an n-dimensional vector space over a Ô¨Åeld k, and if v1, . . . , vn is a
basis, then
V = ‚ü®v1‚ü©‚äï¬∑ ¬∑ ¬∑ ‚äï‚ü®vn‚ü©.
If S1, . . . , Sn are submodules of a module M, when is ‚ü®S1, . . . , Sn‚ü©, the submodule
generated by the Si, equal to their direct sum? A common mistake is to say that it is
enough to assume that Si ‚à©Sj = {0} for all i Ã∏= j, but Example 5.3 on page 251 shows
that this is not enough.
Proposition 7.19.
Let M = S1 + ¬∑ ¬∑ ¬∑ + Sn, where the Si are submodules; that is, each
m ‚ààM has a (not necessarily unique) expression of the form
m = s1 + ¬∑ ¬∑ ¬∑ + sn,
where si ‚ààSi for all i. Then M = S1 ‚äï¬∑ ¬∑ ¬∑ ‚äïSn if and only if, for each i,
Si ‚à©‚ü®S1 + ¬∑ ¬∑ ¬∑ + Si + ¬∑ ¬∑ ¬∑ + Sn‚ü©= {0},
where Si means that the term Si is omitted from the sum.
Proof.
A straightforward adaptation of Proposition 5.4. See Exercise 7.79 on page 519
for the generalization of this proposition for inÔ¨Ånitely many submodules.
‚Ä¢
Here is the last deÔ¨Ånition in this dictionary of modules.
DeÔ¨Ånition.
A sequence of R-maps and R-modules
¬∑ ¬∑ ¬∑ ‚ÜíMn+1
fn+1
‚àí‚ÜíMn
fn
‚àí‚ÜíMn‚àí1 ‚Üí¬∑ ¬∑ ¬∑
is called an exact sequence3 if im fn+1 = ker fn for all n.
Observe that there is no need to label an arrow 0
f‚ÜíA or B
g‚Üí0 for, in either case,
there is a unique map, namely, f : 0 ‚Üí0 or the constant homomorphism g(b) = 0 for all
b ‚ààB.4
Here are some simple consequences of a sequence of homomorphisms being exact.
3This terminology comes from advanced calculus, where a differential form œâ is called closed if dœâ = 0 and
it is called exact if œâ = dh for some function h (see Proposition 9.146 on page 753). The term was coined by the
algebraic topologist W. Hurewicz. It is interesting to look at the book by Hurewicz-Wallman, Dimension Theory,
which was written just before this coinage. We can see there many results that would have been much simpler to
state had the word exact been available.
4In diagrams, we usually write 0 instead of {0}.

436
Modules and Categories
Ch. 7
Proposition 7.20.
(i) A sequence 0 ‚ÜíA
f‚ÜíB is exact if and only if f is injective.
(ii) A sequence B
g‚ÜíC ‚Üí0 is exact if and only if g is surjective.
(iii) A sequence 0 ‚ÜíA
h‚ÜíB ‚Üí0 is exact if and only if h is an isomorphism.
Proof.
(i) The image of 0 ‚ÜíA is {0}, so that exactness gives ker f = {0}, and so f is
injective. Conversely, given f : A ‚ÜíB, there is an exact sequence ker f ‚ÜíA
f
‚àí‚ÜíB. If
f is injective, then ker f = {0}.
(ii) The kernel of C ‚Üí0 is C, so that exactness gives im g = C, and so g is surjective.
Conversely, given g : B ‚ÜíC, there is an exact sequence B
g
‚àí‚ÜíC ‚ÜíC/ im g (see
Exercise 7.13). If g is surjective, then C = im g and C/ im g = {0}.
(iii) Part (i) shows that h is injective if and only if 0 ‚ÜíA
h‚ÜíB is exact; part (ii) shows
that h is surjective if and only if A
h‚ÜíB ‚Üí0 is exact. Therefore, h is an isomorphism if
and only if the sequence 0 ‚ÜíA
h‚ÜíB ‚Üí0 is exact.
‚Ä¢
We can restate the isomorphism theorems in the language of exact sequences.
DeÔ¨Ånition.
A short exact sequence is an exact sequence of the form
0 ‚ÜíA
f‚ÜíB
g‚ÜíC ‚Üí0.
We also call this short exact sequence an extension of A by C.
Some authors call this an extension of C by A; some authors say that the middle module
B is an extension.
Proposition 7.21.
(i) If 0 ‚ÜíA
f‚ÜíB
g‚ÜíC ‚Üí0 is a short exact sequence, then
A ‚àº= im f
and
B/ im f ‚àº= C.
(ii) If T ‚äÜS ‚äÜM is a tower of submodules, then there is an exact sequence
0 ‚ÜíS/T
f‚ÜíM/T
g‚ÜíM/S ‚Üí0.
Proof.
(i) Since f is injective, it is an isomorphism A ‚Üíim f . The Ô¨Årst isomorphism
theorem gives B/ ker g ‚àº= im g. By exactness, however, ker g = im f and im g = C;
therefore, B/ im f ‚àº= C.
(ii) This is just a restatement of the third isomorphism theorem. DeÔ¨Åne f : S/T ‚ÜíM/T
to be the inclusion, and deÔ¨Åne g : M/T ‚ÜíM/S be "coset enlargement:" g : m + T ‚Üí
m + S. As in the proof of Theorem 7.10, g is surjective, and ker g = S/T = im f .
‚Ä¢

Sec. 7.1
Modules
437
In the special case when A is a submodule of B and f : A ‚ÜíB is the inclusion, then
exactness of 0 ‚ÜíA
f‚ÜíB
g‚ÜíC ‚Üí0 gives B/A ‚àº= C.
DeÔ¨Ånition.
A short exact sequence
0 ‚ÜíA
i
‚àí‚ÜíB
p
‚àí‚ÜíC ‚Üí0
is split if there exists a map j : C ‚ÜíB with pj = 1C.
Proposition 7.22.
If an exact sequence
0 ‚ÜíA
i‚ÜíB
p‚ÜíC ‚Üí0
is split, then B ‚àº= A ‚äîC.
Remark.
Exercise 7.17 on page 441 characterizes split short exact sequences.
‚óÄ
Proof.
We show that B = im i ‚äïim j, where j : C ‚ÜíB satisÔ¨Åes pj = 1C. If b ‚ààB,
then pb ‚ààC and b ‚àíjpb ‚ààker p, for p(b ‚àíjpb) = pb ‚àípj(pb) = 0 because pj = 1C.
By exactness, there is a ‚ààA with ia = b‚àíjpb. It follows that B = im i +im j. It remains
to prove im i ‚à©im j = {0}. If ia = x = jc, then px = pia = 0, because pi = 0, whereas
px = pjc = c, because pj = 1C. Therefore, x = jc = 0, and so B ‚àº= A ‚äîC.
‚Ä¢
The converse of the last proposition is not true. Let A = ‚ü®a‚ü©, B = ‚ü®b‚ü©, and C = ‚ü®c‚ü©be
cyclic groups of orders 2, 4, and 2, respectively. If i : A ‚ÜíB is deÔ¨Åned by i(a) = 2b and
p: B ‚ÜíC is deÔ¨Åned by p(b) = c, then 0 ‚ÜíA
i
‚àí‚ÜíB
p
‚àí‚ÜíC ‚Üí0 is an exact sequence
which is not split: im i = ‚ü®2b‚ü©is not even a pure subgroup of B. By Exercise 7.12 on
page 440, for any abelian group M, there is an exact sequence
0 ‚ÜíA
i‚Ä≤
‚àí‚ÜíB ‚äîM
p‚Ä≤
‚àí‚ÜíC ‚äîM ‚Üí0,
where i‚Ä≤(a) = (2b, 0) and p‚Ä≤(b, m) = (c, m), and this sequence does not split either. If
we choose M = I4[x] ‚äîI2[x] (the direct summands are the polynomial rings over I4 and
I2, respectively), then A ‚äî(C ‚äîM) ‚àº= B ‚äîM. (For readers who are familiar with inÔ¨Ånite
direct sums, which we introduce later in this chapter, M is the direct sum of inÔ¨Ånitely many
copies of I4 ‚äîI2.)
Here is a characterization of noetherian rings using these ideas.
Proposition 7.23.
(i) A commutative ring R is noetherian if and only if every submodule of a Ô¨Ånitely
generated R-module M is itself Ô¨Ånitely generated
(ii) If R is a PID and if M can be generated by n elements, then every submodule of M
can be generated by n or fewer elements.

438
Modules and Categories
Ch. 7
Remark.
Proposition 7.23(ii) is not true more generally. For example, if R is not a
PID, there there is some ideal I that is not principal. Thus, R has one generator while its
submodule I cannot be generated by one element.
‚óÄ
Proof.
(i) Assume that every submodule of a Ô¨Ånitely generated R-module is Ô¨Ånitely gen-
erated. In particular, every submodule of R, which is a cyclic R-module and hence Ô¨Ånitely
generated, is Ô¨Ånitely generated. But submodules of R are ideals, and so every ideal is
Ô¨Ånitely generated; that is, R is noetherian.
We prove the converse by induction on n ‚â•1, where M = ‚ü®x1, . . . , xn‚ü©. If n = 1, then
M is cyclic, and so Proposition 7.12 gives M ‚àº= R/I for some ideal I. If S ‚äÜM, then
the correspondence theorem gives an ideal J with I ‚äÜJ ‚äÜR and S ‚àº= J/I. But R is
noetherian, so that J, and hence J/I, is Ô¨Ånitely generated
If n ‚â•1 and M = ‚ü®x1, . . . , xn, xn+1‚ü©, consider the exact sequence
0 ‚ÜíM‚Ä≤
i
‚àí‚ÜíM
p
‚àí‚ÜíM‚Ä≤‚Ä≤ ‚Üí0,
where M‚Ä≤ = ‚ü®x1, . . . , xn‚ü©, M‚Ä≤‚Ä≤ = M/M‚Ä≤, i is the inclusion, and p is the natural map. Note
that M‚Ä≤‚Ä≤ is cyclic, being generated by xn+1 + M‚Ä≤. If S ‚äÜM is a submodule, there is an
exact sequence
0 ‚ÜíS ‚à©M‚Ä≤ ‚ÜíS ‚ÜíS/(S ‚à©M‚Ä≤) ‚Üí0.
Now S ‚à©M‚Ä≤ ‚äÜM‚Ä≤, and hence it is Ô¨Ånitely generated, by the inductive hypothesis. Further-
more, S/(S ‚à©M‚Ä≤) ‚àº= (S + M‚Ä≤)/M‚Ä≤ ‚äÜM/M‚Ä≤, so that S/(S ‚à©M‚Ä≤) is Ô¨Ånitely generated, by
the base step. Using Exercise 7.15 on page 441, we conclude that S is Ô¨Ånitely generated
(ii) We prove the statement by induction on n ‚â•1. If M is cyclic, then M ‚àº= R/I; if
S ‚äÜM, then S ‚àº= J/I for some ideal J in R containing I. Since R is a PID, J is principal,
and so J/I is cyclic.
For the inductive step, we refer to the exact sequence
0 ‚ÜíS ‚à©M‚Ä≤ ‚ÜíS ‚ÜíS/(S ‚à©M‚Ä≤) ‚Üí0
in part (i), where M = ‚ü®x1, . . . , xn, xn+1‚ü©and M‚Ä≤ = ‚ü®x1, . . . , xn‚ü©. By the inductive
hypothesis, S ‚à©M‚Ä≤ can be generated by n or fewer elements, while the base step shows
that S/(S ‚à©M‚Ä≤) is cyclic. Exercise 7.15 on page 441 shows that S can be generated by
n + 1 or fewer elements.
‚Ä¢
The next proposition, whose proof uses Proposition 7.23(ii), shows that the sum and
product of algebraic integers are themselves algebraic integers. If Œ± and Œ≤ are algebraic
integers, it is not too difÔ¨Åcult to give monic polynomials having Œ± + Œ≤ and Œ±Œ≤ as roots, but
it takes a bit of work to Ô¨Ånd such polynomials having all coefÔ¨Åcients in Z (see Pollard, The
Theory of Algebraic Numbers, page 33).
Proposition 7.24.
Let Œ± ‚ààC and deÔ¨Åne Z[Œ±] =

g(Œ±): g(x) ‚ààZ[x]

.
(i) Z[Œ±] is a subring of C.

Sec. 7.1
Modules
439
(ii) A complex number Œ± is an algebraic integer if and only if Z[Œ±] is a Ô¨Ånitely generated
additive abelian group.
(iii) The set of all the algebraic integers is a subring of C.
Proof.
(i) Since 1 = g(Œ±), where g(x) = 1 is a constant polynomial, we have 1 ‚ààZ[Œ±].
If f (Œ±), g(Œ±) ‚ààZ[Œ±], then so is f (Œ±) + g(Œ±) = h(Œ±), where h(x) = f (x) + g(x).
Similarly, f (Œ±)g(Œ±) ‚ààZ[Œ±], and so Z[Œ±] is a subring of C.
(ii) If Œ± is an algebraic integer, there is a monic polynomial f (x) ‚ààZ[x] having Œ± as
a root. We claim that if deg( f ) = n, then Z[Œ±] = G, where G is the set of all linear
combinations m0 + m1Œ± + ¬∑ ¬∑ ¬∑ + mn‚àí1Œ±n‚àí1 with mi ‚ààZ. Clearly, G ‚äÜZ[Œ±]. For the
reverse inclusion, each element u ‚ààZ[Œ±] has the form u = g(Œ±), where g(x) ‚ààZ[x].
Since f (x) is monic, the division algorithm (Corollary 3.22) gives q(x),r(x) ‚ààZ[x] with
g(x) = q(x) f (x) + r(x), where either r(x) = 0 or deg(r) < deg( f ) = n. Therefore,
u = g(Œ±) = q(Œ±) f (Œ±) + r(Œ±) = r(Œ±) ‚ààG.
Thus, the additive group of Z[Œ±] is Ô¨Ånitely generated.
Conversely, if the additive group of the commutative ring Z[Œ±] is Ô¨Ånitely generated,
that is, Z[Œ±] = ‚ü®g1, . . . , gm‚ü©as an abelian group, then each g j is a Z-linear combination of
powers of Œ±. Let m be the largest power of Œ± occurring in any of these g's. Since Z[Œ±] is a
commutative ring, Œ±m+1 ‚ààZ[Œ±]; hence, Œ±m+1 can be expressed as a Z-linear combination
of smaller powers of Œ±; say, Œ±m+1 = m
i=0 biŒ±i, where bi ‚ààZ. Therefore, Œ± is a root of
f (x) = xm+1 ‚àím
i=0 bi xi, which is a monic polynomial in Z[x], and so Œ± is an algebraic
integer.
(iii) Suppose that Œ± and Œ≤ are algebraic integers; let Œ± be a root of a monic f (x) ‚ààZ[x]
of degree n, and let Œ≤ be a root of a monic g(x) ‚ààZ[x] of degree m. Now Z[Œ±Œ≤] is an
additive subgroup of G =

Œ±iŒ≤ j : 0 ‚â§i < n, 0 ‚â§j < m
 
. Since G is Ô¨Ånitely generated, so
is its subgroup Z[Œ±Œ≤], by Proposition 7.23(ii), and so Œ±Œ≤ is an algebraic integer. Similarly,
Z[Œ± + Œ≤] is an additive subgroup of

Œ±iŒ≤ j : i + j ‚â§n + m ‚àí1
 
, and so Œ± + Œ≤ is also an
algebraic integer.
‚Ä¢
This last theorem gives a technique for proving that an integer a is a divisor of an
integer b. If we can prove that b/a is an algebraic integer, then it must be an integer, for it
is obviously rational. This will actually be used in Chapter 8 to prove that the degrees of
the irreducible characters of a Ô¨Ånite group G are divisors of |G|.
EXERCISES
7.1 Let R be a commutative ring. Call an (additive) abelian group M an almost R-module if there
is a function R √ó M ‚ÜíM satisfying all the axioms of an R-module except axiom (iv): We
do not assume that 1m = m for all m ‚ààM.
Prove that
M = M1 ‚äïM0,

440
Modules and Categories
Ch. 7
where
M1 = {m ‚ààM : 1m = m} and M0 = {m ‚ààM : rm = 0 for all r ‚ààR}
are subgroups of M that are almost R-modules; in fact, M1 is an R-module.
7.2 If X is a subset of a module M, prove that ‚ü®X‚ü©, the submodule of M generated by X, is equal
to  S, where the intersection ranges over all those submodules S ‚äÜM containing X.
7.3 Prove that if f : M ‚ÜíN is an R-map and K is a submodule of M with K ‚äÜker f , then f
induces an R-map f : M/K ‚ÜíN by f : m + K ‚Üíf (m).
7.4 Let R be a commutative ring and let J be an ideal in R. Recall that if M is an R-module,
then J M =

i jimi : ji ‚ààJ and mi ‚ààM

is a submodule of M. Prove that M/J M is an
R/J-module if we deÔ¨Åne scalar multiplication:
(r + J)(m + J M) = rm + J M.
Conclude that if J M = {0}, then M itself is an R/J-module; in particular, if J is a maximal
ideal in R and J M = {0}, then M is a vector space over R/J.
7.5 For every R-module M, prove that there is an R-isomorphism
œïM : HomR(R, M) ‚ÜíM,
given by œïM : f ‚Üíf (1).
7.6 Let F = n
i=1 ‚ü®bi‚ü©be a direct sum of R-modules, where fi : R ‚Üí‚ü®bi‚ü©, given by r ‚Üírbi,
is an isomorphism. Prove that if M is a maximal ideal in R, then the cosets {bi + M F : i =
1, . . . , n} form a basis of the vector space F/M F over the Ô¨Åeld R/M. (See Exercise 7.4.)
7.7 Let R and S be commutative rings, and let œï : R ‚ÜíS be a ring homomorphism. If M is an
S-module, prove that M is also an R-module if we deÔ¨Åne
rm = œï(r)m,
for all r ‚ààR and m ‚ààM.
7.8 Let M = S1 ‚äî¬∑ ¬∑ ¬∑ ‚äîSn be a direct sum of R-modules. If Ti ‚äÜSi for all i, prove that
(S1 ‚äî¬∑ ¬∑ ¬∑ ‚äîSn)/(T1 ‚äî¬∑ ¬∑ ¬∑ ‚äîTn) ‚àº= (S1/T1) ‚äî¬∑ ¬∑ ¬∑ ‚äî(Sn/Tn).
7.9 Let R be a commutative ring and let M be a nonzero R-module. If m ‚ààM, deÔ¨Åne ord(m) =
{r ‚ààR : rm = 0}, and deÔ¨Åne F = {ord(m) : m ‚ààM and m Ã∏= 0}. Prove that every maximal
element in F is a prime ideal.
7.10 Let A
f‚ÜíB
g‚ÜíC be a sequence of module maps. Prove that g f = 0 if and only if im f ‚äÜ
ker g. Give an example of such a sequence that is not exact.
7.11 If 0 ‚ÜíM ‚Üí0 is an exact sequence, prove that M = {0}.
7.12 Let 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 be a short exact sequence of modules. If M is any module, prove
that there are exact sequences
0 ‚ÜíA ‚äïM ‚ÜíB ‚äïM ‚ÜíC ‚Üí0
and
0 ‚ÜíA ‚ÜíB ‚äïM ‚ÜíC ‚äïM ‚Üí0.

Sec. 7.1
Modules
441
DeÔ¨Ånition.
If f : M ‚ÜíN is a map, deÔ¨Åne its cokernel, denoted by coker f , as
coker f = N/ im f.
7.13
(i) Prove that a map f : M ‚ÜíN is surjective if and only if coker f = {0}.
(ii) If f : M ‚ÜíN is a map, prove that there is an exact sequence
0 ‚Üíker f ‚ÜíM
f‚ÜíN ‚Üícoker f ‚Üí0.
7.14 If A
f‚ÜíB ‚ÜíC
h‚ÜíD is an exact sequence, prove that f is surjective if and only if h is
injective.
7.15 Let 0 ‚ÜíA
i‚ÜíB
p‚ÜíC ‚Üí0 be a short exact sequence.
(i) Assume that A = ‚ü®X‚ü©and C = ‚ü®Y‚ü©. For each y ‚ààY, choose y‚Ä≤ ‚ààB with p(y‚Ä≤) = y.
Prove that
B =

i(X) ‚à™{y‚Ä≤ : y ‚ààY}
 
.
(ii) Prove that if both A and C are Ô¨Ånitely generated, then B is Ô¨Ånitely generated More
precisely, prove that if A can be generated by m elements and if C can be generated by
n elements, then B can be generated by m + n elements.
7.16 Prove that every short exact sequence of vector spaces is split.
7.17 Prove that a short exact sequence
0 ‚ÜíA
i‚ÜíB
p‚ÜíC ‚Üí0
splits if and only if there exists q : B ‚ÜíA with qi = 1A.
7.18
(i) Prove that a map œï : B ‚ÜíC is injective if and only if œï can be canceled from the left;
that is, for all modules A and all maps f, g: A ‚ÜíB, we have œïf = œïg implies f = g.
A
f
‚áí
g
B
œï‚ÜíC
(ii) Prove that a R-map œï : B ‚ÜíC is surjective if and only if œï can be canceled from the
right; that is, for all R-modules D and all R-maps h, k : C ‚ÜíD, we have hœï = kœï
implies h = k.
B
œï‚ÜíC
h
‚áí
k
D
7.19 (Eilenberg-Moore) Let G be a (possibly nonabelian) group.
(i) If H is a proper subgroup of a group G, prove that there exists a group L and distinct
homomorphisms f, g: G ‚ÜíL with f |H = g|H.
Hint.
DeÔ¨Åne L = SX, where X denotes the family of all the left cosets of H in G
together with an additional element, denoted ‚àû. If a ‚ààG, deÔ¨Åne f (a) = fa ‚ààSX by
fa(‚àû) = ‚àûand fa(bH) = abH. DeÔ¨Åne g: G ‚ÜíSX by g = Œ≥ ‚ó¶f , where Œ≥ ‚ààSX is
conjugation by the transposition (H, ‚àû).
(ii) If A and G are groups, prove that a homomorphism œï : A ‚ÜíG is surjective if and only
if œï can be canceled from the right; that is, for all groups L and all maps f, g: G ‚ÜíL,
we have f œï = gœï implies f = g.
B
œï‚ÜíG
f
‚áí
g
L

442
Modules and Categories
Ch. 7
7.2 CATEGORIES
Imagine a set theory whose primitive terms, instead of set and element, are set and function.
How could we deÔ¨Åne bijection, cartesian product, union, and intersection? Category theory
will force us to think in this way. Now categories are the context for discussing general
properties of systems such as groups, rings, vector spaces, modules, sets, and topological
spaces, in tandem with their respective transformations: homomorphisms, functions, and
continuous maps. There are two basic reasons for studying categories: The Ô¨Årst is that they
are needed to deÔ¨Åne functors and natural transformations (which we will do in the next
sections); the other is that categories will force us to regard a module, for example, not in
isolation, but in a context serving to relate it to all other modules (for example, we will
deÔ¨Åne certain modules as solutions to universal mapping problems).
There are well-known set-theoretic "paradoxes" that show that contradictions arise if
we are not careful about how the undeÔ¨Åned terms set and element are used. For example,
Russell's paradox shows how we can run into trouble by regarding every collection as a
set. DeÔ¨Åne a Russell set to be a set S that is not a member of itself; that is, S /‚ààS. If R
is the family of all Russell sets, is R a Russell set? On the one hand, if R ‚ààR, then R is
not a Russell set; as only Russell sets are members of R, we must have R /‚ààR, and this
is a contradiction. On the other hand, if we assume that R /‚ààR, then R is a Russell set,
and so it belongs to R (which contains every Russell set); again, we have a contradiction.
We conclude that we must impose some conditions on what collections are allowed to be
sets (and also some conditions on the membership relation ‚àà). One way to avoid such
problems is to axiomatize set theory by considering class as a primitive term instead of
set. The axioms give the existence of Ô¨Ånite classes and of N; they also provide rules for
constructing special classes from given ones, and any class constructed according to these
rules is called a set. Cardinality can be deÔ¨Åned, and there is a theorem that a class is a set
if and only if it is "small"; that is, it has a cardinal number. A proper class is deÔ¨Åned to be
a class that is not a set. For example, N, Z, Q, R, and C are sets, while the collection of
all sets is a proper class. Paradoxes are avoided by decreeing that some rules apply only to
sets but not to proper classes.
DeÔ¨Ånition.
A category C consists of three ingredients: a class obj(C) of objects, a set
of morphisms Hom(A, B) for every ordered pair (A, B) of objects, and composition
Hom(A, B) √ó Hom(B, C) ‚ÜíHom(A, C), denoted by
( f, g) ‚Üíg f,
for every ordered triple A, B, C of objects. [We often write f : A ‚ÜíB or A
f‚ÜíB to
denote f ‚ààHom(A, B).] These ingredients are subject to the following axioms:
(i) the Hom sets are pairwise disjoint;5 that is, each morphism has a unique domain and
a unique target;
5One can force pairwise disjointness by labeling morphisms f ‚ààHom(A, B) by A f B.

Sec. 7.2
Categories
443
(ii) for each object A, there is an identity morphism 1A ‚ààHom(A, A) such that
f 1A = f and 1B f = f for all f : A ‚ÜíB;
(iii) composition is associative: Given morphisms
A
f‚ÜíB
g‚ÜíC
h‚ÜíD,
then
h(g f ) = (hg) f.
The important notion, in this circle of ideas, is not category but functor, which will
be introduced in the next section. Categories are necessary because they are an essential
ingredient in the deÔ¨Ånition of functor. A similar situation occurs in linear algebra: Linear
transformation is the important notion, but we must Ô¨Årst consider vector spaces in order to
deÔ¨Åne it.
The following examples will explain certain Ô¨Åne points of the deÔ¨Ånition of category.
Example 7.25.
(i) C = Sets.
The objects in this category are sets (not proper classes), morphisms are functions, and
composition is the usual composition of functions.
A standard result of set theory is that if A and B are sets, then Hom(A, B), the class of
all functions from A to B, is a set. That Hom sets are pairwise disjoint is just the reÔ¨Çection
of the deÔ¨Ånition of equality of functions given in Chapter 1: In order that two functions be
equal, they must, Ô¨Årst, have the same domains and the same targets (and, of course, they
must have the same graphs).
(ii) C = Groups.
Here, objects are groups, morphisms are homomorphisms, and composition is the usual
composition (homomorphisms are functions).
(iii) C = CommRings.
Here, objects are commutative rings, morphisms are ring homomorphisms, and compo-
sition is the usual composition.
(iv) C = RMod.6
The objects in this category are R-modules, where R is a commutative ring, morphisms
are R-homomorphisms, and composition is the usual composition. We denote the sets
Hom(A, B) in RMod by
HomR(A, B).
If R = Z, then we often write
ZMod = Ab
to remind ourselves that Z-modules are just abelian groups.
6When we introduce noncommutative rings in the Chapter 8, then we will denote the category of left R-
modules by RMod and the category of right R-modules by ModR.

444
Modules and Categories
Ch. 7
(v) C = PO(X).
If X is a partially ordered set, regard it as a category whose objects are the elements of
X, whose Hom sets are either empty or have only one element:
Hom(x, y) =

‚àÖ
if x Ã∏‚™Øy
Œ∫x
y
if x ‚™Øy
(the symbol Œ∫x
y denotes the unique element in the Hom set when x ‚™Øy) and whose com-
position is given by
Œ∫ y
z Œ∫x
y = Œ∫x
z .
Note that 1x = Œ∫x
x , by reÔ¨Çexivity, while composition makes sense because ‚™Øis transitive.7
We insisted, in the deÔ¨Ånition of category, that Hom(A, B) be a set, but we left open the
possibility that it be empty. The category PO(X) is an example in which this possibility
occurs. [Not every Hom set in a category C can be empty, for Hom(A, A) Ã∏= ‚àÖfor every
object A ‚ààC because it contains the identity morphism 1A.]
(vi) C = C(G).
If G is a group, then the following description deÔ¨Ånes a category C(G): There is only
one object, denoted by ‚àó, Hom(‚àó, ‚àó) = G, and composition
Hom(‚àó, ‚àó) √ó Hom(‚àó, ‚àó) ‚ÜíHom(‚àó, ‚àó);
that is, G √ó G ‚ÜíG, is the given multiplication in G. We leave veriÔ¨Åcation of the axioms
to the reader.8
The category C(G) has an unusual property. Since ‚àóis merely an object, not a set, there
are no functions ‚àó‚Üí‚àódeÔ¨Åned on it; thus, morphisms here are not functions. Another
curious property of this category is another consequence of there being only one object:
there are no proper subobjects here.
(vii) There are many interesting nonalgebraic examples of categories. For example, C =
Top, the category with objects all topological spaces, morphisms all continuous functions,
and usual composition.
‚óÄ
Here is how to translate isomorphism into categorical language.
DeÔ¨Ånition.
A morphism f : A ‚ÜíB in a category C is an equivalence (or an isomor-
phism) if there exists a morphism g : B ‚ÜíA in C with
g f = 1A
and
f g = 1B.
The morphism g is called the inverse of f .
7A nonempty set X is called quasi-ordered if it has a relation x ‚™Øy that is reÔ¨Çexive and transitive (if, in
addition, this relation is antisymmetric, then X is partially ordered). PO(X) is a category for every quasi-ordered
set.
8That every element in G have an inverse is not needed to prove that C(G) is a category, and C(G) is a category
for every monoid G.

Sec. 7.2
Categories
445
It is easy to see that an inverse of an equivalence is unique.
Identity morphisms in a category are always equivalences. If C = PO(X), where X is
a partially ordered set, then the only equivalences are identities; if C = C(G), where G
is a group (see Example 7.25(vi)), then every morphism is an equivalence. If C = Sets,
then equivalences are bijections; if C = Groups, C = RMod, or C = CommRings, then
equivalences are isomorphisms; if C = Top, then equivalences are homeomorphisms.
Let us give a name to a feature of the category RMod (which we saw in Proposition 7.5)
that is not shared by more general categories: Homomorphisms can be added.
DeÔ¨Ånition.
A category C is pre-additive if every Hom(A, B) is equipped with a binary
operation making it an (additive) abelian group for which the distributive laws hold: for all
f, g ‚ààHom(A, B),
(i) if p: B ‚ÜíB‚Ä≤, then
p( f + g) = pf + pg ‚ààHom(A, B‚Ä≤);
(ii) if q : A‚Ä≤ ‚ÜíA, then
( f + g)q = f q + gq ‚ààHom(A‚Ä≤, B).
In Exercise 7.22 on page 458, it is shown that Groups does not have the structure of a
pre-additive category.
A category is deÔ¨Åned in terms of objects and morphisms; its objects need not be sets,
and its morphisms need not be functions [C(G) in Example 7.25(vi) is such a category].
We now give ourselves the exercise of trying to describe various constructions in Sets or
in RMod so that they make sense in arbitrary categories.
In Proposition 7.15(iii), we gave the following characterization of direct sum M =
A ‚äïB: there are homomorphisms p: M ‚ÜíA, q : M ‚ÜíB, i : A ‚ÜíM, and j : B ‚ÜíM
such that
pi = 1A, qj = 1B, pj = 0, qi = 0
and
ip + jq = 1M.
Even though this description of direct sum is phrased in terms of arrows, it is not general
enough to make sense in every category; it makes use of a property of the category RMod
that is not enjoyed by the category Sets, for example: Morphisms can be added.
In Corollary 7.17, we gave another description of direct sum in terms of arrows:
There is a map œÅ : M ‚ÜíS with œÅs = s; moreover, ker œÅ = im j, im œÅ = im i, and
œÅ(s) = s for every s ‚ààim œÅ.
This description makes sense in Sets, but it does not make sense in arbitrary categories
because the image of a morphism may fail to be deÔ¨Åned. For example, the morphisms in
C(G) [see Example 7.25(vi)] are elements in Hom(‚àó, ‚àó) = G, not functions, and so the
image of a morphism has no obvious meaning.
However, we can deÔ¨Åne direct summand categorically: An object S is (equivalent to) a
retract of an object M if there exist morphisms
i : S ‚ÜíM
and
p: M ‚ÜíS

446
Modules and Categories
Ch. 7
for which pi = 1S and (ip)2 = ip (for modules, deÔ¨Åne œÅ = ip).
One of the nice aspects of thinking in a categorical way is that it enables us to see
analogies that might not have been recognized before. For example, we shall soon see that
direct sum in RMod is the same notion as disjoint union in Sets.
We begin with a very formal deÔ¨Ånition.
DeÔ¨Ånition.
A diagram in a category C is a directed multigraph9 whose vertices are objects
in C and whose arrows are morphisms in C.
For example,
X
h







f

Y
g

k
 Z
is a diagram in a category, as is
A
f

g‚Ä≤

B
g

C
f ‚Ä≤
 D
If we think of an arrow as a "one-way street," then a path in a diagram is a "walk" from
one vertex to another taking care never to walk the wrong way. A path in a diagram may
be regarded as a composite of morphisms.
DeÔ¨Ånition.
A diagram commutes if, for each pair of vertices A and B, any two paths
from A to B are equal; that is, the composites are the same morphism.
For example, the triangular diagram above commutes if g f = h and k f = h, and the
square diagram above commutes if g f = f ‚Ä≤g‚Ä≤. The term commutes in this context arises
from this last example.
If A and B are subsets of a set S, then their intersection is deÔ¨Åned:
A ‚à©B = {s ‚ààS : s ‚ààA and s ‚ààB}
(if two sets are not given as subsets, then their intersection may not be what one expects:
for example, if Q is deÔ¨Åned as all equivalence classes of ordered pairs (m, n) of integers
with n Ã∏= 0, then Z ‚à©Q = ‚àÖ).
We can force two overlapping subsets A and B to be disjoint by "disjointifying" them.
Consider the cartesian product (A ‚à™B) √ó {1, 2}, and consider the subsets A‚Ä≤ = A √ó {1}
and B‚Ä≤ = B √ó {2}. It is plain that A‚Ä≤ ‚à©B‚Ä≤ = ‚àÖ, for a point in the intersection would have
coordinates (a, 1) = (b, 2); this cannot be, for their second coordinates are not equal. We
9A directed multigraph consists of a set V , called vertices and, for each ordered pair (u, v) ‚ààV √ó V , a
(possibly empty) set arr(u, v), called arrows from u to v.

Sec. 7.2
Categories
447
call A‚Ä≤ ‚à™B‚Ä≤ the disjoint union of A and B. Let us take note of the functions Œ± : A ‚ÜíA‚Ä≤
and Œ≤ : B ‚ÜíB‚Ä≤, given by Œ± : a ‚Üí(a, 1) and Œ≤ : b ‚Üí(b, 2). We denote the disjoint union
A‚Ä≤ ‚à™B‚Ä≤ by A ‚äîB.
If there are functions f : A ‚ÜíX and g : B ‚ÜíX, for some set X, then there is a unique
function h : A ‚äîB ‚ÜíX given by
h(u) =

f (u)
if u ‚ààA;
g(u)
if u ‚ààB.
The function h is well-deÔ¨Åned because A and B are disjoint.
Here is a way to describe this construction categorically (i.e., with diagrams).
DeÔ¨Ånition.
If A and B are objects in a category C, then their coproduct, denoted by
A ‚äîB, is an object C in obj(C) together with injection morphisms Œ± : A
‚Üí
A ‚äîB
and Œ≤ : B ‚ÜíA ‚äîB, such that, for every object X in C and every pair of morphisms
f : A ‚ÜíX and g : B ‚ÜíX, there exists a unique morphism Œ∏ : A ‚äîB ‚ÜíX making the
following diagram commute (i.e., Œ∏Œ± = f and Œ∏Œ≤ = g).
A
Œ±

f







A ‚äîB
Œ∏
 X
B
Œ≤

g

	
	
	
	
	
	
	
Here is the formal proof that the set A‚äîB = A‚Ä≤‚à™B‚Ä≤ ‚äÜ(A‚à™B)√ó{1, 2} just constructed
is the coproduct in Sets. If X is any set and if f : A ‚ÜíX and g : B ‚ÜíX are any given
functions, then there is a function Œ∏ : A ‚äîB ‚ÜíX that extends both f and g. If c ‚ààA ‚äîB,
then either c = (a, 1) ‚ààA‚Ä≤ or c = (b, 2) ‚ààB‚Ä≤. DeÔ¨Åne Œ∏((a, 1)) = f (a) and deÔ¨Åne
Œ∏((b, 2)) = g(b), so that Œ∏Œ± = f and Œ∏Œ≤ = g. Let us show that Œ∏ is the unique function
on A ‚äîB extending both f and g. If œà : A ‚äîB ‚ÜíX satisÔ¨Åes œàŒ± = f and œàŒ≤ = g, then
œà(Œ±(a)) = œà((a, 1)) = f (a) = Œ∏((a, 1))
and, similarly,
œà((b, 2)) = g(b).
Therefore, œà agrees with Œ∏ on A‚Ä≤ ‚à™B‚Ä≤ = A ‚äîB, and so œà = Œ∏.
We do not assert that coproducts always exist; in fact, it is easy to construct examples
of categories in which a pair of objects does not have a coproduct (see Exercise 7.21 on
page 458). Our argument, however, shows that coproducts do exist in Sets, where they
are disjoint unions. Coproducts exist in the category of groups, and they are called free
products; free groups turn out to be free products of inÔ¨Ånite cyclic groups (analogous to
free abelian groups being direct sums of inÔ¨Ånite cyclic groups). A theorem of A. G. Kurosh
states that every subgroup of a free product is itself a free product.

448
Modules and Categories
Ch. 7
Proposition 7.26.
If A and B are R-modules, then their coproduct in RMod exists, and
it is the direct sum C = A ‚äîB.
Proof.
The statement of the proposition is not complete, for a coproduct requires injection
morphisms Œ± and Œ≤. The underlying set of C = A ‚äîB is the cartesian product A √ó B, and
so we may deÔ¨Åne Œ± : A ‚ÜíC by Œ± : a ‚Üí(a, 0) and Œ≤ : B ‚ÜíC by Œ≤ : b ‚Üí(0, b).
Now let X be a module, and let f : A ‚ÜíX and g : B ‚ÜíX be homomorphisms. DeÔ¨Åne
Œ∏ : C ‚ÜíX by Œ∏ : (a, b) ‚Üíf (a) + g(b). First, the diagram commutes: If a ‚ààA, then
Œ∏Œ±(a) = Œ∏((a, 0)) = f (a) and, similarly, if b ‚ààB, then Œ∏Œ≤(b) = Œ∏((0, b)) = g(b).
Finally, Œ∏ is unique. If œà : C ‚ÜíX makes the diagram commute, then œà((a, 0)) = f (a)
for all a ‚ààA and œà((0, b)) = g(b) for all b ‚ààB. Since œà is a homomorphism, we have
œà((a, b)) = œà((a, 0) + (0, b))
= œà((a, 0)) + œà((0, b)) = f (a) + g(b).
Therefore, œà = Œ∏.
‚Ä¢
Let us give the explicit formula for the map Œ∏ in the proof of Proposition 7.26. If
f : A ‚ÜíX and g : B ‚ÜíX are the given homomorphisms, then Œ∏ : A ‚äïB ‚ÜíX is given
by
Œ∏ : (a, b) ‚Üíf (a) + g(b).
The outline of the proof of the next proposition will be used frequently; we have already
seen it in our proof of Lemma 5.74, when we proved that the rank of a nonabelian free
group is well-deÔ¨Åned.
Proposition 7.27.
If C is a category and if A and B are objects in C, then any two
coproducts of A and B, should they exist, are equivalent.
Proof.
Suppose that C and D are coproducts of A and B. In more detail, assume that
Œ± : A ‚ÜíC, Œ≤ : B ‚ÜíC, Œ≥ : A ‚ÜíD, and Œ¥ : B ‚ÜíD are injection morphisms. If, in the
deÔ¨Åning diagram for C, we take X = D, then there is a morphism Œ∏ : C ‚ÜíD making the
diagram commute.
A
Œ±
							
Œ≥







C
Œ∏
 D
B
Œ≤

Œ¥

	
	
	
	
	
	
	
Similarly, if, in the deÔ¨Åning diagram for D, we take X = C, we obtain a morphism

Sec. 7.2
Categories
449
œà : D ‚ÜíC making the diagram commute.
A
Œ±







Œ≥
							
D
œà
 C
B
Œ≤

	
	
	
	
	
	
	
Œ¥

Consider now the following diagram, which arises from the juxtaposition of these two
diagrams.
A
Œ±
							
Œ±







C
Œ∏

œàŒ∏

D
œà
 C
B
Œ≤

Œ≤

	
	
	
	
	
	
	
This diagram commutes because œàŒ∏Œ± = œàŒ≥ = Œ± and œàŒ∏Œ≤ = œàŒ¥ = Œ≤. But plainly, the
identity morphism 1C : C ‚ÜíC also makes this diagram commute. By the uniqueness of
the dotted arrow in the deÔ¨Åning diagram for coproduct, œàŒ∏ = 1C. The same argument,
mutatis mutandis, shows that Œ∏œà = 1D. We conclude that Œ∏ : C ‚ÜíD is an equivalence. ‚Ä¢
Informally, an object S in a category C is called a solution to a universal mapping
problem if it is deÔ¨Åned by a diagram such that, whenever we vary an object X and various
morphisms in the diagram, there exists a unique morphism making the new diagram com-
mute. The "metatheorem" is that solutions, if they exist, are unique to unique equivalence.
The proof just given is the prototype for proving the metatheorem (if we wax categorical,
then the statement of the metatheorem can be made precise, and we can then prove it; see
Exercise 7.29 on page 459 for an illustration, and see Mac Lane, Categories for the Work-
ing Mathematician, Chapter III, for appropriate deÔ¨Ånitions, statement, and proof). There
are two steps. First, if C and D are solutions, get morphisms Œ∏ : C ‚ÜíD and œà : D ‚ÜíC
by setting X = D in the diagram showing that C is a solution, and by setting X = C in the
corresponding diagram showing that D is a solution. Second, set X = C in the diagram for
C and show that both œàŒ∏ and 1C are "dotted" morphisms making the diagram commute; as
such a dotted morphism is unique, conclude that œàŒ∏ = 1C. Similarly, the other composite
Œ∏œà = 1D, and so Œ∏ is an equivalence.
DeÔ¨Ånition.
If A and B are objects in a category C, then their product, denoted by A ‚äìB,
is an object P ‚ààC and morphisms p: P ‚ÜíA and q : P ‚ÜíB, such that, for every object
X ‚ààC and every pair of morphisms f : X ‚ÜíA and g : X ‚ÜíB, there exists a unique

450
Modules and Categories
Ch. 7
morphism Œ∏ : X ‚ÜíP making the following diagram commute:
A
A ‚äìB
p









q









X
g
							
Œ∏

f

B
The cartesian product P = A√ó B of two sets A and B is the categorical product in Sets.
DeÔ¨Åne p: A √ó B ‚ÜíA by p: (a, b) ‚Üía and deÔ¨Åne q : A √ó B ‚ÜíB by q : (a, b) ‚Üíb.
If X is a set and f : X ‚ÜíA and g : X ‚ÜíB are functions, then the reader may show
that Œ∏ : X ‚ÜíA √ó B, deÔ¨Åned by Œ∏ : x ‚Üí( f (x), g(x)) ‚ààA √ó B, satisÔ¨Åes the necessary
conditions.
Proposition 7.28.
If A and B are objects in a category C, then any two products of A and
B, should they exist, are equivalent.
Proof.
Adapt the proof of the prototype, Proposition 7.27
‚Ä¢
The reader should note that the deÔ¨Åning diagram for product is obtained from the dia-
gram for coproduct by reversing all the arrows. A similar reversal of arrows can be seen in
Exercise 7.18 on page 441: The diagram characterizing a surjection in RMod is obtained
by reversing all the arrows in the diagram that characterizes an injection. If S is a solution
to a universal mapping problem posed by a diagram D, let D‚Ä≤ be the diagram obtained
from D by reversing all its arrows. If S‚Ä≤ is a solution to the universal mapping problem
posed by D‚Ä≤, then we call S and S‚Ä≤ duals. There are examples of categories in which an
object and its dual object both exist, and there are examples in which an object exists but
its dual does not.
What is the product of two modules?
Proposition 7.29.
If R is a commutative ring and A and B are R-modules, then their
(categorical) product A ‚äìB exists; in fact,
A ‚äìB ‚àº= A ‚äîB.
Remark.
Thus, the product and coproduct of two objects, though distinct in Sets, coin-
cide in RMod.
‚óÄ
Proof.
In Proposition 7.15(iii), we characterized M ‚àº= A ‚äîB by the existence of projec-
tion and injection morphisms
A
i
‚áÑ
p
M
q
‚áÑ
j
B
satisfying the equations
pi = 1A, qj = 1B, pj = 0, qi = 0
and
ip + jq = 1M.

Sec. 7.2
Categories
451
If X is a module and f : X ‚ÜíA and g : X ‚ÜíB are homomorphisms, deÔ¨Åne Œ∏ : X ‚Üí
A ‚äîB by Œ∏(x) = i f (x) + jg(x). The product diagram
A
A ‚äîB
p









q








 
Œ∏
X
g
							
f

B
commutes because, for all x ‚ààX,
pŒ∏(x) = pi f (x) + pjg(x) = pi f (x) = f (x)
(using the given equations) and, similarly, qŒ∏(x) = g(x). To prove uniqueness of Œ∏, note
that the equation ip + jq = 1A‚äîB gives
œà = ipœà + jqœà = i f + jg = Œ∏.
‚Ä¢
Exercise 7.23 on page 458 shows that direct products are products in Groups.
There are (at least) two ways to extend the notion of direct sum of modules from two
summands to an indexed family of summands.
DeÔ¨Ånition.
Let R be a commutative ring and let {Ai : i ‚ààI} be an indexed family of R-
modules. The direct product 
i‚ààI Ai is the cartesian product [i.e., the set of all I-tuples10
(ai) whose ith coordinate ai lies in Ai for every i] with coordinatewise addition and scalar
multiplication:
(ai) + (bi) = (ai + bi)
r(ai) = (rai),
where r ‚ààR and ai, bi ‚ààAi for all i.
The direct sum, denoted by 
i‚ààI Ai (and also by 4
i‚ààI Ai), is the submodule of

i‚ààI Ai consisting of all (ai) having only Ô¨Ånitely many nonzero coordinates.
Each m ‚àà
i‚ààI Ai has a unique expression of the form
m =

i‚ààI
Œ±i(a),
where ai ‚ààAi. Œ±i(a) is the I-tuple in 
i Ai whose ith coordinate is ai and all other
coordinates are 0, and almost all ai = 0; that is, only Ô¨Ånitely many ai can be nonzero.
Note that if the index set I is Ô¨Ånite, then 
i‚ààI Ai = 
i‚ààI Ai. On the other hand, when
I is inÔ¨Ånite and inÔ¨Ånitely many Ai Ã∏= 0, then the direct sum is a proper submodule of the
direct product (moreover, in this case, they are almost never isomorphic).
We now extend the deÔ¨Ånitions of coproduct and product to a family of objects.
10An I-tuple is a function f : I ‚Üí!
i Ai with f (i) ‚ààAi for all i ‚ààI.

452
Modules and Categories
Ch. 7
DeÔ¨Ånition.
Let C be a category, and let {Ai : i ‚ààI} be a family of objects in C in-
dexed by a set I. A coproduct is an ordered pair (C, {Œ±i : Ai ‚ÜíC}), consisting of an
object C = 5
i‚ààI Ai and a family {Œ±i : Ai ‚Üí5
i‚ààI Ai for all i ‚ààI} of injection mor-
phisms, that satisÔ¨Åes the following property. For every object X equipped with morphisms
fi : Ai ‚ÜíX, there exists a unique morphism Œ∏ : 5
i‚ààI Ai ‚ÜíX making the following
diagram commute for each i:
Ai
Œ±i

fi








5
i‚ààI Ai
Œ∏
 X
As usual, coproducts are unique to equivalence should they exist.
We sketch the existence of the disjoint union of sets {Ai : i ‚ààI}. First form the set
B = (!
i‚ààI Ai) √ó I, and then deÔ¨Åne
A‚Ä≤
i = {(ai, i) ‚ààB : ai ‚ààAi}.
Then the disjoint union is 5
i‚ààI Ai = !
i‚ààI A‚Ä≤
i (of course, the disjoint union of two sets
is a special case of this construction). The reader may show that 5
i Ai together with the
functions Œ±i : Ai ‚Üí5
i Ai given by Œ±i : ai ‚Üí(ai, i) ‚àà5
i Ai, comprise the coproduct in
Sets; that is, we have described a solution to the universal mapping problem.
Proposition 7.30.
If {Ai : i ‚ààI} is a family of R-modules, then the direct sum 
i‚ààI Ai
is their coproduct in RMod.
Proof.
The statement of the proposition is not complete, for a coproduct requires injection
morphisms Œ±i. Denote 
i‚ààI Ai by C, and deÔ¨Åne Œ±i : Ai ‚ÜíC by ai ‚ÜíŒ±i(a) as follows:
If ai ‚ààAi, then Œ±i(a) ‚ààC is the I-tuple whose ith coordinate is ai and whose other
coordinates are zero.
Now let X be a module and, for each i ‚ààI, let fi : Ai ‚ÜíX be homomorphisms. DeÔ¨Åne
Œ∏ : C ‚ÜíX by Œ∏ : (ai) ‚Üí
i fi(ai) (note that this makes sense, for only Ô¨Ånitely many
ai's are nonzero). First, the diagram commutes: If ai ‚ààAi, then Œ∏Œ±i(ai) = fi(ai). Finally,
Œ∏ is unique. If œà : C ‚ÜíX makes the diagram commute, then œà((ai)) = fi(ai). Since œà
is a homomorphism, we have
œà((ai)) = œà

i
Œ±i(ai)

=

i
œàŒ±i(ai) =

i
fi(ai).
Therefore, œà = Œ∏.
‚Ä¢
Let us make the formula for Œ∏ explicit. If fi : Ai ‚ÜíX are given homomorphisms, then
Œ∏ : 
i‚ààI Ai ‚ÜíX is given by
Œ∏ : (ai) ‚Üí

i‚ààI
fi(ai)

Sec. 7.2
Categories
453
[of course, almost all the ai = 0, so that there are only Ô¨Ånitely many nonzero terms in the
sum 
i‚ààI fi(ai)].
Here is the dual notion.
DeÔ¨Ånition.
Let C be a category, and let {Ai : i ‚ààI} be a family of objects in C indexed
by a set I. A product is an ordered pair (C, {pi : C ‚ÜíAi}), consisting of an object
5
i‚ààI Ai and a family {pi : C ‚ÜíAi for all i ‚ààI} of projection morphisms, that satisÔ¨Åes
the following condition. For every object X equipped with morphisms fi : X ‚ÜíAi, there
exists a unique morphism Œ∏ : X ‚Üí
5
i‚ààI Ai making the following diagram commute for
each i:
Ai
5
i‚ààI Ai
pi









X
Œ∏

fi

Products are unique to equivalence should they exist.
We let the reader prove that cartesian product is the product in Sets.
Proposition 7.31.
If {Ai : i ‚ààI} is a family of R-modules, then the direct product
C = 
i‚ààI Ai is their product in RMod.
Proof.
The statement of the proposition is not complete, for a product requires projec-
tions. For each j ‚ààI, deÔ¨Åne p j : C ‚ÜíA j by p j : (ai) ‚Üía j ‚ààA j.
Now let X be a module and, for each i ‚ààI, let fi : X ‚ÜíAi be a homomorphism.
DeÔ¨Åne Œ∏ : X ‚ÜíC by Œ∏ : x ‚Üí( fi(x)). First, the diagram commutes: If x ‚ààX, then
piŒ∏(x) = fi(x). Finally, Œ∏ is unique. If œà : X ‚ÜíC makes the diagram commute, then
piœà(x) = fi(ai) for all i; that is, for each i, the ith coordinate of œà(x) is fi(x), which is
also the ith coordinate of Œ∏(x). Therefore, œà(x) = Œ∏(x) for all x ‚ààX, and so œà = Œ∏.
‚Ä¢
The categorical viewpoint makes the next two proofs straightforward.
Theorem 7.32.
Let R be a commutative ring. For every R-module A and every family
{Bi : i ‚ààI} of R-modules,
HomR

A,

i‚ààI
Bi

‚àº=

i‚ààI
HomR(A, Bi),
via the R-isomorphism
œï : f ‚Üí(pi f ),
where the pi are the projections of the product 
i‚ààI Bi.
Proof.
It is easy to see that œï is additive. To see that œï is an R-map, note, for each i and
each r ‚ààR, that pir f = rpi f ; therefore,
œï : r f ‚Üí(pir f ) = (rpi f ) = r(pi f ) = rœï( f ).

454
Modules and Categories
Ch. 7
Let us see that œï is surjective. If ( fi) ‚àà HomR(A, Bi), then fi : A ‚ÜíBi for every i.
Bi
 Bi
pi








A
Œ∏

fi

By Proposition 7.31,  Bi is the product in RMod, and so there is a unique R-map Œ∏ : A ‚Üí
 Bi with piŒ∏ = fi for all i. Thus, ( fi) = œï(Œ∏) and œï is surjective.
To see that œï is injective, suppose that f ‚ààker œï; that is, 0 = œï( f ) = (pi f ). Thus,
pi f = 0 for every i. Hence, the following diagram containing f commutes:
Bi
 Bi
pi








A
f

0

But the zero homomorphism also makes this diagram commute, and so the uniqueness of
the arrow A ‚Üí Bi gives f = 0.
‚Ä¢
Theorem 7.33.
For every R-module B and every family {Ai : i ‚ààI} of R-modules,
HomR

i‚ààI
Ai, B

‚àº=

i‚ààI
HomR(Ai, B),
via the R-isomorphism
f ‚Üí( f Œ±i),
where the Œ±i are the injections of the sum 
i‚ààI Ai.
Proof.
This proof is similar to that of Theorem 7.32, and it is left to the reader.
‚Ä¢
There are examples showing that HomR(A, 
i Bi) Ã∏‚àº= 
i HomR(A, Bi) and that
HomR(
i Ai, B) Ã∏‚àº=

i HomR(Ai, B).
Corollary 7.34.
If A, A‚Ä≤, B, and B‚Ä≤ are R-modules. then there are isomorphisms
HomR(A, B ‚äîB‚Ä≤) ‚àº= HomR(A, B) ‚äîHomR(A, B‚Ä≤)
and
HomR(A ‚äîA‚Ä≤, B) ‚àº= HomR(A, B) ‚äîHomR(A‚Ä≤, B).
Proof.
When the index set is Ô¨Ånite, the direct sum and the direct product of modules are
equal.
‚Ä¢

Sec. 7.2
Categories
455
Example 7.35.
(i) In Example 7.6, we deÔ¨Åned the dual space V ‚àóof a vector space V over a Ô¨Åeld k to be
the vector space of all its linear functionals:
V ‚àó= Homk(V, k).
If dim(V ) = n < ‚àû, then Example 5.6 shows that V = V1 ‚äï¬∑ ¬∑ ¬∑ ‚äïVn, where each
Vi is one-dimensional. By Corollary 7.34, V ‚àó‚àº=

i Homk(Vi, k) is a direct sum of n
one-dimensional spaces [for Exercise 7.5 on page 440 gives Homk(k, k) ‚àº= k], and so
Exercise 7.26 on page 458 gives dim(V ‚àó) = dim(V ) = n. Thus, a Ô¨Ånite-dimensional
vector space and its dual space are isomorphic. It follows that the double dual, V ‚àó‚àó, deÔ¨Åned
as (V ‚àó)‚àó, is isomorphic to V when V is Ô¨Ånite-dimensional.
(ii) There are variations of dual spaces. In functional analysis, one encounters topological
real vector spaces V , so that it makes sense to speak of continuous linear functionals. The
topological dual V ‚àóconsists of all the continuous linear functionals, and it is important to
know whether a space V is reÔ¨Çexive; that is, whether the analog of the isomorphism V ‚Üí
V ‚àó‚àófor Ô¨Ånite-dimensional spaces is a homeomorphism for these spaces. For example, that
Hilbert space is reÔ¨Çexive is one of its important properties.
‚óÄ
We now present two dual constructions that are often useful.
DeÔ¨Ånition.
Given two morphisms f : B ‚ÜíA and g : C ‚ÜíA in a category C, a solution
is an ordered triple (D, Œ±, Œ≤) making the following diagram commute:
D
Œ±

Œ≤

C
g

B
f
 A
A pullback (or Ô¨Åbered product) is a solution (D, Œ±, Œ≤) that is "best" in the following sense:
For every solution (X, Œ±‚Ä≤, Œ≤‚Ä≤), there exists a unique morphism Œ∏ : X ‚ÜíD making the
following diagram commute:
X
Œ±‚Ä≤














Œ∏
Œ≤‚Ä≤

D
Œ≤

Œ±
 C
g

B
f
 A
Pullbacks, when they exist, are unique to equivalence; the proof is in the same style as
the proof that coproducts are unique.

456
Modules and Categories
Ch. 7
Proposition 7.36.
The pullback of two maps f : B ‚ÜíA and g : C ‚ÜíA in RMod exists.
Proof.
DeÔ¨Åne
D = {(b, c) ‚ààB ‚äîC : f (b) = g(c)},
deÔ¨Åne Œ± : D ‚ÜíC to be the restriction of the projection (b, c) ‚Üíc, and deÔ¨Åne Œ≤ : D ‚ÜíB
to be the restriction of the projection (b, c) ‚Üíb. It is easy to see that (D, Œ±, Œ≤) is a
solution.
If (X, Œ±‚Ä≤, Œ≤‚Ä≤) is another solution, deÔ¨Åne a map Œ∏ : X ‚ÜíD by Œ∏ : x ‚Üí(Œ≤‚Ä≤(x), Œ±‚Ä≤(x)).
The values of Œ∏ do lie in D, for fŒ≤‚Ä≤(x) = gŒ±‚Ä≤(x) because X is a solution. We let the reader
prove that the diagram commutes and that Œ∏ is unique.
‚Ä¢
Example 7.37.
(i) That B and C are subsets of a set A can be restated as saying that there are inclusion
maps i : B ‚ÜíA and j : C ‚ÜíA. The reader will enjoy proving that the pullback D exists
in Sets, and that D = B ‚à©C.
(ii) Pullbacks exist in Groups: They are certain subgroups of a direct product constructed
as in the proof of Proposition 7.36.
(iii) If f : B ‚ÜíA is a homomorphism, then ker f is the pullback of the following diagram:
0

B
f
 A
The pullback is {(b, 0) ‚ààB ‚äî{0} : f b = 0} ‚àº= ker f .
‚óÄ
Here is the dual construction.
DeÔ¨Ånition.
Given two morphisms f : A ‚ÜíB and g : A ‚ÜíC in a category C, a solution
is an ordered triple (D, Œ±, Œ≤) making the following diagram commute:
A
g

f

C
Œ≤

B
Œ±
 D
A pushout (or Ô¨Åbered sum) is a solution (D, Œ±, Œ≤) that is "best" in the following sense:
for every solution (X, Œ±‚Ä≤, Œ≤‚Ä≤), there exists a unique morphism Œ∏ : D ‚ÜíX making the

Sec. 7.2
Categories
457
following diagram commute:
A
g

f

C
Œ≤

Œ≤‚Ä≤

B
Œ±

Œ±‚Ä≤














D
Œ∏

X
Again, pushouts are unique to equivalence when they exist.
Proposition 7.38.
The pushout of two maps f : A ‚ÜíB and g: A ‚ÜíC in RMod exists.
Proof.
It is easy to see that
S = {

f (a), ‚àíg(a)

‚ààB ‚äîC : a ‚ààA}
is a submodule of B ‚äîC. DeÔ¨Åne D = (B ‚äîC)/S, deÔ¨Åne Œ± : B ‚ÜíD by b ‚Üí(b, 0) + S,
and deÔ¨Åne Œ≤ : C ‚ÜíD by c ‚Üí(0, c) + S. It is easy to see that (D, Œ±, Œ≤) is a solution.
Given another solution (X, Œ±‚Ä≤, Œ≤‚Ä≤), deÔ¨Åne the map Œ∏ : D ‚ÜíX by Œ∏ : (b, c) + S ‚Üí
Œ±‚Ä≤(b)+Œ≤‚Ä≤(c). Again, we let the reader prove commutativity of the diagram and uniqueness
of Œ∏.
‚Ä¢
Pushouts in Groups are quite interesting; for example, the pushout of two injective
homomorphisms is called a free product with amalgamation.
Example 7.39.
(i) If B and C are subsets of a set A, then there are inclusion maps i : B ‚à©C ‚ÜíB and
j : B ‚à©C ‚ÜíB. The reader will enjoy proving that the pushout D exists in Sets, and that
D is their union B ‚à™C.
(ii) If f : A ‚ÜíB is a homomorphism, then coker f is the pushout of the following diagram:
A
f


B
0
After all, the pushout here is the quotient ({0} ‚äîB)/S, where S = {(0, f a)}, and so
({0} ‚äîB)/S ‚àº= B/ im f = coker f .
‚óÄ

458
Modules and Categories
Ch. 7
EXERCISES
7.20
(i) Prove, in every category C, that each object A ‚ààC has a unique identity morphism.
(ii) If f is an equivalence in a category, prove that its inverse is unique.
7.21
(i) Let X be a partially ordered set, and let a, b ‚ààX. Show, in PO(X) [deÔ¨Åned in Exam-
ple 7.25(v)], that the coproduct a‚äîb is the least upper bound of a and b, and that the
product a ‚äìb is the greatest lower bound.
(ii) Let Y be a set, and let P(Y) denote its power set; that is, P(Y) is the family of all the
subsets of Y. Now regard P(Y) as a partially ordered set under inclusion. If A and B
are subsets of Y, show, in PO(P(Y)), that the coproduct A‚äîB = A ‚à™B and that the
product A ‚äìB = A ‚à©B.
(iii) Give an example of a category in which there are two objects whose coproduct does not
exist.
Hint. See Exercise 6.43 on page 374.
7.22 Prove that Groups is not a pre-additive category.
Hint.
If G is not abelian and f, g: G ‚ÜíG are homomorphisms, show that the function
x ‚Üíf (x)g(x) may not be a homomorphism.
7.23 If A and B are (not necessarily abelian) groups, prove that A ‚äìB = A √ó B (direct product) in
Groups.
7.24 If G is a Ô¨Ånite abelian group, prove that HomZ(Q, G) = 0.
7.25 Let {Mi : i ‚ààI} be a family of modules and, for each i, let Ni be a submodule of Mi. Prove
that

i
Mi

/

i
Ni
 ‚àº=

i

Mi/Ni

.
7.26
(i) Let v1, . . . , vn be a basis of a vector space V over a Ô¨Åeld k, so that every v ‚ààV has a
unique expression
v = a1v1 + ¬∑ ¬∑ ¬∑ + anvn,
where ai ‚ààk for i = 1, . . . , n. For each i, prove that the function v‚àó
i : V ‚Üík, deÔ¨Åned
by v‚àó
i : v ‚Üíai, lies in the dual space V ‚àó.
(ii) Prove that v‚àó
1, . . . , v‚àón is a linearly independent list in V ‚àó.
(iii) Use Example 7.35(i) to conclude that v‚àó
1, . . . , v‚àón is a basis of V ‚àó(it is called the dual
basis of v1, . . . , vn).
(iv) If f : V ‚ÜíV is a linear transformation, let A be the matrix of f with respect to a basis
v1, . . . , vn of V ; that is, the ith column of A consists of the coordinates of f (vi) in terms
of the given basis v1, . . . , vn. Prove that the matrix of the induced map f ‚àó: V ‚àó‚ÜíV ‚àó
with respect to the dual basis is At, the transpose of A.
7.27 Given a map œÉ :  Bi ‚Üí C j, Ô¨Ånd a map œÉ making the following diagram commute,
Hom(A,  Bi)
œÉ

œÑ

Hom(A,  C j)
œÑ ‚Ä≤

 Hom(A, Bi)
œÉ
  Hom(A, C j),

Sec. 7.2
Categories
459
where œÑ and œÑ‚Ä≤ are the isomorphisms of Theorem 7.32.
Hint. If f ‚ààHom(A,  Bi), deÔ¨Åne œÉ : ( fi) ‚Üí(p jœÉ f ); that is, the jth coordinate of œÉ( fi))
is the jth coordinate of œÉ( f ) ‚àà C j.
7.28
(i) Given a pushout diagram in RMod
A
g

f

C
Œ≤

B
Œ±
 D
prove that g injective implies Œ± injective, and that g surjective implies Œ± surjective.
Thus, parallel arrows have the same properties.
(ii) Given a pullback diagram in RMod
D
Œ±

Œ≤

C
g

B
f
 A
prove that f injective implies Œ± injective, and that f surjective implies Œ± surjective.
Thus, parallel arrows have the same properties.
7.29 DeÔ¨Ånition.
An object A in a category C is called an initial object if, for every object C in C,
there exists a unique morphism A ‚ÜíC.
An object $ in a category C is called a terminal object if, for every object C in C, there
exists a unique morphism C ‚Üí$.
(i) Prove the uniqueness of initial and terminal objects, if they exist. Give an example of a
category which contains no initial object. Give an example of a category that contains
no terminal object.
(ii) If $ is a terminal object in a category C, prove, for any G ‚ààobj(C), that the projections
Œª: G ‚äì$ ‚ÜíG and œÅ : $ ‚äìG ‚ÜíG are equivalences.
(iii) Let A and B be objects in a category C. DeÔ¨Åne a new category C‚Ä≤ whose objects are
diagrams
A
Œ±
‚àí‚ÜíC
Œ≤
‚Üê‚àíB,
where C is an object in C and Œ± and Œ≤ are morphisms in C. DeÔ¨Åne a morphism in C‚Ä≤ to
be a morphism Œ∏ in C that makes the following diagram commute:
A
Œ±

1A

C
Œ∏

B
Œ≤

1B

A
Œ±‚Ä≤
 C‚Ä≤
B
Œ≤‚Ä≤

There is an obvious candidate for composition. Prove that C‚Ä≤ is a category.

460
Modules and Categories
Ch. 7
(iv) Prove that an initial object in C‚Ä≤ is a coproduct in C.
(v) Give an analogous construction showing that product is a terminal object in a suitable
category.
7.30 A zero object in a category C is an object Z that is both an initial object and a terminal object.
(i) Prove that {0} is a zero object in RMod.
(ii) Prove that ‚àÖis an initial object in Sets.
(iii) Prove that any one-point set is a terminal object in Sets.
(iv) Prove that a zero object does not exist in Sets.
7.31
(i) Assuming that coproducts exist, prove associativity:
A ‚äî(B ‚äîC) ‚àº= (A ‚äîB) ‚äîC.
(ii) Assuming that products exist, prove associativity:
A ‚äì(B ‚äìC) ‚àº= (A ‚äìB) ‚äìC.
7.32 Let C1, C2, D1, D2 be objects in a category C.
(i) If there are morphisms fi : Ci ‚ÜíDi, for i = 1, 2, and if C1 ‚äìC2 and D1 ‚äìD2
exist, prove that there exists a unique morphism f1 ‚äìf2 making the following diagram
commute:
C1 ‚äìC2
f1 ‚äìf2
pi

D1 ‚äìD2
qi

Ci
fi
 Di,
where pi and qi are projections.
(ii) If there are morphisms gi : X ‚ÜíCi, where X is an object in C and i = 1, 2, prove that
there is a unique morphism (g1, g2) making the following diagram commute:
X
g1

(g1,g2)

g2










C1
C1 ‚äìC2
p1

p2
 C2,
where the pi are projections.
Hint.
First deÔ¨Åne an analog of the diagonal X : X ‚ÜíX √ó X in Sets, given by
x ‚Üí(x, x), and then deÔ¨Åne (g1, g2) = (g1 ‚äìg2)X.
7.33 Let C be a category having Ô¨Ånite products and a terminal object $. A group object in C is
a quadruple (G, ¬µ, Œ∑, œµ), where G is an object in C, ¬µ: G
5
G ‚ÜíG, Œ∑: G ‚ÜíG, and
œµ : $ ‚ÜíG are morphisms, so that the following diagrams commute:
Associativity:
G ‚äìG ‚äìG
1 ‚äì¬µ

¬µ ‚äì1

G ‚äìG
¬µ

G ‚äìG
¬µ
 G

Sec. 7.3
Functors
461
Identity:
G ‚äì$
1 ‚äìœµ 
Œª










G ‚äìG
¬µ

$ ‚äìG
œµ ‚äì1

œÅ

G
where Œª and œÅ are the equivalences in Exercise 7.29(ii).
Inverse:
G
(1,Œ∑)
œâ

G ‚äìG
¬µ

G
(Œ∑,1)

œâ

$
œµ
 G
$
œµ

where œâ: G ‚Üí$ is the unique morphism to the terminal object.
(i) Prove that a group object in Sets is a group.
(ii) Prove that a group object in Groups is an abelian group.
Hint. Use Exercise 2.73 on page 95.
7.3 FUNCTORS
Functors11 are homomorphisms of categories.
DeÔ¨Ånition.
Recall that obj(C) denotes the class of all the objects in a category C. If C and
D are categories, then a functor T : C ‚ÜíD is a function such that
(i) if A ‚ààobj(C), then T (A) ‚ààobj(D);
(ii) if f : A ‚ÜíA‚Ä≤ in C, then T ( f ): T (A) ‚ÜíT (A‚Ä≤) in D;
(iii) if A
f‚ÜíA‚Ä≤
g‚ÜíA‚Ä≤‚Ä≤ in C, then T (A)
T ( f )
‚ÜíT (A‚Ä≤)
T (g)
‚ÜíT (A‚Ä≤‚Ä≤) in D and
T (g f ) = T (g)T ( f );
(iv) for every A ‚ààobj(C),
T (1A) = 1T (A).
Example 7.40.
(i) If C is a category, then the identity functor 1C : C ‚ÜíC is deÔ¨Åned by
1C(A) = A for all objects A,
and
1C( f ) = f for all morphisms f.
11The term functor was coined by the philosopher R. Carnap, and S. Mac Lane thought it was the appropriate
term in this context.

462
Modules and Categories
Ch. 7
(ii) If C is a category and A ‚ààobj(C), then the Hom functor TA : C ‚ÜíSets is deÔ¨Åned by
TA(B) = Hom(A, B) for all B ‚ààobj(C),
and if f : B ‚ÜíB‚Ä≤ in C, then TA( f ): Hom(A, B) ‚ÜíHom(A, B‚Ä≤) is given by
TA( f ): h ‚Üíf h.
We call TA( f ) the induced map, and we denote it by
TA( f ) = f‚àó: h ‚Üíf h.
Because of the importance of this example, we will verify the parts of the deÔ¨Ånition in
detail. First, the very deÔ¨Ånition of category says that Hom(A, B) is a set. Note that the
composite f h makes sense:
A
f h

h
 B
f
 B‚Ä≤.
Suppose now that g : B ‚ÜíB‚Ä≤‚Ä≤. Let us compare the functions
(g f )‚àó, g‚àóf‚àó: Hom(A, B) ‚ÜíHom(A, B‚Ä≤‚Ä≤).
If h ‚ààHom(A, B), i.e., if h : A ‚ÜíB, then
(g f )‚àó: h ‚Üí(g f )h;
on the other hand,
g‚àóf‚àó: h ‚Üíf h ‚Üíg( f h),
as desired. Finally, if f is the identity map 1A : A ‚ÜíA, then
(1A)‚àó: h ‚Üí1Ah = h
for all h ‚ààHom(A, B), so that (1A)‚àó= 1Hom(A,B).
If we denote Hom(A, ) by TA, then Theorem 7.32 says that TA preserves products:
TA

i Bi
 ‚àº= 
i TA(Bi).
(iii) If R is a commutative ring and A is an R-module, then the Hom functor TA : RMod ‚Üí
Sets has more structure. We have seen, in Proposition 7.5, that HomR(A, B) is an R-
module; we now show that if f : B ‚ÜíB‚Ä≤, then the induced map f‚àó: HomR(A, B) ‚Üí
HomR(A, B‚Ä≤), given by h ‚Üíf h, is an R-map. First, f‚àóis additive: If h, h‚Ä≤ ‚ààHom(A, B),
then for all a ‚ààA,
f‚àó(h + h‚Ä≤) = f (h + h‚Ä≤): a ‚Üíf (ha + h‚Ä≤a)
= f ha + f h‚Ä≤a = ( f‚àó(h) + f‚àó(h‚Ä≤))(a),

Sec. 7.3
Functors
463
so that f‚àó(h + h‚Ä≤) = f‚àó(h) + f‚àó(h‚Ä≤). Second, f‚àópreserves scalars. Recall that if r ‚ààR
and h ‚ààHom(A, B), then rh : a ‚Üíh(ra). Thus,
f‚àó(rh): a ‚Üíf (rh)(a) = f h(ra),
while
r f‚àó(h) = r f h : a ‚Üíf h(ra).
Therefore, f‚àó(rh) = (r f )‚àó(h).
In particular, if R is a Ô¨Åeld, then the HomR's are vector spaces and the induced maps
are linear transformations.
(iv) Let C be a category, and let A ‚ààobj(C). DeÔ¨Åne T : C ‚ÜíC by T (C) = A for every
C ‚ààobj(C), and T ( f ) = 1A for every morphism f in C. Then T is a functor, called the
constant functor at A.
(v) If C = Groups, deÔ¨Åne the forgetful functor U : Groups ‚ÜíSets by U(G) is the
"underlying" set of a group G and U( f ) regards a homomorphism f as a mere function.
Strictly speaking, a group is an ordered pair (G, ¬µ), where G is its (underlying) set and
¬µ: G√óG ‚ÜíG is its operation, and U((G, ¬µ)) = G; the functor U "forgets" the operation
and remembers only the set.
There are many variants. For example, an R-module is an ordered triple (M, Œ±, œÉ),
where M is a set, Œ± : M √ó M ‚ÜíM is addition, and œÉ : R √ó M ‚ÜíM is scalar multipli-
cation. There are forgetful functors U ‚Ä≤ : RMod ‚ÜíAb with U ‚Ä≤((M, Œ±, œÉ)) = (M, Œ±), and
U ‚Ä≤‚Ä≤ : RMod ‚ÜíSets with U ‚Ä≤‚Ä≤(M, Œ±, œÉ)) = M, for example.
‚óÄ
The following result is useful, even though it is very easy to prove.
Proposition 7.41.
If T : C ‚ÜíD is a functor, and if f : A ‚ÜíB is an equivalence in C,
then T ( f ) is an equivalence in D.
Proof.
If g is the inverse of f , apply T to the equations
g f = 1A and f g = 1B.
‚Ä¢
This proposition illustrates, admittedly at a low level, the reason why it is useful to
give categorical deÔ¨Ånitions: Functors can recognize deÔ¨Ånitions phrased solely in terms of
objects, morphisms, and diagrams. How could we prove this result in Ab if we regard an
isomorphism as a homomorphism that is an injection and a surjection?
There is a second type of functor that reverses the direction of arrows.
DeÔ¨Ånition.
If C and D are categories, then a contravariant functor T : C ‚ÜíD is a
function such that
(i) if C ‚ààobj(C), then T (C) ‚ààobj(D);
(ii) if f : C ‚ÜíC‚Ä≤ in C, then T ( f ): T (C‚Ä≤) ‚ÜíT (C) in D;

464
Modules and Categories
Ch. 7
(iii) if C
f‚ÜíC‚Ä≤
g‚ÜíC‚Ä≤‚Ä≤ in C, then T (C‚Ä≤‚Ä≤)
T (g)
‚ÜíT (C‚Ä≤)
T ( f )
‚ÜíT (C) in D and
T (g f ) = T ( f )T (g);
(iv) for every A ‚ààobj(C),
T (1A) = 1T (A).
To distinguish them from contravariant functors, the functors deÔ¨Åned earlier are called
covariant functors.
Example 7.42.
(i) If C is a category and B ‚ààobj(C), then the contravariant Hom functor T B : C ‚ÜíSets
is deÔ¨Åned, for all C ‚ààobj(C), by
T B(C) = Hom(C, B)
and if f : C ‚ÜíC‚Ä≤ in C, then T B( f ): Hom(C‚Ä≤, B) ‚ÜíHom(C, B) is given by
T B( f ): h ‚Üíh f.
We call T B( f ) the induced map, and we denote it by
T B( f ) = f ‚àó: h ‚Üíh f.
Because of the importance of this example, we verify the axioms, showing that T B is a
(contravariant) functor. Note that the composite h f makes sense:
C
h f

f
 C‚Ä≤
h
 B.
Given homomorphisms
C
f‚ÜíC‚Ä≤
g‚ÜíC‚Ä≤‚Ä≤,
let us compare the functions
(g f )‚àó, f ‚àóg‚àó: Hom(C‚Ä≤‚Ä≤, B) ‚ÜíHom(C, B).
If h ‚ààHom(C‚Ä≤‚Ä≤, B) (i.e., if h : C‚Ä≤‚Ä≤ ‚ÜíB), then
(g f )‚àó: h ‚Üíh(g f );
on the other hand,
f ‚àóg‚àó: h ‚Üíhg ‚Üí(hg) f,
as desired. Finally, if f is the identity map 1C : C ‚ÜíC, then
(1C)‚àó: h ‚Üíh1C = h

Sec. 7.3
Functors
465
for all h ‚ààHom(C, B), so that (1C)‚àó= 1Hom(C,B).
If Hom( , B) is denoted by T B, then Theorem 7.33 says that the contravariant functor
T B converts sums to products: T B
i Ai
 ‚àº=

i T B(Ai).
(ii) If R is a commutative ring and C is an R-module, then the contravariant Hom functor
RMod ‚ÜíSets has more structure. We show that if f : C ‚ÜíC‚Ä≤ is an R-map, then
the induced map f ‚àó: HomR(C‚Ä≤, B) ‚ÜíHomR(C, B), given by h ‚Üíh f , is an R-map
between R-modules. First, f ‚àóis additive: If g, h ‚ààHom(C‚Ä≤, B), then for all c‚Ä≤ ‚ààC‚Ä≤,
f ‚àó(g + h) = (g + h) f : c‚Ä≤ ‚Üí(g + h) f (c‚Ä≤)
= g f c‚Ä≤ + h f c‚Ä≤ = ( f ‚àó(g) + f ‚àó(h))(c‚Ä≤),
so that f ‚àó(g + h) = f ‚àó(g) + f ‚àó(h). Second, f ‚àópreserves scalars. Recall that if r ‚ààR
and h ‚ààHom(A, B), then rh : a ‚Üíh(ra). Thus,
f ‚àó(rh): c‚Ä≤ ‚Üí(rh) f (c‚Ä≤) = h(r f (c‚Ä≤)),
while
r f ‚àó(h) = r(hf ): c‚Ä≤ ‚Üíh f (rc‚Ä≤).
These are the same, because r f (c‚Ä≤) = f (rc‚Ä≤), and so f ‚àó(rh) = r f ‚àó(h).
In particular, if R is a Ô¨Åeld, then the HomR's are vector spaces and the induced maps
are linear transformations. A special case of this is the dual space functor Homk( , k),
where k is a Ô¨Åeld.
‚óÄ
It is easy to see, as in Proposition 7.41, that every contravariant functor preserves equiva-
lences; that is, if T : C ‚ÜíD is a contravariant functor, and if f : C ‚ÜíC‚Ä≤ is an equivalence
in C, then T ( f ) is an equivalence in D.
DeÔ¨Ånition.
If C and D are pre-additive categories, then a functor T : C ‚ÜíD, of either
variance, is called an additive functor if, for every pair of morphisms f, g : A ‚ÜíB, we
have
T ( f + g) = T ( f ) + T (g).
It is easy to see that Hom functors RMod ‚ÜíAb of either variance are additive functors.
Every covariant functor T : C ‚ÜíD gives rise to functions
TAB : Hom(A, B) ‚ÜíHom(T A, T B),
for every A and B, deÔ¨Åned by h ‚ÜíT (h). If T is an additive functor between pre-additive
categories, then each TAB is a homomorphism of abelian groups; the analogous statement
for contravariant functors is also true.
Here is a modest generalization of Corollary 7.34.

466
Modules and Categories
Ch. 7
Proposition 7.43.
If T : RMod ‚ÜíAb is an additive functor of either variance, then T
preserves Ô¨Ånite direct sums:
T (A1 ‚äï¬∑ ¬∑ ¬∑ ‚äïAn) ‚àº= T (A1) ‚äï¬∑ ¬∑ ¬∑ ‚äïT (An).
Proof.
By induction, it suffÔ¨Åces to prove that T (A ‚äïB) ‚àº= T (A) ‚äïT (B). Proposi-
tion 7.15(iii) characterizes M = A ‚äïB by maps p: M ‚ÜíA, q : M ‚ÜíB, i : A ‚ÜíM,
and j : B ‚ÜíM such that
pi = 1A, qj = 1B, pj = 0, qi = 0
and
ip + jq = 1M.
Since T is an additive functor, Exercise 7.34 on page 470 gives T (0) = 0, and so T
preserves these equations.
‚Ä¢
We have just seen that additive functors T : RMod ‚ÜíAb preserve the direct sum of
two modules:
T (A ‚äïC) = T (A) ‚äïT (C).
If we regard such a direct sum as a split short exact sequence, then we may rephrase this
by saying that if
0 ‚ÜíA
i‚ÜíB
p‚ÜíC ‚Üí0
is a split short exact sequence, then so is
0 ‚ÜíT (A)
T (i)
‚àí‚ÜíT (B)
T (p)
‚àí‚ÜíT (C) ‚Üí0.
This leads us to the more general question: If
0 ‚ÜíA
i‚ÜíB
p‚ÜíC ‚Üí0
is any short exact sequence, not necessarily split, is
0 ‚ÜíT (A)
T (i)
‚àí‚ÜíT (B)
T (p)
‚àí‚ÜíT (C) ‚Üí0
also an exact sequence? Here is the answer for Hom functors (there is no misprint in the
statement of the theorem: "‚Üí0" should not appear at the end of the sequences, and we
shall discuss this point after the proof).
Theorem 7.44.
If
0 ‚ÜíA
i‚ÜíB
p‚ÜíC
is an exact sequence of R-modules, and if X is an R-module, then there is an exact se-
quence
0 ‚ÜíHomR(X, A)
i‚àó‚ÜíHomR(X, B)
p‚àó
‚ÜíHomR(X, C).
Proof.
(i) ker i‚àó= {0}:

Sec. 7.3
Functors
467
If f ‚ààker i‚àó, then f : X ‚ÜíA and i‚àó( f ) = 0; that is,
i f (x) = 0 for all x ‚ààX.
Since i is injective, f (x) = 0 for all x ‚ààX, and so f = 0.
(ii) im i‚àó‚äÜker p‚àó:
If g ‚ààim i‚àó, then g : X ‚ÜíB and g = i‚àó( f ) = i f for some f : X ‚ÜíA. But
p‚àó(g) = pg = pi f = 0 because exactness of the original sequence, namely, im i = ker p,
implies pi = 0.
(iii) ker p‚àó‚äÜim i‚àó:
If g ‚ààker p‚àó, then g : X ‚ÜíB and p‚àó(g) = pg = 0. Hence, pg(x) = 0 for all x ‚ààX,
so that g(x) ‚ààker p = im i. Thus, g(x) = i(a) for some a ‚ààA; since i is injective, this
element a is unique. Hence, the function f : X ‚ÜíA, given by f (x) = a if g(x) = i(a), is
well-deÔ¨Åned. It is easy to check that f ‚ààHomR(X, A); that is, f is an R-homomorphism.
Since
g(x + x‚Ä≤) = g(x) + g(x‚Ä≤) = i(a) + i(a‚Ä≤) = i(a + a‚Ä≤),
we have
f (x + x‚Ä≤) = a + a‚Ä≤ = f (x) + f (x‚Ä≤).
A similar argument shows that f (rx) = r f (x) for all r ‚ààR. But, i‚àó( f ) = i f and
i f (x) = i(a) = g(x) for all x ‚ààX; that is, i‚àó( f ) = g, and so g ‚ààim i‚àó.
‚Ä¢
Example 7.45.
Even if the map p: B ‚ÜíC in the original exact sequence is assumed to be surjective, the
functored sequence need not end with "‚Üí0;" that is, p‚àó: HomR(X, B) ‚ÜíHomR(X, C)
may fail to be surjective.
The abelian group Q/Z consists of cosets q + Z for q ‚ààQ, and it easy to see that
its element 1
2 + Z has order 2. It follows that HomZ(I2, Q/Z) Ã∏= {0}, for it contains the
nonzero homomorphism [1] ‚Üí1
2 + Z.
Apply the functor HomZ(I2, ) to
0 ‚ÜíZ
i‚ÜíQ
p‚ÜíQ/Z ‚Üí0,
where i is the inclusion and p is the natural map. We have just seen that
HomZ(I2, Q/Z) Ã∏= {0};
on the other hand, HomZ(I2, Q) = {0} because Q has no (nonzero) elements of Ô¨Ånite
order. Therefore, the induced map p‚àó: HomZ(I2, Q) ‚ÜíHomZ(I2, Q/Z) cannot be sur-
jective.
‚óÄ

468
Modules and Categories
Ch. 7
DeÔ¨Ånition.
A covariant functor T : RMod ‚ÜíAb is called left exact if exactness of
0 ‚ÜíA
i‚ÜíB
p‚ÜíC
implies exactness of
0 ‚ÜíT (A)
T (i)
‚àí‚ÜíT (B)
T (p)
‚àí‚ÜíT (C).
Thus, Theorem 7.44 shows that covariant Hom functors HomR(X, ) are left exact func-
tors. Investigation of the cokernel of HomR(X, ) is done in homological algebra; it is
involved with a functor called Ext1
R(X, ).
There is an analogous result for contravariant Hom functors.
Theorem 7.46.
If
A
i‚ÜíB
p‚ÜíC ‚Üí0
is an exact sequence of R-modules, and if Y is an R-module, then there is an exact sequence
0 ‚ÜíHomR(C, Y)
p‚àó
‚ÜíHomR(B, Y)
i‚àó
‚ÜíHomR(A, Y).
Proof.
(i) ker p‚àó= {0}.
If h ‚ààker p‚àó, then h : C ‚ÜíY and 0 = p‚àó(h) = hp. Thus, h(p(b)) = 0 for all b ‚ààB,
so that h(c) = 0 for all c ‚ààim p. Since p is surjective, im p = C, and h = 0.
(ii) im p‚àó‚äÜker i‚àó.
If g ‚ààHomR(C, Y), then
i‚àóp‚àó(g) = (pi)‚àó(g) = 0,
because exactness of the original sequence, namely, im i = ker p, implies pi = 0.
(iii) ker i‚àó‚äÜim p‚àó.
If g ‚ààker i‚àó, then g : B ‚ÜíY and i‚àó(g) = gi = 0. If c ‚ààC, then c = p(b) for some
b ‚ààB, because p is surjective. DeÔ¨Åne f : C ‚ÜíY by f (c) = g(b) if c = p(b). Note that
f is well-deÔ¨Åned: If p(b) = p(b‚Ä≤), then b ‚àíb‚Ä≤ ‚ààker p = im i, so that b ‚àíb‚Ä≤ = i(a) for
some a ‚ààA. Hence,
g(b) ‚àíg(b‚Ä≤) = g(b ‚àíb‚Ä≤) = gi(a) = 0,
because gi = 0. The reader may check that f is an R-map. Finally,
p‚àó( f ) = f p = g,
because if c = p(b), then g(b) = f (c) = f (p(b)). Therefore, g ‚ààim p‚àó.
‚Ä¢

Sec. 7.3
Functors
469
Example 7.47.
Even if the map i : A ‚ÜíB in the original exact sequence is assumed to be injective, the
functored sequence need not end with "‚Üí0;" that is, i‚àó: HomR(B, Y) ‚ÜíHomR(A, Y)
may fail be surjective.
We claim that HomZ(Q, Z) = 0. Suppose that f : Q ‚ÜíZ and f (a/b) Ã∏= 0 for some
a/b ‚ààQ. If f (a/b) = m, then, for all n > 0,
nf (a/nb) = f (na/nb) = f (a/b) = m.
Thus, m is divisible by every positive integer n, and this contradicts the fundamental theo-
rem of arithmetic.
If we apply the functor HomZ( , Z) to the short exact sequence
0 ‚ÜíZ
i‚ÜíQ
p‚ÜíQ/Z ‚Üí0,
where i is the inclusion and p is the natural map, then the induced map
i‚àó: HomZ(Q, Z) ‚ÜíHomZ(Z, Z)
cannot be surjective, for HomZ(Q, Z) = {0} while HomZ(Z, Z) Ã∏= {0}, because it con-
tains 1Z.
‚óÄ
DeÔ¨Ånition.
A contravariant functor T : RMod ‚ÜíAb is called left exact if exactness of
A
i‚ÜíB
p‚ÜíC ‚Üí0
implies exactness of
0 ‚ÜíT (C)
T (p)
‚àí‚ÜíT (B)
T (i)
‚àí‚ÜíT (A).
Thus, Theorem 7.46 shows that contravariant Hom functors HomR( , Y) are left exact
functors.12
There is a converse of Theorem 7.46; a dual statement holds for covariant Hom functors.
Proposition 7.48.
Let i : B‚Ä≤ ‚ÜíB and p: B ‚ÜíB‚Ä≤‚Ä≤ be R-maps, where R is a commutative
ring. If, for every R-module M,
0 ‚ÜíHomR(B‚Ä≤‚Ä≤, M)
p‚àó
‚àí‚ÜíHomR(B, M)
i‚àó
‚àí‚ÜíHomR(B‚Ä≤, M)
is an exact sequence, then so is
B‚Ä≤
i
‚àí‚ÜíB
p
‚àí‚ÜíB‚Ä≤‚Ä≤ ‚Üí0.
12These functors are called left exact because the functored sequence has 0 ‚Üíon the left.

470
Modules and Categories
Ch. 7
Proof.
(i) p is surjective.
Let M = B‚Ä≤‚Ä≤/ im p and let f : B‚Ä≤‚Ä≤ ‚ÜíB‚Ä≤‚Ä≤/ im p be the natural map, so that f ‚àà
Hom(B‚Ä≤‚Ä≤, M). Then p‚àó( f ) = f p = 0, so that f = 0, because p‚àóis injective. There-
fore, B‚Ä≤‚Ä≤/ im p = 0, and p is surjective.
(ii) im i ‚äÜker p.
Since i‚àóp‚àó= 0, we have 0 = (pi)‚àó. Hence, if M = B‚Ä≤‚Ä≤ and g = 1B‚Ä≤‚Ä≤, so that
g ‚ààHom(B‚Ä≤‚Ä≤, M), then 0 = (pi)‚àóg = gpi = pi, and so im i ‚äÜker p.
(iii) ker p ‚äÜim i.
Now choose M = B/ im i and let h : B ‚ÜíM be the natural map, so that h ‚àà
Hom(B, M). Clearly, i‚àóh = hi = 0, so that exactness of the Hom sequence gives an
element h‚Ä≤ ‚ààHomR(B‚Ä≤‚Ä≤, M) with p‚àó(h‚Ä≤) = h‚Ä≤ p = h. We have im i ‚äÜker p, by part (ii);
hence, if im i Ã∏= ker p, there is an element b ‚ààB with b /‚ààim i and b ‚ààker p. Thus,
hb Ã∏= 0 and pb = 0, which gives the contradiction hb = h‚Ä≤ pb = 0.
‚Ä¢
DeÔ¨Ånition.
A covariant functor T : RMod ‚ÜíAb is an exact functor if exactness of
0 ‚ÜíA
i‚ÜíB
p‚ÜíC ‚Üí0
implies exactness of
0 ‚ÜíT (A)
T (i)
‚àí‚ÜíT (B)
T (p)
‚àí‚ÜíT (C) ‚Üí0.
An exact contravariant functor is deÔ¨Åned similarly.
In the next section, we will see that Hom functors are exact functors for certain choices
of modules.
EXERCISES
7.34 If T : RMod ‚ÜíAb is an additive functor, of either variance, prove that T (0) = 0, where 0
denotes either a zero module or a zero morphism.
7.35 Give an example of a covariant functor that does not preserve coproducts.
Hint. Use Exercise 7.21(iii) on page 458.
7.36 Let A
S
‚àí‚ÜíB
T
‚àí‚ÜíC be functors. Prove that the composite A
T S
‚àí‚ÜíC is a functor that is
covariant if the variances of S and T are the same, and contravariant if the variances of S and
T are different.
7.37
(i) Prove that there is a functor on CommRings deÔ¨Åned on objects by R ‚ÜíR[x], and on
morphisms f : R ‚ÜíS by r ‚Üíf (r) (that is, in the formal notation for elements of
R[x], (r, 0, 0, ¬∑ ¬∑ ¬∑ ) ‚Üí( f (r), 0, 0, ¬∑ ¬∑ ¬∑ ).
(ii) Prove that there is a functor on Dom, the category of all domains, deÔ¨Åned on objects by
R ‚ÜíFrac(R), and on morphisms f : R ‚ÜíS by r/1 ‚Üíf (r)/1.
7.38 Prove that there is a functor Groups ‚ÜíAb taking each group G to G/G‚Ä≤, where G‚Ä≤ is its
commutator subgroup.

Sec. 7.4
Free Modules, Projectives, and Injectives
471
7.39
(i) If X is a set and k is a Ô¨Åeld, deÔ¨Åne the vector space kX to be the set of all functions
X ‚Üík under pointwise operations. Prove that there is a functor F : Sets ‚ÜíkMod
with F(X) = kX.
(ii) If X is a set, deÔ¨Åne F(X) to be the free group with basis X. Prove that there is a functor
F : Sets ‚ÜíGroups with F : X ‚ÜíF(X).
7.4 FREE MODULES, PROJECTIVES, AND INJECTIVES
The simplest modules are free modules and, as for groups, every module is a quotient
of a free module; that is, every module has a presentation by generators and relations.
Projective modules are generalizations of free modules, and they, too, turn out to be useful.
We deÔ¨Åne injective modules, as duals of projectives, but their value cannot be appreciated
until Chapter 10, when we discuss homological algebra. In the meantime, we will see here
that injective Z-modules are quite familiar.
DeÔ¨Ånition.
An R-module F is called a free R-module if F is isomorphic to a direct sum
of copies of R: that is, there is a (possibly inÔ¨Ånite) index set I with
F =

i‚ààI
Ri,
where Ri = ‚ü®bi‚ü©‚àº= R for all i. We call B = {bi : i ‚ààI} a basis of F.
A free Z-module is a free abelian group, and every commutative ring R, when consid-
ered as a module over itself, is itself a free R-module.
From our discussion of direct sums, we know that each m ‚ààF has a unique expression
of the form
m =

i‚ààI
ribi,
where ri ‚ààR and almost all ri = 0. A basis of a free module has a strong resemblence to
a basis of a vector space. Indeed, it is easy to see that a vector space V over a Ô¨Åeld k is a
free k-module, and that the two notions of basis coincide in this case.
There is a straightforward generalization of Theorem 3.92 from Ô¨Ånite-dimensional vec-
tor spaces to arbitrary free modules (in particular, to inÔ¨Ånite-dimensional vector spaces).
Proposition 7.49.
Let F be a free R-module, and let B = {bi : i ‚ààI} be a basis of F. If
M is any R-module and if Œ≥ : B ‚ÜíM is any function, then there exists a unique R-map
g : F ‚ÜíM with g(bi) = Œ≥ (bi) for all i ‚ààI.
F
g

B

Œ≥
 M

472
Modules and Categories
Ch. 7
Proof.
Every element v ‚ààF has a unique expression of the form
v =

i‚ààI
ribi,
where ri ‚ààR and almost all ri = 0. DeÔ¨Åne g : F ‚ÜíM by
g(v) =

i‚ààI
riŒ≥ (bi).
‚Ä¢
Here is a fancy proof of this result. By Proposition 7.30, a free module F is the coprod-
uct of {‚ü®bi‚ü©: i ‚ààI}, with injections Œ±i mapping ribi to the vector having ribi in the ith
coordinate and 0's elsewhere. As for any coproduct, there is a unique map Œ∏ : F ‚ÜíM
with Œ∏(bi) = Œ≥ (bi). The maps Œ∏ and g agree on each element of the basis B, so that Œ∏ = g.
DeÔ¨Ånition.
The number of elements in a basis is called the rank of F.
Of course, rank is the analog of dimension. The next proposition shows that rank is
well-deÔ¨Åned.
Proposition 7.50.
(i) If R is a nonzero commutative ring, then any two bases of a free R-module F have
the same cardinality; that is, the same number of elements.
(ii) If R is a nonzero commutative ring, then free R-modules F and F‚Ä≤ are isomorphic
if and only if rank(F) = rank(F‚Ä≤).
Proof.
(i) Choose a maximal ideal I in R (which exists, by Theorem 6.46). If X is a
basis of the free R-module F, then Exercise 7.6 on page 440 shows that the set of cosets
{v + I F : v ‚ààX} is a basis of the vector space F/I F over the Ô¨Åeld R/I. If Y is another
basis of F, then the same argument gives {u + I F : u ‚ààY} a basis of F/I F. But any two
bases of a vector space have the same size (which is the dimension of the space), and so
|X| = |Y|, by Theorem 6.51.
(ii) Let X be a basis of F, let X‚Ä≤ be a basis of F‚Ä≤, and let Œ≥ : X ‚ÜíX‚Ä≤ be a bijection.
Composing Œ≥ with the inclusion X‚Ä≤ ‚ÜíF‚Ä≤, we may assume that Œ≥ : X ‚ÜíF‚Ä≤. By Propo-
sition 7.49, there is a unique R-map œï : F ‚ÜíF‚Ä≤ extending Œ≥ . Similarly, we may regard
Œ≥ ‚àí1 : X‚Ä≤ ‚ÜíX as a function X‚Ä≤ ‚ÜíF, and there is a unique œà : F‚Ä≤ ‚ÜíF extending Œ≥ ‚àí1.
Finally, both œàœï and 1F extend 1X, so that œàœï = 1F. Similarly, the other composite
is 1F‚Ä≤, and so œï : F ‚ÜíF‚Ä≤ is an isomorphism. (The astute reader will notice a strong
resemblance of this proof to the uniqueness of a solution to a universal mapping problem.)
Conversely, suppose that œï : F ‚ÜíF‚Ä≤ is an isomorphism. If {vi : i ‚ààI} is a basis of
F, then it is easy to see that {œï(vi) : i ‚ààI} is a basis of F‚Ä≤. But any two bases of the free
module F‚Ä≤ have the same size, namely, rank(F‚Ä≤), by part (i). Hence, rank(F‚Ä≤) = rank(F).
‚Ä¢
The next proposition will enable us to use free modules to describe arbitrary modules.

Sec. 7.4
Free Modules, Projectives, and Injectives
473
Proposition 7.51.
Every R-module M is a quotient of a free R-module F. Moreover, M
is Ô¨Ånitely generated if and only if F can be chosen to be Ô¨Ånitely generated.
Proof.
Let F be the direct sum of |M| copies of R (so F is a free module), and let
{xm : m ‚ààM} be a basis of F. By Proposition 7.49, there is an R-map g : F ‚ÜíM with
g(xm) = m for all m ‚ààM. Obviously, g is a surjection, and so F/ ker g ‚àº= M.
If M is Ô¨Ånitely generated, then M = ‚ü®m1, . . . , mn‚ü©. If we choose F to be the free R-
module with basis {x1, . . . , xn}, then the map g : F ‚ÜíM with g(xi) = mi is a surjection,
for
im g = ‚ü®g(x1), . . . , g(xn)‚ü©= ‚ü®m1, . . . , mn‚ü©= M.
The converse is obvious, for any image of a Ô¨Ånitely generated module is itself Ô¨Ånitely
generated
‚Ä¢
The last proposition can be used to construct modules with prescribed properties. For
example, let us consider Z-modules (i.e., abelian groups). The group Q/Z contains an
element a of order 2 satisfying the equations a = 2nan for all n ‚â•1; take a = 1
2 + Z and
an = 1/2n+1 + Z. Of course, HomZ(Q, Q/Z) Ã∏= {0} because it contains the natural map.
Is there an abelian group G with HomZ(Q, G) = {0} that contains an element a of order 2
satisfying the equations a = 2nan for all n ‚â•1? Let F be the free abelian group with basis
{a, b1, b2, . . . , bn, . . .}
and relations
{2a, a ‚àí2nbn, n ‚â•1};
that is, let K be the subgroup of F generated by {2a, a ‚àí2nbn, n ‚â•1}. Exercise 7.48
on page 487 asks the reader to verify that G = F/K satisÔ¨Åes the desired properties. This
construction is a special case of deÔ¨Åning an R-module by generators and relations (as we
have already done for groups).
DeÔ¨Ånition.
Let X = {xi : i ‚ààI} be a basis of a free R-module F, and let R = {
i r ji xi :
j ‚ààJ} be a subset of F. If K is the submodule of F generated by R, then we say that the
module M = F/K has generators X and relations R.13 We also say that the ordered pair
(X|R) is a presentation of M.
We will return to presentations at this end of the section, but let us now focus on the key
property of bases, Lemma 7.49 (which holds for free modules as well as for vector spaces),
in order to get a theorem about free modules that does not mention bases.
Theorem 7.52.
If R is a commutative ring and F is a free R-module, then for every
surjection p: A ‚ÜíA‚Ä≤‚Ä≤ and each h : F ‚ÜíA‚Ä≤‚Ä≤, there exists a homomorphism g making the
13A module is called free because it has no entangling relations.

474
Modules and Categories
Ch. 7
following diagram commute:
F
h

g

A
p
 A‚Ä≤‚Ä≤
 0
Proof.
Let {bi : i ‚ààI} be a basis of F. Since p is surjective, there is ai ‚ààA with
p(ai) = h(bi) for all i. By Proposition 7.49, there is an R-map g : F ‚ÜíA with
g(bi) = ai for all i.
Now pg(bi) = p(ai) = h(bi), so that pg agrees with h on the basis {bi : i ‚ààI}; it follows
that pg = h on ‚ü®{bi : i ‚ààI}‚ü©= F; that is, pg = h.
‚Ä¢
DeÔ¨Ånition.
We call a map g : F ‚ÜíA with pg = h (in the diagram in Theorem 7.52) a
lifting of h.
If C is any, not necessarily free, module, then a lifting g of h, should one exist, need not
be unique. Since pi = 0, where i : ker p ‚ÜíA is the inclusion, other liftings are g + i f
for any f ‚ààHomR(C, ker p). Indeed, this is obvious from the exact sequence
0 ‚ÜíHom(C, ker p)
i‚àó
‚àí‚ÜíHom(C, A)
p‚àó
‚àí‚ÜíHom(C, A‚Ä≤‚Ä≤).
Any two liftings of h differ by a map in ker p‚àó= im i‚àó‚äÜHom(C, A).
We now promote this (basis-free) property of free modules to a deÔ¨Ånition.
DeÔ¨Ånition.
A module P is projective if, whenever p is surjective and h is any map, there
exists a lifting g; that is, there exists a map g making the following diagram commute:
P
h

g

A
p
 A‚Ä≤‚Ä≤
 0
We know that every free module is projective; is every projective R-module free? We
shall see that the answer to this question depends on the ring R. Note that if projective
R-modules happen to be free, then free modules are characterized without having to refer
to a basis.
Let us now see that projective modules arise in a natural way. We know that the Hom
functors are left exact; that is, for any module P, applying HomR(P, ) to an exact sequence
0 ‚ÜíA‚Ä≤
i
‚àí‚ÜíA
p
‚àí‚ÜíA‚Ä≤‚Ä≤
gives an exact sequence
0 ‚ÜíHomR(P, A‚Ä≤)
i‚àó
‚àí‚ÜíHomR(P, A)
p‚àó
‚àí‚ÜíHomR(P, A‚Ä≤‚Ä≤).

Sec. 7.4
Free Modules, Projectives, and Injectives
475
Proposition 7.53.
A module P is projective if and only if HomR(P, ) is an exact functor.
Remark.
Since HomR(P, ) is a left exact functor, the thrust of the proposition is that p‚àó
is surjective whenever p is surjective.
‚óÄ
Proof.
If P is projective, then given h : P ‚ÜíA‚Ä≤‚Ä≤, there exists a lifting g : P ‚ÜíA with
pg = h. Thus, if h ‚ààHomR(P, A‚Ä≤‚Ä≤), then h = pg = p‚àó(g) ‚ààim p‚àó, and so p‚àóis
surjective. Hence, Hom(P, ) is an exact functor.
For the converse, assume that Hom(P, ) is an exact functor, so that p‚àóis surjective:
If h ‚ààHomR(P, A‚Ä≤‚Ä≤), there exists g ‚ààHomR(P, A) with h = p‚àó(g) = pg. This says
that given p and h, there exists a lifting g making the diagram commute; that is, P is
projective.
‚Ä¢
Proposition 7.54.
A module P is projective if and only if every short exact sequence
0 ‚ÜíA
i‚ÜíB
p‚ÜíP ‚Üí0
is split.
Proof.
If P is projective, then there exists j : P ‚ÜíB making the following diagram
commute; that is, pj = 1P.
P
j

1P

B
p
 P
 0
Corollary 7.17 now gives the result.
Conversely, assume that every short exact sequence ending with P splits. Consider the
diagram
P
f

B
p
 C
 0
with p surjective. Now form the pullback
D
Œ±

Œ≤

P
j

f

B
p
 C
 0
By Exercise 7.28 on page 459, surjectivity of p in the pullback diagram gives surjectivity
of Œ±. By hypothesis, there is a map j : P ‚ÜíD with Œ±j = 1P. DeÔ¨Åne g : P ‚ÜíB by
g = Œ≤j. We check:
pg = pŒ≤j = f Œ±j = f 1P = f.
Therefore, P is projective.
‚Ä¢
We restate one half of this proposition so that the word exact is not mentioned.

476
Modules and Categories
Ch. 7
Corollary 7.55.
Let A be a submodule of a module B. If B/A is projective, then there is
a submodule C of B with C ‚àº= B/A and B = A ‚äïC.
Theorem 7.56.
An R-module P is projective if and only if P is a direct summand of a
free R-module.
Proof.
Assume that P is projective. By Proposition 7.51, every module is a quotient of a
free module. Thus, there is a free module F and a surjection g : F ‚ÜíP, and so there is
an exact sequence
0 ‚Üíker g ‚ÜíF
g‚ÜíP ‚Üí0.
Proposition 7.54 now shows that P is a direct summand of F.
Suppose that P is a direct summand of a free module F, so there are maps q : F ‚ÜíP
and j : P ‚ÜíF with qj = 1P. Now consider the diagram
F
q

h

P
j

f

B
p
 C
 0,
where p is surjective. The composite f q is a map F ‚ÜíC; since F is free, it is projective,
and so there is a map h : F ‚ÜíB with ph = f q. DeÔ¨Åne g : P ‚ÜíB by g = hj. It remains
to prove that pg = f . But
pg = phj = f qj = f 1P = f.
‚Ä¢
Actually, the second half of the proof shows that any direct summand of a projective
module is itself projective.
We can now give an example of a commutative ring R and a projective R-module that
is not free.
Example 7.57.
The ring R = I6 is the direct sum of two ideals:
I6 = J ‚äïI,
where
J = {[0], [2], [4]} ‚àº= I3 and I = {[0], [3]} ‚àº= I2.
Now I6 is a free module over itself, and so J and I, being direct summands of a free
module, are projective I6-modules. Neither J nor I can be free, however. After all, a
(Ô¨Ånitely generated) free I6-module F is a direct sum of, say, n copies of I6, and so F has
6n elements. Therefore, J is too small to be free, for it has only three elements.
‚óÄ

Sec. 7.4
Free Modules, Projectives, and Injectives
477
Describing projective R-modules is a problem very much dependent on the ring R. In
Chapter 9, for example, we will prove that if R is a PID, then every submodule of a free
module is itself free. It will then follow from Theorem 7.56 that every projective R-module
is free in this case. A much harder result is that if R = k[x1, . . . , xn] is the polynomial
ring in n variables over a Ô¨Åeld k, then every projective R-module is also free; this theorem,
implicitly conjectured14 by J.-P. Serre, was proved, independently, by D. Quillen and by A.
Suslin (see Rotman, An Introduction to Homological Algebra, pages 138-145, for a proof).
There is a proof of the Quillen-Suslin theorem using Gr¬®obner bases, due to N. Fitchas, A.
Galligo, and B. Sturmfels.
There are domains having projective modules that are not free. For example, if R is the
ring of all the algebraic integers in an algebraic number Ô¨Åeld (that is, an extension of Q of
Ô¨Ånite degree), then every ideal in R is a projective R-module. There are such rings R that
are not PIDs, and any ideal in R that is not principal is a projective module that is not free
(we will see this in Chapter 11 when we discuss Dedekind rings).
Here is another characterization of projective modules. Note that if A is a free R-module
with basis {ai : i ‚ààI} ‚äÜA, then each x ‚ààA has a unique expression x = 
i‚ààI riai, and
so there are R-maps œïi : A ‚ÜíR given by œïi : x ‚Üíri.
Proposition 7.58.
An R-module A is projective if and only if there exist elements
{ai : i ‚ààI} ‚äÜA and R-maps {œïi : A ‚ÜíR : i ‚ààI} such that
(i) for each x ‚ààA, almost all œïi(x) = 0;
(ii) for each x ‚ààA, we have x = 
i‚ààI(œïi x)ai.
Moreover, A is generated by {ai : i ‚ààI} ‚äÜA in this case.
Proof.
If A is projective, there is a free R-module F and a surjective R-map œà : F ‚ÜíA.
Since A is projective, there is an R-map œï : A ‚ÜíF with œàœï = 1A, by Proposition 7.54.
Let {ei : i ‚ààI} be a basis of F, and deÔ¨Åne ai = œà(ei). Now if x ‚ààA, then there is a unique
expression œï(x) = 
i riei, where ri ‚ààR and almost all ri = 0. DeÔ¨Åne œïi : A ‚ÜíR by
œïi(x) = ri. Of course, given x, we have œïi(x) = 0 for almost all i. Since œà is surjective,
A is generated by {ai = œà(ei) : i ‚ààI}. Finally,
x = œàœï(x) = œà

riei

=

riœà(ei) =

(œïi x)œà(ei) =

(œïi x)ai.
Conversely, given {ai : i ‚ààI} ‚äÜA and a family of R-maps {œïi : A ‚Üí
R : i ‚ààI}
as in the statement, deÔ¨Åne F to be the free R-module with basis {ei : i ‚ààI}, and deÔ¨Åne
an R-map œà : F ‚ÜíA by œà : ei ‚Üíai. It sufÔ¨Åces to Ô¨Ånd an R-map œï : A ‚ÜíF with
œàœï = 1A, for then A is (isomorphic to) a retract (i.e., A is a direct summand of F), and
hence A is projective. DeÔ¨Åne œï by œï(x) = 
i(œïi x)ei, for x ‚ààA. The sum is Ô¨Ånite, by
14On page 243 of "Faisceaux Alg`ebriques Coh¬¥erents," Annals of Mathematics 61 (1955), 197-278, Serre writes
"... on ignore s'il existe des A-modules projectifs de type Ô¨Åni qui ne soient pas libres." Here, A = k[x1, . . . , xn].

478
Modules and Categories
Ch. 7
condition (i), and so œï is well-deÔ¨Åned. By condition (ii),
œàœï(x) = œà

(œïi x)ei =

(œïi x)œà(ei) =

(œïi x)ai = x;
that is, œàœï = 1A.
‚Ä¢
DeÔ¨Ånition.
If A is an R-module, then a subset {ai : i ‚ààI} ‚äÜA and a family of R-maps
{œïi : A ‚ÜíR : i ‚ààI} satisfying the condition in Proposition 7.58 is called a projective
basis.
An interesting application of projective bases is due to R. Bkouche. Let X be a locally
compact Hausdorff space, let C(X) be the ring of all continuous real-valued functions on
X, and let J be the ideal in C(X) consisting of all such functions having compact support.
Then X is a paracompact space if and only if J is a projective C(X)-module.
Remark.
The deÔ¨Ånition of projective module can be used to deÔ¨Åne a projective object in
any category (we do not assert that such objects always exist), if we can translate surjection
into the language of categories. One candidate arises from Exercise 7.18 on page 441, but
we shall see now that deÔ¨Åning surjections in arbitrary categories is not so straightforward.
DeÔ¨Ånition.
A morphism œï : B ‚ÜíC in a category C is an epimorphism if œï can be
canceled from the right; that is, for all objects D and all morphisms h : C ‚ÜíD and
k : C ‚ÜíD, we have hœï = kœï implies h = k.
B
œï‚ÜíC
h
‚áí
k
D
Now Exercise 7.18 on page 441 shows that epimorphisms in RMod are precisely the
surjections, and Exercises 7.45 on page 487 and 7.19 on page 441 show that epimorphisms
in Sets and in Groups, respectively, are also surjections. However, in CommRings, it is
easy to see that if R is a domain, then the ring homomorphism œï : R ‚ÜíFrac(R), given
by r ‚Üír/1, is an epimorphism; if A is a commutative ring and h, k : Frac(R) ‚ÜíA are
ring homomorphisms that agree on R, then h = k. But œï is not a surjective function if R
is not a Ô¨Åeld. A similar phenomenon occurs in Top. If f : X ‚ÜíY is a continuous map
with im f a dense subspace of Y, then f is an epimorphism, because any two continuous
functions agreeing on a dense subspace must be equal.
There is a similar problem with monomorphisms, a generalization of injections to arbi-
trary categories: A category whose objects have underlying sets may have monomorphisms
whose underlying function is not an injection.
‚óÄ
Let us return to presentations of modules.
DeÔ¨Ånition.
An R-module M is Ô¨Ånitely presented if it has a presentation (X|R) in which
both X and R are Ô¨Ånite.

Sec. 7.4
Free Modules, Projectives, and Injectives
479
If M is Ô¨Ånitely presented, there is a short exact sequence
0 ‚ÜíK ‚ÜíF ‚ÜíM ‚Üí0,
where F is free and both K and F are Ô¨Ånitely generated. Equivalently, M is Ô¨Ånitely
presented if there is an exact sequence
F‚Ä≤ ‚ÜíF ‚ÜíM ‚Üí0,
where both F‚Ä≤ and F are Ô¨Ånitely generated free modules (just map a Ô¨Ånitely generated free
module F‚Ä≤ onto K). Note that the second exact sequence does not begin with "0 ‚Üí."
Proposition 7.59.
If R is a commutative noetherian ring, then every Ô¨Ånitely generated
R-module is Ô¨Ånitely presented.
Proof.
If M is a Ô¨Ånitely generated R-module, then there is a Ô¨Ånitely generated free R-
module F and a surjection œï : F ‚ÜíM. Since R is noetherian, Proposition 7.23 says that
every submodule of F is Ô¨Ånitely generated. In particular, ker œï is Ô¨Ånitely generated, and so
M is Ô¨Ånitely presented.
‚Ä¢
Every Ô¨Ånitely presented module is Ô¨Ånitely generated, but we will soon see that the con-
verse may be false. We begin by comparing two presentations of a module (we generalize
a bit by replacing free modules by projectives).
Proposition 7.60 (Schanuel's Lemma).
Given exact sequences
0 ‚ÜíK
i‚ÜíP
œÄ‚ÜíM ‚Üí0
and
0 ‚ÜíK ‚Ä≤
i‚Ä≤
‚ÜíP‚Ä≤ œÄ‚Ä≤
‚ÜíM ‚Üí0,
where P and P‚Ä≤ are projective, then there is an isomorphism
K ‚äïP‚Ä≤ ‚àº= K ‚Ä≤ ‚äïP.
Proof.
Consider the diagram with exact rows
0
 K
Œ±

i
 P
œÄ

Œ≤

M

1M

0
0
 K ‚Ä≤
i‚Ä≤
 P‚Ä≤
œÄ‚Ä≤
 M
 0
Since P is projective, there is a map Œ≤ : P ‚ÜíP‚Ä≤ with œÄ‚Ä≤Œ≤ = œÄ; that is, the right square
in the diagram commutes. We now show that there is a map Œ± : K ‚ÜíK ‚Ä≤ making the
other square commute. If x ‚ààK, then œÄ‚Ä≤Œ≤ix = œÄix = 0, because œÄi = 0. Hence,
Œ≤ix ‚ààker œÄ‚Ä≤ = im i‚Ä≤; thus, there is x‚Ä≤ ‚ààK ‚Ä≤ with i‚Ä≤x‚Ä≤ = Œ≤ix; moreover, x‚Ä≤ is unique

480
Modules and Categories
Ch. 7
because i‚Ä≤ is injective. Therefore, Œ± : x ‚Üíx‚Ä≤ is a well-deÔ¨Åned function Œ± : K ‚ÜíK ‚Ä≤ that
makes the Ô¨Årst square commute. The reader can show that Œ± is an R-map.
This commutative diagram with exact rows gives an exact sequence
0 ‚ÜíK
Œ∏‚ÜíP ‚äïK ‚Ä≤ œà‚ÜíP‚Ä≤ ‚Üí0,
where Œ∏ : x ‚Üí(ix, Œ±x) and œà : (u, x‚Ä≤) ‚ÜíŒ≤u ‚àíi‚Ä≤x‚Ä≤, for x ‚ààK, u ‚ààP, and x‚Ä≤ ‚ààK ‚Ä≤.
Exactness of this sequence is a straightforward calculation that is left to the reader; this
sequence splits because P‚Ä≤ is projective.
‚Ä¢
Corollary 7.61.
If M is Ô¨Ånitely presented and
0 ‚ÜíK ‚ÜíF ‚ÜíM ‚Üí0
is an exact sequence, where F is a Ô¨Ånitely generated free module, then K is Ô¨Ånitely gener-
ated.
Proof.
Since M is Ô¨Ånitely presented, there is an exact sequence
0 ‚ÜíK ‚Ä≤ ‚ÜíF‚Ä≤ ‚ÜíM ‚Üí0
with F‚Ä≤ free and with both F‚Ä≤ and K ‚Ä≤ Ô¨Ånitely generated. By Schanuel's lemma, K ‚äïF‚Ä≤ ‚àº=
K ‚Ä≤ ‚äïF. Now K ‚Ä≤ ‚äïF is Ô¨Ånitely generated because both summands are, so that the left
side is also Ô¨Ånitely generated. But K, being a summand, is also a homomorphic image of
K ‚äïF‚Ä≤, and hence it is Ô¨Ånitely generated.
‚Ä¢
We can now give an example of a Ô¨Ånitely generated module that is not Ô¨Ånitely presented.
Example 7.62.
Let R be a commutative ring that is not noetherian; that is, R contains an ideal I that is not
Ô¨Ånitely generated (see Example 6.39). We claim that the R-module M = R/I is Ô¨Ånitely
generated but not Ô¨Ånitely presented. Of course, M is Ô¨Ånitely generated; it is even cyclic.
If M were Ô¨Ånitely presented, then there would be an exact sequence 0 ‚ÜíK ‚ÜíF ‚Üí
M ‚Üí0 with F free and both K and F Ô¨Ånitely generated. Comparing this with the exact
sequence 0 ‚ÜíI ‚ÜíR ‚ÜíM ‚Üí0, as in Corollary 7.61, gives I Ô¨Ånitely generated, a
contradiction. Therefore, M is not Ô¨Ånitely presented.
‚óÄ
There is another type of module that also turns out to be interesting.
DeÔ¨Ånition.
If E is a module for which the contravariant Hom functor HomR(
, E) is
an exact functor‚Äîthat is, if HomR( , E) preserves all short exact sequences‚Äîthen E is
called an injective module.
The next proposition is the dual of Proposition 7.53.

Sec. 7.4
Free Modules, Projectives, and Injectives
481
Proposition 7.63.
A module E is injective if and only if a dotted arrow always exists
making the following diagram commute whenever i is an injection:
E
0
 A
i

f

B
g

In words, every homomorphism from a submodule into E can always be extended to a
homomorphism from the big module into E.
Remark.
Since HomR( , E) is a left exact contravariant functor, the thrust of the propo-
sition is that i‚àóis surjective whenever i is injective.
Injective modules are duals of projective modules in that both of these terms are charac-
terized by diagrams, and the diagram for injectivity is the diagram for projectivity having
all arrows reversed.
‚óÄ
Proof.
If E is injective, then Hom(, E) is an exact functor, so that i‚àóis surjective. There-
fore, if f ‚ààHomR(A, E), there exists g ‚ààHomR(B, E) with f = i‚àó(g) = gi; that is, the
diagram commutes.
For the converse, if E satisÔ¨Åes the diagram condition, then given f : A ‚ÜíE, there
exists g : B ‚ÜíE with gi = f . Thus, if f ‚ààHomR(A, E), then f = gi = i‚àó(g) ‚ààim i‚àó,
and so i‚àóis surjective. Hence, Hom( , E) is an exact functor, and so E is injective.
‚Ä¢
The next result is the dual of Proposition 7.54.
Proposition 7.64.
A module E is injective if and only if every short exact sequence
0 ‚ÜíE
i‚ÜíB
p‚ÜíC ‚Üí0
is split.
Proof.
If E is injective, then there exists q : B ‚ÜíE making the following diagram
commute; that is, qi = 1E.
E
0
 E
i

1E

B
q

Exercise 7.17 on page 441 now gives the result.
Conversely, assume every exact sequence beginning with E splits. The pushout of
E
0
 A
i

f

B

482
Modules and Categories
Ch. 7
is the diagram
E
Œ±
 D
0
 A
i

f

B
Œ≤

By Exercise 7.28 on page 459, the map Œ± is an injection, so that
0 ‚ÜíE ‚ÜíD ‚Üícoker Œ± ‚Üí0
splits; that is, there is q : D ‚ÜíE with qŒ± = 1E. If we deÔ¨Åne g : B ‚ÜíE by g = qŒ≤, then
the original diagram commutes:
gi = qŒ≤i = qŒ±f = 1E f = f.
Therefore, E is injective.
‚Ä¢
This proposition can be restated without mentioning the word exact.
Corollary 7.65.
If an injective module E is a submodule of a module M, then E is a
direct summand of M: There is a submodule S of M with S ‚àº= M/E and M = E ‚äïS.
Proposition 7.66.
If {Ei : i ‚ààI} is a family of injective modules, then 
i‚ààI Ei is also
an injective module.
Proof.
Consider the diagram
E
0
 A
f

Œ∫
 B,
where E =  Ei. Let pi : E ‚ÜíEi be the ith projection. Since Ei is injective, there is
gi : B ‚ÜíEi with giŒ∫ = pi f . Now deÔ¨Åne g : B ‚ÜíE by g : b ‚Üí(gi(b)). The map g
does extend f , for if b = Œ∫a, then
g(Œ∫a) = (gi(Œ∫a)) = (pi f a) = f a,
because x = (pi x) is true for every x in the product.
‚Ä¢
Corollary 7.67.
A Ô¨Ånite direct sum of injective modules is injective.
Proof.
The direct sum of Ô¨Ånitely many modules coincides with the direct product.
‚Ä¢
A useful result is the following theorem due to R. Baer.

Sec. 7.4
Free Modules, Projectives, and Injectives
483
Theorem 7.68 (Baer Criterion).
An R-module E is injective if and only if every R-map
f : I ‚ÜíE, where I is an ideal in R, can be extended to R.
E
0
 I
i

f

R
g

Proof.
Since any ideal I is a submodule of R, the existence of an extension g of f is just
a special case of the deÔ¨Ånition of injectivity of E.
Suppose we have the diagram
E
0
 A
i

f

B,
where A is a submodule of a module B. For notational convenience, let us assume that i is
the inclusion [this assumption amounts to permitting us to write a instead of i(a) whenever
a ‚ààA]. We are going to use Zorn's lemma on approximations to an extension of f . More
precisely, let X be the set of all ordered pairs (A‚Ä≤, g‚Ä≤), where A ‚äÜA‚Ä≤ ‚äÜB and g‚Ä≤ : A‚Ä≤ ‚ÜíE
extends f ; that is, g‚Ä≤|A = f . Note that X Ã∏= ‚àÖbecause (A, f ) ‚ààX. Partially order X by
deÔ¨Åning
(A‚Ä≤, g‚Ä≤) ‚™Ø(A‚Ä≤‚Ä≤, g‚Ä≤‚Ä≤)
to mean A‚Ä≤ ‚äÜA‚Ä≤‚Ä≤ and g‚Ä≤‚Ä≤ extends g‚Ä≤. The reader may supply the argument that Zorn's
lemma applies, and so there exists a maximal element (A0, g0) in X. If A0 = B, we are
done, and so we may assume that there is some b ‚ààB with b /‚ààA0.
DeÔ¨Åne
I = {r ‚ààR : rb ‚ààA0}.
It is easy to see that I is an ideal in R. DeÔ¨Åne h : I ‚ÜíE by
h(r) = g0(rb).
By hypothesis, there is a map h‚àó: R ‚ÜíE extending h. Finally, deÔ¨Åne A1 = A0 + ‚ü®b‚ü©and
g1 : A1 ‚ÜíE by
g1(a0 + rb) = g0(a0) + rh‚àó(1),
where a0 ‚ààA0 and r ‚ààR.
Let us show that g1 is well-deÔ¨Åned. If a0+rb = a‚Ä≤
0+r‚Ä≤b, then (r ‚àír‚Ä≤)b = a‚Ä≤
0‚àía0 ‚ààA0;
it follows that r ‚àír‚Ä≤ ‚ààI. Therefore, g0((r ‚àír‚Ä≤)b) and h(r ‚àír‚Ä≤) are deÔ¨Åned, and we have
g0(a‚Ä≤
0 ‚àía0) = g0((r ‚àír‚Ä≤)b) = h(r ‚àír‚Ä≤) = h‚àó(r ‚àír‚Ä≤) = (r ‚àír‚Ä≤)h‚àó(1).
Thus, g0(a‚Ä≤
0) ‚àíg0(a0) = rh‚àó(1) ‚àír‚Ä≤h‚àó(1) and g0(a‚Ä≤
0) + r‚Ä≤h‚àó(1) = g0(a0) + rh‚àó(1), as
desired. Clearly, g1(a0) = g0(a0) for all a0 ‚ààA0, so that the map g1 extends g0. We
conclude that (A0, g0) ‚â∫(A1, g1), contradicting the maximality of (A0, g0). Therefore,
A0 = B, the map g0 is a lifting of f , and E is injective.
‚Ä¢

484
Modules and Categories
Ch. 7
Are arbitrary direct sums of injective modules injective?
Proposition 7.69.
If R is noetherian and {Ei : i ‚ààI} is a family of injective R-modules,
then 
i‚ààI Ei is an injective module.
Proof.
By the Baer criterion, Theorem 7.68, it sufÔ¨Åces to complete the diagram

i‚ààI Ei
0
 J
f

Œ∫
 R,
where J is an ideal in R.
Since R is noetherian, J is Ô¨Ånitely generated, say, J =
(a1, . . . , an). For k = 1, . . . , n, f (ak) ‚àà
i‚ààI Ei has only Ô¨Ånitely many nonzero co-
ordinates, occurring, say, at indices in S(ak) ‚äÜI. Thus, S = !n
k=1 S(ak) is a Ô¨Ånite set,
and so im f ‚äÜ
i‚ààS Ei; by Corollary 7.67, this Ô¨Ånite sum is injective. Hence, there is an
R-map g‚Ä≤ : R ‚Üí
i‚ààS Ei extending f . Composing g‚Ä≤ with the inclusion of 
i‚ààS Ei into

i‚ààI Ei completes the given diagram.
‚Ä¢
It is a theorem of H. Bass that the converse of Proposition 7.69 is true: If every direct
sum of injective R-modules is injective, then R is noetherian (see Theorem 8.105).
We can now give some examples of injective modules.
Proposition 7.70.
If R is a domain, then Q = Frac(R) is an injective R-module.
Proof.
By Baer's criterion, it sufÔ¨Åces to extend an R-map f : I ‚ÜíQ, where I is an ideal
in R, to all of R. Note Ô¨Årst that if a, b ‚ààI are nonzero, then af (b) = f (ab) = bf (a), so
that
f (a)/a = f (b)/b in Q for all nonzero a, b ‚ààI;
let c ‚ààQ denote their common value (note how I being an ideal is needed to deÔ¨Åne c: the
product ab must be deÔ¨Åned, and either factor can be taken outside the parentheses). DeÔ¨Åne
g : R ‚ÜíQ by
g(r) = rc
for all r ‚ààR. It is obvious that g is an R-map. To see that g extends f , suppose that a ‚ààI;
then
g(a) = ac = af (a)/a = f (a).
It now follows from Baer's criterion that Q is an injective R-module.
‚Ä¢
DeÔ¨Ånition.
If R is a domain, then an R-module D is divisible if, for each d ‚ààD and
every nonzero r ‚ààR, there exists d‚Ä≤ ‚ààD with d = rd‚Ä≤.

Sec. 7.4
Free Modules, Projectives, and Injectives
485
Example 7.71.
Let R be a domain.
(i) Frac(R) is a divisible R-module.
(ii) Every direct sum of divisible R-modules is divisible. Hence, every vector space over
Frac(R) is a divisible R-module.
(iii) Every quotient of a divisible R-module is divisible.
‚óÄ
Lemma 7.72.
If R is a domain, then every injective R-module E is divisible.
Proof.
Assume that E is injective. Let e ‚ààE and let r0 ‚ààR be nonzero; we must
Ô¨Ånd x ‚ààE with e = r0x. DeÔ¨Åne f : (r0) ‚ÜíE by f (rr0) = re (note that f is well-
deÔ¨Åned: Since R is a domain, rr0 = r‚Ä≤r0 implies r = r‚Ä≤). Since E is injective, there exists
h : R ‚ÜíE extending f . In particular,
e = f (r0) = h(r0) = r0h(1),
so that x = h(1) is the element in E required by the deÔ¨Ånition of divisible.
‚Ä¢
We now prove that the converse of Lemma 7.72 is true for PIDs. Proposition 11.111
shows that a domain R is a Dedekind ring (deÔ¨Åned in the last chapter) if and only if every
divisible R-module is injective.
Corollary 7.73.
If R is a PID, then an R-module E is injective if and only if it is divisible.
Proof.
Assume that E is divisible. By the Baer criterion, Theorem 7.68, it sufÔ¨Åces to
extend maps f : I ‚ÜíE to all of R. Since R is a PID, I is principal; say, I = (r0) for
some r0 ‚ààI. Since E is divisible, there exists e ‚ààE with r0e = f (r0). DeÔ¨Åne h : R ‚ÜíE
by h(r) = re. It is easy to see that h is an R-map extending f , and so E is injective.
‚Ä¢
Remark.
There are domains for which divisible modules are not injective; indeed, there
are domains for which a quotient of an injective module need not be injective.
‚óÄ
Example 7.74.
In light of Example 7.71, the following abelian groups are injective Z-modules:
Q,
R,
C,
Q/Z,
R/Z,
S1,
where S1 is the circle group; that is, the multiplicative group of all complex numbers z
with |z| = 1.
‚óÄ
Proposition 7.51 says that, over any ring, every module is a quotient of a projective
module (actually, it is a stronger result: Every module is a quotient of a free module). The
next result is the dual result for Z-modules: Every abelian group can be imbedded as a
subgroup of an injective abelian group. We will prove this result for modules over any ring
in Chapter 8 (see Theorem 8.104).

486
Modules and Categories
Ch. 7
Corollary 7.75.
Every abelian group M can be imbedded as a subgroup of some injective
abelian group.
Proof.
By Proposition 7.51, there is a free abelian group F = 
i Zi with M = F/K for
some K ‚äÜF. Now
M = F/K =

i
Zi

/K ‚äÜ

i
Q i

/K,
where we have merely imbedded each copy Zi of Z into a copy Q i of Q. But Example 7.71
gives each Q i divisible, hence gives 
i Q i divisible, and hence gives divisibility of the
quotient (
i Q i)/K. By the Proposition, (
i Q i)/K is injective.
‚Ä¢
Writing a module as a quotient of a free module is the essence of describing it by
generators and relations. We may think of the corollary as dualizing this idea.
The next result gives a curious example of an injective module; we shall actually use
it to prove an interesting result (see the remark on page 654 after the proof of the basis
theorem).
Proposition 7.76.
Let R be a PID, let a ‚ààR be neither zero nor a unit, and let J = (a).
Then R/J is an injective R/J-module.
Proof.
By the correspondence theorem, every ideal in R/J has the form I/J for some
ideal I in R containing J. Now I = (b) for some b ‚ààI, so that I/J is cyclic with
generator x = b + J. Since (a) ‚äÜ(b), we have a = rb for some r ‚ààR. We are going to
use the Baer criterion, Theorem 7.68, to prove that R/J is injective.
Assume that f : I/J ‚ÜíR/J is an R/J-map, and write f (b + J) = s + J for some
s ‚ààR. Since r(b+J) = rb+J = a+J = 0, we have r f (b+J) = r(s+J) = rs+J = 0,
and so rs ‚ààJ = (a). Hence, there is some r‚Ä≤ ‚ààR with rs = r‚Ä≤a = r‚Ä≤br; canceling r gives
s = r‚Ä≤b. Thus,
f (b + J) = s + J = r‚Ä≤b + J.
DeÔ¨Åne h : R/J ‚ÜíR/J to be multiplication by r‚Ä≤; that is, h : u + J ‚Üír‚Ä≤u + J. The
displayed equation gives h(b + J) = f (b + J), so that h does extend f . Therefore, R/J
is injective.
‚Ä¢
EXERCISES
7.40 Let M be a free R-module, where R is a domain. Prove that if rm = 0, where r ‚ààR and
m ‚ààM, then either r = 0 or m = 0. (This is false if R is not a domain.)
7.41 Use left exactness of Hom to prove that if G is an abelian group, then HomZ(In, G) ‚àº= G[n],
where G[n] = {g ‚ààG : ng = 0}.
7.42 Prove that a group G ‚ààobj(Groups) is a projective object if and only if G is a free group. (It
is proved, in Exercise 10.3 on page 793, that the only injective object in Groups is {1}.)

Sec. 7.4
Free Modules, Projectives, and Injectives
487
7.43 If R is a domain but not a Ô¨Åeld, and if Q = Frac(R), prove that
HomR(Q, R) = {0}.
7.44 Prove that every left exact covariant functor T : RMod ‚ÜíAb preserves pullbacks. Conclude
that if B and C are submodules of a module A, then for every module M, we have
HomR(M, B ‚à©C) = HomR(M, B) ‚à©HomR(M, C).
Hint. Use pullback.
7.45
(i) Prove that a function is an epimorphism in Sets if and only if it is a surjection.
(ii) Prove that every object in Sets is projective, where an object P in a category is projective
if a dotted arrow always exists for the diagram
P


X
p
 Y,
where p is an epimorphism.
Hint. Use the axiom of choice.
7.46 Given a set X, prove that there exists a free R-module F with a basis B for which there is a
bijection œï : B ‚ÜíX.
7.47
(i) Prove that every vector space V over a Ô¨Åeld k is a free k-module.
(ii) Prove that a subset B of V is a basis of V considered as a vector space if and only if B
is a basis of V considered as a free k-module.
7.48 DeÔ¨Åne G to be the abelian group having the presentation (X|R), where
X = {a, b1, b2, . . . , bn, . . .}
and
R = {2a, a ‚àí2nbn, n ‚â•1}.
Thus, G = F/K, where F is the free abelian group with basis X and K is the subgroup ‚ü®R‚ü©.
(i) Prove that a + K ‚ààG is nonzero.
(ii) Prove that z = a + K satiÔ¨Åes equations z = 2n yn, where yn ‚ààG and n ‚â•1, and that z
is the unique such element of G.
(iii) Prove that there is an exact sequence 0 ‚Üí‚ü®a‚ü©‚ÜíG ‚Üí
n‚â•1 I2n ‚Üí0.
(iv) Prove that HomZ(Q, G) = {0} by applying HomZ(Q, ) to the exact sequence in part (iii).
7.49
(i) If {Pi : i ‚ààI} is a family of projective R-modules, prove that their direct sum 
i‚ààI Pi
is also projective.
(ii) Prove that every direct summand of a projective module is projective.
7.50 Prove that every direct summand of an injective module is injective.
7.51 Give an example of two injective submodules of a module whose intersection is not injective.
Hint. DeÔ¨Åne abelian groups A ‚àº= Z(p‚àû) ‚àº= A‚Ä≤:
A = (an, n ‚â•0|pa0 = 0, pan+1 = an)
and
A‚Ä≤ = (a‚Ä≤
n, n ‚â•0|pa‚Ä≤
0 = 0, pa‚Ä≤
n+1 = a‚Ä≤
n).
In A ‚äïA‚Ä≤, deÔ¨Åne E = A ‚äï{0} and E‚Ä≤ = ‚ü®{(an+1, a‚Ä≤n) : n ‚â•0}‚ü©.

488
Modules and Categories
Ch. 7
7.52
(i) Prove that if a domain R is an injective R-module, then R is a Ô¨Åeld.
(ii) Let R be a domain that is not a Ô¨Åeld, and let M be an R-module that is both injective
and projective. Prove that M = {0}.
(iii) Prove that I6 is simultaneously an injective and a projective module over itself.
7.53
(i) If R is a domain and I and J are nonzero ideals in R, prove that I ‚à©J Ã∏= {0}.
(ii) Let R be a domain and let I be an ideal in R that is a free R-module; prove that I is a
principal ideal.
7.54 Prove that an R-module E is injective if and only if, for every ideal I in R, every short exact
sequence 0 ‚ÜíE ‚ÜíB ‚ÜíI ‚Üí0 splits.
7.55 Prove the dual of Schanuel's lemma. Given exact sequences
0 ‚ÜíM
i‚ÜíE
p‚ÜíQ ‚Üí0
and
0 ‚ÜíM i‚Ä≤
‚ÜíE‚Ä≤ p‚Ä≤
‚ÜíQ‚Ä≤ ‚Üí0,
where E and E‚Ä≤ are injective, then there is an isomorphism
Q ‚äïE‚Ä≤ ‚àº= Q‚Ä≤ ‚äïE.
7.56
(i) Prove that every vector space over a Ô¨Åeld k is an injective k-module.
(ii) Prove that if 0 ‚ÜíU ‚ÜíV ‚ÜíW ‚Üí0 is an exact sequence of vector spaces, then the
corresponding sequence of dual spaces 0 ‚ÜíW ‚àó‚ÜíV ‚àó‚ÜíU‚àó‚Üí0 is also exact.
7.57 (Pontrjagin Duality) If G is an abelian group, its Pontrjagin dual is the group
G‚àó= HomZ(G, Q/Z).
(Pontrjagin duality extends to locally compact abelian topological groups, and the dual con-
sists of all continuous homomorphisms into the circle group.)
(i) Prove that if G is an abelian group and a ‚ààG is nonzero, then there is a homomorphism
f : G ‚ÜíQ/Z with f (a) Ã∏= 0.
(ii) Prove that Q/Z is an injective abelian group.
(iii) Prove that if 0 ‚ÜíA ‚ÜíG ‚ÜíB ‚Üí0 is an exact sequence of abelian groups, then so is
0 ‚ÜíB‚àó‚ÜíG‚àó‚ÜíA‚àó‚Üí0.
(iv) If G ‚àº= In, prove that G‚àó‚àº= G.
(v) If G is a Ô¨Ånite abelian group, prove that G‚àó‚àº= G.
(vi) Prove that if G is a Ô¨Ånite abelian group, and if G/H is a quotient group of G, then G/H
is isomorphic to a subgroup of G. [The analogous statement for nonabelian groups is
false: If Q is the group of quaternions, then Q/Z(Q) ‚àº= V, where V is the four-group;
but Q has only one element of order 2 while V has three elements of order 2. This
exercise is also false for inÔ¨Ånite abelian groups: Since Z has no element of order 2, it
has no subgroup isomorphic to Z/2Z ‚àº= I2.]
7.5 GROTHENDIECK GROUPS
A. Grothendieck introduced abelian groups to help study projective modules. The reader
may regard this section as a gentle introduction to algebraic K-theory.

Sec. 7.5
Grothendieck Groups
489
DeÔ¨Ånition.
A category C is a ‚ãÜ-category if there is a commutative and associative binary
operation ‚ãÜ: obj(C) √ó obj(C) ‚Üíobj(C); that is,
(i) If A ‚àº= A‚Ä≤ and B ‚àº= B‚Ä≤, where A, A‚Ä≤, B, B‚Ä≤ ‚ààobj(C), then A ‚ãÜB ‚àº= A‚Ä≤ ‚ãÜB‚Ä≤.
(ii) there is an equivalence A ‚ãÜB ‚àº= B ‚ãÜA for all A, B ‚ààobj(C);
(iii) there is an equivalence A ‚ãÜ(B ‚ãÜC) ‚àº= (A ‚ãÜB) ‚ãÜC for all A, B, C ‚ààobj(C).
Any category having Ô¨Ånite products or Ô¨Ånite coproducts is a ‚ãÜ-category.
DeÔ¨Ånition.
If C is a ‚ãÜ-category, deÔ¨Åne |obj(C)| to be the class of all isomorphism classes
|A| of objects in C, where |A| = {B ‚ààobj(C) : B ‚àº= A}. If F(C) is the free abelian group
with basis15 |obj(C)| and R is the subgroup of F(C) generated by all elements of the form
|A ‚ãÜB| ‚àí|A| ‚àí|B|
where A, B ‚ààobj(C),
then the Grothendieck group K0(C) is the abelian group
K0(C) = F(C)/R.
(A characterization of K0(C) as a solution to a universal mapping problem is given in
Exercise 7.58 on page 498.) For any object A in C, we denote the coset |A| + R by [A].
We remark that the Grothendieck group K0(C) can be deÔ¨Åned more precisely: C should
be a symmetric monoidal category (see Mac Lane, Categories for the Working Mathemati-
cian, pages 157-161).
Proposition 7.77.
Let C be a ‚ãÜ-category.
(i) If x ‚ààK0(C), then x = [A] ‚àí[B] for A, B ‚ààobj(C).
(ii) If A, B ‚ààobj(C), then [A] = [B] in K0(C) if and only if there exists C ‚ààobj(C)
with A ‚ãÜC ‚àº= B ‚ãÜC.
Proof.
(i) Since K0(C) is generated by |obj(C)|, we may write
x =
r

i=1
[Ai] ‚àí
s

j=1
[B j],
(we allow objects Ai and B j to be repeated). If we now deÔ¨Åne A = A1 ‚ãÜ¬∑ ¬∑ ¬∑ ‚ãÜAr, then
[A] = [A1 ‚ãÜ¬∑ ¬∑ ¬∑ ‚ãÜAr] =

i
[Ai].
Similarly, deÔ¨Åne B = B1 ‚ãÜ¬∑ ¬∑ ¬∑ ‚ãÜBs. It is now clear that x = [A] ‚àí[B].
15There is a minor set-theoretic problem here, for a basis of a free abelian group must be a set and not a proper
class. This problem is usually avoided by assuming that C is a small category; that is, the class obj(C) is a set.

490
Modules and Categories
Ch. 7
(ii) If A ‚ãÜC ‚àº= B ‚ãÜC, then [A ‚ãÜC] = [B ‚ãÜC] in K0(C). Hence, [A] + [C] = [B] + [C],
and the cancellation law in the abelian group K0(C) gives [A] = [B].
Conversely, if [A] = [B], then |B| ‚àí|A| ‚ààR and there is an equation in F(C):
|B| ‚àí|A| =

i
mi(|Xi ‚ãÜYi| ‚àí|Xi| ‚àí|Yi|) ‚àí

j
n j(|U j ‚ãÜVj| ‚àí|U j| ‚àí|Vj|),
where the coefÔ¨Åcients mi and n j are positive integers, and the X, Y, U, and V are objects
in C. Transposing to eliminate negative coefÔ¨Åcients,
|A|+

i
mi|Xi ‚ãÜYi|+

j
n j(|U j|+|Vj|) = |B|+

i
mi(|Xi|+|Yi|)+

j
n j|U j ‚ãÜVj|.
This is an equation in a free abelian group, where expressions in terms of a basis are unique.
Therefore, {A, Xi ‚ãÜYi,U j, Vj}, the set of objects, with multiplicities, on the left-hand side,
coincides with {B,U j ‚ãÜVj, Xi, Yi}, the set of objects, with multiplicities, on the right-hand
side. Since products are commutative and associative, there is an equivalence in C:
A ‚ãÜ

‚ãÜi mi(Xi ‚ãÜYi)

‚ãÜ

‚ãÜj n j(U j ‚ãÜVj)
 ‚àº= B ‚ãÜ

‚ãÜi mi(Xi ‚ãÜYi)

‚ãÜ

‚ãÜj n j(U j ‚ãÜVj)

.
An inspection of terms shows that

‚ãÜi mi(Xi ‚ãÜYi)

‚ãÜ

‚ãÜj n j(U j ‚ãÜVj)
 ‚àº=

‚ãÜi mi(Xi ‚ãÜYi)

‚ãÜ

‚ãÜj n j(U j ‚ãÜVj)

.
If we denote this last object by C, then A ‚ãÜC ‚àº= B ‚ãÜC.
‚Ä¢
DeÔ¨Ånition.
Let R be a commutative ring, and let C be a subcategory of RMod. Two
R-modules A and B are called stably isomorphic in C if there exists a module C ‚ààobj(C)
with A ‚äïC ‚àº= B ‚äïC.
With this terminology, Proposition 7.77 says that two modules determine the same el-
ement of a Grothendieck group if and only if they are stably isomorphic. It is clear that
isomorphic modules are stably isomorphic; the next example shows that the converse need
not hold.
Example 7.78.
(i) If Ab is the category of all Ô¨Ånite abelian groups, then Exercise 5.10 on page 268 shows
that two Ô¨Ånite abelian groups are stably isomorphic in Ab if and only if they are isomorphic.
(ii) If R is a commutative ring and F is a free R-module of inÔ¨Ånite rank, then
R ‚äïF ‚àº= R ‚äïR ‚äïF.

Sec. 7.5
Grothendieck Groups
491
Thus, R and R ‚äïR are nonisomorphic modules that are stably isomorphic in RMod.
Because of examples of this type, we usually restrict ourselves to subcategories C of RMod
consisting of Ô¨Ånitely generated modules.
(iii) Here is an example, due to R. G. Swan, in which stable isomorphism of Ô¨Ånitely gener-
ated projective modules does not imply isomorphism.
Let R = R[x1, . . . , xn]/(1 ‚àí
i x2
i ) [the coordinate ring of the real (n ‚àí1)-sphere].
Regard Rn as n √ó 1 column vectors, and let X = (x1, . . . , xn)t ‚ààRn, where bar denotes
coset mod (1 ‚àí
i x2
i ) in R. DeÔ¨Åne Œª: R ‚ÜíRn by Œª: r ‚Üír X, and deÔ¨Åne œï : Rn ‚ÜíR
by œï(Y) = XtY. Note that the composite œïŒª: R ‚ÜíR is the identity, for
œïŒª(r) = œï(r X) = Xtr X = r,
because Xt X = 
i x2
i = 1. It follows that the exact sequence
0 ‚ÜíR
Œª
‚àí‚ÜíRn
nat
‚àí‚ÜíRn/ im Œª ‚Üí0
splits. Thus, if P = Rn/ im Œª, then
R ‚äïRn‚àí1 ‚àº= Rn ‚àº= R ‚äïP,
and P is stably isomorphic to the free R-module Rn‚àí1 (of course, P is a projective R-
module). Using topology, Swan proved that P is a free R-module if and only if n = 1, 2, 4
or 8. If n = 3, for example, then P is not isomorphic to Rn‚àí1.
‚óÄ
Proposition 7.79.
If C is the category of all Ô¨Ånite abelian groups, then K0(C) is a free
abelian group with a basis B consisting of all the cyclic primary groups.
Proof.
By the basis theorem, each Ô¨Ånite abelian group A ‚àº=

i Ci, where each Ci is a
cyclic primary group. Thus, [A] = 
i[Ci] in K0(C). Since every element in K0(C) is
equal to [A] ‚àí[B], for Ô¨Ånite abelian groups A and B, it follows that B generates K0(C).
To see that B is a basis, suppose that r
i=1 mi[Ci] ‚àís
j=1 n j[C‚Ä≤
j] = 0, where mi and
n j are positive integers. Then 
i[miCi] = 
j[n jC‚Ä≤
j], where miCi is the direct sum of
mi copies of Ci, and so [
i miCi] = [
j n jC‚Ä≤
j]. Therefore, 
i miCi and 
j n jC‚Ä≤
j
are stably isomorphic in C. By Example 7.78(i), r
i=1 miCi ‚àº=
s
j=1 n jC‚Ä≤
j. Finally, the
fundamental theorem of Ô¨Ånite abelian groups applies to give r = s, a permutation œÉ ‚ààSr
with C‚Ä≤
œÉ(i) ‚àº= Ci and mi = nœÉ(i) for all i. Therefore, B is a basis of K0(C).
‚Ä¢
DeÔ¨Ånition.
If R is a commutative ring, then the subcategory Pr(R) of all Ô¨Ånitely gener-
ated projective R-modules is a ‚ãÜ-category (for the direct sum of two such modules is again
Ô¨Ånitely generated projective). We usually denote K0(Pr(R)) by K0(R) in this case.

492
Modules and Categories
Ch. 7
Example 7.80.
We now show that K0(R) ‚àº= Z if R is a commutative ring for which every Ô¨Ånitely generated
projective R-module is free. It is clear that K0(R) is generated by [R], so that K0(R) is
cyclic. DeÔ¨Åne r : obj(Pr(R)) ‚ÜíZ by r(F) = rank(F), where F is a Ô¨Ånitely generated
free R-module. Since r(F ‚äïF‚Ä≤) = r(F) + r(F‚Ä≤), Exercise 7.58 on page 498 shows
that there is a homomorphism r : K0(R) ‚ÜíZ with r([F]) = rank(F) for every Ô¨Ånitely
generated free F. Since K0(R) is cyclic,r is an isomorphism.
‚óÄ
If C is a category of modules, there is another Grothendieck group K ‚Ä≤(C) we can deÔ¨Åne.
DeÔ¨Ånition.
If C is a category of modules, deÔ¨Åne F(C)| to be the free abelian group with
basis |obj(C), and R‚Ä≤ to be the subgroup of F(C) generated by all elements of the form
|B| ‚àí|A| ‚àí|C|
if there is an exact sequence
0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0.
The Grothendieck group K ‚Ä≤(C) is the abelian group
K ‚Ä≤(C) = F(C)/R‚Ä≤;
that is, K ‚Ä≤(C) is the abelian group with generators |obj(C)| and relations R‚Ä≤. For any
module A ‚ààobj(C), we denote the coset |A| + R‚Ä≤ by (A).
Example 7.81.
If R is a domain and a ‚ààR is neither 0 nor a unit, there is an exact sequence
0 ‚ÜíR
¬µa
‚àí‚ÜíR ‚ÜíR/Ra ‚Üí0,
where ¬µa : r ‚Üíar. Thus, there is an equation in K ‚Ä≤(C):
(R) = (R) + (R/Ra).
Hence, (R/Ra) = 0.
‚óÄ
The next proposition uses the observation that the two notions of Grothendieck group‚Äî
K0(R) = K0(Pr(R)) and K ‚Ä≤(Pr(R))‚Äîcoincide. The reason is that there is an exact se-
quence 0 ‚ÜíA ‚ÜíA ‚äïC ‚ÜíC ‚Üí0, so that (A ‚äïC) = (A) + (C) in K ‚Ä≤(C).
Proposition 7.82.
If R is a commutative ring and C is the category of all Ô¨Ånitely generated
R-modules, then there is a homomorphism
Œµ: K0(R) ‚ÜíK ‚Ä≤(C)
with Œµ: [P] ‚Üí(P) for every projective R-module P.
Proof.
Since every short exact sequence of projective modules splits, the relations deÔ¨Ån-
ing K0(R) = K0(Pr(R)) are the same as those deÔ¨Åning K ‚Ä≤(Pr(R)). Hence, the inclusion
map F(Pr(R)) ‚ÜíF(C) induces a well-deÔ¨Åned homomorphism.
‚Ä¢

Sec. 7.5
Grothendieck Groups
493
Proposition 7.83.
Let R be a commutative ring and let C be the category of all Ô¨Ånitely
generated R-modules. If M ‚ààobj(C) and
M = M0 ‚äáM1 ‚äáM2 ‚äá¬∑ ¬∑ ¬∑ ‚äáMn = {0}
has factor modules Qi = Mi‚àí1/Mi, then
(M) = (Q1) + ¬∑ ¬∑ ¬∑ + (Qn) in K ‚Ä≤(C).
Proof.
Since Qi = Mi‚àí1/Mi, there is a short exact sequence
0 ‚ÜíMi ‚ÜíMi‚àí1 ‚ÜíQi ‚Üí0,
so that (Qi) = (Mi‚àí1) ‚àí(Mi) in K ‚Ä≤(C). We now have a telescoping sum:
n

i=1
(Qi) =
n

i=1

(Mi‚àí1) ‚àí(Mi)

= (M0) ‚àí(Mn) = (M).
‚Ä¢
The next obvious question is how to detect when an element in K ‚Ä≤(C) is zero.
Proposition 7.84.
Let R be a commutative ring and let C be the category of all Ô¨Ånitely
generated R-modules. If A, B ‚ààobj(C), then (A) = (B) in K ‚Ä≤(C) if and only if there are
C,U, V ‚ààobj(C) and exact sequences
0 ‚ÜíU ‚ÜíA ‚äïC ‚ÜíV ‚Üí0
and
0 ‚ÜíU ‚ÜíB ‚äïC ‚ÜíV ‚Üí0.
Proof.
If there exist modules C,U, and V as in the statement, then
(A ‚äïC) = (U) + (V ) = (B ‚äïC).
But exactness of 0 ‚ÜíA ‚ÜíA ‚äïC ‚ÜíC ‚Üí0 gives (A ‚äïC) = (A) + (C). Similarly,
(B ‚äïC) = (B) + (C), so that (A) + (C) = (B) + (C) and (A) = (B).
Conversely, if (A) = (B), then |A| ‚àí|B| ‚ààR‚Ä≤. As in the proof of Proposition 7.77,
there is an equation in F(C):
|A| +

|Xi| +

(|Y ‚Ä≤
j| + |Y ‚Ä≤‚Ä≤
j |) = |B| +

(|X‚Ä≤
i| + |X‚Ä≤‚Ä≤
i |) +

|Y j|,
where 0 ‚ÜíX‚Ä≤
i ‚ÜíXi ‚ÜíX‚Ä≤‚Ä≤
i ‚Üí0 and 0 ‚ÜíY ‚Ä≤
j ‚ÜíY j ‚ÜíY ‚Ä≤‚Ä≤
j ‚Üí0 are exact sequences.
DeÔ¨Åne
C = A ‚äï

Xi ‚äï

(Y ‚Ä≤
j ‚äïY ‚Ä≤‚Ä≤
j ).
Setting X‚Ä≤ to be the direct sum of the X‚Ä≤
i, X to be the direct sum of the Xi, and so forth,
the argument in the proof of Proposition 7.77 gives
A ‚äïX ‚äïY ‚Ä≤ ‚äïY ‚Ä≤‚Ä≤ ‚àº= B ‚äïX‚Ä≤ ‚äïX‚Ä≤‚Ä≤ ‚äïY.

494
Modules and Categories
Ch. 7
By Exercise 7.12 on page 440, this isomorphism gives rise to exact sequences
0 ‚ÜíX‚Ä≤ ‚äïY ‚Ä≤‚Ä≤ ‚ÜíX ‚äïY ‚Ä≤‚Ä≤ ‚ÜíX‚Ä≤‚Ä≤ ‚Üí0,
0 ‚ÜíX‚Ä≤ ‚äïY ‚Ä≤‚Ä≤ ‚Üí(X ‚äïY ‚Ä≤‚Ä≤) ‚äïY ‚Ä≤ ‚ÜíX‚Ä≤‚Ä≤ ‚äïY ‚Ä≤ ‚Üí0,
and
0 ‚ÜíX‚Ä≤ ‚äïY ‚Ä≤‚Ä≤ ‚ÜíA ‚äï(X ‚äïY ‚Ä≤ ‚äïY ‚Ä≤‚Ä≤) ‚ÜíA ‚äï(X‚Ä≤‚Ä≤ ‚äïY ‚Ä≤) ‚Üí0.
The middle module is C. Applying Exercise 7.12 once again, there is an exact sequence
0 ‚ÜíX‚Ä≤ ‚äïY ‚Ä≤ ‚ÜíB ‚äïC ‚ÜíB ‚äï(A ‚äïX‚Ä≤‚Ä≤ ‚äïY ‚Ä≤‚Ä≤) ‚Üí0.
DeÔ¨Åne U = X‚Ä≤ ‚äïY ‚Ä≤ and V = B ‚äïA‚äïX‚Ä≤‚Ä≤ ‚äïY ‚Ä≤‚Ä≤; with this notation, the last exact sequence
is
0 ‚ÜíU ‚ÜíB ‚äïC ‚ÜíV ‚Üí0.
Similar manipulation yields an exact sequence 0 ‚ÜíU ‚ÜíA ‚äïC ‚ÜíV ‚Üí0.
‚Ä¢
In Chapter 8, we will prove a module version of Theorem 5.52, the Jordan-H¬®older
theorem. For now, we merely give a deÔ¨Ånition.
DeÔ¨Ånition.
A sequence in a category C of modules,
M = M0 ‚äáM1 ‚äáM2 ‚äá¬∑ ¬∑ ¬∑ ‚äáMn = {0},
is called a composition series of M if each of its factor modules Qi = Mi‚àí1/Mi is a simple
module in obj(C). We say that a category C of modules is a Jordan-H¬®older category if:
(i) Each object M has a composition series;
(ii) For every two composition series
M = M0 ‚äáM1 ‚äáM2 ‚äá¬∑ ¬∑ ¬∑ ‚äáMn = {0}
and
M = M‚Ä≤
0 ‚äáM‚Ä≤
1 ‚äáM‚Ä≤
2 ‚äá¬∑ ¬∑ ¬∑ ‚äáM‚Ä≤
m = {0},
we have m = n and a permutation œÉ ‚ààSn such that Q‚Ä≤
j ‚àº= QœÉ j for all j, where
Qi = Mi‚àí1/Mi and Q‚Ä≤
j = M‚Ä≤
j‚àí1/M‚Ä≤
j.
DeÔ¨Åne the length ‚Ñì(M) of a module M in a Jordan-H¬®older category to be the number n
of terms in a composition series. If the simple factor modules of a composition series are
Q1, . . . , Qn, we deÔ¨Åne
jh(M) = Q1 ‚äï¬∑ ¬∑ ¬∑ ‚äïQn.
A composition series may have several isomorphic factor modules, and jh(M) records their
multiplicity.

Sec. 7.5
Grothendieck Groups
495
Lemma 7.85.
Let C be a Jordan-H¬®older category, and let Q1, . . . , Qn, Q‚Ä≤
1, . . . , Q‚Ä≤
m be
simple modules in obj(C).
(i) If
Q1 ‚äï¬∑ ¬∑ ¬∑ ‚äïQn ‚àº= Q‚Ä≤
1 ‚äï¬∑ ¬∑ ¬∑ ‚äïQ‚Ä≤
m,
then m = n and there is a permutation œÉ ‚ààSn such that Q‚Ä≤
j ‚àº= QœÉ j for all j, where
Qi = Mi‚àí1/Mi and Q‚Ä≤
j = M‚Ä≤
j‚àí1/M‚Ä≤
j.
(ii) If M and M‚Ä≤ are modules in obj(C), and if there is a simple module S ‚ààobj(C) with
S ‚äïjh(M) ‚àº= S ‚äïjh(M‚Ä≤),
then jh(M) ‚àº= jh(M‚Ä≤).
Proof.
(i) Now
Q1 ‚äï¬∑ ¬∑ ¬∑ ‚äïQn ‚äáQ2 ‚äï¬∑ ¬∑ ¬∑ ‚äïQn ‚äáQ3 ‚äï¬∑ ¬∑ ¬∑ ‚äïQn ‚äá¬∑ ¬∑ ¬∑
is a composition series with factor modules Q1, . . . , Qn; similarly, the isomorphic module
Q‚Ä≤
1 ‚äï¬∑ ¬∑ ¬∑ ‚äïQ‚Ä≤
m has a composition series with factor modules Q‚Ä≤
1, . . . , Q‚Ä≤
m. The result
follows from C being a Jordan-H¬®older category.
(ii) This result follows from part (i) because S is simple.
‚Ä¢
Lemma 7.86.
If 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 is an exact sequence in a Jordan-H¬®older
category, then
jh(B) ‚àº= jh(A) ‚äïjh(C).
Proof.
The proof is by induction on the length ‚Ñì(C). Let A = A0 ‚äáA1 ‚äá¬∑ ¬∑ ¬∑ ‚äáAn =
{0} be a composition series for A with factor modules Q1, . . . , Qn. If ‚Ñì(C) = 1, then C is
simple, and so
B ‚äáA ‚äáA1 ‚äá¬∑ ¬∑ ¬∑ ‚äáAn = {0}
is a composition series for B with factor modules C, Q1, . . . , Qn. Therefore,
jh(B) = C ‚äïQ1 ‚äï¬∑ ¬∑ ¬∑ ‚äïQn = jh(C) ‚äïjh(A).
For the inductive step, let ‚Ñì(C) > 1. Choose a maximal submodule C1 of C (which
exists because C has a composition series). If ŒΩ : B ‚ÜíC is the given surjection, deÔ¨Åne
B1 = ŒΩ‚àí1(C1). There is a commutative diagram (with vertical arrows inclusions)
0
 A
 B
ŒΩ
 C
 0
0
 A

 B1

 C1

 0

496
Modules and Categories
Ch. 7
Since C1 is a maximal submodule of C, the quotient module
C‚Ä≤‚Ä≤ = C/C1
is simple. Note that B/B1 ‚àº= (B/A)/(B1/A) ‚àº= C/C1 = C‚Ä≤‚Ä≤. By the base step, we have
jh(C) = C‚Ä≤‚Ä≤ ‚äïjh(C1)
and
jh(B) = C‚Ä≤‚Ä≤ ‚äïjh(B1).
By the inductive hypothesis,
jh(B1) = jh(A) ‚äïjh(C1).
Therefore,
jh(B) = C‚Ä≤‚Ä≤ ‚äïjh(B1)
‚àº= C‚Ä≤‚Ä≤ ‚äïjh(A) ‚äïjh(C1)
‚àº= jh(A) ‚äïC‚Ä≤‚Ä≤ ‚äïjh(C1)
‚àº= jh(A) ‚äïjh(C).
‚Ä¢
Theorem 7.87.
Let C be a category of modules in which every module M ‚ààobj(C) has
a composition series. Then C is a Jordan-H¬®older category if and only if K ‚Ä≤(C) is a free
abelian group with basis the set B‚Ä≤ of all (S) as S varies over all nonisomorphic simple
modules in obj(C).
Proof.
Assume that K ‚Ä≤(C) is free abelian with basis B‚Ä≤. Since 0 is not a member of a
basis, we have (S) Ã∏= 0 for every simple module S; moreover, if S Ã∏‚àº= S‚Ä≤, then (S) Ã∏= (S‚Ä≤),
for a basis repeats no elements. Let M ‚ààobj(C), and let Q1, . . . , Qn and Q‚Ä≤
1, . . . , Q‚Ä≤
m be
simple modules arising, respectively, as factor modules of two composition series of M.
By Proposition 7.83, we have
(Q1) + ¬∑ ¬∑ ¬∑ + (Qn) = (M) = (Q‚Ä≤
1) + ¬∑ ¬∑ ¬∑ + (Q‚Ä≤
m).
Uniqueness of expression in terms of the basis B‚Ä≤ says, for each Q‚Ä≤
j, that there exists Qi
with (Qi) = (Q‚Ä≤
j); in fact, the number of any (Qi) on the left-hand side is equal to the
number of copies of (Q‚Ä≤
j) on the right-hand side. Therefore, C is a Jordan-H¬®older category.
Conversely, assume that the Jordan-H¬®older theorem holds for C. Since every M ‚àà
obj(C) has a composition series, Proposition 7.83 shows that B‚Ä≤ generates K ‚Ä≤(C). Let S be
a simple module in obj(C). If (S) = (T ), then Proposition 7.84 says there are C,U, V ‚àà
obj(C) and exact sequences 0 ‚ÜíU ‚ÜíS‚äïC ‚ÜíV ‚Üí0 and 0 ‚ÜíU ‚ÜíT ‚äïC ‚ÜíV ‚Üí0.
Lemma 7.86 gives
jh(S) ‚äïjh(C) ‚àº= jh(U) ‚äïjh(V ) ‚àº= jh(T ) ‚äïjh(C).
By Lemma 7.85, we may cancel the simple summands one by one until we are left with
S ‚àº= T , a contradiction. A similar argument shows that if S is a simple module, then

Sec. 7.5
Grothendieck Groups
497
(S) Ã∏= 0. Finally, let us show that every element in K ‚Ä≤(C) has a unique expression as a
linear combination of elements in B‚Ä≤. Suppose there are positive integers mi and n j so that

i
mi(Si) ‚àí

j
n j(Tj) = 0,
(1)
where the Si and Tj are simple modules in obj(C) and Si Ã∏‚àº= Tj for all i, j. If we denote
the direct sum of mi copies of Si by mi Si, then Eq. (1) gives

i
mi Si

=

j
n jTj

.
By Proposition 7.84, there are modules C,U, V and exact sequences
0 ‚ÜíU ‚ÜíC ‚äï

i
mi Si ‚ÜíV ‚Üí0
and
0 ‚ÜíU ‚ÜíC ‚äï

j
n jTj ‚ÜíV ‚Üí0,
and Lemma 7.86 gives
jh

i
mi Si
 ‚àº= jh

j
n jTj

.
By Lemma 7.85, some Si occurs on the right-hand side, contradicting Si Ã∏‚àº= Tj for all i, j.
Therefore, Eq. (1) cannot occur.
‚Ä¢
Remark.
A module M is called indecomposable if there do not exist nonzero modules A
and B with M ‚àº= A‚äïB. We say that a category C of modules is a Krull-Schmidt category
if:
(i) Each module in obj(C) is isomorphic to a Ô¨Ånite direct sum of indecomposable mod-
ules in obj(C);
(ii) If
D1 ‚äï¬∑ ¬∑ ¬∑ ‚äïDn ‚àº= D‚Ä≤
1 ‚äï¬∑ ¬∑ ¬∑ ‚äïD‚Ä≤
m,
where all the summands are indecomposable, then m = n and there is a permutation
œÉ ‚ààSn with D‚Ä≤
j ‚àº= DœÉ j for all j.
There is a theorem analogous to Theorem 7.87 saying that a category C of modules is a
Krull-Schmidt category if and only if K0(C) is a free abelian group with basis consisting
of all [D] as D varies over all nonisomorphic indecomposable modules in obj(C).
‚óÄ
Compare the next corollary with Proposition 7.79.
Corollary 7.88.
If C is the category of all Ô¨Ånite abelian groups, then K ‚Ä≤(C) is the free
abelian group with generators all (S), where S is a cyclic group of prime order p.
Proof.
By Theorem 5.52, the category of all Ô¨Ånite abelian groups is a Jordan-H¬®older
category, and the simple Z-modules are the abelian groups Ip for primes p.
‚Ä¢

498
Modules and Categories
Ch. 7
H. Bass deÔ¨Åned higher groups K1 and K2, proved that there is an exact sequence relating
these to K0, and showed how these groups can be used to study projective modules (see
Milnor, Introduction to Algebraic K-Theory). D. Quillen constructed an inÔ¨Ånite sequence
Kn(C) of abelian groups by associating a topological space X(C) to certain categories C.
He then deÔ¨Åned Kn(C) = œÄn+1(X(C)) for all n ‚â•0, the homotopy groups of this space,
and he proved that his Kn coincide with those of Bass for n = 0, 1, 2 (see Rosenberg,
Algebraic K-Theory and Its Applications).
EXERCISES
7.58 Let C be a ‚ãÜ-category. Prove that K0(C) solves the following universal mapping problem.
obj(C)
h

f

K0(C),
f

G
where G is any abelian group. If h : obj(C) ‚ÜíK0(C) is the function A ‚Üí[A], and if
f : obj(C) ‚ÜíG satisÔ¨Åes f (A) = f (B) whenever A ‚àº= B and f (A ‚ãÜB) = f (A) + f (B),
then there exists a unique homomorphism f : K0(C) ‚ÜíG making the diagram commute.
7.59 Regard C = PO(N) as a ‚ãÜ-category, where m ‚ãÜn = m + n, and prove that K0(C) ‚àº= Z. (Thus,
we have constructed the integers from the natural numbers. In a similar way, we can construct
an abelian group G from a semigroup S, although we cannot expect that S is always imbedded
in G.)
7.60
(i) If C is a category of modules having inÔ¨Ånite direct sums of its objects, prove that
K0(C) = {0}.
(ii) (Eilenberg) Prove that if P is a projective R-module (over some commutative ring R),
then there exists a free R-module Q with P ‚äïQ a free R-module. Conclude that
K0(C) = {0} for C the category of countably generated projective R-modules.
Hint. Q need not be Ô¨Ånitely generated.
7.61 Prove that K0(I6) ‚àº= Z ‚äïZ.
7.62 Let C and C‚Ä≤ be ‚ãÜ-categories, and let F : C ‚ÜíC‚Ä≤ be a ‚ãÜ-preserving functor; that is, F(A‚ãÜB) ‚àº=
F(A) ‚ãÜF(B). Prove that F induces a homomorphism K0(C) ‚ÜíK0(C‚Ä≤) by [A] ‚Üí[F A].
7.63 If C is a category of modules, prove that every element in K ‚Ä≤(C) has the form (A) ‚àí(B) for
modules A and B in obj(C).
7.64 Let C be a category having short exact sequences. Prove that there is a surjection K0(C) ‚Üí
K ‚Ä≤(C).
7.6 LIMITS
There are two more general constructions, one generalizing pullbacks and intersections,
the other generalizing pushouts and unions; both involve a family of modules {Mi : i ‚ààI}
whose index set I is a partially ordered set.

Sec. 7.6
Limits
499
DeÔ¨Ånition.
Let I be a partially ordered set. An inverse system of R-modules over I is
an ordered pair {Mi, œà j
i } consisting of an indexed family of modules {Mi : i ‚ààI} together
with a family of morphisms {œà j
i : M j ‚ÜíMi} for i ‚™Øj, such that œài
i = 1Mi for all i and
such that the following diagram commutes whenever i ‚™Øj ‚™Øk:
Mk
œàk
i

œàk
j








Mi
M j
œà j
i








In Example 7.25(v), we saw that a partially ordered set I deÔ¨Ånes a category PO(I): The
objects of PO(I) are the elements of I and Hom(i, j) is empty when i Ã∏‚™Øj while it contains
exactly one element, Œ∫i
j, whenever i ‚™Øj. If we deÔ¨Åne F(i) = Mi and F(Œ∫i
j) = œà j
i , then
it is easy to see that {Mi, œà j
i } is an inverse system if and only if F : PO(I) ‚ÜíRMod is a
contravariant functor. We now see that inverse systems involving objects and morphisms
in any category C can be deÔ¨Åned: Every contravariant functor F : PO(I) ‚ÜíC yields one.
For example, we can speak of inverse systems of commutative rings.
Example 7.89.
(i) If I = {1, 2, 3} is the partially ordered set in which 1 ‚™Ø2 and 1 ‚™Ø3, then an inverse
system over I is a diagram of the form
A
g

B
f
 C
(ii) If I is a family of submodules of a module A, then it can be partially ordered under
reverse inclusion; that is, M ‚™ØM‚Ä≤ in case M ‚äáM‚Ä≤. For M ‚™ØM‚Ä≤, the inclusion map
M‚Ä≤ ‚ÜíM is deÔ¨Åned, and it is easy to see that the family of all M ‚ààI with inclusion maps
is an inverse system.
(iii) If I is equipped with the discrete partial order, that is, i ‚™Øj if and only if i = j, then
an inverse system over I is just an indexed family of modules.
(iv) If N is the natural numbers with the usual partial order, then an inverse system over N
is a diagram
M0 ‚ÜêM1 ‚ÜêM2 ‚Üê¬∑ ¬∑ ¬∑ .
(v) If J is an ideal in a commutative ring R, then its nth power is deÔ¨Åned by
J n =

a1 ¬∑ ¬∑ ¬∑ an : ai ‚ààJ

.

500
Modules and Categories
Ch. 7
Each J n is an ideal and there is a decreasing sequence
R ‚äáJ ‚äáJ 2 ‚äáJ 3 ‚äá¬∑ ¬∑ ¬∑ .
If A is an R-module, there is a sequence of submodules
A ‚äáJ A ‚äáJ 2A ‚äáJ 3A ‚äá¬∑ ¬∑ ¬∑ .
If m ‚â•n, deÔ¨Åne œàm
n : A/J m A ‚ÜíA/J n A by
œàm
n : a + J m A ‚Üía + J n A
(these maps are well-deÔ¨Åned, for m ‚â•n implies J m A ‚äÜJ n A). It is easy to see that
{A/J n A, œàm
n }
is an inverse system over N.
(vi) Let G be a group and let N be the family of all the normal subgroups N of G having
Ô¨Ånite index partially ordered by reverse inclusion. If N ‚™ØN ‚Ä≤ in N, then N ‚Ä≤ ‚â§N; deÔ¨Åne
œà N‚Ä≤
N : G/N ‚Ä≤ ‚ÜíG/N by gN ‚Ä≤ ‚ÜígN. It is easy to see that the family of all such quotients
together with the maps œà N‚Ä≤
N form an inverse system over N.
‚óÄ
DeÔ¨Ånition.
Let I be a partially ordered set, and let {Mi, œà j
i } be an inverse system of
R-modules over I. The inverse limit (also called projective limit or limit) is an R-module
lim
‚Üê‚àíMi and a family of R-maps {Œ±i : lim
‚Üê‚àíMi ‚ÜíMi : i ‚ààI}, such that
(i) œà j
i Œ± j = Œ±i whenever i ‚™Øj;
(ii) for every module X having maps fi : X ‚ÜíMi satisfying œà j
i f j = fi for all i ‚™Øj,
there exists a unique map Œ∏ : X ‚Üílim
‚Üê‚àíMi making the following diagram commute:
lim
‚Üê‚àíMi
Œ± j

Œ±i








X
Œ∏

fi
								
f j
 
Mi
M j
œà j
i

The notation lim
‚Üê‚àíMi for an inverse limit is deÔ¨Åcient in that it does not display the maps
of the corresponding inverse system (and lim
‚Üê‚àíMi does depend on them). However, this is
standard practice.
As with any object deÔ¨Åned as a solution to a universal mapping problem, the inverse
limit of an inverse system is unique (to isomorphism) if it exists.

Sec. 7.6
Limits
501
Proposition 7.90.
The inverse limit of any inverse system {Mi, œà j
i } of R-modules over a
partially ordered index set I exists.
Proof.
DeÔ¨Åne
L = {(mi) ‚àà

Mi : mi = œà j
i (m j) whenever i ‚™Øj};
it is easy to check that L is a submodule of 
i Mi. If pi is the projection of the product to
Mi, deÔ¨Åne Œ±i : L ‚ÜíMi to be the restriction pi|L. It is clear that œà j
i Œ± j = Œ±i.
Assume that X is a module having maps fi : X ‚ÜíMi satisfying œà j
i f j = fi for all
i ‚™Øj. DeÔ¨Åne Œ∏ : X ‚Üí Mi by
Œ∏(x) = ( fi(x)).
That im Œ∏ ‚äÜL follows from the given equation œà j
i f j = fi for all i ‚™Øj. Also, Œ∏ makes
the diagram commute: Œ±iŒ∏ : x ‚Üí( fi(x)) ‚Üífi(x). Finally, Œ∏ is the unique map X ‚ÜíL
making the diagram commute for all i ‚™Øj. If œï : X ‚ÜíL, then œï(x) = (mi) and
Œ±iœï(x) = mi. Thus, if œï satisÔ¨Åes Œ±iœï(x) = fi(x) for all i and all x, then mi = fi(x), and
so œï = Œ∏. We conclude that L ‚àº= lim
‚Üê‚àíMi.
‚Ä¢
Inverse limits in categories other than module categories may exist; for example, inverse
limits of commutative rings exist, as do inverse limits of groups or of topological spaces.
The reader should supply veriÔ¨Åcations of the following assertions in which we describe
the inverse limit of each of the inverse systems in Example 7.89.
Example 7.91.
(i) If I is the partially ordered set {1, 2, 3} with 1 ‚™∞3 and 2 ‚™∞3, then an inverse system is
a diagram
A
g

B
f
 C
and the inverse limit is the pullback.
(ii) We have seen that the intersection of two submodules of a module is a special case
of pullback. Suppose now that I is a family of submodules of a module A, so that I
and inclusion maps is an inverse system, as in Example 7.89(ii). The inverse limit of this
inverse system is 
M‚ààI M.
(iii) If I is a discrete index set, then the inverse system {Mi : i ‚ààI} has the product 
i Mi
as its inverse limit. Indeed, this is just the diagrammatic deÔ¨Ånition of a product.
(iv) If J is an ideal in a commutative ring R and M is an R-module, then the inverse limit
of {M/J nM, œàm
n } [in Example 7.89(v)] is usually called the J-adic completion of M; let
us denote it by 
M. In order to understand the terminology, we give a rapid account of a
corner of point-set topology.

502
Modules and Categories
Ch. 7
DeÔ¨Ånition.
A metric space is a set X equipped with a function d : X √ó X ‚ÜíR, called a
metric, that satisÔ¨Åes the following axioms. For all x, y, z ‚ààX,
(i) d(x, y) ‚â•0
and
d(x, y) = 0 if and only if x = y;
(ii) d(x, y) = d(y, x);
(iii) (Triangle inequality) d(x, y) ‚â§d(x, z) + d(z, y).
For example, d(x, y) = |x ‚àíy| is a metric on R. Given a metric space X, the usual
deÔ¨Ånition of convergence of a sequence makes sense: A sequence (xn) of points xn in X
converges to a limit y ‚ààX if, for every œµ > 0, there is N so that d(xn, y) < œµ whenever
n ‚â•N; we denote (xn) converging to y by
xn ‚Üíy.
A difÔ¨Åculty with this deÔ¨Ånition is that we cannot tell if a sequence is convergent without
knowing what its limit is. A sequence (xn) is a Cauchy sequence if, for every œµ > 0, there
is N so that d(xm, xn) < œµ whenever m, n ‚â•N. The virtue of this condition on a sequence
is that it involves only the terms of the sequence and not its limit. If X = R, then a sequence
is convergent if and only if it is a Cauchy sequence. In general metric spaces, however, we
can prove that convergent sequences are Cauchy sequences, but the converse may be false.
For example, if X consists of the positive real numbers, with the usual metric |x ‚àíy|, then
the sequence (1/n) is a Cauchy sequence, but it does not converge in X because 0 /‚ààX.
DeÔ¨Ånition.
A completion X of a metric space X is a metric space with the following two
properties:
(i) X is a dense subspace of X; that is, for every x ‚ààX, there is a sequence (xn) in X with
xn ‚Üíx;
(ii) every Cauchy sequence in X converges to a limit in X.
It can be proved that any two completions of a metric space X are isometric (there is a
bijection between them that preserves the metrics), and one way to prove existence of X
is to deÔ¨Åne its elements as equivalence classes of Cauchy sequences (xn) in X, where we
deÔ¨Åne (xn) ‚â°(yn) if d(xn, yn) ‚Üí0.
Let us return to the inverse system {M/J n M, œàm
n }. A sequence
(a1 + J M, a2 + J 2M, a3 + J 3M, . . .) ‚ààlim
‚Üê‚àí(M/J n M)
satisÔ¨Åes the condition œàm
n (am + J m M) = am + J n M for all m ‚â•n, so that
am ‚àían ‚ààJ n M
whenever m ‚â•n.
This suggests the following metric on M in the (most important) special case when
‚àû
n=1 J n M = {0}. If x ‚ààM and x Ã∏= 0, then there is i with x ‚ààJ i M and x /‚ààJ i+1M;
deÔ¨Åne ‚à•x‚à•= 2‚àíi; deÔ¨Åne ‚à•0‚à•= 0. It is a routine calculation to see that d(x, y) = ‚à•x ‚àíy‚à•

Sec. 7.6
Limits
503
is a metric on M (without the intersection condition, ‚à•x‚à•would not be deÔ¨Åned for a non-
zero x ‚àà‚àû
n=1 J n M). Moreover, if a sequence (an) in M is a Cauchy sequence, then
(a1 + J M, a2 + J 2M, a3 + J 3M, . . .) ‚ààlim
‚Üê‚àíM/J n M, and conversely.
In particular, when M = Z and J = (p), where p is a prime, then the completion Zp is
called the ring of p-adic integers. It turns out that Zp is a domain, and Qp = Frac(Zp) is
called the Ô¨Åeld of p-adic numbers.
(v) We have seen, in Example 7.89(vi), that the family N of all normal subgroups of Ô¨Ånite
index in a group G forms an inverse system; the inverse limit of this system, lim
‚Üê‚àíG/N,
denoted by 
G, is called the proÔ¨Ånite completion of G. There is a map G ‚Üí
G, namely,
g ‚Üí(gN), and it is an injection if and only if G is residually Ô¨Ånite; that is, 
N‚ààN N =
{1}. It is known, for example, that every free group is residually Ô¨Ånite.
There are some lovely results obtained making use of proÔ¨Ånite completions. If r is a
positive integer, a group G is said to have rank r if every subgroup of G can be generated
by r or fewer elements. If G is a residually Ô¨Ånite p-group (every element in G has order
a power of p) of rank r, then G is isomorphic to a subgroup of GL(n, Zp) for some n
(not every residually Ô¨Ånite group admits such a linear imbedding). See Dixon-du Sautoy-
Mann-Segal, Analytic Pro-p Groups, page 98.
‚óÄ
The next result generalizes Theorem 7.32.
Proposition 7.92.
If {Mi, œà j
i } is an inverse system, then
Hom(A, lim
‚Üê‚àíMi) ‚àº= lim
‚Üê‚àíHom(A, Mi)
for every module A.
Proof.
This statement follows from inverse limit being the solution of a universal map-
ping problem. In more detail, consider the diagram
lim
‚Üê‚àíHom(A, Mi)
Œ≤ j




















Œ≤i












Hom(A, lim
‚Üê‚àíMi)
Œ∏

Œ±i‚àó
!
Œ± j‚àó
	
Hom(A, Mi)
Hom(A, M j)
œà j
i‚àó

where the Œ≤i are the maps given in the deÔ¨Ånition of inverse limit.
To see that Œ∏ : Hom(A, lim
‚Üê‚àíMi) ‚Üílim
‚Üê‚àíHom(A, Mi) is injective, suppose that f : A ‚Üí
lim
‚Üê‚àíMi and Œ∏( f ) = 0. Then 0 = Œ≤iŒ∏ f = Œ±i f for all i, and so the following diagram

504
Modules and Categories
Ch. 7
commutes:
lim
‚Üê‚àíMi
Œ± j

Œ±i








A
f

Œ±i f

Œ± j f
                
Mi
M j
œà j
i

But the zero map in place of f also makes the diagram commute, and so the uniqueness of
such a map gives f = 0; that is, Œ∏ is injective.
To see that Œ∏ is surjective, take g ‚ààlim
‚Üê‚àíHom(A, Mi). For each i, there is a map
Œ≤ig : A ‚ÜíMi with œà j
i Œ≤ig = Œ≤ jg.
lim
‚Üê‚àíMi
Œ± j

Œ±i








A
g‚Ä≤

Œ≤i g

Œ≤ j g
                
Mi
M j
œà j
i

The deÔ¨Ånition of lim
‚Üê‚àíMi provides a map g‚Ä≤ : A ‚Üílim
‚Üê‚àíMi with Œ±ig‚Ä≤ = Œ≤ig for all i. It
follows that g = Œ∏(g‚Ä≤); that is, Œ∏ is surjective.
‚Ä¢
We now consider the dual construction.
DeÔ¨Ånition.
Let I be a partially ordered set. A direct system of R-modules over I is an
ordered pair {Mi, œïi
j} consisting of an indexed family of modules {Mi : i ‚ààI} together
with a family of morphisms {œïi
j : Mi ‚ÜíM j} for i ‚™Øj, such that œïi
i = 1Mi for all i and
such that the following diagram commutes whenever i ‚™Øj ‚™Øk:
Mi
œïi
k

œïi
j








Mk
M j
œï j
k








If we regard I as the category PO(I) whose only morphisms are Œ∫i
j when i ‚™Øj, and if
we deÔ¨Åne F(i) = Mi and F(Œ∫i
j) = œïi
j, then it is easy to see that {Mi, œïi
j} is a direct system
if and only if F : PO(I) ‚ÜíRMod is a (covariant) functor. Thus, we can consider direct
systems involving objects and morphisms in any category C as being a (covariant) functor

Sec. 7.6
Limits
505
F : PO(I) ‚ÜíC. For example, it makes sense to consider direct systems of commutative
rings.
Example 7.93.
(i) If I = {1, 2, 3} is the partially ordered set in which 1 ‚™Ø2 and 1 ‚™Ø3, then a direct
system over I is a diagram of the form
A
g

f

B
C
(ii) If I is a family of submodules of a module A, then it can be partially ordered under
inclusion; that is, M ‚™ØM‚Ä≤ in case M ‚äÜM‚Ä≤. For M ‚™ØM‚Ä≤, the inclusion map M ‚ÜíM‚Ä≤
is deÔ¨Åned, and it is easy to see that the family of all M ‚ààI with inclusion maps is a direct
system.
(iii) If I is equipped with the discrete partial order, then a direct system over I is just a
family of modules indexed by I.
‚óÄ
DeÔ¨Ånition.
Let I be a partially ordered set, and let {Mi, œïi
j} be a direct system of
R-modules over I. The direct limit (also called inductive limit or colimit) is an R-module
lim
‚àí‚ÜíMi and a family of R-maps {Œ±i : Mi ‚Üílim
‚àí‚ÜíMi : i ‚ààI}, such that
(i) Œ± jœïi
j = Œ±i whenever i ‚™Øj;
(ii) for every module X having maps fi : Mi ‚ÜíX satisfying f jœïi
j = fi for all i ‚™Øj,
there exists a unique map Œ∏ : lim
‚àí‚ÜíMi ‚ÜíX making the following diagram commute:
lim
‚àí‚ÜíMi
Œ∏
 X
Mi
œïi
j 
Œ±i

fi

	
	
	
	
	
	
	
	
M j
Œ± j
"
f j
#
The notation lim
‚àí‚ÜíMi for a direct limit is deÔ¨Åcient in that it does not display the maps
of the corresponding direct system (and lim
‚àí‚ÜíMi does depend on them). However, this is
standard practice.
As with any object deÔ¨Åned as a solution to a universal mapping problem, the direct limit
of a direct system is unique (to isomorphism) if it exists.

506
Modules and Categories
Ch. 7
Proposition 7.94.
The direct limit of any direct system {Mi, œïi
j} of R-modules over a
partially ordered index set I exists.
Proof.
For each i ‚ààI, let Œªi be the injection of Mi into the sum 
i Mi. DeÔ¨Åne
D =

i
Mi

/S,
where S is the submodule of  Mi generated by all elements Œª jœïi
jmi ‚àíŒªimi with mi ‚ààMi
and i ‚™Øj. Now deÔ¨Åne Œ±i : Mi ‚ÜíD by
Œ±i : mi ‚ÜíŒªi(mi) + S.
It is routine to check that D ‚àº= lim
‚àí‚ÜíMi.
‚Ä¢
Thus, each element of lim
‚àí‚ÜíMi has a representative of the form  Œªimi + S.
The argument in Proposition 7.94 can be modiÔ¨Åed to prove that direct limits in other cat-
egories exist; for example, direct limits of commutative rings, of groups, or of topological
spaces exist.
The reader should supply veriÔ¨Åcations of the following assertions, in which we describe
the direct limit of some of the direct systems in Example 7.93.
Example 7.95.
(i) If I is the partially ordered set {1, 2, 3} with 1 ‚™Ø2 and 1 ‚™Ø3, then a direct system is a
diagram
A
g

f

B
C
and the direct limit is the pushout.
(ii) If I is a discrete index set, then the direct system is just the indexed family {Mi : i ‚ààI},
and the direct limit is the sum: lim
‚àí‚ÜíMi ‚àº=

i Mi, for the submodule S in the construction
of lim
‚àí‚ÜíMi is {0}. Alternatively, this is just the diagrammatic deÔ¨Ånition of a coproduct.
‚óÄ
The next result generalizes Theorem 7.33.
Proposition 7.96.
If {Mi, œïi
j} is a direct system, then
Hom(lim
‚àí‚ÜíMi, B) ‚àº= lim
‚Üê‚àíHom(Mi, B)
for every module B.
Proof.
This statement follows from direct limit being the solution of a universal mapping
problem. The proof is dual to that of Proposition 7.92 and it is left to the reader.
‚Ä¢
There is a special kind of partially ordered index set that is useful for direct limits.

Sec. 7.6
Limits
507
DeÔ¨Ånition.
A directed set is a partially ordered set I such that, for every i, j ‚ààI, there
is k ‚ààI with i ‚™Øk and j ‚™Øk.
Example 7.97.
(i) Let I be a simply ordered family of submodules of a module A; that is, if M, M‚Ä≤ ‚ààI,
then either M ‚äÜM‚Ä≤ or M‚Ä≤ ‚äÜM. As in Example 7.93(ii), I is a partially ordered set; here,
I is a directed set.
(ii) If I is the partially ordered set {1, 2, 3} with 1 ‚™Ø2 and 1 ‚™Ø3, then I is not a directed
set.
(iii) If {Mi : i ‚ààI} is some family of modules, and if I is a discrete partially ordered index
set, then I is not directed. However, if we consider the family F of all Ô¨Ånite partial sums
Mi1 ‚äï¬∑ ¬∑ ¬∑ ‚äïMin,
then F is a directed set under inclusion.
(iv) If A is a module, then the family Fin(A) of all the Ô¨Ånitely generated submodules of A
is partially ordered by inclusion, as in Example 7.93(ii), and it is a directed set.
(v) If R is a domain and Q = Frac(R), then the family of all cyclic R-submodules of Q of
the form ‚ü®1/r‚ü©, where r ‚ààR and r Ã∏= 0, is a partially ordered set, as in Example 7.93(ii);
here, it is a directed set under inclusion, for given ‚ü®1/r‚ü©and ‚ü®1/s‚ü©, then each is contained
in ‚ü®1/rs‚ü©.
(vi) Let U be the family of all the open intervals in R containing 0. Partially order U by
reverse inclusion:
U ‚™ØV
if
V ‚äÜU.
Notice that U is directed: Given U, V ‚ààU, then U ‚à©V ‚ààU and U ‚™ØU ‚à©V and
V ‚™ØU ‚à©V .
For each U ‚ààU, deÔ¨Åne
F(U) = { f : U ‚ÜíR : f is continuous},
and, if U ‚™ØV , that is, V ‚äÜU, deÔ¨Åne œÅU
V : F(U) ‚ÜíF(V ) to be the restriction map
f ‚Üíf |V . Then {F(U), œÅU
V } is a direct system.
‚óÄ
There are two reasons to consider direct systems with directed index sets. The Ô¨Årst is
that a simpler description of the elements in the direct limit can be given; the second is that
lim
‚àí‚Üípreserves short exact sequences.
Proposition 7.98.
Let {Mi, œïi
j} be a direct system of left R-modules over a directed index
set I, and let Œªi : Mi ‚Üí Mi be the ith injection, so that lim
‚àí‚ÜíMi = ( Mi)/S, where
S =

Œª jœïi
jmi ‚àíŒªimi : mi ‚ààMi and i ‚™Øj
 
.
(i) Each element of lim
‚àí‚ÜíMi has a representative of the form Œªimi + S (instead of

i Œªimi + S).

508
Modules and Categories
Ch. 7
(ii) Œªimi + S = 0 if and only if œïi
t (mi) = 0 for some t ‚™∞i.
Proof.
(i) As in the proof Proposition 7.94, the existence of direct limits, lim
‚àí‚ÜíMi =
( Mi)/S, and so a typical element x ‚ààlim
‚àí‚ÜíMi has the form x =  Œªimi + S. Since I
is directed, there is an index j with j ‚™∞i for all i occurring in the sum for x. For each
such i, deÔ¨Åne bi = œïi
jmi ‚ààM j, so that the element b, deÔ¨Åned by b = 
i bi lies in M j. It
follows that

Œªimi ‚àíŒª jb =

(Œªimi ‚àíŒª jbi)
=

(Œªimi ‚àíŒª jœïi
jmi) ‚ààS.
Therefore, x =  Œªimi + S = Œª jb + S, as desired.
(ii) If œïi
t mi = 0 for some t ‚™∞i, then
Œªimi + S = Œªimi + (Œªtœïi
t mi ‚àíŒªimi) + S = S.
Conversely, if Œªimi + S = 0, then Œªimi ‚ààS, and there is an expression
Œªimi =

j
a j(Œªkœï j
k m j ‚àíŒª jm j) ‚ààS,
where a j ‚ààR. We are going to normalize this expression; Ô¨Årst, we introduce the following
notation for relators: If j ‚™Øk, deÔ¨Åne
r( j, k, m j) = Œªkœï j
k m j ‚àíŒª jm j.
Since a jr( j, k, m j) = r( j, k, a jm j), we may assume that the notation has been adjusted
so that
Œªimi =

j
r( j, k, m j).
As I is directed, we may choose an index t ‚ààI larger than any of the indices i, j, k
occurring in the last equation. Now
Œªtœïi
t mi = (Œªtœïi
t mi ‚àíŒªimi) + Œªimi
= r(i, t, mi) + Œªimi
= r(i, t, mi) +

j
r( j, k, m j).
Next,
r( j, k, m j) = Œªkœï j
k m j ‚àíŒª jm j
= (Œªtœï j
t m j ‚àíŒª jm j) +

Œªtœïk
t (‚àíœï j
k m j) ‚àíŒªk(‚àíœï j
k m j)

= r( j, t, m j) + r(k, t, ‚àíœï j
k m j),

Sec. 7.6
Limits
509
because œïk
t œïi
k = œïi
t , by deÔ¨Ånition of direct system. Hence,
Œªtœïi
t mi =

‚Ñì
r(‚Ñì, t, x‚Ñì),
where x‚Ñì‚ààM‚Ñì. But it is easily checked, for ‚Ñì‚™Øt, that
r(‚Ñì, t, m‚Ñì) + r(‚Ñì, t, m‚Ä≤
‚Ñì) = r(‚Ñì, t, m‚Ñì+ m‚Ä≤
‚Ñì).
Therefore, we may amalgamate all relators with the same smaller index ‚Ñìand write
Œªtœïi
t mi =

‚Ñì
r(‚Ñì, t, x‚Ñì)
=

‚Ñì
Œªtœï‚Ñì
t x‚Ñì‚àíŒª‚Ñìx‚Ñì
= Œªt

‚Ñì
œï‚Ñì
t x‚Ñì

‚àí

‚Ñì
Œª‚Ñìx‚Ñì,
where x‚Ñì‚ààM‚Ñìand all the indices ‚Ñìare distinct. The unique expression of an element in
a direct sum allows us to conclude, if ‚ÑìÃ∏= t, that Œª‚Ñìx‚Ñì= 0; it follows that x‚Ñì= 0, for Œª‚Ñì
is an injection. The right side simpliÔ¨Åes to Œªtœït
t mt ‚àíŒªtmt = 0, because œït
t is the identity.
Thus, the right side is 0 and Œªtœïi
t mi = 0. Since Œªt is an injection, we have œïi
t mi = 0, as
desired.
‚Ä¢
Our original construction of lim
‚àí‚ÜíMi involved a quotient of  Mi; that is, lim
‚àí‚ÜíMi is a
quotient of a coproduct. In the category Sets, coproduct is disjoint union 5
i Mi. We may
regard a "quotient" of a set X as the family of equivalence classes of some equivalence
relation on X. This categorical analogy suggests that we might be able to give a second
construction of lim
‚àí‚ÜíMi using an equivalence relation on 5
i Mi. When the index set is
directed, this can actually be done (see Exercise 7.65 on page 517).
Example 7.99.
(i) Let I be a simply ordered family of submodules of a module A; that is, if M, M‚Ä≤ ‚ààI,
then either M ‚äÜM‚Ä≤ or M‚Ä≤ ‚äÜM. Then I is a directed set, and lim
‚àí‚ÜíMi ‚àº= !
i Mi.
(ii) If {Mi : i ‚ààI} is some family of modules, then F, all Ô¨Ånite partial sums, is a directed
set under inclusion, and lim
‚àí‚ÜíMi ‚àº=

i Mi.
(iii) If A is a module, then the family Fin(A) of all the Ô¨Ånitely generated submodules of A
is a directed set and lim
‚àí‚ÜíMi ‚àº= A.
(iv) If R is a domain and Q = Frac(R), then the family of all cyclic R-submodules of
Q of the form ‚ü®1/r‚ü©, where r ‚ààR and r Ã∏= 0, forms a directed set under inclusion, and
lim
‚àí‚ÜíMi ‚àº= Q; that is, Q is a direct limit of cyclic modules.
‚óÄ

510
Modules and Categories
Ch. 7
DeÔ¨Ånition.
Let {Ai, Œ±i
j} and {Bi, Œ≤i
j} be direct systems over the same index set I. A
transformation r : {Ai, Œ±i
j} ‚Üí{Bi, Œ≤i
j} is an indexed family of homomorphisms
r = {ri : Ai ‚ÜíBi}
that makes the following diagram commute for all i ‚™Øj:
Ai
ri

Œ±i
j 
Bi
Œ≤i
j

A j
r j
 B j
A transformation r : {Ai, Œ±i
j} ‚Üí{Bi, Œ≤i
j} determines a homomorphism
‚Éór : lim
‚àí‚ÜíAi ‚Üílim
‚àí‚ÜíBi
by
‚Éór :

Œªiai + S ‚Üí

¬µiriai + T,
where S ‚äÜ Ai and T ‚äÜ Bi are the relation submodules in the construction of lim
‚àí‚ÜíAi
and lim
‚àí‚ÜíBi, respectively, and Œªi and ¬µi are the injections of Ai and Bi into the direct sums.
The reader should check that r being a transformation of direct systems implies that ‚Éór is
independent of the choice of coset representative, and hence it is a well-deÔ¨Åned function.
Proposition 7.100.
Let I be a directed set, and let {Ai, Œ±i
j}, {Bi, Œ≤i
j}, and {Ci, Œ≥ i
j }
be direct systems over I. If r : {Ai, Œ±i
j} ‚Üí{Bi, Œ≤i
j} and s : {Bi, Œ≤i
j} ‚Üí{Ci, Œ≥ i
j } are
transformations, and if
0 ‚ÜíAi
ri‚ÜíBi
si‚ÜíCi ‚Üí0
is exact for each i ‚ààI, then there is an exact sequence
0 ‚Üílim
‚àí‚ÜíAi
‚Éór‚Üílim
‚àí‚ÜíBi
‚Éós‚Üílim
‚àí‚ÜíCi ‚Üí0.
Remark.
The hypothesis that I be directed enters the proof only in showing that ‚Éór is an
injection.
‚óÄ
Proof.
We prove only that ‚Éór is an injection, for the proof of exactness of the rest is routine.
Suppose that ‚Éór(x) = 0, where x ‚ààlim
‚àí‚ÜíAi. Since I is directed, Proposition 7.98(i) allows
us to write x = Œªiai + S (where S ‚äÜ Ai is the relation submodule and Œªi is the
injection of Ai into the direct sum). By deÔ¨Ånition, ‚Éór(x + S) = ¬µiriai + T (where T ‚äÜ
 Bi is the relation submodule and ¬µi is the injection of Bi into the direct sum). Now
Proposition 7.98(ii) shows that ¬µiriai + T = 0 in lim
‚àí‚ÜíBi implies that there is an index
k ‚™∞i with Œ≤i
kriai = 0. Since r is a transformation of direct systems, we have
0 = Œ≤i
kriai = rkŒ±i
kai.
Finally, since rk is an injection, we have Œ±i
kai = 0 and, hence, that x = Œªiai + S = 0.
Therefore, ‚Éór is an injection.
‚Ä¢

Sec. 7.6
Limits
511
Example 7.101.
Let U be the family of all the open intervals in R containing 0, partially ordered by reverse
inclusion, and let {B(U), Œ≤U
V } be the direct system of Example 7.97(vi), where
B(U) = { f : U ‚ÜíR : f is continuous}
and Œ≤U
V : f ‚Üíf |V .
We now present two more direct systems over U. DeÔ¨Åne
A(U) = {constant functions f : U ‚ÜíZ}
and
C(U) = {continuous f : U ‚ÜíR ‚àí{0}},
the abelian group under pointwise multiplication. Then {A(U), Œ±U
V } and {C(U), Œ≥ U
V } are
direct systems, where the Œ± and Œ≥ are restriction maps.
DeÔ¨Åne transformations s : {B(U), Œ≤U
V } ‚Üí{C(U), Œ≥ U
V } by setting s(U): B(U) ‚Üí
C(U) to be the map f ‚Üíe2œÄi f , and deÔ¨Åne r : {A(U), Œ±U
V } ‚Üí{B(U), Œ≤U
V } by setting
r(U): A(U) ‚ÜíB(U) to be the inclusion map. It is easy to see that
0 ‚ÜíA(U)
rU
‚ÜíB(U)
sU
‚ÜíC(U) ‚Üí0
is exact for all U, and so Proposition 7.100 gives exactness of
0 ‚Üílim
‚àí‚ÜíA(U) ‚Üílim
‚àí‚ÜíB(U) ‚Üílim
‚àí‚ÜíC(U) ‚Üí0.
It is easy to check that lim
‚àí‚ÜíA(U) ‚àº= Z, and so lim
‚àí‚ÜíB(U) Ã∏= 0.
‚óÄ
There is a way to compare two functors.
DeÔ¨Ånition.
Let F : C ‚ÜíD and G : C ‚ÜíD be covariant functors. A natural transfor-
mation is a family of morphisms œÑ = {œÑC : FC ‚ÜíGC}, one for each object C in C, so
that the following diagram commutes for all f : C ‚ÜíC‚Ä≤ in C:
FC
F f 
œÑC

FC‚Ä≤
œÑC‚Ä≤

GC
G f  GC‚Ä≤
If each œÑC is an equivalence, then œÑ is called a natural equivalence and F and G are called
naturally equivalent.
There is a similar deÔ¨Ånition of natural transformation between contravariant functors.
The next proposition shows that the isomorphisms œïM : HomR(R, M) ‚ÜíM in Exer-
cise 7.5 on page 440 constitute a natural transformation.

512
Modules and Categories
Ch. 7
Proposition 7.102.
If R is a commutative ring, then HomR(R, M) is an R-module, and
the R-isomorphisms
œïM : HomR(R, M) ‚ÜíM,
given by œïM( f ) = f (1), comprise a natural equivalence œï : HomR(R,
) ‚Üí1R, the
identity functor on RMod.
Remark.
Proposition 8.85 generalizes this proposition to modules over noncommutative
rings.
‚óÄ
Proof.
It is easy to check that œïM is an additive function. To see that œïM is an R-
homomorphism, note that
œïM(r f ) = (r f )(1) = f (1r) = f (r) = r[ f (1)] = rœïM( f ),
because f is an R-map. Consider the function M ‚ÜíHomR(R, M) deÔ¨Åned as follows:
If m ‚ààM, then fm : R ‚ÜíM is given by fm(r) = rm; it is easy to see that fm is an
R-homomorphism, and that m ‚Üífm is the inverse of œïM.
To see that the isomorphisms œïM constitute a natural equivalence, it sufÔ¨Åces to show,
for any module homomorphism h : M ‚ÜíN, that the following diagram commutes:
HomR(R, M)
h‚àó

œïM

HomR(R, N)
œïN

M
h
 N,
where h‚àó: f ‚Üíh f . Let f : R ‚ÜíM. Going clockwise, f ‚Üíh f ‚Üíh f (1), while going
counterclockwise, f ‚Üíf (1) ‚Üíh( f (1)).
‚Ä¢
An analysis of the proof of Proposition 7.92 shows that it can be generalized by re-
placing Hom(A,
) by any (covariant) left exact functor F : RMod ‚ÜíAb that preserves
products. However, this added generality is only illusory, for it is a theorem of C. E.
Watts, given such a functor F, that there exists a module A with F naturally equivalent
to HomR(A,
); that is, these representable functors are characterized. Another theorem
of Watts characterizes contravariant functors: If G : RMod ‚ÜíAb is a contravariant left
exact functor that converts sums to products, then there exists a module B with G natu-
rally equivalent to HomR( , B). Proofs of Watts's theorems can be found in Rotman, An
Introduction to Homological Algebra, pages 77-79.
Example 7.103.
(i) In Proposition 7.100, we introduced transformations from one direct system over a
partially ordered index set I to another. If we recall that a direct system of R-modules
over I can be regarded as a functor PO(I) ‚ÜíR Mod, then the reader can see that these
transformations are natural transformations.

Sec. 7.6
Limits
513
If we regard inverse systems over a partially ordered index set as contravariant functors,
then we can also deÔ¨Åne transformations between them (as natural transformations).
(ii) Choose a point p once for all, and let P = {p}; we claim that Hom(P, ): Sets ‚ÜíSets
is naturally equivalent to the identity functor on Sets. If X is a set, deÔ¨Åne
œÑX : Hom(P, X) ‚ÜíX by f ‚Üíf (p).
Each œÑX is a bijection, as is easily seen, and we now show that œÑ is a natural transforma-
tion. Let X and Y be sets, and let h : X ‚ÜíY; we must show that the following diagram
commutes:
Hom(P, X)
h‚àó

œÑX

Hom(P, Y)
œÑY

X
h
 Y,
where h‚àó: f ‚Üíh f . Going clockwise, f ‚Üíh f ‚Üíh f (p), while going counterclockwise,
f ‚Üíf (p) ‚Üíh( f (p)).
(iii) If k is a Ô¨Åeld and V is a vector space over k, then its dual space V ‚àóis the vector space
Homk(V, k) of all linear functionals on V . The evaluation map ev : f ‚Üíf (v) is a linear
functional on V ‚àó; that is, ev ‚àà(V ‚àó)‚àó= V ‚àó‚àó. DeÔ¨Åne œÑV : V ‚ÜíV ‚àó‚àóby
œÑV : v ‚Üíev.
The reader may check that œÑ is a natural transformation from the identity functor on kMod
to the double dual functor. The restriction of œÑ to the subcategory of all Ô¨Ånite-dimensional
vector spaces is a natural equivalence.
‚óÄ
There is a lovely part of ring theory developing these ideas. The Ô¨Årst question is when a
category C is "isomorphic" to a category RMod of modules; we have to be a bit fussy about
what isomorphism means here; it is a bit weaker than having functors F : C ‚ÜíRMod and
G : RMod ‚ÜíC with both composites equal to identity functors.
DeÔ¨Ånition.
A functor F : C ‚ÜíD is an equivalence if there is a functor G : D ‚ÜíC such
that the composites GF and FG are naturally equivalent to the identity functors 1C and
1D, respectively.
Morita theory proves that if R and S are commutative rings, then equivalence of their
module categories implies R ‚àº= S. We will say a few words about Morita theory in Chap-
ter 9, once we introduce modules over noncommutative rings, but the reader should really
read accounts of Morita theory in Jacobson, Basic Algebra II or in Lam, Lectures on Mod-
ules and Rings.
DeÔ¨Ånition.
Given functors F : C ‚ÜíD and G : D ‚ÜíC, then the ordered pair (F, G) is
called an adjoint pair if, for each pair of objects C ‚ààC and D ‚ààD, there are bijections
œÑC,D : HomD(FC, D) ‚ÜíHomC(C, GD)

514
Modules and Categories
Ch. 7
that are natural transformations in C and in D.
In more detail, the following two diagrams commute: For every f : C‚Ä≤ ‚ÜíC in C and
g : D ‚ÜíD‚Ä≤ in D,
HomD(FC, D)
(F f )‚àó
œÑC,D

HomD(FC‚Ä≤, D)
œÑC‚Ä≤,D

HomC(C, GD)
f ‚àó HomC(C‚Ä≤, GD);
HomD(FC, D)
g‚àó

œÑC,D

HomD(FC, D‚Ä≤)
œÑC,D‚Ä≤

HomC(C, GD)
(Gg)‚àó HomC(C, GD‚Ä≤).
Here is the etymology of "adjoint." Let F =
‚äóR B : ModR ‚ÜíModS, and let
G = HomS(B, ): ModS ‚ÜíModR. The isomorphism in Theorem 8.99 is
œÑ : HomS(F(A), C) ‚ÜíHomR(A, G(C)).
If we pretend that Hom( , ) is an inner product, then this reminds us of the deÔ¨Ånition of
adjoint pairs in linear algebra: If T : V ‚ÜíW is a linear transformation of vector spaces
equipped with inner products, then its adjoint is the linear transformation T ‚àó: W ‚ÜíV
such that
(T v, w) = (v, T ‚àów)
for all v ‚ààV and w ‚ààW.
Example 7.104.
(i) Let U : Groups ‚ÜíSets be the underlying functor, which assigns to each group G
its underlying set and views each homomorphism as a mere function, and let F : Sets ‚Üí
Groups be the free functor, which assigns to each set X the free group F X having basis
X. That F X is free with basis X says, for every group H, that every function œï : X ‚ÜíH
corresponds to a unique homomorphism œï : F X ‚ÜíH. It follows that if œï : X ‚ÜíY is
any function, then œï : F X ‚ÜíFY; this is how F is deÔ¨Åned on morphisms: Fœï = œï. The
reader should realize that the function f ‚Üíf |X is a bijection (whose inverse is œï ‚Üíœï)
œÑX,H : HomGroups(F X, H) ‚ÜíHomSets(X,U H).
Indeed, œÑX,H is a natural bijection, showing that (F,U) is an adjoint pair of functors.
This example can be generalized by replacing Groups by other categories having free
objects; for example, RMod for any ring R.
(ii) Adjointness is a property of an ordered pair of functors. In (i), we saw that (F,U) is an
adjoint pair, where F is a free functor and U is the underlying functor. Were (U, F) an ad-
joint pair, then there would be a natural bijection HomSets(U H, Y) ‚àº= HomGroups(H, FY),
where H is a group and Y is a set. This is false in general; if H is a Ô¨Ånite group with more

Sec. 7.6
Limits
515
than one element and Y is a set with more than one element, then HomSets(U H, Y) has
more than one element, but HomGroups(H, FY) has only one element. Therefore, (U, F)
is not an adjoint pair.
(iii) In the next chapter, we shall see (Theorem 8.99) that for every covariant Hom functor
G = HomR(A, ), there exists a functor F such that (F, G) is an adjoint pair (F = A‚äóR
is called tensor product).
‚óÄ
For many more examples of adjoint pairs of functors, see Mac Lane, Categories for the
Working Mathematician, Chapter 4, especially pages 85-86.
Let (F, G) be an adjoint pair of functors, where F : C ‚ÜíD and G : D ‚ÜíC. If C ‚àà
obj(C), then setting D = FC gives a bijection œÑ : HomD(FC, FC) ‚ÜíHomC(C, GFC),
so that Œ∑C, deÔ¨Åned by
Œ∑C = œÑ(1FC),
is a morphism C ‚ÜíGFC. Exercise 7.75 on page 518 shows that Œ∑: 1C ‚ÜíGF is a
natural transformation; it is called the unit of the adjoint pair.
Theorem 7.105.
Let (F, G) be an adjoint pair of functors, where F : C ‚ÜíD and
G : D ‚ÜíC. Then F preserves all direct limits and G preserves all inverse limits.
Remark.
(i) There is no restriction on the index sets of the limits; in particular, they need not be
directed.
(ii) A more precise statement is that if lim
‚àí‚ÜíCi exists in C, then lim
‚àí‚ÜíFCi exists in D, and
lim
‚àí‚ÜíFCi ‚àº= F(lim
‚àí‚ÜíCi).
‚óÄ
Proof.
Let I be a partially ordered set, and let {Ci, œïi
j} be a direct system in C over I.
It is easy to see that {FCi, Fœïi
j} is a direct system in D over I. Consider the following
diagram in D:
F(lim
‚àí‚ÜíCi)
Œ≥
 D
FCi
œïi
j 
FŒ±i
$!!!!!!!!!
fi








FC j
FŒ± j
%""""""""""""""""
f j
&###############
where Œ±i : Ci ‚Üílim
‚àí‚ÜíCi are the maps in the deÔ¨Ånition of direct limit. We must show that
there exists a unique morphism Œ≥ : F(lim
‚àí‚ÜíCi) ‚ÜíD making the diagram commute. The
idea is to apply G to this diagram, and to use the unit Œ∑: 1C ‚ÜíGF to replace GF(lim
‚àí‚ÜíCi)

516
Modules and Categories
Ch. 7
and GFCi by lim
‚àí‚ÜíCi and Ci, respectively. In more detail, there are morphisms Œ∑ and Œ∑i,
by Exercise 7.75 on page 518, making the following diagram commute:
lim
‚àí‚ÜíCi
Œ∑  GF(lim
‚àí‚ÜíCi)
Ci
Œ±i

Œ∑i
 GFCi
GFŒ±i

Combining this with G applied to the original diagram gives commutativity of
lim
‚àí‚ÜíCi
Œ≤
 GD
Ci
œïi
j 
Œ±i








(G fi)Œ∑i








C j
Œ± j
"$$$$$$$$$$$$$$$
(G f j)Œ∑ j
&###############
By deÔ¨Ånition of direct limit, there exists a unique Œ≤ : lim
‚àí‚ÜíCi ‚ÜíGD making the diagram
commute; that is, Œ≤ ‚ààHomC(lim
‚àí‚ÜíCi, GD). Since (F, G) is an adjoint pair, there exists a
natural bijection
œÑ : HomD(F(lim
‚àí‚ÜíCi), D) ‚ÜíHomC(lim
‚àí‚ÜíCi, GD).
DeÔ¨Åne
Œ≥ = œÑ ‚àí1(Œ≤) ‚ààHomD(F(lim
‚àí‚ÜíCi), D).
We claim that Œ≥ : F(lim
‚àí‚ÜíCi) ‚ÜíD makes the Ô¨Årst diagram commute. The Ô¨Årst commuta-
tive square in the deÔ¨Ånition of adjointness gives commutativity of
HomC(lim
‚àí‚ÜíCi, GD)
œÑ ‚àí1

Œ±‚àó
i
 HomC(Ci, GD)
œÑ ‚àí1

HomD(F(lim
‚àí‚ÜíCi), D)(FŒ±i)‚àó HomD(FCi, D).
Hence, œÑ ‚àí1Œ±‚àó
i = (FŒ±i)‚àóœÑ ‚àí1. Evaluating both functions on Œ≤, we have
(FŒ±i)‚àóœÑ ‚àí1(Œ≤) = (FŒ±i)‚àóŒ≥ = Œ≥ FŒ±i.
On the other hand, since Œ≤Œ±i = (G fi)Œ∑i, we have
œÑ ‚àí1Œ±‚àó
i (Œ≤) = œÑ ‚àí1(Œ≤Œ±i) = œÑ ‚àí1((G fi)Œ∑i).

Sec. 7.6
Limits
517
Therefore,
Œ≥ FŒ±i = œÑ ‚àí1((G fi)Œ∑i).
The second commutative square in the deÔ¨Ånition of adjointness gives commutativity of
HomD(FCi, FCi)
( fi)‚àó
œÑ

HomD(FCi, D)
œÑ

HomC(Ci, GFCi)
(G fi)‚àó HomC(Ci, GD);
that is,
œÑ( fi)‚àó= (G fi)‚àóœÑ.
Evaluating at 1FCi , the deÔ¨Ånition of Œ∑i gives œÑ( fi)‚àó(1) = (G fi)‚àóœÑ(1), and so œÑ fi =
(G fi)‚àóŒ∑i. Therefore,
Œ≥ FŒ±i = œÑ ‚àí1((G fi)Œ∑i) = œÑ ‚àí1œÑ fi = fi,
so that Œ≥ makes the original diagram commute.
We leave the proof of the uniqueness of Œ≥ as an exercise for the reader, with the hint to
use the uniqueness of Œ≤.
The dual proof shows that G preserves inverse limits.
‚Ä¢
There is a necessary and sufÔ¨Åcient condition, called the adjoint functor theorem, that a
functor be part of an adjoint pair; see Mac Lane, Categories for the Working Mathemati-
cian, page 117.
EXERCISES
7.65 Let {Mi, œïi
j} be a direct system of R-modules with index set I, and let 5
i Mi be the disjoint
union. DeÔ¨Åne mi ‚àºm j on 5
i Mi, where mi ‚ààMi and m j ‚ààM j, if there exists an index k
with k ‚™∞i and k ‚™∞j such that œïi
kmi = œï j
k m j.
(i) Prove that ‚àºis an equivalence relation on 5
i Mi.
(ii) Denote the equivalence class of mi by [mi], and let L denote the family of all such
equivalence classes. Prove that the following deÔ¨Ånitions give L the structure of an R-
module:
r[mi] = [rmi] if r ‚ààR;
[mi] + [m‚Ä≤
j] = [œïi
kmi + œï j
k m‚Ä≤
j], where k ‚™∞i and k ‚™∞j.
(iii) Prove that L ‚àº= lim
‚àí‚ÜíMi.
Hint. Use Proposition 7.98.
7.66 Let {Mi, œïi
j} be a direct system of R-modules, and let F : RMod ‚ÜíC be a functor to some
category C. Prove that {F Mi, Fœïi
j} is a direct system in C if F is covariant, while it is an
inverse system if F is contravariant.

518
Modules and Categories
Ch. 7
7.67 Give an example of a direct system of modules, {Ai, Œ±i
j}, over some directed index set I, for
which Ai Ã∏= {0} for all i and lim
‚àí‚ÜíAi = {0}.
7.68
(i) Let K be a coÔ¨Ånal subset of a directed index set I (that is, for each i ‚ààI, there is k ‚ààK
with i ‚™Øk), let {Mi, œïi
j} be a direct system over I, and let {Mi, œïi
j} be the subdirect
system whose indices lie in K. Prove that the direct limit over I is isomorphic to the
direct limit over K.
(ii) A partially ordered set I has a top element if there exists ‚àû‚ààI with i ‚™Ø‚àûfor all
i ‚ààI. If {Mi, œïi
j} is a direct system over I, prove that
lim
‚àí‚ÜíMi ‚àº= M‚àû.
(iii) Show that part (i) may not be true if the index set is not directed.
Hint. Pushout.
7.69 Let C and D be categories, and let F(C, D) denote the class of all (covariant) functors C ‚ÜíD.
Prove that F(C, D) is a category if we deÔ¨Åne
Hom(F, G) = {all natural transformations F ‚ÜíG}.
Remark. There is a technical, set-theoretic, problem; why is Hom(F, G) a set (and not a
proper class)? The answer is that it may not be a set; the easiest (but not the only) way to
resolve this problem is to assume that the objects in C and D form a set; that is, C and D are
small categories. We allow the reader to do this here.
7.70 A functor T : RMod ‚ÜíAb is called representable if there exists an R-module A and a natural
equivalence œÑ : T ‚ÜíHomR(A, ). Prove that if HomR(A, ) and HomR(B, ) are naturally
equivalent, then A ‚àº= B. Conclude that if a representable functor T is naturally equivalent to
HomR(A, ), then A is determined, up to isomorphism, by T .
7.71 If kV is the category of all Ô¨Ånite-dimensional vector spaces over a Ô¨Åeld k, prove that the double
dual, V ‚ÜíV ‚àó‚àó, is naturally equivalent to the identity functor.
7.72 Let {Ei, œïi
j} be a direct system of injective R-modules over a directed index set I. Prove that
if R is noetherian, then lim
‚àí‚ÜíEi is an injective module.
Hint. Use Proposition 7.69.
7.73 Consider the ideal I = (x) in k[x], where k is a commutative ring. Prove that the completion
of the polynomial ring k[x] is k[[x]], the ring of formal power series.
7.74 Let r : {Ai, Œ±i
j} ‚Üí{Bi, Œ≤i
j} and s : {Bi, Œ≤i
j} ‚Üí{Ci, Œ≥ i
j } be transformations of inverse sys-
tems over an index set I. If
0 ‚ÜíAi
ri‚ÜíBi
si‚ÜíCi
is exact for each i ‚ààI, prove that there is an exact sequence
0 ‚Üílim
‚Üê‚àíAi
‚Éór‚Üílim
‚Üê‚àíBi
‚Éós‚Üílim
‚Üê‚àíCi.
7.75 Let (F, G) be an adjoint pair of functors, where F : C ‚ÜíD and G : D ‚ÜíC, and let
œÑC,D : Hom(FC, D) ‚ÜíHom(C, GC) be the natural bijection.
(i) If D = FC, there is a natural bijection
œÑC,FC : Hom(FC, FC) ‚ÜíHom(C, GFC)
with œÑ(1FC) = Œ∑C ‚ààHom(C, GFC). Prove that Œ∑: 1C ‚ÜíGF is a natural transfor-
mation.

Sec. 7.6
Limits
519
(ii) If C = GD, there is a natural bijection
œÑ‚àí1
GD,D : Hom(GD, GD) ‚ÜíHom(FGD, D)
with œÑ‚àí1(1D) = ŒµD ‚ààHom(FGD, D). Prove that Œµ: FG ‚Üí1D is a natural transfor-
mation. (We call Œµ the counit of the adjoint pair.)
7.76 If I is a partially ordered set and C is a category, then a presheaf over I to C is a contravariant
functor F : PO(I) ‚ÜíC.
(i) If I is the family of all open intervals U in R containing 0, show that F in Exam-
ple 7.97(vi) is a presheaf of abelian groups.
(ii) Let X be a topological space, and let I be the partially ordered set whose elements are
the open sets in X. DeÔ¨Åne a sequence of presheaves F‚Ä≤ ‚ÜíF ‚ÜíF‚Ä≤‚Ä≤ over I to Ab to
be exact if
F‚Ä≤(U) ‚ÜíF(U) ‚ÜíF‚Ä≤‚Ä≤(U)
is an exact sequence for every U ‚ààI. If F is a presheaf on I, deÔ¨Åne Fx, the stalk at
x ‚ààX, by
Fx = lim
‚àí‚Üí
U‚àãx
F(U).
If F‚Ä≤ ‚ÜíF ‚ÜíF‚Ä≤‚Ä≤ is an exact sequence of presheaves, prove, for every x ‚ààX, that
there is an exact sequence of stalks
F‚Ä≤
x ‚ÜíFx ‚ÜíF‚Ä≤‚Ä≤
x .
7.77
(i) Let F : Groups ‚ÜíAb be the functor with F(G) = G/G‚Ä≤, where G‚Ä≤ is the commutator
subgroup of a group G, and let U : Ab ‚ÜíGroups be the functor taking every abelian
group A into itself (that is, U A regards A as a not necessarily abelian group). Prove that
(F,U) is an adjoint pair of functors.
(ii) Prove that the unit of the adjoint pair (F,U) is the natural map G ‚ÜíG/G‚Ä≤.
7.78 Prove that if T : RMod ‚ÜíAb is an additive left exact functor preserving products, then T
preserves inverse limits.
7.79 Generalize Proposition 5.4 to allow inÔ¨Ånitely many summands. Let {Si : i ‚ààI} be a family of
submodules of an R-module M, where R is a commutative ring. If M =
!
i‚ààI Si
 
, then the
following conditions are equivalent.
(i) M = 
i‚ààI Si.
(ii) Every a ‚ààM has a unique expression of the form a = si1 + ¬∑ ¬∑ ¬∑ + sin, where si j ‚ààSi j .
(iii) For each i ‚ààI,
Si ‚à©
6
jÃ∏=i
Sj
7
= {0}.

8
Algebras
This chapter introduces noncommutative rings, along with modules over them. We begin
by showing that modules are just another way of viewing representations of rings; that is,
ring elements can be viewed as operators on an abelian group. Afterward, we prove the
Wedderburn-Artin theorems, which classify semisimple rings, and Maschke's theorem,
which says that group algebras are usually semisimple. After a formal interlude investi-
gating tensor products, a construction intimately related to Hom functors (thanks to the
adjoint isomorphism), we introduce representations and characters of Ô¨Ånite groups. This
discussion is then applied to prove group-theoretic theorems of Burnside and of Frobenius.
8.1 NONCOMMUTATIVE RINGS
All the rings we have considered so far are commutative, but there are interesting examples
of noncommutative rings as well.
DeÔ¨Ånition.
A ring R is an additive abelian group equipped with a multiplication
R √ó R ‚ÜíR, denoted by (a, b) ‚Üíab, such that, for all a, b, c ‚ààR,
(i) a(bc) = (ab)c;
(ii) a(b + c) = ab + ac
and
(b + c)a = ba + ca;
(iii) there is 1 ‚ààR such that, for all a ‚ààR,
1a = a = a1.
Here are some examples of rings that are not commutative.
Example 8.1.
(i) If k is any commutative ring, then Matn(k), all n √ó n matrices with entries in k, is a ring
under matrix multiplication and matrix addition; it is commutative if and only if n = 1.
520

Sec. 8.1
Noncommutative Rings
521
If k is not commutative, Matn(k) is a ring, for the usual deÔ¨Ånition of matrix multiplica-
tion still makes sense: If A = [ai j] and B = [bi j], then the i j entry of AB is 
p aipbpj;
just make sure that entries in A always appear on the left and that entries of B always
appear on the right.
(ii) If k is any commutative ring and G is a group (whose operation is written multiplica-
tively), then we deÔ¨Åne the group algebra kG as follows. Its additive abelian group is the
free k-module having a basis labeled by the elements of G; thus, each element has a unique
expression of the form 
g‚ààG agg, where ag ‚ààk for all g ‚ààG and almost all ag = 0; that
is, only Ô¨Ånitely many ag can be nonzero. If g and h are basis elements (i.e., if g, h ‚ààG),
deÔ¨Åne their product in kG to be their product gh in G, while ag = ga whenever a ‚ààk and
g ‚ààG. The product of any two elements of kG is deÔ¨Åned by extending by linearity:
 
g‚ààG
agg

h‚ààG
bhh

=

z‚ààG
 
gh=z
agbh

z.
A group algebra kG is commutative if and only if the group G is abelian.
In Exercise 8.17 on page 533, we give another description of kG, when G is a Ô¨Ånite
group, as all functions G ‚Üík under pointwise addition and convolution.
(iii) An endomorphism of an abelian group A is a homomorphism f : A ‚ÜíA. The endo-
morphism ring of A, denoted by End(A), is the set of all endomorphisms under pointwise
addition
f + g : a ‚Üíf (a) + g(a),
and composition as multiplication. It is easy to check that End(A) is always a ring, and
simple examples show that it may not be commutative. For example, if p is a prime, then
End(Ip ‚äïIp) ‚àº= Mat2(Fp).
(iv) Let k be a ring, and let œÉ : k ‚Üík be a ring endomorphism. DeÔ¨Åne a new multiplication
on k[x] = {
i ai xi : ai ‚ààk} by
xa = œÉ(a)x.
Thus, multiplication of two polynomials is now given by
 
i ai xi 
j b j x j
=

r cr xr,
where cr = 
i+ j=r aiœÉ i(b j). It is a routine exercise to show that k[x], equipped with this
new multiplication, is a not necessarily commutative ring. We denote this ring by k[x; œÉ],
and we call it a ring of skew polynomials.
(v) If R1, . . . , Rt are rings, then their direct product,
R = R1 √ó ¬∑ ¬∑ ¬∑ √ó Rt,
is the cartesian product with coordinatewise addition and multiplication:
(ri) + (r‚Ä≤
i) = (ri + r‚Ä≤
i)
and
(ri)(r‚Ä≤
i) = (rir‚Ä≤
i);
we have abbreviated (r1, . . . ,rt) to (ri).

522
Algebras
Ch. 8
It is easy to see that R = R1√ó¬∑ ¬∑ ¬∑√óRt is a ring. Let us identify ri ‚ààRi with the "vector"
whose ith coordinate is ri and whose other coordinates are 0. If i Ã∏= j, then rir j = 0.
(vi) A division ring D (or a skew Ô¨Åeld) is a "noncommutative Ô¨Åeld"; that is, D is a ring in
which 1 Ã∏= 0 and every nonzero element a ‚ààD has a multiplicative inverse: there exists
a‚Ä≤ ‚ààD with aa‚Ä≤ = 1 = a‚Ä≤a. Equivalently, a ring D is a division ring if the set D√ó of its
nonzero elements forms a group under multiplication. Of course, Ô¨Åelds are division rings;
here is a noncommutative example.
Let H be a four-dimensional vector space over R, and label a basis 1, i, j, k. Thus, a
typical element h in H is
h = a + bi + cj + dk,
where a, b, c, d ‚ààR. We deÔ¨Åne a multiplication of basis elements as follows:
i2 = j2 = k2 = ‚àí1;
i j = k = ‚àíji;
jk = i = ‚àíkj;
ki = j = ‚àíik,
and we insist that every a ‚ààR commutes with 1, i, j, k. If we now deÔ¨Åne a multiplication
on arbitrary elements by extending by linearity, then H is a ring, called the (real) quater-
nions1 (associativity of multiplication follows from associativity of multiplication in the
group Q = {¬±1, ¬±i, ¬± j, ¬±k} of quaternions). To see that H is a division ring, it sufÔ¨Åces
to Ô¨Ånd inverses of nonzero elements. DeÔ¨Åne the conjugate of u = a + bi + cj + dk ‚ààH
by
u = a ‚àíbi ‚àícj ‚àídk;
we see easily that
uu = a2 + b2 + c2 + d2.
Hence, uu Ã∏= 0 when u Ã∏= 0, and so
u‚àí1 = u/uu = u/(a2 + b2 + c2 + d2).
It is not difÔ¨Åcult to prove that conjugation is an additive isomorphism satisfying
uw = w u.
Just as the Gaussian integers were used to prove Fermat's two-squares theorem (Theo-
rem 3.66)‚ÄîAn odd prime p is a sum of two squares if and only if p ‚â°1 mod 4‚Äîso, too,
can the quaternions be used to prove Lagrange's theorem that every positive integer is the
sum of four squares (see Samuel, Algebraic Theory of Numbers, pages 82-85).
The only property of the Ô¨Åeld R we have used in constructing H is that a sum of nonzero
squares be nonzero; any subÔ¨Åeld of R has this property, but C does not. For example, there
is a division ring of rational quaternions.
We shall construct other examples of division rings in Chapter 10 when we discuss
crossed product algebras.
‚óÄ
1The quaternions were discovered in 1843 by W. R. Hamilton when he was seeking a generalization of the
complex numbers to model some physical phenomena. He had hoped to construct a three-dimensional algebra
for this purpose, but he succeeded only when he saw that dimension 3 should be replaced by dimension 4. This
is why Hamilton called H the quaternions, and this division ring is denoted by H to honor Hamilton.

Sec. 8.1
Noncommutative Rings
523
Remark.
Some mathematicians do not assume, as part of the deÔ¨Ånition, that rings must
contain a unit element 1. They point to natural examples, as the even integers or the
integrable functions, where a function f : [0, ‚àû) ‚ÜíR is integrable if
2 ‚àû
0
| f (x)| dx = lim
t‚Üí‚àû
2 t
0
| f (x)| dx < ‚àû.
It is not difÔ¨Åcult to see that if f and g are integrable, then so are their pointwise sum f + g
and pointwise product f g. The only candidate for a unit is the constant function e with
e(x) = 1 for all x ‚àà[0, ‚àû) but, obviously, e is not integrable.
The absence of a unit, however, makes many constructions more complicated. For
example, if R is a "ring without unit" and a ‚ààR, then deÔ¨Åning (a), the principal ideal
generated by a, as (a) = {ra : r ‚ààR}, leads to the possibility that a /‚àà(a); thus, we must
redeÔ¨Åne (a) to force a inside. Polynomial rings become strange: If R has no unit, then
x /‚ààR[x]. There are other (more important) reasons for wanting a unit, but these examples
should sufÔ¨Åce to show that not assuming a unit can lead to some awkwardness; therefore,
we have decided to insist that rings do have units.
Exercise 8.1 on page 531 shows that every "ring without unit" can be imbedded as an
ideal in a ring (with unit).
‚óÄ
A subring S of a ring R is a ring contained in R so that 1 ‚ààS and if s, s‚Ä≤ ‚ààS, then
their sum s + s‚Ä≤ and product ss‚Ä≤ have the same meaning in S as in R. Here is the formal
deÔ¨Ånition.
DeÔ¨Ånition.
A subring S of a ring R is a subset of R such that
(i) 1 ‚ààS;
(ii) if a, b ‚ààS, then a ‚àíb ‚ààS;
(iii) if a, b ‚ààS, then ab ‚ààS.
Example 8.2.
(i) The center of a ring R, denoted by Z(R), is the set of all those elements z ‚ààR com-
muting with everything:
Z(R) = {z ‚ààR : zr = rz for all r ‚ààR}.
It is easy to see that Z(R) is a subring of R. If k is a commutative ring, then k ‚äÜZ(kG).
Exercise 8.10 on page 532 asks you to prove that the center of a matrix ring, Z(Matn(R)), is
the set of all scalar matrices aI, where a ‚ààZ(R) and I is the identity matrix; Exercise 8.11
on page 532 says that Z(H) = {a1 : a ‚ààR}.
(ii) If D is a division ring, then its center, Z(D), is a Ô¨Åeld. Moreover, if D√ó is the multi-
plicative group of the nonzero elements of D, then Z(D√ó) = Z(D)√ó; that is, the center of
the multiplicative group D√ó consists of the nonzero elements of Z(D).
‚óÄ
Here are two "nonexamples" of subring.

524
Algebras
Ch. 8
Example 8.3.
(i) DeÔ¨Åne S = {a + ib : a, b ‚ààZ} ‚äÜC. DeÔ¨Åne addition in S to coincide with addition in
C, but deÔ¨Åne multiplication in S by
(a + bi)(c + di) = ac + (ad + bc)i
(thus, i2 = 0 in S, whereas i2 Ã∏= 0 in C). It is easy to check that S is a ring, but it is not a
subring of C.
(ii) If R = Z √ó Z, then its unit is (1, 1). Let
S = {(n, 0) ‚ààZ √ó Z : n ‚ààZ}.
It is easily checked that S is closed under addition and multiplication; indeed, S is a ring,
for (1, 0) is the unit in S. However, S is not a subring of R because S does not contain the
unit of R.
‚óÄ
An immediate complication arising from noncommutativity is that the notion of ideal
splinters into three notions. There are now left ideals, right ideals, and two-sided ideals.
DeÔ¨Ånition.
Let R be a ring, and let I be an additive subgroup of R. Then I is a left ideal
if a ‚ààI and r ‚ààR implies ra ‚ààI, while I is a right ideal if ar ‚ààI. We say that I is a
two-sided ideal if it is both a left ideal and a right ideal.
Example 8.4.
In Mat2(R), the equation
a
b
c
d
 u
0
v
0

=
‚àó
0
‚àó
0

shows that the "Ô¨Årst columns" (that is, the matrices that are 0 off the Ô¨Årst column), form a
left ideal (the "second columns" also form a left ideal.) The equation
u
v
0
0
 a
b
c
d

=
‚àó
‚àó
0
0

shows that the "Ô¨Årst rows" (that is, the matrices that are 0 off the Ô¨Årst row), form a right
ideal (the "second rows" also form a right ideal). The reader may show that neither of these
one-sided ideals is two-sided; indeed, the only two-sided ideals are {0} and Mat2(R) itself.
This example generalizes, in the obvious way, to give examples of left ideals and of right
ideals in Matn(k) for all n ‚â•2 and every ring k.
‚óÄ
Example 8.5.
In a direct product of rings, R = R1 √ó ¬∑ ¬∑ ¬∑ √ó Rt, each R j is identiÔ¨Åed with
R j =

(0, . . . , 0,r j, 0 . . . , 0) : r j ‚ààR j

,
where r j occurs in the jth coordinate. It is easy to see that each such R j is a two-sided
ideal in R (for if j Ã∏= i, then r jri = 0 and rir j = 0). Moreover, any left or right ideal in
R j is also a left or right ideal in R.
‚óÄ

Sec. 8.1
Noncommutative Rings
525
Homomorphisms œï : R ‚ÜíS of rings are deÔ¨Åned exactly as in the commutative case;
we shall see that their kernels are two-sided ideals. Annihilator ideals, deÔ¨Åned in the next
section, are another source of two-sided ideals.
DeÔ¨Ånition.
If R and S are rings, then a ring homomorphism (or ring map) is a function
œï : R ‚ÜíS such that, for all r,r‚Ä≤ ‚ààR,
(i) œï(r + r‚Ä≤) = œï(r) + œï(r‚Ä≤);
(ii) œï(rr‚Ä≤) = œï(r)œï(r‚Ä≤);
(iii) œï(1) = 1.
If œï : R ‚ÜíS is a ring homomorphism, then the kernel is deÔ¨Åned as usual:
ker œï = {r ‚ààR : œï(r) = 0}.
The image is also deÔ¨Åned as usual:
im œï = {s ‚ààS : s = œï(r) for some r ‚ààR}.
The kernel is always a two-sided ideal, for if œï(a) = 0 and r ‚ààR, then
œï(ra) = œï(r)œï(a) = 0 = œï(a)œï(r) = œï(ar),
so that a ‚ààker œï implies both ra and ar lie in ker œï. On the other hand, im œï is only a
subring of S.
We can form the quotient ring R/I when I is a two-sided ideal, because the multiplica-
tion on the quotient abelian group R/I, given by (r + I)(s + I) = rs + I, is well-deÔ¨Åned:
If r + I = r‚Ä≤ + I and s + I = s‚Ä≤ + I, then rs + I = r‚Ä≤s‚Ä≤ + I. That is, if r ‚àír‚Ä≤ ‚ààI and
s ‚àís‚Ä≤ ‚ààI, then rs ‚àír‚Ä≤s‚Ä≤ ‚ààI. To see this, note that
rs ‚àír‚Ä≤s‚Ä≤ = rs ‚àírs‚Ä≤ + rs‚Ä≤ ‚àír‚Ä≤s‚Ä≤ = r(s ‚àís‚Ä≤) + (r ‚àír‚Ä≤)s ‚ààI,
for both s ‚àís‚Ä≤ and r ‚àír‚Ä≤ lie in I and, since I is a two-sided ideal, each term on the right
side also lies in I. It is easy to see that the natural map œÄ : R ‚ÜíR/I, deÔ¨Åned (as usual)
by r ‚Üír + I, is a ring map. It is routine to check that the isomorphism theorems and the
correspondence theorem hold for (noncommutative) rings.
We now deÔ¨Åne R-modules when R is any, not necessarily commutative, ring. In contrast
to the commutative case, there are now two different kinds of R-modules: left R-modules
and right R-modules. We have already deÔ¨Åned left R-modules (although we have been
calling them R-modules until now).
DeÔ¨Ånition.
Let R be a ring. A left R-module is an (additive) abelian group M equipped
with a scalar multiplication R √ó M ‚ÜíM, denoted by
(r, m) ‚Üírm,
such that the following axioms hold for all m, m‚Ä≤ ‚ààM and all r,r‚Ä≤, 1 ‚ààR:
(i) r(m + m‚Ä≤) = rm + rm‚Ä≤;

526
Algebras
Ch. 8
(ii) (r + r‚Ä≤)m = rm + r‚Ä≤m;
(iii) (rr‚Ä≤)m = r(r‚Ä≤m);
(iv) 1m = m.
DeÔ¨Ånition.
A right R-module is an (additive) abelian group M equipped with a scalar
multiplication M √ó R ‚ÜíM, denoted by
(m,r) ‚Üímr,
such that the following axioms hold for all m, m‚Ä≤ ‚ààM and all r,r‚Ä≤, 1 ‚ààR:
(i) (m + m‚Ä≤)r = mr + m‚Ä≤r;
(ii) m(r + r‚Ä≤) = mr + mr‚Ä≤;
(iii) m(rr‚Ä≤) = (mr)r‚Ä≤;
(iv) m1 = m.
Notation.
We denote a left R-module M by R M, and we denote a right R-module M by
MR.
Of course, there is nothing to prevent us from denoting the scalar multiplication in a
right R-module by (m,r) ‚Üírm. If we do so, then we see that only axiom (iii) differs
from the axioms for a left R-module; the right version now reads
(rr‚Ä≤)m = r‚Ä≤(rm).
That there is an honest difference between these two deÔ¨Ånitions is apparent from ideals. A
left ideal in a ring R is a left R-module, a right ideal is a right R-module, and we have seen
in Example 8.4 that these are different things.
We deÔ¨Åne submodule in the obvious way; it is a subgroup that is closed under scalar
multiplication. Note that a ring R can be regarded as a left R-module (denoted by R R)
or as a right R-module (denoted by RR). The submodules of R R are the left ideals; the
submodules of RR are the right ideals. If N is a submodule of a left R-module M, then the
quotient module M/N is the quotient group made into a left R-module by deÔ¨Åning scalar
multiplication to be r(m + N) = rm + N.
DeÔ¨Ånition.
An additive function f : MR ‚ÜíNR between right R-modules M and N is
an R-homomorphism (or R-map) if f (mr) = f (m)r for all m ‚ààM and r ‚ààR. All the
right R-modules and R-maps form a category, denoted by ModR. The notation RMod has
already been introduced to denote the category of all left R-modules. In either category,
we denote the set of all R-maps between R-modules M and N, where both are R-modules
on the same side, by
HomR(M, N).

Sec. 8.1
Noncommutative Rings
527
Example 8.6.
Let G be a group, let k be a commutative ring, and let A be a left kG-module. DeÔ¨Åne a
new action of G on A, denoted by g ‚àóa, by
g ‚àóa = g‚àí1a,
where a ‚ààA and g ‚ààG. For an arbitrary element of kG, deÔ¨Åne

g‚ààG
mgg

‚àóa =

g‚ààG
mgg‚àí1a.
It is easy to see that A is a right kG-module under this new action; that is, if u ‚ààkG
and a ‚ààA, the function A √ó kG ‚ÜíA, given by (a, u) ‚Üíu ‚àóa, satisÔ¨Åes the axioms in
the deÔ¨Ånition of right module. Of course, we usually write au instead of u ‚àóa. Thus, a
kG-module can be viewed as either a left or a right kG-module.
‚óÄ
Example 8.7.
We now generalize Example 8.1(iii). If M is a left R-module, then an R-map f : M ‚ÜíM
is called an R-endomorphism of M. The endomorphism ring, denoted by EndR(M), is the
set of all R-endomorphisms of M. As a set, EndR(M) = HomR(M, M), which we have
already seen is an additive abelian group. Now deÔ¨Åne multiplication to be composition: If
f, g : M ‚ÜíM, then f g : m ‚Üíf (g(m)).
If M is regarded as an abelian group, then we write EndZ(M) for the endomorphism
ring End(M) (with no subscript) deÔ¨Åned in Example 8.1(iii), and EndR(M) is a subring of
EndZ(M).
‚óÄ
We are now going to show that ring elements can be regarded as operators (that is, as
endomorphisms) on an abelian group.
DeÔ¨Ånition.
A representation of a ring R is a ring homomorphism
œÉ : R ‚ÜíEndZ(M),
where M is an abelian group.
Representations of rings can be translated into the language of modules.
Proposition 8.8.
Every representation œÉ : R ‚ÜíEndZ(M), where M is an abelian group,
equips M with the structure of a left R-module. Conversely, every left R-module M deter-
mines a representation œÉ : R ‚ÜíEndZ(M).
Proof.
Given a homomorphism œÉ : R ‚ÜíEndZ(M), denote œÉ(r): M ‚ÜíM by œÉr, and
deÔ¨Åne scalar multiplication R √ó M ‚ÜíM by
rm = œÉr(m),

528
Algebras
Ch. 8
where m ‚ààM. A routine calculation shows that M, equipped with this scalar multiplica-
tion, is a left R-module.
Conversely, assume that M is a left R-module. If r ‚ààR, then m ‚Üírm deÔ¨Ånes an
endomorphism Tr : M ‚ÜíM. It is easily checked that the function œÉ : R ‚ÜíEndZ(M),
given by œÉ : r ‚ÜíTr, is a representation.
‚Ä¢
DeÔ¨Ånition.
A left R-module is called faithful if, for all r ‚ààR, whenever rm = 0 for all
m ‚ààM, then r = 0.
Of course, M being faithful merely says that the representation œÉ : R ‚ÜíEndZ(M)
(given in Proposition 8.8) is an injection.
An R-module M is Ô¨Ånitely generated if there are Ô¨Ånitely many elements m1, . . . , mn ‚àà
M with every x ‚ààM an R-linear combination of m1, . . . , mn. In particular, an R-module
is cyclic if it generated by one element.
Example 8.9.
Let E/k be a Galois extension with Galois group G = Gal(E/k). Then E is a kG-module:
If e ‚ààE, then

œÉ‚ààG
aœÉœÉ

(e) =

œÉ‚ààG
aœÉœÉ(e).
We say that E/k has a normal basis if E is a cyclic kG-module. Every Galois extension
E/k has a normal basis (see Jacobson, Basic Algebra I, p. 283).
‚óÄ
We can now augment Proposition 7.24, an earlier result about algebraic integers.
Proposition 8.10.
(i) If M is a Ô¨Ånitely generated abelian group that is a faithful left R-module for some
ring R, then the additive group of R is Ô¨Ånitely generated.
(ii) If Œ± is a complex number, let Z[Œ±] be the subring of C it generates. If there is a
faithful Z[Œ±]-module M that is Ô¨Ånitely generated as an abelian group, then Œ± is an
algebraic integer.
Proof.
(i) By Proposition 8.8, the ring R is isomorphic to a subring of EndZ(M). Since
M is Ô¨Ånitely generated, Exercise 8.6 on page 531 shows that EndZ(M) = HomZ(M, M)
is Ô¨Ånitely generated. By Proposition 7.24, the additive group of R is Ô¨Ånitely generated.
(ii) By Proposition 7.24, it sufÔ¨Åces to prove that the ring Z[Œ±] is Ô¨Ånitely generated as an
abelian group, and this follows from part (i).
‚Ä¢
We could deÔ¨Åne right-sided versions of all the previous deÔ¨Ånitions in Chapter 7‚Äî
submodule, quotient module, R-homomorphisms, isomorphism theorems, correspondence
theorem, direct sums, and so on‚Äîbut there is a more elegant way to do this.

Sec. 8.1
Noncommutative Rings
529
DeÔ¨Ånition.
Let R be a ring with multiplication ¬µ: R √ó R ‚ÜíR. DeÔ¨Åne the opposite ring
to be the ring Rop whose additive group is the same as the additive group of R, but whose
multiplication ¬µop : R √ó R ‚ÜíR is deÔ¨Åned by ¬µop(r, s) = ¬µ(s,r) = sr.
Thus, we have merely reversed the order of multiplication. It is straightforward to check
that Rop is a ring; it is obvious that (Rop)op = R; moreover, R = Rop if and only if R is
commutative.
Proposition 8.11.
Every right R-module M is a left Rop-module, and every left R-module
is a right Rop-module.
Proof.
We will be ultra-fussy in this proof. To say that M is a right R-module is to say
that there is a function œÉ : M √ó R ‚ÜíM, denoted by œÉ(m,r) = mr. If ¬µ: R √ó R ‚ÜíR is
the given multiplication in R, then axiom (iii) in the deÔ¨Ånition of right R-module says
œÉ(m, ¬µ(r,r‚Ä≤)) = œÉ(œÉ(m,r),r‚Ä≤).
To obtain a left R-module, deÔ¨Åne œÉ ‚Ä≤ : R √ó M ‚ÜíM by œÉ ‚Ä≤(r, m) = œÉ(m,r). To see that M
is a left Rop-module, it is only a question of checking axiom (iii), which reads, in the fussy
notation,
œÉ ‚Ä≤(¬µop(r,r‚Ä≤), m) = œÉ ‚Ä≤(r, œÉ ‚Ä≤(r‚Ä≤, m)).
But
œÉ ‚Ä≤(¬µop(r,r‚Ä≤), m) = œÉ(m, ¬µop(r,r‚Ä≤)) = œÉ(m, ¬µ(r‚Ä≤,r)) = m(r‚Ä≤r),
while the right side is
œÉ ‚Ä≤(r, œÉ ‚Ä≤(r‚Ä≤, m)) = œÉ(œÉ ‚Ä≤(r‚Ä≤, m),r) = œÉ(œÉ(m,r‚Ä≤),r) = (mr‚Ä≤)r.
Thus, the two sides are equal because M is a right R-module.
The second half of the proposition now follows because a right Rop-module is a left
(Rop)op-module; that is, a left R-module.
‚Ä¢
It follows from Proposition 8.11 that any theorem about left modules is, in particular, a
theorem about left Rop-modules, and hence it is also a theorem about right R-modules.
Let us now see that opposite rings are more than an expository device; they do occur in
nature.
Proposition 8.12.
If a ring R is regarded as a left module over itself, then there is an
isomorphism of rings
EndR(R) ‚àº= Rop.
Proof.
DeÔ¨Åne œï : EndR(R) ‚ÜíRop by œï( f ) = f (1); it is routine to check that œï is
an isomorphism of additive abelian groups. Now œï( f )œï(g) = f (1)g(1). On the other
hand, œï( f g) = ( f ‚ó¶g)(1) = f (g(1)). But if we write r = g(1), then f (g(1)) = f (r) =
f (r ¬∑1) = r f (1), because f is an R-map, and so f (g(1)) = r f (1) = g(1) f (1). Therefore,
œï( f g) = œï(g)œï( f ).
We have shown that œï : EndR(R) ‚ÜíR is an additive bijection that reverses multiplica-
tion.
‚Ä¢

530
Algebras
Ch. 8
An anti-isomorphism œï : R ‚ÜíA, where R and A are rings, is an additive bijection
such that
œï(rs) = œï(s)œï(r).
It is easy to see that R and A are anti-isomorphic if and only if R ‚àº= Aop. For example,
conjugation in H is an anti-isomorphism. If k is a commutative ring, then transposition,
A ‚ÜíAt, is an anti-isomorphism Matn(k) ‚ÜíMatn(k), because (AB)t = Bt At; therefore,
Matn(k) ‚àº= [Matn(k)]op. However, when k is not commutative, the formula (AB)t = Bt At
no longer holds. For example,
a
b
c
d
 p
q
r
s
	t
=
ap + br
aq + bs
cp + dr
cq + ds
t
,
while
p
q
r
s
t a
b
c
d
t
=
p
r
q
s
 a
c
b
d

has pa + rb Ã∏= ap + br as its 1,1 entry.
Proposition 8.13.
If R is any ring, then
[Matn(R)]op ‚àº= Matn(Rop).
Proof.
We claim that transposition A ‚ÜíAt is an isomorphism of rings
[Matn(R)]op ‚ÜíMatn(Rop).
First, it follows from (At)t = A that A ‚ÜíAt is a bijection. Let us set notation. If M =
[mi j] is a matrix, its i j entry mi j may also be denoted by (M)i j. Denote the multiplication
in Rop by a ‚àób, where a ‚àób = ba, and denote the multiplication in [Matn(R)]op by A ‚àóB,
where (A ‚àóB)i j = (B A)i j = 
k bikakj ‚ààR. We must show that (A ‚àóB)t = At Bt in
Matn(Rop). In [Matn(R)]op, we have
(A ‚àóB)t
i j = (B A)t
i j
= (B A) ji
=

k
b jkaki.
In Matn(Rop), we have
(At Bt)i j =

k
(At)ik ‚àó(Bt)kj
=

k
(A)ki ‚àó(B) jk
=

k
aki ‚àób jk
=

k
b jkaki.
Therefore, (A ‚àóB)t = At Bt in Matn(Rop), as desired.
‚Ä¢

Sec. 8.1
Noncommutative Rings
531
Direct sums and direct products of R-modules, where R is any (not necessarily com-
mutative) ring, exist. An R-module is, after all, an additive abelian group equipped with
a scalar multiplication. If {Mi : i ‚ààI} is a family of left R-modules, construct the di-
rect product 
i‚ààI Mi as the direct product of the underlying abelian groups, and then
deÔ¨Åne scalar multiplication by r(mi) = (rmi) if all the Mi are left R-modules, or by
(mi)r = (mir) if all the Mi are right R-modules. As with modules over commutative
rings, deÔ¨Åne the direct sum 
i‚ààI Mi as the submodule of 
i Mi consisting of all I-tuples
almost all of whose coordinates are 0. There is no difÔ¨Åculty in adapting the deÔ¨Ånition and
Ô¨Årst properties of external and internal direct sums, such as Proposition 7.15 and Corol-
lary 7.16.
Since direct sums exist, we can also construct free left R-modules (as direct sums of
copies of R R) and free right R-modules (as direct sums of RR).
Exact sequences of left or of right modules also make sense (again, because modules
are additive abelian groups with extra structure), and the reader should have no difÔ¨Åculty
using them.
EXERCISES
8.1 Let R be an additive abelian group equipped with an associative multiplication that satisÔ¨Åes
both distributive laws. DeÔ¨Åne a multiplication on the abelian group R‚àó= Z ‚äïR by
(m,r)(n, s) = (mn, ms + nr + rs),
where ms is the sum of s with itself m times if m > 0, and ms is the sum of ‚àís with itself |m|
times if m < 0.
Prove that R‚àóis a ring with unit (1, 0), and that R is a two-sided ideal in R‚àó. (We say that
R‚àóis obtained from R by adjoining a unit.)
8.2 Let R be the set of all matrices of the form
 a
b
‚àíb
a

, where a and b are complex numbers
and a denotes the complex conjugate of a. Prove that R is a subring of Mat2(C) and that
R ‚àº= H, where H is the division ring of quaternions.
8.3 Prove that the following conditions on a ring R are equivalent:
(i) For every sequence of left ideals L1 ‚äáL2 ‚äáL3 ‚äá¬∑ ¬∑ ¬∑ , there exists N so that Li =
Li+1 for all i ‚â•N;
(ii) Every nonempty family F of left ideals has a minimal element in F.
8.4 (Change of Rings) Let œï : R ‚ÜíS be a ring homomorphism, and let M be a left S-module.
Show that the function R√óM ‚ÜíM, given by (r, m) ‚Üíœï(r)m, deÔ¨Ånes a scalar multiplication
that makes M a left R-module.
8.5 Let I be a two-sided ideal in a ring R. Prove that an abelian group M is a left (R/I)-module
if and only if it is a left R-module that is annihilated by I.
8.6 If M is a Ô¨Ånitely generated abelian group, prove that the additive group of the ring End(M) is
a Ô¨Ånitely generated abelian group.

532
Algebras
Ch. 8
Hint. There is a Ô¨Ånitely generated free abelian group F mapping onto M; apply Hom( , M)
to F ‚ÜíM ‚Üí0 to obtain an injection 0 ‚ÜíHom(M, M) ‚ÜíHom(F, M). But Hom(F, M)
is a Ô¨Ånite direct sum of copies of M.
8.7
(i) If k is a commutative ring and G is a cyclic group of Ô¨Ånite order n, prove that kG ‚àº=
k[x]/(xn ‚àí1).
(ii) If k is a domain, deÔ¨Åne the ring of Laurent polynomials as the subring of k(x) consisting
of all rational functions of the form f (x)/xn for n ‚ààZ. If G is inÔ¨Ånite cyclic, prove
that kG is isomorphic to Laurent polynomials.
8.8 Let R be a four-dimensional vector space over C with basis 1, i, j, k. DeÔ¨Åne a multiplication
on R so that these basis elements satisfy the same identities satisÔ¨Åed in the quaternions H [see
Example 8.1(vi)]. Prove that R is not a division ring.
8.9 If k is a ring, possibly noncommutative, prove that Matn(k) is a ring.
8.10 Prove that the center of a matrix ring Matn(R) is the set of all scalar matrices aI, where
a ‚ààZ(R) and I is the identity matrix.
8.11 Prove that Z(H) = {a1 : a ‚ààR}.
8.12 Let R = R1 √ó ¬∑ ¬∑ ¬∑ √ó Rm be a direct product of rings.
(i) Prove that Rop = Rop
1 √ó ¬∑ ¬∑ ¬∑ √ó Rop
m .
(ii) Prove that Z(R) = Z(R1) √ó ¬∑ ¬∑ ¬∑ √ó Z(Rm).
(iii) If k is a Ô¨Åeld and
R = Matn1(k) √ó ¬∑ ¬∑ ¬∑ √ó Matnm (k),
prove that dimk(Z(R)) = m.
8.13 If  is a division ring, prove that op is also a division ring.
8.14 An idempotent in a ring A is an element e ‚ààA with e2 = e. If R is a ring and M is a left
R-module, prove that every direct summand S ‚äÜM determines an idempotent in EndR(M).
Hint. See Corollary 7.17.
8.15 Let R be a ring.
(i) (Peirce Decomposition). Prove that if e is an idempotent in a ring R, then
R = Re ‚äïR(1 ‚àíe).
(ii) Let R be a ring having left ideals I and J such that R = I ‚äïJ. Prove that there are
idempotents e ‚ààI and f ‚ààJ with 1 = e + f ; moreover, I = Ie and J = J f .
Hint. Decompose 1 = e + f , and show that ef = 0 = f e.
8.16 An element a in a ring R has a left inverse if there is u ‚ààR with ua = 1, and it has a right
inverse if there is w ‚ààR with aw = 1.
(i) Prove that if a ‚ààR has both a left inverse u and a right inverse w, then u = w.
(ii) Give an example of a ring R in which an element a has two distinct left inverses.
Hint.
DeÔ¨Åne R = Endk(V ), where V is a vector space over a Ô¨Åeld k with basis
{bn : n ‚â•1}, and deÔ¨Åne a ‚ààR by a(bn) = bn+1 for all n ‚â•1.
(iii) (Kaplansky) Let R be a ring, and let a, u, v ‚ààR satisfy ua = 1 = va. If u Ã∏= v, prove
that a has inÔ¨Ånitely many left inverses.
Hint. Are the elements u + an(1 ‚àíau) distinct?

Sec. 8.2
Chain Conditions
533
8.17 Let k be a Ô¨Åeld, let G be a Ô¨Ånite group, and let F(G, k) denote the vector space of all functions
G ‚Üík.
(i) DeÔ¨Åne œï : kG ‚ÜíF(G, k) as follows: If u = 
x ax x ‚ààkG, then œïu : x ‚Üíax. Prove
that
œïu+v = œïu + œïv
and
œïuv(y) =

x‚ààG
œïu(x)œïv(x‚àí1y).
(This last operation is called the convolution of œïu and œïv.)
(ii) Prove that F(G, k) is a ring and that : kG ‚ÜíF(G, k), given by u ‚Üíœïu, is a ring
isomorphism.
8.18
(i) For k a Ô¨Åeld and G a Ô¨Ånite group, prove that (kG)op ‚àº= kG.
(ii) Prove that Hop ‚àº= H, where H is the division ring of real quaternions.
Exercise 8.30 on page 549 asks for a ring R that is not isomorphic to Rop.
8.19
(i) If R is a ring, if r ‚ààR, and if k ‚äÜZ(R) is a subring, prove that the subring generated
by r and k is commutative.
(ii) If  is a division ring, if r ‚ààR, and if k ‚äÜZ() is a subring, prove that the subdivision
ring generated by r and k is a (commutative) Ô¨Åeld.
8.20 Write the elements of the group Q of quaternions as
1, 1, i, i, j, j, k, k,
and deÔ¨Åne a linear transformation œï : RQ ‚ÜíH by removing the bars:
œï(x) = œï(x) = x
for x = 1, i, j, k.
Prove that œï is a surjective ring map, and conclude that there is an isomorphism of rings
RQ/ ker œï ‚àº= H. (See Example 9.113 for a less computational proof.)
8.21 If R is a ring in which x2 = x for every x ‚ààR, prove that R is commutative. (A Boolean ring
is an example of such a ring.)
8.22 Prove that there is an equivalence of categories RMod ‚ÜíModRop.
Hint. Given a left R-module (M, œÉ), where M is an additive abelian group and œÉ : R√ó M ‚Üí
M is its scalar multiplication, consider the right Rop-module (M, œÉ ‚Ä≤), where œÉ ‚Ä≤ : M √ó Rop ‚Üí
M is deÔ¨Åned in Proposition 8.11. DeÔ¨Åne F : RMod ‚ÜíModRop on objects by (M, œÉ) ‚Üí
(M, œÉ ‚Ä≤).
8.2 CHAIN CONDITIONS
This section introduces chain conditions for modules over an arbitrary ring, as well as the
Jacobson radical, J(R), a two-sided ideal whose behavior has an impact on a ring R. For
example, semisimple rings R are rings that generalize the group ring CG of a Ô¨Ånite group
G, and we will characterize them in the next section in terms of J(R) and chain conditions.

534
Algebras
Ch. 8
We will also prove a theorem of Wedderburn that says that every Ô¨Ånite division ring is a
Ô¨Åeld; that is, it is commutative.
We have already proved the Jordan-H¬®older theorem for groups (see Theorem 5.52).
Here is the version of this theorem for modules. We can prove both of these versions
simultaneously if we introduce the notion of operator groups (see Robinson, A Course in
the Theory of Groups, page 65).
Theorem 8.14 (Zassenhaus Lemma).
Given submodules A ‚äÜA‚àóand B ‚äÜB‚àóof a
module M (over any ring), there is an isomorphism
A + (A‚àó‚à©B‚àó)
A + (A‚àó‚à©B)
‚àº= B + (B‚àó‚à©A‚àó)
B + (B‚àó‚à©A) .
Proof.
A straightforward adaptation of the proof of Lemma 5.49.
‚Ä¢
DeÔ¨Ånition.
A series (or a Ô¨Åltration) of a module M (over any ring) is a Ô¨Ånite sequence
of submodules M = M0, M1, M2, . . . , Mn = {0} for which
M = M0 ‚äáM1 ‚äáM2 ‚äá¬∑ ¬∑ ¬∑ ‚äáMn = {0}.
The factor modules of this series are the modules M0/M1, M1/M2, . . ., Mn‚àí1/Mn =
Mn‚àí1, and the length is the number of strict inclusions; equivalently, the length is the
number of nonzero factor modules.
A reÔ¨Ånement of a series is a series M = M‚Ä≤
0, M‚Ä≤
1, . . . , M‚Ä≤
k = {0} having the original
series as a subsequence. Two series of a module M are equivalent if there is a bijection
between the sets of nonzero factor modules of each so that corresponding factor modules
are isomorphic.
Theorem 8.15 (Schreier ReÔ¨Ånement Theorem).
Any two series
M = M0 ‚äáM1 ‚äá¬∑ ¬∑ ¬∑ ‚äáMn = {0}
and
M = N0 ‚äáN1 ‚äá¬∑ ¬∑ ¬∑ ‚äáNk = {0}
of a module M have equivalent reÔ¨Ånements.
Proof.
A straightforward adaptation of the proof of Theorem 5.51.
‚Ä¢
DeÔ¨Ånition.
A left R-module is simple (or irreducible) if M Ã∏= {0} and M has no proper
submodules.
As with modules over a commutative ring, the correspondence theorem shows that an
R-submodule N of a module M is a maximal submodule if and only if M/N is a simple
module. The proof of Corollary 7.14 can be adapted to show that a left R-module S is
simple if and only if S ‚àº= R/I, where I is a maximal left ideal.

Sec. 8.2
Chain Conditions
535
DeÔ¨Ånition.
A composition series is a series all of whose nonzero factor modules are
simple.
Notice that a composition series admits only insigniÔ¨Åcant reÔ¨Ånements; we can merely
repeat terms (if Mi/Mi+1 is simple, then it has no proper nonzero submodules and, hence,
there is no intermediate submodule L with Mi ‚äãL ‚äãMi+1). More precisely, any reÔ¨Åne-
ment of a composition series is equivalent to the original composition series.
A module need not have a composition series; for example, the abelian group Z, con-
sidered as a Z-module, has no composition series.
DeÔ¨Ånition.
A left R-module M, over any ring R, has the ascending chain condition,
abbreviated ACC, if every ascending chain of left submodules stops: If
S1 ‚äÜS2 ‚äÜS3 ‚äÜ¬∑ ¬∑ ¬∑
is a chain of submodules, then there is some t ‚â•1 with
St = St+1 = St+2 = ¬∑ ¬∑ ¬∑ .
A left R-module M, over any ring R, has the descending chain condition, abbreviated
DCC, if every descending chain of left submodules stops: If
S1 ‚äáS2 ‚äáS3 ‚äá¬∑ ¬∑ ¬∑
is a chain of submodules, then there is some t ‚â•1 with
St = St+1 = St+2 = ¬∑ ¬∑ ¬∑ .
Most of the theorems proved in Chapter 6 for commutative noetherian rings (for ex-
ample, Proposition 6.38: The equivalence of the ACC, the maximum condition, and Ô¨Ånite
generation of ideals) can be generalized, and with the same proofs, to left modules having
the ACC.
Proposition 8.16.
(i) If a left module M has DCC, then every nonempty family F of submodules contains
a minimal element; that is, there is a submodule S0 ‚ààF for which there is no S ‚ààF
with S ‚ääS0.
(ii) If a left module M has ACC, then every nonempty family F of submodules contains
a maximal element; that is, there is a submodule S0 ‚ààF for which there is no S ‚ààF
with S ‚äãS0.
Proof.
Choose S ‚ààF. If S is a minimal element of F, we are done. Otherwise, there is a
submodule S1 ‚ààF with S ‚äãS1. If S1 is a minimal element, we are done; otherwise, there
is a submodule S2 ‚ààF with S ‚äãS1 ‚äãS2. The DCC says that this sequence must stop;
that is, there is St ‚ààF that is a minimal element of F (for the only obstruction to Ô¨Ånding a
smaller submodule is that St is minimal). The proof of the second statement is similar.
‚Ä¢

536
Algebras
Ch. 8
Proposition 8.17.
A module M over any ring R has a composition series if and only if it
has both chain conditions on submodules.
Proof.
If M has a composition series of length n, then no sequence of submodules can
have length > n, or we would violate Schreier's theorem (reÔ¨Åning a series cannot shorten
it). Therefore, M has both chain conditions.
Let F1 be the family of all the proper submodules of M. By Proposition 8.16, the
maximum condition gives a maximal submodule M1 ‚ààF1. Let F2 be the family of all
proper submodules of M1, and let M2 be maximal such. Iterating, we have a descending
sequence
M ‚äãM1 ‚äãM2 ‚äã¬∑ ¬∑ ¬∑ .
If Mn occurs in this sequence, the only obstruction to constructing Mn+1 is if Mn = 0.
Since M has both chain conditions, this chain must stop, and so Mt = 0 for some t. This
chain is a composition series of M, for each Mi is a maximal submodule of its predeces-
sor.
‚Ä¢
Theorem 8.18 (Jordan-H¬®older Theorem).
Any two composition series of a module
M are equivalent. In particular, the length of a composition series, if one exists, is an
invariant of M, called the length of M.
Proof.
As we remarked earlier, any reÔ¨Ånement of a composition series is equivalent to
the original composition series. It now follows from Schreier's theorem that any two com-
position series are equivalent; in particular, they have the same length.
‚Ä¢
Let V be a vector space over a Ô¨Åeld k; if V has dimension n, then V has length n, for if
v1, . . . , vn is a basis of V , then a composition series is
V = ‚ü®v1, . . . , vn‚ü©‚äã‚ü®v2, . . . , vn‚ü©‚äã¬∑ ¬∑ ¬∑ ‚äã‚ü®vn‚ü©‚äã{0}
(the factor modules are one-dimensional, and hence are simple k-modules).
Corollary 8.19.
If a module M has length n, then every chain of submodules of M has
length ‚â§n.
Proof.
By Schreier's theorem, there is a reÔ¨Ånement of the given chain that is a composi-
tion series, and so the length of the given chain is at most n.
‚Ä¢
The Jordan-H¬®older theorem can be regarded as a kind of unique factorization theorem;
for example, we saw in Corollary 5.53 that it gives a new proof of the fundamental theorem
of arithmetic.
If  is a division ring, then a left -module V is called a left vector space over . The
following deÔ¨Ånition from linear algebra still makes sense here.
DeÔ¨Ånition.
If V is a left vector space over a division ring , then a list X = x1, . . . , xm
in V is linearly dependent if
xi ‚àà‚ü®x1, . . . ,xi, . . . , xm‚ü©
for some i; otherwise, X is called linearly independent.

Sec. 8.2
Chain Conditions
537
The reader should check that if x1, . . . , xm is linearly independent, then
‚ü®x1, . . . , xm‚ü©= ‚ü®x1‚ü©‚äï¬∑ ¬∑ ¬∑ ‚äï‚ü®xm‚ü©.
Proposition 8.20.
Every Ô¨Ånitely generated left vector space V = ‚ü®v1, . . . , vn‚ü©over a
division ring  is a direct sum of copies of ; that is, every Ô¨Ånitely generated left vector
space over a division ring has a basis.
Proof.
Consider the series
V = ‚ü®v1, . . . , vn‚ü©‚äá‚ü®v2, . . . , vn‚ü©‚äá‚ü®v3, . . . , vn‚ü©‚äá¬∑ ¬∑ ¬∑ ‚äá‚ü®vn‚ü©‚äá{0}.
Denote ‚ü®vi+1, . . . , vn‚ü©by Ui, so that ‚ü®vi, . . . , vn‚ü©= ‚ü®vi‚ü©+Ui. By the second isomorphism
theorem,
‚ü®vi . . . , vn‚ü©/‚ü®vi+1 . . . , vn‚ü©= (‚ü®vi‚ü©+ Ui)/Ui ‚àº= ‚ü®vi‚ü©/(‚ü®vi‚ü©‚à©Ui).
Therefore, the ith factor module is isomorphic to a quotient of ‚ü®vi‚ü©‚àº=  if vi Ã∏= 0. Since
 is a division ring, its only quotients are  and {0}. After throwing away those vi cor-
responding to trivial factor modules {0}, we claim that the remaining v's, denote them by
v1, . . . , vm, form a basis. For all j, we have v j /‚àà‚ü®v j+1, . . . , vn‚ü©. The reader may now
show, by induction on m, that ‚ü®v1‚ü©, . . . , ‚ü®vm‚ü©generate a direct sum.
‚Ä¢
Another proof of this proposition, using dependency relations, is sketched in Exer-
cise 8.23(ii) on page 548.
The next question is whether any two bases of V have the same number of elements.
The proper attitude is that theorems about vector spaces over Ô¨Åelds have true analogs for
left vector spaces over division rings, but the reader should not merely accept the word of
a gentleman and a scholar that this is so.
Corollary 8.21.
If V is a Ô¨Ånitely generated left vector space over a division ring , then
any two bases of V have the same number of elements.
Proof.
As in the proof of Proposition 8.20, a basis of V gives a series
V = ‚ü®v1, v2, . . . , vn‚ü©‚äã‚ü®v2, . . . , vn‚ü©‚äã‚ü®v3, . . . , vn‚ü©‚äã¬∑ ¬∑ ¬∑ ‚äã‚ü®vn‚ü©‚äã{0}.
This is a composition series, for every factor module is isomorphic to , which is simple
because  is a division ring. By the Jordan-H¬®older theorem, the composition series arising
from any other basis of V must have the same length.
‚Ä¢
Another proof of this corollary is sketched in Exercise 8.23(iii) on page 548.
It now follows that every Ô¨Ånitely generated left vector space V over a division ring 
has a left dimension, which will be denoted by dim(V ).
If an abelian group V is a left vector space and a right vector space over a division ring
, must its left dimension equal its right dimension? There is an example (see Jacobson,
Structure of Rings, page 158) of a division ring  and an abelian group V , which is a
vector space over  on both sides, with left dimension 2 and right dimension 3.

538
Algebras
Ch. 8
We have just seen that dimension is well-deÔ¨Åned for left vector spaces over division
rings. Is the rank of a free left R-module F well-deÔ¨Åned for every ring R; that is, do any
two bases of F have the same number of elements? In Proposition 7.50, we saw that rank
is well-deÔ¨Åned when R is commutative, and it can be shown that rank is well-deÔ¨Åned when
R is left noetherian; that is, if every left ideal in R is Ô¨Ånitely generated (see Rotman, An
Introduction to Homological Algebra, page 111). However, the next example shows that
rank is not always well-deÔ¨Åned.
Example 8.22.
Let k be a Ô¨Åeld, let V be a vector space over k having an inÔ¨Ånite basis {vn : n ‚ààN},
and let R = Endk(V ). Let A be the left ideal consisting of all the linear transformations
œï : V ‚ÜíV for which œï(v2n) = 0 for all n, and let B be the left ideal consisting of all
those linear transformations œà : V ‚ÜíV for which œà(v2n+1) = 0 for all n. We let the
reader check that A ‚à©B = {0} and A + B = R, so that R = A ‚äïB.
Let W be the subspace of V with basis the odd v2n+1. If f : V ‚ÜíW is a k-isomorphism,
then the map œà ‚Üíf œà f ‚àí1 is an R-isomorphism
R = Endk(V ) ‚àº= Endk(W) = A.
Similarly, if Y is the subspace of V spanned by the even v2n, then R ‚àº= Endk(Y) = B. It
follows that the free left R-modules R and R ‚äïR are isomorphic.
‚óÄ
There is another useful unique factorization theorem. Call a left R-module M, over any
ring R, an indecomposable module if there do not exist nonzero submodules A and B with
M = A ‚äïB. The Krull-Schmidt theorem says that if M has both chain conditions on
submodules, then M is a direct sum of indecomposable modules: M = A1 ‚äï¬∑ ¬∑ ¬∑ ‚äïAn.
Moreover, if M = B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBm is another decomposition into indecomposables, then
m = n and there is a permution œÉ ‚ààSn with Ai ‚àº= BœÉ(i) for all i. A proof can be found in
Rotman, An Introduction to the Theory of Groups, pages 144-150.
Here is a surprising result of J. M. Wedderburn.
Theorem 8.23 (Wedderburn).
Every Ô¨Ånite division ring D is a Ô¨Åeld; that is, multipli-
cation in D is commutative.
Proof. (E. Witt2). If Z denotes the center of D, then Z is a Ô¨Ånite Ô¨Åeld, and so it has q
elements (where q is a power of some prime). It follows that D is a vector space over Z,
and so |D| = qn for some n ‚â•1; that is, if we deÔ¨Åne
[D : Z] = dimZ(D),
then [D : Z] = n. The proof will be complete if we can show that n > 1 leads to a
contradiction.
If a ‚ààD, deÔ¨Åne C(a) = {u ‚ààD : ua = au}. It is routine to check that C(a) is a
subdivision ring of D that contains Z: If u, v ‚ààD commute with a, then so do u + v, uv,
2We shall give another proof of this in Theorem 9.123.

Sec. 8.2
Chain Conditions
539
and u‚àí1 (when u Ã∏= 0). Consequently, |C(a)| = qd(a) for some integer d(a); that is,
[C(a) : Z] = d(a). We do not know whether C(a) is commutative, but Exercise 8.25 on
page 548 gives
[D : Z] = [D : C(a)][C(a) : Z],
where [D : C(a)] denotes the dimension of D as a left vector space over C(a). That is,
n = [D : C(a)]d(a), and so d(a) is a divisor of n.
Since D is a division ring, its nonzero elements D√ó form a multiplicative group of order
qn ‚àí1. By Example 8.2(ii), the center of the group D√ó is Z√ó and, if a ‚ààD√ó, then its
centralizer CD√ó(a) = C(a)√ó. Hence, |Z(D√ó)| = q ‚àí1 and |CD√ó(a)| = qd(a) ‚àí1, where
d(a) | n.
The class equation for D√ó is
|D√ó| = |Z√ó| +

i
[D√ó : CD√ó(ai)],
where one ai is chosen from each noncentral conjugacy class. But
[D√ó : CD√ó(ai)] = |D√ó|/|CD√ó(ai)| = (qn ‚àí1)/(qd(ai) ‚àí1),
so that the class equation becomes
qn ‚àí1 = q ‚àí1 +

i
qn ‚àí1
qd(ai) ‚àí1.
(1)
We have already noted that each d(ai) is a divisor of n, while the condition that ai is not
central says that d(ai) < n.
Recall that the nth cyclotomic polynomial is n(x) = (x ‚àíŒ∂), where Œ∂ ranges over
all the primitive nth roots of unity. In Corollary 1.41, we proved that n(q) is a common
divisor of qn ‚àí1 and (qn ‚àí1)/(qd(ai) ‚àí1) for all i, and so Eq. (1) gives
n(q) | (q ‚àí1).
If n > 1 and Œ∂ is a primitive nth root of unity, then Œ∂ Ã∏= 1, and hence Œ∂ is some other point
on the unit circle. Since q is a prime power, it is a point on the x-axis with q ‚â•2, and so
the distance |q ‚àíŒ∂| > q ‚àí1. Therefore,
|n(q)| =

|q ‚àíŒ∂| > q ‚àí1,
and this contradicts n(q) | (q ‚àí1). We conclude that n = 1; that is, D = Z, and so D is
commutative.
‚Ä¢
The next discussion will be used in the next section to prove the Wedderburn-Artin
theorems classifying semisimple rings. Let us consider HomR(A, B), where both A and B
are left R-modules that are Ô¨Ånite direct sums: say, A = n
i=1 Ai and B = m
j=1 B j. By
Theorems 7.32 and 7.33, we have
HomR(A, B) ‚àº=

i j
HomR(Ai, B j).

540
Algebras
Ch. 8
More precisely, if Œ±i : Ai ‚ÜíA is the ith injection and p j : B ‚ÜíB j is the jth projection,
then each f ‚ààHomR(A, B) gives maps fi j = p j f Œ±i ‚ààHomR(Ai, B j). Thus, f deÔ¨Ånes
a generalized n √ó m matrix [ fi j] (we call [ fi j] a generalized matrix because entries in
different positions need not lie in the same algebraic system). The map f ‚Üí[ fi j] is an
isomorphism HomR(A, B) ‚Üí
i j HomR(Ai, B j). Similarly, if g : B ‚ÜíC, where C =
‚Ñì
k=1 Ck, then g deÔ¨Ånes a generalized m √ó‚Ñìmatrix [g jk], where g jk = qkgŒ≤ j : B j ‚ÜíCk,
Œ≤ j : B j ‚ÜíB are the injections, and qk : C ‚ÜíCk are the projections.
The composite g f : A ‚ÜíC deÔ¨Ånes a generalized n √ó ‚Ñìmatrix, and we claim that it is
given by matrix multiplication (g f )ik = 
j gkj f ji:

j
gkj f ji =

j
qkgŒ≤ j p j f Œ±i
= qkg(

j
Œ≤ j p j) f Œ±i
= qkg f Œ±i
= (g f )ik,
because 
j Œ≤ j p j = 1B.
By adding some hypotheses, we can pass from generalized matrices to honest matrices.
Proposition 8.24.
Let V = n
i=1 Vi be a left R-module. If there is a left R-module L
and, for each i, an isomorphism œïi : Vi ‚ÜíL, then there is a ring isomorphism
EndR(V ) ‚àº= Matn(EndR(L)).
Proof.
DeÔ¨Åne
Œ∏ : EndR(V ) ‚ÜíMatn(EndR(L))
by
Œ∏ : f ‚Üí[œï j p j f Œ±iœï‚àí1
i
],
where Œ±i : Vi ‚ÜíV and p j : V ‚ÜíVj are injections and projections, respectively. That Œ∏
is an additive isomorphism is just the identity
Hom

i
Vi,

i
Vi

‚àº=

i j
Hom(Vi, Vj),
which holds when the index sets are Ô¨Ånite. In the paragraph discussing generalized ma-
trices, the home of the i j entries was HomR(Vi, Vj), whereas the present home of these
entries is the isomorphic replica HomR(L, L) = EndR(L).
We now show that Œ∏ preserves multiplication. If g, f ‚ààEndR(V ), then Œ∏(g f ) =

Sec. 8.2
Chain Conditions
541
[œï j p jg f Œ±iœï‚àí1
i
], while the matrix product is
Œ∏(g)Œ∏( f ) =

k
(œï j p jgŒ±kœï‚àí1
k )(œïk pk f Œ±iœï‚àí1
i
)

=

k
œï j p jgŒ±k pk f Œ±iœï‚àí1
i

=

œï j p jg

k
Œ±k pk

f Œ±iœï‚àí1
i

=

œï j p jg f Œ±iœï‚àí1
i

.
‚Ä¢
Corollary 8.25.
If V is an n-dimensional left vector space over a division ring , then
there is an isomorphism of rings
End(V ) ‚àº= Matn()op.
Proof.
The isomorphism Endk(V ) ‚àº= Matn(op) is the special case of Proposition 8.24
for V = V1 ‚äï¬∑ ¬∑ ¬∑ ‚äïVn, where each Vi is one-dimensional, and hence is isomorphic to .
Note that End() ‚àº= op, by Proposition 8.12. Now apply Proposition 8.13, which says
that Matn(op) ‚àº= Matn()op.
‚Ä¢
The next result involves a direct sum decomposition at the opposite extreme of that in
Proposition 8.24.
Corollary 8.26.
Let an R-module M be a direct sum M = B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBm in which
HomR(Bi, B j) = {0} for all i Ã∏= j. Then there is a ring isomorphism
EndR(M) ‚àº= EndR(B1) √ó ¬∑ ¬∑ ¬∑ √ó EndR(Bm).
Proof.
If f, g ‚ààEndR(M), let [ fi j] and [gi j] be their generalized matrices. It sufÔ¨Åces to
show that [gi j][ fi j] is the diagonal matrix
diag(g11 f11, . . . , gmm fmm).
But if i Ã∏= j, then gik fkj ‚ààHomR(Bi, B j) = 0; hence, (g f )i j = 
k gik fkj = 0.
‚Ä¢
DeÔ¨Ånition.
If k is a commutative ring, then a ring R is a k-algebra if R is a
k-module and scalars in k commute with everything:
a(rs) = (ar)s = r(as)
for all a ‚ààk and r, s ‚ààR.
If R and S are k-algebras, then a ring homomorphism f : R ‚ÜíS is called a k-algebra
map if
f (ar) = af (r)
for all a ‚ààk and r ‚ààR; that is, f is also a map of k-modules.

542
Algebras
Ch. 8
The reason that k is assumed to be commutative (in the deÔ¨Ånition of k-algebra) can be
seen in the important special case when k is a subring of R; setting s = 1 and taking r ‚ààk
gives ar = ra.
Example 8.27.
(i) If A = C[x], then A is a C-algebra, and œï : A ‚ÜíA, deÔ¨Åned by œï : 
j c j x j ‚Üí

j c j(x ‚àí1) j is a C-algebra map. On the other hand, the function Œ∏ : A ‚ÜíA, deÔ¨Åned by
Œ∏ : 
j c j x j ‚Üí
j c j(x ‚àí1) j (where c is the complex conjugate of c), is a ring map but
it is not a C-algebra map. For example, Œ∏(ix) = ‚àíi(x ‚àí1) while iŒ∏(x) = i(x ‚àí1). Now
C[x] is also an R-algebra, and Œ∏ is an R-algebra map.
(ii) Every ring R is a Z-algebra, and every ring homomorphism is a Z-algebra map. This
example shows why, in the deÔ¨Ånition of R-algebra, we do not demand that k be isomorphic
to a subring of R.
(iii) If k is a subring contained in the center of R, then R is a k-algebra.
(iv) If k is a commutative ring, then Matn(k) is a k-algebra.
(v) If k is a commutative ring and G is a group, then the group algebra kG is a
k-algebra.
‚óÄ
We have already deÔ¨Åned the ACC for left modules over any ring. The next deÔ¨Ånition
says that a ring R is left noetherian if it has the ACC when viewed as a left module over
itself (recall that its submodules are the left ideals). When R is commutative, this deÔ¨Ånition
specializes to our earlier deÔ¨Ånition of noetherian ring.
DeÔ¨Ånition.
A ring R is left noetherian if it has the ACC (ascending chain condition)
on left ideals: every ascending chain of left ideals
I1 ‚äÜI2 ‚äÜI3 ‚äÜ¬∑ ¬∑ ¬∑
stops; that is, there is some t ‚â•1 with
It = It+1 = It+2 = ¬∑ ¬∑ ¬∑ .
We deÔ¨Åne right noetherian rings similarly as those rings having the ACC on right ide-
als. If k is a Ô¨Åeld, then every Ô¨Ånite-dimensional k-algebra A is both left and right noethe-
rian, for if dim(A) = n, then there are at most n strict inclusions in any ascending chain
of left ideals or of right ideals. In particular, if G is a Ô¨Ånite group, then kG is Ô¨Ånite-
dimensional, and so it is left and right noetherian. Exercise 8.28 on page 549 gives an
example of a left noetherian ring that is not right noetherian.
Proposition 8.28.
The following conditions on a ring R are equivalent.
(i) R is left noetherian.
(ii) Every nonempty family of left ideals of R contains a maximal element.
(iii) Every left ideal is Ô¨Ånitely generated.

Sec. 8.2
Chain Conditions
543
Proof.
Adapt the proof of Proposition 6.38.
‚Ä¢
DeÔ¨Ånition.
A ring R is left artinian if it has the DCC (descending chain condition):
Every descending chain of left ideals
I1 ‚äáI2 ‚äáI3 ‚äá¬∑ ¬∑ ¬∑
stops; that is, there is some t ‚â•1 with
It = It+1 = It+2 = ¬∑ ¬∑ ¬∑ .
We deÔ¨Åne right artinian rings similarly, and there are examples of left artinian rings that
are not right artinian (see Exercise 8.29 on page 549). If k is a Ô¨Åeld, then every Ô¨Ånite-
dimensional k-algebra A is both left and right artinian, for if dim(A) = n, then there are
at most n strict inclusions in any descending chain of left ideals or of right ideals. In
particular, if G is a Ô¨Ånite group, then kG is Ô¨Ånite-dimensional, and so it is left and right
artinian. We conclude that kG has both chain conditions (on both sides) when k is a Ô¨Åeld
and G is a Ô¨Ånite group.
The ring Z is (left) noetherian, but it is not (left) artinian, because the chain
Z ‚äá(2) ‚äá(22) ‚äá(23) ‚äá¬∑ ¬∑ ¬∑
does not stop. In the next section, we will prove that left artinian implies left noetherian.
DeÔ¨Ånition.
A left ideal L in a ring R is a minimal left ideal if L Ã∏= {0} and there is no
left ideal J with {0} ‚ääJ ‚ääL.
A ring need not contain a minimal left ideal. For example, Z has no minimal ideals:
every nonzero ideal I in Z has the form I = (n) for some nonzero integer n, and I =
(n) ‚äã(2n).
Proposition 8.29.
(i) Every minimal left ideal L in a ring R is a simple left R-module.
(ii) If R is left artinian, then every nonzero left ideal I contains a minimal left ideal.
Proof.
(i) If L contained a submodule S with {0} ‚ääS ‚ääL, then S would be a left ideal
of R, contradicting the minimality of L.
(ii) If F is the family of all nonzero left ideals contained in I, then F Ã∏= ‚àÖbecause I is
nonzero. By Proposition 8.16, F has a minimal element, and any such is a minimal left
ideal.
‚Ä¢
We now deÔ¨Åne a special ideal, introduced by N. Jacobson, that is the analog of the
Frattini subgroup in group theory.

544
Algebras
Ch. 8
DeÔ¨Ånition.
If R is a ring, then its Jacobson radical J(R) is deÔ¨Åned to be the intersection
of all the maximal left ideals in R. A ring R is called Jacobson semisimple if J(R) = {0}.
Clearly, we can deÔ¨Åne another Jacobson radical: the intersection of all the maximal
right ideals. It turns out, however, that both of these coincide (see Proposition 8.36).
The ring Z is Jacobson semisimple. The maximal ideals in Z are the nonzero prime
ideals (p), and so J(Z) = 
p prime(p) = {0}. If R is a local ring (a commutative ring
having a unique maximal ideal P), then J(R) = P. An example of a local ring is R =
{a/b ‚ààQ : b is odd}; its unique maximal ideal is
(2) = {2a/b : b is odd}.
Example 8.30.
Let k be a Ô¨Åeld and let R = Matn(k). For any ‚Ñìbetween 1 and n, let COL(‚Ñì) denote the ‚Ñìth
columns; that is,
COL(‚Ñì) =

A = [ai j] ‚ààMatn(k) : ai j = 0 for all j Ã∏= ‚Ñì

.
It is easy to see that COL(‚Ñì) = RE‚Ñì‚Ñì, where E‚Ñì‚Ñìis the matrix having 1 as its ‚Ñì‚Ñìentry and
0s everywhere else. We claim that COL(‚Ñì) is a minimal left ideal in R. If we deÔ¨Åne
COL‚àó(‚Ñì) =

iÃ∏=‚Ñì
COL(i),
then COL‚àó(‚Ñì) is a left ideal with
R/COL‚àó(‚Ñì) ‚àº= COL(‚Ñì)
as left R-modules. Since COL(‚Ñì) is a minimal left ideal, it is a simple left R-module, and
hence COL‚àó(‚Ñì) is a maximal left ideal. Therefore,
J(R) ‚äÜ
"
‚Ñì
COL‚àó(‚Ñì) = {0},
so that R = Matn(k) is Jacobson semisimple.
‚óÄ
Proposition 8.31.
Given a ring R, the following conditions are equivalent for x ‚ààR:
(i) x ‚ààJ(R);
(ii) for every r ‚ààR, the element 1 ‚àírx has a left inverse; that is, there is u ‚ààR with
u(1 ‚àírx) = 1;
(iii) x(R/I) = {0} for every maximal left ideal I (equivalently, x M = {0} for every
simple left R-module M).

Sec. 8.2
Chain Conditions
545
Proof.
(i) ‚áí(ii) If there is r ‚ààR with 1 ‚àírx not having a left inverse, then R(1 ‚àírx)
is a proper left ideal, for it does not contain 1. Hence, there is a maximal left ideal I with
1 ‚àírx ‚ààR(1 ‚àírx) ‚äÜI, for the proof of Theorem 6.46 (Every proper ideal is contained
in some maximal ideal) does not use commutativity. Now rx ‚ààJ(R) ‚äÜI, because J(R)
is a left ideal, and so 1 = (1 ‚àírx) + rx ‚ààI, a contradiction.
(ii) ‚áí(iii) As we mentioned when simple left R-modules were deÔ¨Åned earlier in this
chapter, a left R-module M is simple if and only if M ‚àº= R/I, where I is a maximal left
ideal.
Suppose there is a simple module M for which x M Ã∏= {0}; hence, there is m ‚ààM with
xm Ã∏= 0 (of course, m Ã∏= 0). It follows that the submodule Rxm Ã∏= {0}, for it contains
1xm. Since M is simple, it has only one nonzero submodule, namely, M itself, and so
Rxm = M. Therefore, there is r ‚ààR with rxm = m; that is, (1 ‚àírx)m = 0. By
hypothesis, 1 ‚àírx has a left inverse, say, u(1 ‚àírx) = 1. Hence, 0 = u(1 ‚àírx)m = m, a
contradiction.
(iii) ‚áí(i) If x(R/I) = {0}, then x(1 + I) = x + I = I; that is, x ‚ààI. Therefore, if
x(R/I) = {0} for every maximal left ideal I, then x ‚àà
I I = J(R).
‚Ä¢
Notice that condition (ii) in Proposition 8.31 can be restated: x ‚ààJ(R) if and only if
1 ‚àíz has a left inverse for every z ‚ààRx.
The following result is frequently used in commutative algebra.
Corollary 8.32 (Nakayama's Lemma).
If M is a Ô¨Ånitely generated left R-module, and
if J M = M, where J = J(R) is the Jacobson radical, then M = {0}.
In particular, if R is a local ring, that is, R is a commutative ring with unique maximal
ideal P, and if M is a Ô¨Ånitely generated R-module with PM = M, then M = {0}.
Proof.
Let m1, . . . , mn be a generating set of M that is minimal in the sense that no
proper subset generates M. Since J M = M, we have m1 = n
i=1 rimi, where ri ‚ààJ. It
follows that
(1 ‚àír1)m1 =
n

i=2
rimi.
Since r1 ‚ààJ, Proposition 8.31 says that 1 ‚àír1 has a left inverse, say, u, and so m1 =
n
i=2 urimi. This is a contradiction, for now M can be generated by the proper subset
{m2, . . . , mn}.
The second statement follows at once because J(R) = P when R is a local ring with
maximal ideal P.
‚Ä¢
Remark.
The hypothesis in Nakayama's lemma that the module M be Ô¨Ånitely generated
is necessary. For example, it is easy to check that R = {a/b ‚ààQ : b is odd} is a local ring
with maximal ideal P = (2), while Q is an R-module with PQ = 2Q = Q.
‚óÄ

546
Algebras
Ch. 8
Remark.
There are other characterizations of J(R). One such will be given in Proposi-
tion 8.36, in terms of units in R (elements having two-sided inverses). Another character-
ization is in terms of left quasi-regular elements: An element x ‚ààR is left quasi-regular
if there is y ‚ààR with y ‚ó¶x = 0 (here, y ‚ó¶x = x + y ‚àíyx is the circle operation), and
a left ideal is called left quasi-regular if each of its elements is left quasi-regular. It can
be proved that J(R) is the unique maximal left quasi-regular ideal in R (see Lam, A First
Course in Noncommutative Rings, pages 67-68).
‚óÄ
The next property of an ideal is related to the Jacobson radical.
DeÔ¨Ånition.
A left ideal A in a ring R is nilpotent if there is some integer m ‚â•1 with
Am = {0}.
Recall that Am is the set of all sums of the form a1 ¬∑ ¬∑ ¬∑ am, where a j ‚ààA for all j; that
is, Am = {
i ai1 ¬∑ ¬∑ ¬∑ aim : ai j ‚ààA}. It follows that if A is nilpotent, then every a ‚ààA
is nilpotent; that is, am = 0. On the other hand, if a ‚ààR is a nilpotent element, it does
not follow that Ra, the left ideal generated by a, is a nilpotent ideal. For example, let
R = Mat2(k), for some commutative ring k, and let a =
 0 1
0 0

. Now a2 =
 0 0
0 0

, but Ra
contains
e =
0
0
1
0
 0
1
0
0

=
0
0
0
1

,
which is idempotent: e2 = e. Therefore, em = e Ã∏= 0 for all m, and so (Re)m Ã∏= {0}.
Corollary 8.33.
If R is a ring, then I ‚äÜJ(R) for every nilpotent left ideal I in R.
Proof.
Let I n = {0}, and let x ‚ààI. For every r ‚ààR, we have rx ‚ààI, and so (rx)n = 0.
The equation
(1 + rx + (rx)2 + ¬∑ ¬∑ ¬∑ + (rx)n‚àí1)(1 ‚àírx) = 1
shows that 1 ‚àírx is left invertible, and so x ‚ààJ(R), by Proposition 8.31.
‚Ä¢
Proposition 8.34.
If R is a left artinian ring, then J(R) is a nilpotent ideal.
Proof.
Denote J(R) by J in this proof. The descending chain of left ideals,
J ‚äáJ 2 ‚äáJ 3 ‚äá¬∑ ¬∑ ¬∑ ,
stops, because R is left artinian; say, J m = J m+1 = ¬∑ ¬∑ ¬∑ ; deÔ¨Åne I = J m. It follows that
I = I 2. We will assume that I Ã∏= {0} and reach a contradiction.
Let F be the family of all nonzero left ideals B with I B Ã∏= {0}; note that F Ã∏= ‚àÖ
because I ‚ààF. By Proposition 8.16, there is a minimal element B0 ‚ààF. Choose b ‚ààB0
with Ib Ã∏= {0}. Now
I (Ib) = I 2b = Ib Ã∏= {0},
so that Ib ‚äÜB0 ‚ààF, and minimality gives B0 = Ib. Since b ‚ààB0, there is x ‚ààI ‚äÜ
J = J(R) with b = xb. Hence, 0 = (1 ‚àíx)b. But 1 ‚àíx has a left inverse, say, u, by
Proposition 8.31, so that 0 = u(1 ‚àíx)b = b, and this is a contradiction.
‚Ä¢

Sec. 8.2
Chain Conditions
547
The Jacobson radical is obviously a left ideal, but it turns out to be a right ideal as well;
that is, J(R) is a two-sided ideal. We begin by giving another source of two-sided ideals.
DeÔ¨Ånition.
If R is a ring and M is a left R-module, deÔ¨Åne the annihilator of M to be
ann(M) = {a ‚ààR : am = 0 for all m ‚ààM}.
Even though it is easy to see that ann(M) is a two-sided ideal in R, we prove that it
is a right ideal. Let a ‚ààann(M), r ‚ààR, and m ‚ààM. Since M is a left R-module, we
have rm ‚ààM; since a annihilates every element of M, we have a(rm) = 0. Finally,
associativity gives (ar)m = 0 for all m, and so ar ‚ààann(M).
Corollary 8.35.
(i) J(R) =

I = maximal
left ideal
ann(R/I), and so J(R) is a two-sided ideal in R.
(ii) R/J(R) is a Jacobson semisimple ring.
Proof.
(i) Let A(R) denote 
I ann(R/I), where the intersection is over all maximal left
ideals I. For any left ideal I, we claim that ann(R/I) ‚äÜI. If a ‚ààann(R/I), then, for all
r ‚ààR, we have a(r + I) = ar + I = I; that is, ar ‚ààI. In particular, if r = 1, then a ‚ààI.
Hence, A(R) ‚äÜJ(R).
For the reverse inclusion, assume that I is a maximal left ideal, and deÔ¨Åne S = R/I;
maximality of I implies that S is a simple R-module. For each nonzero x ‚ààS, deÔ¨Åne
œïx : R ‚ÜíS by œïx : r ‚Üírx. It is easy to check that œïx is an R-map, and it is surjective
because S is simple. Thus, R/ ker œïx ‚àº= S, and simplicity of S shows that the left ideal
ker œïx is maximal. But it is easy to see that ann(R/I) = 
x‚ààS ker œïx. It follows that
J(R) ‚äÜA(R). Since J(R) is equal to A(R), which is an intersection of two-sided ideals,
J(R) is a two-sided ideal.
(ii) First, R/J(R) is a ring, because J(R) is a two-sided ideal.
The correspondence
theorem for rings shows that if I is any two-sided ideal of R contained in J(R), then
J(R/I) = J(R)/I; the result follows if I = J(R).
‚Ä¢
Let us now show that we could have deÔ¨Åned the Jacobson radical using right ideals
instead of left ideals.
DeÔ¨Ånition.
A unit in a ring R is an element u ‚ààR having a two-sided inverse; that is,
there is v ‚ààR with
uv = 1 = vu.
Proposition 8.36.
(i) If R is a ring, then
J(R) = {x ‚ààR : 1 + rxs is a unit in R for all r, s ‚ààR}.

548
Algebras
Ch. 8
(ii) If R is a ring and J ‚Ä≤(R) is the intersection of all the maximal right ideals of R, then
J ‚Ä≤(R) = J(R).
Proof.
(i) Let W be the set of all x ‚ààR such that 1 + rxs is a unit for all r, s ‚ààR. If
x ‚ààW, then setting s = ‚àí1 gives 1 ‚àírx a unit for all r ‚ààR. Hence, 1 ‚àírx has a left
inverse, and so x ‚ààJ(R), by Proposition 8.31. Therefore, W ‚äÜJ(R). For the reverse
inclusion, let x ‚ààJ(R). Since J(R) is a two-sided ideal, by Corollary 8.35, we have
xs ‚ààJ(R) for all s ‚ààR. Proposition 8.31 says that 1 ‚àírxs is left invertible for all r ‚ààR;
that is, there is u ‚ààR with u(1 ‚àírxs) = 1. Thus, u = 1 + urxs. Now (‚àíur)xs ‚ààJ(R),
since J(R) is a two-sided ideal, and so u has a left inverse (Proposition 8.31 once again).
On the other hand, u also has a right inverse, namely, 1 ‚àírxs. By Exercise 8.16, u is a
unit in R. Therefore, 1 ‚àírxs is a unit in R for all r, s ‚ààR. Finally, replacing r by ‚àír, we
have 1 + rxs a unit, and so J(R) ‚äÜW.
(ii) The description of J(R) in part (i) is left-right symmetric. After proving right-sided
versions of Proposition 8.31 and Corollary 8.35, one can see that J ‚Ä≤(R) is also described
as in part (i). We conclude that J ‚Ä≤(R) = J(R).
‚Ä¢
EXERCISES
8.23
(i) Generalize the proof of Lemma 6.69 to prove that if  is a division ring, then Œ± ‚™ØS,
deÔ¨Åned by Œ± ‚àà‚ü®S‚ü©, is a dependency relation.
(ii) Use Theorem 6.71 to prove that every left vector space over a division ring has a basis.
(iii) Use Theorem 6.72 to prove that any two bases of a left vector space over a division ring
have the same cardinality.
8.24 If k is a Ô¨Åeld and A is a Ô¨Ånite-dimensional k-algebra, deÔ¨Åne
L = {Œªa ‚ààEndk(A) : Œªa : x ‚Üíax}
and
R = {œÅa ‚ààEndk(A) : œÅa : x ‚Üíxa}.
Prove that there are k-algebra isomorphisms
L ‚àº= A
and
R ‚àº= Aop.
Hint. Show that the function A ‚ÜíL deÔ¨Åned by a ‚ÜíŒªa is an injective k-algebra map which
is surjective because A is Ô¨Ånite-dimensional.
8.25
(i) Let C be a subdivision ring of a division ring D. Prove that D is a left vector space over
C, and conclude that [D : C] = dimC(D) is deÔ¨Åned.
(ii) If Z ‚äÜC ‚äÜD is a tower of division rings with [D : C] and [C : Z] Ô¨Ånite, then [D : Z]
is Ô¨Ånite and
[D : Z] = [D : C][C : Z].
Hint. If u1, . . . , um is a basis of D as a left vector space over C, and if c1, . . . , cd is a
basis of C as a left vector space over Z, show that the set of all ciu j (in this order) is a
basis of D over Z.

Sec. 8.2
Chain Conditions
549
8.26 (Modular Law). Let A, B, and A‚Ä≤ be submodules of a module M. If A‚Ä≤ ‚äÜA, prove that
A ‚à©(B + A‚Ä≤) = (A ‚à©B) + A‚Ä≤.
8.27
(i) Let 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 be an exact sequence of left R-modules over some ring
R. Prove that if both A and C have DCC, then B has DCC. Conclude, in this case, that
A ‚äïB has DCC.
(ii) Let 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 be an exact sequence of left R-modules over some ring
R. Prove that if both A and C have ACC, then B has ACC. Conclude, in this case, that
A ‚äïB has ACC.
(iii) Prove that every semisimple ring is left artinian.
8.28 (L. Small) Prove that the ring of all matrices of the form
 a 0
b c

, where a ‚ààZ and b, c ‚ààQ, is
left noetherian but not right noetherian.
8.29 Let R be the ring of all 2 √ó 2 matrices
 a b
0 c

, where a ‚ààQ and b, c ‚ààR. Prove that R is right
artinian but not left artinian.
Hint.
There are only Ô¨Ånitely many right ideals in R, but for every V ‚äÜR that is a vector
space over Q,
0
V
0
0

=
 0 v
0 0

: v ‚ààV

is a left ideal.
8.30 Give an example of a ring R that is not isomorphic to Rop.
8.31
(i) If R is a commutative ring with J(R) = {0}, prove that R has no nilpotent elements.
(ii) Give an example of a commutative ring R having no nilpotent elements and for which
J(R) Ã∏= {0}.
8.32 Let k be a Ô¨Åeld and R = Mat2(k). Prove that a =
 0 1
0 0

is left quasi-regular, but that the
principal left ideal Ra is not a left quasi-regular ideal.
8.33
(i) If  is a division ring, prove that a Ô¨Ånite subgroup of √ó need not be cyclic. Compare
with Theorem 3.30. (S. A. Amitsur has found all the Ô¨Ånite subgroups of multiplicative
groups of division rings.)
(ii) If  is a division ring whose center is a Ô¨Åeld of characteristic p > 0, prove that every
Ô¨Ånite subgroup G of √ó is cyclic.
Hint. Consider FpG, and use Theorem 8.23.
8.34 If R is a ring and M is a left R-module, prove that HomR(R, M) is a left R-module, and prove
that it is isomorphic to M.
Hint. If f : R ‚ÜíM and r‚Ä≤ ‚ààR, deÔ¨Åne r‚Ä≤ f : r ‚Üírr‚Ä≤.
8.35 If k is a Ô¨Åeld of characteristic 0, then Endk(k[t]) contains the operators
x : f (t) ‚Üíd
dt f (t)
and
y : f (t) ‚Üít f (t).
(i) If A1(k) is the subalgebra of Endk(k[t]) generated by x and y, prove that
yx = xy + 1.
(ii) Prove that A1(k) is a left noetherian ring having no proper nontrivial two-sided ideals
that satisÔ¨Åes the left and right cancellation laws (if a Ã∏= 0, then either equation ab = ac
or ba = ca implies b = c).

550
Algebras
Ch. 8
Remark.
Exercise 8.35 can be generalized by replacing k[t] by k[t1, . . . , tn], the operator x by
partial derivatives
xi : f (t1, . . . , tn) ‚Üí
d
dti f (t1, . . . , tn),
and the operator y by
yi : f (t1, . . . , tn) ‚Üíti f (t1, . . . , tn).
The subalgebra An(k) of Endk(k[t1, . . . , tn]) generated by x1, . . . , xn, y1, . . . , yn is called the nth
Weyl algebra over k. H. Weyl introduced this algebra to model momentum and position operators in
quantum mechanics. It can be shown that An(k) is a left noetherian simple domain for all n ‚â•1 (see
McConnell-Robson, Noncommutative Noetherian Rings, page 19).
‚óÄ
8.3 SEMISIMPLE RINGS
A group is an abstract object; we can picture it only as a "cloud," a capital letter G. Of
course, there are familiar concrete groups, such as the symmetric group Sn and the general
linear group GL(V ) of all nonsingular linear transformations of a vector space V over a
Ô¨Åeld k. Representations of a Ô¨Ånite group G are homomorphisms of G into such familiar
groups, and they are of fundamental importance for G.
We begin by showing the connection between group representations and group rings.
DeÔ¨Ånition.
A k-representation of a group G is a homomorphism
œÉ : G ‚ÜíGL(V ),
where V is a vector space over a Ô¨Åeld k.
Note that if dim(V ) = n, then GL(V ) contains an isomorphic copy of Sn [if v1, . . . , vn
is a basis of V and Œ± ‚ààSn, then there is a nonsingular linear transformation T : V ‚ÜíV
with T (vi) = vŒ±(i) for all i]; therefore, permutation representations are special cases of
k-representations. Representations of groups can be translated into the language of kG-
modules (compare the next proof with that of Proposition 8.8).
Proposition 8.37.
Every k-representation œÉ : G ‚ÜíGL(V ) equips V with the structure
of a left kG-module; denote this module by V œÉ. Conversely, every left kG-module V
determines a k-representation œÉ : G ‚ÜíGL(V ).
Proof.
Given a homomorphism œÉ : G ‚ÜíGL(V ), denote œÉ(g): V ‚ÜíV by œÉg, and
deÔ¨Åne an action kG √ó V ‚ÜíV by

g‚ààG
agg

v =

g‚ààG
agœÉg(v).
A routine calculation shows that V , equipped with this scalar multiplication, is a left kG-
module.
Conversely, assume that V is a left kG-module. If g ‚ààG, then v ‚Üígv deÔ¨Ånes a linear
transformation Tg : V ‚ÜíV ; moreover, Tg is nonsingular, for its inverse is Tg‚àí1. It is easily
checked that the function œÉ : G ‚ÜíGL(V ), given by œÉ : g ‚ÜíTg, is a k-representation. ‚Ä¢

Sec. 8.3
Semisimple Rings
551
If œÑ : G ‚ÜíGL(V ) is another k-representation, when is V œÑ ‚àº= V œÉ, where V œÑ and V œÉ
are the kG-modules determined by œÑ, œÉ, respectively, in Proposition 8.37? Recall that if
T : V ‚ÜíV is a linear transformation, then we made V into a k[x]-module we denoted by
V T , and we saw, in Proposition 7.3, that if S : V ‚ÜíV is another linear transformation,
then V S ‚àº= V T if and only if there is a nonsingular œï : V ‚ÜíV with S = œïT œï‚àí1.
Proposition 8.38.
Let G be a group and let œÉ, œÑ : G ‚ÜíGL(V ) be k-representations,
where k is a Ô¨Åeld. If V œÉ and V œÑ are the corresponding kG-modules deÔ¨Åned in Propo-
sition 8.37, then V œÉ ‚àº= V œÑ as kG-modules if and only if there exists a nonsingular
œï : V ‚ÜíV with
œïœÑ(g) = œÉ(g)œï
for every g ‚ààG.
Remark.
We often say that œï intertwines œÉ and œÑ.
‚óÄ
Proof.
If œï : V œÑ ‚ÜíV œÉ is a kG-isomorphism, then œï : V ‚ÜíV is an isomorphism of
vector spaces with
œï

aggv

=

agg

œï(v)
for all v ‚ààV and all g ‚ààG. But the deÔ¨Ånition of scalar multiplication in V œÑ is gv =
œÑ(g)(v), while the deÔ¨Ånition of scalar multiplication in V œÉ is gv = œÉ(g)(v). Hence, for
all g ‚ààG and v ‚ààV , we have œï(œÑ(g)(v)) = œÉ(g)(œï(v)). Therefore,
œïœÑ(g) = œÉ(g)œï
for all g ‚ààG.
Conversely, the hypothesis gives œïœÑ(g) = œÉ(g)œï for all g ‚ààG, where œï is a nonsingular
k-linear transformation, and so œï(œÑ(g)v) = œÉ(g)œï(v) for all g ‚ààG and v ‚ààV . It now
follows easily that œï is a kG-isomorphism; that is, œï preserves scalar multiplication by

g‚ààG agg.
‚Ä¢
Let us rephrase the last proposition in terms of matrices.
Corollary 8.39.
Let G be a group and let œÉ, œÑ : G ‚ÜíMatn(k) be k-representations.
Then (kn)œÉ ‚àº= (kn)œÑ as kG-modules if and only if there is a nonsingular n √ó n matrix P
with
PœÑ(x)P‚àí1 = œÉ(x)
for every x ‚ààG.
Example 8.40.
If G is a Ô¨Ånite group and V is a vector space over a Ô¨Åeld k, then the trivial homomorphism
œÉ : G ‚ÜíGL(V ) is deÔ¨Åned by œÉ(x) = 1V for all x ‚ààG. The corresponding kG-module

552
Algebras
Ch. 8
V œÉ is called the trivial kG-module: If v ‚ààV , then xv = v for all x ‚ààG. The trivial
module k (also called the principal kG-module) is denoted by
V0(k).
‚óÄ
We now introduce an important class of rings; it will be seen that most group algebras
kG are semisimple rings.
DeÔ¨Ånition.
A left R-module is semisimple if it is a direct sum of simple modules. A ring
R is left semisimple if it is a direct sum of minimal left ideals.3
Recall that if a ring R is viewed as a left R-module, then its submodules are its left
ideals; moreover, a left ideal is minimal if and only if it is a simple left R-module.
The next proposition generalizes Example 8.30.
Proposition 8.41.
If a ring R is left semisimple, then it has both chain conditions on left
ideals.
Proof.
Since R is left semisimple, it is a direct sum of minimal left ideals: R = 
i Li.
Let 1 = 
i ei, where ei ‚ààLi. If r = 
i ri ‚àà
i Li, then r = 1r and so ri = eiri.
Hence, if ei = 0, then Li = 0. We conclude that there are only Ô¨Ånitely many nonzero Li;
that is, R = L1 ‚äï¬∑ ¬∑ ¬∑ ‚äïLn. Now the series
R = L1 ‚äï¬∑ ¬∑ ¬∑ ‚äïLn ‚äáL2 ‚äï¬∑ ¬∑ ¬∑ ‚äïLn ‚äá¬∑ ¬∑ ¬∑ ‚äáLn ‚äá{0}
is a composition series, for the factor modules are L1, . . . , Ln, which are simple. It follows
from Proposition 8.17 that R (as a left R-module over itself) has both chain conditions. ‚Ä¢
We now characterize semisimple modules over any ring.
Proposition 8.42.
A left module M (over any ring) is semisimple if and only if every
submodule of M is a direct summand.
Proof.
Suppose that M is semisimple; hence, M = 
j‚ààJ Sj, where each Sj is simple.
For any subset I ‚äÜJ, deÔ¨Åne
SI =

j‚ààI
Sj.
If B is a submodule of M, Zorn's lemma provides a subset K ‚äÜJ maximal with the
property that SK ‚à©B = {0}. We claim that M = B ‚äïSK . We must show that M = B +SK ,
for their intersection is {0} by hypothesis, and it sufÔ¨Åces to prove that Sj ‚äÜB + SK for
3We can deÔ¨Åne a ring to be right semisimple if it is a direct sum of minimal right ideals. However, we shall
see in Corollary 8.57 that a ring is a left semisimple ring if and only if it is right semisimple.

Sec. 8.3
Semisimple Rings
553
all j ‚ààJ. If j ‚ààK, then Sj ‚äÜSK ‚äÜB + SK . If j /‚ààK, then maximality gives
(SK + Sj) ‚à©B Ã∏= {0}. Thus,
sK + s j = b Ã∏= 0,
where sK ‚ààSK , s j ‚ààSj, and b ‚ààB. Note that s j Ã∏= 0, lest sK = b ‚ààSK ‚à©B = {0}.
Hence,
s j = b ‚àísK ‚ààSj ‚à©(B + SK ),
and so Sj ‚à©(B + SK ) Ã∏= {0}. But Sj is simple, so that Sj = Sj ‚à©(B + SK ), and so
Sj ‚äÜB + SK , as desired. Therefore, M = B ‚äïSK .
Now assume that every submodule of M is a direct summand.
(i) Every nonzero submodule B contains a simple summand.
Let b ‚ààB be nonzero. By Zorn's lemma, there exists a submodule C of B maximal
with b /‚ààC. By Corollary 7.18, C is a direct summand of B: There is some submodule
D with B = C ‚äïD. We claim that D is simple. If D is not simple, we may repeat the
argument just given to show that D = D‚Ä≤ ‚äïD‚Ä≤‚Ä≤ for nonzero submodules D‚Ä≤ and D‚Ä≤‚Ä≤. Thus,
B = C ‚äïD = C ‚äïD‚Ä≤ ‚äïD‚Ä≤‚Ä≤.
We claim that at least one of C ‚äïD‚Ä≤ or C ‚äïD‚Ä≤‚Ä≤ does not contain the original element
b. Otherwise, b = c‚Ä≤ + d‚Ä≤ = c‚Ä≤‚Ä≤ + d‚Ä≤‚Ä≤, where c‚Ä≤, c‚Ä≤‚Ä≤ ‚ààC, d‚Ä≤ ‚ààD‚Ä≤, and d‚Ä≤‚Ä≤ ‚ààD‚Ä≤‚Ä≤. But
c‚Ä≤ ‚àíc‚Ä≤‚Ä≤ = d‚Ä≤‚Ä≤ ‚àíd‚Ä≤ ‚ààC ‚à©D = {0} gives d‚Ä≤ = d‚Ä≤‚Ä≤ ‚ààD‚Ä≤ ‚à©D‚Ä≤‚Ä≤ = {0}. Hence, d‚Ä≤ = d‚Ä≤‚Ä≤ = 0,
and so b = c‚Ä≤ ‚ààC, contradicting the deÔ¨Ånition of C. Finally, either C ‚äïD‚Ä≤ or C ‚äïD‚Ä≤‚Ä≤
contradicts the maximality of C.
(ii) M is left semisimple.
By Zorn's lemma, there is a family {Sj : j ‚ààI} of simple submodules of M maximal
such that the submodule U they generate is their direct sum: U = 
j‚ààI Sj. By hypothesis,
U is a direct summand: M = U ‚äïV for some submodule V of M. If V = {0}, we are
done. Otherwise, by part (i), there is some simple submodule S contained in V that is a
summand: V = S ‚äïV ‚Ä≤ for some V ‚Ä≤ ‚äÜV . The family {Sj : j ‚ààI} ‚à™{S} violates the
maximality of the Ô¨Årst family of simple submodules, for this larger family also generates
its direct sum. Therefore, V = {0} and M is left semisimple.
‚Ä¢
Corollary 8.43.
(i) Every submodule and every quotient module of a semisimple module M is itself left
semisimple.
(ii) If R is a (left) semisimple ring, then every left R-module M is a semisimple module.
(iii) If I is a two-sided ideal in a semisimple ring R, then the quotient ring R/I is also a
semisimple ring.

554
Algebras
Ch. 8
Proof.
(i) Let B be a submodule of M. Every submodule C of B is, clearly, a submodule
of M. Since M is left semisimple, C is a direct summand of M and so, by Corollary 7.18,
C is a direct summand of B. Hence, B is left semisimple, by Proposition 8.42.
Let M/H be a quotient of M. Now H is a direct summand of M, so that M = H ‚äïH‚Ä≤
for some submodule H‚Ä≤ of M. But H‚Ä≤ is left semisimple, by the Ô¨Årst paragraph, and
M/H ‚àº= H‚Ä≤.
(ii) There is a free left R-module F and a surjective R-map œï : F ‚ÜíM. Now R is a
semisimple module over itself (this is the deÔ¨Ånition of semisimple ring), and so F is a
semisimple module. Thus, M is a quotient of the semisimple module F, and so it is itself
semisimple, by part (i).
(iii) First, R/I is a ring, because I is a two-sided ideal. The left R-module R/I is semisim-
ple, by (i), and so it is a direct sum R/I ‚àº=
 Sj, where the Sj are simple left R-modules.
But each Sj is also simple as a left (R/I)-module, for any (R/I)-submodule of Sj is also
an R-submodule of Sj. Therefore, R/I is semisimple.
‚Ä¢
Corollary 8.44.
(i) A Ô¨Ånitely generated left semisimple R-module M (over a ring R) is a direct sum of
a Ô¨Ånite number of simple left modules. In particular, a left semisimple ring R is a
direct sum of a Ô¨Ånite number of minimal left ideals.
(ii) The direct product R = R1 √ó ¬∑ ¬∑ ¬∑ √ó Rm of left semisimple rings R1, . . . , Rm is also
a left semisimple ring.
Proof.
(i) Let x1, . . . , xn be a generating set of M. Since M is left semisimple, it is a
direct sum of simple left modules, say, M = 
j Sj. Now each xi = 
j si j, where
si j ‚ààSj, has only a Ô¨Ånite number of nonzero components. Hence, {x1, . . . , xn} involves
only Ô¨Ånitely many Sj's, say, Sj1, . . . , Sjt . Therefore,
M ‚äÜ‚ü®x1, . . . , xn‚ü©‚äÜSj1 ‚äï¬∑ ¬∑ ¬∑ ‚äïSjt ‚äÜM.
As a left semisimple module over itself, R is cyclic, hence Ô¨Ånitely generated. Therefore,
R is a direct sum of only Ô¨Ånitely many simple left submodules; that is, R is a direct sum of
Ô¨Ånitely many minimal left ideals.
(ii) Since each Ri is left semisimple, it is a direct sum of minimal left ideals, say, Ri =
Ji1 ‚äï¬∑ ¬∑ ¬∑‚äïJi t(i). Each Jik is a left ideal in R, not merely in Ri, as we saw in Example 8.5.
It follows that Jik is a minimal left ideal in R. Hence, R is a direct sum of minimal left
ideals, and so it is a left semisimple ring.
‚Ä¢
It follows that a Ô¨Ånite direct product of Ô¨Åelds is a commutative semisimple ring (we will
prove the converse later in this section). For example, if n is a squarefree integer, then the
Chinese remainder theorem implies that In is a semisimple ring. Similarly, if k is a Ô¨Åeld
and f (x) ‚ààk[x] is a product of distinct irreducible polynomials, then k[x]/( f (x)) is a
semisimple ring.

Sec. 8.3
Semisimple Rings
555
We can now generalize Proposition 8.20: Every, not necessarily Ô¨Ånitely generated, left
vector space over a division ring  has a basis. Every division ring is a left semisimple
ring, and  itself is the only minimal left ideal. Therefore, every left -module M is a
direct sum of copies of ; say, M = 
i‚ààI i. If xi ‚àài is nonzero, then X = {xi : i ‚ààI}
is a basis of M. This observation explains the presence of Zorn's lemma in the proof of
Proposition 8.42.
The next result shows that left semisimple rings can be characterized in terms of the
Jacobson radical.
Theorem 8.45.
A ring R is left semisimple if and only if it is left artinian and J(R) = {0}.
Proof.
If R is left semisimple, then there is a left ideal I with R = J(R) ‚äïI, by
Proposition 8.42. It follows from Exercise 8.15(ii) on page 532 that there are idempotents
e ‚ààJ(R) and f ‚ààI with 1 = e+ f . Since e ‚ààJ(R), Proposition 8.31 says that f = 1‚àíe
has a left inverse; there is u ‚ààR with u f = 1. But f is an idempotent, so that f = f 2.
Hence, 1 = u f = u f 2 = (u f ) f = f , so that e = 1 ‚àíf = 0. Since J(R)e = J(R), by
Exercise 8.15(ii) on page 532, we have J(R) = {0}. Finally, Proposition 8.41 shows that
R is left artinian.
Conversely, assume that R is left artinian and J(R) = {0}. We show Ô¨Årst that if I is a
minimal left ideal of R, then I is a direct summand of R. Now I Ã∏= {0}, and so I Ã∏‚äÜJ(R);
therefore, there is a maximal left ideal A not containing I. Since I is minimal, it is simple,
so that I ‚à©A is either I or {0}. But I ‚à©A = I implies I ‚äÜA, a contradiction, and so
I ‚à©A = {0}. Maximality of A gives I + A = R, and so R = I ‚äïA.
Choose a minimal left ideal I1, which exists because R is left artinian. As we have just
seen, R = I1 ‚äïB1 for some left ideal B1. Now B1 contains a minimal left ideal, say, I2, by
Proposition 8.29(ii), and so there is a left ideal B2 with B1 = I2 ‚äïB2. This construction
can be iterated to produce a strictly decreasing chain of left ideals B1 ‚äãB2 ‚äã¬∑ ¬∑ ¬∑ ‚äãBr+1
as long as Br Ã∏= {0}. If Br Ã∏= {0} for all r, then the DCC is violated. Therefore, Br = {0}
for some r, so that R = I1 ‚äï¬∑ ¬∑ ¬∑ ‚äïIr and R is semisimple.
‚Ä¢
Note that the chain condition is needed. For example, Z is Jacobson semisimple, that
is, J(Z) = {0}, but Z is not a semisimple ring.
We can now prove the following remarkable result.
Theorem 8.46 (Hopkins-Levitzki).
If a ring R is left artinian, then it is left noetherian.
Proof.
It sufÔ¨Åces to prove that R, regarded as a left module over itself, has a composition
series, for then Proposition 8.17 applies at once to show that R is left noetherian as a
module over itself; that is, R has the ACC on left ideals.
If J = J(R) denotes the Jacobson radical, then J m = {0} for some m ‚â•1, by Proposi-
tion 8.34, and so there is a chain
R = J 0 ‚äáJ ‚äáJ 2 ‚äáJ 3 ‚äá¬∑ ¬∑ ¬∑ ‚äáJ m = {0}.
Since each J q is an ideal in R, it has the DCC, as does its quotient J q/J q+1. Now R/J
is a semisimple ring, by Theorem 8.45 [it is left artinian, being a quotient of a left artinian

556
Algebras
Ch. 8
ring, and Jacobson semisimple, by Corollary 8.35(ii)]. The factor module J q/J q+1 is an
(R/J)-module; hence, by Corollary 8.43, J q/J q+1 is a semisimple module, and so it can
be decomposed into a direct sum of (possibly inÔ¨Ånitely many) simple (R/J)-modules. But
there can be only Ô¨Ånitely many summands, for every (R/J)-submodule of J q/J q+1 is
necessarily an R-submodule, and J q/J q+1 has the DCC on R-submodules. Hence, there
are simple (R/J)-modules Si with
J q/J q+1 = S1 ‚äïS2 ‚äï¬∑ ¬∑ ¬∑ ‚äïSp.
Throwing away one simple summand at a time yields a series of J q/J q+1 whose ith factor
module is
(Si ‚äïSi+1 ‚äï¬∑ ¬∑ ¬∑ ‚äïSp)/(Si+1 ‚äï¬∑ ¬∑ ¬∑ ‚äïSp) ‚àº= Si.
Now the simple (R/J)-module Si is also a simple R-module, for it is an R-module an-
nihilated by J, so that we have constructed a composition series for J q/J q+1 as a left
R-module. Finally, reÔ¨Åne the original series for R in this way, for every q, to obtain a
composition series for R.
‚Ä¢
Of course, the converse of Theorem 8.46 is false.
The next result is fundamental.
Theorem 8.47 (Maschke's Theorem).
If G is a Ô¨Ånite group and k is a Ô¨Åeld whose
characteristic does not divide |G|, then kG is a left semisimple ring.
Remark.
The hypothesis always holds if k has characteristic 0.
‚óÄ
Proof.
By Proposition 8.42, it sufÔ¨Åces to prove that every left ideal I of kG is a direct
summand. Since k is a Ô¨Åeld, kG is a vector space over k and I is a subspace. By Corol-
lary 6.49, I is a (vector space) direct summand: There is a subspace V (which may not be
a left ideal in kG) with kG = I ‚äïV . There is a k-linear transformation d : kG ‚ÜíI with
d(b) = b for all b ‚ààI and with ker d = V [each u ‚ààkG has a unique expression of the
form u = b + v, where b ‚ààI and v ‚ààV , and d(u) = b]. Were d a kG-map, not merely a
k-map, then we would be done, by the criterion of Corollary 7.17: I is a summand of kG
if and only if it is a retract; that is, there is a kG-map D : kG ‚ÜíI with D(u) = u for all
u ‚ààI. We now force d to be a kG-map by an "averaging" process.
DeÔ¨Åne D : kG ‚ÜíkG by
D(u) =
1
|G|

x‚ààG
xd(x‚àí1u)
for all u ‚ààkG. Note that |G| Ã∏= 0 in k, by the hypothesis on the characteristic of k, and so
it is invertible. It is obvious that D is a k-map.
(i) im D ‚äÜI.
If u ‚ààkG and x ‚ààG, then d(x‚àí1u) ‚ààI (because im d ‚äÜI), and xd(x‚àí1u) ‚ààI
because I is a left ideal. Therefore, D(u) ‚ààI, for each term in the deÔ¨Åning sum of D(u)
lies in I.

Sec. 8.3
Semisimple Rings
557
(ii) If b ‚ààI, then D(b) = b.
Since b ‚ààI, so is x‚àí1b, and so d(x‚àí1b) = x‚àí1b. Hence, xd(x‚àí1b) = xx‚àí1b = b.
Therefore, 
x‚ààG xd(x‚àí1b) = |G|b, and so D(b) = b.
(iii) D is a kG-map.
It sufÔ¨Åces to prove that D(gu) = gD(u) for all g ‚ààG and all u ‚ààkG. But
gD(u) =
1
|G|

x‚ààG
gxd(x‚àí1u)
=
1
|G|

x‚ààG
gxd(x‚àí1g‚àí1gu)
=
1
|G|

y=gx‚ààG
yd(y‚àí1gu)
= D(gu)
(as x ranges over all of G, so does y = gx).
‚Ä¢
The converse of Maschke's theorem is true: If G is a Ô¨Ånite group and k is a Ô¨Åeld whose
characteristic p divides |G|, then kG is not left semisimple; a proof is outlined in Exer-
cise 8.37 on page 573.
Before analyzing left semisimple rings further, let us give several characterizations of
them.
Proposition 8.48.
The following conditions on a ring R are equivalent.
(i) R is left semisimple.
(ii) Every left R-module is a semisimple module.
(iii) Every left R-module is injective.
(iv) Every short exact sequence of left R-modules splits.
(v) Every left R-module is projective.
Proof.
(i) ‚áí(ii). This follows at once from Corollary 8.43(ii), which says that if R is a
semisimple ring, then every R-module is a semisimple module.
(ii) ‚áí(iii). If E is a left R-module, then Proposition 7.64 says that E is injective if every
exact sequence 0 ‚ÜíE ‚ÜíB ‚ÜíC ‚Üí0 splits. By hypothesis, B is a semisimple module,
and so Proposition 8.42 implies that the sequence splits; thus, E is injective.
(iii) ‚áí(iv). If 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 is an exact sequence, then it must split because, as
every module, A is injective (see Proposition 7.64).
(iv) ‚áí(v). Given a module M, there is an exact sequence
0 ‚ÜíF‚Ä≤ ‚ÜíF ‚ÜíM ‚Üí0,

558
Algebras
Ch. 8
where F is free. This sequence splits, by hypothesis, and so F ‚àº= M ‚äïF‚Ä≤. Therefore, M
is a direct summand of a free module, and hence it is projective (see Theorem 7.56).
(v) ‚áí(i). If I is a left ideal of R, then
0 ‚ÜíI ‚ÜíR ‚ÜíR/I ‚Üí0
is an exact sequence. By hypothesis, R/I is projective, and so this sequence splits (see
Proposition 7.54); that is, I is a direct summand of R. By Proposition 8.42, R is a semisim-
ple left R-module. Therefore, R is a left semisimple ring.
‚Ä¢
Modules over semisimple rings are so nice that there is a notion of global dimension
of a ring R that measures how far removed R is from being semisimple; we will discuss
global dimension in Chapter 11.
Here are more examples of left semisimple rings; the Wedderburn-Artin theorem will
say that there are no others.
Proposition 8.49.
(i) If  is a division ring and V is a left vector space over  with dim(V ) = n, then
End(V ) ‚àº= Matn(op) is a left semisimple ring.
(ii) If 1, . . . , m are division rings, then
Matn1(1) √ó ¬∑ ¬∑ ¬∑ √ó Matnm(m)
is a left semisimple ring.
Proof.
(i) By Proposition 8.24, we have
End(V ) ‚àº= Matn(End());
by Proposition 8.12, End() ‚àº= op. Therefore, End(V ) ‚àº= Matn(op).
Let us now show that End(V ) is semisimple. If v1, . . . , vn is a basis of V , deÔ¨Åne
Col( j) = {T ‚ààEnd(V ) : T (vi) = 0 for all i Ã∏= j}.
It is easy to see that Col( j) is a left ideal in End(V ): If S ‚ààEnd(V ), then S(T vi) = 0
for all i Ã∏= j. Recall Example 8.30: If we look in Matn(op) ‚àº= End(V ), then Col( j)
corresponds to COL( j), all those matrices whose entries off the jth column are 0. It is
obvious that
Matn(op) = COL(1) ‚äï¬∑ ¬∑ ¬∑ ‚äïCOL(n).
Hence, End(V ) is also such a direct sum. We asserted, in Example 8.30, that each COL( j)
is a minimal left ideal, and so End(V ) is a left semisimple ring. Let us prove minimality
of Col( j).
Suppose that I is a nonzero left ideal in End(V ) with I ‚äÜCol( j). Choose a nonzero
F ‚ààI; now F(v j) = u Ã∏= 0, for otherwise F would kill every basis element and, hence,

Sec. 8.3
Semisimple Rings
559
would be 0. If T ‚ààCol( j), write T (v j) = w. Since u Ã∏= 0, there is S ‚ààEnd(V ) with
S(u) = w. Now
SF(vi) =

0
if i Ã∏= j;
S(u) = w
if i = j.
Therefore, T = SF, because they agree on a basis, and so T ‚ààI, because I is a left ideal.
Therefore, Col( j) = I, and Col( j) is a minimal left ideal.
(ii) This follows at once from part (i) and Proposition 8.44(ii), for if  is a division ring,
then so is op, by Exercise 8.13 on page 532.
‚Ä¢
Corollary 8.50.
If V is an n-dimensional left vector space over a division ring , then
the minimal left ideals Col( j), for 1 ‚â§j ‚â§n, in End(V ) are all isomorphic.
Proof.
Let v1, . . . , vn be a basis of V . For each j, deÔ¨Åne p j : V ‚ÜíV to be the linear
transformation that interchanges v j and v1 and that Ô¨Åxes all the other vi. It is easy to see
that T ‚ÜíT p j is an isomorphism Col(1) ‚ÜíCol( j).
‚Ä¢
We will see, in Lemma 8.61(ii), that all the minimal left ideals in End(V ) are isomor-
phic.
DeÔ¨Ånition.
A ring R is simple if it is nonzero and it has no proper nonzero two-sided
ideals.
In Proposition 8.59, we will see that every left artinian simple ring is semisimple.
Proposition 8.51.
If  is a division ring, then R = Matn() is a simple ring.
Proof.
A matrix unit E pq is the n √ó n matrix all of whose entries are 0 except the p, q
entry, which is 1. The matrix units form a basis for Matn() viewed as a left vector space
over , for each matrix A = [ai j] has a unique expression
A =

i j
ai j Ei j.
[Of course, this says that dim(Matn()) = n2.] A routine calculation shows that matrix
units multiply according to the following rule:
Ei j Ek‚Ñì=

0
if j Ã∏= k
Ei‚Ñì
if j = k.
Suppose that N is a nonzero two-sided ideal in Matn(). If A is a nonzero matrix in
N, it has a nonzero entry; say, ai j Ã∏= 0. Since N is a two-sided ideal, N contains E pi AE jq

560
Algebras
Ch. 8
for all p, q. But
E pi AE jq = E pi

k‚Ñì
ak‚ÑìEk‚ÑìE jq
= E pi

k
akj Ekq
=

k
akj E pi Ekq
= ai j E pq.
Since ai j Ã∏= 0 and  is a division ring, a‚àí1
i j
‚àà, and so E pq ‚ààN for all p, q. But the
collection of all E pq span the left vector space Matn() over , and so N = Matn(). ‚Ä¢
We are now going to prove the converse of Proposition 8.49(ii): Every left semisimple
ring is isomorphic to a direct product of matrix rings over division rings. The Ô¨Årst step
shows how division rings arise.
Theorem 8.52 (Schur's Lemma).
Let M and M‚Ä≤ be simple left R-modules, where R is
a ring.
(i) Every nonzero R-map f : M ‚ÜíM‚Ä≤ is an isomorphism.
(ii) EndR(M) is a division ring. In particular, if L is a minimal left ideal in a ring R,
then EndR(L) is a division ring.
Proof.
(i) Since M is simple, it has only two submodules: M itself and {0}. Now the
submodule ker f Ã∏= M because f Ã∏= 0, and so ker f = {0}; that is, f is an injection.
Similarly, the submodule im f Ã∏= {0}, so that im f = M‚Ä≤ and f is a surjection.
(ii) If f : M ‚ÜíM and f Ã∏= 0, then f is an isomorphism, by part (i), and hence it has an
inverse f ‚àí1 ‚ààEndR(M). Thus, the ring EndR(M) is a division ring.
‚Ä¢
Lemma 8.53.
If L and L‚Ä≤ are minimal left ideals in a ring R, then each of the following
statements implies the one below it:
(1) LL‚Ä≤ Ã∏= {0};
(2) HomR(L, L‚Ä≤) Ã∏= {0}, and there exists b‚Ä≤ ‚ààL‚Ä≤ with L‚Ä≤ = Lb‚Ä≤;
(3) L ‚àº= L‚Ä≤ as left R-modules.
If also L2 Ã∏= {0}, then (3) implies (1), and the three statements are equivalent.
Proof.
Let L and L‚Ä≤ be minimal left ideals.
(1) ‚áí(2)
If LL‚Ä≤ Ã∏= {0}, then there exists b ‚ààL and b‚Ä≤ ‚ààL‚Ä≤ with bb‚Ä≤ Ã∏= 0. Thus, the function
f : L ‚ÜíL‚Ä≤, deÔ¨Åned by x ‚Üíxb‚Ä≤, is a nonzero R-map, and so HomR(L, L‚Ä≤) Ã∏= {0}.
Moreover, Lb‚Ä≤ = L‚Ä≤, for it is a nonzero submodule of the minimal left ideal L‚Ä≤.

Sec. 8.3
Semisimple Rings
561
(2) ‚áí(3)
If HomR(L, L‚Ä≤) Ã∏= {0}, then there is a nonzero f : L ‚ÜíL‚Ä≤, and f is an isomorphism,
by Schur's lemma; that is, L ‚àº= L‚Ä≤.
(3) and L2 Ã∏= {0} ‚áí(1)
Assume now that L2 Ã∏= {0}, so there are x, y ‚ààL with xy Ã∏= 0. If g : L ‚ÜíL‚Ä≤ is an
isomorphism, then 0 Ã∏= g(xy) = xg(y) ‚ààLL‚Ä≤, and so LL‚Ä≤ Ã∏= {0}.
‚Ä¢
Note that if J(R) = {0}, then L2 Ã∏= {0}. Otherwise, L is a nilpotent left ideal and
Corollary 8.33 gives L ‚äÜJ(R) = {0}, a contradiction.
Proposition 8.54.
If R = 
j L j is a left semisimple ring, where the L j are minimal left
ideals, then every simple R-module S is isomorphic to some L j.
Proof.
Now S ‚àº= HomR(R, S) Ã∏= {0}, by Exercise 8.34 on page 549. If HomR(L j, S) =
{0} for all j, then HomR(R, S) = {0} (for R = L1‚äï¬∑ ¬∑ ¬∑‚äïLm). Hence, HomR(L j, S) Ã∏= {0}
for some j. Since both L j and S are simple, Theorem 8.52(i) gives L j ‚àº= S.
‚Ä¢
Here is a fancier proof.
Proof.
By Corollary 7.14, there is a left ideal I with S ‚àº= R/I, and so there is a series
R ‚äáI ‚äá{0}.
In Proposition 8.41, we saw that
R = L1 ‚äï¬∑ ¬∑ ¬∑ ‚äïLn ‚äáL2 ‚äï¬∑ ¬∑ ¬∑ ‚äïLn ‚äá¬∑ ¬∑ ¬∑ ‚äáLn ‚äá{0}
is a composition series with factor modules L1, . . . , Ln. The Schreier reÔ¨Ånement theorem
(Theorem 8.15) now says that these two series have equivalent reÔ¨Ånements. Since a com-
position series admits only reÔ¨Ånements that repeat a term, the factor module S occurring
in the reÔ¨Ånement of the Ô¨Årst series must be isomorphic to one of the factor modules in the
second series; that is, S ‚àº= Li for some i.
‚Ä¢
Example 8.55.
The trivial kG-module V0(k) (see Example 8.40) is a simple kG-module (for it is
one-dimensional and so has no subspaces other than {0} and itself). By Proposition 8.54,
V0(k) is isomorphic to some minimal left ideal L of kG. We shall Ô¨Ånd L by searching for
elements u = 
g‚ààG agg in kG with hu = u for all h ‚ààG. For such elements u,
hu =

g‚ààG
aghg =

g‚ààG
agg = u.
Since the elements in G form a basis for the vector space kG, we may equate coefÔ¨Åcients,
and so ag = ahg for all g ‚ààG; in particular, a1 = ah. As this holds for every h ‚ààG, all
the coefÔ¨Åcients ag are equal. Therefore, if we deÔ¨Åne Œ≥ ‚ààkG by
Œ≥ =

g‚ààG
g,

562
Algebras
Ch. 8
then u is a scalar multiple of Œ≥ . It follows that L = ‚ü®Œ≥ ‚ü©is a left ideal isomorphic to the
trivial module V0(k); moreover, ‚ü®Œ≥ ‚ü©is the unique such left ideal.
‚óÄ
An abstract left semisimple ring R is a direct sum of minimal left ideals: R = 
j L j,
and we now know that EndR(L j) is a division ring for every j. The next step is to Ô¨Ånd
the direct summands of R that will ultimately turn out to be matrix rings; they arise from a
decomposition of R into minimal left ideals by collecting isomorphic terms.
DeÔ¨Ånition.
Let R be a left semisimple ring, and let
R = L1 ‚äï¬∑ ¬∑ ¬∑ ‚äïLn,
where the L j are minimal left ideals. Reindex the summands so that no two of the Ô¨Årst m
ideals L1, . . . , Lm are isomorphic, while every L j in the given decomposition is isomor-
phic to some Li for 1 ‚â§i ‚â§m. The left ideals
Bi =

L j‚àº=Li
L j
are called the simple components of R relative to the decomposition R = 
j L j.
We shall see, in Corollary 8.62, that the simple components do not depend on the par-
ticular decomposition of R as a direct sum of minimal left ideals.
We divide the Wedderburn-Artin4 theorem into two parts: an existence theorem and a
uniqueness theorem.
Theorem 8.56 (Wedderburn-Artin I).
A ring R is left semisimple if and only if R is
isomorphic to a direct product of matrix rings over division rings.
Proof.
SufÔ¨Åciency is Proposition 8.49.
For necessity, assume that R is left semisimple. Now R is the direct sum of its simple
components:
R = B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBm,
where each Bi is a direct sum of isomorphic minimal left ideals. Proposition 8.12 says that
there is a ring isomorphism
Rop ‚àº= EndR(R),
where R is regarded as a left module over itself. Now HomR(Bi, B j) = {0} for all i Ã∏= j,
by Lemma 8.53, so that Corollary 8.26 applies to give a ring isomorphism
Rop ‚àº= EndR(R) ‚àº= EndR(B1) √ó ¬∑ ¬∑ ¬∑ √ó EndR(Bm).
By Proposition 8.24, there is an isomorphism of rings
EndR(Bi) ‚àº= Matni (EndR(Li)),
4Wedderburn proved the theorem for semisimple k-algebras, where k is a Ô¨Åeld; Artin generalized the theorem
as it is stated here. This theorem is why artinian rings are so called.

Sec. 8.3
Semisimple Rings
563
because Bi is a direct sum of isomorphic copies of Li. By Schur's lemma, EndR(Li) is a
division ring, say, i, and so
Rop ‚àº= Matn1(1) √ó ¬∑ ¬∑ ¬∑ √ó Matnm(m).
Hence,
R ‚àº= [Matn1(1)]op √ó ¬∑ ¬∑ ¬∑ √ó [Matnm(m)]op.
Finally, Proposition 8.13 gives
R ‚àº= Matn1(op
1 ) √ó ¬∑ ¬∑ ¬∑ √ó Matnm(op
m ).
This completes the proof, for op
i
is also a division ring for all i, by Exercise 8.13 on
page 532.
‚Ä¢
Corollary 8.57.
A ring R is left semisimple if and only if it is right semisimple.
Proof.
It is easy to see that a ring R is right semisimple if and only if its opposite ring
Rop is left semisimple. But we saw, in the middle of the proof of Theorem 8.56, that
Rop ‚àº= Matn1(1) √ó ¬∑ ¬∑ ¬∑ √ó Matnm(m),
where i = EndR(Li).
‚Ä¢
As a consequence of this corollary, we say that a ring is semisimple without the adjec-
tives left or right.
Corollary 8.58.
A commutative ring R is semisimple if and only if it is isomorphic to a
direct product of Ô¨Ånitely many Ô¨Åelds.
Proof.
A Ô¨Åeld is a semisimple ring, and so a direct product of Ô¨Ånitely many Ô¨Åelds is also
semisimple, by Corollary 8.44(ii). Conversely, if R is semisimple, it is a direct product of
matrix rings over division rings. Since R is commutative, all the matrix rings must be of
size 1 √ó 1 and all the division rings must be Ô¨Åelds.
‚Ä¢
Even though the name suggests it, it is not yet clear that a simple ring is semisimple. In-
deed, this is false without assuming the DCC (see Lam, A First Course in Noncommutative
Rings, page 43, for an example of a simple ring that is not semisimple).
Proposition 8.59.
A simple left artinian ring R is semisimple.
Proof. (Rieffel) First, we show that if L is any nonzero left ideal in R and  = EndR(L),
then R ‚àº= End(L). Now L is a left -module [with scalar multiplication  √ó L ‚ÜíL
given by ( f, a) ‚Üíf (a) for all f ‚àà and a ‚ààL].
DeÔ¨Åne œï : R ‚ÜíEnd(L) by œïr being left multiplication by r:
œïr(a) = ra

564
Algebras
Ch. 8
for all r ‚ààR and a ‚ààL. Note that œïr is a -map: If f ‚àà = EndR(L), then
œïr( f (a)) = r f (a) = f (ra) = f œïr(a).
It is easy to check that œï is a ring homomorphism; in particular, œï1 is the identity function
on L. Since œï is not the zero map, ker œï Ã∏= R. But R is a simple ring and ker œï is a
two-sided ideal, so that ker œï = {0} and œï is an injection.
Proving that œï is a surjection is more subtle. If b ‚ààL, deÔ¨Åne œÅb : L ‚ÜíL to be right
multiplication by b:
œÅb : a ‚Üíab.
Now œÅb : L ‚ÜíL is an R-map: If r ‚ààR and a ‚ààL, then
œÅb(ra) = (ra)b = r(ab) = rœÅb(a).
Hence, œÅb ‚ààEndR(L) = . If h ‚ààEnd(L) and a, b ‚ààL, then
h(œÅb(a)) = œÅbh(a).
The left side is h(œÅb(a)) = h(ab) = h(œïa(b)), and the right side is œÅbh(a) = h(a)b =
œïh(a)(b). Therefore,
hœïa = œïh(a) ‚ààœï(L),
and so œï(L) is a left ideal in End(L).
Now L R = {
i viri : vi ‚ààL and ri ‚ààR} is a two-sided ideal in R, and L R Ã∏=
{0} because R has a unit element. Simplicity of R gives L R = R. Therefore, œï(R) =
œï(L R) = œï(L)œï(R) is a left ideal in End(L) (because œï(L) is a left ideal). But œï(R)
contains œï(1) = 1, and so the left ideal œï(R) contains 1. We conclude that œï(R) =
End(L) and R ‚àº= End(L) .
Since R is left artinian, we may assume that L is a minimal left ideal, that  = EndR(L)
is a division ring (by Schur's lemma), and that L is a left vector space over . If L is
Ô¨Ånite-dimensional, say, dim(L) = n, then R ‚àº= End(L) ‚àº= Matn(op), and we are
done. If, on the other hand, L is inÔ¨Ånite-dimensional, then there is an inÔ¨Ånite independent
set v1, v2, . . . , vn, . . . that is part of a basis. If
I j = {T ‚ààEnd(L) : T (v1) = 0 = ¬∑ ¬∑ ¬∑ = T (v j)},
then it is easy to see that I1 ‚äãI2 ‚äã¬∑ ¬∑ ¬∑ is a strictly decreasing sequence of left ideals,
contradicting R being left artinian.
‚Ä¢
The following corollary follows at once from Proposition 8.59 and the Wedderburn-
Artin theorem.
Corollary 8.60.
If A is a simple left artinian ring, then A ‚àº= Matn() for some n ‚â•1
and some division ring .
The next lemma, which gives some interesting properties enjoyed by left semisimple
rings, will be used to complete the Wedderburn-Artin theorem by stating uniqueness of
its constituent parts. In particular, it will say that the integer n and the division ring  in
Corollary 8.60 are uniquely determined by A.

Sec. 8.3
Semisimple Rings
565
Lemma 8.61.
Let R be a left semisimple ring, and let
R = L1 ‚äï¬∑ ¬∑ ¬∑ ‚äïLn = B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBm,
where the L j are minimal left ideals and the Bi's are the corresponding simple components
of R.
(i) Each Bi is a ring that is also a two-sided ideal in R, and Bi B j = {0} if j Ã∏= i.
(ii) If L is any minimal left ideal in R, not necessarily occurring in the given decompo-
sition of R, then L ‚àº= Li for some i and L ‚äÜBi.
(iii) Every two-sided ideal D in R is a direct sum of Bi's.
(iv) Each Bi is a simple ring.
Proof.
(i) Each Bi is a left ideal. To see that it is also a right ideal, consider
Bi R = Bi(B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBm) ‚äÜBi B1 + ¬∑ ¬∑ ¬∑ + Bi Bm.
Recall, for each i, that Bi is a direct sum of left ideals L isomorphic to Li. If L ‚àº= Li
and L‚Ä≤ ‚àº= L j, then the contrapositive not (3) ‚áínot (1) in Lemma 8.53 applies to give
LL‚Ä≤ = {0} if j Ã∏= i. Hence, if j Ã∏= i,
Bi B j =
 
L‚àº=Li
L
 
L‚Ä≤‚àº=L j
L‚Ä≤
‚äÜ

LL‚Ä≤ = {0}.
Thus, Bi B1 + ¬∑ ¬∑ ¬∑ + Bi Bm ‚äÜBi Bi. Since Bi is a left ideal, Bi Bi ‚äÜRBi ‚äÜBi. Therefore,
Bi R ‚äÜBi, so that Bi is a right ideal and, hence, is a two-sided ideal.
In the last step, proving that Bi is a right ideal, we saw that Bi Bi ‚äÜBi; that is, Bi is
closed under multiplication. Therefore, to prove that Bi is a ring, it now sufÔ¨Åces to prove
that it contains a unit element. If 1 is the unit element in R, then 1 = e1 + ¬∑ ¬∑ ¬∑ + em, where
ei ‚ààBi for all i. If bi ‚ààBi, then
bi = 1bi = (e1 + ¬∑ ¬∑ ¬∑ + em)bi = eibi,
for B j Bi = {0} whenever j Ã∏= i, by part (i). Similarly, the equation bi = bi1 gives
biei = bi, and so ei is a unit in Bi. Thus, Bi is a ring.5
(ii) By Proposition 8.54, a minimal left ideal L is isomorphic to Li for some i. Now
L = RL = (B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBm)L ‚äÜB1L + ¬∑ ¬∑ ¬∑ + Bm L.
If j Ã∏= i, then B j L = {0}, by Lemma 8.53, so that
L ‚äÜBi L ‚äÜBi,
because Bi is a right ideal.
5Bi is not a subring of R because its unit ei is not the unit 1 in R.

566
Algebras
Ch. 8
(iii) A nonzero two-sided ideal D in R is a left ideal, and so it contains some minimal left
ideal L, by Proposition 8.29(ii). Now L ‚àº= Li for some i, by Proposition 8.54; we claim
that Bi ‚äÜD. By Lemma 8.53, if L‚Ä≤ is any minimal left ideal in Bi, then L‚Ä≤ = Lb‚Ä≤ for some
b‚Ä≤ ‚ààL‚Ä≤. Since L ‚äÜD and D is a right ideal, we have L‚Ä≤ = Lb‚Ä≤ ‚äÜLL‚Ä≤ ‚äÜDR ‚äÜD. We
have shown that D contains every left ideal isomorphic to Li; as Bi is generated by such
ideals, Bi ‚äÜD. Write R = BI ‚äïBJ, where BI = 
i Bi with Bi ‚äÜD and BJ = 
j B j
with B j Ã∏‚äÜD. By Corollary 7.18 (which holds for modules over noncommutative rings),
D = BI ‚äï(D ‚à©BJ). But D ‚à©BJ = {0}; otherwise, it would contain a minimal left ideal
L ‚àº= L j for some j ‚ààJ and, as above, this would force B j ‚äÜD. Therefore, D = BI.
(iv) A left ideal in Bi is also a left ideal in R: If a ‚ààR, then a = 
j a j, where a j ‚ààB j;
if bi ‚ààBi, then
abi = (a1 + ¬∑ ¬∑ ¬∑ + am)bi = aibi ‚ààBi,
because B j Bi = {0} for j Ã∏= i. Similarly, a right ideal in Bi is a right ideal in R, and so a
two-sided ideal D in Bi is a two-sided ideal in R. By part (iii), the only two-sided ideals
in R are direct sums of simple components, and so D ‚äÜBi implies D = {0} or D = Bi.
Therefore, Bi is a simple ring.
‚Ä¢
Corollary 8.62.
If R is a semisimple ring, then the simple component containing a mini-
mal left ideal Li is the left ideal generated by all the minimal left ideals that are isomorphic
to Li. Therefore, the simple components of a semisimple ring do not depend on a decom-
position of R as a direct sum of minimal left ideals.
Proof.
This follows from Lemma 8.61(ii).
‚Ä¢
Corollary 8.63.
(i) If A is a simple artinian ring, then A ‚àº= Matn() for some division ring . If L
is a minimal left ideal in A, then every simple left A-module is isomorphic to L;
moreover, op ‚àº= EndA(L).
(ii) Two left A-modules M and N are isomorphic if and only if dim(M) = dim(N).
In particular, if A = Matm(), then M ‚àº= N if and only if dim(M) = dim(N).
Proof.
Since A is a semisimple ring, every left module M is isomorphic to a direct sum
of minimal left ideals. But, by Lemma 8.61(ii), all minimal left ideals are isomorphic, say,
to L, and so dim(M) is the number of summands in a decomposition. If M ‚àº= N as
left Matn()-modules, then M ‚àº= N as left -modules, and so dim(M) = dim(N).
Conversely, if dim(M) = d = dim(N), then both M and N are direct sums of d copies
of L, and hence M ‚àº= N as left A-modules.
We may now assume that A = Matn() and that L = Col(1), the minimal left ideal
consisting of all the n √ó n matrices whose last n ‚àí1 columns are 0 (see Proposition 8.49).
DeÔ¨Åne œï :  ‚ÜíEndA(L) as follows: if d ‚àà and ‚Ñì‚ààL, then œïd : ‚Ñì‚Üí‚Ñìd. Note that
œïd is an A-map: it is additive and, if a ‚ààA and ‚Ñì‚ààL, then œïd(a‚Ñì) = (a‚Ñì)d = a(‚Ñìd) =
aœïd(‚Ñì). Next, œï is a ring antihomomorphism: œï1 = 1L, it is additive, and œïdd‚Ä≤ = œïd‚Ä≤œïd:

Sec. 8.3
Semisimple Rings
567
if ‚Ñì‚ààL, then œïd‚Ä≤œïd(‚Ñì) = œïd(‚Ñìd‚Ä≤) = ‚Ñìd‚Ä≤d = œïdd‚Ä≤(‚Ñì); that is, œï is a ring homomorphism
op ‚ÜíEndA(L). To see that œï is injective, note that each ‚Ñì‚ààL ‚äÜMatn() is a matrix
with entries in ; hence, ‚Ñìd = 0 implies ‚Ñì= 0. Finally, we show that œï is surjective.
Let f ‚ààEndA(L). Now L = AE11, where E11 is the matrix unit (every simple module
is generated by any nonzero element in it). If ui ‚àà, let [u1, . . . , un] denote the n √ó n
matrix in L whose Ô¨Årst column is (u1, . . . , un)t and whose other entries are all 0. Write
f (E11) = [d1, . . . , dn]. If ‚Ñì‚ààL, then ‚Ñìhas the form [u1, . . . , un], and using only the
deÔ¨Ånition of matrix multiplication, it is easy to see that [u1, . . . , un] = [u1, . . . , un]E11.
Since f is an A-map,
f ([u1, . . . , un]) = f ([u1, . . . , un]E11)
= [u1, . . . , un] f (E11)
= [u1, . . . , un][d1, . . . , dn]
= [u1, . . . , un]d1 = œïd1([u1, . . . , un]).
Therefore, f = œïd1 ‚ààim œï, as desired.
‚Ä¢
The number m of simple components of R is an invariant, for it is the number of non-
isomorphic simple left R-modules. However, there is a much stronger uniqueness result.
Theorem 8.64 (Wedderburn-Artin II).
Every semisimple ring R is a direct product,
R ‚àº= Matn1(1) √ó ¬∑ ¬∑ ¬∑ √ó Matnm(m),
where ni ‚â•1 and i is a division ring, and the numbers m and ni, as well as the division
rings i, are uniquely determined by R.
Proof.
Let R be a left semisimple ring, and let R = B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBm be a decomposition
into simple components arising from some decomposition of R as a direct sum of minimal
left ideals. Suppose that R = B‚Ä≤
1 √ó¬∑ ¬∑ ¬∑√ó B‚Ä≤
t, where each B‚Ä≤
‚Ñìis a two-sided ideal that is also
a simple ring. By Lemma 8.61, each two-sided ideal B‚Ä≤
‚Ñìis a direct sum of Bi's. But B‚Ä≤
‚Ñì
cannot have more than one summand Bi, lest the simple ring B‚Ä≤
‚Ñìcontain a proper nonzero
two-sided ideal. Therefore, t = m and, after reindexing, B‚Ä≤
i = Bi for all i.
Dropping subscripts, it remains to prove that if B = Matn() ‚àº= Matn‚Ä≤(‚Ä≤) = B‚Ä≤, then
n = n‚Ä≤ and  ‚àº= ‚Ä≤. In Proposition 8.49, we proved that Col(‚Ñì), consisting of the matrices
with jth columns 0 for all j Ã∏= ‚Ñì, is a minimal left ideal in B, so that Col(‚Ñì) is a simple
B-module. Therefore,
{0} ‚äÜCol(1) ‚äÜCol(1) ‚äïCol(2) ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜCol(1) ‚äï¬∑ ¬∑ ¬∑ ‚äïCol(n) = B
is a composition series of B as a module over itself. By the Jordan-H¬®older theorem (Theo-
rem 8.18), n and the factor modules Col(‚Ñì) are invariants of B. Now Col(‚Ñì) ‚àº= Col(1) for
all ‚Ñì, by Corollary 8.63, and so it sufÔ¨Åces to prove that  can be recaptured from Col(1).
But this has been done in Corollary 8.63(i):  ‚àº= EndB(Col(1))op.
‚Ä¢
The description of the group algebra kG simpliÔ¨Åes when the Ô¨Åeld k is algebraically
closed.

568
Algebras
Ch. 8
Corollary 8.65 (Molien).
If G is a Ô¨Ånite group and k is an algebraically closed Ô¨Åeld
whose characteristic does not divide |G|, then
kG ‚àº= Matn1(k) √ó ¬∑ ¬∑ ¬∑ √ó Matnm(k).
Proof.
By Maschke's theorem, kG is a semisimple ring, and its simple components are
isomorphic to matrix rings of the form Matn(), where  arises as EndkG(L)op for some
minimal left ideal L in kG. Therefore, it sufÔ¨Åces to show that EndkG(L)op =  = k.
Now EndkG(L)op ‚äÜEndk(L)op, which is Ô¨Ånite-dimensional over k because L is; hence,
 = EndkG(L)op is Ô¨Ånite-dimensional over k. Each f ‚ààEndkG(L) is a kG-map, hence is
a k-map; that is, f (au) = af (u) for all a ‚ààk and u ‚ààL. Therefore, the map œïa : L ‚ÜíL,
given by u ‚Üíau, commutes with f ; that is, k (identiÔ¨Åed with all œïa) is contained in
Z(), the center of . If Œ¥ ‚àà, then Œ¥ commutes with every element in k, and so k(Œ¥), the
subdivision ring generated by k and Œ¥, is a (commutative) Ô¨Åeld. As  is Ô¨Ånite-dimensional
over k, so is k(Œ¥); that is, k(Œ¥) is a Ô¨Ånite extension of the Ô¨Åeld k, and so Œ¥ is algebraic over
k, by Proposition 3.117. But k is algebraically closed, so that Œ¥ ‚ààk and  = k.
‚Ä¢
Example 8.66.
There are nonisomorphic Ô¨Ånite groups G and H having isomorphic complex group alge-
bras. If G is an abelian group of order n, then CG is a direct product of matrix rings over
C, because C is algebraically closed. But G abelian implies CG commutative. Hence, CG
is the direct product of n copies of C. It follows that if H is any abelian group of order n,
then CG ‚àº= CH. In particular, I4 and I2 ‚äïI2 are nonisomorphic groups having isomorphic
complex group algebras. It follows from this example that certain properties of a group G
get lost in the group algebra CG.
‚óÄ
Corollary 8.67.
If G is a Ô¨Ånite group and k is an algebraically closed Ô¨Åeld whose charac-
teristic does not divide |G|, then |G| = n2
1+n2
2+¬∑ ¬∑ ¬∑+n2
m, where the ith simple component
Bi of kG consists of ni √ó ni matrices. Moreover, we may assume that n1 = 1.6
Remark.
Theorem 8.149 says that all the ni are divisors of |G|.
‚óÄ
Proof.
As vector spaces over k, both kG and Matn1(k) √ó ¬∑ ¬∑ ¬∑ √ó Matnm(k) have the same
dimension, for they are isomorphic, by Corollary 8.65. But dim(kG) = |G|, and the
dimension of the right side is 
i dim(Matni (k)) = 
i n2
i .
Finally, Example 8.55 shows that there is a unique minimal left ideal isomorphic to the
trivial module V0(k); the corresponding simple component, say, B1, is one-dimensional,
and so n1 = 1.
‚Ä¢
The number m of simple components in CG has a group-theoretic interpretation; we
begin by Ô¨Ånding the center of the group algebra.
DeÔ¨Ånition.
Let C1, . . . , Cr be the conjugacy classes in a Ô¨Ånite group G. For each C j,
deÔ¨Åne the class sum to be the element z j ‚ààCG given by
z j =

g‚ààC j
g.
6By Example 8.55, the group algebra kG always has a unique minimal left ideal isomorphic to V0(k), even
when k is not algebraically closed.

Sec. 8.3
Semisimple Rings
569
Here is a ring-theoretic interpretation of the number c of conjugacy classes.
Lemma 8.68.
If r is the number of conjugacy classes in a Ô¨Ånite group G, then
r = dimC(Z(CG)),
where Z(CG)) is the center of the group algebra. In fact, a basis of Z(CG) consists of all
the class sums.
Proof.
If z j = 
g‚ààC j g is a class sum, then we claim that z j ‚ààZ(CG). If h ‚ààG, then
hz jh‚àí1 = z j, because conjugation by any element of G merely permutes the elements
in a conjugacy class. Note that if j Ã∏= ‚Ñì, then z j and z‚Ñìhave no nonzero components in
common, and so z1, . . . , zr is a linearly independent list. It remains to prove that the z j
span the center.
Let u = 
g‚ààG agg ‚ààZ(CG). If h ‚ààG, then huh‚àí1 = u, and so ahgh‚àí1 = ag for all
g ‚ààG. Thus, if g and g‚Ä≤ lie in the same conjugacy class of G, then their coefÔ¨Åcients in u
are the same. But this says that u is a linear combination of the class sums z j.
‚Ä¢
Theorem 8.69.
If G is a Ô¨Ånite group, then the number m of simple components in CG is
equal to the number r of conjugacy classes in G.
Proof.
We have just seen, in Lemma 8.68, that r = dimC(Z(CG)). On the other hand,
Z(Matni (C)), the center of a matrix ring, is the subspace of all scalar matrices, so that
m = dimC(Z(CG)), by Exercise 8.12(iii) on page 532.
‚Ä¢
We began this section by seeing that k-representations of a group G correspond to kG-
modules. Let us now return to representations.
DeÔ¨Ånition.
A k-representation of a group G is irreducible if the corresponding kG-
module is simple.
For example, a one-dimensional (necessarily irreducible) k-representation is a group
homomorphism Œª: G ‚Üík√ó, where k√ó is the multiplicative group of nonzero elements of
k. The trivial kG-module V0(k) corresponds to the representation Œªg = 1 for all g ‚ààG.
The next result is basic to the construction of the character table of a Ô¨Ånite group.
Theorem 8.70.
If G is a Ô¨Ånite group, then the number of its irreducible complex repre-
sentations is equal to the number r of its conjugacy classes.
Proof.
By Proposition 8.54, every simple CG-module is isomorphic to a minimal left
ideal. Since the number of minimal left ideals is m [the number of simple components of
CG], we see that m is the number of irreducible C-representations of G. But Theorem 8.69
equates m with the number r of conjugacy classes in G.
‚Ä¢

570
Algebras
Ch. 8
Example 8.71.
(i) If G = S3, then CG is six-dimensional. There are three simple components, for S3 has
three conjugacy classes (by Theorem 2.9, the number of conjugacy classes in Sn is equal to
the number of different cycle structures), having dimensions 1, 1, and 4, respectively. (We
could have seen this without Theorem 8.69, for this is the only way to write 6 as a sum of
squares aside from a sum of six 1's.) Therefore,
CS3 ‚àº= C √ó C √ó Mat2(C).
One of the one-dimensional irreducible representations is the trivial one; the other is
sgn (signum).
(ii) We now analyze kG for G = Q, the quaternion group of order 8. If k = C, then
Corollary 8.65 gives
CQ ‚àº= Matn1(C) √ó ¬∑ ¬∑ ¬∑ √ó Matnr (C),
while Corollary 8.67 gives
|Q| = 8 = n2
1 + n2
2 + ¬∑ ¬∑ ¬∑ + n2
r ,
where n1 = 1. It follows that either all ni = 1 or four ni = 1 and one ni = 2. The Ô¨Årst
case cannot occur, for it would imply that CQ is a commutative ring, whereas the group Q
of quaternions is not abelian. Therefore,
CQ ‚àº= C √ó C √ó C √ó C √ó Mat2(C).
We could also have used Theorem 8.69, for Q has exactly Ô¨Åve conjugacy classes, namely,
{1}, {1}, {i, i}, { j, j}, {k, k}.
The group algebra RQ is more complicated because R is not algebraically closed. Exer-
cise 8.20 on page 533 shows that H is a quotient of RQ, hence H is isomorphic to a direct
summand of RQ because RQ is semisimple. It turns out that
RQ ‚àº= R √ó R √ó R √ó R √ó H.
‚óÄ
Here is an amusing application of the Wedderburn-Artin theorems.
Proposition 8.72.
Let R be a ring whose group of units U = U(R) is Ô¨Ånite and of odd
order. Then U is abelian and there are positive integers mi with
|U| =
t
i=1
(2mi ‚àí1).
Proof.
First, we note that 1 = ‚àí1 in R, otherwise ‚àí1 is a unit of even order. Con-
sider the group algebra kU, where k = F2. Since k has characteristic 2 and |U| is odd,
Maschke's theorem says that kU is semisimple. There is a ring map œï : kU ‚ÜíR carrying
every k-linear combination of elements of U to "itself." Now R‚Ä≤ = im œï is a Ô¨Ånite sub-
ring of R containing U (for kU is Ô¨Ånite); since dropping to a subring cannot create any new

Sec. 8.3
Semisimple Rings
571
units, we have U = U(R‚Ä≤). By Corollary 8.43(iii), the ring R‚Ä≤ is semisimple, so that the
Wedderburn-Artin Theorem I gives
R‚Ä≤ ‚àº=
t
i=1
Matni (i),
where each i is a division ring.
Now i is Ô¨Ånite, because R‚Ä≤ is Ô¨Ånite, and so i is a Ô¨Ånite division ring. By the "other"
theorem of Wedderburn, Theorem 8.23, each i is a Ô¨Åeld. But ‚àí1 = 1 in R implies
‚àí1 = 1 in i, and so each Ô¨Åeld i has characteristic 2; hence,
|i| = 2mi
for integers mi ‚â•1. All the matrix rings must be 1 √ó 1, for any matrix ring of larger size
must contain an element of order 2, namely, I +K, where K has entry 1 in the Ô¨Årst position
in the bottom row, and all other entries 0. For example,
1
0
1
1
2
=
1
0
2
1

= I.
Therefore, R‚Ä≤ is a direct product of Ô¨Ånite Ô¨Åelds of characteristic 2, and so U = U(R‚Ä≤) is an
abelian group whose order is described in the statement.
‚Ä¢
It follows, for example, that there is no ring having exactly Ô¨Åve units.
The Jacobson-Chevalley density theorem, an important generalization of Wedderburn's
theorem for certain nonartinian rings, was proved in the 1930s. Call a ring R left primitive
if there exists a faithful simple left R-module S; that is, S is simple and, if r ‚ààR and
r S = {0}, then r = 0. It can be proved that commutative primitive rings are Ô¨Åelds, while
left artinian left primitive rings are simple. Assume now that R is a left primitive ring, that
S is a faithful simple left R-module, and that  denotes the division ring EndR(S). The
density theorem says that if R is left artinian, then R ‚àº= Matn(), while if R is not left
artinian, then for every integer n > 0, there exists a subring Rn of R with Rn ‚àº= Matn().
We refer the reader to Lam, A First Course in Noncommutative Rings, pages 191-193.
The Wedderburn-Artin theorems led to several areas of research, two of which are de-
scriptions of division rings and of Ô¨Ånite-dimensional algebras. Division rings will be con-
sidered in the context of central simple algebras in Chapter 9 and crossed product algebras
in Chapter 10. Let us discuss Ô¨Ånite dimensional algebras now.
Thanks to the theorems of Maschke and Molien, the Wedderburn-Artin theorems ap-
ply to ordinary representations of a Ô¨Ånite group G; that is, to kG-modules, where k is a
Ô¨Åeld whose characteristic does not divide |G|. We know kG is semisimple in this case.
However, modular representations, that is, kG-modules for which the characteristic of k
does divide |G|, arise naturally. For example, if G is a Ô¨Ånite p-group, for some prime
p, then a minimal normal subgroup N is a vector space over Fp. Now G acts on N (by
conjugation), and so N is an FpG-module. Modular representations are used extensively

572
Algebras
Ch. 8
in the classiÔ¨Åcation of the Ô¨Ånite simple groups. In his study of modular representations,
R. Brauer observed that the important modules M are indecomposable rather than irre-
ducible. Recall that a module M is indecomposable if there are no nonzero modules A
and B with M = A ‚äïB (in the ordinary case, a module is indecomposable if and only
if it is irreducible [i.e., simple], but this is no longer true in the modular case). When
kG is semisimple, Proposition 8.54 says that there are only Ô¨Ånitely many indecomposable
modules (corresponding to the minimal left ideals). This is not true in the modular case,
however. For example, if k is an algebraically closed Ô¨Åeld of characteristic 2, kV and k A4
have inÔ¨Ånitely many nonisomorphic indecomposable modules.
A Ô¨Ånite-dimensional k-algebra R over a Ô¨Åeld k is said to have Ô¨Ånite representation
type if there are only Ô¨Ånitely many nonisomorphic Ô¨Ånite-dimensional indecomposable R-
modules. D. G. Higman proved that if G is a Ô¨Ånite group, then kG has Ô¨Ånite representation
type for every Ô¨Åeld k if and only if all its Sylow subgroups G are cyclic. In the 1950s, the
following two problems, known as the Brauer-Thrall conjectures, were posed. Let R be
a ring not of Ô¨Ånite representation type.
(I). Are the dimensions of the indecomposable R-modules unbounded?
(II). Is there a strictly increasing sequence n1, n2, . . . with inÔ¨Ånitely many nonisomorphic
indecomposable R-modules of dimension ni for every i?
The positive solution of the Ô¨Årst conjecture, by A. V. Roiter in 1968, had a great im-
pact. Shortly thereafter, P. Gabriel introduced graph-theoretic methods, associating Ô¨Ånite-
dimensional algebras to certain oriented graphs, called quivers. He proved that a connected
quiver has a Ô¨Ånite number of nonisomorphic Ô¨Ånite-dimensional representations if and only
if the quiver is one of the Dynkin diagrams An, Dn, E6, E7, or E8 (Dynkin diagrams are
multigraphs that describe simple complex Lie algebras; see the discussion on page 778).
Gabriel's result can be rephrased in terms of hereditary k-algebras A (one-sided ideals are
projective A-modules). V. Dlab and C. Ringel extended Gabriel's result to all Dynkin dia-
grams (of any type A through G). They proved that a Ô¨Ånite-dimensional hereditary algebra
is of Ô¨Ånite representation type if and only if its graph is a Ô¨Ånite union of Dynkin dia-
grams. Moreover, using Coxeter functors (which were introduced by I. N. Bernstein, I. M.
Gelfand, and V. A. Ponomarev to give a new proof of Gabriel's result), they extended the
classiÔ¨Åcation to hereditary algebras of tame representation type in terms of the so-called
extended Dynkin diagrams (algebras of inÔ¨Ånite representation type are divided into those
of tame type and those of wild type). A conÔ¨Årmation of the second Brauer-Thrall con-
jecture for all hereditary algebras followed. A positive solution of Brauer-Thrall II for all
(not necessarily hereditary) Ô¨Ånite-dimensional algebras over an algebraically closed Ô¨Åeld
follows from the multiplicative basis theorem of R. Bautista, P. Gabriel, A. V. Roiter, and
L. Salmer¬¥on: Every Ô¨Ånite-dimensional k-algebra A of Ô¨Ånite representation type has a mul-
tiplicative basis B: a vector space basis of A such that the product of two basis vectors
lies in B ‚à™{0}. In fact, they proved that there exist multiplicative bases that contain a
complete set of primitive orthogonal idempotents and a basis of each power of the radical.
M. Auslander and I. Reiten created a theory involving almost split sequences (deÔ¨Åned in
Chapter 10) and Auslander-Reiten quivers. This theory, which generalizes the concept of

Sec. 8.3
Semisimple Rings
573
Coxeter functors, provides a construction of new indecomposable representations of (ar-
bitrary) Ô¨Ånite-dimensional algebras. As of this writing, Auslander-Reiten theory is the
most powerful tool in the study of representations of Ô¨Ånite-dimensional algebras. For a
discussion of these ideas, we refer the reader to Artin-Nesbitt-Thrall, Rings with Mini-
mum Condition, Dlab-Ringel, Indecomposable Representations of Graphs and Algebras,
Memoir AMS #173, 1976, Jacobson, The Theory of Rings, Jacobson, Structure of Rings,
and Drozd-Kirichenko, Finite Dimensional Algebras.
EXERCISES
8.36 Let A be an n-dimensional k-algebra over a Ô¨Åeld k. Prove that A can be imbedded as a
k-subalgebra of Matn(k).
Hint. If a ‚ààA, deÔ¨Åne La : A ‚ÜíA by La : x ‚Üíax.
8.37 Let G be a Ô¨Ånite group, and let k be a commutative ring. DeÔ¨Åne Œµ: kG ‚Üík by
Œµ

g‚ààG
agg

=

g‚ààG
ag
(this map is called the augmentation, and its kernel, denoted by G, is called the augmentation
ideal).
(i) Prove that Œµ is a kG-map and that kG/G ‚àº= k as k-algebras. Conclude that G is a
two-sided ideal in kG.
(ii) Prove that kG/G ‚àº= V0(k), where V0(k) is k viewed as a trivial kG-module.
Hint. G is a two-sided ideal containing xu ‚àíu = (x ‚àí1)u ‚ààG.
(iii) Use part (ii) to prove that if kG = G ‚äïV , then V = ‚ü®v‚ü©, where v = a 
g‚ààG g.
Hint. Argue as in Example 8.55.
(iv) Assume that k is a Ô¨Åeld whose characteristic p does divide |G|. Prove that kG is not left
semisimple.
Hint. First show that Œµ(v) = 0, and then show that the short exact sequence
0 ‚ÜíG ‚ÜíkG
Œµ
‚àí‚Üík ‚Üí0
does not split.
8.38 If  is a division ring, prove that every two minimal left ideals in Matn() are isomorphic.
(Compare Corollary 8.50.)
8.39 An element a in a ring R is called a zero divisor if a Ã∏= 0 and there exists a nonzero b ‚ààR
with ab = 0 (more precisely, we call a a left zero divisor and b a right zero divisor). Prove
that a left artinian ring R having no zero divisors must be a division ring.
8.40 Let T : V ‚ÜíV be a linear transformation, where V is a vector space over a Ô¨Åeld k, and let
k[T ] be deÔ¨Åned by
k[T ] = k[x]/(m(x)),
where m(x) is the minimum polynomial of T .
(i) If m(x) = 
p p(x)ep, where the p(x) ‚ààk[x] are distinct irreducible polynomials and
ep ‚â•1, prove that k[T ] ‚àº=

p k[x]/(p(x)ep).

574
Algebras
Ch. 8
(ii) Prove that k[T ] is a semisimple ring if and only if m(x) is a product of distinct linear
factors. (In linear algebra, we show that this last condition is equivalent to T being
diagonalizable; that is, any matrix of T [arising from some choice of basis of T ] is
similar to a diagonal matrix.)
8.41 Find CG if G = D8, the dihedral group of order 8.
8.42 Find CG if G = A4.
Hint. A4 has four conjugacy classes.
8.43
(i) Let k be a Ô¨Åeld, and view sgn: Sn ‚Üí{¬±1} ‚â§k. DeÔ¨Åne Sig(k) to be k made into a
kSn-module (as in Proposition 8.37): If Œ≥ ‚ààSn and a ‚ààk, then Œ≥ a = sgn(Œ≥ )a. Prove
that Sig(k) is an irreducible kSn-module, and if k does not have characteristic 2, then
Sig(k) Ã∏‚àº= V0(k).
(ii) Find CS5.
Hint. There are Ô¨Åve conjugacy classes in S5.
8.44 Let G be a Ô¨Ånite group, and let k and K be algebraically closed Ô¨Åelds whose characteristics p
and q, respectively, do not divide |G|.
(i) Prove that kG and K G have the same number of simple components.
(ii) Prove that the degrees of the irreducible representations of G over k are the same as the
degrees of the irreducible representations of G over K.
8.4 TENSOR PRODUCTS
We now introduce a new notion,7 tensor products, that is used to construct induced rep-
resentations (which extend representations of subgroups to representations of the whole
group). Tensor products are also useful in other areas of algebra as well; for example,
they are involved in bilinear forms, the adjoint isomorphism, free algebras, exterior alge-
bra, and determinants. The reader who wishes to see the impact of the Wedderburn-Artin
and Maschke theorems on groups without this interruption can proceed directly to the next
section, for the Ô¨Årst application we shall give‚ÄîBurnside's theorem‚Äîdoes not use induced
representations in its proof. On the other hand, we shall also prove a theorem of Frobenius
that does use induced representations.
If k is a Ô¨Åeld and H be a subgroup of a group G, then a k-representation of H is the
same thing as a kH-module, and a k-representation of G is the same thing as a kG-module.
If we could force a kH-module M to be a kG-module, then we would be able to create a
representation of the big group G from a representation of a subgroup. More generally, if
A is a subring of a ring R, we may want to force an A-module M to be an R-module. If M
is generated as an A-module by a set X, then each m ‚ààM has an expression of the form
m = 
i ai xi, where ai ‚ààA and xi ‚ààX. Perhaps we could create an R-module containing
M by taking all expressions of the form 
i ri xi for ri ‚ààR. This naive approach is doomed
7Tensor products of R-modules, where R is commutative, could have been presented in Chapter 7. How-
ever, I believe that the best exposition delays the introduction of noncommutative rings to the present chapter.
Consequently, putting tensor products earlier would have forced me to construct them in two stages: Ô¨Årst over
commutative rings in Chapter 7, then over general rings now. This is not a good idea.

Sec. 8.4
Tensor Products
575
to failure. For example, a cyclic group G = ‚ü®g‚ü©of Ô¨Ånite order n is a Z-module; can we
make it into a Q-module? A Q-module V is a vector space over Q, and it is easy to see
that if v ‚ààV and q ‚ààQ, then qv = 0 if and only if q = 0 or v = 0. If we could create a
rational vector space V containing G in the naive way described in the previous paragraph,
then ng = 0 would imply g = 0 in V ! Our goal of adjoining scalars to obtain a module
over a larger ring still has merit but, plainly, we cannot be so cavalier about its construction.
The proper way to deal with such matters is with tensor products.
One of the most compelling reasons to introduce tensor products comes from algebraic
topology, where we assign to every topological space X a sequence of homology groups
Hn(X) for all n ‚â•0 that are of basic importance. The K¬®unneth formula computes the
homology groups of the cartesian product X √ó Y of two topological spaces in terms of the
tensor product of the homology groups of the factors X and Y.
DeÔ¨Ånition.
Let R be a ring, let AR be a right R-module, let R B be a left R-module, and
let G be an (additive) abelian group. A function f : A √ó B ‚ÜíG is called R-biadditive if,
for all a, a‚Ä≤ ‚ààA, b, b‚Ä≤ ‚ààB, and r ‚ààR, we have
f (a + a‚Ä≤, b) = f (a, b) + f (a‚Ä≤, b);
f (a, b + b‚Ä≤) = f (a, b) + f (a, b‚Ä≤);
f (ar, b) = f (a,rb).
An R-biadditive function is also called a pairing.
If R is commutative and A, B, and M are R-modules, then a function f : A √ó B ‚ÜíM
is called R-bilinear if f is R-biadditive and also
f (ar, b) = f (a,rb) = r f (a, b).
Example 8.73.
(i) If R is a ring, then its multiplication ¬µ: R √ó R ‚ÜíR is R-biadditive; the Ô¨Årst two
axioms are the right and left distributive laws, while the third axiom is associativity:
¬µ(ar, b) = (ar)b = a(rb) = ¬µ(a,rb).
If R is a commutative ring, then ¬µ is R-bilinear, for (ar)b = a(rb) = r(ab).
(ii) If R M is a left R-module, then its scalar multiplication œÉ : R√óM ‚ÜíM is R-biadditive;
if R is a commutative ring, then œÉ is R-bilinear.
(iii) If MR and NR are right R-modules, then HomR(M, N) is a left R-module if, for
f ‚ààHomR(M, N) and r ‚ààR, we deÔ¨Åne r f : M ‚ÜíN by
r f : m ‚Üíf (mr).
The reader may show that this does make Hom into a left R-module; moreover, we can
now see that evaluation e: M √ó HomR(M, N) ‚ÜíN, given by (m, f ) ‚Üíf (m), is R-
biadditive.

576
Algebras
Ch. 8
The dual space V ‚àóof a vector space V over a Ô¨Åeld k gives a special case of this con-
struction: Evaluation V √ó V ‚àó‚Üík is R-bilinear.
(iv) If G‚àó= HomZ(G, Q/Z) is the Pontrjagin dual of an abelian group G, then evaluation
G √ó G‚àó‚ÜíQ/Z is Z-bilinear.
‚óÄ
Tensor products convert biadditive functions into linear ones.
DeÔ¨Ånition.
Given a ring R and modules AR and R B, then their tensor product is an
abelian group A ‚äóR B and an R-biadditive function
h : A √ó B ‚ÜíA ‚äóR B
such that, for every abelian group G and every R-biadditive f : A √ó B ‚ÜíG, there exists
a unique Z-homomorphism f : A ‚äóR B ‚ÜíG making the following diagram commute.
A √ó B
h

f









A ‚äóR B
f

G
If a tensor product of A and B exists, then it is unique to isomorphism, for it has been
deÔ¨Åned as a solution to a universal mapping problem (see the proof of Proposition 7.27 on
page 448).
Quite often, we denote A ‚äóR B by A ‚äóB when R = Z.
Proposition 8.74.
If R is a ring and AR and R B are modules, then their tensor product
exists.
Proof.
Let F be the free abelian group with basis A √ó B; that is, F is free on all ordered
pairs (a, b), where a ‚ààA and b ‚ààB. DeÔ¨Åne S to be the subgroup of F generated by all
elements of the following types:
(a, b + b‚Ä≤) ‚àí(a, b) ‚àí(a, b‚Ä≤);
(a + a‚Ä≤, b) ‚àí(a, b) ‚àí(a‚Ä≤, b);
(ar, b) ‚àí(a,rb).
DeÔ¨Åne A ‚äóR B = F/S, denote the coset (a, b) + S by a ‚äób, and deÔ¨Åne
h : A √ó B ‚ÜíA ‚äóR B
by
h : (a, b) ‚Üía ‚äób
(thus, h is the restriction of the natural map F ‚ÜíF/S). We have the following identities
in A ‚äóR B:
a ‚äó(b + b‚Ä≤) = a ‚äób + a ‚äób‚Ä≤;
(a + a‚Ä≤) ‚äób = a ‚äób + a‚Ä≤ ‚äób;
ar ‚äób = a ‚äórb.

Sec. 8.4
Tensor Products
577
It is now obvious that h is R-biadditive.
Consider the following diagram, where G is an abelian group and f is R-biadditive:
A √ó B
h

f
'
i









A ‚äóR B
f
(
F
nat
)








œï

G,
where i : A√óB ‚ÜíF is the inclusion. Since F is free abelian with basis A√óB, there exists
a homomorphism œï : F ‚ÜíG with œï(a, b) = f (a, b) for all (a, b); now S ‚äÜker œï because
f is R-biadditive, and so œï induces a map f : A ‚äóR B ‚ÜíG (because A ‚äóR B = F/S) by
f (a ‚äób) = f ((a, b) + S) = œï(a, b) = f (a, b).
This equation may be rewritten as f h = f ; that is, the diagram commutes. Finally, f is
unique because A ‚äóR B is generated by the set of all a ‚äób's.
‚Ä¢
Remark.
Since A‚äóR B is generated by the elements of the form a‚äób, every u ‚ààA‚äóR B
has the form
u =

i
ai ‚äóbi.
This expression for u is not unique; for example, there are expressions
0 = a ‚äó(b + b‚Ä≤) ‚àía ‚äób ‚àía ‚äób‚Ä≤
= (a + a‚Ä≤) ‚äób ‚àía ‚äób ‚àía‚Ä≤ ‚äób
= ar ‚äób ‚àía ‚äórb.
Therefore, given some abelian group G, we must be suspicious of a deÔ¨Ånition of a map
g : A ‚äóR B ‚ÜíG that is given by specifying g on the generators a ‚äób; such a "function"
g may not be well-deÔ¨Åned because elements have many expressions in terms of these
generators. In essence, g is only deÔ¨Åned on F (the free abelian group with basis A √ó B),
and we must still show that g(S) = {0}, because A‚äóR B = F/S. The simplest (and safest!)
procedure is to deÔ¨Åne an R-biadditive function on A √ó B, and it will yield a (well-deÔ¨Åned)
homomorphism. We illustrate this procedure in the next proof.
‚óÄ
Proposition 8.75.
Let f : AR ‚ÜíA‚Ä≤
R and g : R B ‚ÜíR B‚Ä≤ be maps of right R-modules
and left R-modules, respectively. Then there is a unique Z-homomorphism, denoted by
f ‚äóg : A ‚äóR B ‚ÜíA‚Ä≤ ‚äóR B‚Ä≤, with
f ‚äóg : a ‚äób ‚Üíf (a) ‚äóg(b).

578
Algebras
Ch. 8
Proof.
The function œï : A √ó B ‚ÜíA‚Ä≤ ‚äóR B‚Ä≤, given by (a, b) ‚Üíf (a) ‚äóg(b), is easily
seen to be an R-biadditive function. For example,
œï : (ar, b) ‚Üíf (ar) ‚äóg(b) = f (a)r ‚äóg(b)
and
œï : (a,rb) ‚Üíf (a) ‚äóg(rb) = f (a) ‚äórg(b);
these are equal because of the identity a‚Ä≤r ‚äób‚Ä≤ = a‚Ä≤ ‚äórb‚Ä≤ in A‚Ä≤ ‚äóR B‚Ä≤. The biadditive
function œï yields a unique homomorphism A ‚äóR B ‚ÜíA‚Ä≤ ‚äóR B‚Ä≤ taking
a ‚äób ‚Üíf (a) ‚äóg(b).
‚Ä¢
Corollary 8.76.
Given maps of right R-modules, A
f‚ÜíA‚Ä≤
f ‚Ä≤
‚ÜíA‚Ä≤‚Ä≤, and maps of left
R-modules, B
g‚ÜíB‚Ä≤ g‚Ä≤
‚ÜíB‚Ä≤‚Ä≤,
( f ‚Ä≤ ‚äóg‚Ä≤)( f ‚äóg) = f ‚Ä≤ f ‚äóg‚Ä≤g.
Proof.
Both maps take a ‚äób ‚Üíf ‚Ä≤ f (a) ‚äóg‚Ä≤g(b), and so the uniqueness of such a
homomorphism gives the desired equation.
‚Ä¢
Theorem 8.77.
Given AR, there is an additive functor FA : RMod ‚ÜíAb, deÔ¨Åned by
FA(B) = A ‚äóR B
and
FA(g) = 1A ‚äóg,
where g : B ‚ÜíB‚Ä≤ is a map of left R-modules.
Proof.
First, note that FA preserves identities: FA(1B) = 1A ‚äó1B is the identity 1A‚äóB,
because it Ô¨Åxes every generator a ‚äób. Second, FA preserves composition:
FA(g‚Ä≤g) = 1A ‚äóg‚Ä≤g = (1A ‚äóg‚Ä≤)(1A ‚äóg) = FA(g‚Ä≤)FA(g),
by Corollary 8.76. Therefore, FA is a functor.
To see that FA is additive, we must show that FA(g + h) = FA(g) + FA(h), where
g, h : B ‚ÜíB‚Ä≤; that is, 1A ‚äó(g + h) = 1A ‚äóg + 1A ‚äóh. This is also easy, for both these
maps send a ‚äób ‚Üía ‚äóg(b) + a ‚äóh(b).
‚Ä¢
We denote the functor FA by A‚äóR . Of course, there is a similar result if we Ô¨Åx a left
R-module B: There is an additive functor
‚äóR B : ModR ‚ÜíAb.
Corollary 8.78.
If f : M ‚ÜíM‚Ä≤ and g : N ‚ÜíN ‚Ä≤ are, respectively, isomorphisms of right
and left R-modules, then f ‚äóg : M ‚äóR N ‚ÜíM‚Ä≤ ‚äóR N ‚Ä≤ is an isomorphism of abelian
groups.

Sec. 8.4
Tensor Products
579
Proof.
Now f ‚äó1N‚Ä≤ is the value of the functor FN‚Ä≤ on the isomorphism f , and hence
f ‚äó1N‚Ä≤ is an isomorphism; similarly, 1M ‚äóg is an isomorphism. By Corollary 8.76, we
have f ‚äóg = ( f ‚äó1N‚Ä≤)(1M ‚äóg). Therefore, f ‚äóg is an isomorphism, being the composite
of isomorphisms.
‚Ä¢
Before continuing with properties of tensor products, we pause to discuss a technical
point. In general, the tensor product of two modules is only an abelian group; is it ever a
module? If so, do the tensor product functors then take values in a module category, not
merely in Ab? That is, is 1 ‚äóf always a map of modules?
DeÔ¨Ånition.
Let R and S be rings and let M be an abelian group. Then M is an (R, S)-
bimodule, denoted by R MS, if M is a left R-module and a right S-module, and the two
scalar multiplications are related by an associative law:
r(ms) = (rm)s
for all r ‚ààR, m ‚ààM, and s ‚ààS.
If M is an (R, S)-bimodule, it is permissible to write rms with no parentheses, for the
deÔ¨Ånition of bimodule says that the two possible associations agree.
Example 8.79.
(i) Every ring R is an (R, R)-bimodule; the extra identity is just the associativity of multi-
plication in R.
(ii) Every two-sided ideal in a ring R is an (R, R)-bimodule.
(iii) If M is a left R-module (i.e., if M = R M), then M is an (R, Z)-bimodule; that is,
M = R MZ. Similarly, a right R-module N is a bimodule ZNR.
(iv) If R is commutative, then every left (or right) R-module is an (R, R)-bimodule. In
more detail, if M = R M, deÔ¨Åne a new scalar multiplication M √ó R ‚ÜíM by (m,r) ‚Üí
rm. To see that M is a right R-module, we must show that m(rr‚Ä≤) = (mr)r‚Ä≤, that is,
(rr‚Ä≤)m = r‚Ä≤(rm), and this is so because rr‚Ä≤ = r‚Ä≤r. Finally, M is an (R, R)-bimodule
because both r(mr‚Ä≤) and (rm)r‚Ä≤ are equal to (rr‚Ä≤)m.
(v) In Example 8.6, we made any left kG-module M into a right kG-module by deÔ¨Åning
mg = g‚àí1m for every m ‚ààM and every g in the group G. Even though M is both
a left and right kG-module, it is usually not a (kG, kG)-bimodule because the required
associativity formula may not hold. In more detail, let g, h ‚ààG and let m ‚ààM. Now
g(mh) = g(h‚àí1m) = (gh‚àí1)m; on the other hand, (gm)h = h‚àí1(gm) = (h‚àí1g)m. To
see that these can be different, take M = kG, m = 1, and g and h noncommuting elements
of G.
‚óÄ
The next lemma solves the problem of extending scalars.
Lemma 8.80.
Given a bimodule S AR and a left module R B, then the tensor product
A ‚äóR B is a left S-module, where
s(a ‚äób) = (sa) ‚äób.

580
Algebras
Ch. 8
Similarly, given AR and R BS, the tensor product A ‚äóR B is a right S-module, where
(a ‚äób)s = a ‚äó(bs).
In particular, if k is a commutative ring and A is a k-algebra, then A ‚äók B is a left
A-module.
Proof.
For Ô¨Åxed s ‚ààS, the multiplication ¬µs : A ‚ÜíA, deÔ¨Åned by a ‚Üísa, is an R-map,
for A being a bimodule gives
¬µs(ar) = s(ar) = (sa)r = ¬µs(a)r.
If F =
‚äóR B : ModR ‚ÜíAb, then F(¬µs): A ‚äóR B ‚ÜíA ‚äóR B is a (well-deÔ¨Åned)
Z-homomorphism. Thus, F(¬µs) = ¬µs ‚äó1B : a ‚äób ‚Üí(sa) ‚äób, and so the formula in the
statement of the lemma makes sense. It is now straightforward to check that the module
axioms do hold for A ‚äóR B.
The last statement follows because a k-algebra A is an (A, k)-bimodule.
‚Ä¢
For example, if V and W are vector spaces over a Ô¨Åeld k, then their tensor product
V ‚äók W is also a vector space over k.
After a while, we see that proving properties of tensor products is just a matter of show-
ing that the obvious maps are, indeed, well-deÔ¨Åned functions.
We have made some progress in our original problem: Given a left k-module M, where
k is a subring of a ring K, we can create a left K-module from M by extending scalars;
that is, Lemma 8.80 shows that K ‚äók M is a left K-module, for K is a (K, k)-bimodule.
However, we must still investigate, among other things, why a left k-module M may not
be imbedded in K ‚äók M, where k is a subring of a ring K.
The following special case of extending scalars is important for representations. If H
is a subgroup of a group G and if œÅ : H ‚ÜíGL(V ) is a k-representation, then œÅ : H ‚Üí
GL(V ) equips V with a left kH-module structure. We call V G = kG ‚äókH V the induced
module. Note that kG is a right kH-module (it is even a right kG-module), and so the
tensor product V G = kG ‚äókH V makes sense; moreover, V G is a left kG-module, by
Lemma 8.80. We will investigate this construction more carefully later in this chapter (see
induced modules on page 624).
Corollary 8.81.
(i) Given a bimodule S AR, then the functor FA = A‚äóR : RMod ‚ÜíAb actually takes
values in SMod.
(ii) If R is a commutative ring, then A ‚äóR B is an R-module, where
r(a ‚äób) = (ra) ‚äób = a ‚äórb
for all r ‚ààR, a ‚ààA, and b ‚ààB.
(iii) If R is a commutative ring, r ‚ààR, and ¬µr : B ‚ÜíB is multiplication by r, then
1A ‚äó¬µr : A ‚äóR B ‚ÜíA ‚äóR B
is also multiplication by r.

Sec. 8.4
Tensor Products
581
Proof.
(i) By the lemma, we know that A ‚äóR B is a left S-module, where s(a ‚äób) =
(sa) ‚äób, and so it sufÔ¨Åces to show that if g : B ‚ÜíB‚Ä≤ is a map of left R-modules, then
FA(g) = 1A ‚äóg is an S-map. But
(1A ‚äóg)[s(a ‚äób)] = (1A ‚äóg)[(sa) ‚äób]
= (sa) ‚äógb
= s(a ‚äógb)
by Lemma 8.80
= s(1A ‚äóg)(a ‚äób).
(ii) Since R is commutative, we may regard A as an (R, R)-bimodule by deÔ¨Åning ar = ra.
Lemma 8.80 now gives
r(a ‚äób) = (ra) ‚äób = (ar) ‚äób = a ‚äórb.
(iii) This statement merely sees the last equation a ‚äórb = r(a ‚äób) from a different
viewpoint:
(1A ‚äó¬µr)(a ‚äób) = a ‚äórb = r(a ‚äób).
‚Ä¢
We have deÔ¨Åned R-biadditive functions for arbitrary, possibly noncommutative, rings
R, whereas we have deÔ¨Åned R-bilinear functions only for commutative rings. Tensor
product was deÔ¨Åned as the solution of a certain universal mapping problem involving
R-biadditive functions; we now consider the analogous problem for R-bilinear functions
when R is commutative.
Here is a provisional deÔ¨Ånition, soon to be seen unnecessary.
DeÔ¨Ånition.
If k is a commutative ring, then a k-bilinear product is a k-module X and a
k-bilinear function h : A √ó B ‚ÜíX such that, for every k-module M and every k-bilinear
function g : A √ó B ‚ÜíM, there exists a unique k-homomorphism g: X ‚ÜíM making the
following diagram commute.
A √ó B
h

g








X
g

M
The next result shows that k-bilinear products exist, but that they are nothing new.
Proposition 8.82.
If k is a commutative ring and A and B are k-modules, then the
k-module A ‚äók B is a k-bilinear product.

582
Algebras
Ch. 8
Proof.
We show that X = A‚äók B provides the solution if we deÔ¨Åne h(a, b) = a‚äób; note
that h is also k-bilinear, thanks to Corollary 8.81. Since g is k-bilinear, it is k-biadditive,
and so there does exist a Z-homomorphism g: A ‚äók B ‚ÜíM with g(a ‚äób) = g(a, b) for
all (a, b) ‚ààA √ó B. We need only show that g is a k-map. If u ‚ààk,
g(u(a ‚äób)) = g((ua) ‚äób)
= g(ua, b)
= ug(a, b)
for g is k-bilinear
= ug(a ‚äób).
‚Ä¢
As a consequence of the proposition, the term bilinear product is unnecessary, and we
shall call it the tensor product instead.
In contrast to the Hom functors, the tensor functors obey certain commutativity and
associativity laws.
Proposition 8.83 (Commutativity).
If k is a commutative ring and M and N are
k-modules, then there is a k-isomorphism
œÑ : M ‚äók N ‚ÜíN ‚äók M
with œÑ : m ‚äón ‚Üín ‚äóm.
Proof.
First, Corollary 8.81 shows that both M‚äók N and N‚äók M are k-modules. Consider
the diagram
M √ó N
h

f
*%
%
%
%
%
%
%
%
%
%
M ‚äók N
œÑ
+
N ‚äók M,
where f (m, n) = n‚äóm. It is easy to see that f is k-bilinear, and so there is a unique k-map
œÑ : M‚äók N ‚ÜíN ‚äók M with œÑ : m‚äón ‚Üín‚äóm. A similar diagram, interchanging the roles
of M‚äók N and N ‚äók M, gives a k-map in the reverse direction taking n‚äóm ‚Üím‚äón. Both
composites of these maps are obviously identity maps, and so œÑ is a k-isomorphism.
‚Ä¢
Proposition 8.84 (Associativity).
Given AR,R BS, and SC, there is an isomorphism
Œ∏ : A ‚äóR (B ‚äóS C) ‚àº= (A ‚äóR B) ‚äóS C
given by
a ‚äó(b ‚äóc) ‚Üí(a ‚äób) ‚äóc.
Proof.
DeÔ¨Åne a triadditive function f : A √ó B √ó C ‚ÜíG, where G is an abelian group,
to be a function that is additive in each of the three variables (when we Ô¨Åx the other two),
f (ar, b, c) = f (a,rb, c),
and
f (a, bs, c) = f (a, b, sc),

Sec. 8.4
Tensor Products
583
for all r ‚ààR and s ‚ààS. Consider the univeral mapping problem described by the diagram
A √ó B √ó C
h

f
!
!
!
!
!
!
!
!
!
!
T (A, B, C),
f

G
where G is an abelian group, f is triadditive, and f is a Z-homomorphism. As for biaddi-
tive functions and tensor products of two modules, deÔ¨Åne T (A, B, C) = F/N, where F is
the free abelian group on all ordered triples (a, b, c) ‚ààA √ó B √ó C, and N is the obvious
subgroup of relations. DeÔ¨Åne h : A √ó B √ó C ‚ÜíT (A, B, C) by
h : (a, b, c) ‚Üí(a, b, c) + N
(denote (a, b, c)+ N by a ‚äób ‚äóc). A routine check shows that this construction does give
a solution to the universal mapping problem for triadditive functions.
We now show that A ‚äóR (B ‚äóS C) is another solution to this universal problem. DeÔ¨Åne
a triadditive function Œ∑: A √ó B √ó C ‚ÜíA ‚äóR (B ‚äóS C) by Œ∑: (a, b, c) ‚Üía ‚äó(b ‚äóc);
we must Ô¨Ånd a homomorphism f : A ‚äóR (B ‚äóS C) ‚ÜíG with f Œ∑ = f . For each
a ‚ààA, the S-biadditive function fa : B √ó C ‚ÜíG, deÔ¨Åned by (b, c) ‚Üíf (a, b, c), gives
a unique homomorphism fa : B ‚äóS C ‚ÜíG taking b ‚äóc ‚Üíf (a, b, c). If a, a‚Ä≤ ‚ààA, then
fa+a‚Ä≤(b ‚äóc) = f (a + a‚Ä≤, b, c) = f (a, b, c) + f (a‚Ä≤, b, c) = fa(b ‚äóc) + fa‚Ä≤(b ‚äóc). It
follows that the function œï : A √ó (B ‚äóS C) ‚ÜíG, deÔ¨Åned by œï(a, b ‚äóc) = fa(b ‚äóc), is
additive in both variables. It is R-biadditive, for if r ‚ààR, then œï(ar, b‚äóc) = far(b‚äóc) =
f (ar, b, c) = f (a,rb, c) = fa(rb ‚äóc) = œï(a,r(b ‚äóc)). Therefore, there is a unique
homomorphism f : A ‚äóR (B ‚äóS C) ‚ÜíG with a ‚äó(b ‚äóc) ‚Üíœï(a, b ‚äóc) = f (a, b, c);
that is, f Œ∑ = f . Uniqueness of solutions to universal mapping problems shows that there
is an isomorphism T (A, B, C) ‚ÜíA‚äóR (B ‚äóS C) with a‚äób‚äóc ‚Üía‚äó(b‚äóc). Similarly,
T (A, B, C) ‚àº= (A ‚äóR B) ‚äóS C via a ‚äób ‚äóc ‚Üí(a ‚äób) ‚äóc, and so A ‚äóR (B ‚äóS C) ‚àº=
(A ‚äóR B) ‚äóS C via a ‚äó(b ‚äóc) ‚Üí(a ‚äób) ‚äóc.
‚Ä¢
Remark.
That the elements a‚äób‚äóc ‚ààT (A, B, C) have no parentheses will be exploited
in the next chapter when we construct tensor algebras.
‚óÄ
We now present properties of tensor products that will help us compute them. First, we
give a result about Hom, and then we give the analogous result for tensor.
Recall Exercise 8.34 on page 549: For any left R-module M, for any f ‚ààHomR(R, M),
and for any r, s ‚ààR, deÔ¨Åne
r f : s ‚Üíf (sr).
Using the fact that a ring R is an (R, R)-bimodule, we can check that r f is an R-map and
that HomR(R, M) is a left R-module. We incorporate this into the next result.

584
Algebras
Ch. 8
Proposition 8.85.
If M is a left R-module, then HomR(R, M) is a left R-module, and
there is an R-isomorphism œïM : HomR(R, M) ‚ÜíM, given by œïM( f ) = f (1). Indeed,
œï = {œïM} is a natural equivalence between HomR(R,
) and the identity functor on
RMod.
Proof.
Adapt the proof of Proposition 7.102.
‚Ä¢
Proposition 8.86.
For every left R-module M, there is an R-isomorphism
Œ∏M : R ‚äóR M ‚ÜíM
with Œ∏M : r ‚äóm ‚Üírm. Indeed, Œ∏ = {Œ∏M} is a natural equivalence between R‚äóR
and
the identity functor on RMod.
Proof.
The function R √ó M ‚ÜíM, given by (r, m) ‚Üírm, is R-biadditive, and so there
is an R-homomorphism Œ∏ : R ‚äóR M ‚ÜíM with r ‚äóm ‚Üírm [we are using the fact
that R is an (R, R)-bimodule]. To see that Œ∏ is an R-isomorphism, it sufÔ¨Åces to Ô¨Ånd a
Z-homomorphism f : M ‚ÜíR ‚äóR M with Œ∏ f and f Œ∏ identity maps (for it is now only a
question of whether the function Œ∏ is a bijection). Such a Z-map is given by f : m ‚Üí1‚äóm.
To see that the isomorphisms Œ∏M constitute a natural equivalence, we must show, for
any module homomorphism h : M ‚ÜíN, that the following diagram commutes.
R ‚äóR M
1‚äóh 
Œ∏M

R ‚äóR N
Œ∏N

M
h
 N
It sufÔ¨Åces to look at a generator r ‚äóm of R‚äóR M. Going clockwise, r ‚äóm ‚Üír ‚äóh(m) ‚Üí
rh(m), while going counterclockwise, r ‚äóm ‚Üírm ‚Üíh(rm). These agree, for h is an
R-map, so that h(rm) = rh(m).
‚Ä¢
The next theorem says that tensor product preserves arbitrary direct sums.
Theorem 8.87.
Given a right module AR and left R-modules {R Bi : i ‚ààI}, there is a
Z-isomorphism
œï : A ‚äóR

i‚ààI
Bi ‚Üí

i‚ààI
(A ‚äóR Bi)
with œï : a ‚äó(bi) ‚Üí(a ‚äóbi). Moreover, if R is commutative, then œï is an R-isomorphism.
Proof.
Since the function f : A √ó

i Bi

‚Üí
i(A ‚äóR Bi), given by f : (a, (bi)) ‚Üí
(a ‚äóbi) is R-biadditive, there exists a Z-homomorphism
œï : A ‚äóR

i
Bi

‚Üí

i
(A ‚äóR Bi)

Sec. 8.4
Tensor Products
585
with œï : a ‚äó(bi) ‚Üí(a ‚äóbi).
If R is commutative, then A ‚äóR

i‚ààI Bi

and

i‚ààI

A ‚äóR Bi

are R-modules and œï is an R-map (for œï is the function given by the
universal mapping problem in Proposition 8.82).
To see that œï is an isomorphism, we give its inverse. Denote the injection B j ‚Üí
i Bi
by Œª j [where Œª j(b j) ‚àà
i Bi has jth coordinate b j and all other coordinates 0], so that
1A ‚äóŒª j : A ‚äóR B j ‚ÜíA ‚äóR

i Bi

. That direct sum is the coproduct in RMod gives a
homomorphism Œ∏ : 
i(A ‚äóR Bi) ‚ÜíA ‚äóR

i Bi

with Œ∏ : (a ‚äóbi) ‚Üía ‚äó
i Œªi(bi).
It is now routine to check that Œ∏ is the inverse of œï, so that œï is an isomorphism.
‚Ä¢
There is a theorem of C. E. Watts (see Rotman, An Introduction to Homological Algebra,
page 77) saying that if T : RMod ‚ÜíAb is a (covariant) right exact functor that preserves
direct sums, then there is a right R-module A so that F is naturally equivalent to A‚äóR .
Example 8.88.
Let k be a Ô¨Åeld and let V and W be k-modules; that is, V and W are vector spaces over
k. Now W is a free k-module; say, W = 
i‚ààI ‚ü®wi‚ü©, where {wi : i ‚ààI} is a basis of W.
Therefore, V ‚äók W ‚àº= 
i‚ààI V ‚äók ‚ü®wi‚ü©. Similarly, V = 
j‚ààJ

v j
 
, where {v j : j ‚ààJ}
is a basis of V and, for each i, V ‚äók ‚ü®wi‚ü©‚àº= 
j‚ààJ

v j
 
‚äók ‚ü®wi‚ü©. But the one-dimensional
vector spaces

v j
 
and ‚ü®wi‚ü©are isomorphic to k, and Proposition 8.86 gives

v j
 
‚äók ‚ü®wi‚ü©‚àº=

v j ‚äówi
 
. Hence, V ‚äók W is a vector space over k having {v j ‚äówi : i ‚ààI and j ‚ààJ} as
a basis. In case both V and W are Ô¨Ånite-dimensional, we have
dim(V ‚äók W) = dim(V ) dim(W).
‚óÄ
Example 8.89.
We now show that there may exist elements in a tensor product V ‚äók V that cannot be
written in the form u ‚äów for u, w ‚ààV .
Let v1, v2 be a basis of a two-dimensional vector space V over a Ô¨Åeld k. As in Exam-
ple 8.88, a basis for V ‚äók V is
v1 ‚äóv1, v1 ‚äóv2, v2 ‚äóv1, v2 ‚äóv2.
We claim that there do not exist u, w ‚ààV with v1 ‚äóv2 + v2 ‚äóv1 = u ‚äów. Otherwise,
write u and w in terms of v1 and v2:
v1 ‚äóv2 + v2 ‚äóv1 = u ‚äów
= (av1 + bv2) ‚äó(cv1 + dv2)
= acv1 ‚äóv1 + adv1 ‚äóv2 + bcv2 ‚äóv1 + bdv2 ‚äóv2.
By linear independence of the basis,
ac = 0 = bd and ad = 1 = bc.
The Ô¨Årst equation gives a = 0 or c = 0, and either possibility, when substituted into the
second equation, gives 0 = 1.
‚óÄ

586
Algebras
Ch. 8
As a consequence of Theorem 8.87, if
0 ‚ÜíB‚Ä≤
i‚ÜíB
p‚ÜíB‚Ä≤‚Ä≤ ‚Üí0
is a split short exact sequence of left R-modules, then, for every right R-module A,
0 ‚ÜíA ‚äóR B‚Ä≤ 1A‚äói
‚àí‚ÜíA ‚äóR B
1A‚äóp
‚àí‚ÜíA ‚äóR B‚Ä≤‚Ä≤ ‚Üí0
is also a split short exact sequence. What if the exact sequence is not split?
Theorem 8.90 (Right Exactness).
Let A be a right R-module, and let
B‚Ä≤
i‚ÜíB
p‚ÜíB‚Ä≤‚Ä≤ ‚Üí0
be an exact sequence of left R-modules. Then
A ‚äóR B‚Ä≤ 1A‚äói
‚àí‚ÜíA ‚äóR B
1A‚äóp
‚àí‚ÜíA ‚äóR B‚Ä≤‚Ä≤ ‚Üí0
is an exact sequence of abelian groups.
Remark.
(i) The absence of 0 ‚Üíat the beginning of the sequence will be discussed later; clearly
this has something to do with our initial problem of imbedding a group G in a vector
space over Q.
(ii) We will give a nicer proof of this theorem once we prove the adjoint isomorphism
(see Proposition 8.100)
‚óÄ
Proof.
There are three things to check.
(i) im(1 ‚äói) ‚äÜker(1 ‚äóp).
It sufÔ¨Åces to prove that the composite is 0; but
(1 ‚äóp)(1 ‚äói) = 1 ‚äópi = 1 ‚äó0 = 0.
(ii) ker(1 ‚äóp) ‚äÜim(1 ‚äói).
Let E = im(1 ‚äói). By part (i), E ‚äÜker(1 ‚äóp), and so 1 ‚äóp induces a map
p: (A ‚äóB)/E ‚ÜíA ‚äóB‚Ä≤‚Ä≤ with
p: a ‚äób + E ‚Üía ‚äópb,
where a ‚ààA and b ‚ààB. Now if œÄ : A ‚äóB ‚Üí(A ‚äóB)/E is the natural map, then
pœÄ = 1 ‚äóp,

Sec. 8.4
Tensor Products
587
for both send a ‚äób ‚Üía ‚äópb.
A ‚äóR B
œÄ

1‚äóp










(A ‚äóR B)/E
p
+&&&&&&&&&&&
A ‚äóB‚Ä≤‚Ä≤
Suppose we show that p is an isomorphism. Then
ker(1 ‚äóp) = ker pœÄ = ker œÄ = E = im(1 ‚äói),
and we are done. To see that p is, indeed, an isomorphism, we construct its inverse
A ‚äóB‚Ä≤‚Ä≤ ‚Üí(A ‚äóB)/E. DeÔ¨Åne
f : A √ó B‚Ä≤‚Ä≤ ‚Üí(A ‚äóB)/E
as follows. If b‚Ä≤‚Ä≤ ‚ààB‚Ä≤‚Ä≤, there is b ‚ààB with pb = b‚Ä≤‚Ä≤, because p is surjective; let
f : (a, b‚Ä≤‚Ä≤) ‚Üía ‚äób.
Now f is well-deÔ¨Åned: If pb1 = b‚Ä≤‚Ä≤, then p(b ‚àíb1) = 0 and b ‚àíb1 ‚ààker p = im i. Thus,
there is b‚Ä≤ ‚ààB‚Ä≤ with ib‚Ä≤ = b ‚àíb1, and hence a ‚äó(b ‚àíb1) = a ‚äóib‚Ä≤ ‚ààim(1 ‚äói) = E.
Clearly, f is R-biadditive, and so the deÔ¨Ånition of tensor product gives a homomorphism
f : A ‚äóB‚Ä≤‚Ä≤ ‚Üí(A ‚äóB)/E with f (a ‚äób‚Ä≤‚Ä≤) = a ‚äób + E. The reader may check that f is
the inverse of p, as desired.
(iii) 1 ‚äóp is surjective.
If  ai ‚äób‚Ä≤‚Ä≤
i ‚ààA ‚äóB‚Ä≤‚Ä≤, then there exist bi ‚ààB with pbi = b‚Ä≤‚Ä≤
i for all i, for p is
surjective. But
1 ‚äóp :

ai ‚äóbi ‚Üí

ai ‚äópbi =

ai ‚äób‚Ä≤‚Ä≤
i .
‚Ä¢
A similar statement holds for the functor
‚äóR B. If B is a left R-module and
A‚Ä≤
i‚ÜíA
p‚ÜíA‚Ä≤‚Ä≤ ‚Üí0
is a short exact sequence of right R-modules, then the sequence
A‚Ä≤ ‚äóR B
i‚äó1B
‚àí‚ÜíA ‚äóR B
p‚äó1B
‚àí‚ÜíA‚Ä≤‚Ä≤ ‚äóR B ‚Üí0
is exact.

588
Algebras
Ch. 8
DeÔ¨Ånition.
A (covariant) functor T : RMod ‚ÜíAb is called right exact if exactness of a
sequence of left R-modules
B‚Ä≤
i‚ÜíB
p‚ÜíB‚Ä≤‚Ä≤ ‚Üí0
implies exactness of the sequence
T (B‚Ä≤)
T (i)
‚àí‚ÜíT (B)
T (p)
‚àí‚ÜíT (B‚Ä≤‚Ä≤) ‚Üí0.
There is a similar deÔ¨Ånition for covariant functors ModR ‚ÜíAb.
In this terminology, the functors A‚äóR
and
‚äóR B are right exact functors.
The next example illustrates the absence of "0 ‚Üí" in Theorem 8.90.
Example 8.91.
Consider the exact sequence of abelian groups
0 ‚ÜíZ
i
‚àí‚ÜíQ ‚ÜíQ/Z ‚Üí0,
where i is the inclusion. By right exactness, there is an exact sequence
I2 ‚äóZ
1‚äói
‚àí‚ÜíI2 ‚äóQ ‚ÜíI2 ‚äó(Q/Z) ‚Üí0
(in this proof, we abbreviate ‚äóZ to ‚äó). Now I2 ‚äóZ ‚àº= I2, by Proposition 8.86. On the
other hand, if a ‚äóq is a generator of I2 ‚äóQ, then
a ‚äóq = a ‚äó(2q/2) = 2a ‚äó(q/2) = 0 ‚äó(q/2) = 0.
Therefore, I2 ‚äóQ = 0, and so 1 ‚äói cannot be an injection.
‚óÄ
The next proposition helps compute tensor products.
Proposition 8.92.
For every abelian group B, we have In ‚äóZ B ‚àº= B/nB.
Proof.
If A is a Ô¨Ånite cyclic group of order n, there is an exact sequence
0 ‚ÜíZ
¬µn
‚àí‚ÜíZ
p‚ÜíA ‚Üí0,
where ¬µn is multiplication by n. Tensoring by an abelian group B gives exactness of
Z ‚äóZ B
¬µn‚äó1B
‚àí‚ÜíZ ‚äóZ B
p‚äó1B
‚àí‚ÜíA ‚äóZ B ‚Üí0.
Consider the diagram
Z ‚äóZ B
¬µn‚äó1B
Œ∏

Z ‚äóZ B
p‚äó1B 
Œ∏

A ‚äóZ B
 0
B
¬µn
 B
œÄ
 B/nB
 0,

Sec. 8.4
Tensor Products
589
where Œ∏ : Z‚äóZ B ‚ÜíB is the isomorphism of Proposition 8.86, namely, Œ∏ : m ‚äób ‚Üímb,
where m ‚ààZ and b ‚ààB. This diagram commutes, for both composites take m‚äób ‚Üínmb.
The next, very general, proposition will apply to this diagram, yielding
A ‚äóZ B ‚àº= B/nB.
‚Ä¢
Proposition 8.93.
Given a commutative diagram with exact rows in which the vertical
maps f and g are isomorphisms,
A‚Ä≤
i

f

A
p

g

A‚Ä≤‚Ä≤

h

0
B‚Ä≤
j
 B
q
 B‚Ä≤‚Ä≤
 0,
there exists a unique isomorphism h : A‚Ä≤‚Ä≤ ‚ÜíB‚Ä≤‚Ä≤ making the augmented diagram commute.
Proof.
If a‚Ä≤‚Ä≤ ‚ààA‚Ä≤‚Ä≤, then there is a ‚ààA with p(a) = a‚Ä≤‚Ä≤ because p is surjective. DeÔ¨Åne
h(a‚Ä≤‚Ä≤) = qg(a). Of course, we must show that h is well-deÔ¨Åned; that is, if u ‚ààA satiÔ¨Åes
p(u) = a‚Ä≤‚Ä≤, then qg(u) = qg(a). Since p(a) = p(u), we have p(a ‚àíu) = 0, so that
a ‚àíu ‚ààker p = im i, by exactness. Hence, a ‚àíu = i(a‚Ä≤), for some a‚Ä≤ ‚ààA‚Ä≤. Thus,
qg(a ‚àíu) = qgi(a‚Ä≤) = qj f (a‚Ä≤) = 0,
because qj = 0. Therefore, h is well-deÔ¨Åned.
To see that the map h is an isomorphism, we construct its inverse. As in the Ô¨Årst para-
graph, there is a map h‚Ä≤ making the following diagram commute:
B‚Ä≤
j

f ‚àí1

B
q

g‚àí1

B‚Ä≤‚Ä≤

h‚Ä≤

0
A‚Ä≤
i
 A
p
 A‚Ä≤‚Ä≤
 0
We claim that h‚Ä≤ = h‚àí1. Now h‚Ä≤q = pg‚àí1. Hence,
h‚Ä≤hp = h‚Ä≤qg = pg‚àí1g = p;
since p is surjective, we have h‚Ä≤h = 1A‚Ä≤‚Ä≤. A similar calculation shows that the other
composite hh‚Ä≤ is also the identity. Therefore, h is an isomorphism. If h‚Ä≤ : A‚Ä≤‚Ä≤ ‚ÜíB‚Ä≤‚Ä≤
satisÔ¨Åes h‚Ä≤ p = qg and if a‚Ä≤‚Ä≤ ‚ààA‚Ä≤‚Ä≤, choose a ‚ààA with pa = a‚Ä≤‚Ä≤. Then h‚Ä≤ pa = h‚Ä≤a‚Ä≤‚Ä≤ =
qga = ha‚Ä≤‚Ä≤, and so h is unique.
‚Ä¢
The proof of the last proposition is an example of diagram chasing. Such proofs appear
long, but they are, in truth, quite routine. We select an element and, at each step, there
is essentially only one thing to do with it. The proof of the dual proposition is another
example of this sort of thing.

590
Algebras
Ch. 8
Proposition 8.94.
Given a commutative diagram with exact rows in which the vertical
maps g and h are isomorphisms,
0
 A‚Ä≤
i

f

A
p

g

A‚Ä≤‚Ä≤
h

0
 B‚Ä≤
j
 B
q
 B‚Ä≤‚Ä≤,
there exists a unique isomorphism f : A‚Ä≤ ‚ÜíB‚Ä≤ making the augmented diagram commute.
Proof.
A diagram chase.
‚Ä¢
A tensor product of two nonzero modules can be zero. The following proposition gen-
eralizes the computation in Example 8.91.
Proposition 8.95.
If T is an abelian group with every element of Ô¨Ånite order and if D is
a divisible abelian group, then T ‚äóZ D = {0}.
Proof.
It sufÔ¨Åces to show that each generator t ‚äód, where t ‚ààT and d ‚ààD, is 0 in
T ‚äóZ D. Since t has Ô¨Ånite order, there is a nonzero integer n with nt = 0. As D is
divisible, there exists d‚Ä≤ ‚ààD with d = nd‚Ä≤. Hence,
t ‚äód = t ‚äónd‚Ä≤ = nt ‚äód‚Ä≤ = 0 ‚äód‚Ä≤ = 0.
‚Ä¢
We now understand why we cannot make a Ô¨Ånite cyclic group G into a Q-module, for
Q ‚äóZ G = {0}.
Corollary 8.96.
If D is a nonzero divisible abelian group with every element of Ô¨Ånite
order (e.g., D = Q/Z), then there is no multiplication D √ó D ‚ÜíD making D a ring.
Proof.
Assume, on the contrary, that there is a multiplication ¬µ: D√óD ‚ÜíD making D a
ring. If 1 is the identity, we have 1 Ã∏= 0, lest D be the zero ring, which has only one element.
Since multiplication in a ring is Z-bilinear, there is a homomorphism ¬µ: D ‚äóZ D ‚ÜíD
with ¬µ(d ‚äód‚Ä≤) = ¬µ(d, d‚Ä≤) for all d, d‚Ä≤ ‚ààD. In particular, if d Ã∏= 0, then ¬µ(d ‚äó1) =
¬µ(d, 1) = d Ã∏= 0. But D ‚äóZ D = {0}, by Proposition 8.95, so that ¬µ(d ‚äó1) = 0. This
contradiction shows that no multiplication ¬µ on D exists.
‚Ä¢
The next modules arise from tensor products in the same way that projective and injec-
tive modules arise from Hom. Investigation of the kernel of A ‚äóR B‚Ä≤ ‚ÜíA ‚äóR B is done
in homological algebra; it is intimately related with a functor called Tor.
DeÔ¨Ånition.
If R is a ring, then a right R-module A is Ô¨Çat8 if, whenever
0 ‚ÜíB‚Ä≤
i‚ÜíB
p‚ÜíB‚Ä≤‚Ä≤ ‚Üí0
8 This term arose as the translation into algebra of a geometric property of varieties.

Sec. 8.4
Tensor Products
591
is an exact sequence of left R-modules, then
0 ‚ÜíA ‚äóR B‚Ä≤ 1A‚äói
‚àí‚ÜíA ‚äóR B
1A‚äóp
‚àí‚ÜíA ‚äóR B‚Ä≤‚Ä≤ ‚Üí0
is an exact sequence of abelian groups. Flatness of a left R-module is deÔ¨Åned similarly.
In other words, A is Ô¨Çat if and only if A‚äóR
is an exact functor. Because the functor
A‚äóR
is right exact, we see that A is Ô¨Çat if and only if, whenever i : B‚Ä≤ ‚ÜíB is an
injection, then 1A ‚äói : A ‚äóR B‚Ä≤ ‚ÜíA ‚äóR B is also an injection.
Lemma 8.97.
If every Ô¨Ånitely generated submodule of a right R-module M is Ô¨Çat, then
M is Ô¨Çat.
Remark.
Another proof of this lemma is given in Corollary 8.103.
‚óÄ
Proof.
Let i : A ‚ÜíB be an injective R-map between left R-modules, and assume that
u = 
j x j ‚äóy j ‚ààker(1M ‚äói), where x j ‚ààM and y j ‚ààA. As u ‚ààM ‚äóR A, we have
0 = (1M ‚äói)u =
n

j=1
x j ‚äóiy j.
Let F be the free abelian group with basis M √ó A, and let S be the subgroup of F con-
sisting of the relations of F/S ‚àº= M ‚äóR A (as in the construction of the tensor product in
Proposition 8.74); thus, S is generated by all elements in F of the form
(m, a + a‚Ä≤) ‚àí(m, a) ‚àí(m, a‚Ä≤);
(m + m‚Ä≤, a) ‚àí(m, a) ‚àí(m‚Ä≤, a);
(mr, a) ‚àí(m,ra).
Let M‚Ä≤ be the submodule of M generated by x1, . . . , xn together with the (Ô¨Ånite number
of) Ô¨Årst "coordinates" in M exhibiting 
k(x j, iy j) as a linear combination of relators
just displayed. Of course, M‚Ä≤ is a Ô¨Ånitely generated submodule of M. The element u‚Ä≤ =
 x j ‚äóy j ‚ààM‚Ä≤‚äóR A (which is the version of u lying in this new tensor product M‚Ä≤‚äóR A)
lies in ker 1M‚Ä≤ ‚äói, for we have taken care that all the relations making (1M ‚äói)(u) = 0 are
still present. But M‚Ä≤ is a Ô¨Ånitely generated submodule of M, so that it is Ô¨Çat, by hypothesis,
and so (1M‚Ä≤‚äói)(u) = 0 implies u‚Ä≤ = 0 in M‚Ä≤‚äóR A. Finally, if ‚Ñì: M‚Ä≤ ‚ÜíM is the inclusion,
then (‚Ñì‚äó1A)(u‚Ä≤) = u, and so u = 0. Therefore, 1M ‚äói is injective and M is Ô¨Çat.
‚Ä¢
We will use this lemma to prove that an abelian group is a Ô¨Çat Z-module if and only if
it has no nonzero elements of Ô¨Ånite order (see Corollary 9.6). Here are some examples of
Ô¨Çat modules.
Lemma 8.98.
Let R be an arbitrary ring.
(i) The right R-module R is a Ô¨Çat R-module.

592
Algebras
Ch. 8
(ii) A direct sum of right R-modules 
j M j is Ô¨Çat if and only each M j is Ô¨Çat.
(iii) Every projective right R-module F is Ô¨Çat.
Proof.
(i) Consider the commutative diagram
A
i

œÉ

B
œÑ

R ‚äóR A
1R‚äói
 R ‚äóR B
where i : A ‚ÜíB is an injection, œÉ : a ‚Üí1 ‚äóa, and œÑ : b ‚Üí1 ‚äób. Now both œÉ and œÑ
are isomorphisms, by Proposition 8.86, and so 1R ‚äói = œÑiœÉ ‚àí1 is an injection. Therefore,
R is a Ô¨Çat module over itself.
(ii) By Proposition 7.30, any family of R-maps { f j : U j ‚ÜíVj} can be assembled into an
R-map œï : 
j U j ‚Üí
j Vj, where œï : (u j) ‚Üí( f j(u j)), and it is easy to check that œï is
an injection if and only if each f j is an injection.
Let i : A ‚ÜíB be an injection. There is a commutative diagram
(
j M j) ‚äóR A
1‚äói 

(
j M j) ‚äóR B


j(M j ‚äóR A)
œï
 
j(M j ‚äóR B),
where œï : (m j ‚äóa) ‚Üí(m j ‚äóia), where 1 is the identity map on 
j M j, and where the
downward maps are the isomorphisms of Proposition 8.87.
By our initial observation, 1‚äói is an injection if and only if each 1M j ‚äói is an injection;
this says that 
j M j is Ô¨Çat if and only if each M j is Ô¨Çat.
(iii) Combining the Ô¨Årst two parts, we see that a free R-module, being a direct sum of
copies of R, must be Ô¨Çat. Moreover, since a module is projective if and only if it is a direct
summand of a free module, part (ii) shows that projective modules are always Ô¨Çat.
‚Ä¢
We cannot improve this lemma without further assumptions, for there exist rings R for
which every Ô¨Çat R-module is projective.
There is a remarkable relationship between Hom and ‚äó. The key idea is that a func-
tion of two variables, say, f : A √ó B ‚ÜíC, can be viewed as a one-parameter family of
functions of one variable: If we Ô¨Åx a ‚ààA, then deÔ¨Åne fa : B ‚ÜíC by b ‚Üíf (a, b).
Recall Lemma 8.80: If R and S are rings and AR and R BS are modules, then A ‚äóR B
is a right S-module, where (a ‚äób)s = a ‚äó(bs). Furthermore, if CS is a module, then
it is easy to see that HomS(B, C) is a right R-module, where ( f r)(b) = f (rb); thus
HomR(A, HomS(B, C)) makes sense, for it consists of R-maps between right R-modules.
Finally, if F ‚ààHomR(A, HomS(B, C)), we denote its value on a ‚ààA by Fa, so that
Fa : B ‚ÜíC, deÔ¨Åned by Fa : b ‚ÜíF(a)(b), is a one-parameter family of functions.

Sec. 8.4
Tensor Products
593
Theorem 8.99 (Adjoint Isomorphism).
Given modules AR, R BS, and CS, where R
and S are rings, there is an isomorphism
œÑA,B,C : HomS(A ‚äóR B, C) ‚ÜíHomR(A, HomS(B, C)),
namely, for f : A ‚äóR B ‚ÜíC and a ‚ààA and b ‚ààB,
œÑA,B,C : f ‚Üíf ‚àó, where f ‚àó
a : b ‚Üíf (a ‚äób).
Indeed, Ô¨Åxing any two of A, B, C, the maps œÑA,B,C constitute natural equivalences
HomS( ‚äóR B, C) ‚ÜíHomR( , HomS(B, C)),
HomS(A‚äóR , C) ‚ÜíHomR(A, HomS( , C)),
and
HomS(A ‚äóR B, ) ‚ÜíHomR(A, HomS(B, )).
Proof.
To prove that œÑ = œÑA,B,C is a Z-homomorphism, let f, g : A ‚äóR B ‚ÜíC. The
deÔ¨Ånition of f + g gives, for all a ‚ààA,
œÑ( f + g)a : b ‚Üí( f + g)(a ‚äób) = f (a ‚äób) + g(a ‚äób)
= œÑ( f )a(b) + œÑ(g)a(b).
Therefore, œÑ( f + g) = œÑ( f ) + œÑ(g).
Next, œÑ is injective. If œÑ( f )a = 0 for all a ‚ààA, then 0 = œÑ( f )a(b) = f (a ‚äób) for all
a ‚ààA and b ‚ààB. Therefore, f = 0 because it vanishes on every generator of A ‚äóR B.
We now show that œÑ is surjective. If F : A ‚ÜíHomS(B, C) is an R-map, deÔ¨Åne
œï : A √ó B ‚ÜíC by œï(a, b) = Fa(b). Now consider the diagram
A √ó B
h

œï









A ‚äóR B
œï

C
It is straightforward to check that œï is R-biadditive, and so there exists a Z-homomorphism
œï : A ‚äóR B ‚ÜíC with œï(a ‚äób) = œï(a, b) = Fa(b) for all a ‚ààA and b ‚ààB. Therefore,
F = œÑ(œï), so that œÑ is surjective.
We let the reader prove that the indicated maps are natural transformations; diagrams
and the proof of their commutativity must be given.
‚Ä¢
Given any two functors F : C ‚ÜíD and G : D ‚ÜíC, we called the ordered pair (F, G)
an adjoint pair if, for each pair of objects C ‚ààC and D ‚ààD, there are bijections
œÑC,D : HomD(FC, D) ‚ÜíHomC(C, GD)
that are natural transformations in C and in D.
It follows from Theorem 8.99 that
( ‚äóR B, Hom(B, )) is an adjoint pair.

594
Algebras
Ch. 8
As promised earlier, here is another proof of Theorem 8.90, the right exactness of tensor
product. Since ( ‚äóR B, Hom(B , )) is an adjoint pair of functors, the right functor ‚äómust
preserve all direct limits, by Theorem 7.105. But cokernel is a direct limit, and a functor is
right exact if it preserves cokernels. Here is this proof in more concrete terms.
Proposition 8.100.
Let A be a right R-module, and let
B‚Ä≤
i‚ÜíB
p‚ÜíB‚Ä≤‚Ä≤ ‚Üí0
be an exact sequence of left R-modules. Then
A ‚äóR B‚Ä≤ 1A‚äói
‚àí‚ÜíA ‚äóR B
1A‚äóp
‚àí‚ÜíA ‚äóR B‚Ä≤‚Ä≤ ‚Üí0
is an exact sequence of abelian groups.
Proof.
Regard a left R-module B as a (R, Z)-bimodule, and note, for any abelian group
C, that HomZ(B, C) is a right R-module, by Exercise 8.45 on page 603. In light of Propo-
sition 7.48, it sufÔ¨Åces to prove that the top row of the following diagram is exact for every
C:
0
 HomZ(A ‚äóR B‚Ä≤‚Ä≤, C)

œÑ ‚Ä≤‚Ä≤
A,C

HomZ(A ‚äóR B, C)

œÑA,C

HomZ(A ‚äóR B‚Ä≤, C)
œÑ ‚Ä≤
A,C

0
 HomR(A, H‚Ä≤‚Ä≤)
 HomR(A, H)
 HomR(A, H‚Ä≤),
where H‚Ä≤‚Ä≤ = HomZ(B‚Ä≤‚Ä≤, C), H = HomZ(B, C), and H‚Ä≤ = HomZ(B‚Ä≤, C). By the adjoint
isomorphism, the vertical maps are isomorphisms and the diagram commutes. The bottom
row is exact, for it arises from the given exact sequence B‚Ä≤ ‚ÜíB ‚ÜíB‚Ä≤‚Ä≤ ‚Üí0 by Ô¨Årst
applying the left exact (contravariant) functor HomZ( , C), and then applying the left exact
(covariant) functor HomR(A, ). Exactness of the top row now follows from Exercise 8.51
on page 604.
‚Ä¢
In Theorem 7.92, we proved that Hom(A, ) preserves inverse limits; we now prove that
A‚äópreserves direct limits. This, too, follows from Theorem 7.105. However, we give
another proof based on the construction of direct limits.
Theorem 8.101.
If A is a right R-module and {Bi, œïi
j} is a direct system of left R-modules
(over any not necessarily directed index set I), then
A ‚äóR lim
‚àí‚ÜíBi ‚àº= lim
‚àí‚Üí(A ‚äóR Bi).
Proof.
Note that Exercise 7.66 on page 517 shows that {A ‚äóR Bi, 1 ‚äóœïi
j} is a direct
system, so that lim
‚àí‚Üí(A ‚äóR Bi) makes sense.
We begin by constructing lim
‚àí‚ÜíBi as the cokernel of a certain map between sums. For
each pair i, j ‚ààI with i ‚™Øj in the partially ordered index set I, deÔ¨Åne Bi j to be a module
isomorphic to Bi by a map bi ‚Üíbi j, where bi ‚ààBi, and deÔ¨Åne œÉ : 
i j Bi j ‚Üí
i Bi by
œÉ : bi ‚ÜíŒª jœïi
jbi ‚àíŒªibi,

Sec. 8.4
Tensor Products
595
where Œªi is the injection of Bi into the sum. Note that im œÉ = S, the submodule arising in
the construction of lim
‚àí‚ÜíBi in Proposition 7.94. Thus, coker œÉ = ( Bi)/S ‚àº= lim
‚àí‚ÜíBi, and
there is an exact sequence

Bi j
œÉ‚Üí

Bi ‚Üílim
‚àí‚ÜíBi ‚Üí0.
Right exactness of A‚äóR
gives exactness of
A ‚äóR

Bi j
 1‚äóœÉ
‚àí‚ÜíA ‚äóR

Bi

‚ÜíA ‚äóR (lim
‚àí‚ÜíBi) ‚Üí0.
By Theorem 8.87, the map œÑ : A ‚äóR

i Bi

‚Üí
i(A ‚äóR Bi), given by
œÑ : a ‚äó(bi) ‚Üí(a ‚äóbi),
is an isomorphism, and so there is a commutative diagram
A ‚äó Bi j
1‚äóœÉ

œÑ

A ‚äó Bi
œÑ ‚Ä≤

 A ‚äólim
‚àí‚ÜíBi


0
(A ‚äóBi j)
œÉ
 (A ‚äóBi)
 lim
‚àí‚Üí(A ‚äóBi)
 0,
where œÑ ‚Ä≤ is another instance of the isomorphism of Theorem 8.87, and
œÉ : a ‚äóbi j ‚Üí(1 ‚äóŒª j)(a ‚äóœïi
jbi) ‚àí(1 ‚äóŒªi)(a‚Ä≤ ‚äóbi).
By Proposition 8.93, there is an isomorphism A ‚äóR lim
‚àí‚ÜíBi ‚ÜícokerœÉ ‚àº= lim
‚àí‚Üí(A ‚äóR Bi),
the direct limit of the direct system {A ‚äóR Bi, 1 ‚äóœïi
j}.
‚Ä¢
The reader has probably observed that we have actually proved a stronger result: any
right exact functor that preserves sums must preserve all direct limits. The dual result
also holds, and it has a similar proof; every left exact functor that preserves products must
preserve all inverse limits. In fact, if (F, G) is an adjoint pair of functors (deÔ¨Åned on
module categories), then F preserves direct limits and G preserves inverse limits.
Corollary 8.102.
If {Fi, œïi
j} is a direct system of Ô¨Çat right R-modules over a directed
index set I, then lim
‚àí‚ÜíFi is also Ô¨Çat.
Proof.
Let 0 ‚ÜíA
k
‚àí‚ÜíB be an exact sequence of left R-modules. Since each Fi is Ô¨Çat,
the sequence
0 ‚ÜíFi ‚äóR A
1i‚äók
‚àí‚ÜíFi ‚äóR B
is exact for every i, where 1i abbreviates 1Fi . Consider the commutative diagram
0
 lim
‚àí‚Üí(Fi ‚äóA)
‚Éók

œï

lim
‚àí‚Üí(Fi ‚äóB)
œà

0
 (lim
‚àí‚ÜíFi) ‚äóA
1‚äók  (lim
‚àí‚ÜíFi) ‚äóB,

596
Algebras
Ch. 8
where the vertical maps œï and œà are the isomorphisms of Theorem 8.101, the map ‚Éók is
induced from the transformation of direct systems {1i ‚äók}, and 1 is the identity map on
lim
‚àí‚ÜíFi. Since each Fi is Ô¨Çat, the maps 1i ‚äók are injections; since the index set I is directed,
the top row is exact, by Proposition 7.100. Therefore, 1‚äók : (lim
‚àí‚ÜíFi)‚äóA ‚Üí(lim
‚àí‚ÜíFi)‚äóB
is an injection, for it is the composite of injections œà‚Éókœï‚àí1. Therefore, lim
‚àí‚ÜíFi is Ô¨Çat.
‚Ä¢
Corollary 8.103.
(i) If R is a domain with Q = Frac(R), then Q is a Ô¨Çat R-module.
(ii) If every Ô¨Ånitely generated submodule of a right R-module M is Ô¨Çat, then M is Ô¨Çat.
Proof.
(i) In Example 7.97(v), we saw that Q is a direct limit, over a directed index set,
of cyclic submodules, each of which is isomorphic to R. Since R is projective, hence Ô¨Çat,
the result follows from Corollary 8.102.
(ii) In Example 7.99(iii), we saw that M is a direct limit, over a directed index set, of its
Ô¨Ånitely generated submodules. Since every Ô¨Ånitely generated submodule is Ô¨Çat, by hypoth-
esis, the result follows from Corollary 8.102. We have given another proof of Lemma 8.97.
‚Ä¢
Corollary 7.75 can be extended from abelian groups to modules over any ring.
Theorem 8.104.
For every ring R, every left R-module M can be imbedded as a sub-
module of an injective left R-module.
Proof.
Regarding R as a bimodule ZRR and an abelian group D as a left Z-module, we
use Exercise 8.45 on page 603 to see that HomZ(R, D) is a left R-module; the scalar
multiplication R √ó HomZ(R, D) ‚ÜíHomZ(R, D) is given by (a, œï) ‚Üíaœï, where
aœï : r ‚Üíœï(ra).
If now D is a divisible abelian group, we claim that H = HomZ(R, D) is an injec-
tive R-module; that is, we show that HomR(
, H) is an exact functor. Since Hom is
left exact, it sufÔ¨Åces to show that if i : A‚Ä≤ ‚ÜíA is an injection, then the induced map
i‚àó: HomR(A, H) ‚ÜíHomR(A‚Ä≤, H) is a surjection. Consider the following diagram.
HomR(A, HomZ(R, D))
i‚àó


HomR(A‚Ä≤, HomZ(R, D))

HomZ(A ‚äóR R, D)


HomZ(A‚Ä≤ ‚äóR R, D)

HomZ(A, D)
 HomZ(A‚Ä≤, D)
The adjoint isomorphism gives commutativity of the top square. The bottom square arises
from applying the contravariant functor HomZ(
, D) to the following diagram, which

Sec. 8.4
Tensor Products
597
commutes because the isomorphism A ‚ÜíA ‚äóR R, given by a ‚Üía ‚äó1, is natural.
A ‚äóR R
A‚Ä≤ ‚äóR R

A

A‚Ä≤


Since D is divisible, Corollary 7.73 says that D is an injective Z-module. Therefore,
HomZ(
, D) is an exact functor and the bottom row in the large diagram is surjective.
Since all the vertical maps in the large diagram are isomorphisms, commutativity now
gives i‚àósurjective. We conclude that HomZ(R, D) is an injective left R-module.
Finally, regard M as an abelian group. By Corollary 7.75, there is a divisible abelian
group D and an injective Z-homomorphism j : M ‚ÜíD. It is now easy to see that there is
an injective R-map M ‚ÜíHomZ(R, D), namely, m ‚Üífm, where fm(r) = j(rm) ‚ààD;
this completes the proof.
‚Ä¢
This last theorem can be improved, for there is a smallest injective module containing
any given module, called its injective envelope (see Rotman, An Introduction to Homolog-
ical Algebra, page 73).
We have already seen, in Proposition 7.69, that if R is a noetherian ring, then every
direct sum of injective modules is injective; we now prove the converse.
Theorem 8.105 (Bass).
If R is a ring for which every direct sum of injective left R-
modules is injective, then R is left noetherian.
Proof.
We show that if R is not left noetherian, then there is a left ideal I and an R-map
to a sum of injectives that cannot be extended to R. Since R is not left noetherian, there
is a strictly ascending chain of left ideals I1 ‚ääI2 ‚ää¬∑ ¬∑ ¬∑ ; let I = ! In. We note that
I/In Ã∏= {0} for all n. By Theorem 8.104, we may imbed I/In in an injective left R-module
En; we claim that E = 
n En is not injective.
Let œÄn : I ‚ÜíI/In be the natural map. For each a ‚ààI, note that œÄn(a) = 0 for large n
(because a ‚ààIn for some n), and so the R-map f : I ‚Üí(I/In), deÔ¨Åned by
f : a ‚Üí(œÄn(a)),
does have its image in 
n(I/In); that is, for each a ‚ààI, almost all the coordinates of
f (a) are 0. Composing with the inclusion (I/In) ‚Üí En = E, we may regard f as
a map I ‚ÜíE. If there is an R-map g : R ‚ÜíE extending f , then g(1) is deÔ¨Åned; say,
g(1) = (xn). Choose an index m and choose a ‚ààI with a /‚ààIm; since a /‚ààIm, we have
œÄm(a) Ã∏= 0, and so g(a) = f (a) has nonzero mth coordinate œÄm(a). But g(a) = ag(1) =
a(xn) = (axn), so that œÄm(a) = axm. It follows that xm Ã∏= 0 for all m, and this contradicts
g(1) lying in the direct sum E =  En.
‚Ä¢
We are now going to give a connection between Ô¨Çat modules and projective modules.

598
Algebras
Ch. 8
DeÔ¨Ånition.
If B is a right R-module, deÔ¨Åne its character module B‚àóas the left R-module
B‚àó= HomZ(B, Q/Z).
Recall that B‚àóis a left R-module if one deÔ¨Ånes r f , for r ‚ààR and f : B ‚ÜíQ/Z, by
r f : b ‚Üíf (br).
The next lemma improves Proposition 7.48: If i : A‚Ä≤ ‚ÜíA and p: A ‚ÜíA‚Ä≤‚Ä≤ are maps
and, for every module B,
0 ‚ÜíHom(A‚Ä≤‚Ä≤, B)
p‚àó
‚àí‚ÜíHom(A, B)
i‚àó
‚àí‚ÜíHom(A‚Ä≤, B)
is an exact sequence, then so is
A‚Ä≤
i
‚àí‚ÜíA
p
‚àí‚ÜíA‚Ä≤‚Ä≤ ‚Üí0.
Lemma 8.106.
A sequence of right R-modules
0 ‚ÜíA
Œ±
‚àí‚ÜíB
Œ≤
‚àí‚ÜíC ‚Üí0
is exact if and only if the sequence of character modules
0 ‚ÜíC‚àó
Œ≤‚àó
‚àí‚ÜíB‚àó
Œ±‚àó
‚àí‚ÜíA‚àó‚Üí0
is exact.
Proof.
If the original sequence is exact, then so is the sequence of character modules, for
the contravariant functor HomZ( , Q/Z) is exact, because Q/Z is an injective Z-module,
by Corollary 7.73.
For the converse, it sufÔ¨Åces to prove that ker Œ± = im Œ≤ without assuming either Œ±‚àó
surjective or Œ≤‚àóis injective.
im Œ± ‚äÜker Œ≤.
If x ‚ààA and Œ±x /‚ààker Œ≤, then Œ≤Œ±(x) Ã∏= 0. By Exercise 7.57(i) on page 488, there is a
map f : C ‚ÜíQ/Z with fŒ≤Œ±(x) Ã∏= 0. Thus, f ‚ààC‚àóand fŒ≤Œ± Ã∏= 0, which contradicts the
hypothesis that Œ±‚àóŒ≤‚àó= 0.
ker Œ≤ ‚äÜim Œ±.
If y ‚ààker Œ≤ and y /‚ààim Œ±, then y + im Œ± is a nonzero element of B/ im Œ±. Thus, there
is a map g : B/ im Œ± ‚ÜíQ/Z with g(y + im Œ±) Ã∏= 0, by Exercise 7.57(i) on page 488.
If ŒΩ : B ‚ÜíB/ im Œ± is the natural map, deÔ¨Åne g‚Ä≤ = gŒΩ ‚ààB‚àó; note that g‚Ä≤(y) Ã∏= 0, for
g‚Ä≤(y) = gŒΩ(y) = g(y + im Œ±). Now g‚Ä≤(im Œ±) = {0}, so that 0 = g‚Ä≤Œ± = Œ±‚àó(g‚Ä≤) and
g‚Ä≤ ‚ààker Œ±‚àó= im Œ≤‚àó. Thus, g‚Ä≤ = Œ≤‚àó(h) for some h ‚ààC‚àó; that is, g‚Ä≤ = hŒ≤. Hence, g‚Ä≤(y) =
hŒ≤(y), which is a contradiction, for g‚Ä≤(y) Ã∏= 0, while hŒ≤(y) = 0, because y ‚ààker Œ≤.
‚Ä¢

Sec. 8.4
Tensor Products
599
Proposition 8.107.
A right R-module B is Ô¨Çat if and only if its character module B‚àóis
an injective left R-module.
Proof.
As in the proof of Theorem 8.104 with B playing the role of R (so that Ô¨Çat-
ness implies that the map A‚Ä≤ ‚äóR B ‚ÜíA ‚äóR B is injective), the left R-module B‚àó=
HomZ(B, Q/Z) is injective.
Conversely, assume that B‚àóis an injective left R-module and A‚Ä≤ ‚ÜíA is an injection
between left R-modules A‚Ä≤ and A. Since HomR(A, B‚àó) = HomR(A, HomZ(B, Q/Z)),
the adjoint isomorphism, Theorem 8.99, gives a commutative diagram in which the vertical
maps are isomorphisms.
HomR(A, B‚àó)


HomR(A‚Ä≤, B‚àó)


0
HomZ(B ‚äóR A, Q/Z)
 HomZ(B ‚äóA‚Ä≤, Q/Z)
 0
(B ‚äóR A)‚àó
 (B ‚äóR A‚Ä≤)‚àó
 0
Exactness of the top row now gives exactness of the bottom row. By Lemma 8.106, the
sequence 0 ‚ÜíB ‚äóR A‚Ä≤ ‚ÜíB ‚äóR A is exact, and this gives B Ô¨Çat.
‚Ä¢
Corollary 8.108.
A right R-module B is Ô¨Çat if and only if, for every Ô¨Ånitely generated
left ideal I, the sequence 0 ‚ÜíB ‚äóR I ‚ÜíB ‚äóR R is exact.
Proof.
If B is Ô¨Çat, then the sequence 0 ‚ÜíB ‚äóR I ‚ÜíB ‚äóR R is exact for every left
R-module I; in particular, this sequence is exact when I is a Ô¨Ånitely generated left ideal.
Conversely, the hypothesis of exactness of 0 ‚ÜíB ‚äóR I ‚ÜíB ‚äóR R for every Ô¨Ånitely
generated left ideal I allows us to prove exactness of this sequence for every left ideal,
using Proposition 7.100 and the fact that tensor product commutes with direct limits. There
is an exact sequence (B ‚äóR R)‚àó‚Üí(B ‚äóR I)‚àó‚Üí0 that, by the adjoint isomorphism, gives
exactness of HomR(R, B‚àó) ‚ÜíHomR(I, B‚àó) ‚Üí0. This says that every map from an ideal
I to B‚àóextends to a map R ‚ÜíB‚àó; thus, B‚àósatisÔ¨Åes the Baer criterion, Theorem 7.68,
and so B‚àóis injective. By Proposition 8.107, B is Ô¨Çat.
‚Ä¢
Lemma 8.109.
Given modules (R X,R YS, ZS), where R and S are rings, there is a natural
transformation in X, Y, and Z
œÑX,Y,Z : HomS(Y, Z) ‚äóR X ‚ÜíHomS(HomR(X, Y), Z).
Moreover, œÑX,Y,Z an isomorphism whenever X is a Ô¨Ånitely generated free left R-module.
Proof.
Note that both HomS(Y, Z) and HomR(X, Y) make sense, for Y is a bimodule. If
f ‚ààHomS(Y, Z) and x ‚ààX, deÔ¨Åne œÑX,Y,Z( f ‚äóx) to be the S-map HomR(X, Y) ‚ÜíZ
given by
œÑX,Y,Z( f ‚äóx): g ‚Üíf (g(x)).

600
Algebras
Ch. 8
It is straightforward to check that œÑX,Y,Z is a homomorphism natural in X, that œÑR,Y,Z
is an isomorphism, and, more generally, that œÑX,Y,Z is an isomorphism when X is a Ô¨Ånitely
generated free left R-module.
‚Ä¢
Theorem 8.110.
A Ô¨Ånitely presented left R-module B is Ô¨Çat if and only if it is projective.
Proof.
All projective modules are Ô¨Çat, by Lemma 8.98, and so only the converse is sig-
niÔ¨Åcant. Since B is Ô¨Ånitely presented, there is an exact sequence
F‚Ä≤ ‚ÜíF ‚ÜíB ‚Üí0,
where both F‚Ä≤ and F are Ô¨Ånitely generated free left R-modules. We begin by showing,
for every left R-module Y [which is necessarily an (R ‚àíZ)-bimodule], that the map
œÑB = œÑB,Y,Q/Z : Y ‚àó‚äóR B ‚ÜíHomR(B, Y)‚àóof Lemma 8.109 is an isomorphism.
Consider the following diagram.
Y ‚àó‚äóR F‚Ä≤

œÑF‚Ä≤

Y ‚àó‚äóR F

œÑF

Y ‚àó‚äóR B
œÑB

 0
HomR(F‚Ä≤, Y)‚àó
 HomR(F, Y)‚àó
 HomR(B, Y)‚àó
 0
By Lemma 8.109, this diagram commutes [for Y ‚àó‚äóR F = HomZ(Y, Q/Z) ‚äóR F] and the
Ô¨Årst two vertical maps are isomorphisms. The top row is exact, because Y ‚àó‚äóR is right ex-
act. The bottom row is also exact, because HomR( , Y)‚àóis the composite of the contravari-
ant functors HomR( , Y), which is left exact, and ‚àó= HomZ( , Q/Z), which is exact.
Proposition 8.93 now shows that the third vertical arrow, œÑB : Y ‚àó‚äóR B ‚ÜíHomR(B, Y)‚àó,
is an isomorphism.
To prove that B is projective, it sufÔ¨Åces to prove that Hom(B, ) preserves surjections: If
A ‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is exact, then Hom(B, A) ‚ÜíHom(B, A‚Ä≤‚Ä≤) ‚Üí0 is exact. By Lemma 8.106,
it sufÔ¨Åces to show that 0 ‚ÜíHom(B, A‚Ä≤‚Ä≤)‚àó‚ÜíHom(B, A)‚àóis exact. Consider the diagram
0
 A‚Ä≤‚Ä≤ ‚àó‚äóR B

œÑ

A‚àó‚äóR B
œÑ

0
 Hom(B, A‚Ä≤‚Ä≤)‚àó
 Hom(B, A)‚àó
Naturality of œÑ gives commutativity of the diagram, while the vertical maps œÑ are isomor-
phisms, because B is Ô¨Ånitely presented. Since A ‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is exact, 0 ‚ÜíA‚Ä≤‚Ä≤‚àó‚ÜíA‚àó
is exact, and so the top row is exact, because B is Ô¨Çat. It follows that the bottom row is
also exact; that is, 0 ‚ÜíHom(B, A‚Ä≤‚Ä≤)‚àó‚ÜíHom(B, A‚Ä≤‚Ä≤)‚àóis exact, which is what we were
to show. Therefore, B is projective.
‚Ä¢

Sec. 8.4
Tensor Products
601
Corollary 8.111.
If R is right noetherian, then a Ô¨Ånitely generated right R-module B is
Ô¨Çat if and only if it is projective.
Proof.
This follows from the theorem once we recall Proposition 7.59 (which holds for
noncommutative rings): Every Ô¨Ånitely generated module over a noetherian ring is Ô¨Ånitely
presented.
‚Ä¢
Here is a nice application of tensor products that helps to place the Wedderburn-Artin
theorems in perspective.
DeÔ¨Ånition.
A module P is small if the covariant Hom functor Hom(P,
) preserves
(possibly inÔ¨Ånite) direct sums.
For example, Proposition 8.85 shows that every ring R is a small R-module.
To say that P is small means more than that there is some isomorphism
Hom

P,

i‚ààI
Bi
 ‚àº=

i‚ààI
Hom(P, Bi);
it also means that Hom(P, ) preserves the coproduct diagram; if Œªi : Bi ‚ÜíB are the in-
jections, where B = 
i‚ààI Bi, then the induced maps (Œªi)‚àó: Hom(P, Bi) ‚ÜíHom(P, B)
are the injections of 
i‚ààI Hom(P, Bi).
Example 8.112.
(i) Any Ô¨Ånite direct sum of small modules is small, and any direct summand of a small
module is small.
(ii) Since a ring R is a small R-module, it follows from (i) that every Ô¨Ånitely generated free
R-module is small and that every Ô¨Ånitely generated projective R-module is small.
‚óÄ
DeÔ¨Ånition.
A right R-module P is a generator of ModR if every right R-module M is a
quotient of some direct sum of copies of P.
It is clear that R is a generator of ModR, as is any free right R-module. However, a
projective right R-module may not be a generator. For example, if R = I6, then R =
P ‚äïQ, where P = {[0], [2], [4]} ‚àº= I3, and the projective module P is not a generator (for
Q ‚àº= I2 is not a quotient of a direct sum of copies of P).
Theorem 8.113.
Let R be a ring and let P be a small projective generator of ModR. If
S = EndR(P), then there is an equivalence of categories
ModR ‚àº= ModS.
Proof.
Notice that P is a left S-module, for if x ‚ààP and f, g ‚ààS = EndR(P), then
(g ‚ó¶f )x = g( f x). In fact, P is a (S, R)-bimodule, for associativity f (xr) = ( f x)r,
where r ‚ààR, is just the statement that f is an R-map. It now follows from Corollary 8.81

602
Algebras
Ch. 8
that the functor F : ModS ‚ÜíAb, deÔ¨Åned by F = ‚äóS P, actually takes values in ModR.
Exercise 8.45(ii) on page 603 shows that the functor G : HomR(P,
): ModR ‚ÜíAb
actually takes values in ModS. As (F, G) is an adjoint pair, Exercise 7.75 on page 518
gives natural transformations FG ‚Üí1R and 1S ‚ÜíGF, where 1R and 1S denote identity
functors on the categories ModR and ModS, respectively. It sufÔ¨Åces to prove that each of
these natural transformations is a natural equivalence.
Since P is a projective right R-module, the functor G = HomR(P, ) is exact; since P
is small, G preserves direct sums. Now F =
‚äóS P, as any tensor product functor, is right
exact and preserve sums. Therefore, both composites GF and FG preserve direct sums
and are right exact.
Note that
FG(P) = F(HomR(P, P)) = F(S) = S ‚äóS P ‚àº= P.
Since P is a generator of ModR, every right R-module M is a quotient of some direct sum
of copies of P: There is an exact sequence K ‚Üí P
f
‚àí‚ÜíM ‚Üí0, where K = ker f .
There is also some direct sum of copies of P mapping onto K, and so there is an exact
sequence

P ‚Üí

P ‚ÜíM ‚Üí0.
Hence, there is a commutative diagram (by naturality of the upward maps) with exact rows
 P
  P
 M
 0
 FG(P)

  FG(P)

 FG(M)

 0
We know that the Ô¨Årst two vertical maps are isomorphisms, and so a diagram chase (see
the Ô¨Åve lemma, Exercise 8.52 on page 604) gives the other vertical map an isomorphism;
that is, FG(M) ‚àº= M, and so 1R ‚àº= FG.
For the other composite, note that
GF(S) = G(S ‚äóS P) ‚àº= G(P) = HomR(P, P) = S.
If N is any left S-module, there is an exact sequence of the form

S ‚Üí

S ‚ÜíN ‚Üí0,
because every module is a quotient of a free module. The argument now concludes as that
just done.
‚Ä¢
Corollary 8.114.
If R is a ring and n ‚â•1, there is an equivalence of categories
ModR ‚àº= ModMatn(R).

Sec. 8.4
Tensor Products
603
Remark.
There is an equivalence of categories RopMod ‚ÜíModR, by Exercise 8.22 on
page 533. In particular, if R is commutative, then
RMod ‚àº= ModMatn(R).
‚óÄ
Proof.
For any integer n ‚â•1, the free module P = n
i=1 Ri, where Ri ‚àº= R, is a small
projective generator of ModR, and S = EndR(P) ‚àº= Matn(R).
‚Ä¢
We can now understand Proposition 8.49: Matn() is semisimple when  is a division
ring. By Proposition 8.48, a ring R is semisimple if and only if every R-module is projec-
tive; that is, every object in ModR is projective. Now every -module is projective (even
free), so that equivalence of the categories shows that every object in ModMatn() is also
projective. Therefore, Matn() is also semisimple.
There is a circle of ideas, usually called Morita theory (after K. Morita). The Ô¨Årst
question it asks is when an abstract category C is equivalent to ModR for some ring R. The
answer is very nice: A category C is isomorphic to a module category if and only if it is an
abelian category (this just means that the usual Ô¨Ånitary constructions in the second section
of Chapter 7 exist; see Mac Lane, Categories for the Working Mathematician, pages 187-
206), it is closed under inÔ¨Ånite coproducts, and it contains a small projective object P that
is a generator. Given this hypothesis, then C ‚àº= ModS, where S = End(P) (the proof is
essentially that given for Theorem 8.113).
Two rings R and S are called Morita equivalent if ModR ‚àº= ModS. For example, it
follows from Theorem 8.113 that every commutative ring R is Morita equivalent to the
ring Matn(R), where n ‚â•1. Moreover, if R and S are Morita equivalent, then Z(R) ‚àº=
Z(S); that is, they have isomorphic centers (the proof actually identiÔ¨Åes all the possible
isomorphisms between the categories). In particular, two commutative rings are Morita
equivalent if and only if they are isomorphic. See Jacobson, Basic Algebra II, pages 177-
184, Lam, Lectures on Modules and Rings, Chapters 18 and 19, and Reiner, Maximal
Orders, Chapter 4.
In the next chapter, we will see that the tensor product R‚äók S of two k-algebras R and S
is also a k-algebra. Indeed, when R and S are commutative, then R ‚äók S is their coproduct
in the category of commutative k-algebras.
EXERCISES
8.45 This exercise is an analog of Corollary 8.81.
(i) Given a bimodule R AS, prove that HomR(A, ): RMod ‚ÜíSMod is a functor, where
HomR(A, B) is the left S-module deÔ¨Åned by s f : a ‚Üíf (as).
(ii) Given a bimodule R AS, prove that HomS(A, ): ModS ‚ÜíModR is a functor, where
HomS(A, B) is the right R-module deÔ¨Åned by f r : a ‚Üíf (ra).
(iii) Given a bimodule S BR, prove that HomR( , B): ModR ‚ÜíSMod is a functor, where
HomR(A, B) is the left S-module deÔ¨Åned by s f : a ‚Üís[ f (a)].
(iv) Given a bimodule S BR, prove that HomS(A, ): SMod ‚ÜíModR is a functor, where
HomS(A, B) is the right R-module deÔ¨Åned by f r : a ‚Üíf (a)r.

604
Algebras
Ch. 8
Remark.
Let f : A ‚ÜíB be an R-map. Suppose we write f (a) when A is a right R-module
and (a) f when A is a left R-module (that is, write the function symbol f on the side opposite
the scalar action). With this notation, each of the four parts of this exercise is an associative
law. For example, in part (i) with both A and B left R-modules, writing s f for s ‚ààS, we have
a(s f ) = (as) f . Similarly, in part (ii), we deÔ¨Åne f r, for r ‚ààR so that ( f r)a = f (ra).
‚óÄ
8.46 Let V and W be Ô¨Ånite-dimensional vector spaces over a Ô¨Åeld F, say, and let v1, . . . , vm and
w1, . . . , wn be bases of V and W, respectively. Let S : V ‚ÜíV be a linear transformation
having matrix A = [ai j], and let T : W ‚ÜíW be a linear transformation having matrix
B = [bk‚Ñì]. Show that the matrix of S ‚äóT : V ‚äók W ‚ÜíV ‚äók W, with respect to a suitable
listing of the vectors vi ‚äów j, is the nm √ó nm matrix K, which we write in block form:
A ‚äóB =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£∞
a11B
a12B
¬∑ ¬∑ ¬∑
a1m B
a21B
a22B
¬∑ ¬∑ ¬∑
a2m B
...
...
...
...
am1B
am2B
¬∑ ¬∑ ¬∑
amm B
Ô£π
Ô£∫Ô£∫Ô£∫Ô£ª.
The matrix A ‚äóB is called the Kronecker product of the matrices A and B.
8.47 Let R be a domain with Q = Frac(R). If A is an R-module, prove that every element in
Q ‚äóR A has the form q ‚äóa for q ‚ààQ and a ‚ààA (instead of 
i qi ‚äóai). (Compare this
result with Example 8.89.)
8.48 Let m and n be positive integers, and let d = (m, n). Prove that there is an isomorphism of
abelian groups
Im ‚äóIn ‚àº= Id.
8.49 Let k be a commutative ring, and let P and Q be projective k-modules. Prove that P ‚äók Q is
a projective k-module.
8.50 Let k be a commutative ring, and let P and Q be Ô¨Çat k-modules. Prove that P ‚äók Q is a Ô¨Çat
k-module.
8.51 Assume that the following diagram commutes, and that the vertical arrows are isomorphisms.
0
 A‚Ä≤


A


A‚Ä≤‚Ä≤


0
0
 B‚Ä≤
 B
 B‚Ä≤‚Ä≤
 0
Prove that the bottom row is exact if and only if the top row is exact.
8.52 (Five Lemma). Consider a commutative diagram with exact rows
A1

h1

A2

h2

A3

h3

A4

h4

A5
h5

B1
 B2
 B3
 B4
 B5
(i) If h2 and h4 are surjective and h5 is injective, prove that h3 is surjective.
(ii) If h2 and h4 are injective and h1 is surjective, prove that h3 is injective.

Sec. 8.5
Characters
605
(iii) If h1, h2, h4, and h5 are isomorphisms, prove that h3 is an isomorphism.
8.53 Prove that a ring R is left noetherian if and only if every direct limit (with directed index set)
of injective left R-modules is itself injective.
Hint. See Theorem 8.105.
8.54 Let A, B, and C be categories. A functor of two variables T : A √ó B ‚ÜíC assigns, to each
ordered pair of objects (A, B), where A ‚ààob(A) and B ‚ààob(B), an object T (A, B) ‚ààob(C),
and to each ordered pair of morphisms f : A ‚ÜíA‚Ä≤ in A and g: B ‚ÜíB‚Ä≤ in B, a morphism
T ( f, g): T (A, B) ‚ÜíT (A‚Ä≤, B‚Ä≤), such that
(a) Fixing either variable is a functor: for example, if A ‚ààob(A), then
TA = T (A, ): B ‚ÜíC
is a functor, where TA(B) = T (A, B) and TA(g) = T (1A, g).
(b) The following diagram commutes:
T (A, B)
T (1A,g)
T ( f,g)
*%
%
%
%
%
%
%
%
%
%
T ( f,1B)

T (A, B‚Ä≤)
T ( f,1B‚Ä≤)

T (A‚Ä≤, B) T (1A‚Ä≤,g)
 T (A‚Ä≤, B‚Ä≤)
(i) Prove that ‚äó: ModR √ó RMod ‚ÜíAb is a functor of two variables.
(ii) Modify the deÔ¨Ånition of a functor of two variables to allow contravariance in a variable,
and prove that Hom is a functor of two variables.
8.5 CHARACTERS
Representation theory is the study of homomorphisms of abstract groups G into groups
of nonsingular matrices; such homomorphisms produce numerical invariants whose arith-
metic properties help to prove theorems about G. We now introduce this vast subject with
one goal being a proof of the following theorem.
Theorem 8.115 (Burnside).
Every group G of order pmqn, where p and q are primes,
is a solvable group.
Notice that Burnside's theorem cannot be improved to groups having orders with only
three distinct prime factors, for A5 is a simple group of order 60 = 22 ¬∑ 3 ¬∑ 5.
Using representations, we will prove the following theorem.
Theorem.
If G is a nonabelian Ô¨Ånite simple group, then {1} is the only conjugacy class
whose size is a prime power.

606
Algebras
Ch. 8
Proposition 8.116.
The preceding theorem implies Burnside's theorem.
Proof.
Assume that Burnside's theorem is false, and let G be a "least criminal"; that
is, G is a counterexample of smallest order. If G has a proper normal subgroup H with
H Ã∏= {1}, then both H and G/H are solvable, for their orders are smaller than |G| and are
of the form piq j. By Proposition 4.24, G is solvable, and this is a contradiction. We may
assume, therefore, that G is a nonabelian simple group.
Let Q be a Sylow q-subgroup of G. If Q = {1}, then G is a p-group, contradicting G
being a nonabelian simple group; hence, Q Ã∏= {1}. Since the center of Q is nontrivial, by
Theorem 2.103, we may choose a nontrivial element x ‚ààZ(Q). Now Q ‚â§CG(x), for
every element in Q commutes with x, and so
[G : Q] = [G : CG(x)][CG(x) : Q];
that is, [G : CG(x)] is a divisor of [G : Q] = pm. Of course, [G : CG(x)] is the number
of elements in the conjugacy class xG of x (Corollary 2.100), and so the hypothesis says
that |xG| = 1; hence, x ‚ààZ(G), which contradicts G being simple.
‚Ä¢
The proof that the hypothesis of the proposition is true will use representation theory
(see Theorem 8.153).
We now specialize the deÔ¨Ånition of k-representation on page 550 from arbitrary Ô¨Åelds
k of scalars to the complex numbers C.
DeÔ¨Ånition.
A representation of a group G is a homomorphism
œÉ : G ‚ÜíGL(V ),
where V is a vector space over C. The degree of œÉ is dim(V ).
For the remainder of this section, we restrict ourselves to Ô¨Ånite groups and represen-
tations having Ô¨Ånite degree. If a representation œÉ : G ‚ÜíGL(V ) has degree n and one
chooses a basis of V , then each œÉ(g) can be regarded as an n √ó n nonsingular matrix with
entries in C.
Representations can be translated into the language of modules. In Proposition 8.37,
we proved that every representation œÉ : G ‚ÜíGL(V ) equips V with the structure of a
left CG-module (and conversely): If g ‚ààG, then œÉ(g): V ‚ÜíV , and we deÔ¨Åne scalar
multiplication gv, for g ‚ààG and v ‚ààV , by
gv = œÉ(g)(v).
Example 8.117.
We now show that permutation representations, that is, G-sets,9 give a special kind of
representation. A G-set X corresponds to a homomorphism œÄ : G ‚ÜíSX, where SX is
the symmetric group of all permutations of X. If V is the complex vector space having
X as a basis, then we may regard SX ‚â§GL(V ) in the following way. Each permutation
9Recall that if a group G acts on a set X, then X is called a G-set.

Sec. 8.5
Characters
607
œÄ(g) of X, where g ‚ààG, is now a permutation of a basis of V and, hence, it determines a
nonsingular linear transformation on V . With respect to the basis X, the matrix of œÄ(g) is
a permutation matrix: It arises by permuting the columns of the identity matrix I by œÄ(g);
thus, it has exactly one entry equal to 1 in each row and column while all its other entries
are 0.
‚óÄ
One of the most important representations is the regular representation; in terms of
modules, the regular representation is the group algebra CG regarded as a left module over
itself.
DeÔ¨Ånition.
If G is a group, then the representation œÅ : G ‚ÜíGL(CG) deÔ¨Åned, for all
g, h ‚ààG, by
œÅ(g): h ‚Üígh,
is called the regular representation.
Two representations œÉ : G ‚ÜíGL(V ) and œÑ : G ‚ÜíGL(W) can be added.
DeÔ¨Ånition.
If œÉ : G ‚ÜíGL(V ) and œÑ : G ‚ÜíGL(W) are representations, then their sum
œÉ + œÑ : G ‚ÜíGL(V ‚äïW) is deÔ¨Åned by
(œÉ + œÑ)(g): (v, w) ‚Üí(œÉ(g)v, œÑ(g)w)
for all g ‚ààG, v ‚ààV , and w ‚ààW.
In matrix terms, if œÉ : G ‚ÜíGL(n, C) and œÑ : G ‚ÜíGL(m, C), then
œÉ + œÑ : G ‚ÜíGL(n + m, C),
and if g ‚ààG, then (œÉ + œÑ)(g) is the direct sum of blocks œÉ(g) ‚äïœÑ(g); that is,
(œÉ + œÑ)(g) =
œÉ(g)
0
0
œÑ(g)

.
The following terminology is the common one used in group representations.
DeÔ¨Ånition.
A representation œÉ of a group G is irrreducible if the corresponding CG-
module is simple; a representation œÉ is completely reducible if it is a direct sum of irre-
ducible representations; that is, the corresponding CG-module is semisimple.
Example 8.118.
A representation œÉ is linear if degree(œÉ) = 1. The trivial representation of any group G
is linear, for the principal module V0(C) is one-dimensional. If G = Sn, then sgn: G ‚Üí
{¬±1} is also a linear representation.
Every linear representation is irreducible, for the corresponding CG-module must be
simple; after all, every submodule is a subspace, and {0} and V are the only subspaces of a
one-dimensional vector space V . It follows that the trivial representation of any group G
is irreducible, as is the representation sgn of Sn.
‚óÄ

608
Algebras
Ch. 8
Recall the proof of the Wedderburn-Artin theorem: There are pairwise nonisomorphic
minimal left ideals L1, . . . , Lr in CG and CG = B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBr, where Bi is generated
by all minimal left ideals isomorphic to Li. Now Bi ‚àº= Matni (C), by Corollary 8.65.
But all minimal left ideals in Matni (C) are isomorphic, by Lemma 8.61(ii), so that Li ‚àº=
COL(1) ‚àº= Cni (see Example 8.30). Therefore,
Bi ‚àº= End(Li),
where we have abbreviated EndC(Li) to End(Li).
Proposition 8.119.
(i) For each minimal left ideal Li in CG, there is an irreducible representation Œªi : G ‚Üí
GL(Li), given by left multiplication:
Œªi(g): ui ‚Üígui,
where g ‚ààG and ui ‚ààLi; moreover, degree(Œªi) = ni = dim(Li).
(ii) The representation Œªi extends to a C-algebra mapŒªi : CG ‚ÜíCG if we deÔ¨Åne
Œªi(g)u j =

gui
i f j = i
0
i f j Ã∏= i
(2)
for g ‚ààG and u j ‚ààB j.
Proof.
(i) Since Li is a left ideal in CG, each g ‚ààG acts on Li by left multiplication, and
so the corresponding representation Œªi of G is as stated; it is an irreducible representation
because minimal left ideals are simple modules.
(ii) If we regard CG and End(Li) as vector spaces over C, then Œªi extends to a linear
transformationŒªi : CG ‚ÜíEnd(Li) (because the elements of G are a basis of CG):
Œªi :

g
cgg ‚Üí

g
cgŒªi(g).
Let us show thatŒªi : CG ‚ÜíEnd(Li) is actually a C-algebra map. If ui ‚ààLi and g, h ‚ààG,
then
Œªi(gh): ui ‚Üí(gh)ui,
while
Œªi(g)Œªi(h): ui ‚Üíhui ‚Üíg(hui);
these are the same, by associativity.
At the moment, Œªi(g)ui is deÔ¨Åned only for ui ‚ààBi = End(Li). For each g ‚ààG,
we now extend the map Œªi(g) to CG = B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBr by deÔ¨Åning Œªi(g)u j = 0, where
u j ‚ààB j ‚àº= End(L j) and j Ã∏= i. The extended mapŒªi(g) (we keep the same notation even
though its target has been enlarged from Bi to CG) is also a CG-algebra map. If j Ã∏= i, then
uiu j ‚ààBi B j = {0}, so thatŒªi(g)(uiu j) = 0; on the other hand, (Œªi(g)ui)(Œªi(g)u j) = 0,
by deÔ¨Ånition.
‚Ä¢

Sec. 8.5
Characters
609
It is natural to call two representations equivalent if their corresponding modules are
isomorphic.
DeÔ¨Ånition.
If G is a group and œÉ, œÑ : G ‚ÜíGL(n, C) are representations, then œÉ and œÑ
are equivalent, denoted by œÉ ‚àºœÑ, if there is a nonsingular n √ó n matrix P that intertwines
them; that is,
PœÉ(g)P‚àí1 = œÑ(g)
for every g ‚ààG.
Of course, this deÔ¨Ånition comes from Corollary 8.39, which says that the CG-modules
(Cn)œÉ and (Cn)œÑ are isomorphic as CG-modules if and only if œÉ ‚àºœÑ.
Corollary 8.120.
(i) Every irreducible representation of a Ô¨Ånite group G is equivalent to one of the rep-
resentations Œªi given in Proposition 8.119(i).
(ii) Every irreducible representation of a Ô¨Ånite abelian group is linear.
(iii) If œÉ : G ‚ÜíGL(V ) is a representation of a Ô¨Ånite group G, then œÉ(g) is similar to a
diagonal matrix for each g ‚ààG.
Proof.
(i) If œÉ : G ‚ÜíGL(V ) is an irreducible representation œÉ, then the corresponding
CG-module V œÉ is a simple module. Therefore, V œÉ ‚àº= Li, for some i, by Proposition 8.54.
But Li ‚àº= V Œªi , so that V œÉ ‚àº= V Œªi and œÉ ‚àºŒªi.
(ii) Since G is abelian, CG = 
i Bi is commutative, and so all ni = 1. But ni =
degree(Œªi).
(iii) If œÉ ‚Ä≤ = œÉ|‚ü®g‚ü©, then œÉ ‚Ä≤(g) = œÉ(g). Now œÉ ‚Ä≤ is a representation of the abelian group
‚ü®g‚ü©, and so part (ii) implies that the module V ‚ü®g‚ü©is a direct sum of one-dimensional sub-
modules. If V ‚ü®g‚ü©= ‚ü®v1‚ü©‚äï¬∑ ¬∑ ¬∑ ‚äï‚ü®vm‚ü©, then the matrix of œÉ(g) with respect to the basis
v1, . . . , vm is diagonal.
‚Ä¢
Example 8.121.
(i) The Wedderburn-Artin theorem can be restated to say that every representation œÑ : G ‚Üí
GL(V ) is completely reducible: œÑ = œÉ1 +¬∑ ¬∑ ¬∑+œÉk, where each œÉ j is irreducible; moreover,
the multiplicity of each œÉ j is uniquely determined by œÑ. Since each œÉ j is equivalent to
some Œªi, we usually collect terms and write œÑ ‚àº
i miŒªi, where the multiplicities mi are
nonnegative integers.
(ii) The regular representation œÅ : G ‚ÜíCG is important because every irreducible repre-
sentation is a summand of it. Now œÅ is equivalent to the sum
œÅ ‚àºn1Œª1 + ¬∑ ¬∑ ¬∑ + nrŒªr,
where ni is the degree of Œªi [remember that CG = 
i Bi, where Bi ‚àº= End(Li) ‚àº=
Matni (C); as a CG-module, the simple module Li can be viewed as the Ô¨Årst columns of
ni √ó ni matrices, and so Bi is a direct sum of ni copies of Li].
‚óÄ

610
Algebras
Ch. 8
Recall that the trace of an n √ó n matrix A = [ai j] with entries in a commutative ring k
is the sum of the diagonal entries: tr(A) = n
i=1 aii.
When k is a Ô¨Åeld, then tr(A) turns out to be the sum of the eigenvalues of A (we will
assume this result now, but it is more convenient for us to prove it in the next chapter).
Here are two other elementary facts about the trace that we will prove now.
Proposition 8.122.
(i) If A = [ai j] and B = [bi j] are n √ó n matrices with entries in a commutative ring k,
then
tr(A + B) = tr(A) + tr(B)
and
tr(AB) = tr(B A).
(ii) If B = P AP‚àí1, then tr(B) = tr(A).
Proof.
(i) The additivity of trace follows from the diagonal entries of A+B being aii+bii.
If (AB)ii denotes the ii entry of AB, then
(AB)ii =

j
ai jb ji,
and so
tr(AB) =

i
(AB)ii =

i, j
ai jb ji.
Similarly,
tr(B A) =

j,i
b jiai j.
The entries commute because they lie in the commutative ring k, and so ai jb ji = b jiai j
for all i, j. It follows that tr(AB) = tr(B A), as desired.
(ii)
tr(B) = tr

(P A)P‚àí1
= tr

P‚àí1(P A)

= tr(A).
‚Ä¢
It follows from (ii) that we can deÔ¨Åne the trace of a linear transformation T : V ‚ÜíV ,
where V is a vector space over a Ô¨Åeld k, as the trace of any matrix arising from it: If A
and B are matrices of T , determined by two choices of bases of V , then B = P AP‚àí1 for
some nonsingular matrix P, and so tr(B) = tr(A).
DeÔ¨Ånition.
If œÉ : G ‚ÜíGL(V ) is a representation, then its character is the function
œáœÉ : G ‚ÜíC deÔ¨Åned by
œáœÉ(g) = tr(œÉ(g));
we call œáœÉ the character afforded by œÉ. An irreducible character is a character afforded
by an irreducible representation. The degree of œáœÉ is deÔ¨Åned to be the degree of œÉ; that is,
degree(œáœÉ) = degree(œÉ) = dim(V ).

Sec. 8.5
Characters
611
Example 8.123.
(i) The character Œ∏ afforded by a linear representation (see Example 8.118) is called a
linear character; that is, Œ∏ = œáœÉ, where degree(œÉ) = 1. Since every linear representation
is simple, every linear character is irreducible.
(ii) The representation Œªi : G ‚ÜíGL(Li) [see Proposition 8.119(i)] is irreducible. Thus,
the character
œái = œáŒªi
afforded by Œªi is irreducible.
(iii) In light of Proposition 8.119(ii), it makes sense to speak of œái(u) for every u ‚ààCG.
Of course, œái(u j) = 0 for all u j ‚ààEnd(L j) when j Ã∏= i, so that
œái(u j) =

tr(Œªi(u j))
if j = i
0
if j Ã∏= i.
(iv) If œÉ : G ‚ÜíGL(V ) is any representation, then œáœÉ(1) = n, where n is the degree of œÉ.
After all, œÉ(1) is the identity matrix, and its trace is n = dim(V ).
(v) Let œÉ : G ‚ÜíSX be a homomorphism; as in Example 8.117, we may regard œÉ as a
representation on V , where V is the vector space over C with basis X. For every g ‚ààG,
the matrix œÉ(g) is a permutation matrix, and its xth diagonal entry is 1 if œÉ(g)x = x;
otherwise, it is 0. Thus,
œáœÉ(g) = tr(œÉ(g)) = Fix(œÉ(g)),
the number of x ‚ààX Ô¨Åxed by œÉ(g). In other words, if X is a G-set, then we may view
each g ‚ààG as acting on X, and the number of Ô¨Åxed points of the action of g is a character
value (see Example 8.144 for a related discussion).
‚óÄ
Characters are compatible with addition of representations: If œÉ : G ‚ÜíGL(V ) and
œÑ : G ‚ÜíGL(W), then œÉ + œÑ : G ‚ÜíGL(V ‚äïW), and
tr((œÉ + œÑ)(g)) = tr
œÉ(g)
0
0
œÑ(g)
	
= tr(œÉ(g)) + tr(œÑ(g)).
Therefore,
œáœÉ+œÑ = œáœÉ + œáœÑ.
If œÉ and œÑ are equivalent representations, then
tr(œÉ(g)) = tr(PœÉ(g)P‚àí1) = tr(œÑ(g))
for all g ‚ààG; that is, they have the same characters: œáœÉ = œáœÑ. It follows that if œÉ : G ‚Üí
GL(V ) is a representation, then its character œáœÉ can be computed relative to any convenient
basis of V .

612
Algebras
Ch. 8
Proposition 8.124.
(i) Every character œáœÉ is an N-linear combination of the irreducible characters œái =
œáŒªi afforded by Œªi : G ‚ÜíGL(Li): there are integers mi ‚â•0 with
œáœÉ =

i
miœái.
(ii) Equivalent representations have the same character.
(iii) The only irreducible characters of G are œá1, . . . , œár.
Proof.
(i) The character œáœÉ arises from a representation œÉ of G, which, in turn, arises
from a CG-module V . But V is a semisimple module (because CG is a semisimple ring),
and so V is a direct sum of simple modules: V = 
j Sj. By Proposition 8.54, each
Sj ‚àº= Li for some minimal left ideal Li. If, for each i, we let mi ‚â•0 be the number of Sj
isomorphic to Li, then œáœÉ = 
i miœái.
(ii) This follows from part (ii) of Proposition 8.122 and Corollary 8.120(i).
(iii) This follows from part (ii) and Corollary 8.120(i).
‚Ä¢
As a consequence of the proposition, we call œá1, . . . , œár the irreducible characters
of G.
Example 8.125.
(i) The (linear) character œá1 afforded by the trivial representation œÉ : G ‚ÜíC with œÉ(g) =
1 for all g ‚ààG is called the trivial character. Thus, œá1(g) = 1 for all g ‚ààG.
(ii) Let us compute the regular character œà = œáœÅ afforded by the regular representation
œÅ : G ‚ÜíGL(CG), where œÅ(g): u ‚Üígu for all g ‚ààG and u ‚ààCG. Any basis of CG
can be used for this computation; we choose the usual basis comprised of the elements of
G. If g = 1, then Example 8.123(iv) shows that œà(1) = dim(CG) = |G|. On the other
hand, if g Ã∏= 1, then for all h ‚ààG, we have gh a basis element distinct from h. Therefore,
the matrix of œÅ(g) has 0's on the diagonal, and so its trace is 0. Thus,
œà(g) =

0
if g Ã∏= 1
|G|
if g = 1.
‚óÄ
We have already proved that equivalent representations have the same character. The
coming discussion will give the converse: If two representations have the same character,
then they are equivalent.
DeÔ¨Ånition.
A function œï : G ‚ÜíC is a class function if it is constant on conjugacy
classes; that is, if h = xgx‚àí1, then œï(h) = œï(g).

Sec. 8.5
Characters
613
Every character œáœÉ afforded by a representation œÉ is a class function: If h = xgx‚àí1,
then
œÉ(h) = œÉ(xgx‚àí1) = œÉ(x)œÉ(g)œÉ(x)‚àí1,
and so tr(œÉ(h)) = tr(œÉ(g)); that is,
œáœÉ(h) = œáœÉ(g).
Not every class function is a character. For example, if œá is a character, then ‚àíœá is a
class function; it is not a character because ‚àíœá(1) is negative, and so it cannot be a degree.
DeÔ¨Ånition.
We denote the set of all class functions G ‚ÜíC by cf(G):
cf(G) = {œï : G ‚ÜíC : œï(g) = œï(xgx‚àí1) for all x, g ‚ààG}.
It is easy to see that cf(G) is a vector space over C.
An element u = 
g‚ààG cgg ‚ààCG is an n-tuple (cg) of complex numbers; that is, u is a
function u : G ‚ÜíC with u(g) = cg for all g ‚ààG. From this viewpoint, we see that cf(G)
is a subring of CG. Note that a class function is a class sum; therefore, Lemma 8.68 says
that cf(G) is the center Z(CG), and so
dim(cf(G)) = r,
where r is the number of conjugacy classes in G (see Theorem 8.69).
DeÔ¨Ånition.
Write CG = B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBr, where Bi ‚àº= End(Li), and let ei denote the
identity element of Bi; hence,
1 = e1 + ¬∑ ¬∑ ¬∑ er,
where 1 is the identity element of CG. The elements ei are called the idempotents in CG.
Not only is each ei an idempotent, that is, e2
i = ei, but it is easy to see that
eie j = Œ¥i jei,
where Œ¥i j is the Kronecker delta.
Lemma 8.126.
The irreducible characters œá1, . . . , œár form a basis of cf(G).
Proof.
We have just seen that dim(cf(G)) = r, and so it sufÔ¨Åces to prove that œá1, . . . , œár
is a linearly independent list, by Corollary 3.89(ii). We have already noted that œái(u j) = 0
for all j Ã∏= i; in particular, œái(e j) = 0. On the other hand, œái(ei) = ni, where ni is the
degree of œái, for it is the trace of the ni √ó ni identity matrix.
Suppose now that 
i ciœái = 0. It follows, for all j, that
0 =

i
ciœái

(e j) = c jœá j(e j) = c jn j.
Therefore, all c j = 0, as desired.
‚Ä¢

614
Algebras
Ch. 8
Theorem 8.127.
Two representations of a Ô¨Ånite group G are equivalent if and only if they
afford the same character: œáœÉ = œáœÑ.
Proof.
We have already proved necessity, in Proposition 8.124(ii). For sufÔ¨Åciency, Propo-
sition 8.124(ii) says that every representation is completely reducible: There are nonneg-
ative integers mi and ‚Ñìi with œÉ ‚àº
i miŒªi and œÑ ‚àº
i ‚ÑìiŒªi. By hypothesis, the corre-
sponding characters coincide:

i
miœái = œáœÉ = œáœÑ =

i
‚Ñìiœái.
As the irreducible characters œá1, . . . , œár are a basis of cf(G), mi = ‚Ñìi for all i, and so
œÉ ‚àºœÑ.
‚Ä¢
There are relations between the irreducible characters that facilitate their calculation.
We begin by Ô¨Ånding the expression of the idempotents ei in terms of the basis G of CG.
By Example 8.123(iv), œái(1) = ni, the degree of Œªi. On the other hand, by Eq. (2) in
Proposition 8.119, we have œái(e j) = 0 if j Ã∏= i, so that
ni = œái(1) =

j
œái(e j) = œái(ei).
(3)
We also observe, for all y ‚ààG, that
œái(ei y) = œái(y),
(4)
for y = 
j e j y, and so œái(y) = 
j œái(e j y) = œái(ei y), because e j y ‚ààB j.
Proposition 8.128.
If ei = 
g‚ààG aigg, where aig ‚ààC, then
aig = niœái(g‚àí1)
|G|
.
Proof.
Let œà be the regular character; that is, œà is the character afforded by the regular
representation. Now eig‚àí1 = 
h aihhg‚àí1, so that
œà(eig‚àí1) =

h‚ààG
aihœà(hg‚àí1).
By Example 8.125(ii), œà(1) = |G| when h = g and œà(hg‚àí1) = 0 when h Ã∏= g. Therefore,
aig = œà(eig‚àí1)
|G|
.
On the other hand, since œà = 
j n jœá j, we have
œà(eig‚àí1) =

j
n jœá j(eig‚àí1) = niœái(eig‚àí1),
by Eq. (2) in Proposition 8.119. But œái(eig‚àí1) = œái(g‚àí1), by Eq. (4). Therefore,
aig = niœái(g‚àí1)/|G|.
‚Ä¢
It is now convenient to equip cf(G) with an inner product.

Sec. 8.5
Characters
615
DeÔ¨Ånition.
If Œ±, Œ≤ ‚ààcf(G), deÔ¨Åne
(Œ±, Œ≤) =
1
|G|

g‚ààG
Œ±(g)Œ≤(g),
where c denotes the complex conjugate of a complex number c.
It is easy to see that we have deÔ¨Åned an inner product;10 that is, for all c1, c2 ‚ààC,
(i) (c1Œ±1 + c2Œ±2, Œ≤) = c1(Œ±1, Œ≤) + c2(Œ±2, Œ≤);
(ii) (Œ≤, Œ±) = (Œ±, Œ≤).
Note that (Œ±, Œ±) is real, by (ii), and the inner product is deÔ¨Ånite; that is, (Œ±, Œ±) > 0 if Œ± Ã∏= 0.
Theorem 8.129.
With respect to the inner product just deÔ¨Åned, the irreducible characters
œá1, . . . , œár form an orthonormal basis; that is,
(œái, œá j) = Œ¥i j.
Proof.
By Proposition 8.128, we have
e j =
1
|G|

g
n jœá j(g‚àí1)g.
Hence,
œái(e j)/n j =
1
|G|

g
œá j(g‚àí1)œái(g)
=
1
|G|

g
œái(g)œá j(g)
= (œái, œá j);
the next to last equation follows from Exercise 8.56(ii) on page 632, for œá j is a character
(not merely a class function), and so œá j(g‚àí1) = œá j(g). The result now follows, for
œái(e j)/n j = Œ¥i j, by Eqs. (2) and (3).
‚Ä¢
The inner product on cf(G) can be used to check irreducibility.
DeÔ¨Ånition.
A generalized character œï on a Ô¨Ånite group G is a linear combination
œï =

i
miœái,
where œá1, . . . , œár are the irreducible characters of G and the coefÔ¨Åcients mi ‚ààZ.
If Œ∏ is a character, then Œ∏ = 
i miœái, where all the coefÔ¨Åcients are nonnegative inte-
gers, by Proposition 8.124.
10This inner product is not a bilinear form because we have (Œ≤, Œ±) = (Œ±, Œ≤), not (Œ≤, Œ±) = (Œ±, Œ≤). Such a
function is often called a Hermitian form or a sesquilinear form (sesqui means "one and a half").

616
Algebras
Ch. 8
Corollary 8.130.
A generalized character Œ∏ of a group G is an irreducible character if
and only if Œ∏(1) > 0 and
(Œ∏, Œ∏) = 1.
Proof.
If Œ∏ is an irreducible character, then Œ∏ = œái for some i, and so (Œ∏, Œ∏) = (œái, œái) =
1. Moreover, Œ∏(1) = deg(œái) > 0.
Conversely, let Œ∏ = 
j m jœá j, where m j ‚ààZ, and suppose that (Œ∏, Œ∏) = 1. Then
1 = 
j m2
j; hence, some m2
i = 1 and all other m j = 0. Therefore, Œ∏ = ¬±œái, and so
Œ∏(1) = ¬±œái(1). Since œái(1) = deg(œái) > 0, the hypothesis Œ∏(1) > 0 gives mi = 1.
Therefore, Œ∏ = œái, and so Œ∏ is an irreducible character.
‚Ä¢
Let us assemble the notation we will use from now on.
Notation.
If G is a Ô¨Ånite group, we denote its conjugacy classes by
C1, . . . , Cr,
a choice of elements, one from each conjugacy class, by
g1 ‚ààC1, . . . , gr ‚ààCr,
its irreducible characters by
œá1, . . . , œár,
their degrees by
n1 = œá1(1), . . . , nr = œár(1),
and the sizes of the conjugacy classes by
h1 = |C1|, . . . , hr = |Cr|.
The matrix [œái(g j)] is a useful way to display information.
DeÔ¨Ånition.
The character table of G is the r√ór complex matrix whose i j entry is œái(g j).
We always assume that C1 = {1} and that œá1 is the trivial character. Thus, the Ô¨Årst
row consists of all 1's, while the Ô¨Årst column consists of the degrees of the characters:
œái(1) = ni for all i, by Example 8.123(iv). The ith row of the character table consists of
the values
œái(1), œái(g2), . . . , œái(gr).
There is no obvious way of labeling the other conjugacy classes (or the other irreducible
characters), so that a Ô¨Ånite group G has many character tables. Nevertheless, we usually
speak of "the" character table of G.
Since the inner product on cf(G) is summed over all g ‚ààG, not just the chosen gi (one
from each conjugacy class), it can be rewritten as a "weighted" inner product:
(œái, œá j) =
1
|G|
r

k=1
hkœái(gk)œá j(gk).
Theorem 8.129 says that the weighted inner product of distinct rows in the character table
is 0, while the weighted inner product of any row with itself is 1.

Sec. 8.5
Characters
617
Example 8.131.
A character table can have complex entries. For example, it is easy to see that the character
table for a cyclic group G = ‚ü®x‚ü©of order 3 is given in Table 8.1, where œâ = e2œÄi/3 is a
primitive cube root of unity.
gi
1
x
x2
hi
1
1
1
œá1
1
1
1
œá2
1
œâ
œâ2
œá3
1
œâ2
œâ
Table 8.1.
Character Table of I3
‚óÄ
Example 8.132.
Write the four-group in additive notation:
V = {0, a, b, a + b}.
As a vector space over F2, V has basis a, b, and the "coordinate functions" on V, which
take values in {1, ‚àí1} ‚äÜC, are linear, hence irreducible, representations. For example, the
character œá2 arising from the function that is nontrivial on a and trivial on b is
œá2(v) =

‚àí1
if v = a
or
v = a + b
1
if v = 0
or
v = b.
Table 8.2 is the character table.
gi
0
a
b
a + b
hi
1
1
1
1
œá1
1
1
1
1
œá2
1
‚àí1
1
‚àí1
œá3
1
1
‚àí1
‚àí1
œá4
1
‚àí1
‚àí1
1
Table 8.2.
Character Table of V
‚óÄ
Example 8.133.
Table 8.3 on page 618 is the character table for the symmetric group G = S3. Since two
permutations in Sn are conjugate if and only if they have the same cycle structure, there
are three conjugacy classes, and we choose elements 1, (1 2), and (1 2 3) from each. In
Example 8.71(i), we saw that there are three irreducible representations: Œª1 = the trivial
representation, Œª2 = sgn, and a third representation Œª3 of degree 2. We now give the
character table, after which we discuss its entries.

618
Algebras
Ch. 8
gi
1
(1 2)
(1 2 3)
hi
1
3
2
œá1
1
1
1
œá2
1
‚àí1
1
œá3
2
0
‚àí1
Table 8.3.
Character Table of S3
We have already discussed the Ô¨Årst row and column of any character table. Since œá2 =
sgn, the second row records the fact that 1 and (1 2 3) are even while (1 2) is odd. The
third row has entries
2
a
b,
where a and b are to be found. The weighted inner products of row 3 with the other two
rows gives the equations
2 + 3a + 2b = 0
2 ‚àí3a + 2b = 0.
It follows easily that a = 0 and b = ‚àí1.
‚óÄ
The following lemma will be used to describe the inner products of the columns of the
character table.
Lemma 8.134.
If A is the character table of a Ô¨Ånite group G, then A is nonsingular and
its inverse A‚àí1 has i j entry
(A‚àí1)i j = hiœá j(gi)
|G|
.
Proof.
If B is the matrix whose i j entry is displayed in the statement, then
(AB)i j =
1
|G|

k
œái(gk)hkœá j(gk)
=
1
|G|

g
œái(g)œá j(g)
= (œái, œá j)
= Œ¥i j,
because hkœá j(gk) = 
y‚ààCk œá j(y). Therefore, AB = I.
‚Ä¢
The next result is fundamental.
Theorem 8.135 (Orthogonality Relations).
Let G be a Ô¨Ånite group of order n with con-
jugacy classes C1, . . . , Cr of cardinalities h1, . . . , hr, respectively, and choose elements

Sec. 8.5
Characters
619
gi ‚ààCi. Let the irreducible characters of G be œá1, . . . , œár, and let œái have degree ni.
Then the following relations hold:
(i)
r

k=1
hkœái(gk)œá j(gk) =

0
if i Ã∏= j;
|G|
if i = j.
(ii)
r

i=1
œái(gk)œái(g‚Ñì) =

0
if k Ã∏= ‚Ñì;
|G|/hk
if k = ‚Ñì.
Proof.
(i) This is just a restatement of Theorem 8.129.
(ii) If A is the character table of G and B = [hiœá j(gi)/|G|], we proved, in Lemma 8.134,
that AB = I. It follows that B A = I; that is, (B A)k‚Ñì= Œ¥k‚Ñì. Therefore,
1
|G|

i
hkœái(gk)œái(g‚Ñì) = Œ¥k‚Ñì,
and this is the second orthogonality relation.
‚Ä¢
In terms of the character table, the second orthogonality relation says that the usual
(unweighted, but with complex conjugation) inner product of distinct columns is 0 while,
for every k, the usual inner product of column k with itself is |G|/hk.
The orthogonality relations yield the following special cases.
Corollary 8.136.
(i) |G| = r
i=1 n2
i
(ii) r
i=1 niœái(gk) = 0
if k > 1
(iii) r
k=1 hkœái(gk) = 0
if i > 1
(iv) r
k=1 hk|œái(gk)|2 = |G|
Proof.
(i) This equation records the inner product of column 1 with itself: It is Theo-
rem 8.135(ii) when k = ‚Ñì= 1.
(ii) This is the special case of Theorem 8.135(ii) with ‚Ñì= 1, for œái(1) = ni.
(iii) This is the special case of Theorem 8.135(i) in which j = 1.
(iv) This is the special case of Theorem 8.135(i) in which j = i.
‚Ä¢
We can now give another proof of Burnside's lemma, Theorem 2.113, which counts the
number of orbits of a G-set.

620
Algebras
Ch. 8
Theorem 8.137 (Burnside's Lemma).
Let G be a Ô¨Ånite group and let X be a Ô¨Ånite
G-set. If N is the number of orbits of X, then
N =
1
|G|

g‚ààG
Fix(g),
where Fix(g) is the number of x ‚ààX with gx = x.
Proof.
Let V be the complex vector space having X as a basis. As in Example 8.117,
the G-set X gives a representation œÉ : G ‚ÜíGL(V ) by œÉ(g)(x) = gx for all g ‚ààG and
x ‚ààX; moreover, if œáœÉ is the character afforded by œÉ, then Example 8.123(v) shows that
œáœÉ(g) = Fix(g).
Let O1, . . . , ON be the orbits of X. We begin by showing that N = dim(V G), where
V G is the space of Ô¨Åxed points:
V G = {v ‚ààV : gv = v for all g ‚ààG}.
For each i, deÔ¨Åne si to be the sum of all the x in Oi; it sufÔ¨Åces to prove that these elements
form a basis of V G. It is plain that s1, . . . , sN is a linearly independent list in V G, and
it remains to prove that they span V G. If u ‚ààV G, then u = 
x‚ààX cxx, so that gu =

x‚ààX cx(gx). Since gu = u, however, cx = cgx. Thus, given x ‚ààX with x ‚ààO j, each
coefÔ¨Åcient of gx, where g ‚ààG, is equal to cx; that is, all the x lying in the orbit O j have
the same coefÔ¨Åcient, say, c j, and so u = 
j c js j. Therefore,
N = dim(V G).
Now deÔ¨Åne a linear transformation T : V ‚ÜíV by
T =
1
|G|

g‚ààG
œÉ(g).
It is routine to check that T is a CG-map, that T |(V G) = identity, and that im T = V G.
Since CG is semisimple, V = V G ‚äïW for some submodule W. We claim that T |W = 0.
If w ‚ààW, then œÉ(g)(w) ‚ààW for all g ‚ààG, because W is a submodule, and so T (w) ‚ààW.
On the other hand, T (w) ‚ààim T = V G, and so T (w) ‚ààV G ‚à©W = {0}, as claimed.
If w1, . . . , w‚Ñìis a basis of W, then s1, . . . , sN, w1, . . . , w‚Ñìis a basis of V = V G ‚äïW.
Note that T Ô¨Åxes each si and annihilates each w j. Since trace preserves sums,
tr(T ) =
1
|G|

g‚ààG
tr(œÉ(g))
=
1
|G|

g‚ààG
œáœÉ(g)
=
1
|G|

g‚ààG
Fix(g).

Sec. 8.5
Characters
621
It follows that
tr(T ) = dim(V G),
for the matrix of T with respect to the chosen basis is the direct sum of an identity block
and a zero block, and so tr(T ) is the size of the identity block, namely, dim(V G) = N.
Therefore,
N =
1
|G|

g‚ààG
Fix(g).
‚Ä¢
Character tables can be used to detect normal subgroups.
DeÔ¨Ånition.
If œáœÑ is the character afforded by a representation œÑ : G ‚ÜíGL(V ), then
ker œáœÑ = ker œÑ.
Proposition 8.138.
Let Œ∏ = œáœÑ be the character of a Ô¨Ånite group G afforded by a repre-
sentation œÑ : G ‚ÜíGL(V ).
(i) For each g ‚ààG, we have
|Œ∏(g)| ‚â§Œ∏(1).
(ii)
ker Œ∏ = {g ‚ààG : Œ∏(g) = Œ∏(1)}.
(iii) If Œ∏ = 
j m jœá j, where m j are positive integers, then
ker Œ∏ =
"
j
ker œá j.
(iv) If N is a normal subgroup of G, then there are irreducible characters œái1, . . ., œáis
with N =  s
j=1 ker œái j .
Proof.
(i) By Lagrange's theorem, g|G| = 1 for every g ‚ààG; it follows that the eigenval-
ues Œµ1, . . . , Œµd of œÑ(g), where d = Œ∏(1), are |G|th roots of unity, and so |Œµ j| = 1 for all j.
By the triangle inequality in C,
Œ∏(g)
 =

d

j=1
Œµ j
 ‚â§d = Œ∏(1).
(ii) If g ‚ààker Œ∏ = ker œÑ, then œÑ(g) = I, the identity matrix, and |Œ∏(g)| = tr(I) = Œ∏(1).
Conversely, suppose that Œ∏(g) = Œ∏(1) = d; that is, | d
j=1 Œµ j| = d. By Proposition 1.42,
all the eigenvalues Œµ j are equal, say, Œµ j = œâ for all j. Therefore, œÑ(g) = œâI, by Corol-
lary 8.120(iii), and so
Œ∏(g) = Œ∏(1)œâ.

622
Algebras
Ch. 8
But Œ∏(g) = Œ∏(1), by hypothesis, and so œâ = 1; that is, œÑ(g) = I and g ‚ààker œÑ.
(iii) For all g ‚ààG, we have
Œ∏(g) =

j
m jœá j(g);
in particular,
Œ∏(1) =

j
m jœá j(1).
If g ‚ààker Œ∏, then Œ∏(g) = Œ∏(1). Suppose that œá j‚Ä≤(g) Ã∏= œá j‚Ä≤(1) for some j‚Ä≤. Since œá j‚Ä≤(g)
is a sum of roots of unity, Proposition 1.42 applies to force |œá j‚Ä≤(g)| < œá j‚Ä≤(1), and so
Œ∏(g) = 
j m jœá j(g) Ã∏= Œ∏(1). Therefore, g ‚àà
j ker œá j. For the reverse inclusion, if
g ‚ààker œá j, then œá j(g) = œá j(1), and so
Œ∏(g) =

j
m jœá j(g) =

j
m jœá j(1) = Œ∏(1);
hence, g ‚ààker Œ∏.
(iv) It sufÔ¨Åces to Ô¨Ånd a representation of G whose kernel is N. By part (iii) and Exam-
ple 8.125(ii), the regular representation œÅ of G/N is faithful (i.e., is an injection), and so
its kernel is {1}. If œÄ : G ‚ÜíG/N is the natural map, then œÅœÄ is a representation of G
having kernel N. If Œ∏ is the character afforded by œÅœÄ, then Œ∏ = 
j m jœá j, where the m j
are positive integers, by Lemma 8.126, and so part (iii) applies.
‚Ä¢
Example 8.139.
We will construct the character table of S4 in Example 8.148. We can see there that
ker œá2 = A4 and ker œá3 = V are the only two normal subgroups of S4 (other than {1}
and S4). Moreover, we can see that V ‚â§A4.
In Example 8.140, we can see that ker œá2 = {1} ‚à™zG ‚à™yG (where zG denotes the
conjugacy class of z in G) and ker œá3 = {1} ‚à™zG ‚à™xG. Another normal subgroup occurs
as ker œá2 ‚à©ker œá3 = {1} ‚à™zG.
‚óÄ
A normal subgroup described by characters is given as a union of conjugacy classes;
this viewpoint can give another proof of the simplicity of A5. In Exercise 2.89(iv) on
page 113, we saw that A5 has Ô¨Åve conjugacy classes, of sizes 1, 12, 12, 15, and 20. Since
every subgroup contains the identity element, the order of a normal subgroup of A5 is the
sum of some of these numbers, including 1. But it is easy to see that 1 and 60 are the only
such sums that are divisors of 60, and so the only normal subgroups are {1} and A5 itself.
There is a way to "lift" a representation of a quotient group to a representation of the
group.
DeÔ¨Ånition.
Let H ‚úÅG and let œÉ : G/H ‚ÜíGL(V ) be a representation. If œÄ : G ‚ÜíG/H
is the natural map, then the representation œÉœÄ : G ‚ÜíGL(V ) is called a lifting of œÉ.

Sec. 8.5
Characters
623
Scalar multiplication of G on a CG-module V is given, for v ‚ààV , by
gv = (gH)v.
Thus, every CG-submodule of V is also a C(G/H)-submodule; hence, if V is a simple
C(G/H)-module, then it is also a simple CG-module. It follows that if œÉ : G/H ‚Üí
GL(V ) is an irreducible representation of G/H, then its lifting œÉœÄ is also an irreducible
representation of G.
Example 8.140.
We know that D8 and Q are nonisomorphic nonabelian groups of order 8; we now show
that they have the same character tables.
If G is a nonabelian group of order 8, then its center has order 2, say, Z(G) = ‚ü®z‚ü©.
Now G/Z(G) is not cyclic, by Exercise 2.69 on page 95, and so G/Z(G) ‚àº= V. Therefore,
if œÉ : V ‚ÜíC is an irreducible representation of V, then its lifting œÉœÄ is an irreducible
representation of G. This gives 4 (necessarily irreducible) linear characters of G, each
of which takes value 1 on z. As G is not abelian, there must be an irreducible character
œá5 of degree n5 > 1 (if all ni = 1, then CG is commutative and G is abelian). Since

i n2
i = 8, we see that n5 = 2. Thus, there are Ô¨Åve irreducible representations and,
hence, Ô¨Åve conjugacy classes; choose representatives gi to be 1, z, x, y, w. Table 8.4 is the
character table.
gi
1
z
x
y
w
hi
1
1
2
2
2
œá1
1
1
1
1
1
œá2
1
1
‚àí1
1
‚àí1
œá3
1
1
1
‚àí1
‚àí1
œá4
1
1
‚àí1
‚àí1
1
œá5
2
‚àí2
0
0
0
Table 8.4.
Character Table of D8 and of Q
The values for œá5 are computed from the orthogonality relations of the columns. For
example, if the last row of the character table is
2 a b c d,
then the inner product of columns 1 and 2 gives the equation 4 + 2a = 0, so that a = ‚àí2.
The reader may verify that 0 = b = c = d.
‚óÄ
The orthogonality relations help to complete a character table but, obviously, it would
also be useful to have a supply of characters. One important class of characters consists of
those afforded by induced representations; that is, representations of a group G determined
by representations of a subgroup H of G.

624
Algebras
Ch. 8
The original construction of induced representations, due to F. G. Frobenius, is rather
complicated. Tensor products make this construction more natural. The ring CG is a
(CG, CH)-bimodule (for CH is a subring of CG), so that if V is a left CH-module, then
the tensor product CG ‚äóCH V is deÔ¨Åned; Lemma 8.80 says that this tensor product is, in
fact, a left CG-module.
DeÔ¨Ånition.
Let H be a subgroup of a group G. If V is a left CH-module, then the
induced module is the left CG-module
V ‚ÜøG= CG ‚äóCH V.
The corresponding representation œÅ‚ÜøG : G ‚ÜíV G is called the induced representation.
The character of G afforded by œÅ‚ÜøG is called the induced character, and it is denoted by
œáœÅ‚ÜøG.
Let us recognize at the outset that the character of an induced representation need not
restrict to the original representation of the subgroup. For example, we have seen that there
is an irreducible character œá of A3 ‚àº= I3 having complex values, whereas every irreducible
character of S3 has (real) integer values. A related observation is that two elements may be
conjugate in a group but not conjugate in a subgroup (for example, nontrivial elements in
A3 are conjugate in S3, for they have the same cycle structure, but they are not conjugate
in the abelian group A3).
The next lemma will help us compute the character afforded by an induced representa-
tion.
Lemma 8.141.
(i) If H ‚â§G, then CG is a free right CH-module on [G : H] generators.
(ii) If a left CH-module V has a (vector space) basis e1, . . . , em, then a (vector space)
basis of the induced module V ‚ÜøG= CG ‚äóCH V is the family of all ti ‚äóe j, where
t1, . . . , tn is a transversal of H in G.
Proof.
(i) Since t1, . . . , tn is a transversal of H in G (of course, n = [G : H]), we see
that G is the disjoint union
G =

i
ti H;
thus, for every g ‚ààG, there is a unique i and a unique h ‚ààH with g = tih. We claim that
t1, . . . , tn is a basis of CG viewed as a right CH-module.
If u ‚ààCG, then u = 
g agg, where ag ‚ààC. Rewrite each term
agg = agtih = tiagh
(scalars in C commute with everything), collect terms involving the same ti, and obtain
u = 
i tiŒ∑i, where Œ∑i ‚ààCH.

Sec. 8.5
Characters
625
To prove uniqueness of this expression, suppose that 0 = 
i tiŒ∑i, where Œ∑i ‚ààCH.
Now Œ∑i = 
h‚ààH aihh, where aih ‚ààC. Substituting,
0 =

i,h
aihtih.
But tih = t jh‚Ä≤ if and only if i = j and h = h‚Ä≤, so that 0 = 
i,h aihtih = 
g‚ààG aihg,
where g = tih. Since the elements of G are a basis of CG (viewed as a vector space over
C), we have aih = 0 for all i, h, and so Œ∑i = 0 for all i.
(ii) By Theorem 8.87,
CG ‚äóCH V ‚àº=

i
tiCH ‚äóCH V.
It follows that every u ‚ààCG ‚äóCH V has a unique expression as a C-linear combination of
ti ‚äóe j, and so these elements comprise a basis.
‚Ä¢
We introduce the following notation. If H ‚â§G and œá : H ‚ÜíC is a function, then
Àôœá : G ‚ÜíC is given by
Àôœá(g) =

0
if g /‚ààH
œá(g)
if g ‚ààH.
Theorem 8.142.
If œáœÉ is the character afforded by a representation œÉ : H ‚ÜíGL(V ) of
a subgroup H of a group G, then the induced character œáœÉ‚ÜøG is given by
œáœÉ‚ÜøG(g) =
1
|H|

a‚ààG
ÀôœáœÉ(a‚àí1ga).
Proof.
Let t1, . . . , tn be a transversal of H in G, so that G is the disjoint union G =
!
i ti H, and let e1, . . . , em be a (vector space) basis of V . By Lemma 8.141(ii), a basis
for the vector space V G = CG ‚äóCH V consists of all ti ‚äóe j. If g ‚ààG, we compute the
matrix of left multiplication by g relative to this basis. Note that
gti = tk(i)hi,
where hi ‚ààH, and so
g(ti ‚äóe j) = (gti) ‚äóe j
= tk(i)hi ‚äóe j
= tk(i) ‚äóœÉ(hi)e j
(the last equation holds because we can slide any element of H across the tensor sign).
Now g(ti ‚äóe j) is written as a C-linear combination of all the basis elements of V ‚ÜøG, for
the coefÔ¨Åcients tp ‚äóe j for p Ã∏= k(i) are all 0. Hence, œÉ‚ÜøG(g) gives the nm √ó nm matrix
whose m columns labeled by ti ‚äóe j, for Ô¨Åxed i, are all zero except for an m √ó m block
equal to
[apq(hi)] = [apq(t‚àí1
k(i)gti)].

626
Algebras
Ch. 8
Thus, the big matrix is partitioned into m √ó m blocks, most of which are 0, and a nonzero
block is on the diagonal of the big matrix if and only if k(i) = i; that is,
t‚àí1
k(i)gti = t‚àí1
i
gti = hi ‚ààH.
The induced character is the trace of the big matrix, which is the sum of the traces of these
blocks on the diagonal. Therefore,
œáœÉ‚ÜøG(g) =

t‚àí1
i
gti‚ààH
tr([apq(t‚àí1
i
gti)])
=

i
ÀôœáœÉ(t‚àí1
i
gti)
(remember that ÀôœáœÉ is 0 outside of H). We now rewrite the summands (to get a formula that
does not depend on the choice of the transversal): If t‚àí1
i
gti ‚ààH, then (tih)‚àí1g(tih) =
h‚àí1(t‚àí1
i
gti)h in H, so that, for Ô¨Åxed i,

h‚ààH
ÀôœáœÉ

(tih)‚àí1g(tih)

= |H| ÀôœáœÉ(t‚àí1
i
gti),
because œáœÉ is a class function on H. Therefore,
œáœÉ‚ÜøG(g) =

i
ÀôœáœÉ(t‚àí1
i
gti)
=
1
|H|

i,h
ÀôœáœÉ

(tih)‚àí1g(tih)

=
1
|H|

a‚ààG
ÀôœáœÉ(a‚àí1ga).
‚Ä¢
Remark.
We have been considering induced characters, but it is easy to generalize the
discussion to induced class functions. If H ‚â§G, then a class function Œ∏ on H has a unique
expression as a C-linear combination of irreducible characters of H, say, Œ∏ =  ciœái, and
so we can deÔ¨Åne
Œ∏‚ÜøG =

ciœái‚ÜøG.
It is plain that Œ∏‚ÜøG is a class function on G, and that the formula in Theorem 8.142 extends
to induced class functions.
‚óÄ
If, for h ‚ààH, the matrix of œÉ(h) (with respect to the basis e1, . . . , em of V ) is B(h),
then deÔ¨Åne m √ó m matrices ÀôB(g), for all g ‚ààG, by
ÀôB(g) =

0
if g /‚ààH;
B(g)
if g ‚ààH.

Sec. 8.5
Characters
627
The proof of Theorem 8.142 allows us to picture the matrix of the induced representation
in block form
œÉ‚ÜøG(g) =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£∞
ÀôB(t‚àí1
1 gt1)
ÀôB(t‚àí1
1 gt2)
¬∑ ¬∑ ¬∑
ÀôB(t‚àí1
1 gtn)
ÀôB(t‚àí1
2 gt1)
ÀôB(t‚àí1
2 gt2)
¬∑ ¬∑ ¬∑
ÀôB(t‚àí1
2 gtn)
...
...
...
...
ÀôB(t‚àí1
n gt1)
ÀôB(t‚àí1
n gt2)
¬∑ ¬∑ ¬∑
ÀôB(t‚àí1
n gtn)
Ô£π
Ô£∫Ô£∫Ô£∫Ô£ª.
Corollary 8.143.
Let H be a subgroup of a Ô¨Ånite group G and let œá be a character on
H.
(i) œá‚ÜøG(1) = [G : H]œá(1).
(ii) If H ‚úÅG, then œá‚ÜøG(g) = 0 for all g /‚ààH.
Proof.
(i) For all a ‚ààG, we have a‚àí11a = 1, so that there are |G| terms in the sum
œá‚ÜøG(1) =
1
|H|

a‚ààG Àôœá(a‚àí1ga) that are equal to œá(1); hence,
œá‚ÜøG(1) = |G|
|H|œá(1) = [G : H]œá(1).
(ii) If H ‚úÅG, then g /‚ààH implies a‚àí1ga /‚ààH for all a ‚ààG. Therefore, Àôœá(a‚àí1ga) = 0
for all a ‚ààG, and so œá‚ÜøG(g) = 0.
‚Ä¢
Example 8.144.
Let H ‚â§G be a subgroup of index n, let X = {t1H, . . . , tn H} be the family of left cosets
of H, and let œï : G ‚ÜíSX be the (permutation) representation of G on the cosets of H. As
in Example 8.123(v), we may regard œï : G ‚ÜíGL(V ), where V is the vector space over C
having basis X; that is, œï is a representation in the sense of this section.
We claim that if œáœï is the character afforded by œï, then œáœï = œµ‚ÜøG, where œµ is the trivial
character on H. On the one hand, Example 8.123(v) shows that
œáœï(g) = Fix(œï(g))
for every g ‚ààG. On the other hand, suppose œï(g) is the permutation (in two-rowed
notation)
œï(g) =
 t1H
. . .
tn H
gt1H
. . .
gtn H
	
.
Now gti H = ti H if and only if t‚àí1
i
gti ‚ààH. Thus, Àôœµ(t‚àí1
i
gti) Ã∏= 0 if and only if gti H =
ti H, and so
œµ‚ÜøG(g) = Fix(œï(g)).
‚óÄ

628
Algebras
Ch. 8
Even though a character Œª of a subgroup H is irreducible, its induced character need not
be irreducible. For example, let G = S3 and H be the cyclic subgroup generated by (1 2).
The linear representation œÉ = sgn: H ‚ÜíC is irreducible, and it affords the character œáœÉ
with
œáœÉ(1) = 1
and
œáœÉ((1 2)) = ‚àí1.
Using the formula for the induced character, we Ô¨Ånd that
œáœÉ‚ÜøS3(1) = 3,
œáœÉ‚ÜøS3((1 2)) = ‚àí1,
and
œáœÉ‚ÜøS3((1 2 3)) = 0.
Corollary 8.130 shows that œáœÉ‚ÜøS3 is not irreducible, for (œáœÉ‚ÜøS3, œáœÉ‚ÜøS3) = 2. It is easy to
see that œáœÉ‚ÜøS3= œá2 + œá3, the latter being the nontrivial irreducible characters of S3.
We must mention a result of R. Brauer. Call a subgroup E of a Ô¨Ånite group G elemen-
tary if E = Z √ó P, where Z is cyclic and P is a p-group for some prime p.
Theorem (Brauer).
Every complex character Œ∏ on a Ô¨Ånite group G has the form
Œ∏ =

i
mi¬µi‚ÜøG,
where mi ‚ààZ and the ¬µi are linear characters on elementary subgroups of G.
Proof.
See Curtis-Reiner, Representation Theory of Finite Groups and Associative Alge-
bras, page 283.
‚Ä¢
DeÔ¨Ånition.
If H is a subgroup of a group G, then every representation œÉ : G ‚ÜíGL(V )
gives, by restriction, a representation œÉ|H : H ‚ÜíGL(V ). (In terms of modules, every left
CG-module V can be viewed as a left CH-module.) We call œÉ|H the restriction of œÉ, and
we denote it by œÉ‚áÉH. The character of H afforded by œÉ‚áÉH is denoted by œáœÉ‚áÉH.
The next result displays an interesting relation between characters on a group and char-
acters on a subgroup. (Formally, it resembles the adjoint isomorphism.)
Theorem 8.145 (Frobenius Reciprocity).
Let H be a subgroup of a group G, let œá be
a class function on G, and let Œ∏ be a class function on H. Then
(Œ∏‚ÜøG, œá)G = (Œ∏, œá‚áÉH)H,
where ( , )G denotes the inner product on cf(G) and ( , )H denotes the inner product
on cf(H).

Sec. 8.5
Characters
629
Proof.
(Œ∏‚ÜøG, œá)G =
1
|G|

g‚ààG
Œ∏‚ÜøG (g)œá(g)
=
1
|G|

g‚ààG
1
|H|

a‚ààG
ÀôŒ∏(a‚àí1ga)œá(g)
=
1
|G|
1
|H|

a,g‚ààG
ÀôŒ∏(a‚àí1ga)œá(a‚àí1ga),
the last equation occurring because œá is a class function. For Ô¨Åxed a ‚ààG, as g ranges over
G, then so does a‚àí1ga. Therefore, writing x = a‚àí1ga, the equations continue
=
1
|G|
1
|H|

a,x‚ààG
ÀôŒ∏(x)œá(x)
=
1
|G|
1
|H|

a‚ààG

x‚ààG
ÀôŒ∏(x)œá(x)

=
1
|G|
1
|H||G|

x‚ààG
ÀôŒ∏(x)œá(x)
=
1
|H|

x‚ààG
ÀôŒ∏(x)œá(x)
= (Œ∏, œá‚áÉH)H,
the next to last equation holding because ÀôŒ∏(x) vanishes off the subgroup H.
‚Ä¢
The following elementary remark facilitates the computation of induced class functions.
Lemma 8.146.
Let H be a subgroup of a Ô¨Ånite group G, and let œá be a class function on
H. Then
œá‚ÜøG(g) =
1
|H|

i
|CG(gi)| Àôœá(g‚àí1
i
ggi).
Proof.
Let |CG(gi)| = mi. If a‚àí1
0 gia0 = g, we claim that there are exactly mi elements
a ‚ààG with a‚àí1gia = g. There are at least mi elements in G conjugating gi to g;
namely, all aa0 for a ‚ààCG(gi). There are at most mi elements, for if b‚àí1gib = g, then
b‚àí1gib = a‚àí1
0 gia0, and so a0b ‚ààCG(gi). The result now follows by collecting terms
involving gis in the formula for œá‚ÜøG(g).
‚Ä¢
Example 8.147.
Table 8.5 on page 630 is the character table of A4, where œâ = e2œÄi/3 is a primitive cube
root of unity.

630
Algebras
Ch. 8
gi
(1)
(1 2 3)
(1 3 2)
(1 2)(3 4)
hi
1
4
4
3
œá1
1
1
1
1
œá2
1
œâ
œâ2
1
œá3
1
œâ2
œâ
1
œá4
3
0
0
‚àí1
Table 8.5.
Character Table of A4
The group A4 consists of the identity, eight 3-cycles, and three products of disjoint
transpositions. In S4, all the 3-cycles are conjugate; if g = (1 2 3), then [S4 : CS4(g)] = 8.
It follows that |CS4(g)| = 3, and so CS4(g) = ‚ü®g‚ü©. Therefore, in A4, the number of
conjugates of g is [A4 : CA4(g)] = 4 [we know that CA4(g) = A4 ‚à©CS4(g) = ‚ü®g‚ü©]. The
reader may show that g and g‚àí1 are not conjugate, and so we have veriÔ¨Åed the Ô¨Årst two
rows of the character table.
The rows for œá2 and œá3 are liftings of linear characters of A4/V ‚àº= I3. Note that if h =
(1 2)(3 4), then œá2(h) = œá2(1) = 1, because V is the kernel of the lifted representation;
similarly, œá3(h) = 1. Now œá4(1) = 3, because 3+(n4)2 = 12. The bottom row arises from
orthogonality of the columns. (We can check, using Corollary 8.130, that the character of
degree 3 is irreducible.)
‚óÄ
Example 8.148.
Table 8.6 is the character table of S4.
gi
(1)
(1 2)
(1 2 3)
(1 2 3 4)
(1 2)(3 4)
hi
1
6
8
6
3
œá1
1
1
1
1
1
œá2
1
‚àí1
1
‚àí1
1
œá3
2
0
‚àí1
0
2
œá4
3
1
0
‚àí1
‚àí1
œá5
3
‚àí1
0
1
‚àí1
Table 8.6.
Character Table of S4
We know, for all n, that two permutations in Sn are conjugate if and only if they have
the same cycle structure; the sizes of the conjugacy classes in S4 were computed in Exam-
ple 2.5(i).
The rows for œá2 and œá3 are liftings of irreducible characters of S4/V ‚àº= S3. The en-
tries in the fourth column of these rows arise from (1 2)V = (1 2 3 4)V; the entries
in the last column of these rows arise from V being the kernel (in either case), so that
œá j((1 2)(3 4)) = œá j(1) for j = 2, 3.
We complete the Ô¨Årst column using 24 = 1 + 1 + 4 + n2
4 + n2
5; thus, n4 = 3 = n5.
Let us see whether œá4 is an induced character; if it is, then Corollary 8.143(i) shows that

Sec. 8.5
Characters
631
it arises from a linear character of a subgroup H of index 3. Such a subgroup has order 8,
and so it is a Sylow 2-subgroup; that is, H ‚àº= D8. Let us choose one such subgroup: Let
H = ‚ü®V, (1 3)‚ü©= V ‚à™{(1 3), (2 4), (1 2 3 4), (1 4 3 2)}.
The conjugacy classes are
C1 = {1};
C2 = {(1 3)(2 4)};
C3 = {(1 2)(3 4), (1 4)(2 3)};
C4 = {(1 3), (2 4)};
C5 = {(1 2 3 4), (1 4 3 2)}.
Let Œ∏ be the character on H deÔ¨Åned by
C1
C2
C3
C4
C5
1
1
‚àí1
1
‚àí1.
DeÔ¨Åne œá4 = Œ∏‚ÜøS4. Using the formula for induced characters, assisted by Lemma 8.146,
we obtain the fourth row of the character table. However, before going on to row 5, we
observe that Corollary 8.130 shows that œá4 is irreducible, for (œá4, œá4) = 1. Finally, the
orthogonality relations allows us to compute row 5.
‚óÄ
At this point in the story, we must introduce algebraic integers. Since G is a Ô¨Ånite group,
Lagrange's theorem gives g|G| = 1 for all g ‚ààG. It follows that if œÉ : G ‚ÜíGL(V ) is
a representation, then œÉ(g)|G| = I for all g; hence, all the eigenvalues of œÉ(g) are |G|th
roots of unity, and so all the eigenvalues are algebraic integers. By Proposition 7.24, the
trace of œÉ(g), being the sum of the eigenvalues, is also an algebraic integer.
We can now prove the following interesting result.
Theorem 8.149.
The degrees ni of the irreducible characters of a Ô¨Ånite group G are
divisors of |G|.
Proof.
By Corollary 3.44, the rational number Œ± = |G|/ni is an integer if it is also an
algebraic integer. Now Corollary 8.10(ii) says that Œ± is an algebraic integer if there is
a faithful Z[Œ±]-module M that is a Ô¨Ånitely generated abelian group, where Z[Œ±] is the
smallest subring of C containing Œ±.
By Proposition 8.128, we have
ei =

g‚ààG
ni
|G|œái(g‚àí1)g
=

g‚ààG
1
Œ± œái(g‚àí1)g.

632
Algebras
Ch. 8
Hence, Œ±ei = 
g‚ààG œái(g‚àí1)g. But ei is an idempotent: e2
i = ei, and so
Œ±ei =

g‚ààG
œái(g‚àí1)gei.
DeÔ¨Åne M to be the abelian subgroup of CG generated by all elements of the form Œ∂gei,
where Œ∂ is a |G|th root of unity and g ‚ààG; of course, M is a Ô¨Ånitely generated abelian
group.
To see that M is a Z[Œ±]-module, it sufÔ¨Åces to show that Œ±M ‚äÜM. But
Œ±Œ∂gei = Œ∂gŒ±ei
= Œ∂g

h‚ààG
œái(h‚àí1)hei
=

h‚ààG
œái(h‚àí1)Œ∂ghei.
This last element lies in M, however, because œái(h‚àí1) is a sum of |G|th roots of unity.
Finally, if Œ≤ ‚ààC and u ‚ààCG, then Œ≤u = 0 if and only if Œ≤ = 0 or u = 0. Since Z[Œ±] ‚äÜ
C and M ‚äÜCG, however, it follows that M is a faithful Z[Œ±]-module, as desired.
‚Ä¢
We will present two important applications of character theory in the next section; for
other applications, as well as a more serious study of representations, the interested reader
should look at the books of Curtis-Reiner, Feit, Huppert, and Isaacs. Representation the-
ory was an essential ingredient of the proof of the classiÔ¨Åcation of the Ô¨Ånite simple groups
in the 1980s: There are several inÔ¨Ånite families and 26 sporadic groups belonging to no in-
Ô¨Ånite family (see the chapter by R. Carter in the book edited by Kostrikin and Shafarevich,
as well as Gorenstein-Lyons-Solomon, The ClassiÔ¨Åcation of the Finite Simple Groups).
The ATLAS, by Conway et al, contains the character tables of every simple group of order
under 1025 as well as the character tables of all the sporadic groups. The largest sporadic
simple group is called the Monster; it has order
246 ¬∑ 320 ¬∑ 59 ¬∑ 76 ¬∑ 112 ¬∑ 133 ¬∑ 17 ¬∑ 19 ¬∑ 23 ¬∑ 29 ¬∑ 31 ¬∑ 41 ¬∑ 47 ¬∑ 59 ¬∑ 71.
EXERCISES
8.55 Prove that if Œ∏ is a generalized character of a Ô¨Ånite group G, then there are characters œá and
œà with Œ∏ = œá ‚àíœà.
8.56
(i) Prove that if z is a complex root of unity, then z‚àí1 = z.
(ii) Prove that if G is a Ô¨Ånite group and œÉ : G ‚ÜíGL(V ) is a representation, then
œáœÉ (g‚àí1) = œáœÉ (g)
for all g ‚ààG.
Hint.
Use the fact that every eigenvalue of œÉ(g) is a root of unity, as well as the fact
that if A is a nonsingular matrix over a Ô¨Åeld k and if u1, . . . , un are the eigenvalues of A
(with multiplicities), then the eigenvalues of A‚àí1 are u‚àí1
1 , . . ., u‚àí1
n ; that is, u1, . . . , un.

Sec. 8.5
Characters
633
8.57 If œÉ : G ‚ÜíGL(n, C) is a representation, its contragredient œÉ ‚àó: G ‚ÜíGL(n, C) is the func-
tion given by
œÉ ‚àó(g) = œÉ(g‚àí1)t,
where t denotes transpose.
(i) Prove that the contragredient of a representation œÉ is a representation that is irreducible
when œÉ is irreducible.
(ii) Prove that the character œáœÉ ‚àóafforded by the contragredient œÉ ‚àóis
œáœÉ ‚àó(g) = œáœÉ (g),
where œáœÉ (g) is the complex conjugate. Conclude that if œá is a character of G, then œá is
also a character.
8.58 Construct an irreducible representation of S3 of degree 2.
8.59
(i) If g ‚ààG, where G is a Ô¨Ånite group, prove that g is conjugate to g‚àí1 if and only if œá(g)
is real for every character œá of G.
(ii) Prove that every character of Sn is real valued. (It is a theorem of F. G. Frobenius that
every character of Sn is integer valued.)
8.60
(i) If G is a Ô¨Ånite abelian group, deÔ¨Åne its character group G‚àóby
G‚àó= Hom(G, C√ó),
where C√ó is the multiplicative group of nonzero complex numbers. Prove that G‚àó‚àº= G.
Hint. Use the fundamental theorem of Ô¨Ånite abelian groups.
(ii) Prove that Hom(G, C√ó) ‚àº= Hom(G, Q/Z) when G is a Ô¨Ånite abelian group.
(iii) Prove that every irreducible character of a Ô¨Ånite abelian group is linear.
8.61 Prove that the only linear character of a simple group is the trivial character. Conclude that if
œái is not the trivial character, then ni = œái(1) > 1.
8.62 Let Œ∏ = œáœÉ be the character afforded by a representation œÉ of a Ô¨Ånite group G.
(i) If g ‚ààG, prove that |Œ∏(g)| = Œ∏(1) if and only if œÉ(g) is a scalar matrix.
Hint. Use Proposition 1.42 on page 23.
(ii) If Œ∏ is an irreducible character, prove that
Z(G/ ker Œ∏) = {g ‚ààG : |Œ∏(g)| = Œ∏(1)}.
8.63 If G is a Ô¨Ånite group, prove that the number of its (necessarily irreducible) linear representa-
tions is [G : G‚Ä≤].
8.64 Let G be a Ô¨Ånite group.
(i) If g ‚ààG, show that |CG(g)| = r
i=1 |œái(g)|2. Conclude that the character table of G
gives |CG(g)|.
(ii) Show how to use the character table of G to see whether G is abelian.
(iii) Show how to use the character table of G to Ô¨Ånd the lattice of normal subgroups of G
and their orders.
(iv) If G is a Ô¨Ånite group, show how to use its character table to Ô¨Ånd the commutator sub-
group G‚Ä≤.
Hint. If K ‚úÅG, then the character table of G/K is a submatrix of the character table
of G, and so we can Ô¨Ånd the abelian quotient of G having largest order.

634
Algebras
Ch. 8
(v) Show how to use the character table of a Ô¨Ånite group G to determine whether G is
solvable.
8.65
(i) Show how to use the character table of G to Ô¨Ånd |Z(G)|.
(ii) Show how to use the character table of a Ô¨Ånite group G to determine whether G is
nilpotent.
8.66 Recall that the group Q of quaternions has the presentation
Q = (A, B|A4 = 1, A2 = B2, B AB‚àí1 = A‚àí1).
(i) Show that there is a representation œÉ : Q ‚ÜíGL(2, C) with
A ‚Üí
i
0
0
‚àíi

and B ‚Üí
 0
1
‚àí1
0

.
(ii) Prove that œÉ is an irreducible representation.
8.67
(i) If œÉ : G ‚ÜíGL(V ) and œÑ : G ‚ÜíGL(W) are representations, prove that
œÉ ‚äóœÑ : G ‚ÜíGL(V ‚äóW),
deÔ¨Åned by
(œÉ ‚äóœÑ)(g) = œÉ(g) ‚äóœÑ(g)
is a representation.
(ii) Prove that the character afforded by œÉ ‚äóœÑ is the pointwise product:
œáœÉ œáœÑ : g ‚Üítr(œÉ(g)) tr(œÑ(g)).
(iii) Prove that cf(G) is a commutative ring (usually called the Burnside ring of G).
8.6 THEOREMS OF BURNSIDE AND OF FROBENIUS
Character theory will be used in this section to prove two important results in group the-
ory: Burnside's pmqn theorem and a theorem of Frobenius. We begin with the following
variation of Schur's lemma.
Proposition 8.150.
If œÉ : G ‚ÜíGL(V ) is an irreducible representation and if a linear
transformation œï : V ‚ÜíV satisÔ¨Åes
œïœÉ(g) = œÉ(g)œï
for all g ‚ààG, then œï is a scalar transformation: there exists Œ± ‚ààC with œï = Œ±1V .

Sec. 8.6
Theorems of Burnside and of Frobenius
635
Proof.
The vector space V is a CG-module with scalar multiplication gv = œÉ(g)(v) for
all v ‚ààV , and any linear transformation Œ∏ satisfying the equation Œ∏œÉ(g) = œÉ(g)Œ∏ for all
g ‚ààG is a CG-map V œÉ ‚ÜíV œÉ. Since œÉ is irreducible, the CG-module V œÉ is simple; by
Schur's lemma [Theorem 8.52(ii)], we have End(V œÉ) a division ring, and so every nonzero
element in it is nonsingular. Now œï ‚àíŒ±1V ‚ààEnd(V œÉ) for every Œ± ‚ààC; in particular, this
is so when Œ± is an eigenvalue of œï (which lies in C because C is algebraically closed). The
deÔ¨Ånition of eigenvalue says that œï‚àíŒ±1V is singular, and so it must be 0; that is, œï = Œ±1V ,
as desired.
‚Ä¢
As in Proposition 8.119(ii), we may regard the irrreducible representation Œªi : G ‚Üí
GL(Li), given by left multiplication on the minimal left ideal Li, as a C-algebra map
Œªi : CG ‚ÜíEnd(Li) (after all, imŒªi ‚äÜEnd(Li)). Hence, the restriction to the center of
CG is also an algebra map:
Œªi : Z(CG) ‚ÜíEnd(Li) ‚àº= Matni (C).
Thus, for each z ‚ààZ(CG), we see that Œªi(z) is an ni √ó ni complex matrix. By Proposi-
tion 8.150, eachŒªi(z) is a scalar matrix for every z ‚ààZ(CG):
Œªi(z) = œâi(z)I,
where œâi(z) ‚ààC. Moreover, the function œâi : Z(CG) ‚ÜíC is a C-algebra map because
Œªi is.
Recall, from Lemma 8.68, that a basis for Z(CG) consists of the class sums
zi =

g‚ààCi
g,
where the conjugacy classes of G are C1, . . . , Cr.
Proposition 8.151.
Let z1, . . . , zr be the class sums of a Ô¨Ånite group G.
(i) For each i, j, we have
œâi(z j) = h jœái(g j)
ni
,
where g j ‚ààC j.
(ii) There are nonnegative integers ai jŒΩ with
ziz j =

ŒΩ
ai jŒΩzŒΩ.
(iii) The complex numbers œâi(z j) are algebraic integers.

636
Algebras
Ch. 8
Proof.
(i) Computing the trace ofŒªi(z j) = œâi(z j)I gives
niœâi(z j) = œái(z j) =

g‚ààC j
œái(g) = h jœái(g j),
for œái is constant on the conjugacy class C j. Therefore, œâi(z j) = h jœái(g j)/ni.
(ii) Choose gŒΩ ‚ààCŒΩ. The deÔ¨Ånition of multiplication in the group algebra shows that the
coefÔ¨Åcient of gŒΩ in ziz j is
|{(gi, g j) ‚ààCi √ó C j : gig j = gŒΩ}|,
the cardinality of a Ô¨Ånite set, and hence it is a nonnegative integer. As all the coefÔ¨Åcients
of zŒΩ are equal [for we are in Z(CG)], it follows that this number is ai jŒΩ.
(iii) Let M be the (additive) subgroup of C generated by all œâi(z j), for j = 1, . . . ,r. Since
œâi is an algebra map,
œâi(z j)œâi(z‚Ñì) =

ŒΩ
a j‚ÑìŒΩœâi(zŒΩ),
so that M is a ring that is Ô¨Ånitely generated as an abelian group (because ai jŒΩ ‚ààZ). Hence,
for each j, M is a Z[œâi(z j)]-module that is a Ô¨Ånitely generated abelian group. If M is
faithful, then Corollary 8.10(ii) will give œâi(z j) an algebraic integer. But M ‚äÜC, so that
the product of nonzero elements is nonzero, and this implies that M is a faithful Z[œâi(z j)]-
module, as desired.
‚Ä¢
We are almost ready to complete the proof of Burnside's theorem.
Proposition 8.152.
If (ni, h j) = 1 for some i, j, then either |œái(g j)| = ni or œái(g j) = 0.
Proof.
By hypothesis, there are integers s and t in Z with sni + th j = 1, so that, for
g j ‚ààC j, we have
œái(g j)
ni
= sœái(g j) + th jœái(g j)
ni
.
Hence, Proposition 8.151(iii) gives œái(g j)/ni an algebraic integer, and so |œái(g j)| ‚â§ni,
by Proposition 8.138(i); thus, it sufÔ¨Åces to show that if |œái(g j)/ni| < 1, then œái(g j) = 0.
Let m(x) ‚ààZ[x] be the minimum polynomial of Œ± = œái(g j)/ni; that is, m(x) is the
monic polynomial in Z[x] of least degree having Œ± as a root. We proved, in Corollary 6.29,
that m(x) is irreducible in Q[x]. If Œ±‚Ä≤ is a root of m(x), then Proposition 4.13 shows that
Œ±‚Ä≤ = œÉ(Œ±) for some œÉ ‚ààGal(E/Q), where E/Q is the splitting Ô¨Åeld of m(x)(x|G| ‚àí1).
But
Œ± = 1
ni

Œµ1 + ¬∑ ¬∑ ¬∑ + Œµni

,
where the Œµ's are |G|th roots of unity, and so Œ±‚Ä≤ = œÉ(Œ±) is also such a sum. It follows
that |Œ±‚Ä≤| ‚â§1 [as in the proof of Proposition 8.138(i)]. Therefore, if N(Œ±) is the norm
of Œ± (which is, by deÔ¨Ånition, the absolute value of the product of all the roots of m(x)),
then N(Œ±) < 1 (for we are assuming that |Œ±| < 1). But N(Œ±) is the absolute value of the
constant term of m(x), which is an integer. Therefore, N(Œ±) = 0, hence Œ± = 0, and so
œái(g j) = 0, as claimed.
‚Ä¢

Sec. 8.6
Theorems of Burnside and of Frobenius
637
At last, we can prove the hypothesis of Proposition 8.116, stated at the beginning of the
previous section.
Theorem 8.153.
If G is a nonabelian Ô¨Ånite simple group, then {1} is the only conjugacy
class whose size is a prime power. Therefore, Burnside's theorem is true: every group of
order pmqn, where p and q are primes, is solvable.
Proof.
Assume, on the contrary, that h j = pe > 1 for some j. By Exercise 8.62(ii) on
page 633, for all i, we have
Z(G/ ker œái) = {g ‚ààG : |œái(g)| = ni}.
Since G is simple, ker œái = {1} for all i, and so Z(G/ ker œái) = Z(G) = {1}. By
Proposition 8.152, if (ni, h j) = 1, then either |œái(g j)| = ni or œái(g j) = 0. Of course,
œá1(g j) = 1 for all j, where œá1 is the trivial character. If œái is not the trivial character, then
we have just seen that the Ô¨Årst possibility cannot occur, and so œái(g j) = 0. On the other
hand, if (ni, h j) Ã∏= 1, then p | ni (for h j = pe). Thus, for every i Ã∏= 1, either œái(g j) = 0
or p | ni.
Consider the orthogonality relation, Corollary 8.136(ii):
r

i=1
niœái(g j) = 0.
Now n1 = 1 = œá1(g j), while each of the other terms is either 0 or of the form pŒ±i, where
Œ±i is an algebraic integer. It follows that
0 = 1 + pŒ≤,
where Œ≤ is an algebraic integer. This implies that the rational number ‚àí1/p is an algebraic
integer, hence lies in Z, and we have the contradiction that ‚àí1/p is an integer.
‚Ä¢
Another early application of characters is a theorem of F. G. Frobenius. We begin with
a discussion of doubly transitive permutation groups. Let G be a Ô¨Ånite group and X a Ô¨Ånite
G-set. Recall that if x ‚ààX, then its orbit is O(x) = {gx : g ‚ààG} and its stabilizer is
Gx = {g ‚ààG : gx = x}. Theorem 2.98 shows that |O(x)||Gx| = |G|. A G-set X is
transitive if it has only one orbit: If x, y ‚ààX, then there exists g ‚ààG with y = gx; in this
case, O(x) = X.
If X is a G-set, then there is a homomorphism Œ± : G ‚ÜíSX, namely, g ‚ÜíŒ±g, where
Œ±g(x) = gx. We say that X is a faithful G-set if Œ± is an injection; that is, if gx = x
for all x ‚ààX, then g = 1. In this case, we may regard G as a subgroup of SX acting as
permutations of X.
Cayley's theorem (Theorem 2.87) shows that every group G can be regarded as a faithful
transitive G-set.

638
Algebras
Ch. 8
DeÔ¨Ånition.
A G-set X is doubly transitive if, for every pair of 2-tuples (x1, x2) and
(y1, y2) in X √ó X with x1 Ã∏= x2 and y1 Ã∏= y2, there exists g ‚ààG with y1 = gx1 and
y2 = gx2.11
We often abuse language and call a group G doubly transitive if there exists a doubly
transitive G-set.
Note that every doubly transitive G-set X is transitive: If x Ã∏= y, then (x, y) and (y, x)
are 2-tuples as in the deÔ¨Ånition, and so there is g ‚ààG with y = gx (and x = gy).
Example 8.154.
(i) If n ‚â•2, the symmetric group Sn is doubly transitive; that is, X = {1, . . . , n} is a
doubly transitive SX-set.
(ii) The alternating group An is doubly transitive if n ‚â•4.
(iii) Let V be a Ô¨Ånite-dimensional vector space over F2, and let X = V ‚àí{0}. Then X is
a doubly transitive GL(V )-set, for every pair of distinct nonzero vectors x1, x2 in V must
be linearly independent (see Exercise 3.69 on page 170). Since every linearly independent
list can be extended to a basis, there is a basis x1, x2, . . . , xn of V . Similarly, if y1, y2 is
another pair of distinct nonzero vectors, there is a basis y1, y2, . . . , yn. But GL(V ) acts
transitively on the set of all bases of V , by Exercise 3.78 on page 181. Therefore, there is
g ‚ààGL(V ) with yi = gxi for all i, and so X is a doubly transitive GL(V )-set.
‚óÄ
Proposition 8.155.
A G-set X is doubly transitive if and only if, for each x ‚ààX, the
Gx-set X ‚àí{x} is transitive.
Proof.
Let X be a doubly transitive G-set. If y, z ‚ààX ‚àí{x}, then (y, x) and (z, x) are
2-tuples of distinct elements of X, and so there is g ‚ààG with z = gy and x = gx. The
latter equation shows that g ‚ààGx, and so X ‚àí{x} is a transitive Gx-set.
To prove the converse, let (x1, x2) and (y1, y2) be 2-tuples of distinct elements of X.
We must Ô¨Ånd g ‚ààG with y1 = gx1 and y2 = gy2. Let us denote (gx1, gx2) by g(x1, x2).
There is h ‚ààGx2 with h(x1, x2) = (y1, x2): if x1 = y1, we may take h = 1X; if x1 Ã∏= y1,
we use the hypothesis that X ‚àí{x2} is a transitive Gx2-set. Similarly, there is h‚Ä≤ ‚ààGy1
with h‚Ä≤(y1, x2) = (y1, y2). Therefore, h‚Ä≤h(x1, x2) = (y1, y2), and X is a doubly transitive
G-set.
‚Ä¢
Example 8.156.
Let k be a Ô¨Åeld, let f (x) ‚ààk[x] have no repeated roots, let E/k be a splitting Ô¨Åeld, and let
G = Gal(E/k) be the Galois group of f (x). If X = {Œ±1, . . . , Œ±n} is the set of all the roots
11More generally, we call a G-set X k-transitive, where 1 ‚â§k ‚â§|X|, if, for every pair of k-tuples (x1, . . . , xk)
and (y1, . . . , yk) in X √ó ¬∑ ¬∑ ¬∑ √ó X having distinct coordinates, there exists g ‚ààG with yi = gxi for all i ‚â§k. It
can be proved that if k > 5, then the only faithful k-transitive groups are the symmetric groups and the alternating
groups. The Ô¨Åve Mathieu groups are interesting sporadic simple groups that are also highly transitive: M22 is
3-transitive, M11 and M23 are 4-transitive, and M12 and M24 are 5-transitive.

Sec. 8.6
Theorems of Burnside and of Frobenius
639
of f (x), then X is a G-set (Theorem 4.3) that is transitive if and only if f (x) is irreducible
(Proposition 4.13). Now f (x) factors in k(Œ±1)[x]:
f (x) = (x ‚àíŒ±1) f1(x).
The reader may show that G1 = Gal(E/k(Œ±1)) ‚â§G is the stabilizer GŒ±1 and that X ‚àí{Œ±1}
is a G1-set. Thus, Proposition 8.155 shows that X is a doubly transitive G-set if and only
if both f (x) and f1(x) are irreducible (over k[x] and k(Œ±1)[x], respectively).
‚óÄ
Recall Example 2.92(ii): If H is a subgroup of a group G and X = G/H is the family
of all left cosets of H in G, then G acts on G/H by g : aH ‚ÜígaH. The G-set X is
transitive, and the stabilizer of aH ‚ààG/H is aHa‚àí1; that is, gaH = aH if and only if
a‚àí1ga ‚ààH if and only if g ‚ààaHa‚àí1.
Proposition 8.157.
If X is a doubly transitive G-set, then
|G| = n(n ‚àí1)|Gx,y|,
where n = |X| and Gx,y = {g ‚ààG : gx = x and gy = y}. Moreover, if X is a faithful
G-set, then |Gx,y| is a divisor of (n ‚àí2)!.
Proof.
First, Theorem 2.98 gives |G| = n|Gx|, because X is a transitive G-set. Now
X ‚àí{x} is a transitive Gx-set, by Proposition 8.155, and so
|Gx| = |X ‚àí{x}||(Gx)y| = (n ‚àí1)|Gx,y|,
because (Gx)y = Gx,y. The last remark follows, in this case, from Gx,y being a subgroup
of SX‚àí{x,y} ‚àº= Sn‚àí2.
‚Ä¢
It is now easy to give examples of groups that are not doubly transitive, for the orders
of doubly transitive groups are constrained.
DeÔ¨Ånition.
A transitive G-set X is called regular if only the identity element of G Ô¨Åxes
any element of X; that is, Gx = {1} for all x ‚ààX.
For example, Cayley's theorem shows that every group G is isomorphic to a regular
subgroup of SG. The notion of regularity extends to doubly transitive groups.
DeÔ¨Ånition.
A doubly transitive G-set X is sharply doubly transitive if only the identity
of G Ô¨Åxes two elements of X; that is, Gx,y = {1} for all distinct pairs x, y ‚ààX.
Proposition 8.158.
The following conditions are equivalent for a faithful doubly transi-
tive G-set X with |X| = n.
(i) X is sharply doubly transitive.
(ii) If (x1, x2) and (y1, y2) are 2-tuples in X √ó X with x1 Ã∏= x2 and y1 Ã∏= y2, then there
is a unique g ‚ààG with y1 = gx1 and y2 = gy2.

640
Algebras
Ch. 8
(iii) |G| = n(n ‚àí1).
(iv) Gx,y = {1} for all distinct x, y ‚ààX.
(v) For every x ‚ààX, the Gx-set X ‚àí{x} is regular.
Proof.
All the implications are routine.
‚Ä¢
Example 8.159.
(i) S3 and A4 are sharply doubly transitive groups.
(ii) The afÔ¨Åne group Aff(1, R) was deÔ¨Åned in Exercise 2.46 on page 80; it consists of all
the functions f : R ‚ÜíR of the form f (x) = ax + b with a Ã∏= 0 under composition, and
it is isomorphic to the subgroup of GL(2, R) consisting of all matrices of the form
 a b
0 1

.
It is plain that we can deÔ¨Åne Aff(1, k) for any Ô¨Åeld k in a similar way. In particular, if k
is the Ô¨Ånite Ô¨Åeld Fq, then the afÔ¨Åne group Aff(1, Fq) is Ô¨Ånite, and of order q(q ‚àí1). The
reader may check that Fq is a sharply doubly transitive Aff(1, Fq)-set.
‚óÄ
Notation.
If G is a group, then G# = {g ‚ààG : g Ã∏= 1}.
By Cayley's theorem, every group is regular. We now consider transitive groups G such
that each g ‚ààG# has at most one Ô¨Åxed point. In case every g ‚ààG# has no Ô¨Åxed points,
then we say that the action of G is Ô¨Åxed point free. J. G. Thompson proved that if a Ô¨Ånite
group H has a Ô¨Åxed point free automorphism Œ± of prime order (that is, the action of the
group G = ‚ü®Œ±‚ü©on H# is Ô¨Åxed point free), then H is nilpotent (see Robinson, A Course in
the Theory of Groups, pages 306-307). Thus, let us consider such actions in which there
is some g ‚ààG# that has a Ô¨Åxed point; that is, the action of G is not regular.
DeÔ¨Ånition.
A Ô¨Ånite group G is a Frobenius group if there exists a transitive G-set X
such that
(i) every g ‚ààG# has at most one Ô¨Åxed point;
(ii) there is some g ‚ààG# that does have a Ô¨Åxed point.
If x ‚ààX, we call Gx a Frobenius complement of G.
Note that condition (i) implies that the G-set X in the deÔ¨Ånition is necessarily faithful.
Let us rephrase the two conditions: (i) that every g ‚ààG# has at most one Ô¨Åxed point says
that Gx,y = {1}; (ii) that there is some g ‚ààG# that does have a Ô¨Åxed point says that
Gx Ã∏= {1}.
Example 8.160.
(i) The symmetric group S3 is a Frobenius group: X = {1, 2, 3} is a faithful transitive
S3-set; no Œ± ‚àà(S3)# Ô¨Åxes two elements; each transposition (i
j) Ô¨Åxes one element.
The cyclic subgroups ‚ü®(i
j)‚ü©are Frobenius complements (so Frobenius complements
need not be unique). A permutation Œ≤ ‚ààS3 has no Ô¨Åxed points if and only if Œ≤ is a

Sec. 8.6
Theorems of Burnside and of Frobenius
641
3-cycle. We are going to prove that, in every Frobenius group, 1 together with all those
elements having no Ô¨Åxed points comprise a normal subgroup.
(ii) The example of S3 in part (i) can be generalized. Let X be a G-set, with at least three
elements, which is a sharply doubly transitive G-set. Then X is transitive, Gx,y = {1}, and
Gx Ã∏= {1} (for if x, y, z ‚ààX are distinct, there exists g ‚ààG with x = gx and z = gy).
Therefore, every sharply doubly transitive group G is a Frobenius group.
‚óÄ
Proposition 8.161.
A Ô¨Ånite group G is a Frobenius group if and only if it contains a
proper nontrivial subgroup H such that H ‚à©gHg‚àí1 = {1} for all g /‚ààH.
Proof.
Let X be a G-set as in the deÔ¨Ånition of Frobenius group. Choose x ‚ààX, and
deÔ¨Åne H = Gx. Now H is a proper subgroup of G, for transitivity does not permit gx = x
for all g ‚ààG. To see that H is nontrivial, choose g ‚ààG# having a Ô¨Åxed point; say, gy = y.
If y = x, then g ‚ààGx = H. If y Ã∏= x, then transitivity provides h ‚ààG with hy = x, and
Exercise 2.99 on page 114 gives H = Gx = hGyh‚àí1 Ã∏= {1}. If g /‚ààH, then gx Ã∏= x. Now
g(Gx)g‚àí1 = Ggx. Hence, if h ‚ààH ‚à©gHg‚àí1 = Gx ‚à©Ggx, then h Ô¨Åxes x and gx; that is,
h ‚ààGx,y = {1}.
For the converse, we take X to be the G-set G/H of all left cosets of H in G, where
g : aH ‚ÜígaH for all g ‚ààG. We remarked earlier that X is a transitive G-set and that
the stabilizer of aH ‚ààG/H is the subgroup aHa‚àí1 of G. Since H Ã∏= {1}, we see that
GaH Ã∏= {1}. Finally, if aH Ã∏= bH, then
GaH,bH = GaH ‚à©GbH = aHa‚àí1 ‚à©bHb‚àí1 = a

H ‚à©a‚àí1bHb‚àí1a

a‚àí1 = {1},
because a‚àí1b /‚ààH. Therefore, G is a Frobenius group.
‚Ä¢
The signiÔ¨Åcance of this last proposition is that it translates the deÔ¨Ånition of Frobenius
group from the language of G-sets into the language of abstract groups.
DeÔ¨Ånition.
If X is a G-set, deÔ¨Åne its Frobenius kernel to be the subset
N = {1} ‚à™{g ‚ààG : g has no Ô¨Åxed points}.
When X is transitive, we can describe N in terms of a stabilizer Gx. If a /‚ààN #,
then there is some y ‚ààX with ay = y. Since G acts transitively, there is g ‚ààG with
gx = y, and a ‚ààGy = gGxg‚àí1. Hence, a ‚àà!
g‚ààG gGxg‚àí1. For the reverse inclusion, if
a ‚àà!
g‚ààG gGxg‚àí1, then a ‚ààgGxg‚àí1 = Ggx for some g ‚ààG, and so a has a Ô¨Åxed point;
that is, a /‚ààN. We have proved that
N = {1} ‚à™

G ‚àí

g‚ààG
gGxg‚àí1
.
Exercise 5.32 on page 278 shows that if Gx is a proper subgroup of G, then G Ã∏=
!
g‚ààG gGxg‚àí1, and so N Ã∏= {1} in this case.

642
Algebras
Ch. 8
Proposition 8.162.
If G is a Frobenius group with Frobenius complement H and Frobe-
nius kernel N, then |N| = [G : H].
Proof.
By Proposition 8.161, there is a disjoint union
G = {1} ‚à™

g‚ààG
gH#g‚àí1
‚à™N #.
Note that NG(H) = H: If g /‚ààH, then H ‚à©gHg‚àí1 = {1}, and so gHg‚àí1 Ã∏= H. Hence,
the number of conjugates of H is [G : NG(H)] = [G : H] (Proposition 2.101). Therefore,
| !
g‚ààG gH#g‚àí1| = [G : H](|H| ‚àí1), and so
|N| = |N #| + 1 = |G| ‚àí([G : H](|H| ‚àí1)) = [G : H].
‚Ä¢
The Frobenius kernel may not be a subgroup of G. It is very easy to check that if g ‚ààN,
then g‚àí1 ‚ààN and aga‚àí1 ‚ààN for every a ‚ààG; the difÔ¨Åculty is in proving that N is closed
under multiplication. For example, if V = kn is the vector space of all n√ó1 column vectors
over a Ô¨Åeld k, then V #, the set of nonzero vectors in V , is a faithful transitive GL(V )-set.
Now A ‚ààGL(V ) has a Ô¨Åxed point if and only if there is some v ‚ààV # with Av = v; that
is, A has a Ô¨Åxed point if and only if 1 is an eigenvalue of A. Thus, the Frobenius kernel
now consists of the identity matrix together with all linear transformations which do not
have 1 as an eigenvalue. Let |k| ‚â•4, and let Œ± be a nonzero element of k with Œ±2 Ã∏= 1.
Then A =
 Œ± 0
0 Œ±

and B =

Œ±‚àí1 0
0
Œ±

lie in N, but their product AB =

1 0
0 Œ±2

does not lie
in N. However, if G is a Frobenius group, then N is a subgroup; the only known proof of
this fact uses characters.
We have already remarked that if œà is a character on a subgroup H of a group G, then
the restriction (œà‚ÜøG)H need not equal œà. The next proof shows that irreducible characters
of a Frobenius complement do extend to irreducible characters of G.
Lemma 8.163.
Let G be a Frobenius group with Frobenius complement H and Frobenius
kernel N. For every irreducible character œà on H other than the trivial character œà1,
deÔ¨Åne the generalized character
œï = œà ‚àídœà1,
where d = œà(1). Then œà‚àó= œï‚ÜøG + dœá1 is an irreducible character on G, and œà‚àó
H = œà;
that is, œà‚àó(h) = œà(h) for all h ‚ààH.
Proof.
Note Ô¨Årst that œï(1) = 0. We claim that the induced generalized character œï‚ÜøG
satisÔ¨Åes the equation
(œï‚ÜøG)H = œï.
If t1 = 1, . . . , tn is a transversal of H in G, then for g ‚ààG, the matrix of œï‚ÜøG(g) on
page 627 has the blocks ÀôB(t‚àí1
i
gti) on its diagonal, where ÀôB(t‚àí1
i
gti) = 0 if t‚àí1
i
gti /‚ààH
(this is just the matrix version of Theorem 8.142). If h ‚ààH, then t‚àí1
i
hti /‚ààH for all i Ã∏= 1,
and so ÀôB(t‚àí1
i
hti) = 0. Therefore, there is only one nonzero diagonal block, and
tr(œï‚ÜøG(h)) = tr(B(h));

Sec. 8.6
Theorems of Burnside and of Frobenius
643
that is,
œï‚ÜøG(h) = œï(h).
We have just seen that œï‚ÜøG is a generalized character on G such that (œï‚ÜøG)H = œï. By
Frobenius reciprocity (Theorem 8.145),
(œï‚ÜøG, œï‚ÜøG)G = (œï, (œï‚ÜøG)H)H = (œï, œï)H.
But œï = œà ‚àídœà1, so that orthogonality of œà and œà1 gives
(œï, œï)H = 1 + d2.
Similarly,
(œï‚ÜøG, œá1)G = (œï, œà1)H = ‚àíd,
where œá1 is the trivial character on G. DeÔ¨Åne
œà‚àó= œï‚ÜøG + dœá1.
Now œà‚àóis a generalized character on G, and
(œà‚àó, œà‚àó)G = (œï‚ÜøG, œï‚ÜøG)G + 2d(œï‚ÜøG, œá1)G + d2
=1 + d2 ‚àí2d2 + d2 = 1.
We have
(œà‚àó)H = (œï‚ÜøG)H + d(œá1)H = œï + dœà1 = (œà ‚àídœà1) + dœà1 = œà.
Since œà‚àó(1) = œà(1) > 0, Corollary 8.130 says that œà‚àóis an irreducible character on G. ‚Ä¢
Theorem 8.164 (Frobenius).
Let G be a Frobenius group with Frobenius complement
H and Frobenius kernel N. Then N is a normal subgroup of G, N ‚à©H = {1}, and
N H = G.
Remark.
A group G having a subgroup Q and a normal subgroup K such that
K ‚à©Q = {1} and K Q = G is called a semidirect product. We will discuss such groups in
Chapter 10.
‚óÄ
Proof.
For every irreducible character œà on H other than the trivial character œà1, deÔ¨Åne
the generalized character œï = œà ‚àídœà1, where d = œà(1). By the lemma, œà‚àó= œï‚ÜøG +dœá1
is an irreducible character on G. DeÔ¨Åne
N ‚àó=
"
œàÃ∏=œà1
ker œà‚àó.
Of course, N ‚àóis a normal subgroup of G.

644
Algebras
Ch. 8
By Lemma 8.163, œà‚àó(h) = œà(h) for all h ‚ààH; in particular, if h = 1, we have
œà‚àó(1) = œà(1) = d.
(5)
If g ‚ààN #, then for all a ‚ààG, we have g /‚ààaHa‚àí1 (for g has no Ô¨Åxed points), and so
Àôœï(aga‚àí1) = 0. The induced character formula, Theorem 8.142, now gives œï‚ÜøG(g) = 0.
Hence, if g ‚ààN #, then Eq. (5) gives
œà‚àó(g) = œï‚ÜøG(g) + dœá1(g) = d.
We conclude that if g ‚ààN, then
œà‚àó(g) = d = œà‚àó(1);
that is, g ‚ààker œà‚àó. Therefore,
N ‚äÜN ‚àó.
The reverse inclusion will arise from a counting argument.
Let h ‚ààH ‚à©N ‚àó. Since h ‚ààH, Lemma 8.163 gives œà‚àó(h) = œà(h). On the other
hand, since h ‚ààN ‚àó, we have œà‚àó(h) = œà‚àó(1) = d. Therefore, œà(h) = œà‚àó(h) =
d = œà(1), so that h ‚ààker œà for every irreducible character œà on H. Consider the
regular character, afforded by the regular representation œÅ on H: œáœÅ = 
i niœài. Now
œáœÅ(h) = 
i niœài(h) Ã∏= 0, so that Example 8.125(ii) gives h = 1. Thus,
H ‚à©N ‚àó= {1}.
Next, |G| = |H|[G : H] = |H||N|, by Proposition 8.162. Note that H N ‚àóis a subgroup
of G, because N ‚àó‚úÅG. Now |H N ‚àó||H ‚à©N ‚àó| = |H||N ‚àó|, by the second isomorphism
theorem; since H ‚à©N ‚àó= {1}, we have |H||N| = |G| ‚â•|H N ‚àó| = |H||N ‚àó|. Hence,
|N| ‚â•|N ‚àó|. But |N| ‚â§|N ‚àó|, because N ‚äÜN ‚àó, and so N = N ‚àó. Therefore, N ‚úÅG,
H ‚à©N = {1}, and H N = G.
‚Ä¢
Much more can be said about the structure of Frobenius groups. Every Sylow sub-
group of a Frobenius complement is either cyclic or generalized quaternion (see Huppert,
Endliche Gruppen I, page 502), and it is a consequence of J. G. Thompson's theorem on
Ô¨Åxed-point-free automorphisms that every Frobenius kernel is nilpotent; that is, N is the
direct product of its Sylow subgroups. The reader is referred to Curtis-Reiner, Representa-
tion Theory of Finite Groups and Associative Algebras, pages 242-246, or Feit, Characters
of Finite Groups, pages 133-139.

Sec. 8.6
Theorems of Burnside and of Frobenius
645
EXERCISES
8.68 Prove that the afÔ¨Åne group Aff(1, Fq) in Example 8.159(ii) is sharply doubly transitive.
8.69 If H ‚â§G and the family of left cosets G/H is a G-set via the representation on cosets, prove
that G/H is a faithful G-set if and only if 
a‚ààG aHa‚àí1 = {1}. Give an example in which
G/H is not a faithful G-set.
8.70 Prove that every Sylow subgroup of SL(2, F5) is either cyclic or quaternion.
8.71 A subset A of a group G is a T.I. set (or a trivial intersection set) if A ‚äÜNG(A) and
A ‚à©gAg‚àí1 ‚äÜ{1} for all g /‚ààNG(A).
(i) Prove that a Frobenius complement H in a Frobenius group G is a T. I. set.
(ii) Let A be a T. I. set in a Ô¨Ånite group G, and let N = NG(A). If Œ± be a class function
vanishing on N ‚àíA and Œ≤ is a class function on N vanishing on
!
g‚ààG(Ag ‚à©N)

‚àíA,
prove, for all g ‚ààN#, that Œ±‚ÜøG(g) = Œ±(g) and Œ≤‚ÜøG(g) = Œ≤(g).
Hint. See the proofs of Lemma 8.164 and Theorem 8.163.
(iii) If Œ±(1) = 0, prove that (Œ±, Œ≤)N = (Œ±‚ÜøG, Œ≤‚ÜøG)G.
(iv) Let H be a self-normalizing subgroup of a Ô¨Ånite group G; that is, H = NG(H). If
H is a T. I. set, prove that there is a normal subgroup K of G with K ‚à©H = {1} and
K H = G.
Hint. See Feit, Characters of Finite Groups, page 124.
8.72 Prove that there are no nonabelian simple groups of order n, where 60 < n ‚â§100.
Hint. By Burnside's theorem, the only candidates for n in the given range are 66, 70, 78, 84,
and 90, and 90 was eliminated in Exercise 5.29(ii) on page 278.
8.73 Prove that there are no nonabelian simple groups of order n, where 101 ‚â§n < 168. We
remark that PSL(2, F7) is a simple group of order 168, and it is the unique such group, to
isomorphism. With Proposition 5.41, Corollary 5.68, and Exercise 8.72, we see that A5 is the
only nonabelian simple group of order strictly less than 168.
Hint. By Burnside's theorem, the only candidates for n in the given range are 102, 105, 110,
120, 126, 130, 132, 138, 140, 150, 154, 154, 156, and 165. Use Exercise 2.98 on page 114
and Exercises 5.30 and 5.31 on page 278.

9
Advanced Linear Algebra
This chapter begins with the study of modules over PIDs, including characterizations of
their projective, injective, and Ô¨Çat modules. Our emphasis, however, is on Ô¨Ånitely gener-
ated modules, because the generalization of the Fundamental Theorem of Finite Abelian
Groups, when applied to k[x]-modules, yields the rational and Jordan canonical forms for
matrices. The Smith normal form is also discussed, for it can be used to compute the invari-
ants of a matrix. We then consider bilinear and quadratic forms on a vector space, which
lead to symplectic and orthogonal groups. Multilinear algebra is the next step, leading to
tensor algebras, exterior algebras, and determinants. We end with an introduction to Lie
algebras, which can be viewed as a way of dealing with a family of linear transformations
instead of with individual ones.
9.1 MODULES OVER PIDS
The structure theorems for Ô¨Ånite abelian groups will now be generalized to modules over
PIDs. As we have just said, this is not mere generalization for its own sake, for the module
version will yield canonical forms for matrices. Not only do the theorems generalize, but
the proofs of the theorems generalize as well, as we shall see.
DeÔ¨Ånition.
Let M be an R-module. If m ‚ààM, then its order ideal (or annihilator) is
ann(m) = {r ‚ààR : rm = 0}.
We say that m has Ô¨Ånite order (or is a torsion1 element) if ann(m) Ã∏= {0}; otherwise, m has
inÔ¨Ånite order.
When a commutative ring R is regarded as a module over itself, its identity 1 has inÔ¨Ånite
order, for ann(1) = {0}.
1The etymology of the word torsion is given on page 267.
646

Sec. 9.1
Modules over PIDs
647
Order ideals generalize the group-theoretic notion of the order of an element. Recall that
if G is an additive abelian group, then an element g ‚ààG has Ô¨Ånite order if ng = 0 for some
positive integer n, while g has order d if d is the smallest positive integer with dg = 0. On
the other hand, ann(g) is an ideal in Z and, as any nonzero ideal in Z, it is generated by
the smallest positive integer in it. Thus, the order ideal ann(g) = (d), the principal ideal
generated by the order d of g. In Proposition 7.12, we proved that if M = ‚ü®m‚ü©is a cyclic
R-module, where R is any commutative ring, then M ‚àº= R/I. The ideal I in this corollary
is ker œï, where œï : R ‚ÜíM is the map r ‚Üírm, so that I = ann(m), and
‚ü®m‚ü©‚àº= R/ ann(m).
DeÔ¨Ånition.
If M is an R-module, where R is a domain, then its torsion submodule2 t M
is deÔ¨Åned by
t M = {m ‚ààM : m has Ô¨Ånite order}.
Proposition 9.1.
If R is a domain and M is an R-module, then t M is a submodule of M.
Proof.
If m, m‚Ä≤ ‚ààt M, then there are nonzero elements r,r‚Ä≤ ‚ààR with rm = 0 and r‚Ä≤m‚Ä≤ =
0. Clearly, rr‚Ä≤(m + m‚Ä≤) = 0. Since R is a domain, rr‚Ä≤ Ã∏= 0, and so ann(m + m‚Ä≤) Ã∏= {0};
therefore, m + m‚Ä≤ ‚ààt M.
If s ‚ààR, then sm ‚ààt M, for r ‚ààann(sm) because rsm = 0.
‚Ä¢
This proposition can be false if R is not a domain. For example, let R = I6. In M = I6,
both [3] and [4] have Ô¨Ånite order, for [2] ‚ààann([3]) and [3] ‚ààann([4]). On the other hand,
[3] + [4] = [1], and [1] has inÔ¨Ånite order in M, for ann([1]) = {0}.
For the remainder of this section, R will be a domain (indeed, it will soon be restricted
even further).
DeÔ¨Ånition.
If R is a domain and M is an R-module, then M is torsion if t M = M, while
M is torsion-free if t M = {0}.
Proposition 9.2.
Let M and M‚Ä≤ be R-modules, where R is a domain.
(i) M/tM is torsion-free.
(ii) If M ‚àº= M‚Ä≤, then t M ‚àº= t M‚Ä≤ and M/t M ‚àº= M‚Ä≤/t M‚Ä≤.
Proof.
(i) Assume that m +t M Ã∏= 0 in M/t M; that is, m has inÔ¨Ånite order. If m +t M has
Ô¨Ånite order, then there is some r ‚ààR with r Ã∏= 0 such that 0 = r(m + t M) = rm + t M;
that is, rm ‚ààt M. Thus, there is s ‚ààR with s Ã∏= 0 and with 0 = s(rm) = (sr)m. But
sr Ã∏= 0, since R is a domain, and so ann(m) Ã∏= {0}; this contradicts m having inÔ¨Ånite order.
2There is a generalization of the torsion submodule, called the singular submodule, which is deÔ¨Åned for left
R-modules over any not necessarily commutative ring. See Dauns, Modules and Rings, pages 231-238.

648
Advanced Linear Algebra
Ch. 9
(ii) If œï : M ‚ÜíM‚Ä≤ is an isomorphism, then œï(t M) ‚äÜt M‚Ä≤, for if rm = 0 with r Ã∏= 0, then
rœï(m) = œï(rm) = 0 (this is true for any R-homomorphism); hence, œï|t M : t M ‚Üít M‚Ä≤ is
an isomorphism (with inverse œï‚àí1|t M‚Ä≤). For the second statement, the map œï : M/t M ‚Üí
M‚Ä≤/t M‚Ä≤, deÔ¨Åned by œï : m + t M ‚Üíœï(m) + t M‚Ä≤, is easily seen to be an isomorphism.
‚Ä¢
Here is a fancy proof of Proposition 9.2. There is a functor t : RMod ‚ÜíRMod deÔ¨Åned
on modules by M ‚Üít M and on morphisms by œï ‚Üíœï|t M. That t M ‚àº= t M‚Ä≤ follows from
the fact that every functor preserves equivalences.
A non-noetherian commutative ring R, by its very deÔ¨Ånition, has an ideal that is not
Ô¨Ånitely generated. Now R, viewed as a module over itself, is Ô¨Ånitely generated; indeed, it
is cyclic (with generator 1). Thus, it is possible that a submodule of a Ô¨Ånitely generated
module need not, itself, be Ô¨Ånitely generated. This cannot happen when R is a PID; in fact,
we have proved, in Proposition 7.23(ii), that if R is a PID, then every submodule S of a
Ô¨Ånitely generated R-module is itself Ô¨Ånitely generated; indeed, if M can be generated by n
elements, then S can be generated by n or fewer elements.
Theorem 9.3.
If R is a PID, then every Ô¨Ånitely generated torsion-free R-module M is
free.
Proof.
We prove the theorem by induction on n, where M = ‚ü®v1, . . . , vn‚ü©.
If n = 1, then M is cyclic; hence, M = ‚ü®v1‚ü©‚àº= R/ ann(v1). Since M is torsion-free,
ann(v1) = {0}, so that M ‚àº= R, and hence M is free.
For the inductive step, let M = ‚ü®v1, . . . , vn+1‚ü©and deÔ¨Åne
S = {m ‚ààM : there is r ‚ààR,r Ã∏= 0, with rm ‚àà‚ü®vn+1‚ü©};
it is easy to check that S is a submodule of M. Now M/S is torsion-free: If x ‚ààM, x /‚ààS,
and r(x +S) = 0, then rx ‚ààS; hence, there is r‚Ä≤ ‚ààR with r‚Ä≤ Ã∏= 0 and rr‚Ä≤x ‚àà‚ü®vn+1‚ü©. Since
rr‚Ä≤ Ã∏= 0, we have x ‚ààS, a contradiction. Plainly, M/S can be generated by n elements,
namely, v1 + S, . . . , vn + S, and so M/S is free, by the inductive hypothesis. Since free
modules are projective, Proposition 7.54 gives
M ‚àº= S ‚äï(M/S).
Thus, the proof will be completed once we prove that S ‚àº= R.
If x ‚ààS, then there is some nonzero r ‚ààR with rx ‚àà‚ü®vn+1‚ü©; that is, there is a ‚ààR with
rx = avn+1. DeÔ¨Åne œï : S ‚ÜíQ = Frac(R), the fraction Ô¨Åeld of R, by œï : x ‚Üía/r. It is
a straightforward calculation, left to the reader, that œï is a (well-deÔ¨Åned) injective R-map.
If D = im œï, then D is a Ô¨Ånitely generated submodule of Q.
The proof will be complete if we can prove that every Ô¨Ånitely generated submodule D
of Q is cyclic. Now
D = ‚ü®b1/c1, . . . , bm/cm‚ü©,
where bi, ci ‚ààR. Let c = 
i ci, and deÔ¨Åne f : D ‚ÜíR by f : d ‚Üícd for all d ‚ààD (it
is plain that f has values in R, for multiplication by c clears all denominators). Since D is
torsion-free, f is an injective R-map, and so D is isomorphic to a submodule of R; that is,
D is isomorphic to an ideal of R. Since R is a PID, every nonzero ideal in R is isomorphic
to R; hence, S ‚àº= im œï = D ‚àº= R.
‚Ä¢

Sec. 9.1
Modules over PIDs
649
Corollary 9.4.
If R is a PID, then every submodule S of a Ô¨Ånitely generated free R-
module F is itself free, and rank(S) ‚â§rank(F). In particular, every Ô¨Ånitely generated
projective R-module P is free.
Proof.
By Proposition 7.23(ii), the submodule S can be generated by n or fewer elements,
where n = rank(F). Now F is torsion-free, and hence S is torsion-free. Theorem 9.3 now
applies to give S free.
The second statement follows from Theorem 7.56: the characterization of projective
modules as direct summands of free modules. Since P is Ô¨Ånitely generated, there is a
Ô¨Ånitely generated free module F and a surjection q : F ‚ÜíP; since P is projective, there
is a map j : P ‚ÜíF with qj = 1P. Thus, j restricts to an isomorphism of P with a
submodule of F, which is free, by the Ô¨Årst part of the proof.
‚Ä¢
Remark.
Both statements in the corollary are true without the Ô¨Åniteness hypothesis, and
we shall soon prove them.
‚óÄ
Corollary 9.5.
(i) If R is a PID, then every Ô¨Ånitely generated R-module M is a direct sum
M = t M ‚äïF,
where F is a Ô¨Ånitely generated free R-module.
(ii) If M and M‚Ä≤ are Ô¨Ånitely generated R-modules, where R is a PID, then M ‚àº= M‚Ä≤ if
and only if t M ‚àº= t M‚Ä≤ and rank(M/t M) = rank(M‚Ä≤/t M‚Ä≤).
Proof.
(i) The quotient module M/t M is Ô¨Ånitely generated, because M is Ô¨Ånitely gen-
erated, and it is torsion-free, by Proposition 9.2(i). Therefore, M/t M is free, by Theo-
rem 9.3, and hence M/t M is projective. Finally, M ‚àº= t M ‚äï(M/t M), by Corollary 7.55
on page 476.
(ii) By Proposition 9.2(ii), if M ‚àº= M‚Ä≤, then t M ‚àº= t M‚Ä≤ and M/t M ‚àº= M‚Ä≤/t M‚Ä≤. Since
M/t M is Ô¨Ånitely generated torsion-free, it is a free module, as is M‚Ä≤/t M‚Ä≤, and these are
isomorphic if they have the same rank.
Conversely, since M ‚àº= t M ‚äï(M/t M) and M‚Ä≤ ‚àº= t M‚Ä≤ ‚äï(M‚Ä≤/t M‚Ä≤), Proposition 7.30
assembles the isomorphisms on each summand into an isomorphism M ‚ÜíM‚Ä≤.
‚Ä¢
Remark.
This corollary requires the Ô¨Ånitely generated hypothesis. There exist abelian
groups G whose torsion subgroup tG is not a direct summand of G [see Exercise 9.1(iii)
on page 663].
‚óÄ
We can now characterize Ô¨Çat modules over a PID.

650
Advanced Linear Algebra
Ch. 9
Corollary 9.6.
If R is a PID, then an R-module M is Ô¨Çat if and only if it is torsion-free.
Proof.
By Theorem 9.3, every Ô¨Ånitely generated torsion-free R-module is free, and so it
is Ô¨Çat, by Lemma 8.98. By Lemma 8.97, M itself is Ô¨Çat.
Conversely, if M is not torsion-free, then it contains a nonzero element m of Ô¨Ånite
order, say, (r). If i : R ‚ÜíFrac(R) is the inclusion, then m ‚äó1 ‚ààker(1M ‚äói), for in
M ‚äóR Frac(R), we have
m ‚äó1 = m ‚äór
r = rm ‚äó1
r = 0.
On the other hand, m ‚äó1 Ã∏= 0 in M ‚äóR R, for the map m ‚äó1 ‚Üím is an isomorphism
M ‚äóR R ‚ÜíM, by Proposition 8.86. Therefore, M is not Ô¨Çat.
‚Ä¢
Before continuing the saga of Ô¨Ånitely generated modules, we pause to prove an impor-
tant result: the generalization of Corollary 9.4, in which we no longer assume that free
modules F are Ô¨Ånitely generated. We begin with a second proof of the Ô¨Ånitely generated
case that will then be generalized.
Proposition 9.7.
If R is a PID, then every submodule H of a Ô¨Ånitely generated free
R-module F is itself free, and rank(H) ‚â§rank(F).
Proof.
The proof is by induction on n = rank(F). If n = 1, then F ‚àº= R. Thus, H is
isomorphic to an ideal in R; but all ideals are principal, and hence are isomorphic to {0} or
R. Therefore, H is a free module of rank ‚â§1.
Let us now prove the inductive step. If {x1, . . . , xn+1} is a basis of F, deÔ¨Åne F‚Ä≤ =
‚ü®x1, . . . , xn‚ü©, and let H‚Ä≤ = H ‚à©F‚Ä≤. By induction, H‚Ä≤ is a free module of rank ‚â§n. Now
H/H‚Ä≤ = H/(H ‚à©F‚Ä≤) ‚àº= (H + F‚Ä≤)/F‚Ä≤ ‚äÜF/F‚Ä≤ ‚àº= R.
By the base step, either H/H‚Ä≤ = {0} or H/H‚Ä≤ ‚àº= R. In the Ô¨Årst case, H = H‚Ä≤, and we
are done. In the second case, Corollary 7.55 gives H = H‚Ä≤ ‚äï‚ü®h‚ü©for some h ‚ààH, where
‚ü®h‚ü©‚àº= R, and so H is free abelian of rank ‚â§n + 1.
‚Ä¢
We now remove the Ô¨Åniteness hypothesis.
Theorem 9.8.
If R is a PID, then every submodule H of a free R-module F is itself free,
and rank(H) ‚â§rank(F). In particular, every projective R-module H is free.
Proof.
We are going to use the statement, equivalent to the axiom of choice and to Zorn's
lemma (see the Appendix), that every set can be well-ordered. In particular, we may as-
sume that {xk : k ‚ààK} is a basis of F having a well-ordered index set K.
For each k ‚ààK, deÔ¨Åne
F‚Ä≤
k = ‚ü®x j : j ‚â∫k‚ü©
and
Fk = ‚ü®x j : j ‚™Øk‚ü©= F‚Ä≤
k ‚äï‚ü®xk‚ü©;
note that F = !
k Fk. DeÔ¨Åne
H‚Ä≤
k = H ‚à©F‚Ä≤
k
and
Hk = H ‚à©Fk.

Sec. 9.1
Modules over PIDs
651
Now H‚Ä≤
k = H ‚à©F‚Ä≤
k = Hk ‚à©F‚Ä≤
k, so that
Hk/H‚Ä≤
k = Hk/(Hk ‚à©F‚Ä≤
k)
‚àº= (Hk + F‚Ä≤
k)/F‚Ä≤
k ‚äÜFk/F‚Ä≤
k ‚àº= R.
By Corollary 7.55, either Hk = H‚Ä≤
k or Hk = H‚Ä≤
k ‚äï‚ü®hk‚ü©, where hk ‚ààHk ‚äÜH and
‚ü®hk‚ü©‚àº= R. We claim that H is a free R-module with basis the set of all hk. It will then
follow that rank(H) ‚â§rank(F).
Since F = ! Fk, each f ‚ààF lies in some Fk; since K is well-ordered, there is a
smallest index k ‚ààK with f ‚ààFk, and we denote this smallest index by ¬µ( f ). In
particular, if h ‚ààH, then
¬µ(h) = smallest index k with h ‚ààFk.
Note that if h ‚ààH‚Ä≤
k ‚äÜF‚Ä≤
k, then ¬µ(h) ‚â∫k. Let H‚àóbe the submodule of H generated by all
the hk.
Suppose that H‚àóis a proper submodule of H. Let j be the smallest index in
{¬µ(h) : h ‚ààH and h /‚ààH‚àó},
and choose h‚Ä≤ ‚ààH to be such an element having index j; that is, h‚Ä≤ /‚ààH‚àóand ¬µ(h‚Ä≤) = j.
Now h‚Ä≤ ‚ààH ‚à©Fj, because ¬µ(h‚Ä≤) = j, and so
h‚Ä≤ = a + rh j, where a ‚ààH‚Ä≤
j and r ‚ààR.
Thus, a = h‚Ä≤ ‚àírh j ‚ààH‚Ä≤
j and a /‚ààH‚àó; otherwise h‚Ä≤ ‚ààH‚àó(because h j ‚ààH‚àó). Since
¬µ(a) ‚â∫j, we have contradicted j being the smallest index of an element of H not in H‚àó.
We conclude that H‚àó= H; that is, every h ‚ààH is a linear combination of hk's.
It remains to prove that an expression of any h ‚ààH as a linear combination of hk's is
unique. By subtracting two such expressions, it sufÔ¨Åces to prove that if
0 = r1hk1 + r2hk2 + ¬∑ ¬∑ ¬∑ + rnhkn,
then all the coefÔ¨Åcients ri = 0. Arrange the terms so that k1 ‚â∫k2 ‚â∫¬∑ ¬∑ ¬∑ ‚â∫kn. If rn Ã∏= 0,
then rnhkn ‚àà

hkn
 
‚à©H‚Ä≤
kn = {0}, a contradiction. Therefore, all ri = 0, and so H is a free
module with basis {hk : k ‚ààK}.
‚Ä¢
We return to the discussion of Ô¨Ånitely generated modules. In light of Proposition 9.2(ii),
the problem of classifying Ô¨Ånitely generated R-modules, when R is a PID, is reduced to
classifying Ô¨Ånitely generated torsion modules. Let us say at once that these modules are
precisely the generalization of Ô¨Ånite abelian groups.
Proposition 9.9.
An abelian group G is Ô¨Ånite if and only if it is a Ô¨Ånitely generated torsion
Z-module.

652
Advanced Linear Algebra
Ch. 9
Proof.
If G is Ô¨Ånite, it is obviously Ô¨Ånitely generated; moreover, Lagrange's theorem says
that G is torsion.
Conversely, suppose that G = ‚ü®x1, . . . , xn‚ü©and there are nonzero integers di with
di xi = 0 for all i. It follows that each g ‚ààG can be written
g = m1x1 + ¬∑ ¬∑ ¬∑ + mnxn,
where 0 ‚â§mi < di for all i. Therefore, |G| ‚â§
i di, and so G is Ô¨Ånite.
‚Ä¢
DeÔ¨Ånition.
Let R be a PID and M be an R-module. If P = (p) is a nonzero prime ideal
in R, then M is (p)-primary if, for each m ‚ààM, there is n ‚â•1 with pnm = 0.
If M is any R-module, then its (p)-primary component is
MP = {m ‚ààM : pnm = 0 for some n ‚â•1}.
If we do not want to specify the prime P, we may write that a module is primary (instead
of P-primary). It is clear that primary components are submodules.
All of the coming theorems in this section were Ô¨Årst proved for abelian groups and,
later, generalized to modules over PIDs. The translation from abelian groups to modules
is straightforward, but let us see this explicitly by generalizing the primary decomposition
to modules over PIDs by adapting the proof given in Chapter 5 for abelian groups. For the
reader's convenience, we reproduce this proof with the Ô¨Åniteness hypothesis eliminated.
Theorem 9.10 (Primary Decomposition).
(i) Every torsion abelian group G is a direct sum of its p-primary components:
G =

p
G p.
(ii) Every torsion R-module M,
where R is a PID, is a direct sum of its
P-primary components:
M =

P
MP.
Proof.
(i) Let x ‚ààG be nonzero, and let its order be d. By the fundamental theorem of
arithmetic, there are distinct primes p1, . . . , pn and positive exponents e1, . . . , en with
d = pe1
1 ¬∑ ¬∑ ¬∑ pen
n .
DeÔ¨Åne ri = d/pei
i , so that pei
i ri = d. It follows that ri x ‚ààG pi for each i. But the gcd of
r1, . . . ,rn is 1, and so there are integers s1, . . . , sn with 1 = 
i siri. Therefore,
x =

i
siri x ‚àà
6
p
G p
7
.

Sec. 9.1
Modules over PIDs
653
For each prime p, write Hp =
8!
qÃ∏=p Gq
9
. By Exercise 7.79 on page 519, it sufÔ¨Åces to
prove that if
x ‚ààG p ‚à©Hp,
then x = 0. Since x ‚ààG p, we have p‚Ñìx = 0 for some ‚Ñì‚â•0; since x ‚ààHp, we have
ux = 0, where u = q f1
1 ¬∑ ¬∑ ¬∑ q fn
n , qi Ã∏= p, and fi ‚â•1 for all i. But p‚Ñìand u are relatively
prime, so there exist integers s and t with 1 = sp‚Ñì+ tu. Therefore,
x = (sp‚Ñì+ tu)x = sp‚Ñìx + tux = 0.
(ii) We now translate the proof just given into the language of modules. If m ‚ààM is
nonzero, its order ideal ann(m) = (d), for some d ‚ààR. By unique factorization, there are
irreducible elements p1, . . . , pn, no two of which are associates, and positive exponents
e1, . . . , en with
d = pe1
1 ¬∑ ¬∑ ¬∑ pen
n .
By Proposition 6.17, Pi = (pi) is a prime ideal for each i. DeÔ¨Åne ri = d/pei
i , so that
pei
i ri = d. It follows that rim ‚ààMPi for each i. But the gcd of the elements r1, . . . ,rn
is 1, and so there are elements s1, . . . , sn ‚ààR with 1 = 
i siri. Therefore,
m =

i
sirim ‚àà
6
P
MP
7
.
For each prime P, write HP =
8!
QÃ∏=P G Q
9
. By Exercise 7.79 on page 519, it sufÔ¨Åces
to prove that if
m ‚ààMP ‚à©HP,
then m = 0. Since m ‚ààMP where P = (p), we have p‚Ñìm = 0 for some ‚Ñì‚â•0; since
m ‚ààHP, we have um = 0, where u = q f1
1 ¬∑ ¬∑ ¬∑ q fn
n , Qi = (qi), and fi ‚â•1. But p‚Ñìand u
are relatively prime, so there exist s, t ‚ààR with 1 = sp‚Ñì+ tu. Therefore,
m = (sp‚Ñì+ tu)m = sp‚Ñìm + tum = 0.
‚Ä¢
Proposition 9.11.
Two torsion modules M and M‚Ä≤ over a PID are isomorphic if and only
if MP ‚àº= M‚Ä≤
P for every nonzero prime ideal P.
Proof.
If f : M ‚ÜíM‚Ä≤ is an R-map, then f (MP) ‚äÜM‚Ä≤
P for every prime ideal P = (p),
for if p‚Ñìm = 0, then 0 = f (p‚Ñìm) = p‚Ñìf (m). If f is an isomorphism, then f ‚àí1 : M‚Ä≤ ‚Üí
M is also an isomorphism. It follows that each restriction f |MP : MP ‚ÜíM‚Ä≤
P is an
isomorphism, with inverse f ‚àí1|M‚Ä≤
P. Conversely, if there are isomorphisms fP : MP ‚Üí
M‚Ä≤
P for all P, then there is an isomorphism œï : 
P MP ‚Üí
P M‚Ä≤
P given by 
P m P ‚Üí

P fP(m P).
‚Ä¢

654
Advanced Linear Algebra
Ch. 9
We remark that there is a fancy proof here, just as there is for Proposition 9.2. DeÔ¨Åne
a "P-torsion functor" tP : RMod ‚ÜíRMod on modules by M ‚Üí(t M)P and on mor-
phisms by œï ‚Üíœï|(t M)P. That (t M)P ‚àº= (t M‚Ä≤)P follows from the fact that every functor
preserves equivalences.
For the remainder of this section, we shall merely give deÔ¨Ånitions and statements of
results; the reader should have no difÔ¨Åculty in adapting proofs of theorems about abelian
groups to proofs of theorems about modules over PIDs.
Theorem 9.12 (Basis Theorem).
If R is a PID, then every Ô¨Ånitely generated module
M is a direct sum of cyclic modules in which each cyclic summand is either primary or is
isomorphic to R.
Proof.
By Corollary 9.5, M = t M ‚äïF, where F is Ô¨Ånitely generated free; see Theo-
rem 5.18 for the abelian group version of the basis theorem.
‚Ä¢
Remark.
The reader may be amused by a sophisticated proof of the basis theorem. By
Corollary 9.5 and Theorem 9.10(ii), we may assume that M is P-primary for some prime
ideal P = (p).
There is a positive integer e with peM = {0}: if M = ‚ü®m1, . . . , mn‚ü©, then pei mi = 0
for some ei, and we choose e to be the largest of the ei (we may assume that e = en).
By Exercise 7.4 on page 440, if J = (pe), then M/J M is an R/J-module; indeed, since
J M = {0}, we have M itself is an R/J-module. Now ‚ü®mn‚ü©‚àº= R/(pe) = R/J is an
injective R/J-module, by Proposition 7.76, and Proposition 7.64 says that the submodule
S = ‚ü®mn‚ü©is a direct summand:
M = ‚ü®mn‚ü©‚äïT,
where T is an R/J-submodule of M; a fortiori, T is an R-submodule of M [if r ‚ààR
and t ‚ààT , then (r + J)t makes sense; deÔ¨Åne rt = (r + J)t]. As T can be generated
by fewer than n elements, we may assume, by induction, that it is a direct sum of cyclic
submodules.
‚óÄ
Corollary 9.13.
Every Ô¨Ånitely generated abelian group is a direct sum of cyclic groups,
each of prime power order or inÔ¨Ånite.
When are two Ô¨Ånitely generated modules M and M‚Ä≤ over a PID isomorphic?
Before stating the next lemma, recall that M/pM is a vector space over R/(p), and we
deÔ¨Åne
d(M) = dim(M/pM).
In particular, d(pM) = dim(pM/p2M) and, more generally,
d(pn M) = dim(pn M/pn+1M).
DeÔ¨Ånition.
If M is a Ô¨Ånitely generated (p)-primary R-module, where R is a PID and
P = (p) is a prime ideal, then
UP(n, M) = d(pn M) ‚àíd(pn+1M).

Sec. 9.1
Modules over PIDs
655
Theorem 9.14.
If R is a PID and P = (p) is a prime ideal in R, then any two decompo-
sitions of a Ô¨Ånitely generated P-primary R-module M into direct sums of cyclic modules
have the same number of cyclic summands of each type. More precisely, for each n ‚â•0,
the number of cyclic summands having order ideal (pn+1) is UP(n, M).
Proof.
See Theorem 5.23.
‚Ä¢
Corollary 9.15.
If M and M‚Ä≤ are P-primary R-modules, where R is a PID, then M ‚àº= M‚Ä≤
if and only if UP(n, M) = UP(n, M‚Ä≤) for all n ‚â•0.
Proof.
See Corollary 5.24.
‚Ä¢
DeÔ¨Ånition.
If M is a P-primary R-module, where R is a PID, then the elementary divi-
sors of M are the ideals (pn+1), each repeated with multiplicity UP(n, M).
If M is a Ô¨Ånitely generated torsion R-module, then its elementary divisors are the ele-
mentary divisors of all its primary components.
The next deÔ¨Ånition is motivated by Corollary 5.30: If G is a Ô¨Ånite abelian group with
elementary divisors {p
ei j
i }, then
|G| =

i j
p
ei j
i .
DeÔ¨Ånition.
If M is a Ô¨Ånitely generated torsion R-module, where R is a PID, then the
order of M is the principal ideal generated by the product of its elementary divisors,
namely,

i j p
ei j
i

.
Example 9.16.
If k is a Ô¨Åeld, how many k[x]-modules are there of order (x ‚àí1)3(x + 1)2? By the primary
decomposition, every k[x]-module of order (x ‚àí1)3(x + 1)2 is the direct sum of primary
modules of order (x ‚àí1)3 and (x + 1)2, respectively. There are three modules of order
(x ‚àí1)3, described by the elementary divisors
(x ‚àí1, x ‚àí1, x ‚àí1),
(x ‚àí1, (x ‚àí1)2),
and
(x ‚àí1)3;
there are two modules of order (x + 1)2, described by the elementary divisors
(x + 1, x + 1)
and
(x + 1)2.
Therefore, to isomorphism, there are six modules of order (x ‚àí1)3(x + 1)2.
The reader has probably noticed that this argument is same as that in Example 5.26 on
page 264 classifying all abelian groups of order 72 = 2332.
‚óÄ

656
Advanced Linear Algebra
Ch. 9
Theorem 9.17 (Fundamental Theorem of Finitely Generated Modules).
If R is a
PID, then two Ô¨Ånitely generated R-modules are isomorphic if and only if their torsion
submodules have the same elementary divisors and their free parts have the same rank.
Proof.
By Theorem 9.10(ii), M ‚àº= M‚Ä≤ if and only if, for all primes P, the primary compo-
nents MP and M‚Ä≤
P are isomorphic. Corollary 9.15, Proposition 9.5(ii), and Proposition 9.11
now complete the proof.
‚Ä¢
Here is a second type of decomposition of a Ô¨Ånitely generated torsion module into a
direct sum of cyclics that does not mention primary modules.
Proposition 9.18.
If R is a PID, then every Ô¨Ånitely generated torsion R-module M is a
direct sum of cyclic modules
M = R/(c1) ‚äïR/(c2) ‚äï¬∑ ¬∑ ¬∑ ‚äïR/(ct),
where t ‚â•1 and c1 | c2 | ¬∑ ¬∑ ¬∑ | ct.
Proof.
See Proposition 5.27.
‚Ä¢
DeÔ¨Ånition.
If M is a Ô¨Ånitely generated torsion R-module, where R is a PID, and if
M = R/(c1) ‚äïR/(c2) ‚äï¬∑ ¬∑ ¬∑ ‚äïR/(ct),
where t ‚â•1 and c1 | c2 | ¬∑ ¬∑ ¬∑ | ct, then (c1), (c2), . . . , (ct) are called the invariant factors
of M.
Corollary 9.19.
If M is a Ô¨Ånitely generated torsion module over a PID R, then
(ct) =

r ‚ààR : r M = {0}

,
where (ct) is the last ideal occurring in the decomposition of M in Proposition 9.18.
In particular, if R = k[x], where k is a Ô¨Åeld, then ct is the polynomial of least degree
for which ct M = {0}.
Proof.
For the Ô¨Årst statement, see Corollary 5.28.
The second statement follows from the fact that every nonzero ideal in k[x] is generated
by the monic polynomial of least degree in it.
‚Ä¢
DeÔ¨Ånition.
If M is an R-module, then its exponent (or annihilator) is the ideal
ann(M) = {r ‚ààR : r M = {0}} .
Corollary 9.19 computes the exponent of a Ô¨Ånitely generated torsion module over a PID;
it is the last invariant factor (ct).

Sec. 9.1
Modules over PIDs
657
Corollary 9.20.
If M is a Ô¨Ånitely generated torsion R-module, where R is a PID, with
invariant factors c1, . . . , ct, then the order of M is
t
i=1 ci

.
Proof.
See Corollary 5.30. The reader should check that the principal ideal generated by
the product of the elementary divisors (which is the deÔ¨Ånition of the order of M) is equal
to the principal ideal
t
i=1 ci

.
‚Ä¢
Example 9.21.
We displayed the elementary divisors of k[x]-modules of order (x ‚àí1)3(x + 1)2 in Exam-
ple 9.16; here are their invariant factors.
Elementary divisors
‚Üî
Invariant factors
(x ‚àí1, x ‚àí1, x ‚àí1, x + 1, x + 1) ‚Üîx ‚àí1 | (x ‚àí1)(x + 1) | (x ‚àí1)(x + 1)
(x ‚àí1, (x ‚àí1)2, x + 1, x + 1) ‚Üî(x ‚àí1)(x + 1) | (x ‚àí1)2(x + 1)
((x ‚àí1)3, x + 1, x + 1) ‚Üîx + 1 | (x ‚àí1)3(x + 1)
(x ‚àí1, x ‚àí1, x ‚àí1, (x + 1)2) ‚Üîx ‚àí1 | x ‚àí1 | (x ‚àí1)(x + 1)2
(x ‚àí1, (x ‚àí1)2, (x + 1)2) ‚Üîx ‚àí1 | (x ‚àí1)2(x + 1)2
((x ‚àí1)3, (x + 1)2) ‚Üî(x ‚àí1)3(x + 1)2
‚óÄ
Theorem 9.22 (Invariant Factors).
If R is a PID, then two Ô¨Ånitely generated R-
modules are isomorphic if and only if their torsion submodules have the same invariant
factors and their free parts have the same rank.
Proof.
By Corollary 9.5(i), every Ô¨Ånitely generated R-module M is a direct sum M =
t M ‚äïF, where F is free, and M ‚àº= M‚Ä≤ if and only if t M ‚àº= t M‚Ä≤ and F ‚àº= F‚Ä≤. Corol-
lary 9.5(ii) shows that the free parts F ‚àº= M/t M and F‚Ä≤ ‚àº= M‚Ä≤/t M‚Ä≤ are isomorphic, and
a straightforward generalization of Theorem 5.32 shows that the torsion submodules are
isomorphic.
‚Ä¢
The reader should now be comfortable when we say that a theorem can easily be gener-
alized from abelian groups to modules over PID's. Consequently, we will state and prove
theorems only for abelian groups, leaving the straightforward generalizations to modules
to the reader.
Let us now consider modules that are not Ô¨Ånitely generated. Recall that an abelian
group D is divisible if, for each d ‚ààD and each positive integer n, there exists d‚Ä≤ ‚ààD
with d = nd‚Ä≤. Every quotient of a divisible group is divisible, as is every direct sum of
divisible groups. Now Corollary 7.73 states that an abelian group D is an injective Z-
module if and only if it is divisible, so that classifying divisible abelian groups describes
all injective abelian groups.
Proposition 9.23.
A torsion-free abelian group D is divisible if and only if it is a vector
space over Q.

658
Advanced Linear Algebra
Ch. 9
Proof.
If D is a vector space over Q, then it is a direct sum of copies of Q, for every
vector space has a basis. But Q is a divisible group, and any direct sum of divisible groups
is itself divisible.
Let D be torsion-free and divisible; we must show that D admits scalar multiplication
by rational numbers. Suppose that d ‚ààD and n is a positive integer. Since D is divisible,
there exists d‚Ä≤ ‚ààD with nd‚Ä≤ = d [of course, d‚Ä≤ is a candidate for (1/n)d]. Note, since D
is torsion-free, that d‚Ä≤ is the unique such element: If also nd‚Ä≤‚Ä≤ = d, then n(d‚Ä≤ ‚àíd‚Ä≤‚Ä≤) = 0,
so that d‚Ä≤ ‚àíd‚Ä≤‚Ä≤ has Ô¨Ånite order, and hence is 0. If m/n ‚ààQ, deÔ¨Åne (m/n)d = md‚Ä≤, where
nd‚Ä≤ = d. It is a routine exercise for the reader to prove that this scalar multiplication is
well-deÔ¨Åned [if m/n = a/b, then (m/n)d = (a/b)d] and that the various axioms in the
deÔ¨Ånition of vector space hold.
‚Ä¢
DeÔ¨Ånition.
If G is an abelian group, then dG is the subgroup generated by all the divisible
subgroups of G.
Proposition 9.24.
(i) For any abelian group G, the subgroup dG is the unique maximal divisible subgroup
of G.
(ii) Every abelian group G is a direct sum
G = dG ‚äïR,
where d R = {0}. Hence, R ‚àº= G/dG has no nonzero divisible subgroups.
Proof.
(i) It sufÔ¨Åces to prove that dG is divisible, for then it is obviously the largest such.
If x ‚ààdG, then x = x1 + ¬∑ ¬∑ ¬∑ + xt, where xi ‚ààDi and the Di are divisible subgroups of
G. If n is a positive integer, then there are yi ‚ààDi with xi = nyi, because Di is divisible.
Hence, y = y1 + ¬∑ ¬∑ ¬∑ + yt ‚ààdG and x = ny, so that dG is divisible.
(ii) Since dG is divisible, it is injective, and Proposition 7.64 gives
G = dG ‚äïR,
where R is a subgroup of G. If R has a nonzero divisible subgroup D, then R = D ‚äïS for
some subgroup S, by Proposition 7.64 on page 481. But dG ‚äïD is a divisible subgroup
of G properly containing dG, and this contradicts part (i).
‚Ä¢
DeÔ¨Ånition.
An abelian group G is reduced if dG = {0}; that is, G has no nonzero
divisible subgroups.
In Exercise 9.18 on page 665, we prove that an abelian group G is reduced if and only
if Hom(Q, G) = {0}.
We have just shown that G/dG is always reduced. The reader should compare the roles
of the maximal divisible subgroup dG of a group G with that of tG, its torsion subgroup:

Sec. 9.1
Modules over PIDs
659
G is torsion if tG = G and it is torsion-free if tG = {0}; G is divisible if dG = G and it
is reduced if dG = {0}. There are exact sequences
0 ‚ÜídG ‚ÜíG ‚ÜíG/dG ‚Üí0
and
0 ‚ÜítG ‚ÜíG ‚ÜíG/tG ‚Üí0;
the Ô¨Årst sequence always splits, but we will see, in Exercise 9.1(iii) on page 663, that the
second sequence may not split.
The following group has some remarkable properties.
DeÔ¨Ånition.
If p is a prime, a complex number z is a pth-power root of unity if z pn = 1
for some n ‚â•1. The quasicyclic group (also called the Pr¬®ufer group of type p‚àû) is
Z(p‚àû) = {complex pth power roots of unity}.
Of course, if z is a pth power root of unity, say, z pn = 1, then z is a power of the
primitive pnth root of unity zn = e2œÄi/pn. Note, for every integer n ‚â•1, that the subgroup
‚ü®zn‚ü©is the unique subgroup of Z(p‚àû) of order pn, for the polynomial x pn ‚àí1 ‚ààC[x] has
at most pn complex roots.
Proposition 9.25.
Let p be a prime.
(i) Z(p‚àû) is isomorphic to the p-primary component of Q/Z.
(ii) Z(p‚àû) is a divisible p-primary abelian group.
(iii) The subgroups of Z(p‚àû) are
{1} ‚ää‚ü®z1‚ü©‚ää‚ü®z2‚ü©‚ää¬∑ ¬∑ ¬∑ ‚ää‚ü®zn‚ü©‚ää‚ü®zn+1‚ü©‚ää¬∑ ¬∑ ¬∑ ‚ääZ(p‚àû),
and so they are well-ordered by inclusion.3
(iv) Z(p‚àû) has the DCC on subgroups but not the ACC.4
Proof.
(i) DeÔ¨Åne œï : 
p Z(p‚àû) ‚ÜíQ/Z by œï : (e2œÄicp/pn p ) ‚Üí
p cp/pn p +Z, where
cp ‚ààZ. It is easy to see that œï is an injective homomorphism. The proof that œï is
surjective is really contained in the proof of Theorem 5.13, but here it is again. Let a/b ‚àà
Q/Z, and write b = 
p pn p. Since the numbers b/pn p are pairwise relatively prime,
there are integers m p with 1 = 
p m p(b/pn p). Therefore, a/b = 
p am p/pn p =
œï((am p/pn p)).
(ii) Since a direct summand is always a homomorphic image, Z(p‚àû) is a homomorphic
image of the divisible group Q/Z; but every quotient of a divisible group is itself divisible.
3The group Z(p‚àû) is called quasicyclic because every proper subgroup of it is cyclic.
4Theorem 8.46, the Hopkins-Levitzki theorem, says that a ring with DCC must also have ACC. This result
shows that the analogous result for groups is false.

660
Advanced Linear Algebra
Ch. 9
(iii) Let S be a proper subgroup of Z(p‚àû). Since {zn : n ‚â•1} generates Z(p‚àû), we
may assume that zm /‚ààS for some m. It follows that z‚Ñì/‚ààS for all ‚Ñì> m; otherwise
zm = z p‚Ñì‚àím
‚Ñì
‚ààS. If S Ã∏= {0}, we claim that S contains some zn; indeed, we show that S
contains z1. Now S must contain some element x of order p, and x = zc
1, where 1 ‚â§c < p
[for ‚ü®z1‚ü©contains all the elements in Z(p‚àû) of order p]. Since p is prime, (c, p) = 1, and
there are integers u, v with 1 = cu + pv; hence, z1 = zcu+pv
1
= zcu
1 = xu ‚ààS. Let d be
the largest integer with zd ‚ààS. Clearly, ‚ü®zd‚ü©‚äÜS. For the reverse inclusion, let s ‚ààS. If
s has order pn > pd, then ‚ü®s‚ü©contains zn, because ‚ü®zn‚ü©contains all the elements of order
pn in Z(p‚àû). But this contradicts our observation that z‚Ñì/‚ààS for all ‚Ñì> d. Hence, s has
order ‚â§pd, and so s ‚àà‚ü®zd‚ü©; therefore, S = ‚ü®zd‚ü©.
As the only proper nonzero subgroups of Z(p‚àû) are the groups ‚ü®zn‚ü©, it follows that the
subgroups are well-ordered by inclusion.
(iv) First, Z(p‚àû) does not have the ACC, as the chain of subgroups
{1} ‚ää‚ü®z1‚ü©‚ää‚ü®z2‚ü©‚ää¬∑ ¬∑ ¬∑
illustrates. It is proved in Proposition A.3 of the Appendix that every strictly decreasing
sequence in a well-ordered set is Ô¨Ånite; it follows that Z(p‚àû) has the DCC on subgroups.
‚Ä¢
Notation.
If G is an abelian group and n is a positive integer, then
G[n] = {g ‚ààG : ng = 0}.
It is easy to see that G[n] is a subgroup of G. Note that if p is prime, then G[p] is a
vector space over Fp.
Lemma 9.26.
If G and H are divisible p-primary abelian groups, then G ‚àº= H if and
only if G[p] ‚àº= H[p].
Proof.
If there is an isomorphism f : G ‚ÜíH, then it is easy to see that its restriction
f |G[p] is an isomorphism G[p] ‚ÜíH[p] (whose inverse is f ‚àí1|H[p]).
For sufÔ¨Åciency, assume that f : G[p] ‚ÜíH[p] is an isomorphism. Composing with
the inclusion H[p] ‚ÜíH, we may assume that f : G[p] ‚ÜíH. Since H is injective, f
extends to a homomorphism F : G ‚ÜíH; we claim that any such F is an isomorphism.
(i) F is an injection.
If g ‚ààG has order p, then F(g) = f (g) Ã∏= 0, by hypothesis. Suppose that g has
order pn for n ‚â•2. If F(g) = 0, then F(pn‚àí1g) = 0, and this contradicts the hypothesis,
because pn‚àí1g has order p. Therefore, F is an injection.
(ii) F is a surjection.
We show, by induction on n ‚â•1, that if h ‚ààH has order pn, then h ‚ààim F. If n = 1,
then h ‚ààH[p] = im f ‚äÜim F. For the inductive step, assume that h ‚ààH has order pn+1.
Now pnh ‚ààH[p], so there exists g ‚ààG with F(g) = f (g) = pnh. Since G is divisible,
there is g‚Ä≤ ‚ààG with png‚Ä≤ = g; thus, pn(h ‚àíF(g‚Ä≤)) = 0. By induction, there is x ‚ààG
with F(x) = h ‚àíF(g‚Ä≤). Therefore, F(x + g‚Ä≤) = h, as desired.
‚Ä¢

Sec. 9.1
Modules over PIDs
661
The next theorem classiÔ¨Åes all divisible abelian groups.
DeÔ¨Ånition.
If D is a divisible abelian group, deÔ¨Åne
Œ¥‚àû(D) = dimQ(D/t D)
and, for all primes p,
Œ¥p(D) = dimFp(D[p]).
Theorem 9.27.
(i) An abelian group D is an injective Z-module if and only it is a divisible group.
(ii) Every divisible abelian group is isomorphic to a direct sum of copies of Q and of
copies of Z(p‚àû) for various primes p.
(iii) Two divisible groups D and D‚Ä≤ are isomorphic if and only if Œ¥‚àû(D) = Œ¥‚àû(D‚Ä≤) and
Œ¥p(D) = Œ¥p(D‚Ä≤) for all primes p.
Proof.
(i) This is proved in Corollary 7.73.
(ii) If x ‚ààD has Ô¨Ånite order, if n is a positive integer, and if x = ny, then y has Ô¨Ånite order.
It follows that if D is divisible, then its torsion subgroup t D is also divisible, and hence
D = t D ‚äïV,
where V is torsion-free (by Proposition 7.64 on page 481). Since every quotient of a
divisible group is divisible, V is torsion-free and divisible, and hence it is a vector space
over Q, by Proposition 9.23.
Now t D is the direct sum of its primary components: t D = 
p Tp, each of which is
p-primary and divisible, and so it sufÔ¨Åces to prove that each Tp is a direct sum of copies
of Z(p‚àû). If dim(Tp[p]) = r (r may be inÔ¨Ånite), deÔ¨Åne W to be a direct sum of r copies
of Z(p‚àû), so that dim(W[p]) = r. Lemma 9.26 now shows that Tp ‚àº= W.
(iii) By Proposition 9.2(ii), if D ‚àº= D‚Ä≤, then D/t D ‚àº= D‚Ä≤/t D‚Ä≤ and t D ‚àº= t D‚Ä≤; hence, the
p-primary components (t D)p ‚àº= (t D‚Ä≤)p for all p. But D/t D and D‚Ä≤/t D‚Ä≤ are isomorphic
vector spaces over Q, and hence have the same dimension; moreover, the vector spaces
(t D)p[p] and (t D‚Ä≤)p[p] are also isomorphic, so they, too, have the same dimension.
For the converse, write D = V ‚äï
p Tp and D‚Ä≤ = V ‚Ä≤ ‚äï
p T ‚Ä≤
p, where V and V ‚Ä≤ are
torsion-free divisible, and Tp and T ‚Ä≤
p are p-primary divisible. By Lemma 9.26, Œ¥p(D) =
Œ¥p(D‚Ä≤) implies Tp ‚àº= T ‚Ä≤
p, while Œ¥‚àû(D) = Œ¥‚àû(D‚Ä≤) implies that the vector spaces V and
V ‚Ä≤ are isomorphic. By Proposition 7.30, these isomorphisms can be assembled to give an
isomorphism between D and D‚Ä≤.
‚Ä¢
We can now describe some familiar groups, but the reader may have to review a bit of
Ô¨Åeld theory.

662
Advanced Linear Algebra
Ch. 9
Corollary 9.28.
Let k be an algebraically closed Ô¨Åeld, let k√ó be its multiplicative group,
and let T be the torsion subgroup of k√ó.
(i) If k has characteristic 0, then T ‚àº= Q/Z, and k√ó ‚àº= (Q/Z) ‚äïV , where V is a vector
space over Q.
(ii) If k has prime characteristic p, then T ‚àº= 
qÃ∏=p Z(q‚àû). If k is the algebraic closure
of Fp, then5
k√ó ‚àº=

qÃ∏=p
Z(q‚àû).
Proof.
Since k is algebraically closed, the polynomials xn ‚àía have roots in k whenever
a ‚ààk; this says that every a has an nth root in k, which is the multiplicative way of saying
that k√ó is a divisible group. An element a ‚ààk has Ô¨Ånite order if and only if an = 1 for
some positive integer n; that is, a is an nth root of unity. It is easy to see that T is, itself,
divisible. Hence, k√ó = T ‚äïV , by Lemma 9.24, where V is a vector space over Q (for V
is torsion-free divisible).
(i) If k = Q is the algebraic closure of Q, there is no loss in generality in assuming that
k ‚äÜC. Now the torsion subgroup T of k consists of all the roots of unity e2œÄir, where
r ‚ààQ. It follows easily that the map r ‚Üíe2œÄir is a surjection Q ‚ÜíT having kernel Z,
so that T ‚àº= Q/Z.
If k is any algebraically closed Ô¨Åeld of characteristic 0, then Q ‚äÜk implies Q ‚äÜk.
There cannot be any roots of unity in k not in Q, because Q already contains n roots of
xn ‚àí1.
(ii) Let k = Fp. Every element a ‚ààk is algebraic over Fp, and so Fp(a)/Fp is a Ô¨Ånite
Ô¨Åeld extension; say, [Fp(a) : Fp] = m for some m. Hence, |Fp(a)| = pm and Fp(a) is a
Ô¨Ånite Ô¨Åeld. Now every nonzero element in a Ô¨Ånite Ô¨Åeld is a root of unity (for it is a root of
x pm ‚àíx for some m). But k√ó = T ‚äïV , where V is a vector space over Q. It follows that
V = {0}, for every nonzero element of k is a root of unity.
We now examine the primary components of k√ó. If q Ã∏= p is a prime, then the poly-
nomial f (x) = xq ‚àí1 has no repeated roots (for gcd( f (x), f ‚Ä≤(x)) = 1), and so there is
some qth root of unity other than 1. Thus, the q-primary component of k√ó is nontrivial,
and so there is at least one summand isomorphic to Z(q‚àû). Were there more than one such
summand, there would be more than q elements of order q, and this would provide too
many roots for xq ‚àí1 in the Ô¨Åeld k. Finally, there is no summand isomorphic to Z(p‚àû),
for the polynomial x p ‚àí1 = (x ‚àí1)p in k[x], and so it has no roots other than 1.
‚Ä¢
Corollary 9.29.
The following abelian groups are isomorphic:
C√ó;
(Q/Z) ‚äïR;
R/Z;

p
Z(p‚àû);
S1.
5The additive group of k is easy to describe, for k is a vector space over Fp, and so it is a direct sum of
(inÔ¨Ånitely many) copies of Fp.

Sec. 9.1
Modules over PIDs
663
Here S1 is the circle group; that is, the multiplicative group of all complex numbers z with
|z| = 1.
Proof.
The reader may use Theorem 9.27, because, for every group G on the list, we
have Œ¥p(G) = 1 for all primes p and Œ¥‚àû(G) = c (the cardinal of the continuum). See
Exercise 9.29 on page 666 for G = 
p Z(p‚àû).
‚Ä¢
EXERCISES
9.1 Let G = 
p

ap
 
, where p varies over all the primes, and

ap
 ‚àº= Ip.
(i) Prove that tG = 
p‚ü®ap‚ü©.
Hint. Use Exercise 5.4 on page 267.
(ii) Prove that G/tG is a divisible group.
(iii) Prove that tG is not a direct summand of G.
Hint. Show that Hom(Q, G) = {0} but that Hom(Q, G/tG) Ã∏= {0}, and conclude that
G/tG cannot be isomorphic to a subgroup of G.
9.2 Let R be a PID, and let M be an R-module, not necessarily primary. DeÔ¨Åne a submodule
S ‚äÜM to be a pure submodule if S ‚à©r M = r S for all r ‚ààR.
(i) Prove that if M is a (p)-primary module, where (p) is a nonzero prime ideal in R, then
a submodule S ‚äÜM is pure as just deÔ¨Åned if and only if S ‚à©pn M = pnS for all n ‚â•0.
(ii) Prove that every direct summand of M is a pure submodule.
(iii) Prove that the torsion submodule t M is a pure submodule of M.
(iv) Prove that if M/S is torsion-free, then S is a pure submodule of M.
(v) Prove that if S is a family of pure submodules of a module M that is a chain under
inclusion (that is, if S, S‚Ä≤ ‚ààS, then either S ‚äÜS‚Ä≤ or S‚Ä≤ ‚äÜS), then !
S‚ààS S is a pure
submodule of M.
(vi) Give an example of a pure submodule that is not a direct summand.
9.3
(i) If F is a Ô¨Ånitely generated free R-module, where R is a PID, prove that every pure
submodule of F is a direct summand.
(ii) If R is a PID and M is a Ô¨Ånitely generated R-module, prove that a submodule S ‚äÜM is
a pure submodule of M if and only if S is a direct summand of M.
9.4 Prove that if R is a domain that is not a Ô¨Åeld, then an R-module M that is both projective and
injective must be {0}.
Hint. Use Exercise 7.43 on page 487.
9.5 If M is a torsion module over a domain R, prove that
HomR(M, M) ‚àº=

P
HomR(MP, MP),
where MP is the P-primary component of M.
9.6
(i) If G is a torsion group with p-primary components {G p : p ‚ààP}, where P is the set of
all primes, prove that G = t

p‚ààP G p

.
(ii) Prove that

p‚ààP G p

/

p‚ààP G p

is torsion-free and divisible.
Hint. Use Exercise 5.4 on page 267.

664
Advanced Linear Algebra
Ch. 9
9.7 If M is an R-module, where R is a domain, and if r ‚ààR, let ¬µr : M ‚ÜíM be multiplication
by r; that is, ¬µr : m ‚Üírm [see Example 7.2(iii)].
(i) If Q = Frac(R), prove that an R-module is a vector space over Q if and only if M is
torsion-free and divisible.
(ii) Prove that ¬µr is an injection for every r Ã∏= 0 if and only if M is torsion-free.
(iii) Prove that ¬µr is a surjection for every r Ã∏= 0 if and only if M is divisible.
(iv) Prove that M is a vector space over Q if and only if, for every r Ã∏= 0, the map ¬µr : M ‚Üí
M is an isomorphism.
9.8
(i) Let R be a domain, let r ‚ààR, and let M be an R-module. If ¬µr : M ‚ÜíM is multipli-
cation by r, prove, for every R-module A, that the induced maps
(¬µr)‚àó: HomR(A, M) ‚ÜíHomR(A, M)
and
(¬µr)‚àó: HomR(M, A) ‚ÜíHomR(M, A)
are also multiplication by r.
(ii) Let R be a domain with Q = Frac(R). Using Exercise 9.7 on page 664, prove, for every
R-module M, that both HomR(Q, M) and HomR(M, Q) are vector spaces over Q.
9.9
(i) If M and N are Ô¨Ånitely generated torsion R-modules, prove, for all primes P and all
n ‚â•0, that
UP(n, M ‚äïN) = UP(n, M) + UP(n, N),
(ii) If A, B, and C are Ô¨Ånitely generated R-modules, where R is a PID, prove that A ‚äïB ‚àº=
A ‚äïC implies B ‚àº= C.
(iii) If A and B are Ô¨Ånitely generated R-modules, where R is a PID, prove that A‚äïA ‚àº= B‚äïB
implies A ‚àº= B.
9.10 If A is an abelian group, call a subset X of A linearly independent if, whenever 
i mi xi = 0,
where mi ‚ààZ and almost all mi = 0, then mi = 0 for all i. DeÔ¨Åne rank(A) to be the number
of elements in a maximal linearly independent subset of A.
(i) If X is linearly independent, prove that ‚ü®X‚ü©= 
x‚ààX‚ü®x‚ü©, a direct sum of cyclic groups.
(ii) If A is torsion, prove that rank(A) = 0.
(iii) If A is free abelian, prove that the two notions of rank coincide [the earlier notion deÔ¨Åned
rank(A) as the number of elements in a basis of A].
(iv) Prove that rank(A) = dim(Q ‚äóZ A), and conclude that every two maximal linearly
independent subsets of A have the same number of elements; that is, rank(A) is well-
deÔ¨Åned.
(v) If 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 is an exact sequence of abelian groups, prove that rank(B) =
rank(A) + rank(C).
9.11 (Kulikov) If G is an abelian p-group, call a subset X ‚äÜG pure-independent if X is linearly
independent (see Exercise 9.10) and ‚ü®X‚ü©is a pure subgroup.
(i) Prove that G has a maximal pure-independent subset.
(ii) If X is a maximal pure-independent subset of G, the subgroup B = ‚ü®X‚ü©is called a basic
subgroup of G. Prove that if B is a basic subgroup of G, then G/B is divisible.
9.12 Prove that if G and H are torsion abelian groups, then G‚äóZ H is a direct sum of cyclic groups.
Hint.
Use an exact sequence 0 ‚ÜíB ‚ÜíG ‚ÜíG/B ‚Üí0, where B is a basic subgroup,
along with the following theorem proved in Rotman, An Introduction to Homological Algebra,

Sec. 9.1
Modules over PIDs
665
pages 94-96): If 0 ‚ÜíA‚Ä≤
i
‚àí‚ÜíA ‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is an exact sequence of abelian groups and if
i(A‚Ä≤) is a pure subgroup of A, then, for every abelian group E, there is exactness of
0 ‚ÜíA‚Ä≤ ‚äóZ E ‚ÜíA ‚äóZ E ‚ÜíA‚Ä≤‚Ä≤ ‚äóZ E ‚Üí0.
9.13 Let M be a P-primary R-module, where R is a PID and P = (p) is a prime ideal. DeÔ¨Åne, for
all n ‚â•0,
VP(n, M) = dim

(pn M ‚à©M[p])/(pn+1M ‚à©M[p])

,
where M[p] = {m ‚ààM : pm = 0}. (This invariant is introduced because we cannot subtract
inÔ¨Ånite cardinal numbers.)
(i) Prove that VP(n, M) = UP(n, M) when M is Ô¨Ånitely generated
(ii) Let M = 
i‚ààI Ci be a direct sum of cyclic modules Ci, where I is any index set,
possibly inÔ¨Ånite. Prove that the number of summands Ci having order ideal (pn) is
VP(n, M), and hence it is an invariant of M.
(iii) Let M and M‚Ä≤ be torsion modules that are direct sums of cyclic modules. Prove that
M ‚àº= M‚Ä≤ if and only if VP(n, M) = VP(n, M‚Ä≤) for all n ‚â•0 and all prime ideals P.
9.14
(i) If p is a prime and G = t

k‚â•1 ‚ü®ak‚ü©
, where ‚ü®ak‚ü©is a cyclic group of order pk, prove
that G is an uncountable p-primary abelian group with Vp(n, G) = 1 for all n ‚â•0.
(ii) Use Exercise 9.13 to prove that the primary group G in part (i) is not a direct sum of
cyclic groups.
9.15 Generalize Proposition 8.95 as follows: If R is a domain, D is a divisible R-module, and T is
a torsion R-module with every element of Ô¨Ånite order, then D ‚äóR T = {0}.
9.16 Prove that there is an additive functor d : Ab ‚ÜíAb that assigns to each group G its maximal
divisible subgroup dG.
9.17
(i) Prove that Z(p‚àû) has no maximal subgroups.
(ii) Prove that Z(p‚àû) ‚àº= lim
‚àí‚ÜíIpn.
(iii) Prove that a presentation of Z(p‚àû) is
(an, n ‚â•1 | pa1 = 0, pan+1 = an for n ‚â•1).
9.18 Prove that an abelian group G is reduced if and only if HomZ(Q, G) = {0}.
9.19 If 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 is exact and both A and C are reduced, prove that B is reduced.
Hint. Use left exactness of HomZ(Q, ).
9.20 If {Di : i ‚ààI} is a family of divisible abelian groups, prove that 
i‚ààI Di is isomorphic to a
direct sum of divisible groups.
9.21 Prove that Q√ó ‚àº= I2 ‚äïF, where F is a free abelian group of inÔ¨Ånite rank.
9.22 Prove that R√ó ‚àº= I2 ‚äïR.
Hint. Use ex.
9.23
(i) Prove, for every group homomorphism f : Q ‚ÜíQ, that there exists r ‚ààQ with f (x) =
rx for all x ‚ààQ.
(ii) Prove that HomZ(Q, Q) ‚àº= Q.
(iii) Prove that End(Q) ‚àº= Q as rings.
9.24 For every abelian group A, prove that HomZ(A, Q) and HomZ(Q, A) are vector spaces
over Q.

666
Advanced Linear Algebra
Ch. 9
9.25 Prove that if G is a nonzero abelian group, then HomZ(G, Q/Z) Ã∏= {0}.
9.26 Prove that an abelian group G is injective if and only if every nonzero quotient group is inÔ¨Ånite.
9.27 Prove that if G is an inÔ¨Ånite abelian group all of whose proper subgroups are Ô¨Ånite, then
G ‚àº= Z(p‚àû) for some prime p.6
9.28
(i) Let D = n
i=1 Di, where each Di ‚àº= Z(p‚àû
i ) for some prime pi. Prove that every
subgroup of D has DCC.
(ii) Prove, conversely, that if an abelian group G has DCC, then G is isomorphic to a sub-
group of a direct sum of a Ô¨Ånite number of copies of Z(p‚àû
i ).
9.29 Let G = 
p‚ààP Z(p‚àû), where P is the set of all primes. Prove that Œ¥p(G) = 1 for all p ‚ààP,
and that Œ¥‚àû(G) = c, where c is the cardinal of the continuum.
Hint.
Use Exercise 9.6 on page 663 after noting that 
p‚ààP Z(p‚àû) has cardinality c while

p‚ààP Z(p‚àû) is countable.
9.30 Let R = k[x, y] be the polynomial ring in two variables over a Ô¨Åeld k, and let I = (x, y).
(i) Prove that x ‚äóy ‚àíy ‚äóx Ã∏= 0 in I ‚äóR I.
Hint. Show that this element has a nonzero image in (I/I 2) ‚äóR (I/I 2).
(ii) Prove that x ‚äóy ‚àíy ‚äóx is a torsion element in I ‚äóR I, and conclude that the tensor
product of torsion-free modules need not be torsion-free.
9.31 Let C be the category of all Ô¨Ånitely generated R-modules, where R is a PID.
(i) Compute the Grothendieck group K0(C).
(ii) Compute the Grothendieck group K ‚Ä≤(C).
9.2 RATIONAL CANONICAL FORMS
In Chapter 3, we saw that if T : V ‚ÜíV is a linear transformation and if X = x1, . . . , xn
is a basis of V , then T determines the matrix A = X[T ]X whose ith column consists of
the coordinate-set of T (xi) with respect to X. If Y is another basis of V , then the matrix
B = Y [T ]Y may be different from A. On the other hand, Corollary 3.101 on page 176 says
that two matrices A and B arise from the same linear transformation if and only if A and
B are similar; that is, there exists a nonsingular matrix P with B = P AP‚àí1.
Corollary 3.101. Let T : V ‚ÜíV be a linear transformation on a vector space V over a
Ô¨Åeld k. If X and Y are bases of V , then there is a nonsingular matrix P with entries in k
so that
Y [T ]Y = P

X[T ]X

P‚àí1.
Conversely, if B = P AP‚àí1, where B, A, and P are n √ó n matrices with entries in k and
P is nonsingular, then there is a linear transformation T : kn ‚Üíkn and bases X and Y of
kn such that B = Y [T ]Y and A = X[T ]X.
We now consider how to determine whether two given matrices are similar; that is,
whether they arise from the same linear transformation.
6There exist inÔ¨Ånite nonabelian groups all of whose proper subgroups are Ô¨Ånite. Indeed, Tarski monsters
exist: These are inÔ¨Ånite groups all of whose proper subgroups have prime order.

Sec. 9.2
Rational Canonical Forms
667
Example 9.30.
Recall Example 7.1(v) on page 424: If T : V ‚ÜíV is a linear transformation, where
V is a vector space over a Ô¨Åeld k, then V admits a scalar multiplication by polynomials
f (x) ‚ààk[x]:
f (x)v =
 m

i=0
ci xi
v =
m

i=0
ciT i(v),
where T 0 is the identity map 1V , and T i is the composite of T with itself i times if i ‚â•1.
We denote this k[x]-module by V T .
We now show that if V is n-dimensional, then the k[x]-module V T is a torsion module.
By Corollary 3.88, for each v ‚ààV , the list v, T (v), T 2(v), . . . , T n(v) must be linearly
dependent (for it contains n + 1 vectors). Therefore, there are ci ‚ààk, not all 0, with
n
i=0 ciT i(v) = 0; but this says that g(x) = n
i=0 ci xi lies in the order ideal ann(v).
‚óÄ
There is an important special case of the construction of the k[x]-module V T . If A is an
n √ó n matrix with entries in k, deÔ¨Åne T : kn ‚Üíkn by T (v) = Av (recall that the elements
of kn are n √ó 1 column vectors v, so that Av is matrix multiplication). We denote the
k[x]-module (kn)T by (kn)A; thus, the action is given by
f (x)v =
 m

i=0
ci xi
v =
m

i=0
ci Aiv.
We now interpret the results in the previous section about modules over general PIDs
for the k[x]-modules V T and (kn)A. If T : V ‚ÜíV is a linear transformation, then a
submodule W of V T is an invariant subspace; that is, W is a subspace of V with T (W) ‚äÜ
W, and so the restriction T |W is a linear transformation on W; that is, T |W : W ‚ÜíW.
DeÔ¨Ånition.
If A is an r √ó r matrix and B is an s √ó s matrix, then their direct sum A ‚äïB
is the (r + s) √ó (r + s) matrix
A ‚äïB =
A
0
0
B

.
Lemma 9.31.
If V T = W ‚äïW ‚Ä≤, where W and W ‚Ä≤ are submodules, then
B‚à™B‚Ä≤[T ]B‚à™B‚Ä≤ = B[T |W]B ‚äïB‚Ä≤[T |W ‚Ä≤]B‚Ä≤,
where B = w1, . . . , wr is a basis of W and B‚Ä≤ = w‚Ä≤
1, . . . , w‚Ä≤
s is a basis of W ‚Ä≤.
Proof.
Since W and W ‚Ä≤ are submodules, we have T (W) ‚äÜW and T (W ‚Ä≤) ‚äÜW ‚Ä≤; that is,
the restrictions T |W and T |W ‚Ä≤ are linear transformations on W and W ‚Ä≤, respectively. Since
V = W ‚äïW ‚Ä≤, the union B ‚à™B‚Ä≤ is a basis of V . Finally, B‚à™B‚Ä≤[T ]B‚à™B‚Ä≤ is a direct sum as in
the statement of the lemma: T (wi) ‚ààW, so that it is a linear combination of w1, . . . , wr,
and hence it requires no nonzero coordinates from the w‚Ä≤
j; similarly, T (w‚Ä≤
j) ‚ààW ‚Ä≤, and so
its coordinates from the wi are all 0.
‚Ä¢

668
Advanced Linear Algebra
Ch. 9
When we studied permutations, we saw that the cycle notation allowed us to recognize
important properties that are masked by the conventional functional notation. We now ask
whether there is an analogous way to denote matrices; more precisely, if V T is a cyclic
k[x]-module, can we Ô¨Ånd a basis B of V so that the corresponding matrix B[T ]B displays
important properties of T ?
Lemma 9.32.
A submodule W of V T is cyclic of Ô¨Ånite order if and only if there is a vector
v ‚ààW and an integer s ‚â•1 such that
v, T v, T 2v, . . . , T s‚àí1v
is a basis of W. Moreover, if
T sv +
s‚àí1

i=0
ciT iv = 0,
then the order ideal ann(v) = (g), where g(x) = xs + cs‚àí1xs‚àí1 + ¬∑ ¬∑ ¬∑ + c1x + c0; that is,
W ‚àº= k[x]/(g).
Proof.
Assume that W = ‚ü®v‚ü©= { f (x)v : f (x) ‚ààk[x]}. Since V , hence W, is Ô¨Ånite-
dimensional, there is an integer s ‚â•1 and a linearly independent list v, T v, T 2v, . . .,
T s‚àí1v that becomes linearly dependent when we adjoin T sv. Hence, there are ci ‚ààk with
T sv +
s‚àí1

i=0
ciT iv = 0.
If w ‚ààW, then w = f (x)v for some f (x) ‚ààk[x]. An easy induction on deg( f ) shows
that w lies in the subspace spanned by v, T v, T 2v, . . . , T s‚àí1v; it follows that this list is a
basis of W.
To prove the converse, assume that there is a vector v ‚ààW and an integer s ‚â•1
such that the list v, T v, T 2v, . . . , T s‚àí1v is a basis of W. Clearly, W ‚äÜ‚ü®v‚ü©, the cyclic
submodule generated by v. The reverse inclusion is obvious, for we are assuming that W
is a submodule; hence, f (x)v ‚ààW for every f (x) ‚ààk[x].
The polynomial g(x) lies in the order ideal ann(v). If h(x) ‚ààann(v), the division
algorithm gives q(x) and r(x) with h = gq +r, where r = 0 or deg(r) < deg(g) = s. But
r(x) ‚ààann(v), so that r(x) =  t
j=0 c j x j. Hence,  t
j=0 c jT jv = 0, where t ‚â§s ‚àí1, and
this contradicts the linear independence of the basis. Therefore, g(x) has smallest degree
of all polynomials in ann(v), so that ann(v) = (g). Therefore, W ‚àº= k[x]/ ann(v) =
k[x]/(g).
‚Ä¢
DeÔ¨Ånition.
If g(x) = x + c0, then its companion matrix C(g) is the 1 √ó 1 matrix [‚àíc0];
if s ‚â•2 and g(x) = xs + cs‚àí1xs‚àí1 + ¬∑ ¬∑ ¬∑ + c1x + c0, then its companion matrix C(g) is

Sec. 9.2
Rational Canonical Forms
669
the s √ó s matrix
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
0
0
0
¬∑ ¬∑ ¬∑
0
‚àíc0
1
0
0
¬∑ ¬∑ ¬∑
0
‚àíc1
0
1
0
¬∑ ¬∑ ¬∑
0
‚àíc2
0
0
1
¬∑ ¬∑ ¬∑
0
‚àíc3
...
...
...
...
...
...
0
0
0
¬∑ ¬∑ ¬∑
1
‚àícs‚àí1
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
.
Obviously, we can recapture the polynomial g(x) from the last column of the companion
matrix C(g).
Lemma 9.33.
Let T : V ‚ÜíV be a linear transformation on a vector space V over a Ô¨Åeld
k, and let V T be a cyclic k[x]-module with generator v. If the order ideal ann(v) = (g),
where g(x) = xs +cs‚àí1xs‚àí1 +¬∑ ¬∑ ¬∑+c1x +c0, then B = v, T v, T 2v, . . . , T s‚àí1v is a basis
of V and the matrix B[T ]B is the companion matrix C(g).
Proof.
Let A = B[T ]B. By deÔ¨Ånition, the Ô¨Årst column of A consists of the coordinates
of T (v), the second column the coordinates of T (T v) = T 2v, and, more generally, if
i < s ‚àí1, then T (T iv) = T i+1v; that is, T sends each basis vector into the next one.
However, on the last basis vector, T (T s‚àí1v) = T sv. But T sv = ‚àís‚àí1
i=0 ciT iv, where
g(x) = xs + s‚àí1
i=0 ci xi. Thus, B[T ]B is the companion matrix C(g).
‚Ä¢
Theorem 9.34.
(i) Let A be an n √ó n matrix with entries in a Ô¨Åeld k. If
(kn)A = W1 ‚äï¬∑ ¬∑ ¬∑ ‚äïWr,
where each Wi is cyclic, say, with order ideal ( fi), then A is similar to a direct sum
of companion matrices
C( f1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC( fr).
(ii) Every n √ó n matrix A over a Ô¨Åeld k is similar to a direct sum of companion matrices
C(g1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC(gt)
in which the gi(x) are monic polynomials and
g1(x) | g2(x) | ¬∑ ¬∑ ¬∑ | gt(x).
Proof.
DeÔ¨Åne V = kn and deÔ¨Åne T : V ‚ÜíV by T (y) = Ay, where y is a column vector.
(i) By Lemma 9.33, each Wi has a basis Bi = vi, T vi, T 2vi, . . . and, with respect to this
basis Bi, the restriction T |Wi has matrix C( fi), the companion matrix of fi(x). With
respect to the basis B1 ‚à™¬∑ ¬∑ ¬∑ ‚à™Br, the transformation T has the desired matrix, by Propo-
sition 9.31. Finally, A is similar to C( f1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC( fr), by Corollary 3.101.

670
Advanced Linear Algebra
Ch. 9
(ii) By Example 9.30, the Ô¨Ånitely generated k[x]-module V T is a torsion module, and so
the consequence of the basis theorem, Proposition 9.18, gives
(kn)A = W1 ‚äïW2 ‚äï¬∑ ¬∑ ¬∑ ‚äïWt,
where each Wi is cyclic, say, with generator vi having order ideal (gi), and g1(x) | g2(x) |
¬∑ ¬∑ ¬∑ | gt(x). The statement now follows from part (i).
‚Ä¢
DeÔ¨Ånition.
A rational7 canonical8 form is a matrix R that is a direct sum of companion
matrices,
R = C(g1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC(gt),
where the gi(x) are monic polynomials with g1(x) | g2(x) | ¬∑ ¬∑ ¬∑ | gt(x).
If a matrix A is similar to the rational canonical form
C(g1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC(gt),
where g1(x) | g2(x) | ¬∑ ¬∑ ¬∑ | gt(x), then we say that the invariant factors of A are
g1(x), g2(x), . . . , gt(x).
We have just proved that every n √ón matrix over a Ô¨Åeld is similar to a rational canonical
form, and so it has invariant factors. Can a matrix A have more than one list of invariant
factors?
Theorem 9.35.
Two n √ó n matrices A and B with entries in a Ô¨Åeld k are similar if and
only if they have the same invariant factors. Moreover, a matrix is similar to exactly one
rational canonical form.
Proof.
By Corollary 3.101, A and B are similar if and only if (kn)A ‚àº= (kn)B. By Theo-
rem 9.22, (kn)A ‚àº= (kn)B if and only if their invariant factors are the same.
There is only one rational canonical form for a given list of invariant factors g1(x),
g2(x), . . . , gt(x), namely, C(g1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC(gt). If a matrix were similar to two distinct
rational canonical forms, then it would have two different lists of invariant factors, contrary
to the Ô¨Årst statement of this theorem.
‚Ä¢
Here is a theorem analogous to Corollary 3.41, which states that if k is a subÔ¨Åeld of a
Ô¨Åeld K and if f (x), g(x) ‚ààk[x], then their gcd in k[x] is equal to their gcd in K[x].
7If E ‚äÜR is an extension of Q, then every element e ‚ààE that is not in Q is irrational. More generally, if E/k
is a Ô¨Åeld extension, then we call the elements of the ground Ô¨Åeld k rational. This is the usage of the adjective
rational in rational canonical form, for all the entries of a rational canonical form lie in the Ô¨Åeld k and not in
some extension of it. In contrast, the Jordan canonical form, to be discussed in the next section, involves the
eigenvalues of a matrix that may not lie in k.
8The adjective canonical originally meant something dictated by ecclesiastical law, as canonical hours being
those times devoted to prayers. The meaning broadened to mean things of excellence, leading to the mathematical
meaning of something given by a general rule or formula.

Sec. 9.2
Rational Canonical Forms
671
Corollary 9.36.
(i) Let k be a subÔ¨Åeld of a Ô¨Åeld K, and let A and B be n √ó n matrices with entries
in k. If A and B are similar over K, then they are similar over k (i.e., if there is
a nonsingular matrix P having entries in K with B = P AP‚àí1, then there is a
nonsingular matrix Q having entries in k with B = Q AQ‚àí1).
(ii) If k is the algebraic closure of a Ô¨Åeld k, then two n√ón matrices A and B with entries
in k are similar over k if and only if they are similar over k.
Proof.
(i) Suppose that g1(x), . . . , gt(x) are the invariant factors of A regarded as a ma-
trix over k, while G1(x), . . . , Gq(x) are the invariant factors of A regarded as a matrix over
K. By the theorem, the two lists of polynomials coincide, for both are invariant factors for
A as a matrix over K.
Now B has the same invariant factors as A, for they are similar over K; since these
invariant factors lie in k, however, A and B are similar over k.
(ii) Immediate from part (i).
‚Ä¢
For example, suppose that A and B are matrices with real entries that are similar over
the complexes; that is, if there is a nonsingular complex matrix P such that B = P AP‚àí1,
then there exists a nonsingular real matrix Q such that B = Q AQ‚àí1.
The Ô¨Årst step in analyzing a matrix A is to see whether it leaves any one-dimensional
subspaces of kn invariant; that is, are there any nonzero vectors x with Ax = Œ±x for some
scalar Œ±? We call Œ± an eigenvalue of A and we call x an eigenvector of A for Œ±. To say that
Ax = Œ±x for x nonzero is to say that x is a nontrivial solution of the homogeneous system
(A ‚àíŒ±I)x = 0; that is, A ‚àíŒ±I is a singular matrix. But a matrix with entries in a Ô¨Åeld is
singular if and only if its determinant is 0. Recall that the characteristic polynomial of A
is œàA(x) = det(x I ‚àíA) ‚ààk[x],9 and so the eigenvalues of A are the roots of œàA(x). If
k is the algebraic closure of k, then œàA(x) = n
i=1(x ‚àíŒ±i), and so the constant term of
œàA(x) is (‚àí1)n  Œ±i. On the other hand, the constant term of any polynomial f (x) is just
f (0); setting x = 0 in œàA(x) = det(x I ‚àíA) gives œàA(0) = (‚àí1)n det(A). It follows that
det(A) is the product of the eigenvalues.
Here are some elementary facts about eigenvalues.
Corollary 9.37.
Let A be an n √ó n matrix with entries in a Ô¨Åeld k.
(i) A is singular if and only if 0 is an eigenvalue of A.
(ii) If Œ± is an eigenvalue of A, then Œ±n is an eigenvalue of An.
(iii) If A is nonsingular and Œ± is an eigenvalue of A, then Œ± Ã∏= 0 and Œ±‚àí1 is an eigenvalue
of A‚àí1.
9We continue using familiar properties of determinants even though they will not be proved until Section 9.9.

672
Advanced Linear Algebra
Ch. 9
Proof.
(i) If A is singular, then the homogeneous system Ax = 0 has a nontrivial solution;
that is, there is a nonzero x with Ax = 0. But this just says that Ax = 0x, and so 0 is an
eigenvalue.
Conversely, if 0 is an eigenvalue, then 0 = det(0I ‚àíA) = ¬± det(A), so that det(A) = 0
and A is singular.
(ii) There is a nonzero vector v with Av = Œ±v. It follows by induction on n ‚â•1 that
Anv = Œ±nv.
(iii) If x is an eigenvector for A and Œ±, then
x = A‚àí1Ax = A‚àí1Œ±x = Œ±A‚àí1x.
Therefore, Œ± Ã∏= 0 (because eigenvectors are nonzero) and Œ±‚àí1x = A‚àí1x.
‚Ä¢
Let us return to canonical forms.
Lemma 9.38.
If g(x) ‚ààk[x], then det

x I ‚àíC(g)

= g(x).
Proof.
If deg(g) = s ‚â•2, then
x I ‚àíC(g) =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
x
0
0
¬∑ ¬∑ ¬∑
0
c0
‚àí1
x
0
¬∑ ¬∑ ¬∑
0
c1
0
‚àí1
x
¬∑ ¬∑ ¬∑
0
c2
...
...
...
...
...
...
0
0
0
¬∑ ¬∑ ¬∑
‚àí1
x + cs‚àí1
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
,
and Laplace expansion across the Ô¨Årst row gives
det(x I ‚àíC(g)) = x det(L) + (‚àí1)1+sc0 det(M),
where L is the matrix obtained by erasing the top row and the Ô¨Årst column, and M is
the matrix obtained by erasing the top row and the last column. Now M is a triangular
(s ‚àí1) √ó (s ‚àí1) matrix having ‚àí1's on the diagonal, while L = x I ‚àíC

(g(x) ‚àíc0)/x

.
By induction, det(L) = (g(x) ‚àíc0)/x, while det(M) = (‚àí1)s‚àí1. Therefore,
det(x I ‚àíC(g)) = x[(g(x) ‚àíc0)/x] + (‚àí1)(1+s)+(s‚àí1)c0 = g(x).
‚Ä¢
If R = C(g1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC(gt) is a rational canonical form, then
x I ‚àíR =

x I ‚àíC(g1)

‚äï¬∑ ¬∑ ¬∑ ‚äï

x I ‚àíC(gt)

,
and so the lemma and Proposition 9.163, which says that det(B1 ‚äï¬∑ ¬∑ ¬∑‚äïBt) = 
i det(Bi),
give
œàR(x) =
t
i=1
œàC(gi)(x) =
t
i=1
gi(x).
Thus, the characteristic polynomial is the product of the invariant factors; in light of Corol-
lary 9.20, the characteristic polynomial of an n √ó n matrix A over a Ô¨Åeld k is the analog
for (kn)A of the order of a Ô¨Ånite abelian group.

Sec. 9.2
Rational Canonical Forms
673
Example 9.39.
We now show that similar matrices have the same characteristic polynomial. If B =
P AP‚àí1, then since x I commutes with every matrix, we have P(x I) = (x I)P and, hence,
P(x I)P‚àí1 = (x I)P P‚àí1 = x I. Therefore,
œàB(x) = det(x I ‚àíB)
= det(Px I P‚àí1 ‚àíP AP‚àí1)
= det(P[x I ‚àíA]P‚àí1)
= det(P) det(x I ‚àíA) det(P‚àí1)
= det(x I ‚àíA)
= œàA(x).
It follows that if A is similar to C(g1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC(gt), then
œàA(x) =
t
i=1
gi(x).
Therefore, similar matrices have the same eigenvalues with multiplicities.
‚óÄ
Theorem 9.40 (Cayley-Hamilton).
If A is an n √ó n matrix with characteristic polyno-
mial œàA(x) = xn + bn‚àí1xn‚àí1 + ¬∑ ¬∑ ¬∑ + b1x + b0, then œàA(A) = 0; that is,
An + bn‚àí1An‚àí1 + ¬∑ ¬∑ ¬∑ + b1 A + b0I = 0.
Proof.
We may assume that A = C(g1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC(gt) is a rational canonical form,
by Example 9.39, where œàA(x) = g1(x) ¬∑ ¬∑ ¬∑ gt(x). If we regard kn as the k[x]-module
(kn)A, then Corollary 9.19 says that gt(A)y = 0 for all y ‚ààkn. Thus, gt(A) = 0. As
gt(x) | œàA(x), however, we have œàA(A) = 0.
‚Ä¢
The Cayley-Hamilton theorem is the analog of Corollary 2.44.
DeÔ¨Ånition.
The minimum polynomial m A(x) of an n √ó n matrix A is the monic polyno-
mial f (x) of least degree with the property that f (A) = 0.
Proposition 9.41.
The minimum polynomial m A(x) is a divisor of the characteristic
polynomial œàA(x), and every eigenvalue of A is a root of m A(x).
Proof.
The Cayley-Hamilton theorem shows that m A(x) | œàA(x), while Corollary 9.19
implies that ct(x) is the minimum polynomial of A, where ct(x) is the invariant factor of
A of highest degree. It follows from the fact that
œàA(x) = c1(x) ¬∑ ¬∑ ¬∑ ct(x),
where c1(x) | c2(x) | ¬∑ ¬∑ ¬∑ | ct(x), that m A(x) = ct(x) is a polynomial having every
eigenvalue of A as a root [of course, the multiplicity as a root of m A(x) may be less than
its multiplicity as a root of the characteristic polynomial œàA(x)].
‚Ä¢

674
Advanced Linear Algebra
Ch. 9
Corollary 9.42.
If all the eigenvalues of an n √ó n matrix A are distinct, then m A(x) =
œàA(A); that is, the minimum polynomial coincides with the characteristic polyomial.
Proof.
This is true because every root of œàA(x) is a root of m A(x).
‚Ä¢
Corollary 9.43.
(i) An n √ó n matrix A is similar to a companion matrix if and only if
m A(x) = œàA(x).
(ii) A Ô¨Ånite abelian group G is cyclic if and only if its exponent equals its order.
Proof.
(i) A companion matrix C(g) has only one invariant factor, namely, g(x); but
Corollary 9.19 identiÔ¨Åes the minimum polynomial as the last invariant factor.
If m A(x) = œàA(x), then A has only one invariant factor, namely, œàA(x), by Corol-
lary 9.20. Hence, A and C(œàA(x)) have the same invariant factors, and so they are similar.
(ii) A cyclic group of order n has only one invariant factor, namely, n; but Corollary 9.19
identiÔ¨Åes the exponent as the last invariant factor.
If the exponent of G is equal to its order |G|, then G has only one invariant factor,
namely, |G|. Hence, G and I|G| have the same invariant factors, and so they are isomorphic.
‚Ä¢
EXERCISES
9.32
(i) How many 10 √ó 10 matrices A over R are there, to similarity, with A2 = I?
(ii) How many 10 √ó 10 matrices A over Fp are there, to similarity, with A2 = I?
Hint. The answer depends on whether p is odd or p = 2.
9.33 Find the rational canonical forms of
A =
1
2
3
4

,
B =
Ô£Æ
Ô£∞
2
0
0
1
2
0
0
0
3
Ô£π
Ô£ª,
and
C =
Ô£Æ
Ô£∞
2
0
0
1
2
0
0
1
2
Ô£π
Ô£ª.
9.34 If A is similar to A‚Ä≤ and B is similar to B‚Ä≤, prove that A ‚äïB is similar to A‚Ä≤ ‚äïB‚Ä≤.
9.35 Let k be a Ô¨Åeld, and let f (x) and g(x) lie in k[x]. If g(x) | f (x) and if every root of f (x) is
a root of g(x), show that there exists a matrix A having minimum polynomial m A(x) = g(x)
and characteristic polynomial œàA(x) = f (x).
9.36
(i) Give an example of two nonisomorphic Ô¨Ånite abelian groups having the same order and
the same exponent.
(ii) Give an example of two nonsimilar matrices having the same characteristic polynomial
and the same minimum polynomial.

Sec. 9.3
Jordan Canonical Forms
675
9.3 JORDAN CANONICAL FORMS
If k is a Ô¨Ånite Ô¨Åeld, then GL(n, k) is a Ô¨Ånite group, and so every element in it has Ô¨Ånite
order. Consider the group-theoretic question: What is the order of A in GL(3, F7), where
A =
Ô£Æ
Ô£∞
0
0
1
1
0
4
0
1
3
Ô£π
Ô£ª?
Of course, we can compute the powers A2, A3, . . .; Lagrange's theorem guarantees there
is some n ‚â•1 with An = E, but this procedure for Ô¨Ånding the order of A is rather tedious.
We recognize A as the companion matrix of
g(x) = x3 ‚àí3x2 ‚àí4x ‚àí1 = x3 ‚àí3x2 + 3x ‚àí1 = (x ‚àí1)3
(remember that g(x) ‚ààF7[x]). Now A and P AP‚àí1 are conjugates in the group GL(n, k)
and, hence, they have the same order. But the powers of a companion matrix are compli-
cated (e.g., the square of a companion matrix is not a companion matrix). We now give a
second canonical form whose powers are easily calculated, and we shall use it to compute
the order of A later in this section.
DeÔ¨Ånition.
A 1 √ó 1 Jordan block is a matrix J(Œ±, 1) = [Œ±]. If s ‚â•2, then an s √ó s
Jordan block is a matrix J(Œ±, s) of the form
J(Œ±, s) =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
Œ±
0
0
¬∑ ¬∑ ¬∑
0
0
1
Œ±
0
¬∑ ¬∑ ¬∑
0
0
0
1
Œ±
¬∑ ¬∑ ¬∑
0
0
...
...
...
...
...
...
0
0
0
¬∑ ¬∑ ¬∑
Œ±
0
0
0
0
¬∑ ¬∑ ¬∑
1
Œ±
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
.
.
Here is a more compact description of a Jordan block. Let L denote the s √ó s matrix
having all entries 0 except for 1's on the subdiagonal just below the main diagonal. In this
notation, a Jordan block J(Œ±, s) has the form
J(Œ±, s) = Œ±I + L.
Let us regard L as a linear transformation on ks. If e1, . . . , es is the standard basis, then
Lei = ei+1 if i < s while Les = 0. It follows easily that the matrix L2 is all 0's except for
1's on the second subdiagonal below the main diagonal; L3 is all 0's except for 1's on the
third subdiagonal; Ls‚àí1 has 1 in the s, 1 position, with 0's everywhere else, and Ls = 0.

676
Advanced Linear Algebra
Ch. 9
Lemma 9.44.
If J = J(Œ±, s) = Œ±I + L is an s √ó s Jordan block, then for all m ‚â•1,
J m = Œ±m I +
s‚àí1

i=1
m
i
	
Œ±m‚àíi Li.
Proof.
Since L and Œ±I commute (actually, Œ±I commutes with every matrix), the collec-
tion of all linear combinations of the powers of Œ±I and the powers of L is a (commutative)
ring, and so the binomial theorem applies. Finally, note that all terms involving Li for
i ‚â•s are 0 because Ls = 0.
‚Ä¢
Example 9.45.
Different powers of L are "disjoint"; that is, if m Ã∏= n and the i j entry of Ln is nonzero,
then the i j entry of Lm is zero:
Œ±
0
1
Œ±
m
=

Œ±m
0
mŒ±m‚àí1
Œ±m

and
Ô£Æ
Ô£∞
Œ±
0
0
1
Œ±
0
0
1
Œ±
Ô£π
Ô£ª
m
=
Ô£Æ
Ô£∞
Œ±m
0
0
mŒ±m‚àí1
Œ±m
0
m
2

Œ±m‚àí2
mŒ±m‚àí1
Œ±m
Ô£π
Ô£ª.
‚óÄ
Lemma 9.46.
If g(x) = (x ‚àíŒ±)s, then the companion matrix C(g) is similar to the s √ó s
Jordan block J(Œ±, s).
Proof.
If T : ks ‚Üíks is deÔ¨Åned by z ‚ÜíC(g)z, then the proof of Lemma 9.33 gives a
basis of ks of the form v, T v, T 2v, . . . , T s‚àí1v. We claim that the list Y = y0, . . . , ys‚àí1 is
also a basis of ks, where
y0 = v, y1 = (T ‚àíŒ±I)v, . . . , ys‚àí1 = (T ‚àíŒ±I)s‚àí1v.
It is easy to see that the list Y spans V , because T iv ‚àà‚ü®y0, . . . , yi‚ü©for all 0 ‚â§i ‚â§s ‚àí1.
Since there are s elements in Y, Proposition 3.87 shows that Y is a basis.
We now compute J = Y [T ]Y . If j + 1 ‚â§s, then
T y j = T (T ‚àíŒ±I) jv
= (T ‚àíŒ±I) jT v
= (T ‚àíŒ±I) j[Œ±I + (T ‚àíŒ±I)]v
= Œ±(T ‚àíŒ±I) jv + (T ‚àíŒ±I) j+1v.
Hence, if j + 1 < s, then
T y j = Œ±y j + y j+1.
If j + 1 = s, then
(T ‚àíŒ±I) j+1v = (T ‚àíŒ±I)sv = 0,
by the Cayley-Hamilton theorem [for œàC(g)(x) = (x ‚àíŒ±)s]; hence, T ys‚àí1 = Œ±ys‚àí1.
The matrix J is thus a Jordan block J(Œ±, s). By Corollary 3.101, C(g) and J(Œ±, s) are
similar.
‚Ä¢

Sec. 9.3
Jordan Canonical Forms
677
It follows that Jordan blocks, as companion matrices, correspond to polynomials; in
particular, J(Œ±, s) corresponds to (x ‚àíŒ±)s.
Theorem 9.47.
Let A be an n √ó n matrix with entries in a Ô¨Åeld k. If k contains all the
eigenvalues of A (in particular, if k is algebraically closed), then A is similar to a direct
sum of Jordan blocks.
Proof.
Instead of using the invariant factors g1 | g2 | ¬∑ ¬∑ ¬∑ | gt, we are now going to use
the elementary divisors fi(x) occurring in the basis theorem itself; that is, each fi(x) is a
power of an irreducible polynomial in k[x]. By Theorem 9.34(i), a decomposition of (kn)A
into a direct sum of cyclic k[x]-modules Wi yields a direct sum of companion matrices
U = C( f1) ‚äï¬∑ ¬∑ ¬∑ ‚äïC( fr),
where ( fi) is the order ideal of Wi, and U is similar to A. Since œàA(x) = 
i fi(x),
however, our hypothesis says that each fi(x) splits over k; that is, fi(x) = (x ‚àíŒ±i)si for
some si ‚â•1, where Œ±i is an eigenvalue of A. By the lemma, C( fi) is similar to a Jordan
block and, by Exercise 9.34 on page 674, A is similar to a direct sum of Jordan blocks.
‚Ä¢
DeÔ¨Ånition.
A Jordan canonical form is a direct sum of Jordan blocks.
If a matrix A is similar to the Jordan canonical form
J(Œ±1, s1) ‚äï¬∑ ¬∑ ¬∑ ‚äïJ(Œ±r, sr),
then we say that A has elementary divisors (x ‚àíŒ±1)s1, . . . , (x ‚àíŒ±r)sr .
Theorem 9.47 says that every square matrix A having entries in a Ô¨Åeld containing all the
eigenvalues of A is similar to a Jordan canonical form. Can a matrix be similar to several
Jordan canonical forms? The answer is yes, but not really.
Example 9.48.
Let Ir be the r√ór identity matrix, and let Is be the s√ós identity matrix. Then interchanging
blocks in a direct sum yields a similar matrix:
B
0
0
A

=
 0
Ir
Is
0
 A
0
0
B
  0
Is
Ir
0

Since every permutation is a product of transpositions, it follows that permuting the blocks
of a matrix of the form A1 ‚äïA2 ‚äï¬∑ ¬∑ ¬∑ ‚äïAt yields a matrix similar to the orginal one.
‚óÄ
Theorem 9.49.
If A and B are n √ó n matrices over a Ô¨Åeld k containing all their eigen-
values, then A and B are similar if and only if they have the same elementary divisors.
Moreover, if a matrix A is similar to two Jordan canonical forms, say, H and H ‚Ä≤, then
H and H‚Ä≤ have the same Jordan blocks (i.e., H‚Ä≤ arises from H by permuting its Jordan
blocks).

678
Advanced Linear Algebra
Ch. 9
Proof.
By Corollary 3.101, A and B are similar if and only if (kn)A ‚àº= (kn)B. By Theo-
rem 9.22, (kn)A ‚àº= (kn)B if and only if their elementary divisors are the same.
In contrast to the invariant factors, which are given in a speciÔ¨Åc order (each dividing the
next), A determines only a set of elementary divisors, hence only a set of Jordan blocks. By
Example 9.48, the different Jordan canonical forms obtained from a given Jordan canonical
form by permuting its Jordan blocks are all similar.
‚Ä¢
Here are some applications of the Jordan canonical form.
Proposition 9.50.
If A is an n √ó n matrix with entries in a Ô¨Åeld k, then A is similar to its
transpose At.
Proof.
First, Corollary 9.36(ii) allows us to assume that k contains all the eigenvalues of
A. Now if B = P AP‚àí1, then Bt = (Pt)‚àí1 At Pt; that is, if B is similar to A, then Bt is
similar to At. Thus, it sufÔ¨Åces to prove that H is similar to Ht for a Jordan canonical form
H, and, by Exercise 9.34 on page 674, it is enough to show that a Jordan block J = J(Œ±, s)
is similar to J t.
We illustrate the idea for J(Œ±, 3). Let Q be the matrix having 1's on the "wrong"
diagonal and 0's everywhere else; notice that Q = Q‚àí1.
Ô£Æ
Ô£∞
0
0
1
0
1
0
1
0
0
Ô£π
Ô£ª
Ô£Æ
Ô£∞
Œ±
0
0
1
Œ±
0
0
1
Œ±
Ô£π
Ô£ª
Ô£Æ
Ô£∞
0
0
1
0
1
0
1
0
0
Ô£π
Ô£ª=
Ô£Æ
Ô£∞
Œ±
1
0
0
Œ±
1
0
0
Œ±
Ô£π
Ô£ª
We let the reader prove, in general, that Q = Q‚àí1 and QJ(Œ±, s)Q‚àí1 = J(Œ±, s)t. Per-
haps the most efÔ¨Åcient proof is to let v1, . . . , vs be a basis of a vector space W, to deÔ¨Åne
Q : W ‚ÜíW by Q : vi ‚Üívs‚àíi+1, and to deÔ¨Åne J : W ‚ÜíW by J : vi ‚ÜíŒ±vi + vi+1 for
i < s and J : vs ‚ÜíŒ±vs.
‚Ä¢
Example 9.51.
At the beginning of this section, we asked for the order of the matrix A in GL(3, F7), where
A =
Ô£Æ
Ô£∞
0
0
1
1
0
4
0
1
3
Ô£π
Ô£ª;
we saw that A is the companion matrix of (x ‚àí1)3. Since œàA(x) is a power of x ‚àí1, the
eigenvalues of A are all equal to 1 and hence lie in F7; by Lemma 9.46, A is similar to the
Jordan block
J =
Ô£Æ
Ô£∞
1
0
0
1
1
0
0
1
1
Ô£π
Ô£ª.
By Example 9.45,
J m =
Ô£Æ
Ô£∞
1
0
0
m
1
0
m
2

m
1
Ô£π
Ô£ª,

Sec. 9.3
Jordan Canonical Forms
679
and it follows that J 7 = I because, in F7, we have 7 = 0 and
 7
2

= 21 = 0. Hence, A
has order 7 in GL(3, F7).
‚óÄ
Exponentiating a matrix is used to Ô¨Ånd solutions of systems of linear differential equa-
tions; it is also very useful in setting up the relation between a Lie group and its corre-
sponding Lie algebra. An n √ó n complex matrix A consists of n2 entries, and so A may
be regarded as a point in C n2. This allows us to deÔ¨Åne convergence of a sequence of
n √ó n complex matrices: A1, A2, . . . , Ak, . . . converges to a matrix M if, for each i, j, the
sequence of i, j entries converges. As in calculus, convergence of a series means conver-
gence of the sequence of its partial sums.
DeÔ¨Ånition.
If A is an n √ó n complex matrix, then
eA =
‚àû

k=0
1
k! Ak = I + A + 1
2 A2 + 1
6 A3 + ¬∑ ¬∑ ¬∑ .
It can be proved that this series converges for every matrix A, and that the function
A ‚ÜíeA is continuous; that is, if limk‚Üí‚àûAk = M, then
lim
k‚Üí‚àûeAk = eM.
Here are some properties of this exponentiation of matrices; we shall see that the Jordan
canonical form allows us to compute eA.
Proposition 9.52.
Let A be an n √ó n complex matrix.
(i) If P is nonsingular, then PeA P‚àí1 = eP AP‚àí1.
(ii) If AB = B A, then eAeB = eA+B.
(iii) For every matrix A, the matrix eA is nonsingular; indeed,
(eA)‚àí1 = e‚àíA.
(iv) If L is an n √ó n matrix having 1's just below the main diagonal and 0's elsewhere,
then eL is a lower triangular matrix with 1's on the diagonal.
(v) If D is a diagonal matrix, say, D = diag(Œ±1, Œ±2, . . . , Œ±n), then
eD = diag(eŒ±1, eŒ±2, . . . , eŒ±n).
(vi) If Œ±1, . . . , Œ±n are the eigenvalues of A (with multiplicities), then eŒ±1, . . ., eŒ±n are the
eigenvalues of eA.
(vii) We can compute eA.
(viii) If tr(A) = 0, then det(eA) = 1.

680
Advanced Linear Algebra
Ch. 9
Proof.
(i) We use the continuity of matrix exponentiation.
PeA P‚àí1 = P

lim
n‚Üí‚àû
n

k=0
1
k! Ak
P‚àí1
= lim
n‚Üí‚àû
n

k=0
1
k!

P Ak P‚àí1
= lim
n‚Üí‚àû
n

k=0
1
k!

P AP‚àí1k
= eP AP‚àí1
(ii) The coefÔ¨Åcient of the kth term of the power series for eA+B is
1
k!(A + B)k,
while the coefÔ¨Åcient of the kth term of eAeB is

i+ j=k
1
i! Ai 1
j! B j =
k

i=0
1
i!(k ‚àíi)! Ai Bk‚àíi = 1
k!
k

i=0
k
i
	
Ai Bk‚àíi.
Since A and B commute, the binomial theorem shows that both kth coefÔ¨Åcients are equal.
See Exercise 9.44 on page 682 for an example where this is false if A and B do not com-
mute.
(iii) This follows immediately from part (ii), for ‚àíA and A commute and e0 = I.
(iv) The equation
eL = I + L + 1
2 L2 + ¬∑ ¬∑ ¬∑ +
1
(s‚àí1)! Ls‚àí1
holds because Ls = 0, and the result follows by Lemma 9.44. For example, when s = 5,
eL =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
1
0
0
0
0
1
1
0
0
0
1
2
1
1
0
0
1
6
1
2
1
1
0
1
24
1
6
1
2
1
1
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
.
(v) This is clear from the deÔ¨Ånition:
eD = I + D + 1
2 D2 + 1
6 D3 + ¬∑ ¬∑ ¬∑ ,

Sec. 9.3
Jordan Canonical Forms
681
for
Dk = diag(Œ±k
1, Œ±k
2, . . . , Œ±k
n).
(vi) Since C is algebraically closed, A is similar to its Jordan canonical form J: There is
a nonsingular matrix P with P AP‚àí1 = J. Now A and J have the same characteristic
polynomials, and hence the same eigenvalues with multiplicities. But J is a lower trian-
gular matrix with the eigenvalues Œ±1, . . . , Œ±n of A on the diagonal, and so the deÔ¨Ånition of
matrix exponentiation gives eJ lower triangular with eŒ±1, . . . , eŒ±n on the diagonal. Since
eA = eP‚àí1 J P = P‚àí1eJ P, it follows that the eigenvalues of eA are as claimed.
(vii) By Exercise 9.38, there is a nonsingular matrix P with P AP‚àí1 =  + L, where 
is a diagonal matrix, Ln = 0, and L = L. Hence,
PeA P‚àí1 = eP AP‚àí1 = e+L = eeL.
But e is computed in part (v) and eL is computed in part (iv). Hence, eA = P‚àí1eeL P
is computable.
(viii) By deÔ¨Ånition, the trace of a matrix is the sum of its eigenvalues, while the determinant
of a matrix is the product of the eigenvalues. Since the eigenvalues of eA are eŒ±1, . . ., eŒ±n,
we have
det(eA) =

i
eŒ±i = e

i Œ±i = etr(A).
Hence, tr(A) = 0 implies det(eA) = 1.
‚Ä¢
EXERCISES
9.37 Find all n √ó n matrices A over a Ô¨Åeld k for which A and A2 are similar.
9.38 (Jordan Decomposition)
Prove that every n √ó n matrix A over an algebraically closed Ô¨Åeld k can be written
A = D + N,
where D is diagonalizable (i.e., D is similar to a diagonal matrix), N is nilpotent (i.e., Nm =
0 for some m ‚â•1), and DN = N D.
9.39 Give an example of an n √ó n matrix that is not diagonalizable.
Hint. It is known that every symmetric real matrix is diagonalizable. Alternatively, a rotation
(not the identity) about the origin on R2 sends no line through the origin into itself.
9.40
(i) Prove that all the eigenvalues of a nilpotent matrix are 0.
(ii) Use the Jordan form to prove the converse: If all the eigenvalues of a matrix A are 0,
then A is nilpotent. (This result also follows from the Cayley-Hamilton theorem.)
9.41 How many similarity classes of 6 √ó 6 nilpotent real matrices are there?
9.42 If A is a nonsingular matrix and A is similar to B, prove that A‚àí1 is similar to B‚àí1.

682
Advanced Linear Algebra
Ch. 9
9.43
(i) Prove that every nilpotent matrix N is similar to a strictly lower triangular matrix (i.e.,
all entries on and above the diagonal are 0).
(ii) If N is a nilpotent matrix, prove that I + N is nonsingular.
9.44 Let
A =
1
0
0
0

and B =
0
1
0
0

.
Prove that eAeB Ã∏= eBeA, and conclude that eAeB Ã∏= eA+B.
9.45 How many conjugacy classes are there in GL(3, F7)?
9.46 We know that PSL(3, F4) is a simple group of order 20 160 = 1
28!. Now A8 contains an
element of order 15, namely, (1 2 3 4 5)(6 7 8). Prove that PSL(3, F4) has no element of
order 15, and conclude that PSL(3, F4) Ã∏‚àº= A8.
Hint. Use Corollary 9.36 to replace F4 by a larger Ô¨Åeld containing any needed eigenvalues of
a matrix. Compute the order [in the group PSL(3, F4)] of the possible Jordan canonical forms
A =
Ô£Æ
Ô£∞
a
0
0
1
a
0
0
1
a
Ô£π
Ô£ª, B =
Ô£Æ
Ô£∞
a
0
0
0
b
0
0
1
b
Ô£π
Ô£ª, and C =
Ô£Æ
Ô£∞
a
0
0
0
b
0
0
0
c
Ô£π
Ô£ª.
9.4 SMITH NORMAL FORMS
There is a defect in our account of canonical forms: How do we Ô¨Ånd the invariant factors of
a given matrix A? The coming discussion will give an algorithm for computing its invariant
factors. In particular, it will compute the minimum polynomial of A.
In Chapter 3, we showed that a linear transformation T : V ‚ÜíW between Ô¨Ånite-
dimensional vector spaces determines a matrix, once bases Y of V and Z of W are chosen,
and Proposition 3.98 shows that matrix multiplication arises as the matrix determined by
the composite of two linear transformations. We now generalize that calculation to R-maps
between free R-modules, where R is any commutative ring.
DeÔ¨Ånition.
Let R be a commutative ring, and let T : Rt ‚ÜíRn be an R-map, where Rt
and Rn are free R-modules of ranks t and n, respectively. If Y = y1, . . . , yt is a basis of
Rt and Z = z1, . . . , zn is a basis of Rn, then
Z[T ]Y = [ai j]
is the n √ó t matrix over R whose ith column, for all i, consists of the coordinates of T (yi);
that is,
T (yi) =
n

j=1
a jiz j.
We now compare matrices for an R-homomorphism T arising from different choices
of bases in Rt and in Rn. The next proposition generalizes Corollary 3.101 from vector
spaces to modules over a commutative ring.

Sec. 9.4
Smith Normal Forms
683
Proposition 9.53.
Let R be a commutative ring, let Rt and Rn be free R-modules of
ranks t and n, respectively, and let T : Rt ‚ÜíRn be an R-homomorphism. Let Y and Y ‚Ä≤
be bases of Rt, and let Z and Z‚Ä≤ be bases of Rn. If ! = Z[T ]Y and !‚Ä≤ = Z‚Ä≤[T ]Y ‚Ä≤, then
there exist invertible matrices P and Q, where P is t √ó t and Q is n √ó n, with
!‚Ä≤ = Q!P‚àí1.
Conversely, if ! and !‚Ä≤ are n√ót matrices over R with !‚Ä≤ = Q!P‚àí1 for some invertible
matrices P and Q, then there is an R-homomorphism T : Rt ‚ÜíRn, bases Y and Y ‚Ä≤ of Rt,
and bases Z and Z‚Ä≤ of Rn, respectively, such that ! = Z[T ]Y and !‚Ä≤ = Z‚Ä≤[T ]Y ‚Ä≤.
Proof.
This is the same calculation we did in Proposition 3.101 on page 176 when we
applied the formula
Z[S]Y Y [T ]X = Z[ST ]X,
where T : V ‚ÜíV ‚Ä≤ and S : V ‚Ä≤ ‚ÜíV ‚Ä≤‚Ä≤ and X, Y, and Z are bases of V , V ‚Ä≤, and V ‚Ä≤‚Ä≤,
respectively. Note that the original proof never uses the inverse of any matrix entry, so that
the earlier hypothesis that the entries lie in a Ô¨Åeld is much too strong; they may lie in any
commutative ring.
‚Ä¢
DeÔ¨Ånition.
Two n √ó t matrices ! and !‚Ä≤ with entries in a commutative ring R are
R-equivalent if there are invertible matrices P and Q with entries in R with
!‚Ä≤ = Q!P
(writing P is just as general as writing P‚àí1).
Of course, equivalence as just deÔ¨Åned is an equivalence relation on the set of all (rect-
angular) n √ó t matrices over R.
Proposition 9.54.
If R is a commutative ring, then Ô¨Ånite presentations of (Ô¨Ånitely pre-
sented) R-modules M and M‚Ä≤ give exact sequences
Rt
Œª‚ÜíRn
œÄ‚ÜíM ‚Üí0
and
Rt‚Ä≤
Œª‚Ä≤
‚ÜíRn‚Ä≤ œÄ‚Ä≤
‚ÜíM‚Ä≤ ‚Üí0,
and choices of bases Y, Y ‚Ä≤ of Rt and Z, Z‚Ä≤ of Rn give matrices ! = Z[Œª]Y and !‚Ä≤ =
Z‚Ä≤[Œª‚Ä≤]Y ‚Ä≤. If t‚Ä≤ = t, n‚Ä≤ = n, and ! and !‚Ä≤ are R-equivalent, then M ‚àº= M‚Ä≤.
Proof.
Since ! and !‚Ä≤ are R-equivalent, there are invertible matrices P and Q with !‚Ä≤ =
Q!P‚àí1; now P determines an R-isomorphism Œ∏ : Rn ‚ÜíRn, and Q determines an R-
isomorphism œï : Rt ‚ÜíRt. The equation !‚Ä≤ = Q!P‚àí1 implies that the following diagram
commutes:
Rt
Œª

œï

Rn
œÄ

Œ∏

M

ŒΩ

0
Rt
Œª‚Ä≤
 Rn
œÄ‚Ä≤
 M‚Ä≤
 0

684
Advanced Linear Algebra
Ch. 9
DeÔ¨Åne an R-map ŒΩ : M ‚ÜíM‚Ä≤ as follows: if m ‚ààM, then surjectivity of œÄ gives an
element u ‚ààRn with œÄ(u) = m; set ŒΩ(m) = œÄ‚Ä≤Œ∏(u). Proposition 8.93 is a proof by
diagram chasing that ŒΩ is a well-deÔ¨Åned isomorphism.
‚Ä¢
Proposition 9.54 is virtually useless; for most commutative rings R, there is no way
to determine whether matrices ! and !‚Ä≤ with entries in R are R-equivalent. However,
when R is a euclidean ring, we will be able to use the criterion in the proposition to Ô¨Ånd a
computable normal form of a matrix.
If T : V ‚ÜíV is a linear transformation on a vector space V over a Ô¨Åeld k, the next
theorem gives a Ô¨Ånite presentation of the k[x]-module V T . The next deÔ¨Ånition creates a
free k[x]-module from any vector space V over a Ô¨Åeld k; the construction is based on the
formal deÔ¨Ånition, in Chapter 3, of k[x] as sequences in k almost all of whose coordinates
are zero.
DeÔ¨Ånition.
If V is a k-module over a commutative ring k, deÔ¨Åne
V [x] =

i‚â•0
Vi,
where Vi ‚àº= V for all i. In more detail, we denote the elements of Vi by xiv, where v ‚ààV
(so that xi merely marks the coordinate position; in particular, we let x0v = v, so that
V0 = V ). Thus, each element u ‚ààV [x] has a unique expression of the form
u =

i‚â•0
xivi,
where vi ‚ààV and almost all vi = 0. The k-module V [x] is a k[x]-module if we deÔ¨Åne
x

i
xivi

=

i
xi+1vi.
For readers comfortable with tensor product, the module V [x] just constructed is merely
k[x] ‚äók V . Indeed, the next lemma uses the fact that tensor product commutes with direct
sums, for a subset B is a basis of V if and only if V = 
b‚ààB kb is a direct sum.
Lemma 9.55.
If V is a free k-module over a commutative ring k, then V [x] is a free
k[x]-module. In fact, a basis E of V is also a basis of V [x] as a free k[x]-module.
Proof.
Each element u ‚ààV [x] has an expression of the form u = 
i‚â•0 xivi. Since
xie1, . . . , xien is a basis for Vi = xi V , each vi = 
j Œ± jie j for Œ± ji ‚ààk. Collecting terms,
u = f1(x)e1 + ¬∑ ¬∑ ¬∑ + fn(x)en,
where f j(x) = Œ± j0 + Œ± j1x + ¬∑ ¬∑ ¬∑ + Œ± jtxt for some t.

Sec. 9.4
Smith Normal Forms
685
To prove uniqueness of this expression, suppose that
g1(x)e1 + ¬∑ ¬∑ ¬∑ + gn(x)en = 0,
where g j(x) = Œ≤ j0 + Œ≤ j1x + ¬∑ ¬∑ ¬∑ + Œ≤ jtxt for some t. For each i, this gives the equation

j Œ≤ ji xie j = 0 in Vi. Since xie1, . . . , xien is a basis of Vi, it is linearly independent, and
so all Œ≤ ji = 0.
‚Ä¢
We can now give a Ô¨Ånite presentation of V T . Viewing V [x] as sequences (rather than
as k[x] ‚äók V ) is convenient in this proof.
Theorem 9.56 (Characteristic Sequence).
(i) If V is a Ô¨Ånitely generated k-module over a commutative ring k and T : V ‚ÜíV is a
k-homomorphism, then there is an exact sequence of k[x]-modules
0 ‚ÜíV [x]
Œª‚ÜíV [x]
œÄ‚ÜíV T ‚Üí0,
where, for all i ‚â•0 and all v ‚ààV , Œª(xiv) = xi+1v ‚àíxiT v and œÄ(xiv) = T iv.
(ii) If A is an n √ón matrix over k and E is the standard basis E = e1, . . . , en of kn, then
the matrix E[Œª]E arising from the presentation of (kn)A in part (i) is x I ‚àíA.
Proof.
(i) It is easily checked that both Œª and œÄ are well-deÔ¨Åned k-maps; they are also
k[x]-maps; for example,
Œª(x(xiv)) = xŒª(xiv),
because both equal xi+2v ‚àíxi+1T v.
(1) œÄ is surjective. If v ‚ààV T , then œÄ(v) = T 0v = v.
(2) im Œª ‚äÜker œÄ.
œÄŒª(xiv) = œÄ(xi+1v ‚àíxiT v) = T i+1v ‚àíT i+1v = 0.
(3) ker œÄ ‚äÜim Œª. If u = m
i=0 xivi ‚ààker œÄ, then m
i=0 T ivi = 0. Hence,
u =
m

i=0
xivi ‚àí
m

i=0
T ivi
=
m

i=1
(xivi ‚àíT ivi),
because
x0v0 ‚àíT 0v0 = v0 ‚àív0 = 0.
For any i ‚â•1, we are going to rewrite the ith summand xivi ‚àíT ivi of u as a telescoping

686
Advanced Linear Algebra
Ch. 9
sum, each of whose terms lies in im Œª; this will sufÔ¨Åce to prove that ker œÄ ‚äÜim Œª.
i‚àí1

j=0
Œª(xi‚àí1‚àíjT jvi) =
i‚àí1

j=0

xi‚àíjT jvi ‚àíxi‚àí1‚àíjT j+1vi

= (xivi ‚àíxi‚àí1T vi) + (xi‚àí1T vi ‚àíxi‚àí2T 2vi)+
¬∑ ¬∑ ¬∑ + (xT i‚àí1vi ‚àíT ivi)
= xivi +
i‚àí1

j=1
(‚àíxi‚àíjT jvi + xi‚àíjT jvi)

‚àíT ivi
= xivi ‚àíT ivi.
(4) Œª is injective. As a k-module, V [x] is a direct sum of submodules Vi, and, for all
m ‚â•0, Vm ‚àº= V via fm : xmv ‚Üív; it follows that if xmv Ã∏= 0, then f ‚àí1
m+1 fm(xmv) =
xm+1v Ã∏= 0.
Suppose now that
u =
m

i=0
xivi ‚ààker Œª,
where xmvm Ã∏= 0; it follows that xm+1vm Ã∏= 0. But
0 = Œª(u) = Œª
 m

i=0
xivi

=
m

i=0
(xi+1vi ‚àíxiT vi).
Therefore,
xm+1vm = ‚àí
m‚àí1

i=0
(xi+1vi) +
m

i=0
xiT vi.
Thus, xm+1vm ‚ààVm+1 ‚à©m
i=0 Vi = {0}, so that xm+1vm = 0. But we have seen that
xmv Ã∏= 0 implies xm+1vm Ã∏= 0, so that this contradiction gives ker Œª = {0}.
(ii) In the notation of part (i), let V = kn and let T : kn ‚Üíkn be given by v ‚ÜíAv, where
v is an n √ó 1 column vector. If e1, . . . , en is the standard basis of kn, then e1, . . . , en is a
basis of the free k[x]-module V [x], and so it sufÔ¨Åces to Ô¨Ånd the matrix of Œª relative to this
basis. Now
Œª(ei) = xei ‚àíT ei = xei ‚àí

j
a jie j.
Since [Œ¥i j] = I, where Œ¥i j is the Kronecker delta, we have
xei ‚àí

j
a jie j =

j
xŒ¥ jie j ‚àí

j
a jie j
=

j
(xŒ¥ ji ‚àía ji)e j.
Therefore, the matrix of Œª is x I ‚àíA.
‚Ä¢

Sec. 9.4
Smith Normal Forms
687
Corollary 9.57.
Two n √ó n matrices A and B over a Ô¨Åeld k are similar if and only if the
matrices ! = x I ‚àíA and !‚Ä≤ = x I ‚àíB are k[x]-equivalent.
Proof.
If A is similar to B, there is a nonsingular matrix P with entries in k such that
B = P AP‚àí1. But
P(x I ‚àíA)P‚àí1 = x I ‚àíP AP‚àí1 = x I ‚àíB,
because the scalar matrix x I commutes with P (it commutes with every matrix). Thus,
x I ‚àíA and x I ‚àíB are k[x]-equivalent.
Conversely, suppose that the matrices x I ‚àíA and x I ‚àíB are k[x]-equivalent. By
Theorem 9.56(ii), (kn)A and (kn)B are Ô¨Ånitely presented k[x]-modules with presentations
that give the matrices x I ‚àíA and x I ‚àíB, respectively. Now Proposition 9.54 shows that
(kn)A ‚àº= (kn)B, and so A and B are similar, by Corollary 7.4.
‚Ä¢
Corollary 9.57 reduces the question of similarity of matrices over a Ô¨Åeld k to a problem
of equivalence of matrices over k[x]. Fortunately, Gaussian elimination, a method for
solving systems of linear equations whose coefÔ¨Åcients lie in a Ô¨Åeld, can be adapted here.
We now generalize the ingredients of Gaussian elimination from matrices over Ô¨Åelds to
matrices over arbitrary commutative rings.
In what follows, we denote the ith row of a matrix A by ROW(i) and the jth column by
COL( j).
DeÔ¨Ånition.
There are three elementary row operations on a matrix A with entries in a
commutative ring R:
Type I: Multiply ROW( j) by a unit u ‚ààR.
Type II: Replace ROW(i) by ROW(i) + c j ROW( j), where j Ã∏= i and c j ‚ààR.
Type III: Interchange ROW(i) and ROW( j).
There are analogous elementary column operations.
Notice that an operation of type III (i.e., an interchange) can be accomplished by oper-
ations of the other two types. We indicate this schematically.
a
b
c
d

‚Üí
a ‚àíc
b ‚àíd
c
d

‚Üí
a ‚àíc
b ‚àíd
a
b

‚Üí
‚àíc
‚àíd
a
b

‚Üí
c
d
a
b

DeÔ¨Ånition.
An elementary matrix is the matrix obtained from the identity matrix I by
applying an elementary row10 operation to it.
Thus, there are three types of elementary matrix. It is shown in elementary linear algebra
courses (and it is easy to prove) that performing an elementary operation is the same as
multiplying by an elementary matrix. In more detail, if L is an elementary matrix of type
I, II, or III, then applying an elementary row operation of this type to a matrix A gives
10Applying elementary column operations to I gives the same collection of elementary matrices.

688
Advanced Linear Algebra
Ch. 9
the matrix L A, whereas applying the corresponding elementary column operation to A
gives the matrix AL. It is also easy to see that every elementary matrix is invertible, and its
inverse is elementary of the same type. It follows that every product of elementary matrices
is invertible.
DeÔ¨Ånition.
If R is a commutative ring, then a matrix !‚Ä≤ is Gaussian equivalent to a
matrix ! if there is a sequence of elementary row and column operations
! = !0 ‚Üí!1 ‚Üí¬∑ ¬∑ ¬∑ ‚Üí!r = !‚Ä≤.
Gaussian equivalence is an equivalence relation on the family of all n √ó t matrices
over R.
It follows that if !‚Ä≤ is Gaussian equivalent to !, then there are matrices P and Q, each
a product of elementary matrices, with !‚Ä≤ = P!Q. Recall that two matrices !‚Ä≤ and ! are
R-equivalent if there are invertible matrices P and Q with !‚Ä≤ = P!Q. It follows that if !‚Ä≤
is Gaussian equivalent to !, then !‚Ä≤ and ! are R-equivalent. We shall see that the converse
is true when R is euclidean.
Theorem 9.58 (Smith11 Normal Form).
Every nonzero n √ó t matrix ! with entries in
a euclidean ring R is Gaussian equivalent to a matrix of the form

0
0
0

,
where  = diag(œÉ1, . . . , œÉq) and œÉ1 | œÉ2 | ¬∑ ¬∑ ¬∑ | œÉq are nonzero (the lower blocks of 0's or
the right blocks of 0's may not be present).
Proof.
The proof is by induction on the number n ‚â•1 of rows of !. If œÉ ‚ààR, let
‚àÇ(œÉ) denote its degree in the euclidean ring R. Among all the entries of matrices Gaussian
equivalent to !, let œÉ1 have the smallest degree, and let  be a matrix Gaussian equivalent
to ! that has œÉ1 as an entry, say, in position k, ‚Ñì.
We claim that œÉ1 | Œ∑kj for all Œ∑kj in ROW(k) of . Otherwise, there is j Ã∏= ‚Ñìand an
equation Œ∑kj = Œ∫œÉ1 + œÅ, where ‚àÇ(œÅ) < ‚àÇ(œÉ1). Adding (‚àíŒ∫)COL(‚Ñì) to COL( j) gives a
matrix ‚Ä≤ having œÅ as an entry. But ‚Ä≤ is Gaussian equivalent to ! and has an entry œÅ
whose degree is smaller than ‚àÇ(œÉ1), a contradiction. The same argument shows that œÉ1
divides any entry in its column. We claim that œÉ1 divides every entry of ‚Ä≤. Let a be an
entry not in œÉ1's row or column; schematically, we have
a
b
c
œÉ1
	
, where b = uœÉ1 and
c = vœÉ1. Replace ROW(1) by ROW(1)+(1 ‚àíu)ROW(2) = (a + (1 ‚àíu)c œÉ1). As above,
œÉ1 | a + (1 ‚àíu)c. Since œÉ1 | c, we have œÉ1 | a.
Let us return to , a matrix Gaussian equivalent to ! that contains œÉ1 as an entry. By
interchanges, there is a matrix ‚Ä≤ that is Gaussian equivalent to ! and that has œÉ1 in the 1,1
11This theorem and the corresponding uniqueness result, soon to be proved, were found by H. J. S. Smith in
1861.

Sec. 9.4
Smith Normal Forms
689
position. If Œ∑1 j is another entry in the Ô¨Årst row, then Œ∑1 j = Œ∫ jœÉ1, and adding (‚àíŒ∫ j)COL(1)
to COL( j) gives a new matrix whose 1, j entry is 0. Thus, the matrix  is Gaussian
equivalent to a matrix having œÉ1 in the 1,1 position and with 0's in the rest of the Ô¨Årst row.
This completes the base step n = 1 of the induction, for we have just shown that a nonzero
1√ót matrix is Gaussian equivalent to [œÉ1 0 . . . 0]. Furthermore, since œÉ1 divides all entries
in the Ô¨Årst column, ! is Gaussian equivalent to a matrix having all 0's in the rest of the Ô¨Årst
column as well; thus, ! is Gaussian equivalent to a matrix of the form
œÉ1
0
0
$

.
By induction, the matrix $ is Gaussian equivalent to a matrix
‚Ä≤
0
0
0

,
where ‚Ä≤ = diag(œÉ2, . . . , œÉq) and œÉ2 | œÉ3 | ¬∑ ¬∑ ¬∑ | œÉq. Hence, ! is Gaussian equivalent to
Ô£Æ
Ô£∞
œÉ1
0
0
0
‚Ä≤
0
0
0
0
Ô£π
Ô£ª. It remains to observe that œÉ1 | œÉ2; this follows from our initial remarks,
for the ultimate matrix is Gaussian equivalent to ! and contains œÉ1 as an entry.
‚Ä¢
DeÔ¨Ånition.
The matrix

0
0
0

in the statement of the theorem is called a Smith normal
form of !.
Thus, the theorem states that every nonzero (rectangular) matrix with entries in a eu-
clidean ring R is Gaussian equivalent to a Smith normal form.
Corollary 9.59.
Let R be a euclidean ring.
(i) Every invertible n√ón matrix ! with entries in R is a product of elementary matrices.
(ii) Two matrices ! and !‚Ä≤ over R are R-equivalent if and only if they are Gaussian
equivalent.
Proof.
(i) We now know that ! is Gaussian equivalent to a Smith normal form
  0
0 0

,
where  is diagonal. Since ! is a (square) invertible matrix, there can be no blocks of 0's,
and so ! is Gaussian equivalent to ; that is, there are matrices P and Q that are products
of elementary matrices such that
P!Q =  = diag(œÉ1, . . . , œÉn).
Hence, ! = P‚àí1Q‚àí1. Now the inverse of an elementary matrix is again elementary, so
that P‚àí1 and Q‚àí1 are products of elementary matrices. Since  is invertible, det() =
œÉ1 ¬∑ ¬∑ ¬∑ œÉn is a unit in R. It follows that each œÉi is a unit, and so  is a product of n

690
Advanced Linear Algebra
Ch. 9
elementary matrices [arising from the elementary operations of multiplying ROW(i) by the
unit œÉi].
(ii) It is always true that if !‚Ä≤ and ! are Gaussian equivalent, then they are R-equivalent,
for if !‚Ä≤ = P!Q, where P and Q are products of elementary matrices, then P and Q are
invertible. Conversely, if !‚Ä≤ is R-equivalent to !, then !‚Ä≤ = P!Q, where P and Q are
invertible, and part (i) shows that !‚Ä≤ and ! are Gaussian equivalent.
‚Ä¢
There are examples showing that this proposition may be false for PIDs that are not
euclidean.12 Investigating this phenomenon was important in the beginnings of Algebraic
K-Theory (see Milnor, Introduction to Algebraic K-Theory).
Theorem 9.60 (Simultaneous Bases).
Let R be a euclidean ring, let F be a Ô¨Ånitely gen-
erated free R-module, and let S be a submodule of F. Then there exists a basis z1, . . . , zn
of F and nonzero œÉ1, . . . , œÉq in R, where 0 ‚â§q ‚â§n, such that œÉ1 | ¬∑ ¬∑ ¬∑ | œÉq and
œÉ1z1, . . . , œÉqzq is a basis of S.
Proof.
If M = F/S, then Corollary 9.4 shows that S is free of rank ‚â§n, and so
0 ‚ÜíS
Œª‚ÜíF ‚ÜíM ‚Üí0
is a presentation of M, where Œª is the inclusion. Now any choice of bases of S and F
associates a matrix ! to Œª (note that ! may be rectangular). According to Proposition 9.53,
there are new bases of S and F relative to which ! is R-equivalent to a Smith normal form,
and these new bases are as described in the theorem.
‚Ä¢
Corollary 9.61.
Let ! be an n √ó n matrix with entries in a euclidean ring R.
(i) If ! is R-equivalent to a Smith normal form diag(œÉ1, . . . , œÉq) ‚äï0, then those
œÉ1, . . . , œÉq that are not units are the invariant factors of !.
(ii) If diag(Œ∑1, . . . , Œ∑s) ‚äï0 is another Smith normal form of !, then s = q and there are
units ui with Œ∑i = uiœÉi for all i; that is, the diagonal entries are associates.
Proof.
(i) We may regard ! as the matrix associated to an R-map Œª: Rn ‚ÜíRn relative
to some choice of bases. Let M = Rn/ im Œª. If diag(œÉ1, . . . , œÉq) ‚äï0 is a Smith normal
form of !, then there are bases y1, . . . , yn of Rn and z1, . . . , zn of Rn with Œª(y1) =
œÉ1z1, . . . , Œª(yq) = œÉqzq and Œª(y j) = 0 for all y j with j > q, if any. If œÉs is the Ô¨Årst œÉi
that is not a unit, then
M ‚àº= Rn‚àíq ‚äïR/(œÉs) ‚äï¬∑ ¬∑ ¬∑ ‚äïR/(œÉq),
a direct sum of cyclic modules for which œÉs | ¬∑ ¬∑ ¬∑ | œÉq. The fundamental theorem of Ô¨Ånitely
generated R-modules identiÔ¨Åes œÉs, . . . , œÉq as the invariant factors of M.
(ii) Part (i) proves the essential uniqueness of the Smith normal form, for the invariant
factors, being generators of order ideals, are only determined up to associates.
‚Ä¢
12There is a version for general PIDs obtained by augmenting the collection of elementary matrices by sec-
ondary matrices; see Exercise 9.50 on page 694.

Sec. 9.4
Smith Normal Forms
691
With a slight abuse of language, we may now speak of the Smith normal form of a
matrix.
Corollary 9.62.
Two n √ó n matrices A and B over a Ô¨Åeld k are similar if and only if
x I ‚àíA and x I ‚àíB have the same Smith normal form over k[x].
Proof.
By Theorem 9.57, A and B are similar if and only if x I ‚àíA is k[x]-equivalent to
x I ‚àíB, and Corollary 9.61 shows that x I ‚àíA and x I ‚àíB are k[x]-equivalent if and only
if they have the same Smith normal form.
‚Ä¢
Corollary 9.63.
Let F be a Ô¨Ånitely generated free abelian group, and let S be a subgroup
of F having Ô¨Ånite index; let y1, . . . , yn be a basis of F, let z1, . . . , zn be a basis of S, and
let A = [ai j] be the n √ó n matrix with zi = 
j a ji y j. Then
[F : S] = | det(A)|.
Proof.
Changing bases of S and of F replaces A by a matrix B that is Z-equivalent to it:
B = Q AP,
where Q and P are invertible matrices with entries in Z. Since the only units in Z are 1
and ‚àí1, we have | det(B)| = | det(A)|. In particular, if we choose B to be a Smith normal
form, then B = diag(g1, . . . , gn), and so | det(B)| = g1 ¬∑ ¬∑ ¬∑ gn. But g1, . . . , gn are the
invariant factors of F/S; by Corollary 5.30, their product is the order of F/S, which is the
index [F : S].
‚Ä¢
We have not yet kept our promise to give an algorithm computing the invariant factors
of a matrix with entries in a Ô¨Åeld.
Theorem 9.64.
Let  = diag(œÉ1, . . . , œÉq) be the diagonal block in the Smith normal
form of a matrix ! with entries in a euclidean ring R. If we deÔ¨Åne di(!) by d0(!) = 1
and, for i > 0,
di(!) = gcd( all i √ó i minors of !),
then, for all i ‚â•1,
œÉi = di(!)/di‚àí1(!).
Proof.
We are going to show that if ! and !‚Ä≤ are R-equivalent, then
di(!) ‚àºdi(!‚Ä≤)
for all i, where we write a ‚àºb to denote a and b being associates in R. This will sufÔ¨Åce
to prove the theorem, for if !‚Ä≤ is the Smith normal form of ! whose diagonal block is
diag(œÉ1, . . . , œÉq), then di(!‚Ä≤) = œÉ1œÉ2 ¬∑ ¬∑ ¬∑ œÉi. Hence,
œÉi(x) = di(!‚Ä≤)/di‚àí1(!‚Ä≤) ‚àºdi(!)/di‚àí1(!).

692
Advanced Linear Algebra
Ch. 9
By Proposition 9.59, it sufÔ¨Åces to prove that
di(!) ‚àºdi(L!)
and
di(!) ‚àºdi(!L)
for every elementary matrix L. Indeed, it sufÔ¨Åces to prove that di(!L) ‚àºdi(!), because
di(!L) = di([!L]t) = di(Lt!t) [the i √ói submatrices of !t are the transposes of the i √ói
submatrices of !; now use the facts that Lt is elementary and that, for every square matrix
M, we have det(Mt) = det(M)].
As a Ô¨Ånal simpliÔ¨Åcation, it sufÔ¨Åces to consider only elementary operations of types I
and II, for we have seen on page 687 that an operation of type III, interchanging two rows,
can be accomplished using the other two types.
L is of type I.
If we multiply ROW(‚Ñì) of ! by a unit u, then an i√ói submatrix either remains unchanged
or one of its rows is multiplied by u. In the Ô¨Årst case, the minor, namely, its determinant,
is unchanged; in the second case, the minor is changed by a unit. Therefore, every i √ó i
minor of L! is an associate of the corresponding i √ói minor of !, and so di(L!) ‚àºdi(!).
L is of type II.
If L replaces ROW(‚Ñì) by ROW(‚Ñì) +r ROW( j), then only ROW(‚Ñì) of ! is changed. Thus,
an i √ó i submatrix of ! either does not involve this row or it does. In the Ô¨Årst case, the
corresponding minor of L! is unchanged; in the second case, it has the form m + rm‚Ä≤,
where m and m‚Ä≤ are i √ó i minors of ! (for det is a multilinear function of the rows of a
matrix). It follows that di(!) | di(L!), for di(!) | m and di(!) | m‚Ä≤. Since L‚àí1 is also an
elementary matrix of type II, this argument shows that di(L‚àí1(L!)) | di(L!). Of course,
L‚àí1(L!) = !, so that di(!) and di(L!) divide each other. As R is a domain, we have
di(L!) ‚àºdi(!).
‚Ä¢
Theorem 9.65.
There is an algorithm to compute the elementary divisors of any square
matrix A with entries in a Ô¨Åeld k.
Proof.
By Corollary 9.62, it sufÔ¨Åces to Ô¨Ånd a Smith normal form for ! = x I ‚àíA over
the ring k[x]; by Corollary 9.61, the invariant factors of A are those diagonal entries which
are not units.
There are two algorithms: compute di(x I ‚àíA) for all i (of course, this is not a very
efÔ¨Åcient algorithm for large matrices); put x I ‚àíA into Smith normal form using Gaussian
elimination over k[x]. The reader should now have no difÔ¨Åculty in writing a program to
compute the elementary divisors.
‚Ä¢
Example 9.66.
Find the invariant factors, over Q, of
A =
Ô£Æ
Ô£∞
2
3
1
1
2
1
0
0
‚àí4
Ô£π
Ô£ª.

Sec. 9.4
Smith Normal Forms
693
We are going to use a combination of the two modes of attack: Gaussian elimination and
gcd's of minors. Now
x I ‚àíA =
Ô£Æ
Ô£∞
x ‚àí2
‚àí3
‚àí1
‚àí1
x ‚àí2
‚àí1
0
0
x + 4
Ô£π
Ô£ª.
It is plain that g1 = 1, for it is the gcd of all the entries of A, some of which are nonzero
constants. Interchange ROW(1) and ROW(2), and then change sign in the top row to obtain
Ô£Æ
Ô£∞
1
‚àíx + 2
1
x ‚àí2
‚àí3
‚àí1
0
0
x + 4
Ô£π
Ô£ª.
Add ‚àí(x ‚àí2)ROW(1) to ROW(2) to obtain
Ô£Æ
Ô£∞
1
‚àíx + 2
1
0
x2 ‚àí4x + 1
‚àíx + 1
0
0
x + 4
Ô£π
Ô£ª‚Üí
Ô£Æ
Ô£∞
1
0
0
0
x2 ‚àí4x + 1
‚àíx + 1
0
0
x + 4
Ô£π
Ô£ª.
The gcd of the entries in the 2 √ó 2 submatrix

x2 ‚àí4x + 1
‚àíx + 1
0
x + 4

is 1, for ‚àíx + 1 and x + 4 are distinct irreducibles, and so g2 = 1. We have shown that
there is only one invariant factor of A, namely, (x2 ‚àí4x + 1)(x + 4) = x3 ‚àí15x + 4, and
it must be the characteristic polynomial of A. It follows that the characteristic and minimal
polynomials of A coincide, and Corollary 9.43 shows that the rational canonical form of A
is
Ô£Æ
Ô£∞
0
0
‚àí4
1
0
15
0
1
0
Ô£π
Ô£ª.
‚óÄ
Example 9.67.
Find the abelian group G having generators a, b, c and relations
7a + 5b + 2c = 0
3a + 3b
= 0
13a + 11b + 2c = 0.
Using elementary operations over Z, we Ô¨Ånd the Smith normal form of the matrix of rela-
tions:
Ô£Æ
Ô£∞
7
5
2
3
3
0
13
11
2
Ô£π
Ô£ª‚Üí
Ô£Æ
Ô£∞
1
0
0
0
6
0
0
0
0
Ô£π
Ô£ª.
It follows that G ‚àº= (Z/1Z) ‚äï(Z/6Z) ‚äï(Z/0Z). Simplifying, G ‚àº= I6 ‚äïZ.
‚óÄ

694
Advanced Linear Algebra
Ch. 9
EXERCISES
9.47 Find the invariant factors, over Q, of the matrix
Ô£Æ
Ô£∞
‚àí4
6
3
‚àí3
5
4
4
‚àí5
3
Ô£π
Ô£ª.
9.48 Find the invariant factors, over Q, of the matrix
Ô£Æ
Ô£ØÔ£ØÔ£∞
‚àí6
2
‚àí5
‚àí19
2
0
1
5
‚àí2
1
0
‚àí5
3
‚àí1
2
9
Ô£π
Ô£∫Ô£∫Ô£ª.
9.49 If k is a Ô¨Åeld, prove that there is an additive exact functor kMod ‚Üík[x]Mod taking any vector
space V to V [x]. [See Theorem 9.56(ii).]
9.50 Let R be a PID, and let a, b ‚ààR.
(i) If d is the gcd of a and b, prove that there is a 2 √ó 2 matrix Q =
 x
y
x‚Ä≤
y‚Ä≤

with
det(Q) = 1 so that
Q
a
‚àó
b
‚àó

=
d
‚àó
d‚Ä≤
‚àó

,
where d | d‚Ä≤.
Hint. If d = xa + yb, deÔ¨Åne x‚Ä≤ = b/d and y‚Ä≤ = ‚àía/d.
(ii) Call an n √ó n matrix U secondary if it can be partitioned
U =
Q
0
0
I

,
where Q is a 2√ó2 matrix of determinant 1. Prove that every n √ón matrix A with entries
in a PID can be transformed into a Smith canonical form by a sequence of elementary
and secondary matrices.
9.5 BILINEAR FORMS
In this section, k will be a Ô¨Åeld and V will be a vector space over k, usually Ô¨Ånite-
dimensional. Even though we have not yet proved the basic theorems about determinants
(they will be proved in Section 9.9), we continue to use their familiar properties.
DeÔ¨Ånition.
A bilinear form (or inner product) on V is a bilinear function
f : V √ó V ‚Üík.
The ordered pair (V, f ) is called an inner product space.

Sec. 9.5
Bilinear Forms
695
Of course, (kn, f ) is an inner product space if f is the familiar dot product
f (u, v) =

i
uivi,
where u = (u1, . . . , un)t and v = (v1, ¬∑ ¬∑ ¬∑ , vn)t (the superscript t denotes transpose; re-
member that the elements of kn are n√ó1 column vectors). In terms of matrix multiplication,
we have
f (u, v) = utv.
There are two types of bilinear forms of special interest.
DeÔ¨Ånition.
A bilinear form f : V √ó V ‚Üík is symmetric if
f (u, v) = f (v, u)
for all u, v ‚ààV ; we call an inner product space (V, f ) a symmetric space when f is
symmetric.
A bilinear form f is alternating if f (v, v) = 0 for all v ‚ààV ; we call an inner product
space (V, f ) an alternating space when f is alternating.
Example 9.68.
(i) If V = k2 and its elements are viewed as column vectors, then det: V √ó V ‚Üík, given
by
a
b

,
c
d
	
‚Üídet
a
c
b
d

= ad ‚àíbc,
is an example of an alternating bilinear form.
(ii) In Chapter 8, we deÔ¨Åned a (Hermitian) form on the complex vector space cf(G) of all
class functions on a Ô¨Ånite group G. More generally, deÔ¨Åne a function f : Cn √ó Cn ‚ÜíC
by
f (u, v) =

j
u jv j,
where u = (u1, . . . , un)t, v = (v1, . . . , vn)t, and c denotes the complex conjugate of
a complex number c. Such a function is not C-bilinear because f (u, cv) = c f (u, v)
instead of cf (u, v). Hermitian forms are examples of sesquilinear forms; such forms can
be constructed over any Ô¨Åeld k equipped with an automorphism of order 2 (to play the role
of complex conjugation).
‚óÄ
Every bilinear form can be expressed in terms of symmetric and alternating bilinear
forms.

696
Advanced Linear Algebra
Ch. 9
Proposition 9.69.
Let k be a Ô¨Åeld of characteristic Ã∏= 2, and let f be a bilinear form
deÔ¨Åned on a vector space V over k. Then there are unique bilinear forms fs and fa, where
fs is symmetric and fa is alternating, such that f = fs + fa.
Proof.
By hypothesis, 1
2 ‚ààk, and so we may deÔ¨Åne
fs(u, v) = 1
2

f (u, v) + f (v, u)

and
fa(u, v) = 1
2

f (u, v) ‚àíf (v, u)

.
It is clear that f = fs + fa, that fs is symmetric, and that fa is alternating. Let us
prove uniqueness. If f = f ‚Ä≤
s + f ‚Ä≤
a, where f ‚Ä≤
s is symmetric and f ‚Ä≤
a is alternating, then
fs + fa = f ‚Ä≤
s + f ‚Ä≤
a, so that fs ‚àíf ‚Ä≤
s = f ‚Ä≤
a ‚àífa. If we deÔ¨Åne g to be the common value,
fs ‚àíf ‚Ä≤
s = g = f ‚Ä≤
a ‚àífa, then g is both symmetric and alternating. By Exercise 9.54 on
page 713, we have g = 0, and so fs = f ‚Ä≤
s and fa = f ‚Ä≤
a.
‚Ä¢
Remark.
If (V, g) is an inner product space, then g is called skew if
g(v, u) = ‚àíg(u, v)
for all u, v ‚ààV . We now show that if k does not have characteristic 2, then g is alternating
if and only if g is skew.
If g is any bilinear form, we have
g(u + v, u + v) = g(u, u) + g(u, v) + g(v, u) + g(v, v).
Therefore, if g is alternating, then 0 = g(u, v) + g(v, u), so that g is skew. (We have not
yet used the hypothesis that the characteristic of k is not 2.)
Conversely, if g is skew, then set u = v in the equation g(u, v) = ‚àíg(v, u) to get
g(u, u) = ‚àíg(u, u); that is, 2g(u, u) = 0. Thus, g(u, u) = 0, because k does not have
characteristic 2, and so g is alternating.
‚óÄ
DeÔ¨Ånition.
Let f be a bilinear form on a vector space V over a Ô¨Åeld k, and let E =
e1, . . . , en be a basis of V . Then an inner product matrix of f relative to E is
A = [ f (ei, e j)].
Suppose that (V, f ) is an inner product space, e1, . . . , en is a basis of V , and A =
[ f (ei, e j)] is the inner product matrix of f relative to E. If b =  biei and c =  ciei
are vectors in V , then
f (b, c) = f

biei,

ciei

=

i, j
bi f (ei, e j)c j.
If B and C denote the column vectors (b1, . . . , bn)t and (c1, . . . , cn)t, respectively, then
this last equation can be written in matrix form:
f (b, c) = Bt AC.
Thus, an inner product matrix determines f completely.

Sec. 9.5
Bilinear Forms
697
Proposition 9.70.
Let V be an n-dimensional vector space over a Ô¨Åeld k.
(i) Every n √ón matrix A over a Ô¨Åeld k is the inner product matrix of some bilinear form
f deÔ¨Åned on V √ó V . If f is symmetric, then its inner product matrix A relative to
any basis of V is a symmetric matrix (i.e., At = A). If f is alternating, then any
inner product matrix relative to any basis of V is skew-symmetric (i.e., At = ‚àíA).
(ii) If Bt AC = Bt A‚Ä≤C for all column vectors B and C, then A = A‚Ä≤.
(iii) Let A and A‚Ä≤ be inner product matrices of bilinear forms f and f ‚Ä≤ on V relative to
bases E and E‚Ä≤, respectively. Then f = f ‚Ä≤ if and only if A and A‚Ä≤ are congruent;
that is, there exists a nonsingular matrix P with
A‚Ä≤ = Pt AP.
Proof.
(i) For any matrix A, the function f : kn √ó kn ‚Üík, deÔ¨Åned by f (b, c) = bt Ac, is
easily seen to be a bilinear form, and A is its inner product matrix relative to the standard
basis e1, . . . , en. The reader may easily transfer this construction to any vector space V
once a basis of V is chosen.
If f is symmetric, then so is its inner product matrix A = [ai j], for ai j = f (ei, e j) =
f (e j, ei) = a ji; similarly, if f is alternating, then ai j = f (ei, e j) = ‚àíf (e j, ei) = ‚àía ji.
(ii) If b = 
i biei and c = 
i ciei, then we have seen that f (b, c) = Bt AC, where B
and C are the column vectors of the coordinates of b and c with respect to E. In particular,
if b = ei and c = e j, then f (ei, e j) = ai j is the i j entry of A.
(iii) Let the coordinates of b and c with respect to the basis E‚Ä≤ be B‚Ä≤ and C‚Ä≤, respec-
tively, so that f ‚Ä≤(b, c) = (B‚Ä≤)t A‚Ä≤C‚Ä≤, where A‚Ä≤ = [ f (e‚Ä≤
i, e‚Ä≤
j)]. If P is the transition matrix
E[1]E‚Ä≤, then B = P B‚Ä≤ and C = PC‚Ä≤. Hence, f (b, c) = Bt AC = (P B‚Ä≤)t A(PC‚Ä≤) =
(B‚Ä≤)t(Pt AP)C‚Ä≤. By part (ii), we must have Pt AP = A‚Ä≤.
For the converse, the given matrix equation A‚Ä≤ = Pt AP yields equations:
[ f ‚Ä≤(e‚Ä≤
i, e‚Ä≤
j)] = A‚Ä≤
= Pt AP
=

‚Ñìq
p‚Ñìi f (e‚Ñì, eq)pqj)

=

f

‚Ñì
p‚Ñìie‚Ñì,

q
pqjeq

= [ f (e‚Ä≤
i, e‚Ä≤
j)].
Hence, f ‚Ä≤(e‚Ä≤
i, e‚Ä≤
j) = f (e‚Ä≤
i, e‚Ä≤
j) for all i, j, from which it follows that f ‚Ä≤(b, c) = f (b, c) for
all b, c ‚ààV . Therefore, f = f ‚Ä≤.
‚Ä¢

698
Advanced Linear Algebra
Ch. 9
Corollary 9.71.
If (V, f ) is an inner product space and if A and A‚Ä≤ are inner product
matrices of f relative to different bases of V , then there exists a nonzero a ‚ààk with
det(A‚Ä≤) = a2 det(A).
Consequently, A‚Ä≤ is nonsingular if and only if A is nonsingular.
Proof.
This follows from the facts: det(Pt) = det(P); det(AB) = det(A) det(B); and P
is nonsingular if and only if det(P) Ã∏= 0.
‚Ä¢
The most important bilinear forms are the nondegenerate ones.
DeÔ¨Ånition.
A bilinear form f is nondegenerate if it has a nonsingular inner product
matrix.
For example, the dot product on kn is nondegenerate, for its inner product matrix relative
to the standard basis is the identity matrix I.
The discriminant of a bilinear form is essentially the determinant of its inner product
matrix. However, since the inner product matrix depends on a choice of basis, we must
complicate the deÔ¨Ånition a bit.
DeÔ¨Ånition.
If k is a Ô¨Åeld, then its multiplicative group of nonzero elements is denoted
by k√ó. DeÔ¨Åne (k√ó)2 = {a2 : a ‚ààk√ó}. The discriminant of a bilinear form f is either 0 or
det(A)(k√ó)2 ‚ààk√ó/(k√ó)2,
where A is an inner product matrix of f .
It follows from Corollary 9.71 that the discriminant of f is well-deÔ¨Åned. Quite often,
however, we are less careful and say that det(A) is the discriminant of f , where A is some
inner product matrix of f .
The next deÔ¨Ånition will be used in characterizing nondegeneracy.
DeÔ¨Ånition.
If (V, f ) is an inner product space and W ‚äÜV is a subspace of V , then the
left orthogonal complement of W is
W ‚ä•L = {b ‚ààV : f (b, w) = 0 for all w ‚ààW};
the right orthogonal complement of W is
W ‚ä•R = {c ‚ààV : f (w, c) = 0 for all w ‚ààW}.
It is easy to see that both W ‚ä•L and W ‚ä•R are subspaces of V . Moreover, W ‚ä•L = W ‚ä•R
if f is either symmetric or alternating, in which case we write W ‚ä•.
Let (V, f ) be an inner product space, and let A be the inner product matrix of f relative
to a basis e1, . . . , en of V . We claim that b ‚ààV ‚ä•L if and only if b is a solution of the
homogeneous system Atx = 0. If b ‚ààV ‚ä•L. then f (b, e j) = 0 for all j. Writing
b = 
i biei, we see that 0 = f (b, e j) = f

i biei, e j) = 
j bi f (ei, e j). In matrix
terms, b = (b1, . . . , bn)t and Bt A = 0; transposing, b is a solution of the homogeneous
system Atx = 0. The proof of the converse is left to the reader. A similar argument shows
that c ‚ààV ‚ä•R if and only if c is a solution of the homogeneous system Ax = 0.

Sec. 9.5
Bilinear Forms
699
Proposition 9.72.
If (V, f ) is an inner product space, then f is nondegenerate if and
only if V ‚ä•L = {0} = V ‚ä•R; that is, if f (b, c) = 0 for all c ‚ààV , then b = 0, and if
f (b, c) = 0 for all b ‚ààV , then c = 0.
Proof.
Our remarks above show that b ‚ààV ‚ä•L if and only if b is a solution of the homo-
geneous system Atx = 0. Therefore, V ‚ä•L Ã∏= {0} if and only if there is a nontrivial solution
b, and Exercise 3.70 on page 170 shows that this holds if and only if det(At) = 0. Since
det(At) = det(A), we have f degenerate. A similar argument shows that V ‚ä•R Ã∏= {0} if
and only if there is a nontrivial solution to Ax = 0.
‚Ä¢
Example 9.73.
Let (V, f ) be an inner product space, and let W ‚äÜV be a subspace. It is possible that f
is nondegenerate, while its restriction f |(W √ó W) is degenerate. For example, let V = k2,
and let f have the inner product matrix A =
 0 1
1 0

relative to the standard basis e1, e2. It
is clear that A is nonsingular, so that f is nondegenerate. On the other hand, if W = ‚ü®e1‚ü©,
then f |(W √ó W) = 0, and hence it is degenerate.
‚óÄ
Here is a characterization of nondegeneracy in terms of the dual space. This is quite
natural, for if f is a bilinear form on a vector space V over a Ô¨Åeld k, then for any Ô¨Åxed
u ‚ààV , the function f ( , u): V ‚Üík is a linear functional.
Proposition 9.74.
Let (V, f ) be an inner product space, and let e1, . . . , en be a basis of
V . Then f is nondegenerate if and only if f ( , e1), . . . , f ( , en) is a basis of the dual
space V ‚àó(we call the latter the dual basis).
Proof.
Assume that f is nondegenerate. Since dim(V ‚àó) = n, it sufÔ¨Åces to prove linear
independence. If there are scalars c1, . . . , cn with 
i ci f ( , ei) = 0, then

i
ci f (v, ei) = 0
for all v ‚ààV.
If we deÔ¨Åne u = 
i ciei, then f (v, u) = 0 for all v, so that nondegeneracy gives u = 0.
But e1, . . . , en is a linearly independent list, so that all ci = 0; hence, f (
, e1), . . .,
f ( , en) is also linearly independent, and hence it is a basis of V ‚àó.
Conversely, assume the given linear functionals are a basis of V ‚àó. If f (v, u) = 0 for
all v ‚ààV , where u = 
i ciei, then 
i ci f ( , ei) = 0. Since these linear functionals are
linearly independent, all ci = 0, and so u = 0; that is, f is nondegenerate.
‚Ä¢
Corollary 9.75.
If (V, f ) is an inner product space with f nondegenerate, then every
linear functional g ‚ààV ‚àóhas the form
g = f ( , u)
for a unique u ‚ààV .

700
Advanced Linear Algebra
Ch. 9
Proof.
Let e1, . . . , en be a basis of V , and let f ( , e1), . . . , f ( , en) be its dual basis.
Since g ‚ààV ‚àó, there are scalars ci with g = 
i ci f ( , ei). If we deÔ¨Åne u = 
i ciei, then
g(v) = f (v, u).
To prove uniqueness, suppose that f ( , u) = f ( , u‚Ä≤). Then f (v, u ‚àíu‚Ä≤) = 0 for all
v ‚ààV , and so nondegeneracy of f gives u ‚àíu‚Ä≤ = 0.
‚Ä¢
Corollary 9.76.
Let (V, f ) be an inner product space with f nondegenerate. If e1, . . . , en
is a basis of V , then there exists a basis b1, . . . , bn of V with
f (ei, b j) = Œ¥i j.
Proof.
Since f is nondegenerate, the function V ‚ÜíV ‚àó, given by v ‚Üíf ( , v), is an
isomorphism. It follows that the following diagram commutes:
V √ó V
f

œï

k,
V √ó V ‚àó
ev









where ev is evaluation (x, g) ‚Üíg(x) and œï : (x, y) ‚Üí(x, f ( , y)). For each i, let
gi ‚ààV ‚àóbe the ith coordinate function: If v ‚ààV and v = 
j c je j, then gi(v) = ci. By
Corollary 9.75, there are b1, . . . , bn ‚ààV with gi = f ( , bi) for all i. Commutativity of the
diagram gives
f (ei, b j) = ev(ei, g j) = Œ¥i j.
‚Ä¢
Proposition 9.77.
Let (V, f ) be an inner product space, and let W be a subspace of V .
If f |(W √ó W) is nondegenerate, then
V = W ‚äïW ‚ä•.
Remark.
We do not assume that f itself is nondegenerate; even if we did, it would not
force f |(W √ó W) to be nondegenerate, as we have seen in Example 9.73.
‚óÄ
Proof.
If u ‚ààW ‚à©W ‚ä•, then f (w, u) = 0 for all w ‚ààW. Since f |(W √ó W) is nonde-
generate and u ‚ààW, we have u = 0; hence, W ‚à©W ‚ä•= {0}. If v ‚ààV , then f ( , v)|W
is a linear functional on W; that is, f ( , v)|W ‚ààW ‚àó. By Corollary 9.75, there is w0 ‚ààW
with f (w, v) = f (w, w0) for all w ‚ààW. Hence, v = w0 + (v ‚àíw0), where w0 ‚ààW and
v ‚àíw0 ‚ààW ‚ä•.
‚Ä¢
There is a name for direct sum decompositions as in the proposition.
DeÔ¨Ånition.
If (V, f ) is an inner product space, then we say that a direct sum
V = W1 ‚äï¬∑ ¬∑ ¬∑ ‚äïWr
is an orthogonal direct sum if, for all i Ã∏= j, we have f (wi, w j) = 0 for all wi ‚ààWi and
w j ‚ààW j.

Sec. 9.5
Bilinear Forms
701
We are now going to look more carefully at special bilinear forms; Ô¨Årst we examine
alternating forms, then symmetric ones.
We begin by constructing all alternating bilinear forms f on a two-dimensional vector
space V over a Ô¨Åeld k. As always, f = 0 is an example. Otherwise, there exist two vectors
e1, e2 ‚ààV with f (e1, e2) Ã∏= 0; say, f (e1, e2) = c. If we replace e1 by e‚Ä≤
1 = c‚àí1e1, then
f (e‚Ä≤
1, e2) = 1. Since f is alternating, the inner product matrix A of f relative to the basis
e‚Ä≤
1, e2 is A =
 0
1
‚àí1
0

.
DeÔ¨Ånition.
A hyperbolic plane over a Ô¨Åeld k is a two-dimensional vector space over k
equipped with a nonzero alternating bilinear form.
We have just seen that every two-dimensional alternating space (V, f ) in which f is
not identically zero has an inner product matrix A =
 0 1
‚àí1 0

.
Theorem 9.78.
Let (V, f ) be an alternating space, where V is a vector space over a
Ô¨Åeld k. If f is nondegenerate, then there is an orthogonal direct sum
V = H1 ‚äï¬∑ ¬∑ ¬∑ ‚äïHm,
where each Hi is a hyperbolic plane.
Proof.
The proof is by induction on dim(V ) ‚â•1. For the base step, note that dim(V ) ‚â•2,
because an alternating form on a one-dimensional space must be 0, hence degenerate. If
dim(V ) = 2, then we saw that V is a hyperbolic plane. For the inductive step, note that
there are vectors e1, e2 ‚ààV with f (e1, e2) Ã∏= 0 (because f is nondegenerate, hence,
nonzero), and we may normalize so that f (e1, e2) = 1: if f (e1, e2) = d, replace e2 by
d‚àí1e2. The subspace H1 = ‚ü®e1, e2‚ü©is a hyperbolic plane, and the restriction f |(H1 √ó H1)
is nondegenerate. Thus, Proposition 9.77 gives V = H1‚äïH‚ä•
1 . Since the restriction of f to
H‚ä•
1 is nondegenerate, by Exercise 9.56 on page 713, the inductive hypothesis applies.
‚Ä¢
Corollary 9.79.
Let (V, f ) be an alternating space, where V is a vector space over a
Ô¨Åeld k. If f is nondegenerate, then dim(V ) is even.
Proof.
By the theorem, V is a direct sum of two-dimensional subspaces.
‚Ä¢
DeÔ¨Ånition.
Let (V, f ) be an alternating space in which f is nondegenerate. A symplec-
tic13 basis is a basis x1, y1, . . . , xm, ym such that f (xi, yi) = 1, f (yi, xi) = ‚àí1 for all i,
and all other f (xi, x j), f (yi, y j), f (xi, y j), and f (y j, xi) are 0.
13The term symplectic was coined by H. Weyl. On page 165 of his book, The Classical Groups; Their Invari-
ants and Representations, he wrote, "The name 'complex group' formerly advocated by me in allusion to line
complexes, as these are deÔ¨Åned by the vanishing of antisymmetric bilinear forms, has become more and more
embarrassing through collision with the word 'complex' in the connotation of complex number. I therefore pro-
pose to replace it by the corresponding Greek adjective 'symplectic.' Dickson calls the group the 'Abelian linear
group' in homage to Abel who Ô¨Årst studied it."

702
Advanced Linear Algebra
Ch. 9
Corollary 9.80.
Let (V, f ) be an alternating space in which f is nondegenerate,14 and
let A be an inner product matrix for f (relative to some basis of V ).
(i) There exists a symplectic basis x1, y1, . . . , xm, ym for V , and A is a 2m √ó2m matrix
for some m ‚â•1.
(ii) A is congruent to a matrix direct sum of blocks of the form
 0
1
‚àí1
0

, and the latter
is congruent to
 0
I
‚àíI
0

, where I is the m √ó m identity matrix.
(iii) Every nonsingular skew-symmetric matrix A over a Ô¨Åeld k is congruent to a direct
sum of 2 √ó 2 blocks
 0
1
‚àí1
0

.
Proof.
(i) A symplectic basis exists, by Theorem 9.78, and so V is even-dimensional.
(ii) An inner product matrix A is congruent to the inner product matrix relative to a sym-
plectic basis arising from a symplectic basis x1, y1, . . . , xm, ym. The second inner product
matrix arises from a reordered symplectic basis x1, . . . , xm, y1, . . . , ym.
(iii) A routine calculation.
‚Ä¢
We now consider symmetric bilinear forms.
DeÔ¨Ånition.
Let (V, f ) be a symmetric space, and let E = e1, . . . , en be a basis of V .
Then E is an orthogonal basis if f (ei, e j) = 0 for all i Ã∏= j, and E is an orthonormal
basis if f (ei, e j) = Œ¥i j, where Œ¥i j is the Kronecker delta.
If e1, . . . , en is an orthogonal basis of a symmetric space (V, f ), then V = ‚ü®e1‚ü©‚äï¬∑ ¬∑ ¬∑‚äï
‚ü®en‚ü©is an orthogonal direct sum. In Corollary 9.76, we saw that if (V, f ) is a symmetric
space with f nondegenerate, and if e1, . . . , en is a basis of V , then there exists a basis
b1, . . . , bn of V with f (ei, b j) = Œ¥i j. If E is an orthonormal basis, then we can set bi = ei
for all i.
Theorem 9.81.
Let (V, f ) be a symmetric space, where V is a vector space over a Ô¨Åeld k
of characteristic not 2.
(i) V has an orthogonal basis, and so every symmetric matrix A with entries in k is
congruent to a diagonal matrix.
(ii) If C = diag[c2
1d1, . . . , c2
ndn], then C is congruent to D = diag[d1, . . . , dn].
(iii) If f is nondegenerate and if every element in k has a square root in k, then V has an
orthonormal basis. Every symmetric matrix A with entries in k is congruent to I.
14If the form f is degenerate, then A is congruent to a direct sum of 2 √ó 2 blocks

0 1
‚àí1 0

and a block of 0's.

Sec. 9.5
Bilinear Forms
703
Proof.
(i) If f = 0, then every basis is an orthogonal basis. We may now assume that f Ã∏=
0. By Exercise 9.54 on page 713, which applies because k does not have characteristic 2,
there is some v ‚ààV with f (v, v) Ã∏= 0 (otherwise, f is both symmetric and alternating). If
W = ‚ü®v‚ü©, then f |(W √óW) is nondegenerate, so that Proposition 9.77 gives V = W ‚äïW ‚ä•.
The proof is now completed by induction on dim(W).
If A is an n √ó n symmetric matrix, then Proposition 9.70(i) shows that there is a
symmetric bilinear form f and a basis U = u1, . . . , un so that A is the inner prod-
uct matrix of f relative to U. We have just seen that there exists an orthogonal basis
v1, . . . , vn, so that Proposition 9.70(iii) shows that A is congruent to the diagonal matrix
diag[ f (v1, v1), . . . , f (vn, vn)].
(ii) If an orthogonal basis consists of vectors vi with f (vi, vi) = c2
i di, then replacing each
vi by v‚Ä≤
i = c‚àí1
i
vi gives an orthogonal basis with f (v‚Ä≤
i, v‚Ä≤
i) = di. It follows that the inner
product matrix of f relative to the basis v‚Ä≤
1, . . . , v‚Ä≤
n is D = diag[d1, . . . , dn].
(iii) By part (i), there exists an orthogonal basis v1, . . . , vn; let f (vi, vi) = ci for each i.
Since f is nondegenerate, ci Ã∏= 0 for all i (the determinant of the inner product matrix
relative to this orthogonal basis is c1c2 ¬∑ ¬∑ ¬∑ cn); since each ci is a square, by hypothesis, we
may replace each vi by v‚Ä≤
i = (‚àöci)‚àí1vi, as in part (ii); this new basis is orthonormal. The
Ô¨Ånal statement follows because the inner product matrix relative to an orthonormal basis is
the identity I.
‚Ä¢
Notice that Theorem 9.81 does not say that any two diagonal matrices over a Ô¨Åeld k
of characteristic not 2 are congruent; this depends on k. For example, if k = C, then all
(nonsingular) diagonal matrices are congruent to I, but we now show that this is false if
k = R.
DeÔ¨Ånition.
A symmetric bilinear form f on a vector space V over R is positive deÔ¨Ånite
if f (v, v) > 0 for all nonzero v ‚ààV , while f is negative deÔ¨Ånite if f (v, v) < 0 for all
nonzero v ‚ààV .
The next result, and its matrix corollary, was proved by J. J. Sylvester. When n = 2, it
classiÔ¨Åes the conic sections, and when n = 3, it classiÔ¨Åes the quadric surfaces.
Lemma 9.82.
If f is a symmetric bilinear form on a vector space V over R of dimension
m, then there is an orthogonal direct sum
V = W+ ‚äïW‚àí‚äïW0,
where f |W+ is positive deÔ¨Ånite, f |W‚àíis negative deÔ¨Ånite, and f |W0 is identically 0.
Moreover, the dimensions of these three subspaces are uniquely determined by f .
Proof.
By Theorem 9.81, there is an orthogonal basis v1, . . . , vm of V . Denote f (vi, vi)
by di. As any real number, each di is either positive, negative, or 0, and we rearrange the
basis vectors so that v1, . . . , vp have postive di, vp+1, . . . , vp+r have negative di, and the
last vectors have di = 0. It follows easily that V is the orthogonal direct sum
V =

v1, . . . , vp
 
‚äï

vp+1, . . . , vp+r
 
‚äï

vp+r+1, . . . , vm
 
,

704
Advanced Linear Algebra
Ch. 9
and that the restrictions of f to each summand are positive deÔ¨Ånite, negative deÔ¨Ånite, and
zero.
Now W0 = V ‚ä•depends only on f , and hence its dimension depends only on f as well.
To prove uniqueness of the other two dimensions, suppose that there is a second orthogonal
direct sum V = W ‚Ä≤
+‚äïW ‚Ä≤
‚àí‚äïW0. If T : V ‚ÜíW+ is the projection, then ker T = W‚àí‚äïW0.
It follows that if œï = T |W ‚Ä≤
+, then
ker œï = W ‚Ä≤
+ ‚à©ker T = W ‚Ä≤
+ ‚à©

W‚àí‚äïW0

.
However, if v ‚ààW ‚Ä≤
+, then f (v, v) ‚â•0, while if v ‚ààW‚àí‚äïW0, then f (v, v) ‚â§0;
hence, if v ‚ààker œï, then f (v, v) = 0. But f |W ‚Ä≤
+ is positive deÔ¨Ånite, for this is one of
the deÔ¨Åning properties of W ‚Ä≤
+, so that f (v, v) = 0 implies v = 0. We conclude that
ker œï = {0}, and so œï : W ‚Ä≤
+ ‚ÜíW+ is an injection; therefore, dim(W ‚Ä≤
+) ‚â§dim(W+). The
reverse inequality is proved similarly, so that dim(W ‚Ä≤
+) = dim(W+). Finally, the formula
dim(W‚àí) = dim(V ) ‚àídim(W+) ‚àídim(W0), and its primed version, give dim(W ‚Ä≤
‚àí) =
dim(W‚àí).
‚Ä¢
Theorem 9.83 (Law of Inertia).
Every symmetric n √ó n matrix A over R is congruent
to a matrix of the form
Ô£Æ
Ô£∞
Ip
0
0
0
‚àíIr
0
0
0
0
Ô£π
Ô£ª.
Moreover, the signature s of f , deÔ¨Åned by s = p ‚àír is well-deÔ¨Åned, and two n √ó n
symmetric real matrices are congruent if and only if they have the same rank and the same
signature.
Proof.
By Theorem 9.81, A is congruent to a diagonal matrix diag[d1, . . . , dn], where
d1, . . . , dp are positive, dp+1, . . . , dp+r are negative, and dp+r+1, . . . , dn are 0. But every
positive real is a square, while every negative real is the negative of a square; it now follows
from Theorem 9.81(ii) that A is congruent to a matrix as in the statement of the theorem.
It is clear that congruent n √ó n matrices have the same rank and the same signature.
Conversely, let A and A‚Ä≤ have the same rank and the same signature. Now A is congruent
to the matrix direct sum Ip ‚äï‚àíIr ‚äï0 and A‚Ä≤ is congruent to Ip‚Ä≤ ‚äï‚àíIr‚Ä≤ ‚äï0. Since
rank(A) = rank(A‚Ä≤), we have p‚Ä≤ + r‚Ä≤ = p + r; since the signatures are the same, we have
p‚Ä≤ ‚àír‚Ä≤ = p ‚àír. It follows that p‚Ä≤ = p and r‚Ä≤ = r, so that both A and A‚Ä≤ are congruent
to the same diagonal matrix of 1's, ‚àí1's, and 0's, and hence they are congruent to each
other.
‚Ä¢
It would be simplest if a symmetric space (V, f ) with f nondegenerate always had
an orthonormal basis; that is, if every symmmetric matrix were congruent to the identity
matrix. This need not be so, for the 2 √ó 2 real matrix ‚àíI is not congruent to I because
their signatures are different (I has signature 2 and ‚àíI has signature ‚àí2).
Closely related to bilinear forms are quadratic forms; they arise from a bilinear form f
deÔ¨Åned on a vector space V over a Ô¨Åeld k by considering the function Q : V ‚Üík given by
Q(v) = f (v, v).

Sec. 9.5
Bilinear Forms
705
DeÔ¨Ånition.
Let V be an a vector space over a Ô¨Åeld k. A quadratic form is a function
Q : V ‚Üík such that
(i) Q(cv) = c2Q(v) for all v ‚ààV and c ‚ààk;
(ii) the function g : V √ó V ‚Üík, deÔ¨Åned by
g(u, v) = Q(u + v) ‚àíQ(u) ‚àíQ(v),
is a bilinear form.
Example 9.84.
(i) If f is a bilinear form on a vector space V , deÔ¨Åne Q(v) = f (v, v) for all v ‚ààV ; we
show that Q is a quadratic form. Now Q(cv) = f (cv, cv) = c2 f (v, v) = c2Q(v), giving
the Ô¨Årst axiom in the deÔ¨Ånition. If u, v ‚ààV , then
Q(u + v) = f (u + v, u + v)
= f (u, u) + f (u, v) + f (v, u) + f (v, v)
= Q(u) + Q(v) + g(u, v),
where
g(u, v) = f (u, v) + f (v, u).
It is easy to check that g is a bilinear form that is symmetric.
(ii) We have just seen that every bilinear form f determines a quadratic form Q. If f is
symmetric and k does not have characteristic 2, then Q determines f . In fact, the formula
2 f (u, v) = g(u, v) gives f (u, v) = 1
2g(u, v) in this case.
(iii) If f is the usual dot product deÔ¨Åned on Rn, then the corresponding quadratic form is
Q(v) = ‚à•v‚à•2, where ‚à•v‚à•is the length of the vector v.
(iv) If f is a bilinear form on a vector space V with inner product matrix A = [ai j] relative
to some basis e1, . . . , en, then if u =  ciei,
Q(u) =

i, j
ai jcic j.
If n = 2, for example, we have
Q(u) = a11c2
1 + (a12 + a21)c1c2 + a22c2
2.
Thus, quadratic forms are really homogeneous quadratic polynomials.
‚óÄ
We have just observed, in the last example, that if a Ô¨Åeld k does not have characteris-
tic 2, then symmetric bilinear forms and quadratic forms are merely two different ways of
viewing the same thing, for each determines the other.

706
Advanced Linear Algebra
Ch. 9
We have classiÔ¨Åed quadratic forms Q over C and over R. The classiÔ¨Åcation over the
prime Ô¨Åelds is also known, as is the classiÔ¨Åcation over the Ô¨Ånite Ô¨Åelds, and we now state
(without proof) the results when Q is nondegenerate. Given a quadratic form Q deÔ¨Åned on
a Ô¨Ånite-dimensional vector space V over a Ô¨Åeld k, its associated bilinear form is
f (x, y) = Q(x + y) ‚àíQ(x) ‚àíQ(y).
Call two quadratic forms equivalent if their associated bilinear forms have congruent inner
product matrices, and call a quadratic form nondegenerate if its bilinear form is non-
degerate. As we have just seen in Example 9.84, f is a symmetric bilinear form (which
is uniquely determined by Q when k does not have characteristic 2). If k is a Ô¨Ånite Ô¨Åeld
of odd characteristic, then two nondegenerate quadratic forms over k are equivalent if and
only if they have the same discriminant (see Kaplansky, Linear Algebra and Geometry; A
Second Course, pp. 14-15). If k is a Ô¨Ånite Ô¨Åeld of characteristic 2, the theory is a bit more
complicated. In this case, the associated symmetric bilinear form
g(x, y) = Q(x + y) + Q(x) + Q(y)
must also be alternating, for g(x, x) = Q(2x)+2Q(x) = 0. Therefore, V has a symplectic
basis x1, y1, . . . , xm, ym. The Arf invariant of Q is deÔ¨Åned by
Arf(Q) =
m

i=1
Q(xi)Q(yi)
[it is not at all obvious that the Arf invariant is an invariant; i.e., that Arf(Q) does not
depend on the choice of symplectic basis; see R. L. Dye, "On the Arf Invariant," Journal
of Algebra 53 (1978), pp. 36-39, for an elegant proof]. If k is a Ô¨Ånite Ô¨Åeld of characteristic
2, then two nondegenerate quadratic forms over k are equivalent if and only if they have
the same discriminant and the same Arf invariant (see Kaplansky, Linear Algebra and
Geometry; A Second Course, pp. 27-33). The classiÔ¨Åcation of quadratic forms over Q is
much deeper (see Borevich and Shafarevich, Number Theory, pp. 61-70). Just as R can
be obtained from Q by completing with respect to the usual metric d(a, b) = |a ‚àíb| (that
is, by adding points to force Cauchy sequences to converge), so, too, can we complete Z,
for every prime p, with respect to the p-adic metric (see the discussion on page 503). The
completion Zp is called the p-adic integers. The p-adic metric on Z can be extended to
Q, and its completion Qp [which turns out to be Frac(Zp)] is called the p-adic numbers.
The Hasse-Minkowski theorem says that two quadratic forms over Q are equivalent if and
only if they are equivalent over R and over Qp for all primes p.
The Ô¨Årst theorems of linear algebra consider the structure of vector spaces in order to
pave the way for a discussion of linear transformations. Similarly, the Ô¨Årst theorems of
inner product spaces enable us to discuss the appropriate linear transformations.
DeÔ¨Ånition.
If (V, f ) is an inner product space, where V is a Ô¨Ånite-dimensional vector
space over a Ô¨Åeld k and f is a nondegenerate bilinear form, then an isometry is a linear
transformation œï : V ‚ÜíV such that, for all u, v ‚ààV ,
f (u, v) = f (œïu, œïv).

Sec. 9.5
Bilinear Forms
707
Proposition 9.85.
Let (V, f ) be an inner product space, where f is a nondegenerate
bilinear form, let E = e1, . . . , en be a basis of V , and let A be the inner product matrix
relative to E. Then œï ‚ààGL(V ) is an isometry if and only if its matrix M = E[œï]E satisÔ¨Åes
the equation Mt AM = A.
Proof.
Recall the equation
f (b, c) = Bt AC,
where b, c ‚ààV and B, C ‚ààkn are their coordinate vectors relative to the basis E. In this
notation, E1, . . . , En is the standard basis of kn. Now
œï(ei) = M Ei
for all i, because M Ei is the ith column of M that is the coordinate vector of œï(ei). There-
fore,
f (œïei, œïe j) = (M Ei)t A(M E j) = Et
i (Mt AM)E j.
If œï is an isometry, then
f (œïei, œïe j) = f (ei, e j) = Et
i AE j,
so that f (ei, e j) = Et
i AE j = Et
i (Mt AM)E j. Hence, Proposition 9.70(ii) gives Mt AM =
A.
Conversely, if Mt AM = A, then
f (œïei, œïe j) = Et
i (Mt AM)E j = Et
i AE j = f (ei, e j),
and œï is an isometry.
‚Ä¢
Proposition 9.86.
Let (V, f ) be an inner product space, where V is a Ô¨Ånite-dimensional
vector space over a Ô¨Åeld k and f is a nondegenerate bilinear form. Then Isom(V, f ), the
set of all isometries of (V, f ), is a subgroup of GL(V ).
Proof.
We prove that Isom(V, f ) is a subgroup; of course, 1V is an isometry.
Let
œï : V ‚ÜíV be an isometry. If u ‚ààV and œïu = 0, then, for all v ‚ààV , we have
0 = f (œïu, œïv) = f (u, v).
Since f is nondegenerate, u = 0 and œï is an injection. Hence, dim(im œï) = dim(V ), so
that im œï = V , by Corollary 3.90(ii). Therefore, every isometry is nonsingular.
The inverse of an isometry œï is also an isometry: For all u, v ‚ààV ,
f (œï‚àí1u, œï‚àí1v) = f (œïœï‚àí1u, œïœï‚àí1v)
= f (u, v).
Finally, the composite of two isometries œï and Œ∏ is also an isometry:
f (u, v) = f (œïu, œïv) = f (Œ∏œïu, Œ∏œïv).
‚Ä¢
Computing the inverse of a general nonsingular matrix is quite time-consuming, but it
is easier for isometries.

708
Advanced Linear Algebra
Ch. 9
DeÔ¨Ånition.
Let (V, f ) be an inner product space whose bilinear form f is nondegenerate.
The adjoint of a linear transformation T : V ‚ÜíV is a linear transformation T ‚àó: V ‚ÜíV
such that, for all u, v ‚ààV ,
f (T u, v) = f (u, T ‚àóv).
Let us see that adjoints exist.
Proposition 9.87.
If (V, f ) is an inner product space whose bilinear form f is nonde-
generate, then every linear transformation T : V ‚ÜíV has an adjoint.
Proof.
Let e1, . . . , en be a basis of V . For each j, the function œï j : V ‚Üík, deÔ¨Åned by
œï j(v) = f (T v, e j),
is easily seen to be a linear functional. By Corollary 9.75, there exists u j ‚ààV with
œï j(v) = f (v, u j) for all v ‚ààV . DeÔ¨Åne T ‚àó: V ‚ÜíV by T ‚àó(e j) = u j, and note that
f (T ei, e j) = œï j(ei) = f (ei, u j) = f (ei, T ‚àóe j).
‚Ä¢
Proposition 9.88.
Let (V, f ) be an inner product space whose bilinear form f is nonde-
generate. If T : V ‚ÜíV is a linear transformation with adjoint T ‚àó, then T is an isometry
if and only if T ‚àóT = 1V , in which case T ‚àó= T ‚àí1.
Proof.
If T ‚àóT = 1V , then, for all u, v ‚ààV , we have
f (T u, T v) = f (u, T ‚àóT v) = f (u, v),
so that T is an isometry.
Conversely, assume that T is an isometry. Choose v ‚ààV ; for all u ‚ààV , we have
f (u, T ‚àóT v ‚àív) = f (u, T ‚àóT v) ‚àíf (u, v)
= f (T u, T v) ‚àíf (u, v)
= 0.
Since f is nondegenerate, T ‚àóT v ‚àív = 0; that is, T ‚àóT v = v. As this is true for all v ‚ààV ,
we have T ‚àóT = 1V .
‚Ä¢
DeÔ¨Ånition.
Let (V, f ) be an inner product space, where V is a Ô¨Ånite-dimensional vector
space over a Ô¨Åeld k and f is a nondegenerate bilinear form.
(i) If f is alternating, then Isom(V, f ) is called the symplectic group, and it is denoted
by Sp(V, f ).
(ii) If f is symmetric, then Isom(V, f ) is called the orthogonal group, and it is denoted
by O(V, f ).

Sec. 9.5
Bilinear Forms
709
As always, a choice of basis E of an n-dimensional vector space V over a Ô¨Åeld k gives
an isomorphism ¬µ: GL(V ) ‚ÜíGL(n, k), the group of all nonsingular n √ó n matrices
over k. In particular, let (V, f ) be an alternating space with f nondegenerate, and let
E = x1, y1, . . . , xm, ym be a symplectic basis of V (which exists, by Corollary 9.80);
recall that n = dim(V ) is even; say, n = 2m. Denote the image of Sp(V, f ) by Sp(2m, k).
Similarly, if (V, f ) is a symmetric space with f nondegenerate, and E is an orthogonal
basis (which exists when k does not have characteristic 2, by Theorem 9.81), denote the
image of O(V, f ) by O(n, f ).
Let us Ô¨Ånd adjoints when the bilinear form is symmetric or alternating.
Proposition 9.89.
Let (V, f ) be a symmetric space, where V is an n-dimensional vector
space over a Ô¨Åeld k and f is nondegenerate, and let E = e1, . . . , en be an orthogonal
basis with f (ei, ei) = ci.
If B = [bi j] is a matrix relative to E, then its adjoint B‚àóis its "weighted" transpose
[c‚àí1
i
c jb ji]. In particular, if E is an orthonormal basis, then B‚àó= Bt, the transpose of B.
Remark.
It follows that B is orthogonal if and only if Bt B = I.
‚óÄ
Proof.
We have
f (Bei, e j) = f

‚Ñì
b‚Ñìie‚Ñì, e j

=

‚Ñì
b‚Ñìi f (e‚Ñì, e j)
= b jic j.
If B‚àó= [b‚àó
i j], then a similar calculation gives
f (ei, B‚àóe j) =

b‚àó
‚Ñìj f (ei, e‚Ñì) = cib‚àó
i j.
Since f (Bei, e j) = f (ei, B‚àóe j), we have
b jic j = cib‚àó
i j
for all i, j. Since f is nondegenerate, all ci Ã∏= 0, and so
b‚àó
i j = c‚àí1
i
c jb ji.
The last remark follows, for if E is an orthonormal basis, then ci = 1 for all i.
‚Ä¢
How can we recognize a symplectic matrix?

710
Advanced Linear Algebra
Ch. 9
Proposition 9.90.
Let (V, f ) be an alternating space, where V is a 2m-dimensional
vector space over a Ô¨Åeld k and f is nondegenerate, and let E be a symplectic basis ordered
as x1, . . . , xm, y1, . . . , ym.
The adjoint of a matrix B =
P
Q
S
T

relative to E, partitioned into m √ó m blocks, is
B‚àó=
 T t
‚àíQt
‚àíSt
Pt

.
Remark.
It follows that B ‚ààSp(2m, k) if and only if B‚àóB = I.
‚óÄ
Proof.
We have
f (Bxi, x j) = f

‚Ñì
p‚Ñìi x‚Ñì+ s‚Ñìi y‚Ñì, x j

=

‚Ñì
p‚Ñìi f (x‚Ñì, x j) +

‚Ñì
s‚Ñìi f (y‚Ñì, x j)
= ‚àís ji,
because f (x‚Ñì, x j) = 0 and f (y‚Ñì, x j) = ‚àíŒ¥‚Ñìj for all i, j. Let us partition the adjoint B‚àó
into m √ó m blocks:
B‚àó=
*
K

$

.
Hence,
f (xi, B‚àóx j) = f

xi,

‚Ñì
œÄ‚Ñìj x‚Ñì+ œÉ‚Ñìj y‚Ñì

=

‚Ñì
œÄ‚Ñìj f (xi, x‚Ñì) +

‚Ñì
œÉ‚Ñìj f (xi, y‚Ñì)
= œÉi j,
because f (xi, x‚Ñì) = 0 and f (xi, y‚Ñì) = Œ¥i‚Ñì. Since f (Bxi, x j) = f (xi, B‚àóx j), we have
œÉi j = ‚àís ji. Hence,  = ‚àíSt. Computation of the other blocks of B‚àóis similar.
‚Ä¢
The next question is whether Isom(V, f ) depends on the choice of nondegenerate
alternating bilinear form f . Observe that GL(V ) acts on kV √óV , the set of all functions
V √ó V ‚Üík: If f : V √ó V ‚Üík and œï ‚ààGL(V ), then deÔ¨Åne œïf = f œï, where
f œï(b, c) = f (œï‚àí1b, œï‚àí1c).
This formula does yield an action: If Œ∏ ‚ààGL(V ), then (œïŒ∏) f = f œïŒ∏, where
(œïŒ∏) f (b, c) = f œïŒ∏(b, c)
= f ((œïŒ∏)‚àí1b, (œïŒ∏)‚àí1c)
= f (Œ∏‚àí1œï‚àí1b, Œ∏‚àí1œï‚àí1c).

Sec. 9.5
Bilinear Forms
711
On the other hand, œï(Œ∏ f ) is deÔ¨Åned by
( f Œ∏)œï(b, c) = f Œ∏(œï‚àí1b, œï‚àí1c)
= f (Œ∏‚àí1œï‚àí1b, Œ∏‚àí1œï‚àí1c),
so that (œïŒ∏) f = œï(Œ∏ f ).
DeÔ¨Ånition.
Let V and W be Ô¨Ånite-dimensional vector spaces over a Ô¨Åeld k, and let
f : V √ó V ‚Üík and g : W √ó W ‚Üík be bilinear forms. Then f and g are equivalent
if there is an isometry œï : V ‚ÜíW.
Proposition 9.91.
If V is a Ô¨Ånite-dimensional vector space over a Ô¨Åeld k and if
f, g : V √ó V ‚Üík are bilinear forms, then the following statements are equivalent.
(i) f and g are equivalent.
(ii) If E = e1, . . . , en is a basis of V , then the inner product matrices of f and g with
respect to E are congruent.
(iii) There is œï ‚ààGL(V ) with g = f œï.
Proof.
(i) ‚áí(ii) If œï : V ‚ÜíV is an isometry, then g(œï(b), œï(c)) = f (b, c) for all
b, c ‚ààV . If E = e1, . . . , en is a basis of V , then E‚Ä≤ = œï(e1), . . . , œï(en) is also a basis,
because œï is an isomorphism. Hence, A‚Ä≤ = [g(œï(ei), œï(e j))] = [ f (ei, e j)] = A for all
i, j; that is, the inner product matrix A‚Ä≤ of g with respect to E‚Ä≤ is equal to the inner product
matrix A of f with respect to E. By Proposition 9.70(iii), the inner product matrix A‚Ä≤‚Ä≤ of
g with respect to E is congruent to A.
(ii) ‚áí(iii) If A = [ f (ei, e j)] and A‚Ä≤ = [g(ei, e j)], then there exists a nonsingular
matrix Q = [qi j] with A‚Ä≤ = Qt AQ. DeÔ¨Åne Œ∏ : V ‚ÜíV to be the linear transformation
with Œ∏(e j) = 
ŒΩ qŒΩjeŒΩ. Finally, g = f Œ∏‚àí1:
[g(ei, e j)] = A‚Ä≤ = Qt AQ =

f

ŒΩ
qŒΩieŒΩ,

Œª
qŒªjeŒª

= [ f (Œ∏(ei), Œ∏(e j))] = [ f Œ∏‚àí1(ei, e j)].
(iii) ‚áí(i) It is obvious from the deÔ¨Ånition that œï‚àí1 : (V, g) ‚Üí(V, f ) is an isometry:
g(b, c) = f œï(b, c) = f (œï‚àí1b, œï‚àí1c).
Therefore, g is equivalent to f .
‚Ä¢
Proposition 9.92.
(i) Let (V, f ) be an inner product space, where V is a Ô¨Ånite-dimensional vector space
over a Ô¨Åeld k and f is a nondegenerate bilinear form. The stabilizer GL(V ) f of f
under the action on kV √óV is Isom(V, f ).
(ii) If g : V √ó V ‚Üík lies in the same orbit as f , then Isom(V, f ) and Isom(V, g) are
isomorphic; in fact, they are conjugate subgroups of GL(V ).

712
Advanced Linear Algebra
Ch. 9
Proof.
(i) By deÔ¨Ånition of stabilizer, œï ‚ààGL(V ) f if and only if f œï = f ; that is, for all
b, c ‚ààV , we have f (œï‚àí1b, œï‚àí1c) = f (b, c). Thus, œï‚àí1, and hence œï, is an isometry.
(ii) By Exercise 2.99 on page 114, we have GL(V )g = œÑ(GL(V ) f )œÑ ‚àí1 for some œÑ ‚àà
GL(V ); that is, Isom(V, g) = œÑIsom(V, f )œÑ ‚àí1.
‚Ä¢
It follows from Proposition 9.92 that equivalent bilinear forms have isomorphic iso-
metry groups. We can now show that the symplectic group is, to isomorphism, independent
of the choice of nondegenerate alternating form.
Theorem 9.93.
If (V, f ) and (V, g) are alternating spaces, where f and g are nonde-
generate, then f and g are equivalent and
Sp(V, f ) ‚àº= Sp(V, g).
Proof.
By Corollary 9.80(ii), the inner product matrix of any nondegenerate alternating
bilinear form is congruent to
 0
I
‚àíI 0

, where I is the identity matrix. The result now follows
from Proposition 9.91.
‚Ä¢
Symplectic groups give rise to simple groups. If k is a Ô¨Åeld, deÔ¨Åne PSp(2m, k) =
Sp(2m, k)/Z(2m, k), where Z(2m, k) is the subgroup of all scalar matrices in Sp(2m, k).
The groups PSp(2m, k) are simple for all m ‚â•1 and all Ô¨Åelds k with only three exceptions:
PSp(2, F2) ‚àº= S3, PSp(2, F3) ‚àº= A4, and PSp(4, F2) ‚àº= S6.
The orthogonal groups, that is, isometry groups of a symmetric space (V, f ) when f is
nondegenerate, also give rise to simple groups. In contrast to symplectic groups, however,
they depend on properties of the Ô¨Åeld k. We restrict our attention to Ô¨Ånite Ô¨Åelds k. The
cases when k has odd characteristic and when k has characteristic 2 must be considered
separately, and we must further consider the subcases when dim(V ) is odd or even. When
k has odd characteristic p, there is only one orthogonal group O(n, pm)15 when n is odd,
but there are two, O+(n, pm) and O‚àí(n, pm), when n is even. The simple groups are
deÔ¨Åned from these groups as follows: First form SOœµ(n, pm) (where œµ = + or œµ = ‚àí)
as all orthogonal matrices having determinant 1; next, form PSOœµ(n, pm) by dividing
by all scalar matrices in SOœµ(n, pm). Finally, we can deÔ¨Åne a subgroup $œµ(n, pm) of
PSOœµ(n, pm) (essentially the commutator subgroup), and these groups are simple with
only a Ô¨Ånite number of exceptions (which can be explicitly listed).
When k has characteristic 2, we usually begin with a quadratic form rather than a sym-
metric bilinear form. In this case, there is also only one orthogonal group O(n, 2m) when
n is odd, but there are two, which are also denoted by O+(n, 2m) and O‚àí(n, 2m), when n
is even. If n is odd, say, n = 2‚Ñì+1, then O(2‚Ñì+1, 2m) ‚àº= Sp(2‚Ñì, 2m), so that we consider
only orthogonal groups Oœµ(2‚Ñì, 2m) arising from symmetric spaces of even dimension.
Each of these groups gives rise to a simple group in a manner analogous to the odd char-
acteristic case. For more details, we refer the reader to the books of E. Artin, Geometric
Algebra; Conway et al, Atlas of Finite Groups; J; Dieudonn¬¥e, La G¬¥eometrie des groupes
15When k is a Ô¨Ånite Ô¨Åeld, say, k = Fq for some prime power q, we often denote GL(n, k) by GL(n, q). A
similar notational change is used for any of the matrix groups arising from GL(n, k).

Sec. 9.5
Bilinear Forms
713
classiques; M. Suzuki, Group Theory I; and the article by Carter in Kostrikin-Shafarevich,
Algebra IX.
Quadratic forms are of great importance in number theory. For an introduction to this
aspect of the subject, see Hahn, Quadratic Algebras, Clifford Algebras, and Arithmetic
Witt Groups; Lam, The Algebraic Theory of Quadratic Forms; and O'Meara, Introduction
to Quadratic Forms.
EXERCISES
9.51 It is shown in analytic geometry that if ‚Ñì1 and ‚Ñì2 are lines with slopes m1 and m2, respectively,
then ‚Ñì1 and ‚Ñì2 are perpendicular if and only if m1m2 = ‚àí1. If
‚Ñìi = {Œ±vi + ui : Œ± ‚ààR},
for i = 1, 2, prove that m1m2 = ‚àí1 if and only if the dot product v1 ¬∑ v2 = 0. (Since both
lines have slopes, neither of them is vertical.)
Hint. The slope of a vector v = (a, b) is m = b/a.
9.52
(i) In calculus, a line in space passing through a point u is deÔ¨Åned as
{u + Œ±w : Œ± ‚ààR} ‚äÜR3,
where w is a Ô¨Åxed nonzero vector. Show that every line through the origin is a one-
dimensional subspace of R3.
(ii) In calculus, a plane in space passing through a point u is deÔ¨Åned as the subset
{v ‚ààR3 : (v ‚àíu) ¬∑ n = 0} ‚äÜR3,
where n Ã∏= 0 is a Ô¨Åxed normal vector. Prove that a plane through the origin is a two-
dimensional subspace of R3.
Hint.
To determine the dimension of a plane through the origin, Ô¨Ånd an orthogonal
basis of R3 containing n.
9.53 If k is a Ô¨Åeld of characteristic not 2, prove that for every n √ó n matrix A with entries in k,
there are unique matrices B and C with B symmetric, C skew-symmetric (i.e., Ct = ‚àíC),
and A = B + C.
9.54 Let (V, f ) be an inner product space, where V is a vector space over a Ô¨Åeld k of characteristic
not 2. Prove that if f is both symmetric and alternating, then f = 0.
9.55 If (V, f ) is an inner product space, deÔ¨Åne u ‚ä•v to mean f (u, v) = 0. Prove that ‚ä•is a
symmetric relation if and only if f is either symmetric or alternating.
9.56 Let (V, f ) be an inner product space with f nondegenerate. If W is a proper subspace and
V = W ‚äïW ‚ä•, prove that f |(W ‚ä•√ó W ‚ä•) is nondegenerate.
9.57
(i) Let (V, f ) be an inner product space, where V is a vector space over a Ô¨Åeld k of char-
acteristic not 2. Prove that if f is symmetric, then there is a basis e1, . . . , en of V and
scalars c1, . . . , cn such that f (x, y) = 
i ci xi yi, where x =  xiei and y =  yiei.
Moreover, if f is nondegenerate and k has square roots, then the basis e1, . . . , en can
be chosen so that f (x, y) = 
i xi yi.
(ii) If k is a Ô¨Åeld of characteristic not 2, then every symmetric matrix A with entries in k is
congruent to a diagonal matrix. Moreover, if A is nonsingular and k has square roots,
then A = Pt P for some nonsingular matrix P.

714
Advanced Linear Algebra
Ch. 9
9.58 Give an example of two real symmetric m √ó m matrices having the same rank and the same
discriminant but that are not congruent.
9.59 For every Ô¨Åeld k, prove that Sp(2, k) = SL(2, k).
Hint.
By Corollary 9.80(ii), we know that if P ‚ààSp(2m, k), then det(P) = ¬±1. However,
Proposition 9.89 shows that det(P) = 1 for P ‚ààSp(2, k) [it is true, for all m ‚â•1, that
Sp(2m, k) ‚â§SL(2m, k)].
9.60 If A is an m √ó m matrix with At A = I, prove that
A
0
0
A

is a symplectic matrix. Conclude,
if k is a Ô¨Ånite Ô¨Åeld of odd characteristic, that O(m, k) ‚â§Sp(2m, k).
9.61 Let (V, f ) be an alternating space with f nondegenerate. Prove that T ‚ààGL(V ) is an isome-
try [i.e., T ‚ààSp(V, f )] if and only if, whenever E = x1, y1, . . . , xm, ym is a symplectic basis
of V , then T (E) = T x1, T y1, . . . , T xm, T ym is also a symplectic basis of V .
9.6 GRADED ALGEBRAS
We are now going to use tensor products of many modules in order to construct some
useful rings. This topic is often called multilinear algebra.
Throughout this section, R will denote a commutative ring.
DeÔ¨Ånition.
An R-algebra A is a graded R-algebra if there are R-submodules Ap, for
p ‚â•0, such that
(i) A = 
p‚â•0 Ap;
(ii) For all p, q ‚â•0, if x ‚ààAp and y ‚ààAq, then xy ‚ààAp+q; that is,
Ap Aq ‚äÜAp+q.
An element x ‚ààAp is called homogeneous of degree p.
Notice that 0 is homogeneous of any degree, but that most elements in a graded ring are
not homogeneous and, hence, have no degree. Note also that any product of homogeneous
elements is itself homogeneous.
Example 9.94.
(i) The polynomial ring A = R[x] is a graded R-algebra if we deÔ¨Åne
Ap = {rx p : r ‚ààR}.
The homogeneous elements are the monomials and, in contrast to ordinary usage, only
monomials (including 0) have degrees. On the other hand, x p has degree p in both usages
of the term degree.
(ii) The polynomial ring A = R[x1, x2, . . . , xn] is a graded R-algebra if we deÔ¨Åne
Ap =

rxe1
1 xe2
2 ¬∑ ¬∑ ¬∑ xen
n : r ‚ààR and

ei = p

;
that is, Ap consists of all monomials of total degree p.

Sec. 9.6
Graded Algebras
715
(iii) In algebraic topology, we assign a sequence of (abelian) cohomology groups H p(X, R)
to a space X, where R is a commutative ring and p ‚â•0, and we deÔ¨Åne a multiplication on

p‚â•0 H p(X, R), called cup product, making it a graded R-algebra.
‚óÄ
Just as the degree of a polynomial is often useful, so, too, is the degree of a homoge-
neous element in a graded algebra.
DeÔ¨Ånition.
If A and B are graded R-algebras, then a graded map16 is an R-algebra map
f : A ‚ÜíB with f (Ap) ‚äÜB p for all p ‚â•0.
It is easy to see that all graded R-algebras and graded maps form a category, which we
denote by GrRAlg.
DeÔ¨Ånition.
If A is a graded R-algebra, then a graded ideal (or homogeneous ideal) is a
two-sided ideal I in A with I = 
p‚â•0 I p, where I p = I ‚à©Ap.
In contrast to the afÔ¨Åne varieties that we have considered in Chapter 6, projective vari-
eties are studied more intensely in algebraic geometry. The algebraic way to study these
geometric objects involves homogeneous ideals in graded algebras.
Proposition 9.95.
Let A and B be graded R-algebras.
(i) If f : A ‚ÜíB is a graded map, then ker f is a graded ideal.
(ii) If I is a graded ideal in A, then A/I is a graded R-algebra if we deÔ¨Åne
(A/I)p = (Ap + I)/I.
Moreover, A/I = 
p(A/I)p ‚àº= 
p Ap/(I ‚à©Ap) = 
p(Ap/I p).
(iii) A two-sided ideal I in A is graded if and only if it is generated by homogeneous
elements.
(iv) The identity element 1 in A is homogeneous of degree 0.
Proof.
The proofs of (i) and (ii) are left as (routine) exercises.
(iii) If I is graded, then I = 
p I p, so that I is generated by !
p I p. But !
p I p
consists of homogeneous elements because I p = I ‚à©Ap ‚äÜAp for all p.
Conversely, suppose that I is generated by a set X of homogeneous elements. We must
show that I = 
p(I ‚à©Ap), and it is only necessary to prove I ‚äÜ
p(I ‚à©Ap), for the
reverse inclusion always holds. Since I is the two-sided ideal generated by X, a typical
element u ‚ààI has the form u = 
i ai xibi, where ai, bi ‚ààA and xi ‚ààX. Now u =

p u p, where u p ‚ààAp, and it sufÔ¨Åces to show that each u p lies in I. Indeed, it sufÔ¨Åces
to prove this for a single term ai xibi, and so we drop the subscript i. Since a =  a j and
b =  b‚Ñì, where each a j and b‚Ñìare homogeneous, we have u = 
j,‚Ñìa j xb‚Ñì; but each
16There is a more general deÔ¨Ånition of a graded map f : A ‚ÜíB. Given d ‚ààZ, then a k-algebra map f is
graded map of degree d if f (Ap) ‚äÜB p+d for all p ‚â•0.

716
Advanced Linear Algebra
Ch. 9
term in this sum is homogeneous, being the product of the homogeneous elements a j, x,
and b‚Ñì. Thus, u p is the sum of those a j xb‚Ñìhaving degree p, and so u p ‚ààI.
(iv) Write 1 = e0 + e1 + ¬∑ ¬∑ ¬∑ + et, where ei ‚ààAi. If ap ‚ààAp, then
ap ‚àíe0ap = e1ap + ¬∑ ¬∑ ¬∑ + etap ‚ààAp ‚à©(Ap+1 ‚äï¬∑ ¬∑ ¬∑ ‚äïAp+t) = {0}.
It follows that ap = e0ap for all homogeneous elements ap, and so a = e0a for all a ‚ààA.
A similar argument, examining ap = ap1 (instead of ap = 1ap), shows that a = ae0 for
all a ‚ààA. Therefore, 1 = e0, by the uniqueness of the identity element in a ring.
‚Ä¢
Example 9.96.
The quotient R[x]/(x13) is a graded R-algebra. However, there is no obvious grading on
the algebra R[x]/(x13 + 1). After all, what degree should be assigned to the coset of x13,
which is the same as the coset of ‚àí1?
‚óÄ
We now consider generalized associativity of tensor product.
DeÔ¨Ånition.
Let R be a commutative ring and let M1, . . . , Mp be R-modules. An R-
multilinear function f : M1 √ó ¬∑ ¬∑ ¬∑ √ó Mp ‚ÜíN, where N is an R-module, is a function
that is additive in each of the p variables (when we Ô¨Åx the other p ‚àí1 variables) and if
1 ‚â§i ‚â§p, then
f (m1, . . . ,rmi, . . . , m p) = r f (m1, . . . , mi, . . . , m p),
where r ‚ààR and m‚Ñì‚ààM‚Ñìfor all ‚Ñì.
Proposition 9.97.
Let R be a commutative ring and let M1, . . . , Mp be R-modules.
(i) There exists an R-module U[M1, . . . , Mp] that is a solution to the universal map-
ping problem posed by multilinearity:
M1 √ó ¬∑ ¬∑ ¬∑ √ó Mp
h

f
*'
'
'
'
'
'
'
'
'
'
'
U[M1, . . . , Mp]
f
+
N
There is a R-multilinear h such that, if f is R-multilinear, then there exists a unique
R-homomorphism f making the diagram commute.
(ii) If fi : Mi ‚ÜíM‚Ä≤
i are R-maps, then there is a unique R-map
u[ f1, ¬∑ ¬∑ ¬∑ , f p]: U[M1, . . . , Mp] ‚ÜíU[M‚Ä≤
1, . . . , M‚Ä≤
p]
taking h(m1, . . . , m p) ‚Üíh‚Ä≤( f1(m1), . . . , f p(m p)), where h‚Ä≤ : M‚Ä≤
1 √ó ¬∑ ¬∑ ¬∑ √ó M‚Ä≤
p ‚Üí
U[M‚Ä≤
1, . . . , M‚Ä≤
p].

Sec. 9.6
Graded Algebras
717
Proof.
(i) This is a straightforward generalization of Theorem 8.74, the existence of
tensor products, using multilinear functions instead of bilinear ones. Let F be the free
R-module with basis M1 √ó ¬∑ ¬∑ ¬∑ √ó Mp, and let S be the submodule of F generated by all
elements of the following two types:
(m1, . . . , mi + m‚Ä≤
i, . . . , m p) ‚àí(m1, . . . , mi, . . . , m p) ‚àí(m1, . . . , m‚Ä≤
i, . . . , m p);
(m1, . . . ,rmi, . . . , m p) ‚àír(m1, . . . , mi, . . . , m p),
where mi, m‚Ä≤
i ‚ààMi, r ‚ààR, and 1 ‚â§i ‚â§p.
DeÔ¨Åne U[M1, ¬∑ ¬∑ ¬∑ , Mp] = F/S and deÔ¨Åne h : M1 √ó ¬∑ ¬∑ ¬∑ √ó Mp ‚ÜíU[M1, ¬∑ ¬∑ ¬∑ , Mp] by
h : (m1, . . . , m p) ‚Üí(m1, . . . , m p) + S.
The reader should check that h is R-multilinear. The remainder of the proof is merely an
adaptation of the proof of Proposition 8.74, and it is also left to the reader.
(ii) The function M1 √ó ¬∑ ¬∑ ¬∑ √ó Mp ‚ÜíU[M‚Ä≤
1, . . . , M‚Ä≤
p], given by
(m1, . . . , m p) ‚Üíh‚Ä≤( f1(m1), . . . , fn(m p)),
is easily seen to be R-multilinear, and hence there exists a unique R-homomorphism as
described in the statement.
‚Ä¢
Observe that there are no parentheses needed in the generator h(m1, . . . , m p); that is,
h(m1, . . . , m p) depends only on the p-tuple (m1, . . . , m p) and not on any association of
its coordinates. The next proposition relates this construction to iterated tensor products.
Once this is done, we will change the notation U[M1, . . . , Mp].
Proposition 9.98 (Generalized Associativity).
Let R be a commutative ring and let
M1, . . . , Mp be R-modules. If M1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mp is an iterated tensor product in some
association, then there is an R-isomorphism U[M1, . . . , Mp] ‚ÜíM1 ‚äóR ¬∑ ¬∑ ¬∑‚äóR Mp taking
h(m1, . . . , m p) ‚Üím1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p.
Remark.
We are tempted to quote Theorem 2.20: Associativity for three factors implies
associativity for many factors, for we have proved the associative law for three factors in
Proposition 8.84. However, we did not prove equality, A ‚äóR (B ‚äóR C) = (A ‚äóR B)‚äóR C;
we only constructed an isomorphism. There is an extra condition, due, independently, to
Mac Lane and Stasheff: If the associative law holds up to isomorphism and if a certain
"pentagonal" diagram commutes, then generalized associativity holds up to isomorphism
(see Mac Lane, Categories for the Working Mathematician, pages 157-161).
‚óÄ
Proof.
The proof is by induction on p ‚â•2. The base step is true, for U[M1, M2] =
M1 ‚äóR M2. For the inductive step, let us assume that
M1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mp = U[M1, . . . , Mi] ‚äóR U[Mi+1, . . . , Mp].

718
Advanced Linear Algebra
Ch. 9
We have indicated the Ô¨Ånal factors in the association; for example,
((M1 ‚äóR M2) ‚äóR M3) ‚äóR (M4 ‚äóR M5) = U[M1, M2, M3] ‚äóR U[M4, M5].
By induction, there are multilinear functions h‚Ä≤ : M1 √ó ¬∑ ¬∑ ¬∑ √ó Mi ‚ÜíM1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mi and
h‚Ä≤‚Ä≤ : Mi+1 √ó ¬∑ ¬∑ ¬∑ √ó Mp ‚ÜíMi+1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mp with h‚Ä≤(m1, . . . , mi) = m1 ‚äó¬∑ ¬∑ ¬∑ ‚äómi
associated as in M1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mi, and with h‚Ä≤‚Ä≤(mi+1, . . . , m p) = mi+1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p
associated as in Mi+1‚äóR¬∑ ¬∑ ¬∑‚äóR Mp. Induction gives isomorphisms œï‚Ä≤ : U[M1, . . . , Mi] ‚Üí
M1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mi and œï‚Ä≤‚Ä≤ : U[Mi+1, . . . , Mp] ‚ÜíMi+1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mp with œï‚Ä≤h‚Ä≤ =
h|(M1 √ó ¬∑ ¬∑ ¬∑ √ó Mi) and œï‚Ä≤‚Ä≤h‚Ä≤‚Ä≤ = h|(Mi+1 √ó ¬∑ ¬∑ ¬∑ √ó Mp). By Corollary 8.78, œï‚Ä≤ ‚äóœï‚Ä≤‚Ä≤ is an
isomorphism U[M1, . . . , Mi] ‚äóR U[Mi+1, . . . , Mp] ‚ÜíM1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mp.
We now show that U[M1, . . . , Mi] ‚äóR U[Mi+1, . . . , Mp] is a solution to the universal
problem for multilinear functions. Consider the diagram
M1 √ó ¬∑ ¬∑ ¬∑ √ó Mp
Œ∑

f
*'
'
'
'
'
'
'
'
'
'
'
U[M1, . . . , Mi] ‚äóR U[Mi+1, . . . , Mp]
f
,
N
where Œ∑(m1, . . . , m p) = h‚Ä≤(m1, . . . , mi) ‚äóh‚Ä≤‚Ä≤(mi+1, . . . , m p), N is an R-module, and f
is multilinear. We must Ô¨Ånd a homomorphism f making the diagram commute.
If (m1, . . . , mi) ‚ààM1 √ó ¬∑ ¬∑ ¬∑ √ó Mi, the function f(m1,...,mi) : Mi+1 √ó ¬∑ ¬∑ ¬∑ √ó Mp ‚ÜíN,
deÔ¨Åned by (mi+1, . . . , m p) ‚Üíf (m1, . . . , mi, h‚Ä≤‚Ä≤(mi+1, . . . , m p)), is multilinear; hence,
there is a unique homomorphism f(m1,...,mi) : U[Mi+1, . . . , Mp] ‚ÜíN with
f(m1,...,mi) : h‚Ä≤‚Ä≤(mi+1, . . . , m p) ‚Üíf (m1, . . . , m p).
If r ‚ààR and 1 ‚â§j ‚â§i, then
f(m1,...,rm j,...,mi)(h‚Ä≤‚Ä≤(mi+1, . . . , m p)) = f (m1, . . . ,rm j, . . . , m p)
= r f (m1, . . . , m j, . . . , mi)
= r f(m1,...,mi)(h‚Ä≤‚Ä≤(mi+1, . . . , m p)).
Similarly, if m j, m‚Ä≤
j ‚ààM j, where 1 ‚â§j ‚â§i, then
f(m1,...,m j+m‚Ä≤
j,...,mi) = f(m1,...,m j,...,mi) + f(m1,...,m‚Ä≤
j,...,mi).
The function of i + 1 variables M1 √ó ¬∑ ¬∑ ¬∑ √ó Mi √ó U[Mi+1, . . . , Mp] ‚Üí
N, deÔ¨Åned
by (m1, . . . , mi, u‚Ä≤‚Ä≤) ‚Üíf(m1,...,mi)(u‚Ä≤‚Ä≤), is multilinear, and so it gives a bilinear func-
tion U[M1, . . . , Mi] √ó U[Mi+1, . . . , Mp] ‚ÜíN, namely, (u‚Ä≤, u‚Ä≤‚Ä≤) ‚Üí(h‚Ä≤(u‚Ä≤), h‚Ä≤‚Ä≤(u‚Ä≤‚Ä≤)).
Thus, there is a unique homomorphism f : U[M1, . . . , Mi] ‚äóR U[Mi+1, . . . , Mp] ‚ÜíN
which takes h‚Ä≤(m1, . . . , mi) ‚äóh‚Ä≤‚Ä≤(mi+1, . . . , m p)
‚Üí
f(m1,...,mi)(h‚Ä≤‚Ä≤(mi+1, . . . , m p))
= f (m1, . . . , m p); that is, f Œ∑ = f . Therefore, U[M1, . . . , Mi] ‚äóR U[Mi+1, . . . , Mp]
is a solution to the universal mapping problem. By uniqueness of such solutions, there
is an isomorphism Œ∏ : U[M1, . . . , Mp] ‚ÜíU[M1, . . . , Mi] ‚äóR U[Mi+1, . . . , Mp] with
Œ∏h(m1, . . . , m p) = h‚Ä≤(m1, . . . , mi) ‚äóh‚Ä≤‚Ä≤(mi+1, . . . , m p) = Œ∑(m1, . . . , m p).
Finally,
(œï‚Ä≤ ‚äóœï‚Ä≤‚Ä≤)Œ∏ is the desired isomorphism U[M1, . . . , Mp] ‚àº= M1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mp.
‚Ä¢

Sec. 9.6
Graded Algebras
719
We now abandon the notation in Proposition 9.97; from now on, we shall write
U[M1, . . . , Mp] = M1 ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR Mp,
h(m1, . . . , m p) = m1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p,
u[ f1, . . . , f p] = f1 ‚äó¬∑ ¬∑ ¬∑ ‚äóf p.
Proposition 9.99.
If R is a commutative ring and A and B are R-algebras, then the
tensor product A ‚äóR B is an R-algebra if we deÔ¨Åne (a ‚äób)(a‚Ä≤ ‚äób‚Ä≤) = aa‚Ä≤ ‚äóbb‚Ä≤.
Proof.
First, A ‚äóR B is an R-module, by Corollary 8.81. Let ¬µ: A √ó A ‚ÜíA and
ŒΩ : B √ó B ‚ÜíB be the given multiplications on the algebras A and B, respectively. We
must show there is a multiplication on A ‚äóR B as in the statement; that is, there is an R-
bilinear function Œª: (A‚äóR B)√ó(A‚äóR B) ‚ÜíA‚äóR B with Œª: (a‚äób, a‚Ä≤‚äób‚Ä≤) ‚Üíaa‚Ä≤‚äóbb‚Ä≤.
Such a function Œª exists because it is the composite
(A ‚äóR B) √ó (A ‚äóR B) ‚Üí(A ‚äóR B) ‚äó(A ‚äóR B)
‚Üí(A ‚äóR A) √ó (B ‚äóR B)
‚ÜíA ‚äóR B :
the Ô¨Årst function is (a ‚äób, a‚Ä≤ ‚äób‚Ä≤) ‚Üía ‚äób ‚äóa‚Ä≤ ‚äób‚Ä≤ (which is the bilinear function in
Proposition 8.82); the second is 1‚äóœÑ ‚äó1, where œÑ : B‚äóR A ‚ÜíA‚äóR B takes b‚äóa ‚Üía‚äób
(which exists by Propositions 8.83 and 9.98); the third is ¬µ ‚äóŒΩ. It is now routine to check
that the R-module A ‚äóR B is an R-algebra.
‚Ä¢
Example 9.100.
In Exercise 8.48 on page 604, we saw that there is an isomorphism of abelian groups:
Im ‚äóIn ‚àº= Id, where d = (m, n). It follows that if (m, n) = 1, then Im ‚äóIn = {0}. Of
course, this tensor product is still {0} if we regard Im and In as Z-algebras. Thus, in this
case, the tensor product is the zero ring. Had we insisted, in the deÔ¨Ånition of ring, that
1 Ã∏= 0, then the tensor product of rings would not always be deÔ¨Åned.
‚óÄ
We now show that the tensor product of algebras is an "honest" construction.
Proposition 9.101.
If R is a commutative ring and A and B are commutative R-algebras,
then A ‚äóR B is the coproduct in the category of commutative R-algebras.
Proof.
DeÔ¨Åne œÅ : A ‚ÜíA ‚äóR B by œÅ : a ‚Üía ‚äó1, and deÔ¨Åne œÉ : B ‚ÜíA ‚äóR B by
œÉ : b ‚Üí1 ‚äób. Let X be a commutative R-algebra, and consider the diagram
A
œÅ

f








A ‚äóR B

 X
B
œÉ
-
g










720
Advanced Linear Algebra
Ch. 9
where f and g are R-algebra maps. The function œï : A √ó B ‚ÜíX, given by (a, b) ‚Üí
f (a)g(b), is easily seen to be R-bilinear, and so there is a unique map of R-modules
: A ‚äóR B ‚ÜíX with (a ‚äób) = f (a)g(b). It remains to prove that  is an R-algebra
map, for which it sufÔ¨Åces to prove that 

(a ‚äób)(a‚Ä≤ ‚äób‚Ä≤)

= (a ‚äób)(a‚Ä≤ ‚äób‚Ä≤). Now


(a ‚äób)(a‚Ä≤ ‚äób‚Ä≤)

= (aa‚Ä≤ ‚äóbb‚Ä≤)
= f (a) f (a‚Ä≤)g(b)g(b‚Ä≤).
On the other hand, (a ‚äób)(a‚Ä≤ ‚äób‚Ä≤) = f (a)g(b) f (a‚Ä≤)g(b‚Ä≤). Since X is commutative,
 does preserve multiplication.
‚Ä¢
Bimodules can be viewed as left modules over a suitable ring.
Corollary 9.102.
Let R and S be k-algebras, where k is a commutative ring. Every
(R, S)-bimodule M is a left R ‚äók Sop-module, where
(r ‚äós)m = rms.
Proof.
The function R √ó Sop √ó M ‚ÜíM, given by (r, s, m) ‚Üírms, is k-trilinear, and
this can be used to prove that (r ‚äós)m = rms is well-deÔ¨Åned. Let us write s ‚àós‚Ä≤ for the
product in Sop; that is, s ‚àós‚Ä≤ = s‚Ä≤s. The only axiom that is not obvious is axiom (iii) in
the deÔ¨Ånition of module: If a, a‚Ä≤ ‚ààR ‚äók Sop, then (aa‚Ä≤)m = a(a‚Ä≤m), and it is enough to
check that this is true for generators a = r ‚äós and a‚Ä≤ = r‚Ä≤ ‚äós‚Ä≤ of R ‚äók Sop. But
[(r ‚äós)(r‚Ä≤ ‚äós‚Ä≤)]m = [rr‚Ä≤ ‚äós ‚àós‚Ä≤]m
= (rr‚Ä≤)m(s ‚àós‚Ä≤)
= (rr‚Ä≤)m(s‚Ä≤s)
= r(r‚Ä≤ms‚Ä≤)s.
On the other hand,
(r ‚äós)[(r‚Ä≤ ‚äós‚Ä≤)m] = (r ‚äós)[r‚Ä≤(ms‚Ä≤)] = r(r‚Ä≤ms‚Ä≤)s.
‚Ä¢
DeÔ¨Ånition.
If k is a commutative ring and A is a k-algebra, then its enveloping algebra
is
Ae = A ‚äók Aop.
Corollary 9.103.
If k is a commutative ring and A is a k-algebra, then A is a left Ae-
module whose submodules are the two-sided ideals. If A is a simple k-algebra, then A is a
simple Ae-module.
Proof.
Since a k-algebra A is an (A, A)-bimodule, it is a left Ae-module.
‚Ä¢

Sec. 9.6
Graded Algebras
721
Proposition 9.104.
If k is a commutative ring and A is a k-algebra, then
EndAe(A) ‚àº= Z(A).
Proof.
If f : A ‚ÜíA is an Ae-map, then it is a map of A viewed only as a left A-
module. Proposition 8.12 applies to say that f is determined by z = f (1), because f (a) =
f (a1) = af (1) = az for all a ‚ààA. On the other hand, since f is also a map of A viewed as
a right A-module, we have f (a) = f (1a) = f (1)a = za. Therefore, z = f (1) ‚ààZ(A);
that is, the map œï : f ‚Üíf (1) is a map EndAe(A) ‚ÜíZ(A). The map œï is surjective, for if
z ‚ààZ(A), then f (a) = za is an Ae-endomorphism with œï( f ) = z; the map œï is injective,
for if f ‚ààEndAe(A) and f (1) = 0, then f = 0.
‚Ä¢
We now construct the tensor algebra on an R-module M. When M is a free R-module
with basis X, then the tensor algebra will be seen to be the free R-algebra with basis X;
that is, it is the polynomial ring over R in noncommuting variables X.
DeÔ¨Ånition.
Let R be a commutative ring, and let M be an R-module. DeÔ¨Åne
T 0(M) = R,
T 1(M) = M,
T p(M) = M ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR M
(p times)
if p ‚â•2.
Remark.
Many authors denote T p(M) by :p M. In Proposition 9.97, T p(M) was orig-
inally denoted by U[M1, . . . , Mp] (here, all Mi = M), and we later replaced this notation
by M1 ‚äó¬∑ ¬∑ ¬∑ ‚äóMp, for this is easier to remember. We remind the reader that T p(M),
however it is denoted, is generated by symbols m1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p in which no parentheses
occur.
‚óÄ
Proposition 9.105.
If M is an R-module, then there is a graded R-algebra
T (M) =

p‚â•0
T p(M)
with the action of r ‚ààR on T q(M) given by
r(y1 ‚äó¬∑ ¬∑ ¬∑ ‚äóyq) = (ry1) ‚äóy2 ‚äó¬∑ ¬∑ ¬∑ ‚äóyq = (y1 ‚äó¬∑ ¬∑ ¬∑ ‚äóyq)r,
and with the multiplication T p(M) √ó T q(M) ‚ÜíT p+q(M), for p, q ‚â•1, given by
(x1 ‚äó¬∑ ¬∑ ¬∑ ‚äóx p, y1 ‚äó¬∑ ¬∑ ¬∑ ‚äóyq) ‚Üíx1 ‚äó¬∑ ¬∑ ¬∑ ‚äóx p ‚äóy1 ‚äó¬∑ ¬∑ ¬∑ ‚äóyq.
Proof.
First, deÔ¨Åne the product of two homogeneous elements by the formulas in the
statement. Multiplication ¬µ: T (M) √ó T (M) ‚ÜíT (M) must now be
¬µ:

p
x p,

q
yq

‚Üí

p,q
x p ‚äóyq,

722
Advanced Linear Algebra
Ch. 9
where x p ‚ààT p(M) and yq ‚ààT q(M). Multiplication is associative because no parentheses
are needed in describing generators m1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p of T p(M), and the distributive laws
hold because multiplication is R-bilinear. Finally, 1 ‚ààk = T 0(M) is the identity, each
element of R commutes with every element of T (M), and T p(M)T q(M) ‚äÜT p+q(M), so
that T (M) is a graded R-algebra.
‚Ä¢
The reader may check that if M = R, then T (M) ‚àº= R[x].
DeÔ¨Ånition.
If R is a commutative ring and M is an R-module, then T (M) is called the
tensor algebra on M.
If R is a commutative ring and A and B are R-modules, deÔ¨Åne a word of length p ‚â•0
on A and B to be an R-module of the form
W(A, B)p = T e1(A) ‚äóR T f1(B) ‚äóR ¬∑ ¬∑ ¬∑ ‚äóR T er (A) ‚äóR T fr (B),
where 
i(ei + fi) = p, all ei, fi are integers, e1 ‚â•0, fr ‚â•0, and all the other exponents
are positive.
Proposition 9.106.
If A and B are R-modules, then for all p ‚â•0,
T p(A ‚äïB) ‚àº=
p

j=0
W(A, B) j ‚äóR W ‚Ä≤(A, B)p‚àíj,
where W(A, B) j, W ‚Ä≤(A, B)p‚àíj range over all words of length j and p ‚àíj, respectively.
Proof.
The proof is by induction on p ‚â•0. For the base step,
T 0(A ‚äïB) = R ‚àº= R ‚äóR R ‚àº= T 0(A) ‚äóR T 0(B).
For the inductive step,
T p+1(A ‚äïB) = T p(A ‚äïB) ‚äóR (A ‚äïB)
‚àº=

T p(A ‚äïB) ‚äóR A

‚äï

T p(A ‚äïB) ‚äóR B

‚àº=
p

j=0
W(A, B) j ‚äóR W ‚Ä≤(A, B)p‚àíj ‚äóR X,
where X ‚àº= A or X ‚àº= B. This completes the proof, for every word of length p ‚àíj + 1 has
the form W ‚Ä≤(A, B) ‚äóR X.
‚Ä¢

Sec. 9.6
Graded Algebras
723
Proposition 9.107.
Tensor algebra deÔ¨Ånes a functor T : RMod ‚ÜíGrRAlg. Moreover,
T preserves surjections.
Proof.
We have already deÔ¨Åned T on every R-module M: it is the tensor algebra T (M).
If f : M ‚ÜíN is an R-homomorphism, then Proposition 9.97 provides maps
f ‚äó¬∑ ¬∑ ¬∑ ‚äóf : T p(M) ‚ÜíT p(N),
for each p, which give an R-algebra map T (M) ‚ÜíT (N). It is a simple matter to check
that T preserves identity maps and composites.
Assume that f : M ‚ÜíN is a surjective R-map. If n1 ‚äó¬∑ ¬∑ ¬∑ ‚äón p ‚ààT p(N), then
surjectivity of f provides mi ‚ààM, for all i, with f (mi) = ni, and so
T ( f ): m1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p ‚Üín1 ‚äó¬∑ ¬∑ ¬∑ ‚äón p.
‚Ä¢
We now generalize the notion of free module to free algebra.
DeÔ¨Ånition.
If X is a subset of an R-algebra F, then F is a free R-algebra with basis X
if, for every R-algebra A and every function œï : X ‚ÜíA, there exists a unique R-algebra
map œï with œï(x) = œï(x) for all x ‚ààX. In other words, the following diagram commutes,
where i : X ‚ÜíF is the inclusion.
F
œï

X
i

œï
 A
In the next proposition, we regard the graded R-algebra T (V ) merely as an R-algebra.
Proposition 9.108.
If V is a free R-module with basis X, where R is a commutative ring,
then T (V ) is a free R-algebra with basis X.
Proof.
Consider the diagram
T (V )
T (œï)

V
j

œï

T (A)
¬µ

X
i

œï
 A,
where i : X ‚ÜíV and j : V ‚ÜíT (V ) are inclusions, and A is an R-algebra. Viewing A
only as an R-module gives an R-module map œï : V ‚ÜíA, for V is a free R-module

724
Advanced Linear Algebra
Ch. 9
with basis X. Applying the functor T gives an R-algebra map T (œï): T (V ) ‚ÜíT (A).
For existence of an R-algebra map T (V ) ‚ÜíA, it sufÔ¨Åces to deÔ¨Åne an R-algebra map
¬µ: T (A) ‚ÜíA such that the composite ¬µ ‚ó¶T (œï) is an R-algebra map extending œï. For
each p, consider the diagram
A √ó ¬∑ ¬∑ ¬∑ √ó A
h p

m p
*'
'
'
'
'
'
'
'
'
'
'
'
T p(A)
¬µp

A,
where h p : (a1, . . . , ap) ‚Üía1 ‚äó¬∑ ¬∑ ¬∑ ‚äóap and m p : (a1, . . . , ap) ‚Üía1 ¬∑ ¬∑ ¬∑ ap, the latter
being the product of the elements a1, . . . , ap in the R-algebra A. Of course, m p is R-
multilinear, and so it induces an R-map ¬µp making the diagram commute. Now deÔ¨Åne
¬µ: T (A) ‚ÜíA by ¬µ = 
p ¬µp. To see that ¬µ is multiplicative, it sufÔ¨Åces to show
¬µp+q

(a1 ‚äó¬∑ ¬∑ ¬∑ ‚äóap) ‚äó(a‚Ä≤
1 ‚äó¬∑ ¬∑ ¬∑ ‚äóa‚Ä≤
q)

= ¬µp(a1 ‚äó¬∑ ¬∑ ¬∑ ‚äóap)¬µq(a‚Ä≤
1 ‚äó¬∑ ¬∑ ¬∑ ‚äóa‚Ä≤
q).
But this equation follows from the associative law in A:
(a1 ¬∑ ¬∑ ¬∑ ap)(a‚Ä≤
1 ¬∑ ¬∑ ¬∑ a‚Ä≤
q) = a1 ¬∑ ¬∑ ¬∑ apa‚Ä≤
1 ¬∑ ¬∑ ¬∑ a‚Ä≤
q.
Finally, uniqueness of this R-algebra map follows from V generating T (V ) as an R-algebra
[after all, every homogeneous element in T (V ) is a product of elements of degree 1].
‚Ä¢
Corollary 9.109.
Let R be a commutative ring.
(i) If A is an R-algebra, then there is a surjective R-algebra map T (A) ‚ÜíA.
(ii) Every R-algebra A is a quotient of a free R-algebra.
Proof.
(i) Regard A only as an R-module. For each p ‚â•2, multiplication Ap ‚ÜíA is
R-multilinear, and so there is a unique R-module map T p(A) ‚ÜíA. But these maps may
be assembled to give an R-module map T (A) = 
p T p(A) ‚ÜíA. This map is surjective,
because A has a unit 1, and it is easily seen to be a map of R-algebras; that is, it preserves
multiplication.
(ii) Let V be a free R-module for which there exists a surjective R-map œï : V ‚ÜíA. By
Proposition 9.107, the induced map T (œï): T (V ) ‚ÜíT (A) is surjective. Now T (V ) is
a free R-algebra, and if we compose T (œï) with the surjection T (A) ‚ÜíA, then A is a
quotient of T (V ).
‚Ä¢
DeÔ¨Ånition.
If R is a commutative ring and V is a free R-module with basis X, then T (V )
is called the ring of polynomials over R in noncommuting variables X, and it is denoted
by R‚ü®X‚ü©.

Sec. 9.6
Graded Algebras
725
If V is the free R-module with basis X, then each element u in T (V ) has a unique
expression
u =

p‚â•0
i1,...,i p
ri1,...,i pxi1 ‚äó¬∑ ¬∑ ¬∑ ‚äóxi p,
where ri1,...,i p ‚ààR and xi j ‚ààX. We obtain the usual notation for such a polynomial by
erasing the tensor product symbols. For example, if X = {x, y}, then
u = r0 + r1x + r2y + r3x2 + r4y2 + r5xy + r6yx + ¬∑ ¬∑ ¬∑ .
Example 9.110.
Just as for modules, we can now construct rings (Z-algebras) by generators and relations.
The Ô¨Årst example of a ring that is left noetherian but not right noetherian was given by J.
Dieudonn¬¥e; it is the ring R generated by elements x and y satisfying the relations yx = 0
and y2 = 0. The existence of the ring R is now easy: Let V be the free abelian group
with basis u, v, let R =

p‚â•0 T p(V )

/I, where I is the two-sided ideal generated by
vu and v2, and set x = u + I and y = v + I. Note that since the ideal I is generated by
homogeneous elements of degree 2, we have T 1(V ) = V ‚à©I = {0}, and so x Ã∏= 0 and
y Ã∏= 0.
‚óÄ
We now mention a class of rings generalizing commutative rings.
DeÔ¨Ånition.
If k is a Ô¨Åeld,17 then a polynomial identity on a k-algebra A is an element
f (X) ‚ààk‚ü®X‚ü©(the ring of polynomials over k in noncommuting variables X) all of whose
substitutions in A are 0.
For example, if f (x, y) = xy ‚àíyx ‚ààk‚ü®x, y‚ü©, then f is a polynomial identity on a
k-algebra A if ab ‚àíba = 0 for all a, b ‚ààA; that is, A is commutative.
Here is a precise deÔ¨Ånition. Every function œï : X ‚ÜíA extends to a k-algebra map
œï : k‚ü®X‚ü©‚ÜíA, and f (X) is a polynomial identity on A if and only if f (X) ‚àà
œï ker œï
for all functions œï : X ‚ÜíA.
DeÔ¨Ånition.
A k-algebra A is a PI-algebra (an algebra satisfying a polynomial identity)
if A satisÔ¨Åes some identity at least one of whose coefÔ¨Åcients is 1.
Every k-algebra generated by n elements satisÔ¨Åes the standard identity
sn+1(x1, . . . , xn+1) =

œÉ‚ààSn+1
sgn(œÉ)xœÉ(1) ¬∑ ¬∑ ¬∑ xœÉ(n+1).
We can prove that the matrix algebra Matn(k) satisÔ¨Åes the standard identity sn2+1, and
S. A. Amitsur and J. Levitzki proved that Matn(k) satisÔ¨Åes s2n; moreover, 2n is the lowest
possible degree of such a polynomial identity. There is a short proof of this due to S.
Rosset, "A New Proof of the Amitsur-Levitski Identity," Israel Journal of Mathematics 23,
1976, pages 187-188.
17We could, of course, extend these deÔ¨Ånitions by allowing k to be a commutative ring.

726
Advanced Linear Algebra
Ch. 9
DeÔ¨Ånition.
A central polynomial identity on a k-algebra A is a polynomial identity
f (X) ‚ààk‚ü®X‚ü©on A all of whose values f (a1, a2, . . .) (as the ai vary over all elements of
A) lie in Z(A).
It was proved, independently, by E. Formanek and Yu. P. Razmyslov, that Matn(k)
satisÔ¨Åes a central polynomial identity.
There are theorems showing, in several respects, that PI-algebras behave like commu-
tative algebras. For example, recall that a ring R is primitive if it has a faithful simple left
R-module; if R is commutative, then R is a Ô¨Åeld. I. Kaplansky proved that every primi-
tive quotient of a PI-algebra is simple and Ô¨Ånite-dimensional over its center. The reader is
referred to Procesi, Rings with Polynomial Identities.
Another interesting area of current research involves noncommutative algebraic geom-
etry. In essence, this involves the study of varieties now deÔ¨Åned as zeros of ideals in
k‚ü®x1, . . . , xn‚ü©instead of in k[x1, . . . , xn].
EXERCISES
9.62
(i) If k is a subÔ¨Åeld of a Ô¨Åeld K, prove that the ring K ‚äók k[x] is isomorphic to K[x].
(ii) Suppose that k is a Ô¨Åeld, p(x) ‚ààk[x] is irreducible, and K = k(Œ±), where Œ± is a root of
p(x). Prove that, as rings, K ‚äók K ‚àº= K[x]/(p(x)), where (p(x)) is the principal ideal
in K[x] generated by p(x).
(iii) The polynomial p(x), though irreducible in k[x], may factor in K[x]. Give an example
showing that the ring K ‚äók K need not be semisimple.
(iv) Prove that if K/k is a Ô¨Ånite separable extension, then K ‚äók K is semisimple. (The
converse is also true.)
9.63 Let m and n be positive integers, and let d = gcd(m, n). Prove that Im ‚äóZ In ‚àº= Id as
commutative rings.
Hint. See Exercise 8.48 on page 604.
9.64 If A ‚àº= A‚Ä≤ and B ‚àº= B‚Ä≤ are k-algebras, where k is a commutative ring, prove that A ‚äók B ‚àº=
A‚Ä≤ ‚äók B‚Ä≤ as k-algebras.
9.65 If k is a commutative ring and A and B are k-algebras, prove that
(A ‚äók B)op ‚àº= Aop ‚äók Bop.
9.66 If R is a commutative k-algebra, where k is a Ô¨Åeld, and if G is a group, prove that R ‚äók kG ‚àº=
RG.
9.67
(i) If k is a subring of a commutative ring R, prove that R ‚äók k[x]
‚àº=
R[x] as
R-algebras.
(ii) If f (x) ‚ààk[x] and ( f ) is the principal ideal in k[x] generated by f (x), prove that
R ‚äók ( f ) is the principal ideal in R[x] generated by f (x). More precisely, there is a
commutative diagram
0
 E ‚äók ( f )


E ‚äók k[x]

0
 ( f )E
 E[x]

Sec. 9.7
Division Algebras
727
(iii) Let k be a Ô¨Åeld and E ‚àº= k[x]/( f ), where f (x) ‚ààk[x] is irreducible. Prove that
E ‚äók E ‚àº= E[x]/( f )E, where ( f )E is the principal ideal in E[x] generated by f (x).
(iv) Give an example of a Ô¨Åeld extension E/k with E ‚äók E not a Ô¨Åeld.
Hint. If f (x) ‚ààk[x] factors into g(x)h(x) in E[x], where (g, h) = 1, then the Chinese
remainder theorem applies.
9.68 Let k be a Ô¨Åeld and let f (x) ‚ààk[x] be irreducible. If K/k is a Ô¨Åeld extension, then f (x) =
p1(x)e1 ¬∑ ¬∑ ¬∑ pn(x)en ‚ààK[x], where the pi(x) are distinct irreducible polynomials in K[x] and
ei ‚â•1.
(i) Prove that f (x) is separable if and only if all ei = 1.
(ii) Prove that a Ô¨Ånite Ô¨Åeld extension K/k is separable if and only if K ‚äók K is a semisimple
ring.
Hint.
First, observe that K/k is a simple extension, so there is an exact sequence
0 ‚Üí( f ) ‚Üík[x] ‚ÜíK ‚Üí0. Second, use the Chinese remainder theorem.
9.69 Prove that the ring R in Example 9.110 is left noetherian but not right noetherian.
Hint. See Cartan and Eilenberg, Homological Algebra, p. 16.
9.70 If G is a group, then a k-algebra A is called G-graded if there are k-submodules Ag, for all
g ‚ààG, such that
(i) A = 
g‚ààG Ag;
(ii) For all g, h ‚ààG, Ag Ah ‚äÜAgh.
An I2-graded algebra is called a superalgebra. If A is a G-graded algebra and e is the identity
element of G, prove that 1 ‚ààAe.
9.71 If A is a k-algebra generated by n elements, prove that A satisÔ¨Åes the standard identity deÔ¨Åned
on page 725.
9.7 DIVISION ALGEBRAS
That the tensor product of algebras is, again, an algebra, is used in the study of division
rings.
DeÔ¨Ånition.
A division algebra over a Ô¨Åeld k is a division ring regarded as an algebra over
its center k.
Let us begin by considering the wider class of simple algebras.
DeÔ¨Ånition.
A k-algebra A over a Ô¨Åeld k is central simple if it is Ô¨Ånite-dimensional,18
simple (no two-sided ideals other than A and {0}), and its center Z(A) = k.
Notation. If A is an algebra over a Ô¨Åeld k, then we write
[A : k] = dimk(A).
18Some authors do not assume Ô¨Ånite-dimensionality.

728
Advanced Linear Algebra
Ch. 9
Example 9.111.
(i) Every division algebra  that is Ô¨Ånite-dimensional over its center k is a central simple
k-algebra. The quaternions H is a central simple R-algebra, and every Ô¨Åeld is a central
simple algebra over itself. Hilbert gave an example of an inÔ¨Ånite-dimensional division
algebra (see Drozd-Kirichenko, Finite Dimensional Algebras, page 81).
(ii) If k is a Ô¨Åeld, then Matn(k) is a central simple k-algebra.
(iii) If A is a central simple k-algebra, then its opposite algebra Aop is also a central simple
k-algebra.
‚óÄ
Theorem 9.112.
Let A be a central simple k-algebra. If B is a simple k-algebra, then
A ‚äók B is a central simple Z(B)-algebra. In particular, if B is a central simple k-algebra,
then A ‚äók B is a central simple k-algebra.
Proof.
Each x ‚ààA ‚äók B has an expression of the form
x = a1 ‚äób1 + ¬∑ ¬∑ ¬∑ + an ‚äóbn,
(1)
where ai ‚ààA and bi ‚ààB. For nonzero x, deÔ¨Åne the length of x to be n if there is no
such expression having fewer than n terms. We claim that if x has length n, that is, if
Eq. (1) is a shortest such expression, then b1, . . . , bn is a linearly independent list in B
(viewed as a vector space over k). Otherwise, there is some j and ui ‚ààk, not all zero, with
b j = 
i uibi. Substituting and collecting terms gives
x =

iÃ∏= j
(ai + uia j) ‚äóbi,
which is a shorter expression for x.
Let I Ã∏= {0} be a two-sided ideal in A ‚äók B. Choose x to be a (nonzero) element in I of
smallest length, and assume that Eq. (1) is a shortest expression for x. Now a1 Ã∏= 0. Since
Aa1A is a two-sided ideal in A, simplicity gives A = Aa1 A. Hence, there are elements a‚Ä≤
p
and a‚Ä≤‚Ä≤
p in A with 1 = 
p a‚Ä≤
pa1a‚Ä≤‚Ä≤
p. Since I is a two-sided ideal,
x‚Ä≤ =

p
a‚Ä≤
pxa‚Ä≤‚Ä≤
p = 1 ‚äób1 + c2 ‚äób2 + ¬∑ ¬∑ ¬∑ + cn ‚äóbn
(2)
lies in I, where, for i ‚â•2, we have ci = 
p a‚Ä≤
paia‚Ä≤‚Ä≤
p. At this stage, we do not know
whether x‚Ä≤ Ã∏= 0, but we do know, for every a ‚ààA, that (a ‚äó1)x‚Ä≤ ‚àíx‚Ä≤(a ‚äó1) ‚ààI. Now
(a ‚äó1)x‚Ä≤ ‚àíx‚Ä≤(a ‚äó1) =

i‚â•2
(aci ‚àícia) ‚äóbi.
(3)
First, this element is 0, lest it be an element in I of length smaller than the length of x.
Since b1, . . . bn is a linearly independent list, the k-subspace it generates is ‚ü®b1, . . . , bn‚ü©=
‚ü®b1‚ü©‚äï¬∑ ¬∑ ¬∑ ‚äï‚ü®bn‚ü©, and so
A ‚äók ‚ü®b1, . . . , bn‚ü©= A ‚äók ‚ü®b1‚ü©‚äï¬∑ ¬∑ ¬∑ ‚äïA ‚äók ‚ü®bn‚ü©.

Sec. 9.7
Division Algebras
729
It follows from Eq. (3) that each term (aci ‚àícia) ‚äóbi must be 0. Hence, aci = cia for all
a ‚ààA; that is, each ci ‚ààZ(A) = k. Eq. (2) becomes
x‚Ä≤ = 1 ‚äób1 + c2 ‚äób2 + ¬∑ ¬∑ ¬∑ + cn ‚äóbn
= 1 ‚äób1 + 1 ‚äóc2b2 + ¬∑ ¬∑ ¬∑ + 1 ‚äócnbn
= 1 ‚äó(b1 + c2b2 + ¬∑ ¬∑ ¬∑ + cnbn).
Now b1 + c2b2 + ¬∑ ¬∑ ¬∑ + cnbn Ã∏= 0, because b1, . . . , bn is a linearly independent list, and
so x‚Ä≤ Ã∏= 0. Therefore, I contains a nonzero element of the form 1 ‚äób. But simplicity of
B gives BbB = B, and so there are b‚Ä≤
q, b‚Ä≤‚Ä≤
q ‚ààB with 
q b‚Ä≤
qbb‚Ä≤‚Ä≤
q = 1. Hence, I contains

q(1 ‚äób‚Ä≤
q)(1 ‚äób)(1 ‚äób‚Ä≤‚Ä≤
q) = 1 ‚äó1, which is the unit in A ‚äók B. Therefore, I = A ‚äók B
and A ‚äók B is simple.
We now seek the center of A ‚äók B. Clearly, k ‚äók Z(B) ‚äÜZ(A ‚äók B). For the reverse
inequality, let z ‚ààZ(A ‚äók B) be nonzero, and let
z = a1 ‚äób1 + ¬∑ ¬∑ ¬∑ + an ‚äóbn
be a shortest such expression for z. As in the preceding argument, b1, . . . , bn is a linearly
independent list over k. For each a ‚ààA, we have
0 = (a ‚äó1)z ‚àíz(a ‚äó1) =

i
(aai ‚àíaia) ‚äóbi.
It follows, as above, that (aai ‚àíaia) ‚äóbi = 0 for each i. Hence, aai ‚àíaia = 0, so
that aai = aia for all a ‚ààA and each ai ‚ààZ(A) = k. Thus, z = 1 ‚äóx, where
x = a1b1 + ¬∑ ¬∑ ¬∑ + anbn ‚ààB. But if b ‚ààB, then
0 = z(1 ‚äób) ‚àí(1 ‚äób)z = (1 ‚äóx)(1 ‚äób) ‚àí(1 ‚äób)(1 ‚äóx) = 1 ‚äó(xb ‚àíbx).
Therefore, xb ‚àíbx = 0 and x ‚ààZ(B). We conclude that z ‚ààk ‚äók Z(B), as desired.
‚Ä¢
It is not generally true that the tensor product of simple k-algebras is again simple; we
must pay attention to the centers. In Exercise 9.67(iv) on page 727, we saw that if E/k is
a Ô¨Åeld extension, then E ‚äók E need not be a Ô¨Åeld. The tensor product of division algebras
need not be a division algebra, as we see in the next example.
Example 9.113.
The algebra C ‚äóR H is an eight-dimensional R-algebra, but it is also a four-dimensional
C-algebra: A basis is
1 = 1 ‚äó1, 1 ‚äói, 1 ‚äój, 1 ‚äók.

730
Advanced Linear Algebra
Ch. 9
We let the reader prove that the vector space isomorphism C ‚äóR H ‚ÜíMat2(C) with
1 ‚äó1 ‚Üí
1
0
0
1

,
1 ‚äói ‚Üí
i
0
0
‚àíi

,
1 ‚äój ‚Üí
 0
1
‚àí1
0

,
1 ‚äók ‚Üí
0
i
i
0

,
is an isomomorphism of C-algebras.
‚óÄ
Another way to see that C‚äóRH ‚àº= Mat2(C) arises from Example 8.71(ii). We remarked
then that
RQ ‚àº= R √ó R √ó R √ó R √ó H;
tensoring by C gives
CQ ‚àº= C ‚äóR RQ ‚àº= C √ó C √ó C √ó C √ó C ‚äóR H.
It follows from the uniqueness in Wedderburn's theorem that C ‚äóR H ‚àº= Mat2(C).
The next theorem puts the existence of the isomorphism in Example 9.113 into the
context of central simple algebras.
Theorem 9.114.
Let k be a Ô¨Åeld and let A be a central simple k-algebra.
(i) If k is the algebraic closure of k, then there is an integer n with
k ‚äók A ‚àº= Matn(k).
(ii) If A is a central simple k-algebra, then there is an integer n with
[A : k] = n2.
Proof.
(i) By Theorem 9.112, k‚äók A is a simple k-algebra. Hence, Wedderburn's theorem
(actually, Corollary 8.63) gives k ‚äók A ‚àº= Matn(D) for some n ‚â•1 and some division ring
D. Since D is a Ô¨Ånite-dimensional division algebra over k, the argument in Molien's
Corollary 8.65 shows that D = k.
(ii) We claim that [A : k] = [k ‚äók A : k], for if a1, . . . , am is a basis of A over k, then
1‚äóa1, . . . , 1‚äóam is a basis of k‚äók A over k (essentially because tensor product commutes
with direct sum). Therefore,
[A : k] = [k ‚äók A : k] = [Matn(k) : k] = n2.
‚Ä¢
The division ring of quaternions H is a central simple R-algebra, and so its dimension
[H : R] must be a square (it is 4). Moreover, since C is algebraically closed, Theorem 9.114
gives C ‚äóR H ‚àº= Mat2(C) (Example 9.113 displays an explicit isomorphism).

Sec. 9.7
Division Algebras
731
DeÔ¨Ånition.
A splitting Ô¨Åeld for a central simple k-algebra A is a Ô¨Åeld extension E/k for
which there exists an integer n such that E ‚äók A ‚àº= Matn(E).
Theorem 9.114 says that the algebraic closure k of a Ô¨Åeld k is a splitting Ô¨Åeld for every
central simple k-algebra A. We are going to see that there always exists a splitting Ô¨Åeld
that is a Ô¨Ånite extension of k, but we Ô¨Årst develop some tools in order to prove it.
DeÔ¨Ånition.
If A is a k-algebra and X ‚äÜA is a subset, then its centralizer, CA(X), is
deÔ¨Åned by
CA(X) = {a ‚ààA : ax = xa for every x ‚ààX}.
It is easy to check that centralizers are always subalgebras.
The key idea in the next proof is that a subalgebra B of A makes A into a (B, A)-
bimodule, and that the centralizer of B can be described in terms of an endomorphism ring
(this idea is exploited in proofs of the Morita theorems).
Theorem 9.115 (Double Centralizer).
Let A be a central simple algebra over a Ô¨Åeld
k and let B be a simple subalgebra of A.
(i) CA(B) is a simple k-algebra.
(ii) B ‚äók Aop ‚àº= Mats() and CA(B) ‚àº= Matr() for some division algebra , where
r | s.
(iii) [B : k][CA(B) : k] = [A : k].
(iv) CA(CA(B)) = B.
Proof.
Associativity of the multiplication in A shows that A can be viewed as a (B, A)-
bimodule. As such, it is a left (B ‚äók Aop)-module, where (b ‚äóa)x = bxa for all x ‚ààA;
we denote this module by A‚àó. But B ‚äók Aop is a simple k-algebra, by Theorem 9.112,
so that Corollary 8.63 gives B ‚äók Aop ‚àº= Mats() for some integer s and some division
algebra  over k; in fact, B‚äók Aop has a unique (to isomorphism) minimal left ideal L, and
op ‚àº= EndB‚äók Aop(L). Therefore, as (B ‚äók Aop)-modules, Corollary 8.44 gives A‚àó‚àº= Lr,
the direct sum of r copies of L, and so EndB‚äók Aop(A‚àó) ‚àº= Matr().
We claim that
CA(B) ‚àº= EndB‚äók Aop(A‚àó) ‚àº= Matr();
this will prove (i) and most of (ii). If œï ‚ààEndB‚äók Aop(A‚àó), then it is, in particular, an
endomorphism of A as a right A-module. Hence, for all a ‚ààA, we have
œï(a) = œï(1a) = œï(1)a = ua,
where u = œï(1). In particular, if b ‚ààB, then œï(b) = ub. On the other hand, taking the left
action of B into account, we have œï(b) = œï(b1) = bœï(1) = bu. Therefore, ub = bu for
all b ‚ààB, and so u ‚ààCA(B). Thus, œï ‚Üíœï(1) is a function EndB‚äók Aop(A‚àó) ‚ÜíCA(B). It
is routine to check that this function is an injective k-algebra map; it is also surjective, for
if u ‚ààCA(B), then the map A ‚ÜíA, deÔ¨Åned by a ‚Üíua, is a (B ‚äók Aop)-map.

732
Advanced Linear Algebra
Ch. 9
We now compute dimensions. DeÔ¨Åne d = [ : k]. Since L is a minimal left ideal in
Mats(), we have Mats() ‚àº= Ls (concretely, L = COL(1), consisting of all Ô¨Årst columns
of s √ó s matrices over ). Therefore, [Mats() : k] = s2[ : k] and [Ls : k] = s[L : k],
so that
[L : k] = sd.
Also,
[A : k] = [A‚àó: k] = [Lr : k] = rsd.
It follows that
[A : k][B : k] = [B ‚äók Aop : k] = [Mats() : k] = s2d.
Therefore, [B : k] = s2d
rsd = s
r , and so r | s. Hence,
[B : k][CA(B) : k] = [B : k][Matr() : k] = s
r ¬∑ r2d = rsd = [A : k],
because we have already proved that CA(B) ‚àº= Matr().
Finally, we prove (iv). It is easy to see that B ‚äÜCA(CA(B)): after all, if b ‚ààB and
u ‚ààCA(B), then bu = ub, and so b commutes with every such u. But CA(B) is a simple
subalgebra, by (i), and so the equation in (iii) holds if we replace B by CA(B):
[CA(B) : k][CA(CA(B)) : k] = [A : k].
We conclude that [B : k] = [CA(CA(B)) : k]; together with B ‚äÜCA(CA(B)), this
equality gives B = CA(CA(B)).
‚Ä¢
Here is a minor variant of the theorem.
Corollary 9.116.
If B is a simple subalgebra of a central simple k-algebra A, where k is
a Ô¨Åeld, then there is a division algebra D with Bop ‚äók A ‚àº= Mats(D).
Proof.
By Theorem 9.115(ii), we have B‚äók Aop ‚àº= Mats() for some division algebra .
Hence, (B‚äók Aop)op ‚àº= (Mats())op. But (Mats())op ‚àº= Mats(op), by Proposition 8.13,
while (B‚äók Aop)op ‚àº= Bop‚äók A, by Exercise 9.65 on page 726. Setting D = op completes
the proof.
‚Ä¢
If  is a division algebra over a Ô¨Åeld k and if Œ¥ ‚àà, then the subdivision algebra
generated by k and Œ¥ is a Ô¨Åeld, because elements in the center k commute with Œ¥. We are
interested in maximal subÔ¨Åelds of .
Lemma 9.117.
If  is a division algebra over a Ô¨Åeld k, then a subÔ¨Åeld E of  is a
maximal subÔ¨Åeld if and only if C(E) = E.
Proof.
If E is a maximal subÔ¨Åeld of , then E ‚äÜC(E) because E is commutative.
For the reverse inclusion, it is easy to see that if Œ¥ ‚ààC(E), then the division algebra E‚Ä≤
generated by E and Œ¥ is a Ô¨Åeld. Hence, if Œ¥ /‚ààE, then E ‚ääE‚Ä≤, and the maximality of E is
contradicted.

Sec. 9.7
Division Algebras
733
Conversely, suppose that E is a subÔ¨Åeld with C(E) = E. If E is not a maximal
subÔ¨Åeld of , then there exists a subÔ¨Åeld E‚Ä≤ with E ‚ääE‚Ä≤. Now E‚Ä≤ ‚äÜC(E), so that
if there is some a‚Ä≤ ‚ààE‚Ä≤ with a‚Ä≤ /‚ààE, then E Ã∏= C(E). Therefore, E is a maximal
subÔ¨Åeld.
‚Ä¢
After proving an elementary lemma about tensor products, we will extend the next result
from division algebras to central simple algebras (see Theorem 9.127).
Theorem 9.118.
If D is a division algebra over a Ô¨Åeld k and E is a maximal subÔ¨Åeld of D,
then E is a splitting Ô¨Åeld for D; that is, E ‚äók D ‚àº= Mats(E), where s = [D : E] = [E : k].
Proof.
Let us specialize the algebras in Theorem 9.115. Here, A = D, B = E, and
CA(E) = E, by Lemma 9.117. Now the condition CA(B) ‚àº= Matr() becomes E ‚àº=
Matr(); since E is commutative, r = 1 and  = E. Thus, Corollary 9.116 says that
E ‚äók D = Eop ‚äók D ‚àº= Mats(E).
The equality in Theorem 9.115(iii) is now [D : k] = [E : k][E : k] = [E : k]2. But
[E ‚äók D : k] = [Mats(E) : k] = s2[E : k], so that s2 = [D : k] = [E : k]2 and
s = [E : k].
‚Ä¢
Corollary 9.119.
If D is a division algebra over a Ô¨Åeld k, then all maximal subÔ¨Åelds have
the same degree over k.
Proof.
For every maximal subÔ¨Åeld E, we have [E : k] = [D : E] = ‚àö[D : k].
‚Ä¢
This corollary can be illustrated by Example 9.113.
The quaternions H is a four-
dimensional R-algebra, and so a maximal subÔ¨Åeld must have degree 2 over R. And so
it is, for C is a maximal subÔ¨Åeld.
We now prove a technical theorem that will yield wonderful results. Recall that a unit
in a noncommutative ring A is an element having a two-sided inverse in A.
Theorem 9.120.
Let k be a Ô¨Åeld, let B be a simple k-algebra, and let A be a central
simple k-algebra. If there are algebra maps f, g : B ‚ÜíA, then there exists a unit u ‚ààA
with
g(b) = u f (b)u‚àí1
for all b ‚ààB.
Proof.
The map f makes A into a left B-module if we deÔ¨Åne the action of b ‚ààB on an
element a ‚ààA as f (b)a. This action makes A into a (B, A)-bimodule, for the associative
law in A gives

f (b)x

a = f (b)(xa) for all x ‚ààA. As usual, this (B, A)-bimodule is a
left (B‚äók Aop)-module, where (b‚äóa‚Ä≤)a = baa‚Ä≤ for all a ‚ààA; denote it by fA. Similarly, g
can be used to make A into a left (B ‚äók Aop)-module we denote by gA. By Theorem 9.112,
B ‚äók Aop is a simple k-algebra. Now
[ fA : ] = [A : ] = [gA : ],

734
Advanced Linear Algebra
Ch. 9
so that fA ‚àº= gA as (B‚äók Aop)-modules, by Corollary 8.63. If œï : fA ‚ÜígA is a (B‚äók Aop)-
isomorphism, then
œï( f (b)aa‚Ä≤) = g(b)œï(a)a‚Ä≤
(4)
for all b ‚ààB and a, a‚Ä≤ ‚ààA. Since œï is an automorphism of A as a right module over itself,
œï(a) = œï(1a) = ua, where u = œï(1) ‚ààA. To see that u is a unit, note that œï‚àí1(a) = u‚Ä≤a
for all a ‚ààA. Now a = œïœï‚àí1(a) = œï(u‚Ä≤a) = uu‚Ä≤a for all a ‚ààA; in particular, when
a = 1, we have 1 = uu‚Ä≤. The equation œï‚àí1œï = 1A gives 1 = u‚Ä≤u, as desired. Substituting
into Eq. (4), we have
u f (b)a = œï( f (b)a) = g(b)œï(a) = g(b)ua
for all a ‚ààA. In particular, if a = 1, then u f (b) = g(b)u and g(b) = u f (b)u‚àí1.
‚Ä¢
Corollary 9.121 (Skolem-Noether).
Let A be a central simple k-algebra over a Ô¨Åeld
k, and let B and B‚Ä≤ be isomorphic simple k-subalgebras of A. If œà : B ‚ÜíB‚Ä≤ is an
isomorphism, then there exists a unit u ‚ààA with œà(b) = ubu‚àí1 for all b ‚ààB.
Proof.
In the theorem, take f : B ‚ÜíA to be the inclusion, deÔ¨Åne B‚Ä≤ = im œà, and deÔ¨Åne
g = iœà, where i : B‚Ä≤ ‚ÜíA is the inclusion.
‚Ä¢
There is an analog of the Skolem-Noether theorem in group theory. A theorem of G.
Higman, B. H. Neumann, and H. Neumann says that if B and B‚Ä≤ are isomorphic subgroups
of a group G, say, œï : B ‚ÜíB‚Ä≤ is an isomorphism, then there exists a group G‚àócontaining
G and an element u ‚ààG‚àówith œï(b) = ubu‚àí1 for every b ‚ààB. There is a proof in
Rotman, An Introduction to the Theory of Groups, page 404.
Corollary 9.122.
Let k be a Ô¨Åeld. If œà is an automorphism of Matn(k), then there exists
a nonsingular matrix P ‚ààMatn(k) with
œà(T ) = PT P‚àí1
for every matrix T in Matn(k).
Proof.
The matrix ring A = Matn(k) is a central simple k-algebra. Set B = B‚Ä≤ = A in
the Skolem-Noether theorem.
‚Ä¢
The following proof of Wedderburn's theorem is due to B. L. van der Waerden.
Theorem 9.123 (Wedderburn).
Every Ô¨Ånite division ring D is a Ô¨Åeld.
Proof.
Let Z = Z(D), and let E be a maximal subÔ¨Åeld of D. If d ‚ààD, then Z(d) is
a subÔ¨Åeld of D, and hence there is a maximal subÔ¨Åeld Ed containing Z(d). By Corol-
lary 9.119, all maximal subÔ¨Åelds have the same degree, hence have the same order. By
Corollary 3.132, all maximal subÔ¨Åelds here are isomorphic.19
For every d ‚ààD, the
19It is not true that maximal subÔ¨Åelds in arbitrary division algebras are isomorphic; see Exercise 9.80.

Sec. 9.7
Division Algebras
735
Skolem-Noether theorem says there is xd ‚ààD with Ed = xd Ex‚àí1
d . Therefore, D =
!
x x Ex‚àí1, and so
D√ó =

x
x E√óx‚àí1.
If E is a proper subÔ¨Åeld of D, then E√ó is a proper subgroup of D√ó, and this equation
contradicts Exercise 5.32 on page 278. Therefore, D = E is commutative.
‚Ä¢
Theorem 9.124 (Frobenius).
If D is a noncommutative Ô¨Ånite-dimensional real division
algebra, then D ‚àº= H.
Proof.
If E is a maximal subÔ¨Åeld of D, then [D : E] = [E : R] ‚â§2. If [E : R] = 1,
then [D : R] = 12 = 1 and D = R. Hence, [E : R] = 2 and [D : R] = 4. Let us identify
E with C (we know they are isomorphic). Now complex conjugation is an automorphism
of E, so that the Skolem-Noether theorem gives x ‚ààD with z = xzx‚àí1 for all z ‚ààE. In
particular, ‚àíi = xix‚àí1. Hence,
x2ix‚àí2 = x(‚àíi)x‚àí1 = ‚àíxix‚àí1 = i,
and so x2 commutes with i. Therefore, x2 ‚ààCD(E) = E, by Lemma 9.117, and so
x2 = a + bi for a, b ‚ààR. But
a + bi = x2 = xx2x‚àí1 = x(a + bi)x‚àí1 = a ‚àíbi,
so that b = 0 and x2 ‚ààR. If x2 > 0, then there is t ‚ààR with x2 = t2. Now (x+t)(x‚àít) =
0 gives x = ¬±t ‚ààR, contradicting ‚àíi = xix‚àí1. Therefore, x2 = ‚àír2 for some real r.
The element j, deÔ¨Åned by j = x/r, satisÔ¨Åes j2 = ‚àí1 and ji = ‚àíi j. The list 1, i, j, i j is
linearly independent over R: if a+bi +cj +di j = 0, then (‚àídi ‚àíc) j = a+ib ‚ààC. Since
j /‚ààC (lest x ‚ààC), we must have ‚àídi ‚àíc = 0 = a + bi. Hence, a = b = 0 = c = d.
Since [D : R] = 4, the list 1, i, j, i j is a basis of D. It is now routine to see that if we
deÔ¨Åne k = i j, then ki = j = ‚àíik, jk = i = ‚àíkj, and k2 = ‚àí1, and so D ‚àº= H.
‚Ä¢
In 1929, R. Brauer introduced the Brauer group to study division rings. Since construc-
tion of division rings was notoriously difÔ¨Åcult, he considered the wider class of central
simple algebras. Brauer introduced the following relation on central simple k-algebras.
DeÔ¨Ånition.
Two central simple k-algebras A and B are similar, denoted by A ‚àºB, if
there are integers n and m with
A ‚äók Matn(k) ‚àº= B ‚äók Matm(k).
By the Wedderburn theorem, A ‚àº= Matn() for a unique division algebra  over k, and
we shall see that A ‚àºB if and only if they determine the same division algebra.

736
Advanced Linear Algebra
Ch. 9
Lemma 9.125.
Let A be a Ô¨Ånite-dimensional algebra over a Ô¨Åeld k. If S and T are
k-subalgebras of A such that
(i) st = ts for all s ‚ààS and t ‚ààT ;
(ii) A = ST ;
(iii) [A : k] = [S : k][T : k],
then A ‚àº= S ‚äók T .
Proof.
There is a k-linear transformation f : S ‚äók T ‚ÜíA with s ‚äót ‚Üíst, because
(s, t) ‚Üíst is a k-bilinear function S √ó T ‚ÜíA. Condition (i) implies that f is an algebra
map, for
f

(s ‚äót)(s‚Ä≤ ‚äót‚Ä≤)

= f (ss‚Ä≤ ‚äótt‚Ä≤) = ss‚Ä≤tt‚Ä≤ = sts‚Ä≤t‚Ä≤ = f (s ‚äót) f (s‚Ä≤ ‚äót‚Ä≤).
Since A = ST , by condition (ii), the k-linear transformation f is a surjection; since
dimk(S ‚äók T ) = dimk(A), by condition (iii), f is a k-algebra isomorphism.
‚Ä¢
Lemma 9.126.
Let k be a Ô¨Åeld.
(i) If A is a k-algebra, then
A ‚äók Matn(k) ‚àº= Matn(A).
(ii) Matn(k) ‚äók Matm(k) ‚àº= Matnm(k).
(iii) A ‚àºB is an equivalence relation.
(iv) If A is a central simple algebra, then
A ‚äók Aop ‚àº= Matn(k),
where n = [A : k].
Proof.
(i) DeÔ¨Åne k-subalgebras of Matn(A) by
S = Matn(k)
and
T = {aI : a ‚ààA}.
If s ‚ààS and t ‚ààT , then st = ts (for the entries of matrices in S commute with elements
a ‚ààA). Now S contains every matrix unit Ei j (whose i j entry is 1 and whose other entries
are 0), so that ST contains all matrices of the form ai j Ei j for all i j, where ai j ‚ààA; hence,
ST = Matn(A). Finally, [S : k][T : k] = n2[A : k] = [Matn(A) : k]. Therefore,
Lemma 9.125 gives the desired isomorphism.
(ii) If V and W are vector spaces over k of dimensions n and m, respectively, it sufÔ¨Åces to
prove that Endk(V ) ‚äók Endk(W) ‚àº= Endk(V ‚äók W). DeÔ¨Åne S to be all f ‚äó1W, where
f ‚ààEndk(V ), and deÔ¨Åne T to be all 1V ‚äóg, where g ‚ààEndk(W). It is routine to check
that the three conditions in Lemma 9.125 hold.

Sec. 9.7
Division Algebras
737
(iii) Since k = Mat1(k), we have A ‚àº= A ‚äók k ‚àº= A ‚äók Mat1(k), so that ‚àºis reÔ¨Çexive.
Symmetry is obvious; for transitivity, suppose that A ‚àºB and B ‚àºC; that is,
A ‚äók Matn(k) ‚àº= B ‚äók Matm(k)
and
B ‚äók Matr(k) ‚àº= C ‚äók Mats(k).
Then A ‚äók Matn(k) ‚äók Matr(k) ‚àº= A ‚äók Matnr(A), by part (ii). On the other hand,
A ‚äók Matn(k) ‚äók Matr(k) ‚àº= B ‚äók Matm(k) ‚äók Matr(k)
‚àº= C ‚äók Matm(k) ‚äók Mats(k)
‚àº= C ‚äók Matms(k).
Therefore, A ‚àºC, and so ‚àºis an equivalence relation.
(iv) DeÔ¨Åne f : A√óAop ‚ÜíEndk(A) by f (a, c) = Œªa‚ó¶œÅc, where Œªa : x ‚Üíax and œÅc : x ‚Üí
xc; it is routine to check that Œªa and œÅc are k-maps (so their composite is also a k-map), and
that f is k-biadditive. Hence, there is a k-map f : A ‚äók Aop ‚ÜíEndk(A) with f (a ‚äóc) =
Œªa ‚ó¶œÅc. Associativity a(xc) = (ax)c in A says that Œªa ‚ó¶œÅc = œÅc ‚ó¶Œªa, from which it easily
follows that f is a k-algebra map. As A ‚äók Aop is a simple k-algebra and ker f is a proper
two-sided ideal, we have f injective. Now dimk(Endk(A)) = dimk(Homk(A, A)) = n2,
where n = [A : k]. Since dimk(im f ) = dimk(A ‚äók Aop) = n2, it follows that f is a
k-algebra isomorphism: A ‚äók Aop ‚àº= Endk(A).
‚Ä¢
We now extend Theorem 9.118 from division algebras to central simple algebras.
Theorem 9.127.
Let A be a central simple k-algebra over a Ô¨Åeld k, so that A ‚àº= Matr(),
where  is a division algebra over k. If E is a maximal subÔ¨Åeld of , then E splits A; that
is, there is an integer n and an isomorphism
E ‚äók A ‚àº= Matn(E).
More precisely, if [ : E] = s, then n = rs and [A : k] = (rs)2.
Proof.
By Theorem 9.118,  is split by a maximal subÔ¨Åeld E (which is, of course, a
Ô¨Ånite extension of k): E ‚äók  ‚àº= Mats(E), where s = [ : E] = [E : k]. Hence,
E ‚äók A ‚àº= E ‚äók Matr() ‚àº= E ‚äók ( ‚äók Matr(k))
‚àº= (E ‚äók ) ‚äók Matr(k) ‚àº= Mats(E) ‚äók Matr(k) ‚àº= Matrs(E).
Therefore, A ‚àº= Matr() gives [A : k] = r2[ : k] = r2s2.
‚Ä¢
DeÔ¨Ånition.
If [A] denotes the equivalence class of a central simple k-algebra A under
similarity, deÔ¨Åne the Brauer group Br(k) to be the set
Br(k) =

[A] : A is a central simple k-algebra

with binary operation
[A][B] = [A ‚äók B].

738
Advanced Linear Algebra
Ch. 9
Theorem 9.128.
Br(k) is an abelian group for every Ô¨Åeld k. Moreover, if A ‚àº= Matn()
for a division algebra , then  is central simple and [A] = [] in Br(k).
Proof.
We show that the operation is well-deÔ¨Åned: If A, A‚Ä≤, B, B‚Ä≤ are k-algebras with
A ‚àºA‚Ä≤ and B ‚àºB‚Ä≤, then A ‚äók B ‚àºA‚Ä≤ ‚äók B‚Ä≤. The isomorphisms
A ‚äók Matn(k) ‚àº= A‚Ä≤ ‚äók Matm(k)
and
B ‚äók Matr(k) ‚àº= B‚Ä≤ ‚äók Mats(k)
give A ‚äók B ‚äók Matn(k) ‚äók Matr(k) ‚àº= A‚Ä≤ ‚äók B‚Ä≤ ‚äók Matm(k) ‚äók Mats(k) (we are using
commutativity and associativity of tensor product), so that Lemma 9.126(ii) gives A ‚äók
B ‚äók Matnr(k) ‚àº= A‚Ä≤ ‚äók B‚Ä≤ ‚äók Matms(k). Therefore, A ‚äók B ‚àºA‚Ä≤ ‚äók B‚Ä≤.
That [k] is the identity follows from k‚äók A ‚àº= A, associativity and commutativity follow
from associativity and commutativity of tensor product, and Lemma 9.126(iv) shows that
[A]‚àí1 = [Aop]. Therefore, Br(k) is an abelian group.
If A is a central simple k-algebra, then A ‚àº= Matr() for some Ô¨Ånite-dimensional
division algebra  over k.
Hence, k = Z(A) ‚àº= Z(Matr()) ‚àº= Z(), by Theo-
rem 9.112. Thus,  is a central simple k-algebra, [] ‚ààBr(k), and [] = [A] (because
 ‚äók Matr(k) ‚àº= Matr() ‚àº= A ‚àº= A ‚äók k ‚àº= A ‚äók Mat1(k)).
‚Ä¢
The next proposition shows the signiÔ¨Åcance of the Brauer group.
Proposition 9.129.
If k is a Ô¨Åeld, then there is a bijection from Br(k) to the family D of all
isomorphism classes of Ô¨Ånite-dimensional division algebras over k, and so | Br(k)| = |D|.
Therefore, there exists a noncommutative division ring, Ô¨Ånite-dimensional over its center
k, if and only if Br(k) Ã∏= {0}.
Proof.
DeÔ¨Åne a function œï : Br(k) ‚ÜíD by setting œï([A]) to be the isomorphism class
of  if A ‚àº= Matn(). Note that Theorem 9.128 shows that [A] = [] in Br(k). Let us
see that œï is well-deÔ¨Åned. If [] = [‚Ä≤], then  ‚àº‚Ä≤, so there are integers n and m with
‚äók Matn(k) ‚àº= ‚Ä≤ ‚äók Matm(k). Hence, Matn() ‚àº= Matm(‚Ä≤). By the uniqueness in the
Wedderburn-Artin theorems,  ‚àº= ‚Ä≤ (and n = m). Therefore, œï([]) = œï([‚Ä≤]).
Clearly, œï is surjective, for if  is a Ô¨Ånite-dimensional division algebra over k, then
the isomorphism class of  is equal to œï([]). To see that œï is injective, suppose that
œï([]) = œï([‚Ä≤]). Then,  ‚àº= ‚Ä≤, which implies  ‚àº‚Ä≤.
‚Ä¢
Example 9.130.
(i) If k is an algebraically closed Ô¨Åeld, then Theorem 9.114 shows that Br(k) = {0}.
(ii) If k is a Ô¨Ånite Ô¨Åeld, then Wedderburn's Theorem 9.123 (= Theorem 8.23) shows that
Br(k) = {0}.
(iii) If k = R, then Frobenius's Theorem 9.124 shows that Br(R) ‚àº= I2.
(iv) It is proved, using class Ô¨Åeld theory, that Br(Qp) ‚àº= Q/Z, where Qp is the Ô¨Åeld of
p-adic numbers. Moreover, there is an exact sequence
0 ‚ÜíBr(Q) ‚ÜíBr(R) ‚äï

p
Br(Qp)
œï
‚àí‚ÜíQ/Z ‚Üí0.

Sec. 9.7
Division Algebras
739
If we write Br(R) = ‚ü®1
2 + Z‚ü©‚äÜQ/Z, then œï is the "sum of coordinates" map.
In a series of deep papers, Br(k) was computed for the most interesting Ô¨Åelds k aris-
ing in algebraic number theory (local Ô¨Åelds, one of which is Qp, and global Ô¨Åelds) by
A. A. Albert, R. Brauer, H. Hasse, and E. Noether.
‚óÄ
Proposition 9.131.
If E/k is a Ô¨Åeld extension, then there is a homomorphism
fE/k : Br(k) ‚ÜíBr(E)
given by [A] ‚Üí[E ‚äók A].
Proof.
If A and B are central simple k-algebras, then E ‚äók A and E ‚äók B are central
simple E-algebras, by Theorem 9.112. If A ‚àºB, then E ‚äók A ‚àºE ‚äók B as E-algebras,
by Exercise 9.77 on page 740. It follows that the function fE/k is well-deÔ¨Åned. Finally,
fE/k is a homomorphism, because
(E ‚äók A) ‚äóE (E ‚äók B) ‚àº= (E ‚äóE E) ‚äók (A ‚äók B) ‚àº= E ‚äók (A ‚äók B),
by Proposition 8.84, associativity of tensor product.
‚Ä¢
DeÔ¨Ånition.
If E/k is a Ô¨Åeld extension, then the relative Brauer group, Br(E/k), is the
kernel of homomorphism fE/k : Br(k) ‚ÜíBr(E):
Br(E/k) = ker fE/k =

[A] ‚ààBr(k) : A is split by E

.
Corollary 9.132.
For every Ô¨Åeld k, we have
Br(k) =

E/k Ô¨Ånite
Br(E/k).
Proof.
This follows at once from Theorem 9.127.
‚Ä¢
In a word, the Brauer group arose as a way to study division rings. It is an interesting
object, but we have not really used it seriously. For example, we still know no noncommu-
tative division rings other than the real division algebra H and its variants for subÔ¨Åelds k
of R. We will remedy this when we introduce crossed product algebras in Chapter 10. For
example, we will see, in Corollary 10.133, that there exists a division ring whose center is
a Ô¨Åeld of characteristic p > 0. For further developments, we refer the reader to Jacobson,
Finite-Dimensional Division Algebras over Fields, and Reiner, Maximal Orders.

740
Advanced Linear Algebra
Ch. 9
EXERCISES
9.72 Prove that H ‚äóR H ‚àº= Mat4(R) as R-algebras.
Hint. Use Corollary 8.60 for the central simple R-algebra H ‚äóR H.
9.73 We have given one isomorphism C‚äóR H ‚àº= Mat2(C) in Example 9.113. Describe all possible
isomorphisms between these two algebras.
Hint. Use the Skolem-Noether theorem.
9.74 Prove that C ‚äóR C ‚àº= C √ó C as R-algebras.
9.75
(i) Let C(x) and C(y) be function Ô¨Åelds. Prove that R = C(x) ‚äóC C(y) is isomorphic to a
subring of C(x, y). Conclude that R has no zero divisors.
(ii) Prove that C(x) ‚äóC C(y) is not a Ô¨Åeld.
Hint.
Show that R is isomorphic to the subring of C(x, y) consisting of polynomials
of the form f (x, y)/g(x)h(y).
(iii) Use Exercise 8.39 on page 573 to prove that the tensor product of artinian algebras need
not be artinian.
9.76 Let A be a central simple k-algebra. If A is split by a Ô¨Åeld E, prove that A is split by any Ô¨Åeld
extension E‚Ä≤ of E.
9.77 Let E/k be a Ô¨Åeld extension. If A and B are central simple k-algebras with A ‚àºB, prove that
E ‚äók A ‚àºE ‚äók B as central simple E-algebras.
9.78 If D is a Ô¨Ånite-dimensional division algebra over R, prove that D is isomorphic to either R,
C, or H.
9.79 Prove that Mat2(H) ‚àº= H ‚äóR Mat2(R) as R-algebras.
9.80
(i) Let A be a four-dimensional vector space over Q, and let 1, i, j, k be a basis. Show that
A is a division algebra if we deÔ¨Åne 1 to be the identity and
i2 = ‚àí1
j2 = ‚àí2
k2 = ‚àí2
i j = k
jk = 2i
ki = j
ji = ‚àík
kj = ‚àí2i
ik = ‚àíj
Prove that A is a division algebra over Q.
(ii) Prove that Q(i) and Q( j) are nonisomorphic maximal subÔ¨Åelds of A.
9.81 Let D be the Q-subalgebra of H having basis 1, i, j, k.
(i) Prove that D is a division algebra over Q.
Hint. Compute the center Z(D).
(ii) For any pair of nonzero rationals p and q, prove that D has a maximal subÔ¨Åeld isomor-
phic to Q(

‚àíp2 ‚àíq2).
Hint. Compute (pi + qj)2.
9.82 (Dickson) If D is a division algebra over a Ô¨Åeld k, then each d ‚ààD is algebraic over k. Prove
that d, d‚Ä≤ ‚ààD are conjugate in D if and only if irr(d, k) = irr(d‚Ä≤, k).
Hint. Use the Skolem-Noether theorem.
9.83 Prove that if A is a central simple k-algebra with A ‚àºMatn(k), then A ‚àº= Matm(k) for some
integer m.

Sec. 9.8
Exterior Algebra
741
9.84 Prove that if A is a central simple k-algebra with [A] of Ô¨Ånite order m in Br(k), then
A ‚äók ¬∑ ¬∑ ¬∑ ‚äók A ‚àº= Matr(k)
(there are m factors equal to A) for some integer r. (In Chapter 10, we shall see that every
element in Br(k) has Ô¨Ånite order.)
9.8 EXTERIOR ALGEBRA
In calculus, the differential d f of a differentiable function f (x, y) at a point P = (x0, y0)
is deÔ¨Åned by
d f |P = ‚àÇf
‚àÇx |P(x ‚àíx0) + ‚àÇf
‚àÇy |P(y ‚àíy0).
If (x, y) is a point near P, then d f |P approximates the difference between the true value
f (x, y) and f (x0, y0). The quantity d f is considered "small," and so its square, a second-
order approximation, is regarded as negligible. For the moment, let us take being negligible
seriously: Suppose that
(d f )2 ‚âà0
for all differentials d f . There is a curious consequence: if du and dv are differentials, then
so is du + dv = d(u + v). But (du + dv)2 ‚âà0 gives
0 ‚âà(du + dv)2
‚âà(du)2 + du dv + dv du + (dv)2
‚âàdu dv + dv du,
and so du and dv anticommute:
dv du ‚âà‚àídu dv.
Now consider a double integral

D f (x, y)dx dy, where D is some region in the plane.
Equations
x = F(u, v)
y = G(u, v)
lead to the change of variables formula:
22
D
f (x, y)dx dy =
22

f (F(u, v), G(u, v))Jdu dv,
where  is some new region and J is the Jacobian:
J =
det
 Fu
Fv
Gu
Gv
 .

742
Advanced Linear Algebra
Ch. 9
A key idea in the proof of this formula is that the graph of a differentiable function f (x, y)
looks, locally, like a real vector space‚Äîits tangent plane. Let us denote a basis of the
tangent plane at a point by dx, dy. If du, dv is another basis of this tangent plane, then the
chain rule deÔ¨Ånes a linear transformation by the following linear equations:
dx = Fudu + Fvdv
dy = Gudu + Gvdv.
The Jacobian J now arises in a natural way.
dx dy = (Fudu + Fvdv)(Gudu + Gvdv)
= FuduGudu + FuduGvdv + FvdvGudu + FvdvGvdv
= FuGu(du)2 + FuGvdu dv + FvGudv du + FvGv(dv)2
‚âàFuGvdu dv + FvGudv du
‚âà(FuGv ‚àíFvGu)du dv
= det
 Fu
Fv
Gu
Gv

dudv.
Analytic considerations, involving orientation, force us to use the absolute value of the
determinant when proving the change of variables formula.
In the preceding equations, we used the distributive and associative laws, together with
anticommutativity; that is, we assumed that the differentials form a ring in which all
squares are 0. The following construction puts this kind of reasoning on a Ô¨Årm basis.
DeÔ¨Ånition.
If M is a k-module, where k is a commutative ring, then its exterior algebra20
is ;(M) = T (M)/J, pronounced "wedge M," where J is the two-sided ideal generated
by all m ‚äóm with m ‚ààM. The image of m1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p in ;(M) is denoted by
m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p.
Notice that J is generated by homogeneous elements (of degree 2), and so it is a graded
ideal, by Proposition 9.95. Hence, ;(M) is a graded k-algebra,
<
(M) = k ‚äïM ‚äï
<2(M) ‚äï
<3(M) ‚äï¬∑ ¬∑ ¬∑ ,
where, for p ‚â•2, we have ;p(M) = T p(M)/J p and J p = J ‚à©T p(M). Finally, ;(M)
is generated, as a k-algebra, by ;1(M) = M.
DeÔ¨Ånition.
We call ;p(M) the pth exterior power of a k-module M.
20 The original adjective in this context‚Äîthe German ausserer, meaning "outer"‚Äîwas introduced by Grass-
mann in 1844. Grassmann used it in contrast to inner product. The Ô¨Årst usage of the translation exterior can be
found in work of E. Cartan in 1945, who wrote that he was using terminology of Kaehler. The wedge notation
seems to have been introduced by Bourbaki.

Sec. 9.8
Exterior Algebra
743
Lemma 9.133.
Let k be a commutative ring, and let M be a k-module.
(i) If m, m‚Ä≤ ‚ààM, then in ;2(M), we have
m ‚àßm‚Ä≤ = ‚àím‚Ä≤ ‚àßm.
(ii) If p ‚â•2 and mi = m j for some i Ã∏= j, then m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p = 0 in ;p(M).
Proof.
(i) Recall that ;2(M) = (M‚äók M)/J 2, where J 2 = J‚à©(M‚äók M). If m, m‚Ä≤ ‚ààM,
then
(m + m‚Ä≤) ‚äó(m + m‚Ä≤) = m ‚äóm + m ‚äóm‚Ä≤ + m‚Ä≤ ‚äóm + m‚Ä≤ ‚äóm‚Ä≤.
Therefore,
m ‚äóm‚Ä≤ + J 2 = ‚àím‚Ä≤ ‚äóm + J 2,
because J 2 contains (m + m‚Ä≤) ‚äó(m + m‚Ä≤), m ‚äóm, and m‚Ä≤ ‚äóm‚Ä≤. It follows that
m ‚àßm‚Ä≤ = ‚àím‚Ä≤ ‚àßm
for all m, m‚Ä≤ ‚ààM.
(ii) As we saw in the proof of Proposition 9.95, ;p(M) = T p(M)/J p, where J p =
J ‚à©T p(M) consists of all elements of degree p in the ideal J generated by all elements
in T 2(M) of the form m ‚äóm. In more detail, J p consists of all sums of homogeneous
elements Œ± ‚äóm ‚äóm ‚äóŒ≤, where m ‚ààM, Œ± ‚ààT q(M), Œ≤ ‚ààT r(M), and q + r + 2 = p;
it follows that m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p = 0 if there are two equal adjacent factors, say, mi = mi+1.
Since multiplication in ;(M) is associative, however, we can (anti)commute a factor mi
of m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p several steps away at the possible cost of a change in sign, and so we can
force any pair of factors to be adjacent.
‚Ä¢
One of our goals is to give a "basis-free" construction of determinants, and the idea is
to focus on some properties that such a function has. If we regard an n √ó n matrix A as
consisting of its n columns, then its determinant, det(A), is a function of n variables (each
ranging over n-tuples). One property of determinants is that det(A) = 0 if two columns
of A are equal, and another property is that it is multilinear. It will be seen that these
properties almost characterize the determinant.
DeÔ¨Ånition.
If M and N are k-modules, a k-multilinear function f : √óp M ‚ÜíN (where
√ópM is the cartesian product of M with itself p times) is alternating if
f (m1, . . . , m p) = 0
whenever mi = m j for some i Ã∏= j.
An alternating R-bilinear function arises naturally when considering (signed) areas in
the plane R2. If v1, v2 ‚ààR2, deÔ¨Åne A(v1, v2) to be the area of the parallelogram having
sides v1 and v2. It is clear that
A(rv1, sv2) = rs A(v1, v2)

744
Advanced Linear Algebra
Ch. 9
for all r, s ‚ààR (but we must say what this means when these numbers are negative), and a
geometric argument can be given to show that
A(w1 + v1, v2) = A(w1, v2) + A(v1, v2);
that is, A is R-bilinear. Now A is alternating, for A(v1, v1) = 0 because the degenerate
"parallelogram" having sides v1 and v1 has zero area. A similar argument shows that
volume is an alternating R-multilinear function on R3, as we see in vector calculus using
the cross product.
Theorem 9.134.
For all p ‚â•0 and all k-modules M, the pth exterior power ;p(M)
solves the universal mapping problem posed by alternating multilinear functions.
√ópM
h

f








;p(M)
f

N
If h : √óp M ‚Üí;p(M) is deÔ¨Åned by h(m1, . . . , m p) = m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p, then for every
alternating multilinear function f , there exists a unique k-homomorphism f making the
diagram commute.
Proof.
Consider the diagram
√ópM
h

h‚Ä≤









f
.((((((((((((((((
;p(M)
f
/
T p(M)
f ‚Ä≤

ŒΩ
0)
)
)
)
)
)
)
)
)
N
where h‚Ä≤(m1, . . . , m p) = m1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p and ŒΩ(m1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p) = m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p. Since
f is multilinear, there is a k-map f ‚Ä≤ : T p(M) ‚ÜíN with f ‚Ä≤h‚Ä≤ = f ; since f is alternating,
J ‚à©T p(M) ‚äÜker f ‚Ä≤, and so f ‚Ä≤ induces a map
f : T p(M)/(J ‚à©T p(M)) ‚ÜíN
with f ŒΩ = f ‚Ä≤. Hence,
f h = f ŒΩh‚Ä≤ = f ‚Ä≤h‚Ä≤ = f.
But T p(M)/(J ‚à©T p(M)) = ;p(M), as desired. Finally, f is the unique such map
because im h generates ;p(M).
‚Ä¢

Sec. 9.8
Exterior Algebra
745
Proposition 9.135.
For each p ‚â•0, the pth exterior power is a functor
<p : kMod ‚ÜíkMod.
Proof.
Now ;p(M) has been deÔ¨Åned on modules; it remains to deÔ¨Åne it on morphisms.
Suppose that g : M ‚ÜíM‚Ä≤ is a k-homomorphism. Consider the diagram
√ópM
h

f









;p(M),
;p(g)

;p(M‚Ä≤)
where f (m1, . . . , m p) = gm1 ‚àß¬∑ ¬∑ ¬∑ ‚àßgm p. It is easy to see that f is an alternating
multilinear function, and so universality yields a unique map
<p(g):
<p(M) ‚Üí
<p(M‚Ä≤)
with m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p ‚Üígm1 ‚àß¬∑ ¬∑ ¬∑ ‚àßgm p.
If g is the identity map on a module M, then ;p(g) is also the identity map, for it Ô¨Åxes
a set of generators. Finally, suppose that g‚Ä≤ : M‚Ä≤ ‚ÜíM‚Ä≤‚Ä≤ is a k-map. It is routine to check
that both ;p(g‚Ä≤g) and ;p(g‚Ä≤) ;p(g) make the following diagram commute
√ópM
h

F










;p(M),

;p(M‚Ä≤‚Ä≤)
where F(m1, . . . , m p) = g‚Ä≤gm1 ‚àß¬∑ ¬∑ ¬∑ ‚àßg‚Ä≤gm p. Uniqueness of such a dashed arrow gives
;p(g‚Ä≤g) = ;p(g‚Ä≤) ;p(g), as desired.
‚Ä¢
We will soon see that ;p is not as nice as Hom or tensor, for it is not an additive functor.
Theorem 9.136 (Anticommutativity).
If M is a k-module, x ‚àà;p(M), and y ‚àà
;q(M), then
x ‚àßy = (‚àí1)pq y ‚àßx.
Remark.
This identity holds only for products of homogeneous elements.
‚óÄ
Proof.
If x ‚àà;0(M) = k, then ;(M) being a k-algebra implies x ‚àßy = y ‚àßx for all
y ‚àà;(M), and so the identity holds, in particular, for y ‚àà;q(M) for any q. A similar
argument holds if y is homogeneous of degree 0. Therefore, we may assume that p, q ‚â•1;
we do a double induction.

746
Advanced Linear Algebra
Ch. 9
Base Step: p = 1 and q = 1. Suppose that x, y ‚àà;1(M) = M. Now
0 = (x + y) ‚àß(x + y)
= x ‚àßx + x ‚àßy + y ‚àßx + y ‚àßy
= x ‚àßy + y ‚àßx.
It follows that x ‚àßy = ‚àíy ‚àßx, as desired.
Inductive step: (p, 1) ‚áí(p + 1, 1). The inductive hypothesis gives
(x1 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p) ‚àßy = (‚àí1)py ‚àß(x1 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p).
Using associativity, we have
(x1 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p+1) ‚àßy = x1 ‚àß[(x2 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p+1) ‚àßy]
= x1 ‚àß(‚àí1)p[y ‚àß(x2 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p+1)]
= [x1 ‚àß(‚àí1)py] ‚àß(x2 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p+1)
= (‚àí1)p+1(y ‚àßx1) ‚àß(x2 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p+1).
Inductive Step: (p, q) ‚áí(p, q + 1). Assume that
(x1 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p) ‚àß(y1 ‚àß¬∑ ¬∑ ¬∑ ‚àßyq) =
(‚àí1)pq(y1 ‚àß¬∑ ¬∑ ¬∑ ‚àßyq) ‚àß(x1 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p).
We let the reader prove, using associativity, that
(x1 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p) ‚àß(y1 ‚àß¬∑ ¬∑ ¬∑ ‚àßyq+1) =
(‚àí1)p(q+1)(y1 ‚àß¬∑ ¬∑ ¬∑ ‚àßyq+1) ‚àß(x1 ‚àß¬∑ ¬∑ ¬∑ ‚àßx p).
‚Ä¢
DeÔ¨Ånition.
Let n be a positive integer and let 1 ‚â§p ‚â§n. An increasing p ‚â§n-list is a
list
H = i1, . . . , i p
for which 1 ‚â§i1 < i2 < ¬∑ ¬∑ ¬∑ < i p ‚â§n.
If H = i1, . . . , i p is an increasing p ‚â§n-list, we write
eH = ei1 ‚àßei2 ‚àß¬∑ ¬∑ ¬∑ ‚àßei p.
Of course, the number of increasing p ‚â§n-lists is the same as the number of p-subsets
of a set with n elements, namely,
n
p

.
Proposition 9.137.
Let M be Ô¨Ånitely generated, say, M = ‚ü®e1, . . . , en‚ü©. If p ‚â•1, then
;p(M) is generated by all elements of the form eH, where H = i1, . . . , i p is an increasing
p ‚â§n-list.

Sec. 9.8
Exterior Algebra
747
Proof.
Every element of M has some expression of the form  aiei, where ai ‚ààk. We
prove the proposition by induction on p ‚â•1. Let m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p+1 be a typical generator
of ;p+1(M). By induction,
m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p =

H
aHeH,
where aH ‚ààk and H is an increasing p ‚â§n-list. If m p+1 =  b je j, then
m1 ‚àß¬∑ ¬∑ ¬∑ ‚àßm p+1 = (

H
aHeH) ‚àß(

j
b je j).
Each e j in  b je j can be moved to any position in eH = ei1 ‚àß¬∑ ¬∑ ¬∑ ‚àßei p (with a possible
change in sign) by (anti)commuting it from right to left. Of course, if e j = ei‚Ñìfor any
‚Ñì, then this term is 0, and so we can assume that all the factors in surviving wedges are
distinct and are arranged with indices in ascending order.
‚Ä¢
Corollary 9.138.
If M can be generated by n elements, then ;p(M) = {0} for all p > n.
Proof.
Any wedge of p factors must be 0, for it must contain a repetition of one of the
generators.
‚Ä¢
DeÔ¨Ånition.
If V is a free k-module of rank n, then a Grassmann algebra on V is a
k-algebra G(V ) with identity element, denoted by e0, such that
(a) G(V ) contains ‚ü®e0‚ü©‚äïV as a submodule, where ‚ü®e0‚ü©‚àº= k;
(b) G(V ) is generated, as a k-algebra, by ‚ü®e0‚ü©‚äïV ;
(c) v2 = 0 for all v ‚ààV ;
(d) G(V ) is a free k-module of rank 2n.
The computation on page 741 shows that the condition v2 = 0 for all v ‚ààV implies
vu = ‚àíuv for all u, v ‚ààV . A candidate for G(V ) is ;(V ) but, at this stage, it is not clear
how to show that ;(V ) is free and of the desired rank.
Grassmann algebras carry a generalization of complex conjugation, and this fact is the
key to proving their existence. If A is a k-algebra, then an algebra automorphism is a
k-algebra isomorphism of A with itself.
Theorem 9.139.
Let V be a free k-module with basis e1, . . . , en, where n ‚â•1.
(i) There exists a Grassmann algebra G(V ) with an algebra automorphism u ‚Üíu,
called conjugation, such that
u = u;
e0 = e0;
v = ‚àív for all v ‚ààV.

748
Advanced Linear Algebra
Ch. 9
(ii) The Grassmann algebra G(V ) is a graded k-algebra
G(V ) =

p
G p(V ),
where
G p(V ) = ‚ü®eH : where H is an increasing p-list‚ü©
[we have extended the notation eH = ei1 ‚àß¬∑ ¬∑ ¬∑ ‚àßei p in ;p(V ) to eH = ei1 ¬∑ ¬∑ ¬∑ ei p in
G p(V )]. Moreover, G p(V ) is a free k-module with
rank(G p(V )) =
n
p
	
.
Proof.
(i) The proof is by induction on n ‚â•1. The base step is clear: If V = ‚ü®e1‚ü©‚àº= k, set
G(V ) = ‚ü®e0‚ü©‚äï‚ü®e1‚ü©; note that G(V ) is a free k-module of rank 2. DeÔ¨Åne a multiplication
on G(V ) by
e0e0 = e0;
e0e1 = e1 = e1e0;
e1e1 = 0.
It is routine to check that G(V ) is a k-algebra that satisÔ¨Åes the axioms of a Grassmann
algebra. There is no choice in deÔ¨Åning the automorphism; we must have
ae0 + be1 = ae0 ‚àíbe1.
Finally, it is easy to see that u ‚Üíu is the automorphism we seek.
For the inductive step, let V be a free k-module of rank n + 1 and let e1, . . . , en+1 be
a basis of V . If W = ‚ü®e1, . . . , en‚ü©, then the inductive hypothesis provides a Grassmann
algebra G(W), free of rank 2n, and an automorphism u ‚Üíu for all u ‚ààG(W). DeÔ¨Åne
G(V ) = G(W) ‚äïG(W), so that G(V ) is a free module of rank 2n + 2n = 2n+1. We make
G(V ) into a k-algebra by deÔ¨Åning
(x1, x2)(y1, y2) = (x1y1, x2y1 + x1y2).
We now verify the four parts in the deÔ¨Ånition of Grassmann algebra.
(a) At the moment, V is not a submodule of G(V ). Each v ‚ààV has a unique expression of
the form v = w + aen+1, where w ‚ààW and a ‚ààk. The k-map V ‚ÜíG(V ), given by
v = w + aen+1 ‚Üí(w, ae0),
is an isomorphism of k-modules, and we identify V with its image in G(V ). In particular,
en+1 is identiÔ¨Åed with (0, e0). Note that the identity element e0 ‚ààG(W) in G(W) has been
identiÔ¨Åed with (e0, 0) in G(V ), and that the deÔ¨Ånition of multiplication in G(V ) shows that
(e0, 0) is the identity in G(V ).
(b) By induction, we know that the elements of ‚ü®e0‚ü©‚äïW generate G(W) as a k-algebra;
that is, all (x1, 0) ‚ààG(W) arise from elements of W. Next, by our identiÔ¨Åcation, en+1 =
(0, e0),
(x1, 0)en+1 = (x1, 0)(0, e0) = (0, x1),

Sec. 9.8
Exterior Algebra
749
and so the elements of V generate all pairs of the form (0, x2). Since addition is coordi-
natewise, all (x1, x2) = (x1, 0) + (0, x2) arise from V using algebra operations.
(c) If v ‚ààV , then v = w + aen+1, where w ‚ààW, and v is identiÔ¨Åed with (w, ae0) in
G(V ). Hence,
v2 = (w, ae0)(w, ae0) = (w2, ae0w + ae0w).
Now w2 = 0, and w = ‚àíw, so that v2 = 0.
(d) rank G(V ) = 2n+1 because G(V ) = G(W) ‚äïG(W).
We have shown that G(V ) is a Grassmann algebra. Finally, deÔ¨Åne conjugation by
(x1, x2) = (x1, ‚àíx2).
The reader may check that this deÔ¨Ånes a function with the desired properties.
(ii) We prove, by induction on n ‚â•1, that G p(V ) = ‚ü®eH : where H is an increasing p-list‚ü©
is a free k-module with the displayed products as a basis. The base step is obvious: If
rank(V ) = 1, say, with basis e1, then G(V ) = ‚ü®e0, e1‚ü©; moreover, both G0(V ) and G1(V )
are free of rank 1.
For the inductive step, assume that V is free with basis e1, . . . , en+1. As in the proof
of part (i), let W = ‚ü®e1 . . . , en‚ü©. By induction, G p(W) is a free k-module of rank
n
p

with basis all eH, where H is an increasing p ‚â§n-list.
Here are two types of ele-
ments of G p(V ): elements eH ‚ààG(W), where H is an increasing p ‚â§n-list; elements
eH = ei1 ¬∑ ¬∑ ¬∑ ei p‚àí1en+1, where H is an increasing p ‚â§(n + 1)-list that involves en+1. We
know that the elements of the Ô¨Årst type comprise a basis of G(W). The deÔ¨Ånition of mul-
tiplication in G(V ) gives eHen+1 = (eH, 0)(0, e0) = (0, eH). Thus, the number of such
products is
 n
p‚àí1

. As G(V ) = G(W) ‚äïG(W), we see that the union of these two types of
products form a basis for G p(V ), and so rank(G p(V )) =
n
p

+
 n
p‚àí1

=
n+1
p

.
It remains to prove that G p(V )Gq(V ) ‚äÜG p+q(V ). Consider ei1 ¬∑ ¬∑ ¬∑ ei pe j1 ¬∑ ¬∑ ¬∑ e jqlate.
If some subscript ir is the same as a subscript js, then this product is 0 because it has
a repeated factor; if all the subscripts are distinct, then this product lies in G p+q(V ), as
desired. Therefore, G(V ) is a graded k-algebra whose graded part of degree p is a free
k-module of rank
n
p

.
‚Ä¢
Theorem 9.140 (Binomial Theorem).
If V is a free k-module of rank n, then there is
an isomorphism of graded k-algebras,
<
(V ) ‚àº= G(V ).
Thus, ;p(V ) is a free k-module, for all p ‚â•1, with basis all increasing p ‚â§n-lists, hence
rank
<p(V )

=
n
p
	
.

750
Advanced Linear Algebra
Ch. 9
Proof.
For any p ‚â•2, consider the diagram
√ópV
h

gp
*
*
*
*
*
*
*
*
*
;p(V ),
gp

G p(V )
where gp(v1, . . . , vp) = v1 ¬∑ ¬∑ ¬∑ vp. Since v2 = 0 in G p(V ) for all v ‚ààV , the function gp
is alternating multilinear. By the universal property of exterior power, there is a (unique)
k-homomorphism gp : ;p(V ) ‚ÜíG p(V ) making the diagram commute; that is,
gp(v1 ‚àß¬∑ ¬∑ ¬∑ ‚àßvp) = v1 ¬∑ ¬∑ ¬∑ vp.
If e1, . . . , en is a basis of V , then we have just seen that G p(V ) is a free k-module with
basis all ei1 ¬∑ ¬∑ ¬∑ ei p, and so gp is surjective. But ;p(V ) is generated by all ei1 ‚àß¬∑ ¬∑ ¬∑ ‚àß
ei p, by Proposition 9.137. If some k-linear combination 
H aHeH lies in kergp, then
 aHgp(eH) = 0 in G p(V ). But the list of images gp(eH) forms a basis of the free k-
module G p(V ), so that all the coefÔ¨Åcients aH = 0. Therefore, kergp = {0}, and so gp is
a k-isomorphism.
DeÔ¨Åne Œ≥ : ;(V ) ‚ÜíG(V ) by Œ≥ (n
p=0 u p) = n
p=0 gp(u p), so that Œ≥ (;p(V )) ‚äÜ
G p(V ). We are done if we can show that Œ≥ is an algebra map: Œ≥ (u ‚àßv) = Œ≥ (u)Œ≥ (v). But
this is clear for homogeneous elements of ;(V ), and hence it is true for all elements.
‚Ä¢
Corollary 9.141.
If V is a free k-module with basis e1, . . . , en, then
<n(V ) = ‚ü®e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen‚ü©‚àº= k.
Proof.
By Proposition 9.137, we know that ;n(V ) is a cyclic module generated by
e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen, but we cannot conclude from this proposition whether or not this element
is zero. However, the binomial theorem not only says that this element is nonzero; it also
says that it generates a cyclic module isomorphic to k.
‚Ä¢
Proposition 7.43 says that if T : kMod ‚ÜíkMod is an additive functor, then T (V ‚äïV ‚Ä≤)
‚àº= T (V ) ‚äïT (V ‚Ä≤). It follows, for p ‚â•2, that ;p is not an additive functor: if V is a free
k-module of rank n, then ;p(V ‚äïV ) is free of rank
2n
p

, whereas ;p(V ) ‚äï;p(V ) is
free of rank 2
n
p

.
An astute reader will have noticed that our construction of a Grassmann algebra G(V )
depends not only on the free k-module V but also on a choice of basis of V . Had we chosen
a second basis of V , would the second Grassmann algebra be isomorphic to the Ô¨Årst one?
Corollary 9.142.
Let V be a free k-module, and let B and B‚Ä≤ be bases of V . If G(V )
is the Grassmann algebra deÔ¨Åned using B and if G‚Ä≤(V ) is the Grassmann algebra deÔ¨Åned
using B‚Ä≤, then G(V ) ‚àº= G‚Ä≤(V ) as graded k-algebras.

Sec. 9.8
Exterior Algebra
751
Proof.
Both G(V ) and G‚Ä≤(V ) are isomorphic to ;(V ), and the latter has been deÔ¨Åned
without any choice of basis.
‚Ä¢
A second proof of the binomial theorem follows from the next result.
Theorem 9.143.
For all p ‚â•0 and all k-modules A and B, where k is a commutative
ring,
<p(A ‚äïB) ‚àº=
p

i=0
<i(A) ‚äók
<p‚àíi(B)

.
Sketch of Proof.
Let A be the category of all alternating anticommutative graded k-
algebras R = 
p‚â•0 R p (r2 = 0 for all r ‚ààR of odd degree and rs = (‚àí1)pqsr if r ‚ààR p
and s ‚ààSq); by Theorem 9.136, the exterior algebra ;(A) ‚ààobj(A) for every k-module
A. If R, S ‚ààobj(A), then one veriÔ¨Åes that R‚äók S = 
p‚â•0
p
i=0 Ri ‚äók S p‚àíi
‚ààobj(A);
using anticommutativity, a modest generalization of Proposition 9.101 shows that A has
coproducts.
We claim that (;, D) is an adjoint pair of functors, where ;: kMod ‚ÜíA sends A ‚Üí
;(A), and D : A ‚ÜíkMod sends 
p‚â•0 R p ‚ÜíR1, the terms of degree 1. If R = 
p R p,
then there is a map œÄR : ;(R1) ‚ÜíR; deÔ¨Åne œÑA,R : HomA(;(A), R) ‚ÜíHomk(A, R1)
by œï ‚ÜíœÄR(œï|A). It follows from Theorem 7.105 that ; preserves coproducts; that is,
;(A ‚äïB) ‚àº=
;(A) ‚äók
;(B), and so ;p(A ‚äïB) ‚àº=
p
i=0
;i(A) ‚äók
;p‚àíi(B)

.
‚Ä¢
Here is an explicit formula for an isomorphism. In ;3(A ‚äïB), we have
(a1 + b1) ‚àß(a2 + b2) ‚àß(a3 + b3) = a1 ‚àßa2 ‚àßa3 + a1 ‚àßb2 ‚àßa3
+ b1 ‚àßa2 ‚àßa3 + b1 ‚àßb2 ‚àßa3 + a1 ‚àßa2 ‚àßb3
+ a1 ‚àßb2 ‚àßb3 + b1 ‚àßa2 ‚àßb3 + b1 ‚àßb2 ‚àßb3.
By anticommutativity, this can be rewritten so that each a precedes all the b's:
(a1 + b1) ‚àß(a2 + b2) ‚àß(a3 + b3) = a1 ‚àßa2 ‚àßa3 ‚àía1 ‚àßa3 ‚àßb2
+ a2 ‚àßa3 ‚àßb1 + a3 ‚àßb1 ‚àßb2 + a1 ‚àßa2 ‚àßb3
+ a1 ‚àßb2 ‚àßb3 ‚àía2 ‚àßb1 ‚àßb3 + b1 ‚àßb2 ‚àßb3.
An i-shufÔ¨Çe is a partition of {1, 2, . . . , p} into two disjoint subsets ¬µ1 < . . . < ¬µi and
ŒΩ1 < . . . < ŒΩp‚àíi; it gives the permutation œÉ ‚ààSp with œÉ( j) = ¬µ j for j ‚â§i and
œÉ(i + ‚Ñì) = ŒΩ‚Ñìfor j = i + ‚Ñì> i. Each "mixed" term in (a1 + b1) ‚àß(a2 + b2) ‚àß(a3 + b3)
gives a shufÔ¨Çe, with the a's giving the ¬µ and the b's giving the ŒΩ; for example, a1 ‚àßb2 ‚àßa3
is a 2-shufÔ¨Çe and b1‚àßa2‚àßb3 is a 1-shufÔ¨Çe. Now sgn(œÉ) counts the total number of leftward
moves of a's so that they precede all the b's, and the reader may check that the signs in the
rewritten expansion are sgn(œÉ). DeÔ¨Åne f : ;p(A ‚äïB) ‚Üíp
i=0
;i(A) ‚äók
;p‚àíi(B)

by
f (a1 + b1, . . . , ap + bp) =
p

i=0
=

i-shufÔ¨Çes œÉ
sgn(œÉ)a¬µ1 ‚àß¬∑ ¬∑ ¬∑ ‚àßa¬µi ‚äóbŒΩ1 ‚àß¬∑ ¬∑ ¬∑ ‚àßbŒΩp‚àíi
>
.

752
Advanced Linear Algebra
Ch. 9
Corollary 9.144.
If k is a commutative ring and V is a free k-module of rank n, then
;p(V ) is a free k-module of rank
n
p

.
Proof.
Write V = k ‚äïB and use induction on rank(V ).
‚Ä¢
We will use exterior algebra in the next section to prove theorems about determinants,
but let us Ô¨Årst note a nice result when k is a Ô¨Åeld and, hence, k-modules are vector spaces.
Proposition 9.145.
Let k be a Ô¨Åeld, let V be a vector space over k, and let v1,. . .,vp
be vectors in V . Then v1 ‚àß¬∑ ¬∑ ¬∑ ‚àßvp = 0 in ;(V ) if and only if v1, . . . , vp is a linearly
dependent list.
Proof.
Since k is a Ô¨Åeld, a linearly independent list v1, . . . , vp can be extended to a basis
v1, . . . , vp, . . . , vn of V . By Corollary 9.141, v1 ‚àß¬∑ ¬∑ ¬∑ ‚àßvn Ã∏= 0. But v1 ‚àß¬∑ ¬∑ ¬∑ ‚àßvp is a
factor of v1 ‚àß¬∑ ¬∑ ¬∑ ‚àßvn, so that v1 ‚àß¬∑ ¬∑ ¬∑ ‚àßvp Ã∏= 0.
Conversely, if v1, . . . , vp is linearly dependent, there is some i with vi = 
jÃ∏=i a jv j,
where a j ‚ààk. Hence,
v1 ‚àß¬∑ ¬∑ ¬∑ ‚àßvi ‚àß¬∑ ¬∑ ¬∑ ‚àßvp = v1 ‚àß¬∑ ¬∑ ¬∑ ‚àß

jÃ∏=i
a jv j ‚àß¬∑ ¬∑ ¬∑ ‚àßvp
=

jÃ∏=i
a jv1 ‚àß¬∑ ¬∑ ¬∑ ‚àßv j ‚àß¬∑ ¬∑ ¬∑ ‚àßvp.
After expanding, each term has a repeated factor v j, and so this is 0.
‚Ä¢
We introduced exterior algebra, at the beginning of this section, by looking at Jacobians;
we now end this section by applying exterior algebra to differential forms. Let X be an
open connected21 subset of euclidean space Rn. A function f : X ‚ÜíR is called a C‚àû-
function if, for all p ‚â•1, the pth partials ‚àÇp f/‚àÇpxi exist for all i = 1, . . . , n, as do all the
mixed partials.
DeÔ¨Ånition.
If X is a connected open subset of Rn, deÔ¨Åne
A(X) = { f : X ‚ÜíR : f is a C‚àû-function}.
The condition that X be a connected open subset of Rn is present so that C‚àû-functions
are deÔ¨Åned. It is easy to see that A(X) is a commutative ring under pointwise operations:
f + g : x ‚Üíf (x) + g(x);
f g : x ‚Üíf (x)g(x).
In the free A(X)-module A(X)n of all n-tuples, rename the standard basis
dx1, . . . , dxn.
21A subset X is open if, for each x ‚ààX, there is some r > 0 so that all points y with distance |y ‚àíx| < r also
lie in X. An open subset X of Rn is connected if we can join any pair of points in X by a path lying wholly in X.

Sec. 9.8
Exterior Algebra
753
By the binomial theorem, each element œâ ‚àà;p(A(X)n) has a unique expression
œâ =

i1...i p
fi1...i pdxi1 ‚àß¬∑ ¬∑ ¬∑ ‚àßdxi p,
where fi1...i p ‚ààA(X) is a C‚àû-function on X and i1 . . . i p is an increasing p ‚â§n-list. We
write
$p(X) =
<p(A(X)n),
and we call its elements differential p-forms on X.
DeÔ¨Ånition.
The exterior derivative d p : $p(X) ‚Üí$p+1(X) is deÔ¨Åned as follows:
(i) If f ‚àà$0(X) = A(X), then d0 f = n
j=1
‚àÇf
‚àÇx j dx j;
(ii) If p ‚â•1 and œâ ‚àà$p(X), then œâ = 
i1...i p fi1...i pdxi1 ‚àß¬∑ ¬∑ ¬∑ ‚àßdxi p, and we deÔ¨Åne
d pœâ =

i1...i p
d0( fi1...i p) ‚àßdxi1 ‚àß¬∑ ¬∑ ¬∑ ‚àßdxi p.
If X is an open connected subset of Rn, the exterior derivatives give a sequence of
A(X)-maps, called the de Rham complex:
0 ‚Üí$0(X)
d0
‚Üí$1(X)
d1
‚Üí¬∑ ¬∑ ¬∑
dn‚àí1
‚Üí$n(X) ‚Üí0.
Proposition 9.146.
If X is a connected open subset of Rn, then
d p+1d p : $p(X) ‚Üí$p+2(X)
is the zero map for all p ‚â•0.
Proof.
It sufÔ¨Åces to prove that ddœâ = 0, where œâ = f dxI (we are using an earlier
abbreviation: dxI = dxi1 ‚àß¬∑ ¬∑ ¬∑ ‚àßdxi p, where I = i1, . . . , i p is an increasing p ‚â§n-list).
Now
ddœâ = d(d0 f ‚àßxI)
= d
=
i
‚àÇf
‚àÇxi
dxi ‚àßdxI
>
=

i

j
‚àÇ2 f
‚àÇxi‚àÇx j
dx j ‚àßdxi ‚àßdxI.
Compare the i, j and j, i terms in this double sum: The Ô¨Årst is
‚àÇ2 f
‚àÇxi‚àÇx j
dx j ‚àßdxi ‚àßdxI;

754
Advanced Linear Algebra
Ch. 9
the second is
‚àÇ2 f
‚àÇx j‚àÇxi
dxi ‚àßdx j ‚àßdxI .
But these cancel, for the mixed second partials are equal:
dxi ‚àßdx j = ‚àídx j ‚àßdxi.
‚Ä¢
Example 9.147.
Consider the special case of the de Rham complex for n = 3.
0 ‚Üí$0(X)
d0
‚àí‚Üí$1(X)
d1
‚àí‚Üí$2(X)
d2
‚àí‚Üí$3(X) ‚Üí0
If œâ ‚àà$0(X), then œâ = f (x, y, z) ‚ààA(X), and
d0 f = ‚àÇf
‚àÇx dx + ‚àÇf
‚àÇy dy + ‚àÇf
‚àÇz dz,
a 1-form resembling grad( f ).
If œâ ‚àà$1(X), then œâ = f dx + gdy + hdz, and a simple calculation gives d1œâ =
‚àÇg
‚àÇx ‚àí‚àÇf
‚àÇy
	
dx ‚àßdy +
‚àÇh
‚àÇy ‚àí‚àÇg
‚àÇz
	
dy ‚àßdz +
‚àÇf
‚àÇz ‚àí‚àÇh
‚àÇx
	
dz ‚àßdx,
a 2-form resembling curl(œâ).
If œâ ‚àà$2(X), then œâ = Fdy ‚àßdz + Gdz ‚àßdx + Hdx ‚àßdy. Now
d2œâ = ‚àÇF
‚àÇx + ‚àÇG
‚àÇy + ‚àÇH
‚àÇz ,
a 3-form resembling div(œâ).
These are not mere resemblances. Since $1(X) is a free A(X)-module with basis
dx, dy, dz, we see that d0œâ is grad(œâ) when œâ is a 0-form. Now $2(X) is a free A(X)-
module, but we now choose a basis
dx ‚àßdy, dy ‚àßdz, dz ‚àßdx
instead of the usual basis dx ‚àßdy, dx ‚àßdz, dy ‚àßdz; it follows that d1œâ is curl(œâ) in this
case. Finally, $3(X) has a basis dx ‚àßdy ‚àßdz, and so d3œâ is div(œâ) when œâ is a 2-form.
We have shown that the de Rham complex is
0 ‚Üí$0(X)
grad
‚àí‚Üí$1(X)
curl
‚àí‚Üí$2(X)
div
‚àí‚Üí$3(X) ‚Üí0.
Proposition 9.146 now gives the familiar identities from advanced calculus:
curl ¬∑ grad = 0
and
div ¬∑ curl = 0.

Sec. 9.8
Exterior Algebra
755
We call a 1-form œâ closed if dœâ = 0, and we call it exact if œâ = grad f for some
C‚àû-function f . More generally, call a p-form œâ closed if d pœâ = 0, and call it exact
if œâ = d p‚àí1œâ‚Ä≤ for some (p ‚àí1)-form œâ‚Ä≤. Thus, œâ ‚àà$p(X) is closed if and only if
œâ ‚ààker d p and œâ is exact if and only if œâ ‚ààim d p‚àí1. Therefore, the de Rham complex
is an exact sequence of A(X)-modules if and only if every closed form is exact; this is
the etymology of the adjective exact in "exact sequence." It can be proved that the de
Rham complex is an exact sequence whenever X is a simply connected open subset of
Rn. For any (not necessarily simply connected) space X, we have im grad ‚äÜker curl and
im curl ‚äÜker div, and the R-vector spaces ker curl/ im grad and ker div/ im curl are called
the cohomology groups of X.
‚óÄ
EXERCISES
9.85 Let G(V ) be the Grassmann algebra of a free k-module V , and let u = 
p u p ‚ààG(V ),
where u p ‚ààG p(V ) is homogeneous of degree p. If u is the conjugate of u in Theorem 9.139,
prove that u = 
p(‚àí1)pu p.
9.86
(i) Let p be a prime. Show that ;2(Ip ‚äïIp) Ã∏= 0, where Ip ‚äïIp is viewed as a Z-module
(i.e., as an abelian group).
(ii) Let D = Q/Z ‚äïQ/Z. Prove that ;2(D) = 0, and conclude that if i : Ip ‚äïIp ‚ÜíD is
an inclusion, then ;2(i) is not an injection.
9.87
(i) If k is a commutative ring and N is a direct summand of a k-module M, prove that
;p(N) is a direct summand of ;p(M) for all p ‚â•0.
Hint. Use Corollary 7.17 on page 434.
(ii) If k is a Ô¨Åeld and i : W ‚ÜíV is an injection of vector spaces over k, prove that ;p(i) is
an injection for all p ‚â•0.
9.88 Prove, for all p, that the functor ;p preserves surjections.
9.89 If P is a projective k-module, where k is a commutative ring, prove that ;q(P) is a projective
k-module for all q.
9.90 Let k be a Ô¨Åeld, and let V be a vector space over k. Prove that two linearly independent lists
u1, . . . , u p and v1, . . . , vp span the same subspace of V if and only if there is a nonzero c ‚ààk
with u1 ‚àß¬∑ ¬∑ ¬∑ ‚àßu p = cv1 ‚àß¬∑ ¬∑ ¬∑ ‚àßvp.
9.91 If U and V are R-modules over a commutative ring R and if U‚Ä≤ ‚äÜU and V ‚Ä≤ ‚äÜV are
submodules, prove that
(U ‚äóR V )/(U‚Ä≤ ‚äóR V + U ‚äóR V ‚Ä≤) ‚àº= (U/U‚Ä≤) ‚äóR V ‚äïU ‚äóR (V/V ‚Ä≤).
Hint.
Compute the kernel and image of œï : U ‚äóR V ‚Üí(U/U‚Ä≤) ‚äóR V ‚äïU ‚äóR (V/V ‚Ä≤)
deÔ¨Åned by œï : u ‚äóv ‚Üí(u + U‚Ä≤) ‚äóv + u ‚äó(v + V ‚Ä≤).
9.92 DeÔ¨Åne the symmetric algebra on a k-module M to be S(M) = T (M)/I, where I is the
two-sided ideal generated by all m ‚äóm‚Ä≤ ‚àím‚Ä≤ ‚äóm, where m, m‚Ä≤ ‚ààM.
(i) Prove that I is a graded ideal, so that S(M) is a graded k-algebra.
(ii) Prove that S(M) is commutative.

756
Advanced Linear Algebra
Ch. 9
9.93
(i) DeÔ¨Åne a free commutative k-algebra, and prove that if M is the free k-module with
basis X, then S(M) is the free commutative k-algebra on X. Conclude that S(M) is
independent of the choice of basis of the free k-module M.
(ii) DeÔ¨Åne k[X] to be the polynomial ring in commuting variables X if every u ‚ààk[X] has a
unique expression as a polynomial in Ô¨Ånitely many elements of X. Prove that if M is the
free k-module with basis X, then S(M) is the polynomial ring in commuting variables
X.22
(iii) Prove that if M is a free k-module of Ô¨Ånite rank n, then S p(M) is a free k-module of
rank
n+p‚àí1
p

.
Hint. Use the combinatorial fact that there are
n+p‚àí1
p

ways to distribute p identical
objects among n boxes.
(iv) Prove that every commutative k-algebra is a quotient of a free commutative k-algebra.
9.94 Let V be a Ô¨Ånite-dimensional vector space over a Ô¨Åeld k, and let q : V ‚Üík be a quadratic
form on V . DeÔ¨Åne the Clifford algebra C(V, q) as the quotient C(V, q) = T (V )/J, where
J is the two-sided ideal generated by all elements of the form v ‚äóv ‚àíq(v)1 (note that J is
not a graded ideal). For v ‚ààV , denote the coset v + J by [v], and deÔ¨Åne h : V ‚ÜíC(V, q) by
h(v) = [v]. Prove that C(V, q) is a solution to the following universal problem:
V
f

h  C(V, q),
f

A
where A is a k-algebra and f : V ‚ÜíA is a k-module map with f (v)2 = q(v) for all v ‚ààV .
If dim(V ) = n and q is nondegenerate, then it can be proved that dim(C(V, q)) = 2n. In
particular, if k = R and n = 2, then the Clifford algebra has dimension 4 and C(v, q) ‚àº= H,
the division ring of quaternions. Clifford algebras are used in the study of quadratic forms,
hence of orthogonal groups; see Jacobson, Basic Algebra II, pp. 228-245.
9.9 DETERMINANTS
We have been using familiar properties of determinants, even though the reader may have
seen their veriÔ¨Åcations only over a Ô¨Åeld and not over a general commutative ring. Since
determinants of matrices whose values lie in a commutative ring are of interest, the time
has come to establish these properties in general, for exterior algebra is now available to
help us.
If k is a commutative ring, we claim that every k-module map Œ≥ : k ‚Üík is just multi-
plication by some d ‚ààk: If Œ≥ (1) = d, then
Œ≥ (a) = Œ≥ (a1) = aŒ≥ (1) = ad = da
22In the fourth section of Chapter 6, we assumed the existence of this big polynomial ring in order to construct
the algebraic closure of a Ô¨Åeld.
Our earlier deÔ¨Ånition of k[x, y] as R[y], where R = k[x], was careless. For example, it does not follow that
k[x, y] = k[y, x], although these two rings are isomorphic. However, if M is the free k-module with basis x, y,
then y, x is also a basis of k-algebra M, and so k[x, y] = k[y, x].

Sec. 9.9
Determinants
757
for all a ‚ààk, because Œ≥ is a k-module map. Here is a slight generalization. If V = ‚ü®v‚ü©‚àº= k,
then every k-map Œ≥ : V ‚ÜíV has the form Œ≥ : av ‚Üídav, where Œ≥ (v) = dv. Suppose now
that V is a free k-module with basis e1, . . . , en; Corollary 9.141 shows that ;n(V ) is free
of rank 1 with generator e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen. It follows that every k-map Œ≥ : ;n(V ) ‚Üí;n(V )
has the form Œ≥ (a(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen)) = d(a(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen)).
DeÔ¨Ånition.
If V is a free k-module with basis e1, . . . , en, and if f : V ‚ÜíV is a k-
homomorphism, then the determinant of f , denoted by det( f ), is the element det( f ) ‚ààk
for which
<n( f ): e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen ‚Üíf (e1) ‚àß¬∑ ¬∑ ¬∑ ‚àßf (en)
= det( f )(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen).
If A = [ai j] is an n √ó n matrix with entries in k, then A deÔ¨Ånes a k-map f : kn ‚Üíkn
by f (x) = Ax, where x ‚ààkn is a column vector. If e1, . . . , en is the standard basis of
kn, then f (ei) = 
j a jie j, and the matrix A = [ai j] associated to f has ith column the
coordinates of f (ei) = Aei. We deÔ¨Åne det(A) = det( f ):
Ae1 ‚àß¬∑ ¬∑ ¬∑ ‚àßAen = det(A)(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen).
Thus, the wedge of the columns of A in ;n(kn) is a constant multiple of e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen, and
det(A) is that constant.
Example 9.148.
If
A =
a
c
b
d

,
then the wedge product of the columns of A is
(ae1 + be2) ‚àß(ce1 + de2) = ace1 ‚àße1 + ade1 ‚àße2 + bce2 ‚àße1 + bde2 ‚àße2
= ade1 ‚àße2 + bce2 ‚àße1
= ade1 ‚àße2 ‚àíbce1 ‚àße2
= (ad ‚àíbc)(e1 ‚àße2).
Therefore, det(A) = ad ‚àíbc.
‚óÄ
The reader has probably noticed that this calculation is a repetition of the calculation on
page 742 where we computed the Jacobian of a change of variables in a double integral.
The next example considers triple integrals.
Example 9.149.
Let us change variables in a triple integral

D f (x, y, z)dxdydz using equations:
x = F(u, v, w);
y = G(u, v, w);
z = H(u, v, w).

758
Advanced Linear Algebra
Ch. 9
Denote a basis of the tangent space T of f (x, y, z) at a point P = (x0, y0, z0) by dx, dy,
dz. T If du, dv, dw is another basis of T , then the chain rule deÔ¨Ånes a linear transformation
on T by the equations:
dx = Fudu + Fvdv + Fwdw
dy = Gudu + Gvdv + Gwdw
dz = Hudu + Hvdv + Hwdw.
If we write the differential dxdydz in the integrand as dx ‚àßdy ‚àßdz, then the change of
variables gives the new differential
dx ‚àßdy ‚àßdz = det
Ô£´
Ô£≠
Ô£Æ
Ô£∞
Fu
Fv
Fw
Gu
Gv
Gw
Hu
Hv
Hw.
Ô£π
Ô£ª
Ô£∂
Ô£∏du ‚àßdv ‚àßdw:
expand
(Fudu + Fvdv + Fwdw) ‚àß(Gudu + Gvdv + Gwdw) ‚àß(Hudu + Hvdv + Hwdw)
to obtain nine terms, three of which involve (du)2, (dv)2, or (dw)2, and hence are 0. Of
the remaining six terms, three have a minus sign, and it is now easy to see that this sum is
the determinant.
‚óÄ
Proposition 9.150.
Let k be a commutative ring.
(i) If I is the identity matrix, then det(I) = 1.
(ii) If A and B are n √ó n matrices with entries in k, then
det(AB) = det(A) det(B).
Proof.
Both results follow from ;n being a functor on kMod.
(i) The linear transformation corresponding to the identity matrix is 1kn, and every functor
takes identities to identities.
(ii) If f and g are the linear transformations on kn arising from A and B, respectively, then
f g is the linear transformation arising from AB. If we denote e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen by eN, then
det( f g)eN =
<n( f g)(eN)
=
<n( f )
<n(g)(eN)

=
<n( f )(det(g)eN)
= det(g)
<n( f )(eN)
= det( f ) det(g)eN;

Sec. 9.9
Determinants
759
the next to last equation uses the fact that ;n( f ) is a k-map. Therefore,
det(AB) = det( f g) = det( f ) det(g) = det(A) det(B).
‚Ä¢
Corollary 9.151.
If k is a commutative ring, then det: Matn(k) ‚Üík is the unique
alternating multilinear function with det(I) = 1.
Proof.
The deÔ¨Ånition of determinant (as the wedge of the columns) shows that it is an
alternating multilinear function det: √ón V ‚Üík, where V = kn, and the proposition
shows that det(I) = 1. The uniqueness of such a function follows from the universal
property of ;n.
√ónV
det‚Ä≤








h
 ;n(V )
f

k
If det‚Ä≤ is multilinear, then there exists a k-map f : ;n(V ) ‚Üík with f h = det‚Ä≤; if
det‚Ä≤(e1, . . . , en) = 1, then f (e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen) = 1. Since ;n(V ) ‚àº= k, every k-map
f : ;n(V ) ‚Üík is determined by f (e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen). Thus, the map f is the same for
det‚Ä≤ as it is for det, and so det‚Ä≤ = f h = det.
‚Ä¢
We now show that the determinant just deÔ¨Åned coincides with the familiar determinant
function.
Lemma 9.152.
Let e1, . . . , en be a basis of a free k-module, where k is a commutative
ring. If œÉ is a permutation of 1, 2, . . . , n, then
eœÉ(1) ‚àß¬∑ ¬∑ ¬∑ ‚àßeœÉ(n) = sgn(œÉ)(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen).
Proof.
Since m ‚àßm‚Ä≤ = ‚àím‚Ä≤ ‚àßm, it follows that interchanging adjacent factors in the
product e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen gives
e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßei ‚àßei+1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen = ‚àíe1 ‚àß¬∑ ¬∑ ¬∑ ‚àßei+1 ‚àßei ‚àß¬∑ ¬∑ ¬∑ ‚àßen.
More generally, if i < j, then we can interchange ei and e j by a sequence of interchanges
of adjacent factors, each of which causes a sign change. By Exercise 2.7 on page 50, this
can be accomplished with an odd number of interchanges of adjacent factors. Hence, for
any transposition œÑ ‚ààSn, we have
eœÑ(1) ‚àß¬∑ ¬∑ ¬∑ ‚àßeœÑ(n) = e1 ‚àß¬∑ ¬∑ ¬∑ ‚àße j ‚àß¬∑ ¬∑ ¬∑ ‚àßei ‚àß¬∑ ¬∑ ¬∑ ‚àßen
= ‚àí[e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßei ‚àß¬∑ ¬∑ ¬∑ ‚àße j ‚àß¬∑ ¬∑ ¬∑ ‚àßen]
= sgn(œÑ)(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen).
We prove the general statement by induction on m, where œÉ is a product of m transpo-
sitions. The base step having just been proven, we proceed to the inductive step. Write
œÉ = œÑ1œÑ2 ¬∑ ¬∑ ¬∑ œÑm+1, and denote œÑ2 ¬∑ ¬∑ ¬∑ œÑm+1 by œÉ ‚Ä≤. By the inductive hypothesis,
eœÉ ‚Ä≤(1) ‚àß¬∑ ¬∑ ¬∑ ‚àßeœÉ ‚Ä≤(n) = sgn(œÉ ‚Ä≤)e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen,

760
Advanced Linear Algebra
Ch. 9
and so
eœÉ(1) ‚àß¬∑ ¬∑ ¬∑ ‚àßeœÉ(n) = eœÑ1œÉ ‚Ä≤(1) ‚àß¬∑ ¬∑ ¬∑ ‚àßeœÑ1œÉ ‚Ä≤(n)
= ‚àíeœÉ ‚Ä≤(1) ‚àß¬∑ ¬∑ ¬∑ ‚àßeœÉ ‚Ä≤(n)
(base step)
= ‚àísgn(œÉ ‚Ä≤)(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen)
(inductive step)
= sgn(œÑ1) sgn(œÉ ‚Ä≤)(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen)
= sgn(œÉ)(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen).
‚Ä¢
Remark.
There is a simpler proof of this lemma in the special case when k is a Ô¨Åeld.
If k has characteristic 2, then Lemma 9.152 is obviously true, and so we may assume that
characteristic k is not 2. Let e1, . . . , en be the standard basis of kn. If œÉ ‚ààSn, deÔ¨Åne a
linear transformation œïœÉ : kn ‚Üíkn by œïœÉ : ei ‚ÜíeœÉ(i). Since œïœÉœÑ = œïœÉœïœÑ, as is easily
veriÔ¨Åed, there is a group homomorphism d : Sn ‚Üík√ó given by d : œÉ ‚Üídet(œïœÉ). If œÉ is a
transposition, then œÉ 2 = (1) and d(œÉ)2 = 1 in k√ó. Since k is a Ô¨Åeld, d(œÉ) = ¬±1. As every
permutation is a product of transpositions, it follows that d(œÉ) = ¬±1 for every permutation
œÉ, and so im(d) ‚â§{¬±1}. Now there are only two homomorphisms Sn ‚Üí{¬±1}: the
trivial homomorphism with kernel Sn and sgn. To show that d = sgn, it sufÔ¨Åces to show
d((1 2)) Ã∏= 1. But d((1 2)) = det(œï(1 2)); that is,
det(œï(1 2))(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen) = œï(1 2)(e1) ‚àß¬∑ ¬∑ ¬∑ ‚àßœï(1 2)(en)
= e2 ‚àße1 ‚àße3 ‚àß¬∑ ¬∑ ¬∑ ‚àßen
= ‚àí(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen).
Therefore, d((1 2)) = ‚àí1 Ã∏= 1, because k does not have characteristic 2, and so, for all
œÉ ‚ààSn, d(œÉ) = det(œïœÉ) = sgn(œÉ); that is, eœÉ(1) ‚àß¬∑ ¬∑ ¬∑‚àßeœÉ(n) = sgn(œÉ)(e1 ‚àß¬∑ ¬∑ ¬∑‚àßen).
‚óÄ
Proposition 9.153 (Complete Expansion).
Let e1, . . . , en be a basis of a free k-module,
where k is a commutative ring. If A = [ai j] is an n √ó n matrix with entries in k, then
det(A) =

œÉ‚ààSn
sgn(œÉ)aœÉ(1),1aœÉ(2),2 ¬∑ ¬∑ ¬∑ aœÉ(n),n.
Proof.
Expand the wedge of the columns of A:

j1
a j11e j1 ‚àß

j2
a j22e j2 ‚àß¬∑ ¬∑ ¬∑ ‚àß

jn
a jnne jn
=

j1, j2,..., jn
a j11e j1 ‚àßa j22e j2 ‚àß¬∑ ¬∑ ¬∑ ‚àßa jnne jn.
Any summand in which e jp = e jq must be 0, for it has a repeated factor, and so we may
assume, in any surviving term, that j1, j2, . . . , jn are all distinct; that is, there is some

Sec. 9.9
Determinants
761
permutation œÉ ‚ààSn with jr = œÉ(r) when 1 ‚â§r ‚â§n. The original product now has the
form

œÉ‚ààSn
aœÉ(1)1aœÉ(2)2 ¬∑ ¬∑ ¬∑ aœÉ(n)neœÉ(1) ‚àßeœÉ(2) ‚àß¬∑ ¬∑ ¬∑ ‚àßeœÉ(n).
By the lemma, eœÉ(1) ‚àßeœÉ(2) ‚àß¬∑ ¬∑ ¬∑ ‚àßeœÉ(n) = sgn(œÉ)(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen). Therefore, the wedge
of the columns is equal to

œÉ‚ààSn sgn(œÉ)aœÉ(1)1aœÉ(2)2 ¬∑ ¬∑ ¬∑ aœÉ(n)n

(e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen), and this
completes the proof.
‚Ä¢
Quite often, the complete expansion is taken as the deÔ¨Ånition of the determinant.
Corollary 9.154.
Let k be a commutative ring, and let A be an n √ó n matrix with entries
in k. If u ‚ààk, then det(uI ‚àíA) = f (u), where f (x) ‚ààk[x] is a monic polynomial of
degree n. Moreover, the coefÔ¨Åcient of xn‚àí1 in f (x) is ‚àítr(A).
Proof.
Let A = [ai j] and let B = [bi j], where bi j = uŒ¥i j‚àíai j (where Œ¥i j is the Kronecker
delta). By the proposition,
det(B) =

œÉ‚ààSn
sgn(œÉ)bœÉ(1),1bœÉ(2),2 ¬∑ ¬∑ ¬∑ bœÉ(n),n.
If œÉ = (1), then the corresponding term in the complete expansion is
b11b22 ¬∑ ¬∑ ¬∑ bnn =

i
(u ‚àíaii) = g(u),
where g(x) = 
i(x ‚àíaii) is a monic polynomial in k[x] of degree n. If œÉ Ã∏= (1), then the
œÉth term in the complete expansion cannot have exactly n ‚àí1 factors from the diagonal
of uI ‚àíA, for if œÉ Ô¨Åxes n ‚àí1 indices, then œÉ = (1). Therefore, the sum of the terms
over all œÉ Ã∏= (1) is either 0 or a polynomial in k[x] of degree at most n ‚àí2. It follows that
deg( f ) = n and that the coefÔ¨Åcient of xn‚àí1 is ‚àí
i aii = ‚àítr(A).
‚Ä¢
Proposition 9.155.
If A is an n √ó n matrix with entries in a commutative ring k, then
det(At) = det(A),
where At is the transpose of A.
Proof.
If A = [ai j], write the complete expansion of det(A) more compactly:
det(A) =

œÉ‚ààSn
sgn(œÉ)

i
aœÉ(i),i.
For any permutation œÑ ‚ààSn, we have i = œÑ( j) for all i, and so

i
aœÉ(i),i =

j
aœÉ(œÑ( j)),œÑ( j),

762
Advanced Linear Algebra
Ch. 9
for this merely rearranges the factors in the product. Choosing œÑ = œÉ ‚àí1 gives

j
aœÉ(œÑ( j)),œÑ( j) =

j
a j,œÉ ‚àí1( j).
Therefore,
det(A) =

œÉ‚ààSn
sgn(œÉ)

j
a j,œÉ ‚àí1( j).
Now sgn(œÉ) = sgn(œÉ ‚àí1) [if œÉ = œÑ1 ¬∑ ¬∑ ¬∑ œÑq, where the œÑ are transpositions, then œÉ ‚àí1 =
œÑq ¬∑ ¬∑ ¬∑ œÑ1]; moreover, as œÉ varies over Sn, so does œÉ ‚àí1. Hence, writing œÉ ‚àí1 = œÅ gives
det(A) =

œÅ‚ààSn
sgn(œÅ)

j
a j,œÅ( j).
Now write At = [bi j], where bi j = a ji. Then
det(At) =

œÅ‚ààSn
sgn(œÅ)

j
bœÅ( j), j =

œÅ‚ààSn
sgn(œÅ)

j
a j,œÅ( j) = det(A).
‚Ä¢
We have already seen that the eigenvalues Œ±1, . . . , Œ±n of an n √ón matrix A, with entries
in a Ô¨Åeld k, are the roots of the characteristic polynomial
œàA(x) = det(x I ‚àíA) ‚ààk[x].
We have seen that det(A) = 
i Œ±i, and we are now going to see that tr(A) = 
i Œ±i.
Proposition 9.156.
If A = [ai j] is an n √ó n matrix with entries in a Ô¨Åeld k, then
tr(A) = Œ±1 + Œ±2 + ¬∑ ¬∑ ¬∑ + Œ±n.
Proof.
In the complete expansion of det(x I ‚àíA), the diagonal corresponds to the term
(x ‚àíaœÉ(1),1)(x ‚àíaœÉ(2),2) ¬∑ ¬∑ ¬∑ (x ‚àíaœÉ(n),n) with œÉ the identity permutation. If œÉ Ã∏= 1, then
there are at least two terms off the diagonal, and so the degree of this term is at most n ‚àí2.
Therefore, the coefÔ¨Åcient bn‚àí1 of xn‚àí1 in the diagonal term, namely, ‚àí
i aii, coincides
with the coefÔ¨Åcient of xn‚àí1 in œàA(x), namely, ‚àí
i Œ±i = ‚àítr(A), where Œ±1, . . . , Œ±n are
the eigenvalues of A. On the other hand,
œàA(x) =

i
(x ‚àíŒ±i),
and so the coefÔ¨Åcient of xn‚àí1 is ‚àí
i Œ±i, as desired.
‚Ä¢
We know that similar matrices have the same determinant and the same trace. The next
corollary generalizes these facts, for all the coefÔ¨Åcients of their characteristic polynomials
coincide.

Sec. 9.9
Determinants
763
Corollary 9.157.
If A and B are similar n √ó n matrices with entries in a Ô¨Åeld k, then A
and B have the same characteristic polynomial.
Proof.
There is a nonsingular matrix P with B = P AP‚àí1, and
œàB(x) = det(x I ‚àíB)
= det(x I ‚àíP AP‚àí1)
= det

P(x I ‚àíA)P‚àí1
= det(P) det(x I ‚àíA) det(P)‚àí1
= det(x I ‚àíA)
= œàA(x).
‚Ä¢
DeÔ¨Ånition.
Let A be an n √ó n matrix with entries in a commutative ring k. If H =
i1, . . . , i p and L = j1, . . . , jp are increasing p ‚â§n-lists, then AH L is the p√ó p submatrix
[ast], where (s, t) ‚ààH √ó L. A minor of order p is the determinant of a p √ó p submatrix.
For example, every entry ai j is a minor of A = [ai j] of order 1. If
A =
Ô£Æ
Ô£∞
a11
a12
a13
a21
a22
a23
a31
a32
a33
Ô£π
Ô£ª,
then some minors of order 2 are
det
a11
a12
a21
a22

and det
a12
a13
a32
a33

.
In particular, if 1 ‚â§i ‚â§n, let i‚Ä≤ denote the increasing n ‚àí1 ‚â§n-list in which i is omitted;
thus, an (n ‚àí1) √ó (n ‚àí1) submatrix has the form Ai‚Ä≤ j‚Ä≤, and its determinant is a minor of
order n ‚àí1. Note that Ai‚Ä≤ j‚Ä≤ is the submatrix obtained from A by deleting its ith row and
jth column.
Lemma 9.158.
Let k be a commutative ring, and let xi1,. . ., xi p ‚ààkn be regarded as
columns of an n √ó p matrix A, where H = i1, . . . , i p is an increasing p ‚â§n-list. Then
xi1 ‚àß¬∑ ¬∑ ¬∑ ‚àßxi p =

L
det(AL,H)eL,
where L varies over all increasing p ‚â§n-lists.
Proof.
For ‚Ñì= 1, 2, . . . , p, write xi‚Ñì= 
t‚Ñìat‚Ñìi‚Ñìet‚Ñì, so that
xi1 ‚àß¬∑ ¬∑ ¬∑ ‚àßxi p =

t1
at1i1et1 ‚àß¬∑ ¬∑ ¬∑ ‚àß

tp
atpi petp
=

t1...tp
at1i1 ¬∑ ¬∑ ¬∑ atpi pet1 ‚àß¬∑ ¬∑ ¬∑ ‚àßetp.

764
Advanced Linear Algebra
Ch. 9
All terms involving a repeated index are 0, so that we may assume that the sum is over all
t1 . . . tp having no repetitions; that is, over all p-sublists T = {t1 . . . tp} of {1, 2, . . . , n}.
Collecting terms, we may rewrite the sum as

T

T ={t1,...,tp}
at1i1 ¬∑ ¬∑ ¬∑ atpi pet1 ‚àß¬∑ ¬∑ ¬∑ ‚àßetp.
For any Ô¨Åxed p-sublist T = {t1, . . . , tp}, let L = ‚Ñì1, ‚Ñì2, . . . , ‚Ñìp be the increasing p-
list consisting of the integers in T ; thus, there is a permutation œÉ ‚ààSp with ‚ÑìœÉ(1) =
t1, . . . , ‚ÑìœÉ(p) = tp. With this notation,

T ={t1,...,tp}
at1i1 ¬∑ ¬∑ ¬∑ atpi p(et1 ‚àß¬∑ ¬∑ ¬∑ ‚àßetp) =

œÉ‚ààSp
a‚ÑìœÉ(1)i1 ¬∑ ¬∑ ¬∑ a‚ÑìœÉ(p)i p(et1 ‚àß¬∑ ¬∑ ¬∑ ‚àßetp)
=

œÉ‚ààSp
sgn(œÉ)a‚ÑìœÉ(1)i1 ¬∑ ¬∑ ¬∑ a‚ÑìœÉ(p)i peL
= det(AL,H)eL.
‚Ä¢
Multiplication in the exterior algebra ;(V ) is determined by the products eH ‚àßeK
of pairs of basis elements. Let us introduce the following notation: If H = t1 . . . tp and
K = ‚Ñì1 . . . ‚Ñìq are disjoint increasing lists, then deÔ¨Åne œÑH,K to be the permutation that
rearranges the list t1 . . . tp, ‚Ñì1 . . . ‚Ñìq into an increasing list, denoted by H ‚àóK. DeÔ¨Åne
œÅH,K = sgn(œÑH,K ).
With this notation, Lemma 9.152 says that
eH ‚àßeK =

0
if H ‚à©K Ã∏= ‚àÖ
œÅH,K eH‚àóK
if H ‚à©K = ‚àÖ.
Example 9.159.
If H = 1, 3, 4 and K = 2, 6 are increasing lists, then
H ‚àóK = 1, 2, 3, 4, 6,
and
œÑH,K =
1
3
4
2
6
1
2
3
4
6
	
= (2 4 3).
Therefore,
œÅH,K = sgn œÑH,K = +1,
and
eH ‚àßeK =

e1 ‚àße3 ‚àße4

‚àß

e2 ‚àße6

= e1 ‚àße2 ‚àße3 ‚àße4 ‚àße6 = eH‚àóK .
‚óÄ

Sec. 9.9
Determinants
765
Proposition 9.160.
Let A = [ai j] be an n√ón matrix with entries in a commutative ring k.
(i) If I = i1, . . . , i p is an increasing p-list and xi1, . . . , xi p are the corresponding
columns of A, then denote xi1 ‚àß¬∑ ¬∑ ¬∑ ‚àßxi p by xI. If J = j1, . . . , jq is an increasing
q-list, then
xI ‚àßxJ =

H,K
œÅH,K det(AH,I) det(AK,J)eH‚àóK ,
where H ‚àóK is the increasing (p + q)-list formed from H ‚à™K when H ‚à©K = ‚àÖ.
(ii) Laplace23 expansion down the jth column: For each Ô¨Åxed j,
det(A) = (‚àí1)1+ ja1 j det(A1‚Ä≤ j‚Ä≤) + ¬∑ ¬∑ ¬∑ + (‚àí1)n+ janj det(An‚Ä≤ j‚Ä≤),
where Ai‚Ä≤ j‚Ä≤ is the (n ‚àí1) √ó (n ‚àí1) submatrix obtained from A by deleting its ith
row and jth column.
(iii) Laplace expansion across the ith row: For each Ô¨Åxed i,
det(A) = (‚àí1)i+1ai1 det(Ai‚Ä≤1‚Ä≤) + ¬∑ ¬∑ ¬∑ + (‚àí1)i+nain det(Ai‚Ä≤n‚Ä≤).
Proof.
(i) By the lemma,
xI ‚àßxJ =

H
det(AH,I)eH ‚àß

K
det(AK,J)eK
=

H,K
det(AH,I)eH ‚àßdet(AK,J)eK
=

H,K
det(AH,I) det(AK,J)eH ‚àßeK
=

H,K
œÅH,K det(AH,I) det(AK,J)eH‚àóK .
(ii) If I = j has only one element, and if J = j‚Ä≤ = 1, . . . , j, . . . , n is its complement,
then
x j ‚àßx j‚Ä≤ = x j ‚àßx1 ‚àß¬∑ ¬∑ ¬∑ ‚àß
x j ‚àß¬∑ ¬∑ ¬∑ ‚àßxn
= (‚àí1) j‚àí1x1 ‚àß¬∑ ¬∑ ¬∑ ‚àßxn
= (‚àí1) j‚àí1 det(A)e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen,
because j, 1, . . . , j, . . . , n can be put in increasing order by j ‚àí1 transpositions. On the
other hand, we can evaluate x j ‚àßx j‚Ä≤ using part (i):
x j ‚àßx j‚Ä≤ =

H,K
œÅH,K det(AH, j) det(AK, j‚Ä≤)eH‚àóK .
23After P. S. Laplace.

766
Advanced Linear Algebra
Ch. 9
In this sum, H has just one element, say, H = i, while K has n ‚àí1 elements; thus, K = ‚Ñì‚Ä≤
for some element ‚Ñì. Since eh ‚àße‚Ñì‚Ä≤ = 0 if {i} ‚à©‚Ñì‚Ä≤ Ã∏= ‚àÖ, we may assume that i /‚àà‚Ñì‚Ä≤;
that is, we may assume that ‚Ñì‚Ä≤ = i‚Ä≤. Now, det(Ai, j) = ai j (this is a 1 √ó 1 minor), while
det(AK, j‚Ä≤) = det(Ai‚Ä≤ j‚Ä≤); that is, Ai‚Ä≤ j‚Ä≤ is the submatrix obtained from A by deleting its jth
column and its ith row. Hence, if eN = e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen,
x j ‚àßx j‚Ä≤ =

H,K
œÅH,K det(AH, j) det(AK, j‚Ä≤)eH‚àóK
=

i
œÅi,i‚Ä≤ det(Ai j) det(Ai‚Ä≤ j‚Ä≤)eN
=

i
(‚àí1)i‚àí1ai j det(Ai‚Ä≤ j‚Ä≤)eN.
Therefore, equating both values for x j ‚àßx j‚Ä≤ gives
det(A) =

i
(‚àí1)i+ jai j det(Ai‚Ä≤ j‚Ä≤),
as desired.
(iii) Laplace expansion across the ith row of A is Laplace expansion down the ith column
of At, and so the result follows because det(At) = det(A).
‚Ä¢
Notice that we have just proved that Laplace expansion across any row or down any
column always has the same value; that is, the determinant is independent of the row or
column used for the expansion. The Laplace expansions resemble the sums arising in
matrix multiplication, and the following matrix was invented to make this resemblance a
reality.
DeÔ¨Ånition.
If A = [ai j] is an n √ó n matrix with entries in a commutative ring k, then the
adjoint24 of A is the matrix
adj(A) = [Ci j],
where
Ci j = (‚àí1)i+ j det(A j‚Ä≤i‚Ä≤).
The reversing of indices is deliberate. In words, adj(A) is the transpose of the matrix whose
i j entry is (‚àí1)i+ j det(Ai‚Ä≤ j‚Ä≤). We often call Ci j the i j-cofactor of A.
Corollary 9.161.
If A is an n √ó n matrix with entries in a commutative ring k, then
A adj(A) = det(A)I = adj(A)A.
24There is no connection between the adjoint of a matrix as just deÔ¨Åned and the adjoint of a matrix deÔ¨Åned on
an inner product space.

Sec. 9.9
Determinants
767
Proof.
Denote the i j entry of A adj(A) by bi j. The deÔ¨Ånition of matrix multiplication
gives
bi j =
n

p=1
aipC pj =
n

p=1
aip(‚àí1) j+p det(A j‚Ä≤ p‚Ä≤).
If j = i, then Proposition 9.160 gives
bii = det(A).
If j Ã∏= i, consider the matrix M obtained from A by replacing row j with row i. Of course,
det(M) = 0, for it has two identical rows. On the other hand, we may compute det(M)
using Laplace expansion across its "new" row j. All the submatrices M j‚Ä≤ p‚Ä≤ = A j‚Ä≤ p‚Ä≤, and
so all the corresponding cofactors of M and A are equal. The matrix entries of the new
row j are aip, so that
0 = det(M) = (‚àí1)i+1ai1 det(A j‚Ä≤1‚Ä≤) + ¬∑ ¬∑ ¬∑ + (‚àí1)i+nain det(A j‚Ä≤n‚Ä≤).
We have shown that A adj(A) is a diagonal matrix having each diagonal entry equal to
det(A).
The proof that det(A)I = adj(A)A is similar and it is left to the reader. [We could also
adapt the proof of Corollary 3.107, replacing vector spaces by free k-modules, or we could
show that adj(At) = adj(A)t.]
‚Ä¢
DeÔ¨Ånition.
An n √ó n matrix A with entries in a commutative ring k is invertible over k
if there is a matrix B with entries in k such that
AB = I = B A.
If k is a Ô¨Åeld, then invertible matrices are usually called nonsingular, and they are
characterized by having a nonzero determinant. Consider the matrix with entries in Z:
A =
3
1
1
1

.
Now det(A) = 2 Ã∏= 0, but it is not invertible over Z. Suppose
3
1
1
1
 a
c
b
d

=
3a + b
3c + d
a + b
c + d

.
If this product is I, then
3a + b = 1 = c + d
3c + d = 0 = a + b.
Hence, b = ‚àía and 1 = 3a + b = 2a; as there is no solution to 1 = 2a in Z, the matrix A
is not invertible over Z. Of course, A is invertible over Q.

768
Advanced Linear Algebra
Ch. 9
Proposition 9.162.
If k is a commutative ring and A ‚ààMatn(k), then A is invertible if
and only if det(A) is a unit in k.
Proof.
If A is invertible, then there is a matrix B with AB = I. Hence,
1 = det(I) = det(AB) = det(A) det(B);
this says that det(A) is a unit in k.
Conversely, assume that det(A) is a unit in k, so there is an element u ‚ààk with
u det(A) = 1. DeÔ¨Åne
B = uadj(A).
By Corollary 9.161,
AB = Auadj(A) = u det(A)I = I = uadj(A)A = B A.
Thus, A is invertible.
‚Ä¢
Here is a proof by exterior algebra of the computation of the determinant of a matrix in
block form.
Proposition 9.163.
Let k be a commutative ring, and let
X =
A
C
0
B

be an (m + n) √ó (m + n) matrix with entries in k, where A is an m √ó m submatrix, and B
is an n √ó n submatrix. Then
det(X) = det(A) det(B).
Proof.
Let e1, . . . , em+n be the standard basis of km+n, let Œ±1, . . . , Œ±m be the columns of
A (which are also the Ô¨Årst m columns of X), and let Œ≥i + Œ≤i be the (m + i)th column of X,
where Œ≥i is the ith column of C and Œ≤i is the ith column of B.
Now Œ≥i ‚àà‚ü®e1, . . . , em‚ü©, so that Œ≥i = m
j=1 c jie j. Therefore, if H = 1, 2, . . . , n,
eH ‚àßŒ≥i = eH ‚àß
m

j=1
c jie j = 0,
because each term has a repeated e j. Using associativity, we see that
eH ‚àß(Œ≥1 + Œ≤1) ‚àß(Œ≥2 + Œ≤2) ‚àß¬∑ ¬∑ ¬∑ ‚àß(Œ≥n + Œ≤n)
= eH ‚àßŒ≤1 ‚àß(Œ≥2 + Œ≤2) ‚àß¬∑ ¬∑ ¬∑ ‚àß(Œ≥n + Œ≤n)
= eH ‚àßŒ≤1 ‚àßŒ≤2 ‚àß¬∑ ¬∑ ¬∑ ‚àß(Œ≥n + Œ≤n)
= eH ‚àßŒ≤1 ‚àßŒ≤2 ‚àß¬∑ ¬∑ ¬∑ ‚àßŒ≤n.

Sec. 9.9
Determinants
769
Hence, if J = m + 1, m + 2, . . . , m + n,
det(X)eH ‚àßeJ = Œ±1 ‚àß¬∑ ¬∑ ¬∑ ‚àßŒ±m ‚àß(Œ≥1 + Œ≤1) ‚àß¬∑ ¬∑ ¬∑ ‚àß(Œ≥n + Œ≤n)
= det(A)eH ‚àß(Œ≥1 + Œ≤1) ‚àß¬∑ ¬∑ ¬∑ ‚àß(Œ≥n + Œ≤n)
= det(A)eH ‚àßŒ≤1 ‚àß¬∑ ¬∑ ¬∑ ‚àßŒ≤n
= det(A)eH ‚àßdet(B)eJ
= det(A) det(B)eH ‚àßeJ.
Therefore, det(X) = det(A) det(B).
‚Ä¢
Corollary 9.164.
If A = [ai j] is a triangular n √ó n matrix, that is, ai j = 0 for all i < j
(lower triangular) or ai j = 0 for all i > j (upper triangular), then
det(A) =
n

i=1
aii;
that is, det(A) is the product of the diagonal entries.
Proof.
An easy induction on n ‚â•1, using Laplace expansion down the Ô¨Årst column (for
upper triangular matrices) and the proposition for the inductive step.
‚Ä¢
Although the deÔ¨Ånition of determinant of a matrix A in terms of the wedge of its
columns gives an obvious algorithm for computing it, there is a more efÔ¨Åcient means of
calculating det(A) when its entries lie in a Ô¨Åeld. Using Gaussian elimination, there are
elementary row operations changing A into an upper triangular matrix T :
A ‚ÜíA1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíAr = T.
Keep a record of the operations used. For example, if A ‚ÜíA1 is an operation of Type I,
which multiplies a row by a unit c, then c det(A) = det(A1) and so det(A) = c‚àí1 det(A1);
if A ‚ÜíA1 is an operation of Type II, which adds a multiple of some row to another one,
then det(A) = det(A1); if A ‚ÜíA1 is an operation of Type III, which interchanges two
rows, then det(A) = ‚àídet(A1). Thus, the record allows us, eventually, to write det(A)
in terms of det(T ). But since T is upper triangular, det(T ) is the product of its diagonal
entries.
Another application of exterior algebra constructs the trace of a map.
DeÔ¨Ånition.
Let k be a commutative ring and let A be a k-algebra. A derivation of A is a
homomorphism d : A ‚ÜíA of k-modules for which
d(ab) = (da)b + a(db).
In words, a derivation acts like ordinary differentiation in calculus, for we are saying
that the product rule, ( f g)‚Ä≤ = f ‚Ä≤g + f g‚Ä≤, holds.

770
Advanced Linear Algebra
Ch. 9
Lemma 9.165.
Let k be a commutative ring, and let M be a k-module.
(i) If œï : M ‚ÜíM is a k-map, then there exists a unique derivation Dœï : T (M) ‚Üí
T (M), where T (M) is the tensor algebra on M, which is a graded map (of degree
0) with Dœï|M = œï; that is, for all p ‚â•0,
Dœï

T p(M)

‚äÜT p(M).
(ii) If œï : M ‚ÜíM is a k-map, then there exists a unique derivation dœï : ;(M) ‚Üí
;(M), which is a graded map (of degree 0) with dœï|M = œï; that is, for all p ‚â•0,
dœï
 p
<
(M)

‚äÜ
p
<
(M).
Proof.
(i) DeÔ¨Åne Dœï|k = 1k (recall that T 0(M) = k), and deÔ¨Åne Dœï|T 1(M) = œï (recall
that T 1(M) = M). If p ‚â•2, deÔ¨Åne D p
œï : T p(M) ‚ÜíT p(M) by
D p
œï (m1 ‚äó¬∑ ¬∑ ¬∑ ‚äóm p) =
p

i=1
m1 ‚äó¬∑ ¬∑ ¬∑ ‚äóœï(mi) ‚äó¬∑ ¬∑ ¬∑ ‚äóm p.
For each i, the ith summand in the sum is well-deÔ¨Åned, because it arises from the k-
multilinear function (m1, . . . , m p) ‚Üím1 ‚äó¬∑ ¬∑ ¬∑ ‚äóœï(mi) ‚äó¬∑ ¬∑ ¬∑ ‚äóm p; it follows that Dœï is
well-deÔ¨Åned.
It is clear that Dœï is a map of k-modules. To check that Dœï is a derivation, it sufÔ¨Åces to
consider its action on homogeneous elements u = u1 ‚äó¬∑ ¬∑ ¬∑ ‚äóu p and v = v1 ‚äó¬∑ ¬∑ ¬∑ ‚äóvq.
Dœï(uv) = Dœï(u1 ‚äó¬∑ ¬∑ ¬∑ ‚äóu p ‚äóv1 ‚äó¬∑ ¬∑ ¬∑ ‚äóvq)
=
p

i=1
u1 ‚äó¬∑ ¬∑ ¬∑ ‚äóœï(ui) ‚äó¬∑ ¬∑ ¬∑ ‚äóu p ‚äóv
+
q

j=1
u ‚äóv1 ‚äó¬∑ ¬∑ ¬∑ ‚äóœï(v j) ‚äó¬∑ ¬∑ ¬∑ ‚äóvq
= Dœï(u)v + uDœï(v)
We leave the proof of uniqueness to the reader.
(ii) DeÔ¨Åne dœï : ;(M) ‚Üí;(M) using the same formula as that for Dœï after replacing ‚äó
by ‚àß. To see that this is well-deÔ¨Åned, we must show that Dœï(J) ‚äÜJ, where J is the two-
sided ideal generated by all elements of the form m ‚äóm. It sufÔ¨Åces to prove, by induction
on p ‚â•2, that Dœï(J p) ‚äÜJ, where J p = J ‚à©T p(M). The base step p = 2 follows from
the identity, for a, b ‚ààM,
a ‚äób + b ‚äóa = (a + b) ‚äó(a + b) ‚àía ‚äóa ‚àíb ‚äób ‚ààJ.

Sec. 9.9
Determinants
771
The inductive step follows from the identity, for a, c ‚ààM and b ‚ààJ p‚àí1,
a ‚äób ‚äóc + J = ‚àía ‚äóc ‚äób + J
= c ‚äóa ‚äób + J
= ‚àíc ‚äób ‚äóa + J
‚Ä¢
Proposition 9.166.
Let k be a commutative ring, and let M be a Ô¨Ånitely generated free
k-module with basis e1, . . . , en. If œï : M ‚ÜíM is a k-map and dœï : ;(M) ‚Üí;(M) is
the derivation it determines, then
dœï

n<
(M) = tr(œï)eL,
where eL = e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßen.
Proof.
By Lemma 9.165(ii), we have dœï : ;n(M) ‚Üí;n(M). Since M is a free k-
module of rank n, the binomial theorem gives ;n(M) ‚àº= k. Hence, dœï(eL) = ceL for
some c ‚ààk; we now show that c = tr(œï). Now œï(ei) =  a jie j.
dœï(eL) =

r
e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßœï(er) ‚àß¬∑ ¬∑ ¬∑ ‚àßen
=

r
e1 ‚àß¬∑ ¬∑ ¬∑ ‚àß

a jre j ‚àß¬∑ ¬∑ ¬∑ ‚àßen
=

r
e1 ‚àß¬∑ ¬∑ ¬∑ ‚àßarrer ‚àß¬∑ ¬∑ ¬∑ ‚àßen
=

r
arreL
= tr(œï)eL.
‚Ä¢
EXERCISES
9.95 Let k be a commutative ring, and let V and W be free k-modules of ranks m and n, respectively.
(i) Prove that if f : V ‚ÜíV is a k-map, then
det( f ‚äó1W ) = [det( f )]n.
(ii) Prove that if f : V ‚ÜíV and g: W ‚ÜíW are k-maps, then
det( f ‚äóg) = [det( f )]n[det(g)]m.

772
Advanced Linear Algebra
Ch. 9
9.96
(i) Let z1, . . . , zn be elements in a commutative ring k, and consider the Vandermonde
matrix
V (z1, . . . , zn) =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
1
1
¬∑ ¬∑ ¬∑
1
z1
z2
¬∑ ¬∑ ¬∑
zn
z2
1
z2
2
¬∑ ¬∑ ¬∑
z2n
...
...
...
...
zn‚àí1
1
zn‚àí1
2
¬∑ ¬∑ ¬∑
zn‚àí1
n
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
.
Prove that det(V (z1, . . . , zn)) = 
i< j(z j ‚àízi).
(ii) If f (x) = 
i(x ‚àízi) has discriminant D, prove that D = det(V (z1, . . . , zn)).
(iii) Prove that if z1, . . . , zn are distinct elements of a Ô¨Åeld k, then V (z1, . . . , zn) is nonsin-
gular.
9.97 DeÔ¨Åne a tridiagonal matrix to be an n √ó n matrix of the form
T [x1, . . . , xn] =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
x1
1
0
0
¬∑ ¬∑ ¬∑
0
0
0
0
‚àí1
x2
1
0
¬∑ ¬∑ ¬∑
0
0
0
0
0
‚àí1
x3
1
¬∑ ¬∑ ¬∑
0
0
0
0
0
0
‚àí1
x4
¬∑ ¬∑ ¬∑
0
0
0
0
...
...
...
0
0
0
0
¬∑ ¬∑ ¬∑
xn‚àí3
1
0
0
0
0
0
0
¬∑ ¬∑ ¬∑
‚àí1
xn‚àí2
1
0
0
0
0
0
¬∑ ¬∑ ¬∑
0
‚àí1
xn‚àí1
1
0
0
0
0
¬∑ ¬∑ ¬∑
0
0
‚àí1
xn
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
.
(i) If Dn = det(T [x1, . . . , xn]), prove that D1 = x1, D2 = x1x2 + 1, and, for all n > 2,
Dn = xn Dn‚àí1 + Dn‚àí2.
(ii) Prove that if all xi = 1, then Dn = Fn+1, the nth Fibonacci number. (Recall that
F0 = 0, F1 = 1, and Fn = Fn‚àí1 + Fn‚àí2 for all n ‚â•2.)
9.98 If a matrix A is a direct sum of square blocks,
A = B1 ‚äï¬∑ ¬∑ ¬∑ ‚äïBt,
prove that det(A) = 
i det(Bi).
9.99 If A and B are n √ó n matrices with entries in a commutative ring R, prove that AB and B A
have the same characteristic polynomial.
Hint. (Goodwillie)
I
B
0
I
 0
0
A
AB
 I
‚àíB
0
I

=
B A
0
A
0

.
9.10 LIE ALGEBRAS
There are interesting examples of nonassociative algebras, the most important of which
are the Lie algebras. In the late nineteenth century, Sophus Lie (pronounced LEE) stud-
ied the solution space S of a system of partial differential equations using a group G of

Sec. 9.10
Lie Algebras
773
transformations of S. The underlying set of G is a differentiable manifold and the group
operation is a C‚àû-function; such groups are called Lie groups. The solution space is inti-
mately related to its Lie group G; in turn, G is studied using its Lie algebra, a considerably
simpler object, which arises as the tangent space at the identity element of G. Aside from
this fundamental reason for their study, Lie algebras turn out to be the appropriate way to
deal with families of linear transformations on a vector space (in contrast to the study of
canonical forms of a single linear transformation given in the Ô¨Årst sections of this chapter).
Moreover, the classiÔ¨Åcation of the simple Ô¨Ånite-dimensional complex Lie algebras, due to
W. Killing and E. Cartan at the turn of the twentieth century, served as a model for the re-
cent classiÔ¨Åcation of all Ô¨Ånite simple groups. It was C. Chevalley who recognized that one
could construct analogous families of Ô¨Ånite simple groups by imitating the construction of
simple Lie algebras.
Before giving the deÔ¨Ånition of a Lie algebra, let us Ô¨Årst present an allied deÔ¨Ånition. We
have already deÔ¨Åned derivations of rings; let us now generalize the notion a bit.
DeÔ¨Ånition.
Let k be a commutative ring. A not necessarily associative k-algebra A is a
k-module equipped with some multiplication A √ó A ‚ÜíA, denoted by (a, b) ‚Üíab, such
that
(i) a(b + c) = ab + ac
and
(b + c)a = ba + ca
for all a, b, c ‚ààA;
(ii) ua = au
for all u ‚ààk and a ‚ààA;
(iii) a(ub) = (au)b = u(ab)
for all u ‚ààk and a, b ‚ààA.
A derivation of A is a k-map d : A ‚ÜíA for which
d(ab) = (da)b + a(db).
Aside from ordinary differentiation in calculus, which is a derivation because the prod-
uct rule holds, ( f g)‚Ä≤ = f ‚Ä≤g + f g‚Ä≤, another example is provided by the R-algebra A of all
real valued functions f (x1, . . . , xn) of several variables. The partial derivatives ‚àÇ/‚àÇxi are
derivations, for i = 1, . . . , n.
The composite of two derivations need not be a derivation. For example, if d : A ‚ÜíA
is a derivation, then d2 = d ‚ó¶d : A ‚ÜíA satisÔ¨Åes the equation
d2( f g) = d2( f )g + 2d( f )d(g) + f d2(g);
the mixed term 2d( f )d(g) is the obstruction to d2 being a derivation. More generally, we
may generalize the Leibniz formula (Exercise 1.6 on page 12) from ordinary differentiation
on the ring of all C‚àû-functions to a derivation on any not necessarily associative algebra
A. If f, g ‚ààA, then
dn( f g) =
n

i=0
n
i
	
di f ¬∑ dn‚àíig.

774
Advanced Linear Algebra
Ch. 9
It is still worthwhile to compute the composite of two derivations d1 and d2. If A is a not
necessarily associative algebra and f, g ‚ààA, then
d1d2( f g) = d1 [(d2 f )g + f (d2g)]
= (d1d2 f )g + (d2 f )(d1g) + (d1 f )(d2g) + f (d1d2g).
Of course,
d2d1( f g) = (d2d1 f )g + (d1 f )(d2g) + (d2 f )(d1g) + f (d2d1g).
If we denote d1d2 ‚àíd2d1 by [d1, d2], then subtraction gives
[d1, d2]( f g) = ([d1, d2] f )g + f ([d1, d2]g);
that is, [d1, d2] = d1d2 ‚àíd2d1 is a derivation.
Example 9.167.
If k is a commutative ring, equip Matn(k) with the bracket operation:
[A, B] = AB ‚àíB A.
Of course, A and B commute if and only if [A, B] = 0. It is easy to Ô¨Ånd examples showing
that the bracket operation is not associative. However, for any Ô¨Åxed n √ó n matrix M, the
function
adM : Matn(k) ‚ÜíMatn(k),
deÔ¨Åned by
adM : A ‚Üí[M, A],
is a derivation:
[M, [A, B]] = [[M, A], B] + [A, [M, B]].
The veriÔ¨Åcation of this identity should be done once in one's life.
‚óÄ
The deÔ¨Ånition of Lie algebra involves a vector space with a multiplication generalizing
the "bracket."
DeÔ¨Ånition.
If k is a Ô¨Åeld, then a Lie algebra over k is a vector space L over k equipped
with a bilinear operation L √ó L ‚ÜíL, denoted by (a, b) ‚Üí[a, b] (and called bracket),
such that
(i) [a, a] = 0 for all a ‚ààL;
(ii) For each a ‚ààL, the function ada : b ‚Üí[a, b] is a derivation.

Sec. 9.10
Lie Algebras
775
For all u, v ‚ààL, bilinearity gives
[u + v, u + v] = [u, u] + [u, v] + [v, u] + [v, v],
which, when coupled with the Ô¨Årst axiom [a, a] = 0, gives
[u, v] = ‚àí[v, u];
that is, bracket is anticommutative. The second axiom is often written out in more detail.
If b, c ‚ààL, then their product in L is denoted by [b, c]; that ada is a derivation is to say
[a, [b, c]] = [[a, b], c] + [b, [a, c]];
rewriting,
[a, [b, c]] ‚àí[b, [a, c]] ‚àí[[a, b], c] = 0.
The anticommutativity from the Ô¨Årst axiom now gives the Jacobi identity:
[a, [b, c]] + [b, [c, a]] + [c, [a, b]] = 0
for all a, b, c ‚ààL.
Thus, a vector space L is a Lie algebra if and only if [a, a] = 0 for all a ‚ààL and the Jacobi
identity holds.
Here are some examples of Lie algebras.
Example 9.168.
(i) If V is a vector space over a Ô¨Åeld k, deÔ¨Åne [a, b] = 0 for all a, b ‚ààV . It is obvious that
V so equipped is a Lie algebra, and it is called an abelian Lie algebra.
(ii) In R3, deÔ¨Åne [u, v] = u √ó v, the vector product (or cross product) deÔ¨Åned in calculus.
It is routine to check that v √ó v = 0 and that the Jacobi identity holds, so that R3 is a Lie
algebra. This example may be generalized: For every Ô¨Åeld k, cross product can be deÔ¨Åned
on the vector space k3 making it a Lie algebra.
(iii) A subalgebra S of a Lie algebra L over a Ô¨Åeld k is a subspace that is closed under
bracket: If a, b ‚ààS, then [a, b] ‚ààS. It is easy to see that every subalgebra is itself a Lie
algebra.
(iv) If k is a Ô¨Åeld, then Matn(k) is a Lie algebra if we deÔ¨Åne bracket by
[A, B] = AB ‚àíB A.
We usually denote this Lie algebra by gl(n, k). This example is quite general, for it is a
theorem of I. D. Ado that every Ô¨Ånite-dimensional Lie algebra over a Ô¨Åeld k of character-
istic 0 is isomorphic to a subalgebra of gl(n, k) for some n (see Jacobson, Lie Algebras,
page 202).
(v) An interesting subalgebra of gl(n, k) is sl(n, k), which consists of all n √ó n matrices
of trace 0. In fact, if G is a Lie group whose associated Lie algebra is g, then there is
an analog of exponentiation g ‚ÜíG. In particular, if g = gl(n, C), then this map is

776
Advanced Linear Algebra
Ch. 9
exponentiation A ‚ÜíeA. Thus, Proposition 9.52(viii) shows that exponentiation sends
sl(n, C) into SL(n, C).
(vi) If A is any algebra over a Ô¨Åeld k, then
Der(A/k) = {all derivations d : A ‚ÜíA},
with bracket [d1, d2] = d1d2 ‚àíd2d1, is a Lie algebra.
It follows from the Leibniz rule that if k has characteristic p > 0, then d p is a derivation
for every d ‚ààDer(A/k), for
p
i

‚â°0 mod p whenever 0 < i < p. (This is an example of
what is called a restricted Lie algebra of characteristic p.)
There is a Galois theory for certain purely inseparable extensions, due to N. Jacobson
(see Jacobson, Basic Algebra II, pages 533-536). If k is a Ô¨Åeld of characteristic p > 0 and
E/k is a Ô¨Ånite purely inseparable extension of height 1, that is, Œ± p ‚ààk, for all Œ± ‚ààE,
then there is a bijection between the family of all intermediate Ô¨Åelds and the restricted Lie
subalgebras of Der(E/k), given by
B ‚ÜíDer(E/B);
the inverse of this function is given by
L ‚Üí

e ‚ààE : D(e) = 0 for all D ‚ààL

.
‚óÄ
Not surprisingly, all Lie algebras over a Ô¨Åeld k form a category.
DeÔ¨Ånition.
If L and L‚Ä≤ are Lie algebras over a Ô¨Åeld k, then a function f : L ‚ÜíL‚Ä≤ is a Lie
homomorphism if f is a k-linear transformation that preserves bracket: For all a, b ‚ààL,
f ([a, b]) = [ f a, f b].
DeÔ¨Ånition.
An ideal of a Lie algebra L is a subspace I such that [x, a] ‚ààI for every
x ‚ààL and a ‚ààI.
Even though a Lie algebra need not be commutative, its anticommutativity shows that
every left ideal (as just deÔ¨Åned) is necessarily a right ideal; that is, every ideal is two-sided.
A Lie algebra L is called simple if L Ã∏= {0} and L has no nonzero proper ideals.
DeÔ¨Ånition.
If I is an ideal in L, then the quotient L/I is the quotient space (considering
L as a vector space and I as a subspace) with bracket deÔ¨Åned by
[a + I, b + I] = [a, b] + I.
It is easy to check that this bracket on L/I is well-deÔ¨Åned. If a‚Ä≤ + I = a + I and
b‚Ä≤ + I = b + I, then a ‚àía‚Ä≤ ‚ààI and b ‚àíb‚Ä≤ ‚ààI, and so
[a‚Ä≤, b‚Ä≤] ‚àí[a, b] = [a‚Ä≤, b‚Ä≤] ‚àí[a‚Ä≤, b] + [a‚Ä≤, b] ‚àí[a, b]
= [a‚Ä≤, b‚Ä≤ ‚àíb] + [a‚Ä≤ ‚àía, b‚Ä≤] ‚ààI.

Sec. 9.10
Lie Algebras
777
Example 9.169.
(i) If f : L ‚ÜíL‚Ä≤ is a Lie homomorphism, then its kernel is deÔ¨Åned as usual:
ker f = {a ‚ààL : f (a) = 0}.
It is easy to see that ker f is an ideal in L.
Conversely, the natural map ŒΩ : L ‚ÜíL/I, deÔ¨Åned by a ‚Üía + I, is a Lie homomor-
phism whose kernel is I. Thus, a subspace of L is an ideal if and only if it is the kernel of
some Lie homomorphism.
(ii) If I and J are ideals in a Lie algebra L, then
I J =

r
[ir, jr] : ir ‚ààI and jr ‚ààJ

.
In particular, L2 = LL is the analog for Lie algebras of the commutator subgroup of a
group: L2 = {0} if and only if L is abelian.
(iii) There is an analog for Lie algebras of the derived series of a group. The derived series
of a Lie algebra L is deÔ¨Åned inductively:
L(0) = L;
L(n+1) = (L(n))2.
A Lie algebra L is called solvable if there is some n ‚â•0 with L(n) = {0}.
(iv) There is an analog for Lie algebras of the descending central series of a group. The
descending central series is deÔ¨Åned inductively:
L1 = L;
Ln+1 = LLn.
A Lie algebra L is called nilpotent if there is some n ‚â•0 with Ln = {0}.
‚óÄ
We merely mention the Ô¨Årst two theorems in the subject. If L is a Lie algebra and
a ‚ààL, then ada : L ‚ÜíL, given by ada : x ‚Üí[a, x], is a linear transformation on L
(viewed merely as a vector space). We say that a is ad-nilpotent if ada is a nilpotent
operator; that is, (ada)m = 0 for some m ‚â•1.
Theorem (Engel's Theorem).
(i) If L is a Ô¨Ånite-dimensional Lie algebra over any Ô¨Åeld k, then L is nilpotent if and
only if every a ‚ààL is ad-nilpotent.
(ii) If L is a Lie subalgebra of gl(n, k) all of whose elements A are nilpotent matrices,
then L can be put into strict upper triangular form (all diagonal entries are 0); that
is, there is a nonsingular matrix P so that P AP‚àí1 is strictly upper triangular for
every A ‚ààL.
Proof.
See Humphreys, Introduction to Lie Algebras and Representation Theory,
page 12.
‚Ä¢

778
Advanced Linear Algebra
Ch. 9
Compare Engel's theorem with Exercise 9.43(i) on page 682, which is the much sim-
pler version for a single nilpotent matrix. Nilpotent Lie algebras are so called because of
Engel's theorem; it is likely that nilpotent groups are so called by analogy. Corollary 5.48,
which states that every Ô¨Ånite p-group can be imbedded as a subgroup of unitriangular
matrices over Fp, may be viewed as a group-theoretic analog of Engel's theorem.
Theorem (Lie's Theorem).
Every solvable subalgebra L of gl(n, k), where k is an
algebraically closed Ô¨Åeld, can be put into (not necessarily strict) upper triangular form;
that is, there is a nonsingular matrix P so that P AP‚àí1 is upper triangular for every
A ‚ààL.
Proof.
See Humphreys, Introduction to Lie Algebras and Representation Theory,
page 16.
‚Ä¢
Further study of Lie algebras leads to the classiÔ¨Åcation of all Ô¨Ånite-dimensional sim-
ple Lie algebras, due to E. Cartan and W. Killing, over an algebraically closed Ô¨Åeld of
characteristic 0 (recently, the classiÔ¨Åcation of all Ô¨Ånite-dimensional simple Lie algebras in
characteristic p has been given, where p > 7). To each such algebra, they associated a
certain geometric conÔ¨Åguration called a root system, which is characterized by a Cartan
matrix. Cartan matrices are, in turn, characterized by Dynkin diagrams.
An, n ‚â•1 :
‚Ä¢
1
‚Ä¢
2
¬∑ ¬∑ ¬∑
‚Ä¢
n‚àí1
‚Ä¢
n
Bn, n ‚â•2 :
‚Ä¢
1
‚Ä¢
2
¬∑ ¬∑ ¬∑
‚Ä¢
n‚àí1
 
‚Ä¢
n
Cn, n ‚â•3 :
‚Ä¢
1
‚Ä¢
2
¬∑ ¬∑ ¬∑
‚Ä¢
n‚àí1

‚Ä¢
n
‚Ä¢
n‚àí1
Dn, n ‚â•4 :
‚Ä¢
1
‚Ä¢
2
¬∑ ¬∑ ¬∑
‚Ä¢
n‚àí2


















‚Ä¢
n
‚Ä¢
E6 :
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
E7 :
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢

Sec. 9.10
Lie Algebras
779
‚Ä¢
E8 :
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
F4 :
‚Ä¢
‚Ä¢
 
‚Ä¢
‚Ä¢
G2 :
‚Ä¢

‚Ä¢
Every Dynkin diagram arises from a simple Lie algebra over C, and two such algebras
are isomorphic if and only if they have the same Dynkin diagram. We refer the reader
to Humphreys, Introduction to Lie Algebras and Representation Theory, Chapter IV, and
Jacobson, Lie Algebras, Chapter IV.
There are other not necessarily associative algebras of interest. Jordan algebras are
commutative algebras A in which the Jacobi identity is replaced by
(x2y)x = x2(yx)
for all x, y ‚ààA. They were introduced by P. Jordan to provide an algebraic setting for
doing quantum mechanics. An example of a Jordan algebra is a subspace of all n √ó n
matrices, over a Ô¨Åeld of characteristic not 2, equipped with the binary operation A ‚àóB,
where
A ‚àóB = 1
2(AB + B A).
Another source of not necessarily associative algebras comes from combinatorics. The
usual construction of a projective plane P(k) over a Ô¨Åeld k, as the family of all lines in
k3 passing through the origin, leads to descriptions of its points by "homogeneous coor-
dinates" [x, y, z], where x, y, z ‚ààk. DeÔ¨Åne an abstract projective plane to be an ordered
pair (X, L), where X is a Ô¨Ånite set and L is a family of subsets of X, called lines, subject
to the following axioms:
(i) All lines have the same number of points;
(ii) Given any two points in X, there is a unique line containing them.
We want to introduce homogeneous coordinates to describe the points of such a projective
plane, but there is no Ô¨Åeld k given at the outset. Instead, we look at a collection K of
functions on X, called collineations, and we equip K with two binary operations (called
addition and multiplication). In general, K is a not necessarily associative algebra, but
certain of its algebraic properties‚Äîcommutativity and associativity of multiplication‚Äî
correspond to geometric properties of the projective plane‚Äîa theorem of Pappus and a
theorem of Desargues, respectively.
An interesting nonassociative algebra is the Cayley numbers (sometimes called octo-
nions), which is an eight-dimensional real vector space containing the quaternions as a
subalgebra (see the article by Curtis in Albert, Studies in Modern Algebra). Indeed, Cay-
ley numbers form a real division not necessarily associative algebra in the sense that every
nonzero element has a multiplicative inverse. The Cayley numbers acquire added interest

780
Advanced Linear Algebra
Ch. 9
(as do other not necessarily associative algebras) because its automorphism group has in-
teresting properties. For example, the exceptional simple Lie algebra E8 is isomorphic to
the Lie algebra of all the derivations of the Cayley numbers, while the Monster, the largest
sporadic Ô¨Ånite simple group, is the automorphism group of a certain nonassociative algebra
constructed by R. Griess.
EXERCISES
9.100 Consider the de Rham complex when n = 2:
0 ‚Üí$0(X) d0
‚Üí$1(X) d1
‚Üí$2(X) ‚Üí0.
Prove that if f (x, y) ‚ààA(X) = $0(X), then
d0 f = ‚àÇf
‚àÇx dx + ‚àÇf
‚àÇy dy,
and that if Pdx + Qdy is a 1-form, then
d1(Pdx + Qdy) =
‚àÇQ
‚àÇx ‚àí‚àÇP
‚àÇy
	
dx ‚àßdy.
9.101 Prove that if L and L‚Ä≤ are nonabelian two-dimensional Lie algebras, then L ‚àº= L‚Ä≤.
9.102
(i) Prove that the center of a Lie algebra L, deÔ¨Åned by
Z(L) = {a ‚ààL : [a, x] = 0 for all x ‚ààL},
is an abelian ideal in L.
(ii) Give an example of a Lie algebra L for which Z(L) = {0}.
(iii) If L is nilpotent and L Ã∏= {0}, prove that Z(L) Ã∏= {0}.
9.103 Prove that if L is an n-dimensional Lie algebra, then Z(L) cannot have dimension n ‚àí1.
(Compare Exercise 2.69 on page 95.)
9.104 Equip C3 with a cross product (using the same formula as the cross product on R3).
Prove that
C3 ‚àº= sl(2, C).

10
Homology
10.1 INTRODUCTION
When I was a graduate student, homological algebra was an unpopular subject. The
general attitude was that it was a grotesque formalism, boring to learn, and not very useful
once one had learned it. Perhaps an algebraic topologist was forced to know this stuff, but
surely no one else should waste time on it. The few true believers were viewed as workers
at the fringe of mathematics who kept tinkering with their elaborate machine, smoothing
out rough patches here and there.
This attitude changed dramatically when J.-P. Serre characterized regular local rings us-
ing homological algebra (they are the commutative noetherian local rings of "Ô¨Ånite global
dimension"), for this enabled him to prove that any localization of a regular local ring is
itself regular (until then, only special cases of this were known). At the same time, M.
Auslander and D. A. Buchsbaum completed work of M. Nagata by using global dimension
to prove that every regular local ring is a UFD.
In spite of its newfound popularity, homological algebra still "got no respect." For
example, the two theorems just mentioned used the notion of the global dimension of a ring
which, in turn, is deÔ¨Åned in terms of the homological dimension of a module. At that time,
I. Kaplansky offered a course in homological algebra. One of his students, S. Schanuel,
noticed that there is an elegant relation between different projective resolutions of the same
module (see Proposition 7.60). Kaplansky seized this result, nowadays called Schanuel's
lemma, for it allowed him to deÔ¨Åne the homological dimension of a module without having
Ô¨Årst to develop the fundamental constructs Ext and Tor of homological algebra, and he
was then able to prove the theorems of Serre and of Auslander-Buchsbaum (Kaplansky's
account of this course can be found in his book, Commutative Algebra). However, as more
applications were found and as more homology and cohomology theories were invented
to solve outstanding problems, resistance to homological algebra waned. Today, it is just
781

782
Homology
Ch. 10
another standard tool in a mathematician's kit.
The basic idea of homology comes from Green's theorem, where a double integral over
a region R with holes in it is equal to a line integral on the boundary of R. H. Poincar¬¥e
recognized that whether a topological space X has different kinds of holes is a kind of
connectivity. To illustrate, let us assume that X can be "triangulated;" that is, X can be
partitioned into Ô¨Ånitely many n-simplexes, where n ‚â•0: points are 0-simplexes, edges are
1-simplexes, triangles are 2-simplexes, tetrahedra are 3-simplexes, and there are higher-
dimensional analogs. The question to ask is whether a union of n-simplexes in X that
"ought" to be the boundary of some (n + 1)-simplex actually is such a boundary. For
example, when n = 0, two points a and b in X ought to be the boundary (endpoints)
of a path in X; if there is a path in X joining all points a and b, then X is called path
connected; if there is no such path, then X has a 0-dimensional hole. For an example of
a one-dimensional hole, let X be the punctured plane; that is, the plane with the origin
deleted. The perimeter of a triangle  ought to be the boundary of a 2-simplex, but this is
not so if  contains the origin in its interior; thus, X has a one-dimensional hole. If X were
missing a line segment containing the origin, or even a small disk containing the origin,
this hole would still be one-dimensional; we are not considering the size of the hole, but
the size of the possible boundary. We must keep our eye on the doughnut and not upon the
hole!
a
















b
d
c
For example, in the rectangle drawn above, consider the triangle [a, b, c] with vertices a,
b, c and edges [a, b], [b, c], [a, c]. Its boundary ‚àÇ[a, b, c] should be [a, b]+[b, c]+[c, a].
But edges are oriented (think of [a, c] as a path from a to c and [c, a] as the reverse path
from c to a), so let us write [c, a] = ‚àí[a, c]. Thus, the boundary is
‚àÇ[a, b, c] = [a, b] ‚àí[a, c] + [b, c].
Similarly, let us deÔ¨Åne the boundary of [a, b] to be its endpoints:
‚àÇ[a, b] = b ‚àía.
We note that
‚àÇ(‚àÇ[a, b, c]) = ‚àÇ([a, b] ‚àí[a, c] + [b, c])
= b ‚àía ‚àí(c ‚àía) + c ‚àíb
= 0.
The rectangle with vertices a, b, c, d is the union of two triangles [a, b, c] + [a, c, d], and
we check that its boundary is ‚àÇ[a, b, c] + ‚àÇ[a, c, d] (note that the diagonal [a, c] occurs

Sec. 10.1
Introduction
783
twice, with different signs, and so it cancels, as it should). We see that the formalism
suggests the use of signs to describe boundaries as certain linear combinations u of edges
or points for which ‚àÇ(u) = 0.
Such ideas lead to the following construction. For each n ‚â•0, consider all formal
linear combinations of n-simplexes; that is, form the free abelian group Cn(X) with basis
all n-simplexes, and call such linear combinations n-chains. Some of these n-chains ought
to be boundaries of some union of (n + 1)-simplexes; call them n-cycles (for example,
adding the three edges of a triangle, with appropriate choice of signs, is a 1-cycle). Certain
n-chains actually are boundaries, and these are called n-boundaries (if  is a triangle in the
punctured plane X, not having the origin in its interior, then the alternating sum of the edges
of  is a 1-boundary; on the other hand, if the origin does lie in the interior of , then the
alternating sum is a 1-cycle but not a 1-boundary). The family of all the n-cycles, Zn(X),
and the family of all the n-boundaries, Bn(X), are subgroups of Cn(X). A key ingredient
in the construction of homology groups is that the subgroups Zn and Bn can be deÔ¨Åned in
terms of homomorphisms: there are boundary homomorphisms ‚àÇn : Cn(X) ‚ÜíCn‚àí1(X)
with Zn = ker ‚àÇn and Bn = im ‚àÇn+1, and so there is a sequence of abelian groups and
homomorphisms
¬∑ ¬∑ ¬∑ ‚ÜíC3(X)
‚àÇ3
‚àí‚ÜíC2(X)
‚àÇ2
‚àí‚ÜíC1(X)
‚àÇ1
‚àí‚ÜíC0(X).
It turns out, for all n ‚â•1, that ‚àÇn‚àÇn+1 = 0, from which it follows that
Bn(X) ‚äÜZn(X).
The interesting group is the quotient group Zn(X)/Bn(X), denoted by Hn(X) and called
the nth homology1 group of X. What survives in this quotient group are the n-dimensional
holes; that is, those n-cycles that are not n-boundaries. For example, H0(X) = 0 means
that X is path connected: if there are two points a, b ‚ààX that are not connected by a
path, then a ‚àíb is a cycle that is not a boundary, and so the coset a ‚àíb + B0(X) is
a nonzero element of H0(X). For n ‚â•1, these groups measure more subtle kinds of
connectivity. Topologists modify this construction in two ways. They introduce homology
with coefÔ¨Åcients in an abelian group G by tensoring the sequence of chain groups by G
and then taking homology groups; they also consider cohomology with coefÔ¨Åcients in G
by applying the contravariant functor Hom( , G) to the sequence of chain groups and then
taking homology groups. Homological algebra arose in trying to compute and to Ô¨Ånd
relations between homology groups of spaces.
1I have not been able to discover the etymology of the mathematical term homology as used in this context.
The word "homology" comes from homo + logos, and it means "corresponding." Its Ô¨Årst usage as a mathematical
term occurred in projective geometry in the early 19th century, as the name of a speciÔ¨Åc type of collineation.
The earliest occurrence I have found for its usage in the sense of cycles and boundaries is in an article of
H. Poincar¬¥e: Analysis Situs, Journal de l'¬¥Ecole Polytechnique, Series II, First issue, 1895 (and Oeuvres, vol. 5),
but he does not explain why he chose the term. Emili Bifet has written, in a private communication, "Consider
the projective homology, between two distinct (hyper)planes, given by projection from an exterior point. This ho-
mology suggests (and provides) a natural way of deforming the boundary of a simplex contained in one plane into
the boundary of the corresponding simplex on the other one. Moreover, it suggests a natural way of deforming a
boundary into a point. This could be what Poincar¬¥e had in mind."

784
Homology
Ch. 10
We have already seen, in Proposition 7.51, that every left R-module M, where R is a
ring, has a description by generators and relations. There is an exact sequence
0 ‚Üíker œï
Œπ
‚àí‚ÜíF
œï
‚àí‚ÜíM ‚Üí0,
where F is a free left R-module and Œπ is the inclusion. If R is a PID, then ker œï is free,
because every submodule of a free module is itself free; if R is not a PID, then ker œï may
not be free. Now take generators and relations of ker œï: There is a free module F1 and an
exact sequence
0 ‚Üíker œà
Œ∫
‚àí‚ÜíF1
œà
‚àí‚Üíker œï ‚Üí0.
If we deÔ¨Åne F1 ‚ÜíF to be the composite Œπœà, then there is a second exact sequence
F1
Œπœà
‚àí‚ÜíF
œï
‚àí‚ÜíM ‚Üí0,
and, iterating this construction, there is a long exact sequence
¬∑ ¬∑ ¬∑ ‚ÜíF3 ‚ÜíF2 ‚ÜíF1 ‚ÜíF ‚ÜíM ‚Üí0.
We can view the submodules ker(Fn ‚ÜíFn‚àí1) as "relations on relations" (nineteenth cen-
tury algebraists called these higher relations syzygies). This long exact sequence resembles
the sequence of chain groups in topology. There are other contexts in which such exact
sequences exist; many algebraic structures give rise to a sequence of homology groups,
and these can be used to translate older theorems into the language of homology. Exam-
ples of such theorems are Hilbert's Theorem 90 about algebras (see Corollary 10.129),
Whitehead's lemmas about Lie algebras (see Jacobson, Lie Algebras, pages 77 and 89),
and Theorem 10.22, the Schur-Zassenhaus lemma, about groups. There are methods to
compute homology and cohomology groups, and this is the most important contribution of
homological algebra to this circle of ideas. Although we can calculate many things without
them, the most powerful method of computing homology groups uses spectral sequences.
When I was a graduate student, I always wanted to be able to say, nonchalantly, that such
and such is true "by the usual spectral sequence argument," but I never had the nerve.2 We
will sketch what spectral sequences are at the end of this chapter.
10.2 SEMIDIRECT PRODUCTS
We begin by investigating a basic problem in group theory. A group G having a normal
subgroup K can be "factored" into K and G/K; the study of extensions involves the in-
verse question: How much of G can be recovered from a normal subgroup K and the
quotient Q = G/K? For example, we know that |G| = |K||Q| if K and Q are Ô¨Ånite.
2This introduction is adapted from a review I wrote that appeared in Bulletin of the American Mathematical
Society, Vol. 33, pp. 473-475, 1996; it is reproduced by permission of the American Mathematical Society.

Sec. 10.2
Semidirect Products
785
Exactness of a sequence of nonabelian groups,
¬∑ ¬∑ ¬∑ ‚ÜíGn+1
dn+1
‚àí‚ÜíGn
dn
‚àí‚ÜíGn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ,
is deÔ¨Åned just as it is for abelian groups: im dn+1 = ker dn for all n. Of course, each ker dn
is a normal subgroup of Gn.
DeÔ¨Ånition.
If K and Q are groups, then an extension of K by Q is a short exact sequence
1 ‚ÜíK
i‚ÜíG
p‚ÜíQ ‚Üí1.
The notation K is to remind us of kernel, and the notation Q is to remind us of quotient.
There is an alternative usage of the term extension, which calls the (middle) group
G (not the short exact sequence) an extension if it contains a normal subgroup K1 with
K1 ‚àº= K and G/K1 ‚àº= Q. As do most people, we will use the term in both senses.
Example 10.1.
(i) The direct product K √ó Q is an extension of K by Q; it is also an extension of Q by K.
(ii) Both S3 and I6 are extensions of I3 by I2. On the other hand, I6 is an extension of I2
by I3, but S3 is not, for S3 contains no normal subgroup of order 2.
‚óÄ
We have just seen, for any given ordered pair of groups, that there always exists an
extension of one by the other (their direct product), but there may be other extensions as
well. The extension problem is to classify all possible extensions of a given pair of groups
K and Q.
In Chapter 5, on page 283, we discussed the relation between the extension problem
and the Jordan-H¬®older theorem. If a group G has a composition series
G = K0 ‚â•K1 ‚â•K2 ‚â•¬∑ ¬∑ ¬∑ ‚â•Kn‚àí1 ‚â•Kn = {1}
with simple factor groups Q1, . . . , Qn, where Qi = Ki‚àí1/Ki for all i ‚â•1, then G could
be recaptured from Qn, Qn‚àí1, . . . , Q1 by solving the extension problem n times. Now all
Ô¨Ånite simple groups have been classiÔ¨Åed, and so we could survey all Ô¨Ånite groups if we
could solve the extension problem.
Let us begin by recalling the partition of a group into the cosets of a subgroup. We have
already deÔ¨Åned a transversal of a subgroup K of a group G as a subset T of G consisting
of exactly one element from each coset3 Kt of K.
DeÔ¨Ånition.
If
1 ‚ÜíK ‚ÜíG
p
‚àí‚ÜíQ ‚Üí1
is an extension, then a lifting is a function ‚Ñì: Q ‚ÜíG, not necessarily a homomorphism,
with p‚Ñì= 1Q.
3We have been working with left cosets t K, but, in this chapter, the subgroup K will be a normal subgroup,
in which case t K = Kt for all t ‚ààG. Thus, using right cosets or left cosets is only a matter of convenience.

786
Homology
Ch. 10
Given a transversal, we can construct a lifting. For each x ‚ààQ, surjectivity of p
provides ‚Ñì(x) ‚ààG with p‚Ñì(x) = x; thus, the function x ‚Üí‚Ñì(x) is a lifting. Conversely,
given a lifting, we claim that im ‚Ñìis a transversal of K. If Kg is a coset, then p(g) ‚ààQ;
say, p(g) = x. Then p(g‚Ñì(x)‚àí1) = 1, so that a = g‚Ñì(x)‚àí1 ‚ààK and Kg = K‚Ñì(x).
Thus, every coset has a representative in ‚Ñì(Q). Finally, we must show that ‚Ñì(Q) does
not contain two elements in the same coset. If K‚Ñì(x) = K‚Ñì(y), then there is a ‚ààK
with a‚Ñì(x) = ‚Ñì(y). Apply p to this equation; since p(a) = 1, we have x = y and so
‚Ñì(x) = ‚Ñì(y).
The following group will arise in our discussion of extensions.
DeÔ¨Ånition.
Recall that an automorphism of a group K is an isomorphism K ‚ÜíK. The
automorphism group, denoted by Aut(K), is the group of all the automorphisms of K
with composition as operation.
Of course, extensions are deÔ¨Åned for arbitrary groups K, but we are going to restrict
our attention to the special case when K is abelian. If G is an extension of K by Q, it
would be confusing to write G multiplicatively and its subgroup K additively. Hence, we
shall use the following notational convention: Even though G may not be abelian, additive
notation will be used for the operation in G. Corollary 10.4 gives the main reason for this
decision.
Proposition 10.2.
Let
0 ‚ÜíK
i‚ÜíG
p‚ÜíQ ‚Üí1
be an extension of an abelian group K by a group Q, and let ‚Ñì: Q ‚ÜíG be a lifting.
(i) For every x ‚ààQ, conjugation Œ∏x : K ‚ÜíK, deÔ¨Åned by
Œ∏x : a ‚Üí‚Ñì(x) + a ‚àí‚Ñì(x),
is independent of the choice of lifting ‚Ñì(x) of x. [For convenience, we have assumed
that i is an inclusion; this merely allows us to write a instead of i(a).]
(ii) The function Œ∏ : Q ‚ÜíAut(K), deÔ¨Åned by x ‚ÜíŒ∏x, is a homomorphism.
Proof.
(i) Let us now show that Œ∏x is independent of the choice of lifting ‚Ñì(x) of x.
Suppose that ‚Ñì‚Ä≤(x) ‚ààG and p‚Ñì‚Ä≤(x) = x. There is b ‚ààK with ‚Ñì‚Ä≤(x) = ‚Ñì(x) + b [for
‚àí‚Ñì(x) + ‚Ñì‚Ä≤(x) ‚ààker p = im i = K]. Therefore,
‚Ñì‚Ä≤(x) + a ‚àí‚Ñì‚Ä≤(x) = ‚Ñì(x) + b + a ‚àíb ‚àí‚Ñì(x)
= ‚Ñì(x) + a ‚àí‚Ñì(x),
because K is abelian.
(ii) Now Œ∏x(a) ‚ààK because K ‚úÅG, so that each Œ∏x : K ‚ÜíK; also, Œ∏x is an automorphism
of K, because conjugations are automorphisms.

Sec. 10.2
Semidirect Products
787
It remains to prove that Œ∏ : Q ‚ÜíAut(K) is a homomorphism. If x, y ‚ààQ and a ‚ààK,
then
Œ∏x(Œ∏y(a)) = Œ∏x(‚Ñì(y) + a ‚àí‚Ñì(y)) = ‚Ñì(x) + ‚Ñì(y) + a ‚àí‚Ñì(y) ‚àí‚Ñì(x),
while
Œ∏xy(a) = ‚Ñì(xy) + a ‚àí‚Ñì(xy).
But ‚Ñì(x)+‚Ñì(y) and ‚Ñì(xy) are both liftings of xy, so that equality Œ∏xŒ∏y = Œ∏xy follows from
part (i).
‚Ä¢
Roughly speaking, the homomorphism Œ∏ tells "how" K is normal in G, for isomorphic
copies of a group can sit as normal subgroups of G in different ways. For example, let K
be a cyclic group of order 3 and let Q = ‚ü®x‚ü©be cyclic of order 2. If G = K √ó Q, then G
is abelian and K lies in the center of G. In this case, ‚Ñì(x) + a ‚àí‚Ñì(x) = a for all a ‚ààK
and Œ∏x = 1K . On the other hand, if G = S3, then K = A3 which does not lie in the center;
if ‚Ñì(x) = (1 2), then (1 2)(1 2 3)(1 2) = (1 3 2) and Œ∏x is not 1K .
The existence of a homomorphism Œ∏ equips K with a scalar multiplication making K
a left ZQ-module, where ZQ is the group ring whose elements are all 
x‚ààQ mxx for
mx ‚ààZ.
Proposition 10.3.
Let K and Q be groups with K abelian. Then a homomorphism
Œ∏ : Q ‚ÜíAut(K) makes K into a left ZQ-module if scalar multiplication is deÔ¨Åned by
xa = Œ∏x(a)
for all a ‚ààK and x ‚ààQ. Conversely, if K is a left ZQ-module, then x ‚ÜíŒ∏x deÔ¨Ånes a
homomorphism Œ∏ : Q ‚ÜíAut(K), where Œ∏x : a ‚Üíxa.
Proof.
DeÔ¨Åne scalar multiplication as follows. Each u ‚ààZQ has a unique expression of
the form u = 
x‚ààQ mxx, where mx ‚ààZ and almost all mx = 0; deÔ¨Åne

x
mxx

a =

x
mxŒ∏x(a) =

x
mx(xa).
We verify the module axioms. Since Œ∏ is a homomorphism, Œ∏(1) = 1K , and so 1a = Œ∏1(a)
for all a ‚ààK. That Œ∏x ‚ààAut(K) implies x(a + b) = xa + xb, from which it follows that
u(a + b) = ua + ub for all u ‚ààZQ. Similarly, we check easily that (u + v)a = ua + va
for u, v ‚ààZQ. Finally, (uv)a = u(va) will follow from (xy)a = x(ya) for all x, y ‚ààQ;
but
(xy)a = Œ∏xy(a) = Œ∏x(Œ∏y(a)) = Œ∏x(ya) = x(ya).
The proof of the converse is also routine.
‚Ä¢

788
Homology
Ch. 10
Corollary 10.4.
If
0 ‚ÜíK
i‚ÜíG
p‚ÜíQ ‚Üí1
is an extension of an abelian group K by a group Q, then K is a left ZQ-module if we
deÔ¨Åne
xa = ‚Ñì(x) + a ‚àí‚Ñì(x),
where ‚Ñì: Q ‚ÜíG is a lifting, x ‚ààQ, and a ‚ààK; moreover, the scalar multiplication is
independent of the choice of lifting ‚Ñì.
Proof.
Propositions 10.2 and 10.3.
‚Ä¢
From now on, we will abbreviate the term "left ZQ-module" to "Q-module."
Recall that a short exact sequence of left R-modules
0 ‚ÜíA
i‚ÜíB
p‚ÜíC ‚Üí0
is split if there exists a homomorphism j : C ‚ÜíB with pj = 1C; in this case, the middle
module is isomorphic to the direct sum A ‚äïC. Here is the analogous deÔ¨Ånition for groups.
DeÔ¨Ånition.
An extension of groups
0 ‚ÜíK
i‚ÜíG
p‚ÜíQ ‚Üí1
is split if there is a homomorphism j : Q ‚ÜíG with pj = 1Q. The middle group G in a
split extension is called a semidirect product of K by Q.
Thus, an extension is split if and only if there is a lifting, namely, j, that is also a
homomorphism. We shall use the following notation: The elements of K shall be denoted
by a, b, c, . . ., and the elements of Q shall be denoted by x, y, z, . . . .
Proposition 10.5.
Let G be an additive group having a normal subgroup K.
(i) If 0 ‚ÜíK
i‚ÜíG
p‚ÜíQ ‚Üí1 is a split extension, where j : Q ‚ÜíG satisÔ¨Åes pj = 1Q,
then i(K) ‚à©j(Q) = {0} and i(K) + j(Q) = G.
(ii) In this case, each g ‚ààG has a unique expression g = i(a) + j(x), where a ‚ààK
and x ‚ààQ.
(iii) Let K and Q be subgroups of a group G with K ‚úÅG. Then G is a semidirect product
of K by Q if and only if K ‚à©Q = {0}, K + Q = G, and each g ‚ààG has a unique
expression g = a + x, where a ‚ààK and x ‚ààQ.
Proof.
(i) If g ‚àài(K) ‚à©j(Q), then g = i(a) = j(x) for a ‚ààK and x ‚ààQ. Now
g = j(x) implies p(g) = pj(x) = x, while g = i(a) implies p(g) = pi(a) = 0.
Therefore, x = 0 and g = j(x) = 0.
If g ‚ààG, then p(g) = pjp(g) (because pj = 1Q), and so g ‚àí( jp(g)) ‚ààker p = im i;
hence, there is a ‚ààK with g ‚àí( jp(g)) = i(a), and so g = i(a) + j(pg) ‚àài(K) + j(Q).

Sec. 10.2
Semidirect Products
789
(ii) Every element g ‚ààG has a factorization g = i(a)+ j(pg) because G = i(K)+ j(Q).
To prove uniqueness, suppose that i(a) + j(x) = i(b) + j(y), where b ‚ààK and y ‚ààQ.
Then ‚àíi(b) + i(a) = j(y) ‚àíj(x) ‚àài(K) ‚à©j(Q) = {0}, so that i(a) = i(b) and
j(x) = j(y).
(iii) Necessity is the special case of (ii) when both i and j are inclusions. Conversely, each
g ‚ààG has a unique factorization g = ax for a ‚ààK and x ‚ààQ; deÔ¨Åne p: G ‚ÜíQ by
p(ax) = x. It is easy to check that p is a surjective homomorphism with ker p = K.
‚Ä¢
A semidirect product is so called because a direct product G of K and Q requires, in
addition to K Q = G, and K ‚à©Q = {1}, that both subgroups K and Q be normal; here,
only one subgroup must be normal.
DeÔ¨Ånition.
If K ‚â§G and C ‚â§G satisÔ¨Åes C ‚à©K = {1} and KC = G, then C is called
a complement of K.
In a semidirect product G, the subgroup K is normal; on the other hand, the image j(Q),
which Proposition 10.5 shows to be a complement of K, may not be normal. For example,
if G = S3 and K = A3 = ‚ü®(1 2 3)‚ü©, we may take C = ‚ü®œÑ‚ü©, where œÑ is any transposition
in S3; this example also shows that complements need not be unique. However, any two
complements of K are isomorphic, for any complement of K is isomorphic to G/K.
The deÔ¨Ånition of semidirect product allows the kernel K to be nonabelian, and such
groups arise naturally. For example, the symmetric group Sn is a semidirect product of the
alternating group An by I2. In order to keep hypotheses uniform, however, let us assume
in the text (except in some exercises) that K is abelian, even though this assumption is not
always needed.
Example 10.6.
(i) A direct product K √ó Q is a semidirect product of K by Q (and also of Q by K).
(ii) An abelian group G is a semidirect product if and only if it is a direct product (usually
called a direct sum), for every subgroup of an abelian group is normal.
(iii) The dihedral group D2n is a semidirect product of In by I2. If D2n = ‚ü®a, b‚ü©, where
an = 1, b2 = 1, and bab = a‚àí1, then ‚ü®a‚ü©is a normal subgroup having ‚ü®b‚ü©as a comple-
ment.
(iv) Every Frobenius group is a semidirect product of its Frobenius kernel by its Frobenius
complement.
(v) Let G = H√ó, the multiplicative group of nonzero quaternions. It is easy to see that if
R+ is the multiplicative group of positive reals, then the norm N : G ‚ÜíR+, given by
N(a + bi + cj + dk) = a2 + b2 + c2 + d2,
is a homomorphism. There is a "polar decomposition" h = rs, where r > 0 and s ‚ààker N,
and G is a semidirect product of ker N by R+. (The normal subgroup ker N is the 3-
sphere.) In Exercise 10.4, we will see that ker N ‚àº= SU(2, C), the special unitary group.

790
Homology
Ch. 10
(vi) Cyclic groups of prime power order are not semidirect products, for they cannot be a
direct sum of two proper subgroups.
‚óÄ
DeÔ¨Ånition.
Let K be a Q-module. An extension G of K by Q realizes the operators if,
for all x ‚ààQ and a ‚ààK, we have
xa = ‚Ñì(x) + a ‚àí‚Ñì(x);
that is, the given scalar multiplication of ZQ on K coincides with the scalar multiplication
of Corollary 10.4 arising from conjugation.
Here is the construction.
DeÔ¨Ånition.
Let Q be a group and let K be a Q-module. DeÔ¨Åne
G = K ‚ãäQ
to be the set of all ordered pairs (a, x) ‚ààK √ó Q with the operation
(a, x) + (b, y) = (a + xb, xy).
Notice that (a, 1) + (0, x) = (a, x) in K ‚ãäQ.
Proposition 10.7.
Given a group Q and a Q-module K, then G = K ‚ãäQ is a semidirect
product of K by Q that realizes the operators.
Proof.
We begin by proving that G is a group. For associativity,
[(a, x) + (b, y)] + (c, z) = (a + xb, xy) + (c, z)
= (a + xb + (xy)c, (xy)z).
On the other hand,
(a, x) + [(b, y) + (c, z)] = (a, x) + (b + yc, yz)
= (a + x(b + yc), x(yz)).
Of course, (xy)z = x(yz), because of associativity in Q. The Ô¨Årst coordinates are also
equal: Since K is a Q-module, we have
x(b + yc) = xb + x(yc) = xb + (xy)c.
Thus, the operation is associative. The identity element of G is (0, 1), for
(0, 1) + (a, x) = (0 + 1a, 1x) = (a, x),
and the inverse of (a, x) is (‚àíx‚àí1a, x‚àí1), for
(‚àíx‚àí1a, x‚àí1) + (a, x) = (‚àíx‚àí1a + x‚àí1a, x‚àí1x) = (0, 1).

Sec. 10.2
Semidirect Products
791
Therefore, G is a group, by Exercise 2.22 on page 61.
DeÔ¨Åne a function p: G ‚ÜíQ by p: (a, x) ‚Üíx. Since the only "twist" occurs in the
Ô¨Årst coordinate, p is a surjective homomorphism with ker p = {(a, 1): a ‚ààK}. If we
deÔ¨Åne i : K ‚ÜíG by i : a ‚Üí(a, 1), then
0 ‚ÜíK
i‚ÜíG
p‚ÜíQ ‚Üí1
is an extension. DeÔ¨Åne j : Q ‚ÜíG by j : x ‚Üí(0, x). It is easy to see that j is a
homomorphism, for (0, x) + (0, y) = (0, xy). Now pjx = p(0, x) = x, so that pj = 1Q,
and the extension splits; that is, G is a semidirect product of K by Q. Finally, G realizes
the operators: If x ‚ààQ, then every lifting of x has the form ‚Ñì(x) = (b, x) for some b ‚ààK,
and
(b, x) + (a, 1) ‚àí(b, x) = (b + xa, x) + (‚àíx‚àí1b, x‚àí1)
= (b + xa + x(‚àíx‚àí1b), xx‚àí1)
= (b + xa ‚àíb, 1)
= (xa, 1).
‚Ä¢
We return to the multiplicative notation for a moment. In the next proof, the reader will
see that the operation in K ‚ãäQ arises from the identity
(ax)(by) = a(xbx‚àí1)xy.
Theorem 10.8.
Let K be an abelian group. If a group G is a semidirect product of K by
a group Q, then there is a Q-module structure on K so that G ‚àº= K ‚ãäQ.
Proof.
Regard G as a group with normal subgroup K that has Q as a complement. We
continue writing G additively (even though it may not be abelian), and so will now write
its subgroup Q additively as well. If a ‚ààK and x ‚ààQ, deÔ¨Åne
xa = x + a ‚àíx;
that is, xa is the conjugate of a by x. By Proposition 10.5, each g ‚ààG has a unique
expression as g = a +x, where a ‚ààK and x ‚ààQ. It follows that œï : G ‚ÜíK ‚ãäQ, deÔ¨Åned
by œï : a + x ‚Üí(a, x), is a bijection. We now show that œï is an isomorphism.
œï((a + x) + (b + y)) = œï(a + x + b + (‚àíx + x) + y)
= œï(a + (x + b ‚àíx) + x + y)
= (a + xb, x + y)
The deÔ¨Ånition of addition in K ‚ãäQ now gives
(a + xb, x + y) = (a, x) + (b, y)
= œï(a + x) + œï(b + y).
‚Ä¢
We now use semidirect products to construct some groups.

792
Homology
Ch. 10
Example 10.9.
If K = ‚ü®a‚ü©‚àº= I3, then an automorphism of K is completely determined by the image
of the generator a; either a ‚Üía and the automorphism is 1K , or a ‚Üí2a. Therefore,
Aut(K) ‚àº= I2; let us denote its generator by œï, so that œï(a) = 2a and œï(2a) = a; that is, œï
multiplies by 2. Let Q = ‚ü®x‚ü©‚àº= I4, and deÔ¨Åne Œ∏ : Q ‚ÜíAut(K) by Œ∏x = œï; hence
xa = 2a and x2a = a.
The group
T = I3 ‚ãäI4
is a group of order 12. If we deÔ¨Åne s = (2a, x2) and t = (0, x), then the reader may check
that
6s = 0 and 2t = 3s = 2(s + t).
The reader knows four other groups of order 12. The fundamental theorem says there
are two abelian groups of this order: I12 ‚àº= I3 √ó I4 and I2 √ó I6 ‚àº= V √ó I3. Two nonabelian
groups of order 12 are A4 and S3 √ó I2 (Exercise 10.7 on page 794 asks the reader to prove
that A4 Ã∏‚àº= S3 √ó I2). The group T just constructed is a new example, and Exercise 10.17 on
page 812 says that every group of order 12 is isomorphic to one of these Ô¨Åve. [Note that
Exercise 2.85(ii) on page 113 states that D12 ‚àº= S3 √ó I2.]
‚óÄ
Example 10.10.
Let p be a prime and let K = Ip ‚äïIp. Hence, K is a vector space over Fp, and so
Aut(K) ‚àº= GL(K). We choose a basis a, b of K, and this gives an isomorphism Aut(K) ‚àº=
GL(2, p). Let Q = ‚ü®x‚ü©be a cyclic group of order p.
DeÔ¨Åne Œ∏ : Q ‚ÜíGL(2, p) by
Œ∏ : xn ‚Üí
1
0
n
1

for all n ‚ààZ. Thus,
xa = a + b and xb = b.
It is easy to check that the commutator x + a ‚àíx ‚àía = xa ‚àía = b, and so G = K ‚ãäQ
is a group of order p3 with G = ‚ü®a, b, x‚ü©; these generators satisfy relations
pa = pb = px = 0,
b = [x, a], and [b, a] = 0 = [b, x].
If p is odd, then we have the nonabelian group of order p3 and exponent p in Propo-
sition 5.45. If p = 2, then |G| = 8, and the reader is asked to prove, in Exercise 10.8 on
page 794, that G ‚àº= D8; that is, D8 ‚àº= V ‚ãäI2. In Example 10.6(iii), we saw that D8 is a
semidirect product of I4 by I2. Thus, V ‚ãäI2 ‚àº= I4 ‚ãäI2, and so a group can have different
factorizations as a semidirect product.
‚óÄ

Sec. 10.2
Semidirect Products
793
Example 10.11.
Let k be a Ô¨Åeld and let k√ó be its multiplicative group. Now k√ó acts on k by multiplication
(if a ‚ààk and a Ã∏= 0, then the additive homomorphism x ‚Üíax is an automorphism whose
inverse is x ‚Üía‚àí1x). Therefore, the semidirect product k ‚ãäk√ó is deÔ¨Åned. In particular,
if (b, a), (d, c) ‚ààk ‚ãäk√ó, then
(b, a) + (d, c) = (ad + b, ac).
Recall that an afÔ¨Åne map is a function f : k ‚Üík of the form f : x ‚Üíax + b, where
a, b ‚ààk and a Ã∏= 0, and the collection of all afÔ¨Åne maps under composition is the group
Aff(1, k). Note that if g(x) = cx + d, then
( f ‚ó¶g)(x) = f (cx + d)
= a(cx + d) + b
= (ac)x + (ad + b).
It is now easy to see that the function œï : (b, a) ‚Üíf , where f (x) = ax + b, is an
isomomorphism k ‚ãäk√ó ‚ÜíAff(1, k).
‚óÄ
EXERCISES
In the Ô¨Årst three exercises, the group K need not be abelian; in all other exercises, it is assumed to be
abelian.
10.1 Kernels in this exercise may not be abelian groups.
(i) Prove that SL(2, F5) is an extension of I2 by A5 which is not a semidirect product.
(ii) If k is a Ô¨Åeld, prove that GL(n, k) is a semidirect product of SL(n, k) by k√ó.
Hint. A complement consists of all matrices diag{1, . . . , 1, a} with a ‚ààk√ó.
10.2 Let G be a group of order mn, where (m, n) = 1. Prove that a normal subgroup K of order m
has a complement in G if and only if there exists a subgroup C ‚â§G of order n. (Kernels in
this exercise may not be abelian groups.)
10.3 (Baer) Prove that a group G is injective4 in the category of all groups if and only if G = {1}.
(Kernels in this exercise may not be abelian groups.)
Hint. Let A be free with basis {x, y}, and let B be the semidirect product B = A‚ãä‚ü®z‚ü©, where
z is an element of order 2 that acts on A by zxz = y and zyz = x.
10.4 Let SU(2) be the special unitary group consisting of all complex matrices
 a b
c d

of determi-
nant 1 such that
ab + cd = 0,
aa + bb = 1,
cc + dd = 1.
If S is the subgroup of H√ó in Example 10.6(v), prove that S ‚àº= SU(2).
Hint. Use Exercise 8.2 on page 531.
4The term injective had not yet been coined when R. Baer, who introduced the notion of injective module,
proved this result. After recognizing that injective groups are duals of free groups, he jokingly called such groups
fascist, and he was pleased to note that they are trivial.

794
Homology
Ch. 10
10.5 Give an example of a split extension of groups
1 ‚ÜíK
i‚ÜíG
p‚ÜíQ ‚Üí1
for which there does not exist a homomorphism q : G ‚ÜíK with qi = 1K . Compare with
Exercise 7.17.
10.6 Prove that Q, the group of quaternions, is not a semidirect product.
Hint. Recall that Q has a unique element of order 2.
10.7
(i) Prove that A4 Ã∏‚àº= S3 √ó I2.
Hint. Use Proposition 2.64 saying that A4 has no subgroup of order 6.
(ii) Prove that no two of the nonabelian groups of order 12: A4, S3 √ó I2, and T are isomor-
phic. (See Example 10.9.)
(iii) The afÔ¨Åne group Aff(1, F4) (see Example 10.11) is a nonabelian group of order 12. Is
it isomorphic to A4, S3 √ó I2, or T = I3 ‚ãäI4?
10.8 Prove that the group G of order 8 constructed in Example 10.10 is isomorphic to D8.
10.9 If K and Q are solvable groups, prove that a semidirect product of K by Q is also solvable.
10.10 Let K be an abelian group, let Q be a group, and let Œ∏ : Q ‚ÜíAut(K) be a homomorphism.
Prove that K ‚ãäQ ‚àº= K √ó Q if and only if Œ∏ is the trivial map (Œ∏x = 1K for all x ‚ààQ).
10.11
(i) If K is cyclic of prime order p, prove that Aut(K) is cyclic of order p ‚àí1.
(ii) Let G be a group of order pq, where p > q are primes. If q ‚à§(p ‚àí1), prove that G is
cyclic. Conclude, for example, that every group of order 15 is cyclic.
10.12 Let G be an additive abelian p-group, where p is prime.
(i) If (m, p) = 1, prove that the function a ‚Üíma is an automorphism of G.
(ii) If p is an odd prime and G = ‚ü®g‚ü©is a cyclic group of order p2, prove that œï : G ‚ÜíG,
given by œï : a ‚Üí2a, is the unique automorphism with œï(pg) = 2pg.
10.3 GENERAL EXTENSIONS AND COHOMOLOGY
We now proceed to the study of the general extension problem: Given a group Q and an
abelian group K, Ô¨Ånd all (not necessarily split) extensions G of K by Q. In light of our
discussion of semidirect products, that is, of split extensions, it is reasonable to reÔ¨Åne the
problem by assuming that K is a Q-module and then to seek all those extensions realizing
the operators.
One way to describe a group G is to give a multiplication table for it; that is, to list all its
elements a1, a2, . . . and all products aia j. Indeed, this is how we constructed semidirect
products: the elements are all ordered pairs (a, x) with a ‚ààK and x ‚ààQ, and multiplica-
tion (really addition, because we have chosen to write G additively) is
(a, x) + (b, y) = (a + xb, xy).
O. Schreier, in 1926, solved the extension problem in this way, and we present his solution
in this section. The proof is not deep; rather, it involves manipulating and organizing a
long series of elementary calculations.

Sec. 10.3
General Extensions and Cohomology
795
We must point out, however, that Schreier's solution does not allow us to determine
the number of nonisomorphic middle groups G. Of course, this last question has no easy
answer. If a group G has order n, then there are n! different lists of its elements and hence
at most (n!)n different multiplication tables for G (there are n! possibilities for each of
the n rows). Suppose now that H is another group of order n. The problem of determin-
ing whether or not G and H are isomorphic is essentially the problem of comparing the
families of multiplication tables of each to see if there is one for G and one for H that
coincide.
Our strategy is to extract enough properties of a given extension G that will sufÔ¨Åce to
reconstruct G. Thus, we may assume that K is a Q-module, that G is an extension of K
by Q that realizes the operators, and that a transversal ‚Ñì: Q ‚ÜíG has been chosen. With
this initial data, we see that each g ‚ààG has a unique expression of the form
g = a + ‚Ñì(x),
a ‚ààK
and
x ‚ààQ;
this follows from G being the disjoint union of the cosets K + ‚Ñì(x). Furthermore, if
x, y ‚ààQ, then ‚Ñì(x) + ‚Ñì(y) and ‚Ñì(xy) are both representatives of the same coset (we do
not say these representatives are the same!), and so there is an element f (x, y) ‚ààK such
that
‚Ñì(x) + ‚Ñì(y) = f (x, y) + ‚Ñì(xy).
DeÔ¨Ånition.
Given a lifting ‚Ñì: Q ‚ÜíG, with ‚Ñì(1) = 0, of an extension G of K by Q,
then a factor set5 (or cocycle) is a function f : Q √ó Q ‚ÜíK such that
‚Ñì(x) + ‚Ñì(y) = f (x, y) + ‚Ñì(xy)
for all x, y ‚ààQ.
It is natural to choose liftings with ‚Ñì(1) = 0, and so we have incorporated this condition
into the deÔ¨Ånition of factor set; our factor sets are often called normalized factor sets.
Of course, a factor set depends on the choice of lifting ‚Ñì. When G is a split exten-
sion, then there exists a lifting that is a homomorphism; the corresponding factor set is
identically 0. Therefore, we can regard a factor set as the obstruction to a lifting being a
homomorphism; that is, factor sets describe how an extension differs from being a split
extension.
Proposition 10.12.
Let Q be a group, K a Q-module, and 0 ‚ÜíK ‚ÜíG ‚ÜíQ ‚Üí1 an
extension realizing the operators. If ‚Ñì: Q ‚ÜíG is a lifting with ‚Ñì(1) = 0 and f : Q√óQ ‚Üí
K is the corresponding factor set, then
(i) for all x, y ‚ààQ,
f (1, y) = 0 = f (x, 1);
5 If we switch to multiplicative notation, we see that a factor set occurs in the factorization ‚Ñì(x)‚Ñì(y) =
f (x, y)‚Ñì(xy).

796
Homology
Ch. 10
(ii) the cocycle identity holds: For all x, y, z ‚ààQ, we have
f (x, y) + f (xy, z) = x f (y, z) + f (x, yz).
Proof.
Set x = 1 in the equation that deÔ¨Ånes f (x, y),
‚Ñì(x) + ‚Ñì(y) = f (x, y) + ‚Ñì(xy),
to see that ‚Ñì(y) = f (1, y) + ‚Ñì(y) [since ‚Ñì(1) = 0, by our new assumption], and hence
f (1, y) = 0. Setting y = 1 gives the other equation of (i).
The cocycle identity follows from associativity in G. For all x, y, z ‚ààQ, we have
[‚Ñì(x) + ‚Ñì(y)] + ‚Ñì(z) = f (x, y) + ‚Ñì(xy) + ‚Ñì(z)
= f (x, y) + f (xy, z) + ‚Ñì(xyz).
On the other hand,
‚Ñì(x) + [‚Ñì(y) + ‚Ñì(z)] = ‚Ñì(x) + f (y, z) + ‚Ñì(yz)
= x f (y, z) + ‚Ñì(x) + ‚Ñì(yz)
= x f (y, z) + f (x, yz) + ‚Ñì(xyz).
‚Ä¢
It is more interesting that the converse is true. The next result generalizes the construc-
tion of K ‚ãäQ in Proposition 10.7.
Theorem 10.13.
Given a group Q and a Q-module K, a function f : Q √ó Q ‚ÜíK is a
factor set if and only if it satisÔ¨Åes the cocycle identity6
x f (y, z) ‚àíf (xy, z) + f (x, yz) ‚àíf (x, y) = 0
and f (1, y) = 0 = f (x, 1) for all x, y, z ‚ààQ.
More precisely, there is an extension G of K by Q realizing the operators, and there is
a transversal ‚Ñì: Q ‚ÜíG whose corresponding factor set is f .
Proof.
Necessity is Proposition 10.12. For the converse, deÔ¨Åne G to be the set of all
ordered pairs (a, x) in K √ó Q equipped with the operation
(a, x) + (b, y) = (a + xb + f (x, y), xy).
(Thus, if f is identically 0, then G = K ‚ãäQ.) The proof that G is a group is similar to the
proof of Proposition 10.7. The cocycle identity is used to prove associativity:

(a, x) + (b, y)

+ (c, z) = (a + xb + f (x, y), xy) + (c, z)
= (a + xb + f (x, y) + xyc + f (xy, z), xyz)
6Written as an alternating sum, this identity is reminiscent of the formulas describing geometric cycles as
described in Section 10.1.

Sec. 10.3
General Extensions and Cohomology
797
and
(a, x) +

(b, y) + (c, z)

= (a, x) + (b + yc + f (y, z), yz)
= (a + xb + xyc + x f (y, z) + f (x, yz), xyz).
The cocycle identity shows that these elements are equal.
We let the reader prove that the identity is (0, 1) and the inverse of (a, x) is
‚àí(a, x) = (‚àíx‚àí1a ‚àíx‚àí1 f (x, x‚àí1), x‚àí1).
DeÔ¨Åne p: G ‚ÜíQ by p: (a, x) ‚Üíx. Because the only "twist" occurs in the Ô¨Årst coordi-
nate, it is easy to see that p is a surjective homomorphism with ker p = {(a, 1) : a ‚ààK}.
If we deÔ¨Åne i : K ‚ÜíG by i : a ‚Üí(a, 1), then we have an extension 0 ‚ÜíK
i‚ÜíG
p‚Üí
Q ‚Üí1.
To see that this extension realizes the operators, we must show, for every lifting ‚Ñì, that
xa = ‚Ñì(x) + a ‚àí‚Ñì(x) for all a ‚ààK and x ‚ààQ. Now ‚Ñì(x) = (b, x) for some b ‚ààK and
‚Ñì(x) + (a, 1) ‚àí‚Ñì(x) = (b, x) + (a, 1) ‚àí(b, x)
= (b + xa, x) + (‚àíx‚àí1b ‚àíx‚àí1 f (x, x‚àí1), x‚àí1)
= (b + xa + x[‚àíx‚àí1b ‚àíx‚àí1 f (x, x‚àí1)] + f (x, x‚àí1), 1)
= (xa, 1).
Finally, we must show that f is the factor set determined by ‚Ñì. Choose the lifting
‚Ñì(x) = (0, x) for all x ‚ààQ. The factor set F determined by ‚Ñìis deÔ¨Åned by
F(x, y) = ‚Ñì(x) + ‚Ñì(y) ‚àí‚Ñì(xy)
= (0, x) + (0, y) ‚àí(0, xy)
= ( f (x, y), xy) + (‚àí(xy)‚àí1 f (xy, (xy)‚àí1), (xy)‚àí1)
= ( f (x, y) + xy[‚àí(xy)‚àí1 f (xy, (xy)‚àí1)] + f (xy, (xy)‚àí1), xy(xy)‚àí1)
= ( f (x, y), 1).
‚Ä¢
The next result shows that we have found all the extensions of a Q-module K by a
group Q.
DeÔ¨Ånition.
Given a group Q, a Q-module K, and a factor set f , let G(K, Q, f ) denote
the middle group of the extension of K by Q constructed in Theorem 10.13.
Theorem 10.14.
Let Q be a group, let K be a Q-module, and let G be an extension of K
by Q realizing the operators. Then there exists a factor set f : Q √ó Q ‚ÜíK with
G ‚àº= G(K, Q, f ).

798
Homology
Ch. 10
Proof.
Let ‚Ñì: Q ‚ÜíG be a lifting, and let f : Q √ó Q ‚ÜíK be the corresponding factor
set: that is, for all x, y ‚ààQ, we have
‚Ñì(x) + ‚Ñì(y) = f (x, y) + ‚Ñì(xy).
Since G is the disjoint union of the cosets, G = !
x‚ààQ K + ‚Ñì(x), each g ‚ààG has a unique
expression g = a + ‚Ñì(x) for a ‚ààK and x ‚ààQ. Uniqueness implies that the function
œï : G ‚ÜíG(K, Q, f ), given by
œï : g = a + ‚Ñì(x) ‚Üí(a, x),
is a well-deÔ¨Åned bijection. We now show that œï is an isomorphism.
œï(a + ‚Ñì(x) + b + ‚Ñì(y)) = œï(a + ‚Ñì(x) + b ‚àí‚Ñì(x) + ‚Ñì(x) + ‚Ñì(y))
= œï(a + xb + ‚Ñì(x) + ‚Ñì(y))
= œï(a + xb + f (x, y) + ‚Ñì(xy))
= (a + xb + f (x, y), xy)
= (a, x) + (b, y)
= œï(a + ‚Ñì(x)) + œï(b + ‚Ñì(y)).
‚Ä¢
Remark.
For later use, note that if a ‚ààK, then œï(a) = œï(a + ‚Ñì(1)) = (a, 1) and,
if x ‚ààQ, then œï(‚Ñì(x)) = (0, x). This would not be so had we chosen a lifting ‚Ñìwith
‚Ñì(1) Ã∏= 0.
‚óÄ
We have now described all extensions in terms of factor sets, but factor sets are deter-
mined by liftings. Any extension has many different liftings, and so our description, which
depends on a choice of lifting, must have repetitions.
Lemma 10.15.
Given a group Q and a Q-module K, let G be an extension of K by
Q realizing the operators. Let ‚Ñìand ‚Ñì‚Ä≤ be liftings that give rise to factor sets f and f ‚Ä≤,
respectively. Then there exists a function h : Q ‚ÜíK with h(1) = 0 and, for all x, y ‚ààQ,
f ‚Ä≤(x, y) ‚àíf (x, y) = xh(y) ‚àíh(xy) + h(x).
Proof.
For each x ‚ààQ, both ‚Ñì(x) and ‚Ñì‚Ä≤(x) lie in the same coset of K in G, and so there
exists an element h(x) ‚ààK with
‚Ñì‚Ä≤(x) = h(x) + ‚Ñì(x).
Since ‚Ñì(1) = 0 = ‚Ñì‚Ä≤(1), we have h(1) = 0. The main formula is derived as follows:
‚Ñì‚Ä≤(x) + ‚Ñì‚Ä≤(y) = [h(x) + ‚Ñì(x)] + [h(y) + ‚Ñì(y)]
= h(x) + xh(y) + ‚Ñì(x) + ‚Ñì(y),

Sec. 10.3
General Extensions and Cohomology
799
because G realizes the operators. The equations continue,
‚Ñì‚Ä≤(x) + ‚Ñì‚Ä≤(y) = h(x) + xh(y) + f (x, y) + ‚Ñì(xy)
= h(x) + xh(y) + f (x, y) ‚àíh(xy) + ‚Ñì‚Ä≤(xy).
By deÔ¨Ånition, f ‚Ä≤ satisÔ¨Åes ‚Ñì‚Ä≤(x) + ‚Ñì‚Ä≤(y) = f ‚Ä≤(x, y) + ‚Ñì‚Ä≤(xy). Therefore,
f ‚Ä≤(x, y) = h(x) + xh(y) + f (x, y) ‚àíh(xy).
and so
f ‚Ä≤(x, y) ‚àíf (x, y) = xh(y) ‚àíh(xy) + h(x).
‚Ä¢
DeÔ¨Ånition.
Given a group Q and a Q-module K, a function g : Q √ó Q ‚ÜíK is called a
coboundary if there exists a function h : Q ‚ÜíK with h(1) = 0 such that, for all x, y ‚ààQ,
g(x, y) = xh(y) ‚àíh(xy) + h(x).
The term coboundary arises because its formula is an alternating sum analogous to the
formula for geometric boundaries that we described in Section 10.1.
We have just shown that if f and f ‚Ä≤ are factor sets of an extension G that arise from
different liftings, then f ‚Ä≤ ‚àíf is a coboundary.
DeÔ¨Ånition.
Given a group Q and a Q-module K, deÔ¨Åne
Z2(Q, K) = {all factor sets f : Q √ó Q ‚ÜíK}
and
B2(Q, K) = {all coboundaries g : Q √ó Q ‚ÜíK}.
Proposition 10.16.
Given a group Q and a Q-module K, then Z2(Q, K) is an abelian
group with operation pointwise addition,
f + f ‚Ä≤ : (x, y) ‚Üíf (x, y) + f ‚Ä≤(x, y),
and B2(Q, K) is a subgroup of Z2(Q, K).
Proof.
To see that Z2 is a group, it sufÔ¨Åces to prove that f ‚àíf ‚Ä≤ satisÔ¨Åes the two identities
in Proposition 10.12. This is obvious: Just subtract the equations for f and f ‚Ä≤.
To see that B2 is a subgroup of Z2, we must Ô¨Årst show that every coboundary g is
a factor set; that is, that g satisÔ¨Åes the two identities in Proposition 10.12. This, too, is
routine and is left to the reader. Next, we must show that B2 is a nonempty subset; but the
zero function, g(x, y) = 0 for all x, y ‚ààQ, is clearly a coboundary. Finally, we show that
B2 is closed under subtraction. If h, h‚Ä≤ : Q ‚ÜíK show that g and g‚Ä≤ are coboundaries, that
is, g(x, y) = xh(y) ‚àíh(xy) + h(x) and g‚Ä≤(x, y) = xh‚Ä≤(y) ‚àíh‚Ä≤(xy) + h‚Ä≤(x), then
(g ‚àíg‚Ä≤)(x, y) = x(h ‚àíh‚Ä≤)(y) ‚àí(h ‚àíh‚Ä≤)(xy) + (h ‚àíh‚Ä≤)(x).
‚Ä¢

800
Homology
Ch. 10
A given extension has many liftings and, hence, many factor sets, but the difference
of any two of these factor sets is a coboundary. Therefore, the following quotient group
suggests itself.
DeÔ¨Ånition.
The second cohomology group is deÔ¨Åned by
H2(Q, K) = Z2(Q, K)/B2(Q, K).
DeÔ¨Ånition.
Given a group Q and a Q-module K, two extensions G and G‚Ä≤ of K by Q
that realize the operators are called equivalent if there is a factor set f of G and a factor
set f ‚Ä≤ of G‚Ä≤ so that f ‚Ä≤ ‚àíf is a coboundary.
Proposition 10.17.
Given a group Q and a Q-module K, two extensions G and G‚Ä≤ of K
by Q that realize the operators are equivalent if and only if there exists an isomorphism
Œ≥ : G ‚ÜíG‚Ä≤ making the following diagram commute:
0
 K
i

1K

G
p

Œ≥

Q
1Q

 1
0
 K
i‚Ä≤
 G‚Ä≤
p‚Ä≤
 Q
 1
Remark.
A diagram chase shows that any homomorphism Œ≥ making the diagram com-
mute is necessarily an isomorphism.
‚óÄ
Proof.
Assume that the two extensions are equivalent. We begin by setting up notation.
Let ‚Ñì: Q ‚ÜíG and ‚Ñì‚Ä≤ : Q ‚ÜíG‚Ä≤ be liftings, and let f, f ‚Ä≤ be the corresponding factor sets;
that is, for all x, y ‚ààQ, we have
‚Ñì(x) + ‚Ñì(y) = f (x, y) + ‚Ñì(xy),
with a similar equation for f ‚Ä≤ and ‚Ñì‚Ä≤. Equivalence means that there is a function h : Q ‚ÜíK
with h(1) = 0 and
f (x, y) ‚àíf ‚Ä≤(x, y) = xh(y) ‚àíh(xy) + h(x)
for all x, y ‚ààQ. Since G = !
x‚ààQ K + ‚Ñì(x) is a disjoint union, each g ‚ààG has a unique
expression g = a + ‚Ñì(x) for a ‚ààK and x ‚ààQ; similarly, each g‚Ä≤ ‚ààG‚Ä≤ has a unique
expression g‚Ä≤ = a + ‚Ñì‚Ä≤(x).
This part of the proof generalizes that of Theorem 10.14. DeÔ¨Åne Œ≥ : G ‚ÜíG‚Ä≤ by
Œ≥ (a + ‚Ñì(x)) = a + h(x) + ‚Ñì‚Ä≤(x).
This function makes the diagram commute. If a ‚ààK, then
Œ≥ (a) = Œ≥ (a + ‚Ñì(1)) = a + h(1) + ‚Ñì‚Ä≤(1) = a;

Sec. 10.3
General Extensions and Cohomology
801
furthermore,
p‚Ä≤Œ≥ (a + ‚Ñì(x)) = p‚Ä≤(a + h(x) + ‚Ñì‚Ä≤(x)) = x = p(a + ‚Ñì(x)).
Finally, Œ≥ is a homomorphism:
Œ≥

[a + ‚Ñì(x)] + [b + ‚Ñì(y)]

= Œ≥ (a + xb + f (x, y) + ‚Ñì(xy))
= a + xb + f (x, y) + h(xy) + ‚Ñì‚Ä≤(xy),
while
Œ≥ (a + ‚Ñì(x)) + Œ≥ (b + ‚Ñì(y)) =

a + h(x) + ‚Ñì‚Ä≤(x)

+

b + h(y) + ‚Ñì‚Ä≤(y)

= a + h(x) + xb + xh(y) + f ‚Ä≤(x, y) + ‚Ñì‚Ä≤(xy)
= a + xb +

h(x) + xh(y) + f ‚Ä≤(x, y)

+ ‚Ñì‚Ä≤(xy)
= a + xb + f (x, y) + h(xy) + ‚Ñì‚Ä≤(xy).
We have used the given equation for f ‚àíf ‚Ä≤ [remember that the terms other than ‚Ñì‚Ä≤(xy) all
lie in the abelian group K, and so they may be rearranged].
Conversely, assume that there exists an isomorphism Œ≥ making the diagram commute,
so that Œ≥ (a) = a for all a ‚ààK and
x = p(‚Ñì(x)) = p‚Ä≤Œ≥ (‚Ñì(x))
for all x ‚ààQ. It follows that Œ≥ ‚Ñì: Q ‚ÜíG‚Ä≤ is a lifting. Applying Œ≥ to the equation
‚Ñì(x)+‚Ñì(y) = f (x, y)+‚Ñì(xy) that deÔ¨Ånes the factor set f , we see that Œ≥ f is the factor set
determined by the lifting Œ≥ ‚Ñì. But Œ≥ f (x, y) = f (x, y) for all x, y ‚ààQ because f (x, y) ‚àà
K. Therefore, f is also a factor set of the second extension. On the other hand, if f ‚Ä≤ is any
other factor set for the second extension, then Lemma 10.15 shows that f ‚àíf ‚Ä≤ ‚ààB2; that
is, the extensions are equivalent.
‚Ä¢
We say that the isomorphism Œ≥ in Proposition 10.17 implements the equivalence. The
remark after Theorem 10.14 shows that the isomorphism Œ≥ : G ‚ÜíG(K, Q, f ) imple-
ments an equivalence of extensions.
Example 10.18.
If two extensions of K by Q realizing the operators are equivalent, then their middle groups
are isomorphic. However, the converse is false: We give an example of two inequivalent
extensions with isomorphic middle groups. Let p be an odd prime, and consider the fol-
lowing diagram:
0
 K
i

1K

G
œÄ


Q
1Q

 1
0
 K
i‚Ä≤
 G‚Ä≤
œÄ‚Ä≤
 Q
 1
DeÔ¨Åne K = ‚ü®a‚ü©, a cyclic group of order p, G = ‚ü®g‚ü©= G‚Ä≤, a cyclic group of order p2, and
Q = ‚ü®x‚ü©, where x = g + K. In the top row, deÔ¨Åne i(a) = pg and œÄ to be the natural map;

802
Homology
Ch. 10
in the bottom row deÔ¨Åne i‚Ä≤(a) = 2pg and œÄ‚Ä≤ to be the natural map. Note that i‚Ä≤ is injective
because p is odd.
Suppose there is an isomorphism Œ≥ : G ‚ÜíG‚Ä≤ making the diagram commute. Com-
mutativity of the Ô¨Årst square implies Œ≥ (pa) = 2pa, and this forces Œ≥ (g) = 2g, by Exer-
cise 10.12(ii) on page 794; commutativity of the second square gives g + K = 2g + K;
that is, g ‚ààK. We conclude that the two extensions are not equivalent.
‚óÄ
The next theorem summarizes the calculations in this section.
Theorem 10.19 (Schreier).
Let Q be a group, let K be a Q-module, and let e(Q, K)
denote the family of all the equivalence classes of extensions of K by Q realizing the
operators. There is a bijection
œï : H2(Q, K) ‚Üíe(Q, K)
that takes 0 to the class of the split extension.
Proof.
Denote the equivalence class of an extension
0 ‚ÜíK ‚ÜíG ‚ÜíQ ‚Üí1
by [G]. DeÔ¨Åne œï : H2(Q, K) ‚Üíe(Q, K) by
œï : f + B2 ‚Üí[G(K, Q, f )],
where f is a factor set of the extension and the target extension is that constructed in
Theorem 10.13.
First, œï is a well-deÔ¨Åned injection: f and g are factor sets with f + B2 = g + B2 if and
only if [G(K, Q, f )] = [G(K, Q, g)], by Proposition 10.17. To see that œï is a surjection,
let [G] ‚ààe(Q, K). By Theorem 10.14 and the remark following it, [G] = [G(K, Q, f )]
for some factor set f , and so [G] = œï( f + B2). Finally, the zero factor set corresponds to
the semidirect product.
‚Ä¢
If H is a group and if there is a bijection œï : H ‚ÜíX, where X is a set, then there is a
unique operation deÔ¨Åned on X making X a group and œï an isomorphism: Given x, y ‚ààX,
there are g, h ‚ààH with x = œï(g) and y = œï(h), and we deÔ¨Åne xy = œï(gh). In particular,
there is a way to add two equivalence classes of extensions; it is called Baer sum (see
Section 10.6).
Corollary 10.20.
If Q is a group, K is a Q-module, and H2(Q, K) = {0}, then every
extension of K by Q realizing the operators is a semidirect product.
Proof.
By the theorem, e(Q, K) has only one element; since the split extension always
exists, this one element must be the equivalence class of the split extension. Therefore,
every extension of K by Q realizing the operators is split, and so its middle group is a
semidirect product.
‚Ä¢
We now apply Schreier's theorem.

Sec. 10.3
General Extensions and Cohomology
803
Theorem 10.21.
Let G be a Ô¨Ånite group of order mn, where (m, n) = 1. If K is an
abelian normal subgroup of order m, then K has a complement and G is a semidirect
product.
Proof.
DeÔ¨Åne Q = G/K. By Corollary 10.20, it sufÔ¨Åces to prove that every factor set
f : Q √ó Q ‚ÜíK is a coboundary. DeÔ¨Åne œÉ : Q ‚ÜíK by
œÉ(x) =

y‚ààQ
f (x, y);
œÉ is well-deÔ¨Åned because Q is Ô¨Ånite and K is abelian. Now sum the cocycle identity
x f (y, z) ‚àíf (xy, z) + f (x, yz) ‚àíf (x, y) = 0
over all z ‚ààQ to obtain
xœÉ(y) ‚àíœÉ(xy) + œÉ(x) = nf (x, y)
(as z varies over all of Q, so does yz). Since (m, n) = 1, there are integers s and t with
sm + tn = 1. DeÔ¨Åne h : Q ‚ÜíK by
h(x) = tœÉ(x).
Note that h(1) = 0 and
xh(y) ‚àíh(xy) + h(x) = f (x, y) ‚àíms f (x, y).
But s f (x, y) ‚ààK, and so ms f (x, y) = 0. Therefore, f is a coboundary.
‚Ä¢
Remark.
P. Hall proved that if G is a Ô¨Ånite solvable group of order mn, where (m, n) = 1,
then G has a subgroup of order m and any two such are conjugate. In particular, in a solv-
able group, every (not necessarily normal) Sylow subgroup has a complement. Because of
this theorem, a (not necessarily normal) subgroup H of a Ô¨Ånite group G is called a Hall
subgroup if (|H|, [G : H]) = 1. Thus, Theorem 10.21 is often stated as every normal Hall
subgroup of an arbitrary Ô¨Ånite group has a complement.
‚óÄ
We now use some group theory to remove the hypothesis that K be abelian.
Theorem 10.22 (Schur-Zassenhaus7 Lemma).
Let G be a Ô¨Ånite group of order mn,
where (m, n) = 1. If K is a normal subgroup of order m, then K has a complement and
G is a semidirect product.
7I. Schur proved this theorem, in 1904, for the special case Q cyclic. H. Zassenhaus, in 1938, proved the
theorem for arbitrary Ô¨Ånite Q.

804
Homology
Ch. 10
Proof.
By Exercise 10.2 on page 793, it sufÔ¨Åces to prove that G contains a subgroup of
order n; we prove the existence of such a subgroup by induction on m ‚â•1. Of course, the
base step m = 1 is true.
Suppose that there is a proper subgroup T of K with {1} < T ‚úÅG. Then K/T ‚úÅG/T
and (G/T )/(K/T ) ‚àº= G/K has order n. Since T < K, we have |K/T | < |K| = m,
and so the inductive hypothesis provides a subgroup N/T ‚â§G/T with |N/T | = n. Now
|N| = n|T |, where (|T |, n) = 1 [because |T | is a divisor of |K| = m], so that T is a
normal subgroup of N whose order and index are relatively prime. Since |T | < |K| = m,
the inductive hypothesis provides a subgroup C of N (which is obviously a subgroup of G)
of order n.
We may now assume that K is a minimal normal subgroup of G; that is, there is no
normal subgroup T of G with {1} < T < K. Let p be a prime divisor of |K| and let P be
a Sylow p-subgroup of K. By the Frattini argument, Exercise 5.21 on page 277, we have
G = K NG(P). Therefore,
G/K = K NG(P)/K
‚àº= NG(P)/(K ‚à©NG(P))
= NG(P)/NK (P).
Hence, |NK (P)|n = |NK (P)||G/K| = |NG(P)|. If NG(P) is a proper subgroup of
G, then |NK (P)| < m, and induction provides a subgroup of NG(P) ‚â§G of order n.
Therefore, we may assume that NG(P) = G; that is, P ‚úÅG.
Since {1} < P ‚â§K and P is normal in G, we must have P = K, because K is
a minimal normal subgroup. But P is a p-group, and so its center, Z(P), is nontrivial.
By Exercise 5.19(v) on page 277, we have Z(P) ‚úÅG, and so Z(P) = P, again because
P = K is a minimal normal subgroup of G. It follows that P is abelian, and we have
reduced the problem to Theorem 10.21.
‚Ä¢
Corollary 10.23.
If a Ô¨Ånite group G has a normal Sylow p-subgroup P, for some prime
divisor p of |G|, then G is a semidirect product; more precisely, P has a complement.
Proof.
The order and index of a Sylow subgroup are relatively prime.
‚Ä¢
There is another part of the Schur-Zassenhaus lemma that we have not stated: If K is a
normal subgroup of G whose order and index are relatively prime, then any two comple-
ments of K are conjugate subgroups. We are now going to see that there is an analog of
H2(K, Q) whose vanishing implies conjugacy of complements when K is abelian. This
group, H1(K, Q), arises, as did H2(K, Q), from a series of elementary calculations.
We begin with a computational lemma. Let Q be a group, let K be a Q-module, and let
0 ‚ÜíK ‚ÜíG ‚ÜíQ ‚Üí1 be a split extension. Choose a lifting ‚Ñì: Q ‚ÜíG, so that every
element g ‚ààG has a unique expression of the form
g = a + ‚Ñìx.
where a ‚ààK and x ‚ààQ.

Sec. 10.3
General Extensions and Cohomology
805
DeÔ¨Ånition.
An automorphism œï of a group G stabilizes an extension 0 ‚ÜíK ‚ÜíG ‚Üí
Q ‚Üí1 if the following diagram commutes:
0
 K
i

1K

G
p

œï

Q
1Q

 1
0
 K
i
 G
p
 Q
 1
The set of all stabilizing automorphisms of an extension of K by Q, where K is a
Q-module, form a group under composition, denoted by
Stab(Q, K).
Note that a stabilizing automorphism is an isomorphism that implements an equivalence
of an extension with itself. We shall see, in Proposition 10.26, that Stab(Q, K) does not
depend on the extension.
Proposition 10.24.
Let Q be a group, let K be a Q-module, and let
0 ‚ÜíK
i‚ÜíG
p‚ÜíQ ‚Üí1
be a split extension.
If ‚Ñì: Q ‚ÜíG is a lifting, then every stabilizing automorphism
œï : G ‚ÜíG has the form
œï(a + ‚Ñìx) = a + d(x) + ‚Ñìx,
where d(x) ‚ààK is independent of the choice of lifting ‚Ñì. Moreover, this formula deÔ¨Ånes a
stabilizing automorphism if and only if, for all x, y ‚ààQ, the function d : Q ‚ÜíK satisÔ¨Åes
d(xy) = d(x) + xd(y).
Proof.
If œï is stabilizing, then œïi = i, where i : K ‚ÜíG, and pœï = p. Since we are
assuming that i is the inclusion [which is merely a convenience to allow us to write a
instead of i(a)], we have œï(a) = a for all a ‚ààK. To use the second constraint on œï,
suppose that œï(‚Ñìx) = d(x) + ‚Ñìy for some d(x) ‚ààK and y ‚ààQ. Then
x = p(‚Ñìx)
= pœï(‚Ñìx)
= p(d(x) + ‚Ñìy)
= y;
that is, x = y. Therefore,
œï(a + ‚Ñìx) = œï(a) + œï(‚Ñìx) = a + d(x) + ‚Ñìx.

806
Homology
Ch. 10
To see that the formula for d holds, we Ô¨Årst show that d is independent of the choice of
lifting. Suppose that ‚Ñì‚Ä≤ : Q ‚ÜíG is another lifting, so that œï(‚Ñì‚Ä≤x) = d‚Ä≤(x) + ‚Ñì‚Ä≤x for some
d‚Ä≤(x) ‚ààK. Now there is k(x) ‚ààK with ‚Ñì‚Ä≤x = k(x)+‚Ñìx, for p‚Ñì‚Ä≤x = x = p‚Ñìx. Therefore,
d‚Ä≤(x) = œï(‚Ñì‚Ä≤x) ‚àí‚Ñì‚Ä≤x
= œï(k(x) + ‚Ñìx) ‚àí‚Ñì‚Ä≤x
= k(x) + d(x) + ‚Ñìx ‚àí‚Ñì‚Ä≤x
= d(x),
because k(x) + ‚Ñìx ‚àí‚Ñì‚Ä≤x = 0.
Since d(x) is independent of the choice of lifting ‚Ñì, and since the extension splits, we
may assume that ‚Ñìis a homomorphism: ‚Ñìx + ‚Ñìy = ‚Ñì(xy). We compute œï(‚Ñìx + ‚Ñìy) in two
ways. On the one hand,
œï(‚Ñìx + ‚Ñìy) = œï(‚Ñì(xy)) = d(xy) + ‚Ñì(xy).
On the other hand,
œï(‚Ñìx + ‚Ñìy) = œï(‚Ñìx) + œï(‚Ñìy)
= d(x) + ‚Ñìx + d(y) + ‚Ñìy
= d(x) + xd(y) + ‚Ñì(xy).
The proof of the converse, if œï(a+‚Ñìx) = a+d(x)+‚Ñìx, where d satisÔ¨Åes the given iden-
tity, then œï is a stabilizing isomorphism, is a routine argument that is left to the reader.
‚Ä¢
We give a name to functions like d.
DeÔ¨Ånition.
Let Q be a group and let K be a Q-module. A derivation8 (or crossed
homomorphism) is a function d : Q ‚ÜíK such that
d(xy) = xd(y) + d(x).
The set of all derivations, Der(Q, K), is an abelian group under pointwise addition [if K
is a trivial Q-module, then Der(Q, K) = Hom(Q, K)].
If d is a derivation, then d(11) = 1d(1) + d(1) ‚ààK, and so d(1) = 0.
Example 10.25.
(i) If Q is a group and K is a Q-module, then a function u : Q ‚ÜíK of the form u(x) =
xa0 ‚àía0, where a0 ‚ààK, is a derivation:
u(x) + xu(y) = xa0 ‚àía0 + x(ya0 ‚àía0)
= xa0 ‚àía0 + xya0 ‚àíxa0
= xya0 ‚àía0
= u(xy).
8Earlier, we deÔ¨Åned a derivation of a (not necessarily associative) ring R as a function d : R ‚ÜíR with
d(xy) = d(x)y + xd(y). Derivations here are deÔ¨Åned on modules, not on rings.

Sec. 10.3
General Extensions and Cohomology
807
A derivation u of the form u(x) = xa0 ‚àía0 is called a principal derivation.
If the action of Q on K is conjugation, xa = x + a ‚àíx, then
xa0 ‚àía0 = x + a0 ‚àíx ‚àía0;
that is, xa0 ‚àía0 is the commutator of x and a0.
(ii) It is easy to check that the set PDer(Q, K) of all the principal derivations is a subgroup
of Der(Q, K).
‚óÄ
Recall that Stab(Q, K) denotes the group of all the stabilizing automorphisms of an
extension of K by Q.
Proposition 10.26.
If Q is a group, K is a Q-module, and 0 ‚ÜíK ‚ÜíG ‚ÜíQ ‚Üí1 is a
split extension, then there is an isomorphism Stab(Q, K) ‚ÜíDer(Q, K).
Proof.
Let œï be a stabilizing automorphism. If ‚Ñì: Q ‚ÜíG is a lifting, then Proposi-
tion 10.24 says that œï(a + ‚Ñìx) = a + d(x) + ‚Ñìx, where d is a derivation. Since this
proposition further states that d is independent of the choice of lifting, œï ‚Üíd is a well-
deÔ¨Åned function Stab(Q, K) ‚ÜíDer(Q, K), which is easily seen to be a homomorphism.
To see that this map is an isomorphism, we construct its inverse. If d ‚ààDer(Q, K), de-
Ô¨Åne œï : G ‚ÜíG by œï(a+‚Ñìx) = a+d(x)+‚Ñìx. Now œï is stabilizing, by Proposition 10.24,
and d ‚Üíœï is the desired inverse function.
‚Ä¢
It is not obvious from its deÔ¨Ånition that Stab(Q, K) is abelian, for its binary operation
is composition. However, Stab(Q, K) is abelian, for Der(Q, K) is.
Recall that an automorphism œï of a group G is called an inner automorphism if it is a
conjugation; that is, there is c ‚ààG with œï(g) = c + g ‚àíc for all g ‚ààG (if G is written
additively).
Lemma 10.27.
Let 0 ‚ÜíK ‚ÜíG ‚ÜíQ ‚Üí1 be a split extension, and let ‚Ñì: Q ‚ÜíG
be a lifting. Then a function œï : G ‚ÜíG is an inner stabilizing automorphism by some
a0 ‚ààK if and only if
œï(a + ‚Ñìx) = a + xa0 ‚àía0 + ‚Ñìx.
Proof.
If we write d(x) = xa0‚àía0, then œï(a+‚Ñìx) = a+d(x)+‚Ñìx. But d is a (principal)
derivation, and so œï is a stabilizing automorphism, by Proposition 10.24. Finally, œï is
conjugation by ‚àía0, for
‚àía0 + (a + ‚Ñìx) + a0 = ‚àía0 + a + xa0 + ‚Ñìx = œï(a + ‚Ñìx).
Conversely, assume that œï is a stabilizing conjugation. That œï is stabilizing says that
œï(a+‚Ñìx) = a+d(x)+‚Ñìx; that œï is conjugation says that there is b ‚ààK with œï(a+‚Ñìx) =
b + a + ‚Ñìx ‚àíb. But b + a + ‚Ñìx ‚àíb = b + a ‚àíxb + ‚Ñìx, so that d(x) = b ‚àíxb, as
desired.
‚Ä¢

808
Homology
Ch. 10
DeÔ¨Ånition.
If Q is a group and K is a Q-module, deÔ¨Åne
H1(Q, K) = Der(Q, K)/PDer(Q, K),
where PDer(Q, K) is the subgroup of Der(Q, K) consisting of all the principal derivations.
Proposition 10.28.
Let 0 ‚ÜíK ‚ÜíG ‚ÜíQ ‚Üí1 be a split extension, and let C and C‚Ä≤
be complements of K in G. If H1(Q, K) = {0}, then C and C‚Ä≤ are conjugate.
Proof.
Since G is a semidirect product, there are liftings ‚Ñì: Q ‚ÜíG, with image C,
and ‚Ñì‚Ä≤ : Q ‚ÜíG, with image C‚Ä≤, which are homomorphisms. Thus, the factor sets f
and f ‚Ä≤ determined by each of these liftings is identically zero, and so f ‚Ä≤ ‚àíf = 0. But
Lemma 10.15 says that there exists h : Q ‚ÜíK, namely, h(x) = ‚Ñì‚Ä≤x ‚àí‚Ñìx, with
0 = f ‚Ä≤(x, y) ‚àíf (x, y) = xh(y) ‚àíh(xy) + h(x);
thus, h is a derivation. Since H1(Q, K) = {0}, h is a principal derivation: there is a0 ‚ààK
with
‚Ñì‚Ä≤x ‚àí‚Ñìx = h(x) = xa0 ‚àía0
for all x ‚ààQ. Since addition in G satisÔ¨Åes ‚Ñì‚Ä≤x ‚àía0 = ‚àíxa0 + ‚Ñì‚Ä≤x, we have
‚Ñìx = a0 ‚àíxa0 + ‚Ñì‚Ä≤x = a0 + ‚Ñì‚Ä≤x ‚àía0.
But im ‚Ñì= C and im ‚Ñì‚Ä≤ = C‚Ä≤, and so C and C‚Ä≤ are conjugate via a0.
‚Ä¢
We can now supplement the Schur-Zassenhaus theorem.
Theorem 10.29.
Let G be a Ô¨Ånite group of order mn, where (m, n) = 1. If K is an
abelian normal subgroup of order m, then G is a semidirect product of K by G/K, and
any two complements of K are conjugate.
Proof.
By Proposition 10.28, it sufÔ¨Åces to prove that H1(Q, K) = {0}, where Q = G/K.
Note, Ô¨Årst, that |Q| = |G|/|K| = mn/m = n.
Let d : Q ‚ÜíK be a derivation: for all x, y ‚ààQ, we have
d(xy) = xd(y) + d(x).
Sum this equation over all y ‚ààQ to obtain
 = x + nd(x),
where  = 
y‚ààQ d(y) (as y varies over Q, so does xy). Since (m, n) = 1, there are
integers s and t with sn + tm = 1. Hence,
d(x) = snd(x) + tmd(x) = snd(x),
because d(x) ‚ààK and so md(x) = 0. Therefore,
d(x) = s ‚àíxs.
Setting a0 = ‚àís, we see that d is a principal derivation.
‚Ä¢

Sec. 10.3
General Extensions and Cohomology
809
Removing the assumption in Theorem 10.29 that K is abelian is much more difÔ¨Åcult
than removing this assumption in Theorem 10.21. We Ô¨Årst prove that complements are
conjugate if either K or Q is a solvable group. Since |Q| and |K| are relatively prime, at
least one of K or Q has odd order. The Feit-Thompson theorem, which says that every
group of odd order is solvable, now completes the proof.
There are other applications of homology in group theory besides the Schur-Zassenhaus
lemma. For example, if G is a group, a ‚ààG, and Œ≥a : g ‚Üíaga‚àí1 is conjugation by a,
then Œ≥ n
a : g ‚Üíanga‚àín for all n. Hence, if a has prime order p and a /‚ààZ(G), then Œ≥a
is an automorphism of order p. A theorem of W. Gasch¬®utz uses cohomology to prove that
every Ô¨Ånite nonabelian p-group has an automorphism of order p that is not conjugation by
an element of G.
Let us contemplate the formulas that have arisen.
factor set :
0 = x f (y, z) ‚àíf (xy, z) + f (x, yz) ‚àíf (x, y)
coboundary :
f (x, y) = xh(y) ‚àíh(xy) + h(x)
derivation :
0 = xd(y) ‚àíd(xy) + d(x)
principal derivation :
d(x) = xa0 ‚àía0
All these formulas involve alternating sums; factor sets and derivations seem to be in ker-
nels, and coboundaries and principal derivations seem to be in images. Let us make this
more precise.
Denote the cartesian product of n copies of Q by Qn; for clarity, we denote an element
of Qn by [x1, . . . , xn] instead of by (x1, . . . , xn). Factor sets and coboundaries are certain
functions Q2 ‚ÜíK, and derivations are certain functions Q1 ‚ÜíK. Let Fn be the free
left ZQ-module with basis Qn. By the deÔ¨Ånition of basis, every function f : Qn ‚ÜíK
gives a unique Q-homomorphism f : Fn ‚ÜíK extending f , for K is a Q-module; that is,
if Set(Qn, K) denotes the family of all functions Qn ‚ÜíK in the category of sets, then
f ‚Üíf gives a bijection
Set(Qn, K) ‚ÜíHomZQ(Fn, K).
The inverse of this function is restriction
res: HomZQ(Fn, K) ‚ÜíSet(Qn, K),
deÔ¨Åned by res: g ‚Üíg|Qn.
We now deÔ¨Åne maps that are suggested by the various formulas:
d3 : F3 ‚ÜíF2 :
d3[x, y, z] = x[y, z] ‚àí[xy, z] + [x, yz] ‚àí[x, y];
d2 : F2 ‚ÜíF1 :
d2[x, y] = x[y] ‚àí[xy] + [x].
In fact, we deÔ¨Åne one more map: let Q0 = {1} be a 1-point set, so that F0 = ZQ is the
free Q-module on the single generator, 1. Now deÔ¨Åne
d1 : F1 ‚ÜíF0 :
d1[x] = x ‚àí1.
We have deÔ¨Åned each of d3, d2, and d1 on bases of free modules, and so each extends to a
Q-map.

810
Homology
Ch. 10
Proposition 10.30.
The sequence
F3
d3
‚àí‚ÜíF2
d2
‚àí‚ÜíF1
d1
‚àí‚ÜíF0
is an exact sequence of Q-modules.
Sketch of Proof.
We will only check that d1d2 = 0 and d2d3 = 0; that is, im d2 ‚äÜker d1
and im d3 ‚äÜker d2. The (trickier) reverse inclusions will be proved in Theorem 10.117
after we introduce some homological algebra.
d1d2[x, y] = d1(x[y] ‚àí[xy] + [x])
= xd1[y] ‚àíd1[xy] + d1[x])
= x(y ‚àí1) ‚àí(xy ‚àí1) + (x ‚àí1)
= 0
(the equation d1x[y] = xd1[y] holds because d1 is a Q-map). The reader should note that
this is the same calculation as in Proposition 10.16.
d2d3[x, y, z] = d2(x[y, z] ‚àí[xy, z] + [x, yz] ‚àí[x, y])
= xd2[y, z] ‚àíd2[xy, z] + d2[x, yz] ‚àíd2[x, y]
= x(y[z] ‚àí[yz] + [y]) ‚àí(xy[z] ‚àí[xyz] + [xy])
+ (x[yz] ‚àí[xyz] + [x]) ‚àí(x[y] ‚àí[xy] + [x])
= 0
‚Ä¢
Let us recall that if X is a set and K is a module, then functions X ‚ÜíK are the same
as homomorphisms F ‚ÜíK, where F is the free module having basis X: Formally, the
functors Set(X, ) and Hom(F, ), which map ZQMod ‚ÜíSet, are naturally equivalent.
Applying the contravariant functor HomZQ( , K) to the sequence in Proposition 10.30, we
obtain a (not necessarily exact) sequence
Hom(F3, K)
d‚àó
3
‚Üê‚àíHom(F2, K)
d‚àó
2
‚Üê‚àíHom(F1, K)
d‚àó
1
‚Üê‚àíHom(F0, K);
inserting the bijections res: g ‚Üíg|Qn gives a commutative diagram of sets:
Set(Q3, K)
Set(Q2, K)

Set(Q, K)

Set({1}, K)

Hom(F3, K)
res

Hom(F2, K)
res

d‚àó
3

Hom(F1, K)
res

d‚àó
2

Hom(F0, K).
res

d‚àó
1

We regard a function f : Qn ‚ÜíK as the restriction of the Q-map f : Fn ‚ÜíK which
extends it. Suppose that f : Q2 ‚ÜíK lies in ker d‚àó
3. Then 0 = d‚àó
3( f ) = f d3. Hence, for
all x, y, z ‚ààQ, we have
0 = f d3[x, y, z]
= f (x[y, z] ‚àí[xy, z] + [x, yz] ‚àí[x, y])
= x f [y, z] ‚àíf [xy, z] + f [x, yz] ‚àíf [x, y];

Sec. 10.3
General Extensions and Cohomology
811
the equation f (x[y, z]) = x f [y, z] holds because f is the restriction of a Q-map. Thus,
f is a factor set. If f lies in im d‚àó
2, then there is some h : Q ‚ÜíK with f = d‚àó
2(h) = hd2.
Thus,
f [x, y] = hd2[x, y]
= h(x[y] ‚àí[xy] + [x])
= xh[y] ‚àíh[xy] + h[x];
the equation h(x[y]) = xh[y] holds because h is the restriction of a Q-map. Thus, f is a
coboundary.
A similar analysis shows that if g : Q ‚ÜíK lies in ker d‚àó
2, then g is a derivation. Let us
now compute im d‚àó
1. If k : {1} ‚ÜíK, then
d‚àó
1(k) = kd1(x) = k((x ‚àí1)1) = (x ‚àí1)k(1),
because k is the restriction of a Q-map. Now k(1) is merely an element of K; indeed,
if we identify k with its (1-point) image k(1) = a0, then we see that d‚àó
1(k) is a principal
derivation.
Observe that d2d3 = 0 implies d‚àó
3d‚àó
2 = 0, which is equivalent to im d‚àó
2 ‚äÜker d‚àó
3;
that is, every coboundary is a factor set, which is Proposition 10.16. Similarly, d1d2 = 0
implies im d‚àó
1 ‚äÜker d‚àó
2; that is, every principal derivation is a derivation, which is Exam-
ple 10.25(i).
As long as we are computing kernels and images, what is ker d‚àó
1? If k : {1} ‚ÜíK and
k(1) = a0, then k ‚ààker d‚àó
1 says
0 = d‚àó
1(k) = kd1(x) = (x ‚àí1)k(1) = (x ‚àí1)a0,
so that xa0 = a0 for all x ‚ààQ. We have been led to the following deÔ¨Ånition.
DeÔ¨Ånition.
If Q is a group and K is a Q-module, then the submodule of Ô¨Åxed points is
deÔ¨Åned by
H0(Q, K) = {a ‚ààK : xa = a for all x ‚ààQ}.
The groups H2(Q, K), H1(Q, K), and H0(Q, K) were obtained by applying the func-
tor Hom( , K) to the exact sequence F3 ‚ÜíF2 ‚ÜíF1 ‚ÜíF0. In algebraic topology, we
would also apply the functor ‚äóZQ K, obtaining homology groups [the tensor product is
deÔ¨Åned because we may view the free Q-modules Fn as right Q-modules, as in Exam-
ple 8.79(v)]:
H0(Q, K) = ker(d0 ‚äó1)/ im(d1 ‚äó1);
H1(Q, K) = ker(d1 ‚äó1)/ im(d2 ‚äó1);
H2(Q, K) = ker(d2 ‚äó1)/ im(d3 ‚äó1).
We can show that H0(Q, K) is the maximal Q-trivial quotient of K. In the special case
K = Z viewed as a trivial Q-module, we see that H1(Q, Z) ‚àº= Q/Q‚Ä≤, where Q‚Ä≤ is the
commutator subgroup of Q.
We discuss homological algebra in the next section, for it is the proper context in which
to understand these constructions.

812
Homology
Ch. 10
EXERCISES
10.13 Let Q be a group and let K be a Q-module. Prove that any two split extensions of K by Q
realizing the operators are equivalent.
10.14 Let Q be a group and let K be a Q-module.
(i) If K and Q are Ô¨Ånite groups, prove that H2(Q, K) is also Ô¨Ånite.
(ii) Let œÑ(K, Q) denote the number of nonisomorphic middle groups G that occur in exten-
sions of K by Q realizing the operators. Prove that
œÑ(K, Q) ‚â§|H2(Q, K)|.
(iii) Give an example showing that the inequality in part (ii) can be strict.
Hint.
Observe that œÑ(Ip, Ip) = 2 (note that the kernel is the trivial module because
every group of order p2 is abelian).
10.15 Recall Example 5.79 on page 307: a generalized quaternion group Qn is a group of order 2n,
where n ‚â•3, which is generated by two elements a and b such that
a2n‚àí1 = 1,
bab‚àí1 = a‚àí1, and
b2 = a2n‚àí2.
(i) Prove that Qn has a unique element z of order 2 and that Z(Qn) = ‚ü®z‚ü©. Conclude that
Qn is not a semidirect product.
(ii) Prove that Qn is a central extension (i.e., Œ∏ is trivial) of I2 by D2n‚àí1.
(iii) Using factor sets, give another proof of the existence of Qn.
10.16 If p is an odd prime, prove that every group G of order 2p is a semidirect product of Ip by I2,
and conclude that either G is cyclic or G ‚àº= D2p.
10.17 Show that every group G of order 12 is isomorphic to one of the following Ô¨Åve groups:
I12,
V √ó I3,
A4,
S3 √ó I2,
T,
where T is the group in Example 10.9.
10.18 If Q is a group and K is a Q-module, let E be a semidirect product of K by Q and let ‚Ñì: G ‚Üí
E be a lifting. Prove that ‚Ñì(x) = (d(x), x), where d : Q ‚ÜíK, and ‚Ñìis a homomorphism if
and only if d is a derivation.
10.19 If U : ZQMod ‚ÜíSets is the forgetful functor (which assigns to each module its set of ele-
ments), prove that the ordered pair (, U) is an adjoint pair of functors. [By Exercise 7.39(ii)
on page 471, there exists a free functor : Set ‚ÜíZQMod that assigns to each set X the free
Q-module (X) with basis X.]
10.20 Prove that the functors Set(X, ) and Hom(, ), which map ZQMod ‚ÜíSet, are naturally
equivalent, where  is the free functor deÔ¨Åned in Exercise 10.19.

Sec. 10.4
Homology Functors
813
10.4 HOMOLOGY FUNCTORS
Let R be a ring. In this section, the word module will always mean "left R-module." Given
a module M, there is a free module F0 and a surjection Œµ: F0 ‚ÜíM; thus, there is an exact
sequence
0 ‚Üí$1
i
‚àí‚ÜíF0
Œµ
‚àí‚ÜíM ‚Üí0,
where $1 = ker Œµ and i : $1 ‚ÜíF0 is the inclusion. This is just another way of describing
a presentation of M; that is, a description of M by generators and relations. Thus, if X is
a basis of F0, then we say that X [or Œµ(X)] are generators of M and that $1 are relations.
The idea now is to take generators and relations of $1, getting "second-order" relations
$2, and to iterate this construction giving a free resolution of M, which should be regarded
as a more detailed presentation of M by generators and relations. In algebraic topology,
a topological space X is replaced by a sequence of chain groups, and this sequence yields
the homology groups Hn(X). We are now going to replace an R-module M by a resolution
of it.
DeÔ¨Ånition.
A projective resolution of a module M is an exact sequence,
¬∑ ¬∑ ¬∑ ‚ÜíPn ‚ÜíPn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP1 ‚ÜíP0 ‚ÜíM ‚Üí0,
in which each module Pn is projective. A free resolution is a projective resolution in
which each module Pn is free.
Proposition 10.30 displayed an exact sequence of free left ZQ-modules
F3
d3
‚àí‚ÜíF2
d2
‚àí‚ÜíF1
d1
‚àí‚ÜíF0,
where Fn is the free Q-module with basis Qn. The module F0 = ZQ is free on the
generator 1, and the map d1 : F1 ‚ÜíZQ is given by
d1 : [x] ‚Üíx ‚àí1.
Proposition 10.31.
For any group Q, there is an isomorphism ZQ/ im d1 ‚àº= Z, where Z
is regarded as a trivial Q-module.
Proof.
DeÔ¨Åne Œµ: ZQ ‚ÜíZ by
Œµ:

x‚ààQ
mxx ‚Üí

x‚ààQ
mx.
Now Œµ is a Q-map, for if x ‚ààQ, then Œµ(x) = 1; on the other hand, Œµ(x) = Œµ(x ¬∑ 1) =
xŒµ(1) = 1, because Z is a trivial Q-module. It is clear that Œµ is a surjection and that
im d1 ‚â§ker Œµ [because Œµ(x ‚àí1) = 0]. For the reverse inclusion, if 
x‚ààQ mxx ‚ààker Œµ,
then 
x‚ààQ mx = 0. Hence,

x‚ààQ
mxx =

x‚ààQ
mxx ‚àí

x‚ààQ
mx

1 =

x‚ààQ
mx(x ‚àí1) ‚ààim d1.
Therefore, coker d1 = ZQ/ im d1 ‚àº= Z.
‚Ä¢

814
Homology
Ch. 10
Thus, the exact sequence in Proposition 10.30 can be lengthened so that it ends with
coker d1 = ZQ/ im d1, and so it looks like the beginning of a free resolution of the trivial
Q-module Z.
Proposition 10.32.
Every module M has a free resolution (and hence it has a projective
resolution).
Proof.
As in Section 10.1, there is a free module F0 and an exact sequence
0 ‚Üí$1
i1
‚àí‚ÜíF0
Œµ
‚àí‚ÜíM ‚Üí0.
Similarly, there is a free module F1, a surjection Œµ1 : F1 ‚Üí$1, and an exact sequence
0 ‚Üí$2
i2
‚àí‚ÜíF1
Œµ1
‚àí‚Üí$1 ‚Üí0.
DeÔ¨Åne d1 : F1 ‚ÜíF0 to be the composite i1Œµ1. It is plain that im d1 = $1 = ker Œµ and
ker d1 = $2, so there is an exact sequence
F1
d1

Œµ1
+
+
+
+
+
+
+
+
F0
Œµ
 M
 0
0
 $2
,
,
,
,
,
,
,
,
$1
i1
,
,
,
,
,
,
,
,
Plainly, this construction can be iterated for all n ‚â•0 (so that the ultimate exact sequence
is inÔ¨Ånitely long).
‚Ä¢
There is a dual construction.
DeÔ¨Ånition.
An injective resolution of a module M is an exact sequence,
0 ‚ÜíM ‚ÜíE0 ‚ÜíE1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíEn ‚ÜíEn+1 ‚Üí¬∑ ¬∑ ¬∑ ,
in which each module En is injective.
Proposition 10.33.
Every module M has an injective resolution.
Proof.
We use Theorem 8.104, which states that every module can be imbedded as a
submodule of an injective module. Thus, there is an injective module E0, an injection
Œ∑: M ‚ÜíE0, and an exact sequence
0 ‚ÜíM
Œ∑
‚àí‚ÜíE0
p
‚àí‚Üí1 ‚Üí0,
where 1 = coker Œ∑ and p is the natural map. Now repeat: there is an injective module
E1, an imbedding Œ∑1 : 1 ‚ÜíE1, yielding an exact sequence
0
 M
Œ∑
 E0
d0

p








E1








1
Œ∑1








2
 0
where d0 is the composite d0 = Œ∑1 p. This construction can be iterated.
‚Ä¢

Sec. 10.4
Homology Functors
815
We are now going to generalize both of these deÔ¨Ånitions.
DeÔ¨Ånition.
A complex9 (C‚Ä¢, d‚Ä¢) is a sequence of modules and maps, for every n ‚ààZ,
C‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚ÜíCn+1
dn+1
‚àí‚ÜíCn
dn
‚àí‚ÜíCn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ,
in which dndn+1 = 0 for all n. The maps dn are called differentiations.
Usually, we will shorten the notation (C‚Ä¢, d‚Ä¢) to C‚Ä¢.
Note that the equation dndn+1 = 0 is equivalent to
im dn+1 ‚äÜker dn.
Example 10.34.
(i) Every exact sequence is a complex, for the required inclusions, im dn+1 ‚äÜker dn, are
now equalities, im dn+1 = ker dn.
(ii) The sequence of chain groups of a triangulated space X,
¬∑ ¬∑ ¬∑ ‚ÜíC3(X)
‚àÇ3
‚àí‚ÜíC2(X)
‚àÇ2
‚àí‚ÜíC1(X)
‚àÇ1
‚àí‚ÜíC0(X),
is a complex. However, a complex is supposed to have a module for every n ‚ààZ. We
force this to be a complex by deÔ¨Åning Cn(X) = {0} for all negative n; there is no problem
deÔ¨Åning differentiations dn : Cn(X) ‚ÜíCn‚àí1(X) for n ‚â§0, for there is only the zero map
from any module into {0}.
(iii) In Chapter 9, we considered the de Rham complex of a connected open subset X of Rn:
0 ‚Üí$0(X)
d0
‚Üí$1(X)
d1
‚Üí$2(X) ‚Üí¬∑ ¬∑ ¬∑ ‚Üí$n‚àí1(X)
dn‚àí1
‚Üí$n(X) ‚Üí0,
where the maps are the exterior derivatives.
(iv) The zero complex 0‚Ä¢ is the complex (C‚Ä¢, d‚Ä¢) each of whose terms Cn = {0} and,
necessarily, each of whose differentiations dn = 0.
(v) If {Mn : n ‚ààZ} is any sequence of modules, then (M‚Ä¢, d‚Ä¢) is a complex with nth term
Mn if we deÔ¨Åne dn = 0 for all n.
(vi) Every homomorphism is a differentiation. If f : A ‚ÜíB is a homomorphism, deÔ¨Åne a
complex (C‚Ä¢, d‚Ä¢) with C1 = A, C0 = B, d1 = f , and all other terms and differentiations
zero.
(vii) Every projective resolution of a module M,
¬∑ ¬∑ ¬∑ ‚ÜíP1 ‚ÜíP0 ‚ÜíM ‚Üí0,
is a complex if we add {0}'s to the right.
9These are also called chain complexes in the literature.

816
Homology
Ch. 10
(viii) Every injective resolution of a module M,
0 ‚ÜíM ‚ÜíE0 ‚ÜíE1 ‚Üí¬∑ ¬∑ ¬∑ ,
is a complex if we add {0}'s to the left.
We have used a convenient notation. According to the deÔ¨Ånition of complex, differen-
tiations lower the index: dn : Cn ‚ÜíCn‚àí1. The simplest way to satisfy the deÔ¨Ånition is to
use negative indices: deÔ¨Åne C‚àín = En, and
0 ‚ÜíM ‚ÜíC0 ‚ÜíC‚àí1 ‚ÜíC‚àí2 ‚Üí¬∑ ¬∑ ¬∑
is a complex.
(ix) If C‚Ä¢ is a complex,
C‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚ÜíCn
dn
‚àí‚ÜíCn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ,
and if F is an additive (covariant) functor, say, F : RMod ‚ÜíAb, then F(C‚Ä¢), deÔ¨Åned by
F(C‚Ä¢) = ¬∑ ¬∑ ¬∑ ‚ÜíF(Cn)
Fdn
‚àí‚ÜíF(Cn‚àí1) ‚Üí¬∑ ¬∑ ¬∑ ,
is also a complex:
0 = F(0) = F(dndn+1) = F(dn)F(dn+1);
the equation 0 = F(0) holds because F is an additive functor. Note that even if the original
complex is exact, the functored complex F(C‚Ä¢) may not be exact.
(x) If F is a contravariant additive functor, it is also true that F(C‚Ä¢) is a complex, but we
have to arrange notation so that differentiations lower indices by 1. In more detail, after
applying F, we have
F(C‚Ä¢) = ¬∑ ¬∑ ¬∑ ‚ÜêF(Cn)
Fdn
‚Üê‚àíF(Cn‚àí1) ‚Üê¬∑ ¬∑ ¬∑ ;
the differentiations Fdn increase indices by 1. Introducing negative indices almost solves
the problem. If we deÔ¨Åne X‚àín = F(Cn), then the sequence is rewritten as
F(C‚Ä¢) = ¬∑ ¬∑ ¬∑ ‚ÜíX‚àín+1
Fdn
‚àí‚ÜíX‚àín ‚Üí¬∑ ¬∑ ¬∑ .
However, the index on the map should be ‚àín + 1, and not n. DeÔ¨Åne
Œ¥‚àín+1 = Fdn.
The relabeled sequence now reads properly:
F(C‚Ä¢) = ¬∑ ¬∑ ¬∑ ‚ÜíX‚àín+1
Œ¥‚àín+1
‚àí‚ÜíX‚àín ‚Üí¬∑ ¬∑ ¬∑ .
Negative indices are awkward, however, and the following notation is customary:
Change the sign of the index by raising it to a superscript: Write
Œ¥n = Œ¥‚àín.

Sec. 10.4
Homology Functors
817
The Ô¨Ånal version of the functored sequence now looks like this:
F(C‚Ä¢) = ¬∑ ¬∑ ¬∑ ‚ÜíXn‚àí1 Œ¥n‚àí1
‚àí‚ÜíXn ‚Üí¬∑ ¬∑ ¬∑ .
‚óÄ
It is convenient to consider the category of all complexes, and so we introduce its mor-
phisms.
DeÔ¨Ånition.
If (C‚Ä¢, d‚Ä¢) and (C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢) are complexes, then a chain map
f = f‚Ä¢ : (C‚Ä¢, d‚Ä¢) ‚Üí(C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢)
is a sequence of maps fn : Cn ‚ÜíC‚Ä≤
n for all n ‚ààZ making the following diagram commute:
¬∑ ¬∑ ¬∑
 Cn+1
dn+1 
fn+1

Cn
dn 
fn

Cn‚àí1
fn‚àí1

 ¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑
 C‚Ä≤
n+1
d‚Ä≤
n+1  C‚Ä≤
n
d‚Ä≤
n  C‚Ä≤
n‚àí1
 ¬∑ ¬∑ ¬∑
It is easy to check that the composite g f of two chain maps
f‚Ä¢ : (C‚Ä¢, d‚Ä¢) ‚Üí(C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢)
and
g‚Ä¢ : (C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢) ‚Üí(C‚Ä≤‚Ä≤
‚Ä¢, d‚Ä≤‚Ä≤
‚Ä¢ )
is itself a chain map, where (g f )n = gn fn. The identity chain map 1C‚Ä¢ on (C‚Ä¢, d‚Ä¢) is the
sequence of identity maps 1Cn : Cn ‚ÜíCn.
DeÔ¨Ånition.
If R is a ring, then the category of all complexes of left R-modules is denoted
by RComp; if the ring R is understood, then we will omit the prescript R.
The category Comp is a preadditive category (that is, the Hom's are abelian groups and
the distributive laws hold whenever possible) if we deÔ¨Åne
( f + g)n = fn + gn for all n ‚ààZ.
The following deÔ¨Ånitions imitate the construction of homology groups of triangulated
spaces that we described in Section 10.1.
DeÔ¨Ånition.
If (C‚Ä¢, d‚Ä¢) is a complex, deÔ¨Åne
n-cycles = Zn(C‚Ä¢) = ker dn;
n-boundaries = Bn(C‚Ä¢) = im dn+1.
Since the equation dndn+1 = 0 in a complex is equivalent to the condition
im dn+1 ‚äÜker dn,
we have Bn(C‚Ä¢) ‚äÜZn(C‚Ä¢) for every complex C‚Ä¢.

818
Homology
Ch. 10
DeÔ¨Ånition.
If C‚Ä¢ is a complex and n ‚ààZ, its nth homology is
Hn(C‚Ä¢) = Zn(C‚Ä¢)/Bn(C‚Ä¢).
Example 10.35.
A complex is an exact sequence if and only if all its homology groups are {0}: that is,
Hn(C‚Ä¢) = {0} for all n. Thus, the homology groups measure the deviation of a complex
from being an exact sequence. An exact sequence is often called an acyclic complex;
acyclic means "no cycles"; that is, no cycles that are not boundaries.
‚óÄ
Example 10.36.
In Example 10.34(vi), we saw that every homomorphism f : A ‚ÜíB can be viewed as
part of a complex C‚Ä¢ with C1 = A, C0 = B, d1 = f , and having {0}'s to the left and to
the right. Now d2 = 0 implies im d2 = 0, and d0 = 0 implies ker d0 = B; it follows that
Hn(C‚Ä¢) =
Ô£±
Ô£¥Ô£≤
Ô£¥Ô£≥
ker f
if n = 1;
coker f
if n = 0;
0
otherwise.
‚óÄ
Proposition 10.37.
For each n ‚ààZ, homology Hn : RComp ‚ÜíRMod is an additive
functor.
Proof.
We have just deÔ¨Åned Hn on objects; it remains to deÔ¨Åne Hn on morphisms. If
f : (C‚Ä¢, d‚Ä¢) ‚Üí(C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢) is a chain map, deÔ¨Åne Hn( f ): Hn(C‚Ä¢) ‚ÜíHn(C‚Ä≤
‚Ä¢) by
Hn( f ): zn + Bn(C‚Ä¢) ‚Üífnzn + Bn(C‚Ä≤
‚Ä¢).
We must show that fnzn is a cycle and that Hn( f ) is independent of the choice of cycle
zn; both of these follow from f being a chain map; that is, from commutativity of the
following diagram:
Cn+1
dn+1 
fn+1

Cn
dn 
fn

Cn‚àí1
fn‚àí1

C‚Ä≤
n+1 d‚Ä≤
n+1
 C‚Ä≤
n
d‚Ä≤
n
 C‚Ä≤
n‚àí1
First, let z be an n-cycle in Zn(C‚Ä¢), so that dnz = 0. Then commutativity of the diagram
gives
d‚Ä≤
n fnz = fn‚àí1dnz = 0.
Therefore, fnz is an n-cycle.
Next, assume that z + Bn(C‚Ä¢) = y + Bn(C‚Ä¢); hence, z ‚àíy ‚ààBn(C‚Ä¢); that is,
z ‚àíy = dn+1c

Sec. 10.4
Homology Functors
819
for some c ‚ààCn+1. Applying fn gives
fnz ‚àífny = fndn+1c = d‚Ä≤
n+1 fn+1c ‚ààBn(C‚Ä≤
‚Ä¢).
Thus, fnz + Bn(C‚Ä≤
‚Ä¢) = fny + Bn(C‚Ä≤
‚Ä¢).
Let us see that Hn is a functor. It is obvious that Hn(1C‚Ä¢) is the identity. If f and g are
chain maps whose composite g f is deÔ¨Åned, then for every n-cycle z, we have
Hn(g f ): z + B ‚Üí(g f )n(z + B)
= gn fn(z + B)
= Hn(g)( fnz + B)
= Hn(g)Hn( f )(z + B).
Finally, Hn is additive: if g : (C‚Ä¢, d‚Ä¢) ‚Üí(C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢) is another chain map, then
Hn( f + g): z + Bn(C‚Ä¢) ‚Üí( fn + gn)z + Bn(C‚Ä≤
‚Ä¢)
= fnz + gnz + Bn(C‚Ä≤
‚Ä¢)
=

Hn( f ) + Hn(g)

(z + Bn(C‚Ä≤
‚Ä¢)).
‚Ä¢
DeÔ¨Ånition.
We call Hn( f ) the induced map, and we usually denote it by fn‚àó, or even
by f‚àó.
Proposition 10.38.
Let R and A be rings, and let T : RMod ‚ÜíAMod be an exact
additive functor. Then T commutes with homology; that is, for every complex (C‚Ä¢, d‚Ä¢) ‚àà
RComp and for every n ‚ààZ, there is an isomorphism
Hn(T C‚Ä¢, T d‚Ä¢) ‚àº= T Hn(C‚Ä¢, d‚Ä¢).
Proof.
Consider the commutative diagram with exact bottom row,
Cn+1
d‚Ä≤
n+1 
dn+1
 Cn
dn
 Cn‚àí1
0
 im dn+1
j
 ker dn
k

 Hn(C‚Ä¢)
 0,
where j, and k are inclusions and d‚Ä≤
n+1 is just dn+1 with its target changed from Cn to
im dn+1. Applying the exact functor T gives the commutative diagram with exact bottom
row
TCn+1
T d‚Ä≤
n+1 
T dn+1
 TCn
T dn
 TCn‚àí1
0
 T (im dn+1)
T j
 T (ker dn)
T k

 T Hn(C‚Ä¢)
 0

820
Homology
Ch. 10
On the other hand, because T is exact, we have T (im dn+1) = im T (dn+1) and T (ker dn) =
ker(T dn), so that the bottom row is
0 ‚Üíim(T dn+1) ‚Üíker(T dn) ‚ÜíT Hn(C‚Ä¢) ‚Üí0.
By deÔ¨Ånition, ker(T dn)/ im(T dn+1) = Hn(T C‚Ä¢), and so Hn(T C‚Ä¢) ‚àº= T Hn(C‚Ä¢), by
Proposition 8.93.
‚Ä¢
We now introduce a notion that arises in topology.
DeÔ¨Ånition.
A chain map f : (C‚Ä¢, d‚Ä¢) ‚Üí(C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢) is nullhomotopic if, for all n, there are
maps sn : An ‚ÜíA‚Ä≤
n+1 with
fn = d‚Ä≤
n+1sn + sn‚àí1dn.
¬∑ ¬∑ ¬∑
 An+1
fn+1

dn+1  An
sn
	
fn

dn  An‚àí1
fn‚àí1


sn‚àí1
	
¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑
 A‚Ä≤
n+1 d‚Ä≤
n+1
 A‚Ä≤
n
d‚Ä≤
n
 A‚Ä≤
n‚àí1
 ¬∑ ¬∑ ¬∑
If f, g : (C‚Ä¢, d‚Ä¢) ‚Üí(C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢) are chain maps, then f is homotopic10 to g, denoted by
f ‚ãçg, if f ‚àíg is nullhomotopic.
Proposition 10.39.
Homotopic chain maps induce the same homomorphism between
homology groups: if f, g : (C‚Ä¢, d‚Ä¢) ‚Üí(C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢) are chain maps and f ‚ãçg, then
f‚àón = g‚àón : Hn(C‚Ä¢) ‚ÜíHn(C‚Ä≤
‚Ä¢).
Proof.
If z is an n-cycle, then dnz = 0 and
fnz ‚àígnz = d‚Ä≤
n+1snz + sn‚àí1dnz = d‚Ä≤
n+1snz.
Therefore, fnz ‚àígnz ‚ààBn(C‚Ä≤
‚Ä¢), and so f‚àón = g‚àón.
‚Ä¢
DeÔ¨Ånition.
A complex (C‚Ä¢, d‚Ä¢) has a contracting homotopy11
if its identity 1C‚Ä¢ is
nullhomotopic.
10Two continuous functions f, g: X ‚ÜíY are called homotopic if f can be "deformed" into g; that is, there
exists a continuous F : X √ó I ‚ÜíY, where I = [0, 1] is the closed unit interval, with F(x, 0) = f (x) and
F(x, 1) = g(x) for all x ‚ààX. Now every continuous f : X ‚ÜíY induces homomorphisms f‚àó: Hn(X) ‚Üí
Hn(Y), and one proves that if f and g are homotopic, then f‚àó= g‚àó. The algebraic deÔ¨Ånition of homotopy given
here has been distilled from the proof of this topological theorem.
11A topological space is called contractible if its identity map is homotopic to a constant map.

Sec. 10.4
Homology Functors
821
Proposition 10.40.
A complex (C‚Ä¢, d‚Ä¢) having a contracting homotopy is acyclic; that
is, it is an exact sequence.
Proof.
We use Example 10.35. Now 1C‚Ä¢ : Hn(C‚Ä¢) ‚ÜíHn(C‚Ä¢) is the identity map, while
0‚àó: Hn(C‚Ä¢) ‚ÜíHn(C‚Ä¢) is the zero map. Since 1C‚Ä¢ ‚ãç0, however, these maps are the
same. It follows that Hn(C‚Ä¢) = {0} for all n; that is, ker dn = im dn+1 for all n, and this is
the deÔ¨Ånition of exactness.
‚Ä¢
Once we complete the free resolution of the trivial ZQ-module Z whose Ô¨Årst few terms
were given in Proposition 10.30 (see also Proposition 10.31), we will prove that it is an
exact sequence by showing that it has a contracting homotopy as a complex of abelian
groups.
In order to study the homology functors, it is necessary to understand their domain
Comp. Many of the constructions in RMod can also be done in the category Comp. We
merely list the deÔ¨Ånitions and state certain properties, whose veriÔ¨Åcations are straightfor-
ward exercises for the reader.
(i) An isomorphism in Comp is an equivalence in this category. The reader should
check that a chain map f : C‚Ä¢ ‚ÜíC‚Ä≤
‚Ä¢ is an isomorphism if and only if fn : Cn ‚ÜíC‚Ä≤
n
is an isomorphism in RMod for all n ‚ààZ. (We must check that the sequence of
inverses f ‚àí1
n
is a chain map; that is, that the appropriate diagram commutes.)
(ii) A complex (A‚Ä¢, Œ¥‚Ä¢) is a subcomplex of a complex (C‚Ä¢, d‚Ä¢) if, for every n ‚ààZ, we
have An a submodule of Cn and Œ¥n = dn|An.
If in : An ‚ÜíCn is the inclusion, then it is easy to see that A‚Ä¢ is a subcomplex of C‚Ä¢
if and only if i : A‚Ä¢ ‚ÜíC‚Ä¢ is a chain map.
(iii) If A‚Ä¢ is a subcomplex of C‚Ä¢, then the quotient complex is
C‚Ä¢/A‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚ÜíCn/An
d‚Ä≤‚Ä≤
n
‚àí‚ÜíCn‚àí1/An‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ,
where d‚Ä≤‚Ä≤
n : cn + An ‚Üídncn + An‚àí1 (it must be shown that d‚Ä≤‚Ä≤
n is well-deÔ¨Åned: if
cn + An = bn + An, then dncn + An‚àí1 = dnbn + An‚àí1). If œÄn : Cn ‚ÜíCn/An is the
natural map, then œÄ : C‚Ä¢ ‚ÜíC‚Ä¢/A‚Ä¢ is a chain map.
(iv) If f‚Ä¢ : (C‚Ä¢, d‚Ä¢) ‚Üí(C‚Ä≤
‚Ä¢, d‚Ä≤
‚Ä¢) is a chain map, deÔ¨Åne
ker f = ¬∑ ¬∑ ¬∑ ‚Üíker fn+1
Œ¥n+1
‚àí‚Üíker fn
Œ¥n
‚àí‚Üíker fn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ,
where Œ¥n = dn| ker fn, and deÔ¨Åne
im f = ¬∑ ¬∑ ¬∑ ‚Üíim fn+1
n+1
‚àí‚Üíim fn
n
‚àí‚Üíim fn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ,
where n = d‚Ä≤
n| im fn. It is easy to see that ker f is a subcomplex of C‚Ä¢, that im f
is a subcomplex of C‚Ä≤
‚Ä¢, and that the Ô¨Årst isomorphism theorem holds:
C‚Ä¢/ker f ‚àº= im f.

822
Homology
Ch. 10
(v) A sequence of complexes and chain maps
¬∑ ¬∑ ¬∑ ‚ÜíC‚Ä¢n+1 f n+1
‚àí‚ÜíC‚Ä¢n
f n
‚àí‚ÜíC‚Ä¢n‚àí1 ‚Üí¬∑ ¬∑ ¬∑
is an exact sequence if, for all n ‚ààZ,
im f n+1 = ker f n.
We may check that if A‚Ä¢ is a subcomplex of C‚Ä¢, then there is an exact sequence of
complexes
0‚Ä¢ ‚ÜíA‚Ä¢
i
‚àí‚ÜíC‚Ä¢,
where 0‚Ä¢ is the zero complex and i is the chain map of inclusions. More generally, if
i : C‚Ä¢ ‚ÜíC‚Ä≤
‚Ä¢ is a chain map, then each in is injective if and only if there is an exact
sequence 0‚Ä¢ ‚ÜíC‚Ä¢
i
‚àí‚ÜíC‚Ä≤
‚Ä¢. Similarly, if p: C‚Ä¢ ‚ÜíC‚Ä≤‚Ä≤
‚Ä¢ is a chain map, then each pn
is surjective if and only if there is an exact sequence
C‚Ä¢
p
‚àí‚ÜíC‚Ä≤‚Ä≤
‚Ä¢ ‚Üí0‚Ä¢.
The reader should realize that this notation is very compact. For example, if we
write a complex as a column, then a short exact sequence of complexes is really the
inÔ¨Ånite commutative diagram with exact rows:



0
 C‚Ä≤
n+1
in+1 
d‚Ä≤
n+1

Cn+1
pn+1 
dn+1

C‚Ä≤‚Ä≤
n+1
d‚Ä≤‚Ä≤
n+1

 0
0
 C‚Ä≤
n
in

d‚Ä≤
n 
Cn
pn

dn

C‚Ä≤‚Ä≤
n
d‚Ä≤‚Ä≤
n

 0
0
 C‚Ä≤
n‚àí1
in‚àí1 

Cn‚àí1
pn‚àí1 

C‚Ä≤‚Ä≤
n‚àí1

 0
A sequence of complexes ¬∑ ¬∑ ¬∑ ‚ÜíC‚Ä¢n+1 f n+1
‚àí‚ÜíC‚Ä¢n
f n
‚àí‚ÜíC‚Ä¢n‚àí1 ‚Üí¬∑ ¬∑ ¬∑ is exact if and
only if
¬∑ ¬∑ ¬∑ ‚ÜíCn+1
m
‚ÜíCn
m ‚ÜíCn‚àí1
m
‚Üí¬∑ ¬∑ ¬∑
is an exact sequence of modules for every m ‚ààZ.

Sec. 10.4
Homology Functors
823
(vi) If {(CŒ±
‚Ä¢, dŒ±
‚Ä¢ )} is a family of complexes, then their direct sum is the complex

Œ±
CŒ±
‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚Üí

Œ±
CŒ±
n+1

Œ± dŒ±
n
‚àí‚Üí

Œ±
CŒ±
n

Œ± dŒ±
n‚àí1
‚àí‚Üí

Œ±
CŒ±
n‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ,
where 
Œ± dŒ±
n acts coordinatewise; that is, 
Œ± dŒ±
n : (cŒ±
n ) ‚Üí(dŒ±
n cŒ±
n ).
To summarize, we can view Comp as a category having virtually the same properties
as the category of modules; indeed, we should view a complex as a generalized module.
(Categories such as RMod and Comp are called abelian categories.)
The following elementary construction is fundamental; it gives a relation between dif-
ferent homology modules. The proof is a series of diagram chases. Ordinarily, we would
just say that the proof is routine, but, because of the importance of the result, we present
(perhaps too many) details; as a sign that the proof is routine, we drop subscripts.
Proposition 10.41 (Connecting Homomorphism).
If
0‚Ä¢ ‚ÜíC‚Ä≤
‚Ä¢
i
‚àí‚ÜíC‚Ä¢
p
‚àí‚ÜíC‚Ä≤‚Ä≤
‚Ä¢ ‚Üí0‚Ä¢
is an exact sequence of complexes, then, for each n ‚ààZ, there is a homomorphism
‚àÇn : Hn(C‚Ä≤‚Ä≤
‚Ä¢) ‚ÜíHn‚àí1(C‚Ä≤
‚Ä¢)
deÔ¨Åned by
‚àÇn : z‚Ä≤‚Ä≤
n + Bn(C‚Ä≤‚Ä≤
‚Ä¢) ‚Üíi‚àí1
n‚àí1dn p‚àí1
n z‚Ä≤‚Ä≤
n + Bn‚àí1(C‚Ä≤
‚Ä¢).
Proof.
We will make many notational abbreviations in this proof. Consider the commu-
tative diagram having exact rows:



0
 C‚Ä≤
n+1
in+1 
d‚Ä≤
n+1

Cn+1
pn+1 
dn+1

C‚Ä≤‚Ä≤
n+1
d‚Ä≤‚Ä≤
n+1

 0
0
 C‚Ä≤
n
in

d‚Ä≤
n 
Cn
1
pn

dn

C‚Ä≤‚Ä≤
n
d‚Ä≤‚Ä≤
n



0
0
 C‚Ä≤
n‚àí1
in‚àí1 

Cn‚àí1
2
pn‚àí1 

C‚Ä≤‚Ä≤
n‚àí1

 0
Suppose that z‚Ä≤‚Ä≤ ‚ààC‚Ä≤‚Ä≤
n and d‚Ä≤‚Ä≤z‚Ä≤‚Ä≤ = 0. Since pn is surjective, there is c ‚ààCn with pc = z‚Ä≤‚Ä≤.
Now push c down to dc ‚ààCn‚àí1. By commutativity, pn‚àí1dc = d‚Ä≤‚Ä≤ pnc = d‚Ä≤‚Ä≤z‚Ä≤‚Ä≤ = 0, so

824
Homology
Ch. 10
that dc ‚ààker pn‚àí1 = im in‚àí1. Therefore, there is a unique c‚Ä≤ ‚ààC‚Ä≤
n‚àí1 with in‚àí1c‚Ä≤ = dc,
for in‚àí1 is an injection. Thus, i‚àí1
n‚àí1dp‚àí1
n z‚Ä≤‚Ä≤ makes sense; that is, the claim is that
‚àÇn(z‚Ä≤‚Ä≤ + B‚Ä≤‚Ä≤
n ) = c‚Ä≤ + B‚Ä≤
n‚àí1
is a well-deÔ¨Åned homomorphism.
First, let us show independence of the choice of lifting. Suppose that pn Àác = z‚Ä≤‚Ä≤, where
Àác ‚ààCn. Then c ‚àíÀác ‚ààker pn = im in, so that there is u‚Ä≤ ‚ààC‚Ä≤
n with inu‚Ä≤ = c ‚àíÀác. By
commutativity of the Ô¨Årst square, we have
in‚àí1d‚Ä≤u‚Ä≤ = dinu‚Ä≤ = dc ‚àíd Àác.
Hence, i‚àí1dc ‚àíi‚àí1d Àác = d‚Ä≤u‚Ä≤ ‚ààB‚Ä≤
n‚àí1; that is, i‚àí1dc + B‚Ä≤
n‚àí1 = i‚àí1d Àác + B‚Ä≤
n‚àí1. Thus, the
formula gives a well-deÔ¨Åned function
Z‚Ä≤‚Ä≤
n ‚ÜíC‚Ä≤
n‚àí1/B‚Ä≤
n‚àí1.
Second, the function Z‚Ä≤‚Ä≤
n ‚ÜíC‚Ä≤
n‚àí1/B‚Ä≤
n‚àí1 is a homomorphism. If z‚Ä≤‚Ä≤, z‚Ä≤‚Ä≤
1 ‚ààZ‚Ä≤‚Ä≤
n, let pc =
z‚Ä≤‚Ä≤ and pc1 = z‚Ä≤‚Ä≤
1. Since the deÔ¨Ånition of ‚àÇis independent of the choice of lifting, choose
c + c1 as a lifting of z‚Ä≤‚Ä≤ + z‚Ä≤‚Ä≤
1. This step may now be completed in a routine way.
Third, we show that if in‚àí1c‚Ä≤ = dc, then c‚Ä≤ is a cycle: 0 = ddc = dic‚Ä≤ = idc‚Ä≤, and so
d‚Ä≤c‚Ä≤ = 0 because i is an injection. Hence, the formula gives a homomorphism
Z‚Ä≤‚Ä≤ ‚ÜíZ‚Ä≤/B‚Ä≤ = Hn‚àí1.
Finally, the subgroup B‚Ä≤‚Ä≤
n goes into B‚Ä≤
n‚àí1. Suppose that z‚Ä≤‚Ä≤ = d‚Ä≤‚Ä≤c‚Ä≤‚Ä≤, where c‚Ä≤‚Ä≤ ‚ààC‚Ä≤‚Ä≤
n+1,
and let pu = c‚Ä≤‚Ä≤, where u ‚ààCn+1. Commutativity gives pdu = d‚Ä≤‚Ä≤ pu = d‚Ä≤‚Ä≤c‚Ä≤‚Ä≤ = z‚Ä≤‚Ä≤.
Since ‚àÇ(z‚Ä≤‚Ä≤) is independent of the choice of lifting, we choose du with pdu = z‚Ä≤‚Ä≤, and so
‚àÇ(z‚Ä≤‚Ä≤ + B‚Ä≤‚Ä≤) = i‚àí1d(du) + B‚Ä≤ = B‚Ä≤. Therefore, the formula does give a homomorphism
‚àÇn : Hn(C‚Ä≤‚Ä≤
‚Ä¢) ‚ÜíHn‚àí1(C‚Ä≤
‚Ä¢).
‚Ä¢
The Ô¨Årst question we ask is what homology functors do to a short exact sequence of
complexes. The next theorem is also proved by diagram chasing and, again, we give too
many details because of the importance of the result. The reader should try to prove the
theorem before looking at the proof we give.
Theorem 10.42 (Long Exact Sequence).
If
0‚Ä¢ ‚ÜíC‚Ä≤
‚Ä¢
i
‚àí‚ÜíC‚Ä¢
p
‚àí‚ÜíC‚Ä≤‚Ä≤
‚Ä¢ ‚Üí0‚Ä¢
is an exact sequence of complexes, then there is an exact sequence of modules
¬∑ ¬∑ ¬∑ ‚ÜíHn+1(C‚Ä≤‚Ä≤
‚Ä¢)
‚àÇn+1
‚àí‚ÜíHn(C‚Ä≤
‚Ä¢)
i‚àó
‚àí‚ÜíHn(C‚Ä¢)
p‚àó
‚àí‚ÜíHn(C‚Ä≤‚Ä≤
‚Ä¢)
‚àÇn
‚àí‚ÜíHn‚àí1(C‚Ä≤
‚Ä¢) ‚Üí¬∑ ¬∑ ¬∑ .

Sec. 10.4
Homology Functors
825
Proof.
This proof is also routine. Our notation is abbreviated, and there are six inclusions
to verify.
(i) im i‚àó‚äÜker p‚àó
p‚àói‚àó= (pi)‚àó= 0‚àó= 0
(ii) ker p‚àó‚äÜim i‚àó
If p‚àó(z + B) = pz + B‚Ä≤‚Ä≤ = B‚Ä≤‚Ä≤, then pz = d‚Ä≤‚Ä≤c‚Ä≤‚Ä≤ for some c‚Ä≤‚Ä≤ ‚ààC‚Ä≤‚Ä≤
n+1. But p surjective
gives c‚Ä≤‚Ä≤ = pc for some c ‚ààCn+1, so that pz = d‚Ä≤‚Ä≤ pc = pdc, because p is a chain map,
and so p(z ‚àídc) = 0. By exactness, there is c‚Ä≤ ‚ààC‚Ä≤
n with ic‚Ä≤ = z ‚àídc. Now c‚Ä≤ is a
cycle, for id‚Ä≤c‚Ä≤ = dic‚Ä≤ = dz ‚àíddc = 0, because z is a cycle; since i is injective, d‚Ä≤c‚Ä≤ = 0.
Therefore,
i‚àó(c‚Ä≤ + B‚Ä≤) = ic‚Ä≤ + B = z ‚àídc + B = z + B.
(iii) im p‚àó‚äÜker ‚àÇ
If p‚àó(c + B) = pc + B‚Ä≤‚Ä≤ ‚ààim p‚àó, then ‚àÇ(pz + B‚Ä≤‚Ä≤) = z‚Ä≤ + B‚Ä≤, where iz‚Ä≤ = dp‚àí1 pz.
Since this formula is independent of the choice of liÔ¨Ång of pz, let us choose p‚àí1 pz = z.
Now dp‚àí1 pz = dz = 0, because z is a cycle. Thus, iz‚Ä≤ = 0, and hence z‚Ä≤ = 0, because i
is injective.
(iv) ker ‚àÇ‚äÜim p‚àó
If ‚àÇ(z‚Ä≤‚Ä≤ + B‚Ä≤‚Ä≤) = B‚Ä≤, then z‚Ä≤ = i‚àí1dp‚àí1z‚Ä≤‚Ä≤ ‚ààB‚Ä≤; that is, z‚Ä≤ = d‚Ä≤c‚Ä≤ for some c‚Ä≤ ‚ààC‚Ä≤. But
iz‚Ä≤ = id‚Ä≤c‚Ä≤ = dic‚Ä≤ = dp‚àí1z‚Ä≤‚Ä≤, so that d(p‚àí1z‚Ä≤‚Ä≤ ‚àíic‚Ä≤) = 0; that is, p‚àí1z‚Ä≤‚Ä≤ ‚àíic‚Ä≤ is a cycle.
Moreover, since pi = 0 because of exactness of the original sequence,
p‚àó(p‚àí1z‚Ä≤‚Ä≤ ‚àíic‚Ä≤ + B) = pp‚àí1z‚Ä≤‚Ä≤ ‚àípic‚Ä≤ + B‚Ä≤‚Ä≤ = z‚Ä≤‚Ä≤ + B‚Ä≤‚Ä≤.
(v) im ‚àÇ‚äÜker i‚àó
We have i‚àó‚àÇ(z‚Ä≤‚Ä≤ + B‚Ä≤‚Ä≤) = iz‚Ä≤ + B‚Ä≤, where iz‚Ä≤ = dp‚àí1z‚Ä≤‚Ä≤ ‚ààB; that is, i‚àó‚àÇ= 0.
(vi) ker i‚àó‚äÜim ‚àÇ
If i‚àó(z‚Ä≤ + B‚Ä≤) = iz‚Ä≤ + B = B, then iz‚Ä≤ = dc for some c ‚ààC. Since p is a chain map,
d‚Ä≤‚Ä≤ pc = pdc = piz‚Ä≤ = 0, by exactness of the original sequence, and so pc is a cycle. But
‚àÇ(pc + B‚Ä≤‚Ä≤) = i‚àí1dp‚àí1 pc + B‚Ä≤ = i‚àí1dc + B‚Ä≤ = i‚àí1iz‚Ä≤ + B‚Ä≤ = z‚Ä≤ + B‚Ä≤.
‚Ä¢
Theorem 10.42 is often called the exact triangle because of the diagram
H‚Ä¢(C‚Ä≤
‚Ä¢)
i‚àó
 H‚Ä¢(C‚Ä¢)
p‚àó
))))))))))
H‚Ä¢(C‚Ä≤‚Ä≤
‚Ä¢)
‚àÇ
$!!!!!!!!!

826
Homology
Ch. 10
Corollary 10.43 (Snake Lemma).
Given a commutative diagram of modules with exact
rows,
0
 A‚Ä≤

f

A

g

A‚Ä≤‚Ä≤

h

0
0
 B‚Ä≤
 B
 B‚Ä≤‚Ä≤
 0
there is an exact sequence
0 ‚Üíker f ‚Üíker g ‚Üíker h ‚Üícoker f ‚Üícoker g ‚Üícoker h ‚Üí0.
Proof.
If we view each of the vertical maps f , g, and h as a complex [as in Exam-
ple 10.34(vi)], then the given commutative diagram can be viewed as a short exact se-
quence of complexes. The homology groups of each of these complexes has only two
nonzero terms: for example, Example 10.36 shows that the homology groups of the Ô¨Årst
column are H1 = ker f , H0 = coker f , and all other Hn = {0}. The snake lemma now
follows at once from the long exact sequence.
‚Ä¢
Theorem 10.44 (Naturality of ‚àÇ).
Given a commutative diagram of complexes with
exact rows,
0‚Ä¢
 C‚Ä≤
‚Ä¢
i

f

C‚Ä¢
p

g

C‚Ä≤‚Ä≤
‚Ä¢

h

0‚Ä¢
0‚Ä¢
 A‚Ä≤
‚Ä¢
j
 A‚Ä¢
q
 A‚Ä≤‚Ä≤
‚Ä¢
 0‚Ä¢
there is a commutative diagram of modules with exact rows,
¬∑ ¬∑ ¬∑
 Hn(C‚Ä≤
‚Ä¢)
i‚àó

f‚àó

Hn(C‚Ä¢)
p‚àó

g‚àó

Hn(C‚Ä≤‚Ä≤
‚Ä¢)
‚àÇ

h‚àó

Hn‚àí1(C‚Ä≤
‚Ä¢)
f‚àó

 ¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑
 Hn(A‚Ä≤
‚Ä¢)
j‚àó
 Hn(A‚Ä¢)
q‚àó
 Hn(A‚Ä≤‚Ä≤
‚Ä¢)
‚àÇ‚Ä≤  Hn‚àí1(A‚Ä≤
‚Ä¢)
 ¬∑ ¬∑ ¬∑
Proof.
Exactness of the rows is Theorem 10.42, while commutativity of the Ô¨Årst two
squares follows from Hn being a functor. To prove commutativity of the square involving
the connecting homomorphism, let us Ô¨Årst display the chain maps and differentiations in
one (three-dimensional!) diagram:
0
 C‚Ä≤
n
f‚àó

i

d‚Ä≤

Cn
d
g‚àó

p
 C‚Ä≤‚Ä≤
n

h‚àó

d‚Ä≤‚Ä≤

0
0
 C‚Ä≤
n‚àí1
f‚àó

i
 Cn‚àí1
g‚àó

p
 C‚Ä≤‚Ä≤
n‚àí1
h‚àó

 0
0
 A‚Ä≤
n
j

Œ¥‚Ä≤

An
q

Œ¥

A‚Ä≤‚Ä≤
n

Œ¥‚Ä≤‚Ä≤

0
0
 A‚Ä≤
n‚àí1
j
 An‚àí1
q
 A‚Ä≤‚Ä≤
n‚àí1
 0

Sec. 10.4
Homology Functors
827
If z‚Ä≤‚Ä≤ + B(C‚Ä≤‚Ä≤
‚Ä¢) ‚ààHn(C‚Ä≤‚Ä≤
‚Ä¢), we must show that
f‚àó‚àÇ(z‚Ä≤‚Ä≤ + B(C‚Ä≤‚Ä≤
‚Ä¢)) = ‚àÇ‚Ä≤h‚àó(z‚Ä≤‚Ä≤ + B(C‚Ä≤‚Ä≤
‚Ä¢)).
Let c ‚ààCn be a lifting of z‚Ä≤‚Ä≤; that is, pc = z‚Ä≤‚Ä≤. Now ‚àÇ(z‚Ä≤‚Ä≤ + B(C‚Ä≤‚Ä≤
‚Ä¢)) = z‚Ä≤ + B(C‚Ä≤
‚Ä¢), where
iz‚Ä≤ = dc. Hence, f‚àó‚àÇ(z‚Ä≤‚Ä≤ + B(A‚Ä≤‚Ä≤
‚Ä¢)) = f z‚Ä≤ + B(A‚Ä≤
‚Ä¢). On the other hand, since h is a chain
map, we have qgc = hpc = hz‚Ä≤‚Ä≤. In computing ‚àÇ‚Ä≤(hz‚Ä≤‚Ä≤ + B(A‚Ä≤‚Ä≤
‚Ä¢)), we choose gc as the
lifting of hz‚Ä≤‚Ä≤. Hence, ‚àÇ‚Ä≤(hz‚Ä≤‚Ä≤ + B(A‚Ä≤‚Ä≤
‚Ä¢) = u‚Ä≤ + B(A‚Ä≤
‚Ä¢), where ju‚Ä≤ = Œ¥gc. But
j f z‚Ä≤ = giz‚Ä≤ = gdc = Œ¥gc = ju‚Ä≤,
and so f z‚Ä≤ = u‚Ä≤, because j is injective.
‚Ä¢
We shall apply these general results in the next section.
EXERCISES
10.21 If C‚Ä¢ is a complex with Cn = {0} for some n, prove that Hn(C‚Ä¢) = {0}.
10.22 Prove that isomorphic complexes have the same homology: If C‚Ä¢ and D‚Ä¢ are isomorphic, then
Hn(C‚Ä¢) ‚àº= Hn(D‚Ä¢) for all n.
10.23 Regard the map d : Z ‚ÜíZ, deÔ¨Åned by d : m ‚Üí2m, as a complex, as in Example 10.34(vi).
Prove that it is not a projective object in the category ZComp even though each of its terms is
a projective Z-module.
10.24 View Z as the category PO(Z) whose objects are the integers, and with exactly one morphism
n ‚Üím whenever m ‚â§n, with no morphisms otherwise. [If we view Z as a partially ordered
set, then this is the associated category deÔ¨Åned in Example 7.25(v).] Prove that a complex
(C‚Ä¢, d‚Ä¢) is a contravariant functor PO(Z) ‚ÜíR Mod, and that a chain map is a natural trans-
formation.
10.25 In this exercise, we prove that the snake lemma implies the long exact sequence (the converse
is Corollary 10.43). Consider a commutative diagram with exact rows (note that two zeros are
"missing" from this diagram):
A

Œ±

B
p

Œ≤

C

Œ≥

0
0
 A‚Ä≤
i
 B‚Ä≤
 C‚Ä≤
(i) Prove that : ker Œ≥ ‚Üícoker Œ±, deÔ¨Åned by
: z ‚Üíi‚àí1Œ≤p‚àí1z + im Œ±,
is a well-deÔ¨Åned homomorphism.
(ii) Prove that there is an exact sequence
ker Œ± ‚Üíker Œ≤ ‚Üíker Œ≥

‚àí‚Üícoker Œ± ‚Üícoker Œ≤ ‚Üícoker Œ≥.

828
Homology
Ch. 10
(iii) Given a commutative diagram with exact rows,
0
 A‚Ä≤n

d‚Ä≤
n

An

d

A‚Ä≤‚Ä≤n

d‚Ä≤‚Ä≤
n

0
0
 A‚Ä≤
n‚àí1
 An‚àí1
 A‚Ä≤‚Ä≤
n‚àí1
 0
prove that the following diagram is commutative and has exact rows:
A‚Ä≤n/ im d‚Ä≤
n+1

d‚Ä≤

An/ im dn+1

d

A‚Ä≤‚Ä≤n/ im d‚Ä≤‚Ä≤
n+1

d‚Ä≤‚Ä≤

0
0
 ker d‚Ä≤
n‚àí1
 ker dn‚àí1
 ker d‚Ä≤‚Ä≤
n‚àí1
(iv) Use part (ii) and this last diagram to give another proof of the long exact sequence.
10.26 Let f, g: C‚Ä¢ ‚ÜíC‚Ä≤‚Ä¢ be chain maps, and let F : C‚Ä¢ ‚ÜíC‚Ä≤‚Ä¢ be an additive functor. If f ‚ãçg,
prove that F f ‚ãçFg; that is, if f and g are homotopic, then F f and Fg are homotopic.
10.27 Let 0‚Ä¢ ‚ÜíC‚Ä≤‚Ä¢
i
‚àí‚ÜíC‚Ä¢
p
‚àí‚ÜíC‚Ä≤‚Ä≤‚Ä¢ ‚Üí0‚Ä¢ be an exact sequence of complexes in which C‚Ä≤‚Ä¢ and
C‚Ä≤‚Ä≤‚Ä¢ are acyclic; prove that C‚Ä¢ is also acyclic.
10.28 Let (C‚Ä¢, d‚Ä¢) be a complex each of whose differentiations dn is the zero map. Prove that
Hn(C‚Ä¢) ‚àº= Cn for all n.
10.29 (3 √ó 3 Lemma) Given a commutative diagram in which the columns and the bottom two rows
are exact sequences,
0

0

0

0
 K ‚Ä≤

 K


K ‚Ä≤‚Ä≤

 0
0
 P‚Ä≤

 P


P‚Ä≤‚Ä≤

 0
0
 A‚Ä≤


A


A‚Ä≤‚Ä≤


0
0
0
0
prove that the top row is an exact sequence.
10.30 Prove that homology commutes with direct sums: For all n, there are natural isomorphisms
Hn

Œ±
CŒ±
‚Ä¢

‚àº=

Œ±
Hn(CŒ±
‚Ä¢).

Sec. 10.4
Homology Functors
829
10.31
(i) DeÔ¨Åne a direct system of complexes {Ci‚Ä¢, œïi
j}, and prove that lim
‚àí‚ÜíCi‚Ä¢ exists.
(ii) If {Ci‚Ä¢, œïi
j} is a direct system of complexes over a directed index set, prove, for all n ‚â•0,
that
Hn(lim
‚àí‚ÜíCi
‚Ä¢) ‚àº= lim
‚àí‚ÜíHn(Ci
‚Ä¢).
10.32 Suppose that a complex (C‚Ä¢, d‚Ä¢) of R-modules has a contracting homotopy in which the maps
sn : Cn ‚ÜíCn+1 satisfying
1Cn = dn+1sn + sn‚àí1dn
are only Z-maps. Prove that (C‚Ä¢, d‚Ä¢) is an exact sequence.
10.33
(i) Let 0 ‚ÜíFn ‚ÜíFn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíF0 ‚Üí0 be an exact sequence of Ô¨Ånitely generated
free k-modules, where k is a commutative ring. Prove that
n

i=0
(‚àí1)i rank(Fi) = 0.
(ii) Let
0 ‚ÜíFn ‚ÜíFn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíF0 ‚ÜíM ‚Üí0
and
0 ‚ÜíF‚Ä≤
m ‚ÜíF‚Ä≤
m‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíF‚Ä≤
0 ‚ÜíM ‚Üí0
be free resolutions of a k-module M in which all Fi and F‚Ä≤
j are Ô¨Ånitely generated free
k-modules. Prove that
n

i=0
(‚àí1)i rank(Fi) =
m

j=0
(‚àí1) j rank(F‚Ä≤
j).
The common value is denoted by œá(M), and it is called the Euler-Poincar¬¥e character-
istic of M.
Hint. Use Schanuel's lemma.
10.34
(i) Let C‚Ä¢ : 0 ‚ÜíCn ‚ÜíCn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíC0 ‚Üí0 be a complex of Ô¨Ånitely generated free
k-modules over a commutative ring k. Prove that
n

i=0
(‚àí1)i rank(Ci) =
n

i=0
(‚àí1)i rank(Hi(C‚Ä¢)).
(ii) Let 0 ‚ÜíM‚Ä≤ ‚ÜíM ‚ÜíM‚Ä≤‚Ä≤ ‚Üí0 be an exact sequence of k-modules. If two of the
modules have an Euler-Poincar¬¥e characteristic, prove that the third module does, too,
and that
œá(M) = œá(M‚Ä≤) + œá(M‚Ä≤‚Ä≤).
10.35
(i) (Barratt-Whitehead). Consider the commutative diagram with exact rows:
An
in

fn

Bn
pn

gn

Cn
‚àÇn 
hn

An‚àí1

fn‚àí1

Bn‚àí1

gn‚àí1

Cn‚àí1
hn‚àí1

A‚Ä≤n
jn
 B‚Ä≤n
qn
 C‚Ä≤n
 A‚Ä≤
n‚àí1
 B‚Ä≤
n‚àí1
 C‚Ä≤
n‚àí1

830
Homology
Ch. 10
If each hn is an isomorphism, prove that there is an exact sequence
An
( fn,in)
‚àí‚ÜíA‚Ä≤
n ‚äïBn
jn‚àígn
‚àí‚ÜíB‚Ä≤
n
‚àÇnh‚àí1
n qn
‚àí‚Üí
An‚àí1 ‚ÜíA‚Ä≤
n‚àí1 ‚äïBn‚àí1 ‚ÜíB‚Ä≤
n‚àí1,
where ( fn, in): an ‚Üí( fnan, inan) and jn ‚àígn : (a‚Ä≤n, bn) ‚Üíjna‚Ä≤n ‚àígnbn.
(ii) (Mayer-Vietoris). Assume, in the diagram of Theorem 10.44, that every third vertical
map h‚àóis an isomorphism. Prove that there is an exact sequence
¬∑ ¬∑ ¬∑ ‚ÜíHn(C‚Ä≤
‚Ä¢) ‚ÜíHn(A‚Ä≤
‚Ä¢) ‚äïHn(C‚Ä¢) ‚ÜíHn(A‚Ä¢) ‚ÜíHn‚àí1(C‚Ä≤
‚Ä¢) ‚Üí¬∑ ¬∑ ¬∑ .
Remark.
The Eilenberg-Steenrod axioms characterize homology functors on the category Top
of all topological spaces and continuous maps. If hn : Top ‚ÜíAb is a sequence of functors, for all
n ‚â•0, satisfying the long exact sequence, naturality of connecting homomorphisms, hn( f ) = hn(g)
whenever f and g are homotopic, h0(X) = Z and hn(X) = {0} for all n > 0 when X is a 1-point
space, and excision, then there are natural isomorphisms hn ‚ÜíHn for all n. Now excision involves
an added construction, called relative homology, but in the presence of the other axioms, excision
can be replaced by exactness of the Mayer-Vietoris sequence.
‚óÄ
10.5 DERIVED FUNCTORS
In order to apply the general results about homology, we need a source of short exact
sequences of complexes, as well as commutative diagrams in which they sit. The idea is
to replace a module by a (deleted) resolution of it. We then apply either Hom or ‚äó, and
the resulting homology modules are called Ext or Tor. Given a short exact sequence of
modules, we shall see that we may replace each of its modules by a resolution and obtain
a short exact sequence of complexes.
This section is fairly dry, but it is necessary to establish the existence of homology
functors. The most useful theorems in this section are Theorem 10.46 (the comparison the-
orem), Proposition 10.50 (which shows that the basic construction is well-deÔ¨Åned), Corol-
lary 10.57 (the long exact sequence), and Proposition 10.58 (naturality of the connecting
homomorphism).
For those readers who are interested in using Tor (the left derived functors of tensor) and
Ext (the right derived functors of Hom) immediately, and who are willing to defer looking
at mazes of arrows, the next theorem gives a set of axioms characterizing the functors Extn.
Theorem 10.45.
Let EXTn : RMod ‚ÜíAb be a sequence of contravariant functors, for
n ‚â•0, such that
(i) for every short exact sequence 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0, there is a long exact
sequence and natural connecting homomorphisms
¬∑ ¬∑ ¬∑ ‚ÜíEXTn(C) ‚ÜíEXTn(B) ‚ÜíEXTn(A)
n
‚àí‚ÜíEXTn+1(C) ‚Üí¬∑ ¬∑ ¬∑ ;
(ii) there is a left R-module M with EXT0 and HomR( , M) naturally equivalent;

Sec. 10.5
Derived Functors
831
(iii) EXTn(P) = {0} for all projective modules P and all n ‚â•1.
If Extn( , M) is another sequence of contravariant functors satisfying these same ax-
ioms, then EXTn is naturally equivalent to Extn( , M) for all n ‚â•0.
Remark.
There are axiomatic descriptions of the covariant Ext functors and of the Tor
functors in Exercises 10.44 and 10.45 on page 869.
‚óÄ
Proof.
We proceed by induction on n ‚â•0. The base step is axiom (ii).
For the inductive step, given a module A, choose a short exact sequence
0 ‚ÜíL ‚ÜíP ‚ÜíA ‚Üí0,
where P is projective. By axiom (i), there is a diagram with exact rows:
EXT0(P)

œÑP

EXT0(L)
0

œÑL

EXT1(A)


EXT1(P)
Hom(P, M)
 Hom(L, M)
‚àÇ0
 Ext1(A, M)
 Ext1(P, M),
where the maps œÑP and œÑL are the isomorphisms given by axiom (ii). This diagram com-
mutes because of the naturality of the equivalence EXT0 ‚ÜíHom( , M). By axiom (iii),
Ext1(P, M) = {0} and EXT1(P) = {0}. It follows that the maps 0 and ‚àÇ0 are surjective.
This is precisely the sort of diagram in Proposition 8.93, and so there exists an isomorphism
EXT1(A) ‚ÜíExt1(A, M) making the augmented diagram commute.
We may now assume that n ‚â•1, and we look further out in the long exact sequence.
By axiom (i), there is a diagram with exact rows
EXTn(P)
 EXTn(L)
n

œÉ

EXTn+1(A)


EXTn+1(P)
Extn(P, M)
 Extn(L, M)
‚àÇn  Extn+1(A, M)
 Extn+1(P, M),
where œÉ : EXTn(L) ‚ÜíExtn(L, M) is an isomorphism given by the inductive hypoth-
esis. Since n ‚â•1, all four terms involving the projective P are {0}; it follows from
exactness of the rows that both n and ‚àÇn are isomorphisms.
Finally, the composite
‚àÇnœÉ‚àí1
n : EXTn+1(A) ‚ÜíExtn+1(A, M) is an isomorphism.
It remains to prove that the isomorphisms EXTn(A) ‚ÜíExtn(A, M) constitute a natural
transformation. It is here the assumed naturality in axiom (i) of the connecting homomor-
phism is used, and this is left for the reader to do.
‚Ä¢
Such slow starting induction proofs, proving results for n = 0 and n = 1 before proving
the inductive step, arise frequently, and they are called dimension shifting.

832
Homology
Ch. 10
The rest of this section consists of constructing functors that satisfy axioms (i), (ii), and
(iii). We prove existence of Ext and Tor using derived functors (there are other proofs as
well). As these functors are characterized by a short list of properties, we can usually work
with Ext and Tor without being constantly aware of the details of their construction.
We begin with a technical deÔ¨Ånition.
DeÔ¨Ånition.
If ¬∑ ¬∑ ¬∑ ‚ÜíP2 ‚ÜíP1
d1
‚àí‚ÜíP0 ‚ÜíA ‚Üí0 is a projective resolution of a module
A, then its deleted projective resolution is the complex
PA = ¬∑ ¬∑ ¬∑ ‚ÜíP2 ‚ÜíP1 ‚ÜíP0 ‚Üí0.
Similarly, if 0 ‚ÜíA ‚ÜíE0
d0
‚àí‚ÜíE1 ‚ÜíE2 ‚Üí¬∑ ¬∑ ¬∑ is an injective resolution of a module
A, then a deleted injective resolution is the complex
EA = 0 ‚ÜíE0 ‚ÜíE1 ‚ÜíE2 ‚Üí¬∑ ¬∑ ¬∑ .
In either case, deleting A loses no information: A ‚àº= coker d1 in the Ô¨Årst case, and
A ‚àº= ker d0 in the second case. Of course, a deleted resolution is no longer exact:
H0(PA) = ker(P0 ‚Üí{0})/ im d1 = P0/ im d1 ‚àº= A.
We know that a module has many presentations, and so the next result is fundamental.
Theorem 10.46 (Comparison Theorem).
Given a map f : A ‚ÜíA‚Ä≤, consider the dia-
gram
¬∑ ¬∑ ¬∑
 P2
d2

Àáf2

P1
d1

Àáf1

P0
Œµ

Àáf0

A

f

0
¬∑ ¬∑ ¬∑
 P‚Ä≤
2
d‚Ä≤
2
 P‚Ä≤
1
d‚Ä≤
1
 P‚Ä≤
0
Œµ‚Ä≤
 A‚Ä≤
 0,
where the rows are complexes. If each Pn in the top row is projective, and if the bottom
row is exact, then there exists a chain map Àáf : PA ‚ÜíP‚Ä≤
A‚Ä≤ making the completed diagram
commute. Moreover, any two such chain maps are homotopic.
Remark.
The dual of the comparison theorem is also true. Now the complexes go off to
the right, the top row is assumed exact, and every term in the bottom row other than A‚Ä≤ is
injective.
‚óÄ
Proof.
(i) We prove the existence of Àáfn by induction on n ‚â•0. For the base step n = 0,
consider the diagram
P0
f Œµ


P‚Ä≤
0
Œµ‚Ä≤
 A‚Ä≤
 0

Sec. 10.5
Derived Functors
833
Since Œµ‚Ä≤ is surjective and P0 is projective, there exists a map Àáf0 : P0 ‚ÜíP‚Ä≤
0 with Œµ‚Ä≤ Àáf0 = f Œµ.
For the inductive step, consider the diagram
Pn+1
dn+1  Pn
dn 
Àáfn 
Pn‚àí1
Àáfn‚àí1

P‚Ä≤
n+1 d‚Ä≤
n+1
 P‚Ä≤
n
d‚Ä≤n
 P‚Ä≤
n‚àí1
If we can show that im Àáfndn+1 ‚äÜim d‚Ä≤
n+1, then we will have the diagram
Pn+1
Àáfndn+1


P‚Ä≤
n+1
d‚Ä≤
n+1  im d‚Ä≤
n+1
 0
and projectivity of Pn+1 will provide a map Àáfn+1 : Pn+1 ‚ÜíP‚Ä≤
n+1 with d‚Ä≤
n+1 Àáfn+1 =
Àáfndn+1.
To check that the inclusion does hold, note that exactness at P‚Ä≤
n of the bot-
tom row of the original diagram gives im d‚Ä≤
n+1 = ker d‚Ä≤
n, and so it sufÔ¨Åces to prove that
d‚Ä≤
n Àáfndn+1 = 0. But d‚Ä≤
n Àáfndn+1 = Àáfn‚àí1dndn+1 = 0.
(ii) We now prove uniqueness of Àáf to homotopy. If h : P‚Ä¢ ‚ÜíP‚Ä≤
‚Ä¢ is a chain map also
satisfying Œµ‚Ä≤h0 = f Œµ, then we construct the terms sn : Pn ‚ÜíP‚Ä≤
n+1 of a homotopy s by
induction on n ‚â•0; that is, we want
Àáfn ‚àíhn = d‚Ä≤
n+1sn + sn‚àí1dn.
Let us now begin the induction. If we deÔ¨Åne s0 = 0 = s‚àí1, then d‚Ä≤
1s0 + s‚àí1d0 = 0. On the
other hand,
( Àáf0 ‚àíh0)Œµ‚Ä≤ = Àáf0Œµ‚Ä≤ ‚àíh0Œµ‚Ä≤ = Œµf ‚àíŒµf = 0.
Since Œµ‚Ä≤ is a surjection, we have Àáf0 ‚àíh0 = 0, as desired.
For the inductive step, it sufÔ¨Åces to prove that
im(hn+1 ‚àíÀáfn+1 ‚àísndn+1) ‚äÜim d‚Ä≤
n+2,
for we have a diagram with exact row
Pn+1
hn+1‚àíÀáfn+1‚àísndn+1


P‚Ä≤
n+2
d‚Ä≤
n+2  im d‚Ä≤
n+2
 0

834
Homology
Ch. 10
and projectivity of Pn+1 will give a map sn+1 : Pn+1 ‚ÜíP‚Ä≤
n+2 satisfying the desired equa-
tion. As in the proof of part (i), exactness of the bottom row of the original diagram gives
im d‚Ä≤
n+2 = ker d‚Ä≤
n+1, and so it sufÔ¨Åces to prove
d‚Ä≤
n+1(hn+1 ‚àíÀáfn+1 ‚àísndn+1) = 0.
But
d‚Ä≤
n+1(hn+1 ‚àíÀáfn+1 ‚àísndn+1) = d‚Ä≤
n+1(hn+1 ‚àíÀáfn+1) ‚àíd‚Ä≤
n+1sndn+1
= d‚Ä≤
n+1(hn+1 ‚àíÀáfn+1) ‚àí(hn ‚àíÀáfn ‚àísn‚àí1dn)dn+1
= d‚Ä≤
n+1(hn+1 ‚àíÀáfn+1) ‚àí(hn ‚àíÀáfn)dn+1,
and the last term is 0 because h and Àáf are chain maps.
‚Ä¢
We introduce a term to describe the chain map Àáf just constructed.
DeÔ¨Ånition.
If f : A ‚ÜíA‚Ä≤ is a map of modules, and if PA and P‚Ä≤
A‚Ä≤ are deleted projective
resolutions of A and A‚Ä≤, respectively, then a chain map Àáf : PA ‚ÜíP‚Ä≤
A‚Ä≤
¬∑ ¬∑ ¬∑
 P2
d2

Àáf2

P1
d1

Àáf1

P0
Œµ

Àáf0

A

f

0
¬∑ ¬∑ ¬∑
 P‚Ä≤
2
d‚Ä≤
2
 P‚Ä≤
1
d‚Ä≤
1
 P‚Ä≤
0
Œµ‚Ä≤
 A‚Ä≤
 0
is said to be over f if
f Œµ = Œµ‚Ä≤ Àáf0.
Thus, the comparison theorem implies, given a homomorphism f : A ‚ÜíA‚Ä≤, that a
chain map over f always exists between deleted projective resolutions of A and A‚Ä≤; more-
over, such a chain map is unique to homotopy.
Given a pair of rings R and S and an additive covariant functor T : RMod ‚ÜíSMod, we
are now going to construct, for all n ‚ààZ, its left derived functors LnT : RMod ‚ÜíSMod.
The deÔ¨Ånition will be in two parts: Ô¨Årst on objects; then on morphisms.
Choose, once for all, a deleted projective resolution PA of every module A. As in
Example 10.34(ix), form the complex T PA, and take homology:
LnT (A) = Hn(T PA).
This deÔ¨Ånition is suggested by two examples. First, in algebraic topology, we tensor
the complex of a triangulated space X to get homology groups Hn(X; G) of X with coef-
Ô¨Åcients in an abelian group G; or, we apply Hom( , G) to get a complex whose homology
groups are called cohomology groups of X with coefÔ¨Åcients in G (of course, this last func-
tor is contravariant). Second, when we considered group extensions, the formulas that

Sec. 10.5
Derived Functors
835
arose suggested constructing a free resolution of the trivial module Z, and then applying
Hom( , K) or ‚äóK to this resolution.
We now deÔ¨Åne LnT ( f ), where f : A ‚ÜíA‚Ä≤ is a homomorphism. By the comparison
theorem, there is a chain map Àáf : PA ‚ÜíP‚Ä≤
A‚Ä≤ over f . It follows that T Àáf : T PA ‚ÜíT P‚Ä≤
A‚Ä≤ is
also a chain map, and we deÔ¨Åne LnT ( f ): LnT (A) ‚ÜíLnT (A‚Ä≤) by
LnT ( f ) = Hn(T Àáf ) = (T Àáf )‚àó.
In more detail, if z ‚ààker T dn, then
(LnT ) f : z + im T dn+1 ‚Üí(T Àáfn)z + im T d‚Ä≤
n+1.
In pictures, look at the chosen projective resolutions:
¬∑ ¬∑ ¬∑
 P1
 P0
 A

f

0
¬∑ ¬∑ ¬∑
 P‚Ä≤
1
 P‚Ä≤
0
 A‚Ä≤
 0
Fill in the a chain map Àáf over f , then apply T to this diagram, and then take the map
induced by T Àáf in homology.
Example 10.47.
If r ‚ààZ(R) is a central element in a ring R, and if A is a left R-module, then ¬µr : A ‚ÜíA,
deÔ¨Åned by ¬µr : A ‚Üír A, is an R-map. We call ¬µr multiplication by r.
DeÔ¨Ånition.
A functor T : RMod ‚ÜíRMod, of either variance, preserves multiplications
if T (¬µr): T A ‚ÜíT A is multiplication by r for all r ‚ààZ(R).
Tensor product and Hom preserve multiplications. We claim that if T preserves multi-
plications, then LnT also preserves multiplications; that is,
LnT (¬µr) = multiplication by r.
Given a projective resolution ¬∑ ¬∑ ¬∑ ‚ÜíP1
d1
‚àí‚ÜíP0
Œµ
‚àí‚ÜíA ‚Üí0, it is easy to see that Àá¬µ is a
chain map over ¬µr,
¬∑ ¬∑ ¬∑
 P2
d2

Àá¬µ2

P1
d1

Àá¬µ1

P0
Œµ

Àá¬µ0

A

f

0
¬∑ ¬∑ ¬∑
 P2
d2
 P1
d1
 P0
Œµ
 A
 0,
where Àá¬µn : Pn ‚ÜíPn is multiplication by r for every n ‚â•0.. Since T preserves multipli-
cations, the terms of the chain map T Àá¬µ are multiplication by r, and so the induced maps in
homology are also multiplication by r:
(T Àá¬µ)‚àó: zn + im T dn+1 ‚Üí(T Àá¬µn)zn + im T dn+1 = rzn + im T dn+1,
where zn ‚ààker T dn.
‚óÄ

836
Homology
Ch. 10
Proposition 10.48.
Given a pair of rings R and S and an additive covariant functor
T : RMod ‚ÜíSMod, then
LnT : RMod ‚ÜíSMod
is an additive covariant functor for every n.
Proof.
We will prove that LnT is well-deÔ¨Åned on morphisms; it is then routine to check
that it is a covariant additive functor (remember that Hn is a covariant additive functor from
complexes to modules).
If h : PA ‚ÜíP‚Ä≤
A‚Ä≤ is another chain map over f , then the comparison theorem says that
h ‚ãçÀáf ; therefore, T h ‚ãçT Àáf , by Exercise 10.26 on page 828, and so Hn(T h) = Hn(T Àáf ),
by Proposition 10.39.
‚Ä¢
Proposition 10.49.
If T : RMod ‚ÜíSMod is a covariant additive functor, then LnT A =
{0} for all negative n and for all A.
Proof.
By Exercise 10.21 on page 827, we have LnT A = {0} because, when n is nega-
tive, the nth term of PA is {0}.
‚Ä¢
DeÔ¨Ånition.
If B is a left R-module and T = ‚äóR B, deÔ¨Åne
TorR
n ( , B) = LnT.
Thus, if
PA = ¬∑ ¬∑ ¬∑ ‚ÜíP2
d2
‚àí‚ÜíP1
d1
‚àí‚ÜíP0 ‚Üí0
is the chosen deleted projective resolution of a module A, then
TorR
n (A, B) = Hn(PA ‚äóR B) = ker(dn ‚äó1B)
im(dn+1 ‚äó1B).
The domain of TorR
n ( , B) is ModR, the category of right R-modules; its target is Ab,
the category of abelian groups. For example, if R is commutative, then A ‚äóR B is an
R-module, and so the values of TorR( , B) lie in RMod.
DeÔ¨Ånition.
If A is a right R-module and T = A‚äóR , deÔ¨Åne torR
n (A, ) = LnT . Thus, if
QB = ¬∑ ¬∑ ¬∑ ‚ÜíQ2
d2
‚àí‚ÜíQ1
d1
‚àí‚ÜíQ0 ‚Üí0
is the chosen deleted projective resolution of a module B, then
torR
n (A, B) = Hn(A ‚äóR QB) = ker(1A ‚äódn)
im(1A ‚äódn+1).
The domain of torR
n (A, ) is RMod, the category of left R-modules; its target is Ab, the
category of abelian groups but, as before, its target may be smaller (if R = Q, for example)
or larger [if R = ZG, for every Z-module can be viewed as a (trivial) R-module].

Sec. 10.5
Derived Functors
837
One of the nice theorems of homological algebra is, for all A and B (and for all R and
n), that
TorR
n (A, B) ‚àº= torR
n (A, B).
There is a proof using spectral sequences, but there is also an elementary proof due to A.
Zaks (see Rotman, An Introduction to Homological Algebra, p. 197).
There are now several points to discuss. The deÔ¨Ånition of LnT assumes that a choice
of deleted projection resolution of each module has been made. Does LnT depend on this
choice? And, once we dispose of this question (the answer is that LnT does not depend on
the choice), how can we use these functors?
Assume that new choices PA of deleted projective resolutions have been made, and let
us denote the left derived functors arising from these new choices by LnT .
Proposition 10.50.
Given a pair of rings R and S, and an additive covariant functor
T : RMod ‚ÜíSMod, then, for each n, the functors LnT and LnT are naturally equivalent.
In particular, for all A,
(LnT )A ‚àº= (LnT )A,
and so these modules are independent of the choice of (deleted) projective resolution of A.
Proof.
Consider the diagram
¬∑ ¬∑ ¬∑
 P2
 P1
 P0
 A

1A

0
¬∑ ¬∑ ¬∑
 P2
 P1
 P0
 A
 0,
where the top row is the chosen projective resolution of A used to deÔ¨Åne LnT and the
bottom is that used to deÔ¨Åne LnT . By the comparison theorem, there is a chain map
Œπ: PA ‚ÜíPA over 1A. Applying T gives a chain map T Œπ: T PA ‚ÜíTPA over T 1A = 1T A.
This last chain map induces homomorphisms, one for each n,
œÑA = (T Œπ)‚àó: (LnT )A ‚Üí(LnT )A.
We now prove that each œÑA is an isomorphism (thereby proving the last statement in
the theorem) by constructing its inverse. Turn the preceding diagram upside down, so
that the chosen projective resolution PA ‚ÜíA ‚Üí0 is now the bottom row. Again, the
comparison theorem gives a chain map, say, Œ∫ : PA ‚ÜíPA. Now the composite Œ∫Œπ is a
chain map from PA to itself over 1PA. By the uniqueness statement in the comparison
theorem, Œ∫Œπ ‚ãç1PA; similarly, ŒπŒ∫ ‚ãç1PA. It follows that T (ŒπŒ∫) ‚ãç1TPA and T (Œ∫Œπ) ‚ãç1TPA.
Hence, 1 = (T ŒπŒ∫)‚àó= (T Œπ)‚àó(T Œ∫)‚àóand 1 = (T Œ∫Œπ)‚àó= (T Œ∫)‚àó(T Œπ)‚àó. Therefore, œÑA = (T Œπ)‚àó
is an isomorphism.

838
Homology
Ch. 10
We now prove that the isomorphisms œÑA constitute a natural equivalence: that is, if
f : A ‚ÜíB is a homomorphism, then the following diagram commutes.
(LnT )A
œÑA

LnT ( f )

(LnT )A
LnT ( f )

(LnT )B
œÑB
 (LnT )B
To evaluate in the clockwise direction, consider
¬∑ ¬∑ ¬∑
 P1
 P0
 A

1A

0
¬∑ ¬∑ ¬∑
 P1
 P0
 A

f

0
¬∑ ¬∑ ¬∑
 
Q1
 
Q0
 B
 0,
where the bottom row is some projective resolution of B. The comparison theorem gives
a chain map PA ‚ÜíPA over f 1A = f . Going counterclockwise, the picture will now
have the chosen projective resolution of B as its middle row, and we get a chain map
PA ‚ÜíPA over 1B f = f . The uniqueness statement in the comparison theorem tells us
that these two chain maps are homotopic, so that they give the same homomorphism in
homology. Thus, the appropriate diagram commutes, showing that œÑ : LnT ‚ÜíLnT is a
natural equivalence.
‚Ä¢
Corollary 10.51.
The module TorR
n (A, B) is independent of the choices of projective
resolutions of A and of B.
Proof.
The proposition applies at once to the left derived functors of
‚äóR B, namely,
TorR
n ( , B), and to the left derived functors of A‚äóR , namely torR
n (A, ). But we have
already cited the fact that TorR
n (A, B) ‚àº= torR
n (A, B).
‚Ä¢
Corollary 10.52.
Let T : RMod ‚ÜíSMod be an additive covariant functor. If P is a
projective module, then LnT (P) = {0} for all n ‚â•1.
In particular, if A and P are right R-modules, with P projective, and if B and Q are
left R-modules, with Q projective, then
TorR
n (P, B) = {0}
and
TorR
n (A, Q) = {0}
for all n ‚â•1.

Sec. 10.5
Derived Functors
839
Proof.
Since P is projective, a projective resolution of it is
C‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚Üí0 ‚Üí0 ‚ÜíP
1P
‚àí‚ÜíP ‚Üí0,
and so the corresponding deleted projective resolution CP has only one nonzero term,
namely, C0 = P. It follows that T CP is a complex having nth term {0} for all n ‚â•1, and
so LnT P = Hn(T CP) = {0} for all n ‚â•1, by Exercise 10.21 on page 827.
‚Ä¢
We are now going to show that there is a long exact sequence of left derived functors.
We begin with a useful lemma; it says that if we are given an exact sequence of modules as
well as a projective resolution of its Ô¨Årst and third terms, then we can "Ô¨Åll in the horseshoe";
that is, there is a projective resolution of the middle term that Ô¨Åts in the middle.
Lemma 10.53 (Horseshoe Lemma).
Given a diagram


P‚Ä≤
1

P‚Ä≤‚Ä≤
1

P‚Ä≤
0
Œµ‚Ä≤

P‚Ä≤‚Ä≤
0
Œµ‚Ä≤‚Ä≤

0
 A‚Ä≤
i
 A
p
 A‚Ä≤‚Ä≤
 0,
where the columns are projective resolutions and the row is exact, then there exists a pro-
jective resolution of A and chain maps so that the three columns form an exact sequence
of complexes.
Remark.
The dual theorem, in which projective resolutions are replaced by injective
resolutions, is also true.
‚óÄ
Proof.
We show Ô¨Årst that there is a projective P0 and a commutative 3 √ó 3 diagram with
exact columns and rows:
0

0

0

0
 K ‚Ä≤
0

 K0

 K ‚Ä≤‚Ä≤
0

 0
0
 P‚Ä≤
0
Œµ‚Ä≤

i0
 P0
p0

Œµ

P‚Ä≤‚Ä≤
0
Œµ‚Ä≤‚Ä≤

 0
0
 A‚Ä≤
i


A
p


A‚Ä≤‚Ä≤


0
0
0
0

840
Homology
Ch. 10
DeÔ¨Åne P0 = P‚Ä≤
0 ‚äïP‚Ä≤‚Ä≤
0 ; it is projective because both P‚Ä≤
0 and P‚Ä≤‚Ä≤
0 are projective. DeÔ¨Åne
i0 : P‚Ä≤
0 ‚ÜíP‚Ä≤
0 ‚äïP‚Ä≤‚Ä≤
0 by x‚Ä≤ ‚Üí(x‚Ä≤, 0), and deÔ¨Åne p0 : P‚Ä≤
0 ‚äïP‚Ä≤‚Ä≤
0 ‚ÜíP‚Ä≤‚Ä≤
0 by (x, x‚Ä≤‚Ä≤) ‚Üíx‚Ä≤‚Ä≤. It
is clear that
0 ‚ÜíP‚Ä≤
0
i0
‚àí‚ÜíP0
p0
‚àí‚ÜíP‚Ä≤‚Ä≤
0 ‚Üí0
is exact. Since P‚Ä≤‚Ä≤
0 is projective, there exists a map œÉ : P‚Ä≤‚Ä≤
0 ‚ÜíA with pœÉ = Œµ‚Ä≤‚Ä≤. Now deÔ¨Åne
Œµ: P0 ‚ÜíA by Œµ: (x‚Ä≤, x‚Ä≤‚Ä≤) ‚ÜíiŒµ‚Ä≤x‚Ä≤ +œÉ x‚Ä≤‚Ä≤. It is left as a routine exercise that if K0 = ker Œµ,
then there are maps K ‚Ä≤
0 ‚ÜíK0 and K0 ‚ÜíK ‚Ä≤‚Ä≤
0 (where K ‚Ä≤
0 = ker Œµ‚Ä≤ and K ‚Ä≤‚Ä≤
0 = ker Œµ‚Ä≤‚Ä≤), so
that the resulting 3 √ó 3 diagram commutes. Exactness of the top row is Exercise 10.29 on
page 828.
We now prove, by induction on n ‚â•0, that the bottom n rows of the desired diagram
can be constructed. For the inductive step, assume that the Ô¨Årst n steps have been Ô¨Ålled in,
and let Kn = ker(Pn ‚ÜíPn‚àí1), etc. Now construct the 3 √ó 3 diagram whose bottom row
is 0 ‚ÜíK ‚Ä≤
n ‚ÜíKn ‚ÜíK ‚Ä≤‚Ä≤
n ‚Üí0, and splice it to the nth diagram, as illustrated next (note
that the map Pn+1 ‚ÜíPn is deÔ¨Åned as the composite Pn+1 ‚ÜíKn ‚ÜíPn).
0
 K ‚Ä≤
n+1


Kn+1


K ‚Ä≤‚Ä≤
n+1


0
0
 P‚Ä≤
n+1



Pn+1



P‚Ä≤‚Ä≤
n+1



0
0
 K ‚Ä≤
n

 Kn



 K ‚Ä≤‚Ä≤
n

 0
0
 P‚Ä≤
n


Pn


P‚Ä≤‚Ä≤
n


0
0
 P‚Ä≤
n‚àí1
 Pn‚àí1
 P‚Ä≤‚Ä≤
n‚àí1
 0
The columns of the new diagram are exact because, for example, im(Pn+1 ‚ÜíPn) = Kn =
ker(Pn ‚ÜíPn‚àí1).
‚Ä¢
Theorem 10.54.
If 0 ‚ÜíA‚Ä≤
i
‚àí‚ÜíA
p
‚àí‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is an exact sequence of modules and if
T : RMod ‚ÜíSMod is a covariant additive functor, then there is a long exact sequence:
¬∑ ¬∑ ¬∑ ‚ÜíLnT A‚Ä≤ LnTi
‚àí‚ÜíLnT A
LnT p
‚àí‚ÜíLnT A‚Ä≤‚Ä≤
‚àÇn
‚àí‚Üí
Ln‚àí1T A‚Ä≤ Ln‚àí1Ti
‚àí‚ÜíLn‚àí1T A
Ln‚àí1T p
‚àí‚Üí
Ln‚àí1T A‚Ä≤‚Ä≤ ‚àÇn‚àí1
‚àí‚Üí¬∑ ¬∑ ¬∑
that ends with
¬∑ ¬∑ ¬∑ ‚ÜíL0T A‚Ä≤ ‚ÜíL0T A ‚ÜíL0T A‚Ä≤‚Ä≤ ‚Üí0.
Proof.
Let P‚Ä≤ A‚Ä≤ and P‚Ä≤‚Ä≤
A‚Ä≤‚Ä≤ be the chosen deleted projective resolutions of A‚Ä≤ and of A‚Ä≤‚Ä≤,
respectively. By Lemma 10.53, there is a deleted projective resolution PA of A with
0‚Ä¢ ‚ÜíP‚Ä≤ A‚Ä≤
j
‚àí‚ÜíPA
q
‚àí‚ÜíP‚Ä≤‚Ä≤
A‚Ä≤‚Ä≤ ‚Üí0‚Ä¢

Sec. 10.5
Derived Functors
841
(in the notation of the comparison theorem, j = Àái is a chain map over i,and q = Àáp is a
chain map over p). Applying T gives the sequence of complexes
0‚Ä¢ ‚ÜíT P‚Ä≤ A‚Ä≤
T j
‚àí‚ÜíTPA
Tq
‚àí‚ÜíT P‚Ä≤‚Ä≤
A‚Ä≤‚Ä≤ ‚Üí0‚Ä¢.
To see that this sequence is exact,12 note that each row 0 ‚ÜíP‚Ä≤
n
jn
‚àí‚ÜíPn
qn
‚àí‚ÜíP‚Ä≤‚Ä≤
n ‚Üí0 is
a split exact sequence (because P‚Ä≤‚Ä≤
n is projective), and additive functors preserve split short
exact seqeunces. There is thus a long exact sequence
¬∑ ¬∑ ¬∑ ‚ÜíHn(T P‚Ä≤
A‚Ä≤)
(T j)‚àó
‚àí‚ÜíHn(TPA)
(Tq)‚àó
‚àí‚ÜíHn(T P‚Ä≤‚Ä≤
A‚Ä≤‚Ä≤)
‚àÇn
‚àí‚ÜíHn‚àí1(T P‚Ä≤
A‚Ä≤) ‚Üí¬∑ ¬∑ ¬∑ ;
that is, there is an exact sequence
¬∑ ¬∑ ¬∑ ‚ÜíLnT A‚Ä≤ (Ti)‚àó
‚àí‚ÜíLnT A
(Tq)‚àó
‚àí‚ÜíLnT A‚Ä≤‚Ä≤
‚àÇn
‚àí‚ÜíLn‚àí1T A‚Ä≤ ‚Üí¬∑ ¬∑ ¬∑ .
We do not know that the projective resolution of A given by the horseshoe lemma is the
resolution originally chosen, and this is why we have LnT A instead of LnT A. But there
is a natural equivalence œÑ : LnT ‚ÜíLnT , and so there is an exact sequence
¬∑ ¬∑ ¬∑ ‚ÜíLnT A‚Ä≤ œÑ ‚àí1
A (Ti)‚àó
‚àí‚Üí
LnT A
œÑA(Tq)‚àó
‚àí‚Üí
LnT A‚Ä≤‚Ä≤
‚àÇn
‚àí‚ÜíLn‚àí1T A‚Ä≤ ‚Üí¬∑ ¬∑ ¬∑ .
The sequence does terminate with {0}, for L‚àí1T = {0} for all negative n, by Proposi-
tion 10.49.
It remains to show that œÑ ‚àí1
A (Ti)‚àó= LnT (i) and œÑ ‚àí1
A (Tq)‚àó= LnT (p). Now œÑ ‚àí1
A
=
(T Œ∫)‚àó, where Œ∫ : PA ‚ÜíPA is a chain map over 1A, and so
œÑ ‚àí1
A (Ti)‚àó= (T Œ∫)‚àó(Ti)‚àó=

T (Œ∫i)

‚àó.
Both Œ∫i and i are chain mapsPA ‚ÜíPA over 1A, so they are homotopic, by the comparison
theorem. Therefore, T (Œ∫i) and Ti are homotopic, and hence they induce the same map
in homology: (T (Œ∫i))‚àó= (Ti)‚àó= LnT (i), and so œÑ ‚àí1
A (Ti)‚àó= LnT (i). We prove
œÑ ‚àí1
A (Tq)‚àó= LnT (p) in the same way.
‚Ä¢
Corollary 10.55.
If T : RMod ‚ÜíSMod is a covariant additive functor, then the functor
L0T is right exact.
Proof.
This follows at once from the theorem.
‚Ä¢
12The exact sequence of complexes is not split because the sequence of splitting maps need not constitute a
chain map P‚Ä≤‚Ä≤
A‚Ä≤‚Ä≤ ‚ÜíPA.

842
Homology
Ch. 10
Theorem 10.56.
(i) If an additive covariant functor T : RMod ‚ÜíSMod is right exact, then T is natu-
rally equivalent to L0T .
(ii) The functor
‚äóR B is naturally equivalent to TorR
0 ( , B). Hence, for all right R-
modules A, there is an isomorphism
A ‚äóR B ‚àº= TorR
0 (A, B).
Proof.
(i) Let PA be the chosen deleted projective resolution of A, and let
¬∑ ¬∑ ¬∑ ‚ÜíP1
d1
‚àí‚ÜíP0
Œµ
‚àí‚ÜíA ‚Üí0
be the chosen projective resolution. By deÔ¨Ånition,
L0T A = ker(Œµ ‚äó1B)
im(d1 ‚äó1B) = coker(d1 ‚äó1B).
But right exactness of T gives an exact sequence
T P1
d1‚äó1
‚àí‚ÜíT P0
Œµ‚äó1
‚àí‚ÜíT A ‚Üí0.
Now Œµ ‚äó1 induces an isomorphism œÉA : coker(d1 ‚äó1) ‚ÜíT A, by the Ô¨Årst isomorphism
theorem; that is, œÉA : L0T A ‚ÜíT A. It is left as a routine exercise that œÉ : L0T ‚ÜíT is a
natural equivalence.
(ii) Immediate from part (i), for ‚äóR B is a covariant right exact additive functor.
‚Ä¢
We have shown that Tor repairs the loss of exactness that may occur after tensoring a
short exact sequence.
Corollary 10.57.
If 0 ‚ÜíA‚Ä≤ ‚ÜíA ‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is a short exact sequence of modules,
then there is a long exact sequence
¬∑ ¬∑ ¬∑ ‚ÜíTorR
2 (A‚Ä≤, B) ‚ÜíTorR
2 (A, B) ‚ÜíTorR
2 (A‚Ä≤‚Ä≤, B)
‚ÜíTorR
1 (A‚Ä≤, B) ‚ÜíTorR
1 (A, B) ‚ÜíTorR
1 (A‚Ä≤‚Ä≤, B)
‚ÜíA‚Ä≤ ‚äóR B ‚ÜíA ‚äóR B ‚ÜíA‚Ä≤‚Ä≤ ‚äóR B ‚Üí0.
The next proposition shows that the functors Torn( , B) satisfy the covariant version of
Theorem 10.45.
Proposition 10.58.
Given a commutative diagram of modules having exact rows,
0
 A‚Ä≤
f

i
 A
p

g

A‚Ä≤‚Ä≤
h

 0
0
 C‚Ä≤
j
 C
q
 C‚Ä≤‚Ä≤
 0

Sec. 10.5
Derived Functors
843
there is, for all n, a commutative diagram with exact rows
TorR
n (A‚Ä≤, B)
f‚àó

i‚àó
 TorR
n (A, B)
p‚àó
g‚àó

TorR
n (A‚Ä≤‚Ä≤, B)
h‚àó

‚àÇn  TorR
n‚àí1(A‚Ä≤, B)
f‚àó

TorR
n (C‚Ä≤, B)
j‚àó
 TorR
n (C, B)
q‚àó TorR
n (C‚Ä≤‚Ä≤, B)
‚àÇ‚Ä≤
n  TorR
n‚àí1(C‚Ä≤, B)
There is a similar diagram if the Ô¨Årst variable is Ô¨Åxed.
Proof.
Given the diagram in the statement, erect the chosen deleted projective resolutions
on the corners P‚Ä≤
A‚Ä≤, P‚Ä≤‚Ä≤
A‚Ä≤‚Ä≤, Q‚Ä≤
C‚Ä≤, and Q‚Ä≤‚Ä≤
C‚Ä≤‚Ä≤. We claim that there are deleted projective resolu-
tions PA and QC, together with chain maps, giving a commutative diagram of complexes
having exact rows:
0
 P‚Ä≤
A‚Ä≤
Àáf

Àái
 PA
Àáp

Àág

P‚Ä≤‚Ä≤
A‚Ä≤‚Ä≤
Àáh

 0
0
 Q‚Ä≤
C‚Ä≤
Àáj
 QC
Àáq
 Q‚Ä≤‚Ä≤
C‚Ä≤‚Ä≤
 0
Once this is done, the result will follow from the naturality of the connecting homomor-
phism. As in the inductive proof of Theorem 10.44, it sufÔ¨Åces to prove a three-dimensional
version of the horseshoe lemma. We complete the following commutative diagram, whose
columns are short exact sequences, and in which P‚Ä≤, P‚Ä≤‚Ä≤, Q‚Ä≤, and Q‚Ä≤‚Ä≤ are projectives and
N ‚Ä≤, N ‚Ä≤‚Ä≤, K ‚Ä≤, and K ‚Ä≤‚Ä≤ are kernels,
K ‚Ä≤

K ‚Ä≤‚Ä≤

N ‚Ä≤

N ‚Ä≤‚Ä≤

P‚Ä≤

P‚Ä≤‚Ä≤

Q‚Ä≤

Q‚Ä≤‚Ä≤

0
 A‚Ä≤
i

f

A
p

g

A‚Ä≤‚Ä≤

h

0
0
 C‚Ä≤
j
 C
q
 C‚Ä≤‚Ä≤
 0
to the following commutative diagram, whose rows and columns are short exact sequences,

844
Homology
Ch. 10
and in which P and Q are projective:
0
 K ‚Ä≤



K



K ‚Ä≤‚Ä≤


 0
0
 N ‚Ä≤


N


N ‚Ä≤‚Ä≤


0
0
 P‚Ä≤

F‚Ä≤

Œµ‚Ä≤

P
F

Œµ

P‚Ä≤‚Ä≤

F‚Ä≤‚Ä≤

Œµ‚Ä≤‚Ä≤

0
0
 Q‚Ä≤

Œ∑‚Ä≤

Q

Œ∑

Q‚Ä≤‚Ä≤

Œ∑‚Ä≤‚Ä≤

0
0
 A‚Ä≤
f

i
 A
g

p
 A‚Ä≤‚Ä≤

h

0
0
 C‚Ä≤
j
 C
q
 C‚Ä≤‚Ä≤
 0
Step 1. By the comparison theorem, there are chain maps
Àáf : P‚Ä≤
A‚Ä≤ ‚ÜíQ‚Ä≤
C‚Ä≤ over f and
Àáh : P‚Ä≤‚Ä≤
A‚Ä≤‚Ä≤ ‚ÜíQ‚Ä≤‚Ä≤
C‚Ä≤‚Ä≤ over h. To simplify notation, we will write F‚Ä≤ = Àáf0 and F‚Ä≤‚Ä≤ = Àáh0.
Step 2. DeÔ¨Åne P = P‚Ä≤‚äïP‚Ä≤‚Ä≤, and insert the usual injection and projection maps P‚Ä≤ ‚ÜíP and
P ‚ÜíP‚Ä≤‚Ä≤, namely, x‚Ä≤ ‚Üí(x‚Ä≤, 0) and (x‚Ä≤, x‚Ä≤‚Ä≤) ‚Üíx‚Ä≤‚Ä≤. Similarly, deÔ¨Åne Q = Q‚Ä≤ ‚äïQ‚Ä≤‚Ä≤,
and insert the injection and projection maps Q‚Ä≤ ‚ÜíQ and Q ‚ÜíQ‚Ä≤‚Ä≤. Of course, the
sequences 0 ‚ÜíP‚Ä≤ ‚ÜíP ‚ÜíP‚Ä≤‚Ä≤ ‚Üí0 and 0 ‚ÜíQ‚Ä≤ ‚ÜíQ ‚ÜíQ‚Ä≤‚Ä≤ ‚Üí0 are exact.
Step 3. As in the proof of the horseshoe lemma, deÔ¨Åne Œµ: P ‚ÜíA by Œµ: (x‚Ä≤, x‚Ä≤‚Ä≤) ‚ÜíiŒµ‚Ä≤x‚Ä≤ +
œÉ x‚Ä≤‚Ä≤, where œÉ : P‚Ä≤‚Ä≤ ‚ÜíA satisÔ¨Åes pœÉ = Œµ‚Ä≤‚Ä≤ (such a map œÉ was shown to exist in
the proof of the horseshoe lemma); indeed, the horseshoe lemma shows that the rear
face of the diagram commutes. Similarly, deÔ¨Åne Œ∑: Q ‚ÜíB by Œ∑: (y‚Ä≤, y‚Ä≤‚Ä≤) ‚Üí
jŒ∑‚Ä≤y‚Ä≤ + œÑy‚Ä≤‚Ä≤, where œÑ : Q‚Ä≤‚Ä≤ ‚ÜíB satisÔ¨Åes qœÑ = Œ∑‚Ä≤‚Ä≤; the front face commutes as well.
Step 4. DeÔ¨Åne F : P ‚ÜíQ by
F : (x‚Ä≤, x‚Ä≤‚Ä≤) ‚Üí(F‚Ä≤x‚Ä≤ + Œ≥ x‚Ä≤‚Ä≤, F‚Ä≤‚Ä≤x‚Ä≤‚Ä≤),
where Œ≥ : P‚Ä≤‚Ä≤ ‚ÜíQ‚Ä≤ is to be constructed. It is easy to see that the plane containing
the P's and Q's commutes, no matter how Œ≥ is deÔ¨Åned.
Step 5. It remains to choose Œ≥ so that the square with vertices P, Q, C, and A commutes;
that is, we want f Œµ = Œ∑F. Evaluating each side leads to the equation
f iŒµ‚Ä≤x‚Ä≤ + f œÉ x‚Ä≤‚Ä≤ = jŒ∑‚Ä≤F‚Ä≤x‚Ä≤ + jŒ∑‚Ä≤Œ≥ x‚Ä≤‚Ä≤ + œÑ F‚Ä≤‚Ä≤x‚Ä≤‚Ä≤.
Now f iŒµ‚Ä≤ = j f ‚Ä≤Œµ‚Ä≤ = jŒ∑‚Ä≤F‚Ä≤ (because F‚Ä≤ is the 0th term in the chain map Àáf over f ),
and so it sufÔ¨Åces to Ô¨Ånd Œ≥ so that
jŒµ‚Ä≤Œ≥ = f œÉ ‚àíœÑ F‚Ä≤‚Ä≤.

Sec. 10.5
Derived Functors
845
Consider the diagram with exact row:
P‚Ä≤‚Ä≤
f œÉ‚àíœÑ F‚Ä≤‚Ä≤

Q‚Ä≤
jŒµ‚Ä≤
 C
q
 C‚Ä≤‚Ä≤
Now im( f œÉ ‚àíœÑ F‚Ä≤‚Ä≤) ‚äÜim jŒµ‚Ä≤ = ker q, for
q f œÉ ‚àíqœÑ F‚Ä≤‚Ä≤ = f ‚Ä≤‚Ä≤ pœÉ ‚àíŒ∑‚Ä≤‚Ä≤F‚Ä≤‚Ä≤ = f ‚Ä≤‚Ä≤Œµ‚Ä≤‚Ä≤ ‚àíŒ∑‚Ä≤‚Ä≤F‚Ä≤‚Ä≤ = 0.
Since P‚Ä≤‚Ä≤ is projective, there exists a map Œ≥ : P‚Ä≤‚Ä≤ ‚ÜíQ‚Ä≤ making the diagram com-
mute.
Step 6. By the 3 √ó 3 Lemma (Exercise 10.29 on page 828), the rows 0 ‚ÜíK ‚Ä≤ ‚ÜíK ‚Üí
K ‚Ä≤‚Ä≤ ‚Üí0 and 0 ‚ÜíN ‚Ä≤ ‚ÜíN ‚ÜíN ‚Ä≤‚Ä≤ ‚Üí0 are exact, and we let the reader show that
there are maps on the top face making every square commute.
‚Ä¢
In the next section, we will show how Tor can be computed and used. But, before
leaving this section, let us give the same treatment to Hom that we have just given to tensor
product.
Left derived functors of a functor T are deÔ¨Åned so that T PA is a complex with all its
nonzero terms on the left side; that is, all terms of negative degree are {0}. One consequence
of this is Corollary 10.55: If T is right exact, then L0T is naturally equivalent to T . As
the Hom functors are left exact, we are now going to deÔ¨Åne right derived functors RnT , in
terms of deleted resolutions C‚Ä¢ for which T C‚Ä¢ is on the right. We shall see that R0T is
naturally equivalent to T when T is left exact.
Given an additive covariant functor T : RMod ‚ÜíSMod, where R and S are rings,
we are now going to construct, for all n ‚ààZ, its right derived functors RnT : RMod ‚Üí
SMod.
Choose, once for all, a deleted injective resolution EA of every module A, form the
complex T EA, and take homology:
RnT (A) = Hn(T EA) = ker T dn
im T dn‚àí1 .
The reader should reread Example 10.34(x) to recall the index raising convention; if the
indices are lowered, then the deÔ¨Ånition would be
RnT (A) = H‚àín(T EA) = ker T d‚àín
im T d‚àín+1
.
Notice that we have raised the index on homology modules as well; we write Hn instead
of H‚àín.
The deÔ¨Ånition of RnT ( f ), where f : A ‚ÜíA‚Ä≤ is a homomorphism, is similar to that
for left derived functors. By the dual of the comparison theorem, there is a chain map

846
Homology
Ch. 10
Àáf : EA ‚ÜíE‚Ä≤ A‚Ä≤ over f , unique to homotopy, and so a unique map RnT ( f ): Hn(T EA) ‚Üí
Hn(T EA‚Ä≤), namely, (T Àáfn)‚àó, is induced in homology.
In pictures, look at the chosen injective resolutions:
0
 A‚Ä≤
 E‚Ä≤0
 E‚Ä≤1
 ¬∑ ¬∑ ¬∑
0
 A
f

 E0
 E1
 ¬∑ ¬∑ ¬∑
Fill in the a chain map Àáf over f , then apply T to this diagram, and then take the map
induced by T Àáf in homology.
Proposition 10.59.
Given a pair of rings R and S and an additive covariant functor
T : RMod ‚ÜíSMod, then
RnT : RMod ‚ÜíSMod
is an additive covariant functor for every n.
The proof of this proposition, as well as the proofs of other propositions about right
derived functors soon to be stated, are essentially duals of the proofs we have already
given, and so they will be omitted.
Example 10.60.
If T is a covariant additive functor that preserves multiplications, and if ¬µr : A ‚ÜíA
is multiplication by r, where r ‚ààZ(R) is a central element, then RnT also preserves
multiplications (see Example 10.47).
‚óÄ
Proposition 10.61.
If T : RMod ‚ÜíSMod is a covariant additive functor, then RnT A =
{0} for all negative n and for all A.
DeÔ¨Ånition.
If T = HomR(B, ), deÔ¨Åne Extn
R(B, ) = RnT . Thus, if
EA = 0 ‚ÜíE0
d0
‚àí‚ÜíE1
d1
‚àí‚ÜíE2 ‚Üí¬∑ ¬∑ ¬∑ ,
is the chosen deleted injective resolution of a module A, then
Extn
R(B, A) = Hn(HomR(B, EA)) = ker(dn)‚àó
im(dn‚àí1)‚àó
,
where (dn)‚àó: HomR(B, En) ‚ÜíHomR(B, E‚Ä≤n) is deÔ¨Åned, as usual, by
(dn)‚àó: f ‚Üídn f.
The domain of RnT , in particular, the domain of Extn
R(B, ), is RMod, the category of
all left R-modules, and its target is Ab, the category of abelian groups. The target may be
larger; for example, it is RMod if R is commutative.
Assume that new choices EA of deleted injective resolutions have been made, and let
us denote the right derived functors arising from these new choices by RnT .

Sec. 10.5
Derived Functors
847
Proposition 10.62.
Given a pair of rings R and S, and an additive covariant functor
T : RMod ‚ÜíSMod, then, for each n, the functors RnT and RnT are naturally equivalent.
In particular, for all A,
(RnT )A ‚àº= (RnT )A,
and so these modules are independent of the choice of (deleted) injective resolution of A.
Corollary 10.63.
The module Extn
R(B, A) is independent of the choice of injective reso-
lution of A.
Corollary 10.64.
Let T : RMod ‚ÜíSMod be an additive covariant functor. If E is an
injective module, then RnT (E) = {0} for all n ‚â•1.
In particular, if E is an injective R-module, then Extn
R(B, E) = {0} for all n ‚â•1 and
all modules B.
Theorem 10.65.
If 0 ‚ÜíA‚Ä≤
i
‚àí‚ÜíA
p
‚àí‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is an exact sequence of modules and if
T : RMod ‚ÜíSMod is a covariant additive functor, then there is a long exact sequence:
¬∑ ¬∑ ¬∑ ‚ÜíRnT A‚Ä≤ RnTi
‚àí‚ÜíRnT A
RnT p
‚àí‚ÜíRnT A‚Ä≤‚Ä≤
‚àÇn
‚àí‚Üí
Rn+1T A‚Ä≤ Rn+1Ti
‚àí‚ÜíRn+1T A
Rn+1T p
‚àí‚Üí
Rn+1T A‚Ä≤‚Ä≤ ‚àÇn+1
‚àí‚Üí¬∑ ¬∑ ¬∑
that begins with
0 ‚ÜíR0T A‚Ä≤ ‚ÜíR0T A ‚ÜíR0T A‚Ä≤‚Ä≤ ‚Üí¬∑ ¬∑ ¬∑.
Corollary 10.66.
If T : RMod ‚ÜíSMod is a covariant additive functor, then the functor
R0T is left exact.
Theorem 10.67.
(i) If an additive covariant functor T : RMod ‚ÜíSMod is left exact, then T is naturally
equivalent to R0T .
(ii) If B is a left R-module, the functor HomR(B, ) is naturally equivalent to Ext0
R(B, ).
Hence, for all left R-modules A, there is an isomorphism
HomR(B, A) ‚àº= Ext0
R(B, A).
We have shown that Ext repairs the loss of exactness that may occur after applying Hom
to a short exact sequence.

848
Homology
Ch. 10
Corollary 10.68.
If 0 ‚ÜíA‚Ä≤ ‚ÜíA ‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is a short exact sequence of modules, then
there is a long exact sequence
0 ‚ÜíHomR(B, A‚Ä≤) ‚ÜíHomR(B, A) ‚ÜíHomR(B, A‚Ä≤‚Ä≤)
‚ÜíExt1
R(B, A‚Ä≤) ‚ÜíExt1
R(B, A) ‚ÜíExt1
R(B, A‚Ä≤‚Ä≤)
‚ÜíExt2
R(B, A‚Ä≤) ‚ÜíExt2
R(B, A) ‚ÜíExt2
R(B, A‚Ä≤‚Ä≤) ‚Üí¬∑.
Proposition 10.69.
Given a commutative diagram of modules having exact rows,
0
 A‚Ä≤
f

i
 A
p

g

A‚Ä≤‚Ä≤
h

 0
0
 C‚Ä≤
j
 C
q
 C‚Ä≤‚Ä≤
 0
there is, for all n, a commutative diagram with exact rows
Extn
R(B, A‚Ä≤)
f‚àó

i‚àó
 Extn
R(B, A)
p‚àó
g‚àó

Extn
R(B, A‚Ä≤‚Ä≤)
h‚àó

‚àÇn  Extn+1
R
(B, A‚Ä≤)
f‚àó

Extn
R(B, C‚Ä≤)
j‚àó
 Extn
R(B, C)
q‚àó Extn
R(B, C‚Ä≤‚Ä≤)
‚àÇ‚Ä≤n  Extn+1
R
(B, C‚Ä≤)
Finally, we discuss derived functors of contravariant functors T . If we deÔ¨Åne right
derived functors RnT , in terms of deleted resolutions C‚Ä¢ for which T C‚Ä¢ is on the right,
then we start with a deleted projective resolution PA, for then the contravariance of T puts
T PA on the right.13
Given an additive contravariant functor T : RMod ‚ÜíSMod, where R and S are rings,
we are now going to construct, for all n ‚ààZ, its right derived functors RnT : RMod ‚Üí
SMod.
Choose, once for all, a deleted projective resolution PA of every module A, form the
complex T PA, and take homology:
RnT (A) = Hn(T PA) = ker T dn+1
im T dn
.
If f : A ‚ÜíA‚Ä≤, deÔ¨Åne RnT ( f ): RnT (A‚Ä≤) ‚ÜíRnT (A) as we did for left derived func-
tors. By the comparison theorem, there is a chain map Àáf : PA ‚ÜíP‚Ä≤
A‚Ä≤ over f , unique to
homotopy, which induces a map RnT ( f ): Hn(T P‚Ä≤
A‚Ä≤) ‚ÜíHn(T PA), namely, (T Àáfn)‚àó, in
homology.
13If we were interested in left derived functors of a contravariant T , but we are not, then we would use injective
resolutions.

Sec. 10.5
Derived Functors
849
Example 10.70.
If T is an additive contravariant functor that preserves multiplications, and if ¬µr : A ‚ÜíA
is multiplication by r, where r ‚ààZ(R) is a central element, then RnT also preserves
multiplications (see Example 10.47).
‚óÄ
Proposition 10.71.
Given a pair of rings R and S and an additive contravariant functor
T : RMod ‚ÜíSMod, then
RnT : RMod ‚ÜíSMod
is an additive contravariant functor for every n.
Proposition 10.72.
If T : RMod ‚ÜíSMod is a contravariant additive functor, then
RnT A = {0} for all negative n and for all A.
DeÔ¨Ånition.
If T = HomR( , C), deÔ¨Åne extn
R( , C) = RnT . Thus, if
¬∑ ¬∑ ¬∑ ‚ÜíP2
d2
‚àí‚ÜíP1
d1
‚àí‚ÜíP0 ‚Üí0
is the chosen deleted projective resolution of a module A, then
extn
R(A, C) = Hn(HomR(PA, C) = ker(dn+1)‚àó
im(dn)‚àó,
where (dn)‚àó: HomR(P‚Ä≤
n, C) ‚ÜíHomR(Pn, C) is deÔ¨Åned, as usual, by
(dn)‚àó: f ‚Üíf dn.
The same phenomenon that holds for Tor holds for Ext: for all A and C (and for all R
and n),
Extn
R(A, C) ‚àº= extn
R(A, C).
The same proof that shows that Tor is independent of the variable resolved also works
for Ext (see Rotman, An Introduction to Homological Algebra, p. 197). In light of this
theorem, we will dispense with the two notations for Ext.
Assume that new choices PA of deleted projective resolutions have been made, and let
us denote the right derived functors arising from these new choices by RnT .
Proposition 10.73.
Given a pair of rings R and S, and an additive contravariant functor
T : RMod ‚ÜíSMod, then, for each n, the functors RnT and RnT are naturally equivalent.
In particular, for all A,
(RnT )A ‚àº= (RnT )A,
and so these modules are independent of the choice of (deleted) projective resolution of A.

850
Homology
Ch. 10
Corollary 10.74.
The module Extn
R(A, C) is independent of the choice of projective res-
olution of A.
Corollary 10.75.
Let T : RMod ‚ÜíSMod be an additive contravariant functor. If P is a
projective module, then RnT (P) = {0} for all n ‚â•1.
In particular, if P is a projective R-module, then Extn
R(P, B) = {0} for all n ‚â•1 and
all modules B.
Theorem 10.76.
If 0 ‚ÜíA‚Ä≤
i
‚àí‚ÜíA
p
‚àí‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is an exact sequence of modules
and if T : RMod ‚ÜíSMod is a contravariant additive functor, then there is a long exact
sequence
¬∑ ¬∑ ¬∑ ‚ÜíRnT A‚Ä≤‚Ä≤ RnT p
‚àí‚ÜíRnT A
RnTi
‚àí‚ÜíRnT A‚Ä≤
‚àÇn
‚àí‚Üí
Rn+1T A‚Ä≤‚Ä≤ Rn+1T p
‚àí‚Üí
Rn+1T A
Rn+1Ti
‚àí‚ÜíRn+1T A‚Ä≤ ‚àÇn+1
‚àí‚Üí¬∑ ¬∑ ¬∑
that begins with
0 ‚ÜíR0T A‚Ä≤‚Ä≤ ‚ÜíR0T A ‚ÜíR0T A‚Ä≤ ‚Üí¬∑ ¬∑ ¬∑.
Corollary 10.77.
If T : RMod ‚ÜíSMod is a contravariant additive functor, then the
functor R0T is left exact.
Theorem 10.78.
(i) If an additive contravariant functor T : RMod ‚ÜíSMod is left exact, then T is
naturally equivalent to R0T .
(ii) If C is a left R-module, the functor HomR( , C) is naturally equivalent to Ext0
R( , C).
Hence, for all left R-modules A, there is an isomorphism
HomR(A, C) ‚àº= Ext0
R(A, C).
We have shown that Ext repairs the loss of exactness that may occur after applying Hom
to a short exact sequence.
Corollary 10.79.
If 0 ‚ÜíA‚Ä≤ ‚ÜíA ‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is a short exact sequence of modules, then
there is a long exact sequence
0 ‚ÜíHomR(A‚Ä≤‚Ä≤, C) ‚ÜíHomR(A, C) ‚ÜíHomR(A‚Ä≤, C)
‚ÜíExt1
R(A‚Ä≤‚Ä≤, C) ‚ÜíExt1
R(A, C) ‚ÜíExt1
R(A‚Ä≤, C)
‚ÜíExt2
R(A‚Ä≤‚Ä≤, C) ‚ÜíExt2
R(A, C) ‚ÜíExt2
R(A‚Ä≤, C) ‚Üí¬∑ ¬∑ ¬∑ .

Sec. 10.5
Derived Functors
851
Proposition 10.80.
Given a commutative diagram of modules having exact rows,
0
 A‚Ä≤
f

i
 A
p

g

A‚Ä≤‚Ä≤
h

 0
0
 C‚Ä≤
j
 C
q
 C‚Ä≤‚Ä≤
 0
there is, for all n, a commutative diagram with exact rows
Extn
R(A‚Ä≤‚Ä≤, B)
p‚àó
 Extn
R(A, B)
i‚àó
 Extn
R(A‚Ä≤, B)
‚àÇn  Extn+1
R
(A‚Ä≤‚Ä≤, B)
Extn
R(C‚Ä≤‚Ä≤, B)
h‚àó

q‚àó
 Extn
R(C, B)
g‚àó

j‚àó
 Extn
R(C‚Ä≤, B)
f ‚àó

‚àÇn‚Ä≤  Extn+1
R
(C‚Ä≤‚Ä≤, B)
h‚àó

Remark.
When T is a covariant functor, then we call the ingredients of LnT chains,
cycles, boundaries, and homology. When T is contravariant, we often add the preÔ¨Åx "co,"
and the ingredients of RnT are usually called cochains, cocycles, coboundaries, and co-
homology. Unfortunately, this clear distinction is blurred because the Hom functor is con-
travariant in one variable but covariant in the other. In spite of this, we usually use the "co"
preÔ¨Åx for the derived functors Extn of Hom.
‚óÄ
Derived functors are one way to construct functors like Ext and Tor. In the next section,
along with more properties of Ext and Tor, we shall describe another construction of Ext,
due to N. Yoneda, and another construction of Tor, due to S. Mac Lane. Indeed, derived
functors will rarely be mentioned in the sequel.
EXERCISES
10.36 If œÑ : F ‚ÜíG is a natural transformation between additive functors, prove that œÑ gives chain
maps œÑC : FC ‚ÜíGC for every complex C. If œÑ is a natural equivalence, prove that FC ‚àº=
GC.
10.37
(i) Let T : RMod ‚ÜíSMod be an exact additive functor, where R and S are rings, and
suppose that P projective implies T P projective. If B is a left R-module and PB is a
deleted projective resolution of B, prove that T PT B is a deleted projective resolution of
T B.
(ii) Let A be an R-algebra, where R is a commutative ring, which is Ô¨Çat as an R-module.
Prove that if B is an A-module (and hence an R-module), then
A ‚äóR TorR
n (B, C) ‚àº= TorA
n (B, A ‚äóR C)
for all R-modules C and all n ‚â•0.

852
Homology
Ch. 10
10.38 Let R be a semisimple ring.
(i) Prove, for all n ‚â•1, that TorRn (A, B) = {0} for all right R-modules A and all left
R-modules B.
Hint. If R is semisimple, then every (left or right) R-module is projective.
(ii) Prove, for all n ‚â•1, that Extn
R(A, B) = {0} for all left R-modules A and B.
10.39 If R is a PID, prove, for all n ‚â•2, that TorRn (A, B) = {0} = Extn
R(A, B) for all R-modules A
and B.
Hint. Use Theorem 9.8.
10.40 Let R be a domain and let A be an R-module.
(i) Prove that if the multiplication ¬µr : A ‚ÜíA is an injection for all r Ã∏= 0, then A is
torsion-free.
(ii) Prove that if the multiplication ¬µr : A ‚ÜíA is a surjection for all r Ã∏= 0, then A is
divisible.
(iii) Prove that if the multiplication ¬µr : A ‚ÜíA is an isomorphism for all r Ã∏= 0, then A is
a vector space over Q, where Q = Frac(R).
Hint. A module A is a vector space over Q if and only if it is torsion-free and divisible.
(iv) If either C or A is a vector space over Q, prove that TorRn (C, A) and Extn
R(C, A) are
also vector spaces over Q.
10.41 Let R be a domain and let Q = Frac(R).
(i) If r ‚ààR is nonzero and A is an R-module for which r A = {0}; that is, ra = 0 for all
a ‚ààA, prove that Extn
R(Q, A) = {0} = TorRn (Q, A) for all n ‚â•0.
Hint. If V is a vector space over Q for which rV = {0}, then V = {0}.
(ii) Prove that Extn
R(V, A) = {0} = TorRn (V, A) for all n ‚â•0 whenever V is a vector space
over Q and A is an R-module for which r A = {0} for some nonzero r ‚ààR.
10.42 Let A and B be R-modules. For f : A‚Ä≤ ‚ÜíB, where A‚Ä≤ is a submodule of A, deÔ¨Åne its
obstruction to be ‚àÇ( f ), where ‚àÇ: HomR(A‚Ä≤, B) ‚ÜíExt1
R(A/A‚Ä≤, B) is the connecting homo-
morphism. Prove that f can be extended to a homomorphism f : A ‚ÜíB if and only if its
obstruction is 0.
10.43 If T : Ab ‚ÜíAb is a left exact functor, prove that L0T is an exact functor. Conclude, for any
abelian group B, that L0 Hom(B, ) is not naturally equivalent to Hom(B, ).
10.6 EXT AND TOR
We now examine Ext and Tor more closely. As we said in the last section, all properties of
these functors should follow from versions of Theorem 10.45, the axioms characterizing
them (see Exercises 10.44 and 10.45 on page 869); in particular, their construction as
derived functors need not be used.
We begin by showing that Ext behaves like Hom with respect to sums and products.

Sec. 10.6
Ext and Tor
853
Proposition 10.81.
If {Ak : k ‚ààK} is a family of modules, then there are natural
isomorphisms, for all n,
Extn
R

k‚ààK
Ak, B
 ‚àº=

k‚ààK
Extn
R(Ak, B).
Proof.
The proof is by dimension shifting; that is, by induction on n ‚â•0. The base
step is Theorem 7.33, for Ext0( , B) is naturally equivalent to the contravariant functor
Hom( , B).
For the inductive step, choose, for each k ‚ààK, a short exact sequence
0 ‚ÜíLk ‚ÜíPk ‚ÜíAk ‚Üí0,
where Pk is projective. There is an exact sequence
0 ‚Üí

k
Lk ‚Üí

k
Pk ‚Üí

k
Ak ‚Üí0,
and 
k Pk is projective, for every sum of projectives is projective. There is a commutative
diagram with exact rows:
Hom( Pk, B)

œÑ

Hom( Lk, B) ‚àÇ
œÉ

Ext1( Ak, B)


Ext1( Pk, B)
 Hom(Pk, B)
  Hom(Lk, B) d   Ext1(Ak, B)
  Ext1( Pk, B),
where the maps in the bottom row are just the usual induced maps in each coordinate, and
the maps œÑ and œÉ are the isomorphisms given by Theorem 7.33. Now Ext1( Pk, B) =
{0} =  Ext1(Pk, B), because  Pk and each Pk are projective, so that the maps ‚àÇand
d are surjective. This is precisely the sort of diagram in Proposition 8.93, and so there
exists an isomorphism Ext1( Ak, B) ‚Üí Ext1(Ak, B) making the augmented diagram
commute.
We may now assume that n ‚â•1, and we look further out in the long exact sequence.
There is a commutative diagram
Extn Pk, B

 Extn Lk, B

‚àÇ
œÉ

Extn+1 Ak, B



Extn+1 Pk, B

 Extn(Pk, B)
  Extn(Lk, B)
d  Extn+1(Ak, B)
  Extn+1(Pk, B),
where œÉ : Extn( Lk, B) ‚Üí Extn(Lk, B) is an isomorphism that exists by the induc-
tive hypothesis. Since n ‚â•1, all four Ext's whose Ô¨Årst variable is projective are {0}; it
follows from exactness of the rows that both ‚àÇand d are isomorphisms. Finally, the com-
posite dœÉ‚àÇ‚àí1 : Extn+1( Ak, B) ‚Üí Extn+1(Ak, B) is an isomorphism, as desired.
‚Ä¢
There is a dual result in the second variable.

854
Homology
Ch. 10
Proposition 10.82.
If {Bk : k ‚ààK} is a family of modules, then there are natural
isomorphisms, for all n,
Extn
R

A,

k‚ààK
Bk
 ‚àº=

k‚ààK
Extn
R(A, Bk).
Proof.
The proof is by dimension shifting. The base step is Theorem 7.32, for Ext0(A, )
is naturally equivalent to the covariant functor Hom(A, ).
For the inductive step, choose, for each k ‚ààK, a short exact sequence
0 ‚ÜíBk ‚ÜíEk ‚ÜíNk ‚Üí0,
where Ek is injective. There is an exact sequence
0 ‚Üí

k
Bk ‚Üí

k
Ek ‚Üí

k
Nk ‚Üí0,
and 
k Ek is injective, for every product of injectives is injective, by Proposition 7.66.
There is a commutative diagram with exact rows:
Hom(A,  Ek)

œÑ

Hom(A,  Nk) ‚àÇ
œÉ

Ext1(A,  Bk)


Ext1(A,  Ek)
 Hom(A, Ek)
  Hom(A, Nk) d   Ext1(A, Bk)
  Ext1(A, Ek),
where the maps in the bottom row are just the usual induced maps in each coordinate, and
the maps œÑ and œÉ are the isomorphisms given by Theorem 7.32. The proof now Ô¨Ånishes as
that of Proposition 10.81.
‚Ä¢
It follows that Extn commutes with Ô¨Ånite direct sums in either variable.
Remark.
These last two propositions cannot be generalized by replacing sums by direct
limits or products by inverse limits; the reason is that direct limits of projectives need not
be projective and inverse limits of injectives need not be injective.
‚óÄ
When the ring R is noncommutative, HomR(A, B) is an abelian group, but it need not
be an R-module.
Proposition 10.83.
(i) Let r ‚ààZ(R) be a central element, and let A and B be left R-modules. If ¬µr : B ‚Üí
B is multiplication by r, then the induced map
¬µ‚àó
r : Extn
R(A, B) ‚ÜíExtn
R(A, B)
is also multiplication by r. A similar statement is true in the other variable.
(ii) If R is a commutative ring, then Extn
R(A, B) is an R-module.
Proof.
(i) This follows at once from Example 10.47.
(ii) This follows from part (i) if we deÔ¨Åne scalar multiplication by r to be ¬µ‚àó
r .
‚Ä¢

Sec. 10.6
Ext and Tor
855
Example 10.84.
(i) We show, for every abelian group B, that
Ext1
Z(In, B) ‚àº= B/nB.
There is an exact sequence
0 ‚ÜíZ
¬µn
‚àí‚ÜíZ ‚ÜíIn ‚Üí0,
where ¬µn is multiplication by n. Applying Hom( , B) gives exactness of
Hom(Z, B)
¬µ‚àó
n
‚àí‚ÜíHom(Z, B) ‚ÜíExt1(In, B) ‚ÜíExt1(Z, B).
Now Ext1(Z, B) = {0} because Z is projective. Moreover, ¬µ‚àó
n is also multiplication by n,
while Hom(Z, B) = B. More precisely, Hom(Z, ) is naturally equivalent to the identity
functor on Ab, and so there is a commutative diagram with exact rows
B
œÑB

¬µn
 B
œÑB

 B/nB

 0
Hom(Z, B)
¬µ‚àó
n
 Hom(Z, B)
 Ext1(In, B)
 0
By Proposition 8.93, there is an isomorphism B/nB ‚àº= Ext1(In, B).
(ii) We can now compute Ext1
Z(A, B) whenever A and B are Ô¨Ånitely generated abelian
groups. By the fundamental theorem, both A and B are direct sums of cyclic groups. Since
Ext commutes with Ô¨Ånite direct sums, Ext1
Z(A, B) is the direct sum of groups Ext1
Z(C, D),
where C and D are cyclic. We may assume that C is Ô¨Ånite, otherwise it is projective, and
Ext1(C, D) = {0}. This calculation can be completed using part (i) and Exercise 5.5 on
page 267, which says that if D is a cyclic group of Ô¨Ånite order m, then D/nD is a cyclic
group of order d, where d = (m, n) is their gcd.
‚óÄ
We now give the obvious deÔ¨Ånition analogous to extensions of groups.
DeÔ¨Ånition.
Given R-modules C and A, an extension of A by C is a short exact sequence
0 ‚ÜíA
i
‚àí‚ÜíB
p
‚àí‚ÜíC ‚Üí0.
An extension is split if there exists an R-map s : C ‚ÜíB with ps = 1C.
Of course, if 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 is a split extension, then B ‚àº= A ‚äïC.
Whenever meeting a homology group, we must ask what it means for it to be zero, for its
elements can then be construed as being obstructions. For example, factor sets explain why
a group extension may not be split. In this section, we will show that Ext1
R(C, A) = {0} if
and only if every extension of A by C splits. Thus, nonzero elements of any Ext1
R(C‚Ä≤, A‚Ä≤)
describe nonsplit extensions (indeed, this result is why Ext is so called) .
We begin with a deÔ¨Ånition motivated by Proposition 10.17.

856
Homology
Ch. 10
DeÔ¨Ånition.
Given modules C and A, two extensions Œæ : 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 and
Œæ‚Ä≤ : 0 ‚ÜíA ‚ÜíB‚Ä≤ ‚ÜíC ‚Üí0 of A by C are equivalent if there exists a map œï : B ‚ÜíB‚Ä≤
making the following diagram commute:
Œæ : 0
 A
i

1A

B
p

œï

C
1C

 1
Œæ‚Ä≤ : 0
 A
i‚Ä≤
 B‚Ä≤
p‚Ä≤
 C
 1
We denote the equivalence class of an extension Œæ by [Œæ], and we deÔ¨Åne
e(C, A) =

[Œæ] : Œæ is an extension of A by C

.
If two extensions are equivalent, then the Ô¨Åve lemma (Exercise 8.52 on page 604) shows
that the map œï must be an isomorphism; it follows that equivalence is, indeed, an equiva-
lence relation (for we can now prove symmetry). However, the converse is false: There can
be inequivalent extensions having isomorphic middle terms, as we saw in Example 10.18
(all groups in this example are abelian, and so we may view it as an example of Z-modules).
Proposition 10.85.
If Ext1
R(C, A) = {0}, then every extension
0 ‚ÜíA
i
‚àí‚ÜíB
p
‚àí‚ÜíC ‚Üí0
is split.
Proof.
Apply the functor Hom(C, ) to the extension to obtain an exact sequence
Hom(C, B)
p‚àó
‚àí‚ÜíHom(C, C)
‚àÇ
‚àí‚ÜíExt1(C, A).
By hypothesis, Ext1(C, A) = {0}, so that p‚àóis surjective.
Hence, there exists s ‚àà
Hom(C, B) with 1C = p‚àó(s); that is, 1C = ps, and this says that the extension splits.
‚Ä¢
Corollary 10.86.
An R-module P is projective if and only if Ext1
R(P, B) = {0} for every
R-module B.
Proof.
If P is projective, then Ext1
R(P, B) = {0} for all B, by Corollary 10.52. Con-
versely, if Ext1
R(P, B) = {0} for all B, then every exact sequence 0 ‚ÜíB ‚ÜíX ‚ÜíP ‚Üí0
splits, by Proposition 10.85, and so P is projective, by Proposition 7.54.
‚Ä¢
We are going to prove the converse of Proposition 10.85 by showing that there is a
bijection œà : e(C, A) ‚ÜíExt1(C, A). Let us construct the function œà.
Given an extension Œæ : 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 and a projective resolution of C, form
the diagram
P2
d2


P1
d1

Œ±

P0


C

1C

0
0
 A
 B
 C
 0

Sec. 10.6
Ext and Tor
857
By the comparison theorem (Theorem 10.46), we may Ô¨Åll in dotted arrows to obtain a
commutative diagram. In particular, there is a map Œ± : P1 ‚ÜíA with Œ±d2 = 0; that is,
d‚àó
2(Œ±) = 0, so that Œ± ‚ààker d‚àó
2 is a cocycle. The comparison theorem also says that any two
Ô¨Ållings in of the diagram are homotopic; thus, if Œ±‚Ä≤ : P1 ‚ÜíA is part of a second Ô¨Ålling in,
there are maps s0 and s1 with Œ±‚Ä≤ ‚àíŒ± = 0 ¬∑ s1 + s0d1 = s0d1:
P2
d2
 P1
d1

Œ±‚Ä≤

Œ±

s1
,,,,,,,,
P0
s0
,,,,,,,,
0
 A
 B
Thus, Œ±‚Ä≤ ‚àíŒ± ‚ààim d‚àó
1, and so the homology class Œ± + im d‚àó
1 ‚ààExt1(C, A) is well-deÔ¨Åned.
We leave as an exercise for the reader that equivalent extensions Œæ and Œæ‚Ä≤ determine the
same element of Ext. Thus,
œà : e(C, A) ‚ÜíExt1(C, A),
given by
œà([Œæ]) = Œ± + im d‚àó
1,
is a well-deÔ¨Åned function. In order to prove that œà is a bijection, we Ô¨Årst analyze the
diagram containing the map Œ±.
Lemma 10.87.
Let - : 0 ‚ÜíX1
i
‚àí‚ÜíX0
Œµ
‚àí‚ÜíC ‚Üí0 be an extension of a module X1
by a module C. Given a module A, consider the diagram
- : 0
 X1
j

Œ±

X0
Œµ
 C

1C

0
A
C
(i) There exists a commutative diagram with exact rows completing the given diagram:
0
 X1
j

Œ±

X0
Œµ

Œ≤

C

1C

0.
0
 A
i
 B
Œ∑
 C
 0
(ii) Any two bottom rows of completed diagrams are equivalent extensions.
Proof.
(i) We deÔ¨Åne B as the pushout of j and Œ±. Thus, if
S =

(Œ±x1, ‚àíjx1) ‚ààA ‚äïX0 : x1 ‚ààX1

,

858
Homology
Ch. 10
deÔ¨Åne B = (A ‚äïX0)/S,
i : a ‚Üía + S,
Œ≤ : x0 ‚Üíx0 + S,
and
Œ∑: (a, x0) + S ‚ÜíŒµx0.
That Œ∑ is well-deÔ¨Åned, that the diagram commutes, and that the bottom row is exact are
left for the reader to check.
(ii) Let
0
 X1
j

Œ±

X0
Œµ

Œ≤‚Ä≤

C

1C

0.
0
 A
i‚Ä≤
 B‚Ä≤
Œ∑‚Ä≤
 C
 0
be a second completion of the diagram. DeÔ¨Åne f : A ‚äïX0 ‚ÜíB‚Ä≤ by
f : (a, x0) ‚Üíi‚Ä≤a + Œ≤‚Ä≤x0.
We claim that f is surjective. If b‚Ä≤ ‚ààB‚Ä≤, then Œ∑‚Ä≤b‚Ä≤ ‚ààC, and so there is x0 ‚ààX0 with
Œµx0 = Œ∑‚Ä≤b‚Ä≤. Commutativity gives Œ∑‚Ä≤Œ≤‚Ä≤x0 = Œµx0 = Œ∑‚Ä≤b‚Ä≤. Hence, b‚Ä≤ ‚àíŒ≤‚Ä≤x0 ‚ààker Œ∑‚Ä≤ = im i‚Ä≤,
and so there is a ‚ààA with i‚Ä≤a = b‚Ä≤ ‚àíŒ≤‚Ä≤x0. Therefore, b‚Ä≤ = i‚Ä≤a + Œ≤‚Ä≤x0 ‚ààim f , as desired.
We now show that ker f = S. If (Œ±x1, ‚àíjx1) ‚ààS, then f (Œ±x1, ‚àíjx1) = i‚Ä≤Œ±x1 ‚àí
Œ≤‚Ä≤ jx1 = 0, by commutativity of the Ô¨Årst square of the diagram, and so S ‚äÜker f . For the
reverse inclusion, let (a, x0) ‚ààker f , so that i‚Ä≤a + Œ≤‚Ä≤x0 = 0. Commutativity of the second
square gives Œµx0 = Œ∑‚Ä≤Œ≤‚Ä≤x0 = ‚àíŒ∑‚Ä≤ia = 0. Hence, x0 ‚ààker Œµ = im j, so there is x1 ‚ààX1
with jx1 = x0. Thus, i‚Ä≤a = ‚àíŒ≤‚Ä≤x0 = ‚àíŒ≤‚Ä≤ jx1 = ‚àíi‚Ä≤Œ±x1. Since i‚Ä≤ is injective, we have
a = ‚àíŒ±x1; replacing x1 by y1 = ‚àíx1. We have (a, x0) = (Œ±y1, ‚àíjy1) ‚ààS, as desired.
Finally, deÔ¨Åne œï : B ‚ÜíB‚Ä≤ by
œï : (a, x0) + S ‚Üíf (a, x0) = i‚Ä≤a + Œ≤‚Ä≤x0
[œï is well-deÔ¨Åned because B = (A ‚äïX0)/S and S = ker f ]. To show commutativity of
the diagram
0
 A
1A

i
 B
Œ∑

œï

C
1C

 0
0
 A
i‚Ä≤
 B‚Ä≤
Œ∑‚Ä≤
 C
 0
we use the deÔ¨Ånitions of the maps i and Œ∑ in part (i). For the Ô¨Årst square, if a ‚ààA, then
œïia = œï((a, 0) + S) = i‚Ä≤a. For the second square,
Œ∑‚Ä≤œï : (a, x0) + S ‚ÜíŒ∑‚Ä≤(i‚Ä≤a + Œ≤‚Ä≤x0)
= Œ∑‚Ä≤Œ≤‚Ä≤x0
= Œµx0
= Œ∑((a, x0) + S).
Therefore, the two bottom rows are equivalent extensions.
‚Ä¢

Sec. 10.6
Ext and Tor
859
Notation.
Denote the extension of A by C just constructed by
Œ±-.
The dual result is true; it is related to the construction of Ext using injective resolutions
of the second variable A.
Lemma 10.88.
Let A and Y0 be modules, and let -‚Ä≤ : 0 ‚ÜíA ‚ÜíY0 ‚ÜíY1 ‚Üí0 be an
extension of A by Y1. Given a module C, consider the diagram
A
1A

C
Œ≥

-‚Ä≤ : 0
 A
 Y0
p
 Y1
 0
(i) There exists a commutative diagram with exact rows completing the given diagram:
-‚Ä≤Œ≥ :
0
 A
1A

 B


C
Œ≥

 0
-‚Ä≤ :
0
 A
 Y0
p
 Y1
 0
(ii) Any two top rows of completed diagrams are equivalent extensions.
Proof.
Dual to that of Lemma 10.87; in particular, construct the top row using the pull-
back of Œ≥ and p.
‚Ä¢
Notation.
Denote the extension of A by C just constructed by
-‚Ä≤Œ≥.
Theorem 10.89.
The function œà : e(C, A) ‚ÜíExt1(C, A) is a bijection.
Proof.
We construct an inverse Œ∏ : Ext1(C, A) ‚Üíe(C, A) for œà. Choose a projective
resolution of C, so there is an exact sequence
¬∑ ¬∑ ¬∑ ‚ÜíP2
d2
‚àí‚ÜíP1
d1
‚àí‚ÜíP0 ‚ÜíC ‚Üí0,
and choose a 1-cocycle Œ± : P1 ‚ÜíA. Since Œ± is a cocycle, we have 0 = d‚àó
2(Œ±) = Œ±d2, so
that Œ± induces a homomorphism Œ±‚Ä≤ : P1/ im d2 ‚ÜíA [if x1 ‚ààP1, then Œ±‚Ä≤ : x1 + im d2 ‚Üí
Œ±(x1)]. Let - denote the extension
- : 0 ‚ÜíP1/ im d2 ‚ÜíP0 ‚ÜíC ‚Üí0.

860
Homology
Ch. 10
As in the lemma, there is a commutative diagram with exact rows:
0
 P1/ im d2

Œ±‚Ä≤

P0
Œ≤

 C
1C

 0
0
 A
i
 B
 C
 0
DeÔ¨Åne Œ∏ : Ext1(C, A) ‚Üíe(C, A) using the construction in the lemma:
Œ∏(Œ± + im d‚àó
1) = [Œ±‚Ä≤-].
We begin by showing that Œ∏ is independent of the choice of cocycle Œ±. Suppose that
Œ∂ : P1 ‚ÜíA is another cocycle. Now Œ± and Œ∂ are parts of a chain map that the comparison
theorem says are homotopic. Hence, there is a map s : P0 ‚ÜíA with Œ∂ = Œ± + sd1. But it
is easy to see that the following diagram commutes:
P2
d2


P1
d1

Œ±+sd1

P0

Œ≤+is

C

1C

0
0
 A
i
 B
 C
 0
As the bottom row has not changed, we have [Œ±‚Ä≤-] = [Œ∂ ‚Ä≤-].
It remains to show that the composites œàŒ∏ and Œ∏œà are identities. If Œ± + im d‚àó
1 ‚àà
Ext1(C, A), then Œ∏(Œ± + im d‚àó
1) is the bottom row of the diagram
0
 P1/ im d2

Œ±‚Ä≤

P0
Œ≤

 C
1C

 0
0
 A
i
 B
 C
 0
and œàŒ∏(Œ± + im d‚àó
1) is the homology class of a cocycle Ô¨Åtting this diagram. Clearly, Œ± is
such a cocycle; and so œàŒ∏ is the identity. For the other composite, start with an extension
Œæ, and then imbed it as the bottom row of a diagram
P2
d2


P1
d1

Œ±

P0


C

1C

0
0
 A
i
 B
 C
 0
Both Œæ and Œ±‚Ä≤- are bottom rows of such a diagram, and so Lemma 10.87(ii) shows that
[Œæ] = [Œ±‚Ä≤-].
‚Ä¢
We can now prove the converse of Proposition 10.85.

Sec. 10.6
Ext and Tor
861
Corollary 10.90.
For any modules C and A, every extension of A by C is split if and only
if Ext1
R(C, A) = {0}.
Proof.
Since Ext1(C, A) = {0}, we have |e(C, A)| = 1, so there is only one equivalence
class of extensions of A by C. But the split extension always exists, and so every extension
is equivalent to the split extension; that is, every extension of A by C splits.
‚Ä¢
Example 10.91.
If p is a prime, then Ext1
Z(Ip, Ip) ‚àº= Ip, as we saw in Example 10.84(i). On the other hand,
it follows from Theorem 10.89 that there are p equivalence classes of extensions 0 ‚Üí
Ip ‚ÜíB ‚ÜíIp ‚Üí0. But |B| = p2, so there are only two choices for B to isomorphism:
B ‚àº= Ip2 or B ‚àº= Ip ‚äïIp. Of course, this is consistent with Example 10.18.
‚óÄ
Here is a minor application of Ext.
Proposition 10.92.
(i) If F is a torsion-free abelian group and T is an abelian group of bounded order
(that is, nT = {0} for some positive integer n), then Ext1(F, T ) = {0}.
(ii) Let G be an abelian group. If the torsion subgroup tG of G is of bounded order, then
tG is a direct summand of G.
Proof.
(i) Since F is torsion-free, it is a Ô¨Çat Z-module, by Corollary 9.6, so that exactness
of 0 ‚ÜíZ ‚ÜíQ gives exactness of 0 ‚ÜíZ ‚äóF ‚ÜíQ ‚äóF. Thus, F ‚àº= Z ‚äóF can be
imbedded in a vector space V over Q, namely, V = Q ‚äóF. Applying the contravariant
functor Hom( , T ) to 0 ‚ÜíF ‚ÜíV ‚ÜíV/F ‚Üí0 gives an exact sequence
Ext1(V, T ) ‚ÜíExt1(F, T ) ‚ÜíExt2(V/F, T ).
Now the last term is {0}, by Exercise 10.39 on page 852, and Ext1(V, T ) is (torsion-free)
divisible, by Example 10.70, so that Ext1(F, T ) is divisible. Since T has bounded order,
Exercise 10.41 on page 852 gives Ext1(F, T ) = {0}.
(ii) To prove that the extension 0 ‚ÜítG ‚ÜíG ‚ÜíG/tG ‚Üí0 splits, it sufÔ¨Åces to prove
that Ext1(G/tG, tG) = {0}. Since G/tG is torsion-free, this follows from part (i) and
Corollary 10.90.
‚Ä¢
The torsion subgroup of a group may not be a direct summand; the following proof by
homology is quite different from that of Exercise 9.1(iii) on page 663.
Proposition 10.93.
There exists an abelian group G whose torsion subgroup is not a
direct summand of G; in fact, we may choose tG = 
p Ip, where the sum is over all
primes p.

862
Homology
Ch. 10
Proof.
It sufÔ¨Åces to prove that Ext1
Q, 
p Ip

Ã∏= 0, for this will give a nonsplit extension
0 ‚Üí
p Ip ‚ÜíG ‚ÜíQ ‚Üí0; moreover, since Q is torsion-free, it follows that 
p Ip =
tG.
Consider the exact sequence 0 ‚Üí
p Ip ‚Üí
p Ip ‚ÜíD ‚Üí0. By Exercise 9.6
on page 663, we know that D is divisible (in truth, D ‚àº= R: it is a torsion-free divisible
group, hence it is a vector space over Q, by Proposition 9.23, and we check that dim(D) =
continuum, which is the dimension of R as a vector space over Q). There is an exact
sequence
Hom

Q,

p
Ip

‚ÜíHom(Q, D)
‚àÇ
‚àí‚ÜíExt1
Q,

p
Ip

‚ÜíExt1(Q,

Ip).
But ‚àÇis an isomorphism: Ext1
Q, 
p Ip
 ‚àº=
 Ext1(Q, Ip) = {0}, by Proposition 10.81
and Proposition 10.92, and Hom(Q, 
p Ip) ‚àº=  Hom(Q, Ip) = {0}, by Theorem 7.33.
Since Hom(Q, D) Ã∏= {0}, we have Ext1(Q, 
p Ip) Ã∏= {0}.
‚Ä¢
Remark.
We can prove that a torsion abelian group T has the property that it is a direct
summand of any group containing it as its torsion subgroup if and only if T ‚àº= B ‚äïD,
where B has bounded order and D is divisible.
‚óÄ
If E is a set and œà : E ‚ÜíG is a bijection to a group G, then there is a unique group
structure on E that makes it a group and œà an isomorphism [if e, e‚Ä≤ ‚ààE, then e = œà‚àí1(g)
and e‚Ä≤ = œà‚àí1(g‚Ä≤); deÔ¨Åne ee‚Ä≤ = œà‚àí1(gg‚Ä≤)]. In particular, Theorem 10.89 implies that there
is a group structure on e(C, A); here are the necessary deÔ¨Ånitions.
DeÔ¨Åne the diagonal map C : C ‚ÜíC ‚äïC by C : c ‚Üí(c, c), and deÔ¨Åne the codiag-
onal map ‚ñΩA : A ‚äïA ‚ÜíA by ‚ñΩA : (a1, a2) ‚Üía1 + a2. Note that if f, f ‚Ä≤ : C ‚ÜíA is a
homomorphism, then the composite ‚ñΩA( f ‚äïf ‚Ä≤) maps C ‚ÜíC ‚äïC ‚ÜíA ‚äïA ‚ÜíA.
It is easy to check that ‚ñΩA( f ‚äïf ‚Ä≤) = f + f ‚Ä≤, so that this formula describes addition
in Hom(C, A). Now Ext is a generalized Hom, and so we mimic this deÔ¨Ånition to deÔ¨Åne
addition in e(C, A).
If Œæ : 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 and Œæ‚Ä≤ : 0 ‚ÜíA‚Ä≤ ‚ÜíB‚Ä≤ ‚ÜíC‚Ä≤ ‚Üí0 are extensions, then
their direct sum is the extension
Œæ ‚äïŒæ‚Ä≤ : 0 ‚ÜíA ‚äïA‚Ä≤ ‚ÜíB ‚äïB‚Ä≤ ‚ÜíC ‚äïC‚Ä≤ ‚Üí0.
The Baer sum [Œæ] + [Œæ‚Ä≤] is deÔ¨Åned to the equivalence class [‚ñΩA(Œæ ‚äïŒæ‚Ä≤)C] (we have
already deÔ¨Åned Œ±- and -‚Ä≤Œ≥ ). To show that Baer sum is well-deÔ¨Åned, we Ô¨Årst show that
Œ±(-‚Ä≤Œ≥ ) is equivalent to (Œ±-‚Ä≤)Œ≥ . We then show that e(C, A) is a group under this operation
by showing that œà([Œæ] + [Œæ‚Ä≤]) = œà([‚ñΩA(Œæ ‚äïŒæ‚Ä≤)C]). The identity element is the class of
the split extension, and the inverse of [Œæ] is [(‚àí1A)Œæ].
This description of Ext1 has been generalized by N. Yoneda to a description of Extn for
all n. Elements of Yoneda's Extn(C, A) are certain equivalence classes of exact sequences
0 ‚ÜíA ‚ÜíB1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíBn ‚ÜíC ‚Üí0,

Sec. 10.6
Ext and Tor
863
and we add them by a generalized Baer sum (see Mac Lane, Homology, pages 82-87).
Thus, there is a construction of Ext that does not use derived functors. Indeed, we can
construct Extn without using projectives or injectives.
In their investigation of Ô¨Ånite-dimensional algebras, M. Auslander and I. Reiten intro-
duced the following notion.
DeÔ¨Ånition.
An exact sequence of left R-modules, over any ring R,
- :
0 ‚ÜíN ‚ÜíX ‚ÜíM ‚Üí0
is almost split if it is not split, if both N and M are indecomposable modules, and for
for all R-modules C and every R-map œï : C ‚ÜíM that is not an isomorphism, the exact
sequence -œï is split.
Another way to say this is that [-] is a nonzero element of Ext1
R(N, M), where N and
M are indecomposable, and [-] ‚ààker œï‚àófor every œï : C ‚ÜíM that is not an isomorphism.
Auslander and Reiten proved that for every indecomposable module M that is not projec-
tive, there exists an almost split exact sequence ending with M. Dually, they proved that
for every indecomposable module N that is not injective, there exists an almost split exact
sequence beginning with N.
It is now Tor's turn. We begin with a result that has no analog for Ext.
Theorem 10.94.
If R is a ring, A is a right R-module, and B is a left R-module, then
TorR
n (A, B) ‚àº= TorRop
n
(B, A)
for all n ‚â•0, where Rop is the opposite ring of R.
Proof.
Recall Proposition 8.11: Every left R-module is a right Rop-module, and every
right R-module is a left Rop-module. Choose a deleted projective resolution PA of A. It is
easy to see that t : PA ‚äóR B ‚ÜíB ‚äóRop PA is a chain map of Z-complexes, where
tn : Pn ‚äóR B ‚ÜíB ‚äóRop Pn
is given by
tn : xn ‚äób ‚Üíb ‚äóxn.
Since each tn is an isomorphism of abelian groups (its inverse is b ‚äóxn ‚Üíxn ‚äób), the
chain map t is an isomorphism of complexes. By Exercise 10.22 on page 827,
TorR
n (A, B) = Hn(PA ‚äóR B) ‚àº= Hn(B ‚äóRop PA)
for all n. But PA, viewed as a complex of left Rop-modules, is a deleted projective resolu-
tion of A qua left Rop-module, and so Hn(B ‚äóRop PA) ‚àº= TorRop
n
(B, A).
‚Ä¢
In light of this result, theorems about Tor(A, ) will yield results about Tor( , B); we
will not have to say "similarly in the other variable."

864
Homology
Ch. 10
Corollary 10.95.
If R is a commutative ring and A and B are R-modules, then for all
n ‚â•0,
TorR
n (A, B) ‚àº= TorR
n (B, A).
We know that Torn vanishes on projectives; we now show that it vanishes on Ô¨Çat mod-
ules.
Proposition 10.96.
A right R-module F is Ô¨Çat if and only if TorR
n (A, M) = {0} for all
n ‚â•1 and every left R-module M.
Proof.
Let 0 ‚ÜíN
i
‚àí‚ÜíP ‚ÜíM ‚Üí0 be exact, where P is projective. There is an exact
sequence
Tor1(F, P) ‚ÜíTor1(F, M) ‚ÜíF ‚äóN
1‚äói
‚àí‚ÜíF ‚äóP.
Now Tor1(F, P) = {0}, because P is projective, so that Tor1(F, M) = ker(1 ‚äói). Since
F is Ô¨Çat, however, ker(1 ‚äói) = {0}, and so Tor1(F, M) = {0}. The result for all n ‚â•1
follows by dimension shifting.
For the converse, 0 ‚ÜíA
i
‚àí‚ÜíB exact implies exactness of
0 = Tor1(F, B/A) ‚ÜíF ‚äóA
1‚äói
‚àí‚ÜíF ‚äóB.
Hence, 1 ‚äói is an injection, and so F is Ô¨Çat. (Notice that we have only assumed the
vanishing of Tor1 in proving the converse.)
‚Ä¢
Proposition 10.97.
If {Bk : k ‚ààK} is a family of left R-modules, then there are natural
isomorphisms, for all n,
TorR
n

A,

k‚ààK
Bk
 ‚àº=

k‚ààK
TorR
n (A, Bk).
There is also an isomorphism if the sum is in the Ô¨Årst variable.
Proof.
The proof is by dimension shifting. The base step is Theorem 8.87, for Tor0(A, )
is naturally equivalent to A‚äó.
For the inductive step, choose, for each k ‚ààK, a short exact sequence
0 ‚ÜíNk ‚ÜíPk ‚ÜíBk ‚Üí0,
where Pk is projective. There is an exact sequence
0 ‚Üí

k
Nk ‚Üí

k
Pk ‚Üí

k
Bk ‚Üí0,
and 
k Pk is projective, for every sum of projectives is projective. There is a commutative
diagram with exact rows:
Tor1(A,  Pk)
 Tor1(A,  Bk)

‚àÇ
 A ‚äó Nk

œÑ

A ‚äó Pk
œÉ

 Tor1(A, Pk)
  Tor1(A, Bk)
‚àÇ‚Ä≤
  A ‚äóNk
  A ‚äóPk,

Sec. 10.6
Ext and Tor
865
where the maps in the bottom row are just the usual induced maps in each coordinate, and
the maps œÑ and œÉ are the isomorphisms given by Theorem 8.87. The proof is completed
by dimension shifting.
‚Ä¢
Example 10.98.
(i) We show, for every abelian group B, that
TorZ
1 (In, B) ‚àº= B[n] = {b ‚ààB : nb = 0}.
There is an exact sequence
0 ‚ÜíZ
¬µn
‚àí‚ÜíZ ‚ÜíIn ‚Üí0,
where ¬µn is multiplication by n. Applying ‚äóB gives exactness of
Tor1(Z, B) ‚ÜíTor1(In, B) ‚ÜíZ ‚äóB
1‚äó¬µn
‚àí‚ÜíZ ‚äóB.
Now Tor1(Z, B) = {0}, because Z is projective. Moreover, 1 ‚äó¬µn is also multiplication
by n, while Z ‚äóB = B. More precisely, Z‚äóis naturally equivalent to the identity functor
on Ab, and so there is a commutative diagram with exact rows
0
 B[n]

 B
œÑB

¬µn
 B
œÑB

0
 Tor1(In, B)
 Z ‚äóB
1‚äó¬µn  Z ‚äóB
By Proposition 8.94, there is an isomorphism B[n] ‚àº= Tor1(In, B).
(ii) We can now compute TorZ
1 (A, B) whenever A and B are Ô¨Ånitely generated abelian
groups. By the fundamental theorem, both A and B are direct sums of cyclic groups. Since
Tor commutes with direct sums, TorZ
1 (A, B) is the direct sum of groups TorZ
1 (C, D), where
C and D are cyclic. We may assume that C and D are Ô¨Ånite, otherwise they are projective
and Tor1 = {0}. This calculation can be completed using part (i) and Exercise 5.6 on
page 267, which says that if D is a cyclic group of Ô¨Ånite order m, then D[n] is a cyclic
group of order d, where d = (m, n) is their gcd.
‚óÄ
In contrast to Ext, Proposition 10.97 can be generalized by replacing sums by direct
limits.
Proposition 10.99.
If {Bi, œïi
j} is a direct system of left R-modules over a directed index
set I, then there is an isomorphism, for all right R-modules A and for all n ‚â•0,
TorR
n

A, lim
‚àí‚ÜíBi
 ‚àº= lim
‚àí‚ÜíTorR
n (A, Bi).
Proof.
The proof is by dimension shifting. The base step is Theorem 8.101, for Tor0(A, )
is naturally equivalent to A‚äó.

866
Homology
Ch. 10
For the inductive step, choose, for each i ‚ààI, a short exact sequence
0 ‚ÜíNi ‚ÜíPi ‚ÜíBi ‚Üí0,
where Pi is projective. Since the index set is directed, Proposition 7.100 says that there is
an exact sequence
0 ‚Üílim
‚àí‚ÜíNi ‚Üílim
‚àí‚ÜíPi ‚Üílim
‚àí‚ÜíBi ‚Üí0.
Now lim
‚àí‚ÜíPi is Ô¨Çat, for every projective module is Ô¨Çat, and a direct limit of Ô¨Çat modules is
Ô¨Çat, by Corollary 8.102. There is a commutative diagram with exact rows:
Tor1(A, lim
‚àí‚ÜíPi)
 Tor1(A, lim
‚àí‚ÜíBi)

‚àÇ
 A ‚äólim
‚àí‚ÜíNi

œÑ

A ‚äólim
‚àí‚ÜíPi
œÉ

lim
‚àí‚ÜíTor1(A, Pi)
 lim
‚àí‚ÜíTor1(A, Bi)
‚Éó‚àÇ
 lim
‚àí‚ÜíA ‚äóNi
 lim
‚àí‚ÜíA ‚äóPi,
where the maps in the bottom row are just the usual induced maps between direct limits,
and the maps œÑ and œÉ are the isomorphisms given by Theorem 8.101. The step n ‚â•2 is
routine.
‚Ä¢
This last proposition generalizes Lemma 8.97, which says that if every Ô¨Ånitely generated
submodule of a module M is Ô¨Çat, then M itself is Ô¨Çat. After all, by Example 7.97(iv), M
is a direct limit, over a directed index set, of its Ô¨Ånitely generated submodules.
When the ring R is noncommutative, A ‚äóR B is an abelian group, but it need not be an
R-module.
Proposition 10.100.
(i) Let r ‚ààZ(R) be a central element, let A be a right R-module, and let B be a left
R-modules. If ¬µr : B ‚ÜíB is multiplication by r, then the induced map
¬µr‚àó: TorR
n (A, B) ‚ÜíTorR
n (A, B)
is also multiplication by r.
(ii) If R is a commutative ring, then TorR
n (A, B) is an R-module.
Proof.
(i) This follows at once from Example 10.47.
(ii) This follows from part (i) if we deÔ¨Åne scalar multiplication by r to be ¬µr‚àó.
‚Ä¢
We are now going to assume that R is a domain, so that the notion of torsion submodule
is deÔ¨Åned, and we shall see why Tor is so called.

Sec. 10.6
Ext and Tor
867
Lemma 10.101.
Let R be a domain, let Q = Frac(R), and let K = Q/R.
(i) If A is a torsion R-module, then TorR
1 (K, A) ‚àº= A.
(ii) For every R-module A, we have Torn(K, A) = {0} for all n ‚â•2.
(iii) If A is a torsion-free R-module, then Tor1(K, A) = {0}.
Proof.
(i) Exactness of 0 ‚ÜíR ‚ÜíQ ‚ÜíK ‚Üí0 gives exactness of
Tor1(Q, A) ‚ÜíTor1(K, A) ‚ÜíR ‚äóA ‚ÜíQ ‚äóA.
Now Q is Ô¨Çat, by Corollary 8.103, and so Tor1(Q, A) = {0}, by Proposition 10.96. The last
term Q ‚äóA = {0} because Q is divisible and A is torsion, by Exercise 9.15 on page 665,
and so the middle map Tor1(K, A) ‚ÜíR ‚äóA is an isomorphism.
(ii) There is an exact sequence
Torn(Q, A) ‚ÜíTorn(K, A) ‚ÜíTorn‚àí1(R, A).
Since n ‚â•2, we have n ‚àí1 ‚â•1, and so both the Ô¨Årst and third Tor's are {0}, because Q
and R are Ô¨Çat. Therefore, exactness gives Torn(K, A) = {0}.
(iii) By Theorem 8.104, there is an injective R-module E containing A as a submodule.
Since A is torsion-free, however, A ‚à©t E = {0}, and so A is imbedded in E/t E. By
Lemma 7.72, injective modules are divisible, and so E is divisible, as is its quotient E/t E.
Now E/t E is a vector space over Q, for it is a torsion-free divisible R-module (Exer-
cise 9.7 on page 664). Let us denote E/t E by V . Since every vector space has a basis, V
is a direct sum of copies of Q. Corollary 8.103 says that Q is Ô¨Çat, and Lemma 8.98 says
that a direct sum of Ô¨Çat modules is Ô¨Çat. We conclude that V is Ô¨Çat.14
Exactness of 0 ‚ÜíA ‚ÜíV ‚ÜíV/A ‚Üí0 gives exactness of
Tor2(K, V/A) ‚ÜíTor1(K, A) ‚ÜíTor1(K, V ).
Now Tor2(K, V/A) = {0}, by part (ii), and Tor1(K, V ) = {0}, because V is Ô¨Çat. We
conclude from exactness that Tor1(K, A) = {0}.
‚Ä¢
The next result shows why Tor is so-called.
Theorem 10.102.
(i) If R is a domain, Q = Frac(R), and K = Q/R, then the functor TorR
1 (K, ) is
naturally equivalent to the torsion functor.
(ii) TorR
1 (K, A) ‚àº= t A for all R-modules A.
14Torsion-free Z-modules are Ô¨Çat, but there exist domains R having torsion-free modules that are not Ô¨Çat. In
fact, domains for which every torsion-free module is Ô¨Çat, called Pr¬®ufer rings, are characterized as those domains
in which every Ô¨Ånitely generated ideal is a projective module.

868
Homology
Ch. 10
Proof.
Exactness of
Tor2(K, A/t A) ‚ÜíTor1(K, t A)
ŒπA
‚àí‚ÜíTor1(K, A) ‚ÜíTor1(K, A/t A).
The Ô¨Årst term is {0}, by Lemma 10.101(ii), and the last term is {0}, by Lemma 10.101(iii).
Therefore, the map ŒπA : Tor1(K, t A) ‚ÜíTor1(K, A) is an isomorphism.
Let f : A ‚ÜíB and let f ‚Ä≤ : t A ‚Üít B be its restriction. The following diagram com-
mutes, because Tor1(K, ) is a functor, and this says that the isomorphisms ŒπA constitute a
natural transformation.
Tor1(K, t A)
ŒπA

f ‚Ä≤
‚àó
Tor1(K, A)
f‚àó

Tor1(K, t B)
ŒπB  Tor1(K, B)
‚Ä¢
There is a construction of TorZ
1 (A, B) by generators and relations. Consider all triples
(a, n, b), where a ‚ààA, b ‚ààB, na = 0, and nb = 0. Then TorZ
1 (A, B) is generated by all
such triples subject to the relations (whenever both sides are deÔ¨Åned):
(a + a‚Ä≤, n, b) = (a, n, b) + (a‚Ä≤, n, b)
(a, n, b + b‚Ä≤) = (a, n, b) + (a, n, b‚Ä≤)
(ma, n, b) = (a, mn, b) = (a, m, nb).
For a proof of this result, and its generalization to TorR
n (A, B) for arbitrary rings R, see
Mac Lane, Homology, pp. 150-159.
The Tor functors are very useful in algebraic topology. The Universal CoefÔ¨Åcients The-
orem gives a formula for the homology groups Hn(X; G) with coefÔ¨Åcients in an abelian
group G.
Theorem (Universal CoefÔ¨Åcients).
For every topological space X and every abelian
group G, there are isomorphisms for all n ‚â•0,
Hn(X; G) ‚àº= Hn(X) ‚äóZ G ‚äïTorZ
1 (Hn‚àí1(X), G).
Proof.
See Rotman, An Introduction to Algebraic Topology, page 261.
‚Ä¢
If we know the homology groups of spaces X and Y, then the K¬®unneth formula gives a
formula for the homology groups of X √ó Y, and this, too, involves Tor in an essential way.
Theorem (K¬®unneth Formula).
For every pair of topological spaces X and Y, there are
isomorphisms for every n ‚â•0,
Hn(X √ó Y) ‚àº=

i
Hi(X) ‚äóZ Hn‚àíi(Y) ‚äï

p
TorZ
1 (Hp(X), Hn‚àí1‚àíp(Y)).
Proof.
See Rotman, An Introduction to Algebraic Topology, page 269
‚Ä¢

Sec. 10.6
Ext and Tor
869
EXERCISES
10.44 Prove the following analog of Theorem 10.45. Let En : RMod ‚ÜíAb be a sequence of
covariant functors, for n ‚â•0, such that
(i) for every short exact sequence 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0, there is a long exact sequence
and natural connecting homomorphisms
¬∑ ¬∑ ¬∑ ‚ÜíEn(A) ‚ÜíEn(B) ‚ÜíEn(C) n
‚àí‚ÜíEn+1(A) ‚Üí¬∑ ¬∑ ¬∑ ;
(ii) there is a left R-module M such that E0 and HomR(M, ) are naturally equivalent;
(iii) En(E) = {0} for all injective modules E and all n ‚â•1.
Prove that En is naturally equivalent to Extn(M, ) for all n ‚â•0.
10.45 Let TORn : RMod ‚ÜíAb be a sequence of covariant functors, for n ‚â•0, such that
(i) for every short exact sequence 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0, there is a long exact sequence
and natural connecting homomorphisms
¬∑ ¬∑ ¬∑ ‚ÜíTORn(A) ‚ÜíTORn(B) ‚ÜíTORn(C) n
‚àí‚ÜíTORn‚àí1(A) ‚Üí¬∑ ¬∑ ¬∑ ;
(ii) there is a left R-module M such that TOR0 and ‚äóR M are naturally equivalent;
(iii) TORn(P) = {0} for all projective modules P and all n ‚â•1.
Prove that TORn is naturally equivalent to Torn( , M) for all n ‚â•0. (There is a similar
result if the Ô¨Årst variable is Ô¨Åxed.)
10.46 Prove that any two split extensions of modules A by C are equivalent.
10.47 Prove that if A is an abelian group with nA = A for some positive integer n, then every
extension 0 ‚ÜíA ‚ÜíE ‚ÜíIn ‚Üí0 splits.
10.48 If A is a torsion abelian group, prove that Ext1(A, Z) ‚àº= Hom(A, S1), where S1 is the circle
group.
10.49 Prove that a left R-module E is injective if and only if Ext1
R(A, E) = {0} for every left
R-module A.
10.50 For any ring R, prove that a left R-module B is injective if and only if Ext1(R/I, B) = {0}
for every left ideal I.
Hint. Use the Baer criterion.
10.51 Prove that an abelian group G is injective if and only if Ext1(Q/Z, G) = {0}.
10.52 Prove that an abelian group G is free abelian if and only if Ext1(G, F) = {0} for every free
abelian group F.15
10.53 If 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 is an exact sequence of right R-modules with both A and C Ô¨Çat,
prove that B is Ô¨Çat.
10.54 If A and B are Ô¨Ånite abelian groups, prove that TorZ
1 (A, B) ‚àº= A ‚äóZ B.
15The question whether Ext1(G, Z) = {0} implies G is free abelian is known as Whitehead's problem. It
turns out that if G countable, then it must be free abelian, but S. Shelah proved that it is undecideable whether
uncountable such G must be free abelian.

870
Homology
Ch. 10
10.55 Let R be a domain, Q = Frac(R), and K = Q/R.
(i) Prove, for every R-module A, that there is an exact sequence
0 ‚Üít A ‚ÜíA ‚ÜíQ ‚äóA ‚ÜíK ‚äóA ‚Üí0.
(ii) Prove that a module A is torsion if and only if Q ‚äóA = {0}.
10.56 Let R be a domain.
(i) If B is a torsion R-module, prove that Torn(A, B) is a torsion R-module for all R-
modules A and for all n ‚â•0.
(ii) For all R-modules A and B, prove that Torn(A, B) is a torsion R-module for all n ‚â•1.
10.57 Let k be a Ô¨Åeld, let R = k[x, y], and let I be the ideal (x, y).
(i) Prove that x ‚äóy ‚àíy ‚äóx ‚ààI ‚äóR I is nonzero.
Hint. Consider (I/I 2) ‚äó(I/I 2).
(ii) Prove that x(x ‚äóy ‚àíy ‚äóx) = 0, and conclude that I ‚äóR I is not torsion-free.
10.7 COHOMOLOGY OF GROUPS
Recall that Proposition 10.30 and Proposition 10.31 say that there is an exact sequence
F3
d3
‚àí‚ÜíF2
d2
‚àí‚ÜíF1
d1
‚àí‚ÜíF0 ‚ÜíZ ‚Üí0,
where F0, F1, F2, and F3 are free Q-modules and Z is viewed as a trivial Q-module. In
light of the calculations in Section 10.3, the following deÔ¨Ånition should now seem reason-
able.
DeÔ¨Ånition.
Let G be a group, let A be a G-module (i.e, a left ZG-module), and let Z be
the integers viewed as a trivial G-module (i.e, gm = m for all g ‚ààG and m ‚ààZ). The
cohomology groups of G are
Hn(G, A) = Extn
ZG(Z, A);
the homology groups of G are
Hn(G, A) = TorZG
n (Z, A).
The history of cohomology of groups is quite interesting. The subject began with the
discovery, by the topologist W. Hurewicz in the 1930's, that if X is a connected aspherical
space (in modern language, if the higher homotopy groups of X are all trivial), then all
the homology and cohomology groups of X are determined by the fundamental group œÄ =
œÄ1(X). This led to the question of whether Hn(X) could be described algebraically in terms
of œÄ. For example, Hurewicz proved that H1(X) ‚àº= œÄ/œÄ‚Ä≤, where œÄ‚Ä≤ is the commutator
subgroup. In 1942, H. Hopf proved that if œÄ has a presentation F/R, where F is free, then
H2(X) ‚àº= (R ‚à©F‚Ä≤)/[F, R], where [F, R] is the subgroup generated by all commutators of

Sec. 10.7
Cohomology of Groups
871
the form f r f ‚àí1r‚àí1 for f ‚ààF and r ‚ààR. These results led S. Eilenberg, S. Mac Lane,
Hopf, H. Freudenthal, and B. Eckmann to create cohomology of groups.
In what follows, we will write HomG instead of HomZG and ‚äóG instead of ‚äóZG. Be-
cause of the special role of the trivial G-module Z, the augmentation
Œµ: ZG ‚ÜíZ,
deÔ¨Åned by
Œµ:

x‚ààG
mxx ‚Üí

x‚ààG
mx,
is important. Recall that we have seen, in Exercise 8.37 on page 573, that Œµ is a surjective
ring homomorphism, and so its kernel, G, is a two-sided ideal in ZG, called the augmen-
tation ideal. Thus, there is an exact sequence
0 ‚ÜíG ‚ÜíZG
Œµ
‚àí‚ÜíZ ‚Üí0.
Proposition 10.103.
Let G be a group with augmentation ideal G. As an abelian group,
G is free abelian with basis G ‚àí1 = {x ‚àí1 : x ‚ààG, x Ã∏= 1}.
Proof.
An element u = 
x mxx ‚ààZG lies in ker Œµ = G if and only if 
x mx = 0.
Therefore, if u ‚ààG, then
u = u ‚àí

x
mx

1 =

x
mx(x ‚àí1).
Thus, G is generated by the nonzero x ‚àí1 for x ‚ààG.
Suppose that 
xÃ∏=1 nx(x ‚àí1) = 0. Then 
xÃ∏=1 nxx ‚àí

xÃ∏=1 nx

1 = 0 in ZG, which,
as an abelian group, is free abelian with basis the elements of G. Hence, nx = 0 for all
x Ã∏= 1. Therefore, the nonzero x ‚àí1 comprise a basis of G.
‚Ä¢
We begin by examining homology groups.
Proposition 10.104.
If A is a G-module, then
H0(G, A) = Z ‚äóG A ‚àº= A/G A.
.
Proof.
By deÔ¨Ånition, H0(G, A) = TorZG
0 (Z, A) = Z ‚äóG A. Applying the right exact
functor ‚äóG A to the exact sequence
0 ‚ÜíG ‚ÜíZG ‚ÜíZ ‚Üí0
gives exactness of the Ô¨Årst row of the following commutative diagram:
G ‚äóG A


ZG ‚äóG A


Z ‚äóG A


0
G A
 A
 A/G A
 0
The two solid vertical arrows are given by u ‚äóa ‚Üíua. By Proposition 8.93, there is an
isomorphism Z ‚äóG A ‚àº= A/G A.
‚Ä¢

872
Homology
Ch. 10
It is easy to see that A/G A is G-trivial; indeed, it is the largest G-trivial quotient of A.
Example 10.105.
Suppose that E is a semidirect product of an abelian group A by a group G. Recall that
[G, A] is the subgroup generated by all commutators of the form [x, a] = xax‚àí1a‚àí1,
where x ‚ààG and a ‚ààA. If we write commutators additively, as we did at the beginning
of this chapter, then
[x, a] = x + a ‚àíx ‚àía = xa ‚àía = (x ‚àí1)a
(recall that G acts on A by conjugation). Therefore, A/G A = A/[G, A] here.
‚óÄ
We are now going to use the independence of the choice of projective resolution to
compute the homology groups of a Ô¨Ånite cyclic group G.
Lemma 10.106.
Let G = ‚ü®x‚ü©be a cyclic group of Ô¨Ånite order k. DeÔ¨Åne elements D and
N in ZG by
D = x ‚àí1
and
N = 1 + x + x2 + ¬∑ ¬∑ ¬∑ + xk‚àí1.
Then the following sequence is a G-free resolution of Z:
¬∑ ¬∑ ¬∑ ‚ÜíZG
N
‚àí‚ÜíZG
D
‚àí‚ÜíZG
N
‚àí‚ÜíZG
D
‚àí‚ÜíZG
Œµ
‚àí‚ÜíZ ‚Üí0,
where Œµ is the augmentation and the other maps are multiplication by N and D, respec-
tively.
Proof.
Obviously, every term ZG is free; moreover, since ZG is commutative, the maps
are G-maps. Now DN = N D = xk ‚àí1 = 0, while if u ‚ààZG, then
ŒµD(u) = Œµ

(x ‚àí1)u

= Œµ(x ‚àí1)Œµ(u) = 0,
because Œµ is a ring map. Thus, we have a complex, and it only remains to prove exactness.
We have already noted that Œµ is surjective. Now ker Œµ = G = im D, by Proposi-
tion 10.103, and so we have exactness at the zeroth step.
Suppose u = k‚àí1
i=0 mi xi ‚ààker D; that is, (x ‚àí1)u = 0. Expanding, and using the fact
that ZG has basis {1, x, x2, . . . , xk‚àí1}, we have
m0 = m1 = ¬∑ ¬∑ ¬∑ = mk‚àí1,
so that u = m0N ‚ààim N, as desired.
Finally, if u = k‚àí1
i=0 mi xi ‚ààker N, then 0 = Œµ(Nu) = Œµ(N)Œµ(u) = kŒµ(u), so that
Œµ(u) = k‚àí1
i=0 mi = 0. Therefore,
u = ‚àíD

m01 + (m0 + m1)x + ¬∑ ¬∑ ¬∑ + (m0 + ¬∑ ¬∑ ¬∑ + mk‚àí1)xk‚àí1
‚ààim D.
‚Ä¢

Sec. 10.7
Cohomology of Groups
873
DeÔ¨Ånition.
If A is a G-module, deÔ¨Åne submodules
A[N] =

a ‚ààA : Na = 0

and
AG =

a ‚ààA : ga = a for all g ‚ààG

.
Theorem 10.107.
If G is a cyclic group of Ô¨Ånite order k and A is a G-module, then
H0(G, A) = A/G A;
H2n‚àí1(G, A) = AG/N A
for all n ‚â•1;
H2n(G, A) = A[N]/G A
for all n ‚â•1.
Proof.
Apply ‚äóG A to the resolution of Z in Lemma 10.106, noting that ZG ‚äóG A ‚àº=
A. The calculation of ker / im is now simple, using im D = G A, which follows from
Proposition 10.103 and the fact that (x ‚àí1) | (xi ‚àí1).
‚Ä¢
Corollary 10.108.
If G is a Ô¨Ånite cyclic group of order k and A is a trivial G-module,
then
H0(G, A) = A;
H2n‚àí1(G, A) = A/k A
for all n ‚â•1;
H2n(G, A) = A[k]
for all n ‚â•1.
In particular,
H0(G, Z) = Z;
H2n‚àí1(G, Z) = Z/kZ
for all n ‚â•1;
H2n(G, Z) = {0}
for all n ‚â•1.
Proof.
Since A is G-trivial, we have AG = A and G A = {0} (for Da = (x ‚àí1)a = 0
because xa = a).
‚Ä¢
We now compute low-dimensional homology groups of not necessarily cyclic groups.
Lemma 10.109.
For any group G, we have
H1(G, Z) ‚àº= G/G2.
Proof.
The long exact sequence arising from
0 ‚ÜíG ‚ÜíZG
Œµ
‚àí‚ÜíZ ‚Üí0
ends with
H1(G, ZG) ‚ÜíH1(G, Z)
‚àÇ
‚àí‚ÜíH0(G, G) ‚ÜíH0(G, ZG)
Œµ‚àó
‚àí‚ÜíH0(G, Z) ‚Üí0.

874
Homology
Ch. 10
Now H1(G, ZG) = {0}, because ZG is projective, so that ‚àÇis an injection. Also,
H0(G, ZG) ‚àº= Z,
by Proposition 10.104. Since Œµ‚àóis surjective, it must be injective as well (if ker Œµ‚àóÃ∏= {0},
then Z/ ker Œµ‚àóis Ô¨Ånite; on the other hand, Z/ ker Œµ‚àó‚àº= im Œµ‚àó= Z, which is torsion-free).
Exactness of the sequence of homology groups (‚àÇis surjective if and only if Œµ‚àóis injective)
now gives ‚àÇa surjection. We conclude that
‚àÇ: H1(G, Z) ‚àº= H0(G, G) ‚àº= G/G2,
by Proposition 10.104.
‚Ä¢
Proposition 10.110.
For any group G, we have
H1(G, Z) ‚àº= G/G‚Ä≤,
where G‚Ä≤ is the commutator subgroup of G.
Proof.
It sufÔ¨Åces to prove that G/G‚Ä≤ ‚àº= G/G2. DeÔ¨Åne Œ∏ : G ‚ÜíG/G2 by
Œ∏ : x ‚Üí(x ‚àí1) + G2.
To see that Œ∏ is a homomorphism, note that
xy ‚àí1 ‚àí(x ‚àí1) ‚àí(y ‚àí1) = (x ‚àí1)(y ‚àí1) ‚ààG2,
so that
Œ∏(xy) = xy ‚àí1 + G2
= (x ‚àí1) + (y ‚àí1) + G2
= x ‚àí1 + G2 + y ‚àí1 + G2
= Œ∏(x) + Œ∏(y).
Since G/G2 is abelian, ker Œ∏ ‚äÜG‚Ä≤, and so Œ∏ induces a homomorphism Œ∏‚Ä≤ : G/G‚Ä≤ ‚ÜíG/G2,
namely, xG‚Ä≤ ‚Üíx ‚àí1 + G2.
We now construct the inverse of Œ∏‚Ä≤. By Proposition 10.103, G is a free abelian group
with basis all x ‚àí1, where x ‚ààG and x Ã∏= 1. It follows that there is a (well-deÔ¨Åned)
homomorphism œï : G ‚ÜíG/G‚Ä≤, given by
œï : x ‚àí1 ‚ÜíxG‚Ä≤.
If G2 ‚äÜker œï, then œï induces a homomorphism G/G2 ‚ÜíG/G‚Ä≤ that, obviously, is the
inverse of Œ∏‚Ä≤, and this will complete the proof.

Sec. 10.7
Cohomology of Groups
875
If u ‚ààG2, then
u =

xÃ∏=1
mx(x ‚àí1)

yÃ∏=1
ny(y ‚àí1)

=

x,y
mxny(x ‚àí1)(y ‚àí1)
=

x,y
mxny

(xy ‚àí1) ‚àí(x ‚àí1) ‚àí(y ‚àí1)

.
Therefore, œï(u) = 
x,y(xyx‚àí1y‚àí1)mxnyG‚Ä≤ = G‚Ä≤, and so u ‚ààker œï, as desired.
‚Ä¢
The group H2(G, Z) is useful; it is called the Schur multiplier of G. For example,
suppose that G = F/R, where F is a free group; that is, we have a presentation of a group
G. Then Hopf's formula is
H2(G, Z) ‚àº= (R ‚à©F)/[F, R]
(see Rotman, An Introduction to Homological Algebra, page 274). It follows that the group
(R ‚à©F)/[F, R] depends only on G and not upon the choice of presentation of G.
DeÔ¨Ånition.
An exact sequence 0 ‚ÜíA ‚ÜíE ‚ÜíG ‚Üí1 is a central extension of a group
G if A ‚â§Z(E). A universal central extension of G is a central extension 0 ‚ÜíM ‚Üí
U ‚ÜíG ‚Üí1 for which there always exists a commutative diagram
0
 A


E


G
1G

 1
0
 M
 U
 G
 1
Theorem.
If G is a Ô¨Ånite group, then G has a universal central extension if and only
if G = G‚Ä≤, in which case M ‚àº= H2(G, Z). In particular, every Ô¨Ånite simple group has a
universal central extension.
Proof.
See Milnor, Introduction to Algebraic K-Theory, pages 43-46.
‚Ä¢
This theorem is used to construct "covers" of simple groups.
We now consider cohomology groups.
Proposition 10.111.
Let G be a group, let A be a G-module, and let Z be viewed as a
trivial G-module. Then
H0(G, A) = HomG(Z, A) ‚àº= AG.
Proof.
By deÔ¨Ånition,
H0(G, A) = Ext0
ZG(Z, A) = HomG(Z, A).
DeÔ¨Åne œÑA : HomG(Z, A) ‚ÜíAG by f ‚Üíf (1). Note that f (1) ‚ààAG: If g ‚ààG, then
g f (1) = f (g ¬∑1) (because f is a G-map), and g ¬∑1 = 1 (because Z is G-trivial); therefore,
g f (1) = f (1), and f (1) ‚ààAG. That œÑA is an isomorphism is a routine calculation.
‚Ä¢

876
Homology
Ch. 10
It follows that H0(G, A) is the largest G-trivial submodule of A.
Theorem 10.112.
Let G = ‚ü®œÉ‚ü©be a cyclic group of Ô¨Ånite order k, and let A be a G-
module. If N = k‚àí1
i=0 œÉ i and D = œÉ ‚àí1, then
H0(G, A) = AG;
H2n‚àí1(G, A) = ker N/(œÉ ‚àí1)A
f or all n ‚â•1;
H2n(G, A) = AG/N A
f or all n ‚â•1.
Proof.
Apply the contravariant HomG( , A) to the resolution of Z in Lemma 10.106,
noting that HomG(ZG, A) ‚àº= A. The calculation of ker / im is now as given in the state-
ment.
‚Ä¢
Note that Proposition 10.103 gives im D = G A.
Corollary 10.113.
If G is a cyclic group of Ô¨Ånite order k and A is a trivial G-module,
then
H0(G, A) = A;
H2n‚àí1(G, A) = A[k]
f or all n ‚â•1;
H2n(G, A) = A/k A
f or all n ‚â•1.
In particular,
H0(G, Z) = Z;
H2n‚àí1(G, Z) = {0}
for all n ‚â•1;
H2n(G, Z) = Z/kZ
for all n ‚â•1.
Remark.
A Ô¨Ånite group G for which there exists a nonzero integer d such that
Hn(G, A) ‚àº= Hn+d(G, A),
for all n ‚â•1 and all G-modules A, is said to have periodic cohomology. It can be proved
that a group G has periodic cohomology if and only if its Sylow p-subgroups are cyclic, for
all odd primes p, while its Sylow 2-subgroups are either cyclic or generalized quaternion
(see Adem-Milgram, Cohomology of Finite Groups, p. 148). For example, G = SL(2, 5)
has periodic cohomology: it is a group of order 120 = 8 ¬∑ 3 ¬∑ 5, so its Sylow 3-subgroups
and its Sylow 5-subgroups are cyclic, having prime order, while its Sylow 2-subgroups are
isomorphic to the quaternions.
‚óÄ
We can interpret H1(G, A) and H2(G, A), where G is any not necessarily cyclic group,
in terms of derivations and extensions if we can show that the formulas in Section 10.3 do,
in fact, arise from a projective resolution of Z. Alas, we need a technical interlude.

Sec. 10.7
Cohomology of Groups
877
DeÔ¨Ånition.
If G is a group, deÔ¨Åne B0(G) to be the free G-module on the single generator
[ ] (hence, B0(G) ‚àº= ZG) and, for n ‚â•1, deÔ¨Åne Bn(G) to be the free G-module with basis
all symbols [x1 | x2 | ¬∑ ¬∑ ¬∑ | xn], where xi ‚ààG. DeÔ¨Åne Œµ: B0(G) ‚ÜíZ by Œµ([ ]) = 1 and,
for n ‚â•1, deÔ¨Åne dn : Bn(G) ‚ÜíBn‚àí1(G) by
dn : [x1 | ¬∑ ¬∑ ¬∑ | xn] ‚Üíx1[x2 | ¬∑ ¬∑ ¬∑ | xn]
+
n‚àí1

i=1
(‚àí1)i[x1 | ¬∑ ¬∑ ¬∑ | xi xi+1 | ¬∑ ¬∑ ¬∑ | xn]
+ (‚àí1)n[x1 | ¬∑ ¬∑ ¬∑ | xn‚àí1].
The bar resolution is the sequence
B‚Ä¢(G) : ¬∑ ¬∑ ¬∑ ‚ÜíB2(G)
d2
‚àí‚ÜíB1(G)
d1
‚àí‚ÜíB0(G)
Œµ
‚àí‚ÜíZ ‚Üí0.
Let us look at the low-dimensional part of the bar resolution.
d1 : [x] ‚Üíx[ ];
d2 : [x | y] ‚Üíx[y] ‚àí[xy] + [x];
d3 : [x | y | z] ‚Üíx[y | z] ‚àí[xy | z] + [x | yz] ‚àí[x | y]
These are the formulas that arose in the earlier sections, but without the added conditions
[x | 1] = 0 = [1 | y] and [1] = 0. In fact, there are two bar resolutions; the bar resolution
just deÔ¨Åned, and another we shall soon see, called the normalized bar resolution.
The bar resolution is a free resolution of Z, although it is not a routine calculation to
see this; we prove that it is a resolution by comparing B‚Ä¢(G) to a resolution familiar to
algebraic topologists.
DeÔ¨Ånition.
If G is a group, let Pn(G) be the free abelian group with basis all (n + 1)-
tuples of elements of G; make Pn(G) into a G-module by deÔ¨Åning
x(x0, x1, . . . , xn) = (xx0, xx1, . . . , xxn).
DeÔ¨Åne ‚àÇn : Pn(G) ‚ÜíPn‚àí1(G), whenever n ‚â•1, by
‚àÇn : (x0, x1, . . . , xn) ‚Üí
n

i=0
(‚àí1)i(x0, . . . ,xi, . . . , xn),
where xi means that xi has been deleted. P‚Ä¢(G) is called the homogenous resolution of
Z.
Note that P0(G) is the free abelian group with basis all (y), for y ‚ààG, made into a
G-module by x(y) = (xy). In other words, P0(G) = ZG.
The proof that P‚Ä¢(G) is a projective resolution of Z will be broken into two parts.

878
Homology
Ch. 10
Lemma 10.114.
The sequence
P‚Ä¢(G) : ¬∑ ¬∑ ¬∑ ‚ÜíP2(G)
‚àÇ2
‚àí‚ÜíP1(G)
‚àÇ1
‚àí‚ÜíP0(G)
Œµ
‚àí‚ÜíZ ‚Üí0,
where Œµ is the augmentation, is a complex.
Proof.
It sufÔ¨Åces to prove that ‚àÇn‚àí1‚àÇn(x0, x1, . . . , xn) = 0. Now
‚àÇn‚àí1‚àÇn(x0, x1, . . . , xn) =
n

i=0
(‚àí1)i‚àÇn‚àí1(x0, . . . ,xi, . . . , xn)
=
n

i=0
(‚àí1)i
j<i
(‚àí1) j(x0, . . . ,x j, . . . ,xi, . . . , xn)

+
n

i=0
(‚àí1)i
j>i
(‚àí1) j‚àí1(x0, . . . ,xi, . . . ,x j, . . . , xn)

.
In the last equation, the Ô¨Årst summation has inner sign (‚àí1) j, because j < i and so x j
is still in the jth position after the deletion of xi from the original n-tuple. In the second
summation, however, the inner sign is (‚àí1) j‚àí1, because i < j and so x j is in position
j ‚àí1 after deletion of the earlier xi. Thus, ‚àÇn‚àí1‚àÇn(x0, x1, . . . , xn) is a sum of (n ‚àí2)-
tuples (x0, . . . ,xi, . . . ,x j, . . . , xn) with i < j, each of which occurs twice: once upon
deleting xi by ‚àÇn and then deleting x j by ‚àÇn‚àí1; a second time upon deleting x j by ‚àÇn and
then deleting xi by ‚àÇn‚àí1. In the Ô¨Årst case, the sign of the (n ‚àí2)-tuple is (‚àí1)i+ j‚àí1; in
the second case, its sign is (‚àí1)i+ j. Therefore, the (n ‚àí2)-tuples cancel in pairs, and
‚àÇn‚àí1‚àÇn = 0.
‚Ä¢
Proposition 10.115.
The complex
P‚Ä¢(G) : ¬∑ ¬∑ ¬∑ ‚ÜíP2(G)
‚àÇ2
‚àí‚ÜíP1(G)
‚àÇ1
‚àí‚ÜíP0(G)
‚àÇ0
‚àí‚ÜíZ ‚Üí0,
where ‚àÇ0 = Œµ is the augmentation, is a G-free resolution of Z.
Proof.
We let the reader prove that Pn(G) is a free G-module with basis all symbols of
the form (1, x1, . . . , xn).
To prove exactness of P‚Ä¢(G), it sufÔ¨Åces, by Proposition 10.40, to construct a contracting
homotopy; that is, maps
¬∑ ¬∑ ¬∑ ‚ÜêP2(G)
s1
‚Üê‚àíP1(G)
s0
‚Üê‚àíP0(G)
s‚àí1
‚Üê‚àíZ
with Œµs‚àí1 = 1Z and
‚àÇn+1sn + sn‚àí1‚àÇn = 1Pn(G),
for all n ‚â•0.

Sec. 10.7
Cohomology of Groups
879
DeÔ¨Åne s‚àí1 : Z ‚ÜíP0(G) by m ‚Üím(1), where the 1 in the parentheses is the identity
element of the group G, and, for n ‚â•0, deÔ¨Åne sn : Pn(G) ‚ÜíPn+1(G) by
sn : (x0, x1, . . . , xn) ‚Üí(1, x0, x1, . . . , xn).
These maps sn are only Z-maps, but Exercise 10.32 on page 829 says that this sufÔ¨Åces to
prove exactness. Here are the computations.
Œµs‚àí1(1) = Œµ

(1)

= 1
If n ‚â•0, then
‚àÇn+1sn(x0, . . . , xn) = ‚àÇn+1(1, x0, . . . , xn)
= (x0, . . . , xn) +
n

i=0
(‚àí1)i+1(1, x0, . . . ,xi, . . . , xn)
[the range of summation has been rewritten because xi sits in the (i + 1)st position in
(1, x0, . . . , xn)]. On the other hand,
sn‚àí1‚àÇn(x0, . . . , xn) = sn‚àí1
n

j=0
(‚àí1) j(x0, . . . ,x j, . . . , xn)
=
n

j=0
(‚àí1) j(1, x0, . . . ,x j, . . . , xn).
It follows that

‚àÇn+1sn + sn‚àí1‚àÇn)

(x0, . . . , xn) = (x0, . . . , xn).
‚Ä¢
Proposition 10.116.
The bar resolution B‚Ä¢(G) is a G-free resolution of Z.
Proof.
For each n ‚â•0, deÔ¨Åne œÑn : Pn(G) ‚ÜíBn(G) by
œÑn : (x0, . . . , xn) ‚Üíx0[x‚àí1
0 x1 | x‚àí1
1 x2 | ¬∑ ¬∑ ¬∑ | x‚àí1
n‚àí1xn],
and deÔ¨Åne œÉn : Bn(G) ‚ÜíPn(G) by
œÉn : [x1 | ¬∑ ¬∑ ¬∑ | xn] ‚Üí(1, x1, x1x2, x1x2x3, . . . , x1x2 ¬∑ ¬∑ ¬∑ xn).
It is routine to check that œÑn and œÉn are inverse, and so each œÑn is an isomorphism.
The reader can also check that œÑ : P‚Ä¢(G) ‚ÜíB‚Ä¢(G) is a chain map; that is, the following
diagram commutes:
Pn(G)
œÑn

‚àÇn

Bn(G)
dn

Pn‚àí1(G)
œÑn‚àí1  Bn‚àí1(G)
Finally, Exercise 10.22 on page 827 shows that both complexes have the same homology
groups. By Proposition 10.115, the complex P‚Ä¢(G) is an exact sequence, so that all its
homology groups are {0}. It follows that all the homology groups of B‚Ä¢(G) are {0}, and so
it, too, is an exact sequence.
‚Ä¢

880
Homology
Ch. 10
DeÔ¨Ånition.
DeÔ¨Åne
[x1 | ¬∑ ¬∑ ¬∑ | xn]‚àó=

[x1 | ¬∑ ¬∑ ¬∑ | xn]
if all xi Ã∏= 1;
0
if some xi = 1.
The normalized bar resolution, B‚àó
‚Ä¢(G), is the sequence
B‚àó
‚Ä¢(G) : ¬∑ ¬∑ ¬∑ ‚ÜíB‚àó
2(G)
d2
‚àí‚ÜíB‚àó
1(G)
d1
‚àí‚ÜíB‚àó
0(G)
Œµ
‚àí‚ÜíZ ‚Üí0,
where B‚àó
n(G) is the free G-module with basis all nonzero [x1 | ¬∑ ¬∑ ¬∑ | xn]‚àó, and the maps
dn have the same formula as the maps dn in the bar resolution (except that the symbols
[x1 | ¬∑ ¬∑ ¬∑ | xn] now occur as [x1 | ¬∑ ¬∑ ¬∑ | xn]‚àó).
Since we are making some of the basis elements 0, it is not obvious that the normalized
bar resolution B‚àó
‚Ä¢(G) is a complex, let alone a resolution of Z.
Theorem 10.117.
The normalized bar resolution B‚àó
‚Ä¢(G) is a G-free resolution of Z.
Proof.
We begin by constructing a contracting homotopy
¬∑ ¬∑ ¬∑ ‚ÜêB‚àó
2(G)
t1
‚Üê‚àíB‚àó
1(G)
t0
‚Üê‚àíB‚àó
0(G)
t‚àí1
‚Üê‚àíZ,
where each tn is a Z-map. DeÔ¨Åne t‚àí1 : Z ‚ÜíB‚àó
0(G) by t‚àí1 : m ‚Üím[ ]. Note that B‚àó
n(G)
is a free G-module with basis all nonzero [x1 | ¬∑ ¬∑ ¬∑ | xn]‚àó; hence, it is a direct sum of
copies of ZG. Since ZG is a free abelian group, B‚àó
n(G) is also a free abelian group; the
reader may check that a basis of B‚àó
n(G), as a free abelian group, consists of all nonzero
x[x1 | ¬∑ ¬∑ ¬∑ | xn]‚àó. To deÔ¨Åne tn for n ‚â•0, we take advantage of the fact that tn need only be
a Z-map, by giving its values on these Z-basis elements (and freeness allows us to choose
these values without restrictions). Thus, for n ‚â•0, deÔ¨Åne tn : B‚àó
n(G) ‚ÜíB‚àó
n+1(G) by
tn : x[x1 | ¬∑ ¬∑ ¬∑ | xn]‚àó‚Üí[x | x1 | ¬∑ ¬∑ ¬∑ | xn]‚àó.
That we have constructed a contracting homotopy is routine; the reader may check that
Œµt‚àí1 = 1Z and, for n ‚â•0, that
dn+1tn + tn‚àí1dn = 1B‚àón (G).
The proof will be complete once we show that B‚àó
‚Ä¢(G) is a complex. Since B‚àó
n+1(G) is
generated, as a G-module, by im tn, it sufÔ¨Åces to show that dndn+1 = 0 on this subgroup.
We now prove, by induction on n ‚â•‚àí1, that dndn+1tn = 0. The base step is true, for
Œµ = t‚àí1 and 0 = Œµd1 = t‚àí1d1. For the inductive step, we use the identities in the deÔ¨Ånition
of contracting homotopy and the inductive hypothesis dn‚àí1dn = 0:
dndn+1tn = dn(1 ‚àítn‚àí1dn)
= dn ‚àídntn‚àí1dn
= dn ‚àí(1 ‚àítn‚àí2dn‚àí1)dn
= dn ‚àídn ‚àítn‚àí2dn‚àí1dn
= 0.
‚Ä¢

Sec. 10.7
Cohomology of Groups
881
We can now interpret H1(G, A) and H2(G, A).
Corollary 10.118.
For every group G and every G-module A, the groups H1(G, A) and
H2(G, A) constructed in Section 10.3 coincide with the cohomology groups.
Proof.
We have proved that factor sets, coboundaries, derivations, and principal deriva-
tions do, in fact, arise from a projective resolution of Z.
‚Ä¢
Proposition 10.119.
If G is a Ô¨Ånite group of order m, then mHn(G, A) = {0} for all
n ‚â•1 and all G-modules A.
Proof.
Sum the cocycle formula, as in the proof of Theorem 10.21.
‚Ä¢
Corollary 10.120.
If G is a Ô¨Ånite group and A is a Ô¨Ånitely generated G-module, then
Hn(G, A) are Ô¨Ånite for all n ‚â•0.
Proof.
Hn(G, A) is a Ô¨Ånitely generated abelian group (because A is Ô¨Ånitely generated)
of Ô¨Ånite exponent.
‚Ä¢
Both Proposition 10.119 and its corollary are true for homology groups as well.
There are several aspects of the cohomology of groups that we have not mentioned.
Aside from being a useful tool within group theory itself, these groups also form a link with
algebraic topology. For every group G, there exists a topological space K(G, 1), called an
Eilenberg-Mac Lane space, whose fundamental group is G and whose cohomology groups
coincide with the algebraically deÔ¨Åned cohomology groups.16 There is, in fact, a deep
connection between group theory and algebraic topology, of which this is a Ô¨Årst sign.
An important property of the cohomology of groups is the relation between the co-
homology of a group and the cohomology of its subgroups and its quotient groups. If
œï : S ‚ÜíG is a homomorphism, every G-module A becomes an S-module if we deÔ¨Åne
sa = œï(s)a for all s ‚ààS and a ‚ààA. What is the connection between Hn(S, A) and
Hn(G, A)? What is the connection between Hn(S, A) and Hn(G, A)? [There is also a
connection between homology groups and cohomology groups: Hn(G, A)‚àó‚àº= Hn(G, A‚àó),
where A‚àó= HomZ(A, Q/Z).]
There are three standard maps, which we will deÔ¨Åne in terms of the bar resolution. The
Ô¨Årst is restriction. If S is a subgroup of a group G, then every function f : Bn(G) ‚ÜíA
is deÔ¨Åned on all [x1 | ¬∑ ¬∑ ¬∑ | xn] with xi ‚ààG; of course, f is deÔ¨Åned on all n-tuples of
the form [s1 | ¬∑ ¬∑ ¬∑ | sn] with si ‚ààS ‚äÜG, so that its restriction, which we denote by f |S,
maps Bn(S) ‚ÜíA. If f is an n-cocycle, let us write cls f to denote its cohomology class:
cls f = f + im dn+1. Then
Res: Hn(G, A) ‚ÜíHn(S, A)
is deÔ¨Åned by Res(cls f ) = cls( f |S). One result is that if G is a Ô¨Ånite group, Sp is a
Sylow p-subgroup, and n ‚â•1, then Res: Hn(G, A) ‚ÜíHn(Sp, A) is injective on the
16Because of this topological connection, many authors use the notation Hn(œÄ, Z) to denote cohomology
groups, for œÄ1 is the standard notation for the fundamental group.

882
Homology
Ch. 10
p-primary component of Hn(G, A); thus, the cohomology of G is strongly inÔ¨Çuenced by
the cohomology of its Sylow subgroups.
If S ‚â§G, there is a map
Cor: Hn(S, A) ‚ÜíHn(G, A)
in the reverse direction, called corestriction, which is deÔ¨Åned when S has Ô¨Ånite index in
G. We Ô¨Årst deÔ¨Åne Cor in dimension 0; that is, Cor0 : AS ‚ÜíAG, by a ‚Üí
t‚ààT ta, where
T is a left transversal of S in G (of course, we must check that Cor0 is a homomorphism
that is independent of the choice of transversal). There is a standard way of extending a
map in dimension 0 to maps in higher dimensions (essentially by dimension shifting), and
if [G : S] = m, then
Corn ‚ó¶Resn : Hn(G, A) ‚ÜíHn(G, A) = m;
that is, the composite is multiplication by m. Similarly, in homology, the map
Cor0 : A/G A ‚ÜíA/S A,
deÔ¨Åned by a + G A ‚Üí
t‚ààT t‚àí1a + S A, extends to maps in higher dimensions. When
n = 1 and A = Z, we have Cor1 : H1(G, Z) ‚ÜíH1(S, Z); that is, Cor1 : G/G‚Ä≤ ‚ÜíS/S‚Ä≤.
There is such a homomorphism well known to group theorists, called the transfer VG‚ÜíS,
and it turns out that Cor1 = VG‚ÜíS.
The third standard map is called inÔ¨Çation. Suppose that N is a normal subgroup of a
group G. If A is a G-module, then AN is a G/N-module if we deÔ¨Åne (gN)a = ga for
a ‚ààAN [if gN = hN, then h = gx for some x ‚ààN, and so ha = (gx)a = g(xa) = ga,
because xa = a]. DeÔ¨Åne
Inf: Hn(G/N, AN) ‚ÜíHn(G, A)
by cls f ‚Üícls( f #), where
f # : [g1 | ¬∑ ¬∑ ¬∑ | gn] ‚Üíf [g1N | ¬∑ ¬∑ ¬∑ | gn N].
A useful result here is the Ô¨Åve term exact sequence: If N ‚úÅG and A is a G-module,
there is an exact sequence of abelian groups:
0 ‚ÜíH1(G/N, AN)
Inf
‚àí‚ÜíH1(G, A)
Res
‚àí‚ÜíH1(N, A)G/N
‚àí‚ÜíH2(G/N, AN) ‚àí‚ÜíH2(G, A)
(there is a version of this sequence in homology as well). For an excellent discussion of
these ideas, we refer the reader to Serre, Corps Locaux, pp. 135-138.
We can force cohomology groups to be a graded ring by deÔ¨Åning cup product on
H‚Ä¢(G, R) = 
n‚â•0 Hn(G, R), where R is any commutative ring (see Evens, The Co-
homology of Groups), and this added structure has important applications.
We now consider the cohomology of free groups.

Sec. 10.7
Cohomology of Groups
883
Lemma 10.121.
If G is a free group with basis X, then its augmentation ideal G is a free
G-module with basis
X ‚àí1 = {x ‚àí1 : x ‚ààX}.
Proof.
We show Ô¨Årst that G is generated by all X ‚àí1. The identities
xy ‚àí1 = (x ‚àí1) + x(y ‚àí1)
and
x‚àí1 ‚àí1 = ‚àíx‚àí1(x ‚àí1)
show that if w is any word in X, then w ‚àí1 can be written as a G-linear combination of
X ‚àí1.
To show that G is a free G-module with basis X ‚àí1, it now sufÔ¨Åces to show that the
following diagram can be completed:
G


X ‚àí1

œï
 A,
where A is any G-module and œï is any function (uniqueness of such a map  follows from
X ‚àí1 generating G). Thus, we are seeking  ‚ààHomG(G, A). By Exercise 10.59 on
page 886, we have HomG(G, A) ‚àº= Der(G, A) via f : x ‚Üíf (x ‚àí1), where f ‚ààG ‚ÜíA,
and so we seek a derivation.
Consider the (necessarily split) extension 0 ‚ÜíA ‚ÜíE ‚ÜíG ‚Üí1, so that E consists
of all ordered pairs (g, a) ‚ààG √ó A. The given function œï : X ‚àí1 ‚ÜíA deÔ¨Ånes a lifting ‚Ñì
of the generating set X of G, namely,
‚Ñì(x) = (œï(x ‚àí1), x).
Since G is free with basis X, the function ‚Ñì: X ‚ÜíE extends to a homomorphism L : G ‚Üí
E. We claim, for every g ‚ààG, that L(g) = (d(g), g), where d : G ‚ÜíA. Each g ‚ààG has
a unique expression as a reduced word g = xe1
1 ¬∑ ¬∑ ¬∑ xen
n , where xi ‚ààX and ei = ¬±1. We
prove the claim by induction on n ‚â•1. The base step is clear, while
L(g) = L(xe1
1 ¬∑ ¬∑ ¬∑ xen
n )
= L(xe1
1 ) ¬∑ ¬∑ ¬∑ L(xen
n )
= (œï(x1 ‚àí1), x1)e1 ¬∑ ¬∑ ¬∑ (œï(xn ‚àí1), xn)en
= (d(g), g),
and so the Ô¨Årst coordinate d(g) lies in A.
Exercise 10.59 on page 886 now says that there is a homomorphism : G ‚ÜíA deÔ¨Åned
by (g ‚àí1) = d(g) for all g ‚ààG. In particular, (x ‚àí1) = d(x) = œï(x ‚àí1), so that 
does extend œï.
‚Ä¢

884
Homology
Ch. 10
Theorem 10.122.
If G is a free group, then Hn(G, A) = {0} for all n > 1 and all
G-modules A.
Proof.
The sequence 0 ‚ÜíG ‚ÜíZG ‚ÜíZ ‚Üí0 is a free resolution of Z because G is now
a free G-module. Thus, the only nonzero terms in the deleted resolution occur in positions
0 and 1, and so all cohomology groups vanish for n > 1.
‚Ä¢
We are now going to state an interesting result (the Stallings-Swan theorem), which
was discovered using homomological methods but which does not mention homology in
its statement.
If G is a group and S ‚â§G is a subgroup, then every G-module A can be viewed as an
S-module, for ZS is a subring of ZG.
DeÔ¨Ånition.
A group G has cohomological dimension ‚â§n, in symbols, cd(G) ‚â§n, if
Hn+1(S, A) = {0}
for all G-modules A and every subgroup S of G. We write cd(G) = ‚àûif no such integer
n exists.
We say that cd(G) = n if cd(G) ‚â§n but it is not true that cd(G) ‚â§n ‚àí1.
Example 10.123.
(i) If G = {1}, then cd(G) = 0; this follows from Theorem 10.112 because G is a cyclic
group of order 1.
(ii) If G is a Ô¨Ånite cyclic group of order k > 1, then cd(G) = ‚àû, as we see from Corol-
lary 10.113 with A = Z.
(iii) If G Ã∏= {1} is a free group, then Theorem 10.122 shows that cd(G) = 1, for every
subgroup of a free group is free.
(iv) If cd(G) < ‚àû, then G must be torsion-free; otherwise, G has a subgroup S that is
cyclic of Ô¨Ånite order k > 1, and Hn(S, Z) Ã∏= 0 for all even n.
(v) It is known that if G is a free abelian group of Ô¨Ånite rank n, then cd(G) = n.
‚óÄ
Proposition 10.124 (Shapiro's Lemma).
Let G be a group and let S ‚â§G be a sub-
group. If A is a ZS-module, then for all n ‚â•0,
Hn(S, A) ‚àº= Hn(G, HomZS(ZG, A)).
Proof.
Let ¬∑ ¬∑ ¬∑ ‚ÜíP1 ‚ÜíP0 ‚ÜíZ ‚Üí0 be a ZG-free resolution.
If we denote
HomZS(ZG, A)) by A‚àó, then
Hn(G, A‚àó) = Hn(HomZG(P‚Ä¢, A‚àó)).

Sec. 10.7
Cohomology of Groups
885
By the adjoint isomorphism,
HomZG(Pi, A‚àó) = HomZG(Pi, HomZS(ZG, A))
‚àº= HomZS(Pi ‚äóZG ZG, A)
‚àº= HomZS(Pi, A).
But (the proof of) Lemma 8.141(i) shows that ZG is a free ZS-module, and so the free
ZG-modules Pi are also free ZS-modules. It follows that we may regard P‚Ä¢ as a ZS-free
resolution of Z, and there is an isomorphism of complexes:
HomZS(P‚Ä¢, A) ‚àº= HomZG(P‚Ä¢, A‚àó).
Hence, their homology groups are isomorphic; that is, Hn(S, A) ‚àº= Hn(G, A‚àó).
‚Ä¢
Corollary 10.125.
If G is a group and S ‚â§G is a subgroup, then
cd(S) ‚â§cd(G).
Proof.
We may assume that cd(G) = n < ‚àû. If m > n and there is a ZS-module A with
Hm(S, A) Ã∏= {0}, then Shapiro's lemma gives Hm(G, HomZS(ZG, A)) ‚àº= Hm(S, A) Ã∏=
{0}, and this contradicts cd(G) = n.
‚Ä¢
Corollary 10.126.
A group G of Ô¨Ånite cohomological dimension has no elements (other
than 1) of Ô¨Ånite order.
Proof.
This follows at once from Example 10.123(ii) and the preceding corollary.
‚Ä¢
Are there groups G with cd(G) = 1 that are not free? In 1970, J. Stallings proved the
following nice theorem (F2G denotes the group algebra over F2).
Theorem.
If G is a Ô¨Ånitely presented group for which H1(G, F2G) has more than 2
elements, then G is a free product, G = H ‚àóK, where H Ã∏= {1} and K Ã∏= {1} (free product
is the coproduct in Groups).
As a consequence, he proves the following results.
Corollary.
If G is a Ô¨Ånitely generated group with cd(G) = 1, then G is free.
Corollary.
If G is a torsion-free Ô¨Ånitely generated group having a free subgroup of Ô¨Ånite
index, then G is free.
R. G. Swan showed that both corollaries remain true if we remove the hypothesis that
G be Ô¨Ånitely generated.
Theorem (Stallings-Swan).
A torsion-free group having a free subgroup of Ô¨Ånite index
must be free.

886
Homology
Ch. 10
Corollary 10.127 (Nielsen-Schreier).
Every subgroup S of a free group F is itself free.
Proof.
By Corollary 10.125, we have cd(S) ‚â§1, and so the result follows from the
theorem of Stallings and Swan.
‚Ä¢
We refer the reader to D. E. Cohen, "Groups of Cohomological Dimension 1," Lecture
Notes in Mathematics, Vol. 245, Springer-Verlag, New York, 1972, for proofs of these
theorems.
EXERCISES
10.58
(i) Prove that the isomorphisms in Proposition 10.104 constitute a natural equivalence
Z‚äóG to A ‚ÜíA/G A.
(ii) Prove that the isomorphisms in Proposition 10.111 constitute a natural equivalence
HomG(Z, ) to A ‚ÜíAG.
10.59 For a Ô¨Åxed group G, prove that the functors HomG(G, ) and Der(G, ) are naturally equiva-
lent.
Hint. If f : G ‚ÜíA is a homomorphism, then d f : x ‚Üíf (x ‚àí1) is a derivation.
10.60
(i) If G is a Ô¨Ånite cyclic group and 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 is an exact sequence of
G-modules, prove that there is an exact hexagon; that is, kernel = image at each vertex
of the diagram
H0(G, A)
 H0(G, B)
*%
%
%
%
%
%
%
%
%
%
H1(G, C)
3-
-
-
-
-
-
-
-
-
-
H0(G, C)
+----------
H1(G, B)
4%%%%%%%%%%
H1(G, A)

We remark that this exercise is a key lemma in class Ô¨Åeld theory.
(ii) If G is a Ô¨Ånite cyclic group and A is a G-module, deÔ¨Åne the Herbrand quotient by
h(A) = |H0(G, A)|/|H1(G, A)|
[h(A) is deÔ¨Åned only when both H0(G, A) and H1(G, A) are Ô¨Ånite].
Let 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0 be an exact sequence of G-modules. Prove that if the
Herbrand quotient is deÔ¨Åned for two of the modules A, B, C, then it is deÔ¨Åned for the
third one, and
h(B) = h(A)h(C).
10.61 If G is a group, prove that
Pn(G) ‚àº=
n+1
C
1
ZG,

Sec. 10.8
Crossed Products
887
where Pn(G) is the nth term in the homogeneous resolution P‚Ä¢(G) and
n
C
1
ZG = ZG ‚äóZ ZG ‚äóZ ¬∑ ¬∑ ¬∑ ‚äóZ ZG,
the tensor product over Z of ZG with itself n times.
10.62 If G is a Ô¨Ånite cyclic group, prove, for all G-modules A and for all n ‚â•1, that Hn(G, A) ‚àº=
Hn+1(G, A).
10.63 Let G be a group.
(i) Show, for any abelian group A, that A‚àó= HomZ(ZG, A) is a left ZG-module. We call
A‚àóa coinduced module.
Hint. If œï : ZG ‚ÜíA and g ‚ààG, deÔ¨Åne gœï by x ‚Üígœï(g‚àí1x).
(ii) For any left ZG-module B, prove that HomZG(B, A‚àó) ‚àº= HomZ(B, A).
Hint. Use the adjoint isomorphism, Theorem 8.99.
(iii) If A‚àóis a coinduced module, prove that Hn(G, A‚àó) = {0} for all n ‚â•1.
10.64 If G is a group and A is an abelian group, call the ZG-module A‚àóZG ‚äóZ A an induced
module. Prove that Hn(G, A‚àó) = {0} for all n ‚â•1.
10.8 CROSSED PRODUCTS
This section is essentially descriptive, showing how cohomology groups are used to study
division rings. Let us begin with a return to Galois theory.
Theorem 10.128.
Let E/k be a Galois extension with Galois group G = Gal(E/k). The
multiplicative group E√ó is a kG-module, and
H1(G, E√ó) = {0}.
Proof.
If c: G ‚ÜíE√ó is a 1-cocycle, denote c(œÉ) by cœÉ. In multiplicative notation, the
cocycle condition is the identity œÉ(cœÑ)c‚àí1
œÉœÑ cœÉ = 1 for all œÉ, œÑ ‚ààG; that is,
œÉ(cœÑ) = cœÉœÑc‚àí1
œÉ .
(1)
For e ‚ààE√ó, consider
b =

œÑ‚ààG
cœÑœÑ(e).
By independence of characters, Proposition 4.30, there is some e ‚ààE√ó with b Ã∏= 0. For

888
Homology
Ch. 10
such an element e, we have, using Eq. (1),
œÉ(b) =

œÑ‚ààG
œÉ(cœÑ)œÉœÑ(e)
=

œÑ‚ààG
cœÉœÑc‚àí1
œÉ œÉœÑ(e)
= c‚àí1
œÉ

œÑ‚ààG
cœÉœÑœÉœÑ(e)
= c‚àí1
œÉ

œâ‚ààG
cœâœâ(e)
= c‚àí1
œÉ b.
Hence, cœÉ = bœÉ(b)‚àí1, and c is a coboundary. Therefore, H1(G, E√ó) = {0}.
‚Ä¢
Theorem 10.128 implies Theorem 4.50, which describes the elements of norm 1 in a
cyclic extension.
Corollary 10.129 (Hilbert's Theorem 90).
Let E/k be a Galois extension whose
Galois group G = Gal(E/k) is cyclic, say, with generator œÉ. If u ‚ààE√ó, then Nu = 1 if
and only if there is v ‚ààE√ó with
u = œÉ(v)v‚àí1.
Proof.
By Theorem 10.112, we have H1(G, E√ó) = ker N/ im D, where N is the norm
(remember that E√ó is a multiplicative group) and De = œÉ(e)e‚àí1. Theorem 10.128 gives
H1(G, E√ó) = {0}, so that ker N = im D. Hence, if u ‚ààE√ó, then Nu = 1 if and only if
there is v ‚ààE√ó with u = œÉ(v)v‚àí1.
‚Ä¢
Theorem 10.128 is one of the Ô¨Årst results in what is called Galois cohomology. Another
early result is that Hn(G, E) = {0} for all n ‚â•1, where E (in contrast to E√ó) is the
additive group of the Galois extension (this result follows easily from the normal basis
theorem). We are now going to see that H2(G, E√ó) is useful in studying division rings.
Only one example of a noncommutative division ring has been given in the text: the
quaternions H (this is an R-algebra) and its k-algebra analogs for every subÔ¨Åeld k ‚äÜR
(actually, another example is given in Exercise 9.80 on page 740). W. R. Hamilton discov-
ered the quaternions in 1843, and F. G. Frobenius, in 1880, proved that the only R-division
algebras are R, C, and H (see Theorem 9.124). No other examples of noncommutative
division rings were known until cyclic algebras were found in the early 1900s, by J. M.
Wedderburn and by L. E. Dickson. In 1932, A. A. Albert found an example of a crossed
product algebra that is not a cyclic algebra, and in 1972, S. A. Amitsur found an example
of a noncommutative division ring that is not a crossed product algebra.
Wedderburn proved that every Ô¨Ånite division ring is a Ô¨Åeld (see Theorem 8.23). Are
there any division rings of prime characteristic?
We begin with an elementary calculation. Suppose that V is a vector space over a Ô¨Åeld
E having basis {uœÉ : œÉ ‚ààG} for some set G, so that each v ‚ààV has a unique expression

Sec. 10.8
Crossed Products
889
as an E-linear combination v = 
œÉ aœÉuœÉ for aœÉ ‚ààE. For a function ¬µ: V √ó V ‚ÜíV ,
with ¬µ(uœÉ, uœÑ) denoted by uœÉuœÑ, deÔ¨Åne structure constants gœÉ,œÑ
Œ±
‚ààE by
uœÉuœÑ =

Œ±‚ààG
gœÉ,œÑ
Œ± uŒ±.
To have the associative law, we must have uœÉ(uœÑuœâ) = (uœÉuœÑ)uœâ; expanding this equation
gives, for all indices,

Œ±,Œ≤
gœÉ,œÑ
Œ± gŒ±,œâ
Œ≤
=

Œ≥,Œ¥
gœÑ,œâ
Œ≥
gœÉ,Œ≥
Œ¥
.
Let us simplify these equations. Let G be a group and suppose that gœÉ,œÑ
Œ±
= 0 unless Œ± =
œÉœÑ; that is, uœÉuœÑ = f (œÉ, œÑ)uœÉœÑ, where f (œÉ, œÑ) = gœÉ,œÑ
œÉœÑ . The function f : G √ó G ‚ÜíE√ó,
given by f (œÉ, œÑ) = gœÉ,œÑ
œÉœÑ , satisÔ¨Åes the following equation for all œÉ, œÑ, œâ ‚ààG:
f (œÉ, œÑ) f (œÉœÑ, œâ) = f (œÑ, œâ) f (œÉ, œÑœâ),
an equation reminiscent of the cocycle identity written in multiplicative notation. This is
why factor sets enter into the next deÔ¨Ånition.
Let E/k be a Galois extension with Gal(E/k) = G, and let f : G √ó G ‚ÜíE√ó be a
factor set: In multiplicative notation
f (œÉ, 1) = 1 = f (1, œÑ)
for all œÉ, œÑ ‚ààG
and, if we denote the action of œÉ ‚ààG on a ‚ààE√ó by aœÉ, then
f (œÉ, œÑ) f (œÉœÑ, œâ) = f (œÑ, œâ)œÉ f (œÉ, œÑœâ).
DeÔ¨Ånition.
Given a Galois extension E/k with Galois group G = Gal(E/k) and a factor
set f : G √ó G ‚ÜíE√ó, deÔ¨Åne the crossed product algebra (E, G, f ) to be the vector space
over E having basis all symbols {uœÉ : œÉ ‚ààG} and multiplication
(auœÉ)(buœÑ) = abœÉ f (œÉ, œÑ)uœÉœÑ
for all a, b ‚ààE. If G is a cyclic group, then the crossed product algebra (E, G, f ) is called
a cyclic algebra.
Since every element in (E, G, f ) has a unique expression of the form  aœÉuœÉ, the
deÔ¨Ånition of multiplication extends by linearity to all of (E, G, f ). We note two special
cases:
uœÉb = bœÉuœÉ;
uœÉuœÑ = f (œÉ, œÑ)uœÉœÑ.

890
Homology
Ch. 10
Proposition 10.130.
If E/k is a Galois extension with Galois group G = Gal(E/k) and
if f : G √ó G ‚ÜíE√ó is a factor set, then (E, G, f ) is a central simple k-algebra that is
split by E.
Proof.
Denote (E, G, f ) by A. First, we show that A is a k-algebra. To prove that A is
associative, it sufÔ¨Åces to prove that
auœÉ(buœÑcuœâ) = (auœÉbuœÑ)cuœâ,
where a, b, c ‚ààE. Using the deÔ¨Ånition of multiplication,
auœÉ(buœÑcuœâ) = auœÉ(bcœÑ f (œÑ, œâ)uœÑœâ)
= a

bcœÑ f (œÑ, œâ)
œÉ f (œÉ, œÑœâ)uœÉœÑœâ
= abœÉcœÉœÑ f (œÑ, œâ)œÉ f (œÉ, œÑœâ)uœÉœÑœâ.
We also have
(auœÉbuœÑ)cuœâ = abœÉ f (œÉ, œÑ)uœÉœÑcuœâ
= abœÉ f (œÉ, œÑ)cœÉœÑ f (œÉœÑ, œâ)uœÉœÑœâ
= abœÉcœÉœÑ f (œÉ, œÑ) f (œÉœÑ, œâ)uœÉœÑœâ.
The cocycle identity shows that multiplication in A is associative.
That u1 is the unit in A follows from our assuming that factor sets are normalized:
u1uœÑ = f (1, œÑ)u1œÑ = uœÑ
and
uœÉu1 = f (œÉ, 1)uœÉ1 = uœÉ.
We have shown that A is a ring. We claim that ku1 = {au1 : a ‚ààk} is the center Z(A).
If a ‚ààE, then uœÉau1 = aœÉuœÉ. If a ‚ààk = EG, then aœÉ = a for all œÉ ‚ààG, and so
k ‚äÜZ(A). For the reverse inclusion, suppose that z = 
œÉ aœÉuœÉ ‚ààZ(A). For any b ‚ààE,
we have zbu1 = bu1z. But
zbu1 =

aœÉuœÉbu1 =

aœÉbœÉuœÉ.
On the other hand,
bu1z =

baœÉuœÉ.
For every œÉ ‚ààG, we have aœÉbœÉ = baœÉ, so that if aœÉ Ã∏= 0, then bœÉ = b. If œÉ Ã∏= 1 and
H = ‚ü®œÉ‚ü©, then E H Ã∏= E{1} = E, by Theorem 4.33, and so there exists b ‚ààE with bœÉ Ã∏= b.
We conclude that z = a1u1. For every œÉ ‚ààG, the equation (a1u1)uœÉ = uœÉ(a1u1) gives
aœÉ
1 = a1, and so a1 ‚ààEG = k. Therefore, Z(A) = ku1.
We now show that A is simple. Let I be a nonzero two-sided ideal in A, and choose
a nonzero y ‚ààI of shortest length; that is, y =  cœÉuœÉ has the smallest number of
nonzero coefÔ¨Åcients cœÉ. Suppose that y = cœÉuœÉ + cœÑuœÑ + ¬∑ ¬∑ ¬∑ has at least two nonzero
coefÔ¨Åcients cœÉ and cœÑ. Since uœÑuœÑ ‚àí1œÉ = f (œÑ, œÑ ‚àí1œÉ)uœÉ, it follows that yuœÑ ‚àí1œÉ ‚ààI, and
that y‚àícœÉc‚àí1
œÑ
f (œÑ, œÑ ‚àí1œÉ)‚àí1yuœÑ ‚àí1œÉ is an element of I whose length is shorter than that of y

Sec. 10.8
Crossed Products
891
(this element is nonzero because the coefÔ¨Åcient of uœÉœÑ ‚àí1œÉ is nonzero). We conclude that y
has length 1; that is, y = cœÉuœÉ. Hence, I contains c‚àí1
œÉ
f (œÉ, œÉ ‚àí1)‚àí1(cœÉuœÉ)uœÉ ‚àí1 = u1, the
identity of A. Therefore, I = A, and A is simple.
Finally, Theorem 9.127 says that A is split by K, where K is any maximal subÔ¨Åeld of
A. The reader may show, using Lemma 9.117, that Eu1 ‚àº= E is a maximal subÔ¨Åeld.
‚Ä¢
In light of Proposition 10.130, it is natural to expect a connection between relative
Brauer groups and cohomology.
Theorem.
Let E/k be a Galois extension with G = Gal(E/k). There is an isomorphism
H2(G, E√ó) ‚ÜíBr(E/k) with cls f ‚Üí[(G, E, f )].
Sketch of Proof.
The usual proofs of this theorem are rather long. Each of the items:
the isomorphism is a well-deÔ¨Åned function; it is a homomorphism; it is injective; it is
surjective, must be checked, and the proofs are computational. For example, the proof in
Herstein, Noncommutative Rings covers pages 110 through 116. There is a less computa-
tional proof in Serre, Corps Locaux, pages 164 - 167, using the method of descent.
‚Ä¢
What is the advantage of this isomorphism? In Corollary 9.132, we saw that
Br(k) =

E/k Ô¨Ånite
Br(E/k).
Corollary 10.131.
Let k be a Ô¨Åeld.
(i) The Brauer group Br(k) is a torsion group.
(ii) If A is a central simple k-algebra, then there is an integer n so that the tensor product
of A with itself r times (where r is the order of [A] in Br(k)) is a matrix algebra:
A ‚äók A ‚äók ¬∑ ¬∑ ¬∑ ‚äók A ‚àº= Matn(k).
Sketch of Proof.
(i) Br(k) is the union of the relative Brauer groups Br(E/k), where E/k
is Ô¨Ånite. It can be shown that Br(k) is the union of those Br(E/k) for which E/k is a Galois
extension. We may now invoke Proposition 10.119, which says that |G| H2(G, E√ó) = {0}.
(ii) Tensor product is the binary operation in the Brauer group.
‚Ä¢
Recall Proposition 9.129: there exists a noncommutative division k-algebra over a Ô¨Åeld
k if and only if Br(k) Ã∏= {0}.
Corollary 10.132.
Let k be a Ô¨Åeld. If there is a cyclic Galois extension E/k such that
the norm N : E√ó ‚Üík√ó is not surjective, then there exists a noncommutative k-division
algebra.
Sketch of Proof.
If G is a Ô¨Ånite cyclic group, then Theorem 10.112 gives
H2(G, E√ó) = (E√ó)G/ im N = k√ó/ im N.
Therefore, Br(E/k) Ã∏= {0} if N is not surjective, and this implies that Br(k) Ã∏= {0}.
‚Ä¢

892
Homology
Ch. 10
If k is a Ô¨Ånite Ô¨Åeld and E/k is a Ô¨Ånite extension, then it follows from Wedderburn's
theorem on Ô¨Ånite division rings (Theorem 8.23) that the norm N : E√ó ‚Üík√ó is surjective.
Corollary 10.133.
If p is a prime, then there exists a noncommutative division algebra
of characteristic p.
Proof.
If k is a Ô¨Åeld of characteristic p, it sufÔ¨Åces to Ô¨Ånd a cyclic extension E/k for
which the norm N : E√ó ‚Üík√ó is not surjective; that is, we must Ô¨Ånd some z ‚ààk√ó which
is not a norm.
If p is an odd prime, let k = Fp(x). Since p is odd, t2 ‚àíx is a separable irreducible
polynomial, and so E = k(‚àöx) is a Galois extension of degree 2. If u ‚ààE, then there are
polynomials a, b, c ‚ààFp[x] with u = (a + b‚àöx)/c. Moreover,
N(u) = (a2 ‚àíb2x)/c2.
We claim that x2 + x is not a norm. Otherwise,
a2 ‚àíb2x = c2(x2 + x).
Since c Ã∏= 0, the polynomial c2(x2 + x) Ã∏= 0, and it has even degree. On the other hand, if
b Ã∏= 0, then a2 ‚àíb2x has odd degree, and this is a contradiction. If b = 0, then u = a/c;
since a2 = c2(x2 + x), we have c2 | a2, hence c | a, and so u ‚ààFp[x] is a polynomial.
But it is easy to see that x2 + x is not the square of a polynomial. We conclude that
N : E√ó ‚Üík√ó is not surjective.
Here is an example in characteristic 2. Let k = F2(x), and let E = k(Œ±), where Œ± is a
root of f (t) = t2 + t + x + 1 [ f (t) is irreducible and separable; its other root is Œ± + 1]. As
before, each u ‚ààE can be written in the form u = (a + bŒ±)/c, where a, b, c ‚ààF2[x]. Of
course, we may assume that x is not a divisor of all three polynomials a, b and c. Moreover,
N(u) =

(a + bŒ±)(a + bŒ± + b)

/c2 =

a2 + ab + b2(x + 1)

/c2.
We claim that x is not a norm. Otherwise,
a2 + ab + b2(x + 1) = c2x.
(2)
Now a(0), the constant term of a, is either 0 or 1. Consider the four cases arising from the
constant terms of a and b; that is, evaluate Eq. (2) at x = 0. We see that a(0) = 0 = b(0);
that is x | a and x | b. Hence, x2 | a2 and x2 | b2, so that Eq. (2) has the form x2d = c2x,
where d ‚ààF2[x]. Dividing by x gives xd = c2, which forces c(0) = 0; that is, x | c, and
this is a contradiction.
‚Ä¢
For further discussion of the Brauer group, see the article by Serre in Cassels-Fr¬®ohlich,
Algebraic Number Theory, Jacobson, Basic Algebra II, pages 471-481, Reiner, Maximal
Orders, Chapters 5, 7, and 8, and the article by V. P. Platonov and V. I. Yanchevskii, Finite-
Dimensional Division Algebras, in Kostrikin-Shafarevich, Encyclopaedia of Mathematical
Sciences, Algebra IX. In particular, a global Ô¨Åeld is a Ô¨Åeld which is either an arithmetic

Sec. 10.9
Introduction to Spectral Sequences
893
number Ô¨Åeld [i.e., a Ô¨Ånite extension of Q] or a function Ô¨Åeld [a Ô¨Ånite extension of k(x),
where k is a Ô¨Ånite Ô¨Åeld]. To each global Ô¨Åeld, we assign a family of local Ô¨Åelds. These
Ô¨Åelds are best deÔ¨Åned in terms of discrete valuations. A discrete valuation on a Ô¨Åeld L is
a function v : L√ó ‚ÜíN such that, for all a, b ‚ààL,
v(a) = 0
if and only if a = 0;
v(ab) = v(a)v(b);
v(a + b) = max{v(a), v(b)}.
Now R = {a ‚ààL : v(a) ‚â§1} is a domain and P = {a ‚ààL : v(a) < 1} is a maximal
ideal in R. We call R/P the residue Ô¨Åeld of L with respect to the discrete valuation v. A
local Ô¨Åeld is a Ô¨Åeld which is complete with respect to the metric arising from a discrete
valuation on it, and whose residue Ô¨Åeld is Ô¨Ånite. It turns out that every local Ô¨Åeld is either
a Ô¨Ånite extension of Qp, the p-adic numbers (which is the fraction Ô¨Åeld of the p-adic
integers Zp) or it is isomorphic to Fq[[x]], the ring of formal power series in one variable
over a Ô¨Ånite Ô¨Åeld Fq. If k is a local Ô¨Åeld, then Br(k) ‚àº= H2(ks, k√ó), where ks/k is the
maximal separable extension of k in the algebraic closure k. If A is a central simple K-
algebra, where K is a global Ô¨Åeld, and if Kv is a local Ô¨Åeld of K, then Kv ‚äóK A is a
central simple Kv-algebra. The Hasse-Brauer-Noether-Albert theorem states that if A
is a central simple algebra over a global Ô¨Åeld K, then A ‚àº= K if and only if Kv ‚äóK
A ‚àº= Kv for all associated local Ô¨Åelds Kv. We merely mention that these results where
used by C. Chevalley to develop class Ô¨Åeld theory [the branch of algebraic number theory
involving Galois extensions (of possibly inÔ¨Ånite degree) having abelian Galois groups].
See Neukirch-Schmidt-Wingberg, Cohomology of Number Fields.
For generalizations of the Brauer group [e.g., Br(k), where k is a commutative ring] and
ties to Morita theory, see Orzech-Small, The Brauer Group of Commutative Rings. and
Caenepeel, Brauer Groups, Hopf Algebras, and Galois Theory.
EXERCISES
10.65 Show that the structure constants in the crossed product (E, G, f ) are
gœÉ,œÑ
Œ±
=

f (œÉ, œÑ)
if Œ± = œÉœÑ;
0
otherwise.
10.66 Prove that H ‚äóR H ‚àº= Mat4(R).
10.9 INTRODUCTION TO SPECTRAL SEQUENCES
The last topic we mention is spectral sequences, whose major uses are in computing ho-
mology groups and in comparing homology groups of composites of functors. This brief
section merely describes the setting for spectral sequences, in the hope that it will ease the

894
Homology
Ch. 10
reader's Ô¨Årst serious encounter with them. For a more complete account, we refer the reader
to Mac Lane, Homology, Chapter XI, McCleary, User's Guide to Spectral Sequences, or
Rotman, An Introduction to Homological Algebra, Chapter 11.
Call a series of submodules of a module K,
K = K0 ‚äáK1 ‚äáK2 ‚äá¬∑ ¬∑ ¬∑ ‚äáK‚Ñì= {0},
a Ô¨Åltration (instead of a normal series), and call the quotients Ki/Ki+1 the factor modules
of the Ô¨Åltration. We know that a module K may not be determined by the factor modules of
a Ô¨Åltration; on the other hand, knowledge of the factor modules does give some information
about K. For example, if all the factor modules are zero, then K = {0}; if all the factor
modules are Ô¨Ånite, then K is Ô¨Ånite (and |K| is the product of the orders of the factor
modules); or, if all the factor modules are Ô¨Ånitely generated, then K is Ô¨Ånitely generated.
DeÔ¨Ånition.
If K is a module, then a subquotient of K is a module isomorphic to S/T ,
where T ‚äÜS ‚äÜK are submodules.
Thus, a subquotient of K is a quotient of a submodule. It is also easy to see that a
subquotient of K is also a submodule of a quotient (S/T ‚äÜK/T ).
Example 10.134.
(i) All the factor modules of a Ô¨Åltration of a module K are subquotients of K.
(ii) The nth homology group of a complex (C‚Ä¢, d‚Ä¢) is a subquotient of Cn.
‚óÄ
A spectral sequence computes a homology group Hn in the sense that it computes the
factor modules of some Ô¨Åltration of Hn. In general, this gives only partial information
about Hn, but, if the factor modules are heavily constrained, then they can give much more
information and, indeed, might even determine Hn completely. For example, suppose that
only one of the factor modules of K is nonzero, say, Ki/Ki+1 ‚àº= A Ã∏= {0}; we claim that
K ‚àº= A. The beginning of the Ô¨Åltration is
K = K0 ‚äáK1 ‚äá¬∑ ¬∑ ¬∑ ‚äáKi.
Since K0/K1 = {0}, we have K = K0 = K1. Similarly, K1/K2 = {0} gives K1 = K2;
indeed, K = K0 = K1 = ¬∑ ¬∑ ¬∑ = Ki. Similar reasoning computes the end of the Ô¨Åltration.
For example, since K‚Ñì‚àí1/K‚Ñì= {0}, we have K‚Ñì‚àí1 = K‚Ñì= {0}. Thus, the Ô¨Åltration is
K = K0 = ¬∑ ¬∑ ¬∑ = Ki ‚äãKi+1 = ¬∑ ¬∑ ¬∑ = K‚Ñì= {0},
and so K ‚àº= K/{0} = Ki/Ki+1 ‚àº= A.
In order to appreciate spectral sequences, we must recognize an obvious fact: very
general statements can become useful if extra simplifying hypotheses can be imposed.
Spectral sequences usually arise in the following context. A bigraded module M = M‚Ä¢‚Ä¢
is a doubly indexed family of modules Mp,q, where p, q ‚ààZ; we picture a bigraded
module as a collection of modules, one sitting on each lattice point (p, q) in the plane.

Sec. 10.9
Introduction to Spectral Sequences
895
Thus, there are Ô¨Årst quadrant bigraded modules, for example, with Mp,q = {0} if either
p or q is negative; similarly, there are third quadrant bigraded modules. A bicomplex is
a bigraded module that has vertical arrows d‚Ä≤‚Ä≤
p,q : Mp,q ‚ÜíMp,q‚àí1 making the columns
complexes, horizontal arrows d‚Ä≤
p,q : Mp,q ‚ÜíMp‚àí1,q making the rows complexes, and
whose squares anticommute:
Mp‚àí1,q
d‚Ä≤‚Ä≤
p‚àí1,q

Mp,q
d‚Ä≤
p,q

d‚Ä≤‚Ä≤
p,q

Mp‚àí1,q‚àí1
Mp,q‚àí1
d‚Ä≤
p,q‚àí1

that is, d‚Ä≤d‚Ä≤‚Ä≤ + d‚Ä≤‚Ä≤d‚Ä≤ = 0. The reason for the anticommutativity is to allow us to deÔ¨Åne the
total complex, Tot(M), of a bicomplex M: Its term in degree n is:
Tot(M)n =

p+q=n
Mp,q;
its differentiation dn : Tot(M)n ‚ÜíTot(M)n‚àí1 is given by
dn =

p+q=n
d‚Ä≤
p,q + d‚Ä≤‚Ä≤
p,q.
Anticommutativity forces dn‚àí1dn = 0:
dd = (d‚Ä≤ + d‚Ä≤‚Ä≤)(d‚Ä≤ + d‚Ä≤‚Ä≤) = d‚Ä≤d‚Ä≤ + (d‚Ä≤d‚Ä≤‚Ä≤ + d‚Ä≤‚Ä≤d‚Ä≤) + d‚Ä≤‚Ä≤d‚Ä≤‚Ä≤ = 0;
thus, Tot(M) is a complex.
All bigraded modules form a category. Given an ordered pair of integers (a, b), a family
of maps f p,q : Mp,q ‚ÜíL p+a,q+b is called a map f : M‚Ä¢‚Ä¢ ‚ÜíL‚Ä¢‚Ä¢ of bidegree (a, b). For
example, the maps d‚Ä≤ and d‚Ä≤‚Ä≤ above have respective bidegrees (0, ‚àí1) and (‚àí1, 0). It is
easy to check that all bigraded modules and all maps having some bidegree form a category.
One nice feature of composition is that bidegrees add: if f has bidegree (a, b) and f ‚Ä≤ has
bidegree (a‚Ä≤, b‚Ä≤), then their composite f ‚Ä≤ f has bidegree (a +a‚Ä≤, b +b‚Ä≤). Maps of bigraded
modules are used in establishing certain exact sequences. For example, one proof of the
Ô¨Åve term exact sequence on page 882 uses these maps.
A spectral sequence is a sequence of bicomplexes, Er
p,q, for all r ‚â•2, where each Er+1
p,q
is a subquotient of Er
p,q (we must also specify that the homomorphisms of the bicomplex
Er+1
p,q arise from those of Er
p,q). Most spectral sequences arise from a Ô¨Åltration of Tot(M),
where M‚Ä¢‚Ä¢ is a bicomplex. In particular, there are two "usual" Ô¨Åltrations (if M‚Ä¢‚Ä¢ is either
Ô¨Årst quadrant or third quadrant), and the spectral sequences they determine are denoted by
IEr
p,q and IIEr
p,q.
We say that a spectral sequence Er
p,q converges to a (singly graded) module H‚Ä¢, denoted
by E2
p,q ‚áíHn, if each Hn has a Ô¨Åltration with factor modules
E0,n, E1,n‚àí1, . . . , En,0,

896
Homology
Ch. 10
and, for all p, q with p + q = n, the factor module E p,q is a subquotient of E2
p,q. There
are two steps to establish before using spectral sequences.
Theorem I. If M‚Ä¢‚Ä¢ is a Ô¨Årst quadrant or third quadrant bicomplex, then
IE2
p,q ‚áíHn(Tot(M))
and
IIE2
p,q ‚áíHn(Tot(M)).
Thus, for each n, there are two Ô¨Åltrations of Tot(M)n; one whose factor modules are
subquotients of IE2
p,q, and another whose factor modules are subquotients of IIE2
p,q (as
usual, p + q = n in this context), and both converge to the same thing.
Theorem II. If M‚Ä¢‚Ä¢ is a Ô¨Årst quadrant or third quadrant bicomplex, then there are formulas
for IE2
p,q and IIE2
p,q for every p, q.
Theorem II offers the possibility that subquotients of E2
p,q can be computed.
We illustrate the technique by sketching a proof that Torn(A, B) does not depend on the
variable resolved; that is, the value of Torn(A, B), deÔ¨Åned as Hn(PA ‚äóB), where PA is
a deleted projective resolution of A, coincides with Torn(A, B), deÔ¨Åned as Hn(A ‚äóQB),
where QB is a deleted projective resolution of B. The idea is to resolve both variables
simultaneously, using resolutions of each. DeÔ¨Åne a Ô¨Årst quadrant bigraded module M =
PA ‚äóQB whose p, q term is Pp ‚äóQq; make this into a bicomplex by deÔ¨Åning vertical
arrows d‚Ä≤‚Ä≤
p,q = (‚àí1)p1 ‚äó‚àÇq : Pp ‚äóQq ‚ÜíPp ‚äóQq‚àí1 and horizontal arrows d‚Ä≤
p,q =
p ‚äó1: Pp ‚äóQq ‚ÜíPp‚àí1 ‚äóQq, where the ‚àÇn are the differentiations in QB and the
n are the differentiations in PA (the signs force anticommutativity). The formula whose
existence is stated in Theorem II for the Ô¨Årst spectral sequence IE2
p,q gives, in this case,
IE2
p,q =

{0}
if q > 0;
Hp(PA ‚äóB)
if q = 0.
Since a subquotient of {0} must be {0}, all but one of the factor modules of a Ô¨Åltration of
Hn(Tot(M)) are zero, and so
Hn(Tot(M)) ‚àº= Hn(PA ‚äóB).
Similarly, the formula alluded to in Theorem II for the second spectral sequence gives
IIE2
p,q =

{0}
if p > 0;
Hq(A ‚äóQB)
if p = 0.
Again, there is a Ô¨Åltration of Hn(Tot(M)) with only one possible nonzero factor module,
and so
Hn(Tot(M)) ‚àº= Hn(A ‚äóQB).
Therefore,
Hn(PA ‚äóB) ‚àº= Hn(Tot(M)) ‚àº= Hn(PA ‚äóB).
We have shown that Tor is independent of the variable resolved.
Here is a cohomology result illustrating how spectral sequences can be used to compute
composite functors. The index raising convention extends here, so that one denotes the
modules in a third quadrant bicomplex by M p,q instead of by M‚àíp,‚àíq.

Sec. 10.9
Introduction to Spectral Sequences
897
Theorem 10.135 (Grothendieck).
Let F : B ‚ÜíC and G : A ‚ÜíB be additive functors,
where A, B, and C are module categories. If F is left exact and if E injective in A implies
(Rm F)(GE) = {0} for all m > 0 (where Rm F are the right derived functors of F), then
for every module A ‚ààA, there is a third quadrant spectral sequence
E p,q
2
= (R pF)(RqG(A)) ‚áíRn(FG)(A).
For a proof, see Rotman, An Introduction to Homological Algebra, page 350.
The next result shows that if N is a normal subgroup of a group *, then the cohomology
groups of N and of */N can be used to compute the cohomology groups of *.
Theorem 10.136 (Lyndon-Hochschild-Serre).
Let * be a group with normal sub-
group N. For each *-module A, there is a third quadrant spectral sequence with
E p,q
2
= H p(*/N, Hq(N, A)) ‚áíHn(*, A).
Proof.
DeÔ¨Åne functors G : Z*Mod ‚ÜíZ(*/N)Mod and F : Z(*/N)Mod ‚ÜíAb by G =
HomN(Z, ) and F = Hom*/N(Z, ). Of course, F is left exact, and it is easy to see
that FG = Hom*(Z, ). A proof that Hm(*/N, E) = {0} whenever E is an injective
*-module and m > 0 can be found in Rotman, An Introduction to Homological Algebra,
page 307. The result now follows from Theorem 10.135.
‚Ä¢
This theorem was found by Lyndon in his dissertation in 1948, in order to compute the
cohomology groups of Ô¨Ånitely generated abelian groups *. Several years later, Hochschild
and Serre put the result into its present form.

11
Commutative Rings III
11.1 LOCAL AND GLOBAL
Quite often, it is easier to examine algebraic structures "one prime at a time." Let G
and H be Ô¨Ånite groups. If G ‚àº= H, then their Sylow p-subgroups are isomorphic for
all primes p; studying G and H locally means studying their p-subgroups. This local
information is not enough to determine whether G ‚àº= H; for example, S3 and I6 are
nonisomorphic groups having isomorphic Sylow subgroups. The global problem assumes
that the Sylow p-subgroups of groups G and H are isomorphic, for all primes p, and
asks what else is necessary to conclude that G ‚àº= H. In the case of groups, this leads
to the extension problem and cohomology of groups (but even this is inadequate to solve
the global problem: for example, S3 and I6 have isomorphic Sylow subgroups and the
same composition factors). An illustration of the success of this technique is provided by
Ô¨Ånite abelian groups. The local problem involves primary components (Sylow subgroups),
which are direct sums of cyclic groups, and the global problem is solved by the primary
decomposition: Every Ô¨Ånite abelian group is the direct sum of its primary components. In
this case, the local information is sufÔ¨Åcient to solve the global problem. The advantage
of the local/global approach is that the local problem is simpler than the global and its
solution is valuable. We begin this section with another group-theoretic illustration of
local and global investigation, after which we will consider localization of commutative
rings.
DeÔ¨Ånition.
Let R be a domain with Q = Frac(R). If M is an R-module, deÔ¨Åne
rank(M) = dimQ(Q ‚äóR M).
For example, the rank of an abelian group G is deÔ¨Åned as dimQ(Q ‚äóZ G).
Recall that if R is a domain, then an R-module M is torsion-free if it has no nonzero
elements of Ô¨Ånite order; that is, if r ‚ààR and m ‚ààM are nonzero, then rm is nonzero.
898

Sec. 11.1
Local and Global
899
Lemma 11.1.
Let R be a domain with Q = Frac(R) and let M be a torsion-free R-
module. Then M has rank 1 if and only if it is isomorphic to a nonzero R-submodule
of Q.
Proof.
If rank(M) = 1, then M Ã∏= {0}. Exactness of 0 ‚ÜíR ‚ÜíQ gives exactness of
TorR
1 (Q/R, M) ‚ÜíR ‚äóR M ‚ÜíQ ‚äóR M.
By Lemma 10.101(iii), we have TorR
1 (Q/R, M) ‚àº= t M, the torsion submodule of M, and
so TorR
1 (Q/R, M) = {0} because M is torsion-free. But Proposition 8.86 gives R‚äóR M ‚àº=
M, while Q ‚äóR M ‚àº= Q because M has rank 1. Therefore, M is isomorphic to an R-
submodule of Q.
Conversely, if M is isomorphic to an R-submodule of Q, there is an exact sequence
0 ‚ÜíM ‚ÜíQ. Since Q is a Ô¨Çat R-module, by Corollary 8.103, we have exactness of
0 ‚ÜíQ ‚äóR M ‚ÜíQ ‚äóR Q. This is an exact sequence of vector spaces over Q, with
Q ‚äóR Q ‚àº= Q being one-dimensional. Therefore, the nonzero subspace Q ‚äóR M is also
one-dimensional; that is, rank(M) = 1.
‚Ä¢
Example 11.2.
The following abelian groups are torsion-free of rank 1:
(i) The group Z of integers;
(ii) The additive group Q;
(iii) the set of all rationals having a Ô¨Ånite decimal expansion;
(iv) the set of all rationals having squarefree denominator.
‚óÄ
Proposition 11.3.
Let R be a domain with Q = Frac(R). Two submodules A and B of
Q are isomorphic if and only if there is c ‚ààQ with B = cA.
Proof.
If B = cA, then A ‚àº= B via a ‚Üíca.
Conversely, suppose that f : A ‚ÜíB is an isomorphism. We show Ô¨Årst that if a ‚ààA is
nonzero, then f is determined by its values on ‚ü®a‚ü©: If g : A ‚ÜíB and g|‚ü®a‚ü©= f |‚ü®a‚ü©, then
f = g. If x ‚ààA, then there are r, s ‚ààR with sx = ra ‚àà‚ü®a‚ü©(because A is a submodule of
Q), and so
f (sx) = f (ra) = r f (a) = rg(a) = g(ra) = g(sx).
Hence, s( f (x) ‚àíg(x)) = 0, and, since B is torsion-free, we have f (x) = g(x).
If f (a) = b, deÔ¨Åne c = b/a. In order to show that f (x) = cx for all x ‚ààA, it now
sufÔ¨Åces to prove that f (ra) = c(ra) for all r ‚ààR. But
f (ra) = r f (a) = rb = r(b/a)a = c(ra).
It follows that f (x) = cx for all x ‚ààA and that B = cA.
‚Ä¢

900
Commutative Rings III
Ch. 11
DeÔ¨Ånition.
For each prime p, we deÔ¨Åne a subring of Q,
Z(p) = {a/b ‚ààQ : (b, p) = 1}.
Proposition 11.4.
(i) For each prime p, the ring Z(p) is a local1 PID.
(ii) If G is a torsion-free abelian group of rank 1, then Z(p) ‚äóZ G is a torsion-free
Z(p)-module of rank 1.
(iii) If M is a torsion-free Z(p)-module of rank 1, then M ‚àº= Z(p) or M ‚àº= Q.
Proof.
(i) We show that the only nonzero ideals I in Z(p) are (pn), for n ‚â•0; it will then
follow that Z(p) is a PID and that (p) is its unique maximal ideal. Since Z(p) ‚äÜQ, each
nonzero x ‚ààp‚àí1Z has the form a/b for integers a and b, where (b, p) = 1. But a = pna‚Ä≤,
where n ‚â•0 and (a‚Ä≤, p) = 1; that is, there is a unit u ‚ààZ(p), namely, u = a‚Ä≤/b, with
x = upn. Let I Ã∏= {0} be an ideal. Of all the nonzero elements in I, choose x = upn ‚ààI,
where u is a unit, with n minimal. Then I = (x) = (pn), for if y ‚ààI, then y = vpm,
where v is a unit and n ‚â§m. Hence, pn | y and y ‚àà(pn).
(ii) Since Z(p) ‚äÜQ, it is an additive torsion-free abelian group of rank 1, and so it is Ô¨Çat
(Corollary 9.6). Hence, exactness of 0 ‚ÜíG ‚ÜíQ gives exactness of
0 ‚ÜíZ(p) ‚äóZ G ‚ÜíZ(p) ‚äóZ Q.
By Exercise 11.5 on page 920, Z(p) ‚äóZ Q ‚àº= Q = Frac(Z(p)), so that Z(p) ‚äóZ G is a
torsion-free Z(p)-module of rank 1.
(iii) There is no loss in generality in assuming that M ‚äÜQ and that 1 ‚ààM. Consider the
equations pnyn = 1 for n ‚â•0. We claim that if all these equations are solvable for yn ‚ààM,
then M = Q. If a/b ‚ààQ, then a/b = a/pnb‚Ä≤, where (b‚Ä≤, p) = 1, and so a/b = (a/b‚Ä≤)yn;
as a/b‚Ä≤ ‚ààZ(p), we have a/b ‚ààM. We may now assume that there is a largest n ‚â•0
for which the equation pnyn = 1 is solvable for yn ‚ààM. We claim that M = ‚ü®yn‚ü©,
the cyclic submodule generated by yn, which will show that M ‚àº= Z(p). If m ‚ààM, then
m = c/d = prc‚Ä≤/psd‚Ä≤ = (c‚Ä≤/d‚Ä≤)(1/ps‚àír), where (c‚Ä≤, p) = 1 = (d‚Ä≤, p). Since c‚Ä≤/d‚Ä≤ is a
unit in Z(p), we have 1/ps‚àír ‚ààM, and so s ‚àír ‚â§n; that is, s ‚àír = n ‚àí‚Ñìfor some ‚Ñì‚â•0.
Hence, 1/ps‚àír = 1/pn‚àí‚Ñì= p‚Ñì/pn = p‚Ñìyn, and so m = (c‚Ä≤ p‚Ñì/d‚Ä≤)yn ‚àà‚ü®yn‚ü©.
‚Ä¢
DeÔ¨Ånition.
A discrete valuation ring, abbreviated DVR, is a local PID that is not a Ô¨Åeld.
For example, Z(p) is a DVR.
1Recall that a local ring is a commutative ring having a unique maximal ideal. Most authors insist that local
rings are noetherian [Z(p) is even a PID]. Other authors allow local rings to be noncommutative, deÔ¨Åning a ring
R to be local if it has a unique maximal left ideal m. In this case, m = J(R), the Jacobson radical, so that it is a
two-sided ideal.

Sec. 11.1
Local and Global
901
DeÔ¨Ånition.
Two torsion-free abelian groups of rank 1, G and H, are locally isomorphic
if Z(p) ‚äóZ G ‚àº= Z(p) ‚äóZ H for all primes p.
We have solved the local problem for torsion-free abelian groups G of rank 1; associate
to G the family Z(p) ‚äóZ G of Z(p)-modules, one for each prime p.
Example 11.5.
Let G be the subgroup of Q consisting of those rationals having squarefree denominator.
Then G and Z are locally isomorphic, but they are not isomorphic, because G is not Ô¨Ånitely
generated.
‚óÄ
We now consider the global problem for torsion-free abelian groups of rank 1.
DeÔ¨Ånition.
Let G be an abelian group. If x ‚ààG and p is a prime, we say that x is
divisible by pn in G if there exists yn ‚ààG with pnyn = x. DeÔ¨Åne the p-height of x,
denoted by h p(x), by
h p(x) =

‚àû
if x is divisible by pn in G for all n ‚â•0
k
if x is divisible by pk in G but not by pk+1.
The height sequence (or characteristic) of x in G, where x is nonzero, is the sequence
œá(x) = œáG(x) = (h2(x), h3(x), h5(x), . . . , h p(x), . . .).
Thus, œá(x) is a sequence (h p), where h p = ‚àûor h p ‚ààN. Let G ‚äÜQ and let x ‚ààG
be nonzero. If œá(x) = (h p) and a = p f1
1 ¬∑ ¬∑ ¬∑ p fn
n , then 1
a x ‚ààG if and only if f pi ‚â§h pi for
i = 1, . . . , n.
Example 11.6.
Each of the groups in Example 11.2 contains x = 1.
(i) In Z,
œáZ(1) = (0, 0, 0, . . .).
(ii) In Q,
œáQ(1) = (‚àû, ‚àû, ‚àû, . . .).
(iii) If G is the group of all rationals having a Ô¨Ånite decimal expansion, then
œáG(1) = (‚àû, 0, ‚àû, 0, 0, . . .).
(iv) If H is the group of rationals having squarefree denominators, then
œáH(1) = (1, 1, 1, . . .).
‚óÄ

902
Commutative Rings III
Ch. 11
Different elements in a torsion-free abelian group of rank 1 may have different height
sequences. For example, if G is the group of rationals having Ô¨Ånite decimal expansions,
then 1 and 63
8 lie in G, and
œá(1) = (‚àû, 0, ‚àû, . . .)
and
œá( 63
8 ) = (‚àû, 2, ‚àû, 1, 0, 0, . . .).
Thus, these height sequences agree for inÔ¨Ånite p-heights, but they disagree for two Ô¨Ånite
p-heights.
DeÔ¨Ånition.
Two height sequences (h2, h3, . . . , h p, . . .) and (k2, k3, . . . , kp, . . .) are equiv-
alent, denoted by
(h2, h3, . . . , h p, . . .) ‚àº(k2, k3, . . . , kp, . . .),
if there are only Ô¨Ånitely many p for which h p Ã∏= kp and, for such primes p, neither h p nor
kp is ‚àû.
It is routine to see that equivalence is, in fact, an equivalence relation.
Lemma 11.7.
If G is a torsion-free abelian group of rank 1, and if x, y ‚ààG are nonzero,
then their height sequences œá(x) and œá(y) are equivalent.
Proof.
We may assume that G ‚äÜQ. If b = pe1
1 ¬∑ ¬∑ ¬∑ pen
n , then it is easy to see that
h p(bx) = h p(x) for all p /‚àà{p1, . . . , pn}, while
h pi (bx) = ei + h pi (x)
for i = 1, . . . , n (we agree that ei+‚àû= ‚àû). Hence, œá(x) ‚àºœá(bx). Since x, y ‚ààG ‚äÜQ,
we have x/y = a/b for integers a, b, so that bx = ay. Therefore, œá(x) ‚àºœá(bx) =
œá(ay) ‚àºœá(y).
‚Ä¢
DeÔ¨Ånition.
The equivalence class of a height sequence is called a type. If G is a torsion-
free abelian group of rank 1, then its type, denoted by œÑ(G), is the type of a height sequence
œá(x), where x is a nonzero element of G.
Lemma 11.7 shows that œÑ(G) depends only on G and not on the choice of nonzero
element x ‚ààG. We now solve the global problem.
Theorem 11.8.
If G and H are torsion-free abelian groups of rank 1, then G ‚àº= H if and
only if œÑ(G) = œÑ(H).
Proof.
Let œï : G ‚ÜíH be an isomorphism. If x ‚ààG is nonzero, it is easy to see that
œá(x) = œá(œï(x)), and so œÑ(G) = œÑ(H).
For the converse, there is no loss in generality in assuming that both G and H are
subgroups of Q. Choose nonzero x ‚ààG and y ‚ààH. By the deÔ¨Ånition of equivalence,
there are primes p1, . . . , pn, q1, . . . , qm with h pi (x) < h pi (y) < ‚àû, with ‚àû> hq j (x) >
hq j (y), and with h p(x) = h p(y) for all other primes p. DeÔ¨Åne b =  p
h pi (y)‚àíh pi (x)
i
. Then

Sec. 11.1
Local and Global
903
bx ‚ààG and h pi (bx) =

h pi (y) ‚àíh pi (x)

+ h pi (x) = h pi (y). A similar construction,
using a =  q
hq j (x)‚àíhq j (y)
j
, gives œá(bx) = œá(ay). We have found elements x‚Ä≤ = bx ‚ààG
and y‚Ä≤ = ay ‚ààH having the same height sequence.
DeÔ¨Åne œï : G ‚ÜíQ by œï(g) = y‚Ä≤
x‚Ä≤ g. It is obvious that œï is an injective homomorphism.
We claim that im œï ‚äÜH. Since every g ‚ààG can be written as g = 1
c x‚Ä≤, it sufÔ¨Åces to show
that if 1
c x‚Ä≤ ‚ààG, then œï( 1
c x‚Ä≤) = 1
c y‚Ä≤ ‚ààH. But if c = p f1
1 ¬∑ ¬∑ ¬∑ p ft
t , then 1
c x‚Ä≤ ‚ààG if and
only if f p ‚â§h p(x‚Ä≤). Since œá(x‚Ä≤) = œá(y‚Ä≤), 1
c y‚Ä≤ ‚ààH if and only if f p ‚â§h p(y‚Ä≤) = h p(x‚Ä≤).
Thus, we may view œï as a map G ‚ÜíH. Finally, to see that œï is a surjection, note that its
inverse is given by h ‚Üíx‚Ä≤
y‚Ä≤ h, which is a map H ‚ÜíG.
‚Ä¢
The uniqueness theorem just proved is complemented by an existence theorem.
Proposition 11.9.
Given a height sequence (k2, k3, . . . , kp, . . .), where 0 ‚â§kp ‚â§‚àû,
there exists a unique subgroup G ‚äÜQ containing 1 with h p(1) = kp for all p. Thus, given
any type œÑ, there exists a torsion-free abelian group G of rank 1, unique to isomorphism,
with œÑ(G) = œÑ.
Proof.
DeÔ¨Åne
D = {a ‚ààZ : a =

pei
i with 0 ‚â§ei ‚â§kpi for all i}
(if kpi = ‚àû, then 0 ‚â§ei ‚â§kpi means that ei ‚ààN), and deÔ¨Åne
G = {m/a ‚ààQ : m ‚ààZ and a ‚ààD}.
To see that G is a subgroup of Q, it sufÔ¨Åces to prove that it is closed under addition. Let
m/a and n/b be in G, where a =  pei
i , b =  p fi
i , and max{ei, fi} ‚â§kpi ; that is,
[a, b] ‚ààD. Now
m
a + n
b = ma‚Ä≤ + nb‚Ä≤
[a, b]
,
where [a, b] = lcm{a, b} =  pmax{ei, fi}
i
, a‚Ä≤ = [a, b]/a, and b‚Ä≤ = [a, b]/b. Since
[a, b] ‚ààD, we have m/a + n/b ‚ààG. It is clear that h p(1) = kp for all p, and so
œÑ(G) = œÑ.
Let us now prove uniqueness. Let G and H be subgroups of Q containing 1 with
œáH(1) = œáG(1). Suppose that m/d ‚ààH is in lowest terms‚Äî(m, d) = 1. Then there are
integers s and t with 1 = sm + td, so that 1/d = s(m/d) + td/d ‚ààH. On the other hand,
1/d ‚ààG, by deÔ¨Ånition of height sequence. It follows that H ‚äÜG, for H is generated by
all elements of the form 1/d. The reverse inclusion is proved similarly, and so G = H.
‚Ä¢
Corollary 11.10.
(i) There are uncountably many nonisomorphic subgroups of Q.
(ii) If R is a subring of Q, then the height sequence of 1 consists of 0's and ‚àû's.

904
Commutative Rings III
Ch. 11
(iii) There are uncountably many nonisomorphic subrings of Q. In fact, distinct subrings
of Q are not isomorphic as rings.
Proof.
(i) Given any type œÑ, Proposition 11.9 provides a torsion-free abelian group G of
rank 1 with œÑ(G) = œÑ. But there are uncountably many types; for example, two height
sequences of 0's and ‚àû's are equivalent if and only if they are equal.
(ii) If h p(1) > 0, then 1
p ‚ààR. Since R is a ring,

1
p
n
=
1
pn ‚ààR for all n ‚â•1, and so
h p(1) = ‚àû.
(iii) If R and S are distinct subrings of Q, then the height sequences of 1 are distinct, by
part (ii). Both statements follow from the observation that two height sequences whose
only terms are 0 and ‚àûare equivalent if and only if they are equal.
‚Ä¢
A. G. Kurosh classiÔ¨Åed torsion-free abelian groups G of Ô¨Ånite rank n with invariants
n = rank(G), dim(Fp ‚äóG) for all primes p, and an equivalence class of sequences (Mp),
where Mp is an n √ó n nonsingular matrix over the p-adic numbers Qp (this theorem is not
easy to use, for it is almost impossible to determine whether two groups have equivalent
matrix sequences). It is easy to see that every such group G is a direct sum of indecom-
posable2 groups; however, there is virtually no uniqueness for such a decompostion. For
example, there exists a group G with
G = A1 ‚äïA2 = B1 ‚äïB2 ‚äïB3,
with all the summands indecomposable, with rank(A1) = 1, rank(A2) = 5, and with
rank(B j) = 2 for j = 1, 2, 3. Thus, the number of indecomposable summands in a
decomposition is not uniquely determined by G, nor is the isomorphism class of any of
the indecomposable summands. Here is an interesting theorem of A. L. S. Corner (that
can be used to produce bad examples of torsion-free groups such as the group G just
discussed). Let R be a ring whose additive group is countable, torsion-free, and reduced (it
has no nonzero divisible subgroups). Then there exists an abelian group G, also countable,
torsion-free, and reduced, with End(G) ‚àº= R. Moreover, if the additive group of R has
Ô¨Ånite rank n, then G can be chosen to have rank 2n. For a proof, see Fuchs, InÔ¨Ånite
Abelian Groups II, page 231.
The local approach to commutative rings generalizes the construction of the local rings
Z(p) from Z. Given a subset S of a commutative ring R closed under multiplication, most
authors construct the localization S‚àí1R by generalizing the (tedious) construction of the
fraction Ô¨Åeld of a domain R. They deÔ¨Åne a relation on R √ó S by (r, œÉ) ‚â°(r‚Ä≤, œÉ ‚Ä≤) if there
exists œÉ ‚Ä≤‚Ä≤ ‚ààS with œÉ ‚Ä≤‚Ä≤(rœÉ ‚Ä≤‚àír‚Ä≤œÉ) = 0 (this deÔ¨Ånition reduces to the usual deÔ¨Ånition involv-
ing cross multiplication when R is a domain and S is the subset of all nonzero elements).
After proving that this is an equivalence relation, S‚àí1R is deÔ¨Åned to be the set of all equiva-
lence classes, addition and multiplication are deÔ¨Åned and proved to be well-deÔ¨Åned, all the
R-algebra axioms are veriÔ¨Åed, and the elements of S are shown to be invertible. In other
2An abelian group G is indecomposable if there do not exist nonzero groups A and B with G ‚àº= A ‚äïB.

Sec. 11.1
Local and Global
905
words, we regard the elements of S‚àí1R as fractions with denominators in S. We prefer to
develop the existence and Ô¨Årst properties of S‚àí1R in another manner, which is less tedious
and which will show how the equivalence relation generalizing cross multiplication arises.
DeÔ¨Ånition.
Let R be a commutative ring and let S be any subset of R. A localization
of R is an R-algebra S‚àí1R and an R-algebra map h : R ‚ÜíS‚àí1R, called the localization
map, such that h(s) is invertible in S‚àí1R, for every s ‚ààS, and S‚àí1R is a solution to the
following universal mapping problem.
R
h

œï








S‚àí1R
œï

R‚Ä≤
If R‚Ä≤ is a commutative R-algebra and œï : R ‚ÜíR‚Ä≤ is an R-algebra map for which œï(s) is
invertible in R‚Ä≤ for all s ‚ààS, then there exists a unique R-algebra map œï : S‚àí1R ‚ÜíR‚Ä≤
with œïh = œï.
The localization S‚àí1R, as any solution to a universal mapping problem, is unique up to
isomorphism if it exists.
Theorem 11.11.
For every subset S of a commutative ring R, the localization S‚àí1R
exists.
Proof.
Let X = {xs : s ‚ààS} be a set with xs ‚Üís a bijection X ‚ÜíS, and let R[X] be
the polynomial ring over R with variables X. DeÔ¨Åne
S‚àí1R = R[X]/I,
where I is the ideal generated by {sxs ‚àí1 : s ‚ààS}, and deÔ¨Åne h : R ‚ÜíS‚àí1R by
h : r ‚Üír + I, where r is a constant polynomial. It is clear that S‚àí1R is an R-algebra,
that h is an R-algebra map, and that each h(s) is invertible. Assume now that R‚Ä≤ is an
R-algebra, and that œï : R ‚ÜíR‚Ä≤ is an R-algebra map with œï(s) invertible for all s ‚ààS.
Consider the diagram in which the top arrow Œπ: R ‚ÜíR[X] sends each r ‚ààR to the
constant polynomial r and ŒΩ : R[X] ‚ÜíS‚àí1R is the natural map.
R
Œπ

œï
5...............
h








R[X]
ŒΩ

œï0
(
S‚àí1R
œï

R‚Ä≤
The top triangle commutes because both h and ŒΩŒπ send r ‚ààR to r + I. Since R[X] is
the free commutative R-algebra on X, there is an R-algebra map œï0 : R[X] ‚ÜíR‚Ä≤ with

906
Commutative Rings III
Ch. 11
œï0(xs) = œï(s)‚àí1 for all s ‚ààS. Clearly, I ‚äÜker œï0, for œï0(sxs ‚àí1) = 0, and so there is
an R-algebra map œï : S‚àí1R = R[X]/I ‚ÜíR‚Ä≤ making the diagram commute. That œï is
the unique such map follows from S‚àí1R being generated by im h ‚à™{h(s)‚àí1 : s ‚ààS} as an
R-algebra.
‚Ä¢
The next deÔ¨Ånition is natural in this context, for if s, s‚Ä≤ are invertible elements in some
commutative ring, then their product ss‚Ä≤ is also invertible.
DeÔ¨Ånition.
A subset S of a commutative ring R is multiplicatively closed if 1 ‚ààS and
s, s‚Ä≤ ‚ààS implies ss‚Ä≤ ‚ààS. Every commutative ring is a multiplicative monoid. If S is any
(possibly empty) subset of R, then
S = the submonoid of R generated by S.
We call S the multiplicatively closed subset generated by S.
Exercise 11.8 on page 920 says that (S)‚àí1R ‚àº= S‚àí1R.
Example 11.12.
(i) If R is a commutative ring and s ‚ààR, then {s} = {1, s, s2, s3, . . .} is the multiplicatively
closed set generated by the element s.
(ii) If p is a prime ideal in R, then a /‚ààp and b /‚ààp imply ab /‚ààp. In other words, the
complement R ‚àíp is multiplicatively closed.
(iii) Let P be the set of all primes in Z. If S ‚äÜP, then
S =

pe1
1 ¬∑ ¬∑ ¬∑ pen
n : pi ‚ààS and ei ‚â•0

.
‚óÄ
We now describe the elements in S‚àí1R.
Proposition 11.13.
If S is a subset of a commutative ring R, then each y ‚ààS‚àí1R has a
(not necessarily unique) factorization
y = h(r)h(œÉ)‚àí1,
where r ‚ààR and œÉ ‚ààS.
Proof.
The existence theorem constructs S‚àí1R as R[X]/I, where X = {xs : s ‚ààS} and
I = {sxs ‚àí1 : s ‚ààS}. Thus, each y ‚ààS‚àí1R has the form y = f (x1, . . . , xn) + I, where
xi = xsi for some si ‚ààS. The proposition is proved by induction on n ‚â•0. If n = 0,
then f ‚ààR and y = h( f ). For the inductive step, let y = f (x1, . . . , xn) + I. Write
(x1, . . . , xn‚àí1) = X, xn = x, and
f (X, xn) = g0(X) + g1(X)x + ¬∑ ¬∑ ¬∑ + gm(X)xm,
where gi(X) ‚ààR[X]. In S‚àí1R, we have x = h(s)‚àí1 for some s ‚ààS and, by induction,
gi(X) = h(ri)h(œÉi)‚àí1, where ri ‚ààR and œÉi ‚ààS. Therefore,
y = h(r0)h(œÉ0)‚àí1 + h(r1)h(œÉ1)‚àí1h(s)‚àí1 + ¬∑ ¬∑ ¬∑ + h(rm)h(œÉm)‚àí1h(s)‚àím
= h(s)‚àím
h(r0)h(œÉ0)‚àí1h(s)m + h(r1)h(œÉ1)‚àí1h(s)m‚àí1 + ¬∑ ¬∑ ¬∑ + h(rm)h(œÉm)‚àí1
= h(r‚Ä≤)h(œÉ)‚àí1,

Sec. 11.1
Local and Global
907
where r‚Ä≤ ‚ààR and œÉ = œÉ0œÉ1 ¬∑ ¬∑ ¬∑ œÉmsm ‚ààS. Therefore, y = h(r‚Ä≤)h(œÉ)‚àí1.
‚Ä¢
In light of Proposition 11.13, the elements of S‚àí1R can be regarded as "fractions"
h(r)h(œÉ)‚àí1, where r ‚ààR and œÉ ‚ààS.
Notation. Let h : R ‚ÜíS‚àí1R be the localization map. If r ‚ààR and œÉ ‚ààS, deÔ¨Åne
r/œÉ = h(r)h(œÉ)‚àí1.
In particular, r/1 = h(r).
Is the localization map h : r ‚Üír/1 an injection? The easiest example in which h has a
kernel occurs if 0 ‚ààS (after all, S is allowed to be any subset of R). If 0 is invertible, then
0 = 00‚àí1 = 1, and so S‚àí1R is the zero ring. Thus, h : R ‚ÜíS‚àí1R is the zero map, and
hence it is not injective unless R is the zero ring. The next lemma investigates ker h.
Proposition 11.14.
If S is a subset of a commutative ring R, and if h : R ‚ÜíS‚àí1R is the
localization map, then
ker h = {r ‚ààR : œÉr = 0 for some œÉ ‚ààS}.
Proof.
If œÉr = 0, then 0 = h(œÉ)h(r) in S‚àí1R. Since h(œÉ) is a unit, we have 0 =
h(œÉ)‚àí1h(œÉ)h(r) = h(r), and so r ‚ààker h.
Conversely, suppose that h(r) = 0 in S‚àí1R. Since S‚àí1R = R[X]/I, where I =
(sxs ‚àí1 : s ‚ààS), there is an equation r = n
i=1 fi(X)(si xsi ‚àí1) in R[X]. If S0 =
{s1, . . . , sn}‚à™{nonzero coefÔ¨Åcients of all fi(X)} and h0 : R ‚Üí(S0)‚àí1R is the localization
map, then r ‚ààker h0. In fact, if s = s1 ¬∑ ¬∑ ¬∑ sn and h‚Ä≤ : R ‚Üí{s}‚àí1R is the localization map,
then every h‚Ä≤(si) is invertible, for s‚àí1
i
= s‚àí1s1 ¬∑ ¬∑ ¬∑si ¬∑ ¬∑ ¬∑ sn. Now {s}‚àí1R = R[x]/(sx ‚àí1),
so that r ‚ààker h‚Ä≤ says that there is f (x) = m
i=0 ai xi with
r = f (x)(sx ‚àí1) =
 m

i=0
ai xi
(sx ‚àí1) =
m

i=0

sai xi+1 ‚àíai xi
in R[x].
Expanding and equating coefÔ¨Åcients of like powers of x gives
r = ‚àía0,
sa0 = a1,
. . . ,
sam‚àí1 = am,
sam = 0.
Hence, sr = ‚àísa0 = ‚àía1, and, by induction, sir = ‚àíai for all i. In particular, smr =
‚àíam, and so sm+1r = ‚àísam = 0, as desired.
‚Ä¢
When are two 'fractions" r/œÉ and r‚Ä≤/œÉ ‚Ä≤ equal?
Corollary 11.15.
Let S be a subset of a commutative ring R. If r/œÉ,r‚Ä≤/œÉ ‚Ä≤ ‚ààS‚àí1R, where
œÉ, œÉ ‚Ä≤ ‚ààS, then r/œÉ = r‚Ä≤/œÉ ‚Ä≤ if and only if there exists œÉ ‚Ä≤‚Ä≤ ‚ààS with œÉ ‚Ä≤‚Ä≤(rœÉ ‚Ä≤ ‚àír‚Ä≤œÉ) = 0
in R.

908
Commutative Rings III
Ch. 11
Remark.
If S contains no zero divisors, then œÉ ‚Ä≤‚Ä≤(rœÉ ‚Ä≤‚àír‚Ä≤œÉ) = 0 if and only if rœÉ ‚Ä≤‚àír‚Ä≤œÉ =
0, because œÉ ‚Ä≤‚Ä≤ is a unit, and so rœÉ ‚Ä≤ = r‚Ä≤œÉ.
‚óÄ
Proof.
If r/œÉ = r‚Ä≤/œÉ ‚Ä≤, then multiplying by œÉœÉ ‚Ä≤ gives (rœÉ ‚Ä≤‚àír‚Ä≤œÉ)/1 = 0 in S‚àí1R. Hence,
rœÉ ‚Ä≤ ‚àír‚Ä≤œÉ ‚ààker h, and Proposition 11.14 gives œÉ ‚Ä≤‚Ä≤ ‚ààS with œÉ ‚Ä≤‚Ä≤(rœÉ ‚Ä≤ ‚àír‚Ä≤œÉ) = 0 in R.
Conversely, if œÉ ‚Ä≤‚Ä≤(rœÉ ‚Ä≤ ‚àír‚Ä≤œÉ) = 0 in R for some œÉ ‚Ä≤‚Ä≤ ‚ààS, then h(œÉ ‚Ä≤‚Ä≤)h(rœÉ ‚Ä≤ ‚àír‚Ä≤œÉ) = 0
in S‚àí1R. As h(œÉ ‚Ä≤‚Ä≤) is a unit, we have h(r)h(œÉ ‚Ä≤) = h(r‚Ä≤)h(œÉ); as h(œÉ) and h(œÉ ‚Ä≤) are units,
h(r)h(œÉ)‚àí1 = h(r‚Ä≤)h(œÉ ‚Ä≤)‚àí1; that is, r/œÉ = r‚Ä≤/œÉ ‚Ä≤.
‚Ä¢
Corollary 11.16.
Let S be a subset of a commutative ring R.
(i) If S contains no zero divisors, then the localization map h : R ‚ÜíS‚àí1R is an injec-
tion.
(ii) If R is a domain with Q = Frac(R), then S‚àí1R ‚äÜQ. Moreover, if S = R ‚àí{0},
then S‚àí1R = Q.
Proof.
(i) This follows easily from Proposition 11.14.
(ii) The localization map h : R ‚ÜíS‚àí1R is an injection, by Proposition 11.14. Consider
the diagram
R
h

œï







S‚àí1R
œï

Q
where œï is the inclusion. If œï(h(r)h(œÉ)‚àí1) = 0, then œï(h(r)) = 0, because h(œÉ) is a unit
in S‚àí1R. But commutativity of the diagram gives œïh(r) = œï(r). As œï is an injection,
r = 0; hence, h(r)h(œÉ)‚àí1 = 0, and so œï is an injection.
‚Ä¢
As a consequence of Corollary 11.16(ii), when R is a domain and S is a multiplicatively
closed subset not containing 0, then S‚àí1R consists of all elements a/s ‚ààFrac(R) with
a ‚ààR and s ‚ààS.
Let us now investigate the ideals in S‚àí1R.
DeÔ¨Ånition.
If S is a subset of a commutative ring R, and if I is an ideal in R, then we
denote the ideal in S‚àí1R generated by h(I) by S‚àí1I.
Example 11.17.
(i) If S is a subset of a commutative ring R, and if I is an ideal in R containing an element
œÉ ‚ààS‚Äîthat is, I ‚à©S Ã∏= ‚àÖ, then S‚àí1I contains œÉ/œÉ = 1, and so S‚àí1I = S‚àí1R.
(ii) Let S consist of all the odd integers [that is, S is the complement of the prime ideal
(2)], let I = (3), and let I ‚Ä≤ = (5). Then S‚àí1I = S‚àí1Z = S‚àí1I ‚Ä≤. Therefore, the function
from the ideals in Z to the ideals in S‚àí1Z = Z(2), given by I ‚ÜíS‚àí1I, is not injective.

Sec. 11.1
Local and Global
909
In the next corollary, we will see an improvement when we restrict our attention to prime
ideals contained in (2).
‚óÄ
Corollary 11.18.
Let S be a subset of a commutative ring R.
(i) Every ideal J in S‚àí1R is of the form S‚àí1I for some ideal I in R. In fact, if R is a
domain and I = J ‚à©R, then J = S‚àí1I; in the general case, if I = h‚àí1(h(R) ‚à©J),
then J = S‚àí1I.
(ii) If I is an ideal in R, then S‚àí1I = S‚àí1R if and only if I ‚à©S Ã∏= ‚àÖ.
(iii) If q is a prime ideal in R with q ‚à©S = ‚àÖ, then S‚àí1q is a prime ideal in S‚àí1R.
(iv) The function q ‚ÜíS‚àí1q is a bijection from the family of all prime ideals in R that
are disjoint from S to Spec(S‚àí1R).
(v) If R is noetherian, then S‚àí1R is also noetherian.
Proof.
(i) Let J = ( jŒª : Œª ‚àà.). By Proposition 11.14, we have jŒª = h(rŒª)h(œÉŒª)‚àí1,
where rŒª ‚ààR and œÉŒª ‚ààS. DeÔ¨Åne I to be the ideal in R generated by {rŒª : Œª ‚àà.}; that is,
I = h‚àí1(h(R) ‚à©J). It is clear that S‚àí1I = J; in fact, since all œÉŒª are units in S‚àí1R, we
have J = (h(rŒª) : Œª ‚àà.).
(ii) If œÉ ‚ààI ‚à©S, then œÉ/1 ‚ààS‚àí1I. But œÉ/1 is a unit in S‚àí1R, and so S‚àí1I = S‚àí1R.
Conversely, if S‚àí1I = S‚àí1R, then h(a)h(œÉ)‚àí1 = 1 for some a ‚ààI and œÉ ‚ààS. Therefore,
œÉ ‚àía ‚ààker h, and so there is œÉ ‚Ä≤‚Ä≤ ‚ààS with œÉ ‚Ä≤‚Ä≤(œÉ ‚àía) = 0. Therefore, œÉ ‚Ä≤‚Ä≤œÉ = œÉ ‚Ä≤‚Ä≤a ‚ààI.
Since S is multiplicatively closed, œÉ ‚Ä≤‚Ä≤œÉ ‚ààI ‚à©S.
(iii) Suppose that q is a prime ideal in R. First, S‚àí1q is a proper ideal, for q ‚à©S = ‚àÖ.
If (a/œÉ)(b/œÑ) = q/œâ, where a, b ‚ààR and œÉ, œÑ, œâ ‚ààS, then there is œÉ ‚Ä≤‚Ä≤ ‚ààS with
œÉ ‚Ä≤‚Ä≤(œâab ‚àíœÉœÑq) = 0. Hence, œÉ ‚Ä≤‚Ä≤œâab ‚ààq. Now œÉ ‚Ä≤‚Ä≤œâ /‚ààq (because œÉ ‚Ä≤‚Ä≤œâ ‚ààS and
S ‚à©q = ‚àÖ); hence, ab ‚ààq (because q is prime). Thus, either a or b lies in q, and either
a/œÉ or b/œÑ lies in S‚àí1q. Therefore, S‚àí1q is a prime ideal.
(iv) Suppose that p and q are prime ideals in R with S‚àí1p = S‚àí1q; we may assume that
p ‚à©S = ‚àÖ= q ‚à©S. If a ‚ààp, then there is b ‚ààq and œÉ ‚ààS with a/1 = b/œÉ.
Hence, œÉa ‚àíb ‚ààker h, where h is the localization map, and so there is œÉ ‚Ä≤ ‚ààS with
œÉ ‚Ä≤œÉa = œÉ ‚Ä≤b ‚ààq. But œÉ ‚Ä≤œÉ ‚ààS, so that œÉ ‚Ä≤œÉ /‚ààq. Since q is prime, we have a ‚ààq; that is,
p ‚äÜq. The reverse inclusion is proved similarly.
Let P be a prime ideal in S‚àí1R. By part (i), there is some ideal I in R with P = S‚àí1I.
We must show that I can be chosen to be a prime ideal in R. Now h(R) ‚à©P is a prime
ideal in h(R), and so p = h‚àí1(h(R) ‚à©P) is a prime ideal in R. By part (i), P = S‚àí1p.
(v) If J is an ideal in S‚àí1R, then part (i) shows that J = S‚àí1I for some ideal I in R. Since
R is noetherian, we have I = (r1, . . . ,rn), and so J = (r1/1, . . . ,rn/1). Hence, every
ideal in S‚àí1R is Ô¨Ånitely generated, and so S‚àí1R is noetherian.
‚Ä¢
DeÔ¨Ånition.
If p is a prime ideal in a commutative ring R, then the complement S = R‚àíp
is multiplicatively closed, and S‚àí1R is denoted by Rp.

910
Commutative Rings III
Ch. 11
Example 11.19.
If p is a prime in Z, then p = (p) is a prime ideal, and Zp = Z(p).
‚óÄ
Proposition 11.20.
If R is a domain, then 
m Rm = R, where the intersection is over
all the maximal ideals m in R.
Proof.
Since R is a domain, Rm ‚äÜFrac(R) for all m, and so the intersection in the
statement is deÔ¨Åned. Moreover, it is plain that R ‚äÜRm for all m, so that R ‚äÜ
m Rm.
For the reverse inclusion, let a ‚àà Rm. DeÔ¨Åne
I = (R : a) = {r ‚ààR : ra ‚ààR}.
If I = R, then 1 ‚ààI, and a = 1a ‚ààR, as desired. If I is a proper ideal, then there
exists a maximal ideal m with I ‚äÜm. Now a/1 ‚ààRm, so there is r ‚ààR and œÉ /‚ààm with
a/1 = r/œÉ; that is, œÉa = r ‚ààR. Hence, œÉ ‚ààI ‚äÜm, contradicting œÉ /‚ààm. Therefore,
R = 
m Rm.
‚Ä¢
The next proposition explains why S‚àí1R is called localization.
Proposition 11.21.
If p is a prime ideal in a commutative ring R, then Rp is a local ring
with maximal ideal pRp = {r/s : r ‚ààp and s /‚ààp}.
Proof.
If x ‚ààRp, then x = r/s, where r ‚ààR and s /‚ààp. If r /‚ààp, then r/s is a unit in
Rp; that is, all nonunits lie in pRp. Hence, if I is any ideal in Rp that contains an element
r/s with r /‚ààp, then I = Rp. It follows that every proper ideal in Rp is contained in pRp,
and so Rp is a local ring with unique maximal ideal pRp.
‚Ä¢
The fundamental assumption underlying the local/global strategy is that the local case
is simpler than the global. The structure of projective modules over a general ring can be
quite complicated, but the next proposition shows that projective modules over local rings
are free.
Lemma 11.22.
Let R be a local ring with maximal ideal m. An element r ‚ààR is a unit
if and only if r /‚ààm.
Proof.
It is clear that if r is a unit, then r /‚ààm, for m is a proper ideal. Conversely, assume
that r is not a unit. By Zorn's lemma, there is a maximal ideal containing the principal ideal
(r). Since R is local, there is only one maximal ideal, namely, m, and so r ‚ààm.
‚Ä¢
Proposition 11.23.
If R is a local ring, then every Ô¨Ånitely generated 3 projective R-
module B is free.
Proof.
Let R be a local ring with maximal ideal m, and let {b1, . . . , bn} be a minimal set
of generators of B; that is, B cannot be generated by fewer than n elements. Let F be the
3It is a theorem of Kaplansky that the Ô¨Åniteness hypothesis can be omitted: Every projective module over a
local ring is free. He even proves freeness when R is a noncommutative local ring.

Sec. 11.1
Local and Global
911
free R-module with basis x1, . . . , xn, and deÔ¨Åne œï : F ‚ÜíB by œï(xi) = bi for all i. Thus,
there is an exact sequence
0 ‚ÜíK ‚ÜíF
œï
‚àí‚ÜíB ‚Üí0,
(1)
where K = ker œï.
We claim that K ‚äÜmF. If, on the contrary, K ‚äämF, there is an element y =
n
i=1 ri xi ‚ààK which is not in mF; that is, some coefÔ¨Åcient, say, r1 /‚ààm. Now r1
is a unit, by Lemma 11.22. Now y ‚ààK = ker œï gives ribi = 0. Hence, b1 =
‚àír‚àí1
1
n
i=2 ribi

, which implies that B = ‚ü®b2, . . . , bn‚ü©, contradicting the minimality of
the original generating set.
Returning to the exact sequence (1), projectivity of B gives F = K ‚äïB‚Ä≤, where B‚Ä≤ is
a submodule of F with B‚Ä≤ ‚àº= B. Hence, mF = mK ‚äïmB‚Ä≤. Since mK ‚äÜK ‚äÜmF,
Corollary 7.18 gives
K = mK ‚äï(K ‚à©mB‚Ä≤).
But K ‚à©mB‚Ä≤ ‚äÜK ‚à©B‚Ä≤ = {0}, so that K = mK. The submodule K is Ô¨Ånitely generated,
being a summand (and hence a homomorphic image) of the Ô¨Ånitely generated module F, so
that Nakayama's lemma (Corollary 8.32) gives K = {0}. Therefore, œï is an isomorphism
and B is free.
‚Ä¢
Having localized a commutative ring, we now localize its modules. If M is an R-module
and s ‚ààR, let ¬µs denote the multiplication map M ‚ÜíM deÔ¨Åned by m ‚Üísm. Note that
if S is a subset of R, then ¬µs : M ‚ÜíM is invertible for every s ‚ààS if and only if M is an
S‚àí1R-module.
DeÔ¨Ånition.
Let R be a commutative ring and let S be any subset of R. A localization of
an R-module M is an S‚àí1R-module S‚àí1M (i.e.., ¬µs : S‚àí1m ‚ÜíS‚àí1M is invertible for all
s ‚ààS) and an R-map hM : M ‚ÜíS‚àí1M, called the localization map, which is a solution
to the following universal mapping problem:
M
h

œï
+
+
+
+
+
+
+
+
S‚àí1M
œï

M‚Ä≤
If œï : M ‚ÜíM‚Ä≤ is an R-map, where M‚Ä≤ is an S‚àí1R-module, then there is a unique S‚àí1R-
map œï : S‚àí1M ‚ÜíM‚Ä≤ making the diagram commute.
The obvious candidate for S‚àí1M‚Äînamely, S‚àí1R ‚äóR M‚Äîis, in fact, its localization.
Proposition 11.24.
Let R be a commutative ring, let S be any subset of R, and let M
be an R-module. Then S‚àí1R ‚äóR M and the R-map h : M ‚ÜíS‚àí1R ‚äóR M, given by
m ‚Üí1 ‚äóm, is a localization of M.

912
Commutative Rings III
Ch. 11
Proof.
Let œï : M ‚ÜíM‚Ä≤ be an R-map, where M‚Ä≤ is an S‚àí1R-module. The function
S‚àí1R √ó M ‚ÜíM‚Ä≤, deÔ¨Åned by (r/œÉ, m) ‚Üí(r/œÉ)œï(m), where r ‚ààR and œÉ ‚ààS, is
easily seen to be R-bilinear. Hence, there is a unique R-map œï : S‚àí1R ‚äóR M ‚ÜíM‚Ä≤ with
œïh = œï. Since h(M) generates S‚àí1R ‚äóR M, œï is the unique R-map making the diagram
commute. We let the reader check that œï is an S‚àí1R-map.
‚Ä¢
One of the most important properties of S‚àí1R is that it is Ô¨Çat as an R-module. To prove
this, we Ô¨Årst generalize the argument in Proposition 11.14.
Proposition 11.25.
If S is a subset of a commutative ring R, if M is an R-module, and if
hM : M ‚ÜíS‚àí1M is the localization map, then
ker hM = {m ‚ààM : œÉm = 0 for some œÉ ‚ààS}.
Proof.
Denote {m ‚ààM : œÉm = 0 for some œÉ ‚ààS} by K. If œÉm = 0, for m ‚ààM
and œÉ ‚ààS, then hM(m) = (1/œÉ)hM(œÉm) = 0, and so K ‚äÜker hM. For the reverse
inclusion, proceed as in Proposition 11.14: If m ‚ààK, there is œÉ ‚ààS with œÉm = 0.
Reduce to the case S = {œÉ} for some œÉ ‚ààS, so that S‚àí1R = R[x]/(œÉ x ‚àí1). Now
R[x]‚äóR M ‚àº=

i Rxi ‚äóR M, because R[x] is the free R-module with basis {1, x, x2, . . .}.
Hence, each element in R[x]‚äóR M has a unique expression of the form 
i xi ‚äómi, where
mi ‚ààM. In particular, if m ‚ààker hM, then
0 = 1 ‚äóm = (œÉ x ‚àí1)
n

i=0
xi ‚äómi =
n

i=0
(œÉ xi+1 ‚äómi ‚àíxi ‚äómi).
The proof now Ô¨Ånishes as the proof of Proposition 11.14. Expanding and equating coefÔ¨Å-
cients gives equations
1 ‚äóm = ‚àí1 ‚äóm0, x ‚äóœÉm0 = x ‚äóm1, . . . ,
xn ‚äóœÉmn‚àí1 = xn ‚äómn, xn+1 ‚äóœÉmn = 0.
It follows that
m = ‚àím0,
œÉm0 = m1,
. . .
œÉmn‚àí1 = mn,
œÉmn = 0.
Hence, œÉm = ‚àíœÉm0 = ‚àím1, and, by induction, œÉ im = ‚àími for all i. In particular,
œÉ nm = ‚àímn and so œÉ n+1m = ‚àíœÉmn = 0 in M. Therefore, ker hM ‚äÜK, as desired.
‚Ä¢
Corollary 11.26.
Let S be a subset of a commutative ring R and let M be an R-module.
(i) Every element u ‚ààS‚àí1M has the form u = œÉ ‚àí1m for some œÉ ‚ààS and some m ‚ààM.
(ii) s‚àí1
1 m1 = s‚àí1
2 m2 in S‚àí1M if and only if œÉ(s‚àí1
1 m1 ‚àís‚àí1
2 m2) in M for some œÉ ‚ààS.

Sec. 11.1
Local and Global
913
Proof.
(i) If u ‚ààS‚àí1M, then u = 
i(ri/œÉi)mi, where ri ‚ààR, œÉi ‚ààS, and mi ‚ààM. If
we deÔ¨Åne œÉ =  œÉi and œÉi = 
jÃ∏=i œÉ j, then
u =

(1/œÉi)rimi
=

(œÉi/œÉ)rimi
= (1/œÉ)

œÉirimi
= (1/œÉ)m,
where m = œÉirimi ‚ààM.
(ii) If œÉ ‚ààS with œÉ(s2m1 ‚àís1m2) = 0 in M, then (œÉ/1)(s2m1 ‚àís1m2) = 0 in S‚àí1M. As
œÉ/1 is a unit, s2m1 ‚àís1m2 = 0, and so s‚àí1
1 m1 = s‚àí1
2 m2.
Conversely, if s‚àí1
1 m1 = s‚àí1
2 m2 in S‚àí1M, then (1/s1s2)(s2m1 ‚àís1m2) = 0. Since
1/s1s2 is a unit, we have (s2m1 ‚àís1m2) = 0 and s2m1 ‚àís1m2 ‚ààker hM. By Proposi-
tion 11.25, there exists œÉ ‚ààS with œÉ(s2m1 ‚àís1m2) = 0 in M.
‚Ä¢
Corollary 11.27.
Let S be a subset of a commutative ring R. If A is an S‚àí1R-module,
then A ‚àº= S‚àí1 A.
Proof.
DeÔ¨Åne œï : A ‚ÜíS‚àí1 A by a ‚Üí1 ‚äóa. If œï(a) = 0, then there is œÉ ‚ààS with
œÉa = 0. Since œÉ is a unit in S‚àí1R and A is an S‚àí1R-module, the equation a = œÉ ‚àí1œÉa =
0 makes sense in A. Hence, œï is an injection. To see that œï is a surjection, note that
(1/œÉ) ‚äóa = œï(œÉ ‚àí1a).
‚Ä¢
Theorem 11.28.
If S is a subset of a commutative ring R, then S‚àí1R is a Ô¨Çat R-module.
Proof.
We must show that if 0 ‚ÜíA
f
‚àí‚ÜíB is exact, then so is
0 ‚ÜíS‚àí1R ‚äóR A
1‚äóf
‚àí‚ÜíS‚àí1R ‚äóR B.
Let u ‚ààker(1 ‚äóf ); by Corollary 11.26, u = œÉ ‚àí1 ‚äóa for some œÉ ‚ààS and a ‚ààA. Now
0 = (1 ‚äóf )(u) = œÉ ‚àí1 ‚äóf (a), so that f (a) ‚ààker hM. By Proposition 11.25, there is
œÑ ‚ààS with 0 = œÑ f a = f (œÑa). Thus, œÑa ‚ààker f = {0}, because f is an injection.
Therefore, 0 = 1 ‚äóœÑa = œÑ(1 ‚äóa) = œÑu. Finally, u = 0, because œÑ is a unit. Therefore,
1 ‚äóf is an injection, and so S‚àí1R is a Ô¨Çat R-module.
‚Ä¢
Corollary 11.29.
If S is a subset of a commutative ring R, then localization M ‚Üí
S‚àí1M = S‚àí1R ‚äóR M deÔ¨Ånes an exact functor RMod ‚ÜíS‚àí1RMod.
Proof.
Localization is the functor S‚àí1R‚äóR , and it is exact because S‚àí1R is a Ô¨Çat R-
module.
‚Ä¢
Notation. In the special case S = R ‚àíp, where p is a prime ideal in R, we write
S‚àí1M = Mp.

914
Commutative Rings III
Ch. 11
If f : M ‚ÜíN is an R-map, write fp : Mp ‚ÜíNp, where fp = 1Rp ‚äóf .
We restate Corollary 11.18(iv) in this notation. The function q ‚Üíqp is a bijection from
the family of all prime ideals in R that are contained in p to Spec(Rp) (see Exercise 6.67
on page 398).
Here are some globalization results.
Proposition 11.30.
Let I and J be ideals in a domain R. If Im = Jm for every maximal
ideal m, then I = J.
Proof.
Take b ‚ààJ, and deÔ¨Åne
(I : b) = {r ‚ààR : rb ‚ààI}.
Let m be a maximal ideal in R. Since Im = Jm, there are a ‚ààI and s /‚ààm with b/1 = a/s.
As R is a domain, sb = a ‚ààI, so that s ‚àà(I : b); but s /‚ààm, so that (I : b) ‚ääm. Thus,
(I : b) cannot be a proper ideal, for it is not contained in any maximal ideal. Therefore,
(I : b) = R; hence, 1 ‚àà(I : b) and b = 1b ‚ààI. We have proved that J ‚äÜI, and the
reverse inclusion is proved similarly.
‚Ä¢
Proposition 11.31.
Let R be a commutative ring.
(i) If M is an R-module with Mm = {0} for every maximal ideal m, then M = {0}.
(ii) If f : M ‚ÜíN is an R-map and fm : Mm ‚ÜíNm is an injection for every maximal
ideal m, then f is an injection.
(iii) If f : M ‚ÜíN is an R-map and fm : Mm ‚ÜíNm is a surjection for every maximal
ideal m, then f is a surjection.
(iv) If f : M ‚ÜíN is an R-map and fm : Mm ‚ÜíNm is an isomorphism for every
maximal ideal m, then f is an isomorphism.
Proof.
(i) If M Ã∏= {0}, then there is m ‚ààM with m Ã∏= 0. It follows that the annihilator
I = {r ‚ààR : rm = 0} is a proper ideal in R, for 1 /‚ààI, and so there is some maximal
ideal m containing I. Now 1 ‚äóm = 0 in Mm, so that m ‚ààker hM. Proposition 11.25 gives
s /‚ààm with sm = 0 in M, for R ‚àím is multiplicatively closed. Hence, s ‚ààI ‚äÜm, and
this is a contradiction. Therefore, M = {0}.
(ii) There is an exact sequence 0 ‚ÜíK ‚ÜíM
f
‚àí‚ÜíN, where K = ker f . Since localization
is an exact functor, there is an exact sequence
0 ‚ÜíKm ‚ÜíMm
fm
‚àí‚ÜíNm
for every maximal ideal m. By hypothesis, each fm is an injection, so that Km = {0} for
all maximal ideals m. Part (i) now shows that K = {0}, and so f is an injection.
(iii) There is an exact sequence M
f
‚àí‚ÜíN ‚ÜíC ‚Üí0, where C = coker f = N/ im f .
Since tensor product is right exact, Cm = {0} for all maximal ideals m, and so C = {0}.
But f is surjective if and only if C = coker f = {0}.
(iv) This follows at once from parts (ii) and (iii).
‚Ä¢

Sec. 11.1
Local and Global
915
We cannot weaken the hypothesis of Proposition 11.31(iv) to Mm ‚àº= Nm for all maximal
ideals m; we must assume that all the local isomorphisms arise from a given map f : M ‚Üí
N. If G is the subgroup of Q consisting of all a/b with b squarefree, then we saw, in
Example 11.5, that G(p) ‚àº= Z(p) for all primes p, but G Ã∏‚àº= Z.
Exercises 11.20 and 11.22 on page 921 show that localization preserves projectives and
Ô¨Çats; that is, if A is a projective R-module, then S‚àí1 A is a projective (S‚àí1R)-module, and
if B is a Ô¨Çat R-module, then S‚àí1B is a Ô¨Çat (S‚àí1R)-module. Preserving injectivity is more
subtle.
Lemma 11.32.
Let S be a subset of a commutative ring R, and let M and A be R-modules
with A Ô¨Ånitely presented. Then there is a natural isomorphism
œÑA : S‚àí1 HomR(A, M) ‚ÜíHomS‚àí1R(S‚àí1 A, S‚àí1M).
Proof.
It sufÔ¨Åces to construct natural isomorphisms
Œ∏A : HomR(A, S‚àí1M) ‚ÜíHomS‚àí1R(S‚àí1 A, S‚àí1M)
and
œïA : S‚àí1 HomR(A, M) ‚ÜíHomR(A, S‚àí1M),
for then we can deÔ¨Åne œÑA = Œ∏AœïA.
Assume Ô¨Årst that A = Rn is a Ô¨Ånitely generated free R-module. If a1, . . . , an is a basis
of A, then a1/1, . . . , an/1 is a basis of S‚àí1 A = S‚àí1R ‚äóR Rn. The map
Œ∏Rn : HomR(A, S‚àí1M) ‚ÜíHomS‚àí1R(S‚àí1 A, S‚àí1M),
given by f ‚Üíf , where f (ai/œÉ) = f (ai)/œÉ, is easily seen to be a well-deÔ¨Åned R-
isomorphism.
If, now, A is a Ô¨Ånitely presented R-module, then there is an exact sequence
Rt ‚ÜíRn ‚ÜíA ‚Üí0.
(2)
Applying the contravariant functors HomR( , M‚Ä≤) and HomS‚àí1R( , M‚Ä≤), where M‚Ä≤ =
S‚àí1M is Ô¨Årst viewed as an R-module, gives a commutative diagram with exact rows
0
 HomR(A, M‚Ä≤)

Œ∏A

HomR(Rn, M‚Ä≤)

Œ∏Rn

HomR(Rt, M‚Ä≤)
Œ∏Rt

0
 HomS‚àí1R(S‚àí1 A, M‚Ä≤)
 HomS‚àí1R((S‚àí1R)n, M‚Ä≤)
 HomS‚àí1R((S‚àí1R)t, M‚Ä≤).
Since the vertical maps Œ∏Rn and Œ∏Rt are isomorphisms, there is a dotted arrow Œ∏A which
must be an isomorphism, by Proposition 8.94. If Œ≤ ‚ààHomR(A, M), then the reader may
check that
Œ∏A(Œ≤) = Œ≤ : a/œÉ ‚ÜíŒ≤(a)/œÉ,

916
Commutative Rings III
Ch. 11
from which it follows that the isomorphisms Œ∏A are natural.
Construct œïA : S‚àí1 HomR(A, M) ‚ÜíHomR(A, S‚àí1M) by deÔ¨Åning œïA : g/œÉ ‚ÜígœÉ,
where gœÉ(a) = g(a)/œÉ. Note that œïA is well-deÔ¨Åned, for it arises from the R-bilinear
function S‚àí1R√óHomR(A, M) ‚ÜíHomR(A, S‚àí1M) given by (r/œÉ, g) ‚ÜírgœÉ (remember
that S‚àí1 HomR(A, M) = S‚àí1R ‚äóR HomR(A, M)). Observe that œïA is an isomorphism
when A is Ô¨Ånitely generated free, and consider the commutative diagram
0
 S‚àí1 HomR(A, M)

œïA

S‚àí1 HomR(Rn, M)

œïRn

S‚àí1 HomR(Rt, M)
œïRt

0
 HomR(A, S‚àí1M)
 HomR(Rn, S‚àí1M)
 HomR(Rt, S‚àí1M).
The top row is exact, for it arises from Eq. (2) by Ô¨Årst applying the left exact contravari-
ant functor HomR( , M), and then applying the exact localization functor. The bottom
row is exact, for it arises from Eq. (2) by applying the left exact contravariant functor
HomR( , S‚àí1M). The Ô¨Åve lemma, Exercise 8.52 on page 604, shows that œïA is an isomor-
phism.
‚Ä¢
Example 11.33.
Lemma 11.32 can be false if A is not Ô¨Ånitely presented. For example, let R = Z and
S‚àí1R = Q. We claim that
Q ‚äóZ HomZ(Q, Z) Ã∏‚àº= HomQ(Q ‚äóZ Q, Q ‚äóZ Z).
The left-hand side is {0} because HomZ(Q, Z) = {0}. On the other hand, the right-hand
side is HomZ(Q, Q) ‚àº= Q.
‚óÄ
Proposition 11.34.
If S is a subset of a commutative noetherian ring R, and if E is an
injective R-module, then S‚àí1E is an injective (S‚àí1R)-module.
Remark.
This result can fail if R is not noetherian. If k is a Ô¨Åeld and R = k[X], where X
is an uncountable set of variables, then there exists an injective R-module E and a subset
S of R such that S‚àí1E is not an injective (S‚àí1R)-module (see E. C. Dade, "Localization
of Injective Modules," Journal of Algebra 69 (1981), 416-425).
‚óÄ
Proof.
By the Baer criterion, Theorem 7.68, it sufÔ¨Åces to prove that
i‚àó: HomS‚àí1R(S‚àí1R, S‚àí1E) ‚ÜíHomS‚àí1R(J, S‚àí1E)
is surjective for every ideal J in S‚àí1R, where i : J ‚ÜíS‚àí1R is the inclusion. Now every
ideal J in S‚àí1R has the form J = S‚àí1I, by Corollary 11.18, where I is an ideal in R.
Since R is noetherian, every ideal is a Ô¨Ånitely presented R-module, and so Lemma 11.32

Sec. 11.1
Local and Global
917
applies to give a commutative diagram whose vertical arrows are isomorphisms
S‚àí1 HomR(R, E)

œÑR

S‚àí1 HomR(I, E)
œÑI

HomS‚àí1R(S‚àí1R, S‚àí1E)
i‚àó
 HomS‚àí1R(S‚àí1I, S‚àí1E).
Injectivity of E implies that HomR(R, E) ‚ÜíHomR(I, E) is surjective (where the arrow
is induced from the inclusion I ‚ÜíR), so that exactness of localization shows that the
arrow in the top row is surjective. Since the vertical arrows are isomorphisms, the arrow in
the bottom row is surjective. Therefore, J = S‚àí1I is an injective (S‚àí1R)-module.
‚Ä¢
Localization commutes with Tor, essentially because S‚àí1R is a Ô¨Çat R-module.
Proposition 11.35.
If S is a subset of a commutative ring R, then there are isomorphisms
S‚àí1 TorR
n (A, B) ‚àº= TorS‚àí1R
n
(S‚àí1 A, S‚àí1B)
for all n ‚â•0 and for all R-modules A and B.
Proof.
First consider the case n = 0. For Ô¨Åxed R-module A, there is a natural isomor-
phism
œÑB : S‚àí1(A ‚äóR B) ‚ÜíS‚àí1 A ‚äóS‚àí1R S‚àí1B,
for either is a solution U of the universal mapping problem
S‚àí1 A √ó S‚àí1B

f
*%
%
%
%
%
%
%
%
%
%
%
U,
f

M
where M is an (S‚àí1R)-module, f is (S‚àí1R)-bilinear, and f is an (S‚àí1R)-map.
If PB is a deleted projective resolution of B, then exactness of localization, together with
localization preserving projectives, show that S‚àí1(PB) is a deleted projective resolution of
S‚àí1B. Naturality of the isomorphisms œÑA gives an isomorphism of complexes
S‚àí1(A ‚äóR PB) ‚àº= S‚àí1 A ‚äóS‚àí1R S‚àí1(PB),
so that their homology groups are isomorphic. Since localization is an exact functor, Propo-
sition 10.38 applies, and
Hn(S‚àí1(A ‚äóR PB)) ‚àº= S‚àí1Hn(A ‚äóR PB) ‚àº= S‚àí1 TorR
n (A, B).
On the other hand, since S‚àí1(PB) is a deleted projective resolution of S‚àí1B, the deÔ¨Ånition
of Tor gives
Hn(S‚àí1 A ‚äóS‚àí1R S‚àí1(PB)) ‚àº= TorS‚àí1R
n
(S‚àí1 A, S‚àí1B).
‚Ä¢

918
Commutative Rings III
Ch. 11
Corollary 11.36.
Let A be an R-module over a commutative ring R. If Am is a Ô¨Çat
Rm-module for every maximal ideal m, then A is a Ô¨Çat R-module.
Proof.
The hypothesis, together with Proposition 10.96, give TorRm
n (Am, Bm) = {0} for
all n ‚â•1, for every R-module B, and for every maximal ideal m. But Proposition 11.35
gives TorR
n (A, B)m = {0} for all maximal ideals m and all n ‚â•1. Finally, Proposi-
tion 11.31 shows that TorR
n (A, B) = {0} for all n ‚â•1. Since this is true for all R-modules
B, we have A Ô¨Çat.
‚Ä¢
We must add some hypotheses to get a similar result for Ext (see Exercise 11.23 on
page 921).
Lemma 11.37.
If R is a left noetherian ring and A is a Ô¨Ånitely generated left R-module,
then there is a projective resolution P‚Ä¢ of A in which each Pn is Ô¨Ånitely generated.
Proof.
Since A is Ô¨Ånitely generated, there exists a Ô¨Ånitely generated free left R-module
P0 and a surjective R-map Œµ: P0 ‚ÜíA. Since R is left noetherian, ker Œµ is Ô¨Ånitely gener-
ated, and so there exists a Ô¨Ånitely generated free left R-module P1 and a surjective R-map
d1 : P1 ‚Üíker Œµ. If we deÔ¨Åne D1 : P1 ‚ÜíP0 as the composite id1, where i : ker Œµ ‚ÜíP0 is
the inclusion, then there is an exact sequence
0 ‚Üíker D1 ‚ÜíP1
D1
‚àí‚ÜíP0
Œµ
‚àí‚ÜíA ‚Üí0.
This construction can be iterated, for ker D1 is Ô¨Ånitely generated, and the proof can be
completed by induction. (We remark that we have, in fact, constructed a free resolution
of A.)
‚Ä¢
Proposition 11.38.
Let S be a subset of a commutative noetherian ring R. If A is a
Ô¨Ånitely generated R-module, then there are isomorphisms
S‚àí1 Extn
R(A, B) ‚àº= Extn
S‚àí1R(S‚àí1 A, S‚àí1B)
for all n ‚â•0 and for all R-modules B.
Proof.
Since R is noetherian and A is Ô¨Ånitely generated, Lemma 11.37 says there is a
projective resolution P of A each of whose terms is Ô¨Ånitely generated. By Lemma 11.32,
there is a natural isomorphism
œÑA : S‚àí1 HomR(A, B) ‚ÜíHomS‚àí1R(S‚àí1 A, S‚àí1B)
for every R-module B (a Ô¨Ånitely generated module over a noetherian ring must be Ô¨Ånitely
presented). Now œÑA gives an isomorphism of complexes
S‚àí1(HomR(PA, B)) ‚àº= HomS‚àí1R(S‚àí1(PA), S‚àí1B).
Taking homology of the left hand side gives
Hn(S‚àí1(HomR(PA, B))) ‚àº= S‚àí1Hn(HomR(PA, B)) ‚àº= S‚àí1 Extn
R(A, B),

Sec. 11.1
Local and Global
919
because localization is an exact functor (Proposition 10.38). On the other hand, homology
of the right hand side is
Hn(HomS‚àí1R(S‚àí1(PA), S‚àí1B)) = Extn
S‚àí1R(S‚àí1 A, S‚àí1B),
because S‚àí1(PA) is an (S‚àí1R)-projective resolution of S‚àí1 A.
‚Ä¢
Remark.
An alternative proof of the Proposition 11.38 can be given using a deleted
injective resolution EB in the second variable. We must still assume that A is Ô¨Ånitely
generated, in order to use Lemma 11.32, but now we use the fact, when R is noetherian,
that localization preserves injectives.
‚óÄ
Corollary 11.39.
Let A be a Ô¨Ånitely generated R-module over a commutative noetherian
ring R. Then Am is a projective Rm-module for every maximal ideal m if and only if A is
a projective R-module.
Proof.
SufÔ¨Åciency is Exercise 11.20 on page 921, and necessity follows from Proposi-
tion 11.38: For every R-module B and maximal ideal m, we have
Ext1
R(A, B)m ‚àº= Ext1
Rm(Am, Bm) = {0},
because Am is projective. By Proposition 11.31, Ext1
R(A, B) = {0}, which says that A is
projective.
‚Ä¢
EXERCISES
11.1 Prove that Z(p) Ã∏‚àº= Q as Z(p)-modules.
11.2 If R is a domain with Q = Frac(R), prove that every R-subalgebra A of Q is a localization
of R.
Hint. DeÔ¨Åne S = {b ‚ààR : 1/b ‚ààA}.
11.3 Prove that the following statements are equivalent for a torsion-free abelian group G of rank 1.
(i) G is Ô¨Ånitely generated.
(ii) G is cyclic.
(iii) If x ‚ààG is nonzero, then h p(x) = 0 for almost all p and h p(x) Ã∏= ‚àûfor all primes p.
(iv) œÑ(G) = œÑ(Z).
11.4
(i) If G is a torsion-free abelian group of rank 1, prove that the additive group of End(G)
is torsion-free of rank 1.
(ii) Let x ‚ààG be nonzero with œá(x) = (h2(x), h3(x), . . . , h p(x), . . .), and let R be the
subring of Q in which œá(1) = (k2, k3, . . . , kp, . . .) and
kp =

‚àû
if h p(x) = ‚àû
0
if h p(x) is Ô¨Ånite.
Prove that End(G) ‚àº= R. Prove that there are inÔ¨Ånitely many G with Aut(G) ‚àº= I2.

920
Commutative Rings III
Ch. 11
11.5 Let G and H be torsion-free abelian groups of rank 1.
(i) Prove that G ‚äóZ H is torsion-free of rank 1.
(ii) If (h p) is the height sequence of a nonzero element x ‚ààG, and if (kp) is the height
sequence of a nonzero element y ‚ààH, prove that the height sequence of x ‚äóy is (m p),
where m p = h p + kp (we agree that ‚àû+ kp = ‚àû).
11.6 Let T be the set of all types, and deÔ¨Åne œÑ ‚â§œÑ‚Ä≤, for œÑ, œÑ‚Ä≤ ‚ààT , if there are height sequences
(kp) ‚ààœÑ and (k‚Ä≤p) ‚ààœÑ‚Ä≤ with kp ‚â§k‚Ä≤p for all primes p.
(i) Prove that ‚â§is a partial order on T .
(ii) Prove that if G and G‚Ä≤ are torsion-free abelian groups of rank 1, then œÑ(G) ‚â§œÑ(G‚Ä≤) if
and only if G is isomorphic to a subgroup of G‚Ä≤.
(iii) Prove that T is a lattice, and show that if œÑ = œÑ(G) and œÑ‚Ä≤ = œÑ(G‚Ä≤), then œÑ ‚àßœÑ‚Ä≤ =
œÑ(G ‚à©G‚Ä≤) and œÑ ‚à®œÑ‚Ä≤ = œÑ(G + G‚Ä≤).
(iv) If G and G‚Ä≤ are torsion-free abelian groups of rank 1, prove that Hom(G, G‚Ä≤) Ã∏= {0} if
and only if œÑ(G) ‚â§œÑ(G‚Ä≤).
11.7 If G is a p-primary abelian group, prove that G is a Z(p)-module.
11.8 If S is a subset of a commutative ring R, and if S is the multiplicatively closed subset it
generates, prove that (S)‚àí1R ‚àº= S‚àí1R.
11.9 If S = {s1, . . . , sn} is a Ô¨Ånite nonempty subset of a commutative ring R, prove that S‚àí1R ‚àº=
{s}‚àí1R, where s = s1 ¬∑ ¬∑ ¬∑ sn.
Hint. If s‚àí1 exists, then so does s‚àí1(s1 ¬∑ ¬∑ ¬∑si ¬∑ ¬∑ ¬∑ sn) = s‚àí1
i
.
11.10 Prove that every localization of a PID is a PID. Conclude that if p is a prime ideal in a PID R,
then Rp is a DVR.
11.11 If R is a Boolean ring and m is a maximal ideal in R, prove that Rm is a Ô¨Åeld.
11.12 Let S be a subset of a commutative ring R, and let I and J be ideals in R.
(i) Prove that S‚àí1(I J) = (S‚àí1I)(S‚àí1J).
(ii) Prove that S‚àí1(I : J) = (S‚àí1I : S‚àí1J).
11.13 A domain R is a valuation ring if, for all a, b ‚ààR, either a | b or b | a.
(i) Prove that every DVR is a valuation ring.
(ii) Let R be a domain with F = Frac(R). Prove that R is a valuation ring if and only if
a ‚ààR or a‚àí1 ‚ààR for each nonzero a ‚ààF.
11.14
(i) Prove that every Ô¨Ånitely generated ideal in a valuation ring is principal.
(ii) Prove that every Ô¨Ånitely generated ideal in a valuation ring is projective.
11.15 An abelian group ! is ordered if it is a partially ordered set in which a +b ‚â§a‚Ä≤ +b‚Ä≤ whenever
a ‚â§a‚Ä≤ and b ‚â§b‚Ä≤; call ! a totally ordered abelian group if the partial order is a chain.
A
valuation on a Ô¨Åeld k is a function v : k√ó ‚Üí!, where ! is a totally ordered abelian group,
such that
v(ab) = v(a) + v(b);
v(a + b) ‚â•min{v(a), v(b)}.
(i) If a/b ‚ààQ is nonzero, write a = pma‚Ä≤ and b = pnb‚Ä≤, where m, n ‚â•0 and (a‚Ä≤, p) =
1 = (b‚Ä≤, p). Prove that v : Q√ó ‚ÜíZ, deÔ¨Åned by v(a/b) = m ‚àín, is a valuation.

Sec. 11.1
Local and Global
921
(ii) If v : k√ó ‚Üí! is a valuation on a Ô¨Åeld k, deÔ¨Åne R = {0} ‚à™{a ‚ààk√ó : v(a) ‚â•0}.
Prove that R is a valuation ring. (Every valuation ring arises in this way from a suitable
valuation on its fraction Ô¨Åeld. Moreover, the valuation ring is discrete when the totally
ordered abelian group ! is isomorphic to Z.)
(iii) Prove that a ‚ààR is a unit if and only if v(a) = 0.
(iv) Prove that every valuation ring is a (not necessarily noetherian) local ring.
Hint. Show that m = {a ‚ààR : v(a) > 0} is the unique maximal ideal in R.
11.16 Let ! be a totally ordered abelian group and let k be a Ô¨Åeld. DeÔ¨Åne k[!] to be the group
algebra (consisting of all functions f : ! ‚Üík almost all of whose values are 0). As usual, if
f (Œ≥ ) = rŒ≥ , we denote f by 
Œ≥ ‚àà! rŒ≥ Œ≥ .
(i) DeÔ¨Åne the degree of f = 
Œ≥ ‚àà! rŒ≥ Œ≥ to be Œ± if Œ± is the largest index Œ≥ with rŒ≥ Ã∏= 0.
Prove that k[!] is a valuation ring, where v( f ) is the degree of f .
(ii) Give an example of a non-noetherian valuation ring.
11.17 A subset S of a commutative ring R is saturated if it is multiplicatively closed and ab ‚ààS
implies a ‚ààS and b ‚ààS.
(i) Prove that U(R), the set of all units in R, is a saturated subset of R.
(ii) An element r ‚ààR is a zero divisor on an R-module A if there is some nonzero a ‚ààA
with ra = 0. Prove that Z(A), the set of all zero divisors on an R-module A, is a
saturated subset of R.
(iii) If S is a multiplicatively closed subset of a commutative ring R, prove that there exists a
unique smallest saturated subset S‚Ä≤ containing S (we call S‚Ä≤ the saturation of S). Prove
that (S‚Ä≤)‚àí1R ‚àº= S‚àí1R.
(iv) Prove that a multiplicatively closed subset S is saturated if and only if its complement
R ‚àíS is a union of prime ideals.
11.18 Let S be a subset of a commutative ring R, and let M be a Ô¨Ånitely generated R-module. Prove
that S‚àí1M = {0} if and only if there is œÉ ‚ààS with œÉ M = {0}.
11.19 Let S be a subset of a commutative ring R, and let A be an R-module.
(i) If A is free, prove that S‚àí1 A is a free (S‚àí1R)-module.
(ii) If A is Ô¨Ånitely generated, prove that S‚àí1 A is a Ô¨Ånitely generated (S‚àí1R)-module.
(iii) If A is Ô¨Ånitely presented, prove that S‚àí1 A is a Ô¨Ånitely presented (S‚àí1R)-module.
11.20 If A is projective, prove that S‚àí1 A is a projective (S‚àí1R)-module.
11.21 If p is a prime ideal in a commutative ring R and if A is a projective R-module, prove that Ap
is a free Rp-module.
11.22 If B is a Ô¨Çat R-module, where R is a commutative ring, prove that the localization S‚àí1B is a
Ô¨Çat (S‚àí1R)-module.
Hint. The composite of exact functors is exact.
11.23
(i) Give an example of an abelian group B for which Ext1
Z(Q, B) Ã∏= {0}.
(ii) Prove that Q ‚äóZ Ext1
Z(Q, B) Ã∏= {0} for the abelian group B in part (i).
(iii) Prove that Proposition 11.38 may be false if R is noetherian but A is not Ô¨Ånitely gener-
ated.
11.24 Let R be a commutative k-algebra, where k is a commutative ring, and let M be a k-module.
Prove, for all n ‚â•0, that
R ‚äók
<n(M) ‚àº=
<n(R ‚äók M)

922
Commutative Rings III
Ch. 11
(of course, ;n(R ‚äók M) means the nth exterior power of the R-module R ‚äók M). Conclude,
for all maximal ideals m in k, that
<n(M)

m
‚àº=
<n(Mm).
Hint. Show that R ‚äók
;n(M) is a solution to the universal mapping problem for alternating
n-multilinear R-functions.
11.25 Let R be a commutative noetherian ring. If A and B are Ô¨Ånitely generated R-modules, prove
that TorRn (A, B) and Extn
R(A, B) are Ô¨Ånitely generated R-modules for all n.
11.2 DEDEKIND RINGS
A Pythagorean triple is a triple (a, b, c) of positive integers such that a2 +b2 = c2. Exam-
ples of Pythagorean triples are (3, 4, 5), (5, 12, 13), and (7, 24, 25), and all Pythagorean
triples are classiÔ¨Åed in Exercise 1.23 on page 13 (there is an elegant geometric proof of
this by Diophantus, ca. 100 AD). P. Fermat proved that there do not exist positive integers
(a, b, c) with a4 + b4 = c4 and, in 1637, he wrote in the margin of his copy of a book
by Diophantus that he had a wonderful proof that there are no positive integers (a, b, c)
with an + bn = cn for any n > 2. Fermat's proof was never found, and his remark
(that was merely a note to himself) became known only several years after Fermat's death,
when Fermat's son published his father's works. There were other such statements left by
Fermat, many of them true, some of them false, and this statement, the only one unre-
solved by 1800, was called Fermat's last theorem, perhaps in jest. It remained one of the
outstanding challenges in number theory until 1995, when A. Wiles proved Fermat's last
theorem.
Every positive integer n > 2 is a multiple of 4 or of some odd prime p. Thus, if there do
not exist positive integers (a, b, c) with a p +bp = cp for every odd prime p, then Fermat's
last theorem is true [if n = pm, then an + bn = cn implies (am)p + (bm)p = (cm)p].
Over the centuries, there were many attempts to prove it. For example, L. Euler published
a proof (with gaps, later corrected) for the case n = 3, G. P. L. Dirichlet published a proof
(with gaps, later corrected) for the case n = 5, and G. Lam¬¥e published a correct proof for
the case n = 7.
The Ô¨Årst major progress (not dealing only with particular primes p) was due to E. Kum-
mer, in the middle of the 19th century. If a p + bp = cp, where p is an odd prime, then a
natural starting point of investigation is the identity
cp = a p + bp = (a + b)(a + Œ∂b)(a + Œ∂ 2b) ¬∑ ¬∑ ¬∑ (a + Œ∂ p‚àí1b),
where Œ∂ = Œ∂p is a primitive pth root of unity. Kummer proved that if Z[Œ∂p] is a UFD,
where Z[Œ∂p] = { f (Œ∂p) : f (x) ‚ààZ[x]}, then there do not exist positive integers a, b, c
with a p + bp = cp. On the other hand, he showed that there do exist primes p for which
Z[Œ∂p] is not a UFD. To restore unique factorization, he invented "ideal numbers" that he

Sec. 11.2
Dedekind Rings
923
adjoined to Z[Œ∂p]. Later, R. Dedekind recast Kummer's ideal numbers into our present
notion of ideal. Thus, Fermat's last theorem has served as a catalyst in the development of
both modern algebra and of algebraic number theory. Dedekind rings are the appropriate
generalization of rings like Z[Œ∂p], and we will study them in this section.
Integrality
The notion of algebraic integer is a special case of the notion of integral element.
DeÔ¨Ånition.
A ring extension R‚àó/R is a commutative ring R‚àócontaining R as a subring.
If R‚àó/R is a ring extension, then an element a ‚ààR‚àóis integral over R if it is a root of
a monic polynomial in R[x]. A ring extension R‚àó/R is an integral extension if every
a ‚ààR‚àóis integral over R.
Example 11.40.
The Noether Normalization Theorem is often used to prove the Nullstellensatz. It states
that if k is a Ô¨Åeld and A is a Ô¨Ånitely generated k-algebra, then there exist algebraically inde-
pendent elements a1, . . . , an in A so that A is integral over k[a1, . . . , an]. See Matsumura,
Commutative Ring Theory, page 262.
‚óÄ
Recall that a complex number is an algebraic integer if it is a root of a monic polynomial
in Z[x], so that algebraic integers are integral over Z. The reader should compare the next
lemma with Proposition 7.24.
Lemma 11.41.
If R‚àó/R is a ring extension, then the following conditions on a nonzero
element u ‚ààR‚àóare equivalent.
(i) u is integral over R.
(ii) There is a Ô¨Ånitely generated R-submodule B of R‚àówith uB ‚äÜB.
(iii) There is a Ô¨Ånitely generated faithful R-submodule B of R‚àówith uB ‚äÜB; that is, if
d B = {0} for some d ‚ààR, then d = 0.
Proof.
(i) ‚áí(ii). If u is integral over R, there is a monic polynomial f (x) ‚ààR[x] with
f (u) = 0; that is, there are ri ‚ààR with un = n‚àí1
i=0 riui. DeÔ¨Åne B = ‚ü®1, u, u2, . . . , un‚àí1‚ü©.
It is clear that uB ‚äÜB.
(ii) ‚áí(iii). If B = ‚ü®b1, . . . , bm‚ü©is a Ô¨Ånitely generated R-submodule of R‚àówith uB ‚äÜB,
deÔ¨Åne B‚Ä≤ = ‚ü®1, b1, . . . , bm‚ü©. Now B‚Ä≤ is Ô¨Ånitely generated, faithful (because 1 ‚ààB‚Ä≤), and
uB‚Ä≤ ‚äÜB‚Ä≤.
(iii) ‚áí(i). Suppose there is a faithful R-submodule of R‚àó, say, B = ‚ü®bi, . . . , bn‚ü©, with
uB ‚äÜB. There is a system of n equations ubi = n
j=1 pi jb j with pi j ‚ààR. If P = [pi j]
and if X = (b1, . . . , bn)t is an n √ó 1 column vector, then the n √ó n system can be rewritten
in matrix notation: (uI ‚àíP)X = 0. Now 0 =

adj(uI ‚àíP)

(uI ‚àíP)X = d X, where
d = det(uI ‚àíP), by Corollary 9.161. Since d X = 0, we have dbi = 0 for all i, and so

924
Commutative Rings III
Ch. 11
d B = {0}. Therefore, d = 0, because B is faithful. On the other hand, Corollary 9.154
gives d = f (u), where f (x) ‚ààR[x] is a monic polynomial of degree n; hence, u is
integral over R.
‚Ä¢
Being an integral extension is transitive.
Proposition 11.42.
If T ‚äÜS ‚äÜR are commutative rings with S integral over T and R
integral over S, then R is integral over T .
Proof.
If r ‚ààR, there is an equation rn + sn‚àí1rn‚àí1 + ¬∑ ¬∑ ¬∑ + r0 = 0, where si ‚ààS for all
i. By Lemma 11.41, the subring S‚Ä≤ = T [sn‚àí1, . . . , s0] is a Ô¨Ånitely generated T -module.
But r is integral over S‚Ä≤, so that the ring S‚Ä≤[r] is a Ô¨Ånitely generated S‚Ä≤-module. Therefore,
S‚Ä≤[r] is a Ô¨Ånitely generated T -module, and so r is integral over T .
‚Ä¢
Proposition 11.43.
Let E/R be a ring extension.
(i) If u, v ‚ààE are integral over R, then both uv and u + v are integral over R.
(ii) The commutative ring OE/R, deÔ¨Åned by
OE/R = {u ‚ààE : u is integral over R},
is an R-subalgebra of E.
Proof.
(i) Since u and v are integral over R, Lemma 11.41(ii) says there are R-submodules
B = ‚ü®b1, . . . , bn‚ü©and C = ‚ü®c1, . . . , cm‚ü©of E with uB ‚äÜB and vC ‚äÜC; that is, ubi ‚ààB
for all i and vc j ‚ààC for all j. DeÔ¨Åne BC to be the R-submodule of E generated by all
bic j; of course, BC is Ô¨Ånitely generated. Now uvBC ‚äÜBC, for uvbic j = (ubi)(vc j) is
an R-linear combination of bkc‚Ñìs, and so uv is integral over R. Similarly, u + v is integral
over R, for (u + v)bic j = (ubi)c j + (vc j)bi ‚ààBC.
(ii) Part (i) shows that OE/R is closed under multiplication and addition. Now R ‚äÜOE,
for if r ‚ààR, then r is a root of x ‚àír. It follows that 1 ‚ààOE/R and that OE/R is an
R-subalgebra of E.
‚Ä¢
Here is a second proof of Proposition 11.43(i) for a domain E which uses tensor prod-
ucts and linear algebra. Let f (x) ‚ààR[x] be the minimal polynomial of u, let A be the com-
panion matrix of f (x), and let y be an eigenvector [over the algebraic closure of Frac(E)]:
Ay = uy. Let g(x) be the minimal polynomial of v, let B be the companion matrix of
g(x), and let Bz = vz. Now
(A ‚äóB)(y ‚äóz) = Ay ‚äóBz = uy ‚äóvz = uv(y ‚äóz).
Therefore, uv is an eigenvalue of A ‚äóB; that is, uv is a root of the monic polynomial
det(x I ‚àíA ‚äóB), which lies in R[x] because both A and B have all their entries in R.
Therefore, uv is integral over R. Similarly, the equation
(A ‚äóI + I ‚äóB)(y ‚äóz) = Ay ‚äóz + y ‚äóBz = (u + v)y ‚äóz
shows that u + v is integral over R.
‚Ä¢

Sec. 11.2
Dedekind Rings
925
DeÔ¨Ånition.
Let E/R be a ring extension. The R-subalgebra OE/R of E, consisting of
all those elements integral over R, is called the integral closure of R in E. If OE/R = R,
then R is called integrally closed in E. If R is a domain and R is integrally closed in
F = Frac(R), that is, OF/R = R, then R is called integrally closed.
Thus, R is integrally closed if Œ± ‚ààFrac(R) and Œ± is integral over R, then Œ± ‚ààR.
Example 11.44.
The ring OQ/Z = Z, for if a rational number a is a root of a monic polynomial in Z[x],
then Theorem 3.43 shows that a ‚ààZ. Hence, Z is integrally closed.
‚óÄ
Proposition 11.45.
Every UFD R is integrally closed. In particular, every PID is inte-
grally closed.
Proof.
Let F = Frac(R), and suppose that u ‚ààF is integral over R. Thus, there is an
equation
un + rn‚àí1un‚àí1 + ¬∑ ¬∑ ¬∑ + r1u + r0 = 0,
where ri ‚ààR. We may write u = b/c, where b, c ‚ààR and (b, c) = 1 (gcd's exist because
R is a UFD, and so every fraction can be put in lowest terms). Substituting and clearing
denominators,
bn + rn‚àí1bn‚àí1c + ¬∑ ¬∑ ¬∑ + r1bcn‚àí1 + r0cn = 0.
Hence, bn = ‚àíc

rn‚àí1bn‚àí1 + ¬∑ ¬∑ ¬∑ + r1bcn‚àí2 + r0cn‚àí1
, so that c | bn in R. But (b, c) = 1
implies (bn, c) = 1, so that c must be a unit in R; that is, c‚àí1 ‚ààR. Therefore, u = b/c =
bc‚àí1 ‚ààR, and so R is integrally closed.
‚Ä¢
We now understand Example 6.21. If k is a Ô¨Åeld, the subring R of k[x], consisting of all
polynomials f (x) ‚ààk[x] having no linear term, is not a UFD because it is not integrally
closed. It is easy to check that Frac(R) = k(x), for x = x3/x2 ‚ààFrac(R). But x ‚ààk(x) is
a root of the monic polynomial t2 ‚àíx2 ‚ààR[t], and x /‚ààR.
DeÔ¨Ånition.
An algebraic number Ô¨Åeld is a Ô¨Ånite Ô¨Åeld extension of Q. If E is an algebraic
number Ô¨Åeld, then OE/Z is usually denoted by OE instead of by OE/Z, and it is called the
ring of integers in E.
Because of this new use of the word integers, algebraic number theorists often speak of
the ring of rational integers when referring to Z.
Proposition 11.46.
Let E be an algebraic number Ô¨Åeld and let OE be its ring of integers.
(i) If Œ± ‚ààE, there there is a nonzero integer m with mŒ± ‚ààOE.
(ii) Frac(OE) = E.
(iii) OE is integrally closed.

926
Commutative Rings III
Ch. 11
Proof.
(i) If Œ± ‚ààE, then there is a monic polynomial f (x) ‚ààQ[x] with f (Œ±) = 0.
Clearing denominators gives an integer m with
mŒ±n + cn‚àí1Œ±n‚àí1 + cn‚àí2Œ±n‚àí2 + ¬∑ ¬∑ ¬∑ + c1Œ± + c0 = 0,
where all ci ‚ààZ. Multiplying by mn‚àí1 gives
(mŒ±)n + cn‚àí1(mŒ±)n‚àí1 + mcn‚àí2(mŒ±)n‚àí2 + ¬∑ ¬∑ ¬∑ + c1mn‚àí2(mŒ±) + mn‚àí1c0 = 0.
Thus, mŒ± ‚ààOE.
(ii) It sufÔ¨Åces to show that if Œ± ‚ààE, then there are a, b ‚ààOE with Œ± = a/b. But
mŒ± ‚ààOE, by part (i), m ‚ààZ ‚äÜOE, and Œ± = (mŒ±)/m.
(iii) Suppose that Œ± ‚ààFrac(OE) = E is integral over OE. By transitivity of integral
extensions, Proposition 11.42, we have Œ± integral over Z. But this means that Œ± ‚ààOE
which is, by deÔ¨Ånition, the set of all those elements in E that are integral over Z. Therefore,
OE is integrally closed.
‚Ä¢
Example 11.47.
We shall see, in Proposition 11.76, that if E = Q(i), then OE = Z[i], the Gaussian
integers. Now Z[i] is a PID, because it is a euclidean ring, and hence it is a UFD. The
generalization of this example which replaces Q(i) by an algebraic number Ô¨Åeld E is more
subtle. It is true that OE is integrally closed, but it may not be not true that the elements
of OE are Z-linear combinations of Œ±. Moreover, the rings OE may not be UFDs. We will
investigate rings of integers at the end of this section.
‚óÄ
Given a ring extension R‚àó/R, what is the relation between ideals in R‚àóand ideals in R?
DeÔ¨Ånition.
Let R‚àó/R be a ring extension. If I is an ideal in R, deÔ¨Åne its extension I e
to be R‚àóI, the ideal in R‚àógenerated by I. If I ‚àóis an ideal in R‚àó, deÔ¨Åne its contraction
I ‚àóc = R ‚à©I ‚àó.
Remark.
The deÔ¨Ånition can be generalized. Let h : R ‚ÜíR‚àóbe a ring homomorphism,
where R and R‚àóare any two commutative rings. DeÔ¨Åne the extension of an ideal I in R
to be the ideal in R‚àógenerated by h(I); deÔ¨Åne the contraction of an ideal I ‚àóin R‚àóto be
h‚àí1(I ‚àó). If R‚àó/R is a ring extension, then taking h : R ‚ÜíR‚àóto be the inclusion gives the
deÔ¨Ånition above. Another interesting instance is the localization map h : R ‚ÜíS‚àí1R.
‚óÄ
Example 11.48.
(i) In general, the contraction function c: Spec(R‚àó) ‚ÜíSpec(R) is neither an injec-
tion nor a surjection.
For example, c: Spec(Q) ‚ÜíSpec(Z) is not surjective, while
c: Spec(Q[x]) ‚ÜíSpec(Q) is not injective.
(ii) It is easy to see that if R‚àó/R is a ring extension and p‚àóis a prime ideal in R‚àó, then its
contraction p‚àó‚à©R is also a prime ideal. If a, b ‚ààR and ab ‚ààp‚àó‚à©R ‚äÜp‚àó, then p‚àóprime

Sec. 11.2
Dedekind Rings
927
gives a ‚ààp‚àóor b ‚ààp‚àó; as a, b ‚ààR, either a ‚ààp‚àó‚à©R or b ‚ààp‚àó‚à©R. Thus, contraction
deÔ¨Ånes a function c: Spec(R‚àó) ‚ÜíSpec(R).
(iii) The contraction of a maximal ideal, though necessarily prime, need not be maximal.
For example, if R‚àóis a Ô¨Åeld, then {0}‚àóis a maximal ideal in R‚àó, but if R is not a Ô¨Åeld, then
the contraction of {0}‚àó, namely, {0}, is not a maximal ideal in R.
‚óÄ
Example 11.49.
(i) Let I(R) denote the family of all the ideals in a commutative ring R. Extension deÔ¨Ånes
a function e: I(R) ‚ÜíI(R‚àó); in general, it is neither injective nor surjective. If R‚àóis a
Ô¨Åeld and R is not a Ô¨Åeld, then e: I(R) ‚ÜíI(R‚àó) is not injective; if R is a Ô¨Åeld and R‚àóis
not a Ô¨Åeld, then e: I(R) ‚ÜíI(R‚àó) is not surjective.
(ii) If R‚àó/R is a ring extension and p is a prime ideal in R, then its extension R‚àóp need not
be a prime ideal. Observe Ô¨Årst that if (a) = Ra is a principal ideal in R, then its extension
is the principal ideal R‚àóa in R‚àógenerated by a. Now let R = R[x] and R‚àó= C[x]. The
ideal (x2 + 1) is prime, because x2 + 1 is irreducible in R[x], but its extension is not prime
because x2 + 1 factors in C[x].
‚óÄ
There are various elementary properties of extension and contraction, such as I ‚àóce ‚äÜI ‚àó
and I ec ‚äáI, that are collected in Exercise 11.28 on page 930.
Is there a reasonable condition on a ring extension R‚àó/R that will give a good rela-
tionship between prime ideals in R and prime ideals in R‚àó? This question was posed and
answered by I. S. Cohen and A. Seidenberg. We say that a ring extension R‚àó/R satis-
Ô¨Åes lying over if, for every prime ideal p in R, there exists a prime ideal p‚àóin R‚àówith
p‚àó‚à©R = p. We say that R‚àó/R satisÔ¨Åes going up if p ‚äÜq are prime ideals in R and if p‚àó
lies over p, then there exists a prime ideal q‚àó‚äáp‚àówhich lies over q.
‚Ä¢
‚Ä¢
p‚àó
q
p
p
//////////
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
Lying over
Going Up
We are going to see that extension and contraction are well-behaved in the presence of
integral extensions.
Lemma 11.50.
Let R‚àóbe an integral extension of R.
(i) If p is a prime ideal in R and if p‚àólies over p, then R‚àó/p‚àóis integral over R/p.
(ii) Is S is a subset of R, then S‚àí1R‚àóis integral over S‚àí1R.

928
Commutative Rings III
Ch. 11
Proof.
(i) First, the second isomorphism theorem allows us to regard R/p as a subring of
R‚àó/p‚àó:
R/p = R/(p‚àó‚à©R) ‚àº= (R + p‚àó)/p‚àó‚äÜR‚àó/p‚àó.
Each element in R‚àó/p‚àóhas the form Œ± + p‚àó, where Œ± ‚ààR‚àó. Since R‚àóis integral over R,
there is an equation
Œ±n + rn‚àí1Œ±n‚àí1 + ¬∑ ¬∑ ¬∑ + r0 = 0,
where ri ‚ààR. Now view this equation mod p‚àóto see that Œ± + p‚àóis integral over R/p.
(ii) If Œ±‚àó‚ààS‚àí1R‚àó, then Œ±‚àó= Œ±/œÉ, where Œ± ‚ààR‚àóand œÉ ‚ààS. Since R‚àóis integral over
R, there is an equation Œ±n + rn‚àí1Œ±n‚àí1 + ¬∑ ¬∑ ¬∑ + r0 = 0 with ri ‚ààR. Multiplying by 1/œÉ n
in S‚àí1R‚àógives
(Œ±/œÉ)n + (rn‚àí1/œÉ)(Œ±/œÉ)n‚àí1 + ¬∑ ¬∑ ¬∑ + r0/œÉ n = 0,
which shows that Œ±/œÉ is integral over S‚àí1R.
‚Ä¢
When R‚àó/R is a ring extension and R is a Ô¨Åeld, every proper ideal in R‚àócontracts to {0}
in R. The following proposition eliminates this collapse when R‚àóis an integral extension
of R.
Proposition 11.51.
Let R‚àó/R be a ring extension of domains with R‚àóintegral over R.
Then R‚àóis a Ô¨Åeld if and only if R is a Ô¨Åeld.
Proof.
Assume that R‚àóis a Ô¨Åeld. If u ‚ààR is nonzero, then u‚àí1 ‚ààR‚àó, and so u‚àí1 is
integral over R. Therefore, there is an equation (u‚àí1)n + rn‚àí1(un‚àí1)n‚àí1 + ¬∑ ¬∑ ¬∑ + r0 = 0,
where the ri ‚ààR. Multiplying by un gives u‚àí1 = ‚àíu(rn‚àí1 + ¬∑ ¬∑ ¬∑ + r0un‚àí1). Therefore,
u‚àí1 ‚ààR and R is a Ô¨Åeld.
Conversely, assume that R is a Ô¨Åeld. If Œ± ‚ààR‚àóis nonzero, then there is a monic
f (x) ‚ààR[x] with f (Œ±) = 0. Thus, Œ± is algebraic over R, and so we may assume that
f (x) = irr(Œ±, R); that is, f (x) is irreducible. If f (x) = n
i=0 ri xi, then
Œ±(Œ±n‚àí1 + rn‚àí1Œ±n‚àí1 + ¬∑ ¬∑ ¬∑ + r1) = ‚àír0.
Irreducibility of f (x) gives r0 Ã∏= 0, so that Œ±‚àí1 lies in R‚àó. Therefore, R‚àóis a Ô¨Åeld.
‚Ä¢
Corollary 11.52.
Let R‚àó/R be an integral extension. If p is a prime ideal in R and p‚àóis
a prime ideal lying over p, then p is a maximal ideal if and only if p‚àóis a maximal ideal.
Proof.
By Lemma 11.50(i), the domain R‚àó/p‚àóis integral over the domain R/p. But now
Proposition 11.51 says that R‚àó/p‚àóis a Ô¨Åeld if and only if R/p is a Ô¨Åeld; that is, p‚àóis a
maximal ideal in R‚àóif and only if p is a maximal ideal in R.
‚Ä¢

Sec. 11.2
Dedekind Rings
929
Corollary 11.53.
If E is an algebraic number Ô¨Åeld, then every nonzero prime ideal in
OE is a maximal ideal.
Proof.
Let p be a nonzero prime ideal in OE. If p ‚à©Z Ã∏= {0}, then there is a prime p with
p ‚à©Z = (p), by Example 11.48(i). But (p) is a maximal ideal in Z, so that p is a maximal
ideal, by Corollary 11.52. It remains to show that p ‚à©Z Ã∏= {0}. Let Œ± ‚ààp be nonzero.
Since Œ± is integral over Z, there is an equation
Œ±n + cn‚àí1Œ±n‚àí1 + ¬∑ ¬∑ ¬∑ + c1Œ± + c0 = 0,
where ci ‚ààZ for all i. If we choose such an equation with n minimal, then c0 Ã∏= 0. Since
Œ± ‚ààp, we have c0 = ‚àíŒ±(Œ±n‚àí1+cn‚àí1Œ±n‚àí2+¬∑ ¬∑ ¬∑+c1) ‚ààp‚à©Z, so that p‚à©Z is nonzero. ‚Ä¢
Corollary 11.54.
Let R‚àóbe integral over R, let p be a prime ideal in R, and let p‚àóand
q‚àóbe prime ideals in R‚àólying over p. If p‚àó‚äÜq‚àó, then p‚àó= q‚àó.
Proof.
Lemma 11.50(ii) and Corollary 11.18(iii) show that the hypotheses are preserved
by localizing at p; that is, R‚àó
p is integral over Rp and p‚àóR‚àó
p ‚äÜq‚àóR‚àó
p are prime ideals.
Hence, replacing R‚àóand R by their localizations, we may assume that R‚àóand R are local
rings and that p is a maximal ideal in R (by Proposition 11.21). But Corollary 11.52 says
that maximality of p forces maximality of p‚àó. Since p‚àó‚äÜq‚àó, we have p‚àó= q‚àó.
‚Ä¢
Here are the theorems of Cohen and Seidenberg.
Theorem 11.55 (Lying Over).
Let R‚àó/R be a ring extension with R‚àóintegral over R. If
p is a prime ideal in R, then there is a prime ideal p‚àóin R‚àólying over p; that is, p‚àó‚à©R = p.
Proof.
There is a commutative diagram
R
h

i
 R‚àó,
h‚àó

Rp
j
 S‚àí1R‚àó
where h and h‚àóare localization maps and i and j are inclusions. If S = R ‚àíp, then S‚àí1R‚àó
is an extension of Rp (since localization is an exact functor, R contained in R‚àóimplies Rp
contained in S‚àí1R‚àó); by Lemma 11.50, S‚àí1R‚àóis integral over Rp. Choose a maximal
ideal m‚àóin S‚àí1R‚àó. By Corollary 11.52, m‚àó‚à©Rp is a maximal ideal in Rp. But Rp is
a local ring with unique maximal ideal pRp, so that m‚àó‚à©Rp = pRp. Since the inverse
image of a prime ideal (under any ring map) is always prime, the ideal p‚àó= (h‚àó)‚àí1(m‚àó)
is a prime ideal in R‚àó. Now
(h‚àói)‚àí1(m‚àó) = i‚àí1(h‚àó)‚àí1(m‚àó) = i‚àí1(p‚àó) = p‚àó‚à©R,
while
( jh)‚àí1(m‚àó) = h‚àí1 j‚àí1(m‚àó) = h‚àí1(m‚àó‚à©Rp) = h‚àí1(pRp) = p.
Therefore, p‚àóis a prime ideal lying over p.
‚Ä¢

930
Commutative Rings III
Ch. 11
Theorem 11.56 (Going Up).
Let R‚àó/R be a ring extension with R‚àóintegral over R. If
p ‚äÜq are prime ideals in R, and if p‚àóis a prime ideal in R‚àólying over p, then there exists
a prime ideal q‚àólying over q with p‚àó‚äÜq‚àó.
Proof.
Lemma 11.50 says that (R‚àó/p‚àó)/(R/p) is an integral ring extension, where R/p
is imbedded in R‚àó/p‚àóas (R + p‚àó)/p‚àó. Replacing R‚àóand R by these quotient rings, we
may assume that both p‚àóand p are {0}. The theorem now follows at once from the lying
over theorem.
‚Ä¢
There is also a going down theorem, but it requires an additional hypothesis.
Theorem (Going Down).
Let R‚àó/R be an integral extension and assume that R is in-
tegrally closed. If p1 ‚äáp2 ‚äá¬∑ ¬∑ ¬∑ ‚äápn is a chain of prime ideals in R and if p‚àó
1 ‚äáp‚àó
2 ‚äá
¬∑ ¬∑ ¬∑ ‚äáp‚àó
m, for m < n is a chain of prime ideals in R‚àówith each p‚àó
i lying over pi, then the
chain in R‚àócan be extended to p‚àó
1 ‚äáp‚àó
2 ‚äá¬∑ ¬∑ ¬∑ ‚äáp‚àó
n with p‚àó
i lying over pi for all i ‚â§n.
Proof.
See Atiyah-Macdonald, Introduction to Commutative Algebra, page 64.
‚Ä¢
EXERCISES
11.26 If R is an integrally closed domain and S is a multiplicatively closed subset of R not containing
0, prove that S‚àí1R is also integrally closed.
11.27 Prove that every valuation ring is integrally closed.
11.28 Let R‚àó/R be a ring extension. If I is an ideal in R, denote its extension by I e; if I ‚àóis an ideal
in R‚àó, denote its contraction by I ‚àóc. Prove each of the follow assertions.
(i) Both e and c preserve inclusion: If I ‚äÜJ, then I e ‚äÜJe; if I ‚àó‚äÜJ‚àó, then I ‚àóc ‚äÜJ‚àóc.
(ii) I ‚àóce ‚äÜI ‚àóand I ec ‚äáI.
(iii) I ‚àócec = I ‚àóc and I ece = I e.
(iv) (I ‚àó+ J‚àó)c ‚äáI ‚àóc + J‚àóc and (I + J)e = I e + Je.
(v) (I ‚àó‚à©J‚àó)c = I ‚àóc ‚à©J‚àóc and (I ‚à©J)e ‚äÜI e ‚à©Je.
(vi) (I ‚àóJ‚àó)c ‚äáI ‚àóc J‚àóc and (I J)e = I e Je.
(vii)
‚àö
I ‚àóc =
‚àö
I ‚àóc and
‚àö
I
e ‚äÜ
‚àö
I e.
(viii) (J‚àó: I ‚àó)c ‚äÜ(J‚àóc : I ‚àóc) and (I : J)e ‚äÜ(I e : Je).
11.29 If A is the Ô¨Åeld of all algebraic numbers, then OA is the ring of all algebraic integers. Prove
that
OA ‚à©Q = Z.
Conclude, for every algebraic number Ô¨Åeld E, that OE ‚à©Q = Z.
11.30 Let R‚àó/R be an integral ring extension.
(i) If a ‚ààR is a unit in R‚àó, prove that a is a unit in R.
(ii) Prove that J(R) = R ‚à©J(R‚àó), where J(R) is the Jacobson radical.
11.31 Let R‚àó/R be an integral extension. If p1 ‚äÜp2 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜpn is a chain of prime ideals in R and
if p‚àó
1 ‚äÜp‚àó
2 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜp‚àóm, for m < n is a chain of prime ideals in R‚àówith each p‚àó
i lying over
pi, then the chain in R‚àócan be extended to p‚àó
1 ‚äÜp‚àó
2 ‚äÜ¬∑ ¬∑ ¬∑ ‚äÜp‚àón with p‚àó
i lying over pi for all

Sec. 11.2
Dedekind Rings
931
i ‚â§n. (The going up theorem is so called because the chain of ideals in R‚àóis ascending, in
contrast to the going down theorem in which the chain of ideals in R‚àóis descending.)
11.32 Let R‚àó/R be an integral extension. If every nonzero prime ideal in R is a maximal ideal, prove
that every nonzero prime ideal in R‚àóis also a maximal ideal.
Hint. See the proof of Corollary 11.53.
11.33 Let Œ± be algebraic over Q, let E/Q be a splitting Ô¨Åeld, and let G = Gal(E/Q) be its Galois
group.
(i) Prove that if Œ± is integral over Z, then, for all œÉ ‚ààG, œÉ(Œ±) is also integral over Z.
(ii) Prove that Œ± is an algebraic integer if and only if irr(Œ±, Q) ‚ààZ[x]. Compare this proof
with that of Corollary 6.29.
(iii) Let E be an algebraic number Ô¨Åeld and let R ‚äÜE be integrally closed. If Œ± ‚ààE, prove
that irr(Œ±, Frac(R)) ‚ààR[x].
Hint. If E is a Galois extension of Frac(R) containing Œ±, then G = Gal(E/ Frac(R))
acts transitively on the roots of Œ±.
Nullstellensatz Redux
In this subsection, we will prove the Nullstellensatz for arbitrary algebraically closed Ô¨Åelds
(recall that our proof in Chapter 6 assumed that k is uncountable). There are different
proofs of this result, and we present the proof discovered by O. Goldman, as expounded in
Kaplansky, Commutative Rings.
DeÔ¨Ånition.
A ring extension A/R is Ô¨Ånitely generated if there is a surjective R-algebra
map œï : R[x1, . . . , xn] ‚ÜíA. If œï(xi) = ai, then we write
A = R[a1, . . . , an].
If I is an ideal in a commutative ring R, then the nilpotent elements in R/I arise from
elements of
‚àö
I. We now begin working toward a theorem of W. Krull that characterizes the
nilpotent elements in a commutative ring, for this will give us information about radicals
of ideals.
Lemma 11.57.
Let R be a domain with F = Frac(R). Then F/R is a Ô¨Ånitely generated
ring extension if and only if F/R is a simply generated ring extension; that is, there is
u ‚ààR with F = R[u‚àí1] (and so the localization {u}‚àí1R is a Ô¨Åeld).
Proof.
SufÔ¨Åciency being obvious, we prove only necessity. If F = R[a1/b1, . . . , an/bn],
deÔ¨Åne u = 
i bi. We claim that F = R[u‚àí1]. Clearly, F ‚äáR[u‚àí1]. For the reverse
inclusion, note that ai/bi = aiui/u ‚ààR[u‚àí1], where ui = b1 ¬∑ ¬∑ ¬∑bi ¬∑ ¬∑ ¬∑ bn.
‚Ä¢
DeÔ¨Ånition.
If R is a domain with F = Frac(R), then R is a G-domain if F/R is a Ô¨Ånitely
generated ring extension. An ideal I in a commutative ring R is a G-ideal 4 if R/I is a
G-domain.
4G-ideals are named after O. Goldman.

932
Commutative Rings III
Ch. 11
Every Ô¨Åeld is a G-domain, and so every maximal ideal in a commutative ring is a G-
ideal. If I is a G-ideal, then R/I is a G-domain, hence a domain; therefore, every G-ideal
is a prime ideal. Corollary 11.61 says that Z is not a G-domain; it follows that the prime
ideal (x) in Z[x] is not a G-ideal.
Proposition 11.58.
Let E/R be a ring extension in which both E and R are domains. If
E is a Ô¨Ånitely generated R-algebra and each Œ± ‚ààE is algebraic over R (that is, Œ± is a root
of a nonzero polynomial in R[x]), then R is a G-domain if and only if E is a G-domain.
Proof.
Let R be a G-domain, so that F = Frac(R) = R[u‚àí1] for some nonzero u ‚ààR.
Therefore, E[u‚àí1] ‚äÜFrac(E), for u ‚ààR ‚äÜE. But E[u‚àí1] is a domain algebraic over the
Ô¨Åeld F = R[u‚àí1], so that E[u‚àí1] is a Ô¨Åeld, by Exercise 11.35 on page 938. Since Frac(E)
is the smallest Ô¨Åeld containing E, we have E[u‚àí1] = Frac(E), and so E is a G-domain.
If E is a G-domain, then there is v ‚ààE with Frac(E) = E[v‚àí1]. By hypothesis,
E = R[b1, . . . , bn], where bi is algebraic over F = Frac(R) for all i. As v ‚àà
E, we
have v algebraic over R, and so v‚àí1 is algebraic over R. Thus, there are monic polyno-
mials f0(x), fi(x) ‚ààF[x] with f0(v‚àí1) = 0 and fi(bi) = 0 for all i ‚â•1. Clearing
denominators, we obtain equations Œ≤i fi(bi) = 0, for i ‚â•0, with coefÔ¨Åcients in R:
Œ≤0(v‚àí1)d0 + ¬∑ ¬∑ ¬∑ = 0
Œ≤ibdi
i + ¬∑ ¬∑ ¬∑ = 0.
DeÔ¨Åne R‚àó= R[Œ≤‚àí1
0 , Œ≤‚àí1
1 , . . . , Œ≤‚àí1
n ]. Each bi is integral over R‚àó, for each Œ≤i is a unit
in R‚àó. Clearly, E[v‚àí1] = R‚àó[v‚àí1, b1, . . . , bn]. Thus, the Ô¨Åeld E[v‚àí1] is integral over
R‚àó, by Proposition 11.43 (since E[v‚àí1] = R‚àó[v‚àí1, b1, . . . , bn] and each of the displayed
generators is integral over R‚àó), and this forces R‚àóto be a Ô¨Åeld, by Proposition 11.51. But
R‚àó= R[Œ≤‚àí1
0 , Œ≤‚àí1
1 , . . . , Œ≤‚àí1
n ] ‚äÜF, because Œ≤i ‚ààR for all i, so that R‚àó= F. Therefore,
F = R[Œ≤‚àí1
0 , Œ≤‚àí1
1 , . . . , Œ≤‚àí1
n ] is a Ô¨Ånitely generated ring extension of R; that is, R is a
G-domain.
‚Ä¢
The next lemma leads to Corollary 11.60, an "internal" characterization of G-domains,
phrased solely in terms of R, with no mention of Frac(R).
Lemma 11.59.
Let R be a domain with F = Frac(R). The following conditions are
equivalent for a nonzero element u ‚ààR.
(i) u lies in every nonzero prime ideal of R.
(ii) for every nonzero ideal I in R, there is an integer n with un ‚ààI.
(iii) R is a G-domain; that is, F = R[u‚àí1].
Proof.
(i) ‚áí(ii). Suppose there is a nonzero ideal I for which un /‚ààI for all n ‚â•0. If
S = {un : n ‚â•0}, then I ‚à©S = ‚àÖ. By Zorn's lemma, there is an ideal p maximal with
I ‚äÜp and p ‚à©S = ‚àÖ, and p is a prime ideal, by Exercise 6.9. This contradicts u lying in
every prime ideal.

Sec. 11.2
Dedekind Rings
933
(ii) ‚áí(iii). If b ‚ààR and b Ã∏= 0, then un ‚àà(b) for some n ‚â•1, by hypothesis. Hence,
un = rb for some r ‚ààR, and so b‚àí1 = ru‚àín ‚ààR[u‚àí1]. Therefore,F = R[u‚àí1].
(iii) ‚áí(i). Let p be a nonzero prime ideal. If b ‚ààp is nonzero, then b‚àí1 = n
i=0 riu‚àíi,
where ri ‚ààR, because F = R[u‚àí1]. Therefore, un = b

i riun‚àíi
lies in p, because
b ‚ààp and 
i riun‚àíi ‚ààR. Since p is a prime ideal, u ‚ààp.
‚Ä¢
Corollary 11.60.
A domain R is a G-domain if and only if 
p prime
pÃ∏=0
p Ã∏= {0}.
Proof.
By Lemma 11.59, R is a G-domain if and only if it has a nonzero element u lying
in every nonzero prime ideal.
‚Ä¢
Corollary 11.61.
If R is a PID, then R is a G-domain if and only if R has only Ô¨Ånitely
many prime ideals.
Proof.
If R is a G-domain, then I =  p Ã∏= {0}, where p ranges over all nonzero prime
ideals. If R has inÔ¨Ånitely many prime ideals, then there are inÔ¨Ånitely many nonassociate
prime elements p1, p2, . . .; that is, the (pi) are distinct prime ideals. If a ‚ààI, then pi | a
for all i. But a = qe1
1 ¬∑ ¬∑ ¬∑ qen
n , where the q j are distinct prime elements, contradicting
unique factorization in the PID R.
Conversely, if R has only Ô¨Ånitely many nonzero prime ideals, say, (p1), . . . , (pm),
then the product p1 ¬∑ ¬∑ ¬∑ pm is a nonzero element lying in 
i(pi). Therefore, R is a G-
domain.
‚Ä¢
It follows, for example, that every DVR is a G-domain.
DeÔ¨Ånition.
If R is a commutative ring, then its nilradical is
nil(R) = {r ‚ààR : r is nilpotent}.
We note that nil(R) is an ideal. If r, s ‚ààR are nilpotent, then rn = 0 = sm, for positive
integers m and n. Hence,
(r + s)m+n‚àí1 =
m+n‚àí1

i=0
m + n ‚àí1
i
	
rism+n‚àí1‚àíi.
If i ‚â•n, then ri = 0 and the ith term in the sum is 0; if i < n, then m + n ‚àíi ‚àí1 ‚â•m,
sm+n‚àí‚àí1i = 0, and the ith term in the sum is 0 in this case as well. Thus, (r +s)m+n‚àí1 = 0
and r + s is nilpotent. Finally, rs is nilpotent, for (rs)mn = rmnsms = 0.
The next theorem is an improvement on W. Krull's original version, that characterizes
the nilradical as the intersection of all the prime ideals.
Theorem 11.62 (Krull).
If R is a commutative ring, then
nil(R) =
"
p=prime ideal
p =
"
p=G-ideal
p.

934
Commutative Rings III
Ch. 11
Remark.
If R is a domain, then {0} is a prime ideal, and so nil(R) = {0} (alternatively,
there are no nonzero nilpotent elements in a domain). The intersection of all the nonzero
prime ideals in a commutative ring R may be larger than nil(R); this happens, for example,
when R is a DVR.
‚óÄ
Proof.
It is obvious that nil(R) ‚äÜ
p=prime ideal p ‚äÜ
p=G-ideal p: nilpotent elements
lie in every prime ideal; every G-ideal is a prime ideal. Thus, it sufÔ¨Åces to prove that

p= G-ideal p ‚äÜnil(R). Suppose that u /‚àà
p= G-ideal p. It follows that un Ã∏= 0 for all
n ‚â•1, for if un = 0, then un ‚ààp for every G-ideal p, and so u ‚ààp, because G-ideals are
prime. Therefore, the multiplicatively closed set S = {un : n ‚â•1} does not contain 0. By
Zorn's lemma, there is an ideal q maximal with q ‚à©S = ‚àÖ(that there are ideals disjoint
from S requires 0 /‚ààS). We claim that q is a G-ideal, which will give u /‚àà
p=G-ideal p.
Now q is a prime ideal, by Exercise 6.9, so that R/q is a domain. Suppose there is a nonzero
prime ideal p‚àóin R/q not containing u + q. There is an ideal p ‚äãq in R with p‚àó= p/q
(for p‚àóÃ∏= {0}), contradicting the maximality of q. Therefore, u + q lies in every nonzero
prime ideal in R/q. By Corollary 11.60, R/q is a G-domain, and so q is a G-ideal.
‚Ä¢
The next corollary follows easily from Krull's theorem.
Corollary 11.63.
If I is an ideal in a commutative ring R, then
‚àö
I is the intersection of
all the G-ideals containing I.
Proof.
By deÔ¨Ånition,
‚àö
I = {r ‚ààR : rn ‚ààI for some n ‚â•1}. Therefore,
‚àö
I/I =
nil(R/I) = 
p‚àó=G-ideal p‚àó. For each p‚àó, there is an ideal p containing I with p‚àó= p/I, and
‚àö
I = 
p/I=G-ideal p. Finally, every p involved in the intersection is a G-ideal, because
R/p ‚àº= (R/I)/(p/I) = (R/I)/p‚àóand (R/I)/p‚àóis a G-domain.
‚Ä¢
We now focus on the relation between ideals in R[x] and those in R.
Proposition 11.64.
An ideal I in a commutative ring R is a G-ideal if and only if I is the
contraction of a maximal ideal in R[x].
Proof.
If I is a G-ideal in R, then R/I is a G-domain. Hence, there is u ‚ààFrac(R/I)
with Frac(R/I) = (R/I)[u‚àí1]. Let œï : (R/I)[x] ‚Üí(R/I)[u‚àí1] be the R-algebra map
taking x ‚Üíu‚àí1. Since œï is a surjection onto the Ô¨Åeld (R/I)[u‚àí1] = Frac(R/I), its kernel
m is a maximal ideal in (R/I)[x]. Since œï|(R/I) is an injection, we have m‚à©(R/I) = {0}.
By Exercise 6.2, there is an ideal, necessarily maximal, m‚Ä≤ in R[x] with m‚Ä≤/I = m, and
m‚Ä≤ ‚à©R = I.
Conversely, assume that m is a maximal ideal in R[x] with m ‚à©R = I. If ŒΩ : R[x] ‚Üí
R[x]/m be the natural map and u = ŒΩ(x), then im ŒΩ = (R/I)[u] is a Ô¨Åeld. Hence, R/I is
a G-domain, by Proposition 11.58, and so I is a G-ideal.
‚Ä¢
Notation. If I is an ideal in a commutative ring R and if f (x) ‚ààR[x], then f (x) denotes
the polynomial in (R/I)[x] obtained from f (x) by reducing its coefÔ¨Åcients mod I; that is,
if f (x) = 
i ai xi, where ai ‚ààR, then f (x) = 
i(ai + I)xi.

Sec. 11.2
Dedekind Rings
935
Corollary 11.65.
Let R be a commutative ring, and let m be a maximal ideal in R[x].
If the contraction m‚Ä≤ = m ‚à©R is a maximal ideal in R, then m = (m‚Ä≤, f (x)), where
f (x) ‚ààR[x] and f (x) ‚àà(R/m‚Ä≤)[x] is irreducible. If R/m‚Ä≤ is algebraically closed, then
m = (m‚Ä≤, x ‚àía) for some a ‚ààR.
Proof.
First, Proposition 11.64 says that m‚Ä≤ = m ‚à©R is a G-ideal in R. Consider the
map œï : R[x] ‚Üí(R/m‚Ä≤)[x] which reduces coefÔ¨Åcients mod m‚Ä≤. Since œï is a surjection,
the ideal œï(m) is a maximal ideal; that is, œï(m) = (g(x)), where g(x) ‚àà(R/m‚Ä≤)[x] is
irreducible. Therefore, m = (m‚Ä≤, f (x)), where œï( f ) = g; that is, f (x) = g(x).
‚Ä¢
Maximal ideals are always G-ideals, and G-ideals are always prime ideals. The next
deÔ¨Ånition imposes the condition that G-ideals be maximal. In light of Proposition 11.64,
this will force the contraction of maximal ideals in R[x] to be maximal ideals in R.
DeÔ¨Ånition.
A commutative ring R is a Jacobson5 ring if every G-ideal is a maximal
ideal.
Example 11.66.
(i) Every Ô¨Åeld is a Jacobson ring.
(ii) By Corollary 11.61, a PID R is a G-domain if and only if it has only Ô¨Ånitely many
prime ideals. Such a ring cannot be a Jacobson ring, for {0} is a G-ideal which is not
maximal [R/{0} ‚àº= R is a G-domain]. On the other hand, if R has inÔ¨Ånitely many prime
ideals, then R is not a G-domain and {0} is not a G-ideal. The G-ideals, which are now
nonzero prime ideals, must be maximal. Therefore, a PID is a Jacobson ring if and only if
it has inÔ¨Ånitely many prime ideals.
(iii) We note that if R is a Jacobson ring, then so is any quotient R‚àó= R/I. If p‚àóis a
G-ideal in R‚àó, then R‚àó/p‚àóis a G-domain. Now p‚àó= p/I for some ideal p in R, and
R/p ‚àº= (R/I)/(p/I) = R‚àó/p‚àó. Thus, p is a G-ideal in R. Since R is a Jacobson ring, p is
a maximal ideal, and R/p ‚àº= R‚àó/p‚àóis a Ô¨Åeld. Therefore, p‚àóis a maximal ideal, and so R‚àó
is also a Jacobson ring.
(iv) By Corollary 11.63, every radical ideal in a commutative ring R is the intersection of
all the G-ideals containing it. Therefore, if R is a Jacobson ring, then every radical ideal is
an intersection of maximal ideals.
‚óÄ
Example 11.66(iv) suggests the following result.
Proposition 11.67.
A commutative ring R is a Jacobson ring if and only if every prime
ideal in R is an intersection of maximal ideals.
Proof.
By Corollary 11.63, every radical ideal, hence, every prime ideal, is the intersec-
tion of all the G-ideals containing I. But in a Jacobson ring, every G-ideal is maximal.
5These rings are called Hilbert rings by some authors. In 1951, W. Krull and O. Goldman, independently,
published proofs of the Nullstellensatz using the techniques in this subsection. Krull introduced the term Jacobson
ring in his paper.

936
Commutative Rings III
Ch. 11
Conversely, assume that every prime ideal in R is an intersection of maximal ideals. We
let the reader check that this property is inherited by quotient rings. Let p be a G-ideal in R,
so that R/p is a G-domain. Thus, there is u Ã∏= 0 in R/p with Frac(R/p) = (R/p)[u‚àí1]. By
Lemma 11.59, u lies in every nonzero prime ideal of R/p, and so u lies in every nonzero
maximal ideal. Now every prime ideal in R/p is an intersection of maximal ideals; in
particular, since R/p is a domain, there are maximal ideals mŒ± with {0} = ‚à©Œ±mŒ±. If all
these mŒ± are nonzero, then u ‚àà‚à©Œ±mŒ± = {0}, a contradiction. We conclude that {0} is a
maximal ideal. Therefore, R/p is a Ô¨Åeld, the G-ideal p is maximal, and R is a Jacobson
ring.
‚Ä¢
Corollary 11.68.
A commutative ring R is a Jacobson ring if and only if J(R/I) =
nil(R/I) for every ideal I. In particular, J(R) = nil(R).
Proof.
Let R be a Jacobson ring. If I is an ideal in R, then
‚àö
I =  m, where m is a
maximal ideal containing I. Now J(R/I) is the intersection of all the maximal ideals in
R/I; that is, J(R) = (m/I) = ( m)/I =
‚àö
I/I. On the other hand, nil(R/I) consists
of all the nilpotent elements in R/I. But 0 = ( f + I)n = f n + I holds if and only if
f n ‚ààI; that is, f ‚àà
‚àö
I. To prove the converse, note that condition says that every radical
ideal in R is an intersection of maximal ideals. In particular, every prime ideal is such an
intersection, and so R is a Jacobson ring.
‚Ä¢
The next result will give many examples of Jacobson rings.
Theorem 11.69.
A commutative ring R is a Jacobson ring if and only if R[x] is a Jacob-
son ring.
Proof.
We have seen that every quotient of a Jacobson ring is a Jacobson ring. Hence, if
R[x] is a Jacobson ring, then R ‚àº= R[x]/(x) is also a Jacobson ring.
Conversely, suppose that R is a Jacobson ring. If q is a G-ideal in R[x], then we may
assume that q ‚à©R = {0}, by Exercise 11.36 on page 938. If ŒΩ : R[x] ‚ÜíR[x]/q is the
natural map, then R[x]/q = R[u], where u = ŒΩ(x). Now R[u] is a G-domain, because
q is a G-ideal; hence, if K = Frac(R[u]), then there is v ‚ààK with K = R[u][v‚àí1]. If
Frac(R) = F, then
K = R[u][v‚àí1] ‚äÜF[u][v‚àí1] ‚äÜK,
so that F[u][v‚àí1] = K; that is, F[u] is a G-domain. But F[u] is not a G-domain if u
is transcendental over F, by Corollary 11.61, for F[x] ‚àº= F[u] has inÔ¨Ånitely many prime
ideals. Thus, u is algebraic over F, and hence u is algebraic over R. Since R[u] is a
G-domain, Proposition 11.58 says that R is a G-domain. Now R is a Jacobson ring, and so
R is a Ô¨Åeld, by Exercise 11.34 on page 938. But if R is a Ô¨Åeld, so is R[u], for u is algebraic
over R. Therefore, R[u] = R[x]/q is a Ô¨Åeld, so that q is a maximal ideal, and R[x] is a
Jacobson ring.
‚Ä¢

Sec. 11.2
Dedekind Rings
937
Corollary 11.70.
If k is a Ô¨Åeld, then k[x1, . . . , xn] is a Jacobson ring.
Proof.
The proof is by induction on n ‚â•1. For the base step, k[x] is a PID having
inÔ¨Ånitely many prime ideals, by Exercise 11.40, and so it is a Jacobson ring, by Exam-
ple 11.66(ii). For the inductive step, the inductive hypothesis gives R = k[x1, . . . , xn‚àí1] a
Jacobson ring, and Theorem 11.69 applies.
‚Ä¢
Theorem 11.71.
If m is a maximal ideal in k[x1, . . . , xn], where k is an algebraically
closed Ô¨Åeld, then there are a1, . . . , an ‚ààk such that
m = (x1 ‚àía1, . . . , xn ‚àían).
Proof.
The proof is by induction on n ‚â•1. If n = 1, then m = (p(x)), where p(x) ‚àà
k[x] is irreducible. Since k is algebraically closed, p(x) is linear. For the inductive step,
let R = k[x1, . . . , xn‚àí1]. Corollary 11.70 says that R is a Jacobson ring, and so m ‚à©R is a
G-ideal in R, by Proposition 11.64. Since R is a Jacobson ring, m‚Ä≤ = m ‚à©R is a maximal
ideal. Corollary 11.65 now applies to give m = (m‚Ä≤, f (xn)), where f (xn) ‚ààR[xn] and
f (xn) ‚àà(R/m‚Ä≤)[xn] is irreducible. As k is algebraically closed and R/m‚Ä≤ is a Ô¨Ånitely
generated k-algebra, R/m‚Ä≤ ‚àº= k, and we may assume that f (xn) is linear; there is an ‚ààk
with fn(x) = xn ‚àían. By the inductive hypothesis, m‚Ä≤ = (x1 ‚àía1, . . . , xn‚àí1 ‚àían‚àí1) for
a1, . . . , an‚àí1 ‚ààk, and this completes the proof.
‚Ä¢
We use Theorem 11.71 to prove the Weak Nullstellensatz, Theorem 6.100. Recall that
only the special case of the Nullstellensatz for uncountable algebraically closed Ô¨Åelds was
proved in Chapter 6.
Theorem 11.72 (Weak Nullstellensatz).
If f1(X), . . . , ft(X) ‚ààk[X], where k is an
algebraically closed Ô¨Åeld, then I = ( f1, . . . , ft) is a proper ideal in k[X] if and only if
Var( f1, . . . , ft) Ã∏= ‚àÖ.
Proof.
If I is a proper ideal, then there is a maximal ideal m containing it. By Theo-
rem 6.100, there is a = (a1, . . . , an) ‚ààkn with m = (x1 ‚àía1, . . . , xn ‚àían). Now I ‚äÜm
implies Var(m) ‚äÜVar(I). But a ‚ààVar(m), and so Var(I) Ã∏= ‚àÖ.
‚Ä¢
We could now repeat the proof of the Nullstellensatz over C, Theorem 6.102, to obtain
the Nullstellensatz over any algebraically closed Ô¨Åeld. However, the following proof is
easier.
Theorem 11.73 (Nullstellensatz).
Let k be an algebraically closed Ô¨Åeld. If I is an ideal
in k[x1, . . . , xn], then Id(Var(I)) =
‚àö
I.
Proof.
The inclusion Id(Var(I)) ‚äá
‚àö
I is easy to see. If f n(a) = 0 for all a ‚ààVar(I),
then f (a) = 0 for all a ‚ààVar(I), because the values of f lie in the Ô¨Åeld k. Hence,
f ‚ààId(Var(I)). For the reverse inclusion, note Ô¨Årst that k[x1, . . . , xn] is a Jacobson ring,
by Corollary 11.70; hence, Example 11.66(iv) shows that
‚àö
I is an intersection of maximal
ideals. Let g ‚ààId(Var(I)). If m is a maximal ideal containing I, then Var(m) ‚äÜVar(I),
and so Id(Var(I)) ‚äÜId(Var(m)). But Id(Var(m)) = m: Id(Var(I)) ‚äá‚àöm = m, because
m is a maximal, hence prime ideal. Therefore, g ‚àà m =
‚àö
I, as desired.
‚Ä¢

938
Commutative Rings III
Ch. 11
EXERCISES
11.34 Prove that a commutative ring R is a Ô¨Åeld if and only if R is a Jacobson ring and a G-domain.
11.35 Let E/R be a ring extension in which R is a Ô¨Åeld and E is a domain.
(i) Let b ‚ààE be algebraic over R, prove that there exists an equation
bn + rn‚àí1bn‚àí1 + ¬∑ ¬∑ ¬∑ + r1b + r0 = 0,
where ri ‚ààR for all i and r0 Ã∏= 0.
(ii) If E = R[b1, . . . , bm], where each b j is algebraic over R, prove that E is a Ô¨Åeld.
11.36 Let R be a Jacobson ring, and assume that (R/q‚Ä≤)[x] is a Jacobson ring for every G-ideal q in
R[x], where q‚Ä≤ = q ‚à©R. Prove that R[x] is a Jacobson ring.
11.37
(i) Prove that m = (x2 ‚àíy, y2 ‚àí2) is a maximal ideal in Q[x, y].
(ii) Prove that there do not exist f (x) ‚ààQ[x] and g(y) ‚ààQ[y] with m =

f (x), g(y)

.
11.38 Let k be a Ô¨Åeld and let m be a maximal ideal in k[x1, . . . , xn]. Prove that
m =

f1(x1), f2(x1, x2), . . . , fn‚àí1(x1, . . . , xn‚àí1), fn(x1, . . . , xn)

.
Hint. Use Corollary 11.65.
11.39 Prove that if R is noetherian, then nil(R) is a nilpotent ideal.
11.40 If k is a Ô¨Åeld, prove that k[x] has inÔ¨Ånitely many prime ideals.
Algebraic Integers
We have mentioned that Kummer investigated the ring Z[Œ∂p], where p is an odd prime
and Œ∂p is a primitive pth root of unity. We now study rings of integers in algebraic number
Ô¨Åelds E further. Recall the deÔ¨Ånition:
OE = {Œ± ‚ààE : Œ± is integral over Z}.
We begin with a consequence of Gauss's lemma.
Lemma 11.74.
Let E be an algebraic number Ô¨Åeld with [E : Q] = n, and let Œ± ‚ààE be
an algebraic integer. Then irr(Œ±, Q) ‚ààZ[x] and deg(irr(Œ±, Q)) | n.
Proof.
By Corollary 6.29, irr(Œ±, Q) ‚ààZ[x], and so the result follows from Proposi-
tion 3.117(v).
‚Ä¢
DeÔ¨Ånition.
A quadratic Ô¨Åeld is an algebraic number Ô¨Åeld E with [E : Q] = 2.

Sec. 11.2
Dedekind Rings
939
Proposition 11.75.
Every quadratic Ô¨Åeld E has the form E = Q(
‚àö
d), where d is a
squarefree integer.
Proof.
We know that E = Q(Œ±), where Œ± is a root of a quadratic polynomial; say, Œ±2 +
bŒ± + c = 0, where b, c ‚ààQ. If D = b2 ‚àí4c, then the quadratic formula gives Œ± =
‚àí1
2b ¬± 1
2
‚àö
D, and so E = Q(Œ±) = Q(
‚àö
D). Write D in lowest terms: D = U/V , where
U, V ‚ààZ and (U, V ) = 1. Now U = ur2 and V = vs2, where u, v are squarefree; hence,
uv is squarefree, because (u, v) = 1. Therefore, Q(
‚àö
D) = Q(‚àöu/v) = Q(‚àöuv), for
‚àöu/v =

uv/v2 = ‚àöuv/v.
‚Ä¢
We now describe the integers in quadratic Ô¨Åelds.
Proposition 11.76.
Let E = Q(
‚àö
d), where d is a squarefree integer (which implies that
d Ã∏‚â°0 mod 4).
(i) If d ‚â°2 mod 4 or d ‚â°3 mod 4, then OE = Z[
‚àö
d].
(ii) If d ‚â°1 mod 4, then OE consists of all 1
2

u + v
‚àö
d

with u and v rational integers
having the same parity.
Proof.
If Œ± ‚ààE = Q(
‚àö
d), then there are a, b ‚ààQ with Œ± = a + b
‚àö
d. We Ô¨Årst show
that Œ± ‚ààOE if and only if
2a ‚ààZ
and
a2 ‚àídb2 ‚ààZ.
(3)
If Œ± ‚ààOE, then Lemma 11.74 says that p(x) = irr(Œ±, Q) ‚ààZ[x] is quadratic. Now
Gal(E/Q) = ‚ü®œÉ‚ü©, where œÉ : E ‚ÜíE carries
‚àö
d ‚Üí‚àí
‚àö
d; that is,
œÉ(Œ±) = a ‚àíb
‚àö
d.
Since œÉ permutes the roots of p(x), the other root of p(x) is œÉ(Œ±); that is,
p(x) = (x ‚àíŒ±)(x ‚àíœÉ(Œ±)) = x2 ‚àí2ax + (a2 ‚àídb2).
Hence, Eqs. (3) hold, because p(x) ‚ààZ[x].
Conversely, if Eqs. (3) hold, then Œ± ‚ààOE, because Œ± is a root of x2 ‚àí2ax +(a2 ‚àídb2),
a monic polynomial in Z[x].
We now show that 2b ‚ààZ. Multiplying the second equation in (3) by 4 gives (2a)2 ‚àí
d(2b)2 ‚ààZ. Since 2a ‚ààZ, we have d(2b)2 ‚ààZ. Write 2b in lowest terms: 2b = m/n,
where (m, n) = 1. Now dm2/n2 ‚ààZ, so that n2 | dm2. But (n2, m2) = 1 forces n2 | d;
as d is squarefree, n = 1 and 2b = m/n ‚ààZ.
We have shown that a = 1
2u and b = 1
2v, where u, v ‚ààZ. Substituting these values
into the second equation in (3) gives
u2 ‚â°dv2 mod 4.
(4)
Note that squares are congruent, mod 4, either to 0 or to 1. If d ‚â°2 mod 4, then the
only way to satisfy Eq. (4) is u2 ‚â°0 mod 4 and v2 ‚â°0 mod 4. Thus, both u and v must

940
Commutative Rings III
Ch. 11
be even, and so Œ± = 1
2u + 1
2v
‚àö
d ‚ààZ[
‚àö
d]. Therefore, OE = Z[
‚àö
d] in this case, for
Z[
‚àö
d] ‚äÜOE is easily seen to be true. A similar argument works when d ‚â°3 mod 4.
However, if d ‚â°1 mod 4, then u2 ‚â°v2 mod 4. Hence, v is even if and only if u is even;
that is, u and v have the same parity. If u and v are both even, then a, b ‚ààZ and Œ± ‚ààOE.
If u and v are both odd, then u2 ‚â°1 ‚â°v2 mod 4, and so u2 ‚â°dv2 mod 4, because
d ‚â°1 mod 4. Therefore, Eqs. (3) do hold, and so Œ± lies in OE.
‚Ä¢
If E = Q(
‚àö
d), where d ‚ààZ, then Z[
‚àö
d] ‚äÜOE, but we now see that this inclusion
may be strict. For example, 1
2

1 +
‚àö
5

is an algebraic integer (it is a root of x2 ‚àíx ‚àí6).
Therefore, Z[
‚àö
5] ‚ääOE, where E = Q(
‚àö
5).
The coming brief digression into linear algebra will enable us to prove that rings of
integers OE are noetherian.
DeÔ¨Ånition.
Let E/k be a Ô¨Åeld extension in which E is Ô¨Ånite-dimensional. If u ‚ààE, then
multiplication !u : E ‚ÜíE, given by !u : y ‚Üíuy, is a k-map. If e1, . . . , en is a basis of
E, then !u is represented by a matrix A = [ai j] with entries in k; that is,
¬µ(ei) = uei =

ai je j.
DeÔ¨Åne the trace tr(u) = tr(!u) and the norm N(u) = det(!u). DeÔ¨Åne the trace form
t : E √ó E ‚ÜíR by
t(u, v) = tr(uv) = tr(!uv).
The characteristic polynomial of a linear transformation, and hence, any of its coefÔ¨Å-
cients, is independent of any choice of basis of E/k, and so the deÔ¨Ånitions of trace and
norm do not depend on the choice of basis. If u ‚ààk, then the matrix of !u, with respect to
any basis of E/k, is the scalar matrix uI. Hence,
tr(u) = [E : k]u
and
N(u) = u[E:k]
if u ‚ààk.
It is also easy to see that tr: E ‚Üík is a linear functional and that N : E√ó ‚Üík√ó is a
(multiplicative) homomorphism.
It is a routine exercise, left to the reader, to check that the trace form is a symmetric
bilinear form.
Example 11.77.
If E = Q(
‚àö
d) is a quadratic Ô¨Åeld, then a basis for E/Q is 1,
‚àö
d. If u = a + b
‚àö
d, then
the matrix of !u is
a
bd
b
a

,
so that
tr(u) = 2a
and
N(u) = a2 ‚àídb2.
Thus, trace and norm arose in the description of the integers in quadratic Ô¨Åelds, in Eqs. (3).

Sec. 11.2
Dedekind Rings
941
We now show that u = a +b
‚àö
d is a unit in OE if and only if N(u) = ¬±1. If u is a unit,
then there is v ‚ààOE with 1 = uv. Hence, 1 = N(1) = N(uv) = N(u)N(v), so that N(u)
is a unit in Z; that is, N(u) = ¬±1. Conversely, if N(u) = ¬±1, then N(u) = N(u) = ¬±1,
where u = a ‚àíb
‚àö
d. Therefore, N(uu) = 1. But uu ‚ààQ, so that 1 = N(uu) = (uu)2.
Therefore uu = ¬±1, and so u is a unit.
‚óÄ
Lemma 11.78.
Let E/k be a Ô¨Åeld extension of Ô¨Ånite degree n, and let u ‚ààE. If u =
u1, . . . , us are the roots, with multiplicity, of irr(u, k) (in some extension Ô¨Åeld of E), that
is, irr(u, k) = s
i=1(x ‚àíui), then
tr(u) = [E : k(u)]
s

i=1
ui
and
N(u) =
 s
i=1
ui
[E:k(u)].
Remark.
Of course, if u is separable over k, then irr(u, k) has no repeated roots and each
ui occurs exactly once in the formulas.
‚óÄ
Sketch of Proof.
A basis of k(u) over k is 1, u, u2, . . . , us‚àí1, and the matrix C1 of
!u| k(u) with respect to this basis is the companion matrix of irr(u, k). If 1, v2, . . . , vr
is a basis of E over k(u), then the list
1, u, . . . , us‚àí1, v1, v1u, . . . , v1us‚àí1, . . . , vr, vru, . . . , vrus‚àí1
is a basis of E over k. Each of the subspaces k(u) and ‚ü®v j, v ju, . . . , v jus‚àí1‚ü©for j ‚â•2 is
!u-invariant, and so the matrix of !u relative to the displayed basis of E over k is a direct
sum of blocks C1 ‚äï¬∑ ¬∑ ¬∑ ‚äïCr. In fact, the reader may check that each C j is the companion
matrix of irr(u, k). The trace and norm formulas now follow from tr(C1 ‚äï¬∑ ¬∑ ¬∑ ‚äïCr) =

j tr(C j) and det(C1 ‚äï¬∑ ¬∑ ¬∑ ‚äïCr) = 
j det(C j).
‚Ä¢
If E/k is a Ô¨Åeld extension and u ‚ààE, then a more precise notation for the trace and
norm is
trE/k(u)
and
NE/k(u).
Indeed, the formulas in Lemma 11.78 display the dependence on the larger Ô¨Åeld E.
Proposition 11.79.
Let R be a domain with F = Frac(R), let E/F be a Ô¨Åeld extension
of Ô¨Ånite degree [E : F] = n, and let u ‚ààE be integral over R. If R is integrally closed,
then
tr(u) ‚ààR
and
N(u) ‚ààR.
Proof.
The formulas for tr(u) and N(u) in Lemma 11.78 express each as an elementary
symmetric function of the roots u = u1, . . . , us of irr(u, F). Since u is integral over R,
Exercise 11.33(iii) on page 931 says that irr(u, F) ‚ààR[x]. Therefore, 
i ui and 
i ui lie
in R, and hence tr(u) and N(u) lie in R.
‚Ä¢

942
Commutative Rings III
Ch. 11
In Example 4.35, we saw that if E/k is a Ô¨Ånite separable extension, then its normal
closure E is a Galois extension of k. Recall from the fundamental theorem of Galois theory,
Theorem 4.43, that if G = Gal(E/k) and H = Gal(E/E), then [G : H] = [E : k].
Lemma 11.80.
Let E/k be a separable Ô¨Åeld extension of Ô¨Ånite degree n = [E : k] and
let E be a normal closure of E. Write G = Gal(E/k) and H = Gal(E/E), and let T be a
transversal of H in G; that is, there is a disjoint union G = !
œÉ‚ààT œÉ H.
(i) For all u ‚ààE,

œÉ‚ààT
(x ‚àíœÉ(u)) = irr(u, k)[E:k(u)].
(ii) For all u ‚ààE,
tr(u) =

œÉ‚ààT
œÉ(u)
and
N(u) =

œÉ‚ààT
œÉ(u).
Proof.
(i) Denote 
œÉ‚ààT (x ‚àíœÉ(u)) by h(x); of course, h(x) ‚ààE[x].
We claim that the set X, deÔ¨Åned by X = {œÉ(u) : œÉ ‚ààT }, satisÔ¨Åes œÑ(X) = X for
every œÑ ‚ààG. If œÉ ‚ààT , then œÑœÉ ‚ààœÉ ‚Ä≤H for some œÉ ‚Ä≤ ‚ààT , because T is a left transversal;
hence, œÑœÉ = œÉ ‚Ä≤Œ∑ for some Œ∑ ‚ààH. But œÑœÉ(u) = œÉ ‚Ä≤Œ∑(u) = œÉ ‚Ä≤(u), because Œ∑ ‚ààH,
and every element of H Ô¨Åxes E. Therefore, œÑœÉ(u) = œÉ ‚Ä≤(u) ‚ààX. Thus, the function œïœÑ,
deÔ¨Åned by œÉ(u) ‚ÜíœÑœÉ(u), is a function X ‚ÜíX. In fact, œïœÑ is a permutation, because œÑ
is an isomorphism and so œïœÑ|X is an injection. It follows that every elementary symmetric
function on X = {œÉ(u) : œÉ ‚ààT } is Ô¨Åxed by every œÑ ‚ààG. Since E/k is a Galois extension,
each value of these elementary symmetric functions lies in k. We have shown that all the
coefÔ¨Åcients of h(x) lie in k, and so h(x) ‚ààk[x]. We now compare h(x) and irr(u, k). If
œÉ ‚ààG, then œÉ permutes the roots of irr(u, k), so that every root œÉ(u) of h(x) is also a root
of irr(u, k). By Exercise 3.86 on page 197, we have
h(x) = irr(u, k)m
for some m ‚â•1, and so it only remains to compute m. Now
deg(h) = m deg(irr(u, k)) = m[k(u) : k].
But deg(h) = [G : H] = [E : k], and so m = [E : k]/[k(u) : k] = [E : k(u)].
(ii) Recall our earlier notation: irr(u, k) = s
i=1(x ‚àíui). Since

œÉ‚ààT
(x ‚àíœÉ(u)) = irr(u, k)[E:k(u)] =
 s
i=1
(x ‚àíui)
[E:k(u)],
their constant terms are the same,
¬±

œÉ‚ààT
œÉ(u) = ¬±
 s
i=1
ui
[E:k(u)]
,

Sec. 11.2
Dedekind Rings
943
and their penultimate coefÔ¨Åcients are the same,
‚àí

œÉ‚ààT
œÉ(u) = ‚àí[E : k(u)]
s

i=1
ui.
By Lemma 11.78, tr(u) = [E : k(u)] s
i=1 ui and N(u) =
s
i=1 ui
[E:k(u)]. It follows
that
tr(u) = [E : k(u)]
s

i=1
ui =

œÉ‚ààT
œÉ(u)
and
N(u) =
 s
i=1
ui
[E:k(u)] =

œÉ‚ààT
œÉ(u).
‚Ä¢
DeÔ¨Ånition.
Let E/k be a Ô¨Ånite Ô¨Åeld extension, let E be a normal closure of E, and let T
be a left transversal of Gal(E/E) in Gal(E/k). If u ‚ààE, then the elements œÉ(u), where
œÉ ‚ààT , are called the conjugates of u.
If E/k is a separable extension, then the conjugates of u are the roots of irr(u, k); in the
inseparable case, then the conjugates may occur with multiplicities.
Corollary 11.81.
If E/k is a Galois extension with G = Gal(E/k), then
tr(u) =

œÉ‚ààG
œÉ(u)
and
N(u) =

œÉ‚ààG
œÉ(u).
Proof.
Since E/k is a Galois extension, E is its own normal closure, and so a transversal
T of G in itself is just G.
‚Ä¢
This last corollary shows that the norm here coincides with the norm occurring in Chap-
ter 4 in the proof of Hilbert's Theorem 90.
Let V be a vector space over a Ô¨Åeld k, and let f : V √ó V ‚Üík be a bilinear form. If
e1, . . . , en is a basis of V , then the discriminant is deÔ¨Åned by
D(e1, . . . , en) = det([ f (ei, e j)]).
Recall that f is nondegenerate if there is a basis whose discriminant is nonzero (it then
follows that the discriminant of f with respect to any other basis of V is also nonzero).
Lemma 11.82.
If E/k is a Ô¨Ånite separable6 Ô¨Åeld extension, then the trace form is nonde-
generate.
6If E/k is inseparable, then the trace form is identically 0. See Isaacs, Algebra, A Graduate Course, page
369.

944
Commutative Rings III
Ch. 11
Proof.
We compute the discriminant using Lemma 11.80 (which uses separability). Let
T = {œÉ1, . . . , œÉn} be a transversal of Gal(E/E) in Gal(E/k), where E is a normal closure
of E.
D(e1, . . . , en) = det([t(ei, e j)])
= det([tr(eie j)])
= det

‚Ñì
œÉ‚Ñì(eie j)

(Lemma 11.80)
= det

‚Ñì
œÉ‚Ñì(ei)œÉ‚Ñì(e j)

= det([œÉ‚Ñì(ei)]) det([œÉ‚Ñì(e j)])
= det([œÉ‚Ñì(ei)])2.
To see that det([œÉ‚Ñì(ei)]) Ã∏= 0, we assume otherwise. If [œÉ‚Ñì(ei)] is singular, there is a
column matrix C = [c1, . . . , cn]t ‚ààEn with [œÉ‚Ñì(ei)]C = 0. Hence,
c1œÉ1(e j) + ¬∑ ¬∑ ¬∑ + cnœÉn(e j) = 0
for j = 1, . . . , n. It follows that
c1œÉ1(v) + ¬∑ ¬∑ ¬∑ + cnœÉn(v) = 0
for every linear combination v of the ei. But this contradicts the independence of charac-
ters, Proposition 4.30.
‚Ä¢
Proposition 11.83.
Let R be integrally closed, and let F = Frac(R). If E/F is a Ô¨Ånite
separable Ô¨Åeld extension of degree n, and if O = OE/R is the integral closure of R in E,
then O can be imbedded as a submodule of a free R-module of rank n.
Proof.
Let e1, . . . , en be a basis of E/F. By Proposition 11.46, for each i there is ri ‚ààR
with riei ‚ààO; changing notation if necessary, we may assume that each ei ‚ààO. Now
Corollary 9.76, which uses nondegeneracy of bilinear forms, says that there is a basis
f1, . . . , fn of E with t(ei, f j) = tr(ei f j) = Œ¥i j.
Let Œ± ‚ààO. Since f1, . . . , fn is a basis, there are c j ‚ààF with Œ± =  c j f j. For each
i, where 1 ‚â§i ‚â§n, we have eiŒ± ‚ààO (because ei ‚ààO). Therefore, tr(eiŒ±) ‚ààR, by
Proposition 11.79. But
tr(eiŒ±) = tr

j
c jei f j

=

j
c j tr(ei f j)
= c jŒ¥i j
= ci.
Therefore, ci ‚ààR for all i, and so Œ± = 
i ci fi lies in the free R-module with basis
f1, . . . , fn.
‚Ä¢

Sec. 11.2
Dedekind Rings
945
DeÔ¨Ånition.
If E is an algebraic number Ô¨Åeld, then an integral basis for OE is a list
Œ≤1, . . . , Œ≤n in OE such that every Œ± ‚ààOE has a unique expression
Œ± = c1Œ≤1 + ¬∑ ¬∑ ¬∑ + cnŒ≤n,
where ci ‚ààZ for all i.
We now prove that integral bases always exist.
Proposition 11.84.
Let E be an algebraic number Ô¨Åeld.
(i) The ring of integers OE has an integral basis, and hence it is a free abelian group of
Ô¨Ånite rank under addition.
(ii) OE is a noetherian domain.
Proof.
(i) Since Q has characteristic 0, the Ô¨Åeld extension E/Q is separable. Hence,
Proposition 11.83 applies to show that OE is a submodule of a free Z-module of Ô¨Ånite
rank; that is, OE is a subgroup of a Ô¨Ånitely generated free abelian group. By Corollary 9.4,
OE is itself a free abelian group. But a basis of OE as a free abelian group is an integral
basis.
(ii) Any ideal I in OE is a subgroup of a Ô¨Ånitely generated free abelian group, and hence
I is itself a Ô¨Ånitely generated abelian group, by Proposition 9.7. A fortiori, I is a Ô¨Ånitely
generated OE-module; that is, I is a Ô¨Ånitely generated ideal.
‚Ä¢
Example 11.85.
We show that OE need not be a UFD, and hence it need not be a PID. Let E = Q
‚àö
‚àí5

.
Since ‚àí5 ‚â°3 mod 4, Proposition 11.76 gives OE = Z
‚àö
‚àí5

. By Example 11.77, the
only units in OE are elements u with N(u) = ¬±1. If a2 + 5b2 = ¬±1, where a, b ‚ààZ, then
b = 0 and a = ¬±1, and so the only units in OE are ¬±1. Consider the factorization in OE:
2 ¬∑ 3 =

1 +
‚àö
‚àí5

1 ‚àí
‚àö
‚àí5

.
Note that no two of these factors are associates (the only units are ¬±1), and we now show
that each of them is irreducible. If v ‚ààOE divides any of these four factors (but is not an
associate of it), then N(v) is a proper divisor in Z of 4, 9, or 6, for these are the norms of the
four factors (N

1+
‚àö
‚àí5

= 6 = N

1‚àí
‚àö
‚àí5

). It is quickly checked, however, that there
are no such divisors in Z of the form a2 + 5b2 other than ¬±1. Therefore, OE = Z
‚àö
‚àí5

is not a UFD.
‚óÄ
Trace and norm can be used to Ô¨Ånd other rings of integers.
DeÔ¨Ånition.
If n ‚â•2, then a cyclotomic Ô¨Åeld is E = Q(Œ∂n), where Œ∂n is a primitive nth
root of unity.

946
Commutative Rings III
Ch. 11
Recall that if p is prime, then the cyclotomic polynomial
p(x) = x p‚àí1 + x p‚àí2 + ¬∑ ¬∑ ¬∑ + x + 1 ‚ààZ[x]
is irreducible, so that irr(Œ∂p, Q) = p(x) and [Q(Œ∂p)/Q] = p ‚àí1. Moreover,
Gal(Q(Œ∂p)/Q) = {œÉ1, . . . , œÉp‚àí1},
where œÉi : Œ∂p ‚ÜíŒ∂ i
p for i = 1, . . . , p ‚àí1.
We do some elementary calculations in E = Q(Œ∂p) to enable us to describe OE.
Lemma 11.86.
Let p be an odd prime, and let E = Q(Œ∂), where Œ∂ = Œ∂p is a primitive
pth root of unity.
(i) tr(Œ∂ i) = ‚àí1 f or 1 ‚â§i ‚â§p ‚àí1.
(ii) tr(1 ‚àíŒ∂ i) = p f or 1 ‚â§i ‚â§p ‚àí1.
(iii) p = p‚àí1
i=1 (1 ‚àíŒ∂ i) = N(1 ‚àíŒ∂).
(iv) OE(1 ‚àíŒ∂) ‚à©Z = pZ.
(v) tr(u(1 ‚àíŒ∂)) ‚ààpZ f or every u ‚ààOE.
Proof.
(i) We have tr(Œ∂) = p‚àí1
i=1 Œ∂ i = p(Œ∂) ‚àí1, which is also true for every primitive
pth root of unity Œ∂ i. The result follows from p(Œ∂) = 0.
(ii) Since tr(1) = [E : Q] = p ‚àí1 and tr is a linear functional,
tr(1 ‚àíŒ∂ i) = tr(1) ‚àítr(Œ∂ i) = (p ‚àí1) ‚àí(‚àí1) = p.
(iii) Since (x) = x p‚àí1 + x p‚àí2 + ¬∑ ¬∑ ¬∑ + x + 1, we have p(1) = p. On the other hand,
the primitive pth roots of unity are the roots of p(x), so that
p(x) =
p‚àí1

i=1
(x ‚àíŒ∂ i).
Evaluating at x = 1 gives the Ô¨Årst equation. The second equation holds because the 1‚àíŒ∂ is
are the conjugates of 1 ‚àíŒ∂.
(iv) The Ô¨Årst equation in (iii) shows that p ‚ààOE(1‚àíŒ∂)‚à©Z, so that OE(1‚àíŒ∂)‚à©Z ‚äápZ.
If this inclusion is strict, then OE(1 ‚àíŒ∂) ‚à©Z = Z, because pZ is a maximal ideal in Z. In
this case, OE(1 ‚àíŒ∂) ‚à©Z = Z, hence Z ‚äÜOE(1 ‚àíŒ∂), and so 1 ‚ààOE(1 ‚àíŒ∂). Thus, there
is v ‚ààOE with v(1 ‚àíŒ∂) = 1; that is, 1 ‚àíŒ∂ is a unit in OE. But if 1 ‚àíŒ∂ is a unit, then
N(1 ‚àíŒ∂) = ¬±1, contradicting the second equation in (iii).
(v) Each conjugate œÉi(u(1 ‚àíŒ∂)) = œÉi(u)(1 ‚àíŒ∂ i) is, obviously, divisible by 1 ‚àíŒ∂ i in OE.
But 1 ‚àíŒ∂ i is divisible by 1 ‚àíŒ∂ in OE, because
1 ‚àíŒ∂ i = (1 ‚àíŒ∂)(1 + Œ∂ + Œ∂ 2 + ¬∑ ¬∑ ¬∑ + Œ∂ i‚àí1).

Sec. 11.2
Dedekind Rings
947
Hence, œÉi(1 ‚àíŒ∂ i) ‚ààOE(1 ‚àíŒ∂) for all i, and so 
i(u(1 ‚àíŒ∂ i)) ‚ààOE(1 ‚àíŒ∂). By
Corollary 11.81, 
i(u(1‚àíŒ∂)) = tr(u(1‚àíŒ∂). Therefore, tr(u(1‚àíŒ∂) ‚ààOE(1‚àíŒ∂)‚à©Z = pZ,
by (iv), for tr(u(1 ‚àíŒ∂)) ‚ààZ, by Proposition 11.79.
‚Ä¢
Proposition 11.87.
If p is an odd prime and E = Q(Œ∂p) is a cyclotomic Ô¨Åeld, then
OE = Z[Œ∂p].
Proof.
Let us abbreviate Œ∂p to Œ∂. It is always true that Z[Œ∂] ‚äÜOE, and we now prove that
the reverse inclusion also holds. By Lemma 11.74, each element u ‚ààOE has an expression
u = c0 + c1Œ∂ + c2Œ∂ 2 + ¬∑ ¬∑ ¬∑ + cp‚àí2Œ∂ p‚àí2,
where ci ‚ààQ (remember that [E : Q] = p ‚àí1). We must show that ci ‚ààZ for all i.
Multiplying by 1 ‚àíŒ∂ gives
u(1 ‚àíŒ∂) = c0(1 ‚àíŒ∂) + c1(Œ∂ ‚àíŒ∂ 2) + ¬∑ ¬∑ ¬∑ + cp‚àí2(Œ∂ p‚àí2 ‚àíŒ∂ p‚àí1).
By (i), tr(Œ∂ i ‚àíŒ∂ i+1) = tr(Œ∂ i) ‚àítr(Œ∂ i+1) = 0 for 1 ‚â§i ‚â§p ‚àí2, so that tr(u(1 ‚àíŒ∂)) =
c0 tr(1 ‚àíŒ∂); hence, tr(u(1 ‚àíŒ∂) = pc0, because tr(1 ‚àíŒ∂) = p, by (ii). On the other hand,
tr(u(1 ‚àíŒ∂)) ‚ààpZ, by (iv). Hence, pc0 = mp for some m ‚ààZ, and so c0 ‚ààZ. Now
Œ∂ ‚àí1 = Œ∂ p‚àí1 ‚ààOE, so that
(u ‚àíc0)Œ∂ ‚àí1 = c1 + c2Œ∂ + ¬∑ ¬∑ ¬∑ + cp‚àí2Œ∂ p‚àí3 ‚ààOE.
The argument just given shows that c1 ‚ààZ. Indeed, repetition of this argument shows that
all ci ‚ààZ, and so u ‚ààZ[Œ∂].
‚Ä¢
Before we leave this interesting topic, we must mention a beautiful theorem of Dirich-
let. For proofs of the following statements, see Samuel, Algebraic Theory of Numbers,
Chapter 4. An algebraic number Ô¨Åeld E of degree n has exactly n imbeddings into C. If r1
is the number of such imbeddings with image in R, then n ‚àír1 is even; say, n ‚àír1 = 2r2.
Theorem (Dirichlet Unit Theorem).
Let E be an algebraic number Ô¨Åeld of degree
n. Then n = r1 + 2r2, (where r1 is the number of imbeddings of E into R), and the
multiplicative group U(OE) of units in OE is a Ô¨Ånitely generated abelian group. More
precisely,
U(OE) ‚àº= Zr1+r2‚àí1 √ó T,
where T is a Ô¨Ånite cyclic group consisting of the roots of unity in E.

948
Commutative Rings III
Ch. 11
EXERCISES
11.41
(i) If E = Q
‚àö
‚àí3

, prove that the only units in OE are
¬±1,
1
2

1 ¬±
‚àö
‚àí3

,
1
2

‚àí1 ¬±
‚àö
‚àí3

,
(ii) Let d be a negative squarefree integer with d Ã∏= ‚àí1 and d Ã∏= ‚àí3. If E = Q
‚àö
d

, prove
that the only units in OE are ¬±1.
11.42
(i) Prove that if E = Q
‚àö
2

‚äÜR, then there are no units u ‚ààOE with 1 < u < 1 +
‚àö
2.
(ii) If E = Q
‚àö
2

, prove that OE has inÔ¨Ånitely many units.
Hint. Use (i) to prove that all powers of 1 +
‚àö
2 are distinct.
DeÔ¨Ånition.
If OE is the ring of integers in an algebraic number Ô¨Åeld E, then a discriminant of
OE is
(OE) =

i< j
(Œ±i ‚àíŒ± j)2,
where Œ±1, . . . , Œ±n is an integral basis of OE.
11.43 Let d be a squarefree integer, and let E = Q
‚àö
d

.
(i) If d ‚â°2 mod 4 or d ‚â°3 mod 4, prove that 1,
‚àö
d is an integral basis of OE, and prove
that a discriminant of OE is 4d.
(ii) If d ‚â°1 mod 4, prove that 1, 1
2

1 +
‚àö
d

is an integral basis of OE, and prove that a
discriminant of OE is d.
11.44 Let p be an odd prime, and let E = Q

Œ∂p

be the cyclotomic Ô¨Åeld.
(i) Show that 1, 1 ‚àíŒ∂p, (1 ‚àíŒ∂p)2, . . . , (1 ‚àíŒ∂p)p‚àí2 is an integral basis for OE.
(ii) Prove that a discriminant of OE is (‚àí1)
1
2 (p‚àí1) p p‚àí2.
Hint. See Pollard, The Theory of Algebraic Numbers, page 67.
11.45
(i) If A is the Ô¨Åeld of all algebraic numbers, prove that OA is not noetherian.
(ii) Prove that every nonzero prime ideal in OA is a maximal ideal.
Hint. Use the proof of Corollary 11.53.
Characterizations of Dedekind Rings
The following deÔ¨Ånition involves some of the ring-theoretic properties enjoyed by the ring
of integers OE in an algebraic number Ô¨Åeld E.
DeÔ¨Ånition.
A domain R is a Dedekind ring if it is integrally closed, noetherian, and its
nonzero prime ideals are maximal ideals.

Sec. 11.2
Dedekind Rings
949
Example 11.88.
(i) The ring OE in an algebraic number Ô¨Åeld E is a Dedekind ring, by Proposition 11.46,
Proposition 11.84, and Corollary11.53.
(ii) Every principal ideal domain R is a Dedekind ring.
‚óÄ
It is shown, in Example 11.85, that R = Z
‚àö
‚àí5

is a Dedekind ring that is not a UFD
and, hence, it is not a PID. We remind the reader that E. Kummer, in his investigations
into Fermat's last theorem in the 1840s, recognized such examples, and he forced unique
factorization by adjoining "ideal" numbers to rings of integers. About 30 years later, R.
Dedekind introduced the modern deÔ¨Ånition of ideal, and showed that Kummer's ideal num-
bers correspond to Dedekind's ideals. We will prove, in Theorem 11.95, that every nonzero
ideal in a Dedekind ring has a unique factorization as a product of prime ideals.
We now characterize DVRs, and then show that localizations of Dedekind rings are
well-behaved.
Lemma 11.89.
A domain R is a DVR if and only if it is noetherian, integrally closed,
and has a unique nonzero prime ideal.
Proof.
If R is a DVR, then it does have the required properties (recall that R is a PID,
hence it is integrally closed).
The converse, which requires us to show that R is a PID, is not as simple as we would
expect. Let p be the nonzero prime ideal, and choose a nonzero a ‚ààp. DeÔ¨Åne M = R/Ra,
and consider the family A of all the annihilators ann(m) as m varies over all the nonzero
elements of M. Since R is noetherian, it satisÔ¨Åes the maximum condition, and so there is
a nonzero element b + Ra ‚ààM whose annihilator q = ann(b + Ra) is maximal in A.
We claim that q is a prime ideal. Suppose that x, y ‚ààR, xy ‚ààq, and x, y /‚ààq. Then
y(b + Ra) = yb + Ra is a nonzero element of M, because y /‚ààq. But ann(yb + Ra) ‚äã
ann(b + Ra), because x /‚ààann(b + Ra), contradicting the maximality property of q.
Therefore, q is a prime ideal. Since R has a unique nonzero prime ideal p, we have
q = ann(b + Ra) = p.
Note that
b/a /‚ààR.
Otherwise, b+Ra = 0+Ra, contradicting b+Ra being a nonzero element of M = R/Ra.
We now show that p is principal, with generator a/b (we do not yet know whether
a/b ‚ààFrac(R) lies in R). First, we have pb = qb ‚äÜRa, so that p(b/a) ‚äÜR; that
is, p(b/a) is an ideal in R. If p(b/a) ‚äÜp, then b/a is integral over R, for p is a Ô¨Ånitely
generated R-submodule of Frac(R), as required in Lemma 11.41. As R is integrally closed,
this puts b/a ‚ààR, contradicting what we noted at the end of the previous paragraph.
Therefore, p(b/a) is not a proper ideal, so that p(b/a) = R and p = R(a/b). It follows
that a/b ‚ààR and p is a principal ideal.
Denote a/b by t. The proof is completed by showing that the only nonzero ideals in
R are the principal ideals generated by tn, for n ‚â•0. Let I be a nonzero ideal in R, and

950
Commutative Rings III
Ch. 11
consider the chain of submodules of Frac(R):
I ‚äÜIt‚àí1 ‚äÜIt‚àí2 ‚äÜ¬∑ ¬∑ ¬∑ .
We claim that this chain is strictly increasing. If It‚àín = It‚àín‚àí1, then the Ô¨Ånitely generated
R-module It‚àí1 satisÔ¨Åes t‚àí1(It‚àín) ‚äÜIt‚àín, so that t‚àí1 = b/a is integral over R. As
above, R integrally closed forces b/a ‚ààR, a contradiction. Since R is noetherian, this
chain can contain only Ô¨Ånitely many ideals in R. Thus, there is n with It‚àín ‚äÜR and
It‚àín‚àí1 Ã∏‚äÜR. If It‚àín ‚äÜp = Rt, then It‚àín‚àí1 ‚äÜR, a contradiction. Therefore, It‚àín = R
and I = Rtn, as desired.
‚Ä¢
Proposition 11.90.
If R is a noetherian domain, then R is a Dedekind ring if and only if
for every nonzero prime ideal p, the localization Rp is a DVR.
Remark.
Exercise 11.45 on page 948 shows that it is necessary to assume that R is
noetherian.
‚óÄ
Proof.
If R is a Dedekind ring and p is a maximal ideal, Corollary 11.18(iv) shows that
Rp has a unique nonzero prime ideal. Moreover, Rp is noetherian (Corollary 11.18(v)), a
domain (Corollary 11.16), and integrally closed (Exercise 11.26). By Lemma 11.89, Rp is
a DVR.
For the converse, we must show that R is integrally closed and that its nonzero prime
ideals are maximal. Let u/v ‚ààFrac(R) be integral over R. For every nonzero prime ideal
p, the element u/v is integral over Rp (note that Frac(Rp) = Frac(R)). But Rp is a PID,
hence is integrally closed, and so u/v ‚ààRp. We conclude that u/v ‚àà
p Rp = R, by
Proposition 11.20. Therefore, R is integrally closed.
Suppose there were nonzero prime ideals p ‚ääq in R. By Corollary 11.18(iv), pq ‚ääqq
in Rq. This contradicts the fact that a DVR has a unique nonzero prime ideal. Therefore,
nonzero prime ideals are maximal, and so R is a Dedekind ring.
‚Ä¢
Let R be a domain with F = Frac(R), and let I = Ra be a nonzero principal ideal in
R. If we deÔ¨Åne J = Ra‚àí1 ‚äÜF, the cyclic R-submodule generated by a‚àí1, then it easy to
see that
I J = {uv : u ‚ààI and v ‚ààJ} = R.
DeÔ¨Ånition.
If R is a domain with F = Frac(R), then a fractional ideal is a Ô¨Ånitely
generated nonzero R-submodule of F. If I is a nonzero ideal in R, then
I ‚àí1 = {v ‚ààF : vI ‚äÜR}.
It is always true that I ‚àí1I ‚äÜR; a fractional ideal I is invertible if I ‚àí1I = R.
Every Ô¨Ånitely generated ideal in R is also a fractional ideal. In this context, we often
call such ideals (which are the usual ideals!) integral ideals when we want to contrast them
with more general fractional ideals.

Sec. 11.2
Dedekind Rings
951
We claim that if I = Ra is a nonzero principal ideal in R, then I ‚àí1 = Ra‚àí1. Clearly,
(ra‚àí1)(r‚Ä≤a) = rr‚Ä≤ ‚ààR for all r‚Ä≤ ‚ààR, so that Ra‚àí1 ‚äÜI ‚àí1. For the reverse inclusion,
suppose that (u/v)a ‚ààR, where u, v ‚ààR. Then v | ua in R, so there is r ‚ààR with
rv = ua. Hence, in F, we have u = rva‚àí1, so that u/v = (rva‚àí1)/v = ra‚àí1. Therefore,
every nonzero principal ideal in R is invertible.
Lemma 11.91.
If R is a domain with F = Frac(R), then a fractional ideal I is invertible
if and only if there exist a1, . . . , an ‚ààI and q1, . . . , qn ‚ààF with
(i) qi I ‚äÜR for i = 1, . . . , n;
(ii) 1 = n
i=1 qiai.
Proof.
If I is invertible, then I ‚àí1I = R. Since 1 ‚ààI ‚àí1I, there are a1, . . . , an ‚ààR and
q1, . . . , qn ‚ààI ‚àí1 with 1 = 
i qiai. Since qi ‚ààI ‚àí1, we have qi I ‚äÜR.
To prove the converse, the R-submodule J of F generated by q1, . . . , qn is a fractional
ideal. Since 1 = n
i=1 qiai ‚ààJ I, J I is an R-submodule of R containing 1; that is,
J I = R. To see that I is invertible, it remains to prove that J = I ‚àí1. Clearly, each
qi ‚ààI ‚àí1, so that J ‚äÜI ‚àí1. For the reverse inclusion, assume that u ‚ààF and uI ‚äÜR.
Since 1 = 
i qiai, we have u = 
i(uai)qi ‚ààJ because uai ‚ààR for all i.
‚Ä¢
Corollary 11.92.
Every invertible ideal I in a domain R is Ô¨Ånitely generated.
Proof.
Since I is invertible, there exist a1, . . . , an ‚ààI and q1, . . . , qn ‚ààF as in the
lemma. If b ‚ààI, then b = b1 = 
i bqiai ‚ààI, because bqi ‚ààR. Therefore, I is
generated by a1, . . . , an ‚ààI.
‚Ä¢
Proposition 11.93.
The following conditions are equivalent for a domain R.
(i) R is a Dedekind ring.
(ii) Every fractional ideal is invertible.
(iii) The set of all the fractional ideals F(R) forms an abelian group under multiplication
of ideals.
Proof.
(i) ‚áí(ii).
Let J be a fractional ideal in R. Since R is a Dedekind ring, its localization Rp is
a PID, and so Jp, as every nonzero principal ideal, is invertible (in Theorem 9.3, in the
course of proving that Ô¨Ånitely generated torsion-free abelian groups are free abelian, we
really proved that fractional ideals of PIDs are cyclic modules). Now Exercise 11.50 on
page 958 gives
(J ‚àí1J)p = (J ‚àí1)pJp = (Jp)‚àí1Jp = Rp.
Proposition 11.30 gives J ‚àí1J = R, and so J is invertible.
(ii) ‚áî(iii).

952
Commutative Rings III
Ch. 11
If I, J ‚ààF(R), then they are Ô¨Ånitely generated, by Corollary 11.92, and
I J =

a‚Ñìb‚Ñì: a‚Ñì‚ààI and b‚Ñì‚ààJ

is a Ô¨Ånitely generated R-submodule of Frac(R). If I = (a1, . . . , an) and J = (b1, . . . , bm),
then I J is generated by all aib j. Hence, I J is Ô¨Ånitely generated and I J ‚ààF(R). Asso-
ciativity does hold, the identity is R, and the inverse of a fractional ideal J is J ‚àí1, because
J is invertible. It follows that F(R) is an abelian group.
Conversely, if F(R) is an abelian group and I ‚ààF(R), then there is J ‚ààF(R) with
J I = R. We must show that J = I ‚àí1. But
R = J I ‚äÜI ‚àí1I ‚äÜR,
so that J I = I ‚àí1I. Canceling I in the group F(R) gives J = I ‚àí1, as desired.
(iii) ‚áí(i).
First, R is noetherian, for (iii) ‚áí(ii) shows that every nonzero ideal I is invertible, and
Corollary 11.92 shows that I is Ô¨Ånitely generated.
Second, we show that every nonzero prime ideal p is a maximal ideal. Let I be an ideal
with p ‚ääI (we allow I = R). Then pI ‚àí1 ‚äÜI I ‚àí1 = R, so that pI ‚àí1 is an (integral) ideal
in R. Now (pI ‚àí1)I = p, because multiplication is associative in F(R). Since p is a prime
ideal, Proposition 6.13 says that either pI ‚àí1 ‚äÜp or I ‚äÜp. The second option does not
hold, so that pI ‚àí1 ‚äÜp. Multiplying by p‚àí1I gives R ‚äÜI. Therefore, I = R, and so p is
a maximal ideal.
Third, if a ‚ààFrac(R) is integral over R, then Lemma 11.41 gives a Ô¨Ånitely generated R-
submodule J of Frac(R), i.e., a fractional ideal, with aJ ‚äÜJ. Since J is invertible, there
are q1, . . . , qn ‚ààFrac(R) and a1, . . . , an ‚ààJ with qi J ‚äÜR for all i and 1 =  qiai.
Hence, a = 
i qiaia. But aia ‚ààJ and qi J ‚äÜR gives a = 
i qi(aia) ‚ààR. Therefore,
R is integrally closed, and hence it is a Dedekind ring.
‚Ä¢
Proposition 11.94.
(i) If R is a UFD, then a nonzero ideal I in R is invertible if and only if it is principal.
(ii) A Dedekind ring R is a UFD if and only if it is a PID.
Proof.
(i) We have already seen that every nonzero principal ideal is invertible. Con-
versely, if I is invertible, there are elements a1, . . . , an ‚ààI and q1, . . . , qn ‚ààFrac(R) with
1 = 
i qiai and qi I ‚äÜR for all i. Let qi = bi/ci, where b,ci ‚ààR. Since R is a UFD, we
may assume that qi is in lowest terms; that is, (bi, ci) = 1. But (bi/ci)a j ‚ààR says that
ci | bia j, so that ci | a j for all i, j, by Exercise 6.18(i) on page 339. We claim that I = Rc,
where c = lcm{c1, . . . , cn}. First, c ‚ààI, for cbi/ci ‚ààR and c = c1 = 
i(cbi/ci)ai.
Hence, Rc ‚äÜI. For the reverse inclusion, Exercise 6.18(ii) on page 339 shows that c | a j
for all j, so that a j ‚ààRc, for all j, and so I ‚äÜRc.
(ii) Since every nonzero ideal in a Dedekind ring is invertible, it follows from (i) that if R
is a UFD, then every ideal in R is principal.
‚Ä¢

Sec. 11.2
Dedekind Rings
953
DeÔ¨Ånition.
If R is a Dedekind ring, then its class group C(R) is deÔ¨Åned by
C(R) = F(R)/P(R),
where P(R) is the subgroup of all nonzero principal ideals.
Dirichlet proved, for every algebraic number Ô¨Åeld E, that the class group of C(OE) is
Ô¨Ånite; the order |C(R)| is called the class number of OE. The usual proof of Ô¨Åniteness of
the class number uses a geometric theorem of H. Minkowski which says that sufÔ¨Åciently
large parallelopipeds in euclidean space must contain lattice points (see Samuel, Algebraic
Theory of Numbers, pages 57-58).
L. Claborn proved, for every (not necessarily Ô¨Ånite) abelian group G, that there is a
Dedekind ring R with C(R) ‚àº= G.
We can now prove the result linking Kummer and Dedekind.
Theorem 11.95.
If R is a Dedekind ring, then every proper nonzero ideal has a unique
factorization as a product of prime ideals.
Proof.
Let S be the family of all proper nonzero ideals in R that are not products of prime
ideals. If S = ‚àÖ, then every nonzero ideal in R is a product of prime ideals. If S Ã∏= ‚àÖ,
then S has a maximal element I, because noetherian rings satisfy the maximum condition
(Proposition 6.38). Now I cannot be a maximal ideal in R, for a "product of prime ideals"
is allowed to have only one factor. Let m be a maximal ideal containing I. Since I ‚ääm, we
have m‚àí1I ‚ääm‚àí1m = R; that is, m‚àí1I is a proper ideal properly containing I. Neither
m nor m‚àí1I lies in S, for each is strictly larger than a maximal element, namely, I, and
so each of them is a product of prime ideals. Therefore, I = m(m‚àí1I) (equality holding
because R is a Dedekind ring) is a product of prime ideals, contradicting I being in S.
Therefore, S = ‚àÖ, and every proper nonzero ideal in R is a product of prime ideals.
Suppose that p1 ¬∑ ¬∑ ¬∑ pr = q1 ¬∑ ¬∑ ¬∑ qs, where the pi and q j are prime ideals. We prove
unique factorization by induction on max{r, s}. The base step r = 1 = s is obviously
true. For the inductive step, note that p1 ‚äáq1 ¬∑ ¬∑ ¬∑ qs, so that Proposition 6.13 gives q j with
p1 ‚äáq j. Hence, p1 = q j, because prime ideals are maximal. Now multiply the original
equation by p‚àí1
1
and use the inductive hypothesis.
‚Ä¢
Corollary 11.96.
If R is a Dedekind ring, then F(R) is a free abelian group with basis
all the nonzero prime ideals.
Proof.
Of course, F(R) is written multiplicatively. That every fractional ideal is a prod-
uct of primes shows that the set of primes generates F(R); uniqueness of the factorization
says the set of primes is a basis.
‚Ä¢
In light of Theorem 11.95, many of the usual formulas of arithmetic extend to ideals in
Dedekind rings. Observe that in Z, the ideal (3) contains (9). In fact, Zm ‚äáZn if and only
if m | n. We will now see that the relation "contains" for ideals is the same as "divides,"
and that the usual formulas for gcd's and lcm's (Proposition 1.17) generalize to Dedekind
rings.

954
Commutative Rings III
Ch. 11
Proposition 11.97.
Let I and J be nonzero ideals in a Dedekind ring R, and let their
prime factorizations be
I = pe1
1 ¬∑ ¬∑ ¬∑ pen
n
and
J = p f1
1 ¬∑ ¬∑ ¬∑ p fn
n ,
where ei ‚â•0 and fi ‚â•0 for all i.
(i) J ‚äáI if and only if I = J L for some ideal L.
(ii) J ‚äáI if and only if fi ‚â§ei for all i.
(iii) If mi = min{ei, fi} and Mi = max{ei, fi}, then
I ‚à©J = pM1
1
¬∑ ¬∑ ¬∑ pMn
n
and
I + J = pm1
1 ¬∑ ¬∑ ¬∑ pmn
n .
In particular, I + J = R if and only if min{ei, fi} = 0 for all i.
(iv) Let R be a Dedekind ring, and let I = pe1
1 ¬∑ ¬∑ ¬∑ pen
n be a nonzero ideal in R. Then
R/I = R/pe1
1 ¬∑ ¬∑ ¬∑ pen
n ‚àº=

R/pe1
1

√ó ¬∑ ¬∑ ¬∑ √ó

R/pen
n

.
Proof.
(i) If I ‚äÜJ, then J ‚àí1I ‚äÜR, and
J(J ‚àí1I) = I.
Conversely, if I = J L, then I ‚äÜJ because J L ‚äÜJ R = J.
(ii) This follows from (i) and the unique factorization of nonzero ideals as products of
prime ideals.
(iii) We prove the formula for I + J. Let I + J = pr1
1 ¬∑ ¬∑ ¬∑ prn
n and let A = pm1
1 ¬∑ ¬∑ ¬∑ pmn
n . Since
I ‚äÜI + J and J ‚äÜI + J, we have ri ‚â§ei and ri ‚â§fi, so that ri ‚â§min{ei, fi} = mi.
Hence, A ‚äÜI + J. For the reverse inclusion, A ‚äÜI and A ‚äÜJ, so that A = I I ‚Ä≤ and
A = J J ‚Ä≤ for ideals I ‚Ä≤ and J ‚Ä≤, by (i). Therefore, I + J = AI ‚Ä≤ + AJ ‚Ä≤ = A(I ‚Ä≤ + J ‚Ä≤), and so
I + J ‚äÜA. The proof of the formula for I J is left to the reader.
(iv) This is just the Chinese remainder theorem, Exercise 6.11(iii) on page 325, so that it
sufÔ¨Åces to verify the hypothesis that pei
i and p
e j
j are coprime when i Ã∏= j; that is, pei
i +p
e j
j =
R. But this follows from (iii).
‚Ä¢
Recall Proposition 7.58: an R-module A is projective if and only if it has a projective
basis: there exist elements {a j : j ‚ààJ} ‚äÜA and R-maps {œï j : A ‚ÜíR : j ‚ààJ} such that
(i) for each x ‚ààA, almost all œï j(x) = 0;
(ii) for each x ‚ààA, we have x = 
j‚ààJ(œï j x)a j.

Sec. 11.2
Dedekind Rings
955
Proposition 11.98.
(i) A nonzero ideal I in a domain R is invertible if and only if I is a projective R-module.
(ii) A domain R is a Dedekind ring if and only if every ideal in R is projective.
Proof.
(i) If I is invertible, there are elements a1, . . . , an ‚ààI and q1, . . . , qn ‚ààFrac(R)
with 1 = 
i qiai and qi I ‚äÇR for all i. DeÔ¨Åne œïi : I ‚ÜíR by œïi : a ‚Üíqia (note that
im œïi ‚äÜI because qi I ‚äÜR). If a ‚ààI, then

i
œïi(a)ai =

i
qiaai = a

i
qiai = a.
Therefore, I has a projective basis, and so I is a projective R-module.
Conversely, if I is a projective, it has a projective basis {œï j : j ‚ààJ}, {a j : j ‚ààJ}. If
b ‚ààI is nonzero, deÔ¨Åne q j ‚ààFrac(R) by
q j = œï j(b)/b.
This element does not depend on the choice of nonzero b: if b‚Ä≤ ‚ààI is nonzero, then
b‚Ä≤œï j(b) = œï j(b‚Ä≤b) = bœï j(b‚Ä≤), so that œï j(b)/b = œï j(b‚Ä≤)/b‚Ä≤. To see that q j I ‚äÜR, note
that if b ‚ààI is nonzero, then q jb =

œï j(b)/b

b = œï j(b) ‚ààR. By item (i) in the deÔ¨Ånition
of projective basis, almost all œï j(b) = 0, and so there are only Ô¨Ånitely many nonzero
q j = œï j(b)/b (remember that q j does not depend on the choice of nonzero b ‚ààI).
Item (ii) in the deÔ¨Ånition of projective basis gives, for b ‚ààI,
b =

j
œï j(b)a j =

j
(q jb)a j = b

j
q ja j

.
Canceling b gives 1 = 
j q ja j. Finally, the set of those a j with indices j for which
q j Ã∏= 0 completes the data necessary to show that I is an invertible ideal.
(ii) This follows at once from (i) and Proposition 11.93.
‚Ä¢
Example 11.99.
We have seen that R = Z
‚àö
‚àí5

is a Dedekind ring that is not a PID. Any non-principal
ideal gives an example of a projective R-module that is not free.
‚óÄ
Remark.
A not necessarily commutative ring R is called left hereditary if every left ideal
is a projective R-module (there exist rings that are left hereditary but not right hereditary).
Some examples of left hereditary rings aside from Dedekind rings are semisimple rings,
noncommutative principal ideal rings, and FIRs (free ideal rings‚Äîall left ideals are free R-
modules). P. M. Cohn proved that polynomial rings over a Ô¨Åeld in noncommuting variables
are FIRs, and so there exist left hereditary rings that are not left noetherian.
‚óÄ
The projective and injective modules over a Dedekind ring are well-behaved.

956
Commutative Rings III
Ch. 11
Lemma 11.100.
A left R-module P (over any ring R) is projective if and only if every
diagram below with E injective can be completed to a commutative diagram. The dual
characterization of injective modules is also true.
P


E
 E‚Ä≤‚Ä≤
 0
Proof.
If P is projective, then the diagram can be completed for every not necessarily
injective module E. Conversely, we must show that the diagram
P

f

A
g
 A‚Ä≤‚Ä≤
 0
can be completed for any module A and any surjection g : A ‚ÜíA‚Ä≤‚Ä≤. By Theorem 8.104,
there is an injective R-module E and an injection œÉ : A ‚ÜíE. DeÔ¨Åne E‚Ä≤‚Ä≤ = coker œÉi =
E/ im œÉi, and consider the commutative diagram with exact rows
P
œÄ
6
f

0
 A‚Ä≤
i

1A‚Ä≤

A
g

œÉ

A‚Ä≤‚Ä≤

h

0
0
 A‚Ä≤
œÉi
 E
ŒΩ
 E‚Ä≤‚Ä≤
 0,
where ŒΩ : E ‚ÜíE‚Ä≤‚Ä≤ = coker œÉi is the natural map and h : A‚Ä≤‚Ä≤ ‚ÜíE‚Ä≤‚Ä≤ exists by Propo-
sition 8.93. By hypothesis, there exists a map œÄ : P ‚ÜíE with ŒΩœÄ = h f . We claim
that im œÄ ‚äÜim œÉ. For x ‚ààP, surjectivity of g gives a ‚ààA with ga = f x. Then
ŒΩœÄx = h f x = hga = ŒΩœÉa, and so œÄx ‚àíœÉa ‚ààker ŒΩ = im œÉi; hence, œÄx ‚àíœÉa = œÉia‚Ä≤
for some a‚Ä≤ ‚ààA‚Ä≤, and so œÄx = œÉ(a + ia‚Ä≤) ‚ààim œÉ. Therefore, if x ‚ààP, there is a unique
a ‚ààA with œÉa = œÄx (a is unique because œÉ is an injection). Thus, there is a well-deÔ¨Åned
function œÄ‚Ä≤ : P ‚ÜíA, given by œÄ‚Ä≤x = a, where œÉa = œÄx. The reader may check that œÄ‚Ä≤
is an R-map and that gœÄ‚Ä≤ = f .
‚Ä¢
Theorem 11.101 (Cartan-Eilenberg).
The following conditions are equivalent for a
domain R.
(i) R is a Dedekind ring.
(ii) Every submodule of a projective R-module is projective.
(iii) Every quotient of an injective R-module is injective.

Sec. 11.2
Dedekind Rings
957
Proof.
(i) ‚áî(ii).
If R is Dedekind, then we can adapt the proof of Theorem 9.8 (which proves that every
subgroup of a free abelian group is free abelian) to prove that every submodule of a free
R-module is projective (see Exercise 11.47 on page 958); in particular, every submodule of
a projective R-module is projective. Conversely, since R itself is a projective R-module,
its submodules are also projective, by hypothesis; that is, the ideals of R are projective.
Proposition 11.98 now shows that R is a Dedekind ring.
(ii) ‚áî(iii).
Assume (iii), and consider the diagram with exact rows
P


P‚Ä≤
f


0

E
 E‚Ä≤‚Ä≤
 0,
where P is projective and E is injective; note that the hypothesis gives E‚Ä≤‚Ä≤ injective. To
prove projectivity of P‚Ä≤, it sufÔ¨Åces, by Lemma 11.100, to Ô¨Ånd a map P‚Ä≤ ‚ÜíE making
the diagram commute. Since E‚Ä≤‚Ä≤ is injective, there exists a map P ‚ÜíE‚Ä≤‚Ä≤ giving com-
mutativity. Since P is projective, there is a map P ‚ÜíE also giving commutativity. The
composite P‚Ä≤ ‚ÜíP ‚ÜíE is the desired map. The converse is the dual of this, using the
dual of Lemma 11.100.
‚Ä¢
Corollary 11.102.
Let R be a Dedekind ring.
(i) For all R-modules C and A, then for all n ‚â•2,
Extn
R(C, A) = {0}
and
TorR
n (C, A) = {0}.
(ii) Let 0 ‚ÜíA‚Ä≤ ‚ÜíA ‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 be a short exact sequence. For every module C, there
are exact sequences
0 ‚ÜíHom(C, A‚Ä≤) ‚ÜíHom(C, A) ‚ÜíHom(C, A‚Ä≤‚Ä≤)
‚ÜíExt1(C, A‚Ä≤) ‚ÜíExt1(C, A) ‚ÜíExt1(C, A‚Ä≤‚Ä≤) ‚Üí0
and
0 ‚ÜíTorR
1 (C, A‚Ä≤) ‚ÜíTorR
i (C, A) ‚ÜíTorR
1 (C, A‚Ä≤‚Ä≤)
‚ÜíC ‚äóR A‚Ä≤ ‚ÜíC ‚äóR A ‚ÜíC ‚äóR A‚Ä≤‚Ä≤ ‚Üí0
Proof.
(i) By deÔ¨Ånition, if
¬∑ ¬∑ ¬∑ ‚ÜíP2
d2
‚àí‚ÜíP1
d1
‚àí‚ÜíP0 ‚ÜíC ‚Üí0
is a projective resolution of C, then
Extn(C, A) = ker d‚àó
n+1/ im d‚àó
n;

958
Commutative Rings III
Ch. 11
moreover, Extn(C, A) does not depend on the choice of projective resolution, by Corol-
lary 10.74. Now C is a quotient of a free module F, and so there is an exact sequence
0 ‚ÜíK ‚ÜíF
Œµ
‚àí‚ÜíC ‚Üí0,
(5)
where K = ker Œµ. Since R is Dedekind, the submodule K of the free R-module F is
projective, so that (5) deÔ¨Ånes a projective resolution of C with P0 = F, P1 = K, and
Pn = {0} for all n ‚â•2. Hence, ker d‚àó
n+1 ‚äÜHom(Pn, A) = {0} for all n ‚â•2, and so
Extn
R(C, A) = {0} for all A and for all n ‚â•2. A similar argument works for Tor.
(ii) This follows from Corollary 10.68 and Corollary 10.57, the long exact sequence for
Ext and for Tor, respectively.
‚Ä¢
We will use this result in the next section to generalize Proposition 10.92.
EXERCISES
11.46 Let R be a commutative ring and let M be a Ô¨Ånitely generated R-module. Prove that if I M =
M for some ideal I of R, then there exists a ‚ààJ with (1 ‚àía)M = {0}.
Hint.
If M = ‚ü®m1 . . . , mn‚ü©, then each mi = 
j ai jm j, where ai j ‚ààI. Use the adjoint
matrix (the matrix of cofactors) as in the proof of Lemma 11.41.
11.47 Generalize the proof of Theorem 9.8 to prove that if R is a left hereditary ring, then every
submodule of a free left R-module F is isomorphic to a direct sum of ideals, and hence is
projective.
11.48 Let R be a Dedekind ring, and let p be a nonzero prime ideal in R.
(i) If a ‚ààp, prove that p occurs in the prime factorization of Ra.
(ii) If a ‚ààpe and a /‚ààpe+1, prove that pe occurs in the prime factorization of Ra, but that
pe+1 does not occur in the prime factorization of Ra.
11.49 Let I be a nonzero ideal in a Dedekind ring R. Prove that if p is a prime ideal, then I ‚äÜp if
and only if p occurs in the prime factorization of I.
11.50 If J is a fractional ideal of a Dedekind ring R, prove that (J‚àí1)p = (Jp)‚àí1 for every maximal
ideal p.
11.51 Let I1, . . . , In be ideals in a Dedekind ring R. If there is no nonzero prime ideal p with
Ii = pLi for all i for ideals Li, then
I1 + ¬∑ ¬∑ ¬∑ + In = R.
11.52 Give an example of a projective Z
‚àö
‚àí5

-module that is not free.
Hint. See Example 11.99.
11.53
(i) A commutative ring R is called a principal ideal ring if every ideal in R is a principal
ideal (R would be a PID if it were a domain). For example, In is a principal ideal ring.
Prove that Z √ó Z is not a principal ideal ring.
(ii) Let I1, . . . , In be pairwise coprime ideals in a commutative ring R. If R/Ii is a principal
ideal ring for each i, prove that R/(I1 ¬∑ ¬∑ ¬∑ In) is a principal ideal ring.
Hint. Use the Chinese remainder theorem, Exercise 6.11(iii) on page 325.

Sec. 11.2
Dedekind Rings
959
11.54 Let a be a nonzero element in a Dedekind ring R. Prove that there are only Ô¨Ånitely many
ideals I in R containing a.
Hint. If a ‚ààI, then Ra = I L for some ideal L ‚äÜR.
Finitely Generated Modules over Dedekind Rings
We saw, in Chapter 9, that theorems about abelian groups generalize to theorems about
modules over PIDs. We are now going to see that such theorems can be further generalized
to modules over Dedekind rings.
Proposition 11.103.
Let R be a Dedekind ring.
(i) If I ‚äÜR is a nonzero ideal, then every ideal in R/I is principal.
(ii) Every fractional ideal J can be generated by two elements. More precisely, for any
nonzero a ‚ààJ, there exists b ‚ààJ with J = Ra + Rb.
Proof.
(i) Let I = pe1
1 ¬∑ ¬∑ ¬∑ pen
n be the prime factorization of I. Since the ideals pei
i are
pairwise coprime, it sufÔ¨Åces, by Exercise 11.53(ii) on page 958, to prove that R/pei
i is a
principal ideal ring for each i. Now right exactness of Rpi ‚äóR
shows that (R/pei
i )pi ‚àº=
Rpi /(pei
i )pi . Since Rpi is a PID (it is even a DVR), any quotient ring of it is a principal
ideal ring.
(ii) Assume Ô¨Årst that J is an integral ideal. Choose a nonzero a ‚ààJ. By (i), the ideal
J/Ra in R/Ra is principal; say, J/Ra is generated by b + Ra, where b ‚ààJ. It follows
that J = Ra + Rb.
For the general case, there is a nonzero c ‚ààR with cJ ‚äÜR (if J is generated by
u1/v1, . . . , um/vm, take c = 
J v j). Since cJ is an integral ideal, given any nonzero
a ‚ààJ, there is cb ‚ààcJ with cJ = Rca + Rcb. It follows that J = Ra + Rb.
‚Ä¢
The next corollary says that we can force nonzero ideals to be coprime.
Corollary 11.104.
If I and J are fractional ideals over a Dedekind ring R, then there
are a, b ‚ààFrac(R) with
aI + bJ = R.
Proof.
Choose a nonzero a ‚ààI ‚àí1. Now aI ‚äÜI ‚àí1I = R, so that aI J ‚àí1 ‚äÜJ ‚àí1. By
Proposition 11.103(ii), there is b ‚ààJ ‚àí1 with
J ‚àí1 = aI J ‚àí1 + Rb.
Since b ‚ààJ ‚àí1, we have bJ ‚äÜR, and so
R = J J ‚àí1 = J(aI J ‚àí1 + Rb) = aI + RbJ = aI + bJ.
‚Ä¢
Let us now investigate the structure of R-modules.

960
Commutative Rings III
Ch. 11
Lemma 11.105.
(i) If 0 ‚ÜíM‚Ä≤ ‚ÜíM ‚ÜíM‚Ä≤‚Ä≤ ‚Üí0 is a short exact sequence of R-modules, then
rank(M) = rank(M‚Ä≤) + rank(M‚Ä≤‚Ä≤).
(ii) An R-module is torsion if and only if rank(M) = 0.
(iii) If M is a Ô¨Ånitely generated torsion-free R-module with M Ã∏= {0}, then rank(M) = 1
if and only if M is isomorphic to a nonzero ideal.
Proof.
(i) By Corollary 8.103, the fraction Ô¨Åeld F is a Ô¨Çat R-module. Therefore, 0 ‚Üí
F ‚äóR M‚Ä≤ ‚ÜíF ‚äóR M ‚ÜíF ‚äóR M‚Ä≤‚Ä≤ ‚Üí0 is a short exact sequence of vector spaces over
F, and the result is a standard result of linear algebra (Exercise 3.74 on page 171).
(ii) If M is torsion, then F ‚äóR M = {0}, by an obvious generalization of Proposition 8.95
(divisible ‚äótorsion = {0}). Hence, rank(M) = 0. Conversely, if rank(M) = 0, then
F ‚äóR M = {0}. By Proposition 11.25, if S = R ‚àí{0} and hM : M ‚ÜíS‚àí1M is the
localization map, then ker hM = {m ‚ààM : œÉm = 0 for some œÉ ‚ààR ‚àí{0}}. Thus,
M = ker hM here, and so M is torsion.
(iii) If M ‚àº= I, where I is an ideal, then rank(M) = rank(I), and there is an exact sequence
0 ‚ÜíI ‚ÜíF. Since F is a Ô¨Çat R-module, the sequence 0 ‚ÜíF ‚äóR I ‚ÜíF ‚äóR F is exact.
But F ‚äóR F ‚àº= F is one-dimensional, so that rank(I) ‚â§1. As I Ã∏= {0} (because fractional
ideals are nonzero), we have rank(I) = 1.
Conversely, assume that rank(M) = 1; that is, F ‚äóR M ‚àº= F. Choose nonzero elements
u, v ‚ààM. If u, v are linearly independent, then ‚ü®u, v‚ü©= ‚ü®u‚ü©‚äï‚ü®v‚ü©. But exactness of
0 ‚Üí‚ü®u‚ü©‚äï‚ü®v‚ü©‚ÜíM gives exactness of 0 ‚ÜíF ‚äóR ‚ü®u‚ü©‚äïF ‚äóR ‚ü®v‚ü©‚ÜíF ‚äóR M (we
have used the Ô¨Çatness of F once again). This is a contradiction, for a one-dimensional
space has no two-dimensional subspaces. Choose a nonzero element x ‚ààM. It follows
that if m ‚ààM, then there exist nonzero r, s ‚ààR with sm = rx. The reader may adapt the
argument in the proof of Theorem 9.3 to see that the function M ‚ÜíF, given by m ‚Üír/s,
is a well-deÔ¨Åned (because M is torsion-free) isomorphism of M and a submodule S of F.
As M is Ô¨Ånitely generated, S is a fractional ideal.
It remains to show that every fractional ideal J = ‚ü®a1/bn, . . . , an/bn‚ü©‚äÜF is isomor-
phic to an integral ideal. If b = 
i bi, then bx ‚ààR for all x ‚ààJ, for multiplication by b
merely clears denominators. Hence, the map J ‚ÜíR, given by x ‚Üíbx, is an R-map; it is
injective because Ô¨Åelds have no zero divisors.
‚Ä¢
Proposition 11.106.
If R is a Dedekind ring and M is a Ô¨Ånitely generated torsion-free
R-module, then
M ‚àº= I1 ‚äï¬∑ ¬∑ ¬∑ ‚äïIn,
where Ii is an ideal in R.
Proof.
The proof is by induction on rank(M) ‚â•0. If rank(M) = 0, then M is torsion, by
Lemma 11.105(ii). Since M is torsion-free, M = {0}. Assume now that rank(M) = n + 1.

Sec. 11.2
Dedekind Rings
961
Choose a nonzero m ‚ààM, so that rank(Rm) = 1. The sequence
0 ‚ÜíRm ‚ÜíM
ŒΩ
‚àí‚ÜíM‚Ä≤‚Ä≤ ‚Üí0
is exact, where M‚Ä≤‚Ä≤ = R/Rm and ŒΩ is the natural map. Note that rank(M‚Ä≤‚Ä≤) = n, by
Lemma 11.105(i). Now M Ô¨Ånitely generated implies M‚Ä≤‚Ä≤ is also Ô¨Ånitely generated. If
T = t(M‚Ä≤‚Ä≤) is the torsion submodule of M‚Ä≤‚Ä≤, then M‚Ä≤‚Ä≤/T is a Ô¨Ånitely generated torsion-
free R-module with rank(M‚Ä≤‚Ä≤/T ) = rank(M‚Ä≤‚Ä≤) = n, because rank(T ) = 0. By induction,
M‚Ä≤‚Ä≤/T is a direct sum of ideals, hence is projective. DeÔ¨Åne
M‚Ä≤ = ŒΩ‚àí1(T ) = {m ‚ààM : rm ‚ààRm for some r Ã∏= 0} ‚äÜM.
There is an exact sequence 0 ‚ÜíM‚Ä≤ ‚ÜíM ‚ÜíM‚Ä≤‚Ä≤/T ‚Üí0; this sequence splits because
M‚Ä≤‚Ä≤/T is projective; that is, M ‚àº= M‚Ä≤ ‚äï(M‚Ä≤‚Ä≤/T ). Hence
rank(M‚Ä≤) = rank(M) ‚àírank(M‚Ä≤‚Ä≤/T ) = 1.
Since R is noetherian, every submodule of a Ô¨Ånitely generated R-module is itself Ô¨Ånitely
generated; hence, M‚Ä≤ is Ô¨Ånitely generated. Therefore, M‚Ä≤ is isomorphic to an ideal, by
Lemma 11.105(ii), and this completes the proof.
‚Ä¢
Corollary 11.107.
If R is a Dedekind ring and M is a Ô¨Ånitely generated torsion-free
R-module, then M is projective.
Proof.
Recall that every ideal in a Dedekind ring is projective, by Proposition 11.98. It
now follows from Proposition 11.106 that M is a direct sum of ideals, and hence it is
projective.
We can also prove this result using localization. For every maximal ideal m, the Rm-
module Mm is Ô¨Ånitely generated torsion-free. Since Rm is a PID (even a DVR), however,
Mm is a free module, and hence it is projective. The result now follows from Corol-
lary 11.39.
‚Ä¢
Corollary 11.108.
If M is a Ô¨Ånitely generated R-module, where R is a Dedekind ring,
then the torsion submodule t M is a direct summand of M.
Proof.
The quotient module M/t M is a Ô¨Ånitely generated torsion-free R-module, so that
it is projective, by Corollary 11.107. Therefore, t M is a direct summand of M, by Corol-
lary 7.55.
‚Ä¢
Corollary 11.109.
If R is a Dedekind ring, then every torsion-free R-module A is Ô¨Çat.
Proof.
By Lemma 8.97, it sufÔ¨Åces to prove that every Ô¨Ånitely generated submodule of A
is Ô¨Çat. But such submodules are torsion-free, hence projective, and projective modules are
always Ô¨Çat, by Lemma 8.98.
‚Ä¢
It can be proved, over an arbitrary domain R, that every Ô¨Çat R-module is torsion-free
(see Rotman, An Introduction to Homological Algebra, page 129).
Using homological algebra, we generalize Corollary 11.108 by removing the hypothesis
that t M be Ô¨Ånitely generated.

962
Commutative Rings III
Ch. 11
Corollary 11.110.
Let R be a Dedekind ring with F = Frac(R).
(i) If C is a torsion-free R-module and T is a torsion module with ann(T ) Ã∏= {0}, then
Ext1
R(C, T ) = {0}.
(ii) Let M be an R-module. If ann(t M) Ã∏= {0}, where t M is the torsion submodule of
M, then t M is a direct summand of M.
Proof.
We generalize the proof of Proposition 10.92. Since C is torsion-free, it is a Ô¨Çat
R-module, by Corollary 11.109, so that exactness of 0 ‚ÜíR ‚ÜíF gives exactness of
0 ‚ÜíR ‚äóR C ‚ÜíF ‚äóR C. Thus, C ‚àº= R ‚äóR C can be imbedded in a vector space
V over F, namely, V = F ‚äóR C. Applying the contravariant functor HomR( , T ) to
0 ‚ÜíC ‚ÜíV ‚ÜíV/C ‚Üí0 gives an exact sequence
Ext1
R(V, T ) ‚ÜíExt1
R(C, T ) ‚ÜíExt2(V/C, T ).
Now the last term is {0}, by Corollary 11.102, and Ext1
R(V, T ) is (torsion-free) divisible,
by (a straightforward generalization of) Example 10.70, so that Ext1
R(C, T ) is divisible.
Since ann(T ) Ã∏= {0}, Exercise 10.41 on page 852 gives Ext1
R(C, T ) = {0}.
(i) To prove that the extension 0 ‚Üít M ‚ÜíM ‚ÜíM/t M ‚Üí0 splits, it sufÔ¨Åces to prove
that Ext1
R(M/t M, t M) = {0}. Since M/t M is torsion-free, this follows from part (i) and
Corollary 10.90.
‚Ä¢
The next result generalizes Proposition 7.73.
Proposition 11.111.
The following statements are equivalent for a domain R.
(i) R is a Dedekind ring.
(ii) An R-module E is injective if and only if it is divisible.
Proof.
(i) ‚áí(ii).
Let R be a Dedekind ring and let E be a divisible R-module. By the Baer criterion,
Theorem 7.68, it sufÔ¨Åces to complete the diagram
E
0
 I
f

i
 R
g

where I is an ideal and i : I ‚ÜíR is the inclusion. Of course, we may assume that I is
nonzero, and so I is invertible: there are elements a1, . . . , an ‚ààI and elements q1 . . . , qn ‚àà
F with qi I ‚äÜR and 1 = 
i qiai. Since E is divisible, there are elements ei ‚ààE with
f (ai) = aiei. Note, for every b ‚ààI, that
f (b) = f

i
qiaib

=

i
(qib) f (ai) =

i
(qib)aiei = b

i
(qiai)ei.

Sec. 11.2
Dedekind Rings
963
Hence, if we deÔ¨Åne e = 
i(qiai)ei, then e ‚ààE and f (b) = be for all b ‚ààI. DeÔ¨Åning
g : R ‚ÜíE by g(r) = re shows that the diagram can be completed, and so E is injec-
tive. That every injective R-module is divisible was proved (for arbitrary domains R) in
Lemma 7.72.
(ii) ‚áí(i).
Let E be an injective R-module. If E‚Ä≤ is a quotient of E, then E‚Ä≤ is divisible and hence,
by hypothesis, injective. Therefore, every quotient of an injective module is injective, and
so R is a Dedekind ring, by Theorem 11.101.
‚Ä¢
Having examined torsion-free modules, let us now look at torsion modules.
Proposition 11.112.
Let p be a nonzero prime ideal in a Dedekind ring R. If M is an
R-module with ann(M) = pe for some e > 0, then the localization map M ‚ÜíMp is an
isomorphism (and hence M may be regarded as an Rp-module).
Proof.
It sufÔ¨Åces to prove that M ‚àº= Rp ‚äóR M. If m ‚ààM is nonzero and s ‚ààR with
s /‚ààp, then
pe + Rs = R,
by Proposition 11.97. Hence, there exist u ‚ààpe and r ‚ààR with 1 = u + rs, and so
m = um + rsm = rsm.
If 1 = u‚Ä≤ + r‚Ä≤s, where u‚Ä≤ ‚ààp and r‚Ä≤ ‚ààR, then s(r ‚àír‚Ä≤)m = 0, so that
s(r ‚àír‚Ä≤) ‚ààann(m) = pe.
Since s /‚ààpe, it follows that r ‚àír‚Ä≤ ‚ààpe (the prime factorization of Rs does not contain
pe; if the prime factorization of R(r ‚àír‚Ä≤) does not contain pe, then neither does the prime
factorization of Rs(r ‚àír‚Ä≤)). Hence, rm = r‚Ä≤m. DeÔ¨Åne s‚àí1m = rm. DeÔ¨Åne f : Rp√óM ‚Üí
M by f (r/s, m) = s‚àí1rm, where s‚àí1rm has been deÔ¨Åned in the preceding paragraph. It is
straightforward to check that f is R-bilinear, and so there is an R-map f : Rp ‚äóM ‚ÜíM
with f : (r/s ‚äóm) = s‚àí1rm. In particular, f (1 ‚äóm) = m, so that f is surjective. On
the other hand, the localization map hM : M ‚ÜíRp ‚äóR M, deÔ¨Åned by hM(m) = 1 ‚äóm, is
easily seen to be the inverse of f .
‚Ä¢
DeÔ¨Ånition.
Let p be a nonzero prime ideal in a Dedekind ring R. An R-module M is
called p-primary if, for each m ‚ààM, there is e > 0 with ann(m) = pe.
Theorem 11.113 (Primary Decomposition).
Let R be a Dedekind ring, and let T be a
Ô¨Ånitely generated torsion R-module. If I = ann(T ) = pe1
1 ¬∑ ¬∑ ¬∑ pen
n , then
T = T [p1] ‚äï¬∑ ¬∑ ¬∑ ‚äïT [pn],
where
T [pi] = {m ‚ààM : ann(m) is a power of pi}.
T [pi] is called the pi-primary component of T .

964
Commutative Rings III
Ch. 11
Proof.
It is easy to see that the pi-primary components T [pi] are submodules of T . We
now check the conditions in Proposition 7.19. If Wi is the submodule of T generated by
all T [p j] with j Ã∏= i, we must show that T [pi] ‚à©Wi = {0}. Let x ‚ààT [pi] ‚à©Wi. If
Ii = pe1
1 ¬∑ ¬∑ ¬∑pei
i ¬∑ ¬∑ ¬∑ pen
n ,
then pi and Ii are coprime: pi + Ii = R. Hence, there are ai ‚ààpi and ri ‚ààIi with
1 = ai + ri, and so x = ai x + ri x. But ai x = 0, because x ‚ààT [pi], and ri x = 0, because
x ‚ààWi and Ii = ann(Wi). Therefore, x = 0.
By Exercise 11.51 on page 958, we have
I1 + ¬∑ ¬∑ ¬∑ + In = R.
Thus, there are bi ‚ààIi with b1 + ¬∑ ¬∑ ¬∑ + bn = 1. If t ‚ààT , then t = b1t + ¬∑ ¬∑ ¬∑ + bnt. But if
ci ‚ààpei
i , then cibi ‚ààpei
i Ii = I = ann(T ) and so ci(bit) = 0. Hence, pei
i ‚äÜann(bit), so
that ann(bit) = pe
i for some e > 0. Therefore, bit ‚ààT [pi], and so
T = T [p1] + ¬∑ ¬∑ ¬∑ + T [pn].
The result now follows from Proposition 7.19.
‚Ä¢
Theorem 11.114.
Let R be a Dedekind ring.
(i) Two Ô¨Ånitely generated torsion R-modules T and T ‚Ä≤ are isomorphic if and only if
T [pi] ‚àº= T ‚Ä≤[pi] for all i.
(ii) Every Ô¨Ånitely generated p-primary R-module T is a direct sum of cyclic R-modules,
and the number of summands of each type is an invariant of T .
Proof.
(i) The result follows easily from the observation that if f : T ‚ÜíT ‚Ä≤ is an isomor-
phism, then ann(t) = ann( f (t)) for all t ‚ààT .
(ii) The primary decomposition shows that T is the direct sum of its primary components
T [pi]. By Proposition 11.112, T [pi] is an Rpi -module. But Rpi is a PID (even a DVR),
and so the basis theorem and the fundamental theorem hold: each T [pi] is a direct sum
of cyclic modules, and the numbers and isomorphism types of the cyclic summands are
uniquely determined.
‚Ä¢
We now know that every Ô¨Ånitely generated R-module M is a direct sum of cyclic mod-
ules and ideals. What uniqueness is there in such a decomposition? Since the torsion
submodule is a fully invariant direct summand, we may focus on torsion-free modules.
Recall Proposition 11.3: Two ideals J and J ‚Ä≤ in a domain R are isomorphic if and only
if there is a ‚ààFrac(R) with J ‚Ä≤ = aJ.
Lemma 11.115.
Let M be a Ô¨Ånitely generated torsion-free R-module, where R is a
Dedekind ring, so that M ‚àº= I1 ‚äï¬∑ ¬∑ ¬∑ ‚äïIn, where the Ii are ideals. Then
M ‚àº= Rn‚àí1 ‚äïJ,
where J = I1 ¬∑ ¬∑ ¬∑ In.

Sec. 11.2
Dedekind Rings
965
Remark.
We call Rn‚àí1 ‚äïJ a Steinitz normal form for M. We will prove, in Theo-
rem 11.117, that J is unique up to isomorphism.
‚óÄ
Proof.
It sufÔ¨Åces to prove that I ‚äïJ ‚àº= R ‚äïI J, for the result then follows easily by
induction on n ‚â•2. By Corollary 11.104, there are nonzero a, b ‚ààFrac(R) with aI+bJ =
R. Since aI ‚àº= I and bJ ‚àº= J, we may assume that I and J are coprime integral ideals.
There is an exact sequence
0 ‚ÜíI ‚à©J
Œ¥
‚àí‚ÜíI ‚äïJ
Œ±
‚àí‚ÜíI + J ‚Üí0,
where Œ¥ : x ‚Üí(x, x) and Œ± : (u, v) ‚Üíu ‚àív. Since I and J are coprime, however,
we have I ‚à©J = I J and I + J = R. As R is projective, this sequence splits; that is,
I ‚äïJ ‚àº= R ‚äïI J.
‚Ä¢
The following cancellation lemma, while true for Dedekind rings, can be false for some
other rings. In Example 7.78(iii), we described an example of Swan showing that if R =
R[x1, . . . , xn]/(1‚àí
i x2
i ) is the real coordinate ring of the 3-sphere, then there is a Ô¨Ånitely
generated stably free R-module M that is not free. Hence, there are free R-modules F and
F‚Ä≤ with M ‚äïF ‚àº= F‚Ä≤ ‚äïF but M Ã∏‚àº= F‚Ä≤.
Lemma 11.116.
Let R be a Dedekind ring. If R ‚äïG ‚àº= R ‚äïH, where G and H are
R-modules, then G ‚àº= H.
Proof.
We may assume there is a module E = A ‚äïG = B ‚äïH, where A ‚àº= R ‚àº= B. Let
p: E ‚ÜíB be the projection p: (b, h) ‚Üíb, and let p‚Ä≤ = p|G. Now
ker p‚Ä≤ = G ‚à©H
and
im p‚Ä≤ ‚äÜB ‚àº= R.
Thus, im p‚Ä≤ ‚àº= L, where L is an ideal in R.
If im p‚Ä≤ = {0}, then G ‚äÜker p = H. Since E = A ‚äïG, Corollary 7.18 gives
H = G ‚äï(H ‚à©A). On the one hand, E/G = (A ‚äïG)/G ‚àº= A ‚àº= R; on the other hand,
E/G = (B ‚äïH)/G ‚àº= B ‚äï(H/G) ‚àº= R ‚äï(H/G). Thus, R ‚àº= R ‚äï(H/G). Since R is
a domain, this forces H/G = {0}: if R = X ‚äïY, then X and Y are ideals; if x ‚ààX and
y ‚ààY are both nonzero, then xy ‚ààX ‚à©Y = {0}, giving zero divisors in R. It follows that
H/G = {0} and G = H.
We may now assume that L = im p‚Ä≤ is a nonzero ideal. The Ô¨Årst isomorphism theorem
gives G/(G ‚à©H) ‚àº= L. Since R is a Dedekind ring, L is a projective module, and so
G = I ‚äï(G ‚à©H),
where I ‚àº= L. Similarly,
H = J ‚äï(G ‚à©H),
where J is isomorphic to an ideal. Therefore,
E = A ‚äïG = A ‚äïI ‚äï(G ‚à©H);
E = B ‚äïH = B ‚äïJ ‚äï(G ‚à©H).

966
Commutative Rings III
Ch. 11
It follows that
A ‚äïI ‚àº= E/(G ‚à©H) ‚àº= B ‚äïJ.
If we can prove that I ‚àº= J, then
G = I ‚äï(G ‚à©H) ‚àº= J ‚äï(G ‚à©H) = H.
Therefore, we have reduced the theorem to the special case when G and H are nonzero
ideals.
We will prove that if Œ± : R ‚äïI ‚ÜíR ‚äïJ is an isomorphism, then I ‚àº= J. As in our
discussion of generalized matrices on page 540, Œ± determines a 2 √ó 2 matrix
A =
a11
a12
a21
a22

,
where a11 : R ‚ÜíR, a21 : R ‚ÜíJ, a12 : I ‚ÜíR, and a22 : I ‚ÜíJ. Indeed, as maps
between ideals are just multiplications by elements of F = Frac(R), we may regard A as
a matrix in GL(2, F). Now a21 ‚ààJ and a22I ‚äÜJ, so that if d = det(A), then
dI = (a11a22 ‚àía12a12)I ‚äÜJ.
Similarly, Œ≤ = Œ±‚àí1 determines a 2 √ó 2 matrix B = A‚àí1.
d‚àí1J = det(B)J ‚äÜI,
so that J ‚äÜdI. We conclude that J = dI, and so J ‚àº= I.
‚Ä¢
Let us sketch a proof using exterior algebra that if R is a Dedekind ring and I and J are
fractional ideals, then R ‚äïI ‚àº= R ‚äïJ implies I ‚àº= J. The fact that 2 √ó 2 determinants
are used in the original proof suggests that second exterior powers may be useful. By
Theorem 9.143,
<2(R ‚äïI) ‚àº=

R ‚äó
<2(I)

‚äï
<1(R) ‚äóR
<1(I)

‚äï
<2(R) ‚äóR I

.
Now ;2(R) = {0}, by Corollary 9.138, and ;1(R) ‚äóR
;1(I) ‚àº= R ‚äóR I ‚àº= I. We now
show, for every maximal ideal m, that
;2(I)

m = {0}. By Exercise 11.24 on page 921,
<n(I)

m ‚àº=
<n(Im).
But Rm is a PID, so that Im is a principal ideal, and hence ;2(Im) = {0}, by Corol-
lary 9.138.
It now follows from Proposition 11.31(i) that ;2(I) = {0}.
Therefore,
;2(R ‚äïI) ‚àº= I. Similarly, ;2(R ‚äïJ) ‚àº= J, and so I ‚àº= J.

Sec. 11.2
Dedekind Rings
967
Theorem 11.117 (Steinitz).
Let R be a Dedekind ring, and let M ‚àº= I1 ‚äï¬∑ ¬∑ ¬∑ In and
M‚Ä≤ ‚àº= I ‚Ä≤
1 ‚äï¬∑ ¬∑ ¬∑ I ‚Ä≤
‚Ñìbe Ô¨Ånitely generated torsion-free R-modules. Then M ‚àº= M‚Ä≤ if and only
if n = ‚Ñìand I1 ¬∑ ¬∑ ¬∑ In ‚àº= I ‚Ä≤
1 ¬∑ ¬∑ ¬∑ I ‚Ä≤
n.
Proof.
Lemma 11.105(iii) shows that rank(Ii) = 1 for all i, and Lemma 11.105(i) shows
that rank(M) = n; similarly, rank(M‚Ä≤) = ‚Ñì. Since M ‚àº= M‚Ä≤, we have F ‚äóR M ‚àº=
F ‚äóR M‚Ä≤, so that rank(M) = rank(M‚Ä≤) and n = ‚Ñì. By Lemma 11.115, it sufÔ¨Åces to prove
that if Rn ‚äïI ‚àº= Rn ‚äïJ, then I ‚àº= J. But this follows at once from repeated use of
Lemma 11.116.
‚Ä¢
Let R be a commutative ring, and let C be a subcategory of RMod. Recall that two
R-modules A and B are called stably isomorphic in C if there exists a module C ‚ààobj(C)
with A ‚äïC ‚àº= B ‚äïC.
Corollary 11.118.
Let R be a Dedekind ring, and let C be the category of all Ô¨Ånitely
generated torsion-free R-modules. Then M, M‚Ä≤ ‚ààC are stably isomorphic in C if and only
if they are isomorphic.
Proof.
Isomorphic modules are always stably isomorphic. To prove the converse, assume
that there is a Ô¨Ånitely generated torsion-free R-module X with
M ‚äïX ‚àº= M‚Ä≤ ‚äïX.
There are ideals I, J, L with M ‚àº= Rn‚àí1 ‚äïI, M‚Ä≤ ‚àº= Rn‚àí1 ‚äïJ, and X ‚àº= Rm‚àí1 ‚äïL, where
n = rank(M) = rank(M‚Ä≤). Hence,
M ‚äïX ‚àº= Rn‚àí1 ‚äïI ‚äïRm‚àí1 ‚äïL ‚àº= Rn+m‚àí1 ‚äïI L.
Similarly,
M‚Ä≤ ‚äïX ‚àº= Rn+m‚àí1 ‚äïJ L.
By Theorem 11.117, I L ‚àº= J L, and so there is a nonzero a ‚ààFrac(R) with aI L = J L,
by Lemma 11.3. Multiplying by L‚àí1 gives aI = J, and so I ‚àº= J. Therefore,
M ‚àº= Rn‚àí1 ‚äïI ‚àº= Rn‚àí1 ‚äïJ ‚àº= M‚Ä≤.
‚Ä¢
Recall that if a category C has Ô¨Ånite products, then the Grothendieck group K0(C) is the
abelian group with generators (the isomorphism classes of) obj(C) and relations A ‚äïB =
A + B for all A, B ‚ààobj(C); that is, K0(C) = F(C)/R, where F(C) is the free abelian
group with basis obj(C) and R is the subgroup generated by all A ‚äïB ‚àíA ‚àíB. If [A]
denotes the element A + R in K0(C), where A ‚ààobj(C), then [A] = [B] in K0(C) if and
only if they are stably isomorphic in C, by Proposition 7.77.
Notation.
If Pr(R) is the category of all Ô¨Ånitely generated projective R-modules over a
commutative ring R, write
K0(R) = K0(Pr(R)).
We end this section by displaying a relation between the class group C(R) of a Dedekind
ring R and its Grothendieck group K0(R). If I is a nonzero ideal in a Dedekind ring R,
denote the corresponding element in C(R) by cls(I).

968
Commutative Rings III
Ch. 11
Theorem 11.119.
If R is a Dedekind ring, then
K0(R) ‚àº= C(R) ‚äïZ,
where C(R) is the class group of R.
Proof.
If P is a Ô¨Ånitely generated projective R-module, then P ‚àº= Rn‚àí1‚äïI for a nonzero
ideal I, by Lemma 11.115; moreover, the isomorphism class of I is uniquely determined
by P, by Theorem 11.117. If P ‚àº= Rn‚àí1 ‚äïJ, then there is a ‚ààFrac(R) with J = aI, so
that cls(J) = cls(I) in C(R). Therefore, the function œï : K0(R) ‚ÜíC(R) ‚äïZ, given by
œï([P]) = (cls(I), rank(P)),
is well-deÔ¨Åned. Note that we are writing the Ô¨Årst summand C(R) multiplicatively and the
second summand Z additively. To see that œï is well-deÔ¨Åned on K0(R) = F(Pr(R))/R, it
sufÔ¨Åces to prove that it preserves the relations in R; that is,
œï([P ‚äïQ]) ‚àíœï([P]) ‚àíœï([Q]) = 0.
Let Q = Rm‚àí1 ‚äïJ, where J is a nonzero ideal. Then P ‚äïQ ‚àº= Rn+m‚àí1 ‚äïI J, and
œï([P ‚äïQ]) = (cls(I J), n + m)
= (cls(I)cls(J), n + m)
= (cls(I), n) + (cls(J), m).
Since rank(P ‚äïQ) = rank(P) + rank(Q), it follows that œï is a well-deÔ¨Åned homomor-
phism.
Now œï is surjective, for (cls(I), n) = œï([Rn‚àí1 ‚äïI]), and C(R) ‚äïZ is generated by
all such elements. To see that œï is injective, recall that Proposition 7.77 says that a typical
element of K0(R) has the form [P] ‚àí[Q]. If œï([P] ‚àí[Q]) = 0, then œï([P]) = œï([Q]).
Hence, Proposition 7.77 says that P and Q are stably isomorphic. Corollary 11.118 says
that P ‚àº= Q, and so [P] ‚àí[Q] = 0. Therefore, œï is an isomorphism.
‚Ä¢
Remark.
There is another Grothendieck group in this context. An R-module A is called
invertible if it is Ô¨Ånitely generated and A ‚äóR HomR(A, R) ‚àº= R. By Propositions 8.83 and
9.97, the category of all invertible R-modules under tensor product is a ‚ãÜ-category, and so
it has a Grothendieck group, which is called the Picard group, denoted by Pic(R). It turns
out that every invertible module is isomorphic to an ideal. Thus, Pic(R) is the abelian group
(written multiplicately) with generators all invertible ideals in R and relations I‚äóR J = I J.
When R is a Dedekind ring, then Pic(R) ‚àº= C(R).
‚óÄ
EXERCISES
11.55 Let R be a Dedekind ring, and let I ‚äÜR be a nonzero ideal. Prove that there exists an ideal
J ‚äÜR with I + J = R and I J principal.

Sec. 11.3
Global Dimension
969
Hint. Let I = pe1
1 ¬∑ ¬∑ ¬∑ pen
n , and choose ri ‚ààpei
i ‚àípei+1
i
. Use the Chinese remainder theorem
to Ô¨Ånd an element a ‚ààR with a ‚ààpei
i and a /‚ààpei+1
i
, and consider the prime factorization of
Ra.
11.56
(i) If R is a commutative ring, prove that Rn ‚àº= Rm implies n = m.
Hint. If m is a maximal ideal in R, then the (R/m)-vector spaces (R/m)n and (R/m)m
are isomorphic.
(ii) If R is any commutative ring, prove that Z is a direct summand of K0(R).
11.57 If R is a PID, prove that K0(R) ‚àº= Z.
11.58 If I is a fractional ideal in a Dedekind ring R, prove that I ‚äóI ‚àí1 ‚àº= R.
Hint. Use invertibility of I.
11.59 If R is a local ring, prove that K0(R) ‚àº= Z.
11.60 If R is a commutative ring, prove that rank deÔ¨Ånes a surjective homomorphism K0(R) ‚ÜíZ.
We usually call the kernel of this map the reduced Grothendieck group, and we denote it by

K0(R). Hence,
K0(R) ‚àº= 
K0(R) ‚äïZ.
11.61 If C is a subcategory of RMod, then we deÔ¨Åned a variant of the Grothendieck group on
page 492: K ‚Ä≤(C) is the abelian group with generators obj(C) and relations B = A ‚àíC if
there exists a (not necessarily split) exact sequence 0 ‚ÜíA ‚ÜíB ‚ÜíC ‚Üí0.
(i) If R is a Dedekind ring, prove that restriction of the homomorphism Œµ: K0(R) ‚ÜíK ‚Ä≤(C)
of Proposition 7.82 is an isomorphism 
K0(R) ‚ÜíK ‚Ä≤(C).
(ii) If R is a Dedekind ring, prove that K ‚Ä≤(C) ‚àº= C(R).
11.3 GLOBAL DIMENSION
There are several types of rings whose Ô¨Ånitely generated modules have been classiÔ¨Åed:
semisimple rings; PIDs; Dedekind rings. Each of these rings can be characterized in terms
of its projective modules: a ring R is semisimple if and only if every R-module is projec-
tive; a domain R is Dedekind if and only if every ideal is projective. The notion of global
dimension allows us to classify arbitrary rings in this spirit.
Rings in this section need not be commutative.
DeÔ¨Ånition.
Let R be a ring and let A be a left R-module. If there is a Ô¨Ånite projective
resolution
0 ‚ÜíPn ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP1 ‚ÜíP0 ‚ÜíA ‚Üí0,
then we write pd(A) ‚â§n. If n ‚â•0 is the smallest integer such that pd(A) ‚â§n, then we
say that A has projective dimension n; if there is no Ô¨Ånite projective resolution of A, then
pd(A) = ‚àû.

970
Commutative Rings III
Ch. 11
Example 11.120.
(i) A module A is projective if and only if pd(A) = 0. We may thus regard pd(A) as a
measure of how far away A is from being projective.
(ii) If R is a Dedekind ring, then pd(A) ‚â§1 for every R-module A. By Theorem 11.101,
every submodule of a free R-module is projective. Hence, if F is a free R-module and
Œµ: F ‚ÜíA is a surjection, then
0 ‚Üíker Œµ ‚ÜíF
Œµ
‚àí‚ÜíA ‚Üí0
is a projective resolution of A. This argument extends to left hereditary rings.
‚óÄ
DeÔ¨Ånition.
Let P‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚ÜíP2
d2
‚àí‚ÜíP1
d1
‚àí‚ÜíP0
Œµ
‚àí‚ÜíA ‚Üí0 be a projective resolution
of a module A. If n ‚â•0, then the nth syzygy is
$n(A, P‚Ä¢) =

ker Œµ
if n = 0
ker dn
if n ‚â•1.
Proposition 11.121.
For every n ‚â•1, for all left R-modules A and B, and for every
projective resolution P‚Ä¢ of B, there is an isomorphism
Extn+1
R
(A, B) ‚àº= Ext1
R($n‚àí1(A, P‚Ä¢), B).
Proof.
The proof is by induction on n ‚â•1. Exactness of the projective resolution
P‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚ÜíP2
d2
‚àí‚ÜíP1
d1
‚àí‚ÜíP0
Œµ
‚àí‚ÜíA ‚Üí0
gives exactness of
¬∑ ¬∑ ¬∑ ‚ÜíP2
d2
‚àí‚ÜíP1 ‚Üí$0(A, P‚Ä¢) ‚Üí0,
which is a projective resolution P+
‚Ä¢ of $0(A, P‚Ä¢). In more detail, deÔ¨Åne
P+
n = Pn+1
and
d+
n = dn+1.
Since Ext1 is independent of the choice of projective resolution of the Ô¨Årst variable,
Ext1
R($0(A, P‚Ä¢), B) = ker(d+
2 )‚àó
im(d+
1 )‚àó= ker(d3)‚àó
im(d2)‚àó= Ext2
R(A, B).
The inductive step is proved in the same way, noting that
¬∑ ¬∑ ¬∑ ‚ÜíPn+2
dn+2
‚àí‚ÜíPn+1 ‚Üí$n(A, P‚Ä¢) ‚Üí0
is a projective resolution of $n(A, P‚Ä¢).
‚Ä¢

Sec. 11.3
Global Dimension
971
Corollary 11.122.
For all left R-modules A and B, for all n ‚â•0, and for any projective
resolutions P‚Ä¢ and P‚Ä≤
‚Ä¢ of A, there is an isomorphism
Ext1
R($n(A, P‚Ä¢), B) ‚àº= Ext1
R($n(A, P‚Ä≤
‚Ä¢), B).
Proof.
By Proposition 11.121. both are isomorphic to Extn+1
R
(A, B).
‚Ä¢
Two modules $ and $‚Ä≤ are called projectively equivalent if there exist projective mod-
ules P and P‚Ä≤ with $ ‚äïP ‚àº= $‚Ä≤ ‚äïP‚Ä≤. Exercise 11.62 on page 983 shows that any two nth
syzygies of a module A are projectively equivalent. We often abuse notation and speak of
the nth syzygy of a module, writing $n(A) instead of $n(A, P‚Ä¢).
Syzygies help compute projective dimension.
Lemma 11.123.
The following conditions are equivalent for a left R-module A.
(i) pd(A) ‚â§n.
(ii) Extk
R(A, B) = {0} for all modules B and all k ‚â•n + 1.
(iii) Extn+1
R
(A, B) = {0} for all modules B.
(iv) for every projective resolution P‚Ä¢ of A, the (n ‚àí1)st syzygy $n‚àí1(A, P‚Ä¢) is projec-
tive.
(v) there exists a projective resolution P‚Ä¢ of A with $n‚àí1(A, P‚Ä¢) projective.
Proof.
(i) ‚áí(ii).
By hypothesis, there is a projective resolution P‚Ä¢ of A with Pk = {0} for all k ‚â•n + 1.
Necessarily, all the maps dk : Pk ‚ÜíPk‚àí1 are zero for k ‚â•n + 1, and so
Extk
R(A, B) = ker(dk+1)‚àó
im(dk)‚àó
= {0}.
(ii) ‚áí(iii). Obvious.
(iii) ‚áí(iv).
If P‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚ÜíPn ‚ÜíPn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP1 ‚ÜíP0 ‚ÜíA ‚Üí0 is a projective resolution
of A, then Extn+1
R
(A, B) ‚àº= Ext1
R($n‚àí1(A, P‚Ä¢), B), by Proposition 11.121. But the last
group is {0}, by hypothesis, so that $n‚àí1(A) is projective, by Corollary 10.86.
(iv) ‚áí(v). Obvious.
(v) ‚áí(i).
If
¬∑ ¬∑ ¬∑ ‚ÜíPn ‚ÜíPn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP1 ‚ÜíP0 ‚ÜíA ‚Üí0
is a projective resolution of A, then
0 ‚Üí$n‚àí1(A) ‚ÜíPn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP1 ‚ÜíP0 ‚ÜíA ‚Üí0
is an exact sequence. Since $n‚àí1(A) is projective, the last sequence is a projective resolu-
tion of A, and so pd(A) ‚â§n.
‚Ä¢

972
Commutative Rings III
Ch. 11
Example 11.124.
Let G be a Ô¨Ånite cyclic group with |G| > 1. If Z is viewed as a trivial ZG-module, then
pd(Z) = ‚àû, because Corollary 10.108 gives, for all odd n,
Hn(G, Z) = Extn
ZG(Z, Z) Ã∏= {0}.
‚óÄ
The following deÔ¨Ånition will soon be simpliÔ¨Åed.
DeÔ¨Ånition.
If R is a ring, then its left projective global dimension is deÔ¨Åned by
lpD(R) = sup{pd(A) : A ‚ààobj(RMod)}.
Proposition 11.125.
For any ring R,
lpD(R) ‚â§n
if and only if
Extn+1
R
(A, B) = {0}
for all left R-modules A and B.
Proof.
This follows at once from the equivalence of (i) and (iii) in Lemma 11.123.
‚Ä¢
Example 11.126.
(i) A ring R is semisimple if and only if lpD(R) = 0. Thus, global dimension is a measure
of how far a ring is from being semisimple.
(ii) A ring R is left hereditary if and only if lpD(R) ‚â§1. In particular, a domain R is
Dedekind if and only if pD(R) ‚â§1.
‚óÄ
A similar discussion can be given using injective resolutions.
DeÔ¨Ånition.
Let R be a ring and let B be a left R-module. If there is an injective resolution
0 ‚ÜíB ‚ÜíE0 ‚ÜíE1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíEn ‚Üí0,
then we write id(B) ‚â§n. If n ‚â•0 is the smallest integer such that id(B) ‚â§n, then we
say that B has injective dimension n; if there is no Ô¨Ånite injective resolution of B, then
id(B) = ‚àû.
Example 11.127.
(i) A module B is injective if and only if id(B) = 0. We may thus regard id(B) as a
measure of how far away B is from being injective.
(ii) The injective and projective dimensions of a module A can be distinct. For example,
the abelian group A = Z has pd(A) = 0 and id(A) = 1.
(iii) If R is a Dedekind ring, then Theorem 11.101 says that every quotient module of an
injective R-module is injective. Hence, if Œ∑: B ‚ÜíE is an imbedding of an R-module B
into an injective R-module E, then
0 ‚ÜíB
Œ∑
‚àí‚ÜíE ‚Üícoker Œ∑ ‚Üí0
is an injective resolution of B. It follows that id(B) ‚â§1.
‚óÄ

Sec. 11.3
Global Dimension
973
DeÔ¨Ånition.
Let E‚Ä¢ = 0 ‚ÜíB
Œ∑
‚àí‚ÜíE0
d0
‚àí‚ÜíE1
d1
‚àí‚ÜíE2 ‚Üí¬∑ ¬∑ ¬∑ be an injective resolution
of a module B. If n ‚â•0, then the nth cosyzygy is
‚Ñßn(B, E‚Ä¢) =

coker Œ∑
if n = 0
coker dn‚àí1
if n ‚â•1.
Proposition 11.128.
For every n ‚â•1, for all left R-modules A and B, and for every
injective resolution E‚Ä¢ of A, there is an isomorphism
Extn+1
R
(A, B) ‚àº= Ext1
R(A, ‚Ñßn‚àí1(B, E‚Ä¢)).
Proof.
Dual to the proof of Proposition 11.121.
‚Ä¢
Corollary 11.129.
For all left R-modules A and B, for all n ‚â•0, and for any injective
resolutions E‚Ä¢ and E‚Ä≤‚Ä¢ of B, there is an isomorphism
Ext1
R(A, ‚Ñßn(B, E‚Ä¢)) ‚àº= Ext1
R(A, ‚Ñßn(B, E‚Ä≤‚Ä¢)).
Proof.
Dual to the proof of Corollary 11.122.
‚Ä¢
Two modules ‚Ñßand ‚Ñß‚Ä≤ are called injectively equivalent if there exist injective modules
E and E‚Ä≤ with ‚Ñß‚äïE ‚àº= ‚Ñß‚Ä≤ ‚äïE‚Ä≤. Exercise 11.63 on page 983 shows that any two nth
cosyzygies of a module B are injectively equivalent. We often abuse notation and speak of
the nth cosyzygy of a module, writing ‚Ñßn(B) instead of ‚Ñßn(B, E‚Ä¢).
Cosyzygies help compute injective dimension.
Lemma 11.130.
The following conditions are equivalent for a left R-module B.
(i) id(B) ‚â§n.
(ii) Extk
R(A, B) = {0} for all modules A and all k ‚â•n + 1.
(iii) Extn+1
R
(A, B) = {0} for all modules A.
(iv) for every injective resolution E‚Ä¢ of B, the (n‚àí1)st cosyzygy ‚Ñßn‚àí1(B, E‚Ä¢) is injective.
(v) there exists an injective resolution E‚Ä¢ of B with ‚Ñßn‚àí1(B, E‚Ä¢) injective.
Proof.
Dual to that of Lemma 11.123, using Exercise 10.49 on page 869
‚Ä¢
DeÔ¨Ånition.
If R is a ring, then its left injective global dimension is deÔ¨Åned by
li D(R) = sup{id(B) : B ‚ààobj(RMod)}.
Proposition 11.131.
For any ring R,
li D(R) ‚â§n if and only if Extn+1
R
(A, B) = {0}
for all left R-modules A and B.
Proof.
This follows at once from the equivalence of (i) and (iii) in Lemma 11.130.
‚Ä¢

974
Commutative Rings III
Ch. 11
Theorem 11.132.
For every ring R,
lpD(R) = li D(R).
Proof.
This follows at once from Propositions 11.125 and 11.131, for each number is
equal to the smallest n for which Extn+1
R
(A, B) = {0} for all left R-modules A and B.
‚Ä¢
DeÔ¨Ånition.
The left global dimension of a ring R is the common value of the left projec-
tive global dimension and the left injective global dimension:
lD(R) = lpD(R) = li D(R).
If R is commutative, then we denote its global dimension by D(R)
There is also a right global dimension r D(R) = lD(Rop) of a ring R. If R is com-
mutative, then lD(R) = r D(R) and we write D(R). Since left semisimple rings are also
right semisimple, by Corollary 8.57, we have lD(R) = 0 if and only if r D(R) = 0. On
the other hand, there are examples of rings in which these two dimensions differ.
We are now going to see that lD(R) can be computed from cyclic left R-modules.
Lemma 11.133.
A left R-module B is injective if and only if Ext1
R(R/I, B) = {0} for
every left ideal I.
Proof.
If B is injective, then Ext1
R(A, B) vanishes for every right R-module A. Con-
versely, suppose that Ext1
R(R/I, B) = {0} for every left ideal I. Applying HomR( , B) to
the exact sequence 0 ‚ÜíI ‚ÜíR ‚ÜíR/I ‚Üí0 gives exactness of
HomR(R, B) ‚ÜíHomR(I, B) ‚ÜíExt1
R(R/I, B) = 0.
That is, every R-map f : I ‚ÜíB can be extended to an R-map R ‚ÜíB (see Proposi-
tion 7.63). But this is precisely the Baer criterion, Theorem 7.68, and so B is injective.
‚Ä¢
The next result says that lD(R) can be computed from pd(M) for Ô¨Ånitely generated
R-modules M; in fact, lD(R) can even be computed from pd(M) for M cyclic.
Theorem 11.134 (Auslander).
For any ring R,
lD(R) = sup{pd(R/I) : I is a left ideal}.
Proof. (Matlis) If sup{pd(R/I)} = ‚àû, we are done. Therefore, we may assume there
is an integer n ‚â•0 with pd(R/I) ‚â§n for every left ideal I.
By Lemma 11.130,
Extn+1
R
(R/I, B) = {0} for every left R-module B. But lpD(R) = li D(R), by Theo-
rem 11.132, so that it sufÔ¨Åces to prove that id(B) ‚â§n for every B. Let E‚Ä¢ be an in-
jective resolution of B, with (n ‚àí1)st cosyzygy ‚Ñßn‚àí1(B). By Corollary 11.128, {0} =
Extn+1
R
(R/I, B) ‚àº= Ext1
R(R/I, ‚Ñßn‚àí1(B)). Now Lemma 11.133 gives ‚Ñßn‚àí1(B) injective,
and so Lemma 11.130 gives id(B) ‚â§n, as desired.
‚Ä¢
This theorem explains why every ideal in a Dedekind ring being projective is such a
strong condition.
Just as Ext deÔ¨Ånes the global dimension of a ring R, we can use Tor to deÔ¨Åne the weak
dimension (or Tor-dimension) of a ring R.

Sec. 11.3
Global Dimension
975
DeÔ¨Ånition.
Let R be a ring and let A be a right R-module. A Ô¨Çat resolution of A is an
exact sequence
¬∑ ¬∑ ¬∑ ‚ÜíFn ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíF1 ‚ÜíF0 ‚ÜíA ‚Üí0
in which each Fn is a Ô¨Çat right R-module.
If there is a Ô¨Ånite Ô¨Çat resolution
0 ‚ÜíFn ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíF1 ‚ÜíF0 ‚ÜíA ‚Üí0,
then we write f d(A) ‚â§n. If n ‚â•0 is the smallest integer such that f d(A) ‚â§n, then we
say that A has Ô¨Çat dimension n; if there is no Ô¨Ånite Ô¨Çat resolution of A, then f d(A) = ‚àû.
Example 11.135.
(i) A module A is Ô¨Çat if and only if f d(A) = 0. We may thus regard f d(A) as a measure
of how far away A is from being Ô¨Çat.
(ii) Since projective modules are Ô¨Çat, every projective resolution of A is a Ô¨Çat resolution.
It follows that if R is any ring, then f d(A) ‚â§pd(A) for every R-module A.
(iii) If R is a Dedekind ring and A is an R-module, then f d(A) ‚â§pd(A) ‚â§1, by (ii).
Corollary 11.109 says that every torsion-free R-module is Ô¨Çat (the converse is true as well).
Hence, f d(A) = 1 if and only if A is not torsion-free.
‚óÄ
DeÔ¨Ånition.
Let F‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚ÜíF2
d2
‚àí‚ÜíF1
d1
‚àí‚ÜíF0
Œµ
‚àí‚ÜíA ‚Üí0 be a Ô¨Çat resolution of a
module A. If n ‚â•0, then the nth yoke is
Yn(A, F‚Ä¢) =

ker Œµ
if n = 0
ker dn
if n ‚â•1.
The term yoke is not standard; it is a translation of the Greek œÉœÖŒ∂œÖŒ≥ ¬¥ŒπŒ± (syzygy).
Proposition 11.136.
For every n ‚â•1, for all right R-modules A and left R-modules B,
and for every Ô¨Çat resolution F‚Ä¢ of A, there is an isomorphism
TorR
n+1(A, B) ‚àº= TorR
1 (A, Yn‚àí1(B, F‚Ä¢)).
Proof.
Dual to the proof of Proposition 11.121.
‚Ä¢
Corollary 11.137.
For every right R-module A and left R-module B, for all n ‚â•0, and
for any Ô¨Çat resolutions F‚Ä¢ and F‚Ä≤
‚Ä¢ of B, there is an isomorphism
TorR
1 (A, Yn(B, F‚Ä¢)) ‚àº= TorR
1 (A, Yn(B, F‚Ä≤
‚Ä¢)).
Proof.
Dual to the proof of Corollary 11.122.
‚Ä¢

976
Commutative Rings III
Ch. 11
Lemma 11.138.
The following conditions are equivalent for a right R-module A.
(i) f d(A) ‚â§n.
(ii) TorR
k (A, B) = {0} for all k ‚â•n + 1 and all left R-modules B.
(iii) TorR
n+1(A, B) = {0} for all left R-modules B.
(iv) For every Ô¨Çat resolution F‚Ä¢ of A, the (n ‚àí1)st yoke Yn‚àí1(A, F‚Ä¢) is Ô¨Çat.
(v) There exists a Ô¨Çat resolution F‚Ä¢ of A with Ô¨Çat (n ‚àí1)st yoke Yn‚àí1(A, F‚Ä¢).
Proof.
As the proof of Lemma 11.123.
‚Ä¢
DeÔ¨Ånition.
The right weak dimension of a ring R is deÔ¨Åned by
rwD(R) = sup{ f d(A) : A ‚ààobj(ModR)}.
Proposition 11.139.
For any ring R, rwD(R) ‚â§n if and only if TorR
n+1(A, B) = {0} for
every left R-module B.
Proof.
This follows at once from Lemma 11.138.
‚Ä¢
We deÔ¨Åne the Ô¨Çat dimension of left R-modules in the obvious way.
DeÔ¨Ånition.
The left weak dimension of a ring R is deÔ¨Åned by
lwD(R) = sup{ f d(B) : B ‚ààobj(RMod)}.
Theorem 11.140.
For any ring R,
rwD(R) = lwD(R).
Proof.
If either dimension is Ô¨Ånite, then the left or right weak dimension is the smallest
n ‚â•0 with TorR
n+1(A, B) = {0} for all right R-modules A and all left R-modules B.
‚Ä¢
DeÔ¨Ånition.
The weak dimension of a ring R, denoted by wD(R), is the common value
of rwD(R) and lwD(R).
As we have remarked earlier, there are (noncommutative) rings whose left global di-
mension and right global dimension can be distinct. In contrast, weak dimension has no
left/right distinction, because tensor and Tor involve both left and right modules simulta-
neously.
Example 11.141.
A ring R has wD(R) = 0 if and only if every module is Ô¨Çat. These rings turn out to be von
Neumann regular: for each a ‚ààR, there exists a‚Ä≤ ‚ààR with aa‚Ä≤a = a. Examples of such
rings are Boolean rings (rings R in which r2 = r for all r ‚ààR), and Endk(V ), where V is
a (possibly inÔ¨Ånite-dimensional) vector space over a Ô¨Åeld k. See Rotman, An Introduction
to Homological Algebra, pages 119-120.
‚óÄ
The next proposition explains why weak dimension is so called.

Sec. 11.3
Global Dimension
977
Proposition 11.142.
For any ring R,
wD(R) ‚â§min{lD(R),r D(R)}.
Proof.
It sufÔ¨Åces to prove that f d(A) ‚â§pd(A) for any right R-module A. If pd(A) =
‚àû, there is nothing to prove; if pd(A) ‚â§n, there is a projective resolution
0 ‚ÜíPn ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP0 ‚ÜíA ‚Üí0.
Since every projective module is Ô¨Çat, this is a Ô¨Çat resolution showing that f d(A) ‚â§n.
Hence, wD(R) ‚â§r D(R). A similar argument shows that wD(R) ‚â§lD(R).
‚Ä¢
Corollary 11.143.
Suppose that Extn
R(A, B) = {0} for all left R-modules A and B. Then
TorR
n (C, D) = {0} for all right R-modules C and all left R-modules D.
Proof.
If Extn
R(A, B) = {0} for all A, B, then lD(R) ‚â§n ‚àí1; if TorR
n (C, D) Ã∏= {0} for
some C, D, then n ‚â§wD(DR). This contradicts Proposition 11.142:
lD(R) ‚â§n ‚àí1 < n ‚â§wD(R).
‚Ä¢
Lemma 11.144.
A left R-module B is Ô¨Çat if and only if TorR
1 (R/I, B) = {0} for every
right ideal I.
Proof.
Exactness of 0 ‚ÜíI
i
‚àí‚ÜíR ‚ÜíR/I ‚Üí0 gives exactness of
0 = TorR
1 (R, B) ‚ÜíTorR
1 (R/I, B) ‚ÜíI ‚äóR B
i‚äó1
‚àí‚ÜíR ‚äóR B.
Therefore, i ‚äó1 is an injection if and only if TorR
1 (R/I, B) = {0}. On the other hand, B is
Ô¨Çat if and only if i ‚äó1 is an injection for every right ideal I, by Corollary 8.108.
‚Ä¢
As global dimension, weak dimension can be computed from cyclic modules.
Corollary 11.145.
For any ring R,
wd(R) = sup{ f d(R/I) : I is a right ideal of R}
= sup{ f d(R/J) : J is a left ideal of R}.
Proof.
This proof is similar to the proof of Theorem 11.134, using Lemma 11.144 instead
of Lemma 11.133.
‚Ä¢
Theorem 11.146.
Let R be a left noetherian ring.
(i) If A is a Ô¨Ånitely generated left R-module, then
pd(A) = f d(A).

978
Commutative Rings III
Ch. 11
(ii)
wD(R) = lD(R).
In particular, if R is a commutative noetherian ring, then
wD(R) = D(R).
Proof.
(i) It is always true that f d(A) ‚â§pd(A), for every projective resolution is a
Ô¨Çat resolution. For the reverse inequality, it is enough to prove that if f d(A) ‚â§n, then
pd(A) ‚â§n. By Lemma 11.37, there is a projective resolution of A,
¬∑ ¬∑ ¬∑ ‚ÜíPn ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP0 ‚ÜíA ‚Üí0,
in which each Pi is Ô¨Ånitely generated.
Now this is also a Ô¨Çat resolution, so that, by
Lemma 11.138, f d(A) ‚â§n implies Yn = ker(Pn‚àí1 ‚ÜíPn‚àí2) is Ô¨Çat. But every Ô¨Ånitely
generated Ô¨Çat left R-module is projective, by Corollary 8.111 (because R is left noethe-
rian), and so
0 ‚ÜíYn‚àí1 ‚ÜíPn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP0 ‚ÜíA ‚Üí0
is a projective resolution. Therefore, pd(A) ‚â§n.
(ii) By Theorem 11.134, we have lD(R) is the supremum of projective dimensions of
cyclic left R-modules, and by Corollary 11.145, we have wd(R) is the supremum of Ô¨Çat
dimensions of cyclic left R-modules. But part (i) gives f d(A) = pd(A) for every Ô¨Ånitely
generated right R-module A, and this sufÔ¨Åces to prove the result.
‚Ä¢
We are now going to compute the global dimension D(k[x1, . . . , xn]) of a polynomial
ring over a Ô¨Åeld (the result is called Hilbert's theorem on syzygies).
Lemma 11.147.
If 0 ‚ÜíA‚Ä≤ ‚ÜíA ‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is a short exact sequence, then
pd(A‚Ä≤‚Ä≤) ‚â§1 + max{pd(A), pd(A‚Ä≤)}.
Proof.
We may assume the right side is Ô¨Ånite, or there is nothing to prove; let pd(A) ‚â§n
and pd(A‚Ä≤) ‚â§n. Applying Hom( , B), where B is any module, to the short exact sequence
gives the long exact sequence
¬∑ ¬∑ ¬∑ ‚ÜíExtn+1(A‚Ä≤, B) ‚ÜíExtn+2(A‚Ä≤‚Ä≤, B) ‚ÜíExtn+2(A, B) ‚Üí¬∑ ¬∑ ¬∑ .
The two outside terms are {0}, by Lemma 11.123(ii), so that exactness forces
Extn+2(A‚Ä≤‚Ä≤, B) = {0} for all B. The same lemma gives pd(A‚Ä≤‚Ä≤) ‚â§n + 1.
‚Ä¢
We wish to compare global dimension of R and R[x], and so we consider the R[x]-
module R[x] ‚äóR M ‚àº= M[x] arising from an R-module M. In Chapter 9, on page 684, we
called this module M[x].

Sec. 11.3
Global Dimension
979
DeÔ¨Ånition.
If M is an R-module over a commutative ring R, deÔ¨Åne
M[x] =

i‚â•0
Mi,
where Mi ‚àº= M for all i. The R-module M[x] is an R[x]-module if we deÔ¨Åne
x

i
ximi

=

i
xi+1mi.
In Lemma 9.55, we proved that if V is a free R-module over a commutative ring R, then
V [x] is a free R[x]-module. The next result generalizes this from pd(V ) = 0 to higher
dimensions.
Lemma 11.148.
For every R-module M, where R is a commutative ring,
pdR(M) = pdR[x](M[x]).
Proof.
It sufÔ¨Åces to prove that if one of the dimensions is Ô¨Ånite and at most n, then so is
the other.
If pd(M) ‚â§n, then there is an R-projective resolution
0 ‚ÜíPn ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP0 ‚ÜíM ‚Üí0.
Since R[x] is a free R-module, it is a Ô¨Çat R-module, and so there is an exact sequence of
R[x]-modules
0 ‚ÜíR[x] ‚äóR Pn ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíR[x] ‚äóR P0 ‚ÜíR[x] ‚äóR M ‚Üí0.
But R[x] ‚äóR M ‚àº= M[x] and R[x] ‚äóR Pn is a projective R[x]-module (for a projective is
a direct summand of a free module). Therefore, pdR[x](M[x]) ‚â§n.
If pd(M[x]) ‚â§n, then there is an R[x]-projective resolution
0 ‚ÜíQn ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíQ0 ‚ÜíM[x] ‚Üí0.
As an R-module, M[x] ‚àº= 
n‚â•1 Mn, where Mn ‚àº= M for all n. By Exercise 11.69 on
page 984, pdR(M[x]) = pdR(M). Each projective R[x]-module Qi is an R[x]-summand
of a free R[x]-module Fi; a fortiori, Qi is an R-direct summand of Fi. But R[x] is a free
R-module, so that Fi is also a free R-module. Therefore, as an R-module, Qi is projective,
and so pdR(M) ‚â§pdR[x](M[x]).
‚Ä¢
Corollary 11.149.
If R is a commutative ring and D(R) = ‚àû, then D(R[x]) = ‚àû.
Proof.
If D(R) = ‚àû, then for every integer n, there exists an R-module Mn with n <
pd(Mn). By the lemma, n < pdR[x](Mn[x]), and so D(R[x]) = ‚àû.
‚Ä¢

980
Commutative Rings III
Ch. 11
Proposition 11.150.
For every commutative ring R,
D(R[x]) ‚â§D(R) + 1.
Proof.
Recall the characteristic sequence, Theorem 9.56: If M is an R-module and
T : M ‚ÜíM is an R-map, then there is an exact sequence of R[x]-modules
0 ‚ÜíM[x] ‚ÜíM[x] ‚ÜíMT ‚Üí0,
where MT is the R[x]-module M with scalar multiplication given by axim = aT i(m). If
M is already an R[x]-module and T : M ‚ÜíM is the R-map m ‚Üíxm, then MT = M.
By Lemma 11.147,
pdR[x](M) ‚â§1 + pdR[x](M[x])
= 1 + pdR(M)
‚â§1 + D(R).
‚Ä¢
We proceed to prove the reverse inequality.
DeÔ¨Ånition.
If M is an R-module, where R is a commutative ring, then an element c ‚ààR
is regular on M (or is M-regular) if the R-map M ‚ÜíM, given by m ‚Üícm, is injective.
Otherwise, c is a zero divisor on M; that is, there is some nonzero m ‚ààM with cm = 0.
Before stating the next theorem, let us explain the notation. Suppose that R is a com-
mutative ring, c ‚ààR, and R‚àó= R/Rc. If M is an R-module, then M/cM is an (R/Rc)-
module; that is, M/cM is a R‚àó-module. On the other hand, every R‚àó-module A‚àócan also
be viewed as an R-module. If œÉ : (R/Rc) √ó A‚àó‚ÜíA‚àóis the given scalar multiplication
and if ŒΩ : R ‚ÜíR/Rc is the natural map, then œÉ(ŒΩ √ó 1A‚àó): R √ó A‚àó‚ÜíA‚àóis a scalar
multiplication. In more down-to-earth language, if r‚àó= r + Rc, then
r‚àóa = ra.
We denote A‚àóviewed in this way as an R-module by A‚ô≠. Exercise 11.72 on page 984
asks you to prove that M‚àó‚àº= (R/cR) ‚äóR M and A‚ô≠‚àº= HomR(R/cR, A‚àó), so that these
constructions involve an adjoint pair of functors.
Proposition 11.151 (Rees Lemma).
Let R be a commutative ring, let c ‚ààR be neither
a unit nor a zero divisor, and let R‚àó= R/Rc. If c is regular on an R-module M, then there
are natural isomorphisms, for every R‚àó-module A‚àóand all n ‚â•0,
Extn
R‚àó(A‚àó, M/cM) ‚àº= Extn+1
R
(A‚ô≠, M),
where A‚ô≠is the R‚àó-module A‚àóviewed as an R-module.

Sec. 11.3
Global Dimension
981
Proof.
Recall Theorem 10.45, the axioms characterizating Ext functors. Given a se-
quence of contravariant functors Gn : R‚àóMod ‚ÜíAb, for n ‚â•0, such that:
(i) for every short exact sequence 0 ‚ÜíA‚àó‚ÜíB‚àó‚ÜíC‚àó‚Üí0 of R‚àó-modules, there is a
long exact sequence with natural connecting homomorphisms
¬∑ ¬∑ ¬∑ ‚ÜíGn(C‚àó) ‚ÜíGn(B‚àó) ‚ÜíGn(A‚àó) ‚ÜíGn+1(C‚àó) ‚Üí¬∑ ¬∑ ¬∑ ;
(ii) G0 and HomR‚àó( , L‚àó) are naturally equivalent, for some R‚àó-module L‚àó;
(iii) Gn(P‚àó) = 0 for all projective R‚àó-modules P‚àóand all n ‚â•1;
then Gn is naturally equivalent to Extn
R‚àó( , L‚àó) for all n ‚â•0.
DeÔ¨Åne contravariant functors Gn : R‚àóMod ‚ÜíAb by Gn = Extn+1
R
(
‚ô≠, M). Thus, for
all R‚àó-modules A‚àó,
Gn(A‚àó) = Extn+1
R
(A‚ô≠, M).
Since Axiom (i) holds for the functors Extn, it also holds for the functors Gn. Let us prove
Axiom (ii). The map ¬µc : M ‚ÜíM, deÔ¨Åned by m ‚Üícm, is an injection, because c is
M-regular, and so the sequence 0 ‚ÜíM
¬µc
‚àí‚ÜíM ‚ÜíM/cM ‚Üí0 is exact. Consider the
portion of the long exact sequence, where A‚àóis an R‚àó-module:
HomR(A‚ô≠, M) ‚ÜíHomR(A‚ô≠, M/cM)
‚àÇ
‚àí‚ÜíExt1
R(A‚ô≠, M)
(¬µc)‚àó
‚àí‚ÜíExt1
R(A‚ô≠, M).
We claim that ‚àÇis an isomorphism. If a ‚ààA‚ô≠, then ca = 0, because A‚àóis an R‚àó-module
(remember that R‚àó= R/cR). Hence, if f ‚ààHomR(A‚ô≠, M), then cf (a) = f (ca) =
f (0) = 0. Since ¬µc : M ‚ÜíM is an injection, f (a) = 0 for all a ‚ààA‚ô≠. Thus, f = 0,
ker ‚àÇ= HomR(A‚ô≠, M) = {0}, and ‚àÇis an injection. The map (¬µc)‚àó: Ext1
R(A‚ô≠, M) ‚Üí
Ext1
R(A‚ô≠, M) is multiplication by c, by Example 10.60. On the other hand, Example 10.70
shows that if ¬µ‚Ä≤
c : A‚ô≠‚ÜíA‚ô≠is multiplication by c, then the induced map (¬µ‚Ä≤
c)‚àóon Ext is
also multiplication by c. But ¬µ‚Ä≤
c = 0, because A‚àóis a (R/cR)-module, and so (¬µ‚Ä≤
c)‚àó= 0.
Hence, (¬µc)‚àó= (¬µ‚Ä≤
c)‚àó= 0. Therefore, im ‚àÇ= ker(¬µc)‚àó= Ext1
R(A‚ô≠, M), and so ‚àÇis a
surjection. It follows that
‚àÇ: HomR(A‚ô≠, M/cM) ‚ÜíExt1
R(A‚ô≠, M)
is an isomorphism, natural because it is the connecting homomorphism. By Exercise 11.70
on page 984, there is a natural isomorphism
HomR‚àó(A‚àó, M/cM) ‚ÜíHomR(A‚ô≠, M/cM).
The composite
HomR‚àó(A‚àó, M/cM) ‚ÜíHomR(A‚ô≠, M/cM) ‚ÜíExt1
R(A‚ô≠, M) = G0(A‚àó)
is a natural isomorphism; hence, its inverse deÔ¨Ånes a natural equivalence
G0 ‚ÜíHomR‚àó( , M/cM).

982
Commutative Rings III
Ch. 11
Setting L‚àó= M/cM completes the veriÔ¨Åcation of Axiom (ii).
It remains to verify Axiom (iii): Gn(P‚àó) = {0} whenever P‚àóis a projective R‚àó-module
and n ‚â•1. In fact, since Gn is an additive functor and since every projective is a summand
of a free module, we may assume that P‚àóis a free R‚àó-module with basis, say, E. If
Q = 
e‚ààE Re is the free R-module with basis E, then there is an exact sequence of
R-modules
0 ‚ÜíQ
¬µc
‚àí‚ÜíQ ‚ÜíP‚àó‚Üí0.
(6)
The Ô¨Årst arrow is an injection because c is not a zero divisor in R; the last arrow is a
surjection because
Q/cQ =

e‚ààE
Re

/

e‚ààE
Rce

‚àº=

e‚ààE
(R/Rc)e =

R‚àóe = P‚àó.
The long exact sequence arising from (6) is
¬∑ ¬∑ ¬∑ ‚ÜíExtn
R(Q, M) ‚ÜíExtn+1
R
(P‚ô≠, M) ‚ÜíExtn+1
R
(Q, M) ‚Üí¬∑ ¬∑ ¬∑ .
Since Q is R-free and n ‚â•1, the outside terms are {0}, and exactness gives Gn(P‚àó) =
Extn+1
R
(P‚ô≠, M) = {0}. Therefore,
Extn+1
R
(A‚ô≠, M) = Gn(A‚àó) ‚àº= Extn
R‚àó(A‚àó, M/cM).
‚Ä¢
Theorem 11.152.
For every commutative ring k,
D(k[x]) = D(k) + 1.
Proof.
We have proved D(k[x]) ‚â§D(k) + 1 in Proposition 11.150, and so it sufÔ¨Åces to
prove the reverse inequality.
In the notation of the Rees lemma, Proposition 11.151, let us write R = k[x], c = x,
and R‚àó= k. Let A be a k-module with pd(A) = n. By Exercise 11.65 on page 984, there
is a free k-module F with Extn
k(A, F) Ã∏= {0}; of course, multiplication by x is an injection
F ‚ÜíF. As in the proof of the Rees lemma, there is a free k[x]-module Q = k[x] ‚äók F
with Q/x Q ‚àº= F. The Rees lemma gives
Extn+1
k[x](A, Q) ‚àº= Extn
k(A, Q/x Q) ‚àº= Extn
k(A, F) Ã∏= {0}
(A is viewed as a k[x]-module via k[x] ‚Üík). Therefore, pdk[x](A) ‚â•n + 1, and so
D(k[x]) ‚â•n + 1 = D(k) + 1.
‚Ä¢

Sec. 11.3
Global Dimension
983
Corollary 11.153 (Hilbert's Theorem on Syzygies).
If k is a Ô¨Åeld, then
D(k[x1, . . . , xn]) = n.
Proof.
Since D(k) = 0 and D(k[x]) = 1 for every Ô¨Åeld k, the result follows from
Theorem 11.152 by induction on n ‚â•0.
‚Ä¢
Hilbert's theorem on syzygies implies that if R = k[x1, . . . , xn], where k is a Ô¨Åeld, then
every Ô¨Ånitely generated R-module M has has a resolution
0 ‚ÜíPn ‚ÜíPn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP0 ‚ÜíM ‚Üí0,
where Pi is free for all i < n and Pn is projective. We say that a (necessarily Ô¨Ånitely gener-
ated) R-module M, over an arbitrary commutative ring R, has FFR (Ô¨Ånite free resolution)
if it has a resolution in which every Pi, including the last Pn, is a Ô¨Ånitely generated free
module. Hilbert's theorem on syzygies can be improved to the theorem that if k is a Ô¨Åeld,
then every Ô¨Ånitely generated k[x1, . . . , xn]-module has FFR (see Kaplansky, Commutative
Rings, page 134). (Of course, this result also follows from the more difÔ¨Åcult Quillen-
Suslin theorem, which says that every projective k[x1, . . . , xn]-module, where k is a Ô¨Åeld,
is free.)
EXERCISES
11.62
(i) If A ‚ÜíB
f
‚àí‚ÜíC ‚ÜíD is an exact sequence, and if X is any module, prove that there
is an exact sequence
A ‚ÜíB ‚äïX
f ‚äï1X
‚àí‚ÜíC ‚äïX ‚ÜíD.
(ii) Let
P‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚ÜíP2
d2
‚àí‚ÜíP1
d1
‚àí‚ÜíP0
Œµ
‚àí‚ÜíA ‚Üí0
and
P‚Ä≤
‚Ä¢ = ¬∑ ¬∑ ¬∑ ‚ÜíP‚Ä≤
2
d‚Ä≤
2
‚àí‚ÜíP‚Ä≤
1
d‚Ä≤
1
‚àí‚ÜíP‚Ä≤
0
Œµ‚Ä≤
‚àí‚ÜíA ‚Üí0
be projective resolutions of a left R-module A. For all n ‚â•0, prove that there are
projective modules Qn and Q‚Ä≤n with
$n(A, P‚Ä¢) ‚äïQn ‚àº= $n(A, P‚Ä≤
‚Ä¢) ‚äïQ‚Ä≤
n.
Hint. Proceed by induction on n ‚â•0, using Schanuel's lemma, Proposition 7.60.
11.63 Let
0 ‚ÜíB ‚ÜíE0 ‚ÜíE1 ‚ÜíE2 ‚Üí¬∑ ¬∑ ¬∑
and
0 ‚ÜíB ‚ÜíE‚Ä≤0 ‚ÜíE‚Ä≤1 ‚ÜíE‚Ä≤2 ‚Üí¬∑ ¬∑ ¬∑
be injective resolutions of a left R-module B. For all n ‚â•0, prove that there are injective
modules In and I ‚Ä≤n with
‚Ñßn(B, E‚Ä¢) ‚äïIn ‚àº= ‚Ñßn(B, E‚Ä≤‚Ä¢) ‚äïI ‚Ä≤
n.
Hint. The proof is dual to that of Exercise 11.62.

984
Commutative Rings III
Ch. 11
11.64 Show that there are Ô¨Çat resolutions
0 ‚ÜíZ ‚ÜíQ ‚ÜíQ/Z ‚Üí0
and
0 ‚ÜíK ‚ÜíF ‚ÜíQ/Z ‚Üí0,
where F is free abelian, but that Z ‚äïF Ã∏‚àº= Q ‚äïK.
11.65 If A is an R-module with pd(A) = n, prove that there exists a free R-module F with
Extn
R(A, F) Ã∏= {0}.
Hint. Every module is a quotient of a free module.
11.66 If G is a Ô¨Ånite cyclic group of order not 1, prove that
lD(ZG) = ‚àû= r D(ZG).
Hint. Use Theorem 10.107.
11.67 (Auslander) If R is both left noetherian and right noetherian, prove that
lD(R) = r D(R).
Hint. Use weak dimension.
11.68 Prove that a noetherian von Neumann regular ring is semisimple.
Hint. See Example 11.141.
11.69 If {MŒ± : Œ± ‚ààA} is a family of left R-modules, prove that
pd

Œ±‚ààA
MŒ±

= sup
Œ±‚ààA

pd(MŒ±)

.
11.70 If œï : R ‚ÜíR‚àóis a ring homomorphism and A‚àóand B‚àóare R‚àó-modules, prove that there is a
natural isomorphism
HomR‚àó(A‚àó, B‚àó) ‚ÜíHomR(A‚ô≠, B‚ô≠),
where A‚ô≠is A‚àóviewed as an R-module.
11.71
(i) If 0 ‚ÜíA‚Ä≤ ‚ÜíA ‚ÜíA‚Ä≤‚Ä≤ ‚Üí0 is an exact sequence, prove that
pd(A) ‚â§max{pd(A‚Ä≤), pd(A‚Ä≤‚Ä≤)}.
(ii) If the sequence in part (i) is not split and if pd(A‚Ä≤) = pd(A‚Ä≤‚Ä≤) + 1, prove that
pd(A) = max{pd(A‚Ä≤), pd(A‚Ä≤‚Ä≤)}.
11.72 Let k be a commutative ring, let c ‚ààk, and let k‚àó= k/ck.
(i) If M is a k-module, deÔ¨Åne M‚àó= M/cM. Prove that M‚àó‚àº= (k/ck) ‚äók M.
(ii) If A‚àóis a k‚àó-module, deÔ¨Åne A‚ô≠to be A‚àóviewed as a K-module, as on page 980. Prove
that A‚ô≠‚àº= Homk(k/ck, A‚àó). Conclude that M ‚ÜíM‚àóand A‚àó‚ÜíA‚ô≠form an adjoint
pair of functors.
11.73 Let œï : k ‚Üík‚àóbe a ring homomorphism.
(i) Prove that k‚àóis a (k‚àó, k)-bimodule.
(ii) Prove that every k‚àó-module A‚àócan be viewed as a k-module, denoted by A‚ô≠, and that
A‚àó‚ÜíA‚ô≠gives an exact functor U : k‚àóMod ‚ÜíkMod.

Sec. 11.4
Regular Local Rings
985
(iii) Prove that if F = Homk(k‚àó, ): kMod ‚Üík‚àóMod, then (U, F) and (F,U) are adjoint
pairs of functors. (These functors are called change of rings functors.) Conclude that
U and F preserve all direct limits and all inverse limits.
11.74 Let R be a commutative ring with FFR. Prove that every Ô¨Ånitely generated projective R-
module P has a free complement; that is, there is a Ô¨Ånitely generated free R-module F such
that P ‚äïF is a free R-module.
11.4 REGULAR LOCAL RINGS
We are now going to focus on (commutative) noetherian local rings, the main results being
that such a ring has Ô¨Ånite global dimension if and only if it is a regular local ring (regular
local rings arise quite naturally in algebraic geometry), and that they are UFDs. Let us
begin with a localization result.
Proposition 11.154.
Let R be a commutative noetherian ring.
(i) If A is a Ô¨Ånitely generated R-module, then
pd(A) = sup
m
pd(Am),
where m ranges over all the maximal ideals of R.
(ii)
D(R) = sup
m
D(Rm),
where m ranges over all the maximal ideals of R.
Proof.
(i) We Ô¨Årst prove that pd(A) ‚â•pd(Am) for every maximal ideal m. If pd(A) =
‚àû, there is nothing to prove, and so we may assume that pd(A) = n < ‚àû. Thus, there is
a projective resolution
0 ‚ÜíPn ‚ÜíPn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíP0 ‚ÜíA ‚Üí0.
Since Rm is a Ô¨Çat R-module, by Theorem 11.28,
0 ‚ÜíRm ‚äóPn ‚ÜíRm ‚äóPn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíRm ‚äóP0 ‚ÜíAm ‚Üí0
is a projective resolution of Am, and so pd(Am) ‚â§n. (This implication does not need the
hypotheses that R be noetherian or that A be Ô¨Ånitely generated.)
For the reverse inequality, it sufÔ¨Åces to assume that supm pd(Am) = n < ‚àû. Since
R is noetherian, Theorem 11.146(i) says that pd(A) = f d(A). Now pd(Am) ‚â§n if and
only if TorRm
n+1(Am, Bm) = {0} for all Rm-modules Bm, by Lemma 11.138. However,
Proposition 11.35 gives an isomorphism TorRm
n+1(Am, Bm) ‚àº=

TorR
n+1(A, B)

m. There-
fore, TorR
n+1(A, B) = {0}, by Proposition 11.31(i). We conclude that n ‚â•pd(A).
(ii) This follows at once from part (i), for D(R) = supA{pd(A)}, where A ranges over all
Ô¨Ånitely generated (even cyclic) R-modules, by Theorem 11.134.
‚Ä¢

986
Commutative Rings III
Ch. 11
We now set up notation that will be used in the rest of this section.
Notation. We denote a commutative noetherian local ring by R, by (R, m), or by (R, m, k),
where m is its unique maximal ideal and k is its residue Ô¨Åeld k = R/m.
Theorem 11.134 allows us to compute global dimension as the supremum of projective
dimensions of cyclic modules. When R is a local ring, there is a dramatic improvement;
global dimension is determined by the projective dimension of one cyclic module: the
residue Ô¨Åeld k.
Lemma 11.155.
Let (R, m) be a local ring with residue Ô¨Åeld k. If A is a Ô¨Ånitely generated
R-module, then
pd(A) ‚â§n
if and only if
TorR
n+1(A, k) = {0}
Proof.
Assume pd(A) ‚â§n. By Example 11.135(ii), we have f d(A) ‚â§pd(A), so that
TorR
n+1(A, B) = {0} for every R-module B. In particular, TorR
n+1(A, k) = {0}.
We prove the converse by induction on n ‚â•0. For the base step n = 0, we must prove
that TorR
1 (A, k) = {0} implies pd(A) = 0; that is, A is projective (hence free, since R
is local). Let {a1, . . . , ar} be a minimal set of generators of A (that is, no proper subset
generates A), let F be the free R-module with basis {e1, . . . , er}, and let œï : F ‚ÜíA be the
R-map with œï(ei) = ai. There is an exact sequence
0 ‚ÜíN
i
‚àí‚ÜíF
œï
‚àí‚ÜíA ‚Üí0
where N = ker œï and i is the inclusion; as in the proof of Proposition 11.23,
N ‚äÜmF.
Since TorR
1 (A, k) = {0}, the sequence
0 ‚ÜíN ‚äóR k
i‚äó1
‚àí‚ÜíF ‚äóR k
œï‚äó1
‚àí‚ÜíA ‚äóR k ‚Üí0
is exact. Tensor 0 ‚Üím ‚ÜíR ‚Üík ‚Üí0 by N; right exactness gives a natural isomorphism
œÑN : N ‚äóR k ‚ÜíN/mN;
if n ‚ààN and b ‚ààk, then œÑN : n ‚äób ‚Üín + mN. There is a commutative diagram
0
 N ‚äóR k
œÑN

i‚äó1  F ‚äóR k
œÑF

N/mN
i
 F/mF,
where i : n + mN ‚Üín + mF. Since i ‚äó1 is an injection, so is i. But N ‚äÜmF says that
the map i is the zero map. Therefore, N/mN = {0}, so that N = mN. By Nakayama's
lemma, Corollary 8.32, N = {0}, and so œï : F ‚ÜíA is an isomorphism; that is, A is free.

Sec. 11.4
Regular Local Rings
987
For the inductive step, we must prove that if TorR
n+2(A, k) = {0}, then pd(A) ‚â§n + 1.
Take a projective resolution P‚Ä¢ of A, and let $n(A, P‚Ä¢) be its nth syzygy. Since P‚Ä¢ must
also be a Ô¨Çat resolution of A, we have Yn(A, P‚Ä¢) = $n(A, P‚Ä¢). By Proposition 11.136,
TorR
n+2(A, k) ‚àº= TorR
1 (Yn(A, P‚Ä¢), k). The base step shows that Yn(A, P‚Ä¢) = $n(A, P‚Ä¢) is
free, and this gives pd(A) ‚â§n + 1, by Lemma 11.123.
‚Ä¢
Corollary 11.156.
Let (R, m) be a local ring with residue Ô¨Åeld k. If A is a Ô¨Ånitely
generated R-module, then
pd(A) = sup

i : TorR
i (A, k) Ã∏= {0}

.
Proof.
Let n = sup

i : TorR
i (A, k) Ã∏= {0}

. Then pd(A) ‚â§n ‚àí1, but pd(A) Ã∏< n; that
is, pd(A) = n.
‚Ä¢
Theorem 11.157.
Let R be a local ring with residue Ô¨Åeld k.
(i)
D(R) ‚â§n
if and only if
TorR
n+1(k, k) = {0}.
(ii)
D(R) = pd(k).
Proof.
(i) If D(R) ‚â§n, then Lemma 11.155 applies at once to give TorR
n+1(k, k) = {0}.
Conversely, if TorR
n+1(k, k) = {0}, the same lemma gives pd(k) ‚â§n. By Lemma 11.138,
we have TorR
n+1(A, k) = {0} for every R-module A. In particular, if A is Ô¨Ånitely gener-
ated, then Lemma 11.155 gives pd(A) ‚â§n. Finally, Theorem 11.134 shows that D(R) =
supA{pd(A)}, where A ranges over all Ô¨Ånitely generated (even cyclic) R-modules. There-
fore, D(R) ‚â§n.
(ii) Immediate from part (i).
‚Ä¢
DeÔ¨Ånition.
A prime chain of length n in a commutative ring R is a strictly decreasing
chain of prime ideals
p0 ‚äãp1 ‚äã¬∑ ¬∑ ¬∑ ‚äãpn.
The height ht(p) of a prime ideal p is the length of the longest prime chain with p = p0.
Thus, ht(p) ‚â§‚àû.
Example 11.158.
(i) If p is a prime ideal, then ht(p) = 0 if and only if p is a minimal prime ideal. If R is a
domain, then ht(p) = 0 if and only if p = {0}.
(ii) If R is a Dedekind ring and p is a nonzero prime ideal in R, then ht(p) = 1.

988
Commutative Rings III
Ch. 11
(iii) Let k be a Ô¨Åeld and let R = k[X] be the polynomial ring in inÔ¨Ånitely many variables
X = {x1, x2, . . .}. If pi = (xi, xi+1, . . .), then pi is a prime ideal (R/pi ‚àº= k[x1, . . . , xi‚àí1]
is a domain) and, for every n ‚â•1,
p1 ‚äãp2 ‚äã¬∑ ¬∑ ¬∑ ‚äãpn+1
is a prime chain of length n. It follows that ht(p1) = ‚àû.
‚óÄ
DeÔ¨Ånition.
If R is a commutative ring, then its Krull dimension is
dim(R) = sup{ht(p) : p ‚ààSpec(R)};
that is, dim(R) is the length of a longest prime chain in R.
If R is a Dedekind ring, then dim(R) = 1, for every nonzero prime is a maximal ideal;
if R is a domain, then dim(R) = 0 if and only if R is a Ô¨Åeld. The next proposition
characterizes the noetherian rings of Krull dimension 0.
Proposition 11.159.
If R Is a noetherian ring, then dim(R) = 0 if and only if every
Ô¨Ånitely generated R-module M has a composition series.
Proof.
Assume that R is noetherian with Krull dimension 0. Since R is noetherian,
Corollary 6.120(iii) says that there are only Ô¨Ånitely many minimal prime ideals. Since
dim(R) = 0, every prime ideal is a minimal prime ideal (and a maximal ideal). We con-
clude that R has only Ô¨Ånitely many prime ideals, say, p1, . . . , pn. Now nil(R) = n
i=1 pi
is nilpotent, by Exercise 11.39 on page 938; say, (nil(R))m = {0}. DeÔ¨Åne
N = p1 ¬∑ ¬∑ ¬∑ pn ‚äÜp1 ‚à©¬∑ ¬∑ ¬∑ ‚à©pn = nil(R),
so that
N m = (p1 ¬∑ ¬∑ ¬∑ pn)m = {0}.
Let M be a Ô¨Ånitely generated R-module, and consider the chain
M ‚äáp1M ‚äáp1p2M ‚äá¬∑ ¬∑ ¬∑ ‚äáN M.
The factor module p1 ¬∑ ¬∑ ¬∑ pi‚àí1M/p1 ¬∑ ¬∑ ¬∑ pi M is an (R/pi)-module; that is, it is a vector
space over the Ô¨Åeld R/pi (for pi is a maximal ideal). Since M is Ô¨Ånitely generated, the
factor module is Ô¨Ånite-dimensional, and so the chain can be reÔ¨Åned so that all the factor
modules are simple. Finally, repeat this argument for the chains
N j M ‚äáp1N j M ‚äáp1p2N j M ‚äá¬∑ ¬∑ ¬∑ ‚äáN j+1M.
Since N m = {0}, we have constructed a composition series for M.
Conversely, if every Ô¨Ånitely generated R-module has a composition series, then the
cyclic R-module R has a composition series; say, of length ‚Ñì. It follows that any ascending
chain of ideals has length at most ‚Ñì, and so R is noetherian. To prove that dim(R) = 0,

Sec. 11.4
Regular Local Rings
989
we must show that R does not contain any prime ideals p ‚äãq. Passing to the quotient ring
R/q, we may restate the hypotheses: R is a domain having a nonzero prime ideal as well
as a composition series R ‚äáI1 ‚äá¬∑ ¬∑ ¬∑ ‚äáId Ã∏= {0}. The last ideal Id is a minimal ideal;
choose a nonzero element x ‚ààId. Of course, x Id ‚äÜId; since R is a domain, x Id Ã∏= {0},
so that minimality of Id gives x Id = Id. Hence, there is y ‚ààId with xy = x; that is,
1 = y ‚ààId, and so Id = R. We conclude that R is a Ô¨Åeld, contradicting its having a
nonzero prime ideal.
‚Ä¢
We are going to prove a theorem of W. Krull, the principal ideal theorem, which implies
that every prime ideal in a noetherian ring has Ô¨Ånite height. Our proof is Kaplansky's
adaptation of a proof by D. Rees. We begin with a technical lemma.
Lemma 11.160.
Let a and b be nonzero elements in a domain R. If there exists c ‚ààR
such that ca2 ‚àà(b) implies ca ‚àà(b), then the series (a, b) ‚äá(a) ‚äá(a2) and (a2, b) ‚äá
(a2, ab) ‚äá(a2) have isomorphic factor modules.7
Proof.
Now (a, b)/(a) ‚àº= (a2, ab)/(a2), for multiplication by a sends (a, b) onto (ab, ab)
and (a) onto (a2).
The module (a)/(a2) is cyclic with annihilator (a); that is, (a)/(a2) ‚àº= R/(a). The
module (a2, b)/(a2, ab) is also cyclic, for the generator a2 lies in (a2, ab). Now A =
ann

(a2, b)/(a2, ab)

contains (a), and so it sufÔ¨Åces to prove that A = (a); that is, if
cb = ua2 + vab, then c ‚àà(a). This equation gives ua2 ‚àà(b), and so the hypothesis
give ua = rb for some r ‚ààR. Substituting, cb = rab + vab, and canceling b gives
c = ra + va ‚àà(a). Therefore, (a)/(a2) ‚àº= (a2, b)/(a2, ab).
‚Ä¢
Recall that a prime ideal p is minimal over an ideal I if I ‚äÜp and there is no prime
ideal q with I ‚äÜq ‚ääp.
Theorem 11.161 (Principal Ideal Theorem).
Let (a) be a proper ideal in a noetherian
ring R, and let p be a prime ideal minimal over (a). Then ht(p) ‚â§1.
Proof.
If, on the contrary, ht(p) ‚â•2, then there is a prime chain
p ‚äãp1 ‚äãp2.
We normalize the problem in two ways. First, replace R by R/p2; second, localize at p/p2.
We now modify the hypotheses accordingly: R is a local domain whose maximal ideal m
is minimal over a proper principal ideal (x), and there is a prime ideal q with
m ‚äãq ‚äã(0).
Choose a nonzero element b ‚ààq, and deÔ¨Åne
Ii = ((b) : xi) = {c ‚ààR : cxi ‚àà(b)}.
7Our notation for ideals is not consistent. The principal ideal generated by an element a ‚ààR is sometimes
denoted by (a) and sometimes denoted by Ra.

990
Commutative Rings III
Ch. 11
There is an ascending chain I1 ‚äÜI2 ‚äÜ¬∑ ¬∑ ¬∑ , that must stop, because R is noetherian: say,
In = In+1 = ¬∑ ¬∑ ¬∑ . It follows that if c ‚ààI2n, then c ‚ààIn; that is, if cx2n ‚àà(b), then
cxn ‚àà(b). If we set a = xn, then ca2 ‚àà(b) implies ca ‚àà(b).
If R‚àó= R/(a2), then dim(R‚àó) = 0, for it has exactly one prime ideal. By Propo-
sition 11.159, the R‚àó-module (a, b)/(a2) (as every Ô¨Ånitely generated R‚àó-module) has Ô¨Å-
nite length ‚Ñì(the length of its composition series). But Lemma 11.160 implies that both
(a, b) and its submodule (a2, b) have length ‚Ñì. The Jordan-H¬®older theorem says this
can happen only if (a2, b) = (a, b), which forces a ‚àà(a2, b): there are s, t ‚ààR with
a = sa2 + tb. Since sa ‚ààm, the element 1 ‚àísa is a unit (for (R, m) is a local ring).
Hence, ‚àía(1 ‚àísa) = tb ‚àà(b) gives a ‚àà(b) ‚äÜq. But a = xn gives x ‚ààq, contradicting
m being a prime ideal minimal over (x).
‚Ä¢
We now generalize the principal ideal theorem to Ô¨Ånitely generated ideals.
Theorem 11.162 (Generalized Principal Ideal Theorem).
Let I = (a1, . . . , an) be a
proper ideal in a noetherian ring R, and let p be a prime ideal minimal over I. Then
ht(p) ‚â§n.
Proof.
The hypotheses still hold after localizing at p, so we may assume that R is a local
ring with p as its maximal ideal.
The proof is by induction on n ‚â•1, the base step being the principal ideal theorem. Let
I = (a1, . . . , an+1), and assume, by way of contradiction, that ht(p) > n + 1: there is a
prime chain
p = p0 ‚äãp1 ‚äã¬∑ ¬∑ ¬∑ ‚äãpn+1.
We may assume there are no prime ideals strictly between p and p1, for the module p/p1 has
ACC. Now I Ã∏‚äÜp1, because p is a prime ideal minimal over I. Reindexing the generators
of I if necessary, a1 /‚ààp1. Hence, (a1, p1) ‚äãp1. We claim that p is the only prime ideal
containing (a1, p1); there can be no prime ideal p‚Ä≤ with (a1, p1) ‚äÜp‚Ä≤ ‚äÜp (the second
inclusion holds because p is the only maximal ideal in R) because there are no prime
ideals strictly between p and p1. Therefore, in the ring R/(a1, p1), the image of p is the
unique nonzero prime ideal. As such, it must be the nilradical, and hence it is nilpotent,
by Exercise 11.39 on page 938. There is an integer m with pm ‚äÜ(a1, p1), and so there are
equations
am
i = ria1 + bi,
ri ‚ààR, bi ‚ààp1, and i ‚â•2.
(7)
DeÔ¨Åne J = (b2, . . . , bn+1). Now J ‚äÜp1, while ht(p1) > n. By induction, p1 cannot be a
prime ideal minimal over J, and so there exists a prime ideal q minimal over J:
J ‚äÜq ‚ääp1.
Now am
i
‚àà(a1, q) for all i, by Eq. (7). Thus, any prime ideal p‚Ä≤ containing (a1, q) must
contain all am
i , hence all ai, and hence I. As p is the unique maximal ideal, I ‚äÜp‚Ä≤ ‚äÜp.
But p is a prime ideal minimal over I, and so p‚Ä≤ = p. Therefore, p is the unique prime ideal
containing (a1, q). If R‚àó= R/q, then p‚àó= p/q is a prime ideal minimal over the principal
ideal (a1 + q). On the other hand, ht(p‚àó) ‚â•2, for p‚àó‚äãp‚àó
1 ‚äã{0} is a prime chain, where
p‚àó
1 = p1/q. This contradiction to the principal ideal theorem completes the proof.
‚Ä¢

Sec. 11.4
Regular Local Rings
991
Corollary 11.163.
If R is a noetherian ring, then every prime ideal has Ô¨Ånite height, and
so Spec(R) has DCC.
Proof.
Every prime ideal p is Ô¨Ånitely generated, because R is noetherian; say, p =
(a1, . . . , an). But p is a minimal prime ideal over itself, so that Theorem 11.162 gives
ht(p) ‚â§n.
‚Ä¢
A noetherian ring may have inÔ¨Ånite Krull dimension, for there may be no uniform bound
on the length of prime chains. We will see that this cannot happen for local rings.
The generalized principal ideal theorem bounds the height of a prime ideal that is min-
imal over an ideal; the next result bounds the height of a prime ideal that merely contains
an ideal.
Corollary 11.164.
Let R be a noetherian ring, let I = (a1, . . . , an) be an ideal in R, and
let p be a prime ideal in R containing I. If ht(p/I) denotes the height of p/I in R/I, then
ht(p) ‚â§n + ht(p/I).
Proof.
The proof is by induction on h = ht(p/I) ‚â•0. If h = 0, then Exercise 11.76
on page 1011 says that p is minimal over I, and so the base step is the generalized prin-
cipal ideal theorem. For the inductive step h > 0, p is not minimal over I. By Corol-
lary 6.120(iii), there are only Ô¨Ånitely many minimal primes in R/I, and so Exercise 11.76
says that there are only Ô¨Ånitely many prime ideals minimal over I; say, q1, . . . , qs. Since p
is not minimal over I, p Ã∏‚äÜqi for any i; hence, Proposition 6.14 says that p Ã∏‚äÜq1 ‚à™¬∑ ¬∑ ¬∑‚à™qs,
and so there is y ‚ààp with y /‚ààqi for any i. DeÔ¨Åne J = (I, y).
We now show, in R/J, that ht(p/J) ‚â§h ‚àí1. Let
p/J ‚äãp1/J ‚äã¬∑ ¬∑ ¬∑ ‚äãpr/J
be a prime chain in R/J. Since I ‚ääJ, there is a surjective ring map R/I ‚ÜíR/J. The
prime chain lifts to a prime chain in R/I:
p/I ‚äãp1/I ‚äã¬∑ ¬∑ ¬∑ ‚äãpr/I.
Now pr ‚äáJ ‚äãI, and J = (I, y) does not contain any qi. But the ideals qi/I are the
minimal prime ideals in R/I, by Exercise 11.76, so that pr is not a minimal prime ideal
in R. Therefore, there is a prime chain starting at p of length r + 1. We conclude that
r + 1 ‚â§h, and so ht(p/J) ‚â§h ‚àí1.
Since J = (I, y) = (a1, . . . , an, y) is generated by n + 1 elements, the inductive
hypothesis gives
ht(p) ‚â§n + 1 + ht(p/J)
= (n + 1) + (h ‚àí1) = n + h = n + ht(p/I).
‚Ä¢
When we say, in the next proposition, that a generating set X of an ideal I is minimal,
we mean that no proper subset of X generates I.
If (R, m, k) is a local ring, then m/m2 is an (R/m)-module; that is, it is a vector space
over k.

992
Commutative Rings III
Ch. 11
Proposition 11.165.
Let (R, m, k) be a noetherian local ring.
(i) Elements x1, . . . , xd form a minimal generating set for m if and only if the cosets
x‚àó
i = xi + m2 form a basis of m/m2.
(ii) Any two minimal generating sets of m have the same number of elements.
Proof.
(i) If x1, . . . , xd is a minimal generating set for m, then X‚àó= x‚àó
1, . . . , x‚àó
d spans
the vector space m/m2. If X‚àóis linearly dependent, then there is some x‚àó
i = 
jÃ∏=i r‚Ä≤
j x‚àó
J,
where r‚Ä≤
j ‚ààk. Lifting this equation to m, we have xi ‚àà
jÃ∏=i r j x j + m2. Thus, if
B = ‚ü®x j : j Ã∏= i‚ü©, then B + m2 = m. Hence,
m (m/B) = (B + m2)/B = m/B.
By Nakayama's lemma, m/B = {0}, and so m = B. This contradicts x1, . . . , xd being a
minimal generating set. Therefore, X‚àóis linearly independent, and hence it is a basis of
m/m2.
Conversely, assume that x‚àó
1, . . . , x‚àó
d is a basis of m/m2, where x‚àó
i = xi + m2. If we
deÔ¨Åne A = ‚ü®x1, . . . , xd‚ü©, then A ‚äÜm. If y ‚ààm, then y‚àó= r‚Ä≤
i x‚àó
i , where r‚Ä≤
i ‚ààk, so that
y ‚ààA + m2. Hence, m = A + m2, and, as in the previous paragraph, Nakayama's lemma
gives m = A; that is, x1, . . . , xd generate m. If a proper subset of x1, . . . , xd generates m,
then the vector space m/m2 could be generated by fewer than d elements, contradicting
dimk(m/m2) = d.
(ii) The number of elements in any minimal generating set is dimk(m/m2).
‚Ä¢
DeÔ¨Ånition.
If (R, m, k) is a noetherian local ring, then m/m2 is a Ô¨Ånite-dimensional
vector space over k. Write
¬µ(m) = dimk(m/m2).
Proposition 11.165 shows that all minimal generating sets of m have the same number
of elements, namely, ¬µ(m).
Corollary 11.166.
If (R, m) is a noetherian local ring, then ht(m) ‚â§¬µ(m), and
dim(R) ‚â§¬µ(m).
Proof.
If ¬µ(m) = d, then m = (x1, . . . , xd). Since m is obviously a minimal prime over
itself, Theorem 11.162, the generalized principal ideal theorem, gives ht(m) ‚â§d = ¬µ(m).
If p Ã∏= m is a prime ideal in R, then any prime chain, p = p0 ‚äãp1 ‚äã¬∑ ¬∑ ¬∑ ‚äãph, can
be lengthened by to a prime chain m ‚äãp0 ‚äãp1 ‚äã¬∑ ¬∑ ¬∑ ‚äãph of length h + 1. Therefore,
h < ¬µ(m), and so dim(R) = ht(m) ‚â§¬µ(m).
‚Ä¢

Sec. 11.4
Regular Local Rings
993
DeÔ¨Ånition.
A regular local ring is a noetherian local ring (R, m) such that
dim(R) = ¬µ(m).
It is clear that every Ô¨Åeld is a regular local ring of dimension 0, and every DVR is a
regular local ring of dimension 1. It is not clear from the deÔ¨Ånition whether there are any
other examples. The coming notion of regular sequence will enable us to better understand
regular local rings. Recall that if M is an R-module, then an element c ‚ààR is called regular
on M if the map M ‚ÜíM, given by m ‚Üícm, is an injection; that is, cm = 0 implies
m = 0.
DeÔ¨Ånition.
A sequence x1, . . . , xn in a commutative ring R is an M-regular sequence
if x1 is regular on M, x2 is regular on M/(x1)M, x3 is regular on M/(x1, x2)M,. . ., xn is
regular on M/(x1, ¬∑ ¬∑ ¬∑ , xn‚àí1)M. If M = R, then x1, . . . , xn is also called an R-sequence.
For example, if R = k[x1, . . . , xn] is a polynomial ring over a Ô¨Åeld k, then it is easy to
see that x1, . . . , xn is an R-sequence.
Exercise 11.75 on page 1011 gives an example of a permutation of an R-sequence that
is not an R-sequence. However, if R is local, then every permutation of an R-sequence is
also an R-sequence (see Bruns-Herzog, Cohen-Macaulay Rings, page 5).
The generalized principal ideal theorem gives an upper bound on the height of a prime
ideal; the next lemma gives a lower bound.
Lemma 11.167.
Let R be a commutative ring.
(i) If x ‚ààR is not a zero divisor, then x lies in no minimal prime ideal.
(ii) If p is a prime ideal in R and x ‚ààp is not a zero divisor, then
ht(p/(x)) + 1 ‚â§ht(p).
(iii) If a prime ideal p in R contains an R-sequence x1, . . . , xd, then
d ‚â§ht(p).
Proof.
(i) Suppose, on the contrary, that p is a nonzero minimal prime ideal containing
x. Now Rp is a ring with only one nonzero prime ideal, namely, pp, which must be the
nilradical. Thus, x/1, as every element in pp, is nilpotent. If xm/1 = 0 in Rp, then there is
œÉ /‚ààp (so that œÉ Ã∏= 0) with œÉ x = 0, contradicting x not being a zero divisor.
(ii) If h = ht(p/(x)), then there is a prime chain in R/(x):
p/(x) ‚äãp1/(x) ‚äã¬∑ ¬∑ ¬∑ ‚äãph/(x).
Lifting back to R, there is a prime chain p ‚äãp1 ‚äã¬∑ ¬∑ ¬∑ ‚äãph with ph ‚äá(x). Since x is not
a zero divisor, part (i) says that ph is not a minimal prime. Therefore, there exists a prime
ideal ph+1 properly contained in ph, which shows that ht(p) ‚â•h + 1.

994
Commutative Rings III
Ch. 11
(iii) The proof is by induction on d ‚â•1. For the base step d = 1, suppose, on the contrary,
that ht(p) = 0; then p is a minimal prime ideal, and this contradicts part (i). For the
inductive step, part (ii) gives ht(p/(x1)) + 1 ‚â§ht(p). Now p/(x1) contains an (R/(x1))-
sequence x2+(x1), . . . , xd +(x1), by Exercise 11.79(ii) on page 1012, so that the inductive
hypothesis gives d ‚àí1 ‚â§ht(p/(x1)). Therefore, part (ii) gives d ‚â§ht(p).
‚Ä¢
Proposition 11.168.
Let (R, m) be a noetherian local ring. If m can be generated by an
R-sequence x1, . . . , xd, then R is a regular local ring and
d = dim(R) = ¬µ(m).
Remark.
We will soon prove the converse: In a regular local ring, the maximal ideal can
be generated by an R-sequence.
‚óÄ
Proof.
Consider the inequalities
d ‚â§ht(m) ‚â§¬µ(m) ‚â§d.
The Ô¨Årst inequality holds by Lemma 11.167; the second by Corollary 11.166, and the third
by Proposition 11.165. It follows that all the inequalities are, in fact, equalities, and the
proposition follows because dim(R) = ht(m).
‚Ä¢
Example 11.169.
Let k be a Ô¨Åeld, and let R = k[[x1, . . . , xr]] be the ring of formal power series in r variables
x1, . . . , xr. Recall that an element f ‚ààR is a sequence
f = ( f0, f1, f2, . . . , fn, . . .),
where fn is a homogeneous polynomial of total degree n in k[x1, . . . , xr], and that multi-
plication is deÔ¨Åned by
( f0, f1, f2, . . .)(g0, g1, g2, . . .) = (h0, h1, h2, . . .),
where hn = 
i+ j=n fig j. We claim that R is a local ring with maximal ideal m =
(x1, . . . , xr) and residue Ô¨Åeld k. First, R/m ‚àº= k, so that m is a maximal ideal. To see
that m is the unique maximal ideal, it sufÔ¨Åces to prove that if f ‚ààR and f /‚ààm, then
f is a unit. Now f /‚ààm if and only if f0 Ã∏= 0, and we now show that f is a unit if and
only if f0 Ã∏= 0. If f g = 1, then f0g0 = 1, and f0 Ã∏= 0; conversely, if f0 Ã∏= 0, we can
solve ( f0, f1, f2, . . .)(g0, g1, g2, . . .) = 1 recursively for gn, and f g = 1 if we deÔ¨Åne
g = (g0, g1, g2, . . .).
Exercise 11.83 on page 1012 shows that the ring R is noetherian. But R/(x1, . . . , xi‚àí1)
is a domain, because it is isomorphic to k[[xi, . . . , xr]], and so xi is a regular element on
it. Hence, Proposition 11.168 shows that R = k[[x1, . . . , xr]] is a regular local ring, for
x1, . . . , xr is an R-sequence.
‚óÄ
The next lemmas prepare us for induction.

Sec. 11.4
Regular Local Rings
995
Lemma 11.170.
Let (R, m, k) be a noetherian local ring, and let x ‚ààm ‚àím2.
(i) If x1 + (x), . . . , xs + (x) is a minimal generating set of m/xm, then x, x1, . . . , xs is
a minimal generating set of m.
(ii)
¬µ(m/xm) = ¬µ(m) ‚àí1.
Proof.
(i) Write R = R/(x), m = m/xm, and r = r + (x) for all r ‚ààR. To see that
x, x1, . . . , xs generate m, let y ‚ààm. Then y = 
i r‚Ä≤
i xi, where r‚Ä≤
i ‚ààk. Lifting to R gives
y ‚àí
i ri xi ‚àà(x), where r‚Ä≤
i = ri + m. Therefore, there is r ‚ààR with y = rx + ri xi.
To prove minimality, Proposition 11.165 says that it sufÔ¨Åces to show that the cosets
x‚àó= x + m2, x‚àó
i = xi + m2 form a basis of m/m2. These elements span m/m2 because
x, x1, . . . , xs generate m. To prove linear independence, assume that a‚Ä≤x‚àó+  a‚Ä≤
i x‚àó
i = 0,
where a‚Ä≤, a‚Ä≤
i ‚ààk. Lifting to R, we have
ax +

ai xi ‚ààm2,
(8)
and we must show that a, ai ‚ààm (for then a‚Ä≤, a‚Ä≤
i = 0 in k = R/m). In R = R/(x), this
relation becomes

i
ai xi ‚ààm2.
As x1, . . . , xs is a basis of m/m2, we have a‚Ä≤
i = 0 for all i; that is, ai ‚ààm for all i. It
follows from Eq. (8) that ax ‚ààm2. Since x /‚ààm2, it follows that a ‚ààm, as desired.
(ii) This follows at once from part (i).
‚Ä¢
Lemma 11.171.
Let (R, m) be a regular local ring. If x ‚ààm‚àím2, then R/(x) is regular
and dim(R/(x)) = dim(R) ‚àí1.
Proof.
Since R is regular, we have dim(R) = ¬µ(m). Let us note at the outset that
dim(R) = ht(m). We must show that ht(m‚àó) = ¬µ(m‚àó), where m‚àó= m/(x). By Corol-
lary 11.164, ht(m) ‚â§ht(m‚àó) + 1. Hence,
ht(m) ‚àí1 ‚â§ht(m‚àó)
‚â§¬µ(m‚àó)
= ¬µ(m) ‚àí1
= ht(m) ‚àí1.
The next to last equation is Lemma 11.170; the last equation holds because R is reg-
ular.
Therefore, dim(R‚àó) = ht(m‚àó) = ¬µ(m‚àó), and so R‚àó= R/(x) is regular with
dim(R/(x)) = dim(R) ‚àí1.
‚Ä¢
We are now going to prove that regular local rings are domains, and we will then use
this to prove the converse of Proposition 11.168.

996
Commutative Rings III
Ch. 11
Proposition 11.172.
Every regular local ring (R, m) is a domain.
Proof.
The proof is by induction on d = dim(R). If d = 0, then R is a Ô¨Åeld, by Exer-
cise 11.78 on page 1012. If d > 0, let p1, . . . , ps be the minimal prime ideals in R (there
are only Ô¨Ånitely many such, by Corollary 6.120). If m ‚àím2 ‚äÜp1 ‚à™¬∑ ¬∑ ¬∑ ‚à™ps, then Propo-
sition 6.14 would give m ‚äÜpi, which cannot occur because d = ht(m) > 0. Therefore,
there is x ‚ààm ‚àím2 with x /‚ààpi for all i. By Lemma 11.171, R/(x) is regular of dimen-
sion d ‚àí1. The inductive hypothesis gives R/(x) a domain, and so (x) is a prime ideal. It
follows that (x) contains a minimal prime ideal; say, pi ‚äÜ(x).
If pi = {0}, then {0} is a prime ideal and R is a domain. Hence, we may assume that
pi Ã∏= {0}. For each nonzero y ‚ààpi, there exists r ‚ààR with y = rx. Since x /‚ààpi, we
have r ‚ààpi, so that y ‚ààxpi. Thus, pi ‚äÜxpi ‚äÜmpi. As the reverse inclusion mpi ‚äÜpi
is always true, we have pi = mpi. Nakayama's lemma now applies, giving pi = {0}, a
contradiction.
‚Ä¢
Proposition 11.173.
A noetherian local ring (R, m, k) is regular if and only if m is
generated by an R-sequence x1, . . . , xd. Moreover, in this case,
d = ¬µ(m).
Proof.
We have already proven sufÔ¨Åciency, in Proposition 11.168. If R is regular, we
prove the result by induction on d ‚â•1, where d = dim(R). The base step holds, for R is a
domain and so x is a regular element; that is, x is not a zero divisor. For the inductive step,
the ring R/(x) is regular of dimension d ‚àí1, by Lemma 11.171. Therefore, its maximal
ideal is generated by an (R/(x))-sequence x‚àó
1, . . . , x‚àó
d‚àí1. By Lemma 11.170, a minimal
generating set for m is x, x1, . . . , xd‚àí1. Finally, this is an R-sequence, by Exercise 11.79(i)
on page 1012, because x is not a zero divisor.
‚Ä¢
We are now going to characterize regular local rings by their global dimension.
Lemma 11.174.
Let (R, m, k) be a local ring. If A is an R-module with pd(A) = n and
if x ‚ààm is A-regular, then pd(A/x A) = n + 1.
Proof.
Since x is A-regular, there is an exact sequence
0 ‚ÜíA
¬µx
‚àí‚ÜíA ‚ÜíA/x A ‚Üí0,
where ¬µx : a ‚Üíxa. By Lemma 11.147, we have pd(A/x A) ‚â§n + 1.
Consider the portion of the long exact sequence arising from tensoring by k:
0 = TorR
n+1(A, k) ‚ÜíTorR
n+1(A/x A, k)
‚àÇ
‚àí‚ÜíTorR
n (A, k)
(¬µx)‚àó
‚àí‚ÜíTorR
n (A, k).
Now pd(A) ‚â§n if and only if TorR
n+1(A, k) = {0}, by Lemma 11.155, and so the Ô¨Årst
term is {0}. The induced map (¬µx)‚àóis multiplication by x. However, if ¬µ‚Ä≤
x : k ‚Üík is
multiplication by x, then x ‚ààm implies ¬µ‚Ä≤
x = 0; therefore, (¬µx)‚àó= (¬µ‚Ä≤
x)‚àó= 0. Exactness
now gives ‚àÇ: TorR
n+1(A/x A, k) ‚ÜíTorR
n (A, k) an isomorphism. Since pd(A) = n, we
have TorR
n (A, k) Ã∏= {0}, so that TorR
n+1(A/x A, k) Ã∏= {0}. Therefore, pd(A/x A) ‚â•n + 1,
as desired.
‚Ä¢

Sec. 11.4
Regular Local Rings
997
Proposition 11.175.
If (R, m, k) is a regular local ring, then
D(R) = ¬µ(m) = dim(R).
Proof.
Since R is regular, Proposition 11.173 says that m can be generated by an R-
sequence x1, . . . , xd. Applying Lemma 11.174 to the modules R, R/(x1), R/(x1, x2), . . .,
R/(x1, . . . , xd) = R/m = k, we see that pd(k) = d. By Proposition 11.168, d = ¬µ(m) =
dim(R). On the other hand, Theorem 11.157(ii) gives d = pd(k) = D(R).
‚Ä¢
The converse of Proposition 11.175, A noetherian local ring of Ô¨Ånite global dimension
is regular, is more difÔ¨Åcult to prove.
Lemma 11.176.
Let (R, m, k) be a noetherian local ring of Ô¨Ånite global dimension. If
¬µ(m) ‚â§D(R) and D(R) ‚â§d, where d is the length of a longest R-sequence in m, then R
is a regular local ring.
Proof.
By Corollary 11.166, dim(R) ‚â§¬µ(m). By hypothesis, ¬µ(m) ‚â§D(R) ‚â§d, while
Lemma 11.167 gives d ‚â§ht(m) = dim(R). Therefore, dim(R) = ¬µ(m), and so R is a
regular local ring.
‚Ä¢
Let R be a noetherian ring, let M be a Ô¨Ånitely generated R-module, and let I be an ideal
such that I M Ã∏= M. By Exercise 11.82 on page 1012, I contains a longest M-sequence
(such sequences are usually called maximal M-sequences in I). We are going to prove,
given an ideal I and a Ô¨Ånitely generated R-module M, that all maximal M-sequences in I
have the same length.
DeÔ¨Ånition.
If R is a commutative ring, then an associated prime ideal of a nonzero
R-module B is a prime ideal of the form ann(b) for some nonzero b ‚ààB.
Lemma 11.177.
Let B be a nonzero Ô¨Ånitely generated module over a noetherian ring R.
(i) The maximal elements in F(B) = {ann(b) : b ‚ààB and b Ã∏= 0} are associated prime
ideals of B.
(ii) There are Ô¨Ånitely many associated prime ideals of B, say, p1, . . . , ps, such that
Z(B) = p1 ‚à™¬∑ ¬∑ ¬∑ ‚à™ps,
where Z(B) = {r ‚ààR : rb = 0 for some nonzero b ‚ààB}.
Proof.
(i) The set of ideals F(B) has maximal elements, because R is noetherian. Let
ann(b) be such a maximal element. Suppose that rs ‚ààann(b), where r, s ‚ààR and r /‚àà
ann(b). Now ann(b) ‚äÜann(rb), for if ub = 0, then u(rb) = 0; by maximality, ann(b) =
ann(rb). Hence, s ‚ààann(rb) implies s ‚ààann(b), and so ann(b) is a prime ideal.
(ii) For each r ‚ààZ(B), there is a nonzero b ‚ààB with rb = 0; that is, Z(B) =
!
ann(b)‚ààF(B) ann(b). If we denote the set of maximal elements in F(B) by M, then
Z(B) = !
p‚ààM p, for every ann(b) ‚ààF(B) is contained in a maximal element.

998
Commutative Rings III
Ch. 11
It sufÔ¨Åces to prove that M is Ô¨Ånite. DeÔ¨Åne B‚Ä≤ = ‚ü®b : ann(b) ‚ààM‚ü©. Now B‚Ä≤ is Ô¨Ånitely
generated, for R noetherian implies that every submodule of a Ô¨Ånitely generated R-module
is itself Ô¨Ånitely generated; let B‚Ä≤ = ‚ü®b1, . . . , bn‚ü©, and denote ann(bi) by pi. Suppose there
is q = ann(b0) ‚ààM with b0 Ã∏= bi for i = 1, . . . , n. As b0 ‚ààB‚Ä≤, there are ri ‚ààR with
b0 = 
i ribi. It follows that if r ‚àà
i pi, then rb0 = 0; that is, 
i pi ‚äÜann(b0) = q.
Since q is a prime ideal, Proposition 6.13 gives pi ‚äÜq for some i. As pi is a maximal
element in F(B), we have q = pi, as desired.
‚Ä¢
Remark.
The set Ass(B) of all associated primes of an R-module B is important in
deeper studies [M may be a proper subset of Ass(B)]. For example, it is related to primary
decompositions (see Matsumura, Commutative Ring Theory, pages 39 - 42).
‚óÄ
The next lemma is a generalization of the observation that HomZ(Im, In) = {0} if
(m, n) = 1.
Lemma 11.178.
Let R be a commutative ring, and let A and B be R-modules.
(i) If ann(A) contains a B-regular element, then HomR(A, B) = {0}.
(ii) Conversely, let R be noetherian, and let A and B be Ô¨Ånitely generated R-modules.
If HomR(A, B) = {0}, then ann(A) contains a B-regular element.
Proof.
(i) If r ‚ààann(A), then ra = 0 for all a ‚ààA. Hence, for all f ‚ààHomR(A, B),
we have 0 = f (ra) = r f (a). On the other hand, if r is B-regular, then r f (a) = 0 implies
f (a) = 0, and so f = 0.
(ii) Assume, on the contrary, that ann(A) contains no B-regular elements; that is, ann(A) ‚äÜ
Z(B).
By Lemma 11.177, there are Ô¨Ånitely many associated prime ideals of B, say,
p1, . . . , ps, such that ann(A) ‚äÜZ(B) = p1 ‚à™¬∑ ¬∑ ¬∑ ‚à™ps, and so Proposition 6.14 says
that there is some p = pi with ann(A) ‚äÜp.
Suppose that Ap = {0}. If A = ‚ü®a1, . . . , an‚ü©, then there are œÉi /‚ààp with œÉiai = 0, by
Proposition 11.25. Since p is prime, œÉ = œÉ1œÉ2 ¬∑ ¬∑ ¬∑ œÉn /‚ààp. But œÉ ‚ààann A = I ‚äÜp, and
this is a contradiction. Therefore, Ap Ã∏= {0}.
We wish to prove that HomR(A, B) Ã∏= {0}. By Lemma 11.32, it sufÔ¨Åces to prove
that HomR(A, B)p ‚àº= HomRp(Ap, Bp) Ã∏= {0}. Thus, we may assume that (R, p, k) is a
local ring with maximal ideal p and residue Ô¨Åeld k. Now there is an element b ‚ààB with
ann(b) = p, so that ‚ü®b‚ü©‚àº= R/p = k. Hence, there is a nonzero map œï : k ‚ÜíB (taking
1 ‚Üíb). Since Ap Ã∏= {0}, Nakayama's lemma gives A/pA Ã∏= {0}. But A/pA is a nonzero
vector space over k, so there exists a nonzero map A/pA ‚Üík. The composite of this map
followed by œï is a nonzero map A ‚ÜíB, and so HomR(A, B) Ã∏= {0}.
‚Ä¢
Lemma 11.179.
Let R be a commutative ring, let A and B be R-modules, and let
x1, . . . , xn be a B-sequence in ann(A). If I = (x1, . . . , xn), then
HomR(A, B/I B) ‚àº= Extn
R(A, B).

Sec. 11.4
Regular Local Rings
999
Proof.
The proof is by induction on n ‚â•0. We deÔ¨Åne I = {0} in case n = 0, and so
the base step holds. Assume now that x1, . . . , xn+1 is a B-sequence in ann(A), that I =
(x1, . . . , xn+1), and that J = (x1, . . . , xn). Observe Ô¨Årst that there is an exact sequence
0 ‚ÜíB ‚ÜíB ‚ÜíB/x1B ‚Üí0, for x1 is a regular element on B. Consider the portion of
the long exact sequence, where x1 is multiplication by x1:
Extn
R(A, B)
x1‚àó
‚àí‚ÜíExtn
R(A, B)
‚àÇ
‚àí‚ÜíExtn
R(A, B/x1B) ‚ÜíExtn+1
R
(A, B)
x1‚àó
‚àí‚ÜíExtn+1
R
(A, B).
Since x1 ‚ààann(A), the induced map x1‚àóis the zero map, and there is a short exact sequence
0 ‚ÜíExtn
R(A, B) ‚ÜíExtn
R(A, B/x1B)
‚àÇ
‚àí‚ÜíExtn+1
R
(A, B) ‚Üí0.
By induction, HomR(A, B/J B) ‚àº= Extn
R(A, B). Multiplication by xn+1 : B/J B ‚ÜíB/J B
is an injection, because xn+1 is (B/J B)-regular, and left exactness of HomR(A, ) shows
that (xn+1)‚àóis an injection HomR(A, B/J B) ‚ÜíHomR(A, B/J B). On the other hand,
(xn+1)‚àóis the zero map, for xn+1 ‚ààann(A).
Hence, HomR(A, B/J B) = {0}, and
Extn
R(A, B) = {0}. Therefore, ‚àÇ: Extn
R(A, B/x1B) ‚ÜíExtn+1
R
(A, B) is an isomorphism.
By induction, if B‚Ä≤ = B/x1B, then HomR(A, B‚Ä≤/(x2, . . . , xn+1)B‚Ä≤) ‚àº= Extn
R(A, B/x1B).
But
B‚Ä≤/(x2, . . . , xn+1)B‚Ä≤ ‚àº= (B/x1B)/(I B/x1B) ‚àº= B/I B,
so that HomR(A, B/I B) ‚àº= Extn
R(A, B/x1B). We conclude that HomR(A, B/I B) ‚àº=
Extn+1
R
(A, B), as desired.
‚Ä¢
The following result is due to D. Rees.
Proposition 11.180.
Let R be a commutative noetherian ring, B a Ô¨Ånitely generated R-
module, and I an ideal with I B Ã∏= B. Then all maximal B-sequences in I have the same
length, say, g, where
g = min

i : Exti
R(R/I, B) Ã∏= {0}

.
Proof.
Let x1, . . . , xg be a maximal B-sequence in I. For all i = 1, 2, . . . , g, deÔ¨Åne
Ii = (x1, . . . , xi‚àí1) (with I1 = {0}). Now xi is a (B/Ii B)-regular element, and so
Exti‚àí1
R (R/I, B) ‚àº= HomR(R/I, B/Ii B) = {0},
by Lemma 11.179, which applies because ann(R/I) = I ‚äáIi. On the other hand, since
x1, . . . , xg is a maximal B-sequence in I, the ideal I contains no (B/I B)-regular elements.
Thus, Lemma 11.178 gives
Extg
R(R/I, B) ‚àº= HomR(R/I, B/I B) Ã∏= {0}.
‚Ä¢
DeÔ¨Ånition.
If R is a noetherian ring, B a Ô¨Ånitely generated R-module, and I an ideal
such that I B Ã∏= B, then the grade of B in I is
G(I, B) = length of a maximal B-sequence in I.
If (R, m) is a noetherian local ring, then G(m, B) is called depth of B:
depth(B) = G(m, B).
The number d in Lemma 11.176 is depth(R).

1000
Commutative Rings III
Ch. 11
Proposition 11.181 (Auslander-Buchsbaum).
Let (R, m) be a noetherian local ring,
and let B be a Ô¨Ånitely generated R-module with pd(B) = n < ‚àû. Then
pd(B) + depth(B) = depth(R).
Proof.
The proof is by induction on n = pd(B) ‚â•0. If n = 0, then B is a Ô¨Ånitely
generated projective R-module, and so B is free, by Proposition 11.23. Hence, B ‚àº=
m
j=1 R j, where R j ‚àº= R, and so Extq
R(k, B) ‚àº= m
j=1 Extq
R(k, R) for all q. It follows
that depth(B) = depth(R), as desired.
For the inductive step, there is an exact sequence
0 ‚Üí$ ‚ÜíF ‚ÜíB ‚Üí0,
where F is a Ô¨Ånitely generated free R-module. The long exact sequence is
Exti
R(k, F) ‚ÜíExti
R(k, B) ‚ÜíExti+1
R (k, $) ‚ÜíExti+1
R (k, F).
By Lemma 11.178, Ext0
R(k, F) = HomR(k, F) = {0}; since F is free, Exti
R(k, F) = {0}
for all i > 0. Therefore, Exti
R(k, B) ‚àº= Exti+1
R (k, $) for all i ‚â•0. It follows that
depth($) = depth(B) + 1.
Since n = pd(B) > 0, we have B not projective, and so pd($) = n ‚àí1. By induction,
pd($) + depth($) = depth(R). Therefore,
depth(R) = pd($) + depth($)
= pd($) + 1 + depth($) ‚àí1
= pd(B) + depth(B).
‚Ä¢
Corollary 11.182.
If (R, m) is a noetherian local ring of Ô¨Ånite global dimension, then
D(R) ‚â§depth(R).
Proof.
By Proposition 11.181, pd(M) ‚â§depth(R) for every Ô¨Ånitely generated R-module
M. But D(R) = sup{pd(M) : M is Ô¨Ånitely generated}, by Theorem 11.134, and so
D(R) ‚â§depth(R).
‚Ä¢
To complete the homological characterization of regular local rings, it remains to estab-
lish the second inequality in Lemma 11.176: ¬µ(m) ‚â§D(R). Recall that Theorem 11.157
shows that D(R) = pd(k). If we write s = ¬µ(m), we will prove that s ‚â§pd(k) by com-
paring a Koszul complex for k with a minimal resolution of k. Our exposition is merely a
more detailed version of the account given in Serre, Alg`ebre Locale: Multiplicit¬¥es, pages
112-116.
If f : A ‚ÜíB is a map of R-modules, let f = f ‚äó1k : A ‚äóR k ‚ÜíB ‚äóR k. Recall that
A ‚äóR k ‚àº= A/mA, as can easily be seen by tensoring the short exact sequence 0 ‚Üím ‚Üí
R ‚Üík ‚Üí0 by A. With this identiÔ¨Åcation, f : a + mA ‚Üíf (a) + mB.

Sec. 11.4
Regular Local Rings
1001
Lemma 11.183.
Let (R, m, k) be a noetherian local ring, let f : A ‚ÜíB be a map of
Ô¨Ånitely generated R-modules, and let f = f ‚äó1k.
(i) f is surjective if and only if f is surjective.
(ii) If, in addition, both A and B are free R-modules, then f injective implies that f is
a (split) injection.
Proof.
(i) If f is surjective, tensor the exact sequence A
f
‚àí‚ÜíB ‚Üícoker f ‚Üí0 by k to
obtain the exact sequence
A ‚äóR k
f
‚àí‚ÜíB ‚äóR k ‚Üí(coker f ) ‚äóR k ‚Üí0.
Since f is surjective, (coker f ) ‚äóR k = {0}. But (coker f ) ‚äóR k ‚àº= coker f/m coker f ,
so that coker f = m coker f . Now coker f is Ô¨Ånitely generated, because B is Ô¨Ånitely
generated, and so Nakayama's lemma gives coker f = {0}; that is, f is surjective.
Conversely, since ‚äóRk is right exact, f surjective implies f surjective.
(ii) Assume that f is injective. Let x1, . . . , xt be a basis of A, and let bi = f (xi) for
i = 1, . . . , t. Since f is injective, the elements bi = bi + mB are linearly independent in
B/mB, and so they extend to a basis: There are c1, . . . , cs ‚ààB with b1, . . . , bt, c1, . . . , cs
a basis of B/mB. An application of Nakayama's lemma, as in the proof of Proposi-
tion 11.23, shows that b1, . . . , bt, c1, . . . , cs is a basis of B. If we deÔ¨Åne h : B ‚ÜíA
by h(bi) = xi and h(c j) = 0, then we see that h f = 1A, and so f is injective.
‚Ä¢
DeÔ¨Ånition.
Let (R, m, k) be a noetherian local ring. A map f : A ‚ÜíB of R-modules is
minimal if ker f ‚äÜmA.
Thus, the lemma says that if f : A ‚ÜíB is minimal, where A and B are free R-modules
of Ô¨Ånite rank, then f : A ‚ÜíB injective implies f injective.
DeÔ¨Ånition.
Let (R, m, k) be a noetherian local ring, and let A be a Ô¨Ånitely generated
R-module. A free resolution
¬∑ ¬∑ ¬∑ ‚ÜíL2
d2
‚àí‚ÜíL1
d1
‚àí‚ÜíL0
d0
‚àí‚ÜíA ‚Üí0
is a minimal resolution if all Ln are Ô¨Ånitely generated and ker dn ‚äÜmLn for all n ‚â•0;
that is, all dn are minimal.
Proposition 11.184.
Let (R, m, k) be a noetherian local ring. Every Ô¨Ånitely generated
R-module A has a minimal resolution.
Proof.
Since A is Ô¨Ånitely generated, it has a minimal generating set, say, {a1, . . . , an}. Let
L0 be the free R-module with basis {e1, . . . , en}, and deÔ¨Åne d0 : L0 ‚ÜíA by d0(ei) = ai
for all i. We saw, in the proof of Proposition 11.23 that ker d0 ‚äÜmL0, and so d0 is minimal.
Since R is noetherian, ker d0 is Ô¨Ånitely generated, and so this construction can be iterated.
Thus, induction shows that a minimal resolution of A exists.
‚Ä¢

1002
Commutative Rings III
Ch. 11
Proposition 11.185.
Let (R, m, k) be a noetherian local ring, let A be a Ô¨Ånitely generated
R-module, and let
¬∑ ¬∑ ¬∑ ‚ÜíL2
d2
‚àí‚ÜíL1
d1
‚àí‚ÜíL0
d0
‚àí‚ÜíA ‚Üí0
be a minimal resolution. Then for all i ‚â•0,
TorR
i (A, k) ‚àº= Li/mLi.
Therefore,
rank(TorR
i (A, k)) = rank(Li).
Proof.
Deleting A from the minimal resolution gives a complex LA; tensoring LA by k
gives a complex
LA = ¬∑ ¬∑ ¬∑ ‚ÜíL2
d2
‚àí‚ÜíL1
d1
‚àí‚ÜíL0 ‚Üí0.
Now im di+1 = ker di ‚äÜmLi implies di = 0 for every i, so that Hi(LA) ‚àº= Li for all
i ‚â•0. On the other hand, LA = LA‚äóR k, and so the deÔ¨Ånition of Tor gives Hi(LA‚äóR k) =
TorR
i (A, k). Therefore, TorR
i (A, k) ‚àº= Li ‚àº= Li/mLi.
‚Ä¢
Let us make an elementary observation. If (R, m, k) is a noetherian local ring and M is
an R-module, then we have already seen that M/mM ‚àº= M ‚äóR k; let us denote M/mM by
M. A map œï : M ‚ÜíM‚Ä≤ induces a map œï : M ‚ÜíM‚Ä≤ by
œï : u + mM ‚Üíœï(u) + mM‚Ä≤;
if œï satisÔ¨Åes the additional condition im œï ‚äÜmM‚Ä≤, then there is a second induced map
œï : M/mM ‚ÜímM/m2M, given by
œï(u + mM) = œï(u) + m2M‚Ä≤.
Lemma 11.186.
Let (R, m, k) be a local ring, let A be a Ô¨Ånitely generated R-module,
and let
¬∑ ¬∑ ¬∑ ‚ÜíL2
d2
‚àí‚ÜíL1
d1
‚àí‚ÜíL0
d0
‚àí‚ÜíA ‚Üí0
be a minimal resolution of A. If ¬∑ ¬∑ ¬∑ ‚ÜíM2
D2
‚àí‚ÜíM1
D1
‚àí‚ÜíM0
Œµ
‚àí‚ÜíA ‚Üí0 is a complex
satisfying
(i) each Mp is a Ô¨Ånitely generated free R-module;
(ii) Œµ: M0 ‚ÜíA is injective;
(iii) For all p > 0, we have Dp(Mp) ‚äÜmMp‚àí1, and Dp : M p ‚ÜímMp‚àí1/m2Mp‚àí1,
given by u p + mMp ‚ÜíDp(u p) + m2Mp‚àí1, is an injection;
then, for all p ‚â•0, rank(Mp) ‚â§rank(L p) = rank(TorR
p(A, k)).

Sec. 11.4
Regular Local Rings
1003
Proof.
We will show that each Mp is isomorphic to a direct summand of L p. By The-
orem 10.46, the comparison theorem, there are maps f p making the following diagram
commute:
¬∑ ¬∑ ¬∑
 M1
f1

D1  M0
f0

Œµ
 A
1A

 0
¬∑ ¬∑ ¬∑
 L1
d1
 L0
d0
 A
 0.
It sufÔ¨Åces to Ô¨Ånd surjections gp : L p ‚ÜíMp: since Mp is free, hence projective, Mp
would then be isomorphic to a direct summand of L p. We claim that such maps gp exist if
f p : M p ‚ÜíL p is injective. Now M p and L p are vector spaces over k, so that the subspace
f p(M p) ‚àº= M p is a direct summand of L p; thus, there is a (necessarily) surjective map
Œ≥ : L p ‚ÜíM p with Œ≥ f p = 1M p. Let œÄ : Mp ‚ÜíM p and ŒΩ : L p ‚ÜíL p be the natural
maps (regard M p = Mp/mMp and L p = L p/mL p), and consider the diagram
L p
Œ≥ œÄ

gp

Mp
ŒΩ
 M p
 0.
Since L p is free, there exists gp with ŒΩgp = Œ≥ œÄ; that is, g p = Œ≥ œÄ. Hence, g p is surjective,
and so gp is surjective, by Lemma 11.183.
It remains to show, by induction on p ‚â•0, that the conditions listed in the statement
imply each f p is injective. For the base step, d0 f0 = Œµ implies d0 f 0 = Œµ. By hypothesis,
both Œµ and d0 are injections. However, Lemma 11.183(i) shows that both are isomorphisms,
because both Œµ and d0 are surjections. It follows that f 0 is an injection (in fact, it is even
an isomorphism).
For the inductive step, consider the following commutative diagram.
Mp/mMp
f p

Dp

L p/mL p
dp

mMp‚àí1/m2Mp‚àí1
f p‚àí1
 mL p‚àí1/m2L p‚àí1.
Since L‚Ä¢ is a complex, we have im dp ‚äÜker dp‚àí1; since L‚Ä¢ is a minimal resolution, we
have ker dp‚àí1 ‚äÜmL p‚àí1; hence, the map dp is deÔ¨Åned. By induction, f p‚àí1 is injective;
hence, f p‚àí1 Dp is injective, because Dp is injective, by hypothesis. Therefore, dp f p is
injective, and this implies that f p is injective.
‚Ä¢
The following complex M‚Ä¢ will be seen to satisfy the conditions in Lemma 11.186.

1004
Commutative Rings III
Ch. 11
DeÔ¨Ånition.
Let x1, . . . , xs be a sequence of elements in a commutative ring R. The
Koszul complex M(x1, . . . , xs)‚Ä¢ is deÔ¨Åned as follows.
M(x1, . . . , xs)p =
<p(F),
where F is the free R-module with basis {e1, . . . , es}. The differentiations Dp : ;p(F) ‚Üí
;p‚àí1(F) are deÔ¨Åned by
D1
 s

i=1
ciei

=
s

i=1
ci xi,
where ci ‚ààR for all i (so that D1(ei) = xi), and, for p > 1,
Dp(ei1 ‚àß¬∑ ¬∑ ¬∑ ‚àßei p) =
p

r=0
(‚àí1)r‚àí1xrei1 ‚àß¬∑ ¬∑ ¬∑ ‚àßeir ‚àß¬∑ ¬∑ ¬∑ ‚àßei p.
If A is an R-module, the Koszul complex M(x1, . . . , xs, A)‚Ä¢ is deÔ¨Åned by
M(x1, . . . , xs, A)‚Ä¢ = A ‚äóR M(x1, . . . , xs)‚Ä¢.
We leave the straightforward calculation that Dp‚àí1Dp = 0 to the reader; it is similar to
that in the proof of Lemma 10.114. Thus, the Koszul complex really is a complex.
Note that ;0(F) = R and that im d1 = I, where I = (x1, . . . , xs). In general, the
Koszul complex is not acyclic; that is, it is not an exact sequence. However, if x1, . . . , xs
is an R-sequence, then augmenting it with the natural map Œµ: ;0(F) ‚ÜíR/I gives a free
resolution of R/I (see Bruns-Herzog, Cohen-Macaulay Rings, page 49).
Observe that the pth term of M(x1, . . . , xs, k)‚Ä¢ is, by deÔ¨Ånition, k ‚äóR
;p(F). Since
F is free of rank s, we know, from Theorem 9.140, the binomial theorem, that ;p(F) is
free of rank
s
p

, and so k ‚äóR
;p(F) is a vector space over k of dimension
s
p

. Thus, if
we denote ;p(F) by Mp, as in Lemma 11.186, then k ‚äóR
;p(F) is M p.
If x1, . . . , xs is a minimal generating set for m, then Proposition 11.165 says that
x‚àó
1, . . . , x‚àó
s is a basis for m/m2, where x‚àó
i = xi + m2. If M is an R-module, then there is
an isomorphism mM/m2M ‚Üí(m/m2) ‚äóR M, given by

i
xivi + m2M ‚Üí

i
x‚àó
i ‚äóvi,
where vi ‚ààM. If œï : M ‚ÜíM‚Ä≤ has the property that im œï ‚äÜmM‚Ä≤, then œï(u) = 
i xiv‚Ä≤
i,
where v‚Ä≤
i ‚ààM‚Ä≤. Composing œï : M/mM ‚ÜímM‚Ä≤/m2M‚Ä≤ with the isomorphism above
allows us to regard œï : M/mM ‚Üí(m/m2) ‚äóR M‚Ä≤:
œï : u + mM ‚Üíœï(u) + m2M‚Ä≤ =

i
xiv‚Ä≤
i + m2M‚Ä≤ ‚Üí

i
x‚àó
i ‚äóv‚Ä≤
i.

Sec. 11.4
Regular Local Rings
1005
Lemma 11.187.
Let (R, m, k) be a noetherian local ring, and let x1, . . . , xs be a minimal
generating set for m. Then the Koszul complex M(x1, . . . , xs)‚Ä¢ satisÔ¨Åes the conditions in
Lemma 11.186.
Proof.
First, each term Mp = ;p(F) of the Koszul complex is a Ô¨Ånitely generated
free R-module. Second, deÔ¨Åne Œµ: R ‚Üík to be the natural map. Since ker Œµ = m, the
map Œµ is an injection, by Lemma 11.183. For the third condition, recall the formula for
Dp : ;p(F) ‚Üí;p‚àí1(F) (where F is the free R-module with basis e1, . . . , es):
Dp(ei1 ‚àß¬∑ ¬∑ ¬∑ ‚àßei p) =
p

r=1
(‚àí1)r‚àí1xrei1 ‚àß¬∑ ¬∑ ¬∑ ‚àßeir ‚àß¬∑ ¬∑ ¬∑ ‚àßei p.
The presence of the factor xr forces each term, and hence the sum, into mMp‚àí1.
Finally, if Mp = ;p(F) and Mp‚àí1 = ;p‚àí1(F), let us show that Dp : Mp/mMp ‚Üí
mMp‚àí1/m2Mp‚àí1, given by
Dp(u + mMp) = Dp(u) + m2Mp‚àí1,
is an injection. Recall that if e1, . . . , es is a basis of the free module F, then a basis for
Mp = ;p(F) is the set of all eI, where I = i1 < ¬∑ ¬∑ ¬∑ < i p is an increasing p ‚â§s list and
eI = ei1 ‚àß¬∑ ¬∑ ¬∑‚àßei p. If u = 
I Œ±IeI, we may assume that Œ±I is deÔ¨Åned for every increasing
list I (some Œ±I may be 0). Let us now deÔ¨Åne Œ±I for every, not necessarily increasing,
p-tuple i1, . . . , i p of indices, possibly with a repeated index: set Œ±I = 0 if some index is
repeated, and set Œ±I = ‚àíŒ±I ‚Ä≤ if I ‚Ä≤ is obtained from I by transposing two indices. With this
notation, we may now rewrite the formula for Dp:
Dp(u) = Dp

I
Œ±IeI

=
s

j=1
x j

L
Œ± j LeL,
where L = ‚Ñì1 < ¬∑ ¬∑ ¬∑ < ‚Ñìp‚àí1 is an increasing p ‚àí1 ‚â§s list, and j L = j, ‚Ñì1, . . . , ‚Ñìp‚àí1.
Note that Œ± j L is either 0 or ¬±Œ±I, where I is the rearrangement of j L into an increasing
list. Suppose now that u = 
I Œ±IeI /‚ààmMp; that is, u + mMp Ã∏= 0 in Mp/mMp.
Since the eIs are a basis of Mp, we must have some Œ±I /‚ààm; that is, Œ±I is a unit in R. If
I = i1 < ¬∑ ¬∑ ¬∑ < i p, deÔ¨Åne j = i1 and L = i2 < ¬∑ ¬∑ ¬∑ < i p. The coefÔ¨Åcient Œ± j L = Œ±I of eL
does not lie in m, and so 
L Œ± j LeL Ã∏= 0 in Mp‚àí1 (because the eLs form a basis of Mp‚àí1).
Under the isomorphism mMp‚àí1/m2Mp‚àí1 ‚Üí(m/m2) ‚äóR Mp‚àí1,
Dp(u) =
s

j=1
x‚àó
j ‚äó

L
Œ± j LeL,
where x‚àó
j = x j + m. Since x‚àó
i , . . . , x‚àó
s is a basis of m/m2, an element 
j x‚àó
j ‚äóv j = 0 if
and only if each v j = 0. Therefore, if u /‚ààmMp, then Dp(u + mMp) Ã∏= 0, and so Dp is
an injection.
‚Ä¢

1006
Commutative Rings III
Ch. 11
Proposition 11.188.
If (R, m, k) is a noetherian local ring of Ô¨Ånite global dimension
D(R), then
¬µ(m) ‚â§D(R).
Proof.
Let s = ¬µ(m), and let {x1, . . . , xs} be a minimal generating set of m. Then
rank(M(x1, . . . , xs)p) ‚â§rank(TorR
p(k, k)),
by Lemma 11.186. Now M(x1, . . . , xs)p = ;p(F), where F is the free R-module with
basis e1, . . . , es, so that rank(M(x1, . . . , xs)p) = rank(;p(F)) =
s
p

and
s
p
	
‚â§rank(TorR
p(k, k)).
Therefore, 1 ‚â§rank(TorR
s (k, k)), so that TorR
s (k, k) Ã∏= {0}. But Lemma 11.155 gives
pd(k) = max

p : TorR
p(k, k) Ã∏= {0}

,
so that s ‚â§pd(k) = D(R), by Corollary 11.156.
‚Ä¢
Theorem 11.189 (Serre).
A noetherian local ring R is regular if and only if D(R) is
Ô¨Ånite.
Proof.
In Lemma 11.176, the theorem was reduced to checking two inequalities. These
inequalities are proved in Corollary 11.182 and Proposition 11.188.
‚Ä¢
Corollary 11.190.
If R is a regular local ring, and it p is a prime ideal in R, then Rp is
also a regular local ring.
Proof.
Since p is a prime ideal, the localization Rp is a local ring; it is noetherian because
R is noetherian. In Proposition 11.154, we saw that D(R) ‚â•D(Rp). Therefore, Rp is a
regular local ring, by Serre's theorem.
‚Ä¢
We are now going to prove that every regular local ring is a UFD, and we begin with
several elementary lemmas.
Lemma 11.191.
If R is a noetherian domain, then R is a UFD if and only if every prime
ideal of height 1 is principal.
Proof.
Let R be a UFD, and let p be a prime ideal of height 1. If a ‚ààp is nonzero, then
a = pe1
1 ¬∑ ¬∑ ¬∑ pen
n , where the pi are irreducible and ei ‚â•1. Since p is prime, one of the
factors, say, p j ‚ààp. Of course, Rp j ‚äÜp. But Rp j is a prime ideal, by Proposition 6.17,
so that Rp j = p, because ht(p) = 1.
Conversely, since R is noetherian, Lemma 6.18 shows that every nonzero nonunit in
R is a product of irreducibles, and so Proposition 6.17 says that it sufÔ¨Åces to prove, for
every irreducible œÄ ‚ààR, that RœÄ is a prime ideal. Choose a prime ideal p that is minimal
over RœÄ. By the principal ideal theorem, Theorem 11.161, we have ht(p) = 1, and so the
hypothesis gives p = Ra for some a ‚ààR. Therefore, œÄ = ua for some u ‚ààR. Since œÄ is
irreducible, we must have u a unit, and so RœÄ = Ra = p, as desired.
‚Ä¢

Sec. 11.4
Regular Local Rings
1007
Lemma 11.192.
Let R be a noetherian domain, let x ‚ààR be a nonzero element with Rx
a prime ideal, and denote S‚àí1R by Rx, where S = {xn : n ‚â•0}. Then R is a UFD if and
only if Rx is a UFD.
Proof.
We leave necessity as an exercise for the reader. For sufÔ¨Åciency, assume that Rx
is a UFD. Let p be a prime ideal in R of height 1. If x ‚ààp, then Rx ‚äÜp and, since
ht(p) = 1, we have Rx = p (for Rx is prime), and so p is principal in this case. We
may now assume that x /‚ààp; that is, S ‚à©p = ‚àÖ. It follows that pRx is a prime ideal
in Rx of height 1, and so it is principal, by hypothesis. There is some a ‚ààp and n ‚â•0
with pRx = Rx(a/xn) = Rxa, for x is a unit in Rx. We may assume that a /‚ààRx. If
a = a1x and a1 /‚ààRx, then replace a by a1, for Rxa = Rxa1. If a1 = a2x and a2 /‚ààRx,
then replace a1 by a2, for Rxa1 = Rxa2. If this process does not stop, there are equations
am = am+1x for all m ‚â•1, which give rise to an ascending sequence Ra1 ‚äÜRa2 ‚äÜ¬∑ ¬∑ ¬∑ .
Since R is noetherian, Ram = Ram+1 for some m. Hence, am+1 = ram for some r ‚ààR,
and am = am+1x = ramx. Since R is a domain, 1 = rx; thus, x is a unit, contradicting
Rx being a prime (hence, proper) ideal. Clearly, Ra ‚äÜp; we claim that Ra = p. If b ‚ààp,
then b = (r/xm)a in Rx, where r ‚ààR and m ‚â•0. Hence, xmb = ra in R. Choose m
minimal. If m > 0, then ra = xmb ‚ààRx; since Rx is prime, either r ‚ààRx or a ‚ààRx.
But a /‚ààRx since S ‚à©p = ‚àÖ, so that r = xr‚Ä≤. As R is a domain, this gives r‚Ä≤a = xm‚àí1b,
contradicting the minimality of m. We conclude that m = 0, and so p = Ra is principal.
Lemma 11.191 now shows that R is a UFD.
‚Ä¢
The following elementary lemma is true when the localizing ideal is prime; however,
we will use it only in the case the ideal is maximal.
Lemma 11.193.
Let R be a domain, and let I be a nonzero projective ideal in R. If m is
a maximal ideal in R, then
Im ‚àº= Rm.
Proof.
Since I is a projective R-module, Im is a projective Rm-module. As Rm is a local
ring, however, Im is a free Rm-module. But Im is an ideal in a domain Rm, and so it must
be principal; that is, Im ‚àº= Rm.
‚Ä¢
Theorem 11.194 (Auslander-Buchsbaum).
Every regular local ring R is a UFD.
Proof. (Kaplansky) The proof is by induction on the Krull dimension dim(R), the cases
n = 0 (R is a Ô¨Åeld) and n = 1 (R is a DVR) being obvious (see Exercise 11.78 on
page 1012). For the inductive step, choose x ‚ààm ‚àím2. By Lemma 11.171, R/Rx is a
regular local ring with dim(R/Rx) < dim(R); by Proposition 11.172, R/Rx is a domain,
and so Rx is a prime ideal. It sufÔ¨Åces, by Lemma 11.192, to prove that Rx is a UFD (where
Rx = S‚àí1R for S = {xn : n ‚â•0}). Let P be a prime ideal of height 1 in Rx; we must
show that P is principal. DeÔ¨Åne p = P ‚à©R (since R is a domain, Rx ‚äÜFrac(R), so
that the intersection makes sense). Since R is a regular local ring, D(R) < ‚àû, and so the
R-module p has a free resolution of Ô¨Ånite length:
0 ‚ÜíFn ‚ÜíFn‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíF0 ‚Üíp ‚Üí0.

1008
Commutative Rings III
Ch. 11
Tensoring by Rx, which is a Ô¨Çat R-module (Theorem 11.28), gives a free Rx-resolution of
P (for P = Rxp):
0 ‚ÜíF‚Ä≤
n ‚ÜíF‚Ä≤
n‚àí1 ‚Üí¬∑ ¬∑ ¬∑ ‚ÜíF‚Ä≤
0 ‚ÜíP ‚Üí0,
(9)
where F‚Ä≤
i = Rx ‚äóR Fi.
We claim that P is projective. By Proposition 11.154, it sufÔ¨Åces to show that every
localization PM is projective, where M is a maximal ideal in Rx. Now (Rx)M is a local-
ization of R, and so it is a regular local ring, by Corollary 11.190; its dimension is smaller
than D(R), and so it is a UFD, by induction. Now PM, being a height 1 prime ideal in the
UFD (Rx)M, is principal. But principal ideals in a domain are free, hence projective, and
so PM is projective. Therefore, P is projective.
The exact sequence (9) "factors" into split short exact sequences. Since P is projective,
we have F‚Ä≤
0 ‚àº= P ‚äï$0, where $0 = ker(F‚Ä≤
0 ‚ÜíP). Thus, $0 is projective, being a
summand of a free module, and so F‚Ä≤
1 ‚àº= $1 ‚äï$0, where $1 = ker(F‚Ä≤
1 ‚ÜíF‚Ä≤
0). More
generally, F‚Ä≤
i ‚àº= $i ‚äï$i‚àí1 for all i ‚â•1. Hence,
F‚Ä≤
0 ‚äïF‚Ä≤
1 ‚äï¬∑ ¬∑ ¬∑ ‚äïF‚Ä≤
n ‚àº= (P ‚äï$0) ‚äï($1 ‚äï$0) ‚äï¬∑ ¬∑ ¬∑ .
Since projective modules over a local ring are free, we see that there are Ô¨Ånitely generated
free Rx-modules Q and Q‚Ä≤ with
Q ‚àº= P ‚äïQ‚Ä≤.
Recall that rank(Q) = dimK (K ‚äóRx Q), where K = Frac(Rx); now rank(P) = 1 and
rank(Q‚Ä≤) = r, say, so that rank(Q) = r + 1.
We must still show that P is principal. Now
<r+1(Q) ‚àº=
<r+1(P ‚äïQ‚Ä≤).
Since Q is free of rank r +1, Theorem 9.140, the binomial theorem, gives ;r+1(Q) ‚àº= Rx.
On the other hand, Theorem 9.143 gives
<r+1(P ‚äïQ‚Ä≤) ‚àº=
r+1

i=0
<i(P) ‚äóRx
<r+1‚àíi(Q‚Ä≤)

.
(10)
We claim that ;i(P) = {0} for all i > 1. By Lemma 11.193, we have PM ‚àº= (Rx)M for
every maximal ideal M in Rx. Now Exercise 11.24 on page 921 gives
<i(P)

M
‚àº=
<i(PM) ‚àº=
<i((Rx)M)
for all maximal ideals M and all i. But ;i((Rx)M) = {0} for all i > 1 (by the binomial
theorem or by the simpler Corollary 9.138), so that Proposition 11.31 gives ;i(P) = {0}
for all i > 1.

Sec. 11.4
Regular Local Rings
1009
We have just seen that most of the terms in (10) are {0}; what survives is:
<r+1(P ‚äïQ‚Ä≤) ‚àº=
<0(P) ‚äóRx
<r+1(Q‚Ä≤)

‚äï
<1(P) ‚äóRx
<r(Q‚Ä≤)

.
But ;r+1(Q‚Ä≤) = {0} and ;r(Q‚Ä≤) ‚àº= Rx, because Q‚Ä≤ is free of rank r.
Therefore,
;r+1(P ‚äïQ‚Ä≤) ‚àº= P. Since P ‚àº=
;r+1(P ‚äïQ‚Ä≤) ‚àº=
;r+1(Q) ‚àº= Rx, we have P ‚àº= Rx is
principal. Thus, Rx, and hence R, is a UFD.
‚Ä¢
Having studied localization, we turn, brieÔ¨Çy, to globalization, merely describing its set-
ting. To a given commutative noetherian ring R, we have associated a family of local rings
Rp, one for each prime ideal p. Local rings are simpler than general rings; for example, if
R is a Dedekind ring, its localizations are all principal ideal domains. Globalization asks
how we can make use of all the localizations to gather information. Consider the disjoint
union
E(R) =

p‚ààSpec(R)
Rp.
We call Rp the stalk of R over p, and we deÔ¨Åne the projection œÄ : E(R) ‚ÜíSpec(R) by
œÄ(e) = p if e ‚ààRp; that is, œÄ sends each point in the stalk over p into p.8 Each element
a ‚ààR deÔ¨Ånes a function sa : Spec(R) ‚ÜíE(R) by
sa : p ‚Üía/1 ‚ààRp.
Note that œÄsa = 1Spec(R). We claim that distinct elements a, b ‚ààR give different func-
tions; that is, if sa = sb, then a = b. Let I = R(a ‚àíb). If (a ‚àíb)/1 = 0 in Rp for every
prime ideal p, then Ip = {0} for every p. Proposition 11.31 applies to show that a = b (in
fact, this proposition only needs Im = {0} for all maximal ideals m). Thus, we can regard
the elements of any commutative ring R as E(R)-valued functions on Spec(R).
Consider the question, given f ‚ààRp and g ‚ààRq, whether there exists a ‚ààR with
f = a/1 ‚ààRp and g = a/1 ‚ààRq? That is, is there a ‚ààR with sa(p) = f and sa(q) = g?
A "good" answer might be if p and q are "close" to each other, then such an element a ‚ààR
exists. This suggests that a topology on X = Spec(R) may be of interest, and the Zariski
topology is a good candidate (a subset F ‚äÜSpec(R) is closed if q ‚ààF implies p ‚ààF
whenever p is a prime ideal with q ‚äÜp). Of course, once we decide on a topology for
Spec(R), we expect that E(R) should also be topologized, and that interesting functions
should be continuous.
The Zariski topology is much different from the topology on euclidean space. Not
only is it not a metric space (that is, no distance between two points is deÔ¨Åned), one-point
subsets need not be closed sets; for example, {p} is closed if and only if p is a maximal
ideal. In spite of this, continuity of a function f : X ‚ÜíY can still be deÔ¨Åned: f is
continuous if f ‚àí1(V ) is an open subset of X for every open subset V ‚äÜY. Equivalently,
f is continuous if and only if, for every closed subset C in Y, the subset f ‚àí1(C) is a
8There is a possible source of confusion, for p can be viewed in two ways: as a prime ideal‚Äîa subset of
R; as a point in Spec(R). To distinguish these viewpoints, we often write px to denote p viewed as a point of
X = Spec(R). Thus, the projection œÄ is deÔ¨Åned by œÄ(e) = px for all e ‚ààRp.

1010
Commutative Rings III
Ch. 11
closed subset of X. Similarly, we can deÔ¨Åne the notions of compactness (if {Fi : i ‚ààI is
a family of closed subsets, then there are Ô¨Ånitely many of them, say, Fi1, . . . , Fin such that

i‚ààI Fi = n
j=1 Fi j ) and connectedness (not the union of two nonempty disjoint closed
subsets) for arbitrary topological spaces.
Let us mention an elementary gluing result. Suppose that X and Y are topological
spaces, that {Ui : i ‚ààI} is a family of open subsets of X, and that { fi : Ui ‚ÜíY} is a
family of continuous functions. If the functions agree on overlaps; that is, if fi|(Ui ‚à©U j) =
f j|(Ui ‚à©U j) for all i, j ‚ààI, then there is a unique continuous function f : !
i Ui ‚ÜíY
with f |Ui = fi for all i. Does this remind you of a direct limit?
Here is the formal deÔ¨Ånition of a sheaf from this viewpoint; there is also a second,
equivalent, version using presheaves (introduced in Chapter 7) that we will describe after-
ward.
DeÔ¨Ånition.
If E and X be topological spaces, and let œÄ : E ‚ÜíX be a continuous surjec-
tion. Then F = (E, X, œÄ) is a sheaf of abelian groups if
(i) œÄ is a local homeomorphism: for each e ‚ààE, there is an open set U containing e
such that œÄ(U) is an open subset of X and œÄ|U is a homeomorphism9 from U to
œÄ(U).
(ii) The subsets Fx = œÄ‚àí1(x) of E, for x ‚ààX, are called the stalks of F, and each Fx
is an abelian group.
(iii) If E + E is the subset of E √ó E consisting of all (a, b) with œÄ(a) = œÄ(b), then the
maps E + E ‚ÜíE, given by (a, b) ‚Üía + b and (a, b) ‚Üía ‚àíb, are continuous.
Ignoring the algebraic structure on the stalks, the reader may recognize the basic ingre-
dients present in covering spaces, for example.
Recalling the functions sa : Spec(R) ‚ÜíE(R) mentioned above, we see that the fol-
lowing notion is of interest.
DeÔ¨Ånition.
If F = (E, X, œÄ) is a sheaf of abelian groups, and if U is an open subset of
X, then a section over U is a continuous function s : U ‚ÜíE with œÄs = 1U. We write
!(U, F) = {all sections s : U ‚ÜíE}.
A global section is a section in !(X, F).
It is easy to check that !(U, F) is an abelian group. If V ‚äÜU are open subsets of X,
then there is a restriction map
œÅU
V : !(U, F) ‚Üí!(V, F),
given by s ‚Üís|V . Moreover, the functions œÅU
V are homomorphisms.
9A homeomorphism is a bijection f : X ‚ÜíY, where X and Y are topological spaces, such that both f and
f ‚àí1 are continuous.

Sec. 11.4
Regular Local Rings
1011
For Ô¨Åxed x ‚ààX, let
I (x) = {open sets U ‚äÜX containing x}.
It is easy to see that I (x) is a partially ordered set under reverse inclusion:
U ‚™ØV means U ‚äáV.
In fact, I (x) is a directed index set, for given U, V ‚ààI (x), then U ‚à©V ‚ààI (x), U ‚à©V ‚äÜU,
and U ‚à©V ‚äÜV ; that is, U ‚™ØU ‚à©V and V ‚™ØU ‚à©V . We can recapture the stalks from
the sections. Let F = (E, X, œÄ) be a sheaf of abelian groups. For each x ‚ààX,
Fx ‚àº=
lim
‚àí‚Üí
U‚ààI (x)
!(U, F).
If X is a topological space, then the family of its open sets, with inclusion maps of
subsets as morphisms, is a category; denote it by Open(X). We may now deÔ¨Åne a presheaf
of abelian groups. In fact, there are presheaves with values in any category, say, modules
or commutative rings, not just Ab.
DeÔ¨Ånition.
If X is a topological space and C is a category, then a presheaf over X with
values in C is a contravariant functor F : Open(X) ‚ÜíC.
A sheaf can be reconstructed from its presheaf of sections if we further assume a version
of the gluing result mentioned above.
Given a commutative ring R, sheaves of R-modules are deÔ¨Åned whose stalks are Rp-
modules for p ‚ààSpec(R). These form an abelian category with enough injectives; that is,
every sheaf can be imbedded as a subsheaf of an injective sheaf. Moreover, global sections
!(X, ) is a left exact functor, and cohomology of sheaves is deÔ¨Åned as derived functors of
!(X, ). These cohomology groups provide the most important method of globalizing. We
recommend the article by J.-P. Serre, Faisceaux Alg`ebriques Coh¬¥erents, Annals of Math.
(61) 1955, pages 197-278, for a lucid discussion.
EXERCISES
11.75 Let R = k[x, y, z], where k is a Ô¨Åeld.
(i) Prove that x, y(1 ‚àíx), z(1 ‚àíx) is an R-sequence.
(ii) Prove that y(1 ‚àíx), z(1 ‚àíx), x is not an R-sequence.
11.76 Let R be a commutative ring. Prove that a prime ideal p in R is minimal over an ideal I if and
only if ht(p/I) = 0 in R/I.
11.77 If (R, m, k) is a noetherian local ring, and if B is a Ô¨Ånitely generated R-module, prove that
depth(B) = min

i : Exti
R(k, B) Ã∏= {0}

.

1012
Commutative Rings III
Ch. 11
11.78 Let R be a regular local ring.
(i) Prove that R is a Ô¨Åeld if and only if dim(R) = 0.
(ii) Prove that R is a DVR if and only if dim(R) = 1.
11.79
(i) Let (R, m) be a noetherian local ring, and let x ‚ààR be a regular element; i.e., x is not a
zero divisor. If x1 + (x), . . . , xs + (x) is an (R/(x))-sequence, prove that x, x1, . . . , xs
is an R-sequence.
(ii) Let R be a commutative ring. If x1, . . . , xd is an R-sequence, prove that the cosets
x2 + (x1), . . . , xd + (x1) form an (R/(x1))-sequence.
11.80 Let R be a noetherian (commutative) ring with Jacobson radical J = J(R). If B is a Ô¨Ånitely
generated R-module, prove that
"
n‚â•1
Jn B = {0}.
Conclude that if (R, m) is a noetherian local ring, then 
n‚â•1 mn B = {0}.
Hint. Let D = 
n‚â•1 Jn B, observe that J D = D, and use Nakayama's lemma.
11.81 Use the Rees lemma to prove a weaker version of Proposition 11.175: If (R, m) is a regular
local ring, then D(R) ‚â•¬µ(m) = dim(R).
Hint. If Extd
R(k, R) Ã∏= {0}, then D(R) > d ‚àí1; that is, D(R) ‚â•d.
Let m = (x1, . . . , xd), where x1, . . . , xd is an R-sequence. Then
Extd
R(k, R) ‚àº= Extd‚àí1
R/(x1)(k, R/(x1))
‚àº= Extd‚àí2
R/(x1,x2)(k, R/(x1, x2)) ‚àº= ¬∑ ¬∑ ¬∑
‚àº= Ext0
k(k, k) ‚àº= Homk(k, k) ‚àº= k Ã∏= {0}.
11.82 Let R be a commutative ring, let M be a Ô¨Ånitely generated R-module, and let I be an ideal
such that I M Ã∏= M.
(i) If x1, x2, . . . , xn is an M-sequence contained in I, prove that
(x1) ‚ää(x1, x2) ‚ää¬∑ ¬∑ ¬∑ ‚ää(x1, . . . , xn).
(ii) If R is noetherian, prove that there is a longest M-sequence contained in I.
11.83 If k is a Ô¨Åeld, prove that k[[x1, . . . , xn]] is noetherian.
Hint.
DeÔ¨Åne the order o( f ) of a nonzero formal power series f = ( f0, f1, f2, . . .) to be
the smallest n with fn Ã∏= 0. Find a proof similar to that of the Hilbert basis theorem. (See
Zariski-Samuel, Commutative Algebra II, page 138.)
11.84 If k is a Ô¨Åeld, prove that the ring of formal power series k[[x1, . . . , xn]] is a UFD.

Appendix
The Axiom of Choice and Zorn's
Lemma
Nowadays, most mathematicians accept the axiomatization ZFC of set theory, due to E.
Zermelo and A. Fraenkel; the letter C abbreviates choice. Using consequences of this
axiomatization, we will prove the equivalence of the axiom of choice, the well-ordering
principle, and Zorn's lemma. Let us begin by recalling some deÔ¨Ånitions from Chapter 6.
DeÔ¨Ånition.
If A is a set, let P(A)# denote the family of all its nonempty subsets. The
axiom of choice states that if A is a nonempty set, then there exists a function Œ≤ : P(A)# ‚Üí
A with Œ≤(S) ‚ààS for every nonempty subset S of A. Such a function Œ≤ is called a choice
function.
Informally, the axiom of choice is a harmless looking statement; it says that we can
simultaneously choose one element from each nonempty subset of a set. We now show
that the axiom of choice is equivalent to a statement we would hate to be false.
Proposition A.1.
The axiom of choice holds if and only if the cartesian product 
i‚ààI Xi
of nonempty sets is itself nonempty.1
Proof.
Let us assume the axiom of choice. Recall that an element of 
i‚ààI Xi is an I-tuple
x = (xi) with xi ‚ààXi for all i ‚ààI. Now an I-tuple is really a function
f : I ‚ÜíA =

i‚ààI
Xi
with f (i) = xi ‚ààXi for all i ‚ààI. DeÔ¨Åne œï : I ‚ÜíP(A)# by œï(i) = Xi. If Œ≤ : P(A)# ‚Üí
A is a choice function, then the composite f = Œ≤ ‚ó¶œï : I ‚ÜíA satisÔ¨Åes f (i) = Œ≤(œï(i)) =
Œ≤(Xi) ‚ààXi, and so it is an element of 
i‚ààI Xi. Therefore, the cartesian product is
nonempty.
Conversely, let A be a nonempty set. DeÔ¨Åne I = P(A)#, and consider 
S‚ààI S. By
hypothesis, this product is nonempty, and so it contains an element Œ≤, where Œ≤(S) ‚ààS
1By deÔ¨Ånition, a set X is nonempty if there is an element x ‚ààX. If X1 Ã∏= ‚àÖand X2 Ã∏= ‚àÖ, then there is
x1 ‚ààX1 and x2 ‚ààX2, and hence (x1, x2) ‚ààX1 √ó X2; that is, X1 √ó X2 Ã∏= ‚àÖ. More generally, we can prove, by
induction, that if the index set I = {1, 2, . . . , n} is Ô¨Ånite, then 
i‚ààI Xi = X1 √ó ¬∑ ¬∑ ¬∑ √ó Xn Ã∏= ‚àÖ. Thus, the axiom
of choice is signiÔ¨Åcant only when the index set I is inÔ¨Ånite.
A-1

A-2
The Axiom of Choice and Zorn's Lemma
Appendix
for all S ‚ààP(A)#; that is, Œ≤ is a choice function for A. Therefore, the axiom of choice
holds.
‚Ä¢
There are various equivalent forms of the axiom of choice that are more convenient to
use, the most popular of which are the well-ordering principle and Zorn's lemma, which we
state after some preliminary deÔ¨Ånitions. Most mathematicians accept the axiom of choice
(as do we), and so they also accept these equivalent forms as well.
Recall that a set X is a partially ordered set if there is a relation x ‚™Øy deÔ¨Åned on X
that is reÔ¨Çexive, antisymmetric, and transitive.
If it is necessary to display the ordering relation, we may also say that (X, ‚™Ø) is a
partially ordered set.
DeÔ¨Ånition.
A partially ordered set X is well-ordered if every nonempty subset S of X
contains a smallest element; that is, there is s0 ‚ààS with
s0 ‚™Øs for all s ‚ààS.
A partially ordered set X is a chain if any two elements are comparable; that is, for all
x, y ‚ààX, either x ‚™Øy or y ‚™Øx.
Example A.2.
(i) The least integer axiom in Chapter 1 says that N, the natural numbers, is well-ordered.
More generally, N n equipped with a monomial order, deÔ¨Åned in Chapter 6, is a well-
ordered set.
(ii) The empty set ‚àÖis well-ordered; otherwise, ‚àÖwould contain a nonempty subset (with-
out a smallest element), and this is a contradiction.
(iii) The integers Z is not well-ordered, for there is no smallest integer.
(iv) The subset X of Q, deÔ¨Åned by
X = {1 ‚àí1
n : n ‚â•1} ‚à™{2 ‚àí1
n : n ‚â•1}
is well-ordered. Note that 1 = 2 ‚àí1
1 has inÔ¨Ånitely many predecessors.
(v) Let X be a well-ordered set. An element œÑ ‚ààX is a top element if there is no Œ± ‚ààX
with œÑ ‚â∫Œ±. If Œ± ‚ààX is not the top element of X (should one exist), then XŒ± = {Œ≤ ‚ààX :
Œ± ‚â∫Œ≤} Ã∏= ‚àÖ, and so it has a smallest element Œ±‚Ä≤, called the successor of Œ±. The successor
Œ±‚Ä≤ is the "next" element after Œ±: formally, Œ± ‚â∫Œ±‚Ä≤ and there is no Œ≤ ‚ààX with Œ± ‚â∫Œ≤ ‚â∫Œ±‚Ä≤
(if there were such a Œ≤, then Œ≤ ‚ààXŒ± and so Œ±‚Ä≤ ‚™ØŒ≤). An element Œ≤ ‚ààX is a limit if it
is not a successor; that is, there is no Œ± ‚ààX with Œ≤ = Œ±‚Ä≤. The smallest element is X is a
limit; in part (iv), we saw that X = {1 ‚àí1
n : n ‚â•1} ‚à™{2 ‚àí1
n : n ‚â•1} is well-ordered,
and it is clear that 1 = 2 ‚àí1
1 is a limit in X. Thus, every element in X is either a successor
or a limit.
‚óÄ
Here are some basic properties of well-ordered sets.

The Axiom of Choice and Zorn's Lemma
Appendix
A-3
Proposition A.3.
(i) Every subset Y of a well-ordered set X is itself well-ordered.
(ii) Let X be a well-ordered set. If x, y ‚ààX, then either x ‚™Øy or y ‚™Øx.
(iii) If X is a well-ordered set, then every strictly decreasing sequence x1 ‚âªx2 ‚âª¬∑ ¬∑ ¬∑ in
X is Ô¨Ånite.
(iv) Assuming the axiom of choice, the converse of part (iii) is true. If X is a chain in
which every strictly decreasing sequence x1 ‚âªx2 ‚âª¬∑ ¬∑ ¬∑ in X is Ô¨Ånite, then X is
well-ordered.
Proof.
(i) If S is a nonempty subset of Y, then it is also a subset of X and, as any nonempty
subset of X, it contains a smallest element. Therefore, Y is well-ordered.
(ii) The subset S = {x, y} has a smallest element, which is either x or y. In the Ô¨Årst case,
x ‚™Øy, and in the second case, y ‚™Øx.
(iii) If X is well-ordered, then S = {x1, x2, . . .} has a smallest element, say, xi; that is,
xn ‚™∞xi for all n ‚â•1. In particular, if n = i + 1, then xi+1 ‚™∞xi, which contradicts
xi ‚âªxi+1.
(iv) Assume that there exists a nonempty subset S of X that has no smallest element.
Choose s0 ‚ààS; since s0 is not smallest, it is not true that s0 ‚™Øs for all s ‚ààS. Thus,
either there exists s1 ‚ààS with s0 ‚âªs1 or there is s ‚ààS with s0 and s not comparable;
the latter cannot occur because X is a chain. Similarly, there is s2 ‚ààS with s1 ‚âªs2. By
induction, for all n ‚â•0, there are elements si ‚ààS with s0 ‚âªs1 ¬∑ ¬∑ ¬∑ ‚âªsn ‚âªsn+1. We want
to assemble these inÔ¨Ånitely many choices, one for each n, into one descending sequence2;
that is, we want a function f : N ‚ÜíS with f (n) = sn. Here is the formal way to do this.
Let F be the family of all functions g from all initial segments {0, 1, . . . , n} ‚ÜíS, and let
Œ≤ be a choice function on F: that is, Œ≤(T ) ‚ààT for every nonempty subset T ‚äÜF. We use
Œ≤ to construct the desired sequence. Choose an element s0 ‚ààS, which is possible because
S Ã∏= ‚àÖ. DeÔ¨Åne F0 = {g ‚ààF : domain(g) = {0} and g(0) = s0}) (there is only one g in
F0), and deÔ¨Åne g0 = Œ≤(F0) . For n > 0, we know, by induction, that Fn+1 Ã∏= ‚àÖ, where
Fn+1 =

g : {0, 1, . . . , n + 1} ‚ÜíX : g
{0, . . . , n} = gn and g(n) ‚âªg(n + 1)

.
Therefore, we may deÔ¨Åne gn+1 = Œ≤(Fn+1). Finally, deÔ¨Åne g‚àóto be the union of the gn;
that is, g‚àó(n) = gn(n) for all n. The function g‚àóis a strictly descending sequence in S, and
this contradicts the hypothesis that every strictly decreasing sequence in S is Ô¨Ånite.
‚Ä¢
Well-ordering Principle.
Every set X has some well-ordering of its elements.
2We have already done this, without comment, in Proposition 6.38, when we showed that ACC implies the
maximum condition. Actually, the proof only uses a weaker form of the axiom of choice in which the index set
is countable.

A-4
The Axiom of Choice and Zorn's Lemma
Appendix
If X happens to be a partially ordered set, then a well-ordering, whose existence is
asserted by the well-ordering principle, may have nothing to do with the original partial
ordering. For example, Z can be well-ordered:
0 ‚™Ø1 ‚™Ø‚àí1 ‚™Ø2 ‚™Ø‚àí2 ‚™Ø¬∑ ¬∑ ¬∑ .
That N is well-ordered is just another way of stating mathematical induction. Thus,
the well-ordering principle suggests the possibility of a generalized induction that applies
to a collection of statements indexed by a well-ordered set of any, possibly uncountable,
cardinality. Such a generalization does, in fact, exist, and it is called transÔ¨Ånite induction.
Let {S(Œ±) : Œ± ‚ààI} be a family of statements indexed by a well-ordered set I. If Œ±0 is the
smallest index in I, then the base step is the statement that S(Œ±0) is true. The inductive
step is the statement that if Œ≤ is an index and S(Œ±) is true for all Œ± ‚â∫Œ≤, then S(Œ≤) is
true. TransÔ¨Ånite induction says that if the base step and the inductive step hold, then all
the statements S(Œ±) are true. (Often, the proof of the inductive step splits into two cases,
depending on whether Œ≤ is a successor or a limit). Here is a surprising use of transÔ¨Ånite
induction: There exists a subset Q of the plane that intersects every straight line in exactly
two points. The idea of the proof is to construct Q by well-ordering the set of all the lines
in the plane in such a way that every line has only countably many predecessors. Now,
from each line in turn, judiciously select at most two of its points to put into Q.
We will be able to state Zorn's lemma after the following deÔ¨Ånitions.
DeÔ¨Ånition.
Let X be a partially ordered set. An upper bound of a subset S of X is an
element x ‚ààX, not necessarily in S, such that
s ‚™Øx for all s ‚ààS.
An element m ‚ààX is a maximal element if there is no x ‚ààX for which m ‚â∫x; that is, if
x ‚ààX and if m ‚™Øx, then m = x.
A partially ordered set may have no maximal elements: for example, R, with its usual
ordering, is a chain having no maximal elements. A partially ordered set may have many
maximal elements: for example, if X is the partially ordered set of all the proper subsets of
a set U, then a subset S is a maximal element if and only if S = U ‚àí{u} for some u ‚ààU;
that is, S is the complement of a point.
Zorn's lemma is a criterion that guarantees the existence of maximal elements.
Zorn's lemma.
If X is a nonempty partially ordered set in which every chain has an
upper bound, then X has a maximal element.
Theorem A.4.
The following statements are equivalent.
(i) Zorn's lemma.
(ii) The well-ordering principle.
(iii) The axiom of choice.

The Axiom of Choice and Zorn's Lemma
Appendix
A-5
We split Theorem A.4 into three separate theorems. Let us begin with a deÔ¨Ånition and
a lemma.
DeÔ¨Ånition.
If X is a well-ordered set and c ‚ààX, then the open segment Seg(c) is the
subset
Seg(c) = {x ‚ààX : x ‚â∫c}.
The next result supplements Proposition A.3.
Lemma A.5.
A chain X is well-ordered if and only if every open segment of X is well-
ordered.
Proof.
Necessity is obvious, for every subset of a well-ordered set is well-ordered. Con-
versely, let S be a nonempty subset of X. Of course, if S is a singleton, then it contains
a smallest element, and so we may assume that S contains at least two elements, say, c‚Ä≤
and c. Since X is a chain, we may assume that c‚Ä≤ ‚â∫c. Hence, Seg(c) ‚à©S Ã∏= ‚àÖ; as every
nonempty subset of a well-ordered set is well-ordered, there is a smallest element, say, z,
in Seg(c) ‚à©S. Now z is the smallest element in S, for if there is s‚Ä≤ ‚ààS with s‚Ä≤ ‚â∫z, then
s‚Ä≤ ‚ààSeg(c) ‚à©S, contradicting z being the smallest element in Seg(c) ‚à©S. Therefore, X is
well-ordered.
‚Ä¢
In general, an ascending union of well-ordered subsets of a partially ordered set need
not be well-ordered. For example, it is easy to see that for every positive integer n, the
subset
Sn = {m ‚ààZ : m ‚â•‚àín}
is a well-ordered subset of Z, but !
n Sn = Z is not well-ordered.
With an extra assumption, we can force a union of well-ordered subsets to be well-
ordered.
Notation.
If B and C are subsets of a partially ordered set X, then we write
B ‚ä¥C
if either B = C or B is an open segment of C; that is, there exists c ‚ààC with B = Seg(c).
Lemma A.6.
Let (X, ‚™Ø) be a partially ordered set, and let {Si : i ‚ààI} be a family
of well-ordered subsets of X indexed by some set I. If, for each i, j, either Si ‚ä¥Sj or
Sj ‚ä¥Si, then !
i‚ààI Si is a well-ordered subset of X.
Proof.
Let U = !
i Si. By Lemma A.5, it sufÔ¨Åces to show that any open segment Seg(c),
where c ‚ààU, is well-ordered. Now c ‚ààSi for some i; since Si is well-ordered, so is any
of its subsets; thus, it sufÔ¨Åces to show that Seg(c) = {x ‚ààU : u ‚â∫c} ‚äÜSi; that is, if
u ‚â∫c, we must show that u ‚ààSi. Now u ‚ààSj for some j. If Sj ‚ä¥Si, then u ‚ààSi and we
are done. If Si ‚ä¥Sj, then Si ‚äÜSj, so that c ‚ààSj; moreover, since Si is an open segment
of Sj, u ‚â∫c implies u ‚ààSi, as desired.
‚Ä¢

A-6
The Axiom of Choice and Zorn's Lemma
Appendix
DeÔ¨Ånition.
A subset A of a well-ordered set (X, ‚™Ø) is closed in X if A Ã∏= ‚àÖand if x ‚™Øa,
where x ‚ààX and a ‚ààA, implies x ‚ààA. (Thus, if A is closed and a ‚ààA, then A contains
everything smaller than a as well.)
Given a well-ordered set X and c ‚ààX, it is obvious that the "closed segment"
A = {x ‚ààX : x ‚™Øc}
is a closed subset. If c is the top element of X (should such exist), then A = X; if c is not a
top element, then it has a successor c‚Ä≤, and A = Seg(c‚Ä≤). Thus, closed segments are closed
subsets, but they are nothing new.
Lemma A.7.
If (X, ‚™Ø) is a well-ordered set, then A is closed in X if and only if A ‚ä¥X;
that is, either A = X or A = Seg(c) for some c ‚ààX.
Proof.
It is clear that open segments are closed, and so only necessity needs proof.
Assume that A is closed; we must show that if A Ã∏= X, then A is an open segment. Since
X is well-ordered, there is a smallest element c ‚ààX ‚àíA, and we claim that A = Seg(c).
If there is some a ‚ààA with c ‚™Øa, then c ‚ààA, because A is closed, and this contradicts
c /‚ààA. Therefore, a ‚â∫c for all a ‚ààA (we are using the fact that well-ordered sets are
chains); that is, c is an upper bound of A, and so A ‚äÜSeg(c). For the reverse inclusion,
suppose that x ‚ààSeg(c); that is, x ‚â∫c. If x /‚ààA, then x ‚ààX ‚àíA, and so c ‚™Øx, a
contradiction.
‚Ä¢
Here is the Ô¨Årst step of Theorem A.4. .
Theorem A.8.
If Zorn's lemma holds, then the well-ordering principle holds: every set
X can be well-ordered.
Proof.
Since ‚àÖis well-ordered, we may assume that X Ã∏= ‚àÖ. Let L be the family of all
the well-ordered subsets of X; more precisely, an element of L is an ordered pair (S, ‚äë)
consisting of a subset S of X together with some well-ordering ‚äëof it. Thus, a subset S of
X may appear several times in L, equipped with different well-orderings. We now make L
into a partially ordered set. DeÔ¨Åne
(S, ‚äë) ‚™Ø(S‚Ä≤, ‚äë‚Ä≤)
to mean either (i) S = S‚Ä≤ and ‚äë= ‚äë‚Ä≤ or (ii) S ‚ääS‚Ä≤, the orderings coincide on S (that is, if
a, b ‚ààS, then a ‚äëb holds if and only if a ‚äë‚Ä≤ b holds), and S is an open segment of S‚Ä≤.
We now show that L satisÔ¨Åes the hypothesis of Zorn's lemma. Note that L Ã∏= ‚àÖ, for
any 1-point subset is a well-ordered subset, and so it gives an element of L. Let C =
{(Si, ‚™Øi) : i ‚ààI} be a chain in L; that is, for each i, j, either (Si, ‚äëi) ‚™Ø(Sj, ‚äëj) or
(Sj, ‚äëj) ‚™Ø(Si, ‚äëi). DeÔ¨Åne U = !
i Si, and deÔ¨Åne a partial order ‚äëon U as follows.
If u, v ‚ààU, then there are indices i and j with u ‚ààSi and v ‚ààSj; we may assume
that (Si, ‚äëi) ‚™Ø(Sj, ‚äëj), so that both u, v ‚ààSj, and we deÔ¨Åne u ‚äëv if u ‚äëj v. This
deÔ¨Ånition does not depend on the choice of indices, for if there are indices k and ‚Ñìwith
u ‚ààSk and v ‚ààS‚Ñì, then (Sk, ‚äëk) ‚™Ø(S‚Ñì, ‚äë‚Ñì), say, and u ‚äë‚Ñìv is a competing deÔ¨Ånition.

The Axiom of Choice and Zorn's Lemma
Appendix
A-7
But (Sj, ‚äëj) ‚™Ø(S‚Ñì, ‚äë‚Ñì), and so u ‚äëj v if and only if u ‚äë‚Ñìv. It is now routine to prove
that (U, ‚äë) is a partially ordered set. In fact, (U, ‚äë) is well-ordered, by Lemma A.6, and
so (U, ‚äë) ‚ààL. Furthermore, we claim that each (Si, ‚äëi) is closed in (U, ‚äë). Suppose
that u ‚äësi, where si ‚ààSi and u ‚ààU. Now u ‚ààSj for some j; if (Sj, ‚äëj) ‚™Ø(Si, ‚äëi),
then u ‚ààSi as desired; if (Si, ‚äëi) ‚™Ø(Sj, ‚äëj), then Si is closed in Sj, and so u ‚ààSi.
Lemma A.7 now gives (Si, ‚äëi) ‚™Ø(U, ‚äë) for all i; that is, (U, ‚äë) is an upper bound of C.
By Zorn's lemma, L has a maximal element, say (M, ‚â§). If M contains every element
of X, then X can be well-ordered. If there is some x ‚ààX with x /‚ààM, then deÔ¨Åne a well-
ordering ‚â§‚Ä≤ of M‚à™{x} extending the given well-ordering of M by deÔ¨Åning m <‚Ä≤ x for every
m ‚ààM. Since M = Seg(x) in M ‚à™{x}, we have (M, ‚â§) ‚â∫(M ‚à™{x}, ‚â§‚Ä≤), contradicting
the maximality of (M, ‚â§). Therefore, M = X and X can be well-ordered.
‚Ä¢
Almost all proofs involving Zorn's lemma have the same format: deÔ¨Åne an appropriate
nonempty partially ordered set; show that its chains have upper bounds; show that a max-
imal element, whose existence is guaranteed by Zorn's lemma, can be used to prove the
theorem (this last step is usually an indirect proof).
Here is a small comment about the axiom of choice before we present the second step in
the proof of Theorem A.4. Given sets A and X, one way to deÔ¨Åne a function f : A ‚ÜíX is
to specify its values. For example, there exists a function f : N ‚ÜíN with f (n) = n+1 for
each n ‚ààN. Not every function is given by a formula, however, and the axiom of choice
deals with the problem of when a function is actually deÔ¨Åned. If {Ga : a ‚ààA} is a family
of groups, then we may deÔ¨Åne a choice function f : A ‚Üí!
a Ga by f (a) = 1a, where 1a
is the identity element of Ga; we do not need the axiom of choice to deÔ¨Åne f . In contrast,
if we merely "choose" some element xa ‚ààGa, then the "function" h : A ‚Üí!
a Ga with
h(a) = xa is not well-deÔ¨Åned. Such a "function" h ought not be a bona Ô¨Åde function. How
could one possibly detect any properties of h; for example, is h an injection?
Theorem A.9.
The well-ordering principle implies the axiom of choice.
Proof.
Let A be a nonempty set. We may assume that A has some well-ordering of its
elements, and it follows that every nonempty subset of A is also well-ordered. DeÔ¨Åne a
choice function Œ≤ : P(A)# ‚ÜíA by deÔ¨Åning, for each nonempty subset S of A, Œ≤(S) to be
the smallest element of S.
‚Ä¢
Daniel Grayson has shown me an elegant proof that the axiom of choice implies Zorn's
lemma; it is a variant of a proof of E. Zermelo in 1904, as adapted by H. Kneser in 1950.
Theorem A.10.
The axiom of choice implies Zorn's lemma.
Proof.
Assume that X has no maximal elements. If A is a well-ordered subset of X, then
A is a chain, and hence A has an upper bound, say x. Since x is not a maximal element,
there exists y ‚ààX with x ‚â∫y; it follows that every well-ordered subset A has an upper
bound that is not in A. Let W denote the family of all the well-ordered subsets of X. For
each A ‚ààW, deÔ¨Åne
UA = {all upper bounds u of A with u /‚ààA};

A-8
The Axiom of Choice and Zorn's Lemma
Appendix
each UA Ã∏= ‚àÖ, by hypothesis, and so Proposition A.1 says there is some g in 
A‚ààW UA.
Thus, for all A ‚ààW, we have g(A) an upper bound of A and g(A) /‚ààA.
We use g to construct some special well-ordered subsets. DeÔ¨Åne an element c0 ‚ààX by
c0 = g(‚àÖ). Call a well-ordered subset C of X a g-set if c is the upper bound of C ‚à©Seg(c)
chosen by g;3 that is, c0 ‚ààC and c = g(C ‚à©Seg(c)) for every c ‚ààC.
We are going to show that the union of all the g-sets is itself a g-set, and this will then
be shown to give a contradiction.
If C and D are g-sets, we claim that either C ‚ä¥D or D ‚ä¥C. DeÔ¨Åne W to be the union
of all those subsets B with B ‚ä¥C and B ‚ä¥D. We claim that W ‚ä¥C and W ‚ä¥D; that is,
W is closed in C and in D. Take w ‚ààW; this element got into W because it lies in some
B, where B ‚ä¥C and B ‚ä¥D. If c ‚ààC and c ‚™Øw, then c ‚ààB (because B is closed in C).
Hence, c ‚ààB ‚äÜW (for W is, by deÔ¨Ånition, the union of all such subsets B). Therefore, W
is closed in C. Similarly, W is closed in D. If either W = C or W = D, then the claim is
true. Hence, we may assume that W ‚úÅC [so that W = C ‚à©Seg(c‚Ä≤) for some c‚Ä≤ ‚ààC ‚àíW],
and W ‚úÅD [so that W = D ‚à©Seg(d‚Ä≤) for some d‚Ä≤ ‚ààD ‚àíW]. Since C and D are g-sets,
c‚Ä≤ = g(C ‚à©Seg(c‚Ä≤)) = g(W) and d‚Ä≤ = g(D ‚à©Seg(d‚Ä≤)) = g(W). Therefore, c‚Ä≤ = d‚Ä≤.
But now W ‚à™{c‚Ä≤} = W ‚à™{c‚Ä≤} is closed in C and in D, for it is a closed interval. Thus,
W ‚à™{c‚Ä≤} ‚äÜW, contradicting c‚Ä≤ /‚ààW. Therefore, either W = C or W = D; that is, either
C ‚ä¥D or D ‚ä¥C, as claimed.
Finally, let $ be the union of all the g-sets. The just-established claim shows that the
hypothesis of Lemma A.6 is satisÔ¨Åed, and so $ is a well-ordered subset. Let us show that
$ is itself a g-set. If c ‚àà$, then there is some g-set C containing c, and c = g(C‚à©Seg(c)).
But C ‚ä¥$, by Lemma A.7 and the fact just proved above that either C ‚ä¥$ or $ ‚ä¥C;
hence, C ‚à©Seg(c) = $ ‚à©Seg(c). Therefore, c = g($ ‚à©Seg(c)), and $ is a g-set. On the
other hand, $‚Ä≤ = $ ‚à™{g($)} is a g-set not contained in $, and this is a contradiction. We
conclude that no such function g can exist, and hence that X has a maximal element.
‚Ä¢
It appears that we have used a weaker hypothesis than that of Zorn's lemma: only well-
ordered subsets need upper bounds. However, it is shown in Exercise 6.45 on page 374
that every chain C in a partially ordered set contains a well-ordered subset W such that C
and W have the same upper bounds. Hence, if all well-ordered subsets have upper bounds,
then all chains have upper bounds as well.
If B = C, then W = C; otherwise, B is an open segment of C, and so there is b ‚ààC
with B = Seg(b). If B‚Ä≤ is also a proper subset of C, then B‚Ä≤ = Seg(b‚Ä≤). We may assume
that b ‚™Øb‚Ä≤, and so B ‚ä¥B‚Ä≤. It now follows from Lemma A.7 that W ‚ä¥C.
3Each of the following sets are g-sets. If c1 = g({c0}), deÔ¨Åne c2 = g({c0, c1}), and, by induction, cn+1 =
g({c0, . . . , cn}). Note that c0 ‚â∫c1 ‚â∫c2 ‚â∫¬∑ ¬∑ ¬∑ . Each subset {c0, c1, . . . , cn} is a g-set. There are inÔ¨Ånite g-sets
as well. For example, if C‚Ä≤ = {cn : n ‚ààN}, let c‚Ä≤ = g(C‚Ä≤), and deÔ¨Åne C‚Ä≤‚Ä≤ = C‚Ä≤ ‚à™{c‚Ä≤}.

Bibliography
Adem, A., and Milgram, R. J., Cohomology of Finite Groups, Springer-Verlag, Berlin,
1994.
Albert, A. A., editor, Studies in Modern Algebra, MAA Studies in Mathematics, vol. 2,
Mathematical Association of America, Washington, 1963.
Artin, E., Geometric Algebra, Interscience Publishers, New York, 1957.
Artin, E., Nesbitt, C. J., and Thrall, R. M., Rings with Minimum Condition, University of
Michigan Press, Ann Arbor, 1968.
Aschbacher, M., Finite Group Theory, Cambridge University Press, Cambridge, 1986.
Atiyah, M., and Macdonald, I. G., Introduction to Commutative Algebra, Addison-Wesley,
Reading, 1969.
Biggs, N. L., Discrete Mathematics, Oxford University Press, 1989.
Birkhoff, G., and Mac Lane, S., A Survey of Modern Algebra, 4th ed., Macmillan, New
York, 1977.
Blyth, T. S., Module Theory; an Approach to Linear Algebra, Oxford University Press,
1990.
Borevich, Z. I., and Shafarevich, I. R., Number Theory, Academic Press, Orlando, 1966.
Bourbaki, N., Elements of Mathematics; Algebra I; Chapters 1-3, Springer-Verlag, New
York, 1989.
‚Äî‚Äî‚Äî‚Äî, Elements of Mathematics; Commutative Algebra, Addison-Wesley, Reading,
1972.
Brown, K. S., Cohomology of Groups, Springer-Verlag, Berlin, 1982.
Bruns, W., and Herzog, J., Cohen-Macaulay Rings, Cambridge University Press, 1993.
Buchberger, B., and Winkler, F., editors, Gr¬®obner Bases and Applications, LMS Lecture
Note Series 251, Cambridge University Press, 1998.
B-1

B-2
Bibliography
Burnside, W., The Theory of Groups of Finite Order, 2d ed., Cambridge University Press,
1911; Dover reprint, Mineola, 1955.
Caenepeel, S., Brauer Groups, Hopf Algebras, and Galois Theory, Kluwer, Dordrecht,
1998.
Cajori, F., A History of Mathematical Notation, Open Court, 1928; Dover reprint, Mineola,
1993.
Carmichael, R., An Introduction to the Theory of Groups, Ginn, New York, 1937.
Carter, R., Simple Groups of Lie Type, Cambridge University Press, Cambridge, 1972.
Cassels, J. W. S., and Fr¬®ohlich, A., Algebraic Number Theory, Thompson Book Co., Wash-
ington, D.C., 1967.
Conway, J. H., Curtis, R. T., Norton, S. P., Parker, R. A., Wilson, R. A., ATLAS of Finite
Groups, Oxford University Press, 1985.
Cox, D., Little, J., and O'Shea, D., Ideals, Varieties, and Algorithms, 2d ed., Springer-
Verlag, New York, 1997.
Coxeter, H. S. M., and Moser, W. O. J., Generators and Relations for Discrete Groups,
Springer-Verlag, New York, 1972.
Curtis, C. W., and Reiner, I., Representation Theory of Finite Groups and Associative
Algebras, Interscience, New York, 1962.
Dieudonn¬¥e, J., La G¬¥eometrie des Groupes Classiques, Springer-Verlag, Berlin, 1971.
Dixon, J. D., du Sautoy, M. P. F., Mann, A., and Segal, D., Analytic Pro-p Groups, Cam-
bridge University Press, 1991.
Dornhoff, L., Group Representation Theory, Part A, Ordinary Representation Theory,
Marcel Dekker, New York, 1971.
Drozd, Yu. A., and Kirichenko, V. V., Finite Dimensional Algebras, Springer-Verlag, New
York, 1994.
Dummit, D. S., and Foote, R. M., Abstract Algebra, 2nd ed., Prentice Hall, Upper Saddle
River, 1999.
Eisenbud, D., Commutative Algebra with a View Toward Algebraic Geometry, Springer-
Verlag, New York, 1995.
Evens, L., The Cohomology of Groups, Oxford Mathematical Monographs, Oxford Uni-
versity Press, New York, 1991.
Farb, B., and Dennis, R. K., Noncommutative Algebra, Springer-Verlag, New York, 1993.
Feit, W., Characters of Finite Groups, W. A. Benjamin, New York, 1967.
Fr¬®ohlich, A., and Taylor, M. J., Algebraic Number Theory, Cambridge Studies in Advanced
Mathematics 27, Cambridge University Press, 1991.

Bibliography
B-3
Fuchs, L., InÔ¨Ånite Abelian Groups I, Academic Press, Orlando, 1970.
‚Äî‚Äî‚Äî, InÔ¨Ånite Abelian Groups II, Academic Press, Orlando, 1973.
Fulton, W., Algebraic Curves, Benjamin, New York, 1969.
‚Äî‚Äî‚Äî-, Algebraic Topology; A First Course, Springer-Verlag, New York, 1995.
Gaal, L., Classical Galois Theory with Examples, 4th ed., Chelsea, American Mathemati-
cal Society, Providence, 1998.
Gorenstein, D., Lyons, R. and Solomon, R., The ClassiÔ¨Åcation of the Finite Simple Groups,
Math. Surveys and Monographs Volume 40, American Mathematical Society, Provi-
dence, 1994.
Greub, W. H., Multilinear Algebra, Springer-Verlag, New York, 1967.
Hadlock, C., Field Theory and Its Classical Problems, Carus Mathematical Monographs,
Mathematical Association of America, Washington, 1978.
Hahn, A. J., Quadratic Algebras, Clifford Algebras, and Arithmetic Witt Groups, Univer-
sitext, Springer-Verlag, New York, 1994.
Hardy, G. H., and Wright, E. M., An Introduction to the Theory of Numbers, 4th ed., Oxford
University Press, 1960.
Harris, J., Algebraic Geometry, Springer-Verlag, New York, 1992.
Hartshorne, R., Algebraic Geometry, Springer-Verlag, New York, 1977.
Herstein, I. N., Topics in Algebra, 2d ed., Wiley, New York, 1975.
‚Äî‚Äî‚Äî‚Äî‚Äî, Noncommutative Rings, Carus Mathematical Monographs No. 15, Mathe-
matical Association of America, Washington, 1968.
Humphreys, J. E., Introduction to Lie Algebras and Representation Theory, Springer-
Verlag, New York, 1972.
Huppert, B., Character Theory of Finite Groups, de Gruyter, Berlin, 1998.
‚Äî‚Äî‚Äî-, Endliche Gruppen I, Springer-Verlag, New York, 1967.
Isaacs, I. M., Character Theory of Finite Groups, Academic Press, San Diego, 1976.
‚Äî‚Äî‚Äî‚Äî-, Algebra, A Graduate Course, Brooks/Cole Publishing, PaciÔ¨Åc Grove, 1994.
Jacobson, N., Basic Algebra I, Freeman, San Francisco, 1974.
‚Äî‚Äî‚Äî‚Äî, Basic Algebra II, Freeman, San Francisco, 1980.
‚Äî‚Äî‚Äî‚Äî, Finite-Dimensional Division Algebras over Fields, Springer-Verlag, New York,
1996.
‚Äî‚Äî‚Äî‚Äî, Lie Algebras, Interscience Tracts Number 10, Wiley, New York, 1962.
‚Äî‚Äî‚Äî‚Äî, Structure of Rings, Colloquium Publications 37, American Mathematical Soci-
ety, Providence, 1956.

B-4
Bibliography
Kaplansky, I., Commutative Rings, University of Chicago Press, 1974.
‚Äî‚Äî‚Äî‚Äî-, Fields and Rings, 2d ed., University of Chicago Press, 1972.
‚Äî‚Äî‚Äî‚Äî-, InÔ¨Ånite Abelian Groups, University of Michigan Press, Ann Arbor, 1969.
‚Äî‚Äî‚Äî‚Äî-, Linear Algebra and Geometry; a Second Course, Allyn & Bacon, Boston,
1969.
‚Äî‚Äî‚Äî‚Äî-, Set Theory and Metric Spaces, Chelsea, American Mathematical Society, Prov-
idence, 1977.
Kostrikin, A. I., and Shafarevich, I. R. (editors), Encyclopaedia of Mathematical Sciences,
Algebra IX: Finite Groups of Lie Type; Finite-Dimensional Division Algebras, Springer-
Verlag, New York, 1996.
Lam, T. Y., The Algebraic Theory of Quadratic Forms, Benjamin, Reading, 1973, 2d.
revised printing, 1980.
‚Äî‚Äî‚Äî-, A First Course in Noncommutative Rings, Springer-Verlag, New York, 1991.
‚Äî‚Äî‚Äî-, Lectures on Modules and Rings, Springer-Verlag, New York, 1999.
Lang, S., Algebra, 3d ed., Addison-Wesley, Reading, 1993.
Lidl, R., and Niederreiter, H., Introduction to Finite Fields and Their Applications, Uni-
versity Press, Cambridge, 1986.
Lyndon, R. C., and Schupp, P. E., Combinatorial Group Theory, Springer-Verlag, New
York, 1977.
Macdonald, I. G., Algebraic Geometry; Introduction to Schemes, Benjamin, New York,
1968.
Mac Lane, S., Categories for the Working Mathematician, Springer-Verlag, New York,
1971.
‚Äî‚Äî‚Äî‚Äî, Homology, Springer-Verlag, New York, 3d corrected printing, 1975.
Mac Lane, S., and Birkhoff, G., Algebra, MacMillan, New York, 1967.
Malle, G., and Matzat, B., Inverse Galois Theory, Springer-Verlag, New York, 1999.
Matsumura, H., Commutative Ring Theory, Cambridge University Press, 1986.
McCleary, J., User's Guide to Spectral Sequences, Publish or Perish, Wilmington, 1985.
McConnell, J. C., and Robson, J. C., Noncommutative Noetherian Rings, Wiley, New York,
1987.
McCoy, N. H., and Janusz, G. J., Introduction to Modern Algebra, 5th ed., Wm. C. Brown
Publishers, Dubuque, Iowa, 1992.
Milnor, J., Introduction to Algebraic K-Theory, Annals of Mathematical Studies, No. 72,
Princeton University Press, 1971.

Bibliography
B-5
Montgomery, S. and Ralston, E. W., Selected Papers on Algebra, Raymond W. Brink Se-
lected Mathematical Papers, volume 3, Mathematical Association of America, Washing-
ton, 1977.
Mumford, D., The Red Book of Varieties and Schemes, Lecture Notes in Mathematics
1358, Springer-Verlag, New York, 1988.
Neukirch, J., Schmidt, A., and Wingberg, K., Cohomology of Number Fields, Grundlehren
der mathematicshcen Wissenschaften, vol. 323, Springer-Verlag, New York, 2000.
Niven, I., and Zuckerman, H. S., An Introduction to the Theory of Numbers, Wiley, New
York, 1972.
Northcott, D. G., Ideal Theory, Cambridge University Press, 1953.
O'Meara, O. T., Introduction to Quadratic Forms, Springer-Verlag, New York, 1971.
Orzech, M., and Small, C., The Brauer Group of Commutative Rings, Lecture Notes in
Pure and Applied Mathematics, Marcel Dekker, New York, 1975.
Pollard, H., The Theory of Algebraic Numbers, Carus Mathematical Monographs Num-
ber 9, Mathematical Association of America, 1950.
Procesi, C., Rings with Polynomial Identities, Marcel Dekker, New York, 1973.
Reiner, I., Maximal Orders, Academic Press, London, 1975; Oxford University Press,
2003.
Robinson, D. J. S., A Course in the Theory of Groups, 2d ed., Springer-Verlag, New York,
1996.
Rosenberg, J., Algebraic K-Theory and Its Applications, Springer-Verlag, New York,
1994.
Rotman, J. J., A First Course in Abstract Algebra, 2d ed., Prentice Hall, Upper Saddle
River, 2000.
‚Äî‚Äî‚Äî‚Äî-, Galois Theory, 2d ed., Springer-Verlag, New York, 1998.
‚Äî‚Äî‚Äî‚Äî-, An Introduction to Homological Algebra, Academic Press, Orlando, 1979.
‚Äî‚Äî‚Äî‚Äî-, An Introduction to the Theory of Groups, 4th ed., Springer-Verlag, New York,
1995.
‚Äî‚Äî‚Äî‚Äî-, Journey into Mathematics, Prentice Hall, Upper Saddle River, 1998.
Rowen, L. H., Polynomial Identities in Ring Theory, Academic Press, New York, 1980.
Samuel, P. Algebraic Theory of Numbers, Houghton MifÔ¨Çin, Boston, 1970.
Serre, J.-P., Alg`ebre Locale: Multiplicit¬¥es, Lecture Notes in Mathematics 11, 3d ed.,
Springer-Verlag, New York, 1975.
‚Äî‚Äî‚Äî‚Äî, Corps Locaux, Hermann, Paris, 1968.
‚Äî‚Äî‚Äî‚Äî, Trees, Springer-Verlag, New York, 1980.

B-6
Bibliography
Sims, C. C., Computation with Finitely Presented Groups, Cambridge University Press,
1994.
Stillwell, J., Mathematics and Its History, Springer-Verlag, New York, 1989.
Suzuki, M., Group Theory I, Springer-Verlag, New York, 1982.
Tignol, J.-P., Galois' Theory of Algebraic Equations, Wiley, New York, 1988; World Sci-
entiÔ¨Åc, Singapore, 2001.
van der Waerden, B. L., Geometry and Algebra in Ancient Civilizations, Springer-Verlag,
New York, 1983.
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-, A History of Algebra, Springer-Verlag, New York, 1985.
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-, Modern Algebra, 4th ed., Ungar, New York, 1966.
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-, Science Awakening, Wiley, New York, 1963.
Weibel, C., An Introduction to Homological Algebra, Cambridge University Press, 1994.
Weyl, H., The Classical Groups; Their Invariants and Representations, Princeton, 1946.
Weiss, E., Cohomology of Groups, Academic Press, Orlando, 1969.
Zariski, O., and Samuel, P., Commutative Algebra I, van Nostrand, Princeton, 1958.
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî, Commutative Algebra II, van Nostrand, Princeton, 1960.

Index
Abel, N. H., 236
abelian group, 52
divisible, 484, 661
Ô¨Ånite, 259, 264
Ô¨Ånitely generated, 654, 657
Ô¨Çat, 650
free abelian, 254
ordered, 920
primary, 256
reduced, 658
torsion, 267, 647
torsion-free, 647
totally ordered, 920
abelian Lie algebra, 775
ACC, 340
accessory irrationalities, 217
action of group, 99
transitive, 100
acyclic, 818
addition theorem, 16
additive functor, 465
adjoining to Ô¨Åeld, 188
adjoint functors, 513, 593
adjoint isomorphism, 593
adjoint linear transformation,
708
adjoint matrix, 766
Ado, I. D., 775
Adyan, S. I., 317
afÔ¨Åne group, 125, 640
afforded by, 610
Albert, A. A., 739, 888
algebra, 541
central simple, 727
crossed product, 889
cyclic, 889
division, 727, 892
enveloping, 720
graded, 714
algebra map, 541
algebraic closure, 354
algebraic extension, 187
algebraic integer, 141, 438,
528, 925, 938
conjugate, 335
minimal polynomial, 335
algebraic number Ô¨Åeld, 925
algebraic numbers, 353
algebraically closed, 191, 354
algebraically dependent, 361
algebraically independent,
361
Alhazen, 11
almost all, 451
almost split, 863
alternating bilinear form, 695
alternating group, 64, 108
alternating multilinear, 743
alternating space, 695
alternating sum, 14
Amitsur, S. A., 549, 725, 888
annihilator, 547, 646
Arf invariant, 706
Arf, C., 706
Artin, E., 200, 562
artinian ring, 543
ascending chain condition,
340
associated prime ideal, 394,
997
associated reduced
polynomial, 239
associates, 135, 327
associativity, 51
functions, 30
generalized, 56
tensor product, 582
augmentation, 573
augmentation ideal, 573
Auslander, M., 572, 781, 863,
974, 984, 1000, 1007
Auslander-Buchsbaum
theorem, 1000, 1007
automorphism
Ô¨Åeld, 199
group, 78
inner, 78
automorphism group, 78, 786
axiom of choice, 345, A-1
b-adic digits, 6
Baer sum, 802, 862
Baer, R., 311, 482, 793
bar resolution, 877
normalized, 880
Barr, M., 304
Barratt, M. G., 829
Barratt-Whitehead theorem,
829
base b, 6
basic subgroup, 664
basis
dependency relation, 363
free abelian group, 254
free algebra, 723
free group, 298
I-1

I-2
INDEX
free module, 471
ideal, 341
standard, 164
vector space
Ô¨Ånite-dimensional, 164
inÔ¨Ånite-dimensional, 348
basis theorem
Ô¨Ånite abelian groups, 259
modules, 654
Bass, H., 484, 498, 597
Bautista, R., 572
Beltrami, E., 379
Bernoulli numbers, 10
Bernoulli, John, 376
Bernstein, I. N., 572
biadditive, 575
bidegree, 895
Bifet, E., 783
bijection, 30
bilinear form, 694
alternating, 695
nondegenerate, 698
skew, 696
symmetric, 695
negative deÔ¨Ånite, 703
positive deÔ¨Ånite, 703
bilinear function, 575
bimodule, 579
binomial theorem
commutative ring, 118
exterior algebra, 749
Bkouche, R., 478
blocks of partition, 35
Boole, G., 54
Boolean group, 54
Boolean ring, 124, 326
Boone, W. W., 317
boundaries, 817
bracelet, 115
bracket, 774
Brauer group, 737
relative, 739
Brauer, R., 572, 628, 735, 739
Brauer-Thrall conjectures,
572
Buchberger's algorithm, 417
Buchberger's theorem, 415
Buchberger, B., 400, 411
Buchsbaum, D. A., 781, 1000,
1007
Burnside basis theorem, 288
Burnside ring, 634
Burnside's lemma, 109, 620
Burnside's problem, 317
Burnside's theorem, 605, 637
Burnside, W., 109, 317
C‚àû-function, 12
cancellation law
domain, 119
group, 52
Cardano, G., 207
Carmichael, R., 297
Carnap, R., 461
Cartan, E., 773, 778
Cartan, H., 956
cartesian product, 26, 33
casus irreducibilis, 208
category, 442
composition, 442
morphism, 442
objects, 442
pre-additive, 445
small, 489
Cauchy sequence, 502
Cauchy theorem, 104, 105
Cauchy, A.-L., 104
Cayley theorem, 96
Cayley, A., 64, 96, 98
Cayley-Hamilton theorem,
673
center
group, 77
Lie algebra, 780
matrix ring, 180, 532
ring, 523
centerless, 77
central extension, 875
universal, 875
central simple algebra, 727
centralizer, 101
of subgroup, 113
of subset of algebra, 731
chain, 346, A-2
chain map, 817
over f , 834
change of rings, 985
character, 220, 610
afforded by, 610
degree, 610
generalized, 615
induced, 624
irreducible, 610
kernel, 621
linear, 611
restriction, 628
table, 616
trivial, 612
character module, 598
characteristic of Ô¨Åeld, 184
characteristic subgroup, 277
chessboard, 115
Chevalley, C., 773, 893
Chinese remainder theorem
Z, 10
k[x], 197
commutative rings, 325
circle operation, 125
circle group, 53
Claborn, L., 953
class equation, 104
class function, 612
class group, 953
class number, 953
class sums, 568
Clifford algebra, 756
Clifford, W. K., 756
closed
partially ordered set, A-6
under operation, 63
closed sets in topology, 381
coboundary, 799
cocycle identity, 796
codiagonal, 862
cofactor, 766
coÔ¨Ånal subset, 374
Cohen, I. S., 351, 927
Cohn, P. M., 955
cohomological dimension,
884
cohomology group, 800

INDEX
I-3
cohomology groups of G, 870
coinduced module, 887
cokernel, 441
Cole, F., 293
colimit (see direct limit), 505
colon ideal, 326
coloring, 110
column space of matrix, 181
common divisor
Z, 3, 13
k[x], 135, 157
common multiple
Z, 13
domain, 149
commutative, 52
commutative diagram, 446
commutative ring, 116
Boolean, 124
Dedekind, 948
domain, 119
DVR, 900
euclidean ring, 151
Ô¨Åeld, 122
integers in number Ô¨Åeld,
925
Jacobson, 935
local, 326
regular, 993
noetherian, 342
PID, 147
polynomial ring, 127
several variables, 129
reduced, 383
UFD, 328
valuation ring, 920
commutator, 284
subgroup, 284
companion matrix, 668
comparison theorem, 832
complement
of subgroup, 789
of subset, 37
complete factorization, 43
completely reducible, 607
completion, 502
complex, 815
acyclic, 818
differentiations, 815
quotient, 821
subcomplex, 821
zero, 815
complex numbers
conjugate, 22
exponential form, 19
modulus, 15
polar decomposition, 15
root of unity, 19
composition
category, 442
functions, 30
composition series
factors, 280
groups, 280
modules, 535
compositum, 224
congruence mod m, 7
congruence class, 34
congruent matrices, 697
conjugacy class, 101
conjugate
algebraic integers, 335
complex, 22
elements in Ô¨Åeld extension,
943
group elements, 76
intermediate Ô¨Åelds, 225
subgroups, 101
conjugation
Grassmann algebra, 747
groups, 77
quaternions, 522
connecting homomorphism,
823
constant functor, 463
constant polynomial, 128
constant term, 128
content, 332
continuous, 398
contracting homotopy, 820
contraction of ideal, 926
contragredient, 633
contravariant functor, 463
convolution, 533
coordinate ring, 382
coordinate set, 165
coprime ideals, 325
coproduct
family of objects, 452
two objects, 447
corestriction, 882
Corner, A. L. S., 904
correspondence theorem
groups, 88
modules, 430
rings, 320
coset, 67
coset enlargement, 430
cosyzygy, 973
covariant functor, 464
crossed homomorphism, 806
crossed product algebra, 889
cubic polynomial, 128, 207
formula, 208
cycle
homology, 817
permutation, 41
cycle structure, 44, 46
cyclic algebra, 889
cyclic group, 64, 93
cyclic module, 428
cyclotomic Ô¨Åeld, 945
cyclotomic polynomial, 20,
334
Dade, E. C., 916
DCC, 543
De Moivre theorem, 17
De Moivre, A., 17
De Morgan law, 124
De Morgan, A., 124
de Rham complex, 754
de Rham, G., 754
Dean, R. A., 125
Dedekind ring, 948
Dedekind, R., 220, 923
Degree
several variables, 402
degree
character, 610
extension Ô¨Åeld, 187
homogeneous element, 714
inseparability, 367, 371

I-4
INDEX
polynomial, 126
rational function, 357
representation, 606
separability, 371
degree function
euclidean ring, 151
degree-lexicographic order,
405
deleted resolution, 832
dependency relation, 362
basis, 363
dependent, 363
exchange lemma, 362
generate, 363
depth, 999
derivation
group, 806
Lie algebra, 774
principal, 807
ring, 769, 773
derivative, 130
derived series
groups, 285
Lie algebra, 777
Descartes, R., 209
descending central series
group, 287
Lie algebra, 777
descending chain condition,
543
determinant, 757
diagonal map, 862
diagonalizable, 681
diagram, 446
commutative, 446
diagram chasing, 589
Dickson, L. E., 50, 293, 740,
888
Dieudonn¬¥e, J., 725
differential form, 753
differentiations, 815
dihedral group, 60
inÔ¨Ånite, 318
dimension, 167
dimension shifting, 831
Diophantus, 922
direct limit, 505
direct product
commutative rings, 150
groups, 90
modules, 451
external, 531
rings, 521
direct sum
abelian groups, 250
matrices, 667
modules, 451
external, 432, 434, 531
internal, 433, 435
vector spaces, 171
direct summand
modules, 434
vector space, 181
direct system, 504
transformation, 510
directed set, 507
Dirichlet, G. P. L., 922, 947,
953
discrete valuation ring, 900
discriminant, 238
bilinear form, 698
of OE, 948
of cubic, 240
of quartic, 244
disjoint permutations, 42
disjoint union, 452
divides
Z, 3
commutative ring, 121
divisible module, 484
division algebra, 727
division algorithm
Z, 2
k[x], 131
k[x1, . . . , xn], 408
division ring, 522
characteristic p, 892
quaternions, 522
divisor
Z, 3
commutative ring, 121
Dlab, V., 572
domain
commutative ring, 119
function, 27
PID, 147
regular local ring, 996
UFD, 328
double centralizer theorem,
731
double induction, 12
doubly transitive, 638
sharply, 639
dual basis, 181, 699
dual space, 180, 427
functor, 465
duals in category, 450
DVR, 900
Dye, R. L., 706
Dynkin diagrams, 572, 778
Dynkin, E., 572, 778
Eckmann, B., 871
Eilenberg, S., 441, 498, 871,
956
Eisenstein criterion, 337
Eisenstein, G., 337
elementary divisors
Ô¨Ånite abelian group, 264
modules, 655
elementary matrix, 687
elementary symmetric
functions, 198
elimination ideal, 419
elliptic function, 376
empty word, 299
endomorphism
abelian group, 521
module, 527
endomorphism ring, 521
Engel's theorem, 777
Engel, F., 777
enveloping algebra, 720
epimorphism, 478
equal functions, 27
equivalence
category, 444
normal series, 280
words, 300
equivalence class, 34
equivalence of categories, 513
equivalence relation, 34

INDEX
I-5
equivalent
extensions, 800, 856
matrices, 683
representations, 609
series, groups, 280
series, modules, 534
etymology
abelian, 236
adjoint functors, 514
alternating group, 64
artinian, 562
automorphism, 199
canonical form, 670
commutative diagram, 446
coordinate ring, 382
cubic, 128
cycle, 41
dihedral group, 60
domain, 122
exact sequence, 755
Ext, 855
exterior algebra, 742
factor set, 795
Ô¨Åeld, 122
Ô¨Çat, 590
free group, 306
free module, 473
functor, 461
Gaussian integers, 152
Gr¬®obner basis, 411
homology, 783
homomorphism, 73
hypotenuse, 25
ideal, 923
isomorphism, 73
kernel, 75
left exact, 469
nilpotent, 778
polar decomposition, 15
polyhedron, 60
power, 55
pure subgroup, 257
quadratic, 128
quasicyclic, 659
quaternions, 522
quotient group, 84
quotient ring, 182
radical, 383
rational canonical form, 670
ring, 116
symplectic, 701
Tor, 867
torsion subgroup, 267
transvection, 290
variety, 379
vector, 159
Euclid, 3
Euclid lemma
Z, 4
k[x], 137
euclidean algorithm
Z, 5
k[x], 138
euclidean ring, 151
Euler œÜ-function, 21, 93
Euler theorem
complex exponentials, 18
congruences, 71
Euler, L., 19, 155, 922
Euler-Poincar¬¥e characteristic,
829
evaluation homomorphism,
144
even permutation, 48
exact
functor, 470
hexagon, 886
sequence, 435
almost split, 863
complexes, 822
short, 436
triangle, 825
exchange lemma, 168
dependency relation, 362
exponent
group, 265
module, 656
extension
central, 875
universal, 875
groups, 282, 785
modules, 436, 855
of ideal, 926
extension Ô¨Åeld, 187
algebraic, 187
degree, 187
Ô¨Ånite, 187
pure, 206
purely inseparable, 371
purely transcendental, 362
radical, 206
separable, 201
simple, 229
exterior algebra, 742
exterior derivative, 753
exterior power, 742
factor groups, 212
factor modules, 534
factor set, 795
faithful G-set, 637
faithful module, 528
Feit, W., 236, 284
Feit-Thompson theorem, 236
Fermat theorem, 9, 70, 105
Fermat, P., 922
FFR, 983
Fibonacci, 772
Ô¨Åeld, 122
algebraic closure, 354
algebraically closed, 354
Ô¨Ånite, 205
perfect, 367
rational functions, 129
15-puzzle, 47, 49
Ô¨Åltration, 894
Ô¨Ånite extension, 187
Ô¨Ånite order (module), 646
Ô¨Ånite-dimensional, 163
Ô¨Ånitely generated group, 306
Ô¨Ånitely generated ideal, 341
Ô¨Ånitely generated module, 428
Ô¨Ånitely presented, 479
group, 306
module, 478
Ô¨Årst isomorphism theorem
commutative rings, 183
complexes, 821
groups, 85
modules, 429
vector spaces, 181

I-6
INDEX
Fitchas, N., 477
Ô¨Åxed Ô¨Åeld, 218
Ô¨Åxes, 199
Ô¨Çat dimension, 975
Ô¨Çat module, 590
Ô¨Çat resolution, 975
Fontana, N. (Tartaglia), 207
forgetful functor, 463
formal power series, 130, 518,
994
Formanek, E., 726
four-group, 63
fraction Ô¨Åeld, 123
fractional ideal, 950
Fraenkel, A., A-1
Frattini argument, 277
Frattini subgroup, 288
Frattini, G., 288
free
abelian group, 254
algebra, 723
group, 298
module, 471, 531
monoid, 311
resolution, 813
Freudenthal, H., 871
Frobenius complement, 640
Frobenius group, 640
Frobenius kernel, 641
Frobenius map, 205
Frobenius reciprocity, 628
Frobenius theorem
Frobenius kernels, 643
real division algebras, 735
Frobenius, F. G., 109, 269,
624, 628, 633, 637,
735, 888
fully invariant, 277
function, 27
bijection, 30
identity, 27
inclusion, 27
injective, 29
restriction, 27
surjective, 29
function Ô¨Åeld, 362
functor
additive, 465
constant, 463
contravariant, 463
contravariant Hom, 464
covariant, 461, 464
covariant Hom, 462
dual space, 465
exact, 470
forgetful, 463
identity, 461
left exact, 468, 469
representable, 518
right exact, 586
two variables, 605
fundamental theorem
algebra, 232
arithmetic, 6, 282
Ô¨Ånite abelian groups
elementary divisors, 264
invariant factors, 266
Galois theory, 228
modules
elementary divisors, 656
invariant factors, 657
symmetric functions, 224
symmetric polynomials,
411
G-domain, 931
G-ideal, 931
G-set, 99
faithful, 637
Gabriel, P., 572
Galligo, A., 477
Galois Ô¨Åeld, 196
Galois group, 200
Galois theorem, 193
Galois, E., 69
Gasch¬®utz, W., 809
Gauss theorem
R[x] UFD, 332
cyclotomic polynomial, 338
Gauss, C. F., 155, 207, 230,
377
Gaussian elimination, 687
Gaussian equivalent, 688
Gaussian integers, 117
gcd see greatest common
divisor
Gelfand, I. M., 572
general linear group, 54
general polynomial, 192
generalized associativity, 56
generalized character, 615
generalized quaternions, 298,
812
generate
dependency relation, 363
generator of ModR, 601
generator of cyclic group, 64
generators and relations
algebra, 723
group, 306
module, 473
global dimension
left, 974
left injective, 973
left projective, 972
going down theorem, 930
going up, 927
going up theorem, 930
Goldman, O., 931
Goodwillie, T. G., 772
Gordan, P., 343
grade, 999
graded algebra, 714
graded map
of degree d, 715
Grassmann algebra, 747
Grassmann, H., 747
greatest common divisor, 147
Z, 3, 13
k[x], 157
two polynomials, 135
Griess, R., 780
Gr¬®obner, W., 411
Gr¬®obner basis, 411
Grothendieck group, 489,
492, 967
Jordan-H¬®older, 494
Grothendieck, A., 397, 488,
897

INDEX
I-7
group
abelian, 52
afÔ¨Åne, 125, 640
alternating, 64
axioms, 51, 61
Boolean, 54
circle group, 53
cyclic, 64, 93
dihedral, 60
inÔ¨Ånite, 318
Ô¨Ånitely generated, 306
Ô¨Ånitely presented, 306
four-group, 63
free, 298
free abelian, 254
Frobenius, 640
Galois, 200
general linear, 54
generalized quaternions,
298
integers mod m, 65
nilpotent, 287
p-group, 104, 112
Pr¬®ufer, 659
projective unimodular, 292
quasicyclic, 659
quaternions, 79, 82
quotient, 84
simple, 106
solvable, 212, 286
special linear, 72
special unitary group, 793
symmetric, 40
unitriangular, 274
group algebra, 521
group object, 460
group of units, 122
Hall, P., 284, 803
Hamilton, W. R., 79, 522, 888
Hasse, H., 706, 739
Hasse-Minkowski theorem,
706
height
abelian group, 901
prime ideal, 987
height sequence, 901
Herbrand quotient, 886
Herbrand, J., 886
hereditary ring, 955
Hermite, C., 50
Higgins, P. J., 311
Higman, D. G., 572
Higman, G., 318, 734
Hilbert, D., 116, 246, 343,
728, 983
basis theorem, 343
Nullstellensatz, 386, 937
Theorem 90, 234, 888
theorem on syzygies, 983
Hochschild, G. P., 897
H¬®older, O., 282
Hom functor
contravariant, 464
covariant, 462
homogeneous element, 714
homogeneous ideal, 715
homology, 818
homology groups of G, 870
homomorphism
R-homomorphism, 424
algebra, 541
commutative ring, 143
graded algebra, 715
group, 73
conjugation, 77
natural map, 85
Lie algebra, 776
monoid, 300
ring, 525
semigroup, 300
homotopic, 820
homotopy
contracting, 820
Hopf's formula, 875
Hopf, H., 870, 875
Hopkins, C., 555
Hopkins-Levitzki theorem,
555
Houston, E., 235
Hurewicz, W., 435, 870
hyperbolic plane, 701
hypersurface, 381
ideal, 145, 524
augmentation, 573
basis, 341
colon, 326
commutative ring, 145
elimination, 419
Ô¨Ånitely generated, 341
generated by X, 341
homogeneous, 715
invertible, 950
left, 524
Lie algebra, 776
maximal, 322
minimal, 543
monomial, 410
order, 646
primary, 391
prime, 321
principal, 146
proper, 145
radical, 383
right, 524
two-sided, 524
idempotent, 532, 613
identity
function, 27
functor, 461
group element, 51
morphism, 443
image
function, 27
group homomorphism, 27
linear transformation, 177
module homomorphism,
429
ring homomorphism, 525
inclusion, 27
increasing p ‚â§n list, 746
independence of characters,
220
Dedekind theorem, 220
independent list
dependency relation, 363
longest, 169
index of subgroup, 69
induced character, 624
induced class function, 626
induced map, 462, 464
homology, 819

I-8
INDEX
induced module, 624, 887
induced representation, 624
induction, 2
double, 12
second form, 2
transÔ¨Ånite, A-4
inductive limit (see direct
limit), 505
inÔ¨Ånite order, 58, 646
inÔ¨Ånite-dimensional, 163
inÔ¨Çation, 882
initial object, 459
injections
coproduct, 452
direct sum, 250
direct sum of modules, 432
injective dimension, 972
injective function, 29
injective module, 480
injective resolution, 814
injectively equivalent, 973
inner automorphism, 78
inner product, 694
inner product matrix, 696
inner product space, 694
inseparability degree, 371
inseparable, 201
integers
algebraic number Ô¨Åeld, 925
integers mod m, 65
integral basis, 945
integral closure, 925
integral element, 923
integral extension, 923
integrally closed, 925
intermediate Ô¨Åeld, 224
invariance of dimension, 167,
169
invariant (of group), 75
invariant factors
Ô¨Ånite abelian group, 265
modules, 656
invariant subspace, 428
inverse
commutative ring, 121
function, 31
group element, 51
inverse Galois problem, 246
inverse image, 32
inverse limit, 500
inverse system, 499
invertible ideal, 950
invertible matrix, 767
irreducible character, 610
irreducible element, 135
irreducible module, 534
see simple module, 431
irreducible polynomial, 205
irreducible representation,
569, 607
irreducible variety, 388
irredundant, 394
union, 389
isolated primes, 396
isometry, 706
isomorphic
commutative rings, 143
groups, 73
modules, 425
stably, 490, 967
isomorphism
R-isomorphism, 425
commutative rings, 143
complexes, 821
groups, 73
modules, 425
vector spaces, 171
Ivanov, S. V., 318
Jacobi identity, 775
groups, 289
Jacobi, C., 376
Jacobson radical, 544
Jacobson ring, 935
Jacobson semisimple, 544
Jacobson, N., 543, 776
Janusz, G. J., 247
Jordan canonical form, 677
Jordan, C., 269, 282, 293
Jordan, P., 779
Jordan-H¬®older category, 494
Jordan-H¬®older theorem
Grothendieck group, 494
groups, 282
modules, 536
juxtaposition, 299
k-algebra, 541
k-linear combination, 162
k-map, 355
Kaplansky, I., 532, 726, 781,
910, 1007
kernel
character, 621
group homomorphism, 75
Lie homomorphism, 777
linear transformation, 177
module homomorphism, 429
ring homomorphism, 145,
525
Killing, W., 773, 778
Kneser, H., A-7
Koszul complex, 1004
Koszul, J.-L., 1004
Kronecker delta, xv
Kronecker product, 604
Kronecker theorem, 191
Kronecker, L., 269
Krull dimension, 988
Krull, W., 351, 538, 933, 989
Krull-Schmidt theorem, 538
Kulikov, L. Yu., 664
Kummer, E., 922
Kurosh, A. G., 447, 904
Lagrange theorem, 69, 522
Lagrange, J. L., 69
Lam¬¥e, G., 922
Laplace expansion, 765
Laplace, P. S., 765
Lasker, E., 393
lattice, 226
Laurent polynomials, 532
Laurent, P. M. H., 532
law of inertia, 704
law of substitution, 51
laws of exponents, 57
lcm see least common
multiple
leading coefÔ¨Åcient, 21, 126
least common multiple
Z, 6, 13
domain, 149

INDEX
I-9
least integer axiom, 1
left R-module, 424
left derived functors, 834
left exact, 468
left quasi-regular, 546
Leibniz, G. W., 12, 376
length
cycle, 41
module, 536
series, 534
word, 299
Levi, F., 311
Levitzki, J., 555, 725
lexicographic order, 402
Lie algebra, 774
Lie's theorem, 778
Lie, S., 778
lifting, 474, 785
limit (see inverse limit), 500
linear combination
module, 428
vector space, 162
linear fractional
transformation, 358
linear functional, 427
linear polynomial, 128
linear representation, 607
linear transformation, 171
nonsingular, 171
linearly dependent, 164
linearly disjoint, 246, 372
linearly independent, 164
inÔ¨Ånite set, 348
list, 161
increasing p ‚â§n, 746
local ring, 326
regular, 993
localization, 905
algebra, 905
map, 905, 911
of module, 911
locally isomorphic, 901
long exact sequence, 824
longest independent list, 169
Luigi Ferrari, 209
L¬®uroth's theorem, 359
L¬®uroth, J., 359
lying over, 927
Lyndon, R. C., 897
Lyndon-Hochschild-Serre,
897
M-regular sequence, 993
Mac Lane, S., 373, 461, 717,
871
Mann, A., 105
mapping problem
universal, 449
Matlis, E., 974
matrix
elementary, 687
linear transformation, 173
nilpotent, 681
nonsingular, 54
permutation, 607
scalar, 180
unitriangular, 274
maximal element
partially ordered set, 346,
A-4
maximal ideal, 322
maximal normal subgroup,
113
maximum condition, 341
Mayer, W., 830
Mayer-Vietoris theorem, 830
McKay, J. H., 105
metric space, 502
minimal left ideal, 543
minimal map, 1001
minimal polynomial
algebraic element, 189
algebraic integer, 335
minimal prime ideal, 374
minimal resolution, 1001
minimum polynomial
matrix, 673
Minkowski, H., 706, 953
minor, 763
M¬®obius function, 194
M¬®obius, A. F., 194
mod m, 7
modular law, 549
module, 423
bimodule, 579
cyclic, 428
divisible, 484
faithful, 528
Ô¨Ånitely generated, 428
Ô¨Ånitely presented, 478
Ô¨Çat, 590
free, 471
generator, 601
injective, 480
irreducible, 534
left, 424, 525
primary, 652
quotient, 429
right, 526
semisimple, 552
simple, 431, 534
small, 601
torsion, 647
torsion-free, 647
trivial, 552
modulus
complex number, 15
Molien, T., 568
monic polynomial, 21, 128
several variables, 402
monoid, 300
free, 311
homomorphism, 300
monomial ideal, 410
monomial order, 402
degree-lexicographic order,
405
lexicographic order, 402
Monster, 632, 780
Moore theorem, 196
Moore, E. H., 196, 293
Moore, J., 441
Morita equivalence, 603
Morita theory, 513, 603
Morita, K., 603
morphism, 442
identity, 443
Motzkin, T. S., 153
multidegree, 401
multilinear function, 716
alternating, 743

I-10
INDEX
multiple
Z, 3
commutative ring, 121
multiplication by r, 425
multiplication table, 73
multiplicatively closed, 906
multiplicity, 140
Nagata, M., 781
Nakayama's lemma, 545
Nakayama, T., 545
natural equivalence, 511
natural map
groups, 85
modules, 429
rings, 182, 525
natural transformation, 511
Navarro, G., 260
Neumann, B. H., 734
Neumann, H., 734
Nielsen, J., 311
Nielsen-Schreier theorem,
315, 886
nilpotent
element, 383
group, 287
ideal, 546
Lie algebra, 777
matrix, 681
nilradical, 397, 933
Noether, E., 85, 200, 342,
393, 734, 739
noetherian, 342, 351, 437
left, 542
nondegenerate, 698
nonsingular
linear transformation, 171
matrix, 54
norm, 233, 940
algebraic integer, 335
euclidean ring, 152
normal basis, 528
normal closure, 211
normal extension, 211
normal primary
decomposition, 395
normal series, 212
composition series, 280
derived, 285
descending central series,
287
factor groups, 212
reÔ¨Ånement, 280
normal subgroup, 76
generated by X, 306
maximal, 113
normalized bar resolution, 880
normalizer, 101
not necessarily associative
algebra, 773
Novikov, P. S., 317
nullhomotopic, 820
Nullstellensatz, 386, 937
weak, 385, 937
number Ô¨Åeld
algebraic, 925
quadratic, 938
objects of category, 442
obstruction, 852
odd permutation, 48, 49
Ol'shanskii, A. Yu., 317
one-to-one
see injective, 29
one-to-one correspondence
see bijection, 30
onto (function)
see surjective, 29
open segment, A-5
operation, 51
opposite ring, 529
orbit, 100, 109
order
Ô¨Ånitely generated torsion
module, 655
group, 66
group element
Ô¨Ånite, 58
inÔ¨Ånite, 58
power series, 130
order ideal, 646
order-reversing, 227
ordered abelian group, 920
totally ordered, 920
orthogonal basis, 702
orthogonal complement, 698
orthogonal direct sum, 700
orthogonal group, 708
orthogonality relations, 618
orthonormal basis, 702
p-adic fractions, 326
p-adic integers, 503
p-adic numbers, 503
p-group, 104, 106, 112, 276
p-primary, 963
p-primary abelian group, 256
P-primary module, 652
pairing, 575
pairwise disjoint, 35
parallelogram law, 159
parity, 48
partial order
discrete, 499
monomial, 402
partially ordered set, 226
chain, 346, A-2
closed, A-6
directed set, 507
well-ordered, 345, A-2
partition, 35
partition of n, 268
perfect Ô¨Åeld, 367
periodic cohomology, 876
permutation, 40
complete factorization, 43
cycle, 41
disjoint, 42
even, 48
odd, 48, 49
parity, 48
signum, 48
transposition, 41
permutation matrix, 607
PI-algebra, 725
Picard group, 968
Picard, E., 968
PID, 147
Poincar¬¥e, H., 782, 783
pointwise operations, 120
polar coordinates, 15
polar decomposition, 15
P¬¥olya, G., 112

INDEX
I-11
polynomial, 126, 128
associated reduced
polynomial, 239
cyclotomic, 20
function, 377
general, 192
leading coefÔ¨Åcient, 21
monic, 21, 128
separable, 201
zero, 126
polynomial function, 129, 377
polynomial identity, 725
polynomial ring
noncommuting variables,
724
polynomials, 127
n variables, 129
noncommuting variables,
724
skew, 521
Ponomarev, V. A., 572
Pontrjagin duality, 488
Pontrjagin, L. S., 488
power series, 130, 518, 994
powers, 55
pre-additive category, 445
presentation
group, 306
module, 473
preserves multiplications, 835
presheaf, 519
primary component, 256, 652
primary decomposition, 393,
963
irredundant, 394
normal, 395
primary ideal, 391
prime Ô¨Åeld, 184
prime ideal, 321
associated, 394, 997
minimal, 374
minimal over ideal, 396
prime integer, 1
primitive element, 134
theorem, 230
primitive polynomial, 331
associated, 332
primitive ring, 571
primitive root of unity, 20
principal kG-module, 552
principal character
see trivial character, 612
principal derivation, 807
principal ideal, 146
principal ideal domain, 147
principal ideal theorem, 989
product
categorical
family of objects, 453
two objects, 449
proÔ¨Ånite completion, 503
projections
direct sum, 250
direct sum of modules, 432
product, 453
projective dimension, 969
projective limit (see inverse
limit), 500
projective module, 474
projective plane, 779
projective resolution, 813
projective unimodular group,
292
projectively equivalent, 971
proper
class, 442
divisor, 329
ideal, 145
subgroup, 63
submodule, 428
subset, 26
subspace, 160
Pr¬®ufer, H., 659
Pr¬®ufer group, 659
pullback, 455
pure extension, 206
pure subgroup, 257
pure submodule, 663
purely inseparable, 371, 776
purely transcendental, 362
pushout, 456
Pythagorean triple, 13
primitive, 13
quadratic Ô¨Åeld, 938
quadratic form, 705
quadratic polynomial, 128
quartic polynomial, 128, 209
resolvent cubic, 210
quasi-ordered set, 444
quasicyclic group, 659
quaternions, 79, 81, 82
division ring, 522
generalized, 298, 812
Quillen, D., 477, 498
quintic polynomial, 128
quotient
complex, 821
division algorithm
Z, 3
k[x], 132
group, 84
Lie algebra, 776
module, 429
ring, 182
space, 170
r-cycle, 41
R-homomorphism, 424
R-isomorphism, 425
R-linear combination, 428
R-map, 424
R-module, 423
R-sequence, 993
maximal, 997
Rabinowitch trick, 386
Rabinowitch, S., 386
radical extension, 206
radical ideal, 383
radical of ideal, 383
Rado, R., 261
rank, 898
free abelian group, 254
free group, 305
free module, 472
linear transformation, 181
rational canonical form, 670
rational functions, 129
Razmyslov, Yu. P, 726
realizes the operators, 790
reduced abelian group, 658
reduced basis, 418
reduced degree, 367

I-12
INDEX
reduced mod {g1, . . . , gm},
408
reduced polynomial, 239
reduced ring, 383
reduced word, 299
reduction
generalized euclidean
algorithm, 406
Rees, D., 980, 989, 999
reÔ¨Ånement, 280, 534
regular G-set, 639
regular element
on module, 980
regular local ring, 993
regular representation, 607
regular sequence, 993
Reiten, I., 572, 863
relative Brauer group, 739
relatively prime
Z, 4
k[x], 137
UFD, 331
remainder
division algorithm
Z, 3
k[x], 132
mod G, 409
repeated roots, 142
representable functor, 518
representation
character, 610
completely reducible, 607
group, 550
irreducible, 569, 607
linear, 607
regular, 607
ring, 527
representation on cosets, 97
residue Ô¨Åeld, 986
resolution
bar, 877
deleted, 832
Ô¨Çat, 975
free, 813
injective, 814
minimal, 1001
projective, 813
resolvent cubic, 210, 243
restriction, 27
cohomology, 881
representation, 628
resultant, 241
retract, 434
retraction, 318, 434
Rieffel, M., 563
Riemann, G. F. B., 377
right derived functors, 845,
848
right exact
functor, 588
tensor product, 586
ring
artinian, 543
Boolean, 326
commutative, 116
division ring, 522
quaternions, 522
endomorphism ring, 521
hereditary, 955
Jacobson, 935
left noetherian, 542
local, 326
opposite, 529
polynomial, 126
semisimple, 552, 563
simple, 559
von Neumann regular, 976
zero, 118
ring extension, 923
Ô¨Ånitely generated, 931
Ringel, C., 572
Roiter, A. V., 572
root
multiplicity, 140
polynomial, 132
root of unity, 19
primitive, 20
Rosset, S., 288, 725
roulette wheel, 115
Russell's paradox, 442
Russell, B., 442
S-polynomial, 413
Salmer¬¥on, L., 572
Samuel, P., 231
Sarges, H., 343
saturated, 921
scalar, 159
matrix, 180
multiplication, 159
module, 423
transformation, 180
Schanuel's lemma, 479
dual, 488
Schanuel, S., 781
Schering, E., 269
Schmidt, O., 538
Schreier reÔ¨Ånement
groups, 281
modules, 534
Schreier transversal, 314
Schreier, O., 311
Schur's lemma, 560, 634
Schur, I., 560, 803
Scipio del Ferro, 207
second form of induction, 2
second isomorphism theorem
groups, 87
modules, 429
secondary matrices, 694
Seidenberg, A., 927
semidirect product, 788
semigroup, 300
homomorphism, 300
semisimple
Jacobson, 544
module, 552
ring, 552, 563
separability degree, 371
separable
element, 201
extension, 201
polynomial, 201
separating transcendence
basis, 373
sequence, 126
series, 534
composition
modules, 535
equivalent, 534
factor modules, 534
length, 534

INDEX
I-13
reÔ¨Ånement
modules, 534
Serre, J. J.-P., 897
Serre, J.-P., 311, 397, 477,
781, 1006
Shafarevich, I., 246
Shapiro's lemma, 884
Shapiro, A., 884
sheaf, 1010
Shelah, S, 869
Shirsov, A. I., 421
short exact sequence
almost split, 863
split, 437
shufÔ¨Çe, 751
signature, 704
signum, 48
similar matrices, 177
Simmons, G. J., 194
simple
extension, 229
group, 106
Lie algebra, 776
module, 431, 534
ring, 559
transcendental extension,
357
simple components, 562
Singer, R., 337
single-valued, 28
skew Ô¨Åeld, 522
skew polynomials, 521
Skolem, T., 734
Skolem-Noether theorem,
734
small module, 601
Small, L., 549
smallest element
partially ordered set, 345,
A-2
smallest subspace, 162
Smith normal form, 689
Smith, H. J. S., 688
solution
linear system, 161
universal mapping problem,
449
solution space, 161
solvable
by radicals, 207
group, 212, 286
Lie algebra, 777
spans, 162
inÔ¨Ånite-dimensional space,
348
Spec(R), 398
special linear group, 72
special unitary group, 793
spectral sequence, 895
split extension
groups, 788
modules, 855
split short exact sequence, 437
splits, polynomial, 191
splitting Ô¨Åeld
central simple algebra, 731
polynomial, 191
squarefree integer, 12
stabilizer, 100
stabilizes an extension, 805
stably isomorphic, 490, 967
stalk, 519
Stallings, J., 885
standard basis, 164
standard identity, 725
Stasheff, J., 717
Steinitz theorem, 229
Steinitz, E., 229, 967
Stickelberger, L., 269
structure constants, 889
Sturmfels, B., 477
subalgebra
Lie algebra, 775
subcomplex, 821
subÔ¨Åeld, 124
subgroup, 62
basic, 664
center, 77
centralizer, 101
characteristic, 277
commutator, 284
conjugate, 101
cyclic, 64
Frattini, 288
fully invariant, 277
Hall, 803
normal, 76
generated by X, 306
normalizer, 101
proper, 63
pure, 257
subnormal, 212
Sylow, 269
torsion, 267
submatrix, 763
submodule, 427
cyclic, 428
generated by X, 428
proper, 428
torsion, 647
subnormal subgroup, 212
subquotient, 894
subring, 119, 523
subset, 25
subspace, 160
invariant, 428
proper, 160
smallest, 162
spanned by X, 162
subword, 299
successor, A-2
superalgebra, 727
surjective, 29
Suslin, A., 477
Swan, R. G., 491, 885
Sylow subgroup, 269
Sylow theorem, 270, 271
Sylow, L., 269
Sylvester, J. J., 703
symmetric
algebra, 755
bilinear form, 695
difference, 54
function, 219
elementary, 219
group, 40
space, 695
symplectic
basis, 701
group, 708
syzygy, 970

I-14
INDEX
T. I. set, 645
target (of function), 27
Tarski monster, 666
Tarski, A., 666
Tartaglia, 207
tensor algebra, 722
tensor product, 576
terminal object, 459
third isomorphism theorem
groups, 88
modules, 430
Thompson, J. G., 284, 640,
644
three subgroups lemma, 289
top element, 518
topological space, 381
topology, Zariski, 381
torsion module, 647
torsion subgroup, 267
torsion submodule, 647
torsion-free, 647
totally ordered abelian group,
920
trace, 247, 610, 771, 940
trace form, 940
transcendence basis, 365
separating, 373
transcendence degree, 365
transcendental, 187
transcendental extension
simple, 357
transfer, 882
transÔ¨Ånite induction, A-4
transformation
direct system, 510
transitive
doubly, 638
equivalence relation, 34
group action, 100
transposition, 41
transvection, 290
transversal, 312
Schreier, 314
trivial character, 612
trivial module, 552
type
abelian group, 902
pure extension Ô¨Åeld, 206
UFD, 328
unimodular column, 261
unique factorization
k[x], 139
unique factorization domain,
328
unit, 121
noncommutative ring, 547
unitriangular, 274
universal
central extension, 875
coefÔ¨Åcients theorem, 868
mapping problem, 449
solution, 449
upper bound, 226, A-4
valuation, 920
discrete, 893
valuation ring, 920
van der Waerden, B. L., 734
van Kampen's theorem, 306
van Kampen, E. R., 306
Vandermonde matrix, 772
Vandermonde, A.-T., 772
variety, 379
irreducible, 388
vector space, 159
vectors, 159
Vi`ete, F., 209
Vietoris, L., 830
von Dyck, W., 298
von Neumann regular, 976
von Neumann, J., 976
Watts, C. E., 512, 585
weak dimension, 976
Wedderburn theorem
Ô¨Ånite division rings, 538,
734
Wedderburn, J. M., 538, 562,
888
Wedderburn-Artin theorem
semisimple rings, 562, 567
weight, 401
Weir, A. J., 311
well-deÔ¨Åned, 28
well-ordered, 345, A-2
Weyl algebra, 550
Weyl, H., 550
Whitehead's problem, 869
Whitehead, J. H. C., 829
Wielandt, H., 272
Wiles, A., 377, 922
Williams, K. S., 154
Wilson's theorem, 71
Wilson, J., 71
Witt, E., 538
word, 299
empty, 299
length, 299
reduced, 299
yoke, 975
Yoneda, N., 851, 862
Zaks, A., 837
Zariski closure, 387
Zariski topology
kn, 381
Spec(R), 398
Zariski, O., 381
Zassenhaus lemma, 279
modules, 534
Zassenhaus, H., 803
Zermelo, E., A-7
zero complex, 815
zero divisor, 573
on module, 980
zero object, 460
zero of polynomial, 378
zero polynomial, 126
zero ring, 118
Zorn's lemma, 346, A-4
Zorn, M., 346, A-4

