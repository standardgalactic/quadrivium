208 

IEEE TRANSACTIONS ON  KNOWLEDGE AND DATA  ENGINEERING,  VOL.  3,  NO.  2,  JUNE 1991 

Combining  Multiple  Knowledge  Bases 

Chitta  Baral,  Sarit  Kraus,  and  Jack  Minker,  Fellow,  ZEEE 

Abstmct-  Knowledge  present  in  multiple  knowledge  bases 
might need to be reviewed to make decisions based on the com- 
bined knowledge. We  define the concept of combining knowledge 
present  in  a  set of  knowledge bases and  present  algorithms  to 
maximally combine them  SQ  that  the combination is  consistent 
with  respect  to  the  integrity  constraints associated  with  the 
knowledge bases.  For  this  we  define the  concept of  maximality 
and prove that the algorithms presented combine the knowledge 
bases to generate a maximal theory. We  also discuss the relation- 
ships between combining multiple knowledge bases and the view 
update  problem. 

Index  Terms-  Consistent,  integrity  constraints,  knowledge 

bases, logic programs, maximally combining theories. 

I.  INTRODUCIION 

HE main concern in this paper is to combine knowledge 

T present in multiple knowledge base systems into a single 

knowledge base. A knowledge based system can be considered 
an  extension of  a  deductive database in  that  it permits func- 
tion  symbols  as  part  of  the  theory.  We  consider  alternative 
knowledge bases that deal with the same subject matter. Each 
knowledge base  consists of  a set normal clauses and  a set of 
integrity  constraints. The  set  of  integrity  constraints (IC)  is 
assumed to  be  the same for all knowledge bases, but the sets 
of normal clauses may differ. We  assume that each knowledge 
base is consistent with respect to the integrity constraints when 
considered  alone. 

While  combining  multiple  knowledge  bases  we  have  to 
ensure  that  the  combination  is  consistent  with  respect  to 
the  integrity  constraints.  Such  a  problem  might  arise  in  a 
large company with branches overseas. Each branch manages 
its  own  knowledge  base.  A  consistent  combination  of  the 
knowledge bases is required  while trying to  make  a  decision 
about  the  overall  company. 

In  Section 11,  we  discuss problems that  may  arise in  com- 
bining alternative knowledge bases. Basic definitions are pre- 
sented in  Section 111.  In  Section IV, we present algorithms to 
combine multiple knowledge bases. In Section V, we compare 
this problem to the view update problem  in databases [7],  [6], 
~ 4 1 .  

Manuscript  received  September 14,  1989; revised  March  21,  1990. This 
work was supported by  the National Science Foundation under Grant IRI-86- 
09170 and the Army  Research Office under Grant DAAL-03-88-KW87. 

C.  Baral  is  with  the  Department  of  Computer  Science,  University  of 

Maryland, College Park, MD 20742. 

S .  Kraus and J. Minker are with the Department of  Computer Science and 
Institute for  Advanced  Computer  Studies, University  of  Maryland, College 
Park, MD 20742. 

IEEE Log 9144308. 

11.  COMBINING KNOWLEDGE  BASES 

We  assume the knowledge bases to be logic programs with 
integrity  constraints  associated  with  the  program.  A  logic 
program  consists of  a finite set of  clauses of  the form 

where the expression on  the left-hand side of  the implication 
is a disjunction of  atoms and the expression on the right-hand 
side  is  a  conjunction  of  literals.  When  n  is  1, we  call  it  a 
normal logicprogram and we call a normal logic program, a 
Horn logic program when the literals in the right-hand side are 
all atoms.  When  n  is greater  than  1, we  call  it  a  disjunctive 
logic  program. 

A. Combining Logic Programs 

Suppose  we  consider  the  problem  of  combining  several 
logic programs without integrity constraints. In order to com- 
bine  the  logic  programs  one  may  take  their  union,  i.e.,  all 
information  available  from  all  of  the  logic  programs  are 
combined  into  a  single  program.  It  is  easy  to  see  that  this 
union  is  consistent. 

then TI U  . . U Tk  is consistent. 

Theorem 1: If  T I ,  . . . , ‘Tk  are general Horn  logic programs 
U 
Consider two logic programs TI and T2  that contradict each 
other, i.e., using one we can derive P ( u )  while in the other we 
may derive l P ( u ) .  (Note: By “derive’’ we refer to an SLDNF 
derivation [13].) As shown in Theorem 1, T I  UT2 is consistent, 
and therefore even in such a case it is reasonable to combine 
them by taking their union. In the union of the two theories we 
might derive P ( u )  or we might derive - P ( u ) .  This is because 
the minimal model of  T I  U T2  is not necessarily the union of 
and P2, due to nonmonotonicity of 
the minimal models of 
the semantics. We  explain this by  the following example. 

Example 2.1: Consider the following logic programs PI and 

P2 : 

PI  : 

abnormal(tweety) 
bird(tweety) 
bird(char1i) 

P2  : 

a bnormal(0strich) 
bird(tweety) 
flys(X) + bird(X), labnormal(X) 

We can derive Tflys(tweety) from PI and flys(tweety) from P2. 
But  from  PI U P2  we  can derive  lflys(tweety). On  the  other 
hapd,  from  both  PI  and  P2  we  can  derive  Tflys(char1i) but 
from PI U P2  we can derive flys(char1i). 

1041-4347/91/0600-0208$01.00  0  1991  IEEE 

BARAL et  al.: COMBINING  MULTIPLE  KNOWLEDGE BASES 

209 

B. Handling Integrity Constraints 

In  real  world  applications,  integrity  constraints  restrict  a 
knowledge  base to  a particular  meaning  [16]. In  the presence 
of  integrity  constraints,  the  union  of  a  set  of  logic  programs 
can violate an integrity constraint, even though each individual 
logic  program  does  not  violate  it.  Hence,  in  the  presence 
of  integrity  constraints,  the  union  of  logic  programs  may 
not  always  be  the  correct  way  to  combine  the  theories.  For 
example if  we have fatherof(ken,nick) in T I ,  where fatherof& 
Y) denotes  that  Y is  the  father  of  X ,  and futherof(ken,george) 
in T2, and we take the union of  the two theories, then although 
the  union  is  consistent,  it  violates  an  integrity  constraint  that 
characterizes fatherhood, which states that, “one person cannot 
have  two  fathers,”  even  though  both  TI  and  T2  individually 
satisfy the integrity constraint. To combine theories TI and T2, 
we can choose one of  them and include  it in  the combination, 
we  can  partially  favor  one  theory  and  combine  them  as 
fatherof(ken,nick)+  lfatherof(ken,george) or we can combine 
them  as futherof(ken,nick)V  fatherof(ken,george). In  the  last 
situation  we  do  not  prefer  any  theory,  and  give  the  user  the 
freedom  to  choose  the  appropriate  model  from  the  various 
models  suggested  by  the  combined  theory.  A  normal  clause 
representation  of  the  last  approach  would  be  the  unstratified 
clauses 

futherof (ken, nick) + Tfatherof(ken, george) 

futherof ( k e n ,  george) + lfutherof (ken. nick) 

Semantics  of  such  unstratified  logic  programs,  have  been 
proposed  in  [3],  [26],  [22], and  [lo]. We  do  not  explore  this 
possibility  in  this  paper. 

C. Possible Solutions 

As noted  in  the previous  section  there are different options 
available  to  combine  alternative  theories.  The  following  are 
the  major  possible  alternatives. 

1)  An  Oracle  exists  which  knows  everything.  Whenever 
a  contradiction  between  theories  exists,  a  decision  as 
to  what  to  include  in  the  combination  is  determined 
according  to  the  Oracle, which  may  support  one  of  the 
theories  or  neither. 

2)  A partial order exists between all possible pairs of  <the- 
ory,  concept>. In  case  of  a  contradiction  between  two 
theories relative to a specific concept, in the combination 
we  may  always  select  data  from  the  preferable  theory 
with respect to this concept. For example, <cardiologist, 
cancer>  5  <oncologist, cancer>.  That  is,  the  cancer 
specialist  (called  ‘‘oncologist’’) knows  at  least  as  much 
as  the  cardiologist  about  cancer  and  so we  might  trust 
his  beliefs  about  cancer  rather  than  the  cardiologist’s 
view.  A  syntactic method  based  on  this  is  discussed  in 
Section  IV-C. 

3)  In the extreme case we might define a fact to be unknown 
when  the  facts  in  the  two  knowledge  bases  contradict 
one another. We want to remark that to define a concept 
as  unknown  is  different  than  not  to  include  it  in  the 

combination.  If  we  do  not  include  it  in  the  knowledge 
base,  in  logic  programs  we  will  be  able  to  derive  the 
concept’s  negation.  In  order  to  be  able  to  implement 
such  an  approach  one  needs  to  move  to  three-valued 
logic  [22],  [3],  [8],  [9] or  to  protected  circumscription 
[ 171-[ 19 1. 
A  maximal  amount  of  consistent  information  could 
be  combined  from  alternative  theories.  In  case  of  a 
contradiction,  the  information  could  be  combined  to 
make the knowledge base consistent by converting it into 
a disjunctive knowledge base. This knowledge base may 
be presented to the user and he might choose among the 
disjunctive  facts. 

4) 

Creating  an  Oracle,  as  suggested  in  the  first  approach,  is 
almost  impossible,  especially  while  dealing  with  distributed 
knowledge bases. There are some technical problems, but there 
are  also  some  essential  problems,  such  as  who  knows  the 
truths  to  supply  to  the  Oracle.  We  may  not  have  the  priority 
information  available  so  that  the  second  approach  might  not 
be  possible.  When  we  define  a  concept  as  unknown  we  lose 
information  that  existed  in  the  original  knowledge  bases;  so 
the  third  option  may  be  questionable. 

In  this  paper,  we  take  the  last  approach,  where  we  maxi- 
mally  combine  the  set  of  knowledge  bases  subject  to  consis- 
tency  with  the  integrity  constraints.  We  also  note  that  there 
is  another  option  possible,  where  the  user  decides  what  is  to 
be  done. 

111.  BASIC DEFINITIONS 

Recently,  several  different  semantics  have  been  given  to 
logic programs  [26], [22], [lo], [3]. In the  case of  Horn logic 
programs  without  negation,  it  is  well  known  [25],  [2]  that 
there  exists  a  unique  minimal  model.  This  model  is  used  as 
the  meaning  of  the  program.  In  the  case  of  stratified general 
Horn  programs,  there  is  a  single  perfect  model  [23],  [ l ]  and 
this model is used  as the meaning of  the program. In the case 
of  stratified disjunctive logic programs we use its set of perfect 
models as its meaning. We  call  the set of  perfect models  of  a 
stratified disjunctive program P ,  as MlNSET(P). In this paper, 
we  only  consider  stratified programs  and  further  assume  that 
the  union  of  the  theories to be  combined  is  also stratified. 

Definition 3.1:  Given  a program  P, HERB(P) denotes  the 
(possibly infinite) set of  clauses which are ground instances of 
program clauses  in  P. 

0 

The  definition of  perfect  model  is  based  on  a partial  order 
between  minimal  models.  The  partial  order between  minimal 
models  is  based  on  a  partial  order  between  elements  of  the 
Herbrand  base  of  the  program  P ,  dictated  by  the  position  of 
literals in HERB(P). We now define this partial order formally. 
Definition  3.2:  Definition  of  <  and  5 ,  from  [21]:  The 
< and  5  relation  between  atoms  of  the  Herbrand  base  of  a 
program  P ,  are defined based  on  their position  in  HERB(P). 
1)  G  <  B ,  if  4 3  is  a  negative  literal  in  the  body  of  a 

clause  in  HERB(P),  with  C  in  the  head. 

2 )   C 5 B ,  if  B is a positive literal in  the body  of a clause 

in  HERB(P),  with  C  in  its  head. 

210 

IEEE  TRANSACTIONS ON  KNOWLEDGE  AND DATA ENGINEERING, VOL.  3, NO. 2,  JUNE  1991 

3)  C 5 B  and  B  5 C, if  B  and  C are in  the  head of  the 

same  clause in  HERB(P). 
4)  A L B , B i C + A 5 C .  
5 ) A 5 B , B < C + A < C C .  
6)  A  < B  + A  5  B. 
7)  Nothing else satisfies < or  5. 

0 

Since, we are considering only stratified programs, the relation 
< is  a  partial  order. 

Definition 3.3: Relation between  minimal  models [21]: Let 
M and  N  be  two  distinct models.  We  say  N  <<  M  (N is 
preferable to M) if, VA(a ground atom) in N - M, 3 a ground 
atom B  in  M - N, such that A < B .  
Example 3.1: Consider the program 

0 

A e i B  
C e T D .  
It  has  four  minimal  models  { A , C } ,  { A , D } ,  { B , C } ,  and 
{ B ,  D } .  
Using the  definition for the  relation <, we  have  A < B  and 
C < D  
Consider the models { A ,  C} and { A ,  D } .  Since C < D, hence 
we  have  { A ,  C} <<  { A ,  D } .  

Definition 3.4: Definition of MZNSET(P): The MINSET(P) 

o 

of a program P  is a set of  minimal models of P, such that 

1)  Vx  (x is a minimal model of  P + 3y, y E MINSET(P) 

and  y <<  x). 

0 

2)  Vx, y (x, y E MINSET(P) and z # y + x # y, y 

x). 

Example  3.2: In  the  last  example  we  have  { A ,  C}  << 
{ A , D } ,  { A , C }  <<  { B , C } ,  { A , C }  <<  { B , D } .  Hence, 
MINSET(P) = {  { A , C }  }. 
0 
The  syntax  of  integrity  constraints  we  use  is  similar  to 
that  used  by  Sadri  and  Kowalski  [12]  and  Chakravarthy, 
Grant,  and  Minker  [4].  Integrity constraints  are  of  the  form 
c L1,. . . , L,,  m  >  0,  where  the  Li  are  literals  and  all 
variables  are  assumed  to  be  universally  quantified  in  front 
of  the  constraint  in  which  they  occur.  Such  clauses  are 
called  denials.  When  Li  are  restricted  to  be  only  atoms 
we  call  it  a  positive  integrity  constraint.  Denials  have  to 
be  range  restricted,  that  is,  any  variable  that  occurs  in  a 
negative literal of  the constraint must also have an occurrence 
in  a  positive  literal  of  the  constraint.  Sadri  and  Kowalski 
[12]  show  that  integrity  constraints of  this  form  are  general 
enough  to  represent any  closed  first-order formula using  the 
transformations suggested in  [12]  and  [14]. 

There are several different definitions of  integrity constraint 
satisfaction  in  a  database  or  knowledge  base  [12].  The  two 
main  definitions are the theoremhood definition and  the  con- 
sistency  definition.  Let  P be  a  program  and Sem(P) be  the 
semantics  of  the  program.  According  to  the  theoremhood 
definition, program  P satisfies an  integrity constraint I iff  I 
is true in  Sem(P).  According to  the  consistency definition P 
satisfies I iff  Sem(P)  U I is consistent. The two  approaches 
are  the  same  when  the  program  is  complete.  A  program  P 
is  said  to  be  complete  with  respect  to  a  semantics,  Sem(P), 
when for any formula W, either W is true in Sem(P) or W is 
false in  Sem(P). Most papers that deal with the theoremhood 

approach use Comp(P), Clark's  completion of  a program  [5], 
as  Sem(P). 

We  use  Sem(P)  as  the  perfect  model  of  the  program,  if 
the  program  is  a  normal  program  and,  as  we  are  dealing 
with  stratified programs,  they  have  a  unique  perfect  model. 
When  the  program  is  a  disjunctive program  we  use  the  set 
of  minimal  models  defined  as  MINSET(P)  as  Sem(P).  In 
the  case  of  normal  programs,  P  is  complete  with  respect 
to  Sem(P),  and  hence  there  is  no  difference  between  the 
consistency  and  the  theoremhood  definition  with  respect  to 
our definition of Sem(P). In the case of  disjunctive programs 
we  use  the  consistency definition. 

Definition 3.5 Consistency:  A  theory  T ,  where  T  may  be 
disjunctive, is  said  to  be  consistent  with  respect  to  a  set  of 
integrity constraints IC,  iff  every minimal model of  T  that is 
present in  MINSET(P)  satisfies the integrity constraints.  0 
Definition 3.6: The 5 relationship between theories: Let TI 
and T2  be two theories (possibly disjunctive). We say TI 5 T2 
iff Vx : x E MINSET(Tl), 3y : y  E MINSET(T2) and 
x G Y. 

Definition 3.7 Maximality: A theory T, is said to be maximal 
among a set of theories {TI . . Tn}, iff there does not exist j, 
such that  1 5 i,j 5 n  and T, 5 T j .  

0 

o 

Definition 3.8 Correctness: A theory T is said to be correct 
withrespecttotheoriesT1,...,Tk,ifT5T1U...UTk .  0 
Definition 3.9 Combination of  Theories: Let  T I ,  . +  , Tk  be 
a set of  theories and IC be a set of  integrity constraints, where 
each T, satisfies IC. The combination function C maps from a 
set of  theories and  a set of  integrity constraints into a theory. 
It  should satisfy the following four properties. 

1)  (identity)  C(T, IC)  = T .  
2)  (commutativity) C(T1,. . . , Tz-1, T,,  . . , T j ,  T,+i, . . . , 

Tk, IC) = C(T', .. . , Z - 1 ,  Tj, . . *  >Ta,Tj+1, 
IC). 

3 )   (consistency)  C(T1, . . . , Tk, IC)  is  consistent  with  re- 

spect  to  IC. 

4)  (correctness) C(T1, . . . , Tk, IC) is  correct  with  respect 

to  the  theories  T I ,  . . . , Tk. 

Another  useful  property  is  associativity, which  is  defined 

as  follows.  C(Tl,. .  , T3, C(Tj+l,. . . , Tk, IC), IC)  =,, 
C(Ti, *  . . , TjC(T'+i,. . * ,  Tk), IC, IC)  =mm  c ( T i , .  . . , Tk, 
IC), where P =,, 

Q means MINSET(P) = MINSET(Q). 0 

Our  goal  is  to  combine  a  set  of 

theories  such  that 
C ( T l , .  . . , Tk,  IC)  is  maximal  among  all  consistent  and 
correct combinations of  T I ,  .  . , T,,. The  intuition behind  the 
maximality property is that we would  like the combination of 
the theories to  include as much  information as possible from 
all  theories. The  intuition  behind  the  correctness  is  that  the 
combination will  not  include  new  information that  does  not 
have a basis in  the union.  Consider the following example. 

Example 3.3:  Consider two  theories TI = { A }  and  T2  = 
{B} and  the  integrity constraint c A, B. In  the  absence of 
any priority information, there are three consistent and correct 
combinations of  TI and  Tz. 

1)  The combination whose only minimal model  is  { A } .  
2)  The combination whose only  minimal model is {B}. 

B A R K  et  al.:  COMBINING  MULTIPLE  KNOWLEDGE BASES 

211 

3 )   The combination  that has two minimal  models  {A} and 

{ B } .  

By  definition  of  maximality  the  third  combination  is  the 
maximal  combination.  Our  goal  is  to  develop  algorithms  to 
combine  theories maximally. 

Theorem 2:  Let  T I ,  . . . . Tk  be  a  set  of  theories  and  IC  be 
a set  of  positive  integrity constraints.  There  exists  a maximal 
combination  of  7’1,  . . . , Tk.  All  such  combinations  have  the 
same  set  of  minimal  models. 

0 

Proof: Consider the set of minimal models in MINSET(Tl 
U . . . U Tk). Let  them  be  ml. . . . . m,.  Divide  these  minimal 
models  so  as  to  obtain  a  set  of  maximal  models,  such  that 
none  of  the  maximal  models  violate  any  integrity  constraints 
in IC. For example, if m, = {A1 . . . A,} 
is one of  the original 
minimal models, and t A1 . . . A,  where  T  5 n is an integrity 
constraint  in  IC,  then  m  is  divided  to  the  set  of  maximal 
mod e 1 s : 
{Al,...,A,-l,Ar+l .‘.A,},  { A l , . . .  .Ar-2,Ar,Ar+l  ” ‘  
A , }  . . . {A2.. . . , A,+1  . . . A , } .  After dividing the original set 
of  minimal  models  so  as  to  be  consistent  with  respect  to  all 
the  integrity  constraints,  suppose  we  obtain  M  = mi, . . . m: 
as the set of  maximal models. We claim that any theory which 
has  its  minimal  models  as  M ,  is  a  maximal  combination  of 
Ti, . *  *  , Tk. 

Suppose  this  is  false,  i.e.,  3M‘: M  5  M‘,  and  M‘  is  a 
combination  of  TI, . . . , Tk. Since,  M  5 M‘,  32. y  : x E  M 
and  y  E  M‘  and  x c y.  Since  M’  is  correct  (a  property  of 
all  combinations),  3i 1 5  i  5  s  : y  E  m,.  Since,  x c  y, 
x  m,, i.e.,  x is  obtained  from  m,, while  dividing  m, to 
make  it  consistent  with  respect  to  the  integrity  constraints. 
Since the division creates a set of  maximal consistent  models, 
x c y  implies  y  is not  consistent  with respect  to  the integrity 
constraints.  Hence,  M’  is  not  consistent  with  respect  to  the 
integrity  constraints  and  hence  it  is  not  a  combination.  This 
contradicts  our  initial  assumption  that  M’  is  a  Combination 
of  TI.. . +  . Tk, and  hence  M  is  the  maximal  combination  of 
T i , .  . ’ ,  T k .  

0 

Iv.  COMBINING  A  SET  OF  BELIEF SYSTEMS 

In  this  section  we  give  algorithms  to  maximally  combine 
a  set  of  normal  logic  programs.  First  we  give  algorithms  to 
combine  theories  that  contain  only  facts,  then we  allow rules 
without negation in their body  and finally we consider normal 
logic  programs. 

Throughout  the  rest  of  the  paper  we  assume  that  the 
SLDNF-proof  tree  when  an  integrity  constraint  is  considered 
as a query, with respect to the union of the theories, is finite. A 
sufficient restriction for having finite SLDNF proof trees is that 
the  theory  be  function-free  and  hierarchical.  By  hierarchical, 
we mean that the theory does not have any recursion. We also 
assume that integrity constraints do not have negation in their 
body. 

A .  Combining Theories Consisting Only of  Facts 

Our  initial  assumption  is  that  theories  consist  only  of 
facts.  Consider  a  simple  case  where  TI  consists  of  P(a) 
and  T2  consists  of  P(b), and  the  integrity  constraint  is  t 

P ( X ) ,  P ( Y ) ,  X  # Y .  In the absence of  any information about 
preferences  we  can  combine  these  two  theories,  without  the 
combination  ( T )  violating  the  integrity constraint  and without 
preferring  one theory over  the  other, by  placing  only  P ( a )  V 
P(b) in  the  combination  T ,  of  the  two  theories.  The  theory 
T  has  two  minimal  models:  one  is  { P ( n ) }  and  the  other  is 
{W ) } .  

Before  presenting  our  algorithm  we  first  show, through  an 

example,  how  a combination  is  achieved. 

Example 4.1: Let  TI  def  { P ( a ) :  P(b)},T* def  { P ( c ) } ,  and 
the integrity constraint be  +--  P ( a ) .  P(b), P ( c ) .  The combined 
theory  has  to  satisfy  the  logically  equivalent  integrity  con- 
V  +(b)  V  -P(c). To  be  maximal,  we  want 
straint,  + ( U )  
the  least  number  of  atoms  to  be  false  in  the  combination.  In 
other  words,  we  want  the  least  number  of  negative  literals 
to  be  true.  We  rename  the  negative  literals  in  the  clauses 
obtained  by  transferring  atoms  to  the  left  in  each  of  the 
integrity  constraints.  We  rename  ~ P ( u )  as  P’(u) and  others 
in  a  similar  manner.  After  renaming  we  obtain  the  clause 
P’(u) V P’(b) V P’(c). This clause has three minimal models, 
{ { P ’ ( u ) } ,  {P’(b)}, { P ’ ( c ) } } .  The  minimal  model  { P ’ ( u ) }  
means P’(u) is true, and others are false; that means  +(U)  is 
true and all other negative literals are false, which means P ( a )  
is false, and  all other  atoms  are true. Each  minimal  model  of 
the  renamed  clauses  corresponds  to  a maximal  model. 

Hence, we take the integrity constraints and form clauses by 
transferring  the  atoms  to  the  left.  Next  we  rename  the  atoms 
in  the  clauses.  We  find  the  set  of  minimal  models  for  the 
renamed  clauses.  Since each minimal model  corresponds  to  a 
maximal  model,  we  collect  the  set  of  these  maximal  models. 
We  then construct  a theory whose minimal  models are the set 
of  maximal  models.  The  theory  constructed  is  the maximally 
combined  theory. 

In this example, the minimal models of  the renamed theory 
are  { { P ’ ( a ) } .  {P’(b)}, {P’(c)}}. The  maximal  model  corre- 
sponding  to  {P’(u)} is  { P ( b ) ,  P ( c ) } ;  the  maximal  model 
corresponding  to  {P’(b)} is  { P ( u ) ,  P ( c ) }  and  the  maximal 
model  corresponding  to  {P’(c)} is  { P ( u ) , P ( b ) } .  The  the- 
ory, whose minimal models are { { P ( b ) ,  P ( c ) } ,  { P ( a ) .  P ( c ) } ,  
{ P ( a ) , P ( b ) } }  is  P ( u )  v  P(b), P ( a )  v P ( c ) ,  P(b) v  P(cL 
and is the combined theory which is consistent with respect to 
the integrity constraints. 

0 

It  should  be  noted  that  the  combined  theory  is  disjunctive 
in  the above  example. An answer to the query  t P ( X )  with 
respect  to  the  combined  theory  is  P ( u )  V  P(b), while  the 
answer  to  the  query  t P ( a )  is  “unknown.” 

We  now  give  an  algorithm  to  combine  a  set  of  theories 
consisting only of  facts, such that the resultant theory is correct 
with respect to the original theories, consistent with respect to 
the  integrity  constraints  and  is  a maximal combination. 
Algorithm 4.1 (To combine theories consisting only of facts): 
INPUT: 
1. A  set  of  k  Horn  theories  {TI . . .Tk} which  have  to  be 
combined, where  each T;  consists only of  facts. 
2. A set of  s  integrity constraints, IC = (IC1, . . . , IC,}  where 
each  integrity  constraint  is satisfied by  each  of  the theories. 
OUTPUT: 
A theory T ,  which is the maximal combination of the input set 

212 

IEEE  TRANSACTIONS ON  KNOWLEDGE AND  DATA  ENGINEERING, VOL.  3,  NO.  2,  JUNE 1991 

of theories, such that T is also satisfied by each of the integrity 
constraints. The combined theory T  can be  disjunctive. 
STEP 1: [Find  S, the set of instances of  integrity constraints 
that violate the union  of  the theories.] 
s = 0; 
For i = 1 to s do 
begin 

The  intuition behind  this  algorithm is  as follows; in  order 
for  the  combination of  the  theories to  be  consistent with  the 
integrity constraints, at least one negative literal of each clausal 
form of the integrity constraint has to be true in  each minimal 
model  of  the  combination.  On  the  other  hand,  in  order  to 
make the combination maximal one needs to  minimize those 
negations. 

Let  IC,  be  of the form  +-  P l ; . - , P k ,  where  P l , - . . , P k  
are atoms. 
Solve IC,  with respect to TI U . . . U Tk. 
(Note that, in the beginning of  this section we assume this 
to  be  decidable.)  If  there  are  no  solutions  then  continue 
with the next i, else: 
.01, be  all the ground answer substitutions when 
Let 01 
the IC,  is satisfied as a query  to the  union of  the knowl- 
edge  bases,  meaning  that  ICi  violates  the  union  of  the 
knowledge bases 
s = su{+ ( P l , * ‘ . P k ” l ; * ’ ’ ; +  (Pl,”’Pk)61z} 

end 
S  is the set of  instantiated integrity constraints which violates 
the  combined  theory  TI U . . . U Tk. If  S  is  empty,  then  the 
combined theory TI U.  U Tk  is consistent with respect to the 
integrity constraints and the algorithm terminates. 
If  S  is not  empty, continue with STEP 2. 
STEP 2:  [Obtain the set of minimal models of the transformed 
and  renamed  clauses  in  S  and  their  corresponding maximal 
model.] 
Let S be { C l , .  -  e ,
til, c z 2 ,  * 
by 
Let  { A l ,  . . . A,}  be  all ground  atoms  present  in  S. We  call 
this set the interfering facts. 
The  set  of  facts  that  is  present  in  TI U ..  U Tk  but  not  in 
{ A I ,  .  A p }  are called noninte@ering facts. 
Construct the  set  of  clauses  ( 4 1 1  V lC12 V  . . l C l k l ,  . . . , 
by  transferring the  atoms in  the 

 Cn}, where each C, (1 5 i 5 n) is defined 
’ 7  c z k l *  

V  1Cn2 V 

+ n k , }  

instantiated integrity constraints to the left of  the arrow. 
Rename the negative literals 1Ct3 by  C[3 in the  above set of 
clauses. 
Find  all minimal models of the renamed set of  clauses given 
by  { Cil v ci2 v . . +  Cik,, . *  *  , CL1 v CL2  v .  . cLkn } 
Let the minimal models be mE,, . . - , mi 
For i = 1 to 1 do 

m:  = m: withCi,  replaced byC,,. 

STEP 3:  [Obtain the  theory  whose  only minimal models  are 
the maximal models found in  STEP 2.1 
For i = 1 to 1 do 

m,  = { A 1 , . - * A p }  -mT 

Construct a theory T  (possibly  disjunctive) whose  only mini- 
mal models are ml - . - ml  by  doing the following. 
T = {x : x = fact(A1 V A2.  V A I ) ,  where for all i 5 1, A, 
is  in  mi}, where fact  is  a  function  that  removes  all but  one 
occurrence of  repeated atoms in  a disjunction. 
STEP  4:  [Obtain  the  combined  theory,  by  augmenting  the 
noninterfering facts.] 
Add  all the atoms in TI U T2  U  . -  U Tk  that do not appear in 
{ A l ,  . . . A,}  from STEP 2 to T, and call it C(T1,  . , Tk, IC). 
0 

We  demonstrate this algorithm by  some examples. 
Example 4.2:  We  first  show  Example  4.1  with  respect  to 
this algorithm. 
Let  TI %?f  { P ( u ) ; P ( b ) } ,  T2  ef { P ( c ) } ,  and  the  integrity 
constraint be  t P(u), P(b), P(c). 
STEP  1: We  find that  the  integrity constraint t P(u),P(b), 
P(c) violates the union of  the theories. 
STEP 2:  We  transfer the  atoms  in  the  integrity constraint to 
the left and  rename the negative literals. The  resulting clause 
is  {P’(u) V  P’(b) V P‘(c)}. We  find  the  minimal  models  of 
P’(u) V P’(b) V P’(c) to be  {{P’(u)}, {P’(b)], {P’(c)}}. 
STEP 3: For  all minimal models found in  STEP 2 the corre- 
sponding  maximal  models  are  {{P(b), P(c)}, { P ( u ) ,  P(c)}, 
{ P ( u ) ,  P(b)}}. This is because for the minimal model {P’(u)} 
in  STEP  2  the  corresponding maximal  model  {P(b), P(c)}. 
This  is  further  explained  in  Example  4.1.  We  find  the  the- 
ory, whose minimal models are { { P ( b ) , P ( c ) } ,  { P ( a ) ,  P ( c ) } ,  
{ P ( a ) ,  P ( b ) } }  to be  P(a)V P(b), P(u) V P(c), P(b) V P(c). 
STEP 4: The  combined  theory  is  the  theory  found  in  STEP 
0 
3. 
{P(u)}, T2  sf {P(b)}, T3  $?if 
{ P ( c ) } ,  and the integrity constraint be  + P ( X ) ,  P ( Y ) ,  X # 
Y. 
STEP 1: After solving the constraint we find t P(u), P(b); t 
P(a), P(c) and  t P(b), P(c) to  be  the  instantiated integrity 
constraints that violate the union of  the theories. 
STEP  2:  We 
P’(b),P’(u) v P’(c),P’(b) v P’(c)} to  be  {{P’(u),P’(b)}, 
{P’(.)> P W } ,  {P’(b), P‘(c>}}. 
STEP  3:  We  find  the  theory,  whose  minimal  models  are 
{ { P ( c ) } ,  {P(b)}, { P ( a ) } }  to be  P(,)  v P(b) v P(c>. 
STEP 4:  The  combined  theory  is the  theory  found  in  STEP 
0 
3. 

find  the  minimal  models  of  {P’(u) V 

Example4.3:  Let  TI !Zf 

The following proves the correctness of  our algorithm. 
Theorem 3: C(T1,  . Tk, IC), as given by  Algorithm 4.1 is 

a  maximal combination of  “1  . . . Tk. 

Proofi 

a)  C(Tl, . . . , Tk, IC)  is  correct  because  all  atoms  in  its 

clauses  are satisfied by  TI U 

. U Tk. 

b)  C(T1,  . . , Tk, IC) is  consistent because all  its  minimal 
models, by  virtue of  its construction in STEP 3, do not 
violate the  integrity constraints. 
c)  Let  C  be  all  the  facts  in  TI U 

U Th. Let  B = 
{ A1 , . . . , A p }  be the ground atoms present in S in STEP 
2.  Let  A  = C - B. 

From STEP  1 of  the  algorithm, we  find that  the  atoms in  B 
cannot be all true in  the same model of  C(T1 U . . . U Tk, IC), 
because they violate the integrity constraints. 
In  STEP  2  of  the  algorithm  we  find  a  set  of  minimal  sets, 
where  each  minimal  set  has  the  minimal  number  of  atoms 

BARAL er  al.:  COMBINING  MULTIPLE  KNOWLEDGE  BASES 

213 

false for  the  integrity  constraints to  be  satisfied. 
Thus,  each  minimal  set  of  f a k e   atoms  is  equivalent  to  a 
maximal  set  of  true  atoms  that  can  be  true, while  still  not 
violating  the  integrity  constraints. 
Thus,  in  STEP  3  of  the  algorithm  we  split  B  into  a  set 
{ m l , .  . . , rnr) of maximal  models,  and we construct  T ,  which 
has  {mi, . . . , mr} as the  only  minimal  models. 
In  STEP 4 we  have  C(T1 U . .  . U Tk, IC)  = T U A .  
Now  assume that  our combination  is not  maximal, 
i.e.,  3T’  : C(T1 U . . . U Tk, IC) 5 T’  5 TI U ‘ .  . U Tk. 
==+ 3  a model m of c  : m c m’  and rn’ 
a rn = A+  mi, where  1 5 i  5 1. 
==+  mi  c m’  - A  
a But  since mi  is one of  the  maximal 
in  STEP 3), the  above cannot  be  true. 
a Such  a  T‘ cannot  exist  and  hence 
maximal. 

our  combination  is 

set (by  construction 

is a model of T’. 

0 

B. Combining Theories with Rules Without Negation in their Body 
We  now  extend  Algorithm  4.1  to  the  case  where  we  have 
rules in  the  theories. We  do not  allow negative  literals  in  the 
body  of  the  rules. 
Algorithm 4.2:  (To combine theories with Horn rules). 
INPUT: 
1. A  set  of  k  Horn  theories  {TI . . . T k }   which  have  to  be 
combined.  (Note  that  Horn  theories  do  not  have  negative 
literals  in  the  body  of  their  rules.) 
2. A set of  s integrity  constraints,  IC = { IC1. . . . ~  IC,}  where 
each integrity  constraint  is satisfied  by  each  of  the  theories. 
OUTPUT: 
A theory T ,  which  is the maximal  combination of  the input set 
of theories,  such that T is also satisfied by  each of  the integrity 
constraints.  The combined theory  T can  be  disjunctive. 
ASSUMPTIONS: 
Each of  the theories in TI . . . Tk  is Horn  and  consists of  facts 
and  rules  without  negation  in  their  body. 
STEP 1: [Find  S’  the  set of  instances of  integrity  constraints 
that violate the union of  the theories and for each such instance 
find the set of  interfering  rules.] 
s/ := 0; 
For i = 1 to  s  do 
begin 

Let  IC,  be  of  the  form  + PI.. . . , Pk, where  PI,. . . , P k  
are  atoms. 
Solve IC;  with  respect  to  T I  U . . . U Tk. 
(Note that we assume this to be decidable, in the beginning 
of  the  section.) If  there  are no  solutions continue with  the 
next  i ,  else: 
Let  01 , . . . , 6 j ,   be  the  ground  answer  substitutions for  the 
IC,;  and for  each ground answer  substitution  03, 
Let  R j  = { R j l , .  . . , Rjk} be  the set of  rules,  which  were 
used  to  obtain  the  ground  answer  substitution  B j ,   where 
their  heads  unify  with  one of  the  Pi’s. 
Let  Rji be  the rule  whose head  unifies with  Pi. 
S’ :=  S’  U  {<+-  (Pl,...,Pk)01,R1,81  >:..,<+ 
(Pi , . . . , pk)&, , RlZ , 01,  >>. 

end 

S’ contains the  instantiated  integrity  constraints that  are vio- 
lated  by  Ti  U . . . U T k   and  a set of  rules  for each,  that  has  to 
be restricted. 
The set of  rules present  in  5’‘ is called  interfering rules. 
The  set  of  rules  present  in  TI U . .  . U Tk  but  not  in  S/ are 
called  noninterfering rules. 
If  S  is  empty,  then  the  combined  theory  TI U . . .  U Tk  is 
consistent  with  respect  to  the  integrity  constraints  and  the 
algorithm  terminates.  If  S is not empty, continue with STEP 2. 
STEP 2: [Find  the  set  of  minimal  models of  the  transformed 
and  renamed  clauses  in  S and  their  corresponding maximal 
models.] 
S := the  first element  of  each  tuple  of  S’. (S contains the  set 
of  instantiated  integrity  constraints of  S’  in  step  1). Do STEP 
2 of  Algorithm  4.1. 
STEP 3: [Find the  theory  whose only  minimal  models  are the 
maximal  models found  in  STEP 2 
Do  STEP 3 of  Algorithm  4.1  and  let  the  theory  generated  be 
1 .1 
STEP 4:  [Find  the  resultant  theory  by  augmenting  the  nonin- 
terfering  facts.] 
T  :=  T  U  all  facts  in  TI U . . .  U Tk  that  do  not  appear  in 
{Al. . . . Ap} (see Algorithm  4.1). 
STEP  5:  [Find  the  resultant  theory,  by  augmenting  the  re- 
stricted  version  of  the  interfering  rules.] 
function  Restrict(R: a set of  rules,  0,: a variable  substitution): 
a set of  rules; 
begin 

- 1  

Restrict(R,  19,) := 0 
If  Oz  is empty  then  STOP 
else 
For  all  rules  R,  in  R  do 

Consider  the variables in the  head  of  R,  and the  sub- 
stitution  given by  0,. Let  X , 1 ,  . . . , X,k,  be variables in 
the  head  of  R,  and  t,l,. . . , t&, be  the  corresponding 
variable substitutions. 
Let  R,  be  head  t tail. 
Restrict(R,Q,) := Restrict(R,B,)  U 

{head  t tail, X,1 # t,l; . . .; head 

tail,  Xzk,  #  tzk,) 

end 
{This function  restricts  rules  with  respect  to  a variable  substi- 
tution.} 
Obtain  from  S’ the  pairs  < R ,  I9  > and  call  it ruleset. 
The ruleset  is  {< R I , &  > , . . . , <  Rt,0t >}. 
Let R  = {RI, . . . , Rt}. We call this set of  rules the interfering 
rules. 
Since there  might be multiple  instances of  the  same rule in R, 
for each rule T in R do Restrict(Restrict(.  . . Restrict(r, dv1) . . . 
0Ts-l)19Ts) where OT1 . . . OvS  are the  various variable  substitu- 
tions  associated  with  the  rule  T ,  in  ruleset. 
T  := T  U the collection  of  the  above restricted  rules. 
STEP 6: Find  the combined theory,  by  augmenting  the nonin- 
terfering  rules.  T  := T  U all the rules in Ti U . . . U Tk  that do 
not  appear  in  R. 
c(T1 U . . . U T k ,  IC) := T .  

0 

One  may  ask  why  we  restrict  the  rules  and  do  not,  for 
example, remove  the  facts that  are  used  in  order  to  solve  the 

214 

IEEE  TRANSACTIONS ON  KNOWLEDGE AND DATA  ENGINEERING, VOL.  3,  NO.  2,  JUNE 1991 

integrity constraints. This  is  because  we  want  to  gain  maxi- 
mality. Taking out the facts will restrict the combined theory. 
On the other hand, by  restricting the rules, and minimizing the 
negations of  the facts of  the integrity constraints, and leaving 
as  much  information  as  possible  from  the  original  theories, 
we  obtain  a  maximally combined  theory  consistent  with  the 
integrity  constraints. 

The following example illustrates the above algorithm. 
Example  4.4: Consider  the  integrity  constraint  t P ( X ) ,  

P ( Y ) , X  # Y ,  and  the  theories TI  and T2. 

Step  1: When  we  solve  the  integrity  constraint  as  a  query 
we  find  that  it  is  violated  when  x = U and  y  = b. So  the 
instantiated integrity constraint is  t P(a), P(b) and  the two 
rules  that  are used  are  P ( X )  t R ( X )  and  P ( Y )  t Q ( Y ) .  
In  the  representation given  in  STEP  1  of  Algorithm  4.2 we 
obtain  S'  = {<e P ( u ) , P ( b ) , { P ( X )  c R ( X ) , P ( Y )  t 
Q ( Y > } ,  { X / a 7 Y / b )  >I. 
Step 2 and 3 gives us T = P(u) V P(b). 
In Step 4 we do not have any noninterfering facts to be added. 
In Step 5 we  add the restricted rules  P ( Y )  t Q ( Y ) , Y  # b 
and  P ( X )  t R ( X ) , X  # a  to  T. After we  add  the facts  in 
T1U  T2  that are absent in T ,  we get C(Tl, T2, IC) as 
P ( a )  " P(b) 

R(a) 
Q ( b )  
P ( Y )  + Q ( Y ) , Y  #  b 
P ( X )  + R ( X ) , X  #  a. 
The  above  combined  theory  has  the  minimal  models 
{ P ( a ) ,  R(a), Q ( b ) }  and { P ( b ) ,  R(a), Q(b)}. The union of the 
original  theories  has  the  minimal  model  { P( a) , P( b) ) R( a ) ,  
Q(b)} and  since  the  instantiated  integrity  constraint  is  t 
P ( a ) ,  P(b), we  observe  that  indeed  this  algorithm  gives  a 
maximal and consistent combination of  the theories. 

Theorem 4: C(T1 , . . , T k ,  IC) as given by  Algorithm 4.2 is 

0 

a  maximal combination of  TI ,  . , Tk. 

Proof: 

a) C(T1 , . . , T k )  IC) is consistent because, for all satisfiable 
instances of  integrity constraints t (PI, . , Pk)@ we restrict 
the rules (in  STEP 5) which  expand PI@, . , Pke,  and add  a 
set of  disjunctive facts in STEP 3, to make sure they  are not 
satisfied by  the  resulting combination. 

b)  C(T1,  . . , T k  , IC) is correct because, besides restricting 
the rule, the disjunctive fact we add has all its minimal models 
as a  subset  of  TI  U . 
c) (maximality) 

U Tk. 

.

  U  T k .   (Note  that 

Let  C  be  the  minimal  model  of  Tl  U a -
2'1  U  .  U T k   is a Horn theory.) 
Let  B = {AI,  . , Ak} be  the  ground atoms present  in  S in 
STEP 2. 
In  STEP  5  by  restricting  the  rules  we  make  sure  that 
atoms  in  B  cannot  be  proven  using  those  rules.  Also  it 
is  clear  that  atoms  in  C  - B  belong  to  all  models  in 
MINSET(C(T1,  *  *  ) T k ,  IC). 
Let  A =  B - C  

Similar to Algorithm 4.1 we  split B  into a  set  { r n l ,   . , r n l }  
of  maximal  models  and  construct  T  in  STEP  3 which  has 
{ r n l , . . .  , rnr}  as  the  only  minimal  models.  The  rest  of  the 
proof  is the same as in  the proof  of  Theorem 3. 
U 

C. A  Syntactic Approach 

Several syntactic methods have  been  suggested to  compile 
integrity  constraints  into  a  deductive  database  [ll], [4].  In 
these  approaches,  the  integrity  constraints  are  embedded  as 
part  of  the  deductive  rules  and  the  integrity  constraints  are 
no  longer needed.  Normal  clauses  result  in  the  theory  com- 
bined  with  the  integrity  constraints.  It  would  then  appear 
that  multiple  knowledge  bases  might  be  combined  syntac- 
tically  by  compiling  the  integrity  constraints  to  their  union 
using  the  methods  suggested  in  [ll] and  [4].  We  show  by 
a  counterexample  that  this  approach  does  not  provide  the 
desired result. We  first describe Kowalski and Sadri's  method 
[ll] and  then  give  counterexamples  to  show  why  such  a 
syntactic  approach  cannot  be  used  to  combine  knowledge 
bases. However,  applying Algorithm  4.2 to  the  union  of  the 
theories provides the  desired result. 

Kowalski  and  Sadri  in  [ll] give  a  method  to  compile 
integrity  constraints  inside  a  theory.  They  assume  that  one 
atom in every integrity constraint is more preferable than the 
rest of the atoms. They call it the retractable atom of  the theory. 
Algorithm 4.3 (Kowalskidadri algorithm) 
INPUT: A theory T, and a set of s integrity constraints, IC = { 
IC1,  . . , IC,  } where for each integrity constraint a retractable 
atom is specified. 
OUTPUT:  Revised  theory  that  satisfies all  the  integrity con- 
straints in  IC. 
MAIN STEP: For i =1  to  s,  Call Eliminate(T,  IC,). 
Procedure Eliminate(T:  Theory,  IC:  an  integrity  constraint 
with  its retractable atom specified); 
{Comments: T is the input theory and also the revised theory 
that is output.} 
begin 
If  t A(t),Conj  is  the  integrity  constraint,  where  A ( t )  is 
retractable,  to  eliminate  it  by  compiling  it  into  the  rules, 
replace  each deductive rule in T of  the  form A(t') t Conj' 
by 
1. A@')@ t Conj'B,  TConjB, where B  is the mgu of  A(t) and 
A(t'). 
2. A(t')  t Conj',  t # t', where t'  is an instant of  t. 
end 

0 

The following example explains this  technique. 
Example 4.5:  Let  the  theory  be  P ( X )  c Q ( X )  and  the 

integrity  constraints be 

IC1  : t P ( Y ) , R ( Y )  
IC2  : + P(b),S(c). 

When  we  eliminate  IC1,  the  retractable  atom  P ( Y )  in  IC1 
unifies with  the  head  of  the  rule  P(X) t Q ( X )  and  after 
elimination we obtain the rule P ( X )  t Q ( X ) ,  i R ( X ) ,  using 
STEP 1 of  the procedure Eliminate. When we  eliminate IC2, 
we  have 

P(b) t Q ( b ) ,  i R ( b ) ,  lS(c), by  STEP 1 of  the method and 
P ( X )  t Q ( X ) ,  i R ( X ) ,  X  # b,  by STEP 2 of the method. 

0 

- 

BARAL  et  al.:  COMBINING  MULTIPLE  KNOWLEDGE  BASES 

215 

If we are given a preference relation  between  atoms through 
retractable  atoms  in  each  integrity  constraint,  we  can  use 
Kowalski and  Sadri’s  syntactic method.  We  initially  assumed 
that  we  are  not  given  any  such  information.  In  that  case, 
one  may  think  that  to  compile  the  integrity  constraint  t 
P ( u ) , Q ( b ) , R ( c )  when  the  retractable  atom  is  not  given, 
we  compile  three  integrity  constraints  t P ( u ) ?  Q(b). R(c), 
+  Q(b), P ( u ) ,  R(c), and  +  R(c), Q ( b ) .  P ( a )   where  the 
first  atom  in  each  is  the  retractable  atom.  We  show  by  a 
counterexample  that  such  a  syntactic  method  of  compiling 
each integrity constraint a multiple number of  times, each time 
assuming  a  different  atom  as  retractable  does not  necessarily 
provide  a  consistent  combination. 

Example  4.6:  Consider  combining  four  theories  each  con- 
sisting of  a single fact, A; B; C; D ,  respectively,  and  the  set 
of  integrity  constraints  IC =  {  +- B ,  D  ; t A. B ; t A, C}. 
After eliminating all versions of  the  integrity  constraints from 
the union of the theories, we obtain P  = {A +-  -B. 4’; B  t 
1 D .  TA; C t T A ;  D  t -B}. One of the minimal models in 
MINSET(P),  {A, B}, violates  the  integrity  constraint. Hence, 
the  syntactic  approach  does not  provide  the  desired  result. 

Using  Algorithm  4.2 we  generate  the  theory  { A  V  C ;  D  V 
C ; D  V B} whose  minimal  models  are  { A . D } ,  { C . D } ,  and 
{ B .  C} and they  all  agree with  the  integrity  constraint.  0 

D. Incremental  Combination of  Theories 

In  the  previous  sections  we gave  algorithms  to  maximally 
combine  a set  of  theories,  which  do not  have  negation  in  the 
body  of  the rules of  the theory, so that the combination of  the 
theories  is correct  and  consistent.  Consider the  case when we 
have  combined  the  theories  T I ,  . . . , Tk  to  obtain  a  possibly 
disjunctive  theory  T ,  and  we  obtain  another  set  of  theories 
Tk+1,. . . . T,  to  be  combined  with  the  initial  set  of  theories. 
We  would  like  to  combine  the  partially  combined  theory  T 
with the new set of theories so as to obtain an equivalent theory 
to the  one we would  have obtained  if  we had  started  with  the 
theories  T I ,  . . . . T,.  But  now  we  cannot  use  the  combining 
algorithm  given  in  the  previous  sections.  They  can  only  be 
used  to  combine  Horn  theories  without  negation;  and  in  this 
case T could be a disjunctive theory. We consider this problem 
in  the  following  subsection. 

I )  Integrity  Constraints  and  Disjunctive  Theories:  A  dis- 
junctive  theory  has  multiple  minimal  models.  As  defined 
before,  we say  a disjunctive  theory  satisfies an  integrity  con- 
straint if  it is satisfied in all minimal models of  the disjunctive 
theory. To combine theories we have to first determine whether 
or  not  the  naive  union  of  the  theories  violates  the  integrity 
constraints.  Note  that  although  the  algorithms  in  previous 
sections  generated  a  disjunctive  theory,  they  made  sure  that 
the  integrity  constraints  were  satisfied. 

Definition 4. I  Semantic Definition:  A  disjunctive  theory  is 
said to violate  an integrity  constraint, iff  it is violated in  some 
minimal model. 

Let  IC  :  t PI.. . . . Pk  be  an  integrity  constraint  and 
T  be  a  theory.  If  T  is  a  Horn  theory  then  T  violates  IC 
if  t P I .  . . . , P k   has  a  solution  with  respect  to  T, i.e.,  T 
j 3(P1,. . . , Pk). But if  T has more than one minimal model 
or  it  is  a  disjunctive  theory  this  is  not  the  case.  If  T  is  a 

0 

disjunctive  theory  t PI, . . . , P k   will  have  a  solution  with 
respect  to  T  iff  t P I ,  . . . . P k  has  a  solution  in  all minimal 
models of T ;  while t P I ,  . . -  . Pk  violates T iff 
P I ,  . . . , Pk 
has  a  solution  in  at  least  one  minimal  model  of  T .  It  may 
therefore  be  seen  that,  determining  if  an  IC  is  violated  by  a 
disjunctive  theory  is  not  trivial. 

0 

Definition 4.2 Syntactic Definition: A query  t Q is true  in 
at least one minimal model of  a theory  T  iff  3 K ,  where K  is 
clause  (possibly  nil) and T  k Q V K  and  T  y K .  

The  proof  of  the  equivalence  of  the  syntactic  and  seman- 
tic  definition  of  a  disjunctive  theory  violating  an  integrity 
constraint  is  similar  to  the  proof  of  the  equivalence  of  the 
syntactic  and  semantic  definition  of  Minker’s  GCWA  [ 151. 
The algorithm  to determine  if  a disjunctive  theory  violates  an 
integrity  constraint  can  easily  be  constructed  using  the  above 
syntactic definition and Minker and Rajasekar’s [20] algorithm 
to solve a negative ground  query with  respect to a disjunctive 
theory. 

But  even  after  finding  all  instances  of  the  integrity  con- 
straints  that  violate  the  disjunctive  theory,  we  do  not  know 
which particular  minimal model  is violated. Without knowing 
the  particular  minimal  model  violated,  it  is  difficult  to subdi- 
vide  those  particular  minimal  models  violated,  into  a  set  of 
maximal  nonviolating  models.  This  is  not  a  problem  in  the 
case of  Horn  theories as there is only a single minimal model. 
The  following  algorithm  explains  semantically  what  we 
mean  by  a  combination  of  disjunctive  theories.  In  this  algo- 
rithm  we  start  with  the  set  of  minimal  models  of  the  union 
of  the  theories,  and  start dividing  these  minimal  models such 
that  we  get  a set of  maximal  models, such  that  none  of  these 
maximal  models violate the  integrity  constraints. We  call this 
algorithm  a  semantic  algorithm  because  we  do  not  have  an 
algorithm  to  find  which  integrity  constraints  are  violated  by 
which  minimal  model.  With  the  hope  that  such  an  algorithm 
can  be  found  later,  we  present  the  following  algorithm.  We 
also hope the  following  algorithm will  be used  as a guideline 
to  a  more  practical  algorithm. 
Algorithm 4.4 (Semantic Combination of  disjunctive theories) 
INPUT: A set S  = { T I .  . . . . T k }  of  IC  disjunctive theories and 
IC =  { I C l , .  . . . IC,},  a set  of  n integrity  constraints. 
OUTPUT:  A  combined  theory  of  the  k disjunctive  theories, 
such that it satisfies all the integrity constraints and is maximal. 
STEP 1: Find  all  minimal models of  TI U . . . U  Tk. 
Let  the  set of  minimal models be  m = { m l ,  . . . . mt}. 
STEP 2: ti := t; 
For  L  =1 to  iz  (there  are  n integrity  constraints)  Do 
Begin 
newm  :=  0; 

For j  =1 to t, DO 
Begin 
Solve IC, with  respect  to  m3. 
Divide  7 n J  into  a set of  minimal  models as follows. 
Apply  Algorithm  4.1  to  (m3,1Cz) up  to  STEP  3  and  let 
m;  := be  the  set of  minimal  models . 
newm  := newm  U my. 
end 

216 

IEEE  TRANSACTIONS ON  KNOWLEDGE AND DATA  ENGINEERING, VOL.  3,  NO.  2,  JUNE 1991 

m  := newm 
t;+l := number of  elements in newm. 
end 
STEP 3: 
Let m = { m l , .   , mtn+l 1; 
Remove  all models from m which are subsets of  some other 
model and let the resultant set be m’. Construct a theory whose 
only minimal models are the models in m‘. 
0 
We illustrate the above algorithm by the following example. 
Example 4.7: Consider the combined disjunctive theory (T): 
A V B  t C 
C V D  
E 
F 

which  is  inconsistent with  respect  to  the  integrity constraint 
+ B , C .  
The minimal models of  the theory are ml  = {D, E ,  F } ,  m2  = 
{C, B ,  E ,  F }  and mg  = {C, A, E ,  F } .  m2 violates the integrity 
constraint and therefore in STEP 2 of the algorithm it is split to 
m21  = {C, E ,  F }  and m22  = {B, E ,  F } ,  so that each of  them 
satisfy the integrity constraint. In STEP 3 of the algorithm we 
Since m21  c m3, and  only 
have  m  = { m ~ , m 3 , m 2 1 , m 2 ~ } .  
the  maximal  sets  should  be  present  in  m, we  remove  m21 
from  m. Hence,  the consistent combined theory  should have 
the minimal models as { m l ,  m3, mzz}. 

Theorem 5: Algorithm 4.4 generates a maximal combination 

of  theories. 

Proofi  (Using Theorem 2  and Theorem 3): By  Theorem 
3,  STEP  2  of  Algorithm  4.4  divides  minimal  models  to 
a  maximal  set  of  minimal  models.  Hence,  by  Theorem  2, 
Algorithm 4.4 generates a maximal combination. 

2) Incremental Combination  Using  Partial  Backtracking: 
Let  S  = { T 1 , . . . , T k , . - - , T n }  be  a  set of  Horn  theories, IC 
be  a  set  of  integrity  constraints, and  T  = C(T1, -  . , Tk, IC). 
T could be a disjunctive theory. We  assume that we are given 
the first IC  theories of S and subsequently, we need to combine 
the  rest  of  the  theories  in  S.  If  T  is  a  disjunctive  theory, 
we  cannot  use  the  previous  algorithms. We  now  provide  a 
method to combine the remaining theories with the previously 
combined theories. Our method takes advantage of the fact that 
T  is a maximal and consistent combination of  Horn  theories. 
By  virtue  of  the  combining  algorithm  of  Horn  theories  the 
clauses in  T  are of  two major  types.  The  first  type is the set 
of  disjunctive facts and the second type is the restricted rules 
and  the  unaffected  rules  and  facts. We  take  the  atoms in  the 
disjunctive facts and combine these atoms with the remaining 
clauses of the theory T ,  to obtain a new theory TI. The theory 
TI  is addition equivalent to the union of  the original theories 
Tl , . . . , Tk, where  addition  equivalence  of  Horn  theories  is 
defined  as  follows: 

Definition 4.3:  We  say  two  Horn  theories  TI and  TZ are 
addition  equivalent  to  each  other  (denoted  by  TI G T2) iff 
VS,  where  S is  a  set  of  Horn  clauses  (possibly  empty),  the 
minimal  model  of  Tl U  S  is  same  as  the  minimal  model  of 
Tz U S  and vice versa. 

0 

Example  4.8:  Consider the  theory  T :  
P ( X )  + Q ( X )  
&(a) 

Q(b)* 
A theory which is addition equivalent to this theory is 
P ( X >  + Q ( X ) , X  # a , X  #  b 
P(a> 
P(b) 
&(a) 
Q(b)* 
The  theory  T’  =  P(a);P(b);Q(b);Q(a) 

is  not  addition 
equivalent to T ,  even though their minimal models are same. 
This is because P ( c )  is in the minimal model of  TU { Q ( c ) } ,  
while it is not in the minimal model of  TI  U  { Q ( c ) } .   0 
Algorithm 4.5: The incremental combination algorithm 
INPUT: T I ,  . . . , T, are Horn theories. T = C(T1, . . . , Tk); and 
Tk+1,.  , T,  are  to  be  combined  with  T .  IC  is  the  set  of 
integrity constraints satisfied by  each Ti, i = 1  . . . n and T .  
OUTPUT The combined theory of  T  and  Tk+1,. 
STEP 1: By  virtue of  construction of  T  using Algorithm 4.2, 
T = Gens  U  Gen4  U  Gens where Geni  is the theory  added 
in  the  STEP i  of  Algorithm  4.2.  Gens  consists  of  a  set  of 
disjunctive clauses. Gens consists of  the noninterfering facts 
and Gens consists of the restricted rules and the noninterfering 
rules. 
STEP 2:  FACTS  :=  The  set  of  atoms present  in  the  clauses 
of  Gens.  Let  TI  :=  FACTS U Gen4 U  Gens.  By  virtue  of 
the  construction of  T  using Algorithm 4.2  and  as proved  in 
TI U ... U Tk  Now  use  Algorithm  4.2 to 
Theorem 6, TI 
combine T’, Tk+1,. . , T,. 

, T,. 

Theorem 6: In STEP 2 of Algorithm 4.5, T’ G 

U .  . .UTk. 
Proof:  The  difference between  TI  and  TI U . . . U  Tk  is 

0 

0 

that some clause (C) like: 
P(X1,  . . , X,)  + Body, 
in TI U  . . . U Tk  is replaced by  the set of  clauses: 
Ci  : P(a11, . . . , ai,), 

Cm  : P ( a , l , . . . , a , n )  
and 
Cm+l  : P ( X l , . . . , X n )  + Body,X11  #  a l l , . . . , X l n  # 
ai,, . . . , Xmn  # am, in TI. 
Since for all such cases C 
i.e.,  for  any  set  of  clauses  S ,  C U  S  has  the  same  minimal 
model as C1 U - .  .U Cm+l U S ;  we have TI  TI U .  . .UTk. 0 
Theorem  7:  If  Ti  =  Ti  then  C ( T : , T l , . . . , T k )  and 

C1  U  *  . U Cm+l, 

C(Ti, T I ,  . . , Tk) have the same minimal models. 

- 

Proof:  Since  Ti 

Ti, Ti  U  TI U ...Tk  and  Ti  U 
TI U . . . Tk  have  the same minimal models. Hence,  the same 
integrity  constraints violate  them  and  since  the  combination 
is  a  maximal combination and  the  set  of  minimal  models of 
the combinations are unique, the maximal combination of  the 
above two sets of  the theories have the same minimal models. 
0 

Theorem 8: Associativity  of  the  combination:  C(T’, Tk+1, 
, T,) has the same minimal models as C(T1,  .  , Tk, 
, 

Tn). 

0 

Proof: From the previous two theorems. 

0 

In the above algorithm we decompose T into a Horn theory 
TI, strongly equivalent to  the  initial theory  component of  T .  
But this does not mean that we are starting all over again. That 

BARAL  et  al.: COMBINING  MULTIPLE  KNOWLEDGE  BASES 

217 

is because  any  integrity constraint  that violates  TI U . . . U Tk 
will  also  violate  T’, but  we  can  determine  its  violation  with 
respect  to  T’  very  easily  as  we  only  use  the  facts  (not  any 
rules)  when  we  try  to  solve  it  as  a  query.  Hence,  we  call 
our algorithm a partial backtracking algorithm. The following 
example  explains  the  incremental combination  algorithm. 

Example4.9:  Let  T I   def  { P ( X )  +-  Q ( X ) : Q ( X )  +- 
R ( X ) ;  R ( u ) } ,  T2 ef { P ( b ) } ,  T3 %if { P ( c ) } ,  and the integrity 
constraint  be  t P ( X ) , P ( Y ) ,  X  # Y .  
If  we  combine  Tl  and  T2  first  we  obtain  C(T1,T.) = 
{ P ( X )  + Q ( X ) . X   #  u : Q ( X )  +-  R ( X ) ; R ( a ) : P ( u )  V 
P(b) 1. 
T’  = { P ( X )  + Q ( X ) , X  # u ; & ( X )  +-  R ( X ) : R ( a ) ; P ( a ) ;  
P(b)l. 
C(T’,T3)  =  { P ( X )   +  Q ( X ) , X   #  a : Q ( x )   + 
R ( X ) ;  R(a): P ( u )  v P(b) v P ( c ) } .  
If we had combined all of  the theories together as in  Example 
4.3  we  would  have  obtained  C(Tl,T2.T3) =  { P ( X )  t 
& ( X ) , X  #  U: Q ( X )  t R ( X ) :  R(a): P ( n )  v P(b) v P ( c ) }  
which  is the  same as  C(T’, T3). 
Notice  that  when  we  solve  the  integrity  constraint  + 
P ( X ) ,  P ( Y ) ,  X  # Y  with  respect  to  T’  U T3  we  do not  use 
any  rules  in  T‘  while  when  we  solve  the  integrity  constraint 
t P ( X ) .  P ( Y ) ,  X  # Y with respect to TI U T2 U T3  we use 
the rules  in  T I .  

0 

E.  Normal Theories 

We  now  allow  negative  literals  in  the  body  of  rules  of  a 
theory. In general such theories have multiple minimal models. 
As explained  in  the previous  subsection,  it  is extremely  diffi- 
cult  to  combine  theories  that  have  multiple  minimal  models. 
We  shall  assume  that  our  theories  are  stratified. In  that  case, 
such  a  theory  has  a  single  preferred  model  [21]  among  its 
minimal  models,  called  the  perfect  model.  If  we  combine 
theories,  T I ,  . . . , Tk  all  of  which  are  stratified,  it  does  not 
necessarily mean that T  = TI U . . . U Tk  is also stratified. If  T 
is  not  stratified it  is  again very  difficult to  restrict  it  with  the 
integrity constraints.  We  further assume  that T  is stratified. If 
T is stratified then we need  an algorithm similar to Algorithm 
4.2 to combine the theories appropriately. Since T has negated 
atoms in the body of  the rules, the combined theory might also 
have  negated  atoms  in  the  body  of  its  rules. 

The  combined  theory,  which  will  be  a  disjunctive  theory 
with negated atoms in the body of  its rules, will have multiple 
minimal models. But, as in  stratified Horn theories, where we 
consider  only  the  perfect  model  among  all  minimal  models, 
here we want to consider a subset of the set of minimal models, 
i.e., the set of  minimal models present in MINSET(P) (defined 
in  Definition  3.4). 

We  now  give  an  example  and  show why  Algorithm  4.2  is 

not  sufficiently powerful  to  combine  normal  theories. 
Example  4.10: Consider  the  following  theories. 

Ti  : 
P ( X )  t- T Q ( X )  
& ( a ) .  

T2  : 
R(a) 

integrity  constraints  be  + P ( n ) , R ( u )   and  t- 

Let 
the 
Q ( a ) ,  R(a). 
Step 1 of Algorithm 4.2 gives us 5’  =<+  Q ( u ) ,  R ( u ) ,  { & ( a ) .  
R ( a ) } .  {I >. 
STEPS 2 and 3 give  T  = & ( U )   V R(a). 
STEP 5 adds  the  rule as it is. 
The  combined  theory  is 

Q ( u )  V  R(a) 
P ( X )  +- 

i Q ( X ) .  

The  integrity  constraint  + P ( u ) ,  R(a) is  violated  in  one 
minimal model of  the combined theory even though it  did not 
violate  the original  union of  the two theories. This  is because 
before the combination,  &(U)  was true and P ( a )  was false  in 
all  minimal  models,  but  after  the  combination  Q ( u )  became 
false  in  some minimal models and P ( u )  became  true in those 
minimal  models.  Also,  the  new  combination  is  not  correct 
according  to  Definition  3.8.  That  is  because  { P ( u ) ,  R ( u ) } ,  
a  minimal  model  of  the  combination  is  not  a  subset  of  any 
minimal  model  of  the union  of  the original  theorems. 

In  order  to  solve  these  problems  one  needs  to  restrict 
rules  with  negative  literals  in  their  body  that  are  added  as 
disjunctions  to  the  combined  theory.  In  this  example,  since 
& ( a )  is added as a  disjunction we  would  like to  restrict rules 
with  - Q ( X )   in  their  bodies.  Hence,  we  restrict  P ( X )  +- 
l Q ( X )  as P ( X )  e l Q ( X ) . X  # n and the combined theory 
becomes 

& ( a )  ” W a )  
P ( X )  t- i & ( X ) ,  X  # a 

which  does not violate  any  of  the integrity constraints. 

0 

We now give the combination algorithm that uses Algorithm 

4.2 
Algorithm 4.6:  The General Combination Algorithm 
INPUT: 
1. A  set  of  k  normal  theories  {TI . . . Tk} which  have  to  be 
combined.  Each  of  the  T, is  stratified. The  union  of  the  TZ’s 
is also stratified. 
2. A set of  s  integrity constraints,  IC = {ICl, . . . , IC,}  where 
each  integrity constraint is satisfied by  each of  the theories. 
OUTPUT: A theory T ,  which  is the maximal combination  of 
the  input set  of  theories,  such that T  is also satisfied by  each 
of  the  integrity  constraints.  The  combined  theory  T  can  be 
disjunctive. 
STEP  1 to  STEP 5  are same  as in  Algorithm  4.2. 
STEP 6: For each rule R in  the union of  the theories, that has 
a  negative  literal  in  its  body,  say  1 P ( X 1 .  . . . . X l ) ,  if  there 
exists  a  substitution  H  such  P ( X 1 ,  . . . , Xl)H  is  a  member  of 
{ A l . .  . . . A p }  defined in  STEP  2  of  Algorithm  4.2,  then  add 
Restrict(R,  0) to  the  combined  theory.  (Restrict  is  defined in 
Algorithm  4.2.) 
end 
STEP  7:  T  := T  U all  the  rules  in  T I  U . . . U Tk  that  do  not 
appear in R (defined in STEP 5 of Algorithm 4.2) and are not 
restricted in  STEP 6 of  this algorithm. 
C(T1 U . . . U Tk, IC)  := T .  

0 

Theorem 9:  Let  Tl . . . Tk  be  stratified  Horn  theories  that 
consist  of  general  Horn clauses  and let  Tl U  . . . U Tk  also be 
stratified. Then C(Tl, . . . . Tk, IC), obtained by  Algorithm  4.6 
is  a maximal  combination  with  respect  to  TI U . . . U Tk. 

218 

IEEE  TRANSACTIONS ON  KNOWLEDGE AND DATA  ENGINEERING, VOL.  3,  NO.  2,  JUNE  1991 

0 

Proofi  Consistency and  Correctness: In  Step 1 to Step 5 
of the algorithm, the resulting theory  is made consistent with 
the integrity constraints. In Step 6, by restricting the rules with 
negative literals in their body that are added as disjunctions to 
the  combined theory  we  have  correctness. Steps  6  and  7  do 
not affect the fact that the resulting theory is made consistent 
with respect to the integrity constraints. 
Maximality:  The only  difference between  Algorithm 4.6  and 
Algorithm 4.2  is that  in  the former we  restrict the rules with 
negative  literals in  their  body  that  are  added  as  disjunctions 
to  the  combined theory. A  particular ground  instance  of  the 
head  of  these  rules  is  not  present  in  any  minimal  model  of 
TI U .   UTk, using the unrestricted form of the rule. Therefore, 
by  restricting the rule, we do not  loose maximality. 

In the case of  theories with negated atoms in the body of  its 
rules, the incremental combination of theories is not effective. 
The  reason  is  that  the  combination  is  not  associative.  The 
following example illustrates what  might  happen. 

Example 4.11:  Consider the  theories 

T2 

T3 
Tl 
P ( X )  + iQ(W  R(a) 
Q ( a )  
Let the integrity constraint be  t P(u), R(a). 
C(Ti,T’)  = { P ( X )  + l Q ( X ) ;  &(a)). 
C(C(Ti, T3), Tz) = { P ( X )  + i Q ( x ) Q ( a ) ;  R(a);). 
c(Ti,T2) = { P ( X )  + - Q ( X ) , X   # a; P(a)v R(a)} 
C(C(T1, T2), T3) = C(T1, T2)U {&(a)). 

0 

The  nonmonotonic nature of  negation is the  reason  the com- 
bination  is  not  associative.  One  way  to  deal  with  this  is  to 
consider the preference relation dictated by  the  syntax of  the 
program. In the above example, when we combine TI and Tz, 
its  union  has  a  perfect  model  { P ( a ) , R ( a ) ) ,  which  violates 
the  integrity  constraint.  Since  R(a) is  a  fact  and  P(u) is 
obtained using  default reasoning  in  the  union  of  TI and  Tz, 
we might assume that R(a) is preferable to P(u). In that case, 
we can eliminate P(u) to make the combination consistent. To 
eliminate P(u), we restrict the rule with P ( X )  in the head by 
adding  X  #  a  to  the  body.  We  then  obtain  the  combined 
theory  to  be  { P ( X )  t - Q ( X ) , X   #  a; R(a)}. But  this 
approach is not general enough. If  we have R ( X )  t - Q ( X )  
instead of R(a) in T2, then we can obtain both P ( u )  and R(a) 
using  default reasoning and we  cannot decide how to choose 
between  P(u) and  R(a). 

v.  COMBINING  THEORIES AND THE VIEW  UPDATE PROBLEM 
The problem of  view update in databases has been discussed 
by  Fagin  et  al.  [7],  [6],  Rossi  and  Naqvi  [24],  and  others. 
They  deal  with  the  ambiguity  that  arises  from  translating  a 
view update to  an  update over the  underlying base relations. 
Consider  the  database  D =  { P ( X )  t b l ( X ) , P ( X )  + 
b2(X)}, where P ( X )  can only be defined intensionally. When 
P ( u )  is  to  be  inserted  to  this  database,  by  only  changing 
base facts (the basic requirement of  the view update problem) 
there  are  two  possible  updated  theories  TI = D U  { b l ( a ) }  
and  T2  =  D U {bz(a)}. Fagin  et  al.  want  the  update  to 
reflect both  these  theories  and  to  have  the  updated  theory  a 
disjunctive  theory  which  has  multiple  models  (in  this  case 
two),  each  reflecting  a  possible  updated  theory.  Rossi  and 

Naqvi [24] give algorithms to deal with a general sequence of 
updates in an efficient way (both time and space). In the above 
example, the updated theory obtained by  Rossi and Naqvi [24] 
is { P ( X )  c bl(X); P ( X )  t b z ( X ) ;  b l ( a )  Vbz(u)}, which is 
a disjunctive theory. In  this paper, we dealt with the problem 
of  combining a set of  theories represented by  logic programs, 
where we  do not prefer  any  one theory over the others. 

In  the  view  update  problem,  rules  are  considered  to  be 
universal and  hence  unchangeable. In  the  case  of  combining 
theories,  rules  are  part  of  individual  theories.  Since  they 
lose  their  individuality when  we  combine  them,  we  permit 
restrictions to  them  in  the  modified  theory. 

The insertion problem in view updates as discussed in  [24] 
is  different than  combining the  facts  to  be  inserted with  the 
original theory. In the case of  combining multiple knowledge 
bases, the  combined  theory  has  to  be  consistent with  respect 
to  a  set  of  integrity  constraints. 

Fagin  et  al.  in  section  3  of  [7]  consider  the  case  of 
updating  databases  in  the  presence  of  integrity  constraints. 
Their  approach requires giving  priorities  to  sentences of  the 
theory.  In  the  case  of  combining theories, we  are  concerned 
with the situation where priorities are not  available. 

If  the integrity constraints are considered part of the original 
theory  and  facts  are  inserted, then  in  the  updated  theory  the 
inserted  facts  have  to  be  true.  In  the  case  of  combining 
multiple theories, the combination is affected by  the integrity 
constraints and the facts to be combined may become disjuncts 
in  the  combined  theory. 

On  the  other  hand, the  integrity  constraints could  be  con- 
sidered  as  deletions  followed  by  insertions.  In  that  case,  a 
deletion is  forced after  any  insertion. We  deal with  this  case 
later, when  we  discuss  deletions. 

Even in the absence of  integrity constraints, while combin- 
ing theories we  can  modify  rules.  This is not  allowed during 
insertion in the view update problem. The following example 
shows the  differences in  the two  approaches: 
Example 5.1: Let  the  initial theory  T  be 
P ( X )  
P ( X )  
bl ( a ) .  
If  we want to insert the fact P(b) to the theory T we obtain 

b l ( X )  
b z ( X )  

TI to  be 

P ( X )  + b l ( X )  
P ( X )  
b z ( X )  
bl ( a )  
b l ( b )  v b2(b). 
If  we  want  to  accomplish  the  insertion  of  fact  P(b) by 
combining  T  with  the  theory  {P(b)} we  obtain  the  theory 
T2  to  be 
P ( X )  4.- 
b l ( X )  
P ( X )  + b2(X) 
bl ( a )  
P(b). 
Note  that  TI is  not  correct  according to  our  definition  of 
correctness as bl(b) is present in a minimal model of  T I ,  even 
though it is absent in  the minimal model of  T U  {P(b)}.  0 
The deletion in the view update problem is similar to making 
a  theory  consistent  with  respect  to  an  integrity  constraint. 

BARAL et  al.:  COMBINING  MULTIPLE  KNOWLEDGE BASES 

219 

When  we  combine  a  set  of  theories  we  essentially  try  to 
make  the  union  of  the  theories  consistent  with  respect  to  the 
integrity  constraints.  The  deletion  of  P ( u )  A  & ( a )   from  a 
theory  T  is  equivalent  to  making  T  consistent  with  respect 
to the  integrity  constraint  +- P ( u ) ,  & ( a ) .  The updated  theory 
TI in  the  view  update  problem  neither  changes  nor  deletes 
rules.  When  we  make  a  theory  consistent  with  respect  to  an 
integrity  constraint we might  change the rules.  Let this  theory 
be  called  T2. Because  of  this  T1  is not  necessarily  maximal, 
while T2  is always maximal. The following example illustrates 
this  situation. 

Example 5.2:  Let  the  original  theory  T  be 
P ( X )  + b l ( W  
P ( X )  + b 2 ( X )  
b l  ( a )  
b2(a). 
If  we want to delete P ( u )  from  T ,  the updated  theory  TI  is 
P ( X )  + h ( X )  
P ( X )  + b 2 ( X )  
-b1(a) 
+(a). 
If  we  treat  deleting  P ( u )  as  making  T  consistent  with 
respect to the integrity constraint +- P ( u )  we obtain the theory 
T2  to  be 

P ( X )  + b l ( X ) . X  #  a 
P ( X )  + bZ(X).X  #  a 
b l  ( a )  
b2(a). 
Since  bl(u) and  b2(u) are  in  the  minimal model  of  T2  and 

not  in  the  minimal  model  of  T I ,  TI is not  maximal. 

0 

VI.  CONCLUSION  AND  FURTHER WORK 

In  this  paper,  we  presented  algorithms  to  combine  knowl- 
edge contained  in  Horn  theories.  We  did so in such  a manner 
as  to  achieve  a  maximal  theory.  We  defined  the  concept  of 
a  maximal  theory,  and  we  proved  the  maximality  of  our 
algorithms.  We  gave  methods  to  combine  different  positive 
theories  written  in  the  same  language  such  that  the  combi- 
nation  does  not  violate  the  integrity  constraints  and  yet  they 
are a maximal combination.  We  defined what  it  means for  an 
integrity constraint to violate a disjunctive knowledge base and 
defined  the  notion  of  strong  equivalence  of  logic  programs, 
and  used  them  in  our  algorithms  and  proofs.  We  also  gave 
algorithms  to  combine  them  incrementally.  Finally,  we  gave 
an  algorithm  to  combine  normal  theories  (i.e.,  theories  with 
negation in their body) maximally, when the theories and their 
union  are  stratified. 

We  used  a  a  restricted  syntax  for  integrity  constraints.  We 
are  presently  working  on  generalizing  the  approach  given  in 
this  paper  to  general  integrity  constraints. 

Although  we  have  given  a  semantic algorithm  to  combine 
disjunctive  theories,  a  more  practical  algorithm  is  desirable. 
Practical  algorithms  to  combine  normal  theories  that  are  not 
stratified  are  also  needed. 

ACKNOWLEDGMENT 

We wish to express our appreciation to the National Science 
Foundation for their support of  our work under  Grant IRI-86- 

09170 and the Army  Research Office under  Grant DAAL-03- 
88-K0087.  We  would  also  like  to  thank  V. S. Subrahmaniar, 
for  insightful comments  on  an  earlier  draft of  the  paper. 

REF ER EN c E s 

New  York:  Plenum,  1978, pp.  293-322. 

K. R.  Apt,  H. A.  Blair,  and  A. Walker,  “Toward  a theory  of  declarative 
knowledge,”  in  Foundations  of  Deductive  Databases  and  Logic  Pro- 
gramming, J. Minker,  Ed.  Los  Altos,  CA:  Morgan-Kaufmann,  1988, 
pp.  89-148. 
K. R.  Apt  and  M. H.  van  Emden, “Contributions to the  theory  of  logic 
programming,” J .  ACM, vol. 29, no.  3, pp.  841-862,  1982. 
C. Baral, J.  Lobo, and  J.  Minker, “Generalized well-founded semantics 
for logic programs,” Tech. Rep. CS-TR-2330, Dep. Comput. Sci., Univ. 
of  Maryland, College Park, MD 20742,  1989. A shorter version  appears 
in  Proc.  CADE  ’90. 
U. S. Chakravarthy, J.  Grant, and J.  Minker, “Foundations of  semantic 
query  optimization  for  deductive databases,”  in  Proc.  Workshop Foun- 
dations Deductive Databases  and Logic Programming, J.  Minker, Ed., 
Washington,  DC,  Aug.  18-22,  1986, pp.  67-101. 
K. L. Clark, “Negation as failure,” in Logic and Data Bases, H.  Gallaire 
and  J.  Minker, Eds. 
R.  Fagin,  G.  Kuper,  J.  Ullman,  and  M.  Vardi,  “Updating  logical 
databases,” in Advances in Computing Research,  Vol. 3, 1986, pp.  1-18. 
R.  Fagin, J.  D. Ullman,  and  M. Y. Vardi, “On the semantics of  updates 
in  databases,”  in  ACM  SIGACTISIGMOD  Symp.  Principles Database 
Syst.,  1983, pp.  352-365. 
M. Fitting,  “A Kripke-Kleene, Semantics for logic programs,” J. Logic 
Programming,  vol.  3, pp.  93-114,  1986. 
M.  Fitting  and  M.  Ben-Jacob,  “Stratified  and  three-valued  logic  pro- 
gramming semantics,” in Proc. 5th Int. Conf  Symp. Logic Programming, 
R. A. Kowalski and K. A. Bowen, Eds., Seattle, WA, Aug.  15-19, 1988, 
pp.  1054-1069. 
M.  Gelfond  and  V.  Lifschitz,  “The  stable  model  semantics  for  logic 
programming,” in Proc. 5th Int.  Conf Symp. Logic Programming, R. A. 
Kowalski  and K. A.  Bowen,  Eds.,  Seattle, WA, Aug.  15-19, 1988, pp. 
1070-1080. 
R. Kowalski  and  F. Sadri, “Knowledge representation  without  integrity 
constraints, draft  manuscript,  Dec.  1988. 
“An application  of general purpose theorem  proving to database 
-, 
integrity,”  in  Proc.  Workshop Foundations  Deductive Databases Logic 
Programming, J.  Minker, Ed., Washington,  DC, Aug.  18-22,  1986, pp. 
477-5  17. 
J. W.  Lloyd, Foundations  of  Logic  Programming,  second  ed.  Berlin, 
Germany:  Springer-Verlag,  1987. 
J. W. Lloyd and R. W. Topor, “Making Prolog more expressive,”/.  Logic 
Programming,  vol.  1, no.  3, pp.  225-240,  Oct.  1984. 
J.  Minker, “On  indefinite  databases  and  the  closed world  assumption,” 
in Lecture Notes in Computer Science  138.  Berlin, Germany: Springer- 
Verlag,  1982, pp.  292-308. 
J.  Minker  and  J.  Grant,  “Integrity  constraints  in  knowledge  based 
systems,”  in  Knowledge  Engineering,  Vol. II,  Applications,  H.  Adeli, 
Ed.  New  York:  McGraw-Hill,  1990, pp.  1-25.  Also  CS-TR-2223  of 
Univ.  of  Maryland,  College  Park. 
J.  Minker and D. Perlis, “Computing protected  circumscription,”J. Logic 
Programming,  vol  2,  no.  4, pp.  235-249,  Dec.  1985. 
“Applications of  protected  circumscription” in Lecture Notes on 
-, 
Computer  Science,  Vol. 170, 7th Conf: Automat. Deduction, May  1984, 
pp.  414425. 
.-, 
Reasoning, Oct.  17-19,  1984, pp.  337-343. 
J. Minker and A. Rajasekar, “Procedural interpretation of non-Horn logic 
programs,” in Proc.  9th Int  Conf Automat. Deduction, E. Lusk  and R. 
Overbeek, Eds.,  Argonne, IL, May  23-26,  1988, pp. 278-293. 
T. C.  Przymusinski,  “On  the  declarative  semantics  of  deductive 
databases  and  logic  programming,”  in  Foundations  of  Deductive 
Databases  and  Logic  Programming,  J.  Minker,  Ed.  Los  Altos,  CA: 
Morgan-Kaufmann,  1988, pp.  193-216. 
“Every logic program  has  a natural  stratification and an  iterated 
-, 
fixed point  model,”  in Proc. 8th ACM SIGACT-SIGMOD-SIGART Symp 
Principle  Database Syst.,  1989, pp.  11-21. 
-, 
“Perfect  model  semantics,”  in  Proc.  5th  Int.  Conf and  Symp. 
Logic  Programming,  R. A.  Kowalski  and  K. A.  Bowen,  Eds.,  Seattle, 
WA,  Aug.  15-19,  1988, pp.  1081-1096. 
F. Rossi  and S. Naqvi, “Contributions to the view update  problem,” in 
Proc. Int. Conf Logic Programming Lisbon,  1989, pp. 398415. 

“Protected circumscription,” in Proc. Workshop Non-Monotonic 

220 

IEEE TRANSACTIONS ON  KNOWLEDGE AND  DATA  ENGINEERING,  VOL.  3,  NO.  2,  JUNE  1991 

Jack  Minker  (M’76SM’8&F’91)  received  the 
B.A.  degree (cum laude with honors) in mathematics 
from Brooklyn College in  1949, the M.S.  degree in 
mathematics from the  University  of  Wisconsin, in 
1950,  and  the  Ph.D.  degree  in  mathematics from 
the University of  Pennsylvania, in  1959. 

He  is  a  Professor  of  Computer  Science in  the 
Department  of  Computer  Science and  the  Institute 
for Advanced Computer Studies. 

Dr.  Minker  serves on the  Editorial Boards of  a 
number  of  journals  such  as  the  Journal  ofLogic 
Programming, IEEE EXPERT, and Information System Journal. He also served 
as Chairman of the Advisory Committee on Computing to the National Science 
Fouqdation (1979-1982).  In  1985, he received the Association for Computing 
Machinery’s Outstanding Contribution Award  for his  work  in  human  rights. 
He was also elected Fellow of the American Association for the Advancement 
of  Science based  on  his work in  artificial  intelligence, database theory, and 
his efforts on behalf  of  human rights. He is also a fellow of  the AAAI. 

[25]  M. H. van Emden and R. A. Kowalski, “The semantics of predicate logic 
as a programming language,” J. ACM, vol. 23, no. 4, pp. 733-742,1976. 
[26]  A.  Van  Gelder, K.  Ross, and J.  S. Schlipf, “Unfounded sets and  well- 
founded  semantics for  general  logic  programs,”  in  P m .  7th  Symp 
Principles Database Syst.,  1988, pp,  221-230. 

Chitta Baral received the B.Tech. (hons) degree in 
computer science and  engineering from  the  Indian 
Institute of Technology, Kharagpur, in 1987, and the 
M.S.  degree in computer science from  the Univer- 
sity of  Maryland, College Park, in  1990 

He  is  currently a  graduate student pursuing the 
Ph.D.  degree in computer science at  the University 
of Maryland. He will join the University of Texas at 
El Paso in the Fall of  1991. His current research in- 
terests include nonmonotonic reasoning, knowledge 
representation, logic  programming,  databases, and 
data  structures. 

Sarit  Kraus received  the  B.Sc.  degree in  mathe- 
matics and computer science (with distinction), the 
M.Sc.  degree (with  distinction), and  Ph.D.  degree 
in computer science  from  the  Hebrew  University, 
Jerusalem, Israel, in  1982, 1983, and  1989, respec- 
tively. 

She  was  a  Visiting  Assistant  Professor  at  the 
institute  for  Advanced Computer  Studies  and  the 
Department  of  Computer  Science,  University  of 
Maryland, College Park  in  1989-1990.  She joined 
the  Hebrew  University  in  the  Fall  of  1990.  Her 
current  research interests include automated negotiations, programs capable 
of  intelligent interaction with other agents, logic programming, planning, and 
nonmonotonic logics. 

