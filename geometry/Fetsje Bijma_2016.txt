An Introduction to
Mathematical 
Statistics
Fetsje Bijma
Marianne Jonker
Aad van der Vaart

An Introduction to Mathematical Statistics


An Introduction to  
Mathematical Statistics
Fetsje Bijma, Marianne Jonker, Aad van der Vaart
Amsterdam University Press

Original publication: Fetsje Bijma, Marianne Jonker, Aad van der Vaart, Inleiding in de statistiek. 
Epsilon Uitgaven, 2016 [ISBN 978-90-5041-135-6] 
© Fetsje Bijma, Marianne Jonker, Aad van der Vaart, 2016
Translated by: Reinie Erné
Cover design: V3-Services, Baarn
Amsterdam University Press English-language titles are distributed in the US and Canada by the 
University of Chicago Press.
isbn 
978 94 6298 510 0
e-isbn 
978 90 4853 611 5 (pdf)
nur 
916
doi 
10.5117/9789462985100
© Fetsje Bijma, Marianne Jonker, Aad van der Vaart / Amsterdam University Press B.V., 
Amsterdam 2017
All rights reserved. Without limiting the rights under copyright reserved above, no part of this 
book may be reproduced, stored in or introduced into a retrieval system, or transmitted, in any 
form or by any means (electronic, mechanical, photocopying, recording or otherwise) without the 
written permission of both the copyright owner and the author of the book.
Every effort has been made to obtain permission to use all copyrighted illustrations reproduced in 
this book. Nonetheless, whosoever believes to have rights to this material is advised to contact the 
publisher.

PREFACE
This book gives an introduction into mathematical statistics. It was written for
bachelor students in (business) mathematics, econometrics, or any other subject
with a solid mathematical component. We assume that the student already has solid
knowledge of probability theory to the extent of a semester course at the same level.
In Chapter 1, we give the deﬁnition and several examples of a statistical model,
the foundation of every statistical procedure. Some techniques from descriptive
statistics that can assist in setting up and validating statistical models are discussed
in Chapter 2. The following chapters discuss the three main topics in mathematical
statistics: estimating, testing, and constructing conﬁdence regions. These subjects are
discussed in Chapters 3, 4, and 5, respectively. Next, Chapter 6 provides deeper
theoretical insight, in particular into the question under what circumstances and in
what sense certain statistical models are mathematically optimal. In Chapter 7, we
describe several regression models that are commonly used in practice. The theory
from the previous chapters is applied to estimate and test unknown model parameters
and give conﬁdence regions for them. Finally, in Chapter 8, we discuss model
selection. In that chapter, various criteria are presented that can be used to ﬁnd the
best-ﬁtting model from a collection of (regression) models. Sections and examples
marked with a * are more diﬃcult and do not belong to the basic subject matter of
mathematical statistics. Every chapter concludes with a summary.
In Appendix A, we recall elements from probability theory that are relevant
for understanding the subject matter of this book. In Appendix B, we discuss
properties of the multivariate normal distribution, which is used in several sections.
Appendix C contains tables with values of distribution and quantile functions of
several distributions to which we refer in the text. These are meant to be used at home
or during problem sessions. In "real life," these tables are no longer used: the computer
is faster, more accurate, and easier to use. The statistical package R, for example,
contains standard functions for the distribution function, the density function, and the
quantile function of all standard distributions.
The mathematical style of this book is more informal than that of many
mathematics books. Theorems and lemmas are not always proved or may be
formulated in an informal manner. The reason is that a pure mathematical treatment is
only possible using measure theory, of which we do not assume any knowledge. On
the other hand, the relevance and motivation of the theorems are also clear without
going into all the details.
Each chapter concludes with a case study. It often contains a statistical problem
that is answered as well as possible based on the collected data, using the statistical
techniques and methods available at that point in the book. The R-code and data of
these applications, as well as the data of several case studies described in the book, are
available and can be downloaded from the book's webpage at http://www.aup.nl.
Though this book includes examples, practice is indispensable to gain insight into
the subject matter. The exercises at the end of each chapter include both theoretical
and more practically oriented problems. Appendix D contains short answers to most
v

exercises. Solutions that consist of a proof are not included.
The book has taken form over a period of 20 years. It was originally written
in Dutch and used yearly for the course "Algemene Statistiek" (General Statistics)
for (business) mathematics and econometrics students given by the mathematics
department of VU University Amsterdam. The various lecturers of the course
contributed to the book to a greater or lesser extent. One of them is Bas Kleijn. We
want to thank him for his contribution to the appendix on probability theory. More than
2000 students have studied the book. Their questions on the subject and advice on the
presentation have helped give the book its present form. They have our thanks. The
starting point of the book was the syllabus "Algemene Statistiek" (General Statistics)
of J. Oosterhoﬀ, professor of mathematical statistics at VU University Amsterdam
until the mid-'90s. We dedicate this book to him.
In 2013, the ﬁrst edition of this book was published in Dutch, and three
years later, in 2016, the second Dutch edition came out. This second edition has
been translated into English, with some minor changes. We thank Reinie Ern´e for
translation.
Amsterdam and Leiden, March 2017
vi

FURTHER READING
Reference [1] is an introduction to many aspects of statistics, somewhat comparable
to An Introduction to Mathematical Statistics. References [3] and [4] are standard
books that focus more on mathematical theory, and estimation and tests, respec-
tively. Reference [6] describes the use of asymptotic methods in statistics, on a
higher mathematical level, and gives several proofs left out in An Introduction to
Mathematical Statistics. Reference [5] is a good starting point for whoever wants to
delve further into the Bayesian thought process, and reference [7] provides the same
for nonparametric methods, which are mentioned in An Introduction to Mathematical
Statistics but perhaps less prominently than in current practice. Reference [2]
elaborates on the relevance of modeling using regression models, for example to draw
causal conclusions in economic or social sciences.
[1] Davison, A.C., (2003). Statistical models. Cambridge University Press.
[2] Freedman, D., (2005). Statistical models: theory and applications. Cambridge
University Press.
[3] Lehmann, E.L. and Casella, G., (1998). Theory of point estimation. Springer.
[4] Lehmann, E.L. and Romano, J.P., (2005). Testing statistical hypotheses.
Springer.
[5] Robert, C.P., (2001). The Bayesian choice. Springer-Verlag.
[6] van der Vaart, A.W., (1998). Asymptotic statistics. Cambridge University
Press.
[7] Wasserman, L., (2005). All of nonparametric statistics. Springer.
vii


TABLE OF CONTENTS
1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1. What Is Statistics?
. . . . . . . . . . . . . . . . . . . . .
1
1.2. Statistical Models
. . . . . . . . . . . . . . . . . . . . .
2
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 12
Application: Cox Regression
. . . . . . . . . . . . . . . . . 15
2. Descriptive Statistics
. . . . . . . . . . . . . . . . . . . . . . 21
2.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . 21
2.2. Univariate Samples . . . . . . . . . . . . . . . . . . . . . 21
2.3. Correlation
. . . . . . . . . . . . . . . . . . . . . . . . 32
2.4. Summary . . . . . . . . . . . . . . . . . . . . . . . . . 38
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 39
Application: Benford's Law
. . . . . . . . . . . . . . . . . 41
3. Estimators
. . . . . . . . . . . . . . . . . . . . . . . . . . 45
3.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . 45
3.2. Mean Square Error . . . . . . . . . . . . . . . . . . . . . 46
3.3. Maximum Likelihood Estimators
. . . . . . . . . . . . . . . 54
3.4. Method of Moments Estimators . . . . . . . . . . . . . . . . 72
3.5. Bayes Estimators . . . . . . . . . . . . . . . . . . . . . . 75
3.6. M-Estimators
. . . . . . . . . . . . . . . . . . . . . . . 88
3.7. Summary . . . . . . . . . . . . . . . . . . . . . . . . . 93
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 94
Application: Twin Studies
. . . . . . . . . . . . . . . . .
100
4. Hypothesis Testing . . . . . . . . . . . . . . . . . . . . . .
105
4.1. Introduction . . . . . . . . . . . . . . . . . . . . . . .
105
4.2. Null Hypothesis and Alternative Hypothesis . . . . . . . . . .
105
4.3. Sample Size and Critical Region
. . . . . . . . . . . . . .
107
4.4. Testing with p-Values . . . . . . . . . . . . . . . . . . .
121
4.5. Statistical Signiﬁcance
. . . . . . . . . . . . . . . . . .
126
4.6. Some Standard Tests
. . . . . . . . . . . . . . . . . . .
127
4.7. Likelihood Ratio Tests
. . . . . . . . . . . . . . . . . .
143
4.8. Score and Wald Tests . . . . . . . . . . . . . . . . . . .
150
4.9. Multiple Testing . . . . . . . . . . . . . . . . . . . . .
153
4.10. Summary . . . . . . . . . . . . . . . . . . . . . . . .
159
Exercises . . . . . . . . . . . . . . . . . . . . . . . .
160
Application: Shares According to Black-Scholes
. . . . . . . .
169
5. Conﬁdence Regions
. . . . . . . . . . . . . . . . . . . . .
174
5.1. Introduction . . . . . . . . . . . . . . . . . . . . . . .
174
5.2. Interpretation of a Conﬁdence Region
. . . . . . . . . . . .
174
5.3. Pivots and Near-Pivots
. . . . . . . . . . . . . . . . . .
177
5.4. Maximum Likelihood Estimators as Near-Pivots
. . . . . . . .
181
5.5. Conﬁdence Regions and Tests
. . . . . . . . . . . . . . .
195
5.6. Likelihood Ratio Regions
. . . . . . . . . . . . . . . . .
198
ix

5.7. Bayesian Conﬁdence Regions . . . . . . . . . . . . . . . .
201
5.8. Summary . . . . . . . . . . . . . . . . . . . . . . . .
205
Exercises . . . . . . . . . . . . . . . . . . . . . . . .
206
Application: The Salk Vaccine
. . . . . . . . . . . . . . .
209
6. Optimality Theory
. . . . . . . . . . . . . . . . . . . . . .
212
6.1. Introduction . . . . . . . . . . . . . . . . . . . . . . .
212
6.2. Suﬃcient Statistics . . . . . . . . . . . . . . . . . . . .
212
6.3. Estimation Theory
. . . . . . . . . . . . . . . . . . . .
219
6.4. Testing Theory
. . . . . . . . . . . . . . . . . . . . .
231
6.5. Summary . . . . . . . . . . . . . . . . . . . . . . . .
245
Exercises . . . . . . . . . . . . . . . . . . . . . . . .
246
Application: High Water in Limburg
. . . . . . . . . . . . .
250
7. Regression Models . . . . . . . . . . . . . . . . . . . . . .
259
7.1. Introduction . . . . . . . . . . . . . . . . . . . . . . .
259
7.2. Linear Regression
. . . . . . . . . . . . . . . . . . . .
261
7.3. Analysis of Variance
. . . . . . . . . . . . . . . . . . .
275
7.4. Nonlinear and Nonparametric Regression . . . . . . . . . . .
283
7.5. Classiﬁcation
. . . . . . . . . . . . . . . . . . . . . .
285
7.6. Cox Regression Model
. . . . . . . . . . . . . . . . . .
290
7.7. Mixed Models . . . . . . . . . . . . . . . . . . . . . .
295
7.8. Summary . . . . . . . . . . . . . . . . . . . . . . . .
299
Exercises . . . . . . . . . . . . . . . . . . . . . . . .
300
Application: Regression Models and Causality . . . . . . . . .
303
8. Model Selection . . . . . . . . . . . . . . . . . . . . . . .
308
8.1. Introduction . . . . . . . . . . . . . . . . . . . . . . .
308
8.2. Goal of Model Selection . . . . . . . . . . . . . . . . . .
308
8.3. Test Methods
. . . . . . . . . . . . . . . . . . . . . .
311
8.4. Penalty Methods . . . . . . . . . . . . . . . . . . . . .
312
8.5. Bayesian Model Selection
. . . . . . . . . . . . . . . . .
317
8.6. Cross-Validation . . . . . . . . . . . . . . . . . . . . .
321
8.7. Post-Model Selection Analysis
. . . . . . . . . . . . . . .
322
8.8. Summary . . . . . . . . . . . . . . . . . . . . . . . .
324
Application: Air Pollution
. . . . . . . . . . . . . . . . .
325
A. Probability Theory . . . . . . . . . . . . . . . . . . . . . .
329
A.1. Introduction . . . . . . . . . . . . . . . . . . . . . . .
329
A.2. Distributions
. . . . . . . . . . . . . . . . . . . . . .
329
A.3. Expectation and Variance
. . . . . . . . . . . . . . . . .
332
A.4. Standard Distributions
. . . . . . . . . . . . . . . . . .
333
A.5. Multivariate and Marginal Distributions . . . . . . . . . . . .
338
A.6. Independence and Conditioning . . . . . . . . . . . . . . .
339
A.7. Limit Theorems and the Normal Approximation
. . . . . . . .
342
Exercises . . . . . . . . . . . . . . . . . . . . . . . .
345
B. Multivariate Normal Distribution
. . . . . . . . . . . . . . . .
347
B.1. Introduction . . . . . . . . . . . . . . . . . . . . . . .
347
x

B.2. Covariance Matrices
. . . . . . . . . . . . . . . . . . .
347
B.3. Deﬁnition and Basic Properties
. . . . . . . . . . . . . . .
348
B.4. Conditional Distributions
. . . . . . . . . . . . . . . . .
352
B.5. Multivariate Central Limit Theorem
. . . . . . . . . . . . .
353
B.6. Derived Distributions . . . . . . . . . . . . . . . . . . .
353
C. Tables . . . . . . . . . . . . . . . . . . . . . . . . . . .
355
C.1. Normal Distribution
. . . . . . . . . . . . . . . . . . .
356
C.2. t-Distribution
. . . . . . . . . . . . . . . . . . . . . .
357
C.3. Chi-Square Distribution . . . . . . . . . . . . . . . . . .
358
C.4. Binomial Distribution (n = 10) . . . . . . . . . . . . . . .
360
D. Answers to Exercises . . . . . . . . . . . . . . . . . . . . .
362
Index
. . . . . . . . . . . . . . . . . . . . . . . . . . .
369
xi


1 Introduction
1.1 What Is Statistics?
Statistics is the art of modeling (describing mathematically) situations in which
probability plays a role and drawing conclusions based on data observed in such
situations.
Here are some typical research questions that can be answered using statistics:
(i) What is the probability that the river the Meuse will overﬂow its banks this year?
(ii) Is the new medical treatment signiﬁcantly better than the old one?
(iii) What is the margin of uncertainty in the prediction of the number of representa-
tives for political party A?
Answering such questions is not easy. The three questions above correspond to the
three basic concepts in mathematical statistics: estimation, testing, and conﬁdence
regions, which we will deal with extensively in this book. Mathematical statistics
develops and studies methods for analyzing observations based on probability models,
with the aim to answer research questions as above. We discuss a few more
examples of research questions, observed data, and corresponding statistical models
in Section 1.2.
In contrast to mathematical statistics, descriptive statistics is concerned with
summarizing data in an insightful manner by averaging, tabulating, making graphical
representations, and processing them in other ways. Descriptive methods are only
discussed brieﬂy in this book, as are methods for collecting data and the modeling
of data.
1

1: Introduction
1.2 Statistical Models
In a sense, the direction of statistics is precisely the opposite of that of probability
theory. In probability theory, we use a given probability distribution to compute the
probabilities of certain events. In contrast, in statistics, we observe the results of
an experiment, but the underlying probability distribution is (partly) unknown and
must be derived from the results. Of course, the experimental situation is not entirely
unknown. All known information is used to construct the best possible statistical
model. A formal deﬁnition of a "statistical model" is as follows.
Deﬁnition 1.1 Statistical model
A statistical model is a collection of probability distribution on a given sample space.
The interpretation of a statistical model is: the collection of all possible
probability distributions of the observation X. Usually, this observation is made up
of "subobservations," and X = (X1, . . . , Xn) is a random vector. When the variables
X1, . . . , Xn correspond to independent replicates of the same experiment, we speak
of a sample. The variables X1, . . ., Xn are then independent, identically distributed,
and their joint distribution is entirely determined by the marginal distribution, which
is the same for all Xi. In that case, the statistical model for X = (X1, . . ., Xn) can be
described by a collection of (marginal) probability densities for the subobservations
X1, . . . , Xn.
The concept of "statistical model" only truly becomes clear through examples. As
simply as the mathematical notion of "statistical model" is expressed in the deﬁnition
above, so complicated is the process of the statistical modeling of a given practical
situation. The result of a statistical study depends on the construction of a good model.
Example 1.2 Sample
In a large population consisting of N persons, a proportion p has a certain
characteristic A; we want to "estimate" this proportion p. It is too much work to
examine everyone in the population for characteristic A. Instead, we randomly choose
n persons from the population, with replacement. We observe (a realization of) the
random variables X1, . . ., Xn, where
Xi =
 0
if the ith person does not have A,
1
if the ith person has A.
Because of the set-up of the experiment (sampling with replacement), we know
beforehand that X1, . . . , Xn are independent and Bernoulli-distributed. The latter
means that
P(Xi = 1) = 1 −P(Xi = 0) = p
2

1.2: Statistical Models
for i = 1, . . ., n. There is no prior knowledge concerning the parameter p, other then
0 ≤p ≤1. The observation is the vector X = (X1, . . . , Xn). The statistical model
for X consists of all possible (joint) probability distributions of X whose coordinates
X1, . . . , Xn are independent and have a Bernoulli distribution. For every possible
value of p, the statistical model contains exactly one probability distribution for X.
It seems natural to "estimate" the unknown p by the proportion of the persons
with property A, that is, by n−1n
i=1xi, where xi is equal to 1 or 0 according to
whether the person has property A or not. In Chapter 3, we give a more precise
deﬁnition of "estimating." In Chapter 5, we use the model we just described to
quantify the diﬀerence between this estimator and p, using a "conﬁdence region." The
population and sample proportions will almost never be exactly equal. A conﬁdence
region gives a precise meaning to the "margin of errors" that is often mentioned with
the results of an opinion poll. We will also determine how large that margin is when
we, for example, study 1000 persons from a population, a common number in polls
under the Dutch population.
Example 1.3 Measurement errors
If a physicist uses an experiment to determine the value of a constant μ repeatedly, he
will not always ﬁnd the same value. See, for example, Figure 1.1, which shows the
23 determinations of the speed of light by Michelson in 1882. The question is how
to "estimate" the unknown constant μ from the observations, a sequence of numbers
x1, . . . , xn. For the observations in Figure 1.1, this estimate will lie in the range 700-
900, but we do not know where. A statistical model provides support for answering
this question. Probability models were ﬁrst applied in this context at the end of the
18th century, and the normal distribution was "discovered" by Gauss around 1810 for
the exact purpose of obtaining insight into the situation described here.
600
700
800
900
1000
Figure 1.1. The results of the 23 measurements of the speed of light by Michelson in 1882.The
scale along the horizontal axis gives the measured speed of light (in km/s) minus 299000 km/s.
3

1: Introduction
If the measurements are all carried out under the same circumstances, indepen-
dently of the past, then it is reasonable to include in the model that these numbers
are realizations of independent, identically distributed random variables X1, . . . , Xn.
The measurement errors ei = Xi −μ are then also random variables. A common
assumption is that the expected measurement error is equal to 0, in other words, Eei =
0, in which case EXi = E(ei + μ) = μ. Since we have assumed that X1, . . . , Xn
are independent random variables and all have the same probability distribution, the
model for X = (X1, . . . , Xn) is ﬁxed by the choice of a statistical model for Xi.
For Xi, we propose the following model: all probability distributions with ﬁnite
expectation μ. The statistical model for X is then: all possible probability distributions
of X = (X1, . . . , Xn) such that the coordinates X1, . . . , Xn are independent and
identically distributed with expectation μ.
Physicists often believe that they have more prior information and make more
assumptions on the model. For example, they assume that the measurement errors
are normally distributed with expectation 0 and variance σ2, in other words, that the
observations X1, . . . , Xn are normally distributed with expectation μ and variance σ2.
The statistical model is then: all probability distributions of X = (X1, . . . , Xn) such
that the coordinates are independent and N(μ, σ2)-distributed.
The ﬁnal goal is to say something about μ. In the second model, we know more,
so we should be able to say something about μ with more "certainty." On the other
hand, there is a higher "probability" that the second model is incorrect, in which case
the gain in certainty is an illusory one. In practice, measurement errors are often, but
not always, approximately normally distributed. Such normality can be justiﬁed using
the central limit theorem (see Theorem A.28) if a measurement error can be viewed
as the sum of a large number of small independent measurement errors (with ﬁnite
variances), but cannot be proved theoretically. In Chapter 2, we discuss methods to
study normality on the data itself.
The importance of a precisely described model is, among other things, that
it allows us to determine what is a meaningful way to "estimate" μ from the
observations. An obvious choice is to take the average of x1, . . . , xn. In Chapter 6,
we will see that this is the best choice (according to a particular criterion) if the
measurement errors indeed have a normal distribution with expectation 0. If, on the
other hand, the measurement errors are Cauchy-distributed, then taking the average
is disastrous. This can be seen in Figure 1.2. It shows the average n−1n
i=1xi, for
n = 1, 2, . . ., 1000, of the ﬁrst n realizations x1, . . . , x1000 of a sample from a
standard Cauchy distribution. The behavior of the averages is very chaotic, and they
do not converge to 0. This can be explained by the remarkable theoretic result that the
average n−1n
i=1Xi of independent standard Cauchy-distributed random variables
X1, . . . , Xn also has a standard Cauchy distribution. So taking the averages changes
nothing!
Example 1.4 Poisson stocks
A certain product is sold in numbers that vary for diﬀerent retailers and ﬂuctuate over
time. To estimate the total number of items needed, the central distribution center
4

1.2: Statistical Models
0
200
400
600
800
1000
−5
0
5
10
15
20
25
Figure 1.2. Cumulative averages (vertical axis) of n = 1, 2, . . . , 1000 (horizontal axis) realizations
from the standard Cauchy distribution.
registers the total number of items sold per week and retailer for several weeks. They
observe x = (x1,1, x1,2, . . . , xI,J), where xi,j is the number of items sold by retailer i
in week j. The observation is therefore a vector of length the product IJ of the number
of retailers and the number of weeks, with integral coordinates. The observations can
be seen as realizations of the random vector X = (X1,1, X1,2, . . . , XI,J). Many
diﬀerent statistical models for X are possible and meaningful in given situations. A
common (because often reasonably ﬁtting) model states:
- Every Xi,j is Poisson-distributed with unknown parameter μi,j.
- The X1,1, . . ., XI,J are independent.
This ﬁxes the probability distribution of X up to the expectations μi,j = EXi,j. It
is these expectations that the distribution center is interested in. The total expected
demand in week j, for example, is 
i μi,j. Using the Poisson-character of the demand

i Xi,j, the distribution center can choose a stock size that gives a certain (high)
probability that there is suﬃcient stock.
The goal of the statistical analysis is to deduce μi,j from the data. Up to now, we
have left the μi,j completely "free." This makes it diﬃcult to estimate them from the
data, because only one observation, xi,j, is available for each μi,j. It seems reasonable
to reduce the statistical model by including prior assumptions on μi,j. We could, for
example, postulate that μi,j = μi does not depend on j. The expected number of
items sold then depends on the retailer but is constant over time. We are then left
with I unknowns, which can be "estimated" reasonable well from the data provided
that the number of weeks J is suﬃciently large. More ﬂexible, alternative models are
μi,j = μi+βij and μi,j = μi+βμij, with, respectively, 2I and I+1 parameters. Both
models correspond to a linear dependence of the expected demand on time.
Example 1.5 Regression
Tall parents in general have tall children, and short parents, short children. The heights
of the parents have a high predictive value for the ﬁnal (adult) length of their children,
their heights once they stop growing. More factors inﬂuence it. The gender of the
5

1: Introduction
child, of course, plays an important role. Environmental factors such as healthy eating
habits and hygiene are also important. Through improved nutrition and increased
hygiene in the past 150 years, factors that hinder growth like infectious diseases and
malnutrition have decreased in most Western countries. Consequently, the average
height has increased, and each generation of children is taller.
The target height of a child is the height that can be expected based on the heights
of the parents, the gender of the child, and the increase of height over generations. The
question is how the target height depends on these factors.
Let Y be the height a child will reach, let x1 and x2 be the heights of the
biological father and mother, respectively, and let x3 be an indicator for the gender
(x3 = −1 for a girl and x3 = 1 for a boy). The target height EY is modeled using a
so-called linear regression model
EY = β0 + β1x1 + β2x2 + β3x3,
where β0 is the increase in average height per generation, β1 and β2 are the extent to
which the heights of the parents inﬂuence the target height of their oﬀspring, and β3
is the deviation of the target height from the average ﬁnal height that is caused by the
gender of the child. Since men are, on average, taller than women, β3 will be positive.
The model described above does not say anything about individual heights, only
about the heights of the oﬀspring of parents of a certain height. Two brothers have the
same target height, since they have the same biological parents, the same gender, and
belong to the same generation. The actual ﬁnal height Y can be described as
Y = β0 + β1x1 + β2x2 + β3x3 + e,
where e = Y −EY is the deviation of the actual ﬁnal height Y from the target height
EY . The observation Y is also called the dependent variable, and the variables x1, x2,
and x3 the independent or predictor variables. The deviation e is commonly assumed
to have a normal distribution with expectation 0 and unknown variance σ2. The ﬁnal
height Y then has a normal distribution with expectation β0 + β1x1 + β2x2 + β3x3
and variance σ2.
In the Netherlands, the increase in the height of youth is periodically recorded.
In 1997, the Fourth National Growth Study took place. Part of the study was to
determine the correlation between the ﬁnal height of the children and the heights
of their parents. To determine this correlation, data were collected on adolescents
and their parents. This resulted in the following observations: (y1, x1,1, x1,2, x1,3),
. . . , (yn, xn,1, xn,2, xn,3), where yi is the height of the ith adolescent, xi,1 and xi,2
are the heights of the biological parents, and xi,3 is an indicator for the gender of
the ith adolescent. Suppose that the observations are independent replicates of linear
regression model given above; in other words, given xi,1, xi,2, and xi,3, the variable
Yi has expectation β0 + β1xi,1 + β2xi,2 + β3xi,3 and variance σ2. The parameters
(β0, β1, β2, β3) are unknown and can be estimated from the observations. For a simple
interpretation of the model, we choose β1 = β2 = 1/2, so that the target height is
equal to the average height of the parents corrected for the gender of the child and the
inﬂuence of time. The parameters β0 and β3 are equal to the increase in height in the
6

1.2: Statistical Models
previous generation and half the average height diﬀerence between men and women.
These parameters are estimated using the least-squares method (see Example 3.44).
The parameter β0 is estimated to be 4.5 centimeters, and β3 is estimated to be 6.5
centimeters.† The estimated regression model is then equal to
(1.1)
Y = 4.5 + 1
2(x1 + x2) + 6.5x3 + e.
Figure 1.3 shows the heights of 44 young men (on the left) and 67 young women
(on the right) set out against the average heights of their parents.‡ The line is the
estimated regression line found in the Fourth National Growth Study.
165
170
175
180
185
170
175
180
185
190
195
200
165
170
175
180
185
160
165
170
175
180
185
Figure 1.3. Heights (in cm) of sons (left) and daughters (right) set out against the average height
of their parents. The line is the regression line found in the Fourth National Growth Study.
We can use the estimated regression model found in the Fourth National Growth
Study to predict the ﬁnal heights of children born now. We must then assume that the
height increase in the next generation is again 4.5 centimeters and that the average
height diﬀerence between men and women remains 13 centimeters. Based on the
model presented above, the target heights of sons and daughters of a man of height 180
cm (≈71 in or 5'9") and a woman of height 172 cm are 4.5 + (180 + 172)/2 + 6.5 =
187 cm and 4.5 + (180 + 172)/2 −6.5 = 174 cm, respectively.
Other European countries use other models. In Switzerland, for example, the
target height is
EY = 51.1 + 0.718 x1 + x2
2
+ 6.5x3.
† An inch is approximately 2.54 cm, so 4.5 cm corresponds to 4.5/2.54 ≈1.8 in and 6.5 cm
≈2.6 in.
‡ Source: The data were gathered by the department of Biological Psychology of VU University
Amsterdam during a study on health, lifestyle, and personality. The data can be found on the book's
webpage at http://www.aup.nl under heightdata.
7

1: Introduction
The target heights of sons and daughters of parents of the same heights as above are
now 184 and 171 centimeters, respectively.
In the example above, there is a linear correlation between the response Y and the
unknown parameters β0, . . ., β3. In that case, we speak of a linear regression model.
The simplest linear regression model is that where there is only one predictor variable:
Y = β0 + β1x + e;
this is called a simple linear regression model (in contrast to the multiple linear
regression model when there are more predictor variables).
In general, we speak of a regression model when there is a speciﬁc correlation
between the response Y and the observations x1, . . ., xp:
Y = fθ(x1, . . ., xp) + e,
where fθ describes the correlation between the observations x1, . . ., xp and the
response Y , and the random variable e is an unobservable measurement error with
expectation 0 and variance σ2. If the function fθ is known up to the ﬁnite-dimensional
parameter θ, we speak of a parameterized model. The linear regression model
is an example of this; in this model, we have θ = (β0, . . ., βp) ∈Rp+1 and
fθ(x1, . . ., xp) = β0 + β1x1 + . . . + βpxp. The regression model is then ﬁxed if
we know the values of θ and σ2. The function fθ can, however, also be known up to
the ﬁnite-dimensional parameter θ and an inﬁnite-dimensional parameter. We then
speak of a semiparametric model. An example of a semiparametric model is the
Cox regression model. This model is described at the end of this chapter, after the
exercises. In Chapter 7, we discuss several regression models in detail, including the
linear regression model and the Cox regression model.
Example 1.6 Water levels
In the 20th century (between 1910 and 2000), extreme water levels were measured
70 times in the river the Meuse near the town of Borgharen (Netherlands). Here,
"extreme" is deﬁned by Rijkswaterstaat (the Dutch government agency responsible
for the management of waterways) as "more than 1250 m3/s." The maximal water
ﬂows during those 70 periods are shown in chronological order in Figure 1.4. The
problem is predicting the future. Rijkswaterstaat is particularly interested in how high
the dikes must be to experience ﬂooding at most once every 10 000 years. We can use
a hydraulic model to compute the height of the water from the water ﬂow.
♭The data can be found on the book's webpage at http://www.aup.nl under maxflows and
flows1965.
8

1.2: Statistical Models
Since the maximal water ﬂows x1, . . ., x70 were measured in (mostly) diﬀerent
years, and the water level of the Meuse depends mainly on the weather in the Ardennes
and further upstream, it is not unreasonable to view these numbers as realizations
of independent random variables X1, . . ., X70. The assumption that these parameters
are also identically distributed is somewhat questionable because the course of the
Meuse (and also the climate) has gradually changed during of the last century, but this
assumption is usually made anyway. We can then view X1, . . ., X70 as independent
copies of one variable X and use the measured values x1, . . ., x70 to answer the
question.
Let E be the event that ﬂooding takes place in an (arbitrary) year. The probability
of event E is approximately equal to the expected number EN of extreme periods
in a year, times the probability that there is a ﬂood in an extreme period, that is,
P(E) ≈EN P(X > h) for X a maximal water ﬂow in a period of extreme water
ﬂow, h the maximal water ﬂow so that there is no ﬂood, and N the number of times we
have extremely high water levels in an arbitrary year. For this computation, we use that
the probability of ﬂooding in an extreme period P(X > h) is small. The probability
distribution of N is unknown, but it is reasonable to assume that the expectation of
N is approximately equal to the average number of periods of extreme water ﬂow per
year in the past 90 years, so EN ≈70/90. The question is now: for which number h
do we have P(X > h) = 1/10000 · 90/70 = 0.00013?
0
500
1000
2000
3000
Figure 1.4. Maximal water ﬂows in m3/s (vertical axis) in the Meuse near Borgharen in the 20th
century in chronological order (horizontal axis).
This question cannot easily be answered. If the observed maxima for a period of
100 000 years (or more) were available, then we could determine h with a reasonable
accuracy, for example as the value of the 10%th highest measured water level (10% =
10 000/100 000). Unfortunately, we dispose over only 70 observations, and must
therefore extrapolate far into the future to a (probably) much more extreme situation
than ever measured. If we can determine a good model for the distribution of X, then
this is not a problem. If we, for example, knew that X has the standard exponential
9

1: Introduction
distribution, then we could determine h from the equation 0.00013 = P(X > h) =
e−h. This is not, however, a realistic assumption.
An alternative is given by ﬁtting an extreme value distribution to the data.
These are probability distributions that are commonly used for modeling variables
X that can be viewed as a maximum X = max(Y1, . . ., Ym) of a large number of
independent variables Y1, . . ., Ym. Given the interpretation of X as a maximal water
ﬂow in a period, such distributions seem reasonable. Of the three types of extreme
value distributions, one type proves to ﬁt the data reasonably well. This is the Fr´echet
family, where the distribution function is given by
F(x) =

e−((x−a)/b)−α
if x ≥a,
0
if x < a.
The Fr´echet family has three parameters: a ∈R, b > 0, and α > 0. If we are
convinced of the usefulness of the resulting model, we can estimate these parameters
from the 70 data points and then answer the question through a simple computation.
In Chapter 3, we discuss suitable estimation methods and in the application after
Chapter 6, we further work out the data of the water ﬂows.
Example 1.7 Survival analysis
In survival analysis, we study the probability distribution of time spans. You can think
of the life span of a light bulb, but also of the time before the next bug occurs in a
computer program ("reliability analysis") and, in particular, of the remaining time
until death or until the occurrence of a disease in medical statistics. Below is an
example.
In persons with a leaking heart valve, the heart valve is often replaced by
a biological or mechanical heart valve. A disadvantage of the biological over the
mechanical heart valve is the relatively short life span (10 to 15 years). To study
the distribution function F of the life span of a biological heart valve, n persons
with such a valve are followed from the operation up to the moment that the valve
must be replaced. At the end of the study, we have measured the life spans t1, . . . , tn
of all of the n heart valves. We view these numbers as realizations of independent
random variables T1, . . ., Tn with distribution function F. The probability F(t) that
a biological heart valve must be replaced within t years can be estimated by the
proportion of heart valves in the sample that is replaced within t years.
A special aspect of survival analysis is that, often, not all life spans are observed.
At the moment that we want to draw conclusions from the data, for example, not all
heart valves have needed replacement or a patient may have died with a heart valve
that was still good. In those cases, too, we only observe a lower bound for the life
spans, the time until the end of the study or until the death of the patient. We know
that the heart valve still worked when the study was ended or the patient died. We then
speak of censored data.
10

1.2: Statistical Models
Long life spans are more frequently censored than short ones because the
probability that the patient dies is greater during a long period of time than during
a short one (and the same holds for the study ending). It would therefore be wrong to
ignore censored data and estimate the distribution function F based on the uncensored
data. This would lead to an overestimate of the distribution function of the life span
and an underestimate of the expected life span because relatively longer life spans
would be ignored. A correct approach is to use a statistical model for all observations,
both censored and uncensored.
The statistical model becomes even more complex if we suspect that there are
factors that could inﬂuence the life span of the heart valve, for example the age,
weight, or gender of the patient. In such a case, the life span can be modeled using, for
example, the Cox regression model. This model is studied at the end of this chapter
(after the exercises) and in Chapter 7.
Example 1.8 Selection bias
To correctly answer a research question, it is important that this question, the collected
data, and the statistical model are correctly aligned. This is illustrated below.
The Dutch Railways (Nederlandse Spoorwegen or NS for short) regularly receive
complaints about crowding in the trains during rush hour. A study is set up to
investigate whether these complaints are justiﬁed. There are two research questions.
The ﬁrst is what percentage of the passengers does not have a seat during rush
hour. The second is what percentage of rush hour trains is too crowded. Note that
these are two fundamentally diﬀerent questions. The ﬁrst question concerns people,
a percentage of passengers, while the second question concerns trains. A passenger
is probably only interested in the ﬁrst research question, while the NS also attach
importance to the answer of the second. They have to identify on which trains there
are problems, and where measures must be taken.
To answer the ﬁrst research question, a sample of size 50 is taken from train
passengers that have just got oﬀ. Each person is asked whether they could sit. We
observe the sequence x1, . . . , x50, where xi equals 1 if the ith person did not have
a seat and xi is equal to 0 if the ith person did have a seat. Then x1, . . ., x50
are realizations of independent random variables X1, . . ., X50 with a Bernoulli
distribution with parameter p, where p = P(Xi = 1) is the proportion of passengers
that could not be seated. As in Example 1.2, we can estimate the proportion p using
the sample mean 50−1 50
i=1 xi. This is a correct way to answer the research question.
Answering the second research question is more diﬃcult, because it concerns
trains and not persons. To carry out this study, during rush hour, 50 head conductors
are randomly chosen and asked whether the train they were just on was overcrowded.
We observe the sequence y1, . . . , y50, where yi is equal to 1 if the ith head conductor
indicates that the train was overcrowded and yi is equal to 0 if this was not the case.
We can again view y1, . . . , y50 as realizations of Y1, . . . , Y50, which are independent
Bernoulli variables with probability q = P(Yi = 1). If we assume that there is only
one head conductor on each train, the probability q equals the proportion of rush hour
11

1: Introduction
trains that were overcrowded. We can see Y1, . . . , Y50 as a sample from the trains that
just pulled in. The proportion q can be estimated using the sample mean 50−1 50
i=1 yi.
It is simpler to also ask the sample of travelers we gathered to answer the ﬁrst
research question whether the train they were in was overcrowded. In that case, we
observe a sequence of realization of the independent Bernoulli variables Z1, . . . , Z50
with r = P(Zi = 1). Here, Zi is deﬁned analogously to Yi. Since a train carries more
than one passenger, not every train passenger will correspond to a unique train. Since
there are more persons in crowded trains than in quiet ones, the percentage "people
from crowded trains" in the population of train passengers will be much higher than
the percentage of "crowded trains" in the population of trains. In other words, r will
be greater than q. It is diﬃcult to give a correlation between r and q without making
additional assumptions. That is why the second research question could not easily be
answered based on a sample from the passengers, while the ﬁrst research question
could.
In most of the examples given above, the statistical model is parameterized by
a parameter, for example p, (μ, σ2), (β0, β1, β2, β3), or (a, b, α). Many statistical
models are known up to a parameter. In this book, we often denote that parameter
by θ ("theta"). The statistical model can then be denoted by {Pθ: θ ∈Θ}, where
Pθ is the probability distribution of the observation X and Θ is the set of possible
parameters. There is a tacit assumption that exactly one of the parameter values (or
exactly one element of the model) gives the "true" distribution of X. The purpose of
statistics is to ﬁnd that value. What makes statistics diﬃcult, is that we never fully
succeed and that statements about the true parameter value always contain a certain
element of uncertainty (by deﬁnition).
Exercises
1. Suppose that n persons are chosen randomly from a population and asked their political
aﬃliation. Denote by X the number of persons from the sample whose aﬃliation is with
political party A. The proportion of individuals in the population aﬃliated with party A is
the unknown probability p. Describe a corresponding statistical model. Give an intuitively
reasonable "estimate" of p.
2. Suppose that m + n patients with high blood pressure are chosen randomly and divided
arbitrarily into two groups of sizes m and n. The ﬁrst group, the "treatment group," is
given a particular blood-pressure-lowering drug; the second group, the "control group," is
given a placebo. The blood pressure of each patient is measured before and one week after
administering the drug or placebo, and the diﬀerence in blood pressure is determined. This
gives observations x1, . . ., xm and y1, . . ., yn.
(i) Formulate a suitable statistical model.
(ii) Give an intuitively reasonable "estimate" of the eﬀect of the drug on the height of the
blood pressure, based on the observations (several answers are possible!).
12

1: Exercises
3. We want to estimate the number of ﬁsh, say N, in a pond. We proceed as follows. We catch r
ﬁsh and mark them. We then set them free. After some time, we catch n ﬁsh (without putting
them back). Of these, X are marked. Consider r and n as constants we choose ourselves, and
let X be the observation.
(i) Formulate a suitable statistical model.
(ii) Give an intuitively reasonable "estimate" of N based on the observation.
(iii) Answer the previous questions if, the second time we catch ﬁsh, they are put back
directly after catching them (sampling with replacement).
4. When assessing a batch of goods, we continue until 3 items are rejected.
(i) Formulate a suitable statistical model.
(ii) The third rejected item is the 50th we assess. Give an estimate of the percentage of
defect items in the batch. Justify your choice.
5. The number of customers in the post oﬃce seems to depend on the day of the week (weekday
or Saturday) and half-day (morning or afternoon). On workdays, the post oﬃce is open in the
morning and in the afternoon, and on Saturday, is it open only in the morning. To determine
how many employees are required to provide prompt service, the number of customers is
registered over a period of ten weeks. Every day, the number of customers in the post oﬃce
in the morning (on weekdays and Saturdays) and in the afternoon (on weekdays only) is
noted.
(i) Formulate a suitable statistical model.
(ii) Give an intuitively reasonable "estimate" of the number of clients on a Monday
afternoon. Justify your choice.
(iii) The biggest diﬀerence in numbers of customers is between the half-days during
the workweek (Monday through Friday, mornings and afternoons) and the Saturday
morning. It was therefore decided to only take into account this diﬀerence in the staﬀ
planning. Reformulate the statistical model and give a new estimate.
6. The yearly demand for water in the African city of Masvingo is greater than the amount
that can be recovered from the precipitation in one year. Therefore, water is supplied from a
nearby lake according to the need. The amount of water that needs to be supplied per year
depends on the precipitation in that year and on the size of the population of Masvingo.
Moreover, rich people use more water than poor people. Describe a linear regression
model with "amount of water to be supplied" as dependent variable and "population
size," "precipitation," and "average income" as predictor variables. Indicate for each of the
parameters whether you expect them to be positive or negative.
7. A linear correlation is suspected between the income of a person and their age and level of
education (low, middle, high).
(i) Describe a linear regression model with "income" as dependent variable and "age" and
"education" as predictor variables. Think carefully about how to include the variable
"education" in the model.
(ii) We want to study whether the gender of a person has an inﬂuence on the income. Adapt
the linear regression model so that this can be studied.
8. We want to estimate the average length of wool ﬁbers in a large bin. The bin is ﬁrst shaken
well, after which we take a predeﬁned number of ﬁbers from the bin, one by one and with
closed eyes. We estimate the average length of the wool ﬁbers in the bin to be the average
length of the wool ﬁbers in the sample. Is the estimated length systematically too long,
systematically too short, or just right?
13

1: Introduction
9. At a call center, we want to estimate how long a customer must wait before being helped.
For one day, we register how long each customer must wait. If the customer looses patience
and hangs up, their waiting time up to that moment is noted. Afterward, we calculate the
average waiting time by taking the average of the noted times. This average is used as an
estimate of the waiting time of a new customer. What do you think of this method?
14

COX REGRESSION
In survival analysis, we are interested in the distribution function of the time span
before the occurrence of a particular event, for example, the time before dying after
a serious operation, the time before a certain device breaks down, or the time before
an ex-convict commits a new crime. Several factors can inﬂuence this distribution
function. For example, a young woman will presumably have a lower probability of
dying after a serious operation than an older woman, and, hopefully, more time will
pass before an ex-convict commits a new crime if he receives ﬁnancial support than
if he does not. It is important to gain insight in how and how much these factors
inﬂuence the "life span," so that we can determine a more person-speciﬁc risk and
take measures to reduce risks. If, for example, ex-convicts are more likely to commit
a new crime if they are in ﬁnancial diﬃculty after returning to society, then ﬁnancial
support or help in ﬁnding a job may help these people stay on the right track. In this
application, we will use a sample to delve more deeply into survival analysis.
Ex-convicts often fall back into their old habits and come back into contact with
police and justice. Suppose that we want to study the distribution function of the time
span between release and recidivism and whether ﬁnancial support after release has
a positive eﬀect on the time before an ex-convict comes back into contact with police.
To begin with, we assume that there are no other factors.
Suppose that 100 ex-convicts are followed during one year. We know of each of
them whether they commit a new crime within a year and if so, how many weeks after
their release. We want to use these data to research which percentage of ex-convicts
commit a new crime within t weeks (with t ∈[0, 52]). We ﬁrst set up a statistical model
for these data. Deﬁne Y t
i for i = 1, . . . , 100 as the indicator that tells us whether the
ith ex-convict has committed a new crime within t weeks; yt
i = 0 if they have not,
and yt
i = 1 if they have. Then Y t
1 , . . . , Y t
100 are Bernoulli-distributed with unknown
parameter pt = P(Y t
i = 1), the probability of recidivism within t weeks. Under the
assumption that the variables Y t
1 , . . . , Y t
100 are, moreover, independent, the statistical
model is ﬁxed. We could "estimate" the probability pt using the fraction 100
i=1 yt
i/100.
If the number of ex-convicts we follow, in our case 100, is large, then the proportion
we ﬁnd in the sample will lie close to the actual proportion pt; this follows from the
law of large numbers.
Often, studies are set up in a diﬀerent way. Instead of following all ex-convicts
for a year, we choose to restrict the length of the study to one year. We follow the
convicts released during that year until they commit a new crime (if they do) or until
the study ends. We have followed a total of 432 convicts in such a study. Figure 1.5
shows the observed time spans of 5 ex-convicts. Along the x-axis, the image on the
left has the time from the beginning of the study (the vertical line at time 0) until
the end of the study (the vertical line at week 52). The numbers along the y-axis are
the personal numbers of the ex-convicts. The ﬁrst person was released 10 weeks after
the study began and arrested 31 weeks after the beginning. This person was free for
31 −10 = 21 weeks. The second individual was released 27 weeks after the study
began and had not committed a new crime before the end of the study. We do not know
15

1: Introduction
whether this second person committed a new crime after the end of the study. The ﬁrst
52 −27 = 25 weeks, he did not. For the ﬁrst person, the measurements are complete,
while for the second we only have a lower bound for the time span until a new arrest.
We call this data right-censored.
0
10 20 30 40 50
5
4
3
2
1
time span (weeks)
0
10 20 30 40 50
5
4
3
2
1
time span (weeks)
Figure 1.5. Left: The time between release and new arrest ("time span") of 5 ex-convicts. The
x-axis indicates the time from the beginning of the study. Right: The same data, where the x-axis
indicates the times from release to new arrest or censoring (end of the study or death). A circle
indicates that the data for that person is right-censored.
The image on the right in Figure 1.5 shows the same information, a diﬀerent way.
The x-axis now shows the time from release to a new arrest. For individuals who were
not arrested again during the study, we only know a lower bound for the time span;
this is indicated by a small circle.
Suppose that, based on the observed data, we want to estimate the percentage
of ex-convicts who are arrested again within 26 weeks (a half year). For person 2
in Figure 1.5, for example, we know that he was still free after 25 weeks, but we do
not know anything about the period between 25 and 26 weeks; this person is right-
censored. A natural solution is to remove all right-censored persons from the data set
and use the same estimation method as described before. This proves to be a terrible
choice. The longer an ex-convict is free, the higher the probability that he will be right-
censored and therefore removed from the data set. An ex-convict who is rearrested 51
weeks after his release will only be included in the data set if he was released in
the ﬁrst week of the study. If he is released in the second week, then his data will be
censored by the end of the study. By ignoring right-censored individuals, relatively
many long "life spans" will be removed, and the proportion of ex-convicts who are
rearrested within t weeks in the stripped set will be (much) too high. For example, p51
now has probability close to 1. How should we estimate pt? To do this correctly, we
ﬁrst describe a statistical model for the observed data.
For an arbitrary ex-convict, we deﬁne T as the time span between release and
recidivism. We view T as a random variable with distribution function t →F(t) =
P(T ≤t) and density function f. The survival function S is deﬁned as t →S(t) =
1−F(t) = P(T > t) and describes the probability of not having been arrested again
16

1: Cox Regression
after t weeks. We could assume that the distribution function or the survival function
has a particular form (for example, that the distribution function corresponds to the
exponential or normal distribution), but if there is no prior knowledge of the form of
the distribution, it is better not to make any assumptions. An incorrect assumption can
lead to incorrect conclusions.
For some ex-convicts, the time span T is not observed during the study; at the
end of the study, they had not been rearrested (or the person had died). We therefore
also deﬁne, for each individual, the censoring time C as the time span between release
and the end of the study or death. If T ≤C, then we will observe that the individual
in questions commits a new crime, and if T > C, then we will observe not T but C.
We therefore deﬁne ˜T = min{T, C}, so that ˜T is observed for every individual in the
study. We, moreover, deﬁne Δ as the indicator function Δ = 1{T ≤C}; that is, Δ = 1
if T ≤C or, equivalently, ˜T = T , and Δ = 0 if T > C or, equivalently, ˜T = C. We
observe the pair ( ˜T, Δ) for every ex-convict in the data set. The data set consists of
the values (˜ti, δi) for i = 1, . . . , 432 for the 432 ex-convicts, where ˜ti and δi are the
observed values of ˜Ti and Δi.
Suppose that we want to estimate the probability of an arbitrary ex-convict not
having committed a new crime within 26 weeks (half a year); in other words, we want
to estimate S(26). To explain how to do this, we assume, for now, that we only have
data on 5 persons, shown in Figure 1.5. We have ˜t1 < ˜t2 < 26 < ˜t3 < ˜t4 < ˜t5 (see
Figure 1.5). Individual 1 is the only one whose rearrest within half a year has been
observed. We do not know anything about individual 2; he was censored within half a
year. To estimate S(26), we rewrite S(26) = P(T > 26) as
P(T > 26) = P(T > 26| ˜T > ˜t1)P( ˜T > ˜t1)
= P(T > 26| ˜T > ˜t2, ˜T > ˜t1)P( ˜T > ˜t2| ˜T > ˜t1)P( ˜T > ˜t1)
= P(T > 26| ˜T > ˜t2)P( ˜T > ˜t2| ˜T > ˜t1)P( ˜T > ˜t1).
Instead of estimating S(26) directly, we estimate the three factors on the last line
separately. We begin at the end, with the probability P( ˜T
> ˜t1). Individual 1
committed a crime in week 21. Of the ﬁve individuals, there are four for whom ˜T > ˜t1.
We therefore estimate the probability P( ˜T > ˜t1) to be 4/5. To estimate the second
factor, P(T > ˜t2| ˜T > ˜t1), we use only the data on the individuals who satisfy the
condition ˜T > ˜t1; these are individuals 2 through 5. Individual 2 was censored at
time ˜t2 (end of the study), so of the four ex-convicts that are left, there are only three
for whom ˜T > ˜t2. We estimate the probability P( ˜T > ˜t2| ˜T > ˜t1) to be 3/4. We
estimate the last probability, P(T > 26| ˜T > ˜t2) analogously. Of the three individuals
with ˜T > ˜t2, all have a T -value greater than 26; we therefore estimate this probability
to be 3/3 = 1. Multiplying the three estimates gives 0.6.
♯The data come from a study described in P.H. Rossi, R.A. Berk, and K.J. Lenihan, Money,
Work and Crime: Some Experimental Results (1980), Academic Press, New York. In our example, we have
modiﬁed the data (censored times randomly) to illustrate the concept of censoring. The modiﬁed
data can be found on the book's webpage at http://www.aup.nl under convicts.
17

1: Introduction
We can estimate S at another time than 26 or based on another data set
analogously. When we estimate the function S this way in values between 0 and 52
weeks, we ﬁnd a step function that only jumps (down) in points ti where δi = 1. Figure
1.6 shows the estimated survival curve S based on the full data set. If the number of
observations increases, the intervals where the curve is constant will become shorter,
as will the sizes of the jumps. We can prove that the estimate of S at a time t converges
(in probability) to the true value S(t) if the number of observations goes to inﬁnity. If
we had assumed that F is a known continuous function, for example the distribution
function corresponding to the exponential distribution, then we would estimate F
not with the method described above but with the (parametric) maximum likelihood
method described in Chapter 3. The survival curve would then be estimated by a
continuous decreasing curve. If, however, the assumption about the form of the curve
was wrong, then the estimate of S in an arbitrary point t would not converge (in
probability) to S(t).
Figure 1.6 also shows the estimated curve that would have been found if all
censored data was removed; for estimating S(t), all individuals censored before time
t are removed. The diﬀerence between the two curves increases with t. This is because
the more t increases, the more values are removed, and the greater the error that is
made. This approach leads to an underestimate of the survival curve.
0
10
20
30
40
50
0.0
0.2
0.4
0.6
0.8
1.0
weeks
Figure 1.6. Estimated survival curve based on all data (solid) and based on the data set from
which the censored observations have been removed (dashed).
Another way to represent the distribution of T is by using a so-called risk or
hazard function. The hazard function associated with a probability density f and
distribution function F is deﬁned as
t →λ(t) =
f(t)
1 −F(t) = f(t)
S(t).
If we view f(t) dt as the probability that T lies in the interval [t, t + dt), then λ(t) dt
has the interpretation
λ(t) dt ≈P(t ≤T < t + dt)
P(T > t)
= P(t ≤T < t + dt|T > t).
18

1: Cox Regression
The value λ(t) can therefore be viewed as the conditional probability of committing a
new crime right after time t given that at time t, the ex-convict had not been rearrested.
It is because of this interpretation as an "instantaneous probability" that the hazard
function is often used for modeling survival data. The hazard function is the derivative
of t →−log(1 −F(t)) with respect to t, and given the hazard function λ, we can
recover the distribution function F using the formula F(t) = 1 −e−Λ(t), where
Λ is the cumulative hazard function, that is, Λ(t) =
 t
0 λ(s)ds if F(0) = 0. The
density f is then equal to f(t) = λ(t)e−Λ(t). As for the survival curve, we could
now assume that the hazard function takes on a particular form. For example, if we
assume that the hazard function is constant, λ(t) ≡ν, then the corresponding density
is f(t) = λ(t)e−Λ(t) = νe−νt; in other words, T has an exponential distribution.
We can also make no assumption at all on the form. To obtain an estimate of the
distribution function of T , we can also turn to the hazard function and the formulas
given above.
If factors such as age, gender, and education possibly inﬂuence the time span,
then it is wise to include these in the model. Often, a so-called Cox model is chosen. In
this model, the hazard function for the ith ex-convict with observed variables Xi = xi
is of the form
λ(t|Xi = xi) = eβ1xi1+β2xi2+. . .+βKxiKλ0(t),
where xik is the value of the kth variable for the ith individual and K is the number
of variables in the model. The function t →λ0(t) is called the baseline hazard
function and is equal to the hazard function when all predictor variables are equal to
0. According to the Cox model, the hazard functions of two ex-convicts with predictor
variables xi and xj are proportional; this means that
λ(t|Xi = xi)
λ(t|Xj = xj) = eβT (xi−xj),
does not depend on t.
This gives a simple interpretation for the parameter β: it determines the size
of the relative risks attached to certain predictor variables. For example, suppose
that two ex-convicts score the same for all predictor variables, with the exception of
ﬁnancial support. Person i receives ﬁnancial support (xi1 = 1), while person j does
not (xj1 = 0). The ratio of the hazard functions then reduces to
λ(t|Xi = xi)
λ(t|Xj = xj) = eβ1(xi1−xj1) = eβ1.
If β1 takes on the value −0.400, then the risk of being arrested again is e−0.400 =
0.670 times as great for the ith ex-convict as it is for the jth. The relative risk is
therefore independent of the time since the release of the ex-convicts.
In our example, the Cox model includes the following predictor variables:
ﬁnancial support or not, age, race, marital status, number of prior convictions.
Based on the data of the 432 ex-convicts, we can estimate the regression parameter
β = (β1, . . ., β5) and the unknown baseline hazard function λ0. A suitable method
is elaborated in Chapter 7. Here, we will only give the results. Table 1 shows the
estimates of the regression parameters β1, . . . , β5.
19

1: Introduction
β1
β2
β3
β4
β5
estimate
−0.400
−0.0425
0.282
−0.590
0.0977
exp(estimate)
0.670
0.958
1.326
0.554
1.103
Table 1.1. Estimates of β1, . . ., β5; the parameters correspond to, respectively, ﬁnancial support
or not (0: no support, 1: support), age, race (0: other; 1: black), marital status (0: not married, 1:
married), and number of prior convictions.
The estimate of the regression parameter β1 is negative, ﬁnancial support after
release therefore has a positive eﬀect. However, it seems that being married has a
stronger positive eﬀect than receiving ﬁnancial help. If this eﬀect is causal (see the
application after Chapter 7), then it would be wiser to help an ex-convict ﬁnd a partner
than to help him ﬁnd a job.
In the above, we have made several assumptions for our model. For example, we
have assumed that the hazard functions of two ex-convicts are proportional and that
the predictor variables are additive. These assumptions must, of course, be veriﬁed.
We can do so, for example, by plotting suitable graphs. We refer to the literature for
more information.
20

2 Descriptive Statistics
2.1 Introduction
A statistical model is an expression of our prior knowledge of the probability
experiment that led to the observed data. The model postulates that the observation
X is generated from one of the probability distributions in the model. How do we ﬁnd
a good model? In some cases, the model is clear from the way the experiment was set
up. For example, if in a poll, the sample has been taken randomly and with replacement
from a well-deﬁned population, then the binomial distribution is inevitable. If the
observations concern numbers of emitted radioactive particles, then the Poisson
distribution is the right choice because of the physical theory of radioactivity. It is also
possible that the experiment strongly resembles past experiments, and that a particular
model is suggested by experience. The choice of a statistical model is certainly not
always uncontroversial. At the very least, the chosen model must be validated. In
some cases, this is done before estimating the model parameters, and in other cases
after. These methods are not only applied to the data itself but often also to "residuals,"
after the estimation of, for example, a regression model. In this chapter, we discuss
some of these methods.
21

2: Descriptive Statistics
2.2 Univariate Samples
Suppose that the numbers x1, . . . , xn are the outcomes of a repeated experiment.
From the manner in which the n experiments are carried out (with the same initial
situation, without any "memory" of the previous experiments), we deduce that it is
reasonable to view the n numbers as realization of a univariate sample X1, . . . , Xn;
the random variables are independent and identically distributed. This already ﬁxes
the statistical model for a large part. The remaining question is: which collection of
(marginal) distributions do we use? In this section, we discuss a number of numerical
and graphical methods that can help.
Two important numerical properties of a distribution are location and dispersion.
The expectation and median are often used for the location of a distribution; they are
equal to each other when the distribution is symmetric. When the distribution has a tail
to the right (respectively, to the left), the expectation is greater (respectively, less) than
the median. To obtain an idea of the location of the underlying distribution based on
observations x1, . . . , xn, we can use the sample mean or sample median. The sample
median is the middle value in a sequence of sorted observations.
Deﬁnition 2.1 Sample mean
The sample mean of a sample X1, . . . , Xn is the random variable
X = 1
n
n

i=1
Xi.
The dispersion of a distribution can be represented by the variance (or standard
deviation) and the interquartile range. The interquartile range is the distance between
the upper and lower quartiles of the distribution. Using the observations x1, . . . , xn,
we can compute the sample interquartile range and the sample variance to obtain an
idea of the dispersion. The sample interquartile range is the distance between the upper
and lower quartiles of the data.
Deﬁnition 2.2 Sample variance
The sample variance of a sample X1, . . . , Xn is the random variable
S2
X =
1
n −1
n

i=1
(Xi −X)2.
In practice, the observed sample mean and observed sample standard deviation
are often given when the distribution appears to be symmetric. For asymmetric
distributions, the observed sample median and observed sample interquartile range are
preferred. The best way to determine whether a distribution is symmetric is to use a
22

2.2: Univariate Samples
graphical method. In the next section, we present three graphical methods: histograms,
boxplots, and QQ-plots.
2.2.1 Histograms
A simple technique to obtain an idea of the probability density giving the data
x1, . . . , xn is the histogram. For a partition a0 < a1 < · · · < am that covers the
range of the data x1, . . . , xn, this is the function that, on each interval (aj−1, aj],
takes on the value equal to the number of sample points xi in that interval divided by
the length of the interval. If the intervals (aj−1, aj] all have the same length, then the
histogram is sometimes also deﬁned without dividing by the interval length. In that
case, the heights of the bars of the histogram are equal to the numbers of observations
in the various intervals.
To obtain an idea of the probability density giving certain data, it is useful to
represent the histogram and possible densities in a single diagram. This can be done
by scaling the histogram by 1/n, where n is the total number of data points. The
area under the histogram is then equal to 1, as it is for a probability density. In x ∈
(aj−1, aj], the scaled histogram is given by
hn(x) = #(1 ≤i ≤n: xi ∈(aj−1, aj]

n(aj −aj−1)
=
1
n(aj −aj−1)
n

i=1
1aj−1<xi≤aj,
where the indicator function 1aj−1<xi≤aj is equal to 1 for aj−1 < xi ≤aj and 0
elsewhere. Another way to write this indicator function is 1(aj−1,aj](xi).
A scaled histogram provides a good impression of the density giving the data
x1, . . . , xn, provided that the partition a0 < a1 < · · · < am has been chosen well and
that the number of sample points n is not too small. To see this, we view x1, . . . , xn as
realizations of random variables with density f and compute the expected value of the
scaled histogram hn in terms of X1, . . . , Xn in an arbitrary point x where f(x) > 0.
Suppose that for some 1 < j ≤m, we have aj−1 < x ≤aj; then this expected value
is equal to
Ehn(x) = E
1
n(aj −aj−1)
n

i=1
1aj−1<Xi≤aj =
1
aj −aj−1
E1aj−1<X1≤aj
=
1
aj −aj−1
P(aj−1 < X1 ≤aj) =
 aj
aj−1 f(s) ds
aj −aj−1
.
If f does not vary too much over the interval (aj−1, aj], then the last expression is
approximately equal to the value of f on this interval. The computation shows that the
expected value of hn(x) is approximately equal to f(x). By the law of large numbers
(Theorem A.26), we moreover know that the value hn(x) converges in probability to
this expected value.
23

2: Descriptive Statistics
A histogram therefore provides an impression of the distribution giving a sample.
Unfortunately, we only obtain a good impression if the sample is suﬃciently large (for
example, n = 100 or even better n = 500) and the intervals have been chosen well.
The choice of the intervals is a question of taste. If the chosen intervals are too short,
then, in general, the histogram is too spiky to notice properties of the true density. If
the intervals are too long, then all detail is lost, and little can be said about the true
density based on the histogram. Hence, we may not expect more than a ﬁrst impression
from the histogram. Other, more complicated, techniques can give better results.
Example 2.3 Height
Figure 2.1 shows histograms for the heights (in cm) of 44 men (on the left) and 67
women (on the right).† The histograms have been scaled in such a way that the areas
under the histograms are equal to 1. Both ﬁgures also show the density of a normal
distribution. The expectation and variance of these normal distributions are equal,
respectively, to the sample mean and sample variance of the corresponding data. Based
on the forms of the histograms, there is some doubt whether the data can come from a
normal distribution. The deviation from symmetry in the histogram on the left may be
due to the small number of observations. Further research is certainly recommended.
165
175
185
195
0.00
0.01
0.02
0.03
0.04
0.05
155
165
175
185
0.00
0.02
0.04
0.06
Figure 2.1. Histograms of the heights (in cm) of 44 men (on the left) and 67 women (on the right),
together with the densities of the normal distributions with expectations equal to the sample means
and variations equal to the sample variations of the data.
† Source: The data were gathered by the department of Biological Psychology of VU University
Amsterdam during a study on health, lifestyle, and personality. The data can be found on the book's
webpage at http://www.aup.nl under heightdata.
24

2.2: Univariate Samples
Example 2.4 Normal distribution
Figure 2.2 shows the density of the standard normal distribution, together with four
realizations of the histogram, based on 30, 30, 100, and 100 observations, where the
partitions were chosen by the statistical software package R. The ﬁgures at the top left
and at the bottom right show a clear deviation from symmetry. Because the data come
from the normal distribution, this is merely due to chance variations.
−3
−2
−1
0
1
2
3
0.0
0.1
0.2
0.3
0.4
−3
−2
−1
0
1
2
3
0.0
0.1
0.2
0.3
0.4
−3
−2
−1
0
1
2
3
0.0
0.1
0.2
0.3
0.4
−3
−2
−1
0
1
2
3
0.0
0.1
0.2
0.3
0.4
Figure 2.2. Histograms of samples with 30 (top row) and 100 (bottom row) observations from the
standard normal density, shown together with the true density.
2.2.2 Boxplots
A boxplot is a graphical representation of the data that gives an idea of the location and
dispersion of the data, of possible outliers in the observations, and of the symmetry
of the distribution giving the observations. In the boxplot, the observations are set
out along the vertical axis. The bottom of the "box" is drawn at the level of the
lower quartile, and the top at the level of the upper quartile of the data. The lower
(respectively, upper) quartile of the data is the value x for which one fourth of the
data points are less (respectively, greater) than x. The width of the box is arbitrary.
The box has a horizontal line at the level of the median of the data. The median is
the middle value in a sorted row of data. At the top and bottom of the box, whiskers
are drawn. The whisker at the top links the box to the greatest observation that lies
within 1.5 times the interquartile range of the upper quartile. The interquartile range
is the distance between the lower and upper quartiles, that is, the height of the box. The
whisker at the bottom is drawn analogously. Observations that lie beyond the whiskers
are indicated separately, for example by a star, a small circle, or a dash.
25

2: Descriptive Statistics
Example 2.5 Some common distributions
Figure 2.3 shows boxplots of samples from the exponential distribution with parameter
1, the standard normal distribution, and the standard Cauchy distribution. The samples
from the exponential and Cauchy distributions have outliers, shown by the small
circles beyond the whiskers. The boxplot in the middle shows that the data from the
standard normal distribution are quite symmetric with respect to the median and do
not contain any outliers.
exp(1)
N(0,1)
Cauchy
−6
−4
−2
0
2
4
Figure 2.3. Boxplots of samples of size 20 from the standard exponential distribution (left), the
standard normal distribution (middle), and the standard Cauchy distribution (right).
2.2.3 Location-Scale Family and QQ-plots
A third graphical method that is commonly used to ﬁnd a suitable class of distributions
(a so-called location-scale family) given a sample x1, . . . , xn is drawing QQ-plots. In
this section, we ﬁrst discuss location-scale families and then QQ-plots.
Deﬁnition 2.6 Location-scale family
If the random variable X has a distribution function F, then Y = a + bX has the
distribution function Fa,b given by
Fa,b(y) = P(a + bX ≤y) = F
y −a
b

,
b > 0.
The family of distributions {Fa,b: a ∈R, b > 0} is called the location-scale family
associated with F (or "for X").
26

2.2: Univariate Samples
If F has probability density f, then Fa,b has probability density fa,b given by
fa,b(y) = d
dy F
y −a
b

= 1
b f
y −a
b

.
If EX = 0 and var X = 1, then a and b2 are, respectively, the expected value and
variance of Y , hence those corresponding to the distribution Fa,b.
To every (standard) distribution (normal, Cauchy, exponential, etc.) corresponds
a location-scale family. We note that members of one location-scale family do not
always all have the same name: the members of the location-scale family associated
with the standard Cauchy distribution are not all Cauchy distributions. Conversely,
distributions with the same name are not always members of the same location-scale
family: for example, χ2-distributions with diﬀerent numbers of degrees of freedom
are not in the same location-scale family.
Example 2.7 Normal distribution
Let X be a N(0, 1)-distributed random variable. From probability theory, we know
that Y = a + bX with b > 0 has the N(a, b2)-distribution. Hence, all members
of the location-scale family associated with the N(0, 1)-distribution are normally
distributed. Conversely, if Y has the N(a, b2)-distribution, then Y has the same
distribution as a + bX, where X has the standard normal distribution, and therefore
the N(a, b2)-distribution is a member of the location-scale family associated with the
standard normal distribution. In other words, all members of the location-scale family
associated with the N(0, 1)-distribution are normal distributions, and conversely, all
normal distributions are in the location-scale family associated with the N(0, 1)-
distribution.
"QQ-plots" are a graphical tool for ﬁnding a suitable location-scale family for a
given sample x1, . . . , xn. They are based on quantile functions. If, for a given α ∈
(0, 1), there exists exactly one number xα ∈R such that F(xα) = α, then xα is
called the α-quantile of F, denoted by F −1(α). As suggested by the notation, the
function α →F −1(α) is the quantile function, the inverse of F, provided that this is
well deﬁned. If F is strictly increasing and continuous, then F(F −1(α)) = α for all
α ∈(0, 1) and F −1(F(x)) = x for all x ∈R.
Example 2.8 Exponential distribution
Let X be a random variable with an exponential distribution with parameter λ. The
distribution function F of X is given by F(x) = 1 −e−λx for x ≥0, and the quantile
function F −1 is given by F −1(α) = −log(1 −α)/λ for α ∈(0, 1).
Because a distribution function can exhibit both jumps and constant sections,
in general the equation F(x) = α for a given α can have no solutions, exactly one
solution, or inﬁnitely many solutions (see Figure 2.4). To also be able to speak of an
α-quantile in the ﬁrst and last case, we deﬁne the quantile function of F as follows.
27

2: Descriptive Statistics
Deﬁnition 2.9 α-Quantile
The α-quantile (or α-point) of F is equal to
F −1(α) = inf{x: F(x) ≥α},
α ∈(0, 1).
In words, F −1(α) is the smallest value x with F(x) ≥α.
0.0
0.2
0.4
0.6
0.8
1.0
F-1(a)
a
F-1(b)
b
Figure 2.4. A distribution function and two quantiles.
There is a linear relationship between quantile functions of distributions within a
given location-scale family:
F −1
a,b (α) = a + b F −1(α)
(see Exercise 2.2). In other words, the points {(F −1(α), F −1
a,b (α)): α ∈(0, 1)} are on
the straight line y = a+bx. Figure 2.5 illustrates the fact that two normal distributions
belong to the same location-scale family.
−2
−1
0
1
2
−5
0
5
10
quantiles N(0,1)
quantiles N(2,16)
Figure 2.5. The quantiles of the N(2, 42)-distribution (y-axis) plotted against those of the N(0, 1)-
distribution (x-axis).
28

2.2: Univariate Samples
Notation 2.10 Order statistics
The order statistics of a sample X1, . . . , Xn are given by the sequence X(1), . . . ,
X(n), where the quantities have been placed in increasing order, X(1) ≤X(2) ≤
. . . ≤X(n). In particular, the ﬁrst and last order statistics are equal to
X(1) = min
1≤i≤n Xi
and
X(n) = max
1≤i≤n Xi.
For the ith order statistic X(i) of a given sample X1, . . . , Xn from a distribution
F, we have EF(X(i)) = i/(n + 1) (See Exercise 2.8). We may therefore expect the
points

i/(n + 1), F(x(i))

: i = 1, . . . , n

in the xy-plane to lie approximately on
the line y = x. The same must then hold for the points

F −1

i
n + 1

, x(i)

: i = 1, . . . , n

.
More generally, if the sample x1, . . . , xn comes from an element Fa,b of the location-
scale family associated with F, then we expect the points mentioned above to lie on the
line y = a+bx; after all, we then have x(i) ≈F −1
a,b (i/(n+1)) = a+bF −1(i/(n+1)).
Deﬁnition 2.11 QQ-plot
A QQ-plot of the data set x1, . . . , xn for a distribution function F is a plot of the
points

F −1

i
n + 1

, x(i)

: i = 1, . . . , n

.
A QQ-plot provides a graphical method to verify whether a sample can come
from the location-scale family associated with F. The Q stands for "quantile."
Example 2.12 Normal distribution
Figure 2.6 shows QQ-plots of six samples simulated from the N(2, 42)-distribution
using a random number generator, plotted against the N(0, 1)-distribution. Because
two normal distributions are in the same location-scale family, we can expect the
points to lie more or less on a straight line. The top and bottom ﬁgures represent data
sets of 10 and 50 observations, respectively. The points in the QQ-plots are not exactly
on a straight line, but rather vary slightly around a straight line. In small samples, this
variation is much greater than in larger samples.
29

2: Descriptive Statistics
−1.5
−0.5
0.5
1.5
−4
−2
0
2
4
quantiles N(0,1)
order statistics
−1.5
−0.5
0.5
1.5
0
5
10
quantiles N(0,1)
order statistics
−1.5
−0.5
0.5
1.5
−4
0
2
4
6
8
quantiles N(0,1)
order statistics
−2
−1
0
1
2
−5
0
5
10
quantiles N(0,1)
order statistics
−2
−1
0
1
2
−4
0
4
8
quantiles N(0,1)
order statistics
−2
−1
0
1
2
−5
0
5
10
quantiles N(0,1)
order statistics
Figure 2.6. Six QQ-plots of 10 (top row) or 50 (bottom row) data points from the N(2, 42)-
distribution plotted against the N(0, 1)-distribution.
If a QQ-plot of a sample x1, . . . , xn against the quantiles of F shows approxi-
mately the straight line y = x, then this is an indication that the data come from the
distribution F. Deviations from the line y = x give an indication of the deviation of
the true distribution of the data from F. The simplest case is that the plot does show
a straight line, but not the line y = x. This implies that the data come from another
member of the location-scale family associated with F, as in Example 2.12. The values
of a and b can then be approximated roughly by ﬁtting the line y = a + bx to the QQ-
plot. In Chapter 3, we will see other methods to estimate the parameters. Curved lines
are more diﬃcult to evaluate. These mainly give an indication of the relative weight
of the tails of the distribution of the data with respect to F. To illustrate the diﬀerent
types of deviations from linearity, Figure 2.7 shows some QQ-plots of "true" quantile
functions. These are plots of the points {(F −1(α), G−1(α)): α ∈(0, 1)} for various
distribution functions F and G.
Example 2.13 Height
Based on the form of the histograms in Figure 2.1, there is some doubt whether the
heights can come from a normal distribution. To study this further, QQ-plots have
been drawn in Figure 2.8 that show the heights of men (on the left) and women (on
the right) plotted against the standard normal distribution. To study whether the points
lie on a straight line, a suitable line y = a + bx has been drawn in both ﬁgures.
For the men, this is the line y = 183.5 + 7.5x, and for the women, it is the line
y = 171.3 + 6.2x. These lines have been determined by estimating a and b2 using the
maximum likelihood estimators for the expected value and variance (see Example 2.7
30

2.2: Univariate Samples
0.0
0.2
0.4
0.6
0.8
1.0
-2
-1
0
1
2
homogeen
normaal
-4
-2
0
2
4
-2
-1
0
1
2
logistiek
normaal
0
2
4
6
8
10
-2
-1
0
1
2
lognormaal
normaal
0
1
2
3
4
0
2
4
6
8
10
12
exponential
chi-squared_4
Figure 2.7. Plots of pairs of quantile functions: uniform-normal, logistic-normal, lognormal-
normal, exponential-χ2
4.
and Chapter 3). As the data follow these lines fairly well, we can conclude that the
location-scale family associated with the standard normal distribution is a good ﬁt for
these two data sets. Since this family contains only normal distributions, this supports
the assumption that the data come from normal distributions.
−2
−1
0
1
2
170
175
180
185
190
195
200
−2
−1
0
1
2
160
165
170
175
180
185
Figure 2.8. QQ-plots of the heights of 44 men (on the left) and 67 women (on the right) plotted
against the quantiles of a standard normal distribution.
31

2: Descriptive Statistics
2.3 Correlation
In many cases, the observations xi are not numbers but vectors xi = (xi,1, . . . , xi,d).
We are then often interested in the correlation between the diﬀerent coordinates. In this
section, we will restrict ourselves to vectors with two coordinates and denote these by
(xi, yi) (instead of (xi,1, xi,2)).
Deﬁnition 2.14 Scatter plot
A scatter plot of a sample of 2-dimensional data points (x1, y1), . . . , (xn, yn) is a
graph of these points in the xy-plane.
When there is a strong correlation between the x- and y-coordinates of the data
in a scatter plot, this is clearly visible. For example, the variables in the image on the
right in Figure 2.9 show a clear linear correlation, while no correlation is apparent in
the image on the left.
The linear correlation in the image on the right in Figure 2.9 is unmistakable,
but not perfect. The points do not lie exactly on a straight line but vary around an
(imaginary) line.
-3
-2
-1
0
1
2
3
-1
0
1
-3
-2
-1
0
1
2
3
-1.5
-1.0
-0.5
0.0
0.5
1.0
Figure 2.9. Scatter plots of two samples of 50 points: on the left with independent coordinates
(rx,y = −0.05) and on the right with coordinates with linear correlation (rx,y = 0.87).
Deﬁnition 2.15 Sample correlation coeﬃcient
The sample correlation coeﬃcient of a sample consisting of pairs (X1, Y1),
. . . , (Xn, Yn) is
rX,Y =
n
i=1(Xi −X)(Yi −Y )
(n −1)

S2
X

S2
Y
.
32

2.3: Correlation
The sample correlation coeﬃcient rx,y of the observed pairs (x1, y1), . . . ,
(xn, yn) is a numerical measure for the strength of the linear correlation and lies
between −1 and 1. The value can be interpreted as follows:
(i) If rx,y = 1, then the n points in the scatter plot lie exactly on the line y =
y + (sy/sx) (x −x) (total positive correlation).
(ii) If rx,y = −1, then the n points in the scatter plot lie exactly on the line y =
y −(sy/sx) (x −x) (total negative correlation).
(iii) If X1, . . . , Xn and Y1, . . . , Yn are independent samples, then the resulting rx,y
will take on values close to 0.
The ﬁrst two statements and the inequality |rx,y| ≤1 follow from the Cauchy-
Schwarz inequality from linear algebra.‡ The third statement follows from the fact
that independent random variables are uncorrelated, combined with the intuitively
plausible fact that the sample correlation coeﬃcient will approach the population
correlation coeﬃcient
ρ =
cov(X, Y )
√
var X
√
var Y
=
E(X −EX)(Y −EY )

E(X −EX)2
E(Y −EY )2
when n is large. Since cov(X, Y ) = E(X −EX)(Y −EY ) = E(XY )−EXEY , this
coeﬃcient ρ is equal to 0 for independent random variables X and Y : independent
random variables are uncorrelated. We give a further interpretation of the sample
correlation coeﬃcient when we discuss linear regression in Chapter 7.
-2
-1
0
1
2
3
-2
-1
0
1
2
3
-2
-1
0
1
2
3
0
2
4
6
8
Figure 2.10. Scatter plots of two samples of 50 data points, with sample correlation coeﬃcients
0.98 and -0.05, respectively. The image on the right gives the points (xi, y2
i ) for the points (xi, yi)
in the image on the left.
‡ The inner product of vectors a and b in Rn satisﬁes |a, b| ≤a b, where  ·  is the
Euclidean norm.
33

2: Descriptive Statistics
We may not invert statement (iii) to claim that a correlation close to 0 implies
that the two coordinates are independent. This is illustrated in Figure 2.10. The image
on the left shows a clear linear correlation, corresponding to a correlation coeﬃcient
of 0.98. The image on the right is a scatter plot of the points (xi, y2
i ) for the points
(xi, yi) in the image on the left. The quadratic correlation is clear. The "strength of the
correlation" between the two coordinates in the image on the right is no less than the
strength of the correlation in the image on the left. However, the sample correlation
coeﬃcient for the points in the image on the right is equal to −0.05. Apparently, this
numerical quantity is blind for the quadratic relationship that is present.
Example 2.16 Twin data
Height is largely hereditary. We already saw this in Example 1.5, which models the
correlation between the heights of parents and those of their children. This is also
apparent in studies of twins. Because identical twins are genetically identical and
fraternal twins in general share 50% of their genetic material, the correlation between
the heights of identical twins will be greater than that for fraternal twins (of the same
gender). In Figure 2.11, the heights of identical twins (men on the left, women on
the right) have been plotted against each other. Both scatter plots show a strong
correlation. The sample correlation of the 46 male identical twins is equal to 0.87. For
the 70 female identical twins, it is an impressive 0.96. We can do the same for fraternal
twins of the same gender; see the scatter plots in Figure 2.12 (men on the left, women
on the right). The ﬁgure clearly shows that the correlation is less for fraternal twins.
The sample correlation between the heights of the 29 male fraternal twins is equal to
0.55, while that for the 56 female fraternal twins is 0.50. In the application given after
the exercises in Chapter 3, we will come back in detail to genetic research based on
data on twins.
2.3.1 Autocorrelations
Scatter plots can also be used to verify the common assumption that a sample
x1, . . . , xn is a realization of independent variables. For example, we can plot the
points (x2i−1, x2i) for i = 1, . . . , n/2 or the points (xi, xi+1) for i = 1, . . . , n −1.
If the assumption is correct, then these scatter plots should not show much structure.
The sample autocorrelation coeﬃcient of order h ∈N of an observed sample
x1, . . . , xn is deﬁned by
rx(h) =
n−h
i=1 (xi+h −x)(xi −x)
(n −h)s2x
.
♭Source: The data used in this example were gathered by the department of Biological
Psychology of VU University Amsterdam during a study on health, lifestyle, and personality. The
data can be found on the book's webpage at http://www.aup.nl under twindata.
34

2.3: Correlation
170
180
190
165
170
175
180
185
190
195
155
160
165
170
175
180
155
160
165
170
175
180
Figure 2.11. Scatter plots of the heights of 46 male (on the left) and 70 female (on the right)
identical twins.
170
175
180
185
190
195
170
175
180
185
190
195
160
165
170
175
180
185
155
165
175
185
Figure 2.12. Scatter plots of the heights of 29 male (on the left) and 56 female (on the right)
fraternal twins.
The sample correlation coeﬃcient corresponding to the points (xi, xi+1) for i =
1, . . . , n −1 is (in essence) the sample autocorrelation coeﬃcient of order 1. These
coeﬃcients are especially interesting when the index i of the data point xi corresponds
to a time parameter and the data are thought to exhibit a time dependence. We then
measure the correlation between the variables Xi and Xi−h from h points of time
earlier.
Example 2.17 Share prices
The top image of Figure 4.14 shows the value of a share of Hewlett Packard at the New
York stock exchange plotted against the time, in the period 1984-1991. The values
ai of the share at closing time on consecutive exchange days (i = 1, 2, . . ., 2000) are
plotted; in the graph, these values have been interpolated linearly. Because share prices
35

2: Descriptive Statistics
generally form an exponentially increasing (or decreasing) sequence, it is common to
analyze the "log returns," deﬁned as
xi = log
ai
ai−1
,
instead of the share prices themselves. These values are plotted in the bottom image
of Figure 4.14. Since the index i of xi corresponds to the ith exchange day, it
would not be surprising if x1, . . . , x2000 could not be modeled well as realizations of
independent variables X1, . . . , X2000. After all, a signiﬁcant change on day i would
greatly inﬂuence the change on day i + 1. Regardless, the converse assumption of
independence, the "random walk hypothesis," has long been accepted in econometrics.
A ﬁrst step to verify this hypothesis is computing the sample autocorrelations
of the sequence x1, . . . , x2000. These are shown graphically in the image on the left
in Figure 2.13, where the values h = 0, 1, 2, . . ., 30 have been set out along the
horizontal axis, and the heights of the line segments give the corresponding sample
autocorrelation coeﬃcients of order h (the sample autocorrelation of order 0 is, of
course, equal to 1). Almost all sample autocorrelation coeﬃcients are small, which
justiﬁes the conclusion that the log returns show little linear correlation.
The image on the right gives the sample autocorrelation coeﬃcients of the
squares x2
1, . . . , x2
2000 of the log returns. Although these coeﬃcients are small, the
conclusion that the quadratic log returns show little correlation is debatable: too
many coeﬃcients diﬀer too much from 0. If the squares are not independent, then
the log returns themselves are of course also not independent. It is therefore not a
good assumption that x1, . . . , x2000 can be modeled as realizations of independent
variables: the time eﬀect should be taken into account. Share prices do not form a
random walk.
0
5
10
15
20
25
30
0.0
0.2
0.4
0.6
0.8
1.0
log returns
0
5
10
15
20
25
30
0.0
0.2
0.4
0.6
0.8
1.0
log returns2
Figure 2.13. Sample autocorrelation function of the log returns of HP shares in the period 1984-
1991 (on the left) and of the squares of the log returns (on the right). The dashed lines are at
heights ±1.96/
√
2000 (see Example 4.40).
♯The data can be found on the book's webpage at http://www.aup.nl under hpprices (share
prices) and hplogreturns (log returns).
36

2.3: Correlation
In the above, we wrote that the coeﬃcients in the image on the left in Figure 2.13
are "small," while they "diﬀer from 0" in the image on the right. We can support
these claims objectively using statistical tests such as those discussed in Chapter 4.
The dashed horizontal lines in the two ﬁgures give critical values for the sample
autocorrelations as sample variables for the null hypothesis that x1, . . . , x2000 can
be interpreted as a sample of independent variables (with a margin of error of 5%).
Coeﬃcients that do not land between the lines lead to rejecting the null hypothesis.
We must take into account that when we assume the null hypothesis, about 1 in 20
coeﬃcients will land outside the lines because of "random variations," because of the
5% margin of error (see Chapter 4). In the image on the right, too many values land
outside the lines.
37

2: Descriptive Statistics
2.4 Summary
Quantitative measures for a univariate sample X1, . . . , Xn from an unknown distribu-
tion:
• The sample mean gives an idea of the location of the underlying distribution:
X = 1
n
n

i=1
Xi.
• The sample variance gives an idea of the dispersion of the underlying distribution:
S2
X =
1
n −1
n

i=1
(Xi −X)2.
The sample standard deviation is SX, the square root of S2
X.
• Other commonly used measures are the sample median and the sample interquartile
range.
Graphical methods for a univariate sample X1, . . . , Xn from an unknown distribution:
• A histogram gives an idea of the form of the underlying distribution.
• A boxplot shows the median, the interquartile interval, and the outliers of the
sample. It gives an idea of the location and scale of the underlying distribution,
as well as the symmetry and thickness of the tails.
• A QQ-plot shows the sample quantiles plotted against the quantiles of a chosen
distribution. If the chosen distribution and the underlying distribution are in the
same location-scale family, then the points will lie near a straight line.
Graphical method and quantitative measure for a bivariate sample (X1, Y1), . . . ,
(Xn, Yn) from an unknown distribution:
• A scatter plot gives a graphical representation of the correlation between the
coordinates.
• The sample correlation coeﬃcient is a quantitative measure for the linear correla-
tion between the coordinates:
rX,Y =
n
i=1(Xi −X)(Yi −Y )
(n −1)

S2
X

S2
Y
.
Quantitative measure for a sequence of (possibly dependent) observations X1, . . . , Xn
from an unknown distribution:
• The sample autocorrelation coeﬃcient of order h is used to ﬁnd a possible (time)
dependence among the observations:
rX(h) =
n−h
i=1 (Xi+h −X)(Xi −X)
(n −h)S2
X
.
38

2: Exercises
Exercises
1. Let hn be the scaled histogram of a sample X1, . . . , Xn from a distribution with density f .
The partition of the histogram is given by a0 < a1 < . . . < am. Prove that for aj−1 < x ≤aj,
we have hn(x) →(aj −aj−1)−1  aj
aj−1 f(s) ds with probability 1 as n →∞.
2. Let X be a random variable with distribution function F and quantile function Q. Deﬁne xα
as the α-quantile of F and yα as the α-quantile of the distribution of Y = a + bX.
(i) Suppose that F is strictly increasing and continuous, so that the inverse of F exists
and is equal to Q. Show that there is a linear correlation between xα = F−1(α) and
yα = F−1
a,b(α) by using the inversibility of F.
(ii) Show that the same linear correlation exists between xα and yα for a general distribution
function F. Use the general deﬁnition of the α-quantile.
3. The standard exponential distribution has distribution function x →1 −e−x on [0, ∞).
(i) Does the exponential distribution with parameter λ belong to the location-scale family
associated with the standard exponential distribution?
(ii) Express the parameters a and b in the location-scale family Fa,b associated with the
standard exponential distribution in terms of the expected value and variance of a
random variable with distribution Fa,b.
4. Let X be a random variable with a uniform distribution on [−3, 2].
(i) Determine the distribution function F of X.
(ii) Determine the quantile function F−1 of X.
5. Let X be a random variable with probability density
f(x) = 2
θ2 x1[0,θ](x),
where θ > 0 is a constant.
(i) Determine the distribution function F of X.
(ii) Determine the quantile function F−1 of X.
6. Which line is plotted in Figure 2.5?
7. Let X1, . . . , Xn be a sample from a continuous distribution with distribution function F and
density f. Show that the probability density of the kth order statistic X(k) is equal to
f(k)(x) =
n!
(k −1)!(n −k)! F(x)k−1(1 −F(x))n−k f (x)
by ﬁrst determining the distribution function of X(k). (Hint: We have X(k) ≤x if and only if
at least k observations Xi are less than or equal to x. The number of Xi that are less than or
equal to x is binomially distributed with parameters n and P(Xi ≤x).)
8. Let X1, . . . , Xn be a sample from a continuous distribution with distribution function F. In
this exercise, we want to show that EF(X(k)) = k/(n + 1). Deﬁne Ui = F(Xi) for i = 1, . . . , n.
(i) Show that the random variables U1, . . . , Un form a sample from the uniform
distribution on [0, 1].
(ii) Show that the distribution function F(k) of U(k) is given by
F(k)(x) =
n

j=k

n
j

xj(1 −x)n−j.
39

2: Descriptive Statistics
(iii) Show that the density f(k) of U(k) is given by
f(k)(x) =
n!
(k −1)!(n −k)! xk−1(1 −x)n−k.
(iv) Show that EU(k) = k/(n + 1).
9. Draw a graph of the quantiles of the N(2, 22)-distribution plotted against the quantiles of the
N(0, 32)-distribution. What line is this?
10. Let X be a standard normal random variable. Compute the correlation coeﬃcient between
the random variables X and Y = X2.
11. Explain why it is plausible that the sample correlation rX,Y is approximately equal to the
correlation coeﬃcient ρ for large values of n.
12. Assume that X and Y are independent and that both have the standard normal distribution.
Compute the correlation coeﬃcient between X and Z = X + Y.
40

BENFORD'S LAW
In 1938, the physicist Benford published an academic paper in which he claims that in
a data set, the frequency of the leading digit of the numbers is greater the smaller the
digit. In other words, in a data set, more numbers begin with a 1 than with a 2, more
numbers begin with a 2 than with a 3, and so on. This pattern does not correspond
to the general feeling that all leading digits, from 1 to 9, occur with about the same
frequency. In his paper, Benford even states that the probability of an arbitrary number
from a data set starting with the digit d is equal to log10(1 + 1/d) for d ∈{1, . . ., 9}
(where log10 is the base 10 logarithm). So according to Benford, the probability that
an arbitrary number begins with a 1 is about 0.30, and the probability that it begins
with a 9 has dropped to less than 0.05. Figure 2.14 shows the probabilities. The claim
stated above is known as "Benford's law."
0
2
4
6
8
10
0.0
0.1
0.2
0.3
0.4
0.5
Figure 2.14. The probabilities of the diﬀerent leading digits according to Benford's law.
Benford was not the ﬁrst to discover the regularity mentioned above. More than
ﬁfty years earlier, in 1881, the American astronomer Newcomb published an academic
paper with the same ﬁndings. Newcomb noted that the ﬁrst pages of books with
logarithmic tables were dirtier and showed more wear than the later pages. Since
the books started with the numbers with low leading digits and ended with those with
high leading digits, Newcomb concluded that logarithms of numbers with low leading
digits were consulted more often than those of numbers with high leading digits.
Let us try it out. We compose a data set with the numbers of inhabitants of all
countries in the world† using the CIA World Factbook (February 2006). Figure 2.15
shows a histogram (of area 1) with the leading digits of the numbers of inhabitants,
together with the Benford frequencies. The frequencies of the leading digits seem to
follow "Benford's law" fairly well.
† The data come from http://www.worldatlas.com/aatlas/populations/ctypopls.htm and can be
found on the book's webpage at http://www.aup.nl under populationsize.
41

2: Descriptive Statistics
2
4
6
8
10
0.00
0.05
0.10
0.15
0.20
0.25
0.30
Figure 2.15. Histogram of the leading digits from 1 to 9 in the data set of the population sizes of
all countries in the world. The step function in the ﬁgure gives the expected frequencies based on
Benford's law.
Many data sets have been studied for the validity of Benford's law, from physical
quantities measured in a laboratory to geographical information (like the lengths of
rivers and population sizes of capitals), and from business accounting to currency
conversion factors. In almost all cases, the law holds by approximation. Of course,
not every data set is suitable. Purely random numbers (for example the outcomes of
repeatedly casting a die) or numbers that are subject to restrictions, such as the ages
of the inhabitants of the Netherlands or the phone numbers in a telephone directory,
do not satisfy Benford's law.
Numbers that occur in ﬁnancial statements, for example the accounts of rather
large companies, often approximately satisfy Benford's law. This law can therefore
be used to verify accounts and to investigate fraud and inconsistencies. An employee
who commits fraud and tries to mask this will often fabricate or manipulate numbers
in such a way that the leading digits occur in the same measure. If the employee
manipulates or fabricates numbers regularly, then his actions will change the
distribution of the leading digits, which will then deviate from the one predicted by
Benford's law. If, for example, 9% of the numbers in the accounts begin with a 9, then
the accounts will almost certainly be investigated because, by Benford's law, only
4.6% of the numbers should begin with a 9. However, a deviation from Benford's law
does not automatically mean that there is fraud. In some cases, people prefer numbers
that begin with a 9; for example, a product sells better if the price is 99 euros rather
than 100.
Only structural fraud can be detected using Benford's law. If there is a single
transfer of a large amount to a private account, this will not be noticed if one only
looks at deviations from Benford's law. Figure 2.16 shows a histogram (of area 1) of
the leading digits of 1.5 million numbers in the accounts of a large company, together
with the frequencies one would expect based on Benford's law. The numbers in the
accounts seem to follow Benford's law fairly well.
Despite much research into Benford's law, it is still not completely clear why one
42

2: Benford's Law
2
4
6
8
10
0.00
0.05
0.10
0.15
0.20
0.25
0.30
Figure 2.16. Histogram of the leading digits from 1 to 9 of ﬁgures in the bookkeeping. The
staircase function in the histogram gives the expected frequencies based on Benford's law.
data set satisﬁes it, while another does not. An example where it is satisﬁed, is the
case of exponential growth. Let us study this case more closely. Since we are only
interested in the leading digit of a number, we write a number z as z = x × 10n with
1 ≤x < 10 and n ∈Z. This notation is possible for all positive numbers. We will
call x the normed observation corresponding to z = x × 10n. The leading digit of z
is equal to the leading digit of x. Let D be the random variable that gives the leading
digit of an arbitrary (random) number Z = X × 10n in a data set. Suppose that X
is distributed according to a bY with a, b > 0, and that Y is uniformly distributed on
the interval [0, 1/ log10 b]. Then
P(D = k) = P(k ≤X < k + 1)
= P(k ≤a bY < k + 1)
= P(log10(k/a) ≤Y log10 b < log10((k + 1)/a))
= log10(k + 1) −log10 a −(log10 k −log10 a)
= log10(1 + 1/k),
where the fourth equality follows from the distribution of Y log10 b, the uniform
distribution on the interval [0, 1]. The probability that the leading digit D is equal
to k is therefore exactly the probability according to Benford's law. If b = 10, then
log10 b = 1 and the assumption is that Y is uniformly distributed on [0, 1].
Figure 2.17 shows a QQ-plot of the order statistics of log10 of the normed
population sizes from Figure 2.15 plotted against the quantiles of the uniform
distribution on [0, 1]. For this data set, the assumption apparently holds.
The assumption that X is distributed according to a bY , where a, b > 0 and Y is
uniformly distributed on the interval [0, 1/ log10 b] is not very insightful, and therefore
seems unrealistic. The following example, however, shows that this impression is
misleading. Suppose that a company has a market value of d million euros, which
grows by x% each year. After t years, the market value of the company has increased
to d(1 + x/100)t million euros. After t = 1/ log10(1 + x/100) years, we have
43

2: Descriptive Statistics
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Figure 2.17. QQ-plot of log10 of the normed population sizes plotted against the quantiles of the
uniform distribution on [0, 1]. The line in the ﬁgure is the line y = x.
(1 + x/100)t = 10 and the initial value has increased tenfold. The leading digit
is then equal to the leading digit at time t = 0. Since this time span does not
depend on the initial amount d, the time 0 can be chosen arbitrarily, and we are
only interested in the leading digit, it suﬃces to consider values of t in the interval
[0, 1/ log10(1 + x/100)]. Let T be a random variable that is uniformly distributed on
the interval [0, 1/ log10(1 + x/100)]. For an arbitrary company with market value d,
the value at time T is then equal to Z = d(1+x/100)T = (d/10n)(1+x/100)T10n,
with n ∈N such that (d/10n)(1 + x/100)T ∈[1, 10) with probability 1. We are
now back in the situation of the previous example, with Y = T , b = 1 + x/100, and
a = d/10n. The probability that a company with market value d at time 0 has a market
value beginning with a k at time T is equal to the Benford probability log10(1 + 1/k).
Another argument that leads to the same answer is based on the assumption that
the probability that an arbitrary company has a market value that begins with the digit
k is directly proportional to the time span that the company has a market value that
begins with the digit k. Let tk be the time span (in years) during which the market
value increases from k to k + 1 (million) euros; then k(1 + x)tk = k + 1, that is, tk =
log10(1+1/k)/ log10(1+x/100). The time span necessary to go from leading digit k
(k million euros) to leading digit k + 1 (k + 1 million euros) is therefore proportional
to log10(1+1/k), the probability of having leading digit k according to Benford's law.
This is, of course, independent of the chosen unit "millions of euros." We can again
conclude that under our assumption, a fraction of approximately log10(1+1/k) of all
companies have a market value with leading digit k, exactly as predicted by Benford's
law.
44

3 Estimators
3.1 Introduction
A statistical model consists of all probability distributions that, a priori, seem
possible for the given data. Given a correctly set-up model, we assume that the
data were generated from one of the distributions in the model. After setting up a
suitable statistical model, the next step is determining which distribution within the
model ﬁts the data points best. If the model is described by a parameter, this is
equivalent to determining the best-ﬁtting value of the parameter, often called the "true"
parameter. In statistics, this process is called "estimating." Other names are "ﬁtting"
and "learning."
Suppose that the distribution of X depends on an unknown parameter θ, so that
the statistical model is of the form {Pθ: θ ∈Θ}, for Pθ the distribution of X if θ is
the "true" parameter. Based on an observation x, we want to estimate the true value
of θ, or perhaps the value of a function g(θ) of θ. Here, "estimating" means making
a statement about θ or g(θ) of the form "I think that g(θ) is approximately equal to
T (x)," for some value T (x) that depends on the observed value x.
Deﬁnition 3.1 Estimator
An estimator or statistic is a random vector T (X) that depends only on the
observation X. The corresponding estimate for an observation x is T (x).
45

3: Estimators
By this deﬁnition, many objects are estimators. What matters is that T (X) is a
function of X that does not depend on the parameter θ: we must be able to compute
T (x) from the data x. Given the observed value x, the statistic T is realized as
t = T (x), which is used as an estimate of θ (or g(θ)). We often shorten T (X) to
T . Mathematically, the word "statistic" has exactly the same deﬁnition as "estimator,"
but it is used in a diﬀerent context.
Both estimators and estimates of θ are often indicated by ˆθ. The hat indicates that
ˆθ is a function of the observation, but this notation does not diﬀerentiate between the
random vector and its observed value: ˆθ can mean both ˆθ(X) and ˆθ(x).
There are many estimation methods. In this chapter, we discuss several general
principles, such as the maximum likelihood method, the method of moments, and the
Bayes method. We begin, however, by setting up the framework necessary to compare
the performance of the diﬀerent estimators.
3.2 Mean Square Error
Although every function of the observation is an estimator, not every estimator is a
good one. A good estimator of g(θ) is a function T of the observed data such that T
is "close" to the estimand g(θ). The distance
T −g(θ)
 is an unsatisfactory measure
for two reasons:
- This measure depends on the unknown value θ.
- This measure is stochastic and cannot be computed before carrying out the
experiment.
To avoid the second diﬃculty, we consider the distribution of the distance
T −g(θ)

under the assumption that θ is the true value. The best situation is that where this
distribution is degenerate at 0, that is, if θ is the true value, then
T −g(θ)
 has
probability 1 to be equal to 0. This would mean that we do not make any estimation
errors; the estimate T (x) would be equal to the estimand with absolute certainty.
Unfortunately, this is impossible in practice, and we must settle for the smallest
possible (average) error. We are looking for an estimator whose distribution for the
true value θ is concentrated as much as possible around g(θ) or, equivalently,for which
the distribution of
T −g(θ)
 is concentrated as much as possible in a neighborhood
of 0.
Example 3.2 Uniform distribution
Let X1, . . . , Xn be independent U[0, θ]-distributed random variables. The observa-
tion is the vector X = (X1, . . . , Xn), and we want to estimate the unknown θ. Since
EθXi = 1
2θ, it is reasonable to estimate 1
2θ using the sample mean X and θ using 2X;
after all, by the law of large numbers (Theorem A.26), the sample mean converges (in
probability) to EθXi = 1
2θ. Suppose that n = 10 and that the data have the following
values: 3.03, 2.70, 7.00, 1.59, 5.04, 5.92, 9.82, 1.11, 4.26, 6.96, so that 2x = 9.49.
46

3.2: Mean Square Error
This estimate is certainly too small. Indeed, one of the observations is 9.82, so that we
must have θ ≥9.82.
Can we think of a better estimator? We can avoid the problem we just mentioned
by taking the maximum X(n) of the observations. However, the maximum is certainly
also less than the true value, for all observations xi lie in the interval [0, θ]. An obvious
solution is to add a small correction. We could, for example, take (n+2)/(n+1) X(n)
as estimator.
So there are several candidates. Which estimator is the best? To gain insight into
this question, we carried out the following simulation. We chose n = 50 and simulated
1000 independent samples of size 50 from the uniform distribution on [0, 1]. For each
sample, we computed the estimators 2X and (n + 2)/(n + 1)X(n). Figure 3.1 shows
histograms of two sets with 1000 estimates each for the parameter θ. The image on
the left uses the estimator (n + 2)/(n + 1)X(n), and the one on the right uses 2X.
These histograms can be viewed as approximations of the densities of the
estimators. The density on the left is more concentrated around the true value θ = 1
than the density on the right. We therefore prefer the estimator (n + 2)/(n + 1)X(n):
"on average," it is closer to the true value. (The diﬀerence in the forms of the
histograms is remarkable: the one on the left resembles an (inverse) exponential
density, while the one on the right resembles a normal density. We can easily explain
this theoretically. How?)
0.7
0.8
0.9
1.0
1.1
1.2
1.3
0
10
20
30
40
0.7
0.8
0.9
1.0
1.1
1.2
1.3
0
10
20
30
40
Figure 3.1. Histograms of 1000 realizations of the estimators (n + 2)/(n + 1)X(n) and 2X for the
parameter 1 of a uniform distribution, each based on n = 50 observations.
Note that it is not true that the estimator (n + 2)/(n + 1)X(n) gives the best
estimate on each of the 1000 samples. This can be seen in Figure 3.2, where the
diﬀerence |(n + 2)/(n + 1)x(n) −1| −|2x −1| is set out along the vertical axis.
In general, this diﬀerence is negative, but sometimes it is positive, in which case the
estimator 2X gives a value that is closer to the true value θ = 1. Because in practice
47

3: Estimators
we do not know the true value, it is not possible to choose the "best of both worlds."
We must use the estimator that is the best on average.
0
200
400
600
800
1000
-0.2
-0.1
0.0
Figure 3.2. Diﬀerences |(n + 2)/(n + 1)x(n) −1| −|2x −1| of the absolute distances from the
estimates (n + 2)/(n + 1)x(n) and 2x to the estimand 1 in Figure 3.1.
Our simulation experiment only shows that (n + 2)/(n + 1)X(n) is the better
estimator if the true value of θ is equal to 1. To determine which estimator is better
when θ has a diﬀerent value, we would have to repeat the simulation experiment
with simulated samples from the uniform distribution on [0, θ], for every θ. This
is not something we want to do, of course, and that is one of the reasons to study
estimation problems mathematically. Another reason is that instead of ordering pairs
of estimators, we would like to ﬁnd the overall best estimator.
Since a probability distribution is a complicated object, comparing the "concen-
tration" is not well deﬁned. It is therefore useful to express the concentration as a
number, so that we only need to compare numbers. There are many ways to do this.
One measure of concentration that is relatively simple to deal with mathematically is
the mean square error or mean square deviation.
Deﬁnition 3.3 Mean square error
The mean square error or MSE of an estimator T for the value g(θ) is
MSE(θ; T ) = Eθ
T −g(θ)
2.
The subscript θ in Eθ in the deﬁnition is essential: the MSE is the expected
square deviation of T from g(θ) under the assumption that θ is the true value of the
parameter (this sentence has the same θ twice). We view the mean square error as the
function θ →MSE(θ; T ) for a given statistic T . A more complete notation would be
48

3.2: Mean Square Error
MSE(θ; T, g), but since g is ﬁxed in the context of the problem, we leave g out of the
notation.
The ﬁrst diﬃculty—that the measure of quality depends on θ—has not been
solved yet; the mean square error is a function of θ. In principle, it suﬃces if
MSE(θ; T ) is as small as possible in the "true value" of θ. As we do not know that
value, we try to keep the mean square error (relatively) small for all values of θ at
once.
Convention 3.4
We prefer an estimator with small mean square error (MSE) for all values of the
parameter θ at once.
If for two estimators T1 and T2, we have
Eθ
T1 −g(θ)
2 ≤Eθ
T2 −g(θ)
2
for all θ ∈Θ,
with a strict inequality for at least one value of θ, then we prefer T1. The estimator T2
is then called inadmissible. However, the strict inequality may hold for some θ, while
for other θ, the strict inverse inequality may hold. It is then not directly clear which
estimator we should prefer. Because the true value of θ, say θ0, is unknown, we do not
know which of MSE(θ0; T1) and MSE(θ0; T2) is the smallest.
In Section 6.3, we discuss optimality criteria for estimators and how to ﬁnd
optimal estimators. In this chapter, we discuss several methods to ﬁnd estimators of
which it is intuitively clear that they are reasonable and compare mean square errors.
The mean square error of a real-valued estimator T can be decomposed in two
terms:
MSE(θ; T ) = varθ T +

EθT −g(θ)
2
(verify). Both terms in this decomposition are nonnegative. Hence, the mean square
error can only be small if both terms are small. If the second term is 0, the estimator
is called unbiased.
Deﬁnition 3.5 Unbiased estimator
An estimator T is called unbiased for the estimation of g(θ) if EθT = g(θ) for all
θ ∈Θ. The bias is deﬁned as EθT −g(θ).
The second term in the decomposition of MSE(θ; T ) is therefore the square of the
bias. For an unbiased estimator, this term is identically 0. This seems very desirable,
but is not always so. Namely, the condition that an estimator be unbiased can lead to
the variance being very large, so that we amply loose in the ﬁrst term what we would
have gained in the second one. In general, a small variance leads to a large bias, and
a small bias to a large variance. We must therefore balance the two terms against each
other.
49

3: Estimators
The standard deviation σθ(T )
=
√varθ T of an estimator is also called
the standard error. This should not be confused with the standard deviation of
the observations. In principle, the standard error σθ(T ) depends on the unknown
parameter θ and is therefore itself an unknown. Because the bias of reasonable
estimators is often small, the standard error often gives an idea of the quality of the
estimator. An estimate of the standard error is often given along with the estimate
itself. We will come back to this when we discuss conﬁdence regions in Chapter 5.
We are thus looking for estimators with a small standard error and a small bias.
Example 3.6 Uniform distribution
Let X1, . . . , Xn be independent, U[0, θ]-distributed random variables. The estimator
2X is unbiased because for all θ > 0,
Eθ(2X) = 2
n
n

i=1
EθXi = 2
n
n

i=1
θ
2 = θ.
The mean square error of this estimator is
MSE(θ; 2X) = 4 varθ X = 4
n2
n

i=1
varθ Xi = θ2
3n.
The estimator X(n) is biased because for all θ > 0,
EθX(n) =
 θ
0
xnxn−1 1
θn dx =
n
n + 1θ
(see Exercise A.10 for the distribution of X(n)). Nevertheless, (for n not too small)
we prefer X(n) to 2X, because this estimator has a smaller mean square error:
MSE(θ; X(n)) = varθ X(n) +

EθX(n) −θ
2
= θ2
n
(n + 2)(n + 1)2 + θ2
n
n + 1 −1
2
=
2θ2
(n + 2)(n + 1).
We can cancel out the bias of X(n) by multiplying by a constant: the estimator (n +
1)/n X(n) is unbiased for θ. However, the biased estimator (n + 2)/(n + 1) X(n) is
better than all estimators we have mentioned up to now, because
MSE

θ; n + 2
n + 1X(n)

=
θ2
(n + 1)2 .
Figure 3.3 shows the mean square error of this last estimator, together with the mean
square errors of X(n) and 2X as functions of θ for n = 50. For values of θ close to 0,
the diﬀerences between the mean square errors of 2X and of the other two estimators
are small, but they increase rapidly when θ increases.
50

3.2: Mean Square Error
On closer inspection, it turns out that for values of n that are not too small, the
diﬀerence between the mean square errors of (n + 2)/(n + 1)X(n) and X(n) is small.
The greater precision of (n + 2)/(n + 1)X(n) compared to 2X, however, rapidly
becomes apparent when n increases, because the mean square error of the ﬁrst is
smaller by a factor of n.
We have already noted (see Figure 3.2) that the estimator (n + 2)/(n + 1) X(n)
does not give a better result than the estimator 2X on every sample. The fact that
MSE

1; (n + 2)/(n + 1) X(n)

< MSE(1; 2X) certainly does not exclude this,
because the mean square error is an expected value and can be viewed as the average
over a large number of realizations. An average can be negative without all terms being
negative. On average, (n + 2)/(n + 1) X(n) is (much) better.
0
1
2
3
4
5
6
0.00
0.05
0.10
0.15
0.20
Figure 3.3. The mean square errors as functions of θ for the estimators 2X (solid line), X(n)
(dotted line), and (n + 2)/(n + 1)X(n) (dashed line) for the parameter in U[0, θ], for n = 50.
Example 3.7 Sample mean and sample variance
Let X1, . . . , Xn be independent, identically distributed random variables, with an
unknown marginal distribution. We want to estimate the expected value μ and variance
σ2 of the observations. Formally, we can take θ equal to an unknown distribution, the
so-called "nonparametric model," which does not specify the underlying distribution.
The "parameters" μ and σ2 are functions of this underlying distribution.
The sample mean X and the sample variance S2
X are equal to (see Deﬁnitions
2.1 and 2.2)
X = 1
n
n

i=1
Xi,
S2
X =
1
n −1
n

i=1
(Xi −X)2.
The sample mean is an unbiased estimator for μ since
EθX = 1
n
n

i=1
EθXi = μ.
51

3: Estimators
The mean square error of this estimator is given by
MSE(θ; X) = varθ X = 1
n2
n

i=1
varθ Xi = σ2
n .
The mean square error of X is therefore smaller by a factor of n than the mean square
error of the estimator Xi based on a single observation, MSE(θ, Xi) = varθ Xi = σ2.
Since the mean square error is an estimated square distance, we conclude that the
quality of the estimator X increases by a factor of √n. So for an estimator that is
twice as good, you need four times as many observations.
The sample variance is an unbiased estimator for σ2 because
EθS2
X = Eθ
1
n −1
n

i=1
((Xi −μ) + (μ −X))2
= Eθ
1
n −1
n

i=1

(Xi −μ)2 + (μ −X)2 + 2(μ −X)(Xi −μ)

=
1
n −1
n

i=1
Eθ(Xi −μ)2 −
n
n −1Eθ(X −μ)2 = σ2,
where the last equality follows from Eθ(Xi−μ)2 = varθ Xi = σ2 and Eθ(X −μ)2 =
varθ X = σ2/n. With a bit of work, the mean square error of S2
X can be expressed in
the fourth sample moment of the observations, but we will not discuss this.
Suppose that we are looking for an unbiased estimator for μ2. Since X is an
unbiased estimator for μ, in ﬁrst instance we take X2 as estimator for μ2. However,
this estimator is biased:
Eθ(X)2 = varθ X + (EθX)2 = σ2
n + μ2.
It immediately follows that Eθ(X2 −σ2/n) = μ2, but since σ2 is an unknown
parameter, X2 −σ2/n is not an estimator. If we replace σ2 by its unbiased estimator
S2
X, then we see that X2 −S2
X/n is an unbiased estimator for μ2.
* Example 3.8 Sample theory
Suppose that a proportion p of a population has a certain characteristic A. We will
compare three methods to estimate p, based on a sample with replacement, a sample
without replacement, and a stratiﬁed sample.
In the ﬁrst method, we take a sample of size n from a population, with
replacement, and estimate p using the fraction X/n, where X is the number of persons
with characteristic A in the sample. Then X is bin(n, p)-distributed and has expected
value np and variance np(1 −p). Since Ep(X/n) = p for all p, the estimator X/n is
unbiased. The mean square error is
MSE

p; X
n

= varp
X
n

= p(1 −p)
n
.
52

3.2: Mean Square Error
It follows, among other things, that the estimator is better when p ≈0 or p ≈1, and
the worst when p =
1
2. The mean square error does not depend on the size of the
population. By choosing n suﬃciently large, for example n ≥1000, we can obtain an
estimator with a mean square error of at most (1/4)/1000 = 1/4000, regardless of
whether the population consists of 800 or a trillion persons.
In the second method, we take a sample of size n from a population, without
replacement, and estimate p using the faction Y/n, where Y is the number of persons
with characteristic A in the sample. Then Y is hyp(N, pN, n)-distributed and has
expected value np and variance np(1 −p)(N −n)/(N −1). So the estimator Y/n is
again unbiased; the mean square error is
MSE

p; Y
n

= varp
Y
n

= p(1 −p)
n
N −n
N −1 .
This is smaller than MSE(p; X/n), although the diﬀerence is negligible for n  N.
This is not surprising: it is not useful to study persons that have already been studied
again, but if n  N, the probability of this happening is negligible.
In the third method, we ﬁrst divide the population into a number of subpopu-
lations, called strata. This can be a classiﬁcation by region, gender, age, income,
profession, or some other background variable. Suppose that the entire population
has size N, while the subpopulations have sizes N1, . . . , Nm. We now draw, for
convenience without replacement, (Nj/N)n persons from the jth population, a
stratiﬁed sample, and estimate p using Z/n, where Z is the total number of persons
with property A in our sample. So Z = Z1 + · · · + Zn, where Zj is the number of
persons with characteristic A drawn from the jth population. Now, Z1, . . . , Zm are
independent, bin

(Nj/N)n, pj)-distributed variables, where pj is the proportion of
persons with characteristic A in the jth population. Then
Ep
Z
n

= 1
n
m

j=1
EpZj = 1
n
m

j=1
Nj
N npj = 1
N
m

j=1
Njpj = p,
MSE

p; Z
n

= varp
Z
n

= 1
n2
m

j=1
varp Zj = 1
n2
m

j=1
Njn
N pj(1 −pj)
= p(1 −p)
n
−1
n
m

j=1
Nj
N (pj −p)2.
The estimator Z/n is therefore also unbiased, and its mean square error is less than
or equal to the mean square error of X/n. The diﬀerence is mostly worth considering
when the pj diﬀer greatly. Stratiﬁed sampling is therefore the preferred method in
general, even though in practice, it can mean more work.
Similar results also hold for sampling without replacement, provided that the
sizes of the strata and samples satisfy certain conditions. It is, however, not true that
in this case stratiﬁcation always leads to greater precision.
53

3: Estimators
3.3 Maximum Likelihood Estimators
The "maximum likelihood estimation method" is the most common method to ﬁnd
estimators for an unknown parameter. Before presenting the method in general, we
deduce the maximum likelihood estimator for the (simple) case of the binomial
distribution.
Example 3.9 Binomial distribution
Suppose that we toss a biased coin 10 times. For this coin, the probability p of getting
"head" is not necessarily 1/2. Let X be the number of times we get "head" in the 10
tosses. The random variable X then has a binomial distribution with parameters 10
and the unknown p ∈[0, 1]. Suppose that we get "head" 3 times. The probability of
this outcome is equal to
Pp(X = 3) =
10
3

p3(1 −p)7.
The probability p is unknown and must be estimated. What value for p is the most
probable? Figure 3.4 shows the probability Pp(X = 3) as a function of p. We see
that there is exactly one value of p that maximizes this probability, namely 0.3. This
value for p assigns the greatest possible value to the observation "3 times head." In
this situation, the estimate ˆp = 0.3 turns out to be the maximum likelihood estimate.
0.0
0.2
0.4
0.6
0.8
1.0
0.00
0.05
0.10
0.15
0.20
0.25
Figure 3.4. The probability Pp(X = 3) as a function of p, where the random variable X is
binomially distributed with parameters 10 and p.
The maximum likelihood method requires a likelihood function, which is
deduced from the density of the observation. By a probability density pθ of a random
variable X, we mean the function x →Pθ(X = x) if X is discrete and the function
pθ such that Pθ(X ∈B) =

B pθ(x) dx if X is continuous.
54

3.3: Maximum Likelihood Estimators
Deﬁnition 3.10 Likelihood function
Let X be a random vector with probability density pθ that depends on a parameter
θ ∈Θ. For x ﬁxed, the function
θ →L(θ; x): = pθ(x),
seen as a function of θ ∈Θ (where Θ is the parameter space), is called the likelihood
function.
Often, X = (X1, . . . , Xn) is a vector with independent, identically distributed
coordinates Xi. The density of X in (x1, . . . , xn) is then equal to the product
n
i=1pθ(xi) of the marginal probability densities of X1, . . . , Xn, and the likelihood
function is equal to
θ →L(θ; x1, . . . , xn) =
n

i=1
pθ(xi),
where pθ is now the (marginal) density of one Xi. However, the general deﬁnition of
the likelihood function also holds for an observation vector whose elements are not
independent or identically distributed. We therefore prefer to write the observation as
x, rather than (x1, . . . , xn), and to write the likelihood function as L(θ; x) ≡pθ(x) .
Deﬁnition 3.11 Maximum likelihood estimate and estimator
The maximum likelihood estimate of θ is the value of T (x) ∈Θ that maximizes
the likelihood function θ →L(θ; x). The maximum likelihood estimator is the
corresponding estimator T (X).
In the case of a discrete probability distribution, the maximum likelihood estimate
can be described as the value of the parameter that assigns the greatest probability
to the observed value x. Indeed, in that case, we maximize the probability density
pθ(x) = Pθ(X = x) with respect to θ for ﬁxed x (see Example 3.9). Intuitively, this
is a reasonable principle for taking estimates. It also explains the name. This principle
should, however, be seen only as a way to obtain estimates: maximum likelihood
estimators are not necessarily the best estimators, regardless of their nice name. By a
"best" estimator, we mean an estimator with the smallest possible mean square error.
For a given model, computing the maximum likelihood estimators is a matter
of applying calculus. Often, we diﬀerentiate the likelihood function and set the
derivatives equal to 0. A trick that limits the necessary calculations (especially with
independent observations) is to ﬁrst take the logarithm of the likelihood. Because the
logarithm is a monotone function, the value ˆθ maximizes the function θ →L(θ; x)
if and only if this value maximizes the function θ →log L(θ, x). (Note that we are
speaking only of the value where the maximum is reached, not of the value of the
maximum!) For ﬁxed x, the log-likelihood function is given by
θ →log L(θ; x) = log pθ(x).
55

3: Estimators
If L is diﬀerentiable in θ ∈Θ ⊂Rk and takes on its maximum in an interior
point of Θ, then
∂
∂θj
log L(θ; x)|θ=ˆθ = 0,
j = 1, . . . , k.
This system is called the system of likelihood equations and cannot always be solved
explicitly. If necessary, an iterative method is used to obtain an approximation of the
solution.
Not only maxima, but also minima and inﬂection points are solutions of the
likelihood equations. To verify whether a solution is indeed a maximum, we must
consider the form of the (log-)likelihood function. One way to do this, is to determine
the second derivative (or the Hessian matrix if the parameter has dimension greater
than 1) of the log-likelihood function in the solution. If the function has a maximum
in the solution, the second derivative in that point will be negative. For higher-
dimensional parameters, all eigenvalues of the Hessian matrix must be negative.
If the observation X
= (X1, . . . , Xn) consists of independent, identically
distributed subobservations Xi, then the likelihood L(θ; x) of the observation x is
a product L(θ; x) = 
i pθ(xi), where pθ is the (marginal) density of one Xi. The
log-likelihood is then
θ →log L(θ; x1, . . . , xn) = log
n

i=1
pθ(xi) =
n

i=1
log pθ(xi).
The derivative of log L, the score function, is the sum of the score functions of the
individual observations; see Deﬁnition 5.8. The likelihood equations are then of the
form
n

i=1
∂
∂θj
log pθ(xi) = 0,
j = 1, . . . , k.
Example 3.12 Exponential distribution
Let X = (X1, . . . , Xn) be a sample from the exponential distribution with unknown
parameter λ > 0. Then the log-likelihood function of a realization x1, . . . , xn is equal
to
λ →log L(λ; x1, . . . , xn) = log
n

i=1
λe−λxi = n log λ −λ
n

i=1
xi.
The parameter space for λ is (0, ∞). Setting the derivative of the log-likelihood
function with respect to λ equal to 0 gives
d
dλ log L(λ; x1, . . . , xn)|λ=ˆλ = n
ˆλ
−
n

i=1
xi = 0,
with solution ˆλ = 1/x. The second derivative of the log-likelihood function with
respect to λ is
d2
dλ2 log L(λ; x1, . . . , xn) = −n
λ2 ;
56

3.3: Maximum Likelihood Estimators
it is negative for all λ > 0, so the likelihood function indeed has a maximum in ˆλ. The
maximum likelihood estimator for λ is equal to ˆλ = 1/X.
Example 3.13 Binomial distribution, continued from Example 3.9
The variable X is deﬁned as the number of heads when a coin is tossed 10 times. It
is binomially distributed with parameter 10 and unknown probability p. The observed
value is x = 3. The log-likelihood function is equal to the function
p →log L(p; x = 3) = log
10
3

p3(1 −p)7
= log
10
3

+ 3 log p + 7 log(1 −p).
The maximum likelihood estimate of p is the value in [0, 1] that maximizes this
function with respect to p. This again gives the solution ˆp = 0.3.
In the general case of a binomially distributed quantity X with parameters n and
p, the log-likelihood function is equal to
p →log L(p; x) = log
n
x

+ x log p + (n −x) log(1 −p).
If 0 < x < n, then log L(p; x) →−∞as p ↓0 or p ↑1, so that the log-likelihood
function takes on its maximum in the interval (0, 1). It follows that the likelihood
function L(p; x) also takes on its maximum in the interval (0, 1). Setting the derivative
with respect to p equal to 0 gives one solution, ˆp = x/n. This solution is therefore the
maximum likelihood estimate, ˆp = x/n. Instead of looking at the form, we can also
determine the second derivative of the (log-)likelihood function in p = x/n. If x is
equal to 0 or n, then L(p; x) has a local maximum in 0 or 1. In these cases, too, the
maximum likelihood estimate can be written as ˆp = x/n. The maximum likelihood
estimator is equal to ˆp = X/n.
Example 3.14 Normal distribution
The log-likelihood function for a sample X = (X1, . . . , Xn) from the N(μ, σ2)-
distribution is given by
(μ, σ2) →log
n

i=1
1
√
2πσ2 e−1
2 (xi−μ)2/σ2
= −1
2n log 2π −1
2n log σ2 −
1
2σ2
n

i=1
(xi −μ)2.
57

3: Estimators
We take the natural parameter space for the parameter θ = (μ, σ2), namely Θ =
R × (0, ∞). The partial derivatives of the log-likelihood with respect to μ and σ2 are
∂
∂μ log L(μ, σ2; x1, . . . , xn) = 1
σ2
n

i=1
(xi −μ)
∂
∂σ2 log L(μ, σ2; x1, . . . , xn) = −n
2σ2 +
1
2σ4
n

i=1
(xi −μ)2.
Setting the ﬁrst equation equal to 0 gives one solution: ˆμ = x. In this value for
μ, the log-likelihood indeed has a global maximum for every σ2 > 0, because the
value of the log-likelihood goes to −∞as μ →±∞. Next, we substitute μ = ˆμ
in the second partial derivative, set the latter equal to 0, and solve the likelihood
equation for σ2. This again gives one solution: ˆσ2 = n−1n
i=1(xi −x)2. For the
same reason as before, the log-likelihood function has a maximum in this value. (Note
that maximizing the log-likelihood function in σ instead of σ2 gives the square root
of ˆσ2 as maximum likelihood estimator for σ.) To verify whether the (diﬀerentiable)
log-likelihood function has a maximum in the solution of the likelihood equation that
we found, we can also determine the Hessian matrix of the log-likelihood function in
the point (ˆμ, ˆσ2), which in this case is equal to
1
ˆσ4

−nˆσ2
0
0
−n/2

.
Both eigenvalues of this matrix are negative; consequently, the log-likelihood has a
maximum in the point (ˆμ, ˆσ2).
The resulting maximum likelihood estimator for (μ, σ2) is equal to

X, 1
n
n

i=1
(Xi −X)2
=

X, n −1
n
S2
X

with
S2
X =
1
n −1
n

i=1
(Xi −X)2.
The sample mean is unbiased for μ, but the maximum likelihood estimator ˆσ2 has a
slight bias (see Example 3.7). Because of the small bias, the sample variance S2
X =
(n/(n −1))ˆσ2 is often preferred. However, the mean square error of S2
X is greater
than that of ˆσ2, and both are subordinate to

(n −1)/(n + 1)

S2
X in terms of the
mean square error.‡ Because the diﬀerence is small for large numbers of observations,
it does not matter much which of these estimators is used.
We obtain another model if we assume μ known. The parameter is then θ = σ2,
and the parameter space is (0, ∞). We then ﬁnd that the maximum likelihood estimator
for σ2 is equal to n−1n
i=1(Xi −μ)2. Note that this is only an estimator if μ may be
assumed known!
‡ It takes some calculations to support this statement. Theorem 4.29 can be used to simplify
them. See Exercise 4.27 in Chapter 4.
58

3.3: Maximum Likelihood Estimators
If the maximum of the (log-)likelihood function is not taken in the interior of the
parameter space, then the maximum likelihood estimate ˆθ is usually not a stationary
point of the derivative of the likelihood function, but rather a local maximum, and the
likelihood equations do not hold. In yet other examples, the likelihood function is not
everywhere diﬀerentiable (or even continuous), and the maximum likelihood estimate
also does not satisfy the likelihood equations. Example 3.15 illustrates this situation.
Moreover, it is possible that the likelihood function has several (local) maxima
and minima. The likelihood equations can then have more than one solution. The
maximum likelihood estimate is by deﬁnition the global maximum of the likelihood
function.
Example 3.15 Uniform distribution
Let x = (x1, . . . , xn) be an observed sample from the uniform distribution on the
interval [0, θ], where θ > 0 is unknown. We want to estimate the parameter θ using the
maximum likelihood estimator. Since the observations x1, . . . , xn lie in the interval
[0, θ], we must have θ ≥xi for i = 1, . . . , n. It immediately follows that θ ≥x(n),
where x(n) is the largest observed order statistic.
The likelihood function of the observations x1, . . . , xn is equal to the joint
density of X1, . . . , Xn in x1, . . . , xn, viewed as a function of θ. Because X1, . . . , Xn
are independent and identically distributed, the joint density is equal to the product of
the marginal densities, which is equal to 1/θ on the interval [0, θ] and 0 elsewhere.
The likelihood function is therefore equal to
θ →L(θ; x1, . . . , xn) =
n

i=1
1
θ 10≤xi≤θ =
1
θ
n
1x(1)≥01x(n)≤θ.
This function of θ is equal to 0 for θ < x(n) because the indicator function 1x(n)≤θ
is then equal to 0. In θ = x(n), the function jumps to 1/θn. In θ = x(n), the
likelihood, and therefore also the log-likelihood, is not diﬀerentiable with respect to θ.
A maximum can be found by plotting the likelihood function as a function of θ. For
θ ≥x(n), the likelihood function is equal to the decreasing function θ →1/θn.
Figure 3.5 illustrates the course of the likelihood function (as a function of θ). In x(n),
the likelihood function is upper semi-continuous and also maximal; the maximum
likelihood estimate of θ is therefore equal to x(n) and the corresponding maximum
likelihood estimator is X(n).
Example 3.16 Normal distribution with restriction
Suppose that the observations X1, . . . , Xn are independent and normally distributed
with expected value μ and variance 1, where we know μ ≥0. For a realization
x1, . . . , xn of X1, . . . , Xn, on R the likelihood function takes on an absolute
maximum in x. Now, x can be negative, and μ ≥0, hence x is not the maximum
likelihood estimate. If x ≤0, then on the parameter space [0, ∞), the likelihood
function takes on a local maximum in 0. The maximum likelihood estimate is x if it
is nonnegative and 0 otherwise. The corresponding maximum likelihood estimator is
max(0, X).
59

3: Estimators
0
2
4
6
8
10
0e+00
1e−06
2e−06
3e−06
4e−06
Figure 3.5. Realization of the likelihood function of a sample of size 8 from the uniform
distribution on [0, 5]. The maximum likelihood estimate x(n) (the location of the spike) is 4.73.
The statistical model and the maximum likelihood estimator are determined by
both the form of the density of the observation and the deﬁnition of the parameter
space!
If g: Θ →H is a 1 −1 (bijective) function with a set H as codomain, we can
also parameterize the model using the parameter η = g(θ) ∈H instead of θ ∈Θ. It
immediately follows from the deﬁnition that g(ˆθ) is the maximum likelihood estimator
for η if ˆθ is the maximum likelihood estimator for θ. Accordingly, for an arbitrary
function g, we deﬁne the maximum likelihood estimator for g(θ) simply as g(ˆθ). (This
estimator maximizes the proﬁle likelihood function Lg(τ; x) = supθ∈Θ:g(θ)=τ pθ(x);
see Deﬁnition 5.24.)
In Deﬁnition 3.11, the maximum likelihood estimator is based on the maximum
likelihood estimate. In practice, the (log-)likelihood function is often written directly
in terms of the random variable X instead of the realization x, and the estimator
is deduced directly by maximizing this function with respect to θ. This shortened
notation is used in the following examples of applications of the maximum likelihood
method. Examples in which the method is applied to regression models can be found
in Chapter 7.
Example 3.17 Exponential distribution, continued from Example 3.12
Let X = (X1, . . . , Xn) be a sample from the exponential distribution with unknown
parameter λ > 0. In Example 3.12, we showed that the maximum likelihood estimator
for λ is equal to ˆλ = 1/X. From this, we can easily deduce the maximum likelihood
estimator for EθXi = 1/λ, namely 
EθXi = 1/ˆλ = X.
60

3.3: Maximum Likelihood Estimators
Example 3.18 Gamma distribution
Let X = (X1, . . . , Xn) be a sample from a gamma distribution with probability
density
pα,λ(x) = xα−1λαe−λx
Γ(α)
.
Here α > 0 and λ > 0 are the unknown shape and inverse scale parameters, and Γ is
the gamma function
Γ(α) =
 ∞
0
sα−1e−sds.
The log-likelihood function for X1, . . . , Xn is then equal to
(α, λ) →log
n

i=1
Xα−1
i
λαe−λXi
Γ(α)
= (α −1)
n

i=1
log Xi + nα log λ −λ
n

i=1
Xi −n log Γ(α).
As parameter space for θ = (α, λ), we take Θ = [0, ∞) × [0, ∞). To determine the
maximum likelihood estimators for α and λ, we determine the partial derivatives of
the log-likelihood function with respect to λ and α
∂
∂λ log L(α, λ; X1, . . . , Xn) = nα
λ −
n

i=1
Xi,
∂
∂α log L(α, λ; X1, . . . , Xn) =
n

i=1
log Xi + n log λ −n
 ∞
0
sα−1 log s e−sds
 ∞
0
sα−1e−sds
.
(In the derivative with respect to α, we have diﬀerentiated the gamma function
α →Γ(α) under the integral sign and used that (∂/∂α)sα = sα log s.) The partial
derivatives are equal to 0 in the maximum likelihood estimators (ˆα, ˆλ); this gives two
likelihood equations. It immediately follows from the ﬁrst equation that ˆλ = ˆα/X.
We substitute this into the second likelihood equation. This gives
n

i=1
log Xi + n log ˆα −n log X −n
 ∞
0
sˆα−1 log s e−sds
 ∞
0
sˆα−1e−sds
= 0.
This equation does not have an explicit solution for ˆα, but can be solved numerically,
using an iterative method, when a realization of X1, . . . , Xn has been observed. For
most numeric algorithms, we need initial values as starting point for the search for
a solution of the equation. The method of moments estimates can be used as initial
values (see Section 3.4).
We substitute the resulting value ˆα in the equation ˆλ = ˆα/X to determine ˆλ.
To verify whether the log-likelihood function takes on a maximum in the solution,
we must compute the eigenvalues of the Hessian matrix in (ˆα, ˆλ). If both eigenvalues
are negative in (ˆα, ˆλ), then (ˆα, ˆλ) is the maximum likelihood estimator for (α, λ).
61

3: Estimators
Example 3.19 Application: counting bacteria
Bacteria in contaminated water are impossible to count either by the naked eye or
using a microscope. To obtain an idea of the degree of contamination, we estimate
the number of colony-forming units of bacteria in a centiliter of water. We proceed as
follows. We assume that the number of colony-forming units of bacteria in a centiliter
of contaminated water is Poisson-distributed with parameter μ. To obtain an indication
of the number of colony-forming units of bacteria in the water, we want to estimate μ.
We pour the contaminated water in a bucket with 100 liters of pure water, mix well,
and divide the water over 100 Petri dishes with each a volume of 1 liter. We then check
each dish to see whether a colony forms. If this is the case, then there was at least one
colony-forming unit of bacteria in the centiliter; if it is not the case, then this centiliter
was free of bacteria. Let X be the total number of colony-forming units of bacteria in
the centiliter of contaminated water; then we can write X as X = 100
i=1 Xi, where Xi
is the number of colony-forming units of bacteria in the ith Petri dish. The variables
X1, . . . , X100 are independent and Poisson-distributed with parameter μ/100.
However, we cannot observe X1, . . . , X100. Rather, we observe Y1, . . . , Y100,
where Yi is deﬁned by
Yi =
 0
if no colony forms in the ith dish
1
otherwise.
The observations Yi are independent and have a Bernoulli distribution with
P(Yi = 0) = P(Xi = 0) = e−μ/100
and
P(Yi = 1) = 1 −e−μ/100.
Deﬁne p: = P(Yi = 1) = 1 −e−μ/100. The maximum likelihood estimator for the
parameter p of the Bernoulli distribution can be deduced simply by drawing up the
likelihood equations and solving them for p. Based on the sample Y1, . . . , Y100, this
estimator is equal to ˆp = 100
i=1 Yi/100. Since p = 1 −e−μ/100, the parameter μ is
equal to −100 log(1 −p), and the maximum likelihood estimator for μ is given by
ˆμ = −100 log(1 −100
i=1 Yi/100).
Example 3.20 Application: Poisson stocks
In Example 1.4, a statistical model is described for the total number of specimens of a
certain item sold per week and per retailer. We observe X = (X1,1, X1,2, . . . , XI,J),
where Xi,j is the number of specimens sold by retailer i in week j. Suppose that
X1,1, . . . , XI,J are independent and that Xi,j has a Poisson distribution with unknown
parameter μi. The parameter μi depends only on the retailer and not on the week. We
estimate the parameters μ1, . . . , μI using the maximum likelihood method.
The log-likelihood function for X1,1, . . . , XI,J is equal to
(μ1, . . . , μI) →
I

i=1
J

j=1
log

e−μi μXi,j
i
Xi,j!

= −
I

i=1
Jμi +
I

i=1
J

j=1
Xi,j log μi −
I

i=1
J

j=1
log(Xi,j!).
62

3.3: Maximum Likelihood Estimators
We take the natural parameter space (0, ∞)I for (μ1, . . . , μI). Solving the likelihood
equations gives ˆμk = J−1 J
j=1 Xk,j, provided J
j=1 Xk,j > 0. It is easy to check
that the Hessian matrix in an arbitrary point (μ1, . . . , μI) is a diagonal matrix with
only negative eigenvalues when J
j=1 Xk,j > 0 for all k. If J
j=1 Xk,j = 0 (which
has a positive probability of happening), there in fact does not exist a maximum
likelihood estimator for μk, because in that case, the likelihood function is strictly
decreasing and therefore does not reach a maximum on (0, ∞). If we deﬁne the
Poisson distribution with parameter 0 as the probability distribution that is degenerate
in the point 0 and extend the parameter space for μk to [0, ∞) for every k, then
J−1 J
j=1 Xk,j is the maximum likelihood estimator for μk.
If the number of items sold changes linearly over the weeks, we may assume
μi,j = μi(1 + βj). We assume that the change β is the same for all retailers. In that
case, the log-likelihood function for X1,1, . . . , XI,J is equal to
(μ1, . . . , μI, β) →
I

i=1
J

j=1

−μi(1 + βj) + Xi,j log(μi(1 + βj)) −log(Xi,j!)

.
The likelihood equations for μk and β are equal to
J

j=1

−(1 + ˆβj) + Xk,j
ˆμk

= 0
for k = 1, . . . , I
I

i=1
J

j=1

−ˆμij + jXi,j
1 + ˆβj

= 0.
There are no explicit solutions for these equations, but the zeros of the derivatives can
be found using an iterative algorithm.
* Example 3.21 Autoregression
The maximum likelihood method is not restricted to independent observations. We
illustrate this with a model that is often used to analyze a variable that changes over
time, the autoregressive model:
Xi = βXi−1 + ei.
Here β is an unknown parameter, and the variables e1, . . . , en are unobservable
random ﬂuctuations, also called "noise" or "innovations" in this context. This model
greatly resembles the linear regression model without intercept, except that the
observation Xi is "explained" by regression on the observation Xi−1. If we view
the index i ∈{1, . . . , n} as indicating successive moments in time, then regression
takes place from Xi to the past Xi−1 of the sequence itself, thus explaining the term
"autoregression." Here, we consider the autoregression model of order 1; the extension
to regression on more than one variable in the past is obvious.
63

3: Estimators
The order of the data points is now of great importance, and it is useful to
depict the data as a function of time. Figure 3.6 gives three possible realizations
(x0, x1, . . . , xn) of the vector (X0, X1, . . . , Xn) as a plot of the index i along the
horizontal axis against the value xi along the vertical axis. All three realizations begin
with x0 = 1, but after that, they are generated according to the model Xi = βXi−1+ei
with independent innovations ei but the same value of β. The statistical problem is to
estimate the value of β based on the observed realization (x0, x1, . . . , xn). We will
solve this using the maximum likelihood method.
0
10
20
30
40
50
-4
-2
0
2
4
Figure 3.6. Three realizations of the vector (X0, X1, . . . , X50) distributed according to the
autoregressive model with standard normal innovations, x0 = 1 and β = 0.7. Each of the three
graphs is a linear interpolation of the points {(i, xi): i = 0, . . . , 50}.
We complete the description of the model by assuming that X0 is distributed
according to the probability density pX0 and that the innovations e1, . . . , en are
independent, normally N(0, σ2)-distributed quantities that are independent of X0.
The likelihood function is the joint probability density of the observation vector
X = (X0, . . . , Xn). Because the observations X0, X1, . . . , Xn are stochastically
dependent, the joint density is not the product of the marginal densities. However,
we can use the general decomposition for a joint density:
pX0,. . . ,Xn(x0, . . . , xn) = pX0(x0)pX1|X0(x1| x0)pX2|X0,X1(x2| x0, x1)×
· · · × pXn|X0,. . . ,Xn−1(xn| x0, . . . , xn−1).
This formula gives a factorization of the joint density as the product of conditional
densities and generalizes the product formula for the case of independent observa-
tions. The formula can be proved by repeatedly applying the formula f X,Y (x, y) =
f X(x)f Y |X(y| x). In the autoregressive model, the conditional density of Xi given
X0 = x0, . . . , Xi−1 = xi−1 is equal to the density of βxi−1 + ei, that is, the density
of the normal distribution with expectation βxi−1 and variance var ei = σ2. The
64

3.3: Maximum Likelihood Estimators
likelihood function is therefore of the form
(β, σ) →L(β, σ; X0, . . . , Xn) = pX0(X0)
n

i=1
1
σ φ
Xi −βXi−1
σ

.
We have not yet speciﬁed the density of X0. Because this density inﬂuences only one
of the n + 1 factors and n is usually large, the factor in question, pX0(X0), is left out
of the likelihood function, and the analysis is carried out "conditionally on the value
of X0."
With this deﬁnition of the likelihood function, the (conditional) maximum
likelihood estimator for the parameter (β, σ) can be determined using the same
calculation as that used for the linear regression model (see Section 7.2.1). The
maximum likelihood estimator ˆβ minimizes the sum of squares β →n
i=1(Xi −
βXi−1)2 and is equal to
ˆβ =
n
i=1XiXi−1
n
i=1X2
i−1
.
The maximum likelihood estimator for σ2 is
ˆσ2 = 1
n
n

i=1
(Xi −ˆβXi−1)2.
Depending on the modeling of the initial observation X0, the maximum likelihood
estimators based on the unconditional likelihood function take on slightly diﬀerent
forms.
* Example 3.22 Application: compound Poisson process
A health insurance company refunds the incurred medical expenses to its clients and
health care providers. At the beginning of the month, the company would like to have
an estimate for how much money it needs to reserve for that month in order to be able
to pay all approved claims. For this, a data set is drawn up containing all payments
made in the past 120 months.
The number of approved claims varies from month to month and depends on
the number of clients the health insurance company has in said month. We deﬁne Ni
to be the number of approved claims in month i and assume that N1, . . . , N120 are
independent random quantities with
Ni ∼Poisson(μMi),
i = 1, . . . , 120,
where μ > 0 is an unknown parameter and Mi is the number of clients the company
has at the beginning of month i. The numbers Mi are assumed known and not random.
We denote the size of the jth claim in month i by Ci,j. The payout in month i is
then equal to Ni
j=1 Ci,j. We assume that the sizes of the paid claims are independent
random variables with
Ci,j ∼exp(θ),
i = 1, . . . , 120, j = 1, . . . , Ni,
65

3: Estimators
where θ > 0 is an unknown parameter. We moreover assume that the sizes of the
claims Ci,j are independent of the number of claims Ni.
Under the assumptions on the model made above, it is possible to determine the
expected payout for next month. If it were known that the number of claims for next
month is n, then the expected payout would equal
Eθ
n

j=1
Cj = n
θ ,
where C1, . . . , Cn are the sizes of the claims approved next month. The total number
of claims is, however, unknown, and has a Poisson(μM)-distribution with M the
number of clients next month. The expected payout then becomes
Eμ,θ
 N

j=1
Cj

= Eμ

Eθ
 N

j=1
Cj|N

= Eμ
N
θ

= μM
θ .
In this expression, we ﬁrst compute the expectation of N
j=1 Cj for a given N, which
gives N/θ, and then take the expectation of N/θ. When θ and μ are known, the
expected payout next month is therefore equal to μM/θ.
The parameters μ > 0 and θ > 0 are unknown and must be estimated using
the entries in the data set. We use the maximum likelihood method. To deduce the
likelihood function, we ﬁrst determine the joint density of (C1, . . . , CN, N), the
observations for one month. We denote this density by fθ,μ,
fθ,μ(c1, . . . , cN, N = n) = fθ,μ(c1, . . . , cn|N = n)Pμ(N = n)
=
 n

j=1
θe−θcj
e−μM (μM)n
n!
.
We assume that the observations of diﬀerent months and years are independent. The
log-likelihood function for all observations in the data set of the past 10 years is then
equal to the logarithm of the product of the joint probability densities of the diﬀerent
months:
(μ, θ) →log
120

i=1
 Ni

j=1
θe−θCi,j
e−μMi (μMi)Ni
Ni!

=
120

i=1
log
 Ni

j=1
θe−θCi,j
+
120

i=1
log

e−μMi (μMi)Ni
Ni!

.
The ﬁrst term does not depend on the parameter μ, and the second term does not
contain the parameter θ. To determine the maximum likelihood estimators of θ and μ,
it therefore suﬃces to maximize the ﬁrst term with respect to θ and the second term
with respect to μ. This gives
ˆθ =
120
i=1 Ni
120
i=1
Ni
j=1 Ci,j
and
ˆμ =
120
i=1 Ni
120
i=1 Mi
.
66

3.3: Maximum Likelihood Estimators
The maximum likelihood estimator for the payout is equal to
M ˆμ
ˆθ
= M
120
i=1
Ni
j=1 Ci,j
120
i=1 Mi
.
In this example, we assume that the parameters μ and θ are the same every month
and every year. These assumptions are contestable. Indeed, on average the payout will
increase because of inﬂation, and the number of claims will be greater during the
winter than in the summer months. It is worth considering making the parameters
dependent on the year and month. Instead of one parameter μ, we could take twelve
parameters μ1, . . . , μ12 for the diﬀerent months. However, increasing the number of
unknown parameters in the model decreases the precision of the estimates.
* 3.3.1 Fisher's Scoring
Even though the previous examples of applying the maximum likelihood method
might give another impression, it is often not possible to give an explicit formula
in the data for the maximum likelihood estimator (see Example 3.18). In such a case,
we need to apply a numerical approximation method. For a given observation x, the
likelihood function θ →L(θ; x) is a "normal" function of the parameter θ, and we are
looking for the value of θ where this function is maximal. We can use, for example,
the Newton-Raphson method or the variation of this method known in statistics as
Fisher's scoring. This section contains a short description of these numerical methods.
In most cases, the desired value ˆθ is a stationary point of the derivative of the
log-likelihood function with respect to θ. We therefore discuss ﬁnding a zero ˆθ of the
function θ →˙Λ(θ; x), where ˙Λ is the vector of partial derivatives of the log-likelihood
function θ →Λ(θ; x) = log L(θ; x). The idea behind the Newton-Raphson method
is to start out with a reasonable "ﬁrst estimate" ˜θ0 for ˆθ and replace the function ˙Λ by
the linear approximation
˙Λ(θ; x) ≈˙Λ(˜θ0; x) + ¨Λ(˜θ0; x)(θ −˜θ0).
Here, ¨Λ(θ; x) is the matrix of the second derivatives of the log-likelihood function
with respect to the parameter. Instead of looking for the value of θ where the equation
˙Λ(θ; x) equals 0, we now turn to solving the equation ˙Λ(˜θ0; x)+ ¨Λ(˜θ0; x)(θ−˜θ0) = 0.
The zero of this second equation is equal to
(3.1)
˜θ1 = ˜θ0 −¨Λ(˜θ0; x)−1 ˙Λ(˜θ0; x).
Since the linear approximation is not exact, the value ˜θ1 will in general not be the
desired zero ˆθ. However, we do expect the value ˜θ1 to be a better approximation for ˆθ
than the initial value ˜θ0. We then take ˜θ1 as initial value and compute a third value, etc.
This gives a sequence of approximations ˜θ0, ˜θ1, ˜θ2, . . . that, under certain conditions,
converges to a zero ˆθ. The convergence is assured if the initial value ˜θ0 lies suﬃciently
close to the target value ˆθ and the function ˙Λ is suﬃciently smooth, but in practice
67

3: Estimators
we, of course, do not have this guarantee. Diﬀerent modiﬁcations of the algorithm
can make the convergence more reliable. However, if the log-likelihood function has
several local maxima and/or minima, then a word of caution is necessary, because the
convergence can also take place toward another zero of ˙Λ (corresponding to a local
maximum of minimum), in addition to the possibility that the sequence ˜θ0, ˜θ1, ˜θ2, . . .
diverge.
In Section 6.3, we will see that the second derivative ¨Λ(ˆθ; x) of the log-likelihood
function evaluated in the maximum likelihood estimator has a special signiﬁcance.
This second derivative is called the observed information, and is approximately equal
to the Fisher information (see Lemma 5.10). Instead of the second derivative, another
matrix is sometimes used in the Newton-Raphson algorithm (3.1). If the Fisher
information is used, the algorithm is known as Fisher's scoring. This is especially
interesting when the Fisher information can be computed analytically.
* 3.3.2 The EM Algorithm
Like Fisher's scoring algorithm, the expectation-maximization algorithm, or EM
algorithm, is also a frequently used general algorithm to determine maximum
likelihood estimators. The algorithm is meant to be used when the target data is only
partially observed. In many practical applications, such a missing data model appears
naturally, but the algorithm can also be applied by viewing the observations as part of
an imaginary "complete observation" (see Example 3.24).
As usual, we denote the observation by X, but we assume that we observe "only"
X instead of the "complete data" (X, Y ), which could, theoretically, also be available.
If (x, y) →pθ(x, y) is a probability density of the vector (X, Y ), then we obtain the
density of X through marginalization:
pθ(x) =

pθ(x, y) dy.
(In the case of discretely distributed observations, we take a sum instead of an
integral.) The maximum likelihood estimator for θ based on the observation X
maximizes the likelihood function θ →pθ(X). If the integral in the displayed
equation can be evaluated explicitly, then computing the maximum likelihood
estimator is a standard problem, which can be solved, for example, analytically or
using an iterative algorithm. If the integral cannot be evaluated analytically, then
computing the likelihood requires a numerical approximation of the integral in every
value θ, and ﬁnding the maximum likelihood estimator may require many such
approximations. The EM algorithm tries to circumvent these approximations.
If we had the "complete data" (X, Y ) at our disposal, we would have determined
the maximum likelihood estimator using (X, Y ). This estimator, which will in general
be better than the maximum likelihood estimator based on only X, is the point giving
the maximum of the log-likelihood function θ →log pθ(X, Y ), which is probably
easy to evaluate. A natural procedure when Y is not available, is to replace this log-
likelihood function with its conditional expectation
(3.2)
θ →Eθ0

log pθ(X, Y )| X

.
68

3.3: Maximum Likelihood Estimators
This is the conditional expectation of the log-likelihood for the complete data given
the observation X. The idea is to replace the usual log-likelihood with the function
(3.2) and determine the point giving the maximum of the latter.
Unfortunately, the expected value in (3.2) will usually depend on the true
parameter θ0, which is why we have included it as a subscript of the expectation
operator Eθ0. Since the true value of θ is unknown, the function in the displayed
equation cannot be used as the basis for an estimation method. The EM algorithm
solves this problem by using iteration. Given a suitably chosen ﬁrst guess ˜θ0 for the
true value of θ, we determine an estimator ˜θ1 by maximizing the criterion function in
(3.2). We then replace ˜θ0 in E˜θ0 by ˜θ1, maximize the new criterion, etc.
Initialize ˜θ0.
E-step: given ˜θi, determine the function
θ →E˜θi

log pθ(X, Y )| X = x

.
M-step: define ˜θi+1 as the point where this function
takes on its maximum.
The EM algorithm gives a sequence of values ˜θ0, ˜θ1, . . ., and we hope that for
increasing i, the value ˜θi is an increasingly good approximation of the unknown
maximum likelihood estimator.
This description gives the impression that the result of the EM algorithm is a new
type of estimator. This is not true, because if the sequence ˜θ0, ˜θ1, . . . generated by the
EM algorithm converges to a limit, then this limit is exactly the maximum likelihood
estimator based on the observation X. Indeed, under certain regularity conditions, we
have, for every i,
(3.3)
p˜θi+1(X) ≥p˜θi(X)
(see Lemma 3.23). Thus, the iterates of the EM algorithm give a constantly increasing
value for the likelihood function of the observation X. If the algorithm works
"as desired," the values p˜θi(X) will end up increasing up to the maximum of the
likelihood, and ˜θi will converge to the maximum likelihood estimator. Unfortunately,
there is, in general, no guarantee for such a convergence,and it needs to be studied case
by case. The sequence ˜θi can, for example, converge to a local maximum. Moreover,
carrying out the two steps of the algorithm is not necessarily easy.
Lemma 3.23
The sequence ˜θ0, ˜θ1, ˜θ2, . . . generated by the EM algorithm gives an increasing
sequence of likelihood values p˜θ0(X), p˜θ1(X), p˜θ2(X), . . ..
Proof. The density pθ of (X, Y ) can be factored as
pθ(x, y) = pY |X
θ
(y| x)pθ(x).
69

3: Estimators
The logarithm changes this product into a sum, and so we have
E˜θi

log pθ(X, Y )| X

= E˜θi

log pY |X
θ
(Y | X)| X

+ log pθ(X).
As the value ˜θi+1 maximizes this function with respect to θ, this expression is greater
in θ = ˜θi+1 than in θ = ˜θi,
E˜θi

log p˜θi+1(X, Y )| X

≥E˜θi

log p˜θi(X, Y )| X

.
If we can show that E˜θi

log pY |X
θ
(Y | X)| X

is smaller in θ = ˜θi+1 than in θ = ˜θi,
then the converse must hold for log pθ(X) (and the diﬀerence must be compensated
by this second term), from which follows that (3.3) holds. It therefore suﬃces to show
that
E˜θi

log pY |X
˜θi+1(Y | X)| X

≤E˜θi

log pY |X
˜θi
(Y | X)| X

.
This inequality is of the form

log(q/p) dP ≤0 for p and q the conditional densities
of Y given X for the parameters ˜θi and ˜θi+1, respectively, and P the probability
measure corresponding to the density p. Since log x ≤x −1 for every x ≥0, every
pair of probability densities p and q satisﬁes

log(q/p) dP ≤

(q/p −1) dP =

p(x)>0
q(x) dx −1 ≤0.
This implies the previous displayed equation, completing the proof.
Example 3.24 Mixture distribution
Suppose that a number of objects or individuals can, in principle, be grouped in
more or less uniform clusters. Unfortunately, we cannot observe the cluster labels,
but instead of that, we measure a vector xi for each object. We want to determine the
clustering of the objects based on the observations x1, . . . , xn.
We could assume that each observation xi is the realization of a random vector
Xi, with probability density fj if the object belongs to the jth cluster. We can view
the qualiﬁcation of "more or less uniform" in the previous paragraph to mean that the
probability densities f1, . . . , fk for the diﬀerent clusters show little overlap. We will
assume that the number k of clusters is known, even though we could also determine
this from the data.
One way to determine the clusters is to maximize the likelihood
k

j=1

i∈Ij
fj(Xi)
over all partitions (I1, . . . , Ik) of {1, . . . , n} in k subsets and over all unknown
parameters in the densities fj. The partition then gives the clustering. For example,
taking the normal density with expectation vector μj for fj leads to k-means
clustering: the best classiﬁcation is given by the partition that minimizes
min
(μ1,. . . ,μk)∈Rk
k

j=1

i∈Ij
Xi −μj2.
70

3.3: Maximum Likelihood Estimators
Computationally, this is not a simple problem, but the clusters can be approximated
using an iterative algorithm.
Another way is to assume that every object has been assigned to a cluster
randomly (by "nature"). We can then speak of a random vector (C1, . . . , Cn) that
gives the clusters labels (Ci = j if the ith object belongs to the cluster j), and view
the density fj as the conditional probability density of Xi given Ci = j. The class
vector (C1, . . . , Cn) is not observed. If we assume that (C1, X1), . . . , (Cn, Xn) are
independent, identically distributed vectors with P(Ci = j) = pj for j = 1, . . . , k
for all i, then we can determine the maximum likelihood estimator for the parameters
p = (p1, . . . , pk) and the unknown parameters in f = (f1, . . . , fk) using the EM
algorithm.
The complete data consist of (C1, X1), . . . , (Cn, Xn). The corresponding likeli-
hood function can be written as
(p, f) →
n

i=1
k

j=1
pjfj(Xi)1{Ci=j} =
n

i=1
k

j=1

pjfj(Xi)
1{Ci=j}.
The E-step of the EM algorithm is therefore the computation of
E˜p, ˜
f

log
n

i=1
k

j=1

pjfj(Xi)
1{Ci=j}| X1, . . . , Xn

=
n

i=1
k

j=1
E˜p, ˜f

log pj + log fj(Xi)

1{Ci = j}| Xi

.
Using Bayes's rule, we ﬁnd the conditional probability density of Ci given Xi to be
P(Ci = j| Xi = x) = pjfj(x)/ 
c pcfc(x). The last displayed equation is therefore
equal to
k

j=1
n

i=1
log pj
˜pj ˜fj(Xi)

c ˜pc ˜fc(Xi)
+
k

j=1
n

i=1
log fj(Xi)
˜pj ˜fj(Xi)

c ˜pc ˜fc(Xi)
.
In the M-step of the EM algorithm, we maximize this expression with respect to p
and f. For the maximization with respect to p, only the ﬁrst term matters. Arguments
using calculus show that the maximum is reached for
pj = 1
n
n

i=1
˜pj ˜fj(Xi)

c ˜pc ˜fc(Xi)
.
(Compare this with the calculation in Exercise 3.15.) For the maximization over f,
only the second term matters. Moreover, we maximize each of the j terms individually
with respect to fj if the parameters f1, . . . , fk vary independently from one another:
in that case, fj maximizes
fj →
n

i=1
log fj(Xi)
˜pj ˜fj(Xi)

c ˜pc ˜fc(Xi)
.
71

3: Estimators
If, for example, we choose the normal density with expectation vector μj for fj, so
that log fj(x) is equal to −1
2x −μj2 up to a constant, and maximize with respect
to μj, we ﬁnd
μj =
n
i=1αijXi
n
i=1αij
,
αij =
˜pj ˜fj(Xi)

c ˜pc ˜fc(Xi)
.
This is a weighted average of the observations Xi, where the weights are equal to the
conditional probabilities αij = P˜p, ˜f(Ci = j|Xi) that the ith object belongs to the
jth cluster, for 1 ≤i ≤n, computed using the current approximation (˜p, ˜f) of the
parameters. We now repeatedly iterate these updating formulas until the result hardly
changes.
From the maximum likelihood estimates of the parameters, we also deduce a
maximum likelihood estimate of the probability Pp,f(Ci = j| Xi) that the ith object
belongs to the cluster j. We could assign the object to the cluster where this probability
is the greatest.
3.4 Method of Moments Estimators
The method of moments is an alternative to the maximum likelihood method.
Because the method of moments often does not use all the available information
from the statistical model, method of moments estimators are often less eﬃcient than
maximum likelihood estimators. On the other hand, the method is sometimes easier to
implement. Moreover, the method only requires the theoretical form of the moments
and not the complete probability distribution of the observations. Since these moments
are often easier to model realistically than the full probability distribution, this can be
a great advantage. Using a wrong model to construct estimators can thus be avoided.
Deﬁnition 3.25 Moment and sample moment
The jth moment of a random variable X with a distribution that depends on the
unknown parameter θ, is Eθ(Xj), provided that this expectation exists. The jth
sample moment of a sample of independent and identically distributed variables
X1, . . . , Xn is Xj = n−1n
i=1Xj
i .
The jth moment can be estimated using the jth sample moment of a sample with
the same distribution. It follows from the law of large numbers (Theorem A.26) that
this is a good estimator for Eθ(Xj).
72

3.4: Method of Moments Estimators
Deﬁnition 3.26 Method of moments estimator
Let X1, . . . , Xn be a sample from a distribution with unknown parameter θ. The
method of moments estimator for θ is the value ˆθ where the jth moment corresponds
to the jth sample moment:
Eˆθ(Xj) = Xj.
The method of moments estimator for g(θ) with g: Θ →H a function with codomain
H is g(ˆθ).
In practice, we prefer the method of moments estimator given by taking j as small
as possible. For a 1-dimensional parameter θ, it suﬃces to take j = 1, provided that
the expected value of the marginal distribution depends on θ. When the ﬁrst moment
does not depend on θ, we choose j = 2, etc. If θ has dimension greater than 1, we need
more than one equation to obtain a unique solution for ˆθ. In that case, the method of
moments estimator ˆθ is solved from the equations for j = 1, . . . , k with k the smallest
integer for which the system of equations has a unique solution.
Example 3.27 Exponential distribution
Let X1, . . . , Xn be a sample from an exponential distribution with unknown parameter
λ. Then EλXi = 1/λ. The method of moments estimator for λ can now be found by
solving the equation X = 1/ˆλ for ˆλ. This gives ˆλ = 1/X as a method of moments
estimator for λ. This estimator is also the maximum likelihood estimator for λ (see
Example 3.12).
Example 3.28 Uniform distribution
Let X1, . . . , Xn be a sample from the U[0, θ]-distribution with unknown parameter θ.
Then EθXi = θ/2 and the method of moments estimator for θ is equal to ˆθ = 2X.
The maximum likelihood estimator for θ is equal to X(n) (see Example 3.15). We saw
in Example 3.6 that the mean square error of X(n) is less than that of 2X. In this case,
we therefore prefer to use the maximum likelihood estimator.
Example 3.29 Normal distribution
Let X1, . . . , Xn be a sample from the N(0,σ2)-distribution with unknown parameter
σ2 > 0. Then Eσ2Xi = 0, and therefore the ﬁrst moment cannot be used to determine
the method of moments estimator for σ2. The second moment of Xi is equal to
Eσ2X2
i = σ2. The method of moments estimator for σ2 is then equal to ˆσ2 = X2. If
the expectation of Xi were unknown or nonzero, then we would have found a diﬀerent
method of moments estimator for σ2 (see Example 3.31).
73

3: Estimators
Example 3.30 Gamma distribution
Let X1, . . . , Xn be random variables with a gamma distribution with unknown
shape and inverse scale parameters α and λ, respectively. Then Eα,λXi = α/λ
and varα,λ Xi = α/λ2, and therefore the second moment is equal to Eα,λX2
i =
varα,λ Xi + (Eα,λXi)2 = α(1 + α)/λ2. The method of moments estimators for α
and λ can be found by solving the equations
Eˆα,ˆλXi = ˆα/ˆλ = X
Eˆα,ˆλX2
i = ˆα(1 + ˆα)/ˆλ2 = X2
for ˆα and ˆλ. This gives
ˆα =
(X)2
X2 −(X)2
and
ˆλ =
X
X2 −(X)2 .
Since no explicit expressions for the maximum likelihood estimators are known,
the mean square error cannot be determined. In order to choose between the two
estimators anyway based on their performance (bias and variance), we can carry out a
simulation as described in Section 3.2.
Example 3.31 Expectation and variance
Let X1, . . . , Xn be a sample with expectation μ and variance σ2. Solving for ˆμ and
ˆσ2 in the equations
Eˆμ,ˆσ2Xi = ˆμ = X,
Eˆμ,ˆσ2X2
i = ˆμ2 + ˆσ2 = X2
gives the method of moments estimators for ˆμ and ˆσ2:
ˆμ = X,
ˆσ2 = X2 −(X)2 = 1
n
n

i=1
(Xi −X)2.
If the underlying distribution is the N(μ, σ2)-distribution, then these method of
moments estimators are equal to the maximum likelihood estimators for μ and σ2
(see Example 3.14).
74

3.5: Bayes Estimators
* 3.4.1 Generalized Method Of Moments Estimators
The method of moments can be generalized in several ways. For example, instead
of using the sample moments n−1n
i=1Xj
i , we can use averages of the type
n−1n
i=1g(Xi) for suitably chosen functions g. Furthermore, the observation X need
not be a sample, and we can also use more general functions of X instead of averages.
The essence is solving a system of equations of the type g(X) = e(θ) for suitably
chosen functions and e(θ) = Eθg(X).
If the parameter is k-dimensional, then it seems natural to use k equations for the
deﬁnition of the method of moments estimator. The question is then: which functions?
In fact, the method of moments ﬁrst reduces the observations to the values of k
functions of those observations, and the method of moments estimator is based on
this reduced data. If the original data cannot be reconstructed from the k values,
this reduction leads to a loss of information. The choice of which functions to use
is therefore important for the eﬃciency of the resulting estimators.
A possible way to avoid this loss of information is to use more moments than
there are unknown parameters. Because this leads to more equations than unknowns,
in this case, it will in general not be possible to ﬁnd a parameter value for which
the sample moments are exactly equal to the theoretical moments. Instead of this,
we could minimize a measure of distance between these two types of moments, for
example an expression of the form
l

j=1
 1
n
n

i=1
gj(Xi) −Eθgj(X1)
2
.
The functions g1, . . . , gl are known, ﬁxed functions. The estimator ˆθ is the value of θ
that minimizes this expression. This method is known (especially in econometrics) as
the generalized method of moments.
3.5 Bayes Estimators
Bayes's method is the oldest method for constructing estimators; it was suggested by
Thomas Bayes at the end of the 18th century. This method is guided by a philosophy
on the way to express uncertainty. The starting point of this philosophy (in its strictest
form) is that the statistical model does not contain a unique parameter value that
corresponds to the "true" state of reality. However, every parameter value has a
probability, which can, if necessary, be determined in a subjective, personal way. This
subjective element of the method has lead to much criticism. Bayesian methods in a
more objective sense, however, have been widely accepted, and have known a great
popularity since the 1990s, because initial problems with the computations can now
be solved using computer simulation (see Section 3.5.1).
75

3: Estimators
A Bayesian approach begins with the speciﬁcation of a so-called prior probability
distribution on the parameter space Θ, in addition to the speciﬁcation of a statistical
model (or likelihood function). The prior distribution is chosen either using ad hoc
arguments or as an expression of the a priori, possibly subjective, estimate of the
probability of the diﬀerent parameter values. For example, given a binomial variable
X with success parameter θ ∈[0, 1], we could choose the uniform distribution as prior
distribution for θ.
This prior distribution is then adjusted to the available data by applying
Bayes's rule from probability theory. This adjusted distribution is called the posterior
probability distribution. We will ﬁrst describe Bayes's method as a method for
constructing estimators, and will describe this adjustment of the probability distri-
bution in more detail in Section 3.5.1.
For simplicity, we take the prior distribution to be continuous with density π, an
arbitrary probability density on Θ. The Bayes risk of an estimator T for a real-valued
parameter g(θ) is deﬁned as the weighted average of the MSE(θ; T ), with weight π,
R(π; T ) =

Eθ

T −g(θ)
2 π(θ) dθ.
This is a measure for the quality of the estimator T , which awards a higher weight to
those values θ that are deemed, a priori, more probable. The Bayes estimator is deﬁned
as the best estimator for this quality criterion. The aim is still to ﬁnd an estimator for
which the MSE(θ; T ) are small for all θ; we make the criterion more concrete by
giving weights to the diﬀerent values of θ.
Deﬁnition 3.32 Bayes estimator
The Bayes estimator with respect to the prior density π is the estimator T that
minimizes R(π; T ) over all estimators T .
In the following theorem, the Bayes estimator is speciﬁed as a quotient of two
integrals. Let x →pθ(x) be the probability density of the random vector X.
Theorem 3.33
The Bayes estimate for g(θ) with respect to the prior density π is given by
T (x) =

g(θ)pθ(x) π(θ) dθ

pϑ(x) π(ϑ) dϑ
.
The Bayes estimate therefore depends on both the likelihood function θ →pθ(x)
and the prior density π. Whereas the maximum likelihood estimator is deﬁned as the
point where the likelihood function takes on its maximum, the Bayes estimator is some
kind of weighted average of this function.
76

3.5: Bayes Estimators
Example 3.34 Exponential distribution
Let X = (X1, . . . , Xn) be a sample from the exponential distribution with unknown
parameter θ. As prior distribution for θ, we also take the exponential distribution, but
this time with known parameter λ. The Bayes estimate Tλ(x) for θ based on x =
(x1, . . . , xn) and with respect to the given prior distribution is
 ∞
0
θ
n
i=1 θe−θxi
λe−λθdθ
 ∞
0
n
i=1 ϑe−ϑxi
λe−λϑdϑ =
 ∞
0
θn+1λe−θ(λ+n
i=1xi)dθ
 ∞
0
ϑnλe−ϑ(λ+n
i=1xi)dϑ
.
Computing the integrals in the numerator and denominator of this fraction explicitly
is not the best way to determine Tλ(x). We will see that this becomes easier if we ﬁrst
determine the posterior density; see Example 3.37. In that example, we deduce that
Tλ(x) = (n + 1)/(λ + n
i=1xi) is the Bayes estimate. The Bayes estimator for θ is
therefore equal to Tλ(X) = (n + 1)/(λ + n
i=1Xi). For large values of n, the Bayes
estimator Tλ(X) and the maximum likelihood estimator ˆθ = 1/X are approximately
equal.
The proof of Theorem 3.33 is an exercise in the manipulation of conditional dis-
tributions. The following "Bayesian" notation and notions are useful for this, and of
great importance in their own right. They describe the Bayesian method in a more
comprehensive framework, where the so-called posterior distribution forms the end
point of the analysis.
Normally, we view the parameter θ as being deterministic, and there is a single
"true" parameter value that determines the density x →pθ(x) of the observation X.
In this section, we deviate from this and view pθ as the conditional density pX|Θ=θ of
a variable X given that a (hypothetical) random variable Θ takes on the value θ. We
give this quantity Θ the (marginal) probability density π. The joint density of (X, Θ)
is then equal to
pX,Θ(x, θ) = pX|Θ=θ(x)pΘ(θ) = pθ(x)π(θ).
The marginal density of X in this Bayesian setting is obtained by integrating the joint
density with respect to θ and is therefore equal to
pX(x) =

pX,Θ(x, θ) dθ =

pθ(x)π(θ) dθ.
Hence, the conditional density of Θ given X = x is equal to
pΘ|X=x(θ) =
pX,Θ(x, θ)
pX(x)
=
pθ(x)π(θ)

pϑ(x)π(ϑ) dϑ.
(This formula is exactly Bayes's rule from probability theory; see Section A.6.)
77

3: Estimators
Deﬁnition 3.35 Posterior density
The posterior density of Θ is
pΘ|X=x(θ) =
pθ(x)π(θ)

pϑ(x)π(ϑ) dϑ .
The term in the denominator of the posterior density is just a normalization
constant such that

pΘ|X=x(θ) dθ = 1.
Before the observation was known, we awarded the prior density π to Θ. Once we
know the observation, the posterior density gives the adjusted probability distribution.
This way, the observation leads us to adjust our assumptions concerning the parameter.
These computations show that the expression T (x) in Theorem 3.33 is exactly
the expectation of g(Θ) for the posterior probability distribution, the conditional
expectation of g(Θ) given X = x. We can therefore reformulate the theorem as
follows.
Theorem 3.36
Using the Bayesian notation, the Bayes estimate for g(θ) with respect to the prior
density π is given by
T (x) = E

g(Θ)| X = x

=

g(θ)pΘ|X=x(θ) dθ.
Proof. First, we write the Bayes risk in the Bayesian notation. The term Eθ

T −
g(θ)
2 in the usual notation is the conditional expectation
E

T (X) −g(Θ)
2| Θ = θ

in the Bayesian notation. From this, we deduce that
R(π; T ) =

E

T (X) −g(θ)
2| Θ = θ

π(θ) dθ
= E

T (X) −g(Θ)
2
=

E

T (x) −g(Θ)
2| X = x

pX(x) dx.
We have used the decomposition rule for expectations EZ =

E(Z| Y = y) fY (y) dy
with Z =

T (X) −g(Θ)
2 twice: in the second equality with Y = Θ and in the third
equality with Y = X.
78

3.5: Bayes Estimators
To minimize R(π; T ) with respect to T , we can minimize the integrand with
respect to every x, because the integrand is everywhere nonnegative. Therefore, for
every x, we are looking for the number t = T (x) such that
E

t −g(Θ)
2| X = x

pX(x)
is minimal. Because for given x, the term pX(x) is a nonnegativeconstant, minimizing
the integrand with respect to t is equivalent to minimizing
E

t −g(Θ)
2| X = x

with respect to t. Consequently, for every x, we can ﬁnd the number t = T (x) that
minimizes the last expression. Minimizing E(t −Y )2 with respect to t gives the value
t = EY , the minimum of the parabola t →E(t−Y )2 = t2 −2t EY +EY 2. Here, we
must apply this principle with a random variable Y that has the conditional distribution
of g(Θ) given X = x. We ﬁnd t = E

g(Θ)| X = x

; that is, the Bayes estimate is
given by T (x) = E

g(Θ)| X = x

.
Example 3.37 Exponential distribution, continued from Example 3.34
Let X = (X1, . . . , Xn) be a sample from the exponential distribution with unknown
parameter θ. Assume that the prior density for θ is the exponential distribution with
known parameter λ. Example 3.34 gives an expression for the Bayes estimate for θ. By
ﬁrst determining the posterior distribution, we can more easily determine the Bayes
estimate explicitly.
The posterior distribution is given by
θ →pΘ|X=x(θ) =
n
i=1 θe−θxi
λe−λθ
 ∞
0
n
i=1 ϑe−ϑxi
λe−λϑdϑ
=
θnλe−θ(λ+n
i=1xi)
 ∞
0
ϑnλe−ϑ(λ+n
i=1xi)dϑ
= θne−θ(λ+n
i=1xi)
C(x, λ),
where C(x, λ) is a normalization constant depending on x = (x1, . . . , xn) and λ
such that pΘ|X=x is a density. We see that this posterior distribution is the gamma
distribution with shape parameter n + 1 and inverse scale parameter equal to λ +
n
i=1xi. In general, the expected value corresponding to the gamma distribution with
shape parameter α and inverse scale parameter λ is equal to α/λ (see Example A.13).
The Bayes estimate for θ is the expected value of the posterior distribution, and is
therefore equal to Tλ(x) = (n+1)/(λ+n
i=1xi). The corresponding Bayes estimator
is Tλ(X) = (n + 1)/(λ + n
i=1Xi).
We determine the Bayes estimator for θ2 similarly. By Theorem 3.36, it is equal
to the second moment of the posterior distribution, in this case the gamma distribution
with shape parameter n + 1 and inverse scale parameter λ + n
i=1xi. The second
moment of a gamma(α,λ)-distributed random variable is equal to α/λ2 + (α/λ)2 =
(α + 1)α/λ2. The Bayes estimator for θ2 is therefore equal to (n + 2)(n + 1)/(λ +
n
i=1Xi)2.
79

3: Estimators
Example 3.38 Binomial distribution
Let X be a random variable with a binomial distribution with parameters n and θ,
where n is known and 0 ≤θ ≤1 is unknown. A useful class of prior densities on
[0, 1] is the class of beta densities, parameterized by α and β (see Example A.14):
π(θ) = θα−1(1 −θ)β−1
B(α, β)
1[0,1](θ).
When we take the beta distribution with parameters α and β as prior distribution for
Θ, the posterior density is given by
pΘ|X=x(θ) =
n
x

θx(1 −θ)n−xπ(θ)
 1
0
n
x

ϑx(1 −ϑ)n−xπ(ϑ) dϑ
= θx+α−1(1 −θ)n−x+β−1
C(x, α, β)
,
with C(x, α, β) a normalization constant such that pΘ|X=x is a density. In other words,
the posterior distribution of Θ is the beta distribution with parameters x+α, n−x+β
and with C(x, α, β) = B(x+ α, n−x+ β) for the beta function B. Figure 3.7 shows
two times three realizations of the posterior density. In all cases, the true parameter
value is equal to θ = 1
2 and the prior density (dashed in the ﬁgure) is the beta density
with parameters α = 25 and β = 5. In the top ﬁgure n = 20, while in the bottom
ﬁgure n = 100. The prior density gives a relatively large probability to values of Θ
near 1, and is therefore not suitable for estimating the true parameter value θ = 1
2.
The ﬁgure shows that this incorrect prior density is corrected well if suﬃcient data is
available, but inﬂuences the posterior density if this is not the case.
The Bayes estimate for θ is now given by the expected value corresponding to the
beta distribution with parameters x + α and n −x + β. In general, the expected value
corresponding to the beta distribution with parameters α and β is equal to α/(α + β),
so that the Bayes estimator for θ is equal to
Tα,β(X) =
X + α
n + α + β .
We ﬁnd a diﬀerent estimator for each combination of parameters (α, β) with α > 0
and β > 0. The natural estimator X/n is not in the class of Bayes estimators; rather,
it is the limit case (α, β) →(0, 0).
Which estimator should we use? If we feel strongly about a prior distribution,
we can use the corresponding Bayes estimator. A problem is that another researcher
may have other "feelings," leading to another prior distribution and therefore another
estimator. No Bayes estimator is "wrong." After all, any Bayes estimator is best if we
decide to use the corresponding Bayes risk as quality criterion. Still, it would be wise
to compare the estimators further, for example by computing the mean square errors.
80

3.5: Bayes Estimators
0.0
0.2
0.4
0.6
0.8
1.0
0
2
4
6
8
10
0.0
0.2
0.4
0.6
0.8
1.0
0
2
4
6
8
10
Figure 3.7. Three realizations of the posterior density in the cases n = 20 (top) and n = 100
(bottom). In both cases, the prior density (dashed) is equal to the beta density with α = 25 and
β = 5. The realizations (solid) are based on samples from the binomial distribution with parameters
n and 1
2 .
These are equal to
MSE(θ; Tα,β) = Eθ

X + α
n + α + β −θ
2
=
varθ X
(n + α + β)2 +
 EθX + α
n + α + β −θ
2
= θ2
(α + β)2 −n

+ θ(n −2α(α + β)

+ α2
(n + α + β)2
.
Figure 3.8 shows the mean square error of several estimators as a function of θ. Every
estimator is better than another at some point, and there is no absolutely best estimator.
Interesting special cases are α = β =
1
2
√n (constant mean square error) and
α = β = 0 (estimator X/n). The choice α = β = 1 corresponds to the uniform prior
distribution, which a priori gives all θ ∈[0, 1] the same probability. The latter seems
reasonable, but this estimator is nevertheless seldom used. Fortunately, the diﬀerences
are small when n is large, and even disappear as n →∞. Note that in the bottom
graph (corresponding to n = 100) in Figure 3.7 the three realizations of the posterior
distribution lie closer to the true value 1/2, but are also more concentrated. The
posterior densities seem surprisingly normal. We will come back to this in Section 5.7,
81

3: Estimators
where we will see that Bayes and maximum likelihood estimators often diﬀer little
when the number of observations is large.
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.005
0.010
0.015
0.020
0.025
0.030
Figure 3.8. Mean square error of the Bayes estimators Tα,β with n = 20 and α = β =
1
2
√n
(constant), α = β = 0 (curved, solid), α = √n, β = 0 (linear, dashed), and α = β = 1 (small
dashes) as functions of θ.
Example 3.39 Geometric distribution
Let X = (X1, . . . , Xn) be a sample from the geometric distribution with parameter θ,
Pθ(X1 = x) = (1 −θ)x−1θ,
x = 1, 2, . . .,
where 0 ≤θ ≤1 is unknown. As prior distribution for θ, we choose the beta
distribution with parameters α = β = 2 with probability density
π(θ) = 6(1 −θ)θ,
θ ∈(0, 1).
Then, the posterior distribution is given by
pΘ|X=x(θ) =
n
i=1 Pθ(Xi = xi)π(θ)
 1
0
n
i=1 Pϑ(Xi = xi)π(ϑ) dϑ
= θn+1(1 −θ)n(x−1)+1
C(x1, . . . , xn)
.
This posterior distribution of θ is the beta distribution with parameters n + 2 and
n(x −1) + 2. As in the previous example, we determine the Bayes estimator for θ
using the expectation of the beta distribution T (X) = (n + 2)/(nX + 4).
82

3.5: Bayes Estimators
* 3.5.1 MCMC Methods
The principle behind Bayes's method is simple: from a model and a prior distribution,
we compute the posterior distribution using Bayes's rule. However, the computation
in the last step is not always simple. Traditionally, the prior distribution is chosen in
such a way that it simpliﬁes the computation for the given model. The combination
of the binomial distribution with the beta prior distribution is an example. A more
recent approach is to replace the analytic computation by numerical approximations,
or Markov Chain Monte Carlo (or MCMC) methods. In principle, such methods allow
us to combine an arbitrary prior distribution with a given random model. In this
section, we give a short introduction to these methods.
Given an observation X with realization x with probability density pθ and a prior
density π, the posterior density is proportional to the function
θ →pθ(x)π(θ).
In most cases, this expression is easy to compute, because this function is directly
related to the speciﬁcation of the random model and the prior distribution. In general,
however, it is not easy to compute the posterior density or the Bayes estimate: for
this, we need to evaluate the integral of pθ(x)π(θ) or θpθ(x)π(θ), respectively, with
respect to θ for given x. The fact that this can be diﬃcult has decreased the popularity
of Bayes estimators. It is not very attractive to have to choose a certain prior density
for the sake of simpler computations.
If the dimension of the parameter θ is low, for example if θ is real, implementing
the computations numerically is reasonable straightforward, for example by approx-
imating the integrals by sums. For higher-dimensional parameters, for example of
dimension greater than or equal to 4, the problems are more important. Simulation
methods have been used to reduce these problems since the 1990s. MCMC methods
are a general process used to simulate a Markov chain Y1, Y2, . . . whose marginal
distributions are approximately equal to the posterior distribution. Before we describe
the MCMC algorithms, we discuss a number of essential notions from the theory of
Markov chains.
A Markov chain is a sequence Y1, Y2, . . . of random variables such that the
conditional distribution of Yn+1 given the previous variables Y1, . . . , Yn depends only
on Yn. An equivalent formulation is that given the "present" variable Yn, the "future"
variable Yn+1 is independent of the "past" Y1, . . . , Yn−1. We can then see the variable
Yn as the state at "time" n, and to simulate the next state Yn+1, it suﬃces to know
the current state Yn; knowledge of the prior states is irrelevant. We will consider
only Markov chains that are "time-homogeneous." This means that the conditional
distribution of Yn+1 given Yn does not depend on n, so that the transition from one
state to the next always follows the same mechanism. The behavior of the chain is
then completely determined by the transition kernel Q given by
Q(y, B) = P(Yn+1 ∈B| Yn = y).
83

3: Estimators
For a ﬁxed y, the map B →Q(y, B) gives the probability distribution at the next time
given the current state y. Often, Q is described using the corresponding transition
density q. This is the conditional density of Yn+1 given Yn; it satisﬁes Q(y, B) =

B q(y, z) dz, where in the discrete case, the integral must be replaced by a sum.
A probability distribution Υ is called a stationary distribution for the transition
kernel Q if, for every event B,

Q(y, B) dΥ(y) = Υ(B).
This equation says precisely that the stationary distribution is preserved under the
transition from Yn to Yn+1. If Y1 has a stationary distribution, then Y2 also has a
stationary distribution, etc. If Q has transition density q and Υ has density υ (which is
then called a stationary density), then

q(y, z) υ(y) dy = υ(z)
is an equivalent equation. This gives a simple way to characterize stationary
distributions. (The stationary distribution and density of a Markov chain are custom-
arily called Π and π, respectively. However, in the context of Bayesian estimates, this
notation may lead to confusion, which is why we use the symbols given above.) When
a density υ satisﬁes the detailed balance relation
υ(y)q(y, z) = υ(z)q(z, y),
υ is a stationary density. This can be seen by integrating both sides of the relation with
respect to y and using the fact that  q(z, y) dy = 1 for every z. The detailed balance
relation requires that a transition from y to z be as probable as a transition from z to y
when in both cases, the ﬁrst point is chosen from the density υ. A Markov chain with
this property is called reversible.
The introduction to Markov chains we just gave suﬃces to understand the
principle of MCMC algorithms. In MCMC algorithms, Markov chains are generated
with a transition kernel whose stationary density is equal to the desired posterior
density. In the application to MCMC, the stationary density y →υ(y) in the general
discussion of Markov chains is replaced by a posterior density that is proportional
to θ →pθ(x)π(θ) for observed data x. Fortunately, in simulation schemes, the
proportionality constant is unimportant, so that the fact that the integrals are diﬃcult
to evaluate is not relevant. Consequently, MCMC algorithms can, in principle, be used
for any prior distribution.
Because it is usually not easy to generate the ﬁrst value Y1 of the chain from the
stationary density (in the MCMC context, this is the posterior density), an MCMC
chain is usually not stationary. The chain does converge to a stationary one as
n →∞. In practice, the chain is simulated over a great number (N) of steps, and
the ﬁrst simulated data Y1, . . . , Yb are thrown out; this is called the "burn-in." The
remaining variables Yb+1, Yb+2, . . . , YN can be viewed as a realization of a Markov
chain with the posterior distribution as stationary distribution. Using, for example,
84

3.5: Bayes Estimators
a histogram of Yb+1, . . . , YN, we obtain a good idea of the posterior distribution,
and the average of Yb+1, . . . , YN is a good approximation of the Bayes estimator, the
posterior expectation. The motivation for using this "empirical approach" is the same
as in Section 2.2.1, except that the variables Y1, Y2, . . . now form a Markov chain
and are therefore not independent. However, many Markov chains also follow a law
of large numbers, which guarantees that now, too, averages behave asymptotically as
expectations. The convergence rate does turn out to depend strongly on the transition
kernel, so that in practice, it can still be quite diﬃcult to set up an MCMC algorithm
that leads to a good approximation within a reasonable (CPU) time.
There now exist many types of MCMC algorithms. The two most important ones,
which are often used together, are the Metropolis-Hastings algorithm and the Gibbs
sampler.
Example 3.40 Metropolis-Hastings algorithm
The Metropolis-Hastings algorithm generates a Markov chain using a so-called
proposal transition density q (with associated transition kernel Q). This transition
density is chosen in such a way that it is easy to simulate using the probability density
z →q(y, z), for every given y. At the end of this example, we will come back to the
choice of the proposal density. Next, deﬁne
α(y, z) = υ(z)q(z, y)
υ(y)q(y, z) ∧1
with υ the posterior density we want to approximate and a ∧b = min(a, b). Note
that to determine α(y, z), it suﬃces to know the form of υ and q; the proportionality
constant disappears. In the Metropolis-Hastings algorithm, for every transition from
Yn to Yn+1 in the Markov chain, a state Zn+1 is generated following the proposal
transition kernel Q, which acts as a candidate value (whence the name proposal). This
state is accepted (that is, Yn+1 = Zn+1) with probability α(Yn, Zn+1) and rejected
with probability 1 −α(Yn, Zn+1), in which case the current state is kept (that is,
Yn+1 = Yn). The simulation algorithm is then as follows:
Take a ﬁxed initial value Y0 and then continue recursively as follows:
given Yn, generate Zn+1 from Q(Yn, ·)
generate Un+1 from the uniform distribution on [0, 1]
if Un+1 < α(Yn, Zn+1), let Yn+1: = Zn+1
else let Yn+1: = Yn.
85

3: Estimators
The transition kernel P of the resulting Markov chain Y1, Y2, . . . consists of two
pieces, corresponding to the "if-else" split. The kernel is given by
P(y, B) = P(Yn+1 ∈B| Yn = y)
= P(Zn+1 ∈B, Un+1 < α(Yn, Zn+1)| Yn = y)
+ P(Yn ∈B, Un+1 ≥α(Yn, Zn+1)| Yn = y)
=

B
α(y, z)q(y, z) dz
+

1 −P(Un+1 < α(Yn, Zn+1)| Yn = y)

1y∈B
=

B
α(y, z)q(y, z) dz +

1 −E(α(y, Zn+1)| Yn = y)

1y∈B
=

B
α(y, z)q(y, z) dz +

1 −

α(y, z)q(y, z) dz

1y∈B,
where the last integral is taken over the entire state space. The moves of the chain
corresponding to the ﬁrst term in the last expression are governed by the transition
density r(y, z) = α(y, z)q(y, z). The function α is chosen in such a way that the
codomain contains the interval [0, 1] and that the detailed balance relation
(3.4)
υ(y)r(y, z) = υ(z)r(z, y)
is satisﬁed. This part of the Markov chain is therefore reversible. In the second part of
the chain, given Yn = y, we stay in y with probability
1 −

α(y, z)q(y, z) dz.
This movement from y to y is trivially symmetric. It easily follows from these
statements that υ is a stationary density for the Markov chain Y1, Y2, . . ..
A popular choice for the proposal density q is the random walk kernel q(y, z) =
f(z−y) for a given density f. If we choose f symmetric about 0, then α(y, z) reduces
to υ(z)/υ(y). Choosing a good kernel is not easy. The general principle is to choose
a transition kernel Q that represents "movements" toward variables Zn+1 in the full
domain of υ in the ﬁrst step of the algorithm, and at the same time, does not lead
too often to the step "else", because this would negatively inﬂuence the eﬃciency of
the algorithm. In MCMC jargon, we say that we are looking for a proposal transition
kernel Q that "is suﬃciently mixing," "searches the space suﬃciently well," and "does
not linger too much."
To illustrate this, we apply the algorithm given above to the situation of
Example 3.39, where the posterior density can easily be derived analytically. For this,
we generate a sample of size n = 25 from the geometric distribution with parameter
θ = 0.2 and ﬁnd x = 5.88. For the prior density, we take π(θ) = 6θ(1 −θ), the
beta(2, 2)-density.
86

3.5: Bayes Estimators
0.0
0.2
0.4
0.6
0.8
1.0
0
2
4
6
8
10
12
14
Figure 3.9. Histogram of the values Y201, . . . , Y1000 in the Markov chain generated by the
Metropolis-Hastings algorithm based on a geometric sample of size n = 25 with θ = 0.2 and
x = 5.88. The posterior beta(27, 124)-density (solid line) and the prior beta(2, 2)-density (dashed
line) are also shown.
Figure 3.9 shows the histogram of Y201, . . . , Y1000 for the chain generated using
the Metropolis-Hastings algorithm with a normal random walk kernel. The dashed
line in the ﬁgure depicts the prior density. The computations in Example 3.39 imply
that the posterior density for this case is equal to the density of the beta(27, 124)-
distribution, which is also drawn in Figure 3.9 (solid line). We see that the histogram
of the values of Y gives a good representation of the posterior density, as expected.
Moreover, the average (0.18) of the values of Y is equal to the Bayes estimate:
27/(27+124)=0.18.
Example 3.41 Gibbs sampler
The Gibbs sampler reduces the problem of approximating a high-dimensional
posterior density to repeatedly approximating lower-dimensional distributions. The
algorithm is often used in combination with the Metropolis-Hastings sampler if
no suitable proposal transition density q is available for the Metropolis-Hastings
algorithm.
Let υ be a density for the m-dimensional variable Y from which we want to
generate a sample. Suppose that we have at our disposal a procedure to generate
variables from each of the conditional densities
υi(yi| y1, . . . , yi−1, yi+1, . . .ym) =
υ(y)

υ(y) dyi
,
i = 1, . . . , m,
where y = (y1, . . . , ym). The following algorithm yields a chain Y1, . . . , Yn with
stationary density υ:
Choose an initial value Y0 = (Y0,1, . . . , Y0,m), then continue recursively as follows:
Given Yn = (Yn,1, . . . , Yn,m),
87

3: Estimators
generate Yn+1,1 using υ1(·| Yn,2, . . . , Yn,m)
generate Yn+1,2 using υ2(·| Yn+1,1, Yn,3. . . , Yn,m)
...
generate Yn+1,m using υm(·| Yn+1,1, . . . , Yn+1,m−1).
One by one, the coordinates are replaced by a new value, each time conditionally on
the latest available value of the other coordinates. We can check that the density υ
is stationary for each of the steps of the algorithm individually (see Exercise 3.42).
The resulting chain Y1, . . . , Yn has stationary density υ. The Gibbs sampler can be
used, for example, when there is a high-dimensional proposal transition density in the
Metropolis-Hastings algorithm.
Example 3.42 Missing data
Suppose that instead of the "complete data" (X, Y ), we can only observe the data X.
If (x, y) →pθ(x, y) is a probability density of (X, Y ) that depends on the parameter
θ, then x →

pθ(x, y) dy is a probability density of the observation X. Given a prior
density θ →π(θ), the posterior density based on the observed value x is therefore
proportional to
θ →π(θ)

pθ(x, y) dy.
We can apply the MCMC algorithms described earlier to this posterior density.
However, if the marginal density of X (the integral in the display above) cannot be
computed analytically, then implementing the MCMC algorithms is diﬃcult.
An alternative to computing the marginal distribution is to also approximate
the unobserved values Y . In the Bayesian notation, the posterior distribution is the
conditional distribution of an imaginary variable Θ given the observation X. This
is the marginal distribution of the conditional distribution of the pair (Θ, Y ) given
X. If we could generate a sequence of variables (Θ1, Y1), . . . , (Θn, Yn) using the
last conditional distribution, then the ﬁrst coordinates Θ1, . . . , Θn of this sequence
would be samples from the desired posterior distribution. Marginalizing an empiric
distribution is the same as "forgetting" variables, and that is very easy to do
computationally.
Thus, we can apply an MCMC algorithm to simulate variables (Θi, Yi) from the
probability density that is proportional to the map (θ, y) →pθ(x, y)π(θ), with x equal
to the observed value of X. Next, we throw out the Y -values and view the remaining
Θ-values as a sample from the posterior distribution of the parameter.
88

3.6: M-Estimators
* 3.6 M-Estimators
Let M(θ; X) be an arbitrary function of the parameter and the observation. An M-
estimator for a parameter θ is the value of θ that maximizes (or minimizes) the
criterion function θ →M(θ; X). Another term is maximum (or minimum) contrast
estimator.
If we take M equal to the likelihood function, we ﬁnd the maximum likelihood
estimator for θ. There are many other possibilities. The most common criterion
functions for independent observations X = (X1, . . . , Xn) have a sum structure:
M(θ; X) =
n

i=1
mθ(Xi)
for suitably chosen functions mθ.
Maximizing a function is often the same as solving the system of equations
obtained by setting the derivative equal to 0. The term "M-estimator" is therefore
also used for estimators that solve an equation Ψ(θ; X) = 0. Such equations are
called estimating equations. Because not every vector-valued function is a gradient of
a function, estimating equations are more general than contrast functions. The most
common criterion functions for independent observations X = (X1, . . . , Xn) have a
sum structure:
Ψ(θ; X) =
n

i=1
ψθ(Xi)
for suitably chosen vector-valued functions ψθ. The equation Ψ(θ; X) = 0 is
understood as a system of equations. The number of equations is equal to the
dimension of the range of ψθ, and would typically be chosen equal to the number
of parameters to be estimated.
Example 3.43 Median
The average X of random variables X1, . . . , Xn minimizes the function θ
→
n
i=1(Xi −θ)2. The average is an estimate for the "center" of the probability
distribution of the observations. An alternative estimator with roughly the same
interpretation is obtained by minimizing the function θ →n
i=1|Xi −θ|. We can
show that this leads to the sample median
med{X1, . . . , Xn} =
 X((n+1)/2)
if n is odd,
1
2(X(n/2) + X(n+2)/2))
if n is even.
This is the "middle observation."
89

3: Estimators
Replacing the square by the absolute value has the eﬀect of reducing the inﬂuence
of very large or very small observations. Indeed, the sample median does not change
if the big and small observations are made even bigger or smaller. This property
is referred as the robustness of the median or, more precisely, robustness against
outliers. By making diﬀerent choices of contrast function, we may deﬁne other robust
estimators. For instance, the Huber estimator is given by mθ(x) = (x−θ)21|x−θ|<c+
c|x −θ|1|x−θ|≥c and is a compromise between mean and median. The parameter c is
typically estimated, to reﬂect the scale of the data.
-4
-2
0
2
4
5
10
15
Figure 3.10. The function θ →Σn
i=1|xi −θ| for a sample x1, . . . , xn of size 4 from the standard
normal distribution.
Example 3.44 Least-squares estimator
In Example 1.5, we brieﬂy described the simple linear regression model (see also
Section 7.2). For dependent variables Y1, . . . , Yn and predictor variables x1, . . . , xn,
we have Yi = α + βxi + ei. The measurement errors e1, . . . , en are often assumed
to be independent and have a normal distribution with expectation 0 and variance σ2.
The unknown parameters α and β can be estimated using the least-squares estimators
(LS-estimators); these are the values that minimize
n

i=1
(Yi −α −βxi)2
with respect to α and β. If the measurement errors are normally distributed, the least-
squares estimators correspond to the maximum likelihood estimators for α and β (see
Section 7.2). The LS-estimators can also be used without the normality assumption.
They are then not maximum likelihood estimators, but general M-estimators.
More generally, we can use the least-squares method in a nonlinear regression
model Yi = gθ(xi) + ei, where gθ is a nonlinear function of θ, the terms e1, . . . , en
are unobservable measurement errors, and x →gθ(x) is a function that is known up
to the parameter θ. The LS-estimator for θ minimizes the criterion
θ →
n

i=1

Yi −gθ(xi)
2.
90

3.6: M-Estimators
If the measurement errors are normally distributed, this again leads to the maximum
likelihood estimator for θ. For a nonlinear function gθ, we often need a numerical
algorithm to compute the least-squares estimate.
An example of nonlinear regression is ﬁtting a time curve when we have
observations y1, . . . , yn, including measurement errors, of the curve at certain times
x1, . . . , xn. If a parameterized curve is of the form t →gθ(t), for example gθ(t) =
θ0 + θ1t + θ2e−θ3t with 4-dimensional parameter θ = (θ0, θ1, θ2, θ3), then we can
estimate the parameter θ using the observations (xi, yi) for i = 1, . . . , n.
Example 3.45 Generalized estimating equations
Suppose that we measure each of n experimental units or individuals repeatedly,
obtaining the observations Yi = (Yi,1, . . ., Yi,Ti)T , for i = 1, 2. . ., n, which we wish
to model by a linear regression model of the type as described in Example 1.5 (see
also Section 7.2). We use a common set of parameters β = (β1, . . ., βp)T for all
observations and hence obtain the model, for i = 1, . . ., n and t = 1, . . ., Ti,
Yi,t = xT
i,tβ + ei,t,
where the vectors xi,t ∈Rp are known explanatory variables. Since the observations
Yi,t for the same value of i refer to the same experimental unit, it is often not
reasonable to model the errors ei,t as independent random variables, as in the ordinary
regression model. On the other hand, if the units themselves are a sample of possible
units, then it is reasonable to model the n error vectors ei: = (ei,1, . . ., ei,Ti)T as
independent. A standard model is then to assume that every ei follows a multivariate
normal distribution NTi(0, σ2Λi), where σ2
> 0 and Λi is a positive-deﬁnite
(Ti×Ti)-matrix. The logarithm of the likelihood for observing the independent vectors
Y1, . . ., Yn is then, up to an additive constant,
−1
2
n

i=1
log det(σ2Λi) −
1
2σ2
n

i=1
(Yi −Xiβ)T Λ−1
i (Yi −Xiβ).
Here Xi is the (Ti × p)-matrix with rows the vectors xT
i,t, for t = 1, . . ., Ti. The
expression in the display may be maximized with respect to the unknown parameters
to obtain the maximum likelihood estimators.
The main interest is usually in the vector β of regression parameters. Within
the maximum likelihood setup, the estimation of this vector is confounded by the
presence of the additional parameters σ2 and Λi. The matrices Λi may contribute
many unknowns, even in the simplest case that we choose to restrain them to be equal
for diﬀerent i (and Ti = T is large). The method of estimating equations is helpful to
overcome this problem.
We start by noting that the maximum likelihood estimator for β solves the
stationary equation obtained by setting the partial derivative of the log likelihood with
respect to β equal to 0. This takes on the form
(3.5)
n

i=1
XT
i Λ−1
i (Yi −Xiβ) = 0.
91

3: Estimators
This still contains the matrices Λi, but only as weight factors. The reason that solving
the equation gives a good estimator for β is that the expectations of the terms
of the sum vanish, as E(Yi −Xiβ) = 0, by the fact that the errors ei,t in the
model have expectation 0. One says that the preceding display gives an unbiased
estimating equation for β. This fact does not depend on the matrix Λi, but remains
true if this matrix is replaced by a diﬀerent one. Further analysis will reveal that
the weight matrices Λi are optimal in the sense of leading to the smallest possible
(asymptotic) mean square error for the estimator for β. However, if we do not know
these matrices, then we could only use them in the equation after estimating them from
the data, and this might introduce considerable additional variance, particularly when
the dimensions of the matrices are large relative to n and p. The method of generalized
estimating equations, or GEE, is to replace the matrices by either ﬁxed matrices or
matrices of a particular form, given by a low-dimensional parametric model. For
instance, popular choices are the autoregressive and exchangeable matrices, which
in the case that Ti = 4 take on the forms
⎛
⎜
⎝
1
ρ
ρ2
ρ3
ρ
1
ρ
ρ2
ρ2
ρ
1
ρ
ρ3
ρ2
ρ
1
⎞
⎟
⎠,
⎛
⎜
⎝
1
ρ
ρ
ρ
ρ
1
ρ
ρ
ρ
ρ
1
ρ
ρ
ρ
ρ
1
⎞
⎟
⎠.
The parameter ρ ∈(−1, 1) in these matrices determines the dependence between
the multiple observations on a given experimental unit. The value 0 corresponds to
independence and a value close to the ends of the interval (−1, 1) gives strong negative
or positive dependence. It works best to choose ρ such that the corresponding matrix is
close to the true matrix Λi. In practice, we may estimate an appropriate value from the
data. We next substitute the estimated matrix for the matrix Λi in the equation (3.5),
and ﬁnally solve for β.
92

3.7: Summary
3.7 Summary
Let X = (X1, . . . , Xn) be an observation with distribution Pθ that depends on the
unknown parameter θ. An estimator T = T (X) for g(θ) is a random variable that
depends only on the observation X (and therefore not on the unknown parameter θ!).
(If g(θ) = θ, then T is an estimator for θ.) The corresponding estimate is denoted by
T (x), where x is the vector of the observed values.
Measures for the quality of estimators:
• The bias of an estimator T for g(θ) is EθT −g(θ).
• The mean square error (MSE) is a measure for the accuracy of an estimator. The
MSE is deﬁned as the expected square diﬀerence between T and g(θ):
MSE(θ; T ) = EθT −g(θ)2.
We prefer an estimator with a small MSE for all values of θ. If g(θ) ∈R, then
MSE(θ; T ) = varθ T + (EθT −g(θ))2; that is, the MSE is the sum of the variance
and the square bias.
Diﬀerent types of estimators:
• The maximum likelihood estimate for θ is the value ˆθ that maximizes the likelihood
function. The likelihood function is the (joint) probability density pθ of X viewed
as a function of θ, for a given observation x: θ
→L(θ, x)
=
pθ(x). If
X = (X1, . . . , Xn) is a sample from a distribution with marginal probability
density fθ, then the likelihood function is equal to L(θ; x = (x1, . . . , xn)) =
n
i=1 fθ(xi). The maximum likelihood estimate is often found as a solution of the
likelihood equations, but can also be a value of θ where the likelihood function is
discontinuous. The maximum likelihood estimate for g(θ) is deﬁned as g(ˆθ). The
maximum likelihood estimator is the corresponding random variable.
• A method of moments estimator for θ based on a sample X = (X1, . . . , Xn) is a
random variable ˆθ for which the ﬁrst k theoretical moments are equal to the ﬁrst
k sample moments: EˆθXj
i = Xj for j = 1, . . . , k, with k the least possible. The
method of moments estimator for g(θ) is deﬁned as g(ˆθ).
• The Bayes estimator for g(θ) with respect to a prior density π is the estimator that
minimizes the Bayes risk 
Θ Eθ(T −g(θ))2π(θ) dθ over all estimators T . This
Bayes risk is the probability-weighted average of MSE(θ; T ) for the probability
density π. For a given observation x, the posterior density of the parameter random
variable Θ is
pΘ|X=x(θ) =
pθ(x)π(θ)

pϑ(x)π(ϑ) dϑ.
The Bayes estimate for g(θ) is equal to the expected value of g(Θ) with respect
to the posterior distribution: E

g(Θ)| X = x

. In general, the Bayes estimate for
g(θ) is not equal to the transformation g(ˆθ) of the Bayes estimate ˆθ for θ.
93

3: Estimators
Exercises
1. Give a theoretical explanation for the forms of the (exponential and normal) histograms in
Figure 3.1.
2. Let X1, . . . , Xn be independent and U[0, θ]-distributed, with θ > 0 unknown. Determine the
mean square errors of the estimators cX(n) for θ, for every value of c > 0. Which value for c
gives the best estimator?
3. Let X be binomially distributed with parameters n and p, with n known and p ∈[0, 1]
unknown. Let Tc = cX/n be an estimator for p, where c > 0 is yet to be determined.
(i) For which value of c is Tc unbiased?
(ii) Determine the mean square error of Tc.
(iii) For which value of c is this estimator optimal? Is this optimal estimator usable in
practice? Explain.
(iv) Determine the limit of the optimal value for c as n →∞. Which estimator Tc do you
obtain?
4. Let X1, . . . , Xn be a sample from the Poisson(θ)-distribution. We want to estimate θ2.
(i) Is (X)2 an unbiased estimator for θ2?
(ii) Determine an unbiased estimator for θ2.
5. Let X1, . . . , Xm and Y1, . . . , Yn be independent samples from the Bernoulli distribution with
unknown parameter p ∈[0, 1].
(i) Prove that (X + Y)/2 and (m
i=1 Xi + n
j=1 Yj)/(m + n) are unbiased estimators for p.
(ii) Which of these two estimators is preferable (if m = n)?
6. In a study on discrimination in Amsterdam, the subjects are asked whether they have
experienced discrimination (based on race, skin color, gender, or religion). A stratiﬁed
sample is taken: 50 men and 50 women are chosen randomly from the adult population
of Amsterdam. Let X be the number of men and Y the number of women in the sample that
have experienced discrimination. Deﬁne:
pM = proportion of male Amsterdammers having experienced discrimination
pV = proportion of female Amsterdammers having experienced discrimination
p = proportion of Amsterdammers having experienced discrimination
Assume pV = 2pM and that there are as many men as women living in Amsterdam.
(i) Compute the mean square error of the estimator (X + Y)/100 for p.
Now, deﬁne Z as the number of persons having experienced discrimination in a normal
(nonstratiﬁed = simple) sample of 100 adult Amsterdammers.
(ii) Compute the mean square error of the estimator Z/100 for p.
(iii) Compare the two mean square errors. What do you conclude?
7. We want to study how many Dutch households have a tablet. Let Π be the total population of
all Dutch households. Let k be the number of towns in the Netherlands, and let 1000mi be the
number of households in the ith town, for i = 1, 2, . . . , k. For convenience, we assume mi ∈
N. So in Π, there are M = 
i mi thousands of households. We then take a sample as follows.
First, randomly choose 100 thousands from all these thousands, without replacement. Let Yi
be the number of chosen thousands in the ith town. Next, randomly choose 10Yi households
in the ith town, without replacement. Let pi be the proportion of households with a tablet
in the ith town, and p the proportion of the total population. Approximate p with X/1000,
where X is the total number of chosen households with a tablet. Is X/1000 an unbiased
estimator for p?
94

3: Exercises
8. Compute the maximum likelihood estimator for θ based on a sample X1, . . . , Xn from the
Poisson(θ)-distribution.
9. Let X1, . . . , Xn be a sample from a Weibull distribution, whose probability density is given
by
pθ(x) = θaxa−1e−θxa
for x > 0
and 0 otherwise. Here a is a known number, and θ > 0 is an unknown parameter.
(i) Determine the maximum likelihood estimator for θ.
(ii) Determine the maximum likelihood estimator for 1/θ.
10. Let X1, . . . , Xn be a sample from a distribution with probability density
pθ(x) = θxθ−1
for x ∈(0, 1)
and 0 otherwise. Here θ > 0 is an unknown parameter.
(i) Compute μ = g(θ) = EθX1.
(ii) Determine the maximum likelihood estimator for μ.
11. An urn contains white and black balls in the ratio p : 1 −p. We draw balls one by
one with replacement, continuing until we draw a white ball. Let Yi be the number of
draws necessary. We repeat this process n times, giving numbers Y1, . . . , Yn. Determine the
maximum likelihood estimator for p.
12. Let X1, . . . , Xn be a sample from a distribution with probability density
pθ(x) = θx−2
for x ≥θ
and 0 for x < θ, with θ > 0 unknown.
(i) Determine the maximum likelihood estimator for θ.
(ii) Is this estimator unbiased?
(iii) Determine the mean square error of this estimator.
13. Let X1, . . . , Xn be a sample from a distribution with probability density
pθ(x) = θ(1 + x)−(1+θ)
for x ≥0
and 0 elsewhere, with θ > 0 unknown. Determine the maximum likelihood estimator for θ.
14. Let X1, . . . , Xm and Y1, . . . , Yn be two independent samples from the normal distributions
with parameters (μ1, σ2) and (μ2, σ2), respectively. Determine the maximum likelihood
estimator for θ = (μ1, μ2, σ2).
15. Suppose that the vector X = (X1, . . . , Xm) has a multinomial distribution with parameters n
and (p1, . . . , pm), where p1+. . .+pm = 1. We assume that n is known and that the probabilities
p1, . . . , pm are unknown. Show that the maximum likelihood estimator for (p1, . . . , pm) is
equal to (X1/n, . . . , Xm/n).
16. Let X1, . . . , Xn be a sample from the shifted exponential distribution with intensity parameter
1 and unknown shift parameter θ ∈(−∞, ∞). The corresponding density is given by pθ(x) =
eθ−x for x ≥θ and pθ(x) = 0 for x < θ. Determine the maximum likelihood estimator for θ.
95

3: Estimators
17. We want to estimate the number N of ﬁsh in a pond. We proceed as follows. We catch r
ﬁsh and mark them. We then set them free. After some time, we catch n ﬁsh (without putting
them back). Let Xi be equal to 0 if the ith ﬁsh we catch is marked and 1 if it is not (i = 1, .., n).
(i) Determine the probability distribution of 
Xi expressed in r, n, and N.
(ii) Determine the maximum likelihood estimator for N based on n
i=1Xi.
18. Let X1, . . . , Xn be a sample from a distribution with an unknown distribution function F. We
denote the empirical distribution function of the sample by ˆF.
(i) Which distribution does n ˆF(x) have?
(ii) Is ˆF(x) an unbiased estimator for F(x)?
(iii) Determine the variance of ˆF(x).
(iv) Show that cov( ˆF(u), ˆF(v)) = n−1(F(m) −F(u)F(v)) with m = min{u, v}. It follows that
ˆF(u) and ˆF(v) have a positive correlation.
19. (k-means clustering.) Let X1, . . . , Xn be independent random variables such that for an
unknown partition {1, . . . , n} = ∪k
j=1Ij, the variables (Xi; i ∈Ij) are normally distributed with
expectation μj and variance 1. Show that the maximum likelihood estimator for the partition
and parameter vector (μ1, . . . , μk) minimizes the sum of squares k
j=1

i∈Ij(Xi −μj)2. Give
an interpretation of this procedure in words.
20. Let X1, . . . , Xn be a sample from the exponential distribution with parameter λ, where λ > 0
is an unknown parameter.
(i) Determine the maximum likelihood estimator for 1/λ2.
(ii) Determine a method of moments estimator for 1/λ2.
(iii) Determine an unbiased estimator for 1/λ2.
21. Let X1, . . . , Xn be a sample from the binomial distribution with parameters n and p, where
p ∈[0, 1] is unknown. Determine the maximum likelihood estimator and the method of
moments estimator for p.
22. Let X1, . . . , Xn be a sample from the Bernoulli distribution with unknown parameter p ∈
[0, 1].
(i) Determine the method of moments estimator T for p.
(ii) Show that the estimator T 2 is biased for p2, and then determine an unbiased estimator
for p2.
23. Let X1, . . . , Xn be a sample from the geometric distribution with unknown parameter p ∈
(0, 1]. Determine the method of moments estimator for p.
24. Let X1, . . . , Xn be a sample from a probability distribution with density
pθ(x) = θ(1 + x)−(1+θ)
for x > 0
and 0 elsewhere, with θ > 1 unknown. Determine the method of moments estimator for θ.
25. Let X1, . . . , Xn be a sample from a probability distribution with density
pθ(x) = 2x
θ2 1{0≤x≤θ},
where θ > 0 is an unknown parameter.
(i) Determine the method of moments estimator T for θ.
(ii) Show that T is unbiased for θ.
(iii) Give the method of moments estimator for θ2.
96

3: Exercises
(iv) Show that the method of moments estimator for θ2 is biased for θ2, and then determine
an unbiased estimator for θ2.
26. Let X1, . . . , Xn be a sample from a probability distribution given by Pθ(X = x) = 1/θ for
x ∈{1, 2, . . . , θ}, where θ ∈N is unknown.
(i) Determine the method of moments estimator for θ.
(ii) Determine the maximum likelihood estimator for θ.
27. Let X1, . . . , Xn be sample from the U[σ, τ]-distribution with σ < τ unknown.
(i) Determine the maximum likelihood estimator for the vector (σ, τ).
(ii) Determine the method of moments estimator for the vector (σ, τ).
28. Let X1, . . . , Xn be a sample from the uniform distribution on [−θ, θ], with θ > 0 unknown.
(i) Determine the maximum likelihood estimator for θ.
(ii) Determine the method of moments estimator for θ.
29. Let X be a random variable with ﬁnite second moment. Show that the function b →E(X−b)2
is minimal at b = EX.
30. Let X be a continuously distributed random variable with ﬁnite ﬁrst moment. Show that the
function b →E|X −b| is minimal at a point b such that P(X < b) = P(X > b) = 1/2; we call
b the population median.
31. Let X1, . . . , Xn be a sample from the Laplace distribution (or double exponential distribu-
tion), which has probability density
pθ(x) = 1
2e−|x−θ|
for θ ∈R.
(i) Determine the population median (see previous exercise).
(ii) Determine the maximum likelihood estimator for θ.
(iii) Determine the method of moments estimator for θ.
32. The method of moments estimator and maximum likelihood estimator for the parameter of
a Laplace distribution are very diﬀerent. Use a simulation to determine which estimator is
preferable. The R-program in Table 3.1 can be used for this.
Explanation: in the ﬁrst line, we declare two vectors (arrays) of length 1000, which
we ﬁll with 1000 realizations of the two estimators. In the last two lines, we compute the
mean square deviation of these two vectors from the true value of the parameter (equal to 0
in this case). These are not the true mean square errors, but they are good approximations
thereof. In the ﬁrst line of the for-loop, a sample of size n (n = 100) is taken from the
standard Laplace distribution. Next, both estimates are computed based on this sample. This
is repeated 1000 times.
33. Let X1, . . . , Xn be a sample from a probability distribution with density
pθ(x) = θxθ−1
for 0 ≤x ≤1
and 0 elsewhere, with θ > 0 unknown.
(i) Determine the method of moments estimator for θ.
(ii) Determine the maximum likelihood-estimator for θ.
(iii) Determine the Bayes estimator for θ with respect to the prior density π given by π(θ) =
e−θ for θ > 0 and 0 elsewhere.
97

3: Estimators
moments = mls = numeric(1000)
n = 100
for (i in 1:1000) {
x = rexp(n)*(2*rbinom(n,1,0.5)-1)
moments[i] = mean(x)
mls[i] = median(x) }
msemoments = mean(momentsˆ2)
msemls = mean(mlsˆ2)
Table 3.1.
R-code for comparing the moment and maximum likelihood estimators.
34. Let X1, . . . , Xn be a sample from the distribution with probability density pθ given by
pθ(x) = 1
2θe−θ|x|
for x ∈(−∞, ∞),
where θ > 0 is an unknown parameter. To determine a Bayes estimator for the parameter,
we use a gamma distribution with ﬁxed parameters r, λ > 0 as prior distribution.
(i) Suppose that we have very little prior knowledge of θ. Explain how you would choose
the parameters λ and r in this case.
(ii) Determine the Bayes estimator for θ based on this sample, for general λ and r .
35. Determine the posterior distribution and the Bayes estimator for θ based on an observation X
with negative binomial distribution with parameters r (known) and θ, with respect to a beta
prior distribution.
36. Compute the Bayes estimator for θ based on a sample X1, . . . , Xn from the U[0, θ]-
distribution with respect to a U[0, M] prior distribution.
37. Compute the Bayes estimator for θ based on an observation X from the Poisson distribution
with parameter θ with respect to a gamma distribution with parameters α and λ,
(i) for α = 1,
(ii) for general α > 0.
38. Compute the posterior distribution and Bayes estimator for θ based on a sample X1, . . . , Xn
from the distribution with probability density
pθ(x) = 2θxe−θx2
for x > 0
and 0 elsewhere, with respect to the gamma distribution with parameters α and λ.
39. Compute the posterior distribution and Bayes estimator for θ based on a sample X1, . . . , Xn
from the N(θ, 1)-distribution with respect to an N(0, τ2) prior distribution. Which estimator
do we ﬁnd as τ →∞? How can we characterize the prior distribution for τ ≈∞?
40. Let X1, . . . , Xn be a sample from a Bernoulli distribution with unknown parameter p ∈[0, 1].
We want to give a Bayesian estimate for the variance varp(Xi) = p(1 −p) with respect to a
beta(α, β) prior distribution with parameter p.
(i) Determine the posterior density for p.
(ii) Determine the Bayes estimators for p and varp(Xi).
98

3: Exercises
41. Suppose that instead of the mean square error, we use the mean absolute deviation (MAD)
to deﬁne a Bayes estimator: in Section 3.5, we replace R(π; T) with 
Eθ|T −θ| π(θ) dθ and
deﬁne a Bayes estimator to be an estimator T that minimizes this expression. Show that in
this case, the median of the posterior distribution is a Bayes estimator.
42. Let Y = f(X) be a function of a random vector X with distribution Υ, and let Q(y, B) =
P(X ∈B|Y = y) be the conditional distribution of X given Y = y. If we generate X from
Υ, compute Y = f(X), and then generate Z from the probability density Q(Y, ·), then Z has
distribution Υ.
(i) Prove this.
(ii) Apply this with f(x) = (x1, . . . , xi−1, xi+1, . . . , xm) to prove that the Gibbs sampler has
stationary density υ.
99

TWIN STUDIES
Parents with blue eyes have children with blue eyes. On the other hand, parents with
obesity do not necessarily have children with obesity. Some characteristics, like eye
color, are determined fully genetically and are ﬁxed at birth. Other characteristics, like
having obesity, are only partially genetically determined and are also inﬂuenced by
environmental factors like diet and lifestyle. Studies involving identical and fraternal
twins can provide insight into degree to which characteristics in people are determined
by genetic or environmental factors, or an interaction between the two.
Identical (monozygotic) twins occur when during the ﬁrst cell division of a
fertilized egg, two separate groups of cells form that each grow into an embryo.
Identical twins are identical genetically and therefore always have the same gender.
Fraternal (dizygotic) twins occur when the mother has a double ovulation and
both eggs are fertilized. On average, fraternal twins have 50% of their genetic
material in common; genetically, they are simply siblings. Twins usually grow up
in the same family, go to the same school, and have the same lifestyle; they are
exposed to more or less the same environmental factors. If for some characteristic,
the correlation is higher in pairs of identical twins than it is in pairs of fraternal
twins, then this diﬀerence can be attributed to the degree to which the genetic
material corresponds; indeed, the environmental factors are virtually identical. The
characteristic is therefore partially genetic. If, on the other hand, the correlations are
more or less the same (and nonzero), then the characteristic is determined mostly by
environmental factors.
The Netherlands Twin Register (see www.tweelingenregister.org/en) contains
data on twins and their family members for the sake of scientiﬁc research in the ﬁelds
of health, lifestyle, and personality. The register contains, among other things, the
heights of the twins. Based on this data, we want to obtain an indication of the degree
in which individual diﬀerences in adult height are determined genetically.
On average, men are taller than women. In doing research into the hereditary
component in height, we must therefore take the gender into account. To simplify the
notation, we restrict ourselves to male identical and fraternal twins; extending this to
female or mixed-gender twins is simple as far as the method is concerned, but greatly
complicates the notation. We denote the heights of a pair of adolescent male twins by
(X1, X2) and suppose that the heights X1 and X2 can be written as sums
X1 = μ + G1 + C + E1
X2 = μ + G2 + C + E2
of an average height μ and three random components that represent the deviation
from the average height of the male population by genetic inﬂuences (G1 and G2),
by environmental factors that the twins have in common (C), and by factors speciﬁc
to the individuals, both genetic and environmental (E1 and E2). We often assume
that the variables for the genetic, environmental, and individually speciﬁc factors
are independent from one another: (G1, G2), C, and (E1, E2) are independent. This
100

3: Twin Studies
means that we assume that there is no interaction between the environmental and
genetic factors (it is doubtful that this is true for the height).
We assume that G1 and G2 are equally distributed with expectation 0 and
unknown variance σ2
g. These variables describe the genetic factors inﬂuencing the
variation of the height. In twins, the genetic material is partially or fully equal; G1
and G2 are therefore correlated. Identical twins are genetically identical; for them,
G1 = G2 (with probability 1), and the correlation between G1 and G2 is equal to
cor(G1, G2) = 1. Fraternal twins only share part of their genes, so that G1 and
G2 are not equal to each other, but are correlated. On average, fraternal twins have
50% of their genetic material in common. Under the assumption of the additive model
given above (and a few other assumptions), we can show that in fraternal twins, the
correlation between G1 and G2 is equal to cor(G1, G2) = 1/2. The individually
speciﬁc factors E1 and E2 are assumed to be independent and equally distributed,
with expectation 0 and unknown variance σ2
e. The expectation and variance of C are
0 and σ2
c, respectively. Under the assumptions made above, X1 and X2 are equally
distributed with expectation EXi = μ and variance var Xi equal to
σ2: = var(μ + Gi + C + Ei)
= var Gi + var C + var Ei
= σ2
g + σ2
c + σ2
e,
i = 1, 2,
where the second equality holds because of the independence of the various
components.
The term h2: = var Gi/ var Xi = σ2
g/σ2 is also called the "heritability." The
heritability describes to what degree the variation in, in this case, the height of
individuals, is due to genetic diﬀerences. Heritability is at least 0 and at most 1,
because 0 ≤σ2
g ≤σ2. If the heritability of the height is equal to 1, then σ2
g = σ2 and
σ2
c and σ2
e must both equal 0. Because the expected values of C, E1, and E2 are also
equal to 0, we see that C, E1, and E2 are equal to 0 with probability 1. The variation in
the height of individuals is then completely due to genetics. If the heritability is equal
to 0, then σ2
g = 0 and G1 and G2 are equal to 0 with probability 1; the variation in
the body length of individuals is then not due to genetics at all.
The aim is to estimate h2 based on a sample of heights of identical and fraternal
twins. To do this, we ﬁrst write h2 in terms of the correlations between the heights
within pairs of identical and fraternal twins, and estimate these parameters using
the sample correlations. The correlations between the heights within both pairs of
identical and fraternal twins are equal to
cov(X1, X2)
√var X1 var X2
= cov(μ + G1 + C + E1, μ + G2 + C + E2)
√var X1 var X2
= cov(G1, G2)
σ2
+ cov(C, C)
σ2
= cov(G1, G2)
σ2
+ σ2
c
σ2 ,
where the second equality follows from the independence assumptions made earlier.
The covariance of the genetic components G1 and G2 within pairs of identical twins
101

3: Estimators
is equal to cov(G1, G2) = var G1 = σ2
g because G1 = G2 with probability 1. Within
pairs of fraternal twins, this covariance is equal to
cov(G1, G2) = cor(G1, G2)

var G1 var G2 = 1
2 var G1 = 1
2σ2
g.
It follows from these calculations that the correlations ρ1 and ρ2 between identical
and fraternal twins, respectively, are equal to
ρ1 = σ2
g
σ2 + σ2
c
σ2 ,
ρ2 = σ2
g
2σ2 + σ2
c
σ2 .
It immediately follows that ρ1 ≥ρ2, with equality if σ2
g = 0. In other words, the
correlation between the heights within pairs of identical twins is greater than or equal
to the correlation between the heights within pairs of fraternal twins. Equality occurs
only if there is no genetic inﬂuence on the variation in the heights, and the diﬀerence
is maximal if the variation in the heights is fully due to genetics, that is, if σ2
c = 0.
It follows from the expressions for the correlations ρ1 and ρ2 that the heritability
is equal to
h2 = σ2
g
σ2 = 2(ρ1 −ρ2).
To estimate h2, we can estimate ρ1 and ρ2 using their sample correlations,
rX1,X2 =
n
i=1(X1,i −X1)(X2,i −X2)
(n −1)

S2
X1

S2
X2
based on only identical and fraternal twins, respectively. In this formula, X1,i and
X2,i denote the ﬁrst and second individual of the ith pair of identical or fraternal
twins, respectively, X1 and X2 are the respective sample means of the ﬁrst and second
individuals within the pairs of identical or fraternal twins, and S2
X1 and S2
X2 are the
corresponding sample variances. Since the marginal distribution for the height of all
individuals in the data set is equal, it makes sense to replace X1 and X2 by the
average height of all individuals, both identical and fraternal twins, and both the
ﬁrst and the second individual in a pair. The same can be considered for the sample
variations in the denominator of rX1,X2. This method for estimating the heritability
has many similarities with the method of moments; namely, the unknown parameters
are found by setting a theoretical quantity, in this case the correlation, equal to the
sample value of this same quantity.
Figures 2.11 and 2.12 show the heights of identical (Figure 2.11) and fraternal
(Figure 2.12) twins set out against each other. It is clear that the correlation between
the heights within pairs of identical twins is greater than that within pairs of fraternal
twins. The sample correlations for identical twins are equal to 0.87 and 0.96 for male
and female twins, respectively, and those for fraternal twins are equal to 0.55 and
0.50 for male and female twins, respectively. The heritability is estimated to be 0.64
for men and 0.92 for women.
♭The data can be found on the book's webpage at http://www.aup.nl under twindata.
102

3: Twin Studies
Another method for estimating the heritability is the maximum likelihood
method. Assume that the heights (X1, X2) of male adult twins have a 2-dimensional
normal distribution (for information on the multi-dimensional normal distribution, see
Appendix B) with expectation vector ν = (μ, μ)T and covariance matrices Σ1 and Σ2
for identical and fraternal twins, respectively, where
Σ1 =

σ2
σ2
g + σ2
c
σ2
g + σ2
c
σ2

Σ2 =

σ2
1
2σ2
g + σ2
c
1
2σ2
g + σ2
c
σ2

with σ2 = σ2
g + σ2
c + σ2
e. The diagonal elements of the covariance matrices are equal
to the variances of X1 and X2; the other two terms are equal to the covariance of X1
and X2. The probability density of the height of a pair of twins is equal to
x →
1
2π
√
det Σ
e−1
2 (x−ν)T Σ−1(x−ν),
where x = (x1, x2)T and Σ equals Σ1 or Σ2 depending on the type of twin, while
ν = (μ, μ)T is the vector described earlier. Moreover, det Σ denotes the determinant
of Σ. We assume that the heights of diﬀerent pairs of twins are independent, so that
the likelihood is equal to a product of 2-dimensional densities and the log-likelihood
is equal to
lμ,σ2g,σ2c,σ2e(X1, . . . , Xn1, Y1, . . . , Yn2) =
−(n1 + n2) log 2π −n1
2 log(det Σ1) −n2
2 log(det Σ2)
−1
2
n1

i=1
(Xi −ν)T Σ−1
1 (Xi −ν) −1
2
n2

i=1
(Yi −ν)T Σ−1
2 (Yi −ν),
with X1, . . . , Xn1 the heights of the pairs of identical twins and Y1, . . . , Yn2 those of
the pairs of fraternal twins. So we have Xi = (Xi,1, Xi,2)T and Yi = (Yi,1, Yi,2)T
with Xi,1 and Xi,2 the heights of the ﬁrst and second individuals in the ith pair of
identical twins, and likewise for Yi. Maximizing the log-likelihood for (μ, σ2
g, σ2
c, σ2
e)
over the parameter space [0, ∞)4 gives the maximum likelihood estimates. The
heritability σ2
g/σ2 is estimated by substituting the estimates of σ2
g and σ2 in the
deﬁnition of h2: ˆh2 = ˆσ2
g/ˆσ2 = 0.61.
We can carry out the same computations for female pairs of identical and
fraternal twins. This gives an estimated heritability of 0.93. When a joint likelihood is
set up for the data on men and women, the assumption is often made that the expected
height of women is diﬀerent from that of men, but that the covariance matrices, and
therefore the heritability, are equal. Maximizing the likelihood for the height for men
and women gives an estimate of 0.79 for the heritability.
103

3: Estimators
Heritability is a measure for the variation of a characteristic within a population,
in our case height. That the heritability is large does not mean that the height is
determined completely genetically; it does mean that the variation of the height within
the population giving our data, is predominantly determined by diﬀerences in genetic
material. Environmental factors certainly inﬂuence height (see Example 1.5), but they
are probably so uniform over the population from which the data was drawn, that only
genetic diﬀerences are observable in the variation of the height.
104

4 Hypothesis Testing
4.1 Introduction
In scientiﬁc research, in the industry, and in daily life, we often want to check whether
certain questions have an aﬃrmative answer or not. Does a particular type of therapy
help? Does the age or gender of the patient play a role? Is one type of car safer than
another? Does a batch contain an excessive number of defective items? Does one type
of lamp have a longer life span than another? Does the DNA proﬁle of the suspect
correspond to the DNA proﬁle found at the crime scene? Are the log returns of stock
market values on diﬀerent days independent? Etcetera.
Answers to such questions are based on the results of experiments or studies. In
many cases, however, the results of those experiments do not lead to an unequivocal
answer. If a new form of therapy is tested on 100 patients and gives good results in
64 of them, while this only holds for 50% of the patients with the old therapy, is the
new therapy truly better than the old one, or were we just "lucky"? If 75 of the 100
patients improve, then we can no longer talk of luck, or can we? Is a sample correlation
coeﬃcient of 0.17 "signiﬁcantly" diﬀerent from 0?
The theory of testing is aimed at formalizing this type of decision-making process
where we must choose between two conﬂicting hypotheses.
105

4: Hypothesis Testing
4.2 Null Hypothesis and Alternative Hypothesis
The decision between conﬂicting hypotheses is based on a suitable statistical model
for the observation X. The hypotheses are coded in parameter values that index the
probability distributions in the statistical model. Here, we will restrict ourselves to
two hypotheses. The parameter θ belongs either to a set Θ0 corresponding to the one
hypothesis or to the complement Θ1 = Θ \ Θ0, where Θ = Θ0 ∪Θ1 is a disjoint
partition of the full parameter space Θ. We call the hypothesis H0: θ ∈Θ0 the null
hypothesis and the hypothesis H1: θ ∈Θ1 the alternative hypothesis.
In the standard approach to testing (followed by most users of statistics), the
null and alternative hypotheses are not treated symmetrically. We, in particular,
want to know whether the alternative hypothesis is correct. If the data do not give
suﬃcient indication to support this, this does not necessarily imply that the alternative
hypothesis is incorrect (and the null hypothesis correct); it is also possible that there is
not suﬃcient proof for either of the hypotheses. The statistical analysis can thus lead
to two conclusions:
- Reject H0 (and accept H1 as being correct).
- Do not reject H0 (but do not accept H0 as being correct).
The ﬁrst is a strong conclusion, the second is not truly a conclusion. The second should
be seen as the statement that more information is needed to reach a conclusion.
By basing our statements concerning the hypotheses on our observations, we can
make two types of mistakes, corresponding to mistakenly coming to one of the two
possible conclusions:
- A type I error consists of rejecting H0 when it is correct.
- A type II error consists of not rejecting H0 when it is incorrect.
A type I error corresponds to falsely choosing the strong conclusion. This is very
undesirable. A type II error corresponds to falsely choosing the weak conclusion. This
is also undesirable, but since the weak conclusion is not truly a conclusion, it is not as
bad. Because of the asymmetric handling of the hypotheses H0 and H1 when choosing
a test, we should not attach too much value to not rejecting H0. It is therefore of great
importance to choose the null hypothesis and the alternative hypothesis wisely. In
principle, we choose the statement we want to show as the alternative hypothesis. We
then argue for H0: we only reject H0 if there is strong evidence against it.
Example 4.1 Binomial test
Suppose that we wish to compare a new therapy against depression to an existing
therapy. This existing therapy is successful in only half of the cases. Let p be the
probability of success for the new therapy when applied to an arbitrary patient. Since
we are only interested in the new therapy when it is better than the old one, we
compare the unknown probability of success p of the new therapy to 0.5, the (known)
probability of success of the existing therapy. We want to "prove" that the new therapy
is better than the old one. We therefore take the statement "p > 0.5" as the alternative
hypothesis. The null and alternative hypotheses are then H0: p ≤0.5 and H1: p > 0.5.
106

4.3: Sample Size and Critical Region
When we can reject H0, we assume that the new therapy is better than the existing one.
Example 4.2 Multinomial distribution
When rolling dice that are not fair, the probabilities p1, . . . , p6 for throwing the
diﬀerent face values are not all exactly equal to 1/6. The face value thrown at
each roll X is in general multinomially distributed with parameters (1, θ), with
θ = (p1, . . . , p6). In the statistical model, we can take the parameter space for θ
equal to Θ = {(p1, p2, p3, p4, p5, p6) ∈[0, 1]6: 6
i=1 pi = 1}.
Suppose that we do not trust our opponent's dice in a game of backgammon.
We suspect that he has tampered with the probabilities of the diﬀerent outcomes.
The null hypothesis to formally test whether a die is crooked, is then H0: pi = 1/6
for i = 1, . . . , 6, and the alternative hypothesis is H1: pi = 1/6 for at least one
i ∈{1, . . ., 6}. The null hypothesis space Θ0 is then a subset of Θ consisting of
one point: Θ0 = {(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)}. When we are only interested in the
outcome consisting of the value 6, we can test the null hypothesis H0: p6 = 1/6
against H1: p6 = 1/6. In that case, the null hypothesis space is equal to Θ0 =
{(p1, p2, p3, p4, p5, 1/6) ∈[0, 1]6: 5
i=1 pi = 5/6}.
Example 4.3 Two samples
Figure 4.1 shows boxplots for the level of expression of a gene in diﬀerent types
of tumors. The samples consist of 26 and 15 tumors, respectively. The question is
whether the expression of the gene is greater in one type of tumor than in the other.
The boxplot does not directly answer this question. Although the box of the
second sample is higher than that of the ﬁrst, there is a clear overlap and the spread of
the second sample clearly lies within the spread of the ﬁrst sample. The latter may be
signiﬁcant, but may also be due to the diﬀerent sizes of the samples.
A formal test can help answer the question. A reasonable statistical model is that
the two samples X1, . . . , X26 and Y1, . . . , Y15 are independent samples from normal
distributions with respective parameters (μ, σ2) and (ν, τ 2). We want to test the null
hypothesis H0: μ = ν against the alternative hypothesis H1: μ = ν. We can take the
parameter equal to θ = (μ, ν, σ2, τ2), with parameter space Θ = R2 × (0, ∞)2. The
null hypothesis space is the subset Θ0 = {(μ, μ): μ ∈R} × (0, ∞)2.
4.3 Sample Size and Critical Region
Based on the observation X, we must decide whether there is suﬃcient evidence
against the null hypothesis H0, so that we want to reject H0 and view the statement of
the alternative hypothesis as the correct one. The values of X for which the evidence
is strong enough form the critical region K. For these values of X, we have suﬃcient
conﬁdence in the alternative hypothesis to reject H0.
107

4: Hypothesis Testing
1
2
−0.6
−0.4
−0.2
0.0
0.2
0.4
Figure 4.1. Boxplots of the measure of expression of a gene measured in two groups of 26 (on the
left) and 15 (on the right) tumors.
Deﬁnition 4.4 Statistical test
Given a null hypothesis H0, a statistical test consists of a set K of possible values
for the observation X, the critical region. Suppose that we have an observation x. If
x ∈K, we reject H0; if x /∈K, we do not reject H0.
When X = (X1, . . . , Xn) is a vector of observations, in particular, it is often
diﬃcult to decide based on X whether the statement of the alternative hypothesis can
be true. We therefore often summarize the data in a test statistic. A test statistic is
a real-valued quantity T = T (X) based on the data that gives information on the
correctness of the null and alternative hypotheses; so the test statistic does not depend
on the unknown parameter.
Example 4.5 Binomial test, continued from Example 4.1
Example 4.1 describes a test situation. We want to test whether the probability of
success p of a new therapy is higher than 0.5, the probability of success of the existing
therapy. In all, 100 patients received the new therapy. Let X be the number of patients
for whom the new therapy is successful, and assume that X has the bin(100, p)-
distribution.
It makes sense to take T (X) = X as test statistic and to choose the critical
domain of the form
K = {c, c + 1, . . . , 100},
where we still need to determine the value c. Namely, a large value of X gives an
indication that H0 may be incorrect. The value c should therefore be chosen such that
we do not have suﬃcient conﬁdence in the correctness of the statement of the null
hypothesis if x ≥c.
108

4.3: Sample Size and Critical Region
The critical region K is often of the form {x: T (x) ∈KT }, or {T ∈KT } for
short, for a test statistic T and a set KT in the codomain of T . In practice, the set KT
is often also called the critical region. How to determine the critical region K or KT
is discussed in the next section.
Example 4.6 Gauss test
Let X1, . . . , Xn be a sample from the normal distribution with unknown expectation
μ and known variance σ2. We want to test the null hypothesis H0: μ ≤μ0 against
the alternative hypothesis H1: μ > μ0, for μ0 a ﬁxed number, for example μ0 = 0.
This problem comes up, for example, with the quality control of products in a factory.
Since the manufacturer ﬁnds it too expensive to control all products, the quality is
measured for a sample. Earlier research has shown that the measure of quality is
normally distributed. The manufacturer wants to verify that the average quality of the
total production is greater than μ0. (Assuming σ2 known is unrealistic, but simpliﬁes
the example. In practice, σ2 is assumed unknown, and the t-test from Example 4.30 is
almost always used.) The average X is the maximum likelihood estimator for μ and
can therefore be used to give an idea of the correctness of the null and alternative
hypotheses. If the observed average x is greater than μ0, this indicates that the
alternative hypothesis may be true, and the greater x, the stronger this indication. We
can therefore use the average X as test statistic, and we reject H0 for large values of
this test statistic. The critical region is then of the form
K = {(x1, . . . , xn): x ≥c}
for some c. But, how large must we take c to have suﬃcient conﬁdence in the
correctness of the alternative hypothesis if x ≥c and have a suﬃciently small
probability of making a type I error?
Suppose that a statistical test has critical region K = {x: T (x) ∈KT }, where T
is a test statistic and KT is a subset of the codomain of T . The set KT depends on the
choice of the test statistic T . In general, another test statistic T ′ leads to a diﬀerent set
KT ′. However, the critical region K can be the same in both cases; the same critical
region K can correspond to two diﬀerent test statistics (see Exercise 4.10).
4.3.1 Size and Power Function
When, in testing H0: θ ∈Θ0 against H1: θ ∈Θ1, the true value of θ belongs to Θ0,
the null hypothesis is true. If in that case x ∈K, then we falsely reject H0 and make
a type I error. For a good test, the probability Pθ(X ∈K) for θ ∈Θ0 must therefore
be small. On the other hand, when the null hypothesis is false (θ ∈Θ1), we want
Pθ(X ∈K) to be large. The quality of a test can therefore be measured using the
function θ →Pθ(X ∈K).
109

4: Hypothesis Testing
Deﬁnition 4.7 Power function
The power function of a test with critical region K is
θ →π(θ; K) = Pθ(X ∈K).
We are looking for a critical region for which the power function takes on "small
values" (close to 0) when θ ∈Θ0, and "large values" (close to 1) when θ ∈Θ1.
Figure 4.2 shows the power functions of two tests (as functions of θ along the
horizontal axis), an "ideal test" with probability of both types of errors equal to 0
and a real test.
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.2. Power function of an ideal test (solid) and of a real test (dotted). The parameter
spaces under the null and alternative hypotheses (Θ0 and Θ1) are the sections of the horizontal
axis where the power function of the ideal test is equal to 0 and 1, respectively.
Deﬁnition 4.8 Size
The size of a test with critical region K with power function π(·; K) is the number
α = sup
θ∈Θ0
π(θ; K).
A test has signiﬁcance level or level α0 if α ≤α0.
The asymmetry between the two hypotheses is now made formal by an
assumption that ensures that the probability of a type I error is at most α0.
Convention 4.9
In every practical situation, we ﬁrst choose a ﬁxed number α0, the level. We then
only use tests of level α0. In other words, we only allow tests whose power function
π(·; K) under the null hypothesis is at most α0:
sup
θ∈Θ0
π(θ; K) ≤α0.
110

4.3: Sample Size and Critical Region
It seems appealing to choose the level α0 extremely small, so that making a type I
error is rare. We can only achieve this by making K very small. In that case, however,
the power function for θ ∈Θ1 also becomes small. The probability of a type II error,
Pθ(X /∈K) = 1 −π(θ; K),
θ ∈Θ1,
therefore becomes very large, which is also inadvisable. The requirements for making
both the type I and type II errors small work against each other. We do not treat the
two types of errors symmetrically; for example, we do not try to minimize the sum of
the maximum probabilities of errors of types I and II.
In practice, α0 is often chosen equal to the magical number 0.05. With this
choice, it should not surprise us that if we carry out many tests, 1 out of 20 times,
we will falsely reject the null hypothesis (making a type I error). We should, in fact,
choose α0 depending on the possible consequences of a type I error. If these are
disproportionately serious, α0 = 0.05 may be much too large.
As far are type I errors are concerned, we see Convention 4.9 as giving suﬃcient
guarantee that the probability of these is small. Many tests (possibly with diﬀerent test
statistics) will satisfy this condition. Of these tests, we prefer the test with the smallest
probability of making a type II error. How small this probability is depends on the
situation, among other things on the number of observations and the chosen level α0.
If the probability of making a type II error is too large, the test is, of course, not very
meaningful, because we then almost never reject H0 and instead choose the second,
weak (non-)conclusion.
Convention 4.10
Given the level α0, we prefer a test of level α0 with the greatest possible power
function π(θ; K) for θ ∈Θ1.
Under this assumption, for a given level α0, we prefer a test with critical region
K1 to a test with critical region K2 if both have level α0 and the ﬁrst has a greater
power function than the second for all θ ∈Θ1:
sup
θ∈Θ0
π(θ; Ki) ≤α0, i = 1, 2
and
π(θ; K1) ≥π(θ; K2),
∀θ ∈Θ1,
with strict inequality for at least one θ ∈Θ1. We call the test with critical region K1
more powerful than the test with critical region K2 in some θ ∈Θ1 if π(θ; K1) >
π(θ; K2). We call the test with critical region K1 uniformly more powerful if the
inequality holds for all θ ∈Θ1. In principle, we are now looking for the uniformly
most powerful test of level α0; this is a test whose power function (at a given level)
is maximal for all θ ∈Θ1. We are comparing two functions, and it is possible that
one test is more powerful for certain θ ∈Θ1, and the other test is more powerful for
other θ ∈Θ1. It is then not immediately clear which test we should choose. We do
not discuss this question in this book. In exceptional cases, a uniformly most powerful
test exists for all tests of level α0. There is then an absolutely best test. We will see
examples of this in Chapter 6.
111

4: Hypothesis Testing
Example 4.11 Binomial test, continued from Example 4.5
In Example 4.5, we showed that for a test statistic T (X) = X, it makes sense to take
the critical region of the form
K = {cα0, cα0 + 1, . . . , 100}.
The value cα0 must be chosen such that the size of a test is at most α0. The size of the
test is given by
α = sup
p≤0.5
Pp(X ≥cα0) = P0.5(X ≥cα0).
The supremum is taken in p = 0.5, because as a function of p, the probability
Pp(X ≥cα0) is monotonically increasing. We can prove the latter analytically with
some diﬃculty, but it is also clear intuitively. The function p →Pp(X ≥cα0) has
been drawn in Figure 4.3 for cα0 = 59.
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.3. The function p →Pp(X ≥59) for X with a bin(100, p)-distribution.
Suppose that we choose α0 = 0.05. If we take c0.05 = 59, then the size
α = P0.5(X ≥59) = 0.044 is less than α0 = 0.05, while for c0.05 = 58, the
size satisﬁes P0.5(X ≥58) = 0.067 > 0.05. For c0.05 ≤58, the test therefore
does not have level 0.05 and is therefore not admissible at this value of the level.
We must therefore choose c0.05 ≥59. As an example, Figure 4.4 shows the function
x →P0.5(X ≥x). According to Convention 4.10, we must choose the critical region
such that the power function is the greatest possible. This corresponds to choosing the
critical region as large as possible such that under H1, the probability of (correctly)
rejecting the null hypothesis, Pp(X ∈K), is the greatest possible. We therefore
choose K = {59, 60, . . ., 100}. Under all tests of the given form, this is the test
of level 0.05 with the greatest power function. The function p →Pp(X ≥59) in
Figure 4.3 is exactly the power function of this test.
If we ﬁnd 64 successes using the new therapy, then H0 is therefore rejected
at level 0.05, and the conclusion is that the new therapy has a higher probability
of success than the existing one. With 58 successes, we could not have drawn this
conclusion: H0 would then not have been rejected.
112

4.3: Sample Size and Critical Region
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.4. The function x →P0.5(X ≥x) for X binomially distributed with parameters 100
(and 0.5). This function is left continuous in points where x takes on a value in N. The dashed
horizontal line is at height 0.05.
In the case of a one-dimensional parameter θ, we speak of a one-sided null
hypothesis when the null hypothesis is of the form H0: θ ≤θ0 or H0: θ ≥θ0, where
θ0 is a ﬁxed number. The alternative hypothesis is then of the form H1: θ > θ0 or
H1: θ < θ0, respectively. We call the ﬁrst hypothesis right one-sided and the second
hypothesis left one-sided. When the null and alternative hypotheses are of the form
H0: θ = θ0 and H1: θ = θ0, respectively, we speak of a two-sided null hypothesis.
For a test statistic T , the critical region often takes on one of the following forms:
KT = {T ≥cα0},
KT = {T ≤cα0},
KT = {T ≤cα0} ∪{T ≥dα0},
for numbers cα0 and dα0 with cα0 < dα0 in the last critical region. Which form
the critical region takes on depends on the chosen hypotheses and the choice of test
statistic. The ﬁrst two forms of KT are called one-sided, the last two-sided. The
numbers cα0 and dα0 are called the critical values. If the value of the test statistic
surpasses the critical value, then the null hypothesis is rejected. Note that "to surpass"
can mean both "to be greater than" and "to be less than," depending on the context
and the test statistic. The Gauss test in Example 4.12 is an example of a test where
a one-sided null hypothesis leads to a one-sided critical region KT and a two-sided
null hypothesis leads to a two-sided critical region KT . This is, however, not true in
general; the form of the critical region depends on the hypotheses and the choice of
test statistic. In Section 4.7 (likelihood ratio tests) we see, for example, a two-sided
null hypothesis with a one-sided critical region KT .
Example 4.12 Gauss test, continued from Example 4.6
Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution, where σ2 is a known
constant. Consider the problem of testing H0: μ ≤μ0 against H1: μ > μ0, where μ0
is a ﬁxed number (for example μ0 = 0).
113

4: Hypothesis Testing
We saw in Example 4.6 that the average X might be a suitable test statistic.
However, it turns out to be better to normalize this quantity to
T = √nX −μ0
σ
,
so that under the assumption μ = μ0, the quantity T has the N(0, 1)-distribution. Both
μ0 and σ2 are known, so that T is indeed a test statistic. The test statistic T  = X leads
to another region KT ′, but to the same critical region K (see Exercise 4.10).
Large values of X (greater than μ0) and therefore of T are more probable under
H1 than under H0. After all, X is normally distributed with expectation μ and variance
σ2/n, and this distribution shifts to the right when μ increases. We therefore choose
a critical region, based on the test statistic T , of the form K =

(x1, . . . , xn): T ≥
cα0

. In the next two paragraphs, we argue that the correct choice for cα0 is the (1 −
α0)-quantile ξ1−α0 of the standard normal distribution. (We denote by ξα the number
for which Φ(ξα) = α, where Φ is the standard normal distribution function.)
According to Convention 4.9, we are looking for a test of size at most α0, that is,
(4.1)
sup
μ≤μ0
Pμ((X1, . . . , Xn) ∈K) = sup
μ≤μ0
Pμ(T ≥cα0) ≤α0.
Since √n(X −μ)/σ, when μ is the true value of the parameter, has the standard
normal distribution, we see that the probability Pμ(T ≥cα0) is equal to
Pμ
√nX −μ0
σ
≥cα0

= Pμ
√nX −μ
σ
≥cα0 + √nμ0 −μ
σ

= 1 −Φ

cα0 + √nμ0 −μ
σ

.
This probability is an increasing function of μ (which is also evident intuitively from
the fact that the normal distribution with expectation μ shifts to the right when μ
increases), so that the supremum supμ≤μ0 Pμ(T ≥cα0) is taken on at the greatest
possible value of μ, that is, μ = μ0. Condition (4.1) that the size is at most α0 reduces
to
Pμ0(T ≥cα0) ≤α0.
Since T has the standard normal distribution under the assumption that μ = μ0, it
follows that cα0 ≥ξ1−α0.
Every critical region KT = [cα0, ∞) with cα0 ≥ξ1−α0 gives a size of at
most α0. Among these tests, we are now looking for the most powerful one; see
Convention 4.10. This is, of course, the test with the largest critical region, that is,
with the smallest possible critical value cα0. In combination with the inequality of the
previous paragraph, we take cα0 = ξ1−α0. Note that the size is now exactly equal to
the level α0.
In summary, the test rejects the null hypothesis H0: μ ≤μ0 for values of
(X1, . . . , Xn) such that T = √n(X −μ0)/σ ≥ξ1−α0. This is the usual test for
this problem, the Gauss test (named after the mathematician who was one of the ﬁrst
to work with the normal distribution). The corresponding critical region is equal to
K = {(x1, . . . , xn): T ∈KT } =

(x1, . . . , xn): √nx −μ0
σ
≥ξ1−α0

.
114

4.3: Sample Size and Critical Region
The set KT is therefore equal to [ξ1−α0, ∞). Note that the resulting critical value
cα0 = ξ1−α0 does not depend on the values of μ0 and σ2. The same critical region
KT = [ξ1−α0, ∞) is found for all values of μ0 and σ2. This is the advantage of taking
the normalized T over X as test statistic. It is therefore common to use the normalized
test statistic for the Gauss test. The set KT = [ξ1−α0, ∞) is often called the critical
region of a right-sided Gauss test.
We can test the null hypothesis H0: μ ≥μ0 against the alternative hypothesis
H1: μ < μ0 analogously. We use the same test statistic T . The null hypothesis H0 is
rejected at level α0 if T = √n(X −μ0)/σ ≤ξα0 = −ξ1−α0.
The critical region for testing the null hypothesis H0: μ = μ0 against the two-
sided alternative H1: μ = μ0 at level α0 can be found by combining the critical
regions of the two one-sided tests of size α0/2 each. This leads to rejecting the null
hypothesis if √n(X −μ0)/σ ≤ξα0/2 or √n(X −μ0)/σ ≥ξ1−α0/2 or, equivalently,
if √n|X −μ0|/σ ≥ξ1−α0/2.
−3
−2
−1
0
1
2
3
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.5. Power functions as functions of μ for the two one-sided Gauss tests (dashed) and the
two-sided Gauss test (solid) for μ0 = 0 at α0 = 0.05 and n = 5.
Naturally, the value of the power function of the two-sided test is smaller than
that of the left one-sided test for μ < μ0 and smaller than that of the right one-sided
test for μ > μ0; see Figure 4.5. If we are only interested in one of these types of
alternatives, then a suitable one-sided test is preferable to a two-sided test. This can be
the case, for example, if we consider using a new production method or buying a new
machine. In such a case, we are not so much interested in whether this innovation leads
to a setback as whether we can expect an improvement. The choice between one-sided
and two-sided tests therefore depends on the practical problem. If we want to take the
idea behind "size" seriously, then we should not be inﬂuenced by the outcome of the
experiments! In particular, it would be wrong to choose a right one-sided test after it
has been established that X > μ0.
115

4: Hypothesis Testing
Above, we introduced the Gauss test using an ad hoc argument. In addition to
being intuitively reasonable, these tests are also the best possible. Indeed, we can prove
that the one-sided Gauss tests are uniformly most powerful; that is, for these tests
the power function is maximal in all possible values under the alternative hypothesis
(see Section 6.4). The two-sided Gauss test is uniformly most powerful among the
unbiased tests. Unbiased test are tests with π(θ0) ≤α0 ≤π(θ1) for all θ0 ∈Θ0 and
θ1 ∈Θ1, where α0 is the level.
Example 4.13 Binomial test, continued from Example 4.11
Example 4.11 concerns a special case of the following binomial test. Suppose that for
a ﬁxed number p0 ∈(0, 1), we want to test the null hypothesis H0: p ≤p0 against
H1: p > p0 based on a bin(n, p)-distributed observation X. We choose X itself as
test statistic and reject H0 for large values of X. The critical region is therefore of
the form {x ∈{0, 1, . . ., n}: x ≥cα0} = {cα0, . . . , n}. We choose the critical value
cα0 ∈{0, . . ., n} such that the size of the test is less than or equal to α0 and, under this
secondary condition, the power function is maximal (compare with Example 4.11).
The size of this test is equal to
α = sup
p≤p0
Pp(X ≥cα0) = Pp0(X ≥cα0),
as the probability Pp(X ≥x) is increasing in p for ﬁxed x. To make the power
function as large as possible under the alternative hypothesis, we take the critical
region as large as possible, that is, take the critical value as small as possible:
cα0 = min

t ∈{0, . . . , n}: Pp0(X ≥t) ≤α0

.
Naturally, we then have α ≤α0. Because of the jumps in the binomial distribution
function, this inequality will be strict for most values of α0.
For suﬃciently large values of n, we can approximate the probability Pp0(X ≥
t) using the normal distribution, in which case the jumps in the distribution function
of X are negligible. For the size of the binomial test, this gives
α0 ≥Pp0

X ≥cα0

= Pp0

X ≥cα0 −1
2

= Pp0

X −np0

np0(1 −p0)
≥cα0 −np0 −1
2

np0(1 −p0)

≈1 −Φ
cα0 −np0 −1
2

np0(1 −p0)
 ,
where the sign ≈is necessary because of the approximation of the binomial
distribution function by the normal distribution function and the term 1/2 in the
numerator is the continuity correction (see Appendix A). For given α0, the value of
cα0 is the smallest integer for which
(4.2)
ξ1−α0 ≤cα0 −np0 −1
2

np0(1 −p0)
.
It is evident how this one-sided test can be adapted to the case of a diﬀerent one-sided
problem, H1: p < p0, or to the two-sided problem H1: p = p0.
116

4.3: Sample Size and Critical Region
Example 4.14 Shifted exponential distribution
Let X1, . . . , Xn be a sample from the shifted exponential distribution with intensity
parameter 1 and unknown shift parameter θ ∈(−∞, ∞). The corresponding marginal
density is given by pθ(x) = eθ−x for x ≥θ and pθ(x) = 0 for x < θ. Suppose that we
wish to test the null hypothesis H0: θ ≤0 against the alternative hypothesis H1: θ > 0
at level α0. The maximum likelihood estimator for θ is given by the ﬁrst order statistic
X(1) = min{X1, . . . , Xn} (see Exercise 3.16). It makes sense to use X(1) as test
statistic T and to reject the null hypothesis for large values of T ; indeed, when T is
positive, this is an indication that the alternative hypothesis may be true. The critical
region is therefore of the form K = {(x1, . . . , xn): x(1) ≥cα0}. The next step is to
determine the critical value cα0 for which the size of the test is at most α0 and the
power function is maximal. The size of the test is given by
sup
θ≤0
Pθ((X1, . . . , Xn) ∈K) = sup
θ≤0
Pθ(X(1) ≥cα0).
For θ < cα0, the probability Pθ(X(1) ≥cα0) =

Pθ(X1 ≥cα0)
n = en(θ−cα0) is
increasing in θ. The supremum in the expression for the size of the test is taken in
θ = 0. The critical value cα0 must now satisfy the inequality e−ncα0 ≤α0, that is,
cα0 ≥−n−1 log α0. To maximize the power function, we must maximize the critical
region. It follows that cα0 = −n−1 log α0. The critical region is therefore equal to
K =

(x1, . . . , xn): x(1) ≥−1
n log α0

,
and the size of the test is exactly equal to α0. The test rejects the null hypothesis when
X(1) ≥−n−1 log α0. Note that −n−1 log α0 > 0 for α0 ∈(0, 1). Using the theory
from Chapter 6, we can prove that the test above is uniformly most powerful. This
means that for testing the null hypothesis H0: θ ≤0 against the alternative hypothesis
H1: θ > 0, for every value of θ > 0, the test above is the most powerful among all
tests of level α0.
We could, of course, have chosen another test statistic, for example the method
of moments estimator for θ, which is X −1, which leads to a diﬀerent critical region.
This test turns out to have a smaller power function for θ > 0, which is why we do not
prefer it.
4.3.2 Sample Size
The power function of a test, in general, depends strongly on the amount of available
data. Obviously, with more data, we have a greater power function. Generally, with
"inﬁnitely much data," we can obtain the ideal power function from Figure 4.2.
The null and alternative hypotheses can then be distinguished without any errors. In
practical situations, we cannot avoid type I and type II errors, but we can positively
inﬂuence the slope of the power function as in Figure 4.2 by basing the test procedure
on more data.
117

4: Hypothesis Testing
In practice, this leads to the question of the so-called minimal sample size. This is
the minimal size of the sample such that the corresponding test in a certain alternative
θ ∈Θ1 has a greater power function than a given lower bound. It is clear from this
description that the minimal sample size is only well deﬁned if both the particular
alternative θ and the desired probability of a type II error are ﬁxed, in addition, of
course, to the desired test size α. In most cases, this means that an honest statistician
will not be able to give a simple answer to the question of what a minimal sample size
is.
We illustrate this using several examples in which the computations are more or
less explicit.
Example 4.15 Gauss test, continued from Example 4.12
The Gauss test rejects the null hypothesis H0: μ ≤μ0 for values of the test statistic
T = √n(X −μ0)/σ greater than or equal to ξ1−α0; the critical region for T is
KT = [ξ1−α0, ∞). The power function of the Gauss test is the function
μ →π(μ; K) = Pμ
√nX −μ0
σ
≥ξ1−α0

= Pμ
√nX −μ
σ
≥ξ1−α0 −√nμ −μ0
σ

= 1 −Φ

ξ1−α0 −√nμ −μ0
σ

.
Using the fact that x →Φ(x) is a monotonically increasing function, and ξ1−α is
therefore decreasing in α, we deduce the following properties:
• the greater n, the greater the power function in μ > μ0 (more information is
available)
• the greater μ, the greater the power function in μ (μ lies further from the null
hypothesis)
• the greater σ, the smaller the power function in μ > μ0 (the greater spread in the
observations makes it harder to say something about their expectation)
• the greater α0, the greater the power function in μ > μ0, but also the greater the
probability of a type I error
Now, suppose that for a given level α0 and a given alternative μ > μ0, we want a
power function of at least 1 −β, that is, we want the probability of a type II error in
μ to be less than β. It follows from the formula for the power function that this is the
case provided
Φ

ξ1−α0 −√nμ −μ0
σ

≤β,
that is, provided
√nμ −μ0
σ
≥ξ1−α0 −ξβ
with β = Φ(ξβ). The minimal value of √n satisfying this condition is equal to
(ξ1−α0 −ξβ)σ/(μ−μ0). Note that all natural choices for α0 and β satisfy 1−α0 > β,
so that ξ1−α0 −ξβ is positive.
118

4.3: Sample Size and Critical Region
Example 4.16 Binomial test, continued from Example 4.13
The standard test for the null hypothesis H0: p ≤p0 based on a variable X with the
binomial distribution with parameters n and p rejects H0 for values of X in the critical
region K = {cα0, . . . , n}, where cα0 can be approximated from the equation (4.2),
cα0 −np0 −1
2

np0(1 −p0)
≈ξ1−α0.
The power function of the test is equal to the function
p →Pp(X ≥cα0) ≈1 −Φ
cα0 −np −1
2

np(1 −p)

.
This function is sketched in Figure 4.6 for n = 10 and n = 25,with α0 = 0.05 and
p0 = 1
2. It is clear that for p > 0.5, the power function for n = 25 is much greater than
that for n = 10: when we have more observations, we can better determine whether
H1 is true and reject H0 with a greater probability when H1 is true. (Note that the size
of the test for n = 25 is also slightly bigger. In both cases, we have chosen a value cα0
satisfying our two conditions.)
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.6. Power function of the test for H0: p ≤1
2 at level α0 = 0.05 based on an observation
from the binomial distribution for n = 10 (solid curve) and n = 25 (dotted curve).
The normal approximation is well suited to determine the minimal sample size
for obtaining the prescribed power function. Suppose, for example, that we wish to
test H0: p ≤1
2 against H1: p > 1
2 at level α0 = 0.05, in such a way that the power
function in p = 0.6 is at least 0.8. This leads to the system of equations
c0.05 −n0.5 −1
2

n0.5(1 −0.5)
≈ξ0.95 = 1.64,
c0.05 −n0.6 −1
2

n0.6(1 −0.6)
≤ξ0.2 = −0.84.
The equality gives c0.05 ≈n/2 + 1.64√n/2 + 1/2, and substituting this value for
c0.05 in the inequality gives √n ≥12.32 and therefore n ≥152.
119

4: Hypothesis Testing
Example 4.17 Shifted exponential distribution, continued from Example 4.14
Let X1, . . . , Xn be a sample from a shifted exponential distribution with intensity
parameter 1 and unknown shift parameter θ ∈R. In Example 4.14, we deduced that
the null hypothesis H0: θ ≤0 is rejected when X(1) ≥−n−1 log α0, with α0 the
size of the test. We can determine the minimal sample size for a power function of at
least 0.8 in θ = 0.1. By expressing the distribution function of X(1) in the marginal
distribution function (of X1), we can determine the power function for every θ,
π(θ, K) = Pθ

X(1) ≥−1
n log α0

=

Pθ

X1 ≥−1
n log α0
n
= α0enθ.
The requirement that π(0.1, K) ≥0.8 for α0 = 0.05 leads to the inequality
0.05en0.1 ≥0.80. It immediately follows that n ≥27.7.
Example 4.18 Application: contaminated pool water
The guidelines for the number of Legionella bacteria in pool water in the Netherlands
is: at most 100 colony-forming units of Legionella bacteria per liter. Because the
number of colony-forming units of bacteria cannot be determined exactly, in this
example we use as norm that the probability of more than 100 colony-forming
units of bacteria per liter should be at most 5%. In Example 3.19, we presented a
procedure that can be used to estimate the number of colony-forming units of bacteria
in (contaminated) water. Let X be the number of colony-forming units of Legionella
bacteria in a 1 liter sample of pool water. We assume that X has a Poisson distribution
with unknown parameter μ. For pμ = Pμ(X > 100), the norm can be tested formally
using the hypotheses
H0: pμ ≤0.05
and
H1: pμ > 0.05.
The probability pμ = Pμ(X > 100) is monotonically increasing in μ. We have
Pμ(X > 100) ≤0.05 for μ ≤85.05, while Pμ(X > 100) > 0.05 for μ > 85.05.
Consequently, testing these hypotheses is equivalent to testing the hypotheses
H
0: μ ≤85.05
against
H
1: μ > 85.05.
We partition the sample mixed with 100 liters of pure water over 100 Petri dishes of 1
liter each. As in Example 3.19, we deﬁne Xi as the number of colony-forming units
of bacteria in the ith liter and Yi as the variable that indicates whether a colony forms
in the ith Petri dish. We assume that the variables X1, . . . , X100 are independent and
Poisson-distributed with parameter μ/100. The variables Y1, . . . , Y100 are assumed to
be identical and have the Bernoulli distribution with parameter qμ = Pμ(Yi = 1) =
1−e−μ/100. Since qμ is monotonically increasing in μ and 1−e−85.05/100 = 0.5728,
the hypotheses H
0 and H
1 are equivalent to
H
0 : qμ ≤0.5728
and
H
1 : qμ > 0.5728.
♯Source: Decree "Besluit Hygi¨ene en Veiligheid Badinrichtingen en Zwemgelegenheden,"
January 27, 2011. In practice, things do not go exactly as described in this example; instead,
several samples are taken at diﬀerent places in the pool.
120

4.4: Testing with p-Values
This null hypothesis H
0 can be tested using the test statistic T = 100
i=1 Yi, which is
binomially distributed with parameters 100 and qμ. The null hypothesis can therefore
be tested with the one-sided binomial test, as described in Example 4.13. The normal
approximation is justiﬁed because 100 × 0.5728 × (1 −0.5728) = 24.47 > 5 (see
Appendix A). We can solve the critical value from equation (4.2). It follows that at
level α0 = 0.05, the null hypothesis H
0 is rejected when 100
i=1 Yi ≥66. When we
ﬁnd a colony in at least 66 Petri dishes, we assume qμ > 0.5728, that is, μ > 85.05
(we then also reject H
0 and accept H
1), and therefore in that case reject our initial
null hypothesis H0 and assume pμ = Pμ(X > 100) > 0.05. We conclude that the
pool water does not meet the norm when a colony forms in at least 66 Petri dishes.
4.4 Testing with p-Values
In the previous section, we described tests using test statistics and critical regions.
We can also describe tests using so-called p-values. The relation between the critical
region and p-values is as follows.
Suppose that the critical region is of the form K = {x: T (x) ≥dα0}, where the
constant dα0 is the smallest number for which a test with a critical region of this form
has level α0. In other words,
(4.3)
dα0 = min

t: sup
θ∈Θ0
Pθ(T ≥t) ≤α0

.
Often, minimizing dα0 corresponds to maximizing the power function in Θ1. The
formula is therefore a consequence of Convention 4.10. The equality (4.3) implies
that for every t ∈R,
sup
θ∈Θ0
Pθ(T ≥t) ≤α0
⇐⇒
t ≥dα0.
Deﬁnition 4.19 p-Value
For a test that rejects the null hypothesis for large values of a test statistic T and
observed value t for T , the p-value is equal to
sup
θ∈Θ0
Pθ(T ≥t).
121

4: Hypothesis Testing
−2
0
2
4
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.7. p-Value t →supμ≤μ0 Pμ(T ≥t) = Pμ0 (T ≥t) (solid curve) for the Gauss test for
H0: μ ≤μ0 with μ0 = 0. A dashed line was drawn at the level α0 = 0.05. The thick solid line
shows the corresponding critical region.
We can therefore also carry out the test as follows: when the p-value is less than
or equal to α0, we reject H0; otherwise, we do not reject H0. This rule gives exactly
the test with critical region K = {x: T (x) ≥dα0}, because the p-value is less than
or equal to α0 if and only if t ≥dα0. The above is illustrated in Figure 4.7 using
the Gauss test. It is clear in the ﬁgure that for values t in the critical region, we have
supμ≤μ0 Pμ0(T ≥t) ≤α0, and vice versa.
In words, the p-value is the maximum, under the null hypothesis, over all possible
values of the probability that an identical experiment gives a more extreme value for
the test statistic than the value t found in the experiment that has been carried out.
Having to take the supremum, under the null hypothesis, over all possibilities makes
determining the p-value somewhat complicated. In many cases, taking the supremum
is unnecessary because one of the parameters θ0 ∈Θ (often a boundary point of Θ0)
always has the maximum probability. In that case, the p-value equals Pθ0(T ≥t).
The p-value as we just deﬁned it is speciﬁc for critical regions of the form
{x: T (x) ≥dα0}. It is evident how to extend it to critical regions of the form
{x: T (x) ≤cα0}, where the assumption is now that
cα0 = max

t: sup
θ∈Θ0
Pθ(T ≤t) ≤α0

.
Deﬁnition 4.20 p-Value
For a test that rejects the null hypothesis for small values of a test statistic T and
observed value t for T , the p-value is equal to
sup
θ∈Θ0
Pθ(T ≤t).
122

4.4: Testing with p-Values
Two-sided critical regions of the form {x: T (x) ≤c} ∪{x: T (x) ≥d} often
consist of combinations of one-sided regions in the sense that c = cα0/2 and d =
dα0/2 for cα0 and dα0 as deﬁned earlier. The level α0 is then divided into two equal
parts of α0/2 each in the left and right tail. In this case, the p-value is deﬁned as
follows.
Deﬁnition 4.21 p-Value
For a test that rejects the null hypothesis for small and large values of a test statistic
T and observed value t for T , the p-value is equal to
2 min

sup
θ∈Θ0
Pθ(T ≤t), sup
θ∈Θ0
Pθ(T ≥t)

.
Again, when the p-value is less than or equal to α0, we reject H0; otherwise we
do not reject H0. This corresponds to checking whether one of the two "one-sided p-
values" is less than or equal to α0/2, since 2 min(a, b) ≤α0 if and only if a ≤α0/2
or b ≤α0/2.
Testing using p-values is often preferable to testing using a critical region because
the resulting statements gives more information. Namely, when stating the p-value, it
is also possible to still test (in a very simple way) the hypothesis against any desired
level α0, whereas when stating the critical region and the value of the test statistic for a
ﬁxed α0, this is not possible. Moreover, for example, a very small p-value immediately
tells us that H0 must clearly be rejected.
p-Values can also be deﬁned for tests with a critical region of a general form. To
emphasize this, we give the general deﬁnition, of which Deﬁnitions 4.19, 4.20, and
4.21 are examples.
Deﬁnition 4.22 p-Value
For a collection of tests that contains a test of level α for every α ∈(0, 1), the
observed signiﬁcance level or p-value is the smallest value of α for which the
corresponding test rejects H0.
Example 4.23 Binomial test, continued from Example 4.11
In Example 4.11, we concluded that in the case of 64 successes, the null hypothesis is
rejected at α0 = 0.05, while it is not rejected in the case of 58 successes. The p-values
for 64 and 58 successes are, respectively,
sup
p≤0.5
Pp(X ≥64) = P0.5(X ≥64) = 0.0033
sup
p≤0.5
Pp(X ≥58) = P0.5(X ≥58) = 0.0666.
123

4: Hypothesis Testing
The ﬁrst probability is very small and is indeed less than 0.05, and the second is greater
than 0.05. We moreover see that with 64 successes, the null hypothesis is rejected at all
levels α0 ≥0.0033. So the p-value gives more information than only the fact that the
null hypothesis is rejected at α0 = 0.05, which was the conclusion of Example 4.11.
Example 4.24 Binomial test, continued from Example 4.23
The p-value of the binomial test for the null hypothesis H0: p ≤p0, for an observed
value x, is equal to
sup
p≤p0
Pp(X ≥x) = Pp0(X ≥x).
We reject H0: p ≤p0 when this probability is less than or equal to α0.
For known p0, α0, n, and x, we can either look up the p-value in a table or
compute it using a statistical computer package. For large n, we can also apply the
normal approximation,
Pp0(X ≥x) ≈1 −Φ
 x −np0 −1
2

np0(1 −p0)

.
For the null hypothesis H0: p ≥p0, the p-value Pp0(X ≤x) can also be computed
using the normal approximation, this time with the continuity correction in the other
direction.
Example 4.25 Gauss test, continued from Example 4.12
The Gauss test rejects the null hypothesis H0: μ ≤μ0 for large values of T = √n(X−
μ0)/σ. The critical value ξ1−α0 of the test satisﬁes (4.3). For an observed value x, the
p-value of the test is therefore equal to
sup
μ≤μ0
Pμ

T ≥√nx −μ0
σ

= Pμ0

T ≥√nx −μ0
σ

= 1 −Φ
√nx −μ0
σ

.
When this probability is less than or equal to α0, the null hypothesis H0 is rejected at
level α0.
The p-value for testing the other one-sided null hypothesis H0: μ ≥μ0 against
the alternative hypothesis H1: μ < μ0 is given by the probability Pμ0(T ≤√n(x −
μ0)/σ). We reject the null hypothesis when this probability is less than or equal to α0.
The two-sided Gauss test is nothing more than the combination of the two one-
sided tests, each with level α0/2. We can therefore carry out this test by computing the
p-value of both the left-sided and the right-sided tests. The p-value of the two-sided
test is then equal to twice the minimum of the two one-sided p-values. If one of the
two p-values is less than or equal to α0/2, then the p-value of the two-sided test is less
than or equal to α0 and we reject the null hypothesis H0: μ = μ0.
124

4.4: Testing with p-Values
Example 4.26 Application: Poisson-distributed stocks
Suppose that a distribution center stocks a certain perishable product weekly to supply
diﬀerent retailers (see Example 1.4). Since the product has a limited shelf life, they do
not want to stock too much; products that are not sold are thrown out at the end of the
week. On the other hand, when too little is stocked and consumer demand is not met,
this gives dissatisfaction and a loss of clientele. The center has therefore decided to
stock a ﬁxed number of items such that the probability of having a shortage is at most
10%. However, lately, the stock has regularly been insuﬃcient to meet the demands
of the retailers. Apparently, the weekly demand has increased. We want to check this
using a statistical test.
We assume that the total weekly demand Z has a Poisson distribution with
parameter θ. If C is the number of items stocked weekly, we can determine
the maximal parameter value θ0 for which the 10% norm is satisﬁed: θ0
=
max{θ: Pθ(Z > C) ≤0.10}. To test whether the current weekly demand has
surpassed the number the purchasing policy is based on, we want to test the null
hypothesis H0: θ ≤θ0 against the alternative hypothesis H1: θ > θ0. To do this, we
register the weekly demand for n weeks. This gives observations Z1, . . . , Zn. Assume
that Z1, . . . , Zn are independent and have a Poisson distribution with parameter θ. To
test the null hypothesis, we take as test statistic T = n
i=1 Zi, which has a Poisson
distribution with parameter nθ.
We carry out the test by determining the p-value. For the observed value T = t,
the p-value is supθ≤θ0 Pθ(T ≥t) = Pθ0(T ≥t). If this p-value is less than or equal
to the chosen level α0, then the null hypothesis is rejected, and we can conclude that
the current demand is too high to meet the 10% norm with the current purchasing
policy. We can determine the p-value exactly using a statistical computer package, but
we can also approximate it. When nθ is large, the test statistic T is approximately
normally distributed with expectation and variance both equal to nθ; see Section A.7.
The p-value can then be approximated as follows:
Pθ0(T ≥t) = Pθ0
T −nθ0
√nθ0
≥t −nθ0
√nθ0

≈1 −Φ
t −nθ0
√nθ0

.
This test problem can also be approached from another direction. Suppose that
instead of registering the weekly demand, we only note whether the stock is suﬃcient
to meet it. We observe a sequence X1, . . . , Xn, where Xi = 1Zi>C is equal to 1
when the demand is higher than the number of supplied products C and equal to 0 if
the supply suﬃces. The variables X1, . . . , Xn are independent and have the Bernoulli
distribution with parameter p, where p is the probability that there is shortage during
an arbitrary week. Since we want to study whether the probability is greater than
10%, we test the null hypothesis H0: p ≤0.10 against H1: p > 0.10. As test statistic,
we take X = n
i=1Xi, which is binomially distributed with parameters n and p.
Example 4.24 describes how to determine the p-value of this test.
Which of the tests above is better? We can judge this using the power function.
The power function of the ﬁrst test, based on the Poisson(θ)-distributed quantities
Z1, . . . , Zn, is a function of θ. For the second test, based on the Bernoulli-distributed
125

4: Hypothesis Testing
85
90
95
100
105
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.8. Power function as a function of θ based on the Poisson-distributed observations
Z1, . . . , Zn (solid curve) and the Bernoulli-distributed observations X1, . . . , Xn for n = 26,
C = 100, α0 = 0.05, and θ0 = max{θ: Pθ(Z > 100) ≤0.10} = 88.35.
variables X1, . . . , Xn with distribution parameter p, the power function is, in
principle, a function of p. However, for given θ, the probability p can be computed
as follows:
p = Pθ(Xi = 1) = Pθ(Zi > C) =
∞

k=C+1
e−θ θk
k! .
We can also use this to compute the power function of the second test as a function
of θ.
Figure 4.8 shows the power functions of both tests as a function of θ for the
choice C = 100, n = 26, and α0 = 0.05. We can see that the power function of
the ﬁrst test is greater than that of the second test for values of θ under the alternative
hypothesis, that is, for θ > θ0. Based on this image, our preference would go out to the
test based on the Poisson-distributed random variables Z1, . . . , Zn. However, if there
is any doubt to the assumption that the weekly demand has a Poisson distribution, then
the binomial test is more powerful because this does not make any assumptions on the
distribution of the weekly demand. An incorrect assumption in the statistical model
may lead to a test of size greater than the desired α0.
126

4.5: Statistical Signiﬁcance
4.5 Statistical Signiﬁcance
The general set-up of the theory of testing as described above is both rather
complicated and astonishingly simple because there are only two possible decisions.
In many practical situations, the simplicity is misleading. An eﬀect is called
statistically signiﬁcant if the relevant null hypothesis is rejected at the given level.
This should be interpreted as follows: the eﬀect we observed in the data is probably
not due to random variation; if we were to repeat the entire experiment, we would
probably observe the same eﬀect. This in no way means that the "eﬀect" is practically
signiﬁcant. It is therefore conceivable that the test procedure has correctly shown
that the new therapy is better, but that the improvement is negligible. If the existing
therapy has probability of success p = 0.5 and the new one has probability of success
p = 0.500001, then we will observe this eﬀect and reject H0 provided that we have
suﬃciently many observations, but, practically speaking, it will make little diﬀerence
which therapy we follow.
Because of this, it is desirable to always supplement a test procedure that leads
to rejecting H0 with an estimation procedure that gives an indication of the size of a
possible eﬀect. The context then determines whether this eﬀect is of practical interest.
Another possibility to bridge the discrepancy between statistical and practical
signiﬁcance would be to formulate the null hypothesis diﬀerently. We could, for
example, test the null hypothesis that the diﬀerence p2 −p1 in probabilities of success
for the new and old therapies is at least 0.2, instead of the hypothesis that p2 −p1 > 0.
The value 0.2 could then express the practical signiﬁcance. In practice, however, we
are usually satisﬁed with determining a qualitative diﬀerence and test the hypothesis
H1: p2 −p1 > 0.
4.6 Some Standard Tests
In this section, we discuss several tests that are frequently used, other than the Gauss
test and binomial test. Most of these tests can be understood intuitively.
For a given test problem, the general idea is to ﬁnd a test statistic that is
"reasonable" (often based on a good estimator for the parameter) and for which we can
easily compute a critical value or p-value. For the latter, the probability distribution
of the test statistic under the ("boundary" of the) null hypothesis must be either given
in a table or computable. Often, however, the probability distribution under the null
hypothesis does not belong to the usual list of computed distributions in probability
theory. We can then introduce a new standard probability distribution and produce
tables. An alternative is to approximate the probability distribution "on-the-ﬂy" using
stochastic simulation. Let us discuss examples of both approaches.
127

4: Hypothesis Testing
We begin this section with a discussion of the two most important random
probability distributions, the chi-square and t-distributions. These families of prob-
ability distributions are both related to the normal distribution and occur both
when testing the parameters of the normal distribution and when carrying out
approximations in large samples.
4.6.1 Chi-Square and t-Distribution
The chi-square and t-distributions are continuous probability distributions whose
densities are given by relatively simple expressions. For our purpose, however, the
following structural deﬁnitions of these probability distributions are more appealing.
Deﬁnition 4.27 Chi-square distribution
A random variable W has a chi-square distribution with n degrees of freedom,
denoted by χ2
n, if W has the same distribution as n
i=1Z2
i for Z1, . . . , Zn a sample
from the N(0, 1)-distribution.
0
5
10
15
20
0.00
0.05
0.10
0.15
0.20
0.25
Figure 4.9. Densities of the χ2-distributions with 4 (solid) and 10 (dashed) degrees of freedom.
Deﬁnition 4.28 Student's t-distribution
A random variable T has a t-distribution or Student's t-distribution with n degrees
of freedom, denoted by tn, if T has the same distribution as
Z

W/n
,
for Z and W two independent random variables with the N(0, 1)- and χ2
n-
distributions, respectively.
128

4.6: Some Standard Tests
−4
−2
0
2
4
0.0
0.1
0.2
0.3
0.4
Figure 4.10. Densities of the t-distributions with 1 (dashed), 5 (dotted), and ∞(solid) degrees
of freedom.
Using standard techniques from probability theory, we can derive formulas
for the densities of chi-square and t-distributions. These expressions were used in
"classical" times to produce tables of the distribution functions. More recently, they
are the basis for the standard algorithms in statistical software. We will consider
the tables and software as given, and not discuss the exact form of the densities.
Figures 4.9 and 4.10 give a qualitative idea of the densities.
The following theorem shows why the chi-square and t-distributions are
important.
Theorem 4.29
If X1, . . . , Xn is a sample from the N(μ, σ2)-distribution, then
(i) X is N(μ, σ2/n)-distributed;
(ii) (n −1)S2
X/σ2 is χ2
n−1-distributed;
(iii) X and S2
X are independent;
(iv) √n(X −μ)/SX has the tn−1-distribution.
Proof. Statement (i) is known from probability theory: the sum of independent
normally distributed random variables is again normally distributed. For the proofs
of statements (ii) and (iii), we may, without loss of generality, assume μ = 0 and
σ2 = 1.
The joint density of the random vector X = (X1, . . . , Xn)T is then equal to
(x1, . . . , xn) →
n

i=1
1
√
2π
e−1
2 x2
i =
1
(2π)n/2 e−1
2 x2,
where x2 = n
i=1x2
i is the square of the Euclidean length of x. Deﬁne the
vector f1 = (1/√n, . . . , 1/√n) ∈Rn with f12 = 1 and extend f1 arbitrarily
to an orthonormal basis {f1, . . . , fn} of Rn. Let O be the (n × n)-matrix with rows
129

4: Hypothesis Testing
f1, . . . , fn. It immediately follows from the deﬁnition that OOT = I (with I the
identity matrix), so that OT = O−1 and O is an orthogonal matrix, OOT = OT O =
I, and consequently Ox2 = xT OT Ox = x2 for all x. Deﬁne the random vector
Y = OX. Then
Y1 = f1X = √n X,
n

i=2
Y 2
i = Y 2 −Y 2
1 = X2 −nX2 =
n

i=1
(Xi −X)2.
Statements (ii) and (iii) consequently follow if we can prove that Y1, . . . , Yn are
independent and N(0, 1)-distributed.
The distribution function of Y is given by
P(Y ≤y) =

· · ·

x:Ox≤y
1
(2π)n/2 e−1
2 x2 dx1 · · · dxn
=

· · ·

u:u≤y
1
(2π)n/2 e−1
2 u2 du1 · · · dun,
where we use the substitution Ox = u. Then x = Ox = u, and the Jacobian of
the transformation Ox = u is equal to det O = 1. It immediately follows from the last
expression that Y has the same joint density as X; that is, Y1, . . . , Yn are independent
and normally distributed with expectation 0 and variance 1.
For the proof of statement (iv), we write
√nX −μ
SX
=
√n(X −μ)/σ

(n−1)S2
X/σ2
(n−1)
.
By statement (iii), the numerator and denominator are independent of each other,
and by statements (i) and (ii) they have, respectively, an N(0, 1)-distribution and the
square root of a χ2
n−1-distribution divided by n −1. By Deﬁnition 4.28, the quotient
then has the tn−1-distribution.
The statements of Theorem 4.29 are interesting. In particular, the independence
of the sample mean and sample variance for the same data is surprising. Figure 4.11
illustrates that this property depends on the distribution of the observations: the
normal distribution has this property, while the exponential distribution does not! For
applications, the implication of statement (iv) that the distribution of √n(X −μ)/SX
does not depend on the parameter σ2 is most important for, among other things, setting
up a test. It is nice to know that this distribution is a t-distribution, so that we can refer
to standard functions or tables of this distribution. This is, however, less essential,
because we can also approximate the distribution using stochastic simulation.
Because the form of the density of Student's t-distribution is known explicitly
(determined by W. Gosset, who published his results under the pseudonym "Student"),
simulation is unnecessary. Every statistical package contains functions to compute the
distribution function and quantiles of chi-square and t-distributions numerically.
130

4.6: Some Standard Tests
-1.0
-0.5
0.0
0.5
1.0
0
1
2
3
4
5
0.5
1.0
1.5
2.0
2.5
3.0
0
2
4
6
Figure 4.11. Scatter plot of the sample mean (x-axis) against the sample variance (y-axis) for 1000
samples of size 5 from the standard normal distribution (on the left) and 1000 samples of size 10
from the exponential distribution (on the right). On the left, the two coordinates are independent;
on the right, there is a positive correlation.
4.6.2 One-Sample Tests
Given a sample X1, . . . , Xn, we often want to test whether the location of the marginal
distribution of the sample is to the left or to the right of a certain value. For the
"location," we can take, for example, the "expectation" or "median." If we also assume
that the sample comes from a normal distribution, then the well-known t-test is the
correct test for the problem when the variance is unknown. If the variance were known,
we would use the Gauss test (see Example 4.12).
Example 4.30 t-Test
Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution with μ and σ2 unknown.
We want to test H0: μ ≤μ0 against H1: μ > μ0, where μ0 is a ﬁxed number (for
example μ0 = 0). Formally, the parameter in this case is given by the pair θ = (μ, σ2),
and the null hypothesis is equal to Θ0 =

(μ, σ2): μ ≤μ0, σ2 > 0

.
Since the test statistic and the critical region K of the Gauss test from
Example 4.12 depend on σ, and this parameter is now unknown, we cannot use that
test here. A logical extension of the Gauss test is to replace σ in the deﬁnition of the
test statistic by an estimator. We use the sample standard deviation SX. This gives the
test statistic
T = √nX −μ0
SX
.
We reject the null hypothesis for large values of this variable. Since the substitution
of SX for σ also changes the distribution of this variable, it is no longer normally
distributed when μ = μ0. It is therefore not immediately clear which critical values
we should take. In the next section, we explain, using Theorem 4.29, that this must be
the (1 −α0)-quantile of the t-distribution with n −1 degrees of freedom, which we
denote by tn−1,1−α0.
131

4: Hypothesis Testing
By Convention 4.9, the critical value cα0 for ﬁnding a test of signiﬁcance level
α0 must satisfy
sup
μ≤μ0,σ2>0
Pμ,σ2
√nX −μ0
SX
≥cα0

≤α0,
for α0 the level of the test. Note that the supremum must be taken over both μ ≤μ0
and all possible values of σ2, that is, over the entire parameter space under the null
hypothesis. However, the supremum over μ (for every σ) is taken in the boundary
point μ = μ0, which is clear intuitively (but not trivial to prove), so that the inequality
reduces to
sup
σ2>0
Pμ0,σ2
√nX −μ0
SX
≥cα0

≤α0.
Now, by Theorem 4.29(iv), the distribution of √n(X −μ0)/SX under (μ0, σ2) does
not depend on (μ0, σ2) and is equal to the tn−1-distribution. It now follows from the
inequality above that cα0 ≥tn−1,1−α0. To obtain the largest possible power function,
in accordance with Convention 4.10, we choose the critical region as large as possible
and take cα0 = tn−1,1−α0. The size α of the test is then exactly equal to the level:
α = α0.
The resulting test, called the t-test or Student's t-test, states: "Reject H0 if
√n(X −μ0)/SX ≥tn−1,1−α0." The corresponding p-value for observed values x
and sx is equal to
Pμ0,σ2

T ≥√nx −μ0
sx

= P

Tn−1 ≥√nx −μ0
sx

,
where Tn−1 is a random variable with the tn−1-distribution.
Adjusting the t-test for the test problems H0: μ ≥μ0 and H0: μ = μ0 is
analogous to adjusting the Gauss test. It is important for this to know that the t-
distribution is symmetric around 0, like the normal distribution, so that tn,α =
−tn,1−α.
For small values of n (n ≤10), the tn-distribution diﬀers greatly from the normal
distribution. Using normal quantiles instead of tn−1-quantiles (that is, the Gauss test
with σ taken equal to SX) then leads to a test with a size that is much greater than
the desired size. This violates Convention 4.9. For increasing values of n, the tn-
distribution increasingly resembles the standard normal distribution, with convergence
to the normal distribution as n →∞. For n ≥20, the similarity is already good
enough that the t-test and Gauss test give practically identical results.
We have introduced the t-test using ad hoc arguments. We can, however, show
that the test is uniformly most powerful within the class of all unbiased tests (see
Section 6.4.3).
132

4.6: Some Standard Tests
The t-test is the correct test for testing the location when the observations
X1, . . . , Xn form a sample from the normal distribution. If the last assumption does
not hold, then it may be possible and desirable to transform the observations (for
example using the logarithmic function) to observations for which the normality
assumption is reasonable. An alternative is to use a test that does not require normality.
There are many examples of such tests, of which we will discuss only one.
Example 4.31 Sign test
The sign test can be applied under minimal assumptions and is therefore well suited
when the observations do not come from the normal distribution. It is a test for the
median and not for the expectation, as is the case for the Gauss test and t-test. Suppose
that we want to test whether the median μ of the distribution giving the independent
observations X1, . . . , Xn is greater than a given value μ0, that is, test H0: μ ≤μ0
against H1: μ > μ0. The test statistic is T = #(1 ≤i ≤n: Xi > μ0); we count how
many observations are greater than μ0 or, equivalently, how many diﬀerences Xi −μ0
are positive. We, in fact, apply the binomial test to the signs (positive or negative)
of the diﬀerences X1 −μ0, . . . , Xn −μ0. The test statistic is binomially distributed
with parameters n and pμ = Pμ(Xi > μ0). If the median of the distribution of the
observations is equal to μ0, then the parameters are n and 1
2. If, on the other hand, the
distribution of the observations has median μ with μ ≤μ0, then the probability pμ is
less than or equal to 1/2. The null hypothesis H0: μ ≤μ0 can therefore be tested by
testing the equivalent null hypothesis H0: pμ ≤1/2 using T . We reject H0 for large
values of T , where the critical value is determined as in Example 4.13.
* Example 4.32 Tests for σ2
Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution with μ and σ2 unknown
parameters. Consider the problem of testing H0: σ2 ≤σ2
0 against H1: σ2 > σ2
0, where
σ2
0 is a ﬁxed number. Formally, the parameter is given by the pair θ = (μ, σ2), and the
parameter space under the null hypothesis is equal to Θ0 =

(μ, σ2): μ ∈R, σ2 ≤
σ2
0

. A reasonable estimator for σ2 is the sample variance S2
X. Large values of S2
X
indicate that the alternative hypothesis might be correct. We therefore reject the null
hypothesis for large values of S2
X.
The probability distribution of (n −1)S2
X/σ2 under (μ, σ2) does not depend on
the parameter (μ, σ2), and is exactly the chi-square distribution with n −1 degrees of
freedom (see Theorem 4.29). If we denote the α-quantile of the chi-square distribution
with n−1 degrees of freedom by χ2
n−1,α, then the obvious choice for a test is: "Reject
H0 when (n −1)S2
X/σ2
0 ≥χ2
n−1,1−α0" (with α0 the level of the test). We can show
that the size of this test is α0, in the same way as in previous examples.
133

4: Hypothesis Testing
The tests for the other one-sided test problem H0: σ2 ≥σ2
0 and the two-sided test
problem H0: σ2 = σ2
0 are obvious. Note, however, that the chi-square distribution is
not symmetric and puts all probability mass on (0, ∞). There is consequently no direct
relation between the quantiles χ2
n−1,α and χ2
n−1,1−α, and we cannot use the absolute
value of the test statistic to describe the two-sided test. The two-sided test states:
"Reject H0 when (n −1)S2
X/σ2
0 ≤χ2
n−1,α0/2 or (n −1)S2
X/σ2
0 ≥χ2
n−1,1−α0/2."
We can also carry out these tests with p-values.
4.6.3 Two-Sample Tests
In the two-sample problem, we have two samples X1, . . . , Xm and Y1, . . . , Yn from
possibly diﬀerent probability distributions, and we are interested in comparing these
distributions, for example their locations. Depending on the assumptions, there exist
diﬀerent types of two-sample tests.
We can make an important distinction between tests for paired and independent
observations. In the ﬁrst case, the two samples come from a sample (X1, Y1), . . . ,
(Xn, Yn) of pairs of observations, where the X- and Y -variables in each pair may
be related, but the pairs themselves are assumed to be independent. For example,
when studying the eﬀectivity of treatment, the X might give the state of a patient
before treatment, while the Y gives the state after treatment. Since Xi and Yi are
measurements on the same patient, it is logical that they are stochastically dependent.
Indeed, a low value in the ﬁrst observation indicates that the patient is in poor health,
which makes it more probable that the second observation will also be low (with
respect to the rest of the population, though possibly higher than the ﬁrst observation
if the treatment is successful).
In the case of repeated measures on the same object or person, the dependence
of the measurements is unavoidable. In other applications, the X- and Y -components
may be intentionally chosen dependent by the set-up of the experiment. For example,
a group of subjects may be paired up using background variables such as age, gender,
prior treatment, or case history, so that the two persons in each pair are comparable
with respect to these variables. Then, one (arbitrarily chosen) person in each pair
receives the drug while the other receives a placebo. A diﬀerence in the state of the
patient after this treatment gives an indication of the eﬃcacy of the drug. The purpose
of pairing the subjects in this approach is to emphasize the eﬀect of the treatment.
Indeed, an observed diﬀerence within the pair cannot be explained by ﬂuctuations in
the background variables but must be due to the treatment (or to an as yet unknown
background variable). If we do not pair the observations, then the additional random
ﬂuctuation caused by the background variables can mask the eﬀect of the treatment.
Example 4.33 t-Test for paired observations
It seems natural to base a test for comparing the locations of two paired samples
(X1, Y1), . . . , (Xn, Yn) on the diﬀerences Zi = Xi −Yi. The t-test for pairs is the
usual t-test applied to the diﬀerences Z1, . . . , Zn.
134

4.6: Some Standard Tests
To apply the t-test, we assume that the diﬀerences Z1, . . . , Zn are independent
and N(Δ, σ2)-distributed, where the parameter Δ is equal to the diﬀerence EXi−EYi
of the expectations. Suppose that we want to test the null hypothesis H0: Δ = 0
that the treatment does not have any eﬀect, or one of the hypotheses H0: Δ ≥0 or
H0: Δ ≤0.
If all Xi and Yi are independent and have the N(μ, σ2
1)- and N(μ −Δ, σ2
2)-
distributions, respectively, then the diﬀerences Zi = Xi −Yi have the normal
distribution with expectation Δ and variance σ2 = σ2
1 + σ2
2, and we can apply the
test mentioned above. In many applications, however, the Xi and Yi will not be
independent, because they concern measurements on the same object. Fortunately,
even without that assumption, the normality and independence of the diﬀerences are
reasonable assumptions.
The power function of the t-test depends strongly on the variance σ2. If the
variance is large, then the diﬀerence in expectations is diﬃcult to detect, and the power
function of the t-test is small. A small variance is favorable and ensures a large power
function. This ﬁnding makes it clear that it can be wise to intentionally make the
samples in the two-sample problem dependent. Indeed, by the rule for the variance of
a diﬀerence, we have var Zi = var Yi + var Xi −2 cov(Xi, Yi), which is less than
var Yi + var Xi if Xi and Yi have a positive correlation. An intuitive explanation is
that taking diﬀerences eliminates random ﬂuctuations that are present in both the X-
and Y -components and do not interest us. After eliminating this variation, it is easier
to discover a possible diﬀerence caused by the treatment.
A correct application of the t-test does require that the diﬀerences Z1, . . . , Zn
may be viewed as a sample from a normal distribution.
Example 4.34 Two-sample t-test
Let X1, . . . , Xm and Y1, . . . , Yn be independent samples from, respectively, the
N(μ, σ2)- and the N(ν, σ2)-distributions. We want to carry out a one-sided test for
μ −ν > 0, that is, H0: μ −ν ≤0 against H1: μ −ν > 0. An obvious estimator for
μ−ν is the diﬀerence X −Y of the sample means. Large values of this diﬀerence are
an indication that H1 is correct. The distribution of X −Y is normal with expectation
μ −ν and variance
var(X −Y ) = var X + var Y = σ2
m + σ2
n = σ2 1
m + 1
n

because of the independence of the two samples. Because this distribution depends
on the unknown parameter σ2, we choose not X −Y as test statistic, but rather the
quantity
T =
X −Y
SX,Y

1
m + 1
n
,
where
S2
X,Y =
1
m + n −2
 m

i=1
(Xi −X)2 +
n

j=1
(Yj −Y )2
135

4: Hypothesis Testing
is an unbiased estimator for σ2 (the maximum likelihood estimator for σ2 is equal to
(m+n−2)/(m+n)S2
X,Y ; verify). If μ = ν, then T has a t-distribution with m+n−2
degrees of freedom (see the next paragraph for a deduction). As with the t-test for one
sample in Example 4.30, it suﬃces to consider the distribution of T in the boundary
point μ = ν, which must then be independent of σ2. We therefore choose the critical
value equal to tm+n−2,1−α0, and the test states: "Reject H0 when T ≥tm+n−2,1−α0."
To see that T has a t-distribution, we write it as
T =
(X −Y )/

σ2
m + σ2
n

(m+n−2)S2
X,Y /σ2
m+n−2
.
When μ = ν, the numerator of this expression has the N(0, 1)-distribution. To
determine the distribution of the denominator, we note that the sum of two independent
chi-square distributed random variables again has a chi-square distribution, with the
number of degrees of freedom equal to the sum of the numbers of degrees of freedom
of the two terms. Using Theorem 4.29, we see that (m+n−2)S2
X,Y /σ2 has a χ2
m+n−2-
distribution and is independent of X −Y . The numerator and denominator of the test
statistic are therefore independent. That T has distribution tm+n−2 when μ = ν now
follows from the deﬁnition of the t-distribution.
Tests for other one-sided and two-sided problems, and the corresponding p-
values, can be deduced in a way similar to that used for the one-sample problem.
We call the test in Example 4.34 the t-test (or Student's t-test) for two
samples. This test diﬀers essentially from the one-sample test for diﬀerences from
Example 4.33 because in that case, pairs (Xi, Yi) were deﬁned in a natural way, which
is not the case here. If the coordinates Xi and Yi in a pair (Xi, Yi) are dependent, we
may not use the two-sample t-test, or at least not with critical value tm+n−2,1−α0,
because in that case, there is no guarantee that the size is less than or equal to α0. If,
however, the pairs (X1, Y1), . . . , (Xn, Yn) and the coordinates Xi and Yi in each pair
are independent and normally distributed, then both the t-test for pairs (Example 4.33)
and the two-sample t-test (Example 4.34) have size α0 and are admissible. The two-
sample t-test is then preferable because of its larger power function. The intuitive
reason is that in the t-test for pairs, the unknown parameter σ2 is estimated using n
independent observations (the diﬀerences Zi = Xi −Yi, of which n −1 are "free,"
that is, with n −1 degrees of freedom), while S2
X,Y is based on 2n independent
observations (with 2n −2 degrees of freedom). The latter is obviously better.
In Example 4.34, we assumed that the variance σ2 is the same for both samples,
but in many practical problems, this is uncertain or not true. A more general problem
is obtained by assuming that the two samples come from the N(μ, σ2)- and N(ν, τ 2)-
distributions. We want to test the same null hypothesis H0: μ ≤ν, but now with
unknown σ2 and τ 2. This is the well-known Behrens-Fisher problem. Unlike in the
case σ2 = τ 2, where the test we just discussed is the uniformly most powerful
test among the unbiased tests, there is no absolutely best test in the situation of the
136

4.6: Some Standard Tests
Behrens-Fisher problem (whence the word "problem"). There are several reasonable
tests (for which we refer to other textbooks).
If we ignore the possible inequality of σ2 and τ 2 and apply the two-sample t-test
from Example 4.34, then the true size of the test may diﬀer greatly from the desired
size (called the nominal size in this context). Table 4.1 provides an impression of this.
The eﬀect of diﬀerent variances is relatively small when m and n are approximately
equal and not too small. (We can prove that the size converges to α0 as m = n →∞
for every σ2/τ2!) This leads to the advice to choose samples of equal size whenever
possible. This is also wise when σ2 = τ2, because the power function of the two-
sample t-test is maximal when m = n (for ﬁxed m + n).
σ2/τ2
0.2
0.5
1
2
3
m
n
5
3
0.100
0.072
0.050
0.038
0.031
15
5
0.180
0.098
0.050
0.025
0.008
7
7
0.063
0.058
0.050
0.058
0.063
Table 4.1. True size of the two-sided two-sample t-test for diﬀerent variances and nominal level
0.05.
Example 4.35 Asymptotic t-test
A correct application of the two-sample t-test from Example 4.34 requires that the
two samples be normally distributed with equal variances. If the two samples are both
suﬃciently large, then neither the normality nor the assumption that the variances are
equal is essential, provided that the test be adjusted as follows. As test statistic, we
choose
T =
X −Y

S2
X
m +
S2
Y
n
.
This variable diﬀers from the test statistic in Example 4.34 by the use of a diﬀerent
estimator for the standard deviation in the denominator.
Using the central limit theorem, Theorem A.28, we can show that under the
hypothesis μ = ν of equal expectations for the two samples, the variable T = Tm,n
converges in distribution to a standard normal distribution as m, n →∞, provided
that the variances of the two samples exist and are ﬁnite. For large values of m and n,
we can therefore test the null hypothesis H0: μ ≤ν using the test that states: "Reject
H0 when T ≥ξ1−α0."
The size of this test converges to the level α0 as m, n →∞, for every pair
of underlying distributions with ﬁnite variances. For distributions that are not too
asymmetric, we can already use this result for m = n = 20.
137

4: Hypothesis Testing
It is not always reasonable to assume that the data come from normal distribu-
tions. If there are good reasons to assume a diﬀerent parametric model, for example
exponential distributions, then this will in general lead to a diﬀerent test, because in
that case the t-test does not have the right level and may have an unnecessarily small
power function. The general methods for constructing a test, like the likelihood ratio
test from Section 4.7, suggest which test is reasonable.
It is also possible to ﬁnd correct tests that require hardly any assumptions
on the distribution. So-called distribution-free tests work for very broad classes of
distributions. The sign test from Example 4.31 belongs to this group. Below, we
discuss an example of a distribution-free two-sample test.
Example 4.36 Wilcoxon signed-rank test
Given samples X1, . . . , Xm, Y1, . . . , Yn, we deﬁne the ranks R1, . . . , Rm of the ﬁrst
sample in the total sample as the positions (or ranks) of X1, . . . , Xm after the data
X1, . . . , Xm, Y1, . . . , Yn have been sorted by size. (For example, if X1 is the fourth
smallest observation, then we set R1 = 4; if X2 is the largest, then R2 = m + n,
etc.) The test statistic of the Wilcoxon test (also called the Mann-Whitney U test)
is W = m
i=1Ri. Large values of W indicate that X1, . . . , Xm are relatively large
with respect to Y1, . . . , Yn. This leads to rejecting the null hypothesis H0 that the two
samples are identically distributed for the alternative hypothesis that the ﬁrst sample
comes from a "stochastically larger distribution" for large values of W. Of course, we
can also do a one-sided test in the other direction and do two-sided tests.
Under the null hypothesis, X1, . . . , Xm, Y1, . . . , Yn can be viewed as a sample
of size m+n from a ﬁxed (unknown) distribution. The ranks R1, . . . , Rm can then be
viewed as an arbitrary selection of m numbers out of the numbers {1, 2, . . ., m + n}.
(For simplicity, we assume that the observations are continuously distributed, so that
the ranks are well deﬁned.) The distribution of the Wilcoxon variable under the null
hypothesis is therefore independent of this distribution, and can be determined using
combinatorial arguments. This distribution has been tabulated and is available through
statistical computer packages.
4.6.4 Goodness-of-Fit Tests
Tests to check whether the distribution of an observation belongs to a certain family
are called goodness-of-ﬁt tests.
In Chapter 2, we saw how the distribution of a sample could also be evaluated
graphically, for example using a QQ-plot. It is not our intention to replace these
graphical methods by formal tests; rather, we view the tests as a supplement. The
formal set-up of testing is an advantage because of the clarity, but has the disadvantage
of only giving a yes/no answer, without giving insight into the deviation from
normality when the answer is "no." On the other hand, the method of testing is well
adapted to conﬁrming or refuting an alleged deviation in a QQ-plot objectively.
138

4.6: Some Standard Tests
Example 4.37 Application: Black-Scholes model
The Black-Scholes model for log returns on the value of shares (see Example 2.17)
says that these log returns can be viewed as independent samples from a normal
distribution. The distribution of the log returns is important both for "risk manage-
ment" and for the prices of derivatives (such as options). If we assume normality, but
in reality, the log returns have a distribution with thicker tails (many extreme values),
then someone who owns these shares runs a higher risk than was factored in, and the
option price will not be realistic. This explains the interest in testing the normality
assumption. Can we view the log returns as samples from a normal distribution, or
not?
In addition to the marginal distribution of a sample, we can also study other
aspects with the help of a test. In the case of log returns, for example, it could be
interesting to study the time dependence.
This category of tests does not ﬁt well in the general philosophy of testing
because with goodness-of-ﬁt tests we generally prefer not to reject the null hypothesis.
The null hypothesis says, for example, that the data can be viewed as a sample from
a normal distribution, and conﬁrming this null hypothesis would provide the most
information. However, the general set-up of testing does not give us this possibility:
the only possible strong conclusion is that the null hypothesis is incorrect; in the other
case, we do not obtain a strong statement. One could think that interchanging the
null and alternative hypotheses would solve the problem, for when we then reject
the null hypothesis, we would have the strong conclusion that the data comes from a
normal distribution. However, in practice, this null hypothesis will never be rejected.
In that case, the null hypothesis contains all nonnormal distributions. Every normal
distribution in the alternative hypothesis can be approximated arbitrarily closely by
a nonnormal distribution under the null hypothesis. It is consequently impossible to
make a clear distinction between the null and alternative hypotheses and draw the
strong conclusion. We therefore choose for the ﬁrst-mentioned null hypothesis that
the distribution from which the observations come is a normal distribution.
Following this course of action, it is wise to interpret the results of goodness-
of-ﬁt tests pragmatically. If, for example, the null hypothesis of normality is not
rejected, then we view this as an indication that using the normal distribution is not
unreasonable, without interpreting it as suﬃcient proof that we have normality. It is
simply impossible to show that a given distribution is correct.
Example 4.38 Kolmogorov-Smirnov test
Let X1, . . . , Xn be a sample from an unknown distribution F. We want to test the null
hypothesis H0: F = F0 that this distribution is equal to a given reference distribution
F0 against the alternative H1: F ̸= F0 that this is not the case. The distribution F0
could, for example, be the standard normal distribution.
139

4: Hypothesis Testing
The Kolmogorov-Smirnov test is based on the empirical distribution function Fn
of X1, . . . , Xn, which is deﬁned as
Fn(x) = 1
n#(Xi ≤x) = 1
n
n

i=1
1{Xi≤x}
(see Figure 4.12). The value Fn(x) is equal to the number of observations that
are less than or equal to x, divided by n. By the law of large numbers, we have
Fn(x) P→E1{X≤x} = F(x) as n →∞. For suﬃciently large values of n, the function
Fn must therefore be close to the true distribution, so close to F0 if H0 is true. The
Kolmogorov-Smirnov statistic is the maximal distance between Fn and F0,
T = sup
x∈R
Fn(x) −F0(x)
.
We reject H0: F = F0 for large values of T . We can deduce the critical value for
the test from the probability distribution of T under H0. This does not have a special
name, but it has been tabulated and is available in statistical computer programs. It
is good to know that the distribution is the same for every continuous distribution
function F0, so that one table suﬃces. For large values of n, we can also use the limit
result
lim
n→∞PF0

sup
x∈R
Fn(x) −F0(x)
 > z/√n

= 2
∞

j=1
(−1)j+1e−j2z2.
The sequence on the right can easily be computed numerically for given z.
Consequently, this equality is, in particular, useful for determining p-values.
-3
-2
-1
0
1
2
3
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.12. The empirical distribution function of a sample of size 25 from the N(0, 1)-
distribution and the actual distribution function.
140

4.6: Some Standard Tests
In many practical cases, the problem we just discussed is too simple. We often do
not want to test a simple null hypothesis H0: F = F0, but rather a hypothesis of the
form H0: F ∈

Fθ: θ ∈Θ

for a given statistical model {Fθ: θ ∈Θ

. For example,
tests whether the observations are "normally distributed" correspond to the choices
θ = (μ, σ2) ∈R × (0, ∞) and Fμ,σ2 = N(μ, σ2). An extension of the Kolmogorov-
Smirnov test statistic is
T ∗= sup
x∈R
Fn(x) −Fˆθ(x)
,
for an estimator ˆθ of θ. We again reject for large values of T ∗. Because of the
substitution of ˆθ, however, the distribution of T ∗is not equal to that of T . In general,
this distribution depends on the model we are testing, on the estimator ˆθ that is
used, and even on the true parameter θ. The distribution has been tabulated for some
special cases. In other cases, we use approximations or determine critical values using
computer simulations.
Consider, for example, the application to testing normality. It seems natural to
estimate the unknown parameter θ = (μ, σ2) using the sample mean and the sample
variance. We reject the null hypothesis of normality for large values of the statistic
(4.4)
T ∗= sup
x∈R
Fn(x) −Φ
x −X
SX
.
To determine the critical value for the test, or a p-value, we need to know the
distribution of this statistic under the assumption that the null hypothesis is correct.
Although the null hypothesis is composite, we can show that the distribution of T ∗
is the same under each element of the null hypothesis (Exercise 4.46). It is not easy
to derive an analytic expression for this distribution, but we can easily approximate
it using a simulation. We simulate a sample from the normal distribution of the same
size as the data a great number of times, for example 1000 times, and compute the
value of the Kolmogorov-Smirnov statistic T ∗for each of the 1000 samples. As an
approximation for the p-value, we then take the proportion of the 1000 values that is
greater than the value of the statistic on the actual data.
Example 4.39 Chi-square test
Let X1, . . . , Xn be a sample from an unknown distribution F. An alternative for the
Kolmogorov-Smirnov test for a simple null hypothesis, H0: F = F0 against H1: F =
F0, is the chi-square test for independence. We partition the codomain of X1 into
a number of contiguous intervals I1, I2, . . . , Ik. The number of observations in the
sample in each interval, denoted by Nj for j = 1, . . . , k, is the random variable
Nj = #(1 ≤i ≤n: xi ∈Ij).
141

4: Hypothesis Testing
Under the null hypothesis, the probability pj: = PH0(X1 ∈Ij) that an observation
Xi lies in the interval Ij follows from the distribution F0 for j = 1, . . . , k, and the
expectation of the number of observations in the interval Ij is equal to npj. The test
statistic for the chi-square tests gives a normalized measure of the diﬀerence between
the realized number of observations and the expected number of observations in the
intervals:
X2 =
k

j=1
(Nj −npj)2
npj
.
Under the null hypothesis, for ﬁxed k, X2 has approximately a chi-square distribution
with k −1 degrees of freedom. This approximation is reliable for suﬃciently large
values of n. As a rule of thumb, we use that the expected number of observations in
each interval under the null hypothesis, npj for j = 1, . . . , k, should be at least 5.
Chi-square tests are also used in other situations. In Example 4.48, we discuss another
application of a chi-square test.
Example 4.40 Autocorrelations
In Section 2.3.1, we deﬁne the sample autocorrelation coeﬃcient of order h ∈N for a
given sample X1, . . . , Xn as
ˆρX,n(h) =
n−h
i=1 (Xi+h −Xn)(Xi −Xn)
(n −h)S2
X,n
.
Here, we write ˆρX,n(h), Xn, and S2
X,n instead of ˆρX(h), X, and S2
X to emphasize the
dependence of these random variables on n. The sample autocorrelation coeﬃcient of
order h is a measure for the linear correlation between a variable Xt and a variable
Xt+h measured h "points of time" later. If the sample autocorrelation coeﬃcient takes
on values close to 0, this is an indication for (linear) time dependence.
Suppose that we want to test the null hypothesis that X1, . . . , Xn are independent
and identically distributed; then we could choose the sample autocorrelation coefﬁ-
cients ˆρX,n(h) as test statistics and reject the null hypothesis when these coeﬃcients
are too far from 0. To specify "too far from 0," we need to know the distribution of the
sample autocorrelation coeﬃcients under the assumption of independence, so that we
can deﬁne a critical region and determine p-values.
Since the sample autocorrelation coeﬃcients are a complicated function of
the variables X1, . . . , Xn and their distribution moreover depends on the marginal
distributions of the Xi, it is not easy to determine the null distribution. For large
values of n, however, we can carry out an approximation, based on the following
limit theorem. If X1, . . . , Xn is a sample from a distribution with ﬁnite fourth
moment, then for every h, the sequence √nˆρX,n(h) converges in distribution
to a standard normal distribution as n
→
∞. Moreover, the sequences for
diﬀerent values of h are asymptotically independent. In practice, we consider this
mathematical theorem justiﬁcation for viewing the sample autocorrelation coeﬃcients
√nρX,n(1), √nρX,n(2), . . . as a sequence of independent standard normal variables
142

4.7: Likelihood Ratio Tests
for large values of n and under H0. If this were true, then the test "Reject H0 when
√n|ρX,n(h)| ≥ξ1−α0/2" would have size α0. Since this approximation only holds
for large values of n, in reality, this test has size approximately α0.
We can carry out the test for every h > 0 (where the normal approximation is
only satisfactory when h is relatively small with respect to n). If we carry out the test
for k values of h, each time with size α0, then the size of all tests taken together is
approximately equal to 1−(1−α0)k. (Use the rule P(∪hAh) = 1−P(∩hAc
h) with Ah
the event that the hth test falsely rejects the null hypothesis of independence. Because
of the (asymptotic) independence of the tests, we then have P(∩hAc
h) = 
h

1 −
P(Ah)

.) For small α0, the size is then 1 −(1 −α0)k ≈kα0, so k times as large as
the size of each of the tests individually. If we want to achieve an overall size α0, then
we need to carry out the individual tests with size α0/k. In practice, we are less formal,
and make a plot of, for example, the ﬁrst 20 sample autocorrelation coeﬃcients with
horizontal lines at heights ±1.96/√n (compare with Figure 2.13). If the observations
are independent, then we expect that one of the 20 sample autocorrelation coeﬃcients,
and not signiﬁcantly more, will fall outside the horizontal strip.
If we restrict the null hypothesis to the hypothesis that X1, . . . , Xn are
independent and normally distributed, then it is possible to determine the distribution
of the sample autocorrelation coeﬃcients more precisely.
4.7 Likelihood Ratio Tests
Tests are often set up based on heuristic arguments. A few examples were discussed in
the previous section. In this section and the next, we discuss several general methods
for ﬁnding a test, beginning with the most important one, the likelihood ratio test. In
the next section, we discuss score and Wald tests.
Deﬁnition 4.41 Likelihood ratio statistic
If pθ is the probability density of a random vector X, then the likelihood ratio statistic
for testing H0: θ ∈Θ0 against H1: θ ∈Θ \ Θ0 is deﬁned as
λ(X) =
supθ∈Θ pθ(X)
supθ0∈Θ0 pθ0(X).
(Deﬁne a/b as ∞if a > 0 = b.)
143

4: Hypothesis Testing
To compute λ(X), we maximize the likelihood twice, once with the parameter
θ restricted to Θ0, and once over the full parameter space Θ. Since Θ0 is a subset of
Θ, the likelihood ratio statistic will always be greater than or equal to 1. If we denote
the usual maximum likelihood estimator by ˆθ and the maximum likelihood estimator
under the assumption that the null hypothesis H0 is correct by ˆθ0, then we can also
write the likelihood ratio statistic as
λ(X) = pˆθ(X)
pˆθ0(X).
If ˆθ ∈Θ0, then ˆθ0 = ˆθ and the likelihood ratio statistic is equal to 1. If the
numerator pˆθ(X) of λ(X) is greater than the denominator, this is an indication that
the space Θ \ Θ0 contains "more likely" parameters than the null hypothesis space
Θ0. Large values of λ(X) therefore give an indication that H1 is correct. We therefore
take a critical region of the form

λ(x) ≥cα0

. The critical value cα0 and/or p-values
can be determined from the distributions of λ(X) under every θ0 ∈Θ0.
Example 4.42 Normal distribution
The likelihood ratio statistic for testing H0: μ = μ0 against H1: μ = μ0 based on a
sample X = (X1, . . . , Xn) from the N(μ, σ2)-distribution for a known σ2 is
λn(X1, . . . , Xn) =
n
i=1(2πσ2)−1/2e−1
2 (Xi−ˆμ)2/σ2
n
i=1(2πσ2)−1/2e−1
2 (Xi−μ0)2/σ2
= exp

−
1
2σ2
n

i=1
(Xi −ˆμ)2 +
1
2σ2
n

i=1
(Xi −μ0)2
,
where ˆμ is the maximum likelihood estimator for μ, that is, ˆμ = X. It can be useful to
consider the distribution of 2 log λn instead of that of λn because twice the logarithm
of the likelihood ratio statistic is equal to
2 log λn(X1, . . . , Xn) = −1
σ2
n

i=1
(Xi −X)2 + 1
σ2
n

i=1
(Xi −μ0)2
= n
X −μ0
σ
2
.
Under H0, the variable √n(X −μ0)/σ has the N(0, 1)-distribution, so that 2 log λn
has a χ2
1-distribution (see Deﬁnition 4.27). The null hypothesis is therefore rejected
when n(X −μ0)2/σ2 ≥χ2
1,1−α0. Since (ξ1−α0/2)2 = χ2
1,1−α0, the likelihood ratio
test above is identical to the Gauss test, where H0 is rejected when |√n(X−μ0)/σ| ≥
ξ1−α0/2 (see Example 4.12).
144

4.7: Likelihood Ratio Tests
Generally, determining the distribution of the likelihood ratio statistic for every
θ0 ∈Θ0 is complicated, and approximations are used. A large sample approximation
is often possible when the observation is a vector X = (X1, . . . , Xn) consisting of
a sample X1, . . . , Xn from a distribution with (marginal) probability density pθ. The
likelihood ratio statistic then has the following form:
λn(X) =
n
i=1 pˆθ(Xi)
n
i=1 pˆθ0(Xi).
Denote by √n(Θ −θ0) the set of vectors √n(θ −θ0) as θ runs through Θ, that is,
√n(Θ −θ0) = {√n(θ −θ0): θ ∈Θ}. We assume that Θ is a subset of the Euclidean
space.
Theorem 4.43
Suppose that the map ϑ →log pϑ(x) is continuous and diﬀerentiable for all x, with
gradient ˙ϑ(x) such that  ˙ϑ(x) ≤L(x) for every ϑ in a neighborhood of a given
θ0 ∈Θ0, where L is a function with Eθ0L2(X1) < ∞. Suppose, furthermore, that
for the same θ0, the sets √n(Θ −θ0) and √n(Θ0 −θ0) converge to, respectively,
k-dimensional and k0-dimensional linear subspaces as n →∞. Finally, suppose
that the maximum likelihood estimators ˆθ0 and ˆθ under θ0 converge in probability
to θ0 and that the Fisher information matrix iϑ is invertible for all ϑ and depends
continuously on ϑ. Then, under the given θ0, we have
2 log λn(X1, . . . , Xn) ⇝χ2
k−k0
n →∞.
A "regularity condition" consisting of the diﬀerentiability of the log probability
density with respect to the parameter is essential for the result, as it was in Theorem 5.9
on the asymptotic normality of the maximum likelihood estimator. This theorem (or
Lemma 5.14) also gives suﬃcient conditions for the consistency ˆθ0 P→θ0 and ˆθ P→θ0
as n →∞. The notation
P→means "convergencein probability"; see Deﬁnition A.24.
In addition to this, Theorem 4.43 assumes that the sequences of sets √n(Θ −θ0)
and √n(Θ0 −θ0) converge to linear subspaces. This condition is usually satisﬁed if
the true parameter θ0 is not a boundary point of the parameter spaces Θ and Θ0. If this
condition is not satisﬁed, then the chi-square approach fails. The convergence should
be understood in the following sense: a sequence of sets Hn converges to a set H if
(i) every element h ∈H is the limit h = limn→∞hn of a sequence hn with hn ∈
Hn for every n;
(ii) if h = limi→∞hni for given positive integers n1 < n2 < · · · and elements
hni ∈Hni for every i, then h ∈H.
In most cases, the limit set H is exactly the set of limits h = lim hn of convergent
sequences with hn ∈Hn for every n. Below, we give two general examples, and a
concrete example to clarify the convergence.
145

4: Hypothesis Testing
For a proof of the theorem and an extension to boundary points θ0, we refer to
the book "Asymptotic statistics" written by Van der Vaart (Chapter 16, 1998).
We can extend the theorem to nonidentically distributed or dependent obser-
vations. Moreover, the assumption that the parameter space is a subspace of the
Euclidean space is unnecessary. The statement of the theorem depends only on the
"codimension" of the null hypothesis space Θ0 within Θ (the number k −k0 in the
theorem). The theorem can also be extended to testing ﬁnite-dimensional parameters
in semi-parametric models such as the Cox model in Section 7.6.
The "theorem" proposes to reject the null hypothesis at level α0 if
2 log λn(X1, . . . , Xn) ≥χ2
k−k0,1−α0.
This critical region is always one-sided, regardless of whether the null hypothesis is
one- or two-sided.
Example 4.44 Simple null hypothesis
Let θ be a one-dimensional parameter, and suppose that we want to test the simple null
hypothesis H0: θ = θ0 for a given value θ0. If θ0 is an interior point of the parameter
space Θ, then the convergence in the theorem holds with k = 1 and k0 = 0. Under
certain regularity conditions, twice the logarithm of the likelihood ratio statistic is
therefore asymptotically chi-square distributed with one degree of freedom.
It is immediately clear that k0 = 0, because Θ0 = {θ0}, so that √n(Θ0 −θ0) =
{0} for every n. Obviously, the sequence of sets {0}, {0}, {0}, . . . converges to the
zero-dimensional space {0}.
The assumption that θ0 is an interior point of Θ means that Θ −θ0 contains
a (possibly very small) open ball around 0. Then for large n, the set √n(Θ −θ0)
contains a very large ball around 0, and we can verify that this implies that the limit
of this sequence of sets is the full space R.
Example 4.45 One-dimensional restriction
Let θ = (θ1, . . . , θm) be an m-dimensional vector, and suppose that we want to
test the null hypothesis H0: θ1 = c that the ﬁrst coordinate has a certain value. The
remaining m −1 coordinates can be chosen freely in the null hypothesis. Once again,
assume that a given vector θ0 = (c, θ2
0, . . . , θm
0 ) ∈Θ0 is an interior point of the
parameter space Θ. Arguments similar to those used in the previous example make
it seem plausible that in this case, the convergence in the theorem holds with given
k = m and k0 = m −1 for the given θ0. The limit distribution of twice the logarithm
of the likelihood ratio statistic for testing the null hypothesis over the one-dimensional
parameter is therefore χ2
1 (under certain conditions).
146

4.7: Likelihood Ratio Tests
The more general form of a one-dimensional null hypothesis is H0: bT θ = c,
with b ∈Rm, c ∈R, and bT θ the inner product of b and θ. (In the previous paragraph,
b = (1, 0, . . . , 0).) In that case, there exists an orthonormal coordinate transformation
U on Θ, θ →Uθ =: ˜θ, such that ˜θ1 = btθ/b. Using this, the null hypothesis
H0: bT θ = c becomes equivalent to H0: ˜θ1 = ˜c, with ˜c = c/b. Moreover, the value
of the likelihood ratio statistic remains unchanged because, using the substitution θ →
U −1˜θ, we can write the likelihood as a function of ˜θ and the maximum likelihood
estimator for ˜θ is equal to U ˆθ. It follows that the limit distribution of 2 log λn for a
general one-dimensional restriction is the χ2
1-distribution (under certain conditions).
The likelihood ratio test is not uniformly most powerful (Deﬁnition 6.37). This
is not a deﬁciency of this test, but a consequence of the fact that for many problems,
there does not exist a uniformly most powerful test. For diﬀerent alternative values,
a diﬀerent test is most powerful each time. The likelihood ratio test is "average" for
various alternative values, but often not absolutely optimal for any single alternative
value.
Example 4.46 Normal distribution, continue from Example 4.42
Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution with known σ2. In
Example 4.42, we deduce that under the null hypothesis H0: μ = μ0, twice the
logarithm of the likelihood ratio statistic is exactly χ2
1-distributed.
The likelihood ratio statistic for testing H0: μ ≤μ0 is more complicated, and
we no longer have the convergence of the sets √n(Θ0 −θ0) in the "theorem" for
all θ0 ∈Θ0. Moreover, the asymptotic null distribution is not χ2! To see the ﬁrst
statement, we take Θ0 = (−∞, μ0]. Then √n(Θ0 −μ0) = (−∞, 0] for every n, and
this set does not converge to a linear space.
Example 4.47 Comparing two binomial probabilities
Let X and Y be independent with, respectively, the bin(m, p1)- and bin(n, p2)-
distributions. We want to test the hypothesis H0: p1 = p2 against the alternative
H1: p1 = p2. The maximum likelihood estimator for (p1, p2) without restrictions
is (ˆp1, ˆp2) = (X/m, Y/n), the vector consisting of the two maximum likelihood
estimators when we observe only X or Y . Under the null hypothesis that p = p1 = p2,
the likelihood function is
p →
m
X

pX(1 −p)m−X
n
Y

pY (1 −p)n−Y .
This is maximized by ˆp0 = (X +Y )/(m+n). The maximum likelihood estimator for
(p1, p2) under the null hypothesis is therefore (ˆp0, ˆp0). The likelihood ratio statistic
can now be computed as
λ(X, Y ) = (X/m)X(1 −X/m)m−X(Y/n)Y (1 −Y/n)n−Y
ˆpX+Y
0
(1 −ˆp0)m+n−X−Y
.
147

4: Hypothesis Testing
The "theorem" can be applied and gives a chi-square approximation with 2 −1 = 1
degree of freedom, because it is a one-dimensional restriction. We reject H0 when
2 log λ ≥χ2
1,1−α0.
Alternatives for this test are Fisher's exact test and the chi-square test; see other
textbooks for more information.
* Example 4.48 Multinomial distribution
Let Y = (Y1, . . . , Ym) be multinomially distributed with parameters (n, p1, . . . , pm).
We assume that n is known and want to test a hypothesis on the probability vector
p = (p1, . . . , pm). The likelihood function is given by
p →

n
Y1 · · · Ym

pY1
1 · · · pYm
m .
The maximum likelihood estimator for p1, · · · , pm with respect to the natural
parameter space {p ∈Rm: pi ≥0, m
i=1 pi = 1} (the "unit simplex") is equal to
ˆpi = Yi/n for i = 1, · · · , m. The log-likelihood ratio statistic for testing H0: p ∈P0
for a given subset P0 of the unit simplex is therefore
log λ(Y ) = log

n
Y1Ym
m
i=1(Yi/n)Yi
supp∈P0

n
Y1···Ym
m
i=1pYi
i
= inf
p∈P0
m

i=1
Yi log Yi
npi
.
Even for the simple null hypothesis P0 = {p0}, this statistic has a complicated
distribution. Since Y can be viewed as the sum of n independent multinomially
distributed variables with parameters 1 and p, and the probability density of Y and
the joint density of this sample are proportional, the "theorem" stated previously may
be applied. The dimension of the parameter space (the k in the theorem) is equal to
m −1 (provided that the true parameter p is an interior point of the unit simplex)
because (p1, . . . , pm) varies over an (m −1)-dimensional set.
For a simple null hypothesis, the likelihood ratio test is asymptotically equivalent
to the chi-square test of Example 4.39. To see this, we rewrite the log-likelihood ratio
statistic log λ(Y ). The Taylor approximation of f(y) = y log(y/y0) with f (y) =
log(y/y0) + 1 and f (y) = 1/y in the neighborhood of y0 give, for large n, the
approximation f(y) ≈(y −y0) + 1
2(y −y0)2/y0. This approximation applied to
every term in the sum of log λ(Y ) with y = Yi and y0 = npi gives
log λ(Y ) =
m

i=1
Yi log Yi
npi
≈
m

i=1
(Yi −npi) + 1
2
m

i=1
(Yi −npi)2
npi
= 1
2
m

i=1
(Yi −npi)2
npi
.
The last equality follows from m
i=1npi = n and m
i=1Yi = n.
148

4.7: Likelihood Ratio Tests
* Example 4.49 Application: compound Poisson process
In Example 3.22, the maximum likelihood estimator is determined for the two-
dimensional parameter (θ, μ) in the distribution for the monthly payment made by
a health insurance company. The assumption was made that the expected number of
claims and claim sizes are equal all months of the year. However, it has been theorized
that there is a diﬀerence between the expected size of the claims in the summer and in
the winter. We will test this hypothesis using the likelihood ratio test, based on the data
of n winter months and m summer months. We assume that the data from diﬀerent
months are independent.
As a model, we assume that the sizes of the claims in the summer and in
the winter have exponential distributions with unknown parameters θs and θw,
respectively. The parameter μ from the distribution of the number of claims is taken
the same in the summer and in the winter. The parameter is now three-dimensional,
(μ, θs, θw). The null hypothesis reads H0: θs = θw, and the alternative hypothesis is
H1: θs ̸= θw. The maximum likelihood estimator for the parameter can be determined
as described in Example 3.22. Under the null hypothesis, the parameter is equal to
(μ, θ0, θ0). As in Example 3.22, the log-likelihood function can be written as a sum of
terms that each depend on one of the parameters. The maximum likelihood estimator
for μ follows by maximizing the term that depends only on μ. Since this term appears
in both the log-likelihood of the full model and the log-likelihood under the null
hypothesis, this term cancels out in the log-likelihood ratio statistic. We therefore
from now on disregard the term and the estimator for μ. Under the null hypothesis, θ0
is estimated by
ˆθ0 =
n+m
i=1 Ni
n+m
i=1
Ni
j=1 Ci,j
,
where the data of all n + m months has been taken together. Without the restrictions
of the null hypothesis, the maximum likelihood estimators for θs and θw are given by
ˆθs =
n
i=1 N s
i
n
i=1
N s
i
j=1 Cs
i,j
and
ˆθw =
m
i=1 N w
i
m
i=1
N w
i
j=1 Cw
i,j
,
where the superscript s and w indicate data for the summer and winter months,
respectively. The log-likelihood ratio statistic is given by
log λn,m =
n

i=1
log
 N s
i

j=1
ˆθz
ˆθ0
e−(ˆθs−ˆθ0)Cs
i,j

+
m

i=1
log
N w
i

j=1
ˆθw
ˆθ0
e−(ˆθw−ˆθ0)Cw
i,j

.
By the previous "theorem," for large values of n and m, we know that under the null
hypothesis, the statistic 2 log λn,m has approximately a chi-square distribution with
1 degree of freedom, because we are dealing with a one-dimensional restriction (see
Example 4.45).
149

4: Hypothesis Testing
* 4.8 Score and Wald Tests
Carrying out the likelihood ratio test requires determining the maximum likelihood
estimator for the parameter, both under the null hypothesis and for the full model.
This can be demanding. The score test is an alternative that requires less computation
and has about the same quality when we have many observations.
The score function of a statistical model given by the marginal probability density
pθ is deﬁned as the gradient ˙θ(x) = ∇θ log pθ(x) of the logarithm of the marginal
probability density; see Deﬁnition 5.8. Lemma 5.10 in Chapter 5 states that, under
certain conditions, Eθ ˙θ(X) = 0 for every parameter θ. If the value ˙θ0(x) diﬀers
considerably from 0, this is an indication that θ0 is not the true value of the parameter.
This gives the principle of the score test: the null hypothesis H0: θ = θ0 is rejected
when the score function ˙θ0(x) diﬀers considerably from 0.
The question is how to quantify "considerably." We will answer this question
only in the case where X = (X1, . . . , Xn) is a sample of independent, identically
distributed variables. The probability density of X is then of the form (x1, . . . , xn) →
n
i=1pθ(xi), for pθ the (marginal) density of one observation. The score statistic for
H0: θ = θ0 is then of the form
n

i=1
˙θ0(Xi),
where ˙θ is now the score function for a single observation. The score statistic is a
sum of independent, identically distributed random vectors. Under the null hypothesis,
Eθ0 ˙θ0(X) = 0, and when n is large, the sum above has approximately a normal
distribution by the central limit theorem (Theorem A.28). This theorem implies that
under θ0,
1
√n
n

i=1
˙θ0(Xi) ⇝N(0, iθ0),
iθ0 = Eθ0 ˙θ0(Xi) ˙T
θ0(Xi)
as n →∞. The number iθ0, or the matrix iθ0 when the parameter has dimension
(which we assume to be ﬁnite) greater than one, is exactly the Fisher information,
which we will also encounter in Chapter 5. When θ is a one-dimensional real-valued
parameter, we can choose the following as test statistic:
i−1/2
θ0
1
√n
n

i=1
˙θ0(Xi)
.
We reject the null hypothesis H0: θ = θ0 when this test statistic is greater than the
(1 −α0/2)-quantile of the standard normal distribution.
When we have a k-dimensional parameter, the displayed expression is a vector.
We then choose the square of its norm as test statistic and reject the null hypothesis
H0: θ = θ0 when this quantity is greater than the (1 −α0)-quantile of the chi-square
distribution with k degrees of freedom. If n is suﬃciently large, the size of the test is
approximately equal to α0.
150

4.8: Score and Wald Tests
This gives a complete description of the score test for a simple null hypothesis.
To test a composite null hypothesis H0: θ ∈Θ0 for a given subset Θ0 ⊂Θ, we cannot
use the test in this form, because if the null hypothesis is true, we do not know the true
θ0 ∈Θ0. The score test can be extended to this case by substituting the maximum
likelihood estimator ˆθ0 for the unknown θ0 under the null hypothesis for θ. We then
use the test statistic
(4.5)
i−1/2
ˆθ0
1
√n
n

i=1
˙ˆθ0(Xi)

2
.
Under the same type of regularity conditions as those for the likelihood ratio test
(compare with Theorem 4.43), for large n, under the null hypothesis, this statistic has
approximately the chi-square distribution with k −k0 degrees of freedom, with the
same k and k0 as in Theorem 4.43. We therefore reject H0: θ ∈Θ0 if the statistic in
(4.5) is greater than the (1 −α0)-quantile of the chi-square distribution with k −k0
degrees of freedom.
We see that applying the score test for a composite null hypothesis requires
determining the maximum likelihood estimator under the null hypothesis. If the
parameter θ is partitioned as θ = (θ1, θ2) and the null hypothesis space is of the
form Θ0 = {(θ1, θ2): θ1 ∈Rk0, θ2 = 0}, then this corresponds to determining
the maximum likelihood estimator in a lower-dimensional submodel. If we set
˙θ = ( ˙θ,1, ˙θ,2), where ˙θ,i is the vector of partial derivatives of the logarithm
of the probability density with respect to the coordinates of θi, then ˆθ0 will satisfy
ˆθ0 = (ˆθ0,1, 0) for ˆθ0,1 determined by the likelihood equation
n

i=1
˙ˆθ0,1(Xi) = 0.
This is a system with number of equations equal to the dimension of θ1 in θ = (θ1, θ2).
The vector n
i=1 ˙ˆθ0(Xi) is now of the form (0, n
i=1 ˙ˆθ0,2(Xi)), and the score test
statistic (4.5) reduces to
(4.6)
1
n
 n

i=1
˙ˆθ0,2(Xi)
T 
i−1
ˆθ0

2,2
 n

i=1
˙ˆθ0,2(Xi)

.
Here, (i−1
ˆθ0 )2,2 is the relevant submatrix of the matrix i−1
ˆθ0 . (Note that the submatrix
(A−1)2,2 of an inverse matrix A−1 is not the inverse of the submatrix A2,2.) We
can interpret this quantity as a measure for the success of the maximum likelihood
estimator ˆθ0 = (ˆθ0,1, 0) in reducing the score equation n
i=1 ˙θ(Xi) for the full model
to 0. Since n
i=1 ˙ˆθ(Xi) = 0 for the maximum likelihood estimator ˆθ for the full
model, we can also view the score test statistic as a measure for the diﬀerence between
the maximum likelihood estimators under the null hypothesis and of the full model.
151

4: Hypothesis Testing
For a null hypothesis of the form H0: g(θ) = 0 for a given, general function
g: Rk →Rm, we can sometimes determine the maximum likelihood estimator ˆθ0
under H0 by using the Lagrange method. This is a general method from mathematical
analysis for determining an extremum of a function under an additional constraint.
The idea is to determine the stationary points (ˆθ0, ˆλ) of the function
(θ, λ) →
n

i=1
log pθ(Xi) + λT g(θ).
This function is the likelihood function plus a vector parameter λ ∈Rm, the
"Lagrange multiplier," times the additional constraint (g(θ) −0 = g(θ) in our
situation). By the Lagrange theorem, under certain conditions, the ﬁrst coordinate ˆθ0
of such a stationary point is the desired maximum likelihood estimator under H0.
Diﬀerentiating with respect to θ gives the stationary equation
n

i=1
˙ˆθ0(Xi) + ˙g(ˆθ0)T ˆλ = 0,
where ˙g ∈Rm×k is the gradient of g. This shows that the Lagrange multiplier
ˆλ is "proportional" to n
i=1 ˙ˆθ0(Xi), which is essentially the score test statistic. In
particular, when θ = (θ1, θ2) and g(θ) = θ2, the functional matrix is equal to (0, I)T
and we have ˆλ = n
i=1 ˙ˆθ0,2(Xi), which is essentially the test statistic (4.6). This is
probably why in econometrics, the score test is known as the Lagrange multiplier test.
As noted before, the score test can be viewed as a comparison of the maximum
likelihood estimator ˆθ0 under the null hypothesis and the maximum likelihood
estimator ˆθ for the full model. The Wald test carries out a direct comparison and can
be viewed as a third variant of the likelihood ratio test. In the case of a partitioned
parameter θ = (θ1, θ2) and a null hypothesis of the form Θ0 = {θ = (θ1, θ2): θ2 =
0}, the Wald test is based on the second component ˆθ2 of the maximum likelihood
estimator ˆθ = (ˆθ1, ˆθ2) for the full model. If ˆθ2 diﬀers too much from the maximum
likelihood estimator under the null hypothesis, which is 0, the null hypothesis is
rejected. "Too much" can be speciﬁed by referring to the limit distribution of the
maximum likelihood estimator.
More generally, the Wald test is based on the diﬀerence ˆθ −ˆθ0. If the quadratic
form
n(ˆθ −ˆθ0)T iˆθ0(ˆθ −ˆθ0)
is too great, the null hypothesis is rejected. Under the conditions of Theorem 4.43, we
can show that as n →∞, this sequence of Wald statistics converges to a chi-square
distribution with k −k0 degrees of freedom, so that the correct critical value can be
chosen from the χ2-table.
We can show that, under certain conditions, the likelihood ratio test, the score
test, and the Wald test all have approximately the same power function if the number
of observations is large. We again restrict ourselves to the case where the observation
is a vector X = (X1, . . . , Xn) of identically distributed random variables with density
pθ.
152

4.9: Multiple Testing
Theorem 4.50
Suppose that the conditions of Theorem 4.43 are satisﬁed and that, moreover, the
map ϑ →log pϑ(x) has a second derivative ¨ϑ(x) such that ¨ϑ(x) ≤L(x) for a
function L with Eθ0L2(X1) < ∞. Then, under θ0, as n →∞, we have
1
n
 n

i=1
˙ˆθ0(Xi)
T
i−1
ˆθ0
 n

i=1
˙ˆθ0(Xi)

−n(ˆθ −ˆθ0)T iˆθ0(ˆθ −ˆθ0) ⇝0,
2 log λn(X1, . . . , Xn) −n(ˆθ −ˆθ0)T iˆθ0(ˆθ −ˆθ0) ⇝0,
where the symbol "⇝" means convergence in distribution. Moreover, the sequence
n(ˆθ −ˆθ0)T iˆθ0(ˆθ −ˆθ0) converges in distribution to a chi-square distribution with
k −k0 degrees of freedom.
* 4.9 Multiple Testing
Daily, all over the world, many statistical tests are carried out, generally of size
5%. Some 1 out of 20 true hypotheses are then falsely rejected. This means that in
many statistically supported papers in medical journals, in which a 5% statistically
signiﬁcant result is standard, the claim may be unfounded (we mean 5% of the claims
in situations where there is no eﬀect; this is not the same as 5% of the papers). No one
seems worried about this.
The situation is diﬀerent when one researcher carries out a large number of tests
simultaneously. If he chooses a level of 5% for every test, then when carrying out, for
example, 1000 tests, he should expect at least 50 "signiﬁcant" results, even when in
reality there is nothing signiﬁcant to be found. Such a situation occurs, for example,
in medical image analysis if every pixel is tested to see whether the value of the image
deviates from what is normal, and in the analysis of genetic data if a large number of
genes are being studied for their inﬂuence. In all these situations, the multiple testing
is seen as a problem.
If we carry out N tests simultaneously, each of size α, then the probability that
one or more of the null hypotheses is falsely rejected is less than or equal to Nα. A
simple way to obtain an overall size of α is therefore to carry out each individual test
with size α/N. This is known as the Bonferroni correction.
The disadvantage of this simple correction is that the actual size is often much
smaller than the desired α. (The correction is very conservative.) To gain more insight,
we formalize the test problem. Suppose that we want to test the N null hypotheses
Hj
0: θ ∈Θj
0 for j = 1, . . . , N, where Θ1
0, . . . , ΘN
0 are given subsets of the parameter
set that describe the probability distribution of the observation X. To test Hj
0, we
have a test with critical region Kj, and, in a multiple test procedure, we decide to
153

4: Hypothesis Testing
reject the null hypotheses Hj
0 for which X ∈Kj. If the true parameter θ0 belongs
to Θj
0 and X ∈Kj, then we make a type I error with respect to the jth hypothesis.
In reality, every combination of correct and false null hypotheses is possible. If the
hypotheses Hj
0 for every j in a given set J ⊂{1, . . ., N} are correct, and the other
null hypotheses are incorrect, then a meaningful deﬁnition of the overall size is
sup
θ∈∩j∈JΘj
0
Pθ

X ∈∪j∈JKj
.
This is the maximal probability that we reject at least one of the correct hypotheses.
This expression is less than
sup
θ∈∩j∈JΘj
0

j∈J
Pθ

X ∈Kj
≤

j∈J
sup
θ∈Θj
0
Pθ

X ∈Kj
.
The suprema in the sum on the right-hand side are exactly the sizes of the individual
tests with critical regions Kj for the null hypotheses Hj
0. If all these tests have size
less than or equal to α, then the overall size is less than or equal to #J α ≤Nα, as
we concluded earlier.
The computation shows why the Bonferroni correction is conservative. First,
the upper bound Nα corresponds with the situation that all null hypotheses are
correct, while in reality possibly only #J hypotheses are correct. Second, and
more importantly, the upper bound is based on the inequality Pθ

X ∈∪jKj) ≤

j Pθ(X ∈Kj), which in many cases is too pessimistic: if the critical regions
overlap, then the probability of their union may be much smaller than the sum of
their probabilities. "Overlap" often arises because of "stochastic dependence"between
the tests. In image analysis, for example, data concerning diﬀerent pixels are often
dependent. Unfortunately, there is no general method for taking such dependence into
account when combining tests. The best solution is often to not combine the individual
tests, but deﬁne a new overall test.
In some cases, the stochastic independence of the tests is a reasonable assump-
tion. If the critical regions are stochastically independent, then
Pθ

X ∈∪jKj) = 1 −Pθ(X ∈∩j(Kj)c) = 1 −

j

1 −Pθ(X ∈Kj)

.
If all tests have size less than α, then for θ ∈∩jΘj
0, this expression is bounded by
1 −(1 −α)N, which is (of course) less than Nα. For small values of α, however, the
diﬀerence is very small. If we want an overall size of α0, the Bonferroni correction
suggests to take size α0/N for each test, while for independent hypotheses the
somewhat larger value 1 −(1 −α0)1/N can be taken. As N →∞, the quotient

1 −(1 −α0)1/N
/(α0/N) of these choices increases to −log(1 −α0)/α0. For
α0 = 0.05, the limit is approximately 1.025866, and the Bonferroni correction is only
2.6% greater.
154

4.9: Multiple Testing
If we carry out many tests simultaneously (for example, N ≈1000 or greater),
then controlling the size may not be very meaningful. Because the overall size is
deﬁned as the probability of at least one type I error, it is connected to preventing
all type I errors. This extreme aim will usually lead to a very small power function,
with possibly the result that no hypothesis can be rejected. Another approach is to
accept that a small number of null hypotheses will be falsely rejected if in that case at
least a reasonable number of null hypotheses are correctly rejected.
Deﬁnition 4.51 False discovery rate
The false discovery rate (FDR) is the expected proportion of falsely rejected null
hypothesis among the rejected hypotheses,
FDR(θ) = Eθ
#{j: X ∈Kj, θ ∈Θj
0}
#{j: X ∈Kj}
.
An FDR of at most 5% can be a reasonable criterion. The following procedure,
derived by Benjamini and Hochberg, is often applied to control the FDR. The
procedure is formulated in terms of the p-values Pj of the N tests.
(i) Order the p-values according to size: P(1) ≤P(2) ≤· · · ≤P(N), and let Hj
0 be
the hypothesis that corresponds with the jth order statistic P(j).
(ii) Reject all null hypotheses Hj
0 with NP(j) ≤jα.
(iii) Also reject all null hypotheses with p-value less than that of one of the null
hypotheses rejected in step (ii).
It is clear that in general, this procedure will reject more null hypotheses than the
Bonferroni method. In terms of p-values, the Bonferroni method corresponds to
rejecting the hypotheses Hj
0 with NPj ≤α, whereas the Benjamini-Hochberg
method uses an extra factor j in the equation NP(j) ≤jα in step (ii). Under certain
circumstances, however, this does not negatively inﬂuence the FDR. In particular, we
can prove that
(4.7)
FDR(θ) ≤#{j: θ ∈Θj
0}
N
α (1 + log N),
where the factor 1 + log N may be left out when the test statistics of the diﬀerent tests
are independent or have a certain form of positive dependence (see Theorem 4.52).
Without the logarithmic term, the right-hand side is certainly less than α; with the
logarithmic term, this is not always the case, but the Benjamini-Hochberg procedure
applied with the slightly smaller value α/(1 + log N) certainly gives an FDR(θ) that
is less than α.
The factor #{j: θ ∈Θj
0}/N is the proportion of correct null hypotheses among
the N hypotheses. In many applications, this proportion is close to 1. If this is not
the case, then the Benjamini-Hochberg is conservative, like the Bonferroni method. If
we knew this proportion beforehand, it would be possible to obtain an FDR close to
the nominal value α, by using the previous strategy with an adjusted value of α. This
155

4: Hypothesis Testing
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.13. Illustration of the Benjamini-Hochberg procedure for multiple tests. The points are
ordered p-values p(1) ≤p(2) ≤· · · ≤p(100) (vertical axis) set out against the numbers 1, 2, . . . , 100
(horizontal axis). The dashed curve is the line x →0.20/100x. The hypotheses corresponding
to the p-values left of the intersection point are rejected at α = 0.20. (When there are multiple
intersection points, the last upcrossing of the p-values can be taken.)
is, however, hardly a realistic situation. There do exist reﬁnements to use the data to
determine an estimate for this proportion and correct the value α using this estimate.
In the case of independent test statistics, we can, for example, replace α by
α
(1 −λ)N
#{j: Pj > λ} + 1,
λ ∈(0, 1).
The additional factor can be seen as an estimator for the inverse of the factor
#{j: θ ∈Θj
0}/N, for every ﬁxed λ, for example λ = α/(1 + α). Unfortunately, this
"adaptive" extension of the Benjamini-Hochberg procedure seems to function less
well when the tests are not independent.
For the next theorem, we assume that P1, P2, . . . , PN are random variables with
values in [0, 1] such that the distribution of Pj under a parameter θ ∈Θj
0 (for which
Hj
0 is correct) is stochastically greater than or equal to the uniform distribution; that
is, Pθ(Pj ≤x) ≤x for every x ∈[0, 1]. This last assumption implies that Pj is a
p-value for the null hypothesis Hj
0: θ ∈Θj
0, as the test with critical region {Pj ≤α}
has size Pθ(Pj ≤α) and for a valid p-value, this is less than or equal to the nominal
value α, for every α.
156

4.9: Multiple Testing
Theorem 4.52 Benjamini-Hochberg
If the distribution of Pj is stochastically greater than or equal to the uniform
distribution under every θ ∈Θj
0, then (4.7) holds. If, moreover, P1, . . . , PN are
independent or the function x →Pθ

K(P1, . . . , PN) ≥y| Pj = x

is nonincreasing
for every θ ∈Θj
0, y ∈N, and coordinate-wise decreasing function K: [0, 1]N →N,
then
(4.8)
FDR(θ) ≤#{j: θ ∈Θj
0}
N
α.
Proof. Let P
=
(P1, . . . , PN) be the vector of the p-values and K(P) =
max{j: NP(j) ≤jα}. It follows from the deﬁnition of the Benjamini-Hochberg
procedure that Hj
0 is rejected if and only if j ≤K(P). An equivalent statement is
that Hj
0 is rejected if and only if
NPj ≤K(P)α.
The FDR can therefore be written as
Eθ
#{j: Pj ≤K(P)α/N, θ ∈Θj
0}
K(P)
=

j:θ∈Θj
0
Eθ
1{Pj ≤K(P)α/N}
K(P)

.
The sum is less than or equal to the number of terms times the largest term. To
prove the diﬀerent statements, it therefore suﬃces to bound the expectation by
(α/N)(1+log N) for (4.7) and by α/N for (4.8). Since the expectation is taken under
the assumption θ ∈Θj
0, the quantity Pj is stochastically greater than a uniformly
distributed variable.
The inequality necessary for (4.7) therefore immediately follows from the ﬁrst
assertion of Lemma 4.53. Moreover, by the deﬁnition, K is a coordinate-wise
decreasing function of P1, . . . , PN. If P1, . . . , PN are independent, then it follows
that x →Pθ

K(P) ≥y| Pj = x

is decreasing in x. When P1, . . . , PN are not
independent, the assumption that the latter is decreasing in x is added to the theorem.
Consequently, the inequality necessary for (4.8) also follows from Lemma 4.53.
Lemma 4.53
Let (P, K) be a random vector with values in [0, 1]×{1, 2, . . ., N}. If the distribution
of P is stochastically greater than the uniform distribution, then for every c ∈(0, 1),
E
1{P ≤cK}
K

≤c

1 + log(c−1 ∧N)

.
If the function x →P(K ≥y| P = x) is nonincreasing for every y, then this
inequality also holds without the factor 1 + log(c−1 ∧N).
157

4: Hypothesis Testing
Proof. Since
 ∞
K (1/s2) ds = 1/K for every K > 0, we can write the left-hand side
of the lemma in the form
E
 ∞
K
1
s2 ds1{P ≤cK}
=
 ∞
0
E1{K ≤s, P ≤cK}ds
s2
≤
 ∞
0
E1{P ≤cs ∧cN}ds
s2 ≤
 ∞
0

cs ∧cN ∧1
 ds
s2 .
Here, s is the greatest integer smaller than s, and in the ﬁrst inequality we use that
K takes on its values in N. The last expression can be computed as c(1/2 + 1/3 +
· · · + 1/D) + 1/D, for D the smallest integer greater than or equal to c−1 ∧N. This
expression is bounded by c

1 + log(c−1 ∧N)

. This proves the ﬁrst assertion.
For the second assertion, we denote by u →Q(u| x) the quantile function of
the conditional distribution of K given P = x. By assumption, this conditional
distribution decreases stochastically as x increases, which implies that the correspon-
ding quantile function also decreases: Q(u| x) ≥Q(u| x) if x ≤x, for every
u ∈[0, 1].
Consider a ﬁxed value u ∈(0, 1). The function x →cQ(u| x) −x takes on the
value cQ(u| 0) ≥c1 > 0 in x = 0 and is strictly decreasing on [0, 1]. Let x∗be the
unique point where the function meets the horizontal axis or let x∗= 1 if the function
is always positive. In both cases, we have cQ(u| P) ≥cQ(u| x∗−) ≥x∗if P < x∗,
where Q(u| x∗−) = limx↑x∗Q(u| x). So the event {P ≤cQ(u| P)} is contained in
the event {P ≤x∗}. Consequently,
E
1{P ≤cQ(u| P)}
Q(u| P)

≤E
1{P ≤x∗}
Q(u| P)

≤E
1{P ≤x∗}
x∗/c

≤c.
If U is uniformly distributed on [0, 1], then the variable Q(U| x) is distributed
following the conditional distribution of K given P = x. This implies that the vector

P, Q(U| P)

, for U independent of P, follows the distribution of (P, K). If we
replace u by U on the left-hand side in the display, we therefore obtain exactly the
left-hand side of the lemma.
158

4.10: Summary
4.10 Summary
Let X be an observation with distribution Pθ that depends on an unknown parameter
θ ∈Θ. A test for the null hypothesis H0: θ ∈Θ0 against the alternative hypothesis
H1: θ ∈Θ1 = Θ\Θ0 is deﬁned by a critical region K: if X ∈K, then H0 is rejected;
if X /∈K, then H0 is not rejected.
The following concepts are important for tests:
• The critical region K is often described using a low-dimensional test statistic T =
T (X) for which K = {x: T (x) ∈KT}. The region KT is often also called the
critical region (for simplicity).
• The (statistical) power function of a test with critical region K is the function
θ →π(θ; K) = Pθ(X ∈K) = Pθ(T (X) ∈KT ).
• The size of a test with critical region K is α = supθ∈Θ0 π(θ; K). A test of level α0
has α ≤α0.
• A Type I error is a false positive: H0 is true but is rejected.
• A Type II error is a false negative: H0 is false but is not rejected.
• An ideal test has power 0 for θ ∈Θ0 and 1 for θ ∈Θ1. This test does not make
any errors, but is not realistic. The probability of a type I error is limited by the size
of the test. The probability of a type II error decreases as the sample size increases.
p-Values oﬀer an alternative for a critical region that provides more information:
• For a test K = {x: T (x) ≤cα0}, the p-value is
p = sup
θ∈Θ0
Pθ(T ≤t).
If p ≤α0, then H0 is rejected at size α0. For a test with K = {x: T (x) ≥dα0},
the p-value is deﬁned using Pθ(T ≥t). In the case of a two-sided critical region,
the p-value is
2 min

sup
θ∈Θ0
Pθ(T ≤t), sup
θ∈Θ0
Pθ(T ≥t)

.
In addition to Gauss tests, t-tests, and the binomial test, which assume a speciﬁc
distribution, there also exist the following tests, which can be applied more broadly:
• The likelihood ratio test is based on the likelihood ratio statistic
λ(X) =
supθ∈Θ pθ(X)
supθ0∈Θ0 pθ0(X).
Under certain conditions, under H0: θ = θ0, the statistic 2 log λn(X1. . . , Xn)
based on X = (X1, . . . , Xn) asymptotically has a χ2
k−k0-distribution. For large
n, the test that rejects H0: θ = θ0 when 2 log λn(X1, . . . , Xn) ≥χ2
k−k0,1−α0 has
approximately size α0.
• Nonparametric tests such as the sign test and the Wilcoxon test require few
assumptions and can therefore be applied to a broad class of distributions.
159

4: Hypothesis Testing
Exercises
1. McRonald advertises quarter pound hamburgers. The Consumers Association wants to
research whether these are eﬀectively quarter pounders. They weigh 100 products presented
as quarter pound hamburgers. Give a statistical model and describe the test problem.
2. A coﬀee shop has few clients before 10 A.M. To draw more clients, the owners consider
reducing the price of a cup of coﬀee by 50 cents before 10 A.M. Describe an experiment to
evaluate whether such a measure has eﬀect. Give the statistical model and describe the test
problem.
3. For each of the following situations, give a statistical model and describe the test problem
(null hypothesis, alternative hypothesis).
(i) A sociologist asks a large group of high school students which academic study they
will choose. They expect that a smaller percentage of girls than boys will choose
mathematics.
(ii) A political scientist assumes that there is a correlation between age and voting or not
at elections, in particular a negative correlation. He sets 10 age categories and for each
category asks 100 persons whether they will vote or not.
(iii) To measure the eﬀect of a problem session, a group of students is divided randomly
into two groups. One group only goes to the lectures, while the other goes to both the
lectures and the problem sessions. The observations consist of the exam results of both
groups.
4. Traditionally, we assume that there is a linear correlation y = α + βx1 + γx2 between the
yield y of an industrial process, the temperature x1, and the amount of added catalyst x2.
A researcher, however, believes that (within certain boundaries) the temperature does not
inﬂuence the yield. His colleague does not believe him and wants to use a statistical test to
prove that the temperature does play a role. Describe how this question ﬁts into statistical
testing (give, among other things, the statistical model and hypotheses).
5. A random number generator is supposed to produce a sequence of numbers u1, u2, . . . that
can be viewed as realizations of independent random variables with the uniform distribution
on the interval [0, 1]. It is impossible to prove that a given generator has this property, but we
can try to show, using statistical tests, that the generator does not work properly. Describe
the statistical model and the test problem. Also suggest several possible test statistics.
6. The number of clients in a shoe store on Thursdays is approximately normally distributed
with expectation 200 and standard deviation 50. By advertising in the local paper that is
published on Wednesdays, the store owner hopes to increase the number of clients.
(i) What conclusion can the store owner draw if the average number of clients on four
Thursdays (after the ads appear) is (a) 239 (b) 264? Which assumptions were made?
(ii) The store owners knows that to cover the costs of the ads, he needs 20 additional
clients. Answer the same questions as above with this new aim in mind.
7. According to the packaging, a jar of face cream contains 50 grams of cream. To see whether
the manufacturer puts enough cream in each jar, the contents of 100 jars are weighed. The
average content turns out to be 49.82 grams. The variance when the jars were ﬁlled is
supposed to be 1. Give a statistical model and describe the test problem. Use a suitable
test to check whether the manufacturer complies with the requirement. Take α0 = 0.05.
160

4: Exercises
8. Let X1, . . . , X25 be a sample from the N(μ, 4)-distribution. We want to test the null hypothesis
H0: μ ≤0 against H1: μ > 0 at level α0 = 0.05. The observed sample mean is 0.63.
(i) Determine the critical region of a suitable test.
(ii) Should H0 be rejected?
(iii) Determine the power function of the test in μ = 1/2.
(iv) Determine the p-value of this test.
9. Let X1, . . . , X100 be independent, N(μ, 25)-distributed random variables. We want to test the
the null hypothesis H0: μ = 0 against H1: μ = 0 at level α0 = 0.05. We ﬁnd x = −1.67.
(i) Use a suitable test to determine whether H0 should be rejected.
(ii) Determine the p-value.
10. Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution with μ unknown and σ2 > 0
known. Consider the test problem H0: μ ≤μ0 against H1: μ > μ0, where μ0 is a ﬁxed number.
Suppose that, in contrast to Example 4.12, we take X as test statistic.
(i) Show that the critical region K = {(x1, . . . , xn): x ≥ξ1−α0σ/√n+ μ0} gives a test of size
α0.
(ii) Show that the critical region K from the previous part is equal to the critical region
based on the test statistic √n(X −μ0)/σ given in Example 4.12.
11. Someone pretends to have telepathic gifts in the sense that if you randomly draw one card
from a set with as many red as black cards, he has probability 0.6 of naming the correct
color instead of probability 0.5. To test this, we proceed as follows: we let him guess 25
consecutive times, where the drawn card is put back every time. If he guesses correctly at
least 17 times, we believe him; otherwise, we do not.
(i) Reword this problem in terms of null hypothesis, test statistic, alternative hypothesis,
critical region.
(ii) Determine the size of this test.
(iii) Determine the power function in p = 0.6.
(iv) He guesses correctly 16 times. What is the p-value?
(v) Do we reject H0 at level α0 = 0.05? And at level α0 = 0.10?
12. The random variables X1, . . . , X25 are independent and have the Bernoulli distribution with
parameter p. We want to test the null hypothesis H0: p ≤0.6 against H1: p > 0.6 at level
α0 = 0.05. As test statistic, we take X = 
Xi.
(i) Determine the critical region of the (right one-sided) test.
(ii) Compute the power function by approximation in p = 0.6, 0.7, 0.8, 0.9, and sketch the
graph of the power function. (The rule of thumb for the approximation is not satisﬁed
for p = 0.8 and p = 0.9, but in this exercise and for sketching the graph, we can still
use the approximation.)
(iii) Compute the size of the test.
13. Suppose that in Example 4.11, we choose a test with a critical region of the form K =
{e, e + 1, . . . , 98}.
(i) Determine e such that α ≤0.05.
(ii) Compare the power function of this test with that of the test with critical region
{59, 60, . . . , 100}.
161

4: Hypothesis Testing
14. According to the polls, during an election, political party A should receive 3.5% of all votes.
We think that this is an overestimate. To study this, we ask 250 randomly chosen voters
which party they will vote for. We denote by X the number of followers of party A. In our
sample, x = 5 persons are followers of party A.
(i) Give a statistical model for this situation.
(ii) Determine a suitable null hypothesis.
(iii) Give (an approximation for) the critical region for X at level α0 = 0.05. Test the null
hypothesis from the previous part and give your conclusion.
(iv) Give (an approximation for) the power function in 0.025 corresponding with your
answer to part (iii).
(v) How could we increase the power function in part (iv)?
15. To test the hypothesis H0: p ≤0.5 that a Bernoulli experiment is unbiased, we carry out a
series of n of these experiments, independently from one another, and use the standard test
at level 5%. How large must we at least take n for the power function in p = 0.6 to be at
least 0.9?
16. Let X1, . . . , Xn be a sample from the N(μ, 4)-distribution. We want to test the null hypothesis
H0: μ ≥1 against H1: μ < 1 at level α0 = 0.05. Since in this case, it is very important to
actually reject H0 if μ = 0, we want to choose n such that in the Gauss test, the probability
of a type II error in μ = 0 is at most 0.1. How large must n at least be?
17. To study whether the majority of the inhabitants of the Netherlands go abroad for the summer
holidays, we ask n randomly chosen inhabitants where they are going on vacation next
summer. We denote by X the number of persons in our sample who are going on vacation
abroad. Based on this data, we want to test the null hypothesis H0: p ≤0.5 against the
alternative hypothesis H1: p > 0.5. How large must n at least be chosen to obtain a power
function in p = 0.6 of at least 95% at level α0 = 0.05.
18. We want to know what percentage of the pieces in bags of candy are red, that is, the
probability that a randomly chosen piece of candy from a randomly chosen bag is red. We
take a sample of 30 bags of candy, each with 60 pieces. Let Yi be the number of red pieces in
the ith bag (i = 1, . . . , 30). Assume that Y1, . . . , Y30 are independent and that Yi is binomially
distributed with parameters 60 and p, with p the proportion of red pieces of candy in the
bag.
(i) Determine the maximum likelihood estimator for p.
(ii) Of the total 1800 pieces of candy, 342 are red. Test the hypothesis H0: p = 0.2 against
H1: p = 0.2.
19. Let X be a variable with the bin(25, p)-distribution. We want to test H0: p ≥0.4 against
H1: p < 0.4. If we want a power function of at least 0.6 in p = 0.3, how large must we at
least choose the size of the test? Is this satisfactory?
20. A new vaccine for a virus for which there was no vaccine must be tested. Because the illness
is in general not very serious, 1000 volunteers are given the virus. The vaccine is deemed
successful if it protects in 90% of the cases.
(i) Give a statistical model and the corresponding test problem.
(ii) If the experiment gives a p-value of 0.25, what does that mean?
(iii) The researchers do not ﬁnd a p-value of 0.25 suﬃciently convincing to recommend the
vaccine for regular use; do you agree or disagree with this conclusion?
162

4: Exercises
21. A manufacturer studies the life span of two types of ﬂuorescent tubes, type A and type B. In
an oﬃce building, a large number of ﬂuorescent tubes are placed in pair. Each pair consists
of a tube of type A and a tube of type B. The tubes in each pair are switched on and oﬀat the
same time. The manufacturer wants to study which type of ﬂuorescent tube has the longest
life span. The observations are (X1, Y1), . . . , (Xn, Yn), where for the ith pair, Xi is the life span
of the ﬂuorescent tube of type A and Yi is that of the tube of type B. Two statisticians analyze
the observed values using a statistical test.
(i) The ﬁrst statistician deﬁnes Wi as equal to 1 if Xi ≥Yi and 0 otherwise. Then
W1, . . . , Wn are independent and Bernoulli-distributed with parameter p = Pp(Xi ≥
Yi) = Pp(Xi −Yi ≥0). He tests the null hypothesis H0: p = 1/2 against H1: p = 1/2.
Describe a suitable test based on W1, . . . , Wn; give a test statistic and an (approximate)
critical region. Explain how you have arrived at the critical region. Take α0 as the size
of the test.
(ii) The second statistician looks at the diﬀerences Zi = Xi −Yi, i = 1, 2, . . . , n and assumes
that Z1, . . . , Zn are independent and normally distributed with unknown expectation μ
and unknown variance σ2. He tests the null hypothesis H0: μ = 0 against H1: μ = 0.
Describe a suitable test for the given problem based on the observed diﬀerences; give
a test statistic and an (approximate) critical region (a diﬀerent test than the one for the
ﬁrst statistician). Explain how you have arrived at the critical region. Take α0 as the
size of the test.
(iii) Assume that the diﬀerences Z1. . . , Zn are normally distributed with expectation μ and
variance σ2. Show that the assumptions of the two statisticians are equivalent under
the assumption of normality.
(iv) Both statisticians have carried out their tests. The ﬁrst statistician does not reject the
null hypothesis; the second does. Is this possible, or has one of the two made a mistake?
Explain.
22. Let X1, . . . , Xn be a sample from the distribution with probability density pθ(x) = e−x+θ1x≥θ.
We want to test the null hypothesis H0: θ ≥0 against H1: θ < 0 at level α0 = 0.1. We choose
X(1) as test statistic. Construct the critical region for the suitable (one-sided) test.
23. Let X be a random variable with a Poisson distribution with unknown parameter θ. Based
on X, we want to test the null hypothesis H0: θ = 5 against H1: θ = 5. Show that the power
function of each test in θ = 5 is not greater than the size. Can a meaningful test be set up for
this problem?
24. Let T be a test statistic with a continuous distribution function F0 under H0. Then 1 −F0(t)
is the p-value of a test that rejects H0 for large values of t.
(i) Show that under H0, the p-value 1 −F0(T) is uniformly distributed on [0, 1].
(ii) Is the distribution of this variable for a good test under the alternative hypothesis
stochastically "greater" of "smaller" than the uniform distribution? (Stochastically
greater means that realizations are, in general, greater; more precisely: the distribution
function is smaller.)
25.
(i) Show that the X2
2-distribution is equal to the exponential distribution with parameter
1/2.
(ii) What is therefore the relation between the X2
2n-distribution and a gamma distribution?
26. Show that the expectation and variance of the X2
n-distribution are equal to n and 2n,
respectively.
163

4: Hypothesis Testing
27. Consider the estimators Tc = cS 2
X for the variance of a sample X1, . . . , Xn from the N(μ, σ2)-
distribution. Use Theorem 4.29 and the previous exercise to compute the expected square
error of Tc. For what c is this minimal?
28. Determine the distribution of the sum of two independent chi-square-distributed quantities.
29. (F-test.) A random variable T has the F-distribution with m and n degrees of freedom,
denoted by Fm,n, if T has the same distribution as (U/m)/(V/n) for independent random
variables U and V with, respectively, the χ2
m- and χ2
n-distributions. Use the critical values
from the F-distribution to construct a test for the problem H0: σ2/τ2 ≤1 against H1: σ2/τ2 >
1 based on two independent samples X1, . . . , Xm and Y1, . . . , Yn from, respectively, the
N(μ, σ2)- and N(ν, τ2)-distributions (for unknown μ and ν).
30. Based on two independent samples X1, . . . , X25 and Y1, . . . , Y16 from the N(μ, σ2)- and
N(ν, τ2)-distributions, respectively, we want to test H0: σ2 ≥2τ2 against H1: σ2 < 2τ2 with
unknown μ and ν, and α0 = 0.01.
(i) What is the conclusion if we ﬁnd the sums of squares s2
x = 46.7 and s2
y = 45.1?
(ii) Determine the corresponding p-value.
31. Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution, where μ ∈R and σ2 > 0 are
unknown.
(i) Prove that the test "Reject H0: σ2 ≤σ2
0 when (n −1)S 2
X/σ2
0 ≥χ2
n−1,1−α" (described in
Example 4.32) has size α.
(ii) The power function of this test is a function of (μ, σ). Express this function in the
distribution function of the chi-square distribution.
(iii) Sketch the graph of this function.
32. Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution, where μ is known. How could
you use the known value of μ to construct a test for H0: σ2 = σ2
0 against H0: σ2 = σ2
0? Do
you expect this test to have a greater power function than the test from Example 4.32?
33. Show that a t-distribution is symmetric around the origin.
34. A chemical process should produce at least 800 metric tons of chemicals a day. The daily
production of a certain week is 785, 805, 790, 793, and 802 metric tons. Do these data give a
reason to conclude that there is something wrong with the process? Take α0 = 0.05. Which
assumptions were made?
35. The average birth weight of boys in the Netherlands is 3605 grams. A number of midwives
want to study whether the expected birth weight of boys in their practice deviates from this.
The average birth weight of the 20 most recently born boys in the practice is 3585 grams,
and the sample standard deviation is 253 grams.
(i) Set up a test for the problem described above. Give the null and alternative hypotheses.
Give the test statistic, the distribution of the test statistic under the null hypothesis, and
the critical region. Take level α0 = 0.05. What is your conclusion?
(ii) Test the null hypothesis from part (i) again, now based on an (approximate) p-value.
36. In an experiment, the blood pressure of 32 patients with hypertension is measured after they
have taken a blood-pressure-lowering drug A. In a second experiment, the blood pressure of
20 patients with hypertension is measured after they have taken B, another blood-pressure-
lowering drug. Denote the blood pressure values in the two experiments by X1, . . . , X32 and
Y1, . . . , Y20. The measured outcomes are x = 163, y = 158, sX = 7.8, and sY = 9.0.
(i) Use a suitable test to determine which of the two drugs works best. Take a level of 5%.
(ii) Determine the (approximate) p-value.
164

4: Exercises
37. Ten sweaters are cut in half. One side is washed with product A, the other half with product
B. After washing, the sweaters are measured. We ﬁnd the following lengths:
sweater
1
2
3
4
5
6
7
8
9
10
product A
61, 2
58, 3
56, 7
59, 1
62, 7
61, 3
57, 8
55, 7
61, 8
60, 7
product B
61, 5
58, 2
59, 0
58, 6
62, 4
61, 2
55, 0
55, 0
61, 4
61, 0
Do the sweaters shrink less with product A or with product B? Construct a suitable test and
state your conclusion. Take α0 = 0.05. Which assumptions were made?
38. Mister Young has a cab company with 12 cabs. He plans to buy 6 new tires of brand A and
6 new tires of brand B for the back wheels of the cabs. After every 500 km, he will check
the wear on the tires. He can either
(1) put a single new back tire on each of the 12 cabs, or
(2) put a new back tire of each brand on 6 cabs.
Which of the two methods is preferable statistically? Why?
39. Mister Young from the previous exercise records the following numbers of driven kilometers
when the 12 tires are worn:
km with brand A
51000
50500
61500
59000
64000
59000
km with brand B
55000
49500
62500
61500
65500
60000.
(i) If the results are obtained using method (1), can he see the diﬀerence between the
brands A and B? Take α0 = 0.10.
(ii) Same question if the results are obtained using method (2) (where the vertical columns
show the 6 cabs).
(iii) Is it obvious that the two methods should give approximately the same numbers (as we
have assumed in this exercise for the sake of convenience)?
(iv) Is it reasonable to assume that the number of kilometers is exactly normally
distributed? And approximately?
40. The content of a sunscreen manufacturer's tubes is checked. The tubes say that the content
is equal to 150 grams. The inspector suspects that the manufacturer does not put enough
sunscreen in the tubes. On inspection, the following content (in grams) is measured: 150.10,
149.55, 150.00, 149.65, 149.35, 150.15, 149.75, 150.00, 149.65, 150.20, 149.20, 149.95.
(i) Check with a suitable test whether the inspector's suspicion is correct. Take level α0 =
0.05.
The manufacturer receives a warning from the inspector and claims to have adjusted the
ﬁlling machines. At the next inspection, the following content (in grams) is measured:
149.85, 150.15, 150.05, 149.90, 150.30, 150.05, 149.95, 149.75, 149.95, 150.10.
(ii) Set up suitable null and alternative hypotheses to check the manufacturer's claim that
the expected weight at the second inspection is higher than that at the ﬁrst. Carry out the test
at level α0 = 0.05.
41. A chemical process should produce 10 metric tons of waste material an hour. Inspectors
think that the amount of waste material is too high. The production process is therefore
followed during 16 hours, and the amount of waste material produced each hour is recorded.
Suppose that the amounts of waste material in these 16 hours, denoted by X1, . . ., X16, are
independent and normally distributed with unknown expectation μ and known variance 1.
The sample mean is x = 10.5.
165

4: Hypothesis Testing
(i) Give suitable null and alternative hypotheses for the situation describe above. Test the
null hypothesis at level α0 = 0.05. Give the test statistic, the critical region, and a
conclusion in words.
(ii) How many hours should one measure to have at least a 0.80 probability of discovering
a deviation if the true value μ is equal to 10.4 metric tons?
42. Determining the isolating properties of oil can be done by ﬁlling a glass tube containing two
poles and applying voltage to the two poles, letting it increase until a spark breaks through
the isolation. We can repeat this determination of the breakthrough voltage as often as we
want. In an experiment described by Youden and Cameron, two determinations are carried
out each time ("duplo determinations"). If we denote the breakthrough voltage in the ﬁrst
determination by X and that in the second by Y, then it is reasonable to assume that X and Y
have the same distribution (although it is, in general, diﬀerent for diﬀerent types of oil). This
is, however, in no way certain, since a spark traveling through oil can leave behind ions,
which can inﬂuence the outcome of the second determination. We want to check whether
such an inﬂuence is present. In the experiment, we used 10 oil samples (each of a diﬀerent
type of oil); the tube was ﬁlled twice from each sample, and two determinations were carried
out for each ﬁlling of the tube. The outcomes are given below:
oil sample
1st ﬁlling
2nd ﬁlling
1
16
12
17
14
2
11
10
12
10
3
14
14
15
14
4
19
17
18
19
5
23
20
21
19
6
13
15
14
14
7
16
15
16
14
8
20
19
19
20
9
15
11
16
13
10
14
12
13
15
Test the null hypothesis that there is no systematic diﬀerence between the duplo determi-
nations against the alternative hypothesis that there is one, at level α0 = 0.01, under the
assumption that all breakthrough voltages are independent and normally distributed with the
same (unknown) variance. Indicate the approximate size of the p-value.
43. To study whether toxic material has been released during a large ﬁre, soil samples have
been taken at diﬀerent locations near the site of the ﬁre. The presence of heavy metals is
measured in these samples. For comparison, a number of samples are taken at a safe distance
from the ﬁre where the soil has the same type of composition. We want to test whether the
concentration in the soil near the ﬁre is higher than the concentration at a safe distance. At
both places, 10 samples were taken. The concentrations in the 10 samples near the ﬁre are
denoted by X1, . . . , X10, the concentrations at a safe distance are denoted by Y1, . . . , Y10. The
resulting sample means are x = 101.5, y = 99.2, and the sample variances are s2
x = 5.1 and
s2
y = 5.2.
(i) Give a statistical model and reformulate the problem outlined above as a test problem.
Describe the standard test. Give the test statistic and the critical region. Use level 5%.
Carry out the test. What is your conclusion?
Another researcher argues as follows. Since the ground near the site of the ﬁre is clay, heavy
metals will not quickly descend to lower soil layers. He therefore wants to study whether
the concentration in the top layer is higher than that in the bottom layer; a rise in the top
166

4: Exercises
layer may be caused by the ﬁre. For each sample taken near the ﬁre, he determines the
concentration in the top and bottom layers.
(ii) Write the problem outlined as a test problem. Give the test statistic and explain how
we can determine the p-value.
(iii) Suppose that the p-value is equal to 0.042. What is the conclusion if we take the size
α0 equal to 0.05?
(iv) Which of the two research methods is preferable?
44. Show that a probability density for the tn-distribution is given by
f(x) =
Γ
(n + 1)/2
Γ(n/2)
1
√nπ

1 + t2
n
−(n+1)/2
.
45. Suppose that we have observations x1 = 0.5, x2 = 0.75, and x3 = 1/3. Determine the
value of the Kolmogorov-Smirnov statistic for testing whether x1, x2, x3 are realizations of
independent U[0, 1]-variables.
46. Make the dependence of the Kolmogorov-Smirnov statistic (4.4) on the observations
X1, . . . , Xn visible by writing the statistic in the form T ∗(X1, . . . , Xn). Deﬁne Zi = (Xi −μ)/σ.
Show that T ∗(X1, . . . , Xn) = T ∗(Z1, . . . , Zn). Deduce that the distribution of the Kolmogorov-
Smirnov statistic is the same for every element of the null hypothesis that the observations
are normally distributed.
47. Let X1, . . . , Xn be a sample from the distribution with probability density pθ(x) = e−x+θ1x≥θ.
(i) Determine the likelihood ratio statistic λn for testing H0: θ ≤0 against H1: θ > 0.
(ii) Determine the limit distribution of 2 log λn.
48. Let X1, . . . , Xn be a sample from the uniform distribution on [0, θ].
(i) Determine the likelihood ratio statistic λn for testing H0: θ ≤θ0 against H1: θ > θ0.
(ii) Determine the likelihood ratio statistic λn for testing H0: θ = θ0 against H1: θ = θ0.
49. Let X1, . . . , Xn be a sample from the Poisson distribution with unknown parameter θ.
(i) Determine the likelihood ratio statistic λn for testing H0: θ = θ0 against H1: θ = θ0.
(ii) What limit distribution does 2 log λn have as n →∞?
50. Let X1, . . . , Xn be a sample from the distribution with probability density pθ(x)
=
2θxe−θx21(0,∞)(x), where θ > 0 is an unknown parameter.
(i) Determine the likelihood ratio statistic λn for testing H0: θ = θ0 against H1: θ = θ0.
(ii) Give the critical region for the likelihood ratio test at level α0.
51. Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution. We want to test the null hypothesis
H0: σ2 = σ2
0 against H1: σ2 = σ2
0 at level α0 (both μ and σ2 are unknown). Show that the
likelihood ratio test rejects H0 when (n −1)S 2
X/σ2
0 /∈[c1, c2], where c1 and c2 satisfy
(i) P
χ2
n−1 ∈[c1, c2]
= 1 −α0.
(ii) c1 −c2 = n log(c1/c2).
Note that this test diﬀers somewhat from the test in Example 4.32, but not much for large n.
167

4: Hypothesis Testing
52. (Score test.) Let X1, . . . , Xn be a sample from a distribution with the probability density pθ
indexed by a parameter θ ∈Θ ⊂R. To test the null hypothesis H0: θ = θ0, we consider the
test statistic Tn = 1/nn
i=1˙θ0(Xi), for ˙θ the score function for pθ.
(i) Determine Tn for testing H0: θ = 1 based on a sample from the N(0, θ2)-distribution.
(ii) Determine a critical region for a test that rejects H0 for large values of |Tn| and that has
approximately size α for large n.
(iii) Show that the power function of the test converges to 1 as n →∞for every θ = θ0 such
that Eθ ˙θ0(X1) = 0.
(iv) Verify that Eθ ˙θ0(X1) = 0 for every θ  θ0.
168

SHARES ACCORDING TO BLACK-SCHOLES
In the 1970s, Black and Scholes introduced an economic theory for the pricing of
options on shares or other tradable "assets." After Black's death, Scholes received
the Nobel prize for this work, together with Merton. Even today, the model is the basis
for pricing so-called "ﬁnancial derivatives," ﬁnancial products that are derived from
underlying products such as shares. Below, we will study certain characteristics of
this model statistically.
The top image of Figure 4.14 shows the value of a share of Hewlett Packard at the
New York stock exchange plotted against the time, in the period 1984-1991.The values
At of the share at closing time on consecutive exchange days (i = 1, 2, . . . , 2000) are
plotted; in the graph, these values have been interpolated linearly.† According to the
Black-Scholes model, the share price follows a "geometric Brownian motion." This
corresponds to the log returns, deﬁned by
Xt = log
At
At−1
,
forming a sequence X1, X2, . . . of independent, N(μ, σ2)-distributed random vari-
ables. In other words, the logarithms of the relative changes in the share price form
an unpredictable noise with a normal distribution. The log returns are shown in the
lower image in Figure 4.14; they have also been interpolated linearly. We will study
this assumption of the Black-Scholes model in several ways.
1984
1985
1986
1987
1988
1989
1990
1991
1.0
1.5
2.0
2.5
1984
1985
1986
1987
1988
1989
1990
1991
-0.2
-0.1
0.0
0.1
Figure 4.14. Price and log return of a share of Hewlett Packard at the New York stock exchange;
initial value set equal to 1.
† The data can be found on the book's webpage at http://www.aup.nl under hpprices (share
prices) and hplogreturns (log returns).
169

4: Hypothesis Testing
If the Black-Scholes model holds, then the sample mean X and the sample
variance S2
X are good estimators for the parameters μ and σ2 of the normal
distribution of the log returns. The corresponding estimates, computed both over the
full period and over four quarters, are
period
'84-'91
'84-'85
'86-'87
'88-'89
'90-'91
ˆμ
0.000463
0.000164
0.001111
-0.000132
0.000710
ˆσ
0.022673
0.020514
0.026304
0.019102
0.024100
The estimate ˆμ
≈
0.00046 over the full period means that on average, the
value has increased between 1984 and 1991. If, for a moment, we ignore the
stochastic ﬂuctuations (not a good idea, see below!), then At ≈At−1e0.000463 ≈
At−11.000463. The average increase per day is then almost 0.05%. Yearly (250
stock market days), we have At ≈At−1e0.000463 ≈. . . ≈At−250(e0.000463)250 ≈
At−2501.12, which gives an average yearly increase of 12%. However, this increase is
not uniformly distributed over the full period. In the third quarter '88-'89, the average
of the log returns is negative (ˆμ = −0.000132).
Using a statistical test, we can study whether such a decrease is compatible with
the Black-Scholes model. In the Black-Scholes model, the observations in the four
periods form four independent samples from the same normal distribution. We can, for
example, test whether the log returns in the second quarter have the same expectation
as the log returns in the third quarter, under the assumption that the log returns in
the two quarters are samples from the normal distribution with expectation μ and ν,
respectively, and variance σ2. (We chose to study precisely these two quarters after
computing the expected values of μ. This means that we in fact use the data twice—to
decide what to test and to carry out the test—which makes the interpretation of p-
values and sizes suspicious. It would have been better to compare all four periods, but
this requires a more complicated test or a comparison of all pairs.) We use the t-test for
independent samples. The estimated variance is ˆσ2 = 1
2(0.0263042 + 0.0191022) ≈
0.00528, and the t-statistic has value
√
250(0.001111 −(−0.000132))/
√
0.00528 ≈
0.27. For a t-distribution with 998 degrees of freedom, this corresponds to a right p-
value of approximately 39%. Despite the practically signiﬁcant diﬀerence in sign in
the estimates of μ in the second period, this test therefore does not lead us to doubt the
Black-Scholes model. The observed diﬀerence in the estimates can be amply explained
by the ﬂuctuations of the share prices over time.
In the Black-Scholes model, these ﬂuctuations are measured through the value
of the parameter σ2, which in this context is called the volatility of the share prices.
It is unwise to not involve these ﬂuctuations in the computations. According to the
Black-Scholes model, in one year (250 stock exchange days), we cannot count on a
deterministic growth of approximately 12% ((e0.000463)250 ≈1.12), but rather on a
growth that can be determined using the random variable
A250
A0
= A249eX250
A0
= A248eX249+X250
A0
= · · · = e
250
t=1 Xt.
170

4: Shares According to Black-Scholes
In the Black-Scholes model, the variable 
t Xt is normally distributed with
expectation 250μ and variance 250σ2; in other words, it is the random variable
250μ +
√
250σZ, where Z has the standard normal distribution. The distribution of
exp(
t Xt) is called log normal. The expected growth is
Ee250μ+
√
250σZ = e250μEe
√
250σZ ≈1.12e250σ2/2 ≈1.19,
where we have substituted the estimates ˆμ = 0.000463 and ˆσ = 0.022673 for μ
and σ. The expected yearly growth in the Black-Scholes model is therefore 19%. It
is somewhat surprising that this value is considerably larger than the value 12% we
found earlier by ignoring the randomness of the share prices. The form of the Black-
Scholes model, where the price is an exponential function of the (normally distributed)
log returns, is responsible for this. The expected daily growth is exp(μ + 1
2σ2)
and not exp(μ), in accordance with the inequality E exp(X) ≥exp(EX), which
is strict when X is nondegenerate. (To cancel out the apparent contradiction, the
reparametrization (μ, σ2) →(μ −1
2σ2, σ2) is often applied, so that the distribution
of the log returns is N(μ −1
2σ2, σ2), and the expected daily growth is exp(μ).) The
estimate of μ+ 1
2σ2 in the third quarter of the full period is positive, though just barely,
so that on closer inspection, the investment does have a positive yield.
The volatility σ also plays a decisive role in the Black-Scholes formula for the
price of an option on the HP share. In the dealing rooms and back oﬃces of banks,
this price is even expressed with the volatility as unit. The Black-Scholes model is
then often deviated from in the sense that the parameter σ is not taken as ﬁxed, but
may depend on time. In the four quarter periods, we for example ﬁnd ﬂuctuations of
σ of size 13%. As for the parameter μ, we can test whether these ﬂuctuations are
signiﬁcant. To compare the volatility in the second and third quarters, we compute the
F-statistic (see Exercise 4.29) 0.0191022/0.0263042. This leads to a left p-value of
approximately 7 ∗10−12 with respect to the F-distribution with 499 and 499 degrees
of freedom. This is a strong indication that the volatility is eﬀectively not constant over
time.
Up to now, we have not truly tested the basic assumption of the Black-Scholes
model that the log returns can be viewed as a sample from a normal distribution. We
can, however, argue about both the normality assumption and the assumption that
the log returns are independent variables. In fact, almost no one truly believes in the
model, although it is applied by default.
We ﬁrst study the normality of the log returns, under the assumption that the
independence holds. In that case, we can test whether the log returns X1, . . . , X2000
can be viewed as a sample from a normal distribution. Since we have already
seen that the volatility σ is not constant over time, we will test the less stringent
assumption that the log returns in the third quarter can be seen as a sample
from the normal distribution. Figure 4.15 gives a ﬁrst graphical impression of the
distribution of this sample, through a histogram and a QQ-plot. These two graphs
lead us to doubt the normality assumption, although the deviation from normality
is not very strong. We can study the assumption formally by applying a statistical
test such as the Kolmogorov-Smirnov test (see Example 4.38). Figure 4.16 shows
171

4: Hypothesis Testing
−0.05
0.00
0.05
0
5
10
15
20
25
−3
−2
−1
0
1
2
3
−0.05
0.00
0.05
Figure 4.15. Histogram and QQ-plot against the normal distribution of the log returns in the
period '88-'89 on the HP-shares. The curve in the histogram is the normal density with parameters
equal to the sample mean and sample variance of the log returns.
-0.05
0.0
0.05
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4.16. Empirical distribution function of the log returns in '88-'89 and distribution function
of the normal distribution with parameters equal to the sample mean and sample variance of the
log returns.
the empirical distribution function of X1001, . . . , X1500 and the distribution function
of the normal distribution with expectation and variance equal to, respectively, the
sample mean and the sample variance of this sample. The Kolmogorov-Smirnov
statistic is the maximal vertical distance between these two distribution functions and
can be shown to equal 0.052. The corresponding critical value can be determined
by computing the Kolmogorov-Smirnov statistic for a large number of samples
simulated from the normal distribution. From 10 000 simulated samples, the value
of the Kolmogorov-Smirnov statistic was greater than 0.052 in 6% of the cases. This
means an (approximate) p-value of 6%, so that the null hypothesis of normality is not
rejected at size 5%, but only barely.
Finally, we consider the stochastic time-independence of the log returns assumed
by Black and Scholes. As ﬁrst control quantity, we compute the sample autocorrelation
172

4: Shares According to Black-Scholes
coeﬃcients of the log returns. These are shown on the left in Figure 2.13 and do not
seem to contradict the independence. The sample autocorrelation coeﬃcients of the
squares of the log returns, on the right in Figure 2.13, however, are clearly diﬀerent
from 0. Carrying out the test from Example 4.40 therefore leads us to rejecting the
null hypothesis that the log returns are independent, identically distributed random
variables.
We can argue about the choice of this method. After all, we had already
established that the volatility is not constant over time, so that the null hypothesis that
the log returns are identically distributed and independent is not the most relevant
hypothesis. We can repeat the analysis for each of the four periods individually. This
leads to the same result.
The interesting question is now which dependence between the log returns exists
on diﬀerent days. This is not a simple question, because "dependence" includes
many possibilities: all possible denials of "independence," which, by contrast, is
uniquely determined. From the diﬀerent models, the GARCH(1,1) model is seen as
the benchmark. This model postulates
σ2
t = α + θX2
t−1 + φσ2
t−1,
Xt = σtZt.
The ﬁrst equation concerns the propagation of the volatility σt. This is not observed
directly, but seen as a primary driving process under the log returns. The volatility
on day t is a function of the square of the return and volatility on day t −1, and
increases as these increase (φ, θ ≥0). Given the volatility σt, the log return at time t
is equal to σt times a variable Zt, which is often assumed to be normally distributed
and independent of the past (Xt−1, σt−1, Xt−2, . . .).
173

5 Conﬁdence Regions
5.1 Introduction
In Chapter 3, we saw how a parameter θ could be estimated by the value t = T (x) of
an estimator T . In the context of this chapter, we will also refer to such estimates as
point estimates. As a rule, an estimate t diﬀers from the parameter θ to be estimated.
Using the conﬁdence regions described in this chapter, we can quantify the possible
diﬀerence between the estimator T and θ. In many cases, this leads to an interval
estimate

L(x), R(x)

, with the interpretation that θ has a high probability of lying in
this interval.
5.2 Interpretation of a Conﬁdence Region
The deﬁnition of a conﬁdence region is as follows.
Deﬁnition 5.1 Conﬁdence region
Let X be a random variable with a probability distribution that depends on a
parameter θ ∈Θ. A map X →GX whose codomain is the set of subsets of Θ
is a conﬁdence region for θ of conﬁdence level 1 −α if
Pθ

GX  θ

≥1 −α
for all θ ∈Θ.
174

5.2: Interpretation of a Conﬁdence Region
In other words, a conﬁdence region is a "stochastic subset" GX of Θ that has
a "high probability" of containing the true parameter θ. Because we do not know
beforehand which value of θ is the true value, the condition in the deﬁnition holds
for all values of θ: under the assumption that θ is the true value, this true value must
have probability at least 1 −α of being in GX. After X = x has been observed, the
stochastic set GX changes into a normal, nonstochastic subset Gx of Θ. Generally,
α is taken small, for example α = 0.05, so that the probability that θ lies in the
conﬁdence region is high. As we decrease α, the conﬁdence region will of course
grow and therefore give less information on θ, which, however, will then be "more
certain." We again have a trade-oﬀbetween two goals, as we already encountered
with tests.
We often say that the probability that the realization Gx contains the true value θ
is at least 1−α. This probability statement can easily be interpreted incorrectly. In our
interpretation, the true value of θ is ﬁxed; the realized conﬁdence region Gx is also
not a random variable. Consequently, the true θ either lies in the conﬁdence region
Gx or does not. (Unfortunately, we do not know which of the two cases occurs.) The
probability statement can be interpreted in the sense that if we, for example, carry
out the experiment that gives X independently 100 times and compute the conﬁdence
region Gx 100 times, then we may expect that (at least) approximately 100(1 −α) of
the regions will contain the true θ. This is illustrated in Figure 5.1, which shows 100
independent realizations of a 90% conﬁdence interval for the expectation parameter
of the normal distribution. The true value of the parameter is 0 and is contained in 89
of the intervals. In practical situations, we, of course, cannot repeat experiments and
can only determine one conﬁdence region. This can be one of the 100α regions that
do not contain the true parameter, without our being able to know this!
Because GX is stochastic and θ deterministic, we have written GX  θ instead
of θ ∈GX. In our notation for probabilities, the random variable is always on
the left. For the same reason, some people disapprove of a statement such as "θ
has a high probability of lying in GX." We do not follow this last convention, but
again emphasize that conﬁdence regions have a subtle interpretation. In the Bayesian
terminology of Section 3.5, on the other hand, the parameter is a random variable.
This allows us to see, in that context, the probability statement on the event θ ∈GX
as a statement concerning the random variable θ. The probability of this event can
be determined with respect to the posterior distribution. We discuss this approach in
Section 5.7.
When θ is a numerical parameter (that is, Θ ⊂R), we typically use conﬁdence
intervals. These are conﬁdence regions of the form GX =

L(X), R(X)

for two
functions L and R of X. We then also speak of the conﬁdence interval [L, R] for the
parameter θ. Sometimes the center of the conﬁdence interval is exactly the used point
estimate T = T (X) for θ. We then also write the interval in the form θ = T ± η,
with η = 1
2

R(X) −L(X)

half the length of the interval. In other cases, the interval
is intentionally chosen asymmetric around the used point estimate, which can be an
expression of a "higher precision" upward or downward.
175

5: Conﬁdence Regions
-2
-1
0
1
2
3
0
20
40
60
80
100
Figure 5.1. 100 realizations of the conﬁdence interval of the expectation of the normal distribution
(as computed in Example 5.4) based on 100 independent samples of size 5.
Example 5.2 Normal distribution
Let X = (X1, . . . , Xn) be a sample from the normal N(μ, σ2)-distribution with
unknown μ ∈R and known variance σ2. Then
GX =

X −σ
√nξ1−α/2, X + σ
√nξ1−α/2

is a conﬁdence interval for μ of conﬁdence level 1 −α. We can see this as follows.
The sample mean X, the natural estimator for μ, has the N(μ, σ2/n)-distribution, and
therefore √n(X −μ)/σ has the standard normal distribution. We then have
Pμ

ξα/2 ≤√nX −μ
σ
≤ξ1−α/2

= 1 −α,
where ξα is the α-quantile of the standard normal distribution. We can rewrite this in
the form
Pμ

X −σ
√nξ1−α/2 ≤μ ≤X + σ
√nξ1−α/2

= 1 −α,
where we have used that ξα/2 = −ξ1−α/2. It follows that Pμ(GX  μ) = 1 −α for
the GX mentioned above. This interval is symmetric around the estimator X and is
often written as
μ = X ± σ
√nξ1−α/2.
A realization of this interval contains μ with probability 1 −α.
The smaller σ and the larger n, the shorter (and therefore more informative) the
interval. Note that to cut the interval in half, we need four times as many observations.
For larger α, the interval is also shorter, but this goes at the expense of the conﬁdence
level.
176

5.3: Pivots and Near-Pivots
5.3 Pivots and Near-Pivots
Many conﬁdence regions are constructed using a pivot.
Deﬁnition 5.3 Pivot
A pivot is a function T (X, θ) of the observation and parameter whose probability
distribution does not depend on θ or any other unknown parameters if the probability
distribution of X is given by the "true" parameter θ.
A pivot is therefore not a statistic, because the pivot may depend on both the
observation X and the parameter θ. For a pivot T (X, θ), the probability Pθ

T (X, θ) ∈
B

is in principle known for every set B. Here, "known" means "independent of θ";
the two occurrences θ in the expression Pθ

T (X, θ) ∈B

must therefore cancel each
other out. In Example 5.2, we in fact already saw an example of a pivot: √n(X−μ)/σ,
which has the standard normal distribution.
For every set B such that Pθ

T (X, θ) ∈B

≥1 −α, the set

θ ∈Θ: T (X, θ) ∈B

is a conﬁdence region for θ of conﬁdence level 1 −α. In general, many sets B exist
with this property, and we want to choose a "suitable" candidate from these. Although
it seems natural to look for sets for which the volume of the conﬁdence region is small,
the choice is not unique. We illustrate this with the following examples.
Example 5.4 Normal distribution
Let X = (X1, . . . , Xn) be a sample from the N(μ, σ2)-distribution with μ ∈R and
σ2 > 0 unknown. By Theorem 4.29,
√nX −μ
SX
has a tn−1-distribution, which does not depend on the parameter (μ, σ2). This variable
is therefore a pivot, and we have
Pμ

tn−1,α/2 ≤√nX −μ
SX
≤tn−1,1−α/2

= 1 −α.
It immediately follows from computations analogous to those in Example 5.2 that

X −SX
√ntn−1,1−α/2, X + SX
√ntn−1,1−α/2

is a conﬁdence interval for μ of conﬁdence level 1−α. Since the interval is symmetric
around X, it can also be written as
μ = X ± SX
√ntn−1,1−α/2.
177

5: Conﬁdence Regions
This interval greatly resembles the interval from the previous example, with σ replaced
by SX and ξα replaced by tn−1,α. Since the t-distribution has thicker tails than the
standard normal distribution, the t-quantiles lie further from 0 than the quantiles of the
standard normal distribution, and the interval we found here is in general somewhat
longer than in the case where σ is known (although that also depends on the value
of SX). This is the price we have to pay for σ being unknown. As n →∞, the
tn-distribution increasingly resembles the normal distribution, and SX converges in
probability to σ. Hence the diﬀerence between the two intervals disappears as n →∞.
By the choice of the quantiles, the interval above is symmetric around the
maximum likelihood estimator for μ. Nonsymmetric intervals of conﬁdence level 1−α
can be constructed by choosing other quantiles of the t-distribution:
Pμ

tn−1,β ≤√nX −μ
SX
≤tn−1,1−γ

= 1 −α
for β + γ = α. The conﬁdence interval for μ based on these quantiles is equal to

X −SX
√ntn−1,1−γ, X −SX
√ntn−1,β

.
The shortest conﬁdence interval of conﬁdence level 1 −α is obtained by taking β =
γ = α/2; this results in the interval given earlier.
Example 5.5 Uniform distribution
If X = (X1, . . . , Xn) is a sample from the U[0, θ]-distribution, then the vector
X1/θ,. . ., Xn/θ is a sample from the U[0, 1]-distribution. Every function of X1/θ, . . .,
Xn/θ is therefore a pivot.
The most interesting pivot is X(n)/θ, since this pivot is based on the maximum
likelihood estimator and suﬃcient quantity X(n) for θ (see Section 6.2 for the
deﬁnition of a suﬃcient quantity). We have
Pθ
X(n)
θ
≤x

= xn,
0 ≤x ≤1.
This leads to several conﬁdence intervals for θ. If c, d with 0 ≤c ≤d ≤1 are numbers
such that dn −cn = 1 −α, then
1 −α = dn −cn = Pθ

c ≤X(n)
θ
≤d

= Pθ
X(n)
d
≤θ ≤X(n)
c

.
The interval [X(n)/d, X(n)/c] is therefore a conﬁdence interval for θ of conﬁdence
level 1 −α.
The choices c = 0 and d = (1 −α)1/n lead to the right-open interval [X(n)(1 −
α)−1/n, ∞). The choices c = α1/n and d = 1 give the interval [X(n), X(n)α−1/n].
Because we are certain that θ ≥X(n), this interval puts all uncertainty in the upper
bound. A reasonable strategy is to choose c and d such that |1/d−1/c| is minimal and
the interval [X(n)/d, X(n)/c] is the shortest possible (see Exercise 5.21). However, all
intervals are allowed and have the same interpretation.
178

5.3: Pivots and Near-Pivots
Determining conﬁdence regions exactly from pivots is only possible incidentally,
simply because there is not always a pivot. For example, it is impossible for the
parameter p in the binomial distribution or for the parameter μ in the Poisson
distribution. In such a case, we often settle on an approximate conﬁdence region,
which can be deduced from a near-pivot. When we are dealing with large samples,
such near-pivots are usually amply available.
Example 5.6 Binomial distribution
If X is binomially distributed with parameters n and p, then for large n,
X −np

np(1 −p)
is approximately N(0, 1)-distributed, by the central limit theorem; see Section A.7.
By approximation, this function of X and p is therefore a pivot. The set

p: ξα/2 ≤
X −np

np(1 −p)
≤ξ1−α/2

is consequently approximately a conﬁdence region for p of conﬁdence level 1−α. This
set is an interval that can be found by solving the quadratic equation (X −np)2 ≤
ξ2
1−α/2np(1 −p). Figure 5.2 shows this interval for certain values of α, n, and p.
0.0
0.2
0.4
0.6
0.8
1.0
0
2
4
6
8
10
12
Figure 5.2. Conﬁdence interval for the parameter p of a binomial distribution. The graph shows
the functions p →|x −np| and p →1.96
np(1 −p) for the case 0 < x < n (namely, x = 13 and
n = 20). The conﬁdence interval is the interval on the horizontal axis between the two intersection
points.
As long as we are taking approximations, we can also go a step further. By the
law of large numbers (Theorem A.26), X/n converges in probability to p as n goes to
inﬁnity. Hence the random variable
X −np

n(X/n)(1 −X/n)
179

5: Conﬁdence Regions
is approximately N(0, 1)-distributed. (This follows using Slutsky's lemma; see
Lemma 5.15.) The approximate conﬁdence interval based on this near-pivot is of the
simple form
p = X
n ±
1
√n

X
n

1 −X
n

ξ1−α/2.
This interval is often used as an indication of the size when estimating the proportion
of elements from a population with a certain characteristic, for example during a poll.
It is remarkable that the size of the population does not pay a role in the length of
the interval. Only the sample size counts, and to a lesser degree the true proportion. If
p = 1/2 and n = 1500, then the 95% conﬁdence interval is approximately (X/n) ±
2%. This 2% is probably the value that is meant in newspapers when a deviation of
at most 2% is promised in the results of a given poll. The correct interpretation of
this margin is that in 95% of the polls, the deviation of the sample proportion to the
true proportion is not greater than 2%. Unfortunately, the press often translates this
complicated statement into a ﬁrm error margin.
As p →0 or p →1, the function p →

p(1 −p) converges to 0. The conﬁdence
interval is therefore shorter for extreme values of p. The length of the conﬁdence
interval is the least favorable for p = 1/2.
Example 5.7 Application: counting bacteria
In Example 3.19, we assumed that the number of colony-forming units of bacteria
in a centiliter of contaminated water is Poisson-distributed with parameter μ. To
estimate μ, the contaminated water was mixed with 100 liters of pure water and
divided over 100 Petri dishes. We only observe Y1, . . . , Y100, with Yi equal to 1
when a colony of bacteria forms in the ith dish and equal to 0 otherwise. It follows
that Yi has the Bernoulli distribution with probability p = 1 −e−μ/100 for i =
1, . . . , 100. In Example 3.19, p is estimated using the maximum likelihood estimator
Y . Since 100
i=1 Yi is binomially distributed with parameters 100 and p, it follows from
Example 5.6 that
P

Y −ξ1−α/2
√
100

Y (1 −Y ) ≤p ≤Y + ξ1−α/2
√
100

Y (1 −Y )

≈1 −α.
This conﬁdence interval for p can be used to deduce a conﬁdence interval for μ by
substituting p = 1 −e−μ/100. If we write ˆσ2 = Y (1 −Y ), then

−100 log

1 −Y + ξ1−α/2
√
100
√
ˆσ2

, −100 log

1 −Y −ξ1−α/2
√
100
√
ˆσ2

is a conﬁdence interval for μ of conﬁdence level 1 −α, provided 1 −Y −
ξ1−α/2

ˆσ2/100 > 0. If 1 −Y −ξ1−α/2

ˆσ2/100 ≤0, the upper bound is replaced
by inﬁnity.
180

5.3: Pivots and Near-Pivots
The near-pivot in Example 5.6 comes from an asymptotic approximation of
the distribution of the estimator. Many estimators Tn for a parameter g(θ) are
asymptotically normally distributed in the sense that for certain numbers σn,θ (often
the standard deviation of Tn), under the assumption that θ is the true parameter, we
have
Tn −g(θ)
σn,θ
⇝N(0, 1)
as n →∞. The arrow ⇝is the notation for "convergence in distribution"; see
Deﬁnition A.25. More precisely, the statement means that
lim
n→∞Pθ
Tn −g(θ)
σn,θ
≤x

= Φ(x)
for all x.
An informal interpretation is that for large n, the variable

Tn −g(θ)

/σn,θ is
approximately N(0, 1)-distributed if θ is the true parameter. Consequently,
Tn −g(θ)
σn,θ
is a near-pivot. This is also called the large sample method. This leads to an
approximate conﬁdence region for g(θ) equal to

g(θ): Tn −σn,θξ1−α/2 ≤g(θ) ≤Tn + σn,θξ1−α/2

,
of conﬁdence level 1 −α. For convenience, the expression σn,θ is often replaced by
the estimator ˆσn, which gives the symmetric interval
g(θ) = Tn ± ˆσnξ1−α/2.
The expression ˆσn is usually an estimate for the standard deviation of Tn, the standard
error or s.e. of the estimator (or estimate). In many scientiﬁc reports, only the estimate
and corresponding standard error are mentioned. Provided that the used estimator is
approximately normally distributed, we can roughly interpret this information in the
sense of a 95% conﬁdence interval of the form g(θ) = Tn±ξ0.975 s.e. = Tn±1.96 s.e.
Good statistical software gives both a parameter estimate and the standard error
of the estimator. For an estimate of a vector-valued parameter, it gives a standard
error for every coordinate, and additionally, the estimated covariances between the
estimators, in the form of a matrix with the estimated variances of the estimators (the
squares of the standard errors) on the diagonal (see Section B.2 for the deﬁnition of
the covariance matrix).
181

5: Conﬁdence Regions
5.4 Maximum Likelihood Estimators as Near-Pivots
An important special case of the near-pivots discussed in the previous section is
that where Tn is the maximum likelihood estimator. Under certain conditions, the
maximum likelihood estimator is asymptotically normally distributed. We discuss
the simplest case, that of a sample of independent random variables and ﬁrst restrict
ourselves to parameters θ ∈Θ ⊂R.
Deﬁnition 5.8 Score function and Fisher information
Let pθ be the probability density of the observation X1, and suppose that the function
θ →θ(x): = log pθ(x) is (partially) diﬀerentiable for all x. The gradient
˙θ(x) = ∂
∂θ log pθ(x)
is then called the score function of the model. The Fisher information for θ in X1 is
deﬁned as the number
iθ = varθ ˙θ(X1).
Now, suppose that we have a sample X1, . . . , Xn from the distribution with
(marginal) probability density pθ. The log-likelihood function of the model is then
equal to θ →n
i=1θ(Xi) and has derivative θ →n
i=1 ˙θ(Xi), the sum of the score
functions over the observations. The maximum likelihood estimator ˆθn for θ is the
point where the log-likelihood takes on its maximum and is therefore a solution of the
likelihood equation n
i=1 ˙θ(Xi) = 0, unless the maximum of the likelihood is taken
on on the boundary of the parameter space.
We call the parameter θ ∈Θ identiﬁable if no other parameter gives the same
probability distribution or, more technically, if the densities pϑ and pθ diﬀer with
positive probability: Pθ

pϑ(X1) = pθ(X1)

> 0 for every ϑ = θ. This natural
property will normally be satisﬁed by a suitable parameterization of the model and is
necessary to estimate θ from the observations in a meaningful way. In the following
theorem, we assume that the parameter set Θ is compact. Extension to noncompact
sets is possible, in general, for example by showing that the maximum likelihood
estimator belongs to a compact set with probability converging to 1.
182

5.4: Maximum Likelihood Estimators as Near-Pivots
Theorem 5.9
Suppose that Θ is compact and convex and that θ is identiﬁable, and let ˆθn be the
maximum likelihood estimator based on a sample of size n from the distribution
with (marginal) probability density pθ. Suppose, furthermore, that the map ϑ →
log pϑ(x) is continuously diﬀerentiable for all x, with derivative ˙ϑ(x) such that
| ˙ϑ(x)| ≤L(x) for every ϑ ∈Θ, where L is a function with EθL2(X1) < ∞. If θ is
an interior point of Θ and the function ϑ →iϑ is continuous and positive, then under
θ, the sequence √n(ˆθn −θ) converges in distribution to a normal distribution with
expectation 0 and variance i−1
θ . Therefore, under θ, as n →∞, we have
√n(ˆθn −θ) ⇝N(0, i−1
θ ).
A (partial) proof of the theorem is given in Section 5.4.1. If the statement of the
theorem is applicable, then for large n, under θ, the random variable
√
niθ(ˆθ −θ)
is approximately standard normally distributed and therefore a near-pivot. For
convenience, we can replace iθ by an estimator iθ, and we ﬁnd for θ the approximated
conﬁdence interval
θ = ˆθ ±
1

niθ
ξ1−α/2
of conﬁdence level 1 −α. This interval is called the Wald interval. The statement
of the theorem is often read to mean that 1/(niθ) is an approximation for the
variance of ˆθ, and its square root is an approximation for the standard error. For
α = 0.05, the Wald interval is therefore, in fact, an interval of the general form
θ = ˆθ ± ξ0.975s.e. ≈ˆθ ± 2s.e. (Note that the theorem does not say anything about the
convergence of the variance of the maximum likelihood estimators, but the previous
interpretation is usually defendable.)
Common estimators for the Fisher information iθ are the plug-in estimator and
the observed information. The plug-in estimator is iθ = iˆθ; that is, the parameter θ in
the expression for iθ is replaced by the maximum likelihood estimator ˆθ. The observed
information is deﬁned as
iθ = −1
n
n

i=1
¨ˆθ(Xi),
with
¨θ(x) = ∂2
∂θ2 log pθ(x).
The plug-in estimator requires the (analytic) computation of the Fisher information
iθ, while the observed information follows more easily from the data. The observed
information is −1/n times the second-order derivative of the log-likelihood function
θ →n
i=1θ(Xi) evaluated in θ = ˆθ. If necessary, we can use a numerical derivative
(diﬀerence quotient) instead of an analytic derivative. Graphically, the observed
information gives the curvature of the log-likelihood function in the point θ = ˆθ
183

5: Conﬁdence Regions
where the log-likelihood is maximal. If the likelihood function has a ﬂat top, then the
observed information is small, and the conﬁdence interval for θ is long: the maximum
likelihood estimator is then not very precise. (This does not reﬂect a weakness of this
estimation method; it is due to a parameter that is intrinsically diﬃcult to estimate.)
The meaningfulness of the observed information as estimator for iθ is not immediately
clear, but follows (for large n) from the following lemma and the law of large number,
according to which n−1n
i=1¨θ(Xi) →Eθ¨θ(Xi) as n →∞with probability 1 if θ
is the true parameter.
Lemma 5.10
Suppose that θ →θ(x) = log pθ(x) is diﬀerentiable twice for all x. Then, under
certain regularity conditions, we have Eθ ˙θ(X1) = 0 and Eθ¨θ(X1) = −iθ.
Proof. We write the formulas under the assumption that X1 is continuously
distributed. (For a discrete probability density, we replace the integrals by sums.) Since
pθ is a probability density, we have 1 =

pθ(x) dx for all θ. Consequently,
0 = ∂
∂θ

pθ(x) dx =

∂
∂θpθ(x) dx =

˙pθ(x) dx,
with ˙pθ(x) = ∂/∂θ pθ(x). Interchanging the diﬀerentiation (with respect to θ) and the
integration (with respect to x) is permitted under certain regularity conditions. Since
the score function equals ˙θ(x) = ∂/∂θ log pθ(x) = ˙pθ(x)/pθ(x), we can rewrite the
right-hand side as

˙pθ(x)
pθ(x) pθ(x) dx =

˙θ(x) pθ(x) dx = Eθ ˙θ(X1).
This completes the proof of the ﬁrst assertion: Eθ ˙θ(X1) = 0. For the proof of the
second assertion, we diﬀerentiate

pθ(x)dx twice with respect to θ and ﬁnd
0 = ∂2
∂θ2

pθ(x) dx =

¨pθ(x) dx,
with ¨pθ(x) = ∂2/∂θ2pθ(x).
Diﬀerentiating the equality ˙θ(x) = ˙pθ(x)/pθ(x) with respect to θ gives
¨θ(x) = ¨pθ(x)
pθ(x) −
 ˙pθ(x)
pθ(x)
2
= ¨pθ(x)
pθ(x) −˙θ(x)2.
We multiply this by pθ(x) and take the integral with respect to x to ﬁnd that
Eθ¨θ(X1) =

¨pθ(x) dx −

˙θ(x)2pθ(x) dx
= 0 −Eθ
 ˙θ(X1)2
= −varθ ˙θ(X1) = −iθ,
because varθ ˙θ(X1) = Eθ
 ˙θ(X1)2
−(Eθ ˙θ(X1))2 = Eθ
 ˙θ(X1)2
, by the ﬁrst
assertion. This proves the second assertion.
184

5.4: Maximum Likelihood Estimators as Near-Pivots
Example 5.11 Poisson distribution
Let X = (X1, . . . , Xn) be a sample from the Poisson(θ)-distribution, where θ > 0
is unknown. The maximum likelihood estimator for θ is ˆθ = X provided X > 0. The
score function is equal to
˙θ(x) = ∂
∂θ log e−θθx
x!
= x
θ −1.
The Fisher information is then
iθ = varθ
X1
θ −1

= 1
θ.
By Lemma 5.10, we would have found the same expression using the equation
iθ = −Eθ¨θ(X1) = EθX1
θ2
= 1
θ .
If we estimate θ by X, then the plug-in estimator for iθ is equal to 1/X. The
observed information gives the same estimator since
−1
n
n

i=1
¨ˆθ(Xi) = 1
n
n

i=1
Xi
ˆθ2 =
X
(X)2 = 1
X .
The symmetric approximate conﬁdence interval of conﬁdence level 1 −α is then
θ = X ±
√
X
√n ξ1−α/2.
We could also have found this interval by a more direct route, by applying the central
limit theorem to X. After all, the sequence √n(X −θ)/
√
θ is approximately standard
normally distributed (see Example A.30).
Example 5.12 Cauchy distribution
Let X1, . . . , Xn be independent variables with probability density
pθ(x) =
1
π(1 + (x −θ)2).
The log-likelihood equation is
n

i=1
2(Xi −θ)
1 + (Xi −θ)2 = 0.
This equation cannot be solved explicitly for θ. Therefore, the maximum likelihood
estimator cannot be written as an explicit function of X1, . . . , Xn. However, the
estimator can be determined numerically, for example by reading the position of the
maximum in a graph of the log-likelihood function; see for example Figure 5.3. The
score function is
˙θ(x) =
2(x −θ)
1 + (x −θ)2 .
185

5: Conﬁdence Regions
The Fisher information can be computed with some diﬃculty if iθ = 1/2; it is constant
as a function of θ, and therefore easily estimated to be 1/2. The observed information
is not exactly equal to 1/2; it takes on the form
iθ = 1
n
n

i=1
2 −2(Xi −ˆθ)2

1 + (Xi −ˆθ)22 ,
where ˆθ is the maximum likelihood estimator.
-200
-100
0
100
-300
-250
-200
-150
-100
Figure 5.3. A realization of the Cauchy log-likelihood function. The curvature in the top is the
observed information.
Example 5.13 Exponential distribution
Let X
=
(X1, . . . , Xn) be a sample from the exponential distribution with
unknown parameter λ. The maximum likelihood estimator for λ is ˆλ = 1/X (see
Example 3.12). The score function is equal to
˙λ(x) = ∂
∂λ log λe−λx = 1
λ −x,
and the Fisher information is
iλ = varλ
 1
λ −X1

= 1
λ2 .
By Lemma 5.10, the Fisher information can also be found using the equation iλ =
−Eλ¨λ(X1) = 1/λ2. If λ is estimated by the maximum likelihood estimator, then the
plug-in estimator for iλ is equal to (X)2. The observed information gives the same
estimator for iλ:
−1
n
n

i=1
¨ˆλ(Xi) = 1
n
n

i=1
1
ˆλ2 = X2.
186

5.4: Maximum Likelihood Estimators as Near-Pivots
For both estimators for iλ, we ﬁnd the symmetric approximate conﬁdence interval
λ = 1
X ±
1
√nX ξ1−α/2
for λ of conﬁdence level 1 −α.
* 5.4.1 Proof of Theorem 5.9
The proof of Theorem 5.9 consists of two parts: a proof of consistency and a proof of
convergence in distribution. The estimator ˆθn = ˆθn(X1, . . . , Xn) is called consistent
for θ if ˆθn converges in probability to θ, that is, ˆθn
P→θ under θ as n →∞. We
give a complete proof for the ﬁrst part, in the form of a lemma, but only prove the
second part under stronger conditions than those of Theorem 5.9. For a complete proof
of the theorem under weaker conditions than in the theorem, we refer to the book
"Asymptotic Statistics" (Van der Vaart (1998)).
The proofs of both parts are based on an analysis of the following stochastic
function and its expectation:
Mn(ϑ) = 1
n
n

i=1
ϑ(Xi),
M(ϑ) = Eθϑ(X1).
Note that the argument ϑ of these functions diﬀers from the "true" parameter θ
that determines the distribution of the observations and that we use to compute the
expectation Eθ. (Under the conditions of Theorem 5.9, the variable (ϑ −θ)(X1)
has a ﬁnite ﬁrst moment, so that M(ϑ) −M(θ) = Eθ(ϑ −θ)(X1) is always well
deﬁned. If this is not the case for M(ϑ) itself, then we replace ϑ in the deﬁnitions of
Mn and M and everywhere in the lemma and proof below by ϑ −θ; to simplify the
notation, we refrain from doing this.)
Lemma 5.14 Consistency
Suppose that Θ ⊂Rk is compact and convex and that θ is identiﬁable. Suppose,
moreover, that the map ϑ →log pϑ(x) is continuously diﬀerentiable for all x with
gradient ˙ϑ(x) such that  ˙ϑ(x) ≤L(x) for every ϑ ∈Θ, where L is a function
with EθL2(X1) < ∞. Then ˆθn P→θ under θ as n →∞.
Proof. The proof of the consistency is based on the following two assertions:
(i) The map ϑ →M(ϑ) is continuous with unique absolute maximum in θ.
(ii) The sequence Δn: = supϑ∈Θ
Mn(ϑ) −M(ϑ)
 converges in probability to 0.
187

5: Conﬁdence Regions
Suppose that parts (i)-(ii) hold. It follows from the deﬁnition of ˆθn that Mn(ˆθn) ≥
Mn(θ). If we twice replace Mn in this inequality by M, then it follows from part (ii)
that M(ˆθn) ≥M(θ)−2Δn. For any given δ > 0, the closed subset {ϑ ∈Θ: ϑ−θ ≥
δ} of Θ is compact. The continuous function M takes on its maximum in this set, and
that maximum is less than its value in θ, where M has a unique absolute maximum.
For any given δ > 0, there hence exists an ε > 0 with M(ϑ) < M(θ) −ε for all
ϑ with ϑ −θ ≥δ. Inverting this statement gives that M(ϑ) ≥M(θ) −ε implies
ϑ −θ < δ. We conclude from M(ˆθn) ≥M(θ) −2Δn that ˆθn −θ < δ as soon
as 2Δn ≤ε. By part (ii), the latter has probability converging to 1. We therefore have
ˆθn −θ < δ with probability converging to 1, thus proving the consistency of ˆθn.
We now need to prove parts (i)-(ii). For the proof of part (i), we apply the mean
value theorem to see that for every ϑ1 and ϑ2, there exists a value ˜ϑ between ϑ1 and
ϑ2 such that ϑ1(x) −ϑ2(x) = (ϑ1 −ϑ2) ˙ ˜ϑ(x). It follows that
(5.1)
ϑ1(x) −ϑ2(x)
 ≤ϑ1 −ϑ2 L(x).
If we replace x by X1 and take the expectation under θ, we ﬁnd |M(ϑ1) −M(ϑ2)| ≤
ϑ1−ϑ2 EθL(X1), where EθL(X1) is ﬁnite by assumption. (Note that |EY | ≤E|Y |
for every variable Y .) This proves the continuity of M. For the uniqueness of the
maximum, we use that log x ≤2(√x −1) for all x > 0, so that
M(ϑ) −M(θ) = Eθ

log pϑ
pθ
(X1)

≤2Eθ
pϑ
pθ
(X1) −1

= 2
 √pϑ(x)√pθ(x) dx −2 = −
 √pϑ(x) −√pθ(x)
2 dx.
The integral on the right-hand side is strictly positive when ϑ = θ unless the densities
pϑ and pθ are the same, which is excluded by the assumption that the parameter θ is
identiﬁable. This proves part (i).
For the proof of part (ii), we ﬁx a δ > 0. By the assumed compactness, we
can cover Θ with ﬁnitely many balls of radius δ; denote the centers of the balls by
ϑ1, . . . , ϑk. For a given ϑ ∈Θ, there then exists a ϑj such that ϑ −ϑj < δ. Using
(5.1), we ﬁnd that
Mn(ϑj) −δ 1
n
n

i=1
L(Xi) ≤Mn(ϑ) ≤Mn(ϑj) + δ 1
n
n

i=1
L(Xi),
M(ϑj) −δEθL(X1) ≤M(ϑ) ≤M(ϑj) + δEθL(X1).
Subtracting the second equation from the ﬁrst, we ﬁnd lower and upper bounds for
Mn(ϑ)−M(ϑ), and therefore also for the absolute value of this diﬀerence. If we then
take the supremum over ϑ, we ﬁnd
sup
ϑ
Mn(ϑ) −M(ϑ)
 ≤max
j
Mn(ϑj) −M(ϑj)
 + δ 1
n
n

i=1
L(Xi) + δEθL(X1).
188

5.4: Maximum Likelihood Estimators as Near-Pivots
It is important that the maximum on the right concerns a ﬁnite set of indices j. For
every ﬁxed j, we have Mn(ϑj)−M(ϑj) P→0 as n →∞, by the law of large numbers
(Theorem A.26). The maximum over j therefore converges in probability to 0.
Applying the law of large numbers again, we see that n−1n
i=1L(Xi) P→EθL(X1)
as n →∞. We conclude that the right-hand side of the last display converges in
probability to 2δ EθL(X1) as n →∞. This is true for every δ > 0. Hence the left-
hand side converges in probability to 0. This concludes the proof of part (ii).
We have now proved that ˆθn
P→θ as n →∞, and continue with a proof that
√n(ˆθn −θ) converges in distribution to a normal distribution.
Since, by assumption, θ is an interior point of Θ and ˆθn
P→θ as n →∞, we
know that ˆθn has probability converging to 1 of also being an interior point of Θ. In
that case, ˆθn satisﬁes the likelihood equation ˙Mn(ˆθn) = 0, where the dot means ∂/∂θ.
The mean value theorem gives the existence of a point ˜θn between ˆθn and θ such that
0 = ˙Mn(ˆθn) = ˙Mn(θ) + (ˆθn −θ) ¨Mn(˜θn).
We deduce from this that
√n(ˆθn −θ) = −
√n ˙Mn(θ)
¨Mn(˜θn)
= −n−1/2n
i=1 ˙θ(Xi)
n−1n
i=1¨˜θn(Xi)
.
By Lemma 5.10, we have Eθ ˙θ(X1) = 0; moreover, varθ ˙θ(X1) is by deﬁnition
equal to the Fisher information iθ. By the central limit theorem, the numerator
−n−1/2n
i=1 ˙θ(Xi) of the fraction on the right-hand side converges in distribution
to an N(0, iθ)-distribution. The denominator of the fraction is an average of the
variables ¨˜θn(Xi). Since ˜θn is stochastic and depends on all observations X1, . . . , Xn,
these variables are not independent, and therefore the law of large numbers cannot
be applied as it is. However, ˜θn
P→θ as n →∞, and below we prove that
n−1n
i=1¨˜θn(Xi) behaves like the average n−1n
i=1¨θ(Xi), which does satisfy the
law of large numbers, By Lemma 5.10, the limit satisﬁes Eθ¨θ(X1) = −iθ, hence
we can conclude that n−1n
i=1¨˜θn(Xi)
P→−iθ as n →∞. By Slutsky's lemma,
Lemma 5.15, we therefore conclude that √n(ˆθn −θ) converges in distribution to
(1/iθ) times an N(0, iθ)-distributed variable, that is, to a variable with the N(0, i−1
θ )-
distribution.
For a proof that n−1n
i=1(¨˜θn(Xi) −¨θ(Xi))
P→0 as n →∞, we now also
assume the existence of a third-order derivative of ϑ →ϑ(x) such that |˙¨ϑ(x)| ≤
K(x) for every x and every ϑ in a neighborhood of θ, where K is a function satisfying
EθK(X1) < ∞. Applying the mean value theorem to the second-order derivative then
gives
¨ϑ(x)−¨θ(x)
 ≤K(x)|ϑ−θ| for all x and all ϑ with |ϑ−θ| ≤ε and suﬃciently
small ε. Consequently, for every δ > 0, we have
(5.2)
Pθ
 1
n
n

i=1
¨˜θn(Xi) −¨θ(Xi)
 > δ, |˜θn −θ| ≤ε

≤Pθ
 1
n
n

i=1
K(Xi) |˜θn −θ| > δ

.
189

5: Conﬁdence Regions
By the law of large numbers, the factor n−1n
i=1K(Xi) converges in probability
to EθK(X1)
<
∞. This implies the existence of a constant M such that
Pθ

n−1n
i=1K(Xi) ≤M

→1. Combining this with the inequality Pθ

|˜θn −θ| >
δ/M

→0 shows that the right-hand side of (5.2) converges to 0. The same then
holds for the left-hand side. Since ˜θn P→θ as n →∞, this remains true when we drop
the restriction |˜θn −θ| ≤ε.
The only part of the proof of the asymptotic normality of √n(ˆθn −θ) we still
need to do in detail consists of the statements of Lemma 5.10. Solidifying the given
proof of Lemma 5.10 requires further conditions to justify diﬀerentiating under the
integral sign. We can also prove the statements in a roundabout way under the existing
conditions (see the proof of Theorem 5.39 in Van der Vaart (1998)). It is remarkable
that Theorem 5.9 does not assume the existence of the second-order derivative ¨ϑ, so
that the statements of Lemma 5.10 are certainly not necessary for a proof; the same
holds for the existence of third-order derivatives. We will not discuss this any further.
Lemma 5.15 Slutsky's lemma
Let Sn and Tn be random variables or vectors with Sn
P→σ for a constant σ and
Tn ⇝T as n →∞. Then
(i) Sn + Tn ⇝σ + T as n →∞;
(ii) if σ = 0, then Tn/Sn ⇝T/σ as n →∞.
In part (i), the "constant" σ and T must be vectors of the same length. Part (ii) is
true when σ is a scalar but also holds for matrices σ. In the latter case, σ = 0 means
that σ is invertible, and dividing by σ means multiplying by its inverse.
Proof. The inequality Sn −σ ≤ε implies σ −ε ≤Sn ≤σ + ε. If σ > 0, then we
can choose ε suﬃciently small that σ −ε > 0. In that case, the inequality Tn/Sn ≤x
implies Tn ≤x(σ + ε), and Tn ≤x(σ −ε) implies Tn/Sn ≤x. We conclude that
P

Tn ≤x(σ −ε), Sn −σ ≤ε

≤P

Tn/Sn ≤x, Sn −σ ≤ε

≤P

Tn ≤x(σ + ε), Sn −σ ≤ε

.
Since P

Sn −σ > ε

→0, the three probabilities in this equation change at most
by a term that converges to 0 if we drop the restriction Sn −σ ≤ε. By applying
the convergence Tn ⇝T to the ﬁrst and third probabilities, we conclude that the limit
(or lim inf and lim sup) of P(Tn/Sn ≤x) is asymptotically sandwiched between
P

T ≤x(σ −ε)

and P

T ≤x(σ + ε)

, for every x and ε such that x(σ −ε) and
x(σ + ε) are continuity points of x →P(T ≤x). Since a distribution function can
have at most countably many discontinuity points, there exists a sequence εm →0
such that x(σ −εm) and x(σ + εm) are continuity points for every m. If x is a
continuity point of T/σ, then xσ is a continuity point of T , and P

T ≤x(σ −εm)

and P

T ≤x(σ + εm)

both converge to P(T/σ ≤x). The sequence P(Tn/Sn ≤x)
then has the same limit.
The proof of part (ii) when σ < 0 and the proof of part (i) are analogous.
190

5.4: Maximum Likelihood Estimators as Near-Pivots
* 5.4.2 Multidimensional Parameters
The above can be extended to the case where the parameter θ is a vector of dimension
k > 1. The score function is then deﬁned as the gradient
˙θ(x) = ∇θ log pθ(x) =
 ∂
∂θ1
θ(x), . . . , ∂
∂θk
θ(x)

.
The Fisher information is generalized to a (k × k)-matrix
iθ =

covθ
 ∂
∂θi
θ(X1), ∂
∂θj
θ(X1)

i,j=1,. . .k
.
Theorem 5.9 remains valid, but √n(ˆθ −θ) is a random vector and its limit distribution
is a multivariate normal distribution (see Appendix B). The statement of the "theorem"
must be understood in the sense that the near-pivot (niθ)1/2(ˆθ −θ) is approximately
distributed as a vector Z = (Z1, . . . , Zk) of k independent N(0, 1)-distributed
variables.‡
The quadratic form
(ˆθ −θ)T niθ(ˆθ −θ) =
√ni1/2
θ
(ˆθ −θ)
T √ni1/2
θ
(ˆθ −θ)
then approximately has the same distribution as ZT Z = k
i=1Z2
i , that is, a χ2
k-
distribution (see Section 4.6). For iθ an estimator for the matrix iθ, the set

θ: (ˆθ −θ)T niθ(ˆθ −θ) ≤χ2
k,1−α

is therefore a conﬁdence region of asymptotic conﬁdence level 1 −α (for large n).
Geometrically, this set is an ellipsoid in the k-dimensional space, because the Fisher
information matrix iθ is positive deﬁnite.
Often, we are only interested in a function g(θ) of a higher-dimensional
parameter. Theorem 5.9 can be extended to that case.
Theorem 5.16
Take the situation of Theorem 5.9, but with parameter θ ∈Θ ⊂Rk and a ﬁnite,
invertible Fisher information matrix. For a diﬀerentiable function g: Θ →R with
gradient g, under θ, we have
√n

g(ˆθ) −g(θ)

⇝N

0, g(θ)i−1
θ g(θ)T 
as n →∞.
‡ By (iθ)1/2, we mean a matrix A of the same dimension as iθ such that AT A = iθ.
191

5: Conﬁdence Regions
Proof. The proof consists of two parts. First, Theorem 5.9 holds, precisely as
stated, for multidimensional parameters, where the limit distribution N(0, i−1
θ ) is the
multivariate normal distribution, with covariance the inverse of the Fisher information
matrix. Next, we apply the "delta method" to determine the limit distribution of
√n

g(ˆθ)−g(θ)

. This method corresponds to using the fact that this sequence has the
same limit distribution as the ﬁrst-order Taylor expansion √ng(θ)(ˆθ −θ) at θ. Since
√n(ˆθ −θ) ⇝Z as n →∞, for a normally distributed vector Z with expectation
0 and covariance matrix i−1
θ , we have √ng(θ)(ˆθ −θ) ⇝g(θ)Z as n →∞. The
random variable g(θ)Z has a normal distribution, as in the theorem, because of the
properties of the multidimensional normal distribution (see Lemma B.4). A precise
justiﬁcation of the delta method can be found in Chapter 3 of Van der Vaart (1998).
In particular, the ﬁrst coordinate of θ = (θ1, . . . , θk) corresponds to the function
g(θ) = θ1 and gradient g(θ) = (1, 0, . . . , 0). The asymptotic variance of √n(ˆθ1−θ1)
is therefore equal to (i−1
θ )(1,1), the (1, 1)-element of the inverse matrix i−1
θ
(not to be
confused with 1 divided by the (1, 1)-element of iθ). For θ1, we use the conﬁdence
interval
θ1 = ˆθ1 ±
(iθ
−1)1/2
(1,1)
√n
ξ1−α/2.
If θ2, . . . , θk are known and therefore do not need to be estimated, we have a
one-dimensional estimation problem. We saw in Theorem 5.9 that in this case the
asymptotic variance of √n(ˆθ1 −θ1) is equal to 1 divided by the Fisher information
for the one-dimensional estimation problem. This value is equal to (iθ,(1,1))−1, that
is, 1 divided by the (1, 1)-element of the Fisher matrix iθ in the multidimensional
problem above. In general, we have (iθ−1)(1,1) ≤(iθ,(1,1))−1. This means that when
θ2, . . . , θk are unknown, there is loss of information and θ1 cannot be estimated as
precisely, resulting in a greater asymptotic variance and a longer conﬁdence interval
for θ1. In some cases (see Example 5.18), the Fisher information matrix is a diagonal
matrix. We then have (iθ,(1,1))−1 = (iθ−1)(1,1), and not knowing the other parameters
does not lead to any loss of information.
Example 5.17 Multinomial distribution
Let Y
=
(Y1, . . . , Ym) be multinomially distributed with parameters n and
(p1, . . . , pm); see Example 4.48. We assume n known and the probabilities p1, . . . , pm
unknown. The sum of the probabilities is m
i=1 pi = 1, and therefore pm =
1 −(p1 + . . .+ pm−1). Since pm is ﬁxed whenever p1, . . . , pm−1 are known, we have
a (m −1)-dimensional estimation problem. Let p = (p1, . . . , pm−1) be the vector
of the unknown parameters. We want to construct an approximate conﬁdence region
for p based on the asymptotic distribution of the maximum likelihood estimator for p.
The maximum likelihood estimator for p maximizes the log-likelihood function of the
model; this function is given by
p →log

n
Y1 · · · Ym

+
m

i=1
Yi log pi.
192

5.4: Maximum Likelihood Estimators as Near-Pivots
The maximum likelihood estimator for p relative to its parameter space {p ∈
Rm−1: pi ≥0, m−1
i=1 pi ≤1} is equal to the vector (Y1/n, Y2/n, . . . , Ym−1/n)
(see Exercise 3.15).
In this section, we study the situation where were have a sample of size n.
In the multinomial model, we in fact have only one observation (Y1, . . . , Ym),
but we can also view this observation as a sum of n independent, identically
distributed subobservations Xk for k = 1, . . . , n with Xk multinomially distributed
with parameters 1 and (p1, . . . , pm). We write Xk = (Xk,1, . . . , Xk,m), so that
n
k=1Xk = Y , where the sum is coordinate-wise. For this model, the maximum
likelihood estimators for the parameters p1, . . . , pm are the same as in the multinomial
model. This follows from the fact that the log-likelihood functions are equal up to the
ﬁrst term in the log-likelihood of Y , and this term does not depend on the unknown
parameters. To illustrate the theory in this section, we assume that we observe the
sample X1, . . . , Xn. The score function of the model is given by the vector
X1,1
p1
−X1,m
pm
, . . . , X1,m−1
pm−1
−X1,m
pm

.
A simple computation gives varp X1,i = pi(1 −pi) and covp(X1,i, X1,j) = −pipj
for i = j. The (i, j)-element of the Fisher information matrix ip is therefore given by
(ip)i,j = 1/pi + 1/pm
for i = j and
(ip)i,j = 1/pm
for i = j.
We can estimate the unknown parameters p1, . . . , pm−1 in the Fisher information
matrix by the maximum likelihood estimators ˆp1, . . . , ˆpm−1. The approximate
conﬁdence region for p of conﬁdence level 1 −α is now equal to

p: (ˆp −p)T nip(ˆp −p) ≤χ2
m−1,1−α

,
with ˆp the maximum likelihood estimator for the parameter p and ip the estimated
Fisher information matrix.
Suppose that we are only interested in estimating p1. We apply Theorem 5.16,
but now with g(p) = p1 and gradient g(p) = (1, 0, . . . , 0). It immediately follows
that under the assumption that p1 is the true parameter, as n →∞, we have
√n(ˆp1 −p1) ⇝N(0, (i−1
p )(1,1)),
with variance equal to the (1,1)-element of the inverse Fisher information matrix i−1
p .
The (i, j)-element of this matrix is equal to
(i−1
p )(i,j) = pi(1 −pi)
for i = j and
(i−1
p )(i,j) = −pipj
for i = j.
Note that the ith diagonal element, pi(1 −pi), is equal to varp X1,i and the (i, j)-
element of i−1
p
is equal to covp(X1,i, X1,j). In short, √n(ˆp1 −p1) is asymptotically
normally distributed with expectation 0 and variance p1(1 −p1) = varp X1,1. To
estimate the variance, we can again replace p1 by the maximum likelihood estimator.
An approximate conﬁdence interval of conﬁdence level 1 −α is then equal to
p1 = ˆp1 ± ˆp1(1 −ˆp1)
√n
ξ1−α/2.
193

5: Conﬁdence Regions
If we are only interested in estimating the parameter p1, we could also have
reduced the multinomial model to a binomial model with parameters n and p1. We
do not need to estimate the unknown parameters p2, . . . , pm individually; the sum
p2 + . . . + pm = 1 −p1 suﬃces. A simple computation shows that we ﬁnd the same
approximate conﬁdence interval.
Example 5.18 Normal distribution
Let X = (X1, . . . , Xn) be a sample from the normal distribution with unknown
parameters μ and σ2. We want to determine a conﬁdence interval for μ.
In Example 5.4, we constructed an exact conﬁdence interval of conﬁdence level
1 −α based on the tn−1-distributed random variable √n(X −μ)/SX. This interval
is given by
μ = X ± SX
√ntn−1,1−α/2.
As an alternative, we could also have taken the exact conﬁdence interval from
Example 5.2 and replaced the parameter σ2, which was assumed known, by its
estimator S2
X. We then ﬁnd an approximate conﬁdence interval of conﬁdence level
1 −α:
μ = X ± SX
√nξ1−α/2.
The only diﬀerence with the interval from Example 5.4 is the quantiles. For large n,
there is hardly any diﬀerence between the quantiles of the tn−1-distribution and those
of the standard normal distribution, and the intervals will be approximately equal.
When σ2 is unknown, we can also construct an approximate conﬁdence interval
for μ based on the asymptotic distribution of the maximum likelihood estimator for μ.
Because σ is unknown, we are dealing with a two-dimensional estimation problem.
The score function of the model is given by
˙(μ,σ2)(X1) =
X1 −μ
σ2
, (X1 −μ)2
2σ4
−
1
2σ2
T
=
Z
σ , Z2
2σ2 −
1
2σ2
T
,
where we use the abbreviation Z = (X1 −μ)/σ and Z has the standard normal
distribution. The diagonal elements of the Fisher information matrix are then equal to
var(μ,σ)
Z
σ

= 1
σ2 ,
var(μ,σ)
 Z2
2σ2 −
1
2σ2

=
1
4σ4 var(μ,σ) Z2 =
1
2σ4 ,
since Z2 has the χ2
1-distribution with variance 2. The (1, 2)- and the (2, 1)-elements
of the symmetric Fisher information matrix are equal to
cov(μ,σ)
Z
σ , Z2
2σ2

=
1
2σ3 cov(μ,σ)

Z, Z2
= 0,
194

5.5: Conﬁdence Regions and Tests
where the last equality follows from cov(Z, Z2) = EZ3 −EZ EZ2 = 0 because the
ﬁrst and third moments of the standard normal distribution are equal to 0. The Fisher
information matrix is therefore equal to
i(μ,σ2) =

1/σ2
0
0
1/(2σ4)

.
Since the Fisher information matrix is a diagonal matrix, we can easily determine its
inverse by inverting the diagonal elements:
i−1
(μ,σ2) =

σ2
0
0
2σ4

.
We can again estimate the unknown variance σ2 using the sample variance S2
X. We
then ﬁnd the approximate conﬁdence interval for μ using Theorem 5.16,
μ = X ± SX
√nξ1−α/2.
This is the same approximate interval as at the beginning of this example.
The Fisher information matrix in this example is a diagonal matrix. In this
speciﬁc case, we have (i−1
(μ,σ2))(1,1) = (i(μ,σ2),(1,1))−1; knowing σ2 or not does not
have any inﬂuence on the length of the approximate conﬁdence interval for μ, up to
the estimation of σ2.
5.5 Conﬁdence Regions and Tests
Conﬁdence intervals and tests are closely related. A given set of tests for the problems
H0: g(θ) = τ automatically deﬁnes a conﬁdence region for g(θ) and conversely.
Theorem 5.19
Suppose that for every τ ∈g(Θ), we are given a test of level α for the null hypothesis
H0: g(θ) = τ (with a critical region that depends only on τ). Then the set of all values
τ that are not rejected in testing is a conﬁdence region for g(θ) of conﬁdence level
1 −α.
Conversely, given a conﬁdence region GX for g(θ) of conﬁdence level 1 −α,
the critical region {x: τ /∈Gx} gives a test of conﬁdence level 1 −α for the null
hypothesis H0: g(θ) = τ, for all τ ∈g(Θ).
Proof. For τ ∈g(Θ), we deﬁne the set Θτ = {θ ∈Θ: g(θ) = τ}, so that H0: g(θ) =
τ is equivalent to H0: θ ∈Θτ.
195

5: Conﬁdence Regions
In the ﬁrst part of the theorem, we are given, for every τ ∈g(Θ), a critical
region Kτ of a test of level α for H0: θ ∈Θτ, and the conﬁdence region we have
in mind for g(θ) is the set GX =

τ: X /∈Kτ

. That this test has level α means
that Pθ(X ∈Kτ) ≤α for all θ ∈Θτ, for every given τ. Since τ = g(θ) for every
θ ∈Θτ, we therefore also have Pθ(X ∈Kg(θ)) ≤α for every θ ∈Θ. It follows from
the deﬁnition of GX that g(θ) ∈GX if and only if X /∈Kg(θ). The ﬁrst statement of
the theorem now follows from Pθ

g(θ) ∈GX

= Pθ(X /∈Kg(θ)) ≥1 −α, for all
θ ∈Θ.
In the second part, we are given a conﬁdence region GX for g(θ), and the test
we have in mind for the null hypothesis H0: θ ∈Θτ has critical region Kτ = {x: τ /∈
Gx}. That GX has size α means that Pθ(g(θ) ∈GX) ≥1−α for all θ ∈Θ. It follows
from the deﬁnition of Kτ that X ∈Kτ if and only if τ /∈GX. For θ ∈Θτ, we have
g(θ) = τ, and therefore Pθ(X ∈Kτ) = Pθ(X ∈Kg(θ)) = Pθ(g(θ) /∈GX) ≤α.
We conclude that the test with critical region Kτ has size α. This proves the second
part of the theorem.
At ﬁrst sight, applying this theorem seems a diﬃcult way to construct a
conﬁdence interval: we must test the hypothesis H0: g(θ) = τ for every τ. This can
indeed be much work, but in some standard cases, it is quite easy.
Example 5.20 Normal distribution
Let X = (X1, . . . , Xn) be a sample from the N(μ, σ2)-distribution with unknown
parameters μ and σ2. The t-test does not reject the null hypothesis H0: μ = μ0 at
level α when
−tn−1,1−α/2 ≤√nX −μ0
SX
≤tn−1,1−α/2.
This is equivalent to the inequalities
X −SX
√ntn−1,1−α/2 ≤μ0 ≤X −SX
√ntn−1,α/2.
By Theorem 5.19, the conﬁdence interval of conﬁdence level 1−α for μ is then equal
to
μ = X ± SX
√ntn−1,1−α/2.
We had already found this conﬁdence interval in a diﬀerent way.
* Example 5.21 Exponential distribution
Let X1, . . . , Xn be a sample from the exponential distribution with unknown
parameter λ. An approximate conﬁdence interval of conﬁdence level 1 −α for λ
is
λ = 1
X ±
1
√nX ξ1−α/2;
196

5.5: Conﬁdence Regions and Tests
see Example 5.13. By Theorem 5.19, the test that rejects the null hypothesis H0: λ =
λ0 when λ0 is not in this conﬁdence interval is a test for H0: λ = λ0 against the
alternative H1: λ = λ0 of approximate size α. This test corresponds to the Wald test;
see Section 4.8.
Example 5.22 Binomial distribution
Let X be binomially distributed with unknown parameter p and known n. We can
determine an "exact" conﬁdence interval for p by inverting the exact test for H0: p =
p0 discussed in Example 4.24. The best way to do this is to use the test in terms of
p-values. The null hypothesis H0: p = p0 is rejected at size α if, for an observed
value x,
Pp0(X ≥x) ≤1
2α
or
Pp0(X ≤x) ≤1
2α.
The conﬁdence region for the observed value x is therefore the set

p: Pp(X ≥x) > 1
2α
and
Pp(X ≤x) > 1
2α

.
For x ≥1, the function p →Pp(X ≥x) is a continuous function of p that is strictly
increasing from the value 0 in p = 0 to 1 in p = 1; see Figure 5.4. Consequently, the
set

p: Pp(X ≥x) > 1
2α

is equal to (pl, 1], where pl is the solution of the equation
Ppl(X ≥x) = 1
2α.
On the other hand, for x ≤n −1, the function p →Pp(X ≤x) is a continuous
function that is strictly decreasing from 1 in p = 0 to 0 in p = 1. Consequently, the
set

p: Pp(X ≤x) > 1
2α

is equal to [0, pr), where pr is the solution of the equation
Ppr(X ≤x) = 1
2α.
The desired conﬁdence interval is the intersection (pl, pr) of the two intervals we
found.
If x = 0, then Pp(X ≥x) = 1 for every p, and the equation for pl does not have
any solutions. The conﬁdence interval is then [0, pr). If x = n, then Pp(X ≤x) =
1 for every p, and the equation for pr does not have any solutions. The conﬁdence
interval is then (pl, 1].
The values pl and pr can be solved from the equations using tables or the
computer, or even using the normal approximation (though this goes against the aim
to have an "exact" interval). For example, for α = 0.05, n = 20, and x = 13, the table
gives
P0.84(X ≤13) = 0.03037
P0.85(X ≤13) = 0.02194
⇒pr ≈0.845.
Likewise, we ﬁnd pl ≈0.405, so that the exact conﬁdence interval is (0.405, 0.845).
This interval is indicated in Figure 5.4.
197

5: Conﬁdence Regions
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Figure 5.4. Conﬁdence interval for the binomial distribution. The graph shows the functions
p →Pp(X ≥x) (increasing) and p →Pp(X ≤x) (decreasing) for n = 20 and x = 13 and a dashed
line at height 0.025. The 95% conﬁdence interval contains the values between the intersection
points of the curves with the dashed line.
5.6 Likelihood Ratio Regions
The procedure to deduce conﬁdence regions from tests is, in particular, often applied to
the likelihood ratio test. This test rejects the null hypothesis H0: θ = τ for large values
of the likelihood ratio statistic pˆθ(X)/pτ(X), for ˆθ the maximum likelihood estimator
for θ. In many cases, we use the chi-square approximation to ﬁnd a critical value
(compare with Theorem 4.43). The likelihood ratio test rejects the null hypothesis
H0: θ = τ concerning a k-dimensional parameter when 2 log(pˆθ(X)/pτ(X)) ≥
χ2
k,1−α, for χ2
k,1−α the (1 −α)-quantile of the χ2
k-distribution (this result is a
generalization of the one-dimensional restriction in Example 4.45, which can be
extended to a k-dimensional restriction). The procedure in Theorem 5.19 leads to the
conﬁdence region

θ: log pθ(X) −log pˆθ(X) ≥−1
2χ2
k,1−α

.
The "inversion of the likelihood ratio test" has the intuitively attractive property that
the conﬁdence region contains those values of the parameter θ that maximize the
likelihood function.
We can visualize the conﬁdence region using a plot of the log-likelihood function
minus its maximum: minus the log-likelihood ratio θ →log pθ(x) −log pˆθ(x). For
a one-dimensional parameter, this is a function with a "normal," two-dimensional
graph. If we draw a horizontal line at height −1
2χ2
1,1−α, then the conﬁdence regions
consists precisely of the values of θ where minus the log-likelihood ratio statistic rises
above the horizontal line (see Figure 5.5 for an illustration). For multidimensional
parameters, the log-likelihood function is a hypersurface, and the conﬁdence region
is the set of values where the hypersurface rises above height −1
2χ2
k,1−α, for k the
dimension of the parameter.
198

5.6: Likelihood Ratio Regions
It is clear from the graphical description of the conﬁdence region that the
maximum likelihood estimate always lies in the conﬁdence region, and that the form
of this region is determined by the form of the likelihood function. In particular, a
likelihood ratio conﬁdence region is not necessarily symmetric about the maximum
likelihood estimator; see Figure 5.5 as an illustration. In general, the asymmetry, when
it occurs, is viewed as desirable, as an expression of a diﬀerent measure of uncertainty
over the parameter in diﬀerent directions. Note, however, that the likelihood ratio
surface may have several local maxima, and that in extreme situations, this can lead
to a conﬁdence region that consists of more than one disconnected component. It is
unclear whether disconnected conﬁdence regions are desirable.
0
2
4
6
8
−30
−25
−20
−15
−10
−5
0
Figure 5.5. Minus the log-likelihood ratio statistic as a function of θ for a sample of size 4 from
the Poisson distribution with expectation 1. The dotted line is at height −1
2 χ2
1,0.95. The values of
θ for which the curve rises above the line belong to the approximate 95% conﬁdence interval.
Example 5.23 Exponential distribution
Let X = (X1, . . . , Xn) be a sample from the exponential distribution with unknown
parameter λ > 0. The log-likelihood function is then
λ →n log λ −λ
n

i=1
Xi,
and the maximum likelihood estimator for λ is ˆλ = 1/X (see Example 3.12). The set

λ: n log λ −λ
n

i=1
Xi −

n log ˆλ −ˆλ
n

i=1
Xi

≥−1
2χ2
1,1−α

=

λ: n log λ −λ
n

i=1
Xi + n log X + n ≥−1
2χ2
1,1−α

is then the approximate conﬁdence region for λ based on the likelihood ratio test of
size α.
199

5: Conﬁdence Regions
Often, we are interested in a conﬁdence region for a component θ1 of a higher-
dimensional parameter θ = (θ1, . . . , θk), instead of a region for the full parameter
vector θ. We can easily provide this using the likelihood ratio statistic, by inverting
the test for the hypothesis H0: θ1 = τ, instead of the hypothesis for the full parameter
used earlier (now with τ ∈R). The likelihood ratio test rejects the null hypothesis
H0: θ1 = τ for large values of the test statistic
2 log
supθ∈Θ pθ(X)
supθ∈Θ:θ1=τ pθ(X).
We can often choose the critical value equal to the (1 −α)-quantile of the chi-square
distribution with 1 degree of freedom, because the dimension k of the full model and
the dimension k0 = k −1 of the null hypothesis Θ0 = {θ: θ1 = τ} diﬀer by 1 (see
Example 4.45). The conﬁdence region for θ1 consists of the values of τ that have not
been rejected.
This conﬁdence region can be visualized using the so-called proﬁle likelihood
function.
Deﬁnition 5.24 Proﬁle likelihood
The proﬁle likelihood function is given by
L1(τ; X) =
sup
θ∈Θ:θ1=τ
pθ(X).
For a ﬁxed value of θ1, the proﬁle likelihood L1(θ1; X) is equal to the maximum
of the "usual" likelihood pθ(X) over the remaining parameters θ2, . . . , θk. By
maximizing the proﬁle likelihood θ1 →L1(θ1; X) with respect to θ1, we ﬁnd the
maximum of the "usual" likelihood over the full parameter; the maximum is taken
on in the maximum likelihood estimator ˆθ1 for θ1. (This procedure splits ﬁnding the
overall maximum of the likelihood in two steps but gives the same maximum.) The
likelihood ratio statistic for testing H0: θ1 = τ can therefore be written in the form
L1(ˆθ1; X)/L1(τ; X), and when we use the chi-square approximation, the conﬁdence
region for θ1 is of the form

θ1: log L1(θ1; X) −log L1(ˆθ1; X) ≥−1
2χ2
1,1−α

.
Using the proﬁle likelihood, we can visualize the likelihood ratio region for θ1 in a way
analogous to that used for the usual likelihood for the full parameters. We plot minus
the logarithm of the proﬁle likelihood ratio function, log L1(θ1; x) −log L1(ˆθ1; x),
and take as conﬁdence region the values of θ1 where the function rises above a certain
level.
This procedure can be extended to general functions g of the parameter θ by
deﬁning the proﬁle likelihood for g as the function τ →Lg(τ; X) given by
Lg(τ; X) =
sup
θ∈Θ:g(θ)=τ
pθ(X).
200

5.7: Bayesian Conﬁdence Regions
* Example 5.25 Application: compound Poisson process
In Example 3.22, we modeled the monthly payout by a health insurance company and
estimated the unknown parameters μ and θ using the maximum likelihood estimators.
Suppose that we want to construct a conﬁdence interval for θ. In Example 4.49, we
discussed the likelihood ratio test for testing H0: θ = θ0 against H0: θ = θ0. The test
statistic does not depend on the parameter μ and, under H0, asymptotically follows the
chi-square distribution with 1 degree of freedom. The approximate conﬁdence interval
for θ can now easily be deduced from the above.
* 5.7 Bayesian Conﬁdence Regions
The Bayesian approach gives an alternative way to quantify the uncertainty of an
estimate. In addition to a point estimator, this approach also gives the posterior
distribution. This distribution is an expression of the uncertainty we have about the
value of the parameter after carrying out the observation. The parameter value is
viewed as a random vector distributed following the posterior distribution.
If we want to express our uncertainty through a margin or region around a point
estimate, then a logical choice would be a region with probability 1 −α under the
posterior distribution. This is not uniquely determined, but in general, we will choose
a symmetric region or the smallest possible region with this property.
This way of constructing an uncertainty margin is completely diﬀerent from the
methods discussed previously, and there is no guarantee that such a Bayesian region is
also a conﬁdence region in the sense of Deﬁnition 5.1. To express this diﬀerence, we
speak of a credible region instead of a conﬁdence region. We can show that in many
cases, a credible region based on a large sample is approximately a conﬁdence region
in the usual sense.
The reason for this phenomenon is that Bayesian estimators are asymptotically
normally distributed, and that the diﬀerences with maximum likelihood estimators
disappear as the number of observations increases. A credible region is therefore
asymptotically the same as the conﬁdence region based on the maximum likelihood
estimator, discussed in Section 5.4. The basic theorem that explains this is the
Bernstein-von Mises theorem, according to which a posterior distribution is asymp-
totically a normal distribution centered in the maximum likelihood estimator. For
simplicity, we again restrict ourselves to the case where the observation X
=
(X1, . . . , Xn) is a sample from partial observations Xi with marginal probability
density pθ, for θ ∈Θ ⊂Rk. Let Θn be a random variable that has the prior
distribution, so that the posterior distribution is equal to the conditional distribution
of Θn given X1, . . . , Xn.
201

5: Conﬁdence Regions
Theorem 5.26 Bernstein-von Mises
Suppose that the map ϑ →log pϑ(x) is continuously diﬀerentiable for all x with
gradient ˙ϑ(x) such that  ˙ϑ(x) ≤L(x) for every ϑ in a neighborhood of θ,
where L is a function with EθL2(X1) < ∞. Suppose, moreover, that the Fisher
information matrix iϑ is invertible for all ϑ and depends continuously on ϑ, and
that the maximum likelihood estimator ˆθn is consistent for θ. Then for every prior
probability distribution that is continuous with strictly positive density on Θ, we have
lim sup
n→∞Eθ sup
B
P

Θn ∈B| X1, . . . , Xn

−Nk

ˆθn, 1
ni−1
θ

(B)
 = 0.
Here, we denote by Nk the k-dimensional normal distribution, see Appendix B,
and by Nk(μ, Σ)(B) the probability that an Nk(μ, Σ)-distributed variable takes on
a value in B. In the theorem, the supremum of an absolute diﬀerence between two
probabilities is taken over all events (sets) B ⊂Rk. This diﬀerence can be seen as
a distance between the posterior distribution and a certain normal distribution that
also depends on the observations through the maximum likelihood estimator ˆθn. The
theorem says that the expectation of this distance converges to 0. The variance of
the approximate normal distribution is exactly the (limit) variance of the maximum
likelihood estimator. By choosing the event B suitably, we can transform the statement
into a statement on a credible region.
Let us specify this for the estimation of a real-valued parameter g(θ) based
on a sample from the density pθ. A natural credible interval is then the interval
between two symmetrically chosen quantiles of the posterior distribution of g(θ). If
Fg(Θn)|X1,. . . ,Xn is the distribution function of this posterior distribution and
Qg(Θn)|X1,. . . ,Xn(α) = inf

x: Fg(Θn)|X1,. . . ,Xn(x) ≥α

is the corresponding quantile function, then the credible interval is
(5.3)

Qg(Θn)|X1,. . . ,Xn
α
2

, Qg(Θn)|X1,. . . ,Xn

1 −α
2

.
We can compare this with the conﬁdence interval based on the maximum likelihood
estimator, which equals

g(ˆθn) −ξ1−α/2
√n

g
ˆθni−1
ˆθn (g
ˆθn)T , g(ˆθn) + ξ1−α/2
√n

g
ˆθni−1
ˆθn (g
ˆθn)T

by Theorem 5.16. The endpoints of the two intervals agree asymptotically.
202

5.7: Bayesian Conﬁdence Regions
Theorem 5.27
In the situation of Theorem 5.26, for a diﬀerentiable function g and α ∈(0, 1), we
have
Qg(Θn)|X1,. . . ,Xn(1 −α) −g(ˆθn) −ξ1−α
√n

g
ˆθni−1
ˆθn (g
ˆθn)T = oP n
θ (1/√n).
Consequently, under θ the probability that the credible interval (5.3) contains the
parameter θ converges to 1 −α as n →∞.
Proof. The last statement follows from the ﬁrst and the analogous statement
concerning the coverage probability of the conﬁdence interval based on the maximum
likelihood estimator. See Theorem 5.9 and the discussion following it, or Theo-
rem 5.16 for the case of higher-dimensionalparameters. We also use that the diﬀerence
between the two types of intervals is of order o(1/√n), so that we can reduce the
diﬀerence to 0 by changing the conﬁdence level 1 −α of the maximum likelihood
interval to a value 1 −ˆαn with ˆαn →α. The conﬁdence level of the maximum
likelihood interval still converges to 1 −α as n →∞.
For the proof of the ﬁrst statement of the theorem, we restrict ourselves to the
case of a parameter θ ∈R and the identity function, given by g(θ) = θ. (The general
case requires a second step, based on the delta method.) For Fn(x) = P

Θn ≤
x| X1, . . . , Xn

, by Theorem 5.26 applied with the set B = (−∞, x], we ﬁnd that
E supx
Fn(x) −Φ

(x −μn)/σn
 →0 for μn = ˆθn and σn = 1/√niθ. For
x = QΘn|X1,. . .Xn(1 −α), we have Fn(x −1/n) ≤1 −α ≤Fn(x) because
QΘn|X1,. . .Xn is the quantile function corresponding to Fn. Consequently,
Φ
x −1/n −μn
σn

+ δn ≤1 −α ≤Φ
x −μn
σn

+ Δn,
where both rest terms δn and Δn have an absolute value that is less than supx
Fn(x)−
Φ

(x −μn)/σn
 and therefore converge in probability to 0. By the continuity of the
standard normal quantile function Φ−1, we can now invert the inequalities to obtain
(x −1/n −μn)/σn ≤Φ−1(1 −α −δn) and (x −μn)/σn ≥Φ−1(1 −α −Δn),
which imply x = μn + σn

Φ−1(1 −α) + oP (1)

.
As when we apply Bayesian approximation methods, the weakness of the
credible regions lies in the choice of the prior distribution. This choice can
signiﬁcantly inﬂuence the form of the posterior distribution. A "wrong" choice of
prior distribution can thus lead to "wrong" credible regions. Theorem 5.27 shows that
this problem is small when we have suﬃciently many observations. In that case, a
possible wrong prior choice is corrected by the observations.
Example 5.28 Binomial distribution
Let X be binomially distributed with parameters n (known) and θ (unknown). In
Example 3.38, we computed that the posterior distribution with respect to the beta
203

5: Conﬁdence Regions
distribution with parameters α and β is equal to the beta distribution with parameters
X + α and n −X + β. A credible interval of conﬁdence level 1 −α0 with respect to
a beta prior distribution is therefore the interval between the (α0/2)- and (1 −α0/2)-
quantiles of the beta distribution with parameters X + α and n −X + β. Figure 5.6
shows a realization of the posterior density, where the credible interval is indicated by
the thick solid line.
0.0
0.2
0.4
0.6
0.8
1.0
0
2
4
6
8
10
Figure 5.6. Realization of the posterior density (solid) based on an observation from the binomial
distribution with parameters 100 en 1/2 with respect to the beta prior distribution with parameters
α = 25 and β = 5 (dashed). The 95% credible interval is indicated by the thick solid line.
204

5.8: Summary
5.8 Summary
Let X be an observation with distribution Pθ that depends on an unknown parameter
θ ∈Θ. A conﬁdence region for θ ∈Θ of conﬁdence level 1 −α is a map X →GX
such that
Pθ(GX  θ) ≥1 −α
for all θ ∈Θ.
The region GX depends on X and is therefore stochastic. The conﬁdence level 1 −α
is the probability that this region contains the true value of the parameter.
Conﬁdence regions based on (near-)pivots:
• A pivot is a random variable or vector T = T (X, θ) that has a ﬁxed distribution
that does not depend on the parameter θ. The set of θ for which the pivot belongs
to a ﬁxed region (for example, the interval between two quantiles of its ﬁxed
distribution) is a conﬁdence region for θ. A near-pivot is a variable or vector
T = T (X, θ) that has approximately a ﬁxed distribution.
• Maximum likelihood estimators can act as near-pivots. Let pθ be the marginal
density of a sample X1, . . . , Xn. The Fisher information is the number
iθ = varθ ˙θ(X1),
with θ →˙θ(x) =
∂
∂θ log pθ(x) the score function of the model. Under certain
conditions, the maximum likelihood estimator ˆθn for θ based on the sample X =
(X1, . . . , Xn) satisﬁes √n(ˆθn −θ) ⇝N(0, i−1
θ ). Hence √niθ(ˆθn −θ) is a near-
pivot. When we use an estimator iθ for iθ, this gives the approximate conﬁdence
interval for θ:
θ = ˆθ ±
1

niθ
ξ1−α/2.
Conﬁdence regions based on tests:
• The set of all values τ for which the hypothesis H0: g(θ) = τ is not rejected is a
conﬁdence region for g(θ). If the test has size α, then the conﬁdence region has
conﬁdence level 1 −α. Conversely, rejecting parameter values that do not belong
to a conﬁdence region gives a test of corresponding size.
• A likelihood ratio region for θ is a conﬁdence region based on the likelihood ratio
test for H0: θ = τ. This test does not reject for small values of the likelihood ratio
statistic λ(X), so that the conﬁdence region of (approximate)conﬁdence level 1−α
becomes

θ: λ(X) ≤χ2
k,1−α

=

θ: log pθ(X) −log pˆθ(X) ≥−1
2χ2
k,1−α

,
where ˆθ is the maximum likelihood estimator for θ and k is the dimension of θ.
This region contains the parameter values where the likelihood function exceeds a
certain bound.
205

5: Conﬁdence Regions
Exercises
1. Lab workers are trying to measure a certain quantity θ. Normally distributed measurement
errors occur with a standard deviation of 2.3 and expectation 0. The lab workers carry out
25 independent measurements and ﬁnd an average value of 18.61. Determine a (numerical)
conﬁdence interval for θ of conﬁdence level 0.98.
2. If in the previous exercise, the standard deviation is not assumed known, and the sample
standard deviation is 2.3, what is the (numerical) conﬁdence interval for θ of conﬁdence
level 0.98?
3. Let X1, . . . , Xm and Y1, . . . , Yn be independent random samples from, respectively, a normal
N(μ, σ2)-distribution and a normal N(ν, σ2)-distribution. Determine a conﬁdence interval for
μ −ν of conﬁdence level 1 −α
(i) if σ2 is known,
(ii) if σ2 is unknown.
4. Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution. Determine a conﬁdence interval
for σ2 based on a suitable pivot.
5. Suppose that in 100 independent Bernoulli experiments with unknown probability of success
p, we ﬁnd 36 cases of success. Determine an (approximate) numerical conﬁdence interval
for p of conﬁdence level 0.95.
6. Let X1, . . . , Xm and Y1, . . . , Yn be independent random samples from, respectively, a normal
N(μ, σ2)-distribution and a normal N(ν, τ2)-distribution. Determine a conﬁdence interval for
σ2/τ2 of conﬁdence level 1 −α.
7. Let X1, . . . , Xn be a sample from the exponential distribution with parameter λ.
(i) Determine an exact conﬁdence interval for λ based on a suitable pivot.
(ii) Determine an approximate conﬁdence interval for λ based on the maximum likelihood
estimator and the large sample method.
8. Let X1, . . . , X10 be a sample from the Poisson distribution with unknown expectation θ. We
ﬁnd x1 = x3 = x6 = x8 = x9 = 0, x2 = x5 = x10 = 1, x4 = 2, x7 = 3.
(i) Determine an exact (numerical) conﬁdence interval for θ of conﬁdence level 0.9.
(ii) Determine an approximate (numerical) conﬁdence interval for θ of conﬁdence level
0.9 based on the maximum likelihood estimator by applying the large sample method.
9. Let X1, . . . , Xn be a sample from the distribution with probability density
pθ(x) = 2xθe−θx2
for x ≥0,
and 0 for x < 0. The parameter θ > 0 is unknown. We can prove that X2
1, . . . , X2
n are expo-
nentially distributed with parameter θ and that if θ = 1, the random variable 2n
i=1 X2
i has a
chi-square distribution with 2n degrees of freedom.
(i) Show that 2 n
i=1 θX2
i is a pivot.
(ii) Determine a (1−α)100% conﬁdence interval for θ based on the pivot from the previous
part, expressed in quantiles of a chi-square distribution.
10. By Example 5.2, the square length of the conﬁdence interval for μ based on a sample from
the N(μ, σ2)-distribution when σ2 is known is equal to 4(σ2/n)ξ2
1−α/2. Compare this length
to the expected square length of the interval from Example 5.4 for the case where σ is
unknown.
206

5: Exercises
11. Let X1, .., Xn be a sample from the geometric distribution with parameter p.
(i) Determine the Fisher information for p.
(ii) Determine the observed information.
(iii) Determine an approximate conﬁdence interval for p of conﬁdence level 1−α based on
the maximum likelihood estimator.
(iv) What is the realization of this interval if x1 + ... + x40 = 100 and α = 0.05?
12. Let X1, .., Xn be a sample from the Bernoulli distribution with parameter p.
(i) Determine the Fisher information for p.
(ii) Determine the observed information.
(iii) Determine an approximate conﬁdence interval for p of conﬁdence level 1−α based on
the maximum likelihood estimator.
(iv) What is the realization of this interval if x1 + ... + x100 = 32 and α = 0.05?
13. Let X1, . . . , Xn be a sequence of independent random variables with probability density pθ
given by pθ(x) = θ2xe−θx for x ≥0, where θ > 0 is an unknown parameter.
(i) Determine the maximum likelihood estimator for θ.
(ii) Compute the plug-in estimator for iθ.
(iii) Compute the observed (Fisher) information for θ.
(iv) Give an approximate conﬁdence interval for θ of conﬁdence level 1 −α based on the
maximum likelihood estimator for θ.
14. Let X1, . . . , Xn be a sample from the probability distribution with density pλ(x)
=
xλ−2e−x/λ1x>0, where λ > 0 is an unknown parameter.
(i) Determine the maximum likelihood estimator for λ.
(ii) Determine an approximate conﬁdence interval for λ of conﬁdence level 1−α based on
the maximum likelihood estimator.
(iii) Compare this interval with the interval for θ = 1/λ from the previous exercise.
15. We carry out 25 independent Bernoulli experiments, each with unknown success probability
p. We ﬁnd 18 cases of success. Take conﬁdence level 0.95.
(i) Determine an exact conﬁdence interval for p.
(ii) Determine an approximate conﬁdence interval for p based on the large sample method.
Can 25 be viewed as "large" in this context?
16. Let X1, . . . , Xn be a sequence of independent random variables with probability density pθ
given by pθ(x) = θ2xe−θx for x ≥0, where θ > 0 is an unknown parameter.
(i) Determine the likelihood ratio statistic λn for testing the null hypothesis H0: θ = θ0
against the alternative hypothesis H1: θ = θ0.
(ii) Determine an approximate conﬁdence interval for θ of conﬁdence level 1 −α based on
the likelihood ratio statistic.
17. Let X1, . . . , Xn be a sequence of independent random variables with probability density pθ
given by pθ(x) =
θ
2√xe−θ√x for x ≥0, where θ > 0 is an unknown parameter.
(i) Determine the maximum likelihood estimator for θ.
(ii) Determine the likelihood ratio statistic λn for testing the null hypothesis H0: θ = θ0
against the alternative hypothesis H1: θ = θ0.
(iii) Determine an approximate conﬁdence interval for θ of conﬁdence level 1 −α based on
the likelihood ratio statistic.
18. Let X1, . . . , Xn be a sample from the N(θ, θ2)-distribution, with θ > 0 unknown. Determine
an approximate conﬁdence interval for θ based on the likelihood ratio statistic.
207

5: Conﬁdence Regions
19. A manufacturer of scales claims that his scales have an accuracy of 2 per mille. This
means that if X denotes the weight of a 1000 mg object measured on an arbitrary scale,
the variance of X is equal to 22 = 4 mg2. We want to study whether the manufacturer
is right. To do this, we take a 1000 mg object and determine its mass using 50 randomly
chosen scales. The diﬀerent measurements are denoted by X1, . . . , X50. We assume that the
observations X1, . . . , X50 are independent and normally distributed with expectation μ and
unknown variance σ2. The observed sample variance is equal to 4.8. We have also observed
that 50
i=1(xi −1000)2/50 = 4.8.
(i) Construct a conﬁdence interval for σ2 of conﬁdence level 0.95 under the assumption
that we know that μ = 1000 mg.
(ii) Construct a conﬁdence interval for σ2 of conﬁdence level 0.95 under the assumption
that μ is unknown.
(iii) Describe a test for testing whether σ2 deviates signiﬁcantly from the variance given by
the manufacturer. Do this for the case where μ is known as well as the case where it
is unknown. Give the null hypothesis. Carry out this test with the conﬁdence interval
from the previous part, a critical region, or a p-value. Take conﬁdence level equal to
0.95.
20. Let X and Y be independent, binomially distributed variables with respective parameters
(200, p1) and (725, p2).
(i) Construct an approximate conﬁdence interval for p1 −p2 of conﬁdence level 0.95.
(ii) Test, using the conﬁdence region from the previous part, the null hypothesis H0: p1 =
p2 at level 0.05 if we have observed x = 121 and y = 391.
21. Let X(n) be the maximum of a sample of size n from the uniform distribution on [0, θ].
Determine numbers c and d such that the length of the interval [X(n)/d, X(n)/c] is minimal
and the interval is also a conﬁdence interval of conﬁdence level 1 −α.
22. Let X and Y be independent binomially distributed variables with respective parameters
(n1, p1) and (n2, p2). Determine the proﬁle likelihood function for the parameter g(p1, p2) =
p1/p2.
208

THE SALK VACCINE
Polio (or infantile paralysis) is an infectious disease that was virtually eradicated by
vaccination in Western countries in the second half of the twentieth century. The ﬁrst
vaccines against polio were developed and tested in the 1950s. Jonas Salk's vaccine
was the most promising of these. After research in a lab, the United States Public
Health Service decided, in 1954, to study this vaccine by carrying out a large ﬁeld
trial under the American population.
This experiment consisted of vaccinating a large number of children with either
the Salk vaccine or a placebo (an inactive substance) and carrying out a statistical
comparison of the measure of infection by the poliovirus in the two groups. Using a
placebo is standard procedure in these types of clinical trials, and is meant to rule out
possible (usually positive) eﬀects on a patient resulting from the suggestions that they
are being treated. Neither the children nor the doctors administrating the shots knew
whether a placebo or vaccine was administered: it was a double-blind experiment.
The composition of the group of "cases" (the children treated with the vaccine)
and of the control group (the children treated with the placebo) lead to the necessary
complications. A signiﬁcant problem was that a large number of parents did not give
permission for participation in the trial. Since it was not excluded, and was even
expected, that a positive correlation existed between permission to participate and
susceptibility for polio, the researchers decided to ﬁrst form a group of children whose
parents had given permission for participation in the trial, and only then decide how
to split the group into a case group and control group. The latter came about through
complete randomization, that is, each child had probability 1/2 of being assigned to
one of the two groups, independently of the other children.
The results were as follows. For a group of about 750 000 children, the parents
of 401 974 children gave permission for participation in the trial. Of these children,
200 745 were administered the vaccine and 201 229 the placebo. Of the treated
children, 57 still contracted polio, while in the placebo group, 142 children contracted
polio.♭
This data seems to show that the Salk vaccine signiﬁcantly reduces the
occurrence of polio. How hard can we make this conclusion? Recall that 57 of the
treated children also contracted polio. Can we say that the Salk vaccine reduces the
probability of contracting polio by a factor of 2.5 (≈(142/201 229)/(57/200 745))?
Even for a carefully planned trial, these questions are not at all trivial. The
factor 2.5 that shows up in the data at ﬁrst glance has the highest uncertainty, but
the statement "the Salk vaccine works" also needs further explanation. What do we
mean by "works"? In principle, we are looking for a causal conclusion: just like a
moving billiard ball touching a stationary billiard ball is the reason why the second
ball starts moving, we would like the Salk vaccine to be the reason why there are fewer
cases of polio. A clinical trial as the one carried out here is seen as the best method
♭The date can be found in the paper Evaluation of the 1954 Poliomyelitis vaccine ﬁeld trial, T. Francis,
Journal of American Medical Association 158, 1955.
209

5: Conﬁdence Regions
for drawing such a conclusion, but to a certain level, speaking in terms of causes
may be a linguistic question. By the set-up of the experiment, other explanations for
the observed diﬀerence have been ruled out as much as possible. Note, however, that
the experiment gives hardly any information on children whose parents did not give
permission for administering the vaccine. It could, for example, be possible that this
group corresponds to the group for which the vaccine does not work. On medical
grounds, this is very improbable, but we should not unquestioningly view the factor
2.5 as applicable to this group of children. For example, it turns out that richer parents
often refused participation, and there is a speculation that children of richer parents
are more susceptible to polio because they build up less resistance in their younger
year because of better hygiene.
The contribution of statistics is the analysis of the data based on a statistical
model. Roughly speaking, the question is: suppose that we repeat the entire
experiment, would we still ﬁnd similar results (including the factor 2.5), or was this
by chance? What statistical model should we use? It seems impossible to set up an
experiment in which we also include the possibility that a parent (of a randomly chosen
child?) refuse permission to participate. It seems simplest to restrict ourselves to the
group of 401 974 participating children. Although, theoretically, we may then not
extend our conclusions to all children, such a generalization does seem reasonable.
Let p1 and p2 be the probabilities that a randomly chosen child from the given
401 974 children contracts polio if they receive, respectively, the vaccine and the
placebo. For every child i = 1, 2, . . ., n = 401 974, we observe the pair (Ci, Pi),
where Ci is deﬁned as
Ci =
 1
if child i is in the case group,
2
if child i is in the control group,
and Pi as
Pi =
 0
if child i does not contract polio,
1
if child i contracts polio.
The marginal distribution of Ci is P(Ci = 1) = P(Ci = 2) = 1/2, because of
the set-up of the experiment: every child has the same probability of being assigned
to the case group or control group. The conditional distribution of Pi given Ci =
j is Bernoulli(pj) for j = 1, 2, by the deﬁnitions of p1 and p2. This ﬁxes the
probability distribution of (Ci, Pi). We further ﬁx the joint probability distribution
of (C1, P1), . . . , (Cn, Pn) by postulating that these vectors are independent. This is
a bad assumption, because polio is infectious and does not occur independently in
diﬀerent children. We still make the assumption, for want of a better one.
The observations C1, . . . , Cn are the result of the randomization and do not
give any information on the parameters p1 and p2. The relevant information in the
observations P1, . . . , Pn is (intuitively) contained in
X =

i:Ci=1
Pi,
Y =

i:Ci=2
Pi.
210

5: The Salk Vaccine
These are the numbers of cases of polio in the case group and control group,
respectively. Given the vector (C1, . . . , Cn), the variables X and Y are independent
and binomially distributed with respective parameters (M1: = #{i: Ci = 1}, p1) and
(M2: = #{i: Ci = 2}, p2). The simple approach is now to carry out the statistical
analysis conditionally on the observed values m1 and m2 of M1 and M2. In that
case, we have reduced the problem to the statistical approach in which we observe
the independent variables X and Y with binomial distributions with respective
parameters (m1, p1) and (m2, p2).
To test whether the vaccine has a protective eﬀect, we want to test the null
hypothesis H0: p1 ≥p2 against the alternative hypothesis H1: p1 < p2. Within the
statistical model described above, there exists a standard test, the Fisher test for the
(2 × 2)-table, based on the fact that under the null hypothesis, X given X + Y has
a hypergeometric distribution. We will not discuss this here. Because the number of
observations is very large, we are content with an approximate test.
The natural estimator for p1 −p2 is X/m1−Y/m2. This has expectation p1 −p2
and variance
var
 X
m1
−Y
m2

= p1(1 −p1)
m1
+ p2(1 −p2)
m2
.
We can estimate this variance by replacing p1 and p2 with X/m1 and Y/m2. By the
central limit theorem (Theorem A.28), under p1 = p2, the random variable
T =
X/m1 −Y/m2

X/m1(1−X/m1)
m1
+ Y/m2(1−Y/m2)
m2
approximately has the standard normal distribution; see Section A.7. If we use T
as test statistic to test the null hypothesis stated above, then we ﬁnd a left p-value
9.09 × 10−9, which is less than any interesting level of the test. The conclusion is that
the vaccine indeed has a protective eﬀect.
To say something about the size of the eﬀect p1 −p2, we estimate this diﬀerence
and deduce a 95% conﬁdence interval. As near-pivot, we use
X/m1 −Y/m2 −(p1 −p2)

X/m1(1−X/m1)
m1
+ Y/m2(1−Y/m2)
m2
,
which approximately has the standard normal distribution. For the given data from
the Salk experiment, p1 −p2 is estimated to be −0.000422 and the approximate 95%
conﬁdence interval is equal to −0.000422 ± 0.000137.
Since both p1 and p2 are small, it seems natural to study the relative size p1/p2.
A reasonable estimator is (X/m1)/(Y/m2). In a manner similar to that used for
the diﬀerence, we can deduce a conﬁdence interval for p1/p2, but this requires more
knowledge of asymptotic methods than we wish to introduce here, so we refrain from
doing this.
211

6 Optimality Theory
6.1 Introduction
This chapter is dedicated to optimality theory for estimators and tests. There are,
generally, many possible choices for estimators and test statistics. If we are looking
for the best estimator or test, it would be useful to reduce the set of possible estimators
and test statistics. We can do this by reducing the observation beforehand by ﬁltering
out irrelevant information on the parameter. We then base the estimator or test statistic
on the reduced observation. This is the subject of Section 6.2.
In Section 6.3, we consider how to ﬁnd the best estimator and how good the best
estimator is, measured in the measure of quality discussed in Chapter 3, the mean
square error.
Finally, we discuss the quality of tests in Section 6.4. In Chapter 4, we
constructed diﬀerent tests using ad hoc arguments. Intuitively, most of these tests are
reasonable, but are they also the best possible tests? In the last section of this chapter,
we will show that some of the tests we discussed are uniformly most powerful; this
means that the power of these tests under the alternative hypothesis is maximal.
212

6.2: Suﬃcient Statistics
6.2 Suﬃcient Statistics
If instead of seeing the full observation X, we only see the value of a statistic V (X),
we have, in principle, lost information. For example, X = (X1, . . . , Xn) gives more
information than V (X) = n
i=1Xi. We call a statistic V suﬃcient if, given the model,
no relevant information on the unknown parameter has been lost.
Example 6.1 Bernoulli distribution
For a quality control inspection, n items are randomly chosen from a large batch and
tested. We observe X = (X1, . . . , Xn), where
Xi =
 0
if the ith article is rejected,
1
if the ith article is approved.
The result of the inspection is therefore a sequence of symbols consisting of 0s and
1s. The unknown proportion p of defect items in the large batch clearly aﬀects the
number V = n
i=1Xi of observed 1s (the number of approved articles in the sample),
but intuitively, the order in which we see the 0s and 1s has little to do with the size of
p. Intuitively, V = n
i=1Xi therefore suﬃces.
The technical deﬁnition of a suﬃcient statistic when X has a discrete distribution
is as follows.
Deﬁnition 6.2 Suﬃcient statistic for discrete probability distributions
Suppose that the statistical model for X consists of discrete probability distributions
that depend on the parameter θ. A statistic V = V (X) is called suﬃcient if the
conditional probabilities
P(X = x| V = v)
do not depend on θ, for all possible values of x and v.
The property in the deﬁnition is truly special. The distribution of X depends on
the unknown parameter θ, hence so does the joint distribution of (X, V ). For a general
statistic V that is not suﬃcient, the conditional probabilities Pθ(X = x| V = v) will
also depend on θ.
Intuitively, we can show as follows that it is plausible that a suﬃcient quantity
possesses all relevant information on θ. We could generate an observation x in two
steps:
- First generate v from the marginal distribution of V ; for this, we need the "true"
parameter θ.
- Given v, generate x from the conditional distribution of X given V = v; provided
that V is suﬃcient, we do not need the true θ for this.
213

6: Optimality Theory
We can view the result of these two steps as drawing a sample from the distribution of
X because we always have
Pθ(X = x) =

v
Pθ(X = x| V = v)Pθ(V = v),
where the conditional probabilities Pθ(X = x| V = v) do not depend on θ when
V is suﬃcient. The result therefore contains just as much information as a direct
observation of X in the original experiment. Apparently, all relevant information on θ
is contained in V . If desired, we can always "convert" v to x, by following the second
step of the procedure described above. We do not need to know the parameter for this.
Example 6.3 Bernoulli distribution, continued
In Example 6.1, we showed that intuitively, the variable V = n
i=1Xi is suﬃcient. To
make this more precise, we must specify the underlying statistical model. We assume
that X1, . . . , Xn are independent and have the Bernoulli distribution with parameter
p. Then for xi ∈{0, 1} and v ∈{0, 1, . . ., n},
Pp

X1 = x1, . . . , Xn = xn| V = v

= Pp

X1 = x1, . . . , Xn = xn, V = v

Pp(V = v)
=
⎧
⎨
⎩
pv(1 −p)n−v
n
v

pv(1 −p)n−v
if n
i=1xi = v
0
otherwise
=
⎧
⎨
⎩
n
v
−1
if n
i=1xi = v
0
otherwise.
Because the last expression does not depend on p, the variable V is indeed suﬃcient.
Note that, as a safeguard, we have included p on the left-hand side. Only at the end of
the computation, where p does play a role in the intermediate steps, do we see that we
can leave out p.
6.2.1 Factorization Theorem
How do we determine suﬃcient statistics? The deﬁnition is not very useful, because
we ﬁrst need to guess which statistic V might be suﬃcient, and then compute
conditional probabilities that are sometimes rather complicated. The following
theorem oﬀers a solution.
214

6.2: Suﬃcient Statistics
Theorem 6.4 Factorization theorem
Suppose that the statistical model for X consists of discrete distributions. A statistic
V = V (X) is suﬃcient if and only if there exist functions gθ and h such that for all
x and θ,
pθ(x) = gθ

V (x)

h(x),
where pθ is the probability density of X.
Proof. Suppose that V is suﬃcient. Then
Pθ(X = x) = Pθ

X = x, V = V (x)

= P

X = x| V = V (x)

Pθ

V = V (x)

.
The ﬁrst term on the right-hand side does not depend on θ, because V is suﬃcient.
This term can therefore be used for h(x). The second term does depend on θ, but only
through V (x), and can therefore be used for gθ

V (x)

.
Conversely, suppose that the required functions gθ and h exist. The conditional
probability
Pθ

X = x0| V = v

= Pθ

X = x0, V = v

Pθ(V = v)
is equal to 0 if V (x0) = v. In the other case, where V (x0) = v, the expression is
equal to
Pθ(X = x0)
Pθ(V = v) =
Pθ(X = x0)

x:V (x)=v Pθ(X = x)
=
gθ

V (x0)

h(x0)

x:V (x)=v gθ

V (x)

h(x)
=
gθ

v

h(x0)
gθ

v
 
x:V (x)=v h(x)
=
h(x0)

x:V (x)=v h(x).
Neither the last expression nor the condition V (x0) = v depends on θ. Hence V is
suﬃcient.
Example 6.5 Bernoulli distribution
For the situation in Example 6.3, we have
Pθ(X1 = x1, . . . , Xn = xn) = θ
n
i=1xi(1 −θ)n−n
i=1xi.
This is a function of n
i=1xi. We can take h(x) ≡1 and gθ(s) = θs(1 −θ)n−s. By
the factorization theorem, the variable n
i=1Xi is suﬃcient.
It is mathematically diﬃcult to extend the deﬁnition of suﬃciency given above to
continuously distributed random variables X, because the deﬁnition of the conditional
probability of X given V (X) is not simple mathematically. To avoid this diﬃculty, we
choose the factorization formula as the deﬁnition.
215

6: Optimality Theory
Deﬁnition 6.6 Suﬃcient statistic
A statistic V (X) is called suﬃcient for the observation X with probability density
pθ if there exist functions gθ and h such that for all θ and x,
pθ(x) = gθ

V (x)

h(x).
For discretely distributed observations, we now have two deﬁnitions of sufﬁcien-
cy, but these agree by the factorization theorem. This theorem or the last deﬁnition says
that a statistic V is suﬃcient if the likelihood function (based on the observation X)
depends on θ only through V (X). This also suggests that observing V is "suﬃcient."
Suﬃcient statistics are not at all unique. The observation X itself is, for example,
always suﬃcient, but this is not an interesting suﬃcient statistic. An interesting
suﬃcient statistic is one that is simple and low-dimensional, a statistic that is suﬃcient
but reduces the data as much as possible. We call a suﬃcient statistic V minimally
suﬃcient if V is a function of every other suﬃcient statistic. In that case, we know the
value of V as soon as we know the value of any suﬃcient statistic; V therefore contains
less information. The following lemma shows that this is a meaningful deﬁnition.
Lemma 6.7
Let V be a suﬃcient statistic, and suppose V = f(V ∗) for a map f. Then V ∗is also
suﬃcient. If f is a 1-1 function, then V = f(V ∗) is suﬃcient if and only if V ∗is
suﬃcient.
Proof. The ﬁrst assertion is immediate from the factorization theorem or, in the
continuous case, the deﬁnition. We simply note that gθ

V (x)

can be further written
as gθ ◦f

V ∗(x)

. The second assertion follows by applying the ﬁrst one in both
directions.
Example 6.8 Normal distribution
Let X = (X1, . . . , Xn) be a sample from the N(μ, σ2)-distribution with unknown
parameters μ and σ2. We take the natural parameter space for the parameter θ =
(μ, σ2), namely Θ = R × (0, ∞). The joint density of X1, . . . , Xn is
n

i=1
1
√
2πσ2 e−
1
2σ2 (xi−μ)2 =

1
√
2πσ2
n
e−
1
2σ2
n
i=1(xi−μ)2
=

1
√
2πσ2
n
e−
n
2σ2 μ2e−
1
2σ2
n
i=1x2
i + μ
σ2
n
i=1xi.
So the density depends on X1, . . . , Xn only through (n
i=1xi, n
i=1x2
i ). The vector
(n
i=1Xi, n
i=1X2
i ) is therefore suﬃcient.
216

6.2: Suﬃcient Statistics
The vector (X, S2
X) has a 1-1 relation with this suﬃcient vector and is therefore
also suﬃcient. For a random sample from the normal distribution, the sample mean
and sample variance therefore contain all information on μ and σ2. Note that
(X, S2
X, X1) is also suﬃcient, but not minimally suﬃcient!
Example 6.9 Uniform distribution
Let X = (X1, . . . , Xn) be a sample from the U[0, θ]-distribution with unknown
parameter θ > 0. The joint density of X1, . . . , Xn is
pθ(x1, . . . , xn) =
n

i=1
1
θ 1{0≤xi≤θ} =
1
θ
n
1{x(n)≤θ}.
Apparently, X(n) is suﬃcient: the largest observation contains all information on the
parameter θ.
For discretely distributed observations, we have given a thought experiment
(generating an observation in two steps) to make intuitively plausible that a suﬃcient
statistic indeed contains all information on the parameter. The name "suﬃcient
statistic" suggest that if we want to estimate an unknown parameter or say something
about its value using a test, the information in the data that is not in the suﬃcient
statistic is superﬂuous. As far as estimating is concerned, this is proved in the Rao-
Blackwell theorem (Theorem 6.16) in Section 6.3. In this theorem, we prove that for
every estimator T = T (X), there exists an estimator T ∗= T ∗(V ) that depends only
on the suﬃcient quantity V and is at least as good as T (measured using the mean
square error). For tests, it is a bit more complicated. The quality of a test is determined
by the power function. We thus want to prove that for every test based on X, there
exists a test based on V with power function at least as powerful. This is only true if
we also allow so-called randomized statistics.
* 6.2.2 Randomized Statistics
The proof that a suﬃcient statistic contains all relevant information when we are
dealing with tests requires the deﬁnition of randomized test statistics.
Deﬁnition 6.10 Randomized Statistic
A randomized statistic T = T (X, U) is a random vector that depends only on X and
an independently generated U[0, 1]-distributed variable U.
217

6: Optimality Theory
Every "ordinary" statistic is also a randomized statistic. A randomized statistic
may depend not only on the observation but also on a random number U that must
be generated independently of the actual experiment and parameter. This random
number therefore does not contain any information on the parameter. Without this
action that seems useless at ﬁrst, Theorem 6.11 would not be true. The reason is
that what "remains" of X after the suﬃcient statistic V is known, also does not
contain any relevant information, and therefore works as a random number generator.
In Theorem 6.11, we need U to match this irrelevant source of random numbers.
We can show that if the quality of the estimators is measured incorrectly using the
mean square error, randomizing estimators is never meaningful; there is always a
nonrandomized estimator with a smaller mean square error (namely
 1
0 T (X, u) du).
For tests, randomizing can be meaningful.
Theorem 6.11
Let V = V (X) be suﬃcient for the observation X. For every randomized statistic
T = T (X, U), there exists a randomized statistic T ∗(V, U) based only on V (and the
randomization U), such that the probability distributions of T ∗and T are the same
under every parameter θ.
We leave out the proof of this theorem. We can apply this theorem to both the
estimation problem and the test problem, and obtain the following corollary. We show
that knowing only V , we can construct estimators and tests that are as good (measured
using the mean square error for the estimators and using the power function for the
tests) as those obtained using the full observation X.
Corollary 6.12
Let V = V (X) be suﬃcient for the observation X. For every estimator T = T (X),
there exists an estimator T ∗= T ∗(V, U) based only on V (and the randomization
U) with MSE(θ; T ) = MSE(θ; T ∗) under every parameter θ.
Corollary 6.13
Let V = V (X) be suﬃcient for the observation X. For every test statistic T = T (X)
there exists a test statistic T ∗= T ∗(V, U) based only on V (and the randomization
U), such that the tests {T ≥c} and {T ∗≥c} have the same power function:
Pθ(T ≥c) = Pθ(T ∗≥c) for every c and under every parameter θ.
Proofs. Both the mean square error and the power function depend only on the
probability distribution of the statistics T or T ∗. For example, in the case of a test, we
have (if T is continuously distributed)
Pθ(T ≥c) =
 ∞
c
pT
θ (t) dt,
218

6.3: Estimation Theory
with pT
θ the probability density of T . Equality of probability distributions implies
equality of densities pT
θ = pT ∗
θ , and therefore equality of power functions.
By Theorem 6.11, we can choose the probability distributions of T and T ∗equal
to each other. Consequently, we can also choose the mean square errors and the power
functions equal to each other.
Applying the theorem to the estimation problem is not truly necessary because
the Rao-Blackwell theorem (Theorem 6.16) already convincingly shows the "sufﬁ-
ciency" of suﬃcient statistics. Note, however, that the proof of the ﬁrst corollary holds
for every estimation criterion, hence also for other criteria than the mean square error.
6.3 Estimation Theory
The quality of an estimator is quantiﬁed by its mean square error (see Section 3.2).
An estimator for an unknown parameter g(θ) is good if its mean square error is small
compared to that of other estimators. An estimator T0 for g(θ) would be the absolutely
best estimator if
MSE(θ; T0) ≤MSE(θ; T )
for all T, θ.
However, such an estimator T0 does not exist. We can see this by realizing that a trivial
estimator T (X) = g(θ0), for a ﬁxed θ0, is also an estimator. The mean square error of
this estimator for the estimation of g(θ) is equal to 0 in θ = θ0 (but is very bad for g(θ)
far from g(θ0)). An absolutely best estimator should therefore also have mean square
error 0, in every θ, which is impossible as soon as there are two diﬀerent values g(θ).
The problem is that the measure θ →MSE(θ; T ) for the quality of an estimator
is a function of the (unknown) parameter, which we want to minimize with respect to
"all" parameters. That is impossible. We need additional criteria for the choice of an
estimator. We give three examples. As the basic criterion for quality, we again take
the mean square error, although most of the theory also holds for other measures of
quality, such as Eθ
T −g(θ)
.
We already discussed the Bayes criterion in Section 3.5. For a given prior density
π on Θ, we are looking for the estimator T that minimizes

MSE(θ; T ) π(θ) dθ.
This is by deﬁnition the Bayes estimator with respect to π, which was found in
Theorem 3.36.
The minimax criterion takes the maximum of the mean square error,
sup
θ∈Θ
MSE(θ; T ),
219

6: Optimality Theory
as measure. An estimator T is called minimax if T minimizes this maximal risk over
all estimators. Like the Bayes criterion, the minimax criterion reduces the function
θ →MSE(θ; T ) to a number. A "best" estimator can be found by minimizing this
number over T . In principle, this is almost always possible.
Example 6.14 Binomial distribution
Suppose that the observation X has the bin(n, p)-distribution. Then the minimax
estimator for p is equal to
T (X) = X + 1
2
√n
n + √n .
We can deduce this from the fact that T is a Bayes estimator with mean square
error MSE(p; T ) that is constant in p ∈[0, 1] (see Example 3.38). The proof is by
contradiction. If T were not minimax, there would exist an estimator S with a smaller
maximum risk, and we would have
MSE(p; S) ≤sup
0≤q≤1
MSE(q; S) ≤sup
0≤q≤1
MSE(q; T ) = MSE(p; T )
for all 0 ≤p ≤1. The ﬁrst inequality follows from the deﬁnition of the supremum, the
second inequality expresses the smaller maximum risk of S, and the equality follows
from the fact that MSE(p; T ) is constant in p. In summary, we have MSE(p; S) ≤
MSE(p; T ) for p ∈[0, 1]. It follows that for every prior distribution, the Bayes
risk of S is less than or equal to the Bayes risk of T , because the Bayes risk is a
weighted version of the mean square error. Since T is the Bayes estimator for p for
the beta( 1
2
√n, 1
2
√n) prior distribution, T minimizes the Bayes risk for this prior
distribution over all estimators. The Bayes risk of S therefore cannot be smaller;
hence, the Bayes risks of the two estimators are equal, so that S is also a Bayes
estimator for p with respect to the same prior distribution. Theorem 3.36 then implies
that S = T .
A third criterion, which we will discuss in detail in the next section, is the
criterion of minimum-variance unbiased estimators. The idea is to look for a best
estimator in the class of all unbiased estimators. Since the mean square error of
unbiased estimators is equal to the variance, this means that were are looking for an
unbiased estimator with minimal variance.
220

6.3: Estimation Theory
6.3.1 UMVU Estimators
In this section, we look for the so-called UMVU estimators in an estimation problem.
Deﬁnition 6.15 Uniformly minimum-variance unbiased (UMVU)
An estimator T is called uniformly minimum-variance unbiased or UMVU for g(θ)
if T is an unbiased estimator for g(θ) and varθ T ≤varθ S for all θ and all other
unbiased estimators S for g(θ).
How do we determine UMVU estimators? The Rao-Blackwell theorem is a ﬁrst
step in the right direction. This theorem says that for every estimator T for g(θ), there
exists an estimator T ∗= T ∗(V ) that depends only on the suﬃcient quantity V , has the
same bias as T , and has variance less than or equal to that of T . If we are looking for a
UMVU estimator, then the Rao-Blackwell theorem says that we can restrict ourselves
to unbiased estimators that depend only on a suﬃcient statistic.
When the distribution of X is discrete, we can construct T ∗explicitly: given the
estimator T , we deﬁne
T ∗(v) = E(T | V = v) =

x
T (x)P(X = x| V = v).
Since V is suﬃcient, we may leave θ out of the subscripts of Eθ and Pθ. Hence T ∗
is indeed an estimator; it is a function of the observations and not of the unknown
parameter θ.
Theorem 6.16 Rao-Blackwell
Let V = V (X) be a suﬃcient statistic, and let T = T (X) be an arbitrary real-valued
estimator for g(θ). Then there exists an estimator T ∗= T ∗(V ) for g(θ) that depends
only on V , such that EθT ∗= EθT and varθ T ∗≤varθ T for all θ. In particular, we
have MSE(θ; T ∗) ≤MSE(θ; T ). This inequality is strict unless Pθ(T ∗= T ) = 1.
Proof. We give the proof only in the case where the distribution of X is discrete.
Let T ∗= E(T | V ). In the paragraph before the theorem, we already saw that T ∗does
not depend on the parameter θ and is therefore an estimator for g(θ). By the rules for
conditional expectations, we have
EθT ∗=

v
T ∗(v)Pθ(V = v) =

v
E(T | V = v)Pθ(V = v) = EθT.
221

6: Optimality Theory
This proves the assertion EθT ∗= EθT . We moreover have
EθT T ∗=

v
E(T T ∗| V = v)Pθ(V = v)
=

v
T ∗(v)E(T | V = v)Pθ(V = v)
=

v
T ∗(v)2Pθ(V = v)
= Eθ(T ∗)2.
This implies
EθT 2 = Eθ(T −T ∗)2 + 2Eθ(T −T ∗)T ∗+ Eθ(T ∗)2
= Eθ(T −T ∗)2 + 0 + Eθ(T ∗)2
≥Eθ(T ∗)2.
Since T and T ∗have the same expectation, it immediately follows that varθ T ∗≤
varθ T .
The inequality in the last display is strict unless Eθ(T −T ∗)2 = 0. This is
equivalent to having T = T ∗with probability 1.
When we restrict ourselves to the class of unbiased estimators, then by the
Rao-Blackwell theorem, it suﬃces to consider only unbiased estimators based on a
suﬃcient quantity. Suppose that for a given suﬃcient statistic V , there exists only
one estimator T = T (V ) that is based on V and unbiased. Then T is automatically
UMVU. This method, based on ﬁnding a special suﬃcient statistic, works in many
cases. The special property of the suﬃcient statistic is completeness.
Deﬁnition 6.17 Complete statistic
A statistic V is called complete if Eθf(V ) = 0 (and therefore Eθ|f(V )| < ∞) for
all θ ∈Θ can hold only for functions f such that Pθ

f(V ) = 0

= 1 for all θ ∈Θ.
We can prove that if there exists a minimally suﬃcient statistic, then a suﬃcient
and complete statistic is also minimally suﬃcient (see Exercise 6.10). In that case,
the complete statistic contains all necessary, and no superﬂuous, information from the
data to estimate the model parameter (see Example 6.19).
Theorem 6.18
Let V be suﬃcient and complete, and let T = T (V ) be an unbiased estimator for
g(θ) that depends only on V . Then T is a UMVU estimator for g(θ).
222

6.3: Estimation Theory
Proof. By the Rao-Blackwell theorem, for every unbiased estimator S for g(θ), there
exists an unbiased estimator S∗= S∗(V ) that depends only on V and whose variance
is less than or equal to that of S. Now, S∗−T is a statistic that depends only on V ,
with Eθ(S∗−T ) = EθS∗−EθT = 0 for all θ because both estimators are unbiased.
By the completeness, we have Pθ(S∗−T = 0) = 1 for all θ. Hence T = S∗with
probability 1 and varθ T ≤varθ S.
Example 6.19 Uniform distribution
Let X = (X1, . . . , Xn) be a sample from the U[0, θ]-distribution. In Example 6.9,
we saw that the maximum X(n) is suﬃcient. If the parameter space is equal to Θ =
(0, ∞), then X(n) is also complete. Therefore, assume that
0 = Eθf(X(n)) =
 θ
0
f(x) 1
θn nxn−1 dx
for all θ > 0.
This implies
 θ
0 f(x)xn−1 dx = 0 for all θ > 0. If f is continuous, we can
diﬀerentiate this equality with respect to θ, which gives f(θ)θn−1 = 0 for all θ. Hence
f ≡0. For noncontinuous f, the same conclusion holds, but the deduction requires
measure theory instead of calculus. Hence X(n) is complete.
Since (n + 1)/nX(n) is an unbiased estimator for θ and depends only on the
suﬃcient and complete quantity X(n), it immediately follows from Theorem 6.18 that
this estimator is a UMVU estimator for θ. This is a nice result, which indicates that we
cannot ﬁnd a better unbiased estimator than (n+1)/nX(n). The biased estimator (n+
2)/(n + 1)X(n), however, has a slightly smaller mean square error (see Example 3.6)
and is therefore preferable to the UMVU estimator. The diﬀerence between the mean
square errors of these two estimators is, however, negligible.
Note that the statistic W = (X(n), X) is also suﬃcient, and that 2X is an
unbiased estimator for θ based on W. We cannot conclude that 2X is UMVU,
because W is not complete. For example, Eθf(W) = 0 for all θ > 0 for f(w) =
(n + 1)w1/n −2w2.
It is not always easy to give a direct proof that a given statistic is complete. The
following theorem applies to many of the standard models. It concerns probability
densities that belong to an "exponential family" of probability densities.
Deﬁnition 6.20 Exponential family
A family of probability densities pθ that depends on a parameter θ is called a k-
dimensional exponential family if there exist functions c, h, Qj, and Vj such that
pθ(x) = c(θ)h(x) e
k
j=1Qj(θ)Vj(x).
223

6: Optimality Theory
It follows from the factorization theorem that the statistic V = (V1, . . . , Vk) in a
given exponential family is suﬃcient. This statistic is also complete provided that the
parameter space is "suﬃciently rich" (see Theorem 6.21).
Theorem 6.21
Suppose that a statistical model is given by a k-dimensional exponential family such
that the set

Q1(θ), . . . , Qk(θ)

: θ ∈Θ

⊂Rk
has an interior point. Then V = (V1, . . . , Vk) is suﬃcient and complete.
* Proof. We only sketch the proof, restricting ourselves to the case k = 1 and assuming
that the model is continuous, so that expectations can be given by integrals with respect
to the probability density x →pθ(x).
The equation Eθf(V ) = 0 implies K

Q(θ)

= 0 for K the function deﬁned by
K(z) =

f

V (x)

h(x)ezV (x) dx. The assumptions that this holds for every θ ∈Θ
and that the set {Q(θ): θ ∈Θ} contains an interior point imply that the function
K must be well deﬁned and ﬁnite for all z in an interval (a, b) ⊂R with a < b.
Since for z ∈C and v ∈R we have |ezv| = eRe zv, the function K is also well
deﬁned and ﬁnite for all complex numbers z with Re z ∈(a, b). We can, moreover,
prove that the derivative K(z) exists for every z in this region. (The derivative
is given by K(z) =

f

V (x)

h(x)V (x) ezV (x) dx, computed by "diﬀerentiating
under the integral." The integral on the right-hand side is indeed ﬁnite, because |v| ≤
ε−1(e−εv+eεv) for every ε > 0 and v ∈R, so that |V |ezV ≤ε−1(e(z−ε)V +e(z+ε)V ),
where for given z with Re z ∈(a, b), we choose the value ε suﬃciently small that both
Re z−ε and Re z+ε belong to (a, b) .) In other words, the function K is holomorphic
in the region {z ∈C: Re z ∈(a, b)}. By complex analysis, the zero function is the
only holomorphic function on a given region that is 0 in a set that has a limit point.
Hence, from the assumption K

Q(θ)

= 0 for all θ ∈Θ now follows K = 0.
By taking z = Q(θ) + it with Q(θ) ∈(a, b) and t ∈R, we ﬁnd that
EθeitV f(V ) = 0 for every t ∈R. By the theory of "characteristic functions" of
probability distributions, it follows that f(V ) = 0 with probability 1 and that V is
consequently complete. Let us now give a direct proof of the conclusion that f = 0.
Using the equality

eitve−t2σ2/2 dt = e−v2/(2σ2)√
2π/σ, we ﬁnd, after exchanging
the order of

and Eθ, that for y ∈R and σ > 0,
0 =

EθeitV f(V ) e−ity−t2σ2/2 dt =
√
2π
σ
Eθf(V )e−(V −y)2/(2σ2)
= 2π

φσ(v −y)f(v)qθ(v) dv,
for φσ the density of the N(0, σ2)-distribution and qθ the probability density of V .
Setting f + = f1f>0 and f −= −f1f<0, so that f = f + −f −, we ﬁnd that φσ ∗
(f +qθ)(y) = φσ ∗(f −qθ)(y) for every y ∈R and σ > 0, where ∗is the convolution
224

6.3: Estimation Theory
of two densities. The functions f +qθ and f −qθ are both nonnegative. If we integrate
them up to 0, we have f + = f −, and then f = 0, so the proof is complete. In the other
case, we can multiply f by a constant in order for f +qθ and f −qθ to be probability
densities of random variables X+ and X−. The functions φσ∗(f +qθ) and φσ∗(f −qθ)
are then the probability densities of random variables X+ + σZ and X−+ σZ, for Z
a variable with the standard normal distribution that is independent of X+ and X−.
Equality of the probability densities of the variables X+ + σZ and X−+ σZ implies
equality in distribution, for every σ > 0. As σ →0, the quantities converge with
probability 1 to X+ and X−. It follows that the latter are also equal in distribution.
The probability densities f +qθ and f −qθ therefore agree, from which we conclude
that f + = f −and therefore f = 0.
The condition of the theorem indirectly requires the parameter space of Θ to be
suﬃciently rich. It is a logical condition, because completeness means that the system
of equations
Eθf(V ) = 0
for all θ ∈Θ
has only one solution in f, namely f ≡0. If there are "too few" θ, then there are too
few equations to determine f uniquely, and V is not complete. The condition of the
theorem is ﬂexible: the existence of an arbitrarily small open set in the codomain of Q
suﬃces.
Example 6.22 Binomial distribution
Let X be binomially distributed with parameters n and p. The binomial probability
density can be written as
n
x

px(1 −p)n−x = (1 −p)n
n
x

ex log(p/(1−p)).
This statistical model therefore forms a one-dimensional exponential family, with
c(p) = (1−p)n, h(x) =
n
x

, V (x) = x, and Q(p) = log(p/(1−p)). If we take [0, 1]
as the parameter space for p, then the set

Q(p): 0 ≤p ≤1

=

log

p/(1 −p)

: 0 ≤p ≤1

of Theorem 6.21 is equal to R and certainly contains an interior point. The statistic
V (X) = X is therefore both suﬃcient and complete. The estimator X/n for p
is unbiased and based only on the suﬃcient and complete random variable, and is
therefore a UMVU estimator by Theorem 6.18.
For the same reason, (X/n)2 is a UMVU estimator for the expectation
Ep(X/n)2 = p(1 −p)/n + p2. Can we use this to deduce a UMVU estimator for
p2?
225

6: Optimality Theory
Example 6.23 Poisson distribution
The probability density of a sample X = (X1, . . . , Xn) from the Poisson(θ)-
distribution can be written as
n

i=1
e−θθxi
xi!
= e−nθ
1
n
i=1xi!e
n
i=1xi log θ.
We conclude that this model forms a one-dimensional exponential family, with c(θ) =
e−nθ, h(x) = (n
i=1xi!)−1, V (x) = n
i=1xi, and Q(θ) = log θ. The set

Q(θ): θ > 0

=

log θ: θ > 0

= (−∞, ∞)
contains an interior point. The sum V (X) = n
i=1Xi is therefore suﬃcient and
complete. The estimator X for θ is unbiased and based only on the suﬃcient
and complete random variable, and is therefore a UMVU estimator for θ (see
Theorem 6.18).
Example 6.24 Normal distribution
The probability density of a sample X
=
(X1, . . . , Xn) from the N(μ, σ2)-
distribution can be written as
n

i=1
1
√
2πσ2 e−
1
2σ2 (xi−μ)2 =

1
√
2πσ2
n
e−
n
2σ2 μ2e
μ
σ2
n
i=1xi−
1
2σ2
n
i=1x2
i .
If we take the natural parameter space Θ = R×(0, ∞) for the parameter θ = (μ, σ2),
then the set from Theorem 6.21 is equal to
 μ
σ2 , −1
2σ2

: μ ∈R, σ2 > 0

= R × (−∞, 0)
and contains an interior point. We conclude that the statistic (n
i=1Xi, n
i=1X2
i )
is suﬃcient and complete. Because the sample variance can be rewritten as S2
X =
(n −1)−1(n
i=1X2
i −n(X)2), it immediately follows that X and S2
X are UMVU
estimators for μ and σ2.
Example 6.25 Curved normal family
Let X = (X1, . . . , Xn) be a sample from the N(θ, θ2)-distribution. The joint density
is then given by
n

i=1
1
√
2πθ2 e−1
2 (xi−θ)2/θ2 =

1
√
2πθ2
n
e−1
2 ne
n
i=1xi/θ−1
2
n
i=1x2
i /θ2.
This probability density belongs to the two-dimensional exponential family with
Q(θ) =
1
θ, −1
2θ2

,
and V (X) = (n
i=1Xi, n
i=1X2
i ). However, the condition of Theorem 6.21 is not
satisﬁed. For θ varying over R, the function θ →Q(θ) is a "one-dimensional curve"
in R2; as a subset of R2, it does not contain any interior points.
226

6.3: Estimation Theory
The previous examples, as well as other examples, give a large number of
interesting cases where a UMVU estimator exists and is reasonable. The UMVU
criterion is therefore very appealing. We do have a few comments:
- Sometimes there is no unbiased estimator.
- Even if there exist (many) unbiased estimators, a UMVU estimator does not
necessarily exist.
- There can exist a biased estimator with an overall smaller mean square error than
that of the UMVU estimator.
- The bias is not invariant under nonlinear transformations: if T is UMVU for θ,
then g(T ) is in general not unbiased for g(θ), and therefore also not UMVU.
In other words, always (only) looking for UMVU estimators is not wise, and can
sometimes mean looking for a nonexistent estimator. The UMVU criterion is therefore
not the answer to all questions. Unfortunately, there is no criterion in statistics that
always "works" and pleases everyone. In practice, it is wise to apply several methods
that seem reasonable. If the results do not diverge too much, we can conﬁdently use our
favorite criterion. Otherwise, there is a problem that may not be solvable objectively.
6.3.2 Cram´er-Rao Lower Bounds
Instead of looking for a best estimator according to a speciﬁc criterion, we can also try
to give a lower bound for the mean square error of an arbitrary estimator. For a given
estimator, we can then compare the mean square error with the lower bound, and it
is then clear how much this estimator may still be improved. Such a lower bound can
then only depend on the given statistical model.
Such lower bounds naturally lead to the same shortcoming as "best estimators":
unless we restrict the class of estimators, the absolute lower bound for the mean square
error is 0, and therefore useless.
The Cram´er-Rao lower bound is restricted to unbiased estimators. First, consider
the case of a real-valued parameter θ. If pθ is the probability density of the (full)
observation X, θ = log pθ, and ˙θ = ∂/∂θ log pθ = ˙pθ/pθ is the score function, then
the Fisher information is deﬁned as
Iθ = varθ ˙θ(X).
Unlike the notation in Chapter 5, we have denoted the Fisher information with a capital
Iθ. This is to distinguish between the Fisher information in the full observation and
that in partial observations.
Theorem 6.26 Cram´er-Rao inequality
Suppose that θ →pθ(x) is diﬀerentiable for every x. Under certain regularity
conditions, the variance of every unbiased estimator T of g(θ) ∈R satisﬁes
varθ T ≥g′(θ)2
Iθ
,
with g′ the derivative of g.
227

6: Optimality Theory
Proof.
We write the formulas under the assumption that X is continuously
distributed. (For a discrete probability density, we replace the integrals by sums.) Since
g(θ) = EθT for all θ, we have
g(θ) = ∂
∂θ

T (x)pθ(x) dx =

T (x) ˙pθ(x) dx
=

T (x) ˙θ(x)pθ(x) dx = Eθ

T ˙θ(X)

.
The fact that we may change the order of diﬀerentiation and integration comes
from the regularity conditions. (Explicit conditions are given in calculus, or rather
in measure theory.) We already saw in Lemma 5.10 that Eθ ˙θ(X) = 0. Combining
these two equalities gives g(θ) = Eθ(T ˙θ(X)) −EθT Eθ ˙θ(X) = covθ

T, ˙θ(X)

.
By the Cauchy-Schwarz inequality, we now have
covθ

T, ˙θ(X)
2 ≤varθ T varθ ˙θ(X) = varθ T Iθ.
The inequality of the theorem now follows by replacing covθ

T, ˙θ(X)
2 on the left-
hand side by g(θ)2 and then dividing by Iθ.
The number g(θ)2/Iθ is called the Cram´er-Rao lower bound for estimating
g(θ). For estimating θ, it of course reduces to 1/Iθ. We call the lower bound sharp
if there exists an unbiased estimator T whose variance is equal to the lower bound.
In that case, T is automatically a UMVU estimator for g(θ) because T is an unbiased
estimator for g(θ) and has minimal variance.
The greater the Fisher information, the smaller the Cram´er-Rao lower bound.
Theorem 6.26 suggests that in that case, we can give a more accurate estimate of
θ. Since the lower bound is not always sharp, this suggestion is not entirely correct.
However, at the end of the chapter, we will see that the bound is sharp for (inﬁnitely)
large samples.
The theorem can be extended to multidimensional parameters θ. In that case, the
Fisher information is not a number but a matrix, the Fisher information matrix
Iθ =

covθ
 ∂
∂θi
θ(X), ∂
∂θj
θ(X)

i,j=1,. . .k
.
We still restrict ourselves to real-valued functions g, and denote the gradient of g in θ
by g(θ) (a row vector). Then for every unbiased estimator T of g(θ), we have
varθ T ≥g(θ)I−1
θ g(θ)T .
In particular, the lower bound for the ﬁrst coordinate g(θ) = θ1 is equal to the (1, 1)-
element of I−1
θ , because in that case the gradient is the vector g(θ) = (1, 0, . . . , 0).
When the full observation X is made up of independent subobservations
X1, . . . , Xn, we can use that the information is additive.
228

6.3: Estimation Theory
Lemma 6.27
Let X and Y be independent random variables. Then the Fisher information in the
observation (X, Y ) is equal to the sum of the information in X and Y separately.
Proof. We give the proof only for the case where the parameter θ is real valued.
The (joint) density of (X, Y ) is the product (x, y) →pθ(x)qθ(y) of the (marginal)
densities of X and Y . The Fisher information in (X, Y ) is the variance of the score
function
∂
∂θ log pθ(x)qθ(y) = ∂
∂θ log pθ(x) + ∂
∂θ log qθ(y).
Because of the independence, this variance is the sum of the variances of the two terms
on the right-hand side, namely the Fisher information in X and Y .
In particular, the Fisher information in a vector X
=
(X1, . . . , Xn) of
independent, identically distributed observations X1, . . . , Xn is equal to n times
the Fisher information in one Xi, that is, Iθ = niθ, where iθ denotes the Fisher
information in one observation. The Cram´er-Rao inequality then becomes: for every
unbiased estimator of g(θ) based on X1, . . . , Xn, we have
varθ Tn ≥g(θ)i−1
θ g(θ)T
n
.
Example 6.28 Normal distribution
The Fisher information for μ in one observation from the N(μ, σ2)-distribution (with
σ2 unknown) is equal to
iμ = varμ
 ∂
∂μ

log

1
σ
√
2π e−1
2 (X1−μ)2/σ2
= varμ
X1 −μ
σ2

= 1
σ2 .
The Cram´er-Rao lower bound for estimating μ based on a sample X1, . . . , Xn of size
n from the N(μ, σ2)-distribution is therefore
1
niμ
= σ2
n .
This is exactly the variance of the unbiased estimator X for μ. In this case, the
Cram´er-Rao lower bound is therefore sharp. We have again proved that X is a UMVU
estimator for μ, without using the theory of suﬃcient and complete statistics from
Section 6.2 and Theorem 6.18.
The estimator X2−σ2/n is unbiased for μ2 (and an estimator because we assume
σ2 known) and a function of the suﬃcient, complete variable X, hence UMVU. Some
computation gives
varμ

X2 −σ2
n

= 4μ2σ2
n
+ 2σ4
n2 .
229

6: Optimality Theory
The Cram´er-Rao lower bound for the variance of an unbiased estimator of μ2 is equal
to

(μ2)2
niμ
= 4μ2σ2
n
.
Hence in this case, this lower bound is not attained. However, the extra term 2σ4/n2
is small, and becomes negligible with respect to the ﬁrst term as n →∞.
Example 6.29 Binomial distribution
The Fisher information for p in a bin(n, p)-distributed observation X is equal to
varp
 ∂
∂p

log
 n
X

pX(1 −p)n−X
= varp
 X −np
p(1 −p)

=
n
p(1 −p).
The Cram´er-Rao lower bound for the variance of an unbiased estimator for p based
on X is therefore
p(1 −p)
n
.
This is exactly the variance of the unbiased estimator X/n. Hence in this case, the
Cram´er-Rao lower bound is sharp, and we may conclude that X/n is a UMVU
estimator for p.
Example 6.30 Uniform distribution
Let X = (X1, . . . , Xn) be a sample from the uniform distribution on the interval
[0, θ]. The estimator (n + 1)/nX(n) is unbiased and has variance
varθ
n + 1
n
X(n) =
θ2
n(n + 2).
For large n (and every given θ), this variance is much smaller than a bound of the
form 1/(niθ). So in this case the Cram´er-Rao lower bound does not hold. The reason
is that the density does not depend on the parameter in a diﬀerentiable manner. An
expression such as ˙θ(x) is not well deﬁned for all x.
Upon further consideration, it turns out that the Cram´er-Rao lower bound is
seldom sharp. Nevertheless, we conclude this section with the essential assertion that,
in a sense, the Cram´er-Rao lower bound is asymptotically sharp and that the bound is
attained by the maximum likelihood estimator.
We can see this as follows. We already know from Theorem 5.9 that under θ,
the maximum likelihood estimator ˆθn based on a sample of size n from a density that
depends on the parameter in a diﬀerentiable manner satisﬁes
√n(ˆθn −θ) ⇝N(0, i−1
θ )
230

6.4: Testing Theory
as n →∞. A rough interpretation of this result is that, for large n, the random vector
√n(ˆθn −θ) is normally distributed with Eθ
√n(ˆθn −θ) ≈0 and varθ
√n(ˆθn −θ) ≈
i−1
θ . It immediately follows that
Eθˆθn ≈θ,
varθ ˆθn ≈i−1
θ
n .
In other words, the maximum likelihood estimator is (asymptotically) unbiased for
θ with (asymptotic) variance equal to the Cram´er-Rao lower bound, hence equal
to the minimal variance for unbiased estimators. Conclusion: maximum likelihood
estimators are asymptotically UMVU. This result is a strong motivation for using
maximum likelihood estimators.
Maximum likelihood estimators are not the only types of estimators that
are asymptotically UMVU. For example, by the Bernstein-von Mises theorem,
Theorem 5.26, the median of the posterior distribution has the same asymptotic
distribution provided that the prior density is positive on the entire parameter space
Θ. Since, by this theorem, the posterior distribution is asymptotically normal and
therefore symmetric, it moreover follows that, under certain conditions, most Bayes
estimators are asymptotically normal.
Therefore, based on these asymptotic arguments, we cannot express a preference
for maximum likelihood estimators over Bayes estimators or vice versa. On the other
hand, these arguments do show that these two classes of estimators are preferable to
method of moments estimators, which in general are not asymptotically eﬃcient. The
method of moments is interesting because of its simplicity, and also in cases where
the theoretical moments can be speciﬁed but the full probability density cannot. In
the latter case, we cannot implement the maximum likelihood estimators or Bayes
estimators.
6.4 Testing Theory
According to the theory discussed in Chapter 4, a good test has size less than or equal
to the given level and a power function that is as large as possible. A test is uniformly
most powerful (at a given level) if, under the alternative hypothesis, the power function
is maximal in all possible parameter values. In this section, we discuss several special,
but important, cases in which a uniformly most powerful test exists.
6.4.1 Simple Hypotheses
A "simple" hypothesis is one that consists of only one parameter value. In most cases,
for tests of a simple null hypothesis against a simple alternative, there exists an optimal
test, that is, a test with a maximal power function in the parameter value, under the
alternative hypothesis. This is the statement of the following "fundamental lemma" of
the theory of tests.
231

6: Optimality Theory
Suppose that, for a given parameter space Θ = {θ0, θ1}, pθ0 and pθ1 are
the two possible probability densities of the observation X. Let L(θ1, θ0; X) =
pθ1(X)/pθ0(X) be the quotient of these densities, evaluated in the observation.
Theorem 6.31 Neyman-Pearson
Suppose that there exists a number cα0 such that Pθ0

L(θ1, θ0; X) ≥cα0

= α0.
Then the test with critical region K = {x: L(θ1, θ0; x) ≥cα0} is most powerful at
level α0 for testing H0: θ = θ0 against H1: θ = θ1.
Proof. By the assumption on the number cα0, the size of the critical region K
mentioned in the theorem is exactly α0. Suppose that K′ is another critical region
of size at most α0, that is, Pθ0(X ∈K′) ≤α0. We must prove that Pθ1(X ∈K′) ≤
Pθ1(X ∈K).
We claim that for all x,

1K′(x) −1K(x)

pθ1(x) −cα0pθ0(x)

≤0.
Indeed, if x ∈K, then 1K′(x)−1K(x) = 1K′(x)−1 ≤0 and pθ1(x)−cα0pθ0(x) ≥0
by the deﬁnition of K. If x /∈K, then both inequalities hold in the other direction.
In both cases, the expression on the left-hand side of the inequality is the product of a
nonpositive and a nonnegative term, and is therefore nonpositive.
The integral of this nonpositive function over the sample space (or the sum if the
distribution is discrete) is then also nonpositive. We can write this as
 
1K′(x) −1K(x)

pθ1(x) dx ≤cα0
 
1K′(x) −1K(x)

pθ0(x) dx
= cα0(Pθ0(X ∈K′) −Pθ0(X ∈K))
≤cα0(α0 −α0) = 0.
It follows that Pθ1(X ∈K′) ≤Pθ1(X ∈K), and therefore the test with critical
region K is most powerful at level α0.
The test from Theorem 6.31 is intuitively reasonable because it rejects the null
hypothesis H0: θ = θ0 in favor of the alternative H1: θ = θ1 when under H1, the
density pθ1(X) in the observation is large with respect to the density pθ0(X) under
the null hypothesis. The motivation for this is the same as in the case of the likelihood
ratio test. We view pθ(x) as a measure for the probability that the realization x occurs
if θ is the true parameter, and a small value of pθ(x) means that it is improbable that
θ is the true parameter. (When cα0 ≥1, the test from Theorem 6.31 reduces to the
likelihood ratio test.) Test of the same form as that in Theorem 6.31 are also called
likelihood ratio tests or Neyman-Pearson tests.
232

6.4: Testing Theory
Example 6.32 Gauss test
Let X = (X1, . . . , Xn) be a sample from the normal distribution with unknown
expectation μ and known variance σ2. We want to test the simple null hypothesis
H0: μ = μ0 against the simple alternative H1: μ = μ1. The Neyman-Pearson lemma
says that the test with test statistic
L(μ1, μ0; X) = exp

−
1
2σ2
n

i=1
(Xi −μ1)2 +
1
2σ2
n

i=1
(Xi −μ0)2
= exp

nX(μ1 −μ0)/σ2 + n(μ2
0 −μ2
1)/(2σ2)

and critical region K = {x = (x1, . . . , xn): L(μ1, μ0; x) ≥cα0}, with cα0 such that
Pμ0(L(μ1, μ0; X) ≥cα0) = α0, is the most powerful test at level α0 for testing
the null hypothesis in question. The null hypothesis is rejected for large values of
L(μ1, μ0; X), that is, for large values of X(μ1 −μ0). This means that if μ1 > μ0,
the null hypothesis is rejected for large values of X or, equivalently, for large values
of T = √n(X −μ0)/σ. The most powerful test is therefore the test that rejects the
null hypothesis for √n(X −μ0)/σ greater than a value dα0 such that Pμ0(√n(X −
μ0)/σ ≥dα0) = α0. Since under μ = μ0, the quantity √n(X −μ0)/σ has the
standard normal distribution, we have dα0 = ξ1−α0, and the null hypothesis is rejected
for √n(X −μ0)/σ ≥ξ1−α0. This is exactly the Gauss test from Example 4.12. The
conclusion is that the Gauss test is the most powerful test for testing the simple null
hypothesis H0: μ = μ0 against the simple alternative H1: μ = μ1 based on a sample
from the normal distribution with unknown expectation μ and known variance σ2.
Under the null hypothesis, the condition of Theorem 6.31 that there exist a
number cα0 such that Pθ0

L(θ1, θ0; X) ≥cα0

= α0 is always satisﬁed when
the likelihood ratio statistic L(θ1, θ0; X) has a continuous distribution function.
Namely, the condition is equivalent to the condition that the distribution function of
L(θ1, θ0; X) is equal to 1 −α0 in cα0. The size of the optimal test is exactly α0.
If the distribution function of L(θ1, θ0; X) has jumps, then there will not exist a
cα0 for every α0. The statement of Theorem 6.31 can then be incorrect. The idea that
an optimal test can be based on the likelihood ratio statistic L(θ1, θ0; X) does remain
true, however. In all cases, we can ﬁnd a value cα0 such that
Pθ0

L(θ1, θ0; X) > cα0

≤α0 ≤Pθ0

L(θ1, θ0; X) ≥cα0

.
If these inequalities are strict, then the test with critical region
K = {x: L(θ1, θ0; x) > cα0}
has size strictly less than α0 and the test with critical region K = {x: L(θ1, θ0; x) ≥
cα0} has size strictly greater than α0. The second test is not admissible, but the ﬁrst test
is not necessarily most powerful because we could further enlarge the critical region.
We can construct a more powerful test by sometimes also rejecting the null hypothesis
when L(θ1, θ0; x) = cα0.
233

6: Optimality Theory
In some examples, the set {x: L(θ1, θ0; x) = cα0} can be split into two
subsets R1 and R2, and the test that rejects when L(θ1, θ0; X) > cα0 and when
L(θ1, θ0; X) = cα0 and X ∈R1 is most powerful. In general, we can extend
Theorem 6.31 to likelihood ratio statistics with jumps in the distribution function by
generalizing the notion of test.
Deﬁnition 6.33 Randomized test
A randomized test is a statistic ψ with values in [0, 1]. If x is observed, then we
reject H0 with probability ψ(x). The power function of the randomized test ψ is by
deﬁnition equal to π(θ; ψ) = Eθψ(X), and the size is equal to supθ∈Θ0 π(θ; ψ).
A test with critical region K is a special case of a randomized test, through
the identiﬁcation ψ(x) = 1K(x). If we allow randomized tests, there always exists
a most powerful test. The proof of the following theorem is analogous to that of
Theorem 6.31.
Theorem 6.34 Neyman-Pearson
There exist numbers cα0 and δ ∈[0, 1] such that
Pθ0

L(θ1, θ0; X) > cα0

+ δPθ0

L(θ1, θ0; X) = cα0

= α0.
For every choice of these numbers, the randomized test
ψ = 1{x:L(θ1,θ0;x)>cα0} + δ1{x:L(θ1,θ0;x)=cα0}
is the most powerful test at level α0 for testing H0: θ = θ0 against H1: θ = θ1.
As the theorem shows, the optimal test only uses the randomization to sometimes
reject or not observations in the "boundary region" {x: pθ1(x)/pθ0(x) = cα0}. If the
likelihood ratio L(θ1, θ0; X) is strictly greater than cα0, then we always reject, and if
the ratio is strictly smaller, then we never reject. In the intermediate case, we reject
with probability δ. The randomization with a constant probability δ as in the theorem
is one way to "split" the boundary region, and often the optimal test is not unique with
respect to this aspect.
The randomized test mostly has a theoretical interest. In practice, it is rarely used.
Example 6.35 Binomial distribution
Let X be binomially distributed with parameter n and unknown probability p ∈[0, 1].
The likelihood ratio for testing the simple null hypothesis H0: p = p0 against H1: p =
p1 is given by
L(p1, p0; X) =
 n
X

pX
1 (1 −p1)n−X
 n
X

pX
0 (1 −p0)n−X =
p1
p0
X1 −p1
1 −p0
n−X
.
234

6.4: Testing Theory
In this example, we assume p1 > p0, so that L(p1, p0; x) is increasing in x. A large
value of X therefore implies a large value of L(p1, p0; X) (and vice versa). The
question is now for which values of X we must reject the null hypothesis.
Suppose n = 100, p0 = 1/2, and α0 = 0.05; then P0.5(X ≥59) = 0.044
and P0.5(X ≥58) = 0.067 (see Example 4.11). It follows that the test given by the
critical region {59, 60, . . ., 100} has level 0.05, while the test that rejects for X ≥58
is not admissible at this level. The size of the given test, 0.044, is strictly less than the
level α0 = 0.05. This means that the Neyman-Pearson lemma (Theorem 6.31) cannot
be applied and the test may not be optimal. The randomized test deﬁned by
ψ(x) = 1{x≥59} + 0.26 1{x=58},
on the other hand, does have size exactly equal to 0.05:
E0.5ψ(X) = P0.5(X ≥59) + 0.26P0.5(X = 58) = 0.05.
By Theorem 6.34, the randomized test ψ is now most powerful for testing H0: p = 1/2
against H1: p = p1 for p1 > 1/2.
Note that in this example, we only assume p1 > p0; we do not make any
assumptions about the exact value of p1.
Example 6.36 Uniform distribution
The likelihood ratio for testing the null hypothesis H0: θ = θ0 against the alternative
hypothesis H1: θ = θ1 for θ1 > θ0 based on a sample X = (X1, . . . , Xn) from the
uniform distribution on [0, θ] is given by
L(θ1, θ0; X) =
(1/θ1)n1{X(n)≤θ1}
(1/θ0)n1{X(n)≤θ0} =
 
θ0
θ1
n
if X(n) ≤θ0,
∞
if θ0 < X(n) ≤θ1.
Under the null hypothesis, we are always in the ﬁrst case, and the likelihood ratio has a
degenerate probability distribution; all probability mass lies in the point (θ0/θ1)n. The
value cα0 from Theorem 6.34 is therefore equal to the constant value (θ0/θ1)n of the
likelihood ratio, and the sets of values of the observation for which the likelihood ratio
is strictly greater than or equal to cα0 are, respectively, the sets {(x1, . . . , xn): x(n) >
θ0} and {(x1, . . . , xn): x(n) ≤θ0}.
By Theorem 6.34, the randomized test ψ(X1, . . . , Xn)
=
1{X(n)>θ0} +
δ1{X(n)≤θ0} is optimal, where the randomization value δ must be such that the size
is equal to α0. Since the size is equal to Pθ0(X(n) > θ0) + δPθ0(X(n) ≤θ0) =
δPθ0(X(n) ≤θ0) and Pθ0(X(n) ≤θ0) = 1, we have δ = α0. This test corresponds to
rejecting when X(n) takes on a value that is impossible under the null hypothesis (that
is, when X(n) > θ0) and always randomizing with probability α0 when X(n) takes on
a value that is possible under H0. The ﬁrst is quite natural, while the randomization
does not seem reasonable intuitively.
235

6: Optimality Theory
The optimal test is not unique. In particular, we can avoid randomization by
taking K = {(x1, . . . , xn): x(n) > dα0} with dα0 = θ0
n√1 −α0 as the critical
region, so that the size of this test is equal to α0. This test and the previously described
randomized test both have power function 1 −(1 −α0)(θ0/θ1)n in θ1. We have then
replaced the randomization with probability α0 when X(n) ∈[0, θ0] with always
rejecting when X(n) ∈[θ0
n√1 −α0, θ0]. (Note that both tests always reject when
L(θ1, θ0; X) = ∞and reject with probability α0 when L(θ1, θ0; X) = (θ0/θ1)n. In
terms of the likelihood ratio, the optimal test is therefore unique.)
6.4.2 Monotone Likelihood Ratio
In the previous section, we saw that for testing simple hypotheses, there always exists
an optimal test. For general hypotheses, this unfortunately does not hold. A test is
optimal for a composite alternative hypothesis if the test is uniformly most powerful
in the sense of the following deﬁnition.
Deﬁnition 6.37 Uniformly most powerful test
A test with power function θ →π(θ; K) is called uniformly most powerful or UMP
at size α0 for testing H0: θ ∈Θ0 against H1: θ ∈Θ1 if supθ∈Θ0 π(θ; K) ≤α0 and
the power function θ →π(θ; K) of every other test with supθ∈Θ0 π(θ; K) ≤α0
satisﬁes π(θ; K) ≥π(θ; K) for all θ ∈Θ1.
The qualiﬁcation of "uniform" in "uniformly most powerful" refers to the fact
that the power function of an optimal test must be maximal for all parameter values
under the alternative hypothesis: a uniformly most powerful test for H0: θ ∈Θ0
against H1: θ ∈Θ1 must be most powerful for testing H0: θ ∈Θ0 against H1: θ = θ1
for all θ1 ∈Θ1. The greater the parameter space under the alternative hypothesis, the
stronger this condition.
Nevertheless, in a number of important examples, there do exist uniformly most
powerful tests. First, consider testing a simple null hypothesis H0: θ = θ0 against a
composite alternative hypothesis H1: θ ∈Θ1. A test of level α0 for this composite
problem is also a test of level α0 for every simple testing problem of H0: θ = θ0
against H1: θ = θ1, for every θ1 ∈Θ1. By Theorems 6.31 and 6.34, the most powerful
test for such a simple problem is the Neyman-Pearson test based on the likelihood
ratio pθ1(X)/pθ0(X). It follows from the proofs that the Neyman-Pearson test is also
the unique most powerful test when the likelihood ratio statistic has a continuous
distribution function. We conclude that when the Neyman-Pearson tests for diﬀerent
alternatives θ1 ∈Θ1 diﬀer, there cannot exist a uniformly most powerful test.
Conversely, we can also apply this reasoning in the positive direction and
conclude that if the Neyman-Pearson test for H0: θ = θ0 against H1: θ = θ1 is the
same for every θ1 ∈Θ1, then this test is automatically uniformly most powerful.
At ﬁrst glance, the Neyman-Pearson test with test statistic pθ1(X)/pθ0(X) seems to
always depend on θ1. This is not the case because the critical value of this test will
also depend on θ1, and these two dependencies can cancel each other out.
236

6.4: Testing Theory
Example 6.38 Gauss test, continued from Example 6.32
Let X = (X1, . . . , Xn) be a sample from the normal distribution with unknown
expectation μ and known variance σ2. We are looking for the uniformly most powerful
test for testing the simple null hypothesis H0: μ = μ0 against the composite alternative
H1: μ > μ0.
We already saw in Example 6.32 that for a simple null hypothesis and a simple
alternative hypothesis, the Gauss test is most powerful. In this example, we show that
this also holds for the composite alternative hypothesis given above.
The most powerful test for testing H0: μ = μ0 against H1: μ = μ1 for μ1 >
μ0 rejects the null hypothesis for √n(X −μ0)/σ > ξ1−α0. This criterion does not
depend on the value μ1, and this test is therefore most powerful for every value of
μ1 ∈(μ0, ∞). We conclude that the Gauss test is uniformly most powerful for testing
H0: μ = μ0 against H1: μ > μ0.
Example 6.39 Binomial distribution, continued from Example 6.35
Let X be binomially distributed with parameter n and unknown probability p ∈[0, 1].
In Example 6.35, we deduced that for n = 100 and α0 = 0.05, the most powerful
test for testing the simple hypotheses H0: p = 1/2 against H1: p = p1 with p1 > 1/2
is the randomized test that rejects H0 when X ≥59 and rejects it with probability
0.26 when X = 58. We already noted in that example that the test does not depend
on the value of p1 provided p1 > p0 = 1/2. We can immediately conclude that the
randomized test described here is uniformly most powerful for testing H0: p = 1/2
against H1: p > 1/2.
Example 6.40 Uniform distribution, continued from Example 6.36
In Example 6.36, we saw that the test that rejects H0 when X(n) ≥dα0 for dα0 =
θ0
n√1 −α0 is uniformly most powerful for testing H0: θ = θ0 against H1: θ = θ1 for
every θ1 > θ0. This test does not depend on θ1. We conclude that the test is uniformly
most powerful for testing H0: θ = θ0 against H1: θ > θ0.
Through a similar reasoning, we can sometimes also deduce a uniformly most
powerful test for a composite null hypothesis from uniformly most powerful tests for
simple null hypotheses. The relevant criterion is the size. A test that is uniformly
most powerful for testing H0: θ = θ0 against H1: θ ∈Θ1 for a given θ0 ∈Θ0 is
also uniformly most powerful for testing H0: θ ∈Θ0 against H1: θ ∈Θ1 provided
that the test is of level α0 for this problem, so that the test is admissible. The latter
is not necessarily the case, because the size for the null hypothesis H0: θ ∈Θ0 (a
supremum over Θ0) is greater than that for a simple hypothesis H0: θ = θ0. It is,
however, suﬃcient if we can justify the reasoning for one parameter value θ0 ∈Θ0,
namely the value in which the supremum is taken on.
237

6: Optimality Theory
Example 6.41 Gauss test, continued from Example 6.38
We already saw in Example 6.38 that the Gauss test is a uniformly most powerful test
for a simple null hypothesis and composite alternative hypothesis. In this example,
we will see that even when the null hypothesis is composite, the Gauss test remains
uniformly most powerful. Consider the hypothesis H0: μ ≤μ0 against the alternative
hypothesis H1: μ > μ0. We only need to show that the size of the Gauss test is equal
to α0:
sup
μ≤μ0
Pμ
√nX −μ0
σ
≥ξ1−α0

= Pμ0
√nX −μ0
σ
≥ξ1−α0

= α0,
as we already saw in Example 4.12.
Example 6.42 Binomial distribution, continued from Example 6.39
Let X be binomially distributed with parameters n and unknown probability p ∈[0, 1].
In Example 6.39, we gave a uniformly most powerful randomized test for testing the
simple null hypothesis H0: p = 1/2 against the composite alternative H1: p > 1/2.
In this example we show that this randomized test is also uniformly most powerful
for testing the composite null hypothesis H0: p ≤1/2 against the alternative H1: p >
1/2. We must show that the randomized test also has level α0 = 0.05 for this null
hypothesis; in other words, we must show that supp≤1/2 Epψ(X) ≤0.05 for ψ(x) =
1{x≥59} + 0.26 1{x=58}. The size of the test is given by
sup
p≤1/2
Epψ(X) = sup
p≤1/2

Pp(X ≥59) + 0.26Pp(X = 58)

.
The supremum is taken on at p = 1/2 (see Example 4.11) and E0.5ψ(X) = 0.05 (see
Example 6.35).
Example 6.43 Uniform distribution, continued from Example 6.36
The size of the test from Example 6.36 for testing the null hypothesis H0: θ ≤θ0,
which rejects when X(n) ≥dα0 = θ0
n√1 −α0, is given by
sup
θ≤θ0
Pθ(X(n) ≥dα0) = Pθ0(X(n) ≥dα0) = α0
by the construction of dα0. We conclude that the test is uniformly most powerful for
testing H0: θ ≤θ0 against H1: θ > θ0.
We can use the previous arguments to show that uniformly most powerful tests
exist for testing one-sided hypotheses for one-dimensional exponential families. By
Deﬁnition 6.20, a family of probability densities pθ belongs to a one-dimensional
exponential family if there exist functions c, h, and Q such that the density in the
family is of the following form:
pθ(x) = c(θ)h(x)eQ(θ)V (x),
for a one-dimensional suﬃcient statistic V (X). In the following theorem, we assume
that the density of the observation X is of this form.
238

6.4: Testing Theory
Theorem 6.44 Exponential family
Suppose that the density of X belongs to a one-dimensional exponential family
with suﬃcient statistic V = V (X) and that there exists a number dα0 such that
Pθ0

V (X) > dα0

= α0. Then the test with critical region K = {x: V (x) > dα0}
is uniformly most powerful at level α0 for testing H0: Q(θ) ≤Q(θ0) against
H1: Q(θ) > Q(θ0).
Proof. The Neyman-Pearson test for testing the simple null hypothesis H0: θ = θ0
against the alternative hypothesis H1: θ = θ1 is based on the likelihood ratio
L(θ1, θ0; x) = c(θ1)
c(θ0) e(Q(θ1)−Q(θ0))V (x).
By Theorem 6.34, the most powerful test for testing H0: θ = θ0 against H1: θ = θ1 is
the randomized test
ψ(x) = 1{L(θ1,θ0;x)>cα0} + δ1{L(θ1,θ0;x)=cα0}
for constants cα0 and δ such that the size of the test is equal to α0, that is, such that
Pθ0(L(θ1, θ0; X) > cα0) + δPθ0(L(θ1, θ0; X) = cα0) = α0. For Q(θ1) > Q(θ0),
the likelihood ratio L(θ1, θ0; x) is a strictly increasing function of V (x), so that the
randomized test ψ is equivalent to the test
ψ(x) = 1{V (x)>dα0} + δ1{V (x)=dα0},
for dα0 such that the size of the test is α0. It follows from the assumption that there
exists a number dα0 such that Pθ0

V (X) > dα0

= α0, so that we can choose δ = 0.
Since this test does not depend on the alternative θ1, provided Q(θ1) > Q(θ0), the test
is automatically uniformly most powerful for testing H0: θ = θ0 against H1: Q(θ) >
Q(θ0).
Every test of level α0 for testing H0: Q(θ) ≤Q(θ0) against H1: Q(θ) > Q(θ0)
is also a test of level α0 for testing H0: Q(θ) = Q(θ0) against H1: Q(θ) > Q(θ0). Its
power function is therefore not greater than that of the best test for this problem, the
test ψ deﬁned above. It now suﬃces to prove that the latter has size α0 for the null
hypothesis H0: Q(θ) ≤Q(θ0).
The density pθ(x) = c(θ)h(x) exp(Q(θ)V (x)) is exponential in V (x). The form
of this distribution depends on Q(θ). A larger value of Q(θ) puts relatively more
probability mass on large values of V (x) and less on small values of V (x). This
implies that for every d, the probability Pθ(V ≥d) increases as Q(θ) increases. In
other words, for every parameter value θ with Q(θ) ≤Q(θ0), we have Pθ(V (X) ≥
d) ≤Pθ0(V (X) ≥d) for every d. This holds, in particular, for d = dα0, which means
that the test ψ has size α0 for the null hypothesis H0: Q(θ) ≤Q(θ0). This concludes
the proof of the theorem.
239

6: Optimality Theory
Example 6.45 Gauss test
Let X = (X1, . . . , Xn) be a sample from the normal distribution with unknown
expectation μ and known variance σ2. If we assume σ2 known, then the statistical
model is a one-dimensional exponential family with suﬃcient quantity X. By
Theorem 6.44, there exists a uniformly most powerful test for H0: μ ≤μ0 against
H1: μ > μ0, and this rejects H0 for large values of X. We again recover the Gauss
test from Example 4.12.
The proof of Theorem 6.44 in fact only uses the structure of the exponential
family because this implies that there exists a one-dimensional suﬃcient quantity
V whose distributions under the diﬀerent values of the parameter are ordered
stochastically. The reasoning for the existence of a uniformly most powerful test for
the uniform distribution in Example 6.43 has the same structure. We can unite the two
cases under the notion of "monotone likelihood ratio family."
Deﬁnition 6.46 Monotone likelihood ratio
A statistical model {pθ: θ ∈Θ ⊂R} is called a family with monotone likelihood
ratio if there exist a real-valued statistic V and a monotonically increasing function
gθ0,θ1 for all θ0 ≤θ1 such that
pθ1(x)
pθ0(x) = gθ0,θ1

V (x)

.
Within a family with monotone likelihood ratio, the statistic V is suﬃcient by
the factorization theorem. Moreover, the monotonicity of the function gθ0,θ1 and the
Neyman-Pearson lemma imply that the most powerful test for H0: θ = θ0 against
H1: θ = θ1 for a given θ0 < θ1 can be based on V , where the test rejects H0 for large
values of V . More precisely, there exists a most powerful randomized test of the form
(6.1)
ψ = 1{x:V (x)>dα0} + δ1{x:V (x)=dα0}
for some dα0 and δ. This leads to the following theorem, whose proof is analogous to
that of Theorem 6.44.
Theorem 6.47 Monotone likelihood ratio
For testing the hypothesis H0: θ ≤θ0 against H1: θ > θ0 based on an observation
from a family with monotone likelihood ratio, there exists a uniformly most powerful
randomized test for every given level α0. This test can be taken of the form (6.1), for
V the suﬃcient quantity of the family.
240

6.4: Testing Theory
Example 6.48 Binomial distribution, continued
Let X be a bin(n, p)-distributed random variable. Then the likelihood ratio for
H0: p ≤p0 against H1: p > p0 is equal to
L(p1, p0; X) =
p1
p0
X1 −p1
1 −p0
n−X
(see Example 6.35), which is increasing in X when p1 > p0. By Theorem 6.47, there
now exists a uniformly most powerful randomized test of the form (6.1). We already
found this randomized test in Example 6.42.
6.4.3 Optimality of the t-Test
For statistical models without a one-dimensional suﬃcient quantity, there does not, in
general, exist a uniformly most powerful test. This concerns, in particular, all models
with a two-dimensional parameter. The problem is already apparent with tests of the
expectation parameter for the normal distribution when the variance σ2 is unknown. In
this section, we take X = (X1, . . . , Xn) to be a sample from the normal distribution
with expectation μ and variance σ2. We already saw in the previous section that when
σ2 is assumed known, the Gauss test is the uniformly most powerful test for H0: μ ≤
μ0 against H1: μ > μ0. This test depends on σ and therefore cannot be used when σ
is unknown. An intuitively reasonable solution is to replace the unknown parameter σ
by the sample standard deviation SX. This leads to the t-test, which rejects the null
hypothesis when √n(X −μ0)/SX ≥tn−1,1−α0. In this section, we will prove that
the t-test is uniformly most powerful among the unbiased tests for H0: μ ≤μ0 against
H1: μ > μ0.
Deﬁnition 6.49 Unbiased test
A test is unbiased for testing H0: θ ∈Θ0 against H1: θ ∈Θ1 at a given level α0 if
the power function π of the test satisﬁes π(θ0) ≤α0 ≤π(θ1) for all θ0 ∈Θ0 and
θ1 ∈Θ1.
The randomized test ψ ≡α0, which rejects H0 with probability α0 regardless
of the value of the observation, is unbiased. Since a uniformly most powerful test, if
it exists, must also dominate this test, it follows that a uniformly most powerful test
is automatically unbiased. However, one can prove that at level α0 < 1/2, there do
not exist any uniformly most powerful tests. (Surprisingly, the converse is true when
α0 > 1/2, but such large levels are not interesting from a practical point of view.)
This means that the t-test, although most powerful among the unbiased tests, is not
the most powerful test among all tests. There exist biased tests that have a greater
power function than the t-test in certain alternative values μ > μ0.
241

6: Optimality Theory
Theorem 6.50
The t-test is uniformly most powerful among the unbiased tests for testing H0: μ ≤
μ0 against H1: μ > μ0.
Proof. Without loss of generality, we assume μ0 = 0. Indeed, when μ0 = 0, we can
base the test on the observations X1 −μ0, . . . , Xn −μ0 with expectation ν = μ −μ0.
The new, but equivalent, hypotheses become H0: ν ≤0 against H1: ν > 0.
Suppose that ψ is an unbiased (randomized)test that is admissible at level α0. The
absence of bias implies that the power function (μ, σ2) →Eμ,σ2ψ(X) is at least α0 on
the set {(μ, σ2): μ > 0, σ2 > 0}, while the admissibility implies that this function is
at most α0 on the set of parameters {(μ, σ2): μ ≤0, σ2 > 0}. By the continuity of the
normal distribution in its parameters, the power function is automatically continuous
in (μ, σ2), and on the boundary between these two parameter regions, that is, on the
set of parameters {(0, σ2): σ2 > 0}, the power function is exactly equal to α0. We
conclude that for every σ2 > 0,
(6.2)
α0 = E0,σ2ψ(X) = E0,σ2E0

ψ(X)| X2
.
The family of probability distributions of X = (X1, . . . , Xn), where the Xi are
independent and N(0, σ2)-distributed with σ2 > 0 is a one-dimensional exponential
family, with suﬃcient and complete variable X2. The suﬃciency justiﬁes that we have
indexed the conditional expectation E0

ψ(X)| X2
by the parameter μ = 0 only,
because the conditional distribution of X given X2 is independent of σ2.
It follows from (6.2) that E0,σ2E0

ψ(X) −α0| X2
= 0 for all σ2 > 0. The
completeness of X2 now implies P(E0(ψ(X)−α0| X2) = 0) = 1, that is, for almost
all y,
(6.3)
E0

ψ(X)| X2 = y

= α0.
In other words, the test ψ is necessarily a test of size α0 for testing H0: μ = 0 against
H1: μ > 0 based on an observation X from the conditional distribution of X given
X2 = y, for every y.
Now, consider a ﬁxed y and a ﬁxed parameter (μ, σ2) with μ > 0 from the
alternative hypothesis, and consider the problem of ﬁnding a test that satisﬁes (6.3)
and maximizes the conditional power function Eμ,σ2
ψ(X)| X2 = y

with respect to
(μ, σ2). At ﬁrst glance, this test will depend on the chosen y and (μ, σ2), but we will
show that this is not the case. Since
(6.4)
Eμ,σ2ψ(X) =

Eμ,σ2
ψ(X)| X2 = y

dP X2
μ,σ2(y)
with P X2
μ,σ2 the distribution function of X2 under (μ, σ2), the resulting test ψ
automatically also maximizes (6.4) over the class of tests that satisfy (6.3). Since all
unbiased tests satisfy (6.3), the resulting test is uniformly most powerful among the
unbiased tests.
242

6.4: Testing Theory
To conclude the proof of the theorem, it therefore suﬃces to show that for every
y, the test that maximizes Eμ,σ2
ψ(X)| X2 = y

among all tests that satisfy (6.3)
does not depend on y and is exactly the t-test. We will use Theorem 6.44.
Since the pair (X, X2) is suﬃcient, we may assume without loss of generality
that the test ψ depends only on this pair. For a ﬁxed value of X2 = y, the test ψ is
then a function of only X. We now show that the conditional distribution of X given
X2 = y takes on the form of an exponential family of probability distributions.
By Theorem 4.29, the variables X and S2
X are independent and continuously
distributed. We can ﬁnd the probability density of the pair (X, X2) = (X, (n −
1)S2
X/n + X
2) using the transformation theorem from probability theory, as follows:
p(X,X2)
μ,σ2
(x, y) = p(X,(n−1)S2
X/n)
μ,σ2
(x, y −x2) = φ
 x −μ
σ/√n

p(n−1)S2
X/n
σ
(y −x2).
As a function of x, for ﬁxed y, this expression is proportional to the conditional
density of X given X2 = y. Only the ﬁrst of the two factors of the product
on the right-hand side contains the parameter μ, and this factor can be written
as exp(nμx/σ2) exp(−nμ2/2σ2) times a function that does not depend on μ. We
conclude that for ﬁxed y and σ2, the family of conditional distributions of X given
X2 = y with parameter μ is a one-dimensional exponential family, with suﬃcient
quantity X and natural parameter Q(μ) = nμ/σ2.
By Theorem 6.44, the uniformly most powerful test rejects H0 for testing
H0: μ ≤0 against H1: μ > 0 in this exponential family for values of X greater
than a certain critical value cα0(y, σ2) that can depend on y and σ2 in the current
set-up. Since the function x →x/

y −x2 is monotonically increasing in x (on the
interval [−√y, √y]), this test is equivalent to rejecting for large values of √nX/SX =
√nX/(y −X2)1/2 if X2 = y. The critical value should be chosen such that the size
of the test is equal to α0. In the current situation, this means that H0 is rejected when
√nX/SX ≥dα0(y, σ2) for the critical value dα0(y, σ2) that is determined by the
equation
P0,σ2√nX/SX ≥dα0(y, σ2)| X2 = y

= α0.
Finally, we prove that dα0(y, σ2) = tn−1,1−α0.
Since under μ = 0, the quantity √nX/SX has a tn−1-distribution, it suﬃces to
prove that X/SX and X2 are independent. This is a consequence of Basu's theorem.
Theorem 6.51 Basu's theorem
If V
= V (X) is suﬃcient and complete and T = T (X) is a statistic whose
distribution does not depend on the parameter, then V and T are stochastically
independent.
243

6: Optimality Theory
Proof. For every event B, the probability P(T ∈B) = EθP(T ∈B| V ) is
independent of the parameter. By the suﬃciency of V , the conditional probability
P(T ∈B| V ) is also independent of the parameter. The completeness of V then
implies that P(T ∈B| V ) = P(T ∈B) with probability 1. It follows that T and
V are independent.
244

6.5: Summary
6.5 Summary
Let X be an observation with distribution Pθ and density pθ that depend on an
unknown parameter θ ∈Θ.
• A statistic V (X) is called suﬃcient for X if V (X) contains all pertinent
information from X about θ. A statistic V (X) is suﬃcient if there exist functions
gθ and h such that pθ factors as
pθ(x) = gθ(V (x))h(x)
for all θ, x.
• A statistic V = V (X) is called complete if Eθf(V ) = 0 for all θ ∈Θ can only
hold for functions f with Pθ

f(V ) = 0

= 1 for all θ ∈Θ.
Two optimality characteristics for estimators:
• An estimator T (X) is called a uniformly minimum-variance unbiased (UMVU)
estimator for g(θ) if it is unbiased and varθ T ≤varθ S for all θ and all other
unbiased estimators for g(θ). If a UMVU estimator exists, it is the best estimator
within the class of unbiased estimators. If an unbiased estimator T = T (V )
for g(θ) depends only on a suﬃcient and complete statistic V (X), then T is
automatically a UMVU estimator for g(θ).
• The Cram´er-Rao lower bound: Under certain conditions, every unbiased estimator
T = T (X) for g(θ) ∈R satisﬁes
varθ T ≥g′(θ)2/Iθ
with g′ the derivative of g and Iθ the Fisher information of the full observation
X. If the variance of an unbiased estimator T = T (X) for g(θ) is equal to
this lower bound, then T is automatically UMVU. Under certain conditions,
maximum likelihood estimators are asymptotically unbiased with variance equal
to the Cram´er-Rao lower bound, and therefore asymptotically UMVU.
We say that a test is uniformly most powerful for testing H0: θ ∈Θ0 against H1: θ ∈
Θ1 if in all θ ∈Θ1, the value of the power function is maximal among the values of
all power functions of all tests of the same level.
Optimal tests for simple and composite hypotheses:
• Neyman-Pearson lemma for H0: θ = θ0 against H1: θ = θ1: if there exists a
number cα0 with Pθ0

pθ1(X)/pθ0(X) ≥cα0

= α0, then the test with critical
region K = {x: pθ1(X)/pθ0(X) ≥cα0} is the most powerful test of level α0.
• For testing the hypothesis H0: θ ≤θ0 against H1: θ > θ0 based on an observation
from a family with monotone likelihood ratio, there exists a uniformly most
powerful randomized test based on a suﬃcient statistic V for the family.
245

6: Optimality Theory
Exercises
1. Let X1, . . . , Xn be a sample from the exponential distribution with unknown parameter λ > 0.
Determine a suﬃcient random variable.
2. Let X1, . . . , Xn be a sample from the Poisson distribution with unknown parameter θ > 0.
Determine a suﬃcient random variable.
3. Let X1, . . . , Xn be a sample from a distribution with probability density pθ(x) = θxθ−11(0,1)(x),
where θ > 0 is an unknown parameter. Determine a suﬃcient random variable.
4. Let X1, . . . , Xn be a sample from the uniform distribution on [θ1, θ2], where θ = (θ1, θ2) is an
unknown parameter. Show that (X(1), X(n)) is a suﬃcient random vector.
5. Let X1, . . . , Xn be a sample from the N(θ, θ2)-distribution, where θ > 0 is an unknown
parameter. Determine a suﬃcient two-dimensional random vector.
6. Let X1, . . . , Xn be a sample from a distribution with probability density pλ,μ(x)
=
λe−λ(x−μ)1{x>μ}, where λ > 0 and μ ∈R are unknown parameters. Determine a suﬃcient
random vector.
7. Show that if V is suﬃcient, then the maximum likelihood estimator (based on X) depends
only on V.
8. Show that if V is suﬃcient, then the Bayes estimator (based on X with respect to a given
prior distribution) depends only on V.
9. Show that if V is suﬃcient, then the likelihood ratio statistic (based on X) depends only on
V.
10. Let X = (X1, . . . , Xn) be a sample from a distribution with density pθ, with θ unknown. Let
U be a suﬃcient and complete statistic, and suppose that there exists a minimally suﬃcient
statistic T. Show that U is also minimally suﬃcient. [Hint: Give a proof by contradiction.
Suppose that U is not minimally suﬃcient; then there exists a function ψ such that Pθ(ψ(U) =
E[ψ(U)|T]) > 0.]
11. Do the geometric distributions with parameter p form an exponential family?
12. Determine whether the multinomial probability distributions with parameters n and p form
an exponential family for ﬁxed n.
13. Let X1, . . . , Xn be a sample from the exponential distribution with parameter λ. Determine a
UMVU estimator for 1/λ.
14. Determine a UMVU estimator for p2 based on a bin(n, p)-observation X (n ≥2, 0 ≤p ≤1).
15. Determine a UMVU estimator for μ2 based on a sample X1, . . . , Xn from the N(μ, σ2)-
distribution.
16. Let X1, . . . , Xn be a sample from the Poisson distribution with parameter θ. Determine a
UMVU estimator for θ2.
246

6: Exercises
17. Let X1, . . . , Xn be a sample from the probability distribution with density
pθ(x) = θx−21{x>θ},
where θ > 0 is an unknown parameter.
(i) Determine a suﬃcient and complete statistic.
(ii) Determine a UMVU estimator for θ.
18. Let X1, . . . , Xn be a sample from the uniform distribution on [0, θ]. Determine a UMVU
estimator for θ2.
19. Let X1, . . . , Xn be a sample from the shifted exponential distribution with probability density
pμ,λ(x) = 1
λ exp

−x −μ
λ

1{x≥μ},
with λ > 0 and μ ∈(−∞, ∞) unknown. The function x →1{x≥μ} is equal to 1 for x ≥μ and 0
for x < μ.
(i) Determine a suﬃcient two-dimensional statistic for (μ, λ).
(ii) Determine a UMVU estimator for λ under the assumption μ = 1.
20. Let X1, . . . , Xn be a sample from the beta distribution with density
pα,β(x) = B(α,β)−1xα−1(1 −x)β−11{0<x<1}.
(i) Do the probability distributions of X = (X1, . . . , Xn) form an exponential family?
(ii) Determine a suﬃcient and complete statistic.
(iii) Determine a UMVU estimator for Eα,β log X1.
21. Let X1, . . . , Xm and Y1, . . . , Yn be independent samples from the Bernoulli distributions with
parameters p1 and p2, respectively, where p1 and p2 are unknown parameters in [0, 1].
Determine a UMVU estimator for p1 −p2.
22. Let X1, . . . , Xn be a sample from the N(μ, σ2)-distribution, with σ2 known and μ ∈R
unknown.
(i) Show that X is suﬃcient and complete.
(ii) Show that (X, S 2
X) is not complete.
23. Let X1, . . . , Xn be a sample from the U[−θ, θ]-distribution.
(i) Show that (X(1), X(n)) is suﬃcient.
(ii) Show that (X(1), X(n)) is not complete.
(iii) Determine whether (X(1), X(n)) is minimally suﬃcient.
24. Let X1, . . . , Xn be a sample from the probability distribution with Pθ(Xi = x) = 2−x/θ for
x = θ, θ + 1, θ + 2, . . . , where θ > 0 is an unknown parameter.
(i) Determine a suﬃcient statistic.
(ii) Determine whether the probability distributions of (X1, . . . , Xn) form an exponential
family.
247

6: Optimality Theory
25. Let X1, . . . , Xm be a sample from the N(μ, σ2)-distribution, and let Y1, . . . , Yn be a sample
from the N(μ, τ2)-distribution, where μ, σ2, and τ2 are unknown. Suppose that the two
samples are independent.
(i) Show that for every α ∈R, the estimator αX + (1 −α)Y is an unbiased estimator for μ.
(ii) The vector (X, Y, S 2
X, S 2
Y) is suﬃcient and 1
2 X+ 1
2Y is an unbiased estimator for μ. Does
it follow from Theorems 6.18 and 6.21 that this estimator is UMVU?
(iii) Determine the α minimizing the variance of the given estimator.
(iv) Is the situation diﬀerent if we assume beforehand that σ2 and τ2 are equal?
26. Determine the Cram´er-Rao lower bound for the variance of unbiased estimators of θ based
on a sample from the Poisson(θ)-distribution. Is the bound sharp?
27. Let Y1, . . . , Yn be independent and suppose that Yi has an N(xiθ, 1)-distribution, for known
constants x1, . . . , xn.
(i) Determine the Fisher information for θ in Yi.
(ii) Determine the Fisher information for θ in (Y1, . . . , Yn).
(iii) Determine the Cram´er-Rao lower bound for estimating θ.
(iv) Is this lower bound sharp?
28. Let X1, . . . , Xn be a sample from the N(θ, θ)-distribution, with θ > 0 unknown. Determine
the Cram´er-Rao lower bound for estimating g(θ) =
√
θ.
29. Let X1, . . . , Xn be a sample from the exponential distribution with unknown parameter λ > 0.
(i) Determine the Cram´er-Rao lower bound for estimating g(λ) = 1/λ.
(ii) Show that, in this case, the lower bound is sharp.
30. Let X1, . . . , Xn be a sample from the gamma distribution with parameters k and λ, where k is
known and λ > 0 is unknown.
(i) Determine the Cram´er-Rao lower bound for estimating g(λ) = 1/λ.
(ii) Show that, in this case, the lower bound is sharp.
31. Let X1, . . . , Xn be a sample from a probability density that belongs to an exponential family.
Show that probability distributions of X = (X1, . . . , Xn) also belong to an exponential family.
32. Let X1, . . . , Xn be a sample from a probability distribution with density
pθ(x) = θ exp
x −θ(ex −1)
,
for x > 0 and 0 elsewhere, with θ an unknown parameter.
(i) Determine a most powerful test for H0: θ = 1 against H1: θ = 2 at level α0 = 0.05.
(ii) Determine a most powerful test for H0: θ = 1 against H1: θ = 3 at level α0 = 0.05
33. Let X1, . . . , Xn be a sample from a probability distribution with density
pθ(x) = 2θ2x−31x>θ,
where θ > 0 is an unknown parameter.
(i) Determine a most powerful test for H0: θ = 1 against H1: θ = 1/2 at level α0 = 0.05.
(ii) Determine a most powerful test for H0: θ = 1 against H1: θ = 2 at level α0 = 0.05.
34. Let X1, . . . , Xn be a sample from a discrete probability distribution with probability density
pθ(x) = 1/θ when x ∈{1, 2, . . . , θ}, where θ ∈N.
(i) Determine a most powerful test for H0: θ = 2 against H1: θ = 3 at level α0 = 0.05.
(ii) Determine a uniformly most powerful test for H0: θ = 2 against H1: θ > 2 at level
α0 = 0.05.
248

6: Exercises
35. Let X1, . . . , Xm be N(μ, 1)-distributed, and let Y1, . . . , Yn be N(ν, 1)-distributed. Suppose that
the random variables are all independent. Let μ1 > ν1, and let ξ0 = mμ1/(m+n)+nν1/(m+n).
(i) Determine a most powerful test for the null hypothesis H0: μ = ν = ξ0 against H1: μ =
μ1, ν = ν1 at level α0.
(ii) Determine a uniformly most powerful test for the null hypothesis H0: μ ≤ν against
H1: μ > ν at level α0.
36. Let X be hypergeometrically distributed with parameters m, r, and N. We want to test H0: r ≤
r0 against H1: r > r0. Set pr(x) = P(X = x).
(i) Show that for r1 > r0, the quotient pr1/pr0 is an increasing function of x.
(ii) Determine a uniformly most powerful test for testing H0 against H1.
37. Let X1, . . . , Xn be the incomes of n randomly chosen persons from a certain population.
Suppose that Xi has a Pareto distribution, that is, Xi has probability density
pθ(x) = cθθx−(1+θ)1{x>c},
where θ > 1 and c > 0. We assume that c is known and θ is unknown.
(i) Express the expectation μ of Xi in θ (and c).
(ii) Determine a uniformly most powerful test for H0: μ ≤μ0 against H1: μ > μ0 at level α0.
249

HIGH WATER IN LIMBURG
Figure 6.1 shows the water ﬂow (m3/s) in the river the Meuse near the town of
Borgharen (Netherlands, in the province of Limburg) during 15 consecutive days
in December 1965. In the 20th century, the water ﬂow exceeded 1250 m3/s a total
of 70 times, and each time, the pattern of the water ﬂow over time was known (see
Figure 6.1). The form of the extreme peaks is important for the consequences of the
high water ﬂow. Prolonged high water ﬂow means, for example, an extended exposure
of the dikes to high water, resulting in saturation and a higher probability of a breach
or ﬂooding. We will, however, restrict ourselves to analyzing the maxima of the waves.
The maximum of the wave in Figure 6.1 is 1892 m (recall that 1 m ≈3.28 feet).
2
4
6
8
10
12
14
1000
1200
1400
1600
1800
Figure 6.1. Water ﬂow (in m3/s) in Borgharen on 15 consecutive days in December 1965.
The 70 observed maxima are shown in chronological order in Figure 1.4, and
Figure 6.2 gives a histogram of the maximal water ﬂow.♯The histogram shows several
extremely high values. As follows from Example 1.6, we are greatly interested in the
probability of more extreme maxima occurring.
To have a framework for the analysis, we will take the working hypothesis that
the 70 observed maximal water ﬂows can be viewed as realizations of independent,
identically distributed random variables. This working hypothesis is, of course,
debatable. However, since the high water ﬂows occur at separate times, often in
diﬀerent years, the independence of the maxima is not unreasonable. A certain trend
over time with, for example, a slowly changing distribution for the maxima, can,
however, not be excluded. Think of a climate eﬀect, but more importantly of the eﬀect
of the increasing canalization and construction along the Meuse that have inﬂuenced
the course of the river. We can study a time eﬀect in the data up to a certain point. We
will return to this later.
♯The data can be found on the book's webpage at http://www.aup.nl under maxflows and
flows1965.
250

6: High Water in Limburg
Histogram of water flows
1500
2000
2500
3000
0
5
10
15
20
25
Figure 6.2. Maximal water ﬂow over 1250 m3/s in Borgharen in the twentieth century.
To determine a suitable probability distribution for the maximal water ﬂow,
we can use a theoretical result from probability theory as a starting point. This
somewhat surprising theorem gives an approximation for the distribution of a
maximum max(Y1, . . . , Ym) of a large number of independent, identically distributed
random variables Yi. Since each of the 70 maximal water ﬂows is the maximum of a
pattern of high water ﬂows as in Figure 6.1, it is not entirely unreasonable to view the
maximal water ﬂows as maxima of less extreme water ﬂows.
Theorem 6.52
Suppose that for certain numbers am and bm and independent, identically distributed
random variables Y1, Y2, . . . , we have that for some distribution function G,
lim
m→∞P

am

max(Y1, . . . , Ym) −bm

≤x

= G(x),
x ∈R.
Then G belongs to the location-scale family of one of the following three types of
distributions:
(i) Gumbel: G(x) = e−e−x
(ii) Fr´echet: G(x) = e−(1/xα)1{x>0}, for α > 0
(iii) Negative Weibull: G(x) = e−(−x)α1{x<0} + 1{x≥0}, for α > 0
This theorem gives a mathematical limit result and is certainly not conclusive
evidence that the maximal water ﬂows must be generated from one of the given
distributions. We can, however, use the theorem as motivation to study the ﬁt of the
three types of distributions for the ﬂows.
The three families of extreme value distributions can formally be viewed as one
family with a parameter ξ ∈R. The distribution function of this family is
Gμ,σ,ξ(x) = e−(1+ξ(x−μ)/σ)−1/ξ11+ξ(x−μ)/σ>0.
251

6: Optimality Theory
The limit as ξ →0 corresponds to the Gumbel distribution, ξ > 0 corresponds to the
Fr´echet-distributions, and ξ < 0 corresponds to the negative Weibull distributions.
The parameter α in the latter two cases corresponds to 1/ξ.
In addition to the unknown location and scale parameters, the parameter α for
the second and third families is also unknown. To study the ﬁt of one of these families
using a QQ-plot, we would therefore need to make a QQ-plot for every value of α.
Figure 6.3 shows several of these QQ-plots. It is clear from these ﬁgures that the
negative Weibull distributions (type (iii)) do not ﬁt well. A Gumbel distribution (type
(i)) or a Fr´echet-distribution with large values of α (in the range from 4 tot 10) does
seem to ﬁt the data reasonably well. The lower row of Figure 6.3 gives the QQ-
plots against standard (nonextreme values) distributions. We can conclude that an
exponential or other gamma distribution with a small shape parameter need not be
excluded beforehand. Here, we choose a Fr´echet-distribution.
−3
−2
−1
0
1
1500
2000
2500
3000
neg weibull 1
−1
0
1
2
1500
2000
2500
3000
neg weibull 4
−1
0
1
2
3
4
1500
2000
2500
3000
gumbel
−1
0
1
2
3
4
5
1500
2000
2500
3000
frechet 10
0
2
4
6
1500
2000
2500
3000
frechet 4
0
5
10
15
1500
2000
2500
3000
frechet 2
−2
−1
0
1
2
1500
2000
2500
3000
normal
2
4
6
8
1500
2000
2500
3000
gamma 3
0
1
2
3
4
1500
2000
2500
3000
exponential
Figure 6.3. QQ-plots of the maximal water ﬂows against a selection of distributions.
A next step in the analysis is to estimate the unknown parameters. The Fr´echet
family has three unknown parameters, namely the shape parameter α, location, and
scale. We can estimate these three parameters using the maximum likelihood method,
under the assumption that the maxima are independent. The likelihood function for
the Fr´echet family with location parameter μ and scale parameter σ is
(μ, σ, α) →
n

i=1
σαα
(Xi −μ)α+1 e−((Xi−μ)/σ)−α1{X(1)>μ}.
252

6: High Water in Limburg
Determining the point of maximum of this function requires a numerical optimiza-
tion method, such as the Newton-Raphson (or Fisher-scoring) method. The results
are given in Table 6.1.
Estimates
loc
scale
shape
1530.4691
214.7064
0.2539
Standard Errors
loc
scale
shape
29.4027
24.2129
0.1067
Covariance
[,1]
[,2]
[,3]
loc
864.5207545 436.881289 -0.99632985
scale 436.8812890 586.265220 -0.17045895
shape
-0.9963299
-0.170459
0.01139458
Table 6.1. R-output containing the parameter estimates for ﬁtting an extreme value distribution
to the maximal water ﬂows. The parameters loc, scale, and shape are, respectively, equal to μ,
σ, and 1/α. In addition to the estimated parameter values, under Estimates, we also give the
standard errors for the estimates, under Standard Errors, and the estimated covariance matrix
of the estimators, under Covariance.
We interpret the standard error 0.11 for the estimate ˆξ = 0.25 as deﬁning an
approximate conﬁdence interval ξ = 0.25 ± 2 ∗0.11. The Gumbel distribution with
ξ = 0 and the negative Weibull distributions with ξ < 0 do not seem to qualify.
Given the estimate ˆξ = 1/ˆα = 0.25, we can verify our interpretation of the QQ-
plots in Figure 6.3. Figure 6.4 gives QQ-plots of several samples of size 70 from the
Fr´echet-distribution with shape parameter ξ = 0.25 together with the QQ-plot of the
data. This last QQ-plot is the same as "frechet 4" in Figure 6.3. Since the form of the
QQ-plot of the data does not deviate from that of the other QQ-plots, the assumption
that we have a Fr´echet-distribution is certainly compatible with the QQ-plots. We
could further support the assumption of a Fr´echet-distribution using a goodness-of-ﬁt
test.
Suppose that we are interested in the threshold h such that the probability of a
maximal water ﬂow X greater than or equal to h is equal to p. If X has a Fr´echet-
distribution, then this leads to the equation 1 −exp

−((h −μ)/σ)−α
= p, that
is,
h = μ +
σ
(−log(1 −p))ξ .
The maximum likelihood estimator for h is obtained by replacing the unknown μ, σ,
and ξ by their maximum likelihood estimators. For p = 0.0001, for example, this
gives ˆh = 3757, a value that (naturally) lies far above the measured maxima. The
253

6: Optimality Theory
0
2
4
6
0
2
4
6
0
2
4
6
−1
0
1
2
3
4
5
6
0
2
4
6
0
2
4
6
8
10
0
2
4
6
0
2
4
6
0
2
4
6
0
2
4
6
8
10
0
2
4
6
1500
2000
2500
3000
frechet 4
Figure 6.4. QQ-plots of 5 samples from the Fr´echet-distribution with shape parameter ξ = 0.25
and the maximal water ﬂows (lower right) against the quantiles of the Fr´echet-distribution with
shape parameter ξ = 0.25.
assumption that the distribution is Fr´echet plays an essential role in the extrapolation
of the data to much more extreme values. The standard error of the estimator for h
can be approximated using the numbers in Table 6.1, using the delta method. (An
alternative is to compute the proﬁle likelihood for h.) The diﬀerence ˆh −h is then
approximated linearly as a function of the diﬀerences ˆμ −μ, ˆσ −σ, and ˆξ −ξ, that is,
ˆh −h ≈ˆμ −μ +
1
(−log(1 −p))ξ (ˆσ −σ) −σ log(−log(1 −p))
(−log(1 −p))ξ
(ˆξ −ξ).
The constants by which we multiply the three diﬀerences are the partial derivatives
of h viewed as a function h = h(μ, σ, ξ) of the three parameters. We now compute
an approximation for the standard error of ˆh by expressing the variance of the left-
hand side in the covariances of the diﬀerences on the right-hand side, which are
(approximately) given in the output $varcov of Table 6.1. We replace the remaining
unknown values of ξ and σ in the multiplicative constants by their estimates ˆξ and
ˆσ. This gives the standard error 2180, and therefore a conﬁdence interval of the form
h = 3757 ± 1.96 ∗2180 for h. The interval is extremely long, which indicates that it
is very diﬃcult to extrapolate reliably that far into the future.
The interpretation of this interval is that if the assumption that we have a Fr´echet-
distribution is correct and we were to repeat the entire experiment of measuring water
ﬂows under the same circumstances 100 times and compute the conﬁdence interval
the way described above every time, then approximately 95 out of the 100 intervals
would contain the desired threshold h. In this case, "repeating" is purely a thought
experiment. The restriction that "the assumption of a Fr´echet-distribution is correct"
is important, because the conﬁdence region does not give any control over a possible
systematic error in our analysis.
There are, unfortunately, arguments in favor of such a systematic error. By the
"correctness" of the Fr´echet-distribution, we mean that the maximal water ﬂows can
254

6: High Water in Limburg
be viewed as a sample from an extreme value distribution. Based on our earlier
analysis, the extreme value assumption is not unreasonable, provided that we can
indeed view the data as a (random) sample from a distribution. In particular, there
should not exist any time dependence in the data, a dependence that is certainly
conceivable for this type of data.
We are thinking, in particular, of a trend over time. Stochastic dependence
between consecutive years seems less probable. On the one hand, the 70 maxima
are relatively uniformly distributed over the century. On the other hand, the plot
of the sample autocorrelation function also does not suggest any dependence (see
Figure 6.5).
0
5
10
15
−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
maxima
Figure 6.5. Sample autocorrelation of the maximal water ﬂow.
1920
1940
1960
1980
2000
1500
2000
2500
3000
Figure 6.6. Maximal water ﬂow plotted as a function of time, together with the best-ﬁtting linear
function and a moving average (averaged over periods of 10 years).
255

6: Optimality Theory
A trend in the data is suggested in Figure 6.6, where the maximal ﬂows are plotted
over time, with both the best-ﬁtting (least squares) linear function and the moving
average (averaged over periods of 10 years). For each year, the moving average gives
the average over the previous 10 years. The maxima seem to have increased somewhat
in the course of the century. We can study this hypothesis using, for example, a trend
test, whose test statistic is equal to the number of indices i such that the maximum at
time i is greater than the maximum at time i −1. In case of a strictly increasing trend,
this number would be equal to 69, while for a random sample, the number would be
equal to the number of increases in a random permutation of the indices 1, . . . , 70.
The observed number of increases 31 does not conﬁrm the impression that there is a
trend. This number is even very small (a right p-value of approximately 95%).
Another possible test, with a greater power function, is a two-sample test with the
ﬁrst half of the maxima as ﬁrst sample and the second half as second sample. Since the
maxima are clearly not normally distributed, we use the Wilcoxon test. The two-sided
test gives a p-value of 4%, which conﬁrms the belief that the maxima may change
over time. The diﬀerence between the medians of the two samples is 158. Boxplots of
the two half samples conﬁrm the image of the shift (Figure 6.7), although there is a
considerable overlap between the two samples.
1
2
1500
2000
2500
3000
Figure 6.7. Boxplots of the ﬁrst and last 35 maximal water ﬂows.
If we must take into account a change over time, then it is also possible that the
form of the distribution has changed over time. An empirical QQ-plot, where the order
statistics of the ﬁrst half of the observations are set out against the order statistics of
the second half, gives an indication for a possible diﬀerence in distribution between
the two halves. At ﬁrst glance, Figure 6.8 does seem to show a diﬀerence. However,
this ﬁgure is misleading, as shown by the simulated data (Figure 6.9). The QQ-plot in
Figure 6.8 does not deviate essentially from the QQ-plots in Figure 6.9, for which the
two samples (of size 35) are both simulated from the same Fr´echet-distribution.
We can also apply the idea that the ﬁrst and second halves of the maxima
could diﬀer in distribution within the context of the Fr´echet model, by estimating
256

6: High Water in Limburg
1500
2000
2500
3000
1500
2000
2500
3000
Figure 6.8. Empirical QQ-plot of the ﬁrst 35 maximum water ﬂows against the last 35 water
ﬂows.
1.0
1.5
2.0
2.5
1.0
1.5
2.0
2.5
3.0
1.0
1.5
2.0
1
2
3
4
5
6
1.0
1.5
2.0
2.5
1.0
1.5
2.0
0.8
1.0
1.2
1.4
1.6
1.8
2.0
2.2
2
4
6
8
1.0
1.5
2.0
2.5
3.0
1.0
1.5
2.0
2.5
3.0
1.0
1.5
2.0
2.5
1
2
3
4
5
6
Figure 6.9. Empirical QQ-plots of 6 independently generated pairs of independent samples of size
35 from the Fr´echet-distribution with parameter 0.25.
the parameters of this model separately for the two halves. The results are given
in Tables 6.2 and 6.3. The estimates are quite diﬀerent, but not all diﬀerences are
statistically signiﬁcant. It is important to note that the estimates are based on only
35 observations, and therefore have relatively large margins of error. The conﬁdence
intervals for μ, for example, are μ1 = 1472 ± 1.96 ∗26 and μ2 = 1607 ± 1.96 ∗57
and overlap.
To see how possible diﬀerences inﬂuence the estimate of the threshold h, we can
estimate this threshold separately based on the ﬁrst and second half of the data, using
the same method as that applied to the full data. This gives two conﬁdence intervals,
257

6: Optimality Theory
14 686±1.96∗26 539 and 2505±1.96∗1232. The interval based on the ﬁrst half of the
data has a width of approximately 100 000 and is therefore extremely inaccurate. So
we should not put too much weight on the diﬀerences between the two point estimates
for h themselves and with the estimate based on the full data.
Estimates
loc
scale
shape
1472.4676
125.5073
0.5056
Standard Errors
loc
scale
shape
26.1394
24.7969
0.2195
Table 6.2. R-output containing the parameter estimates and standard errors for ﬁtting an extreme
value distribution to the ﬁrst 35 maximal ﬂows.
Estimates
loc
scale
shape
1606.7206
292.2234
0.1219
Standard Errors
loc
scale
shape
57.2150
44.5610
0.1542
Table 6.3. R-output containing the parameter estimates and standard errors for ﬁtting an extreme
value distribution to the last 35 maximal ﬂows.
258

7 Regression Models
7.1 Introduction
In contemporary usage, the word regression has a negative connotation, even though
in statistics it is the standard name for explaining a variable Y using a variable
X. A dependent variable Y is "regressed on" a predictor variable X, also called
independent variable in this context. Here are some of the many applications:
- predicting the yield of a biochemical process as a function of temperature,
amount of catalyst, etc.
- predicting the price of property as a function of size, location, available
infrastructure, etc.
- predicting the remaining life span as a function of age, gender, risk of a medical
procedure, health indicators, etc.
- predicting the response to a mailing as a function of postal code, education,
income, etc.
- predicting the national product from macro-economic variables such as the labor
force, interest rates, national deﬁcit, inﬂation, etc.
- predicting the length of university studies toward a master's degree as a function
of the average grade in the last year of high school, choice of major, etc.
- predicting the ﬁnal adult height of a child based on the heights of the parents and
the gender of the child
- predicting the value of shares over 10 days based on the value today, yesterday,
etc.
259

7: Regression Models
Since the independent variable X can inﬂuence the dependent variable Y in many
ways and the probability distribution of Y will not be the same for every application,
there exist diﬀerent types of regression models; Sections 7.2, 7.3, and 7.4 treat the most
common regression models, where the variable Y is a real-valued random variable.
Sections 7.5 and 7.6, on the other hand, describe speciﬁc models for application in
classiﬁcation (Y is a 0-1 variable) and life span (Y is a life span).
All applications mentioned above have in common that there does not exist a
perfect correlation between the variables X and Y , although we do expect there to be
a correlation. For example, we expect that the size and age of a property, its location,
and possibly other factors, will inﬂuence the price of the property, but, in general, it
will not be possible to predict the price exactly from a number of such indicators. This
could be due to a lack of information (some relevant variables are still unknown) or
to random factors. In both cases, it is not unreasonable to view (x, y) as a realization
of a random vector (X, Y ). We can then study the correlation between x and y using
a probability distribution of the vector (X, Y ). We will be interested mostly in the
conditional distribution of Y given X = x, and to a lesser degree in the marginal
distribution of X.
In some cases, we can control the value of the predictor variable X. For example,
in determining the optimal production conditions, the diﬀerent settings x are varied
systematically, after which the yield y is analyzed. In such a case, it is not reasonable
to view the predictor variable as a realization of a random variable; instead, we view
only the dependent variable Y as a random variable. When X is random, on the other
hand, we often model the conditional distribution of Y given X = x. Therefore, it
does not make much practical diﬀerence for the diﬀerent regression models whether
we assume X to be random or not. In the next sections, we will indicate each time
whether X is assumed to be random. We view the available data (x1, y1), . . . , (xn, yn)
as either realizations of the random vector (X, Y ) or as realizations of the random
variable Y in combination with the measured nonrandom observation (x1, . . . , xn).
In the application at the end of this chapter, we will discuss in detail the concept
of causality. Because causality is an important subject in the context of regression,
let us already discuss two short examples to illustrate this concept. The ﬁrst example
deals with the myth that babies are delivered by storks. In some regions, a positive
correlation has been observed in the ﬂuctuations of the stork population and the birth
rate; in periods when the stork population shrank, the birth rate dropped, and at times
when the stork population grew, the birth rate also rose. This is a remarkable result
since we are convinced, and have been for some time already, that babies are not
delivered by storks. Despite the correlation, it cannot be expected that if in these
regions, the size of the stork population is increased artiﬁcially, for example by setting
out additional storks, the birth rate will rise. The second example concerns the positive
correlation between income and spending: people who earn more in general also spend
more. In this case, it is often true that if a person earns more, their spending also
increases. What is the diﬀerence between the two examples? In both cases, we can
say that the predictor variable (number of storks and income) has a predicting value
for the dependent variable (birth rate and spending). However, in the stork example,
260

7.2: Linear Regression
we cannot say that there is a causal correlation, while in the income example there
is one: artiﬁcially increasing the number of storks will not aﬀect the birth rate, while
such an eﬀect is likely to be true in the income example. It is not entirely clear why the
birth rate and size of the stork population have a positive correlation in some regions.
Possibly both depend on the industrial development: more industry means, on the one
hand, more wealth, which traditionally causes the birth rate to drop, and, on the other
hand, air pollution and unrest in the region, causing storks to leave.
7.2 Linear Regression
The linear model, the basis for linear regression and analysis of variance, is the
workhorse of "classical" statistics, on the one hand, because it is widely applicable
(with a bit of sense) and, on the other hand, because the necessary computations are
based on simple matrix algebra. Although modern numerical methods have facilitated
the application of more ﬂexible models, the linear model is still of great value.
The theory for the linear model is based on the multivariate normal distribution,
discussed in Appendix B. In this section, we discuss linear regression models, and in
the next, we deal with analysis of variance. The latter is, in fact, a special case of linear
regression.
The standard linear regression model assumes that, given X = x = (x1, . . . , xp),
the variable Y is normally distributed, with conditional expectation and variance
E(Y |X = x) =
p

i=1
βixi,
var(Y |X = x) = σ2,
where the latter is independent of x. When X is not random, Y has this expectation
and variance (unconditionally) for predictor variables (x1, . . . , xp). In the remainder
of this section, we assume that the predictor variable X is not random, so that we can
leave out the conditionality. The model has p + 1 real-valued parameters, which we
can combine into the parameter vector θ = (β1, . . . , βp, σ2).
In the linear regression model, in addition to the observation Y , we also have
the predictor variable x, which we use to model the expected value of the dependent
variable Y . If we deﬁne the "measurement error" as e = Y −p
i=1βixi, then we can
write
Y =
p

i=1
βixi + e.
In the standard regression model, the measurement errors are independent and
normally distributed with expectation 0 and variance σ2. The variable Y then also
has a normal distribution, but now with expectation p
i=1βixi and variance σ2. We
can view the linear regression model as an extension of the measurement error model
of Example 1.3.
261

7: Regression Models
The linear regression model makes a number of speciﬁc assumptions:
- The expectation of Y depends on x, but the variance does not.
- The expectation of Y is a linear function of x.
- The measurement error is normally distributed.
In a surprisingly large number of applications, these conditions hold, but this is, of
course, not always the case. We should note that the variables are often "preprocessed"
into a form that is in line with the linear regression model. For example, the regression
can be carried out after transforming the dependent variable Y (for example by taking
the logarithm log Y ), and the predictor variables, in particular, can be transformed
in many ways. When, for example, in the case of a one-dimensional variable x,
we expect a polynomial relation between x and Y , we can carry out the regression
with predictor variable (1, x, x2, . . . , xk) instead of x. When in the case of a two-
dimensional variable x = (x1, x2), we expect a quadratic joint correlation relation
between the variables (x1, x2) and Y , we can use the vector (1, x1, x2, x2
1, x2
2, x1x2)
in the model, etc. We see that the linearity of the linear regression model relates to the
linearity in the regression parameters, and not so much in the predictor variables.
In many cases an intercept is added to the model. In practice, this corresponds to
setting the ﬁrst predictor variable x1 equal to 1 and including the measured predictor
variables in x2, . . . , xp. A linear regression model with intercept has the following
form:
Y = β1 + β2x2 + . . . + βpxp + e.
The regression parameter β1 is called the intercept; it is the expectation of Y when the
regression parameters β2, . . . , βp are equal to 0.
It may be worth softening the assumptions of the regression model. Instead of
the normality of the measurement errors, we could assume only that the measurement
errors have expectation 0, and we could also model the variance of the measurement
errors as a function of x. We will not discuss these models.
7.2.1 Simple Linear Regression
Suppose that the variable Y depends on a one-dimensional real-valued predictor
variable x and that we have obtained n observations (x1, y1), . . . , (xn, yn). A scatter
plot of the observations (x1, y1), . . . , (xn, yn) can provide insight into the correlation
between x and Y . If this correlation seems to be linear, we can model the observations
using a so-called simple linear regression model. The simple linear regression model
with intercept is then described by
(7.1)
Yi = α + βxi + ei,
i = 1, . . . , n,
where the "measurement errors" e1, . . . , en are independent, N(0, σ2)-distributed,
unobservable random variables. Under this assumption, the variables Y1, . . . , Yn are
also independent and normally distributed, where the variable Yi has expectation
α + βxi and variance σ2. We see that the observations are not identically distributed.
If there were no measurement errors, then there would be an exact linear correlation
between Y and x. We take the parameter space for the parameter θ = (α, β, σ2) as
large as possible: (α, β) ∈R2 and σ2 > 0.
262

7.2: Linear Regression
7.2.1.1
Estimation
By estimating the parameters α and β, we can determine the (linear) correlation
between Y and x.
Theorem 7.1
The maximum likelihood estimators for α, β, and σ2 in the simple linear regression
model (7.1) are equal to
ˆα = Y −ˆβx,
ˆβ = sY
sx
rx,Y ,
ˆσ2 = 1
n
n

i=1
(Yi −ˆα −ˆβxi)2,
where sx, sY , and rx,Y are the sample standard deviation and the sample correlation
(see Deﬁnitions 2.2 and 2.15).
Proof. The log-likelihood function for the model in (7.1) is
(α, β, σ2) →log
n

i=1
1
√
2πσ2 e−1
2 (Yi−α−βxi)2/σ2
= −1
2n log 2π −1
2n log σ2 −
1
2σ2
n

i=1
(Yi −α −βxi)2.
As in Example 3.14, maximizing the log-likelihood function is done in two steps.
Maximizing this function with respect to (α, β) is equivalent to minimizing the
quadratic form n
i=1(Yi −α −βxi)2 with respect to (α, β). Setting the partial
derivatives of the sum with respect to α and β equal to 0 gives the system of equations
(7.2)
n

i=1
(Yi −ˆα −ˆβxi) = 0,
n

i=1
(Yi −ˆα −ˆβxi)xi = 0.
After some computation, the estimator for α and β can be solved from this system:
ˆα = Y −ˆβx,
ˆβ =
n
i=1xi(Yi −Y )
n
i=1xi(xi −x) =
n
i=1(xi −x)(Yi −Y )
n
i=1(xi −x)2
= sY
sx
rx,Y .
We can verify that this solution minimizes the quadratic form for every value of σ2 >
0 by, for example, computing the Hessian matrix in (ˆα, ˆβ). Substituting the resulting
values of ˆα and ˆβ in the log-likelihood function and maximizing this function with
respect to σ2 gives
ˆσ2 = 1
n
n

i=1
(Yi −ˆα −ˆβxi)2
as maximum likelihood estimator for σ2.
263

7: Regression Models
The estimators we found for α and β are so-called least-squares estimators,
because we minimize the sum of squares n
i=1(Yi −α −βxi)2. Geometrically, this
corresponds to minimizing the sum of the squares of the vertical distances from the
measurements (xi, Yi) to the target regression line y = α+βx, see Figure 7.1, whence
the name. The least-squares estimators ˆα and ˆβ are unbiased estimators for α and
β (this also holds when we do not assume the measurement errors to be normally
distributed). Moreover, there exist simple expressions for the mean square errors (see
Exercise 7.4 and Section 7.2.2).
The least-squares estimators ˆα and ˆβ are found by minimizing n
i=1(Yi −α −
βxi)2, and therefore satisfy the likelihood equations in (7.2). More generally, we can
ﬁnd estimators for α and β by solving the equations
n

i=1
ψ(Yi −ˆα −ˆβxi)w(xi) = 0,
n

i=1
ψ(Yi −ˆα −ˆβxi)xiw(xi) = 0
for (ˆα, ˆβ), for suitable functions ψ and w. In general, this leads to diﬀerent estimators.
The role of the function ψ and the weights w is often to reduce the inﬂuence of possible
extreme values of the residues Yi −ˆα −ˆβxi or the variables xi, or to increase the
eﬃciency of the estimators. This is called robust regression.
0
2
4
6
8
10
0
5
10
15
Figure 7.1. A collection of measurements (xi, yi) with the least-squares line.
The maximum likelihood estimator for σ2 can be written as
ˆσ2 = 1
n
n

i=1
(Yi −ˆα −ˆβxi)2 = 1
n
n

i=1
(Yi −Y )2 −1
n
ˆβ2
n

i=1
(xi −x)2.
If we knew beforehand that β = 0, then Yi would not depend on xi, and the maximum
likelihood estimator for σ2 would be given by the ﬁrst term on the right-hand side.
In the current model, we do not know whether β is equal to 0, and the maximum
likelihood estimator for σ2 is smaller (unless ˆβ = 0). Intuitively, this is reasonable:
part of the variation in Y now follows from the variation in x, and therefore the sample
variance of the Yi is an overestimate of σ2.
264

7.2: Linear Regression
Deﬁnition 7.2 Residuals and sums of squares
The numbers Yi −ˆα −ˆβxi for i = 1, . . . , n are called the residuals of the regression
of Y on x. The expressions
SStot =
n

i=1
(Yi −Y )2
and
SSres =
n

i=1
(Yi −ˆα −ˆβxi)2
are called, respectively, the total sum of squares and the residual sum of squares or,
more completely, the "residual sum of squares after linear regression on x."
Deﬁnition 7.3 Coeﬃcient of determination
The coeﬃcient of determination is
1 −SSres
SStot
.
The total sum of squares SStot is the minimum of n
i=1(Yi −α)2 over α, while
the residual sum of squares SSres is the minimum of n
i=1(Yi −α −βxi)2 over
(α, β). The second minimum is, of course, smaller. If SSres is approximately as
large as SStot, then SStot −SSres = ˆβ2n
i=1(xi −x)2 is close to 0 (that is, ˆβ
is approximately equal to 0 for the normalized xi) and xi has little predictive value for
Yi. The coeﬃcient of determination gives the proportion of the variance explained by
regression on x (called the explained variance) and can be written as
1 −SSres
SStot
= ˆβ2
n
i=1(xi −x)2
n
i=1(Yi −Y )2 = r2
x,Y .
When the coeﬃcient of determination is almost equal to 1, this means that the points
(xi, yi) lie approximately on a straight line. When the coeﬃcient of determination
is, for example, 0.2, either the points are widely distributed around a straight line or
the linear regression model is not useful because the correlation between x and Y is
strongly nonlinear. It is therefore not easy to interpret a coeﬃcient of determination.
Note that the scale of the coeﬃcient is quadratic, which is diﬃcult to justify. The
coeﬃcient of determination can, however, be viewed as a useful summary of the data
and is a standard part of the report on a regression analysis.
The ﬁtted regression line is y = ˆα + ˆβx. This line can be used to predict the
y-value for a certain x. After substituting the formulas for ˆα and ˆβ, we can rewrite the
line in the pleasant form
y −Y
SY
= rx,Y
x −x
sx
.
265

7: Regression Models
Since |rx,Y | ≤1 by the Cauchy-Schwarz inequality, with strict inequality unless the
measurement errors are exactly 0, this means that, measured in standard deviations,
the predicted y is closer to Y than the corresponding x is to x. We call this regression
to the mean, in particular in the case where the standard deviations of the two variables
are approximately equal. If x is the intelligence of a father and y is the intelligence
of a son, then this was once used to deduce that humanity is becoming increasingly
mediocre.
An explanation for "regression to the mean" is as follows. We can view an x-
value of a randomly selected individual from the population (such as the intelligence
of the father) as made up of a random and a systematic component. If the x-value
is extremely high, then it is reasonable to assume that the random component has
contributed to this relative size. When predicting the derived y-value, it is wise to
take this into account: we predict that the y-value will lie at a relatively less extreme
position in the population of y-values than that of the x-value in the population of x-
values. This interpretation of "regression to the mean" within the setting of prediction
is supported by Figure 7.2. This ﬁgure shows two regression lines. The dashed line
seems to follow the point cloud the best, but the solid line is the least squares line. The
slope of the dashed line is sy/sx, whereas the least squares line has the smaller slope
rx,ysy/sx. We can see that the least squares line is a better predictor by looking at the
region between the two vertical lines. The least squares line divides the points in this
strip (as with any other vertical strip) into approximately equal numbers, whereas the
dotted line lies too high.
x
y
-3
-2
-1
0
1
2
3
-1
0
1
2
3
Figure 7.2. The least squares line and "regression to the mean."
7.2.1.2
Tests and Conﬁdence Intervals
Since β is, in general, the most interesting parameter in a simple linear regression
model, in this section we will deduce tests and conﬁdence intervals for β. Tests and
conﬁdence intervals for the predictor parameter α can be deduced analogously. In this
section, we describe the frequently used t-test and the likelihood ratio test.
266

7.2: Linear Regression
To determine whether the predictor variable x has a linear inﬂuence on Y , we
test the null hypothesis H0: β = 0. The usual test statistic for the more general null
hypothesis H0: β = β0 is
T =
ˆβ −β0


varˆβ
,
where ˆβ is the maximum likelihood estimator for β and the variance of ˆβ is estimated
by

varˆβ =
1
n−2
n
i=1(Yi −ˆα −ˆβxi)2
n
i=1(xi −x)2
.
This last estimator is obtained by writing ˆβ as
ˆβ =
n
i=1(xi −x)(Yi −Y )
n
i=1(xi −x)2
=
n
i=1(xi −x)Yi
n
i=1(xi −x)2 ,
using that the variance of Yi is equal to σ2, and then estimating σ2 using n
i=1(Yi −
ˆα −ˆβxi)2/(n −2). (Note that this estimator diﬀers by a factor of n/(n −2) from
the maximum likelihood estimator for σ2.) In Section 7.2.2.3, we prove in a more
general model that the test statistic T under H0: β = β0 has a tn−2-distribution:
the number of degrees of freedom is equal to the number of observations minus the
number of estimated regression coeﬃcients. The null hypothesis is then rejected when
|T | ≥tn−2,1−α0/2, where α0 is the level of the test. We can determine a conﬁdence
interval for β of size α0 based on this t-test:
β = ˆβ ± tn−2,1−α0/2


varˆβ.
The hypothesis H0: β = 0 can also be tested using the likelihood ratio test from
Section 4.7. The numerator of the likelihood ratio statistic is the value of the likelihood
function in the maximum likelihood estimator (ˆα, ˆβ, ˆσ2). In particular, we have
ˆσ2 = SSres/n. In the denominator, the likelihood is maximized over the restricted
parameter space with β = 0. Under the null hypothesis H0: β = 0, the observations
Y1, . . . , Yn are independent and N(α, σ2)-distributed, and the likelihood function is
maximal in (ˆα0, ˆβ0, ˆσ2
0) = (Y , 0, SStot/n); see Example 3.14. The likelihood ratio
statistic is then equal to
2 log λn(Y1, . . . , Yn) = −n log ˆσ2 −SSres
ˆσ2
+ n log ˆσ2
0 + SStot
ˆσ2
0
= −n log SSres/n
SStot/n
= −n log(1 −r2
xY ),
267

7: Regression Models
Since the observations are not identically distributed, Theorem 4.43 is not directly
applicable. However, we can extend the theorem to this case, giving a χ2
1-limit
distribution for 2 log λn, since k −k0 = 3 −2 = 1, with k and k0 as in Theorem 4.43.
We therefore reject the null hypothesis that β = 0 when 2 log λn is greater than or
equal to χ2
1,1−α0, where α0 is the size of the test. Hence the test also rejects the
null hypothesis for large values of |rxy|. The transformation of this quantity through
r →−log(1 −r2) can be viewed as a way to transform the distribution of the test
statistic to approximately a standard distribution, namely a chi-square distribution.
7.2.2 Multiple Linear Regression
In the multiple linear regression model, the independent variable is multidimensional
instead of one-dimensional as in the simple linear regression model. The multiple
linear regression model for n dependent variables Y1, . . . , Yn with corresponding p-
dimensional predictor variables (x1,1, . . . , x1,p), . . . , (xn,1, . . . , xn,p) is described by
Yi =
p

j=1
βjxi,j + ei,
i = 1, . . . , n,
where e1, . . . , en are independent normally distributed random variables with expec-
tation 0 and ﬁnite variance σ2. The predictor variables are once again assumed to
be nonrandom, so that we may view the values xi,1, . . . , xi,p as known constants. It
is useful to present this model in matrix notation. The observation is a vector Y =
(Y1, . . . , Yn)T in Rn, and the regression coeﬃcients form a vector β = (β1, . . . , βp)T
in Rp. If we deﬁne the (n × p)-matrix X as the matrix with (i, j)-element xi,j, then
we can write the model as
(7.3)
Y = Xβ + e,
where e = (e1, . . . , en)T in Rn is the error vector. The matrix X is called the design
matrix. Note that we use the notation X for a nonrandom matrix. In models with an
intercept, the elements in the ﬁrst column of the design matrix are taken equal to 1.
The unknown model parameters are the regression coeﬃcients β = (β1, . . . , βp) and
the variance σ2.
7.2.2.1
Dummy Variables
The chosen predictor variables can be both real-valued and categorical. A categorical
predictor variable, also called a nominal variable, is a variable whose values indicate a
classiﬁcation instead of a relevant numerical size. For example, the values 0 and 1 can
be used for male and female or can indicate a particular region. A standard technique
for incorporating both real-valued and categorical variables in a linear regression
model is to use dummy variables. A dummy variable is an indicator variable and
can only take on the values 0 and 1. When the categorical predictor variable has k
possible classes, we add k predictor dummy variables x1, . . . , xk to the regression
model (without intercept). When the categorical variable belongs to class i, the dummy
268

7.2: Linear Regression
variable xi is given value 1, and the other dummy variables value 0. In the linear
regression model, k regression parameters β1, . . . , βk correspond to these k predictor
dummy variables. For an observation corresponding to a predictor variable in the ith
class, only the parameter βi is used in the regression model; see Table 7.1.
x
x1 x2 · · · xk
k
i=1 βixi
"1"
1 0 · · · 0
β1
"2"
0 1 · · · 0
β2
...
...
"k"
0 0 · · · 1
βk
Table 7.1. Deﬁnition of dummy variables x1, . . . , xk for regression on a categorical variable x with
k classes labeled "1", . . . , "k".
This way, the parameter βi is in fact the intercept for the class i. We do not add an
intercept to the model. When we do want to add an intercept, the number of dummy
variables must be less than the number of classes. In that case, for example the dummy
variable for the ﬁrst class is left out. The parameter β1 is then the usual intercept
and the parameter βi (i = 2, . . . , k) gives the eﬀect of class i on the dependent
variable Y with respect to class 1. In the case of two categorical predictor variables
(for example, when both the region and the gender are taken up in the model), for
the second variable, the model includes one dummy variable less than the number
of corresponding classes. This is necessary to ensure that the design matrix has full
rank; see Section 7.2.2.2. Although it is common to allow only the values 0 and 1 for a
dummy variable, in some situations, it makes sense to use other values. For instance, in
Example 1.5 the model includes a dummy variable that takes on the values −1 and 1.
Both the choice of values for the dummy variable and the choice of using an intercept
or not depend on the desired interpretation of the parameters βi. When there are only
categorical variables, the model for analysis of variance from Section 7.3 applies.
7.2.2.2
Estimation
The following theorem gives the maximum likelihood estimators for the parameters
in the multiple linear regression model.
Theorem 7.4
If the design matrix X in regression model (7.3) has full rank, the maximum
likelihood estimators for β and σ2 are given by
ˆβ = (XT X)−1XTY,
ˆσ2 = Y −X ˆβ2
n
.
269

7: Regression Models
Proof. The log-likelihood function for the multiple linear regression model is given
by
(β, σ2) →log
n

i=1
1
√
2πσ2 e
−1
2 (Yi−p
j=1βjxi,j)2/σ2
= −1
2n log 2π −1
2n log σ2 −
1
2σ2 Y −Xβ2,
where  ·  denotes the Euclidean norm. Completely analogously to what we do in the
case of simple linear regression, we ﬁrst deduce the estimator for β for arbitrary σ2
and then the estimator for σ2.
The maximum likelihood estimator for β is the least-squares estimator ˆβ that
minimizes the function
β →Y −Xβ2,
β ∈Rp.
For every β, the vector Xβ belongs to the range (the column space) of the matrix
X, viewed as a map X: Rp →Rn. The least-squares estimator ˆβ that minimizes
Y −Xβ2 is therefore the vector such that X ˆβ is the element of the range of X that
lies as close as possible to the vector Y . In linear algebra, X ˆβ is called the projection
of Y on the range of X. The projection with respect to the Euclidean norm satisﬁes
the orthogonality relation
Y −X ˆβ, Xγ = γT XT(Y −X ˆβ) = 0
∀γ ∈Rp.
In other words, the "residual" Y −X ˆβ is orthogonal to every arbitrary element of
the column space of X, which can, in general, be written as Xγ for a γ ∈Rp.
Requiring this to be 0 for arbitrary γ ∈Rp means that XT (Y −X ˆβ) = 0. This
is the so-called normal equation. Because of the assumption that X has full rank,
XT X is invertible, and consequently ˆβ = (XT X)−1XT Y . Then X ˆβ is equal to
X(XT X)−1XT Y , which is indeed the projection of Y on the column space of X,
because X(XTX)−1XT is the projection matrix that projects onto this space.
In the second step, we substitute ˆβ for β in the log-likelihood function. We can
easily verify that this gives ˆσ2 = Y −X ˆβ2/n as maximum likelihood estimator for
σ2.
The maximum likelihood estimator ˆβ is unbiased:
E ˆβ = (XT X)−1XTEY = (XT X)−1XT Xβ = β.
The mean square error of ˆβ is
Cov ˆβ = (XT X)−1XT Cov Y X(XTX)−1 = σ2(XT X)−1
270

7.2: Linear Regression
(see Appendix B), since the errors e1, . . . , en are uncorrelated and therefore so are
Y1, . . . , Yn. The matrix XTX is known as the hat matrix. The inverse of the hat
matrix therefore gives an indication of the accuracy of the least-squares estimators.
In particular, after multiplication by σ2, the diagonal elements are equal to the mean
square error of the least-squares estimators ˆβj for the regression coeﬃcients βj. The
assumption that X has full rank is required for the existence of the inverse of XT X.
By, if necessary, leaving out or combining columns, we can always choose the design
matrix such that it has full rank. Linear dependence of the columns of X would lead
to the regression coeﬃcients not being uniquely deﬁned; the dependent columns are
then collinear. This is why in a model with dummy variables, one should be careful
with introducing an intercept (see Section 7.2.2.1); the combination of an intercept
and a dummy variable for each class leads to a design matrix that does not have full
rank, and must therefore be avoided.
Deﬁnition 7.5 Residuals and sums of squares
The residuals of the regression of Y on X are the coordinates of the vector Y −X ˆβ.
The expressions
SStot = Y −Y 12
and
SSres = Y −X ˆβ2
with Y 1 = (Y , . . . , Y ) are called the total sum of squares and the residual sum of
squares.
The coeﬃcient of determination, which is equal to 1 −SSres/SStot (see
Deﬁnition 7.3) takes on values between 0 and 1, as it does in the case of simple
linear regression. This can be seen as follows. The vector Y 1 = (Y , . . . , Y ) is the
best prediction of Y in a model consisting of only an estimated intercept. It is the
projection of Y onto the one-dimensional linear space spanned by the vector 1: =
(1, 1, . . . , 1). Since we have chosen a model with intercept, this space is contained in
the column space of X. Consequently, the residue vector Y −X ˆβ is orthogonal to
the vector 1, that is, Y −X ˆβ, 1 = 0. It also follows that Y −X ˆβ, Y 1 = 0.
Moreover, for every γ in Rp, we have Y −X ˆβ, Xγ = 0, hence in particular
Y −X ˆβ, X ˆβ = 0. Consequently, Y −X ˆβ is orthogonal to both the vector Y 1
and the vector X ˆβ. So the vectors Y −X ˆβ and X ˆβ −Y 1 are orthogonal to each
other. By the Pythagorean theorem, the square of the length of the sum of these two
vectors, Y −Y 1 = (Y −X ˆβ) + (X ˆβ −Y 1), is equal to
Y −Y 12 = Y −X ˆβ2 + X ˆβ −Y 12.
The left-hand side of this equation is equal to SStot, and the ﬁrst term on the
right-hand side is equal to SSres. We see that 0 ≤SSres ≤SStot and that the
coeﬃcient of determination lies between 0 and 1. We can show that, analogously
to 1 −SSres/SStot = r2
x,Y in the simple linear regression model, we have 1 −
SSres/SStot = r2
X ˆβ,Y for the multiple linear regression model.
271

7: Regression Models
When we do not include an intercept in the model, we should also not include an
intercept when computing the total sum of squares. In that case we use SStot = Y 2.
7.2.2.3
Tests
As for the simple linear regression model, for a multiple linear regression model, there
are two important types of tests to determine the inﬂuence of one or more predictor
variables on the dependent variable Y . In this section, we discuss the likelihood ratio
test and the F-test.
For the likelihood ratio test, it is best to view the multiple linear regression model
as a special case of the general linear model. When the design matrix X has full rank,
the column space of X is a p-dimensional linear subspace V ⊂Rn. The multiple
linear regression model can therefore be viewed as a model for the n-dimensional
normally distributed observation Y with expectation vector μ in the linear subspace
V . This is the general form of a linear model. We take the covariance matrix Σ of Y
equal to Σ = σ2I. The model is then parameterized by θ = (μ, σ2) ∈V × (0, ∞).
The log-likelihood function is given by
(μ, σ2) →log
n

i=1
1
√
2πσ2 e−1
2 (yi−μi)2/σ2
= −n
2 log 2π −n
2 log σ2 −Y −μ2
2σ2
.
Maximizing the log-likelihood with respect to μ ∈V is equivalent to minimizing
the function μ →Y −μ2 with respect to μ ∈V . Analogously to what we saw
in Section 7.2.2.2, this minimum is reached in ˆμ = PV Y , with PV Y the orthogonal
projection of Y onto the space V . The square distance Y −ˆμ2 = (I −PV )Y 2
from Y to its projection is then exactly the residual sum of squares. Maximizing the
likelihood with respect to σ2 then gives the maximum likelihood estimator ˆσ2 = (I−
PV )Y 2/n.
The null hypothesis that one or more variables do not inﬂuence the dependent
variable Y can now be viewed as a special case of the null hypothesis H0: μ ∈V0,
with V0 a p0-dimensional linear subspace of V . The log-likelihood ratio statistic is
based on the maximum likelihood estimators under the null hypothesis and for the full
model. Computations analogous to those described above show that the maximum
likelihood estimators for μ and σ2 under the null hypothesis are given by ˆμ0 = PV0Y
and ˆσ2
0 = (I −PV0)Y 2/n. Twice the log-likelihood ratio statistic then becomes
2 log λn(Y ) = −n log ˆσ2 −(I −PV )Y 2
ˆσ2
+ n log ˆσ2
0 + (I −PV0)Y 2
ˆσ2
0
= n log (I −PV0)Y 2
(I −PV )Y 2
272

7.2: Linear Regression
(verify). We see that the numerator of the likelihood ratio statistic is equal to the
residual sum of squares under the null hypothesis, while the denominator is the
residual sum of squares under the full model. When the numerator is much larger
than the denominator, this is an indication that the null hypothesis is incorrect. We
therefore reject the null hypothesis for large values of the statistic. More precisely, we
reject the null hypothesis at level α0 when 2 log λn(Y ) ≥χ2
p−p0;1−α0.
In the F-test, we use a diﬀerent, but related ratio of sums of squares:
F = (PV −PV0)Y 2/(p −p0)
(I −PV )Y 2/(n −p)
.
The vector (PV −PV0)Y is an element of V , since V0 ⊂V and V is a linear space.
Since (I −PV )Y is orthogonal to V , by the Pythagorean theorem we therefore have
(I−PV0)Y 2 = (I−PV )Y +(PV −PV0)Y 2 = (I−PV )Y 2+(PV −PV0)Y 2.
By substituting this equality in the formula for 2 log λn(Y ), we see that we can write
the latter as 2 log λn(Y ) = n log

1 + (p −p0)F/(n −p)

. The log-likelihood ratio
is therefore an increasing function of F, and the likelihood ratio test can equivalently
be formulated as rejecting the null hypothesis for large values of F. By Cochran's
theorem, Theorem B.8, under the null hypothesis F has an F-distribution with p −p0
and n −p degrees of freedom. We consequently reject the null hypothesis at level
α0 when the F-test statistic is greater than or equal to the (1 −α0)-quantile of the
Fp−p0,n−p-distribution, which we denote by Fp−p0,n−p;1−α0.
A common null hypothesis for multiple linear regression models is H0: βj = 0
for some j ∈{1, . . . , p}. If βj = 0, then the jth predictor variable does not
inﬂuence the dependent variable Y . Under the null hypothesis, the regression model
can therefore be simpliﬁed by leaving out this predictor variable. Speciﬁcally, this
means that we remove the jth column from the design matrix, as well as the jth
coordinate of β. We denote the new design matrix by X−j and the shortened vector of
regression parameters by β−j. The maximum likelihood estimator for β−j is derived
analogously to the estimator for β and is equal to ˆβ−j = (XT
−jX−j)−1XT
−jY . The
projection matrices PV and PV0 deﬁned for the general linear model are then equal to
X(XT X)−1XT and X−j(XT
−jX−j)−1XT
−j, and the test statistic for the likelihood
ratio test becomes
2 log λn(Y ) = n log (I −X−j(XT
−jX−j)−1XT
−j)Y 2
(I −X(XTX)−1XT )Y 2
.
The null hypothesis that βj = 0 is rejected when 2 log λn(Y ) ≥χ2
1,1−α0. The F-
test statistic under H0: βj = 0 can be found by substituting the expressions for the
projection matrices; under the null hypothesis, it has an F-distribution with 1 and
n −p degrees of freedom. A test equivalent to this F-test is based on the test statistic
(7.4)
T =
ˆβj
ˆσ2
(XT X)−1
j,j
,
273

7: Regression Models
for which we can show that T 2 = F. Under the null hypothesis, the variable T has a
t-distribution with n−p degrees of freedom. We have F ≥F1,n−p;1−α0 if and only if
|T | ≥tn−p;1−α0/2 since F1,n−p;1−α0 = (tn−p;1−α0/2)2. In particular, for the simple
linear regression model with p = 2, the variable F is the square of the test statistic T
in Section 7.2.1.2 corresponding to H0: β = β0 with β0 = 0.
Example 7.6 Height
Example 1.5 describes a multiple linear regression model for estimating the ﬁnal adult
height of a child based on the heights of the (biological) parents and the gender of the
child. In that example, the regression parameters for the predictor variables "height of
the father" and "height of the mother" are taken equal to 1/2, so that the estimated
model is easy to interpret. In this section, we will leave out this assumption and
estimate a multiple linear regression model based on our own data.
For Y the ﬁnal height of a child, x2 the height of the father, x3 the height of the
mother, and x4 a variable for the child's gender, the multiple linear regression model
looks as follows:
Y = β1 + β2x2 + β3x3 + β4x4 + e,
with e a normally distributed random variable with expectation 0 en variance σ2. We
have taken the ﬁrst predictor variable, x1, equal to 1, so that the model has an intercept.
The predictor variable x4 indicates whether the child is a boy or a girl. Because the
model has one intercept, one dummy variable suﬃces. We want β4 to be equal to half
the average height diﬀerence between men and women, and therefore choose x4 equal
to −1 for a girl and equal to 1 for a boy. Since, on average, boys are taller than girls,
β4 will be positive.
Our data consist of ﬁnal heights of 111 adolescents (44 male and 67 female),
their gender, and the heights of their parents.† For each of the regression parameters,
we test whether the value deviates signiﬁcantly from 0, using the t-test described in
the previous section. We take the size of the tests equal to 0.05. All test are rejected,
and the ﬁnal model with estimated regression parameters is given by
Y = 2.52 + 0.46x2 + 0.55x3 + 6.27x4 + e,
where e is assumed to be normally distributed with expectation 0 and (estimated)
variance 25.78. The coeﬃcient of determination of the model is 0.69. To study whether
the normality assumption is plausible, we can draw scatter plots and possibly carry out
additional tests. Despite the fact that the estimated regression parameters in the model
above do not match the estimates in the Fourth (Dutch) National Growth Study (see
(1.1)), the expected ﬁnal heights are not far apart. For example, in the model above,
the ﬁnal heights of the children of a 180 cm man and a 172 cm woman are equal to
186.2 cm (son) and 173.7 cm (daughter), while the regression model in (1.1) gives
heights 187 cm and 174 cm.
† The data can be found on the book's webpage at http://www.aup.nl under heightdata.
274

7.3: Analysis of Variance
In the model above, the mother's height is of greater inﬂuence on the ﬁnal height
of the child than the father's. Under the assumption that the inﬂuences are equal, the
estimated parameters are ˆβ1 = 3.47, ˆβ2 = ˆβ3 = 0.50, and ˆβ4 = 6.30. This model
matches the model in (1.1) better. The estimated values for β1 and β4 in the model are,
however, somewhat lower, so that the predicted ﬁnal heights will also be somewhat
lower. The model estimated in the Fourth National Growth Study is based on much
more data. The estimated models in this example are therefore less reliable.
7.3 Analysis of Variance
Analysis of variance (or ANOVA) is a technique used to study the inﬂuence of discrete
experimental variables, called factors, on a given continuous dependent variable. We
will focus on analysis of variance with two factors, although the technique is certainly
not restricted to this case.
The classical analysis of variance was developed for the analysis of experiments
in agriculture, to study which type of fertilizer, which irrigation method, combined
with which plant genera, would give the highest yield. Each of the variables fertilizer,
irrigation, and genera is referred to as a factor, and the "yield" is the dependent
variable. It is typical that the factors are categorical variables and take on only a
few diﬀerent values, which are usually not ordered. The values of the factors are
ﬁxed before the experiment and are viewed as known constants. The observation is
a vector whose coordinates are the measured yield for diﬀerent combinations of the
factors. Table 7.2 gives an example of data classiﬁed according to two factors with,
respectively, two and three categories.
A
B
C
L
101
78
68
80
82
42
41
23
19
37
100
83 101
80 106
80
85
74
77
87
52
32
53
67
47
73 106 102 109 105
N
94
71
93 103
87
34
52
42
44
58
117
81
83
91 127
92
86
81
72
87
36
69
82
49
32
99
91 105
91 118
Table 7.2. Data for the analysis of variance with two factors. The ﬁrst factor has I = 2 levels, "L"
and "N"; the second factor has J = 3 levels, "A", "B", and "C". There are K = 10 observations for
each combination of the factors. The data give the traveled distance per day in kilometers (1 km
= 1.6 mi) for rental cars in three diﬀerent classes, rented in Leiden or Noordwijk (Netherlands).
275

7: Regression Models
Two factors with, respectively, I and J diﬀerent levels can be combined in IJ
diﬀerent ways. There can be several observations for each combination (i, j), as in
Table 7.2. We parameterize the model with expectation values μij for the diﬀerent
combinations (i, j) of the two factors. A basic assumption in analysis of variance is
that the observation for combination (i, j) is normally distributed with expectation
μij and variance σ2. Moreover, all observations are assumed independent, so that the
observation vector is a multidimensional normally distributed vector. The goal is to
analyze the dependence of μij on the two factors.
In an analysis of variance, the expectations μij are commonly expressed in so-
called main and interaction eﬀects,
(7.5)
μij = μ + αi + βj + γij.
The parameter μ is the grand mean over all combinations of factors. The main eﬀects
αi and βj give the deviations with respect to the grand mean if the factors are set to i
and j, respectively. The parameters γij are the parts of the expectations μij that cannot
be explained by the factors separately, but can be explained by their combinations; they
are called interaction eﬀects. Without additional conditions on the parameters μ, αi,
βj, and γij, the model cannot be identiﬁed, because we have 1+I+J +IJ parameters
for the IJ expectations. The usual conditions for the parameters are
(7.6)

i
αi = 0,

j
βj = 0,
I

i=1
γij = 0
for j = 1, . . . , J,
J

j=1
γij = 0
for i = 1, . . . , I.
We can easily verify that the parameters that satisfy (7.6) also satisfy
(7.7)
μ = μ..,
αi = μi. −μ,
βj = μ.j −μ,
γij = μij −μ −αi −βj = μij −μi. −μ.j + μ...
In these formulas, a dot · means that an average was taken over the corresponding
index, for example μi.
=
J−1 J
j=1 μij. Conversely, we can verify that the
parameters μ, αi, βj, γij deﬁned in (7.7) are the only parameters that satisfy all
conditions in (7.5) and (7.6).
We can therefore describe the model both in terms of the parameters μij and in
terms of the parameters μ, αi, βj, γij. An advantage of reparameterizing is that we
can easily formulate the important hypotheses in terms of main eﬀects and interaction
eﬀects. The hypothesis that there is no interaction is H0: γij = 0 for i = 1, . . . , I, j =
1, . . . , J, while the hypotheses H0: αi = 0 for i = 1, . . . , I and H0: βj = 0 for
j = 1, . . . , J imply that, respectively, the ﬁrst and second factors of the experiment
do not play a role in the value of the observation. Of course, more speciﬁc hypotheses
concerning the eﬀects can also be interesting.
276

7.3: Analysis of Variance
7.3.1 Estimation
When there are Kij observations for each combination (i, j) of the factors, we have
an observation vector Y = (Yijk) of length n = 
i,j Kij. The model is then given
by
(7.8)
Yijk = μ + αi + βj + γij + eijk,
where the errors eijk are independent and normally distributed with expectation 0 and
variance σ2 for i = 1, . . . , I, j = 1, . . . , J, and k = 1, . . . , Kij. The log-likelihood
function is given by
(μ, α, β, γ, σ2) →−n
2 log(2πσ2) −
1
2σ2

i,j,k
(Yijk −μ −αi −βj −γij)2,
where the vector (μ, α, β, γ) is the parameter vector that contains all eﬀects. As with
linear regression, the maximum likelihood estimators for the expectation parameters
(in this case, the eﬀects) are equal to the least-squares estimators. The likelihood
equations for the eﬀects are
I

i=1
J

j=1
Kij

k=1
(Yijk −μ −αi −βj −γij) = 0,
J

j=1
Kij

k=1
(Yijk −μ −αi −βj −γij) = 0
for i = 1, . . . , I,
I

i=1
Kij

k=1
(Yijk −μ −αi −βj −γij) = 0
for j = 1, . . . , J,
Kij

k=1
(Yijk −μ −αi −βj −γij) = 0
for i = 1, . . . , I, j = 1, . . . , J.
Using the relations in (7.6), we ﬁnd the following estimators:
ˆμ = Y...,
ˆαi = Yi.. −Y...,
ˆβj = Y.j. −Y...,
ˆγij = Yij. −Yi.. −Y.j. + Y...,
where a dot · again means averaging over the corresponding index. The estimator for
the variance can be found by substituting these estimators in the likelihood function
and maximizing the result with respect to σ2:
ˆσ2 = 1
n

i,j,k
(Yijk −ˆμ −ˆαi −ˆβj −ˆγij)2.
277

7: Regression Models
Finally, we note that it follows from the above that the maximum likelihood
estimator for μij is equal to ˆμij = ˆμ + ˆαi + ˆβj + ˆγij = Yij.. This result is, of
course, not surprising; if we were to leave out the reparameterization and estimate the
parameter μij itself, we would have found exactly this estimator.
7.3.2 Tests
The interesting null hypotheses to test in analysis of variance are H0: αi = 0 for
i = 1, . . . , I and H0: βj = 0 for j = 1, . . . , J, which we can use to study the main
eﬀects, and H0: γij = 0 for i = 1, . . . , I, j = 1, . . . , J, which we can use to study
the signiﬁcance of the interaction eﬀects. The analysis is particularly appealing if we
have the same number Kij = K > 1 of replicates for every combination (i, j), a so-
called "balanced design with replication." The observations vector Y = (Yijk) is then
an n-dimensional multivariate normally distributed random vector, with n = IJK.
In the remainder of this section, we assume that we have a balanced design with K
replicates.
Not all hypotheses can be tested in a meaningful way; whether they can be
tested depends on the available data. If, for example, we have only one observation
for each combination (i, j) of factors, then we have only one observation for each
"free" parameter μij (not counting an additional variance parameter). It is intuitively
clear that in such a case, we cannot draw meaningful conclusions on the interaction
parameters γij. We then need to either collect more data or make some prior
assumptions. A popular assumption is, for example, that the interaction factors γij
are equal to 0. The resulting additive model μij = μ + αi + βj has only I + J −1
parameters and can be ﬁtted to the data in a meaningful way, provided that the prior
assumption that there is no interaction is correct. Unfortunately, the latter can rarely
be shown (without additional data).
It turns out to be useful and insightful to view analysis of variance as a special
case of the general linear model (see Section 7.2.2.3). For this interpretation, we ﬁrst
study the design matrix. Consider, for convenience, the case I = 2 and J = 3, as in
Table 7.2. The expectation vector (μij) for a single replicate can be written as
(7.9)
⎛
⎜
⎜
⎜
⎜
⎜
⎝
μ11
μ12
μ13
μ21
μ22
μ23
⎞
⎟
⎟
⎟
⎟
⎟
⎠
=
⎛
⎜
⎜
⎜
⎜
⎜
⎝
1
1
1
0
1
0
1
1
0
1
0
1
1
1
−1
−1
−1
−1
1
−1
1
0
−1
0
1
−1
0
1
0
−1
1
−1
−1
−1
1
1
⎞
⎟
⎟
⎟
⎟
⎟
⎠
⎛
⎜
⎜
⎜
⎜
⎜
⎝
μ
α1
β1
β2
γ11
γ12
⎞
⎟
⎟
⎟
⎟
⎟
⎠
.
There are IJ = 6 parameters (μ, α1, β1, β2, γ11, γ12) on the right-hand side. In this
parameterization, the parameters (α2, β3, γ13, γ21, γ22, γ23) are expressed in the other
parameters using the relations (7.6). For example,
μ23 = μ + α2 + β3 + γ23
= μ −α1 −β1 −β2 −γ13
= μ −α1 −β1 −β2 + γ11 + γ12.
278

7.3: Analysis of Variance
The 6 parameters on the right-hand side, and therefore the 6 columns of the design
matrix, break up into 4 groups corresponding to the grand mean (column 1), the main
eﬀect α (column 2), the main eﬀect β (columns 3 and 4), and the interaction eﬀects
(columns 5 and 6). Inspecting the design matrix shows that the four linear spaces
spanned by these groups of columns are orthogonal to one another. This property of
the design matrix also holds for other values of I and J. The number of columns per
group is equal to 1 (grand mean), I −1 (main eﬀects α), J −1 (main eﬀects β),
and (I −1)(J −1) (interaction eﬀects). The total number of columns in the design
matrix, and hence the number of parameters, is therefore equal to IJ. This number of
parameters is equal to the number of parameters before the reparameterization (7.5),
that is, to the number of expected values μij. In the case of a balanced design with
K replicates, the expectation vector for the full observation vector Y of length IJK
can be obtained by stacking K expectation vectors of length IJ for one replicate of
all combinations on top of one another. The design matrix corresponding to this full
observation matrix is obtained by repeating the design matrix in (7.9) K times and
placing the matrices on top of one another. The distribution of the columns in four
orthogonal groups (grand mean, main eﬀect α, main eﬀect β, and interaction eﬀects)
is obviously preserved in this combined design matrix.
The distribution in orthogonal column groups of the design matrix described
above is important for the application of the F-test from Section 7.2.2.3 to the relevant
null hypotheses in analysis of variance. The maximum likelihood estimator for the
expectation vector EY in a balanced design is given by PV Y if V is the linear
subspace of Rn spanned by the columns of the combined design matrix. Since V
is spanned by four orthogonal column groups, the projection PV is equal to the sum
of the four orthogonal projections, each corresponding to a column group,
(7.10)
PV Y = PμY + PαY + PβY + PγY,
where Pμ, Pα, Pβ, and Pγ are the orthogonal projections from Rn onto the four
subspaces. The dimensions of the spaces onto which Pμ, Pα, Pβ, and Pγ project are
equal to the numbers of columns in the corresponding column groups of the design
matrix, that is, 1, I −1, J −1, and (I −1)(J −1), respectively. The null hypotheses
on the interaction and main eﬀects are linear in the parameters and can therefore
be viewed as assertions that the expectation vector EY belongs to a certain linear
subspace of the n-dimensional space. For example, the null hypothesis that there is
no interaction, H0: γij = 0 for i = 1, . . . , I, j = 1, . . . , J, corresponds to the linear
subspace V0 spanned by the three column groups of the design matrix corresponding
to Pμ, Pα, and Pβ. In that case, the term PV0Y in the F-test statistic is equal to
PV0Y = PμY + PαY + PβY . To compute the sums of squares in the numerator and
denominator of the F-test statistic, we take a closer look at the projections in (7.10).
The four projections on the right-hand side of (7.10) are orthogonal to one
another and orthogonal to (I −PV )Y . It therefore follows from the Pythagorean
theorem that
Y 2 −PμY 2 = PαY 2 +PβY 2 +PγY 2 +
(I −Pμ −Pα −Pβ −Pγ)Y
2.
279

7: Regression Models
After some computation, we see that the diﬀerent terms in this decomposition can be
written as
(7.11)
Y 2 −PμY 2 =

i,j,k
(Yijk −Y...)2,
PαY 2 =

i,j,k
(Yi.. −Y...)2 = JK

i
ˆα2
i ,
PβY 2 =

i,j,k
(Y.j. −Y...)2 = IK

j
ˆβ2
j ,
PγY 2 =

i,j,k
(Yij. −Yi.. −Y.j. + Y...)2 = K

i,j
ˆγ2
ij.
Deﬁnition 7.7 Sums of squares
The total sum of squares is equal to
SStot =

i,j,k
(Yijk −Y...)2.
The sums of squares of the ﬁrst and second factors are equal to
SSα =

i,j,k
(Yi.. −Y...)2,
SSβ =

i,j,k
(Y.j. −Y...)2.
The sum of squares of the interaction is equal to
SSγ =

i,j,k
(Yij. −Yi.. −Y.j. + Y...)2.
The residual sum of squares is equal to
SSres =

i,j,k
(Yijk −Yij.)2.
It follows from Deﬁnition 7.7 that
SStot = SSα + SSβ + SSγ + SSres.
The F-test statistics turn out to be quotients of these sums of squares, also called
"variances." This explains the name "analysis of variance." The following theorem
follows from the equations in (7.11), Deﬁnition 7.7, and Cochran's theorem (Theorem
B.8).
280

7.3: Analysis of Variance
Theorem 7.8
Suppose that the errors eijk in (7.8) are independent and normally distributed with
expectation 0 and variance σ2. Then
(i) under H0: αi = 0 for i = 1, . . . , I, the variable
Fα =
SSα/(I −1)
SSres/(IJ(K −1))
has an F-distribution with I −1 and IJ(K −1) degrees of freedom;
(ii) under H0: βj = 0 for j = 1, . . . , J the variable
Fβ =
SSβ/(J −1)
SSres/(IJ(K −1))
has an F-distribution with J −1 and IJ(K −1) degrees of freedom;
(iii) under H0: γij = 0 for i = 1, . . . , I, j = 1, . . . , J, the variable
Fγ = SSγ/((I −1)(J −1))
SSres/(IJ(K −1))
has an F-distribution with (I −1)(J −1) and IJ(K −1) degrees of freedom.
Together with (7.11), this theorem shows that the null hypothesis that the ﬁrst
factor does not have any inﬂuence is rejected for large values of  ˆα2
i , which is
intuitively clear. An analogous statement holds for the second main eﬀect and the
interaction eﬀects. The results of these three tests are commonly given in an analysis
of variance table.
In the case of an unbalanced design with replication, the test statistics can
be computed analogously using the general theory. However, the linear spaces
corresponding to the eﬀects are no longer necessarily orthogonal to one another. The
sums of squares corresponding to the hypotheses then do not add up to the total sum
of squares, and Theorem 7.8 does not hold.
Example 7.9
We apply the theory given above to the data in Table 7.2. The traveled distance is
assumed to be approximately normally distributed. We discuss the results of both the
model with interaction and the additive model. For both models, we have I = 2 and
J = 3, and we have a balanced design with K = 10.
For the model with interaction, the estimates for the grand mean and the main
and interaction eﬀects are given in Table 7.3. We can easily verify that the relations in
(7.6) hold for the estimated eﬀects.
281

7: Regression Models
Grand mean
75.95
City
Leiden Noordwijk
-2.95
2.95
Class
A
B
C
7.95 -30.40
22.45
City:Class
Class
City
A
B
C
Leiden
0.25 -1.30
1.05
Noordwijk -0.25
1.30 -1.05
Table 7.3.
R-output containing the maximum likelihood estimates for the grand mean and the
main and interaction eﬀects for the data from Table 7.2.
The results of the three F-tests from Theorem 7.8 are shown in the analysis of
variance table in Table 7.4. The sums of squares SSα, SSβ, SSγ, and SSres are the
successive entries in the column "Sum Sq". The column "Df" has the corresponding
degrees of freedom. The column "Mean Sq" gives the quotient of the sum of squares
and the number of degrees of freedom. The values of Fα, Fβ, and Fγ are the successive
entries in the column "F value", and the last column gives the p-values for these test
statistics.
Df
Sum Sq
Mean Sq
F value
Pr(>F)
city
1
522.2
522.2
2.9586
0.09115
class
2
29827.3
14913.7
84.5028
< 2e-16
city:class
2
57.1
28.5
0.1618
0.85105
residuals
54
9530.3
176.5
Table 7.4. R-output containing the analysis of variance table for testing the main and interaction
eﬀects for the data from Table 7.2 in an analysis of variance model with two factors with interaction.
The result of the tests is that the null hypothesis of no interaction is not rejected.
The main eﬀect of the factor "city" is not signiﬁcant at level 0.05, whereas the main
eﬀect of the factor "class" is clearly signiﬁcant. The conclusion of the tests is that the
class inﬂuences the traveled distance, while there is no clear inﬂuence of the factor
"city".
When we make the prior assumption that there are no interaction eﬀects, we can
use an additive model. The estimates for the main eﬀects are equal to those for the
model with interaction in Table 7.3. The analysis of variance table for the additive
model is given in Table 7.5. The conclusions concerning the signiﬁcance of the main
282

7.4: Nonlinear and Nonparametric Regression
Df
Sum Sq
Mean Sq
F value
Pr(>F)
city
1
522.2
522.2
3.0499
0.08623
class
2
29827.3
14913.7
87.1106
< 2e-16
residuals
56
9587.4
171.2
Table 7.5. R-output containing the analysis of variance table for testing the main eﬀects for the
data from Table 7.2 in an additive analysis of variance model with two factors.
eﬀects are the same as in the model with interaction. Note that the residual sum
of squares and the corresponding number of degrees of freedom are greater than in
the (more elaborate) model with interaction. The p-values of both tests are therefore
diﬀerent from those in the model with interaction.
7.4 Nonlinear and Nonparametric Regression
In the linear regression model, the conditional expectation of the dependent variable Y
given the predictor variable X = x, that is, x →E(Y | X = x), is a linear function of
the parameter β. We can replace this regression function by a more general function,
E(Y | X = x) = f(x).
This equation is also called the regression equation.
If f = fθ is known up to the parameter θ and fθ is a nonlinear function of θ, then
we speak of nonlinear regression. As with linear regression, the parameter θ can be
estimated using the least-squares method. The least-squares estimator for θ minimizes
the criterion
θ →
n

i=1

Yi −fθ(xi)
2.
Often, a numeric algorithm is necessary to determine the least-squares estimate. If the
measurement errors in the model
Y = fθ(x) + e
are normally distributed, then the least-squares estimator for θ is also the maximum
likelihood estimator. An example of a parameterized nonlinear regression model is the
time curve
E(Y | X = x) = gθ(x) = θ0 + θ1x + θ2e−θ3x.
For observations y1, . . . , yn at times x1, . . . , xn, we ﬁnd the least-squares estimator
θ = (θ0, θ1, θ2, θ3) by minimizing
n

i=1

yi −θ0 −θ1xi −θ2e−θ3xi2
283

7: Regression Models
with respect to θ.
If the form of the function f is not speciﬁed beforehand, then we speak of
nonparametric regression. We then use the observations to determine a suitable type of
function. We can use diﬀerent methods for approximating functions, including Fourier
series, wavelets, spline functions, and neural networks. An (almost) arbitrary function
f(x) = E(Y | X = x) on the interval [0, 2π] can, for example, be represented as a
Fourier series
f(x) =
∞

n=0

an cos(nx) + bn sin(nx)

,
for certain constants an and bn that depend on f. By estimating these constants from
the data and substituting the estimates in the formula (where we truncate the sum after
a ﬁnite number of terms), we ﬁnd an estimator for f. So-called wavelets are similar
series expansions with appealing features.
An intermediate form consists of the additive models, in which the conditional
expectation E(Y | X = x) with a vector-valued predictor variable X = (X1, . . . , Xk)
is modeled as
E(Y | X = x) = f1(x1) + f2(x2) + · · · + fk(xk),
for functions f1, . . . , fk that are not speciﬁed beforehand. Choosing linear functions
fi would lead back to the linear regression model.
Figures 7.3 and 7.4 illustrate the possibilities with a model that is partially
additive and partially nonparametric. We have ﬁtted the model E(Y | X = x) =
f(x1) + g(x2, x3), where Y is the ozone concentration and X = (X1, X2, X3)
contains the predictor variables radiation, temperature, and wind speed. Figure 7.3
gives the estimate of f, and Figure 7.4 give the estimate of g. This model will be
discussed further in the application following Chapter 8.
0
50
100
150
200
250
300
−10
−5
0
5
radiation
Figure 7.3. The estimate of f in the model E(Y | X = x) = f(x1) + g(x2, x3).
284

7.4: Nonlinear and Nonparametric Regression
wind
5
10
15
20
25
30
temperature
15
20
25
30
35
50
100
150
Figure 7.4. The estimate of g in the model E(Y | X = x) = f(x1) + g(x2, x3).
The dimensionality of the predictor variable plays a major role in regression
problems. Without prior information or huge amounts of data, we can barely determine
the correlation between a variable Y and a multidimensional predictor variable X.
Even "estimating," for example, 10 unknown parameters β1, . . . , β10 in a linear
regression model can, in practice, cause problems. Unless the number of data points is
large with respect to the number of unknown parameters, it is impossible to estimate
the unknown parameters reliably. In a linear regression model, the number of unknown
parameters is relatively small (the number of βi and the unknown σ2), but in a
nonparametric model, the number of unknown parameters is theoretically inﬁnitely
large. A certain prior restriction on the model is therefore necessary.
We are dealing with a trade-oﬀ, which we have also encountered in another
context. If we use a small model with few unknown parameters (for example, a
linear model), then we can determine these parameters reasonably well based on the
available data. We run a high risk, however, that the model is incorrect, because of
which applying it (for example as a prediction) could have disastrous consequences.
A large model (for example, a nonparametric model or a linear model that includes, in
addition to each predictor variable Xi, the powers X2
i , X3
i , . . . and mixed products
XiXj, XiX2
j , . . .) can potentially describe the reality better, but the amount of
available data may be too small to accurately estimate the parameters reliably.
285

7: Regression Models
7.5 Classiﬁcation
To determine the "credit risk" of clients, insurance companies use background
variables such as age, living conditions, income, number of claims in the past year,
size of the claims, etc. Based on this data, the insurance company wants to estimate
whether the client will ﬁle a substantial claim.
This is an example of a classiﬁcation problem. Based on the data x
=
(x1, . . . , xm), we want to predict whether a certain event will take place. If we encode
these two possibilities as Y = 1 and Y = 0, respectively, then the problem is to
predict the Y -value of an individual based on the measured "input" x. These values x
are often called covariates. In contrast to the assumption in Section 7.2, in this section,
we take a random predictor variable X and view the observed (x, y) as a realization
of a random vector (X, Y ). We are now looking for the conditional distribution of Y
given X = x. In most cases, there will not exist a perfect correlation between x on the
one hand and Y given X = x on the other. It seems natural to use a model expressed
in probabilities, and therefore we are interested in the conditional probability
P(Y = 1| X = x) = 1 −P(Y = 0| X = x)
that an arbitrary event for which the value of the predictor variable X is known has a
Y -value equal to 1.
In this set-up, a statistical model consists of a detailed description of the
probability distribution of (X, Y ). In particular, we need a detailed description of the
conditional probabilities mentioned above. A classical model is the logistic regression
model, in which
(7.12)
P(Y = 1| X = x) =
1
1 + e
−m
j=1 βjxj .
In this model, the value of the predictor variable x = (x1, . . . , xm) inﬂuences the
probability distribution of the dependent variable Y through a linear combination
m
j=1 βjxj, for certain coeﬃcients β1, . . . , βm that express the relative importance
of the diﬀerent xj. The function x →Ψ(x) = (1 + e−x)−1 is the logistic distribution
function and maps the real numbers m
j=1 βjxj onto the interval [0, 1], so that
the function values may have the character of a probability. Choosing this function
seems useful for computations, but other than that, it is rather arbitrary. The normal
distribution function is also often used, in which case we speak of probit regression.
In that case,
P(Y = 1| X = x) = Φ
 m

j=1
βjxj

.
Figure 7.5 shows that Ψ(x) ≈Φ(x/1.8), so that the two functions lead to almost
identical results, up to a scaling constant of β.
286

7.5: Classiﬁcation
-6
-4
-2
0
2
4
6
0.0
0.2
0.4
0.6
0.8
1.0
Figure 7.5. The logistic function (solid line) and the normal distribution with standard deviation
1.8 (dotted).
The variables X1, . . . , Xm can measure more or less isolated aspects of the
individuals, but can also be related. If the correlation between the independent variable
Y and the predictor variable X1 is quadratic instead of linear (for example, if both
small and large values of X1 lead to a high probability that Y = 1, while intermediate
values usually give Y = 0), then it is wise to include x2
1 in addition to x1 in the
model of the conditional probability. As in the case of linear regression, we then, for
example, take x2 = x2
1. Logarithmic and exponential transformations are also often
applied. Interactions between predictor variables can be modeled in the regression
model by also including products like x1x2. Categorical predictor variables that are
classiﬁed in ﬁnitely many classes, like regions, can be included in the model using
dummy variables, as was done for linear regression (see Section 7.2.2.1).
In addition to polynomials, there are many other possibilities to model the
probabilities P(Y = 1| X = x), for example using wavelets or neural networks.
The underlying idea remains the same: in a class of possibilities for the probabilities
P(Y
= 1| X = x) we determine the one that ﬁts best with the observed data
(x1, y1), . . . , (xn, yn) and then use this for the classiﬁcation of new cases. In the
machine learning literature, the full observed data is also called the training sample
and ﬁnding the best-ﬁtting model is called training or learning. Here, we will keep the
statistical terms "observed data" and "estimating."
7.5.1 Estimation
In this section, we restrict ourselves to a one-dimensional variable X and deduce
equations for the maximum likelihood estimators for the classiﬁcation problem
Pα,β(Y = 1|X = x) =
1
1 + e−α−βx ,
where α and β are the unknown parameters. The parameters can be estimated based
on a sample of values (x1, y1), . . . , (xn, yn). Then, we can use the estimated model to
predict Y based on a new value of x in the future.
287

7: Regression Models
Suppose that Y1, . . . , Yn given X1, . . . , Xn are independent random variables
with values in {0, 1}, distributed following the probability distribution above. The
probability distribution of Yi given Xi can then also be written as
Pα,β(Yi = yi|Xi = xi) =

1
1 + e−α−βxi
yi
1 −
1
1 + e−α−βxi
1−yi
,
for i = 1, . . . , n. In other words, Yi given Xi = xi has the Bernoulli distribution, and
the probability of "success" is some function of the value xi.
The likelihood function is given by
L(α, β; Y1, . . . , Yn) =
n

i=1

1
1 + e−α−βxi
Yi
1 −
1
1 + e−α−βxi
1−Yi
.
After some computation, setting the partial derivatives of the log-likelihood function
with respect to α and β equal to 0 leads to the following equations:
n

i=1
Yi −Ψ(ˆα + ˆβxi)
Ψ(ˆα + ˆβxi)

1 −Ψ(ˆα + ˆβxi)
Ψ(ˆα + ˆβxi) = 0,
n

i=1
Yi −Ψ(ˆα + βxi)
Ψ(ˆα + ˆβxi)

1 −Ψ(ˆα + ˆβxi)
Ψ(ˆα + ˆβxi)xi = 0,
where Ψ(x) = (1+e−x)−1. We cannot solve ˆα and ˆβ explicitly from these equations.
In practice this is not a problem because we can easily solve the equations numerically,
using an iterative algorithm. This also holds in the case of a multidimensional predictor
variable X.
The likelihood equations given above also hold when we use another "linking"
function than the logistic function Ψ. In probit regression, for example, where instead
of Ψ we use the normal distribution function Φ, we ﬁnd the same equations with Ψ
replaced by Φ. The logistic distribution function Ψ has the computational advantage
that Ψ = Ψ(1 −Ψ), so that the likelihood equations can be greatly simpliﬁed. They
do, however, remain nonlinear.
7.5.2 Tests
In the logistic regression model with a multidimensional predictor variable X, it is
interesting to test whether a certain component of the predictor variable inﬂuences the
response. This is, for example, an interesting hypothesis when the dependent variable
Y stands for ﬁling or not ﬁling a claim with an insurance company in the past two
years and the ﬁrst coordinate X1 indicates the age of the insured person. When the
insurance company wants to know whether the age indeed has a predictive value for
ﬁling claims, the null hypothesis H0: β1 = 0 that the ﬁrst coordinate of the parameter
vector β = (β1, . . . , βm) is 0 can be tested against the alternative H1: β1 = 0.
288

7.5: Classiﬁcation
To test a null hypothesis of the form H0: (βj: j ∈J) = 0, the likelihood
ratio test is often used. Although there is no analytic expression for the likelihood
ratio statistic, the value of the likelihood ratio statistic can easily be determined
numerically using an iterative algorithm. For observed values (x1,1, . . . , x1,m, y1),
. . ., (xn,1, . . . , xn,m, yn), the value of the likelihood can be computed as
L(β, y1, . . . , yn) =
n

i=1

1
1 + e
−m
j=1 βjxi,j
yi
1 −
1
1 + e
−m
j=1 βjxi,j
1−yi
;
see Section 7.5.1. To compute the likelihood ratio statistic, it therefore suﬃces to
determine the maximum likelihood estimators under the full model and under the null
hypothesis. In Section 7.5.1, we discuss a particular case of this computation.
Standard computer software packages often do not report the likelihood ratio
statistic directly; they rather give it through a so-called (residual) deviance. This is
equal to twice the log-likelihood ratio statistic, 2 log λn, for testing the null hypothesis
that the model is correct, that is, that there exists a vector β ∈Rm such that (7.12)
holds, inside the full model that Y1, . . . , Yn are independent Bernoulli variables with
possibly diﬀerent probabilities of success pi = P(Yi = 1). The deviance therefore
gives a measure for the ﬁt of the logistic regression model. Moreover, the diﬀerence
between the deviance for the full model (7.12) and the deviance for a submodel (such
as the model under H0: (βj: j ∈J) = 0) is equal to twice the log-likelihood ratio
statistic for testing the submodel.
An alternative for the likelihood ratio test is the Wald test (see Section 4.8), whose
p-values are often reported in computer outputs.
7.5.3 Conﬁdence Regions
We can determine conﬁdence regions for the parameter β using the Fisher information
matrix. In this section, we again restrict ourselves to a one-dimensional predictor
variable, as in Section 7.5.1,
Pα,β(Y = 1|X = x) =
1
1 + e−α−βx .
Let (X1, Y1), . . . , (Xn, Yn) be independent, identically distributed random vectors
with Yi ∈{0, 1}, and assume that the joint probability distribution of X and Y is
given by
Pα,β(X = x, Y = y) = Pα,β(Y = y|X = x)pX(x)
=

1
1 + e−α−βx
y
1 −
1
1 + e−α−βx
1−y
pX(x),
for unknown parameters (α, β). Here, pX is the marginal density (or probability
mass function) of X. We can estimate the parameters α and β using their maximum
likelihood estimators (see Section 7.5.1). The score function of the model is given by
˙α,β(x, y) =
y −Ψ(α + βx)
Ψ(α + βx)

1 −Ψ(α + βx)
Ψ(α + βx)

1
x

.
289

7: Regression Models
The Fisher information matrix is therefore given by (see Section 5.4.2)
iα,β =

Ψ(α + βx)2
Ψ(α + βx)

1 −Ψ(α + βx)


1
x
x
x2

pX(x) dx,
where the integral is taken over all possible outcomes of X. We can estimate this
matrix by replacing the integral by a sum over the observations and replacing the
marginal density pX by 1/n for every observation. In other words, we estimate
the marginal distribution of X using the empirical marginal distribution of X. We
moreover use the idea of a plug-in estimator for the Fisher information and replace α
and β by their maximum likelihood estimators. This gives

iα,β = 1
n
n

i=1
Ψ(ˆα + ˆβxi)2
Ψ(ˆα + ˆβxi)

1 −Ψ(ˆα + ˆβxi)


1
xi
xi
x2
i

.
An approximate conﬁdence region for (α, β) of size α0 is given by the set

(α, β): ( α −ˆα
β −ˆβ ) n
iα,β

α −ˆα
β −ˆβ

≤χ2
2,1−α0

.
* 7.6 Cox Regression Model
In survival analysis, we are interested in the probability distribution of time spans.
You can think of the life span of a device, the incubation time of an illness, the time
before dying after a serious operation, the time before an ex-convict commits a new
crime (see the application after Chapter 1), but also the time before the next bug occurs
in a computer program ("reliability analysis").
Models in survival analysis are often given in terms of the risk function or the
hazard function. The hazard function associated with a probability density f is deﬁned
as
λ(t) =
f(t)
1 −F(t),
where F is the corresponding distribution function. If we view f(t) dt as the
probability that a life span T lies in the interval [t, t + dt), then λ(t) dt has the
interpretation
λ(t) dt ≈P(t ≤T < t + dt)
P(T ≥t)
= P(t ≤T < t + dt| T ≥t).
The value λ(t) is therefore the conditional probability of "dying" right after time t
given that at time t, the person or product is still "alive." It is this interpretation as
an "instantaneous probability" that makes the hazard function appealing as a tool for
modeling.
290

7.6: Cox Regression Model
The hazard function t →λ(t) is the derivative of t →−log(1 −F(t)) with
respect to t. Given the hazard function λ, we can recover the distribution function F
using the formula F(t) = 1 −e−Λ(t), for Λ the cumulative hazard function, that is,
the primitive function of λ with Λ(0) = 0 (if F(0) = 0). The density f is then equal
to f(t) = λ(t)e−Λ(t).
A popular model from medical statistics is the Cox model, proposed by Cox in
the 1970s. In this model, the life span T (the dependent variable) is correlated to a
vector X of predictor variables such as age, weight, blood pressure, prognosis, etc.
The Cox model postulates that the hazard function of a patient with "covariate vector"
x is equal to
λT |X=x(t) = eβT xλ(t).
Here, λ is the hazard function of a patient with predictor variable x = 0, the so-called
"baseline hazard." Thus, the Cox model postulates that the hazard functions of two
patients with predictor variables x1 and x2 are proportional,
λT |X=x1(t)
λT |X=x2(t) = eβT (x1−x2),
independently of t. This gives a simple interpretation for the parameter β: it
determines the size of the relative risks attached to certain predictor variables. For
example, if x is body weight, T is the age at time of death, and β = 1.4, then the risk
of dying now for someone of weight 120 kg is a factor e1.4∗(120−90) times as great
as that for someone who weights 90 kg. That this relative risk is independent of time
(and therefore of age in this example) simpliﬁes the interpretation, but is not always a
reasonable assumption. That is why there are many variations of the Cox model.
In the Cox model, the hazard function λ is not speciﬁed. The model therefore
has as parameter the pair θ = (β, λ) consisting of a vector β and a function
λ. Both parameters are estimated from the available data, for example a sample
(T1, X1), . . . , (Tn, Xn) of life spans and predictor variables.
We can also set as model that λ has a certain form. The assumption that the
function t →λ(t) is constant, for example, corresponds to the assumption that if the
variable x is equal to 0, then the survival distribution is the exponential distribution.
This assumption, which has the interpretation that "new is just as good (or bad)
as used," is in general unrealistic in medical statistics, but can (unfortunately) be
realistic for the number of remaining bugs in reliability theory. The Weibull family,
for which the function λ is a power function λ(t) = βtα, is another possible family.
The advantage of the Cox model without speciﬁcation of the hazard function λ over
these possibilities is that it avoids the randomness of the choice of a particular type
of function, so that the parameters that are estimated using the Cox model will more
frequently give a good approximation for the data. On the other hand, if there are
reasonable grounds to expect a certain form for the hazard function, then it is better
not to use the Cox model because it contains more prior uncertainty.
291

7: Regression Models
A diﬃcult aspect of survival analysis is that, often, not all life spans are observed.
At the moment when we want to draw conclusions from the data, for example, not
all individuals have "died," and we only know a lower bound for those life spans.
In medical applications, it frequently occurs that patients cannot be followed until
their death, for example because they have moved away or because they have died
from another cause than the one being studied. In those cases, too, we only observe a
lower bound for the life spans. We then speak of censored data. Long life spans are
more frequently censored than short ones. The reason is that moving away, death from
another cause, or the end of the study have a greater probability of occurring in a long
time interval than in a short one. It would therefore be wrong to ignore censored data
because we would then ignore relatively many long life spans. This could lead to an
underestimate of the life span distribution. A correct approach is to use a statistical
model for all observations.
7.6.1 Estimation
In an uncensored Cox model with one-dimensional predictor variable X, we assume
that we have a sample (T1, X1), . . . , (Tn, Xn). This model is speciﬁed by the
conditional hazard function
λT |X=x(t) = eβxλ(t).
This corresponds to a conditional density of the form
f T |X=x(t) = eβxλ(t)e−eβxΛ(t)
and a conditional distribution function
F T |X=x(t) = 1 −e−eβxΛ(t),
with Λ the cumulative hazard function. For the maximum likelihood estimator for the
parameter (β, λ), we need the likelihood function. This is given by
(β, λ) →
n

i=1
f T |Xi(Ti)pX(Xi) =
n

i=1
eβXiλ(Ti)e−eβXi Λ(Ti)pX(Xi)
=
n

i=1
eβXiλ(Ti)e−eβXi Λ(Ti)
n

j=1
pX(Xj),
where pX is the marginal density of the predictor variable. Because it is not obvious
that this distribution contains information on the parameters, we can disregard the
term n
j=1 pX(Xj) in the likelihood when we maximize with respect to (β, λ). The
maximum likelihood estimator for (β, λ) is therefore the value that maximizes the
function
(β, λ) →
n

i=1
eβXiλ(Ti)e−eβxΛ(Ti)
292

7.6: Cox Regression Model
over all possible parameter values (β, λ).
Unfortunately, this problem has no solution (a point of maximum does not exist,
and the supremum over all possible parameter values is inﬁnite) because the parameter
space for λ, the set of all hazard functions, is too large. The most common modiﬁcation
of the problem is to deﬁne it in terms of (β, Λ) instead of (β, λ). We then replace the
factor λ(Ti) by the jump ΔΛ(Ti) in the cumulative hazard function in Ti. In other
words, we are looking for the pair (ˆβ, ˆΛ) that maximizes the function
(β, Λ) →
n

i=1
eβXiΔΛ(Ti)e−eβXi Λ(Ti)
over all possible parameter values (β, Λ) consisting of a scalar β and a right-
continuous, monotonically increasing function Λ: [0, ∞) →[0, ∞) with Λ(0) = 0.
This problem does have a solution, known as the Cox estimator. In practice, to
compute this estimator we need an iterative algorithm. This is standard in computer
packages for survival analysis.
An estimate for β is a number, while an estimate for Λ is a function. Often, the
computer output does not list the estimate for Λ itself; rather, it lists the corresponding
baseline survival function, 1 −F T |X=0(t) = e−Λ(t). Figure 7.6 shows an example.
0
1
2
3
4
5
6
7
0.0
0.2
0.4
0.6
0.8
1.0
Figure 7.6. Estimate of the baseline survival function in the Cox model λT |X=x(t) = eβxλ(t)
based on 50 observations, generated using the Weibull baseline hazard λ, a one-dimensional
predictor variable x from the uniform distribution on [−5, 5], and the parameter β = −0.3. The
dashed curve is the true baseline survival function 1 −F T |X=0(t) = e−Λ(t).
7.6.2 Tests and Conﬁdence Intervals
Suppose that we want to test the null hypothesis H0: β = β0 against the alternative
H1: β = β0. We can use the likelihood ratio test. In the numerator of this test, the
likelihood is maximized over the full parameter space. In the denominator,on the other
hand, the maximization is restricted to the smaller parameter space with β = β0. In
293

7: Regression Models
the previous subsection, we gave an (adapted) likelihood function of the general Cox
model for survival analysis:
(β, Λ) →
n

i=1
eβXiΔΛ(Ti)e−eβXi Λ(Ti)
n

j=1
pX(Xj).
The factor n
j=1 pX(Xj) occurs in both the numerator and the denominator of the
likelihood ratio statistic. If the distribution pX does not depend on the parameter
(β, λ), then the products in the numerator and denominator cancel each other out.
Hence, it again suﬃces to maximize the function
L(β, λ; T1, X1, . . . , Tn, Xn) =
n

i=1
eβXiΔΛ(Ti)e−eβXi Λ(Ti).
with respect to (β, λ) under H0 and under H1.
The likelihood function given above is an example of a "semiparametric
likelihood function" because the parameter Λ does not vary over a ﬁnite-dimensional
space, but over a function space. We can, however, show that the likelihood ratio
statistic for testing H0: β = β0 asymptotically has a chi-square distribution with one
degree of freedom. If β is multidimensional, then the number of degrees of freedom
of the chi-square distribution is equal to the dimension of β. The proﬁle likelihood can
therefore be used to construct a conﬁdence interval for β in exactly the same way as
for parametric models, that is, models in which all parameters are ﬁnite-dimensional.
Although there does not exist an analytic expression for the maximum likelihood
estimator ˆβ, we can compute the proﬁle likelihood exactly (see Section 5.6). We ﬁrst
verify that for ﬁxed β, the likelihood Λ →L(β, Λ; T1, X1, . . . , Tn, Xn) is maximized
by a function Λ that has jumps at every one of the points Ti and is constant on each of
the intervals [T(i−1), T(i)), where T(i) is the ith order statistic. Given the jump sizes
λi = ΔΛ(Ti), the likelihood function is given by
(β, λ1, . . . , λn) →
n

i=1
eβXiλie
−eβXi 
j:Tj ≤Ti λj.
We can maximize this expression with respect to (λ1, . . . , λn) in [0, ∞)n in the usual
way, by ﬁrst taking the logarithm and then setting the partial derivatives with respect
to λi equal to 0. We can write the resulting likelihood equations in the form
1
λi
=

k:Tk≥Ti
eβXk.
The proﬁle likelihood is obtained by substituting these values in the likelihood
and is therefore equal to
L1(β; T1, X1, . . . , Tn, Xn) = sup
Λ
L(β, Λ; T1, X1, . . . , Tn, Xn)
=
n

i=1
eβXi

j:Tj≥Ti eβXj e−1.
294

7.7: Mixed Models
This expression follows from
n

i=1
e
−eβXi 
j:Tj ≤Ti λj = e
−n
i=1

j:Tj ≤Ti eβXi λj
= e
−n
j=1

i:Ti≥Tj eβXi λj =
n

j=1
e−1,
where the last equality follows by substituting the expression for λj.
We can maximize the proﬁle likelihood with respect to β using a numeric
algorithm, to determine the maximum likelihood estimator ˆβ. The values β for which
the logarithm of the proﬁle likelihood is closer than 1
2χ2
1,1−α0 to the maximum value
of the logarithm of the proﬁle likelihood form a conﬁdence region for β of size
approximately 1 −α0.
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
−750
−700
−650
−600
−550
−500
−450
Figure 7.7. Three realizations of the log-proﬁle likelihood for β for the Cox model λT |X=x(t) =
eβxλ(t) based on 100 observations, generated using the standard Weibull baseline hazard λ, the
one-dimensional predictor variable x generated from the uniform distribution on [−5, 5], and the
true parameter β = −0.3.
7.7 Mixed Models
A mixed model can be viewed as a regression model in which some of the parameters
have been replaced by random variables, called random eﬀects. Such a model is useful
to model dependence between the observations or heterogeneities in the data.
In the linear mixed model, the observation is a vector Y
= (Y1, . . ., Yn)T
satisfying
(7.13)
Y = Xβ + Zγ + e.
295

7: Regression Models
Here, X and Z are known (n × p)- and (n × q)-matrices, β ∈Rp is an unknown
parameter vector, and γ and e are Gaussian random vectors in Rq and Rn, respectively.
The vector e is an error vector with the same interpretation as in the multivariate linear
regression model (7.3) and is usually modeled as having i.i.d. coordinates e1, . . ., en
with mean 0. The vector Xβ is also borrowed from the linear regression model. The
novelty is the vector Zγ, which is random and typically creates dependencies between
the Y1, . . ., Yn. As the error vector e, the vector of random eﬀects γ is not observed.
We can view this vector as a device to describe the distribution of the observation
Y through the structural equation (7.13) or as a way to model real world variation
between observational units at a deeper level. Such an unobserved random vector is
also called a latent variable.
Example 7.10 Variance components
In the ANOVA model (7.8), the parameters αi, βj and γij model the eﬀects of factors
that inﬂuence the outcomes Yijk. When measured at factor levels i and j, the deviation
of the mean value of Yijk from the overall average is given by αi +βj +γij. It may be
that the levels of these factors can be considered a sample from a bigger set of possible
levels, and interest is in generalizing the conclusions to this bigger population. Then,
it makes sense to model one or both factors as random variables.
As an example, suppose that an experiment to measure the eﬀect αi of a factor
is carried out in a number of diﬀerent laboratories. Care has been taken to align the
experimental procedures, but it is suspected that the measurements are still dependent
on the laboratories. We can model this by the ANOVA model (7.8), with βj referring
to the jth laboratory, but we are not particularly interested in the laboratories and view
the laboratories that participate in the experiment as exchangeable with other ones.
Then, we might model the βj, which describe the main eﬀects of the laboratories, as a
sample from a distribution. If we stick to the αi as parameters, we then have a mixed
eﬀects model, with ﬁxed eﬀects αi and random eﬀects βj. If we include interaction
eﬀects γij, then naturally these will also be modeled as random eﬀects.
In the general notation (7.13), the vector β now corresponds to the vector of
parameters μ and αi, and the vector γ to the vector of all βj and all γij. Once the
variables Yijk are ordered as coordinates of a vector, the matrices X and Z can be
determined so that (7.13) is valid.
Example 7.11 Repeated measures
Mixed models are frequently used when experimental units are measured more than
once, such as in longitudinal analysis, where subjects are followed over time. If there
is variation between the units, then an ordinary regression model is inappropriate
because this models all observations as independent, while measurements on the same
subject are clearly related. Random eﬀects can be used to model the dependence.
Repeated measurements were also discussed in Example 3.45 on generalized
estimated equations. We can view the present random eﬀects as a way to model the
error vector (ei,t) in the GEE model structurally through the vector Zγ + e.
296

7.7: Mixed Models
We consider one concrete example as illustration. Suppose that we follow S
subjects, indexed s = 1, . . . , S, over time, and measure each subject at times t =
1, . . . , T. The observational vector Y can then best be described by two indices, for
subject and time, and be partitioned in blocks as (Y1,1, . . . , Y1,T , Y2,1, . . . , Y2,T , . . . ,
YS,1, . . . , YS,T)T , where Ys,1, . . ., Ys,T are the consecutive measurements on indivi-
dual s. A simple model would be
Ys,t = β0 + β1t + γs,0 + γs,1t + es,t,
where es,t are i.i.d. univariate normal variables. The idea of this model is that every
individual s follows a linear model in time t, but the intercept and slopes vary over
the individuals: for individual s these are β0 + γs,0 and β1 + γs,1. The parameters
β0 and β1 are the "population intercept and slope," while the parameters γs,0 and
γs,1 are the deviations of individual s from the average. If the data consists of
measurements on individuals sampled from some population, then it makes sense
to think of the pairs (γs,0, γs,1) as a sample from a distribution. The vector γ =
(γ1,0, γ1,1, . . ., γS,0, γS,1)T is then also random.
We deﬁne the parameter β = (β0, β1)T by collecting the two ﬁxed eﬀects
parameters. The model can next be written in matrix form (7.13) by deﬁning the
appropriate matrices X and Z, so that the equations in the preceding display are
valid. Since the pairs (γ1,0, γ1,1), . . . , (γS,0, γS,1) correspond to diﬀerent individuals,
it is natural to restrict the covariance matrix Λ of γ to matrices with block structure,
expressing the independence of these S pairs. For identically distributed pairs this
gives 3 free parameters. Together with the parameters β0, β1, and σ2, the model then
has 6 free parameters.
If the random eﬀects and error vectors are distributed as γ ∼Nq(0, σ2Λ) and e ∼
Nn(0, σ2I), then the observation Y in (7.13) possesses an Nn

Xβ, σ2ZΛZT +σ2I

-
distribution, where I is the (n× n)-identity matrix. The parameter value is (β, σ2, Λ),
where β ∈Rp, σ2 > 0, and Λ is a positive-deﬁnite matrix, which is usually restricted
to a subset of such matrices through further speciﬁcation of the model. The likelihood
function is given by the multivariate normal density, and its logarithm is, up to a
constant, equal to
(β, σ2, Λ) →−n log σ −1
2 log det(ZΛZT + I)
−
1
2σ2 (Y −Xβ)T (ZΛZT + I)−1(Y −Xβ).
This may be maximized with respect to the parameter to ﬁnd the maximum likelihood
estimator, and likelihood ratio tests or conﬁdence sets can be obtained as usual.
A diﬃculty is that many situations lack an analytic expression for the maximum
likelihood estimator. A numerical routine, such as Fisher scoring, is necessary to
approximate the solution. The presence of the matrices Λ can make this nontrivial,
but several packages are available.
297

7: Regression Models
It turns out that the maximum likelihood estimators are somewhat biased,
similarly to how the maximum likelihood estimator of the variance σ2 in an ordinary
regression model is biased. This is often solved by restricted maximum likelihood
estimation or REML, which separates the estimation of the parameter β from the
estimation of the variances. The idea is to remove the parameter β from the model
by premultiplying the equation (7.13) by a matrix P whose rows are orthogonal
to the column space of X, so that PX = 0. Then, the distribution of PY
∼
N(0, σ2PZΛZTP T + σ2PP T ) is free of β and is used to estimate (σ2, Λ). This
removes the bias resulting from the "loss of degrees of freedom" by estimating the
parameter β. In a second step, the parameter β is estimated using the conditional
likelihood of Y given PY , in which the unknown parameters (σ2, Λ) are ﬁxed at the
estimates from the ﬁrst step (which depend on PY only). A "maximal" matrix P with
the desired properties is given by the orthogonal projection P = I −X(XTX)−1XT
onto the orthocomplement of the range of X.
Because the random eﬀects γ can be viewed as "random parameters," a Bayesian
description of the model is natural. The distribution of γ is then equated to a prior
distribution on these parameters. Indeed, the general Bayesian framework makes little
diﬀerence between latent variables and parameters, and even data is special only in
that it is observed, all quantities of interest being random. This is in contrast to the
non-Bayesian view, which considers the parameter (β, σ2, Λ) as unknown but having
a true value independent of the statistician, whereas the latent vector γ is truly random.
Bayesian methods for mixed models are typically also of a numerical nature, but
several standard software solutions are available (e.g. MCMC). One advantage oﬀered
by the Bayesian setup is that we can speak of the posterior distribution of the random
eﬀects γ given the data Y , which is an ordinary conditional distribution, given by
Bayes's rule. Non-Bayesians often also like to reconstruct the random eﬀects from the
data, but as these are random this does not ﬁt naturally in the framework of "parameter
estimation."
Just as the linear regression model, other models can be similarly augmented with
random eﬀects. For instance, the logistic regression model (7.12) can be augmented
to
P(Y = 1| X = x, Z = z, γ) =
1
1 + e
−m
j=1 βjxj−k
j=1 γjzj .
As the random eﬀects γ are not observed, the distribution of Y that is relevant for
forming a likelihood is its marginal distribution. This is obtained by multiplying the
probability in the display by the marginal density of γ, which could be multivariate
Gaussian, and then integrating over γ. A diﬀerence with the linear mixed model is
that this cannot be achieved analytically, and hence implementation of general linear
mixed models requires advanced numerical routines.
A Cox model that is augmented with a random eﬀect is known as a frailty model.
In a survival setting, the random eﬀect then often models an unmeasured risk factor
for death, which explains the name "frailty."
298

7.8: Summary
7.8 Summary
For a given dependent variable Y and predictor variables x1, . . . , xp, the relations
among the dependent and predictor variables can be described in a regression model.
Here is an overview of common regression models:
• In a linear regression model, we assume that Y is a continuous random variable.
The relation between Y and (x1, . . . , xp) is given by
Y = β0 + β1x1 + . . . + βpxp + e,
a linear function of the unknown regression parameters β0, . . . , βp, with e a
normally distributed error term with expectation 0 and unknown variance σ2.
• In analysis of variance, the dependent variable Y is continuous, and the predictor
variables ("factors") are categorical. In a model with two factors with interactions,
the relation is modeled as
Yij = μ + αi + βj + γij + e,
where Yij is the dependent variable for the categories i and j, respectively, of the
two factors, μ is the grand mean, αi and βj are the unknown main eﬀects of the two
factors, γij is the unknown interaction between the two factors, and e is a normally
distributed error term with expectation 0 and unknown variance σ2.
• In a nonlinear model, we have
Y = fθ(x) + e,
where fθ is a nonlinear function in θ and e is an error term, which is often assumed
to be normally distributed with expectation 0 and unknown variance σ2.
• In a logistic regression model, the dependent variable Y is binary, so that we are
dealing with a classiﬁcation problem. The relation between Y and the vector x =
(x1, . . . , xp) is given by
P(Y = 1|X = x) =
1
1 + e
−p
j=1 βjxj .
• In a Cox regression model, the dependent variable is the time up to a certain event
and is often denoted by T instead of Y . The relation between T and the predictor
vector x = (x1, . . . , xp) is described using the hazard function
λT |x(t) =
f T |x(t)
1 −F T |x(t) = e
p
j=1 βjxjλ(t),
with λ the hazard function for the individual or object with x1 = . . . = xp = 0,
which is completely unknown.
There exist diﬀerent methods to estimate or test the unknown parameters in the models
described above.
299

7: Regression Models
Exercises
1. We want to research whether there is a correlation between the average grade for the ﬁnal
exams of the last year of high school (on a scale from 1 to 10) and the duration of university
studies (in months). We have the following data, which refer to a sample under students
working toward (the equivalent of) a master's degree in mathematics who arrived at the
University of Amsterdam in 1970.
grade
8
7
7
7
7.5
7
6.5
9
7
9
8
7.5
duration
82
80
66
77
79
75
58
46
58
56
70
55
(i) Determine estimates for the regression coeﬃcients in the linear regression model using
the method of least squares.
(ii) Compute the explained variance.
(iii) Make a graph showing the observations and the ﬁtted straight line.
2. We want to include the predictor variable "education" in a regression model. There are three
categories: low, middle, high. We include the variable X in the model as follows. We deﬁne
X = 1 if the person is low skilled, X = 2 if the person has an average education level,
and X = 3 if the person is highly educated. Is this a good choice, or would you choose
diﬀerently? Why?
3. Consider the simple linear regression model. Based on observations Y1, . . . , Yn and
x1, . . . , xn, we want to predict the expected value of Y corresponding to a given x. Determine
an unbiased estimator for this value.
4. Consider the linear regression model of Section 7.2.
(i) Show that the estimators for the regression coeﬃcients are linear combinations ˆα =

μiYi and ˆβ = 
λiYi of the observations.
(ii) Show that ˆα and ˆβ are unbiased estimators for α and β.
(iii) Show that MSE(α, β, σ2; ˆα) = σ2/n + x2σ2/
(n −1)s2
x

.
(iv) Show that MSE(α, β, σ2; ˆβ) = σ2/
(n −1)s2
x

.
(v) Suppose that the values x1, . . . , xn can be ﬁxed by the researcher within a given interval
[a, b]. What is the optimal choice to obtain the best estimate of β?
(vi) Is there a practical reason not to make this optimal choice?
5. Consider the simple linear regression model, but suppose that we know beforehand that
α = 0.
(i) Determine the least-squares estimator for β.
(ii) Is this estimator unbiased?
(iii) Determine the variance of this estimator.
(iv) Suppose that the values x1, . . . , xn can be ﬁxed by the researcher within a given interval
[0, b]. What is the optimal choice to obtain the best estimate of β?
(v) Is there a practical reason not to make this optimal choice?
6. Consider the simple regression model Yi = α + βxi + ei, where α and β are unknown
parameters, x1, . . . , xn are known constants, and e1, . . . , en are independent, normally
distributed with Eei = 0 and Ee2
i = ziσ2 for known positive numbers z1, . . . , zn. Such a
model with errors of diﬀerent levels of accuracy is called heteroscedastic. Determine the
maximum likelihood estimators for α and β.
300

7: Exercises
7. Consider the simple linear regression model of Section 7.2.
(i) Find a suﬃcient vector for (α, β, σ2) that is as small as possible.
(ii) Show that this model forms an exponential family.
(iii) Show that the least-squares estimators ˆα and ˆβ are UMVU.
(vi) Find a UMVU estimator for σ2.
8. Suppose that we want to determine the gravitational constant using a pendulum test. We
attach a massive ball to a thin cord. We then swing the ball and measure the period of
oscillation. The period of oscillation is the time it takes the ball to make one complete
cycle. If the amplitude of the ball is not too great, then the period of oscillation is constant
and therefore independent of the amplitude. By Newton's second law of motion, we have
T = 2π
√
l/√g, where T (in s) is the period of oscillation, g (in m/s2) is the gravitational
constant, and l (in m) is the length of the cord. We assume that in our set-up, Newton's
second law holds. We carry out the pendulum test n times with cord lengths l1, . . . , ln.
This gives observations (l1, T1), . . . , (ln, Tn). We make small measurement errors, so that the
measurements do not follow Newton's second law exactly, but only approximately.
(i) Describe a suitable simple linear regression model.
(ii) Determine the least-squares estimator for the gravitational constant g.
(iii) Determine the variance of the least-squares estimator for the regression parameter
2π/√g that represents the slope.
(iv) How would you choose the cord lengths in the experiment to minimize the variance in
question (iii)?
(v) Explain (or compute) how you would choose the cord lengths in the experiment to
minimize the variance of the least-squares estimator for the gravitational constant.
9. In a study on the inﬂuence of caﬀeine on memory, 18 students are asked to study a book for
8 hours. Every hour they have a break and are given coﬀee with little, an average amount of,
or much caﬀeine. The coﬀee is sweetened with only sugar, half sugar and half sweetener, or
only sweetener. Other food or drinks are not allowed. In all, there are 3 × 3 possible drinks.
Two students are arbitrarily chosen for each combination, which they then get during each
break. After 8 hours of study, the students are given a test with 100 questions on the material
they have studied. The numbers of wrong answers are registered.
little
average
much
only sugar
12 10
7 12
19 21
half sugar, half sweetener
6 3
10 16
21 29
only sweetener
15 12
8 6
24 13
Table 7.3. Number of wrong answers made by the students. Per combination of amount of
caﬀeine and type of sweetener, the numbers of mistakes made by two students have been
registered.
(i) To begin simply, we ﬁrst disregard the factor "sugar/sweetener" and the interaction
term with caﬀeine in the model. Set up a suitable analysis of variance model.
(ii) Test whether the amount of caﬀeine in the coﬀee inﬂuences the number of wrong
answers. Give the null and alternative hypotheses, the test statistic, and the p-value.
What is your conclusion?
(iii) Now, consider the full model, including interaction terms, and model this. Again, test
whether the amount of caﬀeine in the coﬀee inﬂuences the number of wrong answers.
What is your conclusion?
301

7: Regression Models
(iv) Would you still use this model if the students could themselves choose how much sugar
they want in their coﬀee?
10. A farmer wants to study which combination of wheat species (2 species), fertilizer (3 types),
and method of irrigation (2 methods) produces the highest yield. Describe an experiment to
study this, and give the corresponding analysis of variance model with the yield as dependent
variable.
11. Suppose that the probability of contracting disease Z is inﬂuenced by a single gene. Suppose,
moreover, that the gene is biallelic with alleles A1 and A2. A person can then have genotype
(A1, A1), (A1, A2), or (A2, A2). The variables blood pressure and gender also inﬂuence the
probability of contracting disease Z. We have observed the occurrence of the disease,
genotype, gender, and blood pressure of 100 individuals.
(i) Suppose that A2 is dominant over A1, which means that if we disregard the other
factors, then a person with genotype (A1, A2) has the same risk of contracting disease
Z as a person with genotype (A2, A2). Describe a suitable logistic regression model for
the data.
(ii) Suppose that a person with genotype (A1, A2) has a smaller risk of contracting disease
Z than a person with genotype (A1, A1), but a greater risk than someone with genotype
(A2, A2). Describe a suitable logistic regression model.
12. Obese people who are put on a diet exhibit an exponential decrease of their adipose tissue
during the period of the diet. To study how long someone should be put on a speciﬁc diet, the
weight loss of n subjects is measured daily for a month while they follow the diet. Formulate
a suitable statistical model for the weight loss. (Several models are possible!)
13. People with heart valve disease often get a new heart valve. There are two types of
replacement heart valves: biological and mechanical. In a study on the life span of the
biological valve, n patients are followed from their operation until the valve fails. We suspect
that the age, weight, and gender of the patient inﬂuence the life span of the valve. Formulate
a suitable statistical model to investigate whether mechanical heart valves last longer or
shorter than biological heart valves.
14. Suppose that the random variable T has probability density f and hazard function λ. Show
that f(t) = λ(t)e−Λ(t).
15. Show that the hazard function of a random variable X is constant if and only if X has an
exponential distribution.
16. In a study carried out to compare two new methods for teaching arithmetic, 30 schools are
divided arbitrarily into two groups. Each group is assigned one method. After two years,
all students at the 30 schools are given an arithmetic test (adapted to the age of the child).
Formulate a suitable model to study whether there is a correlation between the method that
is used and the test scores.
17. A researcher studies the eﬀect of exercise on the BMI of overweight children. In all, 25
children participate in the study. These children do cardio workouts every week and are
weighed monthly. Formulate a suitable model to estimate the eﬀect of working out.
302

REGRESSION MODELS AND CAUSALITY
Regression models quantify the correlation between an output variable Y and an input
variable X and can be used to predict Y from X. Sometimes we would also like to
use the regression model to "explain" Y from X. We speak of a causal explanation
when X can be seen as a cause of Y . A change in the value of X is then necessarily
followed by a change in Y ; the size of the change is determined by the regression
model.
Certainly not all regression models may be interpreted in a causal sense. The
"price of a house" can, for example, be predicted in part from the income of the
residents of the neighborhood; however, "income" is certainly not a cause for the
price. Likewise, the "interest rates in the last few weeks" cannot be seen as cause
for the "interest rates tomorrow," although the historical interest rates can certainly
be used for predictions. On the other hand, we can probably view "temperature" as
a cause for the "speed of a chemical reaction." Suppose that we use regression to
explain "number of days unemployed" from, among other things, "highest level of
education," where the regression coeﬃcient turns out to be negative. Does this mean
that a higher level of education is a cause for a shorter unemployment period?
The concept of causality belongs to philosophy rather than statistics, but it is
of great signiﬁcance for the interpretation of regression models. If we only want
to use the regression model to predict Y based on an x observed under the same
conditions as the data on which the regression model was ﬁt, then causality is not very
important. It is diﬀerent if we want to use the outcomes of a regression analysis for
an "intervention." If a higher level of education does lead to a shorter unemployment
period, then it makes sense socio-economically to oﬀer people more training since this
must lead to lower unemployment. Causality can, in general, be studied this way by
looking at the eﬀects of an intervention. Suppose that we could change the x-value of
an object while keeping the other relevant factors equal, does substituting the new x-
value in the regression model give a correct prediction for the Y -value of the object?
If this is the case, then it is justiﬁed to view X as a cause for Y .
In addition to the practical situation, the possibility of a causal interpretation
greatly depends on the way the data are collected. Suppose, for example, that we want
to know whether schools outside the Randstad (megalopolis in the Netherlands) oﬀer
better education than schools inside the Randstad. To study this, we take a sample
from pupils in Group 8, the ﬁnal year of elementary school (6th grade), in the Dutch
population and compare the average CITO exam scores of the students at schools
in the four large cities in the Randstad with the average score of pupils at schools
outside these cities.‡ We observe a small diﬀerence (see the ﬁrst column in Table 7.3).
A causal explanation of the observed diﬀerence from a diﬀerence in the quality of
education between schools in and outside the Randstad seems logical but is certainly
not justiﬁable. It is, for instance, quite conceivable that pupils at schools in and outside
‡ The CITO exam is a national exam used to help decide which type of secondary school a
child is admitted to (there are three types, preparing for a vocational, polytechnic, or university
education). The score is an integer between 500 and 550.
303

7: Regression Models
the Randstad are not comparable and that other diﬀerences are responsible for the
measured diﬀerence in CITO scores. Children at schools outside the Randstad may,
for example, more often have highly-educated and/or Dutch-speaking parents than
those in the Randstad. To rule out the inﬂuence of such confounding factors, we should
set up a randomized trial: we randomly select a group of four-year-old children from
the population and then determine by a randomized test to which school each child
will go. (In the Netherlands, the choice of school is not determined by the location of
your family residence.) In that case, the two groups of children would be comparable,
and a possible diﬀerence in CITO scores could reasonably only be explained by the
quality of the education. Unfortunately, we cannot carry out such an experiment. Our
data will necessarily be observational data: the location of the school is determined
by factors outside of our control, and we take a sample from the population as it has
formed without our interference. In this type of observational studies, we are thus
dealing with unintended (and statistically undesirable) selection.
Although a causal interpretation based on an observed correlation between
CITO score and location is incorrect within our observational context, the estimated
regression model can have a predictive value. Suppose that the correlation, quantiﬁed
by the regression model, is indeed present. We must see the predictive values as
follows: If we were to select a new pupil in the same way as our original sample,
then the regression model gives a reasonable prediction of their CITO score. If, on the
other hand, as an intervention, we were to close the schools whose pupils score low
(in or outside the Randstad), then there is no guarantee at all that the school results
will improve in general.
The realization that other factors, such as the level of education and ethnic
background of the parents, could explain the measured diﬀerence in CITO scores
motivates us to try to correct ("control") for these results in our analysis. Indeed,
eﬀects observed in an overall analysis can disappear or even reverse in an analysis
on subgroups. This remarkable fact is known as Simpson's paradox. Consider, for
example, Table 7.3, which gives the average scores on CITO exams for pupils in Group
8 in 2005, split into 7 strata determined by the proportion of pupils of non-Dutch
background, for all of the Netherlands (ﬁrst row) and only for the four largest cities
(second row). According to the table, the pupils in the large cities obtain a score that is
on average 2.3 points lower (ﬁrst column). If we look in the diﬀerent strata, however,
we see that they are on average better and at most 1.4 point worse (in stratum 4). Is
there an error in the table? Not at all. The somewhat surprising result is a consequence
of the fact that in large cities, there are many more children from the higher strata
7, 6, . . . , which clearly have a lower average score. The grand mean is a weighted
mean of the 7 scores, weighted according to the number of children per stratum. The
grand mean in the large cities is therefore lower than the national average. A naive
statistician would conclude from the lower grand mean in the large cities that the
education in those cities is worse than in other schools in the country. However, the
stratiﬁcation rather suggests the opposite. But this stratiﬁcation only partially solves
the problem of observational data. There may be other factors involved that are not
taken into account in the table. We cannot defend a causal explanation until we have
304

7: Regression Models and Causality
mean
1
2
3
4
5
6
7
national
534.5
537.5
536.0
534.0
531.8
532.1
529.6
528.4
C4
532.2
541.0
537.3
534.0
530.4
531.4
529.6
528.5
Table 7.3. Final CITO exam for pupils in Group 8 in 2005. The column "mean" gives the grand
mean. The columns 1 through 7 gives the average scores for schools with an increasing proportion
of non-Dutch background. The rows "national" and "C4" gives the scores in, respectively, the
whole country and the four large cities.
a better understanding of this situation, and perhaps not at all.
To correct for alternative explanations, we often set up a regression model
including possible "confounding variables." In our example, for example, we carry
out a regression of the CITO score Y on a vector (X, Z) = (X, Z1, . . . , Zk) in which
X is "school location," Z1 is "educational level parents," Z2 is "living conditions,"
etc. The regression equation is then E(Y |X = x, Z = z) = f(x, z). This is a step in
the right direction but is certainly not yet the solution to all problems. First, we have
the question of how the function f should look, that is, how the diﬀerent variables
Zi should be included in the regression equations: additively? with interactions? etc.
Second, it is not clear that the problem with observational data is solved using this
approach.
There exist many tools for the ﬁrst problem (setting up a correct regression
model), including some discussed in this chapter. We assume that we have a well-
ﬁtting model. We can sharpen the second problem (observational data) by introducing
so-called counterfactual variables. Every person can, in principle, go to school in
("0") or outside ("1") the Randstad. In practice, only one of the two possibilities can
be realized, but let us denote by Y0 and Y1 the CITO scores that would be obtained by
using the locations "0" and "1", respectively. The school choice itself will be encoded
in the variable X, and possible confounding variables are encoded in the vector Z.
The observed CITO score Y is
Y =
 Y0
if X = 0,
Y1
if X = 1.
We want to answer the question whether the location has a causal eﬀect on the CITO
score. In the previous notation, the eﬀect of location "1" instead of "0" can be
measured by the diﬀerence Y1 −Y0. Of the pair (Y0, Y1), we always observe only one,
namely the variable realized in Y . In this sense, the pair (Y0, Y1) is "counterfactual"
and seems useless for solving the problem.
The counterfactual variables, however, supply a useful framework, provided that
we assume more structure. We ﬁrst consider the simple case where we assume that
every person is randomly assigned to one of the locations, as in a randomized study.
In terms of the counterfactual variables, this corresponds to the assumption that the
location indicator X is independent of the pair (Y0, Y1). For every individual, at birth
two possible outcomes are available, Y0 and Y1, and a randomized test ("generate
X") determines which of the two is realized: Y0 if X = 0 and Y1 if X = 1. The
expectation of Yi is then also independent of the location: at birth, there exists an
expectation of the CITO score for both locations, independently of which location will
305

7: Regression Models
be chosen. (This assumption is not realistic because there are confounding factors Z
that inﬂuence both the choice of location and the height of the CITO score, but the
computations for this simple case serve as a basis for the computations in which we
correct for the information in Z.)
For the simple case, we have
(7.14)
EYi = E(Yi| X = i) = E(Y | X = i),
i = 0, 1,
where we use the independence for the ﬁrst equality and the correlation between Y
and Y0, Y1, X for the second. The expected location eﬀect EY1 −EY0 is therefore
given by
(7.15)
EY1 −EY0 = E(Y | X = 1) −E(Y | X = 0).
This can be estimated from the data by (for example) subtracting the average CITO
score of pupils at location "0" from the average CITO score of pupils at location
"1". This estimate is only correct if the experiment is randomized, without inﬂuence
of confounding variables. It is clear that we cannot carry out such an experiment
concerning school choice ourselves, and it is unrealistic to hope that the "natural life"
would orchestrate such an experiment itself. To correct for the confounding variables
in Z, we can again use the idea of subgroups. The subgroups are determined by equal
values of the vector Z. If Z contains all relevant background information for the
outcome of the CITO score and the school choice, then it is reasonable to assume that
given Z, the variable X is independent of (Y0, Y1). Conditioning on Z corresponds
to making the independence assumption for each subgroup. Suppose that the only
variable in Z is the level of education of the parents. Then this assumption means
that within a level of education, the school indicator X is independent of the vector
(Y0, Y1). In other words, within the group with same level of education, at birth one
has two possible outcomes Y0 and Y1, and the randomized test ("generate X") again
determines which of the two outcomes is realized. Both Yi and the randomization
X depend on the level of education of the parents, but within the subgroups, this
inﬂuence is the same for all individuals. When Z contains all relevant background
information, the independence assumption should hold; the variation in CITO scores
between individuals with a ﬁxed value of Z is then based on "irrelevant" factors,
and must be the product of "background noise". Let us assume that we have found a
suitable Z. The equation (7.14) no longer holds because it is based on the assumption
of unconditional independence (the case where Z is empty). Instead, we have
(7.16)
EYi =

E(Yi| Z = z) pZ(z) dz =

E(Yi| X = i, Z = z) pZ(z) dz
=

E(Y | X = i, Z = z) pZ(z) dz.
306

7: Regression Models and Causality
The ﬁrst equality is the general expression of an expectation in conditional expec-
tations (with pZ the marginal density of Z); for the second equality, we use the
assumption of conditional independence of (Y0, Y1) and X given Z, and for the third
we use the correlation between Y and Y0, Y1, X. The average school eﬀect is therefore
given by
(7.17)
EY1 −EY0 =
 
E(Y | X = 1, Z = z) −E(Y | X = 0, Z = z)

pZ(z) dz.
A ﬁrst conclusion is that this eﬀect can, in principle, be estimated from the
observed data (Y, X, Z): although we have unobservable "counterfactual" variables
Y0, Y1 on the left-hand side, the expressions on the right-hand side concern only
observable data. A second conclusion is that the expression in (7.15) for the causal
eﬀect EY1−EY0 no longer holds. We assumed that we had a randomized trial in which
the average CITO scores of pupils at school locations "1" and "0" were compared. In
the current subgroup analysis, the expected average CITO scores per school location
are of the form
E(Y | X = i) =

E(Y | X = i, Z = z)pZ|X(z| i) dz.
If X and Z are independent, then pZ|X = pZ, and this reduces to the last expression
in (7.16). In that case (for example, if Z is empty), the two expressions for the causal
eﬀect are equal. If X and Z are not independent, then in general the two expressions
in (7.15) and (7.17) are not equal.
The diﬀerence between the ﬁrst and second analyses is only the conditioning on
the vector Z. In fact, the second analysis is exactly equal to the ﬁrst on every one of
the subgroups deﬁned by a ﬁxed value of Z, after which the estimated eﬀects in (7.17)
are averaged over the subgroups, weighted with the marginal density pZ of Z. The
estimated eﬀect E(Y | X = 1, Z) −E(Y | X = 0, Z) in the subgroups is given by a
joint regression model of Y on (X, Z). As long as we have a correct regression model
and a confounding variable Z for which the assumption of conditional independence
of X and (Y0, Y1) is correct, estimating a causal eﬀect is not diﬃcult. Unfortunately,
these assumptions are less innocent than they seem.
We have illustrated the problem of observational data in the context of CITO
scores. The problem of unintentional selection from a population in observational
studies also plays a major role in statistical research into medical treatment.
Medical treatment (for example, the administration of a drug or an operation) is
an intervention, and we would like to give a causal interpretation of the eﬀect. A
regression model based on a sample of treated and untreated persons can, however,
give a wrong impression if the sample does not take other possible predictor variables
into account. For example, if we compare the remaining life span of treated and
untreated patients, but people with a poorer general health had a higher probability of
being treated (for example, because they went to the doctor for another condition and
the doctor performed a general health check), then the results of a regression analysis
will be misleading. Treated persons will live less long, but that is because they are less
healthy in general, not because they received treatment.
307

8 Model Selection
8.1 Introduction
In a regression analysis we try and explain a dependent variable using a number of
independent (predictor) variables. It is often unwise to include all measured predictor
variables in the regression model. Not only can a model with many variables be more
diﬃcult to interpret, but it often also has less predictive value. Model selection is
aimed at ﬁnding the best-ﬁtting model from a given collection of models.
In this chapter, we discuss the most important methods for choosing a suitable
model in a general framework: methods based on tests, penalty methods (including
AIC), the Bayesian approach, and cross-validation. Choosing suitable variables in a
regression model is an important example. Within (nonparametric) estimation theory,
model selection is also applied to ﬁnd a model of a complexity that ﬁts the data.
8.2 Goal of Model Selection
Suppose that for given data X, several statistical models Pd seem reasonable. We
index the models with a parameter d and write the models as Pd = {Pd,θ: θ ∈Θd}.
The dth model Pd thus has parameter space Θd. The index d can, for example, indicate
the number of "free" parameters in the model or the number of indices in a group of
predictor variables; we can then choose between a "large model" (large d) or a "small
model" (small d).
308

8.2: Goal of Model Selection
Every model Pd is a collection of possible probability distributions for X, and,
of course, ∪dPd is also such a collection and therefore also a statistical model. At ﬁrst
glance, the statistical problem is choosing the "best-ﬁtting" probability distribution
from ∪dPd, and we have only complicated the notation by introducing the extra
symbol d. However, the models Pd will generally diﬀer greatly from one another, and
the extra notation allows us to further deﬁne the notion of "best-ﬁt model." Moreover,
the methods to estimate d are of a diﬀerent nature than the previously described
methods.
Example 8.1 Regression
In the multiple regression problem of Chapter 7, a "dependent variable" Y
=
(Y1, . . . , Yn) is modeled as a linear regression on a number of "predictor variables"
xi,j using the equation
Yi =
p

j=1
βjxi,j + ei,
i = 1, . . . , n.
Here, e1, . . . , en are random variables with expectation 0 and ﬁnite variance σ2. The
independent variables xi,1, . . . , xi,p are usually the values of background variables
measured on the ith object, and Yi is a "response" measured on the same object.
Within the context of model selection, it is useful to consider the model as
a speciﬁcation of an outcome Y as a function of input vectors X1, . . . , Xp. To
emphasize this, we can write the displayed equation in vector form,
Y =
p

j=1
βjXj + e = Xβ + e.
Here, the symbols Y and X1, . . . , Xp are vectors of length n whose ith coordinate
refers to the ith object, and e is an error vector. In matrix notation, X is an (n × p)-
matrix with columns X1, . . . , Xp, and β = (β1, . . . , βp)T is the vector of parameters.
In Chapter 7, we discussed how the unknown parameters β1, . . . , βp ("regression
coeﬃcients") can be estimated from the data. In practice, however, there are often
many possible candidates Xj. Does it make sense to involve the postal code in the
equation, in addition to gender, age, and level of education? Do neighborhood or
volume give extra information on the price of a property when included in addition
to surface area, year of building, and subdistrict? Do two speciﬁc genes give a good
description of the genetic component of a disease, or is it wise to involve all 40 000
genes in the regression equation?
309

8: Model Selection
These questions are more complex than they seem. Not only do the questions
relate to very diverse situations, they also have diﬀerent purposes. The question
concerning the price of a property is likely to come from the IRS or a broker, who
is looking for a simple formula to determine a price objectively. The "best ﬁt" is the
model that supplies the best predictions. The question from genetics is probably meant
causally: certain genes will inﬂuence the occurrence of a disease through biochemical
processes, while others will not. If we are only interested in predicting a disease,
it does not matter if we also involve a few genes from the second group in the
regression equation (they may be linked to genes that do have a direct inﬂuence and
therefore have predictive value), but to understand the development of the disease
(causal explanation), it is essential to make a sharp distinction between the two groups
of genes.
As can be seen in the previous example, model selection can focus both on
predicting and on explaining. For predicting, the structure of the model does not
matter. The model may be arbitrarily complicated as long as the predictions are good.
For explaining, we want to include in the model only variables (parameters) that have
a causal relation with the studied outcome. This distinction between predicting and
explaining can be recognized in part in the diﬀerent methods of model selection.
Neither of these objectives focuses on a model that approximates the observed
data as closely as possible. Such a model is usually the most complex type of model,
with the most parameters, which tries to follow every aspect of the data. A good model
abstracts only those elements that are systematic. We say that a model that is too large
overﬁts the given data, with as a result that it does not generalize to new data. We
illustrate this in the following example.
Example 8.2 Overﬁtting
Suppose that we want to describe the data (x1, y1), . . . , (xn, yn) in the plane using a
(d+1)-dimensional regression model y = β0+β1x+β2x2+· · ·+βdxd. If we assume
that the observations (xi, yi) follow this curve up to additive errors with expectation
0, then the least squares method is a reasonable method to estimate the coeﬃcients
β0, . . . , βd.
The dimension d + 1 is the essential parameter of the model. A large value of d
gives more possible regression curves y = β0 + β1x + · · · + βdxd, but also requires
that we estimate more unknown parameters from the available data. Figure 8.1 gives
the least squares curves for d = 1 (the straight line) and d = 10 (the dashed curve,
partially outside the frame of the ﬁgure) based on n = 11 observations. The linear and
11-dimensional ﬁt are extremely diﬀerent. The true regression curve in this simulated
example is the parabola given in the ﬁgure (the solid curve). The straight line is a
better approximation of it than the dashed curve and is therefore preferable.
310

8.2: Goal of Model Selection
The true curve can be given explicitly by a curve of type y = β0+β1x+· · ·+βdxd
with d = 10, by taking β3 = · · · = β10 equal to 0. This model was therefore not
wrong. However, the least squares method did not "know" that the true curve only had
degree 2, and ﬁt a degree 10 curve with nonzero coeﬃcients β3, . . . , β10. This degree
10 curve has an excellent ﬁt with the actual observations (x1, y1), . . . , (x11, y11),
but gives a bad impression of the mechanism according to which these data were
simulated. It "overﬁts" the observed data.
Conversely, the linear model y = β0 + β1x cannot describe the true curve
perfectly but does give a usable approximation.
The diﬀerence in the success of the two models can be understood as a
consequence of a diﬀerent trade-oﬀbetween bias and variance, the two ingredients
of the mean square error. The least-squares estimators for the model with d = 10 are
unbiased, and therefore the prediction ˆβ10
0 + ˆβ10
1 x + · · · + ˆβ10
10x10 is also unbiased.
However, this equation contains 11 estimators, each with a variance (or estimation
inaccuracy). These combine to an unbiased estimator for the regression function with
a large variance. On the other hand, the estimator ˆβ1
0 + ˆβ1
1x is biased, because the
linear model cannot explain the quadratic function, but has a small variance. Of the
two methods, the second works best, though a quadratic model would probably have
been better.
0.0
0.2
0.4
0.6
0.8
1.0
0.8
1.0
1.2
1.4
1.6
Figure 8.1. Regression analysis applied to observations (x1, y1), . . . , (x11, y11) from the model
Yi = (xi −0.25)2 + 1 + ei for a sample e1, . . . , e11 from the N(0, 0.12)-distribution. Plotted are
the parabola y = (x −0.25)2 + 1 and the least squares curve for the linear model y = β0 + β1x and
the polynomial model y = β0 + β1x + · · · + β10x10. The points x1, . . . , x11 were simulated from
the uniform distribution on [0, 1].
311

8: Model Selection
8.3 Test Methods
Hypothesis tests, as described in Chapter 4, can also be used for model selection. In
a linear regression model, for example, we test whether the coeﬃcient of a certain
variable diﬀers signiﬁcantly from 0. If not, then this variable is not included in the
model. More generally, we take a model with many parameters in mind and use tests
to determine whether a certain parameter value diﬀers signiﬁcantly from 0. Next,
insigniﬁcant parameters are set equal to 0 and only signiﬁcant parameters are left
free in the model and estimated from the data.
The relevant tests can be carried out in several ways. To obtain initial insight, one
often tests every parameter separately in the model with only that parameter (and all
other parameters equal to 0). Popular overall methods are the step-down and step-up
methods, which can be applied to every (ﬁnite) parameter set (θi: i ∈I).
The step-down method begins with testing all null hypotheses H0: θi = 0, for
every i ∈I, separately, each time within the model with all parameters θj for j ∈I. If
all null hypotheses are rejected (at a given threshold, for example 5%), then we choose
the model with all parameters. In the other case, the parameter θi with the greatest
p-value is removed, after which we repeat the procedure with the model without this
parameter. (By removing the parameter, the p-values of the null hypotheses H0: θj = 0
for the remaining parameters change; they need to be computed again!) Continuing in
this manner, we remove one parameter at a time, until the p-values for all remaining
parameters are less than the chosen threshold.
The step-up method, on the other hand, begins with the model without parameters
(or the model with only an intercept) and ﬁrst tests the null hypothesis H0: θi = 0
for all parameters separately, within the model with only the parameter θi. If none
of the null hypotheses are rejected, then we choose the model without parameters.
In the other case, we add the parameter with the smallest p-value and then test the
null hypotheses H0: θi = 0 for each of the remaining parameters within the model
consisting of this parameter and the previously chosen ones. If none of the p-values is
less than the threshold, then we choose the model consisting of the previously added
parameters; otherwise, we repeat the procedure.
These two methods can be varied in numerous ways. We can, for example, test
several parameters at a time, alternate step-up and step-down, or vary the thresholds
we use.
One disadvantage of all test methods is that after repeatedly carrying out a test (at
a given level), the overall size is unclear. Another disadvantage is that the ﬁnal model
will depend on the order in which the parameters are tested. In general, the step-up
and step-down methods will not lead to the same model, and certain models will never
be taken into consideration.
The simplicity of the test method is its main merit.
312

8.4: Penalty Methods
8.4 Penalty Methods
The maximum likelihood and least squares methods, and more general estimation
methods that minimize or maximize a criterion function, generally choose the largest
model when several are available. After all, a larger model gives a larger space in
which to optimize the criterion function, and therefore always has a better value for
the criterion. We only obtain a smaller model if the optimum over the larger model
belongs to the smaller model. This appears to be a rather fortuitous situation, so the
naive application of these methods generally leads to overﬁtting.
Adding a penalty to the criterion can correct this. Suppose that we obtain a
suitable parameter for the model Pd = (Pd,θ: θ ∈Θd) by maximizing a criterion
θ →L(θ; X) over Θd. We then determine a suitable parameter and suitable model by
maximizing the function
D × Θd  (d, θ) →L(θ; X) −pen(d)
with respect to θ ∈Θd and d ∈D. The term pen(d) in this expression is the penalty;
its purpose is to decrease the criterion as the model increases in size. This discourages
large models.
The Akaike information criterion (AIC) is one of the best-known model selection
criteria. In the case of the log-likelihood for observing a sample X1, . . . , Xn from a
density pd,θ indexed by a |d|-dimensional parameter, the AIC penalty is equal to the
dimension of the parameter. The best model is thus determined by maximizing
d →log
n

i=1
pd,ˆθd(Xi) −|d|
with respect to d, where |d| is the number of parameters of the model Pd and ˆθd is
the maximum likelihood estimator for the parameter using this model. It is common
practice to multiply this expression by −2 and then deﬁne the AIC penalty as 2|d|, but
this leads to the same optimum.
Example 8.3 Regression
The log-likelihood function for the parameters β1, . . . , βd in the regression model
Y = β1X1 +· · ·+βdXd +e with normally distributed errors e is equal to −n log σ −
Y −β1X1 −· · · −βdXd2/(2σ2), up to a constant. For given σ2, the AIC criterion
is therefore equal to minimizing
(β1, β2, . . . , βd, d) →Y −β1X1 −· · · −βdXd2 + 2σ2d.
The penalty thus increases the sum of squares by 2σ2 times the number of parameters
of the model. The minimum over (β1, . . . , βd) is achieved by the least-squares
estimator, for which the expression is equal to the residual sum of squares plus 2σ2d.
The best model according to AIC is the model for which this sum is minimal.
313

8: Model Selection
Generally, the variance σ2 will be unknown and also estimated from the data. In
that case, the corresponding AIC criterion is equivalent to minimizing
(β1, β2, . . . , βd, σ2, d) →n log σ +
1
2σ2 Y −β1X1 −· · · −βdXd2 + d + 1.
Minimizing for σ2 gives ˆσ2(β1, . . . , βd) = n−1Y −β1X1 −· · · −βdXd2.
Substituting this gives an AIC criterion for only (β1, . . . , βd) equal to the expression
n
2 log
 1
nY −β1X1 −· · · −βdXd2
+ n
2 + d + 1.
The factor 1/n inside the logarithm, the term +n/2, and the +1 in the last term can be
left out. The minimum over (β1, . . . , βd) is achieved by the least-squares estimator.
We substitute these in the equation. AIC chooses the model for which the resulting
value is minimal.
AIC aims at choosing the model that gives the best estimate (or "prediction")
of the density of the observation. The quality is measured by the Kullback-Leibler
divergence between the chosen density pd,ˆθd (where ˆθd is the maximum likelihood
estimator when the model Pd is assumed to be correct) and the true density p. The
Kullback-Leibler divergence is a measure for the diﬀerence between two probability
densities, closely related to the maximum likelihood method, deﬁned as K(p; q) =
Ep(log(p/q)(X)), where Ep means that the quantity X has density p. The relevant
divergence in this case is therefore
(8.1)
K(p; pd,ˆθd) = Ep log
p(X)
pd,θ(X) |θ=ˆθd
.
This divergence depends on the unknown density p and therefore cannot simply be
minimized with respect to the model index d. The probability density in the numerator
of the expression can be avoided, because d →−Ep log pd,θ(X)|θ=ˆθd has the same
point of minimum. We could replace the expectation Ep by an average over a sample
of n observations X1, . . . , Xn from the density p, which leads to the criterion
−1
n
n

i=1
log pd,ˆθd(Xi).
This estimator for −Ep log pd,θ(X)|θ=ˆθd turns out to be biased and systematically
underestimates its estimand. An intuitive explanation is that the same data X1, . . . , Xn
is used twice: ﬁrst, to determine the maximum likelihood estimator ˆθd and then, to
replace the expectation Ep in (8.1) by an empirical mean (a form of overﬁtting).
Akaike made it seem plausible that the bias is approximately equal to n−1 times the
number parameters |d|, which leads to the AIC penalty.
314

8.4: Penalty Methods
Lemma 8.4
Suppose Θd ⊂R|d| and that the function θ →log pd,θ(x) is twice continuously
diﬀerentiable with derivatives ˙d,θ(x) and ¨d,θ(x), and let θd be the point of minimum
of θ →K(p; pd,θ) over θ ∈Θd. Then, under certain regularity conditions, we have
Ep

−1
n
n

i=1
log pd,ˆθd(Xi) +
˜d
n

−

−Ep log pd,ˆθd(X1)

= o(n−1),
for ˜d the trace of the matrix

Ep ˙d,θd ˙T
d,θd(X1)

−Ep¨d,θd(X1)
−1. If p ∈Pd (and
p = pd,θd), then ˜d = |d|.
Proof. (Sketch). Write Pnf and Pf for, respectively, n−1n
i=1f(Xi) and Epf(X1).
By the deﬁnitions of ˆθd and θd, we have Pn ˙d,ˆθd = 0 and P ˙d,θd = 0. Second-order
Taylor expansions about ˆθd and θd, respectively, therefore give
Pn log pd,θd
pd,ˆθd
= 1
2(ˆθd −θd)T Pn¨d,ˆθd(ˆθd −θd) + · · · ,
−P log pd,θd
pd,ˆθd
= 1
2(ˆθd −θd)T P ¨d,θd(ˆθd −θd) + · · · .
On the right-hand side of the ﬁrst equation, we replace Pn by P, as a further
approximation. We then use that, for large n, √n(ˆθd−θd) is approximately distributed
as a multivariate normal vector V with expectation 0 and covariance matrix Σ =
(P ¨d,θd)−1(P ˙d,θd ˙T
d,θd)(P ¨d,θd)−1. (This follows from an extension of Theorem 5.9
to the case where the density p of the data does not belong to the model.) From
EV T AV
= tr(AΣ), we then deduce that the expectations of the two right-hand
sides are asymptotically equal to −˜d/(2n). Finally, we compute the expected values
of the two equations, use EpPn log pd,θd = Ep log pd,θd, and take the sum of the two
equations.
If p = pd,θd, then both matrices P ¨d,θd and −P ˙d,θd ˙T
d,θd reduce to the Fisher
information matrix. The relevant matrix is then the identity, which has trace |d|.
Lemma 8.4 shows that Akaike's correction for the bias is correct only if the
density p of the data belongs to the model Pd (in which case ˜d = |d|). Unfortunately,
the value ˜d depends on the unknown parameter θd and therefore cannot be used as
penalty. (We could replace ˜d by an estimate; this gives the "Takeuchi method.")
A correct expectation of a criterion is no guarantee for good behavior, but the
AIC criterion proves to have good properties. This follows from so-called oracle
inequalities, of the form
EpK(p; p ˆd,ˆθ ˆ
d) ≤C inf
d∈D

K(p; Pd) + |d|
n

.
315

8: Model Selection
Here, ˆd is the index of the model chosen by AIC, and ˆθ ˆd is the maximum likelihood
estimator for the parameter in this model. Furthermore, K(p; Pd) = K(p; pd,θd) is
the Kullback-Leibler divergence between the model Pd and the true density p, and
|d| is the number of parameters in the model Pd. The left-hand side of the inequality
gives the expected Kullback-Leibler distance between the density p ˆd,ˆθ ˆ
d chosen by
AIC and the true density p. This is bounded above (up to a multiplicative constant)
by the minimum over all models Pd of the sum K(p; Pd) + |d|/n of the distance
to the model and the AIC penalty divided by n. The term K(p; Pd) can be viewed
as a necessary, minimal (square) bias when using the model Pd. Every estimator in
this model will have at least this "distance" to the true density p. The term |d|/n can
be viewed as a variance term, or estimation inaccuracy, as a result of estimating |d|
unknown parameters when using the model Pd. Such a variance term is also necessary.
When using the model Pd, we could hope to make an error of order K(p; Pd) +
|d|/n. The inﬁmum over d in the inequality shows that the model chosen by AIC
makes a smaller error than every other model, at least up to a multiplicative constant
C (which must usually be taken greater than 1). AIC therefore works as an "oracle"
that knows the best model.
Without further speciﬁcation of the constant C, the oracle inequality is not very
interesting for a small number of low-dimensional models. After all, the largest model
then has the smallest bias and also gives order 1/n. For models with very diﬀerent
dimensions |d|, however, the inequality suggests a high potential gain for model
selection methods.
For a precise mathematical formulation, we consider the linear regression model
Y = β1X1 +· · ·+βpXp +e = Xβ +e, with models deﬁned by subcollections of the
predictor variables. For d ⊂{1, 2, . . ., p}, deﬁne the model Pd as the linear regression
model Y = 
j∈d βjXj + e with coeﬃcients βd = (βj: j ∈d). The least-squares
estimator in this model is ˆβd = (XT
d Xd)−1XdY , for Xd the matrix with columns Xj
for j ∈d, and the least squares prediction for EY is Xd ˆβd = PdY = PdXβ + Pde,
for Pd the orthogonal projection on the column space of Xd. The mean square error
of this prediction is
EβXd ˆβd −Xβ2 = PdXβ −Xβ2 + EPde2 = PdXβ −Xβ2 + |d|σ2.
The last equality follows from the fact that Pde2/σ2 has a chi-square distribution
with d degrees of freedom. The ﬁrst term on the right-hand side is the square of the
bias of the estimator. Since PdXβ −Xβ ≤Xdβd −Xβ, this term is certainly
equal to 0 if the true coeﬃcients βj for j /∈d are equal to 0. The fact that this is
not known beforehand advocates the use of larger models. However, the second term
|d|σ2 is then large, and it is better to balance the two terms. This is a "bias-variance
trade-oﬀ" in the form of model selection.
AIC is capable of making this "trade-oﬀ."
 Proofs of the following two results can be found in, e.g., L. Birg and P. Massart, Gaussian
model selection. J. Eur. Math. Soc. (2001), no. 3, 203-268; and R. Nishii, Asymptotic properties of
criteria for selection of variables in multiple regression, Ann. Statist. 12 (1984), no. 2, 758-765.
316

8.5: Bayesian Model Selection
Theorem 8.5 AIC
Let Y = β1X1 + · · · + βpXp + e = Xβ + e, with e a vector of independent,
normally distributed errors with expectation 0 and variance σ2. Let ˆd be the model
chosen by AIC from an arbitrary set of models D given by subsets (Xj: j ∈d). Then
the least-squares estimator ˆβd satisﬁes
EβX ˆd ˆβ ˆd −Xβ2 ≤C min
d

Xdβd −Xβ2 + |d|σ2
.
The theorem is restricted to ﬁnitely many models, but AIC can also be applied to
inﬁnitely many models. The regression model y = β0 + β1x + β2x2 + · · · + βdxd + e
from Example 8.2 can, for example, be applied with arbitrary, unknown d ∈N, to
approximate a true model y = f(x) + e as well as possible, where the function f is
not necessarily a polynomial.
The quality of AIC is in the prediction. Somewhat unexpectedly, AIC is not
capable of ﬁnding the right model. In the regression example, this is the model d0
consisting of all regression coeﬃcients βj that are nonzero. For large n, AIC never
chooses a small model; rather, it adds every zero coeﬃcient to the model with positive
probability.
Theorem 8.6 AIC
In the situation of Theorem 8.5, as n →∞, the model ˆd converges in distribution to
a random variable that allocates a positive probability to every element d of the set
{d: d ⊃d0}, where d0 = {j: βj = 0}.
8.5 Bayesian Model Selection
In Bayesian statistics, model selection does not give any conceptual problems. The
additional parameter d is simply given a prior distribution, just like the parameters
in the models. Bayes's rule then gives a posterior distribution for all parameters,
in particular for the model index d. The latter is a vector of "probabilities" of the
diﬀerent models, given the data. Although we could choose the most probable model,
the Bayesian approach does not lead to model selection. Instead, we speak of model
averaging.
317

8: Model Selection
For a more precise description, we denote the prior probabilities of the models
Pd, for d ∈D, by a probability vector (pd: d ∈D) (so 0 ≤pd ≤1 for every d and

d pd = 1). We, moreover, denote by θ →πd(θ) a prior density on the parameter
set Θd, for every d. If the probability density of the data X given (d, θ) is written as
x →pd,θ(x), then Bayes's rule tells us that the conditional density of (d, θ) satisﬁes
(8.2)
π(d, θ| X) ∝pd πd(θ) pd,θ(X).
This depends on both the prior distribution (pd: d ∈D) on the models and the relative
probabilities πd(θ) of the parameters in the dth model. For a small number of models
of not too diﬀerent dimensions, the ﬁrst is often chosen uniformly: pd = 1/#D for
every d. In nonstandard situations, however, the posterior distribution can depend
strongly on the choice. The necessity to choose prior distributions is seen both as a
strength and as a weakness of the Bayesian method, depending on the statistician.
The joint posterior distribution for (d, θ) can be marginalized over θ to give the
posterior distribution of the model index as
(8.3)
π(d| X) ∝

pd πd(θ) pd,θ(X) dθ.
Instead of this full posterior distribution, often only the Bayes factors are reported.
The Bayes factor for the pair of models with indices d1 and d2 is given by
BF(d1, d2) =
 πd1(θ) pd1,θ(x) dθ

πd2(θ) pd2,θ(x) dθ .
When the prior weights of the models are equal (pd1 = pd2), this is exactly the ratio of
the posterior probabilities, also called "posterior odds ratio." More generally, we have
the rule that " the posterior odds are the prior odds times the Bayes factor":
π(d1| X)
π(d2| X) = pd1
pd2
BF(d1, d2).
A value greater than 1 means that model Pd1 has a greater posterior probability than
model Pd2.
Prior probabilities of models can, in particular, be sensitive to the variance of
the prior density. In many cases, we want to choose this large, as an expression
of uncertainty over the parameter (so-called vague prior distribution). To avoid this
sensitivity, the method of the intrinsic Bayes factor proposes to split the data into two
parts. The ﬁrst is used to compute a posterior distribution for every parameter and
the second is used to compute (8.2), where the prior densities πd are replaced by the
posterior distributions from the ﬁrst step.
The following simple example shows that, in practice, Bayesian model selection
is not that simple.
318

8.5: Bayesian Model Selection
Example 8.7 Bayes factors for a vague prior distribution
Suppose that the data X1, . . . , Xn form a sample from either a N(0, 1)-distribution
or a N(θ, 1)-distribution for an unknown θ ∈R. For an N(0, τ 2) prior density on the
parameter θ, the Bayes factor between the two models is equal to

φ(θ/τ)/τ n
i=1φ(Xi −θ) dθ
n
i=1φ(Xi)
=

1
1 + nτ2 e
1
2 nX2/(1+(nτ 2)−1).
For large n and ﬁxed τ this expression has the same order of magnitude as
(τ 2n)−1/2 exp(n 1
2X2). The prior standard deviation τ therefore plays a crucial role.
This is usually not seen as an advantage because τ →∞expresses the full uncertainty
of θ.
An alternative for a normal distribution with large variance is the "uniform
distribution" on R, the distribution with density 1. This is not a probability distribution
(and is therefore called an "improper" prior distribution), but the relevant Bayes factor
is well deﬁned and is equal to
 n
i=1φ(Xi −θ) dθ
n
i=1φ(Xi)
=

2π
n e
1
2 nX2.
As for the normal prior distribution, this is an increasing function of |X|. This is
reasonable, because the choice between the two models in fact comes down to testing
the hypothesis that the expectation θ is 0. The Bayes factor is greater than a certain
value c when √n|Xn| >

log(c2/2π) + log n. For large n, the presence of the term
log n makes the Bayes factor more conservative than the Gauss test, which rejects the
null hypothesis for values greater than quantiles from the standard normal distribution.
Within the context of model selection, this is probably wise. The theory of tests deals
asymmetrically with the two hypotheses, and always works with a ﬁxed type I error,
regardless of the number of observations. On the other hand, the choice of the prior
density equal to 1 is somewhat arbitrary, which also makes the choice of the constant c
arbitrary. Since the "uniform distribution on R" has inﬁnite mass, there is no canonical
normalization, and every other constant is just as logical.
To compute an intrinsic Bayes factor, we could split the data in X1, . . . , Xm and
Xm+1, . . . , Xn, for a given m. The posterior distribution given the data X1, . . . , Xm
and an N(0, τ 2) prior distribution is the normal distribution with expectation νm: =
m/(m+τ −2)Xm and variance τ2
m: = 1/(m+τ−2). We take this as prior distribution
for computing the Bayes factor given the data Xm+1, . . . , Xn and ﬁnd

φ

(θ −νm)/τm)/τm
n
i=m+1 φ(Xi −θ) dθ
n
i=m+1 φ(Xi)
.
The dependence on m and the asymmetry in the observations are unpleasant. We could
choose m = 1 and take the average over the n expressions obtained by replacing X1
by Xi.
319

8: Model Selection
In addition to the posterior probabilities of the diﬀerent models, the full posterior
distribution (8.2) also gives the posterior distribution of the parameter. For a given
function g: ∪dΘd →Rd, we have
P

g(θ) ∈B| X

=

d
P

g(θ) ∈B| d, X

π(d| X)
=

d pd

θ:g(θ)∈B πd(θ) pd,θ(X) dθ

d pd

πd(θ) pd,θ(X) dθ
.
This shows that we obtain the best prediction of g(θ) by combining the diﬀerent
models. The Bayesian approach does not select one model, but averages the
predictions of all models, weighed according to their posterior probability.
Nevertheless, in many cases, we want to indicate one model as best ﬁtting.
Then the value d that maximizes (8.3) is frequently natural, that is, the mode of the
posterior distribution of the model index. In standard situations, with a large number
of observations, this model index turns out to correspond to a penalized maximum
likelihood estimator for d, with penalty equal to half the logarithm of the number of
observations times the AIC penalty, the so-called BIC penalty. We consider this for the
situation that the observation forms a sample X1, . . . , Xn with (marginal) probability
density p, and take n →∞.
Theorem 8.8 BIC
Consider a model Pd with parameter θ ∈Θd ⊂R|d| given by probability densities
pd,θ that satisfy the conditions of Theorems 4.50 and 5.26 and such that the maximum
likelihood estimators ˆθd are consistent for the point of minimum of θ →K(p; pθ,d).
Then
log

πd(θ)
n

i=1
pd,θ(Xi) dθ = log
n

i=1
pd,ˆθd(Xi) −1
2|d| log n + OP (1).
Furthermore, BF(d, d0) →0 in probability as n →∞whenever p belongs to Pd ∩
Pd0 and |d| > |d0|, and, under certain regularity conditions, the same is true for
every model Pd with |d| < |d0| such that K(p; Pd) > 0.
In addition to establishing a link between the Bayesian method for model
selection and the penalized maximum likelihood, the theorem also shows that,
ultimately, the Bayesian methods choose (with high probability) the correct model,
namely the smallest model that contains the true distribution of the data. We say that
these methods are consistent for model selection.
 A proof of the following theorem for exponential families can be found in the original paper:
Gideon Schwarz, Estimating the dimension of a model. Ann. Statist. 6 (1978), no. 2, 461464.
320

8.6: Cross-Validation
The penalty |d| log n is known as the BIC penalty. This is a factor 1
2 log n times
the AIC penalty 2|d|. Since log n increases slowly with n (for example, log(1000) =
7), this does not make a great diﬀerence for small values of n. For larger n, however,
the BIC penalty is signiﬁcantly greater, which leads to the choice for smaller models
than those given by AIC.
The higher penalty for larger models is necessary for the consistency of the
method. The AIC method overestimates the dimension (see Theorem 8.6) and is
not consistent. On the other hand, we have seen that AIC gives good estimates
for the distribution of the observations, in the sense of the Kullback-Leibler
divergence between estimate and true density. It is somewhat paradoxical that for
BIC, and consistent model selection methods in general, oracle inequalities such as
in Theorem 8.5 do not hold. The problem is that consistent model selection methods
necessarily reject larger models with one or more parameters that are almost 0 in favor
of the smaller model in which these parameters are 0. Thus, consistent model selection
methods "shrink" the parameters too much for good predictions. A larger model may
well be closer to the truth.
Theorem 8.8 is restricted to ﬁnitely many models of ﬁnite dimensions. However,
this is not a requirement for the Bayesian approach, which conceptually allows
inﬁnitely many models, possibly of inﬁnite dimensions. This leads to a very diﬀerent
situation than BIC, which unfortunately is not easy to summarize. The choice of the
priors (pd: d ∈D) plays a much more important role when there are more models, in
particular when the dimensions of these models diﬀer greatly.
8.6 Cross-Validation
The idea behind cross-validation is to base the choice of a model and the estimation of
its parameters on independent observations. The problem of "overﬁtting," as identiﬁed
in Example 8.2, is thereby avoided.
The method can be applied to every estimation method that is deﬁned to optimize
a criterion. Consider, as an example, the least squares method for linear regression.
Given a response vector Y and a corresponding collection X1, . . . , Xp of predictor
variables, we determine a suitable parameter ˆβd for a regression model Y = Xdβd +e
by minimizing the sum of squares
Y −Xdβd2 =
n

i=1
(Yi −

j∈d
βd,jxi,j)2.
We know from Chapter 7 that this least squares method provides unbiased estimators
as long as the errors ei have expectation 0. If, however, we choose from a given number
of models the model with predictor variables (Xj: j ∈d) with minimal residual sum
of squares Y −Xd ˆβd2, then we are overﬁtting the model. After all, the largest model
gives the smallest residues.
321

8: Model Selection
Suppose that a second data set ( ˜X, ˜Y ) is available, with the same statistical
properties as the ﬁrst data set (X, Y ), and statistically independent of it. We base the
estimate ˆβd = ˆβd(X, Y ) on the ﬁrst data set, but evaluate the quality of the diﬀerent
models using the second data set: for every model index d, we compute the residual
sum of squares  ˜Y −˜Xd ˆβd2 on the new data and then choose the model with index
d for which this is minimal. The data in the second set is called the validation data,
and the corresponding sum of squares is called the validation sum; the data in the ﬁrst
set (X, Y ) is called the training data.
Because we use new data, the residual sum of squares  ˜Y −˜Xd ˆβd2 gives an
honest measure for the quality of the regression model d. Indeed, this is exactly the
error we would make by using this model for predicting a future response ˜Y from the
corresponding independent variables ˜X. There is no question of overﬁtting (provided
that there is suﬃcient validation data to give a good estimate of the future error).
In practice, we do not have a second data set, but we can split a given data set
(arbitrarily). In the procedure described above, we would then use the two half data
sets asymmetrically. It would make more sense to use both data sets in both roles: both
in the role of training set and in the role of validation set. We then measure the quality
of a model by taking the sum of the two residual sums of squares computed on one
half of the data with parameter estimates based on the other half. This is the principle
of cross-validation.
Instead of two equal parts, we can also use other partitions. We speak of k-fold
cross-validation if the data set is split into k parts of equal size, after which each part
is used as validation set and the parameter estimates are computed on the union of the
remaining k−1 parts of the data. The best model minimizes the sum of the k validation
sums. When k = n, where n is the number of data points, this process is called the
leave-one-out cross-validation. Estimates ˆβ−i
d
are then computed on all data points
except (Xi, Yi) and validated with score (Yi −xi ˆβ−i
d )2, where xi = (xi,1, . . . , xi,p) is
the row vector of predictor variables for the ith observation. The best model minimizes
the sum over all these scores.
Cross-validation is simple to implement and reasonably accurate if we have
suﬃcient data. However, partitioning the data leads to a loss in eﬃciency, because
estimates and model choice are, in fact, based on only part of the data. This method
is less suitable for small sets of data because in that case, the validation sum is not an
accurate estimate of the actual error.
Cross-validation has a goal similar to that of AIC, namely ﬁnding the model
that provides the best prediction. AIC uses the entire data set but adds a penalty to
the criterion to correct for "using the data twice" (for estimating the parameters and
selecting the model). This penalty is based on theoretical analysis and depends on the
structure of the data and the models. The justiﬁcation of cross-validation is simpler,
and this method can therefore be used in more situations.
322

8.7: Post-Model Selection Analysis
8.7 Post-Model Selection Analysis
Suppose that we have used one of the methods described above to select a suitable
model Pd from a given collection. The second step is to determine a suitable parameter
θd within this model, possibly with a corresponding conﬁdence region. This is called
post-model selection estimation.
In practice, in this second step, one often uses the standard methods for the model
Pd without taking into account that this model was itself estimated. This can give
misleading results, in particular for conﬁdence regions. After all, the uncertainty holds
for both the model and the parameter value, and a standard method for the model Pd
will ignore the ﬁrst. Conﬁdence regions will be too small, in particular if the model
choice and parameter estimate are based on the same data.
Unfortunately, there is no simple or generally accepted solution for this dilemma:
conﬁdence statements are diﬃcult to reconcile with model selection. For fair
conﬁdence regions, as deﬁned in Chapter 5, we will generally need to use the largest
model.
323

8: Model Selection
8.8 Summary
Let X1, . . . , Xn be a sample from an unknown distribution P with density p. Model
selection methods select the best model from a set ∪dPd with Pd = {Pd,θ: θ ∈Θd}.
This "best" model is often not the model that ﬁts best with the observed data; the
best-ﬁtting model for the data suﬀers from overﬁtting.
Four methods for selecting a model:
• Test methods. We ﬁrst test which parameter values in the model diﬀer signiﬁcantly
from 0. The selected model only involves the signiﬁcant parameters. This model
selection method is often used with regression models to select predictor variables
for the model.
• Penalty methods. Many estimation methods optimize a criterion function. Penalty
methods add a term to the criterion function that "penalizes" more as the
model grows. The Akaike information criterion (AIC) chooses the best model by
maximizing
d →log
n

i=1
pd,ˆθd(Xi) −|d|
(the log-likelihood minus the number of estimated model parameters in Pd), where
ˆθd is the maximum likelihood estimator for θ ∈Θd under the assumption that Pd
is the right model. This choice of penalty is justiﬁed by using the Kullback-Leibler
divergence as distance measure between the chosen density and the true density p.
• Bayesian model selection. In the Bayesian approach, the diﬀerent models Pd and
the parameter θd ∈Θd are assigned prior probabilities. Bayesian estimation takes
the average of the predictions concerning θ over the diﬀerent models, weighted
by their posterior distribution. When we nevertheless want to select a single
model, we choose the model d with the maximal mode of the posterior density
d →π(d|X1, . . . , Xn). Under certain conditions, this corresponds asymptotically
to maximizing the function
d →log
n

i=1
pd,ˆθd(Xi) −1
2|d| log n.
The term 1
2|d| log n is called the BIC penalty (where BIC stands for Bayesian
information criterion).
• Cross-validation. In cross-validation, the choice of model and the parameter
estimate are based on independent parts of the data. In the simplest case, the data
is split into two equal parts. The ﬁrst part (the training data) is used to estimate the
model parameters, and the second part (the validation data) is used to determine the
ﬁt of the models quantitatively using a validation sum. The roles are then reversed.
This method can be generalized to k-fold cross-validation, where the data is split
into k equal parts. The best model minimizes the sum of the validation sums.
324

AIR POLLUTION
In New York, in the summer of 1973, daily measurements were carried out to study
the relation between the ozone concentration and a number of other meteorological
variables. In addition to the ozone concentration, the solar radiation, the wind speed,
and the temperature were measured. Ozone is an important component of smog.
It forms from nitrogen dioxides and volatile hydrocarbons under the inﬂuence of
sunlight. In warm weather with little wind, the ozone concentration can rise sharply
and cause respiratory problems.
The ozone concentration is measured in parts per billion (ppb); 1 ppb corre-
sponds to 2μ g/m3. The unit for solar radiation is langley (Ly). It expresses the amount
of solar energy per surface unit, 1 Ly = 41840 J / m2. Wind speed is measured in
miles per hour (mph) and the temperature in degrees Fahrenheit. In this application,
we have converted the latter two to km/h and degrees Celsius, respectively.†
We consider four regression models to explain the ozone concentration based on
the three background variables wind speed, temperature, and solar radiation. We will
then use leave-one-out cross-validation to select the best model. The four regression
models we consider are
model 1:
Y = β0 + β1X1 + β2X2 + β3X3 + e
model 2:
Y = β0 + β1X1 + β2X2 + β3X3 + β4X1X2 + e
model 3:
Y = f1(X1) + f2(X2) + f3(X3) + e
model 4:
Y = g(X1, X2) + h(X3) + e.
Here, Y is the ozone concentration, X1 is the wind speed, X2 is the temperature, and
X3 is the solar radiation. Models 1 and 2 are linear regression models. In addition
to a term for each background variable, model 2 has a term X1X2 for the interaction
between wind and temperature. Models 3 and 4 are nonparametric additive models.
Model 3 is a generalization of model 1: the linear functions βiXi are replaced
by nonspeciﬁed functions fi. In model 4, we have again included the interaction
between X1 (wind speed) and X2 (temperature), in the function g, in addition to a
nonparametric function h for the inﬂuence of the solar radiation. In all models, we
assume that the measurement errors e are normally distributed.
The estimated parameters of model 1 are in Table 8.1. In this model, the estimated
parameter value ˆβ1 (wind speed) is negative, while ˆβ2 (temperature) and ˆβ3 (solar
radiation) are both positive. This corresponds to the increased smog in warm weather
with little wind. The last column in the table gives the p-value of the t-tests for
H0: βi = 0 based on the T -statistic from (7.4). The three parameters β1, β2, and
β3 all diﬀer signiﬁcantly from 0.
Table 8.2 gives the results of model 2. In this model, the estimated parameters
ˆβ1, ˆβ2, and ˆβ3 are all positive. This is, however, compensated by a negative estimate
for the interaction parameter β4.
† The data can be found on the book's webpage at http://www.aup.nl under ozone.
325

8: Model Selection
Coefficients:
Estimate Std. Error t value
Pr(>|t|)
(Intercept) -11.47511
15.64553
-0.733
0.4649
wind
-2.07184
0.40672
-5.094
1.52e-06
temperature
2.97377
0.45635
6.516
2.42e-09
radiation
0.05982
0.02319
2.580
0.0112
Table 8.1. R-output containing the parameter estimates and p-values for model 1. The numbers
under Std. Error are the standard errors corresponding to the estimates. The numbers under t
value are the values of the T -statistic from (7.4), and those under Pr(>|t|) are the corresponding
p-values.
Coefficients:
Estimate Std. Error t value
Pr(>|t|)
(Intercept)
-119.84436
28.89624
-4.147
6.80e-05
wind
4.40662
1.54137
2.859
0.00512
temperature
7.04471
1.02990
6.840
5.26e-10
radiation
0.06599
0.02152
3.067
0.00274
wind:temperature
-0.25501
0.05883
-4.334
3.34e-05
Table 8.2. R-output containing the parameter estimates and p-values for model 2. The numbers
under Std. Error are the standard errors corresponding to the estimates. The numbers under t
value are the values of the T -statistic from (7.4), and those under Pr(>|t|) are the corresponding
p-values.
The ﬁtted functions for models 3 and 4 were computed using the function
mgcv::gam from package mgcv version 1.8-6 in the R-language for statistical
computing, with default choices of the parameters. This function iteratively determines
functions for the additive terms by ﬁtting penalized regression splines, with the
smoothing parameter determined by generalized cross validation (GCV). See the R-
documentation for details. Figure 8.2 shows the estimates of the three functions f1,
f2, and f3 in model 3. The estimated function ˆf1 for the inﬂuence of the wind speed on
the formation of ozone is chieﬂy decreasing, whereas ˆf2 (temperature) and ˆf3 (solar
radiation) are increasing. This agrees with model 1, where ˆβ1 is negative and ˆβ2 and
ˆβ3 are positive. The nonlinearity of the estimated functions in clearly visible in Figure
8.2, which shows that model 3 is more general than model 1.
Figure 8.3 shows the estimate of the function g in model 4. The ﬁgure on the
left gives a perspective view of the estimate ˆg, and the ﬁgure on the right shows the
estimate using contour lines. The estimated form of g is more complicated than the
function β1X1 + β2X2 + β4X1X2 used in model 2. Figure 8.4 shows the estimate of
the function h in model 4.
To determine the best model, we use cross-validation. In this method, we
split the data in a part used to estimate the model and a part used to evaluate
the estimated model (the validation data). In leave-one-out cross-validation, each
individual observation is used once as validation data. The validation sum of leave-
326

8: Air Pollution
5
10
15
20
25
30
−10
10
30
50
wind
15
20
25
30
35
−10
10
30
50
temperature
0
50
100
150
200
250
300
−10
10
30
50
radiation
Figure 8.2. Estimates of the functions f1, f2, and f3 in model 3. The short vertical line segments
on the horizontal axis indicate the measured values of the three background variables.
one-out cross-validation is
n

i=1
(Yi −ˆl−i(xi))2,
where ˆl−i is the estimated regression function, estimated on all data points except
the ith observation, and xi contains the values of the predictor variables of the ith
observation. Table 8.3 gives the values of these validation sums for the four models.
It shows that model 4 is the best. Apparently, for this situation, it is important that
the interaction between the variables wind speed and temperature is included in the
model, and in a more general way than taking their product as in model 2.
327

8: Model Selection
wind
5
10
15
20
25
30
temperature
15
20
25
30
35
50
100
150
wind
temperature
 20 
 20 
 30 
 40 
 50 
 60 
 70 
 80 
 90 
 90 
 100 
 110 
 120 
 130 
 140 
5
10
15
20
25
30
15
20
25
30
35
Figure 8.3. Estimate of the function g in model 4: a perspective view on the left and contour lines
on the right.
0
50
100
150
200
250
300
−10
0
5
radiation
Figure 8.4. Estimate of the function h in model 4. The short vertical line segments on the
horizontal axis indicate the measured value of the solar radiation.
model
1
2
3
4
validation sum
52038.87
44454.35
40635.28
32770.13
Table 8.3. R-output containing the value of the validation sum for the four models.
328

A Probability Theory
A.1 Introduction
This appendix contains some deﬁnitions and results from probability theory that
are relevant when reading this book. The aim is to present this matter brieﬂy.
For further information, including proofs of theorems, examples, and applications,
we refer to textbooks on probability theory, such as S. Ross, A First Course in
Probability, Prentice-Hall and R. Meester, A Natural Introduction to Probability
Theory, Birkh¨auser.
A.2 Distributions
The basis of all statistical procedures is an observation X inﬂuenced by uncertainty,
chance, or another form of randomness. As in probability theory, in statistics the
uncertainty is translated mathematically by assigning a probability distribution to X.
Deﬁnition A.1 Random variable
A random variable is an observation subject to uncertainty, described by a
probability distribution.
329

A: Probability Theory
The set of all possible outcomes of X is called the sample space and denoted
by Ω. A probability distribution is a function that gives the probability of ﬁnding the
observation X in A for (almost) all subsets A ⊆Ω,
P(X ∈A).
Probability distributions have three properties:
(i) P(X ∈Ω) = 1.
(ii) 0 ≤P(X ∈A) ≤1 for all A ⊆Ω.
(iii) (σ-additivity) For disjoint sets A1, A2, . . . ⊆Ω (Ai ∩Aj = ∅if i = j), we have
P(X ∈
∞

i=1
Ai) =
∞

i=1
P(X ∈Ai).
All other general properties of a probability distribution can be deduced directly from
these three; for example, P(X ∈A) ≤P(X ∈B) for A, B ⊆Ω with A ⊆B. For
other properties of probability distributions, we refer to books on probability theory.
In some cases, we are not interested in the random variable X itself, but in a
function g of this variable, for example g(X) = X2. In many cases, the function
g is deﬁned on the entire real line, and g(X) is therefore deﬁned for all real-valued
random quantities X.‡ Suppose that the probability distribution of X is known; the
distribution of Y = g(X) is then determined by
P(Y ∈A) = P(g(X) ∈A) = P(X ∈g−1(A)),
where g−1(A) is called the inverse image of A under g:
g−1(A) = {x: g(x) ∈A}.
(The notation g−1 might suggest that we need the inverse of g for the deﬁnition of the
inverse image. This is not the case; even if g is not invertible, the right-hand side is
well deﬁned.)
A.2.1 Discrete and Continuous Distributions
There are two basic types of probability distributions: discrete distributions and
continuous distributions. A discrete distribution is characterized by a ﬁnite or
countable set of possible outcomes of the random variable, while a random variable
with a continuous distribution can have outcomes in an interval of the real line. To
every discrete and every continuous distribution correspond a probability density (or
density for short) and a distribution function.
‡ The condition that X lie in the domain of g with probability 1 ensures that, in general, g(X)
is well deﬁned. Strictly speaking, there is a condition on g (measurability), but in this book we do
not discuss nonmeasurable functions.
330

A.2: Distributions
For a discrete distribution, the probability density assigns a weight (probability
mass) to every possible outcome, equal to the probability of that outcome. These
weights are nonnegative and add up to 1. The probability of an outcome in a subset A
of the sample space Ω is equal to
P(X ∈A) =

ω∈A
p(ω),
where p(ω) = P(X = ω). Some examples of common discrete distributions are
the Bernoulli, binomial, Poisson, geometric, hypergeometric, and negative binomial
distributions.
If X has a continuous distribution over (part of) the real line, we use a
probability density function f: R →R, which we also call probability density for
short. The summation in discrete distributions is replaced by integration in continuous
distributions. The probability of an outcome in A ⊆R for the continuous random
variable X with probability density f is given by
P(X ∈A) =

A
f(x) dx.
Some examples of common continuous distributions are the uniform, normal, expo-
nential, Cauchy, chi-square, t, gamma, and beta distributions.
A.2.2 Distribution Functions
Probability densities are a way to specify distributions. Another, equivalent, way is by
using so-called distribution functions.
Deﬁnition A.2 Distribution function
Let X be a random variable following some probability distribution. The cumulative
distribution function or distribution function F corresponding to the probability
distribution is deﬁned by
F(x) = P(X ≤x).
The distribution function is a monotonically increasing function, that is, if x ≤y,
then F(x) ≤F(y). The deﬁnition of the distribution function in this form holds for
both discrete and continuous random variables that are real valued.
For a real-valued, discrete random variable X, the relation between the probabi-
lity density p and the distribution function F can be expressed as follows:
F(x) = P(X ≤x) =

ω≤x
p(ω).
331

A: Probability Theory
The distribution function has jumps at all points that are possible outcomes of X.
Between these jumps, the distribution function is constant. The size of the jump at the
point ω is equal to p(ω). Hence, discrete distributions can be speciﬁed in two ways:
either using the probability density p (the distribution function F can be found using
summation) or using the distribution function F (the probability density p follows
from the size of the jumps).
For a continuous random variable X, the relation between the probability density
f and distribution function F can be expressed as follows:
F(x) = P(X ≤x) =
 x
−∞
f(u) du.
The distribution function F can therefore be seen as the primitive function of the
probability density f. Conversely, f is the derivative of F,
f(x) = F (x).
It follows that continuous distributions can also be speciﬁed in two ways: either using
the probability density f (the distribution function F follows by integration) or using
the distribution function F (the probability density follows by diﬀerentiation).
Using the distribution function, it is easy to compute the probability for intervals
of the form (c, d]:
P(c < X ≤d) = P(X ≤d) −P(X ≤c) = F(d) −F(c).
For discrete distributions, it matters whether the interval is open, closed, or half closed.
For example, the probability P(c ≤X ≤d) is greater than P(c < X ≤d) when
P(X = c) > 0, because P(c ≤X ≤d) = P(c < X ≤d) + P(X = c). For
continuous random variables we have P(X = c) = 0 for all c; hence the choice of an
open or closed interval is of no consequence.
A.3 Expectation and Variance
The expectation and variance of a distribution are properties that reﬂect the location
and dispersion of the distribution, respectively. The location is a point around which
the distribution is centered, while the dispersion is a measure for the width of the
distribution around its location. Several properties can act as location or dispersion.
Expectation and variance are examples that are often used.
The expected value or expectation E(X) of a random variable X corresponds
to the notion of weighted average. The weights are based on the probability density.
When there is no risk of confusion, we write simply EX for the expectation. For a
discrete random variable X with probability density p, the expectation EX is given
by
EX =

ω∈Ω
ω p(ω),
332

A.4: Standard Distributions
For a continuous random variable X with probability density f, the expectation is
deﬁned by
EX =
 ∞
−∞
x f(x) dx.
For a function g, the expectation of g(X) is
E(g(X)) =
 ∞
−∞
g(x) f(x) dx.
The expected value of X or g(X) is not always well deﬁned. The integral or sum
may not converge. For example, the expectation of a random variable with Cauchy
distribution does not exist. In this book, we assume that all integrals we use exist.
The variance is the expectation of the square of the distance from X to its
expected value,
var X = E(X −EX)2.
We can easily check that the variance can be written as
var X = E(X2) −(EX)2.
This way of writing it is often useful when computing the variance of a random
variable. The expectation E(X2) is computed as E(g(X)) with g(X) = X2. The
variance is large if the probability that X is found at a considerable distance from EX
is relatively large. This property characterizes the notion of dispersion.
The covariance of two random variables X and Y is equal to
cov(X, Y ) = E

(X −EX)(Y −EY )

= E(XY ) −EXEY.
The following identities can be deduced from the deﬁnitions of the expected value and
variance:
E(a + bX) = a + b EX
var(a + bX) = b2 var(X)
E(X + Y ) = EX + EY
var(X + Y ) = var(X) + var Y + 2 cov(X, Y ).
A.4 Standard Distributions
In this section, we give examples of common discrete and continuous distributions.
333

A: Probability Theory
A.4.1 Discrete Distributions
Example A.3 Bernoulli distribution
The random variable X has a Bernoulli distribution with parameter p ∈[0, 1] if
P(X = 0) = 1 −p
and
P(X = 1) = p.
This probability mass function can also be written as
P(X = x) = px(1 −p)1−x,
x ∈{0, 1}.
The expected value and variance are then equal to EX = p and var X = p(1 −p).
If X1, . . . , Xn are independent Bernoulli random variables with parameter p, then
X1 + . . . + Xn is binomially distributed with parameters n and p.
Example A.4 Binomial distribution
The random variable X has a binomial distribution with parameters n ∈N and p ∈
[0, 1] if
P(X = k) =
n
k

pk(1 −p)n−k
for k ∈{0, 1, . . ., n}. The expected value and variance are then equal to EX = np and
var X = np(1−p). The binomial distribution with parameters n = 1 and p ∈[0, 1] is
equal to the Bernoulli distribution with parameter p. If X1 and X2 are two independent
binomial random variables with parameters (n, p) and (m, p), respectively, then X1 +
X2 is again binomially distributed, with parameters (n + m, p).
Example A.5 Multinomial distribution
The random variable X
=
(X1, . . . , Xr) has a multinomial distribution with
parameters (n, p1, . . . , pr), where n ∈N and pi ∈[0, 1] for i = 1, . . . , r with
r
i=1 pi = 1, if
P(X1 = k1, . . . , Xr = kr) =

n
k1 · · · kr

pk1
1 · · · pkr
r
for ki ∈{0, 1, . . ., n} for i = 1, . . . , r with r
i=1 ki = n, where

n
k1 · · · kr

=
n!
k1! · · · kr!.
In the case r = 2, the multinomial distribution reduces to the binomial distribution
with parameters n and p1.
334

A.4: Standard Distributions
Example A.6 Poisson distribution
The random variable X has a Poisson distribution with parameter λ > 0, denoted by
Poisson(λ), if
P(X = k) = λke−λ
k!
for k ∈{0, 1, . . .}. The expected value and variance are then equal to EX = λ and
var X = λ. If X1 and X2 are two independent Poisson random variables with means
λ and μ, respectively, then X1 + X2 again has a Poisson distribution, with parameter
λ + μ.
Example A.7 Geometric distribution
The random variable X has a geometric distribution with parameter p ∈(0, 1] if
P(X = k) = p(1 −p)k−1
for k ∈{1, 2, . . .}. The expected value and variance are then equal to EX = 1/p
and var X = (1 −p)/p2. If X1, . . . , Xr are independent, geometrically distributed
random variables with parameter[nope: means?] p, then X1 + . . .+ Xr has a negative
binomial distribution with parameters r and p.
Example A.8 Negative binomial distribution
The random variable X has a negative binomial distribution with parameters r ∈N
and p ∈(0, 1] if
P(X = k) =
k −1
r −1

pr(1 −p)k−r
for k ∈{r, r + 1, . . .}. The expected value and variance are then equal to EX = r/p
and var X = r(1 −p)/p2. The negative binomial distribution with parameters r = 1
and p ∈(0, 1] is equal to the geometric distribution with parameter p.
Example A.9 Hypergeometric distribution
The random variable X has a hypergeometric distribution with parameters N, m, n ∈
N, where n, m < N, if
P(X = k) =
m
k
N−m
n−k

N
n

for k ∈{0, 1, . . ., n}. The expected value and variance are then equal to EX =
nm/N and var X = n(m/N)(1 −m/N)(N −n)/(N −1).
335

A: Probability Theory
A.4.2 Continuous Distributions
Example A.10 Uniform distribution
The random variable X has a uniform distribution U[a, b] on the interval [a, b] if the
density of X is equal to
f(x) =
1
b −a1[a,b](x).
The indicator function 1[a,b](x) takes on the value 1 for x ∈[a, b] and 0 elsewhere.
The expected value and variance are then equal to EX = (a + b)/2 and var X =
(b −a)2/12. When a = 0 and b = 1, the density is equal to f(x) = 1[0,1](x), the
expected value is 1/2, and the variance is 1/12.
Example A.11 Normal distribution
The random variable X has a normal distribution with parameters μ ∈R and σ2 > 0
if the density of X is equal to
f(x) =
1
√
2πσ2 e−1
2
(x−μ)2
σ2
.
The expected value and variance are then equal to EX = μ and var(X) = σ2. The
standard normal distribution is the normal distribution with parameters μ = 0 and
σ2 = 1. The density and distribution function of the standard normal distribution are
denoted by φ and Φ, respectively. If X1 and X2 are two independent normal random
variables, then X1+X2 is again normally distributed, with parameters (μ+ν, σ2+τ 2).
Example A.12 Exponential distribution
The random variable X has an exponential distribution with parameter λ > 0 if the
density of X is equal to
f(x) = λe−λx,
x ≥0.
The expected value and variance are then equal to EX = 1/λ and var X = 1/λ2.
If X1, . . . , Xn are independent, exponentially distributed random variables with
parameter λ, then the sum X1 + . . . + Xn has a gamma distribution with shape
parameter n and inverse scale parameter or rate parameter λ.
336

A.4: Standard Distributions
Example A.13 Gamma distribution
The random variable X has a gamma distribution with shape parameter n and inverse
scale parameter λ > 0 (or scale parameter 1/λ) if the density of X is equal to
f(x) = xα−1λαe−λx
Γ(α)
,
x ≥0,
where Γ is the so-called gamma function
Γ(α) =
 ∞
0
xα−1e−xdx.
When α ∈N, we have Γ(α) = (α −1)!. The expected value and variance of X are
given by EX = α/λ and var X = α/λ2. The gamma distribution with parameters
α = 1 and λ > 0 is equal to the exponential distribution with parameter λ. If X1 and
X2 are two independent random variables with gamma distributions with parameters
(α, λ) and (β, λ), respectively, then X1 + X2 again has a gamma distribution, with
parameters α + β and λ.
Example A.14 Beta distribution
The random variable X has a beta distribution met parameters α > 0 and β > 0 if the
density of X is equal to
f(x) = xα−1(1 −x)β−1
B(α, β)
,
x ∈[0, 1],
where B is the so-called beta function
B(α, β) =
 1
0
xα−1(1 −x)β−1dx.
We have B(α, β) = Γ(α)Γ(β)/Γ(α + β) and B(α + 1, β)/B(α, β) = α/(α + β).
The expectation of X can be calculated as follows:
 1
0
xxα−1(1 −x)β−1
B(α, β)
dx = B(α + 1, β)
B(α, β)
 1
0
x(α+1)−1(1 −x)β−1
B(α + 1, β)
dx
=
α
α + β ,
where the last equality follows from the fact that the integral in the second-to-last
expression is equal to 1. The variance of X is given by var X = αβ/((α + β)2(α +
β + 1)).
337

A: Probability Theory
Example A.15 Cauchy distribution
The random variable X has a Cauchy distribution with location parameter θ if the
density of X is equal to
f(x) =
1
π(1 + (x −θ)2).
When θ = 0, this is called the standard Cauchy distribution. The expected value and
variance of the Cauchy distribution do not exist.
Example A.16 Chi-square distribution
The random variable X has a chi-square distribution with n degrees of freedom if
X has the same distribution as n
i=1Z2
i for Z1, . . . , Zn independent standard normal
random variables. The expected value and variance of X are given by EX = n and
var X = 2n. The chi-square distribution with n degrees of freedom is denoted by χ2
n.
This distribution is identical to the gamma distribution with parameters (n/2, 1/2).
Example A.17 t-distribution
The random variable X has a t-distribution (or Student's t-distribution) with n
degrees of freedom if X has the same distribution as Z/

Y/n, where Y and Z
are independent random variables, Z has a standard normal distribution, and Y has
a χ2
n-distribution. The t-distribution with n degrees of freedom is denoted by tn. An
expression for the density is given in Exercise 4.44.
Example A.18 F-distribution
A random variable X has an F-distribution with m and n degrees of freedom if X
has the same distribution as (U/m)/(V/n), where U and V are independent, chi-
square distributed random variables with m and n degrees of freedom, respectively.
The F-distribution with m and n degrees of freedom is denoted by Fm,n.
A.5 Multivariate and Marginal Distributions
In many cases, we are not interested in a single observation but want to consider
several measured quantities at the same time. In probability theory, random vectors
are used in such cases. The simplest case is that of two random variables X and Y that
are combined into a vector (X, Y ). Let ΩX and ΩY be the sample spaces of X and Y ,
respectively. The possible outcomes of (X, Y ) are the points (x, y) ∈Ω = ΩX × ΩY .
When X and Y are real valued, the combined sample space Ω is equal to (part of)
the real plane; that is, Ω ⊆R2. The joint distribution of X and Y describes the
probabilities of the form
P

(X, Y ) ∈A

,
338

A.6: Independence and Conditioning
where A is a subset of Ω.
For random vectors, too, there is a distinction between discrete and continuous
distributions. If the vector (X, Y ) has a discrete distribution, then the distribution
is determined by the multivariate probability density p(ω1, ω2), where p(ω1, ω2) =
P

(X, Y ) = (ω1, ω2)

for all possible outcomes (ω1, ω2) ∈Ω. In this case, the
probability of an outcome in a subset A of Ω is equal to the sum
P

(X, Y ) ∈A

=

(ω1,ω2)∈A
p(ω1, ω2).
When the vector (X, Y ) has a continuous distribution, we use a multivariate
probability density function f: R2 →R, also called a multivariate density for short.
The probability of an outcome in a set A is then given by the integral
P

(X, Y ) ∈A

=

A
f(x, y) dx dy.
Examples of joint probability densities and computations involving them can be found
in textbooks on probability theory.
From the multivariate distribution of the random vector (X, Y ), we can deduce
the marginal distributions of X and Y . A marginal distribution is determined by the
corresponding marginal probability density. When the random variables are discrete,
the marginal probability density pX of X is deduced as follows from the multivariate
probability density p:
pX(ω) =

ω2∈ΩY
p(ω, ω2).
For continuous random variables, the summation is replaced by integration, and the
marginal probability density function fX of X is deduced from the multivariate
probability density f,
fX(x) =
 ∞
−∞
f(x, y) dy.
Analogous formulas hold for the marginal distribution of Y . For random vectors
(X1, . . . , Xn) with n >
2, we can easily generalize the above. In that case,
the marginal density of X1, for example, can be deduced by integrating the
multivariate density over x2, . . . , xn. In Appendix B, we discuss the multivariate
normal distribution.
A.6 Independence and Conditioning
Independence and the conditioning of random variables play an important role in
statistics.
339

A: Probability Theory
Deﬁnition A.19 Independent random variables
Two random variables X and Y are called independent if for all events A ⊆ΩX and
B ⊆ΩY , we have
P

X ∈A, Y ∈B

= P(X ∈A) P(Y ∈B).
The following theorem shows how the independence of two random variables is
reﬂected in the joint distribution. Proofs of this theorem and Theorem A.22 can be
found in textbooks on probability theory.
Theorem A.20
If the random variables X and Y have a discrete joint distribution with probability
density p, then X and Y are independent if and only if
p(ω1, ω2) = pX(ω1) pY (ω2) for all ω1, ω2.
If (X, Y ) has a continuous joint distribution with probability density p, then X and
Y are independent if and only if
f(x, y) = fX(x) fY (y) for all x, y.
The independence of X and Y means that information on the realization of Y
does not inﬂuence the distribution of X and vice versa. This heuristic interpretation
can be substantiated by considering conditional probabilities.
Deﬁnition A.21 Conditional probability
For random variables X and Y , the conditional probability of X ∈A given Y ∈B
is deﬁned by
P

X ∈A| Y ∈B

= P

X ∈A, Y ∈B

P

Y ∈B

for A ⊆ΩX, B ⊆ΩY , and P

Y ∈B

> 0.
For independent random variables X and Y , the probability of X ∈A given
Y ∈B reduces to
P

X ∈A| Y ∈B

= P

X ∈A

for all A ⊆ΩX and B ⊆ΩY because the product form from Deﬁnition A.19
then holds. This calculation shows that if using additional information on Y by
conditioning does not inﬂuence the distribution of X, then X and Y are independent.
340

A.6: Independence and Conditioning
Theorem A.22 Bayes's rule
Let A1, . . . , An be a partition of Ω, that is, Ai ∩Aj = ∅for i = j and n
i=1 Ai = Ω,
and assume P(X ∈Ai) > 0 for all i. Then for an arbitrary B with P(Y ∈B) > 0,
we have
P

X ∈Ai| Y ∈B

=
P

Y ∈B| X ∈Ai

P

X ∈Ai

n
j=1 P

Y ∈B| X ∈Aj

P

X ∈Aj
.
Deﬁnition A.23 Conditional density
For continuous random variables X and Y , the conditional density of X given Y is
equal to
fX|Y (x| y) = f(x, y)
fY (y) .
In fact, the conditional density is an application of Bayes's rule. Here, too, if
X and Y are independent, the conditional density of X given Y has a simpler form:
fX|Y (x| y) = fX(x) for arbitrary y.
The expected value and variance of the sum of two independent random variables
are equal to
E(X + Y ) = EX + EY
var(X + Y ) = var(X) + var(Y )
because in that case Cov(X, Y ) = E(XY ) −EXEY = 0.
The expressions above can easily be extended to sums of n random variables. Let
X1, . . . , Xn be random variables with ﬁnite expectation μ, then
E
 n

i=1
Xi

=
n

i=1
EXi = nμ.
If X1, . . . , Xn have ﬁnite variance σ2 and are independent, then we also have
var
 n

i=1
Xi

=
n

i=1
var Xi = nσ2.
The expectation and variance of the sample mean
X = 1
n
n

i=1
Xi
are then equal to
EX = 1
nE
 n

i=1
Xi

= μ,
var X = 1
n2 var
 n

i=1
Xi

= σ2
n .
341

A: Probability Theory
A.7 Limit Theorems and the Normal Approximation
For independent, identically distributed continuous random variables X1, X2, . . . , Xn
with marginal probability density fX, the joint density f is equal to the product of the
marginal densities:
f(x1, . . . , xn) =
n

i=1
fX(xi).
The joint density comes up frequently in statistical problems. The following important
theorems from probability theory apply to sequences of independent and identically
distributed random variables. Since the limit theorems concern the limit for n →∞,
in this section the sample mean X will be denoted by Xn to highlight the dependence
on n.
Deﬁnition A.24 Convergence in probability
A sequence of random vectors Tn converges in probability to the random vector T ,
denoted by Tn P→T , if P

Tn −T  > ε

→0 as n →∞for all ε > 0.
Deﬁnition A.25 Convergence in distribution
A sequence of random vectors Tn converges in distribution to the random vector T ,
denoted by Tn ⇝T , if P(Tn ≤x) →P(T ≤x) as n →∞for all x for which the
map x →P(T ≤x) is continuous.
Theorem A.26 Weak law of large numbers
Let X1, X2, . . . be independent, identically distributed random variables with a
marginal distribution with ﬁnite expected value μ. Then for every ε > 0,
lim
n→∞P

|Xn −μ| > ε

= 0.
In other words, Xn converges in probability to μ.
Theorem A.27 Strong law of large numbers
Let X1, X2, . . . be independent, identically distributed random variables with a
marginal distribution with ﬁnite expected value μ. Then
P

lim
n→∞Xn = μ

= 1.
342

A.7: Limit Theorems and the Normal Approximation
Theorem A.28 Central limit theorem
Let X1, X2, . . . be independent, identically distributed random variables with a
marginal distribution with ﬁnite expected value μ and ﬁnite variance σ2. Then
lim
n→∞P
√n(Xn −μ)
√
σ2
≤z

= Φ(z),
where Φ is the distribution function of the standard normal distribution. In other
words, the standardized sample mean converges in distribution to a standard normal
random variable.
The central limit theorem as such cannot be applied in practice because we never
have an inﬁnite amount of data. However, for large values of n, the probability on the
left-hand side is approximately equal to the probability on the right-hand side. How
large n must be exactly for a reasonable approximation depends, among other things,
on the skewness of the marginal distribution.
The random variable on the left-hand side can also be written as
√n(Xn −μ)
√
σ2
= Xn −μ

σ2/n
= Xn −EXn

var Xn
.
Thus, the central limit theorem implies that the standardized sample mean approxi-
mately follows the standard normal distribution when the number of observations is
large.
Example A.29 Normal approximation of the binomial distribution
Let X1, . . . , Xn be a sample from the Bernoulli distribution with parameter p. The
corresponding expected value and variance are both ﬁnite, respectively p and p(1−p).
The central limit theorem implies that for large values of n,
Xn −EXn

var Xn
=
Xn −p

p(1 −p)/n
approximately has the standard normal distribution. The sample mean therefore
approximately has distribution N(p, p(1 −p)/n). From this, we can also derive an
approximation for the distribution of Y = n
i=1Xi, namely the binomial distribution
with parameters n and p. If Xn approximately has distribution N(p, p(1 −p)/n),
then Y = nXn approximately has distribution N(np, np(1−p)). This approximation
is reasonable when n is not too small and p is not too close to 0 or 1. As a rule
of thumb, we use the condition np(1 −p) ≥5. Since the binomial distribution is
discrete and the normal distribution is continuous, we generally apply a continuity
correction to improve the approximation. The probability mass at Y
= i in the
discrete distribution is, as it were, spread out over the interval (i −1/2, i + 1/2] in the
continuous distribution, P(Y = i) = P(i −1/2 < Y ≤i + 1/2) for all i ∈N. This
gives
P

Y ≤i

= P

Y ≤i + 1
2

and
P

Y ≥i

= P

Y > i −1
2

.
343

A: Probability Theory
For example, for n = 25 and p = 0.4, the combination of the normal approximation
and the continuity correction gives
P(Y ≤11) = P(Y ≤11.5) = P
Y −10
√
6
≤11.5 −10
√
6

≈Φ
1.5
√
6

= 0.730.
The exact probability in this case is equal to 0.732. For comparison, we also give
the approximated probability without continuity correction: Φ(1/
√
6) = 0.658. The
correction clearly improves the approximation.
Example A.30 Normal approximation of the Poisson distribution
Let X1, . . . , Xn be a sample from the Poisson distribution with parameter λ. The
expected value and the variance of this distribution are both equal to λ and therefore
ﬁnite. By the central limit theorem,
Xn −EXn

var Xn
= Xn −λ

λ/n
approximately follows the standard normal distribution. This quantity can also be
written as
n
i=1Xi −nλ
√
nλ
.
Because the sum of independent Poisson random variables again has a Poisson
distribution, see Example A.6, the random variable Y = n
i=1Xi has a Poisson
distribution with parameter μ = nλ. Consequently,
Y −μ
√μ
approximately follows the standard normal distribution. This is equivalent to saying
that for large values of μ, the distribution Poisson(μ) can be approximated using the
distribution N(μ, μ).
344

A: Exercises
Exercises
1. Compute EX2 if X has a Poisson distribution with parameter θ.
2. Compute EX(X −1)(X −2) if X has a Poisson distribution with parameter 1.
3. Compute EeX if X has a standard normal distribution.
4. Let X and Y be independent exponential random variables with expectation 1. Determine the
probability density and the expectation of max(X, Y).
5. Let X = (X1, X2, X3) follow the multinomial distribution with parameters n and p =
(p1, p2, p3). Show that
(i) EXi = pi,
(ii) var Xi = npi(1 −pi),
(iii) cov(Xi, Xj) = −npipj for i = j. Hint: Write Xi and Xj as sums of independent random
variables.
6. Let X and Y be independent normal random variables with distributions N(0, 1) and N(1, 2),
respectively.
(i) Determine P(X + Y ≤2).
(ii) Determine a number ξ such that P(X + Y > ξ) = 0.95.
7. Determine the distribution function and the probability density of X2 + Y2 if X and Y are
independent standard normal random variables.
8. The random vector (X, Y) has an absolutely continuous distribution with density
f(x, y) =

e−y
√π
if y > x2,
0
otherwise.
(i) Show that X has a normal distribution with expectation 0 and variance 1/2.
(ii) Show that the marginal density of Y is given by 2√ye−y/√π for y > 0.
(iii) Given x, determine the conditional density of Y given X = x.
(iv) Given x, determine E(Y| X = x).
(v) Determine EY.
9. The random vector (X, Y) has an absolutely continuous distribution with density
f(x, y) =

e−x2y
if x > 1, y > 0,
0
if x ≤1 or y ≤0.
(i) Show that Z = X2Y has an exponential distribution with parameter 1.
(ii) Determine E(X2Y)2.
(iii) Determine EeZ−X−Y.
10. Let X1, . . . , Xn be independent random variables with the uniform distribution on the interval
[0, 1]. Determine the expectation and variance of Y = max(X1, . . . , Xn). Hint: Deduce the
density of Y from the distribution function P(Y ≤y) of Y, which can be determined using
the distribution functions of X1, . . . , Xn.
11. Let X1, . . . , Xn be independent, identically distributed random variables with expectation μ
and variance σ2. Compute EXn, var Xn, E(Xn)2, and cov(Xi −Xn, Xn).
345

A: Probability Theory
12. Let X1, . . . , Xn be independent, identically distributed continuous random variables with
probability density f. Let F be the function given by Fn(A) = (1/n)#(Xi ∈A) for a ﬁxed set
A (for example an interval). Show that Fn(A) converges in probability to a limit as n →∞.
What is the limit?
13. Let X be binomially distributed with parameters 100 and 1/4. Determine an approximation
for P(X ≤30) using the central limit theorem.
14. Let X1, . . . , X25 be independent random variables with distribution Poisson(5). Determine an
approximation for P(Xn ≥4.5) using the central limit theorem.
346

B Multivariate Normal Distribution
B.1 Introduction
The multivariate normal distribution is the generalization of the usual normal
distribution to higher dimensions. The distribution is used as the basis for the deﬁnition
of certain statistical models, such as the general linear regression model but also
occurs in limit results related to estimating or testing vector-valued parameters.
In this appendix, we discuss, as background material, the main properties of
multidimensional distributions. These are useful for understanding certain parts of
this book.
B.2 Covariance Matrices
The covariance of two random variables X and Y is deﬁned as cov(X, Y ) =
E(X −EX)(Y −EY ) (provided that these expectations exist). The variance of X is
equal to var X = cov(X, X). The expectation is linear: E(αX+βY ) = αEX+βEY .
The covariance is symmetric and bilinear: cov(αX + βY, Z) = α cov(X, Z) +
β cov(Y, Z).
347

B: Multivariate Normal Distribution
The expectation vector and covariance matrix of a random vector (X1, . . . , Xk)
are the vector and matrix
EX =
⎛
⎜
⎜
⎝
EX1
EX2
...
EXk
⎞
⎟
⎟
⎠,
Cov X =
⎛
⎜
⎜
⎝
cov(X1, X1)
· · ·
cov(X1, Xk)
cov(X2, X1)
· · ·
cov(X2, Xk)
...
...
cov(Xk, X1)
· · ·
cov(Xk, Xk)
⎞
⎟
⎟
⎠.
For k = 1, these reduce to the expectation and variance of the variable X1. We
conclude this section with the following lemma, which states a number of properties
of random vectors.
Lemma B.1
For every matrix A, vector b, and random vector X, we have
(i) E(AX + b) = AEX + b,
(ii) Cov(AX) = A(Cov X)AT ,
(iii) Cov X is symmetric and positive deﬁnite,
(iv) P

X ∈EX + range(Cov X)

= 1.
B.3 Deﬁnition and Basic Properties
For given numbers μ ∈R and σ > 0, we say that a random variable X has the normal
distribution N(μ, σ2) if X has a probability density of the form
x →
1
√
2πσ2 e−1
2 (x−μ)2/σ2.
Furthermore, we say that X has distribution N(μ, 0) if P(X = μ) = 1. This is the
natural extension to the case σ = 0, because we then always have EX = μ and
var X = σ2.
We now want to generalize the deﬁnition of the normal distribution to higher
dimensions. Let μ and Σ be an arbitrary vector and a positive deﬁnite, symmetric
k × k matrix. Every positive deﬁnite, symmetric matrix Σ can be written as
Σ = LLT
348

B.3: Deﬁnition and Basic Properties
for a k × k matrix L. The matrix L is not unique, but it does not matter which we
choose. One possibility with a geometric interpretation comes from the transformation
to an orthonormal basis of eigenvectors of Σ. With respect to this basis, the linear
transformation Σ is represented by the diagonal matrix D whose entries are the
eigenvalues of Σ (in a given order), and Σ is equal to Σ = ODOT for the orthogonal
matrix O that represents the change of basis (orthogonal means OT = O−1). In the
decomposition, we now choose L equal to L = OD1/2OT with D1/2 the diagonal
matrix whose entries are the square roots of the eigenvalues of Σ. We then have
LLT = OD1/2OT OD1/2OT = OD1/2D1/2OT = Σ.
This matrix L therefore has the desired decomposition property. This L is a positive
deﬁnite, symmetric matrix, just as Σ is, and is therefore also known as a "positive
square root" of Σ.
Deﬁnition B.2 Multivariate normal distribution
A k-dimensional random vector X has a multivariate normal distribution with
parameters μ and Σ, denoted by Nk(μ, Σ), if X has the same probability distribution
as the vector μ + LZ for a k × k matrix L with Σ = LLT and a vector
Z = (Z1, . . . , Zk)T whose coordinates are independent random variables with
distribution N(0, 1).
The notation Nk(μ, Σ) suggests that the distribution of X depends only on μ and
Σ. This is indeed the case, although this is not immediately clear from the deﬁnition
because, at ﬁrst glance, the distribution of μ + LZ appears to depend on μ and L. We
will see further on, in Lemmas B.3 and B.4, that the distribution of the vector μ + LZ
depends only on μ and LLT = Σ.
The parameters μ and Σ are exactly the expectation and covariance matrix of the
vector X because, by Lemma B.1,
EX = μ + LEZ = μ,
Cov X = L Cov ZLT = Σ.
The multivariate normal distribution with μ = 0 and Σ = I, the identity matrix,
is called the standard normal distribution. By Deﬁnition B.2, the coordinates of a
standard normal vector X are independent variables with distribution N(0, 1).
If the matrix Σ is singular, then the multivariate normal distribution Nk(μ, Σ)
does not have a density. (This corresponds to the case σ2 = 0 in dimension 1.) This
follows from Lemma B.1, which implies that the vector X −EX takes on its values
in the range of the matrix Σ, which is a lower-dimensional subspace of Rk when Σ
is singular. It also immediately follows from Deﬁnition B.2 because if Σ is singular,
then L is also singular, and the range of X −μ = LZ is contained in the range of L.
Conversely, if Σ is nonsingular, then the multivariate normal distribution Nk(μ, Σ) is
continuous. The following lemma gives the probability density explicitly.
349

B: Multivariate Normal Distribution
Lemma B.3
A random vector X has a multivariate normal distribution with parameters μ and a
nonsingular matrix Σ if and only if X has a density of the form
x →
1
(2π)k/2√
det Σ
e−1
2 (x−μ)T Σ−1(x−μ).
Proof. The density of Z = (Z1, . . . , Zk) is the product of standard normal densities.
Hence, for every vector b, we have
P

μ + LZ ≤b

=

z:μ+Lz≤b
k

i=1
1
√
2πe−1
2 z2
i dz.
We apply the substitution μ + Lz = x to this integral. The Jacobian ∂z/∂x of this
linear transformation is L−1; it has determinant det L−1 = (det Σ)−1/2. Moreover,
 z2
i = zT z = (x −μ)T Σ−1(x −μ). Hence we can rewrite the integral as

x:x≤b
1
(2π)k/2 e−1
2 (x−μ)T Σ−1(x−μ) (det Σ)−1/2 dx.
Since this is true for every b, the result follows from the deﬁnition of a probability
density.
It is often useful to "reduce" vectors to one-dimensional variables using linear
combinations. We can prove that the distribution of a vector X is completely
determined by the distributions of all linear combinations aT X, in the sense that two
k-dimensional random vectors X and Y are identically distributed if and only if the
random variables aT X and aT Y are identically distributed for all a ∈Rk. Using this
property, we can prove the following lemma concerning the normal distribution.
Lemma B.4
The random vector X has distribution Nk(μ, Σ) if and only if for every a ∈Rk, the
one-dimensional variable aT X has distribution N1(aT μ, aT Σa).
Proof. When X has the normal distribution Nk(μ, Σ), the parameters aT μ and aT Σa
are correct, because they are exactly the expectation and covariance of the variable
aT X. It therefore suﬃces to prove that aT X is normally distributed. Because X
has the same distribution as μ + LZ, the variable aT X has the same distribution as
aT μ+(LTa)T Z. The latter is a constant plus a linear combination bT Z of independent
variables with distribution N(0, 1) (for b = LT a). We know from probability theory
that such a linear combination is normally distributed.
350

B.3: Deﬁnition and Basic Properties
Conversely, when aT X has the normal distribution N1(aT μ, aT Σa), by the
argument we just gave, aT X has the same distribution as aT Y for an Nk(μ, Σ)-
distributed vector Y . If this holds for every a, then X and Y have the same distribution
because of the property mentioned before this lemma; hence X has distribution
Nk(μ, Σ).
Corollary B.5
If the vector X = (X1, . . . , Xk) has distribution Nk(μ, Σ) and A: Rk →Rm is an
arbitrary matrix, then AX has distribution Nm(Aμ, AΣAT ).
Proof. The parameters Aμ and AΣAT are correct because they are the expectation
and covariance matrix of AX. It suﬃces to prove that AX is normally distributed. For
every vector a, we have aT (AX) = (AT a)T X. This variable has a one-dimensional
normal distribution by Lemma B.4. Hence AX has a multivariate normal distribution
by Lemma B.4, now applied in the other direction.
Lemma B.4 and Corollary B.5 imply that the marginal distributions of a
multivariate normal distribution are again normal. Indeed, they are the distributions
of the linear combinations eT
i X for the unit vectors e1, . . . , ek. The converse is false:
it is possible that each of the variables X1, ˙ s, Xk has the normal distribution, while
the vector (X1, . . . , Xk) does not have the multivariate normal distribution.
A commonly used application of Corollary B.5 is that an orthogonal transfor-
mation of a standard normal vector again has a standard normal distribution: if O is
a k × k matrix with OT O = OOT = I and Z has distribution Nk(0, I), then OZ
also has distribution Nk(0, I) because O0 = 0 and OT IO = I. Geometrically, this
property means that the standard normal distribution is invariant under rotations.
We conclude with a surprising property of multivariate normal vectors. The
random variables X1, . . . , Xk are called uncorrelated if the covariance matrix
of (X1, . . . , Xk) is a diagonal matrix. Independent random variables are always
uncorrelated, but the converse does not hold in general. If the vector X
=
(X1, . . . , Xk) has a multivariate normal distribution, then the converse does hold.
Lemma B.6
The vector X = (X1, . . . , Xk) has a multivariate normal distribution with Σ a
diagonal matrix if and only if X1, . . . , Xk are independent and have normal marginal
distributions.
Proof. A symmetric, positive deﬁnite diagonal matrix Σ can be written as Σ = LLT
for L the diagonal matrix with entries the square roots of the diagonal entries of Σ.
Then, by deﬁnition, X has distribution Nk(μ, Σ) if it has the same distribution as
μ+ LZ = (μ1 +L11Z1, . . . , μk + LkkZk) for independent standard normal variables
Z1, . . . , Zk. Hence the coordinates of X are independent and normally distributed.
351

B: Multivariate Normal Distribution
Conversely, if X1, . . . , Xk are independent and have distribution N(μi, σ2
i ), then
X has the same distribution as (μ1 + σ1Z1, . . . , μk + σkZk) = μ + LZ, for L the
diagonal matrix with diagonal (σ1, . . . , σk). Hence X has distribution N(μ, LLT),
where LLT is a diagonal matrix.
B.4 Conditional Distributions
If (X, Y ) is a random vector with density (x, y) →f(x, y), then the conditional
distribution of X given Y = y is deﬁned as
x →fX|Y =y(x) =
f(x, y)

f(x, y) dx.
For a multivariate normally distributed random vector, these conditional distributions
are again normal.
For the sake of simplicity, we consider only two-dimensional normal distri-
butions. The proof of the following theorem can, however, easily be extended to
conditional distributions of higher-dimensional vectors. For a two-dimensional normal
vector (X, Y ), we write the expectation and covariance matrix as
(B.1)

μ
ν

,

σ2
ρστ
ρστ
τ 2

.
Then, σ2 and τ 2 are the variances van X and Y , respectively, and ρ is the correlation
coeﬃcient of X and Y .
Theorem B.7
If (X, Y ) has a two-dimensional normal distribution with expectation and covariance
matrix as in (B.1), then the conditional distribution of X given Y = y is equal to the
normal distribution with expectation μ −ρσν/τ + ρσy/τ and variance (1 −ρ2)σ2.
Proof. For a given λ ∈R, we can write X = X −λY + λY = Z + λY for
Z = X −λY . Then (Z, Y ) is a linear transformation of (X, Y ) and therefore has a
two-dimensional normal distribution. For λ = ρσ/τ, we have
cov(Z, Y ) = cov(X −λY, Y ) = ρστ −λτ 2 = 0.
By Lemma B.6 , we conclude that for the given value λ = ρσ/τ, the variables Z and
Y are independent; in other words, the conditional distribution of Z given Y = y is the
unconditional distribution of Z. The latter is the one-dimensional normal distribution
with expectation EZ = μ −λν = μ −ρσν/τ and variance var Z = σ2 + λ2τ 2 −
2λρστ = (1 −ρ2)σ2. The conditional distribution of X = Z + λY given Y = y is
then the unconditional distribution of Z + λy, which is the normal distribution with
expectation μ −ρσν/τ + ρσy/τ and variance (1 −ρ2)σ2.
352

B.5: Multivariate Central Limit Theorem
B.5 Multivariate Central Limit Theorem
The "usual" central limit theorem says that the average of a sequence of independent
random variables with ﬁnite variance is approximately normally distributed. More
precisely, if Y1, Y2, . . . is a sequence of independent, identically distributed random
variables with expectation μ and ﬁnite variance σ2, then for every x ∈R,
lim
n→∞P
√n(Y n −μ) ≤x

= Φ(x/σ).
We say that the sequence √n(Y n −μ) converges in distribution to N1(0, σ2).
This theorem is also true when the sequence Y1, Y2, . . . consists of random
vectors. We then deﬁne the average Y n as the vector whose coordinates are the
averages of the coordinates of the Yi. As parameters, we have an expectation vector
μ and a covariance matrix Σ. The central limit theorem for vectors states that the
sequence of vectors √n(Y n −μ) converges in distribution to Nk(0, Σ).
B.6 Derived Distributions
The chi-square distribution with k degrees of freedom is by deﬁnition the distribution
of k
i=1Z2
i for independent standard normal random variables Z1, . . . , Zk. The
sum of squares k
i=1Z2
i is exactly the Euclidean norm Z2 of the vector Z =
(Z1, . . . , Zk), which has a standard normal distribution. We conclude that the squared
norm of a k-dimensional standard normal distribution has a chi-square distribution
with k degrees of freedom.
If X has distribution Nk(μ, Σ) for a nonsingular matrix Σ and L is the
symmetric, positive deﬁnite square root of Σ, so that Σ = L2, then L−1(X −μ)
has the standard normal distribution. It follows that the quadratic form
(X −μ)T Σ−1(X −μ) =
L−1(X −μ)
2
has a chi-square distribution with k degrees of freedom.
The chi-square distribution also occurs as the distribution of the squared norm
of a projection of a multivariate normal distribution. A projection is a linear map
P: Rk →Rk of the following form. For a given orthonormal basis {f1, . . . , fk} of Rk
(not necessarily the standard basis!), we set Px = l
i=1 ξifi when x = k
i=1ξifi.
In other words, we "forget" the component of x in the space spanned by fl+1, . . . , fk.
We call P the projection onto the linear space spanned by f1, . . . , fl. The squared
norm of Px is Px2 = l
i=1 ξ2
i . The matrix I −P gives the projection onto the
space spanned by fl+1, . . . , fk: (I −P)x = k
i=l+1 ξifi.
353

B: Multivariate Normal Distribution
If Z has distribution Nk(0, I), then its coordinates Z1, . . . , Zk with respect to the
standard basis are independent and have distribution N(0, 1). Because of the rotation
invariance of the standard normal distribution, the coordinates ζ1, . . . , ζk with respect
to an arbitrary basis are also independent and also have distribution N(0, 1). For a
projection P as in the previous paragraph, it follows that PZ2 = l
i=1 ζ2
i has a
chi-square distribution with l degrees of freedom. This statement is part of Cochran's
theorem.
Consider a partition
{f 1
1 , . . . , f 1
i1}, {f 2
1, . . . , f 2
i2}, . . . , {f r
1, . . . , f r
ir}
of a given orthogonal basis {f1, . . . , fk}, with corresponding projections P1, . . . , Pr.
The linear subspaces H1, . . . , Hr spanned by the elements of this partition are
orthogonal, and P1, . . . , Pr map Rk exactly onto H1, . . . , Hr.
Theorem B.8 Cochran's theorem
Let P1, P2, . . . , Pr be orthogonal projections onto orthogonal subspaces H1, H2,
. . . , Hr as deﬁned above. If Z has distribution Nk(0, I), then P1Z, P2Z, . . . , PrZ
are independent random variables, and the random quantities P1Z2, . . . , PrZ2
have a chi-square distribution with, respectively, dim(H1), . . . , dim(Hr) degrees of
freedom.
It follows from this theorem that the quotients
PjZ2/ij
PlZ2/il
have F-distributions with ij and il degrees of freedom.
354

C Tables
This appendix contains some tables for the normal distribution, the t-distribution, the
chi-square distribution, and the binomial distribution with n = 10. They are meant
to be used when there is no computer available. These tables, and many more, can
be computed, for example in R, in a fraction of a second and to a higher degree of
precision than presented here.
355

C: Tables
C.1 Normal Distribution
0
1
2
3
4
5
6
7
8
9
0.0
0.5000
0.5040
0.5080
0.5120
0.5160
0.5199
0.5239
0.5279
0.5319
0.5359
0.1
0.5398
0.5438
0.5478
0.5517
0.5557
0.5596
0.5636
0.5675
0.5714
0.5753
0.2
0.5793
0.5832
0.5871
0.5910
0.5948
0.5987
0.6026
0.6064
0.6103
0.6141
0.3
0.6179
0.6217
0.6255
0.6293
0.6331
0.6368
0.6406
0.6443
0.6480
0.6517
0.4
0.6554
0.6591
0.6628
0.6664
0.6700
0.6736
0.6772
0.6808
0.6844
0.6879
0.5
0.6915
0.6950
0.6985
0.7019
0.7054
0.7088
0.7123
0.7157
0.7190
0.7224
0.6
0.7257
0.7291
0.7324
0.7357
0.7389
0.7422
0.7454
0.7486
0.7517
0.7549
0.7
0.7580
0.7611
0.7642
0.7673
0.7704
0.7734
0.7764
0.7794
0.7823
0.7852
0.8
0.7881
0.7910
0.7939
0.7967
0.7995
0.8023
0.8051
0.8078
0.8106
0.8133
0.9
0.8159
0.8186
0.8212
0.8238
0.8264
0.8289
0.8315
0.8340
0.8365
0.8389
1.0
0.8413
0.8438
0.8461
0.8485
0.8508
0.8531
0.8554
0.8577
0.8599
0.8621
1.1
0.8643
0.8665
0.8686
0.8708
0.8729
0.8749
0.8770
0.8790
0.8810
0.8830
1.2
0.8849
0.8869
0.8888
0.8907
0.8925
0.8944
0.8962
0.8980
0.8997
0.9015
1.3
0.9032
0.9049
0.9066
0.9082
0.9099
0.9115
0.9131
0.9147
0.9162
0.9177
1.4
0.9192
0.9207
0.9222
0.9236
0.9251
0.9265
0.9279
0.9292
0.9306
0.9319
1.5
0.9332
0.9345
0.9357
0.9370
0.9382
0.9394
0.9406
0.9418
0.9429
0.9441
1.6
0.9452
0.9463
0.9474
0.9484
0.9495
0.9505
0.9515
0.9525
0.9535
0.9545
1.7
0.9554
0.9564
0.9573
0.9582
0.9591
0.9599
0.9608
0.9616
0.9625
0.9633
1.8
0.9641
0.9649
0.9656
0.9664
0.9671
0.9678
0.9686
0.9693
0.9699
0.9706
1.9
0.9713
0.9719
0.9726
0.9732
0.9738
0.9744
0.9750
0.9756
0.9761
0.9767
2.0
0.9772
0.9778
0.9783
0.9788
0.9793
0.9798
0.9803
0.9808
0.9812
0.9817
2.1
0.9821
0.9826
0.9830
0.9834
0.9838
0.9842
0.9846
0.9850
0.9854
0.9857
2.2
0.9861
0.9864
0.9868
0.9871
0.9875
0.9878
0.9881
0.9884
0.9887
0.9890
2.3
0.9893
0.9896
0.9898
0.9901
0.9904
0.9906
0.9909
0.9911
0.9913
0.9916
2.4
0.9918
0.9920
0.9922
0.9925
0.9927
0.9929
0.9931
0.9932
0.9934
0.9936
2.5
0.9938
0.9940
0.9941
0.9943
0.9945
0.9946
0.9948
0.9949
0.9951
0.9952
2.6
0.9953
0.9955
0.9956
0.9957
0.9959
0.9960
0.9961
0.9962
0.9963
0.9964
2.7
0.9965
0.9966
0.9967
0.9968
0.9969
0.9970
0.9971
0.9972
0.9973
0.9974
2.8
0.9974
0.9975
0.9976
0.9977
0.9977
0.9978
0.9979
0.9979
0.9980
0.9981
2.9
0.9981
0.9982
0.9982
0.9983
0.9984
0.9984
0.9985
0.9985
0.9986
0.9986
3.0
0.9987
0.9987
0.9987
0.9988
0.9988
0.9989
0.9989
0.9989
0.9990
0.9990
3.1
0.9990
0.9991
0.9991
0.9991
0.9992
0.9992
0.9992
0.9992
0.9993
0.9993
3.2
0.9993
0.9993
0.9994
0.9994
0.9994
0.9994
0.9994
0.9995
0.9995
0.9995
3.3
0.9995
0.9995
0.9995
0.9996
0.9996
0.9996
0.9996
0.9996
0.9996
0.9997
3.4
0.9997
0.9997
0.9997
0.9997
0.9997
0.9997
0.9997
0.9997
0.9997
0.9998
3.5
0.9998
0.9998
0.9998
0.9998
0.9998
0.9998
0.9998
0.9998
0.9998
0.9998
3.6
0.9998
0.9998
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
3.7
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
3.8
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
0.9999
3.9
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
Table C.1. Distribution function of the normal distribution on the interval [0, 4]. The value in the
table is Φ(x) for x = a + b/100, where a is the value in the ﬁrst column and b is the value in the
ﬁrst row.
356

C.2: t-Distribution
C.2 t-Distribution
df
0.6
0.7
0.75
0.8
0.85
0.9
0.925
0.95
0.975
0.98
0.99
0.995
0.999
1
0.32
0.73
1.00
1.38
1.96
3.08
4.17
6.31
12.71
15.89
31.82
63.66
318.31
2
0.29
0.62
0.82
1.06
1.39
1.89
2.28
2.92
4.30
4.85
6.96
9.92
22.33
3
0.28
0.58
0.76
0.98
1.25
1.64
1.92
2.35
3.18
3.48
4.54
5.84
10.21
4
0.27
0.57
0.74
0.94
1.19
1.53
1.78
2.13
2.78
3.00
3.75
4.60
7.17
5
0.27
0.56
0.73
0.92
1.16
1.48
1.70
2.02
2.57
2.76
3.36
4.03
5.89
6
0.26
0.55
0.72
0.91
1.13
1.44
1.65
1.94
2.45
2.61
3.14
3.71
5.21
7
0.26
0.55
0.71
0.90
1.12
1.41
1.62
1.89
2.36
2.52
3.00
3.50
4.79
8
0.26
0.55
0.71
0.89
1.11
1.40
1.59
1.86
2.31
2.45
2.90
3.36
4.50
9
0.26
0.54
0.70
0.88
1.10
1.38
1.57
1.83
2.26
2.40
2.82
3.25
4.30
10
0.26
0.54
0.70
0.88
1.09
1.37
1.56
1.81
2.23
2.36
2.76
3.17
4.14
11
0.26
0.54
0.70
0.88
1.09
1.36
1.55
1.80
2.20
2.33
2.72
3.11
4.02
12
0.26
0.54
0.70
0.87
1.08
1.36
1.54
1.78
2.18
2.30
2.68
3.05
3.93
13
0.26
0.54
0.69
0.87
1.08
1.35
1.53
1.77
2.16
2.28
2.65
3.01
3.85
14
0.26
0.54
0.69
0.87
1.08
1.35
1.52
1.76
2.14
2.26
2.62
2.98
3.79
15
0.26
0.54
0.69
0.87
1.07
1.34
1.52
1.75
2.13
2.25
2.60
2.95
3.73
16
0.26
0.54
0.69
0.86
1.07
1.34
1.51
1.75
2.12
2.24
2.58
2.92
3.69
17
0.26
0.53
0.69
0.86
1.07
1.33
1.51
1.74
2.11
2.22
2.57
2.90
3.65
18
0.26
0.53
0.69
0.86
1.07
1.33
1.50
1.73
2.10
2.21
2.55
2.88
3.61
19
0.26
0.53
0.69
0.86
1.07
1.33
1.50
1.73
2.09
2.20
2.54
2.86
3.58
20
0.26
0.53
0.69
0.86
1.06
1.33
1.50
1.72
2.09
2.20
2.53
2.85
3.55
21
0.26
0.53
0.69
0.86
1.06
1.32
1.49
1.72
2.08
2.19
2.52
2.83
3.53
22
0.26
0.53
0.69
0.86
1.06
1.32
1.49
1.72
2.07
2.18
2.51
2.82
3.50
23
0.26
0.53
0.69
0.86
1.06
1.32
1.49
1.71
2.07
2.18
2.50
2.81
3.48
24
0.26
0.53
0.68
0.86
1.06
1.32
1.49
1.71
2.06
2.17
2.49
2.80
3.47
25
0.26
0.53
0.68
0.86
1.06
1.32
1.49
1.71
2.06
2.17
2.49
2.79
3.45
26
0.26
0.53
0.68
0.86
1.06
1.31
1.48
1.71
2.06
2.16
2.48
2.78
3.43
27
0.26
0.53
0.68
0.86
1.06
1.31
1.48
1.70
2.05
2.16
2.47
2.77
3.42
28
0.26
0.53
0.68
0.85
1.06
1.31
1.48
1.70
2.05
2.15
2.47
2.76
3.41
29
0.26
0.53
0.68
0.85
1.06
1.31
1.48
1.70
2.05
2.15
2.46
2.76
3.40
30
0.26
0.53
0.68
0.85
1.05
1.31
1.48
1.70
2.04
2.15
2.46
2.75
3.39
31
0.26
0.53
0.68
0.85
1.05
1.31
1.48
1.70
2.04
2.14
2.45
2.74
3.37
32
0.26
0.53
0.68
0.85
1.05
1.31
1.47
1.69
2.04
2.14
2.45
2.74
3.37
33
0.26
0.53
0.68
0.85
1.05
1.31
1.47
1.69
2.03
2.14
2.44
2.73
3.36
34
0.26
0.53
0.68
0.85
1.05
1.31
1.47
1.69
2.03
2.14
2.44
2.73
3.35
35
0.26
0.53
0.68
0.85
1.05
1.31
1.47
1.69
2.03
2.13
2.44
2.72
3.34
36
0.26
0.53
0.68
0.85
1.05
1.31
1.47
1.69
2.03
2.13
2.43
2.72
3.33
37
0.26
0.53
0.68
0.85
1.05
1.30
1.47
1.69
2.03
2.13
2.43
2.72
3.33
38
0.26
0.53
0.68
0.85
1.05
1.30
1.47
1.69
2.02
2.13
2.43
2.71
3.32
39
0.26
0.53
0.68
0.85
1.05
1.30
1.47
1.68
2.02
2.12
2.43
2.71
3.31
40
0.26
0.53
0.68
0.85
1.05
1.30
1.47
1.68
2.02
2.12
2.42
2.70
3.31
41
0.25
0.53
0.68
0.85
1.05
1.30
1.47
1.68
2.02
2.12
2.42
2.70
3.30
42
0.25
0.53
0.68
0.85
1.05
1.30
1.47
1.68
2.02
2.12
2.42
2.70
3.30
43
0.25
0.53
0.68
0.85
1.05
1.30
1.47
1.68
2.02
2.12
2.42
2.70
3.29
44
0.25
0.53
0.68
0.85
1.05
1.30
1.47
1.68
2.02
2.12
2.41
2.69
3.29
45
0.25
0.53
0.68
0.85
1.05
1.30
1.46
1.68
2.01
2.12
2.41
2.69
3.28
46
0.25
0.53
0.68
0.85
1.05
1.30
1.46
1.68
2.01
2.11
2.41
2.69
3.28
47
0.25
0.53
0.68
0.85
1.05
1.30
1.46
1.68
2.01
2.11
2.41
2.68
3.27
48
0.25
0.53
0.68
0.85
1.05
1.30
1.46
1.68
2.01
2.11
2.41
2.68
3.27
49
0.25
0.53
0.68
0.85
1.05
1.30
1.46
1.68
2.01
2.11
2.40
2.68
3.27
50
0.25
0.53
0.68
0.85
1.05
1.30
1.46
1.68
2.01
2.11
2.40
2.68
3.26
Table C.2. Quantiles of the t-distribution with 1 to 50 degrees of freedom.
357

C: Tables
C.3 Chi-Square Distribution
df
0.001
0.01
0.02
0.025
0.05
0.075
0.1
0.15
0.2
0.25
0.3
0.4
1
0.00
0.00
0.00
0.00
0.00
0.01
0.02
0.04
0.06
0.10
0.15
0.27
2
0.00
0.02
0.04
0.05
0.10
0.16
0.21
0.33
0.45
0.58
0.71
1.02
3
0.02
0.11
0.18
0.22
0.35
0.47
0.58
0.80
1.01
1.21
1.42
1.87
4
0.09
0.30
0.43
0.48
0.71
0.90
1.06
1.37
1.65
1.92
2.19
2.75
5
0.21
0.55
0.75
0.83
1.15
1.39
1.61
1.99
2.34
2.67
3.00
3.66
6
0.38
0.87
1.13
1.24
1.64
1.94
2.20
2.66
3.07
3.45
3.83
4.57
7
0.60
1.24
1.56
1.69
2.17
2.53
2.83
3.36
3.82
4.25
4.67
5.49
8
0.86
1.65
2.03
2.18
2.73
3.14
3.49
4.08
4.59
5.07
5.53
6.42
9
1.15
2.09
2.53
2.70
3.33
3.78
4.17
4.82
5.38
5.90
6.39
7.36
10
1.48
2.56
3.06
3.25
3.94
4.45
4.87
5.57
6.18
6.74
7.27
8.30
11
1.83
3.05
3.61
3.82
4.57
5.12
5.58
6.34
6.99
7.58
8.15
9.24
12
2.21
3.57
4.18
4.40
5.23
5.82
6.30
7.11
7.81
8.44
9.03
10.18
13
2.62
4.11
4.77
5.01
5.89
6.52
7.04
7.90
8.63
9.30
9.93
11.13
14
3.04
4.66
5.37
5.63
6.57
7.24
7.79
8.70
9.47
10.17
10.82
12.08
15
3.48
5.23
5.98
6.26
7.26
7.97
8.55
9.50
10.31
11.04
11.72
13.03
16
3.94
5.81
6.61
6.91
7.96
8.71
9.31
10.31
11.15
11.91
12.62
13.98
17
4.42
6.41
7.26
7.56
8.67
9.45
10.09
11.12
12.00
12.79
13.53
14.94
18
4.90
7.01
7.91
8.23
9.39
10.21
10.86
11.95
12.86
13.68
14.44
15.89
19
5.41
7.63
8.57
8.91
10.12
10.97
11.65
12.77
13.72
14.56
15.35
16.85
20
5.92
8.26
9.24
9.59
10.85
11.73
12.44
13.60
14.58
15.45
16.27
17.81
21
6.45
8.90
9.91
10.28
11.59
12.5
13.24
14.44
15.44
16.34
17.18
18.77
22
6.98
9.54
10.60
10.98
12.34
13.28
14.04
15.28
16.31
17.24
18.10
19.73
23
7.53
10.20
11.29
11.69
13.09
14.06
14.85
16.12
17.19
18.14
19.02
20.69
24
8.08
10.86
11.99
12.40
13.85
14.85
15.66
16.97
18.06
19.04
19.94
21.65
25
8.65
11.52
12.70
13.12
14.61
15.64
16.47
17.82
18.94
19.94
20.87
22.62
26
9.22
12.20
13.41
13.84
15.38
16.44
17.29
18.67
19.82
20.84
21.79
23.58
27
9.80
12.88
14.13
14.57
16.15
17.24
18.11
19.53
20.70
21.75
22.72
24.54
28
10.39
13.56
14.85
15.31
16.93
18.05
18.94
20.39
21.59
22.66
23.65
25.51
29
10.99
14.26
15.57
16.05
17.71
18.85
19.77
21.25
22.48
23.57
24.58
26.48
30
11.59
14.95
16.31
16.79
18.49
19.66
20.60
22.11
23.36
24.48
25.51
27.44
31
12.20
15.66
17.04
17.54
19.28
20.48
21.43
22.98
24.26
25.39
26.44
28.41
32
12.81
16.36
17.78
18.29
20.07
21.30
22.27
23.84
25.15
26.30
27.37
29.38
33
13.43
17.07
18.53
19.05
20.87
22.12
23.11
24.71
26.04
27.22
28.31
30.34
34
14.06
17.79
19.28
19.81
21.66
22.94
23.95
25.59
26.94
28.14
29.24
31.31
35
14.69
18.51
20.03
20.57
22.47
23.76
24.80
26.46
27.84
29.05
30.18
32.28
36
15.32
19.23
20.78
21.34
23.27
24.59
25.64
27.34
28.73
29.97
31.12
33.25
37
15.97
19.96
21.54
22.11
24.07
25.42
26.49
28.21
29.64
30.89
32.05
34.22
38
16.61
20.69
22.30
22.88
24.88
26.25
27.34
29.09
30.54
31.81
32.99
35.19
39
17.26
21.43
23.07
23.65
25.70
27.09
28.20
29.97
31.44
32.74
33.93
36.16
40
17.92
22.16
23.84
24.43
26.51
27.93
29.05
30.86
32.34
33.66
34.87
37.13
41
18.58
22.91
24.61
25.21
27.33
28.76
29.91
31.74
33.25
34.58
35.81
38.11
42
19.24
23.65
25.38
26.00
28.14
29.61
30.77
32.63
34.16
35.51
36.75
39.08
43
19.91
24.40
26.16
26.79
28.96
30.45
31.63
33.51
35.07
36.44
37.70
40.05
44
20.58
25.15
26.94
27.57
29.79
31.29
32.49
34.40
35.97
37.36
38.64
41.02
45
21.25
25.90
27.72
28.37
30.61
32.14
33.35
35.29
36.88
38.29
39.58
42.00
46
21.93
26.66
28.50
29.16
31.44
32.99
34.22
36.18
37.80
39.22
40.53
42.97
47
22.61
27.42
29.29
29.96
32.27
33.84
35.08
37.07
38.71
40.15
41.47
43.94
48
23.29
28.18
30.08
30.75
33.10
34.69
35.95
37.96
39.62
41.08
42.42
44.92
49
23.98
28.94
30.87
31.55
33.93
35.54
36.82
38.86
40.53
42.01
43.37
45.89
50
24.67
29.71
31.66
32.36
34.76
36.40
37.69
39.75
41.45
42.94
44.31
46.86
Table C.3. Quantiles of the chi-square distribution with 1 to 50 degrees of freedom.
358

C.3: Chi-Square Distribution
df
0.6
0.7
0.75
0.8
0.85
0.9
0.925
0.95
0.975
0.98
0.99
0.999
1
0.71
1.07
1.32
1.64
2.07
2.71
3.17
3.84
5.02
5.41
6.63
10.83
2
1.83
2.41
2.77
3.22
3.79
4.61
5.18
5.99
7.38
7.82
9.21
13.82
3
2.95
3.66
4.11
4.64
5.32
6.25
6.90
7.81
9.35
9.84
11.34
16.27
4
4.04
4.88
5.39
5.99
6.74
7.78
8.50
9.49
11.14
11.67
13.28
18.47
5
5.13
6.06
6.63
7.29
8.12
9.24
10.01
11.07
12.83
13.39
15.09
20.52
6
6.21
7.23
7.84
8.56
9.45
10.64
11.47
12.59
14.45
15.03
16.81
22.46
7
7.28
8.38
9.04
9.80
10.75
12.02
12.88
14.07
16.01
16.62
18.48
24.32
8
8.35
9.52
10.22
11.03
12.03
13.36
14.27
15.51
17.53
18.17
20.09
26.12
9
9.41
10.66
11.39
12.24
13.29
14.68
15.63
16.92
19.02
19.68
21.67
27.88
10
10.47
11.78
12.55
13.44
14.53
15.99
16.97
18.31
20.48
21.16
23.21
29.59
11
11.53
12.90
13.70
14.63
15.77
17.28
18.29
19.68
21.92
22.62
24.72
31.26
12
12.58
14.01
14.85
15.81
16.99
18.55
19.60
21.03
23.34
24.05
26.22
32.91
13
13.64
15.12
15.98
16.98
18.20
19.81
20.90
22.36
24.74
25.47
27.69
34.53
14
14.69
16.22
17.12
18.15
19.41
21.06
22.18
23.68
26.12
26.87
29.14
36.12
15
15.73
17.32
18.25
19.31
20.60
22.31
23.45
25.00
27.49
28.26
30.58
37.70
16
16.78
18.42
19.37
20.47
21.79
23.54
24.72
26.30
28.85
29.63
32.00
39.25
17
17.82
19.51
20.49
21.61
22.98
24.77
25.97
27.59
30.19
31.00
33.41
40.79
18
18.87
20.60
21.60
22.76
24.16
25.99
27.22
28.87
31.53
32.35
34.81
42.31
19
19.91
21.69
22.72
23.90
25.33
27.20
28.46
30.14
32.85
33.69
36.19
43.82
20
20.95
22.77
23.83
25.04
26.50
28.41
29.69
31.41
34.17
35.02
37.57
45.31
21
21.99
23.86
24.93
26.17
27.66
29.62
30.92
32.67
35.48
36.34
38.93
46.80
22
23.03
24.94
26.04
27.30
28.82
30.81
32.14
33.92
36.78
37.66
40.29
48.27
23
24.07
26.02
27.14
28.43
29.98
32.01
33.36
35.17
38.08
38.97
41.64
49.73
24
25.11
27.10
28.24
29.55
31.13
33.20
34.57
36.42
39.36
40.27
42.98
51.18
25
26.14
28.17
29.34
30.68
32.28
34.38
35.78
37.65
40.65
41.57
44.31
52.62
26
27.18
29.25
30.43
31.79
33.43
35.56
36.98
38.89
41.92
42.86
45.64
54.05
27
28.21
30.32
31.53
32.91
34.57
36.74
38.18
40.11
43.19
44.14
46.96
55.48
28
29.25
31.39
32.62
34.03
35.71
37.92
39.38
41.34
44.46
45.42
48.28
56.89
29
30.28
32.46
33.71
35.14
36.85
39.09
40.57
42.56
45.72
46.69
49.59
58.30
30
31.32
33.53
34.80
36.25
37.99
40.26
41.76
43.77
46.98
47.96
50.89
59.70
31
32.35
34.60
35.89
37.36
39.12
41.42
42.95
44.99
48.23
49.23
52.19
61.10
32
33.38
35.66
36.97
38.47
40.26
42.58
44.13
46.19
49.48
50.49
53.49
62.49
33
34.41
36.73
38.06
39.57
41.39
43.75
45.31
47.40
50.73
51.74
54.78
63.87
34
35.44
37.80
39.14
40.68
42.51
44.90
46.49
48.60
51.97
53.00
56.06
65.25
35
36.47
38.86
40.22
41.78
43.64
46.06
47.66
49.80
53.20
54.24
57.34
66.62
36
37.50
39.92
41.30
42.88
44.76
47.21
48.84
51.00
54.44
55.49
58.62
67.99
37
38.53
40.98
42.38
43.98
45.89
48.36
50.01
52.19
55.67
56.73
59.89
69.35
38
39.56
42.05
43.46
45.08
47.01
49.51
51.17
53.38
56.90
57.97
61.16
70.70
39
40.59
43.11
44.54
46.17
48.13
50.66
52.34
54.57
58.12
59.20
62.43
72.05
40
41.62
44.16
45.62
47.27
49.24
51.81
53.50
55.76
59.34
60.44
63.69
73.40
41
42.65
45.22
46.69
48.36
50.36
52.95
54.66
56.94
60.56
61.67
64.95
74.74
42
43.68
46.28
47.77
49.46
51.47
54.09
55.82
58.12
61.78
62.89
66.21
76.08
43
44.71
47.34
48.84
50.55
52.59
55.23
56.98
59.30
62.99
64.12
67.46
77.42
44
45.73
48.40
49.91
51.64
53.70
56.37
58.13
60.48
64.20
65.34
68.71
78.75
45
46.76
49.45
50.98
52.73
54.81
57.51
59.29
61.66
65.41
66.56
69.96
80.08
46
47.79
50.51
52.06
53.82
55.92
58.64
60.44
62.83
66.62
67.77
71.20
81.40
47
48.81
51.56
53.13
54.91
57.03
59.77
61.59
64.00
67.82
68.99
72.44
82.72
48
49.84
52.62
54.20
55.99
58.14
60.91
62.74
65.17
69.02
70.20
73.68
84.04
49
50.87
53.67
55.27
57.08
59.24
62.04
63.88
66.34
70.22
71.41
74.92
85.35
50
51.89
54.72
56.33
58.16
60.35
63.17
65.03
67.50
71.42
72.61
76.15
86.66
Table C.3. (Continued) Quantiles of the chi-square distribution with 1 to 50 degrees of freedom.
359

C: Tables
C.4 Binomial Distribution (n = 10)
p
0
1
2
3
4
5
6
7
8
9
10
0.01
904
996
1000
1000
1000
1000
1000
1000
1000
1000
1000
0.02
817
984
999
1000
1000
1000
1000
1000
1000
1000
1000
0.03
737
965
997
1000
1000
1000
1000
1000
1000
1000
1000
0.04
665
942
994
1000
1000
1000
1000
1000
1000
1000
1000
0.05
599
914
988
999
1000
1000
1000
1000
1000
1000
1000
0.06
539
882
981
998
1000
1000
1000
1000
1000
1000
1000
0.07
484
848
972
996
1000
1000
1000
1000
1000
1000
1000
0.08
434
812
960
994
999
1000
1000
1000
1000
1000
1000
0.09
389
775
946
991
999
1000
1000
1000
1000
1000
1000
0.1
349
736
930
987
998
1000
1000
1000
1000
1000
1000
0.11
312
697
912
982
997
1000
1000
1000
1000
1000
1000
0.12
279
658
891
976
996
1000
1000
1000
1000
1000
1000
0.13
248
620
869
969
995
999
1000
1000
1000
1000
1000
0.14
221
582
845
960
993
999
1000
1000
1000
1000
1000
0.15
197
544
820
950
990
999
1000
1000
1000
1000
1000
0.16
175
508
794
939
987
998
1000
1000
1000
1000
1000
0.17
155
473
766
926
983
997
1000
1000
1000
1000
1000
0.18
137
439
737
912
979
996
1000
1000
1000
1000
1000
0.19
122
407
708
896
973
995
999
1000
1000
1000
1000
0.2
107
376
678
879
967
994
999
1000
1000
1000
1000
0.21
95
346
647
861
960
992
999
1000
1000
1000
1000
0.22
83
318
617
841
952
990
998
1000
1000
1000
1000
0.23
73
292
586
821
943
987
998
1000
1000
1000
1000
0.24
64
267
556
799
933
984
997
1000
1000
1000
1000
0.25
56
244
526
776
922
980
996
1000
1000
1000
1000
0.26
49
222
496
752
910
976
996
999
1000
1000
1000
0.27
43
202
466
727
896
971
994
999
1000
1000
1000
0.28
37
183
438
702
882
966
993
999
1000
1000
1000
0.29
33
166
410
676
866
960
991
999
1000
1000
1000
0.3
28
149
383
650
850
953
989
998
1000
1000
1000
0.31
24
134
357
623
832
945
987
998
1000
1000
1000
0.32
21
121
331
596
813
936
984
997
1000
1000
1000
0.33
18
108
307
568
794
927
981
997
1000
1000
1000
0.34
16
96
284
541
773
916
978
996
1000
1000
1000
0.35
13
86
262
514
751
905
974
995
999
1000
1000
0.36
12
76
241
487
729
893
969
994
999
1000
1000
0.37
10
68
221
460
706
879
964
993
999
1000
1000
0.38
8
60
202
434
682
865
959
991
999
1000
1000
0.39
7
53
184
408
658
850
952
990
999
1000
1000
0.4
6
46
167
382
633
834
945
988
998
1000
1000
0.41
5
41
152
358
608
817
937
985
998
1000
1000
0.42
4
36
137
333
582
798
929
983
997
1000
1000
0.43
4
31
124
310
556
779
919
980
997
1000
1000
0.44
3
27
111
288
530
759
909
976
996
1000
1000
0.45
3
23
100
266
504
738
898
973
995
1000
1000
0.46
2
20
89
245
478
717
886
968
995
1000
1000
0.47
2
17
79
226
453
694
873
963
994
999
1000
0.48
1
15
70
207
427
671
859
958
992
999
1000
0.49
1
13
62
189
402
647
844
952
991
999
1000
0.5
1
11
55
172
377
623
828
945
989
999
1000
Table C.4. Cumulative probabilities (×1000) for the binomial distribution with parameters 10
and p going from 0.01 to 0.5.
360

C.4: Binomial Distribution (n = 10)
p
0
1
2
3
4
5
6
7
8
9
10
0.5
1
11
55
172
377
623
828
945
989
999
1000
0.51
1
9
48
156
353
598
811
938
987
999
1000
0.52
1
8
42
141
329
573
793
930
985
999
1000
0.53
1
6
37
127
306
547
774
921
983
998
1000
0.54
0
5
32
114
283
522
755
911
980
998
1000
0.55
0
5
27
102
262
496
734
900
977
997
1000
0.56
0
4
24
91
241
470
712
889
973
997
1000
0.57
0
3
20
81
221
444
690
876
969
996
1000
0.58
0
3
17
71
202
418
667
863
964
996
1000
0.59
0
2
15
63
183
392
642
848
959
995
1000
0.6
0
2
12
55
166
367
618
833
954
994
1000
0.61
0
1
10
48
150
342
592
816
947
993
1000
0.62
0
1
9
41
135
318
566
798
940
992
1000
0.63
0
1
7
36
121
294
540
779
932
990
1000
0.64
0
1
6
31
107
271
513
759
924
988
1000
0.65
0
1
5
26
95
249
486
738
914
987
1000
0.66
0
0
4
22
84
227
459
716
904
984
1000
0.67
0
0
3
19
73
206
432
693
892
982
1000
0.68
0
0
3
16
64
187
404
669
879
979
1000
0.69
0
0
2
13
55
168
377
643
866
976
1000
0.7
0
0
2
11
47
150
350
617
851
972
1000
0.71
0
0
1
9
40
134
324
590
834
967
1000
0.72
0
0
1
7
34
118
298
562
817
963
1000
0.73
0
0
1
6
29
104
273
534
798
957
1000
0.74
0
0
1
4
24
90
248
504
778
951
1000
0.75
0
0
0
4
20
78
224
474
756
944
1000
0.76
0
0
0
3
16
67
201
444
733
936
1000
0.77
0
0
0
2
13
57
179
414
708
927
1000
0.78
0
0
0
2
10
48
159
383
682
917
1000
0.79
0
0
0
1
8
40
139
353
654
905
1000
0.8
0
0
0
1
6
33
121
322
624
893
1000
0.81
0
0
0
1
5
27
104
292
593
878
1000
0.82
0
0
0
0
4
21
88
263
561
863
1000
0.83
0
0
0
0
3
17
74
234
527
845
1000
0.84
0
0
0
0
2
13
61
206
492
825
1000
0.85
0
0
0
0
1
10
50
180
456
803
1000
0.86
0
0
0
0
1
7
40
155
418
779
1000
0.87
0
0
0
0
1
5
31
131
380
752
1000
0.88
0
0
0
0
0
4
24
109
342
721
1000
0.89
0
0
0
0
0
3
18
88
303
688
1000
0.9
0
0
0
0
0
2
13
70
264
651
1000
0.91
0
0
0
0
0
1
9
54
225
611
1000
0.92
0
0
0
0
0
1
6
40
188
566
1000
0.93
0
0
0
0
0
0
4
28
152
516
1000
0.94
0
0
0
0
0
0
2
19
118
461
1000
0.95
0
0
0
0
0
0
1
12
86
401
1000
0.96
0
0
0
0
0
0
0
6
58
335
1000
0.97
0
0
0
0
0
0
0
3
35
263
1000
0.98
0
0
0
0
0
0
0
1
16
183
1000
0.99
0
0
0
0
0
0
0
0
4
96
1000
Table C.4. (Continued) Cumulative probabilities (×1000) for the binomial distribution with
parameters 10 and p going from 0.5 to 0.99.
361

D Answers to Exercises
1.1. model: X ∼bin(n, p), p ∈[0, 1], estimate: X/n
1.2. (i). Xi blood pressure change ith person in treatment group, Yj blood pressure change jth
person in control group, model: X1, . . ., Xn, Y1, . . ., Ym independent, Xi ∼N(μ1, σ2
1), Yi ∼
N(μ2, σ2
2)
(ii). estimate: xn −ym
1.3. (i). model: X ∼hyp(N, r, n) with N ≥max(r, n)
(ii). estimate: rn/X
(iii). model: X ∼bin(n, r/N) with N ≥max(r, n), estimate: rn/X
1.4. (i). model: X ∼neg −bin(3, p) with p ∈(0, 1]
(ii). estimate: 3/50
1.5. (i). Xij is the number of customers in week i on half-day j, where j has 11 possible values;
model: Xj ∼Poisson(θij) independent, with θij > 0
(ii). estimate: (1/10) 10
i=1 xij, where j corresponds to Monday afternoon
1.8. too long
1.9. not good, the estimate is too low
2.3. (i). yes
(ii). if Y ∼Fa,b, then b =
√
var Y and a = EY −
√
var Y
2.4. (i). F(x) = ((x + 3)/5)1−3<x<2 + 1x≥2
(ii). F−1(α) = −3 + 5α
2.5. (i). F(x) = x2/θ210<x<θ + 1x≥θ
(ii). F−1(α) = θ√α
2.6. y = 2 + 4x
2.7. y = 2 + 2x/3
2.10. 0
2.12. 1/
√
2
3.2. c = (n + 2)/(n + 1)
3.3. (i). c = 1
(ii). c2p(1 −p)/n + p2(c −1)2
(iii). c = pn/(1 −p + pn), not usable
(iv). c →1
362

D: Answers to Exercises
3.4. (i). no
(ii). many possibilities, including X
2 −X/n
3.5.
(ii). (m
i=1 Xi + n
j=1 Yj)/(m + n)
3.6. (i). pM = (2/3)p and pV = (4/3)p, MSE(p, (X + Y)/100) = p/100 −p2/90
(ii). MSE(p, Z/100) = p/100 −p2/100
(iii). (X + Y)/100 is better
3.8. X
3.9. (i). n/n
i=1 xa
i
(ii). n−1 n
i=1 xa
i
3.10. (i). θ/(θ + 1)
(ii). ˆθ = −n/ n
i=1 log(Xi) and

θ/(θ + 1) = ˆθ/(ˆθ + 1)
3.11. 1/Y
3.12. (i). X(1)
(ii). no
(iii). MSE(θ; X(1)) = θ2/((n −1)(n −2))
3.14. 
X, Y, (m + n −2)−1 m
i=1(Xi −X)2 + n
j=1(Yj −Y)2
3.16. X(1)
3.17. (i). hyp(N, r, n)
(ii). rn/x (round down to the nearest integer)
3.18. (i). bin(n, F(x))
(ii). yes
(iii). F(x)(1 −F(x))/n
3.20. (i). X
2
(ii). X
2
(iii). (n/(n + 1))X
2
3.21. ˆp = X in both cases
3.22. (i). ˆp = X
(ii). (n/(n −1)X
2 −(1/(n −1))X, for example, is unbiased
3.23. ˆp = 1/X
3.24. (X + 1)/X
3.25. (i). 3X/2
(iii). (3X/2)2
(iv). (18n/(8n + 1))X
2, for example, is unbiased
3.26. (i). 2X −1
(ii). X(n)
3.27. (i). ( ˆσ, ˆτ) = (X(1), X(n))
(ii). ( ˆσ, ˆτ) = (X −(3X
2/2 −3X2)1/2, X + (3X
2/2 −3X2)1/2)
3.28. (i). max(|X(1)|, X(n))
(ii). (3X2)1/2
3.31. (i). θ
(ii). the sample median: med(X1, . . ., Xn)
(iii). X
3.33. (i). X/(1 −X)
(ii). −n/ n
i=1 log Xi
(iii). posterior distribution Γ(n+1, 1−n
i=1 log Xi), Bayes estimator (n+1)/(1−n
i=1 log Xi)
3.34.
(ii). posterior distribution Γ(n + r, λ + n
i=1 |Xi|), Bayes estimator (n + r)/(λ + n
i=1 |Xi|)
3.35. beta(α + r, β + x −r)
363

D: Answers to Exercises
3.36. (n −1)/(n −2)(X−(n−2)
(n)
−M−(n−2))/(X−(n−1)
(n)
−M−(n−1))
3.37. (i). posterior distribution Γ(X + 1, λ + 1), Bayes estimator (X + 1)/(λ + 1)
(ii). posterior distribution Γ(X + α, λ + 1), Bayes estimator (X + α)/(λ + 1)
3.38. posterior distribution Γ(α + n, λ + n
i=1 X2
i ), Bayes estimator (α + n)/(λ + n
i=1 X2
i )
3.39. normal posterior distribution, Bayes estimator (τ2 n
i=1 Xi)/(nτ2 + 1)
3.40. (i). beta(α + n
i=1 Xi, n + β −n
i=1 Xi)
(ii). (α+n
i=1 Xi)/(α+β+n) and 
(α+n
i=1 Xi)(n+β−n
i=1 Xi)
/
(α+β+n)(α+β+n+1)
4.1. X1, . . ., Xn ∼N(μ, σ2), H0: μ = 125 versus H1: μ = 125 (Another possible hypothesis is:
H0: μ ≥125 versus H1: μ < 125)
4.3. (i). X ∼bin(nj, pj) with nj the size of the sample of boys, pj the proportion of boys
that choose mathematics, Y ∼bin(nm, pm) with nm the size of the sample of girls, pm the
proportion of girls that choose mathematics. H0: pj ≤pm versus H1: pj > pm
4.4. Y ∼N(α + βx1 + γx2, σ2). H0: β = 0 versus H1: β = 0
4.6. (i). H0: μ ≤200 versus H1: μ > 200 (a): do not reject H0, (b): reject H0
(ii). H0: μ ≤220 versus H1: μ > 220 (a): do not reject H0, (b): reject H0
4.7. X1, . . ., X100 ∼N(μ, 1), H0: μ ≥50 versus H1: μ < 50, H0 is not rejected
4.8. (i). K = {x: √n(x −0)/σ ≥1.64} = {x: x ≥0.66}
(ii). no, H0 is not rejected
(iii). π(0.5; K) = 0.34
(iv). 0.058
4.9. (i). reject H0
(ii). 0.0008
4.11. (i). X ∼bin(25, p), p ∈[0, 1], H0: p ≥0.6 versus H1: p < 0.6, T = X, K = {17, . . ., 25}
(ii). 0.055
(iii). 0.27
(iv). 0.12
(v). no, do not reject H0 for either value of α0
4.12. (i). T = X, K = {20, . . ., 25}
(ii). π(0.6; K) ≈0.034, π(0.7; K) ≈0.19, π(0.8; K) ≈0.60, π(0.9; K) ≈0.98 with normal
approximation
(iii). 0.034 with normal approximation
4.13. (i). e = 59, K = {59, 60, . . ., 100}
(ii). equal
4.14. (i). X ∼bin(n, p) with n = 250
(ii). H0: p ≥0.035 versus H1: p < 0.035
(iii). K = {0, 1, 2, 3}
(iv). 0.13
(v). more observations
4.15. n ≥213
4.16. n ≥35
4.17. n ≥263
4.18. (i). ˆp = 30
i=1 Yi/1800
(ii). the p-value equals 0.30, the null hypothesis is not rejected
4.19. α ≥0.215
4.20. (i). X ∼bin(n, p) with n = 1000, H0: p ≤0.9 versus H1: p > 0.9
4.21. (i). T = n
i=1 Wi ∼bin(n, p), two-sided binomial test
(ii). T = √n(Z −0)/S Z, two-sided t-test with KT = (−∞, −ξα0/2] ∪[ξα0/2, ∞)
(iv). there need not be a mistake, because the p-values can diﬀer; under the assumption of
part (iii) we go with the second statistician, whose test is more powerful
364

D: Answers to Exercises
4.22. T = X(1) with KT = (−∞, −(log 0.9)/n]
4.27. MSE(σ2; Tc) = σ4(2c2/(n −1) + (c −1)2), minimal for c = (n −1)/(n + 1)
4.28. X ∼χ2
k and Y ∼χ2
l , so X + Y ∼χ2
k+l
4.29. T = S 2
X/S 2
Y, KT = [Fm−1,n−1;1−α0, ∞)
4.30. (i). T = S 2
X/(2S 2
Y), KT = [0, F24,15;0.01] = [0, 0.346]. do not reject H0
(ii). 0.0728
4.34. T =
√
5(X −800)/S X, KT = (−∞, t4,0.05] = (−∞, −2.13], do not reject H0
4.35. (i). X1, . . .X20 ∼N(μ, σ2) independent, identically distributed. H0: μ = 3585 versus H1: μ =
3585. test: T =
√
20(X −3585)/S X, KT = (−∞, t19,0.025] ∪[t19,0.975, ∞) = (−∞, −2.09] ∪
[2.09, ∞), do not reject H0
(ii). p ≈2 × (1 −0.6368) = 0.73 > 0.05 based on the normal table. Do not reject
4.36. T = (X −Y)/S X,Y × (1/20 + 1/32)−1/2, KT = (−∞, t50,0.025] ∪[t50,0.975, ∞) = (−∞, −2.01] ∪
[2.01, ∞), reject H0, drug B is better
4.37. T =
√
10(Z −0)/S Z, KT = (−∞, t9,0.05] = (−∞, −1.83], do not reject H0
4.38. method (2)
4.39. (i). T =
√
3(X −Y)/S X,Y, KT = (−∞, t10,0.05]∪[t10,0.95, ∞) = (−∞, −1.81]∪[1.81, ∞), do not
reject H0
(ii). T =
√
6(Z −0)/S Z, KT = (−∞, t5,0.05] ∪[t5,0.95, ∞) = (−∞, −2.02] ∪[2.02, ∞), reject
H0, brand B lasts longer
4.40. (i). T =
√
12(X −150)/S X, KT = (−∞, t11,0.05] = (−∞, −1.80], reject H0
(ii). two-sample t-test with T = (X −Y)/S X,Y(1/12 + 1/10)−1/2, KT = (−∞, t20,0.05] =
(−∞, −1.72], do not reject H0
4.41. (i). H0: μ ≤10 versus H1: μ > 10, test: T =
√
10(X −10)/σ, KT = [ξ0.95, ∞) = [1.64, ∞), do
not reject H0
(ii). n ≥39
4.42. paired t-test, T =
√
20(Z −0)/S Z, KT = (−∞, t19,0.005] ∪[t19,0.995, ∞) = (−∞, −2.86] ∪
[2.86, ∞), reject H0, p-value between 2 × 0.005 = 0.01 and 2 × 0.001 = 0.002
4.45. 1/3
4.47. (i). λn = 1 if X(1) ≤0 and λn = exp(nX(1)) if X(1) > 0
(ii). 2 log λ = 2n max(X(1), 0). If θ < 0, the limit distribution is degenerate at 0. If θ = 0, the
limit distribution is exp(1/2). If θ > 0, the sequence tends to ∞.
4.48. (i). λn = 1 if θ0 ≥X(n) and λn = ∞if θ0 < X(n)
(ii). λn = θn
0/Xn
(n) if θ0 ≥X(n) and λn = ∞if θ0 < X(n)
4.49. (i). λn = (X/θ0)nX exp(−nX + nθ0)
(ii). χ2
1
4.50. (i). λn = (θ0
n
i=1 X2
i /n)−n exp(−n + θ0
n
i=1 X2
i )
(ii). K = {(X1, . . ., Xn): 2 log λn ≥χ2
1,1−α0}
5.1. [17.42, 19.80]
5.2. [17.32, 19.90]
5.3. (i). μ −ν = X −Y ± σ√1/m + 1/n ξ1−α/2
(ii). μ −ν = X −Y ± S X
√1/m + 1/n tm+n−2,1−α/2
5.4. pivot T = (n −1)S 2
X/σ2 ∼χ2
n−1, interval [(n −1)S 2
X/χ2
n−1,1−α/2, (n −1)S 2
X/χ2
n−1,α/2]
5.5. [0.27,0.46]
5.6. pivot T = (S 2
Y/τ2)/(S 2
X/σ2) ∼Fn−1,m−1, interval [S 2
X/S 2
YFn−1,m−1;α/2, S 2
X/S 2
YFn−1,m−1;1−α/2]
5.7. (i). pivot T = n
i=1 λXi ∼Gamma(n, 1), interval
Γn,1;α/2/ n
i=1 Xi, Γn,1;1−α/2/n
i=1 Xi

(ii). λ = 1/X ± ξ1−α/2/(√nX)
5.8. (i). exact interval based on test: [0.40, 1.44]
(ii). approximate interval: X ±

X/10ξ1−α/2 = [0.33, 1.27]
365

D: Answers to Exercises
5.9.
(ii). [(2 n
i=1 X2
i )−1χ2
2n,α/2, (2n
i=1 X2
i )−1χ2
2n,1−α/2]
5.11. (i). (p2(1 −p))−1
(ii). X
3/(X −1)
(iii). p = 1/X ± (X −1)1/2n−1/2X
−3/2 ξ1−α/2
(iv). [0.30, 0.50]
5.12. (i). (p(1 −p))−1
(ii). (X(1 −X))−1
(iii). p = X ±

X(1 −X)/nξ1−α/2
(iv). [0.23, 0.41]
5.13. (i). 2/X
(ii). iθ = 2/θ2, iˆθ = X
2/2
(iii). iθ = X
2/2
(iv). θ = 2/X ± √2/n/X ξ1−α/2
5.14. (i). ˆλ = X/2
(ii). λ = X/2 ± X/(2
√
2n)ξ1−α/2
5.15. (i). exact interval based on test: [0.51, 0.87]
(ii). approximate interval: X ± (X(1 −X)/n)1/2 ξ1−α/2 = [0.54, 0.9]
5.16. (i). ˆθ = 2/X and λn = (θ0X/2)−2n exp(−2n + θo
n
i=1 Xi)
(ii). {θ: −2n log 2 + 2n log(θX) + 2n −θ n
i=1 Xi ≥−χ2
1,1−α/2}
5.17. (i). ˆθ = n/n
i=1
√
Xi
(ii). λn = (θ0
√
X)−n exp(−n + θ0
n
i=1
√Xi)
(iii). {θ: n log(θ
√
X) + n −θ n
i=1
√Xi ≥−χ2
1,1−α/2}
5.18. ˆθ = X/2+(X
2+4X2)1/2/(2n), λn = (θ0/ˆθ)n exp(−n
i=1(Xi−ˆθ)2/(2ˆθ2)+n
i=1(Xi−θ0)2)/(2θ2
0)),
c.i. {θ: −n log θ −n
i=1(Xi −θ)2/(2θ2) + n log ˆθ + n
i=1(Xi −ˆθ)2/(2ˆθ2) ≥−χ2
1,1−α/2}
5.19. (i). pivot n
i=1(Xi −μ)2/σ2 ∼χ2
50, c.i. n
i=1(Xi −μ)2/χ2
50,0.975,n
i=1(Xi −μ)2/χ2
50,0.025

=
[3.36, 7.42]
(ii). pivot n
i=1(Xi −X)2/σ2 ∼χ2
49, c.i. n
i=1(Xi −X)2/χ2
49,0.975,n
i=1(Xi −X)2/χ2
49,0.025

=
[3.35, 7.45]
5.20. (i). near-pivot (X/200 −Y/725 −(p1 −p2))/ ˆσ ∼N(0, 1), for ˆσ2 = ˆp1(1 −ˆp1)/200 + ˆp2(1 −
ˆp2)/725, c.i. ˆp1 −ˆp2 ± ˆσ ξ0.975
(ii). realized interval: [-0.011,0.142], do not reject H0, because 0 ∈[−0.011, 0.142]
6.1. n
i=1 Xi
6.2. n
i=1 Xi
6.3. n
i=1 log Xi
6.5. (n
i=1 Xi,n
i=1 X2
i )
6.6. (n
i=1 Xi, X(1))
6.11. yes
6.13. X
6.14. X(X −1)/(n(n −1))
6.15. (n
i=1 Xi,n
i=1 X2
i ) is suﬃcient and complete, UMVU for σ2 is X
2 −S 2
X/n
6.16. X
2 −X/n
6.17. (i). X(1)
(ii). (n −1)/n X(1)
6.18. (n + 2)/n X2
(n)
6.19. (i). (X(1),n
i=1 Xi)
(ii). n
i=1(Xi −μ)/n
366

D: Answers to Exercises
6.20. (i). yes
(ii). V(X1, . . ., Xn) = (n
i=1 log Xi,n
i=1 log(1 −Xi))
(iii). n−1 n
i=1 log Xi
6.21. X −Y
6.24. (i). (X(1),n
i=1 Xi)
6.25.
(ii). no
(iii). α = mτ2/(nσ2 + mτ2)
(iv). (m
i=1 Xi + n
j=1 Yj)/(m + n) is then UMVU for μ
6.26. varθ(Tn) ≥θ/n is sharp
6.27. (i). x2
1
(ii). n
i=1 x2
i
(iii). varθ(Tn) ≥(n
i=1 x2
i )−1
(iv). yes
6.28. iθ = (1 + 2θ)/(2θ2), varθ(Tn) ≥2θ2/(n(1 + 2θ))
6.29. (i). varθ(Tn) ≥1/(nλ2)
6.30. (i). varλ(Tn) ≥1/(nkλ2)
6.32. (i). T = n
i=1 eXi −n with KT = [0, Γn,1;α0]
(ii). T = n
i=1 eXi −n with KT = [0, Γn,1;α0]
6.33. (i). ψ(x) = 1x(1)≤2 + 4n(4n −1)−1(0.05 −4−n)1x(1)>2 if n is suﬃciently large that 0.05 > 4−n
(ii). ψ(x) = 11/2<x(1)≤1 + 0.05 × 1x(1)>1
6.34. (i). ψ(x) = 1x(1)>2 + 0.05 × 1x(1)≤2
(ii). ψ(x) = 1x(1)>2 + 0.05 × 1x(1)≤2
7.1. (the duration is the response variable Y) (i). Y = α + βx + e, ˆα = 109, ˆβ = −5.6
(ii). 0.14
7.3. ˆα + ˆβx
7.6. ˆβ = (n
i=1 xiYiz−1
i
−n
i=1
n
j=1 xiYj(zizjZ)−1)/(n
i=1 x2
i z−1
i
−n
i=1
n
j=1 xixj(zizjZ)−1), ˆα =
(n
i=1 Yiz−1
i
−ˆβn
i=1 xiz−1
i )/Z, ˆσ2 = n−1 n
i=1(Yi −ˆα −ˆβxi)2z−1
i , with Z = n
i=1 z−1
i
7.7. the vector (n
i=1 Yi, n
i=1 Y2
i ,n
i=1 Yixi) is suﬃcient
7.8. (i). Yi = βxi + ei with xi = √li and β = 2π/√g
(ii). ˆβ = n
i=1 Yixi/n
i=1 x2
i
(iii). var(ˆβ) = σ2/n
i=1 x2
i
(iv). long
7.10. Additive: Yijkl = μ + αi + βj + γk + eijkl, possibly extended with interactions
7.11. (i). P(Y = 1| X1, X2, X3) = (x1, x2, x3)) = (1 + e−β0−β1x1−β2x2−β3x3)−1, with X1 the blood
pressure, X2 = 0 if a man and X2 = 1 if a woman, X3 = 0 if genotype (A1, A2) or (A2, A2)
and X3 = 0 if genotype (A1, A1).
(ii). as in (i), but with X3 equal to the number of alleles A2
7.13. λ(t) = λ0(t)eβ0+β1x1+β2x2+β3x3+β4x4 with X1 the age, X2 the weight, X3 = 0 if man and X3 = 1
if woman, X4 = 0 if mechanical and X3 = 1 if biological.
A.1. EX2 = θ + θ2
A.2. For X ∼Poisson(θ), we have E(X(X −1)(X −2)) = θ3, which equals 1 when θ = 1.
A.3. √e
A.4. If X, Y ∼exp(θ), then Z = max(X, Y) has density 2θe−θz(1 −e−θz) for z > 0 and EZ =
2/θ −1/(2θ). If θ = 1, then EZ = 3/2.
A.6. (i). P(X + Y ≤2) = Φ
1/
√
3
= 0.718
(ii). ξ = 1 +
√
3Φ−1(0.95) = 3.849
A.7. If Z = X2 + Y2, then P(Z ≤z) = 1 −e−z/2.
367

D: Answers to Exercises
A.8.
(iii). ex2−y for y > x2
(iv). E(Y| X = x) = x2 + 1
(v). EY = 3/2
A.10. EY = n/(n + 1), var Y = n/(n + 2) + (n/(n + 1))2
A.11. EXn = μ, var Xn = σ2/n, E(Xn)2 = σ2/n + μ2, cov(Xi −Xn, Xn) = 0
A.13. P(X ≤30) ≈0.898 (with continuity correction)
A.14. P(Xn ≥4.5) ≈0.868 (without continuity correction)
368

Index
additive model, 278, 284
Akaike information criterion (AIC), 313,
324
α-point, 28
α-quantile, 27, 28
alternative hypothesis, 106
analysis of variance, 299
analysis of variance table, 281
ANOVA, 275
Bayes criterion, 219
Bayes estimator, 93
Bayes factor, 318
Bayesian model selection., 324
Bayes risk, 76
Behrens-Fisher problem, 136
Benjamini and Hochberg, 155
Bernoulli distribution, 334
Bernstein-von Mises theorem, 201
beta densities, 80
beta distribution, 337
beta function, 337
bias, 49, 93
BIC penalty, 321,324
binomial distribution, 334
Bonferroni correction, 153
boxplot, 25,38
categorical predictor variable, 268
Cauchy distribution, 338
causal, 209
causal explanation, 303
censored data, 10, 292
chi-square distribution, 128, 338
classiﬁcation, 286
coeﬃcient of determination, 265
collinear, 271
complete, 222, 245
conditional density, 341
conditional probability, 340
conﬁdence intervals, 175
conﬁdence level, 205
conﬁdence region, 174, 205
confounding factors, 304
conservative, 153
consistent, 187, 320
continuity correction, 343
continuous distribution, 330
converges in distribution, 342
converges in probability, 342
counterfactual variables, 305
covariance, 333
covariance matrix, 348
covariates, 286
Cox estimator, 293
Cox model, 291
Cox regression model, 299
Cram´er-Rao lower bound, 228, 245
credible region, 201
critical region, 108, 159
critical values, 113
cross-validation, 322, 324

cumulative distribution function, 331
density, 331
dependent variable, 259, 299
descriptive statistics, 1
design matrix, 268
detailed balance, 84
deviance, 289
discrete distribution, 330
disjoint, 330
dispersion, 332
distribution-free tests, 138
distribution function, 331
double exponential distribution, 97
dummy variables, 268
EM, 68
empirical distribution function, 140
estimate, 45, 93
estimating equations, 89
estimator, 45, 93
expectation, 332
expectation-maximization algorithm, 68
expectation vector, 348
expected value, 332
explained variance, 265
exponential distribution, 336
exponential family, 223
extreme value distribution, 10
factor, 275
F-distribution, 164, 338
Fisher information, 182, 205, 227
Fisher information matrix, 228
Fisher's scoring, 67, 68
ﬁtted regression line, 265
ﬁxed eﬀects, 296
Fourier series, 284
Fr´echet family, 10
frailty model, 298
F-test, 164
gamma distribution, 337
gamma function, 337
Gauss test, 114
GEE, 92
generalized estimating equations, 92
generalized method of moments, 75
geometric distribution, 335
Gibbs sampler, 85
goodness-of-ﬁt tests, 138
hat matrix, 271
hazard function, 290
heteroscedastic, 300
histogram, 23, 38
hypergeometric distribution, 335
ideal test, 159
identiﬁable, 182
inadmissible, 49
independent, 134, 340
independent variable, 259
indicator function, 23
interaction eﬀects, 276
intercept, 262
interquartile range, 22, 25
interval estimate, 174
inverse image, 330
joint distribution, 338
k-fold cross-validation, 322
k-means clustering, 70, 96
Kolmogorov-Smirnov test, 140
Kullback-Leibler divergence, 314, 324
Lagrange multiplier test, 152
Laplace distribution, 97
latent variable, 296
learning, 287
least-squares estimators, 264
leave-one-out cross-validation, 322
left one-sided, 113
level, 110
likelihood equations, 56, 93
likelihood function, 55, 93
likelihood ratio region, 205
likelihood ratio statistic, 143, 159
likelihood ratio test, 159
linear mixed model, 295
linear regression model, 261, 299
location, 332
location-scale family, 26
logistic regression model, 286, 299
log-likelihood function, 55
longitudinal analysis, 296
main eﬀects, 276
Mann-Whitney U test, 138
marginal distribution, 339
marginal probability density, 339
marginal probability density function, 339
Markov Chain Monte Carlo, 83
maximum likelihood estimate, 55, 93
maximum likelihood estimator, 55, 93,
205
maximum (or minimum) contrast

estimator, 89
MCMC, 83
mean absolute deviation, 99
mean square error, 48, 93
median, 25
M-estimator, 89
method of moments estimator, 93
method of the intrinsic Bayes factor, 318
Metropolis-Hastings, 85
minimally suﬃcient, 216
minimal sample size, 118
minimax, 220
minimax criterion, 219
minimum-variance unbiased estimators,
220
missing data, 68
mixed model, 295
model averaging, 317
moment, 72
monotone likelihood ratio, 240, 245
moving average, 256
MSE, 48
multinomial distribution, 334
multiple linear regression model, 268
multivariate normal distribution, 349
multivariate probability density, 339
multivariate probability density function,
339
near-pivot, 179, 181, 205
negative binomial distribution, 335
Neyman-Pearson lemma, 245
Neyman-Pearson tests, 232
nominal size, 137
nominal variable, 268
nonlinear model, 299
nonlinear regression, 283
nonlinear regression model, 90
nonparametric regression, 284
nonparametric test, 159
normal distribution, 336
normal equation, 270
null hypothesis, 106
observational data, 304
observed information, 68, 183
observed signiﬁcance level, 123
one-sided null hypothesis, 113
oracle inequalities, 315
order statistics, 29
overall size, 154
paired, 134
parameterized, 12
penalty, 313
penalty methods, 324
pivot, 177, 205
plug-in estimator, 183
point estimates, 174
Poisson distribution, 335
population correlation coeﬃcient, 33
population median, 97
posterior density, 78, 93
posterior probability distribution, 76
post-model selection estimation, 323
power function, 110
practically signiﬁcant, 127
predictor variable, 259, 299
prior probability distribution, 76
probability density function, 331
probability distribution, 329
probit regression, 286
proﬁle likelihood function, 200
projection, 270, 353
p-value, 121, 122, 123, 159
QQ-plot, 29, 38
quantile function, 27
random eﬀects, 296
randomized statistic, 217
randomized test, 234
randomized trial, 304
random variable, 329
random walk kernel, 86
ranks, 138
regression, 259
regression equation, 283
regression model, 299
regression to the mean, 266
REML, 298
residuals, 265, 271
residual sum of squares, 265, 271, 280
restricted maximum likelihood estimation,
298
reversible, 84
right one-sided, 113
risk function, 290
robustness, 90
robust regression, 264
sample, 2
sample autocorrelation coeﬃcient, 34, 38
sample correlation coeﬃcient, 32, 38

sample mean, 22, 38
sample median, 22, 89
sample moment, 72
sample space, 330
sample standard deviation, 38
sample variance, 22, 38
scatter plot, 32, 38
score function, 56, 182, 205
score test, 150, 168
s.e., 181
σ-additivity, 330
signiﬁcance level, 110
simple linear regression model, 262
Simpson's paradox, 304
size, 110, 159
standard error, 50, 181
standard normal distribution, 336, 349
stationary density, 84
stationary distribution, 84
statistic, 45
statistically signiﬁcant, 127
statistical model, 2
(statistical) power function, 159
statistical test, 108
step-down method, 312
step-up method, 312
strata, 53
stratiﬁed sample, 53
Student's t-distribution, 128, 338
Student's t-test, 132
suﬃcient, 213, 216, 245
survival analysis, 15, 290
t-distribution, 128, 338
test, 159
test methods, 324
test statistic, 108, 159
total sum of squares, 265, 271, 280
training, 287
training data, 322, 324
training sample, 287
transition density, 84
transition kernel, 83
trend test, 256
t-test, 132
two-sample problem, 134
two-sided null hypothesis, 113
type I error, 106, 159
type II error, 106, 159
UMP, 236
UMVU, 221
unbiased, 49, 241
unbiased tests, 116
uniform distribution, 336
uniformly minimum-variance unbiased,
221, 245
uniformly most powerful, 236, 245
uniformly most powerful test, 111
vague prior distribution, 318
validation data, 322, 324
variance, 333
volatility, 170
Wald interval, 183
Wald statistics, 152
Wald test, 152
Weibull, 291
Weibull distribution, 95
whiskers, 25
Wilcoxon test, 138

