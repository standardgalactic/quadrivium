Chapter 8 is called Active Inferencing Continuous Time. Begins with that timeless quote,
everything flows, nothing stands still. So what would you say about Chapter 8?
All right, so this chapter probably is my most favorite chapter in the book because of my
own personal interests in, I don't know, the process materials and so on. But,
yeah, so Chapter 7 acts as a really good starting point for anyone who wants to
develop the discrete time situations, to model discrete time situations
within Active Inference Framework. But in Chapter 8, we kind of get to
model a bit more interesting or, let's say, more involving situations. And they're not necessarily
kind of toy examples we saw at least at the beginning of Chapter 7. So,
obviously, as the title suggests, this chapter deals with the continuous time situations. So,
in that case, we need to, maybe at this point, refresh our memory about what continuous time
situation involves by reading the relevant parts, reading or reviewing the relevant parts of Chapter
4. So, yeah, in Chapter 4, we saw that the generative model for continuous time situation
derives from the idos-stochastic calculus in terms of putting the whole process
into two elements of stochastic equations, one of which is the actual state, the condition of
actual states, or the behavior of the actual states, and the other one is the randomness
that we need to account for in each real-time continuous time situations. So, that's what we
get here in equation 8.1. And then, building up from that equation, it generalizes that equation to
involve, I mean, the functionals of g and f instead of just the single-valued functions of g and f. So,
then we get to put that into the situation that can be used for describing the behavior of dynamical
systems, which is a very well-known situation to use, these kinds of stochastic equations,
and it's widely studied how those kinds of dynamics can be characterized, especially in
recent Bayesian mechanics paper by Dalton, Saktivadevel and others. So, and then it gets to some more
specific examples, such as lat-cabal-terra dynamics and synchronicity and so on, in order to show
how these kinds of dynamics can be elaborated upon and can be generalized
to and enables them to characterize more complex situations. So,
yeah, that's a really short and brief overview of the whole chapter. Maybe
we can talk about a bit more details as we go through it.
Great. Well said. Well, I'm sure for another day, the philosophical implications of eight,
seven, and eight, and high road and low road, and all these other parts of the textbook, great
topics. I agree. I would see chapter eight as demonstrating continuity with some classical
continuous time modeling motifs from a few different areas of dynamical systems, science,
which is applied in like many, many, many fields, but these are some classic examples.
So, figure 8.1 goes a little bit more into depth, or at least into more formalism detail
about exactly what we saw in chapter five with the spinal reflex arc, with the proprioceptive
data coming in, and then a differential being calculated with the set point,
which reflects a descending prediction from a decision making layer. And that can be viewed
as this kind of mechanics that plays out in a phase space, in continuous time, like a spring
moving around with someone making a certain path with an attractor, and a spring being dragged
around something in that area. Box 8.1 goes into a very fascinating topic. Do you want to describe it?
Well, it's maybe one of the most thought-provoking pages of the whole book. And if I remember
correctly, in all of the cohorts, this particular box always gives rise to lots of questions
because of some of the interesting and at least initially counterintuitive
claims here. But I don't want to spoil it. But as a kind of spoiler alert, it kind of gets to
really interesting, but alas, very brief discussion about comparing these terms precision,
attention, and sensory attenuation, and the relation and similarities and difference between
these three terms, and how understanding each of them is essential to understanding the other ones.
But as I said, it's a really interesting topic, which gives rise to lots of discussions. And
I believe it's one of those topics that that's worth looking a bit more, looking into in some
other literature as well. Great. Well said. What a cliffhanger. Next, they go to a classic model
family called Laka Volterra. These dynamics inherit from characterizations of predator-prey dynamics
in ecology. So it's kind of a classical ecology model shown in Figure 8.2. On the top, it's actually
the ecosystem model. Plants, herbivores, and carnivores, which follow different kinds of
oscillatory trends in continuous time. And so that also has enabled it to be applied for other
so-called winterless competitions. And that relates to topics like neural Darwinism and also neural
dynamics, where things have kind of oscillatory relationships with each other, which are being
modeled as a continuous time underlying process with a lot of measurement, noise, and discretization
through space and time. Those are the kinds of algorithms that SPM explores more. And there's
Laka Volterra and a lot of other dynamical systems theory in SPM. So active inference kind of adds
action and more to what was laid out from a pure dynamical systems theory in SPM. Here,
it really is just showing the ecology example and how you can project. If you have three different
species, you can think about that motion in a cube or tetrahedron. And then you could project
onto kind of like looking at a lower dimensional manifold relating just two of the three species.
And that evinces this kind of oscillatory but also moving behavior. That gets connected in figure
8.3 to neurobiology. What would you say about this? Okay, so here in figure 8.3, we see some
applications of Laka Volterra dynamics. So the left column here represents what happens in
I mean in eye blinking, eye blink conditioning. So of course, here we need to account for
I mean the expected states of the sequences of events that happens in the eye blinking. So
the upper left figure shows the expectations in terms of time. And then the parallel right hand
side figures shows the Laka Volterra system that is applied in the handwriting situation.
So as we can see, although the mathematical technology is the same or at least the modeling
technology is the same, the outcome of each situation varies drastically in two distinct
neurobiological behavior. Not neurobiological but biological behavior. So yeah, we can see how
the same modeling framework can give rise to different outcomes based on what parameters
needs to be optimized, what parameters are selected for the modeling and so on. So I believe it's a
quite interesting example to compare handwriting and the blinking together and how those can be
compared to each other using the Laka Volterra dynamics. Great, thank you. Box 8.2 gives a variant
on the learning here presented with the formalism for continuous models, kind of a technical aside.
Section 8.4 is about generalized synchrony. So figure 8.4 is going to visualize one of the
classic dynamical systems, which is the Lorenz attractor. So what would you say about this
figure? Okay, so this section is truly interesting because when one thinks of active inference,
probably the first situations that comes to mind is the situations in which we have quite well
defined probability distributions for different parameters. But as we can see here in section
8.4, actually some of the formalism of active inference can be successfully used to characterize
even chaotic systems and in particular the way in which two chaotic systems can be synchronized
with each other. So this is a classic example of a chaotic Lorenz system and it draws upon
from some of Professor Pristin's earlier work on birdsong synchrony. And as a side note,
any literature before 2016 is considered earlier history in active inference literature because
it evolves quite rapidly. So yeah, this kind of synchrony between two chaotic systems can be
interpreted as providing evidence or even, let's say, a way to model a kind of primitive theory of
mind in the sense that how exactly can we understand or can two agents can trace each other's
trajectories without engaging in any direct exchange of observations between their internal
and external states. So yeah, that's a really good example and I believe one of the most
interesting examples of how active inference can even account for these kinds of behavior.
So and the rest of the section goes into the details of how this kind of synchrony between
multi-scale Lorenz systems can happen and how can we formulate it mathematically in terms of
continuous time active inference. Awesome. And there's been more recent work on Mark
Alblanket's and stochastic chaos, but the bird example is a classic. 8.5 goes into hybrid,
discrete, and continuous models. So this could be kind of like an in-between chapter of 7 and 8,
but now that we've been introduced to the pure form of discrete and the pure form of continuous
models, here's shown that that composability extends to so-called hybrid models, where here
the lower level visually is using the continuous time formalism and the higher level is describing
the little line added here, the discrete time formalism. And this was the similar structure
described by the authors of the paper, Active Inference Does Not Contradict Folk Psychology,
where they describe this lower level as motor active inference, which was closely
allied with the spinal arc reflex shown above. And then this higher level, they called decision
active inference, because in that case it was referring to a discrete decision.
And so they used that kind of basic motif of continuous activity or continuous time modeling
at the more peripheral aspects of a cognitive entity. And like Ali said, more discretization
and hybridization as well at higher levels of the cognitive modeling.
And that type of an architecture here, instead of describing who wants the ice cream cone,
I believe, here it's going to be a mixed or hybrid model that is going to call back the
isocade system, where there's a fixed point that is able to be moved as a set point,
and then there's a continuous time isocade that pursues the new fixed point. And so that's
analogous to a new set point or fixed point being specified from the top down muscle command
about a new location for a muscle, followed by movement towards it. This is a muscular activity
that is realizing that, but not in the elbow coming away from the hot stove. This is about
the ice accading to an epistemic foraging location specified by top down hierarchical systems.
8.3 describes a little technical aside on mixture of Gaussian, Gaussian mixture models, kind of a
technical modeling note. And 8.6 closes. It says it's a huge topic and much has been left out.
And so they list in table 8.1 key advances and continuous time models. And those areas are
synthetic bird song, ocular motor delays, condition reflexes, smooth pursuit, eye movement,
psychosis, illusions, saccades, action observation, attention, hybrid models, and self-organization.
And that's chapter eight. What else would you say? And also, what would you kind of lead someone to
in the philosophical implications of 8? Because it sounds kind of cool.
Okay, so, well, the case of continuous time active inference,
I think it leads to really interesting questions, both in terms of philosophical questions and also
more practical modeling questions about what parameters
needs to be accounted for and so on. And as I said, I believe it's a more interesting way of,
if not interesting, but at least more involved way of doing active inference modeling.
But one thing that's one of the philosophical questions that
Mau and I have explored in our paper is how the processes of, I mean, ontological processes can
philosophically describe using FEP assertions in terms of their interaction with the environment
in which they co-constitute themselves. And we don't necessarily distinguish between
between the internal and the external states. So one obvious example of this is that generalized
synchrony example that we saw in this chapter in which we don't necessarily distinguish between
which of the birds act as the agent and which one is the environment or the vice versa.
So this kind of co-constitution of the environment and the agent, which gives rise
to the partitioning of state space through a Markov blanket, is one of the interesting
philosophical points that I think needs to be elaborated a bit more using
some of the recent advances in philosophy, such as the tools that's been developed in new materialism
school or some other philosophical approaches. But yeah, these kinds of
what exactly gives rise to emergence, what is the ontological status of emergent properties
and so on, are some of the burning questions for many philosophers today. And I believe
active inference and particularly continuous time active inference provides a clear,
precise mathematical formalism, even if not to answer these questions, but at least
to explore it in a more rigorous and practical way and also practical and tractable way. So
this is the area that I believe philosophy and science are beautifully intertwined
into a coherent view of not only the phenomenon of interest, but even
about the whole world. Wow. Wow. Pretty cool. Yeah, a lot to say about that topic.
After completing chapters seven and eight, you've seen the kind of two major branches or
two major motifs of just one kind of modeling. But these kind of models have so many different
forms that that's why it's such a hands on process to specify the generative model in chapter six
and fit it with data in chapter nine. Those are all what's required. And that's kind of the last
mile of where these discussions about general motifs gets you. But also playing with these
pedagogical models can be really helpful, because it will help you understand the basic
patterns and relationships and start to see see different patterns in the graphical models
and know from there what levels of technical processes can be kind of coarse grained over.
