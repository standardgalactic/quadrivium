Chapter seven is called Active Inference and Discrete Time.
Chapter seven is the first in a pair of chapters
with chapter eight on discrete and continuous time.
So they're kind of like two forks of a river
that we discussed in chapter four and before
and describe the recipe in chapter six.
Now seven and eight are kind of like one level deeper,
going from the kind of all of this group of animals
to one level deeper into its classification scheme
on the way to the specific generative model
for which it's actually given in its totality.
But everything prior to that is about the learning about its principles
and this is kind of on the trunk of the path to discrete time modeling
just like chapter eight will be about continuous time modeling.
What would you add in?
Okay, so I think chapters seven and eight
really helps to understand in a more practical way
how the materials from particularly chapters one through five
applies in real-time situations.
So even if we somehow didn't get to understand
every details of chapters one through four,
by when we come to chapters seven and eight,
I think some of those uncertainties about our understandings
can be clarified in a at least in a practical sense.
So I believe these two chapters are really helpful
in order to consolidate our understandings from the previous chapters.
Awesome, well said. So it's going to involve specifying some discrete time models.
Seven point two goes into perceptual processing
and the general structure of the chapter is going to walk through
a series of examples that build in complexity
where they first start with perception in seven point two,
introduce decision-making and then describe a few more types of motifs or
cognitive structure or patterns and also check out step by step
and model stream one where it's built up to in a different way.
So the first example is I'll let you describe it since it's musical.
Okay, so yeah, the first example is the situation in which we try to describe
the performance of an amateur musician in terms of how we listen to the
performance of an amateur musicians in terms of the predictions we get from
our anticipation of the following notes as opposed to the actual notes that's being played.
So these kinds of anticipatory reaction, listening reaction to the musician can be
successfully formalized using discrete time active inference by
putting together the matrices A for the states and matrix B for the transition between the states
or the transition probabilities which in this case describes the probability from going from
one note to the other and obviously the actual sequence that's been played which
can be described with the matrix D. And another point I wanted to mention is
for anyone who has downloaded this chapter before, I don't know, I think about June or something,
I recommend re-downloading it from MIT's website because they have corrected some of the typos
that was previously present in this chapter, particularly in figure 7.2.
Cool, so this graphical model where a person is listening, this is a general perceptual
Bayesian framing, it's specified. Just like with any other equations, there's a lot to look into,
but A indicates the probability of an outcome given a state. This is saying if it were all
on the diagonal identity matrix, this is kind of a common motif, then states kind of map to
themselves. So in the context of, in the context of this model, A represents the mapping between
the observed note and the underlying hidden true note, and then B describes the transition
matrix of how those change through time D is the prior, they're specified.
Figure 7.2, do you want to describe it?
All right, so in figure 7.2, or at least the incomplete version of figure 7.2 we see here,
well, at the upper left part of the picture, we see, I mean, the beliefs about each note
at each step, at each time step, and at upper right, we somehow translate those beliefs into
specific numerical values. So instead of just assigning some continuous values, we
simplified the situation by assigning some discrete numerical values for each note.
And then the lower left is supposed to show the free energy gradients
over time, or in other terms, the prediction errors we get from, I mean, comparing our
predictions with the actual outcomes. So lastly, the lower right picture
shows, in parallel to the upper right picture, determines the values of these errors. So
we can see both the continuous, the initial, or at least initial continuous assignment and values,
and then the further discretizing of the values in order to get the discrete time
situation, or the more tractable discrete time situations.
Okay, so it's a general passive inference task where there's priors about how states are going
to change through time, and then there's real data coming in. So that's the kind of classical
predictive coding, video compression, Kalman filter, Bayesian setting. 7.3 introduces a key
motif, which is decision making and planning as inference. So this is the idea of having a
Bayes graph where the variables can relate to different things. There's high composability.
And here the idea is that a variable is going to be proposed that we can do inference about
that describes the process of decision making or policy selection. So what would you say about 7.3?
Okay, so 7.3 is obviously similar to what we saw in chapter four. And if I'm not mistaken,
even the topology is exactly the same with that picture we saw previously. So this is
the initial setup, or which acts also as a review about how these different
components upon DP generative models needs to be described in such situations.
But ultimately, the specific case study we come across in this section is the attempt to model
the behavior of the mouse in a teammate, so the rat in a teammate. So especially
teammates containing an aversive stimulus in one arm and an attractive stimulus on the other.
So this can act as a kind of toy example to use this kind of probabilistic modeling to
describe these situations.
Thanks. So that leads us right to figure 7.4. Here's a visualization of the situation with
the rat in this case, where there's a pleasant and aversive stimuli on each end of a decision
point. And there's also a epistemic opportunity to receive some information about the context
that the animal is in. And so that setting is described for both the case with white on the
left, black on the right, and black on the left, white on the right. And those are shown in terms
of their differences in the matrices, the explicit specification of the generative model.
Visualizations show some of the slices of the B variable, which reflect different transition
probabilities. C represents the preferences, which are expressed over the observable states.
D reflects the priors on the different states that need priors. 7.4. What would you say about this?
Okay, so in 7.4, it builds up on the previous section and adds other elements that we previously
saw in chapters 3 and sorry, 2 and 4, which is how the exact formulation for
expected free energy can be used, sorry, variation free energy can be used to formulate the tradeoff
between the information seeking or at least between the epistemic value and information
seeking. So here it uses, again, that rad example in a bit more extended and elaborate form to
formulate the epistemic value of observing Q in a given location. And figure 7.7 is a
representation of this situation. But another situation that's been,
let me see, yeah, in 7.9, another case study discussed here is the situation of the
psychotic eye movements. And because it is something that can be quite successfully described or
characterized in terms of information seeking versus the epistemic value. And the situation here
is, let me see, yeah, shown visually in figure 7.9, which clearly shows how our visual
psychotic eye movements can be described in such a way as to kind of trace the trajectory
of our eye movement among different regions of the visual space. And how the information we gather
from a given region can affect the, I mean, the subsequent trajectories of our psychotic eye movement.
So yeah, that's basically the main premise of this section, I guess.
Nice, great. 7.5, what would you say about it?
Okay, so 7.5, again, adds another dimension to the previous formulations. And this time,
we get to update the generator models by learning. And so the generator models for
this situation is a bit more complicated than the previous ones, because it now needs to
account for a mechanism or a way to update the matrices we had before. So in the previous
situations, we didn't account for learning per se, but here, we directly update our general, sorry,
the word update can be confusing here, we get to somehow improve our generator models to
accommodate for these updating accounts. And yeah, so the situation here, or the case study
here, which somehow elucidates the way that the learning can be accounted for with these models,
is again, a toy example of a creature in a simple world of black and white tiles,
which kind of tries to find a path to reach a given destination, a certain destination.
So it is more complicated than the situation we had for the rat example, because it only had,
I mean, simple trajectories that needed to traverse. But here, the creature or the agent,
in this case, needs to do lots of, lots more learning and information seeking and so on.
So all the previous elements is kind of combined in this example. And it's a really good example
to see how the different components of active inference can be connected to each other.
Nice. And 76, hierarchical or deep inference. First, a box 7.3 interlude on structure learning,
boxed off topic and a lot to say. But structure learning broadly refers to learning the structure
about a model, using the same types of methods that you might to do inference on, for example,
a more observable sensor data reading, something like that.
This section works towards the idea of nested inference or multi-scale modeling.
What would you say about figure 712?
Okay, so again, this situation is, I think, the most complex situations of this chapter,
which builds up from the previous sections. And this time, it adds another layer to accommodate
for the inferences that happen in, I mean, different time steps. So in this case, we have
multi-time or multi-scale inference and learning happening, both at the levels of,
sorry, at the levels of learning and at the levels of information seeking. So this is represented in
figure 7.12, which represents how this fractal generative model can be seen as a component
in this multi-scale bigger generative or as a kind of leaf in this bigger, bigger generative model.
So it can be seen as a lower level inference happening at the leaf level going up to the hierarchy
and influencing, sorry, collaborating on the whole process of learning and inference at the
higher level. So yeah, I guess that somehow summarizes this figure. So if you have anything to add.
That's great. It's an example of the composability of generative models. What we've
talked about and had Toby Sinclair-Smith describe as the compositional cognitive
cartography and just what kinds of connectors can and can't you do? And how can that motif
that the discrete time model introduces and then the rest of these features,
including action and learning and so on, get layered in on top. What can you do with that?
7.13 gives another example. Do you want to say anything about it or maybe continue on?
Yeah, so the case study here is the example of language learning through reading. So
not language learning, maybe just what happens in reading. Yeah, in comprehension. So what happens
when reading in an anticipatory way, the words that comes each after the other. So
why this kind of situation can be most successfully characterized with this kind of
modeling because it involves different scales of learning and comprehension, both at the level of
reading at the level of somehow observing the letters and then going on to the words and
then word groups and so on. So yeah, that's a really interesting way to again combine all of those
elements into a single unified model to see how those different timescales, slow and fast timescales
operate together to build this more encompassing model, more encompassing generative model of the
situation.
