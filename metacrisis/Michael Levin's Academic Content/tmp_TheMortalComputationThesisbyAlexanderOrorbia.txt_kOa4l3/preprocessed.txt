Yeah. Thank you for having me, Michael. And thank you everyone for coming to the talk.
So I'm going to talk to you today about some work that my friend Carl and I have done.
We call it the mortal computation thesis. And I think it complements some of the things
that I know Michael's group does. Actually, in fact, we cite particular mortal computers
that I will get into a little bit later. And we can talk about that perhaps. So just
very briefly, who am I? So I'm Alex Rubia, and I'm the director of the Neural Adaptive
Computing Laboratory at Rochester Institute of Technology. These are my students, as you
can see. And we work on quite a few things, but our primary focus is building biomimetic
systems and the learning algorithms and computational architectures that would facilitate their
learning and inference with the goal of obviously building things in hardware substrate.
So again, neuromorphic computing might be familiar to some of you. We also work on a lot of things
based on the free energy principle. Some of you might have heard of predictive coding
or active inference and my group contributes to that. And we have a lot of collaborators,
but this is just our brief little intro. So you might be asking what exactly is mortal
computation? And if you're familiar with it, you might be you might be aware that Jeff
Hinton last year came up with a phrase called Mortal Computation. And one of his works,
the Ford Ford algorithm paper, the idea effectively is that software cannot be divorced from the
physical substrate or hardware in which it is instantiated. And the idea is that the
calculations and processing are embodied. And in fact, inseparable from the medium, medium,
breaks down stops functioning. The software ceases to existing cannot be carried out on
another medium. This sort of effectively says that the software should die as long along
with its quirks and its properties, if the hardware or substrate that executes it ceases
to function. And of course, this is going to have implications for edge devices, energy
efficient systems and robotics, and so on and so forth. However, this challenges the
notion of immortal computation in computer science, sort of a foundational idea that we
can essentially write our program independently of the medium that we're going to execute it.
And that this program or software can be copied or executed on another GPU or TPU server, for
example, if you're doing machine learning, and it's going to pretty much run the same. It's not
going to have any particularities that are tied to its actual medium. And so effectively, the
knowledge and characteristics that your program acquires is done irrespective of the medium in
which you're executing it. So this is the work that maybe I believe you were linked to. It's a
little bit long. So I don't blame me if maybe perhaps you didn't read it all. But this is work
that we sort of did like a review and then sort of a perspective on what mortal computation really
should be as Jeff sort of just introduced it in about a couple of sentences. So Carl and I wrote
40 pages roughly about it. So why exactly mortal computation? Well, part of it is a thermodynamic
consideration. And this is basically getting at the relationship between information processing
and thermodynamic efficiency. The idea effectively is that we want to adhere to Landau's principle.
And these are just some principles I'm going to briefly introduce. Those of you who might have
deep physics background might even understand them even better than myself. But the idea is that
there is a minimum amount of energy required for any irreversible operation. Think of like erasing
a bit on your computer. And it is proportional to the operational temperature of the computing system.
And I just give you the relationship here, pay B as Boltzmann's constant. And the idea is that an
irreversible change in a computer's stored information requires dissipation of a minimum level
of heat to the environment. This is paired with the Jarzynski inequality. And I have a floating
bullet point there, but that's because I wanted to remove some unnecessary detail. But the idea is
that we're talking about the difference of the free energies, the physics free energies between
two states, x and y. And we are saying that the difference between them can be constrained to be
equal to the average of the work, the physics work done from all paths taken from perhaps an
equilibrium state x to a typical non equilibrium state y. What does this really mean in plain
English? Well, roughly, we can know something about a system's equilibrium by observing the system
when it is not at equilibrium. And so the main takeaway when you pair these ideas together, as
Carl and I argue, is that there's a lower amount lower bound on the amount of thermodynamic work
that you need to do to change information content in an information system. And so this of course
has wonderful implications. If we can get our intelligence systems that we try to strive to
date in artificial intelligence to emulate to build something that adheres to in memory processing.
And effectively, this just means that we are changing the computer's information content. And we are
saying that it's equal to the inference belief updating in response to external perturbations. So as
the computing system is dealing with an environment, we essentially want to be working at as close as
possible to the substrate, these calculations should not be divorced. And then of course, we can tie
this as I'll show you a little bit later to the variational free energy formulation. And effectively
that when a computing system or an intelligence system is minimizing its variational free energy,
it's the same minima as the thermodynamic free energy. And there is equivalence in work that we
point you to. And so of course, the idea is that we need to essentially try to circumvent what's
called the von Neumann bottleneck or the memory wall. And that's the idea that when we are doing
things, you might be aware of deep learning and what is rocking the world of artificial
intelligence to the state, we're effectively executing our programs on software that is in
random access memory. And as you can see in the bottom left diagram, there's a lot of expended
energy to start moving information from long term memory, depending on your computing structure,
to random access memory. And so we essentially would like to overcome that. And that's sort of
what just one common example that we see today in memory computing is neuromorphic computing,
where we're effectively designing our biological models, our neuronal models, actually as close to
the hardware as possible, and using things like BEMRisters to adhere to synaptic connections, and
so on and so forth. But ultimately, the idea is that realizing thermodynamic efficiency of Bayesian
computations, which is effectively what biological systems we are doing, requires belief
updating and memory to be Bayes optimal is to be thermodynamically efficient and vice versa. This
also has some wonderful implications for green AI, which is this argument that we need to
essentially figure out how to do the intelligent operations we do today, without expending
mammoths of quantities of energy, chat GBT and transformers themselves are pretty expensive.
So then there's also cognitive philosophical motivations. I won't dwell too long here as
well. But the idea is that there is in cognitive science, the embodiment thesis or the embodiment
hypothesis and inactivism, which is just effectively saying at a high level that the mind your mind
or any mind is grounded in its sensory motor accompanying. So the ideas that we are shaped by
the actions that we take, the nature of mental activity depends on your body. Effectively, you
need to be in some type of actual physical instantiation. You cannot have what is known in
classical cognitive scientists known as brain and event. So the idea is that we don't have
something called isolated cognition, we are actually primarily driven by our body. And
inactivism takes us an extra step further. And the idea is that we are dependent on our
environment, our cognition is we are coupled to an environment we effectively that affects us as
well as affects our environment. So a mortal computer in effect is an active participant in
the generation of the information that it processes, thus shaped by the consequences of
how it acts, and has acted on its niche. Effectively, this is called niche construction. And then we
also talk a little bit about some other nice connections in naturalist philosophy and existential
ism. That actually refers to a little bit the initial quote that you might have seen in the
paper by Soren Kikegaard. But the idea is that there is a finite to the life, it endows us with
purpose entails reproduction, and motivates us to pass on knowledge to future generations.
Ultimately, death is a horizon that shapes our behavior and consciousness. Now, of course,
while mortal computation doesn't go as broad and as far reaching as existentialism and other
aspects of natural philosophy does, it does actually we do pull or extract a small part of it,
talk about that even animals in any organism is implicitly constrained and conscious or maybe
not conscious of the fact that they have a finite horizon and they act accordingly.
And of course, there's some other parts that we touch on in our framework about operational
closure, which is just the idea that the system must auto undergo auto poetic, met self assembly
and self maintenance to keep separate its internal states from its external states is going to
motivate the Markov blanket construction of the mortal computer I'll talk to you about later.
And then, of course, the idea of sense making, which is that there's a mutual dependence
between external processes and an entity, whether it's a biological organism or rather
any mortal computer as we generalize, because a mortal computer does not need to be artificial.
We are all effectively mortal computers, a biological system must distinguish itself
from its niche, yet be coupled to it in order to persist in that niche. And this will motivate
the idea that we don't want to dissolve in our heatbath, we don't want to cease to exist.
So effectively, a part of the work that again, you might have read is it's a review. This idea
is interestingly enough echoed for many, many decades across all kinds of thinkers and engineers
and wonderful ideas have cropped up throughout time. So we sort of unified them and scoped them
out. Obviously, this talk, you've been time constraints is not going to possibly go into all
the details. But I will give you a swath. So sort of you can think of the paper or the concept in
terms of three particular slices. That's why it's called the three slices of moral computation.
We have a biophysics physiological naturalist philosophies interpretation in the top left
towards the top bottom left, we have a cybernetics interpretation, and then a cognitive science
interpretation. And I'm going to give you some of the highlights. So we're going to start with
the biophysics aspect of our framework. And I'll just leave this diagram to sit here as I explain
just a few of the key concepts to sort of parse it. So the idea is that a mortal computer self
organization constitutes its thermodynamic and metabolic efficiency. And we talk about metabolism
and autocatalytic closure as some motivating concepts. But effectively, these ground the
mortal computer's agency or its ability to adapt. Ultimately, we need to understand
that a mortal computer is not a thermodynamic equilibrium. And it operates as a dissipative
system, given that energy and matter would be lost by essentially in the ideas that we are
adhering to the first order, first law of biological thermodynamics, which allows us to
reconcile and ensure that we are still adhering to the classical second law of thermodynamics.
Entropy has to increase in the environment. But in biological open systems, we don't see that we
see entropy decreasing. So the idea is you have to kind of view it all as one big closed system.
You need the environment and the entity itself. But ultimately, a mortal computer or any entity
that can be considered one, its metabolic organization stands far from thermodynamic
equilibrium. And so ultimately, it needs to forage like any living system or any system to
continue to acquire new resources. This sort of motivates like that bottom level, the diagram,
the metabolic processes are essential primitives. This is something that Carl and I chose his
language to pull a little bit from cybernetics and bring it back into the biophysics interpretation.
But ultimately, these are the foundational components of a computer or a mortal computer
or any system arranged within a morphology, of course. And then of course, we need homeostatic
or homeohedic processes that live on top of it. This is our active regulation of those essential
primitives. And the idea is that we have metabolic processes as we discuss reactions that use energy
to trans materials into structures that then harness further energy to transform transport
material, eliminate toxins or surplus material. And of course, this is sort of our way of keeping
track of set points if we want to stay within a certain range or near a particular value.
And so we need to be designing out homeostatic processes, which ultimately, by the way, you'll
notice that there's these arrows for influence in the diagram. So all of these processes in effect
should have some type of influence on their sensory motor action. This is motivated actually a
little bit by work by Egbert and others on chemotaxis and talking about metabolic dependencies
and the idea that action is shaped driven by your metabolic functions. Sometimes it can be
entirely dependent on only dependent on that. But we sort of generalize it a little bit to
allow some design flexibility. On top of this, any of you are most likely aware of what allostasis
is, but we also need allostatic processes because this is instead of having error reaction or reactive
processes, we have error correction processes as well. So this is what serves homeostasis or
homeohesis, precludes future deviations to the essential variables. And then of course, at the
very, very top is our auto paedic autonomy level. And this is where we need to account for the fact
that a mortal computer, if to be unification of artificial as well as biological systems,
needs to have the ability to make itself from within. It must continuously reproduce,
organize, maintain the relationships between its parts, and as well as do this without external
intervention. It must come from within. And of course, then we have the notions of morphogenesis
because the idea is that the mortal computer needs to persist longer than its actual physical
instantiation of its components. So it means its actual organization or relations live longer,
and that's its identity throughout time. This will also motivate the self-evidencing aspect
of mortal computation. And it's continuously reproducing itself. And then as I mentioned,
there are motor sensory motor dependencies that a couple this to its niche. So ultimately, what
does this really tell you at the highest level? Well, that we need to essentially design our
mortal computer system with the niche in mind. The niche cannot be this decoupled or disentangled.
We need to understand the properties of the niche as well. Again, some might be wondering from
computer computational backgrounds, won't this make the system rather brittle because it's rather
dependent on the body and the niche that you are designing. But that's sort of the point. The idea
is that your behavior and your cognitive functionality is directly dependent on your
physical instantiation and the environment or niche in which you live. So again, the organizational
closure of the mortal computer, it depends or sorry, it's the means that the mortal computer
operates on the basis of self-reproduced structures. And, you know, as I've said already,
the mortal computer is auto poetic. And so this is where we have sensing, actuation, and we need to
be modeling or essentially accounting for energy exchange and matter transformation. And so again,
at the bottom right is our reinterpretation of the homeostatic dependencies of some good work
over the years. Well, we just have that as a little, oh, and it was called, well, we generalize
and call it homeostasis dependent, but you know, it was originally called metabolistic or metabolism
dependencies. So now we can move on to what we call the cybernetics backend. And again,
this could take a while, but I'm not going to dwell too long on it. Effectively, what I want to say
to you is there's a couple of concepts that we can bring from classical cybernetics. It's sort of
like the forerunner to aspects of computer science and certainly to artificial intelligence. But
ultimately, cybernetics deals with this concept known as retroaction, a system must incorporate
ends or goals into its means or mechanisms in order to ensure goal attainment is absolutely
inevitable or almost inevitable. And so the system essentially the question that characterizes
cybernetics is how can a system learn what it needs to know in order to act effectively?
This gets into this notions of self organizing systems, elementary parts and local interactions
with upward and downward causation. And we detail these a bit more in the paper and point you to
plenty of references for all those details. But the idea is that the system is dealing with variety.
And this is the central concept behind cybernetics. And you can see as you see on the slide, it's the
number of distinguishable states in a system state space. Another way you can interpret it is the
degrees of freedom that a system has in choosing what state it will be in. This can be reduced
via selection. And this leads us to sort of organizing and another aspect of cybernetics is
there's a lot of principles and laws. And so we try to organize a couple of them into three central
pillars that we felt were useful and complementary to the notion of moral computation. So we organize
them into, as you can see in the bottom, stability, regulation and growth. And so effectively,
stability is going to relate really nicely to homeostasis and homeohesis as we discussed
in the biophysics part of the talk. And the idea is that the system ultimately,
its goal is to reach a state of stability or ultra stability. And all this means is that it
performs selections to cross state space to try to reach new states until it converges to a place
where essentially doesn't need to alter its part to part relationships. It sort of stabilizes
and ultra stability means it's found an attractor it really likes. So this is a good place for the
system. It's very hard also for it to leave that particular state. So ultra stability is
effectively it's able to maintain its homeostasis. It keeps those variables near its set point. It
has all that it needs to sort of stay in a good configuration. And then of course, there's other
principles like the principle of asymmetric transitions. And these are things that are
characterized deeply in cybernetics system in unstable configurations usually moves to stable
ones, but not the opposite. And again, a system as it rejects fewer states as it reaches more
stable ones, the variety decreases as the system becomes more organized again, it's sort of converged
to a good state. You can equate variety with thermodynamic free energy. But the idea is that
then the system does work or it exerts its variation to reach those stable states. If it
is stable, it's not going to undergo variation. And it's less likely to expend the energy to leave
its current state to state. So then the other aspect or the other pillars you can see on the
right slice of the diagram is growth. And again, we're not going to talk about all little sub
principles again, I recommend reading work to see how they all kind of fit together. But the idea is
that our mortal computer must be morphogenic. It maintains its continuity and integrity by
altering aspects of its organization and structure over time. Morphogenic processes may
also be triggered by environmental conditions. And then of course, we have this principle in
cybernetics of self replication. This is kind of really important, something we don't really have
in artificial intelligence systems today. System behavior is important that it results in copying
or generating copies of itself. We do have some classical work like the von Neumann universal
constructor, you might have heard of Conrad's game of life or Conway's game of life, sorry.
And the idea is that these are models of rules or rule based systems that can show you how you have
death and life in the computational systems. And then another important notion is that
reproduction on a mortal computer would not just be replication, but you would add mutation.
So if we have perturbations to a replicated copy, now we have an offspring. And now that is subject
to the same pressures that the original source computer is subjected to, and it will undergo
selection and try to find its own stable states. Ultimately, then you can think of reproduction
as another means to propagate one's identity through time. And then the last principle or the
last pillar that we organize is cybernetical regulation. I do mention sometimes cybernetical
homeostasis is kind of like implied throughout various principles, but we have the law of
requisite variety. Just very briefly, what these three principles ultimately try to tell you is
that you need to have enough internal variety in order to, or at least in enough equal amount of
internal variety compared to your environment's variety in order to successfully maintain, for
example, homeostasis or block particular variables and stay in a stable state or more, you could
have more variety. That's fine. So it is an inequality. But the idea is that this is important
for a system essentially to try to maximize its internal variety in order to be optimally prepared
for all possible perturbations or things that the environment could throw at you.
The good regulator theorem complements this a bit. And it's just basically saying that every
self-regulating controller of an environment must itself contain a model of that environment.
And this motivates the notion of a generative model that effectively one way you could think of it is
that the mortal computer or entity is a generative model of its own environment. So the mortal
computer ultimately seeks to become a model of the niche that it wishes to control. And then this
motivates aspects of survival. And the principle model control, internal model control, I'm not
going to go into it for sake of time, complements the good regulator theorem. It just basically
talks about things that are how you deem if the system is structurally stable. And I'm going to
move on because I want to make sure that we get through to the actual definition. So then the
last slice that we review and we had a preview of this earlier is aspects of cognitive science.
So effectively, Carl and I sort of generated something that we call a 5e cognitive theory.
You might have heard of 4e cognitive theory, so we slightly extended it. Very briefly, if you
look at the center component, the extended, embedded, inactive, embodied, and elementary,
you'll notice elementary is the new aspect of the new extension to cognitive theory.
Elementary cognition, and I know many of in Mike's group is very familiar with basal cognition,
and is that cognition stands on fundamental functions and structures that enable acting
and tracking aspects of an entity's niche to ensure it survives fine food, avoiding danger,
trying to reproduce. So these are, again, known as basal cognition, and it's a manifestation
manifested through a system's autopoiesis. So this is sort of the base level that you must have as
the starting point, essentially, to build a reasonable or effective, moral computer. And then,
of course, on top of that lives the embodied cognition aspect. And this, again, they all depend
on each other. So if you have one, you're going to start getting the others. If you add these levels
of complexity, so it's kind of organized as the higher up in this chain you go, the more complex
your mortal computer is. The body cognition, as we talked about earlier, is that you can't describe
your cognition or mental processing without a body. The idea is that you must involve the body
or morphology of the living system. And yes, this is a little bit more of the extreme version
of the embodiment thesis. There are a spectrum of different types, but we sort of leaned in more
on the idea that we even offload cognition to aspects of our body. And this is motivated by
like morphological robotics, where, again, we know that if we can offload the physics onto
particular limbs and things of that form, you can reduce the processing of the computational brain
that you build into the computer. We know that inactive cognition lives on top of this is the
idea that you depend on your environment, and you have a meaningful relation, two-way relationship
with it. Again, not only for extracting resources and transmitting waste, but you are essentially
inhabiting and actively shaping your niche construction, as I mentioned earlier.
Then on top of these, we didn't really go into detail. I'm just going to mention that you can get
further and further and more complexity introduced. You have embedded cognition because the idea is
that you live in a system of other mortal computers. So that's kind of what we have there.
On the left, we show some neurorobots as just an example. And the idea is that you are determined.
Your cognition is affected by cultural norms and other social interactions and the behavior of
other entities that are also in this environment undergoing the same forces that you are.
And so, again, the mind extends now beyond boundaries of the individual. And then, of course,
extended cognition is the final one where you offload cognition or the theory of extended mind
into non-biological or non-mortal objects. So if we generalize things to mortal computation,
these are not mortal computers like your pencil or your phone. So essentially, we are using objects
as an extension of our cognitive functionality. And of course, that kind of like pie-sliced circle
is just sort of grouping them in another way. So we have basal cognition as like the biggest
slice. It's more of the foundational component. Morphological cognition deals with anything that
would be bodily kind of cognition or processing. Inactive, of course, you need to account for
the environment. And externalized sort of absorbs extended embedded. So that was another way that
we organized it. So maybe you might have heard of Kirchoff's life-mind continuity thesis. This is
another way of saying like, it's an artificial manifestation of it.
So what now, equipped with all this review of wonderful work of far smarter people than myself,
we get to the mortal computation thesis. So there are a couple of parts that I'll just introduce
briefly. And I have reduced and cut away some of the mathematics. We can talk more about that if
we want later. The Markov blanket is really the central underpinning of a mortal computer
and effectively what this does is this is our interface between what's inside you or the entity
or the mortal computer and what exists outside of it. It is that particular interface and things
are exchanged through that interface will be coupled. We can break it down a little bit further.
You could think of, by the way, Markov blanket like a cell surface, which separates intracellular
from extracellular elements. And then of course, we talk about sets. And again, these can be viewed
as discrete states, but everything's really continuous and it makes things more complicated.
But as you can see in the diagram to the right, we can decompose the Markov blanket into sensory
states and active states. And these are the ways in which the agent actually gets information
from the environment and transmits information to it can do things to it. Always the external
states of the environment and Z is the internal states of the system itself. So these again
are not observable by the environment. And the observable states are not observed by the agent
and must interact through this Markov blanket formalism or this construct. And again, this
motivates again, how you now need to design the body need to account for the morphology
of the agent. And so here we have a little bit of an expansion where again, I told you what
all the different ones are, we have iterators and we talk about them as actual sets of states
and they evolve with time as well. So again, ultimately what we want to take away from this
is that there is a weak coupling and local interactions. And this will motivate the free
energy application of the free energy principle shortly. And the Markov blanket provides that
necessary partitioning non living systems by the way that exhibit persistent local dynamics,
do not maintain a boundary. So you could argue, well, well, this is your framework and the concept
of the free energy principle Markov blankets apply to a campfire. And the answer is no,
because the campfire dissipates rapidly in the flux of the universe, it is extinguished by the
downpour of rain. So this is not going to have persistent dynamics, it just has local dynamics
or you can think of a candle flame as well as an example of a system that would not be a computer.
So now we get to the idea that mortal computation or the mortal computation thesis is really just
another corollary of the free energy principle. And just to briefly review what the free energy
principle at one perspective is, is all centers around what I was already hinting at before,
which is the non equilibrium steady state solution, or the NESS. This is what agents or any mortal
computer really wants to strive to reach. And so the idea is that, according to the free energy
principle or the FEP, entities maintain their structural and functional integrity by changing
their relationship with their eco niche through action. So action is really important because
this is our way of which the system can actually forage for materials. So the free energy principles
about random dynamical systems that actively resist the natural tendency to disorder going
to equilibrium and non equilibrium is bad. That means you have died. And so the kind of the whole
idea of mortality as we act so that we do not talk that we do continue to persist. And then the
free energy principle can then be broken down into kind of two key parts as you can see with
numbers one and two. Mortal computers internal density dynamics are conditionally independent
of its environment. What does that mean? The environment and the mortal computer are weekly
coupled and the mortal computer has states that are distinct from its external or environmental
states. That was again what was ZT versus OFT. And then the second key point or the key aspect
of the FEP is that the mortal computer will continually self-events or self-evidence by
returning to or trying to be as close as possible to its NESS, its NEST state. So the mortal computer
behaves to preserve its functional integrity and its dynamics do not diverge when a perturbation
is applied. So it's trying to gather those resources to continue to survive. It's striving to reach
ultrastability which connects back to the cybernetics back in. And then we talk a little bit about
the formulation of the variational free energy. I removed all the terms for you for simplicity here
again for the sake of time. But really under the hood of the free the F curly F is that an entity
has a morphology queue. This is referring to its actual structural organization. It has a set of
internal states and it has parameters move. And so again ultimately the free energy principle
is following the gradients or the differentials across each of those aspects. And we talk a
bit more detail. But I'm going to shift you to the final piece of the puzzle which is just
and we've seen this again like throughout morphic versus amorphic is an important distinction.
We've talked about biological entities having a 3D physical structure and von Neumann computers do
also have that physical structure. They're designed to maximize heat dissipation and things of that
form. But our programs and our software do not adhere to that structure. They are not
entangled with it. They are not taking advantage of that. And so we have again in a morphic system
we have a thermodynamic cost and we have information coupling. These are very important
constraints that characterize entities in this category. And so the morphology itself is a
computational resource and living entities. We also go on the paper in the free energy
principle about how you'd need to do structural optimization which connects back to morphogenesis.
But our computers are amorphic or sorry our programs are intelligent systems today.
Our software is independent of that substrate. Think of when you if any of you have experience
writing a mathematical model for a deep neural network you can write those equations independently
of any realization of a 3D environment. The execution of that program is possible because of
that computer's architecture but you are not accounting for its morphology. It is amorphic
even though we present it pedagogically as dot scenarios and try to connect them back to
synaptic structure. So ultimately mortal computers follow self-evidencing the same
self-advancing principles as enduring entities. They are inherently morphic thus we can apply
or ground them in the free energy principle. As I mentioned briefly earlier you can see to the far
right those are the gradient flows that you follow and of course we formulated them as
differential equations or differentials that you could essentially traverse as the free energy
sort of gets you back towards or trying to minimize your variational free energy to get back to that
ness. But this is the essentially we talk about the relationship between inference
learning and structure and how there is a circular causality between them and we go at
quite length and I'm not going to go into in this talk because that's going to take a while.
We also talk about mean field approximations and simplifications that give rise to known
structures and neural structures in the brain. But the idea is that a mortal computer is a
dynamics on structure with dynamics was ultimately one conclusion that we lead and we call this
backbone mortal inference and learning or mills for short. This is a key part of the final definition
I'm about to show you and remember that inference changing or altering your internal states or
variables internally depends on learning and of course learning depends on those internal
states and then there is another interesting relationship we point out that the morphology
or the structure depends on the learning or the synaptic parameters if we're thinking about
neuron networks and vice versa. So there are these causal relationships or these circular
dependencies that are necessary and actually important to embrace that a lot of modern day
machine learning or artificial intelligence does not embrace and we should be looking to
biology and neurobiology for those sources of inspiration for design. And I also mentioned
that mortal computers are an instantiation of physically realized Bayesian evidence. Not
only are they going to read to you this entire definition but this is effectively one starting
point an informal definition of mortal computer or mortal computation and what it would mean for
designing is going forward for artificial general intelligence. Very briefly the core agent goal
is to remain in non-equilibrium steady state of stability in the face of a changing environment.
Very briefly from the high level view of this definition you will notice that it
emphasizes strongly you need to have a morphology although we give you sort of a backdoor for those
that do computational modeling perhaps a virtual morphology would be acceptable for now.
And then we obviously need to have accounts for homeostatic homeohedic processes. So a generalized
homeohesis or homeostasis we also need to ensure that we have implementation of various aspects
of mills as I just briefly discussed earlier. And then we end by talking about categories of
different types of mortal computers and we came up with some very broad and these are subject to
change because this is sort of pointing in a completely new direction for artificial general
intelligence research to go into or biomimetic intelligence. So we have homeostatic mortal
computers and they satisfy essentially the core principles of the definition but in a very basic
sense. So it has homeostatic regulation over those essential variables or primitives I mentioned
very early on. You also then have a higher level regulatory processes so allostatic mortal computers
these might evince homeohesis in contextualized by allostatic regulatory processes. Obviously
the ultimate goal is to have a fully auto poetic mortal computer and we actually really have some
of these interesting ones. I'm going to wrap up with those examples some of which Mike's group
definitely knows for sure and of course we need to evince homeostasis allostasis
and engage in self repair and self replication. So what you might ask do any mortal computers
currently exist we already have some of them not necessarily that the problem is solved but rather
we have some wonderful examples that we could bring back to the science as the artificial.
One of the earliest ones is Ashby. Ross Ashby is a very important founding figure of cybernetics
which was one of the slices that I read Carl and I reviewed earlier and Ashby's homeostat which is
what's shown in the picture here. It's one of the earliest examples of what we would consider a
homeostatic mortal computer. It's very very simple but it is able to stay autonomously in its own
stable state so it's able to maintain a form of homeostasis without any external intervention
and usefully enough if you read into the literature without any knowledge on the designer's part of
really how this even works which is kind of interesting. So the primary aim is it keeps
control variables within certain ranges and we'll do this with random exploration. There are
modifications that were done over the decades to add learning components to it and then you can kind
of make it look like what Carl tells me is an allostat. If you add some form of memory or learning
you sort of get a little bit more of an allostatic interpretation. The funny thing was the homeostat
can survive as one comment from an early cybernetician says something that any normal computer cannot
or digital computer, a wire cutter, you can turn off your normal computer and break it down
but a homeostat would learn to replace one of its submodules if you cut one of its wires which is
really interesting. Then we also have things by Bap, Pask and Beer and many of those that
contribute to what was known as Maverick machines. These are actually variants of
autopoietic mortal computers in some sense. The electrochemical ear was essentially a system
made of several platinum nodes inserted in a dish given an electrical stimulation and they
would grow and self-organize. You can also give them positive reinforcement and that's why it was
called the electrochemical ear. It would actually grow sensory organs in some sense that it could
actually pick up sound waves and it could build filters conducive to its survival. We also have
fungal and mold-based computing. Some of them are designed based on or using actually integrating
the pink oyster mushroom which is known for its internal geometrical calculations that can be
reprogrammed and then it can leverage the resultant electrical activity from the pink oyster mushroom
to drive the actual circuits of the system. So you sort of get a chimeric hybrid type of system
and they have many useful properties that have aspects of autopoietic mortal computing but not
all of them and it's not quite clear the current direction that fungal or mold-based computing
go but it is a promising example of aspects of mortal computation. I don't need to spend your
time on this one. I know you guys know Xenobots quite well but they are certainly an example of an
autopoietic mortal computer and you know it's a swarm of bio bots or biological robotic agents.
Essentially really I'll just digest to the point of that they essentially exhibit a form of morphogenesis
and basal cognition idealized in a multicellular form of a biological mortal computer. These could
serve as a source of inspiration for in silico-mortal computer designs as well especially for example
at neuromorphic computing. Maybe we could borrow a couple of the principles that we get. The nice
thing about Xenobots is they heal which I think is the most important part. Yeah and then there's
some nice aspects about the hardware. We talk about this in the paper and the very the extra appendix
that the hardware includes the genome whereas the software is the cellular communication
sorry the emergent cellular structures and the software is the cellular communication that
underwrites the creation of higher level structures and then of course what was let me see if I have
it here. Why is it not showing up? Oh for some reason my oh there it is. We also had very new
recently actually we'd already finished drafts. Anthrobots which are wonderful as well. We also
have the organoid there to the bottom right or known as intelligence at a dish. I also know you
guys are quite aware of that so I don't necessarily need to talk about sentient organoids but these
are examples of autopoietic mcs or mortal computers and the ideas that they have aspects that strongly
embody those central five tenets of mortal computation that we discussed earlier and since I
don't want to take up any more of your time there's a lot of implications for artificial
general intelligence. The mortal computation thesis could be one possible catalyst for what we
think is the next stage of artificial intelligence research where we need to go. A lot of today's
work again from the artificial transformers you might have heard of is that we have a sort of
centered around tool-oriented view or perspective of artificial intelligence while it's valuable and
stands to make a lot of nice benefits for humanity. The idea is that this is very different than how
animals and humans for example conduct processing and how we are naturally intelligent so we should
be pursuing survival and its relationship to mind and how what that can teach us about embodiment
and inactive intelligence. This could be the place that we need to go for biomedics by the way
biomedics is just the engineering application of biomimetic intelligent concepts and then we
have some things these are actually me appendix but I just wanted to briefly mention we're essentially
working towards like a form of artificial sentience rather than using the word intelligence. We are
also not dealing with the questions of consciousness we we tried to not really deal with that because
that can get quite messy philosophically. That's not important for what mortal computation says
we need to go but there are some implications if we actually built the exact idealized
mortal computer well now we have the fact that they can feel they can think that do we have to
consider giving them rights and I think that's a wonderful and important ethical discussion
that would need to happen assuming that this research program gets built on and then we have
this problem called the body niche problem very briefly just means that let's say research groups
like myself we don't have xenobots we don't have access to organoids so it'd be very hard for us to
actually use those resources unlike those in biological domains but perhaps we could build
virtual morphologies and we talk a little bit about how that's done in robotics and that could serve
as an example to democratize aspects of biological mortal computers and so I just I'll leave here
I'm not going to lab about this slide but I'll leave it hanging here these are some questions
that even I had as I was reading or rereading some of Michael's group's wonderful work about
enthrobots and xenobots and some potential interesting collaborative or at least directions
that could be explored and I am shamelessly plugging my lab software for modeling neuronal
dynamics in biological credit assignment and so forth so with that thank you very much and
if there's any questions I think we have like at least 10 minutes or so
cool thank you so much anybody else have questions
I've got a question so yeah thanks this was really interesting so I back when you were talking about
these three pillars of the cyber cybernetics as they apply to this I was interested in
the growth pillar could you just expand a bit upon what that is telling us basically
yeah so and I don't know if I have it here actually it's good to look at the
actually I'll do it this way so I don't have too uh yeah the growth uh yeah so there was a there's
a couple of more principles and things that I sort of hid here can you kind of see the slide
at least the picture yeah so the nice thing about growth from cybernetics is the idea that and I
mentioned that you know one of the starting points is self-replication the idea that you should be able
to produce copies of subsystems or produce essentially duplicates or be able to produce
extra parts and change and repair with time but autocatalytic growth was something I didn't really
mention and this is the idea that um you sort of get a feedback process so you can see from some
of the arrows that this is leading to self-assembly and so what it really was saying that we need a
morphogenetic process and as we gather resources then what ends up having is you see like an increase
out of a catalyst right the idea is that growth will start to grow up to a certain point until of
course you have no more resources this is what we talk about the niche providing that substrate
that material and energy exchange is really important in it of course doesn't allow you to
just keep growing infinitely ultimately what this leads in cybernetics view is this another
principle called the principle of recursive growth which ultimately leads to the emergence of
heterarchical not hierarchical heterarchical systems that are saying things grow really really
really big and of course they start creating things that are stable in the sense of building blocks
so there's a point where a system that's reached like an ultra stable state or has reached a certain
point of organization becomes a building block to a much bigger higher level system and so that's
kind of where the idea that like Herbert Simon and other classical thinkers talked about heteroc
emergence of heterarchical systems so effectively it's trying to say that you need to essentially
build in these morphogenetic changes you need to have this process that promotes growth and
self-repair because this is what's ultimately going to allow that system to continually persist
over time and again it sort of affects that the idea is that you get more and more complex systems
I didn't mention it later in the talk but you can have nested Markov blankets you can have Markov
blankets of Markov blankets of Markov blankets and now you get the of top down and bottom up
causal modulation but ultimately growth is just trying to say that we need these resources
and we need to be able to replicate either your entire entity and then add mutation which creates
the offspring as I mentioned earlier or you need to be able to reproduce and grow and replace
subsystems and that's the part where the building block concept comes in there's also one final
comment that at least I recall which is that as these things become stable systems that are built
of lower subsystems make it easier for those building blocks to join in because again now we
have this organizational principle from a high level relationships between parts I don't know if
that was helpful yeah it was uh okay thanks yeah thank you it's a good question
videos um yeah I also had a question um so one of the hallmarks of classical one diamond
computers is programmability right um the type of computer I just didn't hear you
uh uh one diamond computers the conventional computers it's it's uh programmability
so we can almost anyone can write a program almost using natural language um what about
programmability of models computers do you think that we might need some sort of model
programming language framework which is fundamentally different from a traditional
programming language framework that is a really good question and yeah that is something that
in my view you would lose uh from classical computer because the idea is that uh as I just
said and everything is sort of dependent on the morphology and the niche in which that morphology
is to exist in that agent or that mortal computer is to interact with so I would say that it gets
difficult because you need to now account for the properties of the morphology and sprinkle
throughout the paper we talk about uh that the homeostatic variables or the sorry the uh
metabolic primitives will largely depend on the actual substrate in which you are building
and it could be in silica it could be biological um I think that there is potentially and it's not
clear to me how so I'm just speculating to design general specifications not so much
that it would be like you can program in a mortal computer just like you would in your
standard von Neumann computer and like the python programming language but you could
take advantage that the system's organizationally closed and that they have essentially relations
between the parts so there are some sort of design principles that they adhere to and I think you
could design some level of general programmability for certain classes of mortal computers it wouldn't
be like oh let's say I have an animal let's say a very low level type of mortal computer something
very low level cellular versus a complex organism I would say that the programming specifications
might be dependent on the class of mortal computer and the type of entity in the even the niche in
which it interacts but you could essentially program classes or slices of mortal computer so
again if we're dealing with like I had in my other diagram the neuro robot that was a version of like
the dog robots that come from like Boston Dynamics um you could essentially imagine designing
programming language around those types of quadrupeds um and so I think it would be you'd
need to account for like the essential primitives and the environmental variables that are part
of this process and we need to be able to specify them to some degree if we want the programmability
I think it gets complicated though because I do think while we are sort of arguing for this
entanglement right because the software really isn't divorceable from the hardware and real entities
um the place where maybe you get some of that general programmability is in the virtual morphology
and I think that's our best bet because ultimately when you're building these uh systems themselves
you sort of need to work with the actual hardware for time but let's see robotics uh it's a little
bit different with biological entities too although I know like the Xenobots that you have way or the
Anthrobots even you have ways of which you can program them uh you know there was some uh biochemical
processes that were described in some of Mike's work um I don't know if that helps though but I do
think you lose some of that programmability but what you gain is this massive energy efficiency
as you start to approach uh those lower bounds you start to approach the place of thermodynamic
efficiency the best that you can get with physically realizable Bayesian inference I do
think though the programming part can come in from more virtual morphologies to allow us to
deal with the organizational properties and allow us to experiment and you know work with
different designs does that answer your question too the
