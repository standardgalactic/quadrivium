Okay, so I'm Mark James, I'm a philosopher in cognitive science and Tesh and I are both
part of something called, that's my cat, forgive her, Tesh and I are some part of something
called the Embodied Cognitive Science Unit, we're situated in the Okinawa Institute of
Science and Technology in Japan, and our PI in the unit is Tom Froze, and the unit was
kind of set up in the tradition of someone like Francisco Varela, intended to be a kind
of scientific inquiry into a kind of generally non-representational approach to cognition.
Maybe the kind of like maybe guiding model of our unit is the idea that interaction matters,
so that's interaction between say, brain, body and environment, but also individual
person and the various scales that both comprise them and they help comprise.
So we have projects on the individual science of agency and sensory substitution, we have
some projects looking at data interaction, be they say real-time reciprocal interaction
face-to-face or in digitally mediated environments, we have people looking at collectives, so
like criticality in the swarms of bees or in teams, we also have archaeologists looking
at the emergence of social complexity and even astrobiologists looking at resilience
at a planetary scale, and at least part of the ambition is to acknowledge the kind of
synthesis across these scales and how all these things interact, which is an ongoing
work, as you might imagine.
Our unit PI itself tends to be focused on questions related to the interaction of let's
say mind and matter, so questions around consciousness.
Personally I'm interested in how all these interactions can be leveraged in a kind of
practical sense to serve the redirection of our behavior towards health, I guess broadly
speaking, and TESH I guess is one of the people working on one of the models that we
find helpful in all of this to think about how these systems learn and evolve together
as the notion of self-optimization, so I'm happy to jump back in for any sort of questions
or whatever, but I'll let TESH take it over from here.
Thank you Mark, yeah, so Tesh or Natalia officially, just a bit about my background, I'm originally
trained as a chemist and I did theoretical chemistry for my monsters, then during my PhD
in OIST I found an opportunity to switch to the field of cognitive science and I got very
lucky in that I could combine the skills I had with a topic I find very interesting.
So the work that I will present you today is based on this paper we published in December
and in it we show that how can we leverage the power of associative memory of hopeful
neural networks to solve complex logical problems, specifically propositional satisfiability
problems, this paper is fairly technical but it ties neatly with what I want to do in
my own research project which is related to creativity because with this computational
model we get to explore how dynamic assistive can break constraints of a problem that it
is supposed to solve and constraints are integral to creativity, so Michael you're familiar
with this model but just to be in the interest of self-contained I will give introduction
to hopeful networks and then disability problems and I'll show how we can cover maps with it.
So hopeful neural networks named after John Hopfield are a former recurring network meaning
that there are back and forth connections between all the nodes of the network.
To describe the dynamics of the system we can use a vector of states s where each node
can be described either as a discrete or has a discrete or continuous value, in this work
we use a bipolar value of minus one and one.
We update the system asynchronously meaning that at each step of the simulation only one
node is randomly picked and updated.
The output of that node is a function of a weighted sum of all the inputs from all the
nodes in the network, in this specific work we use a simple step pressure function.
So then with this state update what will happen is that the network will start rearranging
itself depending on the sign and the value of the weight wij between any two nodes.
So si might switch sign or sj might switch sign and these rearrangements of signs will
result in a different state of the system.
We can then evaluate the difference between these two states using so-called energy function
described by this mathematical formula which reflects the misalignment of stress within
the state.
The minus sign indicates that the energy decreases as the network moves towards a stable state.
So at some point when the energy does not change anymore we know that the system reached
a stable state or an attractor.
So hopeful neural networks are recurring neural networks that converge to a stable state.
This converges to a stable state can be used in several ways.
So first we can find the solution to a complex combinatorial problem, for example the traveling
salesman problem.
This is a problem that you given a certain list of cities and you need to find the shortest
route visiting all the cities exactly once and return to the starting point.
So Hopfield and Tank show that if the connections of the Hopfield neural network, the weight
matrix w, correspond to the constraints of this problem then the natural dynamics of
the system is to converge to a stable state that will correspond to a locally optimal
solution to that problem, meaning one of the possible routes.
Now another way we can use this convergence to a stable state of Hopfield networks is
to recall patterns for example.
And this is what Hopfield did in his original work.
He showed that we can take some patterns for example images and use heavy learning to
store them in the network's connections.
This is a learning rule often summarized as cells that fire together, wire together.
If the system then is introduced to a partial pattern or corrupted image of the stored memory,
it will act as an associative memory and converge to a state representing that stored memory.
Now what I mentioned briefly before is that the usual dynamics of the Hopfield network
is to converge to a local minimum.
This is often results in a suboptimal solution.
In fact in that traveling salesman problem paper Hopfield and Tank mentioned that this
system will only find the shortest path 50% of the time.
This problem however can be resolved if we use the associative memory capability of Hopfield
network.
So and this is what Richard Watson and his colleagues did.
They showed that if we take some abstract combinatorial optimization problem and constraints of that
problem will be again represented in the weights, but we will also update the weights
using heavy learning with certain learning rate alpha, meaning that we imprint on the
weight matrix every state it visits.
And we also reset the system to some random initial state every time it converges to local
minimum.
Then the system can reach a global minimum, which potentially means the best solution.
So this model which we address as the self optimization model in our group was shown
to be generally enough to model various complex adaptive systems from gene regulation networks
to selfish agents and socio-political networks to just name a few.
And if I'm not mistaken in the recent paper with you, Michael, you are using slight modification
of this model to show transition in agency.
However, all of this research focuses mainly on abstract problems.
Now, abstract problems are very important for providing understanding of the general
behavior of the process.
But when the weight matrix doesn't represent a concrete set of constraints, it is hard
to analyze what exactly learning does to the system.
And this is what we wanted to investigate in this work.
We showed that the model can also solve concrete problems as well, specifically the satisfiability
problems or SAT problems.
By having concrete problems, we can then provide an insight to the relationship between learning
and breaking of the problem constraints.
So just before I jump to the results, I want to give a quick overview of satisfiability
problems.
So satisfiability problems or SAT in short are questions and logic where you need to
determine if there is a way to assign true values to a variable such that a certain proposition
of formal is true.
This has immense applications since many important real-world problems in different scientific
fields can be expressed as max k SAT, which means maximum satisfiability problems with
a maximum of k literals per class.
And I'll explain what that means in a bit.
So anything from planning problems in engineering can verify software and computer science to
solving bioinformatics problems.
To give you an example of a problem, of a SAT problem, let's look at Lyres problem.
So imagine we have a room with four people, Alice, Bob, Cal, and Dan.
And some of them or all of them can make statements here.
Alice says Dan is a liar, Dan says Bob is a truth teller, Cal says both is a liar.
And so our goal is given those statements to find out who is actually the truth teller
or who is a liar.
These facts can be represented by a vector of states s with the fact that the i of person
is a liar or truth teller represented by the state si, where if si equals one, it denotes
that the person i being a truth teller and si equals zero denotes that person being a
liar.
So from this statement, using these representations, we can build logical relations.
And then from these relations, we can get our propositional formula.
And if somebody doesn't have a background in satisfiability, I recommend this link here
below as an initial tutorial.
I initially didn't have a background in satisfiability, so this was very useful to me.
But what we see here in this propositional formula, each term in the brackets is essentially
a clause.
There are two literals per clause, and they're separate by an operator here.
The operator inside the first term is an or or disjunction.
And the operators connecting each term, each brackets, each clause are operators of and
or conjunction.
So this is a formula of six clauses, so a conjunction of the disjunctions.
And each term here has two literals in this in in the in the clause.
So this is a max two set problem.
So only two literals per each clause.
This will be relevant in a bit.
That's why I'm kind of explaining it.
So now that we have this propositional formula, the next thing that we would do, we would
put it inside of a set solver.
And there is a plethora of set solvers out there.
There's a competition on set solvers every year in an interesting field.
And what a set solver does essentially, it outputs two possible outputs.
So either this propositional formula is satisfiable, and then it will provide us with an assignment
of the values that we're interested in.
So in this case, Alice in Calour Liars, Bob, and then the truth tellers.
Or it will output no, it's unsatisfiable.
So given those relations that we give it, we cannot satisfy this propositional formula.
So in this in this work, what we were interested in is, can we take this propositional formula
and start using this sol model such that if the there is a solution, so the system will
converge to a stable state with energy equals zero.
And each node will represent our assignment.
Or if there is no solution, or then the state will be with higher energy, such that every
unit of an energy will present how many clauses were not satisfied.
So what we needed, what we needed is a way of mapping this set problem to the Hopf-H端ner
network.
Fortunately, this mapping was already performed in the 90s, first by Gottlieb Pinkins, and
then followed by one abdua, and his method is the one we implement here.
In short, given the description of the problem by the propositional formula, this method
allows us to describe the formula as an energy expression.
So then we can compare this term, this expression term by term with the expression of the energy
of the Hopf-H端ner network.
And this will give us a weight matrix that will describe the set problem.
So for this specific problem, a max to solve problem, as I said, the Liars problem.
So similarly to when the weights describe the constraints of a traveling salesman problem,
and then the dynamics of the system will give us the solution, the shortest path.
By using this method, we can use any set problem, and the dynamics of the system will give us
the solution to the that set problem.
So this is what it is.
So using this model, we can look again at the Liars problem.
We took a bit more, 50 people with 34 statements.
So person 1 says, person 4 is a liar, and so on.
So what we see here in this pot A is how this weight matrix initially looks like, that represents
those 34 statements.
Then in this pot, what we see is basically the solutions.
There's essentially three distribution of energies.
First let's look from 0 to 1000, the dark blue.
This is basically regular Hopf-H端ner dynamics, no learning.
What would happen if we just run the simulation for this weight matrix on the Hopf-H端ner
dynamics, and let it converge, and then reset it again?
So what we see is that there is basically the system explores all possible solutions.
Sometimes it finds the correct solution.
Sometimes it converges to a stable state of energy four, meaning there's four clauses
that were not satisfied.
Now the red part, the self-fantasy, is basically when we turn on the learning, this is the
SL model.
So what you see here is that after a certain amount of resets, the entire system converges
to a global solution, the correct one, with energy equals zero, meaning it managed to
find a state that satisfies all the constraints.
And what is interesting is that once we turn off the learning, this is the light blue line
at the end, even though we continue resetting the system to some random initial state, it
stays on the global solution.
So yeah, and just to show you, this is how the weight matrix looks like at the end of
the simulation.
So this is a system that augments its behavior with associative memory of its own attractors
