When Josh was visiting our lab, we had two, among many other things, we had two interesting points that we talked about that I thought, you know, Chris could talk about as well, which one was about error correcting codes.
So, maybe we can, we can start with that and then the other one had to do with with proto cognitive capacities at the bottom of the scale, you know, particles and things like that so.
So, I don't know, maybe, maybe we start with the error correcting codes. You guys want to talk about error correction and how you see it. Maybe Josh, did you want to go first and just summarize what you were saying.
Yes, very briefly put, the reason why there's something rather than nothing is probably because the universe is not impossible. So if you're based reality nothing precedes the universe to make it not happen it's going to have an existing in the non existing branch.
And the non existing branch you don't get observers that complain so you basically have existence for free.
Now we need to figure out why some things are happening in the existing branch and others are not happening.
And the easiest answer to that is that simply everything is happening because there's nothing proceeding universe to select operators.
The universe is the superposition of all operators, which means it's a multivase system.
And you yourself being computed by it don't know which pass you are so the universe for you is going to have the appearance of being into domestic, which means that if you zoom in at the lowest level near the vacuum you'll see lots of random fluctuations that usually don't amount to anything.
In the structure, one part of the universe needs to what another part of the universe is doing. So sometimes you get the circumstances where you have a pattern that remains stable, statistically stable.
You will not be able to figure out whether you are in the past where the universe is going to the photon is going to the right or left slot, but you know what a million photons are going to look like.
Okay, you don't know which operator is going to happen next, but you know what the superposition of operators is going to look like when you have enough of them, and certain starting state.
And sometimes, basically you get a situation where the universe is going to perform our correction.
Before I think is you sit in a bus tub you move your hand you see on the surface of the bus tub lots of patterns emerging lots of waves, most of which are just dissipating not amounting to anything.
But sometimes you get a particle which means a vortex, and the vortex has this property that it's basically circle so it's shoving the information around in the same volume of space and doesn't dissipate until friction makes it disappear or until it bumps into something.
Water in the bus tub wants to produce those vertices more than other things is just what's left over.
And I suspect that the same thing is true for all the particles that basically they are error correcting codes, and the simplest one are control systems that act in the present on the present state or just the immediate state after that.
And slightly more complex control systems have a certain degree of elasticity like molecules can squish them and they bounce back into shape.
And cells are controllers for future states their agents they basically make models of future past so you can remain stable over much more complicated circumstances and in this way you could say that life itself is an error correcting code that allows to keep particle
integration stable that otherwise wouldn't control regions of the universe that wouldn't. And of course it doesn't stop at the level of sales but also their systems above the levels of sales like organisms societies and so on, where you find the replication of those control principles.
But that all sounds good to me.
Next.
So the conclusion from from that train of thought is that one way of thinking about mental representations is to look at them from the perspective of our correction to look at them as quasi particles, a difference between heat and sound is not that one is not bouncing molecules
so it's not that both are, but sound is information preserving.
It's even quantized. If you look at phonons, it's a quasi particle that is emergent over the activity of the molecules it's what's left over after you dissipate the heat, in some sense, in the same way if our brain is we can be seen maybe as an ether where the individual neurons are
that are passing on signals from neighboring nodes in the topology.
And then, if that thing is stable information preserving so you can compute with it. It's basically representations activation waves are something like quite a particles moving so that's thing.
Yeah, so.
Yeah, are you familiar with Princeton's work on free energy.
Yeah, okay. So, I mean, I guess I interpret the, or I see the free energy principle in its simplest form.
As saying something much along these lines.
That any system that persists that remains stable has to do something or other to keep its its boundary intact.
It has to effectively be auto poetic.
Has to maintain some level of structure.
But not so whatever the system looks like. Pardon me.
It needs to keep its boundary and time and tech, not in space. Right. It is needs to write itself into the future.
But it can be something that is actively colonizing as long as nothing invades it.
Yeah, it has to write some bounded set of values of some bounded set of degrees of freedom into the future.
But for instance life doesn't need to keep its boundary intact in the sense that it needs to be worried about being invaded by nothingness.
Because you can just itself invade chaos, but it needs to keep its boundary and time intact.
Basically, it's frontier by which it writes itself into the future needs to preserve it.
Okay, okay. Yeah, by boundary, I mean state space boundary.
Yes.
So, yeah, put everything in a Hilbert space or something. That's the boundary that's of interest in the in the free energy principle.
One, I think in translate what you just said into free energy principle terms without too much trouble. It's certainly consistent.
With what the free energy principle says, although the, the FEP community doesn't seem to talk about error correcting codes very much.
They talk about persistent structure instead. But since they fundamentally think of systems as informational structures, maintaining a consistent structure.
If you're an informational structure just is being an error correcting code.
So I think that hangs together quite nicely.
I guess another reflection, I think off of what you just said is the Zurich quantum Darwinist picture, which you probably are familiar with also in which state components of some system are being selected by its environment for stability.
And again, it's a very boundary preservation sort of idea.
If you fix the boundary between the system and its environment, then you fix the interaction at that boundary and given given an interaction for the whole system.
And then the stability of that interaction is effectively has to be preserved by the system and its environment working together.
And in that case, the eigenvalues of the interaction are essentially being preserved by an error correcting code, the code space being the internal dynamics of both the system and its environment.
And I guess the third kind of perspective on that is sort of the more more general perspective of error correcting codes that's operable and things like ADS CFT, where the state of of some volume is coupled to the state of its surface.
So, again, and a question of, although, although there in that community they don't talk explicitly about observation they take that for granted.
So there is something or other going on in the surface that's describable by some theory.
I suspect that the ADS CFT conformance is is a bit of a red herring.
I think that the universe fundamentally is automata.
Right, so it does is not a volume or not a surface because it's geometry geometry is only what happens when you squint at automata at scale.
Yeah, no, so of course you need to have some kind of conformance like this if you have a field description of the universe and the graph description and you need to map between them.
This time is based at a set of locations that we can make out and the trajectories that information can take between them, and that puts some constraints on what spaces you can observe if they give rise to systems like you.
Yeah, terrific.
Yeah, I completely agree about space and being a merchant.
In fact, Mike and I have been talking for some time about it.
I don't really know what it exactly describes if you look at the LLM that seems to be a radically Fristonian machine in that it's trying to minimize the prediction error.
And you could say that it's this free my energy minimization going on at some level.
But for organisms, it's happening in the limit, like for all life on Earth or something like that. But individual organisms look for more concrete things, because they are occupying only a small region in the space of behaviors.
Right, in some sense, humanity is is not an independent species it's more an organ in the entire dance of the cell on Earth.
And our particular role in this organ is just to burn the oil apparently to
No, our role is to really provide walking apartment houses for bacteria.
That's true for all large organisms.
I think they are the only organism that is able to basically collect this particular entropy the accidentally fossilized biocarbon that was turned into trees before there were enough insects to take the trees apart.
And so our role is to basically put it back into a circulation so that I can make new organisms and they don't know whether guy are already planned for us to wake up the rocks.
I think if that happens, there is the next stage of evolution, but it's going to be awesome because we are going to have substrates to run consciousness on that are magnitudes faster.
Which leads me to this question what consciousness is nice suspect that it's not in a prediction error minimizer but a coherence maximizer.
It's basically an operator that is not working like the transformer does and the alarm minimizing some prediction error, but it's a colonizing operator that takes suitable trainable, but somewhat cardiac substrate, and then imposes an
operation on it that is locally coherent so it acts in such a way as if it was a single agent.
Is there any operational difference between those two.
Because we see that the LLM is becoming coherent in the limit after you train the entire internet into it and use almost all of the compute on the planet it's almost coherent.
But it does lack the creativity right now to.
Yeah, I mean you can say the same thing about people right most of us are not coherent all the time.
But, but that's also because I think humans are evolved to be domesticated.
We are not the smart home in it we are the programmable home in it we can walk a lockstep.
I see a lot of humans when they are confronted with the opportunity to be truthful or to be in synchronization with the environment, pick the letter.
And you can see why that is evolutionary beneficial under the conditions where the ancestors go up.
I also think that there are a lot of humans which lack that limitation and they are basically generally intelligent vision the limitations of the substrate which are severe but if you put them into a different substrate, there is nothing that they cannot do.
Be interesting to test.
I mean history tries to test it but we can't replicate those those experiments.
I'm not I'm not sure as you know how similar it is to to surprise minimization all that but but I do but I really like this notion of sense making as the function as the as the right as the primary goal of it and I've been thinking about this recently in the context of
memory and the idea that you know what you get in these n grams is an incredibly compressed, very sparse representation of things that happened before, and at any given time since you don't have access to all of that which have access to is just the n gram.
The process of sort of re expanding it back out is very creative it isn't, you know you don't have a real allegiance to what did this mean before all you have is well what do I do with this now right what sense can I make of this now, and this like, you know,
ongoing dynamic property of a process of trying to understand what your own memories mean, and I almost feel like, you know, Mark, Mark solmes has this has this phrase about consciousness being palpated uncertainty about the environment.
I think maybe it's more palpated uncertainty about your own memories it's this constant process of, you know, here you are now with whatever traces the past is left in your in your brain and body, and you're constantly trying to make a coherent story out of this you know it's a, and a lot of it I
think you have to be creative you have to bring stuff to it that is not in the in the n gram itself because you've, you know of course compressed that you've thrown away all the, you know, all the, all the correlations and everything else and so a lot of it I think is that that that confabulatory kind of process where it doesn't matter what it used to
what matters is what can I do with it now, you know, and and we have in biology we have we have examples of this like the fact that the, the fact that the butterfly retains memories of the caterpillar, right, even though the brain is refactored during metamorphosis and all that but
you know to me the most interesting part of that is that the actual memories of the caterpillar are of no use to the butterfly whatsoever, you can't you can't use the the exact memories but what you can do is re and remap some of that information onto a completely new body new preferences,
new motion, motion control. Now you live in a 3D world you're a hard-bodied creature now instead of a, you know, a crawler and 2D.
You can't use the memories directly but you can re reinterpret them in ways that make sense to you now, you know, and do things with them now. So, I like I like that that emphasis on this, you know, the kind of the active construction aspect of it.
You know, Mike, I think we could tell exactly the same story you've told here about percepts from the external world as opposed to memories which we kind of tend to think of as percepts from the internal world.
Although lots of them are actually written on the external world as some sort of stigmatic record as we've discussed a lot, but any, you know, take it down to the cellular level, some receptor becomes activated and kicks off some pathway.
It doesn't actually matter to the cell what the previous event that kicked off that receptor was. What matters to the cell is what do I have to do now, given what I just sensed.
And that sensation or percept, if you want to put it in some sort of conceptual terms, can be external or internal. It doesn't really matter. It's still information that has to be coped with in the present somehow or other.
And this is this is why I think that Carl's emphasis on appropriate action is a nice way to think about coherence.
I mean, we've, we've sort of adopted previously in papers, Bateson's notion of differences that make a difference. And what do they make a difference for? They make a difference for doing something.
And coping in real time with whatever information is coming in. And from that point of view, the question of, I have this information, what do I do? What do I do next? Is a prediction problem?
And the question is, you make a prediction, you do something, right? You act on the environment in some way or other. And the result of that action is either good for you or bad for you.
And so maybe you cease to exist, or maybe some food appears, or maybe maybe something very threatening appears, who knows.
So in that sense, this is a very simple sense, of course, of testing predictions. You're just acting and seeing what happens. But there was some model that drove the selection of that action.
And I think that's really all that Carl's talking about. You can, you can, you can make it sound very cognitive, but you don't have to.
The good side of the transformer is that, in my view, the serialization of only adjacent events has limitations.
When you want to model the structure of text, you cannot use the same as for images or images, you can use convolutional networks because they basically embody this bias that adjacent pixels are semantically related, which works relatively well in the visual world.
But for text, this doesn't work because you are going to miss all the long range connections in the text. If you look at ngrams, it's very difficult because the alphabet is too large to basically make an ngram model that is bridging over large distance in the text.
So now you basically need to find structure that is freeform, so to speak, that is deserializing the text into a scene and operate on that scene. And you need to have a process that is actively constructing your working memory contents.
Not as a sequence of events where you decide what to do next, but where you're modeling the entire future space of possibilities at once and then sort that space somehow.
It seems just a funny thing, Sam Gershman wrote a couple of days ago, you're about to computer code and kind of keeping it up to date and everything, and he said, your most important collaborator is you six months ago, and he's not answering emails.
And I thought that was pretty funny, you know, in terms of, in terms of, you know, the messages, interpreting the messages and where they come from.
But I think in, you know, Chris, to your point a minute ago, when you get this, when this event happens, I think maybe one important piece of metadata you might want is whether that event was caused by you, whatever that is, or by something else, right?
Because wouldn't you want to know if something is like, am I being hacked? Am I being trained? Am I learning or am I being trained? You know, if there's a particular event, biologically anyway, it would seem like there's some value to understand, did I just do that?
Or was this somehow triggered from the outside? It seems like there would be evolutionary pressure to have ways of figuring that out, no?
Well, we certainly have very complicated machinery that tries to answer that question, that this whole kind of cognitive ownership and the emotions associated with cognitive ownership and all of that stuff that goes wrong in particular ways and particular unfortunate people.
And yeah, getting that sort of thing systematically wrong is debilitating. But it's all essentially heuristic, right? It's a heuristic solution to an undecidable problem. It's like our frame problem, you know, heuristics.
So, yeah, I think that sort of heuristic metaprocessing is extremely important. Let me remark also for a moment on language. When we're thinking about language and parsing and non-local relations and all of that, I think one way,
one thing we have to think about in terms of chunking input into bigger pieces that are then analyzed as units is that that's a time-windowing kind of process where we allow some input to come in.
And then we say, okay, you mentioned working memory capacity. I mean, now we're going to put this in working memory, and we're going to do a bunch of stuff to it, and then we're going to allow the frame to advance and do a bunch of stuff to the next chunk and compare those two results for consistency, et cetera.
So, we are working at this larger delta t, but I think at that larger delta t, we're still answering what do I do next question. You know, what do I do with this sentence? What do I do with this paragraph?
How can I put this in a representation that I feel like I understand? And feeling like I understand it means feeling like there's something I can do with it. There's some inference I can make from it, for example.
So it's a very good point that you make about the difference between language and images. But I think it's mainly a scaling point as well. It's like the geometry point you made earlier.
You know, we're constantly imposing these sorts of geometries on information that we encounter. And the geometry may or may not be there. We always treat it as there, right? We say, oh, that geometry is in the external world, but it's really us that's putting that geometry under the input.
I think a lot of our actions only make sense when we recognize that you're not just deciding what to do now. Like some of us start us like a control system in the present best, but the agency is the control of future states.
And what I observe in humans that they seem to be temporarily more coherent than, for instance, the present AI video models, which have more real-time coherence in the sense that they're coherent in space, that when you generate a picture, all the features in the picture seem to be more
coherent than the picture is coherent in two seconds into the future.
So basically the information preservation across time is something that's difficult to discover for the present models. And humans are much, much better at this, recognizing that the volume that you are looking at needs to remain constant over very many frames into the future, for instance.
For the spatial cohesion of the objects that we're looking at.
And that means that we have to build a model that is more compressed than the ones that the LLMs and the foundation models are currently building.
Yeah, no, I can, I can certainly see that. I mean, in a sense, you're making Mike's point about memory, except in the other direction.
We have this notion of, not only a past notion of, but a future expectation about the preservation of identity, but what counts as identity gets fuzzier and fuzzier as the planning horizon increases.
So if I'm planning my future, I could think, okay, well, I'm still going to exist a year from now, maybe. But who knows what I'll be like, right? I don't have, I don't have details about that.
In the same way that I don't have details about last year.
So I think this, this business of coarse graining is very important when we think about temporal coherence.
Yeah, I think that identity is ultimately always instrumental to a credit assignment.
And if you remove that, then identity is going to dissolve. It's not going to form in the first place.
But if you don't have a reason to discover yourself as something that is idiosyncratic, for instance, behaving specifically based on your protocol memory.
And then it makes very little sense to assign identity to yourself, making a self model.
One thing that's interesting to me is the question of what it means to train another system and observe that cats are usually most stupid than dogs, but they are much better at training people.
And as a result, they're also less trainable.
It seems they basically have evolved to train others.
As opposed to be trained, which dogs are evolved to be similar to a government.
They sometimes joke that government is the principle to recursively bully people.
And it's invented in many, many societies independently and once government is discovered it's going to colonize until it meets the boundary of another government with a shorter logistics chain.
And so up to a certain size of the system governments tend to be singletons.
They suspect the same is true for consciousness in the brain, for instance, across brains, but the protocol changes and the degree of cohesion changes the bandwidth changes.
And so it's much easier for other systems to work up to this boundary than you for yourself to spread over that boundary.
The bandwidth is no longer large enough to do that. A similar thing is happening when 120 people are controlling the Indian subcontinent you will be British East India company until the local systems are figuring out how this algorithm works and that they have a shorter information chain and are pushing out the occupants.
So basically I wonder what it means to colonize an environment to entrain yourself visit and to build it into structure that extends you.
That's nice. That's, I think that's a nice way to think about things. Yeah.
More sociology applied to biology and physics.
Except normally they decide distinguish two types of sociologists, those who understand social power and those who don't. And the former are called economists.
At ultimately it's an economical problem.
So what the dictators call energy is actually compute credits that you get computed by the substrate when you're competing with other agents that want to be computed by the same sub spreads in your society of mind, for instance, or more generally in nature.
Yeah, jump back for a second back back to just one last thing on this error correction business. So would you, would you say then that the notion of error correction presupposes a distinction between what's an error and what isn't.
In other words, like, you know, chemistry doesn't make mistakes so chemistry just does what chemistry does, but developmental biology which in theory people think is driven by chemistry, definitely makes mistakes.
Right, you have birth defects and things like that. And so, so the distinction. So there's a distinction there because you make errors relative to expectation of some other observer expectation of yourself about what you were trying to do expectation with respect to some
like, you know, you want it to hit whatever but in in in the in the way that you guys are using this term is there any notion of error as distinct from, you know, enough non error or or is this something else.
So, first of all, there are in variances that we observe. And, for instance, I told you I became an animus in recent years.
And that's not because I think that physicalism is wrong, but because I think that the invariance that you're looking at when you look at living things is the software that runs on the region of physics, not the mechanism itself.
The current dominant perspective in Western science is that the world is mechanical, and we need to explain it in terms of mechanisms.
Yet we also understand that, for instance, money is not mechanical.
It's a software that is only apparent when you have a certain course when you put on to the world to interpret the world, but also important aspects of the world make no sense if you don't use money as the experiment.
And because money itself is the invariant pattern that inscribes itself onto the physical reality there.
And the same way minds are invariant pattern or software is an invariant pattern that we care about we don't care about the number of transistors that implement the software.
We don't care about the specific neurons that implement the mind, because the mind is able to recruit other neurons if some of them fail.
And so the invariance is actually the software pattern.
And the reason why these invariances exist is because they compress reality and such a way that becomes controllable.
And according to the good regulator theory, if you want to control something you need to implement a model of what you control.
And I suspect that's the reason why the universe is so surprisingly learnable because all the structure that you observe is probably control structure.
And that means that the universe was able to miss its means on every level was able to discover models.
And particles are probably just vortices. So it's not much to discover.
And the atoms and molecules are the emergent patterns over the particle dynamics.
And, but for sales, it's much more complicated because for sales, you need to have some kind of control system and this that is looking into the future.
And here the complexity becomes so large that you need to stay in the realm of discoverable models.
And that means that you need to highly compress what the agent is doing. So you describe it as a single system with a single main concern and all the other concerns of the system being subservient to it.
You know, our discussion about thoughts and thinkers Mike.
Yeah.
Yeah, I broadly agree with that.
And I would say to have to have a usable error correcting code.
You need to have.
You need to also have classical communication.
And what counts as an error then is a discrepancy between what some system sees and what it expects to see based on its communications with some other system.
So, if I'm
And this is basically Shannon information theory.
If I'm sending a message across some channel and you're receiving it.
Then the message is noise unless we've already shared some sort of information like a language, for example, or a language plus some semantic box that the message is supposed to be about.
And if we share enough, then all I need to do is send a bit.
And for safety, I send three bits to give you some error correction capacity.
But those three bits only mean anything if we've communicated before about what the question is that's being answered.
And the, I mean, the same considerations go over into quantum codes.
When you talk about classical communication. What alternative is that classical communication.
Well,
I think the, I think the question here is, if you have a bunch of interactions, which are defining using quantum theory or information flow or whatever you want to use.
