Hello, this is Zenyash, and this is Steven, and we are the base in conspiracy. Katrina
is not with us today. Last episode, we talked about ethical theories. Yeah, moral philosophy.
Moral philosophy. And while we were doing that afterwards, I said, you know, there's
this guy named Alonso Fife who has a blog called The Atheist Ethicist, and he was a
huge influence on my ethical thinking over the past decade or so. And how would you guys
feel about just talking to him for a little while? And I said, yeah, sure, that sounds
like a good idea. So I got into contact with him, and he agreed to come on the show. And
this is our interview, Steven and me with Alonso Fife.
The sound quality was a little touch and go. We ended up taking a break partway through
to go reset the router. We're not sure where the problems are coming from, but do forgive
the subpar audio quality. Anyway, thanks. Hope you enjoyed the episode.
Okay, now that we are actually recording, I would like to introduce you again. This
is Alonso Fife on the line with us. He is the, he blogs at the Atheist Ethicist blog,
and I have been a fan of his for a long time. So as a follow up to last episode, we decided
to call him and talk with him about moral theory. Alonso, I'm sorry I interrupted you
earlier. Could you introduce yourself and briefly tell us about desirism?
Okay, my name is Alonso Fife. When I was in junior high, I got interested in moral philosophy.
What I noticed was that there were a lot of different people making a bunch of different
claims. And I wanted to know which ones were right. So, well, that got me into moral philosophy,
which I've been studying for quite some time. Desirism is the idea that actions really aren't
the primary object of moral evaluation. When people evaluate or make moral evaluations,
what they're actually evaluating are desires. And the evaluation of actions is derived from
that. So, a right act is the act that a person with good desires would do. It's not right
in itself or for its own sake. And usually the first question that gets asked when someone
hears that is, what makes a desire good? What makes a desire good is its capacity to fulfill
other desires. One of the main things about desirism is it holds that desires are the
only, well, the technical phrase is it's the only end reason for intentional action.
The only reason that you have to do something or to avoid something is because it either
fulfills or it forwards a desire. And that also applies to, that applies to evaluating
anything. Everything is evaluated according to its relationship to desires. But that includes
other desires. Each desire is evaluated according to its capacity to either fulfill or thwart
other desires. Is desirism your term or does that go back further? More or less, it's my
term or it's the term that's applied to these ideas that I came from. It came about in part,
I had a couple of people convince me to adopt the term desirism. Originally, I believe
you called it desire utilitarianism. Yeah, it was originally called desire utilitarianism,
which is a version of motive utilitarianism, which came out by R. M. Hare, no, Robert Adams
in the 1974 Journal of Philosophy. Desire utilitarianism, it's pretty much the same
thing, except it holds that desires are evaluated according to their capacity to maximize utility.
And then the question is, what is utility and why does it deserve to be maximized? Ultimately,
when I came to the idea that a desire has to be evaluated according to its capacity to
fulfill other desires, that meant dropping the utilitarianism aspect and just adopting
desirism. So did you become convinced that what utility is, is desires being fulfilled
or did you just change what you actually think the correct evaluation of things is?
Well, desires being fulfilled, there's no such thing as an intrinsic value. You can't
identify something in the universe and say, this has value for its own sake. Everything
has value because of its relationship to desires. And that applies to desire fulfillment itself,
it doesn't have any type of intrinsic value. If, for example, I like chocolate cake, if
I'm eating chocolate cakes, then that's a good thing because it fulfills my desire to
eat chocolate cake, but desire fulfillment itself isn't what has value, it's the eating
the chocolate cake that has value to me because I have a desire for chocolate cake.
So when you use the word desire, is that the same kind of thing that, say, you know,
a lion has a desire to catch prey animals or is it something that we learned in this
little bit on our last episode we were talking about, that in my experience in the field
of moral philosophy, most consideration of things that can be considered moral agents
are rational agents that exclude children, or against human children, mentally infirm
humans and basically nonhumans. So it wouldn't make sense to morally judge a cat or a dog
or whatever. So does desires encompass the desires of nonhumans in that same regard?
Well, animals have desires, which means animals can be harmed or benefited. I don't think
that part is controversial. As far as holding animals morally responsible, that would be
kind of a waste of time because they can't understand the moral claims. So that applies
also to young children or to the mentally infirm. So they're not moral agents, but
they are what's called moral patients. They can be the subject of morality even though
you can't hold them morally responsible for their actions.
That makes sense.
I like the distinction that they still have desires, but okay, I guess I'm skipping ahead
here, that the tools of moral instruction tend to be things like reward and praise and
condemnation. And since they don't have the ability to reward or praise or punish us,
that it makes it very hard for their desires to be taken into our calculations.
Well, yeah, that's right. They don't have the capacity to know that they can modify
our behavior by modifying our desires. The way we do to them, and we do do that to animals,
we do punish and praise animals as a way of modifying their behavior to suit our interests,
particularly that it particularly applies to pets and trained animals.
So I can, I guess I skipped ahead and I want to walk back a little bit. This whole concept
of desires being not just things that are what we, not just things that are evaluated,
but things that are altered by humans.
Yes. Desires can be molded, and that's where the idea of praise and condemnation or reward
and punishment come in, is that's the way that we change the desires of other creatures,
other human beings.
When you praise something, you create in the other people a stronger desire to do that,
which is praise, or if you reward something, it creates an interest in doing that, which
is rewarded. And that gives us a reason to reward such things as charitable actions,
or honesty, or kindness. And the opposite is true with respect to punishment and condemnation.
That tends to form an aversion to certain types of things or certain types of acts.
So we have reason to condemn and to punish things like breaking promises, or taking
other people's property without their consent, or vandalism, or assault. We condemn those
things in order to create an aversion to those particular types of actions.
How do you weigh competing desires? Say, someone's desire to eat a chicken sandwich
and a chicken's desire to not be made, or any other two examples? I guess what I'm asking
in general is, when desires conflict, what's their formula for resolution?
Well, desires do have a weight. You notice that whenever you act, you have conflicting
desires, but you have the capacity to consider some of them being more important than others,
some of them are stronger than others, some are weaker. And that is true on an interpersonal
scale as well. One person has a strong desire for something, another person has a weaker
desire. But I do need to warn against one of the things that desirism doesn't do, is
it doesn't say that you weigh all of the desires and you do whichever fulfills the most and
strongest desires as a moral principle. It evaluates desires according to their capacity
to fulfill other desires, so it seeks a type of harmony amongst desires, it seeks desires
that don't conflict. I can see that. I guess, but when they do, I guess, what am I trying
to say? I come from a utilitarian disposition, so I'm trying to think of a way to not think
about it in the terms of maximization. I'm still curious. So the utilitarian has a pretty
solid stance on eating animal products or something. They'll say, well, the pleasure
you get out of eating whatever hamburger doesn't outweigh the pain that went to making it,
etc. Certain conditions haven't been met or something. Do you, I guess, does desirism
amode, I guess, for how to answer those elements?
Well, desirism would look at what's true about that particular situation, or these types
of situations. Yes, animals have desires. Unfortunately, they can't mold our desires
because they don't understand the concepts of praise and condemnation, so they can't
get us to dislike the things that would hurt them. But humans do have a reason to make
sure that other humans are kind and unwilling to inflict pain on other creatures. If you're
willing to inflict pain on other creatures, you may be willing to inflict pain on other
humans. And also, humans have the capacity to care for animals, and if I care for an
animal, I have a reason to cause other people not to harm that animal. So, we do have reasons
to mold the desires of other humans in order to protect and care for animals.
For sure. I think I'm still trying to keep my head around the goodness in the satisfaction
of a desire. Is that one of the main things that's going on here? I'm still trying to
understand. Yeah, that's actually the biggest problem with desirism, the biggest problem
that people have, is the idea that they want to interpret it as desire satisfaction, having
some type of intrinsic value. What matters is that a desire is satisfied. And that's
not the way the theory works. If I have one of the examples that I use is I just imagine
a planet where there's one being on the planet. I tend to call him Elf, and he has one desire
which is a desire to gather stones. So, him gathering stones doesn't have any type of
intrinsic value. Nothing in that planet in that world has intrinsic value. However, gathering
stones is an action that has value to Elf because Elf has a desire to gather stones.
So, a utilitarian would look at this from the point of an observer looking down and
say that because Elf's desire is satisfied that that has some type of intrinsic goodness.
Desirism says if you're looking down from the outside, nothing has value unless the
person looking down also has a desire. And it's only that desire that anything that he
sees has any value. So, if I'm looking, if the impartial observer is looking down, sees
Elf gathering stones, knows that Elf has a desire to gather stones, he's completely
indifferent to that fact unless he has an interest in desires being fulfilled.
Got you. Yes, I think I understand.
Okay, so, nothing has value unless you can relate it to a desire. It only has value
to the person with that desire, and so far as it fulfills that desire.
Yeah, I think that sounds pretty clear and it sounds appealing. I like the overall idea.
I do wonder, I mean, so yeah, if I have true desires that are conflicting, say my desire
he chocolate cake, I'm also a fan, and my desire to stay physically fit, those desires
can't both be fulfilled at that same time, but I obviously feel more strongly for one
than the other. But I guess, how would I imply that on a larger scale? If there are two people
that desire two different things? Yeah, I mean, or they both desire the same thing,
right? And they didn't care about each other, I guess, whichever one gets it.
If you're talking about a simple situation like that, you have two people, or two beings
that both desire the same thing, then effectively, as a matter of descriptive fact, they're going
to fight about it. They don't have any other option available to them unless you introduce
some other desire to resolve it. But desirism is actually interested in molding desires
or choosing desires. So let me modify my previous example a little bit. I had Alf on a planet
with a desire to gather stones, that's what he wanted. Now, let's introduce a second
person to that planet, a person that I tend to call Bet, and we'll give Alf the ability
to choose Bet's desire. And Alf could give Bet one of two desires, either a desire to
gather stones like him, or a desire to scatter stones. Now, looking at this from Alf's point
of view with his desire to gather stones, and let's make the further assumption that
there's a limited number of stones, so what Alf does is he gathers stones for a while,
then he's got them all in one big pile and he has to scatter them again. By giving Bet
a desire to scatter stones, he can spend all of his time gathering stones. So he has a
reason to give Bet a desire to scatter stones, that's the option, that's the rational choice
for him. So the desire to scatter stones for Bet is the better desire, and that's the
desire that he gives that new person.
Sounds like a great position for Alf.
Yeah, but it also turns out to be a good position for Bet, because Bet gets this desire to scatter
stones, and there's already somebody in the world that's gathering stones for Bet, and
so Bet ends up just being in a good position as well. And these are the types of situations
that desirism looks for.
So what we would want to do in Steve's example is to make someone who has the desire to bake
chocolate cakes, but not eat them?
That would help. Or if they like to bake chocolate cakes, just bake enough chocolate cake for
two people. Let's generalize that, or let's look at something in a larger community.
Let's look at the type of situations that we have. We have reasons to have other people
tell us the truth, because we need true information in order to fulfill our desires. If they lie
to us or they give us false information and we use that information and we're not going
to get the things that we're aiming for.
So we have reason to cause other people to tell us the truth, and the tool that we have
for doing that are condemnation and punishment when they lie, and praise and reward when
they tell the truth.
So we're trying to create desires that actively help people cooperate and get along and fulfill
their other desires, and that's the way we do it, and that's what conventional morality
really consists in, is using these tools of reward and punishment and praise and condemnation
to get people to like and dislike certain things that are more useful for us to have
them like and dislike.
I think one of the things I like about Desirism is that it starts out as being a descriptive
theory first, that with any theory you first have to describe what you are working with
before you can make recommendations in it. Like if someone wants to know how to get to
the moon, you first have to describe how gravity works and how chemicals interact in order
to produce force and what that will do with the materials you're working with, and then
once you have the framework where you can describe everything that happens, you can
make recommendations off that given what we know about physics, this is what you would
do in order to get to them.
Right. Everything in Desirism is what's called a hypothetical imperative. There are no categorical
imperatives in it, which means everything is built on wants. If you want X, what do
you have to do to get X?
And in the moral case, for just about everything that I want, I need other people to be honest
with me. So given that, and the same is true with you and with everybody else, you have
reasons to want others to be honest with you, and then the use of these tools of reward
and punishment is simply the way of causing them to have this aversion to lying, which
is beneficial to you, and they're causing you to have an aversion to lying, which is
beneficial to them, but everything's built on hypothetical imperatives.
So really, what I consider neat aspect of this is that you aren't really working with
acts, so you aren't trying to encourage people to always do the act of telling the truth,
what you're trying to do is give them the desire of wanting to tell the truth, so that
it's self enforcing. You don't have to worry about someone lying to you if you know they
have a deep desire to want to tell the truth all the time anyway, which is why the evaluations
are of desires rather than acts, because then they give the motivation with them.
Well, right. That's one of the differences between this and the type of deterrence.
If you think about deterrence, if deterrence says you're going to cause somebody not to,
for example, take your property, you're going to punish them, and the punish them as a cost
that they have a reason to avoid. Now, that works to a certain extent up to the point
where they can take your property without getting caught, in which case you have no deterrence
value. But what if you can get them to not want to take your property? One of the things
about people, if they don't want to do something, then they don't need somebody looking over
their shoulder to catch them if they should do it. They simply don't want to do it. So
if you can create an aversion in people to taking property such that I wouldn't take
that for a million dollars, I just don't want to take things from other people, take things
that aren't mine, then your property is safe even when you have no deterrence, even when
there's nobody watching over their shoulder. I guess the people steal because they want
your stuff. This is sort of raising the question for me of how you let me lay out the problem
that I'm thinking and the solution that I'm halfway developed to do. So the problem, I
guess, would be how to decide which desires to try and foster other people or how to weigh
desires against each other to say this is the one that you should have, you shouldn't have
this one as much. And I guess one way of solving the problem would be saying, okay, look, if
you want this, it's going to hurt you in all these other ways. It's going to inhibit your
future ability to satisfy your desires, or it's going to conflict all these number of
desires. So really just want the ones that are the most consistent with each other and
with everyone else. Maybe not with yet. Maybe not with everyone else.
Yeah, how do you decide which desires should be increased and which should be decreased?
Well, you simply look at the ones that tend to fulfill other desires. You go for honesty
because everybody needs to have true beliefs in order to fulfill their desires. You go for,
you don't want them taking your property without your consent, because then you wouldn't be
able to plan and do you know good to work on something because your property would be
disappearing. You definitely have a reason to cause other people to have an aversion to
causing you pain simply because you don't like pain. So what you do is you look at the
things that you want and you look at how different desires will make it either easier
or harder for you to get what you want. And those are the desires you have reason to promote
in others. And they're the same desires that they have reason to promote in you. And it
comes up to your fairly basic set of moral principles. You know, don't lie, don't break
promises, be kind to others, help them when they're in need. Don't take things without consent,
that type of stuff. What about in situations like colonial America where there's 100 white people
who want free labor and one black person who doesn't want to be enslaved? How do why do his
desires outweigh the desires of the 100 white people?
There you're getting into the idea that what's right as well but fulfills the most desires. But
that's not the case. Remember, we're evaluating desires. Now, who has, does anybody have any good
reason? I mean, everybody has a good reason to cause other people to have an aversion to slavery.
Because if people don't have an aversion to slavery, then you're at risk of being the slave. So the
desire for slavery itself is a bad desire when one that everybody has reason to condemn as it
turns out. Well, it's only a scary desire insofar as you have any realistic risk of becoming a slave.
Yeah, what if you instill the desire not to instill, not to enslave people with the same skin
color as you in a place where you are a majority, then you could get the benefits of free labor
without having to worry about being enslaved yourself. Well, if you could...
I'm not trying, we're not trying to stump you and be like, ah, gotcha. I'm really just trying to,
like the way that I assess different world theories is I try to see how they tackle real
world problems, right? So this isn't, if it sounds like we're just trying to drill you into a part.
Oh, no.
This is what we're trying to do.
No, this is a standard problem. And if you go to my blog, I actually have a blog post called
The 1000 Satists Objection, which is what this is. What if a thousand people wished to torture
one person, then would desirism say that that's a good desire? And so, you know, it is a common
problem. But when you're talking about the moral desires, you're talking about desires that are
to be universal across everybody. And the way to look at it, like the The 1000 Satists
example, is do you have any reason to be surrounded by sadists? Do you have any reason to be surrounded
by people who are willing to enslave others? Now, you can say, what about, we're going to give
everybody a desire to enslave only this particular people with a particular color skin. How are you
going to do that? And once they have, if they have no aversion to slavery, if they're sitting there
thinking, okay, I can go ahead and enslave this person, identify, enslave more people, I get more
labor. Now, you're going to create a situation where they're going to try to enslave more people,
and that puts you and your descendants at risk. There's also an issue in that it's difficult to
make specific desires. Desires aren't like rules. You can make rules that are really complex. They
have lots of exceptions. But when you're using praise and condemnation to molded desires,
you're not going to be able to mold desires that are incredibly complex. Like you can give somebody
an aversion to slavery. But how do you give them an aversion to slavery of people of a particular
color skin? I think, as humans, we do very naturally break down people into in groups and
out groups, though. And it's very easy to have distinctions between the in groups and out groups,
so that it can be even someone like people who can't pronounce a word a certain way are now the
out group. And all the moral rules that apply to the in group do not apply to the out group.
I think one of the major advances that we've made over the past few centuries is the expanding of
the in group to include more and more people. Until now, it seems that, at least in the Western
world, to include all human beings. But I don't think it's necessarily that difficult to decrease
the size of the in group, if you wanted to, so that people will feel discussed in aversion
towards people of certain ethnicities or religions. And they don't have trouble making separate moral
rules within and the out group. It is incredibly easy. In fact, there's been experiments,
what they've done is they've taken random people and invited them into a room and simply given them
two different colored tags, tags and green tags. And after just a couple of hours of mixing with
each other, it's them about their level of trust that they would say that people of the same color
tag are more honest. They would trust somebody of the same color tag to watch over their children.
And this is just, these are strangers. And the only difference is the tag color. And so, yes,
it is incredibly easy. But in virtue of the fact that it's incredibly easy, it also creates a great
deal of hardship. If it's hardships, it's the fact that the violence and the discrimination
that people have to endure, all of that is what gives us reason to work against these
common psychological dispositions and to get something that actually treats people according
to their actual worth, how useful they are. And to put these things aside, the very fact that
they're destructive is the reason to work against them. Okay, so you're arguing that having lots
of this separate in-group and out-groups like that will cause a lot of conflict between various
groups and that a society that eliminates this sort of intergroup conflict will be stronger
and dominate ones that are very fractious? Well, that's true. I'm a bit uncomfortable with the
dominate ones that are fractious because I don't know what you're meaning by dominate there.
But yes, we do have reason to get rid of this conflict and look at human history. Just about
every horrible thing that's happened in human history has happened because of this
tendency to form in-groups and out-groups, whether you're talking about the Thirty Years
War or the Holocaust or the Mongol invasions, and it's all caused by this disposition to
form in-groups and out-groups. And the fact of all that we have reason to avoid all of those
hardships are the reasons to fight against this disposition to form these in-groups and out-groups.
I want to change gears a little bit, but only predicated on the possibility. Have you read
the Harry Potter book series? Pardon? I'm sorry, have you read the Harry Potter book series?
I haven't read books, I know the movies. I can't remember if this was in the movies or not. In
the fourth book, and probably the movie, there was a house elf that was... I kind of bring the
problem of desirism to like creative and artificial minds, like using house elves as a go-to example.
Right. The house elves basically want to be servants, and so like if they want it,
you want a servant, it sounds like everybody wins. There was a part in the fourth book where
one house elf is trying... They also have a desire to self-harm if they aren't good servants,
and when at one point one was stopped from self-harming, and she was distressed about it,
and it's hard for me... I think I'm still trying to be together with desirism enough,
because to me, it makes sense, like, look, I'm going to stop you from hurting yourself,
I'm going to try and teach you why it's wrong to hurt yourself, but she was distressed about it.
The house elf wanted to hurt herself for being a bad house elf, and, you know, letting her do
that would have satisfied her desire to do it. I guess, are there good and bad desirers, especially,
I guess, trying to think of something as convoluted as created minds?
I only heard part of that, that you're cutting off. Could you repeat just the very end of it?
In Harry Potter, the house elves had a desire to self-harm if they weren't good servants,
and then at some point in the book, one of them is having that desire to self-harm
supported by one of the humans in the book, and she's distressed by not being able to self-harm,
but it seems to me that that's not a great desire to have, but she wants it,
and she really wants it for other house elves, presumably, so I guess,
is there a way to say that, no, this desire is bad?
Well, a desire is bad if it thwarts other desires. If it thwarts other desires,
then you have a reason to get rid of it. Now, you talk about the house elf wanting to harm
themselves, but what is the harm? The harm itself is necessarily thwarting another desire,
so he has a desire to thwart other desires, and that desire to thwart other desires is a desire
he has reason to be rid of, and that just is the same thing as calling it bad.
I think in the context of the book, I think they self-harmed as sort of like a program's way to
make sure they were even better servants. It's like they wanted to hurt themselves because
they wanted to be good servants, and if they needed to punish themselves to do it, that's what
they did, so they weren't really challenging their own desires, and if this is too far-fetched to
be worth considering, that's totally fine. It is necessarily countering their own desires,
because otherwise it wouldn't be harmed. Can you be harmed by something that you'd like?
Oh, I see. Yeah, I guess it hurt. They were punishing themselves, though.
Right, but in punishing themselves, they were creating a situation that they had an aversion to,
that they had a reason to avoid, otherwise it wouldn't be punishment.
Gotcha. Okay, that makes sense. Yeah, another good example might be a crazy religious fundamentalist
whipping themselves in repentance or something. They're only doing it because they feel bad,
and they want not to whip themselves, but they're doing it because they feel they have to.
Right, yeah. They have a reason to get rid of that desire, too. If it's any desire that thwarts
other desires is one that you have reason to get rid of, and the reason comes exactly from
those desires that are being thwarted by it. One of the things I really liked about
desirism is that it has a category of moral negligence, which some ethical theories don't,
whereas it is the fact that you can condemn people and punish them for not doing something
that a good person would want to do. Right, that was one of the objections that I first
heard of when I started talking about this theory. There was a philosopher in the 1900s by the name
of James Martino, who his theory was that the value of an action is determined by the value
of the desire from which it springs. What I call motives, he called springs of action.
And one of the objections brought against him by Henry Sidgwick was that this doesn't account for
negligence, because negligence doesn't come from a bad desire. The drunk driver who just wants to
get home doesn't have a bad desire, he just has a desire to get home. So how can you condemn that
under this type of theory? And the answer is that you can condemn people for having the absence of
a good desire. The negligent person, the drunk driver, isn't properly concerned with the well
being of other people that we have reason to cause people to have. So we have reason to condemn
the drunk driver and anybody else whose carelessness puts other people at risk. We have a reason to
demand that they take more concern to avoid harming other people. I think this is particularly
of relevance today, these days, because I consider a lot of these
not necessarily news sites, but places that put forward claims that are ridiculous and wrong,
and they simply don't care that they're wrong. And I think that they are harming society in
general for putting forward these claims as if they were true and not even caring to check if
they are correct or not. I condemn them as being morally negligent and on the scale of evil for
not caring that they should be telling the truth. Actually, I would put them as something
beyond negligent. They're being dishonest, so we have a reason to cause people to have a
version to lying, and apparently it hasn't worked with them because they are lying.
But in lying, they are making it... Well, the way that desirism views lying is lying
is a type of a parasitical action. Think about it as putting a... If I had a way of controlling
your actions so that instead of doing what you wanted, you did what fulfilled my desires,
if I had a remote control or something that I can put into your head, then I would be using you
for my own ends. And that's exactly what a lie does. What a lie does is it puts something in your
brain that will cause you to act in ways that for your desires, for your interest and fulfill mine
in its place. And we definitely have reason to condemn that type of action, but we have reason
to condemn lying, and that's what they're doing. I think it extends further that it extends through
the people who just don't care if what they're publishing is true or not. They're like, well,
this sounds good, and this supports my narrative, so I will spread it without bothering at all to
check if there's any truth behind what they're publishing. The people who honestly believe,
for example, now that it's not relevant anymore, that Obama was born in Kenya and would spread
that, they I think are at least somewhat morally culpable for not caring enough to check if that
was true. Right. That is something that I call epistemic negligence, and it is something that
we have reason to condemn because it spreads all sorts of false beliefs that do actual harms,
and we do have reason to give people an aversion to doing that. The invention of social media,
I think, has made that particular vice much more damaging than it has been in the past when the
only people you could talk to are your neighbors. But yeah, a lot of the things, there is an obligation
to check whatever it is you find on Facebook or what gets forward to you in an email before you
pass it on to 100 other people. It is negligence. I kind of feel like religion had a role in
encouraging epistemic negligence from the very beginning. Yeah, that is one of the charges I
think you can bring up. Well, not religion, it's say religion is an extremely broad term and
encompasses a great many things, but the idea of faith, the idea that you could accept certain
propositions and completely ignore any type of evidence for or against it, that's a problem. Now,
some religions don't put that much stock in faith, although many of them do. But faith itself is
something that I think can be condemned as an epistemic negligent way of approaching truth.
I agree. I'm not a huge fan of faith either. I like the idea that epistemic negligence seems to
talk a lot. We were talking once about, not on this podcast, but previously we talked about
a Clifford, William Clifford wrote that essay on what it was called. It was the parable of the
boat captain. Right. Yeah, and that the boat captain has a duty to not be epistemic negligent.
Another world example might be like 60s to faculty. Right. They might have suspected,
but they're not going to look into it. That might prove them wrong. They're going to say,
well, no, we're not going to look at this particular claim. Right. Or you could look at the energy
companies today with respect to global warming. I mean, I'm certain that some of those executives
are simply convinced themselves that greenhouse gas emissions can't harm the planet. But still,
they're producing a product, which it is going to cause a great deal of harm. It's going to kill
people. And so that gives them an obligation to look through this evidence objectively and determine
whether or not these claims are true. And if they can't be objective, then their next best option
is to find a panel who that can be objective and to ask them to render a decision for them.
I want to bring up one of the things that I think is possibly more controversial, but which
I really like and get behind. The idea that the only, there's this sense in our society
that there should be no such thing as a thought crime. And you brought up once that the only
sorts of crimes are thought crimes. That what makes something a crime is specifically the
thoughts that were going through someone's head as they were taking partaking the action,
which is how it is that all crimes reduced to just thought crimes. Do you elaborate on that at all?
Well, in the field of criminal law, one of the things that the prosecution has to prove
is what's called man's rare or guilty mind. You have to prove that the person
had a particular mindset at the time that they committed the crime. And to illustrate the issue,
the fact that every crime is in fact a crime, the question about what a person was thinking is,
how do you distinguish between murder and self-defense? I mean, in both cases, a person
aimed a gun at somebody, they pulled a trigger and shot and killed somebody. All of the facts
that distinguish self-defense from murder have to do with what is going on in the mind
of the person when he pulled the trigger. That's what you're punishing him for,
is what his mental states were when he pulled the trigger. Or take a person who at the airport
grabs a piece of luggage and walks off with it, and it happens to be your luggage,
but your suitcase looks the same as them. Did they commit an act of theft or was it an accident?
Again, the only distinction between an accident and theft is what was in the mind of the person
at the time they performed the actions. So every time we judge a crime, we judge something as being
wrong, we are necessarily judging what is going on in their head. That's just a fact of the matter
of when we make moral judgments. That makes sense. That's why we punish whatever accidental
manslaughter less than murder. If you're texting while driving and running somebody over, you
probably won't be charged with life in prison because you didn't try to murder somebody. You
might say that's the best example. No, that's a good example. You were negligent and you should
be punished for that, but that's different from planning someone's murder. The lack of concern
for the well-being of others that is evidence in texting or drunk driving,
that's something we have less reason to punish as severely as the person who actually
wants to kill another person. That's something we definitely need to get rid of,
so that's something we need to come down harshly on is the actual desire to kill,
or even killing knowingly. That is, the only way you can get to your end is to kill a person,
so you do have to get to an end. Those are much more severe. There are things that we have more
reason to condemn than negligence, although we do have reason to condemn negligence.
We are at about an hour since we first called you. We did have a few minutes there that we
lost connection, though. Was there anything that you wanted to speak about in terms of
desirism and what you would like people to know about it? Any good questions we didn't ask?
Actually, yes, some pretty good questions. I don't have anything in mind at the time. It
sounds like it seems to me like you covered a lot of the hard stuff. I remember back when I was
reading, Luke Mulhauser was reading too, and you guys started up a podcast and a joint project
until he went off to join the less wrong community. Have you touched with him at all?
A bit, not a lot.
Do you have any idea how his views have been modified? Aside from my parents who helped
instill my initial social conditioning and my most basic desires and aversions,
I think your writing was probably one of the biggest influences on my ethical thinking. Has he
been affected the same way? Do you know anything about his current things that are happening?
Last I talked to him, he continued to accept a desirism. One of the things, and this is actually
the thing that ended our podcast, is when you discuss moral philosophy, one of the things that
a lot of people seem to be interested in is you're expected to come up with the one right and true
definition of morality. If they think that you haven't done that, then they think that that's
a criticism of your view and a reason to reject it. Luke and I both came to the realization
that that is a ridiculous requirement for a theory because all words are invented. There is no one
right and true definition of any term. We can change the definitions of terms at any time.
For example, the definition of Adam. Adam once meant an indivisible particle, something that
can't be divided. But then chemists took these things that they thought were atoms and they
found out that they had parts, electrons and neutrons and protons. So they simply changed the
definition of the word. They did the same thing with planet. And the same thing is true of
morality. The correct theory of morality isn't the theory that comes up with the one right and
true definition. Luke took that and developed what he called a type of moral pluralism.
And he argued that people actually have different definitions for the term morality.
They mean different things by the word according to their background where they raised religious.
If they were, then they might have an idea that morality is that which obeys God's law.
They might have an idea that morality is something with intrinsic value. And the way to get away
from disputes about morality when we have that type of situation is simply to cast the word aside.
Don't talk about morality. Simply talk about the facts of the matter that you can agree on
and don't get bogged down in terms. I like the dodging of terms as well. Not even dodging,
just saying, look, it's going to be pointless if you're going to debate about what the word
morality means. We're going to debate about what we should do in this circumstance. Or we're going
to be able to solve this problem. And you save a lot of time by skipping that first conversation
if you can't get any headway. Even just using a different phrasing. I tend to use the phrase
make the world a better place. I'm talking about the right action. But then you've got to define
better place. Yeah, but more or less, it means you've got no people's intuitions as it means.
Well, a desire is, I would say, a world that is a better place is one where there are more
harmonious desires. Oh, yeah, for sure. But I guess, yeah, so then rather than get bogged down
on, well, why would you define morality that way? Then you can kind of smooth past that and say,
well, this is what I'm talking about. Are we on board? All right, now let's go.
What I've learned from Luke with respect to that is I can write and discuss
desirism without ever mentioning the morality. Just talking about the relationships between
states of affairs and desires. And desires provide the motivational force to realize a
state of affairs. And so I can skip all of that. And if somebody starts bringing up definitions of
morality, I simply say, tell me whatever definition of morality you want to use. And I'll tell you
what desirism says is true with respect to that definition. And we can go from there.
But one of the worst things to do is to get into what is a false idea that there is one
true and correct definition of a term. Because there isn't. It's just a matter of convention.
I remember some people complaining when they first come to realize that
a desire is judged based on how many other desires it tends to fulfill or thwart. Complaining that,
well, then it's just all desires all the way down. It's just desires that fulfill desires
that fulfill desires. And where do you base anything aside from a big web of desires?
In the answer, don't. Right. Yeah. I think that's right. It's got to be proximate.
Right. You go with a big web of desires. But the same view exists with respect to beliefs.
How do you justify a belief? One view is foundationalism, that you take a belief and
you justify it by another belief until you get to these self-evident foundational beliefs.
But try to identify what those are and you have all sorts of difficulties.
The alternative view with respect to belief is called coherentism. Each belief is justified
according to the number and the strength of its connections to other beliefs. So you look at it,
you justify a belief by justifying it by looking at its connections to other beliefs and then you
look at those connections. And the job is to create a big, complex web of beliefs that all
fit together. And desirism says you do about the same thing with desires. Your goal is to create
this big web of mutually supporting desires. I like that desirism has stated, at least last I
read, it's been actually a couple of years or so, maybe a bit longer, that there is no point in trying
to change desires that are not malleable, that you should not try to punish and condemn or praise
an award. For example, don't punish a gay person for being attracted to people of the same gender
because that is a fixed desire and it cannot be changed by punishment. All you're doing is making
their lives worse by punishing them for that desire that can't change. I was wondering, first
of all, if you still believe that, but also how do you view the coming future if we are to create,
if we have the ability to change those desires that used to be fixed desires to really make it so
that you can change what you're attracted to or some core things like how people feel in relationship
to pain or their relatives or basically anything could potentially be at some point,
what do we do once we get to the point where any desire can be changed by a few hours with a really
good surgeon? You've got at least three different questions there. One is, yes, it's still the case
that praise and condemnation, reward and punishment are tools to be used and to use a tool on something
where it doesn't work is simply irrationally. You have no reason to do that. Using a hammer
to pound in screws is a waste of time. You can't have bad desires which can't be
affected by praise and condemnation, but then you go through to some other method if necessary.
You confine them so that they can't hurt other people or try some other ways of altering those
bad desires, but praise and condemnation are only used on desires that can be molded by praise
and condemnation, only where it's useful. Now some desires are moved out of morality
and into the realm of medicine, but then you're right, then the question comes,
are medical ability to understand the mind is improving and we may have the ability to
alter desires? That's actually one of the questions I asked with respect to homosexuality.
One of the arguments that a lot of people gave is homosexuality isn't a choice,
therefore it should not be condemned, but that's really not the way you want to go because what
happens when they come up with a pill and it is a choice. The real question to be asking isn't
whether homosexuality is a choice, but does homosexuality, is it something that causes harm
to others? Is it something that affects others in some negative way? The answer to that question
is no, and that's the reason why it's legitimate, why there's no reason to condemn it, not because
it isn't a choice. I think that's a solid way of coming about that problem, because otherwise
other things, I guess that's a good example personally that currently isn't a choice,
but then it could be. Then that brings the question, well, how would you wait your desire
to make everyone straight versus their desire to not be modified?
I think the more interesting question is, I mean, there's asexuals out there who are perfectly
happy with their lives and they don't have all this possible sexual frustration and all the
other complications that come with having relationships. There's a lot of great things
that happen with relationships too, but would it potentially be desirable to modify all humanity
so that no one has romantic desires at all anymore if we come to the conclusion that they are more
costly emotionally and economically and what other ways you can think of than to have those?
I don't see any reason to force it on people against their will. Once you start forcing
things on people against their will, you're automatically talking about thwarting a desire,
otherwise you wouldn't need to force it on them, but it is something that I think people
may want to choose in the future. Now, with respect to the desire that there be no homosexuals,
which is in conflict with homosexuality, the question to ask with respect, remember that
what we're evaluating here are desires. We're not evaluating actions. We're not looking for the
action that fulfills the most desires. We're looking at the desire, for example, that there be no
homosexuals. Now, the question is, why have that desire? What good does that desire do?
I've never heard a good reason for that desire. That's right. Religious ones. In a society where
the population is dangerously low, there might be a good reason. It wouldn't even necessarily be an
argument in favor of heterosexuality. That's been an argument in favor of just buckle down and
reproduce. That goes back to your question about conflicting desires earlier. What happens if
desires conflict? What a desirism would look at is, which of those desires can be modified?
Can they be modified easily? What are the reasons for the desire? You're not looking
to evaluate an action according to whether the action fulfills the most desires.
You're looking at the desires themselves and you're looking at what are the reasons to keep
and to promote that desire across the whole population, as opposed to get rid of that desire.
Or in some cases, there are desires that you want some people to have, but not everybody.
That's the realm of morality that we call non-obligatory permissions.
Like desires to be an architect?
Yeah. Desires for your profession. You don't want everybody to be a teacher. You don't want
everybody to be an architect. You need some teachers and some architects. Desirism says
that's one of those areas where there's no moral requirement. There's no moral prohibition.
It's a non-obligatory permission. You can choose one or the other, depending on whatever other
interests you have. I think I am out of questions. I think that's why I'm full of
eagerness to read through your blog. We just heard about, you know, I was reaching out to you,
had to get a chance to go through it too much, but I'm very eager to. Like you, I started my
interest in moral philosophy and philosophy in general when I was a teenager. And it's always
been interesting for me. I love reading about really most things, but ethics especially,
because there's a definite immediate connection to real life. Whereas, you know, considering
something esoteric and boring, or I guess, just something esoteric is more just like for fun,
but asking what is the good life? How would I live? Those are the questions that you really
ought to have at least answer to before you go out and do stuff. So yeah, that's really interesting.
I can't wait to get more into it. What's a good place to or a good way to learn about
desirism if someone doesn't want to wade through years of back blog posts?
Well, I did start a Wiki site on desirism, so that exists out there. But other than that,
at the moment, the blog site is the best option, I'm afraid.
I remember when I first started reading your blog, it was within a couple months of when you
first started blogging. I actually went back to the beginning and was able to read all of it. So
for a while there, I had read literally everything you'd published.
If I remember correctly, you were inspired to start the blog based on the results of Hurricane
Katrina. Is that right? Yeah, that's when I started it. There were some arguments going,
or some claims being made with respect to Hurricane Katrina.
Can you refresh me on those? What was it that sparked you to start the blog?
Actually, at this point, I have to say I don't remember. I do remember that it had to do with
Katrina and that I was frustrated with certain arguments that were being uttered, but I don't
remember the arguments at the time, the arguments that actually inspired that.
Excellent. I'll get to go dig them up. I know they're near the top or near the bottom.
And now it's led to all this. That's right. Well, I think it's here.
Yeah. Thank you very much for coming on and speaking with us. It was a pleasure.
And if you want to send us any links of anything that you'd like us to link to on the post once
this goes live, please do so. You have my contacts and once it goes online, I will send you a link
as well if you'd like to hear it. Okay. Sure. Thank you.
Well, thanks again. I really enjoyed this conversation. And I just learned
about this conversation here at Denver Local. If you want to get bored and you want to get a drink,
let's do it. Sure. Yeah. I live up in Lafayette and I work in downtown Denver and Loto.
Awesome. We'll be in touch. Oh, what a real quick question before we go. This is a thing that I've
been kind of curious about. How do you feel about use of intoxicants, like alcohol?
Other than the fact I don't do it. Yeah. Generally, I think it's a weak, bad idea.
Prohibition obviously doesn't work. So that's not something that I would support because it
creates a great deal of criminal activity for no good reason.
I don't like the idea of a person impairing their judgment because when people impair their
judgment, they put themselves and others at risk of making bad decisions. That being said,
there are also studies that suggest that there are certain health risks. It turns out that people
who don't drink are as likely to die early as people who drink excessively. And it's only the
moderate drinkers who extend their lives in that way. The people who don't drink are so depressed
that they don't drink. They end up killing themselves. Actually, the hypothesis is that
alcohol provides a social lubricant and the people who don't drink tend not to have the
strong social connections, which are essential effectively in protecting their own life,
having the friends and the support structure that they need to handle the life's issues.
Why do you personally not drink? I don't like the taste.
I'd like to clarify my invitation to get together for a drink. It can be a drink of any liquid.
Yeah, yeah. Any non-lethal liquid, yes.
Well, we're happy to. Yeah, well, hey, that sounds great. And once again, thanks for talking
with us. I really look forward to reading through more of the atheist ethicists.
My pleasure. All right, have a good evening. You too. Thanks, bye.
You
