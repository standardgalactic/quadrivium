Hey everyone, it's Tristan, and this is a bonus episode of Your Undivided
Attention, the podcast from the Center for Humane Technology. As you may have
heard, last week the Wall Street Journal released the Facebook Files, a huge
investigation of the extent to which Facebook's problems are known inside
the company, all the way up to Mark Zuckerberg. To respond to the story, I was
invited by pollster Frank Luntz to talk about this on his weekly webinar,
together with my friend Daniel Schmockenberger. Daniel is a founding member
of the Consilience Project, which is aimed at improving public sense-making
and dialogue. And you may remember him from Your Undivided Attention episode 36.
A problem well stated is a problem half solved. Frank Luntz is a political and
communications consultant, pollster, and pundit who deeply understands the hopes
and fears of Americans. So without further ado, here's my conversation hosted by
Frank Luntz with Daniel Schmockenberger about the Wall Street Journal's
Facebook Files.
As people get brought into the Zoom, I don't know if I've ever done a Fridays
with Frank that was more appropriate and more timely because of all that has
happened in the last seven days. Tristan Harris, congratulations on winning two
Emmy Awards. You're the first personal friend I have. That is actually a
multiple Emmy Award winner. Good for you. You should feel very proud. And you're
already getting a comment from one of the people who is listening in. And Daniel,
what you are trying to achieve with a more constructive, a more open, a more
useful dialogue and the teaching of civility and decency and how we
communicate in the public square is something that we should all emulate. I
am a proponent of technology. I am a supporter of it. We're going to hear a
lot of criticism today because of the problems. I do want to open up saying
that I believe in it, believe in what it has done for us. And in fact, I'm going
to do something I've never done, one of these Fridays with Frank, which is I'm
actually going to show some data that we've not shown publicly until now.
We've been looking at technology. Now people react to it. This is important. We
asked the question in the opposite way that most people do. How would your life
be different if you didn't have all that technology, the stuff that we use every
day, Google, Amazon, YouTube? And the public action by almost two to one say
that the quality of your life would be better without that technology. However,
they wanted to know whether technology has made their life easier or more
difficult. And overwhelmingly, they say that technology has made it much easier
to keep in touch with people as well as issues that are important to you. Another
example, it's given people more choices. It's actually made their lives easier to
consume because you get more services and more products. And again, numbers are
overwhelming. In terms of making shopping hassle free, 63% easier, only 6%
harder. We got more for these. Saving money in the things you buy, overwhelmingly
easier. One more. Has it made it easier or harder to get involved in politics by
47 to 10? They say it's made it easier. Again, I go back to that very first
statistic I showed you. Not easier, but better. The public has an issue with
that. So let me go to you, Tristan. And again, congratulations on your success.
We've talked about this. You and I've known each other for a year and a half.
Our meeting, our was a chance encounter by a friend of mine who said, I must sit
down with you. And I admit that I was going to not show up. I was going to
cancel the meeting. And probably in the year 2020, you're the single most
important person I met. You look at that data. You know how much people need and
want and value technology. But you also know the consequences. What have you
learned in the last seven days? The Wall Street Journal has been pummeling
Facebook and really shining a bright light on social media. What have you
learned over the last week that would be helpful for all the people who are on
this Zoom? Thank you, Frank. And yeah, really pleasure to be here with both
you and Daniel. So for those who don't know, over the last seven days, last
five days, I think the Wall Street Journal has released a new series called
the Facebook Files. This looks like it's the largest event. I would say they
call this the largest event since Cambridge Analytica in terms of revealing
research that the company has been aware of harms across the balance sheets of
teenage mental health increases in teen suicide, body image issues for teenagers,
the radicalization of political parties. There's evidence of the way that Facebook
changed its ranking systems that then caused political parties to actually
tell Facebook, we know that you changed your algorithm and we switched it to we
know because we have to publish now 80% negative content about our opponents to
even get any attention the way that we used to. We know that publishers had to
learn to publish more negative content to get any attention. I just really
recommend that people check out the Facebook Files because it's really the
first time that there's evidence of so many of the things, Frank, that you and
I, because we've done one or two of these before, have been saying for a long
time and that what we said in the social limit, yeah, for those who don't know the
social limit, just also won a couple Emmy Awards came out a year ago, we're
coming up on the one year, we just passed the one year anniversary. And really what
the social dilemma is about, to answer your question, Frank, is it's not about
technology, it's about these certain kind of incentive systems that are built into
technology. So if you take a look at Facebook, TikTok, Snapchat, YouTube, what
do they have in common? They seem like they're different products, like one is a
video broadcasting site, that's YouTube, the other is a social networking tweet
site, Twitter. So they seem like different categories, but their business
models are all optimizing for the same thing, which is whatever gets people's
attention. And so I think that is the generator function of all the harms
because in the same way that a values blind economy that's counting GDP, war is
good for GDP, prostitution and drugs are good for GDP, human trafficking is good
for GDP. In the same way, things that are good for attention that are not things
that we want, well, body image issues that had had kids basically, you know,
infinite looking at anorexia videos, that's really good for keeping time
spent up. Addiction is really good for keeping time spent up. Negativity and
outrage and things that go viral that are, as we said in the social dilemma, fake
news spread six times faster than true news, because the speaker who can say
anything that they want to unconstrained, meaning they can lie is going to do
better than a person who has to wait and say, well, what's actually true, but
the unconstrained actor is going to win. So for your slides, Frank, the thing
here is not that it's about technology being good or bad. It's about the kind
of technology and incentives that we bind to the technology and the business
model of maximizing engagement. Well, we found out in the Wall Street Journal
articles, and I could run through some of the things that we found. But
basically, Facebook knew, for example, that they were increasing some of the
negativity in society. And they had research showing that they knew that.
But Zuckerberg didn't want to change the ranking algorithms of Facebook if it
was going to hurt engagement. And now you could say he's just greedy or he
just wants the profits or he just needs to keep his share price up. He also is
bound because he set up a set of incentives. All of his employees, all
those people at Facebook, most of them are incentivized by how much they can
get engagement up. So all throughout the company, imagine you have a bonus
structure where everyone's salaries and paychecks come in through maximizing
engagement. But then you find out that, let's say 50% of that engagement is
causing genocides in Ethiopia, is causing body image issues in kids. You can't
say we need to have our engagement because now all your employees are going
to leave because they won't be able to get their benefits. You've actually gone
against the own incentive structure for your own employees.
So I want to know what it is causing. And I'm going to add a little bit of
pressure on you, which is that we have two members of the Judiciary Committee.
By the way, I'm in Belfast. I'm actually here in Conflict Capital of the Globe.
And that's why I'm so happy, Daniel, that you're involved. But I'm just
telling you, I've got one more for you. You've got two members of the Judiciary
Committee say that fast five times. They have to deal with this. What should
they know? If I gave you 30 seconds, what should they know that you know
about what's happening?
Well, I think Daniel, in a moment, I think we'll help elevate the conversation
to what kind of changes needed because, unfortunately, while I wish that there
was, you know, a couple of laws or bills that we could pass to get to some
better state, the challenge is that this is based, this is now baked into the
the infrastructure that we use is now the fabric of our democracy and
virality. The thing that is causing some of this, I think of this, everyone's
now familiar with the idea of a lab leak in Wuhan, the Wuhan Institute of
Viralogy that was doing potentially gain of function research on what viruses
can go viral. Well, people now know what are not is the idea of something that
can go viral and how many people does it infect? The purpose of Facebook is to
be the Zuckerberg Institute of Viralogy. The purpose is to create and allow for
things to go viral across the world and be spread to millions of people and to
literally take the R not to be as high as possible. We want it to infect as
many people and spread to as many people because that makes engagement go up.
And that's the core thing. So you say, what's the law that we can pass? What's
the issue that we can change? It's not going to be as simple as that. I think
we have to change the nature. We can't have it be the Zuckerberg Institute of
Viralogy. It has to turn into something safer. So I will warn you that there is a
Facebook executive that's on this conversation. So don't be surprised by
challenging Harry Clark, who is one of the best minds in communication, public
relations. He's asking as part of the Q and A one more. And this is one of both
Why not just boycott Facebook? Why is that a strategy you're considering?
And I don't want to, I don't want to sandbag you. Someone from Facebook is
going to hear this. Why not boycott Facebook? He wants to know.
Well, I mean, if people could boycott Facebook and there was meaningful
alternatives that were not the same problem in TikTok is basically has the
same problem. YouTube has many of the same problems. Snapchat has different, but
some of the same problems. So boycotting and then going, there's nowhere safe to
go. That's that's one of the issues. And the second issue is that you can't really
boycott it when your life depends on it. So one of the problems that's actually in
the article about teenage girls is that you can't actually say it's not an
individual choice to say, I don't want to use these things because I'm going to
ostracize myself. And if all my friends are still on it, you'd have to get the
entire world to boycott it together and move to something else because it's
fundamentally been baked into our lives. Small businesses have to use it to
advertise. How else are they going to reach their users and their and their
customers? They have owned the capacity to reach people. If we want this video to
reach as many people as possible, we probably want to post it on not some
random tiny video site. No one's going to click on, but you want to post it on
the one that gets as many views and likes, etc. So you're going to post it on
Facebook and you're going to post it on YouTube. So they have a monopoly on
reach, which makes it very hard for people to boycott it and say, let's go
somewhere else.
Daniel, you, even though you're involved in this issue, I look at you as being
essential to to public discourse, because you're looking at it, you're looking
for solutions. You're looking for results. You're one of the strongest thought
leaders in how we talk to each other now in society. I'll ask you the question I
asked Tristan, would you recommend a boycott knowing that there's a Facebook
person on this conversation? And do you have any solutions to the problems that
Tristan has raised?
I think it's kind of like what Tristan said that there's a monopoly, but not a
monopoly in terms of a government contract monopoly, but in terms of a
network dynamic monopoly. Network dynamics create natural monopolies where one, as
you get increasing returns on the more people that are in a network, then you
fundamentally have to engage with that thing because there's something like
exclusive value offered there. If somebody decides they're not going to sell on
Amazon and they have a small business, they just can't compete with the ones
that are doing that. Or similarly, if they're advertising on Facebook. So one
of the things is when we built the laws around monopoly and antitrust, network
dynamics didn't exist yet. Those were built before internet and those dynamics.
So we actually have to take the emergence of the internet and the emergence
of network dynamics and Metcalf law and say we actually have to rethink that
monopoly didn't just mean a crony capitalist government contracting. It
means
Can you, for those of us who only went to the University of Pennsylvania, can
you dumb it down just a little bit so we understand what you're talking about?
Nobody wants to use 20 different social networks and have to remember all the
logins and find some friends in one place and some friends in another place,
just like they don't want to use 20 different kinds of currencies. So if
there's a currency that everyone accepts, that currency kind of gets a
monopoly value. If there is a network that everybody's on and you can see your
friends from high school and your family and the news and all the things you're
interested in with one login, like those stats you showed, people said it was
easier and made their life worse. Like everyone who has conveniences where
they don't exercise and don't do the things that actually strengthen them
or read or study, there's a lot of things that make life easier and worse.
And so where something has a network dynamic where the more people that
engage with it, the more value it has because now everybody's producing
content, everyone I want to find is on there. The AI will curate all the
content to show me exactly what I want to see, but which part of me wants to
see? Well, the AI is going to optimize based on my behavior and how long I
spend on site and how many things I like and comment on and share. And it
happens that the things that appeal to my existing biases and increase my
sense of certainty in an uncertain world and the things that scare me and
kind of create emotional responses that make me less clear about the fact I
don't want to be on Facebook and go do other stuff with my life. And the
things that reinforce tribal identity maximize time on site and engagement.
So it's one of those things where you can manufacture demand from the supply
side and then say, we're just giving people what they want, but you're
appealing to the weakest, lowest angels of people's nature and then doing
so with radical asymmetries of power.
So Richard Dreyfus, who's always been a friend of these Fridays with
Frank and he's just his brain is incredible. Is there proof that social
media is leading to incivility, leading to anger? We may think it, but Daniel,
is there proof of this?
Well, this is what you were talking to Tristan about regarding what the Wall
Street Journal has been showing this week. And they're obviously previous cases
and it's this week and what will be continuing as more information comes out
is stuff that Tristan and Jaron Laney are have been saying would happen for
nine years because the business model guarantees it. Now there is increasing
proof in the form of hard internal documents and disclosure.
But for anyone who's been kind of paying attention, the business model of
maximizing people's time on site and maximizing engagement combined with the
technology of behavioral modification AIs was bound to be antithetical to
democracy and antithetical to health. So Tristan can give the proof, but for the
people who've been paying attention, it's kind of like saying, is there proof
that deforestation is happening? And as soon as you're looking at the financial
incentive to cut down the trees in an area where the trees alive are worth
less than the trees dead, you're kind of like, it's going to happen.
Right. And the same way that a tree is worth more dead than alive and a whale
is worth more dead than alive. In this case, our attention, it's easily more
sought with outrage. It will be, that will be the profitable model. Us being
happy or civil, talking to each other off screens and not on screen is not
profitable for any of the social media companies, specifically some of the data.
And again, I recommend people check. I think it's the third article that the
Wall Street Journal released. They talk about actually due to some of my own
work, Facebook changed its core metric. It used to be maximizing for time spent.
I was part of a movement called time well spent. That was my first TED talk.
Facebook decided actually Mark Zuckerberg wrote in his January 2018 post his
yearly goal, his new goal for the year was to take Facebook in the direction of
time well spent, not time spent. He took my words. Then he said, we're going to
change the way we measure success at Facebook. We're going to use something
called meaningful social interactions, MSI. And this Wall Street Journal
article, I recommend everybody reads it, showed how meaningful social
interactions they were trying to give, they assigned different points. So for
example, you've got one point, if you for a post would get one point if it had
a like, it got five points if it got a reaction or a reshare without any text.
It got 15 points for what they call a non-significant comment. And then it
got 30 points for significant comments and significant reshares. What that
really meant was the more long comment threads and article created, which is
to say more arguments, the more those things got boosted to the top. So
whenever there was an argument, it was like, Hey, let's put that at the front
and center for everyone's feet and then do that in a decentralized way for the
entire world all at once for 2 billion people. And when you basically highlight
divisiveness and disagreement and instability, which is the thing, frankly,
that you're trying to find one thing you and I were just at the milk and
conference. And there's a lot of people who are funding things like, Hey, how
do we do American one room? How do we fund with hundreds of millions of
dollars of depolarization for the country? And let's have people together
physically in rooms talking to each other. That's great. But how's that going
to compare to the four hours a day? People spend seeing in civility every
single day. And if 90% of people became civil, but only 10% are left that are
in civil, then what does Twitter and Facebook show you? Well, they only show
you that all the bad faith in civil people. So that keeps just completely
blasting over and plastering your whole feed. And so it continues to look like
the world is in civil, even if many people are starting to get better. We
cannot have that system with democracy period. Open societies cannot allow
this situation to be. And Daniel, I'd love for you to speak about that because
I think it's the reason why I wanted to have Daniel here, Frank, is I think
this isn't just about less toxic social media. How do we just reign in? Let's
take the reins and if we just move at five degrees this way, we would suddenly
have a better democracy plus Facebook. We have to look at a deeper problem
statement there to get to where we want to go. Okay, so I'm going to ask both
of you and you can go another order. Solve it. By the way, we've got a lot
of parents on this, and I'm going to ask you in a moment to scare the living
hell out of them. Give me your most frightening conclusion based on all
the research you've done on young people. But before I do, we're adults, do
either of you have an actual solution that you're going to be presenting to
Congress? Either of you. Daniel, do you want to try to describe? I can say
some things that would be directionally right. So we read all the documents
around the founding of this country and know that the idea of universal public
education and a adequate fourth estate were considered prerequisite
institutions for democracy to function. The people had to be educated and they
had to have access to the information to participate in governance. There's a very
deep question. Hold on one second. Those people who are watching because you're
actually, we're 25 minutes into this and I can see the number of participants is
actually rowing. I'm going to focus on kids in about five minutes. So if you
guys want to send out an email, want to send out a text to people saying tune in.
In about five minutes we're going to specifically focus on what social
media is doing to your children. So I suggest you stay on this. Daniel, please
continue. So you can actually see how the critical role of the fourth estate
following the printing press and it's been well analyzed the role that the
printing press had in the formation of democracy. We don't need a small educated
nobility who rules everybody because everyone can have access to textbooks
and newspaper. They can be educated and we can come to a town hall and participate
in our own governance. But this was based on the idea that we could get
something like fair and independent news and all read the same thing and then be
able to have an educated discussion about it. So when you have an internet where
there's radically more information than anyone could begin to parse, what
information you see ends up being determined by curation processes. I'm not
going to see all the videos. I'm not going to see all the news. I'm not going to
see all the posts. And so it's not like we respond as rational actors to the best
information. We respond to whatever YouTube's algorithms and Facebook's
algorithms put in front of me and they put it in front of me based on a business
model that's maximizing time on site based on engagement. And it happens to
be that that which appeals to my existing biases and emotions maximizes time on
site. So someone on the far right and the far left when they're looking at their
newsfeed and how they're coming to understand the world might see nothing
in common. And so, and yet it's representing the world to them. So you
have to say if democracy doesn't exist without a fourth of state and people
having a shared sense of what base reality is, and the internet, and
specifically, network curation based internet has destroyed the fourth
estate irrevocably. How do you remake a democracy post internet network age?
Because people can't do shared choice making if they don't have a basis for
shared sense making of what's going on.
Yes. And so that question, then how do you do it? It's the right question, but
I'm pushing you now. How do you do it?
Well, you can see that China decided, well, let's control our internet to not
have radically divisive ideas that end up making people against being good
citizens. And you can see that there's an effectiveness in that, but it's
antithetical to the idea of an open society. So you either keep an open
society with these type of network dynamics, and it just becomes
increasingly chaotic and fails. Or you try to apply the China model, those are
the only two things currently as the possibilities. And what we want is how
do you have something like open speech, but with this degree of radical
amplification possibility that doesn't become total chaos. And you have to
look at what is the incentive for the amplification. If there is a tool that
can curate it and make stuff radically more amplified, what is the incentive
guiding it? And so let's say, for instance, if Facebook is the most powerful
behavioral modification machine in the history of the world that can gather
micro targeted information on people and then specifically put information in
front of them to control their behavior for advertisers. But the people who it's
gathering information about and influencing are not the customer. But it's
gathering privileged information about people to then sell it to the customer
who is the advertiser. This should be a break of a fiduciary contract where
you're not allowed to gather privileged information about someone and then use
it against them. If the user was the customer, rather than the advertiser
being the customer. And as a result, the optimization algorithm was not to sell
people ads or to maximize time to sell them ads, but was to find the metrics
that actually correspond to people's real quality of life. And the AIs were
oriented to that, we might start to get somewhere. But that's the beginning of a
radically different business model. An ad based business model with AI controlled
behavioral mechanics will break democracies. They don't go together.
I trust down. I know you agree with this, but can you explain it to someone who
only went to pen? Daniel, half of Congress is not going to understand this. They
still call the tape recorder a machine or sorry, a microphone speaking the
speaking the machine. No, it's actually a microphone. They don't even know what
the internet is. Just on go ahead. Well, I think the thing that Daniel saying is
that an advertising supported. Imagine Frank, I put a brain plan in you and I
actually talked to the guys at Neuralink once about this, right? Imagine Neuralink,
Elon Musk's Neuralink project. I'm going to put a brain implant in your brain. It's
going to shape the thoughts. I'm going to give you thinking superpowers, but let's
imagine that brain implant in your brain. It's going to intimately shape every
thought that you have from the moment you wake up to the moment you go to bed and
your dreams, that someone attached the advertising business model to that Neuralink
brain implant. So now you start having thoughts that you didn't even intend to
have and it's actually in control. We would just say immediately when I say it
that way, it should be clear. Maybe we can have brain implants, but we certainly
would never allow brain implants with an advertising based business model. What
Daniel is saying is that we cannot have democracy and the primary brain implant
of that democracy be an advertising based business model. But when Daniel says
fiduciary, what he's referring to is a brain implant that would have your best
interest at heart, just like a doctor, theoretically, is supposed to have your
best interest at heart. And a psychotherapist, you're going to tell the
psychotherapist all this privilege, deep information that's deep in your psyche.
They have to have your best interest at heart. What we're saying is such a deep
change that we have to have technology that's humane with our best interests at
heart. Now, the reason that's such an uncomfortable conversation is that I
believe Facebook stock price has not moved that much this week, despite the
fact of these, these awful revelations. And it's worth about a trillion dollars
in that trillion dollar valuation comes from the advertising based business
model. So it's as if we had an entire industry of psychotherapy that was
based on a manipulative business model that was worth a trillion dollars. But
now we have to switch to what does it look like to be in the interests of
people. And the question is that's that's a very dramatic economic change. So I
think it's more that our brain wants to shy away from that because it's so
uncomfortable that we'd have to make a change as deep as that. That's one of
the big things that has to change.
I want you guys to know that one of the comments is maybe we need more people
like you in Congress, that it's not your fault that you're speaking the truth.
It's their fault for not understanding it. And actually, that's not such a bad
idea. Let me ask you, I wanted to speak to what you said earlier about what
people in Congress would understand. If because of who the people in government
are or the structure of government, if it cannot understand the nature of the
issues it's supposed to regulate, and particularly as technology is evolving
rapidly faster than the people who are in there are able to understand the
consequences of, then it will just break. Right. If the regulatory apparatus can't
understand the effects of what it needs to regulate, it will just break. And
this is the key thing that we're talking about is we're right now talking about
the case of social media tech following a business model. But we could also be
talking about CRISPR and tabletop CRISPR emerging, where we're getting very,
very close to cheap ability to make bio weapons for everybody. And with regard
to AI and generative text AI, we're getting very, very close to the ability
to make content in your voice, saying anything that anyone can do and flood
the internet with more information that passes the Turing test. And and so and
Elon said this, he said, if we wait to regulate AI and the other technologies
that operate this quickly AI specifically, who's talking about till after the
effects have been seen for as long as we did with cigarettes or DDT, it's way too
late. The effects will have been irreversible. So when we say exponential
tech, what we mean is exponentially faster to scale exponentially larger
effects that can happen from exponentially smaller groups of people. It
doesn't take state actors like it did to make nukes to make AI weapons, bio
weapons, CRISPR weapons. And so the big question becomes in the presence of the
speed and scale of emerging technologies, our processes of governance are just
inadequate. They're too slow. They are too divided. And this is why China has done
a good job of saying, no, we actually have to control these technologies,
otherwise they'll break the country. How do we do it? But it's in a particular
direction. If we want something like an open society in the presence of
exponential tech, how do we make a regulatory apparatus capable of
regulating what it needs to in time and ahead of time that is aligned with the
civil values of an open society? That's the central question of our time. I
believe I want a simple number, a number. Daniel, what percent of Congress house
in the Senate is really intellectually not ready to tackle this issue? What
percent? I don't know. I don't know them enough. What would you guess? I would
trust your guess over mine on this. Okay, Tristan, you've been testifying. So you
are not letting you out of this. What percent don't really shouldn't be
regulating this that they do not know? I think it's very understandable why
people are skeptical of Congress to regulate this effectively when they
hear senators ask Mark Zuckerberg questions like, how do you make money? And
he responds famously, Senator, we sell ads. If I was Zuckerberg, I would have
paid for that moment to happen. And maybe I did because it generates the
impression forever in people's minds. It sticks, Frank, in your language, into
the minds of the public that government cannot regulate this, right? So I've
created the outcome that I want. And someone I noticed in the chat was
talking about do social media companies own the numbers of Congress? Well,
let's say that this narrative gets really strong. Well, it's a trillion dollar
market cap corporation. It's not very hard to start buying off any of the
numbers of Congress that get critical. And a couple will make some public
statements. But what's really what we're trying to do here and what Daniel's
really saying is that this is existential for our society continuing to
work. This will break our society. We've been saying that for eight years. The
social lemma says that it's clearer than ever. January 6, I had text messages
from people, Joe Rogan saying, Oh, my God, I thought the social lemma, you know,
it's so eerie, all this stuff is coming true. You know, when I remember in the
film, people may remember the guy who invented Facebook's business model, Tim
Kendall, he was asked on camera, you know, what are you worried about is the
consequence of this. And he was, I think he was recorded saying this in 2019 or
2018. And he said civil war. And I remember that I think Netflix wanted that to
not be in the film because it sounded like it was too aggressive a statement to
make. It sounded like that wasn't where we were. That was before the pandemic.
And when people saw January 6 and they see the results and people should read
this Wall Street Journal article about the outrage economy and how it how it
drove up basically more insanity, it makes perfect sense. And the point Daniel's
trying to say is that we were trying to ask the question, if we don't want to
beat China by becoming China, then we have to develop an open society
alternative to exponential technology that does not result in catastrophe and
chaos. And we're spending some time in Washington DC. And part of the reason,
Frank, I wanted to do this with your audience, because I know you have a
lot of listeners that are in DC and that are curious to get to this point is
that, you know, we're trying to see who resonates with this and wants to have a
serious conversation about the more comprehensive change that's needed.
But I'm being asked again and again, both in people who are texting me,
emailing me in this comment right here, everybody says, we got to do something,
but I don't trust Washington to do it.
What's the answer? They don't, the direct language. I don't want Washington
making the decision for me or my children, what we're going to see.
Well,
I can speak to this as one of the things we've seen during COVID is the
breakdown of the sense of a shared, trustable authority or institution.
And when it comes to news media, and even when it comes to scientists and
public intellectuals weighing in on the science, there's just radical
polarization of what would be a trusted authority.
And so, yeah, people rightly don't trust Washington, but they would also
rightly not trust private companies that have interests that are exactly
opposite of their own and radical asymmetries of data manipulation capability.
So the question becomes, when you have technology that is this asymmetrically
powerful, who could you trust to govern it, given humanity's track record with
power? And yet, like whoever had the
cannons in the past is nothing like who has the AIs and all the world's
information, the behavioral dynamics on your children.
And so as we follow an exponential curve of power,
there's this core governance question of we've never done all that good a job of
being great stewards of power, and now we have radically
increasing exponential power. How do we govern it?
And the whole thing when we don't trust Washington is Washington was never
supposed to be a thing separate from of foreign by the people governance.
It was supposed to be that the state was given the ability to regulate
predatory market interests while still allowing healthy market interests
to ensure the values of the people that were encoded into law
could be implemented with a monopoly of violence.
But the state could only check the market if the people checked the state.
And that like everything you can read by the founding fathers
and the Declaration and the Constitution was all about the people's ability to
oversight and check the state and be engaged in governance.
When the people stop checking the government, the government gets captured
by the market and you get short-termism, crony capitalism, regulatory capture,
those types of things. So ultimately there is a cultural revolution
that has to happen of people who get committed to actually being able to
make sense of reality together and make effective choices together
and participate with the remaking of 21st century governance, 21st century
democracy, republic, open society, whatever you want to call it,
and the creation of institutions that actually can be trusted because of the
right types of checks and balances on power and oversight process
with this technology. Okay, I'm going to read it from Eric Schwartz.
Due to forceful regulation, banks are obligated to know their customers and
there's no room for anonymity. Why shouldn't social media be governed
the same way if there was no anonymity and the platforms were obliged to know
how to access all participants? Would that help?
Either of you. I'll just respond to something there. We've been saying
also for about five years, just like banking has, know your customer
laws and so on, KYC, there is eventually especially going to need to be
that with social media and online publishing because of
what Daniel was talking about with GPT-3. So for those who don't know
when you say GPT-3 or deepfakes, people have heard about this term, right? They
just quickly say what this was. Daniel and I were actually just with one of the
top AI research people in the entire world
and they were saying how much this field has progressed. You can basically say
write me a novel in the voice of James Joyce
about the topic of democracy or something like that
and it would write you a 100-page book. I could say, hey, write me a
article about why the COVID vaccine is dangerous and with
lots of charts and graphs and actually criticize with the names of
the logical fallacies that people are using that
that makes them wrong about the vaccine and why they actually shouldn't
trust it and it'll actually generate like a 100-page
research paper with charts and graphs that it'll take biostatitions like a
year to actually parse out what's right or what's wrong about that.
That capacity to instantly flood the internet with information and by the
way for those who don't believe me, do a google search for open AI
and I don't know what they call this video. They can actually do
programming so you can actually tell this GPT-3 AI.
Hey, write me a computer program, a game, where there's a moving asteroid. Whenever
I hit the letter, the left and right arrows, it goes back and forth,
make the asteroid bigger. I say all that and it writes the entire code of the
video game for me. I'm just saying a natural language
what I want. So in the next election, Frank, we're moving to a world and this
is not sci-fi so people might hear this as
alarmism or moral panic and people who believe that this is moral panic
like listen to the fact that we were saying these things eight years ago and
all of them have come true. We're about to hit a world
where in the next election, midterm elections, for those who don't remember
in 2016, there is this popping up of these fake local news websites, the Denver
Post, the Cincinnati Herald, I don't know the names of the
fake ones, you can basically make them up. GPT-3, you can also say spin up a
local news website with the fonts and everything and the big sections at the
top. It'll generate the entire website and it looks perfect, it looks totally
indistinguishable, then generate lots of articles about why the other side is
untrustworthy and he beat his dog and whatever and it'll actually just
generate thousands of these websites. We're getting so close to that being
possible and the reason I'm saying this is to
answer Eric Schwartz's question about why we need to know our customers, why we
need verified identity because if we don't have the sense that someone who
generated this comment or this post or this text is a human
being that's traceable to some kind of ID,
we're not going to have a working open society. So table stakes going into the
future is we're going to have to have some kind of zero knowledge proof
identity and people who are following this closely know that that's one of the
big changes that's going to need to make.
When we talk about Congress regulating these issues, we're often talking about
looking backwards in time at the at the historical issues. How do we deal with
these common threads on Facebook or like the stuff from like four years ago
issues? We're missing the fact that what Daniel's
saying is the first derivative of how technology is constantly changing
and generating new issues, second and third order effects,
faster than any of our governance processes keeping up. So what we really
need is a new kind of governance process. We need a Manhattan project
for governing exponential technologies that move faster and I would actually say
similar to the Einstein-Sillard letter that was written to FDR in 1939 that said
if we don't do this and open society values don't have nuclear bombs,
if Nazism gets the nuclear bomb or if Communism gets the nuclear bomb,
they will run the future because whoever wields the power of exponential technologies
will run the world and we're at another choice point today
where we have to have open societies consciously employ the technology and
bind to the predatory negative aspects. Otherwise we're seeing what China is
doing and they're moving much faster. Okay well I don't want us to become China
and there have been several comments about that that just because China is doing it
doesn't make it right. They don't value freedom, they don't value democracy,
they don't value the things that we insist on. Agreed and that's why that's
why what Daniel was saying is actually, go ahead Daniel, sorry.
Like to connect what Tristan is saying to the question that you asked about rigorous identity.
So obviously being able to know was this a human that produced it or was this an AI
would be pretty valuable. But even just is this the human that it seems like it is
or is this a fake account sock puppet that is part of a state actor propaganda farm?
That's pretty valuable because we've forensically find those types of
bought farms and fake actor farms all the time. And what they can do is use
Facebook split testing algorithm to see what is stickiest for certain populations and
continue to modify the content they produce even without AI to push vulnerable populations.
Now the AI just gets to take that exponentially. So obviously rigorous identity would be valuable
but then this question that comes back again it's like saying regulation be valuable.
Who do we trust to have the rigorous identity associated with all of someone's online
behaviors, including through changes in government that will never forget that
where now some despotic government comes in in the future or someone that I didn't vote for
or didn't like but now that is an unerasable memory. So we get to see on either sides here
we're like okay we actually want anonymity because we don't trust anybody. On the other side
the anonymity makes it to where there's no possibility for justice or knowing what is
true or not true. This is a hard issue and it corresponds to it's pretty hard as Tristan was
mentioning about the the war for the arms race for nukes. It's pretty hard to make nukes enriching
uranium is difficult the precision engineering that was needed for the rockets was hard. It's not hard
to make drone weapons anymore home based drones with homemade bombs on them. It's not hard to
take papers that are written about the cutting edge of AI and reverse engineering and make
crypto cyber weapons and AI type weapons. The thing about exponential tech is that
the idea of decentralizing tech we have this kind of romantic Silicon Valley idea of this
means democratized power for everyone but it also means catastrophe weapons for everyone
and when you have catastrophe weapons for everybody and it's non-state actors and there's
no way to even be able to visualize it you can't have mutually assured destruction you can't create
equilibrium. So then the the only other answer so far has been okay well either catastrophe
weapons for everyone if you want something like freedom or ubiquitous surveillance.
Ubiquitous surveillance is a good answer if we know what everyone's doing in their basement nobody
can do work on AI weapons. Those two answers are both so terrible we need a better answer.
So in the presence of decentralizing exponential power how do you not have ubiquitous surveillance
and not have centralized access to that personalized data and yet still have something
that can create anti fragility in the presence of that much power that even small actor groups
could engage with. There are some answers that are neither just allow the chaos to continue
or become oppressive but we'd say civilizations typically teeter between the civilization is
how do we get a lot of people to participate in some way that creates order we can get the
order through imposition and it becomes increasingly oppressive or we fail to get the order and it
becomes chaotic and it fails on either side. The idea of democracy is that we can have emergent
order rather than imposed because we can all make sense of the world together and make sense of
each other's values and have some basis for shared choice making. This is ultimately cultural.
I promise to focus on kids and I've actually got a young person who's watching this right now
I'm going to read her question. I'm a senior in high school inspired after watching the social
dilemma and spending a year researching practical ways for young people to limit the use of social
media. I'm curious to know your view in the following how do the tactics to curb social media use
differ by age youth groups specifically pre-teens, teens, and college? What advice,
what guidance would you give her as she seeks to understand the difference between those three age
groups? Can you say the age groups again? Pre-teen, teen, and college? Pre-teen, teen, and college.
Pre-teen, teen, and college. I mean I will say that I'm actually I don't consider myself an expert on
the developmental psychology of children at these different ages. What I can speak of is
so long as the business model of TikTok and Snapchat and Instagram is I have to race down
your brainstem and create artificial social obligation and artificial social reciprocity
that you feel the pressure of getting likes if the other guy doesn't and you don't get it.
That thing is just not compatible with children's development. It turns kids into validation seeking
machines and it creates social pressure and anxiety that's simply not it's frankly it's not good for
any of those populations right it's not good I don't feel good how you know none of us feel good
when we feel like you know frankly I'm sure you get this all the time so if you get a comment on
Twitter you post to Twitter a lot I follow you and you get 100 comments on a post that you make
and 99 of the comments are negative are positive and one of the comments is negative where does
your attention go? Of course of course but you've got 99 to 1 positive but our brain is not neutral
our brains focus where on the negative and do you think you're alone in this experience
or do you think that everyone feels that and do you think that children's feel it more than you
or less than you more than you so we what we have is essentially a system that creates
overwhelming pressure and negativity and and the conditions for just not psychological health.
Daniel has this nice line about how what would be how do you measure the health of a society
and it's a hard thing to measure the social health of the society but you could measure it as the
inverse of the amount of addiction in society and then I don't know if you want to riff on that but
I don't have an answer to your I would like to answer her question go for it because the thing
Tristan is saying relates to the question someone asked about boycotts earlier when you have a
trillion dollar organization with two billion people's behavioral data run by ai's and then you
have a person just the little person the asymmetry of that info war because the person wants to control
their own thoughts and behavior but Facebook wants to control their thoughts and behavior
but it is a many orders of magnitude asymmetric info war to control their thoughts and behavior
that's such a problem that you can't just say well let's leave it up to the individual person
it's like saying let's leave up to individual people turning their lights off as the solution
to climate change and environmental destruction it's like no that just really doesn't work this needs
solutions that are at the scale of where they're coming from and switching the burden of responsibility
from the joggernauts to the individual is just like a bad move both ethically and from effectiveness
so that's what Tristan's trying to get to but we have this person here who's asking a question
about what she can actually do so I want to speak to it and by the way this has been this has been
Jordan's focus now since you all created you got people agitated you got people focused
now you got to start to deliver for them what would you say to her
I'm not going to make a distinction between the three age groups I'm going to say what's true in
general and then the developmental application of it is something that you should totally work on
people are more susceptible to addictive things what we'd call a hypernormal stimuli stimuli that
gives more dopamine or hit faster whether it is sugar or drugs or social media type stimulation
or porn they're more susceptible to that when they're in a hypo normal environment meaning
they're less fulfilled than an evolutionary environment in an evolutionary environment
humans evolved to be part of a tribe where you were having a lot of rich social interactions a
lot of embodied movements a lot of time in nature you know those types of things so
the lonelier people are the more susceptible they're going to be to Facebook and Instagram
the less creatively fulfilled they are if you can find groups of friends groups of people and
create richer possibilities of offline engagement it's the thing that'll help them the most if
they can have a place where there's drum circles every Friday night and everybody's dancing and
having drum circles if there's musical things where they're getting together and having kind of
jazz fun stuff if there's craft places if there's places where they get to have circling to do
meaningful like sharing about what's going on for them if people feel a richer fullness and other
opportunities they will be less susceptible to that then you can actually start to have not
only are there more fulfilling other opportunities but there's actually social connectivity and status
associated with something else you've got seven minutes to go and there are more people on this
now than there were after 10 minutes I've never had that happen in any of these Jared Carney asks
the primary issue for me is not manipulation although it's a big issue it's surveillance
if Facebook's business model is predicated on conflict plus knowing everything and trying
to steer commerce how do you counteract that
I mean this is really the topic of Shoshana Zuboff's book Surveillance Capitalism that
when you control this much of people's lives and you can let's say someone builds an alternative
social platform funded by venture capitalists there's got some investors I'm sure on this call
many people might be wondering well what if we funded some alternative social network that because
we want to do it in a way that doesn't capture people's data well that will be funded by venture
capital venture capital expects you know big multiples of returns there's actually no way
to exit that except by getting acquired by one of the existing big surveillance capitalism
companies whether it's Google or Facebook etc you'd have to do it in some way where it's an
independent thing something more like a Wikipedia or a blockchain type project where the data is
kept separate somehow but you're not going to be able to transition these existing platforms
Daniel do you want to jump in you could you need something that is like the equivalent of HIPAA
so which is the medical privacy regulations so if I have a medical file so that I go into a
ICU somewhere they can pull up what I'm allergic to and those types of things it's very sensitive
information about me everything that's in my life medical file that information could be sold
to drug companies it could be sold to lots of places it would be interested in doing
stuff with it it's really really important that that isn't sold so there is state-based
governance of that data and how that data can be shared and not shared if and so when you're
saying manipulation is second to surveillance the purpose of surveillance is manipulation right
it's the gathering of the data is to use the data for a purpose and whether it's to affect how you
vote or to affect your market behavior or to affect how you affect the cultural zeitgeist
that will affect market behavior and voting of others or to be able to arrest you for things
that we decide later or seditious or whatever it was ultimately it's the control of behavior that
we're gathering the data for and so how do we create safety of the data and this is where the
question has been do we trust Facebook with it no do we trust Washington with it no do we want
there to be a place where there is data so that we know that it's a person and not a bot
putting the information out yes so do we need to create a better checks and balances and oversight
process to ensure the trustworthiness yes do technologies like blockchain do part of the
thing where you can do provenance on data and see how it moves and have things where the data only
becomes released if certain flags happen otherwise it's in a decentralized rather than the centralized
database there's partial solutions there and we could work on full solutions but like with the
hippo kind of thing it's that data there's a hippocratic oath that is saying that data is being
gathered by the doctor who has serving your interests not the pharmaceutical or anybody
else's interests in mind and we can see it's not perfect if Facebook's business model shifted
where the user was the customer and either that and or as a state say got made into being a state
utility so the interest of the state which would mean that people didn't take views in such
antipathy to each other in the state that was basically like second-order treason and sedition
but where the interest of the integrity of the state and the interest of the well-being of its
citizens were actually what was directing its AI and its use of that data as opposed to advertisers
and there was the appropriate privacy and protections on it and I got to adjust the settings
and say I'm interested in learning these things I'm interested in being exposed to these other
kinds of ideas here's the ways here's what I want my time on site to do of all the information here's
what I wanted to curate for me now we have a situation where the the behavioral data that
happens by the fact that I click on stuff I can't have technology where I click on stuff and not
gather behavioral data but who is storing it for what purpose and how is it being stored becomes
really critical and it could be stored where the legal binding of it kept it from being used for
purposes other than the ones that I am actually consenting to. It's like personalized learning
Frank I mean think about things like Khan Academy where it's your yes or your personalizing information
you're gathering lots of information about where people look like they're getting stuck or what lessons
they might want to learn more of but the purpose of Khan Academy isn't to manipulate you into click
bait and to make you hate the other political party it's to help increase learning right so you
could have that's the kind of thing that we're talking about is personalized in the interest of
helping society get wiser and more thoughtful not the direction of whatever gets their attention.
This conversation doesn't happen there is no news program that has a conversation like this
like I'm embarrassed I have to keep saying to Daniel to simplify I shouldn't have to do that.
Just like we said just like we said that the fourth estate has broken obviously so has education
because the idea in the founding of this country following the Enlightenment and modernity was
that everyone could be educated well enough to understand the issues that law was going to be
created that would affect and bind their life if I'm going to be bound by law I need to understand
the issues well enough to get a say in that if the people are not educated well enough to have a
say in the law that's going to bind their life it's not a democracy it's just a story or a simulation
of it in which case monarchies might actually be better and not have all the attention go to
flipping back and forth every four years and internal divisiveness if we really want it to be a
democracy an effective fourth estate and education are prerequisites at the level that is needed for
people to understand the issues well enough to participate now we have to say using AI and
attention tech and all of the modern technologies could we make new better educational systems
and better participatory governance systems where everybody can't fit in the town hall but
everybody can give input that now these AIs can semantically parse and help create propositions
that are not vested interest group propositions but that are saying what would the best proposition
that fulfills the interests of everyone look like and now we get to work on proposition crafting
we could use these same technologies that are destroying open societies to build better ones
that though has to become the central imperative of the time and it does require a new cultural
enlightenment it does require an educational rise to understand the issues well enough or it just
doesn't matter it's over like if congress and the public don't understand the issues well enough
then of course the corporate interests are just going to run and authoritarian nation states
employing exponential tech see both facebook and google on one side and china on the other side
are deploying exponential tech towards purposes but neither of them are open societies if the
open societies are not also developing and deploying where the power is then they will just
lose and what we're saying is that the open societies have to develop and deploy the full
suite of modern technologies to create new digital era open societies that can protect
against catastrophe but also protect against dystopias and that is the central imperative
okay i got one last central imperative which is to keep people alive during this at the hopefully at
the uh back end of covid and i don't know of any example that frightens me more or angers me more
than the crap that's put out against the vaccines and i go absolutely crazy and i read it and i
shouldn't because it makes my head explode help me here what can we do we are coming down to the
end of the vaccine process and we are not going to hit herd immunity and the us is not even in the
top 15 of vaccines anymore because of the crap that's coming that's being generated in america uh
about uh from social media how do we combat it when it comes to health because tristan
your idea that they're going to be able to create these stories with these reports i've read them
i've seen them they look real and i know they're not how do we combat it right now because we
don't even have a year to wait on this we have to do this right now it's a big question
they'll you sure um uh we're not going to that's just that just loses um in the same way that we're
not going to prevent climate change from creating droughts and uh affecting areas of poverty that
will create massive human migration there are a lot of impending catastrophes that will just
happen and we'll just lose that we we could have done a better job with this pandemic at a million
points and so this is why we're thinking a little bit more long range about what are the
even worst catastrophic things that we possibly have time to address and why do we why are we
doing so badly at all of them and what would it take to do a better job at all of them because if
we can't coordinate for for climate change or overfishing or biodiversity things or nuclear
deep proliferation or stopping ai arms races or stopping crisper arms races or getting misinformation
right we just fail at everything so ultimately we have to get better global coordination capacity
for global level coordination challenges if we get that we get all the other things otherwise we
don't and so you're talking here about a shared sense making of what is true what is base reality
but in a world where there's a breakdown of trust and a breakdown of trust and what is
legitimate authority you will not get shared sense making so then you either do have to become
china and say i don't care if you don't believe it and if you think it's terrible we're going to
force it on you or you have to say well we're going to just fail or you have to say oh we actually
have to be able to recreate legitimate authority and not just people's falsely falsely belief in it
but a good basis for it how do we do that how do we recreate a shared sense of sense making but
also not just that the social contract and social solidarity that if someone thinks something different
than me and they're a fellow countryman i don't just instantly have antipathy for them i try to
steal man rather than straw man what might be true what values might they hold in their perspective
because if i just go to a culture war with my fellow countrymen and china doesn't have that problem
but we get to amplify our net antipathy towards each other using exponential information tech then
our country's just destroyed it's over open societies there has to be a process of how
do we do better sense making but also better understanding of the partial truths and the
values in each other's perspective so that we can find new attractors together okay daniel
daniel if you're right we're screwed yeah if your conclusions are right because we're not
going to be able to do the things to address the challenges challenges that you lay before us
it cannot it will not happen not so not in the time scale of the issue you're focused on
for this now we're screwed uh just on you're gonna have the last word you do not have to
make people feel good i want you to end in 45 seconds with what you want people to take away
from this conversation don't screw it up i was i was just going to say that i think people think
that trust can't be recovered from where we are and i feel just to say something very concrete
is that if people were to communicate and feel like they're in a way that they reflected why
people distrust the cdc of the david show talked about and if those institutions came out and said
yeah we did flip flop on this and this they people need to feel like they're being told the truth
with earnestness and sincerity and not gaslet and i think the problem in communication is when
you communicate to large audiences and you feel like people aren't going to get it you simplify
the message and you say something that's not completely true but you force it down people's
throats and those who know that that's happening get rebellious and we're not going to create a
unified understanding until we come with sincerity and i think trust is the sort of the fuel that
undergirds all of this conversation and i feel like sincerity and earnestness is the is the vehicle
to reestablishing that trust um and i feel like that's what we're we're trying to do now and just
to name one thing is daniel and i are and and some others are are really looking to see in
washington dc especially in the national security community who resonates and understands with
what we've laid out and we're not trying to be pessimists we're just very we're trying to be
very clear about the space space of problems and what it will take to actually look ahead so we
don't just you know have another covid and we in climate change we get we we mess those up too
um we have a chance right now to to not mess up some of the future tech that's impending dooms
that's coming um and we're looking for help so if you're interested um you know hope we can all
connect through uh through frank and i really appreciate frank you giving the opportunity to
have this conversation i think happy to do more i know we we kept this to an hour but um uh i think
it's incredibly important each of the issues go very deep i mean the teenage mental health stuff
versus the polarization and uh how do we deal with the exponential tech issues
well i i this is incredible and as harry clark says go see ben sass i need to find a way to
have the two of you sit down with him and you don't have to simplify it daniel you can say it
exactly as you say it right now and he'll be he'll be with you every step of the way you guys are
brilliant you guys are the way it should be uh your parents i'm sure were are proud of you
you got a great education this was probably the most important session i've ever done
and i'm grateful for you all for not pulling any punches for not dumbing things down
and the next time i will go to sleep will probably be never after all the things that you just said
so everyone thank you we're not going to do this that often i'm only going to do it when
it really matters and this time it really matters so daniel i hope people pay attention to you
tristan i hope you do another documentary with another couple emmy awards you deserve them
this session's done and heddle do me a favorite post this on youtube now unedited complete
let's use twitter uh to take a couple segments from this we're going to use social media the
right way to get your message out to as many people as possible everyone good night good afternoon
was an honor to be here thank you thanks frank
your undivided attention is produced by the center for humane technology our executive
producer is stefanie lep our senior producer is natalie jones and our associate producer is
nur al samorai dan kedney is our editor at large original music and sound design by ryan and haze
holiday and a special thanks to the whole center for humane technology team for making this podcast
possible
