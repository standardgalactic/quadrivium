I predict Lee Cronin will remain silent on polypeptides, polynucleotides, polysaccharides,
these three key polymers that build us.
I predicted that he would talk about things other than that.
He would talk about bubbles, he would talk about salad dressing,
he would talk about the birth of stars, anything but the formation of molecules.
The paper is one of the most engaged, it was only published on the 4th of October,
had 2.3 million interactions on Twitter, had a couple of hundred thousand downloads,
has provoked discussion, and the thing is, it could be quite wrong.
I don't think that's the way science should be done, I don't think we should be proud of how many
likes we have on Twitter, and I think actually this has the potential to kill science because it
is killing the credibility of the people that are doing science.
There are segments in society that want to cause a god in the gaps,
and I'm sorry Jim, I actually think you're just trying, there's a god in the gaps.
It's actually kind of sad to have to clarify this,
but I feel Professor Tour is also attacked because of his personal beliefs, and that is,
I think, wrong. I think science communicators have a very hard time seeing behind
titles and unfounded claims.
That's the title of the paper, so you're wrong and lying, you know.
Those science communicators may be able to refute unsophisticated charlatans,
like later there is, but they wouldn't be able to call out sophisticated deceivers.
We're here today to talk about the recent debate that I had with Lee Cronin at Harvard,
and you can check out that online.
It was a streaming event, so the actual stream is now up there,
and it's been viewed to date by almost 100,000 people, and presumably there'll be more.
But I have today with me Dr. Hector Zanil, and let me just introduce Hector,
and then what I'm going to do is I'm going to talk a little bit about the debate,
and then I'm going to turn it over to Hector to give his views on this.
But Dr. Hector Zanil has two PhDs from Sorbonne in Paris and Lilly in Computer Science,
Logic, and Epistemology. He was a senior researcher at the Structural Biology Group
at the Department of Computer Science at the University of Oxford,
and the Alan Turing Institute in London, and more recently in the Machine Learning Group
at the Department of Chemical Engineering and Biotechnology at the University of Cambridge.
He's also a lab leader at the Center of Molecular Medicine at Karolinska Institute,
the institution that awards the Nobel Prize in Medicine or Physiology,
and has been an invited scholar at Carnegie Mellon and MIT working on projects for NASA,
among other positions in academia and industry. He's published over 120 papers across some of
the best journals in physics, biology, mathematics, computer science, molecular biology, and artificial
intelligence. But let me just unpack it. So James is a really accomplished chemist,
he's a great designer, so he loves designing molecules and he's good at it, but he clearly
clearly doesn't understand information or the mathematics. Lee has said before that Jim Tour
doesn't know anything about information, so what we've got is we've got an information expert with
us today. Let me just give you my thoughts, and if you haven't watched that video where I was at
Harvard and had that debate slash discussion, let me just fill in a few points for you.
I was accused by Lee Cronin of shouting and hurting people's ears.
So problems are something we should embrace, not shout at relentlessly to say everyone's an idiot.
I wasn't shouting, I've gone back and watched my 20-minute presentation twice. I mean that's
just Jim Tour, that's who I am. I wasn't shouting, I wasn't raising my voice, I wasn't angry.
Professor Cronin's older work, he tried to make illegal peptides by some prebiotic-like
root. It was a bunch of garbage. There was nonsense there. And same thing with saccharides,
because this is hard. He tried to make these sugars that we made billions of compounds.
It's very hard to do this. You try to push molecules toward life, they don't want to go.
When I said his paper on peptides, I showed the title of his paper on peptides,
and I said that was garbage. That means the material that he made in that paper was absolute
garbage. He said he made illegal peptides, he made garbage. He made millions of illegal
peptides at once, all of them scrambled. And then in the few cases where he put
side-chain active peptides in there, they had to have been cross-linked. Yet he said in his
supplemental information that they did see linear ones, but he had no data to support that claim.
It would have been very hard to get any linear ones. And it was a bunch of garbage. The material
in there was a bunch of garbage. I even talked about one of his papers on saccharides. That, too,
made a bunch of garbage, absolute garbage. And I've pointed that out in other videos. He says
it made a billion compounds within an hour, and he somehow made it so that it had less compounds.
No, it still had, I don't know, half a billion or maybe more. And that's only because he skimmed
off the top of it. And he didn't take the ones that had already precipitated out. As far as his
comment on Origin of Life being a scam, yeah, when he went on Lex Friedman's podcast, he said
there was tongue in cheek. That's not how he portrayed it the first time. We go back, somebody
asked him, why do you say Origin of Life is a scam? And he said, because nobody is really doing it.
And those were his words. He never said it was tongue in cheek. That was a year later when he
got such grief probably from the Origin of Life community for saying that. Let me just tell
you about the people who organized the event at Harvard. They gave me every opportunity. I had
20 minutes undisturbed to say what I wanted to say. If I couldn't get my point across to the
community or to that roomful of people in that time, that's on me. That's my problem. I had 20
minutes to say what I wanted to say. Nobody interrupted me. And I think I made all my points.
I came loaded for bear. I fired that shot. And I think I hit a bullseye right on this thing of
pointing out all the difficulties with Origin of Life. So I'm not retracting any of that. I just
wanted you to know some of the constraints that I was under. I had agreed with the organizers
because they were afraid that I'd take over the conversation. I said, after my talk, I will say
nothing unless I'm asked a question. And you will see. I never responded. I never initiated
anything. I just sat at that table. And unless a question came to me, I didn't say it. And I also
said I wouldn't interrupt anybody. And so if they interrupted me, I would yield to them. And just so
that you know the background on that. Now, we have Hector Zaniel here. And I talked about Hector
Zaniel and his thoughts on assembly theory, which was Lee Cronin's major theory. What I had predicted
is Lee Cronin would not address anything with regard to polypeptide problem, polynucleotide,
and polysaccharide problem. I predict Lee Cronin will remain silent on polypeptides,
polynucleotides, polysaccharides, these three key polymers that build us and sell assembly,
resorting to calling those narrow questions and not worth even addressing. I predicted that he
would talk about things other than that. He would talk about bubbles. He would talk about
salad dressing. He would talk about the birth of stars, anything, but the formation of molecules.
So all of my predictions came true. I had also asked whether the audience would really understand
anything from his talk and come away from that, knowing anything more about the origin of life.
And as far as I can tell, I don't think anybody left that room knowing more about how life formed
from that conversation. One person wrote, and after multiple reads, I still have absolutely no idea
what this paper is doing. Another wrote, I read the paper and I feel more confused. I think reading
that paper has made me forget my own name. But now with Hector here, I just want you to know the
background. Hector is not a religious person. He doesn't share my religious convictions. And so
this is perfect. This is not a God of the gaps Christian evangelical coming here. Hector is
neutral to that as far as I can tell. But let's just hear what Hector has to say because when I
quoted him, I was actually pulling out the nice quotes of his concerning Lee. Just a few quotes.
These authors only a few months ago announced that they had achieved the breakthrough of making
time physical using assembly theory, a claim that nobody could understand. Now they claim the same
theory can explain selection and evolution, unifying biology and physics and explains all of life.
But I just want to turn it over to Hector to take it from here and give his perspective on the debate,
his perspective on assembly theory, and his perspective on the utility of assembly theory.
So with that Hector, I turn it over to you, my friend. Thank you very much,
Jim. And it is a pleasure to be here with you, analyzing the outcome of the debate. So let me
share my screen and some slides with you. This is the first time I accept an invitation to a
podcast. And I'm doing it because Professor Stewart and Cronin refer to me on the debate at
Harvard University. Professor Stewart and I may not share the same set of beliefs, but I respect
Professor Stewart's beliefs. And I also respect very much his work as a scientist as one of the
world-leading synthetic chemists. I want to set the record straight that I do not follow any religion
and I am a nice atheist. And that Professor Stewart has never made any religious argument,
as far as I know, in his scientific arguments. It's actually kind of sad to have to clarify this.
But I feel Professor Stewart is also attacked because of his personal beliefs and that is,
I think, wrong. I do not believe for supporting intelligent design. I'm the opposite of a creationist,
just as Professor Stewart says, I think he also believes that eventually there may be a plausible
mechanistic explanation for the origin of life. And that is still my hope and my expectation.
I do not follow all the research of origin of life. Whether they also exaggerate their claims,
I don't know. If they do, it is also very unfortunate. I never speak online with YouTubers or
influencers like the authors of Assembly Theory do all the time. I'm very selective and thank you
very much for this invitation, Jim. So let me start with what I think are the three main components
of Assembly Theory. I think it can be divided into the theory, whether there are any ideas behind
that may be novel. So the three main components of Assembly Theory is the theory itself, whether
there are any new ideas or actual substance, the methods, what they call the assembly index,
the molecular assembly, assembly pathways and so on. And then the application, especially that the
claim is that they can separate living from non-living systems or organic versus inorganic
matter, which by the way, I think it's a completely different question. And more many other claims
that they have made, including that they can detect extraterrestrial life, unified physics and
biology, redefine time, fully characterize life and much more. So this is really like almost
like a theory of everything according to the author. So we are going to explain what are the
contributions and limitations in each of these cases. So first question, are there any new ideas?
I think if there are any, they are very limited because almost word by word, I believe they are
taking much of the content from an area that is called Algorithmic Information Theory that has
its own indexes called more of complexity is one of them. Algorithmic probability is another one
that is deeply related and another one that is called logical depth that was introduced by Charles
Benedict of which you can see two papers on the screen. And this concept was introduced in the
80s and is basically exactly about trying to find the causal history of an object by applying
some sort of statistical and algorithmic index, which in this case is called logical depth.
And this was in the context precisely of trying to characterize life and explain
living systems and structure in the world. And most of these ideas are actually based on a concept
and theory that was developed in the 60s and 70s that quantifies time by the minimal number of steps.
And this is very related to compression as we are going to see in the next slides. So some say that
assembly theory is making some good points that assembly theory is telling us for example how
living systems are complex, highly modular and hierarchical. And I don't think that is a contribution.
We know this since the discovery of the cell. We know this since the development of genetics.
All the work by professional scientists that have been done in the field of omics and not from assembly
theory. Every complexity theorist and systems biologist would tell you that life is highly
modular and hierarchical. We talk about building blocks all the time, how living systems reuse
these building blocks to build everything at every steps from genes to proteins to cells.
And I think one of the tricks of assembly theory, if you see it as some sort of deception,
I'm going to make the case of why I think it is. I think it was not deception at the beginning,
but now it is becoming one when they are being represented with evidence that it is actually
the contrary, that it is not a contribution. But I think the strategy has been to mix full or half
truths with non-truths. And the truths are so obvious and undisputed that they
give some sort of credibility to the deceptive content. So for example, when they talk about
the combinatorial argument regarding how nature comes up with these highly structured entities,
their explanation is not different than algorithmic probability. And also we are not going to be able
to get into the details of what each of these theories actually try to explain. Anyone can
just go online and look for these theories. So algorithmic probability is another way to see
probability. As you may know with classical probability theory, what you do is to approach
events in a traditional statistical approach. Let me give you an example. We have an object like
the concept of a mathematical constant like pi, for example. You remember 3.14159 and so on.
If you ask the question, if you regard this number as some sort of generating mechanism
producing every one of the digits, and you ask what is the probability of getting every digit
right by typing randomly on a typewriter, for example, the probability is extremely low, right?
It's one over 10 to the number of digits that you want to get right in the first place. So the
probability diminishes very fast. But what if you ask the question of what is the probability of
coming up with a formula or the computer program that produces pi? Then things change dramatically
because pi is a number that has a very short formula because it has low complexity. That's
the definition of complexity. If something may be very large or long, but it has a very short
description. So pi has many short descriptions. It could be a formula, it could be a computer
program. So instead of hitting keystrokes on a typewriter, you hit keystrokes and each of them
are actually a piece of a computer program. It turns out that the probability of producing
an object with such a structure is actually quite high because the computer program that
produces pi is very short. And that's basically kind of the definition of what assembly theory
is offering. So they are taking all these pieces from algorithmic information theory,
putting them together, nothing that some other people and authors have already done,
and presenting it as something new. Okay, Hector, let me just interject. I just want to make sure
people are understanding what you're saying. So first of all, if you think I'm the only one who
talks technical, I mean, it's Hector too. This is our world. This isn't the world in which
scientists speak. But what Hector has just said is that assembly theory can be reduced to a number
of things that have been discussed in the 60s and 70s and 80s. But there's nothing particularly
new here. And he's also mentioned how he thinks that this has migrated beyond just fundamentally
getting things wrong and claiming something as being novel when it's not novel. But he did
interject there. He said it's moved into the deceptive. Because things have been pointed
out to them, yet they continue with this. So he's saying that now it's moved into the deceptive.
So Hector, did I summarize that to this point? Okay.
That's right. I think that actually they are even doubling down with their effort,
because they cannot back off now. It is probably too late for them. I'm going to continue showing
in more detail how actually how similar, if not indistinguishable, from algorithmic information
theory. So let me now move to the methods. We covered whether there are some new ideas in
the theory and the methods are going to support what I'm saying about the theory.
Just a few quotes. These authors only a few months ago announced that they had achieved
the breakthrough of making time physical using assembly theory, a claim that nobody could
understand. Now they claim the same theory can explain selection and evolution unifying biology
and physics and explains all of life. Assembly theory is a weaker version of one of the simplest
algorithms known in computer science, Huffman's coding scheme. If you remember from the debate,
Cronin came almost like offended when Jim suggested using my reference that this was
related to a compression algorithm. So it's not compression like Huffman encoding?
So definitely it is a compression algorithm. And I'm going to show you some of the examples,
specific examples that they use and how they would look like with another algorithm that has
been introduced in the 70s or even before. So why they don't recognize that this is a compression
algorithm? Because everything else would collapse. Assembly theory would basically collapse into
exactly algorithmic complexity. So it is in their interest to say that this is not a compression
algorithm. Not only that, but their compression algorithm is very basic. So it is based on
compression algorithms that are called dictionary based. So basically it's just about finding
repetitions in a piece of text or at the piece of data. And it is not optimal in any universal
sense. And Cronin always says no, but we are not looking for optimality. The problem is that
they don't have any evidence that their compression algorithm or however they want to call it corresponds
to anything ground truth about nature. They are just speculating on how it may assemble. That's
the whole hypothesis. So they don't have any reason to believe that their scheme is better than any
other. And the problem is that we have applied all the other schemes and actually either reproduce
exactly the same results or better. So there's actually evidence of potential evidence that those
other compression algorithms may be closer to ground truth. That will be the scientific evidence.
Okay, so let me just summarize for the audience what you're saying. You're saying that what
assembly theory is, it really backs out to a standard compression algorithm that is analogous
to such algorithms that were developed in the 1960s. And in fact, the ones in the 1960s actually
did a better job than what assembly theory is doing. That's correct. That's right. And people may ask
us why you publish, write and publish a paper. Well, we have and it is online and people can
find it. I'm going to show some figures in the next slides. Obviously it is more difficult and
this is the asymmetry paradox. So they are making deceiving statements. We have to come up with all
the effort to disprove them. And that is very expensive. It requires a lot of effort. We're
distracting ourselves from our own research. We basically try to make a favor to the science.
But let me show you how similar their algorithms are actually to
existing compression algorithms. And this is the paper I was talking about, our study is currently
available online. And I'm hoping it's going to be soon published in the journal. But you can see here
on the screen, we reproduce exactly their results. So this is figure four, and it coincides with their
figure four. They also have the same figure, but with only one of the measures. And that's one of
the criticisms that we have made before, why they didn't compare their index to anything else. So
that's a basic control experiment. You don't just come up with a new measure and say it is
fantastic. You have to prove that actually you are doing something that no other measure can do.
Otherwise you are just repeating what you could have done before with anything else. And that's
exactly what we are showing on this paper. We used exactly the same data because that's another
argument that he has put forward against our paper that we are perhaps using some sort of
different data that is not true. So in figure three on this paper, we use different data because
we wanted to show that actually if you take nomenclature names of the chemical compounds,
or you take distance matrices, for example, almost pretty much any representation of the data,
the chemical data, you get the same results. Later on, you are going to see one of the arguments.
Basically, we are showing that any index and any data basically gives you the same results as they
are pretending to be completely novel and revolutionary. So that's what it doesn't make
sense. So on the screen you are seeing their molecular assembly is the blue one. And you can
see that for abiotic and dead categories, they are kind of in the same place. But then biological
ones, they call them that way because these are organic compounds, they have a higher index. And
here the y-axis doesn't have to correspond because obviously we are using logarithmic space so that
we can put all these indexes together on the same screen. So you see that molecular assembly comes
higher. And that's fine. It is basically saying that you can separate this category from this
other two. But then when you look at anything else, including, for example, a very simple compression
algorithm that is called RLE for run length encoding, it is also doing so. If you take also
Hoffman on our own measure in yellow, they are also exactly doing the same. So you have like the
two examples almost at the same level, sharing the same mean. But then for biological cases,
they come much higher. And if you do the statistics, we don't only match their results for actually
outperform them. So what Hector is saying, he's taken his theory, which was developed quite some
time ago, but several years ago, and also theory from the 1960s and matching the output that assembly
theory is supposed to be giving and is totally novel. No, he's saying that there are algorithms
from the 1960s that are matching it and even outperforming. On the actual data that assembly
theory has put out, just these old theories that are 50 years old are doing the same thing. So
what he's doing is he's dispelling the novelty of assembly theory. He says that this is a
traditional compression algorithm that does the same thing. That's absolutely correct. Exactly
the same data that they made available for their paper, which by the way is kind of incomplete
and not in the best shape. But we took at face value their results for their index and then used
the data that they provided. We were able to produce this plot on the screen. Exactly the same
procedure. Now the other thing, so Jim was saying, oh, it's not correct. We can actually measure it.
This is when I was like, oh, we can physically measure it without any mathematics. We can go
and do molecular spectroscopy. That doesn't make any sense. What does he mean by not using mathematics
and directly on physical data? That doesn't make any sense. They show a formula on the screen that
we are going to see in the next slide. It is a mathematical formula. And when they say they are
applying to physical data, it's basically just a matrix with real numbers, which is exactly what
we fed with our algorithms. So exactly the same. So let me get into the details. Why it is not a
surprise that we are basically matching the same results if not doing it much better. That's because
their algorithm is, as I said, a dictionary based compression algorithm, even if they hate the idea.
I have put as an example Hoffman coding because it's kind of the simplest and optimal. But
actually their algorithm is exactly the same step by step to an algorithm that is called LC77.
What a typical LZ compressor will do is it will work its way through all of the text
that you need to compress and will actually look for sequences of characters that recur
over and over again and will attempt to reuse them as much as it possibly can.
This comes from their paper. This is an example and you can see it on the clip. He provides the
same example with Abra-Cadabra. And he basically says because you produced Abra before you can reuse
it and put it at the end and basically you save that step. And you do things and events happen
and there is a memory trapped on that line. And then you count the number of steps. That's exactly
the definition step by step of LZ77 algorithm. And you can see it here. I didn't have even to
produce by myself the examples because if you go online and you type LZ77 Abra-Cadabra, you are going
to find hundreds of examples of students that have been given this as a homework in an introductory
course in computer science. And this is exactly the same algorithm. So you traverse the stream,
find the longest repetition and then you have a pointer. You have to go seven places back
and the length of the word that you are going to replace is four letters. And you can find
plenty of examples of exactly the same. From understanding you have an object at a beginning
and you do things and events happen and there is a memory trapped on that line. And that is assembly
theory. It's not hard. He says this is it about assembly theory. This is the whole algorithm.
There's nothing else. This is very simple. I'm using pretty much his words. So if this is it,
this is LZ77 that was introduced in the 77. There's nothing else. Then he says it's because
we can produce a graph. You can produce a graph for this exactly as they do. Actually, the way
they are doing it is kind of the wrong way because as I said, they don't do it optimally. They cannot
prove that the algorithm is optimized. It's limited. So after LZ77, the world has moved on to more
powerful compression schemes because it has some limitations. Let me just interject there. So what
Hector is suggesting is that Abracadabra teaching that Lee gave, that is a typical homework assignment
for a student taking computer science and that's using a compression algorithm, this LZ77. There
was nothing novel in this and in fact, assembly theory did it in an inferior way and that's why
it's often not used because they have much better algorithms now. That's right. So it is exactly the
same as LZ77. But what I'm saying is that there are new, better algorithms that are different to
this one and therefore to assembly theory that are much better and that's why it is not a surprise
that we were able to actually do better on their data to separate the classes of
organic and non-organic categories. And they always have an answer. They may say now, for
example, no, that's because we are only interested in the number of steps and not the resulting compressed
text or whatever it is. It doesn't matter. The algorithm comes with the number of steps anyway.
As I said, they also say that it doesn't come up with the graph. The graph, you can produce it
yourself just as you're doing it for assembly theory. So this is not a situation in which we
are attacking Cronin because he's kind of a Galileo with a new theory, a renegade of
status quo because actually he mentions Galileo, I think, twice during the debate.
I've reminded you the heliocentric view of the universe that Galileo kind of had
Bill popularized a lot about what Galileo did and I'm no Galileo.
This is about no substance at all. And that is very strange. They also say, oh, that's because we
are applying this algorithm to mass spectral data. And that's when he says that they are applying it
on physical data that nobody else can do. We can actually measure it. This is when I was like, oh,
we can physically measure it without any mathematics. We can go and do molecular spectroscopy.
That doesn't make any sense. So LC77, the evolved version of LC77 is called LZW.
Basically, just a small variation of the same algorithm is used behind GZIP. And we use this
algorithm to compress images all the time. Images are just real value matrices, just the
mass spectral matrices that Cronin was using in his original paper. So there's absolutely no
difference in the kind of input to these measures. They are exactly the same. It doesn't make any
sense to talk about physical data. There's some post processing in the middle, but it is exactly
the same. We take exactly the same input. We run a very simple algorithm that is implemented,
instantiated in a computer program, just as he did. There's absolutely no difference.
Let me just clarify something. Hector, is it right that you have used the very mass spec data
that he has used, and you're able to reproduce it with much older algorithms?
That's correct. So that's figure four I showed before. That's exactly the data he was talking
about. Well, actually, I am aware of a new paper coming out on this regard already showing that
you can produce, actually, they occur naturally, these kind of minerals with very high assembly
index. So even that separation between organic and nonorganic doesn't make much sense. And that's
why we didn't make much noise with our own research. I just showed you a paper that we published
five years before assembly theory showing that we could separate those categories. But again,
organic doesn't necessarily mean directly like biology or the other way around. We thought it
was interesting, but not to make these kind of claims because a lot of research is needed.
And that's exactly what a responsible scientist says when doing science. You say we have made
progress, but that doesn't mean we have solved everything. So here's another paper from the
same group with Cronin and Sarah Walker, also senior authors. They opened this paper with this
figure, and I made sure to put in purple color what I added to this figure. So the original one is
the blue, white, black figure. And this is, I think, figure two or somewhere in the paper.
So let's take first figure one in this paper published in entropy. They are claiming that
assembly theory is different to Kolmogorov complexity and to Shannon entropy. But strangely
enough, this example is exactly the same. It is only that they are applying it in the wrong way.
So you remember assembly theory basically counts the number of repetitions. And in this case,
I think it is probably five. Now, depending whether you take the input as a step or not.
But then look at what they put in the figure. They say Kolmogorov complexity is completely
different because what it's going to come back with is a computer program that says,
do six times this output or print six times this output. And they claim this is completely different.
Well, the information they need is exactly here. It is the number of steps. So I don't understand
what they are saying. They say that Kolmogorov complexity is not computable. That's partially
true. It is to be technically correct. It is semi computable, which means that you can approximate
it just as they are approximating it with assembly theory. So assembly theory is an
approximation to Kolmogorov complexity. It is called a resource bounded approximation of
Kolmogorov complexity. And that's what makes it computable. But there are plenty of computable
approximations, including the ones that my groups have proposed for a number of years.
We have the coding theorem method, the block decomposition method, and there are methods
that others have been using. So basically there are two main approximations, approximation methods
to Kolmogorov complexity, as we are going to see in the next slide. Either you approximated by
compression algorithms of which assembly theory is one and one of the most basic, or you do something
a little bit more sophisticated that is a little bit farther away from simple statistics just as
assembly theory is. Remember, assembly theory is just counting repetitions. You then count how many
copies of the object you have, and the larger the number of copies and the larger assembly index,
the more you're sure it came from evolution. And actually, we all know, I mean, those that
work in my field, computer scientists, informaticians, are actually Shannon entropy is a function that
counts repetitions. It basically was introduced in the 40s or 50s for that purpose. It counts
repetitions based on a probability distribution. So you have some sort of prior, you don't leave
the same way to everyone. But you can even see here how they apply wrongly Shannon entropy,
because they are providing Shannon entropy with a different input. The input should have
been the two squares, not only one. And with two squares, what you have to implement is some sort of
Shannon entropy rate estimator, which would have told you that the lowest entropy of this
object is when you take the tuples, and then you just count the number of tuples. And that's
exactly what these compression algorithms do. What that's why they are entropy estimators,
optimal entropy estimators. So RLD, Hoffman coding, and this Hoffman coding is the one
optimal I was talking about. LC-77 is also optimal in the Shannon entropy sense. So they are
Shannon entropy estimator, and they would provide you exactly with information that you would
have required for a uniform probability distribution. Let me pull this together, is that what you're
seeing is you're seeing an informatician, somebody who works in the air of computer science,
and has to package information. So when you download an image, and you bring up an image on
your computer, how did that image transfer through a wire and through the internet, through the cloud?
How was that image packaged? And computer scientists have devised ways to do this.
Mathematicians, computer scientists, informaticians have devised ways to do this over a period of
60, 70 years, and he's even quoting even longer than that, packages to do this.
And what he's saying is that assembly theory is doing exactly the same thing that these are doing.
Now, these are far more developed because people have been working on these things for 60 or 70
years. And he says that assembly theory is just a weak version of these things, that there's nothing
novel here. And that's why even on this slide, he's saying, is this ignorance of theirs? Could be.
Or is it out and out dishonesty? Now, I have never presupposed that Lee Cronin was being
dishonest, but here's the question that Hector is asking. He says it's so obvious to those in the
field that this is well known. That's correct, Jim. And at the beginning, I was sure this was
ignorance, but actually I've been in communication with Cronin even before his first paper.
And I was telling him everything that I'm telling you and your audience. And he decided not to
take it on board. So that's why I'm asking what is the motivation behind it. And so oddly, in this
example, it turns out that Shannon entropy called more of complexity that they despise so much.
And assembly theory basically gives you exactly same information. I'm obviously
abusing here the equal sign, because it's not exactly equal. Some of them would give you more
information. So called more of complexity is actually coming back with a computer program.
But the computer program has the information needed. So as a definition of complexity,
algorithmic complexity, the size of the information and then the number of steps to
compress and decompress this object is exactly the same. The same when they claim that they
can come up with these graphs again, these are very well known in computer science.
Introductory courses, you come up with these kind of graphs and finite state of automata all the
time, dictionary trees or nothing new. Assembly pathway start with a basic set of building blocks
and allow joining reuse. It's a bit like a give a child and say, right, start here,
let's just take abracadabra. Well, they call them assembly pathways. So everything is about like
renaming things that were already around. So as I was saying, basically, there's two ways to
approximate called more complexity. And called more complexity is not just a random measure
of complexity. It was proven in the sixties to be the measure of randomness. So different
mathematicians were trying to characterize randomness in the different ways by compression,
by prediction or by what is called universal studies, statistical tests, and they were proven
to be equivalent between each other. So that means that you have captured something very
fundamental in mathematics that basically randomness is really captured by this definition.
And one of the criticisms I'm already running in my head, what Corning would say is that,
yeah, but randomness is not the measure that we are interested in. It's more like a structure.
And that's right. But that's why many other measures have come up after algorithmic complexity
on top of algorithmic complexity use it to characterize what it is called sophistication.
So the number of steps, for example, exactly what they are talking about, that one is logical depth.
But actually, they are not even implementing anything similar to logical depth. So there's
always this disconnection with what they are saying they want to capture all this structure and how
the causal history and then something so extremely, I'm trying to find another way to
call it trivial because I really find difficult not to appear like I'm attacking them personally,
but this is incredibly trivial. So the method is incredibly trivial. And the theory is basically a
copy of algorithmic information theory. And as I was saying before, there are two ways to approximate
a model of complexity, basically compression algorithms that have been used for at least 25
years or 30 years for the purpose of applying it in all sorts of data, biological, chemical,
and so on. So even when these compression algorithms have been around for 40, 50 years,
it's been only 25 or 30 years that they have been used as approximations to call model complexity
by people like Paul Vitani and Lee, for example. They have a very beautiful paper where they can
reconstruct all the non-phylogenetic tree by looking at the compressibility of full genomes,
for example. And they didn't make any claims to the media where perhaps they could have done so.
Again, that was not very surprising for someone like me that is also in biology because we know
that, for example, GC content in genomic sequences is very similar to similar species. So it's almost
like trivial to reconstruct these trees, but it was an interesting approach to use compression
algorithms, which by the way is exactly LZW that includes LC-77 to reconstruct that phylogenetic
tree. And the other method is the ones that we have been using and we introduced a few years ago.
We've been working on this for 15 years that we call block decomposition method. And actually,
in appearance, it's very similar to their own index, which by the way is very difficult to
understand. One person wrote, and after multiple reads, I still have absolutely no idea what this
paper is doing. Another wrote, I read the paper and I feel more confused. I think reading that paper
has made me forget my own name. You even forget your name when you start reading their papers,
that is actually the case. It is very confusing, but anyway, what we know that it's going on is that
they are counting blocks. And our measure is called actually a block decomposition method and has
been around for 15 years. And what we do is exactly that count blocks, but instead of doing it just
trivially, behind every of these blocks, and that is the key that you are seeing in my definition,
we do something much more interesting, which is related to the likelihood of that computer program
to actually compress data. And it is not related to traditional statistics. So it has to do with
finding the computer programs that are able to generate that piece of information.
And that's because it is much more powerful. We found like 50 years ago, we had to move away from
Shannon entropy and this kind of simplicity of counting repetitions, because you would leave behind
so many things, including for example, just reversion. So imagine that you are counting the
complexity of a protein structure. If you find, if you read the protein in the reverse way,
assembly theory basically would miss it. So what this kind of new measures like the
one that we introduced is basically taking all the possible or many other linear and nonlinear
transformation of that data and not trivial repetitions. So it is an improvement over previous
measures. And if you look at our papers, we always compare our new index or this index
to previous ones, to Shannon entropy, to compression all the time, because that's
basic insight and that's a control experiment. So the group of assembly theory, they never compare,
they just start the paper basically just discarding everything else. Say, you know,
this is not Conmogorov complexity, this is not Shannon entropy, this is completely different.
And some people take it at face value and believe that it is actually the case, but it is not.
Well, I, you know, I found it interesting that you also got confused reading their paper because
I didn't understand it. So if you had trouble understanding it, it makes me, makes me relieve.
It is incredibly difficult. And I suspect that it is because, and as I said, I don't think this,
I'm hoping this didn't start as a dishonest exercise. I think in their group,
there's no computer science expert, perhaps, or I don't know if there's any mathematician,
this doesn't look like the work of a mathematician. But it looks like they kind of operate that way
that they don't look for what others may have done. And if they had the idea, they, they adopted
and implemented without doing any research. Right. And so, so let's give them the benefit
of the doubt. Lee said in the debate that he's an amateur mathematician and an amateur, I don't
know if he said computer scientist or something else. Right. I am a chemist. I also do computer
science in my spare time, a little bit robotics, want to be physicists, want to be math, mathematician,
had 2.3 million interactions on Twitter, had had a couple of hundred thousand downloads,
has provoked discussion. And the thing is, it could be quite wrong.
And Cronin says it when, when he's in the debate with other, in front of other scholars,
he says, this may be wrong. This is perhaps a small step. I don't know about this or that,
but then you, you saw on the screen the press release from their universities.
Right. So, so, and this is what happened in the debate. He opened himself up and he says, you
know, I may be wrong. I'm just throwing the ideas out there. But what you're saying is,
when he's before a group of scholars, that's, that's the, what he'll say, but when he is
speaking to, to non-experts, he portrays this quite differently.
That's right. And it is not only general public, but co-leagues in other areas. And unfortunately,
many of their citations, he's very proud of, to those papers, maybe from colleagues that don't
know much about this area and believe what they are saying, you know, on their titles, on the media.
So it is not only about deception in science, communication for the general public is,
is everywhere. And that contaminates science. It is not just the practice of science.
So I don't know what else there is for assembly theory. And you can see also on the clip that
he says that it is not scientifically disputed. I knew something interesting was going on,
because everyone's like, arguing about words and no one's disputing the science.
No one's disputing the fact we can measure assembly. Well, every step
is disputed. I told you, for me, for assembly theory, I did not see how it would apply to chemistry.
And then I said, you're making these oligopeptides. He showed a picture of oligopeptides in his figure,
where he had amino acids, and then he has now this oligopeptide. I said, how do these things get
together? And then in the debate, he said, well, this was never made to be a chemical model.
Jim talked to the graphs in the nature paper saying these are, you know, this is just
nonsensical graphs, mathematical objects. They're not schema. I didn't say in the legend they were
reaction diagrams. That's a massive misquote in this service. But he showed chemical structures.
So I was completely lost there. And I doubt if anybody else really understood it in that room,
because, you know, I'm supposed to know about these things. And it made no sense to me. And then
when I asked him about the very molecules that you show, why, you know, can you show a picture of a
duck and then describe that you describe things about this duck? And then somebody asked you, well,
how'd you get the duck? Well, it didn't really apply to a duck. Well, you showed a duck in the
article. Here you showed a bunch of polypeptide in the article coming from amino acids. And then
you tell me it doesn't apply. It was just a model. It wasn't meaning to apply to chemistry. That's
another point of confusion that I had. Maybe he just didn't know. You know, sometimes people write
to me with these amazing chemical ideas, and they say, you know, I'm not a chemist, but, you know,
I thought of this. We could mix this and mix this and this could happen. And I have to go back and
explain to them that that's not really the case. And you're a little bit confused on how these
things work. That could be the case that in the amateur side. But I think what you're saying
is it gets beyond that because you've pointed these things out to them, and they've doubled
down. And that's what gives you greater reason for pause in this case, correct?
That's correct. And there are many answers for those kind of limitations, because we all have
those limitations. My original background is in mathematics and computer science. And I've been
working in computational biology and systems medicine for a number of years now, perhaps a
decade or more. And what you do is basically to team up with experts. And that's the way you
start learning and make sure that you don't make basic mistakes. And as I told you, I approached
Cronin when I saw that he posted this paper on archive, the preprint, and told him, I think there
are many basic mistakes, and I will be happy to advise you and do something together. And he
refused. I don't know why. But I think that's the answer. And as you say, when someone is pointing
you out the possible mistakes, you have to do something about it instead of doubling down.
And something very important here is that the problem is that's fine. I can believe that perhaps
it is that because they didn't know. But we have to compare and measure everything related to
assembly theory against the public claims that they are making. And these are some of the public
claims that you also showed on the debate. So things like assembly theory puts chemistry
center stage to explain molecular complexity and life's origins. Assembly theory unites physics
and biology to explain the universe. Assembly theory, a new theory of everything. Assembly theory,
all new theory of everything could unite physics and evolution. A new theory of matter may help
explain life. And on the cover of Scientific America and also suggesting that they can now
detect extraterrestrial life. And there's so much more. And who is to blame? Because I don't think
they are making up these titles by themselves. I think it is mostly, I'm sorry to say it this
way, but garbage in garbage out. They are also saying life, modern physics can't explain it.
But our new theory, which says time is fundamental might, time is an object. So they are redefining
time. Conventional physics doesn't really recognize time as a thing other than just a,
you know, a coordinate. But what if time is a little bit different, right, in a block universe?
Nobody knows what that means. Our radical redefinition of life could help us find aliens. So there's no
moderation of our self-restraint here. If their claims would have been something like simplified
compression scheme based on algorithmic complexity and previous work produced similar results
applied to mass spectrum molecular data, we wouldn't probably even just discussing this.
No, no, nobody would accept a title like that for a lay heart and call. You know, that's only good
for the chemical, for the scientific literature. But, but yeah. And so we can't just throw things
like this always at the feet of the press, because very often the press will talk with,
with our scientists and say, have we got this thing right? Now they don't always,
but they often do. Sometimes their strictures don't allow us to, to critique it, but they'll
ask us about it. And certainly the best journals always do. They, they get a fact checker and they
go back with the author. We've said this is this right. We've said this is this right.
So one of my complaints in the origin of life community is that if the researchers themselves
are the source of the bold claims that are way beyond realistic here, it's not just the press
running wild. It starts with the researchers themselves making crazy claims that are way
bold beyond it. And I think that that's what you're saying here. It's not just some reporter doing this.
The source of this is the, the very authors of, of the article.
And that is the case. Actually, my next slide is the proof that this is not coming from the
media, unfortunately. So this is coming from themselves. So these are their press, the
university press releases that certainly are run by all through the authors, the senior authors
themselves. And actually they, they most likely wrote them because the press release departments
don't know what their research is about. That's the case. So, so what he's saying is this is from
their universities themselves. And I, this happens to me all the time when I work with a university
reporter in the public affairs office is that, that they will write an article and I have to
approve that. And I'll often edit it and I have to approve that. So if there's, if there's over
extrapolated claims in a university press article, that for sure has been seen by the author.
That's correct. And you can see also in the debate how different the attitudes of Croning was saying
that he was pretty much an amateur on everything and that he could be completely wrong. But that's
not the impression they are giving to the media, general public and other colleagues.
And one of the other things I should say is I'm a, I'm an amateur, Jim says I'm a bad chemist.
I'm an amateur philosopher because I want to learn how to think. And I really think the problems
are a sign of where we can make progress. And I've come here today not to argue with, with Jim and to
make grandstand, but just say, Hey, there's some really cool problems. These are the press releases
from their universities, even saying assembly theory could spell good news for drug discovery.
In no of their papers, I could find anything about drugs. So, so they are even anticipating
that this could be revolutionary in drug discovery. Yeah, I want to, want to focus on one other thing
here. Hector, you've said that, that in the debate, and you wrote this in your blog. So
for anybody, if you just googled eight fallacies of assembly theory, you would immediately find
Hector's blog. And he has 100 pages written like this of pointing out things in great detail.
But one of the things that you, you wrote on there concerning the debate was that, that Professor
Cronin came as, Oh, well, you know, I'm not an expert on, on, on this, I'm not an expert on that.
And you say, this is, this is, you know, the Dr. Jekyll and Mr. Hyde in a sense, you know,
you didn't use those words, I'm using those words in that, in that the impression that he puts out
there is he's an absolute expert in these areas. And he's discovered all of these new theories.
Is, am I understanding this right Hector? That's, that's right. That's what I believe. And you can
see it on their own title that definitely was their author's choice and assembly theory explains
and quantifies selection and evolution. And again, I want to say that this is not exclusive of
Lee Cronin and Sarah Walker. But, but so far, they are kind of the best examples of how you
should not exaggerate your results. You may remember also how he said that this is how
science makes progress, that he likes to provoke and be provocative.
And I wondered into the field, relatively innocently, and I like making provocative statements to get
people to think, not to get people to shout at me until they're hoarse. Now assembly theory is
just the first step. Now, okay, Jim, you put up some, you know, you picked a handful of complaints
about the paper. But the paper is one of the most engaged, it was only published on the fourth of
October, had 2.3 million interactions on Twitter, had had a couple hundred thousand downloads,
has provoked discussion. And the thing is, it could be quite wrong. But maybe it's less wrong
than some other approaches. That is science. I definitely don't think that's how science
makes progress. I think actually this has the potential to kill science because it is killing
the credibility of the people that are doing science. And this is definitely not a good practice
of science or communicating science. Yes, this has been, as you heard, I said several times in
the debate, when you start claiming that you're going to make life in two years, or three years,
or five years, or you're very close, or all of the paradoxes, or most of the paradoxes in origin
of life have been solved, it's a disservice to the field. Because who wants to study it if you've
got this thing solved? And that's why the general public was so confused. I gave the statistics
on the general public, on the confused, they think that one third of the general public thinks that
scientists have made frogs in the lab. Two thirds think that they've made a bacterium in the lab.
And 80% of these people had college degrees. So there's a real danger in throwing this out there,
and to just say, well, we like to be provocative, that actually is a disservice to the field. And
I think, Hector, you're agreeing with that because you see it in this one paper, in this one area,
and I see it throughout origin of life. I see this sort of thing. I see it. I wouldn't know about
the other researches in that field, but I'm certainly know of others in other fields. And I
think it goes beyond just deceiving the general public. I think this deforms also the way in which
scientists are evaluated. So here on the screen, I'm showing what I think is some sort of a
vicious cycle. So when you do this kind of paper embellishment, media hype, totally unfounded,
exaggerated claims, what you do is to also improve your citations because, and sometimes
for the wrong reasons, either they are negative citations, or they are positive from misled
colleagues. And then that increases basically everything else, your edge index, your credibility
reputation, that leads you to more taxpayer money for more grants, larger groups that can
write more papers. And it is a cycle that has no checkpoints. Nowhere here, you can see that if
you do something wrong, then you get something wrong. Basically, whatever you do, you do better.
The paper is one of the most engaged, it was only published on the 4th of October,
had 2.3 million interactions on Twitter, had had a couple of hundred thousand downloads,
has provoked discussion. And the thing is, it could be quite wrong.
I don't think that's the way science should be done. I don't think we should be proud of how many
likes we have on Twitter. And that's what has become with some authors and some groups.
What you've said on your blog is exactly this, is that there is this cycle. And if people say,
well, it's just gotten millions of impressions, well, you say in your blog that just because it
got millions of impressions, it's for the wrong reasons that many people are looking at this and
scratching their heads and saying this can't be. So just because something has an impression,
somebody downloads a paper, doesn't mean that it's correct. It could mean because it's grossly
incorrect. I'm glad you're pointing this out now, and I'm not the lone voice crying in the
wilderness. And I think there should be more people speaking out. And that's what I found around.
So my colleagues pretty much agree with how I see things, but they don't come out.
I don't know if there's some sort of unwritten agreement to keep the status quo or something.
But just to be more constructive, what can we do to solve this? And here's a random idea.
Should we have some sort of science watch organization to denounce abuses like this?
Or should institutions held accountable? What about Glasgow and Arizona State University?
Allowing all this to happen? There are no checkpoints.
One of the things that is going on here, as I've said before on my channel,
there are many colleagues that have said to me, Jim, I see your videos and I agree with you.
We don't know how these things happen. But they'll say, but don't use my name.
Don't use my name. And I'll invite them onto my channel to talk about it. They don't want to get
near my channel because they don't want to happen to them what has happened to me. Where
there is an establishment that makes it very difficult on those people who raise these sorts
of flags and say, hey, there's a problem here. There's an establishment that controls funding
and it does affect funding. And I've been greatly blessed in spite of this. Now, I've gone through
seasons where it really hit me. Interestingly enough, I had two program directors from two
different federal agencies tell me, Jim, don't even bother applying because they're not going to
fund you in this agency. And so, you know, that's kind of frightening because you take a stand on
something, you know, you get in trouble for it. So we have laws in the United States called
whistleblower laws that protect people that call out fraud in certain categories. But
when you cry foul in science, there's not an easy checkpoint here. And I've experienced this in my
own life. And this is why there's not more people coming up. I mean, there's young folks, young men
and women trying to get tenure. The last thing they want to do is have a community of scientists
against them because it's the community that is going to write their letters to say, yes,
this person's done great work, give them tenure or not. And so I came through a system where this
wasn't a big factor and I wasn't talking about origin of life. And thankfully, I'm a full professor
and it's harder to deal with me. Now, you can try to cut off my funding. But in spite of that,
I've been greatly blessed because the quality of our work, but it has been a battle and it is a battle.
And this is, I think, what you're experiencing, Hector, have you experienced some of this?
You know that for younger researchers, it's actually much more difficult and I felt it in
many ways. Just to give an example, I submitted this paper I showed you on the screen and it
appears that actually someone in Cronin's group was asked to be one of the reviewers. So you cannot
even get replies to their science easily go through because the way the system works, even if you can
ask them to not include some of the authors in Cronin's group, there are at least like 100
postdoc researchers. And it is most likely one of them trying to review our paper because
they are the experts in assembly theory and basically they do just world matching.
So we are going to be finding blogs at every stage. And as you say, we want to do research in
this area. Cronin is regarded as one of the leading scientists. So it's very likely that
there's a very good chance that he's going to go through him and obviously there's a competing
interest. So definitely there are issues. So the people understand the system. Let me explain
this. So at least in the United States, if I submit a grant to a grant proposal to the National
Science Foundation, that is going to be read and critiqued by four or five of people around the
United States and some even in other countries. And they say, is this good research? Is it worth
funding? Are there problems here? If you don't have all excellence, even if you have one person that
just checks good, you're not going to get funded. If you have one person that checks good, not even
fair or poor, but just good, you won't get funding. So if you have three or four excellence and one
good, you don't get funding. So it's very easy to cut somebody off from funding. And if you say, well,
they didn't get that grant, that is a career killer. You're paying graduate students and now
all of a sudden, because somebody's felt that way. And so in some agencies, there's a chance to
rebut. In other agencies, there's not so much of a chance to rebut. So it can be a real problem.
It's really scary, particularly for the younger people. And Hector, I mean, I know what you're
talking about and I feel for you. And hopefully, you're going to be proved right by a larger community
here so that at least there's some protection for you, protection for your career, and that
there's some reward at the end that would be good. Thanks, Jim. So before going to another subject,
let me show you some examples of what I think are measured self-restraint news headlines
from today, actually. Because if we, in medicine or some other fields, were seeing this kind of
claims, most likely they would bear some liability. Definitely would bring the attention and
scrutiny of regulating bodies. And they are borderline by talking about drugs, for example.
So one step further and in any other field, this would bring consequences. And again,
this is not only about crowning a worker. It's beyond what we are talking about, this particular
example. So I think we really have to do something about it. So when it comes to the theory,
I don't think there are any new ideas, no radical definition of life. They themselves
suggest and say that their definition is very simple. And as I have shown, and everybody
had can see just by googling LGC 77, that's exactly the definition of assembly theory.
Their measure is a compression algorithm and not a good one. It's beyond my comprehension
how they can defend that it is not a compression algorithm. I can understand why they don't like
the idea to be regarded as a compression algorithm, because then everything else collapses much easier.
They are taking ideas from other areas that they don't recognize as such if they credit them
for anything is actually for being wrong and not for basically contributing to what they are saying.
They don't cite anyone who is not their friends, unfortunately. So my whole work after 15 years
using very similar measures, almost with the same name, because as I said, it is block the
composition method. But doing more interesting things, but with very similar applications
actually, they don't cite it. We actually published almost five years before them,
results exactly in the same area. So this is a paper that we published in 2018,
and we show that if you take chemical compounds, and actually we took all of them from a repository,
so orders of magnitude, what they took in their own research, because they used first
100 compounds. And so that's the order of magnitude of the compounds they looked at
in their own paper. And we looked at 15,000, more than 15,000 elements and compounds.
And when we tried to, for example, separate acids and alcohols, we couldn't. But when we
wanted to separate organic and inorganic, we were able to do so with nomenclature and with
distance matrices, molecular distance matrices, both together or separately. So in other words,
it is very easy to separate these categories. We published this way before assembly theory,
we didn't make any grandiose claim, and it is out there for people to check out. And I think
Ronin is very well aware of this one, and they just don't say anything. Let me show you one of the
proper, perhaps the last slide. I think science communicators have a very hard time to distinguish
or seeing behind titles and unfounded claims. They would take it at face value.
The same for some researchers or colleagues from other areas, as I said. And those science
communicators may be able to refute unsophisticated charlatans, like Lat-Erders and so on. But they
wouldn't be able to call out sophisticated receivers. Fake rigor, for example. People taking
selecting parts of science that make sense, sometimes following the scientific method to
look credible, but then not following it when they feel threatened by the results. Part of fake
rigor in the entropy paper of assembly theory, for example, they provide a proof of the computability
of assembly or the assembly index as a way to prove the advantage that it has against
the Kolmogorov complexity that, as I said, is semi-computable. Which, by the way, is irrelevant
because, again, there are computable approximations to Kolmogorov complexity of which assembly theory
is one. But anyway, let's take that example. They provide a mathematical proof of computability
of this index, which is simpler than Shannon entropy, and nobody would have doubt that Shannon
entropy is completely computable. Computable means that if you run it on a computer for any input,
you are going to get a result. Uncomputable means that, basically, if you run your computer program,
there's a chance that it may not produce the result because it keeps computing it at infinitum.
That's the problem with uncomputability, and that's why you have to come up with resource-bounded
measures. That means that, basically, you restrict the area of application of your measure, you restrict
the memory, or you restrict the time, and that means that the result is going to always come back,
and it may not be the actual value, but it is an approximation, and that's what assembly theory is.
But when you have something like assembly theory that is so simple that I couldn't come up with a
better example to try to convey this, but it is the equivalent of proving Pythagoras theorem
that applies to all triangles for yellow triangles only. So, really, I don't know if this is the
result of ignorance or deception, but when I tell my colleagues about this, they literally laugh,
and I'm not trying to be mean to them, but it is really just incredible how these papers went
through any peer review with actual experts. And the problem, I think, is that many colleagues and
researchers in other areas and science communicators are not able to see behind the trees. As you do,
for example, I'm sure that you see behind the trees of the origin of life research where you
don't take titles of papers at face value, and actually, as you say, what all these papers are
actually saying is how difficult it is to find the conditions to push all these molecules to actually
look anything closer to life. So, all the literature is actually telling you the opposite. Even when
every one of the articles is saying something positive, when you take them all together, it's
the opposite of positive, because it is not a model. What you need is a model that is very likely,
like in gravitation, for example. In gravitation, you don't say, oh, planets have to be pushed in
this particular situation, and if they deviate, you bring them back in some way or another. They
apply everywhere, and actually, they can explain more phenomena that any other theory before could
explain. So, they are truly unifying models that don't require special situations, and all the origin
of life research requires a lot of very special situations. Maybe it is because we haven't found
the right assumptions, those special situations, but in both cases, it means that we haven't hit
really the right model, or we still know very little, even when there has been some progress. So,
I'm dividing progress here into levels. Very low progress, that we have these articles showing
that in special conditions, pushing things together with 10 people trying to move molecules,
they may have a chance to produce something close, not even life, but then when you took
everything together as a domain expert saying behind the trees, you actually see that it is the
opposite. Yes, yes, and this is what happens in science. So, what I'm suggesting is we need a
whole lot more basic science discoveries in chemical synthesis to be able to solve these
issues, and we're really not that good at it. To speak to any synthetic chemist, when we want to
make a new compound, make a new, just a particular carbon-carbon bond, we have to try 20 different
conditions in order to find something before we get, say, 80% yield. We can't just dial in,
and so I say we need a lot more basic discoveries. So, I predict that leachron in a synthetic
chemist will not discuss anything tonight about chemical reactions leading to life's origin.
I predict leachronin will remain silent on polypeptides, polynucleotides, polysaccharides,
these three key polymers that build us and sell assembly, resorting to calling those
narrow questions and not worth even addressing. Most importantly, with you, the audience, leave
tonight understanding anything more about life's origin based on what Professor Cronin says.
You know, in that debate, I predicted that Lee would not talk about any of the molecular
structures, any of the polypeptides, any of the items that I said are going to be critical,
the things that we're going to need to address this. He would avoid it, and that's what he did.
But he got into assembly theory and talked of that, spoke of that as if that would somehow
help us to explain how life might begin to come about because the topic of the discussion
was the origin of life. And so one would presuppose that the assembly theory is going
to help us with that. And I don't know that I certainly was not equipped to do battle with it
except the fact that say I don't see how that applies to chemistry. What we've had here is we've
had Hector Zaniel, Dr. Hector Zaniel, who is an expert in information, in the packaging of
information, in the describing of different entities, the structures, where Lee is saying his
measures can describe the complexities that have to do with life versus non-life. And what Hector
has shown is these sorts of compression algorithms have been around for 50 and 60 years. And in fact,
the things that are 50 years old often do better than assembly theory. So there really was not a
whole lot of novelty there. I'm glad we could have you, Hector, as an expert to help us to
understand what might be happening here. And I think that the audience sometimes thinks that I
can get a little heavy on the science side. But this is what science demands. It demands a description.
And so what Hector did is he was putting before us a description. And I'm sure he was trying to speak
lightly to us, but still it sounded pretty heavy. But this is the description of what went on.
Just Google eight fallacies of assembly theory. Hector's name will come up, click on that, and
you'll see this. And you'll see 100 pages like this of things that he has written regarding assembly
theory and with links to all of his papers that he has written five years ago and then links to
other papers that have been put out there 50 years ago on these sorts of topics. And do your own
analysis here. And with that, I just want to thank you, Hector. You've given us a lot of your time.
You've given us a lot of your insight. And hopefully this message will come out. Thanks so much.
Thank you very much, Ian, for the invitation. My pleasure.
If you're enjoying this series, give us a thumbs up and click the subscribe button. And that way
you'll hear when we're coming out with new videos. There are no salary to employees in this
organization, all the accounting, all the legal work that's all done by friends of mine. The only
thing that I have to pay for is the production work. And if you could help us out with that,
I'd appreciate it. There's a link below where you can just click on that and help us in several
different ways. Thank you.
