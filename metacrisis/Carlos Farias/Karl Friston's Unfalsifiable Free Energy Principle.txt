You know, you take it as something like the free energy principle, you try to think,
okay, what's even more fundamental than that?
What's behind that?
What's below that?
What kind of feeds into that?
I have to say, also, you won't get more fundamental or simple than the free energy principle.
When you realize that your environment is composed of other things very much like you,
right, when you're young, your mom or as your own or your colleagues and your friends and your
family, I think that's interesting because now we're getting to a much more symmetrical
sort of relationship between me and the environment and certainly in this context,
you know, most of my universe is basically you and me.
So now there's a certain kind of symmetry in play, whereas you are my environment and I am
your environment and yet we both have gelatine models of our environments, which basically means
I have a gelatine model of you and you have a gelatine model of me, but the best way to minimize
surprise when I surprising signal that generated by things like me, namely you, is to ensure that
I was much like you as possible so that I can predict what you're going to do next,
because that's what I was going to do next.
And exactly symmetric is so for you.
So that basically means that we come to share a gelatine model,
a shared narrative we're seeing from the same PIM sheet and everything becomes mutually predictable.
What it doesn't describe though is the going back to your
firelight zone and the man in the nice hell, the epistemic hell.
So if it was the case that we could become completely mutually predictable and just keep
on singing the same song together for hour after hour after hour, that will become boring.
And at this point, I think you're now into sort of social neuroscience and joint free energy
minimization that can sometimes lead to quite paradoxical results or
understandings of the way that we search for information or engage with people.
On the one hand, I want to make my world as predictable as possible, so I don't get any
nasty surprises.
So I'm going to go to those kinds of news channels, I've talked to this kind of person,
because I think that we have a lined frame of reference, we have common grounds,
we speak the same language.
On the other hand, I'm going to be compelled to be slightly curious about other ways of thinking.
It's not, you know, we're not all going to merge into one massive community and we are
one massive hive mind, one massive collective intelligence.
It's not going to work because we are compelled to, you know, what would happen if I looked at it
this way? Or what's that kind of person like? What's this culture like?
So, you know, I haven't got any answers, but there's a really, really interesting
field of information in sort of social neuroscience.
Professor Carl Friston is a world-renowned neuroscientist and researcher.
He is best known for his work in developing groundbreaking statistical methods and mathematical
models to understand the workings of the brain and how it gives rise to complex behaviors.
Our discussion mainly tackles his free energy principle, which states that the brain is
constantly working to minimize the amount of free energy in its system.
According to this principle, the brain is a predictive engine that is constantly trying
to make accurate predictions about the world in order to minimize its own uncertainty.
If you got this far, please subscribe and I hope you enjoy our conversation.
Professor Friston, thank you for coming up.
Thank you for inviting me.
Yes, it is a pleasure. For the folks watching this on YouTube, I just want to say they should
know that you are one of the most cited scientists in the world and have made, you know,
monumental impacts on the field of neuroscience.
So, it is the highest honor, honestly, to be speaking with you today.
And thank you so much for coming on.
It's very gracious for you. Thank you.
Yeah. And, you know, your time is very valuable.
So, I do want to jump right into it.
And as we discussed over email, the primary focus of the conversation
will be on your free energy principle.
So, I think it will be awesome as it is discover.
Let's maybe set the table, so to speak.
Could you provide a high level, sort of simple description of the free energy principle?
And then I have a number of specifics to ask you about it.
Right. So, when confronted with that challenge, I normally say there are two ways you can
know description. So, there's a sort of intuitive low road approach, which I'll describe first.
And then there's the appreciation of the principle from them through the lens of a
physicist to understand self-organization.
But from the point of view of a psychologist or a neuroscientist, we're talking about a very
longstanding way of formulating our capacity to make sense of our world in terms of being able
to predict. So, these ideas go all the way back to Plato and probably Kantian in nature,
but probably best articulated by Helmholtz in the 19th century.
In the sense that perception is a constructive act.
It is, in the words of people like Richard Gregory, it is the brain actively constructing
explanations, hypotheses, fantasies for what might have caused my sensations.
So, this is very much, as Andy Clark would say, an inside-out process that you're creating a fantasy,
an explanation for what I would have seen if this was the right explanation.
And then you're using the actual sensations to correct, update, revise your internal hypothesis,
your internal fantasies. On that view, you could regard the brain as literally a fantastic organ.
It's a purveyor of fantasies that are trying to make sense of the lived world, or at least the
sensed world. And if you cast that in terms of inference mathematically, abductive reasoning,
and write down the rules that would have to obtain if we were in the game of inferring the
causes of our sensations, then you get to a formalism that can be described in terms of
optimizing a quantity called variational free energy. And this quantity is quite ubiquitous in
statistics and machine learning, also known as an evidence lower bound. And it simply scores the
surprise that is inherent in any sensory evidence or any sensation. And we use that surprise, if you
like, to revise our beliefs. And that mathematically can be written down as minimizing free energy.
So all that you can think of in terms of what constitutes a good brain, and possibly a good
mind, can thereby be described as trying to minimize free energy or minimizing surprise.
You can understand that in terms of the average surprise, which would be uncertainty.
So all of this is really saying, it's a mathematical statement, that self organizing
sentient system, look as if they are trying to minimize uncertainty, trying to find the most
the best guess, if you like, the best hypothesis for the causes of their sensation.
You can understand this in a very generalized sense. You don't have to think of it in terms
of sentience, you could understand this is just a kind of homeostasis.
Both your body and my body is in the same game of trying to minimize surprising deviations from
states of being. And we do so, certainly at the level of physiology, by trying to keep ourselves
within prior ranges of states, a temperature or blood sugar and the like, that would be very
surprising if we found ourselves outside those regimes under very, very cold or
in some kind of physical extremists. So that would be, if you like, a sort of biological
perspective of the energy, the physicist would come along and say, okay, there are certain,
or possibly quite remarkable systems in my universe that seem to restrict themselves to
certain characteristic states of being. They have a peculiar capacity to resist
the second law of thermodynamics, which I should say just applies to some closed systems, but
I think it's a useful concept here in relation to this notion of homeostasis.
So what characteristics must these systems possess in order to keep themselves within
characteristic states, technically, mathematically, of course, a pullback attractor,
is it just states of being that look as if they're attracting certain systems so that
they gather themselves up and keep themselves within these characteristic states. And it turns
out if you write down the equations for the dynamics of these kinds of systems, then you can
explain or you can describe these in terms of a variational principle of least action that just
says you're always trying to flow down gradients established by these surprises, these prediction
errors that's quantified by the free energy. And that's a really nice, or that has a very nice
interpretation. Because mathematically, this surprise is the negative of what statisticians
would call log evidence. It is a quantity that measures the goodness of your model,
of the negative of this goodness of your model, which is simply the probability of my sensations
given a model of how I think those sensations were generated. So this is exactly the same kind
of generative model you'd find in generative AI or say large language models and the like.
So that sort of gives you a theological gloss on this free energy minimizing process.
There's just a way of describing self-organizing systems that have this particular capacity
to organize themselves and resist this entropic dissipation on dissolution, decay and death.
And you can describe this as effectively looking as if they're trying to maximize the evidence
for their models of the world. So this can either be read as basically gathering evidence from my
own existence if I am a model of my lived world, also in philosophy by nicely denoted
self-evidencing. So it's a special kind of self-organization that can be read
as self-evidencing in the sense of gathering evidence from the way I think my world works
and how I operate within that world. So those would be two sort of perspectives on the same
phenomenon. Yeah, it's wonderful. Thank you. That's a great summation. And we're going to dive
into this and we're going to slice this up in many different ways. But one thing that I haven't
heard and I've listened to many of your podcast interviews and watched some of your presentations
and read your papers. What I haven't heard yet is what is the origin story of the free energy
principle? How did this all come together for you? I know you have a long history in the field,
but was there an aha moment or a eureka moment at some point? When did this kind of all start to
come together? What was the origin of this idea? Well, I think the first thing to say
in response to that question is that this idea has been around for, if not millennia, certainly centuries
and has been increasingly formalized and simplified. So there could be many starting
points to this story and each will have their precedent. So this is a legacy and a legacy of
what? Well, you could argue it's a legacy of ideas proposed by Helmholtz and refined by psychologists
like Richard Gregory, notions of analysis by synthesis and all sorts of the brain as a
constructive organ, statistical organ and trying to make sense of its world that you'll find in
the 20th century. Ideas which were taken up to great effect in machine learning by people like
Jeffrey Hinton and Peter Diane, they actually invented a Helmholtz machine that had this sort of
this Bayesian mechanics under the hood, borrowing from another legacy left by Richard Feynman,
which was the technical, resolving the technical differences of doing this kind of
this kind of inference, hence the variation of free energy that he brought to the table
in the context of quantum electrodynamics. Personally, it all started to make a lot more
sense when reading the work of people like Raj Rao and Dana Ballard. That story was a
predictive coding story, but it transpired that this was just another way of telling the same
story, but you are using a slightly different rhetoric. So the prediction errors in predictive
coding just are a measure of free energy under certain simplifying assumptions. But the key insight
in the late 90s was that exactly the same objective function could be used to describe
both perception in the spirit of predictive processing as championed by people like Andy
Clark and predictive coding, but also the learning, the updates to connection strengths
of the kind that you'd find in machine learning, but also you find natural intelligence and
experience dependency in the brain. The thing that I found particularly intriguing was that
if you just stood back and I repeat, so looked at this through the lens of a physicist,
you could also explain all of action through minimizing exactly the same quantity.
So bit by bit, everything that needed to be explained sort of fell into the camp of
it's just minimizing free energy. And everywhere you looked, everything could suddenly be very
simply explained in terms of minimizing free energy, attention, and even in the past few years,
your natural selection is just another free energy minimizing process. So this is,
I haven't really answered your question in this period which we've asked because
there was no one moment. But every few years, I certainly get a nice aha, oh, it's just another
instance of minimizing free energy. And then you write a paper usually using numerical simulations
with a bit of analysis to say, well, this is another way of looking at it. And it looks very
much like this kind of thing. Because it's all, if you like, a reflection of the same fundamental
process of self-organization. Can you give us a sense of, I guess, the scope of this discovery?
So as far as I understand it, it explains, you know, process of dynamic happening in the brain,
which is the most complex object that we know of in the universe. What is the simplest scale?
What is the smallest, say, dynamic or thing that would adhere to this principle? Does that make
sense? Like, basically, what is this principle start? Yeah. Yeah, no, I just wanted to interrupt
to congratulate you on the question because that's the second focus of many colleagues
in vertical biology and physics. So I'm thinking here, people like Mike Levin and Chris Fields
and Jim Glazebrook. So that is, that's absolutely key, I think, that notion. It does this apply
to a particular thing? Or does it apply to everything? And if it applies to everything,
what scale does it apply? And does it apply at every scale? And the answer should be,
it's scale invariant, and it applies to everything, literally. And that sort of
perspective is being championed, I repeat, by my colleagues, Mike, Jim, and Chris,
in the context of quantum information theory, on the one side, on the point of view of physics.
But on the other side, there's this story, which I think is very nicely articulated by Chris Fields,
it is time to remove the bright lines between physics, biology and psychology. They're all
just the same thing. And you get this notion of basal cognition, which is something I think Mike
Levin has brought to the table, that all self-organization can be read as this kind of basic
sentence, this sort of basal cognition, that is just a reflection of the existence of things.
And this may sound a little bit like an overstatement, but the interpretation
of self-organization, in terms of the interpretation of self-organization as self-evident thing,
is a relatively straightforward consequence of the individuation of anything from the rest
of the universe. And this separation appeals to what is now a little literature on Markov
Blankets, in this particular context. So the Markov Blanket is just a definition of
thingness, where you start with the notion, okay, I want to explain the states of something.
And then you ask, well, what's a thing? Now, maybe you have to appeal to
scrolling and formulation of boundaries. Can you explain what goes on within the boundaries
of living things? And of course, as soon as you say that, you realize it's the boundary that's
the important structure that allows you to individuate something from everything else or no thing.
And indeed, if you just then look back with that view on what you learned at school,
in terms of physics, you suddenly realize how important that boundary is,
let's say the heat path in physics, for example. So wherever you look, there's this crucial notion
of a separation, an individuation, and simply by thinking carefully and articulating formally
how you would define that boundary. There is, if you like, a partial separation from
states on the inside of something and states on the outside of something.
But there's a two-way traffic across this blanket or this boundary, this Markov boundary.
And this two-way traffic enables you now to describe the internal dynamics or dynamics on the
inside as holding beliefs about probabilistic subpersonal beliefs about the outside. And it is
that that enables you then to assign this free energy functional to belief structures in the brain.
And you can do this for anything. You can do this for a droplet of oil. You can do it for a virus.
You can do it for a person. You can do it. In fact, I've just signed off on a wonderful paper
by my colleagues, Saugir and Lanceter Costa, where they've actually applied it to the biosphere.
So the same maths unfolds. Once you've identified the separation of something from anything else,
you just apply this mechanics as Bayesian mechanics. And then you can interpret the
self-organisation in terms of sense-making and self-evidencing and an implicit or a description
of that sense-making in terms of belief updating by minimising this surprise or maximising this
Bayesian model evidence. So it can be applied to single cells or it can be applied to the biosphere.
So it should apply to everything. And Saugir, that's what Chris Fields would say,
at what level of analysis then it comes to quantum information theoretic applications of the emission.
Yeah, that's fascinating. I'm familiar with Chris Fields' work. I've read some of his research
and actually spoke with Michael Levin a few weeks ago. I interviewed him. Yeah, we actually covered,
I mean, in great detail, one of his papers, I think it was 2019 paper called the Computational
Boundary of the Self. I don't know if you happen to see that, but he has this visual cognitive
light cones, sort of the boundary, the assumed boundary of nested cells, let's say, all going
all the way down to the cell. Say the cell, then you have ants, then ant colony, and it sort of,
he brings up just fascinating ideas around collective intelligence. All intelligence is
being collective and stuff like that. So yeah, a little bit, those things I'm quite a little
bit familiar with. So it's great that you could call them out. Can you define, one thing would be
great to get some definitions down. Can you define free energy? So I believe in a thermodynamic sense,
it's the amount of available energy for a system to do work, because a simpler, perhaps one of the
simpler definitions for it, is that applied in the same way in your free energy principle?
Yeah, again, an excellent question. Yes and no. So the functional form of the variational free energy,
and that's why I tend to say the variational free energy, so that we do not misinterpret it as a
thermodynamic free energy. The functional forms are identical, and they inherit from the same kind
of physics and probability institute dynamics. However, thermodynamic free energy is, I think,
a very particular application of this kind of mechanics to certain systems. So it is, you know,
I think, from the point of view of, you know, so somebody is not a physicist, I think it's
important to say that the variational free energy is an information theoretic measure. It has no
commitments to joules or Boltzmann's constants or anything of that nature. So it's very much like
a statistical measure, like you're a variance or an average or an entropy. So the free energy has
a free energy is just defined effectively in terms of a relative entropy, or sometimes known as a
KL divergence, and a constraint or an internal energy. So the variational free energy is talking
about probability distributions, it's talking about information, and crucially it's talking about
information about things. And then we come back to the central foundations of the Markov blanket,
and separating the inside from the outside. So the whole point of the free energy principle
is that you can interpret the inside states as holding information or probabilistic beliefs
about outside states. So this is, if you like, something quite fundamentally different from
Shannon information on the surprise of finding the brain in this state. So the brain will have
two kinds of free energy, it'll have a variational free energy, which is a comment about its goodness
of fit or its beliefs about what's going on outside, which a statistician would understand,
but it will also have a dynamic free energy in terms of the actual metabolism and electrochemical
signalling, and the metabolic states of the world that requires a further commitment to, I repeat,
sort of interpreting certain quantities, you know, for the amplitude of random fluctuations in terms
of thermal constructs, and applying things like Boltzmann's constant to it. So there is a difference,
you know, between the two. Having said that, I think that difference is specious on two counts.
First of all, you know, taking again a Feynman-esque point of view, information is energy and energy
is information. And at the level of analysis that we're talking about, you know, a thermodynamic
interpretation is just another interpretation. You don't need to start self-organization
if you wanted to talk to a sort of business system, the 19th or 20th century will be useful,
but it's not necessary. Another, the other point is if you did talk to that kind of thermodynamic
person, then you would find that there is a, that these free energies share the same minimum.
There is a necessary thermodynamic cost to any variational free energy minimization or
belief updating by things like that was principle. So there is a physics which really binds these
two things together. The final point of contact, or perhaps the final, you know, some of your
more technical viewers, the free energy principle that we're talking about can be
regarded as dual to James's maximum entropy principle. So James's maximum entropy principle
basically says that the universe or anything in the game of measuring anything else
will conform to the principle of a maximum entropy and the constraints. And those constraints
are what are supplied by the generative model that generates the predictions that are necessary to
provide the surprise. So the surprise part, the internal energy part of the free energy principle
is that which rests upon or is defined in terms of our world models, our generative models.
So we come back to this notion of what is a free energy? Well, it's an internal energy
minus an entropy. So where you want to minimize your free energy, you're going to maximize your
entropy in a chord which changes its maximum entropy principle, but under constraints that
you're trying to minimize the internal energy. And that internal energy just is a surprise that
we were talking about before. So on that view, I think there's a deep connection between
a certain kind of free energy in physics, but it would have to be a Jamesian kind of free energy.
What is the kind of free energy you did at school when you boiled in water, like?
Sure, yes. Okay, it's so interesting. And actually, you bring up William James' maximum entropy
principle, something that I learned about listening to one of your lectures, because I believe you
said, I think it's a quote, if I have no preferences at all, then my best bet is to keep options open.
So it's a bit of, so that's like the non-technical kind of layman's way to look at it,
which I hadn't thought of before. And I was actually thinking, and it's one of the questions that I
have for you, and it's something that I think is really interesting about this principle is that,
please correct me if I'm wrong or fill in here, the preferences are built into the
Bayesian beliefs. Is that correct? Yes, you've immediately gone into a much more glorious world
of preferences and purpose and plan of intentions. Yeah, I'm sorry, we can go there later if you
want, because it's a great place to be. But just at the moment, we've just been talking about
self-organization, self-evidencing, but what you've done is really speak to the active part of this.
So you're just to set the scene. When you look at certain kinds of systems, and specifically
systems that have very precise internal dynamics, so the random fluctuations are suppressed, or at
least at the scale of observation that you might want to apply, that all the random fluctuations
are averaged away. But these kinds of systems, basically systems like you and me, but not
systems that are very, very small and very, very hot thermodynamically, that would have
lots of random fluctuations. But if you get a big enough system like you and me,
then it is the case that the solution or the variational principles that have to be in play
in order for this separation to persist, separation of self from non-self to be in play,
and you apply it to the way that you act upon the world, then you can describe this in terms of
minimizing the free energy that you would expect if you pursued this course of action.
It's at that point, I think you get notions of preferences and how you could interpret
this expected surprise. Very much as we said before, the one way of reading expected surprise
just is in terms of entropy. But there's another way of avoiding surprises, which is just to avoid
surprising outcomes, which means complying with the constraints that were implicit in
James's constraint maximum principle. The complement of avoiding surprising outcomes
is that it looks as if I am always acting in a way that convinces preferred outcomes,
outcomes that just are the characteristic states that define the kind of states that you'd find
the inner. I think you're absolutely right that these prior preferences are just a way of articulating
the typical or characteristic states that define who I am. You can either put a teleology on that
and say, oh, this thing is behaving as if it prefers to be in these states. It's actively
choosing these causes of action, these paths into the future. The result that those consequences
are that you end up in your preferred states. On the physicist's point of view,
you start off with a system that seems to be able to occupy these preferred characteristic states
and then you work out what dynamics must these systems have. That's the deflation part of the
free energy principle. It's just a description of things that have preferred states effectively,
and these preferred states are literally the attracting set that constitutes the pullback
attractor that was mentioned before. You're absolutely right in one sense that these
preferences are part of Bayesian beliefs, but that does, if you like, commit you to a
rather teleological interpretation of the energy principle. You don't have to do that.
You can't do that. You don't have to do that. Please forgive my ignorance here, because I might
shrug my hand a little bit here, but is the brain trying to minimize free energy
because it's trying to use as much of it as possible? I know it's trying to minimize surprise
uncertainty, but I imagine something like a resourceful, greedy brain. Is the minimization
of free energy sort of like the byproduct? Is this a downstream effect, or is it the real pump
that's moving the water along? Does that make sense? It makes sense. In a sense, it's exactly the
question which I try to intimate. There are two completely contradictory answers to, so if you're
talking to a physicist, I know there's no sort of pump here. There's no aspirations to deploy my
free energy in the most efficient way. It's just that's what systems do. Systems just settle down
to a free energy minimum. That's another way. Those systems that settle down to an attractor
set them to their free energy minimum, that is their definitional attribute, the stipulation,
that is what things are. So it is no surprise that when you describe their dynamics, they'll
look as if they're trying to minimize their free energy, because that's what defines them.
But if you now talk to a biologist or a psychologist, then your description is perfectly
out. It will look as if these systems, particularly systems like you and me,
are actively trying to minimize a surprise in a resourceful way. I would actually frame that more
in terms of in a very efficient way. So if you go to Wikipedia and you say, well, free energy is
the amount of energy available to do work, I mean, that's a thermodynamic interpretation.
I don't think it's quite necessary to put that out of all the size things in quite a
but it certainly, I think, would be
you would be perfectly licensed just to interpret various parts or decompose
variation of free energy. And as for what would it look like if we just focused on this particular
part or that particular part? I think one really interesting decomposition of
variation of free energy is that which a statistician would usually appeal to. And that's
basically accuracy minus complexity, where accuracy is effectively how accurate your
predictions of the world are, how good is your explanation of these sensory data, or if you're
a statistician, sort of your empirical data that they're trying to make sense of.
The other thing, the complexity, I think, is even more interesting. So in the same way you were
talking about before, keeping your options open and maximizing your entropy in accord with James's
maximum entropy principle, the same sort of Occam's like principle emerges in terms of this
complexity term. So the complexity is just a way of lumping together part of the internal energy
with the entropy to give you this relative entropy or this KL divergence. And then to put
this very simply, what it measures is effectively the degree to which some sensory data or some
sensations or some sensory evidence changes your mind. So if you're trying to describe this as a
statistician, this is the degree to which you move from your state of privilies to your state of
posterior beliefs. So it's degrees of freedom you're using up in terms of providing an accurate
account of your data. And it is this that is minimized. Remember, free energy equals accuracy
minus complexity. So, well, actually it's going to be around negative free energy is equal to
accuracy minus complexity. So as you're minimizing the free energy, you're also, you're trying to
maximize the accuracy, but at the same time you minimize the complexity. So this is where
I think you get what you're alluding to. You're trying to accurately navigate the world
in the most efficient way possible using up the least resources. But why do I say resource as well?
Because of this link between the information and energy, you're afforded by things like
the Jinsky equality and the Handao's principle. It costs energy to change your mind. It costs energy
to create and well, to destroy information. So that complexity is also a cost. Technically,
it's also an information game, but it's also a complexity cost. So what it looks as if
a brain of this kind would be in the game of updating itself, changing its biophysical
state in a way to make predictions that are as accurate as possible, whilst at the same time
complying with complexity constraints. So do it in the most parsimonious way that it can. So hence
Occam's principle. So that would also translate into the most energetically efficient way of
making sense of the world. And if you sort of unpack that principle in terms of computation
in silico, then what that tells you is that the good computers are those computers that work on
the edge very cheaply with small amounts of electricity. They're doing it very in the simplest
way possible with a cool head, literally. So these are really interpretations of, if you like,
unpacking the terms that go into a variational free energy and making sense of them. And I think
that's exactly what should be done. It's a wonderful game. And you could also repeat that
game in terms of the expected free energy. So now you have expected accuracy and expected complexity.
And when you look at the functional forms of these terms, you suddenly see things that people have
been dealing with and optimizing for nearly a century. So for example, the expected accuracy
or the negative expected accuracy is just the ambiguity or the negative precision
that would be used to explain an efficient sampling of the world of the kind that you might find in
the visual cortex and the organization of the visual brain. The expected complexity becomes risk
of the kind you'd find in economics. It is basically the distance I move from my prior beliefs
if I pursued this course of action. And of course, we've just said that the prior beliefs
about the consequences of action are our preferences. They describe our attracting
set of preferred states. So now the expected complexity, the risk, is just scoring the degree
to which I expect to be displaced from my third states of being probabilistically speaking.
We just measure that with the KL divergence on the relative entropy. So that's, you know, that's
bread and butter for many economists. Another way of, if you're like unpacking or rearranging the
terms is in terms of what is referred to as expected information gain and expected cost. So
those two components are exactly those things that you find in the two aspects of being base
optimal. So there are two ways of being base optimal. One way is to minimize your expected cost
or maximize your expected utility or valuable log preferences. And that's the kind of base
option you'd find in Bayesian decision theory. And you can look at that as grandfathering things
like reinforcement learning and utility theory. On the other hand, though, you've got this sort of
again, this sort of, it's not ambiguity, it's ambiguity with bells on, which is the expected
information gain. And that was exactly the objective function devised at the inception
of the principles of optimum Bayesian design. So if you have the problem of designing an experiment
that's going to yield some data, and you now ask yourself the question, what's the best kind of
experiment I could possibly design that will give me the kind of information that's going to resolve
the most uncertainty about hypothesis? What's going to maximize the expected information gain?
And it is exactly that quantity, that part, that epistemic value, this measure of the resolution
of uncertainty that defines Bayes' optimality in the context of experimental design.
That may seem a little bit sort of unconnected to you and me in conversation or just walking down
the road. But of course, we are experiment, we are actively experimenting all the time,
just by looking around. The way that we move our eyes, the category every 250 milliseconds,
every little act of this kind is an experiment. So we come back now to the notion of Richard
Gregory, that perception just is hypothesis testing. What's the experimentation? It's just
palpating the world in the right kind of way to get that kind of information that's going to resolve
the most expected surprise or the most uncertainty. And you can have that at the level of
visual palpation every four times a second, or the news channels that you would afford epistemic
trust, which is probably quite a hot issue. Or the kind of, whether you've got a Wikipedia,
who would you consult? We make choices all the time in terms of what's the best way to act,
and what are the, what this notion of expected free energy brings to the table is that there are
the imperatives of a dual aspect, this pragmatic aspect that is formally this expected cost,
where the cost of the negative or the surprise in relation to my preferred states of being.
But also, to my mind, even more important is this epistemic part, this sort of expected
information gain that actually makes us all little scientists of one sort or another.
Yeah, that's incredible. I'm glad I'm recording this conversation, because I'm going to have to
listen to that a few times over to fully pull together all the pieces, because there's so much
there. I actually found this when I was doing research on the free energy principle that I was
going off and finding definitions for things, because to bring it all together is, well,
it's amazing that it incorporates so many different ideas from different disciplines.
I mean, you have your neuroscience, but you also have information theory. I mean, it's
physics, you know, you have all these different things that you're pulling together
and finding these deep truths that I think are fascinating.
Well, it's nice you said that, because that's exactly what Chris Fields wants. He wants to
sort of physics, psychology, biology, they're all the same thing. And again, you know,
when I was trying to answer your question, when was the harm moment? There really wasn't one, but
every few months you say, oh, that's just one of those. So to my mind, in a sense,
it is that capacity to accommodate very gracefully things that definitely have worked in the past,
that haven't been framed in this sort of simplifying, sort of unifying framework. It's that
capacity which lends the free energy principle of a veracity and a utility that you continually
impresses me, that when you were able to articulate something that's endured for
centuries or at least decades, that we all use in work, and that in terms of our understanding,
and suddenly fits in with the free energy principle, that to my mind is a reflection
of the utility of the free energy principle, but also interestingly, it means that the free
energy principle is conforming to itself. So if you remember, the whole point of the free energy
principle is finding accurate explanations as simple as possible. So it should provide a simple
explanation for everything. That's its foundational premise. So you shouldn't really be surprised
that you can do economics and move forward with learning. Yeah, one of your my favorite papers
is yours. I think it's the free energy principle made as simple as possible, but no simpler,
I think is the title, or it's close. I'll link to that in the description for folks who want to
read that. I may have butchered that title, sorry, but it's close.
It was Einstein's famous quote. Yes, it's from Einstein, yeah.
I even found that I didn't know this, but there's a great little article in Wikipedia called
the principle of simplicity. So there's actually people like Nick Chaitre and colleagues
have found this formalization of what comes principle. I think the free energy principle
could also be read as a dual to that kind of imperative to find the simple minimally complex
explanations for stuff. So I'd love to, I'll just focus somewhere in time on surprise,
the idea of surprise. It's central to this theory. And correct me if I'm wrong. So we're
trying to minimize surprise or slash uncertainty, right? Does the system want
zero surprise, precisely zero surprise? Or that might be, I imagine that might be impossible,
actually. So is it trying to approach zero? Is that optimally, is that better? Does that make
sense? It does, but again, you're, you're, you're asking as a, as a biologist, not a physicist.
I'll keep mixing that too, sorry.
But there is a lovely paradox here. The notice we've been saying in the past exchange that we are
compelled if we exist as certain kinds of things that have these very precise internal dynamics
to maximize information gain. So we are compelled to seek out novel novelty. We are compelled to
seek out surprising informative, informative outcomes, which needs to be contrasted with
what you've just brought to the table, which is the underlying, the underlying imperative really
is that of homeostasis to minimize surprise. So you've got this interesting dialectic here,
which just falls out of the maths, that in the service of trying to minimize my surprise to
maintain my homeostatic to keep myself within these, within these attracting sets that have a
low entropy. Remember that the entropy is just the average surprise. So if I spend my life minimizing
surprise, I am by definition, when averaged over time, minimizing my entropy, this minimizing
that's the other number of surprising physiological and mental and emotional states that I experience
during that period of time. But to do that, I have to actually go and minimize, maximize my
expensive information gain. So I'm going to look as if I'm actually very curious. So part of keeping
my home, keeping myself out of unfulfilled states and minimizing surprise, which you can
read as like this prediction error, for example, part of underwriting my capacity to minimize my
prediction error is actually to go and seek out surprising or apparently surprising outcomes.
So I will, I will be quintessentially curious, I will be sensation seeking,
I will be wanting to answer, it'll look as if I'm going to want to answer the question,
what would happen if I did that? So it is, you know, when you say we all want to minimize surprise,
we certainly want to avoid surprising sensations. Yes, you know, no deception underwrites our,
you know, beliefs about being in pain, for example, being very cold, being very poor,
being very unloved, being dead. You know, these are all very surprising states of being,
which we will in the moment avoid. But that does not mean to say that we will not seek out
those outcomes that can have, have information. So we're still very, very curious. And I say that
at length, because there was an interesting philosophical paradox called the dark room
paradox that was brought to the table around the inception of the free energy principle
in neurophilosophy. And it went along the following, well, perhaps you know this,
you probably know this better than I do, do you want to tell, tell your viewers what it was?
No, I wish I did, I'm sorry, I don't know about it.
It's a very commonsensical argument, but if it's the case, you want to minimize surprise,
why don't you just go into a dark room, turn off the lights, lie down, stay there forever.
Okay, that's kind of an idea, question ahead, why not just jump off a cliff, right? That's,
you'll know, the surprise will be over and then that'll, yeah, for extreme, but.
Yes, it's interesting that. So why don't we do that? And yet we go bungee jumping.
This is interesting. Yeah, let's go. Jumping off cliffs and bungee jumping are, you know,
they should be explainable under the free energy principle. And of course there's a crucial,
there's a crucial difference between the bungee jump and the jumping over a cliff.
But to come out to the dark room problem, I repeat, it's just the paradox that why don't surprise
minimizing machines or artifacts or systems basically sequester themselves from their environment
and close their eyes or turn the lights off and remove themselves from any particularly
surprising sensations. And the answer to that, well, there are a number of different answers
depending upon how seriously you take the question. Well, less serious answer is, well,
that's exactly what I do every day when I go to bed. So it's not quite that surprising.
Interesting. Yeah, that's a good counter. Yeah.
But, you know, ignoring the fact that we do need some downtime. And there are good reasons for
that, which come back to this separation of free energy into accuracy and complexity.
But more importantly, the first thing I do when I go into a dark room, imagine, you know,
you're at a conference and you go back to your hotel room and the lights don't work in your hotel
room because you can't find the switch. So, you know, what tells you first of all, the first thing
you do, you and I would do as free energy minimising creatures in the future, minimising the expected
free energy, maximising my expected information gain, it's a turn on the light. That's the first
thing that any free energy minimising system would do. And the second thing that that little
analogy tells you is that if you can't find the light, you just kind of feel your way around.
So, again, this is exploration, this curiosity that is coming to the imperative to resolve uncertainty.
Remembering that uncertainty is average surprise. So, in resolving uncertainty, you are minimising
your expected surprise. But this is about outcomes in the future that are not yet witnessed. So,
again, when you talk about things I do, then you are now talking about the imperatives that
underlie action upon the world and the consequences that live in the future. And in those instances,
it's all about minimising uncertainty. When you're talking about things, you know,
my states of being, surprise, it's just a measure of my state of being, it's just a likelihood of
these sensations given my model, my predictions of the sensations at this point in time. So,
they're fundamentally different ways of using the notion of surprise. I hope that makes sense. It's
probably a little bit over answered. I've over shared. No, no, it's great. That was useful. I mean,
it is something that I think that's why I wanted to remain at this, on this topic, on this level,
because it is, I think, the area where I still still have the hardest time
intuiting the difference between information gain and minimising surprise. Those two things,
they seem counter, or they seem like, you know, you can't have both, right? But I think it's
partly perhaps a problem of language in terms of like assigning a positive or negative valence
to the term surprise. So, something like, like an example, so I was thinking about this the other
day, if you won the lottery, if you had a winning lottery ticket, right, you won $100 million,
that's extremely surprising, and also very good, right? But it seemed to be counter to
minimising surprise, right? So, but I think it's a difference of scale, perhaps, like,
it's like the difference between perhaps the overall model and a particular event within
that model, you know, you know, perhaps using that example, could you possibly help
help me into it, sort of the difference in where, or these tensions kind of resolve?
Well, I think you've identified, well actually, it's a wonderful, let's talk about winning the
lottery, which is very surprising. Yes, I left you some day.
But also, I think just to reiterate what you implicitly just said, that, you know,
the word surprise is applied to many different constructs, sometimes more anthropomorphic and
sometimes less. So, when surprise is used in the context of the free energy principle or
and mathematically, it has a very specific and very deflationary meaning, it's just the
negative log probability of some data given your model of how those data were caused. So,
it's a measure of the implausibility of getting these data given a particular commitment to how
you think these data were generated. So, I repeat, it's probably best thought of as a
prediction error, you know, I've got some outcome, and I had a prediction of that outcome,
and the surprise is just the measure of the mismatch or the distinction, discrepancy between
my prediction and what I actually observed. This is also known as the prival, a l, an information
theory, a term coined by Tribus. More formally, more generically, it's also called self-information.
It's just a negative log probability of an event conditioned upon the model or the context in which
that event occurred. So, I think that's, if I was talking to, you know, students of
physics or information theory, I wouldn't use the word surprise, I'd use self-information because
immediately they know that the expected self-information is entropy of a Shannon sort.
So, when I talk about minimizing self-information, I'm using that as a shorthand that's saying,
I'm trying to describe systems that resist a tendency to dispersion of their states. So,
notice that this is, again, because it can be very confusing, again, this is, if you like,
almost the opposite of James's maximum entropy principle, and there's a reason for that because
what we're talking about here is the entropy, the average self-information or the average surprise
of actual outcomes, of real deterministic variables that constitute technically the
sensory states of my Markov blanket, the way that the world impresses itself upon me.
So, this has nothing to do with beliefs or probability distributions. It's the surprise
afforded this outcome, and I want to, you know, being a good homeostat to you,
cybernetics notion, I'm going to want to make sure that everything that the world impresses
upon me is within the bounds of, you know, that something like me can take, and this is just
a statement basis again. So, that kind of entropy, we're trying to minimize. So, remember before,
we were talking about James's maximum entropy principle, but the entropy was about the beliefs
about the causes. It wasn't about the actual outcomes. So, this is, again, if you like,
a dialectic or a paradox. On the one hand, they're trying to minimize the surprise or the
self-information of my, of the actual outcomes that the world impresses upon me, but when it comes to
the Occam's principle view of free energy minimization, I'm now going to try to maximize
the entropy of my beliefs about the causes of that. So, it is complicated, and perhaps I
won't should apologize for that. It's a little bit, it's a same kind of like dialectic that you get
into if you commit to James's maximum entropy principle as the right way of measuring things
and understanding things. Then you have to say, well, hang on a second. I thought the whole point
of biological self-organization was to resist the natural tendency to an increase in entropy.
I thought the whole point of Schrodinger's formulation of life was to minimize entropy. So,
who's right? Schrodinger or James? Well, they're both right. It's just that the entropy of the
things I talk about are completely different. James and the free energy principle are talking
about the entropy of measurements and beliefs. Schrodinger and homeostasis and syllogetics,
for example, are talking about the entropy of outcomes, of measurements, of the data that you
use to make your inferences and build your beliefs and update your beliefs. So, it's a fascinating
sort of yin and yang, and it really forces you to think about the nature of these mathematical
descriptions and to what they pertain. So, things like entropy and surprise and self-information
are just attributes of probability distributions. So, you have to say, of what? Is it the outcomes
or is it your beliefs about things? And with that sort of in mind, weighing the lottery,
is that surprising? Well, if you imagine the probability of it happening to you being surprising,
I can see that you might think, oh, that's highly implausible. So, it's not. It is very surprising.
On the other hand, if you believe that you are the kind of lucky chap that good things happen to,
which you have to believe in order to actually self-evidence your way, predict your way into
being a happy chap and that good things happen to you, winning a lottery is not that surprising.
That's the kind of thing that happens to people like me. I'm a successful New Yorker.
And I wouldn't be that surprised because that's consistent. It's egocintonic.
Winning the lottery is not going to put me in a truly surprising state that if I had a car accident
or I had a stroke or my partner let me, these are truly surprising things. Winning the lottery
is not surprising because it doesn't take me out of my comfort zone, my attracting center,
my callback attractor. Furthermore, I'm not sure that this example works so well,
in practice, but certainly you can now, if you win the lottery, if you did actually win the lottery,
that actually reduces a lot of surprise in terms of what you're going to do next.
So, that puts you in a certain position with a certain attitude of ways forward and ways of
behaving, which actually resolves uncertainty about whether you're going to be able to pay these
bills, whether you're going to be able to support an elderly relative, whether you're going to be
able to pay for your children to go to college. All of these uncertainties are exactly what
you're trying to actively resolve, but if you're very rich, a lot of those uncertainties resolve
themselves. So, that kind of, if you like, expected surprise, which is all about the surprise that
attends the things that you're going to do, is actually resolved by winning the lottery.
So, winning the lottery is both good of that simple level of analysis. I'm sure if you actually
speak to people that actually won the lottery, you probably get a very different impression,
but at least at this level of analysis, it's both good and surprise minimizing.
That's interesting. Right, it depends on the frame, almost the frame of reference,
which state are you looking at it at. Are you familiar? Just came to mind the other day,
as I was thinking about this principle. Do you ever watch The Twilight Zone?
Yes.
From back in the day, there's an episode called A Nice Place to Visit and Spoiler Alert for anyone
watching, but it's an old show, so if you haven't seen it by now. But basically, in the episode,
a thief, a robber dies and it goes to heaven, and they're a gambler. They like to gamble. So,
in a casino, basically, the way it works is they win every game at the casino. They're playing
craps, they're playing blackjack, and every time they win, right? And the robber is happy. You
know, he's like, oh my god, this is amazing. Everything I play, it's so great. And then,
please stop me if you've seen this episode already, but for folks watching, he's happy at first,
but then it goes a month later and he's sitting at the table and he's bored out of his mind,
right? He's winning every time and he's just like, oh, I won again. Like, oh, why even play, right?
And maybe you think about this, I mean, maybe this is completely off, but in the fact that
there's no more surprise in the games that he's playing, right? So he's lost all of the will,
basically, to go on. And of course, at the end, you find out he's not in heaven, he's in hell,
right? He's got everything that he wanted, but it wasn't the right thing that he wanted,
sort of, you know, the lesson in the story, I guess. But maybe think about this a little bit,
because basically, the surprise is zero. And actually, all the veil, it's only a negative
outcome, really, for him. You know, he hasn't realized that the folly of his actions, you know,
there's no more hypothesis testing happening here. Every time it's the same thing and what a dull life
to live. And maybe think about this a little bit, and please tell me if that's anywhere close to
this idea. I know it's art. I know it's different. It's television, but...
No, I think that's spot on. I hadn't seen that episode. That's a marvelous, marvelous story.
I know you're absolutely right. So this is, you know, not only do you see this in psychology,
but when you start to simulate, you know, little animals minimizing their sanity, you see exactly
this kind of behavior. And as you say, it's just the fact that the expected surprise entails
the motivation to do those things that resolve uncertainty. And if you're denied the opportunity,
because there is no more uncertainty to resolve, there's no more curiosity out there. There's no
more epistemic importance. There's no more expected information gain that you expect because you know
everything. And this keeps happening the same again and again and again and again. That would be awful.
You know, when you actually simulate it, you actually can simulate little artifacts who just
get so bored. They do nothing. And certainly if you have, you know, once they attain their preferred
state, so they're maximized their expected utility or minimized their expected cost,
because there's nothing to shape their behavior, because there's no now reducible uncertainty
out there. There's no more, there's no more epistemic affordance. There's nothing to do.
They just sit there and do absolutely nothing. And that must be an awful situation to be in.
And I say that because, you know, 99% of your life is not chasing, you know, if you are a mouse,
cheese, it's not putting yourself in a position where you're going to win the lottery. It's actually
indulging in your curiosity. The very fact you're doing these podcasts, having this exchange,
is just an expression of the fact you are compelled to be a curious creature. So this
is part of our makeup. And if we didn't do this, then, you know, at least from a mathematical
perspective, it's highly unlikely that we would exist over an appreciable period of time. So,
yes, I hadn't seen that episode, but I love the twist that you end up in.
Yeah, he was a thief, so he deserved it.
So about the, let's see here, I'm trying to figure out where we're going to go.
I believe there's two ways, right, to minimize prediction error.
They were change the model to better fit sensory input, and or change the world,
act on the world in order to better fit the prediction. But I wasn't sure, are these two
mutually exclusive? I mean, do you have to choose between the two? And if so, how does
the system decide which one to do? Right, so we're now at a sort of more elemental
application of the energy principle, just to understand the fundamental, you know,
the fundamental drives to both perception and action, and you face up beautifully. So,
if we now simplify things, and then just read surprise and free energy in the moment
as prediction error, then there are two ways, as you say, that I can minimize my prediction error.
I can either change my mind, so my prediction error has become more like the sensory data at hand,
or I can act upon the world to solicit some more or a different set of sensory input that are
closer to my predictions. So what would that look like? It would look as if I am basically
acting to fulfill my predictions, which is what I meant before, is that if you weren't
optimistic, successful New Yorker, if you didn't have that prior, that optimism, that sort of
optimism bias, then you wouldn't be able to act in a base optimal way, because you need
to fulfill your own predictions to survive. There's something quite fundamental about that,
but at the level I think we're talking, the kind of self-fulfilling purposes we're talking about
are very sub-personal. So all we're talking about, basically, is effectively reflexes. So,
when we move, when we talk or move our eyes, what's happening is that we're sending predictions
down to the Pontine nuclear to the spinal cord about the kind of signals we're getting from
the state of our body. Technically, it's called proprioception. And if I predict that I'm going
to be moving in a particular way, I would expect to get these signals from my muscles.
And if I don't get them, there's a prediction error. So by acting, all I mean or all that one
means in this setting is that you send these prediction errors back to the muscle so that
it contracts to the right length. So it sends the signals that you predicted. So this is just
like a thermostat. It's just like feedback control that we find in many, many devices.
All you need to supply is the set point, the temperature you want or the length of the muscle
you predict will happen. And then the body does the rest. So this is how a very sort of elemental
level of just moving around. You can understand action, motor action, motor being the use of
particular kinds of muscles as minimizing prediction error or minimizing free energy.
So it's not quite this more deliberative kind of action. It's not how do I imagine myself
behaving tomorrow or generally unfolding in this conversation. We're talking about action in the
moment as basically eliminating prediction errors, reflexes very, very, very quickly.
So in answer to your question, how do we decide which to do? And are they
mutually exclusive? They're certainly not mutually exclusive in the sense that the whole point
of this explanation of action and perception and the action perception cycle
is that there is a common theme. It's just all driven by minimizing prediction error
or minimizing free energy in a more general context. However, in practice, I think you're
absolutely right that we do seem to be built to switch between the two. So in principle,
you could do them both at the same time. In principle, you could dynamically adjust your set
points and your reflexes could try to fulfill those set points or those predictions and the
two could go hand in hand contemporaneously. But in fact, in practice, it looks as if there was
actually a turn taking. And it looks as if certainly sort of larger mammals have a very
particular schedule of turn taking. I mean, this may sound very specific, but I think it's really
interesting that it speaks to the cognitive moment. So it looks as if if we just take say vision,
then our vision, certainly active vision, where sometimes it's kind of active sensing,
where we actually have to go and palpate and select little parts of the visual scene,
bearing in mind, we can only actually see a very, very small part of the visual scene
without, you know, with high resolution in our familial representations. So basically,
although we think we can see everything, we're not, we just see little patches and we're knitting
it together in our heads. It's fantasy that I can see everything. That's not true. You could see
something if you looked over there. And that gives you the illusion that you can see everything.
In fact, you can't. So this is part of this sort of debate as a fantastic organ, having a fantasy
you can see all around me. You can't, you have to go and get the most epistemically rich,
maximize the expected information gain, arts of the visual field to knit together and to
accumulate the right kind of information that builds your hypothesis about the scene that
I'm currently constructing in my head. But this process happens very, very quickly. So we move
our eyes about four times a second. Interestingly, well, yeah, he's amazing. But it's also, well,
I've had even more amazing is that everything seems to be about four times a second. And by
everything I made, if you were a mouse, you wouldn't really be using your eyes so much,
you'd be using your whiskers as your burrows in the field. And you whisk about four times a second.
If you are talking, you produce little chunks of information called phonemes about four times
per second. When you're listening, you're listening about four times per second. When you sniff,
you sniff it about four times per second. The way that we sample, the way that we sort of
gather our information from the world, seems to have this very saltatory aspect that you're
roughly at four hertz, technically a theta rhythm. We seem to be going to sample in the
information. But even more interestingly, during the action, during the actual movement itself,
the way that you adjudicate between changing your mind and updating your, allowing your brain to
revise its beliefs by changing its neural activity to provide better predictions.
During movement, you actually attenuate the consequences of that movement to enable you to
act. So this is a really interesting phenomenon called sensory attenuation.
But simply, if I had the prior belief that I was going to lift my arm,
and I didn't ignore or attenuate the prediction errors that were coming from my arm,
telling me my arm is not moving, then I wouldn't be able to lift my arm because those predictors
would come and revise my beliefs. Oh, no, my arm's not moving. But if I can ignore the sensations
that I am going to generate, then I can use my reflexes to fulfill my predictions that my arm
is actually raising. So in order to move, I have to attenuate the prediction errors that are,
if you like, undermining my predictions. And this is called sensory attenuation.
And it's beautifully exemplified in eye movements. So if you now look at this finger,
and then it's the card to this finger, whilst you were moving,
saccading and moving your eyes from one finger to the other finger,
you were suppressing and attenuating all the prediction errors. I know that because you didn't
see the massive optic flow, the shift of the world induced by moving your eyes.
You can actually see it, if you press your eye, this is Helmholtz's famous experiment,
if you just gently nudge the outer edge of your eye, you'll see the world shift around.
Huh. I don't want to push it too hard. I like being quite careful of the viewers at home,
don't poke your eye out. Okay. Yep. Can you see the world just jump around a little bit?
It does, yeah. So that's because your eyes weren't causing the motion,
and you were able to actually register and attend to that visual motion, that visual,
if you like, retinal slip. Exactly the same signals were being generated when you were
moving your eyes with your eye muscles. You didn't see that. You didn't see the world jump.
All you saw was my finger, and my finger again in a different position, the world had not moved.
So you were actually attenuating your sensory prediction errors, your visual prediction errors
during the movement. That's called saccadic suppression. It's a remarkable capacity of the
brain to temporarily suspend attention to self, the consequences of self-generated
sensations. And this happens everywhere. It's a wonderful explanation for the phenomena
when you've got two children in the back of the car, and he hit me hard, and I hit him,
and the escalation and the argument came out absolutely right, because when they're hitting,
they attenuate the sensory information from the reports, how hard they're hitting.
So they actually feel being hit as more intense than they feel they're doing the hitting.
So they're just like a little arms race, they just ratchet up, and this is due to sensory
attenuation. You could actually use that metaphor for a political excitation.
Sure. Is that related to, I know if you've ever heard this, I actually don't know if it's technically
true. I think it is. I've tested it out. I've asked people to test this out. How you can't tickle
yourself. Yep. Yep. The same kind of. That's a brilliant observation. So that example comes from
people like Daniel Wolpert, who I think is now actually in New York, and Sarah Jane Blakemore,
and trying to understand the remarkable, first of all, it is remarkable you can't tickle yourself
because you're attenuating the consequences of self-generated behavior. So in a sense,
the fact you can't induce visual motion by moving your own eyes with your eye muscles
is an example of that. But you can circumvent that by tickling your eye, by using something you're
not used to, which is your finger. So it is exactly that notion. You can't tickle yourself,
which explains this little experiment. It's actually devised by hell health, so you can
perform on yourself. The interesting thing is that what Sarah and colleagues and Chris
Frith were pursuing was that people with schizophrenia have great difficulty
in this kind of sensory attenuation in another paradigm called the force-matching paradigm,
which means that people, there may be certain psychopathologies that interfere with your
ability to suspend attention to the consequences of your own actions. So for example, if you had
inner speech and you heard yourself because you were not attenuating the consequences of your
inner speech, you might then try to explain away these unattainuated auditory or pseudo auditory
inputs as if somebody else was speaking. So this is the notion that Chris Frith bought the table
as an explanation for auditory hallucinations. If you were able to sense your own movements
and were not, if you moved and you were not able to attenuate the sensations of movement,
it might feel as if somebody had caused your movement. So you've got this phenomenon made
acts. So there are all sorts of very quite frightening experiences that would ensue if you
failed to have this sort of turn-taking between action and perception, especially at this very,
very fast time scale. And some of these frightening consequences, one could argue,
are seen quite frequently in many guises in psychiatry and in the neurology. For example,
Parkinson's disease, an abnormality of dopaminergic neurotransmission, where dopamine in this context
is thought to affect the capacity to do this kind of sensory attenuation at a particular level
in the motor system, and therefore subverting your capacity to realise your intentions to move.
So what would that look like? Or it would look like somebody who can't initiate an act.
And that, of course, is one of the common symptoms of Parkinson's disease.
So this adjudication between acting and perceiving, quickly going out there,
moving actively, ignoring the consequences of that movement until you get there,
and then fixating, not moving, getting the information, sorting it out, doing your processing,
and then starting again, the cycle of action perception, where you have actually got the
separation in play, at least from a biological perspective, seems to be a sort of ubiquitous
way that we actively sense our world, or actively make sense of our world, and is very,
very reliant upon this notion of selective attention, sensory attenuation, to get that dance
between action and perception exactly right. Sure. That reminds me, if I tell you just a
personal anecdote from last summer, it was a random day, I was out on my fire escape
eating smoke meal, and, you know, I do this in some days, and all of a sudden,
there was, I live on a one-way street, but coming the opposite way was a police chase.
There was a dark SUV being chased by a cop car. And I remember the first, second, or two,
where I was looking over at what was happening, I didn't quite see the vehicles.
I saw what I can describe as like a fuzzy black cloud. It took a second or two for my brain to
catch up to what was happening, and to construct a car being chased by another car. It was very
bizarre, because I mean, it was highly unexpected, right? It just doesn't happen every day.
And I'm not sure if that's a common thing with people who see things that are extremely uncommon,
but I did have that, and perhaps I was just getting into sort of the perceptual science
literature and reading about the stuff, so perhaps it's hard to disentangle that from
expectations, let's say, but I mean, it really stuck with me as, you know, one, confirming,
although it's well-confirmed, obviously, in the science, but that this is what our brain is doing,
is constructing, you know, correcting for errors, because that's a, you know, highly uncertain,
or really surprising thing to happen, and my brain in real time took a second or two to
cohere and make that a solid, those solid objects.
Yes, well, that's a wonderful story. And, you know, as you say, I mean, it really speaks to the,
you know, the brain as a constructive organ, as an organ that really is trying to actively
make sense of what's going on, and sometimes in a bigger situation, that can take many,
many seconds. So you would also, I think you may be able to rediscover that remarkable,
if you like, suspension of the fantasy that we can perceive immediately,
sort of see yourself seeing using things like ambiguous figures. So psychophysicists have
a whole range of really beautiful experiments, you know, using ambiguous figures and different
kinds of illusions that deliberately put you on the edge, so that you can experience
the sense making and all the sort of settling down a option or another option, you know,
resolving the fuzzy cloud into, ah, yes, that's the percept that makes the most sense in this
instance. And sometimes it's, you know, when you're looking at ambiguous figures, for example,
sometimes it stops making sense, and you cannot voluntarily stop yourself
seeing the other interpretation. So, you know, famous two faces or a vase example. So, you know,
I think these kinds of experiments, that kind of experience really do speak very powerfully
to the kind of experiments you can do at home to convince yourself you've got a very
fantastic organ, but it takes time to construct the fantasies in situations which you're not
used to. And either you'll wait until you experience a police car chase, or you can go and look at some
sort of illusory stimuli devised by psychophysicists. I should just add though, if my
erstwhile colleague Alan Hobson was here, he'd just remind you that, you know,
if you want evidence that your brain constructs all your percepts, just think about dreaming.
That is such clear evidence that our vision is actually something we built from the inside.
And it's just gently constrained by, in the form of prediction errors, the actual sensations.
Then just think about your visual experiences, you know, during dreaming.
So, I want to ask you about that. While you're dreaming, let's say having a
standard dream. I don't know what a standard dream is, but you know, let's say having a
typical dream where you're in it and you're non-lucid, let's say, and you're out and you're on the
beach or something. Is there, and so while you're in the dream, you're experiencing it,
you're not realizing it's a dream, you're not realizing that you're constructing the
environment, the beach. So, is there, in a sense, a Markov blanket between your personal,
your first-person experience in that dream and the dream world? Or is that making it
like, am I getting fuzzy here? I mean, is there technically the same thing or is it different?
I think, technically, it is the same thing. It's just, you know, you introduced a really
challenging issue there, that you know that you are dreaming or not. I mean, sometimes you do
know you're dreaming, certainly as you're moving into lucid phases or sort of only working, making
up. So, I'm just thinking, you know, a proper answer to your question would have to accommodate the
fact that you perceive and you act in this world, and yet you're not aware that you are actually
dreaming. And that must, as you say, induce a whole series of Markov blankets. First of all,
you're sequestered from the sensorium. So, you know, the biological state of dreaming
rests upon a particular kind of sensory attenuation, which is very enduring, unless for many hours,
if you're sleeping halfway. But it's mediated by the same neurochemical, the same modulated
neurotransmitters that we were talking about before in relation to Parkinson's disease,
different kinds, but basically the same kind of functional role. So, basically, you're switching
off sensory import from the periphery upon the body. So, you're now letting your brain free wheel
in terms of generating predictions and resolving, in a hierarchical context, where you're resolving
the self-generated predictions by other parts of the brain, trying to explain them away. So,
effectively, you're rehearsing your prior beliefs about the narratives that you usually
are certainly constrained by the experiences you've had the previous day. And yet, as you say,
you're not aware that you are dreaming. So, there are certain very high levels of this hierarchical
construct, or say, deep levels, if we think of centripetal like hierarchy or heterarchy,
that have dissolved that sense of presence and Belford, or no, sorry, that is associated with
the reality monitoring. So, yes, not only is there a Markov blanket established that separated you
from the sensorium, but there's possibly another higher one that separated your normal
reality checking and self-modeling from certain parts of the brain that are engaged in
rehearsing particular fantasies that you are experienced as dreams. One of the things I
was thinking about with your model, with the principle, is I can understand what the system
is doing a bit in terms of like having its own internal states. Can we think of the environment
as doing anything with surprise, or are we staying agnostic on what the environment is doing?
Right. So, again, a very leading question. So, I'm just, there's a whole other
sort of podcast under the hood. Possibly, I'm not the best person to have that conversation. There
are people who speak, I think, in an informed and very fluent way about this perspective. But
what you are suggesting is that one can appeal to the mathematical symmetry of this
way of partitioning the inside and the outside of the Markov blanket,
which has an exact symmetry. So, technically, certainly at the level of sort of basic
sentience and sense-making of the kind we were discussing earlier on, it is mathematically
true that you can also interpret the environment as inferring your internal states, because you've
got this generalized synchrony, which is another manifestation of self-information or surprise
or surprise minimization when the surprise of the measure of your sensory impressions. So,
on that view, the environment now is acted upon by you in the way that, from the environment's
perspective, render your actions sensory inputs, and the way that the environment acts upon you
is by providing you with sensory impressions. But, yes, mathematically speaking, the environment
should certainly be modeling you. There are various flavors of that truism that you could pursue.
One would fully acknowledge that there is clearly a vast asymmetry between you and your environment.
The environment is usually making it bigger. It doesn't always have the same delicate structures
or the precise mechanics that would require the sort of planning that we're talking about in terms
of the expected free energy. So, we're not saying the environment plans, but in terms of still trying
to minimize prediction errors and doing the right kind of learning about you, I think there is good
evidence. Well, you can certainly read certain aspects of the environment as doing exactly that.
So, the favorite example is the elephant path of a desire path, the shortcut that is worn by repeated
use across a grassy lawn when you're getting to what the cutter corner to walking through the park
or to your favorite coffee cafe. So, one way of looking at this is something I've done
to my environment, and I've done it with my conspecifics, and I've created a little path to
my favorite place, or the place that is the favorite of me and my conspecifics,
from the environment's point of view, it's learned a lot about the behavior of its inhabitances,
of its denizens. So, you think you are impressing yourself from the environment's point of view,
it's just a bit of plasticity, an experience-dependent kind of learning,
where it's remembering things about you. And you can take that argument right through to
those kinds of parts of the environment that are actually constructed by conspecifics,
by traffic lights, by signs that have a semiotics and sort of deontic value.
So, you could say that the lived environment you would express if you walked out onto the street,
it's all man-made, and it's all built to maximize expected information gain. I mean,
what is a sign? It is there to create an environment that states our curiosity in terms of making it
easy to respond to epistemic affordances that you're underwrite our curiosity or our plans
to maximize expected information gain. But we build that. So, then you go into the role of
into the game of cultural niche construction, the notion of the designer environment from Andy
Carr, for example. So, all of these, I'm just summarizing conversations you could have,
probably with other people who I want to. The final kind of conversation you might have is that
when you realize that your environment is composed of other things very much like you.
When you're young, your mum, or as you're older, or your colleagues, and your friends,
and your family, and your specifics on the street. I think that's interesting because now we're
getting to a much more symmetrical sort of relationship between me and the environment.
And certainly in this context, most of my universe is basically you and me. So, now there's a certain
kind of symmetry in play, whereas you are my environment, and I am your environment. And yet
we both have gelatine models of our environments, which basically means I have a gelatine model of
you and you have a gelatine model of me. Minimizing the surprise in the exchange
is one description of, can be understood as leading to a generalized synchrony,
literally a meeting of minds, a mutual predictability. The rest of all certain things, such as
communication and language, and certain common frames of reference, common ground.
But you could actually argue that in this setting, it is an inevitable consequence
of joint free energy or surprise minimization. When we put two of the things that are sufficiently
similar together, that this would be inevitable. The best way to minimize surprise, when I
surprising signal that generated by things like me, namely you, is to ensure that I was much like
you as possible, so that I can predict what you're going to do next, because that's what I was going
to do next. And exactly symmetrically so for you. So that basically means that we come to share a
gelatine model, a shared narrative, we're seen from the same hymn sheet, and everything becomes
mutually predictable. And that would be what explanation for the kind of in-group formation
and the kind of, you know, the mechanisms you might find in evolutionary psychology,
could be described in terms of niche construction. What it doesn't describe though, is the going
back to your twilight zone, and the man in the nice hell, the epistemic hell. So if it was
the case that we could become completely mutually predictable and just keep on singing the same song
together for hour after hour after hour, that would become boring. So now we come back to,
you know, what would this kind of mechanics and this way of understanding self-organization look
like when I'm packed in societies and in exchanges between different kinds of conspecifics. And you
get to really interesting questions about polarization in-group, out-group, the spread of
ideas and the spread of memes that can be simulated. At this point, I think you're now into sort of
social neuroscience and joint free energy minimization that can sometimes lead to quite
paradoxical results or understandings of the way that we search for information or engage with
people. On the one hand, I want to make my world as predictable as possible, so I don't get any
nasty surprises. So I'm going to go to those kinds of news channels. I've talked to this kind of person
because I think that, you know, we have a lined frame of reference. We have common grounds. We
speak the same language. On the other hand, I'm going to be compelled to be slightly curious
about other ways of thinking. It's not, you know, we're not all going to merge into one
massive community, you know, one massive hive mind, one massive collective intelligence. It's
that's not going to work because we are compelled to, you know, what would happen if I looked at it
this way? Well, what's that kind of person like? What's this culture like? So, you know, I haven't
got any answers, but there's a really, really interesting field of information in the social
neuroscience. Sure. It reminds me a bit about, I think you've spoken to it a bit, the Explore,
Exploit, TradeOff, EETO, a little bit because it's sort of this balance between exploiting sort of the
linearist, say, most accessible forms of energy or, say, news content, but then also having this
balance between doing that and exploring, say, other modes of thought or, you know, exploring
what else is out there and that balance, that getting that balance right. And I think you said
something to the effect once about the free energy principle that it gets, was it solves it in the
right order? Something to that effect? I think it's in the way I perceived it was or viewed it was
in order to know what's surprising, you have to know what's possible, kind of, does that make any
sense? Is that performing it? Absolutely. So, yeah, I probably said it sort of dissolves the
exploitation, exploration dilemma, but you're absolutely right, it does so in a particular way.
And it does matter in terms of the order in exactly the way you say. So, if I go to this
gambler's heaven, there's an enormous opportunity for me to resolve uncertainty and to indulge my
curiosity, to respond to epistemic affordances, which is the expected information part of the
expected surprise and the expected free energy. So, I'm going to, first of all, explore all
possibilities. What is possible in this particular new environment? I moved to a new city or I put
a new device in the kitchen. So, the first thing I'm going to do is explore by becoming a little
scientist and trying out this and that and going there and seeing what happens until I have resolved
sufficient uncertainty that there's no more irreducible uncertainty there. At that point,
the component, the expected information gain will fall below the expected costs or the expected
utility. So, I'll have innate preferences that put constraints on my exploration. So,
at the point where you literally, your epistemic expected information gain falls below the expected
value, then the expected value will take over and I will switch deterministically to exploitative
behavior. So, that means the first thing I'm going to do is explore and then, so there is no
uncertainty left to resolve and then I will exploit. So, exactly, secure the possibilities
and then just act in a way that is predominantly dictated by my prior preferences or my constraints.
Another way of looking at that is,
we are primarily surprise minimizing or uncertainty minimizing creatures, but we do
so in the constraints. The constraints are provided by our prior preferences or by our,
the constraints afforded by the fact that I would be in this state would be very, very surprising.
So, one way of looking at this resolution of the exploration dilemma is that it's not a dilemma.
In any sense, we are quintessentially exploration machines, exploration curious artifacts,
but we have constraints that we can't become dead or disabled or dehydrated or dissipated.
We can't allow ourselves to be damaged, but under those constraints, our primary
imperative is to explore. Unless, of course, there's nothing left to explore and then we get bored.
Yeah, sure. It's the train off. Are you familiar at all with, I believe it's called a number of
different things, but it's like a game theory question. So, they're called like the marriage
problem or the secretary problem. Have you ever heard this before? Yeah, so, would you like to
hear it? I don't know. Yeah, so basically the way the game works is you're looking for a partner,
a life partner, and the question is how many partners, how many people should you date
before settling on one person? How do you know the available options? I guess, how do you know when
to stop looking is kind of the question. It's also called the secretary problem. It can be called
the hiring problem because sort of like the question of, you see one applicant, you have to
say yes or no to that one applicant, and if you say no, you can't go back to them, right?
The jilted x, let's say. You can't ever go back to, apparently, what's optimal is,
and you have to know, what's interesting is you have to know kind of how long you're willing
to date. How many partners are you willing to sort of to suss out?
The answer is you basically date and you say no to the first 37% of potential partners,
or potential applicants, let's say it's for a job, and then after that point, you say yes to
the first person who's better than all the options you saw already.
It's kind of how it works, right? So it's like you have to date around, you have to kind of explore,
but even if you find someone that's incredible by this model, you're not supposed to say yes to
anybody until you've seen a little more than a third of the whole people that you're trying to
observe, and that just makes you think about EETO a little bit because it requires a certain amount
of exploration. Obviously, there's certain parameters here that are more firmly set than
you'll find for most system environment dynamics, but that there is actually technically a
mathematically precise sort of strategy that works across the board, so I just thought I'd share that.
No, I haven't heard that. That's brilliant. It reminds me of sort of evolutionary game theory,
having sort of stay wins, or tip-a-tap, like different strategies and which super things
that an evolutionist has done as well. The free energy principle. How it reacts to or how it's
related to Hamilton's principle of least action. Can you possibly make that help make that link?
Yeah, well, so the free energy principle, as we were discussing earlier on, can be regarded either
as a variational principle of least action or a constrained maximum entry principle, just depending
upon your favourite way of understanding the maths. So the variational principle of least
action just is an instance of how it's this principle of least action. Technically, both
when applying Hamilton's principle of least action, say to mechanics or movement of massive
objects, for example, what these principles prescribe is a prescription of the trajectory
or path that something will take. So you could apply Hamilton's principle of least action to
the trajectory of a ball if thrown at a particular angle with a particular velocity
from this point. And it would be the case that the trajectory caused out by that ball
would be a path of least action. It would be the path that minimised a certain energy
when averaged along that path. So this is a path integral, meaning sort of adding things up.
So the path of least action, the path of least at least resistance, if you like,
where the resistance scores the expenditure of energy because it deviates from the path,
is prescribed by the principle of least action. And you can use that principle then to predict
or to describe the most likely path that anything will take. And indeed, that sort of path integral
view is exactly where free energy, the variational free energy comes from. But here we're talking
about sort of Feynman trying to work out the probability of various paths of small particles
or electrons. So a very difficult mathematical problem that was finessed by introducing this
notion of a variational bound on the probability of a particular path in his pathological formulation
quantum electrodynamics. The math is identical to the free energy principle. And it just says that
there is a particular path through a space of beliefs that is the most likely. And in the same
way that there is a particular path, if I throw a ball, that is conforms to Hampton's principle
least action. And the space through which we're talking about how traveling now is the space
of probabilistic beliefs encoded by the internal states of something. So slightly more abstract,
it's more about the measurement thing, more like the sort of James in use of the word entropy,
or the way that James would apply his entropy to belief structures. But the mathematics,
the variational calculus is exactly the same. It just tells you, given a particular initial
condition and some sensory input, for example, I can tell you the most likely trajectory of
beliefs that would be described in terms of belief updating, for example, that will ensue
using this variational principle of least action, which is the free energy principle. It's exactly
the same math. I'm just trying to think of even more intuitive ways of describing it. It's a path
of least effort. It's just a mathematical way of describing the path of least path into the
future or the past of least effort, where the effort is effectively scored by the amount of
surprise I can avoid. Are you familiar with Jeremy England's work with dissipative adaptation?
Yes, well, I was about four years ago pre-COVID. Yes, I haven't read what he's been up to recently.
So he moved recently. He moved to Georgia, I think. Oh, really? Oh, I didn't realize he moved. Yeah,
but it's far more of it. I know it's more of a thermodynamic. It's solely, I think,
a thermodynamic, but it makes me, because one of my general interests or one of the things I try to
get to is, you take something like the free energy principle, you try to think, okay,
what's even more fundamental than that? You keep trying to cut away and say, okay, well,
how do you make this even, what's behind that? What's below that? What kind of feeds into that?
And I don't, I mean, to be completely transparent, I don't fully understand how
dissipative adaptation works. I think that's something to do with the environment,
adjusting itself to best accept the energy that's flowing through it, something like that.
But of course, it's very technical. Is that, at least, I know it's maybe been a few years since
you follow the, follow the idea, but does that, does it conform? Well, I guess it would have to,
but does this play into the free energy principle at all, or is this a dynamic that kind of works?
No, I mean, it's fascinating work. And you may also want to invite Suzanne Still
to one of these conversations who's been doing very similar work from the point of view of
sort of predictive information theory. And recently, she's also been looking at this sort of
remarkable capacity of systems to, again, resist the second law, and, you know, use their free
energy thermodynamically, but she would frame it in terms of information theory, to, if I could,
extract order from, from else. And you know, common to a lot of these notions, there's a notion of a
ratchet, that you, you, you, you, you, you can make little random jumps, but you, you, you maintain them.
And each jump is maintained. If it's heading in the right direction, you know, if they are
minimizing sort of free energy at the expense of something else. However, I have to say,
it's not really addressing the same kinds of issues that the free energy principle is addressing.
I have to say, also, you won't get more fundamental or simpler than the free energy principle. So,
I look at thermodynamics as one particular domain of application of that kind of mechanics.
The only difference between thermodynamics and the free energy principle is that the free energy
principle actually commits to a thickness, it commits to a Markov blanket. So, it's now got a
partition of states where you can start to talk about beliefs in a non-trivial sense, in the sense that
there is a morphism from the internal states of a physical system to the states beyond the heat
path or beyond, beyond the blanket. And all the more interesting questions really about
maintenance of that blanket or the heat path. It's not about the equilibrium physics of things on
the inside. Most of them are just rather uninteresting descriptions of ensembles of things on the
inside that have some particular exchangeability criteria. And then you can apply classical
equilibrium physics to that. That's not terribly interesting from the point of view of people
looking at non-equilibrium physics. And even less interesting from the point of view of people
looking at real randomly dynamical couple systems because these systems are not exchangeable.
You mentioned before that Mike Levin's description of sort of cells of cells of cells of cells of
cells are boundaries of boundaries of boundaries of boundaries. Markov blankets of blankets of
blankets of blankets. There's a heterogeneity to implicit in that scale invariant description
of actual systems that will not allow you I think to apply to adopt the assumptions that we
would have to commit to if you wanted to apply thermodynamics. So I have a missing attitude
to thermodynamics. So in that sense, trying to understand the thermodynamics of
self-organization, I think it's possibly misguided because you have to make too many
commitments to the kind of systems, particularly the exchangeability of ensembles
to make it really interesting. On the other hand, the the the questions that people like Jeremy
England and Suzanne Still more recently have been addressing are I think deeply interesting
and are not really addressed by the free energy principle. I think what you're talking about here
is the sort of the complexification that seems to be an inevitable property certainly
of biotic self-organization. You could argue other kinds of self-organization but certainly
biotic self-organization are far from equilibrium systems that have this kind of stale freeness and
implicit heterogeneity in them. I think that there has yet to be a simple story to explain why we
are becoming increasingly more sophisticated increasingly, but if we are organized. I think
that's a fascinating issue. I don't have a clear answer and I will repeat. The free energy principle
itself does not properly address that because the free energy principle starts by saying,
let's assume something has self-organized its house and attracting set. That's where it starts
and that's really where it finishes. I think if you want to think about how these attracting
sets evolve and contextualize each other, I think you're going to be in a slightly more
challenging frame which lots of people are addressing. It's a really interesting question.
I'm not sure thermodynamics is the right toolkit to address that to be honest. I think you need
to look at more fundamental maths probably quantum information theory at different scales and think
about that through the lens of say theoretical biology and evolutionary thinking. I'm so glad
you brought up quantum information theory because that's where I wanted to go next.
I was wondering if the free energy principle lends any credence to the idea or has any
relationship to, I'm not sure if you're familiar with some theories about the universe being
like a quantum air correcting code. If you're familiar at all with that landscape,
basically it's a speculative idea but looks like there's some evidence to support it that the
fabric of space-time itself is actually like a quantum air correcting code. When I hear that
and I think about the free energy system trying to minimize uncertainty, it's trying to close to
air correction or it seems kind of similar too. I wonder if there is a potential link there and
if you have any comments about that or if that's something that's come across your desk.
Well no, it literally came across my desk about three or four weeks ago so suddenly
sent me this paper on the universe being an air correcting code. I'm delighted and if I remember
the sentiment of the email was it would be great to get this chaps or this woman's take
on this in relation to free energy, theoretic formulation because it seemed as if there was
a very very close connection as you have spotted. I think the best person to comment on that would
be Chris Fields. I did quantum physics as a young man but that was 40 years ago.
I usually defer to Chris when he comes to quantum information theory. He has a beautifully rounded
perspective on these things and will probably be able to give you quite a definitive answer. He'll
probably say yes it's the same thing but then try to explain why it's the same thing. Yeah,
it's hard to link to. I can't do that. Again, I will be surprised if all of these things weren't
entirely conciliant and I probably ultimately, you know, you probably aren't going to fall back
on something like James' maximum entropy principle, certainly if you're in the quantum
information theory. You will probably find an equivalent description of the kind we've already
mentioned in terms of variational principles of least action but you may also find similar
explanations in gauge theory and ultimately category theory but they should all, I think,
be internally consistent. You should be able to sort of morph from one to the other without doing
too much damage to your governments and anyone, your favourite way of framing them. I'm sure the
other directing universe is one example of this. Yeah, this is very well could be. It reminds me
too of Chris Fields, a frequent collaborator of his is a cognitive scientist, Donald Hoffman.
I'm not sure if you're familiar with his work. I've interviewed him a couple of times on this
channel as well but one thing that you said that stood out to me and it's something that
he said as well or something similar is that we don't need to know the truth. We just need to
minimize prediction error. You know, it's like this very separate thing and I don't know if you
are familiar with it. He's got a few different theories. I mean, one of which is fitness beats
truth theorem that we've evolved in order to basically maximize fitness instead of to see
what's vertically actually there in the environment. So much of what we see is or all of what we see
is an illusion. We can never, he posits that we can never actually get to the base reality, the
base truth. And I'm sure if you have any thoughts about that or if it's something that you've come
across or if you've spoken with Don. No, I think that's absolutely right. And it sort of leads you
to interesting discussions. Should you want to go there in terms of skepticism versus realism,
internalism versus externalism and the like with philosophers, but certainly from the point of view
of the maths, the physics of this kind of sentence, it is all about making, forming or
understanding internal dynamics as encoding subpersonal probabilistic Bayesian belief about
stuff which is fundamentally hidden beyond your mark of blood, beyond your sensory veil.
It is inaccessible. It is unknowable. And I think that probably Chris Fields would frame this in
terms of holographic streams, sort of appealing to the holographic principle that, you know,
classical exchange of information across your sensory veil or your mark of blanket
can be construed as a holographic stream from the point of view of quantum information theory.
But that's the only way you can entangle a couple, two systems, you know, with classical information.
So, you know, again, we come back to this fundamental separation between the inside and the
outside, which, you know, read in terms of your conversations would be exactly,
you can never know what's out there. We don't need to. If you can keep your prediction errors
very, very small for as long as you live, job done. I mean, that's perfectly, that's perfectly
okay. It does raise the interesting issue, though, is there an outside, which would involve
philosophical issue. So both Chris and I, I think, would have to commit to the fact that probably
is an outside in order to help to actually be able to read and write to your holographic screen,
or to be able to transact with an environment, you know, in terms of in both directions over
your mark of blanket. So the free energy principle puts you in a slightly ambiguous position when
it comes to philosophy. So on the one hand, you can be entirely skeptical, everything that needs to
be done is beneath your mark of blanket within the skull bound brain. There is nothing else.
On the other hand, you're making sense of signals that are provided by something
out there. So you have to commit to at least a mathematical description of stuff being out there.
What the something is, sure. I'm just really looking at the time and I realize we've gone way
over what we had sort of planned out to go. I hope you've enjoyed this discussion. I mean,
I've gotten so much out of it, Professor, and thank you so much. Anything else you want to?
I mean, I literally have so many questions I could continue to ask you, but I do want to be
mindful of your time and energy as well. So please let me know if, you know, if you have a few extra
minutes, I can ask you a couple more. But if, you know, if you've reached your limit, please let me
know also. Please ask me two more questions and then I'm going to go and have a nice cigarette.
Okay. Oh, that sounds nice. That sounds lovely. Yeah, one of those once in a while isn't so bad.
I think, okay, okay, two questions. So now I have to really narrow it down here. But
we'll see it's a little bit. Well, one, one I'll ask you is, and I'm surprised we actually haven't
touched on it, active inference, which honestly for, I mean, maybe the first couple of weeks I
was looking into the free energy principle, I actually thought they were the same thing. I
actually think it's written in other places, I think Wikipedia maybe kind of writes them as
equivalent. And I believe active inference is a subset of the free energy principle or it's like,
well, perhaps, I mean, you could probably, you could definitely do the best job. Can you help
separate the two or help us make a distinction between free energy principle and what active
inference is? I think you could be forgiven by by using them synonymously. And so, you know,
that's how it was portrayed, I think, in the in the Wikipedia links. Having said that,
you know, in the world of philosophy, one's got to be a little bit more rigorous in the way that you
you frame various offerings. So nowadays, I mean, I am, and then one of my friends
in the philosophy are also very careful to distinguish between the free energy principle,
which is just a method. So very much like we were talking about Hamilton's principle of
least action as a method for determining the path of least action or least effort.
But the free energy principle is just what that what it is, it's just a method. It's a tool
for describing the most likely kind of active sense making or belief updating,
or, as you say, active inference. So it's not falsifiable. It's not a theory. This is a principle.
This is a tool. It's a method. If you apply that to purposeful behavior,
then you have active inference. So active inference, I think, is an application of the free energy
principle to usually simulate or predict or emulate or to model purposeful section behavior,
basically. So I've given you a long winded technical answer, but so you you can you can
so free energy principle is usually for sort of physicists and philosophers that
the fossils like to shout about it. The physicists think it's probably quite trivial.
The active inference is more an application that you might want to actually apply if you're
a psychologist or artificial intelligence researcher wanting to emulate this kind of behavior
or understand, say, given subjects behavior by fitting an active inference model to that
subjects behavior using the much more practical way. I mean, you can regard the free energy
principle as only having utility in that ability to simulate active inference. Just technically,
the only thing you get from the free energy principle is really a way of writing down the
dynamics of self organization as a gradient flow on the on the generative model on those prior
preferences on the probabilistic description of those attracting sense, which means instead of
just just looking at the way a system behaves, given its dynamics and trying to reverse engineer
its Lagrangian. What you could do is actually write down the Lagrangian as a Jamesian constraint
as a set of prior preferences and then just apply the rules of the free energy principle
to simulate the behavior of a system that self organizes to that set of attracting states on
that particular set of preferred states. That's basically what we do in computational neuroscience
and machine learning research. Okay. Thank you very much. That helps. The distinction is super
helpful. Great. Now, last question. I had to kind of a bunch of different ones. I'm like,
oh, I forgot to ask them about attractor landscapes and strange loopiness, but I will
instead ask you if you, this is more of a metaphor, this is a personal question, but
if you could give your 20 year old, 20 year old self one piece of advice, what would it be? So if
you go back. I think it would. No, I'm trying to be too clever about this. Probably to go
to the dentist more often, to be honest, if you're much less trivial answer. I think it would be
nice to do a couple of years of philosophy. I always say when people, when my children and
when my students and when other people ask me what's good career advice is keeping your options
open. You've used that phrase earlier on today. I think there's something quite fundamental about
that. As broad a foundation as possible, bearing in mind that we are all quintessentially curious
creatures. And therefore, if you omitted your academic career, you are indulging that. But
the best way to explore is to have a very broad foundation. And I managed to do that to a certain
extent. I didn't, I didn't miss out a lot of history and a lot of philosophy. And I remember
one of my mentors, Jerry Edelman, used to refer to me. I won't say fondly. He just used to refer
to me as an intellectual thug because of my lack of scholarly understanding and very little finesse
when it comes to sort of mechanical or history. So it would have been nice. I don't know what would
have happened if I had spent time doing that, but it would have been nice just to involve myself
with what somebody is and not trying to try. Sure to have that base. But there's still time.
I mean, it's not like, you know, I mean, I'm sure you're busy, so you don't have too much free time,
but you know, it's always available. Well, Professor Friston, thank you so much. This has been,
I mean, this has been amazing speaking with you. And I'm so honored, so blessed that you
take the time to speak with me. And I'm sure the audience will appreciate everything here.
And I'll include links in the description of this video for people who want to learn more,
who want to read your papers, I'll link to some of your papers and some of your
some of your presentations. And thanks again. It's a treat.
Well, thank you. I really enjoyed talking to you. And I'm going to find out how long we've been
talking. I deliberately haven't looked. I shouldn't have said anything. I wish I had
said anything now because I'm going to ask you about attractor landscapes. But no, yeah,
it has been a while and I appreciate so appreciate you going over.
Right, I shall go away thinking about attractor landscapes and what I should have advised myself
to do when I was 20 years of age. That's a great question. Bye.
