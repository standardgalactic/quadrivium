Welcome back to Carnades.org, today we're going to be continuing our series on Bayesian
confirmation theory as part of our series in Bayesian epistemology.
In this video we're going to be starting our shift from the confirmation theory to the
paradox of dogmatism and how that plays in with the confirmation theory and how that
can kind of help us understand how the confirmation theory does or doesn't work.
In this video, like I said, we're looking at Bayesian dogmatism and the irrationality
of certainty.
In this video we'll offer an example that will both help you kind of use some of the
rules of Bayesian confirmation theory but also hopefully show off a little bit of the
problem we're going to run into with Bayesian dogmatism.
So as we remember from our last video on entailment, unlike with deductive rationality
where once you discover that you hold contradictory beliefs, you're allowed to change them with
inductive rationality, once you believe something for certain, if you ever change that belief,
you are irrational and you can't do anything to change that because the rational process
of changing your beliefs is exactly what's at issue.
We have codified how you can change your beliefs.
So if you change your beliefs outside of those rules, then you're going to be counted as
irrational one way or another and those new beliefs are going to be irrational.
And so will anything based on that.
If that was confusing to you, I encourage you to watch the previous videos in this series
because this is a complicated topic.
So we're going to look back on the paradox of dogmatism that we mentioned at the beginning
of this series and start thinking about that as we move forward with this next example.
So if I know some statement P to be true, then I know that any evidence against P is
misleading.
I should disregard evidence that I know is misleading.
If P is known, then all evidence against P can be disregarded.
Therefore once I know that P, I cannot ever change my mind.
We remember that the normal epistemist, the non Bayesian epistemology believer claimed
that we can get out of this by rejecting the hardiness of knowledge, basically by rejecting
that once you know something, you can't change that knowledge.
That's going to be a little bit more of a problem for the Bayesian.
But let's take a look at an example.
So imagine a man named Xingyu.
Xingyu is certain that he is Chinese.
His parents are Chinese.
He's seen his birth certificate.
All of his relatives are Chinese.
His degree of belief in the proposition, I am Chinese, is one.
Let's call that the probability of C is equal to one.
Now imagine that Xingyu finds out that he was adopted, a DNA test is done and he finds
that his actual parents are Korean and that he is and has always been ethnically Korean.
His foster parents admit to him that they lied.
Call this evidence the probability of K.
Xingyu's degrees of beliefs might look something like this.
His initial probability that C is equal to one, he is certain that he is Chinese.
And the probability of C given that K only goes down a little bit, it goes down to 0.9.
He only changes that certainty a little bit, a very small amount.
Many of us might completely throw out that certainty.
But because we're trying to give kind of this Bayesian epistemology everything we can, let's
say he only changes his belief a little bit.
He is certain that he is Chinese, but if he were shown evidence that he were Korean, then
he would be slightly less certain, but still pretty certain.
The problem is this, according to Bayesian epistemology, is an irrational way to behave.
Note that any greater degree of belief he had of changed it to, so if he had of changed
it to P of C given that K is 0.2 or something would be more irrational than his changing
it to 0.9.
Remember from entailment, if you are certain that a particular hypothesis is or is not
the case, then no evidence will ever confirm it, disconfirm it, or cause you to change
your degree of belief.
And if you ever change your degree of belief, you will be inductively irrational, according
to Bayesian confirmation theory.
Basically, the contradiction is going to follow like this, if you don't understand why these
two beliefs are irrational.
If P of C given that K is less than 1, then P of C and K initial is less than P of K initial.
This is by Bayes' theorem.
Because remember, P of C given that K is just going to be a ratio between the probability
of C and K and the probability of K.
If it's less than 1, that means that P of C and K, the top part of our fraction, is
going to be less than the bottom part of our fraction, P of K initial.
If the probability of C and K initial is less than P of K initial, which we got from our
last line, then the probability of not C and K initial is greater than 0.
Since the probability of C and K initial plus the probability of not C and K initial is
going to be equal to the probability of K initial.
That means that we have to have a greater than 0 probability of not C and K initial.
But if that is greater than 0, then the probability of not C initial is going to be greater than
0, since the probability of not C and K initial plus the probability of not C and not K initial
is going to be equal to the probability of not C initial.
These are just all of those original equations we did when we were talking about kind of
the way that Bayes's theorem works.
And if the probability of not C initial is greater than 0, then the probability of C
initial must be less than 1, since the probability of not C initial plus the probability of C
initial is equal to 1.
Remember, all of these only work because we can't have negative probabilities.
We can't have a probability that's less than 0 or greater than 1.
But we've already stated in our first line that the probability of C is equal to 1.
Therefore, we have a contradiction.
So if that didn't make sense, let's take a look at this in terms of our lovely chart.
We say that C implies not K. The reason we say that is because one can't be both all
Chinese and all Korean, or completely Chinese and completely Korean.
So we're going to say that the probability of C and K is going to be less than the probability
of K. That comes from Bayes's theorem and the fact that our conditional probability
of C given that K is going to be less than 1, it's going to be that 0.9.
That means we have to have a not 0 number for not C.
Therefore, if we have C equal to 1 and not C equal to not 0, then our total has to be
greater than 1.
The reason we have to have a not 0 probability for not C and K is because if C and K is less
than the probability of K, we have to add something to that to get to our total probability
for K. And we can't just add 0.
The point is, it's impossible to have a total probability that's greater than 1, so we've
reached a contradiction.
Therefore, it is irrational for Xinyu to alter his belief that it is Chinese even when presented
with evidence to the contrary, yet to hold any belief come what may seems equally irrational
and is going to be a problem for our original deductive rationality.
The only thing that we can conclude if we want to hold on to our Bayesian epistemology
is that certainty itself is irrational.
That was an example of the problems with Bayesian dogmatism.
In the next video, we're going to take a look at an official premise conclusion argument
for the new paradox of dogmatism.
Watch this video and more here at Carnades.org.
Check out the SEP for more information and stay skeptical everybody.
