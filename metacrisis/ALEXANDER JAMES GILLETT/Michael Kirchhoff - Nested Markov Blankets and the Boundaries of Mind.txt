We'll have a discussion session before the end of the year.
It's a real pleasure again to welcome another expert for you guys today about the paper,
so you can join us in this as well.
Thank you.
Thanks for your invitation.
I should say part of the paper is inspired by an art paper,
and you're all marked off blank.
It's a 17th paper.
And, predominantly, the talk is going to be...
Can you move your left leg here back?
You can hear?
You don't?
No.
Okay.
Sorry about that.
We might have this strange question.
Can I hear it?
Excuse me.
Okay.
Is that set up?
Is that set up?
Is that set up?
Okay.
Is that set up?
Okay.
Yes.
China has nested marked off blankets in the boundaries of mind,
and thanks to Regina for setting some of the conceptual tools
to do with marked off blankets,
and I'll try to do a little bit more work
in terms of getting out to perhaps an extended,
or sort of extended notion of A of a marked off blanket.
Now, let me just start with a little bit of intro.
I'm going to speak a little bit in the beginning about the extended mind,
and I'm going to segue into talking about marked off blankets,
and hopefully the point of connectivity will be clear enough on slide two.
And here's Dave Chambliss laying out,
setting out what I find to be a quite nice definition of the extended mind thesis
as follows.
He says this is a forthcoming paper.
A subject's cognitive processes and mental states
can be partly constituted by entities that are external to the subject.
In virtue of a subject's sensory-motor engagements
or interactions with those entities.
I find that to be a nice definition
because it speaks to the kind of sensory motor dimension of an activism.
It speaks to a kind of manipulation thesis,
which is developed both by Richard Menari and Mark Romans,
on what is it that we should think of when we think of what constitutes
an extended cognitive system.
That we interact through sensory-motor engagement with entities in our environment.
Now if you take that sort of definition to be what the extended mind thesis is all about,
then Chambliss suggests that this is one of the possibly strongest objections
that are particular thesis that you can find.
So he says,
perception and action constitute the principal boundary to the mind.
In this view, the mental is constituted by processes between perception and action.
So that what falls outside those boundaries or these boundaries
cannot constitute the mental.
So if you combine one and two,
then the verdict is when it seems like the extended mind thesis is not plausible.
In the paper, he goes on to suggest various ways of moving back
or arguing against the perception, action criteria only for the mind.
But what I want to do is to suggest the following.
You can think about the action-perception criteria on the Chambliss establishes
by which to demarcate the cognitive from the non-cognitive.
You can think of that as mapping on to something like the Markov blanket
or at least the kind of partitioning that you get between states
when you start thinking about the Markov blanket.
So here you've got a cell and above you've got a brain.
The Markov blanket, as Regina pointed out, is comprised of sensory and active states
and those states distinguish or separate external states in the environment
from internal states comprising an organism, for instance, a cell or brain.
What I want to consider is whether or not there is a principle Markov blanket, say,
surrounding the brain that insulates the neural states from external states
in such a way that that particular boundary can qualify as a kind of mark of the mental.
So I want to ask whether or not, say, a boundary around the brain,
the Markov blanket boundary, necessarily enforces a kind of internalistic picture
the realises of mental.
Let me find the right spot.
There we go.
I'm going to do this by, first of all, just laying out a broad overview of the Markov blanket itself
and the kind of conceptual apparatus that follows,
particularly the kind of independencies between states that it is argued to follow from the Markov blanket.
Then I'm going to consider an argument for how the presence of the Markov blanket
might lead to a kind of brain bound view of the mind or cognition.
And then I'm going to gesture towards an alternative called the nested view of Markov blankets.
That's based on some work I've been doing at UCL with Carl Friston and so Pellasio's Rasi and Thomas Pah,
where we explore the self-organisation of the individual Markov blankets,
organising into larger and larger Markov blanket systems.
Okay.
What should I stand for?
Markov blanket for you.
That's exactly right.
Okay.
So in this picture we're looking at three different ways in which you think about kind of couplings between systems.
So if you just look over here and figure out what we have there is some spatially independent subsystems
and I'm mediated by long-range interactions just kind of illustrated with long errors.
Now here the idea is that all the states influence one another continuously.
To such an extent that it becomes impossible to separate the states from each other.
So if you run the simulation you will see that you get to end up with a kind of homogenous blob.
You can't determine where one state starts and another state ends.
What we want to do is to try to say something about what makes states different from other states.
We do that is to introduce shorter range kind of interactions and that's what we do in figure B.
So here we get only short range interactions between subsystems.
And that means that in contrast to figure A where the couplings are spatially independent
we get spatially dependent couplings between states of all subsystems.
What you can see is for instance in the gray cells on the right hand side figure B illustrates short range interactions
between subsystems and you get that again in the dark circles short range interactions between the systems.
What we have here is a situation where B and A are unconditionally independent
and which means you only find interactions between cells or subsystems on the dark side
and you only find interactions between subsystems on the gray side but you won't find any interactions between them.
So there's no further states that couples the gray cells to the dark cells.
And when it comes to the issue of a Markov blanket what we're interested in is conditional independence
such that we get states that are statistically independent from one another
but we also want to ask what can it be that couples those states to each other.
So what you see here is internal red states and external blue states
and they can be distinguished in virtual separation induced by the third state
namely the Markov blanket which is composed of this case D.
The yellow sensory states on the outside and the active orange states just so surrounding the internal red states.
And here the idea is that the Markov blanket both separates internal states from external states
and couples those states through active and sensory states.
And so in our decision to figure B what we get here is we get states that are separated
yet coupled through a set of mediating states in this case sensory and active states.
So the Markov blanket separates internal and external states via sensory and active states.
You can also think of that as the kind of partitioning rule governing the presence of a Markov blanket.
So in this case external states cause sensory states which influence but are not influenced by internal states
while internal states cause active states which influence but are not themselves influenced by external states.
The partitioning rule highlights that internal states and external states are conditionally independent
given the Markov blanket.
And you can cash that out formally by saying if you look at this particular figure
you can think what's the Markov blanket for note 5.
In this case the Markov blanket is the union of its parents which is state 2 and state 3.
The children of 5 which are 6 and 7 and then the parents children which is state number 4.
So the Markov blanket for 5 is therefore the union of 6 and 7, 2 and 3 and 4.
You'll notice that the Markov blanket for note 5 is the cute note number 1.
And the idea here is that once you know states the Markov blanket
insulating the internal state 5 from state number 1
there's no further information you need to know about the operations of 5
except for the information that you get through the states comprising the Markov blanket for note number 1.
Sorry, note number 5.
So that's what it means for note number 5 to be statistically or conditionally independent of note number 1
given its Markov blanket.
Just speaking a little bit about the relationship now of Markov blankets and active inference.
So the idea here is that the presence of a Markov blanket induces a simple form of active inference.
And you can think about as follows.
The tendency of a dynamical system to minimize free energy of its internal states at Markov blanket.
And in virtue of doing that it enables the system to conserve its integrity all the time functionally and structurally.
That means that both internal states, active states and sensory states are in the same sort of game
but they do precisely the same.
They minimize on average their free energy.
Alternatively you can say that these states work to optimize model evidence.
So they work to optimize evidence effectively for their own existence.
So part of what a Markov blanket allows you to do, it allows you to separate say intracellular states from extracellular states.
And if you weren't able to do that you wouldn't be able to identify the system in question.
So it gives you a boundary to talk about.
But given a Markov blanket it becomes possible to cast a brain.
For instance weaving a cell is engaged in the optimization of model evidence or the minimization of free energy.
And what I have here is just a figure of how you might think of that particular process.
So each cell has a generative model.
You can think of a brain having a generative model.
You can think of an organism perhaps as having a generative model that generates predictions.
And those predictions are carried through by sensory motor couplings to the environment.
Those sensory motor couplings affect and select the kind of activities that the environment would forge just to use that terminology.
Which in turn influence the generative process which in turn modulates the dynamics of predictions and generative model.
So here the generative process both orchestrates and maintains the generative model.
That is thought to be if you like comprised or bounded by a cell of states, active and sensory states.
In this case the generative process.
So if you think something like that.
Then all the states that are involved in the Markov blanket active sensory states separating internal from external states are effectively functioning to minimize free energy.
If you think that's the same which Carl Friston does as optimizing model evidence.
Or if you think that's the same as minimizing free energy.
Then you can cast that in terms of statistical inferences.
So what you have here is just an equality of states.
The free energy of sensory states, active states are to know the internal states.
Is equal to the negative log probability of the sensory active states given a model, a generative model.
Plus the Pubek-Liebler divergence between effectively two probability distributions.
Variational density on the one hand.
And then the true posterior density on the other hand.
And what the KL divergence allows you to do is to measure the distance between the variational density and the true posterior density.
So what we can take away from that is it's effectively two ways in which an organism can minimize its free energy or variational free energy.
Can change its internal states thereby reducing the distance between its beliefs or hypotheses.
About external states and the true posterior density given the states of the Markov blanket.
And that's in this literature typically thought of as perception.
You can change active states thereby changing surprise or model evidence which is action.
And if you think about action and perception not being fundamentally separate but running continuously or in parallel.
Then what you get is minimizing free energy is the same as working to minimize the negative log probability of sensory and active states given a model.
And the divergence between variational density and the true posterior.
So active inference is thus all about maintaining your internal states and Markov blanket.
And you can cast that in terms of active inference on the agenda tomorrow.
Just a simple example.
So here's a riverbed.
See you're an organism some sorts.
And what you need to do in order to stay alive very minimally is to at least avoid kind of crossing terminal phase boundaries.
It's not a problem to cross phase boundaries.
It's a problem to cross terminal phase boundaries.
So on one side of the boundary you might think that the organism will maintain its integrity which basically just means maintaining its model of blanket.
On the other side it's likely that it will not unless it gets rid.
So in any case the organism faces a couple of possibilities.
It can choose to remain at a distance from the riverbed or it can choose to jump in.
And it needs to be able to select between the two.
In other words it needs to be able to make inferences about the outcomes of certain actions were it to actually pursue those actions.
So that suggests that to do surprise or negative log evidence it must be able to sample across different probabilistic outcomes of its own actions.
So survival is premised on having generative models with a particular kind of temporal thickness which allows you to make inferences across possible counterfactual scenarios where you have to act in a particular way.
Okay, so now I'm going to segue back.
So I started with Chalmers and the extended mind thesis and Chalmers' proposal for the strongest possible objection.
And Chalmers works from a kind of common sense view of perception and action.
And he thinks that there is a criterion in appeal to demarcate between the mind and the rest of the non-mental world.
There's a sense in which you find a similar kind of argument in Yakovsky's work.
But not in a commonsensical way.
So this is formalized through the notion of a Markov blanket under variational base.
Let's see how such an argument could play out.
Hope that's an okay picture.
So here we have the brain again and forget about formalisms.
But think here that the brain is enveloped, if you like, by a Markov blanket, allowing you to have a separation of internal and neural states from say external states.
Think of external states as bodily states and environmental states.
And that separation is given by a third set of states, active and sensory states.
So here one claim is, given the Markov blanket, the Markov blanket insulates the internal states from external states.
If that's the case, then the internal states don't have any sort of direct means of assessing the external states.
In other words, you can't leave your brain and go check on what external causes are currently impinging on your sensory.
So that suggests that you need to make inference about what is the most likely external cause that explains the sensory states that you are currently having.
Conditional independence.
So knowing sensory and active states renders external states uninformative with respect to the internal states.
So I don't have to go out and consult the external states in question.
Once I have information about sensory and active states, I have all the information that I require.
Or the brain has all the information that it requires in order to carry through the set of top-down predictions.
It's just a quote.
So in more technical terms, there is sensory input and active output at this boundary forms a so-called Markov blanket,
such that observation of the states of these parts of the system together with observation of the prior expectations of the system
in principle will allow prediction of the behavior of the system such.
Courses beyond this blanket, such as bodily states or external states, are rendered uninformative once the states of the blanket are known.
So the Markov blanket just repeats, separates internal states of the system from external environmental states.
Sensory active states comprising the Markov blanket can be thought of in terms of perception and action,
essentially shielding the cognitive agent from the rest of the cognitive world.
If that's correct, it gives you a Markov blanket inspired perception-action boundary for the mind.
There's lots more to be said in terms of the technical details of this, but I take it this is roughly the picture.
I quite like the Markov blanket.
It doesn't involve having to appeal to, say, intrinsic or non-derived content as a way of separating the cognitive from the non-cognitive.
It doesn't involve having to draw, say, kinds of distinctions between what's causation and what's constitution.
It doesn't involve having to appeal to minimal supervenous bases, etc.
In other words, it doesn't carry with it a bunch more, at least some potentially unjustified philosophical assumptions
about how to carve up the mark that meant for the joints of the cognitive system.
In that sense, it has a lot of versions.
So the question is why worry about this particular picture?
Why worry at all about, say, a brain-bound view induced by a Markov blanket,
and why worry about it for your life as a cognition?
So this is Michael Anderson, and he has one word.
It's the kind of converse of cognitive bloat in extended cognition.
So if we call, if we're willing to accept that by manipulating or having a notebook available on a certain conditions,
the notebook or at least the inscriptions should count as dispositional beliefs,
then you might worry that, well, Macquarie University Library has a bunch of books,
and they may serve the same sort of purposes on this set of conditions,
so that's the kind of worry about cognitive bloat.
Anderson's worry is something like close to unrestricted, as far as I can tell, shrinkage of the mind.
So the idea here is that if you draw a boundary, a kind of action-perception boundary between mentality and non-mentality,
then at least on the Markov blanket view, it seems like you can continue to push that boundary further and further and further in.
That seems pretty straightforward because, statistically speaking, the singular cells got the same properties as a bunch of Markov blanket cells.
So there is active and sensory states.
Those active and sensory states separate external and internal states in that statistical sense that I've been speaking about.
It's not as hard to see how it's any different if you've got a much larger Markov blanket, say, bounding the brain,
or bounding, say, internal, neural states from external, bodily and environmental states.
So you get the kind of same separation of the internal and external states via sensory and active states.
So it seems like if you want to have, say, a single or a stable Markov blanket that separates mentality from something else,
you can push that kind of picture further and further and further in.
That's how I read the worry at least.
So maybe the idea is to move away from thinking that there is a particular blanket we should appeal to.
So I take my staff from a nice paper by Mika Allen and Carl Frister, and they say this is a 2016 paper in Sintesa.
They say the delineation of the boundaries of the Markov blanket is essentially relative and variable.
Any organism will be defined not by a singular Markov blanket, but by a near-infinite regress of course of the interacting Markov blankets within Markov blankets.
So that kind of speaks to this idea that biological systems are hierarchically organized.
There are kind of systems of systems or systems within systems.
So you can think here of cells assembled to form tissues.
Think of tissues organizing to organisms.
You can think of organizing only into organisms.
And of course you can think of all that as by taking in an embedded environmental niche as well.
So the organism is a system with a much larger environmental system.
Any one of these systems micro to macro, if we thought to have a Markov blanket,
merely by being able to pick it up from something else.
This is implied as I said in virtue of having distinct boundaries.
So complex living systems that comprise the many Markov blankets,
all of which exhibits the same statistical structure.
They all have active and sensory states and they all separate internal states from external states.
Effectively what I said, kind of systems of systems view or a complex view of the organization of biological systems.
So what you can start doing if you're interested in this sort of stuff,
is to start creating simulations of Markov blankets.
I'll take it as what Andy referred to earlier as one of these very basic, simple forms of Fristonian simulation.
So hopefully it's not overly significant.
What we have here is 16 cells.
We're not scaling up to anything that smells like human cognition or anything like that.
All we're wanting to explore here is whether you can kind of make sense of the idea
that single cells can self-organize into something that has a Markov blanket structure.
So imagine that you have an undifferentiated bunch of cells.
You run the simulation, you kind of see the spread out like this.
We have a prescribed point attractor for each cell, an ensemble of 16 cells.
The point attractor determines how the cell or the example, in this case, will converge.
The point attractor here takes the form of a Markov blanket.
So cells come to accept the conditional dependencies and independencies highlighted by the petitioning rule governing the Markov blanket.
Internal states, in this case the little kind of orange blob, are surrounded by active states
and the active states are surrounded by sensory states.
All you have to do in order to achieve this, at least on the sort of, the simplistically speaking,
is to equip each individual cell with a generative model that carries expectations about its own identity, if you like.
Not so much about where it's meant to be placed, but what kind of cell is meant to be.
So if you're predicting that you're an internal state and you're receiving sensory stimuli from sensory states,
then you're going to move into a position of the orange.
Similarly, if you're an active state, you can only have direct influence from internal states.
So if that prediction is fulfilled, you're going to see the active states organizing themselves around the internal state and so forth.
So that's the idea.
What we want to try to ask is if we're comprised of a bunch of different cells or a bunch of different systems,
all of which have a Markov blanket, and we're interested in thinking about systems that are Markov-blanketed systems
in the numerous sense of being Markov-blankets, of Markov-blankets.
Then we want to try to see if we can scale those simulations up,
so if you have the self-organization of Markov-blanketed systems at the micro-scale
and Markov-blanketed systems at a much larger scale,
comprised of a bunch of other Markov-blanketed systems.
Sorry for saying that word by many times.
So here we have 16 ensembles, comprised of 16 cells, 256 cells in total.
Exactly the same as the first simulation.
Each cell comes equipped with a generative model,
but this time of its identity at the micro-scale and at the level above at the macro-scale,
what particular type of cell it's meant to be, whether it be an active sensory or internal state.
Given posterior beliefs about its role in both scales of organization,
the cell or the collective can predict the local and global intracellular signals it would respect to receive.
The ensembles, or the collective of collectives in this case,
have a point of tractor to which it converges, just as in the previous slide.
Again, the point of tractor is a Markov-blanket,
where the Markov-blanket is made up of 16 photoplankets.
So we can see, take an individual cell here, like that one,
see it's comprised of internal states, active states and sensory states,
and similarly you can take that for the much larger or bigger Markov-blanket,
which is comprised of the large red cells, the large orange cells and the large yellow cells
distinguished from the surrounding blue cells or the darker cells.
So the organization of the macro-scale Markov-blanket can be thought in this case to be involved
in free energy minimization, just like the organization of all the Markov-blankets at the micro-scale.
That should follow fairly straightforwardly from the claim that,
if you think about the minimization of free energy in this particular cell,
it's carried through by internal states, active and sensory states,
something similar is going to happen when you scale that picture up.
So there's no principle reason for thinking that you can't recursively scale up this organizational structure.
So in this we've only done simulation of how cells that are Markov-blankets assemble into systems
that are the larger scale that has a Markov-blanket,
but there's no reason to think that you can't have much larger and larger Markov-blankets,
comprised of even larger Markov-blankets.
You go all the way down, which we've heard, you go all the way up to UNI,
and in certain cases I suspect we can go out to include part of the environment as what comprises our Markov-blanket.
Okay, so here's just a few implications.
There seems to be kind of no unique or fixed Markov-blanket that we can appeal to.
If there is a Markov-blanket and that Markov-blanket can work as a boundary of the mind,
it seems that we should accept that the mental boundary is multi-layered and nested.
So this doesn't prove anything, but it opens up the door for thinking of the boundary of the mind
as not simply being the boundary of the brain.
Appealing to perception and action is setting a principle boundary for the mind as unlikely to work,
putting channels as internal states in the Markov-blanket can all be cast at doing precisely the same thing,
optimizing model evidence, which is the same as minimizing free energy.
I don't want to, actually, I have put that in just in case I didn't have enough time,
but since I am nearly out of time, I'm going to skip my own objection.
Thanks.
Thank you.
The first question would easily be, if you would like to do a presentation.
Sure.
But Ken, press, and then, for the back, please, can you hand up the phone for me?
Thanks for the topics of educating me on this business.
You said there are nested Markov-blankets.
Okay, so I want to ask you, and that slide from molecules to ecosystems really caught my mind.
So I want to ask, no, one before biological systems.
So how far down does the Markov-blankets go?
Are the absence in our eyes, do they have Markov-blankets around them?
Do they have atoms and ions that, you know, they have?
Are biophysicists and biochemists missing something by not learning about Markov-blankets?
Or does it go down to a level of where the minimal cognitive is, as I call it,
defined cognition, which is some form of defining boundaries?
Pharrella and Thompson, who's the other, what's the other name?
Well, I guess the simple sort of answer to that question is,
wherever you can find a statistical separation of internal and external states,
states through a set of other states, you're going to have something that has an open field of Markov-blankets.
So how do molecules?
So if it turns out, not a molecular biologist,
but if it turns out that you can carve out that separation between internal and outer states,
given a third set of states, active and sensory states, then you have a Markov-blanket.
Yep.
Oh, sorry.
This is just really sort of adding Christy on the other thing with regards to the nesting of Markov-blankets.
But in the upholstery newspaper, he points out, in a small paragraph,
that you can actually, by taking the sort of bottom level of a generic model out,
you effectively have a Markov-blanket predicting that all the states up,
all that it lays in the model up until that,
and until that later you can have a Markov-blanket that's doing the job of predicting
what that top model is going to send back.
So it looks like you can have, as you say, you can have Markov,
you can extend the Markov-blankets outside what we used to think was the mine,
we can make it right down to the cellular level and beyond, perhaps.
So within what we traditionally think is cognition, you can have, I think,
a quote-unquote-trainish cognition.
Notice that at no point in this talk have I said something like,
will we be defending that there is one Markov-blanket that rules them all,
or there's one that owns them all?
No. If you're committed to hierarchical predictive processing,
or just hierarchical generative models,
the reason, in part, that you have those is because you've got Markov-blanket
organizations running up and running down the hierarchy.
Yes, I guess what I was wondering is this,
whether it's the same notion of perception and action all the way,
if it kind of seems like it needs to be, for the argument to go through,
I'm sympathetic to the idea that it is, but I think if Dave was here,
he would probably say, well, I understand what you're saying about cells and livers and so on,
but they're not consumers and actors in the sense that I care about.
So you've given us a sense of perception and action,
which is convivial to a best-in-Markov-blanket story,
but can we have more reason to believe it?
Yes, so I don't think that the account that I've given of active and sensory states
at all mirrors, I might think that Chambos was thinking of action and perception.
I don't think so at all.
I think he means me visually perceiving you as you're sitting there.
Maybe even consciousness gets him.
It could be the case, but I don't really want to touch consciousness.
Yes, but that's not the topic.
Okay.
So I think one observation or one remark would be there's no reason for thinking
that you have to have a kind of commonsensical view of perception and action.
That's a way in which to think about where you've got intuitive boundaries
of certain cognitive processes or cognitive states.
We're more than willing to grant that cognitive processes don't fall at the level below experience.
And there I take it that how individual neurons react and act is quite dissimilar
to how we would think you and I perceive an act.
But that doesn't really count against us thinking that these sorts of processes
are part of processes we're willing to call cognitive processes at a sub-personal level.
So that would just be one reaction to why I don't see a deep problem with reformulating
or tinkering with the way Dave Chalmers sets up the perception, action, and distinction
and the way it's worked through, say, the Markov-Lankin formulation.
I also started by saying this is something similar to or akin,
not the same sort of notions as he might operate with.
And just a footnote to that, I think he's more than happy to reformulate
and tinkered with the kind of commonsensical perception and action.
Yeah, I just thought it was one thing in the part that I'm entitled to
and I think there's a difference between bringing with structure the world interview
and just as it were, minimizing your free energy to hang around a bit longer.
Which is what the other stuff is doing.
What sort of difference is that?
So you could, I mean, I guess you could from a certain point of view say
that is just to minimize free energy, couldn't you?
And you have described it in a particular way.
That seems not quite to be the same as straightforward free energy reformization.
Yeah, I have to think about that as a good proposal or comment.
My guess is from the talk you've given,
you don't spend a lot of time lying awake late at night
wondering about whether there really are Markov blankets.
And I'm not sure that I do either,
but de-entertain the possibility there might be sort of approximations of Markov blankets
with big holes in them that change and that need to be sort of improvisational.
I'm thinking about it on the analogy to sort of modules, right?
And the old sort of literature in the 80s when the modularity was really big.
There were the sorts of ways of defining what modules were
which gave a certain kind of insulation of certain units within the head, right?
And there were notoriously sort of leaking and incomplete and they were partial
and there were idealizations that we could, if we made those assumptions
about how language processing would pass, we could make lots of sort of progress
but there were completely idealizations.
I'm going to ask the question is how much of an idealization is built into this idea of Markov blankets?
Sure.
It's the same sort of question as the metaphor questions earlier in the morning, I feel.
I was just kind of using this sort of terminology
shorthand to describe something that's not really there.
I think there's no harm in just thinking about anything that can be separated from something else
giving a set of mediate states can be thought of as a markov.
So that just gives you a kind of grip to speak about if you like statistical relations between states.
And that's all the blanket does.
It's not as if, I mean, if you look up to the standard machine learning textbooks
and you look into the features of the Markov blanket,
you're not going to find it to have sort of causal powers.
It's just the way of separating certain states from other states given a third set of states.
That's all the terminology allows you to do in the initial setup before you start building material
and then you have to justify.
Is that okay? Is that helpful at all?
Yeah, that's okay. It just seems like it's doing a bit more metaphysical sort of work here
in terms of separating the boundaries of the line, for example.
Yes, sure, that's true.
But it's also embedded within a philosophical discussion with that particular blanket plays
or the notion of a blanket plays a particular role,
at least in a certain set of arguments for making that boundary between a mental and a non-mental.
And what I'm trying to do is simply to say,
well, it's not altogether clear where to draw that boundary if you're comprised of a whole heap of these Markov blankets.
Then you might think they're not booking that the bummering can move up and down.
Okay, thanks Michael, that really was very, very good.
I am going to give exactly the idealization objection tomorrow,
so I'm not going to say much about that now.
I think there is an issue about taking the original Markov blanket idea from Judea Pearl
from the machine learning literature,
and then making it do all this kind of causal metaphysical work.
I mean, that Kristen and Rika Allen point that we had, that's causal patterns in there.
Yeah, sure, I understood that.
So look, I'll leave that aside, because we've just discussed it out there.
I'm going to put my Yakub Herbie head on for a minute.
I'm going to turn and just leave you over there if you have an answer to the question.
It's on the list.
It's on the list.
You know, Yakub's point here is that the precision estimation functions of the brain
are always behind a Markov blanket relative to the environment.
So that's the boundary that counts.
And so you can have, you know, extensions of Markov blankets,
you can have Markov blankets within Markov blankets
to do various kinds of self-organizational work.
But really here, to understand those precision estimation functions,
you have to think of the Markov blanket as separating the internal states of the brain
from the external states of the environment.
Yeah, okay.
I take it that that is the argument, at least in part.
But notice that as we're running the argument that sort of leaves the precision estimation,
the machinery is slightly aside.
And that's just the kind of pure self-evidence in Arizona,
where I'm making predictions about what I'm thinking of post my sensory protocol,
and so far I'm all my brains doing a particularly good job here.
Lessening and lessening and lessening the divergence here in KL
or just the minimization of the prediction error.
And in that sense, I'm gaining evidence for my own predictions.
So that shouldn't do something like an epistemic, at least, boundary
between predictions of the internal prediction machinery and then the external states.
But that doesn't apply to the precision estimation machinery.
I imagine you put that back in.
Then you can definitely be skeptical about whether or not you need them to say
it's only internal neural states that can play a role in setting the game
on how reliable something is.
So if you think about if the Markov blanket of Markov blanket U
can be recursively scaled up to include external features of our environment,
then you might think, for instance, the example of the white lines in the road
that has particular regularity, you can always expect it actually reduces
the uncertainty of the error signal itself.
So if you can just gesture it, you don't have an argument for that,
you can think of that as being part of the state's comprise by your Markov blanket.
Then you have an extended notion of a Markov blanket,
and you've got external elements that can play the role of something
that we normally associate with, or something that is associated with
internal neural states, precision estimation.
Paul?
I just didn't understand something.
Can you go back to the third slide, the one with the three pictures on it?
I have, yeah.
It makes it easier to explain what I'm saying.
So when you go from A to B, you switch from, you know,
discord to a little interaction.
But what's actually going on there is just you've introduced spatial structure.
So let's go to the one on the other side.
So if I was thinking about that as a population of organisms
and thinking the same terms, sure, there's a boundary,
but everything in the figure is equally consistent
with being able to re-center to any known and generated new boundary.
So there's another assumption going in there, roughly the existence of the boundary.
The actual causal matrix is one where if you re-center to another,
the actual, in other words, you haven't shown all the little local interaction arrows
and the structure in that causal graph is such that you're getting a boundary.
So what I don't get is I didn't see anything in the formalism
that tells me why, all the way through the rest of the talk,
these things were being strictly nested.
It's not just that they're, apart from maybe that Tristan quote,
it's not just that there are little ones
and there are big ones which have been almost within them.
It's strict nesting. I didn't see anything that,
where the hell is the strict nesting coming from?
I see, I understand.
I don't think you need to have, this is not the strict,
this is not an image of something that's strictly nested.
No, but all the cells are all of the, you know, cells of our local hierarchy stuff.
It's all strict nested hierarchy.
So is that in fact just, does that follow?
Well, it follows in the world of, in the simulation world I guess,
where you can, where you can see how,
what's a different example, take a conventional example.
Yeah, maybe we can talk a little bit about a different example.
So that's, there's a bunch of molecules moving in a particular way.
A certain threshold of temperature gradient
gives rise to a particular rolling motion.
One way of thinking about that is,
you've got a conventional rolling motion
comprised of individual molecules.
Yeah.
That, that okay?
Yeah, that's alright.
That's alright.
This is really, as a journey, I just, I mean, I just,
I don't understand, whether or not the total definition needs to be
some nifty trick.
No, I don't think so.
But here we're just doing sort of something similar to the
convection rules.
An example is you've got, you've got some cells that comprise
the mark of blanket.
That cell can then be part of what organizes something
at a larger scale that has a mark of blanket.
In the same sort of way you've got automatic tools
that can come together in particular way
and form a rolling motion of oil.
Nothing, nothing more complex is going on
and I'm not trying to say anything more.
Have you been to that?
A tiny comment that I didn't understand.
That's not really, I think,
you think I'm objecting to something I'm not.
I'm just trying to wonder if, we end up in the last sort of
slides in which you've got these bounded units
within a bigger boundary unit.
I was trying to find something in the formalism
that stopped the bigger boundary unit from slicing
to the middle of the smaller boundary units.
I couldn't see something, you know,
why can't we have in your final diagram
where you've got the 2 and a 61 nodes?
Yeah, everyone's right.
Why the big boundary can't whack through the middle
of one of the little boundaries?
I guess my question is, is there some story
given the build definition?
I'm not smart enough to see what it is.
I don't know.
It would be really cool if there was a reason
why that had to be the case, but it isn't.
Then the whole world opens up and you're dead.
That's true.
Yeah, I just don't want to cook off an attempt at that.
That's what I'm saying.
I think there is on that particular point,
I think that this violates the definition.
I think it violates the definition,
violates the condition of the dependency
of the individual.
It would, but then you can see it just
right.
So what I'm going to do is there is a nice
of a proof that if all of a sudden
units meet the mark of boundary condition
of the third law,
but any ensemble of them are on the opposite.
I want to say that there must be a difference.
There must be a difference.
There's a difference, of course.
The point I wanted to make,
because I thought that I thought
about at the moment, is one way of thinking
is that the flux of decision-making
changes the effective mark of boundary
organization of the realm.
So from tasks to tasks,
you've got actually a different set
of mark of boundaries.
I think once you've got that amount
of places to stop into a system,
you're going to be blessing
by the thing that the mark of boundary
is just kind of where the mind stops
and the world begins.
Okay, thank you.
I'm wondering if you're delivering
the victory that the extended mind
defenders want and need.
So there are two reasons for this.
The first one is that,
as you say, conditional
dependencies are everywhere,
and you can easily draw a mark of
boundary around you and your iPhone,
and we'd also draw a third thing
or out or whatever way.
So you get extended mind,
but in a way that's kind of really trigger,
and maybe that's not what it wanted.
So imagine an alternative
history of cognitive philosophy
or whatever, where we all
were extended cognitive services,
and people come around, you come around
and say, well, we can draw the boundary elsewhere.
So that's the first reason.
The other one goes back to
Charlie's definition that you started with.
I couldn't say to a step, it's an extended
condition or an extended mind.
We have to have something outside
of the agent, outside of the mind,
that is part of this mental state.
But the moment you draw the mark
of the blanket, such that
it includes the iPhone, then
that's part of the agent.
The agent is defined by the
mark of the blanket.
So now you actually get a self undermining
argument. You can't be
an extended mind defender
if you start drawing mark of the blankets
around the things you want to extend
the mind to.
You draw a mark of the blanket
to include the iPhone.
Not to exclude the iPhone.
Then it's not external.
Then it's part of the agent.
That's enough. I think that's
actually fine.
Just to speak to that a little bit,
so that just goes against the view
that you start as a single agent
and then you kind of hook up to
something that then extends.
You can start from somewhere else
and think that the system is extended
to the first place.
So the basic set up there is
that cognition is extended
and then it's only special cases
that it's not. Like when I dream about
for instance this kind of thing
at night.
So that would be one way of answering that.
So the first one was
trivializing the claim.
So the notion of
mark of the blanket is so general
that it's going to talk
about external in terms of
means nothing much.
That's sort of the same worry that
you can describe
quite a fair number
of not all systems
that's free energy
minimizing systems and worry about
the explanatory point.
But even if
it's a trivial set up
sorry I'm just thinking my way through this
I don't have the ready to hand that.
Even if it's a trivial set up that I
when incorporated
in the right sort of way with my iPhone
comprising cognitive system
that follows very forward
given its formalism can still say
that there's something external to that blanket.
Yeah.
Presumably.
So it's not the case that it just
kind of balloons out of the portion.
That's in the kind of cognitive
global objection I'm taking which would be trivial
because then you would find cognitive processes
everywhere you look.
So even if it's
fairly simple to draw a boundary
around me and say the microphone
or the iPhone there would still be something
external to that particular boundary.
I take it.
Otherwise it wouldn't be a microphone
actually in the first place.
And that doesn't sound trivial to me.
All it does for me is just in Europe
you still have to do explanatory work
I take it.
Okay I think we're going to come back to that.
We've got time for two more short questions.
No? Back here.
Chris and Ian can you run up
on my phone?
I can try. Thank you very much.
I just wanted to ask you
but I've been wanting to for a long time
how does it connect to the
third wave extended cognition
and just send them
so they are deterioralized
is it cognitive science?
Deteriorized.
That's right.
Probe-gaining internal and external media.
Well
I take it just
for me very simply
it connects in the sort of following way
that
the mark of blanket comes with a set of properties
but
where you draw the blankets can be
negotiated.
In other words there isn't a clear
and only one boundary.
If you can think of the boundary of the
mentors being quite flexible
then that boundary
is up for renegotiation
given if you like constraints
of
ecological constraints
social cultural constraints
biological constraints
that's just how
I draw the inspiration there
from that particular quote
I don't mean to make a big meal of that.
Next question is
on this slide.
Do you have a question sir?
Yes?
You have a question? Yes.
Sorry.
I have a broad exploratory question
so I'll try to do it quickly.
So I've wondered
for a long time I've liked the
predictive processing approach
and I wondered how it dealt
with communities of cognitive
agents of human beings for example
in the sense that
it's
it's based as a word as the individual
organism and it gives a very
interesting account of that
but I was wondering if the mark of blanket
of matter
I wonder if that
suggests the possibility
of thinking
of
various
short-lived communities
of cognitive agents
like people doing something together
and longer
and larger ones.
And because
there are very interesting concepts and problems
relating to that from earlier
discussions for example
problem of common knowledge
and how to model that and so on
and problems
about shared intentions
in communities of robots and so on.
So there are many different areas in which
these problems of groups
have been looked at
and various technical issues that arise.
I'm wondering if your approach
has the possibility
of being used in a way so that
each of the individuals
has
a mark of blanket account
but also the kind of
system whether it be smaller, large,
short-lived or long-lived?
Yeah, I don't think
the notion itself
has much to do with
the kind of the temporal span
over which
you can pick up
that particular separation
between states.
The notion, not on my approach
but just straightforward here,
can be used to segregate
sub-cultures from
mainstream or individuals
in society from larger groups
of individuals.
And I mean there's nothing
it's not
uniquely special
to biologists.
Thank you.
Thank you.
Very quick.
We'll just take a quick five-minute break
and
