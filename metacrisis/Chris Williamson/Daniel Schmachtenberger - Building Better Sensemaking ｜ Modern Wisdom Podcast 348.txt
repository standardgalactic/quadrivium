i actually want to understand the world i live in as best i can because i actually hold that life is meaningful and i hold that my life could be meaningful which means that my choices can be meaningful and so i want them to be informed as well as they can be.
What i think people really liked about our first conversation was that we brought some of your work down to an individual level so a friend referred to it as creating a narrative of resonance and given that i thought it would be nice to stop by looking at something that you talk about a lot which is sense making but from the level of the actor so how do you define a sense making agent.
Well i don't know what background the other people listening to your show will have on the general topic when you're mentioning individual agents i think you mean individual humans obviously an organization can act like an agent act like a unit of agency but i think you mean.
Individuals seeking to make sense of the world they live in better we often times talk about sense making at a societal level meaning.
I am currently it comes up a lot like why do we have such a hard time coming to clear understanding about what the nature of climate change is or what the nature of.
Covid viral origins or vaccines or whatever your systemic racism or how we should deal with nuclear disarmament or why does it seem like there are such radically divergent views meaning the way that we're sensing the world is leading to very different senses of the world.
Which of course leads to very different senses of what should happen which makes it very hard to coordinate which makes it very easy to have conflict and so we're talking about sense making we're usually talking about it in the context of shared sense making.
As a prerequisite for shared choice making what i.e governance sense making is not the only prerequisite when we talk about governance and i governance i don't mean government which is a maybe a specific establishment that has a rule of law monopoly of violence but governance meaning some process by which a bunch of people who want different things and see the world differently come to coordinate force in some effective positive productive ways.
So we're talking about how do we get people to have some kind of coherence coordination between the choices they make such that it.
Isn't making choices that we would think of as crime or something that really messes up each other's choice making capacity and where we need to coordinate on choices like we're not gonna make our own roads and things like that we're able to coordinate effectively regarding shared resources shared infrastructure.
Happens to be that lots of humans who don't know each other and have experienced the world differently and feel different things and want different things coordinating on what the right choices is a tricky thing because they have a different sense of what is and what they want what should be so this is why for most of human history the number of people that would coordinate with small tribes were small they classically stayed.
Beyond you know smaller than the number number give or take hundred and fifty ish where there were no strangers everybody that you're coordinating with you know your whole life they had known you your whole life.
Everybody had the same shared basis of experience and everybody could it be in a single conversation on a campfire and so the ability to coordinate.
We could coordinate sense make is we're sensing the same stuff we're living in the same place right we're reading different books we're watching different tv shows like we were nobody had been speaking different languages were exposed to the same stuff.
And so you can also fact check anybody just by looking there right by just having such a shared basis.
And it was pretty easy to unify values because the culture that had conditioned them was the same culture.
So there might be little differences of waiting and so then the ability to you know unified choice making if we have shared values and we have shared sense of the world to both what we think is and what we want to be it's not that hard.
Once we started to get to larger scales where now I've got to maybe make compromises for strangers.
I've got you know we're gonna have some coordination with people who I don't have any shared sense of real fealty with whatever that becomes a different talk and where they really do see the world differently.
And so this is where mostly the order came through some kind of imposition or oppression or top down force which is why it was largely empires.
Okay and then that still meant a number of people smaller than Dunbar that would equal the king and council making the decisions and imposing it by rule of law and force on everybody right so shared sense making didn't matter.
Because people didn't really have meaningful choices they were gonna do the thing that they were gonna do within that context.
So the idea of something like democracy or a republic or an open society where some humongous number of people who don't know each other who don't have the same experiences are all going to.
Not just do totally different stuff that creates chaos but also not need somebody to kind of rule they're gonna find order that isn't imposed it's emergent order that's actually a wild idea right like it's a really wild idea.
That would even be possible and you know the modern democracies came following the enlightenment the cultural kind of European enlightenment with the idea that we could have this thing called the philosophy of science.
Where we could all measure the same thing and get the same result independent of biases didn't matter you know what we thought beforehand if we measure the speed of sound in the right way or whatever it is we're gonna get the same results there's this unifying nature of objectivity that allows us to sense make together.
Which is why Karl Popper who advanced the philosophy of science was the guy who turned open society right that we can do open societies based on.
The ability to do shared sense making using using a more methodological rather than I had divine revelation and it's true and you don't know kind of approach and.
And then but like we said the idea of governance is that there's some kind of emergent choice making or order at the level of the choices we're making the choices are both the result of our sense making what do we think is actually happening what do we think the cause of what's happening are.
And if we do X what do we think will happen right that's kind of forecasting sense making.
But it's also what do we want to happen which is our values which is not sense making sense making is sensing what is the values is what ought what do we think ought to be what do we really care about so we can call that values generation meaning making.
So sense making and meaning making are the prerequisites for choice making the thing that we call governance in an open society is that there's some coordinated process for choice making.
That doesn't have to be imposed by King doesn't just turn into there's no way we can get on the same page that has to be chaos because we can sense the world together and we can sense each other's values and find a higher order set of values includes everyone's this is another part of the enlightenment was the idea that we could do a dialectic on values.
You could say I really believe in doing X whatever X proposition is more like why do you want to do it well because it's in service of.
Decreasing infant mortality and the value that you have is infants and we're like yeah but if you do that thing it'll be bad for this other thing because it whatever it'll damage the water supplies what you care about the water supply.
Let's not focus on the proposition for a moment what you value is children what you value is the water supply let's hold all those as legitimate values right what you value is individual freedom what you value is the responsibility of the individuals to the collective that they are benefited by.
So the ability to hear each other's values and synthesize and say a good solution will meet everybody's values as best as possible.
So often we get stuck with you know a proposition is created to meet some value before even looking at what all the values are and so it benefits the environment but it hurts the economy or benefits the economy and it's the environment or whatever it is.
So those who feel particularly connected to the thing being hurt or like this is terrible we have to everything to fight it.
And those who feel connected to the thing that's being benefited like this is critical someone finally gets us now those two sides is have to become enemies.
If the only chance they have is to vote on a preexisting proposition that is a shitty proposition because it was based on the theory of trade offs between those it was never even consciously explicated they never even said oh this is gonna harm this thing both of your values is can we take these values and find a better way forward better proposition.
It may be could meet them both better maybe rather than that bridge that is gonna harm the environment the way that it is but helps transportation which will help the economy a barge could do it without harming the environment or we could just build better local economies on both sides or whatever it is right.
So the dialectic process is where I want to hear the values that you care about and so you believe everyone needs to be vaccinated or no one should be forced to be vaccinated or everyone should have to wear a mask or nobody should what is the value you care about independent of the strategy the strategy is the way to fill value there is something legitimate in the value even if.
Then the sense making about is that thing about vaccines or about masks or about whatever is that true is separate from is that value legitimate right.
And so if so we don't have participatory governance in the US we don't really in the world in any very meaningful way we have the the legacy story of it but we don't have a population.
Hardly anywhere that are really seeking to understand the world we live in where they're where the government is gonna make choices on stuff.
And for the government to be informed by the people that we understand enough to be able to weigh in well and we seek to understand our own values and other people's values and be able to have the dialectical conversations to see if we're missing some sense making somebody know some stuff we don't we really want to hear it rather than have our.
In group continue to feel right by saying how dumb the people in the out group are.
So there isn't anything like participatory governance which is why open societies are basically failing and doing should leave all the authoritarian societies that aren't even claiming to do that and are just doing top down government better just doing better at long term planning infrastructure.
So.
You know people will hear me talking about sense making usually it's in this context of how do we develop better capacity as a society as a whole.
For everyone to be doing a better job making sense of the world and just believing whatever happens to come through the Facebook feed is algorithmically optimized to appeal to their current biases and kind of limbically hijack or maximally bother them.
And drive in group dynamics where people's fear of being out group by believing the wrong thing in their.
Messes with subtle deep tribal biases.
How can we do better job with sense making at the level of training individuals at the level of how we change education and train people and at the level of the quality of media we put out at the level of how we design the information architecture so that rather than a Facebook or YouTube having an algorithm to maximize time on site.
That it does through appealing to your biases which make you spend more time it which makes people on the right more right the left more left anti conspiracy theorists more hate conspiracy theorists conspiracy theorists farther down that direction.
And so there's this just hyper fragmentation as a result of the financial model of this information technology right so how do we make better information technology.
How do we make better media and for the state how do we do better education all those things so that we can actually have better sense making about what is real.
Better dialogue and communication around what is meaningful or the values so that that those types of conversations can lead to what would a good proposition even be that meets that factors all of what's real as constraints factors what matters as constraints and works to find the best proposition forward.
So if we take as the background that's the societal context of where we're usually coming from and talking about the needs for sense making.
That was a long preface to then say you want to bring it to the level of the individual and say alright so I'm not trying to fix Facebook's algorithms for sense making right now I'm not trying to necessarily fix participatory governance or democracy or the fourth estate or public education.
I'm trying to say how do I as a person do a better job of making sense of the things that I should make sense of that affect the choices I need to make in the world what things should I just actually not bother myself with because I really don't have a choice and it's not the best use of my life energy.
What things should I or do I care to and how do I do a good job and how do I know if I'm doing a good job because almost everyone that we're sure is wrong is sure they're right.
And so we are one of the everyone that they're pretty sure is wrong right and so we should all be pretty dubious of our own certainty statistically.
We're almost certainly wrong about most of things that we're sure right about.
And that's dangerous right like it's dangerous that.
I'm clear about lots of things I think other people are wrong about.
And I'm clear about a lot of things I think people in the past were wrong about.
And I'm clear about things that I was wrong about in my past.
But I probably can't say anything that I'd say I believe today that's probably wrong.
That's that's tricky because it's probably mostly wrong.
And so how do we.
And now when ego gets tied up in that right and then when belonging gets tied up in that if I don't if I don't say the right narrative about.
Masks or about vaccines or about social justice I'll be totally out grouped right because now I'm a anti-vaxxer or a sheeple or whatever it is.
So there's a lot of reasons to have everybody double down on their worst traits of unwarranted certainty and sanctimony.
So if we want to ask the question.
How important is it to our own life to develop our sense making?
How do we know how well we're doing with it?
How do we do it?
We can get into that more.
Absolutely.
One of the things that I've got in my head there is how much more considered and slow decision making at the governance level would have to be in order to factor in all of these different values and choices.
No expediency is something that people value if the bridge needs to be built and people think that it's going to make their life better.
But in order to factor in everybody's different values it's going to take two years of debating and planning and all of the rest of it and that situation of consideration and being moderate and more nuanced with your thinking.
That happens at the individual level as well right it's far easier to just react take something that we think is the closest approximation of correct and just move forward.
No this is gibberish argument.
So let's say we don't have clear sense making on a topic but we have to act.
Why do we have to act are there are there real consequences are just made up bullshit like an election cycle or whatever that we could change the way we're doing governance if there's real consequences how consequential is it to get it wrong.
Well it might be more consequential than taking more time right it depends there are times we have to make consequential choices under uncertainty we're not choosing fast enough is also a choice that's a real thing.
But it's that way less often than we pretend that it is.
And so then what is the consequence of getting it wrong and doing something much might be much more harmful.
But also what's the what is the time effect of moving forward with something because we just have to move forward that a huge part of the world thinks is wrong and bad and are going to actively keep fighting like how efficient does that end up being.
They're all going to pay lobbyists they're all going to help pay for academics to sponsor counter narratives.
They're going to pay for politician candidacy processes and whatever it is so how fast is it really in that being to try to advance something that half the world thinks is a terrible idea.
And so what you can see is we try that we're like no the science is settled that's a famous bullshit line on a million things right.
And you'll see it on both sides of all kinds of things.
The science is settled is just a nice way to say my unwarranted certainty is true.
But the the science is settled climate change the thing it is we got to move forward we and we don't have time to educate you dumb fucks anymore about it and we're just you know so we're going to carbon trade this is the way to do it or cap cap and trade carbon tax whatever.
Okay well how well does that work when all of the groups are going to keep lobbying against it and getting Republican candidates who will then try to undo the laws and four years that those.
You spend four years trying to do the shit knowing that the next four years will undo all of it.
And actually you never even plan on doing something that won't have returns within those four years because it won't possibly get you elected and all the things that need done need to have 1020 3050 year timelines and no one will ever even look at it.
And most of the time you're actually just working on getting political support and campaigning to be reelected.
So the expediency we just have to move forward is usually a bullshit argument for someone in a power position moving forward in a way that will advance their power position.
With plausible deniability that it's something else.
If you want to move a civilization forward.
Either you're moving forward in a way that everybody's getting on board with.
Or you're deciding to use force to oppress the fact that everybody's not on board or you're deciding to keep fighting the fact that they also have force like you just have to be realistic about that.
It's interesting the option of delaying a choice is also a choice there's always a third option of being more considered.
Yeah I like that.
Okay so back down to the individual how how can someone become an adept sense making agent.
We're at the mercy of certain things that individually immediately we can't control.
Therefore making the most of the capacities that we do have is a good idea.
I would not say the answer for this is the same for everybody based on.
What they feel called to their dispositions there.
Their vocation and their kind of sense of what their mission to do is.
If.
Someone is a nurse caring for patients if someone is a mother raising children.
How much does them understanding what's really happening with the digital you want and whether it's going to become the reserve currency of the world or whether or not the US micro grids are susceptible to EMP attacks like how much does their sense making matter.
How much agency do they have to do fucking anything about that pretty little.
How much does it likely stress them out probably a lot.
Does that make them a better nurse or mom probably worse.
Could that same energy be applied to doing better sense making about tuning into their children and their patients better and where they actually have some agency.
So it when we recognize that sense making is to inform choice making right.
Do I have choice around this thing like what is the basis of why I'm wanting to do sense making is it simply because.
I need to know which side of the narrative or I'm on because I think I have to be on one of the sides what if I just don't what if I say I don't know.
I don't I don't I don't know what I think about systemic racism know you have to know but I don't.
Well.
You know and people can try to do a forcing function and within your complicit or whatever it is.
Okay well I can put a huge amount of time and energy and then still not actually have any real agency to move this thing forward given where I am in my life.
But I can put that energy into studying better nursing or whatever it is right.
So I don't think that the idea that like everyone should be deeply informed about all of the existential risks and understand the entire effect of the tech stack and globalization and planetary boundaries and geopolitics is like a thing that everyone should have.
I don't think that's true.
So the first question is like what matters for me to make sense about based on what choices I actually have to make in my life.
That's an important question because it's easy to get sucked into the thing for somewhat unconscious reasons.
Now we can talk about how to do good sense making on geopolitical and environmental and complex scientific topics there.
But the first part is make sure like make sure that the reason that you feel called to do that makes sense.
And I'm of course not saying that if you don't have a company or an organization or you're not a politician of some way that can directly affect that thing you shouldn't know anything about it.
There is something about general informatness as a citizen that can have value.
But you do want to pay attention to like I have finite units of life energy.
And where do I want to put my attention that is also connected to my creativity.
So I want people sense making to be informing their creativity right to be informing their agency and their choice making and the quality of life for themselves and the people they touch and for the world at large as they can touch it.
Now how to actually do good epistemology we can get into next but does that part make sense.
Yeah absolutely I'm interested to hear what the underlying principles are presumably there must be a structure upon which are some commonalities that all sense making agents whether they be the nurse the government official the creator the mother.
Are there some commonalities between all of them.
Are there commonalities and how to do good sense making in any domain regarding regardless of the domain sure they're going to be different there's certain places where it's like.
How to get how to really get this particular kind of backflip is not something I get from reading Wikipedia like I only get it from trying to do backflips like it's an embodied sense making there's like oh I clicked and I got it.
And there's no amount of reading Wikipedia that's going or watching YouTube that's ever going to give it to me.
So there isn't like one type of sense making like there's no amount of reading music theory that will actually get my fingers to grok how to play Chopin so there are different kinds of creative capacities that require different kinds of like.
Because you're sensing how something works right sense making is not purely cognitive it's taking your senses and having a pattern emerge sense making of like I got it we've all had that experience playing the piano trying to do the backflip where it's like I got it that sense making.
Of a type that's a bunch of sensory perceptions that came into a pattern where now I have it in a way that can inform my creativity.
Right.
But I'll stick in the cognitive domain for now.
Since that's largely what I think most people are talking about.
Some super helpful basic tips.
If I'm trying to make sense of a topic.
That is conflicted with where the public opinion on it or even the scientific opinion or whatever on it is highly conflicted.
I should understand the conflicting views before coming to one on my own.
That's a that's a very helpful thing to do so.
You know you were mentioning how do I do better sense making of nursing.
Well let's say I'm a nurse and it's covid time and there's like major conflict of this ivermectin work or not.
And should we be doing this with people and.
You know who do we think actually has too much contraindication for these vaccines or whatever it is like those are places where a nurse would actually maybe want to do some sense making.
Now they might not feel that they have any time.
They might not feel the agency that if they came to think something different than hospital policy they could do anything other than get fired.
But they still might care anyways because like fuck I signed up to this thing because of a calling in an oath and I need to know right.
So.
One place there I like to start as I like to see okay.
Are there two primary narratives or are there a few narratives right let's begin say there's two narratives.
Ivermectin really works and it's awesome it doesn't work at all and it's dangerous right.
Typically there's more than that typically there's like five or six maybe it works early case but not later or works for these kinds of situations or there's some indication works but we don't really know or whatever.
But let's take kind of primary narrative camps because in today's.
World most people are trying to sense make between pre existing narrative camps.
And it's kind of important to understand.
There is a very strong incentive for everyone to fall in narrative camps are basically these strange attractors.
And so there are underlying forces that drive what you can think of as polarization to rather than just like well whatever is true it's going to be.
It's much easier to believe something is true that someone with expertise says with a lot of certainty and other people agree with.
Especially if there's a lot of literature and I'm unskilled or I don't have the time how I'm going to read all of it myself.
And then you get a narrative and then you get people say that narrative has something false with it and they do a counter narrative that is usually an anti narrative that are also kind of smart.
And typically based on either a different emphasis and values hey this is about personal freedoms this is about public health.
This is about my right to decide on my own body this is about not being a grandma killer whatever it is right.
Sometimes it's just a difference of values that affects their sense making.
Because they're sense making the thing that seems most aligned with their own values are not actually paying attention to the sense making they're looking at the narrative of truth that fits the value that they seem to care more about right.
I don't think anyone should be comfortable with the idea of more imposition on people's personal freedoms than necessary and I think everyone should be dubious of anyone who feels that they are in a position to say what is necessary and impose it by force.
Like everyone should be dubious oh you have a monopoly of violence that can impose necessary limits on everyone's freedom and who is the authority like what is the authority process that is not influenced by power or fucked up motives or ego or mistakes at all that deserves to have that fucking power over everybody.
Like everybody should be legitimately concerned about that that there is such a thing as adequately legitimate authority to wield monopoly of power.
Simultaneously everybody should be legitimately concerned about.
Unnecessarily being a grandma killer right like about taking a risk as a young person that would be not that consequential for you probabilistically they'd be way more consequential for other people and everyone should have some sense of like yeah we actually have a duty to each other we have a social responsibility
a social fealty that insofar as we're affecting each other we're not just automata.
And if we can affect each other invisibly but still tangibly there's real consequence to that like.
Even as libertarian as I want to be non aggression I don't have the right to come up and hit you in the face right well do I have the right to dump toxic waste in the river on my property if you live right downstream for me and that's the river that.
Feeds your well no I'm aggressing on you right so if I'm sneezing and coughing in your space.
And I might have an infection like there's a real situation there regarding what is the limit of personal sovereignty and what is the limit of civic duty.
And everybody's comfortable and it's interesting because a lot of people really like.
Libertarian sovereignty feel comfortable the idea of civic duty to go die and more.
Including where there's a draft if it has to be right not just even where it's voluntary so like okay there is a relationship between.
Between the way that the individual affects the larger holes that they're part of and is affected by them and so how do we maximize everyone's.
Liberty and maximize the well being of the whole.
In a way that no one's liberty is unduly harming anybody else's right.
Obviously we'd like to do that with emergent order rather than impose a rather than a law doing lockdown more conscientious citizens who understand more and care more would be better.
Right if you had citizens who cared more and did the research better and really came to understand it better than they wouldn't need police they would be self.
Then you don't have to worry about who is the authority that has a monopoly of violence it's there is a.
Population that is well educated conscientious communicating with each other respectful and self policing in that way right self wandering.
So the point is that oftentimes there are these values that have to live in a dialectical relationship but we will forget that and focus on one of them.
Then we'll focus on the sense making narrative that supports that one and think and then we'll wait it's the scientists who believe in it as being credible.
And when people quote them we're like this is a credible scientist but then when someone quotes the credible scientists on the other side will say you're doing a logical fallacy of appeal to authority.
And it's like really you just did that like it's an appeal to authority when they pick their scientists but this is a credible person when you do it.
And that kind of subtle bias just all over the place right and it's fundamentally a kind of bad faith sense making that people don't even realize they're doing most of the time.
So we call motivated reasoning motivated reasoning is tricky.
And.
There's so many reasons for it sometimes I want to be certain just because.
I'm fucking scared to have to say I have no idea what's going on about super consequential stuff as a pandemic or the variance.
Going to get worse or is the vaccine going to make them worse everybody going to die am I ever going to go outside again at this guy seems really certain and the story is not too scary or whatever it is like.
Sometimes there's deep subconscious stuff like my desire for safety and certainty seems to be a path to it.
So the same place in people to get scared of the dark is just when they can't see what's going on they project nasty stuff into it.
Or they get scared of deep water because when they can't see what's going on they project nasty stuff into it.
Get scared of the unknown in general projects nasty stuff and then wants to pretend there is no unknowns they want excessive certainty about everything.
So they get scared of death and so then they want to project certainly about what happens in the afterlife and make up religions.
When you recognize that how much of reality is unknown and actually unknowable.
There is no way through other than actually there's no way through well with grace that doesn't involve deep friendship with the unknown.
Where you don't project nastiness into the dark spaces you just say I don't know like a lot of things in life have been really interesting so far and I'm curious what happens right and I rather than.
Pretend that I know and possibly steer really wrong I'd like to just keep my eyes open and keep paying attention.
So I was giving one example of how motivated reasoning and values and fears and all like that can affect people sense making their other things that can affect people sense making get into.
But the first simple principle you're saying across any domain.
Lab leak hypothesis versus natural genotic origin or anthropogenic climate change being terrible really soon versus not or whatever it is.
Find people who seem very well researched and earnest.
Who hold strong versions of the various narratives and see if you can study their narrative and the reason for it well enough that you can steal man it you can be like I actually really get and can give like an essentialized version of this.
Then when you see the difference between them see if you can come to understand why.
Like are they drawing on different data are they both cherry picking their data is probably something that neither of them are saying there is a lot of data and they're each cherry picking their each framing.
It is one of them.
Following much more motivated reasoning and less good empiricism than the other one.
But generally that dialectical process where one it'll point out to you where you're faster to start to believe in something rather than something else because of your own biases.
And if you notice that and you realize that your bias will be.
It's bias which means it misleads you mislead biases like.
If I let go of the steering wheel my car starts going left.
I have to go actually get it adjusted if I let go and it goes goes right like that's dangerous only like going to stay straight bias cognitively is the same thing it means I'm going to be veering off of reality naturally based on what.
Appeals as more true or less true to me because of.
Various things right dramas conditionings partial value sets in group identities the fact that the world of my childhood.
Is not a fair representation of the whole world but I was early imprinted that it was so I'll take those imprints on everything.
So people should be fairly scared of their own biases.
Right like they should want to seek out and find their biases and correct them.
And so anyone who gets upset when someone says I think you're wrong about something is actually fucking up their own life.
If you if you protect your biases because they're protecting some sacred thing like your fear of uncertainty or whatever.
Then you won't grow in this way and your life will stay upper bound at whatever the limit of truth that those allow you to understand and whatever vulnerable things are underneath it.
And whatever partial values are underneath it but if instead you like actually.
I don't think I can navigate well on a busted map and just doesn't make sense any place where my maps off I want to know.
By definition I can't see my own blind spots blind spot is.
Everybody has biases I can see everybody else is I'm just pretty sure I don't have any.
The best gift somebody can give me is where they actually tell me if they're like I think you're off about this now.
They can be an asshole and just judge me whatever and I still want to listen maybe they're wrong but I want to listen to see if there's possibly a gift in it.
But if they're my friend they'll be like look I know you're really trying I love you I agree with a lot of things I think there's something you're missing here.
Because the worst thing I can imagine is that I harm the things I care about or serve what I care about less well because of something I can't even see and somebody saw it and didn't help me.
So having this is another principle of sense making have friends that disagree with you on really deep things like have different biases if you're liberal have conservative friends.
If you're strongly you know LGBTQ etc have traditionalist friends.
Don't be so sure that your moral set is the only and superior moral set.
That your sense making said it's the only one have friends who have different orientations and see if you can actually see the world through their eyes in a non pejorative way.
Like oh yes I can see if I was as uneducated and traumatized and whatever is them.
But see if you can actually be like wow yeah I can feel.
The clarity and rightness of seeing it this way.
And so have friends that sees things differently and ask them their take on things and listen and ask their take on your take on things and on you.
So this is one of the other things that I think is this one of the other things very destructive social media is the filter bubble phenomena is.
Since Facebook is going to give me what it's not trying like there's not a person having an agenda there's an algorithm that is optimizing time on site and it just happens to be when I see stuff.
The disorient me and I don't and I'm getting less certainty when I want more certainty I bail.
But when I want more certainty and I'm getting more in group validation and I'm only getting outrage at the out group that makes me feel even more like I need to double down or whatever it is I spend more time so it just happens to be.
The appeal and I don't even know I bail I just keep scrolling in the fast infinite scroll because it didn't capture my attention because there's so much shit in the infinite scroll.
That I'm only going to stop to look if the person is hot enough or if it looks like something that my brain is pre triggered to say that's important pre triggered to say that's important means appeals to an existing bias.
And otherwise just scroll right and just kind of don't even notice that I passed it.
But what that means is that I'm going to have both content and people in the nature of that world that will be confirming my biases rather than correcting them.
And so then of course you will get increasing polarization on everything as a nature of even just the info technology infrastructure itself.
Right.
People haven't seen the social delimitation watch it it covers this really well.
So just to even if you keep Facebook at all or whatever social media.
Curate it for the most part the more time you spend on it the less good your sense making will be because it is optimizing for something that is not your sense making.
But if you're going to use it curate it so I went in intentionally found.
Groups and public intellectuals that represented opposite sides of every topic and I liked and followed all of them.
To just confuse the fuck out of the algorithm because it's like who likes the sunrise movement and the Cato Institute at the same time and then what you know.
And then to be careful because I know it pays attention that if I'm going to like stuff I want to kind of have a balanced distribution of my likes which can confuse other people socially.
But it's because I want to see a representative feed right.
And specifically I want to pay attention to when I notice that I have a leaning on a topic.
I want to find the best thinkers that disagree and I want to read their stuff more.
To see am I missing stuff right like is there anything in here I'm missing.
So curating your algorithm that way is helpful getting the fuck off Facebook and just doing better internet research than than that or just following the recommendations on YouTube which are so sticky they're so damn hard to avoid especially because it's going to send up some
hypernormal stuff we're pretty soon you're just watching MMA or bloopers or something.
And then you're like where did two hours ago and you're like I was doing internet research and so just being real about how messed up those algorithms are like OK.
What is it I'm trying to get clarity on what are the narratives and who are good.
First let's just Google who are the who are the scientists academics thinkers whatever that are representing these well.
Let me go read some articles right then let me find who's critiquing those well.
If I can get to the point where I can make each of the arguments as well as they can make it and then I get a sense of why they disagree.
Is it different data.
Is it different values.
Is it different models.
Is it disingenuousness like why do I think that then I might be able to start to say do I see a synthesis here where they each cherry picking and there is a higher order kind of insight.
Very often it's.
You know it's looking at this cross section in this cross section of the cylinder and saying it's a circle in a rectangle and there's partial truth and they're just too low a dimensional insight they're hyper focusing on a thing like.
You know the founding fathers were slaveholders and the whole thing is a legitimate and they built all of these institutions just to buy slavery so all of our institutions are built on supporting that so this institutional racism everywhere and how can you possibly like.
Say anything good about or quote these guys like yeah.
And.
The people.
Who want a better world than all the racism and slavery want a world that is aligned with the declaration of independence more than other articles of governance written.
And.
Civil rights were slow but emerged out of some of the structures that were hypocrites fuck that emerged and there was greatness in the nature of what happened in the country so there was like evilness and greatness mixed together.
And so I can make each of those partial narratives by themselves adamantly and talk past each other.
But the reality is it's complex right like some of the individual people involved.
Where I have a friend Gilbert Morris who's a professor on these topics and he's like Benjamin or he's like a Jefferson.
Was a great man and not a good man at all and you have to hold both like what is what does it mean to be able to hold both of those because I can tell each of those stories on their own and they're both bullshit partial stories.
So can I start to find a higher order synthesis than either of the cherry picked or partial stories.
That's the thing I want to start to look for and then not just jump to artificial certainty that now I got it.
I got the whole thing right.
I got something.
And there's probably still lots of insights.
So how do I stay oriented to continue to gain insights.
So those few things of make sure that what you're being exposed to is the various different ideas.
Make sure you're seeking to understand them and synthesize them.
Curate your info environments to support that and curate your friend circles to support that.
Those are a few things.
There's a sentence in CrossFit that says get comfortable being uncomfortable.
I guess here it's get comfortable with the unknown would be an equivalent.
And there is some it's very easy to have uncomfort with the unknown.
So they're related right.
Yeah.
And the reason CrossFit says that is because comfort and growth don't happen in the same place.
And good sense making and high certainty don't happen in the same place.
Yeah.
It seems to me that it's going to be effortful.
You know, to do this to undertake good sense making is going to require you to go through discomfort to go through unknown and to spend a lot more energy than just the limbic sort of reflex action.
There's a quote from last year is in The Times.
I've got this newspaper clipping.
Matthew Syed I think identified it.
It's called compensatory control.
He said when we feel uncertain when randomness intrudes upon our lives, we respond by reintroducing order in some other way.
Superstitions and conspiracy theories speak to this need.
It is not easy to accept that important events are shaped by random forces.
This is why for some it makes more sense to believe that we are threatened by the grand plans of maligned scientists than the chance mutation of a silly little microbe.
15 months hence now with the lab leak hypothesis.
This feels even more sort of new and interesting.
But yeah, that compensated.
I want to touch on that for a minute.
There was something that that writing did.
I don't know.
I don't hear who you said did it.
So I'm saying this with no allegiance or anti allegiance.
It presented a thought about it presented a position on a polarized topic.
Right.
The conspiracy theories aren't true and this is just a and there weren't mad scientists plotting and anything else and this was just a bug.
It conflated that with a high morals, almost spiritual insight that everybody would naturally agree with and feel elevated by.
Which was that we've all had the experience of feeling disorder and then seeking where we start cleaning the house where we had procrastinated when we our taxes come in.
We don't know how to pay it and want to feel productive in some way or whatever it is.
Like we've all experienced that thing.
And so people are like, yeah, that's true.
And then they're like, no, it is true.
We should just be able to embrace the uncertainty.
So there's like a resonant true thing.
There's like an aspirational thing.
And then there's like a given that a conclusion on a topic that is not concluded is there.
That's a kind of narrative warfare where it almost makes it seem like believing that belief is aligned with the high moral, almost poetic.
Like there's both a good.
There's the ethical and there's almost a beautiful aesthetic and then the true.
Right.
So so the best narrative warfare takes the true, the good and the beautiful distorts them all a little bit and braids them to align with a particular position.
And that's how I feel when I'm reading like the New York Times or something where I'm like.
If I believed anything other than this, I would just be a bad person.
Like it's so clear that what moral high ground is and right side of history.
And it's written so beautifully like whoever wrote this a fucking brilliant writer and poetic.
It's achingly beautiful or whatever.
And and it seems so clear because they're quoting the New England Journal of Medicine and Harvard and whatever it is.
And it seems like the best scientists all agree in the peer reviewed journal setting.
It doesn't make it true.
Like it doesn't make it doesn't mean that the morals that are there are like.
So the lab leak hypothesis is a really great example.
I have not done my research on it to have my own opinion on it adequately.
So I am not going to.
But I'm going to look at it just from a narrative point of view.
The lab leak hypothesis was up till whenever a couple months ago.
You know, like being a flat earther.
Right.
Like a flat earther, anti vex or tin foil hat wearing reptilian baby blood drinkers from the world.
And you know, you have to believe all that nonsense.
And it's like.
But even more, it's like anyone who's saying that could have leaked out of a lab not only doesn't understand science and it's anti science, but they're trying to cause a war with China.
They're xenophobic.
They're against Asians.
They're like, like all this moral sanctimony of what a bad person you are, what the bad effects will be and how dumb you are.
If you think that it's reasonable that it might have escaped a lab that happens to be in that area that happens to work with those viruses.
And because the science is settled because of something that we later came to realize was not settled science.
And so you're like, how?
And so then it starts to come out that actually wasn't settled science.
And we're like, how the fuck did the zeitgeist get that powerful that quickly?
That you were a dumb and horrible person for believing a thing because the science was settled and the science was never settled.
And everyone who believed the science was settled and everyone else is dumb and bad should be reflecting like, what the fuck?
I got captured.
Like I got captured.
I was certain about something.
And I didn't even read the article in nature that proved that it was certainly zoonotic hypothesis and I'm not qualified.
And I wouldn't have known how to do the rebuttal that came out later.
But the guy in the New Yorker, whoever it was that wrote about it seemed really certain.
And it appealed to my sensibilities.
And the institutions that agreed with it were the institutions that seem high-minded that I like to agree with.
So I hope people take seriously right now as an example, regardless of where the virus actually came from,
that the lab-league hypothesis was not dumb, whether it was true or not.
It was not proven false and was not dumb in the way that was said in the narrative.
And then like, how did that narrative get that?
Like what was the force that wanted to make it seem that certain and to push against the other narrative so strong?
That should be a very interesting question for everybody.
And yeah, it's fascinating in this whole situation.
I have seen zeitgeist formation that is more intense and faster than I've ever seen previously,
that is not based on good sense-making but other stuff.
Just rapid news cycle iteration.
And yeah, one of the terms that you use a lot is talking about good faith and bad faith actors.
And I guess that this ties in with sense-making individuals or actors,
if you want to say that sense-making agent.
What I find, especially over the last 15 months and the lab-league hypothesis is a good identify because it is so flagrant and in your face,
was people who had complete certainty plus powerful distribution to be able to convince others of their certainty
are able to reverse their position essentially without an apology within the space of 15 months.
That it's, here was a thing that I'm certain is true and now here's another story about a potential other truth
without referring to the fact that the first truth that we made you believe was true was untrue.
We saw this with Joe Biden last year where he said that shutting down travel from China was xenophobic in February
and then by May was saying that Donald Trump had left it too late to close the borders.
You don't get to do that. You do not get to fucking do that.
You're supposed to be the people leading the country.
You're supposed to be the ones that we hold to the highest levels of good faith actor requirements.
Yeah, that's cute.
Like obviously they do get to do that because people are easy enough to capture and move along in that way.
That's why it happens.
What's interesting is each time, say, a narrative changes,
we made a mistake before we couldn't have known or science takes time, which sometimes is true.
But now we know.
It's all it and now we know.
So it's a continuous justification for the authority we have.
And the Consilience Project, we just published an article there recently called where arguments come from.
A team that worked on it did a really, really good job and it basically shows like where do arguments in the public sphere come from?
Like in order for a lot of people to have heard it, a lot of amplification of the message had to happen,
which meant a lot of people who had the ability to amplify a message had to care about it.
Or some people that had the ability to amplify it had to do a lot of work to make that happen.
And so typically there's a narrative that somebody who has some vested interest wants.
So they have like a demand for a narrative because it will create a demand for a thing in the population.
And so they find a source of narrative supply.
They find a academic or a think tank or whatever it is that already thinks that thing or thinks something close enough.
So they don't have to get somebody to lie.
They just upregulate the narrative that currently wasn't like that person has been writing about that thing for 30 years.
It never got any traction.
Now it's everywhere because there's now an agenda that it is useful for it that will upregulate it where before it was women upstream.
And so it's important to just really think about the mechanics of what allows a meme to propagate.
What allows a narrative is I guys to propagate and not just allows it what what propagates it right there is energy involved in propagation.
The energy has an interest at seeking ROI on that energy.
And so this is why DC is filled full of think tanks that are intellectuals putting out public policy that is already predetermined in advance.
What the ideology is they're doing it on every new topic that emerges right.
What do you think a good sense making agent is not or what are some of the most common pitfalls that people have when trying to become one.
I mean we've been talking about the pitfall of excessive certainty this whole time.
And epistemic certainty is I know what is true excessive moral certainty is I know what is good also called sanctimony right.
Those are both pretty big pitfalls.
There is another one on the other side which is I don't know and I don't care as nihilism.
What I find interesting is that most people will or many people will flip from certainty to nihilism in like one step.
Where they're pretty certain of something if they find out that that's not true they're like I can't make sense anything I'm giving up I'm going to watch TV or whatever it is and.
Because the hard work of having to sit and I don't know and I'm going to work at it and I'm still not going to know I'm going to work out more and I'm still going to know for a long time.
A bunch of friends get really frustrated with me because they send me a thing and say what what's your opinion on this thing whatever it is and it's like something about a different narrative on early human civilization and hominid origins or whatever it is and I'm like.
Like did you read the paper I said yeah it's interesting.
And they're like well what do you think I'm like it would take me hundreds of hours to start to have a sense of it like I it's an interesting topic.
I don't have hundreds of hours to put into it I'm not nihilistic and that I don't care it just might not make it to the top of my stack.
And a lot of the things that are on the top of my stack I also say I don't know but I'm working on it right.
So when we talk about sense making being good sense making agent like what are we really like if we try to make it.
Simple and grounded what we're saying is.
I actually want to understand the world I live in as best I can.
Because.
I actually hold that life is meaningful.
And I hold that my life could be meaningful.
Which means that my choices can be meaningful.
And so I want them to be informed as well as they can be.
If my choices are me acting on and in with the world I want to understand things about me and the world and about what those actions will do as best I can.
Because if my choices really matter I don't want to believe it's going to go a certain way and I'm wrong.
Unnecessarily and I don't like I want to understand as much as possible because I act because it matters like ultimately because it matters and I care.
And then the hard part say it matters and I don't know and I might still have choices to make and I care.
It's easier to jump to I know or I don't care.
Because that I don't know and I care and it's consequential and it's moving is fucking hard right like that's scary and heartbreaking.
But it's like there's an epistemic humility.
And an epistemic commitment at the same time.
I don't know but I can progressively come to know better.
Not all positions are equally good positions.
Some of them have more error and some of them are more inclusive of more perspectives.
So I can progressively come to know better so that my choices can be better informed so they can be more effective and more meaningful.
But in order to do that I'm going to have to stay the course of seeking understanding for quite some time.
Which means I'm not going to have to not prematurely come to think I already figured it out too quickly.
Or defer my sense making to someone else who thinks they figured it out.
Easy exits out of the discomfort.
It's deciding to give up halfway through the workout.
It's sandbagging it so that you don't go to your maximum heart rate.
Yeah it's dropping the weight down so that the discomfort is a little bit less.
Yeah the get uncomfortable with the unknown I think is a really good.
Sort of overarching heuristic that you've got there.
One more way to say that.
Get okay with the unknown.
There's an even more poetic and beautiful way to say it that I actually feel and think everybody feels if they drop in.
Is actually connect to your love of reality.
If you didn't care about like if you didn't have a love for reality wouldn't care if it got hurt.
You wouldn't care if you lost it.
You wouldn't care like the fear of losses because there's something meaningful you don't want to lose.
The anger at anyone doing the wrong thing is because they're harming something you care about.
Like care and love are the origin of all the other emotions because otherwise you'd just be apathetic and not give any shits.
So ultimately I give shits about things because there is a care and love about life my life others lives reality that's real.
So there is a love of reality that is at the basis of the meaningfulness of anything.
And reality is mostly unknown to me I know the tiniest fragment.
So my love of reality and my love of the unknown right if I have a love of reality and it's mostly unknown.
That means not just comfort with the unknown but and this is the awe of the mystery this is the spiritual sense of faith and trust whatever right it's actually extending the love of reality into the fact that most of it's unknown.
That's nicer.
We'll take that one.
One of the things that I was very interested in is to try and work out at what stage of personal actualization people should start to serve the world at large.
Should we sort our own shit first before trying to go and fix the world and when do you know when you're ready for one of a better term.
Yeah definitely total enlightenment before sweeping the kitchen.
I joke because it shows how ludicrous it is to think that it is not both always right.
If I am seeking to help the world.
And I have not learned what's going on in the world I might be doing stuff that's totally not needed.
Or not very useful and trying to solve a problem but I don't understand the upstream things that are causing the problem so my actions will mostly be useless right.
So do I want to work on myself in this place just means work on my cognitive models and maps that I understand the issue well enough I can be helpful right sometimes I care about the thing I want to help the first thing is do I understand the problem well enough.
To be able to help right sometimes it doesn't matter this trash on the beach and pick it up.
Did I fix the issue trash on the beach no I don't know who's putting the trash there why what cultural effects are causing that so but I still picked up the trash that day cool.
That is not a comprehensive solution to pollution.
It's a meaningful activity in the moment.
But to the degree I want a comprehensive solution to pollution I have to start to understand the financial incentives to make throw away plastics have to understand what it would take.
Technologically to be able to make plastics that biodegraded I have to understand the culture of why people do that here and they don't in Japan and how we could change the culture there might be a number of ways I can come to understand it well enough right.
So I might want to work on my understanding of the problem before trying to help it so that I have a sense of how to really be effective.
Particularly the more complex the issue is the more consequential it is and the more consequential my action is going to be right.
Oh we're gonna do a solar.
Remittance program where we that's not the right word but where we reflect 20% of the sunlight out of the earth or geoengineering.
She probably pretty fucking sure.
Pretty fucking sure that's a good idea because pretty consequential right or where we're gonna try and sequester to using these genetically modified plants that we've never planted at scale don't know the biological effects of the modified organisms like.
More sense making before choices that are really consequential.
So that's one example of I want to work on my own cognitive maps of what is needed what's going on would be effective.
Enough that I have a sense of what to do but then also there's a point at which there's no more research will work I need to field test the thing try some stuff and be like oh it didn't work for reasons know the lab would never told me I didn't realize that the locals don't even like that thing or they don't believe it or.
And so there's a place where the application layer also ends up being part of the epistemology it's the testing right.
So that's one example there's also the example of well what if I'm working on trying to help the world and it's not.
The problem isn't a lack of cognitive elements a lack of certain kind of emotional healing and development where.
That is affecting how I'm showing up well let's say.
Whatever wounding issues in childhood have me have an outsized need for credit seeking because of not having ever felt loved enough or enough or only having felt good enough based on performance and credit attribution whatever.
Will I possibly mess up a project to ensure that I get the credit out of it where I'll undermine other people or sabotage or whatever it is or emphasize to me getting credit more than the effect of the project.
Where me doing work on not needing that as much because of healing whatever kind of place that isn't me would actually make me a much better agent for change in the world.
Yeah that's like a real thing right that's a real thing where that kind of stuff messes stuff up.
Or where.
I.
I'm trying to heal a particular issue in the world that I don't realize is unresolved wounds in me where I see something resonant out there.
And when I heal the thing in me I have a totally different assessment of it right like I have a totally different assessment because I really.
I was trying to.
Fix marriages in a particular way because of my trauma around my parents divorce or whatever it was and so I was seeing it through a traumatized lens I didn't even realize that I had this whole mission and nonprofit and whatever it is.
So there are times where our own trauma will get projected on the world this is why Lao Tzu said if you want to protect your feet from rocks better to put on shoes and try to cover the world and leather right that that idea of like.
But that doesn't mean that any pain you feel looking at the world is just your pain like I think if someone.
Was as healed and integrated as they could be and they see a factory farm.
They would feel the empathetic pain of the pain of those animals if they see hungry hungry kids they feel an empathetic pain if they didn't there would be something wrong with them they wouldn't be enlightened they'd be sociopaths.
And this is why you see the Buddha crying right this is why you see the the passion of the Christ is the idea of the enlightenment is not just oh I can see you suffering and doesn't do anything to me it's like sociopathic enlightenment is not that interesting.
It's.
But this is where it can be either way right am I clear and I'm really feeling the pain of the other feeling called to help.
Or is the some pain somewhere else just triggering my pain and then rather than face it in myself I'm gonna try to solve it in the world in a way that will always keep my sense making and my effectiveness off right.
So these are examples that people give people understand this is like you do more work on yourself first or my own need for excessive certainty because my own comfort with the unknown that will make me do shit where I'm.
I'm wrong but certain I'm right too often right these and we I'm sure the listeners can generate a hundred more examples.
So should I just do a bunch of psychotherapy and a bunch of Zen meditation and a bunch of.
Study until I am second tier or third tier or whatever the fuck the developmental metric I want to look at is that means I am now whole enough and integrated enough that I can work in the world.
No that's ridiculous you can't even like so many of the ways we learn about the problems is by engaging with them and you couldn't only do it and study and so many of the ways we learn about our issues is by engaging in the world and seeing
Oh I really did try to get too much ego credit there and I'm reflecting on it and I was an asshole and like I need to work on that and I wouldn't have seen it otherwise or wow that project failed and I was so certain that's how I'm seeing my certainty issue.
Right so as I heal and learn and grow I can show it better in the world but as I show up in the world I also get to see those things if I'm looking for them if I don't look for them always blame the world.
Every failure with somebody else's fault right every but if I'm looking for it then I can see those things and rather than just get crushed I'm a piece of shit that's all there is to it I can take it as oh this is this was some.
Belief trauma pattern that created a self-fulfilling prophecy or whatever but I could shift right so I want to bring an empowerment where I will look at.
What in me was off not to just beat myself up and hate myself not to put or not to pretend there was nothing in the off but to be able to see it look at it work on integrating and growing past it.
But similarly.
There's also this thing that we're showing up to the world.
With things that were passionate about it motivates our growth.
Because.
Let's say.
I'm afraid of public speaking.
Let's say I'm like catatonically afraid of public speaking.
I can just avoid that forever and don't have to go through it but let's say I'm somebody like Jane Goodall or whatever and I go and I'm working with the.
With the primates in the wild and I watch the poaching.
Right and I'm so fucking broken by that.
And it matters so much more than whether the people like me or not I get up on stage and talk about it and like we have to stop this position we have to because something bigger than me and my fear of public speaking is actually now moving me.
And if when I get up on the stage to talk I'm still under like are people gonna like me or not like me plays I won't get over the fear if I'm touched by something that is so much more important than that I can actually transcend that because it's not about me I'm talking about the topic.
I'm talking about the issue.
I don't even talk about giving the fuck off have somebody else talk about I'll just talk about there's nobody else is doing it.
So I also find that like the hardest parts of our healing are hard right like we avoid those things for reasons we don't notice them they're in the shadow for reasons.
And oftentimes this is why like so many people only heal patterns when they have kids.
Because there's something bigger than them for which they're willing to work because they're like man I'm fucking my kids up the way my parents fucked me up I told myself I wasn't going to do this I'm repeating the same patterns I see they're going to get it.
And that's the only thing that has them like double down on what it takes to shift that.
So whether it's your kids or whether it's some other calling there's a place where showing up to the world is actually the only thing that can make something more important than you that can allow you to transcend the parts of self that were just too hard otherwise.
So what we want is a virtuous cycle between growing as a being and having who we are show up for what we care about.
And where as we show up for what we care about it gives us insight about our self about the situation and it gives us motivation and as we grow and heal more as a person we can show up to what we care about better.
That's beautiful have you got any sense of whether you think on the whole people tend to more toward the side of showing up or more toward the side of working on themselves first.
If you were to give most people a little bit of a push in one direction would you say consider the outside or consider the inside more.
There are just different groups of people.
Right you have a personal growth world.
And a kind of psychotherapy and healing world and the call it Eastern Enlightenment world that is very focused in that direction.
You have a entrepreneurial and activist in various types of action oriented focus in that direction biases in both sides.
Yeah, have you considered the potential that humans are just to at the mercy of our emotions are programming to be able to reach our civilizational potential.
I was thinking about this when the most recent potential release about aliens was coming about and I had a conversation with a friend saying.
I don't think that aliens could be even 10% more emotional than us by whatever criteria you want to cause that more emotionally reactive because coordination would become so difficult if you had to turn it up to maybe 10 or 20% more.
You'd be able to achieve shit.
Like, have you considered that that we might just be kind of bouncing off a glass ceiling that the creatures that we are a so self limiting that no matter how much we try to transcend our own programming that we are sort of destined to fail.
Yeah, so this is the there's a common question of that I've received many times of like, do I actually get human nature and
Well, they're related questions. Okay. Right. It's a related question. And it usually comes in the form of I am dubious of two things. I'm dubious.
I'm dubious that people can be or I'll say it another way. I'm concerned that people are too irrational and to rival risk to do anything like this emergent coordination shit you're talking about that the level of rationality and the level of anti rivalry.
It's like wisdom and compassion or whatever it is that would be needed don't seem to be well demonstrated across the population anywhere. So what kind of a query and nonsense is this.
And so let's address that it's a real politic critique right or concern.
Am I asking the same thing you're asking not far off. Yes, I mean, I wasn't accusing you directly it was more abstract but yes, yes, you're right.
I've never considered. Yeah.
So
I'll tell you the, the first part of how I approach this so the same way I'll actually use it as an example of when I was saying a good way to sense make is to do dialectic.
Everything on the nature versus nurture arguments and the range of what people thought nurture could do were topics I really wanted to see what were all of the thinking and what was the basis for the thinking.
And were there any kind of axioms that were unquestioned or new possibilities that could change the landscape from even those ideas.
So
one thing is when we look at say how violent versus altruistic or
rational or whatever metric we want to look at and however we assess looking at across a population to get some kind of distribution.
First I would say I'm extraordinarily dubious of pretty much all social science of this type for a bunch of reasons.
One is it almost all started post industrial revolution and much more recent than that and almost all of human history that conditioned us genetically and otherwise was in tribal environments.
And those are so different.
And just like we're saying even the nature of Facebook engaging with it changes the patterns of what we think feel believe react to.
And there's tests that Facebook is run of like we can make people more depressed and happier and believe different things just by putting what's in the out.
Changements in the algorithm a little bit right so.
Post ubiquitous capitalism and ubiquitous industrialization and ubiquitous nuclear family homes and a bunch of things none of which were natural to the human evolutionary environment but they're conditioning that kind of one.
And so it became a ubiquitous conditioning we do the social science then and then pretend that that's not conditioning and call it human nature because it's ubiquitous conditioning that silly right.
And then there's so few indigenous people left or whatever we can just make them statistical outliers.
And even though they have very very different patterns on a lot of those things.
Also.
So that's one reason that I'm very dubious of the social sciences.
And this is even like when they're trying to do a good job not like like the nonsense social science that was.
Reifying why whites were superior in the early US based on bad interpretations of Darwin and for knowledge and stuff right.
But you can see from that stuff how easily bias influences something as complex as social science complex and consequential.
The other thing is that there are a lot of things about people's behavioral dispositions that change with development and development is not factored we don't factor levels of higher stages of human development post just be becoming 18.
Even though they're very real things we just put it all together and under a bell curve.
But you know when you look at the work of Piaget and then the kind of Neo Piaget and educational philosophers were looking at human development and childhood is very clear there's neurologic development and corresponding.
Change and find motor skills and logic skills and verbal skills etc.
And we get to like 18 schools over and then development ends right and that's a fully developed person this.
So what is development beyond that so you have a bunch of people.
Who have worked on higher stages of development and.
Zach Steins a good colleague of mine work on that very heavily and looked at the work of Colburn graves and lots of people who've worked on that but it's like.
The complexity of someone's cognitive model the development of their moral models the development of their aesthetic the development of their capacity to perspective take perspective seek.
And perspective synthesize those things keep developing right or they can keep developing one can do things to help them and then at those higher developmental capacities there are different behavioral dispositions.
And this is not just typologically they're typologically left or right or whatever this is.
But there so we could say if the society was supporting more development of that type you would have a totally different bell curve.
Right and but that's not a topic that's usually factored.
So there's a bunch of things like this where I would say the social science all needs taken some grains of salt.
One thing I have looked at is on the traits that matter most to a civilization that would work well I've looked for positive deviance outliers of the statistical norms on the positive side.
To see is there an upper is the is the upper boundary that we think of really the upper boundary or are there places where what we think of is the upper boundary is the medium right like it's quite different.
And so.
If you there's heaps of examples but if you look at like.
Through much of the last few thousand years across lots of different cultures.
And different geographies have Jewish families raised better educated kids than the people around them.
Much of the time.
They have in and so is there are there cultural dispositions that can lead to.
Higher qualities of education and correspondingly different qualities of ways of being right different types of disposition so then you have that for a long time the Jews all as a diaspora pretty much didn't defect on each other.
Right and the way.
The.
Jewish law is structured there it's kind of like a formal logical system so they're also getting very good at how to be able to think in formal ways which makes them good at which is why they became good at science and finance and other things that were thinking in formal logic is relevant.
It's a really important example because you can say well.
If what Jewish culture gave in terms of.
The development of education and rationality and non defection on each other could happen across the whole population would that change things yeah it really would.
What about the Janists you have a religion where across a long period of time nobody hurts bugs or plants yeah you do.
What about the violent kids in the society about the sociopaths across a huge population the violence bell curve is completely different right you have.
Extraordinarily low violence across the whole population how can that be well they're they're developed differently.
Can you have a population where almost everyone is violent yeah there's a few cultures where violence is ubiquitous right.
And you can see in cultures where kids grow up as child soldiers that you don't make it to adulthood without killing people.
And so it's like the John Jweed and the Jains are both possible in human nature depending on conditioning.
So the idea that what we naturally are is the median of that is just gibberish it's just not understanding how we create societal structures to create conditioning that support the societal structure.
So what if we had something that was conditioning non violence and compassion more like James or Buddhists or Quakers and conditioning.
Rationality more like Nordic build on countries or Jews and what if we had a few of those things and we brought them together into not just an educational but a cultural developmental system.
Could we have is it within human nature.
If rightly conditioned to have higher potentials totally is within human nature for the condition of higher potentials what if in addition we created an economic system where we addressed perverse incentive.
So rather than the guy who externalizes the most harm.
To the environment makes the most money and then gets the most checks and status and whatever to actually all of the harms the externalized harms are internalized to the cost.
So the guy who gets the most money is the one who does the most omnibenefit and no harm anywhere.
Well now there's no sociopathic niche to condition bad behavior and bad values in people and doing the thing that's good for others ends up being good for you actually is conditioning the values even from self centeredness right.
It starts to bridge them in that way.
Well how do we make an economic system that rigorously internalizes externalities and addresses perverse incentive.
That's a really deep question for changing what we would call human nature that isn't human nature.
It's the nature of made up human coordination systems.
Right.
Does all property law does all access to resource have to be at the level of individual private property.
No.
Can we do things that change that fundamentally.
Is every good fundamentally rival risk because it scares no digital goods made it very clear that you have things that are not only not scarce but anti-reverse the more people that use them the more valuable it becomes but we still make them artificially scarce.
Because of the artificially scarce dollars artificially scarce materials economy can we make materials economy that isn't artificially scarce by making it closed loop with enough energy to run it.
Yeah we can.
So the point is do we see positive deviance of.
You know you you look at a very wealthy population old wealth families while they still have the integrity of how to do dynasty or even just the kids going to the best prep schools in the US right and then who go to the best Ivy League schools and how all the best tutors.
Do you have the same distribution of success in life of the kids coming out of Exeter and the kids coming out of an average public school no they're totally different.
Well what if everybody went to Exeter and had that corresponding life since they were little will be totally different.
Well but we can't afford to do that.
Yeah so that here's the thing.
The idea of the dumb masses is class propaganda.
Because the upper class that has access to the things that develop them having more capacity is why they end up having more capacity is a major part of why they have more capacity.
And then the idea that some people like them need to be in positions to rule because the masses are too dumb.
Is a self fulfilling prophecy because then we'll keep the masses dumb by not giving them better educational resources and other types of you know things that would create a difference there so.
I like I actually think that the idea of the irrationality and the rivalrousness of the masses is one of the deepest.
Parts of like propaganda zeitgeist of ruling classes forever.
Because it justifies the basis for rulership.
Cultural conditioning masquerading as human nature in the modern world is something that I've never even thought of before that is.
So interesting.
Yeah I mean if you look at you know you've ran these clubs and you see all these teenagers come into the clubs and how they behave and so you've seen patterns that are on repeat so much you're like I know human nature I've seen this hundred thousand times right.
But if you went to the tribes in the western Amazon and saw how the teenagers there were engaging who'd already been doing ayahuasca for ten years since the time they were little it's not the same like there are some things yes they have a sex drive right yes there are certain aspects of paying attention to social hierarchies that everyone's going to notice.
But there's more that's different like a lot more that's different right.
That's conditioning.
Given the fact that the moment the cultural conditioning.
Appears to be making human nature into a rival risk game it's difficult we have.
Coordination problems we not everybody is a Jane or a Jew at the moment or some perfect amalgamation of both.
With that in mind you said something in our first conversation that was where God's we're just shitty God's and it was a comment on the difference between technological prowess and sort of wisdom more ability to deploy that technological prowess.
If you could do you think it would be optimal to curtail technological development perhaps a couple of millennia say while we let our wisdom catch up or do we risk more by accumulating background risk and potentially.
Losing galactic real estate by not progressing within that time if you got any sense of how that balances.
It's irrelevant because it's impossible.
It's impossible to slow the progress.
Much if you had a God's I view.
If I had a God's I ability to slow it yeah what I yes well if I had the God if I had the God's ability to slow it I would just speed up the rate of the wisdom.
Like what it takes to grow the wisdom of everyone and what it takes to stop the progress are actually the paired thing because.
Outside of the wisdom the multipolar traps when anybody who says I'm going to get there first is going to just win the world because there's so much power so now.
They have everyone has maximum incentive to get there as fast as they can.
Including lying to other people about that they're not doing it so people aren't trying to race and so so.
You know you can say God we are not ready to be stewards of this much technological power let alone power that we won't even be stewards of because it'll become auto poetic and run itself like a G.I.
Right.
So we need to just slow this fucking thing down okay so we can become a unabomber which that was his idea right to his idea was like we we're not ready for tech like we.
We suck with spears we were assholes with spears we were assholes with guns we're assholes with ICBMs and now we're going to have like drone weapons everywhere like no we got to slow that stuff down because we have been assholes with all the weapons we've had and all of the.
We've destroyed environments with way less capacity than we have now okay.
So you come to that idea and you you can do what if you don't have tech you don't have the power to affect stuff.
Because the tech ends up being the power so other people disagree with you and they want the power so if you want to stop them you gotta get more power than them which means you gotta beat them at the race to get the power to beat to stop.
So.
The techno optimists the naive techno optimists who just say tech will solve all the problems is a gibberish position it's not just gibberish it is.
Super dangerous in my opinion it's the most dangerous world view currently.
Because like.
A militant jihadi world view doesn't make AI and crisper tech and things like that it just doesn't make the tools that can be tools of destruction and scale only the.
The world view that supports the increased rapid development of exponential tech is the thing that increases the destruction.
The fundamental destruction power not just the application of the existing destruction power right.
So the idea that the faster we build the stuff the better everything will get because I will just solve all the problems and we can't possibly solve until it's just get to the fastest let it solve all the problems and etc.
Like.
Yeah that's an extraordinarily dangerous view.
The blood I view right the techno pessimists who says.
We have always been bad stewards of power we cannot wield exponential power well.
We've used powerful war exponential war destroys everything we've used power to extract from the environment and externalize the cost exponential externality destroys everything.
We've used our power to create radical asymmetries of power exponential asymmetries of power sounds like a shitty world for almost everybody.
So.
So why like we need to stop that thing well that view.
Well that's true that view ensures that it will have no power to do anything.
Right.
So the only view that can forward is the one that embraces the tech that is where the power is.
But embraces it recognizing that it's not a given that that tech is good it could be developed in ways that are positive but it can also like a facebook wasn't developed with a time on site maximizing algorithm.
It could be a very different forms right like the ability to to.
Take all of my behavioral data make an advanced psychographic profile on me and then use a i to curate an infinite news scroll to affect my mind and behavior that's fucking powerful tech.
But if the goal is optimize my time on site to sell me and my information advertisers.
Then it's going to optimize for putting in front of me the limbic hijacks and the.
Cognitive bias in the in group and the things that drive addiction but if it's desire if it was optimized for.
Developmental metrics of like expose the person to the things that will actually help them see alternate views that they don't already see and help them learn and grow and perspective seeking like.
It could be techniques like that could be the most powerful tools of consciousness elevation and education that have ever been.
So it's not that the technology is.
Definitely bad it's it and it's also not the technologies values agnostic not values agnostic no technologies values agnostic.
I.
If I make a plow.
It's not values agnostic that can be used good or bad the plow will make a lot more food for my people than just hunting and gathering.
So that means that if other people use it and I don't I'm just going to lose.
In terms of making it through famines and having stuff to trade and whatever so I have to use the plow as soon as it exists pretty much right.
And the plow codes a pattern of behavior now I have to yoke and ox.
And beat it all day long to do that so I before I was animistic when we're doing hunting gathering and kill the buffalo every once in a while but I believe in the spirit of the buffalo I can't believe in the spirit of the buffalo and beat it all day long after cutting its testicles off and putting something through its nose and whatever.
So I have to change my whole view on the spirit of the animal right was the tech values agnostic no coded values into me by my using it by the fact that I had to use it for game theoretic advantage right.
So the idea that tech is just tech and it's not good or bad it's how we use it this is a misunderstanding.
Yes of course I can use a hammer to build a house for the homeless or beat somebody skull in and it's a positive or negative use but it's also the hammer will code certain patterns of behavior those patterns of behavior will end up coding values into me right.
And so what it means is if I have social tech.
I can develop social tech that isn't like Facebook right I can develop a social technology knowing that it will code patterns of human behavior that will code their values and how they see the world I can develop it intentionally.
That will code patterns of behavior and values that.
Some model of human development says is actually a more developed person versus is a more.
Attention extracting and profit extracting person which usually means a less developed person.
So it's not that the tech is values agnostic and it's not that it's necessarily good is the technical missings are necessarily bad it's that we can design it in a way where the fact that it's not values agnostic and it will be conditioning values can be good or bad but it comes not just how we use it but how we design it.
Right the nature of the design itself will end up affecting the use patterns which will end up affecting the beings in the society.
So in order to forward we have to both utilize the technologies that have power otherwise the stuff we're doing just won't matter those who are utilizing it will just win.
But we have to do it in a way that is also aligned with the human development and the social values and the integrity of the.
The planet in the comments that we want to see so right now the exponential technology like it's fair to say that exponential tech is in.
Converse so much more power than all other legacy forms of power that only those who are developing and guiding exponential tech will have much say in the future.
Right now.
There is like two attractors for what happens either the exponential technologies.
Just cause catastrophic destruction because you have exponential warfare or exponential externalities right.
Or we figure out how to avoid those by some good control systems using the tech and now we get exponential control systems.
And so we see authoritarian nation states using the tech to make better authoritarian nation states and we see some companies using the tech to make.
Companies that are more powerful than countries but they don't have jurisprudence of foreign by the people.
Right.
And so that is like more like a new kind of feudalism so both the authoritarianism and feudalism are like technologically empowered.
Autocratic structures so there's basically kept catastrophes and dystopias are the only two things that are currently on the landscape.
If we want something that is not a catastrophe and not a dystopia then we have to utilize the tech in a way that binds the tech.
So it doesn't cause the catastrophes that does it in a way that's not dystopic meaning that the order.
Is emergent rather than imposed how do we utilize these how do we utilize and crypto and social and attention tech and all of these things how do we utilize them.
To increase collective intelligence and collective coordination so that we get.
Increased effective coordination and order without it being a kind of dystopic control system like there's a lot of innovations we can really implement there.
So the question of should we slow down the rate of progress if I could like if if I could slow it down and just say hey the guys who are getting way too close to super dangerous.
If I could slow it down yes yes I would like that because right now our growth in doing it rightly and wisdom is not good relative to our growth getting technology more powerful.
If I could get like how powerful crisper technology is becoming as cheaply as it's becoming to slow down so that it wasn't so easy to have very small groups have by weapons capacity like yes I would like that to slow the fuck down.
There's not going to because there is no world authority that can stop it everywhere and anyone that does it is advancing so that nobody really wants to stop it.
So what we have to do is get the utilization of those technologies to a better attractor that can guide them to happen even faster.
The consideration of what sort of a world we would be in if facebook optimized for well-being or happiness or insight or whatever we think about how powerful it is and some of the changes that we've seen in.
Human nature which we now know might very well be cultural conditioning.
It's crazy I just think about the sort of thing about the sort of society that we would have.
If you had multi so you prefer to learn through 15 second video clips okay.
Tick tock education is tick tock mindfulness is for you and then to all you prefer to actually read but you could you get away with more pithy sort of aphoristic stuff okay so.
Twitter enlightenment that's your place like.
Yeah and like okay let's take so the type of media we give people but then also the nature of the content to be bias challenging more than bias confirming.
I don't know.
So if you take a there are some YouTube channels and Facebook groups that just document police violence.
And so you can just watch videos of cops beating the shit out of people that in ways that seem unprovoked and some of them are just cops beating up black people.
And as much as I am aware of the statistics and I'm aware of how we're affected by this I can't watch that channel for more than a few minutes without just seeing red everywhere right like and.
And that's the only issue I can care about I can't care about anything else in that moment.
And then you watch a different channel that is a blue lives matter one that basically just shows cops risking themselves to protect other people and then people attacking cops which is why they are the way they are.
And maybe one that just shows black people attacking cops and then you're like fuck what a fucked up job that is and how amazing they're doing and how much self restraint and.
And now neither of these are giving me statistical representations right I just watched four videos now there's a million interactions or thousands of interactions in every city every day right and there's all kinds of complexity in this.
And I didn't even watch what happened leading up to it but if I'm a if I'm a black person living in some inner city area and I watch a few of those videos and it profiles me and it shows me more of those because I spend time on psychs it fucking hurts.
I'm just getting vicariously traumatized.
Right by watching someone that looks like me that I resonate with get fucking killed or beat up or whatever for and and so what does that do.
But then the other guy who's watching it who's watching the other one right the guy in Texas watching the blue lives matter one is getting more and more both patriotic and he's getting vicariously traumatized of the way the cops are being wrongly attacked by the black lives matter folks the protesters whoever it is and.
That person is actually becoming more racist than they were right becoming more scared and so what if they got the other videos like what if the algorithm was actually giving them the other content and what if it was.
Giving them the specific subsets of the other content that would be likely to actually touch something and appeal to something in them.
So that there was just some so one it wasn't just just traumatizing them and two it might be giving them some insight how to do something other than culture war.
How to do something that could possibly bridge where there's trauma on different sides simultaneously.
So if you start to think about let alone the science of yeah you're no one ivermectin right or whatever so if you start to think about could we.
Curate it to have the right media forms.
And the right distribution of the types of content.
And exposure to the types of people that would help this person be more trans perspectival more perspective seeking more perspective taking more holistic in their thoughts and insights.
I mean it's and and even where in so far as someone is watching something and it's their liking and it's being seen what they're watching word where in so far as like status shit is being hijacked.
We use it for the right thing where people start to have status conferred by the amount of stuff that they're looking at from different perspectives and it's educational in nature.
I think it's fascinating to start to think about and and still people be scared hearing this like who the fuck thinks that they know what human development is and what I should see and is going to socially engineer me for their good idea.
And they should be dubious of that.
The thing is you're being socially engineered right now and you and you never aren't right so it's not like socially engineered or not it's.
Bring consciousness to the fact that it can't not happen because we are all conditioned by the environments we're in and then take responsibility to say how do we how do we actually do that intentionally well what does that mean.
I mean at the moment.
I'm sure that there would be a way to make it worse to make it more polarizing or more limbically hijacked.
But it feels like there's a lot more ways to make it better than there are ways to make it worse.
It's interesting the ways to make it worse.
The search algorithm or ants there better it's like is it possible to make food that is much worse for you than hostess and McDonald's.
Well like only if it's not food at all it's just poison right like if I'm doing just pure poison.
But I couldn't really make anything that could even masquerade its food much worse because there's not that many things that are food.
And they they split test optimized for the most addictive ones and with the easiest palatability with the drives most addiction it's like maybe maybe they'll come out with a new type of Twinkie that's even more addictive.
But probably like they kind of already did most of that search base right.
And they're making innovations like OK can we make porn that is even more addictive.
Yeah VR right so and then we'll do shit.
But so but the thing is like hyper normal stimuli that lead people to addictive behavior is just good for capitalism.
If I run a business I want to supply something people are addicted to.
Because because the first rule of business if I'm you know I'm an NBA the first rule is to maximize lifetime revenue of a customer.
And I maximize lifetime revenue very well through addiction.
And but what that means is that there are lower and higher angels in my nature and it's easier to make money off the lower angels of my nature than the higher ones.
Which means the money will go into developing technologies that will drive the lower angels people's nature.
Which is why the underlying incentive system is one of the things we have to work on deeply.
Because whilst that's still in place there's always going to be these particular individual agents here and there that will just take advantage of other people deciding to slow down.
If you can't coordinate effectively.
Yeah I mean the reason to have rule of law is to bind the predatory aspects of market incentive.
To say yes I know you can make money by cutting down the national forest but you know you're not allowed and.
And we actually do have a monopoly of violence with the police force so if you try to take your goons in there to say we're going to do it anyways we'll actually come physically stopping.
And yes you can make money killing people and harvesting their organs and selling them and know you're not allowed to do that right like there's a bunch of things that are just bad you shouldn't do that.
And so this is why we say no not just total free for all free market because.
Then what you end up getting is a few people who have all the money like we have and most people have no money and the people who have most all of the money have relatively unchecked power.
This kind of radical power asymmetry to impose things that might totally suck for the will of all these people so these people say we're going to pull our power into a kind of labor union of sorts called the state.
And the state is going to take our collective values that will encode as rule of law right our values as the basis of jurisprudence creating rule of law.
With a government of people that are supposed to have no vested interest at all because it's up for and by the people.
They are a belief of the monopoly of violence so the state's even more powerful than the top of the people in the market more than the billionaires at the top of the power distribution so that the values of the people can check the otherwise.
Radical asymmetries of market differences that's the idea right.
It obviously breaks down because what that means is those at the top of the market have maximum incentive to corrupt the state to capture it to capture the regulators until you see someone who works at the FDA who used to work at Big Ag or.
Someone who works in the DOD who used to work at Lockheed or whatever it is you're like oh that seems like an incentive problem.
And then you see that GDP goes up when there's war right and because we spend a lot of money on military manufacturing and.
So the regulator that is supposed to regulate the state ends up getting I mean they're that is supposed to regulate the market ends up getting captured by the market because.
The state was supposed to be regulated by the people right a government of form by the people with high transparency where the people saw what was going on.
So the people so the representatives were really representing the will of the people not representing their own private interests that were being paid for by some kind of state.
So the state can only check the market and so far as the people are checking the state.
The people obviously are not checking the state at all the state is not trying and nor are the market forces trying to support the people to do that they're trying to support the people to believe that they can do that by voting every four years or something.
But having no real transparency inside awareness.
But.
But yeah so the thing about perverse incentive well.
You have to be able to say no that way that you can make money and yes you'll be able to say hey they want it right on Facebook is like we're just providing a service people want right and that's what the drug dealer says when providing the drug to kids they're paying for it right.
We're just providing a service they want to yeah you there are weaknesses in people that you can exploit and then they'll want it you'll fuck up their lives we should not do that right that's not like.
Authentic voluntaryism that's like exploiting people's weaknesses and talking up their life because of bad incentive that's the thing we should not do we should provide goods and services that enrich the quality of people's lives and not provide the particularly predatory ones.
So that's where you need a state or you need some kinds of forces to be able to identify those and check them.
We we and this is where we need better collective sense making to be able to identify these are perverse incentives.
Oh we should actually make different kinds of laws and regulations around that old our whole process of law and regulation is too slow for the rate of the tech moves how do we actually change the structure of.
But our governance system hasn't employed any of the new tech why is that China's governments employing their the new tech before an autocratic system we're not employing it to make better open societies why not.
Taiwan starting to we could it's working there.
Yeah.
Have you ever read Seven Eves by Neil Stevenson it's a hard sci-fi book.
So the moon explodes in the first sentence.
And the next two years are humanity trying to work out how they're going to survive how they're going to get genetic progeny somewhere.
Right and they decide to go through sort of a forked strategy they send some up to Izzy the ISS that then gets made huge and loads of other stuff happens they send some under the water.
Given the fact that you spend a lot of time thinking about existential risk we don't have a second community on Mars or another planet or anything.
Why haven't we created a siloed community somewhere which is totally self sufficient defended air gap from the rest of the world so that if anything was to happen there is a contingency already in place like that.
Well there kind of is in terms of do we have deep underground military bases for the continuity of governance or government.
Yes of course right like especially after World War Two and during the Cold War the idea of there's a nuclear attack how do we have continuity of government let's make the bases do that and that they have the self sustaining resource to be able to do that.
And then of course plenty of billionaires have their own bug out bunkers for those scenarios.
Why has the world not created a its own breakaway civilization.
Say something that the world is work together to do.
At all like with with coordination that isn't in the interest of those who are working on it like that's the deeper question there because if if we could work together make a breakaway civilization why not just make this one much better.
Yeah yeah the global coordination does seem to be the challenge you are right it's just it's something that they're interested me I'm reading this book I'm looking at all of the challenges that occur when you have an imminent threat.
But as anyone that spent a bit of time learning about existential risk the fact that you can't see the imminence of something doesn't mean that it isn't imminent.
Like it could be it could be around the fucking corner you know we didn't need much of a difference in some of the parameters of covid to have made this a very imminent sort of danger.
And Rob I suggested to Rob Reed last week and he said that he could think of a way where this would almost be like conscription in a way like you would do your time in the.
Humanity 2.0 bunker or whatever perhaps people would cycle in and cycle out for a couple of years at the time and it would be something that would be really prestigious and people be picked based on sort of.
Genetic markers or attributes that they would want and we would always have a siloed civilization just there ready in case something was to happen to me.
I'm aware that it's probably not going to be super fun but also it kind of might be fun there's not many things you can do that not many other people have done.
It seems like for any country to do.
Relatively small cost yeah gonna suck for some people but it's a pretty small outlay for.
Well.
University of Arizona biosphere to project was something in that direction right can we make a closed sustaining biosphere.
And it's hard and there's easier versions are not quite ambitious that all the big countries do have which is.
If the world blows up.
Is there somebody that still makes it well all of the serious nuclear power submarines are that.
And they know that right when they go when they go under you could have full scale strategic thermonuclear war on the surface and they're still doing the thing.
And they have the ability to do that thing for a while and they have the ability to blow up a big portion of the world from the.
Artillery they're carrying on them so like the they're very interesting like the risk that they pose and the psychological experiment that nuclear submarines are is actually very interesting.
And so but that's also a continuity of government military capacity thing was okay well let's say first strike happened all of a sudden we've got these guys out there and there's they have the ability to respond independent of whatever else got blown up so.
So that's like part partial experiments like that have happened.
I think this is how Elon describes part of his goal with Mars is that we can take a stand somewhere else other than Earth asteroids and whatever.
And as just inspiring enough project to motivate us to think positively about the future and do something interesting.
I'll tell you what I really like about the Mars colony.
Is and what I like about the idea that you're saying even if it wasn't Mars colony but I think Mars colony is maybe the most popular version of it right now and also kind of well resourced one.
I like it as a thought experiment for how to design civilization from scratch.
Because if I make the Mars colony of course there are some differences there and here with like microgravity and cosmic rays and microbiomes which are pretty serious issues but let's take those issues off and just take all the other ones that identical Earth would have.
I still have this issue of how do I.
Make a civilization that does not require import.
And it doesn't mess itself up.
There's going to be very limited oxygen.
I can't have the inefficiencies of a bunch of.
Unnecessary farm animals breathing the oxygen.
If that's not a good way to produce nutrient and chloric density.
I can't have criminals who aren't contributing anymore breathing the oxygen.
So how do I create a social system that doesn't create criminals or that deals with criminality in a way of putting people in prisons for a long time.
I can't just assume that we can get new shit easily not only can I not produce waste or trash I can't even produce micro pollution volatile organic compounds from the epoxies or whatever in this space in this very finite amount of air supply.
I have to be able to make all of our own hardware and software and mining and everything and all of our own biotech.
And if anything breaks we have to be able to make the tools to fix it all right in the same space.
Are we going to use the same law that is retrofitting stuff back from like the 1200s or are we going to redo law from scratch.
If so are we going to do it on a blockchain.
What is the basis.
Well if we're going to redo law what is the jurisprudence upon which it's based.
Well what are the values upon which the whole thing is based.
What is the Constitution.
What is the metaphysics that gives rise to how we pick the Constitution.
If you really want to think about a Mars colony you're thinking about everything.
You're thinking about the full tech stack the full suite of social technologies.
How are we doing education and towards what what is a developed human being that we're trying to develop humans towards.
And ultimately what is the value system what is the metaphysics that we are that we're basing the Constitution and the educational theory and the everything on.
As we get clear on that because of that thought experiment then it's well could we rebuild the world here that way.
Could we build floating cities at sea that where we don't have to produce our own oxygen and deal with all of our own CO2.
We can still piggyback off this biosphere.
And we don't have the we just have to ship it across the ocean not across the solar system you know for the import stuff that we do need.
Could we do ground up civilizations that way.
And you know could some nation states pick up levels of design iteration.
And even if we can't do it ground up knowing what it would look like can we say now we know how to vector to make a 50 year plan to vector the current system in that direction.
That's something so the the actuality of making it on Mars actually interests me less than the thought experiment of what the thing worth making would be and then what it portends for us to get clear on that.
So the constraints of being somewhere like Mars where inefficiencies whether they be metaphysical biological technological sociological legal all of these show up potential flaws within the system.
And.
Is it right to say that on earth because the the externalities of getting these things wrong have sufficient slippage or.
The opaque enough that we don't actually get to see when they happen we have a surplus resources or at least we feel like we have surplus resources that can kind of chew up some of these inefficiencies yet when you start to bring those constraints in in my.
Super silos second world or whatever or on Mars that's when you actually get to see them in a harsher light.
Yeah it's not that Mars has more constraints it has more and less constraints in ways that lead to more innovative design.
It has more constraints in all the ways you just mentioned it has less constraints to be an iteration of the previous things to stay bound to being intelligible to the previous things.
Right it would be very hard to try to make a really fundamentally different law and culture in.
In England.
Because there's a very very strong tradition there's very strong basis of law what would be the to bring it into being what would the basis of law in current law be to bring it into being and does it even make that kind of thing possible.
Whereas on the Mars calling is like we got here first fuck off we're doing it right it's more that kind of thing so whether they get there or not even the thought experiment of it is less constraints about what it has to be or can be.
Based on our past and where the constraints are more just physics.
But those constraints are more obvious to us because we don't have the huge buffer of pollutability and more resources.
Daniel from action burger ladies and gentlemen what can people expect from you over the the next few months where should people go to check out interesting stuff that you're doing at the moment.
The project that is still in just a very very early beta phase but that has most my attention is called the conciliants project I'm one of the members of that team and so conciliants project org and it's really working on.
Right now.
Through a bunch of articles and then translation of those articles through podcasts and then maybe animation other forms of media on helping people to understand.
The problem space of the world better.
The types of things we're talking about the relationship between sense making meaning making choice making imposed order versus chaos and how do we have emergent order to understand some of the things well enough to be able to start to think about.
The.
Innovations it would actually make a difference at a fundamental level how do we understand the meta crisis well enough that we can design better.
We can employ the more powerful exponential physical technologies to make better social technologies that are neither the catastrophes or the dystopias.
And how do we make both the need for that and the design criteria of what the solutions would look like not exactly the solutions but the design criteria of the solutions to be able to kind of drive innovation zeitgeist so both existing institutions can say.
Wow we need to reform ourselves and we need to reform ourselves in these ways and new independent groups like blockchain governance imperatives and whatever can.
Can also innovate informed by these things so that's that's where much of the attention is and then.
Invited like by yourself to do a podcast on interesting and fun and random topics in that so I have a blog that is basically just a place I put podcasts called a civilization emerging dot com you can check that out.
Awesome that'll be linked in the show notes below Daniel.
It's always a pleasure. Thank you so much.
Thank you my friend. Thank you for having me. It's good to be back with you.
Thank you very much for tuning in. If you enjoyed that then press here for a selection of the best clips from the podcast over the last few months and don't forget to subscribe.
Makes me very happy indeed.
Peace.
