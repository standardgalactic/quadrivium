Hello and welcome to a new and ancient story. This is a podcast, a series of
conversations, interviews, and occasionally speeches dedicated to the
transformation of self and society. The basic idea is that we are moving from a
story of separation to a new story, new for the dominant culture at least, of
interbeing. What that means will become apparent as you listen to this series. We
explore things like technology, spirituality, agriculture, healing,
economics, politics, ecology, relationships, education. I mean pretty much
everything that is undergoing a transition today as our old story nears
collapse. If you want to engage these ideas more deeply, you can come to our
website, CharlesEisenstein.net.
Hey everybody, Charles Eisenstein here with my friend Daniel Schmockenberger. I
would call him a non-institutional and non-institutionalized intellectual. I
find that the most interesting, generally speaking, the most interesting
intellectuals and philosophers tend to be outside of academia these days. Maybe
there are some exceptions, but I feel like Daniel is a kindred spirit
because both of us have walked a path that wasn't prescribed and it's taken us
both to places that were not on the map. At least that's how Daniel
has landed on me, that he's gained insights and developed perspectives that
are not on the menu, conventionally speaking. I'm really excited to share
some of those with you. We just recorded a podcast a couple days ago for his
podcast and Daniel, you were such a gracious and generous and skillful
interviewer. I felt really humbled by that and I hope to be able to return the
favor. So welcome to a new and ancient story. Thanks Charles, it's fun being here
with you. I'm looking forward to us getting to have this dialogue. Yeah, maybe
we could begin by, I'll just say that you use certain vocabulary that is
unfamiliar and it took me a little while listening to you to really begin to
understand what you were saying. Talking about things like multi-polar traps and
existential crises and there's a few non-rival risk games, things like that.
And I think that those will come up and when they do come up, maybe we'll pause for
explanation of those things. We had a plan to start about talking about the
paperclip maximizer problem. And it's like this AI thing, but it has huge
implications for the direction of civilization even down to a deep
philosophical level. So is it cool if we just start with that? Do you want to
introduce that? Yeah. So some of the listeners have probably heard of the
paperclip maximizer thought experiment for those who haven't to construct it
briefly. I believe the term was first introduced or at least introduced to
the public by a researcher named Nick Bostrom in a book called Super
Intelligence where he was exploring the risks of artificial intelligence and
there are many different AI risk scenarios. And one of the general ones is
called a paperclip maximizer. And the idea is that we don't need an AI getting
a sadistic will of its own against us or even being applied to weapons to be
problematic. The idea of the paperclip maximizer is you basically have some
goal that you want to train an artificial intelligence system on to help
optimize whatever that goal is. And when we look at being able to train an AI
on a particular goal like winning chess or winning AlphaGo or something like
that, we see that if they understand the boundaries of how they could optimize
that, they get capable of things that humans couldn't do very quickly.
And so let's say I have a factory and I produce whatever and in this case just
for simplicity and Selena's sake, I produce paperclips. And I train the AI system
on the goal of maximizing the number of paperclips that I can produce and
increasing the efficiency of my paperclip production. So first it gets
trained on the data sets of my entire supply chain and my whole manufacturing
process and it sees where there are inefficiencies in the manufacturing and
the supply chain. It fears out how to tighten up those
those inefficiencies and the business is just running better and that's awesome.
That could even seem like a good thing for the environment because of decreased
inefficiencies and things like that. But if it continues to get more and more
intelligent and actually as it gets more intelligent,
it gets better at getting more intelligent. The key to the paperclip
maximizer is that it does two things. It does whatever goal you train it on plus
it gets better at its ability to do that goal.
And it gets better with an exponential curve because as it gets smarter,
it's also smarter at figuring out how to get smarter. So you have compounding
returns on intelligence that are then all applied to doing whatever the thing is.
So pretty soon it starts running out of substrate
to make paperclips and so it starts looking at how to make paperclips from
additional substrate. So it starts realizing it can use recycled metals,
not just whatever the original metal was and trash and whatever and of course
then it eventually runs out of that and eventually it needs to
use the stuff that humans need to live for substrate and then eventually needs
to use the humans and then it turns the whole universe into paperclips.
And the idea is that if you had something that is
way more intelligent than us, in terms of it's just strategic
capacity to achieve a specified objective, it's a very
narrow kind of intelligence we're talking about right now,
in terms of we're not saying that it's good at defining what is meaningful,
but if an outcome has been defined and it has access to the data set of things
that are connected to that outcome, it can do optimization better than we can.
And as we try to learn how to deal with it, it's going to learn how to deal with
us faster and we're going to learn how to deal with it, right? So the
chess systems competing against human systems are getting better at beating
us faster than we're getting better at learning what they do to adapt.
And so we're getting more and more obsolete as chess players
on a very fast curve. Well this is what we're already applying AI to do.
Like before we start to think about true general AI and
we are already across many industries applying artificial intelligence to
optimize fairly narrow metrics. And you know a classic example is Facebook
or social media of any kind, Google whatever, but we'll take Facebook as a
simple example, trying to optimize the goal of time
spent on site. How much time does a person spend on
site because the more time on site means the more advertising revenue and at
the end of the day it's a for-profit company that makes money and returns to
shareholders by advertising revenue that's proportional to time on site.
But there's an AI running its optimization of what makes my news
feed as sticky as possible and what makes the notifications as engaging as
possible to come back. So it finds out that there are
certain things, and this is the same as the YouTube suggested views feed,
finds out that there are certain things that I'm particularly
more likely to pay attention to and it optimizes for those. Now it's not
conscious, it doesn't care, this is just pure analytics,
but it's effective and so we'll see that my news feed is totally different than
your news feed and it's based on what is the most sticky
addictive stuff for me possible. And it tends to be
that if I get, it's probably going to be things that involve
attractive people of the opposite gender and things that scare me, anger me, or
create in-group outgroup dynamics because it's appealing to my limbic
brain, because if it's appealing to my rational brain, rationally I'd say I need
to get the fuck off Facebook and go get some work done.
And so we see that just using Facebook as an example here,
people who are on the left and people who are on the right of a political
spectrum have been shown to increase the radicalization
of their view because from using Facebook, not
because Facebook has the goal to make them radical, but it simply has the
goal to engage them more in the stuff that scares them and makes them angry
and that they share because they're scared and angry is stickier
and ends up being more viral. So we're like, oh wow, the paperclip maximizer of
Facebook or of YouTube videos that is simply trying to maximize time on
site has as an externality the entire sense-making capacity of the
world getting ruined, right? And individual lives getting worse
in quality and relationships getting more messed up and changing social
dynamics, right? That's a big deal. So we can see that
paperclip maximizing is already happening with what we call machine
learning, artificial intelligence. And the thing that Charles and I
have discussed previously and I think we'll get into now is that
the idea of a paperclip maximizer in artificial intelligence,
that's a thought experiment for the risks of artificial intelligence, but it's
also then a thought experiment for how our
civilization as a whole works, independent of artificial
intelligence, which is if you have a some kind of system of
intelligence that optimizes a particular goal,
maybe at the expense of other goals, right? Because it has a very particular
goal and it gets better at doing that,
there are problems associated with that. If it's part of a complex system where
those other things that it might harm to optimize something
matter for the continuance of life and thriving.
And so we've talked about what we call civilization as a whole
in modern terms and we can think of capitalism to start,
but it's not just capitalism, it's capitalism as the center of kind of
in-group out-group competing against each other in a rivalrous way
game dynamics, of which capitalism is kind of at the center, but
nationalism and all forms of power structures are.
It's a kind of collective intelligence, not an artificial intelligence,
but a collective intelligence that predisposes what all the humans do
and it gets smarter and better at doing what it does.
And it happens to be reductive, meaning moving things in the direction of
particular simple metrics. And so I'll kind of take a break and
see Charles where you want to go before building out the example, but
the idea is that civilization as a whole right now has
paperclip maximizing elements as a collective intelligence system that is
the core of the issue that we have to address.
Yeah, it brings up for me Lewis Mumford
and his characterization of the mega machine, he called it,
which basically he was saying, what was the first machine
in the sense of an industrial entity? And he said it was the first
builder civilizations where human beings were the components of this
machine doing standardized jobs controlled
by the hierarchy, by the pharaoh or whoever it was.
And this allowed whoever was in control of this machine
to perform godlike feats, which was why the pharaoh or whoever was given a
semi-divine status. And he says the basic model of the machine already
existed 5,000 years ago in the standardization of
rules. And then what happened is eventually the human parts
were replaced by mechanical parts so that one person now controlling the
machine can perform a godlike feats like
moving at rapid rates of speed, flying through the air, communicating
instantaneously over vast distances and so forth. We're all gods
now because we are at the helm of of a machine.
And so like so the the machine of civilization could also be thought of
as a computer or as an artificial intelligence because it definitely has
an intelligence beyond that of any human being. It can solve problems
that no one person could solve. And so then then it's what you're saying is
okay so what are the imperatives of this
machine? And gosh it sure looks like maximizing
GDP or maximizing human dominion or producing more
more stuff or whatever motives and incentives are built into the machine.
It's doing a better and better job at accomplishing those.
And yeah where is this going and how can we
stop the world from turning into paperclips or money?
Right so let's explore the model applied to civilization in some detail.
So if you think about a colony of ants or termites you see that the colony as a
whole has certain kinds of intelligence that the individual ants don't have.
None of the ants on their own know how to make a
ant mound of that type or underground labyrinths of that type and yet the
coordinated behavior of all of them has the capacity to do that. So we'd
call this a collective intelligence. And it rather than being centralized that
there is one consciousness of the ant colony controlling
everything it's a decentralized emergent collective
intelligence where we generally think of it.
And we can see many examples of that so
the thing that we're describing here today is that the
the thing that we call civilization is a collective intelligence
that is misfit for its ongoing continuation with itself.
Misfit for its ongoing continuation with life. It has kind of mathematically
self-terminating processes built in and we're getting close enough to the
self-termination points that those can start to become eminent so we'll
look at those. So for instance let's just take capitalism to begin with and we'll
expand because we're not going to say that communism wasn't this it was too.
Capitalism was just the better version which is why it got selected for.
So if we look at what capitalism is as a system of decentralized
incentive. The incentive is controlling or influencing patterns of
human behavior. If people can make money and survive doing
a particular thing and they make less money and are less able to survive
doing other things then there is a incentive to do certain things.
And if they can move beyond just surviving to actually getting ahead
there's more incentive to do the things that keep increasing their capacity
because of all the things that money makes possible.
And eventually those who are near the top of the money hierarchy
want to continue to double down on whatever it is that increases
the capacity to be there. So then you look at what the nature of
fiscal incentive looks like and we say okay well I can't really get
dollars for leaving whales alive in the ocean.
I can't convert their life onto my balance sheet but if I kill them
I can get dollars for that by selling the whale meat and
I can't get many dollars by leaving trees alive in an ecosystem but as two by
fours I can sell them and so in general there's a movement towards
extraction and commodification. Okay so we see the nature of that
movement. We see that maybe the largest block of
global economics were at large if we were to take all the things that make it
up is the military industrial complex. So we see the war is super profitable and
I can make a lot of money by doing that. We look at all the areas we see
so money ends up being a decentralized incentive system that
orients everyone towards the things that can make more of it.
And as we look at the evolution of kind of the economic system itself we say
just like the paperclip maximizer gets better and better at being able to do
its thing we say okay well originally humans were just
sharing resources and tribal settings and then there was exchange between
tribes and then we can look at
early currencies and then eventually fiat currencies and then fractional
reserve banking and then high-speed trading on digital
fractional reserve banking that's very much like the curve of a paperclip
maximizer that is getting better and better at
being able to get all of the humans to do its bidding and here's kind of the
key way of thinking about it. It doesn't have
its own ability to be an actuator to do stuff in the world
outside of getting humans to do this stuff and so any human that does the
bidding of capitalism meaning converts more of
nature into stuff that can be put on a balance sheet
and we're oversimplifying here but to get the idea we'll expand in a moment
anyone who does its bidding well will get more power within the system
right they get more money which ends up meaning more influence and then also
more influence to continue to double down on their ability to keep having that
influence. I get enough money and I can actually start to make laws
by paying lobbyists that support the government's ability to have me keep
making that money or to even subsidize how I make the money or
I make enough money that I can start controlling the media
to be able to control the collective opinion of all the other humans to
support me continue to make the money so there's this
as I do better in the system I get more capable of doing more better in the
system. It's exactly parallel to the AI
learning how to learn better and better right and the humans
so the humans that basically do the bidding of the system get more power
in it the people who are at the top of the power hierarchy are the people who
are most perfectly aligned with the will of that system
and then you look at kind of what the will of that system not from a
anthropomorphic but just from a behavioral disposition point of view
and then the people who oppose the system if they're actually effective at
opposing the system are a risk to those who are in power and they will
inherently have less power so they get taken out of some form
and if you look at like famous people who got assassinated throughout history
they were pretty much all against the paperclip maximizer and they mostly got
taken out by people who are stewards of the paperclip maximizer at the time the
power system and so the interesting thing is it's
not like the pharaoh or the head of the big banks or the whatever is
actually in charge the key thing is that they are a
symptom of a system that incentivizes people to do those behaviors
they are actually an emergent property so it's like
are there sociopaths running the world yes of course there are sociopaths
running the world because if you create a system where
to get to the top of a power hierarchy you have to beat lots of people in zero
some win lose games to get up i have to actually be good at beating
people at good at and oriented to beating people at zero some win lose games
to get to the top which will include lying and disinformation and
externalizing harm and layoffs and whatever it has to
involve but you see it we have a system that attracts
sociopathy and then conditions rewards and trains it
and whereas like living in a tribe you would not do well as a sociopath
right you do very badly and so you don't have an evolutionary environment we
have a system where the very top of the power hierarchy is an
evolutionary niche for those who are most abusive with power
in those particular kinds of ways but effectively abusive meaning that they
they figure out how to game the system to support them continuing to do it
so it's like the are there sociopaths running the world of course
are there people who conspire against for their own goals against other people
of course there are and for every watergate or enron there's
a thousand that don't get publicly acknowledged that doesn't mean every
conspiracy theory is true most of mirjibberish but a lot of them are true
but that's not the cause of the problems it is a symptom of a system that
incentivizes conspiring if you incentivize something it will
happen right that's kind of the supply and demand
dynamic of it and at the heart of the supply and demand dynamic
is not a particular good or service it's get more power within the system
yeah so sociopathic traits are basically part of the job description for
being an elite and if you don't enact those traits then
you will be squeezed out in one way or another
and somebody who is more sociopathic will step into those roles
and you're also saying that there are conspiracies but the whole system
itself isn't a conspiracy it's not that an evil elite
created the system and is running it in order to enslave everybody it's that
the system created the evil elite that operates its levers so they're more
like functionaries than puppet masters
one then of course it's recursive right that's how the system works it's the
deep learning system has a recursive element so the people who get into the
positions of power will then work to control
will work to influence public opinion and influence law
to support them being in power so do they do stuff that is directly harmful
to the system writ large or to the commons at least yes of course they do
and do they do stuff that increases their ability to keep doing that
of course that is what the system predisposition is
well that's not very cheerful Daniel I mean it seems like
like and they're getting better and better and better at it or are they
like some of these things they get exponentially better for a while but
then they you know level off and they reach an inherent limit
like it looks like our civilization is doing that in a way
which is reflected in the slowdown in the rate of economic growth
the decreasing effectiveness of our technologies to
solve basic problems like it doesn't look so exponential anymore
what do you think about that yeah so
if we think about the development of the things we call civilizations
historically there will be some pioneering effort
to go explore some new territory niche of some kind
most of those don't work and they're expensive and then the ones that do work
become the basis of a new development and then
you get a lot of development on whatever that thing is hey now we're mining
like we figured that thing out or now we've got this spot that's good or now
we're working the plow here or whatever it is
and then you will start to get to a place where you get
you know early people having captured much of the
power system associated with those things the pioneering landscape having
not having open opportunities for new people to pioneer from scratch
and so then everybody else has to work for the people who already did the
early pioneering in some kind of way and so the
first people who were doing whatever the thing was
had a direct relationship with pioneering innovation with actually
the natural world itself or with um yeah reality itself
and then and so they were able to get ahead through an innovative process
at a certain point there's no more space to actually
innovate or come up with new stuff so on your own so what you end up doing is
working for the existing system and now
all those people are in a domestication system and there is an upper limit on
what they can do and the only way they can get ahead is to climb that power
hierarchy so they go to work for a company rather than the very few people
who found the company and of course most of the companies fail
when the founders do it they fail the few that make it and there's now a huge
cash stream coming in then everybody goes to work there
the people who work there are not going to have as much power as the people who
founded it as time goes on it gets bigger even less so
and at a certain point climbing that power hierarchy whether it's a
government or a corporation or whatever becomes my
only way to get ahead more than doing fundamental
innovation and so i have to get better and better at figuring out how to
win that power hierarchy kinds of stuff and so if you look at
the court of Versailles and Louis XIV and the courtier type dynamics there was
a world where everyone like nobody was trying to make
fundamentally new stuff or new innovation there was no real pioneering
space everyone was just trying to get more of
the power somebody already had you know bestowed on them
and this is what we call politics and the things that give you power within an
institution are not necessarily the same things that
make the institution more effective make the government work better make the
corporation make more money even like so very very often
uh actually it's usually the opposite of that right so
we can't do things that are so damaging to it that i damaged my ability to get
ahead but i also don't need to optimize the
organization i have to optimize my own bonus structure within the
organization i have to also optimize my ability to
get away with the fact that optimizing my bonus structure
is not optimizing the company and so that looks like
hiding transparency like systems that decrease transparency and the decrease
accountability so we'll make a limited liability
law that doesn't make me accountable to certain things we'll make
certain kinds of corporate veils where nobody can even tell who's doing
certain things well you know whatever right and those
basically those breakdowns of accountability and justice
end up leading to again doubling down on the environmental niche we're doing
the more sociopathic thing actually is selected for
but i guess what i'm saying this is we see this interesting thing where
you know in the last years and decades there's a tremendous amount of new
wealth that is not part of kind of older wealth systems because of a
proliferation of software tech and the people who do that
are still part of the paperclip maximizer as a whole
but of a slightly different type someone who didn't
come from the mindset of being at the top of a power
hierarchy and mostly maintain their power hierarchy without actually
innovating new novel goods or services or
discovering new stuff basically that adaptive environment is
pretty close to purely political which is mostly sociopathic environment
the make new tech from scratch that can meet some good or service that can meet
some need for someone is actually a more adaptive thing so we can see
that happening which is cool we can then also see though that that
tech even if it was created for an in a positive intention at first
both has externalities like facebook created hope
like will be generous and say for the purpose of connecting people socially
actually leading to much worse social connectivity and political polarization
radicalization and breakdown of sense making writ large
and that's because of its financial structure if it wasn't optimizing for
ad revenue it wouldn't have to optimize for time on site it could apply
its capability to radically different things right and the same is true with
youtube's algorithms the same is true with all of these so even if it
starts for a positive purpose it ends up becoming captured by the
machine if it is to continue to be successful within this larger
machine of capitalism okay so there's two things that
i want to basically name that you've already
described i'm just want to make them explicit and see
how they relate one of them is this i called it a mega machine but
civilization that's getting better and better at converting the world into
money on the other hand we have
inefficiencies and dysfunctions within the machine
that are incentives incentivizing behavior that doesn't necessarily make
the machine get better and better at converting the world to money
because what serves someone's personal interest
can actually make the whether it's a corporation or the mega machine as a
whole less efficient so does this mean that there is
a light at the end of the tunnel like a way out from
a bleak future of the entire world just turned into paperclips
like could we build an alternative or could we
somehow take advantage of the built-in inefficiencies of
organizations as we know them that are financially motivated to
supplant the civilization with something better
is there a solution yes i propose so and we'll get to it
it's not from exploiting the inefficiencies because what makes a
corporation inefficient or a country inefficient
actually still serves the paperclip maximizer writ large because it just
moves the center of power from that corporation
from you know microsoft to google from us to china or you know
british empire to us or whatever it is and so the paperclip maximizer keeps
doing quite well as the local parts rise and then collapse rise and then
collapse but continue to whenever one part is
starting to collapse all the adaptive things that learn just move to a new
center uh-huh there's a couple more ideas we
have to construct to get into the alternative because we
we haven't specified the key of why this system works the way it does yet
okay i'll be patient so one thing you know you and i've
talked about this before when we to define what evolution is
not just in a biologic sense but the the deepest sense that complexity science
gives us is that evolution is a increase in ordered complexity
that leads in the direction of emergent properties
and that what's being selected for emergent properties so
you know a cell respirates even though none of the molecules on their own that
make up a cell respirate it's an emergent property and
so there is advantage to those molecules being together from even a
thermodynamic perspective that there isn't being a part so we can
say that biologic evolution is a special case of this larger principle by
which subatomic particles come into atoms into molecules and to
there is a process of increasing complexity
but specifically complexity that doesn't have emergent property doesn't get
selected for so it's ordered complexity in a
certain way as emergent property the emergent properties come from synergies
and so we can say evolution is defined by these kinds of
synergies and increasing complexity so we look at a biosphere
and we see we see the complexity of a single organism like a cell that is
really incomprehensible and or a tree but then we look at the
intercomplexities of all the cells in a tree or all the cells in an animal and
then the relationships between the aerobic and the anaerobic bacteria
between the predator and the prey and between the
gas exchanges and all the things like wow right and
and it keeps increasing over time of course you're going to have
some species die off and new species come about but we're
over time you get an increase in the complexity of the species from
single cell you know up to neurologies and then
reptiles and mammals and primates and on and on right more complex nervous
systems more complex behavioral patterns
so the interesting thing there is we can we can see that the paperclip maximizer
has the exact opposite directional orientation as evolution
does evolution is increasing the orderly complexity
and
in which automatically means that it increases the type of diversities in
the system and the synergies between those
diversities right so in an old growth forest
there's radical diversity and also radical synergy across all those
diversities and and it's oriented to the continuation
of both the diversity and the order the agency and the
communion the individuality and the interconnectedness
um and the paperclip maximizer takes complex stuff and makes simple stuff
out of it and so if we think about that for
a minute we take the example of a tree in the forest tree in the forest is super
complex you know if we ask like what is the
value of a tree we have to start by even saying value to whom
in whose perspective who is the beneficiary of value
and we start to look at and we're like well pretty much
everybody is a beneficiary of the value of the tree but there are
different kinds of value the pollinators come get a certain thing and
the birds that live in it get another thing and the squirrels that live in it
get another thing and the fish that live in the river that is cleaner water
because the topsoil was stabilized by the roots get
another thing and the fungus in the soil that has the
mycorrhizia that has a relationship with the roots is another thing we're
like okay and the the sequestering of CO2 in the production of oxygen for the
mammals so the tree has a kind of indefinite number of beneficiaries
that it benefits with an indefinite number of different
outputs right so this is like not optimizing for a single output
to a single kind of beneficiary it's uh you can't even call it optimizing
actually um but if you wanted to say that just
loosely here it's optimizing for synergetic benefit across this whole
interconnected web of things and so we take the tree and it's not worth
anything economically to me but if i cut it down
and turn it into a two by four now it's worth something economically
and the tree is self organizing and self healing
if i burn the forest the forest will regrow right
if i burn the house that i'm in made of two by fours it doesn't regrow if i
burn the two by four it doesn't regrow and so
i take something that is anti-fragile that is resilient
and i turn it into something non resilient and fragile i take something
that affects many beneficiaries and i try to capture it for one beneficiary
i take something with many value types and i try to turn it into one value
type right so now i turn this very complex
thing of a tree into a very simple thing called a two by four
and then i might build a complicated thing out of the simple things
house complicated different than complex the tree self organizes the house
doesn't self organize make a blueprint somebody builds it from the outside
the forest self heals the house doesn't self heal the forest evolves towards
more increasing complexity the house entropically breaks down in time
yeah so humans build complicated stuff complicated stuff is inherently fragile
our our laptops don't self repair they don't self organize
neither do our roads or infrastructure our water systems or whatever
and so we convert the anti-fragile complexity of the natural world that
evolution brought about into simple and then complicated
fragile and entropic more than centropic
stuff which require top-down management because
they don't organically maintain themselves right
i mean maybe another example of it would be the imposition of monocultures
cultural agricultural various kinds of monocultures on the world
which is reduction of uniqueness and complexity into something
simple the ultimate of which would be the monoculture called money
which is pure quantity right so say i take the tree
i turn it into two by fours and now i can accumulate a bunch of these two by
fours so i can build something out of it but i can
also trade them but they're a little bit cumbersome to trade
actually i can't the liquidity is not high enough that i can just trade a
bunch of minute hurry if i want something else
so actually don't even want to store the two by fours i want to sell them right
away and get money because even though the money
has no actual value it's purely representative value meaning i can't
build a house out of it or eat it or really anything
because of its liquidity for other forms of value it seems to maximize my
choice my freedom my optionality so i don't want trees i want two by
fours and i don't want two by fours i want dollars
and then because i can't spend a dollar on amazon i actually don't want dollars i
want bits which is the digital dollar in an account that has maximum
liquidity and its potential and so we actually see
each of those are a step towards more simplicity
and so now we have a world that wants to convert
the natural world and human creativity and human labor and all of it
into bits of a particular type that are abstractable
fungible tradable optimizable that is exactly the opposite direction of
evolution it is decreasing orderly complexity it is converting
the anti-fragile natural world into an increasingly fragile built world
and then we're trying to run exponentially more flow through an
increasingly fragile system so when we look at
oil pipeline spills we look at the fragility of the system that's trying to
run more and more stuff through when we look at wars and economic collapse
and environmental collapse we're looking at breakdowns of fragile systems
but if we keep trying to convert the anti-fragility of the natural world
into increasingly fragile world that we're trying to run exponentially more
flux through that self terminates and process self terminates
but there the fiscal incentive is in that direction
and again it doesn't take everyone like you could have a lot of people who are
like man something matters more than money i don't want to do that
but anyone does that thing and of course they might have a fiduciary
responsibility to shareholders they might whatever it is
anyone does the thing that continues in that direction and they gain so much
more money which equals power which means adaptive
advantage that everyone else has to justify continuing to do that or they
lose in the economic competition by default
now that's the concept you mentioned earlier called the multipolar trap
the multipolar trap is one term to be able to explain a scenario where
you've got a lot of different agents that are in a soon competitive
relationship with each other so the agent could just be individual people
competing with other people or it could be tribes competing against each other
or corporations or countries right but some
agent that is acting for its own benefit through the polls in the
multipolar right okay and so if any of the agents
does something that is bad for the whole bad for the commons
over the long term but that provides a lot of near term advantage to them
there's a big incentive for them to do that and if they do
then all the other agents in the system have to try and do that as well to not
lose where that agent was getting ahead
or they do lose by default so they basically anyone
exploiting such an opportunity creates a gradient for everyone else to race to
exploit that opportunity so the tragedy of the commons
and the arms race are two classic examples
tragedy of the commons is okay i don't want to
fish all the fish out because i actually think fish are beautiful i'm in a
tribe or i love them i want them to be there in the future
i don't want to cut down all the forest i think forests are beautiful i want to
keep hunting in it and i actually don't need that many trees
but if i only cut down the trees that i need from our tribe only cuts on the
trees we need and to leave the forest the forest
still isn't going to get left because the other tribe is going to go cut down the
trees or some other tribe beyond that one is
so i don't even have the choice to protect the forest
so if it's going to be them cut down the trees or me cut down the trees and if
they cut them down they're going to build weapons to attack me
they're going to build storage of resource to get through the famines
they're going to all those things i have to go cut the trees down
not only do i have to cut down more than i need and store it i have to do it
faster than they do because they are an assumed competitor
but they're thinking the same thing they're only doing that because they
assume i'm going to so everyone is now in this
situation where they assume somebody does the fucked up thing and i'm like
well we could make a treaty okay so me and this other
tribe and the other tribe close by i'll make a treaty that we only cut down x
number of trees cool but the other tribe is totally
sucks and they won't join the treaty and so they're going to do the fucked up
thing so we can't even keep the treaty we all have to do the thing
so then we cut down all the trees and we actually race to go from
axes to saws to chainsaws to whatever to cut down the trees as fast as possible
to get there before the other guy and this is why 80% of the old growth
forests are gone this is why 90% of the large fish species
populations are gone the whales the whatever else is because
multi polar traps so that's the tragedy of the commons example
and the arms race is if some say somebody produces this new terrible weapon
and nobody wants to live in the world with that terrible weapon because it's
just worse for everybody everybody's more likely to die in terrible wars
but if anyone produces the new terrible weapon everybody else has to produce the
terrible weapon to be able to have any chance in war against them plus they
have to produce defenses and counter offenses to the terrible
weapons they have to increase total terrible weaponry
in a lot of ways right and if they don't they're just gonna lose
so we saw that with nukes we see that with ai weapons happening right now we
saw that with chemical weapons biologic weapons we saw that from the canon
right like just the the bronze age the stone tools
and so here's how we define it where an agent can get ahead
independent of the well-being of other agents or the commons and even at the
expense of other agents or the commons that's the rival risk game
theoretic environment rival risk meaning i i am both rival risk
with the commons and rival risk with other agents in that environment my
ability to exploit the commons faster than the other guys
and find some new way to do it in which case then all the other guys need to be
racing to do that same exploitation with me
there's no way to bind that
unless we try and create the historically the only way to bind that
what we call multipolar trap is with some agreement right that's what the
can we make a treaty to not do it is but how would we enforce that anyone keeps
the agreement well there has to then be some monopoly of force that is
stronger than any of the agents that can say hey if you don't keep the
agreement we're going to put some force on you to push you back into it
so one of the main reasons we have created states
governments is to bind multipolar traps so you have some monopoly of force
meaning the police force that is backed up by the national guard of the military
force whatever that is backing up law because law
wouldn't be that thing without monopoly of force
so the idea now is we try and create laws to bind the multipolar traps
you can't cut down trees in the protected area right in the national
forest or whatever it is so we have an EPA or an FDA or
an FTC or somebody to protect against some bad action
backed up by a monopoly of force now and that's a national level or a state
level but it can also be at an international level
that's the idea of what the UN is right the that after world war one we're
like oh national governments on their own can't actually govern in a way that
keeps them from wanting to blow the whole world up
and our technology is now so terrible that we can't have wars like this anymore
so can we create some super national organization that was the league of
nations league of nations obviously failed in its
goal of preventing world war two and so we changed the name called the united
nations and so the goal there was let's
let's do nuclear disarmament because now nuclear is the really big thing and
let's prevent spread of nukes and the use of them
and we haven't had world war three formally kinetically yet
but we went from two countries having nukes to
19 or however many having nukes and nukes not even being the concerning thing
now in the proliferation of exponential tech mediated weapons everybody's got
them not even state actors so we're like okay well why is it that the top
down force the UN has a monopoly of force why can't it keep the nations
in check well because the nations have too much power for the
UN to have a monopoly of force over them so say your country with nukes
and we're trying to do nuclear deep proliferation we say okay you're gonna
you're gonna give up your last nuke now you're like no i'm not that's
fucking stupid i give up my last nuke and somebody's gonna come invade me
who has nukes and so you'll lie and say this is your last nuke while stock
piling some other ones right and then not agree to the inspections or
whatever it is and because you assume that whoever
else is giving up their last nuke is also lying
and stock piling some and so this is the multi-polar trap thing right
and so then if the UN so nobody wants to volunteer to give it up so then can the
UN force and say we're gonna force you to give up your last nuke they're like
no fuck off we have nukes you're not you can't do that
so multi-polar traps from bottom-up dynamics market style dynamics can't be
bound by the market or countries competing
by each other can't be bound by the country they can't be bound at their own
level and top-down forces can only bind them
when there is a monopoly of force and that is oriented to bind them
and at this point because of exponential tech
there can never be a monopoly of force in the same way there was previously
because the bottom-up forces are too powerful
to be overridden in that way and so we say oh
all right so now we have this place where we have multi-polar traps of all kinds
right now it's build AI as fast as you can for all purposes that
there's incentive for including weapons right or things like that
and if anyone makes a law that tries to
protect against something like an environmental destruction
whoever has the economic interest to do that environmental destruction has the
economic incentive to pay lots of lobbyists
to change the law and to hide that under some
other thing that doesn't seem to make any sense that nobody pays attention to
and to pay for campaign budgets and to you know all those types of things so we
end up seeing that law falls to economic
incentive when it's even though it's supposed to bind
economic incentive the problems of it because economics is actually deeper
in the stack of power than law and government is
yeah quite a few things in there you're basically
establishing one pillar after another after another
of an argument that i think you're going to continue developing
i'll just add like maybe a supporting comment i i read a little bit about the
actual tragedy of the commons the textbook example was villagers grazing
their sheep and it's to the advantage of any one
villager to graze them as much as possible so that his herd increases
but if everybody does that then the pasture gets overgrazed and everybody's
sheep die but no it's to nobody's interest to reign
themselves in historically however according to
what i read that didn't happen because the community had
explicit and implicit agreements social pressure if you were grazing too many
sheep then people would make life difficult for you and you would feel
shame and so people actually got along quite well
and didn't destroy their commons until market economics
and the idea of the separate individual came in
and introduced that logic and weakened the informal ways that people
regulated the use of the commons and when that happened
then the imposition of force by a state became necessary
so it was kind of a substitute for right yeah
okay so this is a super important example when we say that there's a top
down force that binds the bottom up one that has a monopoly of force
monopoly of force from the way we think about it today is
um a actual police force or military force that is asymmetric to
the physical rebellion capacity of a subset of the population
now there was something that you could think of as a kind of monopoly
of influence before state type dynamics that weren't just mediated by
those type of police forces and it was what you're describing right in a
community if someone starts behaving a poor way
being ostracized from the community right like being shamed or being excluded
or people not wanting to interact with you
you're you can no longer do it you can't actually get ahead or survive if you
can't interact with people and so uh that was actually able to work
at a fairly small number of total people where there was transparency to the
dynamics right so there's only three sheepherders
that can be letting that grazing happen and
anyone who's doing the thing everybody can see so remember how we said when
there is a breakdown of transparency or a breakdown of
accountability you create the environmental niche for the bad actor
so as we get to larger sizes everybody can't see what everybody's doing and
it becomes easier and easier to obscure this which is then where you have to
try and say okay well can we make government bodies that can do
investigation and that kind of thing so if you think about like
if i if i'm in a big corporation nobody no one's really watching what i'm
doing um in the same way that they would be in a
tribe and particularly the only other people who will be watching that closely
might have somewhat i can coordinate it that they might
have somewhat aligned interests but it's not like the actual end users that
we're making products for that are on the other side of the world have any
idea what i'm doing and or there might be some
accountability within the corporation to make sure you're not imbezzling funds
or something like that yeah that you know but that only keeps you
acting in the interest of the corporation not in the interest of
the other the other stakeholders the corporation
right and so this is actually really important
for most of human history we had people inside of families inside of extended
families inside of communities inside of groups of communities
and there was
um there was organization that happened at each of those levels and it's kind
of like cells inside of a tissue inside of organs inside of
organ systems inside of a body it's not just like 50 trillion cells
inside of your body with no substructure organization
wouldn't work at all but right now the family doesn't actually provision
resources all that much families become a largely broken saying especially the
extended family and the families were actually very good at
provisioning resources having an inner invested in each other that
wasn't game theoretic and knowing what each other
needed having enough awareness that if someone had resources they could
provision within the family and communities tribes were also
pretty good at those types of issues because you could actually see what was
going on and they could be inter invested in each other
and now you mostly have the individual interacting with the market in the
state right the the big giant everything
that is impersonal and the individual as a voter
consumer producer and that system is neccess is definitely
broken right so the problem isn't so much that there
are too many people or that the scale society is too big it's more that there
aren't enough coherent intermediary structures like you
could imagine having a community where it's small enough that people
usually regulate each other's behavior and you're not going to raise your sheep
too much because then the blacksmith isn't going to help you and
and the herbalist won't treat your kids and so and then you can imagine having
the community interacting with other communities
in a similar way where if one community doesn't behave well
then the other ones assuming that they're interdependent enough the other
ones don't provide it with something at ease then you could have
right a community of groups of communities and then a community of a
community of groups of communities and you could imagine a planet
operating on that level which would be a complex
organic structure rather than a disintermediated
world where you'd have an undifferentiated mass
of people and a hierarchical control structure
in the model of industry which is all about the standardization of parts
the standardization of inputs and outputs and so forth
so maybe is where you're going with this like some kind of
successor to the industrial model of organizing society
um so so let's look at
complex systems that evolved and have orientation towards
increasing evolution and anti-fragility and like that
so there's a couple key principles that we see that are important here
let's say we look at the 50 trillion give or take cells in a body
which cells kind of run the show is a silly question
there are no few cells that are elected representatives or dictators or
whatever which cells have really asymmetric power over all the other
cells there are none and that was a delusion of
physiologists i mean they people fought that while the brain must be in charge
but it's totally not like yeah yeah right the cells in a petri dish will
continue to do their own thing from liver cells or kidney cells or fat
cells or they are self-regulating in a bottom-up way
there are top-down effects where the neuroendocrine system is gathering
big picture messages and then communicating big picture information
back for coordination but the coordination is not just happening at a
bottom-up cellular and top-down whole system level
there's coordination happening at the level of a tissue and there's
coordination happening at the level of an organ and at an organ system so there
is something that is neither bottom-up nor top-down
and where the bottom-up influences cascade all the way up to this emergent
top thing the top-down influences come in turn affect the bottom-up ones but
it's happening at all these layers and there's a kind of coherence phenomena
and so this is neither market nor government this is something
much much more interesting and much more complex but you see that
at the level of a cell there's a symmetry of power where all the cells
they're all doing their thing but none of them have asymmetric power over
any of the other cells and you can think about as far as messaging goes
cells are capable of sharing messages to other cells that they have a particular
relationship with mostly adjacent cells right
we can see some effects where it'll be an endocrine effect but it's still
going to be things of a particular receptor type that it evolved to have
that relationship with so why that is important
let's say a cell becomes a cancer cell this happens all the time
to some degree just because of mutation oxidation whatever that occurs
the job of the body is that to prevent the kind of carcinogenesis that makes
cancer cells to make it much less common but when it does happen to actually
convert the cancer cells back to healthy cells and if
it can't then it has to kill them so they don't spread
and kill the whole body because then they're acting in a way where their own
interest is put against the interest of everything else unlike healthy cells
healthy cells you know liver cells are not competing with kidney
cells to accumulate more of the scarce resource
and liver and kidney writ large are not competing in that way right the
bones will move calcium they're holding into the blood for ph
buffering or into the brain for calcium ion
dynamics and then move them back in for storage and there's this very complex
provisioning that is optimizing the well-being of the whole system across
every kind of metric
but imagine that one cell became cancerous and it had the ability to
broadcast its cancer signals its cancer genes to every other cell
simultaneously and they would be uptaken because they
hit some kind of addictive gradient or near-term
advantage gradient well everybody would die of cancer very very quickly
and so it's important that they're only able to affect nearby ones and the
nearby ones exert a restorative force on that one
and so it actually requires the cancer is going to grow somewhat slowly the
body has a lot of opportunity to deal with it this is the only reason we're
not all dying of cancer all the time and so today though
when you look at what broadcast media is or you look at just asymmetric power of
any kind well what is the asymmetric power of a
a Putin or a Trump in terms of kinetic warfare compared to you or me
right it's it's trillions of times what is the asymmetric
fiscal power of a Gates or a Bezos compared to us what is the
asymmetric messaging capacity of a top celebrity right in comparison
and so we look at the tools that are mediating that kind of asymmetry
so broadcast messaging is a good example i can transmit a meme that will catch on
because it has certain stickiness or limbic hijacked dynamics but it's
actually a bad meme it moves things in the wrong direction but i can
broadcast it to everybody and there's no check mechanisms to see that that was
actually a good meme that was adaptive for the whole
that's actually super destructive super dangerous and you say can we have
anti fragility in the presence of any agent becoming
maladaptive and being able to influence the whole asymmetrically
nope and so now we come back to the example of
if i was in a family in an extended family in a tribe and
and i started doing something that was maladaptive for the tribe there would
be a pressure that sought to make me healthy and
first it would see it pretty early and sought to make me healthier before i
had the ability to influence everything
um this is an important thing that's missing and
so when we start to think about extending asymmetric influence technologies
and where an individual or a small group can influence the whole thing too much
which exponential tech does exponential tech means i've exponentially
bigger levers to make choices with i mean more impact from my choice but
nothing ensuring exponentially better choice making
and better in a good for the whole not just a game theoretic get ahead at the
expense of everybody else choice making that equation itself exponentially
more powerful choices without exponentially better choices
is also a fundamental problem right so we need to say how do we get
good choice making to scale faster than the power of our
choice making this this is like a fundamental thing
that we're looking at here but so let's say we extend exponential
technologies the next several years we say okay
so crisper biotech gene drives making it to where more and more people can do
really fucked up things on smaller and smaller scales the ability to do
cyber warfare ai nanotech whatever these types of things because
as we see with exponential tech it doesn't just make exponentially more
power it also makes the power cheaper
right we look at the cost of computation or any of these things which also
means then more decentralized so it's not only state actors it's
non-state actors it's smaller and smaller groups having more and more power
and that's like having each cell if it mutates have the ability to affect the
whole system too rapidly so there is no possibility for
anti-fragility for resilience in that particular structure
so if you ask people who study existential risk
like exponential tech mediate existential risk how do we avoid
blowing ourselves up from stuff that people are doing in their basement with
no exotic materials that nobody can tell a very common answer is
ubiquitous surveillance universal surveillance everywhere nobody can be
doing anything in there and again we said it's when there's a
lack of transparency that a lot of these problems start to happen so that we can
see why someone would say that right is we don't want somebody in their
basement being able to build crisper weapons that's a bad idea
and yet we also don't want 1984 and if we have a surveillance state where the
state is there's a structure that guarantees that the
state is going to move towards corruption because that's how top-down
power hierarchies work and you have a power hierarchy of one to many power
structure the state has surveillance on everybody everybody
doesn't have an input back to that and it's oriented to be captured and
corrupted all right that's so that's a failed system
but not having that seems like a failed system in the presence of exponential
text it's like what what the fuck do we do so
you know you can see that even with the technology the killing technology of
guns as opposed to knives you just can't kill as many people with a knife if you
get if you go wacky right so when we look at mass shootings
whenever we hear that somebody took an air-15 and went and shot up a bunch of
people and the news reporters go and do the
investigation the neighbors all say yeah he was
real quiet he kept to himself we never heard from him
etc what that means is that person might have been progressing
as a cancer cell right they might have been progressing in their own psychopathology
depression and upset for years with no one
actually engaging with them to be able to see that they could go to the store
buy food and no one noticed if they were upset or not or healthy or not in the
way that they would in a tribal dynamic if you have people who can isolate
themselves progress in their psychopathology not be checked and they
have air 15s you're going to have those kind of shootings if they have access
to progress in those types of isolated dynamics and they have worse weapons
it gets worse so what do you do well you don't have to have
surveillance by the top-down state remember there's a top-down force that
happens not at the level of the whole body to a cell but even a tissue to a
cell and so this is like if that person was part of
a family and part of a tribe where they actually needed each other they
couldn't just use this abstraction called money to get their needs met
without having to interact with humans in any meaningful way
the other people would see hey this person doesn't seem well let's
spend more time with them and work with them and help them be healthier
so this is a kind of surveillance but it's not a top-down captured surveillance
it's a mini to mini rather than a one to mini kind of system so there's a
cemetery in it and this is a how do we have more
awareness of what's going on for everyone so that
we can help people actually be healthy this is not
sufficient for but it's necessary for having
choice-making be our choice-making basis be capable of holding our
choice-making power
yeah i've been thinking about this for a long time
in phrasing a little bit differently but but how do we restore community
when we have a system that strip mines community
because community is based on it's not just
people knowing each other but it's people depending on each other
so the economy as we know it replaces interdependency with dependency on
distant abstract institutions and anonymous service providers
mediated by a very complicated division of labor
when when production is on such a vast scale
and requires such a fine division of labor how can you have
meaningful community when all of our needs
our tangible needs at least are sourced from afar
and not yeah so right so so one one avenue is to
relocalize and replace some of the functions that we've
handed over to a global mega machine with
locally met needs and there's already movement in this
direction for example the food movement people are wanting
to source their food locally but the economic system
is stacked against that because of externalized costs
mostly so let us shipped from california
to the east coast is cheaper than let us grown here
because of the subsidization the perverse subsidies embodied in roads for
example and the external environmental costs
etc etc so from what you said the people who wield power
aren't going to change those conditions because
they are part of the paperclip maximizer i mean they are
their job is to maintain those conditions from which they personally
benefit but also the paperclip maximizer
benefits in this production of paperclips so and it seems
that the system has only strengthened its grip
over the course of my lifetime and i mean forever
so it looks like a really bleak picture you're painting here
like yeah we know what the solution would be to restore
connection to to each other to place to community
so that we can have informal bottom-up organic
surveillance or you could say transparency so that we can identify the
cancer cell before it starts shooting its cancer messages
out to the entire world before one unabomber in his basement with a
you know genetic engineering crisper technology is able to
unleash something horrible uh we know what we have right now we have a
rivalrous system that compels everybody in it
toward to enact behavior that is going to destroy everything
and we know where we want to go which would be to a society organized much
more like a body with multiple levels of complex structure interacting with
each other and enabling us to be
transparent to the people around us in this kind of nested system
that is non-hierarchical that has an interplay of bottom
bottom down and bottom up and top down dynamics
that evolves toward greater and greater complexity
we know where we are we know where we're going
do you have like at least like a little uh a little through line from here to
there like how do we take a step into this transition
yeah
the heart of the problem
is the word that you mentioned a couple times is power
and what we're talking about is a system where the primary concept is not power
power meaning power over or power against in a
rivalrous way in a game theoretic way where the core idea is resiliency we
could think of we could use different terms resiliency strength
whatever where the goal is not to maximize my power
over the environment or other agents it's to maximize my sovereignty
and my ability which includes my ability to not be controlled by other agents
right to be anti-fragile to power without actually engaging in the game of
power that it's a fundamentally different
and kind of critical distinction because the game of power is actually the
paperclip maximizer and capitalism is simply a part of it
and this is the key thing for us to construct so we can show what the
alternative looks like
a lot of people are going to maybe be thinking um
Daniel it seems like you missed biology class and uh don't understand how
Darwinian evolution works and that uh these type of rivalrous
behaviors are nature itself and we evolved to have these kind of
rivalrous dynamics and you're asking for something that is outside of human
nature or outside of nature itself this is an important
point to address because i can't offer what an alternative is if people think
that it goes against what is actually possible
and something that we need to understand in terms of the nature of this
situation we're in is that if we look at ecosystem natural
systems came about through evolutionary process
there are rivalrous dynamics there's also heaps of symbiotic dynamics and
there's a lot more symbiotic dynamics and there are rivalrous ones
but there are rivalrous ones and they're worth pointing out
but even the rivalrous dynamics end up driving symbiotic dynamics at a higher
level and this is a key part that we have to understand and we have kind of
understood it we've based our theory of markets on this idea
so you know the key example is we look at competition in terms of
various animals of the same species competing for reproductive opportunity
and obviously predator-prey relationships being directly
rivalrous there's plenty of things that look zero sum
and so we look at a fox chasing a rabbit
and if the rabbit if the fox catches the rabbit the rabbit's dead
so that's pretty clearly rivalrous if the rabbit gets away the fox might
actually starve to death or not be able to feed its kids so there's a very
clearly rivalrous dynamic but we see that the foxes as a whole
species and the rabbits as a whole species actually depend upon each other
they couldn't even really survive without each other and they're driving
each other's evolution because the slowest rabbits get eaten
the slowest foxes starve and don't uh don't mate
the fastest of both get through and then those genes reselect and so rabbits
are evolving and foxes are evolving because of each other
and if it weren't for the rabbits the foxes would have nothing to eat and if
it wasn't for the foxes the rabbits would eat themselves to extinction
so we say oh this actually very interesting at one-on-one interactions
there's a rivalrous dynamic but it leads to a macro symbiosis
so how is it that micro rivalry becomes macro symbiosis
and the key insight there is that there is a symmetry of power
between the fox and the rabbit between the lion and the gazelle between the
shark and the tuna between all these places
where the prey gets away as often as it gets caught
and or more often whatever the particular symmetry is
but there is a there is actually a power symmetry that has it to
where that dynamic between them doesn't have one get asymmetrically ahead of
the other one so they both co-evolve as a result of that
process but we could imagine if the foxes had a mutation where they got 100
times faster in one generation that they would eat all the rabbits their
population would boom and then they'd all starve to death
so breaking the symmetry of power would actually break how evolution works but
the symmetry of power is never broken in evolution because
what leads to right natural selection mutation and then selection of the
adaptive mutations both survival selection and
sexual selection that happens the same everywhere right there is a
distribution of what creates the mutation dynamics and so
there the symmetry of power is maintained as the whole system
steps up until technology came about and with early humans
homo habilis double down and homo sapien was the beginning of a creative
process that is different than anything that had happened in the evolutionary
process up to that point where we were able to increase our power
not through the same kind of slow mutation process that was
increasing it on all sides in a way that actually broke the symmetry of power
so we could make stone tools and we could go hunt and we became radically more
lethal became better predators faster than the
environment could adapt to our increased
predative capacity and so we could over hunt a whole environment
and then not only did our tool making capacity allow us to do that it also
allowed us to put on a skin and move into an environment that we hadn't adapted
so we could go to the Arctic like polar bears in the savannah like cheetahs and
the like we could go everywhere and become the peak predator in every
environment that's a fundamentally different deal because
micro rivalry leads to macro symbiosis only if there's a power cemetery
if the power cemetery is broken micro rivalry leads to macro rivalry
without bind and ends up self-terminating and so
if we take evolutionary rivalrous dynamics and multiply them
by technology which creates increasing asymmetry and eventually exponential
technology you do get an unstable system an unstable
oscillator that eventually breaks down so because of our technology the social
Darwinist idea that markets are basically a Darwinian evolution
process where different companies will create mutation on the same product and
the one that people like will get selected via supply and demand dynamics
the idea actually doesn't hold in the same way because we do have the ability
to outstrip environments faster than they can reproduce themselves
kill whole species whatever and if we are debasing the substrate upon which we
depend then we're self-terminating and that's how this is happening so
our tool making has given us enough power that rivalrous dynamics are unsustainable
this is the key thing that i'm wanting to share
rivalrous dynamics where they occur are actually sustainable where there's a
cemetery of power but we have a radical asymmetry
between humans and other humans and between humans and the rest of the
ecosystem in nature there's a cemetery between lions
and lions right the in competing for reproductive
opportunity no lion is a thousand x more powerful than another lion
and between the lions and the gazelles right now we've broken it to where the
human to human and the human to nature
asymmetries are many orders of magnitude
so we have to figure out anti rivalrous relationships with each other that can
hold that technological power with each other and with the ecosystem
or we actually self-terminate and this is the key thing within the presence of
exponential tech
and even before exponential tech right like we started desertification thousands
of years ago we started extincting species a long time ago or over hunting
environments and we also started larger scale warfares than any other animal
was capable of having as our technology got bigger
it's and so whole civilizations have collapsed for these reasons it's just
we have a totally globalized civilization for the first time
where the scope of this is much larger the degree of power we have necessitates
an evolutionary change like a fundamental change to evolutionary
process itself where we can't model ourselves as apex predators anymore
where you know a great white shark can kill one tuna at a time we can use an
a super trawler with a mile long drift net and kill all the tuna like
you can't model yourself as an apex predator with that kind of asymmetric
technological power when you have the ability to destroy whole ecosystems
make whole new environments genetically engineers new species
you have to model yourself as nature itself which is the only thing that has
had that power previously and recognize that
if we're moving in the direction of increasing simplicity the paperclip
maximizer direction that is a self-terminating direction
if nature is moving in the direction of increasing orderly complexity and
we're powerful enough to affect all of nature we have to actually be stewards
of the increasing orderly complexity of the whole system
so we move to from just being parts of the whole competing with each other with
broken power cemeteries to saying okay the level of power we have
we've kind of got the power of gods we have to have the wisdom and love of
gods to be able to steward that that's a way of thinking about the transition
where it is
unconscious evolution of the whole right natural selection is kind of this
evolutionary process that we don't think of as conscious
then toolmaking is a conscious process but it's just parts
right in rivalrous relationship with each other
the next part is conscious evolution of the whole which is really this kind of
new epoch phase and that is a fundamentally different
relationship to not only power but even identity
and this is where you come to why we need a new story and a new mythos where
where there is no way of thinking about me my race my nation
independent of all the other people and independent of the ecosystem because i
actually don't exist without them i can't and my rivalrous dynamics with them
will lead to their increased rivalrous dynamics lead to the
self-termination of the whole so when you ask how does it transition
i don't know that we have the time to get into what is a new
method of collective sense making and collective choice making and
provisioning of resources that replaces what we think of as economics and
governance now and how do we do toolmaking in a way that
doesn't cause externality but culture actually has to be the
first part of the transition because our new social
systems our new economic systems are going to require new types of toolmaking
that mediate them in the same way that it's like you can't do cryptocurrency
as an economic system without a computational infrastructure for it
and you can't have stores of grain that leads to capitalism
or that lead to private ownership in that way before you have plows
there are tools that mediate the new type of social agreements we're going to
have new methods of sense making largely because we also have new methods of
communication and information processing and
computational infrastructure and whatever but how to even build the tools
that are oriented to that as opposed to oriented to some other purpose will be
some subsets of the population that have a new story a new value system that
then build tools that can be in service of that that then build social
systems where then people's participation with that social system
recursively reconditions that underlying value system
and it's a movement from separate competitive self
to interconnected symbiotic self from us as
modeling ourselves as competing for apex predator status to stewards of
the whole system where rather than humans compete against humans using
better technology to exploit nature its nature gives rise to humans humans
gives rise to technology so to be sustainable technology has to in
turn be in service to the resilience of nature
and this is i mean this is why i'm happy to be here talking with you and i think
this is the core of your work and why you have started with narrative and
methods there have to be people that are oriented to a
model of what healthy civilization could even mean
in the presence of the kinds of things we face to be working towards
building things that make such a possibility come about where then the
increased adaptiveness of that new system becomes the strange attractor
yeah what you're saying is is so so closely congruent to
the things i've been saying for years with totally different language
i speak for example of a transition from a relationship of mother earth to a
relationship of lover earth where we no longer just
our feel-out liberty to take and take and take as best we can
which is the proper relationship of a child to a parent
but where we understand that we are here to give
and take in in harmonious measure and perhaps to
as with a lover to co-create something together
so that really does translate into abandoning the behavior of an apex
predator and taking responsibility for the effects
of our actions on the other it also means a
reconception of who we are in relationship to the other in
relationship to nature it's a change that goes all the way to
the bottom yeah all the way to what we believe we are what
we believe reality is and the relationship between us in reality
because what we understand to be real is going to inform what we
understand to be meaningful that is the basis for then what we
are making choices and service to right um yeah i see it as
really an initiation into a different collective state of being that also
then induces a different personal state of being
because one hallmark of an initiation is that you're faced with circumstances
that none of your existing tools are sufficient to handle
right and you're you're then forced or every strongly invited to
uh metamorphosize you know to grow and just to become something else
i mean i'm not going to say that it's entirely new i think that at each stage
of human evolution like with the advent of stone tools with the advent of fire
with the advent of domestication and so on like each of these
qualitative step-ups in the our ability to outcompete the rest of nature
there was at each point the possibility of coming into a responsible
equilibrium that necessitated taking some responsibility
and exercising some kind of restraint so there are hunter gatherer cultures
who and maybe some just still still to this day
who really understood themselves as among other things as stewards of the
land and caretakers of the land among some of the
native americans for example the idea of the wild
was a repulsive concept like no it's not the wild we're here we're here to
interact it wasn't that they left no trace it was that they
interacted in a positive way and left a positive trace
and there were those at each stage of our technological development
that didn't take responsibility and did tremendous damage
so just to say that it's not an entirely a new thing
that we're seeking here there are precedents for it that operated on
um earlier levels of technological development you know if you can look at
technology is kind of a step up function where you had a sudden leap and
then maybe a gradual increase in another sudden leap and so forth
you know there so there were stone age cultures that
lived in equilibrium there were agrarian cultures
that lived in equilibrium and maintained ecological symbiosis
for thousands of years and i'm not sure if we could say the same for
industrial societies let alone digital societies but
just saying that there are precedents and cultural memories that we might be
able to draw on as we forge a story that
locates us in a different relationship to to nature
yeah i think i think it's interesting because
we're definitely not going backwards right we're moving to a society that is
both higher touch and higher nature as well as higher tech
but a fundamentally different way of thinking about what
technology is and what it's for what it's for
and so any orientation to say it was good before let's go back we'll just lose
but there's a lot of principles that we've had in various previous phases that
are actually a critical part of it and so
you know one one thing to what you said is that of course there is a
distribution of cultures that were say more
harmonious with their environment versus more exploitive
less warring versus more warring and in general the way the curve goes is that
the more warring cultures killed the less warring cultures at a certain point
and the ones that exploited the environments have been ended up
taking over the ones that didn't at a certain point and so
we can see that it's like
the only cultures that were kind of that were more
peaceful that were left for a while was if they didn't have natural resource
they weren't a threat they were in some faraway place like
Tibet until Tibet actually became a threat because
you know things like modern media where its message could
damage the message of China to the rest of the world and then it had to be
taken out and we could see that with patriarchal versus
matriarchal cultures and you know Greece falling to Rome and all those types of
things and yet so what we're looking at is in those
phases doing the more power dominant thing
one not doing it loss by default and so the power dominant thing both worked
and was compulsory right now the power dominant thing has got to a high
enough level of power that increasing the level of power on all sides is
actually what is breaking the underlying substrate itself and so it no
longer can keep winning the thing that has one so far the winning
and when lose itself is now the underlying threat to survival
and so when you say we need new tools we actually need new meta tools we need a
meta process by which we aren't trying to create a situation that
selects for us against others because that
againstness itself will actually break the ability to even select for us
and so of course there have been lots of epochs with the agricultural revolution
and industrial revolution and there were major changes
but i would say that epoch that we are on the brink of that we're talking about
now is like maybe the last time that something
of this magnitude happened was homo habilis and tool making
because you know we said like okay you've got evolution it's a very old process
depending upon how we want to define it billions of years on this earth or as
old as the universe and that's a mathematical process
that just kept happening for a very long time until tool making
created a conscious central serial rather than
unconscious de-central parallel creative process
and then there've been a lot of epochal shifts in how we do the tool making
thing but we're really looking at a new third
creative process that is neither evolution nor tool making
it's something that navigates the relationship between the both of them
it's a conscious creation of holes rather than an unconscious
creation of holes or a conscious creation of parts
so i would say that that's kind of a meta epoch
that we have not had a transition like that
in the history of our species that's very
that's very interim i agree with that i think that
what we face is qualitatively different than
any of the technological revolutions before it's
bigger than the neolithic revolution it's bigger than the industrial revolution
because all of those were an intensification of something that was
already in progress right it was a next level of the
development of the technologies of control and this is something entirely
different it's a bigger and deeper
qualitatively different kind of revolution than anything
that we've had before but every religion spoke to it or in the most part
most religions spoke to something like this with the what is
happening at the end of the mayan calendar or the end of kaliyuga and the
emergence of satyuga in the hindu system or the
you know the end of the end of times and purgatory and then heaven or hell if we
take these kind of metaphorically we say
yeah let's let's just play with the idea that
the rapture story in christianity was just kind of like
prescient people looking and saying hey as we went from stone tools to metal
tools and as we keep developing better and better tools
we're destroying environments faster than we were their deserts where there
didn't used to be and the wars are getting bigger
and they can just imagine that that doesn't get to go on forever
at a certain point we become too powerful to keep being that dumb
and so there's this story that says this phase that we're in comes to an end
we fell out of the garden in terms of how to live in harmony with things
this phase comes to an end there's a purgatory where there's some really
hard reckoning with the choices we've made and we either go a very different
direction where we kind of are reintroduced to the
garden but at a higher order or it or it's pretty bleak
i think that's actually a literally true story and we're just in purgatory now
we're actually in that eminent place where the choices we've been making have
to be not not only do we have to shift them we
actually have to make amends we have to do reparations on those
choices which is how do we actually clean the oceans not just stop polluting
them and fix the topsoil and those types of things
and so i think it is like you know people can get
despairing or overwhelmed they could also be like this is the most
interesting possible time to get to contribute to a deeper level shift of
how for the future of all life then anyone has ever had the opportunity to
contribute to and to just be like even if i don't know
how to do it i'm going to commit to do it before i know
how and start increasing my understanding and
sense making so i can more and more deeply engage
right we may not know the answers but at least maybe we know the question
you know we know the the direction we want to go and i think you just named it
it is as reparations you know regeneration healing
what i mean this is the question i i ask you know knowing that
no species on earth is given superfluous or unnecessary gifts
that don't contribute to the well-being and evolution of the whole
the question is well what are our gifts for and maybe for the next 500 years
they're for healing the damage that's been done after that
they're probably for something else that is unimaginable
and and who knows you know why why we're really here why we really have this
ability to to forge exponential technology to
enact this new kind of evolution who knows why
but for the next few centuries i think it's pretty clear
we're here for and for the time being that's good enough for me
yep agreed so i think like we have um
we got to a point this is like maybe a good stopping point
you've really laid the foundation of here's what needs to happen
here's the question to ask you know we can do this again and
talk about more of of the how to
i'll say one brief thing on the how to just so that those who are really paying
attention can be thinking about it if the paperclip maximizer that we
currently have is a collective intelligent system
that is working on humans as the processors
predisposing them in particular ways etc but it is a collective intelligent
system that is oriented in a particular way and getting
better the answer is a new collective intelligence system
that is oriented in a different direction that is actually in service to
evolution itself increasing orderly complexity rather than paperclip
maximizing and yet that also has the ability to
not just move in a direction but increase its intelligence and
capacity of moving that direction so we want to be thinking about how could we
have a fundamentally different kind of collective intelligence which is not
individual intelligence how do we have humans interacting
with each other in ways that produces system
disposition that orients itself in the evolutionary direction
and increases its capacity to do that and yes maybe we can have a future
conversation where we dive into that more but if people are thinking on it
that's a good area to be thinking in yeah it would have a system component and a
story component or a psychology component because the system
creates the individual and the individual creates the system
you know like you can try to hold a story of
interbeing you know is the word i'd like to use for it but we live in a system
that every day in a million ways enforces separation
so it's really hard to live from interbeing
and we could have a system that invites us and supports us in being
cooperative and transparent and so forth so we can work on many many levels i
think the system's level and the individual level and that to me
points to a convergence of activism and spirituality
right and i would say for people who want to figure out okay well how do
how do i take these very macro topics and apply them to myself in the near term
if i really care and i'm earnest and i say okay well there is a collective
intelligence that is actually predisposing even my action facebook is
moving me in a particular direction capitalism and state and etc actually
have an influence on me i want to evolve to where i can
actually be part of an influence on the whole that is in a different direction
but in order to increase my ability to influence the whole in a positive
direction i also need to decrease the way the current
system is influencing me and have things around me that are
influencing me in a direction that i want so how do i create
collective intelligence that i'm a part of that is
continuing to support my own sovereignty and sense making and orient me in the
right direction and i would say the degree to which you can
find people that are also really earnestly exploring these topics and
not ones that all agree with you but are earnestly exploring them and you can
create higher quality conversations with more
regularity where the space that you are in is a space of
earnest high quality exploration across a diversity of points of view
you will be moved in the right direction better than if you leave
the input to your brain largely to those who are doing broadcast media
continuously trying to control the input to your brain
yeah that's very attractive advice for me validates the direction i've been
going of course i could just be rebelling against my father or
something in rejecting the information that's that's being
fed to me by the structures of power but if so so be it
hey i want to say briefly people who are interested in this dialogue
you know your charles mentioned lewis mumford and i'm sure he has a list on
the site of recommended reading things that we've
talked about today you know there's i didn't come up within
really any of the ideas that i'm saying i at most are kind of kind of
synthesizing them but their ideas coming from bucky fuller and
barbara marx hovered and christina murty and david bowman
and others that are worth looking at and specifically some of the
some of the structures regarding evolution as a creative process and
then technology as a creative process and that making an unstable oscillator
and what the new process will be and the distinctions between power and
strength and have come largely that a lot of brilliant
structures have come through a collaboration with a friend of mine
named forest landry and he goes into those
structures in a lot more formal detail in some of his writing so i'd encourage
anyone who's interested to look that up and
that just a little bit on resources and
yeah if people are interested in questions come in and we get to do a
feature dialogue to explore those further that would be really fun
yeah and you said you had a blog or something like that and you have a
podcast as well yeah civilization emerging
dot com is a blog that i have and there's a podcast called collective
insights and there's a couple different show hosts there's a
really brilliant doctor who does a lot on the future of medicine named dr
hither sanderson and then i do some on these kind of social topics
which will include one posting soon where charles was there
sharing about climate change and polarization and the really fun
conversation great okay yeah we'll put links to those
in our blurb for this show yeah yeah all right well great
daniel thank you so much for taking all this time
likewise thanks for having me charles and thank you for all the work that you
were doing in helping people shift narrative and
sense making and i look forward to continued collaboration
all right this has been a new and ancient story with your host charles
eisenstein i offer this podcast in the spirit of the gift by which i mean
that i don't withhold premium content for a price or put up paywalls or do
affiliate marketing or have advertising or anything like that
instead i rely on supporters like you if you would like to support it you can
subscribe at charleseisenstein.net for a small monthly
amount or you can subscribe for free as well
either way you get the same content everything's the same
and you'll be notified every time a new podcast comes out
also on the site you can find archived episodes
along with everything else that i produce essays books videos online courses
thank you very much for listening and i'll be with you again next time
