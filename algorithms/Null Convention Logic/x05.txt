community. In 1958 a new programming language was named ALGOL
(ALGOrithmic Language). In 1960 a new department of the Communications
of the ACM was introduced called “Algorithms” [7].

Historically, the algorithm was developed to investigate the foundations of
mathematics, and it has evolved in relation to the needs of mathematicians.

The notion of the algorithm in mathematics is a limiting defi nition of what
constitutes an acceptable solution to a mathematical problem. It establishes
the ground rules of mathematics.

1.2 THE ADVENT OF COMPUTERS
The electronic digital computer emerged in 1945. It computed one step at a
time, was by practical necessity limited to a fi nite number of steps, and was
limited to a fi nite number of exactly formulated hypotheses (instructions). The
electronic digital computer was an incarnation of the mathematician’s effec-
tive solution procedure. The mathematicians, being intimately involved with
the creation of the computer, having studied mechanical computation for half
a century, and having in hand an explicitly mechanical model of computation
in the Turing machine, quite reasonably became the de facto theorists for this
new phenomenon. One of these mathematicians, John Von Neumann, was a
student of Hilbert’s and a signifi cant contributor to his program to resolve the
foundations of mathematics. Another was of course Turing himself. The
related mathematical concepts along with the notion of the algorithm were
transplanted into the fl edgling science of computers.

The notion of the algorithm has become accepted as a fundamental para-
digm of computer science.

The notion of the algorithm is basic to all computer programming. . . . [8]
One of the concepts most central to computer science is that of an algorithm.

[9]
To appreciate the role of the algorithm in computer science, it is necessary
fi rst to characterize computer science.

THE ADVENT OF COMPUTERS 5

A CRITICAL REVIEW OF THE NOTION OF THE ALGORITHM IN COMPUTER SCIENCE
1.3 COMPUTER SCIENCE
Many attempts have been made to defi ne computer science [10–14]. All
these defi nitions view computer science as a heterogeneous group of
disciplines related to the creation, use, and study of computers. A typical
defi nition simply offers a list of included topics: computability, complexity,
algorithm theory, automata theory, programming, high-level languages,
machine languages, architecture, circuit design, switching theory, system
organization, numerical mathematics, artifi ial intelligence, other applications,
and so forth. The most recent and comprehensive survey of the attempts to
defi ne computer science is an article in the Annals of the History of Computing
[15].

Computer science appears to consist of a quite disparate collection of dis-
ciplines, but there is a common thread of conceptual focus running through
the various disciplines of computer science. All of the disciplines that are
included under the heading of computer science in any list are concerned in
one way or another with the creation of or actualization of process expres-
sions. A logic circuit is an expression of a logical process. An architecture
is an expression of a continuously acting process to interpret symbolically
expressed processes. A program is a symbolic expression of a process. A
programming language is an environment within which to create symbolic
process expressions. A compiler is an expression of a process that translates
between symbolic process expressions in different languages. An operating
system is an expression of a process that manages the interpretation of
other process expressions. Any application is an expression of the application
process.

Computer science can be viewed as primarily concerned with questions
about the expression of processes and the actualization of those expressions.

What are all the possible ways a process can be expressed? Are some expres-
sions superior in any sense to other expressions? What are all the possible
ways of actualizing an expression. Are there common conceptual elements
underlying all expressions? What is the best programming language? How can
the best program be formulated? How can the best architecture be built?
What is the best implementation environment? These are the questions that
occupy computer scientists, and they all revolve around the nature of process
expression.

Mathematicians, on the other hand, are primarily interested in exploring
the behavior of specifi c processes or classes of process. They bypass general
problems of expression by appealing to a very formal and minimalized model
of expression, the algorithm as characterized by the Turing machine. They are
only interested in whether an expression is possible and whether it conforms
to certain specifi c properties. The mathematicians consider the process as
independent of its expression. A process may be expressed in any convenient
language and executed on any convenient machine including a human with a
pencil.


Mathematics is primarily concerned with the nature of the behavior of
process independent of how that process is expressed:
the nature of a process is considered independent of its expression.

Computer science is primarily concerned with the nature of the expression
of processes regardless of what particular process might be expressed:
the nature of expression is considered independent of its process.

There is much overlap between the interests of computer science and math-
ematics, but the core concern with the nature of process expression itself is
the unique conceptual focus that distinguishes computer science from the
other sciences and from mathematics. Computer science is the science of
process expression.

1.4 THE ALGORITHM IN COMPUTER SCIENCE
Introductory texts on computer science often begin with a chapter on the
notion of the algorithm declaring it the fundamental paradigm of computer
science. Conspicuously absent from these introductory chapters is discussion
of how the notion contributes to the resolution of signifi cant problems of
computer science. In the remaining chapters of these texts there is typically
no further appeal to the notion of the algorithm and rarely even a usage of
the word itself. The notion is never or very rarely appealed to in texts on logic
design, computer architecture, operating systems, programming, software
engineering, programming languages, compilers, data structures, and data
base systems.

The notion of the algorithm is typically defi ned by simply presenting a list
of properties that an expression must posses to qualify as an algorithm. The
following defi nition of an algorithm is typical:
1. An algorithm must be a step-by-step sequence of operations.

2. Each operation must be precisely defi ned.

3. An algorithm must terminate in a fi nite number of steps.

4. An algorithm must effectively yield a correct solution.

5. An algorithm must be deterministic in that, given the same input, it will
always yield the same solution.

This is pretty much what Hilbert proposed in 1900, and it is easy to see how
this list of restrictive characteristics serves to defi ne what is acceptable as a
mathematical solution. But what conceptual service does the notion of the
algorithm perform for computer science?
The notion of the algorithm demarcates all expressions into algorithm and
nonalgorithm, but what purpose does it serve to know that one program is an
acceptable mathematical solution and another is not? Is the expression of one
THE ALGORITHM IN COMPUTER SCIENCE 7

A CRITICAL REVIEW OF THE NOTION OF THE ALGORITHM IN COMPUTER SCIENCE
fundamentally different from the expression of the other? Is one interpreted
differently from the other? Are algorithms fi rst-class citizens in some sense
and nonalgorithms second-class citizens? Does determining whether or not a
given expression is an acceptable mathematical solution aid in building better
computer systems or in writing better programs?
Important process expressions do not qualify as algorithms. A logic circuit
is not a sequence of operations. An operating system is not supposed to ter-
minate, nor does it yield a singular solution. An operating system cannot be
deterministic because it must relate to uncoordinated inputs from the outside
world. Any program utilizing random input to carry out its process, such as a
Monte Carlo simulation or fuzzy logic simulation, is not an algorithm. No
program with a bug can be an algorithm, and it is generally accepted that no
signifi cant program can be demonstrated to be bug free. Programs and com-
puters that utilize concurrency where many operations are carried out simul-
taneously cannot be considered algorithms. What does it mean when a
sequential program qualifying as an algorithm is parallelized by a vectorizing
compiler, and no longer qualifi es as an algorithm.

While a digital computer appears to be an algorithmic machine, It is
constructed of nonalgorithmic parts (logic circuits) and a great deal of what
it actually does is nonalgorithmic. These diffi culties with the notion of the
algorithm have not gone unnoticed, and a variety of piecemeal amendments,
revisions, and redefi nitions have been proposed:
. . . there is an extension of the notion of algorithm (called nondeterministic
algorithm). [11]
Any computer program is at least a semi-algorithm and any program that always
halts is an algorithm. [16]
There is another word for algorithm which obeys all of the above properties
except termination and that is computational procedure. [17]
An algorithm A is a probabilistically good algorithm if the algorithm “almost
always” generates either an exact solution or a solution with a value that is
“exceedingly close” to the value of the optimal solution. [18]
The procedure becomes an algorithm if the Turing machine always halts. [19]
By admitting probabilistic procedures in algorithms. . . . [20]
. . . if, after executing some step, the control logic shifts to another step of the
algorithm as dictated by a random device (for example, coin tossing), we call the
algorithm random algorithm. [21]
An algorithm which is based on such convergence tests is called an infi nite
algorithm. [21]
Algorithms that are not direct are called indirect. [22]
We drop the requirement that the algorithm stop and consider infi nite
algorithms. [22]

These authors have sensed an inappropriate conceptual discrimination or
simply an incompleteness and proposed a remedy. Programs that do not ter-
minate, are not deterministic, and do not give specifi c solutions can now be
“included.” They are no longer simply nonalgorithmic, they now have positive
labels, but simply assigning labels to nonalgorithms misses the point. The point
is that algorithm–nonalgorithm is not a conceptual distinction that contributes
to an understanding of process expression.

As a paradigm of process expression, the notion of the algorithm is decid-
edly defi cient. It offers no suggestion as to how an operation might be precisely
defi ned. Nor does it suggest how a sequence should be determined. Data are
not even mentioned. The defi nition simply states that an algorithm must
consist of a sequence of precisely defi ned operations. This unsupported imper-
ative is at once an admission of expressional incompleteness and a refusal to
be complete. The other algorithmic properties of termination, correctness, and
determination, while important to issues of computation, are quite irrelevant
to issues of process expression.

