In this lecture, I want to talk about three scientific ideas that are related, and the
common denominator is mathematics, which is a nice thing to have a common denominator
of, I guess. The first is going to be the idea of algebra, the second is going to be
the idea of calculus, and the third is going to be the idea of probability theory, especially
probability theory as applied to real world decision making. All three of these ideas
are 16th and 17th, especially 17th century phenomena, and I understand that many people
beginning immediately upon hearing words like algebra and calculus and probability theory
think that it's time to bail out, but I will not be using any mathematics per se, and the
ideas underlying these three developments in modern science are fascinating, and I believe
quite beautiful, and very interesting from the point of view of the people involved.
In fact, some of the people involved, the people are going to be mentioning, Descartes
and Newton are two central players here, and they had come up, of course, in the last lecture
having to do with method, so let me begin by picking up on the discussion of method
in the previous lecture in order to carry it forward in a way that I think blends nicely
with the emergence of these three ideas, algebra, calculus, and probability theory in the 17th
century. I had highlighted in the previous lecture Francis Bacon, Rene Descartes, and
Galileo and Newton as representing three different conceptions of the scientific method, just
to give you some feeling for the fact that in the 17th century there was no such thing
as one scientific method, one method that one can say is this is the scientific method,
this is the method that modern philosophers of nature, who we call scientists, use in
order to get knowledge of nature. Bacon, of course, championed a strictly inductive method
experimentally based that required little or no mathematics. In fact, he thought the
less mathematics, the better, because mathematics led people into mystical and metaphysical
speculations. Descartes' method was rigorously deductive, intensively mathematical, and very
suspicious of experiment. Descartes' feeling was that experimental outcomes were ambiguous
and needed to be interpreted, and that often led people astray, so that experiment should
be very, very limited and carefully controlled. Galileo and Newton used experiment intensively,
used a deductive mathematical form of reasoning intensively, so they, especially Newton, considered
himself in the Baconian tradition, ironically, even though all of his work was intensively
mathematical, and Galileo identified himself methodologically with Archimedes. And a lot
of Galileo's experiments were thought experiments, including almost certainly the experiments
that were associated with studying freely falling bodies. Many of those were thought
experiments. It is unlikely, I think, that Galileo actually climbed up the Tower of Pisa
and dropped heavy weights off to see if they fell at the same time. We do know that a predecessor,
a younger contemporary of his, Simon Stevin, in Holland, a very important figure in late
16th and early 17th century, early modern science, did do such an experiment, but of
course not with the Tower of Pisa, because he lived in Holland. Now, what is the common
denominator of these approaches to what we call the scientific method? If you say, well,
what is it that these people had in common? What these people had in common was a total
commitment to the idea that the right method for studying nature was a radically impersonal
method. We would say a radically objective method, although the word objective was not
used that way, even in English in the 17th century, that whatever method you used had
to be one in which the person of the student of nature, the natural philosopher, the person
that we have come to call the scientist, the person of the scientist is irrelevant to the
results. Now, this seems obvious to us, but it was not obvious in the 17th century, because
this is one of the pieces of the study of nature puzzle that was taken out, that was rejected
by the founders of modern science, because in Renaissance nature philosophy, especially
the part associated the dominant thread of magical nature philosophy, the person of
the inquirer was relevant to their ability to acquire knowledge of nature, so that who
you were and how you sort of cultivated your soul was a factor. In the modern period, what
we're looking at, what we claim to be the case is that there is some method that you
have to follow and you have to present your results in a particular way that in which
you drop out and who you are is utterly irrelevant. The conclusions have to be substantiated
on the basis of logic and empirical confirmation, not on the basis of who you happen to be.
We still have a considerable amount of influence on peers by knowing that somebody is a Nobel
Prize. That's why we're supposed to have proposals and articles submitted in a blind
or double blind manner, so that we don't know who wrote the proposal and we don't know
who submitted the article and the merit has to flow from the argument that's presented.
But in fact, this is very often not honored. It can become quite awkward. In fact, very
often you see a proposal and you know immediately who must have done it based on your familiarity
with the field. If you don't have familiarity with the field, you can't judge the proposal
anyway. This is the common denominator of method and it links up with the subject matter
of this lecture, which is the way that mathematics became the language of modern science. The
first step towards creating a new mathematics that would become in the 17th century and
after the language in which scientific theories were expressed was the adoption of algebra
in place of the Greek emphasis on geometry. For whatever reason, the ancient Greek thinkers
did not like algebra or did not like what the subject that we call algebra, that is
actually a Latin and now English corruption of an Arabic word that only became, was formulated
that we found after the 9th century. But in antiquity, the study of equations was just
not of interest to the Greeks. They believed in geometry and their conception of deductive
reasoning, as I've already mentioned many times, was considered to be exemplified by
Euclid's geometry. It's not just that Euclid's geometry embodied deductive reasoning but
because it embodied deductive reasoning, then geometry was the one descriptive language
that you could use in explaining natural phenomena that you could be sure led to truth because
it embodied deductive reasoning. So as a matter of fact, the Greek mathematicians focused
overwhelmingly on geometry, theory of proportions, which often was described in geometric language,
and trigonometry, which also has a geometric character to it. So now the rise of algebra
had to, so to speak, fight against this commitment to geometry as the only mathematical language
that we could use confident that it would lead to truth, to demonstration. Remember
what I read from Galileo? He wanted to not just tell you, here are some interesting formulas
for calculating the strength of material. I am going to show demonstratively. That means
give a deductive argument showing that the relative strength of two beams can be deduced
from first principles. So this replacement of geometry by algebra, which really took
place in the 16th and 17th centuries, is as momentous as the transition from Ptolemaic
astronomy to Copernican astronomy in terms of revealing the mindset, the ways of thinking
that became, that were central to the founders of modern science and the practitioners of
modern science. Remember I told you how bizarre it looks after the fact that for 2,000 years
effectively no one questioned Pythagoras' notion that the planet surely were spheres
moving at a uniform speed in circular orbits. And for 2,000 years astronomers wrestled with
how you could have a theory of the motions of the planets that fulfilled those criteria
and still displayed the appearances that we observe when we look at the night sky and
keep track of them, keep track of the motions of the planets for some period of time. They
don't seem to be doing that. At 2,000 years, I think I referred to this once as the chicken
little syndrome in the history of science. Well here's another one that for over 2,000
years geometry had a stranglehold on the thinking of Western natural philosophers who used mathematics
in their nature philosophy. So in the 16th century when Arabic language texts from Egypt
and Persian authors primarily came into the West, were translated into Latin, especially
Al Quarizmi, a 9th century mathematician who used this term aljibar to refer to the study
solving problems where something is unknown and we want to solve it and using what we
recognize as algebraic equations. So algebra became an identified branch of mathematics
in the 16th century in Western Europe, building initially on the work of Al Quarizmi. His
name survives in the word algorithm by the way, although it's obviously a bit of a stretch.
You might not think from the word algorithm that it has an origin and a person's name,
but it is a deliberate version of Al Quarizmi and one of his successors and followers, a
man who refers back to Al Quarizmi's solutions and offers new and what he thinks is more
interesting and better solutions, an Egyptian mathematician named Abu Kamil who lived in
the next century. So the 10th century as opposed to Al Quarizmi who lived in the 9th, but their
lives overlapped. So it was through this channel, so to speak, that apparently in the 16th
century we see the beginnings of European mathematicians beginning to focus on algebra
and very quickly achieving new results, some of which had been said in antiquity could
not be achieved. For example, solving the cubic equation. Now, I'm not going to give
you a cubic equation, but we all know what a quadratic equation is from high school. A
cubic equation is one that involves x cubed. So we would put it today, something like
A x cubed plus B x squared plus C x minus D is equal to zero. So that would be a cubic
equation in its most general form. And while the Greeks and Arabic mathematicians could
solve the cubic equation for special cases, nobody had a general solution for that equation.
And it was believed that such a solution did not exist. It was not possible to have a general,
you could only solve specific cases. Now, there is now evidence, I must say, that Omar
Kayam, known to most Westerners I think because of the Rubaiyat of Omar Kayam as a poet based
on Fitzgerald's creative translation of his poetry in the 19th century, the Rubaiyat of
Omar Kayam, a book of verse beneath the bow, et cetera. And Kayam was a lovely poet, but
he was also a very good mathematician. He was a world-class mathematician. And there
is, manuscripts of his have been found now, which show that he seems to have solved every
specific case that's relevant of the cubic equation that's relevant to a general solution.
But it does not look as though he sort of pulled it together and says, and now that
I've solved all these cases, I can say that I have a general solution to the cubic equation.
It turns out to be an important equation, even in practical use. For example, Greek and
Roman catapults were designed using the cubic equation in order to calculate the torsion
necessary so that when you release the pressure, the catapult through the rock or whatever else
it was throwing. So in designing those catapults, special solutions, specific solutions of a
cubic equation are relevant. So it's not just an abstract piece of mathematics. Well, what
happened in the 16th century is that an Italian mathematician named Nicola, Tartaglia, that
was his nickname, but that's the name that he was known by and he even signed his own
books that way, Tartaglia discovered a general solution to the cubic equation. And he used
this general solution in order to win money at mathematics contests, which people did
in those days because they didn't have television yet. So they had tournaments for mathematics
and the way you did it was you set up a series of problems and you challenged other mathematicians
to solve them. You, of course, already had the solutions to all of those problems. And
then some king or prince who had nothing better to do with his money said, okay, I'll give
a thousand ducats to whoever wins this competition. And everybody got together at that time. And
Tartaglia would always set problems that involve solutions to cubic equations. And he won all
of the contests because nobody else could do it. Finally, another Italian mathematician
and a man actually an extraordinary character, extraordinary eccentric character, but one
of his geniuses was in mathematics, Jerome Cardan, Gioromo Cardano. So Cardano eventually
talked Tartaglia into telling him the secret of solving the cubic equation. And Tartaglia
was stupid enough to tell him, even though Cardano promised, maybe on his mother's name,
I don't know, that he would not reveal the secret. He immediately published it, giving
Tartaglia full credit. But he published it in a book that he wrote and saying now Tartaglia,
now of course this took away Tartaglia's bread and butter. Interestingly, Cardano had
a servant who subsequently became a professor of mathematics. Tartano tutored his servant
in mathematics. He had a gift for it, a man by the name of Ferrari. And Ferrari improved
on Tartaglia's solution and then showed that you could solve the Quartic equation, equations
in x to the fourth power by reducing it to two quadratic equations. And these are major
creative acquirements in mathematics, accomplishments in algebra, sort of showing that in fact European
mathematicians had got it. They grasped algebra as a form of mathematics and were pursuing
it aggressively and creatively. In order, Cardano himself also wrote a book that is
on perhaps the first book written on the subject of probability theory, but I'll come back
to that. This was in the late 15, all of this is happening in the late 1500s. As you pursue
algebra, at the time, algebra problems and had been, since antiquity, written in words.
So for example, reading from Abu Kamil, an English translation of Abu Kamil's 10th century
Arabic textbook called the Algebra, he gives the following description of a problem. Here's
a textbook problem. One says that can be divided into two parts. Multiply one by the other.
Multiply the larger part by itself. The part multiplied by itself equals the product of
the one part by the other plus its half. The half is also written in words, not in symbols.
The method for solving this problem is that we let the larger part be the thing, we would
call that x. The other part is then 10 minus a thing. Multiply the thing by 10 minus a
thing. It is 10 things minus a square. Multiply the larger part, a thing by itself, to get
a square. This square is equal to 10 things minus a square plus a half of this. Multiply
10 things minus a square by one and a half. It comes to 15 things minus a square and a
half square. The latter is equal to a square. Put the 15 things with the one and a half
squares. Then it is 15 things. Add the one and a half squares to the square to get two
and a half squares. This is equal to 15 things. The square is equal to six things. The thing,
what we would call x, if you've been following all of this, the thing equals six. This is
the larger part. The other part is four and is the remainder from 10. Contrast proposing
mathematical problems and solutions in words and using the symbolic notation that we're
familiar with in which you have x, y, and z standing for variables, a, b, and c standing
for constants. The superscripts for square and the cube and fourth power and the square
root sign for the square root of and the equal sign, the plus and the minus and the sign
for multiplication and division. None of that existed prior to the 16th century. That symbolic
notation was invented in Western Europe in response to the interest in algebra. The symbolic
notation then unleashed. This has something to do with the way we think and the way our
minds work. Once we had that symbolic notation, that unleashed an incredible exponential growth
in mathematical knowledge, in algebra, over the next several hundred years. The invention
of these notations had to be invented. People had to agree, okay, that's what an equal sign
looks like. For a while, people used different equal signs, but they had an equal sign. By
the time you get to Descartes writing in the 1620s and 30s, and I'm going to be talking
about that in a moment, he writes recognizable equations. I want to do two things now. First
of all, I had said earlier that the acceptance of algebra as the primary form of mathematical
knowledge encountered resistance because people wanted to continue to do it. They didn't
trust algebra. Yeah, okay, these equations work, but show me a geometric version of solving
this algebraic equation. How powerful was this stranglehold? I mentioned in the previous
lecture that Galileo's most important book as a scientist was the discourse concerning
the two great sciences. The second part of that book founds the modern science of mechanics,
which is the cornerstone of physics. There is not a single equation in the book. The
word algebra does not occur in the book. Every single proposition, every single statement
about the world, about motion, about moving particles is demonstrated geometrically. Oh,
well, that was only the 1630s. But Newton's Principia, Newton who invented the calculus,
only used geometry in order to prove the theorems in the Principia. So even as algebra was becoming
the dominant form of mathematical knowledge in western science for western science and
in western mathematics, but geometry underwent a tremendous resurrection in the 19th and
early 20th century, but one could call it an algebraized form of geometry. This was
there was tremendous resistance to it. And why was the resistance? Because the fear that an
algebraic solution might not be deductively accurate. That somehow it pulls a rabbit out
of a hat. When you give a geometric proof and you can step through the proof using lines
and curves, then you really know that you've gotten the truth. Descartes' major contribution
here was that Descartes invented, well, this is a bit of an exaggeration. It's what the
history books say, and it is largely true, but Descartes invented analytic geometry,
a forbidding phrase. But what it really what he did was, and in a book that ironically is
called La Geom√©trie in his French version, a book called Geometry, he argued, he says
at the beginning, every problem in geometry can be solved algebraically. And therefore,
we don't need geometry anymore. All we need is algebra. And he shows the power of algebraic
solutions to problems in geometry. In fact, showing how easily he is able to solve problems
that ancient geometries to solve were too complicated to do. That no one had even attempted to do.
And yet he shows that algebraically you can find solutions very quickly. So Descartes,
and this book does have some residual echoes of falling back on geometry, but it really
is in some sense a watershed in that after Descartes, after this, we can solve any problem
geometry algebraically. The fact that people didn't shows the strength that our ideas have
on how we reason and what we reason about. That's a little bit of the story of algebra
as an idea. And I hope you see that it really is an idea. It's not a discovery. People didn't
discover algebra in the 16th century. People were introduced to algebra in the 16th century,
but that only opened the door that mathematicians ran through. And in the 17th century, scientists
tiptoed through because they weren't sure that using this would lead to knowledge, demonstrative
knowledge. Demonstration still was identified with geometry for a long time. But behind
the scenes, people like Christian Halkins, for example, were major contributors to the
growth of algebra in the 17th century, as well as major contributors to the growing
science of mechanics and science generally. Huygens wrote also on probability theory.
Newton, the second idea I want to talk about is the idea of the calculus. Newton and independently
got freed Leibniz. In the 1660s, Newton claimed he really got the idea. Leibniz in the 1670s,
but Newton published later and then argued that, ah, but I was really first. Newton and
Leibniz invented the calculus. The calculus is an incredibly beautiful idea and an incredibly
beautiful and powerful mathematical tool. For the first time, we could in an equation
capture motion and change. Now, you remember back from, I said back in Aristotle's time,
the fundamental problem for a scientist, for a philosopher of nature, is explaining change.
Change is the most fundamental phenomenon as far as understanding, responding to experiences.
It is change that we need to explain. If things don't change, well, if they don't change
long enough, then you might say, well, I have to explain that. But experiences always change.
The problem of the scientist is explaining change. And the calculus incredibly gives
us a tool for capturing change. The equations, the calculus lets us take an equation that
describes the motion of a particle or the changes in some physical system, whatever
it is. Once you can describe motion and change in an equation, then the calculus lets you
analyze that equation as if you were observing the moving particle or the changing system.
And you can figure out in advance where the system is moving, when the particle is moving
up, when it's moving down, when it's at a point of inflection, using up and down just
as stand-ins here. You can analyze the details of changing patterns through the equations,
using calculus as a tool. And that's the differential calculus, the integral calculus
and the two are complementary, and Newton and Leibniz were involved in both. The integral
calculus allows you to calculate the sum, the consequences, the accumulated change.
So these two tools became extremely, there's no way of exaggerating how important and powerful
the idea of the calculus became initially to physics and subsequently to any of the
sciences that were able to capture in equations descriptions of the changes that they studied,
whether in sociology and psychology, whether it's in biology, whether it's in chemistry,
there is some scope for the application of calculus. The third idea that I want to at
least briefly refer to is the idea of probability theory. Now, in a culture dominated by a definition
of knowledge that is universal and necessary and certain, in which knowledge means certainty.
Well, you remember the thing I read about Galileo, but that's just the tip of the iceberg.
The whole course I've been pointing out that this is just one of those intellectual fetishes
of the Western intellectual tradition since the time of Plato and Aristotle building on
their predecessors, Parmenides and part Pythagoras. Although in Plato's time, there was still
a fight going on in which the Sophists and later the skeptics rejected this definition.
But nevertheless, in a culture which has adopted this definition of knowledge, then probability
theory is a problem. It is an idea that needs to be invented, so to speak, because we dismiss
probability. It's not really knowledge. That's just opinion. And I think that a founding text
of probability theory, not because it was the first, but it is the first one that uses
probability theory in the way that we do. And it was the first text that I believe it
was the first text that explicitly linked probability theory to real-world decision-making.
That mathematical theory of probability was a tool for making wise decisions in the real
world in the absence of the kind of knowledge that would allow you to deduce what to do
was the book called, in English, The Art of Conjecturing by Jacob Bernoulli. Bernoulli
wrote this book, Bernoulli wrote this book in the 1690s. He died in 1705, and it was
published by a family member eight years later in 1713. Now, it turns out that Cardano had
written the book on probability theory in the late 1500s, but it was not published until
the late 1600s. By that time, two Frenchmen, Blaise Pascal and Pierre Fermat, famous from
Fermat's Last Theorem, had written books on probability theory as applied to gambling
games. And that unleashed a flurry of publications in the 1690s and early 1700s, most of which
were triggered by responding to Pascal and Fermat on the probability applied to gambling
games. But this four-part book by Jacob Bernoulli, who was a member of a great mathematical
family that for generations produced world-class mathematicians, and he himself was one, so
part four is devoted to this idea that probability theory is a guide to decision making. It's
not just a matter of gambling. That's not what it's all about, and he in fact was the
first to use probability in this particular way. We are said to know or understand those
things that are certain and beyond doubt, but only to conjecture or have opinions about
all other things, right out of the first couple of lectures of this course. We are said to
know or to understand those things that are certain and beyond doubt. Anything other than
that is not knowledge. We can only conjecture or have opinions about anything else. To conjecture
about something is to measure its probability. Therefore, we define the art of conjecture,
or stochastics, as the art of measuring the probabilities of things as exactly as possible.
To the end that, in our judgment and actions, we may always choose or follow that which
has been found to be better, more satisfactory, safer, or more carefully considered. On this
alone turns all the wisdom of the philosopher and all the practical judgment of the statesman.
He was already dead, but his book unleashed a whole new line of thinking in the 18th century
that became associated with social reform, the idea that there was a rational basis for
making decisions that were not deductive. That's a very important compliment to the
rigidity of a definition of knowledge that doesn't allow you to act on the basis of knowledge,
to deduce action from knowledge, so you can't act rationally if you mean by rationality,
only deductive reasoning. Certainty. Here was a claim that it is possible to loosen
up that definition of rationality to still be scientific, mathematical, less than certainty,
but you can proceed rationally by being confident that your mathematical analysis of a situation
has identified the most reasonable course of action, and this has become very important
in contemporary science.
