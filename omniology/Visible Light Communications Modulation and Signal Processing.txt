Visible Light 
Communications
www.ebook3000.com

IEEE Press
445 Hoes Lane
Piscataway, NJ 08854
IEEE Press Editorial Board
Tariq Samad, Editor in Chief
Giancarlo Fortino
Don Heirman
Linda Shafer
Dmitry Goldgof
Xiaoou Li
Mohammad Shahidehpour
Ekram Hossain
Jeffrey Nanzer
Saeid Nahavandi
Andreas Molisch
Ray Perez
Zidong Wang

Visible Light 
Communications
Modulation and Signal
Processing
 
Zhaocheng Wang
Qi Wang
Wei Huang
Zhengyuan Xu
www.ebook3000.com

Copyright © 2017 by The Institute of Electrical and Electronics Engineers, Inc.  All rights reserved.   
 
Published by John Wiley & Sons, Inc., Hoboken, New Jersey. 
Published simultaneously in Canada. 
 
No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form  
or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as  
permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior  
written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to  
the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400,  
fax (978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should  
be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ  
07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permission. 
 
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in  
preparing this book, they make no representations or warranties with respect to the accuracy or  
completeness of the contents of this book and specifically disclaim any implied warranties of  
merchantability or fitness for a particular purpose.  No warranty may be created or extended by sales  
representatives or written sales materials.  The advice and strategies contained herein may not be  
suitable for your situation.  You should consult with a professional where appropriate.  Neither the  
publisher nor author shall be liable for any loss of profit or any other commercial damages, including  
but not limited to special, incidental, consequential, or other damages. 
 
For general information on our other products and services or for technical support, please contact  
our Customer Care Department within the United States at (800) 762-2974, outside the United States at  
(317) 572-3993 or fax (317) 572-4002. 
 
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may 
not be available in electronic formats. For more information about Wiley products, visit our web site at  
www.wiley.com. 
 
Library of Congress Cataloging-in-Publication Data is available. 
 
ISBN: 978-1-119-33138-4 
 
 
 
 
 
 
 
 
Printed in the United States of America. 
 
10   9   8   7   6   5   4   3   2   1 

v
Contents
Preface
ix
1
Introduction to Visible Light Communications
1
1.1
History
1
1.2
Advantages and applications
4
1.3
Overview of modulation and signal processing
6
1.4
Standards
10
2
Visible Light Communications: Channel and Capacity
17
2.1
LED characteristics
17
2.1.1
Operation principles
19
2.1.2
LED nonlinearity
21
2.2
LED lighting constraints
23
2.2.1
Dimming control
23
2.2.2
Chromaticity control
25
2.2.3
Flicker-free communication
26
2.3
Photodiode characteristics
27
2.4
Propagation links
29
2.4.1
LOS link
31
2.4.2
NLOS link
32
2.5
Noise in VLC systems
33
2.6
Channel capacity
35
2.6.1
Channel models
36
2.6.2
Capacity bounds for free-space optical intensity channel
38
2.6.3
Capacity bounds for discrete-time Poisson channel
47
2.6.4
Capacity bounds for improved free-space intensity channel
50
2.7
Conclusion
53
3
Single Carrier/Carrierless Modulation and Coding
57
3.1
Pulse amplitude modulation
57
3.2
Pulse position modulation
62
3.3
Carrierless amplitude phase modulation
68
3.3.1
Principles of CAP
69
www.ebook3000.com

vi
3.3.2
Multidimensional CAP
73
3.4
Modulation and coding schemes for dimmable VLC
77
3.4.1
Modulation schemes for dimmable VLC
78
3.4.2
Coding schemes for dimmable VLC
80
3.5
Conclusion
82
4
Multicarrier Modulation
89
4.1
Optical OFDM for visible light communications
90
4.1.1
DC-biased optical OFDM
90
4.1.2
ACO-OFDM and PAM-DMT
93
4.1.3
Unipolar OFDM
97
4.1.4
Performance comparison
98
4.2
Performance enhancement for optical OFDM
99
4.2.1
DC bias and scaling optimization
100
4.2.2
LED nonlinearity mitigation
103
4.2.3
PAPR reduction
107
4.3
Spectrum- and power-eﬃcient optical OFDM
111
4.3.1
Hybrid optical OFDM
111
4.3.2
Enhanced U-OFDM
118
4.3.3
Layered ACO-OFDM
121
4.4
Optical OFDM under lighting constraints
131
4.4.1
Pulse width modulation
133
4.4.2
Reverse polarity optical OFDM
136
4.4.3
Asymmetrical hybrid optical OFDM
137
4.5
Conclusion
142
5
Multicolor Modulation
147
5.1
Color shift keying
147
5.1.1
Constellation
148
5.1.2
Color calibration
151
5.1.3
Constellation optimization
152
5.1.4
CSK with Quad-LED
155
5.2
CSK with coded modulation
156
5.3
Wavelength division multiplexing with predistorion
159
5.3.1
System model
160
5.3.2
Receiver-side predistortion
161
5.3.3
Performance evaluation
164
5.4
Conclusion
166
6
Optical MIMO
169
6.1
Non-imaging optical MIMO techniques
170
6.1.1
Channel response
170
6.1.2
Optical MIMO techniques
171
6.1.3
Performance comparison
175
6.2
Imaging optical MIMO techniques
178

vii
6.3
Multiuser precoding techniques
180
6.4
Optical MIMO-OFDM
190
6.4.1
DCO-OFDM-based MU-MIMO VLC
193
6.4.2
ACO-OFDM-based MU-MIMO VLC
194
6.4.3
Performance evaluation
195
6.5
Conclusion
197
7
Signal Processing and Optimization
201
7.1
Sum-rate maximization for the multi-chip-based VLC system
201
7.1.1
System model
202
7.1.2
Constraints on illumination and communication
203
7.1.3
Sum-rate maximization
205
7.1.4
Performance evaluation
208
7.2
Heterogeneous VLC-WiFi optimization
212
7.2.1
System model
213
7.2.2
Eﬃcient VHO scheme
214
7.2.3
Performance evaluation
219
7.3
Signal estimation and modulation design for VLC with SDGN
223
7.3.1
Signal estimation for VLC with SDGN
223
7.3.2
Suboptimal estimation for VLC with SDGN
228
7.3.3
Eﬃcient signal design for VLC with SDGN
230
7.4
Conclusion
236
8
Optical Camera Communication: Fundamentals
239
8.1
Why OCC
239
8.1.1
Wide spectrum
240
8.1.2
Image-sensor-based receiver
240
8.1.3
Advantages of image sensor receiver
241
8.1.4
Challenges for OCC implementation
244
8.2
OCC applications: beyond imaging
246
8.2.1
Indoor localization
246
8.2.2
Intelligent transportation
249
8.2.3
Screen–camera communication
250
8.2.4
Privacy protection
251
8.3
Fundamentals of OCC
252
8.3.1
Optical imaging system
252
8.3.2
Image sensor architecture
253
8.3.3
Noise characteristics in the image-sensor-based receiver
261
8.3.4
Channel model for OCC
270
8.4
Capacity bounds for OCC
275
8.4.1
SISO-OCC channel capacity with M-SDGN
275
8.4.2
Capacity-achieving probability measurement with M-SDGN
276
8.4.3
Capacity of imaging optical MIMO systems with bounded inputs
280
8.5
Outage capacity for OCC with misalignment
284
8.6
Conclusion
285
www.ebook3000.com

viii
9
Optical Camera Communication: Modulation and System
Design
291
9.1
Coding and decoding
292
9.1.1
Multilevel coding and multi-stage decoding
293
9.1.2
Single-level coding and joint decoding
295
9.2
Modulation schemes
297
9.2.1
Undersampling-based modulation
298
9.2.2
Rolling shutter eﬀect-based modulation
301
9.2.3
Spatial OFDM
304
9.2.4
Spatial WPDM
307
9.3
System impairment factors
309
9.3.1
Impairment factors in spatial OFDM
309
9.3.2
Impairment mitigation techniques
322
9.4
Synchronization in OCC
329
9.4.1
Synchronization challenges
329
9.4.2
Per-line tracking and inter-frame coding
331
9.4.3
Rateless coding
333
9.5
OCC system experimental platform
336
9.5.1
Design and implementation of a real-time OCC system
336
9.6
Conclusion
347
10
Index
353

ix
Preface
This book presents the state-of-the-art of visible light communication (VLC) focus-
ing on the modulation and signal processing aspects. VLC has many advantages,
such as wide unregulated bandwidth, high security and low cost over its traditional
radio frequency counterpart. It has attracted increasing attention from both academia
and industry, and is considered as a promising complementary technology in the ﬁfth
generation (5G) wireless communications and beyond, especially in indoor applica-
tions. This book provides for the ﬁrst time a systematical and advanced treatment
of modulation and signal processing for VLC and optical camera communication
(OCC) systems. Example designs are presented and the analysis of their performance
is detailed. In addition, the book includes a bibliography of current research literature
and patents in this area.
Visible Light Communications: Modulation and Signal Processing endeavours to
provide topics from VLC models to extensive coverage of the latest modulation and
signal processing techniques for VLC systems. Major features of this book include
a practical guide to design of VLC systems under lighting constraints, and the com-
bination of the theoretical rigor and practical examples in present OCC systems.
Although it contains some introductory materials, this book is intended to serve as
a useful tool and a reference book for communication and signal processing profes-
sionals, such as engineers, designers and developers with VLC related projects. For
university undergraduates majoring in communication and signal processing, this
book can be used as a supplementary tool in their design projects. Graduate students
and researchers working in the ﬁeld of modern communications will also ﬁnd this
book of interest and valuable. The book is organized as follows.
Chapter 1 provides an overview of the history of VLC, its advantages, applications,
related modulation and signal processing techniques, and standardization progresses.
Chapter 2 investigates optical channel models and channel capacity subject to light-
ing constraints from light emitting diode (LED), where chromaticity control, dim-
ming control and ﬂicker mitigation are also discussed. The link characteristics in-
cluding shadowing, direct versus indirect lighting and natural light are introduced.
Typical optical channel models are addressed in detail. In addition, channel capac-
ity under diﬀerent lighting constraints is derived to achieve tight upper and lower
bounds.
www.ebook3000.com

x
Chapter 3 reviews carrierless, single carrier modulations and some coding schemes
for VLC systems. Modulation and coding techniques for dimming control and ﬂicker
mitigation are also introduced to satisfy illumination requirements.
Chapter 4 brieﬂy reviews conventional optical orthogonal frequency division mul-
tiplexing (OFDM) schemes and then focuses on recent developments on optical
OFDM including performance enhancement, spectrum- and power- eﬃcient optical
OFDM, and optical OFDM under lighting constraints. Comprehensive comparisons
of the existing and proposed modulation techniques are provided as well.
Chapter 5 discusses multicolor modulation schemes under illumination require-
ments. The LED colorimetry is introduced as a measure for illumination quality,
and various modulation schemes are explored to support both communication and
high quality illumination.
Chapter 6 explains optical multiple-input multiple-output (MIMO) techniques for
imaging and non-imaging VLC systems, including modern optical MIMO, optical
spatial modulation, optical space shift keying, and optical MIMO-OFDM. Further-
more, multiuser precoding techniques for VLC systems are also introduced under
lighting constraints.
Chapter 7 addresses the signal processing and optimization issues for VLC sys-
tems including pre- and post-equalization, interference mitigation and capacity max-
imization. The hybrid visible light communication and wireless ﬁdelity (VLC-WiFi)
system is also introduced to provide better coverage, and the system optimization
problem is formulated and solved.
Chapter 8 introduces OCC fundamentals. It describes a typical OCC link, from
the optical signal source, propagation path, to optical lens, ﬁlters, pixelated image
sensors and the receiver. Diﬀerent noise models such as ambient noise, temporal
noise and ﬁxed pattern noise are also addressed. Inter-pixel interference in the active
pixel sensor, optical crosstalk due to diﬀraction and light diﬀusion, and the distortion
due to perspective are introduced.
Chapter 9 discusses OCC modulation schemes and system design aspects. It also
introduces various system impairment factors and mitigation techniques, including
tracking and coding techniques to achieve synchronization. The oﬀ-line and real-time
prototypes as well as the potential applications of smartphone cameras are illustrated.
This work was supported by National Key Basic Research Program of China under
Grant No. 2013CB329200.
The authors also wish to thank Mr. Rui Jiang at Tsinghua University, China for his
contributions to Chapter 2, Mr. Jiandong Tan at Tsinghua University, China for his
help with writing Chapter 4.
The authors are indebted to anonymous reviewers for their detailed and insightful
constructive comments, as well as many researchers for their published works serving
as rich reference sources in the book. The help provided by Mary Hatcher and other
staﬀmembers from John Wiley & Sons is most appreciated.

1
1
Introduction to Visible Light Communications
1.1
History
Visible light communication (VLC) is an age-old technique which uses visible light
to transmit messages from one place to another. In ancient China, communication
by ﬂames was an eﬀective way to relay signals from border sentry stations to distant
command oﬃces on the Great Wall. Similarly, lighthouses were distributed along
seashore or on islands to navigate the cargo ships on oceans. Nowadays, visible
lights are also mounted on modern skyscrapers to not only indicate its presence at
particular locations, but also provide reference signals to pilots ﬂying a plane.
Along with the evolution of telecommunication science and technology, using vis-
ible lights instead of other electromagnetic waves to transmit information started
to attract attentions from scientists, tracing back to the famous photophone exper-
iment by Alexander Graham Bell in 1880 [1]. In his experiment, the voice signal
was modulated onto the sunlight and the information was transmitted over a distance
of about 200 m. Eﬀorts to explore natural lights and artiﬁcial lights for communi-
cation continued for decades. In 1979, F. R. Gfeller and G. Bapst demonstrated the
technical feasibility of indoor optical wireless communication using infrared light
emitting diodes (LEDs) [2]. Built upon ﬂuorescent lamps, VLC at low data rates
was investigated in [3]. As LED illumination industry advanced, the fast switching
characteristic of visible light LEDs prompted active researches on high-speed VLC.
A concept was ﬁrst proposed by Pang et al. in 1999 [4], using the traﬃc light LED as
the optical signal transmitter. Later on, a series of fundamental studies were carried
out by S. Haruyama and M. Nakagawa at Keio University in Japan. They investi-
gated the possibility of providing concurrent illumination and communication using
white LEDs for VLC systems [5, 6]. Meanwhile, they not only discussed and ana-
lyzed eﬀects of light reﬂection and shadowing on the system performance, but also
explored VLC applications at relatively low rates [7, 8]. Using LED traﬃc lights to
transmit traﬃc information was experimented based on avalanche photodiode (APD)
and two-dimensional image sensor receiver, respectively [9, 10]. VLC and power-
line communication (PLC) were coherently integrated to provide a network capa-
bility [11], where the performance of an advanced orthogonal frequency division
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.
www.ebook3000.com

2
multiplexing (OFDM) modulation format was evaluated [12]. Applications were ex-
tended to brightness control [13] and high-accuracy positioning [14] in addition to
communications.
As mobile broadband grows rapidly, the demand for high-speed data services also
increases dramatically. VLC emerges as an alternative to alleviate radio spectrum
crunch. Higher rate VLC has attracted global research attentions, in particular, from
European researchers at the beginning, by maximally exploring the LED capabilities
and increasing the spectral eﬃciency. Using a simple ﬁrst-order analogue equalizer,
a data rate of 100 Mbps was realized with on-oﬀkeying non-return-to-zero (OOK-
NRZ) modulation in 2009 [15]. Meanwhile, 125 Mbps over 5 m using OOK and 200
Mbps over 0.7 m using OFDM were reported by Vucic et al. [16, 17], where photodi-
odes (PDs) were used in those VLC systems to detect optical signals. By adopting a
2×1 array of white LEDs and an imaging receiver consisting of a 3×3 photodetector
array, a multiple-input multiple-output OFDM (MIMO-OFDM) system could deliv-
er a total transmission rate of 220 Mbps over a range of 1 m [18]. The data rate can
be further increased if APD is adopted. In 2010, the data rate of the OOK-based sys-
tem reached 230 Mbps [19] and the data rate of the OFDM-based system approached
513 Mbps with bit- and power-loading [20]. In 2012, the highest data rate of a single
LED-based VLC system achieved 1 Gbps with OFDM [21]. Additionally, carrierless
amplitude and phase modulation (CAP) was introduced into VLC systems, and a data
rate of 1.1 Gbps was achieved [22]. Using an MIMO structure, a 4 × 9 VLC system
achieving 1.1 Gbps was presented, where the parallel streams were transmitted by 4
individual LEDs and detected by a 3 × 3 receiver array [23].
In the previous studies, a phosphor-converted LED (pc-LED) was adopted as op-
tical signal transmitter. The bandwidth of a pc-LED is however limited by slow re-
sponse of the phosphorescent component. In 2014, a post-equalization circuit con-
sisting of two passive equalizers and one active equalizer was proposed to extend the
bandwidth from tens of MHz to around 150 MHz [24]. If other types of LEDs having
higher bandwidth are employed, it has potential to increase the throughput signiﬁ-
cantly. For example, using micro LEDs as transmitters in VLC systems could be
ﬁrstly attributed to McKendry et al. and a data rate of 1 Gbps was reported at a price
of low luminous eﬃciency [25]. Multicolor LEDs, radiating particularly red, green,
and blue lights, can provide high-rate transmission by wavelength division multi-
plexing (WDM). Data were simultaneously conveyed in parallel by diﬀerent colors
such as red, green, and blue lights. In principle, the data rate could be tripled in the
absence of color crosstalk. An OFDM-based VLC system using a multicolor LED
was realized supporting a data rate of 803 Mbps over 0.12 m [26]. Using multicolor
LED as the transmitter and APD as the receiver, the data rate of OFDM-based VLC
systems was increased from 780 Mbps over 2.5 m to 3.4 Gbps over 0.3 m, where
WDM and bit- and power-loading techniques were jointly applied [27–29]. In an-
other study [30], the bandwidths of multicolor LED chips were extended to 125 MHz
and modulated by 512 quadrature amplitude modulation (QAM) and 256WDM, re-
spectively, and the frequency domain equalization based VLC system ﬁnally reached
a data rate of 3.25 Gbps. The data rate of CAP-based VLC systems using multicolor
LEDs was increased up to 3.22 Gbps, also beneﬁting from WDM technology [31].

3
It is well known that lighting LEDs typically serve as transmitters for downlink
information transmission to mobile devices. In 2013, an asynchronous bidirectional
VLC system was demonstrated in [32] where a 575 Mbps downlink transmission
was realized by red and green LEDs, and a 225 Mbps uplink transmission by a single
blue LED. From a network perspective, a spectrum reuse scheme based on diﬀerent
colors was proposed for diﬀerent cells in an indoor optical femtocell, where multiple
users can share the spectrum and access the network simultaneously [33]. User-
centric cluster formation methods were proposed for interference-mitigation in [34].
A VLC system can also be combined with a wireless ﬁdelity (WiFi) system to provide
seamless coverage after a judicious handover scheme was designed and applied [35].
In multicolor LED-based VLC systems, signals from three color light sources were
transmitted independently in most experiments, leaving room for capacity increase.
In 2015, Manousiadis et al. used a polymer-based color converter to generate red,
green, and blue lights emitted by blue micro LEDs [36]. Three color lights were
modulated and mixed for white light illumination. The aggregate data rate from
three colors was 2.3 Gbps. Techniques to explore spatial and temporal capabilities
of devices were also investigated. A MIMO VLC system employing diﬀerent ﬁeld of
view (FOV) detectors in order to improve signal-to-noise ratio (SNR) was analyzed
in [37]. An optical diversity scheme was proposed, where the original data and its
delayed versions were simultaneously transmitted over orthogonal frequencies [38].
Data rate can be signiﬁcantly enhanced by employing diﬀerent degrees of freedom.
Combining with WDM, high-order CAP, and post-equalization techniques, Chi et
al. showed that a multicolor LED based VLC system could provide a data rate of
8 Gbps [39]. A novel layered asymmetrically clipped optical OFDM scheme was
proposed to make a tradeoﬀbetween complexity and performance of an intensity-
modulated direct-detection (IM/DD) VLC system [40]. Under lighting constraints,
DC-informative modulation and system optimization techniques were proposed [41–
43]. Some receiver design issues were particularly addressed in weak illuminance
environments and several bidirectional real-time VLC systems with low complexity
were reported [44, 45].
Besides individual research groups, there are also many large scale organizations
and research teams worldwide that have contributed to the development and standard-
ization of VLC technology. In Europe, the HOME Gigabit Access (OMEGA) project
was launched in 2008 to develop a novel indoor wireless access network, providing
gigabit data rates for home users [46]. The project members included France Tele-
com, Siemens, University of Oxford, University of Cambridge, and many other com-
panies and universities. This project ﬁnally demonstrated a real-time VLC system us-
ing 16 white LEDs on the ceiling to transfer HD video streams at 100 Mbps. Another
organization called OPTICWISE was funded by the European Science Foundation
under an action of the European Cooperation in Science and Technology (COST),
which allowed coordination of nationally funded VLC researches across European
countries. Signiﬁcant research results and professional activities were reported from
its various groups [47].
In Japan, Visible Light Communication Consortium (VLCC) consisting of many
Hi-tech enterprises and manufacturers in the areas of illumination and communica-
www.ebook3000.com

4
tion, such as Casio, NEC, and Panasonic, was founded in 2003. It was devoted to
marketing investigation, application promotion, and technology standardization. Af-
ter years of development, it evolved to Visible Light Communications Association
(VLCA) in 2014 to collaborate various industries closely for realizing the visible
light communication infrastructure, from telecommunication to lighting, social in-
frastructure, Internet, computer, semiconductor, etc.
In the United States, the Ubiquitous Communication by Light Center (UC-Light),
Center on Optical Wireless Applications (COWA), and Smart Lighting Engineering
Research Center (ERC), are notable VLC research groups. UC-Light focuses on ef-
ﬁcient lighting, communication, and navigation technologies by LEDs, and aims to
create new technological innovations, economic activities, and energy-saving ben-
eﬁts. COWA is dedicated to the optical wireless applications of communications,
networking, imaging, positioning, and remote sensing. ERC concentrates on LED
communication systems and networks, supporting materials and lighting devices,
and applications for detection of biological and biomedical hazards.
In China, two sizable teams were built in 2013 to focus on the research of optical
wireless communications over broad spectra, including visible light communication.
One was funded by National Key Basic Research Program of China (973 Program),
including about 30 researchers from top universities and research institutes. The oth-
er was funded by National High Technology Research and Development Program of
China (863 Program). Both project teams have made tremendous eﬀorts on theory
breakthrough, technology development, and real-time VLC system demonstrations.
The real-time data rate has reached 1.145 Gbps at 2.5 m to deliver multimedia ser-
vices, and the highest oﬀ-line data rate of 50 Gbps was achieved at a shorter distance.
To jointly prompt commercialization of VLC technologies, Chinese Visible Light
Communications Alliance (CVLCA) was founded in 2014, which attracted univer-
sities and industries in lighting, telecommunication, energy, consumer electronics,
and ﬁnancing agencies.
1.2
Advantages and applications
Visible light communication has many attractive advantages compared to its radio
frequency (RF) counterpart, which include but are not limited to the following as-
pects.
(1) Wide spectrum: As the demand for high-speed wireless services is increasing
dramatically, RF spectrum is getting congested. The radio wave spectrum is
limited, from 3 kHz to 300 GHz, while the visible light spectrum is at least 1000
times greater, which is from 400 THz to 780 THz [48].
(2) No electromagnetic interference: Since light does not cause any electromagnetic
interference, VLC is suitable for communications in the electromagnetic inter-
ference immunity (EMI) environments, such as hospitals, nuclear power plants,
and airplanes.

5
(3) Easy implementation: VLC modules can be made small and compact, so that
they can be easily implemented into the existing lighting infrastructure. The
modulation unit, digital-to-analog converter, and driving circuit can be integrat-
ed into LEDs. The photodiode, analog-to-digital converter, and other signal pro-
cessing units can be manufactured as a portable external receiver, or embedded
into the lighting infrastructure.
(4) Low cost: The implementation of a VLC system is relatively simple. Instead
of designing an entire wireless communication system, it reuses the ubiquitous
lighting infrastructure, and only a few additional modules are added to the light-
ing system. As LED industry is rapidly developing, the cost of massively pro-
ducing VLC transceivers is expected to decrease.
(5) High energy eﬃciency: As green lighting devices, LEDs have been recognized
as the next generation lighting devices, which can reduce the energy consumption
of traditional lighting sources by 80% [49]. If all the lighting sources are replaced
by LEDs, the global electricity consumption is expected to reduce by as much as
50% [50]. According to a recent report from the U.S. Department of Energy, by
the year of 2025, it is possible to save the amount of energy up to 217 terawatt-
hours (TWh) with the adoption of LED lighting technology [51].
(6) Health safety: Unlike infrared LED and laser having concentrated optical power
within a narrow beam, lighting LED is a diﬀusive light source. Therefore, it is
intrinsically safe for many application scenarios with large emitted optical power.
Since lighting LED does not generate radiation as radio frequency or microwave
devices do, no obvious health hazard is incurred to the environment and end
users.
(7) Information security: Security is an important issue to RF communication be-
cause radio waves can penetrate walls, causing information leakage. Since light
cannot penetrate opaque objects, VLC can be conﬁned in an indoor, enclosed
space and more secure communication links are ensured.
The aforementioned features help to yield various indoor and outdoor VLC ap-
plications. The most desirable application, perhaps, is indoor high-speed Internet
access for smart phones and computers. People usually spend much more time stay-
ing indoors than outdoors, in oﬃces and homes for study, work, entertainment, etc.
It would be convenient to access the Internet by simply using LED lighting devices
on the ceiling. The inherent modulation bandwidth of LEDs (orders of MHz to hun-
dreds of MHz) is able to provide much higher data rate than WiFi and existing mo-
bile networks. Equipped with advanced techniques, such as multicarrier modulation,
wavelength multiplexing, and equalization, the VLC data rate can be increased up to
gigabit per second.
Besides oﬃces and homes, electromagnetic sensitive environments also require
safe and reliable wireless services. Visible light does not cause any electromagnetic
interference to the existing electrical equipment, and is thus ideal for communication
www.ebook3000.com

6
in those environments. In a hospital, for example, some sophisticated and expen-
sive medical equipment, such as magnetic resonance imaging equipment, must be
insulated from electromagnetic interference. The electronic devices radiating the
electromagnetic waves are prohibited in an airplane cabin during takeoﬀand landing
because those waves might cause equipment malfunction. In a nuclear plant, it is
also very restrictive to use a mobile phone. It is evident that VLC becomes a safe
technology for communications in such EMI environments.
In some cases, users would like to directly communicate to each other at high
speed, without routing messages through a network, such as machine-to-machine
(M2M) and device-to-device (D2D) communications. Two VLC transceivers such
as smart phones or laptops can realize point-to-point communication directly. Light
communication becomes a feasible solution as well.
It is well known that LED is a natural transmitter and can easily broadcast informa-
tion, which can be embedded in LED displays and screens in diﬀerent public areas,
such as waiting hall at the airports and train stations, and sent to passengers. If an
image sensor in a camera is used as signal detector, optical camera communication
(OCC) could receive the broadcasting information [52]. Also, in shopping malls and
outlets, merchandise and advertisement information can be broadcasted to customers
through lighting LEDs or signage. Exhibitions, galleries, and museums are also ideal
places to use LEDs for seamless information broadcasting.
Besides that, people could take the advantage of densely distributed LEDs for lo-
cation references and use triangularization algorithms to forecast device positions.
As a result, highly accurate indoor positioning and navigation come true by LEDs,
like GPS in outdoors by satellites. LEDs could also send control signals to an intel-
ligent robot and guide its precise movement along a route to reach its predeﬁned
destination [53].
Since there are a large number of LEDs deployed/used outdoors as well, street
lights, traﬃc lights, and vehicle lights are also applicable for establishing VLC wire-
less links among vehicles, vehicle and roadside lighting infrastructure, vehicle and
traﬃc lights [9, 10, 54]. Since the vehicle is usually equipped with an image sen-
sor array, it can predict its relative motion together with data transmission [55–57].
Underwater VLC is also a competitive communication technology for ocean explo-
ration.
The aforementioned indoor and outdoor applications span a variety of ﬁelds, which
could gradually penetrate diﬀerent markets for various services, from low rate com-
munication and positioning, to high-rate communication, and intelligent transporta-
tion. As words “visible light” indicate, VLC will have a bright future in our modern
life.
1.3
Overview of modulation and signal processing
For VLC systems, LEDs and photodiodes are used as alternative transceivers to con-
vey information via visible light. Accordingly, modulation and signal processing for

7
VLC systems possess new features and new challenges, compared to their RF coun-
terparts. Normally, LED works under a forward bias while photodiode is driven by
a reverse voltage. Since LED is used for lighting and communication simultaneous-
ly, its chromaticity and nonlinearity have to be investigated in VLC systems. As for
the photodiode, key parameters such as absorption coeﬃcient, quantum eﬃciency,
and responsivity are considered in the system model. Based on whether there exists
a line-of-sight (LOS) link between the transmitter and the receiver, optical wireless
propagation links can be classiﬁed into two categories: LOS link and non-line-of-
sight (NLOS) link. Besides, noise from other devices and surrounding environment
should be considered. Based on the dominant noise in practical scenarios, three com-
mon optical wireless channel models are discussed, i.e., free-space optical intensity
channel, discrete-time Poisson channel, and improved free-space intensity channel.
Since there are no analytic expressions of channel capacity, several upper and low-
er bounds have been illustrated. Considering these speciﬁc channel models of VLC
systems, several modulation and signal processing schemes have been demonstrated.
Single carrier modulation and carrierless modulation schemes are addressed ﬁrst-
ly. Pulse amplitude modulation (PAM) is a simple modulation format widely used in
VLC systems. When multipath channel is considered, PAM together with frequency-
domain equalization is utilized to combat inter-symbol interference (ISI). Besides,
several implementation schemes are introduced in order to overcome the eﬀect of
LED nonlinearity, i.e., PAM can be implemented with multiple LEDs, where each
LED is modulated by OOK. Pulse position modulation (PPM) is another simple mod-
ulation format for VLC systems and PPM together with decision feedback equaliza-
tion could eliminate the ISI. Since PPM has low data rate with only one pulse in
a single symbol duration, several modiﬁed schemes have been proposed including
diﬀerential PPM, multipulse PPM, overlapping PPM, and variable PPM. Besides,
CAP is also adopted in VLC systems due to its high spectral eﬃciency and simple
implementation, which can also be extended to multi-dimensional CAP. Meanwhile,
various modiﬁed modulation and coding schemes have been proposed for dimming
control in single carrier VLC systems, which could support communication and il-
lumination simultaneously.
Optical OFDM techniques have been investigated in order to realize broadband and
high-rate transmission. Since IM/DD methodology is used in VLC systems, the am-
plitude of optical OFDM signals is constrained to be real-valued and non-negative.
Therefore, the conventional OFDM method is not feasible for intensity modulation
and several optical OFDM schemes have been proposed to satisfy the speciﬁc sig-
nal constraints in VLC systems, such as DC-biased optical OFDM (DCO-OFDM),
asymmetrically clipped optical OFDM (ACO-OFDM), pulse-amplitude-modulated
discrete multitone (PAM-DMT), and unipolar OFDM (U-OFDM). Similar to conven-
tional RF systems, optical OFDM suﬀers from high peak-to-average power ratio (PA-
PR), which might introduce severe nonlinear distortion and impair the performance
of VLC systems. There are several techniques to enhance the performance of optical
OFDM by optimizing DC bias and scaling factor, mitigating the nonlinear eﬀect of
LED, and PAPR reduction. Besides, some recently proposed power- and spectral-
eﬃcient optical OFDM methodologies, such as hybrid optical OFDM, enhanced U-
www.ebook3000.com

8
OFDM, and layered ACO-OFDM have shown great potential for future VLC sys-
tems. In addition, seamless integrations of OFDM modulation and dimming control
are discussed, including pulse width modulation, reverse polarity optical OFDM and
asymmetrical hybrid optical OFDM, which have shown that dimmable OFDM can
support a wide dimming range with a relatively small throughput ﬂuctuation.
Multicolor modulation is an interesting candidate for VLC systems, compared
to the traditional RF modulation methods. White LEDs are usually classiﬁed into
single-chip LEDs and RGB-type LEDs. The single-chip LEDs use a single blue LED
that excites a yellow phosphor to create an overall white emission, while the RGB-
type LEDs combine light from LEDs of three primary colors of red, green, and blue.
They are preferable to single-chip LEDs since the transmission rate can be improved
owing to their faster response time. Moreover, three wavelengths corresponding to
the three primary colors can be used to carry multiple data streams independently
and thus oﬀer the possibility of WDM. Accordingly, multicolor modulation schemes
under illumination requirements for VLC systems with RGB-type LEDs have been
illustrated, whereby color shift keying (CSK) is developed and adopted in the IEEE
802.15.7 standard. Furthermore, the optimal design rules of CSK constellation as
well as Qual-LED CSK are provided to achieve superior capacity, while CSK with
coded modulation is introduced for practical scenarios. Moreover, WDM system
combined with channel coding is detailed, and a receiver-side predistortion is pro-
posed before channel decoding, which has shown signiﬁcant performance gain.
Despite the fact that the spectrum of visible light is as wide as several THz, the
bandwidth of oﬀ-the-shelf LED is limited, which makes it very challenging to achieve
high-rate transmission. Meanwhile, in order to provide suﬃcient illumination, mul-
tiple LED units are usually installed in a single room. In such scenarios, MIMO tech-
niques can be naturally employed in indoor VLC schemes to boost the data rate. Typi-
cally, there are two optical MIMO approaches for VLC systems, namely non-imaging
MIMO and imaging MIMO. For non-imaging MIMO systems, each receiver collects
the surrounding light with its own optical concentrator, and optical MIMO, optical
spatial modulation, and optical space shift keying can be used. For imaging MIMO
systems, an imaging diversity receiver is utilized to distinguish the light from diﬀer-
ent transmitters. Meanwhile, in order to support data transmission for multiple users
simultaneously, precoding techniques are employed to eliminate the inter-user inter-
ference under the lighting constraints in VLC systems. Moreover, MIMO-OFDM is
introduced for single-user and multiuser VLC systems, which provides high spectral
eﬃciency and robust reception.
Due to the special characteristics of transceivers and channels for VLC systems,
several signal processing and optimization issues for VLCs have been discussed.
For multi-chip-based multiple-input single-outputVLCsystem, an electricalandopti-
cal power allocation scheme is introduced to maximize the multi-user sum-rate in con-
sideration of the luminance, chromaticity, amplitude, and bit error rate constraints.
Considering the vulnerability of VLC LOS links, heterogeneous VLC-WiFi systems
oﬀer a solution for future indoor communications that combines VLC to support
high-data-rate transmission and RF to support reliable connectivity. In such hetero-
geneous systems, vertical handover is critical to improve the system performance and

9
a dynamic approach is adopted to obtain a tradeoﬀbetween the switching cost and the
delay requirement, where the vertical handover is formulated as a Markov decision
process problem.
For VLC systems with narrow FOV, the PD shot noise modeled by Poisson statis-
tics is signal-dependent since it originates from the quantum nature of the received
optical energy rather than external noises, which is in contradiction to the conven-
tional signal-independent additive white Gaussian noise model. Therefore, novel
signal processing and estimation techniques are illustrated to guarantee the trans-
mission performance. OCC is a new form of visible light communication, which
employs pervasive image sensors assembled in consumer electronic devices as the
receiver. The advantages of OCC include the wide spectrum compared to the con-
ventional VLC systems, the pervasive optical light sources including illumination
LED, display and traﬃc light, and the pervasive consumer cameras having natural
multicolor sensitivity, the feasibility of massive MIMO and anti-interference image-
sensor-based receivers. With these advantages, OCC combined with mobile com-
puting could realize novel forms of sensing and communication applications, such
as indoor location, intelligent transportation system, screen-camera communication,
and privacy protection. However, there exist also challenging issues to be addressed,
including the limited frame rate, synchronization issue, non-negligible shot noise,
perspective distortion, pixel misalignment, and blur eﬀect.
To investigate the channel characteristics and system performances of OCC sys-
tems, the pixel-sensor structure and its operation procedure for CMOS image sensors
have been addressed and the noise composition, including photo shot noise, dark cur-
rent shot noise, ﬁxed-pattern noise, source follower noise, sense node reset noise, and
quantization noise at high illumination, is illustrated and analyzed. A plurality of ex-
perimental results demonstrate that the noise in a CMOS image-sensor-based receiv-
er can be modeled as Gaussian noise, such as signal-independent electrical thermal
noise as well as the signal-dependent and signal-independent shot noise. Based on
these noise models, the SNR in OCC systems should be redeﬁned, and accordingly,
a uniﬁed communication model is proposed for OCC systems. Moreover, channel
capacity of OCC systems has been investigated and the asymptotic upper bound and
the tight lower bound with peak and average power constraints have been addressed.
The capacity bounds indicate that a spectral eﬃciency of 8–11 bit/s/Hz is achievable
under an ideal channel with diversity structure, and there is room for improvement
using the today’s OCC prototypes.
According to speciﬁc OCC channel characteristics, the modulation schemes, syn-
chronization issues and several technical challenges in a real-time OCC system have
been addressed. Based on the signal-dependent noise model, a capacity-achieving
discrete nonuniform signaling scheme has been designed for OCC systems. However,
it requires the feedback link, which possesses high complexity. Alternative modula-
tion schemes which convey signal on diﬀerent domains are adopted in OCC systems,
including the under-sample-based modulation schemes in time/frequency domains,
the rolling-shutter-eﬀect-based modulation schemes in time/frequency domains,
color-intensity modulation (CIM) in color space, and the spatial OFDM/WDM in
spatial/frequency domains. Moreover, the eﬀect of nonideal factors, such as linear
www.ebook3000.com

10
misalignment, geometry distortion, blur eﬀect and vignetting, and the corresponding
mitigating schemes, are discussed, including equalization, perspective correction,
adaptive coding, and modulation. For a practical OCC wireless link, synchronization
is important and several methodologies have been discussed. The per-line tracking,
inter-frame coding, and rateless coding could tackle the synchronization issues by
decoding imperfect frames and recovering any lost frames.
Furthermore, a real-time CIM-MIMO OCC prototype has been realized, which
utilizes spatial, color, and intensity dimensions to generate a high-dimensional sig-
nal constellation and parallel wireless links, leading to an increased data rate and
improved bit error rate performance. Several technical challenges including unstable
frame rate, joint nonlinearity and crosstalk, ﬂicker noise, and rolling shutter, have
been tackled.
For a real-time OCC system, commercial CMOS cameras are used as receivers.
The corresponding products can be used in near-ﬁeld screen-camera communica-
tions and indoor visible light positioning. If the sensor is equipped with an external
optical lens, the transmission distance between the light source and the sensor can be
signiﬁcantly extended, which makes the system suitable for other applications, for
example, capturing signals from a distant traﬃc light, or information broadcasting
displays in a public area such as shopping mall and transportation hub.
1.4
Standards
With rapid evolution of VLC technologies, it is imperative to develop the correspond-
ing standards to harmonize the physical layer (PHY) protocols and media access
control (MAC) layer protocols, and help to transfer technologies into applications
promptly, which has attracted much attention from various international and nation-
al standardization bodies.
The ﬁrst international VLC standard, that is IEEE 802.15.7, was published by IEEE
802.15.7 working group for wireless personal area networks in 2011 [58]. The stan-
dard clearly speciﬁes the PHY and MAC layers for short-range optical wireless com-
munications using visible light for indoor and outdoor applications. IEEE 802.15.7
accommodates three diﬀerent PHY layer types, i.e., PHY I, PHY II, and PHY III,
respectively. PHY I supports lower rate (11.6–266.6 kb/s) and long-distance outdoor
applications, PHY II supports higher rate (1.25–96 Mb/s) systems working in indoor
infrastructures and point-to-point applications, and PHY III is designed to support
the same rate (1.25–96 Mb/s) with multicolor light sources/detections. PHY I and
PHY II adopt OOK and VPPM, which is a combination of two-pulse position modu-
lation and pulse width modulation (PWM). A color shift keying modulation format,
generated by using three-color light sources out of the seven-color bands, is also
deﬁned. Diﬀerent forward error correction (FEC) schemes and run length limited
(RLL) codes are added to meet various channel conditions and to guarantee the light-
ing brightness. In the MAC layer, IEEE 802.15.7 supports three diﬀerent topologies,
namely star, peer-to-peer, and broadcast. The MAC layer is also responsible for the

11
following major tasks: initiating/maintaining procedures, association/disassociation
procedures, color-function support mechanism, illumination and dimming support
mechanism, mobility support mechanism, color stabilization, etc.
In 2014, a new working group 802.15.7r1 was formed to make revisions on the pre-
vious standard. The new standard, called as IEEE 802.15.7r1, is expected to be pub-
lished in 2017 [59]. IEEE 802.15.7r1 will specify the following three diﬀerent appli-
cation scenarios depending on various data rates and devices. First, LED-ID is low-
rate photodiode-based communication sending identiﬁcation information through
various LEDs. Second, OCC is an image-sensor-based communication which of-
fers positioning/localization, message broadcasting, etc. Accordingly, three diﬀerent
source types have been deﬁned, i.e., discrete source (15 bps–4 kbps), surface source
(90 bps–8 kbps) and two-dimensional screen source (40 bps–64 kbps). At current
stage, the modulation formats are still under on-going discussions. As a related appli-
cation, a new interest group, called as IEEE 802.15 Vehicular Assistant Technology
(VAT), was formed in January 2017 for OCC-based long range vehicular applica-
tions. Smart automotive lighting in vehicle safety systems has been also investigated
in [60]. Third, light ﬁdelity (LiFi) is high-rate photodiode-based communication that
can support Gbps data stream, bidirectional and multiple access, mobility, and hand-
over. The technical speciﬁcations focusing on modulation, coding, bandwidth, and
optical clock rate have been intensively discussed. Although IEEE 802.15.7r1 has not
been ﬁnalized, the endorsed reference channel models were presented in [61], where
four diﬀerent reference scenarios, including work place, oﬃce room with secondary
light, living room, and manufacturing cell, are emulated by a powerful software Ze-
max to describe the channel impulse responses.
Besides IEEE 802.15.7 and IEEE 802.15.7r1, International Telecommunication
Union (ITU), established a study group (named as SG15) to standardize the VLC
technology within the G.vlc framework in September 2015. Research community
together with key industrial members, such as Huawei and Marvell, are constructively
and jointly developing a high-speed VLC standard. So far, G.vlc has been specifying
VLC modulation format, dimming control, channel and source models, band plans,
and network topology. Recently, SG15 decided to start a new G.occ framework (Gbps
OCC) in order to cover various aspects of optical wireless applications.
In addition to international eﬀorts, there are also national organizations focusing
on VLC standardization. In Japan, VLCC was established in November 2003, whose
members were major electronic companies and research centers. VLCC tried to
merge VLC technology into LED lightings in oﬃces and homes, commercial dis-
plays, traﬃc signals, and small lamps on home appliances. The Visible Light ID
System was standardized by Japan Electronics and Information Technology Indus-
tries Association (JEITA), for commercial applications including indoor navigation
and POS/client data exchange. In 2014, VLCA was established as the successor to
VLCC, to facilitate various industrial collaborations and further develop the appli-
cation and business of VLC technology.
Globally, China becomes the largest LED manufacturer and consumer market, and
owns the most complete LED industry chain. Its VLC technology has bloomed in
the recent decade, where lighting, wireless communication and automobile indus-
www.ebook3000.com

12
tries are all actively participating in the technology development and standardization
of VLC systems. In March 2017, Smart Visible Light Industrial Technology In-
novation Association was established in Guangdong Province, China, with over 20
industry members, including ZTE, Philips Lighting, and Audi. Its main goal is to
publicize, popularize, and standardize the VLC technology in various industrial and
commercial sectors. The Chinese VLC standard is being drafted by China Electron-
ics Standardization Institute (CESI), and its ﬁrst version will be released soon.
The above on-going standardization activities will prompt successful and rapid
applications of various VLC technologies, which span from positioning, accurate
control, low rate communication, to information broadcasting, and high-speed indoor
and outdoor communications, for mobile devices, robotics, vehicles, and even new
forms of terminals and applications such as drones, unmanned underwater vehicles,
and virtual/augmented reality [62].

13
References
1 A. G. Bell, W. G. Adams, Tyndall, and
W. H. Preece, “Discussion on the
photophone and the conversion of radiant
energy into sound,” J. Soc. Telegraph Eng.,
vol. 9, no. 34, pp. 375–383, 1880.
2 F. R. Gfeller and U. Bapst, “Wireless
in-house data communication via diﬀuse
infrared radiation,” Proc. IEEE, vol. 67,
no. 11, pp. 1474–1486, Nov. 1979.
3 D. Jackson, T. Buﬀaloe, and S. Leeb, “Fiat
lux: A ﬂuorescent lamp digital transceiver,”
IEEE Trans. Ind. Appl., vol. 34, no. 3, pp.
625–630, May/Jun. 1998.
4 G. Pang, T. Kwan, C. H. Chan, and H. Liu,
“LED traﬃc light as a communications
device,” in Proc. IEEE/IEEJ/JSAI
International Conference on Intelligent
Transportation Systems 1999 (Tokyo,
Japan), Oct. 5–8, 1999, pp. 788–793.
5 Y. Tanaka, S. Haruyama, and
M. Nakagawa, “Wireless optical
transmissions with white colored led for
wireless home links,” in Proc. IEEE
International Symposium on Personal
Indoor and Mobile Radio Communications
(PIMRC) 2000 (London, United Kindom),
Sep. 18–21, 2000, vol. 2, pp. 1325–1329.
6 Y. Tanaka, T. Komine, S. Haruyama, and
M. Nakagawa, “Indoor visible light data
transmission system utilizing white LED
lights,” IEICE Trans. Commun., vol. 86, no.
8, pp. 2440–2454, Aug. 2003.
7 T. Komine and M. Nakagawa,
“Fundamental analysis for visible-light
communication system using LED lights,”
IEEE Trans. Consum. Electron., vol. 50,
no. 1, pp. 100–107, Feb. 2004.
8 T. Komine and M. Nakagawa, “A study of
shadowing on indoor visible-light wireless
communication utilizing plural white LED
lightings,” in Proc. International
Symposium on Wireless Communication
Systems (ISWCS) 2004 (Mauritius), Sep.
20–22, 2004, pp. 36–40.
9 M. Akanegawa, Y. Tanaka, and
M. Nakagawa, “Basic study on traﬃc
information system using LED traﬃc
lights,” IEEE Trans. Intell. Transp. Syst.,
vol. 2, no. 4, pp. 197–203, Dec. 2001.
10 H. B. C. Wook, T. Komine, S. Haruyama,
and M. Nakagawa, “Visible light
communication with LED-based traﬃc
lights using 2-dimensional image sensor,”
in Proc. IEEE Consumer Communications
and Networking Conference (CCNC) 2006
(Las Vegas, USA), Jan. 8–10, 2006, pp.
243–247.
11 T. Komine and M. Nakagawa, “Integrated
system of white LED visible light
communication and powerline
communication,” IEEE Trans. Consum.
Electron., vol. 49, no. 1, pp. 71–79, Feb.
2003.
12 T. Komine, S. Haruyama, and
M. Nakagawa, “Performance evaluation of
narrowband OFDM on integrated system of
power line communication and visible light
wireless communication,” in Proc.
International Symposium on Wireless
Pervasive Computing (ISWPC) 2006
(Phuket, Thailand), Jan. 16–18, 2006, pp.
1–6.
13 H. Sugiyama, S. Haruyama, and
M. Nakagawa, “Brightness control methods
for illumination and visible-light
communication systems,” in Proc.
International Conference on Wireless and
Mobile Communications (ICWMC) 2007
www.ebook3000.com

14
(Guadeloupe, France), Mar. 4–9, 2007, pp.
78–83.
14 M. Yoshino, S. Haruyama, and
M. Nakagawa, “High-accuracy positioning
system using visible LED lights and image
sensor,” in Proc. IEEE Radio and Wireless
Symposium 2008 (Orlando, FL), Jan.
22–24, 2008, pp. 439–442.
15 H. L. Minh, D. O’Brien, and G. Faulkner,
“100-Mb/s NRZ visible light
communications using a postequalized
white LED,” IEEE Photon. Technol. Lett.,
vol. 21, no. 15, pp. 1063–1065, Aug. 2009.
16 J. Vucic, C. Kottke, and S. Nerreter, “125
Mbit/s over 5m wireless distance by use of
OOK-modulated phosphorescent white
LEDs,” in Proc. European Conference on
Optical Communication (ECOC) 2009
(Vienna, Austria), Sep. 20–24, 2009, pp.
1–2.
17 J. Vucic, C. Kottke, S. Nerreter, and
A. Buttner, “White light wireless
transmission at 200Mb/s net data rate by
use of discrete-multitone modulation,”
IEEE Photon. Technol. Lett., vol. 21, no.
20, pp. 1511–1513, Oct. 2009.
18 A. H. Azhar, T. Tuan-Anh, and D. O’Brien,
“Demonstration of high-speed data
transmission using mimo-ofdm visible light
communications,” in Proc. IEEE Global
Communications Conference
(GLOBECOM) Workshops 2010 (Miami,
FL), Dec. 5–10, 2010, pp. 1052–1056.
19 J. Vucic, C. Kottke, and S. Nerreter, “230
Mbit/s via a wireless visible light link based
on OOK modulation of phosphorescent
white LEDs,” in Proc. Optical Fiber
Communication Conference and Exposition
and the National Fiber Optic Engineers
Conference (OFC/NFOEC) 2010 (San
Diego, CA), Mar. 21–25, 2010, pp. 1–3.
20 J. Vucic, C. Kottke, S. Nerreter, K. Langer,
and J. W. Walewski, “513 Mbit/s visible
light communications link based on
DMT-modulation of a white LED,” J.
Lightw. Technol., vol. 28, no. 24, pp.
3512–3518, Dec. 2010.
21 A. M. Khalid, G. Cossu, R. Corsini,
P. Choudhury, and E. Ciaramella, “1-Gb/s
transmission over a phosphorescent white
LED by using rate-adaptive discrete
multitone modulation,” IEEE Photon. J.,
vol. 4, no. 5, pp. 1465–1473, Oct. 2012.
22 F. M. Wu, C. T. Lin, and C. C. Wei,
“1.1-Gb/s white-LED-based visible light
communication employing carrier-less
amplitude and phase modulation,” IEEE
Photon. Technol. Lett., vol. 24, no. 19, pp.
1730–1732, Oct. 2012.
23 A. Azhar, T. Tran, and D. O’Brien, “A
gigabit/s indoor wireless transmission
using MIMO-OFDM visible-light
communications,” IEEE Photon. Technol.
Lett., vol. 25, no. 2, pp. 171–174, Jan. 2013.
24 H. Li, X. Chen, B. Huang, D. Tang, and
H. Chen, “High bandwidth visible light
communications based on a
post-equalization circuit,” IEEE Photon.
Technol. Lett., vol. 26, no. 2, pp. 119–122,
Jan. 2014.
25 J. McKendry, R. Green, and A. Kelly,
“High speed visible light communications
using individual pixels in a micro light
emitting diode array,“ IEEE Photon.
Technol. Lett., vol. 22, no. 18, pp.
1346–1348, Sep. 2010.
26 J. Vucic, C. Kottke, K. Habel, and
K. D. Langer, “803 Mbit/s visible light
WDM link based on DMT modulation of a
single RGB LED luminary,” in Proc.
Optical Fiber Communication Conference
and Exposition and the National Fiber
Optic Engineers Conference
(OFC/NFOEC) 2011 (Los Angeles, CA),
Mar. 6–10, 2011, pp. 1–3.
27 G. Cossu, A. M. Khalid, P. Choudhury,
R. Corsini, and E. Ciaramella, “Long
distance indoor high speed visible light
communication system based on RGB
LEDs,” in Proc. Asia Communications and
Photonics Conference (ACP) 2012
(Guangzhou, China), Nov. 7–10, 2012, pp.
1–3.
28 G. Cossu, A. M. Khalid, P. Choudhury,
R. Corsini, and E. Ciaramella, “2.1 Gbit/s
visible optical wireless transmission,” in
Proc. European Conference and Exhibition
on Optical Communication (ECOC) 2012
(Amsterdam, Netherlands), Sep. 16–20,
2012, pp. 1–4.
29 G. Cossu, A. M. Khalid, P. Choudhury,
R. Corsini, and E. Ciaramella, “3.4 Gbit/s
visible optical wireless transmission based
on RGB LED,” Opt. Exp., vol. 20, no. 26,
pp. B501–B506, Dec. 2012.
30 Y. Wang, R. Li, Y. Wang, and Z. Zhang,

15
“3.25-Gbps visible light communication
system based on single carrier frequency
domain equalization utilizing an RGB
LED,” in Proc. Optical Fiber
Communications Conference and
Exhibition (OFC) 2014 (San Francisco,
CA), Mar. 9–13, 2014, pp. 1–3.
31 F. M. Wu, C. T. Lin, and C. C. Wei,
“3.22-Gb/s WDM visible light
communication of a single RGB LED
employing carrier-less amplitude and phase
modulation,” in Proc. Optical Fiber
Communication Conference and Exposition
and the National Fiber Optic Engineers
Conference (OFC/NFOEC) 2013
(Anaheim, CA), Mar. 17–21, 2013, pp. 1–3.
32 Y. Wang, Y. Wang, N. Chi, J. Yu, and
H. Shang, “Demonstration of 575-Mb/s
downlink and 225-Mb/s uplink
bi-directional SCM-WDM visible light
communication using RGB LED and
phosphor-based LED,” Opt. Exp., vol. 21,
no. 1, pp. 1203–1208, Jan. 2013.
33 K. Cui, J. Quan, and Z. Xu, “Performance
of indoor optical femtocell by visible light
communication,” Opt. Commun., vol.
298–299, pp. 59–66, Jul. 2013.
34 X. Li, F. Jin, R. Zhang, J. Wang, Z. Xu, and
L. Hanzo, “Users ﬁrst: User-centric cluster
formation for interference-mitigation in
visible-light networks,” IEEE Trans. Wirel.
Commun., vol. 15, no. 1, pp. 39–53, Jan.
2016.
35 F. Wang, Z. Wang, C. Qian, L. Dai, and
Z. Yang, “MDP-based vertical handover
scheme for indoor VLC-WiFi systems,” in
Proc. OptoElectronics and
Communications Conference (OECC) 2015
(Shanghai, China), Jun. 28–Jul. 2, 2015,
pp. 1–3.
36 P. Manousiadis, H. Chun, and
S. Rajbhandari, “Demonstration of 2.3 Gb/s
RGB white-light VLC using polymer based
colour-converters and GaN micro-LEDs,”
in Proc. IEEE Summer Topicals Meeting
Series (SUM) 2015 (Nassau, Bahamas), Jul.
13–15, 2015, pp. 222–223.
37 A. Sewaiwar, P. P. Han, and Y. H. Chung,
“3-Gbit/s Indoor visible light
communications using optical diversity
schemes,” IEEE Photon. J., vol. 7, no. 6, p.
7904609, Dec. 2015.
38 C. He, T. Q. Wang, and J. Armstrong,
“Performance of optical receivers using
photodetectors with diﬀerent ﬁelds of view
in a MIMO ACO-OFDM system,” J.
Lightw. Technol., vol. 33, no. 23, pp.
4957–4967, Dec. 2015.
39 Y. Wang, L. Tao, X. Huang, J. Shi, and
N. Chi, “8-Gb/s RGBY LED-based WDM
VLC system employing high-order CAP
modulation and hybrid post equalizer,”
IEEE Photon. J., vol. 7, no. 6, p. 7904507,
Dec. 2015.
40 Q. Wang, C. Qian, X. Guo, Z. Wang,
D. Cunningham, and I. White, “Layered
ACO-OFDM for intensity-modulated
direct-detection optical wireless
transmission,” Opt. Exp., vol. 23, no. 9, pp.
12382–12393, May 2015.
41 C. Gong, S. Li, Q. Gao, and Z. Xu, “Power
and rate optimization for visible light
communication system with lighting
constraints,” IEEE Trans. Signal Process.,
vol. 63, no. 16, pp. 4245–4256, Aug. 2015.
42 Q. Gao, R. Wang, Z. Xu, and Y. Hua,
“DC-informative joint color-frequency
modulation for visible light
communications,” J. Lightw. Technol., vol.
33, no. 11, pp. 2181–2188, Jun. 2015.
43 Q. Gao, C. Gong, S. Li, and Z. Xu,
“DC-informative visible light
communications under lighting
constraints,” IEEE Wirel. Commun., vol.
22, no. 2, pp. 54–60, Apr. 2015.
44 X. Liu, C. Gong, S. Li, and Z. Xu, “Signal
characterization and receiver design for
visible light communication under weak
illuminance,” IEEE Commun. Lett., vol. 20,
no. 7, pp. 1349–1352, Jul. 2016.
45 H. Chen, C. Wu, H. Li, X. Chen, Z. Gao,
S. Cui, and Q. Wang, “Advances and
prospects in visible light communications,”
J. Semicond., vol. 37, no. 1, p. 011001, Jan.
2016.
46 D. C. O’Brien, G. Faulkner, H. L. Minh,
O. Bouchet, M. E. Tabach, M. Wolf,
J. W. Walewski, S. Randel, S. Nerreter,
M. Franke, K. D. Langer, J. Grubor, and
T. Kamalakis, “Home access networks
using optical wireless transmission,” in
Proc. IEEE International Symposium on
Personal, Indoor and Mobile Radio
Communications (PIMRC) 2008 (Cannes,
France), Sep. 15–18, 2008, pp. 1–5.
47 V. Jungnickel, M. Uysal, N. Seraﬁmovski,
www.ebook3000.com

16
T. Baykas, D. O’Brien, E. Ciaramella,
Z. Ghassemlooy, R. Green, H. Haas,
P. A. Haigh, V. P. G. Jimenez,
F. Miramirkhani, M. Wolf, and
S. Zvanovec, “A European view on the next
generation optical wireless communication
standard,” in Proc. IEEE Conference on
Standards for Communications and
Networking (CSCN) 2015 (Tokyo, Japan),
Oct. 28–30, 2015, pp. 106–111.
48 H. Parikh, J. Chokshi, N. Gala, and
T. Biradar, “Wirelessly transmitting a
grayscale image using visible light,” in
Proc. International Conference on
Advances in Technology and Engineering
(ICATE) 2013 (Mumbai, India), Jan.
23–25, 2013, pp. 1–6.
49 C. W. Chow, C. H. Yeh, Y. F. Liu, and
Y. Liu, “Improved modulation speed of
LED visible light communication system
integrated to main electricity network,”
Electron. Lett., vol. 47, no. 15, pp.
867–868, Jul. 2011.
50 M. Kavehrad, “Sustainable energy-eﬃcient
wireless applications using light,” IEEE
Commun. Mag., vol. 48, no. 12, pp. 66–73,
Dec. 2010.
51 N. Bardsley et al., “Solid-state lighting
research and development: Multi-year
program plan,” U.S. Dept. Energy,
Washington, DC, USA, Tech. Rep., 2014,
[online],
http://www1.eere.energy.gov/buildings
/ssl/techroadmaps.html.
52 W. Huang, P. Tian, and Z. Xu, “Design and
implementation of a real-time CIM-MIMO
optical camera communication system,”
Opt. Exp., vol. 24, no. 21, pp.
24567–24579, Oct. 2016.
53 J. Hu, C. Gong, and Z. Xu, “Demonstration
of a robot controlling and positioning
system based on visible light,” in Proc.
International Conference on Wireless
Communications & Signal Processing
(WCSP) 2016 (Yangzhou,China), Oct.
13–15, 2016, pp. 1–6.
54 K. Cui, G. Chen, Z. Xu, and R. D. Roberts,
“Traﬃc light to vehicle VLC channel
characterization,” Appl. Opt., vol. 51, no.
27, pp. 6594–6605, Sep. 2012.
55 T. Yamazato, I. Takai, H. Okada, T. Fujii,
T. Yendo, S. Arai, M. Andoh, T. Harada,
K. Yasutomi, K. Kagawa, and S. Kawahito,
“Image-sensor-based visible light
communication for automotive
applications,” IEEE Commun. Mag., vol.
52, no. 7, pp. 88–97, Apr. 2014.
56 T. Yamazato, M. Kinoshita, S. Arai,
E. Souke, T. Yendo, T. Fujii, K. Kamakura,
and H. Okada, “Vehicle motion and pixel
illumination modeling for image sensor
based visible light communication,” IEEE
J. Sel. Area. Commun., vol. 33, no. 9, pp.
1793–1805, Sep. 2015.
57 Y. Goto, I. Takai, T. Yamazato, H. Okada,
T. Fujii, S. Kawahito, S. Arai, T. Yendo,
and K. Kamakura, “A new automotive VLC
system using optical communication image
sensor,” IEEE Photon. J., vol. 8, no. 3, p.
6802716, Jun. 2016.
58 IEEE Std. 802.15.7-2011, Part 15.7:
Short-Range Wireless Optical
Communication Using Visible Light, Sep.
2011.
59 “The IEEE 802.15.7r1 Study Group,”
[online], http://www.ieee802.org/15/.
60 S. H. Yu, O. Shih, H. M. Tsai,
N. Wisitpongphan, and R. D. Roberts,
“Smart automotive lighting for vehicle
safety,” IEEE Commun. Mag., vol. 51,
no. 12, pp. 50–59, Dec. 2013.
61 M. Uysal, F. Miramirkhani,
O. Narmanlioglu, T. Baykas, and
E. Panayirci, “IEEE 802.15.7r1 reference
channel models for visible light
communications,” IEEE Commun. Mag.,
vol. 55, no. 1, pp. 212–217, Jan. 2017.
62 S. Arnon, Visible Light Communication,
Cambridge University Press, 2015.

17
2
Visible Light Communications: Channel and Capacity
In this chapter, the channel and capacity of visible light communication (VLC) are in-
troduced. Speciﬁcally, the characteristics of light emitting diode (LED) as the trans-
mitter and photodiode as the receiver are described in Section 2.1. When LED is
employed for lighting and communication simultaneously, its nonlinearity and light-
ing constraints are investigated in Section 2.2. Besides, absorption coeﬃcient, quan-
tum eﬃciency, and responsivity of the photodiode are demonstrated in Section 2.3.
Furthermore, diﬀerent propagation links between the transmitter and the receiver are
analyzed in Section 2.4. Since the dominant noise might be diﬀerent in various appli-
cation scenarios, three optical wireless channels are addressed including free-space
optical intensity channel, discrete-time Poisson channel, and improved free-space
intensity channel in Sections 2.5 and 2.6. Considering there exist no analytic ex-
pressions of the channel capacity, the state-of-the-art upper and lower bounds are
presented in Section 2.6 as well.
2.1
LED characteristics
One of the ﬁrst red LEDs was developed in 1962 based on GaAsP [1]. Compared
to conventional lighting sources such as ﬂuorescent and incandescent lights, LEDs
have many advantages including energy eﬃciency, light density, lifetime, and reli-
ability. Beneﬁting from the reﬁnement of III-V alloy and the development of the
epitaxy methods, LEDs have gained signiﬁcant performance improvement over the
last ﬁfty years. The eﬃciency of commercial LEDs has been dramatically increased
from 0.1 lm/W to a level that is above 100 lm/W. Currently, LEDs can emit the light
covering all visible spectrum from short wavelength (i.e., violet) to long wavelength
(i.e., red). As a result, LEDs have been widely applied in our daily lives, such as
general lighting, traﬃc lights, and ﬂat panel display. The market share of LEDs in
global commercial lighting is continuously growing and the revenue from commer-
cial LEDs sales would exceed 20 billion US dollars in the coming years. Although
the price of LEDs is relatively higher than conventional light sources at present, it is
foreseeable that the commercialization of LED associated with the advancement of
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.
www.ebook3000.com

18
the fabrication technique would further reduce their costs.
(a) Pc-LED
(b) Multi-chip LED
(c) OLED
(d) μLED
Figure 2.1 Diﬀerent LED types.
Until now, there are various types of LEDs such as phosphor-converted LED (pc-
LED), multi-chip LED, organic LED (OLED), and micro LED (μLED), which are
shown in Fig. 2.1. Pc-LED and multi-chip LED are two common types of white LEDs
for lighting, which use two or more diﬀerent wavelength lights to generate the white
light. In pc-LED packages, one or more visible light-emitting phosphors are coat-
ed on an LED chip emitting short-wavelength light. The pc-LEDs employ some of
the short-wavelength light to pump the phosphors and produce long-wavelength light
while the rest of the short-wavelength light is leaked out. By mixing these diﬀerent
wavelength lights together, the white light could be generated. Typical commercial
pc-LEDs utilize the cerium doped yttrium aluminum garnet (Ce:YAG) phosphor to
produce the yellow light and mix it with the blue light emitted by the gallium nitride
based LED chip [2]. Due to the development of modern manufacturing technology,
the luminous eﬃcacy of pc-LED has been improved to above 150 lm/W [3]. How-
ever, the intrinsic modulation bandwidth of pc-LED is limited to several MHz due to
the slow relaxation time of the phosphor [4]. On the other hand, multi-chip LEDs ex-

19
ploit three or more LED chips to emit diﬀerent monochromatic lights and mix them
together according to the predeﬁned ratio to produce the white light, i.e., red-green-
blue (RGB) LEDs. Multi-chip LEDs can provide variable color points and control
the white light dynamically. The color rendering of mutli-chip LEDs is excellent
(color rendering index > 95). With the help of external detectors including thermal,
electrical or optical sensors, the undesirable high variability in the color point can be
reduced considerably. Although multi-chip LEDs are more complex and expensive,
their intrinsic modulation bandwidth is several times larger than that of pc-LEDs [5].
The basic structure of OLEDs is thin-ﬁlm organic semiconductors sandwiched be-
tween the anode and the cathode. The luminescence mechanism for OLEDs is diﬀer-
ent from inorganic LEDs. In the recombination of electron-hole pair, a high-energy
molecular state called singlet or triplet exciton is formed. The exciton would emit the
light and its wavelength is related to the emitting layer material rather than the band
gap. Organic LEDs based on small-molecular or polymer (SMOLEDs or PLEDs)
are usually used in ﬂat panel display. Compared to liquid crystals, OLEDs possess
several advantages in energy eﬃciency, contrast ratio, refresh rate, and the capacity
of vibrant color rendering.
μLED is an emerging type of LEDo that can be used in self-emissive micro-displays,
multi-site photostimulation and hybrid inorganic/organic devices. Unlike liquid crys-
tal displays, μLED displays are self-luminescent and power-eﬃcient. Besides, they
can support wide-angle viewing without color shift and degradation. Diﬀerent from
the organic materials of OLEDs which are chemically unstable, μLEDs inherit the
advantages of inorganic LEDs and have a longer lifetime. Usually, μLED display in-
tegrates massive yet small LED elements. The size of each element is only μm×μm
or smaller. The common method of fabricating μLED arrays is to arrange several
microchip elements onto a substrate, and the elements of μLED are addressed indi-
vidually, which increases the layout complexity. An alternative solution is to address
the elements either row by row or column by column.
2.1.1
Operation principles
Common LEDs are generally based on the theory of p-n junction, a boundary be-
tween two types of semiconductor materials (i.e., p-type and n-type). For the p-type
region, the holes are major carriers and the electrons are minor carriers. While for
the n-type region, the electrons are major carriers and the holes are minor carriers.
Without a bias voltage, the holes as the major carriers in the p-type region would
diﬀuse into the n-type region and recombine with the electrons, leaving positive-
ly charged ions behind near the boundary of the n-type region. On the other side,
the electrons in the n-type region would diﬀuse into the p-type region and recom-
bine with the holes, leaving the negatively charged ions behind near the boundary of
the p-type region. As a result, a built-in electric ﬁeld known as diﬀusion voltage is
formed in the boundary between the p-type region and the n-type region, which is
www.ebook3000.com

20
Figure 2.2 p-n junction under an equilibrium condition.
expressed as
VD = kT
q ln NAND
n2
i
,
(2.1)
where q is the elementary charge, k is the Boltzmann constant, T is the absolute
temperature, NA and ND are the acceptor concentration at p-type region and the
donor concentration at n-type region, respectively, and ni is the intrinsic carrier con-
centration of the semiconductor. The built-in voltage would obstruct the diﬀusion
of the major carriers from the p-type and n-type regions and an equilibrium state is
reached, which is illustrated in Fig. 2.2. The built-in space charge region between
p-type region and n-type region is also called the depletion zone.
As shown in Fig. 2.3, when a forward bias voltage V is loaded on the p-n junction,
where positive electrode is connected to p-type region and negative electrode is con-
nected to n-type region, the holes in p-type region and the electrons in n-type region
are injected into the opposite side, resulting in the width decrease of the depletion
zone, which can be approximately given by
WD ≈

2ϵ
q
NA + ND
NAND
(VD −V ),
(2.2)
where ϵ is the dielectric permittivity of the semiconductor. If the depletion zone is
thin enough, the electrons would cross the p-n junction into the neutral p-type region
and recombine with the holes. Due to the energy/band gap between the electrons
in the conduction band and the holes in the valence band, the recombination of the
electron-hole pair could cause a photon emission. The energy/band gap (Eg) between
the energy at the top of the valence band (Ev) and that at the bottom of the conduction
band (Ec) can be expressed as
Eg = Ec −Ev.
(2.3)

21
Figure 2.3 p-n junction under forward bias.
Here, the energy of the electrons in the conduction band is given by
Ee = Ec + h2ˆk2
2m∗
e
,
(2.4)
and the energy of the holes in the valence band is given by
Eh = Ev −h2ˆk2
2m∗
h
,
(2.5)
where h is Planck’s constant, ˆk is the wavenumber, m∗
e and m∗
h are the electron
and hole eﬀective masses, respectively. Since the energy of the electrons in the con-
duction band is higher than the energy of the holes in the valence band, during the
spontaneous recombination of the electron-hole pair, the emitted photon energy can
be expressed as
hv = Ee −Eh = Eg + h2ˆk2
2m∗
r
,
(2.6)
where m∗
r is the reduced eﬀective mass, which satisﬁes
1
m∗
r = ( 1
m∗
e +
1
m∗
h ).
Since diﬀerent materials have distinct band gaps, the emitted lights could have
diﬀerent wavelengths and present diﬀerent colors. For example, the band gap of
InGaP is ∼1.9 eV (∼650 nm, deep red). For AlxGa1−xN, its band gap varies from
∼0.7 eV (∼1800 nm, infrared) to ∼3.4 eV (∼365 nm, UV-A).
2.1.2
LED nonlinearity
For an ideal LED system model, the input (forward bias) is linear to the output (emit-
ted optical power). In practice, LEDs always suﬀer from nonlinear distortion, which
would degrade the system performance considerably. The classical Shockley ideal
www.ebook3000.com

22
diode equation was proposed in the early 1950s to describe this nonlinearity eﬀect
between the current and the voltage, which is given by [6]
I = IS(eqV/kT −1),
(2.7)
where IS is the saturation current, which is expressed as
IS = qA(

Dp
τp
n2
i
NA
+

Dn
τn
n2
i
ND
),
(2.8)
where A is the junction area, Dp and Dn denote the electron and hole diﬀusion con-
stants, and τp and τn are the minority carrier lifetimes of electrons and holes. Since
the diﬀusion constants, the minority carrier lifetimes, and the intrinsic carrier con-
centration are all temperature-dependent, the saturation current is not constant for a
speciﬁc LED.
As forward voltage is typically much larger than thermal voltage (i.e., kT
e ), the
Shockley ideal diode equation can be simply approximated as
I = ISeqV/kT .
(2.9)
In addition, the current-optical power (I–P) conversion is also nonlinear, which
can be modeled as either memory-less model or memory model. A typical memory-
less LED model is a polynomial model. Based on Taylor series, a polynomial ap-
proximation for the nonlinear transfer function can be obtained as
P =
N

n=0
αn(I −IDC)n,
(2.10)
where αn is the coeﬃcient of the nth order power of the nonlinear transfer function
and IDC denotes the direct current (DC). As the nonlinear transfer function is mod-
eled to be static, the polynomial approximation is only valid when the modulation
frequency is below 3-dB bandwidth of the LEDs [7].
Since an LED’s capacitance and conductance are frequency-dependent, the poly-
nomial model is not capable of describing the dynamics and memory eﬀects of the
LEDs accurately. Instead, a Volterra model, combining the nonlinearity and the
memory eﬀects together, is employed. The current-optical power conversion based
on Volterra series for the continuous-time system can be expressed as
P(t) = P0 +
∞

n=1
1
n!Pn(t),
(2.11)
where P0 is DC component of the optical power, and Pn(t) is the nth order compo-
nent of P(t), which can be further detailed as
Pn(t) =
 +∞
−∞
· · ·
 +∞
−∞
hn(τ1, ..., τn)
n

k=1
I(t −τk)dτk,
(2.12)

23
where hn(τ1, ..., τn) is the nth order Volterra Kernel of the nonlinear system, which
can be obtained from the measurement data [8]. The nth order Volterra Kernel
hn(τ1, ..., τn) can be regarded as the higher-order impulse response of the nonlinear
system.
For the discrete-time case, the nth order component Pn(m) can be expressed as
Pn(m) =
+∞

k1=0
· · ·
+∞

kn=0
hn(k1, ..., kn)
n

j=1
I(m −kj).
(2.13)
In practice, the series is truncated, i.e., the order of (2.12) and (2.13) is set to be
a speciﬁc value instead of the inﬁnity. The drawback of the Volterra model comes
from its high complexity in estimating the Volterra coeﬃcients.
2.2
LED lighting constraints
LED lighting constraints are crucial to modulation and signal processing for VLC
systems, which include dimming control, chromaticity control, and ﬂicker-free com-
munication.
2.2.1
Dimming control
To describe the light brightness perceived by human eyes, spectral luminous eﬃ-
ciency function V (λ) is deﬁned by International Commission on Illumination (CIE),
which indicates that the human visual system is more sensitive to the light with mid-
dle wavelengths compared to either short or long wavelengths. The perceived light
power is measured as luminous ﬂux, which is given by [9]
Φ = Km

λ
P(λ)V (λ)dλ,
(2.14)
where Km is a constant of 683 lm/W to convert irradiance to illuminance and P(λ)
is the power spectral distribution. Accordingly, the luminous intensity is deﬁned as
It = dΦ
dΩ,
(2.15)
where Ω denotes the spatial angle.
Since LEDs are speciﬁc semiconductor devices that emit incoherent light when
driven by current, the information to be conveyed is usually modulated into the in-
stantaneous optical power of the LEDs. In indoor VLC systems, the brightness of
LED light should be dimmed for the convenience of illumination. Usually, the driv-
er circuit has a set of transistors that combine the dimming signal with the biased
modulating signal and switch the LEDs.
www.ebook3000.com

24
Figure 2.4 VPPM signal with 25% pulse width.
In recent times, VLC is mainly aimed at supporting high-rate transmission. How-
ever, lighting quality and power consumption, which are also crucial aspects of VLC
systems, had mostly been overlooked. The lighting requirements for indoor scenar-
ios are generally application speciﬁc. Bedroom/living room might require lighting
levels as low as 1% of the maximum illumination for aesthetic and comfort purposes.
An illuminance level of 300 lux (lumen per square meter) is preferred for reading and
writing purpose, whereas 30 lux is suﬃcient for computer task [10]. Other locations
such as corridors and stairwells have a ﬂexible dimming requirement where life time
and energy-saving are the primary considerations of the LEDs. The brightness of
an LED is adjusted by controlling the forward current, which can be classiﬁed into
analog dimming, digital dimming, and hybrid dimming. Analog dimming adjusts
the current amplitude linearly to the radiated optical ﬂux. In digital dimming, pulse
width modulation (PWM) scheme is usually adopted, where the time period (T) of
the PWM signal is ﬁxed and the duty cycle varies proportionally to the required dim-
ming level. Hybrid dimming combines both analog dimming and digital dimming
for further reduction of perceived chromaticity shifts [11].
IEEE 802.15.7 standard uses both on-oﬀkeying (OOK) and variable pulse posi-
tion modulation (VPPM) for VLC links. OOK dimming can be realized by]`fq)
sting the light intensity of both “on” ]j` “oﬀ” status, or the light intensity could
remain unchanged whereby the average duty cycle of the waveform can be adjusted
by the insertion of “compensation” time into the modulation waveform. During the
“compensation” time, the light source is fully turned on or oﬀwhich allows a DC
component to be added to the waveform. VPPM changes the duty cycle of each op-
tical symbol based on the required dimming level. It is similar to 2-PPM when the
duty cycle is 50%. The logic zero and logic one symbols are pulse width modulated
depending on the dimming duty cycle requirements. The pulse width ratio of pulse
position modulation (PPM) can be adjusted to produce the required duty cycle for
supporting dimming. Figure 2.4 shows an example waveform indicating how VPPM
can attain a 25% dimming duty cycle, where both logic zero and logic one have a
25% pulse width [12].

25
2.2.2
Chromaticity control
When multi-chip LEDs are used, chromaticity is a critical issue which presents the
quality of a color regardless of its luminance. Since human color perception is deter-
mined by three types of cones in the retina of human eyes, which are sensitive to the
light of long, middle, and short wavelengths, respectively, three tristimulus values
(R, G, B) associated with their color matching functions (¯r(λ), ¯g(λ), and ¯b(λ)) are
utilized to describe any color perception based on red/green/blue primaries. Howev-
er, some portions of these color matching functions might be negative. As a result,
a linear transformation is performed to obtain alternative positive tristimulus values
(X, Y, Z) and color matching functions (¯x(λ), ¯y(λ), and ¯z(λ)), which are expressed
as
X = Km

λ
P(λ)¯x(λ)dλ,
(2.16a)
Y = Km

λ
P(λ)¯y(λ)dλ,
(2.16b)
Z = Km

λ
P(λ)¯z(λ)dλ.
(2.16c)
Then, the chromaticity of the color can be represented by two coordinate points x
and y in the CIE 1931 color space chromaticity diagram, which are deﬁned as
x =
X
X + Y + Z ,
(2.17a)
y =
Y
X + Y + Z .
(2.17b)
Good design of VLC systems shall guarantee that there is no color mismatching
from human eyes’ point of view [13].?olor shift keying (CSK), already adopted in
the IEEE 802.15.7 standard, is an instance that considers the chromaticity control in
signal modulation. CSK is similar to frequency shift keying whereby the bit patterns
are encoded according to diﬀerent color combinations [12]. The modulation scheme
relies on the x-y color coordinates in the CIE 1931 color space chromaticity diagram
to realize color matching. Speciﬁcally, in order to provide various colors for convey-
ing the data information, the IEEE 802.15.7 standard breaks the spectrum into seven
color bands to support multiple LED color choices for visible light communications.
Figure 2.5 indicates the center of the seven color bands on the x-y color coordinates
deﬁned by CIE 1931 where the 3-bit values indicate each of the seven color bands.
For example, in 4-CSK (two bits per symbol), the light source is wavelength keyed
such that one of four possible wavelengths (colors) is transmitted per bit pair combi-
nation. Diﬀerent wavelengths (colors) are generated by the three color light sources
out of the seven color bands. The three vertices of the CSK constellation triangle
are decided by the center wavelength of the three color bands on the x-y color co-
ordinates. The ﬁnal output color (e.g., white) is guaranteed by the color coordinates
shown in Fig. 2.5.
www.ebook3000.com

26
Figure 2.5 CIE 1931 x-y color coordinates, where x and y are the chromaticity values.
The outer curve is the spectral locus with wavelengths shown in nm. The three-digit values
refer to the center wavelength of the seven bands deﬁned in the IEEE 802.15.7 standard.
2.2.3
Flicker-free communication
Flicker is deﬁned as the periodic or non-periodic output power (brightness) ﬂuctua-
tion which human eyes can perceive. It can fatigue the eyes quickly and deteriorate
the eye sight if they are exposed to a noticeable ﬂicker for a long period of time.
According to statistical analysis, about 1 in 4,000 people are highly susceptible to
ﬂashing lights cycling in the range from 3 to 70 Hz. Less well known is the fact that
long time exposure to higher frequency and unintentional ﬂicker in the range from
70 to 160 Hz could also cause malaise, headaches, and visual impairments. Unless
human beings stay in natural daylight, they are likely to be exposed to such kind of
ﬂicker, since ﬂuorescent lamps or LEDs are subject to ﬂicker. Accordingly, many
eﬀorts have been carried out to design good-quality and fast-switching LED drivers
in order to reduce the negative ﬂicker eﬀect.
Apparently, ﬂicker mitigation technology is crucial in VLC systems. To facili-
tate ﬂicker-free VLC, it is important to have a DC-free signal so that the average
light intensity does not change. To achieve DC-free properties, DC-free modula-
tion codes can be employed. A simple and commonly used modulation code is the
binary Manchester code, where bit 1 is converted into symbols [+1,-1] and bit -1
is converted into symbols [-1,+1]. Flicker mitigation technology is classiﬁed into

27
intra-frame ﬂicker mitigation and inter-frame ﬂicker mitigation in the IEEE 802.15.7
standard [12]. Intra-frame ﬂicker mitigation aims to eliminate the ﬂicker within the
transmission of a data frame. For OOK and VPPM modulations, it is implemented
by using the dimmed OOK mode and run length limited (RLL) line coding. RLL line
codes are adopted to avoid long runs of 1’s and 0’s which could potentially cause ﬂick-
er and clock recovery problems. Various RLL line codes such as Manchester, 4B6B,
and 8B10B codes are deﬁned in the IEEE 802.15.7 standard, and provide tradeoﬀs
between coding overhead and ease of implementation. For CSK modulation, it is
implemented by ensuring constant average power across multiple light sources along
with scrambling and high optical clock rates. Inter-frame ﬂicker mitigation applies
to both data transmission and idle periods. While idling, visibility patterns or idle
patterns may be used to ensure that light emission by the VLC transmitters have the
same average brightness over adjacent maximum ﬂicker time period.
2.3
Photodiode characteristics
A photodiode is used as the optical receiver to convert the optical signal to the elec-
trical signal in visible light communications. When a photon with enough energy is
absorbed in the photodiode, an electron moves from the valence band to the conduc-
tion band, resulting in the generation of an electron-hole pair. In this process, the
energy of the photon hv should not be less than the energy gap between the valence
band and the conduction band Eg, i.e., hv ≥Eg.
Usually, the photodiode is driven by the reverse voltage, where the anode connects
to the negative terminal while the cathode connects to the positive terminal. If the
absorption occurs in the depletion zone, the built-in electric ﬁeld would impel the
separation of the electron-hole pairs. The holes would drift toward the anode and the
electrons drift toward the cathode. Consequently, the photocurrent is generated. The
reverse voltage can strengthen the built-in ﬁeld in the depletion zone to accelerate
the drift of the photon-induced carriers and enlarge the length of the depletion zone
as well as decrease the capacitance so that the response time is shortened.
Both direct-bandgap (InGaAs, GaAs, etc) and indirect-bandgap (Si, Ge, etc) semi-
conductors can be used for photodiodes. Compared to the indirect-bandgap semi-
conductors, direct-bandgap counterparts often have higher absorption coeﬃcients.
When absorbing the same amount of the light, the absorption region of the direct-
bandgap semiconductors is thinner than their indirect-bandgap counterparts. In prac-
tice, the materials such as Ge and InGaAs are chosen to fabricate the photodiodes for
receiving long-wavelength light (infrared spectral range). As for short-wavelength
light (200–1600 nm), the receiver material is preferred to be Si. Thus, Si-based pho-
todiodes are commonly used in VLC systems.
There are various types of photodiodes such as PN photodiode, PIN photodiode
and avalanche photodiode (APD). PN photodiode consists of a thin p-type, highly
doped layer and an n-type substrate. Its frequency response exhibits a double cutoﬀ:
the lifetime cutoﬀ(MHz) due to the lifetime of the carrier in the diﬀusion regions at p-
www.ebook3000.com

28
type and n-type sides, and the RC cutoﬀ(GHz) due to the transit time and capacitance
eﬀects. The performance of PN photodiode is usually limited by the carrier lifetime
with a maximum cutoﬀfrequency of 100–200 MHz.
Compared to PN photodiode, an additional intrinsic region is sandwiched between
the p-type region and the n-type region in PIN photodiode in order to improve the
frequency response and the high-frequency eﬃciency. In PIN photodiode, the de-
pletion region is much larger than the carriers’ diﬀusion region. As a result, the
photocurrent due to carrier diﬀusion at the p-type and n-type region can be ignored
and the cutoﬀfrequency is increased to the order of GHz. The frequency response
of PIN photodiode is limited by the photodiode capacitance and the transit time of
the carriers drifting through the depletion region.
As a highly sensitive semiconductor, APD utilizes the impact ionization process to
detect and amplify the current. In APDs, the photon-generated carriers produce more
electron-hole pairs by collision with bounded electrons, i.e., the impact ionization.
The photon-generated carriers occur in the generation region and the avalanche mul-
tiplication happens in the multiplication region. For conventional APDs, these two
regions are the same. While for a sperate absorption and multiplication APD (SAM-
APD), these two regions are physically separated. Compared to PIN photodiodes,
APD has higher sensitivity.
A. Absorption coeﬃcient
According to the Beer-Lambert law, the received radiant ﬂux Φr in the photodiodes
is given by
Φr = Φt · e−τ,
(2.18)
where Φt is the radiant ﬂux of the light penetrating into the surface of the photodiode
and τ is the optical depth, which is deﬁned as
τ =
 d
0
α(z)dz,
(2.19)
where d is the thickness of the photodiode that the light goes through and α(·) is
the attenuation/absorption coeﬃcient, which describes how far the light with specif-
ic wavelength penetrates into the photodiode before it is totally absorbed. A high-
er absorption coeﬃcient is usually in favor of the improvement of the photodiode’s
quantum eﬃciency.
If the attenuation is uniformly distributed, (2.18) can be rewritten as
Φr = Φt · e−αd.
(2.20)
At this time, the coeﬃcient α is also referred to as the linear attenuation coeﬃcient,
which is related to the photodiode material as well as the wavelength of the light.
B. Quantum eﬃciency

29
Quantum eﬃciency describes the photodiode’s sensitivity to the light. Two dif-
ferent types of quantum eﬃciency are often discussed, which are internal quantum
eﬃciency and external quantum eﬃciency, respectively. The internal quantum eﬃ-
ciency ηi is deﬁned as the ratio of the number of the charge carriers (corresponding to
the photocurrent) to the number of the photons (corresponding to the light absorbed
by the photodiode), i.e.,
ηi =
Ipc/q
(Φt −Φr)/hv ,
(2.21)
where Ipc is the photocurrent.
One typical internal quantum eﬃciency model for the silicon photodiode is ex-
pressed as [14]
ηi = c + (1 −c)
αD
(1 −e−αD) −Wne−αWp,d
αL2
,
(2.22)
where c denotes the collection eﬃciency at the silicon-silicon dioxide interface, D
is the depth where the collection eﬃciency is unity, Wp,d is the width of the p-type
region and the depletion region, Wn is the width of the n-type region and L deﬁnes
the depth at which the minority carriers diﬀuse in the n-type region. In (2.22), the
ﬁrst two terms describe the collection eﬃciency from the oxide interface to the point
Wp,d while the third term is an approximation of the collection eﬃciency in the n-type
region with a uniform dopant concentration.
In addition, the external quantum eﬃciency is deﬁned as the ratio of the number of
the charge carriers (corresponding to the photocurrent) to the number of the photons
(corresponding to the incident light Φi at the surface of the photodiode), i.e.,
ηe = Ipc/q
Φi/hv .
(2.23)
C. Responsivity
Similar to the quantum eﬃciency, responsivity is deﬁned in units of amperes per
watt of radiant power (A/W), which depends on the wavelength of the incident light.
The conversion from the external quantum eﬃciency to the responsivity is given by
R = ηe
q
hv .
(2.24)
2.4
Propagation links
Based on whether there exists a line-of-sight (LOS) path between the transmitter
and the receiver, the propagation links can be classiﬁed into two categories: LOS
link and non-line-of-sight (NLOS) link. Since the power of the LOS path dominates
and the power of the reﬂected paths is much lower, an LOS wireless system usually
www.ebook3000.com

30
has a higher power eﬃciency. However, the optical channel vulnerability is a tricky
problem. When the LOS path is blocked by moving objects, the system performance
would be rapidly deteriorated, even leading to communication interruption. While
for a NLOS wireless system, the lights radiated by the transmitter are reﬂected by the
surfaces of the ceiling or walls within a room. Compared to the LOS link scenarios,
multipath propagation improves the robustness of the NLOS link based VLC systems.
Even when barriers exist between the transmitter and the receiver, the signals via
reﬂected paths can still be detected.
(a) LOS/directed link
(b)
LOS/non-directed
link
(c) LOS/hybrid link 1
(d) LOS/hybrid link 2
(e) NLOS/directed link
(f) NLOS/non-directed
link
(g) NLOS/hybrid link 1
(h) NLOS/hybrid link 2
Figure 2.6 Classiﬁcations of the propagation links [15].
Considering the directionality of the transmitter and the receiver, the VLC propa-
gation links could be also classiﬁed into three categories: directed link, non-directed
link, and hybrid link. For the directed link, the transmitter and the receiver directly
point to each other with narrow semiangle and ﬁeld of view (FOV). Thus, the di-
rected link based system has a high power eﬃciency. While in the non-directed link,
both the transmitter and the receiver have wide semiangles for ease of use. As for
the hybrid link, the transmitter and the receiver have diﬀerent directionality (narrow
semiangle transmitter in combination with wide FOV receiver or wide semiangle
transmitter in combination with narrow FOV receiver). The classiﬁcations of these
propagation links are shown in Fig. 2.6.
In conventional radio frequency communications, multipath propagation could
cause the variation of the magnitude of the received electromagnetic signals and
inter-symbol interference. By contrast, VLC is usually free from multipath fading
because the physical detection area of the photodiode is much larger than the square
wavelength of the light. The inherent size of the photodiode could be treated as a two-
dimensional antenna array, which provides spatial diversity to eliminate the multipath
fading eﬀect. However, although multipath fading is neglected in VLC systems, time

31
spread due to multipath propagation is still an issue for signal detection, especially
for the NLOS link case.
2.4.1
LOS link
For most LEDs, the generalized Lambert law is applied, which indicates that the
radiant intensity is relevant to the cosine of the angle θ between the emitted light and
the normal to the LED surface. Thus, the radiant intensity can be expressed as [16]
R(θ) = m + 1
2π
cosm(θ)PLED,
(2.25)
where PLED is the total radiated power, which is given by
PLED =

λ
P(λ)dλ,
(2.26)
where P(λ) is the spectral power distribution and m is the order of Lambertian
emission, which depends on the semiangle at half illuminance of the LED Φ1/2, i.e.,
m = −
ln 2
ln cos Φ1/2
.
(2.27)
The coeﬃcient m+1
2π
ensures that the radiant intensity integration over the surface
of a hemisphere equals the total optical power.
When the distance is deﬁned as d, the irradiance can be given by
Ee(d) = R(θ)
d2 .
(2.28)
For the optical receiver, the detected optical power is proportional to the eﬀective
signal-collection area, which is given by
Ae(ψ) =

Af(ψ)g(ψ) cos(ψ),
if 0 ≤ψ ≤Ψc,
0,
if ψ > Ψc,
(2.29)
where ψ is the incident angle, A is the photodetector physical area, Ψc is the concen-
trator FOV, f(ψ) and g(ψ) denote the optical ﬁlter gain and the concentrator gain,
respectively. For a non-imaging concentrator, g(ψ) can be expressed as
g(ψ) =

n2
sin2(Ψc),
if 0 ≤ψ ≤Ψc,
0,
if ψ > Ψc,
(2.30)
where n is the internal refractive index. Thus the received optical power can be
obtained by
Pr = Ee(d)Ae(ψ).
(2.31)
www.ebook3000.com

32
For VLC channel, the frequency response is relatively ﬂat near DC and only the
LOS path is considered to calculate the DC gain. From (2.28) and (2.29), it can be
expressed as
HLOS =
 (m+1)A
2πd2
cosm(θ)f(ψ)g(ψ) cos(ψ),
if 0 ⩽ψ ⩽Ψc,
0,
if ψ > Ψc.
(2.32)
It can be observed from (2.32) that if photodetector physical area A, the optical ﬁl-
ter gain f(ψ) and the concentrator gain g(ψ) are ﬁxed, the DC gain depends on the
distance d between the transmitter and the receiver, the irradiation angle θ and the in-
cident irradiation angle ψ. If the VLC receiver is moving in the room, it is important
to adjust some of those factors to guarantee the system performance.
2.4.2
NLOS link
In the NLOS link case, the DC gain is calculated via the multiple reﬂections from
the surfaces of a room. The impulse response of multiple bounces is expressed as
h(t) =
∞

k=0
h(k)(t; P(λ)),
(2.33)
where k is the number of bounces. For the ith reﬂected path, the (i −1)th bounce
point is regarded as a virtual lighting source obeying the Lambert law and the ith
bounce point is treated as a virtual receiver. After k bounces, the impulse response
can be recursively calculated, which is given by [17]
h(k)(t; P(λ)) =
1
PLED

s
[L1L2 · · · Lk+1P (k)
n rect(ψk+1
Ψc
)×
δ(t −d1 + d2 + · · · + dk+1
c
)]dAs,
(2.34)
where dAs is a small reﬂection area, rect(·) is the rectangular function, i.e.,
rect(x) =

1,
if |x| ≤1,
0,
if |x| > 1,
(2.35)
δ(·) is the delta function, c is the light velocity, d1, d2, · · · , and dk+1 are the distance
of each path during k bounces, L1, L2, · · · , Lk+1 are the path loss/DC gain of each
path during k bounces, which are expressed as
L1 = (m + 1)Aref
2πd2
1
cosm(θ1) cos(ψ1),
(2.36)
L2 = Aref
πd2
2
cos(θ2) cos(ψ2),
(2.37)

33
...
Lk+1 =
APD
πd2
k+1
cos(θk+1)f(ψk+1)g(ψk+1) cos(ψk+1),
(2.38)
and P (k)
n
denotes the optcial power of the reﬂected light after k-bounces, which is
given by
P (k)
n
=

λ
P(λ)γ1(λ)γ2(λ) · · · γk(λ)dλ,
(2.39)
where γi(λ) is the spectral reﬂectance of the surface at the ith bounce.
When the spectral reﬂectance is assumed to be wavelength-independent, i.e.,
γ(λ) = γ, the DC gain based on the ﬁrst reﬂection is given by
H(1)
ref =

s
(m + 1)A
2π2d2
1d2
2
γ cosm(θ1) cos(θ2)f(ψ)g(ψ) cos(ψ1) cos(ψ2)dAs.
(2.40)
2.5
Noise in VLC systems
The noise existing in VLC systems can be classiﬁed into two categories: noise from
the light including the quantum noise (or photon ﬂuctuation noise) from the optical
signal itself,]j`phe background radiation noise from ambient light, and noise from
thereceiver devices such as dark current noise, thermal noise, and 1/f noise. Many
types of noise can be regarded as shot noise in the wireless optical link, such as dark
current noise, quantum noise, and background radiation noise. Speciﬁcally, dark
current noise is due to random generation of electrons and holes within the depletion
region without photon-induced excitation, which is signal-independent. Quantum
noise is produced by the random arrival rate of photons from the optical source,
which is signal-dependent. On the other hand, background radiation noise is caused
by the reception of the photons from ambient light, which is signal-independent and
can be modeled as being additive, white, and Gaussian due to its high intensity. For
many application scenarios, the received signal-to-noise ratio (SNR) is limited by
the background radiation noise, which is much stronger than the quantum noise from
the optical source as well as other noise sources.
Next, various noise types in VLC systems are detailed as below.
A. Quantum noise
Quantum noise or photon ﬂuctuation noise is caused by the discrete nature of the
photons from the optical source. When the optical power from the light source is
kept unchanged, the number of arrival photons is statistically constant during a long
www.ebook3000.com

34
period. However, in a short time interval, the number of photons follows a Poisson
distribution, i.e.,
P(n = k) = λk
k! e−λ,
k = 1, 2, · · · ,
(2.41)
where λ is the average number of arrival photons per interval and n is the number of
arrival photons in a given time interval.
Since intensity modulation is usually employed in VLC systems, the quantum noise
always appears to be shot noise, which has a one-sided power spectral density in unit
of A2/Hz as
σ2 = 2qipc,
(2.42)
where q is the electronic charge, ipc denotes the photocurrent and we have ipc =
RPLED, where R is the photodiode responsivity and PLED is the light source power.
B. Background radiation noise
Background radiation noise or ambient light noise is caused by the reception of
the photons from the environment. Ambient light sources include the sun, the sky,
incandescent lamps, and ﬂuorescent lamps. Background radiation noise is signal-
independent and can be modeled as being additive, white, and Gaussian due to its
high intensity. In the NLOS link case where a wide FOV receiver is employed, the
received SNR is limited by the background radiation noise that is much stronger than
the quantum noise from the optical source as well as other noise sources even with
the adoption of the optical ﬁlters.
When the spectral radiance Le (W·m−2·sr−1·Hz−1) is assumed to be independent
of the wavelength, the received background noise power can be expressed as [18]
Pbg = LeΩsAT0g(ψ)Bopt
cos(ψ)
cos(θ) ,
(2.43)
where Ωs is part of the FOV subtended by the background source at the receiver,
T0 is the transmittance of the atmosphere, and Bopt is the bandwidth of the optical
ﬁlter. From (2.43), the background noise power strongly depends on the FOV and
the optical bandwidth of the receiver, and its variance is given by
σ2
bg = 2qBpdRPbg,
(2.44)
where Bpd is the electrical bandwidth of the photodiode.
C. Thermal noise
Thermal noise or Jonson-Nyquist noise is caused by the random ﬂuctuation of
the charge carriers (usually electrons) in any conducting medium at a temperature
higher than the absolute zero temperature. The power spectral density of thermal
noise remains constant (“white”) in a wide frequency range up to the near-infrared

35
frequency. Considering the independent agitation of massive charge carriers, the
thermal noise obeys Gaussian distribution according to the central limit theorem.
The variance of the thermal noise in the noisy resistor in A2 · Hz−1 is given by
σ2
thermal = 4KT
RF
,
(2.45)
where RF is the resistance.
Thermal noise in the noisy resistor can be modeled as a voltage source (Veq =
√4KTRF) in series or a current source (Ieq =

4KT
RF ) in parallel with a noiseless
resistor with a resistance RF. In both cases, the sources generate the Gaussian white
noise.
D. 1/f noise
1/f noise is an intermediate between white noise and Brownian noise caused by
Brownian motion, whose power spectral density is given by
S1/f(f) = c
f α ,
(2.46)
where c is a constant and α denotes the exponent satisfying 0 < α < 2 (usually
close to 1). 1/f noise is not white and becomes strong at low frequencies.
E. Dark current noise
Dark current is an electric current, which exists in the photodiode even when there
is no incident light. The dark current in the p-n junction based devices consists of the
surface and bulk currents which are caused by the random generation of the electron-
hole pairs thermally or tunneling between the conduction band and the valence band.
Thus, it is related to the loaded bias voltage and photodiode temperature.
The dark current can be divided into two categories: the surface dark current and
the bulk current. The surface current contains the surface generation-combination
current and the surface leakage shunt current, while the bulk current is made of the
bulk diﬀusion current, the bulk generation-combination current and the bulk tun-
neling current. Since the dark current causes random ﬂuctuations of the average
photocurrent, it usually exhibits as shot noise with a variance of
σ2
d = 2qBpdid,
(2.47)
where id is the dark current.
2.6
Channel capacity
For intensity-modulated direct-detection (IM/DD)-based VLC systems, the classic
Shannon channel capacity formula is considered, i.e.,
C = log(1 + SNR).
(2.48)
www.ebook3000.com

36
However, it might not be suitable for actual optical wireless channels due to the
following reasons:
• In IM/DD-based VLC systems, the intensity/amplitude of the signal would de-
termine the voltage loaded on LEDs and the instantaneous emitted optical pow-
er. Thus, the signal is constrained to be nonnegative and real-valued. Moreover,
LEDs have a maximum permissible forward current, resulting in a limited maxi-
mum amplitude value of the signal. As a result, the transmitted signal is conﬁned
to be unipolar and amplitude-limited.
• Traditionally, if the electrical power of the signal is constrained, the signal follow-
ing a Gaussian distribution would approach Shannon channel capacity. However,
since LEDs are primarily used for illumination, the signal is subject to the average
optical power instead of the electrical power. When the electrical power constraint
is not applied, the input signal distribution to approach Shannon channel capacity
does not necessarily follow Gaussian distribution in optical wireless channels.
In recent years, the capacities for diﬀerent optical wireless channel models (e.g.,
free-space optical intensity channel, discrete-time Poisson channel, and improved
free-space optical intensity channel) have been investigated. Several capacity bounds
are derived based on three constraints:
1) The nonnegative constraint, which is illustrated as
P(x < 0) = 0;
(2.49)
2) The peak-power constraint, which is given by
P(x > A) = 0;
(2.50)
3) The average-power constraint, which is expressed as
E(x) ≤P.
(2.51)
Moreover, for analysis, the average-to-peak power ratio is deﬁned as
α = P
A.
(2.52)
Next, diﬀerent channel models in actual VLC systems are described. Afterward,
the corresponding capacity bounds are introduced.
2.6.1
Channel models
The optical wireless channels can be divided into three categories: free-space optical
intensity channel, discrete-time Poisson channel, and improved free-space intensity
channel.

37
A. Free-space optical intensity channel
Free-space optical intensity channel is commonly employed in visible light commu-
nications where the noise exhibits white and Gaussian features and is independent of
the signal [19–24]. This channel model can be described as
Y = X + Z,
(2.53)
where X and Y are the input and output signals, respectively, and Z is Gaussian
noise with zero mean and variance of σ2. Without loss of generality, the channel
gain is assumed to be unit in the following analysis. The conditional probability
distribution of the output signal is given by
W(y|x) =
1
√
2πσ2 e−(y−x)2
2σ2 .
(2.54)
(2.54) is valid when the background radiation noise and the thermal noise are dom-
inant in VLC systems. However, if the power of data-carrying optical source is larger
than ambient lighting and the noise power in electronic devices, this model cannot
describe the channel characteristics precisely since the dominant noise source might
be the quantum noise caused by the discrete nature of the photons from the optical
source.
B. Discrete-time Poisson channel
Discrete-time Poisson channel is an alternative channel model widely investigated in
VLC systems [25, 26], where the discrete nature of the photons is taken into consid-
eration. The transmission signal is modeled as a Poisson counting process, where
the number of arrival photons remains statistically constant during a long period but
varies in a short time interval. The arrival rate of the photons from the data-carrying
optical source is proportional to its average optical power. At the receiver, a pho-
ton counter is employed to measure the number of the received photons. Usually,
the received photons consist of the photons from the data-carrying optical source
and the photons from the background radiation noise. The conditional probability
distribution of the output signal is given by
W(y|x) = (x + λ)y
y!
e−(x+λ),
(2.55)
where λ is the arrival rate of the photons from the background radiation noise.
C. Improved free-space optical intensity channel
Improved free-space optical intensity channel is discussed in [27], where the out-
put signal follows Gaussian distribution but its variance is signal-dependent. In this
model, quantum noise, background radiation noise, and thermal noise are considered
and assumed to be Gaussian. The quantum noise is signal-dependent and its variance
www.ebook3000.com

38
is proportional to the signal strength while the background radiation noise and the
thermal noise are signal-independent. The output signal is given by
Y = X +
√
XZ1 + Z0,
(2.56)
where we have Z1 ∼N(0, ς2σ2) and Z0 ∼N(0, σ2). ς denotes the ratio of the
power of the signal-dependent noise to the signal-independent noise. Accordingly,
the conditional probability distribution of the output signal can be expressed as
W(y|x) =
1

2πσ2(1 + ς2x)e
−
(y−x)2
2σ2(1+ς2x) .
(2.57)
2.6.2
Capacity bounds for free-space optical intensity channel
A. Upper bounds
The capacity upper bounds of free-space optical intensity channel have been wide-
ly investigated. From the geometric point of view, based on the well-known sphere
packing method [28], tight closed-form upper bounds are derived in [21, 22] using
the Steiner-Minkowski formula when only an average-power constraint is imposed.
Nevertheless, obvious gaps exist between these upper bounds and the lower bounds in
the high optical signal-to-noise ratio (OSNR) region due to the mathematical approx-
imation of the intrinsic volumes of the simplex. To narrow the gap between the upper
and the lower bounds in the high OSNR region, alternative mathematical approxi-
mation for the intrinsic volumes of the simplex has been proposed in [23]. In [24],
an even tighter sphere-packing upper bound is derived using a recursive approach.
However, the notable gap in the low OSNR region is still unsolved.
In [19], tight upper bounds are derived using a dual expression for channel capacity
with diﬀerent ratios of the peak power to the average power. When both peak-power
and average-power constraints are applied and the ratio of the peak power to the
average power is ﬁxed, they would coincide with the lower bound as the average
power tends to inﬁnity. The drawback of these upper bounds comes from their higher
complexity than the sphere-packing bounds.
1) Sphere packing
When m independent transmitted symbols are denoted as x = [x1 x2 · · · xm] and
the average optical power in a VLC channel is deﬁned as P, the admissible set of the
transmitted symbols is given by
T(P) =

x
				 ∀i, xi ∈R+, 1
m
m

i=1
xi ≤P

.
(2.58)
These elements in the admissible set form a regular m-simplex [29], and the re-
ceived signal is calculated by
y = x + z.
(2.59)

39
From the geometrical point of view, each element in the signal vector x is sur-
rounded by a small uncertainty region caused by the noise z [28]. When the noise
is white and Gaussian, the perturbations of the received samples are independent.
If m is large enough, the perturbation would lie within an m-dimensional sphere
Bm(ρ) with the radius ρ and centered at the original signal point. The volume of the
m-dimensional sphere Bm(ρ) is expressed as [28]
V (Bm(ρ)) =
πm/2
Γ( m
2 + 1)ρm,
(2.60)
where Γ(·) is gamma function and ρ = √mσ.
In other words, the received signal would fall into the set O(P, ρ) deﬁned as the
outer parallel body to the admissible set T(P) at distance ρ with the probability near
to one, which is illustrated as
O(P, ρ) =

y
				 y = x + z, x ∈T(P), z ∈Bm(ρ)

.
(2.61)
(a) Two dimensions
(b) Three dimensions
Figure 2.7 Illustrations of m-simplex and its outer parallel body.
The two-dimensional and three-dimensional illustrations of m-simplex and its out-
er parallel body are shown in Fig. 2.7(a) and Fig. 2.7(b), respectively. Based on
the outer parallel body O(P, ρ), the number of nonoverlapping spheres packed in
O(P, ρ) is the maximum number of the diﬀerent and distinguishable transmitted
symbols, and can be regarded as the upper bound on channel capacity, which is ex-
pressed as [28]
C ≤lim
m→∞
1
m log V (O(P, ρ))
V (Bm(ρ)) .
(2.62)
www.ebook3000.com

40
Likewise, when only peak-power constraint is applied, the admissible set is deﬁned
as
T(A) =

x
				 ∀i, xi ∈R+, xi ≤A

.
(2.63)
It forms an m-dimensional cube and its outer parallel is given by
O(A, ρ) =

y
				 y = x + z, x ∈T(A), z ∈Bm(ρ)

.
(2.64)
The upper bound on channel capacity is expressed as
C ≤lim
m→∞
1
m log V (O(A, ρ))
V (Bm(ρ)) .
(2.65)
The two-dimensional representations of the m-dimensional cube and its outer par-
allel body are illustrated in Fig. 2.8(a). In Fig. 2.8(b), the method of the sphere
packing is presented.
(a) Two-dimensional cube and its outer parallel
body
(b) Sphere packing
Figure 2.8 Two-dimensional cube with its outer parallel body and sphere packing.
To obtain the closed-form expressions for the upper bound, two methods are used,
which are illustrated as Steiner-Minkowski formula and recursive approach.
• Steiner-Minkowski formula
The volume of the outer parallel body V (O(P, ρ)) is expressed as [30]
V (O(P, ρ)) =
m

k=0
Vk(P)V (Bm−k(ρ)),
(2.66)
where the intrinsic volume Vk(P) is given by
Vk(P) = ηk(mP)k,
k = 0, 1, ..., m,
(2.67)

41
and
ηk =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
1
m!,
if k = m,

m
k

1
k!2m−k +

m
k + 1

√k+1
k!√πm−k
×
 +∞
0
e−x2(
 x/√k+1
−∞
e−y2 dy)m−k−1 dx,
if 0 ≤k < m.
(2.68)
Substituting (2.66), (2.67), and (2.68) into (2.62), the upper bound can be rewritten
as
C ≤lim
m→∞
1
m log
m

k=0
Γ( m
2 + 1)(mP)kηk
Γ( m−k
2
+ 1)π
k
2 ρk
≤lim
m→∞
1
m log

(m + 1) sup
k∈χ
Γ( m
2 + 1)(mP)kηk
Γ( m−k
2
+ 1)π
k
2 ρk

= lim
m→∞
1
m log sup
k∈χ
Γ( m
2 + 1)(mP)kηk
Γ( m−k
2
+ 1)π
k
2 ρk ,
(2.69)
where χ = {0, 1, ..., m}.
To derive a simple closed-form upper bound, the coeﬃcient ηk is considered. For
every 0 ≤k < m, there is an inequality for ηk, that is
ηk <

m + 1
k + 1

k + 1
k!(m −k)( k
β + 1)γ−k
β 2m−k −1
2m−k
,
(2.70)
where γ and β are positive real-valued coeﬃcients of the tight lower bound (i.e.,
γ exp(−βx2)) on the complementary error function erfc(x).
According to (2.69) and (2.70), the upper bound on channel capacity is calculated
by [23]
C <
sup
α∈[0,1]

log

( e
2π)
α
2 γ−α
β
(α)2α(1 −α)
3
2 (1−α) (P
σ )α

.
(2.71)
Another upper bound based on the Steiner-Minkowski formula (with diﬀerent ap-
proximation value of ηk) is given by [22]
C ≤sup
α∈[0,1]

α log

e2
4π
P
σ

−log

(1 −α)
(1−α)
2
(1 −α
2 )1−α
2 α
3
2 α
.
(2.72)
When only peak-power constraint is applied, by way of packing sphere in the cube
with Steiner-Minkowski formula, the upper bound on channel capacity is further giv-
en by [24]
C ≤sup
α∈[0,1]

α log

1
√
2πe
A
σ

−log

(1 −α)
3(1−α)
2
αα
.
(2.73)
www.ebook3000.com

42
• Recursive approach
The recursive approach proposed in [24] utilizes the geometry of m-dimensional
spheres Bm(ρ) to obtain a tighter upper bound at the high OSNR region. When
only average-power constraint is imposed, the total volume of the spheres packed in
m-simplex is given by
ˆV (P, ρ) = Vin(T(P)) + Vout(T(P)),
(2.74)
where Vin(T(P)) denotes the volume of the spheres and the portions of spheres in-
side the m-simplex and Vout(T(P)) denotes the volume of the portions of spheres
outside the m-simplex. Vin(T(P)) can be upper-bounded by the volume of the
m-simplex, while the portions outside the m-simplex are distributed among the
(m−1)-dimensional faces of the m-simplex, which would lead to packing (m−1)-
dimensional spheres on the (m−1)-dimensional faces of the m-simplex. m-simplex
has
m+1
m
 (m −1)-dimensional faces, and the (m −1)-dimensional face is an
(m −1)-simplex Tm−1(P). By repeating the above procedure for the (m −i)-
dimensional faces (i = 0, 1, ..., m), the upper bound of ˆV (P, ρ) can be expressed
as
ˆV (P, ρ) ≤
m

i=0

m + 1
m −i + 1

V (Tm−i(P)) V (Bm(ρ))
V (Bm−i(ρ)).
(2.75)
Then, the upper bound on channel capacity can be obtained by
C ≤log
 m

i=0

m + 1
m −i + 1

V (Tm−i(P))
V (Bm−i(ρ))

,
(2.76)
where the (m −i)-simplex V (Tm−i(P)) is given by
V (Tm−i(P)) = (mP)m−i
(m −i)!
√
m −i + 1.
(2.77)
Similar to (2.69), the upper bound can be obtained by [24]
C ≤sup
α∈[0,1]

α log
 e
2π
P
σ

−log

(1 −α)1−αα
3
2 α
.
(2.78)
Likewise, when only peak-power constraint is considered, by packing sphere in the
cube with recursive approach, the upper bound on channel capacity is further given
by [24]
C ≤sup
α∈[0,1]

α log

1
√
2πe
A
σ

−log

(1 −α)(1−α)α
α
2 2α−1
.
(2.79)
2) Dual expression of channel capacity

43
When a dual expression of channel capacity is applied, the channel capacity under
both peak-power and average-power constraints is given by [19]
C ≤sup
Q
EQ[D(W(·|X)∥R(·))],
(2.80)
where W(·|·) is the conditional output distribution, Q denotes any channel input dis-
tribution, R(·) is the channel output distribution, and D(·∥·) is the relative entropy.
When the channel output has a probability distribution p(y), then (2.80) can be
rewritten as
C ≤sup
Q
EQ[−
 ∞
−∞
p(y)dW(y|X)] −1
2 log 2πeσ2].
(2.81)
The upper bounds in diﬀerent cases are given as follows [19].
• Case I: Peak-power and average-power constraints are considered with α ∈
(0, 1/2),
C ≤1
2 log

1 + α(1 −α)A2
σ2

(2.82)
and
C ≤

1 −Q
δ + αA
σ

−Q
δ + (1 −α)A
σ

log
A
σ
e
νδ
A −e−ν(1+ δ
A )
√
2πν(1 −2Q( δ
σ))

−1
2 + Q( δ
σ ) +
δ
√
2πσ e−δ2
2σ2 + σ
A
ν
√
2π

e−δ2
2σ2 −e−(A+δ)2
2σ2

+να

1 −2Q(δ + A
2
σ
)

(2.83)
where ν and δ are positive parameters given in [19, (14) & (15)].
• Case II: Peak-power and average-power constraints are considered with α ∈
[1/2, 1],
C ≤1
2 log

1 + A2
4σ2

(2.84)
and
C ≤

1 −2Q
δ + A
2
σ

log

A + 2δ
√
2πσ

1 −2Q
 δ
σ


−1
2 + Q
 δ
σ

+
δ
√
2πσ e−δ2
2σ2
(2.85)
where δ is a positive parameter given in [19, (21)].
www.ebook3000.com

44
• Case III: Only the average-power constraint is considered,
C ≤log

βe−δ2
2σ2 +
√
2πσQ
 δ
σ

−log
√
2πσ
 −δP
2σ2
+ δ2
2σ2

1 −Q
 δ
σ

−P
δ Q
 δ
σ

+ 1
β

P +
σ
√
2π

,
if δ ≤−σ
√e
(2.86)
and
C ≤log

βe−δ2
2σ2 +
√
2πσQ
 δ
σ

+ 1
2Q
 δ
σ

+
δ
2
√
2πσ e−δ2
2σ2
+ δ2
2σ2

1 −Q
δ + P
σ

+ 1
β

P + δ +
σ
√
2π e−δ2
2σ2

−1
2 log 2πeσ2,
if δ ≥0
(2.87)
where β and δ are free parameters given in [19, (29), (30), (31) & (32)].
B. Lower bounds
With a proper choice of the input distribution, a tight lower bound can be obtained
to approach the channel capacity or upper bound. Two speciﬁc lower bounds on
channel capacity for free-space optical intensity channel are detailed as below.
• Entropy power inequality
For any speciﬁc input distribution, based on the entropy power inequality (EPI),
we have
C ≥I(X; Y )
= H(X + Z) −H(Z)
≥1
2 log

e2H(X) + e2H(Z)

−H(Z)
= 1
2 log

1 + e2H(X)
2πeσ2

.
(2.88)
The maximum diﬀerential entropy of the input signals, i.e., max H(X), would
result in a tight lower bound [19].
• Case I: When peak-power and average-power constraints are considered with α ∈
(0, 1/2), the input distribution approaching maximum diﬀerential entropy is given
by
p(x) =
ν
A(1 −e−ν)e−νx
A ,
0 ≤x ≤A,
(2.89)

45
where ν satisﬁes
1
ν −
e−ν
1 −e−ν = α.
(2.90)
In this case, the lower bound is given by
C ≥1
2 log

1 + A2 e2αν
2πeσ2
1 −e−ν
ν
2
.
(2.91)
• Case II: When peak-power and average-power constraints are considered with α ∈
[1/2, 1], the input distribution approaching maximum diﬀerential entropy is given
by
p(x) = 1
A,
0 ≤x ≤A,
(2.92)
and the lower bound is given by
C ≥1
2 log

1 +
A2
2πeσ2

.
(2.93)
• Case III: When only the average-power constraint is considered, the input distri-
bution approaching maximum diﬀerential entropy is given by
p(x) = 1
P e−x
P ,
x ≥0,
(2.94)
and the lower bound is given by
C ≥1
2 log

1 + P 2e
2πσ2

.
(2.95)
The upper bounds and lower bounds for Case I and Case II are shown in Fig. 2.9
and Fig. 2.10, respectively.
• Discrete input distribution
Under the average-power constraint, all probability distributions on the input X form
the set given by
P =

p(x) | p(x < 0) = 0, E(x) ≤P,

p(x)dx = 1

.
(2.96)
To ﬁnd a capacity-achieving input distribution, the distributions of equidistant
mass points are considered. The set consisting of these discrete distributions is illus-
trated as
Pl =

pl(x) ∈P | ak ≥0, l > 0, pl(x) =
∞

k=0
akδ(x −kl)

,
(2.97)
www.ebook3000.com

46
A/σ (dB)
-5
0
5
10
15
20
25
30
Channel Capacity (bit/channel use)
0
1
2
3
4
5
6
7
8
9
Upper Bound (2.82)
Upper Bound (2.83)
Lower Bound (2.91)
Figure 2.9 Comparison of free-space optical intensity channel capacity bounds when both
peak-power and average-power constraints are applied with α = 0.1.
A/σ (dB)
-5
0
5
10
15
20
25
30
Channel Capacity (bit/channel use)
0
1
2
3
4
5
6
7
8
9
Upper Bound (2.84)
Upper Bound (2.85)
Lower Bound (2.93)
Figure 2.10 Comparison of free-space optical intensity channel capacity bounds when
both peak-power and average-power constraints are applied with α ∈[1/2, 1].
where ak is the amplitude of the kth mass point and l is the distance between two mass
points. Intuitively, the input distribution with maximum entropy under the average-
power constraint may achieve the channel capacity, which is given by [22]
p∗
l = arg
max
pl(x)∈Pl H(pl(x))
s.t.
∞

k=0
akkl ≤P,
∞

k=0
ak = 1,
ak ≥0.
(2.98)

47
P/σ (dB)
0
5
10
15
20
25
Channel Capacity (bit/channel use)
0
1
2
3
4
5
6
7
8
9
Upper Bound (2.71)
Upper Bound (2.72)
Upper Bound (2.78)
Upper Bound (2.87)
Lower Bound (2.95)
Lower Bound (2.102)
Figure 2.11 Comparison of free-space optical intensity channel capacity bounds when
only the average-power constraint is applied.
Based on (2.98), the input signal with maximum entropy follows a geometric dis-
tribution given by
p∗
l =
∞

k=0
l
l + P (
P
l + P )kδ(x −kl).
(2.99)
Afterwards, the mutual information can be calculated by
Ip∗
l (X; Y ) = −

fW (w) log fW (w)dw −1
2 log(2πeβ2),
(2.100)
where
fW (w) =
∞

k=1
1
1 + P
l

P
l
1 + P
l
k
l
√
2πσ2 e−(w−k)2l2/2σ2.
(2.101)
Since the mutual information Ip∗
l (X; Y ) is a function of the argument l, a tight
lower bound can be obtained by [22]
C ≥CL = max
l
Ip∗
l (X; Y ).
(2.102)
Although this method does not provide a closed-form expression, the lower bound
can be numerically calculated from (2.102). When only the average-power constraint
is applied, the upper and lower bounds are shown in Fig. 2.11.
2.6.3
Capacity bounds for discrete-time Poisson channel
In the discrete-time Poisson channel, the conditional output signal follows a Poisson
distribution as shown in (2.55). Like the free-space optical intensity channel, there is
www.ebook3000.com

48
no analytical expression for channel capacity subject to the average-power and peak-
power constraints. Thus, only capacity bounds on the discrete-time Poisson channel
are presented.
A. Upper bounds
Similar to free-space optical intensity channel, upper bounds on the discrete-time
Poisson channel are derived using the dual expression of the channel capacity for the
following three diﬀerent cases [25].
• Case I: Peak-power and average-power constraints are imposed and α ∈(0, 1/3),
C ≤1
2 log A −(1 −α)ν −log
1
2 −αν

−1
2 log 2πe + oA(1),
(2.103)
where oA(1) is deﬁned as a function that tends to zero as the peak power and average
power tend to inﬁnity, and ν satisﬁes
1
2ν −
e−ν
√πνerf(√ν) = α.
(2.104)
• Case II: Peak-power and average-power constraints are imposed and α ∈[1/3, 1]
(when α = 1, only peak-power constraint is considered),
C ≤1
2 log A −1
2 log πe
2 + oA(1).
(2.105)
• Case III: Only the average-power constraint is applied,
C ≤1
2 log P + oP (1),
(2.106)
where oP (1) is deﬁned as a function that tends to zero as the average power goes to
inﬁnity.
B. Lower bounds
The entropy of the output is lower-bounded by [25]
H(Y ) ≥H(X) + (1 + E(X)) log(1 +
1
E(X)) −1,
(2.107)
and the conditional entropy H(Y |X) is upper-bounded by
H(Y |X) ≤1
2E

log 2πe(X + λ + 1
12)

.
(2.108)
The lower bound on Poisson channel capacity can be given by
C ≥I(X; Y )
= H(Y ) −H(Y |X)
≥H(X) + (1 + E(X)) log(1 +
1
E(X)) −1 −1
2E

log 2πe(X + λ 1
12)

.
(2.109)

49
According to (2.109), the lower bound strongly depends on the entropy of input
signal [25].
• Case I: When peak-power and average-power constraints are imposed with α ∈
(0, 1/3), the input distribution approaching the maximum entropy is given by
p(x) =
√ν
√
Aπxerf(√ν)
e−ν
A x,
0 < x ≤A,
(2.110)
where ν satisﬁes (2.104). Thus, the lower bound is given by
C ≥1
2 log A −(1 −α)ν −log(1
2 −αν) −eν(1
2 −αν)·

log

1 + λ + 1
12
A

+ 2

λ + 1
12
A
arctan

A
λ + 1
12

+ (P + 1) log(1 + 1
P ) −1 −1
2 log 2πe.
(2.111)
• Case II: When peak-power and average-power constraints are imposed with α ∈
[1/3, 1], the input distribution approaching the maximum entropy is given by
p(x) =
1
2
√
Ax
,
0 < x ≤A,
(2.112)
and the lower bound is given by
C ≥1
2 log A −

1 + A
3

log

1 + 3
A

−1
−

λ + 1
12
A
π
4 + 1
2 log 2

−1
2 log πe
2 .
(2.113)
• Case III: When only the average-power constraint is applied, the input distribution
approaching the maximum entropy is given by
p(x) =
1
√
2πPx
e−x
2P ,
x > 0,
(2.114)
and the lower bound is given by
C ≥1
2 log P −

π(λ + 1
12)
2P
+ (P + 1) log(1 + 1
P ) −1.
(2.115)
Figure 2.12 depicts the upper bounds and lower bounds on Poisson channel capac-
ity for Case I and Case II, while Fig. 2.13 shows the upper bound and lower bound
on Poisson channel capacity for Case III.
www.ebook3000.com

50
A/σ2 (dB)
5
10
15
20
25
30
35
40
45
50
Channel Capacity (bit/channel use)
0
1
2
3
4
5
6
7
Asympotic Upper Bound (2.103), α = 0.1
Lower Bound (2.111), α = 0.1
Asympotic Upper Bound (2.105), α ≥ 1/3
Lower Bound (2.113), α ≥ 1/3
Figure 2.12 Comparison of Poisson channel capacity bounds when both peak-power and
average-power constraints are applied.
P/σ2 (dB)
0
5
10
15
20
25
30
35
40
Channel Capacity (bit/channel use)
0
1
2
3
4
5
6
7
Asympotic Upper Bound (2.106)
Lower Bound (2.115)
Figure 2.13 Comparison of Poisson channel capacity bounds when only the
average-power constraint is applied.
2.6.4
Capacity bounds for improved free-space intensity channel
For improved free-space intensity channel, both the signal-dependent Gaussian noise
and the signal-independent Gaussian noise are considered. Compared to the free-
space optical intensity channel, the analysis of channel capacity becomes diﬃcult
when the signal-dependent Gaussian noise is included.
A. Upper bounds
By using the dual expression of the channel capacity, the upper bounds for improved
free-space intensity channel are given as follows [27].
• Case I: Peak-power and average-power constraints are considered and α
∈

51
(0, 1/3),
C ≤1
2 log A
σ2 −1
2 log 2πeς2 −(1 −α)μ −log(1
2 −αμ) + oA(1),
(2.116)
where μ ∈(0, 1
2α) satisﬁes
1
2μ −
e−μ
√πμerf(√μ) = α.
(2.117)
• Case II: Peak-power and average-power constraints are considered and α ∈
[1/3, 1] (when α = 1, only peak-power constraint is considered),
C ≤1
2 log A
σ2 −1
2 log πeς2
2
+ oA(1).
(2.118)
• Case III: Only the average-power constraint is considered,
C ≤1
2 log P
σ2 −1
2 log ς2 + oP (1).
(2.119)
B. Lower bounds
The derivation of the lower bounds for improved free-space optical intensity channel
is similar to Poisson channel. Based on the lower bound on the entropy of the output
signal, we have
H(Y ) ≥H(x) + 1
2 log(1 + 2ς2σ2
P
) +

P(P + 2ς2σ2)
ς2σ2
−P + ς2σ2
ς2σ2
,
(2.120)
and the lower bound on channel capacity can be given by
C ≥I(X; Y )
= H(Y ) −H(Y |X)
≥H(X) + 1
2 log(1 + 2ς2σ2
P
) +

P(P + 2ς2σ2)
ς2σ2
−P + ς2σ2
ς2σ2
−1
2E

log 2πeσ2(1 + ς2X)

.
(2.121)
The speciﬁc lower bounds for diﬀerent cases are given as follows [27].
• Case I: When peak-power and average-power constraints are considered with α ∈
(0, 1/3), with the same distribution as (2.110), the lower bound is given by
C ≥1
2 log A
σ2 −1
2 log 2πeς2 −(1 −α)μ −log(1
2 −αμ) + β(A,α,μ,σ,ς),
(2.122)
www.ebook3000.com

52
A/σ2 (dB)
5
10
15
20
25
30
35
40
45
50
Channel Capacity (bit/channel use)
0
1
2
3
4
5
6
7
Asympotic Upper Bound (2.116), α = 0.1
Lower Bound (2.122), α = 0.1
Asympotic Upper Bound (2.118), α ≥ 1/3
Lower Bound (2.124), α ≥ 1/3
Figure 2.14 Comparison of improved free-space optical intensity channel capacity bounds
when both peak-power and average-power constraints are applied with ς = 1.
where
β(A,α,μ,σ,ς) = −eμ(1
2 −αμ)(
2
√
ς2A arctan(

ς2A) + log(1 +
1
ς2A))
+1
2 log(1 + 2ς2σ2
αA ) −αA
ς2σ2 −1 +

αA(αA + 2ς2σ2)
ς2σ2
.
(2.123)
• Case II: When peak-power and average-power constraints are considered with α ∈
[1/3, 1], using the same distribution as (2.112), the lower bound is given by
C ≥1
2 log A
σ2 −1
2 log πeς2
2
+ β(A,1/3,0,σ,ς),
(2.124)
where β(A,1/3,0,σ,ς) is deﬁned as
β(A,α,μ,σ,ς) = −
1
√
ς2A arctan(

ς2A) −1
2 log(1 +
1
ς2A)
(2.125)
+1
2 log(1 + 6ς2σ2
A
) −
A
3ς2σ2 −1 +

A(A + 6ς2σ2)
3ς2σ2
.
• Case III: When only the average-power constraint is considered, using the same
distribution as (2.114), the lower bound is given by
C ≥1
2 log P
σ2 −log ς2 + 1
2 log(1 + 2ς2σ2
P
) −
P
ς2σ2 −1
(2.126)
+

P(P + 2ς2σ2)
ς2σ2
−

π
2ς2P .
The upper and lower bounds on improved free-space optical intensity channel ca-
pacity for Case I and Case II are shown in Fig. 2.14. In Fig. 2.15, the upper and lower
bounds for Case III are illustrated.

53
P/σ2 (dB)
0
5
10
15
20
25
30
35
40
Channel Capacity (bit/channel use)
0
1
2
3
4
5
6
7
Asympotic Upper Bound (2.119)
Lower Bound (2.126)
Figure 2.15 Comparison of improved free-space optical intensity channel capacity bounds
when only the average-power constraint is applied with ς = 1.
2.7
Conclusion
In this chapter, the characteristics of LED as the transmitter and photodiode as the
receiver are described. Normally, LED works under a forward bias while photodi-
ode is driven by a reverse voltage. When LED is employed for lighting and com-
munication simultaneously, its nonlinearity and lighting constraints are investigated.
Besides, absorption coeﬃcient, quantum eﬃciency, and responsivity of the photo-
diode are demonstrated. Furthermore, diﬀerent LOS and NLOS propagation links
between the transmitter and the receiver are analyzed. Since the dominant noise
might be diﬀerent in various application scenarios, three optical wireless channels
are addressed including free-space optical intensity channel, discrete-time Poisson
channel, and improved free-space intensity channel. Considering there exist no ana-
lytic expressions of the channel capacity, the state-of-the-art upper and lower bounds
are presented.
www.ebook3000.com


55
References
1 D. A. Steigerwald, J. C. Bhat, D. Collins,
R. M. Fletcher, M. O. Holcomb,
M. J. Ludowise, P. S. Martin, and
S. L. Rudaz, “Illumination with solid state
lighting technology,” IEEE J. Sel. Topics
Quantum Electron., vol. 8, no. 2,
pp. 310–320, Mar. 2002.
2 J. Wang, C. C. Tsai, W. C. Cheng,
M. H. Chen, C. H. Chung, and
W. H. Cheng, “High thermal stability of
phosphor-converted white-lightemitting
diodes employing Ce:YAG doped glass,”
IEEE J. Sel. Topics Quantum Electron.,
vol. 17, no. 3, pp. 741–746, May/Jun. 2011.
3 S. Pimputkar, J. S. Speck, S. P. DenBaars,
and S. Nakamura, “Prospects for LED
lighting,” Nature Photon., vol. 3,
pp. 179–181, Apr. 2009.
4 J. Grubor, S. Randel, K. D. Langer, and
J. W. Walewski, “Broadband information
broadcasting using LED-based interior
lighting,” J. Lightw. Technol., vol. 26,
no. 24, pp. 3883–3892, Dec. 2008.
5 D. Karunatilaka, F. Zafar, V. Kalavally, and
R. Parthiban, “LED based indoor visible
light communications: State of the art,”
IEEE Commun. Surv. Tuts., vol. 17, no. 3,
pp. 1649–1678, Mar. 2015.
6 A. Martí, J. L. Balenzategui, and
R. F. Reyna, “Photon recycling and
Shockley’s diode equation,” J. Appl. Phys.,
vol. 82, no. 8, pp. 4067–4075, Oct. 1997.
7 I. Neokosmidis, T. Kamalakis,
J. W. Walewski, B. Inan, and
T. Sphicopoulos, “Impact of nonlinear LED
transfer function on discrete multitone
modulation: Analytical approach,” J.
Lightw. Technol., vol. 27, no. 22, pp.
4970–4978, Nov. 2009.
8 T. Kamalakis, J. Walewski, G. Ntogari, and
G. Mileounis, “Empirical Volterra-series
modeling of commercial light-emitting
diodes,” J. Lightw. Technol., vol. 29, no. 14,
pp. 2146–2155, Jul. 2011.
9 G. Wyszecki and W. S. Stiles, Color
Science: Concepts and Methods,
Quantitative Data and Formulae, 2nd ed.
New York: Wiley, 1982.
10 F. Zafar, D. Karunatilaka, and R. Parthiban,
“Dimming schemes for visible light
communications: The state of research,”
IEEE Wirel. Commun., vol. 22, no. 2, pp.
29–35, Apr. 2015.
11 J. Gancarz, H. Elgala, and T. D. C. Little,
“Impact of lighting requirements on VLC
systems,” IEEE Commun. Mag., vol. 51,
no. 12, pp. 34–41, Dec. 2013.
12 S. Rajagopal, R. D. Roberts, and S. K. Lim,
“IEEE 802.15.7 visible light
communication: Modulation schemes and
dimming support,” IEEE Commun. Mag.,
vol. 50, no. 3, pp. 72–82, Mar. 2012.
13 R. Singh, T. O’Farrell, and J. P. R. David,
“An enhanced color shift keying
modulation scheme for high-speed wireless
visible light communications,” J. Lightw.
Technol., vol. 32, no. 14, pp. 2582–2592,
Jul. 2014.
14 J. Geist, E. F. Zalewski, and A. R. Schaefer,
“Spectral response self calibration and
interpolation of silicon photodiodes,” Appl.
Opt., vol. 19, no. 22, pp. 3795–3799, Nov.
1980.
15 J. M. Kahn and J. R. Barry, “Wireless
infrared communications,” Proc. IEEE,
vol. 85, no. 2, pp. 265–298, Feb. 1997.
16 F. R. Gfeller and U. H. Bapst, “Wireless
in-house data communication via diﬀuse
www.ebook3000.com

56
infrared radiation,” Proc. IEEE, vol. 67, no.
11, pp. 1474–1486, Nov. 1979.
17 P. H. Pathak, X. Feng, P. Hu, and
P. Mohapatra, “Visible light
communication, networking, and sensing:
A survey, potential and challenges ,” IEEE
Commun. Surv. Tuts., vol. 17, no. 4, pp.
2047–2077, Nov. 2015.
18 N. S. Kopeika and J. Bordogna,
“Background noise in optical
communication systems,” Proc. IEEE, vol.
58, no. 10, pp. 1571–1577, Oct. 1970.
19 A. Lapidoth, S. M. Moser, and
M. A. Wigger, “On the capacity of
free-space optical intensity channels,”
IEEE Trans. Inf. Theory, vol. 55, no. 10,
pp. 4449–4461, Oct. 2009.
20 S. Hranilovic and F. R. Kschischang,
“Capacity bounds for power- and
band-limited optical intensity channels
corrupted by Gaussian noise,” IEEE Trans.
Inf. Theory, vol. 50, no. 5, pp. 784–795,
May 2004.
21 J. Wang, Q. Hu, J. Wang, M. Chen, and
J. Wang, “Tight bounds on channel
capacity for dimmable visible light
communications,” J. Lightwave Technol.,
vol. 31, no. 23, pp. 3771–3779, Dec. 2013.
22 A. Farid and S. Hranilovic, “Capacity
bounds for wireless optical intensity
channels with Gaussian noise,” IEEE
Trans. Inf. Theory, vol. 56, no. 12,
pp. 6066–6077, Dec. 2010.
23 R. Jiang, Z. Wang, Q. Wang, and L. Dai, “A
tight upper bound on channel capacity for
visible light communications,” IEEE
Commun. Lett., vol. 20, no. 1, pp. 97–100,
Jan. 2016.
24 A. Chaaban, J. Morvan, and M. Alouini,
“Free-space optical communications:
Capacity bounds, approximations, and a
new sphere-packing perspective,” IEEE
Trans. Commun., vol. 64, no. 3, pp.
1176–1191, Mar. 2016.
25 A. Lapidoth and S. M. Moser, “On the
capacity of the discrete-time Poisson
Channel,” IEEE Trans. Inf. Theory, vol. 55,
no. 1, pp. 303–322, Jan. 2009.
26 S. Shamai, “Capacity of a pulse amplitude
modulated direct detection photon
channel,” Proc. IEE, vol. 137, no. 6, pp.
424–430, Dec. 1990.
27 S. M. Moser, “Capacity results of an optical
intensity channel with input-dependent
Gaussian noise,” IEEE Trans. Inf. Theory,
vol. 58, no. 1, pp. 207–223, Jan. 2012.
28 C. E. Shannon, “Communication in the
presence of noise,” Proc. IRE, vol. 37, no.
1, pp. 10–21, Jan. 1949.
29 W. Rudin, Principle of Mathematical
Analysis. New York: McGraw-Hill, 1976.
30 U. Betke and M. Henk, “Intrinsic volumes
and lattice points of crosspolytopes,”
Monatsh. Math., vol. 115, no. 1, pp. 27–33,
Mar. 1993.

57
3
Single Carrier/Carrierless Modulation and Coding
In this chapter, we present a review of carrierless and single carrier modulation
schemes for visible light communication (VLC). In order to meet the illumination
requirements, we also provide a brief introduction of modulation and coding tech-
niques recently developed for dimming control and ﬂicker mitigation.
In Section 3.1, pulse amplitude modulation (PAM), which is a simple modulation
format widely used in VLC systems, is addressed. When a multipath channel is
considered, frequency-domain equalization is preferred and its bit error rate (BER)
is analyzed. Besides, several implementation considerations are brought to overcome
the nonlinearity eﬀect of light emitting diode (LED).
In Section 3.2, pulse position modulation (PPM) is illustrated as well as its corre-
sponding decision feedback equalizers (DFE). PPM has low data rate with only one
pulse in a single symbol duration. Several modiﬁed schemes are introduced includ-
ing diﬀerential PPM (DPPM), multipulse PPM (MPPM), overlapping PPM (OPPM),
and variable PPM (VPPM).
Carrierless amplitude phase modulation (CAP) is a variant of quadrature ampli-
tude modulation (QAM), which has high spectral eﬃciency and simple implemen-
tation. In Section 3.3, the concept of CAP is detailed. After that, the design of
multi-dimensional CAP is discussed as an extension of two-dimensional CAP.
In indoor VLC systems, since communication and illumination should be main-
tained at the same time, where the light may be dimmed to satisfy diﬀerent illumi-
nation and energy requirements, modulation and coding schemes for the dimming
control are discussed in Section 3.4.
3.1
Pulse amplitude modulation
PAM is a simple modulation methodology, widely used in VLC and other optical
communication systems [1, 2]. On-oﬀkeying (OOK), which can be regarded as a spe-
cial candidate of PAM with only two levels, has been adopted in the IEEE 802.15.7
standard [3]. Recently, gigabit/s VLC transmissions have been reported adopting
either OOK or PAM [4–6].
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.
www.ebook3000.com

58
 
 
 
 
Figure 3.1 A PAM-SCFDE VLC system.
In order to remove the inter-symbol interference (ISI) for PAM systems, single-
carrier modulation with frequency-domain equalization (SCFDE) is usually adopted,
which is referred to as PAM-SCFDE [7]. A PAM-SCFDE VLC system diagram is
illustrated in Fig. 3.1. The binary signal vector x is fed into the M-PAM modulator,
where M denotes the modulation order. Since intensity modulation is preferred in
VLC systems, the transmitted waveform is non-negative and direct current (DC) bias
should be added to the bipolar PAM signal to generate a unipolar PAM waveform.
Therefore, the output signal vector ˜x = [˜x0 ˜x1 · · · ˜xL−1]T is real and non-negative,
and we have ˜xk ∈{0, 1, ..., M −1} for 0 ≤k < L, where L is the block
length. A cyclic preﬁx (CP) with K elements is commonly added to mitigate the
multipath dispersion and K is equal to or larger than the maximum number of taps
in the multipath channel. After inserting the CP to the transmitted signal vector ˜x, the
generated waveform is then sent to the digital-to-analog converter (DAC) to obtain
x (t), which is used to drive the LEDs and generate the optical signal radiated to the
air.
At the receiver, the optical signal is directly detected by photodiode (PD), which
converts the optical waveform into the electrical signal. The multipath channel dis-
persion can be modeled by hc (t). In addition, the shot and thermal noises at the
receiver, denoted as w(t), can be modeled as independent, identically distributed
(i.i.d.) additive white Gaussian noise (AWGN) [7]. After analog-to-digital converter
(ADC) and CP removal, we have
y = Hx + w,
(3.1)
where w = [w0 w1 · · · wL−1]T is the sample vector of AWGN noise with wi ∼
N (0, N0/2), which includes both shot noise and thermal noise. N0 is the single-

59
sided noise power spectral density, and H is a channel matrix with the size of L×L.
If the line-of-sight (LOS) channel is considered, the channel matrix H is diagonal
with the LOS channel coeﬃcient h0 as its diagonal elements. The equalized signal
vector ˆy can be calculated by
ˆy = h−1
0 y,
(3.2)
which is used for the estimation of the transmitted signal vector ˆx.
In a multipath VLC channel, H can be deﬁned as an L × L circulant convolution
matrix with the ﬁrst column [h0 h1 · · · hK−1 0 · · · 0]T, and h = [h0 h1 · · · hK−1]
is the K-tap discrete multipath channel coeﬃcients with hi = hc(i · Ts) for
i ∈[0, K −1], where hc(·) is the channel response and Ts is the symbol duration.
Thus, the channel matrix H can be diagonalized as
H = FHΛF,
(3.3)
where F is an L × L discrete Fourier transform (DFT) matrix and FH denotes its
Hermitian matrix. Λ denotes the L × L diagonal matrix, whose diagonal elements
{Λ1, Λ2, ..., ΛL} are the eigenvalues of H. When DFT is applied to (3.1), we have
Y = ΛX + W, where Y = Fy, X = Fx and W = Fw. As a result, frequency-
domain equalization with the diagonal equalizer VEQ can be utilized, and the equal-
ized signal vector can be calculated after inverse discrete Fourier transform (IDFT)
as
ˆy = FHVEQY = FHVEQΛFx + FHVEQFw,
(3.4)
which is then used for M-PAM demodulation and the estimation of the transmitted
signal vector ˆx.
In a unipolar M-PAM system, the transmitted signal x (t) can be rewritten as
x (t) = smp (t) , m = 0, ..., M −1,
(3.5)
where p (t) is a shaping pulse with a duration of T and the constellation point sm is
denoted as sm = m for m = 0, ..., M −1. Therefore, the transmitted energy is
given by
τm =
 ∞
−∞
s2
mp2 (t) dt = m2τp,
(3.6)
where τp is the energy of p (t). The average energy of PAM signal is calculated as
τav = τp
M
M−1

m=0
m2 = τp
6 (M −1) (2M −1) ,
(3.7)
and the average electrical energy per bit, Eb(elec,av) can be deﬁned as
Eb(elec,av) =
τp
6log2M (M −1) (2M −1) .
(3.8)
www.ebook3000.com

60
When Gray mapping is used in the design of PAM constellation, the minimum
Euclidean distance between diﬀerent constellation points is given by
dmin =

6Eb(elec,av)log2M
(M −1) (2M −1).
(3.9)
Therefore, the BER of unipolar PAM systems in the LOS channel can be calculated
as [7]
P M−PAM
LOS
≈2 (M −1)
M
Q
 dmin
√2N0

(3.10)
= 2 (M −1)
M
Q

3γavlog2M
(M −1) (2M −1)

,
where Q(x) =
1
√
2π
 ∞
x exp
 −u2
2
du represents the standard tail probability
function of the Gaussian distribution with zero mean and unit variance, and γav =
Eb(elec,av)/N0 is the ratio of average electrical energy per bit to noise power spectral
density.
When a multipath VLC channel is considered, linear minimum mean squared error
(LMMSE) equalization can be implemented to achieve better performance than its
zero-forcing (ZF) counterpart in SCFDE systems [7, 8]. Its equalization matrix is
given by
VLMMSE =
ΛHΛ + γ−1I
−1ΛH,
(3.11)
which is used to replace VEQ in (3.4), where γ = Eb(elec)/N0 denotes the ratio of
energy per bit to noise power spectral density, and I is the identity matrix.
When z (γ, Λ) is deﬁned as
z (γ, Λ)
△= 1
L
L−1

k=0
1
1 + γ |Λk|2 ,
(3.12)
for the L × L diagonal matrix Λ in (3.3), γav can be expressed as [9]
γav = z−1
PAM −1,
(3.13)
where
zPAM = z (γlog2M, Λ) .
(3.14)
According to (3.10), the BER of M-PAM-SCFDE with LMMSE equalization can
be roughly given by
P M−PAM
LMMSE
≈2 (M −1)
M
F

3
(M −1) (2M −1), zPAM

,
(3.15)

61
Figure 3.2 Illustration of 4-SPAM modulation scheme with two LEDs.
where F (α, z) is deﬁned as
F (α, z)
△= Q

α (z−1 −1)

, z ∈(0, 1] .
(3.16)
Furthermore, since LED nonlinearity is also a challenge for the PAM-based VLC
systems, several implementation methodologies have been proposed to mitigate
its negative eﬀects, such as superposed pulse amplitude modulation (SPAM) and
grouped modulation [10, 11].
In SPAM, various groups of LED chips are placed together for simultaneous illumi-
nation, which have diﬀerent intensities when suitable driving voltages are applied.
For each single LED, it can only stay in either “on” or “oﬀ” status, i.e., two-level
OOK. Therefore, there exist no LED nonlinearity issues. However, if they are con-
trolled by the input bit vector as a whole, diﬀerent intensities are combined together
to support multilevel modulations. Speciﬁcally, N LEDs having intensity ranges of
V , V/2, V/4, ..., V/2N−1 are used in the 2N-SPAM. An example of 4-SPAM is
illustrated in Fig. 3.2, where two OOK signals of V1 and V1/2 drive two correspond-
ing LEDs to produce four-level optical signals. Since only one PD is required to
collect the optical signals at the SPAM receiver, itlkooaooao much lower complexity.
The principle of SPAM can be extended by way of adopting several LEDs with the
same intensity, which are divided into N groups for 2N-level modulation. In each
group, the number of illuminating LEDs is diﬀerent to maintain the required inten-
sity, which is referred to as grouped modulation [11]. An example of two-grouped
modulation with a nine-LED squared array is shown in Fig. 3.3, which is installed in
the center of the ceiling. Group 1 contains three LEDs (in red color), while Group
2 consists of the other six LEDs (in black color). When the same driving voltage is
applied on each LED, the ratio of optical power emitted by Group 1 over Group 2 is
1 : 2, which is similar to the previous 4-SPAM example. There exist
9
3

possible
choices for group partition of those 9 LEDs. In order to provide uniform illumina-
tion, it is preferred to choose 1st, 6th, and 8th LEDs for Group 1 as illustrated in
www.ebook3000.com

62
Figure 3.3 Illustration of two-grouped modulation with a nine-LED squared array.
Fig. 3.3 [11].
If the size of LED array is
2N −1
 ×
2N −1

, it could be divided into N
groups for 2N-level modulation. In the mth group, where m = 1, 2, ..., N, 2m−1×
2N −1

LEDs with identical driving voltage are illuminated simultaneously. The
distribution of N small-sized LED groups can be calculated carefully to get a uni-
form illumination. In each group, a two-level OOK optical signal is generated and
corresponds to binary 0 and 1, respectively. A 2N level constellation can be real-
ized with the combination of binary modulation in diﬀerent groups. Therefore, N
bit/s/Hz can be achieved via grouped modulation. Similar to SPAM method [10],
multiple-level modulation scheme realized by grouped modulation is simple since
only two-level modulation is utilized in diﬀerent groups. Compared with its SPAM
counterpart, grouped modulation is easier to be implemented since all the LEDs have
the same driving voltage. However, it requires more LEDs in order to meet the same
throughput requirement.
3.2
Pulse position modulation
PPM is an orthogonal modulation scheme, which has been widely used in optical
wireless communication systems [12]. In L-PPM, one symbol duration is equally
divided into L time slots, and only one of the L slots is utilized for data transmission,
which is occupied by a given pulse. The power of the activated pulse is constant,
denoted as LPt, while the other L −1 time slots are set to zero. The transmitted
data is represented by the position of the pulse instead of its intensity, and log2 L
bits can be conveyed. The transmitted waveforms for 2-PPM and 4-PPM are shown
in Fig. 3.4. Compared with PAM, PPM requires much lower average-power since
only 1/L of the symbol duration is activated, which is achieved at the expense of
an increased bandwidth. For L-PPM, the required bandwidth is L/ log2 L times
that of OOK with the same data throughput. For example, when 16-PPM is used, it

63
 
 
(a) 2-PPM
 
 
 
 
(b) 4-PPM
Figure 3.4 Transmitted waveforms for 2-PPM and 4-PPM.
requires four times frequency bandwidth. When L increases, the average power of
L-PPM decreases by a factor of 1/L and the noise is only increased by L/ log2 L,
considering the bandwidth expansion. Therefore, the received SNR is dramatically
improved. From another point of view, since the transmitted signal is zero in most
of the time, the peak-to-average power ratio (PAPR) is signiﬁcantly increased, which
requires higher transmitted peak power.
In an LOS channel without multipath distortion, the optimum maximum likeli-
hood (ML) receiver for L-PPM employs a continuous-time ﬁlter matched to one
timeslot/one chip, whose output is sampled at the chip rate [12]. Afterwards, the
L samples in each symbol duration are sent to a block decoder, which decodes the
transmitted log2 L information bits. When a soft-decision decoder is used, the largest
sample is estimated as the activated pulse, and the actual samples are kept. When
a hard-decision decoder is used, each sample is simply quantized to “on” or “oﬀ”
with a threshold detector, and the transmitted bits are determined by the position
of “on” pulses. Accidental occasions such as no sample or more than one sample
is “on” have to be treated specially in the hard-decision decoder. Compared with
soft-decision decoder, hard-decision decoder is easier for implementation with the
sacriﬁce of around 1.5 dB optical power penalty [12].
In a multipath channel, the “on” pulse may induce interference in the other “oﬀ”
chips, which is denoted as ISI. Due to its negative eﬀect, the optimal soft-decision
decoder proposed for LOS channel does not work well. Therefore, maximum likeli-
hood sequence detection (MLSD) is proposed in [13], which could eliminate the ISI
at the expense of high complexity and large processing delay, which is not favorable
in practical applications. Decision feedback equalizers (DFEs) are proposed in [14],
which consist of a symbol-rate DFE, a chip-rate DFE, and a correcting-chip-rate
www.ebook3000.com

64
Figure 3.5 L-PPM system with chip-rate zero-forcing decision feedback equalizer.
DFE. A minimum mean squared error (MMSE) DFE is also derived in [15].
The multipath channel with ISI can be expressed as
y (t) = x (t) ⊗h (t) + n (t) ,
(3.17)
where x (t) and y (t) denote the transmitted and received signals, respectively. The
symbol ⊗indicates the convolution operation, and n (t) is the additive white Gaus-
sian noise. h (t) is the channel response and its frequency response is given by
H (f). The optical path loss can be calculated as
H (0) =
 ∞
−∞
h (t) dt,
(3.18)
and the received optical power is Pr = H (0) Pt.
The block diagram of an L-PPM system with the chip-rate zero-forcing DFE (ZF-
DFE) is illustrated in Fig. 3.5 [16]. The input bit sequences {aj} are sent to a block
encoder with the rate of log2 L/L, which generates length-L symbol vectors with
only one unit chip value and L −1 zero chip values. The chip sequences {bk} are
then scaled by LP for transmission. The eﬀects of transmitter ﬁlter, multipath chan-
nel, and whitened-matched ﬁlter are combined as a causal, minimum-phase discrete-
equivalent channel impulse response hk, which is normalized as 
k hk = 1. The
samples {nk} are AWGN noise with zero mean and variance of N0. In the chip-rate
ZF-DFE, the ﬁrst decision in the feedback loop in Fig. 3.5 makes chip-by-chip deci-
sions ˆb′
k, where ˆb′
k = 1 if rk > λ and ˆb′
k = 0 otherwise, and λ is the predeﬁned
threshold. Afterwards, the chip-by-chip decisions are fed back through a reverse ﬁlter
LP (hk −h0δk) containing the strictly causal portion of hk. The second decision
makes symbol-by-symbol decisions, based on which is the largest of the L sample
values rk −L + 1, ..., rk, independent of the chip-by-chip decision.
The transmitted PPM codeword is denoted as b = [b0 b1 · · · bL−1]T, and X
indicates the event that all previous chip decisions and symbol decisions from prior
PPM codewords are correct. When el is deﬁned as an L × 1 vector with all zeros

65
but a single one at position l ∈{0, 1, ..., L −1}, we have
P (symbol error|X)
(3.19)
= 1
L
L−1

l=0
P (error|X, b = el)
= 1
L
L−1

l=0
{P

error|X, ˆb′ = b, b = el

P

ˆb′ = b|X, b = el

+
l−1

j=0
P

error|X, ˆb′ −b = ej, b = el

P

ˆb′ −b = ej|X, b = el

+ P

error|X, ˆb′ = 0, b = el

P

ˆb′ = 0|X, b = el

+
L−1

j=l+1
P

error|X, ˆb′ −b = ej, b = el

P

ˆb′ −b = ej|X, b = el

+ P

error|X, wH

ˆb′ −b

≥2, b = el

P

wH

ˆb′ −b

≥2|X, b = el

},
where wH denotes the Hamming weight. For simplicity, we can rewrite (3.19) as
P (symbol error|X)
(3.20)
= 1
L
L−1

l=0
⎛
⎝P0π0 +
l−1

j=0
P1,jπ1,j + P2π2 +
L−1

j=l+1
P3,jπ3,j + P4π4
⎞
⎠.
Since a symbol error occurs only when a chip is wrong, it is obvious that the
symbol-decision error P0 = 0. For the ease of derivation, let ηk = LPrhk/√N0
denote the normalized impulse response, and the normalized threshold for the chip-
rate slicer is set to the minimax value λ = η0/2, which maximizes the probability
that all chips are successfully detected. The symbol-decision error P1,j in (3.20) oc-
curs when a chip j is detected above the threshold before the actual transmitted chip
l. Therefore, one noise sample is above λ, which is denoted as z1. The probability
of the symbol error P1,j is then given by
P1,j =1 −E{(1 −Q1,0 (z1 + η0 −ηl−j))j
(3.21)
× (1 −Q1,j (z1 + η0 −ηl−j))
×
L−1

i=j+1̸=l
(1 −Q (z1 + η0 −ηl−j + ηi−j))},
where
Q1,i (x) = max {(Q (x) −Q (λ + ηi−j))/(1 −Q (λ + ηi−j)) , 0} , i ̸= j,
(3.22)
www.ebook3000.com

66
and
Q1,j (x) = min {Q (x)/Q (λ) , 1} .
(3.23)
Besides, the probability of the event that one chip error happens before the trans-
mitted chip occurs is expressed as [16]
π1,j =(1 −Q (λ))jQ (λ)
l−1

i=j+1
(1 −Q (ηi−j + λ))
(3.24)
× Q (ηi−j −η0 + λ)
L−1

i=l+1
(1 −Q (ηi−j −ηi−l + λ)).
The symbol-decision error P2 in (3.20) indicates that the transmitted chip is not
detected, i.e., none of the L chips is greater than λ. Denoting z2 as the noise sample
in position l, which is smaller than λ, we have
P2 = 1 −E

(1 −Q2,0 (z2 + η0))l
L−1

i=l+1
(1 −Q2,l (z2η0 −ηi−l))

,
(3.25)
where Q2,i has the similar expression as Q1,i and ηi−j is replaced by ηi−l in (3.22).
The probability of the event that no chips are larger than λ is given by
π2 = (1 −Q (λ))l
L−l−1

i=0
Q (ηi −λ).
(3.26)
The symbol-decision error P3,j in (3.20) presents that the chip j is detected above
λ. Denoting z3 as the noise sample that is above the threshold, we have
P3,l = 1 −E
⎧
⎨
⎩(1 −Q1,0 (z3 + η0))j
L−1

i=j+1
(1 −Q1,i (z3 + η0 + ηi−j))
⎫
⎬
⎭.
(3.27)
The symbol-decision error P4 in (3.20) means that more than one chip is detected
incorrectly, which is diﬃcult to calculate. Therefore, we obtain a lower bound for
P (error|X) by simply setting P4 = 0, and an upper bound for P (error|X) by
setting P4 = (L −1) /L. The probability π4 can be calculated as π4 = 1 −
(π0 + π1 + π2 + π3), where π0 = 1 −LQ (λ) denotes the probability that all
chips are detected correctly.
The block diagram of an L-PPM system with the symbol-rate ZF-DFE is illustrated
in Fig. 3.6, which feedbacks symbol decisions instead of intermediate chip decisions.
Diﬀerent from its chip-rate counterpart, the feedback ﬁlter in the symbol-rate ZF-
DFE feedbacks appropriate information to cancel all postcursor ISI, but it does not
cancel intra-symbol interference. At each time k = JL −1, where J is an integer,

67
Figure 3.6 L-PPM system with symbol-rate zero-forcing decision feedback equalizer.
a symbol decision is made. The resultant length-L vector ˆbk−L+1, ...,ˆbk is passed
to the feedback ﬁlter and generates the output as
zk = LP
Ns−1

i=1
(bk−iL+liδk ⊗hk+iL−liuk),
(3.28)
where li ∈{0, 1, ..., L −1} , i = 1, 2, ..., Ns −1 represent the symbols already
detected previously, and Ns is the largest number of symbols that can be spanned by
hk. The received samples rk−L+1, ..., rk are passed through a minimum-Euclidean-
distance detector, and the symbol decision module selects the detected symbol which
minimizes
L−1

k=0
			rk −LP

ˆbk ⊗hk
			
2
.
Since only one pulse is “on” during one symbol duration, the spectral eﬃcien-
cy of PPM is limited. Several variants of modulation schemes have been proposed
recently. Figure 3.7 provides several examples of the modiﬁed PPM schemes. Dif-
ferential PPM (DPPM) is a simple modiﬁcation of PPM, which omits the “oﬀ” chips
when the “on” chip appears [17]. As a result, less time is required to convey the
same information, and symbols have unequal durations. Since DPPM has variable
symbol durations, the receiver does not know the symbol boundaries, MLSD is pre-
ferred to be used in the optimal soft-decision decoder, which has high complexity. If
]hard-decision decoder is used, it might be easier to decode DPPM than PPM since
the former does not require symbol-level timing recovery. For a ﬁxed modulation
order L, DPPM requires much less bandwidth and slightly more power than PPM
because of the reduced duty cycle. It was indicated in [12] that 16-DPPM achieved
3.1 dB optical power gain compared with 4-PPM with only 6% increased bandwidth.
Multipulse PPM (MPPM) achieves an increased spectral eﬃciency with more than
one “on” chip in a single symbol duration [18]. Besides, MPPM has lower PAPR
compared with PPM. Overlapping PPM (OPPM) is a generalization of conventional
PPM, which also transmits more than one “on” consecutive chip in a symbol dura-
tion [19]. However, the “on” chips in diﬀerent symbols can be overlapped. It was
shown in [19] that OPPM could not only achieve a higher spectral eﬃciency com-
pared to PPM, but also support dimming control. Expurgated PPM (EPPM) was
www.ebook3000.com

68
Figure 3.7 Examples of modiﬁed PPM schemes.
proposed in [20, 21], where the symbols in the MPPM are expurgated to maximize
the inter-symbol distance. It can achieve the same spectral eﬃciency as PPM and
provide dimming support in VLC systems at the same time since it can realize ar-
bitrary levels of illumination by changing the number of pulses per symbol and the
length of the symbol. Moreover, it can mitigate the ﬂickering with multiple pulses in
a single symbol duration. In the IEEE 802.15.7 standard, variable PPM (VPPM) is
used, which is a hybrid of PPM and pulse width modulation (PWM) [3]. In VPPM,
the bits are encoded by the position of pulse similar to PPM. Meanwhile, the pulse
width could be adjusted as well. Therefore, dimming control can be achieved and the
simplicity and robustness inherited from PPM can be maintained.
3.3
Carrierless amplitude phase modulation
CAP was ﬁrstly developed by Bell Labs as a variant of quadrature amplitude modula-
tion (QAM) [22, 23]. Due to its high spectral eﬃciency and simple implementation,
CAP has been successfully employed in asymmetric digital subscriber line (ADSL).
Recently, it is also considered as a promising modulation format for optical ﬁber
communications and visible light communications [24–30].

69
 
 
(a) CAP transmitter
 
 
(b) CAP receiver
Figure 3.8 Diagram of CAP transceiver.
3.3.1
Principles of CAP
CAP is a bandwidth-eﬃcient two-dimensional (2-D) passband transmission scheme.
The basic principle of CAP is to choose two orthogonal ﬁlters to modulate two dif-
ferent data streams, which are combined for simultaneous transmission. Those two
orthogonal ﬁlters can be obtained by multiplying a root raised cosine (RRC) ﬁlter
with sine or cosine functions, which are given by [31]
f0 (t) = g (t) cos (2πfct) ,
(3.29)
f1 (t) = g (t) sin (2πfct) ,
where g (t) is the RRC ﬁlter with roll-oﬀfactor α, fc is the symbol frequency, which
is larger than the highest frequency in g (t).
The diagram of CAP transceiver is shown in Fig. 3.8. The data stream is encoded
into two independent symbol streams {s0,k} and {s1,k}, which are modulated by
their corresponding orthogonal ﬁlters. The combined signal is given by
x (t) =
∞

k=−∞

s0,kf0

t −k
fc

+ s1,kf1

t −k
fc

.
(3.30)
At the receiver, the receiving ﬁlters g0 (t) and g1 (t) are used to invert the channel
response and transmitting ﬁlters, which are then used for decoding. Several tech-
niques have been proposed for data recovery, including the linear equalizer and the
decision feedback equalizer [31]. In order to achieve perfect reconstruction perfor-
mance, a fractionally spaced linear equalizer (FSLE) can be utilized together with a
training sequence to update the ﬁlter taps adaptively via the least mean square (LMS)
algorithm [31].
www.ebook3000.com

70
Figure 3.9 Diagram of CAP as a multirate transmultiplexer.
Alternatively, the CAP transceiver can be regarded as a transmultiplexer. The shap-
ing ﬁlter at the transmitter is implemented by an upsampled ﬁnite impulse response
(FIR) window from the original continuous-time noncausal signal, while the equaliz-
er at the receiver is downsampled to match the original symbol rate. The upsampling
and downsampling factor ζ is chosen carefully considering the tradeoﬀbetween per-
formance and implementation complexity. In particular, ζ = 4 would be a reason-
able choice [31], and the corresponding diagram of the transmultiplexer is illustrated
in Fig. 3.9. When perfect reconstruction is considered, the CAP transceiver topology
is an obvious multirate transmultiplexer, which can be written as

ˆs0
ˆs1

= T

s0
s1

,
(3.31)
where T is the overall system transfer matrix given by
T = G (z) ΓF (z) ,
(3.32)
where
G
ejω =
G0
 ω
4

G0
 ω
4 + π
2

G0
 ω
4 + π

G0
 ω
4 + 3π
2

G1
 ω
4

G1
 ω
4 + π
2

G1
 ω
4 + π

G1
 ω
4 + 3π
2


(3.33)
denotes the type I polyphase decomposition of the receiver ﬁlter bank, and
F
ejω =
⎛
⎜
⎜
⎝
F0
 ω
4

F1
 ω
4

F0
 ω
4 + π
2

F1
 ω
4 + π
2

F0
 ω
4 + π

F1
 ω
4 + π

F0
 ω
4 + 3π
2

F1
 ω
4 + 3π
2

⎞
⎟
⎟
⎠
(3.34)
is the type II polyphase decomposition of the transmitter ﬁlter bank [32]. Γ is a
permutation matrix representing the fractional delay in the receiver downsampling.
F0, F1, G0, and G1 denote the corresponding discrete-time Fourier transforms for
the ﬁlters f0, f1, g0, and g1, respectively. In order to achieve perfect reconstruction

71
performance, T should satisfy
T = z−nI,
(3.35)
which only contains the identity matrix I and n delay elements z−n. Since n does
not have to be a multiple of the symbol period in (3.7), the fractional part of the delay
should be adjusted accordingly. Moreover, if the transmitter polyphase decomposi-
tion matrix F is paraunitary, i.e.,
F −1 = z−mF H,
(3.36)
the perfect reconstruction receiver would be the matched ﬁlter pair of the transmitter.
Since the CAP system utilizes shaping waveforms which span over multiple symbol
periods, the Hilbert pair constitutes a nonparaunitary system with the receiver ﬁlters.
Therefore, the unique minimum norm solution can be derived for the underdeter-
mined system, which is given by
(P (f0)) g0 = δ,
(3.37)
(P (f1)) g0 = O,
(P (f0)) g1 = O,
(P (f1)) g1 = δ,
where g0 and g1 are the vectors of samples corresponding to the receiver ﬁlters g0
and g1. P (·) is a permutation matrix of the transmitter ﬁlter, O is a vector with all
the elements being zero, and δ is a vector with all zero elements but one ’1’ in the
middle.
From (3.30), the transmitted signal x(t) is a cyclostationary random process with
the period T = 1/fc for both PAM and CAP, and we can restrict analysis to the time
interval (0, T] for simplicity. Furthermore, even when the roll-oﬀfactor is extremely
small, i.e., α = 0.99, 99% of the energy is still constrained in K = 2000 symbol
periods [33]. When only K symbols are considered, the signals for PAM and CAP
are given by
xPAM (t) =
K

k=1
skfk (t)
(3.38)
and
xCAP (t) =
K

k=1
(s0,kf0,k (t) + s1,kf1,k (t)) ,
(3.39)
where fk (t) = f (t −(k −K/2) T), f0,k (t) = f0 (t −(k −K/2) T), and
f1,k (t) = f1 (t −(k −K/2) T). Denote xPAM
k
(t) and xCAP
k
(t) as
xPAM
k
(t) = skfk (t) ,
(3.40)
www.ebook3000.com

72
and
xCAP
k
(t) = s0,kf0,k (t) + s0,kf0,k (t) ,
(3.41)
it is obvious that (3.38) and (3.39) are the sum of xPAM
k
(t) and xCAP
k
(t). The signal
can be considered as an interference of past and future symbols multiplied by the
ﬁlter response with diﬀerent time shifts. To calculate the PAPR for both PAM and
CAP, the characteristic functions of (3.40) and (3.41) are exploited. Speciﬁcally,
for a random variable X, its characteristic function is given by the inverse Fourier
transform of its probability density function (PDF) [33]
ϕX (f) = E

ej2πX
=
 ∞
−∞
pX (x) ej2πxdx,
(3.42)
where pX (x) is the PDF. Therefore, the characteristic function of M-ary PAM is
expressed as
ϕxPAM
k
(t) (f) = 2
M
M/2

m=1
cos (2πffk (t) smcPAM),
(3.43)
where {sm} is the constellation set for PAM and cPAM is the corresponding normal-
ization factor to maintain the average energy of the constellations as1.Oeieh]nhupda
characteristic functions for two-dimensional CAP are given by
ϕxCAP
0,k(t) (f) =
2
√
M
√
M/2

m=1
cos (2πff0,k (t) smcCAP),
(3.44)
ϕxCAP
1,k(t) (f) =
2
√
M
√
M/2

m=1
cos (2πff1,k (t) smcCAP).
Therefore, the characteristic functions of both PAM and CAP signals in (3.38) and
(3.39) are written as
ϕxPAM(t) (f) =
K

k=1
ϕxPAM
k
(t) (f),
(3.45)
and
ϕxCAP(t) (f) =
K

k=1
ϕxCAP
0,k(t) (f) ϕxCAP
1,k(t) (f).
(3.46)
After Fourier transform, the PDFs of xPAM (t) and xCAP (t) can be obtained. When
x (t) is used to replace either xPAM (t) or xCAP (t), and px(t) (x) is deﬁned as its PDF,
we have
pX (x) = 1
T
 ∞
0
px(t) (x) dt,
(3.47)

73
0
0.2
0.4
0.6
0.8
1
3
4
5
6
7
8
9
10
11
12
13
α
PAPR (dB)
2PAM
4PAM
8PAM
CAP−4
CAP−16
CAP−64
Figure 3.10 PAPR at CCDF = 10−5 for PAM and CAP.
and the complementary cumulative distribution function (CCDF) is given by
ΘX (z) =
 ∞
z
pX (x) dx.
(3.48)
The calculation of the characteristic functions can be implemented by fast Fourier
transform (FFT) and inverse fast Fourier transform (IFFT), which have low complex-
ity. When the interval (0, T] is equally divided into 64 parts, the amplitude range is
limited to (-32, 32) and the size of FFT/IFFT is set to 216, Fig. 3.10 illustrates the
required PAPR at CCDF = 10−5 for CAP and PAM, where CAP-4, CAP-16, and
CAP-64 employ 2PAM, 4PAM, and 8PAM in each dimension, respectively. It can be
seen that the PAPR of CAP is always higher than PAM when the same modulation
order is applied, and their PAPRs vary when the ﬁlter roll-oﬀfactor α changes.
3.3.2
Multidimensional CAP
In conventional 2-D CAP, two orthogonal ﬁlters are generated by multiplying a single
RRC ﬁlter with sine or cosine functions, which are used to modulate two diﬀerent
data streams. If the third orthogonal ﬁlter is adopted, one additional data stream can
be transmitted, which is referred to as 3-D CAP and can be seen as an extension of
the conventional 2-D CAP. Denoting the 3-D symbol vector as sk = [s0,k s1,k s2,k],
and the orthogonal ﬁlters as f0 (t), f1 (t), and f2 (t), the combined 3-D CAP signal
www.ebook3000.com

74
Figure 3.11 Diagram of 3-D CAP as a multirate transmultiplexer.
can be generated as
x (t) =
∞

k=−∞
2

i=0
si,kfi

t −k
fc

.
(3.49)
The diagram of 3-D CAP is illustrated in Fig. 3.11, which is obviously an exten-
sion of the 2-D CAP. The upsampling and downsampling factors are still ζ = 4.
Therefore, the symbol rate per dimension remains unchanged, leading to increased
overall throughput. However, in order to allow for the extra dimension, the excess
bandwidth of the shaping ﬁlter should be increased as well. Fortunately, it has no
eﬀect on the performance for additive white noise over a ﬂat channel [34]. Besides,
increasing excess bandwidth might achieve better performance than increasing either
the symbol rate or the number of bits per symbol [31]. Since there exist more than
two orthogonal shaping ﬁlters, the original Hilbert pair signals do not work well.
It is illustrated in [35] that when the upsampling factor is 4, perfect reconstruction
performance can be maintained for up to four orthogonal ﬁlters. However, it has to
use the entire sampling range and surpass the allowed frequency bandwidth, which
is unfavorable for actual VLC systems. Therefore, only three ﬁlters are designed in
the 3-D CAP system.
The input data is ﬁrstly divided into three bit streams, which are listed in the vector
form as [s0,k s1,k s2,k]. The output [ˆs0,k ˆs1,k ˆs2,k] after the multirate transmulti-
plexer should be as close as possible to [s0,k s1,k s2,k]. Afterwards, the receiver-
side equalizer can be used to achieve the perfect reconstruction. Similar to (3.32),
the transmultiplexer can be modeled as the multiple-input multiple-output transfer

75
matrix, where the polyphase decomposition of the ﬁlters can be rewritten as
G
ejω =
⎛
⎝
G0
 ω
4

G0
 ω
4 + π
2

G0
 ω
4 + π

G0
 ω
4 + 3π
2

G1
 ω
4

G1
 ω
4 + π
2

G1
 ω
4 + π

G1
 ω
4 + 3π
2

G2
 ω
4

G2
 ω
4 + π
2

G2
 ω
4 + π

G2
 ω
4 + 3π
2

⎞
⎠, (3.50)
and
F
ejω =
⎛
⎜
⎜
⎝
F0
 ω
4

F1
 ω
4

F2
 ω
4

F0
 ω
4 + π
2

F1
 ω
4 + π
2

F2
 ω
4 + π
2

F0
 ω
4 + π

F1
 ω
4 + π

F2
 ω
4 + π

F0
 ω
4 + 3π
2

F1
 ω
4 + 3π
2

F2
 ω
4 + 3π
2

⎞
⎟
⎟
⎠.
(3.51)
Usually, the adaptive equalizer at the receiver side is preferred to be implemented
by an FIR ﬁlter instead of an inﬁnite impulse response (IIR) ﬁlter. The problem to
ﬁnd three input signals can be modeled as an optimization problem traversing the
entire space and several constraints have to be included in the optimization problem.
The perfect reconstruction condition should be satisﬁed, and the frequency-domain
characteristics should be as close as possible to the raised-cosine frequency char-
acteristics since the latter has relatively reliable performance in the VLC link. The
minimax optimization was performed in [31] to ﬁnd three signals based on the se-
quential quadratic programming method [36]. In the optimization problem, three
signals {f0, f1, f2} are solved at the same time, aiming to minimize the ∞-norm of
the diﬀerence in frequency domain [31]
min
{f0,f1,f2} {max (|H −R|)} subject to
G (z) ΓF (z) = z−nI,
(3.52)
where H denotes the frequency magnitude characteristic for a given signal fi ∈
{f0, f1, f2}, R represents the required passband frequency magnitude response, and
F is the polyphase decomposition of fi.
The calculation of matrix G is completed by computing the polyphase decom-
position of the receiver corresponding to three ﬁlters {f0, f1, f2}, while ﬁlters at
the receiver are obtained by directly computing the unique minimum norm solution
of the underdetermined problem, which maximizes the signal-to-noise ratio (SNR)
when channel distortion is not considered. Figure 3.12(a) illustrates the time-domain
waveform of three signals obtained by the minimax optimization algorithm, and their
corresponding frequency responses are demonstrated in Fig. 3.12(b).
From Fig. 3.12(b), the frequency responses of three solved signals are nonzero at
high frequency. Nevertheless, only negligible transmitted power is allocated. Com-
pared with 2-D CAP with the same bandwidth and modulation order per dimension,
there exists some kind of SNR penalty in 3-D CAP when near-end cross-talk is con-
sidered [37]. However, to achieve the same throughput, the modulation order of the
conventional 2-D CAP has to be enlarged and its required SNR becomes higher. For
example, if 4PAM is adopted in each dimension of 3-D CAP, 2-D CAP needs to
employ 8PAM in each dimension to maintain the same throughput, which requires
around 6 dB receiver sensitivity improvement. Another merit of 3-D CAP is to serve
three users simultaneously in a multiple access manner.
www.ebook3000.com

76
−3
−2
−1
0
1
2
3
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Symbol Time Steps
Time−Domain Dignal
 f0
 f1
 f2
(a) Time-domain waveform
0
0.2
0.4
0.6
0.8
1
0
0.5
1
1.5
2
2.5
Normalized Frequency
Normalized Frequency Response
 f0
 f1
 f2
(b) Frequency response
Figure 3.12 The three signals solved using the minimax optimization algorithm.

77
3.4
Modulation and coding schemes for dimmable VLC
In indoor VLC systems, communication and illumination should be maintained at the
same time, where the light can be dimmed to satisfy various illumination and power
requirements [38]. Besides, dimming technology is preferred to be energy eﬃcient.
As illustrated in Fig. 3.13, the LEDs can be dimmed at daytime to save energy, while
high optical power is required at night to provide suﬃcient illumination. However,
the dimming operation will inevitably interfere with the communication function of
VLC systems since it will alter the received optical power and SNR. The conventional
modulation schemes should be modiﬁed to support dimming control, and coding
schemes should be combined to achieve reliable performance.
Figure 3.13 Visible light communications with dimming control.
The inherent nonlinearity of LEDs is a challenge for orthogonal frequency division
multiplexing (OFDM) methodology since OFDM has high PAPR. The input of an
LED has a minimum threshold value that can generate current, which is referred to
as turn-on voltage (TOV). When the input voltage is above the TOV, the voltage-
current and current-power characteristics are nonlinear. Several methods have been
proposed to mitigate the eﬀect of LED nonlinearity, where the transfer characteristic
of the LED is considered to be quasi-linear in a limited range after predistortion.
That is, if vmin and vmax are denoted as the minimum and maximum allowed signals
according to the voltage levels permitted by LED, the transfer characteristic of the
LED between [vmin, vmax] is assumed to be linear. Speciﬁcally, the relationship
between the emitted optical power and the input voltage is given by
Popt(t) =
⎧
⎪
⎨
⎪
⎩
0,
v(t) < vmin,
η (v(t) −vmin) ,
vmin ≤v(t) ≤vmax,
η (vmax −vmin) ,
v(t) > vmax,
(3.53)
www.ebook3000.com

78
where η and v(t) are the voltage-power transfer coeﬃcient and instantaneous input
voltage, respectively.
Since the illumination level is proportional to the average emitted optical pow-
er, dimming control can be implemented by adjusting the average optical power of
LEDs. The measured dimming level d is deﬁned as
d = E (Popt(t)) / (η (vmax −vmin)) ,
(3.54)
which obviously falls in the interval [0, 1]. When the required dimming level is
adjusted, the received optical power and eﬀective SNR are changed, which will in-
evitably alter the achievable data rate for a given BER requirement. The modulation
schemes preferred for VLC systems should support relatively high data rate under
diﬀerent dimming targets.
3.4.1
Modulation schemes for dimmable VLC
The dimming control for OOK and PAM can be achieved by changing the intensity
levels of the symbols. It can keep the symbol rate constant when diﬀerent dimming
level is required, the required SNR is however changed, and the modulation order
should be decreased at some time to maintain the BER performance. Alternatively,
one can keep the levels of information symbols unchanged and adjust the average duty
cycle of the waveform by inserting some compensation symbols, which can be fully
on or oﬀduring the required time interval to provide dimming performance. It can
be regarded as a DC bias added to the waveform, which is positive when the required
optical power is high and negative otherwise. For example, if the average intensity of
information data is A with period T1 and the average intensity of the compensation
symbols is B with period T2, the resulting average intensity is expressed as [39]
N = AT1 + BT2
T1 + T2
.
(3.55)
Apparently, this compensation scheme results in diﬀerent symbol rate when the
dimming level changes.
An example of OOK is illustrated in Fig. 3.14, where
Fig. 3.14(a) is the original OOK signal, Figs. 3.14(b) and 3.14(c) show the dimmed
signal with d = 30% and d = 70%, respectively.
Another modulation scheme is variable OOK (VOOK), which inserts zero to the
“on” chip when the dimming level is below 50% and one to the “oﬀ” chip when
the dimming level is above 50% [40]. In this way, the average emitted optical power
could be altered. The dimming control of PPM can be achieved via VPPM introduced
in Section 3.2, which is similar to VOOK. For MPPM, the symbol duration T is
divided into n chips, and w (1 ≤w ≤n) optical pulses are emitted during one
symbol duration. For adjusting dimming level, the number of optical pulses w should
be modiﬁed and the dimming factor of MPPM can be written as
d = w
n .
(3.56)

79
(a) d = 50%
(b) d = 30%
(c) d = 70%
Figure 3.14 An example of the compensation scheme for OOK.
Speciﬁcally, the system is under full brightness when w = n, and d = 100%.
n diﬀerent dimming levels could be supported, which are 1, (n −1) /n, ..., 1/n,
respectively. The MPPM symbol is given by x (t) = n−1
i=0 cirect (nt/T −i),
where c = [c0 c1 · · · cn−1] is a binary vector with length n and weight w, rect (t)
is deﬁned as one for 0 ≤t ≤1 and zero for otherwise.
The power requirement and spectral eﬃciency for these modulation schemes under
dimming control are analyzed. When high SNR is considered, the BER is dom-
inated by the nearest two diﬀerent symbols, which can be well approximated as
Q (Dmin/2σ), where Dmin is the minimum Euclidean distance between arbitrary
two symbols. OOK is used as a benchmark for comparison. The power required
to achieve the same BER as OOK is deﬁned as P ≈(DOOK/Dmin) POOK and
POOK = Q−1 (BER) √N0Rb, and Rb is the bit rate. The Euclidean distance of
VOOK is given by
DVOOK =
⎧
⎨
⎩
P

2d
Rb ,
0 ≤d ≤0.5,
P

2(1−d)
Rb
,
0.5 < d ≤1.
(3.57)
The ratio of DOOK to DVOOK indicates that there is a power increase in VOOK
www.ebook3000.com

80
compared with OOK. The Euclidean distance of VPPM is given by
DVPPM =
⎧
⎨
⎩
P

2d
Rb ,
0 ≤d ≤0.5,
P

2(1−d)
Rb
,
0.5 < d ≤1,
(3.58)
which is the same as VOOK. Therefore, the required power for VPPM is the same as
that for VOOK.
For MPPM, the minimum distance is expressed as
DMPPM = (P/n)

2n log2
n
w

/Rb,
(3.59)
which is altered according to diﬀerent dimming requirements. The spectral eﬃcien-
cies of VOOK and VPPM are given by
νVOOK =

2d,
0 ≤d ≤0.5,
2 (1 −d) ,
0.5 < d ≤1,
(3.60)
and
νVPPM =

d,
0 ≤d ≤0.5,
(1 −d) ,
0.5 < d ≤1,
(3.61)
respectively. It can be seen that VOOK could realize twice the spectral eﬃciency of
VPPM, while the spectral eﬃciency of MPPM can be expressed as
νMPPM =
n
w

/n.
(3.62)
3.4.2
Coding schemes for dimmable VLC
In addition to the modulation schemes, coding is also considered in the design of
dimming support. In the IEEE 802.15.7 standard, convolutional code and Reed-
Solomon code are employed for forward error correction (FEC). After FEC encoding,
run length limited (RLL) line encoding is adopted to provide DC balance and ﬂicker
mitigation, which includes Manchester, 4B6B, and 8B10B codes [41].
Apart from the RLL line coding, the source coding can be redesigned to increase
the data rate. For a given codeword length, the construction of the codebook should
contain as many codewords as possible. The inverse source coding (ISC) employs
inverse mapping of lossless compression for OOK/PAM signals, and has been im-
plemented with a reversal of practical Huﬀman encoding [42]. Since the Huﬀman
code can achieve optimal lossless compression, ISC could achieve the maximal data
rate for a given dimming target. It can also be extended to M-PAM signals [43].
For a given dimming target d, the ratio of transmitting “1” and “0” is d : 1 −d.
Therefore, the maximum eﬃciency is determined by the entropy as
Ep = −d log2 d −(1 −d) log2 (1 −d) .
(3.63)

81
In order to achieve the maximum data rate in (3.63), the distribution of data bits
has to be adjusted, where the probability of “1” is d while the probability of “0” is
1 −d. It is the inverse operation of source coding, which is referred to as ISC.
The ratio of the eﬃciency of ISC and its compensation scheme is given by [39]
Ep
E0
=
 −d log2 d−(1−d) log2(1−d)
2d
,
0 < d ≤0.5,
−d log2 d−(1−d) log2(1−d)
2(1−d)
,
0.5 < d < 1,
(3.64)
where E0 is the eﬃciency of the compensation scheme. It can be seen that the upper
bound of ISC is better than the compensation scheme, except for the cases that d = 0,
0.5, or 1 when both schemes have the same performance. When the dimming target
stays far from 50%, large performance gain can be achieved by ISC. Speciﬁcally, for
the dimming target of 29% or 71%, the performance gain is 50% and it is increased to
100% when the dimming target becomes 16% or 84%. Even though the performance
improvement is huge when the dimming target is close to 0 or 100%, the absolute
value becomes very small, which is not preferred for data transmission. When the re-
quired data rate is set to at least 50% of the maximum transmission rate, the dimming
target should be within the range [11%, 89%]. The dimming range could be extend-
ed to [3.1%, 96.9%] when the required data rate is set to only 20% of the maximum
transmission rate.
An example of ISC was proposed in [42], which employed Huﬀman codes to trans-
form the data with equal distribution of “0” and “1” to the data with the probability
of d for “1” and the probability of 1 - d for “0”. For example, if the dimming target
is set to d = 70%, the probabilities of “1” and “0” should be 70% and 30%, respec-
tively. When Huﬀman encoding is used to compress the data, since the probability
of “1” is high, the following bit after “1” has to be jointly considered. An exam-
ple of Huﬀman encoding is listed in Table 3.1, where the probability of “1” is 70%.
The average lengths of the codewords before and after encoding are 1.7 and 1.51,
respectively, where the compression ratio is 0.888. The entropy for 70% dimming is
0.881 according to (3.63). As a result, more than 94% compression is achieved com-
pared to its optimum solution. Table 3.2 is the inverse operation of Table 3.1, which
transforms the evenly distributed binary data to the data with 70% of “1” by inverse
Huﬀman coding. The average lengths before and after inverse Huﬀman encoding
are 1.5 and 1.75, respectively, and the decompression ratio is 1.17. The resultant
dimming level is around 71.4%, which is close to the target value of 70%. If more
bits are included in Huﬀman and inverse Huﬀman encoding, the achievable dimming
level will be more close to the required dimming target.
To facilitate arbitrary dimming targets in noisy environments, the codebook is de-
signed to select binary sequences with nonuniform probability, which equals the dim-
ming target. However, only a subset of codewords should be chosen so that their
elements are separated far enough from each other in Hamming distance to pro-
vide error correcting capability. To facilitate practical implementation, the rules of
both encoder and decoder should abide by linear property. Therefore, feasible dim-
ming targets are discrete rather than arbitrary. The codebook generated from a linear
codebook where all codewords have constant Hamming weight is a useful choice for
www.ebook3000.com

82
Table 3.1 An example of Huﬀman encoding.
Symbol/Length
Probability
Codeword/Length
0/1
0.3
00/2
10/2
0.21
01/2
11/2
0.49
1/1
Table 3.2 An example of inverse Huﬀman encoding.
Symbol/Length
Probability
Codeword/Length
00/2
0.25
0/1
01/2
0.25
10/2
1/1
0.5
11/1
dimming support, and was applied to Reed–Muller (RM) codes in [44]. Since only
dimming target in the form of 1/2b, b = 1, 2, ..., could be bolstered, it needs to
be combined with compensation symbol insertion to support an arbitrary dimming
level.
Although a codebook with the constant-weight property has a sub-exponential
number of codewords, its code rate might be less than actual achievable rate required
by high throughput transmission [41]. Therefore, it is not preferred for high-rate
transmission and the constraint of constant-weight has to be relaxed to furnish more
choices of code rates, which is realistic since the dimming requirement is imposed
on the average optical power instead of the instantaneous optical power. For exam-
ple, by scrambling a linear codeword with a random sequence, the dimming target
of d = 0.5 can be easily realized. The weight of a codeword can be viewed as a bi-
nomial random variable, and dimming level is represented by the weight divided by
the codeword length, which is also treated as a random variable. Its mean value is
the dimming target and its variance is inversely proportional to the codeword length.
In order to facilitate arbitrary dimming target, puncturing technique can be applied
to the convolutional code and turbo code [45, 46]. However, puncturing does not
perform well in the low dimming region since lots of useful bits might be pruned
away.
3.5
Conclusion
In this chapter, single carrier and carrierless modulation schemes have been intro-
duced for VLC systems. Speciﬁcally, PAM with frequency-domain equalization and
PPM with decision feedback equalization are presented to combat ISI caused by mul-
tipath distortion and their BER performances are analyzed. In order to overcome the
eﬀect of LED nonlinearity, PAM can be implemented with multiple LEDs and each

83
LED is modulated by OOK independently. Besides, 2-D CAP is also addressed due
to its high spectral eﬃciency and simple implementation, which is then extended to
multidimensional CAP in order to improve the spectral eﬃciency. Finally, various
modulation and coding schemes have been illustrated for dimming control in single
carrier VLC systems to support communication and illumination simultaneously.
www.ebook3000.com


85
References
1 G. Stepniak, M. Schuppert, and C. A. Bunge,
“Advanced modulation formats in
phosphorous LED VLC links and the impact
of blue ﬁltering,” J. Lightw. Technol.,
vol. 33, no. 21, pp. 4413–4423, Nov. 2015.
2 D. J. F. Barros, S. K. Wilson, and
J. M. Kahn, “Comparison of orthogonal
frequency-division multiplexing and
pulse-amplitude modulation in indoor
optical wireless links,” IEEE Trans.
Commun., vol. 60, no. 1, pp. 153–163,
Jan. 2012.
3 IEEE Std. 802.15.7-2011, Part 15.7:
Short-Range Wireless Optical
Communication Using Visible Light, Sep.
2011.
4 N. Fujimoto and H. Mochizuki, “477 Mbit/s
visible light transmission based on
OOK-NRZ modulation using a single
commercially available visible LED and a
practical LED driver with a pre-emphasis
circuit,” in Proc. Optical Fiber
Communication Conference and Exposition
and the National Fiber Optic Engineers
Conference (OFC/NFOEC) 2013 (Anaheim,
CA), Mar. 17–21, 2013, JTh2A. 73.
5 B. Fahs, A. J. Chowdhury, and M. M. Hella,
“A 12-m 2.5-Gb/s Lighting Compatible
Integrated Receiver for OOK Visible Light
Communication Links,” J. Lightw. Technol.,
vol. 34, no. 16, pp. 3768–3775, Aug. 2016.
6 X. Li, N. Bamiedakis, X. Guo,
J. J. D. McKendry, E. Xie, R. Ferreira,
E. Gu, M. D. Dawson, R. V. Penty, and
I. H. White, “Wireless visible light
communications employing feed-forward
pre-equalization and PAM-4 modulation,” J.
Lightw. Technol., vol. 34, no. 8,
pp. 2049–2055, Apr. 2016.
7 A. Nuwanpriya, S. W. Ho, J. A. Zhang,
A. J. Grant, and L. Luo, “PAM-SCFDE for
optical wireless communications,” J. Lightw.
Technol., vol. 33, no. 14, pp. 2938–2949,
Jul. 2015.
8 K. Lee, H. Park, and J. Barry, “Indoor
channel characteristics for visible light
communications,” IEEE Commun. Lett.,
vol. 15, no. 2, pp. 217–219, Feb. 2011.
9 Y. P. Lin and S. M. Phoong, “BER
minimized OFDM systems with channel
independent precoders,” IEEE Trans. Signal
Process., vol. 51, no. 9, pp. 2369–2380,
Sep. 2003.
10 J. F. Li, Z. T. Huang, R. Q. Zhang,
F. X. Zeng, M. Jiang, and Y. F. Ji,
“Superposed pulse amplitude modulation for
visible light communication,” Opt. Exp.,
vol. 21, no. 25, pp. 31006–31011, Dec. 2013.
11 A. Yang, Y. Wu, M. Kavehrad, and G. Ni,
“Grouped modulation scheme for led array
module in a visible light communication
system,” IEEE Wirel. Commun., vol. 22,
no. 2, pp. 24–28, Apr. 2015.
12 J. M. Kahn and J. R. Barry, “Wireless
infrared communications,” Proc. IEEE,
vol. 85, no. 2, pp. 265–298, Feb. 1997.
13 M. D. Audeh, J. M. Kahn, and J. R. Barry,
“Performance of pulseposition modulation
on measured nondirected indoor infrared
channels,” IEEE Trans. Commun., vol. 44,
no. 6, pp. 654–659, Jun. 1996.
14 J. R. Barry, “Sequence detection and
equalization for pulse-position modulation,”
in Proc. IEEE International Conference on
Communications (ICC) 1994 (New Orleans,
LA), May 1–5, 1994, pp. 1561–1565.
15 A. G. Klein and P. Duhamel,
“Decision-feedback equalization for
www.ebook3000.com

86
pulse-position modulation,” IEEE Trans.
Signal Process., vol. 55, no. 11,
pp. 5361–5369, Nov. 2007.
16 M. D. Audeh, J. M. Kahn, and J. R. Barry,
“Decision-feedback equalization of
pulse-position modulation on measured
nondirected indoor infrared channels,” in
IEEE Trans. Commun., vol. 47, no. 4,
pp. 500–503, Apr. 1999.
17 D. S. Shiu and J. M. Kahn, “Diﬀerential
pulse-position modulation for
power-eﬃcient optical communication,”
IEEE Trans. Commun., vol. 47, no. 8,
pp. 1201–1210, Aug. 1999.
18 H. Sugiyama and K. Nosu, “MPPM: A
method for improving the band-utilization
eﬃciency in optical PPM,” J. Lightw.
Technol., vol. 7, no. 3, pp. 465–472,
Mar. 1989.
19 B. Bai, Z. Xu, and Y. Fan, “Joint LED
dimming and high capacity visible light
communication by overlapping PPM,” in
Proc. Wireless and Optical Communications
Conference (WOCC) 2010 (Shanghai,
China), May 14–15, 2010, pp. 1–5.
20 M. Noshad and M. Brandt-Pearce,
“Expurgated PPM using symmetric balanced
incomplete block designs,” IEEE Commun.
Lett., vol. 16, no. 7, pp. 968–971, Jul. 2012.
21 M. Noshad and M. Brandt-Pearce,
“Application of expurgated PPM to indoor
visible light communications-Part I:
Single-user systems,” J. Lightw. Technol.,
vol. 32, no. 5, pp. 875–882, Mar. 2014.
22 G. H. Im and J. J. Werner,
“Bandwidth-eﬃcient digital transmission up
to 155 Mb/s over unshielded twisted pair
wiring,” in Proc. IEEE International
Conference on Communications (ICC) 1993
(Geneva, Switzerland), May 23–26, 1993,
vol. 3, pp. 1797–1803.
23 G. H. Im and J. J. Werner,
“Bandwidth-eﬃcient digital transmission
over unshielded twisted-pair wiring,” IEEE
J. Sel. Areas Commun., vol. 13, no. 9,
pp. 1643–1655, Dec. 1995.
24 J. L. Wei, J. D. Ingham, D. G. Cunningham,
R. V. Penty, and I. H. White, “Performance
and power dissipation comparisons between
28 Gb/s NRZ, PAM, CAP and optical
OFDM systems for data communication
applications,” J. Lightw. Technol., vol. 30,
no. 20, pp. 3273–3280, Oct. 2012.
25 F. M. Wu, C. T. Lin, C. C. Wei,
C. W. Chen, H. T. Huang, and C. H. Ho, “1.1
Gb/s white-LED-based communication
employing carrier-less amplitude and phase
modulation,” IEEE Photon. Technol. Lett.,
vol. 24, no. 19, pp. 1730–1732, Oct. 2012.
26 J. L. Wei, D. G. Cunningham, R. V. Penty,
and I. H. White, “Study of 100 gigabit
ethernet using carrierless amplitude/phase
modulation and optical OFDM,” J. Lightw.
Technol., vol. 31, no. 9, pp. 1367–1373,
May 2013.
27 L. Tao, Y. Ji, J. Liu, A. P. T. Lau, N. Chi,
and C. Lu, “Advanced modulation formats
for short reach optical communication
systems,” IEEE Netw., vol. 27, no. 6,
pp. 6–13, Nov./Dec. 2013.
28 F. M. Wu, C. T. Lin, C. C. Wei, C. W. Chen,
Z. Y. Chen, and K. Huang, “3.22-Gb/s WDM
visible light communication of a single RGB
LED employing carrier-less amplitude and
phase modulation,” in Proc. Optical Fiber
Communication Conference and Exposition
and the National Fiber Optic Engineers
Conference (OFC/NFOEC) 2013 (Anaheim,
CA), Mar. 17–21, 2013, OTh1G.4.
29 M. Sharif, J. K. Perin, and J. M. Kahn,
“Modulation schemes for single-laser
100Gb/s links: Single-carrier,” J. Lightw.
Technol., vol. 33, no. 20, pp. 4268–4277,
Oct. 2015.
30 P. A. Haigh, A. Burton, K. Werﬂi,
H. L. Minh, E. Bentley, P. Chvojka,
W. O. Popoola, I. Papakonstantinou, and
S. Zvanovec, “A multi-CAP visible-light
communications system with 4.85-b/s/Hz
spectral eﬃciency,” IEEE J. Sel. Areas
Commun., vol. 33, no. 9, pp. 1771–1779,
Sep. 2015.
31 A. F. Shalash and K. K. Parhi,
“Multidimensional carrierless AM/PM
systems for digital subscriber loops,” IEEE
Trans. Commun., vol. 47, no. 11,
pp. 1655–1667, Nov. 1999.
32 P. P. Vaidyanathan, Multirate Systems and
Filter Banks. Englewood Cliﬀs, NJ:
Prentice-Hall, 1993.
33 S. Stern and R. Fischer, “Eﬃcient
assessment of the instantaneous power
distributions of pulse-shaped single-and
multi-carrier signals,” in Proc. International
Black Sea Conference on Communications
and Networking (BlackSeaCom) 2013

87
(Batumi, Georgia), Jul. 3–5, 2013, pp.
12–17.
34 J. J. Werner, Tutorial on carrierless
AM/PM-Part II: Performance of bandwidth
eﬃcient line codes, T1E1 Contribution, vol.
T1E1.4/93-058, 1992.
35 M. Vetterli and J. Kovacevic, Wavelets and
Subband Coding. Englewood Cliﬀs, NJ:
Prentice-Hall, 1993.
36 R. K. Brayton, S. W. Director,
G. D. Hachtel, and L. M. Vidigal, “A new
algorithm for statistical circuit design based
on quasinewton methods and function
splitting,” IEEE Trans. Circuits Syst.,
vol. 26, no. 9, pp. 784–794, Sep. 1979.
37 A. F. Shalash and K. K. Parhi,
“Three-dimensional carrierless AM/PM line
code for the UTP cables,” in Proc. IEEE
International Symposium on Circuits and
Systems (ISCAS) 1997 (Hong Kong, China),
Jun. 09–12, 1997, pp. 2136–2139.
38 A. Tsiatmas, C. P. M. J. Baggen,
F. M. J. Willems, J. M. G. Linnartz, and
J. W. M. Bergmans, “An illumination
perspective on visible light
communications,” IEEE Commun. Mag.,
vol. 52, no. 7, pp. 64–71, Jul. 2014.
39 S. Rajagopal, R. D. Roberts, and S. K. Lim,
“IEEE 802.15.7 visible light
communication: Modulation schemes and
dimming support,” IEEE Commun. Mag.,
vol. 50, no. 3, pp. 72–82, Mar. 2012.
40 K. Lee and H. Park, “Modulations for
visible light communications with dimming
control,” IEEE Photon. Technol. Lett.,
vol. 23, no. 16, pp. 1136–1138, Aug. 2011.
41 S. H. Lee, D. Y. Jung, and J. K. Kwon,
“Modulations and coding for dimmable
visible light communication,” IEEE
Commun. Mag., vol. 53, no. 2, pp. 136–143,
Feb. 2015.
42 J. K. Kwon, “Inverse source coding for
dimming in visible vight communications
using NRZ-OOK on reliable links,” IEEE
Photonics Tech. Lett., vol. 22, no. 19,
pp. 1455–57, Oct. 2010.
43 K. I. Ahn and J. K. Kwon, “Capacity
analysis of M-PAM inverse source coding in
visible light communications,” J. Lightw.
Tech., vol. 30, no. 10, pp. 1399–1404,
May. 2012.
44 S. Kim and S. Jung, “Novel FEC coding
scheme for dimmable visible light
communication based on the modiﬁed
Reed-Muller codes,” IEEE Photon. Technol.
Lett., vol. 23, no. 20, pp. 1514–1516, Oct.
2011.
45 S. Lee and J. Kwon, “Turbo code-based
error correction scheme for dimmable
visible light communication systems,” IEEE
Photon. Technol. Lett., vol. 24, no. 17,
pp. 1463–1465, Sep. 2012.
46 J. Kim and H. Park, “A coding scheme for
visible light communication with wide
dimming range,” IEEE Photon. Technol.
Lett., vol. 26, no. 5, pp. 465–468, Mar. 2014.
www.ebook3000.com

89
4
Multicarrier Modulation
In this chapter, we present a review of optical orthogonal frequency division multi-
plexing (OFDM) schemes for broadband and high-data-rate visible light communi-
cations (VLCs). We also introduce the recent development on optical OFDM with
respect to performance enhancement, power- and spectral-eﬃciency promotion and
discuss modiﬁed optical OFDM schemes under lighting constraints. A comprehen-
sive comparison of existing and proposed optical OFDM techniques is provided as
well.
Unlike radio frequency (RF) transmission, VLC usually adopts intensity-modulation
and direct-detection (IM/DD), where the optical OFDM signals are directly mod-
ulated onto the luminance of the emitted visible light. In the IM/DD scheme, the
amplitude of the optical OFDM signals is constrained to be real-valued and non-
negative. Since the conventional RF OFDM scheme is not feasible for intensity
modulation, several optical OFDM schemes have been proposed to satisfy the spe-
ciﬁc signal constraints in VLC, such as DC-biased optical OFDM (DCO-OFDM),
asymmetrically clipped optical OFDM (ACO-OFDM), pulse-amplitude-modulated
discrete multitone (PAM-DMT), and unipolar OFDM (U-OFDM). The recapitula-
tive architecture and mechanism of these schemes are presented in Section 4.1. The
performance comparison is investigated as well.
The time-domain signal of optical OFDM is the sum of a large number of orthogo-
nal harmonic components. The peak power of optical OFDM signals in time domain
is much higher than the average, which increases the probability that the amplitude
of optical OFDM signals exceeds the dynamic region of light emitting diode (LED).
This inherent high peak-to-average power ratio (PAPR) issue is prone to induce se-
vere nonlinear distortion and impair the transmission performance of VLC systems.
In Section 4.2, we introduce the recent inspiring researches on the performance en-
hancement for optical OFDM. This topic involves three major perspectives including
optimization of direct current (DC) bias and scaling factor, mitigating the nonlinear
eﬀect of LED, and PAPR reduction.
The power and spectral eﬃciency is another important issue for optical OFDM
schemes in VLC applications. The existing optical OFDM schemes, depicted in
Section 4.1, either require an additional DC bias or sacriﬁce part of the subcarriers
to satisfy the real-valued and non-negative constraints. Hence, considerable spectral
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.

90
or power eﬃciency loss is inevitable in these conventional optical OFDM schemes.
Recent research exhibits great potential to enhance the spectral and power eﬃciency
of optical OFDM. State-of-the-art power- and spectral-eﬃcient optical OFDM, ex-
empliﬁed by hybrid optical OFDM, enhanced U-OFDM (eU-OFDM), and Layered
ACO-OFDM (LACO-OFDM), are discussed in Section 4.3.
In VLC applications, the illumination function should be considered besides in-
formation transmission. Dimming control is used to adjust brightness of the illu-
mination and to satisfy diﬀerent illumination requirements in daily scenarios. To
support dimming control, optical OFDM must be capable of operating under light-
ing constraints on user’s demand. In Section 4.4, optical OFDM techniques under
lighting constraints, including pulse width modulation (PWM), reverse polarity opti-
cal OFDM (RPO-OFDM), and asymmetrical hybrid optical OFDM (AHO-OFDM),
are introduced comprehensively.
4.1
Optical OFDM for visible light communications
There has been a long history of OFDM technology since its embryonic form ﬁrst ap-
peared in a patent by R. W. Chang from Bell Labs in 1966 [1]. From then on, several
critical techniques including fast Fourier transform (FFT) and cyclic preﬁx (CP) were
proposed to complement OFDM schemes [2]. Nowadays, practical communication
systems, for example, the Long Term Evolution-Advanced (LTE-A) standard [3],
have successfully applied OFDM to provide high-rate transmission and multiple ac-
cess. Since OFDM exhibits a strong resistance to inter-symbol interference (ISI) in
dispersive channel, OFDM technology has become a promising multicarrier modu-
lation format for VLC applications. In this section, we introduce four mainstream
optical OFDM schemes for VLC systems.
4.1.1
DC-biased optical OFDM
In conventional RF OFDM schemes, the data are transmitted in parallel on multi-
carriers. The orthogonality of subcarriers ensures that the symbols in the same
OFDM block do not interfere with each other. Because OFDM is capable of mit-
igating ISI eﬀectively, it is an ideal modulation scheme for VLC for high-rate trans-
mission. The optical OFDM scheme inherits the basic attributes from its RF coun-
terparts but also exhibits several diﬀerences. Most of all, optical OFDM is directly
modulated on the intensity of emitted light and constrained to be real-valued and non-
negative. Modiﬁcation is embedded in optical OFDM to satisfy this constraint. In
this subsection, a representative multicarrier scheme, referred to as DCO-OFDM [4],
is introduced.
Figure 4.1 depicts the architecture of DCO-OFDM transceiver. Assuming that to-
tal N subcarriers are allocated in a single OFDM block, where N is typically a large
even number. At the transmitter, the serial bit stream is ﬁrst converted to a paral-
www.ebook3000.com

91
Figure 4.1 The block diagram of DCO-OFDM transceiver for visible light communications.
lel sequence and then mapped to the N/2 −1 complex-valued symbols according
to the speciﬁc modulation constellation X such as quadrature amplitude modula-
tion (QAM) [5]. The modulated OFDM block X = [X0 X1 · · · XN−1], where
subscript number denotes the associated subcarrier index, is constructed as follows:
X0 = 0 and X1 to XN/2−1 carry the N/2 −1 information symbols, while XN/2
to XN−1 satisfy the Hermitian symmetry as
Xk = X∗
N−k, k = N/2, ..., N −1,
(4.1)
where the superscript mark “*” represents the conjugate operation. Setting X0 =
XN/2 = 0 is to avoid the DC and complex-valued harmonic components, while
the Hermitian symmetry of X enables the transmitter to generate real-valued time-
domain signals.
The OFDM symbol vector X is fed to the processor of inverse fast Fourier trans-
form (IFFT) and converted to discrete time-domain samples eﬃciently as
xn =
1
√
N
N−1
k=0 Xk exp

j 2πkn
N

, n = 0, 1, ..., N −1,
(4.2)
where xn represents the nth discrete time-domain sample. Considering the imposed
Hermitian symmetry, the IFFT operation (4.2) is further expressed as
xn = 1
√
N
N/2−1
k=1

Xk exp

j 2πkn
N

+ XN−k exp

j 2π (N −k) n
N

= 1
√
N
N/2−1
k=1

Xk exp

j 2πkn
N

+ X∗
k exp

−j 2πkn
N

= 2
√
N
N/2−1
k=1
Re

Xk exp

j 2πkn
N

, n = 0, 1, ..., N −1,
(4.3)
where Re (Z) denotes the real part of Z. The imaginary parts of the time-domain
signal samples are forced to zero. It is worth emphasizing again that the total num-
ber of used subcarriers is N/2 −1 and the rest of the subcarriers are exploited to
impose the Hermitian symmetry. After IFFT, a CP of length LCP, which is the copy
of the last LCP samples of each time-domain DCO-OFDM block, is appended in its

92
front. CP provides guard interval without destroying the orthogonality of subcarri-
ers. When LCP exceeds the maximum delay of the dispersive channel, ISI is totally
discarded.
Then the discrete samples are converted into a serial sequence and fed to a digital-
to-analog converter (DAC). The converted electrical signal x (t) is still bipolar and
is not feasible for intensity modulation. A DC bias BDC should be added to x (t). In
DCO-OFDM, the DC bias BDC is set to
BDC = μ

E {x2 (t)},
(4.4)
where E {·} denotes the expectation operation and μ is a constant coeﬃcient.
Considering the power gain induced by BDC, the DC bias level is evaluated as
10 log
μ2 + 1

. Besides that, the negative amplitudes of the biased signals are
clipped as zero for intensity modulation. After biasing and clipping, the electrical
DCO-OFDM signal xDCO (t) is used to drive the LED and to be modulated on the
intensity of illumination. According to the central limit theorem, x (t) approximates
a Gaussian distribution with zero mean when N ≥64 [4]. Therefore, the optical
power of DCO-OFDM is BDC, while its electric power is
μ2 + 1
 E
)x2 (t)
*
.
At the receiver, the photodiode (PD) component captures the optical signal from
the VLC channel and transforms it into the electrical signal y (t). A lens can be
placed in front of the PD to ﬁlter the background light. In the PD, the thermal noise
and shot noise interfere with the received signal. These two types of noise can be both
modeled as additive white Gaussian noise (AWGN) [6]. Thus, for the dispersive VLC
channel with the impulse response h (t), the received signal y (t) is expressed as
y (t) = h (t) ⋆xDCO (t) + w (t) ,
(4.5)
where the notation “⋆” denotes the convolution operation and w (t) is the AWGN
with zero mean. After analog-to-digital converter (ADC), the received DCO-OFDM
discrete sample block is acquired with the CP removed and then is reshaped as the
parallel sequence {yn, n = 0, 1, ..., N −1}.
To recover the transmitted data symbols, the N-point FFT component con-
verts the time-domain samples into the frequency-domain symbols
)Yk, k
=
0, 1, ..., N −1
*
. For each subcarrier, the associated channel is ﬂat. Hence, simple
one-tap equalization method is imposed. The equalizer divides the received symbols
{Yk, k = 1, 2, ..., N/2 −1} on the used subcarriers by the associated channel state
information (CSI) Hk, which can be estimated according to the pilot embedded in
DCO-OFDM signals. Based on these equalized symbols, a maximum likelihood
(ML) detection is invoked as
Xr
k = arg min
Xk∈X
++Yk −HkXk
++2 ,
(4.6)
where Xk and Xr
k represent the candidate and recovered symbols on the kth sub-
carrier, respectively, while ∥·∥indicates the Euclidean distance. The demapper then
maps the complex symbol Xr
k into the corresponding bits to recover the transmitted
data.
www.ebook3000.com

93
0
2
4
6
−1
0
1
Subcarrier Index  k
Real Part
DCO−OFDM
0
2
4
6
−1
0
1
Subcarrier Index  k
Imaginary Part
DCO−OFDM
0
2
4
6
−4
−2
0
2
4
Discrete Time Index  k
Amplitude
DCO−OFDM
0
2
4
6
−1
0
1
Subcarrier Index  k
Real Part
ACO−OFDM
0
2
4
6
−1
0
1
Subcarrier Index  k
Imaginary Part
ACO−OFDM
0
2
4
6
−4
−2
0
2
4
Discrete Time Index  k
Amplitude
ACO−OFDM
0
2
4
6
−1
0
1
Subcarrier Index  k
Real Part
PAM−DMT
0
2
4
6
−1
0
1
Subcarrier Index  k
Imaginary Part
PAM−DMT
0
2
4
6
−4
−2
0
2
4
Discrete Time Index  k
Amplitude
PAM−DMT
Figure 4.2 Three diﬀerent optical OFDM signals: DCO-OFDM (left-column plots),
ACO-OFDM (center-column plots), and PAM-DMT (right-column plots).
A simple DCO-OFDM block with eight subcarriers is depicted in the left-column
plots of Fig. 4.2, where circles and crosses denote non-clipped and clipped signals, re-
spectively. The three data symbols are modulated according to 4QAM constellation
and allocated to the ﬁrst to third subcarriers, while the ﬁfth to seventh subcarriers are
occupied by X∗
3, X∗
2, and X∗
1, respectively. In this case, a 3 dB DC bias, denoted by
the black dash line, is added to the DCO-OFDM signals. It is observed that clipping
operation results in slight distortions on all the subcarriers. The clipping distortions
reduce the amplitudes of the received symbols and impair the performance of ML
detection. Since the DC part of the DCO-OFDM signal carries no data information,
3 dB power cost is just for mitigating the distortions.
DCO-OFDM is a simple and spectral-eﬃcient multicarrier scheme for VLC trans-
mission. However, it has the inherent issue of low power eﬃciency. This is because
a high DC bias level is required to raise the negative peak over zero. This induces
a severe power-eﬃciency loss, which restricts the achievable performance of DCO-
OFDM systems.
4.1.2
ACO-OFDM and PAM-DMT
In order to enhance the power eﬃciency of VLC multicarrier systems, several mod-
iﬁed optical OFDM schemes were proposed in [7, 8]. Among them, ACO-OFDM
is the most typical and inspiring scheme for power-eﬃcient transmission. The basic

94
idea of ACO-OFDM is sacriﬁcing even subcarriers to accommodate the clipping dis-
tortions. This strategy avoids DC bias and reduces the power cost signiﬁcantly, at the
considerable cost of reduced spectrum eﬃciency. PAM-DMT is another alternative
asymmetric optical OFDM scheme [8].
4.1.2.1
ACO-OFDM
The block diagram of ACO-OFDM is similar to its DCO-OFDM counterpart. The
major diﬀerence is the allocation of data symbols. In the ACO-OFDM scheme, the
data symbols are only placed on the odd subcarriers of the ﬁrst N/2 subcarriers and
hence, an ACO-OFDM block of N subcarriers can only accommodate N/4 infor-
mation symbols. Considering the constraint of real-valued amplitude, the Hermitian
symmetry constraint of (4.1) is also imposed on the (N/2)th to (N −1)th subcar-
riers. At the transmitter, after the IFFT operation, the discrete time-domain samples
have the asymmetry as
xn = 1
√
N
N−1
k=0 Xk exp

j 2πkn
N

= 1
√
N
N/2−1
m=0
X2m+1 exp

j 2π(2m + 1)n
N

= −
1
√
N
N/2−1
m=0
X2m+1 exp

j 2π(2m + 1) (n + N/2)
N

= −xn+N/2, n = 0, 1, ..., N/2 −1.
(4.7)
The asymmetry in (4.7) manifests the fact that the amplitudes of the ﬁrst half sam-
ples are identical to those of the second half samples but with opposite signs. The
negative-valued sample xn < 0 can be simply recovered by observing its asymme-
try sample xn+N/2 or xn−N/2. Hence, the ACO-OFDM signal xACO (t) is directly
clipped at zero without adding any DC bias, and then transformed into an optical
signal. Assuming that xc
n is the clipped sample, where
xc
n =
 xn,
xn > 0,
0,
xn ≤0,
(4.8)
www.ebook3000.com

95
the distorted data symbols Xc
2m+1 on the odd subcarriers m = 0, 1, ..., N/2 −1
can be derived as
Xc
2m+1 = 1
√
N
N−1
n=0 xc
n exp

−j 2π(2m + 1)n
N

= 1
√
N
N/2−1
n=0

xc
n −xc
n+N/2

exp

−j 2π(2m + 1)n
N

=
1
2
√
N
N/2−1
n=0
xn −xn+N/2
 exp

−j 2π(2m + 1)n
N

=
1
2
√
N
N/2−1
n=0
xn exp

−j 2π(2m + 1)n
N

+
1
2
√
N
N/2−1
n=0
xn+N/2 exp

−j 2π(2m + 1) (n + N/2)
N

=1
2X2m+1.
(4.9)
It can be seen that clipping operation reduces the power of an ACO-OFDM signal by
half.
Since xn approximates a Gaussian distribution when N ≥64, the distribution of
xc
n could be written as [4]
pACO (xc
n) =
⎧
⎨
⎩
1
2,
xc
n = 0,
1
√
2πσACO exp

−(xc
n)2
2σ2
ACO

,
xc
n > 0,
(4.10)
where σACO denotes the root mean square (RMS) of the unclipped ACO-OFDM sig-
nal xn. The optical power of xc
n is then calculated by E {xc
n} = σACO/
√
2π, while
the electric power of xc
n is given by E

(xc
n)2
= σACO2/2 [9].
At the receiver of an ACO-OFDM system, which shares a similar procedure as
the DCO-OFDM scheme, only the symbols Y2m+1 on the odd subcarriers m =
0, 1, ..., N/4 −1 are extracted after the FFT operation and fed to the equalizer and
demapper. Taking into account the clipping distortion in (4.8), the ML detection for
the ACO-OFDM demapper is modiﬁed as
Xr
k = arg min
Xk∈X
++2Yk −HkXk
++2 .
(4.11)
Notice that one element of the transmitted sample pair

xc
n, xc
n+N/2

, where n =
0, 1, ..., N/2−1, is zero-valued. This feature of ACO-OFDM signal can be used to
enhance the receiver performance. Assuming that ye
n represents the equalized time
sample, which is simply acquired by computing the IFFT of the equalized frequency-
domain sequence, a pairwise ML detection [10] can be carried out to mitigate the
noise as

yr
n, yr
n+N/2

=

{ye
n, 0} ,
ye
n > ye
n+N/2,

0, ye
n+N/2

,
ye
n < ye
n+N/2, n = 0, 1, ..., N/2 −1.

96
(4.12)
By performing the FFT and the ML detection of (4.11) according to the detected
sample sequence {yr
n}, the data symbols can be recovered more accurately. The
pairwise ML detection removes about half of the noise and it achieves performance
gains of 1.3 dB and 1 dB over the ﬂat and dispersive channels, respectively [10].
4.1.2.2
PAM-DMT
In the PAM-DMT scheme, the data symbol is only allocated on the imaginary part
of a subcarrier, whereas the real part of the subcarrier is always set to zero. The
frequency-domain PAM-DMT block of N subcarriers can be expressed as
X =
,
0 jXPAM
1
jXPAM
2
· · · jXPAM
N/2−1 0 −jXP AM
N/2−1 · · · −jXPAM
1
-
,
(4.13)
where XPAM
k
is real-valued mapped symbol taking value from the pulse amplitude
modulation (PAM) constellation XRe. After the IFFT operation, the time-domain
PAM-DMT signal follows the asymmetry as
xn = −
2
√
N
N−1
k=0 XPAM
k
sin
2πkn
N

= 2
√
N
N−1
k=0 XPAM
k
sin
2πk(N −n)
N

= −xN−n, n = 1, 2, ..., N/2 −1.
(4.14)
Since the two elements of the pair {xn, xN−n} are opposite to each other, the
asymmetric clipping can be executed without any DC bias, just as in the case of
ACO-OFDM. Similarly, the optical power and electric power of PAM-DMT are
σPAM/
√
2π and σPAM2/2, where σPAM denotes the RMS of the unclipped PAM-
DMT signal [9]. The distortion on the imaginary part is derived as
Im (Xc
k) = −
1
√
N
N−1
n=0 xc
n sin
2πkn
N

= −
1
√
N
N/2−1
n=0
xc
n −xc
N−n
 sin
2πkn
N

= −
1
2
√
N
N/2−1
n=0
(xn −xN−n) sin
2πkn
N

=1
2XPAM
k
, k = 1, 2, ..., N/2 −1,
(4.15)
where Im (Z) denotes the imaginary part of Z. Hence, the amplitude of the distorted
symbol in the imaginary part is half of the original data symbol. In order to recover
the data symbol XPAM,r
k
at the receiver, the ML detection for the PAM-DMT signal
is imposed as
XPAM,r
k
= arg
min
Xk∈XRe
++Im
2Yk −HkXk
++2 .
(4.16)
j
www.ebook3000.com

97
The pairwise ML detection [10] can also be applied to mitigate the noise eﬀect.
Both the ACO-OFDM and PAM-DMT signals are also exempliﬁed in Fig. 4.2.
For the ACO-OFDM scheme depicted in the center-column plots of Fig. 4.2, two
4QAM symbols are modulated on the two odd subcarriers. As for the PAM-DMT
signal shown in the right-column plots of Fig. 4.2, the real parts of all the subcarriers
are set to zero, and three 2PAM symbols are allocated on the imaginary parts of
the subcarriers 1, 2, and 3. It is observed that both schemes exhibit asymmetry in
discrete samples. For ACO-OFDM, the 0th, 1st, 2nd, and 3rd samples are opposite
to the 4, 5, 6, 7th samples, whereas the 1st, 2nd, and 3rd samples are opposite to the
7, 6, 5th samples in PAM-DMT. The distorted data symbols are all reduced to half
in both schemes. The leftover non-regular distortions fall on the even subcarrier and
the real part in ACO-OFDM and PAM-DMT, respectively.
Compared to DCO-OFDM, ACO-OFDM and PAM-DMT achieve signiﬁcant pow-
er eﬃciency enhancement. However, since half of the subcarriers in ACO-OFDM
signals are sacriﬁced to accommodate the asymmetry clipping distortions, the spec-
tral eﬃciency is half of its DCO-OFDM counterpart when the same modulation con-
stellation is applied. The same disadvantage also exists in PAM-DMT systems, as on-
ly a real-valued constellation is employed. Hence, a careful tradeoﬀbetween power-
and spectral- eﬃciency is required to select a suitable optical OFDM to meet practical
requirements.
4.1.3
Unipolar OFDM
For both ACO-OFDM and PAM-DMT schemes, speciﬁc part of the spectrum is ex-
ploited to accommodate the clipping distortions. By contrast, U-OFDM [11], which
Figure 4.3 Unipolar optical OFDM signal encoding.

98
was also referred to as Flip-OFDM in [12, 13], doubles the OFDM block length to
transmit the negative amplitudes without requiring clipping operation. Hence, the
block length of U-OFDM is 2N, and each block carries N/2 −1 information sym-
bols with the ﬁrst subcarrier set to zero while the Hermitian symmetry of (4.1) is
deployed to generate Xk for 0 ≤k ≤N −1. The bipolar discrete time sam-
ples {xn, n = 0, 1, ..., N −1} are acquired after the IFFT processor. In order to
generate the unipolar signals for intensity modulation, the U-OFDM block is extend-
ed to {xu
n, n = 0, 1, ..., 2N −1}. Each sample xn is encoded into the new pair
)xu
n, xu
n+N
*
. When the amplitude of the original OFDM sample xn is positive, the
ﬁrst sample of the new pair is labeled as “active” and the second one as “inactive”.
Otherwise, the ﬁrst sample is set as “inactive” and the second sample is set as “ac-
tive”. The active sample is equal to the absolute value of xn and the inactive sample
is zero. This encoding in U-OFDM is equivalent to the bijection as
xn →
)xu
n, xu
n+N
* =

{xn, 0} ,
xn > 0,
{0, −xn} ,
xn ≤0, n = 0, 1, ..., N −1.
(4.17)
Figure 4.3 exempliﬁes the encoding procedure in U-OFDM. The eight-point bipo-
lar sequence is the original OFDM signal. After adopting the bijection of (4.17),
this sample sequence is extended into a 16-point sample signal. The ﬁrst half of the
U-OFDM signal, denoted by the blue circle, allocates the positive part of the origi-
nal OFDM signal and sets the negative sample as zero. In the second half with the
legend of red circle, the absolute values of the original negative samples are placed
The transmitter modulates the unipolar signals {xu
n} on the emitting light. The
receiver captures the signals {yu
n, n = 0, 1, ..., 2N −1} and recovers the bipolar
OFDM signals {yn, n = 0, 1, ..., N −1} as yn = yu
n −yu
n+N. The pairwise
ML decoder [10] can be applied to enhance the detection performance. The power-
eﬃcient U-OFDM scheme does not require DC bias. However, since the length of the
OFDM block is doubled, the spectral eﬃciency is reduced to half of the DCO-OFDM
scheme.
4.1.4
Performance comparison
In this section, four mainstream optical OFDM schemes have been introduced. DCO-
OFDM enjoys an advantage of high spectral eﬃciency, whereas ACO-OFDM, PAM-
DMT, and U-OFDM enhance the power eﬃciency at the expense of spectral eﬃ-
ciency. A simulation is carried out to compare these optical OFDM schemes. In the
simulated VLC system, the total subcarrier number is set to 512. QAM constella-
tion is adopted for DCO-OFDM, ACO-OFDM, and U-OFDM signals, while PAM is
applied for PAM-DMT signal. Figure 4.4 depicts the simulation results. The spec-
tral eﬃciencies, constellations, modulation orders, and DC bias levels employed are
attached near the corresponding curves. The vertical axis of Fig. 4.4 is Eb,elec/N0
which denotes the ratio between the average electrical energy per bit Eb,elec and the
noise power spectral density N0. For fair comparison, the power of DC bias is in-
www.ebook3000.com

99
1
2
3
4
5
6
5
10
15
20
25
30
35
40
Spectral Efficiency (bis/s/Hz)
 Eb, elec/ N0 (dB)
4QAM, 2PAM
16QAM, 4PAM
64QAM, 8PAM
256QAM, 16PAM
1024QAM, 32PAM
4096QAM, 64PAM
64QAM DCO−OFDM
11 dB DC Bias
4QAM DCO−OFDM
7 dB DC Bias
16QAM DCO−OFDM
7 dB DC Bias
DCO−OFDM
ACO−OFDM
PAM−DMT
U−OFDM
Figure 4.4 Performance comparison of DCO-OFDM, ACO-OFDM, PAM-DMT, and
U-OFDM schemes.
cluded in Eb,elec. Since bit errors at the bit error rate (BER) level of 10−3 can be
corrected by using forward error correction (FEC) code, the demodulation threshold
for Eb,elec/N0 at BER = 10−3 is selected to evaluate the power cost of each optical
OFDM scheme. As expected, the ACO-OFDM, PAM-DMT, and U-OFDM schemes
share the same performance, and the demodulation threshold curves of these three op-
tical OFDM schemes coincide with each other. When the required spectral eﬃciency
is below 2 bit/s/Hz, the ACO-OFDM scheme achieves a slight performance gain of
0.7 dB compared to DCO-OFDM. However, when the required spectral eﬃciency
exceeds 4 bit/s/Hz, the DCO-OFDM scheme enjoys lower power cost and exhibits
higher power-eﬃciency than the other three schemes. In summary, DCO-OFDM is
a preferred multicarrier scheme for high spectral-eﬃciency VLC transmission.
4.2
Performance enhancement for optical OFDM
Although the above-mentioned optical OFDM schemes provide high-rate transmis-
sion for VLC multicarrier systems, their achievable performance are restricted by
the inherent high PAPR issue. In practical VLC systems, the deployed LEDs exhibit
a strong nonlinearity and a narrow dynamic region. Due to the high PAPR of an
OFDM signal, its peak amplitude is prone to exceed the dynamic region and the sig-

100
nal is considerably distorted when driving LEDs. The nonlinear distortion spreads to
all the subcarriers after FFT operation and induces a severe performance loss. Hence,
several major performance enhancement methods are presented in this section.
4.2.1
DC bias and scaling optimization
Due to the p-n junction barrier and saturation eﬀect, the relationship between the
forward voltage across an LED component and the forward current is nonlinear [14].
This relationship may be modeled by the nonlinear transfer characteristic between
the input electrical power and the output optical power. Thus, the LED nonlinearity
is generally deﬁned by the relationship between the input current amplitude z, which
is linearly proportional to the square root of the input electrical power, and the output
current F (z), which is linearly proportional to the output optical power. Figure 4.5
exempliﬁes a typical LED nonlinear transfer characteristic between z and F (z). In
Fig. 4.5, the dynamic region, denoted by [λlower, λupper], can be regarded as the linear
range of the LED transfer curve. In an optical OFDM scheme, a suitable DC bias is
exploited to allocate the OFDM signal z = x + BDC to within the dynamic region.
The amplitude outside the dynamic region should be clipped to mitigate the nonlinear
eﬀect. Hence, the LED nonlinear transfer function can be modeled as double side
O
O
Figure 4.5 LED nonlinear transfer characteristic and DC bias setting for DCO-OFDM
signal.
www.ebook3000.com

101
clipping [14], which is expressed as
F (x + BDC) =
⎧
⎨
⎩
λlower,
x + BDC < λlower,
x + BDC,
λlower ≤x + BDC < λupper,
λupper,
x + BDC ≥λupper.
(4.18)
Obviously, the clipping level is related to the LED dynamic region and the average
power of input signal x. In order to evaluate the eﬀect of clipping distortion, clipping
level CL is deﬁned as
CL = 10 log ∥λupper −λlower∥2
E {x2}
dB.
(4.19)
The DCO-OFDM time-domain signal x satisﬁes a Gaussian distribution [14]. By
applying Bussgang theorem [15], the clipped signal F (z) can be modeled as
F (z) −BDC = Kx + wclip,
(4.20)
where K denotes the attenuation factor and wclip the non-correlative clipping noise.
At the receiver, the ML detection regards the clipping distortion as part of the Gaus-
sian noise and equalizes the data symbol with the attenuation factor K. Hence, the
eﬀective signal-to-noise ratio (SNR) Γb,elec on the kth subcarrier is equal to
Γb,elec =
K2σ2
x
σ2
clip + σ2
AWGN/ |Hk|2 ,
(4.21)
where σ2
x and σ2
AWGN denote the powers of the transmitted DCO-OFDM signal and
the AWGN noise, respectively [16]. The DC bias BDC is not included in the eﬀective
SNR since it does not convey any information. According to [14], σ2
clip and K are
the functions of BDC and σ2
x. When the dynamic region [λlower, λupper] is known,
DC bias and signal power can be optimized to maximize the eﬀective SNR and thus
enhance the performance. In order to support ﬂexible power adjustment for DCO-
OFDM, scaling factor α > 0 is introduced. Assuming that the OFDM signal xnormal
converted by IFFT components is normalized in electrical power, the transmitted
DCO-OFDM signal x is ampliﬁed as αxnormal and the signal power σ2
x is equal to
α2. The optimization for mitigating the clipping noise can then be expressed as
{Bop
DC, αop} = arg
max
BDC>0,α>0 Γb,elec (BDC, α) .
(4.22)
The DC bias and scaling factor optimization methods are classiﬁed as static and
dynamic methods. In the static method, the DC bias and scaling factor of each DCO-
OFDM block are ﬁxed. The optimum DC bias can be formulated according to Buss-
gang theorem and the Gaussian distribution characteristics of DCO-OFDM signals,
which is reported in [17]. The optimum scaling factor is acquired by minimizing the
required average normalized optical signal-to-noise ratio (OSNR) for the target BER
level of 10−3 [16]. However, the peak amplitudes of diﬀerent DCO-OFDM blocks

102
vary in a large range and the ﬁxed scaling factor cannot make full use of dynamic
region. Hence, a dynamic DC bias and scaling factor optimization method was pro-
posed in [16], whereby the DC bias and scaling factor are adaptively adjusted for
each DCO-OFDM block. Since all the samples in the normalized sample sequence
)xnormal
n
, n = 0, 1, ..., N −1
*
generated by the IFFT converter are multiplied by
the scaling factor, a large scaling factor increases the power of clipping noise, where-
as a small scaling factor reduces the eﬀective signal power. Considering the tradeoﬀ
between the powers of clipping noise and signal, the scaling factor is recommended
to set according to [16]
αop =
2 (λupper −λlower)
xnormal
max + xnormal
s max −xnormal
min
−xnormal
s max
,
(4.23)
where xnormal
max and xnormal
min
denote the maximum and minimum elements of
)xnormal
n
*
,
respectively, while xnormal
s max and xnormal
s min represent the second maximum and second
minimum samples, respectively. By adopting this scaling factor, only the positive
and negative peak amplitudes of OFDM signal may exceed the dynamic region, and
this limits the clipping distortion level. Although αop given in (4.23) is not the true
optimum scaling factor that maximizes the eﬀective SNR, it achieves a desired bal-
ance between the powers of clipping noise and signal eﬀectively without high calcu-
lation complexity. After αop is determined, the DC bias is acquired by minimizing
the power of clipping noise according to [16]
Bop
DC = arg min
BDC>0
N−1
n=0
F
αopxnormal
n
+ BDC
 −αopxnormal
n
−BDC
2 .
(4.24)
The optimization of (4.24) still imposes considerable computation especially when
the subcarrier number is large. Since αop acquired in (4.23) guarantees that the range
of the signal amplitudes approaches the dynamic region of the LED, an approximate
optimum Bop
DC is recommended as [16]
Bop
DC = (λupper + λlower) /2 −αop xnormal
max + xnormal
min
 /2.
(4.25)
After adopting this approximation, the middle point of the amplitude range in each
DCO-OFDM block is raised to coincide with the center of the LED dynamic re-
gion. Since the optimum scaling factor is unknown to the receiver, an additional
pilot should be embedded in each DCO-OFDM block for equalization. The DC bias
is converted onto the zeroth subcarrier after the FFT operation and it does not aﬀect
the data symbols. Only simple addition and multiplication are required in the solu-
tion of Eqs. (4.23) and (4.25). The peak and second peak amplitudes are obtained
by simply traversing the sample sequence once. Thus, the DC bias and scaling fac-
tor optimization proposed in [16] is of extremely low complexity and suitable for
practical implementation.
In Fig. 4.6, the simulated BER curves of both the static and dynamic optimization
methods are presented. In the simulation system, each DCO-OFDM block contains
www.ebook3000.com

103
256 subcarriers and adopts 64QAM constellation. The results show that the dynam-
ic optimization method enjoys a performance gain of around 1 dB compared to the
static counterpart. Furthermore, the approximate optimum DC bias of (4.25) is ob-
served to achieve almost the same BER performance as the true optimal solution.
This conﬁrms that this low-complexity near-optimal DC bias is preferred for practi-
cal implementation.
4.2.2
LED nonlinearity mitigation
As introduced in the previous subsection, the nonlinear distortion is often modeled as
part of the non-correlative noise at the conventional receiver. Although the negative
eﬀect of the clipping noise is restricted by the DC bias and scaling factor optimiza-
tion, the nonlinear distortion still impairs the performance of optical OFDM systems.
In this subsection, a state-of-the-art algorithm is introduced to signiﬁcantly mitigate
the nonlinear eﬀect of LED.
According to [18], the achievable capacity of OFDM transmission over nonlinear
channel only suﬀers a slight performance loss even when narrow dynamic region is
imposed. Hence, the correlation between the clipping distortion and received signal
28
29
30
31
32
33
34
35
10
−4
10
−3
10
−2
Normalized OSNR (dB)
BER
Statics
Dynamics, Optimal Bias
Dynamics, Near−Optimal Bias
Figure 4.6 Performance comparison of static and dynamic DC bias and scaling factor
optimization.

104
can be exploited to enhance the performance of the clipped DCO-OFDM. A nov-
el maximum likelihood sequence detection (MLSD) was proposed to mitigate the
LED nonlinear eﬀect in [19]. Unlike the conventional receiver which detects the da-
ta symbol on each subcarrier by using (4.6), the DCO-OFDM data symbol sequence
is jointly detected in the proposed method.
For clear clariﬁcation, denote the Ns-length candidate symbol sequence of each
DCO-OFDM block by X =
.X1 X2 · · · XNs
/ ∈X Ns, where 0 < Ns < N/2,
and the associated candidate DCO-OFDM sample sequence after the operations of
the Hermitian symmetry in (4.1), IFFT in (4.2) and LED double side clipping in
(4.18) by r
X

. Since the noise vector obeys the N-dimensional independent and
identical Gaussian distribution with each element having zero mean and variance of
σ2, the conditional probability density function (PDF) or likelihood of the candidate
symbol sequence X is given by
p
r
		X = X
 =
1
(2πσ2)N/2 exp

−1
2σ2
++y −r
X
++2
,
(4.26)
where y is the received sample sequence and a ﬂat channel is assumed. Hence, the
MLSD of [19] is expressed as
Xr
MLSD = arg min
X∈X Ns
++y −r
X
++2 .
(4.27)
However, the minimization in (4.27) needs to be solved by traversing all the possible
candidate symbol sequences. For M-ary constellation, the complexity of the MLSD
is on the order of O(M Ns), which makes this detection infeasible.
A low-complexity suboptimal algorithm was further proposed in [19]. Since the
clipping only distorts a symbol around its transmitted constellation point, the symbol
sequence Xr
MLD recovered by the conventional subcarrier based maximum likelihood
detection (MLD) of (4.6) is close to Xr
MLSD. In the proposed suboptimal algorithm,
Xr
MLD is set as the initial candidate symbol sequence as X = Xr
MLD. Starting on
the ﬁrst subcarrier, X1 of X is substituted by its 4 nearest neighbor constellation
points to generate the four candidate sequences X
(i), i = 1, 2, 3, 4. Compute the
Euclidean distances
+++y −r

X
(i)+++
2
, i = 1, 2, 3, 4, and ﬁnd the sequence X
(imin)
with the minimum Euclidean distance. If
+++y −r

X
(imin)+++
2
<
++y −r
X
++2,
update X with X
(imin). Then move to the next subcarrier, and continue the same
update until all the subcarriers are updated. Then return to the ﬁrst subcarrier and
repeat the same procedure until the iteration number reaches its maximum number
L. The detailed algorithm is summarized in Algorithm 4.1.
The ﬁnal output 0Xr
MLSD is a suboptimal solution of (4.27). With this algorithm,
the complexity of the sequence detection is reduced to O(LMNs). According to
the simulation results presented in [19], the approximate MLSD algorithm can sig-
niﬁcantly mitigate the clipping distortions of DCO-OFDM signals in comparison to
the conventional subcarrier-based MLD. When CL is set as 11 dB and 16QAM is
www.ebook3000.com

105
Algorithm 4.1 Low Complexity Near MLSD Algorithm.
Input: Received signal sequence y; Constellation set X ;
Output: Near optimal MLSD solution 0Xr
MLSD;
1: Pre-processing: For each X ∈X , ﬁnd its four nearest constellation points
Xnear(X, 0), Xnear(X, 1), Xnear(X, 2), and Xnear(X, 3); Store all the resulting
subsets by look-up table;
2: Initialization: Find the conventional MLD solution Xr
MLD with the ML detec-
tion (4.6); Set X = Xr
MLD, reconstruct the clipped DCO-OFDM signal r
X

and calculate the MLSD metric
++y −r
X
++2;
3: for l = 1 : L do
4:
for k = 1 : N/2 −1 do
5:
for i = 0 : 3 do
6:
Find Xk,i = Xnear
Xk, i

for Xk from the look-up table;
7:
Generate X
(i) by substituting Xk in X with Xk,i;
8:
Reconstruct r

X
(i)
, and compute
+++y −r

X
(i)+++
2
;
9:
end for
10:
Find imin = arg min
0≤i≤3
+++y −r

X
(i)+++
2
;
11:
if
+++y −r

X
(imin)+++
2
<
++y −r
X
++2 then
12:
Set X = X
(imin) with
++y −r
X
++2 =
+++y −r

X
(imin)+++
2
;
13:
end if
14:
end for
15: end for
16: return 0Xr
MLSD = X;
adopted, the BER performance of this approximate MLSD algorithm converges to
almost the same level of the ideal case, where the DCO-OFDM signal is not clipped
at the transmitter, with only L = 1 iteration. As for higher-order constellations,
such as 64QAM and 256QAM, the approximate MLSD algorithm achieves a perfor-
mance enhancement of around 2 dB at BER = 10−3 compared to the conventional
subcarrier-based MLD. Moreover, the BER curves of the approximate MLSD almost
coincide with those of the ideal-case counterparts. The results of [19] hence demon-
strate the eﬀectiveness of the approximate MLSD.
A similar method for mitigating the LED nonlinearity is applied to encoded DCO-
OFDM [20]. More speciﬁcally, a bit-interleaved coded modulation with iterative
demapping and decoding (BICM-ID) scheme is proposed for clipped DCO-OFDM
to further mitigate the LED nonlinearity. The architecture of this proposed DCO-
OFDM BICM-ID system is depicted in Fig. 4.7. At the transmitter, the source bit
vector u is ﬁrstly encoded as c, interleaved as cπ and then mapped into symbol
vector X. After imposing Hermitian symmetry and IFFT operation, the time-domain
signal x is generated, which is then added with DC bias and clipped as xDCO to

106




Figure 4.7 The block diagram of BICM-ID scheme for clipped DCO-OFDM in visible light
communications.
accommodate the dynamic region of LED. At the receiver, the demapper calculates
the extrinsic log-likelihood ratio (LLR) Le as soft information and feeds it to the
channel decoder after de-interleaving as a priori information La,d. Then, the decoder
outputs the a posteriori LLR Lp,d to recover the received bits and the extrinsic LLR
Le,d to provide the feedback a priori information for the next iterative demapping.
For an arbitrary encoded bit b, its LLR is deﬁned as
Lb = log P (b = 0)
P (b = 1),
(4.28)
where P (A) represents the probability of event A. For the M-ary constellation,
where M = 2m, let Le
bk,i and La
bk,i denote the demapping extrinsic LLR and de-
coding feedback LLR of the ith labeled bit bk,i on the kth subcarrier, respectively,
the conventional soft demapping criterion is expressed as [20]
Le
bk,i =
max
Xk∈X (0)
i

−1
σ2
++Xk −Yk
++2 + 1
2s
Xk
 La
bk
T

−
max
Xk∈X (1)
i

−1
σ2
++Xk −Yk
++2 + 1
2s
Xk
 La
bk
T

−La
bk,i, (4.29)
where (·)T stands for the transpose operator and X (b)
i
, b = 0, 1, denotes the con-
stellation set with the ith labeled bit bi = b. In (4.29), the vector s
Xk

is equal to
1 −2b
Xk

, where b
Xk

is the labeled bit vector of candidate symbol Xk and
1 is the vector with all the elements being 1, while La
bk is the associated vector of
the feedback LLRs on the kth subcarrier, denoted as
,
La
bk,0 La
bk,1 · · · La
bk,m
-
.
The above-mentioned soft demapper still models the nonlinear distortion as
non-correlative noise. In order to mitigate the LED nonlinearity, a novel demap-
ping criterion was further presented in [20].
The feedback LLR vector La =
.La
b1 La
b2 · · · La
bNs
/
from the channel decoder is an accurate estimation of the en-
coded bits in a DCO-OFDM block. The proposed demapping method exploits this
www.ebook3000.com

107
fact to recover the encoded bits. According to the deﬁnition of LLR, the encoded bit
vector ba La
bk

is calculated by the following hard decision
bk
i
La
bk
 =
 0,
La
bk,i ≥0,
1,
La
bk,i < 0,
(4.30)
where bk
i
La
bk

is the ith element of ba La
bk

. Then, bk
i
La
bk

is mapped onto the
estimated data symbol Xa La
bk

based on the constellation X , whereas the data
symbol sequence X (La) is simply generated as
X (La) =
.Xa La
b1
 Xa La
b2
 · · · Xa La
bNs
/ .
(4.31)
By replacing the kth element Xa La
bk

of X (La) with Xk, a candidate symbol
sequence X
La, Xk

is acquired. Transfer X
La, Xk

into the clipped DCO-
OFDM signal r
X
La, Xk

and extract the kth distorted candidate symbol
Rd
k
La, Xk

from the frequency-domain sequence of r
X
La, Xk

after FFT
operation, which can be simply calculated as
Rd
k
La, Xk
 =
1
√
N
ek
r
X
La, Xk
T ,
(4.32)
where ek =
.exp
j 2π
N 0k
 exp
j 2π
N 1k
 · · · exp
j 2π
N (N −1) k
/
is the dis-
crete Fourier transform (DFT) harmonic vector. The novel demapping criterion is
then presented as [20]
Le
bk,i =
max
Xk∈X (0)
i

−1
σ2
+++Rd
k
La, Xk
 −Yk
+++
2
+ 1
2s
Xk
 La
bk
T

−
max
Xk∈X (1)
i

−1
σ2
+++Rd
k
La, Xk
 −Yk
+++
2
+ 1
2s
Xk
 La
bk
T

−La
bk,i.
(4.33)
With the aid of the decoding feedback LLR La, the associated LED nonlinearity
distortion on the candidate symbol Xk can be eﬀectively mitigated, which enhances
the accuracy of the output demapping LLR. The convergence performance of the
proposed BICM-ID receiver with the soft demapping criterion of (4.33) was reported
in [20], which also conﬁrms that a BER performance enhancement of around 1 dB
is achieved by the proposed iterative demapper in comparison to the conventional
counterpart when a low density parity check (LDPC) code is adopted as the channel
code.
4.2.3
PAPR reduction
Besides the narrow dynamic region of LEDs, the high PAPR of optical OFDM signal
is another major cause of severe nonlinear eﬀects. PAPR reduction techniques can
decrease the probability that the peak amplitude is nonlinearly distorted and enhance

108
the performance over the nonlinear channel. Many PAPR reduction algorithms have
been presented for RF multicarrier systems, as were reported in the overview [21].
Since VLC transmission systems adopt intensity modulation, these PAPR reduction
techniques for RF OFDM cannot be directly applied in optical OFDM systems. In
this subsection, a comprehensive introduction of PAPR reduction techniques for op-
tical OFDM is presented.
In optical OFDM, the PAPR of an OFDM block is deﬁned as
PAPR =
++++ max
0≤n<N {xn}
++++
2
E {x2n}
.
(4.34)
Since the PAPR varies in a large range for diﬀerent OFDM blocks, the complemen-
tary cumulative distribution function (CCDF) is used to depict the distribution of
PAPR, which is deﬁned as the probability that the PAPR exceeds the speciﬁc thresh-
old PAPR0 as
CCDF (PAPR0) = Pr (PAPR > PAPR0) .
(4.35)
The CCDF curve is an eﬀective metric to evaluate the PAPR reduction performance.
In the work [22], a universal PAPR reduction method for optical OFDM schemes
is proposed based on precoding technique. At the transmitter, the data symbol vector
Xs = [X1 X2 · · · XNs] is multiplied by a precoding matrix as
(Xp)T = P (Xs)T ,
(4.36)
where P is an Ns × Ns matrix which can be expressed as
P =
⎡
⎢⎢⎢⎣
p1,1
p1,2
· · ·
p1,Ns
p2,1
p2,2
· · ·
p2,Ns
...
...
...
...
pNs,1
pNs,2
· · ·
pNs,Ns
⎤
⎥⎥⎥⎦.
(4.37)
The precoded symbol vector Xp is allocated on the associated subcarriers with the
Hermitian symmetry (4.1) imposed for DCO-OFDM and ACO-OFDM or (4.13) im-
posed for PAM-DMT. Then, the frequency-domain symbol sequence is fed to the
IFFT converter to generate the time-domain sample sequence. The research [22]
recommended DFT, Zadoﬀ–Chu (ZC) sequence or discrete cosine transform (DCT)
based precoding matrix for DCO-OFDM and ACO-OFDM signals. Denoting the el-
ements of P as pDFT
n+1,k+1, pZC
n+1,k+1, and pDCT
n+1,k+1, 0 ≤n, k < Ns, for the DFT,
ZC sequence, and DCT precoding methods, respectively, one has
pDFT
n+1,k+1 =
1
√
Ns
exp

j 2π
Nsnk

,
(4.38)
pZC
n+1,k+1 =
⎧
⎨
⎩
1
√
Ns exp

j 2πr
Ns2

(nNs+k)2
2
+q (nNs+k)

,
Ns even,
1
√
Ns exp

j 2πr
Ns2

(nNs+k)2
2
+
q+ 1
2
 (nNs+k)

, Ns odd,
www.ebook3000.com

109
(4.39)
and
pDCT
n+1,k+1 =
⎧
⎨
⎩

1
Ns,
n = 0,

2
Ns cos

πn

2k+1
2Ns

,
n = 1, ..., Ns −1.
(4.40)
In (4.39), r is the code index relatively prime to Ns and q is any integer. Since the
precoded symbols are restricted to be real-valued in PAM-DMT, only DCT precod-
ing can be used. The precoding method ﬂattens the distribution of the time-domain
sample amplitude and reduces the PAPR eﬀectively. The simulation results present-
ed in [22] conﬁrm that the precoding methods with DCT and ZC precoding matrices
reduce the PAPR threshold at the CCDF level of 10−4 by over 3 dB for both ACO-
OFDM and PAM-DMT signals.
Another PAPR reduction technique called selective mapping (SLM) is also in-
troduced for DCO-OFDM [23]. The transmitter randomly generates R groups of
Ns-length phase factors pr
SLM = [pr
1 pr
2 · · · pr
Ns] for 1 ≤r ≤R, where pr
k =
exp
j w
W 2π

with w randomly taking the value from the set {0, 1, ..., W −1}.
The DCO-OFDM block X (pr
SLM) after applying SLM is
X (pr
SLM) = [pr
1X1 pr
2X2 · · · pr
NsXNs] .
(4.41)
By imposing the Hermitian symmetry and applying the IFFT operation, the time-
domain sample sequence {xn (pr
SLM)} is generated. The transmitter compares all
the PAPR values of the R groups of {xn (pr
SLM)} and selects the sequence with the
minimum PAPR for modulation into DCO-OFDM signal. Since the receiver requires
the information of the selected phase factor pr
SLM for demodulation, an additional
pilot block is embedded in the DCO-OFDM signal. In order to further reduce the
PAPR, the pilot-assisted SLM method [23] applies the same pr
SLM for consecutive U
DCO-OFDM blocks to minimize the PAPR of the (U +1)N-length sample sequence
including the additional pilot block. This pilot-assisted SLM technique reduces the
PAPR threshold at the CCDF level of 10−4 by around 2 dB.
Partial transmit sequence (PTS) is another PAPR reduction technique that is capa-
ble of enhancing the performance of ACO-OFDM over nonlinear channel [24].
In this technique, the symbol block is divided into the V disjoint clusters as
Xs = [X1 X2 · · · XV ]. By multiplying a V -length phase factor vector pr
PTS =
[pr
1 pr
2 · · · pr
V ] with Xs, it is transformed into
X (pr
PTS) = [pr
1X1 pr
2X2 · · · pr
V XV ] ,
(4.42)
which are allocated on the odd subcarriers and converted to the ACO-OFDM sam-
ple sequence {xn (pr
PTS)}. The transmitter is required to compute the optimal pr
PTS
to minimize the PAPR of {xn (pr
PTS)}. In order to transmit the side information of
phase factor, the proposed scheme in [24] modulates the optimal pr
PTS into a low-
power PAM-DMT signal, whereby pr
PTS is converted to a burst pulse shift key (B-
PSK) symbol and allocated on the imaginary parts of the even subcarriers. The trans-
mitter adds up the ACO-OFDM and PAM-DMT signals to drive the LED. Since the

110
clipping distortion of PAM-DMT falls on the real parts of even subcarriers and does
not aﬀect the data symbol on odd subcarriers, the receiver can recover the two signals.
Hence, the modiﬁed ACO-OFDM scheme based on PTS proposed in [24] does not
occupy extra spectral resource to transmit the information of phase factor. Accord-
ing to the simulation results of [24], this modiﬁed PTS technique achieves a PAPR
reduction of around 5 dB at the CCDF level of 10−4 and a performance gain of 1 dB
under the LED nonlinearity, compared to the conventional ACO-OFDM.
The PAPR reduction techniques for optical OFDM discussed so far impose
high computational cost.
In [25], a low-complexity recoverable upper-clipping
(RoC) was developed to reduce the PAPR of ACO-OFDM signals. Assuming that

xc
n, xc
n+N/2

for n = 0, 1, ..., N/2 −1 is the ACO-OFDM sample pair after
imposing the constraint from (4.8). The RoC scheme is expressed as [25]

xRoC
n , xRoC
n+N/2

=
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
{xc
n, 0} ,
0 < xc
n ≤A,

0, xc
n+N/2

,
0 < xc
n+N/2 ≤A,
{A, xc
n −A} ,
A < xc
n ≤(1 + α) A,

xc
n+N/2 −A, A

,
A < xc
n+N/2 ≤(1 + α) A,
{A, αA} ,
xc
n > (1 + α) A,
{αA, A} ,
xc
n+N/2 > (1 + α) A,
(4.43)
where A is the clipping threshold and 0 < α < 1 is a ﬁxed factor. Figure 4.8
illustrates three diﬀerent cases of upper-clipping. If the positive sample xc
n ranges
from A to (1 + α) A, xc
n is clipped at A and the clipped error xc
n −A is placed at
the (n+N/2)th sample, which is used to be zero. If xc
n exceeds (1 + α) A, it is still
clipped at A and the clipped error placed on the (n + N/2)th sample is restricted to
αA. Since α < 1, the clipped error is always lower than the associated recoverable
upper-clipped sample. This property helps the receiver to distinguish which sample
of the received sample pair

yRoC
n , yRoC
n+N/2

is allocated with the positive amplitude
of the ACO-OFDM signal sample. The original ACO-OFDM pair
)yn, yn+N/2
*
is
Origin Sample
Clipped Sample
A
A
 A
α A
α A
α A
 n
n+N/2
n+N/2
n+N/2
 n
 n
(1+α) A
(1+α) A
(1+α) A
Figure 4.8 Three cases of recoverable upper-clipping in RoC aided ACO-OFDM scheme.
www.ebook3000.com

111
simply recovered as [25]
)yn, yn+N/2
*
(4.44)
=
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
)yRoC
n , 0
* ,
yRoC
n
> yRoC
n+N/2 & yRoC
n
+ yRoC
n+N/2 ≤A,

0, yRoC
n+N/2

,
yRoC
n
≤yRoC
n+N/2 & yRoC
n
+ yRoC
n+N/2 ≤A,
)yRoC
n
+ A, 0
* ,
yRoC
n
> yRoC
n+N/2 & yRoC
n
+ yRoC
n+N/2 > A,

0, yRoC
n+N/2 + A

,
yRoC
n
≤yRoC
n+N/2 & yRoC
n
+ yRoC
n+N/2 > A.
A low clipping threshold A can reduce the peak amplitude signiﬁcantly but induce
severe clipping distortion and performance loss. The tradeoﬀbetween PAPR reduc-
tion and BER performance needs to be carefully considered to set an appropriate
value of A. On the condition that the demodulation threshold SNR at the BER level
of 10−3 almost coincides with the conventional ACO-OFDM, the RoC aided ACO-
OFDM scheme achieves a maximum PAPR reduction of around 5 dB at the CCDF
level of 10−4. Furthermore, over the optical channel which includes the LED non-
linearity, a signiﬁcant BER performance gain was observed with the proposed RoC
aided ACO-OFDM scheme.
4.3
Spectrum- and power-eﬃcient optical OFDM
As illustrated before, DCO-OFDM suﬀers from low power eﬃciency since a high DC
bias is required to maintain the non-negativity of the transmitted signals. Although
several power-eﬃcient optical OFDM schemes, such as ACO-OFDM, PAM-DMT,
and U-OFDM, have been proposed to avoid the DC bias, their spectral eﬃciencies
are reduced considerably. Consequently, these power eﬃcient schemes perform even
worse than DCO-OFDM when a high spectral eﬃciency is required. This is because
these schemes must employ higher constellation orders to meet the required spectral
eﬃciency. Recently, several spectrum- and power-eﬃcient optical OFDM schemes
have been proposed to overcome this diﬃculty.
4.3.1
Hybrid optical OFDM
Since ACO-OFDM only occupies the odd subcarriers for data transmission, the
even subcarriers can be employed to improve the spectral eﬃciency, and three
hybrid optical OFDM have been proposed recently. Asymmetrically clipped DC
biased optical OFDM (ADO-OFDM) is a combination of DCO-OFDM and ACO-
OFDM, where the ACO-OFDM signal is transmitted on the odd subcarriers and
the DCO-OFDM signal is transmitted on the even subcarriers [9, 26]. The sym-
bols in a data block X are divided into two parts Xodd and Xeven, where Xodd =
[0 X1 0, X3 0 · · · 0 XN−1] contains the odd-subcarrier symbols and Xeven =
[X0 0 X2 0 · · · XN−2 0] includes the even-subcarrier symbols.
Since X0 =

112
XN/2 = 0 and the Hermitian symmetry of (4.1) is imposed on X, both Xodd
and Xeven also satisfy the Hermitian symmetry.
After the IFFT operation, the
two time-domain signal vectors xodd = [xodd,0 xodd,1 · · · xodd,N−1] and xeven =
[xeven,0 xeven,1 · · · xeven,N−1] are obtained. The elements in both xodd and xeven are
real and bipolar.
However, the structure of xodd is the same as that of ACO-OFDM, and an ACO-
OFDM signal vector can be obtained by clipping the negative signals in xodd, leading
to
xACO = 1
2xodd + iACO,
(4.45)
where iACO denotes the clipping distortion vector. It has been proven in [7] that
the clipping distortion only falls on the even subcarriers after FFT, which will not
interfere with the useful information on the odd subcarriers. As for xeven, a DC bias
BDC is added and the remaining negative signals are clipped. The resultant DCO-
OFDM signal is written by
xDCO = xeven + BDC1 + iDCO,
(4.46)
where iDCO denotes the clipping distortion vector. Since Xeven only occupies the
even subcarriers, the elements of xeven follow the even symmetry
xeven,n = xeven,n+N/2, n = 0, 1, ..., N/2 −1.
(4.47)
After adding DC bias and clipping, the DCO-OFDM signal vector also follows the
same even symmetry
xDCO,n = xDCO,n+N/2, n = 0, 1, ..., N/2 −1.
(4.48)
Therefore, the clipping distortion vector of this DCO-OFDM signal also follows the
even symmetry
iDCO,n = iDCO,n+N/2, n = 0, 1, ..., N/2 −1,
(4.49)
and it will only interfere with information on the even subcarriers when transformed
to the frequency domain, which means that both the useful information and clipping
distortion are on the even subcarriers, and they will not aﬀect the useful information
in the ACO-OFDM signal. Hence, the two signal streams can be combined into the
single ADO-OFDM signal vector
xADO = xACO + xDCO
(4.50)
for simultaneous transmission.
Assuming an AWGN channel, the time-domain received signal vector can be writ-
ten as
y = xACO + xDCO + wAWGN
= 1
2xodd+iACO + xeven+BDC1+iDCO + wAWGN,odd + wAWGN,even,
(4.51)
www.ebook3000.com

113
where the channel AWGN vector wAWGN is decomposed into two parts wAWGN,odd
and wAWGN,even, whose DFTs WAWGN,odd and WAWGN,even correspond to the frequency-
domain AWGN samples on the odd and even subcarriers, respectively. Furthermore,
WAWGN,odd only corrupts the odd subcarriers, while WAWGN,even only distorts the
even subcarriers. Therefore, after FFT, the symbols on the odd subcarriers can be
written as
Yodd = 1
2Xodd + WAWGM,odd,
(4.52)
which can be used to detect the ACO-OFDM symbols directly. In order to demod-
ulate the DCO-OFDM symbols, however, the interference on the even subcarriers
induced by the ACO-OFDM signal should be removed ﬁrst. An estimation of the
transmitted ACO-OFDM signal can be made by performing the IFFT on Yodd and
clipping, yielding
yACO = 1
2xACO + iACO,est + wAWGN,odd,
(4.53)
where iACO,est is the estimated iACO since a noisy signal is used to reconstruct the
ACO-OFDM signal. The estimated ACO-OFDM signal is then subtracted from the
received signal y to obtain the DCO-OFDM signal by FFT
Y′
even = Xeven + IDCO + B′
DCO1 + IACO,est + WAWGN,even,
(4.54)
where B′
DCO denotes the DC component in the frequency domain, while IDCO and
IACO,est are the DFTs of iDCO and iACO,est, respectively. The DCO-OFDM symbols
can be detected with Y′
even, which contains not only the AWGN but also the estimated
distortion of ACO-OFDM.
ADO-OFDM utilizes all the subcarriers for modulation, which improves the spec-
tral eﬃciency compared to ACO-OFDM. However, DC bias is still required at the
branch of DCO-OFDM, which is not power eﬃcient. Therefore, a hybrid asym-
metrical clipped optical OFDM (HACO-OFDM) is proposed, which replaces DCO-
OFDM with unipolar PAM-DMT signals to avoid DC bias [27]. In the HACO-
OFDM scheme, the ACO-OFDM signal generated on the odd subcarriers is identical
to (4.45). As for the even subcarriers, however, only their imaginary parts are modu-
lated by PAM, so that the corresponding time-domain signals follow the asymmetry
as
xeven,n = −xeven,N−n, n = 1, ..., N/2 −1.
(4.55)
The PAM-DMT signal vector is obtained by clipping the negative signals in xeven,
resulting in
xPAM = 1
2xeven + iPAM,
(4.56)
where iPAM denotes the clipping distortion of PAM-DMT. The clipping distortion
only falls on the real parts of even subcarriers after FFT, which will not interfere

114
Figure 4.9 Block diagram of the transmitter for ADO-OFDM (top and middle branches)
and HACO-OFDM (bottom and middle branches).
with the useful information on the imaginary parts. Since both the useful symbols
and clipping distortion of xPAM are on the even subcarriers, they will not interfere
with the symbols of ACO-OFDM on the odd subcarriers. Therefore, PAM-DMT and
ACO-OFDM can be combined to generate the HACO-OFDM signal as
xHACO = xACO + xPAM.
(4.57)
For a convenient comparison, the transmitters of both ADO-OFDM and HACO-
OFDM are illustrated in Fig. 4.9.
In HACO-OFDM, diﬀerent modulation schemes are utilized for its ACO-OFDM
and PAM-DMT components, which have diﬀerent performance at the same SNR
level. Speciﬁcally, PAM-DMT only employs one signal dimension of the even sub-
carriers and, therefore, the SNR value required for PAM-DMT to achieve the same
BER performance is larger than that for ACO-OFDM with the same modulation or-
ders. If diﬀerent modulation orders are used for ACO-OFDM and PAM-DMT, the
required SNRs are also diﬀerent. For practical HACO-OFDM systems, it is highly
desired that the information transmitted from both ACO-OFDM and PAM-DMT has
similar performance. Therefore, the unequal power allocation of ACO-OFDM and
PAM-DMT was proposed in [28].
For ACO-OFDM with a QAM constellation of size MACO and PAM-DMT with a
PAM constellation of size MPAM, the BER performance of QAM and PAM can be
formulated as [29]
Pb,QAM ≈
4(√MACO −1)
√MACO log2 (MACO)Q

3
MACO −1
Es
N0

,
(4.58)
Pb,PAM ≈
2(MPAM −1)
MPAM log2 (MPAM)Q

6
M 2
PAM −1
Es
N0

,
(4.59)
www.ebook3000.com

115
where Es denotes the electrical energy per symbol and N0 represents the power
spectral density of the noise. Given a required BER value Pb, we can calculate nu-
merically, the required Es/N0 values for the MACO-QAM-based ACO-OFDM and
MPAM-PAM-based PAM-DMT to achieve the same BER Pb, which are denoted by
Es,ACO and Es,PAM, respectively. Then, the power allocation of ACO-OFDM and
PAM-DMT is determined by the power allocation factor
ηHACO =
Es,ACO
Es,ACO +
Es,PAM
,
(4.60)
which speciﬁes the proportion of the total optical power allocated to ACO-OFDM.
At the receiver, the detection of HACO-OFDM symbols is also divided into two
steps, similar to ADO-OFDM [27]. The ACO-OFDM symbols on odd subcarriers
can be detected ﬁrst by simple FFT. Afterwards, the clipping distortion of ACO-
OFDM is removed for the demodulation of the PAM-DMT symbols on even subcar-
riers. The entire detection procedure is the same as that given in Eqs. (4.51)–(4.54)
but with the notation “DCO” replaced by “PAM-DMT” and without the DC bias term.
Although the receiver of [27] is simple and straightforward, it does not eliminate the
interference between ACO-OFDM and PAM-DMT signals thoroughly, which limits
its performance. To further improve the performance of HACO-OFDM, an iterative
receiver was proposed in [28], which reduces the interference between ACO-OFDM
and PAM-DMT signals in the time domain by pairwise clipping.




Figure 4.10 Block diagram of the iterative receiver for HACO-OFDM.
The block diagram of the iterative receiver for HACO-OFDM is illustrated in
Fig. 4.10. In each iteration, the ACO-OFDM symbols on odd subcarriers are ﬁrst
detected using FFT. Then, the ACO-OFDM time-domain signal is regenerated and
subtracted from the received signal. The residual signal is considered as the inter-
fered PAM-DMT signal, and a pairwise clipping is applied to reduce the eﬀect of
noise and estimation error. The pairwise-clipped PAM-DMT signal is fed to the
FFT module to detect the PAM-DMT symbols, and the resulting time-domain PAM-
DMT signal is estimated. Afterwards, the estimated time-domain PAM-DMT signal

116
is subtracted from the received signal and the pairwise clipping is employed again to
acquire a more accurate ACO-OFDM signal. The receiver employs the received sig-
nal to detect the ACO-OFDM symbols in the ﬁrst iteration but the pairwise-clipped
ACO-OFDM signal is used in the subsequent iterations. We now detail the design of
this iterative receiver.
First iteration. FFT is performed on the received signal directly and the detection
of ACO-OFDM symbols is the same as (4.52). Let the resulting ML estimation be
denoted by 0
XACO,k for k = 1, 3, ..., N/2 −1. The estimated time-domain ACO-
OFDM samples 0xACO,n, n = 0, 1, ..., N −1, are regenerated with the aid of IFFT
and (4.45).
Unlike the conventional receiver where the subtraction takes place in the frequency
domain with the estimated ACO-OFDM symbols, the estimated time-domain ACO-
OFDM sample is subtracted from the received time-domain signal yn, resulting in
the interfered time-domain PAM-DMT signal as
0yPAM,n =yn −0xACO,n, n = 0, 1, ..., N −1.
(4.61)
By considering the ACO-OFDM estimation error iACO,est,n = xACO,n −0xACO,n,
which follows a Gaussian distribution according to the central limit theorem, and the
receiver noise wn, the above equation can be rewritten as
0yPAM,n =xPAM,n + wn + iACO,est,n, n = 0, 1, ..., N −1.
(4.62)
For PAM-DMT, half of the time-domain samples are set to zero by asymmetrical
clipping, and the remaining samples are non-negative. Therefore, for the pair of
transmitted samples {xPAM,n, xPAM,N−n}, where n = 0, 1, ..., N/2 −1, one of
them has to be zero. Similar to the algorithm proposed for ACO-OFDM in [10], the
pairwise ML detector can be used for PAM-DMT. Speciﬁcally, for n = 1, ..., N/2−
1, the following pairwise clipping is used
0yc
PAM,n = 0yPAM,nI{yPAM,N−n≤yPAM,n},
(4.63)
0yc
PAM,N−n = 0yPAM,N−nI{yPAM,N−n>yPAM,n},
(4.64)
where I{A} is the indicator function deﬁned by: I{A} = 1 if the event A is true,
and I{A} = 0 otherwise. If the estimation of zero-valued samples is suﬃcient accu-
rate, which is the case under high SNR scenarios, half of the noise and ACO-OFDM
estimation error are eliminated, and this achieves a considerable performance gain.
Besides that, as xPAM,0 = xPAM,N/2 = 0, 0yc
PAM,0 and 0yc
PAM,N/2 are also set to zero
to further reduce the noise and estimation error.
The pairwise-clipped PAM-DMT samples 0yc
PAM,n are fed to the FFT block to ob-
tain the frequency-domain symbols 0Y c
PAM,k, and the PAM-DMT symbols on even
subcarriers are estimated according to
0
XPAM,k = arg min
X∈XRe
+++X −2Im

0Y c
PAM,k
+++ , k = 2, 4, ..., N/2 −2.
(4.65)
www.ebook3000.com

117
0
XPAM,k of (4.65) is more accurate since part of the noise and estimation error are
eliminated. It is used to further improve the estimation accuracy of the ACO-OFDM
symbols in an iterative way, where the time-domain PAM-DMT samples are also
regenerated and subtracted from the received samples to yield
0yACO,n =yn −0xPAM,n, n = 0, 1, ..., N −1,
(4.66)
where 0yACO,n contains both the receiver noise wn and the PAM-DMT estimation
error iPAM,n = xPAM,n −0xPAM,n. Thus, the above equation can be rewritten as
0yACO,n =xACO,n + wn + iPAM,n, n = 0, 1, ..., N −1.
(4.67)
As with the ACO-OFDM scheme, iPAM,n also follows a Gaussian distribution. Simi-
lar to the PAM-DMT signal, a pairwise clipping could also be employed to the ACO-
OFDM samples to reduce the noise and estimation error. Due to the symmetry struc-
ture of ACO-OFDM, for n = 0, 1, ..., N/2 −1, one has
0yc
ACO,n = 0yACO,nI{yACO,n+N/2≤yACO,n},
(4.68)
0yc
ACO,n+N/2 = 0yACO,n+N/2I{yACO,n+N/2>yACO,n}.
(4.69)
Second and subsequent iterations. The pairwise-clipped ACO-OFDM samples
0yc
ACO,n are used for detection. After obtaining the frequency-domain symbols 0Y c
ACO,k
by FFT, the ACO-OFDM symbols on odd subcarriers are estimated according to
0
XACO,k = arg min
X∈X
+++X −20Y c
ACO,k
+++ , k = 1, 3, ..., N/2 −1.
(4.70)
The iteration continues by conducting the estimation of PAM-DMT symbols, until
the preset maximum number of iterations is reached.
Compared to the conventional counterpart given in [27], this iterative receiver re-
quires one more IFFT and two pairwise-clipping modules. The IFFT module has low
complexity since it is usually integrated in hardware, while the pairwise clipping can
be realized by simple comparison operations. Therefore, this iterative receiver only
increases the complexity slightly.
The BER performance of the iterative receiver is evaluated by simulations, in com-
parison to the conventional receiver of [27]. Two diﬀerent HACO-OFDM systems
are used: (Case 1) ACO-OFDM-4QAM and PAM-DMT-4PAM, and (Case 2) ACO-
OFDM-16QAM and PAM-DMT-16PAM. The size of FFT/IFFT in the transmitter is
set to 512 for both ACO-OFDM and PAM-DMT. The iteration number of our pro-
posed iterative receiver is set to 2.
To guarantee that ACO-OFDM and PAM-DMT signals have similar BER perfor-
mance at the same Eb,elec/N0, unequal power allocation is considered. By setting
the target BER to Pb = 10−3, the corresponding power allocation factors are found
to be 0.3942 and 0.2650 for Case 1 and Case 2, respectively. The BER performances
are shown in Figs. 4.11 and 4.12 for those two cases, respectively. It can be seen that
the required Eb,elec/N0 values for ACO-OFDM and PAM-DMT are very close at the

118
BER level of 10−3 for both cases, which is consistent with the theoretical analysis. It
can also be seen that the iterative receiver outperforms its conventional counterpart.
Speciﬁcally, at the BER of 10−3, the iterative receiver achieves 1.56 dB and 1.91 dB
gains for the ACO-OFDM and PAM-DMT components in Case 1, while the perfor-
mance gains become 2.05 dB and 2.62 dB in Case 2. At the BER level of 10−4,
the iterative receiver achieves 1.78 dB and 2.00 dB gains for the ACO-OFDM and
PAM-DMT signals in Case 1, while the performance gains are 2.25 dB and 2.66 dB,
respectively, in Case 2.
4.3.2
Enhanced U-OFDM
Hybrid optical OFDM schemes combine diﬀerent optical OFDM schemes to utilize
all the available subcarriers, which improves the spectral eﬃciency of ACO-OFDM.
However, DC bias is still required in ADO-OFDM, which degrades the power eﬃ-
ciency of its ACO-OFDM component. In HACO-OFDM, only the imaginary parts of
even subcarriers are employed for PAM-DMT modulation, which wastes a quarter
Figure 4.11 BER performance comparison of the conventional and iterative receivers for
HACO-OFDM (Case 1 with power allocation factor η = 0.3942).
8
10
12
14
16
18
10
−4
10
−3
10
−2
10
−1
10
0
 Eb,elec/ N0 (dB)
BER
Conventional, ACO−OFDM in HACO−OFDM
Conventional, PAM−DMT in HACO−OFDM
Iterative, ACO−OFDM in HACO−OFDM
Iterative, PAM−DMT in HACO−OFDM
www.ebook3000.com

119
5
10
15
20
25
30
10
−4
10
−3
10
−2
10
−1
10
0
 Eb,elec/ N0 (dB)
BER
Conventional, ACO−OFDM in HACO−OFDM
Conventional, PAM−DMT in HACO−OFDM
Iterative, ACO−OFDM in HACO−OFDM
Iterative, PAM−DMT in HACO−OFDM
Figure 4.12 BER performance comparison of the conventional and iterative receivers for
HACO-OFDM (Case 2 with power allocation factor η = 0.2650).
of the spectral resource. To avoid spectral eﬃciency loss, an enhanced U-OFDM
(eU-OFDM) was proposed in [30, 31].
Figure 4.13 eU-OFDM transmitter with three modulation depths.
The transmitter of eU-OFDM is illustrated in Fig. 4.13, which combines diﬀerent
depths of U-OFDM streams for simultaneous transmission. Each depth employs the

120
conventional U-OFDM with diﬀerent repetitions, where the sub-frame correspond-
ing to the positive signals is labeled with P and the reversed negative sub-frame is
labeled with N. In the subscript, the ﬁrst number denotes the depth index, while
the second number represents the frame index. In Depth 1, the transmitted signal is
exactly the same as the conventional U-OFDM, as described in Section 4.1.3. CP
is added before each negative and positive frames to avoid ISI. In Depth 2, since
the signals are superimposed on those of Depth 1, they should not interfere with the
recovery of signals in Depth 1. In order to achieve this goal, the U-OFDM stream
is repeated twice for both the positive and negative frames, as shown in Fig. 4.13.
Since the demodulation of Depth 1 U-OFDM is carried out by subtracting the neg-
ative frame from the positive frame, the Depth 2 signals will not interfere with this
demodulation as long as they are periodic within the U-OFDM frame in Depth 1.
Therefore, in Depth 2, each U-OFDM frame is divided into two sub-frames for rep-
etition. First, the positive sub-frame is repeated twice, which corresponds to the ﬁrst
frame of U-OFDM in Depth 1. Subsequently, the negative sub-frame is repeated
twice corresponding to the second frame of U-OFDM in Depth 1. Since each U-
OFDM signal is transmitted twice in Depth 2, the signals should be scaled by

1/2
to maintain the same energy per bit as in Depth 1.
Similarly, another stream can be added for simultaneous transmission, referred to
as Depth 3. In Depth 3, the U-OFDM signals should be periodic within the U-OFDM
frame in Depth 2, so that they can be eliminated at the demodulation of Depth 2 sig-
nals. Speciﬁcally, the positive and negative sub-frames of U-OFDM are transmitted
four times in Depth 3, respectively. In this way, the Depth 3 signals are also periodic
within the U-OFDM frame in Depth 1, which will not interfere with the demodula-
tion of Depth 1 either. In order to keep the energy per bit constant at all streams, the
signals in Depth 3 should be scaled by

1/4 since all the signals are transmitted for
four times. Analogously, additional streams can be added for simultaneous transmis-
sion. For Depth d, the positive and negative sub-frames of U-OFDM are transmitted
2d−1 times and the signals are scaled by
√
21−d, so that they will not interfere with
the demodulation of Depth 1 to Depth d−1.
At the receiver, the demodulation of diﬀerent depths is conducted in a serial man-
ner. Depth 1 can be simply demodulated as conventional U-OFDM as described
in Section 4.1.3. Speciﬁcally, the negative sub-frame is subtracted from the posi-
tive sub-frame. For example, the demodulation of the ﬁrst frame utilizes the FFT of
P11 −N11. Due to the special design of eU-OFDM, the interference from all the
other depths for P11 is exactly the same as that for N11, which can be completely
eliminated by the subtraction operation. Therefore, the information bits in Depth 1
can be successfully demodulated by the conventional U-OFDM receiver. After the
demodulation of Depth 1, the information bits are used to regenerate the U-OFDM
signals as an estimation of time-domain Depth 1 signals, which are then subtracted
from the received signals for the demodulation of other depths. The resultant signals
contain the signals of Depth 2 and subsequent depths, as well as the receiver noise
and the estimation error of Depth 1. For the demodulation of Depth 2, since all the
signals are transmitted twice, they need to be summed to obtain diversity gain. For
example, the ﬁrst two positive sub-frames corresponding to the time slot of P11 and
www.ebook3000.com

121
N11 are summed to get P21, and the third and the fourth sub-frames corresponding
to the time slot of P12 and N12 are summed to obtain N21. Afterwards, P21 −N21
is used for the demodulation of Depth 2 as conventional U-OFDM demodulation.
After demodulation of Depth 2, the information bits are then used for the estimation
of the time-domain Depth 2 signals, which are removed from the subtracted received
signals of Depth 1 to demodulate other depths in a similar way. It can be seen that in
the demodulation of each depth, the interference from the subsequent depths will not
interfere with the recovery due to the special structure of eU-OFDM. After the in-
formation bits are recovered at each depth, they are used to regenerate the U-OFDM
signals as an estimation of the corresponding time-domain signals, which are then
subtracted from the residual received signals for the demodulation of the subsequent
depths.
The eU-OFDM scheme achieves higher spectral eﬃciency compared with con-
ventional U-OFDM since more streams are transmitted at the same time. When D
depths are used, the spectral eﬃciency of eU-OFDM can be calculated by summing
the spectral eﬃciencies of all the individual streams as
ξeU(D) =
D

d=1
ξU
2d−1 = 2ξU

1 −
1
2
D
,
(4.71)
where ξU denotes the spectral eﬃciency of Depth 1 U-OFDM stream. It can be seen
that the spectral eﬃciency of eU-OFDM increases with the number of depths used.
If D is very high, ξeU(D) converges to 2ξU, which is also the same as the spectral
eﬃciency of DCO-OFDM. Since DC bias is not required in eU-OFDM, it is more
power eﬃcient than DCO-OFDM.
For practical implementation, eU-OFDM has its disadvantages. The frame length
of eU-OFDM with D depths is 2D−1 times of conventional U-OFDM, and 2D times
of DCO-OFDM. The demodulation of all the D depths of eU-OFDM has to be car-
ried out in depth-by-depth manner and, therefore, the detection latency is very large
compared with conventional optical OFDM schemes. In addition, since diﬀerent
U-OFDM streams are required at the transmitter, the complexity is also increased.
4.3.3
Layered ACO-OFDM
Layered ACO-OFDM (LACO-OFDM) proposed in [32] achieves the same spec-
tral eﬃciency as eU-OFDM by simultaneously transmitting multiple ACO-OFDM
streams, but it reduces the latency since it has a smaller frame length.
In LACO-OFDM, Layer 1 ACO-OFDM is the same as conventional ACO-OFDM,
whose time-domain samples are rewritten as x(1)
ACO,n for n = 0, 1, ..., N −1, where
the superscript represents the layer index. For an OFDM block in which only even

122
subcarriers are modulated, its output is deﬁned as
xn =
1
√
N
N/2−1
k=0
X2k exp

j 2πn
N 2k

=
√
2
2
1

N/2
N/2−1
k=0
X(2)
k
exp

j 2πn
N/2k

=
√
2
2 x(2)
mod (n,N/2), n = 0, 1, ..., N −1,
(4.72)
where X(2)
k
= X2k,

x(2)
n

denotes the N/2-point IFFT of

X(2)
k

, and
mod (·, N) represents the modulo N operator.
It can be seen that xn is peri-
odic and can be obtained by repeating the signal x(2)
n
twice. If only the subcarriers
with odd indices of

X(2)
k

, i.e., X2(2k+1) for k = 0, 1, ..., N/4 −1, are used
for modulation, the time-domain signal x(2)
n , n = 0, 1, ..., N/2 −1, follows a
half-length symmetry as
x(2)
n
= −x(2)
n+N/4, n = 0, 1, ..., N/4 −1,
(4.73)
which can be clipped at zero without information loss. After asymmetric clipping,
another ACO-OFDM stream, Layer 2 ACO-OFDM, can be obtained, which is denot-
ed as x(2)
ACO,n, where x(2)
ACO,n = x(2)
ACO, mod (n,N/2), n = 0, 1, ..., N −1. Similar
to the conventional ACO-OFDM, the negative clipping distortion of x(2)
ACO,n falls on
the subcarriers with even indices of X(2)
k , k = 0, 1, ..., N/2 −1, corresponding
to the 4kth (k = 0, 1, ..., N/4 −1) subcarriers in the conventional ACO-OFDM.
Therefore, both the signal and clipping distortion of Layer 2 ACO-OFDM only fall
on the even subcarriers and do not contaminate the Layer 1 ACO-OFDM signal. By
transmitting Layer 1 and Layer 2 ACO-OFDM signals simultaneously, 3/4 of all
the subcarriers are utilized, which improves the spectral eﬃciency of conventional
ACO-OFDM by 50%. In Layer 2 ACO-OFDM, half of the even subcarriers, i.e.,
N/4 subcarriers, are modulated. The 4kth (k = 0, 1, ..., N/4 −1) subcarriers
remain unoccupied, which can be used to further improve the spectral eﬃciency.
In general, Layer l ACO-OFDM for 1 ≤l < log2 N is deﬁned as follows. For an
OFDM block in which only the 2l−1kth (k = 0, 1, ..., N/2l−1 −1) subcarriers are
modulated,
xn =
1
√
N
N/2l−1−1
k=0
X2l−1k exp

j 2πn
N 2l−1k

=
1
√
2l−1
1

N/2l−1
N/2l−1−1
k=0
X(l)
k exp

j
2πn
N/2l−1 k

=
1
√
2l−1 x(l)
mod (n,N/2l−1), n = 0, 1, ..., N −1,
(4.74)
where X(l)
k
= X2l−1k and

x(l)
n

denotes the N/2l−1-point IFFT of

X(l)
k

. It
can be seen that xn is also periodic and can be obtained by repeating the N/2l−1-
www.ebook3000.com

123
length signal x(l)
n .
The Layer l ACO-OFDM signal x(l)
ACO,n, where x(l)
ACO,n =
x(l)
ACO, mod (n,N/2l−1), n = 0, 1, ..., N −1, can be generated by modulating the
subcarriers with odd-indexed X(l)
k
and N/2l subcarriers are utilized. Both the sig-
nal and clipping distortion of x(l)
ACO,n only fall on the subcarriers of X(l)
k , i.e., the
2l−1kth (k = 0, 1, ..., N/2l−1 −1) subcarriers of the original ACO-OFDM signal.
Therefore, diﬀerent layers of ACO-OFDM signals can be generated, and the signal
and clipping distortion of the Layer l ACO-OFDM will not interfere with the useful
symbols in Layer 1 to Layer (l −1) ACO-OFDM. The examples of Layer 1, Layer
2, and Layer 3 ACO-OFDM signals are illustrated in Fig. 4.14, where 16 subcarriers
are utilized for modulation.
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
1
1∗
2
2∗
3
3∗
4
4∗
0
1
2
3
4
5
6
7
5
5∗
6
6∗
0
1
2
3
7
7∗
Figure 4.14 Examples of Layer 1, Layer 2, and Layer 3 ACO-OFDM signals with 16
subcarriers.
Thus, in the LACO-OFDM scheme, diﬀerent layers of ACO-OFDM can be com-
bined in the time domain for simultaneous transmission. The time-domain LACO-
OFDM signal with L layers is written as
xLACO,n =
L
l=1 x(l)
ACO,n =
L
l=1

x(l)
n + i(l)
n

, n = 0, 1, ..., N −1, (4.75)
where x(l)
n and i(l)
n denote the unclipped signal and the negative clipping distortion
of Layer l ACO-OFDM, respectively. The number of occupied subcarriers in the
LACO-OFDM with L layers can be calculated by
NLACO =
L
l=1 N/2l = (1 −1/2L)N,
(4.76)
which is (2 −1/2L−1) times of conventional ACO-OFDM. When the maximum
number of layers L = log2 N −1 is used, the spectral eﬃciency of LACO-OFDM
is (2 −4/N) times of conventional ACO-OFDM, which converges to 2 when N is
large.
The block diagram of LACO-OFDM transmitter is summarized in Fig. 4.15, where
for simplicity the modulator, Hermitian symmetry, CP insertion and P/S operations
are omitted. After bit-to-symbol modulation, the modulated symbol stream is ﬁrst

124
Figure 4.15 Block diagram of LACO-OFDM transmitter with L layers.
divided into L streams for layered transmission. In the Layer l ACO-OFDM, only
the 2l−1(2k + 1)th (k = 0, 1, ..., N/2l −1) subcarriers are modulated, which
are orthogonal to all the other layers. Due to the periodicity of the time-domain
signals as shown in (4.74), the Layer l ACO-OFDM can be simply implemented
by N/2l−1-point IFFT and the N/2l−1-length signal is then repeated 2l−1 times
to obtain the N-length OFDM signal block. Afterwards, the time-domain signals
from L layers of ACO-OFDM are combined for simultaneous transmission. Since
asymmetric clipping is performed in all the L layers, the combined LACO-OFDM
signals are also non-negative and no DC bias is required for obtaining unipolar time-
domain signals.
At the receiver, the shot noise and thermal noise are usually modeled by an AWGN,
and the received samples are given by yn = xLACO,n + wn, n = 0, 1, ..., N −1,
where wn denote the samples of the AWGN. The received signal samples are fed to
the FFT block to generate the frequency-domain symbols as Yk = XLACO,k + Wk
for k = 0, 1, ..., N −1, where Wk denotes the frequency-domain representation of
the AWGN.
In LACO-OFDM, diﬀerent layers utilize diﬀerent subcarriers, which are orthogo-
nal in the frequency domain. However, due to the asymmetric clipping operation at
the transmitter, the negative clipping distortion falls on the even subcarriers in each
layer, which distorts the higher layers. For Layer l ACO-OFDM, the negative clip-
ping distortion falls on the 2l−1(2k)th (k = 0, 1, ..., N/2l −1) subcarriers, where
the Layer (l+1) ACO-OFDM stream is modulated. Therefore, the symbols in Layer
(l + 1) can be recovered only after the negative clipping distortions from the Layer
1 to Layer l have been removed.
For Layer l ACO-OFDM, denote the received frequency-domain symbol and neg-
ative clipping distortion by 0Y (l)
ACO,k and 0I(l)
ACO,k, where k = 0, 1, ..., N/2l−1 −1.
For Layer 1 ACO-OFDM, the transmitted symbols can be directly detected by using
the odd subcarriers of Yk according to
0
X(1)
ACO,k = arg min
X∈X
			X −20Y (1)
ACO,k
			 , k = 1, 3, ..., N/2 −1,
(4.77)
www.ebook3000.com

125
where 0Y (1)
ACO,k = Yk and the factor 2 is due to the fact that the clipping operation
reduces the power of ACO-OFDM symbols in the odd subcarriers by half. The esti-
mated time-domain Layer 1 ACO-OFDM samples 0x(1)
ACO,n can be regenerated from
0
X(1)
ACO,k, and the frequency-domain negative clipping distortion 0I(1)
ACO,k of Layer 1
ACO-OFDM can also be estimated by performing the FFT on 0x(1)
ACO,n. After sub-
tracting 0I(1)
ACO,k from the received frequency-domain symbols on the even subcarriers,
the Layer 2 ACO-OFDM symbols can be detected.
For Layer l (l > 1) ACO-OFDM, after removing the negative clipping distortions
from Layer 1 to Layer (l−1) ACO-OFDM, the received frequency-domain symbols
can be expressed as
0Y (l)
ACO,k =Y2l−1k −
l−1
m=1
0I(m)
ACO,2l−mk
=0Y (l−1)
ACO,2k −0I(l−1)
ACO,2k, k = 0, 1, ..., N/2l−1 −1,
(4.78)
where only one subtraction operation per symbol is required. Similar to (4.77), the
transmitted symbols in Layer l ACO-OFDM are detected according to
0
X(l)
ACO,k = arg min
X∈X
			X −20Y (l)
ACO,k
			 , k = 1, 3, ..., N/2l−1 −1.
(4.79)
If l = L, the detection is completed. Otherwise, 0I(l)
ACO,k and hence 0Y (l+1)
ACO,k are gen-
erated to detect the transmitted symbols in Layer l + 1 ACO-OFDM.
The spectral eﬃciencies of the LACO-OFDM and the conventional ACO-OFDM
are compared in Fig. 4.16, where the length of CP is omitted from the calculation of
spectral eﬃciency. It can be seen that the LACO-OFDM scheme improves the spec-
tral eﬃciency signiﬁcantly, compared to the ACO-OFDM of the same modulation
order. The spectral eﬃciency of LACO-OFDM improves when the layer number in-
creases and it converges to twice of conventional ACO-OFDM when the layer number
is suﬃciently large. Even with a small number of layers such as L = 4, the 87.5%
spectral eﬃciency improvement is still considerable. When LACO-OFDM with two
and three layers modulated by 16QAM are used, they achieve the same spectral eﬃ-
ciencies as ACO-OFDM with 64QAM and 128QAM, respectively. Therefore, lower
modulation orders can be adopted in LACO-OFDM to achieve the same spectral ef-
ﬁciency as ACO-OFDM, which has the advantage of lower SNR requirement at the
receiver.
To guarantee that the information bits in diﬀerent layers have similar performance,
the modulation scheme and average power of modulated subcarriers should be the
same in each layer. In Layer 1 ACO-OFDM, the symbols are directly detected with
the received signals and they are only distorted by the noise at the receiver. In other
layers, however, the symbols are also distorted by the estimation error of the nega-
tive clipping distortion in previous layers, which could degrade their performance.
Fortunately, when the SNR increases, the estimation of negative clipping distortion
becomes more accurate and the performance of the other layers converges to that of
Layer 1, which has been veriﬁed by simulations.

126
1
2
3
4
5
6
7
8
0
0.5
1
1.5
2
2.5
3
3.5
4
Layer Number
Spectral Efficiency (bit/s/Hz)
LACO−OFDM−16QAM
LACO−OFDM−64QAM
ACO−OFDM−16QAM
ACO−OFDM−64QAM
ACO−OFDM−128QAM
ACO−OFDM−256QAM
Figure 4.16 Spectral eﬃciency comparison between LACO-OFDM and ACO-OFDM.
The complexity of an LACO-OFDM transceiver is analyzed in two parts.
At
the transmitter, only one N-point IFFT is required in conventional ACO-OFDM
and its complexity can be written as O
N log2 (N)

.
In LACO-OFDM with
L layers, however, L diﬀerent sizes of IFFT blocks are employed, and the to-
tal computational complexity increases to
L

l=1
O
N/2l−1 log2
N/2l−1 
≈
2 −1/2L−1 O
N log2 (N)

.
Therefore, the computational complexity of
LACO-OFDM transmitter is less than twice of the conventional ACO-OFDM
transmitter and this complexity increase is the same as the spectral eﬃciency im-
provement. Since the L layers are calculated at the same time, there is no more
latency compared with conventional ACO-OFDM. At the receiver, the compu-
tational complexity of conventional ACO-OFDM is also O
N log2 (N)

since
only one N-point FFT is utilized. In LACO-OFDM with L layers, the compu-
tational complexity is O
N log2 (N)
 + 2
L−1

l=1
O
N/2l−1 log2
N/2l−1  ≈
5 −1/2L−3 O
N log2 (N)

, which is less than ﬁve times the conventional
ACO-OFDM receiver.
In hardware implementation, the complexity of LACO-
OFDM receiver is only twice the conventional one since the N-point FFT/IFFT
block can be reused. With the assumption that N is the power of 2, for the sequence
www.ebook3000.com

127
Figure 4.17 BER performance of LACO-OFDM with 16QAM and four layers.
with length N/2l, an N-length sequence can be obtained by zero-padding and the
same N-point FFT/IFFT block can be shared. The serial structure also leads to
extra latency in the LACO-OFDM receiver. Fortunately, when the number of layers
increases, the sizes of FFT/IFFT used in the iterative receiver decrease exponentially
and the latency of the iterative receiver is also
5 −1/2L−3
times the conventional
ACO-OFDM receiver, which is acceptable considering the improvement of spectral
eﬃciency. Compared with eU-OFDM, LACO-OFDM has much smaller frame size,
which signiﬁcantly reduces the latency.
The BER performance of the LACO-OFDM is evaluated by simulations. The num-
ber of IFFT points used at the transmitter is 512, and the subcarriers are modulated
by16QAM in all layers. Figure 4.17 shows the BER performance of LACO-OFDM
with four layers, where the BER in each layer of LACO-OFDM is calculated sepa-
rately. For the same Eb,elec/N0 level, the BER increases with the layer number since
the symbols in higher layers are distorted by the estimation error of the lower layers.
However, as shown in Fig. 4.17, when Eb,elec/N0 increases, the estimation accuracy
improves with the reduction of BER in higher layers, and the four BER curves con-
verge to one, which is also the working point for the practical system. This result
also matches the performance analysis.
5
10
15
20
10
−4
10
−3
10
−2
10
−1
10
0
 Eb,elec/ N0 (dB)
BER
 Layer 1 ACO−OFDM
 Layer 2 ACO−OFDM
 Layer 3 ACO−OFDM
 Layer 4 ACO−OFDM

128
5
10
15
20
25
10
−4
10
−3
10
−2
10
−1
10
0
 Eb,elec/ N0 (dB)
BER
ACO−OFDM−16QAM
ACO−OFDM−64QAM
ACO−OFDM−128QAM
LACO−OFDM−16QAM with 2 Layers
LACO−OFDM−16QAM with 3 Layers
LACO−OFDM−16QAM with 4 Layers
HACO−OFDM−16QAM−4PAM
HACO−OFDM−64QAM−2PAM
Figure 4.18 BER performance comparison of LACO-OFDM, ACO-OFDM, and
HACO-OFDM.
The average BER of LACO-OFDM is compared with that of conventional ACO-
OFDM and HACO-OFDM in Fig. 4.18, where BERs of all layers in LACO-OFDM
are averaged. In LACO-OFDM, the subcarriers are modulated by 16QAM in all
layers. The numbers of layers are set to 2, 3, and 4, and the spectral eﬃciencies
are 1.5 bit/s/Hz, 1.75 bit/s/Hz, and 1.875 bit/s/Hz, respectively. Three diﬀerent kinds
of ACO-OFDM are used for comparison, where the odd subcarriers are modulat-
ed by 16QAM, 64QAM, and 128QAM, corresponding to the spectral eﬃciencies of
1 bit/s/Hz, 1.5 bit/s/Hz, and 1.75 bit/s/Hz, respectively. In HACO-OFDM, the odd
subcarriers are modulated by ACO-OFDM with 16QAM and 64QAM and the even
subcarriers are modulated by PAM-DMT with 4PAM and 2PAM, corresponding to
the spectral eﬃciencies of 1.5 bit/s/Hz and 1.75 bit/s/Hz. The optimal proportion
of optical power for HACO-OFDM is obtained by the method in [27], and the pro-
portions of optical power allocated to ACO-OFDM block are 0.6 and 0.85 for two
diﬀerent HACO-OFDM schemes.
When the same modulation orders are used, the performance of LACO-OFDM is
worse than the conventional ACO-OFDM, which is due to the fact that the power of
ACO-OFDM in each layer is smaller than that of the conventional ACO-OFDM since
it is distributed to diﬀerent layers. For example, at the BER of 10−4, the performance
www.ebook3000.com

129
degradations of LACO-OFDM-16QAM with 2, 3, and 4 layers are 1.2 dB, 2.0 dB,
and 2.6 dB compared with the conventional ACO-OFDM-16QAM, but the spectral
eﬃciency is improved by 50%, 75%, and 87.5% as shown in Fig. 4.16.
When the three schemes with the same spectral eﬃciency are compared, it can
be seen that LACO-OFDM signiﬁcantly outperforms the conventional ACO-OFDM,
and it is also better than HACO-OFDM. The LACO-OFDM-16QAM with two layers
achieves 3.1 dB gain compared with the ACO-OFDM-64QAM with the same spec-
tral eﬃciency of 1.5 bit/s/Hz, and it is also slightly better than HACO-OFDM with
the same spectral eﬃciency. For the LACO-OFDM-16QAM with three layers, it also
outperforms ACO-OFDM-128QAM by 3.1 dB with the same spectral eﬃciency of
1.75 bit/s/Hz. Even compared with HACO-OFDM with the same spectral eﬃciency,
the performance gain is still 1.77 dB. When LACO-OFDM-16QAM with four lay-
ers is employed, which has 0.125 bit/s/Hz more spectral eﬃciency compared with
ACO-OFDM-128QAM, the performance gain is 2.4 dB.
In order to fully exploit the structure of LACO-OFDM signals, an improved re-
ceiver was proposed in [33] to further enhance the performance of LACO-OFDM,
where diﬀerent layers of ACO-OFDM signals are distinguished in the time domain
and pairwise clipping is utilized in each layer.
The signals in diﬀerent layers of LACO-OFDM are ﬁrst separated in the time do-
main. The symbols on Layer 1 ACO-OFDM are detected after FFT as in (4.77). The
time-domain signals in Layer 1 ACO-OFDM are reconstructed by
ˆy(1)
n
=
N−1

k=0
ˆX(1)
ACO,k exp

j 2π
N nk

, n = 0, 1, ..., N −1,
(4.80)
where ˆX(1)
ACO,k =

ˆX(1)
ACO,N−k
∗
.
Afterwards, the reconstructed signals ˆy(1)
n
are discarded from the original received
signals yn, where the remaining signals ˜y(2)
n
= yn −ˆy(1)
n
can be considered as the
combination of the signals in Layer 2 ∼L ACO-OFDM. Since the signals ˆy(1)
n
containing both the transmitted symbols and clipping distortion in Layer 1 ACO-
OFDM are already removed, the symbols in Layer 2 ACO-OFDM can be directly
detected after FFT as well.
When the symbols in Layer 1 ∼l −1 (l > 1) ACO-OFDM are detected, all of
their reconstructed signals are subtracted from the original received signals yn, and
one has
˜y(l)
n = yn −
l−1

m=1
ˆy(m)
n
= ˜y(l−1)
n
−ˆy(l−1)
n
,
(4.81)
where ˜y(1)
n
= yn and the reconstructed time-domain signals in Layer l ACO-OFDM
are given by
ˆy(l)
n =
N/2l−1−1

k=0
ˆX(l)
ACO,k exp

j 2π
N n · 2l−1k

,
(4.82)

130
for n = 0, 1, ..., N −1.
The symbols in Layer l ACO-OFDM can be directly detected after the FFT of ˜y(l)
n .
It can be seen that in LACO-OFDM with L layers, ˜y(l)
n contains more than one layer
of ACO-OFDM when l < L. However, ˜y(L)
n
only includes the signals in Layer
L ACO-OFDM since all the signals from Layer 1 ∼L −1 have been removed.
Therefore, the structure of Layer L ACO-OFDM can be utilized to further improve
the performance.
Denote the received signals with only Layer l ACO-OFDM as ¯y(l)
n = x(l)
n +wn +
e(l)
n , where e(l)
n is the inter-layer interference and it follows a Gaussian distribution
according to the central limit theorem, and we have ¯y(L)
n
= ˜y(L)
n
. In Layer l ACO-
OFDM, the transmitted time-domain signals are periodic. Besides, an asymmetric
clipping is imposed on the time-domain signals so that either x(l)
n or x(l)
n+N/2l is zero
when they are transmitted, and the remaining signals are non-negative. Therefore,
one can estimate which signal should be set to zero according to ¯y(l)
n , and half of the
noise and inter-layer interference are eliminated. In Layer l ACO-OFDM, consider-
ing the periodicity of the signals, the pairwise clipping is modiﬁed as
¯y(l)
n,c =

¯y(l)
n IH(n′),
n′ ≤N/2l,
¯y(l)
n
1 −IH(n′−N/2l)
 ,
n′ > N/2l,
(4.83)
where n′ =
mod (n, N/2l−1) and I{A} is an indicator function with I{A} = 1
if the event A is true and I{A} = 0 otherwise. H(n′) is deﬁned as
H(n′) :
2l−1−1

m=0
¯y(l)
n′+mN/2l−1 ⩾
2l−1−1

m=0
¯y(l)
n′+N/2l+mN/2l−1.
(4.84)
Pairwise clipping is ﬁrst utilized in Layer L ACO-OFDM signals since ¯y(L)
n
can be
obtained after signals of all the other layers are removed. Afterwards, the pairwise-
clipped signal is used to demodulate the symbols in Layer L ACO-OFDM, which
can achieve better performance compared with the conventional method since half
of the noise and inter-layer interference have been eliminated, and the received time-
domain signals in Layer L ACO-OFDM are reconstructed.
Since the time-domain signals in each layer have been reconstructed, the received
signals with only Layer l ACO-OFDM can be obtained by subtracting the signals in
other layers from the received signals as
¯y(l)
n = yn −

m̸=l
ˆy(m)
n
,
(4.85)
so that diﬀerent layers of ACO-OFDM signals are distinguished in the time domain
and pairwise clipping can be applied to eliminate half of the noise and inter-layer
interference.
The symbols on Layer l ACO-OFDM are detected again after pairwise clipping
and FFT, where more accurate results are obtained, which could be used to update
www.ebook3000.com

131
Algorithm 4.2 Improved Receiver for LACO-OFDM.
Input: Received signals, yn; Constellation set, S;
Output: Detected symbols, ˆX(l)
ACO,k;
1: ˜y(1)
n
= yn;
2: for l = 1 : L −1 do
3:
˜Y (l)
ACO,k = FFT

˜y(l)
n

;
4:
ˆX(l)
ACO,k = arg min
X∈S |X −2 ˜Y (l)
ACO,k|;
5:
ˆy(l)
n =
N/2l−1−1

k=0
ˆX(l)
ACO,k exp
j 2π
N n · 2l−1k

;
6:
˜y(l+1)
n
= ˜y(l)
n −ˆy(l)
n ;
7: end for
8: ¯y(L)
n
= ˜y(L)
n
;
9: for i = 1 : Niter do
10:
for l = L : −1 : 1 do
11:
Calculate ¯y(l)
n,c according to Eqs. (4.83)–(4.84);
12:
¯Y (l)
ACO,k,c = FFT

¯y(l)
n,c

;
13:
ˆX(l)
ACO,k = arg min
X∈S |X −2 ¯Y (l)
ACO,k,c|;
14:
ˆy(l)
n =
N/2l−1−1

k=0
ˆX(l)
ACO,k exp
j 2π
N n · 2l−1k

;
15:
¯y(l′)
n
= yn −
m̸=l′ ˆy(m)
n
, l′ ̸= l;
16:
end for
17: end for
18: return ˆX(l)
ACO,k;
the signals ˆy(l)
n
and back substitute to (4.85) to update the signals in other layers.
Therefore, the receiver operates in an iterative way. In each iteration, the signals in
each layer are sequentially detected, and the reconstructed time-domain signals are
used to update the signals in other layers. The pseudocode of the proposed receiver
is summarized in Algorithm 4.2, where Niter denotes the number of iterations.
4.4
Optical OFDM under lighting constraints
In indoor VLC systems, communication and illumination should be maintained si-
multaneously, where the light may be dimmed to satisfy diﬀerent illumination and
power requirements [34].
Furthermore, dimming technology is energy eﬃcient.
However, the dimming operation could interfere with the communication function
of VLC systems since it alters the received optical power and SNR. Conventional

132
optical OFDM schemes concentrate mainly on data transmission and could not sup-
port various dimming levels eﬃciently. For IEEE 802.15.7 Standard, single carrier
pulsed modulations such as on-oﬀkeying (OOK), pulse-position modulation (PPM)
and color shift keying (CSK) are utilized, whilst dimming control is usually realized
by combining the existing modulation schemes with PAM or pulse width modulation
(PWM) [34].
The inherent nonlinearity of LEDs is a challenge for OFDM implementation since
OFDM has high PAPR. The input of LED has a minimum threshold value that can
generate current, which is referred to as turn-on voltage (TOV). When the input volt-
age is above the TOV, the voltage–current and current–power characteristics are non-
linear. Several algorithms have been proposed to mitigate the eﬀect of LED nonlin-
earity, where the transfer characteristic of LED is regarded as quasi-linear in a limited
range after predistortion. That is, if vmin and vmax are the minimum and maximum
allowed signals according to the voltage levels permitted by LED, the transfer char-
acteristic of LED between [vmin, vmax] is assumed to be linear. Speciﬁcally, the
relationship between the emitted optical power and the input voltage is given by
Popt(t) =
⎧
⎪
⎨
⎪
⎩
0,
v(t) < vmin,
η (v(t) −vmin) ,
vmin ≤v(t) ≤vmax,
η (vmax −vmin) ,
v(t) > vmax,
(4.86)
where η and v(t) denote the voltage-power transfer coeﬃcient and instantaneous
input voltage, respectively.
Since the illumination level is proportional to the average optical power, dimming
control can be achieved by adjusting the average optical power of LEDs. Thus, the
dimming level d is deﬁned as
d = E (Popt(t)) / (η (vmax −vmin)) ,
(4.87)
which falls in the interval [0, 1]. When the required dimming level is adjusted, the
received optical power and eﬀective SNR are changed, which will vary the achievable
data rate for a given BER requirement. Therefore, any modulation scheme should
support high data rate under diﬀerent dimming targets.
The basic idea of dimming control for DCO-OFDM is to adjust the DC bias to
fulﬁll diﬀerent illumination requirements. Since the time-domain OFDM signals
follow Gaussian distribution with zero mean, they are symmetrically distributed on
both sides of the DC bias, and the average optical power is in proportion to the DC
bias. If the DC bias is not in the middle of the linear range, the signals on one side
will suﬀer from severer clipping. In order to maintain acceptable clipping distortion,
the actual dynamic range of the signals is smaller than the linear range of the LEDs.
For example, when the DC bias is set to BDC, the actual dynamic range would be
[max (vmin, 2BDC −vmax) , min (vmax, 2BDC −vmin)]. The transmitted signals
should be scaled to satisfy this dynamic range and they would become very small
when high or low illumination is required, which degrades the performance signiﬁ-
cantly. Therefore, several optical OFDM schemes have been proposed under lighting
www.ebook3000.com

133
constraints, which aim to fully exploit the dynamic range of LEDs and provide stable
data transmission under diﬀerent illumination requirements.
4.4.1
Pulse width modulation
The PWM signal is periodic, whose pulse width can be adjusted to change the average
optical power. Denoting the period of the PWM signal as TPWM, and the pulse width
TW, the PWM signal pPWM (t) in one period is given by
pPWM (t) =

1,
0 ≤t ≤TW,
0,
TW < t ≤TPWM.
(4.88)
The average optical power of pPWM (t) is equal to TW/TPWM, which can be adjusted
from 0 to 1 by changing the pulse width TW. In Fig. 4.19, three PWM signals are
depicted for diﬀerent dimming levels d = 20%, d = 50%, and d = 80%, where
the signal rate fPWM = 1/TPWM is 1 MHz.
In order to adjust the average optical power of the OFDM signal, a PWM signal
can be superimposed, and the transmitted signal is the product of the DMT and PWM
waveforms, i.e.,
xPWM-DMT (t) = xOFDM (t) · pPWM (t) ,
(4.89)
where xOFDM (t) denotes the time-domain optical OFDM signal, which can be mod-
ulated by any optical OFDM schemes, such as DCO-OFDM, ACO-OFDM, and so
on. This combination was referred to as PWM-DMT modulation in [35]. The ra-
tio of the OFDM time-domain signal duration over the PWM period is deﬁned as
R = TOFDM/TPWM, which should not be smaller than 1. If R < 1 and TW <
TPWM −TOFDM for a certain dimming requirement, pPWM (t) can be zero within an
entire OFDM signal duration, which will cause information loss and inter-carrier
interference [35]. Therefore, the PWM signal rate should be at least twice the band-
width of OFDM signals, which is diﬃcult to be implemented. Moreover, the PWM
signal would spread the bandwidth of the combined signals, leading to ineﬃcient
current-to-light conversion eﬃciency.
PWM-DMT is an eﬃcient means for dimming control since the optical power of
the transmitted signal is adjusted proportionally to the pulse width. After direct de-
tection and synchronization, the amplitude of received signal is the product of dim-
ming level and original OFDM signals. The dimming level can be regarded as part
of the channel state information and can be handled by equalization. Therefore, the
demodulation of PWM-DMT is exactly the same as conventional optical OFDM.
Since PWM-DMT requires a very high-frequency PWM signal compared with the
OFDM signal, which is infeasible for high-data-rate implementation, variable optical
OFDM (VO-OFDM) was proposed in [36]. In VO-OFDM, the OFDM signals are
only modulated onto the PWM signals during the on-state, which requires a relatively
low-frequency PWM signal. The waveform of VO-OFDM is shown in Fig. 4.20,
where the OFDM is transmitted only when the PWM signal is on.

134
0
0.5
1
1.5
2
2.5
3
3.5
4
0
0.2
0.4
0.6
0.8
1
Time (μs)
Amplitude
(a) d = 20%
0
0.5
1
1.5
2
2.5
3
3.5
4
0
0.2
0.4
0.6
0.8
1
Time (μs)
Amplitude
(b) d = 50%
0
0.5
1
1.5
2
2.5
3
3.5
4
0
0.2
0.4
0.6
0.8
1
Time (μs)
Amplitude
(c) d = 80%
Figure 4.19 PWM signal with diﬀerent pulse widths for dimming control.
www.ebook3000.com

135
0
0.5
1
1.5
2
2.5
3
3.5
4
0
0.2
0.4
0.6
0.8
1
Time (μs)
Amplitude
Figure 4.20 Variable optical OFDM for visible light communications with dimming control.
The VO-OFDM signal is not a simple multiplication of OFDM and PWM signals
since there should be zero-padding in OFDM during the oﬀ-state of PWM. In this
way, the period of a PWM signal can be much larger than the OFDM signal duration,
which is easier for implementation. However, the period of a PWM signal cannot
be too large since it can induce light ﬂicker, which may cause noticeable, negative
physiological changes in the human eye. To avoid ﬂicker, the period of PWM signal
in VO-OFDM should be smaller than the maximum ﬂickering time period (MFTP).
The MFTP is deﬁned as the maximum time period over which the light intensity can
change without the human eye perceiving it, which should be less than 5 ms.
For both PWM-DMT and VO-OFDM, the resultant dimming level can be calcu-
lated by the product of the dimming levels of PWM and OFDM, which is given by
d = dOFDM · dPWM,
(4.90)
where dOFDM and dPWM denote the dimming levels of PWM and OFDM, respectively.
When the required dimming level is low, it can be adjusted by dPWM directly. For
example, if the DC bias is set to the middle of the linear range, i.e., (vmin + vmax) /2,
then dOFDM = 50%, and d can be adjusted continuously from 0 to 50%, where dPWM
is within the range [0, 100%]. However, the combination of PWM signal is only able
to reduce the optical power since part of the signal is set to zero during the PWM
signal duration. When the required dimming level is higher than 50%, the dimming
level of OFDM needs to be adjusted as the conventional optical OFDM by increasing
the DC bias, and dPWM should be set to 100%. Therefore, these PWM-based schemes
are more suitable for low illumination requirements.

136
4.4.2
Reverse polarity optical OFDM
Reverse polarity optical OFDM (RPO-OFDM) also uses a low-frequency PWM sig-
nal for dimming control, but it utilizes the entire PWM signal duration for data trans-
mission instead of only the on-state duration [37]. The combined RPO-OFDM signal
is given by
xRPO(t) =

pPWM(t) −m · xOFDM(t),
0 ≤t ≤TM,
pPWM(t) + m · xOFDM(t),
TM < t ≤TPWM,
(4.91)
where m denotes the scaling factor of optical OFDM signal. When the PWM signal is
on, the polarity of optical OFDM signal is reversed for combination, while the optical
OFDM signal is directly transmitted when the PWM signal is oﬀ. In this way, the
combined signal can utilize the full linear range of LEDs for transmission, which can
increase the eﬀective electrical power at the receiver. In fact, if the DC component in
the PRO-OFDM signal is ignored, the power of received OFDM signal remains the
same when the PWM signal changes. Therefore, as long as the electronic power of
the OFDM signal remains unchanged, the same performance can be achieved when
the PWM signal changes. The dimming level of RPO-OFDM can be given by
d = dOFDM · (1 −dPWM) + (1 −dOFDM) · dPWM.
(4.92)
Hence, the supportable dimming range is between dOFDM and 1−dOFDM by changing
the pulse width of PWM. If a larger dimming range is required, the dimming level of
optical OFDM should be changed by scaling.
For conventional DCO-OFDM with the DC bias in the middle of the linear range,
dOFDM = 50% and the PWM signal cannot change the dimming level in RPO-
OFDM according to (4.92). However, ACO-OFDM and U-OFDM can be used in
RPO-OFDM to achieve a larger dimming range, since DC bias is not required in
these modulation schemes, and the dimming level is much lower. Figure 4.21 shows
the RPO-OFDM signal waveforms with dPWM = 20% and dPWM = 80%, respec-
tively, where ACO-OFDM is used as the optical OFDM scheme for modulation. The
dimming level for ACO-OFDM is set to 10%, and the actual dimming levels of RPO-
OFDM are 26% and 74%, respectively.
RPO-OFDM can support stable BER performance when the dimming level
changes within the range [dOFDM, 1 −dOFDM]. When the required dimming lev-
el is outside this range, the dimming level for conventional OFDM should be re-
duced, which will decrease the received electrical power and lower modulation order
should be used to maintain the BER performance. However, since ACO-OFDM or
U-OFDM is used in RPO-OFDM, the spectral eﬃciency is limited. Some spectrum-
eﬃcient optical OFDM schemes introduced in Section 4.3 may be preferred to
further improve its spectral eﬃciency.
www.ebook3000.com

137
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
0
0.2
0.4
0.6
0.8
1
Time (μs)
Amplitude
(a) dPWM = 20%
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
0
0.2
0.4
0.6
0.8
1
Time (μs)
Amplitude
(b) dPWM = 80%
Figure 4.21 RPO-OFDM signal waveform with diﬀerent PWM signals.
4.4.3
Asymmetrical hybrid optical OFDM
The aforementioned schemes all utilize PWM signal to adjust the average optical
power. In PWM-DMT, high-frequency PWM signal is required, which is not suitable

138
for high-speed transmission. VO-OFDM and RPO-OFDM both use a much lower-
frequency PWM signal for dimming control. In VO-OFDM, the oﬀ-state of PWM
is empty, leading to the reduction of data rate. In RPO-OFDM, unipolar optical
OFDM schemes are used, which is not spectrum-eﬃcient. Asymmetrical hybrid
optical OFDM (AHO-OFDM) was proposed in [38], which does not require extra
PWM signal for dimming control.
In AHO-OFDM, ACO-OFDM and PAM-DMT signals are combined to transmit
simultaneously. In PAM-DMT, only the imaginary part of even subcarriers is modu-
lated to make sure that the ACO-OFDM symbols are not interfered. Unlike HACO-
OFDM where ACO-OFDM and PAM-DMT signals are directly added, either ACO-
OFDM or PAM-DMT signal is inverted in AHO-OFDM so that the combined signals
are bipolar. Dimming control is achieved by directly adjusting the amplitude of the
combined signals so that PWM signal is not required. Given diﬀerent powers of
ACO-OFDM and PAM-DMT signals corresponding to the positive and negative val-
ues, the combined AHO-OFDM signal is asymmetrical and therefore the dynamic
range of LEDs could be fully utilized. The combined signals are biased by BDC and
the transmitted AHO-OFDM signals generated by ACO-OFDM and inverse PAM-
DMT are given by
xAHO,n = xACO,n −xPAM,n + BDC, n = 0, 1, ..., N −1,
(4.93)
where xACO,n and xPAM,n denote the time-domain signals of ACO-OFDM and PAM-
DMT, respectively.
According to Section 4.1.2, the average amplitude of the combined AHO-OFDM
signal can be calculated as
EAHO = E (xAHO,n) = σACO
√
2π −σPAM
√
2π + BDC,
(4.94)
which is proportional to the average optical power of LEDs since the amplitude of
AHO-OFDM signal is used to modulate the instantaneous power of the optical emit-
ter.
The dimming level for AHO-OFDM can be deﬁned as
d = (EAHO −vmin) / (vmax −vmin)
(4.95)
according to (4.87). For a given dimming level d, the average amplitude EAHO can be
obtained according to (4.95). It is seen from (4.94) that the average amplitude EAHO
is determined by the DC bias BDC as well as σACO and σPAM. Since the amplitude
of combined AHO-OFDM signal is constrained by the dynamic range of LEDs, it
has to be clipped when it is beyond the dynamic range of LEDs, which results in
undesirable clipping distortion. To estimate the clipping distortion of the proposed
scheme, the scaling factors of ACO-OFDM and PAM-DMT as βACO and βPAM are
deﬁned, where βACO = (vmax −BDC) /σACO and βPAM = (BDC −vmin) /σPAM.
www.ebook3000.com

139
The probability of the clipped signal is then given by
P (xAHO,n > vmax) = P (xACO,n −xPAM,n > vmax −BDC)
=
 ∞
0
pPAM (y)
 ∞
βACOσACO+y
pACO (x) dxdy,
(4.96)
and
P (xAHO,n < vmin) = P (xPAM,n −xACO,n > BDC −vmin)
=
 ∞
0
pACO (x)
 ∞
βPAMσPAM+x
pPAM (y) dydx.
(4.97)
When the scaling factors βACO and βPAM are large enough, the probability of
clipped signal would be very small and clipping distortion can be suppressed. For
example, in the case of βACO = βPAM = 3, the probability of the clipped signal
would be less than 1%. However, a large scaling factor will result in low eﬀective
power at the receiver, which degrades the system performance. Therefore, a tradeoﬀ
has to be made between the eﬀective power and the clipping distortion for a required
BER performance. When the scaling factors are chosen, the required DC bias for
the desired dimming level d can be derived as
BDC = βACOβPAM
√
2π ((vmax −vmin) d + vmin) −βACOvmin −βPAMvmax
βACOβPAM
√
2π −βACO −βPAM
(4.98)
according to the deﬁnition of scaling factors and (4.94)–(4.95).
Figure 4.22 illustrates an example of AHO-OFDM signal generated by ACO-
OFDM and inverse PAM-DMT, where the required dimming level is 70% and the
number of subcarriers is set to 128. 16QAM and 16PAM are employed in ACO-
OFDM and PAM-DMT, respectively. The scaling factors of both ACO-OFDM and
PAM-DMT are set to three. In Fig. 4.22(a), the ACO-OFDM and inverse PAM-DMT
signals are depicted separately, where the former is above the DC bias BDC and the
latter is below it. Figure 4.22(b) shows the combined AHO-OFDM signals, which
are asymmetrical to the DC bias BDC. One can see that BDC is unequal to the desired
average amplitude EAHO and the dynamic range of LEDs could be fully utilized.
Simulations are conducted to evaluate the performance of the AHO-OFDM
scheme. The maximum and minimum allowed signals of LEDs are vmax = 1
and vmin = 0, respectively. Figure 4.23 shows the obtained dimming level d as a
function of βACO, βPAM, and BDC according to (4.98). It can be seen that a wide dim-
ming range is achieved. For example, when the scaling factors βACO = βPAM = 4,
the achieved dimming range is from 10% to 90%. Larger scaling factors can be used
to support a wider dimming range. Therefore, the AHO-OFDM scheme can achieve
arbitrary dimming range in theory.
The performance of AHO-OFDM is compared with DCO-OFDM and HACO-
OFDM. In DCO-OFDM, dimming control is achieved by simply adjusting the DC

140
0
0.2
0.4
0.6
0.8
1
1.2
Amplitude
vmin
EAHO
BDC
vmax
Time (μs)
ACO−OFDM in AHO−OFDM
PAM−DMT in AHO−OFDM
(a) ACO-OFDM and PAM-DMT signals in AHO-OFDM
0
0.2
0.4
0.6
0.8
1
1.2
Amplitude
vmin
EAHO
BDC
vmax
Time (μs)
(b) The combined AHO-OFDM signal
Figure 4.22 An example of AHO-OFDM signal with dimming level d = 70%.
www.ebook3000.com

141
0
0.2
0.4
0.6
0.8
1
0
10
20
30
40
50
60
70
80
90
100
BDC
 d (%)
βACO=βPAM=2
βACO=βPAM=3
βACO=βPAM=4
Figure 4.23 Optical dimming level d as a function of βACO, βPAM, and BDC.
bias, which does not require PWM signals. Adaptive scaling factors can be used to
realize diﬀerent dimming levels in DCO-OFDM to mitigate clipping distortion. In
the HACO-OFDM scheme, the optical power is equally distributed to ACO-OFDM
and PAM-DMT, and a DC bias still has to be added when the required dimming level
is high. The achievable spectral eﬃciency comparisons of HACO-OFDM, DCO-
OFDM, and AHO-OFDM with diﬀerent dimming levels are shown in Fig. 4.24 for a
target BER of 2 × 10−3 with the noise power of -10 dBm. It can be seen that AHO-
OFDM can support a much wider dimming range compared with its two counter-
parts, and its achievable spectral eﬃciency is relatively stable when the dimming level
varies since its asymmetry could fully utilize the dynamic range of LEDs. For exam-
ple, it can support a wide dimming range from 5% to 95% with the spectral eﬃciency
of at least 1.5 bit/s/Hz. For an extremely small dimming level where DCO-OFDM
and HACO-OFDM could not work, i.e., 2%, the achievable spectral eﬃciency is still
0.75 bit/s/Hz for AHO-OFDM.

142
0
20
40
60
80
100
0
0.5
1
1.5
2
2.5
3
3.5
4
 d (%)
Spectral Efficiency (bit/s/Hz)
DCO−OFDM
HACO−OFDM
AHO−OFDM
Figure 4.24 Performance comparison of AHO-OFDM, DCO-OFDM, and HACO-OFDM for
a target BER of 2 × 10−3 under diﬀerent dimming levels.
4.5
Conclusion
This chapter has reviewed the optical OFDM techniques for broadband and high-
data-rate VLC systems. Since IM/DD scheme is used in VLC, the amplitude of the
optical OFDM signals is constrained to be real-valued and non-negative. In this chap-
ter, the comparisons of mainstream optical OFDM schemes, such as DCO-OFDM,
ACO-OFDM, PAM-DMT, and U-OFDM, are provided. Optical OFDM suﬀers from
high PAPR as in RF, which is prone to induce severe nonlinear distortion and im-
pair the transmission performance of VLC systems. Therefore, several techniques
have been introduced to enhance the performance of optical OFDM by optimization
of DC bias and scaling factor, mitigating the nonlinear eﬀect of LED, and PAPR
reduction. Besides, recently proposed power- and spectral-eﬃcient optical OFDM
schemes, such as hybrid optical OFDM, eU-OFDM, and LACO-OFDM are also dis-
cussed. At last, the integration of OFDM and dimming control is discussed for VLC
system, which has shown that dimmable OFDM can support a wide dimming range
with a small throughput ﬂuctuation.
www.ebook3000.com

143
References
1 R. W. Chang, Orthogonal Frequency
Multiplex Data Transmission System. U.S.
Patent 3,488,445, 1966.
2 J. Armstrong, “OFDM: From copper and
wireless to optical,” in Proc. Optical Fiber
Communication Conference and Exposition
and the National Fiber Optic Engineers
Conference (OFC/NFOEC) 2008 (San
Diego, CA), Feb. 24–28, 2008, Tutorial,
OMM1.
3 3GPP TS 36.211, Evolved Universal
Terrestrial Radio Access (E-UTRA):
Physical Channels and Modulation. v.8.9.0,
Dec. 2009.
4 J. Armstrong, “OFDM for optical
communications,” J. Lightw. Technol.,
vol. 27, no. 3, pp. 189–204, Feb. 2009.
5 R. Gitlin and E. Ho, “The performance of
staggered quadrature amplitude modulation
in the presence of phase jitter,” IEEE Trans.
Commun., vol. 23, no. 3, pp. 348–352, Mar.
1975.
6 J. M. Kahn and J. R. Barry, “Wireless
infrared communications,” Proc. IEEE,
vol. 85, no. 2, pp. 265–298, Feb. 1997.
7 J. Armstrong, and A. J. Lowery, “Power
eﬃcient optical OFDM,” Electron. Lett.,
vol. 42, no. 6, pp. 370–372, Mar. 2006.
8 S. C. J. Lee, S. Randel, F. Breyer, and
A. M. J. Koonen, “PAM-DMT for
intensity-modulated and direct-detection
optical communication systems,” IEEE
Photon. Technol. Lett., vol. 21, no. 23,
pp. 1749–1751, Dec. 2009.
9 S. D. Dissanayake and J. Armstrong,
“Comparison of ACO-OFDM, DCO-OFDM
and ADO-OFDM in IM/DD systems,” J.
Lightw. Technol., vol. 31, no. 7,
pp. 1063–1072, Apr. 2013.
10 K. Asadzadeh, A. Dabbo, and
S. Hranilovic, “Receiver design for
asymmetrically clipped optical OFDM,” in
Proc. IEEE Global Communications
Conference (GLOBECOM) Workshops 2011
(Houston, TX), Dec. 5–9, 2011,
pp. 777–781.
11 D. Tsonev, S. Sinanovic, and H. Haas,
“Novel unipolar orthogonal frequency
division multiplexing (U-OFDM) for optical
wireless,” in Proc. IEEE Vehicular
Technology Conference (VTC Spring) 2012
(Yokohama, Japan), May 6–9, 2012, pp. 1–5.
12 N. Fernando, Y. Hong, and E. Viterbo,
“Flip-OFDM for optical wireless
communications,” in Proc. IEEE
Information Theory Workshop (ITW) 2011
(Paraty, Brazil), Oct. 16–20, 2011, pp. 5–9.
13 N. Fernando, Y. Hong, and E. Viterbo,
“Flip-OFDM for unipolar communication
systems,” IEEE Trans. Commun., vol. 60,
no. 12, pp. 3726–3733, Dec. 2012.
14 S. Dimitrov and H. Haas, “Information rate
of OFDM-based optical wireless
communication systems with nonlinear
distortion,” J. Lightw. Technol., vol. 31,
no. 6, pp. 918–929, Mar. 2013.
15 J. Bussgang, “Cross correlation function of
amplitude-distorted Gaussian signals,”
Mass. Inst. Technol., Cambridge, MA, USA,
Tech. Rep. 216, Mar. 1952.
16 Z. Wang, Q. Wang, S. Chen, and L. Hanzo,
“An adaptive scaling and biasing scheme for
OFDM-based visible light communication
systems,” Opt. Exp., vol. 22, no. 10,
pp. 12707–12715, May 2014.
17 M. Zhang and Z. Zhang, “An optimum
DC-biasing for DCO-OFDM system,” IEEE
Commun. Lett., vol. 18, no. 8,

144
pp. 1351–1354, Jun. 2014.
18 P. Zillmann and G. R. Fettweis, “On the
capacity of multicarrier transmission over
nonlinear channels,” in Proc. IEEE
Vehicular Technology Conference (VTC
Spring) 2005 (Stockholm, Sweden), May
30–Jun. 1, 2005, pp. 1148–1152.
19 J. Tan, Z. Wang, Q. Wang, and L. Dai,
“Near-optimal low-complexity sequence
detection for clipped DCO-OFDM,” IEEE
Photon. Technol. Lett, vol. 28, no. 3,
pp. 233–236, Feb. 2016.
20 J. Tan, Z. Wang, Q. Wang, and L. Dai,
“BICM-ID scheme for clipped DCO-OFDM
in visible light communications,” Opt. Exp.,
vol. 24, no. 5, pp. 4573–4581, 2016.
21 S. H. Han and J H .Lee, “An overview of
peak-to-average power ratio reduction
techniques for multicarrier transmission,”
IEEE Wirel. Commun., vol. 12, no. 2,
pp. 56–65, Apr. 2012.
22 B. Ranjha and M. Kavehrad, “Precoding
techniques for PAPR reduction in
asymmetrically clipped OFDM based optical
wireless system,” in Proc. SPIE, vol. 8165,
Jan. 2013.
23 W. O. Popoola, Z. Ghassemlooy, and
B. G. Stewart, “Pilot-assisted PAPR
reduction technique for optical OFDM
communication systems, ”
J. Lightw. Technol., vol. 32, no. 7,
pp. 1374–1382, Apr. 2014.
24 J. Tan, Q. Wang, and Z. Wang, “Modiﬁed
PTS-based PAPR reduction for ACO-OFDM
in visible light communications,” Sci. China
Inf. Sci., vol.58, no.12, Oct. 2015.
25 W. Xu, M. Wu, H. Zhang, X. You, and
C. Zhao, “ACO-OFDM-speciﬁed
recoverable upper clipping with eﬃcient
detection for optical wireless
communications,” IEEE Photon. J., vol. 6,
no. 5, p. 7902617, Oct. 2014.
26 S. D. Dissanayake, K. Panta, and
J. Armstrong, “A novel technique to
simultaneously transmit ACO-OFDM and
DCO-OFDM in IM/DD systems,” in Proc.
IEEE Global Communications Conference
(GLOBECOM) Workshops 2011 (Houston,
TX), Dec. 5–9, 2011, pp. 782–786.
27 B. Ranjha and M. Kavehrad, “Hybrid
asymmetrically clipped OFDM-based
IM/DD optical wireless system,” J. Opt.
Commun. Netw, vol. 6, no. 4, pp. 387–396,
Apr. 2014.
28 Q. Wang, Z. Wang, and L. Dai, “Iterative
receiver for hybrid asymmetrically clipped
optical OFDM,” J. Lightw. Technol., vol. 32,
no. 22, pp. 4471–4477, Nov. 2014.
29 J. Li, X. Zhang, Q. Gao, Y. Luo, and D. Gu,
“Exact BEP analysis for coherent M-ary
PAM and QAM over AWGN and Rayleigh
fading channels,” in Proc. IEEE Vehicular
Technology Conference (VTC Spring) 2008
(Singapore), May 11–14, 2008, pp. 390–394.
30 D. Tsonev and H. Haas, “Avoiding spectral
eﬃciency loss in unipolar OFDM for optical
wireless communication,” in Proc. IEEE
International Conference on
Communications (ICC) 2014 (Sydney,
Australia), Jun. 10–14, 2014, pp. 3336–3341.
31 D. Tsonev, S. Videv, and H. Haas,
“Unlocking spectral eﬃciency in intensity
modulation and direct detection systems,”
IEEE J. Sel. Areas Commun., vol. 33, no. 9,
pp. 1758–1770, Sep. 2015.
32 Q. Wang, C. Qian, X. Guo, Z. Wang,
D. G. Cunningham, and I. H. White,
“Layered ACO-OFDM for
intensity-modulated direct-detection optical
wireless transmission,” Opt. Exp., vol. 23,
no. 9, pp. 12382–12393, May 2015.
33 Q. Wang, Z. Wang, X. Guo, and L. Dai,
“Improved receiver design for layered
ACO-OFDM in optical wireless
communications,” IEEE Photon. Technol.
Lett., vol. 28, no. 3, pp. 319–322, Feb. 2016.
34 IEEE 802.15.7, Part 15.7: Short-Range
Wireless Optical Communication Using
Visible Light, IEEE Std. 802.15.7-2011, Sep.
2011.
35 G. Ntogari, T. Kamalakis, J. Walewski, and
T. Sphicopoulos, “Combining illumination
dimming based on pulsewidth modulation
with visible-light communications based on
discrete multitone,” J. Opt. Commun. Netw.,
vol. 3, no. 1, pp. 56–65, Jan. 2011.
36 Z. Wang, W. D. Zhong, C. Yu, J. Chen,
C. P. S. Francois, and W. Chen,
“Performance of dimming control scheme in
visible light communication system,” Opt.
Exp., vol. 20, no. 17, pp. 18861–18868, Aug.
2012.
37 H. Elgala and T. D. C. Little, “Reverse
polarity optical-OFDM (RPO-OFDM):
Dimming compatible OFDM for gigabit
VLC links,” Opt. Exp., vol. 21, no. 20,
www.ebook3000.com

145
pp. 24288–24299, Oct. 2013.
38 Q. Wang, Z. Wang, and L. Dai,
“Asymmetrical hybrid optical OFDM for
visible light communications with dimming
control,” IEEE Photon. Technol. Lett.,
vol. 27, no. 9, pp. 974–977, May 2015.

147
5
Multicolor Modulation
Generally, white light emitting diodes (LEDs) are classiﬁed into two types, which
are single-chip LEDs and RGB-type LEDs. The single-chip LED uses a single blue
LED that excites a yellow phosphor to create an overall white emission. However,
the slow response of yellow phosphor limits the transmission bandwidth in visible
light communications (VLCs). The RGB-type LEDs combine light from LEDs of
the three primary colors, which are red, green, and blue, and three LEDs emit their
corresponding colors simultaneously. They are preferable to single-chip LEDs to
improve the transmission rate due to their faster response time. Moreover, these three
wavelengths can be used to carry multiple data streams independently and thus oﬀer
the possibility of the wavelength division multiplexing (WDM).
This chapter discusses multicolor modulation schemes to satisfy both communi-
cation and illumination requirements. In Section 5.1, we introduce color shift keying
(CSK), which has been adopted in the IEEE 802.15.7 standard. Besides the CSK con-
stellation in the standard, the optimal design rules of CSK constellation as well as
Quad-LED CSK are provided. In practical communications, channel coding is wide-
ly used before modulation to achieve better performance. In Section 5.2, CSK with
coded modulation is discussed with both hard and soft detections. In Section 5.3,
WDM is introduced, which modulates signals on diﬀerent optical sources for both
communication and illumination requirements. Particularly, a receiver-side predis-
tortion is used before channel decoding to improve the performance of WDM sys-
tems.
5.1
Color shift keying
Figure 5.1 illustrates the diagram of CSK transmitter with three light sources of bands
i, j, and k. A scrambler is utilized before channel coding in order to ensure pseudo-
random data and ﬂicker-free illumination, whose polynomial generator is given by
g (D) = 1 + D14 + D15,
(5.1)
where D is a single bit delay element [1]. After scrambling and channel coding, the
coded bits are mapped into the color coordinates (x, y) by the color coding block.
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.
www.ebook3000.com

148
Figure 5.1 Diagram of CSK transmitter.
The color coordinates are then transformed to a three-dimensional intensity vector
[Pi Pj Pk]T to modulate the three light sources of bands i, j, and k. We denote the
color coordinates of the three light sources as (xi, yi), (xj, yj), (xk, yk), respective-
ly. For a given color coordinate (xp, yp), the intensities for the three light sources
can be calculated by
xp = Pixi + Pjxj + Pkxk,
(5.2)
yp = Piyi + Pjyj + Pkyk,
(5.3)
Pi + Pj + Pk = 1.
(5.4)
At the receiver, the color coordinates are reconstructed by the received optical powers
of the three colors, which are then used for decoding.
5.1.1
Constellation
The visible light spectrum is deﬁned from 380 nm to 780 nm in wavelength, which
is divided into seven frequency bands in the IEEE 802.15.7 standard [1]. In CSK,
three color light sources are used to generate the transmitted signal, where the three
verticesoftheCSKconstellationtrianglearedeterminedby the center wavelengtho of
the corresponding color bands on (x, y) color coordinates. Table 5.1 gives the color
coordinate values for the seven color bands whose spectral peaks are at the center of
each color band, and Fig. 5.2 illustrates the centers of the seven color bands on color
coordinates.

149
Table 5.1 Color coordinates for the seven color bands [1].
Band (nm)
Code
Center (nm)
(x, y)
380-478
000
429
(0.169, 0.007)
478-540
001
509
(0.011, 0.733)
540-588
010
564
(0.402, 0.597)
588-633
011
611
(0.669, 0.331)
633-679
100
656
(0.729, 0.271)
679-726
101
703
(0.734, 0.265)
726-780
110
753
(0.734, 0.265)
Figure 5.2 Centers of the seven color bands on x-y color coordinates.
The constellations of 4-CSK, 8-CSK, and 16-CSK recommended by the IEEE
802.15.7 standard are shown in Fig. 5.3, where the points I, J, and K denote the
center of the three color bands on the color coordinates deﬁned in Table 5.1. In
order to make sure the triangle is large enough to maximize the distances between
the adjacent symbols, nine valid combinations of the color bands are provided in
Table 5.2 [2]. In this way, the output color for illumination can be guaranteed [3].
In 4-CSK, the symbols are denoted as S0 to S3, where S1, S2, and S3 are the
vertices of the triangle △IJK and S0 is the centroid of the triangle △IJK.
In 8-CSK, the symbols are denoted as S0 to S7, where S0, S4, and S7 are the
vertices of the triangle △IJK. S1 and S2 are the trisection points of the lines JK
www.ebook3000.com

150
(a) 4-CSK
(b) 8-CSK
(c) 16-CSK
Figure 5.3 Constellations of 4-CSK, 8-CSK, and 16-CSK provided by IEEE 802.15.7
standard.
Table 5.2 Valid color band combinations for CSK [2].
Combination
Band i
Band j
Band k
1
110
010
000
2
110
001
000
3
101
010
000
4
101
001
000
5
100
010
000
6
100
001
000
7
011
010
000
8
011
001
000
9
010
001
000
and JI, where we have JS1 = 1/3JK and JS2 = 1/3JI. The midpoints of
the lines JI, JK, and KI are denoted as B, C, and S6, respectively. Point A is the
centroid of the triangle △BS6I, while D is the centroid of the triangle △CKS6. S3
and S5 are the trisection points of the lines AB and CD that satisfy AS3 = 1/3AB
and DS5 = 1/3CD.
In 16-CSK, the symbols are denoted as S0 to S15, where S5, S10, and S15 are
the vertices of the triangle △IJK. The symbols S2, S8, S3, S12, S11, and S14
divide the sides JK, JI, and KI into three parts, respectively. S0 is the centroid
of the triangle △IJK, while S1, S4, S6, S7, S9, and S13 are the centroids of the
smaller triangles △JS2S3, △S2S8S0, △S3S0S12, △S8KS11, △S0S11S14, and
△S14S12I, respectively.
Although the intensities of the light sources are diﬀerent in diﬀerent symbols, the
total power of each symbol remains constant. Therefore, ﬂicker is avoided com-
pletely. The dimming control of CSK can be implemented by adjusting the current
drivers of each light sources isometrically, which maintains the constellation since
the proportions of the three colors remain unchanged.

151
c
c
c
ª
º
«
»
«
»
«
»
¬
¼

c
ª
º
ª
º
ª
º
«
»
«
»
«
»c
 «
»
«
»
«
»
«
»
c
«
»
«
»
¬
¼
¬
¼
¬
¼
Figure 5.4 Diagram of CSK receiver with color calibration.
5.1.2
Color calibration
It should be noted that, the optical source may have a diﬀerent spectral peak or even
multiple spectral peaks in practice. Therefore, the implementation of CSK can use
the color band based on the center wavelength of the actual optical source. At the
receiver, color calibration should be conducted to compensate the color coordinate
errors and cancel the interference among diﬀerent colors. Besides, other light devices
and ambient light may cause multicolor imbalance and multicolor interference as
well, which can be compensated by a color calibration at the same time. The diagram
of CSK receiver with color calibration is shown in Fig. 5.4.
Before data transmission, Walsh codes modulated by OOK are used to estimate
the channel propagation matrix. Three Walsh code sequences with length-4 are used
for the three color bands i, j, and k, namely, W(1, 4) = 1, −1, 1, −1, W(2, 4) =
1, 1, −1, −1, and W(3, 4) = 1, −1, −1, 1. In order to maintain the accuracy of the
estimation, each bit of the Walsh code is transmitted twice by repetition coding. The
estimated channel propagation matrix is a 3 × 3 square matrix deﬁned as
H =
⎡
⎣
hii
hij
hik
hji
hjj
hjk
hki
hkj
hkk
⎤
⎦.
(5.5)
At the receiver, the received signals can be compensated by the color calibration
module, which multiplies the signal vector with inverted estimated channel matrix
www.ebook3000.com

152
as
⎡
⎣
Pi
Pj
Pk
⎤
⎦=
⎡
⎣
hii
hij
hik
hji
hjj
hjk
hki
hkj
hkk
⎤
⎦
−1 ⎡
⎣
P ′
i
P ′
j
P ′
k
⎤
⎦.
(5.6)
5.1.3
Constellation optimization
The IEEE 802.15.7 standard provides a simple design rule for CSK constellation.
However, the constellation is not optimized for the best performance. Several meth-
ods have been proposed to redesign the CSK constellation [4–7].
Assuming that the shaping pulse is rectangular and additive white Gaussian noise
(AWGN) is induced at the receiver, the equivalent discrete-time channel model can
be written as [7]
r = Hpm + n,
(5.7)
where pm = [Pi,m Pj,m Pk,m]T denotes the mth symbol in the M-CSK constel-
lation, r, H, and n are the received symbol, the channel response, and the AWGN
noise vector, respectively.
In the IEEE 802.15.7 standard, the optical power of each symbol is constant to
minimize light intensity ﬂuctuations since the ﬂuctuations may do harm to human
health [1]. Denoting the optical gain of each optical source as ηi , ηj , and ηk in units
of lumens per ampere (lm/A), the optical gain vector is given by η = [ηi ηj ηk]T.
The optical gains ηi , ηj , and ηk may change with temperature and usage time, and
this can be reﬂected by variation in H. The instantaneous optical power of the mth
symbol is deﬁned as
L (pm) = ⟨η, pm⟩,
(5.8)
where ⟨·, ·⟩denotes the inner product operator. The IEEE 802.15.7 standard states
that
L (pm) = L, m = 1, 2, . . . , M,
(5.9)
where L is the ﬁxed optical power.
In practical data transmission, the symbol rate is usually very high to support high
data rate. Therefore, the ﬂuctuations of light intensity ]na negligible for human eyes
and it is acceptable for small ﬂuctuations in the design of CSK constellation to pro-
vide larger degree of freedom [8]. The dynamic range of the instantaneous optical
power is given by
Lmin ≤L (pm) ≤Lmax,
(5.10)
where Lmin and Lmax are the minimum and maximum allowable total optical pow-
er, respectively. When Lmin = Lmax, the total optical power is constant for each

153
symbol as in the IEEE 802.15.7 standard. Moreover, since intensity modulation is
used and the optical sources have limited dynamic ranges, the symbols should also
satisfy the following constraint as
0 ⪯pm ⪯[Ii Ij Ik]T ,
(5.11)
where Ii, Ij , and Ik are the maximum allowable currents for the optical sources of
bands i, j, and k, respectively.
It is also possible to design the CSK constellation with constant current instead of
optical power, where we deﬁne the total current of symbol pm as
I (pm) = Pi,m + Pj,m + Pk,m.
(5.12)
If Imin and Imax are the minimum and maximum allowable total currents, then (5.10)
can be rewritten as
Imin ≤I (pm) ≤Imax,
(5.13)
which can be used to limit radio frequency (RF) radiation caused by high current
switching through stray inductance [7].
For a given color coordinate (xp, yp), denote the relative luminous ﬂux as p, then
⎡
⎢⎣
xi
yi
xj
yj
xk
yk
1
1
1
1−xi−yi
yi
1−xj−yj
yj
1−xk−yk
yk
⎤
⎥⎦p =
⎡
⎢⎣
xp
yp
1
1−xp−yp
yp
⎤
⎥⎦,
(5.14)
according to (5.2)–(5.4), and the sum of the elements of p is equal to one. If the
perceived chromaticity is required to be (xp, yp), the constellation should satisfy the
following constraint
1
M
M

m=1
L (pm) = L.
(5.15)
If Lmin < Lmax, the value of L should be speciﬁed in the constellation design.
Alternatively, it can be used as a design variable.
At high signal-to-noise ratios (SNRs), the symbol error rate (SER) of CSK is dom-
inated by the minimum pairwise Euclidean distance between all received symbols
when AWGN channel is assumed with uniform constellation. Therefore, the opti-
mization of the CSK constellation is achieved by maximizing the minimum pairwise
Euclidean distance for a given SNR, which is written as
A = arg max
{pm}
min
s̸=t |H (ps −pt)|2
subject to
Lmin ≤L (pm) ≤Lmax,
0 ⪯pm ⪯[Ii Ij Ik]T ,
1
M
M

m=1
L (pm) = L.
(5.16)
www.ebook3000.com

154
If the total current is constrained, the ﬁrst constraint in (5.16) should be replaced by
(5.13).
The objective in (5.16) is both nonconvex and non-diﬀerentiable, which cannot be
solved by conventional gradient-based numerical optimization tools. For noncon-
vex problems, the conventional optimization algorithms can only ﬁnd local minima,
which depends on the initial estimate of the constellation used to start the optimiza-
tion process. Therefore, the optimization problem can be solved multiple times with
random starting points, so that it is more likely to ﬁnd the global optimal solution. Be-
sides, the following approximation may be used to eliminate the non-diﬀerentiability
of (5.16) [6, 7]
min
m dm ≈−ln
 N

m=1
exp (−βdm)

/β,
(5.17)
where {dm} is the set of pairwise distances and β is a large positive number to main-
tain accuracy of the approximation. If one of the distance is very small compared to
the others, it is obvious that (5.17) is a good approximation. With this approximation,
the objective in (5.16) is rewritten as
arg max
{pm}
−ln
⎛
⎝
s̸=t
exp

−β|H (ps −pt)|2
⎞
⎠/β,
(5.18)
which can be readily solved by any optimization toolkit under the constraints given
in (5.16), and the smallest distances between all symbols approach the same value
when they are near a local optimum. However, for a given β, the approximation of
the minimum in (5.17) becomes less reliable near a local minimum. If β is set to a
ﬁxed large value, there will be large gradients, which may result in numeric instability
and convergence problems. Therefore, the value of β is increased progressively in
a series of sequential optimizations [7] to obtain a reliable approximation without
the convergence issue. In each iteration, the value of β is doubled until the mean
squared error between the constellations in the current and past iterations is less than
a speciﬁed threshold. According to [7], the optimized constellations have much larger
minimum pairwise Euclidean distance compared with the IEEE 802.15.7 standard,
which is summarized in Table 5.3.
Table 5.3 The minimum pairwise Euclidean distance of CSK constellation with diﬀerent
design rules.
Design Rule
4-CSK
8-CSK
16-CSK
IEEE 802.15.7 standard
0.4245
0.1758
0.1400
Optimization in [7]
0.5141
0.2725
0.1755

155
5.1.4
CSK with Quad-LED
In Quad-LED (QLED), four optical sources of bands i, j, k, and v are used for illumi-
nation, which provides better illumination performance. Furthermore, the additional
dimension also increases the degree of freedom in the constellation design, leading
to improved transmission performance. Similar to the conventional CSK, the design
of QLED CSK is based on the CIE 1931 color space. The four optical sources are in
the bands of blue, cyan, yellow, and red (BCYR), respectively. When QLED is used,
a quadrilateral instead of a triangular constellation can be obtained, which allows a
simple symbol mapping and constellation design as in squared QAM.
The relationship of the color coordinate and the intensities for the four light sources
can be written as
xp = Pixi + Pjxj + Pkxk + Plxv,
(5.19)
yp = Piyi + Pjyj + Pkyk + Pkyv,
(5.20)
Pi + Pj + Pk + Pv = 1,
(5.21)
which are extensions of (5.2)–(5.4). However, (5.19)–(5.21) are under-determined
since there are only three equations with four unknown variables, and do not have
a unique solution when the color coordinates are given. Therefore, only up to three
optical sources are used in each QLED CSK symbol, which can be solved similar
to the conventional CSK as in (5.2)–(5.4). The constellation of QLED CSK can be
regarded as a subset of four conventional CSK constellations with diﬀerent colors.
In order to generate any color within the quadrilateral bounded by the four bands, the
QLED system requires at least three LEDs to illuminate at speciﬁc intensities, two
LEDs for any color on the border lines and one at the central wavelength position or
the vertices [9]. Hence, the quadrilateral can be divided into four smaller triangles(
each illuminated by the optical sources corresponding to its three vertices, and only
up to three out of four optical sources will be “on” at any time instance in the QLED
CSK system, which maintains the same total optical power as conventional CSK.
However, the additional optical source increases electrical power since a certain level
of biasing is required to satisfy the switching requirements.
The constellations of 4-CSK, 8-CSK, and 16-CSK for QLED are illustrated in
Fig. 5.5. Similar to the squared QAM constellation, Gray mapping can be imposed
on the CSK constellation to further reduce the bit error rate. In QLED 4-CSK con-
stellation, the symbols are located at vertices of the quadrilateral. In QLED 8-CSK
constellation, the symbols S0, S3, S5, and S6 are located at the vertices of the quadri-
lateral as well, while the symbols S1, S2, S4, and S7 are the midpoints of the four
sides. In QLED 16-CSK constellation, the symbols are located as in conventional
16-QAM, which divide the quadrilateral into 16 smaller quadrilaterals as their ver-
tices. Similarly, 64-CSK constellation can be obtained with the locations of 64-QAM
symbols.
www.ebook3000.com

156
Figure 5.5 Constellations of 4-CSK, 8-CSK, and 16-CSK for QLED.
The color coordinates of the symbols for QLED 4-CSK, 8-CSK, and 16-CSK are
shown in Table 5.4, which also provides the corresponding intensity value in each
band calculated by (5.2)–(5.4). Depending on the symbol positions, the color co-
ordinates utilized in (5.2)–(5.4) vary for diﬀerent symbols. As in the conventional
CSK, the total optical power of each symbol is set to one to eliminate ﬂicker due to
intensity variations.
The constellation proposed in [9] gives a simple design rule for QLED CSK con-
stellation. Furthermore, the constellation can be optimized with the method intro-
duced in Section 5.1.3.
5.2
CSK with coded modulation
When perfect channel state information (CSI) is assumed at the receiver, the esti-
mated intensity vector ˆp can be obtained by the maximum likelihood (ML)-based
detection given by
ˆp = arg min
˜p∈S
∥r −H˜p∥2,
(5.22)
which is then mapped to the bit vector by a channel decoder. Since the detection in
(5.22) estimates the optimal intensity vector directly, it is referred to as hard detection.
The performance of the ML-based hard detection can be approximated by the union
bound, where the average bit error probability can be expressed as [10]
Pe,union ⩽
1
MNb
M

ξ=1
M

ζ=1,ζ̸=ξ
d

˜p(ξ), ˜p(ζ)
P

˜p(ξ) →˜p(ζ)
,
(5.23)
where d

˜p(ξ), ˜p(ζ)
denotes the Hamming distance between the intensity vectors
˜p(ξ) and ˜p(ζ). P

˜p(ξ) →˜p(ζ)
is the pairwise error probability (PEP) of the two
(a) QLED 4-CSK
(b) QLED 8-CSK
(c) QLED 16-CSK

157
Table 5.4 Constellations of QLED 4-CSK, 8-CSK, and 16-CSK and their intensity values in
each band [9].
Symbol
x
y
I
J
K
V
4-CSK
S0
0.169
0.007
1
0
0
0
S1
0.011
0.460
0
1
0
0
S2
0.734
0.265
0
0
0
1
S3
0.402
0.597
0
0
1
0
8-CSK
S0
0.169
0.007
1
0
0
0
S1
0.09
0.2335
0.5
0.5
0
0
S2
0.2065
0.5285
0
0.5
0.5
0
S3
0.011
0.460
0
1
0
0
S4
0.4515
0.1360
0.5
0
0
0.5
S5
0.734
0.265
0
0
0
1
S6
0.402
0.597
0
0
1
0
S7
0.568
0.431
0
0
0.5
0.5
16-CSK
S0
0.1690
0.0070
1
0
0
0
S1
0.1163
0.1580
0.6667
0.3333
0
0
S2
0.0110
0.4600
0
1
0
0
S3
0.0637
0.3090
0.3333
0.6667
0
0
S4
0.3573
0.0930
0.6667
0
0
0.3333
S5
0.2853
0.2306
0.3787
0.3247
0
0.2966
S6
0.1413
0.5057
0
0.6667
0.3333
0
S7
0.2134
0.3681
0.3202
0.2915
0.3882
0
S8
0.7340
0.2650
0
0
0
1
S9
0.6223
0.3757
0
0
0.3333
0.6667
S10
0.4020
0.5970
0
0
1
0
S11
0.5127
0.4853
0
0
0.6667
0.3333
S12
0.5457
0.1790
0.3333
0
0
0.6667
S13
0.4544
0.3031
0.2934
0
0.3428
0.3638
S14
0.2717
0.5513
0
0.3333
0.6667
0
S15
0.3630
0.4272
0
0.3955
0.2563
0.3483
intensity vectors given by
(5.24)
P

˜p(ξ) →˜p(ζ)
=P
+++r −H˜p(ξ)+++
2
>
+++r −H˜p(ζ)+++
2
=P
+++H˜p(ξ)+++
2
/2 −rTH˜p(ξ) >
+++H˜p(ζ)+++
2
/2 −rTH˜p(ζ)

=P
⎛
⎜
⎝

H˜p(ξ) + n
T
H

˜p(ζ) −˜p(ξ)
>
+++H˜p(ζ)+++
2
−
+++H˜p(ξ)+++
2
2
⎞
⎟
⎠
=P

nTH

˜p(ζ) −˜p(ξ)
> Ψ

,
www.ebook3000.com

158
S
S
S 
Figure 5.6 Diagram of MAP-based soft detection for coded CSK system.
where Ψ is deﬁned as
Ψ =
+++H˜p(ζ)+++
2
−
+++H˜p(ξ)+++
2
2
−

H˜p(ξ)T
H

˜p(ζ) −˜p(ξ)
.
(5.25)
Since H

˜p(ζ) −˜p(ξ)
is a constant matrix and the noise term n is Gaussian-
distributed, the term nTH

˜p(ζ) −˜p(ξ)
also follows the Gaussian distribution with
zero mean and variance of
+++H

˜p(ζ) −˜p(ξ)+++
2
σ2
0, where σ2
0 is the variance of the
noise. Therefore, the PEP between ˜p(ξ) and ˜p(ζ) is expressed as
P

˜p(ξ) →˜p(ζ)
= Q

Ψ
++H
˜p(ξ) −˜p(ζ)++ σ0

,
(5.26)
where Q(x) =
1
√
2π
 ∞
x exp
 −u2
2
du represents the standard tail probability
function of the Gaussian distribution with zero mean and unity variance.
A joint maximum a posteriori (MAP)-based soft detection was proposed in [10],
whose diagram is shown in Fig. 5.6. The information bit vector b is ﬁrstly encoded
by the channel encoder, and the coded vector u is sent to the interleaver π1. The
interleaved bits are used for CSK mapping to modulate the optical sources. At the
receiver, a joint MAP-based soft detection is used to generate the soft information as
the input for channel decoder, which exchanges extrinsic information with the chan-
nel decoder, and hard decision is only performed when the channel decoder reaches
its maximum number of iterations. In Fig. 5.6, Lp
det, La
det, and Le
det denote the a pos-
teriori, a priori, and extrinsic log-likelihood ratio (LLR) of the detection module,
while Lp
dec, La
dec, and Le
dec represent the a posteriori, a priori, and extrinsic LLR of
the channel decoder. For the bit vector u with log2 M bits, the bit-wise a posteriori
information of its vth bit is given by the Max-Log approximation as [10]
Lp
det (uv) =La
det (uv) + max
˜p∈S1uv

−∥r −H˜p∥2/2σ2 + A

(5.27)
−max
˜p∈S0uv

−∥r −H˜p∥2/2σ2 + A

,
where A is deﬁned as A = Nb
τ=1,τ̸=v uvLa
det (uτ), S0
uv and S1
uv are the subsets of
S given by S0
uv = {˜p ∈S|uv = 0} and S1
uv = {˜p ∈S|uv = 1}. The extrinsic

159
S
S
S 
S
S
S 
Figure 5.7 Diagram of three-stage CSK system with MAP-based soft detection and URC
precoder.
LLRs Le
det are ﬁrstly deinterleaved before fed into the outer decoder as the a priori
LLRs La
dec. Afterwards, the updated extrinsic LLRs Le
dec are fed back and reinter-
leaved, and then they are used as the a priori LLRs La
det for the detection block.
In order to reduce the error ﬂoor of a coded system, a unity-rate code (URC) is
usually utilized after the channel encoder since it can spread the extrinsic information
without increasing the system’s interleaver delay with its inﬁnite impulse response.
Besides, it keeps the throughput unchanged with negligible increase of complexity.
Therefore, a three-stage CSK system was also proposed in [10], which inserts a URC
encoder and interleaver at the transmitter. At the receiver, the iterations are ﬁrstly
performed between the joint MAP-based soft detection and the URC decoder referred
to as inner iterations. Afterwards, its output Lp
p,o is fed to the outer decoder, which
calculates extrinsic information La
o,p for the inner decoder in return. The diagram
of the three-stage CSK system with MAP-based soft detection and URC precoder is
illustrated in Fig. 5.7.
5.3
Wavelength division multiplexing with predistorion
Another multicolor modulation scheme is WDM, which utilizes colors with diﬀerent
wavelengths for data transmission. Unlike the CSK modulation where one symbol
is iecdp^a mapped to diﬀerent colors, the streams modulated on diﬀerent optical
sources inWDM are independent to provide parallel transmission. Recently, WDM
has beenemployed in VLC links to boost the data rate, and several gigabits/s trans)
missionshave been reported [11–13].
www.ebook3000.com

160
Figure 5.8 VLC system with RGB-type white LEDs.
5.3.1
System model
A VLC system using RGB-type white LEDs is illustrated in Fig. 5.8, where the in-
formation bits are encoded by the channel encoder and then serial-to-parallel (S/P)
converted into three streams. Each bit-stream is sent to the chip of a primary color
LED for simple OOK modulation. In order to generate white light, the modulated
optical signals of the three primary color LEDs are mixed using speciﬁc optical pow-
er mixing ratios. At the receiver, the optical ﬁlters for the three primary colors are
employed to attenuate the ambient light and separate the three primary color signals,
which are converted to their electronic counterparts by the optical to electronic (O/E)
converters. The three received electronic signals are then parallel to serial (P/S) con-
verted into the single signal stream for the soft-decision decoder.
Since illuminance takes priority over communication for indoor LEDs, one should
make sure that the appropriate optical power mixing ratio of the three primary colors
are used for white light. Let Mr, Mg, and Mb denote the optical power emitted from
the red, green, and blue LEDs. In [14], four combinations of the three primary colors
and their optical power mixing ratios Mr : Mg : Mb were provided to generate the
white light, whose wavelengths and the mixture ratios are listed in Table 5.5. Obvi-
ously, unequal optical power ratios are required for three primary colors to produce
the white light. The O/E conversion eﬃciency η is calculated as η = γ e λ
h c, where
γ is the quantum eﬃciency of the photo detector, e is the electron charge, λ is the
signal wavelength, h is Plank’s constant, and c is the speed of light [15]. For diﬀerent
colors, both the wavelengths and the quantum eﬃciencies of the photo detector are
diﬀerent. Therefore, the conversion eﬃciencies between the optical and electronic
signals are also diﬀerent for the three primary colors, which are denoted as ηr, ηg,
and ηb for the red, green, and blue colors, respectively. The amplitude of the elec-
tronic signal at the receiver is proportional to the intensity of the received light. If
the electronic energies received per symbol from the red, green, and blue LEDs are

161
deﬁned as Er, Eg, and Eb, we have

Er :

Eg :

Eb = Mrηr : Mgηg : Mbηb.
(5.28)
Table 5.5 Combination of three primary colors and the corresponding optical power mixing
ratio Mr : Mg : Mb for white light [14].
Type
Red
Green
Blue
1. Wavelength (nm)
600
555
480
Mixture ratio
1
0.89
2.51
2. Wavelength (nm)
610
555
475
Mixture ratio
1
1.43
2.29
3. Wavelength (nm)
610
555
450
Mixture ratio
1
2.62
1.96
4. Wavelength (nm)
610
565
450
Mixture ratio
1
11.17
7.19
5.3.2
Receiver-side predistortion
ceived signal from each O/E converter corresponding to each primary color is also
diﬀerent, which causes the performance degradation when soft-decision decoder is
used at the receiver. In order to improve the system performance, a predistorion
module can be used to predistort the received signal before it is passed to the soft-
decision decoder [16]. We denote the serial received signal from the P/S converter as
r(t), which combines the signals from the red, green, and blue color converters. The
weight parameters of the predistortion block for diﬀerent LED signals are deﬁned
as Fr, Fg, and Fb. The predistortion block gives the signal r(t) diﬀerent weights
according to which O/E converter the signal comes from. Therefore, the output of
the predistortion block r′(t) is given by
r′(t) =
⎧
⎪
⎨
⎪
⎩
r(t) · Fr,
r(t) ∈red light;
r(t) · Fg,
r(t) ∈green light;
r(t) · Fb,
r(t) ∈blue light.
(5.29)
With the predistortion module, a higher weight is assigned to the more reliable signal,
while a less reliable signal has a lower weight. However, the weighting factors of
the predistortion block must be carefully selected to optimize the achievable system
performance.
Consider a classic convolutional code as an example. When the soft-decision Viter-
bi decoder [17] is used, a common technique of estimating the attainable performance
Since the energies received from diﬀerent LEDs ]na not equal, the reliability of re-
]na
www.ebook3000.com

162
of the decoder is to use the union upper bound of the ﬁrst event error probability,
which is given by [18]
Pe ≤
∞

d=dfree
ndPd,
(5.30)
where dfree is the free distance of the convolutional code, nd denotes the number of
trellis-paths having a distance d from the all-zero path that merge with the all-zero
path for the ﬁrst time, and Pd represents the pairwise error probability. Furthermore,
nd is the coeﬃcient of the polynomial T(B, D)|B=1 derived from the transfer func-
tion T(B, D) [17]. The VLC channel may be modeled by an AWGN channel under
the line of sight user scenario of high-rate optical wireless communication systems
using white LEDs [19]. For the AWGN channel having the noise power spectral den-
sity of N0/2, the pairwise error probability Pd for OOK modulation can be expressed
as
Pd = Q

d Es
N0

,
(5.31)
where Es denotes the energy per symbol.
Since the energy received from each O/E converter corresponding to each primary
color is diﬀerent, the overall energy of each path is also diﬀerent. Thus, the union
upper bound of the ﬁrst event error probability in the absence of the predistortion
block can be rewritten as
Pe ≤
∞

d=dfree
nd

k=1
Q
⎛
⎝
rd,k
√Er + gd,k
Eg + bd,k
√Eb
2
d N0
⎞
⎠,
(5.32)
where k represents the kth path at a distance of d from the all-zero path that merges
with the all-zero path for the ﬁrst time, while the numbers of ones transmitted from
the red, green, and blue LEDs in the kth path are deﬁned as rd,k, gd,k, and bd,k,
respectively. Apparently, rd,k + gd,k + bd,k = d, and the upper bound in (5.32) is
larger than that given in (5.30).
In order to improve the performance of the soft-decision Viterbi decoder, the pre-
distortion block allows more reliable signals to contribute more to both the branch-
and path-metric calculation, while reducing the contribution of the less reliable sig-
nals, by weighting the three signals gleaned from the three O/E converters corre-
sponding to the primary colors of red, green, and blue with the weighting factors of
Fr, Fg, and Fb. The weighting factor changes both the desired signal energy and the
noise power gleaned from each O/E converter simultaneously, which is proportional
to the squared value of the weight applied, and therefore the union upper bound of
the ﬁrst event error probability can be expressed as
Pe ≤
∞

d=dfree
nd

k=1
Q
⎛
⎜
⎝
7
8
8
9
rd,kFr
√Er + gd,kFg
Eg + bd,kFb
√Eb
2
rd,kF 2r + gd,kF 2g + bd,kF 2
b
 N0
⎞
⎟
⎠.

163
(5.33)
Based on Cauchy–Schwarz inequality, the union upper bound in (5.33) is minimized
as
∞

d=dfree
nd

k=1
Q
⎛
⎜
⎝
7
8
8
9
rd,kFr
√Er + gd,kFg
Eg + bd,kFb
√Eb
2
rd,kF 2r + gd,kF 2g + bd,kF 2
b
 N0
⎞
⎟
⎠
≥
∞

d=dfree
nd

k=1
Q
⎛
⎝
7
8
8
9
rd,kF 2r + gd,kF 2g + bd,kF 2
b
 · (rd,kEr + gd,kEr + bd,kEr)
rd,kF 2r + gd,kF 2g + bd,kF 2
b
 N0
⎞
⎠
=
∞

d=dfree
nd

k=1
Q
⎛
⎝

(rd,kEr + gd,kEr + bd,kEr)
N0
⎞
⎠,
(5.34)
where the last equality holds only when
Fr : Fg : Fb =

Er :

Eg :

Eb.
(5.35)
To keep the signal power unchanged after predistortion, the optimal weighting pa-
rameters are given by
Fr =
√
3Mrηr

M 2r η2r + M 2g η2g + M 2
b η2
b
,
(5.36)
Fg =
√
3Mgηg

M 2r η2r + M 2g η2g + M 2
b η2
b
,
(5.37)
Fb =
√
3Mbηb

M 2r η2r + M 2g η2g + M 2
b η2
b
.
(5.38)
According to (5.36)–(5.38), it is interesting to note that the weighting factors de-
pend only on the emitted optical powers and on the conversion eﬃciencies of the O/E
converters regardless of the structure of the convolutional codes. Therefore, they are
optimal for any convolutional codes. The computational complexity of the predis-
tortion module is extremely low, which requires only a single accumulation and a
multiplication operation. For other soft-decision decoders, such as the belief prop-
agation (BP) decoder of low density parity check (LDPC) codes [20] and the BCJR
decoder of turbo codes [21], the error performance bounds are less straightforward to
obtain, since their code structures are complex and the decoding algorithms are itera-
tive. Therefore, ﬁnding the optimal weighting parameters of the predistortion module
for these soft-decision decoders is challenging. Fortunately, the optimal weighting
parameters of the predistortion block derived for the soft-decision Viterbi decoder
may nonetheless be beneﬁcial for employment in soft-decision aided LDPC and tur-
bo decoders.
www.ebook3000.com

164
6
8
10
12
14
16
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
 Es/ N0 (dB)
BER
Equal Power Illumination
Case 1, Decoder without Predistortion
Case 1, Decoder with Predistortion
Case 2, Decoder without Predistortion
Case 2, Decoder with Predistortion
Figure 5.9 BER performance comparison of the RGB-type LED-based VLC system with
and without the predistortion module, where the convolutional code with the soft-decision
Viterbi decoder is used.
5.3.3
Performance evaluation
Two cases of diﬀerent mixture ratios of the optical powers emitted from the red,
green, and blue LEDs are considered in order to create white light according to Ta-
ble 5.5. For Case 1, the mixing ratio of the optical emitted powers is Mr : Mg :
Mb = 1 : 2.62 : 1.96 and the corresponding wavelengths of the red, green, and
blue colors are 610 nm, 555 nm, and 450 nm, respectively. By contrast, for Case
2, the mixing ratio is Mr : Mg : Mb = 1 : 11.17 : 7.19 and the correspond-
ing wavelengths of the red, green, and blue colors are 610 nm, 565 nm, and 450 nm,
respectively. For simplicity, the O/E conversion eﬃciencies for the three primary
colors, namely ηr, ηg, and ηb, are assumed to be equal. Naturally, this does not alter
the fundamental nature of the unequal powers of the three received electronic signals
corresponding to the red, green, and blue LEDs. Case 2 represents a much more
uneven optical power mixture of the three primary colors for emitting white light.
A convolutional code, an LDPC code, and a turbo code are used in the simulations.
The convolutional code employed has a code rate of 1/2, while its constraint length
is seven and the generator polynomials are the same as [171, 133]8. Soft-decision
Viterbi decoder is used with the trace back length of ﬁve times of the constraint
length. The LDPC code used in the simulations is that of the IEEE 802.11 standard

165
4
6
8
10
12
14
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
 Es/ N0 (dB)
BER
Equal Power Illumination
Case 1, Decoder without Predistortion
Case 1, Decoder with Predistortion
Case 2, Decoder without Predistortion
Case 2, Decoder with Predistortion
Figure 5.10 BER performance comparison of the RGB-type LED-based VLC systems with
and without the predistortion module, where the LDPC code with the BP decoder is used.
with a codeword-length of 1944 bits and a code rate of 1/2 [22], while the BP decoder
is employed at the receiver and the maximum number of iterations is 30. At last, the
turbo code for the 3rd Generation Partnership Project (3GPP) is used with a code rate
of 1/3 and an interleaver length of 1440 bits [23]. The BCJR decoder is used at the
receiver and the number of iterations is set to six.
The BER performance obtained both with and without the predistortion block are
illustrated in Figs. 5.9–5.11 for the convolutional code, LDPC code, and turbo code,
respectively. The BER curve obtained from the case of the equal optical power radi-
ations from the red, green, and blue LEDs is also included as the benchmark, which
represents the lower bound of BER obtained with the aid of an equal optical power
mixture of Mr : Mg : Mb = 1 : 1 : 1.
From Figs. 5.9–5.11, it can be seen that a signiﬁcant performance gain can be at-
tained with the predistortion block. Quantitatively, at the BER level of 10−5 and
for the unequal optical power mixture of the three primary colors of Case 1, the
performance gains of 0.6 dB, 0.7 dB, and 0.5 dB are achieved, respectively, for the
convolutional code, LDPC code, and turbo code over the corresponding systems op-
erating without predistortion. As expected, the attainable BER performance of Case
2 is considerably poorer than that of Case 1 since the optical power distribution of
the red, green, and blue LEDs in Case 2 is much more uneven. However, the perfor-
mance gain attained by the predistortion block is signiﬁcantly higher in Case 2 due
to larger imbalance. Speciﬁcally, at the BER level of 10−5, the predistortion scheme
www.ebook3000.com

166
0
2
4
6
8
10
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
 Es/ N0 (dB)
BER
Equal Power Illumination
Case 1, Decoder without Predistortion
Case 1, Decoder with Predistortion
Case 2, Decoder without Predistortion
Case 2, Decoder with Predistortion
Figure 5.11 BER performance comparison of the RGB-type LED-based VLC systems with
and without the predistortion module, where the turbo code with the BCJR decoder is
used.
attains SNR gains of 2.8 dB, 3.9 dB, and 2.2 dB, respectively, for the convolutional
code, LDPC code, and turbo code. The results of Figs. 5.9–5.11 also conﬁrm that
the best BER performance is obtained with the equal optical illumination powers
of the red, green, and blue LEDs. However, the equal optical power mixture of the
three primary colors cannot produce white light and, therefore, it cannot carry out
the primary lighting function.
5.4
Conclusion
This chapter discusses multicolor modulation schemes for VLC systems with RGB-
type LEDs, which combine light from red, green, and blue LEDs for white light. Due
to its good property, CSK was developed and adopted in the IEEE 802.15.7 standard.
Besides the CSK constellation in the standard, the optimal design rules of CSK con-
stellation as well as Quad-LED CSK are provided to achieve superior capacity, while
CSK with coded modulation is introduced for practical transmission. Finally, WDM
VLC system is discussed with channel coding, and a receiver-side predistortion is
proposed before channel decoding, which has shown signiﬁcant performance gain
for WDM systems.

167
References
1 IEEE Std. 802.15.7-2011, Part 15.7:
Short-Range Wireless Optical
Communication Using Visible Light, Sep.
2011.
2 A. Yokoi, J. Son, and T. Bae, “More
description about CSK constellation,” March
2011, IEEE 802.15 contribution
15-11-0247-00-0007.
3 S. Rajagopal, R. D. Roberts, and S. K. Lim,
“IEEE 802.15.7 visible light
communication: Modulation schemes and
dimming support,” IEEE Commun. Mag.,
vol. 50, no. 3, pp. 72–82, Mar. 2012.
4 R. J. Drost and B. M. Sadler, “Constellation
design for color-shift keying using billiards
algorithms,” in Proc. IEEE Global
Communications Conference (GLOBECOM)
Workshops 2010 (Miami, FL), Dec. 6–10,
2010, pp. 980–984.
5 E. Monteiro and S. Hranilovic,
“Constellation design for color-shift keying
using interior point methods,” in Proc. IEEE
Global Communications Conference
(GLOBECOM) Workshops 2012 (Anaheim,
CA), Dec. 3–7, 2012, pp. 1224–1228.
6 R. J. Drost and B. M. Sadler, “Constellation
design for channel precompensation in
multi-wavelength visible light
communications,” IEEE Trans. Commun.,
vol. 62, no. 6, pp. 1995–2005, Jun. 2014.
7 E. Monteiro and S. Hranilovic, “Design and
implementation of color-shift keying for
visible light communications,” J. Lightw.
Technol., vol. 32, no. 10, pp. 2053–2060,
May 2014.
8 A. Wilkins, J. Veitch, and B. Lehman, “LED
lighting ﬂicker and potential health
concerns: IEEE standard PAR1789 update,”
in Proc. IEEE Energy Conversion Congress
and Exposition 2010 (Atlanta, GA), Sep.
12–16, 2010, pp. 171–178.
9 R. Singh, T. O’Farrell, and J. P. R. David,
“An enhanced color shift keying modulation
scheme for high-speed wireless visible light
communications,” J. Lightw. Technol.,
vol. 32, no. 14, pp. 2852–2592, Jul. 2014.
10 J. Jiang, R. Zhang, and L. Hanzo, “Analysis
and design of three-stage concatenated
color-shift keying,” IEEE Trans. Veh.
Technol., vol. 64, no. 11, pp. 5126–5136,
Nov. 2015.
11 W. Y. Lin, C. Y. Chen, H. H. Lu,
C. H. Chang, Y. P. Lin, H. C. Lin, and
H. W. Wu, “10m/500Mbps WDM visible
light communication systems,” Opt. Exp.,
vol. 20, no. 9, pp. 9919–9924, Apr. 2012.
12 F. M. Wu, C. T. Lin, C. C. Wei, C. W. Chen,
Z. Y. Chen, and K. Huang, “3.22-Gb/s WDM
visible light communication of a single RGB
LED employing carrier-less amplitude and
phase modulation,” in Proc. Optical Fiber
Communication Conference and Exposition
and the National Fiber Optic Engineers
Conference (OFC/NFOEC) 2013 (Anaheim,
CA), Mar. 17–21, 2013, OTh1G.4.
13 Y. Wang, Y. Wang, N. Chi, J. Yu, and
H. Shang, “Demonstration of 575-Mb/s
downlink and 225-Mb/s uplink bi-directional
SCM-WDM visible light communication
using RGB LED and phosphor-based LED,”
Opt. Exp., vol. 21, no. 1, pp. 1203–1208,
Jan. 2013.
14 Y. Tanaka, T. Komine, S. Haruyama, and
M. Nakagawa, “Indoor visible light data
transmission system utilizing white LED
lights,” IEICE Trans. Commun., vol. E86-B,
no. 8, pp. 2440–2454, Aug. 2003.
15 X. Zhu and J. M. Kahn, “Free-space optical
www.ebook3000.com

168
communication through atmospheric
turbulence channels,” IEEE Trans. Commun.,
vol. 50, no. 8, pp. 1293–1300, Aug. 2002.
16 Q. Wang, Z. Wang, S. Chen, and L. Hanzo,
“Enhancing the decoding performance of
optical wireless communication systems
using receiver-side predistortion,” Opt. Exp.,
vol. 21, no. 25, pp. 30295–30305, Dec. 2013.
17 A. J. Viterbi, “Convolutional codes and
their performance in communication
systems,” IEEE Trans. Commun. Technol.,
vol. 19, no. 5, pp. 751–772, Oct. 1971.
18 J. G. Proakis and M. Salehi, Digital
Communications, 5th Edition. McGraw-Hill:
New York, 2008.
19 T. Komine, J. H. Lee, S. Haruyama, and
M. Nakagawa, “Adaptive equalization system
for visible light wireless communication
utilizing multiple white LED lighting
equipment,” IEEE Trans. Wirel. Commun.,
vol. 8, no. 6, pp. 2892–2900, Jun. 2009.
20 D. J. C. MacKay, “Good error-correcting
codes based on very sparse matrices,” IEEE
Trans. Inf. Theory, vol. 45, no. 2,
pp 399–431, Mar. 1999.
21 L. Bahl, J. Cocke, F. Jelinek, and J. Raviv,
“Optimal decoding of linear codes for
minimizing symbol error rate,” IEEE Trans.
Inf. Theory, vol. 20, no. 2, pp. 284–287, Mar.
1974.
22 IEEE Std. 802.11-2012, Part 11: Wireless
LAN Medium Access Control (MAC) and
Physical Layer (PHY) Speciﬁcations, Mar.
2012.
23 3GPP2 C.S0002-F v1.0, Physical Layer
Standard for CDMA2000 Spread Spectrum
Systems, Dec. 2012.

169
6
Optical MIMO
In this chapter, we discuss optical multiple-input multiple-output (MIMO) techniques
for imaging and non-imaging visible light communication (VLC) systems, including
modern optical MIMO, optical spatial modulation (OSM), optical space shift keying
(OSSK), and optical MIMO combined with orthogonal frequency division multi-
plexing (MIMO-OFDM). Multiuser precoding techniques for VLC systems are also
introduced under lighting constraints.
Despite the fact that visible light spectrum is as wide as several terahertz (THz),
the bandwidth of oﬀ-the-shelf light emitting diodes (LEDs) is limited, which makes
it very challenging to achieve high-data-rate transmission. Meanwhile, in order to
provide suﬃcient illumination, multiple LED units are usually installed in a single
room. Therefore, MIMO techniques can be naturally employed in indoor VLC sys-
tems to boost the data rate. Typically, there are two optical MIMO approaches for
VLC, namely, non-imaging and imaging MIMO. In non-imaging MIMO systems,
each receiver collects light with its own optical concentrator, while the imaging MI-
MO systems employ an imaging diversity receiver structure to distinguish the light
from diﬀerent transmitters. Two optical MIMO systems are introduced in Section 6.1
and Section 6.2, respectively.
Meanwhile, MIMO VLC systems usually support data transmission for multiple
users simultaneously. In order to eliminate the inter-user interference, precoding
techniques can be utilized at the transmitters. Although precoding techniques have
been widely investigated in RF communications, these schemes cannot be applied to
VLC systems directly since intensity modulation is used in VLC systems. Therefore,
several precoding schemes for multiuser MIMO VLC under lighting constraints are
provided in Section 6.3.
Finally, MIMO-OFDM is a promising technique to provide high-speed VLC trans-
mission, which inherits the advantages of both MIMO and OFDM. In Section 6.4,
MIMO-OFDM for VLC systems under both single user and multiple user scenarios
are introduced.
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.
www.ebook3000.com

170
Figure 6.1 Non-imaging optical MIMO VLC system.
6.1
Non-imaging optical MIMO techniques
A non-imaging MIMO VLC system is illustrated in Fig. 6.1, where a single room is
equipped with multiple LED units for illumination, which can cooperate to transmit
information simultaneously. We assume Nt LED units are at the ceiling, and Nr
non-imaging concentrators and photodiodes (PDs) are at the receiver to collect light.
6.1.1
Channel response
The DC gain of the subchannel hp,q between the qth LED unit and the pth PD is
expressed as [1]
hp,q =
 ρpAp
d2
p,q R (φq) cos (ϕp,q) ,
ϕp,q ≤Ψc,p,
0,
ϕp,q > Ψc,p,
(6.1)
where ρp is the responsivity coeﬃcient of the PD, dp,q is the distance between the
qth LED unit and the pth PD, φq is the emission angle of the qth LED unit, ϕp,q is
the incidence angle of the light, and Ψc,p is the receiver ﬁeld of view (FOV) of the
pth PD. Unlike conventional RF channels, the channel matrix H = {hp,q}Nr×Nt is
real-valued and commonly highly correlated when the users locate closely [2]. For

171
the pth PD, the receiver collection area Ap can be calculated as
Ap = γ2APD,p/sin2 (Ψc,p),
(6.2)
where γ is the concentrator refractive index of the PD, APD,p is the area of the pth PD.
In (6.1), R (φq) denotes the generalized Lambertian radiant intensity given by [1]
R (φq) = ((m + 1) cosm (φq)) /2π,
(6.3)
where m is the order of Lambertian emission.
At the receiver, the optical signal is directly detected by the corresponding PD,
which generates an electric signal proportional to the received optical power. Be-
sides that, shot noise and thermal noise are induced at the receiver, which can be
modeled as real-valued additive white Gaussian noise (AWGN) with zero mean, and
the variance of the noise at the pth PD can be written as [1]
σ2
p = 2ePpB + 2eρpχambAp (1 −cos (Ψc,p)) B + i2
amp,
(6.4)
where e is the electronic charge, χamb is the ambient light photocurrent, B is the
bandwidth of receiver, iamp is the preampliﬁer noise current density, and Pp is the
average received optical power at the pth PD collected from all the LED units.
6.1.2
Optical MIMO techniques
In this part, diﬀerent optical MIMO techniques for non-imaging VLC systems will
be introduced and compared, and maximum likelihood (ML) detection is used
at the receiver assuming perfect channel estimation and synchronization.
De-
note the transmitted and received signal vector as x = [x1 x2 . . . xNt]T and
y = [y1 y2 . . . yNr]T, respectively, the channel matrix H can be calculated ac-
cording to (6.1). Therefore, the transmitted signal vector can be estimated by
ˆx = arg max
x
py (y | x, H) = arg min
x ∥y −Hx∥2 ,
(6.5)
where py (y | x, H) is the conditional probability density function.
The simplest technique of optical MIMO is the repetition coding (RC), where all
the transmitters convey the same information: x1 = x2 = · · · = xNt. In this way,
multiple transmitters can provide transmit-diversity gain since all the lights can be
accumulated at the receiver to enhance the received optical power, leading to better
performance. If M-ary pulse amplitude modulation (PAM) is employed at the trans-
mitter, RC can achieve the spectral eﬃciency of log2 (M) bit/s/Hz. In VLC system,
the transmitted signal should be non-negative real-valued since intensity modulation
is used. Therefore, unipolar M-ary PAM can be used whose intensity level is given
by [2]
IPAM
m
=
2I
M −1m, m = 0, 1, . . . , M −1,
(6.6)
www.ebook3000.com

172
where I is the average optical power. The lower bound of its bit error rate (BER) can
be calculated as
Pe,PAM ≥2(M −1)
M log2(M)Q

1
M −1
√γelec,r

,
(6.7)
where Q(x) =
1
√
2π
 ∞
x exp
 −u2
2
du represents the standard tail probability
function of the Gaussian distribution with zero mean and unity variance, and γelec,r
denotes the received electrical signal-to-noise ratio (SNR).
In order to maintain the total optical power constant, the optical power for each
transmitter is set to I/Nt and the optical-to-electrical conversion coeﬃcient is nor-
malized. Therefore, the received optical power at the pth PD from all the transmitters
can be calculated as
Ir,p =
Nt

q=1
Ihp,q/Nt.
(6.8)
Denote Es = I2Ts as the mean emitted electrical energy of the intensity-modulated
optical signals and Ts as the symbol period, when maximum ratio combining (MRC)
is used, the electrical SNR after combining is given by
γelec,r = Ts
N0
Nr

p=1
⎛
⎝
Nt

q=1
I
Nt
hp,q
⎞
⎠
2
=
Es
N0N 2
t
Nr

p=1
⎛
⎝
Nt

q=1
hp,q
⎞
⎠
2
.
(6.9)
With (6.7) and (6.9), the BER for RC is bounded by [2]
Pe,RC ≥2(M −1)
M log2(M)Q
⎛
⎜
⎜
⎝
1
M −1
7
8
8
8
9
Es
N0N 2
t
Nr

p=1
⎛
⎝
Nt

q=1
hp,q
⎞
⎠
2
⎞
⎟
⎟
⎠.
(6.10)
RC can provide reliable transmission performance with transmit-diversity. How-
ever, it is not spectrally eﬃcient since all the LEDs transmit the same information. If
diﬀerent LEDs convey independent information, enhanced spectral eﬃciency can be
achieved, which is referred to as spatial multiplexing (SMP) [3]. When the unipolar
M-PAM is used at each transmitter, and the optical power is also distributed equal-
ly to each LED as RC, the spectral eﬃciency of SMP is Nt log2 (M) bit/s/Hz. In
order to estimate the BER of SMP, pairwise error probability (PEP) is used, which
calculates the probability that the detector wrongly estimates the signal vector xm(1)
as xm(2), and we have
PEPSMP = PEP (xm(1) →xm(2)|H)
(6.11)
= Q

Ts
4N0
∥H (xm(1) →xm(2))∥2

.

173
When all the possible error situations are considered, the BER of SMP can be
upper-bounded by [2]
Pe,SMP ≤
1
M Nt log2(M Nt)
MNt

m(1)=1
MNt

m(2)=1
dH (bm(1), bm(2))
(6.12)
Q

Ts
4N0
∥H (xm(1) →xm(2))∥2

,
where bm(1) and bm(2) denote the bit vectors corresponding to the signal vectors
xm(1) and xm(2), respectively, and dH (bm(1), bm(2)) is the Hamming distance be-
tween bm(1) and bm(2).
As an energy-eﬃcient modulation scheme, spatial modulation (SM) was proposed
in [4], which transmits information not only by the amplitude and phase of the signals,
but also by the indices of antennas. In SM, only one antenna is activated during one
symbol duration, where some bits are transmitted by conventional constellations such
as quadrature amplitude modulation (QAM) and PAM, and the index of the activated
antenna represents the rest of the information. In this way, spatial dimension can
be used to improve the spectral eﬃciency without extra transmitting power, leading
to improved energy eﬃciency. Moreover, inter-channel interference is completely
avoided since only one channel is used at a time. Due to its good performance, SM
has been applied to the optical domain termed as optical SM (OSM) [5, 6]. Since
intensity modulation is employed, unipolar PAM can be used at each transmitter.
When Nt transmitters are used and M-ary unipolar PAM is mapped to the activated
transmitter, the spectral eﬃciency of OSM is log2 (Nt)+log2 (M) bit/s/Hz. Unlike
RC and SMP, where the zero intensity is used in PAM, zero intensity cannot be used
in SM since the receiver cannot distinguish which transmitter is activated if all the
signals are zero. Therefore, modiﬁed PAM constellation is used in OSM, which is
given by [2]
ImPAM
m
=
2I
M + 1m, m = 1, 2, . . . , M.
(6.13)
Similar to SMP, the PEP of SM can be calculated by
PEPSM = PEP (xm(1) →xm(2)|H)
(6.14)
= Q
⎛
⎝
7
8
8
9 Ts
4N0
Nr

p=1
		ISM
m(1)hpq(1) −ISM
m(2)hpq(2)
		2
⎞
⎠.
When all the MNt signal vectors of OSM are considered, the upper bound of its
www.ebook3000.com

174




(a) Repetition coding




(b) Spatial multiplexing

  
  
  
(c) Spatial modulation
Figure 6.2 Examples of optical MIMO encoding.

175
BER is given by
Pe,SM ≤
1
MNt log2(MNt)
M

m(1)=1
Nt

q(1)=1
M

m(2)=1
Nt

q(2)=1
dH
bm(1)q(1), bm(2)q(2)

(6.15)
Q
⎛
⎝
7
8
8
9 Ts
4N0
Nr

p=1
		ISM
m(1)hpq(1) −ISM
m(2)hpq(2)
		2
⎞
⎠,
where bm(1)q(1) is the bit vector corresponding to the situation where transmitter
q(1) is activated and its intensity is ISM
m(1), bm(2)q(2) is the demodulated bit vector
corresponding to the situation where transmitter q(2) is activated and its intensity is
ISM
m(2). In Fig. 6.2, some examples of encoding for RC, SMP, and SM are given.
Due to the high channel correlation in line-of-sight (LOS) scenarios, OSM and
SMP cannot perform well in visible light communications [2]. Therefore, power
imbalance is proposed to reduce the channel correlation [7], which introduces inde-
pendent ampliﬁcation factors to diﬀerent LEDs. The ampliﬁcation matrix is denoted
as A = diag{a1, . . . , aNt}, which is normalized by
Nt
q=1 aq
Nt
= 1. Therefore,
Nt −1 variables should be considered in the optimization, leading to high complex-
ity. In [2], a heuristic solution was given with exponential function
aq =
⎧
⎨
⎩
Nt
Nt−1
i=0
αi ,
q = 1,
αaq−1,
1 < q ≤Nt,
(6.16)
where α = 10
β
10 is the optical power imbalance factor and β is the optical power
imbalance factor in dB. At the receiver, power imbalance factor can be regarded as
part of the channel gain, which can be obtained by conventional channel estimation.
Therefore, the receiver does not need to know the actual power imbalance factor, and
power imbalance will not increase the complexity of the receiver.
6.1.3
Performance comparison
In this section, simulations are conducted to compare the MIMO techniques for non-
imaging VLC system. The simulation parameters for the VLC system conﬁguration
are listed in Table 6.1. Both transmitters and receivers are aligned in a quadratically
2×2 manner as shown in Fig. 6.1, which are in the middle of the room. The vertical
distance between the transmitters and receivers are 1.75 m. The spacing between the
adjacent receivers is assumed to be dRX = 0.1 m on both the x- and y-axis. Diﬀerent
spacings between adjacent transmitters are investigated on the x- and y-axis, which
are given by dTX = 0.2 m, 0.4 m, and 0.6 m. The corresponding channel matrices
are obtained by (6.1).
Figure 6.3 illustrates the BER performance of RC, SMP, and OSM for the three
transmitter spacings at the spectral eﬃciency of R = 4 bit/s/Hz, where the SNR is
www.ebook3000.com

176
Table 6.1 Simulation parameters for VLC system conﬁguration.
Room Size (length × width × height)
5 m × 5 m × 3 m
LED emission angle φq
15◦
PD area APD,p
1 cm2
PD responsivity coeﬃcient ρp
1 A/W
PD concentrator refractive index γ
1
Lambertian emission mode number m
1
Receiver FOV angle Ψc,p
15◦
Pre-ampliﬁer noise density iamp
5 pA/Hz−1/2
Ambient light photocurrent χamb
10.93 A/m2/Sr
80
85
90
95
100
105
110
115
120
10
−4
10
−3
10
−2
10
−1
10
0
SNR (dB)
BER
RC ( dTX = 0.2 m)
RC ( dTX = 0.4 m)
RC ( dTX = 0.6 m)
SMP ( dTX = 0.2 m)
SMP ( dTX = 0.4 m)
SMP ( dTX = 0.6 m)
OSM ( dTX = 0.2 m)
OSM ( dTX = 0.4 m)
OSM ( dTX = 0.6 m)
Figure 6.3 Performance comparison of RC, SMP, and OSM for non-imaging VLC system
with spectral eﬃciency of 4 bit/s/Hz, where all the LEDs have equal power.
deﬁned as the energy ratio of transmitted signal to noise. The theoretical lower and
upper error bounds according to (6.10) and (6.12) are shown by markers, while the
simulation results are shown in diﬀerent lines. It can be seen that theoretical bounds
match well with the simulation results especially at high SNR regions. In order to
achieve the required spectral eﬃciency, 16PAM, 2PAM, and 4PAM are used for RC,
SMP, and OSM, respectively. When dTX = 0.2 m and 0.4 m, RC achieves the best
performance while SMP performs worst due to the high channel correlation. When
dTX = 0.6 m and the channel matrix is well-conditioned, however, RC suﬀers 7 dB

177
80
85
90
95
100
105
110
115
120
10
−4
10
−3
10
−2
10
−1
10
0
SNR (dB)
BER
RC (δ = 1 dB)
RC (δ = 3 dB)
RC (δ = 4 dB)
SMP (δ = 1 dB)
SMP (δ = 3 dB)
SMP (δ = 4 dB)
OSM (δ = 1 dB)
OSM (δ = 3 dB)
OSM (δ = 4 dB)
Figure 6.4 Performance comparison of RC, SMP, and OSM for 4 × 4 non-imaging VLC
system with spectral eﬃciency of 4 bit/s/Hz and diﬀerent power imbalance factors.
performance degradation compared with the scenario with dTX = 0.2 m since less
energy is received. Interestingly, both SMP and OSM outperform RC signiﬁcantly,
and they are even better than RC for the other two scenarios with more received
energy. At high SNR regions, SMP outperforms SM since a lower modulation order
is used with its multiplexing gain. However, when the SNR is lower than 103 dB,
OSM achieves the best performance because OSM can convey information in the
spatial domain.
Figure 6.4 compares the BER of RC, SMP, and OSM with dTX = 0.2 m at the
spectral eﬃciency of R = 4 bit/s/Hz. Power imbalance is considered with diﬀerent
power imbalance factors δ = 1 dB, 3 dB, and 4 dB. With imbalanced power, the cor-
relation of the channel matrix can be reduced. It can be observed that considerable
performance gain can be achieved with power imbalance for both SMP and OSM,
while the performance of RC remains the same when power imbalance factor varies.
For RC, its performance is only related to the absolute channel gains rather than the
channel correlation as shown in (6.10). Therefore, power imbalance has no inﬂuence
on its performance. Although larger power imbalance factor may lead to lower chan-
nel correlation, it also reduces the transmitted power for some of the links, which may
also degrade the system performance. Therefore, there should be a tradeoﬀbetween
the correlation and the transmitted power. For OSM, the best power imbalance factor
is about δ = 1 dB, while for SMP, δ = 3 dB provides the best performance.
www.ebook3000.com

178
Figure 6.5 Imaging optical MIMO VLC system.
6.2
Imaging optical MIMO techniques
An imaging MIMO VLC system is illustrated in Fig. 6.5, where an imaging diversity
receiver is utilized to isolate the signals from diﬀerent transmitters. Each LED unit
is imaged onto a detector array, where the images may be on any pixels. Diﬀerent
from the non-imaging approach, the channel gain of imaging MIMO can be written
as [1]
himage,p,q = κp,qh′
q,
(6.17)
where h′
q is the channel gain for the qth LED unit at the aperture of imaging lens
when the receiver is at a particular position, which can be written as
h′
q =
 ρ′A′
d′2
q R
φ′
q
 cos
ϕ′
q
 ,
ϕ′
q ≤Ψ′
c,
0,
ϕ′
q > Ψ′
c,
(6.18)
where ρ′ is the responsivity coeﬃcient of the receiver, A′ is the imaging receiver
collection area, d′
q is the distance between the qth LED unit and the center of the
receiver collection lens, φ′
q is the emission angle of the qth LED unit, ϕ′
q is the
incidence angle of the light, and Ψ′
c is the FOV of the receiver. In (6.17), κp,q denotes

179
Figure 6.6 An example of the image on the receiver array.
the proportion of the image area that falls on the pth detector pixel in the array
κp,q = Aq,s(s=p)
Nr
s=1 Aq,s
,
(6.19)
where Aq,s represents the area of the image for the qth LED unit on the sth detector
pixel in the array.
An example of the image on the receiver array for the qth LED unit is illustrated
in Fig. 6.6. A paraxial optics approach is used where the system magniﬁcation is
independent of the angle of incidence of the rays, and image distortion is not con-
sidered as in [1]. Denote the diameter and f-number of the image lens as δ and f#,
respectively, the focal length is given by L = δf#. Therefore, the magniﬁcation
of the system can be calculated as M = dz/L, where dz is the vertical distance
from the ceiling to the receiver. As shown in Fig. 6.6, the four vertices of one LED
unit in the ceiling are A, B, C, and D, and their corresponding image coordinates
at the receiver are A′, B′, C′, and D′. According to the imaging principle, we have
A′B′ = MAB, B′C′ = MBC, C′D′ = MCD, and D′A′ = MDA.
Figure 6.7 illustrates three typical scenarios of the images on the detector array.
In Fig. 6.7(a), the images for diﬀerent LED units fall on diﬀerent detectors. The
corresponding channel matrix is diagonal, and the signals from diﬀerent LED units
can be separated perfectly. In Fig. 6.7(b), however, all the received signals fall on
the same detector. Only one row of the channel matrix is nonzero, and the signals
from diﬀerent LED units cannot be recovered. Therefore, the number of detectors
should be increased to distinguish diﬀerent signals. Alternatively, the signals fall
on the same detector can carry the same information similar to repetition coding. If
parts of each signal are received by diﬀerent detectors, as shown in Fig. 6.7(c), the
www.ebook3000.com

180
(a) Example 1
(b) Example 2
(c) Example 3
Figure 6.7 Examples of images on the detector array.
signals can still be recovered even though parts of diﬀerent signals are mixed at the
same detector. In order to make sure the channel matrix is full-rank, the number of
receivers should be always no smaller than that of transmitters, and a pseudo-inverse
operation can be used to estimate the transmitted data.
6.3
Multiuser precoding techniques
In a typical indoor scenario, multiple users usually need to be served simultaneously,
where the elimination of multiuser interference is crucial. The precoders and de-
coders for MU-MIMO in RF communications have been widely studied to cancel
the interference [8, 9]. However, they cannot be applied to VLC systems directly.
For VLC systems, the channels and the transmitted signals are both real-valued and
non-negative. Thus, the constellation is limited within one dimension and DC bias

181
Figure 6.8 Illustration of MU-MIMO VLC system.
is required. Meanwhile, the power constraints for VLC are on optical domain rather
than electrical domain.
An MU-MIMO VLC system is illustrated in Fig. 6.8, where a single room is
equipped with Nt LED units for illumination, which can cooperate to transmit in-
formation for Nr users each with a single PD. In order to eliminate multiuser in-
terference, the transmitted Nr × 1 data vector d is ﬁrstly precoded into an Nt × 1
transmitted vector x. Since VLC systems utilize intensity modulation, the transmit-
ted vector should be real-valued and nonnegative. The channel gain between the LED
units and receivers can be calculated according to Section 6.1.1.
Denote dp as the real-valued symbol for the pth user, which is zero-mean and
normalized to the range [−1, 1], at the qth LED unit, dp is multiplied by a precoding
weight wp,q, which is also real-valued. By adding up all the weighted symbols from
Nr users at the qth LED unit, we have
xq =
Nr

p=1
dpwp,q,
(6.20)
which is real-valued but not always non-negative. Therefore, PDC,q is added to xq
for modulating the LED unit and the transmitted signal is given by
yq = xq + PDC,q.
(6.21)
Let wp = [wp,1 wp,2 · · · wp,Nt]T as the precoding vector and hp = [hp,1 hp,2 · · · hp,Nt]T
www.ebook3000.com

182
as the channel gain vector for the pth user, after removing the DC component, the
received signal at the pth user can be written as
rp =
Nt

q=1
xqhp,q + zp = hT
pwpdp +

l̸=p
hT
pwldl + zp,
(6.22)
where the ﬁrst term hT
pwpdp denotes the desired signal for the pth user, while the
second term 
l̸=p hT
pwldl denotes the inter-user interference to the pth user, which
should be eliminated by precoding.
(6.22) can be rewritten in matrix form as
x = HWd + z,
(6.23)
where H = [h1 h2 · · · hNr]T and W = [w1 w2 · · · wNr] denote the correspond-
ing channel and precoding matrices.
When linear zero-forcing is used for precoding, the interference 
l̸=p hT
pwldl
from other users is eliminated completely, where we have [10]
HW = diag(λ),
(6.24)
where λp > 0, and the precoding matrix is calculated by
W = HT(HHT)−1diag(λ).
(6.25)
Zero-forcing (ZF) is a good precoding approach for high power or low noise sce-
narios. However, when the channel matrix is ill-conditioned, zero-forcing requires
a large normalization factor, which will dramatically reduce the received power [9].
Therefore, when the SNR is low at the receiver, zero-forcing cannot achieve a good
performance since noise instead of interference is the dominant impairment of the
system.
Linear minimum mean squared error (MMSE) precoding, with which the interfer-
ence at the receivers is not identically zero, however, can achieve a tradeoﬀbetween
interference and noise based on which one is the dominant part in the signal-to-
interference-plus-noise ratio (SINR) at the receivers. The MMSE precoding matrix
is given by [11]
W = HHHHH + diag
σ2
Z
−1diag (λ) ,
(6.26)
where σ2
Z denotes the variance vector of Z.
When more than one PD is located at each user, the ZF and MMSE schemes cannot
work well since the channels of PDs at one user are highly correlated and these PDs
could cooperate to decode the signal. Meanwhile, the number of LEDs is usually
assumed to be no less than the number of PDs to eliminate the inter-user interference
eﬀectively [10–13], which may not hold in some speciﬁc cases where the number of
activated LEDs are determined by the illumination requirements. Therefore, leakage-
based precoding is proposed in [14], which utilizes the criterion that maximizes the

183
Figure 6.9 Diagram of the MU-MIMO VLC transmitter.
signal-to-leakage-plus-noise ratio (SLNR) and does not have the restriction on the
number of LEDs and PDs.
At the ith user, 1 ≤i ≤Nr, Ki PDs are equipped to receive ki data streams. The
total number of receiving PDs is 
i
Ki = K, while the total number of data streams
is 
i
ki = k. Figure 6.9 illustrates the diagram of the MU-MIMO VLC transmitter,
and the corresponding transmitting vector is given by
r = Wd + p =
Nr

i=1
Widi + p,
(6.27)
where d = [d1
T d2
T · · · dNr
T]T is the real-valued source symbol vector with
di = [di,1 di,2 · · · di,ki]T denoting the ki data streams for the ith user. W =
[W1 W2 · · · WNr] is the precoding matrix, where Wi ∈RNt×ki is the precod-
ing matrix for the ith user and p is the Nt ×1 DC vector to ensure the non-negativity
of the modulated signals.
Since the source symbol vector d is zero-mean and independent of the precoding
matrix, the precoded signal vector is also zero-mean, and we have
E(Wd) = E(W)E(d) = 0.
(6.28)
Therefore, the expectation of the transmitted signal is equal to the DC bias, and the
average optical power emitted from the transmitter is proportional to the DC bias
determined by the illumination requirements.
Let Hi ∈RKi×Nt denote the channel matrix between the LEDs and the ith user,
www.ebook3000.com

184
which is given by
Hi =
⎡
⎢⎢⎣
hi,1,1 · · · hi,1,Nt
...
...
...
hi,Ki,1 · · · hi,Ki,Nt
⎤
⎥⎥⎦,
(6.29)
where hi,n,m represents the channel gain between the mth LED unit and the nth PD
of the ith user, and can be obtained by (6.1).
When direct detection is used at receivers, the received signal at the ith user can
be written as
ri = HiWd + Hip + zi = HiWidi +

j̸=i
HiWjdj + Hip + zi,
(6.30)
where the ﬁrst term is the desired signal, the second part is the inter-user interference,
the third term is the DC bias and the last part zi = [zi,1 zi,2 · · · zi,Ki]T is the ad-
ditive white Gaussian noise with the covariance of Ki = diag([σ2
i,1 σ2
i,2 · · · σ2
i,Ri]).
zi,n denotes the noise at the nth PD of the ith user with the variance of σ2
i,n, which is
given by (6.4). Since the PDs within one user are close and have similar parameters,
it is assumed that σ2
i,n = σ2
i,j = σ2
i , ∀n, j ∈[1, ..., Ki].
At the ith user, a linear decoder Gi is applied after DC removal to recover the
transmitted signal, and the decoded signal vector is given by
ˆdi = GiHiWidi + Gi

j̸=i
HiWjdj + Gizi.
(6.31)
For simplicity, the precoding can be split into two parts
W = Qdiag(a),
(6.32)
where Q = [Q1 Q2 · · · QNr] ∈RNt×k is used to cancel the interference with
Qi ∈RNt×ki denoting the interference elimination matrix for the ith user, while a
is the k × 1 power scaler vector to satisfy the optical power constraint. Speciﬁcally,
to ensure the non-negativity of the transmitted signal, we have
Wd ⩾−p.
(6.33)
The source symbol is assumed to be modulated by PAM with optical power nor-
malization that the constellation is bounded within [−1, 1]. Therefore, we have
−1 ⩽dn ⩽1, where dn is the nth element of the source symbol vector d. Conse-
quently, the optical power constraint can be written as
abs(W)1 ⩽p,
(6.34)
where abs(·) denotes the element-wise absolute operator and 1 is a k × 1 vector
whose elements are all unit.

185
Accordingly, the magnitude of the transmitted signal x is also bounded. The sim-
ple double-sided signal clipping distortion model is considered, where the signals
within the linear range are transferred linearly while the signals out of the linear
range are clipped [15]. By adjusting the boundary and limiting the signals within the
linear range, the clipping distortion can be avoided. Obviously, the power scalers are
positive and the optical power constraint can be rewritten as
abs(W)1 = abs(Q)a ≤p.
(6.35)
When ZF scheme is used in MU-MIMO systems, the matrix Qi is calculated as
Qi = FiVi,
(6.36)
where Fi is used to eliminate the inter-user interference and calculated as Fi =
I −:H†
i :Hi. I is the Nt-dimensional identity matrix, :Hi is deﬁned by :Hi =
[HT
1 · · · HT
i−1 HT
i+1 · · · HT
Nr]T, and :H†
i is the pseudo inverse of :Hi. Vi is used to
eliminate the intra-user interference further. HiFi can be rewritten as the singular
value decomposition (SVD) form that HiFi = UΛVT, where Vi is composed of
the ki columns of V that correspond to the ki largest singular values in Λ while the
decoder matrix Gi is composed of the corresponding ki rows of UT. It is easy to
verify that interference can be eliminated completely when the number of LEDs is
no less than the number of PDs.
ZF scheme imposes a constraint on the number of transmitters and receiving PDs in
order to cancel all inter-user interference. Moreover, the performance of ZF scheme
degrades when the channels of diﬀerent users are highly correlated, which occurs
frequently in VLC systems. Therefore, a leakage-based precoding method can be
applied to solve this problem. Instead of considering the interference at a speciﬁc user
that is caused by the data streams of other users, the leakage, which represents the
interference caused by a speciﬁc user to other users, is considered and the interference
elimination matrix is designed by maximizing the SLNR as in [16].
Maximizing SLNR under optical power constraint directly has high complexity,
and does not employ the feature of SLNR that only the ith user’s precoding matrix is
included in the expression of the ith user’s SLNR, since the optical power constraint
connects the precoding matrices together again. Therefore, the optical power con-
straint is placed on the design of power scaler and the constraint on the calculation
of matrix Q is not considered. As a result, the interference elimination matrix Qi
can be constituted by ki generalized eigenvectors of (HT
i Hi, ((Kiσ2
i )I + :HT
i :Hi))
and the elements of Qi satisfy the real-valued constraints naturally. According to the
property of generalized eigenvector, it can be shown that
QT
i HT
i HiQi = Λi,
(6.37)
and
QT
i ((Kiσ2
i )I + :HT
i :Hi)Qi = I.
(6.38)
At the ith receiver, decoder matrix is given by
Gi = ciWT
i HT
i ,
(6.39)
www.ebook3000.com

186
where ci is the normalization scaler ci =

1/Tr(WT
i HT
i HiWi). We can see that
intra-user interference is also eliminated. Thus, the decoded signal can be split into
ki separate data streams given by
ˆdi = GiHiWidi + Gi

j̸=i
HiWjdj+Gizi
= ciΛi(diag(ai))2di + Gi

j̸=i
HiWjdj+˜zi,
(6.40)
where ai is the ki × 1 power scaler for the ith user. The second part in (6.40) is the
interference after decoding. Unlike ZF scheme, the interference cannot be eliminated
completely since the noise is considered in the design of precoding and decoding
matrix. However, the interference is reduced greatly and the residual interference can
be ignored compared with the noise. :zi is the equivalent noise with the covariance
matrix of
:Ri = GiRiGT
i = σ2
i GiGT
i .
(6.41)
In [16], the power allocated on diﬀerent data streams is assumed to be equal. Under
this assumption, the power scaler a can be expressed as a = a1. According to the
optical power constraint, a can be calculated as
a = min
n
pn
(abs(Q)1)n
,
(6.42)
where vn denotes the nth element of an arbitrary vector v.
The inter-user interference elimination matrix Qi can suppress the multiuser in-
terference. Meanwhile, the multiple data streams for one user are also separated.
However, the performance of leakage-based precoding is limited if the diﬀerence be-
tween the diagonal elements of Λi in (6.40) is large. Since the PDs of one user are
close such that their channels are highly correlated, the diagonal elements of Λi can
be of great diﬀerence. Therefore, equal power allocation on diﬀerent data streams is
not a good option in this scenario and the optimal power allocation has to be consid-
ered to optimize the throughput of the system.
Since the source signal symbol di is modulated by PAM constellation, given the
BER constraint BERT, the achievable rate of the ith user can be calculated as [10]
ζi =
ri

n=1
log2(1 + η

SINRi,n),
(6.43)
where η =

(−log(5BERT))−1. The optimization problem to maximize the
throughput of the system can be written as
max
a
K

i=1
ri

n=1
log2(1 + η

SINRi,n)
subject to
abs(Q)a ⩽p,
a ⩾0.
(6.44)

187
Table 6.2 Simulation parameters for MU-MIMO VLC systems.
Room Size
5 m × 5 m × 3 m
Lambertian emission mode number m
1
PD responsibility ρi,n
0.4 A/W
PD area APD,i,n
1 cm2
Receiver FOV θc,i,n
62◦
Refractive index of optical concentrator qi,n
1.5
Pre-ampliﬁer noise density iamp
5 pA/Hz−1/2
Ambient light photocurrent χamb
10.93 A/m2/Sr
Bandwidth of receiver B
100 MHz
BER constraint BERT
10−3
For the leakage-based precoding, the inter-user interference can be ignored when
k ≤Nt. Therefore, the received signal is approximated as
ˆdi ≈c
(
Λi diag(ai)) di + :zi.
(6.45)
As a result, the optimization problem can be simply rewritten as
max
a
K

i=1
ri

n=1
log2(1 + η λi,nai,n
:σi,n
)
subject to
abs(Q)a ⩽p,
a ⩾0,
(6.46)
where :σ2
i,n = ;
Ri(n, n) is the nth diagonal element of ;
Ri. This is a convex optimal
problem and can be solved by CVX, a package for specifying and solving convex
problems [17]. It should be noted that (6.46) is suitable for both leakage-based pre-
coding and ZF precoding.
To verify the performance of leakage-based precoding combined with power al-
location, simulations are conducted with the parameters listed in Table 6.2 where
the optical device parameters are obtained from [1, 18]. Without loss of generali-
ty, all the transmitting LEDs and PDs are assumed to share identical conﬁgurations.
The system throughput as a function of the optical power constraint is considered.
As shown in (6.46), the system throughput is the sum of the achievable rates for all
users. The optical power constraints for diﬀerent LEDs are assumed the same and
denoted as p.
The locations of LEDs and PDs are listed in the Table 6.3 and Table 6.4, respec-
tively. Meanwhile, the spacing between diﬀerent PDs at one user is small and a value
of 0.1 m is adopted in the simulations [12]. To evaluate the performance of the pre-
coding schemes, four scenarios are discussed in the simulations. In scenario 1, the
locations of LEDs are listed in Table 6.3 and the PDs are located as Case 1 in Table
i
2
www.ebook3000.com

188
Table 6.3 Locations of LEDs.
LED 1 coordinate
[1.25 1.25 3]
LED 2 coordinate
[1.25 3.75 3]
LED 3 coordinate
[3.75 1.25 3]
LED 4 coordinate
[3.75 3.75 3]
Table 6.4 Locations of PDs.
Case 1
Case 2
PD 1 of User 1
[1.5 1.5 0.85]
[1.5 1.5 0.85]
PD 2 of User 1
[1.4 1.5 0.85]
[1.4 1.5 0.85]
PD 1 of User 2
[2.0 3.0 0.85]
[1.0 1.5 0.85]
PD 2 of User 2
[1.9 3.0 0.85]
[1.1 1.5 0.85]
6.4. Scenario 2 considers the situation that users are close to each other whose PDs
are located as Case 2 in Table 6.4 without changing the locations of LEDs. Scenarios
3 and 4 discuss the situation that the number of LEDs is less than the number of PDs.
Therefore, only LED 1 and LED 4 are activated in these two scenarios, while the
locations of PDs are the same as in scenario 1 and scenario 2, respectively.
Figure 6.10 shows that the optimal power allocation by maximizing the system
throughput outperforms the equal power allocation. As the channel correlation in-
creases, the performance gain of optimal power allocation also increases. Therefore,
only the optimal power allocation is adopted in the simulations afterwards.
When the number of LEDs is no less than that of PDs, Fig. 6.11 shows the compar-
ison of the leakage-based and ZF precoding schemes under scenario 1 and scenario
2. It is shown that when the two users are relatively far from each other (scenario
1), the advantage of leakage-based precoding is unobvious, which indicates that ZF
precoding scheme is suitable for this scenario since the channel correlation is not
that high. However, when the two users are close to each other (scenario 2), leakage-
based precoding outperforms ZF precoding signiﬁcantly. It is also shown that the
throughput of the system in scenario 2 diminishes since the elimination of the inter-
user interference is more diﬃcult when the two users are close to each other. How-
ever, leakage-based precoding could alleviate the performance loss compared to ZF
precoding in this scenario.
When the number of transmitters is less than that of receivers, Fig. 6.12 shows that
leakage-based precoding still performs well (scenario 3 and 4). On the contrary, ZF
precoding fails to cancel the interference completely when the number of transmitters
is less than that of receivers and the system throughput does not increase with the
average optical power.

189
−10
−5
0
5
10
0
5
10
15
20
25
30
 p (dBW)
System Throughput (bit/s/Hz)
Optimal PA, Scenario 1,  ri = 2
Optimal PA, Scenario 2,  ri = 2
Equal PA, Scenario 1,  ri = 2
Equal PA, Scenario 2,  ri = 2
Figure 6.10 System throughput comparison between equal power allocation and optimal
power allocation.
−10
−5
0
5
10
0
5
10
15
20
25
 p (dBW)
System Throughput (bit/s/Hz)
Leakage−Based Precoding, Scenario 1,  ri = 1
ZF Precoding, Scenario 1,  ri = 1
Leakage−Based Precoding, Scenario 2,  ri = 1
ZF Precoding, Scenario 2,  ri = 1
Figure 6.11 System throughput comparison when the number of LEDs is no less than that
of PDs.
www.ebook3000.com

190
Figure 6.12 System throughput comparison when the constraint about the number of
LEDs and PDs is not satisﬁed.
6.4
Optical MIMO-OFDM
The combination of MIMO and optical orthogonal frequency-division multiplexing
(OFDM) yields the MIMO-OFDM, which is a popular technique in RF systems to
support multiuser service and provide high-data-rate transmission [19, 20]. It can be
extended to the optical domain in VLC systems to improve the performance. In [21],
a MIMO-OFDM VLC system is demonstrated, but it requires an imaging diversity
receiver to distinguish signals from diﬀerent LEDs, which is infeasible for multiuser
scenarios.
In most studies on MU-MIMO VLC systems, single-carrier modulations are con-
sidered with limited bandwidth [10–12], which conduct precoding in the time do-
main and only the DC channel gain in (6.1) is considered. Since the distances of
the multiple transmitter–receiver links are diﬀerent, their temporal delays are var-
ied, resulting in complex channel gains and phase diﬀerences when transformed to
the frequency domain. Considering this phenomenon, the time-domain channel re-
sponse in (6.1) can be rewritten as [22, 23]
˜hp,q (t) = hp,qδ

t −dp,q
c

,
(6.47)
where δ(·) denotes the Dirac delta function and c is the speed of light. Correspond-
ingly, the frequency-domain channel response for the kth subcarrier is given by
˜Hp,q,k = hp,q exp

−j2πkBdp,q
Nc

,
(6.48)
−10
−5
0
5
10
0
5
10
15
20
25
 p (dBW)
System Throughput (bit/s/Hz)
Leakage−Based Precoding, Scenario 3,  ri = 1
ZF Precoding, Scenario 3,  ri = 1
Leakage−Based Precoding, Scenario 4,  ri = 1
ZF Precoding, Scenario 4,  ri = 1

191
Figure 6.13 MU-MIMO-OFDM VLC transmitter with Nr users, Nt LED units, and N
subcarriers.
where B is the system bandwidth and N is the size of fast Fourier transform (FFT).
j is the imaginary unit j = √−1. According to the expression, the phase of the
frequency-domain channel gain is proportional to the bandwidth. Moreover, when
the temporal delay is considered, the frequency-domain channel response is complex-
valued, which provides another dimension and reduces the channel correlation with
the phase diﬀerences of multiple links. When up to 100 Gbps high data rate is re-
quired in future VLC networks, wide bandwidth optical components are used [24–
26], the phase in the complex channel gain cannot be neglected. Therefore, MU-
MIMO-OFDM scheme is proposed for VLC system and precoding is conducted on
diﬀerent subcarriers individually [22, 23].
For the pth user, the information bit stream is ﬁrstly mapped onto the complex-
valued symbols Dp,k, k = 0, 1, · · · , N −1. Since intensity modulation requires
real-valued output, Hermitian symmetry should be imposed on the OFDM subcarri-
ers where Dp,k = D∗
p,N−k, k = 1, 2, · · · , N/2 −1, and the subcarriers Dp,0 and
Dp,N/2 are set to zero.
The diagram of the MU-MIMO-OFDM VLC system is illustrated in Fig. 6.13. At
the transmitter of MU-MIMO-OFDM VLC system, precoding is performed on each
subcarrier to eliminate multiuser interference. Let {Wp,q,k, 1 ≤p ≤Nr, 1 ≤q ≤Nt}
denote the precoding weights for the kth (k = 0, 1, · · · , N −1) subcarrier. By
adding up all the weighted symbols from Nr users at the qth LED unit, the frequency-
domain signal can be written as
Xq,k =
Nr

p=1
Wp,q,kDp,k, k = 0, 1, · · · , N −1,
(6.49)
which is also complex-valued.
Afterwards, the frequency-domain signals for the qth LED unit are converted to
www.ebook3000.com

192
the time domain by inverse fast Fourier transform (IFFT) as
xq,n =
1
√
N
N−1

k=0
Xq,n exp

j 2π
N nk

, n = 0, 1, · · · , N −1,
(6.50)
which are real-valued since the symbols on diﬀerent subcarriers satisfy the Hermitian
symmetry. Since xq,n may be negative, a DC bias PDC,q is added to the qth trans-
mitter in DC-biased optical OFDM (DCO-OFDM) to obtain nonnegative signals for
emission.
At the receiver of the pth user, FFT is performed on the received signals to generate
frequency-domain symbols given by
Rp,k =
Nt

q=1
˜Hp,q,kXq,k + Zp,k
= ˜HT
p,kWp,kDp,k +
Nt

l̸=p
˜HT
l,kWl,kDl,k + Zp,k, k = 0, 1, · · · , N −1,
(6.51)
where ˜Hp,k, ˜Hl,k, Wp,k, and Wl,k are Nt × 1 vectors of channel gains and pre-
coding weights for the kth subcarrier, Zp,k denotes the equivalent noise on the kth
subcarrier. The ﬁrst term ˜HT
p,kWp,kDp,k in (6.51) denotes the desired signal for
the pth user, while the second term
Nt

l̸=p
˜HT
l,kWl,kDl,k is the inter-user interference
to the pth user, which should be eliminated by precoding.
(6.51) can be rewritten in the matrix form when all the Nr users are considered,
which is given by
Rk = ˜HkWkDk + Zk, k = 0, 1, · · · , N −1,
(6.52)
where Dk = [D1,k D2,k · · · DNr,k]T and Rk = [R1,k R2,k · · · RNr,k]T de-
note the transmitted and received symbol vectors on the kth subcarrier, ˜Hk =
,
˜H1,k ˜H2,k · · · ˜HNr,k
-T
and Wk = [W1,k W2,k · · · WNr,k] represent the
corresponding channel and precoding matrices, and Zk is the noise vector on the
kth subcarrier. For diﬀerent subcarriers, the channel matrices are diﬀerent due to
temporal delays, thus their corresponding precoding matrices should be calculated
separately. Several precoding schemes have been proposed for MU-MIMO in RF
systems [8, 9]. Here, two well-known techniques are employed to eliminate the
inter-user interference, namely, ZF and MMSE algorithms.
ZF is a simple method to eliminate the inter-user interference by directly forcing
the interference terms to be zeros, i.e., the matrix HkWk is diagonal as [8]
HkWk = diag (λk) ,
(6.53)
where all the entries in λk are positive and the precoding matrix is given by
Wk = ˜H†
kdiag (λk) = ˜HH
k

˜Hk ˜HH
k
−1
diag (λk) .
(6.54)

193
In linear MMSE precoding, the interference at the receiver is not completely re-
moved, while a tradeoﬀbetween interference and noise is achieved based on which
one is the dominant part in the SINR at the receiver. The MMSE-based precoding
matrix is calculated as [9]
Wk = ˜HH
k

˜Hk ˜HH
k + diag
σ2
Zk
−1
diag (λk) ,
(6.55)
where σ2
Zk denotes the variance vector of Zk.
6.4.1
DCO-OFDM-based MU-MIMO VLC
According to the central limit theorem, xq,n approximates a Gaussian distribution
when N ≥64, which might have a very large absolute value [27]. Therefore, a
DC bias cannot necessarily guarantee the non-negativity for all the signals and some
signals should be clipped. The DC bias for the qth transmitter can be represented
as [28]
¯PDC,q = η

E
)x2q,n
*,
(6.56)
where η denotes the DC bias ratio. When a larger DC bias is used, less signals are
clipped, leading to smaller clipping distortion. However, DC bias does not carry
useful information, hence it is ineﬃcient in terms of power. A tradeoﬀshould be
made between the DC bias and clipping distortion, here we set the minimum DC
bias ratio to η0 [28].
Due to the precoding matrix, the electric power of the Nt transmitters is diﬀerent,
which requires diﬀerent minimum DC bias. For the qth LED unit, the DC bias is
¯PDC,q = η0

E
)x2q,n
*, q = 0, 1, · · · , Nt −1,
(6.57)
and this scheme is named as the minimum DC bias scheme. Correspondingly, the
emitted optical power of the qth LED unit is given by
Popt,q = E
)xq,n + ¯PDC,q
* = E {xq,n} + ¯PDC,q = ¯PDC,q,
(6.58)
where the equality holds since the expectation of xq,n is zero according to (6.50).
When the average optical power of all the LED units is constrained to P for illu-
mination requirement, the biased signal should be scaled and the transmitted signal
for the qth LED unit is written as
yq,n = α
xq,n + ¯PDC,q
 ,
(6.59)
where the scaling factor can be calculated as
α =
NtP
Nt

q=1
PDC,q
=
NtP
η0
Nt

q=1

E
)x2q,n
*.
(6.60)
www.ebook3000.com

194
Therefore, the actual DC bias for the qth LED unit is given by
PDC,q = α ¯PDC,q =

E
)x2q,n
*NtP
Nt

q=1

E
)x2q,n
* , q = 0, 1, · · · , Nt −1.
(6.61)
It is shown in (6.61) that the emitted optical power varies for the Nt LED units
and it also changes with the topology of users, which is not suitable for the illumina-
tion function of LEDs. To maintain data transmission and high quality illumination
simultaneously, the uniﬁed DC bias scheme is considered, where the same DC bias
is applied to all the LED units as
PDC,q = P.
(6.62)
When all the Nt transmitters are considered, the DC bias should make sure the clip-
ping distortion of the transmitter with maximum electric power is acceptable. There-
fore, the scaling factor is calculated as
α =
P
η0

max
1⩽q⩽Nt
E
)x2q,n
*.
(6.63)
The uniﬁed DC bias scheme improves the illumination performance at the cost of
energy eﬃciency since larger DC biases are imposed on most of the LED units.
6.4.2
ACO-OFDM-based MU-MIMO VLC
Since DCO-OFDM requires a high DC bias, asymmetrically clipped optical OFDM
(ACO-OFDM) can be used to improve the energy eﬃciency. In ACO-OFDM, the
even subcarriers are set to zero, while the symbols are only transmitted by the odd
subcarriers [29]. After IFFT, the time-domain signals of ACO-OFDM are antisym-
metric, where
xq,n = −xq,n+N/2, n = 0, 1, · · · , N/2 −1,
(6.64)
which can be clipped at zero without information loss. At the receiver, the symbols
on the odd subcarriers can be directly detected by FFT since the clipping distortion
only falls on the even subcarriers. However, scaling is still required to fulﬁll the
illumination requirement of P. Since xq,n follows a Gaussian distribution when
N ≥64, the optical power of the clipped ACO-OFDM signals x(c)
q,n can be given
by [28]
Popt,q = E

x(c)
q,n

=

E
)x2q,n
*/2π,
(6.65)

195
and the scaling factor for the qth LED unit is calculated by
α =
NtP
Nt

q=1
Popt,q
=
NtP
Nt

q=1

E
)x2q,n
* /2π
.
(6.66)
When the same optical power is given, ACO-OFDM-based scheme can use higher-
order constellations to improve the spectral eﬃciency since DC bias is not required.
However, only the odd subcarriers are employed in ACO-OFDM, leading to the loss
of spectral eﬃciency by half when the same constellation orders are used. Therefore,
ACO-OFDM is not always better than DCO-OFDM especially when high spectral
eﬃciency is required.
6.4.3
Performance evaluation
In the simulations, four LED units and two users are assumed in one room, while the
other parameters are listed in Table 6.5. The performance of the MU-MIMO-OFDM
VLC is validated in terms of the aggregate achievable spectral eﬃciency, which is
calculated with all the SINRs at the receiver by
Nr

p=1
log2 (1 + SINRp). Two cases of
users’ locations are considered. In Case 1, User 1 is in the middle of the room with
the coordinate of [2.5 2.5 0.85], while the coordinate of User 2 is [3.2 3.9 0.85]. The
channel matrices for Case 1 are in good conditions since the two users are not close.
In Case 2, the two users’ coordinates are [2.05 1.6 0.85] and [2.05 1.4 0.85], which
are very close and their corresponding channel matrix is ill-conditioned. The mini-
mum DC bias factor η0 is set to 3 to achieve a tradeoﬀbetween clipping distortion
and eﬀective power.
Figure 6.14 depicts the average spectral eﬃciency with diﬀerent average emitted
optical power, where DCO-OFDM is utilized with minimum DC bias and uniﬁed
DC bias according to Section 6.4.1. It can be seen that MMSE achieves higher spec-
tral eﬃciency when the optical power is low and the noise is the dominant part of
interference-plus-noise. Moreover, higher performance gain is observed in Case 2
since the channel matrices are more ill-conditioned. Besides, the system with mini-
mum DC bias according to (6.57) and (6.60) outperforms that with uniﬁed DC bias
according to (6.61) and (6.62) since more power are used for data transmission. How-
ever, the latter provides better illumination performance.
Figure 6.15 provides the performance comparison of ACO-OFDM-based and
DCO-OFDM-based schemes, where zero-forcing precoding is employed and the
minimum DC bias scheme is used after precoding for DCO-OFDM-based system.
It is shown that ACO-OFDM-based schemes achieve higher spectral eﬃciency than
DCO-OFDM-based schemes when the emitted optical power is low. However, when
larger optical power is employed and the achievable spectral eﬃciency is above 6
bit/s/Hz, the performance of DCO-OFDM-based scheme is better, which is consis-
tent with the previous analysis.
www.ebook3000.com

196
Table 6.5 Simulation parameters for MU-MIMO-OFDM VLC system conﬁguration.
Room Size (length × width × height)
5 m × 5 m × 3 m
LED 1 coordinate
[1.25 1.25 3]
LED 2 coordinate
[1.25 3.75 3]
LED 3 coordinate
[3.75 1.25 3]
LED 4 coordinate
[3.75 3.75 3]
LED emission angle φq
60◦
PD area APD,p
1 cm2
PD responsivity coeﬃcient ρp
0.4 A/W
PD concentrator refractive index γ
1.5
Lambertian emission mode number m
1
Receiver FOV angle Ψc,p
62◦
Pre-ampliﬁer noise density iamp
5 pA/Hz−1/2
Ambient light photocurrent χamb
10.93 A/m2/Sr
System bandwidth B
1 GHz
OFDM subcarrier number N
64
Cyclic preﬁx length NCP
3
−10
−5
0
5
10
0
2
4
6
8
10
12
14
 P (dBW)
Achievable Spectral Efficiency (bit/s/Hz)
Case1, ZF, Minimum DC Bias
Case1, ZF, Unified DC Bias
Case1, MMSE, Minimum DC Bias
Case1, MMSE, Unified DC Bias
Case2, ZF, Minimum DC Bias
Case2, ZF, Unified DC Bias
Case2, MMSE, Minimum DC Bias
Case2, MMSE, Unified DC Bias
Figure 6.14 Average spectral eﬃciency of DCO-OFDM-based MU-MIMO VLC system
with diﬀerent average emitted optical power and DC bias.

197
Figure 6.15 Average spectral eﬃciency comparison of ACO-OFDM-based and
DCO-OFDM-based MU-MIMO VLC systems with diﬀerent average emitted optical power.
6.5
Conclusion
In this chapter, imaging and non-imaging optical MIMO techniques have been intro-
duced for VLC systems. In non-imaging MIMO systems, each receiver collects light
with its own optical concentrator, and optical MIMO, OSM, and OSSK can be used
to boost the data rate. For imaging MIMO systems, an imaging diversity receiver
is utilized to distinguish the light from diﬀerent transmitters. Meanwhile, in order
to support data transmission for multiple users simultaneously, precoding techniques
are employed to eliminate the inter-user interference, which consider the lighting
constraints in VLC systems. Finally, MIMO-OFDM is discussed for single-user and
multiuser VLC systems, which combines the MIMO with OFDM to provide high
spectral eﬃciency and robust transmission.
−10
−5
0
5
10
0
2
4
6
8
10
12
14
 P (dBW)
Achievable Spectral Efficiency (bit/s/Hz)
Case1, ZF, Minimum DC Bias
Case1, ZF, ACO−OFDM
Case2, ZF, Minimum DC Bias
Case2, ZF, ACO−OFDM
www.ebook3000.com


199
References
1 L. Zeng, D. O’Brien, H. Minh, G. Faulkner,
K. Lee, D. Jung, Y. J. Oh, and E. T. Won,
“High data rate multiple input multiple
output (MIMO) optical wireless
communications using white LED lighting,”
IEEE J. Sel. Areas Commun., vol. 27, no. 9,
pp. 1654–1662, Dec. 2009.
2 T. Fath and H. Haas, “Performance
comparison of MIMO techniques for optical
wireless communications in indoor
environments,” IEEE Trans. Commun.,
vol. 61, no. 2, pp. 733–742, Feb. 2013.
3 L. Zheng and D. N. C. Tse, “Diversity and
multiplexing: A fundamental tradeoﬀin
multiple-antenna channels,” IEEE Trans. Inf.
Theory, vol. 49, no. 5, pp. 1073–1096, May
2003.
4 R. Y. Mesleh, H. Haas„ S. Sinanovic,
C. W. Ahn, and S. Yun, “Spatial
modulation,” IEEE Trans. Veh. Technol.,
vol. 57, no. 7, pp. 2228–2241, Jul. 2008.
5 R. Mesleh, R. Mehmood, H. Elgala, and
H. Haas, “Indoor MIMO optical wireless
communication using spatial modulation,” in
Proc. IEEE International Conference on
Communications (ICC) 2010 (Cape Town,
South Africa), May 23–27, 2010, pp. 1–5.
6 R. Mesleh, H. Elgala, and H. Haas, “Optical
spatial modulation,” J. Opt. Commun. Netw.,
vol. 3, no. 3, pp. 234–244, Mar. 2011.
7 N. Ishikawa and S. Sugiura, “Maximizing
constrained capacity of power-imbalanced
optical wireless MIMO communications
using spatial modulation,” J. Lightw.
Technol., vol. 33, no. 2, pp. 519–527, Jan.
2015.
8 Q. H. Spencer, A. L. Swindlehurst, and
M. Haardt, “Zero-forcing methods for
downlink spatial multiplexing in multiuser
MIMO channels,” IEEE Trans. Signal
Process., vol. 52, no. 2, pp. 461–471, Feb.
2004.
9 Q. H. Spencer, C. B. Peel,
A. L. Swindlehurs, and M. Haardt, “An
introduction to the multi-user MIMO
downlink,” IEEE Commun. Mag., vol. 42,
no. 10, pp. 60–67, Oct. 2004.
10 Z. Yu, R. J. Baxley, and G. T. Zhou,
“Multi-user MISO broadcasting for indoor
visible light communication,” in Proc. IEEE
International Conference on Acoustics,
Speech and Signal Processing (ICASSP)
2013 (Vancouver, Canada), May 26–31,
2013, pp. 4849–4853.
11 H. Ma, L. Lampe, and S. Hranilovic,
“Robust MMSE linear precoding for visible
light communication broadcasting systems,”
in Proc. IEEE Global Communications
Conference (GLOBECOM) Workshops 2013
(Atlanta, GA), Dec. 9–13, 2013, pp.
1081–1086.
12 Y. Hong, J. Chen, Z. Wang, and C. Yu,
“Performance of a precoding MIMO system
for decentralized multiuser indoor visible
light communications,” IEEE Photon. J.,
vol. 5, no. 4, p. 7800211, Aug. 2013.
13 B. Li, J. Wang, R. Zhang, S. Hong,
C. Zhao, and L. Hanzo, “Multiuser MISO
transceiver design for indoor downlink
visible light communication under per-LED
optical power constraints,” IEEE Photon. J.,
vol. 7, no. 4, p. 7201415, Aug. 2015.
14 J. Chen, Q. Wang, and Z. Wang,
“Leakage-based precoding for MU-MIMO
VLC systems under optical power
constraint,” Opt. Commun., vol. 382,
pp. 348–353, Jan. 2017.
15 H. Elgala, R. Mesleh, and H. Haas, “An
www.ebook3000.com

200
LED model for intensity-modulated optical
communication systems,” IEEE Photon.
Technol. Lett., vol. 22, no. 11, pp. 835–837,
Jun. 2010.
16 M. Sadek, A. Tarighat, and A. H. Sayed, “A
leakage-based precoding scheme for
downlink multi-user MIMO channels,“ IEEE
Trans. Wirel. Commun., vol. 6, no. 5, pp.
1711–1721, May 2007.
17 Inc. CVX Research, “CVX: Matlab
software for disciplined convex
programming, version 2.0 beta,“ Sep. 2012.
18 Y. Wang and N. Chi, Demonstration of
high-speed 2 × 2 non-imaging MIMO
Nyquist single carrier visible light
communications with frequency domain
equalization, J. Lightw. Technol., vol. 32,
no. 11, pp. 2087–2093, Jun. 2014.
19 G. L. Stuber, J. R. Barry, S. W. Mclaughlin,
Y. Li, M. A. Ingram, and T. G. Pratt,
“Broadband MIMO-OFDM wireless
communications,” Proc. IEEE, vol. 92,
no. 2, pp. 271–294, Feb. 2004.
20 M. Jiang and L. Hanzo, “Multiuser
MIMO-OFDM for next-generation wireless
systems,” Proc. IEEE, vol. 95, no. 7,
pp. 1430–1469, Jul. 2007.
21 A. H. Azhar, T. Tran, and D. O’Brien, “A
gigabit/s indoor wireless transmission using
MIMO-OFDM visible-light
communications,” IEEE Photon. Technol.
Lett., vol. 25, no. 2, pp. 171–174, Jan. 2013.
22 Q. Wang, Z. Wang, C. Qian, J. Quan, and
L. Dai, “Multi-user MIMO-OFDM for
indoor visible light communication
systems,” in Proc. IEEE Global Conference
on Signal and Information Processing
(GlobalSIP) 2015 (Orlando, FL), Dec.
14–16, 2015, pp. 1170–1174.
23 Q. Wang, Z. Wang, and L. Dai, “Multiuser
MIMO-OFDM for visible light
communications,” IEEE Photon. J., vol. 7,
no. 6, p. 7904911, Dec. 2015.
24 A. C. Boucouvalas, K. Yiannopoulos and
Z. Ghassemlooy, “100 Gbit/s optical
wireless communication system link
throughput,” Electron. Lett., vol. 50, no. 17,
pp. 1220–1222, Aug. 2014.
25 D. Tsonev, S. Videv, and H. Haas,
“Towards a 100 Gb/s visible light wireless
access network,” Opt. Exp., vol. 23, no. 2,
pp. 1627–1637, Jan. 2015.
26 A. Gomez, K. Shi, C. Quintana, M. Sato,
G. Faulkner, B. C. Thomsen, D. O’Brien,
“Beyond 100-Gb/s indoor wide ﬁeld-of-view
optical wireless communications,” IEEE
Photon. Technol. Lett., vol. 27, no. 4,
pp. 367–370, Feb. 2015.
27 Q. Wang, Z. Wang, and L. Dai, “Iterative
receiver for hybrid asymmetrically clipped
optical OFDM,” J. Lightw. Technol., vol. 32,
no. 22, pp. 3869–3875, Nov. 2014.
28 S. D. Dissanayake and J. Armstrong,
“Comparison of ACO-OFDM, DCO-OFDM
and ADO-OFDM in IM/DD systems,” J.
Lightw. Technol., vol. 31, no. 7,
pp. 1063–1072, Apr. 2013.
29 J. Armstrong and A. J. Lowery, “Power
eﬃcient optical OFDM,” Electron. Lett.,
vol. 42, no. 6, pp. 370–372, Mar. 2006.

201
7
Signal Processing and Optimization
In this chapter, we address several signal processing and optimization issues for vis-
ible light communications (VLCs). For multi-chip-based multi-input single-output
VLC systems, an electrical and optical power allocation scheme is introduced in Sec-
tion 7.1 to maximize the multiuser sum-rate in consideration of the luminance, chro-
maticity, amplitude, and bit error rate constraints. From the perspective of human
color vision, the chromaticity constraint is deﬁned within a MacAdam ellipse. As a
result, the degree of freedom can be achieved by relaxing the chromaticity constraint
from a ﬁxed color point to an elliptic region.
Heterogeneous VLC and wireless ﬁdelity (VLC-WiFi) systems oﬀer a solution for
future indoor communications that combines VLC to support high-data-rate trans-
mission and radio frequency (RF) to support reliable connectivity. In such heteroge-
neous systems, vertical handover (VHO) is critical for improving the system perfor-
mance. In Section 7.2, the VHO is formulated as a Markov decision process (MDP)
problem and a dynamic approach is adopted to obtain a tradeoﬀbetween the switch-
ing cost and the delay requirement.
In VLC systems with narrow ﬁeld of view (FOV), the photodiode (PD) shot noise
modeled by Poisson statistics is signal-dependent since it originates from the quan-
tum nature of the received optical energy rather than any external sources of noise,
which changes the nature of eﬃcient signaling problem from that of the convention-
al signal-independent additive white Gaussian noise (AWGN) model in RF systems.
Complex modiﬁcations should be made to the signal processing and estimation tech-
niques to maintain the transmission performance, which is introduced in Section 7.3.
7.1
Sum-rate maximization for the multi-chip-based VLC system
In VLC systems, white light emitting diodes (LEDs) are used as illumination sources
and transmitters simultaneously. Compared to the phosphor-converted LEDs, multi-
chip LEDs have higher modulation bandwidth. Since each chip of the multi-chip
LEDs can be modulated independently, parallel communication channels are vi-
able for information transmission. Therefore, multi-chip-based VLC systems have
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.
www.ebook3000.com

202
Figure 7.1 Block diagram of the multi-chip LED-based VLC system.
great potential for high-data-rate transmission. In this section, a multi-chip LED-
based VLC system is introduced, where multiple independent parallel information
bit streams are modulated onto the monochromatic light emitted by the LED chips.
As brightness and chromaticity are the objective quality speciﬁcations of the color
perceived by human eyes, luminance as well as chromaticity requirements should be
satisﬁed in the design of the multi-chip-based VLC system. Speciﬁcally, chromatici-
ty variation within MacAdam ellipse is considered since human eyes could not notice
the small diﬀerence between two diﬀerent colors in the MacAdam ellipse [1], which
would be detailed in Section. 7.1.2.
7.1.1
System model
A multi-chip LED-based VLC system is shown in Fig. 7.1, where a multi-chip LED
with Nt chips is used as the transmitter array. At the access point, each LED chip
emits one monochromatic light and serves a single user. For diﬀerent users, the
user-speciﬁc optical ﬁlters and PDs are employed to concentrate their corresponding
monochromatic light. For each link, pulse amplitude modulation (PAM) is employed
to modulate the information bits due to its high spectral eﬃciency and low peak-to-
average power ratio (PAPR).
For each transmitting chain i (i = 1, 2, · · · , Nt), the modulated signal di has zero
mean and is normalized within [−1, 1]. To combat the nonlinearity of LEDs, time-
domain predistortion is employed at the transmitter [2]. Moreover, ampliﬁers are
used to fully exploit the dynamic range of LEDs and thus the electric signal power
can be increased, where we denote the ampliﬁcation coeﬃcient as γi for transmit-
ting chain i. Since intensity-modulated direct-detection (IM/DD) is adopted in VLC
systems, a direct current (DC) bias dDC,i is employed with the bias-tee circuits, and
the resultant electric signal is given by
si = γidi + dDC,i,
i = 1, 2, · · · , Nt.
(7.1)
At the jth receiver, the received signal rj can be expressed as
rj = hijsi + wj,
(7.2)

203
where hij is the channel gain and wj ∼N(0, σ2) is the Gaussian noise.
7.1.2
Constraints on illumination and communication
In VLC, since illumination and communication should be maintained simultaneous-
ly, several constraints should be considered. For illumination, luminance and chro-
maticity constraints are imposed, while signal amplitude and bit error rate (BER)
constraints are important for data communication. In the following, the various con-
straints are discussed.
1) Luminance constraint
When Nt chips are utilized for data transmission in multi-chip LEDs, indoor users
should not perceive the luminance variation of the white light. That is
1Tφ =
Nt

i=1
φi = Pt,
(7.3)
where Pt is the total luminous ﬂux of the multi-chip LED.
Since the light intensity perceived by human eyes is determined by the average
luminous ﬂux, the average luminous ﬂux instead of instantaneous luminous ﬂux is
optimized to improve the system performance. Besides, the optimization of the in-
stantaneous luminous ﬂux requires the knowledge of the DC bias for each signal at
the receiver, which is impractical for implementation.
2) Chromaticity constraint
For the ith chip of the multi-chip LED, assuming the luminous ﬂux emitted is Φi
and the chromaticity coordinates of the emitted monochromatic light are (xi, yi).
Based on Grassmann’s laws of additive color mixture, the chromaticity coordinates
of the mixed white light can be calculated by [3]
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
ˆx = aTΦ
bTΦ =
Nt
i=1
xi
yi Φi
Nt
i=1
1
yi Φi
,
ˆy = 1TΦ
bTΦ =
Nt
i=1 Φi
Nt
i=1
1
yi Φi
,
(7.4)
where Φ = [Φ1 Φ2 · · · ΦNt]T is the luminous ﬂux vector, a = [ x1
y1
x2
y2 · · · xNt
yNt ]T
and b = [ 1
y1
1
y2 · · ·
1
yNt ]T are the coeﬃcient vectors.
As human eyes have certain limitation on color discrimination, quantifying chro-
maticity diﬀerence is subjective. MacAdam ellipse is used as a statistical measure-
ment tool to describe the small chromaticity diﬀerence between two colors in the
chromaticity diagram at the same luminance [1]. When two colors are located in-
side the same MacAdam ellipse, average human observers could not discern the col-
or diﬀerence. The original ellipse in MacAdam’s experiment is named as one-step
MacAdam ellipse. In practice, larger ξ-step (ξ > 1) MacAdam ellipses are usually
www.ebook3000.com

204
Figure 7.2 MacAdam ellipses in CIE 1931 color space chromaticity diagram with 10 times
the actual size in MacAdam’s experiment.
used, where the lengths of its major and minor axes are ξ times the lengths of the orig-
inal ellipse’s major and minor axes in MacAdam’s experiment. As shown in Fig. 7.2,
there are twenty-ﬁve 10-step MacAdam ellipses with diﬀerent center points in the
chromaticity diagram, which are 10 times the size of the 1-step MacAdam ellipses
to make them observed clearly. Each of them varies in size and orientation. It can be
observed that the blue region is much smaller than the green region. This is because
human eyes have diﬀerent sensitivities to diﬀerent colors. The ξ-step MacAdam el-
lipse can be expressed as
g11dx2 + 2g12dxdy + g22dy2 = ξ2,
(7.5)
where g11, g12, and g22 are constant coeﬃcients to describe the orientation and size
of each ellipse; dx and dy are the diﬀerences of x and y coordinates between the
color points on the ellipse and the center point of the ellipse.
Therefore, if the chromaticity coordinate of the white light moves within the
MacAdam ellipse, small chromaticity change can be tolerated in practical VLC
systems. Based on (7.4) and (7.5), the chromaticity constraint can be expressed as
g11(aTφ
bTφ −x0)2 + 2g12(aTφ
bTφ −x0)(1Tφ
bTφ −y0)
+g22(1Tφ
bTφ −y0)2 ⩽ξ2,
(7.6)

205
where x0 and y0 are the chromaticity coordinates of the center point inside the
MacAdam ellipse.
3) Amplitude constraint
In VLC systems, the electric signal should be nonnegative, i.e., si ⩾0. Therefore,
the signals should satisfy γi ⩽dDC,i = ciφi, where ci is the constant coeﬃcient
to convert the luminous ﬂux to the forward current. Moreover, since LEDs have a
maximum forward current, the electric signal exceeding the maximum permissible
amplitude Ai suﬀers from clipping distortion. As a result, the maximum amplitude
constraint needs to be considered as well (i.e., si ⩽Ai), and we have γi ⩽Ai −
dDC,i = Ai −ciφi. Therefore, the amplitude constraint can be summarized as
0 ⩽γi ⩽min(Ai −ciφi, ciφi),
i = 1, · · · , Nt.
(7.7)
4) BER constraint
For the communication function, low BER at the receiver is required. For the ith
user, we have BERi ⩽BERt, where BERt denotes the BER threshold to ensure the
quality of service (QoS).
7.1.3
Sum-rate maximization
In the following, a typical point-to-point transmission scheme for the multi-chip
LED-based VLC system is investigated, where the transmitter employs all its Nt col-
ors (i.e., Nt parallel channels) to send the signals to the Nt receivers with individual
optical ﬁlters (i.e., Nr = Nt ). Moreover, an electric and optical power allocation
scheme is employed to maximize the sum-rate for all users under the aforementioned
constraints. With the constraint of BER (i.e., BERi ⩽BERt), the achievable data
rate for the ith user can be given by [4, 5]
υi = log(1 + ρhiγi
σi
),
i = 1, · · · , Nt,
(7.8)
where ρ =

(−log(5BERt))−1.
Afterwards, the sum-rate maximization problem in terms of the ampliﬁcation co-
eﬃcient γi and luminous ﬂux φi can be formulated as
P1 : max
φ,γ
Nt

i=1
log(1 + ρhiγi
σi
)
s.t.
g11(aTφ
bTφ −x0)2 + 2g12(aTφ
bTφ −x0)(1Tφ
bTφ −y0)
+ g22(1Tφ
bTφ −y0)2 ⩽ξ2,
0 ⪯γ ⪯min(A −c ◦φ, c ◦φ),
φ ⪰0,
1Tφ = Pt,
(7.9)
www.ebook3000.com

206
where γ = [γ1 γ2 · · · γNt] is the ampliﬁcation coeﬃcient vector, A = [A1 A2 · · · ANt]
is the maximum amplitude vector, and c = [c1 c2 · · · cNt] is the luminous ﬂux–
forward current conversion coeﬃcient vector. The notation ⪯denotes the general-
ized inequality, and the notation ◦denotes Hadamard product

i.e., for two matrices
E and F, (E ◦F)ij = Eij ∗Fij

.
Since the compound function of the ﬁrst inequality constraint in the optimization
problem P1 is non-convex, P1 should be cast into a convex problem in order to
ﬁnd a global optimization solution. First, polar coordinates are used to transform the
rotated MacAdam ellipse expressed by (7.5) to the ellipse with a standard form given
by
p2
α2 + q2
β2 = ξ2,
(7.10)
where α is the length of the semi-major axis and β is the length of the semi-minor
axis. From (7.5), α and β can be given by [6]
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
α =

2
(g11 + g22) −

(g11 −g22)2 + 4g2
12
,
β =

2
(g11 + g22) +

(g11 −g22)2 + 4g2
12
.
(7.11)
Then, the chromaticity point (p, q) on the standard ellipse can be written as

p = ¯x cos θ + ¯y sin θ,
q = −¯x sin θ + ¯y cos θ,
(7.12)
where we have ¯x = aTφ
bTφ −x0, ¯y = 1Tφ
bTφ −y0, and the rotated angle is donated as
θ, given by
θ =
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
0,
for g12 = 0 and g11 < g22;
π
2 ,
for g12 = 0 and g11 > g22;
1
2 cot−1 
g11−g22
2g12

,
for g12 ̸= 0 and g11 < g22;
π
2 + 1
2 cot−1 
g11−g22
2g12

,
for g12 ̸= 0 and g11 > g22.
(7.13)
Correspondingly, the ﬁrst constraint in P1 is equivalent to the following expres-
sions
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
p2
α2 + q2
β2 ⩽ξ2,
p = (aTφ
bTφ −x0) cos θ + (1Tφ
bTφ −y0) sin θ,
q = (1Tφ
bTφ −y0) cos θ −(aTφ
bTφ −x0) sin θ.
(7.14)

207
Moreover, due to the monotonicity of logarithmic function, the objective function
is equivalent to
det(I + diag(κ ◦γ)) =
Nt

i=1
(1 + ρhiγi
σi
),
(7.15)
where κ = [ ρh1
σ1
ρh2
σ2 · · · ρhNt
σNt ]. det(·) denotes the determinant of a matrix, and
diag(·) is a diagonal matrix.
Therefore, the optimization problem P1 can be reformulated as
P2 : max
φ,γ det(I + diag(κ ◦γ))
s.t.
p2
α2 + q2
β2 ⩽ξ2,
0 ⪯γ ⪯min(A −c ◦φ, c ◦φ),
φ ⪰0,
p = (aTφ
bTφ −x0) cos θ + (1Tφ
bTφ −y0) sin θ,
q = (1Tφ
bTφ −y0) cos θ −(aTφ
bTφ −x0) sin θ,
1Tφ = Pt.
(7.16)
Since the fourth and ﬁfth constraints (i.e., the two equality constraints involving
p, q, and φ) in P2 are not aﬃne or linear, two intermediate variables m = p
αbTφ
and n =
q
β bTφ are introduced, and the sum-rate maximization problem can be
transformed into [7]
P3 : max
φ,γ det(I + diag(κ ◦γ))
s.t.
m2 + n2 ⩽(ξbTφ)2,
0 ⪯γ ⪯min(A −c ◦φ, c ◦φ),
φ ⪰0,
m = 1
α[(aT −x0bT) cos θ + (1T −y0bT) sin θ]φ,
n = 1
β [(1T −y0bT) cos θ −(aT −x0bT) sin θ]φ,
1Tφ = Pt.
(7.17)
Given a real-valued slack variable t, the ﬁrst inequality constraint in P3 is equiv-
alent to

m2 + n2 ⩽t2,
0 ⩽t ⩽ξbTφ.
(7.18)
www.ebook3000.com

208
In (7.18), the ﬁrst inequality deﬁnes a second order or Lorentz cone

i.e.,
)(z, w) ∈R2 × R | zTz ⩽w2, w ⩾0
*
[8]. Hence, the problem becomes
a conic optimization problem represented by
P4 : max
φ,γ det(I + diag(κ ◦γ))
s.t.
m2 + n2 ⩽t2,
0 ⩽t ⩽ξbTφ,
0 ⪯γ ⪯min(A −c ◦φ, c ◦φ),
φ ⪰0,
m = 1
α[(aT −x0bT) cos θ + (1T −y0bT) sin θ]φ,
n = 1
β [(1T −y0bT) cos θ −(aT −x0bT) sin θ]φ,
1Tφ = Pt,
(7.19)
which can be solved by several convex optimization algorithms such as infeasible
path-following algorithms [9]. In MATLAB, it can be solved by the optimization
software package CVX [10].
7.1.4
Performance evaluation
Thesum-rateperformancesofthemulti-chipLED-basedVLCsystem]nainvestigated
on the assumption that three indoor users are at the same distance from the transmitter
and use perfect optical ﬁlters to receive their own information, while Table 7.1 lists
the parameters used in the simulations. The target BER is set to 10−3 for each user.
Figure 7.3 illustrates the maximum sum-rate under diﬀerent luminous ﬂuxes,
where the step of MacAdam ellipse is set to 7 and the correlated color temperature
(CCT) value is deﬁned as 5000 K. Unlike conventional RF system where higher
electric power results in higher achievable data rate, higher optical power for LED in
VLC might even diminish the data rate. It is shown that the curves of the achievable
data rate for red and green chips present the open-down parabolic shapes and have a
peak point at 100 lm. The reason is that optical power is determined by the DC bias
and narrower dynamic range would be available to amplify the modulated signal in
case of clipping distortion when DC bias deviates from the middle position of the
dynamic range of LED chips. Moreover, the variations of the data rate for red and
green chips further cause the change of the sum-rate according to the same tendency.
Due to the small portion of the blue component in the white light, the DC bias for the
blue chip is always below the middle position of the dynamic range of blue LED chip
in the luminous ﬂux range. Consequently, the data rate for the blue chip increases
slowly when DC bias approaches to the middle position.
The percentages of three light components to achieve the maximum sum rate are
compared in Fig. 7.4 when the CCT is deﬁned as 5000 K and chromaticity tolerance
]na

209
Table 7.1 Simulation parameters for multi-chip LED-based VLC system.
Parameters
Values
Type of white LED
RGB LED
(Cree Xlamp MC-E)
Number of LED chips Nt
3
Target BER for each user
10−3
Maximum forward current for each chip
700 mA
Distance between LED and users τi
2 m
Detect area A
1 cm2
Lambertian emission order m
1
FOV of the receiver
60◦
Angle of the irradiance
30◦
Angle of the incidence
40◦
Concentrator refractive index
1.5
Receiver responsivity
0.5 A/W
Noise variance
0.013 mA2
Peak wavelength of each chip
Red
625 nm
Green
530 nm
Blue
460 nm
Chromaticity coordinates
Red
(0.7006, 0.2993)
Green
(0.1547, 0.8059)
Blue
(0.1440, 0.0297)
Luminance ﬂux–forward current
Red
0.0114 A/lm
conversion coeﬃcient
Green
0.0052 A/lm
Blue
0.0427 A/lm
Table 7.2 Chromaticity coordinates for the MacAdam ellipse [11].
CCT
Center point
g11
2g12
g22
2700 K
(0.459 0.412)
40 × 104
−39 × 104
28 × 104
3000 K
(0.440 0.403)
39 × 104
−39 × 104
27.5 × 104
3500 K
(0.411 0.393)
38 × 104
−40 × 104
25 × 104
4000 K
(0.380 0.380)
39.5 × 104
−43 × 104
26 × 104
5000 K
(0.346 0.359)
56 × 104
−50 × 104
28 × 104
6500 K
(0.313 0.337)
86 × 104
−80 × 104
45 × 104
www.ebook3000.com

210
Figure 7.3 Maximum sum-rate for diﬀerent luminous ﬂuxes when CCT = 5000 K.
is within a 7-step MacAdam ellipse. In order to satisfy the white light constraint,
the chromaticity variation is still restricted in a small range. Therefore, the percent-
ages of all components almost remain unchanged, which are 0.3, 0.675, and 0.025
respectively, while the ﬂuctuation of each component is very small.
In Fig. 7.5, diﬀerent steps of the MacAdam ellipse are compared with CCT = 5000
K. It is shown that multiuser sum-rate is aﬀected by the steps of the MacAdam el-
lipse. When 10-step MacAdam ellipse is considered, it achieves over 0.5 bit/s/Hz
performance gain over the system with 1-step MacAdam ellipse.
The maximum sum-rates are also investigated in Fig. 7.6 under diﬀerent CCT val-
ues with the chromaticity constraint based on MacAdam ellipse. Six CCT values
are investigated according to ANSI C78.376–2001 [11, 12], which are 2700 K, 3000
K (warm white), 3500 K(white), 4000 K (cool white), 5000 K, and 6500 K (day-
light), respectively. A seven-step MacAdam ellipse is chosen for every CCT value in
the simulation. The parameters of the corresponding MacAdam ellipse are listed in
Table 7.2. It can be seen that the curve of the sum-rate for each CCT value has an
open-down parabolic tendency* When larger CCT value is used, higher sum-rate is
achieved. The reason is that when a larger CCT value is considered, the proportion
of the blue component becomes higher. The increase of the data rate in the blue light
link has the main impact on the sum-rate compared to the other two links for a larger
CCT. Besides, for a lower CCT value, the decrease of the electric power as well as the
data rate in the red light link is much severer under large total luminous ﬂux (above
100 lm). Thus, the diﬀerence of the sum-rates among all CCT values becomes more
obvious.
0
50
100
150
200
Luminous Flux (lm)
0
1
2
3
4
5
6
7
8
9
Achievable Sum-Rate (bit/s/Hz)
RGB Chips
Red Chip
Green Chip
Blue Chip

211
0
50
100
150
200
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Luminous Flux (lm)
Ratio
Red Chip
Green Chip
Blue Chip
Figure 7.4 Percentages of three light components to achieve the maximum sum-rate for
diﬀerent luminous ﬂuxes when CCT = 5000 K.
0
20
40
60
80
100
120
140
160
180
200
Luminous Flux (lm)
1
2
3
4
5
6
7
8
9
Achievable Sum-Rate (bit/s/Hz)
One-step MacAdam ellipse
Seven-step MacAdam ellipse
Ten-step MacAdam ellipse
Figure 7.5 Comparison between diﬀerent steps of MacAdam ellipse under diﬀerent
luminous ﬂuxes when CCT = 5000 K.
www.ebook3000.com

212
0
50
100
150
200
Luminous Flux (lm)
1
2
3
4
5
6
7
8
9
Achievable Sum-Rate (bit/s/Hz)
CCT = 2700 K
CCT = 3000 K
CCT = 3500 K
CCT = 4000 K
CCT = 5000 K
CCT = 6500 K
Figure 7.6 Maximum achievable sum-rate comparison for diﬀerent CCT values under
chromaticity constraint based on MacAdam ellipse.
7.2
Heterogeneous VLC-WiFi optimization
In VLC systems, line-of-sight (LOS) transmission is usually assumed, which cannot
be always guaranteed especially in indoor applications due to random movements of
mobile terminals (MTs). Therefore, heterogeneous network is considered to exploit
the advantages of both VLC and conventional RF systems. When the vulnerable VLC
LOS link is blocked, a vertical handover (VHO) from VLC to RF communications,
for example, wireless local area network (WLAN), can be utilized to maintain the
continuity of wireless data transmission.
In a heterogeneous VLC-RF network, it is preferred to exploit VLC LOS link for
content distribution since higher data rate can be supported. When the LOS link is
unavailable, however, MTs will suﬀer from severe quality of experience (QoE) degra-
dation, and the system should switch to the RF connection to provide continuous data
transmission with low QoE. When the VLC LOS link is recovered, the system should
switch back to the VLC connection again to provide high QoE. However, LOS block-
age is usually a temporary phenomenon lasting for a very short period. Therefore, it
might be more eﬃcient to wait for a while rather than switch immediately in some
occasions, since switching back and forth will cause additional signaling overhead
and latency, especially for non-real-time services. Therefore, “waiting” action might
avoid unnecessary switching if the LOS link is recovered rapidly with an acceptable
short blockage duration. Otherwise, “switching” action is preferred to avoid the pos-
sible communication breakdown. The main challenge lies in the eﬃcient strategy to

213
decide whether performing a VHO or not when LOS blockage happens.
VHO is a common problem in heterogeneous networks, such as integrated 3G/4G
and WLAN networks [13]. Due to human activities, LOS link is intermittently inter-
rupted and resumed. In general, LOS blockage is caused by random movements of
MTs either in the shadow area or out of the coverage [14]. The link interruption from
the ﬁrst type of movements is usually short and temporary, while that from the sec-
ond type usually lasts for a relatively long time. Therefore, VLC channels are quite
diﬀerent from conventional RF counterparts, and the conventional VHO schemes of
all-radio heterogeneous systems could not be directly adopted in VLC-RF heteroge-
neous networks. Furthermore, VLC interruption mainly depends on the behaviors
of MTs, which always follow certain patterns and can be depicted by factors such
as location, group, time-of-day, and duration [15]. Hence, the movements of MTs
can be forecasted by the record of behavior history, which can be used to model and
predict the interruption of VLC links.
7.2.1
System model
Since both VLC and WiFi systems are commonly adopted for indoor scenarios, the
heterogeneous VLC-WiFi system is investigated, which is illustrated in Fig. 7.7. Both
VLC cell and WiFi radio cell are overlapped in the room, where the central area
is covered by VLC to provide a relatively higher data rate, while a wider area is
covered by WiFi. All MTs are assumed to support multi-mode transmission, which
can download multimedia content either through VLC or WiFi network. Since the
uplink traﬃc is usually much less than the downlink [16], only WiFi is utilized for
uplink transmission.
As shown in Fig. 7.7, data packets from remote content providers are queued at
the local access point (AP) for ﬁrst-in-ﬁrst-out (FIFO) transmission. At the AP, a
controller is used to select the transmission mode of each packet, i.e., either VLC
or WiFi. Since the coverage of WiFi network is larger than its VLC counterpart
and WiFi works well under non-line-of-sight (NLOS) scenarios, it is reasonable to
assume that WiFi link is always available in the integrated VLC-WiFi heterogeneous
network. When VLC LOS link is blocked during the transmission of a packet in VLC
mode, the packet has to be retransmitted, either through the recovered VLC link or
WiFi channel. When the buﬀer of the AP overﬂows, new incoming packets have to
be dropped.
The objective of an eﬃcient VHO scheme is to ﬁnd the balance between switch-
ing cost and traﬃc congestion. The design of an eﬀective VHO decision-making
algorithm is challenging due to the following reasons: 1) the best tradeoﬀpoint is
determined by switching cost and delay requirement; 2) both signaling overhead and
handover latency are induced during VHO process. For the ﬁrst reason, since mul-
timedia services might have diﬀerent requirements, the controller may prefer to stay
in VLC mode and wait for link recovery during LOS blockage if the switching cost
is high, whereas it may immediately switch to WiFi mode if low transmission delay
is required. For the second reason, the controller may stay in VLC mode if the VLC
www.ebook3000.com

214
Figure 7.7 Illustration of the heterogeneous VLC-WiFi system.
link is unavailable when there is a high probability that it will be recovered soon, or
stay in WiFi mode even if the VLC link is currently available when it is frequently
blocked.
It is evident that the arrival process of packets and the service process for these two
transmission modes follow Poisson distribution [17]. λ (packets/s), μ1 (packets/s),
and μ2 (packets/s) are deﬁned as the arrival rate of packets, the service rate of VLC,
and the service rate of WiFi, respectively. An ON-OFF model is used to describe
the intermittent interruption of VLC link, where ON represents that VLC link is
available while OFF represents the opposite. γ1 (s−1) and γ2 (s−1) are described as
two diﬀerent rates at which the VLC channel changes from unblocking to blocking
and vise versa. Thus, 1/γ1 and 1/γ2 represent the average duration of VLC link
staying in ON or OFF, respectively. The packet delivery process of the heterogeneous
VLC-WiFi system can be modeled by a Markov chain, where the VHO decision-
making problem can be formulated as a Markov decision process and solved by a
dynamic programming approach.
7.2.2
Eﬃcient VHO scheme
For heterogeneous VLC-WiFi networks, we formulate the VHO decision-making
problem as a continuous time MDP [18–21]. A two-state Markov process is used
to model the intermittent VLC LOS blockage. Based on MDP, a VHO scheme is
proposed in [22], which could achieve a tradeoﬀbetween switching cost and traﬃc
congestion.
In the heterogeneous VLC-WiFi system, the state space of data delivery is deﬁned

215
as
Ω = {(s, b, w), s ∈S, b ∈B, w ∈W},
(7.20)
where S = {ON, OFF} denotes the status of the VLC link, B = {0, 1, ..., B}
represents the number of packets in the queue with size of B. W = {1, 0} is the
action space for the transmission mode, where 1 means the packets are transmitted
over VLC link, while 0 means the packets are transmitted over WiFi channel. The
system stays in state i = (s, b, w) when the condition of the optical channel is s,
the number of packets in the system is b and the current transmission mode is w.
The possible events include packet arrivals and departures, and the optical channel
changes between ON and OFF. The event of packet departure includes two cases
where the packet is transmitted either over VLC link or over WiFi channel. When
any one of those events occurs, the system state is updated.
Let a stage be the period between two consecutive events, and the period is so
short that any two events do not occur simultaneously. At the beginning of each
stage, an action is taken to determine which state to enter. The solution of this MDP
is a scheme denoted by p, indicating which action p(i) should be taken for each
state i. A two-dimensional (2-D) Markov process is used to describe the transition
rates between diﬀerent states, as shown in Fig. 7.8. Note that each state (s, b) in
the ﬁgure actually includes two states (s, b, 1) and (s, b, 0). Let Prp(i)
i→i′ denote the
transition probability from state i to state i′ with action p(i), the transition probability
for s = ON is given by
Prp(i)
i→i′ =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
λ
λ + ηγ1 + μON
, if i′ = (ON, b + 1, p(i));
ηγ1
λ + ηγ1 + μON
, if i′ = (OFF, b, p(i));
μON
λ + ηγ1 + μON
, if i′ = (ON, b −1, p(i));
0, else,
(7.21)
where μON = p(i)μ1 + (1 −p(i))μ2, λ + ηγ1 + μON is the sum of weighted
transition rates, and η is the weighting factor with unit of packets. Similarly, the
transition probability for s = OFF is given by
Prp(i)
i→i′ =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
λ
λ + ηγ2 + μOFF
, if i′ = (OFF, b + 1, p(i));
ηγ2
λ + ηγ2 + μOFF
, if i′ = (ON, b, p(i));
μOFF
λ + ηγ2 + μOFF
, if i′ = (OFF, b −1, p(i));
0, else,
(7.22)
where μOFF = (1 −p(i))μ2. Note that packet departure happens in situation s =
OFF only if the transmission mode is WiFi. When b = 0, no packet departs, while
no packet arrives when b = B.
www.ebook3000.com

216
(a)
(b)
(c)
Figure 7.8 Illustration of transition rates for (a) 0 < b < B, (b) b = 0 and (c) b = B.

217
In the VHO decision problem, the objective is to minimize a weighted sum of the
traﬃc consumption, switching cost, and traﬃc congestion. Let g(i, p(i)) denote the
cost incurred at state i = (s, b, w) under action p(i), we have
g(i, p(i)) = p(i)EO + (1 −p(i))EW + ζb + |p(i) −w|(Esw + θλτ), (7.23)
which consists of two parts, denoted as g1(i, p(i)) = p(i)EO +(1−p(i))EW +ζb
and g2(i, p(i)) = |p(i) −w|(Esw + θλτ), respectively. g1(i, p(i)) is a weight-
ed sum of the energy cost for packet transmission and the delay cost induced by the
packets queuing, where EO and EW are the energy consumption of staying in VLC
and WiFi modes, and ζ is the tradeoﬀparameter. Compared with EO and EW , the
energy consumption for the transceiver of either VLC or WiFi in the idle state is neg-
ligible, which is not considered in this problem. g2(i, p(i)) denotes the switching
cost, including the signaling overhead for switching the transmission mode, denoted
as Esw, and the handover latency, denoted as λτ, which represents λτ packets ac-
cumulating in the buﬀer during the VHO process. θ is the scaling parameter which
measures the importance of the latency.
To make the continuous time problem tractable, uniformization is required to trans-
form it into a discrete one [23]. Deﬁne vm as the uniform transition rate, which is no
smaller than all the transition rates vi(p(i)) of any state i and action p(i), we have
vm = max{λ + ηγ1 + μ1, λ + ηγ1 + μ2, λ + ηγ2 + μ2}.
(7.24)
Denote ˆ
Pr
p(i)
i→i′ as the new transition probability of the discrete-time Markov chain
from state i to state i′ under vm, which is given by [23]
ˆ
Pr
p(i)
i→i′ =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
vi(p(i))
vm
Prp(i)
i→i′, if i ̸= i′;
vi(p(i))
vm
Prp(i)
i→i′ + 1 −vi(p(i))
vm
, if i = i′.
(7.25)
Afterwards, the cost per stage after uniformization is calculated as
ˆg(i, p(i)) =
1
β + vm
g1(i, p(i)) + g2(i, p(i)),
(7.26)
where β is the parameter related to the discounted factor α [23]. α is calculated by
α =
vm
β+vm and β is chosen so that α ≈1.
To describe the VHO scheme, the discounted model is adopted [23]. Instead of
minimizing the total cost, the cost of current stage and the discounted cost of future
stages are minimized. According to Bellman’s function [23], the average discounted
sum of costs deﬁned as the cost of current stage plus the expected cost of all future
stages, is minimized by
V (i) = min
p(i) {ˆg(i, p(i)) + α

i′∈Ω
ˆ
Pr
(p(i))
i→i′ V (i′)},
(7.27)
where V (i) is the cost of state i.
www.ebook3000.com

218
The VHO solution is calculated by the value iteration algorithm demonstrated in
Algorithm 7.1 [22]. Since all the components in (7.26) and ˆg(i, p(i)) are bounded,
the iteration algorithm is convergent [23]. Qk(i, p(i)) and V ∗
k (i) are denoted as the
average cost for each state i of iteration k under action p(i) and the optimal average
cost for each state i of iteration k, respectively. In the algorithm, with the knowledge
of V ∗
k−1(i), the optimal action p∗
k(i) for each state i of iteration k is determined
by selecting the action that minimizes Qk(i, p(i)) in line 10 and the corresponding
optimal cost V ∗
k (i) is obtained from line 11. Since the updated average costs V ∗
k (i)
are also the input for iteration k+1, such procedure is repeated until the convergence
criterion ||Vk −Vk−1|| ≤ϵ is satisﬁed.
Algorithm 7.1 Value Iteration Algorithm
Input:
1: Ω, W, α, transition probability ˆP, and cost function ˆg after uniformization, con-
vergence criterion parameter ϵ;
Output:
2: Action p;
3: for each i ∈Ω do
4:
V0(i) = 0;
5: end for
6: Δ = inf;
7: while Δ > ϵ do
8:
for each i ∈Ω do
9:
for each p(i) ∈W do
10:
Qk(i, p(i)) = ˆg(i, p(i)) + α 
i′∈Ω
ˆ
Pr
p(i)
i→i′Vk−1(i′);
11:
end for
12:
p∗
k(i) = arg minp(i){Qk(i, p(i))};
13:
V ∗
k (i) = Qk(i, p∗
k(i));
14:
end for
15:
Δ = ||Vk −Vk−1||;
16: end while
With the VHO solution, the transition rate matrix Q is also derived. Let π∗(s, b, w)
and ⃗π∗= [· · · π∗(s, b, w) · · · ] denote the stationary state probability of state
(s, b, w) and the stationary probability vector, ⃗π∗can be obtained by solving the
following set of equations [24]
⃗π∗Q = 0,
(7.28)
⃗π∗1T = 1,
(7.29)
where 1 is a vector with all unity entries. Packet blockage occurs when a new packet
arrives at a time when the buﬀer overﬂows. Let Pb denote the blockage probability
of packets, which is deﬁned as the probability that the number of packets in the queue

219
is B, we have
Pb =

s∈S

w∈W
π∗(s, B, w).
(7.30)
7.2.3
Performance evaluation
The performance of the aforementioned VHO scheme, named as O-VHO, is com-
pared with two benchmark schemes including immediate-VHO (I-VHO) and dwell-
VHO (D-VHO) [14]. In I-VHO scheme, the controller immediately performs VHO
to switch the transmission mode from VLC to WiFi once the optical channel is in-
terrupted and from WiFi to VLC once the optical channel is restored. In D-VHO
scheme, the controller waits for a dwell period of t0 when the LOS blockage is detect-
ed. When the dwell time expires, if the optical link is still unavailable, the controller
switches the transmission mode to WiFi, otherwise it stays in VLC mode. When the
system detects that the VLC link is recovered, the controller immediately performs
VHO from WiFi back to VLC. D-VHO can avoid potential ping-pong eﬀects. To
facilitate the simulations, we set t0 to 0.5 s and 1 s, respectively.
Four metrics are used for performance evaluation. First, ρ denotes the packet loss
rate, which is deﬁned as the ratio of the number of dropped packets to the total num-
ber of arrived packets. Second, d denotes the average delay representing the average
waiting time for a packet to be served. Third, l is the average queue length, which is
deﬁned as the average number of waiting packets. Finally, c is the number of VHO,
which is proportional to signaling cost. When B packets are waiting in the queue, if
there are packets that can be delivered successfully before new packet’s arrival, then
newly arrived packets will not be dropped. Therefore, Pb is the upper bound of ρ and
ρ ≤Pb.
Simulations are carried out based on stochastic process over a period of continu-
ous time. As mentioned previously, packet arrival and packet departure through two
transmission modes are modeled as Poisson process with rates λ, μ1, and μ2, re-
spectively [17]. The VLC LOS link blockage is modeled as an independent blocking
event, whose duration has negative and exponential distribution with rate γ2. Similar-
ly, non-blocking duration of the LOS link is modeled by γ1 [25]. Hereby, we mainly
evaluate the switching cost during VHO process, thus the energy consumption of
VLC and WiFi transmission is assumed to be the same. The simulation parameters
are summarized in Table 7.3.
First, τ is set to 0.2 s and γ2 is varied from 0.3 to 1.1 s−1. Larger γ2 means shorter
average time when the system stays in the OFF state and the VLC link is more likely
to be available. As shown in Fig. 7.9, when γ2 increases from 0.3 to 1.1 s−1, ρ
attained from I-VHO, O-VHO, D-VHO with t0 = 0.5 s and D-VHO with t0 = 1 s
is decreased by 68.08%, 61.56%, 59.82%, and 59.25% respectively, while d attained
from those four schemes is decreased by 30.63%, 22.14%, 28.39%, and 30.71%,
respectively. In addition, l attained from those four schemes is decreased by 29.86%,
21.25%, 27.24%, and 28.97%, respectively, and c attained from those four schemes
www.ebook3000.com

220
Table 7.3 Simulation parameters.
Parameter
Value
Packet arrival rate λ
1 packet/s
Handover delay τ
0–0.5 s
Packet departure rate of VLC μ1
2 packets/s
Packet departure rate of WiFi μ2
1.1 packets/s
Rate of optical channel changing from
ON to OFF γ1
0.4 s−1
Rate of optical channel changing from
OFF to ON γ2
0.3–1.1 s−1
Signaling cost for VHO Esw
418
Energy consumption for transmission
EO and EW
5 × 10−4 kwh
Buﬀer size B
10 packets
Scaling parameter θ
3000 J
Tradeoﬀparameter ζ
500 J
Weighting factor η
1 packet
Dwell time t0
1, 0.5 s
Simulation period
30,000 s
is increased by 71.11%, 24.97%, 44.84%, and 31.09%, respectively. Although I-
VHO achieves the lowest packet loss rate, shortest average delay, and average queue
length, the number of VHO obtained by I-VHO is the highest. Besides, the gaps of
the number of VHO between I-VHO and the other three handover schemes become
larger with the increase of γ2. Consequently, I-VHO is not preferred in practical
scenarios.
As for D-VHO, its performance depends highly on the value of t0. For example,
when t0 = 0.5 s, it is similar to the proposed O-VHO in terms of d and l. However,
when t0 = 1 s, the performance of D-VHO is worse than O-VHO. Furthermore, the
values of c attained from D-VHO with t0 = 0.5 s and D-VHO with t0 = 1 s are
much higher than O-VHO. As shown in Fig. 7.9, O-VHO always achieves the lowest
number of VHO and has similar performance compared with I-VHO in terms of ρ, d,
and l. Take γ2 = 0.8 s−1 as an example, ρ, d, and l attained by O-VHO are 1.1903,
1.147, and 1.1454 times of those attained from I-VHO, while c attained by O-VHO
is 54.94% of that attained from I-VHO. Hence, the proposed O-VHO can achieve a
balance between switching cost and QoS requirement.
In Fig. 7.10, γ2 is ﬁxed to 1 s−1 and handover delay τ is changed. When τ increases
from 0 to 0.5 s, ρ attained from I-VHO, O-VHO, and D-VHO with t0 = 0.5 s and
D-VHO with t0 = 1 s is increased from 0.219%, 0.226%, 0.459%, and 0.798%
to 2.228%, 3.378%, 3.685%, and 4.984%, respectively, while d attained from those
four schemes is increased from 1.388, 1.389, 1.703, and 1.994 to 2.793, 3.51, 3.344,
and 3.739, respectively, and l is increased from 1.384, 1.387, 1.695, and 1.979 to
2.733, 3.389, 3.216, and 3.552, respectively. c attained from O-VHO decreases with
the increase of τ, while c attained from the other three schemes changes slightly. As

221
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1
1.5
2
2.5
3
3.5
4
4.5
Rate of optical channel changing γ2 (s−1)
Packet loss rate ρ (%)
O−VHO
I−VHO
D−VHO,t0=1
D−VHO,t0=0.5
(a) Packet loss rate
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1
1.5
2
2.5
3
3.5
4
4.5
5
Rate of optical channel changing γ2 (s−1)
Average delay d (s)
O−VHO
I−VHO
D−VHO,t0=1
D−VHO,t0=0.5
(b) Average delay
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.8
2
2.2
2.4
2.6
2.8
3
3.2
3.4
3.6
 Rate of optical channel changing γ2 (s−1)
Average queue length l (number)
O−VHO
I−VHO
D−VHO,t0=1
D−VHO,t0=0.5
(c) Average queue length
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
0.6
0.8
1
1.2
1.4
1.6
1.8 x 10
4
Rate of optical channel changing γ2 (s−1)
Number of VHO c (times)
O−VHO
I−VHO
D−VHO,t0=1
D−VHO,t0=0.5
(d) Number of VHO
Figure 7.9 Impact of γ2 on the system performance for four schemes.
www.ebook3000.com

222
0
0.1
0.2
0.3
0.4
0.5
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
5.5
Handover delay τ (s)
Packet loss rate ρ (%)
O−VHO
I−VHO
D−VHO,t0=1
D−VHO,t0=0.5
(a) Packet loss rate.
0
0.1
0.2
0.3
0.4
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Handover delay τ (s)
Average delay d (s)
O−VHO
I−VHO
D−VHO,t0=1
D−VHO,t0=0.5
(b) Average delay.
0
0.1
0.2
0.3
0.4
0.5
1.5
2
2.5
3
3.5
4
Handover delay τ (s)
Average queue length l (number)
O−VHO
I−VHO
D−VHO,t0=1
D−VHO,t0=0.5
(c) Average queue length.
0
0.1
0.2
0.3
0.4
0.5
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8 x 10
4
Handover delay τ (s)
Number of VHO c (times)
O−VHO
I−VHO
D−VHO,t0=1
D−VHO,t0=0.5
(d) Number of VHO.
Figure 7.10 Impact of handover delay τ on the system performance for four schemes.
shown in (7.23), the value of the cost function grows for VHO action with the increase
of τ. Therefore, more stages keep their transmission mode unchanged, leading to
fewer VHO processes. I-VHO and D-VHO , on the other hand, do not consider the
handover delay, and thus there is almost no ﬂuctuation in the number of VHO with
the increase of τ. It coincides with the phenomenon that the slope of the curves
obtained by O-VHO is steeper than those obtained by the others in Fig. 7.10 (a)–
(c). The performance degradation is not only a reﬂection of the increase of handover
delay, but also the balance of cost and delay. If we compare the proposed O-VHO to
D-VHO with t0 = 0.5 s, d and l attained from O-VHO are lower than those attained
from D-VHO when τ ≤0.2 s, while the opposite result is observed when τ > 0.2
s. For all cases, O-VHO performs better than D-VHO with t0 = 0.5 s in terms of
ρ and c. D-VHO with t0 = 1 s achieves a lower c than O-VHO when τ = 0, but
it does not perform well in other scenarios. Therefore, although D-VHO performs
better than I-VHO and O-VHO in some occasions, it requires adaptive t0 when the
condition of the system changes. The proposed O-VHO, however, is able to make
the near optimal VHO decision for all the cases dynamically and adaptively.

223
7.3
Signal estimation and modulation design for VLC with SDGN
Conventionally, the research about VLC is mainly focused on the system with signal-
independent Gaussian noise (SIDGN), whilst much less eﬀort is made to cope with
the system degradation due to signal-dependent Gaussian noise (SDGN). In optical
communication, the photodetector shot noise is originally modeled by Poisson statis-
tics dependent on signal. As the number of received photons increases, the shot noise
process can be well approximated by Gaussian statistics. Thus, the channel can be
described by an AWGN model, including electrical thermal noise, signal-dependent
shot noise, and signal-independent shot noise. When a single element photodiode
is used as the reception device, the system will suﬀer from serious interference in
direct background light, especially in the wide FOV case. This is because the back-
ground light is typically strong and can often be received at an average power much
higher than the desired signal. Furthermore, it is diﬃcult to reduce the enormous
amount of noise signal from the background light in a wide FOV, even if an opti-
cal band-pass ﬁlter is used. Hence, the noise in VLC is typically assumed to be
signal-independent. However, the signal-dependent distortion is observed in shot
noise limited optical communication systems where the signal-dependent shot noise
is comparable with background/thermal noise. Some examples of such systems are
VLC links with high signal-to-noise ratios (SNRs) employing high-gain narrow FOV
avalanche photodiode (APD) receivers [26], and free-space optical communication
systems with high-sensitive receivers such as single photon avalanche diode (SPAD)
array [27]. The SDGN channel model fundamentally changes the problem of eﬃ-
cient signaling, optimal signal detection/estimation, and system performance. This
section discusses the optimal signal detection/estimation and eﬃcient signal design
in the presence of SDGN.
7.3.1
Signal estimation for VLC with SDGN
The general IM/DD channel with SDGN can be modeled as
Y = hX + kg(hX)Z1 + Z0,
(7.31)
where X is the nonnegative input signal and is proportional to the light intensity,
which is generally characterized by the probability function fX(X). Z1 and Z0 are
signal-independent random noise processes, which are assumed to be statistically
independent of X. g(hX) is the function of the input signal, k and h are scalar
constant and channel state respectively, and Y is the noisy measurement. The term
kg(hX)Z1 is called signal-dependent noise. The commonly used signal-dependent
model in VLC typically sets g(hX) to (hX)p, and the value of p used for charac-
terizing the signal-dependent noise to 1/2. Moreover, for a determined channel or a
channel with channel-state-information-at-the-transmitter (CSIT), the scaling factor
h represents the product of all the path losses and photoelectric conversion factors.
Since h scales the SNR only, without loss of generality, we set h = 1 to simplify the
www.ebook3000.com

224
analysis. Therefore, the general signal-dependent measurement model in (7.31) can
be simpliﬁed as
Y = X + kXpZ1 + Z0.
(7.32)
For ease of signal estimation, the observed value can be used for estimation, which
results in a minimum-variance unbiased estimate. That is, when the estimation of
X, denoted as ˆX, is equal to Y , the average error is given by
E( ˆX −X) = E(Y −X) = E(kXpZ1 + Z0) = 0.
(7.33)
The estimator is unbiased since the average error is 0. The mean squared estimation
error (MSEE) for this mismatched case is given by
E[( ˆX −X)2] = k2σ2
1E(X2p) + σ2
0.
(7.34)
According to the arguments in Jensen’s inequality, for a convex function d(X), if
d
′′(X) ≥0 for all X, then d(E[X]) ≤E[d(X)], while for a concave function
d(X), the inequality is reversed. Thus, if p = 1
2, equality holds in Jensen’s inequal-
ity, and the mismatched MSEE is given by
E[( ˆX −X)2] = k2σ2
1E(X) + σ2
0.
(7.35)
For p >
1
2 and p <
1
2, the MSEE is lower-bounded and upper-bounded by
k2σ2
1[E(X)]2p + σ2
0, respectively.
Cramer–Rao lower bound (CRLB) is a well-known lower bound on the variance of
any unbiased estimate for a ﬁxed but unknown X. Given the conditional probability
density function (PDF) f(Y |X), the CRLB is given by
E
)( ˆX −X)2|X
* ≥

−E
∂2lnf(Y |X)
∂X2
−1
.
(7.36)
For the channel model given in (7.32), where Y is Gaussian with mean X and with
variance σ(X), the conditional PDF is given by
f(Y |X) =
1

2πσ(X)e−(Y −X)2
2σ(X) ,
(7.37)
where
σ(X) = k2σ2
1X2p + σ2
0.
(7.38)
Then the CRLB can be expressed as
E
)( ˆX −X)2|X
* ≥
2[σ(X)]2
2σ(X) + [σ
′(X)]2
=
k4σ4
1X4p + 2k2σ2
1σ2
0X2p + σ4
0
k2σ2
1X2p + 2p2k4σ4
1X4p−1 + σ2
0
,
(7.39)

225
where σ
′(X) is the derivative of σ(X) with respect to X. Although it is not obvious
by inspection, the bound given by (7.39) may actually be smaller than the bound given
by σ2
0 for the SDGN channel case and the bound given in (7.34) for the MSEE of the
mismatched case in the SDGN channel. There are cases that a properly matched
signal-dependent estimator may potentially outperform the corresponding properly
matched signal-independent estimator. Some optimal estimators are presented in the
next to achieve the CRLB.
7.3.1.1
MMSE estimation
The minimum mean square error (MMSE) estimator is a commonly studied optimal
estimator, whose criterion is to minimize the mean square estimation error, given by
ˆXMMSE = min
ˆ
X(Y )
E{[X −ˆX(Y )]2}.
(7.40)
Deﬁne estimation error as e(X, Y ) ≜X −ˆX(Y ). Then MMSE is given by
E
)e2(X, Y )
* =
 ∞
−∞
 A
0
e2(X, Y )f(X, Y )dXdY
=
 ∞
−∞
  A
0
e2(X, Y )f(X|Y )dX

f(Y )dY,
(7.41)
where A is the peak-intensity constraint for the nonnegative input signal X. Since
f(Y ) is nonnegative, E
)e2(X, Y )
*
can be minimized if the term
 A
0 e2(X, Y )f(X|Y )dX
is minimized for all values of Y . Then, the conditional MMSE to estimate ˆX can be
minimized as
ˆXMMSE = min
ˆ
X(Y )
E
)e2(X, Y )|Y
* = min
ˆ
X(Y )
 A
0
.X −ˆX(Y )
/2f(X|Y )dX.
(7.42)
The ˆXMMSE is the value of ˆX when the partial derivative is 0 with respect to ˆX.
Thus,
∂2E
)e2(X, Y )|Y
*
∂ˆX
|X= ˆ
XMMSE = 0 = −2
 A
0
(X −ˆXMMSE)f(X|Y )dX.
(7.43)
After some mathematic manipulations, the ˆXMMSE can be expressed as
ˆXMMSE =
 A
0
Xf(X|Y )dX.
(7.44)
Thus, the MMSE estimate is the conditional mean of X given the measurement Y .
For this reason, the estimator is also referred to as the conditional mean (CM) esti-
mator. The expected value of the estimation error e(X, Y ) = X −ˆXMMSE is given
by
E[e(X, Y )] = E
)E[e(X, Y )|Y ]
* = E
)E[X|Y ] −E[ ˆXMMSE|Y ]
*,
(7.45)
www.ebook3000.com

226
where the ﬁrst term on the right side of (7.45) is simply the conditional mean of X
given the measurement Y , or equivalently ˆXMMSE as given in (7.44). The second
term on the right side is deterministic once Y is given. Thus we have
E[ ˆXMMSE|Y ] = ˆXMMSE.
(7.46)
Combining (7.44) and (7.46) in (7.45), we have
E[e(X, Y )] = 0.
(7.47)
Since the estimation error e(X, Y ) has zero-mean and variance E[e2(X, Y )],
ˆXMMSE is also known as the minimum-variance unbiased (MVU) estimate.
Noteworthily, (7.44) is computationally inconvenient due to the diﬃculty of deriv-
ing f(X|Y ). To alleviate this problem, Bayes’ rule can be used and ˆXMMSE can be
expressed as
ˆXMMSE =
 A
0 Xf(Y |X)f(X)dX
 A
0 f(Y |X)f(X)dX
.
(7.48)
In this form, it is only necessary to know the PDF of fX(X) and f(Y |X), and gen-
erally, these are either given, assumed known, or easily derived. Due to high com-
plexity and suboptimal performance of the MMSE estimator, it is worth investigating
alternative estimators.
7.3.1.2
MAP estimation
The maximum a posteriori probability (MAP) estimator is another optimum estima-
tor. The conditional probability f(X|Y ) is known as the a posteriori probability,
which represents the probability distribution of the variable X, given that the mea-
surement Y is known. Its mean value is the MMSE estimation shown in the previous
section. On the other hand, its most probable value is the one maximizing f(X|Y ).
This MAP estimator can be expressed as ˆXMAP, which satisﬁes
f( ˆXMAP|Y ) ≥f( ˆX|Y ), ˆXMAP ̸= ˆX.
(7.49)
Thus, MAP estimation is a conditional mean of X given Y , just like the MMSE
estimation.
For MAP, the estimator is attained by taking the partial derivative of the a posteriori
probability and equating the derivative to 0, provided that the derivative is valid. Thus
ˆXMAP satisﬁes
∂
∂X f(X|Y )|X= ˆ
XMAP = 0.
(7.50)
Similar to MMSE estimation, the a posteriori probability f(X|Y ) is diﬃcult to com-
pute, thus Bayes’ rule can be used again to rewrite (7.50) as
∂
∂X
.f(Y |X)f(X)
f(Y )
/|X= ˆ
XMAP = 0 ⇔
∂
∂X
.f(Y |X)f(X)
/|X= ˆ
XMAP = 0,

227
(7.51)
where the right equality holds based on the assumption that f(Y ) is independent of
X. Moreover, since monotonic transformations preserve maxima and minima, the
MAP estimation ˆXMAP equivalently satisﬁes
∂
∂X lnf(X|Y )|X= ˆ
XMAP =
∂
∂X lnf(Y |X) + ∂
∂X lnf(X)|X= ˆ
XMAP = 0. (7.52)
Actually, when f(X|Y ) satisﬁes the following two conditions: (1) the a posteriori
probability f(X|Y ) is symmetrical; (2) limX→∞C(X, ˆX)f(X|Y ) = 0, where
C(X, ˆX) = (X −ˆX)2 is the quadratic cost function, MMSE and MAP estimators
are equivalent.
To investigate the eﬀect of SDGN on the MAP estimator, the channel model given
in (7.32) and the conditional probability f(Y |X) in (7.36) are used. A straightfor-
ward substitution of f(Y |X) into (7.52) yields the MAP equation,
(Y −ˆXMAP)2σ
′( ˆXMAP) + 2(Y −ˆXMAP)σ( ˆXMAP) −σ
′( ˆXMAP)σ( ˆXMAP)
+ 2[σ( ˆXMAP)]2
∂
∂ˆXMAP
lnf( ˆXMAP) = 0,
(7.53)
where σ
′ (X) denotes the partial derivative of σ(X) with respect to X. General-
ly, compared with the optimal MMSE criterion, the mathematical complexity of the
MAP estimator is reduced.
7.3.1.3
ML estimation
Another commonly used optimal estimator is the maximum likelihood (ML) estima-
tor, which is employed when prior statistical knowledge of the signal is unknown,
and obtained by maximizing f(Y |X) over X. Thus, the ML estimation ˆXML is the
value which satisﬁes the inequality
f(Y | ˆXML) ≥f(Y | ˆX), ˆXML ̸= ˆX.
(7.54)
Computationally, the ML estimator can be found by equating the partial derivative
of f(Y |X) to 0 with respect to X, provided that the derivative exists. Similar to
the MAP estimator, maximizing the logarithm of f(Y |X) can lead to the ML solu-
tion. Thus, either of the following equivalent equations can be used to ﬁnd the ML
estimator, where the ML estimation is the value ˆXML which satisﬁes
∂
∂X f(Y |X)|X= ˆ
XML = 0 ⇔
∂
∂X lnf(Y |X)|X= ˆ
XML = 0.
(7.55)
Comparing ML estimation in (7.55) with MAP in (7.52), it is found that the MAP
estimation is equivalent to the ML estimation when f(X) is constant, thus the MAP
estimation can be viewed as a speciﬁc case of ML estimation, where all values of X
in the range of interest are assumed to have equal probability. The last term in (7.53)
www.ebook3000.com

228
which embodies the a priori knowledge of X can be eliminated. The ML estimator
is the solution of
(Y −ˆXML)2σ
′( ˆXML) + 2(Y −ˆXML)σ( ˆXML) −σ
′( ˆXML)σ( ˆXML) = 0.
(7.56)
Substituting the expression of σ( ˆX) and σ
′( ˆX) into (7.56), the ML estimator is
obtained by the positive root solution of
[2k2σ2
1(p −1)] ˆX2p+1
ML
+ [2Y k2σ2
1(1 −2p)] ˆX2p
ML
+ [2pk2σ2
1(Y 2 −σ2
0)] ˆX2p−1
ML
−[2σ2
0] ˆXML
−[2pk4σ4
1] ˆX4p−1
ML
+ [2σ2
0Y ] = 0.
(7.57)
Noteworthily, compared with the MAP estimator, the ML estimator has lower com-
plexity.
7.3.2
Suboptimal estimation for VLC with SDGN
The motivation of the development of suboptimal estimators for the SDGN channel
as in (7.32) stems from the obvious shortcomings in optimal estimators [28]: (1)
the mathematical complexity, (2) diﬃculty of implementation, (3) general lack of
closed-form solutions, and (4) sensitivity to the a priori function fX(X). To avoid
these problems, several suboptimal estimators are exploited at the cost of perfor-
mance degradation.
7.3.2.1
Linearization
Obviously, the term Xp in (7.32) leads to extra computational complexity. An ob-
vious suboptimal estimation scheme is to modify the measurement model by simply
ignoring the term Xp. By doing so, the problem becomes one with a classical signal-
independent noise model and the entire analysis of this approach is on the basis of the
mismatch case discussed in the previous section with degraded performance. Actu-
ally, by linearizing the term Xp, nonlinearity can be removed. Speciﬁcally, in (7.32),
Xp is expanded in a Taylor series at E(X) = μX, while the second and higher order
terms are dropped. The linearized measurement model becomes
Y ≈X + k
.pμp−1
X
X + μp
X −μXpμp−1
X
/Z1 + Z0
=
.1 + kpμp−1
X
Z1
/X + k
.μp
X −μXpμp−1
X
/Z1 + Z0.
(7.58)
This is in the form of Y = AX+B, where A =
.1+kpμp−1
X
Z1
/
and B = k
.μp
X −
μXpμp−1
X
/Z1 + Z0, and the accuracy of this linear approximation depends on the
dropped second and higher order terms 1
2(X −μX)2p(p−1)μp−2
X
+o(μn
X). Since
X is a random variable, it is more meaningful to consider the statistical properties
of the second and higher order terms. Recall that when p = 1
2, the mean value is

229
deﬁned as
1
2σ2
Xp(p −1)μp−2
X
+ o(μn
X) = −1
8σ2
Xμ
−3
2
X
+ o(μn
X).
(7.59)
Obviously, the value of σ2
X and the nonlinear feature determine the accuracy of the
linear approximation of (7.58).
As mentioned above, the signal-independent noises Z1 ∼N(0, σ2
1) and Z0 ∼
N(0, σ2
0) are assumed to be statistically independent with X. Then, the expectation
of the measurement based on the linearized model in (7.58) can be calculated as
E(Y ) = E(A)μX + E(B) = μX.
(7.60)
This demonstrates that ˆX = Y is an unbiased estimator for X.
7.3.2.2
Modiﬁed noise cheating
To tackle the SDGN issue, one way is to average a small portion of the measurement
and use the local average as the estimate. Deﬁne the jth sample mean as ¯Yj, given
by
¯Yj = 1
n
n

i=1
Yi,j,
(7.61)
and the estimate ˆX is taken to be
ˆXj = ¯Yj.
(7.62)
This estimator is a modiﬁcation of noise-cheating, which is simpler to implement
and analyze. Obviously, the modiﬁed noise-cheating estimator is unbiased since
E[ ¯Yj] = 1
n
n

i=1
E[Yi,j] = 1
n
n

i=1
μX = μX.
(7.63)
The advantages of the modiﬁed noise-cheating estimator are as follows. It is easy to
implement and does not need a priori statistical knowledge of the measurement
process. Moreover, the modiﬁed noise-cheating estimator is robust to the a priori
probability function of the signal X. However, this method also has some drawbacks.
Since the modiﬁed noise-cheating algorithm is actually a ﬁnite-window low-pass
ﬁlter, it loses high-frequency signal information, which makes this method not robust
to the noise power spectrum.
7.3.2.3
Modiﬁed MAP and James–Stein estimation with SDGN
Compared with the MMSE estimator, the computational complexity of the MAP es-
timator is greatly reduced. However, the complexity is still high for practical imple-
mentation. To retain the ease of implementation, a proper choice is using a modiﬁed
signal-independent MAP estimator. Assuming that X is normally distributed with
mean μX and variance σ2
X, the signal-independent MAP estimator is given by
ˆXMAP =
σ2
X
σ2
X + σ2
0
Y +
σ2
0
σ2
X + σ2
0
μX.
(7.64)
www.ebook3000.com

230
To modify the signal-independent MAP estimation, so that it will accommodate the
SDGN eﬀects better, μX in (7.64) is replaced with the mean sample ¯Yj, as given
in (7.61). Moreover, the signal variance σ2
X is adaptively estimated with the local
sampled variance. Thus the modiﬁed signal-independent MAP estimator is given by
ˆXj = QjYj + (1 −Qj) ¯Yj,
(7.65)
where Qj is given by
Qj =
uj
uj + σ2
0
.
(7.66)
The sample variance uj is given by
uj =
n
i=1(Yi,j −¯Yj)2
n −1
,
(7.67)
where the denominator n −1 is to make an unbiased estimate of the variance. Al-
though the modiﬁed signal-independent MAP estimator is robust due to its employ-
ment of sample means as parameters, this estimator is designed for the signal with
Gaussian distribution.
The empirical Bayesian estimator, i.e., the James–Stein estimator, estimates the
mean of a multivariate normal distribution with uniformly lower MSEE than the
sample mean. By estimating the sample variance σ2
Y = σ2
X + σ0
0 with its proper
sample variance uj, the James–Stein estimator is given by
ˆXj = ¯Yj + Q+
j (Yj −¯Yj),
(7.68)
where Q+
j ≜max(0, (1−σ2
0
uj )), with which a lower MSEE can be obtained, while ¯Yj
is given by (7.61). To guarantee the unbiased estimate of the variance, the estimate,
denoted by uj, is given by
uj =
n
i=1(Yi,j −¯Yj)2
n −3
.
(7.69)
Note that when Qj = 1, the estimate is given by ˆXj = Yj; when Qj = 0, the
estimate is ˆXj = ¯Yj, which is the modiﬁed noise-cheating estimator.
7.3.3
Eﬃcient signal design for VLC with SDGN
The SDGN model fundamentally changes the problem of eﬃcient signaling com-
pared to the conventional SIDGN model. Complex modiﬁcations to signal pro-
cessing techniques may be required to ensure optimal data transmission. Eﬃcient
transmission with nonuniform signaling is possible, which is capacity-achieving op-
timal signaling, but such a signaling scheme would require complex optimization

231
and additional signal processing for coding and decoding. However, via transform-
ing signals in square-root or frequency domains, the strength of the SDGN can be
normalized and essentially transmission with signal-independent distortions is al-
lowed [27]. Moreover, this approach can identify eﬃcient communication schemes
which can take the advantages of conventional coding, signal processing, and esti-
mation/detection techniques. Additionally, the signal in the presence of the SDGN
can be optimally designed and the improved performance can be achieved.
7.3.3.1
Eﬃcient signaling in the square-root domain
A simple scheme was developed based on signaling in the square-root (SQR) domain,
which transforms the optimal channel originally distorted by SDGN into a stationary
SIDGN channel [26, 27, 29], so that the conventional coding, signal processing, and
detection/estimation techniques with lower complexity can be utilized. The concept
of signaling in the square-root domain and the eﬃcient communication with square-
root signaling will be introduced here.
For a general square-root transformation, it can normalize the variance of random
variable X, where its variance σ2
X is the function of the mean μX as
σ2
X = l2(μX).
(7.70)
The corresponding normalizing transformation Y = T(X) can be expressed as
T(X) =

dX
l(X),
(7.71)
for which σ2
Y ≈1 and μY ≈T(μX) when the value of μX is suﬃciently large.
That means the signal-dependent noise becomes signal-independent after the trans-
formation.
Based on this, recall that the variance of signal is σ(X) = k2σ2
1X +σ2
0 as shown
in (7.38) and p = 1/2. Deﬁne the function l(X) =

k2σ2
1X + σ2
0 for the Gaus-
sian random variable Y , which falls within the general family of random variables
described above. The corresponding normalizing transform for Y is given by
T(Y ) =

dY

k2σ2
1Y + σ2
0
=
2
kσ1

Y + σ2
0/k2σ2
1.
(7.72)
Then, the resultant transform is in a square-root form as the received signal is orig-
inally distorted by a Poisson-distributed shot noise. Thus, the normalized form of
(7.72) is called square-root transform. Considering the normalization as
˜Y = Tsqr(Y ) =

Y + σ2
0/k2σ2
1,
(7.73)
then the stabilized variance of the output of the square-root transform can be ex-
pressed as
σ2
˜Y = k2σ2
1
4
.
(7.74)
www.ebook3000.com

232
Figure 7.11 VLC system with square-root signaling.
Furthermore, the inverse transform can be expressed as
Y = T −1
sqr ( ˜Y ) = ˜Y 2 −σ2
0/k2σ2
1.
(7.75)
The system diagram of VLC with signaling in the SQR domain is shown in
Fig. 7.11. Since the signal is generated in the SQR domain, the channel in Fig. 7.11
can be described as the conventional SIDGN channel in the SQR domain although it
suﬀers from SDGN in the time domain. Then, conventional coding and signal pro-
cessing techniques can be directly applied to the signal. After the biasing operation
by σ0/kσ1 to generate non-negative signal, the modulated signal undergoes inverse
square-root transform. At the receiver, the received signal is distorted by the SDGN.
The distorted signal is transformed back into the SQR domain where the noise is
signal-independent. Finally, using the conventional signal detection/estimation for
SIDGN channel, the original data can be recovered.
7.3.3.2
Optimal signal design for VLC with SDGN
In the previous sections, linearization, modiﬁed noise cheating, and square-root
transform are used to tackle the communication issues with SDGN, in which the
conventional coding, signal processing, and detection/estimation techniques can be
directly applied. However, these schemes are suboptimal in a SDGN channel. In the
following, a joint signal and corresponding threshold design for an IM/DD system
with SDGN under intensity constraints will be presented. To guarantee the optimal
performance, ML-based estimation is applied.
For a general SDGN channel deﬁned in (7.32), when we set k = 1 and p = 1
2, we
have
Y = X +
√
XZ1 + Z0.
(7.76)
As mentioned before, X is the nonnegative input signal and is proportional to
the light intensity. Z1 and Z0 are the SIDGNs with Z1 ∼N(0, σ2
1) and Z0 ∼
N(0, σ2
0), respectively. Moreover, Z1, Z0, and X are assumed to be statistically
independent.

233
For a SDGN channel, the optimally designed signal is the one which has the mini-
mum symbol error rate (SER). Assume that the collection of the intensity-modulated
PAM signal is X = {X1, X2, . . . , XM} where M is the maximum intensity level.
At the receiver, symbol Xm can be selected using an ML detector, thus
m = arg max
n∈S f(Y |Xn),
(7.77)
where S = {1, 2, . . . , M} contains the intensity levels, and f(Y |Xm) is the con-
ditional probability, given by
f(Y |Xm) =
1

2π(σ2
1Xm + σ2
0)
exp{−
(Y −Xm)2
2(σ2
1Xm + σ2
0)}.
(7.78)
In a SDGN channel, the ML detection rule is given by
ˆXm = arg
max
n∈{1,...,M} f(Y |Xn)
= arg
max
n∈{1,...,M}

ln

σ2
1Xn + σ2
0 +
(Y −Xn)2
2(σ2
1Xn + σ2
0)2

.
(7.79)
The corresponding probability of detection error is given by [27]
Pe ≈
1
log2M · M
M−1

m=1
Q

τm −Xm
2

σ2
1Xm + σ2
0

+ Q

Xm+1 −τm
2

σ2
1Xm+1 + σ2
0

,
(7.80)
where τm, m ∈S is the threshold, formulated as a function of the transmitted signal
given by
ln

σ2
1Xm + σ2
0

+
(τm −Xm)2
2(σ2
1Xm + σ2
0)
= ln

σ2
1Xm+1 + σ2
0

+
(τm −Xm+1)2
2(σ2
1Xm+1 + σ2
0).
(7.81)
For notational simplicity, the transmitted signals and corresponding thresholds are
packed into vectors as
XM = [X1 X2 · · · XM]T, and τ M = [τ1 · · · τM−1]T.
(7.82)
Further, due to safety and practical consideration, the input signal has peak and non-
negative constraints as
Pr[0 ≤Xm ≤A] = 1, m ∈S,
(7.83)
and an average intensity constraint is given by
E[XM] ≤P.
(7.84)
www.ebook3000.com

234
We use ρ to denote the average to peak power ratio (APPR)
ρ ≜P
A
(0 < ρ ≤1).
(7.85)
Note that if ρ = 1, the average intensity constraint is inactive, which corresponds
to the case with only a peak-intensity constraint. Similarly, ρ ≪1 corresponds to
a very weak peak-intensity constraint. Then, the optimal signals and thresholds are
found jointly by solving the following problem [30]
min
XM,τ M
Pe(XM, τ M)
s.t.
[0 τ T
M]T ≤XM ≤[τ T
M A]T,
1TXM = ρA · M.
(7.86)
Although the objective function is non-convex, the feasible region is convex for
XM, τ M. Such optimization can be solved via several non-convex optimization
methods, such as the gradient projection procedure in [30].
The following simulation results illustrate the performance of the optimally de-
signed signal. The intensity level M is set to 4, the peak intensity value A equals
8, and the APPR ρ is set 0.5. The optimally designed nonuniform signaling is com-
pared with the conventional uniform signaling and signaling in the SQR domain.
The thresholds τn for those scenarios are obtained by a similar gradient projection
procedure but with ﬁxed intensity.
0.1
0.09
0.08
0.07
0.06
0.05
0.04
0.03
0.02
0.01
0
0.02
0.04
0.06
0.08
0.1
0.12
σ0
2 (ς2 = 2)
SER
Optimal
Conventional
Square−root
Figure 7.12 SER performance of the optimal signaling against thermal noise variance.
Figures 7.12–7.14 show the SER performance for optimal nonuniform signaling,
uniform signaling, and signaling in the SQR domain, against diﬀerent values of ther-
mal noise variance, shot noise scaling factor ς2 = σ2
1/σ2
0, and APPR ρ. The sim-
ulation results indicate that the optimally designed signal achieves better SER per-
formance than the conventional uniform signaling and signaling in the SQR domain
under the intensity constraints. For the case with lower SNR, the uniform signaling
has a superior performance to the signaling in the SQR domain. However, in the

235
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
ς2 (σ0
2 = 0.05)
SER
Optimal
Conventional
Square−root
Figure 7.13 SER performance of the optimal signaling against shot noise variance.
0.38
0.36
0.34
0.32
0.30
0.28
0.26
0
0.02
0.04
0.06
0.08
0.1
0.12
APPR ρ (ς2 = 2, σ0
2 = 0.05)
SER
Optimal
Conventional
Square−root
Figure 7.14 SER performance of the optimal signaling against the APPR.
www.ebook3000.com

236
cases with high SNR, signaling in the SQR domain performs better [30]. Further-
more, due to signal-dependent noise, the SER performance degrades as the APPR ρ
increases.
7.4
Conclusion
In this chapter, signal processing and optimization issues are addressed for VLC sys-
tems. For multi-chip-based multi-input single-output VLC system, an electric and
optical power allocation scheme is proposed to maximize the multiuser sum-rate
in consideration of the luminance, chromaticity, amplitude, and bit error rate con-
straints. For heterogeneous VLC-WiFi systems, the vertical handover is formulated
as a MDP problem and a dynamic approach is adopted to obtain a tradeoﬀbetween
the switching cost and the delay requirement, thus oﬀering a solution for future indoor
communications that combines VLC to support high-data-rate transmission and RF
to support reliable connectivity. For VLC with narrow FOV, since the PD shot noise
is signal-dependent, novel signal processing and estimation techniques are proposed
to maintain the transmission performance.

237
References
1 D. L. MacAdam, “Visual sensitivities to
color diﬀerences in daylight,” J. Opt. Soc.
Amer., vol. 32, no. 5, pp. 247–273, May
1942.
2 H. Elgala, R. Mesleh, and H. Haas,
“Non-linearity eﬀects and predistortion in
optical OFDM wireless transmission using
LEDs,” Inderscie. Int. J. Ultra Wideband
Commun. Syst., vol. 1, no. 2, pp. 143–150,
2009.
3 G. Wyszecki and W. S. Stiles, Color
Science: Concepts and Methods,
Quantitative Data and Formulae, 2nd ed.
New York: Wiley, 1982.
4 K. H. Park, Y. C. Ko, and M. S. Alouini,
“On the power and oﬀset allocation for rate
adaption of spatial multiplexing in optical
wireless MIMO channels,” IEEE Trans.
Commun., vol. 61, no. 4, pp. 1535–1543,
Apr. 2013.
5 Z. Yu, R. J. Baxley, and G. T. Zhou,
“Multi-user MISO broadcasting for indoor
visible light communication,” in Proc.
IEEE International Conference on
Acoustics, Speech and Signal Processing
(ICASSP) 2013 (Vancouver, Canada), May
26–31, 2013, pp. 4849–4853.
6 H. Flanders and J. J. Price, Calculus with
Analytic Geometry. New York: Academic
Press, 1978.
7 R. Jiang, Z. Wang, Q. Wang, and L. Dai,
“Multi-user sum-rate optimization for
visible light communications with lighting
constraints,” J. Lightw. Technol., vol. 34,
no. 16, pp. 3943–3952, Aug. 2016.
8 S. Boyd and L. Vandenberghe, Convex
Optimization. Cambridge: Cambridge
University Press, 2004.
9 M. Hintermller and K. Kunisch.
“Path-following methods for a class of
constrained minimization problems in
function space,” SIAM J. on Optim.,
vol. 17, no. 1, pp. 159–187, May 2006.
10 M. Grant, S. Boyd, and Y. Ye, “CVX:
Matlab software for disciplined convex
programming,” Jun. 2015,” [online],
http://cvxr.com/cvx/.
11 ANSI NEMA ANSLG C78.376-2001:
Specications for the chromaticity of
ﬂuorescent lamps, ANSI, 2001.
12 ANSI NEMA ANSLG C78.377-2008:
Specications for the chromaticity of solid
state lighting products, ANSI, 2008.
13 A. Ahmed, L. Boulahia, and D. Gaïti,
“Enabling vertical handover decisions in
heterogeneous wireless networks: A
state-of-the-art and a classiﬁcation,” IEEE
Commun. Surv. Tuts., vol. 16, no. 2, pp.
776–811, 2014.
14 J. Hou and D. O’brien, “Vertical
handover-decision-making algorithm using
fuzzy logic for the integrated radio-and-OW
system,” IEEE Trans. Wirel. Commun.,
vol. 5, no. 1, pp. 176–185, Jan. 2006.
15 W. Wanalertlak, B. Lee, C. Yu, M. Kim,
S. M. Park, and W. T. Kim,
“Behavior-based mobility prediction for
seamless handoﬀs in mobile wireless
networks,” Wirel. Netw., vol. 17, no. 3, pp.
645–658, 2011.
16 Z. Huang and Y. Ji, “Design and
demonstration of room division
multiplexing-based hybrid VLC network,”
Chin. Opt. Lett., vol. 11, no. 6, p. 060603,
Jun. 2013.
17 T. Nguyen, M. Chowdhury, and Y. M. Jang,
“Flexible resource allocation scheme for
link switching support in visible light
www.ebook3000.com

238
communication networks,” in Proc.
International Conference on ICT
Convergence (ICTC) 2012 (Jeju, South
Korea), Oct. 15–17, 2012, pp. 145–148.
18 E. Stevens-Navarro, Y. Lin, and V. Wong,
“An MDP-based vertical handoﬀdecision
algorithm for heterogeneous wireless
networks,” IEEE Trans. Veh. Technol.,
vol. 57, no. 2, pp. 1243–1254, Mar. 2008.
19 B. J. Chang, J. F. Chen, C. H. Hsieh, and
Y. H. Liang, “Markov decision
process-based adaptive vertical handoﬀ
with RSS prediction in heterogeneous
wireless networks,” in Proc. IEEE Wireless
Communications and Networking
Conference (WCNC) 2009 (Budapest,
Hungary), Apr. 5–8, 2009, pp. 1–6.
20 C. Sun, E. Stevens-Navarro,
V. Shah-Mansouri, and V. W. Wong, “A
constrained mdp-based vertical handoﬀ
decision algorithm for 4G heterogeneous
wireless networks,” Wirel. Netw., vol. 17,
no. 4, pp. 1063–1081, May 2011.
21 J. Pan and W. Zhang, “An mdp-based
handover decision algorithm in hierarchical
LTE networks,” in Proc. IEEE Vehicular
Technology Conference (VTC Fall) 2012
(Quebec City, Canada), Sep. 3–6, 2012, pp.
1–5.
22 F. Wang, Z. Wang, C. Qian, L. Dai, and
Z. Yang, “Eﬃcient vertical handover
scheme for heterogeneous VLC-RF
systems,” J. Opt. Commun. Netw., vol. 7,
no. 12, pp. 1172–1180, Dec. 2015.
23 D. Bertsekas, Dynamic Programming and
Optimal Control, 4th ed. Athena Scientiﬁc,
Belmont, MA, USA, 2007.
24 S. Ross, Stochastic Processes. John Wiley
and Sons, 1983.
25 J. Wang, R. V. Prasad, and I. Niemegeers,
“Solving the uncertainty of vertical
handovers in multi-radio home networks,”
Comput. Commun., vol. 33, no. 9, pp.
1122–1132, Jun. 2010.
26 A. Tsiatmas, F. M. Willems, and C. P.
Baggen, “The optical illumination
channel,” in Proc. IEEE Symposium on
Communications and Vehicular Technology
in the Benelux (SCVT) 2012 (Eindhoven,
Netherlands), Nov. 16, 2012, pp. 1–6.
27 M. Safari, “Eﬃcient optical wireless
communication in the presence of
signal-dependent noise,” in Proc. IEEE
International Conference on
Communications Workshop (ICCW) 2015
(London, United Kingdom), Jun. 8-12,
2015, pp. 1387–1391.
28 G. K. Froehlich, “Estimation in
signal-dependent noise,” 1980.
29 P. R. Prucnal and B. E. Saleh,
“Transformation of
image-signal-dependent noise into
image-signal-independent noise,” Opt.
Lett., vol. 6, no. 7, pp. 316–318, Jul. 1981.
30 Q. Gao, S. Hu, C. Gong, and Z. Xu,
“Modulation designs for visible light
communications with signal-dependent
noise,” J. Lightw. Technol., vol. 34, no. 23,
pp. 5516–5525, Dec. 2016.

239
8
Optical Camera Communication: Fundamentals
In this chapter, the fundamentals of optical camera communication (OCC) are dis-
cussed. The OCC system employs the pervasive image sensor assembled in con-
sumer electrons as the receiver. It occupies a wide spectrum, and can be easily
built upon pervasive optical light sources and the pervasive consumer cameras, as
discussed in Section 8.1. There are various potential applications, such as indoor
localization, intelligent transportation, screen–camera communication, and privacy
protection, which are introduced in Section 8.2.
To investigate the fundamental problems, including the channel characteristics and
system performance, the pixel-sensor structure and the process during each phase
of its operation for the complimentary metal-oxide-semiconductor (CMOS) image
sensor are discussed in Section 8.3. Besides, the noise compositions, such as photon
shot noise, dark current shot noise, source follower noise, sense node reset noise,
and quantization noise at high illumination are analyzed. Based on the noise model,
a uniﬁed communication model for OCC is derived. Moreover, the OCC channel
capacity under an ideal pixel-matched channel with bounded inputs and intensity
constraints is presented in Section 8.4.
8.1
Why OCC
Recently, OCC emerges as a new form of visible light communication. It employs an
image sensor assembled in consumer electronic devices, such as smartphone, iPad as
a receiver to serve as an alternative to the photodiode (PD) or avalanche photodiode
(APD) based receiver [1, 2]. OCC allows easier implementation of various services
into smart devices. A study group IEEE 802.15.7r1 is dedicated to revision of for-
merly established IEEE 802.15.7 visible light communication (VLC) standard, and
incorporating new physical layers to support OCC functionalities and medium ac-
cess control (MAC) modiﬁcations [3]. The technologies for smart devices have been
developed greatly in the past few years, especially for the smartphones. According to
the 2015 annual Mobility Report from Ericsson, there are 2.6 billion smartphone sub-
scriptions in the world. That number will increase to 6.1 billion by 2020. Moreover,
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.
www.ebook3000.com

240
Figure 8.1 The diagram of the transceiver for optical camera communication (OCC) [4].
the majority of smart devices are equipped with light emitting diode (LED) ﬂash, and
front and/or rear cameras. This opens a possibility of pragmatic form of VLC imple-
mentation based on these devices as a transceiver pair, without additional hardware
modiﬁcations. Therefore, there is a growing interest in VLC implementation using
LEDs and displays for wireless data transmission, and cameras as receivers.
8.1.1
Wide spectrum
According to the proposal of IEEE 802.15.7r1, the wavelength of optical light for
OCC is in the range of 10,000 nm, spanning from infrared (IR) to 190 nm [3], which
is much wider than that for VLC or radio frequency (RF). Adoption of such an un-
regulated and unused spectral region will alleviate the mobile communication traﬃc
congestion. However, only some spectral regions are suitable for optical wireless
communications. For example, the wavelength in the range of 780–950 nm is cur-
rently the best choice for the IR-based communication, and the ultraviolet-C band is
suitable for wide ﬁeld of view (FOV) applications. In the visible light band, VLC
performance may vary with wavelength. The frame rate of many consumer-grade
image sensors is about 30–60 fps, which is suitable for low-rate applications. An
industrial grade image sensor oﬀers a high frame rate of up to millions of frames per
second, which opens a new horizon for high-speed OCC.
8.1.2
Image-sensor-based receiver
A typical OCC system is shown in Fig. 8.1. The signals are modulated in intensi-
ty, color, or time-frequency domain for pervasive optical light sources (illumination
LED, display or traﬃc light). The cameras, which are integrated in pervasive con-
sumer electronic devices, are used as receivers to detect the signals beyond traditional
imaging.
The major driving force of OCC applications stems from the availability of com-
mercial visible light LEDs for data transmission and the possibility of utilizing the
camera in the smart devices to decode signal received from LEDs. The commercial
visible light LEDs are widely deployed in the indoor or outdoor scenarios, which
include LED-based infrastructure lighting, LED ﬂashes, LED tags, displays, image

241
patterns, new generation projectors, traﬃc lights, rear and front lights of vehicles,
roadside luminaries, and other outdoor LED signage. Some LEDs are modulated for
lighting control by pulse-width modulation (PWM) and dimming circuit. They are
probably ﬁrst for fast migration to data transmission applications with slight modi-
ﬁcations. The widespread LED displays are also capable of transmitting non-visual
information, imperceptible to human eyes.
In addition to vastly existing transmitters, an OCC system aims to use camera as a
convenient receiver, which consists of an imaging lens, an image sensor, and a read-
out circuit. The imaging lens projects light onto the image sensor, which is comprised
of multiple PD-based pixels to detect the incident optical (photon) radiation. Each
activated pixel generates a voltage proportional to the number of impinging photons.
It is also connected to an external circuit to convert the pixel voltage into binary da-
ta. According to the readout circuit conﬁguration and exposure mechanism, image
sensor can be classiﬁed into two categories, namely, the global shutter type charge
coupled device (CCD) image sensor and the rolling shutter type CMOS image sensor.
In a CCD image sensor, the global shutter exposes all pixels per frame simultaneous-
ly. However, in a CMOS image sensor, the rolling shutter exposes one row/column of
pixels at a time, and reads out the pixel voltages row-by-row or column-by-column.
Most personal mobile devices or high-end professional camcorders use CMOS im-
age sensors due to excellent performance/cost tradeoﬀs. According to the Grand
View Research’s report about image sensor market [5], CMOS image sensors take
83.8% of market share by 2013, while CCD image sensors take only 16.2%. By
2015, CMOS shipments amount to 3.6 billion units or 97% market share, compared
to CCD shipments of just 95.2 million, or 3% market share. The majority of com-
mercial CMOS image sensors utilize a rolling shutter, while only a few expensive
high-end CMOS image sensors can support global shutter, since the global shutter
is hard to be accomplished with the current CMOS technology. Although these im-
age sensors have their own advantages and disadvantages, it is preferable to use the
CMOS image sensor as the OCC receiver for its high frame rate.
8.1.3
Advantages of image sensor receiver
The image sensor has a high resolution and can classify multiple spatially separated
light sources. It is thus a natural multielement optical receiver. Meanwhile, it has
a multicolor ﬁlter layout and easily separates the blended multicolor lights. There-
fore, it is also a natural multicolor receiver. Moreover, a front optical lens can help
distinguish the light sources in the image sensor and reduce the channel correlation.
These appealing features make the image-sensor-based receiver suitable for imaging
optical multi-input multi-output (MIMO) settings, and are expected to support a huge
number of parallel transmissions.
Pervasiveness: An OCC system uses widespread transmitters and receivers. The
LED screens display arbitrary images of objects. They can be used as transmitters
if they are illuminated by temporally modulated signals. Even the reﬂective surface
illuminated by a signal-carrying light source can be used as the transmitter. The
www.ebook3000.com

242
pervasive camera assembled in the smartphone and iPad, as well as the smartglass
and tachographscan, can serve as an alternative receiver to the PD- or APD-based
VLC receiver.
A multicolor receiver [7]: Usually, a color ﬁlter array (CFA), or color ﬁlter mo-
saic (CFM), is a mosaic of tiny color ﬁlters placed over the pixel sensors of an image
sensor to capture color information. The color ﬁlters ﬁlter the light by wavelength
range, such that the separate ﬁltered intensities contain information about the col-
or of light. Typical CFAs used in image sensor include Bayer ﬁlter, RGBE (red,
green, blue, emerald-cyan) ﬁlter, CYYM (cyan, two yellow, magenta) ﬁlter, CYGM
(cyan, yellow, green, magenta) ﬁlter, and RGBW (red, green, blue, white) Bayer ﬁl-
ter. Due to the Bayer-pattern or Foveon X3 color ﬁlter layout, the image sensor is a
natural multicolor receiver. Figure 8.2(a) shows the Bayer-pattern color ﬁlter, which
contains 25%, 50%, and 25% of red, green, and blue ﬁlters, respectively. Using
such a Bayer-pattern ﬁlter, each pixel produces signal components corresponding to
three colors. One can demodulate the multicolor modulated signal for a pixel-based
receiver. For a Bayer-pattern color ﬁlter sensor, interpolation is required for image-
processing, during which the missing color data is estimated from neighboring pixel
data. However, the pattern images are less sharp than they otherwise could be, due
to undersampling, and optical blurring is introduced due to the lateral displacement
of the color ﬁlters. The Foveon X3 color ﬁlter pattern image sensor can avoid the
drawbacks of the traditional Bayer color ﬁlter pattern. As shown in Fig. 8.2(b), the
Foveon X3 image sensor directly measures red, green, and blue colors at each loca-
tion by stacking color pixels on top of one another, increasing the sampling density
in the image plane. It also enhances sharpness in luminance and chrominance, as
well as robustness to color aliasing artifacts.
(a) Bayer pattern color ﬁlter
(b) Foveon X3 pattern color ﬁlter
Figure 8.2 Color ﬁlter arrays in image sensor.
An optical MIMO receiver [8, 9]: Optical MIMO can help achieve high data
rate by utilizing spatial multiplexing or spatial diversity. However, channel correla-

243
Table 8.1 Typical CFAs in image sensor.
Pattern
Name
Description
Pattern size
GRGB Bayer
ﬁlter
Bayer pattern (green, red, green, blue) CFA is
the most commonly used CFA in image sensor
2 × 2
RGBE ﬁlter
RGBE (red, green, blue, emerald-cyan) CFA can
reduce the color reproduction errors and record
natural images closer to the natural sigh
2 × 2
RGBW ﬁlter
RGBW (red, green, blue, white) CFA allow the
pixel to respond to all colors of light, and more
of light is detected, rather than absorbed
2 × 2
CYYM ﬁlter
CYYM (cyan, two yellow, magenta) CFA would
result in a more sensitive imager (less light
sapping dye over each pixel)
2 × 2
CYGM ﬁlter
A CYGM (cyan, yellow, green, magenta) CFA
uses mostly secondary colors, again to allow
more of the incident light to be detected
2 × 2
tion is a major concern for optical MIMO. Thus, it is not practical to apply MIMO
techniques directly in an optical wireless communication (OWC) system since the
channel condition is very sensitive to transmitter spacing and receiver position. In-
tuitively, an ill-conditioned channel matrix may occur due to homogenous behaviors
of diﬀerent direct current (DC) channel gains. In such a case, the channel matrix
may lose rank or its condition number may be very large. Some methods have been
proposed to reduce the channel correlation. The non-imaging like blocked receiver,
mirror diversity receiver, angle diversity receiver were proposed to reduce the chan-
nel correlation. However, the problem is that the complex receiver structures limit
its practical application. A simple way of decorrelation is to apply channel matrix
pseudo-inversion at the receiver side no matter the channel matrix is rank-deﬁcient
or not. However, it might result in noise ampliﬁcation in commonly encountered
sparse or low-correlation MIMO channels. Singular value decomposition (SVD)-
based spatial multiplexing MIMO is another choice, where the pre-coding matrix
and the combining matrix are adopted at the transmitter and receiver to form paral-
lel channels respectively. For SVD-based optical MIMO, the transceiver design is
based on the assumption that channel state information (CSI) is perfectly known at
the transmitter and receiver. Otherwise, the performance will dramatically degrade
due to imperfect CSI. However, perfect channel estimation is impossible in practi-
cal systems. Moreover, the challenges of uplink provision, CSI feedback, and the
high computational complexity of designing the pre-coding and combining matrix
for massive-MIMO, limit the application of the SVD-based decorrelation method.
For an image-sensor-based receiver, optical lens can help distinguish the images of
www.ebook3000.com

244
LEDs at the image sensor and reduce the channel correlation, which make the image-
sensor-based receiver one of the most eﬃcient ways for optical MIMO systems. Us-
ing a well-designed lens, the imaging receiver can clearly separate the signal from
diﬀerent light sources to achieve omnidirectional receiving and provide high spatial
diversity for decoding of the MIMO signals. Moreover, due to the high resolution
of the modern image sensor, there are millions or even more pixels integrated into a
pixel array. Ideally, every pixel can be used as a receiver unit. Light is emitted from
each light source and then projected onto a detector array, where it may strike any
pixel or group of pixels on the array, and be in arbitrary alignment with them. In
such a way, an image sensor still serves well as an eﬃcient optical MIMO receiver.
An anti-interference receiver [10]: Generally speaking, if a conventional single
PD is used as a receiver in VLC, the system cannot perform well under direct sun-
light or other direct interference light sources, because the FOV of a conventional
PD is wide and the direct interference light is typically strong to overwhelm the de-
sired signal. Furthermore, it is very diﬃcult to reduce the enormous amount of noise
from background light to the desired optical signal level with a wide FOV, even if an
optical band-pass ﬁlter is used. Therefore, when a single element photodiode is used
outdoors, directed linkage with small optical beam divergence is required. On the
contrary, an image sensor is composed of a PD/pixel array with massive number of
available pixels. It is able to spatially separate diﬀerent sources. A series of experi-
ments have illustrated that ambient noise can be eliminated via an image sensor, due
to the spatial ﬁltering and separation. Furthermore, from the noise suppression per-
spective, a tracking algorithm based on image-processing techniques is considerably
easier to implement than those based on mechanical techniques.
8.1.4
Challenges for OCC implementation
Despite various appealing features mentioned above, there are several factors that
make OCC deployment challenging.
Limited frame rate [6]: The transmission speed of an OCC system is inherently
limited by camera’s (or image sensor) frame rate. Most of the consumer electronic
cameras typically operate at 30 fps, which limits the achievable data rate. Exposure
time and frame speed are mutually exclusive parameters aﬀecting signal quality and
data decoding rate. Exposure time has a direct relationship with the frequency of
transmitted signal. This relationship can be understood based on the rolling shutter
camera principle, in which the accumulated photons are collected and read out. In
order to decode data eﬃciently, exposure time should be signiﬁcantly smaller than
transmission refresh frequency of the transmitter. Long exposure time results in a
partial exposure problem in cameras using rolling shutter. Therefore, the received
image will have a reduced contrast between bright and dark bands, which may lead
to bit errors. According to the Nyquist sampling requirement, the receiver-side frame
rate should be twice as fast as the transmitter-side signal rate.
Synchronization [6]: For most of commercial image sensors, the frame rate
is unstable and limited by the manufacturing process and image post-processing.

245
Moreover, the frame rate of commercial image sensor is diverse. If the frame rate
mismatches between transmitter and camera receiver, the synchronization problem
arises for the image-sensor-based receiver. For example, liquid crystal display (LCD)
has a frame rate of 30–60 fps, whist a maximum frame rate of 30 fps is for typical
smart device cameras. Meanwhile, the frame rate of a camera is not constant dur-
ing signal capture due to variable exposure period and software issues relevant to
ﬁrmware and application programming interface (API). During the exposure period,
image sensor pixels get bombarded by light signal, and eventually become saturated.
Saturation of a pixel requires suﬃcient light exposure, which depends on the quan-
tum eﬃciency, ﬁll factor of the image sensor, and the illumination intensity. From the
illumination perspective, the synchronization of the LED-based transmitters diﬀers
from the display-based transmitters. Therefore, diﬀerent exposure time settings in a
camera for two types of transmitters should be controlled manually. The exposure
time also depends on the frequency of the OCC signal transmission. Meanwhile,
both ﬁrmware and API constraints contribute to the variation of camera frame rate.
The frame rate mismatch results in mixed frames or lost frames.
Shot noise [11]: In OCC, the shot noise in photodetectors, originally modeled
by Poisson statistics, is signal-dependent. This is because it originates from the
quantum nature of the received optical energy rather than any external sources of
noise. As the number of received photons increases, the shot noise process can be
well approximated by Gaussian statistics. The channel can be described by an addi-
tive white Gaussian noise (AWGN) model which includes electrical thermal noise as
well as the signal-dependent (caused by the optical signal) and signal-independent
(caused by background light) shot noise. In the image-sensor-based receiver, the
signal-dependent distortions can be typically observed, because the signal-dependent
shot noise is comparable with the background/thermal noise. Typically, an OCC sys-
tem has a high signal-to-noise ratio (SNR) and highly narrow FOV receiver for each
pixel or pixels block-based receiver. The signal-dependent noise model fundamen-
tally changes the problem of eﬃcient signaling compared to the conventional signal-
independent AWGN model in VLC or RF communication. Thus, complex modiﬁ-
cations to signal processing and estimation/detection techniques may be required to
ensure optical data transmission and reception.
Perspective distortions [12]: Perspective distortions depend on the nature of the
camera imaging mechanism and manifest as the deformation in size and shape of
the captured object on the image. They lead to visual compression or magniﬁcation
of the object’s projection on the image. When the transmitter, such as the screen,
is at an out-of-focus distance from the camera lens (or at an oblique angle), these
distortions become prominent and create interference among adjacent screen pixels
on the camera image, termed as inter-pixel interference (IPI). The combined eﬀect
of background noise and IPI degrades the received signal quality and hence reduces
information capacity in camera channels.
Misalignment and blur [13]: Mismatch between the physical size of transmitter
and camera pixels can cause the transmitter misaligned with a camera pixel, even if
the transmitter is at the camera focus. Such misalignment will cause a deviation of
the distortion factor for each pixel as the perspective changes. Meanwhile, some vi-
www.ebook3000.com

246
brations on the pixels are inevitable, especially when the camera is not stable, which
means that the area of misalignment can keep changing with perspective. Such dy-
namic change in perspective arises primarily when the camera is hand-held, due to
handshakes or lateral movements. Misalignment also applies to many more station-
ary scenarios. In such cases, the distortion eﬀect is in the form of blurry and mixed
frames due to motion blur and diﬀraction limited optical subsystem. The blur eﬀect
arises from movement within or between camera frames, and has been well studied
in computer vision literature. The impact of misalignments and lens blur becomes
smaller as one block covers more pixels on the camera and only aﬀects pixels near
the boundary.
Ambient light: Ambient light is a source of interference in OCC. It changes the
luminance at the received pixels and causes decoding errors, resulting in information
loss at the receiver. Especially, the main source of noise is ﬂicker noise, which is
caused by background lighting. If the peak-peak intensity value of ﬂicker noise is
larger than half of the modulation intensity gap, the performance will dramatically
degrade.
The comparisons between OCC and the other short-range communication methods
are concluded in Table 8.2.
8.2
OCC applications: beyond imaging
The image sensor receivers available on today’s mobile devices prompt a new di-
rection of research and applications where VLC can be combined with mobile com-
puting to realize novel forms of sensing and communication applications, which are
discussed in this section.
8.2.1
Indoor localization
Location-based services have been observed tremendous growth in last few years.
Mobile device localization in outdoor scenarios largely depends on Global Position-
ing System (GPS) [14]. On the other hand, accurate indoor positioning can enable
a wide range of location-based services across many sectors. Retailers, supermar-
kets, and shopping malls, for example, are interested in indoor positioning because
it can provide improved navigation for customers to easily locate merchandise or for
customer tracking. The overall demand for indoor positioning in the retail sector is
predicted to grow to $5 billion by 2018.
Despite the strong demand forecast, indoor positioning remains a “grand chal-
lenge”, and no existing system oﬀers accurate location and orientation using unmodi-
ﬁed smartphones. The widely used GPS is not suitable for indoor positioning because
the measurement errors due to signal attenuation, radio disturbance, and multipath
eﬀect will degrade its positioning accuracy.
In the past decade, various indoor positioning approaches have been proposed and

247
Table 8.2 Characteristics of OCC [3].
Comparison Between VLC and OCC
VLC
OCC
Receiver
Photodetector (PD)
Image sensor (Camera)
Interference
High
Low
SNR
Low
High
MIMO Multiplexing
Easy to implement
Diﬃcult to implement
Decoding
Signal processing (low complexity)
Image processing (high complexity)
The Beneﬁts for OCC
Bluetooth
WiFi
VLC
OCC
Interference
Yes
Yes
Yes
Less
Security
High
High
Highest due to LOS
Highest due to LOS
Link Setup
Scan-and-link
Scan-and-link
LOS-Link
Look-and-Link
Protocol
IEEE.802.15.1
IEEE.802.11a & IEEE.802.11b
IEEE.802.15.7
IEEE.802.15.7r1
Frequency Band
2.4 GHz
2.4 /3.6 /5 GHz
Visible light (400–800 THz)
IR, Visible light, UV
Data Rate
800 kbps
11 Mbps
PHY I: 11.67–266.6 kbps
PHY II: 1.25–96 Mbps
PHY III: 12–96 Mbps
Lower than VLC
Enhanced by
• numbers of LEDs
• camera’s resolution
• camera’s frame rate
Cover Range
30 m
46–100 m
Near
Can be extended up to kms
www.ebook3000.com

248
developed, including radio frequency identiﬁcation (RFID), Bluetooth, wireless ﬁ-
delity (WiFi), ultra wide band (UWB), wireless local area network (WLAN), and
ZigBee. Among those alternatives, WiFi-based and other RF-based indoor localiza-
tion have been proven to be attractive where existing WiFi access point (AP) deploy-
ment is leveraged to identify the client’s location. However, due to metope reﬂection
and non-line-of-sight (NLOS) path, the positioning errors of these RF based systems
are up to the order of decimeters or even higher. Although it is low cost, a WiFi-
based indoor localization system oﬀers low accuracy and no orientation information.
Thus it is not ideal for navigation and shelf-level advertising. The complex multipath
cancelation techniques are required to improve the accuracy. Moreover, RF-based
positioning is impossible when RF is prohibited such as in a hospital, airplane, or
coal mine. Those environments avoid interference to the mission-critical electronic
equipment or explosion trigger.
Similar to WiFi-based localization, indoor visible light communication system can
also be leveraged for indoor localization [15]. Typically, multiple LED luminaries are
available each time for triangularization-based positioning. It has been surveyed that
there are 10 times more LED luminaries than the number of WiFi APs in a typical
indoor building. The higher density allows more accurate triangulation of the mo-
bile device, resulting in higher accuracy. Compared with a conventional RF-based
positioning system, a visible light positioning (VLP) system is free of the electro-
magnetic radiation and provides high positioning accuracy. The conventional PDs
and the ubiquitous commercial cameras can be used as receivers. The PD-based VLP
approaches rely on the received signal strength (RSS) or time diﬀerence of arrival
(TDOA) [16]. However, the positioning precision of an RSS method is determined
by the model of source radiation and the PD characteristic. Meanwhile, perfect syn-
chronization among the LED transmitters is required for the TDOA-based positioning
methods.
In recent years, many research groups focus on camera-based VLP, and several
VLP systems have been implemented. In 2003, a positioning beacon system using
digital camera and LEDs was proposed [17]. The LED array is divided into sub-
arrays, and each one has its own visual pattern. High-frequency switching of the
sub-arrays is not noticeable for the human eyes. A digital camera is used as a receiv-
er to capture a sequence of images of the LED-positioning beacon transmitter, and
then location codes are decoded correctly. Another practical VLP system is Luxa-
pose [18]. It leverages the rolling shutter eﬀect of the CMOS camera to decode
location codes, and adopts angle-of-arrival (AOA) to estimate the position of the
camera-based receiver. Luxapose has been shown to achieve localization accuracy
about 0.1 m within 3o orientation error. Similar to Luxapose, an imaging sensor can
be used to receive light signals from multiple luminaries, each of which creates a vi-
sual landmark. In 2014, a light-weight indoor positioning system called PIXEL took
the polarizer to convert unpolarized light into polarized light [19]. It utilizes sin-
gle pixel LCD and a diﬀuser in front of the light source in order to disperse light of
diﬀerent colors of diﬀerent polarizations. Although PIXEL can solve the ﬂickering
problem, the polarizer will reduce the light intensity and degrade the illumination
performance. Even though there is still much room for improvement in a camera-

249
based VLP system, very high accuracy and ability to leverage the existing lighting
infrastructure make it a good candidate for future indoor positioning applications.
8.2.2
Intelligent transportation
As new and revolutionary lighting sources, LEDs are superior to conventional incan-
descent lights due to the low power consumption, long lifetime and low heat gener-
ation. Since LEDs are semiconductor devices and have a short response time, they
are possible to transmit data in conjunction with illumination. Such a feature is well
suited for intelligent transport system (ITS) [20]. ITS can help control the traﬃc jams
and traﬃc accidents with the development of information technology. Widespread
use of LEDs in ITS presents an opportunity for VLC applications, for example, LED
traﬃc light and signs broadcast driving assistance data to cars (road-to-vehicle com-
munications), and LED car brake lights can be used to transmit warning data to a car
behind (vehicle-to-vehicle communications). These systems contribute to exchange
safety information between roadway infrastructures and vehicles.
In the area of ITS, VLC oﬀers several advantages. Since VLC links are visible,
installation of roadside equipment is much easier. Additionally, previously installed
facilities, such as LED traﬃc lights or LED sign boards, can be used as transmitters
or receivers. Furthermore, since the transmitters, or LED light sources, are designed
for illumination, the SNR is high for VLC, and eye safety is maintained for dual-use
lighting. Conventionally, if a single element photodiode is used as a VLC reception
device, the VLC system cannot be used under direct sunlight, especially for wide
FOV cases because the average received power is much higher than that of the desired
signal [10]. Furthermore, it is very diﬃcult to reduce the enormous amount of noise
from background light to the optical signal with a wide FOV, even if an optical band-
pass-ﬁlter is used. Therefore, when a single element photodiode is used outdoors,
narrow optical beam and FOV are required. In some cases, a telephoto can help the
receiver to track the light source, but requires complex mechanical tracking.
Image sensors emerge as new OCC receivers attributed to their multifunctionality,
low manufacturing costs, low power consumption, and a massive number of pixels
to spatially separate sources and ﬁlter out light noise [10]. These sensors also facili-
tate image-processing and accurate tracking, applicable for ITS. The communication
pixels specialized for receiving high-speed optical signals are integrated with ordi-
nary image pixels into a pixel array. The ﬁeld trial results show the novel design of
optical communication image sensor (OCI) [21] enables vehicle-to-vehicle VLC at
a data rate of 10 Mbps.
It is possible that a camera can recognize objects, track their locations, and receive
LED modulated data at the same time. Exploring millions of pixels of an image-
sensor-based receiver, parallel data transmissions can be realized from multiple in-
dividually modulated LED traﬃc lights, traﬃc signs or car brake lights. Moreover,
by using image or video processing to detect and recognize moving vehicles, safety
applications can be integrated. For example, as methods of enhancing driving safe-
ty, collision warning, pedestrian detection, and range estimation for nearby vehicles
www.ebook3000.com

250
are potential candidate functions to be incorporated into the VLC systems. A map
of surrounding vehicles is drawn, showing clearly car-to-car distances, and broad-
casting real-time speeds to the neighbors through the LED headlight and taillight.
Other nearby vehicles receiving this information can adjust their speed accordingly
to maximize the fuel eﬃciency and minimize the chances of collisions. Therefore,
camera-based OCC approach is very attractive for ITS, particularly on congested
highways where the traﬃc density and the resulting contention impose challenges on
traditional RF communications.
Figure 8.3 The application of OCC in intelligent transportation system.
8.2.3
Screen–camera communication
In many occasions, mobile users would like to have quick connections with neigh-
boring users, and exchange messages using device-to-device communications with-
out routing messages through a remote base station in a cellular network. VLC over
a handset screen–camera link has become an attractive short-range wireless commu-
nication solution due to the high availability of camera-equipped smartphones over
the past years [12, 22, 23], where information can be encoded as a stream of images
and displayed in screens of smartphone, laptop, or advertisement boards. Due to the
short wavelengths and narrow beams of visible light, screen–camera links are highly
directional, less interfering, and secure as compared with the RF techniques such as
Bluetooth and WiFi. By controlling the direction, FOV and distance, screen–camera
communication simpliﬁes the complicated authentication process for quickly setting
up link connections. In addition, screen–camera communication is user-friendly. It is
well suited for ﬁle transfer between smartphones when either no wireless connections
are available or security is much concerned. Through analysis and experiments, such
links have been shown capable of achieving hundreds of kbps to Mbps transmission.
Another unique scenario to make screen–camera communication attractive is ser-
vice provision in the area of high user density [12]. For example, in a congested party,
trade fair or business reception, many people would like to exchange brochures, pho-

251
tos or video demos. Traditional RF-based communication performs poorly because
the available spectrum is congested under a large number of user contentions. In con-
trast, the high directionality of screen–camera communication enables a multitude of
such communication links simultaneously without inter-user interference. Besides,
in a public area, such as museum, gallery, or shopping mall, there is an interest in
providing additional information about the displayed objects [12]. For example, in
a gallery or museum, a user may access a video presentation about the artifact the
user is viewing. The screen–camera communication provides additional details or
side-information accompanying the primary video watching.
The performance and capabilities of digital camera and screens improve at a fast
pace and consistently reduced price. Additionally, new technologies such as mi-
crolens arrays provide sophisticated but compact optical capabilities in a signiﬁcant-
ly smaller size. Moreover, with the advent of electronic shutters, industrial grade
image sensors are now able to support up to thousands or even millions of frames
per second. Although a consumer camera supports a range of frame rate from 10
fps to 1000 fps nowadays, the frame rate is increasing continually. Those advantages
make the screen–camera communication a good candidate for future short-range and
convenient communication.
Figure 8.4 The application of OCC in screen–camera communication.
8.2.4
Privacy protection
The basic OCC systems have been developed and implemented, which improve the
visual communication over screen–camera links. However, there exists a security
issue on how to prevent unauthorized users from videotaping a video played on a
screen or a projector [23], whilst not aﬀecting the viewing experience of legitimate
audiences, such as in a cinema or a lecture hall for high-quality display. According to
a survey, over 90% of the illegal online contents are delivered from the pirate movies.
Unauthorized videotaping during the exhibition could cause undesirable informa-
tion leakage. To avoid the copyright piracy issues, many exhibitions have imposed
no-camera policies. Moreover, videotaping a presentation or project demonstration
www.ebook3000.com

252
could also cause the infringement of copyright and even plagiarism. Copyright pro-
tection is becoming increasingly important.
With the rapid spread of camera-enabled mobile devices or wearable devices,
recording video in a cinema or a lecture hall becomes extremely easy and hard to
detect. Traditionally, to protect the copyright, copyright is ﬁrst ﬁled for a digital
property indicating that it is protected by law and unauthorized usage is illegal. Var-
ious technologies have been developed in the industry and research community for
conveying this copyright protection information and/or protecting the digital prop-
erty copyright from being violated, such as the watermarking. Film industry often
implements expensive security strategies or equips guards with night vision goggles
to prevent ﬁlm piracy. Unfortunately, these technologies are ineﬀective in preventing
attendees from taking pirate video for later redisplay. Thus, it is necessary to develop
a universal technology that can be used to protect the video displayed in a variety of
devices from pirate videotaping using typical mobile devices, such as smartphone or
smartglasses, without introducing extra hardware.
In contrast to the existing techniques, which are used to maximize decodability of
screen-camera communication, the copyright system needs to maximize the quality
degradation of the display-camera channel while retaining the quality of the screen-
eye channel [23]. Along this line, one can explore the fundamental diﬀerences among
human vision, video encoding, screen display, and video-recording mechanisms. By
taking advantage of the limited disparities (e.g., the spectral and temporal color mix-
ture, the ﬂicker eﬀect, critical ﬂicker frequency, and rolling shutter) between human
vision and video-recoding, it is possible to develop the techniques for protecting the
copy of the video, and preventing audience from taking a high-quality pirated copy
of the video.
8.3
Fundamentals of OCC
In this section, based on the structure of active pixel sensor (APS) equivalent circuit
and actual communication scenarios, the noise characteristic and channel model are
investigated.
8.3.1
Optical imaging system
An image sensor is one of the most important building blocks in an optical cam-
era based system [24, 25]. The block diagram of an imaging system architecture is
shown in Fig. 8.5. First, the source radiation is focused on the image sensor using
the imaging optics. The image sensor comprising a two-dimensional array of pixels
converts the light incident at its sensitive area into an array of electrical signals. To
perform color imaging, a CFA such as Bayer pattern color ﬁlter array or Foveon X3
pattern color ﬁlter array is typically deposited in a certain pattern on the top of the
image sensor array. The converted electrical signals are read out and digitized by an

253
analog-to-digital converter (ADC). To recover a full color image with Bayer pattern
color ﬁlters, spatial interpolation process known as demosaicking is needed. Further
digital signal processing is performed as white balancing and color correction to di-
minish the adverse eﬀects of faulty pixels and imperfect optics. Other processing
and control operations are also included for performing autofocus, auto-exposure,
and general camera control. All these components of an imaging system determine
the overall performance together. However, it is the image sensor that often limits
the ultimate performance.
Figure 8.5 The imaging system pipeline.
8.3.2
Image sensor architecture
An image sensor consists of an array of pixels. Each pixel contains a photodiode
that converts incident light into photocurrent and then the photocurrent is converted
into electric charge or voltage by some readout circuits [26]. The percentage of area
occupied by the eﬀective photodiode in a pixel is known as ﬁll factor. The rest of the
readout circuits is located at the periphery of the array and multiplexed by the pixels.
An array includes about tens of megapixels for high-end applications, where the size
of each pixel is about 1.22 μm × 1.22 μm to 7.5 μm × 7.5 μm. A microlens array
is typically deposited on the top of the pixel array to increase the ﬁll factor and allow
more light incident on each photodiode in certain exposure time. Figure 8.6 shows
anatomy of the CMOS image sensor and APS photodiode, respectively.
Since the mid-1960, combinations of p-n or n-p-n junction have been used to con-
vert optical light into electrons, and read the signal out from the arrays of pixels.
The earliest solid-state image sensors were the bipolar and MOS photodiode arrays.
Afterwards, CCDs quickly became the dominant ones. The research on CMOS im-
age sensors started in the mid-1980s, and the passive pixel sensor (PPS) became
the alternative technology for CMOS image sensor in the early 1990s [27]. How-
ever, since typical sizes of the available CMOS technologies were too large and it
was impossible to accommodate more than a single transistor and three interconnect
lines in a PPS pixel, thus, the ﬁll-factor was lower for CMOS image sensor. Because
of the need for transistors, the pixels read out, and ampliﬁcation, the PPS CMOS
www.ebook3000.com

254
Figure 8.6 The structure of a CMOS image sensor.
image sensors have much lower performance than CCDs, which limits their appli-
cability to low-end machine-vision applications. The ability to produce CCD image
sensor with the necessary number of pixels for application gave CCDs a big advan-
tage over CMOS image sensor. However, improvements in CMOS fabrication tech-
nology and increasing pressure to reduce power consumption for battery-operated
devices began the re-emergence of CMOS as a viable imaging device. It is gener-
ally regarded that the ﬁrst all-CMOS sensor array to produce acceptable images is
the APS image sensor [28]. The APS design uses the linear integration method for
measuring light because of the large output signal generated. By adding an ampli-
ﬁer to each pixel, it can signiﬁcantly increase sensor speed and improve SNR, thus
overcoming the shortages of PPS. With the advent of deep submicron CMOS and
integrated microlens technologies, APS has made CMOS image sensor a viable al-
ternative to CCD sensor. While CMOSs and CCDs continue to compete for a share
of the image sensor market, the ability to design customized integrated circuits with
photodetectors to perform speciﬁc functions is an enormous advantage over CCD
image sensor. Taking further advantage of technology scaling, the digital pixel sen-
sor (DPS) integrates an ADC in each pixel [29]. The DPS architecture oﬀers several
advantages over an analog image sensor. These include better scaling with CMOS
technology due to reduced analog circuit performance demands, and the elimination
of read-related column ﬁxed-pattern noise (FPN) and column readout noise. More
signiﬁcantly, massive parallel conversion and digital readout provide very high-speed
readout, which makes it possible to enhance the sensor’s dynamic range (DR) via
programming ]j`iqhpelha sampling.
For these two widely used image sensors in cameras for microscopy, namely the
CCD image sensor and CMOS image sensor, there are a number of similarities be-
tween these two technologies. But one major distinction is the way each sensor reads
the signal accumulated at a given pixel. Figure 8.7 shows the readout architectures
of CCD and CMOS image sensors. In a CCD image sensor, every pixel is exposed
simultaneously at the same time, and the charge is shifted out of the array via vertical
and horizontal CCDs, converted into a voltage via a simple follower ampliﬁer, and
then serially read out. In a CMOS image sensor, charge voltage signals are read out
(a) CMOS image sensor anatomy
(b) APS photodiode anatomy

255
(a) CCD image sensors
(b) CMOS image sensors
Figure 8.7 Readout architectures of interline transfer of diﬀerent image sensors [26].
www.ebook3000.com

256
row-by-row similar to a random access memory using row and column selection cir-
cuits. Each readout architecture has its advantages and shortcomings, as presented
in Table 8.3.
The main advantage of the CCD readout architecture is minimal pixel overhead,
making it possible to design an image sensor with very small pixel sizes [26]. More-
over, the charge transfer is passive and therefore does not introduce temporal noise or
pixel-to-pixel variations due to device mismatches, known as FPN. The CCD how-
ever has an inherent disadvantage when frame rate is of concern. When the expo-
sure is complete, the signal from each pixel is serially transferred to a single ADC.
The CCD’s ultimate frame rate is limited by the rate that individual pixels can be
transferred and then digitized. The more pixels to transfer in a sensor, the slower
the total frame rate of the image sensor. It also has high power consumption due to
the need of high-rate and high-voltage clocks to achieve near-perfect charge transfer
eﬃciency. By comparison, the random access readout of CMOS image sensors pro-
vides the potential of high-speed readout and window-of-interest operations at low
power consumption [26]. A CMOS chip enhances the frame rate performance by
using an ADC for every column of pixels up to the thousands. The total number of
pixels digitized by any converter is signiﬁcantly reduced, enabling shorter readout
times and consequently faster frame rates. Meanwhile, there are many parallel AD-
Cs sharing the workload, the entire sensor array must still be converted one row at
a time. This results in a small time delay between each row’s readout. Nowadays,
the frame rate reaches hundreds of frames per second for a commercial image sensor
and even millions of frames per second for an industrial grade image sensor with
high resolution. Other diﬀerences between CCD image sensors and CMOS image
sensors arise from diﬀerences in their fabrication technologies. CCDs are fabricated
by specialized technologies solely optimized for imaging and charge transfer. Con-
trol over the fabrication technology also makes it possible to scale pixel size down
without signiﬁcant degradation in performance. The disadvantage of using such spe-
cialized technologies, however, is the inability to integrate other camera functions on
the same chip with the sensor. CMOS image sensors, on the other hand, are fabricat-
ed by mostly standard technologies, and thus are ready to integrate with other analog
and digital processing and control circuits. Such integration further reduces imaging
system power and size, and enables the implementation of new sensor functionalities.
8.3.2.1
Pixel-based photodetection
The core of the sensing element of a CMOS detector is the photosensitive element
of the circuit. Photogates, phototransistors, and photodiodes all can be used as the
sensing elements. The photodiode is simply a junction between a p-type and a n-type
semiconductor, commonly known as a p-n junction. Although a simple p-n junction
can be used for light detection, the more advanced p-i-n junction with an intrinsic
region between the p-type and n-type is often used to improve the device eﬃciency.
In an APS, a photodiode is usually made by forming an n-type region on a p-type
semiconductor substrate, or vice versa. This can be realized by epitaxial growth,
diﬀusion, or ion implantation.

257
Table 8.3 Comparison between CCD and CMOS image sensors.
Attributes
CCD Image Sensor
CMOS Image Sensor
Electronic shutter
Global shutter
Rolling shutter
Sensor noise
Low
High
Dark current
Low
High
SNR
High
Comparatively low
Fill factor
100%
< 100%
Integration capability
Low
High
Power consumption
High
Low
Cost
High cost
Low cost
Frame rate
Comparatively low speed
High speed
The two important metrics that are used to characterize the eﬀectiveness of detec-
tion by a photodetector are external quantum eﬃciency (QE) and dark current. Ex-
ternal QE is the fraction of incident photo ﬂux that contributes to the photocurrent
in a PD as a function of wavelength. It is typically combined with the transmittance
of each color ﬁlter to determine its overall spectral response. External QE can be ex-
pressed as the product of internal QE and optical eﬃciency (OE). Internal QE is the
fraction of photons incident on the PD surface that contributes to the photocurrent,
which mainly depends on PD geometry and doping concentrations and eo always
less than 1 for silicon-photodetector. OE is the photo-to-photo eﬃciency from the
pixel surface to the photodetector’s surface. The geometric arrangement of the PD
with respect to other elements of the pixel structure, i.e., shape and size of the aper-
ture, length of the dielectric tunnel, position, shape and size of the PD, also aﬀects
OE [30]. Experimental evidence shows that OE can have a signiﬁcant role in de-
termining the resultant external QE, and eventually determining the pixel response
function (PRF) or modulation transfer function (MTF) for image sensor. Figure 8.8
shows the 2-D MTF for pixel-based photodetector with diﬀerent shapes of active
area. It demonstrates that diﬀerent geometrical shapes of the pixel active area will
signiﬁcantly inﬂuence the PRF or MTF.
The second important characteristic of the photodiode is its leakage or dark cur-
rent. Dark current is the photodiode current when no illumination is present. One
kind of the dark current under reverse bias is caused by saturation current. On the
boundaries of the depletion region, minority carriers can diﬀuse into the depletion
region, causing saturation current. Apart from the diﬀusion contribution to the dark
current, carriers that are generated by thermal excitation inter-band trap (defect) states
in the depletion region contribute to the dark current. The generated dark current is
also contributed by other sources, including surface leakage current, Frankel–Poole
current, and impact ionization current. It is noted that the dark current is detrimental
to imaging performance under low illumination, as it introduces shot noise which is
uniformly distributed over sensor array and cannot be corrected [26]. In CCDs, the
www.ebook3000.com

258
(a) Detector with diﬀerent shaped active area
(b) Rectangular (A = B = 40 μm)
(c) L Shape (A = B = 40 μm, a = b = 20 μm)
(d) Rhomb (A = B = 40 μm)
(e) Hexagonal (D = 40 μm)
Figure 8.8 2-D MTF for the image sensor detector with diﬀerent shape active areas.

259
high-resistivity wafers can be used to minimize traps from metallic contamination as
well as buried channels, and multiphase pinned operations can be used to minimize
surface generated dark current. Dark current in the standard submicron CMOS pro-
cess is the order of magnitude higher than that in a CCD. Fortunately, several process
modiﬁcations are employed to reduce the dark current nowadays.
8.3.2.2
PPS, APS, and DPS architectures
There are diﬀerent forms of readout architectures in CMOS image sensor, including
the PPS, which is the earliest CMOS image sensor architecture, the three, four and
ﬁve transistors (3T, 4T, and 5T) per pixel APS, which are the most popular architec-
tures at present, and DPS, which includes a photodiode and an ADC for each pixel.
The main advantage of PPS is its small pixel size. The column readout, however, is
slow and vulnerable to noise and disturbances. The APS and DPS architectures can
solve these problems with more transistors in each pixel.
Each of the APS architectures has its advantages and disadvantages. The 3-T APS
pixel includes a reset transistor, a source follower transistor and a row select transis-
tor. The current source component of the follower ampliﬁer is shared by a column of
pixels, and the readout is performed on one row at a time. A 4-T pixel is either larger
or has a smaller ﬁll factor than a 3-T pixel implemented with the same technology.
The 4-T APS architecture employs a pinned diode, which adds a transfer gate and a
ﬂoating diﬀusion (FD) node to decouple the read and reset operations from the inte-
gration period, enabling true correlated double sampling (CDS). Moreover, in a 4-T
pixel, the capacitance of the FD node can be selected independently of the photodi-
ode size, allowing conversion gain to be optimized for the sensor application. The
5-T APS pixel adds a transistor to tackle the blooming issue and provide reset opera-
tion for photodiode. By appropriately setting the gate voltage of the reset transistor in
an APS pixel, the blooming eﬀect, which is the overﬂow of charge from a saturated
pixel into its neighboring pixels, can be mitigated. However, since more transistors
and more complex control circuit are needed, the ﬁll factor will be reduced.
DPS is the third and more advanced CMOS image sensor architecture, where ADC
is performed locally at each pixel, and digital data is read out from the pixel array
in a manner similar to a random access digital memory. The advantages of DPS
over analog PPS and APS, include simplicity, scalability, on-chip processing, lower
power consumption, wide dynamic range, the reduced read-related column FPN, and
readout noise. More signiﬁcantly, employing an ADC and memory at each pixel
enables massive parallel analog-to-digital conversion and high-speed digital readout
processes, providing a potential of high frame rate. The main drawback of DPS is
that more transistors per pixel are needed, resulting in larger pixel size and lower ﬁll
factor [26].
www.ebook3000.com

260
(a) PPS
(b) 4T-APS
(c) DPS
Figure 8.9 Schematic of a CMOS pixel sensor.

261
(a) CCD
(b) CMOS
Figure 8.10 PFN noise for CCD and CMOS image sensors.
8.3.3
Noise characteristics in the image-sensor-based receiver
In general, ambient noise, temporal noise, and FPN are the main fundamental and
technology related noises in CMOS image sensor. Temporal noise is the dominant
noise in the image sensor, which is generated in pixel during each phase of its oper-
ation. Sources of temporal noise include photodetector shot noise, pixel reset circuit
noise, readout circuit thermal and ﬂicker noise, and quantization noise. In addition
to temporal noise, CMOS image sensor also suﬀers from FPN, which is the pixel-to-
pixel output variation under uniform illumination due to the device and interconnect
mismatches across the image sensor array.
In this part, we analyze the sources of noise in a typical APS during each phase
of its operation, including photon-to-charge operation, charge-to-voltage operation,
and voltage-to-digital signal operation, as shown in Fig. 8.11. Moreover, the nonlin-
earities are also taken into account [4, 32].
From photon to charge
In pixel sensor, the photon-capturing process has an uncertainty that arises from ran-
dom ﬂuctuations when photons are collected by the photodiode, which will induce
photon shot noise. The shot noise can be described by the Poisson distribution in a
low light level, and can be approximated by a Gaussian distribution [33] in the case
of a high light level. Denote the average number of photons Iphoton collected by a
single pixel during unit integration time as
Iphoton = round
Iirrad · Ap
Ep

,
(8.1)
where Iirrad is sensor’s irradiance with units of [W/m2], Ap is the area of a pixel
sensor, Ep =
h·c
λ is the energy of a single photon at the wavelength λ, and h is
Planck’s constant. The photon shot noise corresponding to this pixel sensor can be
www.ebook3000.com

262
Figure 8.11 The diagram of the photosensor model.
modeled as a Poisson process P with mean λph
Iphoton,shot = P(λph),
where λph = Iphoton.
(8.2)
Then, the collected photons during exposure time tint, including the shot noise, are
converted to electrons Ie−for each pixel as
Ie−= QE · Iphoton · tint = Iph · tint,
(8.3)
where QE is the quantum eﬃciency [e−/incident photons] for the given wavelength,
and it indicates the ability of a semiconductor to produce electrons from incident
photons.
The photo response nonuniformity (PRNU) is the spatial variation in pixel output
under uniform illumination mainly due to the variation in substrate material during
the fabrication of the photodiodes. Moreover, the PRNU is signal-dependent and
ﬁxed-pattern (time-invariant) according to amounts of experimental measurements.
The PRNU can be modeled as Gaussian distribution as
IPRNU,e−= Ie−+ Ie−· N(0, σ2
PRNU),
(8.4)
where σPRNU is the PRNU factor value.
The dark current is inevitable in pixel sensor. It is induced by the thermally gener-
ated electrons that discharge the pixel, together with the surface defects and imper-
fections of the semiconductor manufacturing process. The average dark current Idc
[e−/sec/pixel] can be characterized by
Idc = ApIFMT 3/2 exp
−Egap
2kBT

,
(8.5)
where IFM [nA/cm2] is the dark current ﬁgure-of-merit at 300 K, T is the temperature
in K, kB is the Boltzman’s constant, and Egap [eV] is the band gap energy of the
semiconductor which varies with temperature.

263
When pixel exposure begins, a dark current is generated even if there is no light.
The longer the integration time tint, the stronger the dark signal Sdark,e−(number of
electrons per pixel), which can be modeled as
Sdark,e−= Idc · tint.
(8.6)
The dark signal Sdark,e−varies from pixel to pixel. It is linear with the integration
time and doubles with every 6–8oC increase of temperature. Measurements are con-
ducted at the room temperature +25oC. Moreover, since the electrons are generated
randomly, the dark signal Sdark,e−is a subject of dark current shot noise, which is due
to the random arrival of the generated electrons and therefore described by a Poisson
process as
Idark,shot,e−= P(λdark,e−), where λdark,e−= Sdark,e−.
(8.7)
In a practical sensor, pixels cannot be manufactured exactly the same, and there
will be the variations in the photodetector area that are spatially uncorrelated. Con-
sequently, the average dark signal is not uniform but has a spatial-random and ﬁxed
pattern noise structure, which is called dark current ﬁxed pattern noise. The dark cur-
rent FPN can be modeled as log-normal distribution in the case of short integration
time [32].
Idark,FPN,e−= Idark,shot,e−
1 + lnN(0, σ2
dark,FPN,e−)),
(8.8)
where
σdark,FPN,e−= ξdark,FPN · Idc · tint,
(8.9)
and ξdark,FPN is the average dark current FPN factor that is typically 0.1, · · · , 0.4 for
CMOS and CCD sensors.
In most of the commercial CMOS sensors, the source follower noise is signiﬁcant
and should be included in a photosensor model. The source follower noise generated
due to the source follower ampliﬁer has a resistance that generates thermal noise,
imperfect contacts between two materials at the junction, moreover the random trap-
ping and emission of mobile charge carriers resulting in discrete modulation of the
channel current. The variance of source follower noise [e−rms] can be expressed as
σSF ≈
fclock
f=1 SSF(f) · HCDS(f)
ASN · ASF(1 −exp[−ts/τD]),
(8.10)
where SSF(f) is the power spectrum of the noise, HCDS(f) is the CDS transfer func-
tion, fclock is the readout clock frequency, ASN is a sense node conversion gain, ASF
is a source follower gain, ts is the CDS sample-to-sampling time, and τD is the CDS
dominant time constant and usually related to ts as τD = 0.5ts. Using parame-
ters provided in the speciﬁcations of the image sensor, we can model this Gaussian
distribution source follower noise as
ISF,e−= round
.N(0, σ2
SF)
/.
(8.11)
www.ebook3000.com

264
From charge to voltage
The process of charge–voltage conversion is performed as follows. The light signal
Ilight,e−contains photon shot noise and the PRNU
Ilight,e−= Ie−(1 + N(0, σ2
PRNU)).
(8.12)
The dark signal Idark,e−consists of dark current shot noise and dark current FPN. It
can be expressed as
Idark,e−= Idark,shot,e−
1 + lnN(0, σ2
dark,FPN,e−)
.
(8.13)
Then total number of electrons Itotal,e−is a result of the light signal Ilight,e−, dark
signal Idark,e−, and source follower noise ISF,e−which are summed together and
rounded
Itotal,e−= round(Ilight,e−+ Idark,e−+ ISF,e−).
(8.14)
After that, the number of electrons Itotal,e−is truncated to the full well (the maximum
number of electrons in the pixel) and rounded. Then electron–voltage conversion is
applied to convert the electrons to voltages by multiplying the sense node conversion
gain GSN. Speciﬁcally, the charge–voltage conversion uses the sense node gain ASN
[V/e−] as a parameter in the range of 1 μV/e−to 5 μV/e−. The conversion from
charge to voltage is performed in the sense node as follows
VSN,V = Vref −Itotal,e−· ASN,
(8.15)
where VSN,V is the sense node voltage, and Vref is the reference voltage.
Prior to measuring each pixel’s charge packet, the sense node capacitor is reset to
a reference voltage level. Noise is generated at sense node by an uncertainty in the
reference voltage level, which is called reset noise and is a signiﬁcant contributor to
dark noise. The variance of reset noise can be expressed as
σreset =

kBT
CSN
,
(8.16)
where CSN is the sense node capacitance [F]. Moreover, the reset noise may be per-
formed as an addition to non-symmetric distribution to the reference voltage Vref,
and its distribution depends on sensor’s architecture and the reset technique. Here,
log-normal distribution is used to model the reset noise for soft-reset techniques, as
VSN,reset,V = lnN(0, σ2
reset).
(8.17)
Noteworthily, when the reset noise exists, the reference voltage in (8.15) should be
modiﬁed as
Vref,new = Vref + VSN,reset,V.
(8.18)

265
After that, the sense node voltage is multiplied by the source follower gain ASF
[V/V] as
VSF,V = VSN,V · ASF.
(8.19)
In particular, for a CMOS image sensor, pixels in the same column of the photo-
sensor share a column ampliﬁer. Diﬀerences in the gain and oﬀset of these column
ampliﬁers contribute to a column-wise oﬀset ﬁxed pattern noise. The oﬀset FPN ap-
pears as “stripes” in the received image, which will signiﬁcantly degrade the system
performance, but can be suppressed by the noise reduction circuits.
In nowadays image sensors, the noise reduction circuits such as CDS circuits are
employed to eliminate or reduce the FPN and reset noise, as illustrated in Fig. 8.12.
The CDS circuits consist of two sample-and-hold circuits. During the pixel read-out
cycle, two samples are taken: the ﬁrst when the pixel is in reset state and the second
when the charge has been transferred to the read-out node [26]. During the reset
stage, the photodiode capacitance is charged to a reset voltage. The reset voltage is
read by the ﬁrst sample-and-hold in a CDS circuit. Then the exposure begins: the
photodiode capacitor is discharged during an integration time at a rate proportional to
the incident illumination. This voltage is then read by the second sample-and-hold
of the CDS. The CDS circuit subtracts the signal pixel value from the reset value.
Although the dark current FPN and reset noise can be removed by CDS in CCD
sensors, it is diﬃcult to remove them in CMOS image sensors even after application
of CDS. Moreover, CDS can suppress oﬀset FPN and reset noise but increases the
read noise power.
Figure 8.12 System diagram of correlated double sampling.
From voltage to digital numbers
ADC is employed to transform the voltage signal into discrete codes and the accuracy
of output gray value corresponding to the voltage signal is determined by the reso-
lution of ADC, which indicates the number of discrete values that can be produced
www.ebook3000.com

266
over the range of analogue value as
KADC = VADC,ref −Vmin
Nmax
,
(8.20)
where VADC,ref is the maximum voltage, Vmin is the minimum quantiﬁable voltage,
and Nmax = 2N is the number of voltage intervals. Therefore, the output of an ADC
can be expressed as
ADCcode = round
VSF,V −Vmin
KADC

,
(8.21)
where VSF,V is the total voltage signal accumulated by the end of the integration time
and conversion, as in (8.19).
Due to the ﬁnite precision in an ADC, the quantization error is inevitable. The
probability distribution of quantization noise is generally assumed to be uniform.
Denote qADC as the quantizing step of the ADC, the variance of quantization noise
can be expressed as
σ2
ADC = q2
ADC
12 ,
(8.22)
where q = 2−b, and (b + 1) is the ADC bit.
Communication SNR for OCC
Diﬀerent from the noise and SNR deﬁned in image processing, in this part we analyze
the noise from the communication perspective at a high illumination level. Gener-
ally speaking, intensity-modulated direct-detection (IM/DD) is commonly used in
OCC due to its practical simplicity. The input signal modulates the optical intensity
of the emitted light, which is transmitted to the receiver over a free space link. The
input signal is proportional to the light intensity and is nonnegative. The pixel, be-
ing basically a power-detecting unit, responds to the instantaneous ﬁeld count rate
process produced from the receiver area. Its output appears as shot noise process
whose count rate is proportional to the instantaneous received power. The noise in
the received signal is caused by several eﬀects. First, the exact number of arriving
photons at the pixel-based receiver during a given integral time is a random process
and is modeled by the mentioned Poisson distribution with a rate proportional to the
input signal power. Second, the signal is corrupted by the noise from the background
radiation. Third, the received signal is impaired by the signal-dependent noise. Note-
worthily, other FPNs except PRNU are not damage factors for a ﬁxed single pixel or
pixel-group-based communication receiver, because these FPNs are time-invariant
and signal-independent. Moreover, the read noise is another source noise in OCC,
which is a combination of the remained noise generated between the photodiode and
the output of the ADC circuitry.
The received intensity signal before being converted into electrons can be ex-
pressed as
Ry = hX + Rback,
(8.23)

267
where X is the nonnegative input signal and is proportional to the light intensity, h
is the channel gain, and Rback is the received intensity due to background light radi-
ation. For an ideal pixel-matched case, if we only consider the OCC system suﬀers
from aforementioned types of noise, but ignore the generalized optical or electrical
interference, then the channel gain can be assumed as h = 1. The converted electri-
cal signal can be expressed as
Y = X + Zshot + ZPRNU + Zread,
(8.24)
where X is the desired input signal, Zshot is the shot noise including the photon
shot noise and dark current shot noise, and ZPRNU is the PNUN noise. Zread is the
read noise, which contains any noise that is not a function of the signal, and is a
combination of the remaining noise generated between the photodiode and the output
of the ADC circuitry, consisting of sense node reset noise, source follower noise and
ADC quantization noise. Assuming CDS is performed, part of the reset noise can be
eﬀectively cancelled. Then, we can quantify the communication SNR at the end of
integration as
SNROCC =
E{X2}
σ2
shot + σ2
prnu + σ2
read
,
(8.25)
where the power of the desired signal is given by
E{X2} = (Iphtint)2.
(8.26)
The shot noise variance is given by
σ2
shot = q[Iph + Iback + Idc]tint,
(8.27)
where Iback is the current induced by background radiation. Moreover, only the PR-
NU is considered in pixel-based receiver with the variance of
σ2
prnu = σ2
PRNU[(Iphtint)2 + (Ibacktint)2].
(8.28)
The read noise, which consists of reset noise, source follower noise, and ADC quan-
tization noise, has the variance of
σ2
read = q2(σ2
reset + σ2
SF + σ2
ADC).
(8.29)
As mentioned above, SNR is a function of photocurrent, pixel area, integration
time, and so on. In addition, one can leverage the spatial diversity to improve SNR
by grouping multiple pixels into a block to map one transmitter. Assuming B pixels
in the block, the average output gray value for this block is Y =
1
B
B
i=1 Yi. By
grouping multiple pixels as a block receiver, the noise will be reduced by spatial aver-
aging. Thus, the pixels block receiver can support diﬀerent SNR transmissions with
diﬀerent block sizes. In the following, we analyze SNR with diﬀerent parameters.
Table 8.4 lists the key speciﬁcations of the typical image sensor used in simulations.
www.ebook3000.com

268
Table 8.4 The key image sensor speciﬁcations.
Manufacture process
CMOS
PRNU factor
0.6%–1%
Pixel size
3.75 μm × 3.75 μm
Dark current FPN factor
1%
Number of pixels
1080 × 720
Column oﬀset FPN factor
0.1%
Wavelength λ
550 nm
Dark current ﬁgure of merit
1.00 nA/cm2
Fill factor
55%
Sense node gain
5.00 μV/e−
Quantum eﬃciency
65%
Read nose σread
30 e−
Full well
60,000 e−
ADC bit
12 bit
10
10
10
11
10
12
10
13
10
14
−20
−10
0
10
20
30
40
50
Incident Photons (1/cm2)
SNR (dB)
1.4 μm × 1.4 μm
1.75 μm × 1.75 μm
2.2 μm × 2.2 μm
2.8 μm × 2.8 μm
3.75 μm × 3.75 μm
5.6 μm × 5.6 μm
6.5 μm × 6.5 μm
7.5 μm × 7.5 μm
Figure 8.13 SNR in OCC with diﬀerent pixel size areas.
10
−16
10
−15
10
−14
10
−13
10
−12
−40
−30
−20
−10
0
10
20
30
40
50
Photocurrent Iph (A)
SNR (dB)
tint = 1 ms (1000 fps)
tint = 4.16 ms (240 fps)
tint = 8.33 ms (120 fps)
tint = 16.67 ms (60 fps)
tint = 33.33 ms (30 fps)
tint = 50 ms (20 fps)
tint = 100 ms (10 fps)
Figure 8.14 SNR in OCC with diﬀerent integration time.

269
Figures 8.13–8.14 show the SNR in OCC with diﬀerent areas of pixel and integra-
tion time. We set pixel area Ap = 3.75 μm × 3.75 μm, and integration time tint =
33.3 ms in simulation if they are not speciﬁed. It can be seen that SNR increases
with the photocurrent Iph. First, SNR increases 20 dB as photocurrent increases 10
dB when readout noise and dark current shot noise dominate for small photocurrent.
SNR increases 10 dB as photocurrent increases 10 dB when shot noise dominates.
Further increase of photocurrent leads to signiﬁcant PRNU, and SNR ﬂattens out.
The achieved maximum SNR roughly approaches the well capacity before satura-
tion. Moreover, SNR increases with pixel area and integration time. However, even
the pixel size is scaled down to 1.4 μm × 1.4 μm, SNR remains 17–37 dB when the
average incident photon density is about 1012–1014/cm2 as shown in Fig. 8.13. Most
commercial CMOS image sensors provide frame rate exceeding 30 fps. For example,
iPhone 7 supports 240 fps, and the frame rate of some special image sensor can be
even up to 1000 fps. According to the simulation results shown in Fig. 8.14, SNR
can range from 25 dB to 38 dB in OCC systems under a general parameter setting,
even the frame rate exceeds 200 Hz.
10
−16
10
−15
10
−14
10
−13
10
−12
−10
0
10
20
30
40
50
60
70
Photocurrent Iph (A)
SNR (dB)
B = 1 × 1
B = 3 × 3
B = 6 × 6
B = 9 × 9
B = 12 × 12
B = 15 × 15
B = 18 × 18
B = 21 × 21
Figure 8.15 SNR in OCC with diﬀerent block size.
To improve communication SNR in OCC, a potential solution is to leverage the
diversity structure by grouping multiple pixels into a block receiver to map the same
transmitter, as in RF-MIMO. Figure 8.15 shows SNR with diﬀerent pixel block sizes.
It can be seen that SNR can dramatically increase with the pixel block size or diversity
order. When the pixel block size is 3 × 3, 6 × 6, or 9 × 9, SNR in these blocks can
be improved by about 9.5 dB, 15.6 dB, and 19 dB compared with 1 × 1 pixel block
when photocurrent is Iph = 10−13 A. However, as the pixel block size continues to
increase, SNR improvement slows down. It is seen that even the block pixel-based
detection with diversity structure can obtain higher SNR and support higher capacity,
the eﬀective data throughput for imaging MIMO system with spatial multiplexing is
degraded since the number of parallel channels is reduced. Thus, the diversity gain
is smaller than the multiplex gain in pixel-matched case for imaging MIMO system.
www.ebook3000.com

270
8.3.4
Channel model for OCC
Figure 8.16 The equivalent system model for CMOS image-sensor-based OCC.
The system diagram for image-sensor-based OCC can be modeled as the space
and linear shift-invariant system (LSI) [34]. As shown in Fig. 8.16, f(x, y) is the
intensity distribution for light sources in aperture plane of the optical lens group.
MTFopt(u, v) is the modulation transfer function for the diﬀraction limited opti-
cal subsystem, MTFsensor(u, v) is the MTF for the CMOS image sensor, which
is determined by the geometrical shape of the active area MTFdet(u, v) and pix-
el sampling MTFsamp(u, v), charge diﬀusion MTFdiﬀ(u, v), and charge collection
eﬃciency MTFcte(u, v). MTFrecon(u, v) is the MTF for the imaging processing
subsystem such as interpolation, color transformations, and is usually assumed to be
MTFrecon(u, v) = 1 to simplify the analysis. The equivalent model for the whole
CMOS image-sensor-based receiver can be expressed as
MTFsys(u, v) = MTFopt(u, v) · MTFdet(u, v)·
MTFsamp(u, v) · MTFdiﬀ(u, v) · MTFcte(u, v).
(8.30)
In line-of-sight (LOS) OCC communication links, pointing accuracy is an impor-
tant factor for link performance and reliability. However, the relative motions be-
tween transceiver result in random optical beam sways, which in turn cause pointing
error and signal fading at the receiver. In the following, we will discuss the fac-
tors which contribute to the pointing error or pixel-mismatch, including the optical
interference induced by the diﬀraction limited optical subsystem, electrical interfer-
ence due to carrier diﬀusion, spatial nonideal condition such as linear misalignment
or geometry perspective distortion, and the jitter variance [37]. However, the uniﬁed
statistical channel model for OCC with pointing errors is still unavailable. Moreover,
since the light sources are diverse, diﬀerent light sources have diﬀerent radiation pat-
terns, such as Lambertian radiation, batwing-type radiation, and side-emitting radia-
tion. For the widely used LEDs, to make a general and an accurate radiation pattern,
the emitting surfaces (chip, chip array, or phosphor surface), the light redirected by
both the reﬂecting cup and the encapsulating lens must be taken into account [38].
Diﬀraction limited optical subsystem (on-axis image irradiance)

271
Imperfect focusing or blur eﬀect will degrade the OCC performance. The blur eﬀect
is attributed to the camera lens and more formally termed as lens-blur. Lens-blur
causes the received light energy to spread to areas outside the pixel, where the spread
range depends on the type of lens. Lens-blur can be viewed as a low-pass ﬁlter that
suppresses the high-frequency components in the image, such as edges and high-
contrast regions. To simplify the analysis, we assume that ideal lens is used in the
image sensor and the radial distortion and eccentricity distortion need not be taken
into account. Actually, a camera lens usually consists of 15 or more optical elements
in sequence, which have diﬀerent thicknesses and focal lengths and are unevenly
spaced along the optical axis. The combination of these elements is typically chosen
to make fabrication more cost-eﬀective, the size of the optical system smaller, and
some of the aberrations mitigated. However, there still lacks an optical model which
consists of a variable number of thin lens with diﬀerent distances from one another
and diﬀerent focal lengths. Fortunately, the equivalent single thick-lens model is
nearly identical to the ideal thin-lens model, with a non-negligible lens thickness
Dlens and a focal length as
1
fc
=
1
Dfoc-img
+
1
Dobj −Dlens
.
(8.31)
For example, if the aperture lens area is assumed to be circular with diameter d,
the PSF for the equivalent thick-lens system can be calculated as [33]
fopt = 2π
λfc
 d/2
0
rJ0
πrρ
λfc
dr =
 πd2
4λfc
2J1(πdρ/λfc)
πdρ/λfc
,
(8.32)
where ρ =

x2 + y2 and J0(x) and J1(x) are Bessel functions.
Carrier diﬀusion induced crosstalk in CMOS image sensors
The optical beam or optical distribution is also aﬀected by the carrier diﬀusion or
electrical crosstalk. In [39], a uniﬁed MTF model for CMOS image sensor is pro-
posed. The sensor is built on the epitaxial layer, which is deposited on a substrate
layer and presents a doping gradient. As shown in Fig. 8.18, the charge diﬀusion and
sampling aperture are taken into account in the uniﬁed model as
MTFsensor(u, v) = MTFdiﬀ(u, v) · MTFgeom(u, v),
(8.33)
where MTFgeom is determined by the pixel sampling active area and geometrical
shape, MTFdiﬀis derived by solving the steady-state diﬀusion equation based on
the Fourier transform [39]. The MTF model due to sampling aperture geometry
MTFgeom(u, v) = MTFdet(u, v)·MTFsamp(u, v) for a square shape pixel is given
by
MTFgeom(u, v) = sinc(aπu) · sinc(bπv),
(8.34)
where a, b are the sensitive widths of APS along the x direction and y direction.
Then, the PSF in the spatial domain is the 2-D spatial inversion Fourier transform
www.ebook3000.com

272
(a) The elements of an example camera lens
(b) The equivalent ideal thick-lens model
Figure 8.17 Diﬀraction limited optical subsystem.

273
of the MTF. Without loss of generality, fsensor(x, y) can be modeled as a Gaussian
ﬁlter [11] as
fsensor(x, y) =
1
2πσ2
sensor
e
−x2+y2
2σ2sensor ,
(8.35)
where σ2
sensor is determined by sensitive width, substrate, charge diﬀusion, and CMOS
structure.
Figure 8.18 Geometrical model of CMOS image sensor by Ibrahima Djite [39].
Pointing error model
Taking both source radiation pattern, diﬀraction optical subsystem and charge diﬀu-
sion into account, the spatial distribution of the optical intensity in the pixel-based
receiver can be expressed as
Ibeam(ζ) = Isource(θ) ∗fopt ∗fsensor,
(8.36)
where ∗denotes 2-D convolution, and Isource(θ) denotes the source radiation pattern
with irradiance angle θ. Considering that most commercial image sensors adopt
square detection, with a dimension of (c, d) as shown in Fig. 8.19(a), the attenuation
of geometric spread with pointing vector r is expressed as
hp(r) =

A
Ibeam(ζ −r)dζ,
(8.37)
where hp(·) represents the fraction of the power collected by the detector and A
is the detector area. When a pointing error of r is present, hp is a function of
the radial displacement and the angle [40, 41]. Assuming the radial displacement
vector at the receiver aperture plane as r = [rx ry]T, where rx and ry denote
www.ebook3000.com

274
the displacements along the horizontal and elevation axes at the detector plane, re-
spectively. In general, the rx and ry, both follow a nonzero mean Gaussian dis-
tribution, i.e., rx ∼N(μx, σ2
x), ry ∼N(μy, σ2
y), then the radial displacement
r = ∥r∥=

r2x + r2y follows the Beckmann distribution [41]:
fr(r) =
r
2πσxσy
×
 2π
0
exp

−(rcosφ −μx)2
2σ2x
−(rsinφ −μy)2
2σ2y

dφ.
(8.38)
Note that, the Beckmann distribution is a versatile model to describe the point error,
leading to a variety of models. For example, when μx = μy = 0, σx = σy, the
Beckmann distribution is equivalent as Rayleigh distribution. When μx = μy = 0,
σx ̸= σy, then the Beckmann distbution is equivalent as Hoyt distribution.
Combining (8.37) and (8.38), the channel fading due to beam spread and point
error can be expressed as
hp =
 c/2
−c/2
 d/2
−d/2

r>0
Ibeam(x, y, r)fr(r)drdydx.
(8.39)
As for the imaging optical MIMO case with a large single-aperture pixel-based
receiver, the PDF of pointing error is similar to the single-input single-output (SISO)
case. However, the diﬀerence is that the symmetrical light array should be assumed
as an equivalent beam shape with uniform distribution. Figure 8.19 demonstrates the
detector and beam footprint for transmitter and pixel-based detector plane for SISO
and MIMO cases, respectively.
(a) SISO-OCC
(b) MIMO-OCC
Figure 8.19 Detector and beam footprint for transmitters with misalignment and
inter-pixel-interference in the pixel-based detector plane.
Channel statistical model with generalized point error
The probability distribution of channel state h can be expressed as
fh(h) =

r>0
ArI(θ)
d2
· Ts(ψ) · g(D, fc, r, ψ) · cosψ · fr(r, I, D, fc)dr,

275
(8.40)
where d denotes the distance between LED source and focal plane, Arcosψ is the
eﬀective collection area of the detector, ψ is the incident angle and smaller than
the detector FOV Ψc, Ts(·) is the transmission of optical lens, g(D, fc, r) is the
concentrator of gain with lens thickness D and focal length fc, and fr(r, I, D, fc)
denotes the channel fading due to pointing error.
8.4
Capacity bounds for OCC
8.4.1
SISO-OCC channel capacity with M-SDGN
In the pixel-matched case, we only consider the mentioned front-end noise sources,
but ignore the generalized optical and electrical interference and the alignment error.
Then, the converted electrical signal in (8.24) from a pixel readout circuit can be
rewritten as
Y = X + XZ2 +
√
XZ1 + Z0.
(8.41)
Here, X = Iphtint is the desired electrical signal and is proportional to the channel
input. Z0 ∼NR(0, σ2) is the signal-independent Gaussian noise, including shot
noise contributed by background light and dark current, background light induced
PRNU, and read noise. Z1 ∼NR(0, ς2
1σ2) and Z2 ∼NR(0, ς2
2σ2) are both the
signal-dependent noise, which is contributed by input signal induced shot noise and
PRNU, respectively. The parameter
σ2 =q(Idc + Iback)tint + σ2
PRNU(Ibacktint)2
+ q2(σ2
reset + σ2
SF + σ2
ADC)
(8.42)
describes the strength of the signal-independent noise, where Iback is the current in-
duced by background radiation. Parameters ς2
2, ς2
1 are the ratio of the input-dependent
noise variance ς2
2σ2, ς2
1σ2 to the input-independent noise variance σ2, respectively.
Here, Z2, Z1 are assumed to be independent of Z0.
The conditional PDF of this mixed-signal-dependent Gaussian noise (M-SDGN)
channel is given by
fY |X(y|x) =
1

2πσ2(1 + ς2
2x2 + ς2
1x)
e
−
(y−x)2
2σ2(1+ς2
2 x2+ς2
1 x) ,
x ∈R+, y ∈R.
(8.43)
Further, due to safety and practical consideration, the input signal has a peak intensity
(amplitude) and nonnegative constraint as
Pr[0 ≤X ≤A] = 1,
(8.44)
www.ebook3000.com

276
and an average intensity constraint as
E[X] ≤P.
(8.45)
We use ρ to denote the average-to-peak-power ratio (APPR) as
ρ ≜P
A.
(8.46)
Note that the input signal is proportional to the light intensity. Thus the power con-
straint is imposed on the signal itself, instead of its square as in RF communications.
The capacity bound can better reﬂect the physical channel properties and ultimate
communication performance. In the following, we will focus on this Gaussian chan-
nel with M-SDGN, and present the capacity with bounded inputs and intensity con-
straints. The channel model (8.41) is a special case of the general signal-dependent
Gaussian noise (SDGN) channel model. Unfortunately, the channel capacity of this
M-SDGN channel is unknown, and it is diﬃcult to apply the sphere-packing method
or the dual expression approach. However, following similar arguments as in [42–
46], it has been proven that the mutual information function is a concave, continu-
ous, and weakly diﬀerentiable function over a compact and convex space of input
distribution [4]. Thus, invoking the Karush–Kuhn–Tucker (KKT) Theorem results
in suﬃcient and necessary conditions for the capacity-achieving input distribution.
There is a unique optimal input distribution F0, which achieves maximum mutual
information. Finally, it can be proven that the capacity-achieving distribution for this
M-SDGN channel is discrete with ﬁnite number of mass points from the complex
analysis. The result is given in the following theorem.
Theorem 1. C is achieved by a random variable, denoted by X0 with probability
distribution function F0 ∈FX, i.e.,
C =
max
FX∈FX I(FX) = I(F0),
(8.47)
for some F0 ∈FX. A suﬃcient and necessary condition for F0 to achieve capacity
is
iF0(x) ≤I(F0), ∀x ∈[0, A].
(8.48)
Furthermore, this distribution is discrete and consists of ﬁnite number of mass
points if some conditions on (1 + ς2
2x2 + ς2
1x) hold.
With the aforementioned theorem showing a ﬁnite number of mass points for ﬁnite
A and P, we can use the search algorithm to ﬁnd the optimal input distribution and
the corresponding maximum mutual information for such constrained channel.
8.4.2
Capacity-achieving probability measurement with M-SDGN
The capacity-achieving probability distribution for the M-SDGN channel as in (8.41)
subject to optical intensity constraints is discrete and nonuniform. It can be expressed

277
as
fX(x) =
N

n=1
pnδ(x −xn),
(8.49)
where N is the modulation order, pn is the probability mass point with N
n=1 pn =
1, and xn ∈[0, A], (xn < xn+1) is the intensity/amplitude mass point.
The capacity-achieving distribution for OCC channels under amplitude constraints
is discrete and nonuniform. This distribution can be computed numerically by solv-
ing a complex non-linear optimization problem. In this problem, the mutual infor-
mation is maximized over the input distributions with all constraints fulﬁlled. The
amplitude mass point xn, probability mass point pn, and modulation order N are
free parameters in the optimization problem. Eﬃcient numerical optimization tech-
niques can be applied to solve this problem and provide numerical solutions for the
input distribution and channel capacity at diﬀerent SNRs and APPR. In 2005, Chan
et al. derived a necessary and suﬃcient condition for capacity-achieving probability
measure [45]. Using this necessary and suﬃcient condition, they proposed an algo-
rithm to ﬁnd the capacity-achieving measure of a signal-dependent optical channel,
which is traditionally diﬃcult to analyze.
Theorem 2. (Necessity and Suﬃciency) : Let F0 be an admissible input probability
measure, i.e., F0 ∈FX. Let H(x) = HF0(Y |X) = 1
2log(2πeσ2) + 1
2E
.
log(1 +
2ς2
2x2 +ς2
1x)
/
. Then, F0 is capacity achieving if and only if there exists λ ≥0 such
that for all x ∈[0, A]
Q(x; F0) −H(x) −IF0(X; Y ) −λ(x −P) ≤0,
(8.50)
where Q(x, F0) = −
 ∞
∞fY |X(y|x)logfY (y; F0)dy.
Proposition 1. Suppose F0 is the capacity-achieving measure for the optical channel
with M-SDGN with amplitude constraints as in (8.41). Then x = 0 is a point of
increase of F0.
Corollary 1. If F0 is capacity achieving for channel (8.41) with amplitude con-
straints, and it satisﬁes (8.50), then
λ =
.IF0(X; Y ) −Q(0; F0) + 1
2log(2πeσ2)
//P,
where P is the average optical power. For each n ∈{2, 3, · · · }, let τ (n) be an input
probability measure in FX that maximizes IFX(X; Y ) and has n or fewer points of
increase.
Above theorem ensures a ﬁnite number of mass points of capacity-achieving input
distribution. Using an approach similar to [45], the capacity-achieving measure of
this channel can be found via the following search algorithm.
Search algorithm for capacity-achieving measures [45]
www.ebook3000.com

278
• Step 1: Set n = 2;
• Step 2: Solve for τ (n);
• Step 3: Let λ(n) =
.I(τ (n)) −Q(0; τ (n)) + 1
2log(2πeσ2)
//P. If λ(n) < 0,
increase n by 1 and go back to step 2;
• Step 4: Verify whether the inequality Q(x; τ (n)) −I(τ (n)) −H(x) −λ(n)(x −
P) ≤0 holds for all x ∈[0, A]. If so, then τ (n) is capacity achieving. Otherwise,
increase n by 1 and go back to step 2.
0
0.02
0.04
0.06
0.08
0.1
0
2
4
6
8
10
0
0.1
0.2
0.3
0.4
0.5
ς2
2σ2
X
Probability
Figure 8.20 Capacity-achieving distribution for signal-dependent noise channel
(P = 4, A = 10, ς2
1σ2 = 100ς2
2σ2).
Figure 8.20 shows the computed capacity of the capacity-achieving distribution
for the M-SDGN channel using this algorithm, where x-axis denotes the values of
ς2
2σ2, y-axis denotes the input signal, and z-axis denotes the probability. If a point
is indicated at the position (ς2
2σ2, x∗), then x∗is an amplitude mass point and the
probability value is the probability mass point for optimal distribution. The simu-
lation results demonstrate that x = 0 and x = A are always the amplitude mass
points in optimal input distribution. It has been proven in Proposition 1 that x = 0
is always an amplitude mass point. However, it is not clear whether x = A is also an
amplitude mass point. Moreover, the distance between two neighboring amplitude
mass points varies signiﬁcantly, which means that the optimal input distribution is
nonuniform distribution.
Based on the redeﬁned SNR and channel model, the capacity bounds for this M-
SDGN channel can be derived using the aforementioned search algorithm to ﬁnd the
capacity-achieving input distribution and the corresponding channel capacity. Fig-
ure 8.21(a) shows the capacity results for single-pixel receiver-based OCC with peak
and average-intensity constraints. It is observed that the capacity increases as the

279
10
−16
10
−15
10
−14
10
−13
10
−12
0
1
2
3
4
5
6
7
8
9
Photocurrent Iph (A)
Capacity (bit/s/Hz/pixel)
Only with Peak Intensity Constraint
ρ = 0.5
ρ = 0.15
(a) Capacity bounds for OCC with optical intensity constraints under an
ideal channel
10
−16
10
−15
10
−14
10
−13
10
−12
0
2
4
6
8
10
12
Photocurrent Iph (A)
Capacity (bit/s/Hz/block)
B = 1 × 1
B = 6 × 6
B = 12 × 12
B = 18 × 18
(b) The capacity bounds for OCC with diﬀerent pixel block size under an
ideal channel. Blue color-solid line (only peak intensity constraint), green
color-dash dot line (ρ = 0.5), fuchsia color-dash line (ρ = 0.15)
Figure 8.21 Capacity bounds for OCC.
www.ebook3000.com

280
photocurrent gets larger. Moreover, the capacity bound increases as the APPR ρ
becomes larger, especially when ρ = 1 which corresponds to the case with peak
intensity constraint only. The channel can support 7.1 bit/s/Hz per pixel when pho-
tocurrent is Iph = 10−13 A, corresponding to SNR of 37 dB as in Fig. 8.14. More-
over, Fig. 8.21(b) shows the capacity bounds for a block-pixel receiver with diﬀerent
sizes under peak and average intensity constraints. It demonstrates that the channel
capacity can be further improved by grouping multiple pixels into a block, and in-
creases as the pixel block size increases. About 10.8 bit/s/Hz per block is possible
when block size is B = 18 × 18 and photocurrent is Iph = 10−13 A with gener-
al parameter settings. As the pixel block size increases, the capacity improvement
slows down.
8.4.3
Capacity of imaging optical MIMO systems with bounded inputs
Generally, the indoor VLC systems are vulnerable to obstacles (shadowing). If di-
rectionality is oﬀset, the system performance may dramatically degrade. Moreover,
the high-data-rate parallel optical interconnects with low bit error rate (BER) typi-
cally require precise alignment. The optical MIMO technique allows the alignment
to be achieved in electrical domain as it is not necessary for light from a source to
strike a signal detector precisely. Therefore, the motivation for using optical MIMO
in VLC is not only for capacity increase, but to alleviate the diﬃculty in achieving
alignment physically by using electrical signal processing. However, it is diﬃcult to
apply the spatial-multiplexing MIMO scheme in an indoor VLC intensity channel
with a dominant LOS link. Otherwise, a highly correlated channel matrix prevents
from decoding the received signals in parallel at the receiver [48]. Optical MIMO can
help to achieve high data rate by utilizing spatial diversity, but channel correlation is
a major concern, and is sensitive to transmitter spacing and receiver position. Intu-
itively, ill-conditioned channel matrix may occur due to homogenous behaviors with
diﬀerent channel DC gains, which implies that the channel matrix is not full-rank or
the condition number is very large.
As shown in Fig. 8.22, in order to reduce the correlation between the sub-channels
in the channel matrix, various advanced receiver structures have been proposed. A
simple way to decorrelate is to apply channel matrix pseudo-inversion at the receiver
no matter whether the channel matrix is rank-deﬁcient or not [8]. However, the prob-
lem is that these methods might result in noise ampliﬁcation if some singular values
of the channel matrix are very small. In [49], the non-imaging link-blocked receiver
(LBR), spatially separated receiver (SSR) and the power imbalance between trans-
mitters were proposed to reduce the channel correlation. However, the challenges
are that the link-block is diﬃcult to implement in practice by adaptively reﬂecting
the change of blocking area, due to the user mobility and location changement, the
larger receiver size, and limited performance improvement for SSR receiver. Re-
cently, the mirror diversity receiver (MDR) was proposed to block the reception of
light in one speciﬁc direction, and improve the channel gain in other directions by
receiving the light reﬂected from a mirror between the PDs [48]. The problem is that

281
the complex receiver structure limits its practical application. More recently, another
advanced receiver, i.e., the angle diversity receiver (ADR) has been proposed to vary
the orientation angles of PDs, so that the incident light from the speciﬁc direction can
not reach the receiver plane or is directed out of the receiver FOV [50, 51]. However,
these angle diversity receivers are bulky and impractical to incorporate hand-held
devices. For imaging receivers, optical lens can help distinguish the light source im-
ages and reduce the channel correlation. This makes the imaging receiver to be one
of the most eﬃcient ways to implement optical MIMO. In [52, 53], the hemispherical
lens and ﬁsheye lens-based imaging receivers for VLC MIMO were proposed. They
project the optical intensity signals onto the receiver PD array, yielding partial and
complete separated light images. Consequently, a well-conditioned channel matrix
and signiﬁcant spatial diversity were achieved.
(a) Mirror diversity receiver
(b) Angle diversity receiver
(c) Cubic diversity receiver
Figure 8.22 Non-imaging MIMO receivers.
An important performance metric is the channel capacity, which speciﬁes the high-
est rate of reliable information transmission over the imaging optical MIMO chan-
nel. In [11], Hranilovic et al. discussed the basic structure of channel model and
capacity for the pixelated-MIMO. Exactly, the noise was modeled as SDGN and the
channel was modeled as a 2-D Gaussian ﬁlter from prototype experimental mea-
surement and data ﬁtting. As for the channel capacity, they estimated the channel
capacity by sphere-packing argument [54, 55] and water-pouring. However, the ca-
pacity contains only the on-axis case and does not take the optical intensity con-
straint into account. Ashok et al. predicted the OCC capacity under lens diﬀraction
and perspective distortion [56]. However, the OCC channel was simply modeled as
an additive input-independent Gaussian noise channel and interference was treated
as noise. Thus the presented capacity is not very accurate. In [57], the upper and
lower bounds on the capacity of constant parallel OWC channel with a total aver-
age intensity constraint were derived. Even though the parallel MIMO system was
considered, the crosstalk between signals from diﬀerent transmitters was neglected.
In fact, electrical crosstalk and optical crosstalk are inevitable between pixels due
to charge diﬀusion in APS [39], and diﬀraction limited optical subsystem in an im-
age sensor. In [9], a modiﬁed SVD method was proposed. They applied coordinate
system transformations on correlated channels to generate simultaneous independent
links and maximize the capacity of the imaging optical MIMO channel while main-
www.ebook3000.com

282
taining the target illumination. Moreover, the upper bound on capacity of the imaging
SVD-VLC MIMO system was presented. These studies are still far more complete,
and on-going research is necessary.
In the following, we consider the capacity of imaging optical MIMO channel with
bounded inputs and total average intensity constraint. Unfortunately, extending the
results of Smith in [43] to vector random variables is unattainable since the Iden-
tity Theorem cannot be directly applied. The theorem has shown strength for one-
dimensional functions, but ineﬃciency in holomorphic function of several complex
variables in a higher dimension space. In [58], the upper and lower bounds on the ca-
pacity of MIMO system with amplitude-limited inputs were derived by considering
an equivalent channel via SVD, and by enlarging and reducing the corresponding fea-
sible region of the channel input vector. Moreover, it demonstrates that the capacity-
achieving distribution of an input-bounded vector Gaussian channel remains to have
a ﬁnite number of discrete amplitudes [59, 61]. Following the arguments above, we
ﬁrst transform the coupled imaging optical MIMO channel into independent parallel
channels, and then derive the capacity bound achieved using an exponential distribu-
tion or discrete input distribution. If CSI is available at the transmitter, the bounds
have to be optimized with respect to intensity allocation over the parallel channels.
Note that, the availability of channel-state-information-at-the-transmitter (CSIT) is
not a strong assumption in OCC, whose coherence time is typically much larger than
the symbol duration. Thus, estimation and feedback of the CSI can be achieved in
negligible time without considerably aﬀecting performance. Furthermore, in a full-
duplex system, CSI can be estimated directly at the transmitter if channel reciprocity
applies [57].
8.4.3.1
Imaging optical MIMO system
The schematic diagram of the imaging optical MIMO system is shown in Fig. 8.23.
In this system, M LED arrays provide indoor illumination and transmit signals using
spatial multiplexing. An imaging receiver with well-designed lens is used to receive
the optical signal. Light propagates from each transmitter array to the receiver as
before, and each LED array is projected onto a detector array, where images may
strike any pixel or group of pixels on the array, and be in arbitrary alignment with
them. Each pixel on the detector array is a receiving element. We use matrix H to
describe the optical connection between each pixel or pixel block and each transmitter
LED array. With a well-designed lens, the imaging receiver can clearly separate
the signals from diﬀerent LEDs, achieve omnidirectional receiving and provide high
spatial diversity for decoding of the MIMO signals. The received vector signal is
given by
Y = HX + Z,
(8.51)
where X = [X1 X2 · · · XM] is the input signal vector whose element should
satisfy the non-negative constraint and total average intensity constraint ||P ||1 ≤P,
where Pi = E(Xi), i ∈{1, 2, · · · , M}. H is an N × M channel matrix whose
entry hn,m ≥0 represents the channel gain from mth transmitter to nth receiver,
Y is the received signal vector, and Z is the Gaussian noise vector of independent

283
Figure 8.23 Diagram of the imaging optical MIMO system.
components for simplicity. The imaging optical MIMO channel H can be expressed
as
H =
⎡
⎢⎢⎢⎣
h1,1
h1,2
· · ·
h1,M
h2,1
h2,2
· · ·
h2,M
...
...
...
...
hN,1
hN,2
· · ·
hN,M
⎤
⎥⎥⎥⎦.
(8.52)
8.4.3.2
Capacity of imaging optical MIMO systems
Consider bounded inputs and power constraints. Extending the results of Smith to
vector random variables is unattainable since conditions required by the Identity The-
orem are not satisﬁed [58, 59]. The SVD technique mentioned above can be applied
under certain conditions, but does not impose any form of nonnegativity and power
constraints. Thus a modiﬁed SVD-MIMO method is needed to maximize the data
rate while maintaining the target power constraint. The imaging optical MIMO chan-
nel matrix H can be decomposed into rotation and scaling matrices using SVD as
H = UΛV ∗,
(8.53)
where U and V are unitary rotation matrices while Λ is a diagonal scaling matrix.
Matrices H and Λ have the same rank Γ ≤min(M, N). The diagonal elements
of Λ, (λ1, · · · , λk, · · · , λΓ) are the singular values of matrix H. The transmitted
signal is constructed as
X ≜V S + B,
(8.54)
where B ∈RM is a DC oﬀset vector and S ∈RM is the information-bearing
symbols. The symbol of the codeword satisﬁes Si ∈[−Ai, Ai] for any Ai > 0 and
www.ebook3000.com

284
E[Si] = 0. Since E[Si] = 0, then E[Xi] = Bi = Pi. To guarantee non-negativity
of X, it is required that Pi = M
i=1 |vi,j|Aj, where vi,j is the (i, j)th component
of V .
At the receiver, upon receiving Y , the receiver is ﬁrstly subtracted by HB and
then multiplies the signal by U ∗, and we have
U ∗Y = ΛS + U ∗Z.
(8.55)
Deﬁne the new variable in rotated coordinate system as
˜Y ≜U ∗Y ,
˜Z ≜U ∗Z,
(8.56)
where ˜Y and ˜Z are output and noise for the transformed system. The transformed
simultaneous independent parallel link models are described by
˜Yk = λkSk + ˜Zk, 1 ≤k ≤Γ.
(8.57)
Then, the overall capacity lower bound is given by
C(H, P) = max
A∈A
Γ

i=1
r(λi, Ai),
(8.58)
which is to be maximized with respect to Ai subject to
N

i=1
M

j=1
|vi,j|Aj ≤P.
(8.59)
Note that, r(λi, Ai) in (8.58) is the achievable rate or capacity bound over channel
i using a DC-oﬀset input signal with peak-constrained input (peak 2P).
8.5
Outage capacity for OCC with misalignment
For practical OCC communication, pointing accuracy is an important issue in de-
termining link performance and reliability. However, the relative motions between
transceivers result in random optical beam sways, which in turn, cause pointing er-
rors and signal fading at the receiver. In this case, availability of CSIT cannot be
assumed. For such a system with no CSIT, and under a quasi-static channel, the ca-
pacity in the strict Shannon sense is zero. Performance, in this case, is captured by
the outage probability [37, 57].
Since the typical time scale of the OCC fading process is much smaller than the
bit transmission interval, it is realistic to model the OCC channel as a slow-fading
channel. Then, the availability of CSIT is not a strong assumption. Channel can
be estimated by transmitting a training sequence, and sent back from the receiver
through a feedback link [37, 57]. Two scenarios are considered for transmission over

285
slow fading channels, either utilizing a ﬁxed or a variable rate at the transmitter. Here,
the ﬁxed rate scenario is considered. For a given ﬁxed transmission rate, there is a
ﬁnite probability that the transmitted rate exceeds the instantaneous mutual informa-
tion of the channel, leading to an outage event. The outage event is mathematically
described by the probability of outage. Since each data rate has a corresponding
probability of outage, the pair of rate and outage probability are used together to
describe the outage capacity.
In the SISO case, the instantaneous mutual information R(h) at given SNR(h)
associated with channel gain h and input distribution fX(x) is
R(h) = I(X; Y |H = h).
(8.60)
The received SNR(h) is random and given as
SNR(h) =
(Ph)2
σ2(1 + ς2
1hP + ς2
2h2P 2),
(8.61)
where P is the average signal intensity. The outage probability for a slow-fading
channel with pointing error for intensity-modulation signaling can be computed using
fh(h) = fhp(hp). Then the outage probability at a given rate R0 can be expressed
as
Pout(R0) = Prob(R(h) < R0).
(8.62)
Note that R(h) monotonically increases with h. The above expression is simpli-
ﬁed as
Pout(R0) = Prob(h < h0),
(8.63)
where h0 satisﬁes R(h0) = R0.Therefore, the outage probability is the cumulative
density function of h evaluated at h0 and is expressed as
Pout(R0) =
 h0
0
fh(h)dh.
(8.64)
The derivation of outage capacity for an imaging optical MIMO channel is similar
to SISO case. We can study the capacity upper bounds with pointing errors and the
probability distribution of the pointing error is incorporated into the fading channel.
8.6
Conclusion
As a new form of VLC, OCC employs the pervasive image sensors in consumer elec-
tronics as the receivers, and optical light sources (illumination LED, display or traﬃc
light) as the transmitters. Image sensors are the natural multicolor, optical MIMO
and anti-interference receivers, as well as a high-resolution object detector. Various
www.ebook3000.com

286
challenges involved in an OCC system are addressed, including the limited frame rate,
synchronization issue, shot noise eﬀects, perspective distortions, pixel misalignment,
and blur eﬀect. Then, the channel characteristics and system performance, the pixel
sensor structure, and the process during each phase of the sensor operation are dis-
cussed in detail. Besides, diﬀerent noise sources are analyzed. Based on the noise
model, the SNR, and a uniﬁed communication model for OCC are derived. More-
over, the OCC channel capacity under an ideal pixel-matched channel with bounded
inputs and intensity constraints is presented. Preliminary study shows that capac-
ity of 8–11 bit/s/Hz is possible under an ideal channel with a diversity structure.
Combined with mobile computing, OCC has realized novel forms of sensing and
communication applications, such as indoor localization, intelligent transportation,
screen–camera communication, and privacy protection.

287
References
1 P. H. Pathak, X. Feng, P. Hu, and
P. Mohapatra, “Visible light communication,
networking, and sensing: A survey, potential
and challenges,” IEEE Commun. Surv. Tuts.,
vol. 17, no. 4, pp. 2047–2077, Fourth
Quarter 2015.
2 N. Saha, M. S. Ifthekhar, N. T. Le, and Y. M.
Jang, “Survey on optical camera
communications: Challenges and
opportunities,” IET Optoelectron., vol. 9,
no. 5, pp. 172–183, May 2015.
3 “The ieee 802.15.7r1 study group,” [online],
http://www.ieee802.org/15/pub/IEEE%20802
_15%20WPAN%2015_7%20Revision1%20
Task%20Group.htm.
4 W. Huang and Z. Xu, “Characteristics and
performance of image sensor
communication,” IEEE Photon. J., vol. 9,
no. 2, pp. 1–19, Apr. 2017.
5 “Image sensors market analysis,” [online],
http://www.grandviewresearch.com/industry-
analysis/imagesensors-market.
6 W. Hu, H. Gu, and Q. Pu, “Lightsync:
Unsynchronized visual communication over
screen-camera links,” in Proc. International
Conference on Mobile Computing &
Networking 2013 (Miami, FL), Sept. 30–Oct.
4, 2013, pp. 15–26.
7 W. Huang, P. Tian, and Z. Xu, “Design and
implementation of a real-time CIM-MIMO
optical camera communication system,” Opt.
Exp., vol. 24, no. 21, pp. 24567–24579, Oct.
2016.
8 L. Zeng, D. C. O’Brien, H. Le Minh, G. E.
Faulkner, K. Lee, D. Jung, Y. Oh, and E. T.
Won, “High data rate multiple input multiple
output (MIMO) optical wireless
communications using white led lighting,”
IEEE J. Sel. Areas Commun., vol. 27, no. 9,
pp. 1654–1662, Dec. 2009.
9 P. M. Butala, H. Elgala, and T. D. Little,
“SVD-VLC: A novel capacity maximizing
VLC MIMO system architecture under
illumination constraints,” in Proc. IEEE
Global Communications Conference
(GLOBECOM) Workshops 2013 (Atlanta,
GA), Dec. 9–13, 2013, pp. 1087–1092.
10 T. Yamazato, M. Kinoshita, S. Arai,
E. Souke, T. Yendo, T. Fujii, K. Kamakura,
and H. Okada, “Vehicle motion and pixel
illumination modeling for image sensor
based visible light communication,” IEEE J.
Sel. Areas Commun., vol. 33, no. 9,
pp. 1793–1805, Sept. 2015.
11 S. Hranilovic and F. R. Kschischang, “A
pixelated MIMO wireless optical
communication system,” IEEE J. Sel. Topics
Quantum Electron., vol. 12, no. 4,
pp. 859–874, Jul./Aug. 2006.
12 S. D. Perli, N. Ahmed, and D. Katabi,
“Pixnet: Interference-free wireless links
using LCD-camera pairs,” in Proc.
International Conference on Mobile
Computing and Networking 2010 (Chicago,
IL), Sept. 20–24, 2010, pp. 137–148.
13 M. R. H. Mondal and K. Panta,
“Performance analysis of spatial OFDM for
pixelated optical wireless systems,” Trans.
Emerg. Telecommun. Technol., vol. 28, no. 2,
pp. 1–13, May 2015.
14 M. S. Grewal, L. R. Weill, and A. P.
Andrews, Global Positioning Systems,
Inertial Navigation, and Integration, John
Wiley & Sons, 2007.
15 N. U. Hassan, A. Naeem, M. A. Pasha,
T. Jadoon, and C. Yuen, “Indoor positioning
using visible LED lights: A survey,” ACM
Comput. Surv., vol. 48, no. 2,
www.ebook3000.com

288
pp. 20:1–20:32, Nov. 2015.
16 S. Y. Jung, S. Hann, and C. S. Park,
“TDOA-based optical wireless indoor
localization using led ceiling lamps,” IEEE
Trans. Consum. Electron., vol. 57, no. 4,
pp. 1592–1597, Nov. 2011.
17 H. S. Liu and G. Pang, “Positioning beacon
system using digital camera and LEDs,”
IEEE Trans. Veh. Technol., vol. 52, no. 2,
pp. 406–419, Mar. 2003.
18 Y. S. Kuo, P. Pannuto, K. J. Hsiao, and
P. Dutta, “Luxapose: Indoor positioning
with mobile phones and visible light,” in
Proc. International Conference on Mobile
Computing and Networking 2014 (Maui,
HI), Sept. 7–11, 2014, pp. 447–458.
19 Z. Yang, Z. Wang, J. Zhang, C. Huang, and
Q. Zhang, “Wearables can aﬀord:
Light-weight indoor positioning with visible
light,” in Proc. International Conference on
Mobile Systems, Applications, and Services
2015 (Florence, Italy), May 18–22, 2015,
pp. 317–330.
20 T. Yamazato, I. Takai, H. Okada, T. Fujii,
T. Yendo, S. Arai, M. Andoh, T. Harada,
K. Yasutomi, K. Kagawa, and S. Kawahito,
“Image-sensor-based visible light
communication for automotive
applications,” IEEE Commun. Mag., vol. 52,
no. 7, pp. 88–97, Jul. 2014.
21 I. Takai, S. Ito, K. Yasutomi, K. Kagawa,
M. Andoh, and S. Kawahito, “LED and
CMOS image sensor based optical wireless
communication system for automotive
applications,” IEEE Photon. J., vol. 5, no. 5,
pp. 6801418–6801418, Oct. 2013.
22 A. Wang, Z. Li, C. Peng, G. Shen, G. Fang,
and B. Zeng, “Inframe++: Achieve
simultaneous screen-human viewing and
hidden screen-camera communication,” in
Proc. International Conference on Mobile
Systems, Applications, and Services 2015,
(Florence, Italy), May 18–22, 2015,
pp. 181–195.
23 T. Li, C. An, X. Xiao, A. T. Campbell, and
X. Zhou, “Real-time screen-camera
communication behind any scene,” in Proc.
International Conference on Mobile Systems,
Applications, and Services 2015 (Florence,
Italy), May 18–22, 2015, pp. 197–211.
24 J. Chen, K. Venkataraman, D. Bakin,
B. Rodricks, R. Gravelle, P. Rao, and Y. Ni,
“Digital camera imaging system simulation,”
IEEE Trans. Electron Devices, vol. 56,
no. 11, pp. 2496–2505, Nov. 2009.
25 J. E. Farrell and B. A. Wandell, “I2. 2:
Invited paper: Image systems simulation,” in
SID Symposium Digest of Technical Papers,
vol. 46, no. 1, pp. 180–183, Wiley Online
Library, 2015.
26 A. El Gamal and H. Eltoukhy, “CMOS
image sensors,” IEEE Circuits Devices Mag.,
vol. 21, no. 3, pp. 6–20, May/Jun. 2005.
27 P. B. Denyer, D. S. Renshaw, G. Wang,
M. Y. Lu, and S. Anderson, “On-chip CMOS
sensors for VLSI imaging systems.” in VLSI,
vol. 91, pp. 157–166, 1991.
28 E. R. Fossum, “Active pixel sensors: Are
CCDS dinosaurs?” in Proc. IS&T/SPIE’s
Symposium on Electronic Imaging: Science
and Technology 1993 (San Jose, CA), Jan.
31, 1993, pp. 2–14.
29 B. Fowler, A. El Gamal, and D. X. Yang,
“A CMOS area image sensor with pixel-level
a/d conversion,” in Proc. IEEE International
Solid-State Circuits Conference 1994 (Ulm,
Germany), Sept. 20–22, 1994, pp. 226–227.
30 O. Yadid-Pecht, “Geometrical modulation
transfer function for diﬀerent pixel active
area shapes,” Opt. Eng., vol. 39, no. 4,
pp. 859–865, Apr. 2000.
31 Y. Reibel, M. Jung, M. Bouhifd, B. Cunin,
and C. Draman, “CCD or CMOS camera
noise characterisation,” Eur. Phys. J. AP,
vol. 21, no. 1, pp. 75–80, Nov. 2002.
32 M. Konnik and J. Welsh, “High-level
numerical simulations of noise in CCD and
CMOS photosensors: Review and tutorial,”
arXiv preprint arXiv:1412.4031, Dec. 2014.
33 R. M. Gagliardi and S. Karp, Optical
Communications, New York:
Wiley-Interscience, 1976.
34 J. C. Chau and T. D. Little, “Analysis of
cmos active pixel sensors as linear
shift-invariant receivers,” in Proc. IEEE
International Conference on
Communications Workshops (ICCW) 2015
(London, UK), Jun. 8–12, 2015,
pp. 1398–1403.
35 S. M. Moser, “Capacity results of an optical
intensity channel with input-dependent
Gaussian noise,” IEEE Trans. Inf. Theory,
vol. 58, no. 1, pp. 207–223, Jan. 2012.
36 A. A. Farid and S. Hranilovic, “Channel
capacity and non-uniform signalling for
free-space optical intensity channels,” IEEE

289
J. Sel. Areas Commun., vol. 27, no. 9,
pp. 1553–1563, Dec. 2009.
37 A. A. Farid and S. Hranilovic, “Diversity
gain and outage probability for MIMO
free-space optical links with misalignment,”
IEEE Trans. Commun., vol. 60, no. 2,
pp. 479–487, Feb. 2012.
38 I. Moreno and C.-C. Sun, “Modeling the
radiation pattern of leds,” Opt. Exp., vol. 16,
no. 3, pp. 1808–1819, 2008.
39 I. Djite, M. Estribeau, P. Magnan,
G. Rolland, S. Petit, and O. Saint-Pe,
“Theoretical models of modulation transfer
function, quantum eﬃciency, and crosstalk
for CCD and CMOS image sensors,” IEEE
Trans. Electron Devices, vol. 59, no. 3,
pp. 729–737, Mar. 2012.
40 A. A. Farid and S. Hranilovic, “Outage
capacity optimization for free-space optical
links with pointing errors,” J. Lightw.
Technol., vol. 25, no. 7, pp. 1702–1710,
2007.
41 F. Yang, J. Cheng, and T. A. Tsiftsis,
“Free-space optical communication with
nonzero boresight pointing errors,” IEEE
Trans. Commun., vol. 62, no. 2, pp. 713–725,
2014.
42 J. G. Smith, On the information capacity of
peak and average power constrained
Gaussian channels, University of California,
1969.
43 J. G. Smith, “The information capacity of
amplitude-and variance-constrained sclar
Gaussian channels,” Inf. Control, vol. 18,
no. 3, pp. 203–219, Apr. 1971.
44 A. Tchamkerten, “On the discreteness of
capacity-achieving distributions,” IEEE
Trans. Inf. Theory, vol. 50, no. 11,
pp. 2773–2778, Nov. 2004.
45 T. H. Chan, S. Hranilovic, and F. R.
Kschischang, “Capacity-achieving
probability measure for conditionally
Gaussian channels with bounded inputs,”
IEEE Trans. Inf. Theory, vol. 51, no. 6,
pp. 2073–2088, Jun. 2005.
46 B. Mamandipoor, K. Moshksar, and A. K.
Khandani, “On the sum-capacity of
Gaussian MAC with peak constraint,” in
Proc. IEEE International Symposium on
Information Theory (ISIT) 2012
(Cambredge, MA), Jul. 1–6, pp. 26–30.
47 A. ElMoslimany, “A new communication
scheme implying amplitude limited inputs
and signal dependent noise: System design,
information theoretic analysis and channel
coding,” Ph.D. dissertation, Arizona State
University, 2015.
48 K. H. Park, W. G. Alheadary, and M. S.
Alouini, “A novel mirror diversity receiver
for indoor MIMO visible light
communication systems,” in Proc. IEEE
International Symposium on Personal,
Indoor, and Mobile Radio Communications
(PIMRC) 2016 (Valencia, Spain), Sept. 4–7,
2016, pp. 1–6.
49 T. Fath and H. Haas, “Performance
comparison of MIMO techniques for optical
wireless communications in indoor
environments,” IEEE Trans. Commun.,
vol. 61, no. 2, pp. 733–742, Feb. 2013.
50 A. Nuwanpriya, S. W. Ho, and C. S. Chen,
“Indoor MIMO visible light
communications: Novel angle diversity
receivers for mobile users,” IEEE J. Sel.
Areas Commun., vol. 33, no. 9,
pp. 1780–1792, Sept. 2015.
51 P. F. Mmbaga, J. Thompson, and H. Haas,
“Performance analysis of indoor diﬀuse
VLC MIMO channels using angular
diversity detectors,” J. Lightw. Technol.,
vol. 34, no. 4, pp. 1254–1266, Feb. 2016.
52 T. Q. Wang, Y. A. Sekercioglu, and
J. Armstrong, “Analysis of an optical
wireless receiver using a hemispherical lens
with application in MIMO visible light
communications,” J. Lightw. Technol.,
vol. 31, no. 11, pp. 1744–1754, Jun. 2013.
53 T. Chen, L. Liu, B. Tu, Z. Zheng, and
W. Hu, “High-spatial-diversity imaging
receiver using ﬁsheye lens for indoor MIMO
VLCs,” IEEE Photon. Technol. Lett., vol. 26,
no. 22, pp. 2260–2263, Nov. 2014.
54 S. Hranilovic and F. R. Kschischang,
“Capacity bounds for power- and band-
limited optical intensity channels corrupted
by Gaussian noise,” IEEE Trans. Inf. Theory,
vol. 50, no. 5, pp. 784–795, May 2004.
55 A. Farid and S. Hranilovic, “Capacity
bounds for wireless optical intensity
channels with Gaussian noise,” IEEE Trans.
Inf. Theory, vol. 56, no. 12, pp. 6066–6077,
Dec. 2010.
56 A. Ashok, S. Jain, M. Gruteser,
N. Mandayam, W. Yuan, and K. Dana,
“Capacity of pervasive camera based
communication under perspective
www.ebook3000.com

290
distortions,” in Proc. IEEE International
Conference on Pervasive Computing and
Communications 2014 (Budapest, Hungary),
Mar. 24–28, 2014, pp. 112–120.
57 A. Chaaban, Z. Rezki, and M. S. Alouini,
“Fundamental limits of parallel optical
wireless channels: Capacity results and
outage formulation,” IEEE Trans. Commun.,
vol. 65, no. 1, pp. 296–311, Jan. 2017.
58 A. ElMoslimany and T. Duman, “On the
capacity of multiple-antenna systems and
parallel Gaussian channels with
amplitude-limited inputs,” IEEE Trans.
Commun., vol. 64, no. 7, pp. 2888–2899, Jul.
2016.
59 B. Rassouli and B. Clerckx, “On the
capacity of vector Gaussian channels with
bounded inputs,” in Proc. IEEE
International Conference on
Communications (ICC) 2015 (London, UK),
Jun. 8–12, 2015, pp. 4030–4035.
60 B. Mamandipoor, K. Moshksar, and A. K.
Khandani, “Capacity-achieving distributions
in Gaussian multiple access channel with
peak power constraints,” IEEE Trans. Inf.
Theory, vol. 60, no. 10, pp. 6080–6092, Oct.
2014.
61 T. H. Chan, S. Hranilovic, and F. R.
Kschischang, “Capacity achieving
probability measure of an input-bounded
vector Gaussian channel,” in Proc. IEEE
International Symposium on Information
Theory (ISIT) 2003 (Yokohama, Japan), Jun.
29–Jul. 4, 2003, pp. 371–371.
62 T. M. Cover and J. A. Thomas, Elements of
Information Theory, John Wiley & Sons,
2012.

291
9
Optical Camera Communication: Modulation and
System Design
In this chapter, we review modulation schemes and discuss system design issues
in optical camera communication (OCC). We also point out impairment factors in
each modulation scheme and the corresponding mitigation methods. Then we ad-
dress synchronization challenges, and in particular introduce two synchronization
schemes, namely the per-line tracking and inter-frame coding, and rateless coding.
We then turn our attention from theory to practice by investigating practical modu-
lation schemes and multiplexing techniques in the system design. The spatial, color
and intensity dimensions are fully explored to create high-dimensional signal con-
stellations and parallel communication channels. Moreover, the color-intensity mod-
ulation (CIM) and multiple-input multiple-output (MIMO) conﬁgurations are built.
Finally, we present designs and implementations of a real-time CIM-MIMO OCC
system.
In Section 9.1, the problem about how to design the capacity-achieving nonuni-
form discrete signaling for signal-dependent noise channels under the optical inten-
sity constraints in practice is discussed. To implement a capacity-achieving system,
a nonuniform source distribution is required for an OCC system. It can be accom-
plished by employing multilevel coding (MLC) and multi-stage decoding (MSD)
with a deterministic mapper applied to multiple binary linear codes. Furthermore,
a nonuniform mapper coupled with a binary low density parity check (LDPC) code
can be used to generate the desired input distribution. This scheme has a lower com-
plexity compared with non-binary LDPC code constructions and requires a single
encoder and decoder. Thus it is free of error propagation and has less latency in
decoding.
However, some challenges in the aforementioned design still exist. Link feed-
back is necessary and the computational complexity of the sum-product-based
joint demapper/decoder algorithm is very high. Thus, other modulation schemes
are developed in OCC. In Section 9.2, modulation schemes in diﬀerent domains
are introduced, including the undersampling-based modulation schemes and the
rolling-shutter-eﬀect-based modulation schemes in the time-frequency domain,
color-intensity modulation in the color space, and the spatial orthogonal frequen-
cy division multiplexing (OFDM) and spatial wavelet packet division multiplexing
(WPDM) in the spatial-frequency domain. Then, the nonideal factors in each mod-
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.
www.ebook3000.com

292
ulation scheme are considered, and the eﬀects of impairment factors on various
modulation schemes are analyzed in Section 9.3. Speciﬁcally, the linear misalign-
ment, geometry perspective distortion, blur eﬀect, and vignetting in spatial OFDM
are considered. And the corresponding techniques to mitigate the impairment fac-
tors are discussed, including equalization, perspective correction, adaptive coding,
and modulation. Synchronization is another important aspect for a practical OCC
system. The diﬃculty in frame synchronization mainly arises from frame diversity
and variability. In Section 9.4, two synchronization schemes, the per-line tracking
and inter-frame coding, and rateless coding are discussed. These methods tackle
the synchronization issues by decoding imperfect frames and recovering every lost
frame at the receiver.
Based on those designs and considerations, an experimental OCC platform has
been built and its components are described in Section 9.5. In particular, spatial, col-
or, and intensity dimensions are fully utilized to create high-dimensional signal con-
stellations and parallel communication channels for a real-time CIM-MIMO OCC
system. In this way, the data rate is signiﬁcantly increased and bit error rate (BER)
performance improves. Particularly, some solutions to tackle several challenges in
the system design are introduced, including unstable frame rate, joint nonlinearity
and crosstalk, ﬂicker noise, and rolling shutter.
9.1
Coding and decoding
Typically, an OCC system adopts intensity-modulation direct-detection (IM/DD),
where the desired information is modulated onto the optical intensity and transmitted
to the receiver over a free space link. The pixel, being basically a power detection unit
and a fundamental element in an image sensor, responds to the instantaneous ﬁeld
count rate process. Its output appears as a shot noise process, whose count rate is pro-
portional to the instantaneous received power. Pulse amplitude modulation (PAM)
is one of the most popular intensity modulation schemes developed for an optical
communication system, and on-oﬀkeying (OOK), as a binary-level version of PAM,
is also widely used.
Almost all existing PAM-based schemes belong to uniform signaling with equal-
probability symbols. It performs well for a channel with additive white Gaussian
noise (AWGN), independent of the signal. However, it has been proven that the
capacity-achieving input probability for signal-dependent Gaussian noise channels
subject to optical intensity constraints follows a nonuniform discrete distribution.
Meanwhile, binary linear codes can be applied directly for channels with uniform
input distribution, but channel coding with nonuniform input distribution is more
complex. The method to implement nonuniform distribution signal was ﬁrst pro-
posed by Gallager [1], where a deterministic mapper was employed at the output of
a binary encoder to generate symbols following a nonuniform distribution. Another
approach to induce the nonuniform distribution is to design LDPC codes over GF(q)
with q > 2 [2]. Furthermore, an inverse Huﬀman code type mapper was proposed

293
to generate the nonuniform distribution [3]. Although these approaches yield sub-
stantial performance improvement, the higher complexity in both code design and
decoding limits their applications. Moreover, the complexity of soft decoding is also
prohibitive.
In this section, we introduce the widely used methods to realize a capacity-
achieving system. The MLC and MSD with a deterministic mapper [4] are applied to
induce the nonuniform source distribution. However, MLC/MSD requires multiple
encoders and decoders, which result in error propagation and decoding latency. To
address this problem, Cao et al. [5] proposed a nonuniform mapper coupled with
a binary LDPC code to generate the desired input distribution. They also provided
a joint demapper/decoder design based on a sum-product algorithm. This scheme
only requires a single encoder and decoder with lower complexity compared with
non-binary LDPC code constructions. It also oﬀers less decoding latency and no
propagation error.
9.1.1
Multilevel coding and multi-stage decoding
The MLC/MSD structure consists of two parts: mapping/demapping and encod-
ing/decoding modules [4, 6]. Figure 9.1 shows a diagram for an optical channel
including a mapper. Every N-bits from the independent bit stream with uniform dis-
tribution form a group W = [W1 · · · WN]. And then, the bits are mapped to a
symbol X through the mapping function M, to form nonuniform distribution sym-
bols. The output symbols have probability m/2N, where m = 1, · · · , 2N −1 is an
integer. Thus, there exist a set of nonuniform distributions that can be induced for a
given N. Note that the mapping W
M
−−→X is not necessarily one-to-one. However,
the mutual information I(X; Y ) between the channel input and output is unaﬀected,
since W →X →Y is a Markov chain and M(W ) = X is a deterministic map-
per. Thus, for a given deterministic mapping function M, the information rate can
be realized and achieved even when the mapping is not reversible.
Figure 9.1 Illustrative diagram for an optical channel with a mapper [4].
Figure 9.2 shows a block diagram for the MLC system with a deterministic mapper.
Assuming a bit stream with independent and equal-probability bits, k-bits from the
stream are divided into N sub-streams each with ki bits, where i = 1, · · · , N, such
that k = N
i=1 ki. The ith sub-stream is encoded by a linear binary code of rate Ri.
The codeword length of each encoder output is ﬁxed to n = ki/Ri. The outputs of
the encoders are arranged in a vector W = [W1 · · · WN], where Wi denotes the
ith encoder output bit. The vector W is mapped to a symbol using a deterministic
mapper function M, which can output the desired nonuniform probability signal.
www.ebook3000.com

294
Figure 9.2 Schematic block diagram for MLC and mapper [4].
Based on the chain rule, the mutual information can be expressed in terms of the
sub-channel rates as
I(W ; Y ) =
N

i=1
Ri,
(9.1)
where the sub-channel rates are given by
Ri = I(Wi; Y |W1, · · · , Wi−1).
(9.2)
Figure 9.3 Schematic block diagram for multi-stage decoders (MSD) [4].

295
At the receiver, the received codeword is decoded sequentially to recover the trans-
mitted bits. Figure 9.3 illustrates the sequential decoding strategy of the MSD. The
ﬁrst decoder utilizes the received signal Y to decode W1 as ˆW1. Given that the
codeword is decoded correctly, the second decoder utilizes both Y and estimated
ˆW1 to obtain the estimated ˆW2 since the second encoder operates at rate R2 =
I(W2; Y |W1). Repeat this process till ˆWN is estimated. Note that if a codeword is
decoded incorrectly, an error occurs and propagates, resulting in decoding error in
the estimated transmitted data. Due to the sequential decoding processing in MSD,
time latency is inevitable.
Example: To illustrate how the nonuniform signal is generated, we assume that
the nonuniform distribution has two mass points {0, A} with probabilities of p(0) =
7/8 and p(A) = 1/8. This system can be constructed using N = 3 encoders with
a deterministic mapping function M, given by
W = [W1 W2 W3] M
−−→X : X =
 A,
if
W1 = W2 = W3 = 1,
0,
otherwise.
(9.3)
The detailed diagram of the mapping function is presented in Fig. 9.4. To achieve the
rate of R1 = I(W1; Y ), the bit W1 = 0, which is the most signiﬁcant bit, is mapped
to X = 0 in all cases, while W1 = 1 is mapped to X = 0 with the probability of
3/4.
Figure 9.4 Mapping function over X = {0, A} to induce p(0) = 7/8 and p(A) = 1/8.
9.1.2
Single-level coding and joint decoding
Although a mapper coupled with MLC/MSD can induce nonuniform signaling, this
method suﬀers from error propagation and decoding latency, and requires multiple
encoders and decoders. Alternatively, a single code can be used to encode all bits
and the mapper is employed to induce the correct distribution.
Figure 9.5 shows the block diagram of the single encoder with a mapper. When
a stream of independent message U composed of k-bits with uniformly distributed
www.ebook3000.com

296
Figure 9.5 System model for the single encoding and mapping scheme.
inputs to the LDPC encoder and the length of the LDPC code is nN, the modulation
order becomes 2N. The parameter n takes an integer value to ensure the capacity
C > k/n. The output bits of the encoder are (W (i)
1 , · · · , W (i)
N ), for i = 1, · · · , n.
Since the LDPC code is a linear code, the output distribution of the symbols in W
can be assumed to be uniform. After that, the output of the encoder W is mapped to a
symbol using a deterministic mapper function M to induce the desired distribution.
This mapper is easy to implement since all probable masses are constrained to be
the form of k/2N. Thus, each block of N coded bits is sent to the mapper to yield
a single channel input X with the desired probability distribution. At the receiver,
demapping and decoding are conducted jointly via the sum-product algorithm [5].
Example : Consider N = 2. The mapper function M induces the following
distribution
(W i
1, W i
2) M
−−→X : X =
 A,
if
W i
1 = W i
2 = 1,
0,
otherwise.
(9.4)
The equivalent channel seen by bit W1 (and W2 due to the symmetry of the mapper)
can be obtained by marginalizing the conditional probability density function (PDF)
fY |W (y|w1 = 1) =

w2
fY |X(y, w2|w1 = 1)
= 1
2fY |X(y|A) + 1
2fY |X(y|0),
(9.5)
fY |W (y|w1 = 0) = fY |X(y|0),
(9.6)
where fY |X(·|·) is the channel conditional PDF.
Joint LDPC decoding and demapping can be represented in the factor graph, as
shown in Fig. 9.6. Then, the message passing on this graph using the sum-product
algorithm can demap and decode the bits jointly [5]. The lower part of the graph
represents a traditional LDPC code and the mapping function M is represented by
the triangular nodes. Both w(i) and xi are binary in this example. Following the
standard sum-product algorithm, the message from the mapper to the message bit
w(i)
1
is
μM→w(i)
1 (w(i)
1
= 1) =μxi→M(xi = A)μw(i)
2 →M(w(i)
2
= 1)
+ μxi→M(xi = 0)μw(i)
2 →M(w(i)
2
= 0).
(9.7)

297
Figure 9.6 The factor graph for joint demapping and decoding.
μM→w(i)
1 (w(i)
1
= 0) =μxi→M(xi = 0)μw(i)
2 →M(w(i)
2
= 1)
+ μxi→M(xi = 0)μw(i)
2 →M(w(i)
2
= 0).
(9.8)
An analogous message from M to w(i)
2
can also be derived similarly. Then, the
message from xi to M can be written in a log-likelihood ratio (LLR) form as
mxi→M = ln μxi→M(xi = 0)
μxi→M(xi = A) = ln f(xi = 0|yi)
f(xi = A|yi) = ln3f(yi|xi = 0)
f(yi|xi = A) .
(9.9)
All other message passing for the LDPC code takes place in the standard manner.
Due to the symmetry of the mappers in w(i)
1
and w(i)
2 , the update rules for both are
the same. After several rounds of message passing, a hard decision is performed for
each w(i).
9.2
Modulation schemes
In the previous section, we introduce how to design the capacity-achieving nonuni-
form signaling in practice. However, some challenges in the aforementioned design
still exist. Link feedback is necessary and the computational complexity of the joint
demapper/decoder is very high. Thus, other modulation schemes are employed in
OCC.
www.ebook3000.com

298
9.2.1
Undersampling-based modulation
An OCC system design requires consideration of human perception of light source
ﬂicker. Usually, the commercial camera’s frame rate is lower than the transmission
frequency. To achieve a ﬂicker-free communication, undersampling-based modula-
tion methods are proposed to ensure no perceptual intensity ﬂuctuation. Figure 9.7
shows the cutoﬀfrequencies of human eye and camera. The human eye has a cut-
oﬀfrequency in the vicinity of 100 Hz, whereas the camera’s cutoﬀfrequency can
signiﬁcantly exceed 100 Hz depending on the exposure speed setting. In regard to
the observability of a “blinking light”, the signal waveform based on undersampling
modulation can be captured by a camera with the appropriate exposure setting, but
not perceived by the human eye because the camera’s exposure speed is much faster
than the eye can perceive.
Figure 9.7 The cutoﬀfrequencies of the human eye and the camera.
Undersampling frequency shift on-oﬀkeying (UFSOOK) is a form of direct current
(DC) balanced diﬀerential coding [7]. Similar to frequency shift keying (FSK), mark
and space ON-OFF keying frequencies indicate the coding bits. The mark (logic 1)
and space (logic 0) frequencies are selected such that when undersampled by a low
frame rate camera, the mark/space frequencies distorted by low pass frequencies can
be further processed to decode the bit values. The mark frequency is deﬁned as an
integer multiple of the camera frame rate fcamera plus/minus one half, i.e., (n± 1
2)×
fcamera, and the space frequency is deﬁned as an integer multiple of the camera frame
rate, i.e., n × fcamera.
In UFSOOK, two transmitted frame samples represent one bit, which does not
eﬀectively utilize the sampled values. Figure 9.8(a) depicts an example of the UF-
SOOK pattern, where y-axis indicates whether the light is turned ON or OFF. In this
particular example, a logic 1 (mark frequency) is selected to be transmitted for seven
cycles of 105 Hz OOK, which is 3.5 times the camera frame rate (the camera frame
rate is 30 Hz), followed by a logic 0 (space frequency) that is chosen to be transmitted
at a rate 4 times of the camera frame rate. The frame head is transmitted with a fre-
quency fFH, which is much higher than the cutoﬀfrequency fmax-camera of a camera.
Therefore, the light appears as half ON (average) in the received frame. The camera

299
captures continuous frames at the position of the dash sampling strobes, with each
UFSOOK symbol sampled twice at the frequency of 30 Hz. Thus, the camera sub-
sampling of the mark frequency results in the light to appear blinking OFF then ON,
and the camera subsampling of the space frequency results in the light to be OFF for
both samples. In principle, subsampling of the mark frequency will result in aliasing
that causes the light to appear blinking (OFF-ON or ON-OFF), and subsampling of
the space frequency will result in aliasing that causes the light to be in a steady state
(either ON or OFF). Adhering to the stated rules, it always results in an even number
of OOK cycles per bit for a space frequency and an odd number of cycles for a mark
frequency. Hence, the “code” is always balanced.
(a) UFSOOK pattern “FH, 0, 1” (fcamera = 30 fps, fFH = 25 kHz,
fspace = 120 Hz, fmark = 105 Hz)
(b) UPSOOK pattern (fcamera = 30 fps, fFH = 10 kHz, fspace =
fmark = 120 Hz, θmark = 0o, θspace = 180o)
Figure 9.8 The example of UFSOOK pattern and UPSOOK pattern [8].
Undersampling phase shift on-oﬀkeying (UPSOOK) modulation is similar to the
phase shift keying (PSK) [8], where the mark (logic 1) and space (logic 0) have the
same frequency and amplitude, but the phases of the corresponding carrier signal are
opposite. In UPSOOK, frame head is also transmitted at the frequency fF H, which
is much higher than the camera’s cutoﬀfrequency fmax-camera. The mark and space
are represented by square waves of the same frequency fmark = fspace = n × fcamera
but diﬀerent phase (e.g., θmark = 0o, θspace = 180o), where n is an even integer
(fmax-eye < fmark < fmax-camera). Figure 9.8(b) depicts an example of the UPSOOK
pattern, where fcamera = 30 Hz, and fmark = fspace = 120 Hz. Under this setting,
one bit per four frames can be transmitted. Since it is likely that the sample phase
of the camera is out of control, there might be a random phase diﬀerence between
the transmitter and the camera. Therefore, at the receiver side, it is uncertain to de-
www.ebook3000.com

300
termine whether the received “1” or “0” represents mark or space, and a framing
strategy is needed to eliminate this uncertainty. The phase uncertainty problem will
only cause an error when receiving a mark or a space signal, while it has no eﬀect
on the frame header signal. Data is sent according to the frame structure as shown
in Fig. 9.9(b), where each q-PAM (including OOK) symbol is packed into the pay-
load of a data frame with a header named as a start frame delimiter (SFD) for asyn-
chronous communication and nonlinear compensation at the receiver. Speciﬁcally,
SFD is composed of three parts labeled as A, B, and C. Part A denotes the start of a
data frame. When the camera captures the UPSOOK modulated signal in Part A, the
recorded transmitter will be in the half-ON (HO) state. Part B is the mark symbol,
which can be used to indicate the phase uncertainty. Part C has the length of L sym-
bols for L-level undersampling phase shift pulse amplitude modulation (UPSPAM)
signal, and is designed to obtain the transceiver nonlinear curve. In UPSOOK, Part
C is unnecessary in SFD. In such a way, the error caused by phase uncertainty can be
detected by examining the second received symbol of a frame. There will be two pos-
sible states of the second symbol in the received data frame. If the second received
symbol in the received frame is fully ON, it means that phase uncertainty does not
introduce error. If the second symbol in received frame is OFF, it means all the fully
ON symbols in the frame should be OFF, and all the OFF symbols should be fully
ON. This procedure can correct the error introduced by phase uncertainty, which can
also be considered as a special forward error correction (FEC) scheme.
(a)
(b)
Figure 9.9 An example of the 4-UPSPAM signal and the data frame structure.
As introduced above, both the UFSOOK and UPSOOK modulation schemes
employ the undersampling technique to sample high-frequency signals and obtain
the transmitter’s states for data recovery. However, the spectral eﬃciencies are 0.5
bit/s/transmitter and 1 bit/s/transmitter for UFSOOK and UPSOOK, respective-
ly. In order to improve the spectral eﬃciency without increasing the number of

301
transmitters, UPSPAM is proposed for high eﬃciency and non-ﬂicking OCC [9].
Instead of directly transmitting baseband PAM signal, in UPSPAM, a square wave
intensity-modulated PAM at the carrier frequency of fs = n×fcamera is transmitted.
Figure 9.9(a) illustrates the waveform of 4-UPSPAM symbols. If we assume the
original binary data stream is [1 1 1 0 0 1 0 0] and n = 4, then the corresponding
4-PAM signal using Gray coding is [3 1 −1 −3]. Correspondingly, the modulated
4-UPSPAM signal is [3 −3 3 −3 3 −3 3 −3 1 −1 1 −1 1 −1 1 −1 −1 1 −1 1 −1 1
−1 1 −3 3 −3 3 −3 3 −3 3]. Since it is likely that the sampling phase of camera at
the receiver side is out of control, there may exist a random phase diﬀerence between
the transmitter and the camera, which can be shown in Fig. 9.9(a). Note that the
subsampled result (shown on the top of Fig. 9.9(a)) using blue solid strobes is the
same as the original data, but the obtained result sampled with red dot strobes has
an inverse sign from the original data. Thus, at the receiver, the uncertainty can also
be eliminated by a framing strategy as shown in Fig. 9.9(b). Part C in SFD, which
has the length of L symbols for the L-UPSPAM signal, is designed to obtain the
transceiver nonlinear curve. After obtaining the transceiver nonlinearity, curve pre-
compensation or post-compensation techniques can be used to mitigate the nonlinear
eﬀect [10].
9.2.2
Rolling shutter eﬀect-based modulation
As mentioned above, the complementary metal oxide semiconductor (CMOS) image
sensors, most commonly used in today’s consumer electronics, exhibit a phenomenon
referred to as rolling shutter [11–15]. The image sensor consists of a matrix of photo-
diodes, where each photodiode converts the incident photons into voltage. In order to
reduce the design complexity and power consumption, or to accelerate the read rate
in readout circuit, the rolling shutter image sensors expose only one scanline of pho-
todiodes at a time and read the output. This scanning of photodiodes, one scanline
after another in sequence, is referred to as the rolling shutter. Generally speaking,
the rolling shutter eﬀect is undesirable, because it is challenging for symbol demod-
ulation, and inevitably introduces intensity ﬂuctuation, leading to performance loss.
However, the property of the rolling shutter can actually be utilized for data trans-
mission from a light source to a rolling-shutter-based image sensor.
We ﬁrst introduce the principle of the rolling shutter [16]. As shown in Fig. 9.10,
the exposure in CMOS image sensor is controlled by the row-reset and row-select
signals generated by the row address decoder, where each row becomes photosensi-
tive after row reset, and stops collecting photons and starts reading out data once a
row-select signal is detected. Since there is only one row of readout circuits, the read-
out timings for diﬀerent rows cannot overlap. Thus, the level of the signal generated
by image sensor depends on the amount of incident light on the photodetectors, in
terms of both intensity and duration. During the scanning process, each scanline of
the sensor array is exposed, sampled, and stored sequentially. When this procedure
is completed, the scanlines are merged together in order to form a single image.
Various eﬀects can be observed due to rolling shutter operation, such as the skew in
www.ebook3000.com

302
Figure 9.10 Timing chart for the rolling shutter image sensor.
Figure 9.11 Data decoding using the rolling shutter scheme.
images of a moving object [12]. While this may seem undesirable, it can also be uti-
lized for data communication. When the transmission frequency of the light source
is lower than the rolling shutter’s scanning frequency but higher than the frame rate,
bands of diﬀerent light intensity appear in the image sensor as shown in Fig. 9.11.
When the light source is “ON”, the image sensor captures a bright frame and the
CMOS image sensor exposes one array of this image shown as the ﬁrst white line in
the image. The light source then changes to the “OFF” state and the second scanline
is enabled, which results in the ﬁrst black line in the image. The aforementioned
operations continue until all the scanlines are exposed and the image is complet-
ed. Thus, it demonstrates that as the state of light source alternates between “ON”
and “OFF”, the corresponding image sensor produces an image frame by alternating
bands of pixels with bright dark shades due to the rolling shutter eﬀect. If the light
source’s “ON” and “OFF” states are used to represent bit “1” and “0” respectively,
then the OOK modulation is realized, which is shown in Fig. 9.12. In practice, since
OOK only utilizes light source’s white light, it is less robust to ambient light noise.
Moreover, OOK can also induce human perceivable light source ﬂickering for long
runs of 0s or 1s in the transmission data.
In practice, the width of bright or dark bands is proportional to the symbol rate of
the transmitter and the rate of the image sensor to capture preview images [11, 15].
By adjusting these values, an array of images with bands of diﬀerent widths and
intensity can be obtained. Using simple image processing techniques, these bands
can be converted into a binary array, from which useful information can be extracted.
Thus, if diﬀerent symbols are conveyed by ON-OFF bands at diﬀerent frequencies,

303
Figure 9.12 OOK, FSK, and CSK modulation using the rolling shutter eﬀect.
then FSK modulation is realized. Figure 9.12 shows a frame with two FSK symbols.
In particular, FSK modulation can reduce the demodulation error due to long symbol
duration and multiple ON-OFF bands in each symbol.
As introduced in the previous chapter, a CMOS image sensor is a natural multicolor
receiver enabled by a color ﬁlter array, and color shift keying (CSK) modulation can
be performed in OCC. With the ability of commodity cameras to detect a wide range
of colors, it is possible to use high-order constellations with CSK [14]. In the case of
one transmitter, diﬀerent duty cycles or transmission frequencies with a steady volt-
age between 0 and full, allow us to control the brightness of the transmitter. If we
use three pulse width modulation (PWM) signals to control the multicolor transmitter
elements, such as one tri-LED containing the inner red, green, and blue LEDs with
diﬀerent duty cycles respectively, the tri-LED will generate an accumulated color and
produce a desired CSK symbol. At the receiver, the CMOS image sensor receives
the color symbols in the form of diﬀerent color bands in a recorded frame as shown
in Fig. 9.12. The receiver then compares the received color to reference symbol’s
color for demodulation. The higher order CSK modulation along with shorter sym-
bol duration provides higher data rates compared to previously studied modulation
approaches like FSK. Thus, it is possible that the joint eﬀect of CSK modulation
does not impact the human perceivable color for consistent white illumination of the
LED, and the color ﬂicker problem in conventional CSK can be eliminated.
For rolling-shutter-eﬀect-based modulation schemes, there are still many open
challenges. The ﬁrst one is the ﬂicker eﬀect. When an LED or screen is used for
data communication, it concurrently serves for illumination or display. The OOK
and FSK utilize white light during the ON period. If the transmission frequency is
high enough, human will perceive no illumination ﬂuctuation. However, if the data
symbols are transmitted in the form of diﬀerent color light, the color changes can
be perceived by human eye. Hence, even when the color symbols are transmitted,
the human perceivable color of illumination should remain white. The second one
is the inter-frame data loss problem. The commercial cameras available in the con-
sumer electronics market cannot capture image frames in a successive manner. They
require a certain amount of time to process the captured frame. Thus, the symbols
transmitted during this inter-frame interval are not received by the camera. Tech-
niques to recover the symbols are needed to ensure reliable communication. When
adopting commercial image sensors as receivers, it is necessary to take into account
www.ebook3000.com

304
the diversity of these cameras, such as color ﬁlters, type and arrangement, and frame
rate. Due to the variety, the same transmitted CSK symbol can be perceived diﬀer-
ently by diﬀerent cameras. It is essential to design an adaptive mechanism to reduce
the demodulation errors.
9.2.3
Spatial OFDM
It is known that optical MIMO systems have the potential to provide higher data rate
than their single-input single-output (SISO) counterparts. However, it is also demon-
strated that a non-imaging optical MIMO system provides little diversity gain due to
the ill-conditioned channel matrix. For an imaging receiver, optical lens can help dis-
tinguish the source light images and reduce the channel correlation, which makes the
imaging receiver one of the most eﬃcient ways to apply optical MIMO. The pixel-
based system is a typical imaging MIMO systems, where a series of image frames
are transmitted, and a lens along with an array of pixelized photodetectors is used to
capture images at the receiver. The pixelated imaging optical MIMO system is shown
in Fig. 9.13, where a 2-D array of optical elements sends information encoded as a
sequence of images. Some intensity modulators (IM) such as the liquid crystal dis-
plays (LCDs) or LED arrays can be used as transmitters. A charge-coupled device
(CCD) or CMOS camera can be used as a direct detection (DD)-based receiver. The
imaging optical MIMO systems are attractive candidates for many applications in
highly dense contention scenarios, or near-ﬁeld communication (NFC) applications
such as mobile advertisement, data exchange and secure communication in military
applications. A possible outdoor application of an imaging optical MIMO system is
in intelligent transportation system (ITS), where LED traﬃc lights and LED automo-
bile headlights can be used to transmit driver assistance information, and a camera
mounted in a vehicle is used to detect the signal.
Figure 9.13 Illustration of an imaging optical MIMO communication system.
Recently, spatial orthogonal frequency division multiplexing (spatial OFDM) was
proposed, which encodes information in the spatial-frequency domain [6, 17–20].
Such a design is inspired by the popular OFDM transmission scheme that encodes
data in time frequencies. The spatial OFDM modulation forms images by trans-
mitting data in spatial-frequency bins subject to a loading algorithm. By insert-

305
ing training sequences before the data transmission, the receiver can determine the
signal-to-noise ratio (SNR) in each spatial-frequency bin. With this information, the
transmitter can perform power allocation and load the spatial-frequency bins appro-
priately. This technique allows for eﬃcient transmission over the spatial-frequency
selective optical channel. More importantly, a spatial OFDM system is capable of
tackling the perspective distortion by detecting and correcting such distortions from
the communication perspective. By designing and adaptive coding at the transmitter,
the receiver can decode the images after applying simple correction algorithms with
a low computational complexity. This is diﬀerent from perspective transformation,
which is widely studied in computer vision.
The transmitted signals in spatial OFDM are constrained to be non-negative for
IM/DD-based imaging optical MIMO system. DC-biased optical OFDM (DCO-
OFDM) and asymmetrically clipped optical OFDM (ACO-OFDM) are two forms
of optical OFDM that have been developed for 1-D VLC. Accordingly, the 2-D spa-
tial DCO-OFDM (SDCO-OFDM) [6, 17, 18, 21] and spatial ACO-OFDM (SACO-
OFDM) [19] can be adopted in an imaging optical MIMO system. Similar to 1-D
optical OFDM, SDCO-OFDM uses a DC bias to convert the bipolar spatial OFDM
signal into unipolar, and thus suﬀers poor power eﬃciency. The SACO-OFDM has
been shown to be more eﬃcient in terms of electrical as well as optical power, where
only the odd spatial frequencies are used to carry data and the resultant bipolar sig-
nals are clipped at zero to generate a unipolar signal.
The concept of a generalized spatial OFDM system is shown in Fig. 9.14. Consider
SACO-OFDM ﬁrst. For each of the transmitted SACO-OFDM frames, the input data
is mapped onto the N1 × N2 matrix X of constellation symbols given by
X =
⎛
⎜
⎝
0
X0,1
0
· · ·
X0,N2−1
...
...
...
...
...
0
XN1−1,1
0
· · ·
XN1−1,N2−1
⎞
⎟
⎠.
(9.10)
Each element of X denotes the symbol encoded in the corresponding spatial-
frequency subcarrier.
Therefore, Xk1,k2 represents the signal on the (k1, k2)th
subcarrier, where 0 ≤k1 < N1 and 0 ≤k2 < N2. In order to ensure a real-valued
matrix x as the 2-D inverse fast Fourier transform (IFFT) output of X, Hermitian
symmetry is maintained for X. Assuming that both N1 and N2 are even integers,
the Hermitian symmetry for X can be deﬁned as
Xk1,k2 = X∗
N1−k1,N2−k2,
(9.11)
where k1 and k2 are the row and column indices respectively, and ‘∗’ is the complex
conjugate operator. In a SACO-OFDM system, data are mapped onto only odd index
columns (or odd subcarriers) of X, while the even index columns (or even subcarri-
ers) are set to zero. The use of only odd subcarriers ensures that the desired signal
is not aﬀected by the clipping noise due to asymmetrical clipping. Next, the bipolar
output x from the 2-D IFFT processing of X is generated, and the elements of x are
www.ebook3000.com

306
given by
xl1,l2 =
1
N1N2
N1−1

k1=0
N2−1

k2=0
Xk1,k2exp
j2πk1l1
N1
+ j2πk2l2
N2

,
(9.12)
where (l1, l2) is the 2-D spatial index, with 0 ≤l1 < N1 and 0 ≤l2 < N2. The
bipolar signal xl1,l2 is then converted to an unipolar signal sl1,l2 by asymmetrical
clipping at the zero amplitude level, as
sl1,l2 =
 0,
xl1,l2 < 0,
xl1,l2,
xl1,l2 ≥0.
(9.13)
Figure 9.14 Block diagram of a spatial OFDM system [27].
For SDCO-OFDM, X is also constrained by Hermitian symmetry. However, in
SDCO-OFDM, data is encoded onto both odd and even subcarriers of X given by
X =
⎛
⎜
⎝
X0,0
X0,1
X0,2
· · ·
X0,N2−1
...
...
...
...
...
XN1−1,0
XN1−1,1
XN1−1,2
· · ·
XN1−1,N2−1
⎞
⎟
⎠,
(9.14)
where X0,0 is not used for data transmission. To generate an unipolar signal xl1,l2
as required in an IM/DD system, a DC bias bDC is added to xl1,l2 so that the resultant
signal does not take a negative value. The DC biased signal can be described as
xb
l1,l2 = xl1,l2 + bDC,
(9.15)
where bDC = μσx is the DC bias, μ is a proportionality constant and σx =

E{x2
l1,l2} is the power of xl1,l2. Since the bipolar signal xl1,l2 before clipping
has a Gaussian distribution, there may exist some negative time domain samples even
with a large DC bias. To remove this negative part, the resulting signal is clipped at

307
zero which generates clipping noise. The clipping noise can be reduced by using a
high level of DC bias at the cost of increased average optical power. So it is required
to select an optimum DC bias bDC to have low clipping noise with comparatively
small power wastage. The clipped signal is given by
sl1,l2 = Kxl1,l2 + bDC + dl1,l2,
(9.16)
where K is clipping attenuation and is approximately equal to 1 −Q(bDC/σx) with
Q(·) denoting the Q-function, and dl1,l2 is the clipping noise. Since K can easily
be compensated at the receiver, we set K = 1 for simplicity.
For both SACO-OFDM and SDCO-OFDM, cyclic extension in the form of a cyclic
preﬁx (CP) and a cyclic postﬁx (CPo) is appended around the edges of clipped sig-
nal matrix. The last part of the transmitted frame represents the modulated signals
s. Assuming the electrical-to-optical conversion eﬃciency is ς, the intensity of the
transmitted signal pl1,l2 is given by
pl1,l2 = ςsl1,l2.
(9.17)
The transmitted optical signal is aﬀected by spatial distortion before being collect-
ed by the pixels. The intensity of the received signal ql1,l2, as a function of pl1,l2,
is determined by the joint eﬀects of various spatial distortions. The received inten-
sity value is then converted back to an electrical signal by the pixel-based detector.
Moreover, the electrical signal suﬀers from the channel noise zl1,l2 composed of shot
noise and thermal noise modeled as AWGN. Next, the CP and CPo are removed from
the noisy signal, yielding the following received electrical signal yl1,l2 as
yl1,l2 = Rp · pl1,l2 ⊗hl1,l2 + zl1,l2 = Rpql1,l2 + zl1,l2,
(9.18)
where Rp is the responsivity of the photo-detecting elements, hl1,l2 is the system
point spread function (PSF), ⊗represents the 2-D linear convolution, and zl1,l2 is
channel noise. The PSF is linear, spatially invariant, and determined by the joint
eﬀects of impairment factors. After frame synchronization, channel estimation, and
equalization, 2-D FFT is then performed to obtain a spatial-frequency domain signal
Yk1,k2, which is further demodulated to recover the data.
9.2.4
Spatial WPDM
To generate real-valued and positive signals, various optical OFDM schemes for the
IM/DD system have been proposed. Note that, generating the real-valued signals
imposes extra loss of at least 50% reduction in spectral eﬃciency due to Hermi-
tian symmetry redundancy. Moreover, the cyclic preﬁx as time-domain guard in-
terval, further reduces the transmission spectral eﬃciency. The other disadvantages
of OFDM-based transmission are the high peak-to-average power ratio (PAPR) and
high side lobe. On the other hand, WPDM has been proposed as an alternative for
OFDM [22, 23]. As one type of ﬁlter bank multicarrier (FBMC), WPDM employs
www.ebook3000.com

308
orthogonal wavelet packet functions for symbol modulation. Similarly to OFDM, it
provides orthogonality between subcarriers, whilst the basis functions are wavelet
packet functions with ﬁnite length in time domain. The advantages of WPDM over
OFDM lie in higher spectral and power eﬃciency, lower PAPR, and stronger resis-
tance to inter-symbol-interference (ISI). For these merits, WPDM has been proposed
for ultra-wideband (UWB) communication, power line communication (PLC), and
optical ﬁber communication. It is also a candidate waveform for 5G transmission
system. In 2015, WPDM was introduced in 1-D VLC with optimal waveform design
in the presence of LED dispersion [24], showing the capability of enhancing the per-
formance over OFDM, in terms of superior out-of-band power leakage suppression,
lower PAPR, stronger resistance to the LED nonlinearity, and channel dispersion.
Moreover, the optimized waveform for the LED dispersion achieves performance
gain over the conventional wavelet basis function.
Figure 9.15 Block diagram of a spatial WPDM system.
Considering an imaging optical MIMO communication system where data is
mapped onto the spatial-frequency domain, the 1-D optical WPDM scheme can also
be extended to spatial WPDM. Figure 9.15 shows the block diagram of a generalized
spatial WPDM system. In a similar way to the 2-D IFFT and 2-D FFT processing
in spatial OFDM system, the 2-D inverse discrete wavelet packet transform (IDW-
PT) and the 2-D DWPT are performed at the transmitter and receiver, respectively.
Although the WPDM modulation can be implemented by fast iterative Mallat algo-
rithm for inﬁnite-length signals, the boundary eﬀect occurs because of ﬁnite length
when the transmitted signal is convolved with the wavelet ﬁlters. This will lead to
aliasing in signal reconstruction. To alleviate this eﬀect, the input signal has to be
extended via adding zeros before the WPDM modulation by symmetric boundary
extension [24]. The signal extension and extraction are needed in WPDM implemen-
tation. Otherwise, the error ﬂoor will signiﬁcantly degrade the system performance.
In addition, another signiﬁcant diﬀerence between spatial WPDM and spatial OFDM
is that the waveform bases for OFDM schemes are deﬁned in the complex domain,

309
but WPDM bases can be deﬁned either in the real domain or complex domain, which
is determined by the scaling and dilatation ﬁlters. For IM/DD system, the spatial
WPDM signal must be real and positive. It is thus more preferable to deﬁne the
WPDM bases in the real domain and adopt M-PAM modulation on each subcarrier.
Moreover, WPDM belongs to overlapped transformation, yielding better spectral
concentration. Meanwhile, WPDM waveforms overlap in the time domain. There is
no need for CP/CPo which could improve the bandwidth eﬃciency.
In Japan, the concept of spatial WPDM was adopted in road-to-vehicle VLC from
the LED array to the high-speed camera [25, 26]. The measurement results from
ﬁeld trials at a speed of 30 km/h show that the spatial WPDM is more robust to the
spatial nonideal conditions such as perspective distortion and blur eﬀect, and can
support long distance communication. In particular, one can adaptively choose the
transceiver structure attributed to the ﬂexibility and adaptability of the orthogonal
bases. The number of subcarriers no longer needs to be power of 2 for each di-
mension, and the optimal orthogonal basis waveforms can be designed to meet the
requirement. It is expected that the optimal spatial WPDM system is more robust to
spatial distortion and blur eﬀect, and has superior out-of-band power leakage sup-
pression performance, lower PAPR, and high spectral eﬃciency.
9.3
System impairment factors
The system performances are impaired by a number of factors inherent to OCC chan-
nels, including linear misalignment between the transmitted and received images,
perspective distortion, which is the geometry distortion of the original object, illu-
mination fall-oﬀat the received images termed as blur eﬀect, vignetting, which is
the blurring eﬀect because of the limited diﬀraction optics subsystem. Some other
problems such as temporal and spatial synchronization, and rotational misalignment
are also inevitable. Theoretical and simulation results for their eﬀects in the pres-
ence of received noise are analyzed subsequently in this section. Moreover, the as-
sociated mitigation techniques such as temporal and spatial frame synchronization,
blur-adaptive coding, and perspective correction are introduced.
9.3.1
Impairment factors in spatial OFDM
In this subsection, we analyze some spatial impairment factors in the spatial OFDM-
based imaging optical MIMO system, including linear misalignment [19, 27], per-
spective distortion due to geometry distortion [18, 28], blur eﬀect [28, 29], and vi-
gnetting [30] in the presence of channel noise. Moreover, the associated mitigation
techniques such as equalization, blur-adaptive coding, and perspective correction are
introduced.
www.ebook3000.com

310
9.3.1.1
Linear misalignment
The performance of imaging optical MIMO system can be impaired by linear mis-
alignment, since it is practically impossible to perfectly align the pixel in image sen-
sor with the transmitted image in spatial domain [19, 27]. The misalignment occurs
as an integer multiple of the side-length of the pixels or a fractional number of pixels.
We theoretically analyze and numerically simulate the eﬀect of integer and fractional
linear misalignment on spatial OFDM.
For an imaging optical MIMO system, the receiver samples the incoming image in
the spatial domain. The spatial sampling rate depends on the spacing of the receiver
pixels, and each pixel is a spatial sample. To simplify the analysis of linear misalign-
ment eﬀect, the blur eﬀect or magniﬁcation is not taken into account. Besides, the
number of data-carrying transmitted pixels is equal to the number of received pixels,
and all the pixels are square-shaped. When the misalignment is in one or two dimen-
sions, a receiving pixel will be aﬀected by two or four transmitted pixels, respectively.
Figure 9.16 illustrates the fractional misalignment in both dimensions. Figure 9.16(a)
shows a small frame of 4×4 pixels without CP and CPo, whilst Fig. 9.16(b) indicates
that a transmitted pixel is divided conceptually into four segments by the borders of
the received pixels. The area of each square-shaped transmitted pixel is Ar = m2,
where m is the length of a pixel. Then the four segments have the normalized areas
of A1 = mrmc/m2, A2 = mr(m −mc)/m2, A3 = (m −mr)mc/m2, and
A4 = (m −mr)(m −mc)/m2, where mr and mc are the sampling oﬀsets in
two dimensions. The intensity of a received pixel ql1,l2 is contributed by up to four
transmitted pixels based on their normalized areas
ql1,l2 = A4p(l1+Δl1),(l2+Δl2) + A3p(l1+Δl1),(l2+Δl2+1)
+ A2p(l1+Δl1+1),(l2+Δl2) + A1p(l1+Δl1+1),(l2+Δl2+1),
(9.19)
where Δl1 and Δl2 are the number of oﬀset pixels along the two dimensions. There-
fore, the total length of misalignment Δld1 and Δld2 in each dimension can be ex-
pressed as
Δld1 =
Δl1 + mr
m
m, and Δld2 =
Δl2 + mc
m
m.
(9.20)
Now we analyze the eﬀect of fractional misalignment in the spatial-frequency do-
main. The received electrical signal after the deduction of CP and CPo can be ob-
tained by modifying as (9.18)
yl1,l2 = A4s(l1+Δl1),(l2+Δl2) + A3s(l1+Δl1),(l2+Δl2+1)
+ A2s(l1+Δl1+1),(l2+Δl2) + A1s(l1+Δl1+1),(l2+Δl2+1) + zl1,l2.
(9.21)
To simplify analysis, we assume that ς = 1 in (9.17) and Rp = 1 in (9.18). sl1,l2
is the transmitted signal before the addition of CP and CPo. For SACO-OFDM, the
generated unipolar signal sl1,l2 can be expressed as Xk1,k2 after using the formula

311
(a) The transmitted and received frames
(b) A transmitted pixel and a received pixel
Figure 9.16 Illustration of the linear misalignment between transmitted and received
frames [27].
of 2-D IFFT, as
sl1,l2 =
1
N1N2
N1−1

k1=0
N2−1

k2=0
Xk1,k2 exp
j2πk1l1
N1
+ j2πk2l2
N2

,
(9.22)
where (k1, k2) represents the 2-D spatial frequency. By applying (9.22) into (9.21),
yl1,l2 is formulated as
yl1,l2 =
1
N1N2
N1−1

k1=0
N2−1

k2=0
W ′′
k1,k2 exp
j2πk1l1
N1
+ j2πk2l2
N2

+ zl1,l2, (9.23)
where
W ′′
k1,k2 = Xk1,k2 exp
j2πk1Δl1
N1
+ j2πk2Δl2
N2

A4 + A3 exp
j2πk2
N2

+ A2 exp
j2πk1
N1

+ A1 exp
j2πk1
N1
+ j2πk2
N2

.
(9.24)
To obtain the received constellations Yk1,k2, 2-D FFT is performed on (9.23), After
some rearrangement, we obtain
Yk1,k2 = Xk1,k2H′
k1,k2H′′
k1,k2 + Zk1,k2,
(9.25)
where Zk1,k2 is the AWGN noise in the spatial-frequency domain. Moreover,
H′
k1,k2 = exp
j2πk1Δl1
N1
+ j2πk2Δl2
N2

.
(9.26)
www.ebook3000.com

312
(a) One received pixel
(b) A transmitted and a received frame
Figure 9.17 Illustration of a received pixel depending on four transmitted pixels.
and
H′′
k1,k2 = A4 + A3 exp
j2πk2
N2

+ A2 exp
j2πk1
N1

+ A1 exp
j2πk1
N1
+ j2πk2
N2

.
(9.27)
The exponential terms in H′
k1,k2 and H′′
k1,k2 will both cause phase rotation. The
rotation angle depends linearly on both the subcarrier indices (k1, k2) and the extent
of the misalignment (Δl1, Δl2). In addition to the phase shift, H′′
k1,k2 also induces
attenuation, which is a function of A1, A2, A3, and A4 that depend on the mag-
nitude of the spatial sampling oﬀset. Besides, the attenuation also depends on the
spatial frequency. It means that, higher spatial frequency subcarriers may experi-
ence greater attenuation, since they change more rapidly with spatial distance than
lower frequency subcarriers.
Figure 9.18 shows the constellation of four-phase quadrature amplitude modula-
tion (4-QAM) SACO-OFDM signals in the presence of integer and fractional mis-
alignment. It is observed from Fig. 9.18(a) that, when only integer misalignment is
considered, the received constellation points experience only phase rotation, which
depends only on the spatial frequency. However, in the case of fractional misalign-
ment, the constellation points experience not only phase rotation but also amplitude
attenuation as shown in Fig. 9.18(b). Similar to the rotation, the amplitude attenua-
tion is also dependent on the spatial subcarrier index.
Figure 9.19(a) illustrates the amplitude attenuation of the received constellation
points versus spatial subcarrier index of a SACO-OFDM system in the case of frac-
tional misalignment with a sampling oﬀset of 70%. From Fig. 9.19(a), the Nyquist
rows thus, the N1
2 th and ( N1
2 + 1)th subcarriers, suﬀer greater attenuation than the
ﬁrst row subcarrier, which indicates that higher spatial subcarriers suﬀer greater at-

313
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Real Component
Imaginary Component
(a) Integer misalignment
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Real Component
Imaginary Component
(b) Fractional misalignment (mc = mr = 0.7m)
Figure 9.18 Constellation of SACO-OFDM impaired by linear misalignment.
0
20
40
60
80
100
120
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Subcarrier Index
Attenuation
First Row
Nyquist Row
N2/4
(a) Attenuation versus subcarrier index in one row of
4-QAM SACO-OFDM frame
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Fraction of a Single Pixel
Attenuation at Nyquist Subcarrier
(b) Attenuation at the highest subcarrier with diﬀer-
ent oﬀset in SACO-OFDM [27]
Figure 9.19 Attenuation versus subcarrier index and fraction of misalignment.
tenuation than lower spatial subcarriers. Moreover, the attenuation of the subcarrier
depends on the amount of the spatial sampling oﬀset as shown in Fig. 9.19(b). It
illustrates that the attenuation at the subcarrier is the greatest and equal to 50% of
a pixel. Theoretically, the value of |H′′
k1,k2| is minimum in (9.27) for the case of
mr = mc = 0.5m. In such a case, the intensity of a received pixel depends equally
on the four transmitted pixels, leading to maximum spatial averaging eﬀect.
9.3.1.2
Perspective distortion
The perspective distortions are caused by the nature of the imaging system mech-
anism and depend on the perspective of the image sensor. They manifest as defor-
mation in size and shape of the captured object on the image, resulting in visual
compression or magniﬁcation of the transmitter’s projection on the image [18, 28].
Moreover, when the transmitted element is at an out-of-focus distance from the imag-
ing lens, these distortions become prominent and lead to interference between adja-
cent transmitted pixels on the image, namely the inter-pixel interference (IPI). The
www.ebook3000.com

314
perspective distortions cause the transmitted elements to deform in size when the
transmitter is not at the focus of the image sensor, and in shape when it is not frontal-
ly aligned (viewed at an angle) with the image sensor. If the transmitted element is at
the focus, and assuming the transmitter and image sensor have the same resolution,
its image on the image sensor should occupy the same area as one pixel. Actual-
ly, the light rays from the transmitted element may not end exactly on image sensor
pixel boundaries, and there is some surrounding area that accumulates interference.
This area of misalignment and geometry of the imaged transmitted element will be
perspective-dependent and accounts for distortion due to the perspective scaling of
the pixel area.
Figure 9.20 Illustration of a received frame with geometry perspective distortion.
In this section, we only focus on the geometry distortion but ignore the blur dis-
tortion. The illustration of received geometry perspective distortion is provided in
Fig. 9.20. Similar to the linear misalignment, the received pixel depends on up to four
transmitted pixels due to blur eﬀect, and the intensity of a received pixel ql1,l2 can
be expressed as a function of the intensities of the transmitted pixels. Noteworthily,
for the received pixel ql1,l2, the four corresponding transmitted pixels have the nor-
malized areas of Al1,l2
1
, Al1,l2
2
, Al1,l2
3
, and Al1,l2
4
, which are determined by the shift
oﬀsets of (ax, ay), (bx, by), (cx, cy), and (dx, dy). Moreover, the normalized areas
of interference pixels are spatial dependent, diﬀerent from the linear misalignment.
If ax = bx = cx = dx and ay = by = cy = dy, then all the pixels experience
the constant shift, and the normalized areas of interference pixels are spatial inde-
pendent. Speciﬁcally, linear misalignment is a special case of geometry perspective
distortion with a constant shift oﬀset. The received ql1,l2 can be obtained from the
transmitted pixel pl1,l2 as
ql1,l2 = Al1,l2
1
p(l1+Δl(1)
1
),(l2+Δl(1)
2
) + Al1,l2
2
p(l1+Δl(2)
1
),(l2+Δl(2)
2
+1)
+ Al1,l2
3
p(l1+Δl(3)
1
+1),(l2+Δl(3)
2
) + Al1,l2
4
p(l1+Δl(4)
1
+1),(l2+Δl(4)
2
+1),

315
(9.28)
where (Δl(1)
1 , Δl(2)
1 , Δl(3)
1 , Δl(4)
1 ) and (Δl(1)
2 , Δl(2)
2 , Δl(3)
2 , Δl(4)
2 ) are the num-
ber of full pixels along the two dimensions, which are determined by the sam-
pling/shift oﬀsets.
So, the expression of the received electrical signal after the
deduction of CP and CPo, yl1,l2 can be obtained by modifying (9.21) as
yl1,l2 = Al1,l2
1
s(l1+Δl(1)
1
),(l2+Δl(1)
2
) + Al1,l2
2
s(l1+Δl(2)
1
),(l2+Δl(2)
2
+1)
+ Al1,l2
3
s(l1+Δl(3)
1
+1),(l2+Δl(3)
2
)
+ Al1,l2
4
s(l1+Δl(4)
1
+1),(l2+Δl(4)
2
+1) + zl1,l2.
(9.29)
For SACO-OFDM, after some mathematical derivation, yl1,l2 can be simpliﬁed as
yl1,l2 =
1
N1N2
N1−1

k1=0
N2−1

k2=0
U ′′
k1,k2 exp
j2πk1l1
N1
+ j2πk2l2
N2

+ zl1,l2, (9.30)
where
U ′′
k1,k2 = Xk1,k2

Al1,l2
1
exp
j2πk1Δl(1)
1
N1
+ j2πk2Δl(1)
2
N2

+ Al1,l2
2
exp
j2πk1Δl(2)
1
N1
+ j2πk2(Δl(2)
2
+ 1)
N2

+ Al1,l2
3
exp
j2πk1(Δl(3)
1
+ 1)
N1
+ j2πk2Δl(3)
2
N2

+ Al1,l2
4
exp
j2πk1(Δl(4)
1
+ 1)
N1
+ j2πk2(Δl(4)
2
+ 1)
N2

.
(9.31)
After 2-D FFT processing, the received constellations Yk1,k2 can be equivalently
expressed as
Yk1,k2 = Xk1,k2H⋆⋆
k1,k2 + Zk1,k2,
(9.32)
where Zk1,k2 is the AWGN in the spatial-frequency domain, and
H⋆⋆
k1,k2 = Al1,l2
1
exp
j2πk1Δl(1)
1
N1
+ j2πk2Δl(1)
2
N2

+ Al1,l2
2
exp
j2πk1Δl(2)
1
N1
+ j2πk2(Δl(2)
2
+ 1)
N2

+ Al1,l2
3
exp
j2πk1(Δl(3)
1
+ 1)
N1
+ j2πk2Δl(3)
2
N2

+ Al1,l2
4
exp
j2πk1(Δl(4)
1
+ 1)
N1
+ j2πk2(Δl(4)
2
+ 1)
N2

.
(9.33)
www.ebook3000.com

316
The exponential components in H⋆⋆
k1,k2 will cause phase rotation and attenuation.
The rotation angle depends linearly on the subcarrier indices (k1, k2), the extent
of the geometry distortion (Δl1, Δl2), and the spatial position (l1, l2). For a par-
ticular spatial-frequency, the amount of attenuation is determined by Al1,l2
1
, Al1,l2
2
,
Al1,l2
3
, and Al1,l2
4
which depend on the magnitude of the spatial shift/sampling oﬀsets
(ax, ay), (bx, by), (cx, cy), and (dx, dy), as shown in Fig. 9.20.
9.3.1.3
Blur eﬀect
Here, we consider only the blur eﬀect at the receiver, while the rest of impairment
factors is not taken into account except for the AWGN. To clearly illustrate the blur
eﬀect, the number of transmitted pixels is assumed to be equal to the number of
received pixels. In a practical image-sensor-based receiver, imperfect focus or limited
diﬀraction of the optics subsystem results in blurring which can be modeled by a
2-D Gaussian distribution in the spatial domain. Moreover, for the receiver made
up of an array of pixel-based photodetecting elements, the PSF is a discrete rather
than a continuous function. In a practical system, the presence of blurring leads to
ﬂuctuations in the intensity pattern, and the intensity is distributed over a larger space.
The blurring-degraded PSF hl1,l2 can be described as a 2-D discrete symmetrical
Gaussian distribution with a spread of standard deviation σ and a dimension of (2P +
1) × (2P + 1), where P is the length of both directions with respect to the center
of the distribution [21, 29]. It is assumed that P < CP and P < CPo. The discrete
blurring-degraded PSF hl1,l2 is given by
hl1,l2 = h0,0 exp
−l2
1 −l2
2
2σ2

,
(9.34)
where h0,0 is the maximum amplitude of the distribution. Considering this blurring
eﬀect in terms of hl1,l2, the intensity of each received pixel becomes the summa-
tion of the intensity of (2P + 1) × (2P + 1) transmitted pixels weighted by the
corresponding PSF elements. Hence we have
ql1,l2 = pl1,l2 ⊗hl1,l2 =
P

u=−P
P

v=−P
hu,vpl1+u,l2+v.
(9.35)
Substituting (9.35) into (9.18) and using (9.17), we obtain
yl1,l2 =
P

u=−P
P

v=−P
hu,vsl1+u,l2+v + zl1,l2,
(9.36)
where we assume ς = 1 in (9.17) and Rp = 1 in (9.18) to simplify the analysis.
Applying 2-D IFFT to Sk1,k2, the transmitted signal sl1+u,l2+v can be expressed
as
sl1+u,l2+v =
1
N1N2
N1−1

k1=0
N2−1

k2=0
Sk1,k2exp
j2πk1(l1 + u)
N1
+ j2πk2(l2 + v)
N2

.

317
(9.37)
Substituting (9.37) into (9.36) and with some rearrangement, we obtain
yl1,l2 =
1
N1N2
N1−1

k1=0
N2−1

k2=0
Sk1,k2 exp
j2πk1l1
N1
+ j2πk2l2
N2

×

P

u=−P
P

v=−P
hu,v exp
j2πk1u
N1
+ j2πk2v
N2

+ zl1,l2
=
1
N1N2
N1−1

k1=0
N2−1

k2=0
Sk1,k2Hd
k1,k2 exp
j2πk1l1
N1
+ j2πk2l2
N2

+ zl1,l2,
(9.38)
where the term Hd
k1,k2 represents the blur eﬀect, given by
Hd
k1,k2 =
P

u=−P
P

v=−P
hu,v exp
j2πk1u
N1
+ j2πk2v
N2

(a)
= h0,0 + 2
P

u=1
hu,0 cos
2πk1u
N1

+ 2
P

v=1
h0,v cos
2πk2v
N2

+ 4
P

u=1
P

v=1
hu,v cos
2πk1u
N1

cos
2πk2v
N2

,
(9.39)
where (a) is due to the symmetric of PSF in 2-D [21]. The term yl1,l2 in (9.38) is
the 2-D IFFT of Sk1,k2Hd
k1,k2 with zl1,l2. After using 2-D FFT, the term Yk1,k2 is
given by
Yk1,k2 = Sk1,k2Hd
k1,k2 + Zk1,k2,
(9.40)
where Zk1,k2 is the AWGN in the spatial-frequency domain.
For SDCO-OFDM, it is assumed that the clipping noise in (9.16) is dl1,l2 = 0.
Applying 2-D FFT to the SDCO-OFDM signal given in (9.16) results in
Sk1,k2 = Xk1,k2 + BDC δk1,k2,
(9.41)
where BDC = N1N2bDC and δk1,k2 is the 2-D Kronecker delta function deﬁned as
δk1,k2 =
 1,
(k1, k2) = (0, 0),
0,
(k1, k2) ̸= (0, 0).
(9.42)
Recall that, in spatial OFDM, the zeroth subcarrier, (k1, k2) = (0, 0), is not used to
carry data. Hence (9.41) results in Sk1,k2 = Xk1,k2 for all the received subcarriers.
www.ebook3000.com

318
Similarly, Sk1,k2 = Xk1,k2 for the data-carrying subcarriers of SACO-OFDM. So,
for both SDCO-OFDM and SACO-OFDM, one can conclude that
Sk1,k2 = Xk1,k2.
(9.43)
Substituting (9.43) into (9.40) gives
Yk1,k2 = Xk1,k2Hd
k1,k2 + Zk1,k2.
(9.44)
From (9.44), it can be observed that the blur eﬀect only attenuates the original
subcarrier Xk1,k2 by a factor of Hd
k1,k2. Moreover, the attenuation is subcarrier
dependent as shown in (9.39). Thus, the higher spatial frequency subcarriers will
experience greater attenuation.
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
Real Component
Imaginary Component
(a) Received constellation points
0
10
20
30
40
50
60
0.8
0.85
0.9
0.95
1
Subcarrier Index
Attenuation
(b) Attenuation versus subcarrier index
Figure 9.21 Received constellation for SACO-OFDM and Gaussian PSF due to blur eﬀect
with σ = 0.35.
Figure 9.21(a) illustrates the received constellation for the case of 4-QAM SACO-
OFDM, where N1 = N2 = 256, and the PSF has a standard deviation σ = 0.35. It
shows that the blur eﬀect will only attenuate the received constellation points, rather
than the phase rotation. Moreover, the attenuation is subcarrier dependent as shown
in Fig. 9.21(b). It shows that the amplitude attenuation of the constellation points
reduces gradually from unity at DC spatial frequency to 0.934 at the highest spatial
frequency. This observation veriﬁes that the constellations are attenuated depending
on the spatial frequencies and the variance of the PSF distribution.
9.3.1.4
Vignetting eﬀect
For imaging optical MIMO communication, the system is also impaired by vignetting
eﬀect which is the gradual illumination fall-oﬀfrom the center to the corners of
the received images [30]. The level of vignetting depends on the geometry of the
lens optics, aperture setting, and other optical properties of the receiver. Especially,
the cosine-fourth radiometric eﬀect is the most prominent factor that contributes to
vignetting.
Here, we consider only the vignetting eﬀect at the receiver, while the rest of the
impairment factors is not taken into account except for the addition of AWGN. Fig-
ure 9.22 shows the setup of the imaging optical MIMO system, where a1b1c1d1 is

319
Figure 9.22 Illustration of imaging optical MIMO system using an optical lens.
the transmitted frame and a′
1b′
1c′
1d′
1 is the corresponding received frame. The cen-
tre of the receiver lens is oc. The transmitted intensity signal from any pixel-based
transmitted element pl1,l2 creates an angle θl1,l2 to the optical axis acoc. The corre-
sponding received pixel ql1,l2 is also oﬀ-axis by θl1,l2. For simplicity, it is assumed
that the lens is lossless and gives a constant magniﬁcation across the whole transmit-
ting image. The aperture of the lens is small. With these assumptions, the intensity
of the received pixel ql1,l2 scaled by the vignetting eﬀect is as follows
ql1,l2 = cos4θl1,l2 · pl1,l2,
(9.45)
where the vignetting function cos4θl1,l2 for any pixel pl1,l2 can be expressed as
cosθl1,l2 =
acoc

(acoc)2 + (acal1,l2)2 ,
(9.46)
where acal1,l2 is the distance between the centre of the transmitted image ac and the
pixel pl1,l2, and acoc is the distance between the lens centre and ac. From (9.45) and
(9.46), it is clear that the vignetting function tends to approach unity when acoc ≫
acal1,l2 or acoc ≈ocal1,l2. Therefore, the size of the transmitted image and its
distance from the lens centre have an impact on the maximum level of vignetting.
Consequently, the amount of vignetting for any particular transmitter and receiver
setup depends on two ratios: γ1 = a1a2
acoc and γ2 = b1b2
acoc , where a1a2 and b1b2 are
the height and width of the transmitted image. The imaging optical MIMO system
has potential usage in short range communication where the ratios γ1 and γ2 are not
negligible. Thus the level of vignetting must be considered.
To simplify the analysis, we assume that ς = 1 in (9.17) and Rp = 1 in (9.18).
Substituting (9.45) into (9.18) gives
yl1,l2 = cos4θl1,l2 · sl1,l2 + zl1,l2.
(9.47)
Applying a 2-D FFT to (9.47), then rearranging and separating out the component at
www.ebook3000.com

320
(k′
1, k′
2), it gives
Yk′
1,k′
2 =
1
N1N2

Sk′
1,k′
2
 N1−1

l1=0
N2−1

l2=0
cos4θl1,l2

+
N1−1

k1=0
×
N2−1

k2=0
Sk1,k2 ·
N1−1

l1=0
N2−1

l2=0
cos4θl1,l2exp
j2π(k1 −k′
1)l1
N1
+ j2π(k2 −k′
2)l2
N2

+ Zk′
1,k′
2, (k1, k2) ̸= (k′
1, k′
2).
(9.48)
For SACO-OFDM, only the odd subcarriers are used to carry data. When an
SACO-OFDM signal is asymmetrically clipped, all the clipping noise falls on the
even subcarriers. Although clipping halves the amplitude of the odd subcarriers, it
can be corrected by multiplying by a factor of two before transmission. This leads to
the following frequency symbol
Sk1,k2 =
 Xk1,k2,
when k2 is odd,
Dk1,k2,
when k2 is even,
(9.49)
where Dk1,k2 is the clipping noise in the spatial-frequency domain. For SDCO-
OFDM, Sk1,k2 can be obtained by applying 2-D FFT to (9.16), where we assume
K = 1 and the clipping noise dl1,l2 = 0 to simplify analysis, as
Sk1,k2 = Xk1,k2 + BDCδk1,k2.
(9.50)
Substituting (9.49) and (9.50) into (9.48), respectively, both SACO-OFDM and
SDCO-OFDM experience attenuation Hk′
1,k′
2, and ICI term Ik′
1,k′
2, as
Yk′
1,k′
2 = Xk′
1,k′
2Hk′
1,k′
2 + Ik′
1,k′
2 + Zk′
1,k′
2,
(9.51)
where
Hk′
1,k′
2 =
1
N1N2
N1−1

l1=0
N2−1

l2=0
cos4θl1,l2.
(9.52)
For SACO-OFDM, the ICI term Ik′
1,k′
2 is given by
Ik′
1,k′
2 =
1
N1N2
N1−1

k1=0
N2−1

k2=0
(Xk1,k2 + Dk1,k2)
N1−1

l1=0
N2−1

l2=0
cos4θl1,l2 exp
j2π(k1 −k′
1)l1
N1
+ j2π(k2 −k′
2)l2
N2

, (k1, k2) ̸= (k′
1, k′
2).
(9.53)

321
For SDCO-OFDM, the ICI term Ik′
1,k′
2 is given by
Ik′
1,k′
2 =
1
N1N2
N1−1

k1=0
N2−1

k2=0
Xk1,k2
N1−1

l1=0
N2−1

l2=0
cos4θl1,l2 ·
exp
j2π(k1 −k′
1)l1
N1
+ j2π(k2 −k′
2)l2
N2

, (k1, k2) ̸= (k′
1, k′
2).
(9.54)
In Eqs. (9.52)–(9.54), the attenuation term, Hk′
1,k′
2 is independent of (k′
1, k′
2), while
the inter-carrier interference (ICI) term, Ik′
1,k′
2 is a function of Xk1,k2 and cos4θl1,l2.
The analysis of ICI term can be simpliﬁed by deﬁning an ICI complex gain F˜k1,˜k2,
given by
F˜k1,˜k2 =
1
N1N2
N1−1

l1=0
N2−1

l2=0
cos4θl1,l2 exp
j2π˜k1l1
N1
+ j2π˜k2l2
N2

,
(˜k1, ˜k2) ̸= (0, 0),
(9.55)
where (˜k1 = k1 −k′
1) and (˜k2 = k2 −k′
2) represent the spacing between the
subcarriers Sk1,k2 and Sk′
1,k′
2 in the two dimensions, and the term Sk1,k2F˜k1,˜k2
denotes the ICI contribution of Sk1,k2 to Sk′
1,k′
2. Figure 9.23(a) shows the absolute
value of F˜k1,˜k2 versus ˜k2 for N1 = N2 = 256, ˜k1 = 0, and for three levels of
vignetting. It is apparent that the value of |F˜k1,˜k2| is signiﬁcant only for small ˜k2,
and the peak is at ˜k2 = ±1. For other values of ˜k1, they have a similar form but the
absolute values are smaller.
−40
−30
−20
−10
0
10
20
30
40
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
Index Distance
ICI Gain
γ1 = γ2 = 1
γ1 = γ2 = 0.8
γ1 = γ2 = 0.6
(a) The ICI gain |F˜k1,˜k1| versus index distance ˜k2
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Real Component
Imaginary Component
(b) Constellation for a 4-QAM SACO-OFDM under
vignetting with γ = 1 [30]
Figure 9.23 The ICI gain and received constellation for spatial OFDM in the presence of
vignetting.
Consequently, for both SACO-OFDM and SDCO-OFDM, the zeroth subcarrier
has the largest amplitude and therefore makes the greatest ICI contribution than any
www.ebook3000.com

322
other subcarriers. Moreover, the subcarriers close to the zeroth one experience severe
ICI. This is more pronounced in SDCO-OFDM, where the zeroth subcarrier has a
very large amplitude resulting from the DC bias. Figure 9.23(b) shows the received
constellations for the case of 4-QAM SACO-OFDM, using 256 × 256 subcarriers,
CP = CPo = 10%, and γ1 = γ2 = 1 as shown in Fig. 9.22. Noteworthily, the large
amplitudes for even subcarriers are not displayed in Fig. 9.23(b), since SACO-OFDM
uses only odd subcarriers for data carrying. Moreover, the eﬀect of noise is ignored
to illustrate the eﬀect of vignetting. It can be seen that, the constellation points will
experience both phase rotation and amplitude attenuation with vignetting eﬀect.
9.3.2
Impairment mitigation techniques
As discussed above, the general case of the linear misalignment and geometry per-
spective distortion produces pixel-dependent sampling oﬀset and spatial dependent
normalized areas of interference pixels. It thus induces both amplitude attenuation
and phase rotation. The rotation angle is determined by the subcarrier index, the ex-
tent of the geometry distortion, and the spatial position. The amplitude attenuation
is subcarrier dependent, and the attenuation level also depends on the magnitude
of the spatial shift/sampling oﬀsets. Under signiﬁcant perspective distortion, the
equalizer cannot completely compensate the attenuation and angle rotation eﬀect if
the sampling oﬀsets are large. Therefore, perspective correction is necessary before
equalization. Another impairment, the blur eﬀect causes attenuation on the higher
spatial frequency subcarriers. Similar to the fractional misalignment, the attenuation
can be corrected by an equalizer at the cost of noise enhancement. Furthermore, the
vignetting also causes attenuation in the spatial-frequency domain. However, dif-
ferent from the linear misalignment and blur eﬀect, the attenuation is the same for
all subcarriers, and independent of spatial frequency. Moreover, the vignetting also
causes ICI which brings an extra noise term in the received subcarriers. This ICI
noise is enhanced by the equalizer, and interacts with the attenuations due to all the
impairments.
Note that, the four components of attenuation and phase rotation are independent
because of the diﬀerent underlying mechanisms. The overall attenuation and phase
rotation for a given subcarrier can be calculated by multiplying the individual atten-
uation and phase rotation factors jointly.
9.3.2.1
Equalization
Based on the property of spatial impairment factors, linear misalignment, geometry
perspective distortion, blur eﬀect, and vignetting all aﬀect the system performance in
a similar manner. In order to overcome the linear misalignment and blur eﬀect, one
can equalize the received signal with the unused higher subcarriers. To minimize the
vignetting eﬀect, a small number of lower subcarriers is kept null, and a vignetting
estimation and equalization technique is applied.
In conventional 1-D OFDM, OFDM can dramatically simplify the equalization
task by turning the frequency-selective channel into a ﬂat channel. Similarly, in

323
the spatial-frequency domain, a simple one-tap equalizer is needed to estimate the
channel and recover the data [6, 17]. In the following, utilizing a decision feedback
equalizer (DFE) for mitigating the nonideal spatial eﬀect at the receiver side will be
addressed.
For short-range imaging optical MIMO links where the receiver plane is assumed
to be parallel to the transmitter plane, the channel noise is dominated by the thermal
noise due to readout circuit and shot noise due to ambient light. The transmitter is
a spatial light modulator, LCDs or LEDs of size N1 × N2 pixels with pixel space
equal to DT in both dimensions. The image sensor has a resolution of M1 × M2
and a sampling rate DR in both dimensions. The full Nyquist region of size is
1
DT ×
1
DT and
1
DR ×
1
DR for transmitter and receiver, respectively. It imposes a limit
on the maximum spatial frequency that can be supported by each side. Its spatial
frequency response is termed as optical transfer function (OTF) to characterize the
spatial property, similar to PSF in the temporal impulse response of the channel. The
imaging optical MIMO channel can be modeled in general as
y[l1, l2] = x(T {x, y}) ⊗h(x, y) + z(x, y)|x=l1DR,y=l2DR,
(9.56)
where h(·) denotes the spatial PSF, including magniﬁcation (or blur) eﬀect, rota-
tion (or geometry perspective distortion), and DR is the spatial sampling rate (pixel
spacing) at the receiver in both spatial dimensions. The transformation T (·) denotes
the remapping of the coordinates caused by spatial misalignment, magniﬁcation, and
rotation perspective. In the following, the magniﬁcation and rotation perspective are
addressed, while the spatial misalignment is excluded since the resulting linear phase
shift in the spatial frequency domain can be easily equalized.
The blur eﬀect or spatial magniﬁcation will expand the image in space, equivalent
to compression in spatial frequency. This joint spatial distortion in the continuous
spatial frequency domain can be described by
 ˜f1
˜f2

= 1
κ

cosθ
sinθ
−sinθ
cosθ
  f1
f2

,
(9.57)
where ( ˜f1, ˜f2) are the transformed spatial frequency coordinates, (f1, f2) are the
spatial frequency coordinates of the transmitter. The spatial magniﬁcation is denoted
by κ, and θ is the rotation angle. After spatial discrete multitone (SDMT) modulation
based on continuous tones, the Nyquist region of the transmitted frames is divided
into discrete spatial frequency bins. The continuous spectrum of the transmitted
frames in the continuous spatial frequency domain X(f1, f2) is given by
X(f1, f2) =
1
N1N2D2
T
N1−1

k1=0
N2−1

k2=0

X[k1, k2]
· δ

f1 −
k1
N1DT
, f2 −
k2
N2DT

,
(9.58)
where X[k1, k2] denotes the SDMT frame in the discrete spatial frequency. Actu-
ally, the eﬀect of the pixel shape is coupled with the OTF measurement. Thus the
www.ebook3000.com

324
transmitted image can be treated as a continuous waveform in 2-D space.
During reception by the image sensor, the transmitted image is magniﬁed and ro-
tated. The spatial frequency spectrum (or signal) of the transformed image is given
by
˜X(f1, f2) =
1
N1N2D2
T κ2
N1−1

k1=0
N2−1

k2=0

X[k1, k2]δ
f1 −ν1, f2 −ν2

,
(9.59)
where
ν1 = 1
κ
k1cosθ
N1DT
+ k2sinθ
N2DT

,
(9.60)
and
ν2 = 1
κ

−k1sinθ
N1DT
+ k2cosθ
N2DT

.
(9.61)
At the receiver, the captured image is multiplied by a windowing function of size
M1DR × M2DR, where the windowing function signiﬁes the ﬁnite extent of the
image sensor. The resulting signal is given by
Y (f1, f2) = H(f1, f2)
N1N2D2
T κ2
N1−1

k1=0
N2−1

k2=0

X[k1, k2]
· W
f1 −ν1, f2 −ν2

+ ˜Z(f1, f2),
(9.62)
where W(·) is the 2-D Fourier transform of the ﬁnite extent window, H(·) is the
channel OTF, and ˜Z(f1, f2) = Z(f1, f2)⊗W(f1, f2) is the 2-D Fourier transform
of the windowed channel noise. This signal is sampled in the spatial domain with a
sampling period equal to DR in both dimensions. The received sampled signal can
be expressed as
Y [˜k1, ˜k2] =H[˜k1, ˜k2]
N1−1

k1=0
N2−1

k2=0

X[k1, k2]
U[˜k1, ˜k2; k1, k2]

+ ˜Z[˜k1, ˜k2],
(9.63)
where
U[˜k1, ˜k2; k1, k2] =
W

˜k1
M1DR −ν1,
˜k2
M2DR −ν2

N1N2D2
T κ2M1M2D2
R
.
(9.64)
In (9.63), the received data in the spatial frequency bin [˜k1, ˜k2; k1, k2] is a combi-
nation of the transmitted data in all the discrete spatial frequency bins. And the joint

325
eﬀect is referred to as spatial frequency inter-channel interference (SF-ICI). The joint
function U(·) is a spatial frequency-dependent function, determined by the window,
magniﬁcation, and rotation perspective. It is desirable to have a narrow main-lobe
and high side-lobe attenuation. However, there is a tradeoﬀbetween the width of the
main-lobe and the attenuation of the side-lobes. Since the SF-ICI exists in a small
band of neighboring frequencies and can easily be equalized, a wide main-lobe and
high side-lobe attenuation window such as Blackman window is preferred.
Bin-by-bin detection for the SF-ICI channel
For bin-by-bin detection, the received signal in space is multiplied by a rectangular
window function, and the detected signal is given by
ˆX[˜k1, ˜k2] = D−1

Y [˜k1, ˜k2; ]
H[˜k1, ˜k2]U[˜k1, ˜k2; k1, k2]

,
(9.65)
where D−1(·) represents a decision device. Note that, by using a rectangular win-
dowing function, the SF-ICI eﬀect is assumed to be negligible to simplify system
design, since most of the signal energy is concentrated in one frequency bin. That
means, when SF-ICI is zero, bin-by-bin detection is the optimal detection strategy.
DFE for the SF-ICI channel
Figure 9.24 Diagram of decision feedback equalization in spatial frequency domain.
Since magniﬁcation and rotation perspective aﬀect the system in a similar manner,
it is assumed that the system undergoes magniﬁcation only to simplify the receiver
design. By designing a proper window, the SF-ICI can be limited to a small band of
www.ebook3000.com

326
frequencies, and (9.63) can be approximated by
ˆY [˜k1, ˜k2] ≈H[˜k1, ˜k2]
˜k1+τh1

k1=˜k1−τg1
˜k2+τh2

k2=˜k2−τg2

X[k1, k2]
U[˜k1, ˜k2; k1, k2]

+ ˜Z[˜k1, ˜k2].
(9.66)
The above equation implies that, by choosing a proper window, the interference in
each frequency bin [˜k1, ˜k2] can be limited in its neighboring bins [−τg1, τh1], and
[−τg2, τh2]. Note that, since the inference in Y [˜k1, ˜k2] is non-causal, it cannot be
eliminated completely from Y [˜k1, ˜k2]. To overcome non-causality, the DFE is in-
troduced to the system as shown in Fig. 9.24. By introducing a spatial delay, the
signal ˆX[˜k1 + τh1, ˜k2 + τh2] is estimated by observing its SF-ICI contribution to
the received signal Y [˜k1, ˜k2]. Note that, for DFE equalization, ˆX must be known
for all frequencies preceding the spatial frequency bin [˜k1 + τh1, ˜k2 + τh2] relative
to a decoding path.
To improve the performance of the DFE, windowing function design is needed.
In [17], two window design criteria are introduced. The ﬁrst one is to design a win-
dow with high SNR, and the second one is to make most of the window energy to
be used in the feedback loop. Thus, for SF-ICI limited channels, the complex win-
dowing with DFE can be used to equalize the SF-ICI in the spatial frequency domain
with excellent BER performance and low complexity.
9.3.2.2
Perspective correction
Perspective transformation is widely studied in computer vision and usually requires
higher computation complexity. However, for the imaging optical MIMO communi-
cation system, the oﬀ-line algorithms are not applicable and the system cannot toler-
ate signiﬁcant time delay. The system can only tolerate minor perspective distortions
typically acceptable to the human eyes. On the other hand, it oﬀers more design
ﬂexibility if we can encode the imaged object in a manner that simpliﬁes correction
for perspective distortion. Due to the constraints mentioned above, the traditional
perspective correction algorithms cannot be used in imaging optical MIMO systems
directly. Then, a generalized spatial OFDM sampling correction algorithm is intro-
duced [18].
The intuition underlying these approaches is as follows. We can approach the
perspective distortion problem as a sampling problem from the communication per-
spective [18]. Speciﬁcally, the intensities of transmitted elements refer to the signal
samples at the transmitter. The received intensities in a pixelized receiver refer to the
signal samples at the receiver. When the transmitter, such as LCD, and camera-based
receiver, are located at an angle, some parts of the LCD are closer to the camera, and
hence occupy a relatively bigger space in the image. This means a higher sampling
rate for this part. Parts of the transmitted elements further away from the camera
occupy a relatively smaller space in the image, which means they are sampled at a
lower rate. To tackle the perspective distortion problem, the spatial OFDM-based

327
imaging optical MIMO system needs to ﬁnd the relationship between the sampling
points on the image sensor and those on the transmitted elements, and resample the
received image at the location that best reﬂects the originally transmitted samples.
To decode the signal properly, the receiver needs to resample the signal as closely as
possible to the transmitter’s samples. Based on this intuition, a generalized OFDM
sampling correction algorithm can be used to tackle the perspective distortion.
A basic property of the Fourier transform is that a time shift corresponds to the
phase oﬀset in the frequency domain. Given this property, it is relatively simple to
ﬁgure out how the sampling shift oﬀsets aﬀect the encoded data as in Eqs. (9.31)–
(9.32). Consider a general case where we sample a spatial OFDM symbol with a
perspective distortion as shown in Fig. 9.20. The corner shifts would result in phase
oﬀsets at the receiver. Speciﬁcally, spatial OFDM symbol xl1,l2 is generated by tak-
ing a 2-D IFFT on the complex signal Xk1,k2, and the receiver samples the spatial
symbol with a shift. To decode the spatial OFDM symbol from these samples, the re-
ceiver takes a 2-D FFT. However, because the samples are shifted, the 2-D FFT does
not reproduce exactly the original complex signal, rather than a phase-shifted ver-
sion, denoted as Xk1,k2H⋆⋆
k1,k2 +Zk1,k2, of the original complex signal. Thus, each
complex signal experiences attenuation and phase shift H⋆⋆
k1,k2 as in (9.33), where
H⋆⋆
k1,k2 is determined by the shift oﬀsets of (ax, ay), (bx, by), (cx, cy), and (dx, dy).
Thus, if the unknown attenuation and phase shift H⋆⋆
k1,k2 need to be estimated, there
are totally eight unknowns to estimate (ax, ay), (bx, by), (cx, cy), and (dx, dy). It
means that we need at least eight equations to estimate these eight oﬀsets. We solve
this problem by considering a super-symbol consisting of four symbols as shown in
Fig. 9.20.
A 2 × 2 spatial OFDM super symbol can be used by taking the 2-D IFFT on the
complex Xr
k1,k2, where (k1, k2) are the subcarrier indices with 0 ≤k1 < N1 and
0 ≤k2 < N2, r ∈{(l1, l2), (l1, l2 + 1), (l1 + 1, l2), (l1 + 1, l2 + 1)} denotes the
symbol index or the spatial position. This symbol is sampled with relatively small
x and y corner oﬀsets of (ax, ay), (bx, by), (cx, cy), and (dx, dy) at its four cor-
ners. Let Δθr
x be the diﬀerence between the phase shifts experienced by Xr
k1,k2 and
Xr
k′
1,k2, and Δθr
y be the diﬀerence between the phase shifts experienced by Xr
k1,k2
and Xr
k1,k′
2, then we have [18]
⎛
⎜
⎜
⎜
⎝
Δθ(l1,l2)
x
Δθ(l1,l2+1)
x
Δθ(l1+1,l2)
x
Δθ(l1+1,l2+1)
x
⎞
⎟
⎟
⎟
⎠= 2π(k1 −k′
1)
16N1
⎛
⎜
⎜
⎝
9
3
3
1
3
9
1
3
3
1
9
3
1
3
3
9
⎞
⎟
⎟
⎠
⎛
⎜
⎜
⎝
ax
bx
cx
dx
⎞
⎟
⎟
⎠,
(9.67)
and
⎛
⎜
⎜
⎜
⎝
Δθ(l1,l2)
y
Δθ(l1,l2+1)
y
Δθ(l1+1,l2)
y
Δθ(l1+1,l2+1)
y
⎞
⎟
⎟
⎟
⎠= 2π(k2 −k′
2)
16N2
⎛
⎜
⎜
⎝
9
3
3
1
3
9
1
3
3
1
9
3
1
3
3
9
⎞
⎟
⎟
⎠
⎛
⎜
⎜
⎝
ay
by
cy
dy
⎞
⎟
⎟
⎠.
(9.68)
www.ebook3000.com

328
Using the pilot bins, the receiver computes the attenuation and phase shift ex-
perienced by each known pilot. Then, the oﬀsets (ax, ay), (bx, by), (cx, cy), and
(dx, dy) are estimated with the help of Eqs. (9.67) and (9.68). Afterwards, the re-
ceiver can resample each spatial OFDM symbol at the correct sampling points and
compute the 2-D FFT again. Then the received signals are demodulated to obtain
the transmitted bits.
9.3.2.3
Adaptive coding and modulation
The joint blur eﬀect and perspective distortions eliminate sharp transitions in an im-
age and cause nearby pixels to blend together. This process is similar to low pass
ﬁltering which attenuates the high-frequency subcarriers in spatial OFDM. General-
ly, the signal amplitudes of the transmitted signal and its received version are func-
tions of the frequency index, as shown in Fig. 9.25. The transmitted signal is chosen
to have the same energy at all frequencies. At the receiver, the high frequencies
are heavily attenuated and can only support low-order modulation signals. In some
extreme cases, they cannot even be used for transmitting information. Conversely,
the low frequencies have only slight attenuation. They can deliver information with
almost no error and can support high-order modulation transmission. All other fre-
quencies experience signiﬁcant attenuation but can still be used to transmit some
information [18].
Figure 9.25 The transmitted and received signal amplitudes across diﬀerent frequencies
due to the blur eﬀect.
It is clear that spatial OFDM belongs to spatial-frequency domain modulation.
It can naturally deal with diﬀerent frequencies experiencing diﬀerent attenuations.
Spatial OFDM completely suppresses very high frequencies, which are not used to
transmit information or only transmit low-order modulation signal. Frequencies that
experience low or moderate attenuation are used to transmit information and protect-
ed with error correction code such as Reed–Solomon (RS) code. An error correction
code is chosen for each frequency with diﬀerent redundancy commensurate with the
attenuation each frequency experiences. Moreover, due to geometry distortion, the
extent of attenuation varies not only with frequency, but also with the spatial position
of the pixels/symbols in a received frame. Generally, symbols away from the center

329
of the frame are not in the plane of focus and hence experience increased attenua-
tion due to blur eﬀect. Thus, a spatial OFDM system can exploit this property to
optimize the redundancy of the error correction code and the modulation order [18].
Speciﬁcally, the symbols at the center of the frame will have low redundancy and can
support high-order modulation, while the symbols away from the center of the frame
will have high redundancy.
9.4
Synchronization in OCC
9.4.1
Synchronization challenges
To achieve a high throughput, the imperfect frame synchronization issues must be ad-
dressed in a practical OCC system. Frame synchronization is a prerequisite for eﬀec-
tive communication. However, perfect synchronization is diﬃcult in OCC. Synchro-
nization failure is mainly caused by frame rate mismatch and a phase oﬀset between
the transmitted element and the image sensor. Figure 9.26 shows some examples.
Typically, only a frame within one transmission period is a clean frame, and thus can
be decoded. If a captured frame spans across diﬀerent transmission frames, it be-
comes a mixed frame. Moreover, since most CMOS-based cameras employ rolling
shutter which scans one line at a time, it makes frame mixing vary on a per-line basis.
Such a frame has to be dropped usually. The frames may also get lost due to discrete
shutter sampling, if the transmitted element’s refresh rate is higher than the camera’s
capture rate. Only after receiving all the transmitted frames cleanly can a receiver
successfully decode the original message (cases 1 and 3).
Figure 9.26 Mismatched frame rates between transmitter–receiver pairs (inter-frame
intervals are omitted).
The diﬃculty in frame synchronization arises from frame rate diversity and vari-
www.ebook3000.com

330
ability [31]. From Nyquist sampling theorem, a receiver should capture frames at a
rate at least twice the transmitted rate, to guarantee that it could receive all frames
cleanly (case 3). Unfortunately, in terms of rate capability and visual experience,
Nyquist sampling rate is unavailable for a commercial image sensor. Some mod-
ern transmitted elements such as LCD screens usually have a 60 fps or even higher.
The other transmitted elements such as LED array or traﬃc light can support higher
rate. However, most of the commercial consumer cameras have lower frame rates of
up to 30 fps. Moreover, many cameras embedded in smartphones exhibit unsteady
frame rate due to hardware design, ﬁrmware setting, and application program inter-
face (API) constraints.
Variability and unsteady inter-frame intervals: Compared to the transmitted ele-
ments, the received frame rate exhibits more variability. The camera needs suﬃcient
light exposure to capture legible frames. The time it takes to harvest suﬃcient light
depends on the image sensor’s sensitivity and the lighting conditions, in particular,
the contrast and intensity levels. Therefore, it is necessary to adopt a diﬀerent frame
rate adaptive to speciﬁc contrast and intensity levels, and the camera normally ad-
justs this rate automatically to ensure the visual quality of the captured frames. Since
the readout rate is limited by the image sensor readout circuit hardware, perfect ac-
quisition of the matched frame rate is impossible. Even if we control the frame rate
by the application software and disregard the imaging quality in the OCC mode, the
unsteady frame rate is inevitable due to the limited readout rate in the readout circuit
and the post-processing unit in an image sensor.
Operation range and diversity across devices: The maximum frame rate is deter-
mined by the readout rate in the image sensor and the hardware quality, such as the
sensor quality and heat dissipation capability of the device. Diﬀerent cameras can
support diﬀerent maximum frame rates. Moreover, the camera will automatically
compensate for the changed average intensity of each transmitted frame by adjusting
the frame rate. Thus, the frame rate varies across diﬀerent transmitted frames for a
given camera, and for the same transmitted frame across diﬀerent cameras.
Usually, if each frame for mixing is homogeneous, the mixed frame is also homo-
geneous. We often obtain mixtures of diﬀerent frames at the same captured frame
rate. Moreover, since most image sensors embedded in cameras are rolling-shutter-
based CMOS image sensors, the proportion of mixture varies by line even for the
same frames. Generally, only completely clean frames can be decoded. Therefore,
the goal of frame synchronization is to adjust the frame rates on both sides to capture
enough clean frames to decode all original information.
Typical frame synchronization approaches let the receiver capture frames at a rate
twice as fast as the transmitter to ensure a good frame every other frame. However,
there are several fundamental drawbacks for these approaches. First, they are inef-
ﬁcient. The transmitter-side capacity is under-utilized, while the receiver drops a
large number of mixed frames that actually contain much useful information. Sec-
ond, they assume an initial sender setup based on the receiver capability, which, in
practice, requires feedback and needs to tailor to individual receivers. Third, they are
still unreliable in the presence of receiver rate ﬂuctuation, which makes it diﬃcult to
work with a general phone camera. Since each frame is already in the form of discrete

331
samples, we could have equal frame rates on both sides in theory. The key to achieve
this is to decode imperfect frames and recover lost frames. The former is complicat-
ed due to inherent image quality issues. The latter can be easily implemented with
erasure coding across the original frames, which can also help to reduce decoding
errors. Except the oversampling approach, there exist some other schemes to tackle
the synchronization issue, such as per-line tracking and inter-frame coding [31], and
rateless coding [33].
9.4.2
Per-line tracking and inter-frame coding
To achieve faster and more ﬂexible frame synchronization, and allow smooth commu-
nication between the transmitter and cameras with diﬀerent frame rate, the per-line
tracking and inter-frame coding synchronization scheme was proposed in [31], which
features two main components. First, this approach adopts intra-frame per-line color
tracking to decode the mixed frames. As a result, any received frame is decodable
and useful. Second, it employs inter-frame erasure coding and frame-based tracking
to recover lost frames and to prevent incorrect frames. Based on this scheme, all
captured frames containing useful information can contribute to the overall frame
recovery, and result in reliable information transmission.
9.4.2.1
Line-based overlap tracking
To tackle frame mixing due to rolling shutter eﬀect, the pre-designed line-based over-
lap tracking bars are inserted into each frame in the shutter rolling direction. With
these tracking bars, the percentage of overlap in each line can be tracked by compar-
ing with the reference colors. Figure 9.27 illustrates the layout of the color pattern,
where four bars are placed in each transmitted frame, two white and two black. Each
vertical line represents a tracking bar, while each horizontal line represents the color
pattern of a line in the frame. The color pattern shifts by one bar in each succes-
sive transmitted frame, and the overall patterns repeat every four frames. As a result,
all four combinations are present in any received frame, and the four blocks in each
line serve as reference colors for per-frame decoding. The idea for these schemes
is analogous to training sequence placement in traditional 1-D radio frequency (RF)
communications.
For any block in a mixed frame, the decoding algorithm proceeds in two stages [31].
First, the exact transmitted frames are determined by using the tracking bar encod-
ing pattern. By identifying the component frames per line, we are able to handle
practically any phase oﬀsets between the transmitted and the captured frames. And
then, the code block color was compared with the reference colors to determine the
code block sequence in the original frames concerned. Taking the color distortion
into account, the inference-based approach is preferred, which allows us to decode
multiple transmitted frames from a single mixed frame. Otherwise, we look up the
block at the same position in the previous captured frame to help resolve the ambi-
guity. If that still fails, we mark this block unknown, and leave it to the cross-frame
correction stage of inter-frame erasure decoding.
www.ebook3000.com

332
Figure 9.27 Per-frame tracking bar pattern.
9.4.2.2
Inter-frame erasure coding
One of the key ideas of inter-frame coding is to apply erasure coding across the orig-
inal frames, so that every transmitted frame may contain information from multiple
original frames [31]. It means that any partial or mixed frame is just a version of the
coded frame and can be decoded as long as we keep track of the coding coeﬃcients.
Therefore, once the image sensor captures enough linearly independent frames, all
original frames can be recovered.
Ideally, each encoded frame should be a linear combination of all original frames,
but linearly independent of any other encoded frames. This would allow us to re-
cover all N original frames from any N encoded frames. Generally, a sparse and
deterministic coding matrix is necessary for low complexity coding. To guarantee
no more than one frame loss per three frames and speed up decoding, we can di-
vide all original frames to groups of three consecutive frames. Then, generate the
transmitted frame sequence as [F1, F2, F3, F1 ⊗F2, F2 ⊗F3, F1 ⊗F3], where the
ﬁrst half of the frame sequence F1, F2, and F3 contains the original frames, and the
second half includes the encoded frames. The chosen coding matrix is suboptimal to
make a linearly independent transmitted frame sequence. However, even seemingly
linearly dependent encoded frames will be helpful when per-frame decoding error
happens.
An erasure coder treats each frame as a stream of bits and encodes it to a coded bit
stream with the same length. Therefore, the inter-frame coding is independent of the
base code per frame, and can be viewed as an outer code over a 2-D barcode. The
coded bits within a frame can then be mapped to colored blocks and the blocks are
arranged in some pattern following the per-frame base code. After frame tracking, the
original frames are determined. Once the receiver captures enough coded frames and
the corresponding rows of the coding matrix are known, decoding is straightforward
by using a few XOR to recover the original frames. Since only part of the frame is

333
lost, decoding can be performed only for the lines with missing information.
9.4.2.3
Unsynchronized system design
At the transmitter, an erasure-coded bit stream is obtained by erasure coder and the
transmitted frames are generated following bit-to-block mapping according to the
code block layout. To keep track of the transmitted frames with low complexity, a
code block as in COBRA system [32] can be optimized and designed. The tracking
bars as shown in Fig. 9.27 can be inserted into each frame which is perpendicular
to the scanning direction in order to track the mixed frames. Finally, the encoded
frames are transmitted at a given transmission frequency.
At the receiver, after identifying the beginning coded sequence, we invoke per-
frame decoding and cross-frame correction. And then, we perform per-frame de-
coding process to decode the coded blocks. Once the decoder detects a frame in the
second half of the transmitted frame sequence in the received frame, we start cross-
frame correction after erasure decoding each new frame and ﬁlling in any missing
blocks at the relevant positions if possible. Both frame capture and decoding ter-
minate if all original frames have been decoded. The blocks are then mapped to an
output bit stream.
From the signal processing perspective, an erasure coding approach is essentially a
form of undersampling, where the sampling rate is lower than the Nyquist rate. And
it is an eﬀective approach to tackle the synchronization issue. In the last subsection,
another special erasure coding approach, named as rateless coding approach, will be
introduced for an asynchronous system.
9.4.3
Rateless coding
Similar to synchronization scheme using the per-line tracking and inter-frame coding,
which could decode mixed frames, recover lost frames and guard against incorrectly
decoded frames, there exists another synchronization scheme to recover the original
data by rateless coding approach [33]. In a practical OCC system, the link quality
varies according to many factors, including ambient light, unsteady frame rate, per-
spective distortion, and trembling of user’s hands. Therefore, the systems need to
adapt to the link diversity. For rateless coding, it ﬁts well with the channels in which
interruptions occur frequently since the encoded bits of the same original informa-
tion are generated continuously till the successful transmission is completed [34]. By
using rateless codes, protocol complexity and packet delay can be reduced due to the
fact that only the correctly received information needs the feedback information. If
rateless coding is adopted to convert the original data into a stream of encoded bits,
the receiver can extract information from the captured frames, even with error bits.
Since every encoded bit contains useful information of the original data, each cor-
rectly decoded bit is useful for the link throughput. Once the receiver accumulates
suﬃcient amount of clean bits, it can recover the original data by rateless decod-
ing. Thus, the transmitter is able to automatically adapt the data rate to the dynamic
channels with diﬀerent qualities, including the asynchronous link.
www.ebook3000.com

334
The conventional rateless erasure codes, such as Luby Transform (LT) code [35]
and Raptor code [36], are both based on blocks of bits. The transmitted block (or
packet) is assumed to be either correctly received or totally lost. A critical factor that
aﬀects the system performance is the block size. If the block size is too large, more
blocks may be discarded even though they contain a large proportion of clean bits.
Otherwise, more overhead is required. And the block size is adaptively adjusted ac-
cording to the channel coherence as in conventional RF communication. However,
for OCC links, it is diﬃcult to set an appropriate block size due to the lack of feed-
back about channel coherence from cameras. Thus, it is diﬃcult to build an eﬃcient
erasure channel. The other rateless codes for AWGN channels, like Spinal codes
and soft decoding, avoid the block size setting by bit-level coding. However, the
computational complexity is too high in the decoding process, due to the intensive
ﬂoating-point iteration operations. To tackle the challenges, the light-weight rateless
coding on bit-level erasure channel is proposed [33], which extracts soft hint from
every received symbol to assess how likely each bit is correctly decoded during de-
modulation. An erasure channel can be established by discarding the symbols with a
soft hint lower than a threshold, where the soft hint can be interpreted as distance in
signal space between the received symbol’s constellation and the decoded symbol’s
constellation points [33]. And then, light-weight rateless erasure coding can be used
over the bit-level erasure channels.
By incorporating a set of proper modulation techniques, it enables an accurate
soft hint estimation and establishes a bit-level erasure channel with minimized false
positive (the ratio between the number of wrongly reserved bits and the total number
of received bits) and false negative (the ratio between the number of wrongly erased
bits and the total number of received bits). Furthermore, the rateless coding scheme
adopts a new light-weight bit-level rateless coding scheme that tolerates the false
positive of the bits provided by the erasure channel. The transmitter encodes the data
frames based on a systematic rateless code and the receiver decodes the received
frames by XOR operations at the frame level. The uncertain bit positions are taken
into account, which enables bit-level rateless decoding. A majority vote decoding
algorithm can be used to eliminate the impact of false bits and guarantee the decoding
eﬃciency with slight computational complexity increase.
At the transmitter, the encoder encodes data by a systematic rateless code at the
frame level. The transmitter divides the original bit stream into a sequence of bit
frames, then the bit frames are encoded by a FEC code, like RS code, LDPC code, or
extended irregular repeat accumulate (eIRA) code as shown in Fig 9.28, to generate
some parity-check frames for error correction. The intermediate frames (including
the original bit frames and the parity check frames) are further encoded to produce a
stream of rateless frames, each of which is calculated by XORing a certain number
of randomly chosen intermediate frames. The encoded frames including both the
intermediate frames and the XORed frames are transmitted in series. The systematic
design allows the system to approach the channel capacity when the link quality is
high. In every transmitted frame, the coding information is inserted, including the
number of original frames and the seed of random number generator, which allows
the receiver to reproduce the generation equations (coeﬃcient matrix) of encoded

335
frames.
Figure 9.28 The architecture of eIRA-Raptor coding and joint iterative decoding.
Upon the reception of its ﬁrst frame, the receiver reproduces the generation equa-
tions. By solving the linear generation equations (the number of equations is n times
larger than the number of variables), every intermediate frame has multiple instances,
each of which is expressed by XORing several encoded frames. When an encoded
frame is received, it is plugged into the expressions of the related instances. As more
encoded frames are received, more instances are calculated. For one bit position, all
calculated instances of diﬀerent intermediate frames may have diﬀerent results. A
majority vote decoding algorithm is performed to ﬁnd the correct value of each bit.
We record the occurrence frequency of “1” and “0” at every bit position in all calcu-
lated instances. The bits are set to the value with the highest occurrence frequency.
Therefore, for every bit position, the error or “x” bits in one or few instances can be
overweighed by the other correct instances.
As mentioned above, the CMOS-based cameras in the current smart devices cap-
ture an image by the rolling shutter scheme. If the frame rate of the transmitter is
high, some received frames may contain the contents of multiple transmitted frames
and the lines captured during the transition of the transmitted frames experience se-
vere blur eﬀects. With the rateless coding scheme, the system can automatically
recover from the bit loss of blurred symbols by accumulating more rateless encoded
bits. Moreover, the rateless coding scheme is able to automatically adapt to diﬀerent
communication environments and signiﬁcantly improve the throughput of OCC sys-
tems. Furthermore, we can optimally design the code-rate, code-length, or degree
distribution for OCC according to the link quality variations. In addition, the intra-
frame diversity causes link quality variation, and thus considerable decoding errors.
In order to recover the erroneous symbols, interleaving operation can be incorporat-
ed before transmission. By interleaving, the bits at diﬀerent positions experience a
similar bit reception rate on average. All bit positions succeed in decoding almost
www.ebook3000.com

336
at the same time. Even if a few bits of the intermediate frames are incorrect, the
original bit frames can be recovered by the parity-check frames.
9.5
OCC system experimental platform
9.5.1
Design and implementation of a real-time OCC system
In OCC, most eﬀorts are focused on increasing data rate and communication dis-
tance by maximally utilizing the spatial, frequency, intensity, and color dimensions,
such as undersampling-based modulation schemes, rolling shutter eﬀect-based mod-
ulation schemes, spatial OFDM/DMT, and CSK, as introduced in Section 9.2. The
modulation methods in the literature can perform very well under a stable frame
rate. However, the system performance will dramatically degrade due to the frame
rate ﬂuctuation of a commercial image sensor.
In this part, a real-time OCC system design by using an LED display and an image
sensor will be introduced. To solve the frame synchronization problem encountered
in a typical commercial sensor, the LED display is refreshed at a much lower rate than
the sensor frame rate, and upsampled signal processing techniques are developed to
recover data at the receiver. Each LED has independently controlled RGB chips,
and each Bayer-pattern sensor unit yields RGB parallel outputs. Thus, CSK [39, 40]
and multilevel PAM [41] are combined in the design of the proposed color-intensity
modulation (CIM). Meanwhile, the pixels in the sensor are partitioned into detec-
tion sub-blocks, and each block is ﬁt with the image of the LED at the display and
separates three colors as well. Thus, an MIMO channel conﬁguration is constructed.
In the following, by using an RGB LED array and millions of pixels, we can design
a real-time CIM-MIMO OCC system [37]. To tackle the critical issues in a practi-
cal OCC system, including the unstable frame rate, the joint transceiver nonlinearity
and color crosstalk eﬀect, ﬂicker noise, and rolling shutter, a redundant transmis-
sion and upsampled reception technique is applied to make a smooth communica-
tion, even with the inevitable frame instability. Moreover, signal constellation and
iterative training sequences are designed to tackle the joint nonlinearity and color
crosstalk eﬀect, and rolling shutter eﬀect, respectively. Therefore, spatial, color, and
intensity dimensions are fully utilized to create a suboptimal high-dimensional signal
constellation and parallel communication channels. Applying a commercial 16×16
LED array with 192 data-carrying LEDs using 256-CIM at a refresh rate of 82.5 Hz
and a mobile phone camera at a frame rate of 330 fps, the proposed experimental
system achieves a real-time data rate of 126.72 kbps over communication distance
up to 1.4 m without any external optical assistance.
9.5.1.1
CIM-MIMO modulation and signal detection framework
In the CIM-MIMO framework, signals in terms of triplet LED driving currents are

337
mapped into the intensity and color of emitted light of each RGB LED unit in a
K-element array. Considering (Lr, Lg, Lb) intensity levels for each color, totally
M = Lr × Lg × Lb CIM symbols, each of which contains B = log2M data bits,
are generated and described as the collection of triplets
S = {s1, s2, · · · , sM},
(9.69)
where the mth CIM symbol is given by
sm = [im
r im
g im
b ],
(9.70)
with im
r , im
g , and im
b representing the driving currents of red, green, and blue LEDs,
respectively.
Following electrical–optical–electrical conversion, the blended-color CIM signal
is detected by the active pixel sensor (APS) with Bayer-pattern color ﬁlter, to produce
an output photocurrent. To make a full-rank matrix, the sensor area is partitioned into
N detection blocks, where N ≥K. Each detection block is a collection of pixels
and the output photocurrent is the average output photocurrent for these pixels. In an
extreme case, a detection block only contains a single pixel. The 3N × 3K channel
matrix for CIM-MIMO transmitter–receiver pairs is given by
H ≜
⎡
⎢⎢⎢⎣
H1,1
H1,2
· · ·
H1,K
H2,1
H2,2
· · ·
H2,K
...
...
...
...
HN,1
HN,2
· · ·
HN,K
⎤
⎥⎥⎥⎦.
(9.71)
Each entry Hn,k in H is actually the CIM channel from the kth transmitter unit to
the nth detection block, as
Hn,k ≜
⎡
⎢⎣
hn,k
r,r
hn,k
r,g
hn,k
r,b
hn,k
g,r
hn,k
g,g
hn,k
g,b
hn,k
b,r
hn,k
b,g
hn,k
b,b
⎤
⎥⎦,
(9.72)
where hn,k
p,q , p, q ∈{r, g, b} represents the transceiver channel gain between the
electrical current input of the color-q LED of the kth LED unit and the color-p output
photocurrent of the nth detection block, given by
hn,k
p,q ≜ηn,k

Sk
q (λ)Rn
p(λ)dλ, p, q ∈{r, g, b},
(9.73)
where ηn,k is the path loss between the kth transmitter and nth receiver, Sk
q (λ) and
Rn
p(λ) denote the spectral response for color-q in the kth transmitter and the optical
ﬁlter-p at the nth receiver, respectively. It is observed that the elements of Hn,k vary
with transmitted symbols due to the transceiver nonlinearity and color crosstalk.
At the receiver, if the nth detection block has W pixels, then the three average out-
put values corresponding to red/green/blue channels are Y p
n =
1
W
W
u=1 yp
n,u, p ∈
www.ebook3000.com

338
{r, g, b}. For notational convenience, we stack all 3K input currents into vector X
and all 3N outputs into vector Y. In practice, the elements of H vary with trans-
mitted symbols due to the nonlinearity eﬀect. To make the problem tractable, H is
assumed to be static over transmitted symbols in the near-linear dynamic range. Note
that, since the crosstalk and the received ﬂicker noise are typically strong, it is diﬃ-
cult to reduce these noise signal. Hence, the noise in the CIM-MIMO system can be
assumed to be signal-independent. The received vector signal can be expressed as
Y = HX + Z.
(9.74)
For the equiprobable CIM symbols with Gaussian noise, a maximum likelihood
(ML) detector is the optimal detector. If the received noise is assumed to be signal-
independent Gaussian noise, ML detection can be achieved through the minimum
Euclidean distance rule. Given all observations and the estimated channel matrix H
through training, the symbol can be estimated as
ˆX = arg max
X
fY|X(Y|X, H)
= arg min
X ∥Y −HX∥2,
(9.75)
where X is the possible transmitted symbol.
9.5.1.2
Principles of system design
Figure 9.29 The CIM-MIMO OCC transceiver diagram.
The CIM-MIMO OCC system diagram is shown in Fig. 9.29. At the transmitter, after
CIM modulation, the synchronization sequence, training sequence, and transmission
signal are encapsulated into data frames in the time domain. And then, the time
frames are arranged as the spatial frame format and are used to modulate the LED
array via a micro-controller unit (MCU). At the receiver, an image sensor captures
the images in a successive manner. After adaptive anchor detection, perspective cor-
rection, symbol detection, frame synchronization, and signal estimation, each CIM
symbol is demodulated in real-time.
In a practical system design, the following challenges must be addressed.

339
5
10
15
20
25
30
35
40
45
50
55
60
327
328
329
330
331
332
333
Time (s)
Received Frames per Second
(a) The received eﬀective frames
350
400
450
500
550
600
650
700
750
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Wavelength (nm)
The Relative Spectral
(b) The measured optical spectrum for RGB LEDs in transmitter
Figure 9.30 Observed nonideal issues in CIM-MIMO OCC design.
Unstability: The unstable frame rate for most commercial image sensors will in-
troduce sampling drifts and sampling errors. Figure 9.30(a) shows the statistics of
eﬀective received frames per second for the employed image sensor.
Nonlinearity: The nonlinearity exists not only between electrical current and opti-
cal power at the transmitter, but also between received optical power and converted
electrical current at the receiver.
Flicker noise: The main source of noises in the indoor case is ﬂicker noise caused
by background lamp.
Crosstalk: Due to optical spectrum overlaps between red/green/blue colors at the
transmitter as shown in Fig. 9.30(b) and mismatches with the Bayer-pattern ﬁlters at
the receiver, the crosstalk is inevitable.
Sampling: Although the sampling time can be optimally set for the kth pixel-based
receiver, it might be the worst sampling time for the lth pixel-based receiver due to
www.ebook3000.com

340
diﬀerent signal arrival times.
To tackle the challenges mentioned above, some solutions can be employed to re-
alize a successful OCC communication link.
Optimal CIM symbol design:
If the transmitted symbols have equal probability and the ML detector is adopted,
at high SNR, the symbol error rate (SER) is dominated by the minimum pairwise
Euclidean distance between received symbols. With intensity constraint and color
constraint, the symbol set S = {s1, s2, · · · , sM} that maximizes the minimum
distance for a given SNR is given by [39]
S = arg max
sm min
m̸=k∥H(sm)sm −H(sk)sk∥
subject to
Lmin ≤L(sm) ≤Lmax
0 ⪯sm ⪯[Ir Ig Ib],
(9.76)
where H(sm) is the crosstalk matrix corresponding to symbol sm, which varies
with symbol sk due to the nonlinearity in each color channel. Ir, Ig, and Ib are the
peak currents of the red, green and blue LED, respectively. Lmin and Lmax are the
minimum and maximum allowable total luminous ﬂux, respectively.
The joint nonlinearity and crosstalk eﬀect between red–green–blue channels with
diﬀerent region of interest (ROI) sizes are shown in Fig. 9.31. The average re-
ceived values in the 30 × 30 ROI size for red/green/blue channels when only one
of red/green/blue LED is illuminated are shown in Fig. 9.31(a). For example, with
only red LED activated, not only the red-ﬁlter pixels but also the green-ﬁlter and
blue-ﬁlter pixels can perceive signal intensity. Thus, color crosstalks are inevitable
in each color channel. The nonlinearity between the transmitted signal intensity and
the received gray value, as well as the intensity ﬂuctuations due to rolling shutter, can
be observed in Fig. 9.31(a). Furthermore, it is seen that the nonlinearity varies across
color channels. To make an eﬀective and low complexity demodulation in real-time,
several pixels, which are close to the center pixel of the LED image, are selected
to group as a block receiver. Figure 9.31(b) shows the average received gray value
in the 3 × 3 ROI size for red/green/blue channels when only one of red/green/blue
LEDs is illuminated.
It is seen that, the crosstalk and nonlinearity still exist even though the ROI size
is reduced. Meanwhile, the near-linear dynamic range decreases as the ROI size de-
creases. Due to the joint nonlinearity and color crosstalk eﬀects, each CIM symbol
experiences a unique symbol-dependent channel. More importantly, it is impossible
for the receiver to obtain complete channel knowledge through a training procedure.
Thus, a sub-optimal CIM constellation is pursued by assuming that all symbols ex-
perience a symbol-independent channel in the near-linear dynamic range. Hence, in
CIM symbol optimization, the channel matrix H8 corresponding to the transmitted
intensity level in a near-linear dynamic range is assumed as a static channel matrix.
Spatial frame format and packet format design:

341
0
50
100
150
0
5
10
15
20
The Optical Intensity in Transmitter
The Average Received Gray Value in ROI
Red−Red
Red−Green
Red−Blue
Green−Red
Green−Green
Green−Blue
Blue−Red
Blue−Green
Blue−Blue
(a) 30 × 30 ROI
0
10
20
30
40
50
60
70
80
90
100
0
50
100
150
200
250
The Optical Intensity in Transmitter
The Average Received Gray Value in ROI
Red−Red
Red−Green
Red−Blue
Green−Red
Green−Green
Green−Blue
Blue−Red
Blue−Green
Blue−Blue
(b) 3 × 3 ROI
Figure 9.31 The joint nonlinearity and crosstalk eﬀect between red–green–blue channels.
Figure 9.32(a) shows the actual design of the 16 × 16 LED array in the proposed
CIM-MIMO system. The four outmost corner LEDs are used as reference anchors
for corner detection. If the coordinates of these anchors are estimated, then all the
coordinates of LEDs in the array can be calculated according to the spatial format
layout. The remaining 196 LEDs in the inner area of the array are used for data
transmission except for four LEDs from the second to the ﬁfth LED in the second
row of the array, which are used as a frame cyclic counter, similar to the COBRA
system. For robust transmission, OOK modulation is adopted for both frame syn-
chronization and anchor detection. Note that, diﬀerent signals may arrive at dif-
ferent detection blocks at diﬀerent times and are possibly sampled asynchronously.
Meanwhile, the nonlinearity and crosstalk vary for diﬀerent LEDs. Thus, the de-
modulation thresholds and detection time need to be adjusted for diﬀerent detection
areas. To tackle this problem, preamble sequences are inserted in each data pack-
et for each LED unit in CIM-MIMO OCC systems. The packet format is shown in
www.ebook3000.com

342
Fig. 9.32(b), where a Barker code sequence of length 13 is selected as synchroniza-
tion header due to its robust time synchronization performance. In order to achieve
robust synchronization performance, we use the OOK modulation, where the Barker
codes “0” and “1” are represented by the transmitted signals s1 and sM, respectively.
Moreover, to tackle the joint rolling shutter and ﬂicker noise issue, G preamble se-
quences s1,1, · · · , s1,M, · · · , sG,1, · · · , sG,M are repetitively transmitted and used
as training sequences. According to the actual measurement, about G = 4 preamble
sequences can yield improved and stable BER performance.
(a) Spatial frame format in LED array
(b) Time packet format for each LED
Figure 9.32 The spatial frame layout and packet format for each LED.
As mentioned above, in order to tackle the critical issues in a practical OCC system,
the pre-designs, including a redundant transmission, CIM constellation optimization,
iterative training sequence design, and spatial frame format design, are employed at
the transmitter. And, the corresponding key signal processing techniques toward
successful data recovery are needed at the receiver.
Adaptive array anchoring and symbol detection:
To extract and demodulate the signal from the captured images of the LED array, the
LED array should be located ﬁrst under perspective distortion. By using Hough cir-
cle detection, the coordinates of the four outmost anchor LEDs can be obtained. To
eliminate the background radiation, diﬀerential image processing is used to estimate

343
LED locations reliably. Moreover, to make a smooth communication, a redundant
transmission and unsampled reception technique is applied, and the refresh rate of
LED array and the frame rate of the camera are set as 82.5 Hz and 330 fps, respective-
ly. Thus, every four captured images in a successive manner should be diﬀerentiated
to obtain puriﬁed intensity copies of each LED signal free of background noise. And
then, two pairs of spurred points with the longest distance in between can be found
from those images, corresponding to four anchor LED positions. After circle de-
tection, we assume that the centers of these detected anchor circles are the center
coordinates of four anchor LEDs if the relative rotation angle of the LED array to the
vertical direction is within −45◦to +45◦. Then, we can correct the perspective dis-
tortion of the LED array by perspective transformation, as shown in Fig. 9.33. After
that, we can calculate the coordinates of all LEDs and color pixels according to the
spatial format layout and Bayer-pattern layout, respectively.
Figure 9.33 LED array and symbol detection.
Synchronization and iterative training:
To make a reliable symbol demodulation, a reasonable training signal threshold is
needed. For a practical CMOS image-sensor-based OCC in the indoor case, the
ﬂicker noise and rolling shutter eﬀect will inevitably introduce intensity ﬂuctuation
and degrade the system performance. The ﬂicker noise can be approximated as a
harmonic intensity ﬂuctuation. Moreover, for the rolling-shutter-based receiver, the
accumulated charge ﬂows out row-by-row, which will induce bright and dark strips
in the image. To tackle the ﬂicker noise and rolling shutter issue, G (G is set as
4) preamble sequences are inserted in time packet before data transmission. Thus,
iterative training and recursive estimation can be performed to obtain the average
intensity under ﬂuctuation.
For M-CIM, G preamble sequences, each of which contains M kinds of training
signals s1, · · · , sM, are inserted in the time packet for each LED. Moreover, due to
the unstable frame rate for the CMOS image sensor, upsampled signal processing is
performed at the receiver to alleviate the frame drift issue. Thus, the image sensor
will capture Q (3, 4, or 5) successive images, which contain at least one complete and
valid preamble sequence during the training period. Then, the most probable one is
www.ebook3000.com

344
selected as the training signal threshold. For example, during the transmission period
of the training symbol sm, the image sensor can capture Q groups of red/green/blue
signals corresponding to each LED unit. The 3-D Euclidean distance Em
i,j between
the ith group and jth group in the color space can be expressed as
Em
i,j = ∥Pm
i −Pm
j ∥2, i ̸= j, i, j = 1, 2, · · · , Q; m = 1, 2, · · · , M,
(9.77)
where Pm
i , P = [R, G, B] is the gray value for red/green/blue colors in ith cap-
tured group corresponding to the training symbol sm. After obtaining the Euclidean
distance, we compare it with the Euclidean distance threshold Em
th. If Em
i,j ≤Em
th,
we conclude that these two groups are similar in the color space. For these similar
groups, F m
i
is deﬁned as
F m
i
=
Q

j=1,j̸=i
u
Em
th −Em
i,j
 ,
(9.78)
where u(·) is the step function. And then, we select the most probable one as the
training signal threshold based on F m
i . Speciﬁcally, if F m
i
̸= 0, which indicates that
it has successfully acquired at least one eﬀective training symbol sm, we select the
one with the largest F m
i
as the obtained training symbol corresponding to transmitted
symbol sm, and then mark the Flagm = 1. However, if F m
i
= 0, which indicates
that it fails to detect the training symbol sm, we mark Flagm = 0 and choose the
middle group signal as the training symbol. The selected m-CIM training symbol
threshold T m is given by
T m =
⎧
⎨
⎩
sm
i0, i0 =
max
i={1,··· ,Q}{F m
i }
if
max
i={1,··· ,Q}{F m
i } ̸= 0, Flagm = 1,
sm
i0, i0 = ⌈Q
2 ⌉
if
max
i={1,··· ,Q}{F m
i } = 0, Flagm = 0.
(9.79)
Following the similar processing, we can acquire M kinds of training symbols for
each LED unit.
Note that, G preamble sequences are inserted in time packet to average the inten-
sity ﬂuctuation induced by the ﬂicker noise and rolling shutter issue. If we deﬁne
U(m, k, g) as the renewed received signal corresponding to the m-CIM training
symbol for the kth LED in the gth preamble sequence, it is renewed iteratively as
U(m, k, g) = U(m, k, g −1) × Flag(m, k, g −1) + U(m, k, g)
Flag(m, k, g −1) + 1
, 1 ≤g ≤G.
(9.80)
Then the ﬁnal estimated signal corresponding to the m-CIM training symbol for the
kth LED is U k
m = U(m, k, G).
CIM symbol demodulation:

345
0
50
100
150
0
50
100
150
200
0
50
100
150
200
250
G
R
B
Threshold Constellation
Received Constellation
(a) Un-optimal
0
50
100
150
200
0
100
200
300
0
50
100
150
200
250
G
R
B
Opt−Threshold Constellation
Received Constellation
(b) Optimized
Figure 9.34 The 3-D 64-CIM constellation at the receiver.
After obtaining the valid training symbols thresholds U k
m, m ∈{1, 2, · · · , M} of
the kth LED, we compare them with the received signals from Q frame images for
symbol demodulation, which is given by
mk
q =
argmin
m∈{1,2,··· ,M}
∥rk
q −U k
m∥2, q = 1, · · · , Q.
(9.81)
The ﬁnal demodulated symbol for the kth LED is represented by sk
m,q whose index
satisﬁes
mk
q = mk
q−1 or mk
q = mk
q+1 or mk
q−1 = mk
q = mk
q+1.
(9.82)
www.ebook3000.com

346
Figure 9.34 shows the received constellation points at the receiver for the conven-
tional and optimized CIM symbols. The optimized constellation points in 3-D color
space distribute more uniformly than non-optimized constellation points. Aside from
the few abnormal constellation points away from threshold constellation points due
to rolling shutter, most of the constellation points are close to the thresholds, which
illustrates that the M-CIM system can achieve high SNR. The Nc LEDs in the cod-
ing domain can transmit Nclog2M bits per transmitted frame. Successive new data
frames continue to be demodulated until the frame synchronization sequence value
becomes one. Following this decoding mechanism, we can perform an eﬀective and
reliable symbol demodulation, and avoid missing demodulation or duplicate modu-
lation.
9.5.1.3
OCC experimental platform and performance evaluation
Figure 9.35 The OCC experimental platform.
The OCC experimental platform is shown in Fig. 9.35. A programmable 16 × 16
LED array is employed as the transmitter and a smartphone image sensor controlled
by the FPGA is employed as the receiver. All modules are mounted on the top of an
optical breadboard to control the transmission distance accurately. Moreover, to test
the robustness to the perspective distortion, we can move or rotate the LED array to
vary oﬀset angle and rotation angle. No external lens is used except a small integrat-
ed lens on the close top of the sensor. The image sensor can support the refresh rate
of 330 fps and LED array can support up to 400 Hz refresh rate. If the array refresh
rate is chosen as 330 Hz, the synchronization mismatch between the LED array and
the image sensor will dramatically degrade the BER performance. To minimize the
synchronization error and tackle the frame rate unstability of the sensor, we set the
LED array refresh rate to 82.5 Hz. Table 9.1 lists the speciﬁcations of the image sen-
sor receiver and the experimental parameters. The input data stream is continuously
fed to the MCU from the computer at the transmitter and data is demodulated in real

347
Table 9.1 The key speciﬁcations and experimental parameters.
Manufacture process
CMOS
LED power
0.5 W
Output formats
10 bits RAW
LED array size
16 × 16
Pixel size
2 μm × 2 μm
LED array refresh rate
82.5 Hz
Frame rate
330 fps
LED pixel pitch
1 cm
Resolution
672 × 380 pixel
LED dimension
5 mm
Lens size
1/3 inch
Communication distance
50–150 cm
time at the receiver.
The actual measured BER performances for CIM-MIMO OCC systems with dif-
ferent modulation orders and transmission distances are shown in Fig. 9.36(a). Note
that M = Lr × Lg × Lb and we set (Lr = Lg = Lb = 4) for M = 64, and
(Lr = Lg = 8, Lb = 4) for M = 256. For a ﬁxed distance, it is clear that the
BER decreases as modulation order M decreases, since the Euclidean distance in the
color space becomes larger.
For a given modulation order, the BER performance can be dramatically improved
if iterative training and constellation optimization are performed. The eﬀectiveness
of iterative training and constellation optimization to trackle the critical issues in
OCC systems is experimentally veriﬁed. Note that, without external lens assistance,
the system is able to achieve a data rate of 126.72 kbps over a range of up to 1.4
m. It is anticipated that much longer distance can be achieved if an extra lens with
larger focusing length is used in front of the sensor. We further verify the system ro-
bustness to the perspective distortion with diﬀerent rotation angles and oﬀset angles.
Figure 9.36(b) shows the BER performance versus rotation angle when oﬀset angle
is ﬁxed to be 0o and the BER performance versus oﬀset angle when rotation angle is
ﬁxed to be 0o, with 60 cm separation distance. It is seen that, when the oﬀset angle
is within the ﬁeld of view (FOV) of the image sensor, and the rotation angle is small-
er than the threshold value, which can be corrected by perspective transformation,
reliable symbol detection and demodulation are unaﬀected.
9.6
Conclusion
In this chapter, OCC system design principles are presented.
First, modulation
schemes spanning time, frequency, space, color, and intensity domains are intro-
duced. Subsequently, corresponding nonideal factors and mitigation techniques are
discussed. In particular, synchronization problems are tackled by per-line tracking
and inter-frame coding, and rateless coding. Then issues in a real-time OCC system
design are discussed. Using color and intensity jointly, methods to increase data
rate and improve BER performance are proposed. In addition, solutions to deal with
www.ebook3000.com

348
60
70
80
90
100
110
120
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
Transmission Distance (cm)
BER
64−CIM Non−optimized (G = 1)
64−CIM Non−optimized (G = 4)
64−CIM Optimized (G = 4)
256−CIM Non−optimized (G = 1)
256−CIM Non−optimized (G = 4)
256−CIM Optimized (G = 4)
(a) BERs with diﬀerent distances and M
0
5
10
15
20
25
30
35
40
10
−6
10
−5
10
−4
10
−3
Rotation Angle & FOV (°)
BER
64−CIM Optimized (Rotation)
64−CIM Optimized (FOV)
256−CIM Optimized (Rotation)
256−CIM Optimized (FOV)
(b) BERs with diﬀerent rotation angles and FOVs
Figure 9.36 BER performance of CIM-MIMO OCC systems.
frame rate unstability, system nonlinearity and crosstalk, ﬂicker noise, and rolling
shutter in the system design are presented.
The preliminary results in this chapter show that it is feasible to use a commer-
cial CMOS camera as a real-time OCC receiver. The corresponding system can be
used in the near-ﬁeld screen–camera communication and indoor visible light posi-
tioning. Equipped with an external optical lens, the system is also suitable for other
applications, for example, capturing signals from a distant traﬃc light, or information
broadcasting display in a public area such as the shopping mall and the transportation
hub.

349
References
1 R. G. Gallager, Information Theory and
Reliable Communication, New York, NY,
USA: Wiley, 1968.
2 E. A. Ratzer and D. J. MacKay, “Sparse
low-density parity-check codes for channels
with cross-talk,” in Proc. IEEE Information
Theory Workshop 2003 (Paris, France), Mar.
32–Apr. 4, 2003, pp. 127–130.
3 E. Ratzer, “Sparse data blocks and
multi-user channels,” in Proc. IEEE
International Symposium on Information
Theroy (ISIT) 2003 (Yokohama, Japan), Jun.
29–Jul. 4, 2003, pp. 314–314.
4 A. A. Farid and S. Hranilovic, “Channel
capacity and non-uniform signalling for
free-space optical intensity channels,” IEEE
J. Sel. Areas Commun., vol. 27, no. 9,
pp. 1553–1563, Dec. 2009.
5 J. Cao, S. Hranilovic, and J. Chen, “Capacity
and nonuniform signaling for discrete-time
poisson channels,” J. Opt. Commun. Netw,
vol. 5, no. 4, pp. 329–337, Apr. 2013.
6 S. Hranilovic and F. R. Kschischang, “A
pixelated MIMO wireless optical
communication system,” IEEE J. Sel. Topics
Quantum Electron., vol. 12, no. 4,
pp. 859–874, Jul./Aug. 2006.
7 R. D. Roberts, “Undersampled frequency
shift on-oﬀkeying (ufsook) for camera
communications (camcom),” in Proc.
Wireless and Optical Communication
Conference (WOCC) 2013 (Chongqing,
China), May 16–18, 2013, pp. 645–648.
8 P. Luo, Z. Ghassemlooy, H. Le Minh,
X. Tang, and H. M. Tsai, “Undersampled
phase shift on-oﬀkeying for camera
communication,” in Proc. International
Conference on Wireless Communications &
Signal Processing (WCSP) 2014 (Hefei,
China), Oct. 23–25, 2014, pp. 1–6.
9 P. Luo, Z. Ghassemlooy, H. Le Minh,
H. M. Tsai, and X. Tang,
“Undersampled-pam with subcarrier
modulation for camera communications,” in
Proc. OptoElectronics and Communications
Conference (OECC) 2015 (Shanghai,
China), Jun. 28–Jul. 2, 2015, pp. 1–3.
10 P. Luo, M. Zhang, Z. Ghassemlooy,
H. Le Minh, H. M. Tsai, X. Tang, and
D. Han, “Experimental demonstration of a
1024-QAM optical camera communication
system,” IEEE Photon. Technol. Lett.,
vol. 28, no. 2, pp. 139–142, Jan. 2016.
11 N. Rajagopal, P. Lazik, and A. Rowe,
“Visual light landmarks for mobile devices,”
in Proc. International Symposium on
Information Processing in Sensor Networks
2014 (Berlin, Germany), Apr. 15–17, 2014,
pp. 249–260.
12 C. Danakis, M. Afgani, G. Povey,
I. Underwood, and H. Haas, “Using a cmos
camera sensor for visible light
communication,” in Proc. IEEE Global
Communications Conference (GLOBECOM)
Workshops 2012 (Anaheim. CA), Dec. 3–7,
2012, pp. 1244–1248.
13 K. Jo, M. Gupta, and S. Nayar, “Disco:
Display-camera communication using
rolling shutter sensors,”ACM Trans.
Graphics., vol. 35, no. 5, pp. 150:00–150:13,
Jul. 2016.
14 P. Hu, P. H. Pathak, X. Feng, H. Fu, and
P. Mohapatra, “Colorbars: Increasing data
rate of LED-to-camera communication using
color shift keying,” in Proc. ACM
Conference on Emerging Networking
Experiments and Technologies 2015
(Heidelberg, Germany), Dec. 1–4, 2015,
www.ebook3000.com

350
pp. 1–12.
15 H. Y. Lee, H. M. Lin, Y. L. Wei, H. I. Wu,
H. M. Tsai, and K. C. J. Lin, “Rollinglight:
Enabling line-of-sight light-to-camera
communications,” in Proc. International
Conference on Mobile Systems,
Applications, and Services 2015 (Florence,
Italy), May 18–22, 2015, pp. 167–180.
16 J. Gu, Y. Hitomi, T. Mitsunaga, and
S. Nayar, “Coded rolling shutter
photography: Flexible space-time sampling,”
in Proc. IEEE Computational Photography
2010 (Cambridge, MA), Mar. 29–30, 2010,
pp. 1–8.
17 A. Dabbo and S. Hranilovic, “Receiver
design for wireless optical MIMO channels
with magniﬁcation,” in Proc. International
Conference on Telecommunications (ICT)
2009 (Zagreb, Croatia), Jun. 8–10, 2009,
pp. 51–58.
18 S. D. Perli, N. Ahmed, and D. Katabi,
“Pixnet: Interference-free wireless links
using LCD-camera pairs,” in Proc.
International Conference on Mobile
Computing and Networking 2010 (Chicago,
IL), Sept. 20–24, 2010, pp. 137–148.
19 M. R. H. Mondal, K. R. Panta, and
J. Armstrong, “Performance of two
dimensional asymmetrically clipped optical
OFDM,” in Proc. IEEE Global
Communications Conference (GLOBECOM)
Workshops 2010 (Miami, FL), Dec. 6–10,
2010, pp. 995–999.
20 E. Katz and Y. Bar-Ness,
“Two-dimensional (2-d) spatial domain
modulation methods for unipolar pixelated
optical wireless communication systems,” J.
Lightw. Technol., vol. 33, no. 20,
pp. 4233–4239, Oct. 2015.
21 M. R. H. Mondal and K. Panta,
“Performance analysis of spatial OFDM for
pixelated optical wireless systems,” Trans.
Emerging Telecommun. Technol., vol. 28,
no. 2, May 2015.
22 K. M. Wong, J. Wu, T. N. Davidson, and
Q. Jin, “Wavelet packet division
multiplexing and wavelet packet design
under timing error eﬀects,” IEEE Trans.
Signal Process., vol. 45, no. 12,
pp. 2877–2890, Dec. 1997.
23 H. Nikookar, Wavelet Radio: Adaptive and
Reconﬁgurable Wireless Systems Based on
Wavelets, Cambridge University Press, 2013.
24 W. Huang, C. Gong, and Z. Xu, “System
and waveform design for wavelet packet
division multiplexing-based visible light
communications,” J. Lightw. Technol.,
vol. 33, no. 14, pp. 3041–3051, Jul. 2015.
25 T. Nagura, T. Yamazato, M. Katayama,
T. Yendo, T. Fujii, and H. Okada, “Improved
decoding methods of visible light
communication system for its using LED
array and high-speed camera,” in Proc. IEEE
Vehicular Technology Conference (VTC
Spring) 2010 (Taipei, Taiwan), May 16–19,
2010, pp. 1–5.
26 H. Okada, T. Ishizaki, T. Yamazato,
T. Yendo, and T. Fujii, “Erasure coding for
road-to-vehicle visible light communication
systems,” in Proc. IEEE Consumer
Communications and Networking
Conference (CCNC) 2011 (Las Vegas, NV),
Jan. 9–12, 2011, pp. 75–79.
27 M. R. H. Mondal and J. Armstrong,
“Impact of linear misalignment on a spatial
ofdm based pixelated system,” in Proc.
Asia-Paciﬁc Conference on Communications
(APCC) 2012 (Jeju Island, Korea), Oct.
15–17, 2012, pp. 617–622.
28 A. Ashok, S. Jain, M. Gruteser,
N. Mandayam, W. Yuan, and K. Dana,
“Capacity of pervasive camera based
communication under perspective
distortions,” in Proc. IEEE International
Conference on Pervasive Computing and
Communications 2014 (Budapest, Hungary),
Mar. 24–28, 2014, pp. 112–120.
29 M. Rubaiyat, H. Mondal, and J. Armstrong,
“The eﬀect of defocus blur on a spatial
OFDM optical wireless communication
system,” in Proc. International Conference
on Transparent Optical Networks 2012
(Coventry, England), Jul. 2–5, 2012, pp. 1–4.
30 M. R. H. Mondal and J. Armstrong,
“Analysis of the eﬀect of vignetting on
MIMO optical wireless systems using spatial
OFDM,” J. Lightw. Technol., vol. 32, no. 5,
pp. 922–929, Mar. 2014.
31 W. Hu, H. Gu, and Q. Pu, “Lightsync:
Unsynchronized visual communication over
screen-camera links,” in Proc. International
Conference on Mobile Computing &
Networking 2013 (Miami, FL), Sept. 30–Oct.
4, 2013, pp. 15–26.
32 T. Hao, R. Zhou, and G. Xing, “Cobra:
Color barcode streaming for smartphone

351
systems,” in Proc. IEEE International
Conference on Distributed Computing
Systems 2012 (Low Wood Bay, UK), Jun.
25–29, 2012, pp. 85–98.
33 W. Du, J. C. Liando, and M. Li, “Softlight:
Adaptive visible light communication over
screen-camera links,” in Proc. IEEE
International Conference on Computer
Communications (INFOCOM) 2016 (San
Francisco, CA), Apr. 10–14, 2016, pp. 1–9.
34 J. W. Byers, M. Luby, M. Mitzenmacher,
and A. Rege, “A digital fountain approach to
reliable distribution of bulk data,” ACM
SIGCOMM Computer Communication
Review, vol. 28, no. 4, pp. 56–67, Sept. 1998.
35 M. Luby, “Digital fountain,
inc.luby@digitalfountain.com,” 2002.
36 A. Shokrollahi, “Raptor codes,” IEEE
Trans. Inf. Theory, vol. 52, no. 6,
pp. 2551–2567, Jun. 2006.
37 W. Huang, P. Tian, and Z. Xu, “Design and
implementation of a real-time CIM-MIMO
optical camera communication system,” Opt.
Exp., vol. 24, no. 21, pp. 24567–24579, Oct.
2016.
38 P. Tian, W. Huang, and Z. Xu, “Design and
experimental demonstration of a real-time
95kbps optical camera communication
system,” in Proc. IEEE International
Conference on Communication Systems,
Networks and Digital Signal Processing
(CSNDSP) 2016 (Prague, Czech Republic),
Jul. 20–22, 2016, pp. 1–6.
39 E. Monteiro and S. Hranilovic, “Design and
implementation of color-shift keying for
visible light communications,” J. Lightw.
Technol., vol. 32, no. 10, pp. 2053–2060,
May 2014.
40 R. Singh, T. O. Farrell, and J. P. David, “An
enhanced color shift keying modulation
scheme for high-speed wireless visible light
communications,” J. Lightw. Technol.,
vol. 32, no. 14, pp. 2582–2592, Jul. 2014.
41 W. Huang, C. Gong, P. Tian, and Z. Xu,
“Experimental demonstration of high-order
modulation for optical camera
communication,” in Proc. IEEE Global
Conference on Signal and Information
Processing (GlobalSIP) 2015 (Orlando, FL),
Dec. 14–16, 2015, pp. 1027–1031.
www.ebook3000.com

353
10
Index
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc.
 
 
 
 
 
3GPP 3rd Generation Partnership Pro-
ject, 165 
5G fifth generation, 308 
 
ACO-OFDM asymmetrically clipped 
optical OFDM, 7–8, 
97, 108 
ADC analog-to-digital converter, 5, 58, 
92, 253 
ADO-OFDM asymmetrically clipped 
DC biased optical OFDM, 111–115, 
118
 
ADR angle diversity receiver, 243, 281 
ADSL asymmetric digital subscriber 
line, 68 
AHO-OFDM asymmetrically hybrid 
optical OFDM, 90, 138–142 
AOA angle-of-arrival, 248 
AP access point, 202, 213, 248 
APD avalanche photodiode, 1, 27, 223, 
239 
API application program interface, 
330
 
APPR average to peak power ratio, 36, 
234, 276 
APS active pixel sensor, 252, 337 
AWGN additive white Gaussian noise, 
9, 58, 64, 92, 152, 171, 184, 201, 
245,
 
292 
B-PSK burst pulse shift key, 109 
BER bit error rate, 
292 
BICM-ID bit-interleaved coded modul
ation with iterative demapping and 
decoding, 105–107 
BP belief propagation, 163 
 
CAP carrierless amplitude phase 
modulation, 2 57, 68 
CCT correlated color temperature, 208–
212 
CCDF complementary cumulative 
distribution function, 73, 108–111 
CDS correlated double sampling, 259, 
265 
CESI china electronics standardization 
institute, 12 
CFA color filter array, 242–243, 252 
CFM color filter mosaic, 242 
CIE international commission on 
illumination, 23 
CIM color-intensity modulation, 9, 291, 
336 
CMOS complementary metal oxide 
semiconductors, 239, 301 
COST European cooperation in science 
and technology, 3 
COWA center on optical wireless 
applications, 4 
CP cyclic prefix, 58, 90, 196, 307 
CRLB Cramer-Rao lower bound, 224 
CSI channel state information, 92, 133, 
156, 223, 243, 282 
CSIT channel-state-information-at-the-
transmitter, 223, 282, 284 
CSK color shift keying, 8, 25, 27, 132, 
147, 303
CVLCA Chinese visible light 
communications alliance, 4 
 
D2D device-to-device, 6, 250 
DAC digital-to-analog converter, 5, 58, 
92 
DC direct current, 22, 58, 89, 202, 243,
 298 
 
 CCD charge coupled device, 241, 
304
 
 89, 93,
245
 
57,
,
 
280 
2 3
0 ,
,

354
 
DCO-OFDM DC-biased optical OFDM, 
7, 89–95, 97, 99–102, 104–106, 108–
109, 111–113, 121, 132–133, 136, 
139, 141–142, 192–197, 305 
DCT discrete cosine transform, 108–109 
DD direct detection, 3, 35, 89, 133, 184, 
202, 266, 292, 304 
DFE decision feedback equalizer, 57, 63–
64, 67, 69, 323 
DFT discrete Fourier transform, 59, 
107 
DPPM differential PPM, 7, 57, 67 
DPS digital pixel sensor, 254 
DR dynamic range, 132–133, 138–139, 
141, 152–153, 202, 208, 254, 259, 
      338, 340 
DWPT discrete wavelet packet transform, 
308 
 
EMI electromagnetic interference 
immunity, 4 
EPI entropy power inequality, 44 
EPPM expurgated PPM, 67 
ERC smart lighting engineering research 
center, 4 
eU-OFDM enhanced U-OFDM, 90, 119–
121, 127, 142 
 
FBMC filter bank multicarrier, 307 
FD floating diffusion, 259 
FDE frequency domain equalization, 2, 
57–58, 82 
FEC forward error correction, 10, 80, 99, 
300 
FFT fast Fourier transform, 73, 90–91, 
191–192
 
FIFO first-in-first-out, 213 
FIR finite impulse response, 70, 75  
 
FOV field of view, 3, 30, 170, 201, 240, 
347 
FPGA field programmable gate array, 
      346 
FPN fixed-pattern noise, 9, 254 
FSK frequency shift keying, 25, 298 
FSLE fractionally spaced linear equalizer, 
69 
 
GPS global position system, 6, 246 
 
HACO-OFDM hybrid asymmetrical 
clipped optical OFDM, 113, 128–129, 
141 
IDFT inverse discrete Fourier transform, 59 
IDWPT inverse discrete wavelet packet 
transform, 308 
IFFT inverse fast Fourier transform, 73, 91, 
192, 305 
IIR infinite impulse response, 75, 159 
IM/DD intensity-modulated direct 
detection, 3, 35, 89, 142, 202, 223, 232, 
266, 292 
IPI inter-pixel interference, 245, 274, 313 
IR infrared, 1, 5, 21, 27, 34, 240 
ISC inverse source coding, 80 
ISI inter-symbol interference, 7, 30, 58, 90, 
308 
ITS intelligent transportation system, 249, 
304 
ITU international telecommunication union, 
11 
 
JEITA japan electronics and information 
technology industries association, 11 
 
KKT Karush-Kuhn-Tucker, 276 
 
LACO-OFDM layered asymmetrically 
clipped optical OFDM, 90, 121, 123–
125 
LBR link blocked receiver, 280 
LCD liquid crystal display, 19, 245, 304 
LDPC low density parity check, 107, 163, 
291 
LED light emitting diode, 1, 17, 57, 89, 147, 
169, 201, 240 
LiFi light fidelity, 11 
LLR log-likelihood ratio, 106, 158, 297 
LMMSE linear minimum mean square 
error, 60 
LMS least mean square, 69 
LOS line-of-sight, 7, 29, 59, 175, 212, 270 
LT Luby transform, 334 
LTE-A long term evolution-advanced, 90 
LUX lumen per square meter, 24 
 
M2M machine-to-machine, 6 
MAC medium access control, 10, 239
MAP maximum a posteriori, 158, 226 
MCU micro-controller unit, 338 
MDP Markov decision process, 9, 201,   
214 
MDR mirror diversity receiver, 243, 280–
281 
MFTP maximum flickering time period, 135
www.ebook3000.com

355
 
MIMO multiple input multiple output, 2, 
74, 169, 241, 291 
ML maximum likelihood, 63, 92, 156, 
171, 227, 338 
MLC multi-level coding, 291, 293–295 
MLD maximum likelihood detection, 104 
MLSD maximum likelihood sequence 
detection, 63, 67, 104–105 
MMSE minimum mean squared error, 60, 
64, 182, 225 
MPPM multipulse PPM, 7, 57, 67–68, 78, 
80 
MRI magnetic resonance imaging, 6 
MSD multi-stage decoding, 291, 293 
M-SDGN mixed-signal-dependent Gaus
sian noise, 275–278 
MSEE mean squared estimation error, 224 
MT mobile terminal, 212 
MTF modulation transfer function, 257, 
270
MVU minimum variance unbiased, 226 
 
NLOS non-line-of-sight, 7, 29, 213, 248 
NRZ non-return-to-zero, 2 
 
OCC optical camera communication, 6, 
239–240, 291 
OCI optical communication image senor, 
249 
OE optical efficiency, 257 
OFDM orthogonal frequency division 
multiplexing, 1–2, 77, 89, 169, 190, 
291
OLED organic light emitting diode, 18–19 
OMEGA home gigabit access, 3 
OOK on-off keying, 2, 24, 57, 132, 292, 
298–299 
OPPM overlapping PPM, 57, 67 
OSM optical spatial modulation, 8, 169 
OSNR optical signal-to-noise ratio, 38, 
101 
OSSK optical space shift keying, 8, 169 
OTF optical transfer function, 323 
OWC optical wireless communication, 1, 
4, 10, 62, 162, 240, 243 
 
PAM pulse amplitude modulation, 7, 57, 
61, 96, 171, 202, 292, 300 
PAM-DMT pulse-amplitude modulated 
discrete multitoned, 7, 89, 93–94, 96–
98, 109, 110
PAPR peak-to-average power ratio, 7, 63, 
89, 202, 307 
PC phosphor converted, 2, 18, 201 
PD photodiode, 2, 17, 58, 61, 92, 170–171, 
201, 239, 301 
PDF probability density function, 72, 104, 
171, 224, 296 
PEP pairwise error probability, 156, 162, 
172 
PLC powerline communication, 1, 308 
PPM pulse position modulation, 7, 10, 24, 
57, 62, 132 
PPS passive pixel sensor, 253 
PRF pixel response function, 257 
PRNU photo response non-uniformity, 262, 
264, 266–269, 275 
PSF point spread function, 271, 307 
PSK phase shift keying, 299 
PTS partial transmit sequence, 109 
PWM pulse width modulation, 8, 10, 24, 
68, 90, 132–133, 241, 303 
 
QAM quadrature amplitude modulation, 2, 
57, 68, 91, 173, 312 
QE quantum efficiency, 7, 17, 160, 257, 262 
QLED quad LED, 147, 155, 166 
QoE quality of experience, 212 
QoS quality of service, 205 
 
RC repetition coding, 151, 171, 174, 179 
RCC root raised cosine, 69 
RF radio frequency, 4–5, 30, 89, 153, 169, 
201, 240, 248, 331 
RFID radio frequency identification, 248 
RLL run length limited, 10, 27, 80 
RoC recoverable upper-clipping, 110 
ROI region of interest, 340 
RPO-OFDM reverse polarity optical 
OFDM, 8, 90, 136–138 
RMS root mean square, 95 
RS Reed-Solomon, 80, 328 
RSS received signal strength, 248 
SAM-APD separate absorption and 
multiplication APD, 28 
SACO-OFDM spatial ACO-OFDM, 305, 
307, 310, 312–313, 315, 318, 320–322 
SDCO-OFDM spatial DCO-OFDM, 305–
307, 317–318, 320–322 
SDGN signal-dependent Gaussian noise, 
50, 223, 225, 228–233, 281
SDMT spatial discrete multitone, 323 

356
SER symbol error rate, 153, 233, 340 
SFD start frame delimiter, 300 
SF-ICI spatial frequency inter-channel 
interference, 325–326 
SINR signal-to-interference-plus noise 
ratio, 182, 186, 193, 195 
SISO single-input single-output, 274, 
      304 
SLM selective mapping, 109 
SLNR signal to leakage plus noise ratio, 
183 
SM spatial modulation, 8, 169, 173–174 
SMP spatial multiplexing, 172, 174, 242–
243, 269, 280, 282 
SNR signal-to-noise ratio, 3, 33, 75, 101, 
153, 172, 223, 245, 305 
SPAD single photon avalanche diode, 
      223 
SPAM superposed pulse amplitude 
modulation, 61–62 
SQR square-root, 231–232, 234–235 
SSR spatially separated receiver, 280 
SVD singular value decomposition, 185, 
243 
 
TDOA time difference of arrival, 248 
THz terahertz, 4, 8, 169, 247 
TOV turn-on voltage, 77, 132 
 
U-OFDM unipolar OFDM, 7, 89, 97 
UPSOOK undersampled phase shift on-
off keying, 299–300 
UFSOOK undersampled frequency shift 
on-off keying, 298–300 
UPSPAM undersampled phase shift pulse 
amplitude modulation, 300–301 
URC unity-rate code, 159 
UWB ultra wideband, 248, 308 
 
VAT vehicular assistant technology, 11 
VHO vertical handover, 8–9, 201, 212, 
      236 
VLC visible light communication, 3–12, 
17, 23–24, 26, 30, 32, 57, 89, 147, 169, 
201, 239 
VLCA visible light communications 
association, 4, 11 
VLCC visible light communication 
consortium, 3, 11 
VLP visible light position, 248–249 
VPPM variable PPM, 10, 24, 27, 57, 68, 
78–80 
VO-OFDM variable optical OFDM, 133, 
135, 138 
VOOK variable on off keying, 78–80 
 
 WDM wavelength division multiplexing, 
2–3, 8–9, 147, 159, 166 
WiFi wireless fidelity, 3, 212, 248 
WLAN wireless local area network, 212, 
213, 248 
WPAN wireless personal area networks, 10  
WPDM wavelet packet division 
multiplexing, 291, 307–309 
 
ZC Zadoff-Chu, 108–109 
ZF zero forcing, 60, 182, 185–187, 189–
190, 192, 196–197 
www.ebook3000.com

IEEE PRESS SERIES ON 
DIGITAL AND MOBILE COMMUNICATION
John B. Anderson, Series Editor
University of Lund
1. Future Talk: The Changing Wireless Game
Ron Schneiderman
2. Digital Transmission Engineering
John B. Anderson
3. Fundamentals of Convolutional Coding
Rolf Johannesson and Kamil Sh. Zigangirov
4. Mobile and Personal Communication Services and Systems
Raj Pandya
5. Wireless Video Communications: Second to Third Generation and Beyond
Lajos Hanzo, Peter J. Cherriman, and Jürgen Streit
6. Wireless Communications in the 21st Century
Mansoor Shafi, Shigeaki Ogose, and Takeshi Hattori
7. Introduction to WLLs: Application and Deployment for Fixed and
Broadband Services
Raj Pandya
8. Trellis and Turbo Coding
Christian B. Schlegel and Lance C. Perez
9. Theory of Code Division Multiple Access Communication
Kamil Sh. Zigangirov
10. Digital Transmission Engineering, Second Edition
John B. Anderson
11. Wireless LAN Radios: System Definition to Transistor Design
Arya Behzad
12. Wireless Broadband: Conflict and Convergence
Vern Fotheringham and Chetan Sharma
13. Millimeter Wave Communication Systems
Kao-Cheng Huang and Zhaocheng Wang
14. Channel Equalization for Wireless Communications: From Concepts to
Detailed Mathematics
Gregory E. Bottomley
15. Handbook of Position Location: Theory, Practice and Advances
Seyed A. Reza Zekavat and R. Michael Buehrer
16. Digital Filters: Principles and Applications with MATLAB
Fred J. Taylor
17. Resource Allocation in Uplink OFDMA Wireless Systems: Optimal
Solutions and Practical Implementations
Elias Yaacoub and Zaher Dawy
Visible Light Communications: Modulation and Signal Processing. First edition. Zhaocheng Wang, Qi Wang, 
Wei Huang, and Zhengyuan Xu. Copyright © 2017 by the Institute of Electronic and Electrical Engineers, Inc. 
Published 2017 by John Wiley & Sons, Inc. 

18. Non-Gaussian Statistical Communication Theory
David Middleton
19. Frequency Stability:  Introduction & Applications
Venceslav F. Kroupa
20. Mobile Ad Hoc Networking: Cutting Edge Directions, Second Edition
Stefano Basagni, Marco Conti, Silvia Giordano, and Ivan Stojmenovic
21. Surviving Mobile Data Explosion
Dinesh C. Verma and Paridhi Verma
22. Cellular Communications: A Comprehensive and Practical Guide
Nishith Tripathi and Jeffrey H. Reed
23. Fundamentals of Convolutional Coding, Second Edition
Rolf Johannesson and Kamil Sh. Zigangirov
24. Trellis and Turbo Coding, Second Edition
Christian B. Schlegel and Lance C. Perez
25. Problem-Based Learning in Communication Systems Using MATLAB
and Simulink
Kwonhue Choi and Huaping Liu
26. Bandwidth Efficient Coding
John B. Anderson
27. Visible Light Communications: Modulation and Signal Processing 
Zhaocheng Wang, Qi Wang, Wei Huang, and Zhengyuan Xu
www.ebook3000.com

