Theory of functions of a real variable.
Shlomo Sternberg
May 10, 2005

2
Introduction.
I have taught the beginning graduate course in real variables and functional
analysis three times in the last ﬁve years, and this book is the result.
The
course assumes that the student has seen the basics of real variable theory and
point set topology. The elements of the topology of metrics spaces are presented
(in the nature of a rapid review) in Chapter I.
The course itself consists of two parts: 1) measure theory and integration,
and 2) Hilbert space theory, especially the spectral theorem and its applications.
In Chapter II I do the basics of Hilbert space theory, i.e. what I can do
without measure theory or the Lebesgue integral. The hero here (and perhaps
for the ﬁrst half of the course) is the Riesz representation theorem. Included
is the spectral theorem for compact self-adjoint operators and applications of
this theorem to elliptic partial diﬀerential equations. The pde material follows
closely the treatment by Bers and Schecter in Partial Diﬀerential Equations by
Bers, John and Schecter AMS (1964)
Chapter III is a rapid presentation of the basics about the Fourier transform.
Chapter IV is concerned with measure theory. The ﬁrst part follows Caratheodory’s
classical presentation. The second part dealing with Hausdorﬀmeasure and di-
mension, Hutchinson’s theorem and fractals is taken in large part from the book
by Edgar, Measure theory, Topology, and Fractal Geometry Springer (1991).
This book contains many more details and beautiful examples and pictures.
Chapter V is a standard treatment of the Lebesgue integral.
Chapters VI, and VIII deal with abstract measure theory and integration.
These chapters basically follow the treatment by Loomis in his Abstract Har-
monic Analysis.
Chapter VII develops the theory of Wiener measure and Brownian motion
following a classical paper by Ed Nelson published in the Journal of Mathemat-
ical Physics in 1964. Then we study the idea of a generalized random process
as introduced by Gelfand and Vilenkin, but from a point of view taught to us
by Dan Stroock.
The rest of the book is devoted to the spectral theorem. We present three
proofs of this theorem. The ﬁrst, which is currently the most popular, derives
the theorem from the Gelfand representation theorem for Banach algebras. This
is presented in Chapter IX (for bounded operators). In this chapter we again
follow Loomis rather closely.
In Chapter X we extend the proof to unbounded operators, following Loomis
and Reed and Simon Methods of Modern Mathematical Physics. Then we give
Lorch’s proof of the spectral theorem from his book Spectral Theory. This has
the ﬂavor of complex analysis. The third proof due to Davies, presented at the
end of Chapter XII replaces complex analysis by almost complex analysis.
The remaining chapters can be considered as giving more specialized in-
formation about the spectral theorem and its applications. Chapter XI is de-
voted to one parameter semi-groups, and especially to Stone’s theorem about
the inﬁnitesimal generator of one parameter groups of unitary transformations.
Chapter XII discusses some theorems which are of importance in applications of

3
the spectral theorem to quantum mechanics and quantum chemistry. Chapter
XIII is a brief introduction to the Lax-Phillips theory of scattering.

4

Contents
1
The topology of metric spaces
13
1.1
Metric spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
1.2
Completeness and completion. . . . . . . . . . . . . . . . . . . . .
16
1.3
Normed vector spaces and Banach spaces. . . . . . . . . . . . . .
17
1.4
Compactness. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
1.5
Total Boundedness. . . . . . . . . . . . . . . . . . . . . . . . . . .
18
1.6
Separability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
1.7
Second Countability. . . . . . . . . . . . . . . . . . . . . . . . . .
20
1.8
Conclusion of the proof of Theorem 1.5.1. . . . . . . . . . . . . .
20
1.9
Dini’s lemma. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
1.10 The Lebesgue outer measure of an interval is its length. . . . . .
21
1.11 Zorn’s lemma and the axiom of choice. . . . . . . . . . . . . . . .
23
1.12 The Baire category theorem.
. . . . . . . . . . . . . . . . . . . .
24
1.13 Tychonoﬀ’s theorem. . . . . . . . . . . . . . . . . . . . . . . . . .
24
1.14 Urysohn’s lemma. . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
1.15 The Stone-Weierstrass theorem. . . . . . . . . . . . . . . . . . . .
27
1.16 Machado’s theorem.
. . . . . . . . . . . . . . . . . . . . . . . . .
30
1.17 The Hahn-Banach theorem. . . . . . . . . . . . . . . . . . . . . .
32
1.18 The Uniform Boundedness Principle. . . . . . . . . . . . . . . . .
35
2
Hilbert Spaces and Compact operators.
37
2.1
Hilbert space. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
2.1.1
Scalar products.
. . . . . . . . . . . . . . . . . . . . . . .
37
2.1.2
The Cauchy-Schwartz inequality. . . . . . . . . . . . . . .
38
2.1.3
The triangle inequality . . . . . . . . . . . . . . . . . . . .
39
2.1.4
Hilbert and pre-Hilbert spaces. . . . . . . . . . . . . . . .
40
2.1.5
The Pythagorean theorem.
. . . . . . . . . . . . . . . . .
41
2.1.6
The theorem of Apollonius. . . . . . . . . . . . . . . . . .
42
2.1.7
The theorem of Jordan and von Neumann.
. . . . . . . .
42
2.1.8
Orthogonal projection. . . . . . . . . . . . . . . . . . . . .
45
2.1.9
The Riesz representation theorem. . . . . . . . . . . . . .
47
2.1.10 What is L2(T)? . . . . . . . . . . . . . . . . . . . . . . . .
48
2.1.11 Projection onto a direct sum. . . . . . . . . . . . . . . . .
49
2.1.12 Projection onto a ﬁnite dimensional subspace. . . . . . . .
49
5

6
CONTENTS
2.1.13 Bessel’s inequality. . . . . . . . . . . . . . . . . . . . . . .
49
2.1.14 Parseval’s equation.
. . . . . . . . . . . . . . . . . . . . .
50
2.1.15 Orthonormal bases.
. . . . . . . . . . . . . . . . . . . . .
50
2.2
Self-adjoint transformations. . . . . . . . . . . . . . . . . . . . . .
51
2.2.1
Non-negative self-adjoint transformations. . . . . . . . . .
52
2.3
Compact self-adjoint transformations.
. . . . . . . . . . . . . . .
54
2.4
Fourier’s Fourier series.
. . . . . . . . . . . . . . . . . . . . . . .
57
2.4.1
Proof by integration by parts. . . . . . . . . . . . . . . . .
57
2.4.2
Relation to the operator
d
dx. . . . . . . . . . . . . . . . . .
60
2.4.3
G˚arding’s inequality, special case. . . . . . . . . . . . . . .
62
2.5
The Heisenberg uncertainty principle.
. . . . . . . . . . . . . . .
64
2.6
The Sobolev Spaces. . . . . . . . . . . . . . . . . . . . . . . . . .
67
2.7
G˚arding’s inequality. . . . . . . . . . . . . . . . . . . . . . . . . .
72
2.8
Consequences of G˚arding’s inequality.
. . . . . . . . . . . . . . .
76
2.9
Extension of the basic lemmas to manifolds. . . . . . . . . . . . .
79
2.10 Example: Hodge theory. . . . . . . . . . . . . . . . . . . . . . . .
80
2.11 The resolvent. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
3
The Fourier Transform.
85
3.1
Conventions, especially about 2π. . . . . . . . . . . . . . . . . . .
85
3.2
Convolution goes to multiplication. . . . . . . . . . . . . . . . . .
86
3.3
Scaling.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
3.4
Fourier transform of a Gaussian is a Gaussian.
. . . . . . . . . .
86
3.5
The multiplication formula. . . . . . . . . . . . . . . . . . . . . .
88
3.6
The inversion formula. . . . . . . . . . . . . . . . . . . . . . . . .
88
3.7
Plancherel’s theorem . . . . . . . . . . . . . . . . . . . . . . . . .
88
3.8
The Poisson summation formula. . . . . . . . . . . . . . . . . . .
89
3.9
The Shannon sampling theorem.
. . . . . . . . . . . . . . . . . .
90
3.10 The Heisenberg Uncertainty Principle. . . . . . . . . . . . . . . .
91
3.11 Tempered distributions. . . . . . . . . . . . . . . . . . . . . . . .
92
3.11.1 Examples of Fourier transforms of elements of S′. . . . . .
93
4
Measure theory.
95
4.1
Lebesgue outer measure. . . . . . . . . . . . . . . . . . . . . . . .
95
4.2
Lebesgue inner measure. . . . . . . . . . . . . . . . . . . . . . . .
98
4.3
Lebesgue’s deﬁnition of measurability. . . . . . . . . . . . . . . .
98
4.4
Caratheodory’s deﬁnition of measurability. . . . . . . . . . . . . . 102
4.5
Countable additivity. . . . . . . . . . . . . . . . . . . . . . . . . . 104
4.6
σ-ﬁelds, measures, and outer measures. . . . . . . . . . . . . . . . 108
4.7
Constructing outer measures, Method I. . . . . . . . . . . . . . . 109
4.7.1
A pathological example. . . . . . . . . . . . . . . . . . . . 110
4.7.2
Metric outer measures. . . . . . . . . . . . . . . . . . . . . 111
4.8
Constructing outer measures, Method II. . . . . . . . . . . . . . . 113
4.8.1
An example.
. . . . . . . . . . . . . . . . . . . . . . . . . 114
4.9
Hausdorﬀmeasure. . . . . . . . . . . . . . . . . . . . . . . . . . . 116
4.10 Hausdorﬀdimension. . . . . . . . . . . . . . . . . . . . . . . . . . 117

CONTENTS
7
4.11 Push forward. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
4.12 The Hausdorﬀdimension of fractals
. . . . . . . . . . . . . . . . 119
4.12.1 Similarity dimension. . . . . . . . . . . . . . . . . . . . . . 119
4.12.2 The string model.
. . . . . . . . . . . . . . . . . . . . . . 122
4.13 The Hausdorﬀmetric and Hutchinson’s theorem. . . . . . . . . . 124
4.14 Aﬃne examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
4.14.1 The classical Cantor set. . . . . . . . . . . . . . . . . . . . 126
4.14.2 The Sierpinski Gasket . . . . . . . . . . . . . . . . . . . . 128
4.14.3 Moran’s theorem . . . . . . . . . . . . . . . . . . . . . . . 129
5
The Lebesgue integral.
133
5.1
Real valued measurable functions.
. . . . . . . . . . . . . . . . . 134
5.2
The integral of a non-negative function.
. . . . . . . . . . . . . . 134
5.3
Fatou’s lemma. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
5.4
The monotone convergence theorem. . . . . . . . . . . . . . . . . 140
5.5
The space L1(X, R). . . . . . . . . . . . . . . . . . . . . . . . . . 140
5.6
The dominated convergence theorem. . . . . . . . . . . . . . . . . 143
5.7
Riemann integrability. . . . . . . . . . . . . . . . . . . . . . . . . 144
5.8
The Beppo - Levi theorem.
. . . . . . . . . . . . . . . . . . . . . 145
5.9
L1 is complete. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
5.10 Dense subsets of L1(R, R).
. . . . . . . . . . . . . . . . . . . . . 147
5.11 The Riemann-Lebesgue Lemma.
. . . . . . . . . . . . . . . . . . 148
5.11.1 The Cantor-Lebesgue theorem. . . . . . . . . . . . . . . . 150
5.12 Fubini’s theorem. . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
5.12.1 Product σ-ﬁelds. . . . . . . . . . . . . . . . . . . . . . . . 151
5.12.2 π-systems and λ-systems. . . . . . . . . . . . . . . . . . . 152
5.12.3 The monotone class theorem. . . . . . . . . . . . . . . . . 153
5.12.4 Fubini for ﬁnite measures and bounded functions.
. . . . 154
5.12.5 Extensions to unbounded functions and to σ-ﬁnite measures.156
6
The Daniell integral.
157
6.1
The Daniell Integral . . . . . . . . . . . . . . . . . . . . . . . . . 157
6.2
Monotone class theorems. . . . . . . . . . . . . . . . . . . . . . . 160
6.3
Measure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
6.4
H¨older, Minkowski , Lp and Lq. . . . . . . . . . . . . . . . . . . . 163
6.5
∥· ∥∞is the essential sup norm. . . . . . . . . . . . . . . . . . . . 166
6.6
The Radon-Nikodym Theorem. . . . . . . . . . . . . . . . . . . . 167
6.7
The dual space of Lp.
. . . . . . . . . . . . . . . . . . . . . . . . 170
6.7.1
The variations of a bounded functional. . . . . . . . . . . 171
6.7.2
Duality of Lp and Lq when µ(S) < ∞. . . . . . . . . . . . 172
6.7.3
The case where µ(S) = ∞.
. . . . . . . . . . . . . . . . . 173
6.8
Integration on locally compact Hausdorﬀspaces.
. . . . . . . . . 175
6.8.1
Riesz representation theorems.
. . . . . . . . . . . . . . . 175
6.8.2
Fubini’s theorem. . . . . . . . . . . . . . . . . . . . . . . . 176
6.9
The Riesz representation theorem redux. . . . . . . . . . . . . . . 177
6.9.1
Statement of the theorem. . . . . . . . . . . . . . . . . . . 177

8
CONTENTS
6.9.2
Propositions in topology.
. . . . . . . . . . . . . . . . . . 178
6.9.3
Proof of the uniqueness of the µ restricted to B(X).
. . . 180
6.10 Existence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
6.10.1 Deﬁnition. . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
6.10.2 Measurability of the Borel sets. . . . . . . . . . . . . . . . 182
6.10.3 Compact sets have ﬁnite measure.
. . . . . . . . . . . . . 183
6.10.4 Interior regularity. . . . . . . . . . . . . . . . . . . . . . . 183
6.10.5 Conclusion of the proof. . . . . . . . . . . . . . . . . . . . 184
7
Wiener measure, Brownian motion and white noise.
187
7.1
Wiener measure. . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
7.1.1
The Big Path Space. . . . . . . . . . . . . . . . . . . . . . 187
7.1.2
The heat equation. . . . . . . . . . . . . . . . . . . . . . . 189
7.1.3
Paths are continuous with probability one.
. . . . . . . . 190
7.1.4
Embedding in S′. . . . . . . . . . . . . . . . . . . . . . . . 194
7.2
Stochastic processes and generalized stochastic processes.
. . . . 195
7.3
Gaussian measures. . . . . . . . . . . . . . . . . . . . . . . . . . . 196
7.3.1
Generalities about expectation and variance.
. . . . . . . 196
7.3.2
Gaussian measures and their variances.
. . . . . . . . . . 198
7.3.3
The variance of a Gaussian with density. . . . . . . . . . . 199
7.3.4
The variance of Brownian motion.
. . . . . . . . . . . . . 200
7.4
The derivative of Brownian motion is white noise. . . . . . . . . . 202
8
Haar measure.
205
8.1
Examples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
8.1.1
Rn.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
8.1.2
Discrete groups.
. . . . . . . . . . . . . . . . . . . . . . . 206
8.1.3
Lie groups.
. . . . . . . . . . . . . . . . . . . . . . . . . . 206
8.2
Topological facts. . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
8.3
Construction of the Haar integral.
. . . . . . . . . . . . . . . . . 212
8.4
Uniqueness. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216
8.5
µ(G) < ∞if and only if G is compact. . . . . . . . . . . . . . . . 218
8.6
The group algebra. . . . . . . . . . . . . . . . . . . . . . . . . . . 218
8.7
The involution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
8.7.1
The modular function. . . . . . . . . . . . . . . . . . . . . 220
8.7.2
Deﬁnition of the involution. . . . . . . . . . . . . . . . . . 222
8.7.3
Relation to convolution. . . . . . . . . . . . . . . . . . . . 223
8.7.4
Banach algebras with involutions.
. . . . . . . . . . . . . 223
8.8
The algebra of ﬁnite measures.
. . . . . . . . . . . . . . . . . . . 223
8.8.1
Algebras and coalgebras. . . . . . . . . . . . . . . . . . . . 224
8.9
Invariant and relatively invariant measures on homogeneous spaces.225

CONTENTS
9
9
Banach algebras and the spectral theorem.
231
9.1
Maximal ideals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
9.1.1
Existence. . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
9.1.2
The maximal spectrum of a ring. . . . . . . . . . . . . . . 232
9.1.3
Maximal ideals in a commutative algebra. . . . . . . . . . 233
9.1.4
Maximal ideals in the ring of continuous functions. . . . . 234
9.2
Normed algebras. . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
9.3
The Gelfand representation. . . . . . . . . . . . . . . . . . . . . . 236
9.3.1
Invertible elements in a Banach algebra form an open set. 238
9.3.2
The Gelfand representation for commutative Banach al-
gebras. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
9.3.3
The spectral radius.
. . . . . . . . . . . . . . . . . . . . . 241
9.3.4
The generalized Wiener theorem. . . . . . . . . . . . . . . 242
9.4
Self-adjoint algebras. . . . . . . . . . . . . . . . . . . . . . . . . . 244
9.4.1
An important generalization. . . . . . . . . . . . . . . . . 247
9.4.2
An important application. . . . . . . . . . . . . . . . . . . 248
9.5
The Spectral Theorem for Bounded Normal Operators, Func-
tional Calculus Form.
. . . . . . . . . . . . . . . . . . . . . . . . 249
9.5.1
Statement of the theorem. . . . . . . . . . . . . . . . . . . 250
9.5.2
SpecB(T) = SpecA(T). . . . . . . . . . . . . . . . . . . . . 251
9.5.3
A direct proof of the spectral theorem. . . . . . . . . . . . 253
10 The spectral theorem.
255
10.1 Resolutions of the identity.
. . . . . . . . . . . . . . . . . . . . . 256
10.2 The spectral theorem for bounded normal operators. . . . . . . . 261
10.3 Stone’s formula. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
10.4 Unbounded operators. . . . . . . . . . . . . . . . . . . . . . . . . 262
10.5 Operators and their domains. . . . . . . . . . . . . . . . . . . . . 263
10.6 The adjoint. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
10.7 Self-adjoint operators. . . . . . . . . . . . . . . . . . . . . . . . . 265
10.8 The resolvent. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
10.9 The multiplication operator form of the spectral theorem. . . . . 268
10.9.1 Cyclic vectors.
. . . . . . . . . . . . . . . . . . . . . . . . 269
10.9.2 The general case. . . . . . . . . . . . . . . . . . . . . . . . 271
10.9.3 The spectral theorem for unbounded self-adjoint opera-
tors, multiplication operator form. . . . . . . . . . . . . . 271
10.9.4 The functional calculus. . . . . . . . . . . . . . . . . . . . 273
10.9.5 Resolutions of the identity.
. . . . . . . . . . . . . . . . . 274
10.10The Riesz-Dunford calculus. . . . . . . . . . . . . . . . . . . . . . 276
10.11Lorch’s proof of the spectral theorem.
. . . . . . . . . . . . . . . 279
10.11.1Positive operators. . . . . . . . . . . . . . . . . . . . . . . 279
10.11.2The point spectrum. . . . . . . . . . . . . . . . . . . . . . 281
10.11.3Partition into pure types. . . . . . . . . . . . . . . . . . . 282
10.11.4Completion of the proof. . . . . . . . . . . . . . . . . . . . 283
10.12Characterizing operators with purely continuous spectrum.
. . . 287
10.13Appendix. The closed graph theorem. . . . . . . . . . . . . . . . 288

10
CONTENTS
11 Stone’s theorem
291
11.1 von Neumann’s Cayley transform.
. . . . . . . . . . . . . . . . . 292
11.1.1 An elementary example. . . . . . . . . . . . . . . . . . . . 297
11.2 Equibounded semi-groups on a Frechet space. . . . . . . . . . . . 299
11.2.1 The inﬁnitesimal generator. . . . . . . . . . . . . . . . . . 299
11.3 The diﬀerential equation . . . . . . . . . . . . . . . . . . . . . . . 301
11.3.1 The resolvent. . . . . . . . . . . . . . . . . . . . . . . . . . 303
11.3.2 Examples. . . . . . . . . . . . . . . . . . . . . . . . . . . . 304
11.4 The power series expansion of the exponential.
. . . . . . . . . . 309
11.5 The Hille Yosida theorem. . . . . . . . . . . . . . . . . . . . . . . 310
11.6 Contraction semigroups. . . . . . . . . . . . . . . . . . . . . . . . 313
11.6.1 Dissipation and contraction. . . . . . . . . . . . . . . . . . 314
11.6.2 A special case: exp(t(B −I)) with ∥B∥≤1. . . . . . . . . 316
11.7 Convergence of semigroups. . . . . . . . . . . . . . . . . . . . . . 317
11.8 The Trotter product formula. . . . . . . . . . . . . . . . . . . . . 320
11.8.1 Lie’s formula. . . . . . . . . . . . . . . . . . . . . . . . . . 320
11.8.2 Chernoﬀ’s theorem.
. . . . . . . . . . . . . . . . . . . . . 321
11.8.3 The product formula.
. . . . . . . . . . . . . . . . . . . . 322
11.8.4 Commutators.
. . . . . . . . . . . . . . . . . . . . . . . . 323
11.8.5 The Kato-Rellich theorem.
. . . . . . . . . . . . . . . . . 323
11.8.6 Feynman path integrals. . . . . . . . . . . . . . . . . . . . 324
11.9 The Feynman-Kac formula. . . . . . . . . . . . . . . . . . . . . . 326
11.10The free Hamiltonian and the Yukawa potential.
. . . . . . . . . 328
11.10.1The Yukawa potential and the resolvent. . . . . . . . . . . 329
11.10.2The time evolution of the free Hamiltonian. . . . . . . . . 331
12 More about the spectral theorem
333
12.1 Bound states and scattering states. . . . . . . . . . . . . . . . . . 333
12.1.1 Schwartzschild’s theorem. . . . . . . . . . . . . . . . . . . 333
12.1.2 The mean ergodic theorem
. . . . . . . . . . . . . . . . . 335
12.1.3 General considerations.
. . . . . . . . . . . . . . . . . . . 336
12.1.4 Using the mean ergodic theorem. . . . . . . . . . . . . . . 339
12.1.5 The Amrein-Georgescu theorem. . . . . . . . . . . . . . . 340
12.1.6 Kato potentials.
. . . . . . . . . . . . . . . . . . . . . . . 341
12.1.7 Applying the Kato-Rellich method. . . . . . . . . . . . . . 343
12.1.8 Using the inequality (12.7). . . . . . . . . . . . . . . . . . 344
12.1.9 Ruelle’s theorem. . . . . . . . . . . . . . . . . . . . . . . . 345
12.2 Non-negative operators and quadratic forms.
. . . . . . . . . . . 345
12.2.1 Fractional powers of a non-negative self-adjoint operator.
345
12.2.2 Quadratic forms. . . . . . . . . . . . . . . . . . . . . . . . 346
12.2.3 Lower semi-continuous functions. . . . . . . . . . . . . . . 347
12.2.4 The main theorem about quadratic forms. . . . . . . . . . 348
12.2.5 Extensions and cores.
. . . . . . . . . . . . . . . . . . . . 350
12.2.6 The Friedrichs extension.
. . . . . . . . . . . . . . . . . . 350
12.3 Dirichlet boundary conditions.
. . . . . . . . . . . . . . . . . . . 351
12.3.1 The Sobolev spaces W 1,2(Ω) and W 1,2
0
(Ω).
. . . . . . . . 352

CONTENTS
11
12.3.2 Generalizing the domain and the coeﬃcients. . . . . . . . 354
12.3.3 A Sobolev version of Rademacher’s theorem.
. . . . . . . 355
12.4 Rayleigh-Ritz and its applications. . . . . . . . . . . . . . . . . . 357
12.4.1 The discrete spectrum and the essential spectrum. . . . . 357
12.4.2 Characterizing the discrete spectrum.
. . . . . . . . . . . 357
12.4.3 Characterizing the essential spectrum
. . . . . . . . . . . 358
12.4.4 Operators with empty essential spectrum. . . . . . . . . . 358
12.4.5 A characterization of compact operators.
. . . . . . . . . 360
12.4.6 The variational method. . . . . . . . . . . . . . . . . . . . 360
12.4.7 Variations on the variational formula.
. . . . . . . . . . . 362
12.4.8 The secular equation.
. . . . . . . . . . . . . . . . . . . . 364
12.5 The Dirichlet problem for bounded domains.
. . . . . . . . . . . 365
12.6 Valence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366
12.6.1 Two dimensional examples. . . . . . . . . . . . . . . . . . 367
12.6.2 H¨uckel theory of hydrocarbons. . . . . . . . . . . . . . . . 368
12.7 Davies’s proof of the spectral theorem . . . . . . . . . . . . . . . 368
12.7.1 Symbols.
. . . . . . . . . . . . . . . . . . . . . . . . . . . 368
12.7.2 Slowly decreasing functions. . . . . . . . . . . . . . . . . . 369
12.7.3 Stokes’ formula in the plane.
. . . . . . . . . . . . . . . . 370
12.7.4 Almost holomorphic extensions. . . . . . . . . . . . . . . . 371
12.7.5 The Heﬄer-Sj¨ostrand formula.
. . . . . . . . . . . . . . . 371
12.7.6 A formula for the resolvent. . . . . . . . . . . . . . . . . . 373
12.7.7 The functional calculus. . . . . . . . . . . . . . . . . . . . 374
12.7.8 Resolvent invariant subspaces.
. . . . . . . . . . . . . . . 376
12.7.9 Cyclic subspaces. . . . . . . . . . . . . . . . . . . . . . . . 377
12.7.10The spectral representation. . . . . . . . . . . . . . . . . . 380
13 Scattering theory.
383
13.1 Examples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
13.1.1 Translation - truncation. . . . . . . . . . . . . . . . . . . . 383
13.1.2 Incoming representations. . . . . . . . . . . . . . . . . . . 384
13.1.3 Scattering residue. . . . . . . . . . . . . . . . . . . . . . . 386
13.2 Breit-Wigner. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387
13.3 The representation theorem for strongly contractive semi-groups. 388
13.4 The Sinai representation theorem.
. . . . . . . . . . . . . . . . . 390
13.5 The Stone - von Neumann theorem.
. . . . . . . . . . . . . . . . 392

12
CONTENTS

Chapter 1
The topology of metric
spaces
1.1
Metric spaces
A metric for a set X is a function d from X × X to the non-negative real
numbers (which we dente by R≥0),
d : X × X →R≥0
such that for all x, y, z ∈X
1. d(x, y) = d(y, x)
2. d(x, z) ≤d(x, y) + d(y, z)
3. d(x, x) = 0
4. If d(x, y) = 0 then x = y.
The inequality in 2) is known as the triangle inequality since if X is the
plane and d the usual notion of distance, it says that the length of an edge of a
triangle is at most the sum of the lengths of the two other edges. (In the plane,
the inequality is strict unless the three points lie on a line.)
Condition 4) is in many ways inessential, and it is often convenient to drop
it, especially for the purposes of some proofs. For example, we might want to
consider the decimal expansions .49999 . . . and .50000 . . . as diﬀerent, but as
having zero distance from one another. Or we might want to “identify” these
two decimal expansions as representing the same point.
A function d which satisﬁes only conditions 1) - 3) is called a pseudo-
metric.
A metric space is a pair (X, d) where X is a set and d is a metric on X.
Almost always, when d is understood, we engage in the abuse of language and
speak of “the metric space X”.
13

14
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
Similarly for the notion of a pseudo-metric space.
In like fashion, we call d(x, y) the distance between x and y, the function
d being understood.
If r is a positive number and x ∈X, the (open) ball of radius r about x is
deﬁned to be the set of points at distance less than r from x and is denoted by
Br(x). In symbols,
Br(x) := {y| d(x, y) < r}.
If r and s are positive real numbers and if x and z are points of a pseudo-
metric space X, it is possible that Br(x) ∩Bs(z) = ∅. This will certainly be
the case if d(x, z) > r + s by virtue of the triangle inequality. Suppose that this
intersection is not empty and that
w ∈Br(x) ∩Bs(z).
If y ∈X is such that d(y, w) < min[r −d(x, w), s −d(z, w)] then the triangle
inequality implies that y ∈Br(x) ∩Bs(z). Put another way, if we set t :=
min[r −d(x, w), s −d(z, w)] then
Bt(w) ⊂Br(x) ∩Bs(z).
Put still another way, this says that the intersection of two (open) balls is either
empty or is a union of open balls. So if we call a set in X open if either it
is empty, or is a union of open balls, we conclude that the intersection of any
ﬁnite number of open sets is open, as is the union of any number of open sets.
In technical language, we say that the open balls form a base for a topology
on X.
A map f : X →Y from one pseudo-metric space to another is called con-
tinuous if the inverse image under f of any open set in Y is an open set in
X. Since an open set is a union of balls, this amounts to the condition that
the inverse image of an open ball in Y is a union of open balls in X, or, to use
the familiar ϵ, δ language, that if f(x) = y then for every ϵ > 0 there exists a
δ = δ(x, ϵ) > 0 such that
f(Bδ(x)) ⊂Bϵ(y).
Notice that in this deﬁnition δ is allowed to depend both on x and on ϵ. The
map is called uniformly continuous if we can choose the δ independently of
x.
An even stronger condition on a map from one pseudo-metric space to an-
other is the Lipschitz condition. A map f : X →Y from a pseudo-metric
space (X, dX) to a pseudo-metric space (Y, dY ) is called a Lipschitz map with
Lipschitz constant C if
dY (f(x1), f(x2)) ≤CdX(x1, x2)
∀x1, x2 ∈X.
Clearly a Lipschitz map is uniformly continuous.
For example, suppose that A is a ﬁxed subset of a pseudo-metric space X.
Deﬁne the function d(A, ·) from X to R by
d(A, x) := inf{d(x, w), w ∈A}.

1.1. METRIC SPACES
15
The triangle inequality says that
d(x, w) ≤d(x, y) + d(y, w)
for all w, in particular for w ∈A, and hence taking lower bounds we conclude
that
d(A, x) ≤d(x, y) + d(A, y).
or
d(A, x) −d(A, y) ≤d(x, y).
Reversing the roles of x and y then gives
|d(A, x) −d(A, y)| ≤d(x, y).
Using the standard metric on the real numbers where the distance between a
and b is |a −b| this last inequality says that d(A, ·) is a Lipschitz map from X
to R with C = 1.
A closed set is deﬁned to be a set whose complement is open. Since the
inverse image of the complement of a set (under a map f) is the complement
of the inverse image, we conclude that the inverse image of a closed set under a
continuous map is again closed.
For example, the set consisting of a single point in R is closed. Since the
map d(A, ·) is continuous, we conclude that the set
{x|d(A, x) = 0}
consisting of all points at zero distance from A is a closed set. It clearly is a
closed set which contains A. Suppose that S is some closed set containing A, and
y ̸∈S. Then there is some r > 0 such that Br(y) is contained in the complement
of S, which implies that d(y, w) ≥r for all w ∈S. Thus {x|d(A, x) = 0} ⊂S.
In short {x|d(A, x) = 0} is a closed set containing A which is contained in all
closed sets containing A. This is the deﬁnition of the closure of a set, which is
denoted by A. We have proved that
A = {x|d(A, x) = 0}.
In particular, the closure of the one point set {x} consists of all points u such
that d(u, x) = 0.
Now the relation d(x, y) = 0 is an equivalence relation, call it R. (Transitiv-
ity being a consequence of the triangle inequality.) This then divides the space
X into equivalence classes, where each equivalence class is of the form {x}, the
closure of a one point set. If u ∈{x} and v ∈{y} then
d(u, v) ≤d(u, x) + d(x, y) + d(y, v) = d(x, y).
since x ∈{u} and y ∈{v} we obtain the reverse inequality, and so
d(u, v) = d(x, y).

16
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
In other words, we may deﬁne the distance function on the quotient space X/R,
i.e. on the space of equivalence classes by
d({x}, {y}) := d(u, v),
u ∈{x}, v ∈{y}
and this does not depend on the choice of u and v. Axioms 1)-3) for a metric
space continue to hold, but now
d({x}, {y}) = 0 ⇒{x} = {y}.
In other words, X/R is a metric space. Clearly the projection map x 7→{x} is
an isometry of X onto X/R. (An isometry is a map which preserves distances.)
In particular it is continuous. It is also open.
In short, we have provided a canonical way of passing (via an isometry) from
a pseudo-metric space to a metric space by identifying points which are at zero
distance from one another.
A subset A of a pseudo-metric space X is called dense if its closure is the
whole space. From the above construction, the image A/R of A in the quotient
space X/R is again dense.
We will use this fact in the next section in the
following form:
If f : Y →X is an isometry of Y such that f(Y ) is a dense set of X, then
f descends to a map F of Y onto a dense set in the metric space X/R.
1.2
Completeness and completion.
The usual notion of convergence and Cauchy sequence go over unchanged to
metric spaces or pseudo-metric spaces Y . A sequence {yn} is said to converge
to the point y if for every ϵ > 0 there exists an N = N(ϵ) such that
d(yn, y) < ϵ
∀n > N.
A sequence {yn} is said to be Cauchy if for any ϵ > 0 there exists an N = N(ϵ)
such that
d(yn, ym) < ϵ
∀m, n > N.
The triangle inequality implies that every convergent sequence is Cauchy. But
not every Cauchy sequence is convergent. For example, we can have a sequence
of rational numbers which converge to an irrational number, as in the approxi-
mation to the square root of 2. So if we look at the set of rational numbers as a
metric space Q in its own right, not every Cauchy sequence of rational numbers
converges in Q. We must “complete” the rational numbers to obtain R, the set
of real numbers. We want to discuss this phenomenon in general.
So we say that a (pseudo-)metric space is complete if every Cauchy sequence
converges. The key result of this section is that we can always “complete” a
metric or pseudo-metric space. More precisely, we claim that

1.3. NORMED VECTOR SPACES AND BANACH SPACES.
17
Any metric (or pseudo-metric) space can be mapped by a one to one isometry
onto a dense subset of a complete metric (or pseudo-metric) space.
By the italicized statement of the preceding section, it is enough to prove
this for a pseudo-metric spaces X. Let Xseq denote the set of Cauchy sequences
in X, and deﬁne the distance between the Cauchy sequences {xn} and {yn} to
be
d({xn}, {yn}) := lim
n→∞d(xn, yn).
It is easy to check that d deﬁnes a pseudo-metric on Xseq. Let f : X →Xseq
be the map sending x to the sequence all of whose elements are x;
f(x) = (x, x, x, x, · · · ).
It is clear that f is one to one and is an isometry. The image is dense since by
deﬁnition
lim d(f(xn), {xn}) = 0.
Now since f(X) is dense in Xseq, it suﬃces to show that any Cauchy sequence
of points of the form f(xn) converges to a limit. But such a sequence converges
to the element {xn}. QED
1.3
Normed vector spaces and Banach spaces.
Of special interest are vector spaces which have a metric which is compatible
with the vector space properties and which is complete: Let V be a vector space
over the real or complex numbers. A norm is a real valued function
v 7→∥v∥
on V which satisﬁes
1. ∥v∥≥0 and > 0 if v ̸= 0,
2. ∥cv∥= |c|∥v∥for any real (or complex) number c, and
3. ∥v + w∥≤∥v∥+ ∥w∥∀v, w ∈V .
Then d(v, w) := ∥v−w∥is a metric on V , which satisﬁes d(v+u, w+u) = d(v, w)
for all v, w, u ∈V . The ball of radius r about the origin is then the set of all v
such that ∥v∥< r. A vector space equipped with a norm is called a normed
vector space and if it is complete relative to the metric it is called a Banach
space.
Our construction shows that any vector space with a norm can be completed
so that it becomes a Banach space.

18
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
1.4
Compactness.
A topological space X is said to be compact if it has one (and hence the other)
of the following equivalent properties:
• Every open cover has a ﬁnite subcover.
In more detail: if {Uα} is a
collection of open sets with
X ⊂
[
α
Uα
then there are ﬁnitely many α1, . . . , αn such that
X ⊂Uα1 ∪· · · ∪Uαn.
• If F is a family of closed sets such that
\
F ∈F
= ∅
then a ﬁnite intersection of the F’s are empty:
F1 ∩· · · ∩Fn = ∅.
1.5
Total Boundedness.
A metric space X is said to be totally bounded if for every ϵ > 0 there are
ﬁnitely many open balls of radius ϵ which cover X.
Theorem 1.5.1 The following assertions are equivalent for a metric space:
1. X is compact.
2. Every sequence in X has a convergent subsequence.
3. X is totally bounded and complete.
Proof that 1. ⇒2. Let {yi} be a sequence of points in X. We ﬁrst show that
there is a point x with the property for every ϵ > 0, the open ball of radius ϵ
centered at x contains the points yi for inﬁnitely many i. Suppose not. Then
for any z ∈X there is an ϵ > 0 such that the ball Bϵ(z) contains only ﬁnitely
many yi. Since z ∈Bϵ(z), the set of such balls covers X. By compactness,
ﬁnitely many of these balls cover X, and hence there are only ﬁnitely many i,
a contradiction.
Now choose i1 so that yi1 is in the ball of radius 1
2 centered at x. Then
choose i2 > i1 so that yi2 is in the ball of radius 1
4 centered at x and keep going.
We have constructed a subsequence so that the points yik converge to x. Thus
we have proved that 1. implies 2.

1.6. SEPARABILITY.
19
Proof that 2. ⇒3. If {xj} is a Cauchy sequence in X, it has a convergent
subsequence by hypothesis, and the limit of this subsequence is (by the triangle
inequality) the limit of the original sequence. Hence X is complete. We must
show that it is totally bounded. Given ϵ > 0, pick a point y1 ∈X and let Bϵ(y1)
be open ball of radius ϵ about y1. If Bϵ(y1) = X there is nothing further to
prove. If not, pick a point y2 ∈X −Bϵ(y1) and let Bϵ(y2) be the ball of radius ϵ
about y2. If Bϵ(y1) ∪Bϵ(y2) = X there is nothing to prove. If not, pick a point
y3 ∈X −(Bϵ(y1) ∪Bϵ(y2)) etc. This procedure can not continue indeﬁnitely,
for then we will have constructed a sequence of points which are all at a mutual
distance ≥ϵ from one another, and this sequence has no Cauchy subsequence.
Proof that 3. ⇒2. Let {xj} be a sequence of points in X which we relabel as
{x1,j}. Let B1, 1
2 , . . . , Bn1, 1
2 be a ﬁnite number of balls of radius 1
2 which cover X.
Our hypothesis 3. asserts that such a ﬁnite cover exists. Inﬁnitely many of the j
must be such that the x1,j all lie in one of these balls. Relabel this subsequence
as {x2,j}. Cover X by ﬁnitely many balls of radius 1
3. There must be inﬁnitely
many j such that all the x2,j lie in one of the balls. Relabel this subsequence as
{x3,j}. Continue. At the ith stage we have a subsequence {xi,j} of our original
sequence (in fact of the preceding subsequence in the construction) all of whose
points lie in a ball of radius 1/i. Now consider the “diagonal” subsequence
x1,1, x2,2, x3,3, . . . .
All the points from xi,i on lie in a ﬁxed ball of radius 1/i so this is a Cauchy
sequence. Since X is assumed to be complete, this subsequence of our original
sequence is convergent.
We have shown that 2. and 3. are equivalent. The hard part of the proof
consists in showing that these two conditions imply 1. For this it is useful to
introduce some terminology:
1.6
Separability.
A metric space X is called separable if it has a countable subset {xj} of points
which are dense. For example R is separable because the rationals are countable
and dense. Similarly, Rn is separable because the points all of whose coordinates
are rational form a countable dense subset.
Proposition 1.6.1 Any subset Y of a separable metric space X is separable
(in the induced metric).
Proof. Let {xj} be a countable dense sequence in X. Consider the set of pairs
(j, n) such that
B1/2n(xj) ∩Y ̸= ∅.
For each such (j, n) let yj,n be any point in this non-empty intersection. We
claim that the countable set of points yj,n are dense in Y . Indeed, let y be any
point of Y . Let n be any positive integer. We can ﬁnd a point xj such that
d(xj, y) < 1/2n since the xj are dense in X. But then d(y, yj,n) < 1/n by the
triangle inequality. QED

20
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
Proposition 1.6.2 Any totally bounded metric space X is separable.
Proof. For each n let {x1,n, . . . , xin,n} be the centers of balls of radius 1/n
(ﬁnite in number) which cover X. Put all of these together into one sequence
which is clearly dense. QED
A base for the open sets in a topology on a space X is a collection B of open
set such that every open set of X is the union of sets of B
Proposition 1.6.3 A family B is a base for the topology on X if and only if
for every x ∈X and every open set U containing x there is a V ∈B such that
x ∈V and V ⊂U.
Proof. If B is a base, then U is a union of members of B one of which must
therefore contain x. Conversely, let U be an open subset of X. For each x ∈U
there is a Vx ⊂U belonging to B. The union of these over all x ∈U is contained
in U and contains all the points of U, hence equals U. So B is a base. QED
1.7
Second Countability.
A topological space X is said to be second countable or to satisfy the second
axiom of countability if it has a base B which is (ﬁnite or ) countable.
Proposition 1.7.1 A metric space X is second countable if and only if it is
separable.
Proof. Suppose X is separable with a countable dense set {xi}. The open balls
of radius 1/n about the xi form a countable base: Indeed, if U is an open set
and x ∈U then take n suﬃciently large so that B2/n(x) ⊂U. Choose j so that
d(xj, x) < 1/n. Then V := B1/n(xj) satisﬁes x ∈V ⊂U so by Proposition
1.6.3 the set of balls B1/n(xj) form a base and they constitute a countable set.
Conversely, let B be a countable base, and choose a point xj ∈Uj for each
Uj ∈B. If x is any point of X, the ball of radius ϵ > 0 about x includes some
Uj and hence contains xj. So the xj form a countable dense set. QED
Proposition 1.7.2 Lindelof’s theorem. Suppose that the topological space
X is second countable. Then every open cover has a countable subcover.
Let U be a cover, not necessarily countable, and let B be a countable base. Let
C ⊂B consist of those open sets V belonging to B which are such that V ⊂U
where U ∈U. By Proposition 1.6.3 these form a (countable) cover. For each
V ∈C choose a UV ∈U such that V ⊂UV . Then the {UV }V ∈C form a countable
subset of U which is a cover. QED
1.8
Conclusion of the proof of Theorem 1.5.1.
Suppose that condition 2. and 3. of the theorem hold for the metric space
X. By Proposition 1.6.2, X is separable, and hence by Proposition 1.7.1, X is

1.9. DINI’S LEMMA.
21
second countable. Hence by Proposition 1.7.2, every cover U has a countable
subcover. So we must prove that if U1, U2, U3, . . . is a sequence of open sets
which cover X, then X = U1 ∪U2 ∪· · · ∪Um for some ﬁnite integer m. Suppose
not. For each m choose xm ∈X with xm ̸∈U1 ∪· · · ∪Um. By condition 2.
of Theorem 1.5.1, we may choose a subsequence of the {xj} which converge to
some point x. Since U1 ∪· · · ∪Um is open, its complement is closed, and since
xj ̸∈U1 ∪· · · ∪Um for j > m we conclude that x ̸∈U1 ∪· · · ∪Um for any m.
This says that the {Uj} do not cover X, a contradiction. QED
Putting the pieces together, we see that a closed bounded subset of Rm is
compact. This is the famous Heine-Borel theorem. So Theorem 1.5.1 can be
considered as a far reaching generalization of the Heine-Borel theorem.
1.9
Dini’s lemma.
Let X be a metric space and let L denote the space of real valued continuous
functions of compact support. So f ∈L means that f is continuous, and the
closure of the set of all x for which |f(x)| > 0 is compact. Thus L is a real
vector space, and f ∈L ⇒|f| ∈L. Thus if f ∈L and g ∈L then f +g ∈L and
also max (f, g) = 1
2(f + g + |f −g|) ∈L and min (f, g) = 1
2(f + g −|f −g|) ∈L.
For a sequence of elements in L (or more generally in any space of real valued
functions) we write fn ↓0 to mean that the sequence of functions is monotone
decreasing, and at each x we have fn(x) →0.
Theorem 1.9.1 Dini’s lemma. If fn ∈L and fn ↓0 then ∥fn∥∞→0. In
other words, monotone decreasing convergence to 0 implies uniform convergence
to zero for elements of L.
Proof.
Given ϵ > 0, let Cn = {x|fn(x) ≥ϵ}.
Then the Cn are compact,
Cn ⊃Cn+1 and T
k Ck = ∅. Hence a ﬁnite intersection is already empty, which
means that Cn = ∅for some n. This means that ∥fn∥∞≤ϵ for some n, and
hence, since the sequence is monotone decreasing, for all subsequent n. QED
1.10
The Lebesgue outer measure of an interval
is its length.
For any subset A ⊂R we deﬁne its Lebesgue outer measure by
m∗(A) := inf
X
ℓ(In) : In are intervals with A ⊂
[
In.
(1.1)
Here the length ℓ(I) of any interval I = [a, b] is b −a with the same deﬁnition
for half open intervals (a, b] or [a, b), or open intervals. Of course if a = −∞
and b is ﬁnite or +∞, or if a is ﬁnite and b = +∞the length is inﬁnite. So the
inﬁmum in (1.1) is taken over all covers of A by intervals. By the usual ϵ/2n
trick, i.e. by replacing each Ij = [aj, bj] by (aj −ϵ/2j+1, bj + ϵ/2j+1) we may

22
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
assume that the inﬁmum is taken over open intervals. (Equally well, we could
use half open intervals of the form [a, b), for example.).
It is clear that if A ⊂B then m∗(A) ≤m∗(B) since any cover of B by
intervals is a cover of A. Also, if Z is any set of measure zero, then m∗(A∪Z) =
m∗(A). In particular, m∗(Z) = 0 if Z has measure zero. Also, if A = [a, b] is an
interval, then we can cover it by itself, so
m∗([a, b]) ≤b −a,
and hence the same is true for (a, b], [a, b), or (a, b). If the interval is inﬁnite, it
clearly can not be covered by a set of intervals whose total length is ﬁnite, since
if we lined them up with end points touching they could not cover an inﬁnite
interval. We still must prove that
m∗(I) = ℓ(I)
(1.2)
if I is a ﬁnite interval. We may assume that I = [c, d] is a closed interval by
what we have already said, and that the minimization in (1.1) is with respect
to a cover by open intervals. So what we must show is that if
[c, d] ⊂
[
i
(ai, bi)
then
d −c ≤
X
i
(bi −ai).
We ﬁrst apply Heine-Borel to replace the countable cover by a ﬁnite cover.
(This only decreases the right hand side of preceding inequality.) So let n be
the number of elements in the cover. We want to prove that if
[c, d] ⊂
n
[
i=1
(ai, bi) then d −c ≤
n
X
i=1
(bi −ai).
We shall do this by induction on n. If n = 1 then a1 < c and b1 > d so clearly
b1 −a1 > d −c.
Suppose that n ≥2 and we know the result for all covers (of all intervals
[c, d] ) with at most n −1 intervals in the cover. If some interval (ai, bi) is
disjoint from [c, d] we may eliminate it from the cover, and then we are in the
case of n −1 intervals. So every (ai, bi) has non-empty intersection with [c, d].
Among the the intervals (ai, bi) there will be one for which ai takes on the
minimum possible value. By relabeling, we may assume that this is (a1, b1).
Since c is covered, we must have a1 < c. If b1 > d then (a1, b1) covers [c, d] and
there is nothing further to do. So assume b1 ≤d. We must have b1 > c since
(a1, b1) ∩[c, d] ̸= ∅. Since b1 ∈[c, d], at least one of the intervals (ai, bi), i > 1
contains the point b1. By relabeling, we may assume that it is (a2, b2). But now
we have a cover of [c, d] by n −1 intervals:
[c, d] ⊂(a1, b2) ∪
n
[
i=3
(ai, bi).

1.11. ZORN’S LEMMA AND THE AXIOM OF CHOICE.
23
So by induction
d −c ≤(b2 −a1) +
n
X
i=3
(bi −ai).
But b2 −a1 ≤(b2 −a2) + (b1 −a1) since a2 < b1. QED
1.11
Zorn’s lemma and the axiom of choice.
In the ﬁrst few sections we repeatedly used an argument which involved “choos-
ing” this or that element of a set. That we can do so is an axiom known as
The axiom of choice. If F is a function with domain D such that F(x)
is a non-empty set for every x ∈D, then there exists a function f with domain
D such that f(x) ∈F(x) for every x ∈D.
It has been proved by G¨odel that if mathematics is consistent without the
axiom of choice (a big “if”!)
then mathematics remains consistent with the
axiom of choice added.
In fact, it will be convenient for us to take a slightly less intuitive axiom as
out starting point:
Zorn’s lemma.
Every partially ordered set A has a maximal linearly
ordered subset. If every linearly ordered subset of A has an upper bound, then
A contains a maximum element.
The second assertion is a consequence of the ﬁrst. For let B be a maximum
linearly ordered subset of A, and x an upper bound for B. Then x is a maximum
element of A, for if y ≻x then we could add y to B to obtain a larger linearly
ordered set. Thus there is no element in A which is strictly larger than x which
is what we mean when we say that x is a maximum element.
Zorn’s lemma implies the axiom of choice.
Indeed, consider the set A of all functions g deﬁned on subsets of D such
that g(x) ∈F(x). We will let dom(g) denote the domain of deﬁnition of g. The
set A is not empty, for if we pick a point x0 ∈D and pick y0 ∈F(x0), then
the function g whose domain consists of the single point x0 and whose value
g(x0) = y0 gives an element of A. Put a partial order on A by saying that
g ⪯h if dom(g) ⊂dom(h) and the restriction of h to dom g coincides with g.
A linearly ordered subset means that we have an increasing family of domains
X, with functions h deﬁned consistently with respect to restriction. But this
means that there is a function g deﬁned on the union of these domains, S X
whose restriction to each X coincides with the corresponding h. This is clearly
an upper bound. So A has a maximal element f. If the domain of f were not

24
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
all of D we could add a single point x0 not in the domain of f and y0 ∈F(x0)
contradicting the maximality of f. QED
1.12
The Baire category theorem.
Theorem 1.12.1 In a complete metric space any countable intersection of dense
open sets is dense.
Proof. Let X be the space, let B be an open ball in X, and let O1, O2 . . . be
a sequence of dense open sets. We must show that
B ∩
 \
n
On
!
̸= ∅.
Since O1 is dense, B ∩O1 ̸= ∅, and is open. Thus B ∩O1 contains the closure B1
of some open ball B1. We may choose B1 (smaller if necessary) so that its radius
is < 1. Since B1 is open and O2 is dense, B1∩O2 contains the closure B2 of some
open ball B2, of radius < 1
2, and so on. Since X is complete, the intersection of
the decreasing sequence of closed balls we have constructed contains some point
x which belong both to B and to the intersection of all the Oi. QED
A Baire space is deﬁned as a topological space in which every countable
intersection of dense open sets is dense. Thus Baire’s theorem asserts that every
complete metric space is a Baire space. A set A in a topological space is called
nowhere dense if its closure contains no open set. Put another way, a set A is
nowhere dense if its complement Ac contains an open dense set. A set S is said
to be of ﬁrst category if it is a countable union of nowhere dense sets. Then
Baire’s category theorem can be reformulated as saying that the complement of
any set of ﬁrst category in a complete metric space (or in any Baire space) is
dense. A property P of points of a Baire space is said to hold quasi - surely
or quasi-everywhere if it holds on an intersection of countably many dense
open sets. In other words, if the set where P does not hold is of ﬁrst category.
1.13
Tychonoﬀ’s theorem.
Let I be a set, serving as an “index set”. Suppose that for each α ∈I we are
given a non-empty topological space Sα. The Cartesian product
S :=
Y
α∈I
Sα
is deﬁned as the collection of all functions x whose domain in I and such that
x(α) ∈Sα. This space is not empty by the axiom of choice. We frequently write
xα instead of x(α) and called xα the “α coordinate of x”.
The map
fα :
Y
α∈I
Sα →Sα,
x 7→xα

1.14. URYSOHN’S LEMMA.
25
is called the projection of S onto Sα. We put on S the weakest topology such
that all of these projections are continuous. So the open sets of S are generated
by the sets of the form
f −1
α (Uα) where Uα ⊂Sα is open.
Theorem 1.13.1 [Tychonoﬀ.]
If all the Sα are compact, then so is S =
Q
α∈I Sα.
Proof. Let F be a family of closed subsets of S with the property that the
intersection of any ﬁnite collection of subsets from this family is not empty. We
must show that the intersection of all the elements of F is not empty. Using
Zorn, extend F to a maximal family F0 of (not necessarily closed) subsets of S
with the property that the intersection of any ﬁnite collection of elements of F0
is not empty. For each α, the projection fα(F0) has the property that there is
a point xα ∈Sα which is in the closure of all the sets belonging to fα(F0). Let
x ∈S be the point whose α-th coordinate is xα. We will show that x is in the
closure of every element of F0 which will complete the proof.
Let U be an open set containing x. By the deﬁnition of the product topology,
there are ﬁnitely many αi and open subsets Uαi ⊂Sαi such that
x ∈
n
\
i=1
f −1
αi (Uαi) ⊂U.
So for each i = 1, . . . , n, xαi ∈Uαi. This means that Uαi intersects every
set belonging to fαi(F0). So f −1
αi (Uαi) intersects every set belonging to F0 and
hence must belong to F0 by maximality. Therefore,
n
\
i=1
f −1
αi (Uαi) ∈F0,
again by maximality. This says that U intersects every set of F0. In other
words, any neighborhood of x intersects every set belonging to F0, which is just
another way of saying x belongs to the closure of every set belonging to F0.
QED
1.14
Urysohn’s lemma.
A topological space S is called normal if it is Hausdorﬀ, and if for any pair
F1, F2 of closed sets with F1 ∩F2 = ∅there are disjoint open sets U1, U2 with
F1 ⊂U1 and F2 ⊂U2. For example, suppose that S is Hausdorﬀand compact.
For each p ∈F1 and q ∈F2 there are neighborhoods Oq of p and Wq of q with
Oq ∩Wq = ∅. This is the Hausdorﬀaxiom. A ﬁnite number of the Wq cover
F2 since it is compact. Let the intersection of the corresponding Oq be called
Up and the union of the corresponding Wq be called Vp. Thus for each p ∈F1
we have found a neighborhood Up of p and an open set Vp containing F2 with

26
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
Up ∩Vp = ∅. Once again, ﬁnitely many of the Up cover F1. So the union U of
these and the intersection V of the corresponding Vp give disjoint open sets U
containing F1 and V containing F2. So any compact Hausdorﬀspace is normal.
Theorem 1.14.1 [Urysohn’s lemma.] If F0 and F1 are disjoint closed sets
in a normal space S then there is a continuous real valued function f : S →R
such that 0 ≤f ≤1, f = 0 on F0 and f = 1 on F1.
Proof.
Let
V1 := F c
1.
We can ﬁnd an open set V 1
2 containing F0 and whose closure is contained in V1,
since we can choose V 1
2 disjoint from an open set containing F1. So we have
F0 ⊂V 1
2 ,
V 1
2 ⊂V1.
Applying our normality assumption to the sets F0 and V c
1
2 we can ﬁnd an open
set V 1
4 with F0 ⊂V 1
4 and V 1
4 ⊂V 1
2 . Similarly, we can ﬁnd an open set V 3
4 with
V 1
2 ⊂V 3
4 and V 3
4 ⊂V1. So we have
F0 ⊂V 1
4 , V 1
4 ⊂V 1
2 , V 1
2 ⊂V 3
4 , V 3
4 ⊂V1 = F c
1.
Continuing in this way, for each 0 < r < 1 where r is a dyadic rational, r = m/2k
we produce an open set Vr with F0 ⊂Vr and Vr ⊂Vs if r < s, including
Vr ⊂V1 = F c
1. Deﬁne f as follows: Set f(x) = 1 for x ∈F1. Otherwise, deﬁne
f(x) = inf{r|x ∈Vr}.
So f = 0 on F0.
If 0 < b ≤1, then f(x) < b means that x ∈Vr for some r < b. Thus
f −1([0, b)) =
[
r<b
Vr.
This is a union of open sets, hence open. Similarly, f(x) > a means that there
is some r > a such that x ̸∈Vr. Thus
f −1((a, 1]) =
[
r>a
(Vr)c,
also a union of open sets, hence open. So we have shown that
f −1([0, b))
and
f −1((a, 1])
are open. Hence f −1((a, b)) is open. Since the intervals [0, b), (a, 1] and (a, b)
form a basis for the open sets on the interval [0, 1], we see that the inverse image
of any open set under f is open, which says that f is continuous. QED
We will have several occasions to use this result.

1.15. THE STONE-WEIERSTRASS THEOREM.
27
1.15
The Stone-Weierstrass theorem.
This is an important generalization of Weierstrass’s theorem which asserted that
the polynomials are dense in the space of continuous functions on any compact
interval, when we use the uniform topology. We shall have many uses for this
theorem.
An algebra A of (real valued) functions on a set S is said to separate points
if for any p, q ∈S, p ̸= q there is an f ∈A with f(p) ̸= f(q).
Theorem 1.15.1 [Stone-Weierstrass.] Let S be a compact space and A an
algebra of continuous real valued functions on S which separates points. Then
the closure of A in the uniform topology is either the algebra of all continuous
functions on S, or is the algebra of all continuous functions on S which all
vanish at a single point, call it x∞.
We will give two diﬀerent proofs of this important theorem. For our ﬁrst proof,
we ﬁrst state and prove some preliminary lemmas:
Lemma 1.15.1 An algebra A of bounded real valued functions on a set S which
is closed in the uniform topology is also closed under the lattice operations ∨and
∧.
Proof.
Since f ∨g = 1
2(f + g + |f −g|) and f ∧g = 1
2(f + g −|f −g|) we
must show that
f ∈A
⇒|f| ∈A.
Replacing f by f/∥f∥∞we may assume that
|f| ≤1.
The Taylor series expansion about the point 1
2 for the function t 7→(t + ϵ2)
1
2
converges uniformly on [0, 1]. So there exists, for any ϵ > 0 there is a polynomial
P such that
|P(x2) −(x2 + ϵ2)
1
2 | < ϵ
on [−1, 1].
Let
Q := P −P(0).
We have |P(0) −ϵ| < ϵ so
|P(0)| < 2ϵ.
So Q(0) = 0 and
|Q(x2) −(x2 + ϵ2)
1
2 | < 3ϵ.
But
(x2 + ϵ2)
1
2 −|x| ≤ϵ
for small ϵ. So
|Q(x2) −|x| | < 4ϵ
on
[0, 1].

28
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
As Q does not contain a constant term, and A is an algebra, Q(f 2) ∈A for any
f ∈A. Since we are assuming that |f| ≤1 we have
Q(f 2) ∈A,
and
∥Q(f 2) −|f| ∥∞< 4ϵ.
Since we are assuming that A is closed under ∥· ∥∞we conclude that |f| ∈A
completing the proof of the lemma.
Lemma 1.15.2 Let A be a set of real valued continuous functions on a compact
space S such that
f, g ∈A ⇒
f ∧g ∈A and f ∨g ∈A.
Then the closure of A in the uniform topology contains every continuous function
on S which can be approximated at every pair of points by a function belonging
to A.
Proof.
Suppose that f is a continuous function on S which can be approxi-
mated at any pair of points by elements of A. So let p, q ∈S and ϵ > 0, and let
fp,q,ϵ ∈A be such that
|f(p) −fp,q,ϵ(p)| < ϵ,
|f(q) −fp,q,ϵ(q)| < ϵ.
Let
Up,q,ϵ := {x|fp,q,ϵ(x) < f(x) + ϵ},
Vp,q,ϵ := {x|fp,q,ϵ(x) > f(x) −ϵ}.
Fix q and ϵ. The sets Up,q,ϵ cover S as p varies. Hence a ﬁnite number cover S
since we are assuming that S is compact. We may take the minimum fq,ϵ of the
corresponding ﬁnite collection of fp,q,ϵ. The function fq,ϵ has the property that
fq,ϵ(x) < f(x) + ϵ
and
fq,ϵ(x) > f(x) −ϵ
for
x ∈
\
p
Vp,q,ϵ
where the intersection is again over the same ﬁnite set of p’s. We have now
found a collection of functions fq,ϵ such that
fq,ϵ < f + ϵ
and fq,ϵ > f −ϵ on some neighborhood Vq,ϵ of q. We may choose a ﬁnite number
of q so that the Vq,ϵ cover all of S. Taking the maximum of the corresponding
fq,ϵ gives a function fϵ ∈A with f −ϵ < f < f + ϵ, i.e.
∥f −fϵ∥∞< ϵ.

1.15. THE STONE-WEIERSTRASS THEOREM.
29
Since we are assuming that A is closed in the uniform topology we conclude
that f ∈A, completing the proof of the lemma.
Proof of the Stone-Weierstrass theorem.
Suppose ﬁrst that for every
x ∈S there is a g ∈A with g(x) ̸= 0. Let x ̸= y and h ∈A with h(y) ̸= 0.
Then we may choose real numbers c and d so that f = cg + dh is such that
0 ̸= f(x) ̸= f(y) ̸= 0.
Then for any real numbers a and b we may ﬁnd constants A and B such that
Af(x) + Bf 2(x) = a
and Af(y) + Bf 2(y) = b.
We can therefore approximate (in fact hit exactly on the nose) any function at
any two distinct points. We know that the closure of A is closed under ∨and
∧by the ﬁrst lemma. By the second lemma we conclude that the closure of A
is the algebra of all real valued continuous functions.
The second alternative is that there is a point, call it p∞at which all f ∈A
vanish. We wish to show that the closure of A contains all continuous functions
vanishing at p∞. Let B be the algebra obtained from A by adding the constants.
Then B satisﬁes the hypotheses of the Stone-Weierstrass theorem and contains
functions which do not vanish at p∞. so we can apply the preceding result. If
g is a continuous function vanishing at p∞we may, for any ϵ > 0 ﬁnd an f ∈A
and a constant c so that
∥g −(f + c)∥∞< ϵ
2.
Evaluating at p∞gives |c| < ϵ/2. So
∥g −f∥∞< ϵ.
QED
The reason for the apparently strange notation p∞has to do with the notion
of the one point compactiﬁcation of a locally compact space. A topological space
S is called locally compact if every point has a closed compact neighborhood.
We can make S compact by adding a single point. Indeed, let p∞be a point
not belonging to S and set
S∞:= S ∪p∞.
We put a topology on S∞by taking as the open sets all the open sets of S
together with all sets of the form
O ∪p∞
where O is an open set of S whose complement is compact. The space S∞is
compact, for if we have an open cover of S∞, at least one of the open sets in
this cover must be of the second type, hence its complement is compact, hence
covered by ﬁnitely many of the remaining sets.
If S itself is compact, then
the empty set has compact complement, hence p∞has an open neighborhood

30
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
disjoint from S, and all we have done is add a disconnected point to S. The
space S∞is called the one-point compactiﬁcation of S. In applications of
the Stone-Weierstrass theorem, we shall frequently have to do with an algebra
of functions on a locally compact space consisting of functions which “vanish
at inﬁnity” in the sense that for any ϵ > 0 there is a compact set C such that
|f| < ϵ on the complement of C. We can think of these functions as being
deﬁned on S∞and all vanishing at p∞.
We now turn to a second proof of this important theorem.
1.16
Machado’s theorem.
Let M be a compact space and let CR(M) denote the algebra of continuous
real valued functions on M. We let ∥· ∥= ∥· ∥∞denote the uniform norm on
CR(M). More generally, for any closed set F ⊂M, we let
∥f∥F = sup
x∈F
|f(x)|
so ∥· ∥= ∥· ∥M.
If A ⊂CR(M) is a collection of functions, we will say that a subset E ⊂M
is a level set (for A) if all the elements of A are constant on the set E. Also,
for any f ∈CR(M) and any closed set F ⊂M, we let
df(F) := inf
g∈A ∥f −g∥F .
So df(F) measures how far f is from the elements of A on the set F. (I have
suppressed the dependence on A in this notation.) We can look for “small”
closed subsets which measure how far f is from A on all of M; that is we look
for closed sets with the property that
df(E) = df(M).
(1.3)
Let F denote the collection of all non-empty closed subsets of M with this
property. Clearly M ∈F so this collection is not empty. We order F by the
reverse of inclusion: F1 ≺F2 if F1 ⊃F2. Let C be a totally ordered subset
of F. Since M is compact, the intersection of any nested family of non-empty
closed sets is again non-empty. We claim that the intersection of all the sets in
C belongs to F, i.e. satisﬁes (1.3). Indeed, since df(F) = df(M) for any F ∈C
this means that for any g ∈A, the sets
{x ∈F||f(x) −g(x)| ≥df((M))}
are non-empty. They are also closed and nested, and hence have a non-empty
intersection. So on the set
E =
\
F ∈C
F
we have
∥f −g∥E ≥df(M).

1.16. MACHADO’S THEOREM.
31
So every chain has an upper bound, and hence by Zorn’s lemma, there exists a
maximum, i.e. there exists a non-empty closed subset E satisfying (1.3) which
has the property that no proper subset of E satisﬁes (1.3). We shall call such a
subset f-minimal.
Theorem 1.16.1 [Machado.] Suppose that A ⊂CR(M) is a subalgebra which
contains the constants and which is closed in the uniform topology. Then for
every f ∈CR(M) there exists an A level set satisfying(1.3).
In fact, every
f-minimal set is an A level set.
Proof.
Let E be an f-minimal set. Suppose it is not an A level set. This
means that there is some h ∈A which is not constant on A. Replacing h by
ah + c where a and c are constant, we may arrange that
min
x∈E h = 0
and max
x∈E h = 1.
Let
E0 := {x ∈E|0 ≤h(x) ≤2
3} and E1 : {x ∈E|1
3 ≤x ≤1}.
These are non-empty closed proper subsets of E, and hence the minimality of
E implies that there exist g0, g1 ∈A such that
∥f −g0∥E0 ≤df(M) −ϵ
and
∥f −g1∥E1 ≤df(M) −ϵ
for some ϵ > 0. Deﬁne
hn := (1 −hn)2n
and
kn := hng0 + (1 −hn)g1.
Both hn and kn belong to A and 0 ≤hn ≤1 on E, with strict inequality on
E0 ∩E1. At each x ∈E0 ∩E1 i we have
|f(x) −kn(x)|
=
|hn(x)f(x) −hn(x)g0(x) + (1 −hn(x))f(x) −(1 −hn(x))g1(x)|
≤
hn(x)∥f −g0|∥E0∩E1 + (1 −hn)∥f −g1|∥E0∩E1
≤
hn(x)∥f −g0∥E0 + (1 −hn(x)∥f −g1|∥E1 ≤df(M) −ϵ.
We will now show that hn →1 on E0 \ E1 and hn →0 on E1 \ E0. Indeed, on
E0 \ E1 we have
hn <
1
3
n
so
hn = (1 −hn)2n ≥1 −2nhn ≥1 −
2
3
n
→1
since the binomial formula gives an alternating sum with decreasing terms. On
the other hand,
hn(1 + hn)2n = 1 −h2·2n ≤1
or
hn ≤
1
(1 + hn)2n .

32
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
Now the binomial formula implies that for any integer k and any positive number
a we have ka ≤(1 + a)k or (1 + a)−k ≤1/(ka). So we have
hn ≤
1
2nhn .
On E0 \ E1 we have hn ≥
  2
3
n so there we have
hn ≤
3
4
n
→0.
Thus kn →g0 uniformly on E0 \ E1 and kn →g1 uniformly on E1 \ E0. We
conclude that for n large enough
∥f −kn∥E < df(M)
contradicting our assumption that df(E) = df(M). QED
Corollary 1.16.1 [The Stone-Weierstrass Theorem.] If A is a uniformly
closed subalgebra of CR(M) which contains the constants and separates points,
then A = CR(M).
Proof.
The only A-level sets are points. But since ∥f −f(a)∥{a} = 0, we
conclude that df(M) = 0, i.e. f ∈A for any f ∈CR(M). QED
1.17
The Hahn-Banach theorem.
This says:
Theorem 1.17.1 [Hahn-Banach]. Let M be a subspace of a normed linear
space B, and let F be a bounded linear function on M. Then F can be extended
so as to be deﬁned on all of B without increasing its norm.
Proof by Zorn.
Suppose that we can prove
Proposition 1.17.1 Let M be a subspace of a normed linear space B, and let
F be a bounded linear function on on M. Let y ∈B, y ̸∈M. Then F can be
extended to M + {y} without changing its norm.
Then we could order the extensions of F by inclusion, one extension being ⪰
than another if it is deﬁned on a larger space. The extension deﬁned on the
union of any family of subspaces ordered by inclusion is again an extension, and
so is an upper bound. The proposition implies that a maximal extension must
be deﬁned on the whole space, otherwise we can extend it further. So we must
prove the proposition.
I was careful in the statement not to specify whether our spaces are over the
real or complex numbers. Let us ﬁrst assume that we are dealing with a real
vector space, and then deduce the complex case.

1.17. THE HAHN-BANACH THEOREM.
33
We want to choose a value
α = F(y)
so that if we then deﬁne
F(x + λy) := F(x) + λF(y) = F(x) + λα,
∀x ∈M, λ ∈R
we do not increase the norm of F. If F = 0 we take α = 0. If F ̸= 0, we
may replace F by F/∥F∥, extend and then multiply by ∥F∥so without loss of
generality we may assume that ∥F∥= 1. We want to choose the extension to
have norm 1, which means that we want
|F(x) + λα| ≤∥x + λy∥
∀x ∈M, λ ∈R.
If λ = 0 this is true by hypothesis. If λ ̸= 0 divide this inequality by λ and
replace (1/λ)x by x. We want
|F(x) + α| ≤∥x + y∥
∀x ∈M.
We can write this as two separate conditions:
F(x2) + α ≤∥x2 + y∥∀x2 ∈M and
−F(x1) −α ≤∥x1 + y∥∀x1 ∈M.
Rewriting the second inequality this becomes
−F(x1) −∥x1 + y∥≤α ≤−F(x2) + ∥x2 + y∥.
The question is whether such a choice is possible. In other words, is the supre-
mum of the left hand side (over all x1 ∈M) less than or equal to the inﬁmum
of the right hand side (over all x2 ∈M)? If the answer to this question is yes,
we may choose α to be any value between the sup of the left and the inf of the
right hand sides of the preceding inequality. So our question is: Is
F(x2) −F(x1)| ≤∥x2 + y∥+ ∥x1 + y∥
∀x1, x2 ∈M?
But x1 −x2 = (x1 + y) −(x2 + y) and so using the fact that ∥F∥= 1 and the
triangle inequality gives
|F(x2) −F(x1)| ≤∥x2 −x1∥≤∥x2 + y∥+ ∥x1 + y∥.
This completes the proof of the proposition, and hence of the Hahn-Banach
theorem over the real numbers.
We now deal with the complex case.
If B is a complex normed vector
space, then it is also a real vector space, and the real and imaginary parts of a
complex linear function are real linear functions. In other words, we can write
any complex linear function F as
F(x) = G(x) + iH(x)

34
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
where G and H are real linear functions. The fact that F is complex linear says
that F(ix) = iF(x) or
G(ix) = −H(x)
or
H(x) = −G(ix)
or
F(x) = G(x) −iG(ix).
The fact that ∥F∥= 1 implies that ∥G∥≤1. So we can adjoin the real one
dimensional space spanned by y to M and extend the real linear function to it,
keeping the norm ≤1. Next adjoin the real one dimensional space spanned by
iy and extend G to it. We now have G extended to M ⊕Cy with no increase
in norm. Try to deﬁne
F(z) := G(z) −iG(iz)
on M ⊕Cy. This map of M ⊕Cy →C is R-linear, and coincides with F on
M. We must check that it is complex linear and that its norm is ≤1: To check
that it is complex linear it is enough to observe that
F(iz) = G(iz) −iG(−z) = i[G(z) −iG(iz)] = iF(z).
To check the norm, we may, for any z, choose θ so that eiθF(z) is real and is
non-negative. Then
|F(z)| = |eiθF(z)| = |F(eiθz)| = G(eiθz) ≤∥eiθz∥= ∥z∥
so ∥F∥≤1. QED
Suppose that M is a closed subspace of B and that y ̸∈M. Let d denote
the distance of y to M, so that
d := inf
x∈M ∥y −x∥.
Suppose we start with the zero function on M, and extend it ﬁrst to M ⊕y by
F(λy −x) = λd.
This is a linear function on M + {y} and its norm is ≤1. Indeed
∥F∥= sup
λ,x
|λd|
∥λy −x∥= sup
x′∈M
d
∥y −x′∥= d
d = 1.
Let M 0 be the set of all continuous linear functions on B which vanish on
M. Then, using the Hahn-Banach theorem we get
Proposition 1.17.2 If y ∈B and y ̸∈M where M is a closed linear subspace
of B, then there is an element F ∈M 0 with ∥F∥≤1 and F(y) ̸= 0. In fact we
can arrange that F(y) = d where d is the distance from y to M.

1.18. THE UNIFORM BOUNDEDNESS PRINCIPLE.
35
We have an embedding
B →B∗∗
x 7→x∗∗where x∗∗(F) := F(x).
The ﬁrst part of the preceding proposition can be formulated as
(M 0)0 = M
if M is a closed subspace of B.
The map x 7→x∗∗is clearly linear and
|x∗∗(F)| = |F(x)| ≤∥F∥∥x∥.
Taking the sup of |x∗∗(F)|/∥F∥shows that
∥x∗∗∥≤∥x∥
where the norm on the left is the norm on the space B∗∗. On the other hand,
if we take M = {0} in the preceding proposition, we can ﬁnd an F ∈B∗with
∥F∥= 1 and F(x) = ∥x∥. For this F we have |x∗∗(F)| = ∥x∥. So
∥x∗∗∥≥∥x∥.
We have proved
Theorem 1.17.2 The map B →B∗∗given above is a norm preserving injec-
tion.
1.18
The Uniform Boundedness Principle.
Theorem 1.18.1 Let B be a Banach space and {Fn} be a sequence of elements
in B∗such that for every ﬁxed x ∈B the sequence of numbers {|Fn(x)|} is
bounded. Then the sequence of norms {∥Fn∥} is bounded.
Proof.
The proof will be by a Baire category style argument. We will prove
Proposition 1.18.1 There exists some ball B = B(y, r), r > 0 about a point y
with ∥y∥≤1 and a constant K such that |Fn(z)| ≤K for all z ∈B.
Proof that the proposition implies the theorem. For any z with ∥z∥< 1
we have
z −y = 2
r
r
2(z −y)

and
∥r
2(z −y)∥≤r
since ∥z −y∥≤2.
|Fn(z)| ≤|Fn(z −y)| + |Fn(y)| ≤2K
r
+ K.

36
CHAPTER 1. THE TOPOLOGY OF METRIC SPACES
So
∥Fn∥≤2K
r
+ K
for all n proving the theorem from the proposition.
Proof of the proposition. If the proposition is false, we can ﬁnd n1 such that
|Fn1(x)| > 1 at some x ∈B(0, 1) and hence in some ball of radius ϵ < 1
2 about x.
Then we can ﬁnd an n2 with |Fn2(z)| > 2 in some non-empty closed ball of radius
< 1
3 lying inside the ﬁrst ball. Continuing inductively, we choose a subsequence
nm and a family of nested non-empty balls Bm with |Fnm(z)| > m throughout
Bm and the radii of the balls tending to zero. Since B is complete, there is
a point x common to all these balls, and {|Fn(x)|} is unbounded, contrary to
hypothesis. QED
We will have occasion to use this theorem in a “reversed form”.
Recall
that we have the norm preserving injection B →B∗∗sending x 7→x∗∗where
x∗∗(F) = F(x). Since B∗is a Banach space (even if B is incomplete) we have
Corollary 1.18.1 If {xn} is a sequence of elements in a normed linear space
such that the numerical sequence {|F(xn)|} is bounded for each ﬁxed F ∈B∗
then the sequence of norms {∥xn∥} is bounded.

Chapter 2
Hilbert Spaces and
Compact operators.
2.1
Hilbert space.
2.1.1
Scalar products.
V is a complex vector space. A rule assigning to every pair of vectors f, g ∈V
a complex number (f, g) is called a semi-scalar product if
1. (f, g) is linear in f when g is held ﬁxed.
2. (g, f) = (f, g). This implies that (f, g) is anti-linear in g when f is held
ﬁxed. In other words. (f, ag + bh) = a(f, g) + b(f, h). It also implies that
(f, f) is real.
3. (f, f) ≥0 for all f ∈V .
If 3. is replaced by the stronger condition
4. (f, f) > 0 for all non-zero f ∈V
then we say that ( , ) is a scalar product.
Examples.
• V = Cn, so an element z of V is a column vector of complex numbers:
z =



z1
...
zn



and (z, w) is given by
(z, w) :=
n
X
1
ziwi.
37

38
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
• V consists of all continuous (complex valued) functions on the real line
which are periodic of period 2π and
(f, g) := 1
2π
Z π
−π
f(x)g(x)dx.
We will denote this space by C(T). Here the letter T stands for the one
dimensional torus, i.e. the circle. We are identifying functions which are
periodic with period 2π with functions which are deﬁned on the circle
R/2πZ.
• V consists of all doubly inﬁnite sequences of complex numbers
a = . . . , a−2, a−1, a0, a1, a2, . . .
which satisfy
X
|ai|2 < ∞.
Here
(a, b) :=
X
aibi.
All three are examples of scalar products.
2.1.2
The Cauchy-Schwartz inequality.
This says that if ( , ) is a semi-scalar product then
|(f, g)| ≤(f, f)
1
2 (g, g)
1
2 .
(2.1)
Proof. For any real number t condition 3. above says that (f −tg, f −tg) ≥0.
Expanding out gives
0 ≤(f −tg, f −tg) = (f, f) −t[(f, g) + (g, f)] + t2(g, g).
Since (g, f) = (f, g), the coeﬃcient of t in the above expression is twice the real
part of (f, g). So the real quadratic form
Q(t) := (f, f) −2Re(f, g)t + t2(g.g)
is nowhere negative. So it can not have distinct real roots, and hence by the
b2 −4ac rule we get
4(Re(f, g))2 −4(f, f)(g, g) ≤0
or
(Re(f, g))2 ≤(f, f)(g, g).
(2.2)
This is useful and almost but not quite what we want. But we may apply this
inequality to h = eiθg for any θ. Then (h, h) = (g, g). Choose θ so that
(f, g) = reiθ

2.1. HILBERT SPACE.
39
where r = |(f, g)|. Then
(f, h) = (f, eiθg) = e−iθ(f, g) = |(f, g)|
and the preceding inequality with g replaced by h gives
|(f, g)|2 ≤(f, f)(g, g)
and taking square roots gives (2.1).
2.1.3
The triangle inequality
For any semiscalar product deﬁne
∥f∥:= (f, f)
1
2
so we can write the Cauchy-Schwartz inequality as
|(f, g)| ≤∥f∥∥g∥.
The triangle inequality says that
∥f + g∥≤∥f∥+ ∥g∥.
(2.3)
Proof.
∥f + g∥2
=
(f + g, f + g)
=
(f, f) + 2Re(f, g) + (g, g)
≤
(f, f) + 2∥f∥∥g∥+ (g, g)
by (2.2)
=
∥f|2 + 2∥f∥∥g∥+ ∥g∥2
=
(∥f∥+ ∥g∥)2.
Taking square roots gives the triangle inequality (2.3). Notice that
∥cf∥= |c|∥f∥
(2.4)
since (cf, cf) = cc(f, f) = |c|2∥f∥2.
Suppose we try to deﬁne the distance between two elements of V by
d(f, g) := ∥f −g∥.
Notice that then d(f, f) = 0, d(f, g) = d(g, f) and for any three elements
d(f, h) ≤d(f, g) + d(g, h)
by virtue of the triangle inequality. The only trouble with this deﬁnition is that
we might have two distinct elements at zero distance, i.e. 0 = d(f, g) = ∥f −g∥.
But this can not happen if ( , ) is a scalar product, i.e. satisﬁes condition 4.

40
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
A complex vector space V endowed with a scalar product is called a pre-
Hilbert space.
Let V be a complex vector space and let ∥· ∥be a map which assigns to any
f ∈V a non-negative real ∥f∥number such that ∥f∥> 0 for all non-zero f. If
∥·∥satisﬁes the triangle inequality (2.3) and equation (2.4) it is called a norm.
A vector space endowed with a norm is called a normed space. The pre-Hilbert
spaces can be characterized among all normed spaces by the parallelogram law
as we will discuss below.
Later on, we will have to weaken condition (2.4) in our general study. But
it is too complicated to give the general deﬁnition right now.
2.1.4
Hilbert and pre-Hilbert spaces.
The reason for the preﬁx “pre” is the following: The distance d deﬁned above
has all the desired properties we might expect of a distance. In particular, we
can deﬁne the notions of “limit” and of a “Cauchy sequence” as is done for the
real numbers: If fn is a sequence of elements of V , and f ∈V we say that f is
the limit of the fn and write
lim
n→∞fn = f,
or fn →f
if, for any positive number ϵ there is an N = N(ϵ) such that
d(fn, f) < ϵ
for all n ≥N.
If a sequence converges to some limit f, then this limit is unique, since any
limits must be at zero distance and hence equal.
We say that a sequence of elements is Cauchy if for any δ > 0 there is an
K = K(δ) such that
d(fm, fn) < δ
∀, m, n ≥K.
If the sequence fn has a limit, then it is Cauchy - just choose K(δ) = N( 1
2δ)
and use the triangle inequality.
But it is quite possible that a Cauchy sequence has no limit. As an example
of this type of phenomenon, think of the rational numbers with |r −s| as the
distance. The whole point of introducing the real numbers is to guarantee that
every Cauchy sequence has a limit.
So we say that a pre-Hilbert space is a Hilbert space if it is “complete” in
the above sense - if every Cauchy sequence has a limit.
Since the complex numbers are complete (because the real numbers are),
it follows that Cn is complete, i.e.
is a Hilbert space.
Indeed, we can say
that any ﬁnite dimensional pre-Hilbert space is a Hilbert space because it is
isomorphic (as a pre-Hilbert space) to Cn for some n. (See below when we
discuss orthonormal bases.)
The trouble is in the inﬁnite dimensional case, such as the space of continuous
periodic functions.
This space is not complete.
For example, let fn be the
function which is equal to one on (−π + 1
n, −1
n), equal to zero on ( 1
n, π −1
n)

2.1. HILBERT SPACE.
41
and extended linearly −1
n to 1
n and from π −1
n to π + 1
n so as to be continuous
and then extended so as to be periodic.(Thus on the interval (π −1
n, π + 1
n) the
function is given by fn(x) = n
2 (x −(π −1
n).) If m ≤n, the functions fm and fn
agree outside two intervals of length
2
m and on these intervals |fm(x)−fn(x)| ≤
1. So ∥fm −fn∥2 ≤
1
2π · 2/m showing that the sequence {fn} is Cauchy. But
the limit would have to equal one on (−π, 0) and equal zero on (0, π) and so
be discontinuous at the origin and at π. Thus the space of continuous periodic
functions is not a Hilbert space, only a pre-Hilbert space.
But just as we complete the rational numbers (by throwing in “ideal” el-
ements) to get the real numbers, we may similarly complete any pre-Hilbert
space to get a unique Hilbert space. See the section Completion in the chapter
on metric spaces for a general discussion of how to complete any metric space.
In particular, the completion of any normed vector space is a complete normed
vector space. A complete normed space is called a Banach space. The general
construction implies that any normed vector space can be completed to a Ba-
nach space. From the parallelogram law discussed below, it will follow that the
completion of a pre-Hilbert space is a Hilbert space.
The completion of the space of continuous periodic functions will be denoted
by L2(T).
2.1.5
The Pythagorean theorem.
Let V be a pre-Hilbert space. We have
∥f + g∥2 = ∥f∥2 + 2Re(f, g) + ∥g∥2.
So
∥f + g∥2 = ∥f∥2 + ∥g∥2
⇔Re (f, g) = 0.
(2.5)
We make the deﬁnition
f ⊥g ⇔(f, g) = 0
and say that f is perpendicular to g or that f is orthogonal to g. Notice that
this is a stronger condition than the condition for the Pythagorean theorem,
the right hand condition in (2.5). For example ∥f + if∥2 = 2∥f∥2 but (f, if) =
−i∥f∥2 ̸= 0 if ∥f∦= 0.
If ui is some ﬁnite collection of mutually orthogonal vectors, then so are ziui
where the zi are any complex numbers. So if
u =
X
i
ziui
then by the Pythagorean theorem
∥u∥2 =
X
i
|zi|2∥ui∥2.

42
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
In particular, if the ui ̸= 0, then u = 0 ⇒zi = 0 for all i. This shows that any
set of mutually orthogonal (non-zero) vectors is linearly independent.
Notice that the set of functions
einθ
is an orthonormal set in the space of continuous periodic functions in that not
only are they mutually orthogonal, but each has norm one.
2.1.6
The theorem of Apollonius.
Adding the equations
∥f + g∥2
=
∥f∥2 + 2Re (f, g) + ∥g∥2
(2.6)
∥f −g∥2
=
∥f∥2 −2Re (f, g) + ∥g∥2
(2.7)
gives
∥f + g∥2 + ∥f −g∥2 = 2
 ∥f∥2 + ∥g∥2
.
(2.8)
This is known as the parallelogram law. It is the algebraic expression of the
theorem of Apollonius which asserts that the sum of the areas of the squares on
the sides of a parallelogram equals the sum of the areas of the squares on the
diagonals.
If we subtract (2.7) from (2.6) we get
Re(f, g) = 1
4
 ∥f + g∥2 −∥f −g∥2
.
(2.9)
Now (if, g) = i(f, g) and Re {i(f, g)} = −Im(f, g) so
Im(f, g) = −Re(if, g) = Re(f, ig)
so
(f, g) = 1
4
 ∥f + g∥2 −∥f −g∥2 + i∥f + ig∥2 −i∥f −ig∥2
.
(2.10)
If we now complete a pre-Hilbert space, the right hand side of this equation
is deﬁned on the completion, and is a continuous function there. It therefore
follows that the scalar product extends to the completion, and, by continuity,
satisﬁes all the axioms for a scalar product, plus the completeness condition for
the associated norm. In other words, the completion of a pre-Hilbert space is a
Hilbert space.
2.1.7
The theorem of Jordan and von Neumann.
This is essentially a converse to the theorem of Apollonius. It says that if ∥· ∥
is a norm on a (complex) vector space V which satisﬁes (2.8), then V is in fact
a pre-Hilbert space with ∥f∥2 = (f, f). If the theorem is true, then the scalar
product must be given by (2.10). So we must prove that if we take (2.10) as the

2.1. HILBERT SPACE.
43
deﬁnition, then all the axioms on a scalar product hold. The easiest axiom to
verify is
(g, f) = (f, g).
Indeed, the real part of the right hand side of (2.10) is unchanged under the
interchange of f and g (since g −f = −(f −g) and ∥−h∥= ∥h∥for any h is one
of the properties of a norm). Also g + if = i(f −ig) and ∥ih∥= ∥h∥so the last
two terms on the right of (2.10) get interchanged, proving that (g, f) = (f, g).
It is just as easy to prove that
(if, g) = i(f, g).
Indeed replacing f by if sends ∥f + ig∥2 into ∥if + ig∥2 = ∥f + g∥2 and sends
∥f + g∥2 into ∥if + g∥2 = ∥i(f −ig)∥2 = ∥f −ig∥2 = i(−i∥f −ig∥2) so has the
eﬀect of multiplying the sum of the ﬁrst and fourth terms by i, and similarly
for the sum of the second and third terms on the right hand side of (2.10).
Now (2.10) implies (2.9). Suppose we replace f, g in (2.8) by f1 + g, f2 and
by f1 −g, f2 and subtract the second equation from the ﬁrst. We get
∥f1 + f2 + g∥2 −∥f1 + f2 −g∥2 + ∥f1 −f2 + g∥2 −∥f1 −f2 −g∥2
= 2
 ∥f1 + g∥2 −∥f1 −g∥2
.
In view of (2.9) we can write this as
Re (f1 + f2, g) + Re (f1 −f2, g) = 2Re (f1, g).
(2.11)
Now the right hand side of (2.9) vanishes when f = 0 since ∥g∥= ∥−g∥. So if
we take f1 = f2 = f in (2.11) we get
Re (2f, g) = 2Re (f, g).
We can thus write (2.11) as
Re (f1 + f2, g) + Re (f1 −f2, g) = Re (2f1, g).
In this equation make the substitutions
f1 7→1
2(f1 + f2),
f2 7→1
2(f1 −f2).
This yields
Re (f1 + f2, g) = Re (f1, g) + Re (f2, g).
Since it follows from (2.10) and (2.9) that
(f, g) = Re (f, g) −iRe (if, g)
we conclude that
(f1 + f2, g) = (f1, g) + (f2, g).

44
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
Taking f1 = −f2 shows that
(−f, g) = −(f, g).
Consider the collection C of complex numbers α which satisfy
(αf, g) = α(f, g)
(for all f, g). We know from (f1 + f2, g) = (f1, g) + (f2, g) that
α, β ∈C ⇒α + β ∈C.
So C contains all integers. If 0 ̸= β ∈C then
(f, g) = (β · (1/β)f, g) = β((1/β)f, g)
so β−1 ∈C. Thus C contains all (complex) rational numbers. The theorem
will be proved if we can prove that (αf, g) is continuous in α. But the triangle
inequality
∥f + g∥≤∥f∥+ ∥g∥
applied to f = f2, g = f1 −f2 implies that
∥f1∥≤∥f1 −f2∥+ ∥f2∥
or
∥f1∥−∥f2∥≤∥f1 −f2∥.
Interchanging the role of f1 and f2 gives
| ∥f1∥−∥f2∥| ≤∥f1 −f2∥.
Therefore
| ∥αf ± g∥−∥βf ± g∥| ≤∥(α −β)f∥.
Since ∥(α −β)f∥→0 as α →β this shows that the right hand side of (2.10)
when applied to αf and g is a continuous function of α. Thus C = C. We have
proved
Theorem 2.1.1 [P. Jordan and J. von Neumann] If V is a normed space
whose norm satisﬁes (2.8) then V is a pre-Hilbert space.
Notice that the condition (2.8) involves only two vectors at a time.
So we
conclude as an immediate consequence of this theorem that
Corollary 2.1.1 A normed vector space is pre-Hilbert space if and only if every
two dimensional subspace is a Hilbert space in the induced norm.
Actually, a weaker version of this corollary, with two replaced by three had
been proved by Fr´echet, Annals of Mathematics, July 1935, who raised the
problem of giving an abstract characterization of those norms on vector spaces
which come from scalar products. In the immediately following paper Jordan
and von Neumann proved the theorem above leading to the stronger corollary
that two dimensions suﬃce.

2.1. HILBERT SPACE.
45
2.1.8
Orthogonal projection.
We continue with the assumption that V is pre-Hilbert space. If A and B are
two subsets of V , we write A ⊥B if u ∈A and v ∈B ⇒u ⊥v, in other words
if every element of A is perpendicular to every element of B. Similarly, we will
write v ⊥A if the element v is perpendicular to all elements of A. Finally, we
will write A⊥for the set of all v which satisfy v ⊥A. Notice that A⊥is always
a linear subspace of V , for any A.
Now let M be a (linear) subspace of V . Let v be some element of V , not
necessarily belonging to M. We want to investigate the problem of ﬁnding a
w ∈M such that (v −w) ⊥M. Of course, if v ∈M then the only choice is to
take w = v. So the interesting problem is when v ̸∈M. Suppose that such a w
exists, and let x be any (other) point of M. Then by the Pythagorean theorem,
∥v −x∥2 = ∥(v −w) + (w −x)∥2 = ∥v −w∥2 + ∥w −x∥2
since (v −w) ⊥M and (w −x) ∈M. So
∥v −w∥≤∥v −x∥
and this inequality is strict if x ̸= w. In words: if we can ﬁnd a w ∈M such
that (v −w) ⊥M then w is the unique solution of the problem of ﬁnding the
point in M which is closest to v. Conversely, suppose we found a w ∈M which
has this minimization property, and let x be any element of M. Then for any
real number t we have
∥v −w∥2 ≤∥(v −w) + tx∥2 = ∥v −w∥2 + 2tRe (v −w, x) + t2∥x∥2.
Since the minimum of this quadratic polynomial in t occurring on the right is
achieved at t = 0, we conclude (by diﬀerentiating with respect to t and setting
t = 0, for example) that
Re (v −w, x) = 0.
By our usual trick of replacing x by eiθx we conclude that
(v −w, x) = 0.
Since this holds for all x ∈M, we conclude that (v −w) ⊥M. So to ﬁnd w we
search for the minimum of ∥v −x∥, x ∈M.
Now ∥v −x∥≥0 and is some ﬁnite number for any x ∈M. So there will be
some real number m such that m ≤∥v−x∥for x ∈M, and such that no strictly
larger real number will have this property. (m is known as the “greatest lower
bound” of the values ∥v −x∥, x ∈M.) So we can ﬁnd a sequence of vectors
xn ∈M such that
∥v −xn∥→m.
We claim that the xn form a Cauchy sequence. Indeed,
∥xi −xj∥2 = ∥(v −xj) −(v −xi)∥2

46
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
and by the parallelogram law this equals
2
 ∥v −xi∥2 + ∥v −xj∥2
−∥2v −(xi + xj)∥2.
Now the expression in parenthesis converges to 2m2. The last term on the right
is
−∥2(v −1
2(xi + xj)∥2.
Since 1
2(xi + xj)∈M, we conclude that
∥2v −(xi + xj)∥2 ≥4m2
so
∥xi −xj∥2 ≤4(m + ϵ)2 −4m2
for i and j large enough that ∥v −xi∥≤m + ϵ and ∥v −xj∥≤m + ϵ. This
proves that the sequence xn is Cauchy.
Here is the crux of the matter: If M is complete, then we can conclude that
the xn converge to a limit w which is then the unique element in M such that
(v −w) ⊥M. It is at this point that completeness plays such an important role.
Put another way, we can say that if M is a subspace of V which is complete
(under the scalar product ( , ) restricted to M) then we have the orthogonal
direct sum decomposition
V = M ⊕M ⊥,
which says that every element of V can be uniquely decomposed into the sum
of an element of M and a vector perpendicular to M.
For example, if M is the one dimensional subspace consisting of all (complex)
multiples of a non-zero vector y, then M is complete, since C is complete. So
w exists. Since all elements of M are of the form ay, we can write w = ay for
some complex number a. Then (v −ay, y) = 0 or
(v, y) = a∥y∥2
so
a = (v, y)
∥y∥2 .
We call a the Fourier coeﬃcient of v with respect to y. Particularly useful is
the case where ∥y∥= 1 and we can write
a = (v, y).
(2.12)
Getting back to the general case, if V = M ⊕M ⊥holds, so that to every v
there corresponds a unique w ∈M satisfying (v −w) ∈M ⊥the map v 7→w is
called orthogonal projection of V onto M and will be denoted by πM.

2.1. HILBERT SPACE.
47
2.1.9
The Riesz representation theorem.
Let V and W be two complex vector spaces. A map
T : V →W
is called linear if
T(λx + µy) = λT(x) + µT(Y )
∀x, y ∈V,
λ, µ ∈C
and is called anti-linear if
T(λx + µy) = λT(x) + µT(Y )
∀x, y ∈V
λ, µ ∈C.
If ℓ: V →C is a linear map, (also known as a linear function) then
ker ℓ:= {x ∈V | ℓ(x) = 0}
has codimension one (unless ℓ≡0). Indeed, if
ℓ(y) ̸= 0
then
ℓ(x) = 1 where x =
1
ℓ(y)y
and for any z ∈V ,
z −ℓ(z)x ∈ker ℓ.
If V is a normed space and ℓis continuous, then ker (ℓ) is a closed subspace.
The space of continuous linear functions is denoted by V ∗. It has its own norm
deﬁned by
∥ℓ∥:=
sup
x∈V,∥x∦=0
|ℓ(x)|/∥x∥.
Suppose that H is a pre-hilbert space. Then we have an antilinear map
φ : H →H∗,
(φ(g))(f) := (f, g).
The Cauchy-Schwartz inequality implies that
∥φ(g)∥≤∥g∥
and in fact
(g, g) = ∥g∥2
shows that
∥φ(g)∥= ∥g∥.
In particular the map φ is injective.
The Riesz representation theorem says that if H is a Hilbert space, then this
map is surjective:

48
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
Theorem 2.1.2 Every continuous linear function on H is given by scalar prod-
uct by some element of H.
The proof is a consequence of the theorem about projections applied to
N := ker ℓ:
If ℓ= 0 there is nothing to prove. If ℓ̸= 0 then N is a closed subspace of
codimension one. Choose v ̸∈N. Then there is an x ∈N with (v −x) ⊥N. Let
y :=
1
∥v −x∥(v −x).
Then
y ⊥N
and
∥y∥= 1.
For any f ∈H,
[f −(f, y)y] ⊥y
so
f −(f, y)y ∈N
or
ℓ(f) = (f, y)ℓ(y),
so if we set
g := ℓ(y)y
then
(f, g) = ℓ(f)
for all f ∈H. QED
2.1.10
What is L2(T)?
We have deﬁned the space L2(T) to be the completion of the space C(T) under
the L2 norm ∥f∥2 = (f, f)
1
2 . In particular, every linear function on C(T) which
is continuous with respect to the this L2 norm extends to a unique continuous
linear function on L2(T). By the Riesz representation theorem we know that
every such continuous linear function is given by scalar product by an element of
L2(T). Thus we may think of the elements of L2(T) as being the linear functions
on C(T) which are continuous with respect to the L2 norm. An element of L2(T)
should not be thought of as a function, but rather as a linear function on the
space of continuous functions relative to a special norm - the L2 norm.

2.1. HILBERT SPACE.
49
2.1.11
Projection onto a direct sum.
Suppose that the closed subspace M of a pre-Hilbert space is the orthogonal
direct sum of a ﬁnite number of subspaces
M =
M
i
Mi
meaning that the Mi are mutually perpendicular and every element x of M can
be written as
x =
X
xi,
xi ∈Mi.
(The orthogonality guarantees that such a decomposition is unique.) Suppose
further that each Mi is such that the projection πMi exists. Then πM exists
and
πM(v) =
X
πMi(v).
(2.13)
Proof. Clearly the right hand side belongs to M. We must show v −P
i πMi(v)
is orthogonal to every element of M. For this it is enough to show that it is
orthogonal to each Mj since every element of M is a sum of elements of the Mj.
So suppose xj ∈Mj. But (πMiv, xj) = 0 if i ̸= j. So
(v −
X
πMi(v), xj) = (v −πMj(v), xj) = 0
by the deﬁning property of πMj.
2.1.12
Projection onto a ﬁnite dimensional subspace.
We now will put the equations (2.12) and (2.13) together: Suppose that M is
a ﬁnite dimensional subspace with an orthonormal basis φi. This implies that
M is an orthogonal direct sum of the one dimensional spaces spanned by the φi
and hence πM exists and is given by
πM(v) =
X
aiφi
where
ai = (v, φi).
(2.14)
2.1.13
Bessel’s inequality.
We now look at the inﬁnite dimensional situation and suppose that we are given
an orthonormal sequence {φi}∞
1 . Any v ∈V has its Fourier coeﬃcients
ai = (v, φi)
relative to the members of this sequence. Bessel’s inequality asserts that
∞
X
1
|ai|2 ≤∥v∥2,
(2.15)
in particular the sum on the left converges.

50
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
Proof. Let
vn :=
n
X
i=1
aiφi,
so that vn is the projection of v onto the subspace spanned by the ﬁrst n of the
φi. In any event, (v −vn) ⊥vn so by the Pythagorean Theorem
∥v∥2 = ∥v −vn∥2 + ∥vn∥2 = ∥v −vn∥2 +
n
X
i=1
|ai|2.
This implies that
n
X
i=1
|ai|2 ≤∥v∥2
and letting n →∞shows that the series on the left of Bessel’s inequality
converges and that Bessel’s inequality holds.
2.1.14
Parseval’s equation.
Continuing the above argument, observe that
∥v −vn∥2 →0 ⇔
X
|ai|2 = ∥v∥2.
But ∥v −vn∥2 →0 if and only if ∥v −vn∥→0 which is the same as saying that
vn →v. But vn is the n-th partial sum of the series P aiφi, and in the language
of series, we say that a series converges to a limit v and write P aiφi = v if and
only if the partial sums approach v. So
X
aiφi = v
⇔
X
i
|ai|2 = ∥v∥2.
(2.16)
In general, we will call the series P
i aiφi the Fourier series of v (relative
to the given orthonormal sequence) whether or not it converges to v.
Thus
Parseval’s equality says that the Fourier series of v converges to v if and only if
P |ai|2 = ∥v∥2.
2.1.15
Orthonormal bases.
We still suppose that V is merely a pre-Hilbert space. We say that an orthonor-
mal sequence {φi} is a basis of V if every element of V is the sum of its Fourier
series.
For example, one of our tasks will be to show that the exponentials
{einx}∞
n=−∞form a basis of C(T).
If the orthonormal sequence φi is a basis, then any v can be approximated
as closely as we like by ﬁnite linear combinations of the φi, in fact by the partial
sums of its Fourier series. We say that the ﬁnite linear combinations of the φi
are dense in V . Conversely, suppose that the ﬁnite linear combinations of the

2.2. SELF-ADJOINT TRANSFORMATIONS.
51
φi are dense in V . This means that for any v and any ϵ > 0 we can ﬁnd an n
and a set of n complex numbers bi such that
∥v −
X
biφi∥≤ϵ.
But we know that vn is the closest vector to v among all the linear combinations
of the ﬁrst n of the φi. so we must have
∥v −vn∥≤ϵ.
But this says that the Fourier series of v converges to v, i.e. that the φi form
a basis. For example, we know from Fejer’s theorem that the exponentials eikx
are dense in C(T). Hence we know that they form a basis of the pre-Hilbert
space C(T). We will give some alternative proofs of this fact below.
In the case that V is actually a Hilbert space, and not merely a pre-Hilbert
space, there is an alternative and very useful criterion for an orthonormal se-
quence to be a basis: Let M be the set of all limits of ﬁnite linear combinations of
the φi. Any Cauchy sequence in M converges (in V ) since V is a Hilbert space,
and this limit belongs to M since it is itself a limit of ﬁnite linear combinations
of the φi (by the diagonal argument for example). Thus V = M ⊕M ⊥, and
the φi form a basis of M. So the φi form a basis of V if and only if M ⊥= {0}.
But this is the same as saying that no non-zero vector is orthogonal to all the
φi. So we have proved
Proposition 2.1.1 In a Hilbert space, the orthonormal set {φi} is a basis if
and only if no non-zero vector is orthogonal to all the φi.
2.2
Self-adjoint transformations.
We continue to let V denote a pre-Hilbert space. Let T be a linear transfor-
mation of V into itself. This means that for every v ∈V the vector Tv ∈V
is deﬁned and that Tv depends linearly on v :
T(av + bw) = aTv + bTw for
any two vectors v and w and any two complex numbers a and b. We recall
from linear algebra that a non-zero vector v is called an eigenvector of T if Tv
is a scalar times v, in other words if Tv = λv where the number λ is called the
corresponding eigenvalue.
A linear transformation T on V is called symmetric if for any pair of
elements v and w of V we have
(Tv, w) = (v, Tw).
Notice that if v is an eigenvector of a symmetric transformation T with
eigenvalue λ, then
λ(v, v) = (λv, v) = (Tv, v) = (v, Tv) = (v, λv) = λ(v, v),
so λ = λ. In other words, all eigenvalues of a symmetric transformation are
real.

52
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
We will let S = S(V ) denote the “unit sphere” of V , i.e. S denotes the set
of all φ ∈V such that ∥φ∥= 1. A linear transformation T is called bounded
if ∥Tφ∥is bounded as φ ranges over all of S. If T is bounded, we let
∥T∥:= max
φ∈S ∥Tφ∥.
Then
∥Tv∥≤∥T∥∥v∥
for all v ∈V . A linear transformation on a ﬁnite dimensional space is automat-
ically bounded, but not so for an inﬁnite dimensional space.
Also, for any linear transformation T, we will let N(T) denote the kernel of
T, so
N(T) = {v ∈V |Tv = 0}
and R(T) denote the range of T, so
R(T) := {v|v = Tw for some w ∈V }.
Both N(T) and R(T) are linear subspaces of V .
For bounded transformations, the phrase “self-adjoint” is synonymous with
“symmetric”.
Later on we will need to study non-bounded (not everywhere
deﬁned) symmetric transformations, and then a rather subtle and important
distinction will be made between self-adjoint transformations and those which
are merely symmetric.
But for the rest of this section we will only be con-
sidering bounded linear transformations, and so we will freely use the phrase
“self-adjoint”, and (usually) drop the adjective “bounded” since all our trans-
formations will be assumed to be bounded.
We denote the set of all (bounded) self-adjoint transformations by A, or by
A(V ) if we need to make V explicit.
2.2.1
Non-negative self-adjoint transformations.
If T is a self-adjoint transformation, then
(Tv, v) = (v, Tv) = (Tv, v)
so (Tv, v) is always a real number. More generally, for any pair of elements v
and w,
(Tv, w) = (Tw, v).
Since (Tv, w) depends linearly on v for ﬁxed w, we see that the rule which
assigns to every pair of elements v and w the number (Tv, w) satisﬁes the ﬁrst
two conditions in our deﬁnition of a semi-scalar product. Since (Tv, v) might
be negative, condition 3. of the deﬁnition need not be satisﬁed. This leads to
the following deﬁnition:
A self-adjoint transformation T is called non-negative if
(Tv, v) ≥0
∀v ∈V.

2.2. SELF-ADJOINT TRANSFORMATIONS.
53
So if T is a non-negative self-adjoint transformation, then the rule which
assigns to every pair of elements v and w the number (Tv, w) is a semi-scalar
product to which we may apply the Cauchy-Schwartz inequality and conclude
that
|(Tv, w)| ≤(Tv, v)
1
2 (Tw, w)
1
2 .
Now let us assume in addition that T is bounded with norm ∥T∥. Let us take
w = Tv in the preceding inequality. We get
∥Tv∥2 = |(Tv, Tv)| ≤(Tv, v)
1
2 (TTv, Tv)
1
2 .
Now apply the Cauchy-Schwartz inequality for the original scalar product to
the last factor on the right:
(TTv, Tv)
1
2 ≤∥TTv∥
1
2 ∥Tv∥
1
2 ≤∥T∥
1
2 ∥Tv∥
1
2 ∥Tv∥
1
2 = ∥T∥
1
2 ∥Tv∥,
where we have used the deﬁning property of ∥T∥in the form ∥TTv∥≤∥T∥∥Tv∥.
Substituting this into the previous inequality we get
∥Tv∥2 ≤(Tv, v)
1
2 ∥T∥
1
2 ∥Tv∥.
If ∥Tv∦= 0 we may divide this inequality by ∥Tv∥to obtain
∥Tv∥≤∥T∥
1
2 (Tv, v)
1
2 .
(2.17)
This inequality is clearly true if ∥Tv∥= 0 and so holds in all cases.
We will make much use of this inequality. For example, it follows from (2.17)
that
(Tv, v) = 0
⇒Tv = 0.
(2.18)
It also follows from (2.17) that if we have a sequence {vn} of vectors with
(Tvn, vn) →0 then ∥Tvv∥→0 and so
(Tvn, vn) →0
⇒
Tvn →0.
(2.19)
Notice that if T is a bounded self adjoint transformation, not necessarily non-
negative, then rI −T is a non-negative self-adjoint transformation if r ≥∥T∥:
Indeed,
((rI −T)v, v) = r(v, v) −(Tv, v) ≥(r −∥T∥)(v, v) ≥0
since, by Cauchy-Schwartz,
(Tv, v) ≤|(Tv, v)| ≤∥Tv∥∥v∥≤∥T∥∥v∥2 = ∥T∥(v, v).
So we may apply the preceding results to rI −T.

54
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
2.3
Compact self-adjoint transformations.
We say that the self-adjoint transformation T is compact if it has the following
property: Given any sequence of elements un ∈S, we can choose a subsequence
uni such that the sequence Tuni converges to a limit in V .
Some remarks about this complicated looking deﬁnition: In case V is ﬁnite
dimensional, every linear transformation is bounded, hence the sequence Tun
lies in a bounded region of our ﬁnite dimensional space, and hence by the com-
pleteness property of the real (and hence complex) numbers, we can always ﬁnd
such a convergent subsequence. So in ﬁnite dimensions every T is compact.
More generally, the same argument shows that if R(T) is ﬁnite dimensional and
T is bounded then T is compact. So the deﬁnition is of interest essentially in
the case when R(T) is inﬁnite dimensional.
Also notice that if T is compact, then T is bounded. Otherwise we could
ﬁnd a sequence un of elements of S such that ∥Tun∥≥n and so no subsequence
Tuni can converge.
We now come to the key result which we will use over and over again:
Theorem 2.3.1 Let T be a compact self-adjoint operator. Then R(T) has an
orthonormal basis {φi} consisting of eigenvectors of T and if R(T) is inﬁnite
dimensional then the corresponding sequence {rn} of eigenvalues converges to
0.
Proof. We know that T is bounded. If T = 0 there is nothing to prove. So
assume that T ̸= 0 and let
m1 := ∥T∥> 0.
By the deﬁnition of ∥T∥we can ﬁnd a sequence of vectors un ∈S such that
∥Tun∥→∥T∥. By the deﬁnition of compactness we can ﬁnd a subsequence
of this sequence so that Tuni →w for some w ∈V . On the other hand, the
transformation T 2 is self-adjoint and bounded by ∥T∥2. Hence ∥T∥2I −T 2 is
non-negative, and
((∥T∥2I −T 2)un, un) = ∥T∥2 −∥Tun∥2 →0.
So we know from (2.19) that
∥T∥2un −T 2un →0.
Passing to the subsequence we have T 2uni = T(Tuni) →Tw and so
∥T∥2uni →Tw
or
uni →
1
m2
1
Tw.
Applying T to this we get
Tuni →
1
m2
1
T 2w

2.3. COMPACT SELF-ADJOINT TRANSFORMATIONS.
55
or
T 2w = m2
1w.
Also ∥w∥= ∥T∥= m1 ̸= 0. So w ̸= 0. So w is an eigenvector of T 2 with
eigenvalue m2
1. We have
0 = (T 2 −m2
1)w = (T + m1)(T −m1)w.
If (T −m1)w = 0, then w is an eigenvector of T with eigenvalue m1 and we
normalize by setting
φ1 :=
1
∥w∥w.
Then ∥φ1∥= 1 and
Tφ1 = m1φ1.
If (T −m1)w ̸= 0 then y := (T −m1)w is an eigenvector of T with eigenvalue
−m1 and again we normalize by setting
φ1 :=
1
∥y∥y.
So we have found a unit vector φ1 ∈R(T) which is an eigenvector of T with
eigenvalue r1 = ±m1.
Now let
V2 := φ⊥
1 .
If (w, φ1) = 0, then
(Tw, φ1) = (w, Tφ1) = r1(w, φ1) = 0.
In other words,
T(V2) ⊂V2
and we can consider the linear transformation T restricted to V2 which is again
compact. If we let m2 denote the norm of the linear transformation T when
restricted to V2 then m2 ≤m1 and we can apply the preceding procedure to
ﬁnd a unit eigenvector φ2 with eigenvalue ±m2.
We proceed inductively, letting
Vn := {φ1, . . . , φn−1}⊥
and ﬁnd an eigenvector φn of T restricted to Vn with eigenvalue ±mn ̸= 0 if the
restriction of T to Vn is not zero. So there are two alternatives:
• after some ﬁnite stage the restriction of T to Vn is zero. In this case R(T)
is ﬁnite dimensional with orthonormal basis φ1, . . . , φn−1. Or
• The process continues indeﬁnitely so that at each stage the restriction of
T to Vn is not zero and we get an inﬁnite sequence of eigenvectors and
eigenvalues ri with |ri| ≥|ri+1|.

56
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
The ﬁrst case is one of the alternatives in the theorem, so we need to look at
the second alternative.
We ﬁrst prove that |rn| →0. If not, there is some c > 0 such that |rn| ≥c for
all n (since the |rn| are decreasing). If i ̸= j,then by the Pythagorean theorem
we have
∥Tφi −Tφj∥2 = ∥riφi −rjφj∥2 = r2
i ∥φi∥2 + r2
j∥φj∥2.
Since ∥φi∥= ∥φj| = 1 this gives
∥Tφi −Tφj∥2 = r2
i + r2
j ≥2c2.
Hence no subsequence of the Tφi can converge, since all these vectors are at
least a distance c
√
2 apart. This contradicts the compactness of T.
To complete the proof of the theorem we must show that the φi form a basis
of R(T). So if w = Tv we must show that the Fourier series of w with respect
to the φi converges to w. We begin with the Fourier coeﬃcients of v relative to
the φi which are given by
an = (v, φn).
Then the Fourier coeﬃcients of w are given by
bi = (w, φi) = (Tv, φi) = (v, Tφi) = (v, riφi) = riai.
So
w −
n
X
i=1
biφi = Tv −
n
X
i=1
airiφi = T(v −
n
X
i=1
aiφi).
Now v −Pn
i=1 aiφi is orthogonal to φ1, . . . , φn and hence belongs to Vn+1. So
∥T(v −
n
X
i=1
aiφi)∥≤|rn+1|∥(v −
n
X
i=1
aiφi)∥.
By the Pythagorean theorem,
∥(v −
n
X
i=1
aiφi)∥≤∥v∥.
Putting the two previous inequalities together we get
∥w −
n
X
i=1
biφi∥= ∥T(v −
n
X
i=1
aiφi)∥≤|rn+1|∥v∥→0.
This proves that the Fourier series of w converges to w concluding the proof of
the theorem.
The “converse” of the above result is easy. Here is a version: Suppose that
H is a Hilbert space with an orthonormal basis {φi} consisting of eigenvectors

2.4. FOURIER’S FOURIER SERIES.
57
of an operator T, so Tφi = λiφi, and suppose that λi →0 as i →∞. Then T
is compact. Indeed, for each j we can ﬁnd an N = N(j) such that
|λr| < 1
j
∀r > N(j).
We can then let Hj denote the closed subspace spanned by all the eigenvectors
φr, r > N(j), so that
H = H⊥
j ⊕Hj
is an orthogonal decomposition and H⊥
j is ﬁnite dimensional, in fact is spanned
the ﬁrst N(j) eigenvectors of T.
Now let {ui} be a sequence of vectors with ∥ui∥≤1 say. We decompose
each element as
ui = u′
i ⊕u′′
i ,
u′
i ∈H⊥
1 , u′′
i ∈Hj.
We can choose a subsequence so that u′
ik converges, because they all belong to
a ﬁnite dimensional space, and hence so does Tuik since T is bounded. We can
decompose every element of this subsequence into its H⊥
2 and H2 components,
and choose a subsequence so that the ﬁrst component converges. Proceeding in
this way, and then using the Cantor diagonal trick of choosing the k-th term of
the k-th selected subsequence, we have found a subsequence such that for any
ﬁxed j, the (now relabeled) subsequence, the H⊥
j component of Tuj converges.
But the Hj component of Tuj has norm less than 1/j, and so the sequence
converges by the triangle inequality.
2.4
Fourier’s Fourier series.
We want to apply the theorem about compact self-adjoint operators that we
proved in the preceding section to conclude that the functions einx form an
orthonormal basis of the space C(T).
In fact, a direct proof of this fact is
elementary, using integration by parts. So we will pause to given this direct
proof. Then we will go back and give a (more complicated) proof of the same
fact using our theorem on compact operators. The reason for giving the more
complicated proof is that it extends to far more general situations.
2.4.1
Proof by integration by parts.
We have let C(T) denote the space of continuous functions on the real line which
are periodic with period 2π. We will let C1(T) denote the space of periodic
functions which have a continuous ﬁrst derivative (necessarily periodic) and by
C2(T) the space of periodic functions with two continuous derivatives. If f and
g both belong to C1(T) then integration by parts gives
1
2π
Z π
−π
f ′gdx = −1
2π
Z π
−π
fg′dx

58
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
since the boundary terms, which normally arise in the integration by parts
formula, cancel, due to the periodicity of f and g. If we take g = einx/(in), n ̸= 0
the integral on the right hand side of this equation is the Fourier coeﬃcient:
cn = 1
2π
Z π
−π
f(x)e−inxdx.
We thus obtain
cn = 1
in
1
2π
Z π
−π
f ′(x)e−inxdx
so, for n ̸= 0,
|cn| ≤A
n
where A := 1
2π
Z π
−π
|f ′(x)|dx
is a constant independent of n (but depending on f).
If f ∈C2(T) we can take g(x) = −einx/n2 and integrate by parts twice. We
conclude that (for n ̸= 0)
|cn| ≤B
n2
where B := 1
2π
Z π
−π
|f ′′(x)|2
is again independent of n. But this proves that the Fourier series of f,
X
cneinx
converges uniformly and absolutely for and f ∈C2(T). The limit of this series
is therefore some continuous periodic function. We must prove that this limit
equals f. So we must prove that at each point f
X
cneiny →f(y).
Replacing f(x) by f(x−y) it is enough to prove this formula for the case y = 0.
So we must prove that for any f ∈C2(T) we have
lim
N,M→∞
M
X
−N
cn →f(0).
Write f(x) = (f(x) −f(0)) + f(0). The Fourier coeﬃcients of any constant
function c all vanish except for the c0 term which equals c. So the above limit
is trivially true when f is a constant. Hence, in proving the above formula, it is
enough to prove it under the additional assumption that f(0) = 0, and we need
to prove that in this case
lim
N,M→∞(c−N + c−N+1 + · · · + cM) →0.
The expression in parenthesis is
1
2π
Z π
−π
f(x)gN,M(x)dx

2.4. FOURIER’S FOURIER SERIES.
59
where
gN,M(x) = e−iNx+e−i(N−1)x+· · ·+eiMx = e−iNx 
1 + eix + · · · + ei(M+N)x
=
e−iNx 1 −ei(M+N+1)x
1 −eix
= e−iNx −ei(M+1)x
1 −eix
,
x ̸= 0
where we have used the formula for a geometric sum. By l’Hˆopital’s rule, this
extends continuously to the value M + N + 1 for x = 0. Now f(0) = 0, and
since f has two continuous derivatives, the function
h(x) :=
f(x)
1 −e−ix
deﬁned for x ̸= 0 (or any multiple of 2π) extends, by l’Hˆopital’s rule, to a func-
tion deﬁned at all values, and which is continuously diﬀerentiable and periodic.
Hence the limit we are computing is
1
2π
Z π
−π
h(x)eiNxdx −1
2π
Z π
−π
h(x)e−i(M+1)xdx
and we know that each of these terms tends to zero.
We have thus proved that the Fourier series of any twice diﬀerentiable peri-
odic function converges uniformly and absolutely to that function. If we consider
the space C2(T) with our usual scalar product
(f, g) = 1
2π
Z π
−π
fgdx
then the functions einx are dense in this space, since uniform convergence implies
convergence in the ∥∥norm associated to ( , ). So, on general principles, Bessel’s
inequality and Parseval’s equation hold.
It is not true in general that the Fourier series of a continuous function
converges uniformly to that function (or converges at all in the sense of uniform
convergence). However it is true that we do have convergence in the L2 norm,
i.e. the Hilbert space ∥∥norm on C(T). To prove this, we need only prove that
the exponential functions einx are dense, and since they are dense in C2(T), it is
enough to prove that C2(T) is dense in C(T). For this, let φ be a function deﬁned
on the line with at least two continuous bounded derivatives with φ(0) = 1 and
of total integral equal to one and which vanishes rapidly at inﬁnity. A favorite
is the Gauss normal function
φ(x) :=
1
√
2π e−x2/2
Equally well, we could take φ to be a function which actually vanishes outside
of some neighborhood of the origin. Let
φt(x) := 1
t φ
x
t

.

60
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
As t →0 the function φt becomes more and more concentrated about the origin,
but still has total integral one. Hence, for any bounded continuous function f,
the function φt ⋆f deﬁned by
(φt ⋆f)(x) :=
Z ∞
−∞
f(x −y)φt(y)dy =
Z ∞
−∞
f(u)φt(x −u)du.
satisﬁes φt ⋆f →f uniformly on any ﬁnite interval. From the rightmost expres-
sion for φt ⋆f above we see that φt ⋆f has two continuous derivatives. From
the ﬁrst expression we see that φt ⋆f is periodic if f is. This proves that C2(T)
is dense in C(T). We have thus proved convergence in the L2 norm.
2.4.2
Relation to the operator
d
dx.
Each of the functions einxis an eigenvector of the operator
D = d
dx
in that
D
 einx
= ineinx.
So they are also eigenvalues of the operator D2 with eigenvalues −n2. Also, on
the space of twice diﬀerentiable periodic functions the operator D2 satisﬁes
(D2f, g) = 1
2π
Z π
−π
f ′′(x)g(x)dx = f ′(x)g(x)

π
−π −1
2π
Z π
−π
f ′(x)g′(x)dx
by integration by parts. Since f ′ and g are assumed to be periodic, the end
point terms cancel, and integration by parts once more shows that
(D2f, g) = (f, D2g) = −(f ′, g′).
But of course D and certainly D2 is not deﬁned on C(T) since some of the func-
tions belonging to this space are not diﬀerentiable. Furthermore, the eigenvalues
of D2 are tending to inﬁnity rather than to zero. So somehow the operator D2
must be replaced with something like its inverse. In fact, we will work with the
inverse of D2 −1, but ﬁrst some preliminaries.
We will let C2([−π, π]) denote the functions deﬁned on [−π.π] and twice dif-
ferentiable there, with continuous second derivatives up to the boundary. We
denote by C([−π, π]) the space of functions deﬁned on [−π, π] which are continu-
ous up to the boundary. We can regard C(T) as the subspace of C([−π, π]) con-
sisting of those functions which satisfy the boundary conditions f(π) = f(−π)
(and then extended to the whole line by periodicity).
We regard C([−π, π]) as a pre-Hilbert space with the same scalar product
that we have been using:
(f, g) = 1
2π
Z π
−π
f(x)g(x)dx.

2.4. FOURIER’S FOURIER SERIES.
61
If we can show that every element of C([−π, π]) is a sum of its Fourier series
(in the pre-Hilbert space sense) then the same will be true for C(T). So we will
work with C([−π, π]).
We can consider the operator D2 −1 as a linear map
D2 −1 : C2([−π, π]) →C([−π, π]).
This map is surjective, meaning that given any continuous function g we can
ﬁnd a twice diﬀerentiable function f satisfying the diﬀerential equation
f ′′ −f = g.
In fact we can ﬁnd a whole two dimensional family of solutions because we can
add any solution of the homogeneous equation
h′′ −h = 0
to f and still obtain a solution. We could write down an explicit solution for the
equation f ′′ −f = g, but we will not need to. It is enough for us to know that
the solution exists, which follows from the general theory of ordinary diﬀerential
equations.
The general solution of the homogeneous equation is given by
h(x) = aex + be−x.
Let
M ⊂C2([−π, π])
be the subspace consisting of those functions which satisfy the “periodic bound-
ary conditions”
f(π) = f(−π),
f ′(π) = f ′(−π).
Given any f we can always ﬁnd a solution of the homogeneous equation such
that f −h ∈M. Indeed, we need to choose the complex numbers a and b such
that if h is as given above, then
h(π) −h(−π) = f(π) −f(−π), and h′(π) −h′(−π) = f ′(π) −f ′(−π).
Collecting coeﬃcients and denoting the right hand side of these equations by c
and d we get the linear equations
(eπ −e−π)(a −b) = c, (eπ −e−π)(a + b) = d
which has a unique solution.
So there exists a unique operator
T : C([−π, π]) →M
with the property that
(D2 −I) ◦T = I.

62
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
We will prove that
T
is self adjoint and compact.
(2.20)
Once we will have proved this fact, then we know every element of M can
be expanded in terms of a series consisting of eigenvectors of T with non-zero
eigenvalues. But if
Tw = λw
then
D2w = (D2 −I)w + w = 1
λ[(D2 −I) ◦T]w + w =
 1
λ + 1

w.
So w must be an eigenvector of D2; it must satisfy
w′′ = µw.
So if µ = 0 then w = a constant is a solution.
If µ = r2 > 0 then w is
a linear combination of erx and e−rx and as we showed above, no non-zero
such combination can belong to M. If µ = −r2 then the solution is a linear
combination of eirx and e−irx and the above argument shows that r must be
such that eirπ = e−irπ so r = n is an integer.
Thus (2.20) will show that the einx are a basis of M, and a little more
work that we will do at the end will show that they are in fact also a basis of
C([−π, π]). But ﬁrst let us work on (2.20).
It is easy to see that T is self adjoint. Indeed, let f = Tu and g = Tv so
that f and g are in M and
(u, Tv) = ([D2 −1]f, g) = −(f ′, g′) −(f, g) = (f, [D2 −1]g) = (Tu, v)
where we have used integration by parts and the boundary conditions deﬁning
M for the two middle equalities.
2.4.3
G˚arding’s inequality, special case.
We now turn to the compactness. We have already veriﬁed that for any f ∈M
we have
([D2 −1]f, f) = −(f ′, f ′) −(f, f).
Taking absolute values we get
∥f ′∥2 + ∥f∥2 ≤|([D2 −1]f, f)|.
(2.21)
(We actually get equality here, the more general version of this that we will
develop later will be an inequality.)
Let u = [D2 −1]f and use the Cauchy-Schwartz inequality
|([D2 −1]f, f)| = |(u, f)| ≤∥u∥∥f∥

2.4. FOURIER’S FOURIER SERIES.
63
on the right hand side of (2.21) to conclude that
∥f∥2 ≤∥u∥∥f∥
or
∥f∥≤∥u∥.
Use (2.21) again to conclude that
∥f ′∥2 ≤∥u∥∥f∥≤∥u∥2
by the preceding inequality. We have f = Tu, and let us now suppose that u
lies on the unit sphere i.e. that ∥u∥= 1. Then we have proved that
∥f∥≤1,
and
∥f ′∥≤1.
(2.22)
We wish to show that from any sequence of functions satisfying these two condi-
tions we can extract a subsequence which converges. Here convergence means,
of course, with respect to the norm given by
∥f∥2 = 1
2π
Z π
−π
|f(x)|2dx.
In fact, we will prove something stronger: that given any sequence of functions
satisfying (2.22) we can ﬁnd a subsequence which converges in the uniform norm
∥f∥∞:=
max
x∈[−π,π] |f(x)|.
Notice that
∥f∥=
 1
2π
Z π
−π
|f(x)|2dx
 1
2
≤
 1
2π
Z π
−π
(∥f∥∞)2dx
 1
2
= ∥f∥∞
so convergence in the uniform norm implies convergence in the norm we have
been using.
To prove our result, notice that for any π ≤a < b ≤π we have
|f(b) −f(a)| =

Z b
a
f ′(x)dx
 ≤
Z b
a
|f ′(x)|dx = 2π(|f ′|, 1[a,b])
where 1[a,b] is the function which is one on [a, b] and zero elsewhere. Apply
Cauchy-Schwartz to conclude that
|(|f ′|, 1[a,b])| ≤∥|f ′| ∥· ∥1[a,b]∥.
But
∥1[a,b]∥2 = 1
2π |b −a|
and
∥|f ′|∥= ∥f ′∥≤1.

64
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
We conclude that
|f(b) −f(a)| ≤(2π)
1
2 |b −a|
1
2 .
(2.23)
In this inequality, let us take b to be a point where |f| takes on its maximum
value, so that |f(b)| = ∥f∥∞. Let a be a point where |f| takes on its minimum
value. (If necessary interchange the role of a and b to arrange that a < b or
observe that the condition a < b was not needed in the above proof.) Then
(2.23) implies that
∥f∥∞−min |f| ≤(2π)
1
2 |b −a|
1
2 .
But
1 ≥∥f∥=
 1
2π
Z π
−π
|f|2(x)dx
 1
2
≥
 1
2π
Z π
−π
(min |f|)2dx
 1
2
= min |f|
and |b −a| ≤2π so
∥f∥∞≤1 + 2π.
Thus the values of all the f ∈T[S] are all uniformly bounded - (they take values
in a circle of radius 1 + 2π) and they are equicontinuous in that (2.23) holds.
This is enough to guarantee that out of every sequence of such f we can choose
a uniformly convergent subsequence.
(We recall how the proof of this goes: Since all the values of all the f are
bounded, at any point we can choose a subsequence so that the values of the
f at that point converge, and, by passing to a succession of subsequences (and
passing to a diagonal), we can arrange that this holds at any countable set of
points. In particular, we may choose say the rational points in [−π, π]. Suppose
that fn is this subsequence. We claim that (2.23) then implies that the fn form
a Cauchy sequence in the uniform norm and hence converge in the uniform norm
to some continuous function. Indeed, for any ϵ choose δ such that
(2π)
1
2 δ
1
2 < 1
3ϵ,
choose a ﬁnite number of rational points which are within δ distance of any
point of [−π, π] and choose N suﬃciently large that |fi −fj| < 1
3ϵ at each of
these points, r. when i and j are ≥N. Then at any x ∈[−π, π]
|fi(x) −fj(x)| ≤|fi(x) −fi(r)| + |fj(x) −fj(r)| + |fi(r) −fj(r)| ≤ϵ
since we can choose r such that that the ﬁrst two and hence all of the three
terms is ≤1
3ϵ.)
2.5
The Heisenberg uncertainty principle.
In this section we show how the arguments leading to the Cauchy-Schwartz in-
equality give one of the most important discoveries of twentieth century physics,
the Heisenberg uncertainty principle.

2.5. THE HEISENBERG UNCERTAINTY PRINCIPLE.
65
Let V be a pre-Hilbert space, and S denote the unit sphere in V . If φ and ψ
are two unit vectors (i.e. elements of S) their scalar product (φ, ψ) is a complex
number with 0 ≤|(φ, ψ)|2 ≤1. In quantum mechanics, this number is taken as
a probability. Although in the “real world” V is usually inﬁnite dimensional,
we will warm up by considering the case where V is ﬁnite dimensional.
Given a φ ∈S and an orthonormal basis φ1, . . . , φn of V , we have
1 = ∥φ∥2 = |(φ, φ1)|2 + · · · + |(φ, φn|2.
The says that the various probabilities |(φ, φi)|2 add up to one. We recall some
language from elementary probability theory: Suppose we have an experiment
resulting in a ﬁnite number of measured numerical outcomes λi, each with prob-
ability pi of occurring. Then the mean ⟨λ⟩is deﬁned by
⟨λ⟩:= λ1p1 + · · · + λnpn
and its variance (∆λ)2
(∆λ)2 := (λ1 −⟨λ⟩)2p1 + · · · + (λn −⟨λ⟩)2pn
and an immediate computation shows that
(∆λ)2 = ⟨λ2⟩−⟨λ⟩2.
The square root ∆λ of the variance is called the standard deviation. The vari-
ance (or the standard deviation) measures the “spread” of the possible values of
λ. To understand its meaning we have Chebychev’s inequality which estimates
the probability that λk can deviate from ⟨λ⟩by as much as r∆λ for any posi-
tive number r. Chebychev’s inequality says that this probability is ≤1/r2. In
symbols
Prob (|λk −⟨λ⟩| ≥r∆λ) ≤1
r2 .
Indeed, the probability on the left is the sum of all the pk such that |λk −⟨λ⟩| ≥
r∆. Denoting this sum by P
r we have
X
rpk ≤
X
rpk
(λ −⟨λ⟩)2
r2(∆λ)2
≤
≤
X
all k
pk
(λ −⟨λ⟩)2
r2(∆λ)2
=
1
r2(∆λ)2
X
all k
(λ −⟨λ⟩)2pk = 1
r2 .
Replacing λi by λi + c does not change the variance.
Now suppose that A is a self-adjoint operator on V , that the λi are the
eigenvalues of A with eigenvectors φi constituting an orthonormal basis, and
that the pi = |(φ, φi|2 as above.
1. Show that ⟨λ⟩= (Aφ, φ) and that (∆λ)2 = (A2φ, φ) −(Aφ, φ)2.

66
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
We will write the expression (Aφ, φ) as ⟨A⟩φ, In quantum mechanics a unit
vector is called a state and a self-adjoint operator is called an observable
and the expression ⟨A⟩φ is called the expectation of the observable A in the
state φ. Similarly we denote
 (A2φ, φ) −(Aφ, φ)21/2 by ∆φA. It is called the
uncertainty of the observable A in the state φ. Notice that
(∆φA)2 = ⟨(A −⟨A⟩I)2⟩φ
where I denotes the identity operator. Indeed
((A −(Aφ, φ)I)2 = A2 −2(Aφ, φ)A + (Aφ, φ)2I
so
⟨(A −⟨A⟩φ)2⟩φ = (A2φ, φ) −2⟨A⟩2
φ + ⟨A⟩2
φ = ⟨A2⟩φ −⟨A⟩2
φ.
When the state φ is ﬁxed in the course of discussion, we will drop the sub-
script φ and write ⟨A⟩and ∆A instead of ⟨A⟩φ and ∆φA. For example, we
would write the previous result as
∆A = ⟨(A −⟨A⟩I)2⟩.
If A and B are operators we let [A, B] denote the commutator:
[A, B] := AB −BA.
Notice that [A, B] = −[B, A] and [I, B] = 0 for any B. So if A and B are
self adjoint, so is i[A, B] and replacing A by A −⟨A⟩I and B by B −⟨B⟩I does
not change ∆A, ∆B or i[A, B].
The uncertainty principle says that for any two observables A and B we
have
(∆A)(∆B) ≥1
2|⟨i[A, B]⟩|q.
Proof. Set A1 := A −⟨A⟩,
B1 := B −⟨B⟩so that
[A1, B1] = [A, B].
Let
ψ := A1φ + ixB1φ.
Then
(ψ, ψ) = (∆A)2 −x⟨i[A, B]⟩+ (∆B)2.
Since (ψ, ψ) ≥0 for all x this implies that (b2 ≤4ac) that
⟨i[A, B]⟩2 ≤4(∆A)2(∆B)2,
and taking square roots gives the result.
The purpose of the next few sections is to provide a vast generalization of
the results we obtained for the operator D2. We will prove the corresponding
results for any “elliptic” diﬀerential operator (deﬁnitions below).

2.6. THE SOBOLEV SPACES.
67
I plan to study diﬀerential operators acting on vector bundles over manifolds.
But it requires some eﬀort to set things up, and I want to get to the key analytic
ideas which are essentially repeated applications of integration by parts. So I will
start with elliptic operators L acting on functions on the torus T = Tn, where
there are no boundary terms when we integrate by parts. Then an immediate
extension gives the result for elliptic operators on functions on manifolds, and
also for boundary value problems such as the Dirichlet problem.
The treatment here rather slavishly follows the treatment by Bers and Schechter
in Partial Diﬀerential Equations by Bers, John and Schechter AMS (1964).
2.6
The Sobolev Spaces.
Recall that T now stands for the n-dimensional torus. Let P = P(T) denote
the space of trigonometric polynomials. These are functions on the torus of the
form
u(x) =
X
aℓeiℓ·x
where
ℓ= (ℓ1, . . . , ℓn)
is an n-tuplet of integers and the sum is ﬁnite. For each integer t (positive, zero
or negative) we introduce the scalar product
(u, v)t :=
X
ℓ
(1 + ℓ· ℓ)taℓbℓ.
(2.24)
For t = 0 this is the scalar product
(u, v)0 =
1
(2π)n
Z
T
u(x)v(x)dx.
This diﬀers by a factor of (2π)−n from the scalar product that is used by Bers
and Schecter. We will denote the norm corresponding to the scalar product
( , )s by ∥∥s.
If
∆:= −

∂2
∂(x1)2 + · · · +
∂2
∂(xn)2

the operator (1 + ∆) satisﬁes
(1 + ∆)u =
X
(1 + ℓ· ℓ)aℓeiℓ·x
and so
((1 + ∆)tu, v)s = (u, (1 + ∆)tv)s = (u, v)s+t
and
∥(1 + ∆)tu∥s = ∥u∥s+2t.
(2.25)

68
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
We then get the “generalized Cauchy-Schwartz inequality”
|(u, v)s| ≤∥u∥s+t∥v∥s−t
(2.26)
for any t, as a consequence of the usual Cauchy-Schwartz inequality. Indeed,
X
ℓ
(1 + ℓ· ℓ)saℓbℓ
=
X
ℓ
(1 + ℓ· ℓ)
s+t
2 aℓ(1 + ℓ· ℓ)
s−t
2 bℓ
=
((1 + ∆)
s+t
2 u, (1 + ∆)
s−t
2 v)0
≤
∥(1 + ∆)
s+t
2 u∥0∥(1 + ∆)
s−t
2 v∥0
=
∥u∥s+t∥v∥s−t.
The generalized Cauchy-Schwartz inequality reduces to the usual Cauchy-
Schwartz inequality when t = 0.
Clearly we have
∥u∥s ≤∥u∥t
if s ≤t.
If Dp denotes a partial derivative,
Dp =
∂|p|
∂(x1)p1 · · · ∂(xn)pm
then
Dpu =
X
(iℓ)paℓeiℓ·x.
In these equations we are using the following notations:
• If p = (p1, . . . , pn) is a vector with non-negative integer entries we set
|p| := p1 + · · · + pn.
• If ξ = (ξ1, . . . , ξn) is a (row) vector we set
ξp := ξp1
1 · ξp2
2 · · · ξpn
n
It is then clear that
∥Dpu∥t ≤∥u∥t+|p|
(2.27)
and similarly
∥u∥t ≤(constant depending on t)
X
|p|≤t
∥Dpu∥0
if t ≥0.
(2.28)
In particular,

2.6. THE SOBOLEV SPACES.
69
Proposition 2.6.1 The norms
u 7→∥u∥t
t ≥0 and
u 7→
X
|p|≤t
∥Dpu∥0
are equivalent.
We let Ht denote the completion of the space P with respect to the norm
∥∥t. Each Ht is a Hilbert space, and we have natural embeddings
Ht ,→Hs if s < t.
Equation (2.25) says that
(1 + ∆)t : Hs+2t →Hs
and is an isometry.
From the generalized Schwartz inequality we also have a natural pairing of
Ht with H−t given by the extension of ( , )0, so
|(u, v)0| ≤∥u∥t∥v∥−t.
(2.29)
In fact, this pairing allows us to identify H−t with the space of continuous linear
functions on Ht. Indeed, if φ is a continuous linear function on Ht the Riesz
representation theorem tells us that there is a w ∈Ht such that φ(u) = (u, w)t.
Set
v := (1 + ∆)tw.
Then
v ∈H−t
and
(u, v)0 = (u, (1 + ∆)tw)0 = (u, w)t = φ(u).
We record this fact as
H−t = (Ht)∗.
(2.30)
As an illustration of (2.30), observe that the series
X
ℓ
(1 + ℓ· ℓ)s
converges for
s < −n
2 .
This means that if deﬁne v by taking
bℓ≡1

70
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
then v ∈Hs for s < −n
2 . If u is given by u(x) = P
ℓaℓeiℓ·x is any trigonometric
polynomial, then
(u, v)0 =
X
aℓ= u(0).
So the natural pairing (2.29) allows us to extend the linear function sending
u 7→u(0) to all of Ht if t > n
2 . We can now give v its “true name”: it is the
Dirac “delta function” δ (on the torus) where
(u, δ)0 = u(0).
So δ ∈H−t for t > n
2 , and the preceding equation is usually written symbolically
as
1
(2π)n
Z
T
u(x)δ(x)dx = u(0);
but the true mathematical interpretation is as given above.
We set
H∞:=
\
Ht,
H−∞:=
[
Ht.
The space H0 is just L2(T), and we can think of the space Ht,
t > 0
as consisting of those functions having “generalized L2 derivatives up to order
t”. Certainly a function of class Ct belongs to Ht. With a loss of degree of
diﬀerentiability the converse is true:
Lemma 2.6.1 [Sobolev.]
If u ∈Ht and
t ≥
hn
2
i
+ k + 1
then u ∈Ck(T) and
sup
x∈T
|Dpu(x)| ≤const.∥u∥t
for |p| ≤k.
(2.31)
By applying the lemma to Dpu it is enough to prove the lemma for k = 0. So
we assume that u ∈Ht with t ≥[n/2] + 1. Then
(
X
|aℓ|)2 ≤
X
(1 + ℓ· ℓ)t|aℓ|2 X
(1 + ℓ· ℓ)−t < ∞,
since the series P(1 + ℓ· ℓ)−t converges for t ≥[n/2] + 1. So for this range of
t, the Fourier series for u converges absolutely and uniformly. The right hand
side of the above inequality gives the desired bound. QED
A distribution on Tn is a linear function T on C∞(Tn) with the continuity
condition that
⟨T, φk⟩→0
whenever
Dpφk →0

2.6. THE SOBOLEV SPACES.
71
uniformly for each ﬁxed p. If u ∈H−t we may deﬁne
⟨u, φ⟩:= (φ, u)0
and since C∞(T) is dense in Ht we may conclude
Lemma 2.6.2 H−t is the space of those distributions T which are continuous
in the ∥∥t norm, i.e. which satisfy
∥φk∥t →0
⇒⟨T, φk⟩→0.
We then obtain
Theorem 2.6.1 [Laurent Schwartz.] H−∞is the space of all distributions.
In other words, any distribution belongs to H−t for some t.
Proof. Suppose that T is a distribution that does not belong to any H−t. This
means that for any k > 0 we can ﬁnd a C∞function φk with
∥φk∥k < 1
k
and
|⟨T, φk⟩| ≥1.
But by Lemma 2.6.1 we know that ∥φk∥k < 1
k implies that Dpφk →0 uniformly
for any ﬁxed p contradicting the continuity property of T. QED
Suppose that φ is a C∞function on T. Multiplication by φ is clearly a
bounded operator on H0 = L2(T), and so it is also a bounded operator on
Ht,
t > 0 since we can expand Dp(φu) by applications of Leibnitz’s rule.
For t = −s < 0 we know by the generalized Cauchy Schwartz inequality that
∥φu∥t = sup |(v, φu)0|/∥v∥s = sup |(u, φv)|/∥v∥s ≤∥u∥t∥φv∥s/∥v∥s.
So in all cases we have
∥φu∥t ≤(const. depending on φ and t)∥u∥t.
(2.32)
Let
L =
X
|p|≤m
αp(x)Dp
be a diﬀerential operator of degree m with C∞coeﬃcients. Then it follows from
the above that
∥Lu∥t−m ≤constant∥u∥t
(2.33)
where the constant depends on L and t.
Lemma 2.6.3 [Rellich’s lemma.]
If s < t the embedding Ht ,→Hs is
compact.

72
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
Proof.
We must show that the image of the unit ball B of Ht in Hs can be
covered by ﬁnitely many balls of radius ϵ. Choose N so large that
(1 + ℓ· ℓ)(s−t)/2 < ϵ
2
when ℓ·ℓ> N. Let Zt be the subspace of Ht consisting of all u such that aℓ= 0
when ℓ· ℓ≤N. This is a space of ﬁnite codimension, and hence the unit ball
of Z⊥
t ⊂Ht can be covered by ﬁnitely many balls of radius ϵ
2. The space Z⊥
t
consists of all u such that aℓ= 0 when ℓ· ℓ> N. The image of Z⊥
t in Hs is the
orthogonal complement of the image of Zt. On the other hand, for u ∈B ∩Z
we have
∥u∥2
s ≤(1 + N)s−t∥u∥2
t ≤
 ϵ
2
2
.
So the image of B ∩Z is contained in a ball of radius ϵ
2. Every element of the
image of B can be written as a(n orthogonal) sum of an element in the image
of B ∩Z⊥
t and an element of B ∩Zt and so the image of B is covered by ﬁnitely
many balls of radius ϵ. QED
2.7
G˚arding’s inequality.
Let x, a, and b be positive numbers. Then
xa + x−b ≥1
because if x ≥1 the ﬁrst summand is ≥1 and if x ≤1 the second summand is
≥1. Setting x = ϵ1/aA gives
1 ≤ϵAa + ϵ−b/aA−b
if ϵ and A are positive. Suppose that t1 > s > t2 and we set a = t1−s, b = s−t2
and A = 1 + ℓ· ℓ. Then we get
(1 + ℓ· ℓ)s ≤ϵ(1 + ℓ· ℓ)t1 + ϵ−(s−t2)/(t1−s)(1 + ℓ· ℓ)t2
and therefore
∥u∥s ≤ϵ∥u∥t1 + ϵ−(s−t2)/(t1−s)∥u∥t2 if t1 > s > t2,
ϵ > 0
(2.34)
for all u ∈Ht1. This elementary inequality will be the key to several arguments
in this section where we will combine (2.34) with integration by parts.
A diﬀerential operator L = P
|p|≤m αp(x)Dp with real coeﬃcients and m
even is called elliptic if there is a constant c > 0 such that
(−1)m/2 X
|p|=m
ap(x)ξp ≥c(ξ · ξ)m/2.
(2.35)
In this inequality, the vector ξ is a “dummy variable”. (Its true invariant signif-
icance is that it is a covector, i.e. an element of the cotangent space at x.) The

2.7. G˚
ARDING’S INEQUALITY.
73
expression on the left of this inequality is called the symbol of the operator L.
It is a homogeneous polynomial of degree m in the variable ξ whose coeﬃcients
are functions of x. The symbol of L is sometimes written as σ(L) or σ(L)(x, ξ).
Another way of expressing condition (2.35) is to say that there is a positive
constant c such that
σ(L)(x, ξ) ≥c for all x and ξ such that ξ · ξ = 1.
We will assume until further notice that the operator L is elliptic and that
m is a positive even integer.
Theorem 2.7.1 [G˚arding’s inequality.] For every u ∈C∞(T) we have
(u, Lu)0 ≥c1∥u∥2
m/2 −c2∥u∥2
0
(2.36)
where c1 and c2 are constants depending on L.
Remark.
If u ∈Hm/2, then both sides of the inequality make sense, and we
can approximate u in the ∥∥m/2 norm by C∞functions. So once we prove the
theorem, we conclude that it is also true for all elements of Hm/2.
We will prove the theorem in stages:
1. When L is constant coeﬃcient and homogeneous.
2. When L is homogeneous and approximately constant.
3. When the L can have lower order terms but the homogeneous part of L
is approximately constant.
4. The general case.
Stage 1.
L = P
|p|=m αpDp where the αp are constants. Then
(u, Lu)0
=

X
aℓeiℓ·x,
X
ℓ

X
|p|=m
αp(iℓ)p

aℓeiℓ·x


0
≥
c
X
ℓ
(ℓ· ℓ)m/2|aℓ|2
by (2.35)
=
c
X
[1 + (ℓ· ℓ)m/2]|aℓ|2 −c∥u∥2
0
≥
cC∥u∥2
m/2 −c∥u∥0
where
C = sup
r≥0
1 + rm/2
(1 + r)m/2 .
This takes care of stage 1.

74
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
Stage 2. L = L0 + L1 where L0 is as in stage 1 and L1 = P
|p|=m βp(x)Dp and
max
p,x |βp(x)| < η,
where η suﬃciently small.
(How small will be determined very soon in the
course of the discussion.) We have
(u, L0u)0 ≥c′∥u∥2
m/2 −c∥u∥2
0
from stage 1.
We integrate (u, L1u)0 by parts m/2 times. There are no boundary terms
since we are on the torus. In integrating by parts some of the derivatives will
hit the coeﬃcients. Let us collect all the these terms as I2. The other terms we
collect as I1, so
I1 =
X Z
bp′+p′′Dp′uDp′′udx
where |p′| = |p′′| = m/2 and br = ±βr. We can estimate this sum by
|I1| ≤η · const.∥u∥2
m/2
and so will require that η · (const.) < c′.
The remaining terms give a sum of the form
I2 =
X Z
bp′qDp′uDqudx
where p′ ≤m/2, q′ < m/2 so we have
|I2| ≤const.∥u∥m
2 ∥u∥m
2 −1.
Now let us take
s = m
2 −1, t1 = m
2 , t2 = 0
in (2.34) which yields, for any ϵ > 0,
∥u∥m
2 −1 ≤ϵ∥u∥m
2 + ϵ−m/2∥u∥0.
Substituting this into the above estimate for I2 gives
|I2| ≤ϵ · const.∥u∥2
m/2 + ϵ−m/2const.∥u∥m/2∥u∥0.
For any positive numbers a, b and ζ the inequality (ζa−ζ−1b)2 ≥0 implies that
2ab ≤ζ2a2 + ζ−2b2. Taking ζ2 = ϵ
m
2 +1 we can replace the second term on the
right in the preceding estimate for |I2| by
ϵ−m−1 · const.∥u∥2
0
at the cost of enlarging the constant in front of ∥u∥2m
2 . We have thus established
that
|I1| ≤η · (const.)1∥u∥2
m/2

2.7. G˚
ARDING’S INEQUALITY.
75
where the constant depends only on m, and
|I2| ≤ϵ(const.)2∥u∥2
m/2 + ϵ−m−1const.∥u∥2
0
where the constants depend on L1 but ϵ is at our disposal. So if η(const.)1 < c′
and we then choose ϵ so that ϵ(const.)2 < c′ −η · (const.)1 we obtain G˚arding’s
inequality for this case.
Stage 3.
L = L0 + L1 + L2 where L0 and L1 are as in stage 2, and L2 is a
lower order operator. Here we integrate by parts and argue as in stage 2.
Stage 4, the general case.
Choose an open covering of T such that the
variation of each of the highest order coeﬃcients in each open set is less than
the η of stage 1. (Recall that this choice of η depended only on m and the c
that entered into the deﬁnition of ellipticity.) Thus, if v is a smooth function
supported in one of the sets of our cover, the action of L on v is the same as
the action of an operator as in case 3) on v, and so we may apply G˚arding’s
inequality. Choose a ﬁnite subcover and a partition of unity {φi} subordinate
to this cover. Write φi = ψ2
i (where we choose the φ so that the ψ are smooth).
So P ψ2
i ≡1. Now
(ψiu, L(ψiu))0 ≥c′′∥ψiu∥2
m/2 −const.∥ψiu∥2
0
where c′′ is a positive constant depending only on c, η, and on the lower order
terms in L. We have
(u, Lu)0 =
Z
(
X
ψ2
i u)Ludx =
X
(ψiu, Lψiu)0 + R
where R is an expression involving derivatives of the ψi and hence lower order
derivatives of u. These can be estimated as in case 2) above, and so we get
(u, Lu)0 ≥c′′′ X
∥ψiu∥2
m/2 −const.∥u∥2
0
(2.37)
since ∥ψiu∥0 ≤∥u∥0. Now ∥u∥m/2 is equivalent, as a norm, to P
p≤m/2 ∥Dpu∥0
as we veriﬁed in the preceding section. Also
X
∥Dp(ψiu)∥0 =
X
∥ψiDpu∥0 + R′
where R′ involves terms diﬀerentiating the ψ and so lower order derivatives of
u. Hence
X
∥ψiu∥2
m/2 ≥pos. const.∥u∥2
m/2 −const.∥u∥2
0
by the integration by parts argument again. Hence by (2.37)
(u, Lu)0 ≥c′′′ X
∥ψiu∥2
m/2 −const.∥u∥2
0
≥pos. const.∥u∥2
m/2 −const.∥u∥2
0

76
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
which is G˚arding’s inequality. QED
For the time being we will continue to study the case of the torus. But a
look ahead is in order. In this last step of the argument, where we applied the
partition of unity argument, we have really freed ourselves of the restriction of
being on the torus. Once we make the appropriate deﬁnitions, we will then
get G˚arding’s inequality for elliptic operators on manifolds. Furthermore, the
consequences we are about to draw from G˚arding’s inequality will be equally
valid in the more general setting.
2.8
Consequences of G˚arding’s inequality.
Proposition 2.8.1 For every integer t there is a constant c(t) = c(t, L) and a
positive number Λ = Λ(t, L) such that
∥u∥t ≤c(t)∥Lu + λu∥t−m
(2.38)
when
λ > Λ
for all smooth u, and hence for all u ∈Ht.
Proof.
Let s be some non-negative integer. We will ﬁrst prove (2.38) for
t = s + m
2 . We have
∥u∥t∥Lu + λu∥t−m = ∥u∥t∥Lu + λu∥s−m
2
= ∥u∥t∥(1 + ∆)sLu + λ(1 + ∆)su∥−s−m
2
≥(u, (1 + ∆)sLu + λ(1 + ∆)su)0
by the generalized Cauchy - Schwartz inequality (2.26).
The operator (1 + ∆)sL is elliptic of order m + 2s so (2.25) and G˚arding’s
inequality gives
(u, (1 + ∆)sLu + λ(1 + ∆)su)0 ≥c1∥u∥2
s+ m
2 −c2∥u∥2
0 + λ∥u∥2
s.
Since ∥u∥s ≥∥u∥0 we can combine the two previous inequalities to get
∥u∥t∥Lu + λu∥t−m ≥c1∥u∥2
t + (λ −c2)∥u∥2
0.
If λ > c2 we can drop the second term and divide by ∥u∥t to obtain (2.38).
We now prove the proposition for the case t = m
2 −s by the same sort of
argument: We have
∥u∥t∥Lu + λu∥−s−m
2 = ∥(1 + ∆)−su∥s+ m
2 ∥Lu + λu∥−s−m
2
≥((1 + ∆)−su, L(1 + ∆)s(1 + ∆)−su + λu)0.

2.8. CONSEQUENCES OF G˚
ARDING’S INEQUALITY.
77
Now use the fact that L(1 + ∆)s is elliptic and G˚arding’s inequality to continue
the above inequalities as
≥c1∥(1 + ∆)−su∥2
s+ m
2 −c2∥(1 + ∆)−su∥2
0 + λ∥u∥2
−s
= c1∥u∥2
t −c2∥u∥−2s + λ∥u∥2
−s ≥c1∥u∥2
t
if λ > c2. Again we may then divide by ∥u∥t to get the result. QED
The operator L + λI is a bounded operator from Ht to Ht−m (for any t).
Suppose we ﬁx t and choose λ so large that (2.38) holds. Then (2.38) says that
(L+λI) is invertible on its image, and bounded there with a bound independent
of λ > Λ, and this image is a closed subspace of Ht−m.
Let us show that this image is all of Ht−m for λ large enough. Suppose not,
which means that there is some w ∈Ht−m with
(w, Lu + λu)t−m = 0
for all u ∈Ht. We can write this last equation as
((1 + ∆)t−mw, Lu + λu)0 = 0.
Integration by parts gives the adjoint diﬀerential operator L∗characterized
by
(φ, Lψ)0 = (L∗φ, ψ)0
for all smooth functions φ and ψ, and by passing to the limit this holds for all
elements of Hr for r ≥m. The operator L∗has the same leading term as L and
hence is elliptic. So let us choose λ suﬃciently large that (2.38) holds for L∗as
well as for L. Now
0 =
 (1 + ∆)t−mw, Lu + λu

0 =
 L∗(1 + ∆)t−mw + λ(1 + ∆)t−mw, u

0
for all u ∈Ht which is dense in H0 so
L∗(1 + ∆)t−mw + λ(1 + ∆)t−mw = 0
and hence (by (2.38)) (1 + ∆)t−mw = 0 so w = 0. We have proved
Proposition 2.8.2 For every t and for λ large enough (depending on t) the
operator L + λI maps Ht bijectively onto Ht−m and (L + λI)−1 is bounded
independently of λ.
As an immediate application we get the important
Theorem 2.8.1 If u is a distribution and Lu ∈Hs then u ∈Hs+m.
Proof.
Write f = Lu. By Schwartz’s theorem, we know that u ∈Hk for some
k. So f + λu ∈Hmin(k,s) for any λ. Choosing λ large enough, we conclude that
u = (L + λI)−1(f + λu) ∈Hmin(k+m,s+m). If k + m < s + m we can repeat

78
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
the argument to conclude that u ∈Hmin(k+2m,s+m). we can keep going until
we conclude that u ∈Hs+m. QED
Notice as an immediate corollary that any solution of the homogeneous equa-
tion Lu = 0 is C∞.
We now obtain a second important consequence of Proposition 2.8.2. Choose
λ so large that the operators
(L + λI)−1
and
(L∗+ λI)−1
exist as operators from H0 →Hm. Follow these operators with the injection
ιm : Hm →H0 and set
M := ιm ◦(L + λI)−1,
M ∗:= ιm ◦(L∗+ λI)−1.
Since ιm is compact (Rellich’s lemma) and the composite of a compact operator
with a bounded operator is compact, we conclude
Theorem 2.8.2 The operators M and M ∗are compact.
Suppose that L = L∗. (This is usually expressed by saying that L is “for-
mally self-adjoint”. More on this terminology will come later.) This implies
that M = M ∗. In other words, M is a compact self adjoint operator, and we
can apply Theorem 2.3.1 to conclude that eigenvectors of M form a basis of
R(M) and that the corresponding eigenvalues tend to zero. Prop 2.8.2 says
that R(M) is the same as ιm(Hm) which is dense in H0 = L2(T). We con-
clude that the eigenvectors of M form a basis of L2(T).
If Mu = ru then
u = (L + λI)Mu = rLu + λru so u is an eigenvector of L with eigenvalue
1 −rλ
r
.
We conclude that the eigenvectors of L are a basis of H0.
We claim that
only ﬁnitely many of these eigenvalues of L can be negative. Indeed, since we
know that the eigenvalues rn of M approach zero, the numerator in the above
expression is positive, for large enough n, and hence if there were inﬁnitely
many negative eigenvalues µk, they would have to correspond to negative rk
and so these µk →−∞. But taking sk = −µk as the λ in (2.38) in Prop. 2.8.1
we conclude that u = 0, if Lu = µku if k is large enough, contradicting the
deﬁnition of an eigenvector. So all but a ﬁnite number of the rn are positive,
and these tend to zero. To summarize:
Theorem 2.8.3 The eigenvectors of L are C∞functions which form a basis of
H0. Only ﬁnitely many of the eigenvalues µk of L are negative and µn →∞as
n →∞.
It is easy to extend the results obtained above for the torus in two directions.
One is to consider functions deﬁned in a domain = bounded open set G of Rn
and the other is to consider functions deﬁned on a compact manifold. In both
cases a few elementary tricks allow us to reduce to the torus case. We sketch
what is involved for the manifold case.

2.9. EXTENSION OF THE BASIC LEMMAS TO MANIFOLDS.
79
2.9
Extension of the basic lemmas to manifolds.
Let E →M be a vector bundle over a manifold. We assume that M is equipped
with a density which we shall denote by |dx| and that E is equipped with a
positive deﬁnite (smoothly varying) scalar product, so that we can deﬁne the
L2 norm of a smooth section s of E of compact support:
∥s∥2
0 :=
Z
M
|s|2(x)|dx|.
Suppose for the rest of this section that M is compact. Let {Ui} be a ﬁnite cover
of M by coordinate neighborhoods over which E has a given trivialization, and
ρi a partition of unity subordinate to this cover. Let φi be a diﬀeomorphism or
Ui with an open subset of Tn where n is the dimension of M. Then if s is a
smooth section of E, we can think of (ρis)◦φ−1
i
as an Rm or Cm valued function
on Tn, and consider the sum of the ∥·∥k norms applied to each component. We
shall continue to denote this sum by ∥ρif ◦φ−1
i ∥k and then deﬁne
∥f∥k :=
X
i
∥ρif ◦φ−1
i ∥k
where the norms on the right are in the norms on the torus.
These norms
depend on the trivializations and on the partitions of unity. But any two norms
are equivalent, and the ∥∥0 norm is equivalent to the “intrinsic” L2 norm deﬁned
above. We deﬁne the Sobolev spaces Wk to be the completion of the space of
smooth sections of E relative to the norm ∥∥k for k ≥0, and these spaces are
well deﬁned as topological vector spaces independently of the choices. Since
Sobolev’s lemma holds locally, it goes through unchanged. Similarly Rellich’s
lemma: if sn is a sequence of elements of Wℓwhich is bounded in the ∥∥ℓnorm
for ℓ> k, then each of the elements ρisn ◦φ−1
i
belong to Hℓon the torus, and
are bounded in the ∥∥ℓnorm, hence we can select a subsequence of ρ1sn ◦φ−1
1
which converges in Hk, then a subsubsequence such that ρisn ◦φ−1
i
for i = 1, 2
converge etc. arriving at a subsequence of sn which converges in Wk.
A diﬀerential operator L mapping sections of E into sections of E is an
operator whose local expression (in terms of a trivialization and a coordinate
chart) has the form
Ls =
X
|p|≤m
αp(x)Dps
Here the ap are linear maps (or matrices if our trivializations are in terms of
Rm).
Under changes of coordinates and trivializations the change in the coeﬃcients
are rather complicated, but the symbol of the diﬀerential operator
σ(L)(ξ) :=
X
|p|=m
ap(x)ξp
ξ ∈T ∗Mx
is well deﬁned.

80
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
If we put a Riemann metric on the manifold, we can talk about the length
|ξ| of any cotangent vector.
If L is a diﬀerential operator from E to itself (i.e. F=E) we shall call L
even elliptic if m is even and there exists some constant C such that
⟨v, σ(L)(ξ)v⟩≥C|ξ|m|v|2
for all x ∈M, v ∈Ex, ξ ∈T ∗Mx and ⟨, ⟩denotes the scalar product on
Ex. G˚arding’s inequality holds. Indeed, locally, this is just a restatement of
the (vector valued version) of G˚arding’s inequality that we have already proved
for the torus.
But Stage 4 in the proof extends unchanged (other than the
replacement of scalar valued functions by vector valued functions) to the more
general case.
2.10
Example: Hodge theory.
We assume knowledge of the basic facts about diﬀerentiable manifolds, in par-
ticular the existence of an operator d : Ωk →Ωk+1 with its usual properties,
where Ωk denotes the space of exterior k-forms. Also, if M is orientable and
carries a Riemann metric then the Riemann metric induces a scalar product on
the exterior powers of T ∗M and also picks out a volume form. So there is an
induced scalar product ( , ) = ( , )k on Ωk and a formal adjoint δ of d
δ : Ωk →Ωk−1
and satisﬁes
(dψ, φ) = (φ, δφ)
where φ is a (k + 1)-form and ψ is a k-form. Then
∆:= dδ + δd
is a second order diﬀerential operator on Ωk and satisﬁes
(∆φ, φ) = ∥dφ∥2 + ∥δφ∥2
where ∥φ∥|2 = (φ, φ) is the intrinsic L2 norm (so ∥∥= ∥∥0 in terms of the
notation of the preceding section). Furthermore, if
φ =
X
I
φIdxI
is a local expression for the diﬀerential form φ, where
dxI = dxi1 ∧· · · ∧dxik
I = (i1, . . . , ik)
then a local expression for ∆is
∆φ = −
X
gij
∂φI
∂xi∂xj + · · ·

2.10. EXAMPLE: HODGE THEORY.
81
where
gij = ⟨dxi, dxj⟩
and the · · · are lower order derivatives. In particular ∆is elliptic.
Let φ ∈Ωk and suppose that
dφ = 0.
Let C(φ), the cohomology class of φ be the set of all ψ ∈Ωk which satisfy
φ −ψ = dα,
α ∈Ωk−1
and let
C(φ)
denote the closure of C in the L2 norm. It is a closed subspace of the Hilbert
space obtained by completing Ωk relative to its L2 norm. Let us denote this
space by Lk
2, so C(φ) is a closed subspace of Lk
2.
Proposition 2.10.1 If φ ∈Ωk and dφ = 0, there exists a unique τ ∈C(φ) such
that
∥τ∥≤∥ψ∥∀ψ ∈C(φ).
Furthermore, τ is smooth,and
dτ = 0
and
δτ = 0.
If choose a minimizing sequence for ∥ψ∥in C(φ).
If we choose a minimizing sequence for ∥ψ∥in C(φ) we know it is Cauchy, cf.
the proof of the existence of orthogonal projections in a Hilbert space. So we
know that τ exists and is unique. For any α ∈Ωk+1 we have
(τ, δα) = lim(ψ, δα) = lim(dψ, α) = 0
as ψ ranges over a minimizing sequence.
The equation (τ, δα) = 0 for all
α ∈Ωk+1 says that τ is a weak solution of the equation dτ = 0.
We claim that
(τ, dβ) = 0
∀β ∈Ωk−1
which says that τ is a weak solution of δτ = 0. Indeed, for any t ∈R,
∥τ∥2 ≤∥τ + tdβ∥2 = ∥τ∥2 + t2∥dβ∥2 + 2t(τ, dβ)
so
−2t(τ, dβ) ≤t2∥dβ∥2.
If (τ, dβ) ̸= 0, we can choose
t = −ϵ (τ, dβ)
|(τ, dβ)|,
ϵ > 0

82
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
so
|(τ, dβ)| ≤ϵ|dβ|2.
As ϵ is arbitrary, this implies that (τ, dβ) = 0.
So (τ, ∆ψ) = (τ, [dδ + δd]ψ) = 0 for any ψ ∈Ωk. Hence τ is a weak solution
of ∆τ = 0 and so is smooth. The space Hk of weak, and hence smooth solutions
of ∆τ = 0 is ﬁnite dimensional by the general theory. It is called the space
of Harmonic forms.
We have seen that there is a unique harmonic form in
the cohomology class of any closed form, s the cohomology groups are ﬁnite
dimensional. In fact, the general theory tells us that
Lk
2
M
λ
Ek
λ
(Hilbert space direct sum) where Ek
λ is the eigenspace with eigenvalue λ of ∆.
Each Eλ is ﬁnite dimensional and consists of smooth forms, and the λ →∞.
The eigenspace Ek
0 is just Hk, the space of harmonic forms. Also, since
(∆φ, φ) = ∥dφ∥2 + ∥δφ∥2
we know that all the eigenvalues λ are non-negative.
Since d∆= d(dδ + δd) = dδd = ∆d, we see that
d : Ek
λ →Ek+1
λ
and similarly
δ : Ek
λ →Ek−1
λ
.
For λ ̸= 0, if φ ∈Ek
λ and dφ = 0, then λφ = ∆φ = dδφ so φ = d(1/λ)δφ so d
restricted to the Eλ is exact, and similarly so is δ. Furthermore, on L
k Ek
λ we
have
λI = ∆= (d + δ)2
so we have
Ek
λ = dEk−1
λ
⊕δEk+1
λ
and this decomposition is orthogonal since (dα, δβ) = (d2α, β) = 0.
As a ﬁrst consequence we see that
Lk
2 = Hk ⊕dΩk−1 ⊕δΩk−1
(the Hodge decomposition). If H denotes projection onto the ﬁrst component,
then ∆is invertible on the image of I −H with a an inverse there which is
compact. So if we let N denote this inverse on im I −H and set N = 0 on Hk
we get
∆N
=
I −H
Nd
=
dN
δN
=
Nδ
∆N
=
N∆
NH
=
0

2.11. THE RESOLVENT.
83
which are the fundamental assertions of Hodge theory, together with the asser-
tion proved above that Hφ is the unique minimizing element in its cohomology
class.
We have seen that
d + δ :
M
k
E2k
λ →
M
k
E2k+1
λ
is an isomorphism for λ ̸= 0
(2.39)
which of course implies that
X
k
(−1)k dim Ek
λ = 0
This shows that the index of the operator d + δ acting on L Lk
2 is the Euler
characteristic of the manifold.
(The index of any operator is the diﬀerence
between the dimensions of the kernel and cokernel).
Let Pk,λ denote the projection of Lk
2 onto Ek
λ. So
e−t∆=
X
e−λtPk,λ
is the solution of the heat equation on Lk
2.
As t →∞this approaches the
operator H projecting Lk
2 onto Hk. Letting ∆k denote the operator ∆on Lk
2
we see that
tr e−t∆k =
X
e−λk
where the sum is over all eigenvalues λk of ∆k counted with multiplicity. It
follows from (2.39) that the alternating sum over k of the corresponding sum
over non-zero eigenvalues vanishes. Hence
X
(−1)k tr e−t∆k = χ(M)
is independent of t. The index theorem computes this trace for small values of
t in terms of local geometric invariants.
The operator d + δ is an example of a Dirac operator whose general deﬁ-
nition we will not give here. The corresponding assertion and local evaluation
is the content of the celebrated Atiyah-Singer index theorem, one of the most
important theorems discovered in the twentieth century.
2.11
The resolvent.
In order to connect what we have done here notation that will come later, it is
convenient to let A = −L so that now the operator
(zI −A)−1
is compact as an operator on H0 for z suﬃciently negative. (I have dropped the
ιm which should come in front of this expression.) The operator A now has only

84
CHAPTER 2. HILBERT SPACES AND COMPACT OPERATORS.
ﬁnitely many positive eigenvalues, with the corresponding spaces of eigenvectors
being ﬁnite dimensional. In fact, the eigenvectors λn = λn(A) (counted with
multiplicity) approach −∞as n →∞and the operator (zI −A)−1 exists and
is a bounded (in fact compact) operator so long as z ̸= λn for any n. Indeed,
we can write any u ∈H0 as
u =
X
n
anφn
where φn is an eigenvector of A with eigenvalue λn and the φ form an orthonor-
mal basis of H0. Then
(zI −A)−1u =
X
1
z −λn
anφn.
The operator (zI −A)−1 is called the resolvent of A at the point z and denoted
by
R(z, A)
or simply by R(z) if A is ﬁxed. So
R(z, A) := (zI −A)−1
for those values of z ∈C for which the right hand side is deﬁned.
If z and are complex numbers with Rez > Rea, then the integral
Z ∞
0
e−zteatdt
converges, and we can evaluate it as
1
z −a =
Z ∞
0
e−zteatdt.
If Rez is greater than the largest of the eigenvalues of A we can write
R(z, A) =
Z ∞
0
e−ztetAdt
where we may interpret this equation as a shorthand for doing the integral for
the coeﬃcient of each eigenvector, as above, or as an actual operator valued
integral. We will spend a lot of time later on in this course generalizing this
formula and deriving many consequences from it.

Chapter 3
The Fourier Transform.
3.1
Conventions, especially about 2π.
The space S consists of all functions on mathbbR which are inﬁnitely diﬀer-
entiable and vanish at inﬁnity rapidly with all their derivatives in the sense
that
∥f∥m,n := sup{|xmf (n)(x)|} < ∞.
The ∥· ∥m,n give a family of semi-norms on S making S into a Frechet space -
that is, a vector space space whose topology is determined by a countable family
of semi-norms. More about this later in the course. We use the measure
1
√
2π dx
on R and so deﬁne the Fourier transform of an element of S by
ˆf(ξ) :=
1
√
2π
Z
R
f(x)e−ixξdx
and the convolution of two elements of S by
(f ⋆g)(x) :=
1
√
2π
Z
R
f(x −t)g(t)dt.
The Fourier transform is well deﬁned on S and
 d
dx
m
((−ix)nf)

ˆ= (iξ)m
 d
dξ
n
ˆf,
as follows by diﬀerentiation under the integral sign and by integration by parts.
This shows that the Fourier transform maps S to S.
85

86
CHAPTER 3. THE FOURIER TRANSFORM.
3.2
Convolution goes to multiplication.
(f ⋆g)ˆ(ξ)
=
1
2π
Z Z
f(x −t)g(t)dxe−ixξdx
=
1
2π
Z Z
f(u)g(t)e−i(u+t)ξdudt
=
1
√
2π
Z
R
f(u)e−iuξdu
1
√
2π
Z
R
g(t)e−itξdt
so
(f ⋆g)ˆ= ˆfˆg.
3.3
Scaling.
For any f ∈S and a > 0 deﬁne Saf by (Sa)f(x) := f(ax). Then setting u = ax
so dx = (1/a)du we have
(Saf)ˆ(ξ)
=
1
√
2π
Z
R
f(ax)e−ixξdx
=
1
√
2π
Z
R
(1/a)f(u)e−iu(ξ/a)du
so
(Saf)ˆ= (1/a)S1/a ˆf.
3.4
Fourier transform of a Gaussian is a Gaus-
sian.
The polar coordinate trick evaluates
1
√
2π
Z
R
e−x2/2dx = 1.
The integral
1
√
2π
Z
R
e−x2/2−xηdx
converges for all complex values of η, uniformly in any compact region. Hence
it deﬁnes an analytic function of η that can be evaluated by taking η to be real
and then using analytic continuation. For real η we complete the square and
make a change of variables:
1
√
2π
Z
R
e−x2/2−xηdx
=
1
√
2π
Z
R
e−(x+η)2/2+η2/2dx
=
eη2/2
1
√
2π
Z
R
e−(x+η)2/2dx
=
eη2/2.

3.4. FOURIER TRANSFORM OF A GAUSSIAN IS A GAUSSIAN.
87
Setting η = iξ gives
ˆn = n
if n(x) := e−x2/2.
If we set a = ϵ in our scaling equation and deﬁne
ρϵ := Sϵn
so
ρϵ(x) = e−ϵ2x2/2,
then
(ρϵ)ˆ(x) = 1
ϵ e−x2/2ϵ2.
Notice that for any g ∈S we have
Z
R
(1/a)(S1/ag)(ξ)dξ =
Z
R
g(ξ)dξ
so setting a = ϵ we conclude that
1
√
2π
Z
R
(ρϵ)ˆ(ξ)dξ = 1
for all ϵ.
Let
ψ := ψ1 := (ρ1)ˆ
and
ψϵ := (ρϵ)ˆ.
Then
ψϵ(η) = 1
ϵ ψ
η
ϵ

so
(ψϵ ⋆g)(ξ) −g(ξ) =
1
√
2π
Z
R
[g(ξ −η) −g(ξ)]1
ϵ ψ
η
ϵ

dη =
=
1
√
2π
Z
R
[g(ξ −ϵζ) −g(ξ)]ψ(ζ)dζ.
Since g ∈S it is uniformly continuous on R, so that for any δ > 0 we can ﬁnd
ϵ0 so that the above integral is less than δ in absolute value for all 0 < ϵ < ϵ0.
In short,
∥ψϵ ⋆g −g∥∞→0,
as ϵ →0.

88
CHAPTER 3. THE FOURIER TRANSFORM.
3.5
The multiplication formula.
This says that
Z
R
ˆf(x)g(x)dx =
Z
R
f(x)ˆg(x)dx
for any f, g ∈S. Indeed the left hand side equals
1
√
2π
Z
R
Z
R
f(y)e−ixydyg(x)dx.
We can write this integral as a double integral and then interchange the order
of integration which gives the right hand side.
3.6
The inversion formula.
This says that for any f ∈S
f(x) =
1
√
2π
Z
R
ˆf(ξ)eixξdξ.
To prove this, we ﬁrst observe that for any h ∈S the Fourier transform of
x 7→eiηxh(x) is just ξ 7→ˆh(ξ −η) as follows directly from the deﬁnition.
Taking g(x) = eitxe−ϵ2x2/2 in the multiplication formula gives
1
√
2π
Z
R
ˆf(t)eitxe−ϵ2t2/2dt =
1
√
2π
Z
R
f(t)ψϵ(t −x)dt = (f ⋆ψϵ)(x).
We know that the right hand side approaches f(x) as ϵ →0. Also, e−ϵ2t2/2 →1
for each ﬁxed t, and in fact uniformly on any bounded t interval. Furthermore,
0 < e−ϵ2t2/2 ≤1 for all t. So choosing the interval of integration large enough,
we can take the left hand side as close as we like to
1
√
2π
R
R ˆf(x)eixtdt by then
choosing ϵ suﬃciently small. QED
3.7
Plancherel’s theorem
Let
˜f(x) := f(−x).
Then the Fourier transform of ˜f is given by
1
√
2π
Z
R
f(−x)e−ixξdx =
1
√
2π
Z
R
f(u)eiuξdu = ˆf(ξ)
so
( ˜f)ˆ= ˆf.
Thus
(f ⋆˜f)ˆ= | ˆf|2.

3.8. THE POISSON SUMMATION FORMULA.
89
The inversion formula applied to f ⋆˜f and evaluated at 0 gives
(f ⋆˜f)(0) =
1
√
2π
Z
R
| ˆf|2dx.
The left hand side of this equation is
1
√
2π
Z
R
f(x) ˜f(0 −x)dx =
1
√
2π
Z
R
|f(x)|2dx.
Thus we have proved Plancherel’s formula
1
√
2π
Z
R
|f(x)|2dx =
1
√
2π
Z
R
| ˆf(x)|2dx.
Deﬁne L2(R) to be the completion of S with respect to the L2 norm given by
the left hand side of the above equation. Since S is dense in L2(R) we conclude
that the Fourier transform extends to unitary isomorphism of L2(R) onto itself.
3.8
The Poisson summation formula.
This says that for any g ∈S we have
X
k
g(2πk) =
1
√
2π
X
m
ˆg(m).
To prove this let
h(x) :=
X
k
g(x + 2πk)
so h is a smooth function, periodic of period 2π and
h(0) =
X
k
g(2πk).
We may expand h into a Fourier series
h(x) =
X
m
ameimx
where
am = 1
2π
Z 2π
0
h(x)e−imxdx = 1
2π
Z
R
g(x)e−imxdx =
1
√
2π ˆg(m).
Setting x = 0 in the Fourier expansion
h(x) =
1
√
2π
X
ˆg(m)eimx
gives
h(0) =
1
√
2π
X
m
ˆg(m).

90
CHAPTER 3. THE FOURIER TRANSFORM.
3.9
The Shannon sampling theorem.
Let f ∈S be such that its Fourier transform is supported in the interval [−π, π].
Then a knowledge of f(n) for all n ∈Z determines f. More explicitly,
f(t) = 1
π
∞
X
n=−∞
f(n)sin π(n −t)
n −t
.
(3.1)
Proof.
Let g be the periodic function (of period 2π) which extends ˆf, the
Fourier transform of f. So
g(τ) = ˆf(τ),
τ ∈[−π, π]
and is periodic.
Expand g into a Fourier series:
g =
X
n∈Z
cneinτ,
where
cn = 1
2π
Z π
−π
g(τ)e−inτdτ = 1
2π
Z ∞
−∞
ˆf(τ)e−inτdτ,
or
cn =
1
(2π)
1
2 f(−n).
But
f(t) =
1
(2π)
1
2
Z ∞
−∞
ˆf(τ)eitτdτ =
1
(2π)
1
2
Z π
−π
g(τ)eitτdτ =
1
(2π)
1
2
Z π
−π
X
1
(2π)
1
2 f(−n)ei(n+t)τdτ.
Replacing n by −n in the sum, and interchanging summation and integration,
which is legitimate since the f(n) decrease very fast, this becomes
f(t) = 1
2π
X
n
f(n)
Z π
−π
ei(t−n)τdτ.
But
Z π
−π
ei(t−n)τdτ = ei(t−n)τ
i(t −n)

π
−π
= ei(t−n)π −ei(t−n)π
i(t −n)
= 2sin π(n −t)
n −t
.
QED
It is useful to reformulate this via rescaling so that the interval [−π, π] is
replaced by an arbitrary interval symmetric about the origin: In the engineering
literature the frequency λ is deﬁned by
ξ = 2πλ.

3.10. THE HEISENBERG UNCERTAINTY PRINCIPLE.
91
Suppose we want to apply (3.1) to g = Saf. We know that the Fourier transform
of g is (1/a)S1/a ˆf and
supp S1/a ˆf = asupp ˆf.
So if
supp ˆf ⊂[−2πλc, 2πλc]
we want to choose a so that a2πλc ≤π or
a ≤
1
2λc
.
(3.2)
For a in this range (3.1) says that
f(ax) = 1
π
X
f(na)sin π(x −n)
x −n
,
or setting t = ax,
f(t) =
∞
X
n=−∞
f(na)sin( π
a(t −na)
π
a(t −na)
.
(3.3)
This holds in L2 under the assumption that f satisﬁes supp ˆf ⊂[−2πλc, 2πλc].
We say that f has ﬁnite bandwidth or is bandlimited with bandlimit λc.
The critical value ac = 1/2λc is known as the Nyquist sampling interval
and (1/a) = 2λc is known as the Nyquist sampling rate. Thus the Shannon
sampling theorem says that a band-limited signal can be recovered completely
from a set of samples taken at a rate ≥the Nyquist sampling rate.
3.10
The Heisenberg Uncertainty Principle.
Let f ∈S(R) with
Z
|f(x)|2dx = 1.
We can think of x 7→|f(x)|2 as a probability density on the line. The mean of
this probability density is
xm :=
Z
x|f(x)|2dx.
If we take the Fourier transform, then Plancherel says that
Z
| ˆf(ξ)|2dξ = 1
as well, so it deﬁnes a probability density with mean
ξm :=
Z
ξ| ˆf(ξ)|2dξ.

92
CHAPTER 3. THE FOURIER TRANSFORM.
Suppose for the moment that these means both vanish. The Heisenberg Un-
certainty Principle says that
Z
|xf(x)|2dx
 Z
|ξ ˆf(ξ)|2dξ

≥1
4.
Proof. Write −iξf(ξ) as the Fourier transform of f ′ and use Plancherel to
write the second integral as
R
|f ′(x)|2dx. Then the Cauchy - Schwarz inequality
says that the left hand side is ≥the square of
Z
|xf(x)f ′(x)|dx ≥

Z
Re(xf(x)f ′(x))dx
 =
1
2

Z
x(f(x)f ′(x) + f(x)f ′(x)dx

= 1
2

Z
x d
dx|f|2dx
 = 1
2

Z
−|f|2dx
 = 1
2. QED
If f has norm one but the mean of the probability density |f|2 is not necessar-
ily of zero (and similarly for for its Fourier transform) the Heisenberg uncertainty
principle says that
Z
|(x −xm)f(x)|2dx
 Z
|(ξ −ξm) ˆf(ξ)|2dξ

≥1
4.
The general case is reduced to the special case by replacing f(x) by
f(x + xm)eiξmx.
3.11
Tempered distributions.
The space S was deﬁned to be the collection of all smooth functions on R such
that
∥f∥m,n := sup
x {|xmf (n)(x)|} < ∞.
The collection of these norms deﬁne a topology on S which is much ﬁner that
the L2 topology: We declare that a sequence of functions {fk} approaches g ∈S
if and only if
∥fk −g∥m,n →0
for every m and n.
A linear function on S which is continuous with respect to this topology is
called a tempered distribution.
The space of tempered distributions is denoted by S′. For example, every
element f ∈S deﬁnes a linear function on S by
φ 7→⟨φ, f⟩=
1
√
2π
Z
R
φ(x)f(x)dx.

3.11. TEMPERED DISTRIBUTIONS.
93
But this last expression makes sense for any element f ∈L2(R), or for any
piecewise continuous function f which grows at inﬁnity no faster than any poly-
nomial. For example, if f ≡1, the linear function associated to f assigns to φ
the value
1
√
2π
Z
R
φ(x)dx.
This is clearly continuous with respect to the topology of S but this function of
φ does not make sense for a general element φ of L2(R).
Another example of an element of S′ is the Dirac δ-function which assigns
to φ ∈S its value at 0. This is an element of S′ but makes no sense when
evaluated on a general element of L2(R).
If f ∈S, then the Plancherel formula formula implies that its Fourier trans-
form F(f) = ˆf satisﬁes
(φ, f) = (F(φ), F(f)).
But we can now use this equation to deﬁne the Fourier transform of an arbitrary
element of S′: If ℓ∈S′ we deﬁne F(ℓ) to be the linear function
F(ℓ)(ψ) := ℓ(F−1(ψ)).
3.11.1
Examples of Fourier transforms of elements of S′.
• If ℓcorresponds to the function f ≡1, then
F(ℓ)(ψ) =
1
√
2π
Z
R
(F−1ψ)(ξ)dξ = F
 F−1ψ

(0) = ψ(0).
So the Fourier transform of the function which is identically one is the
Dirac δ-function.
• If δ denotes the Dirac δ-function, then
(F(δ)(ψ) = δ(F−1(ψ)) =
 (F−1(ψ)

(0) =
1
√
2π
Z
R
ψ(x)dx.
So the Fourier transform of the Dirac δ function is the function which is
identically one.
• In fact, this last example follows from the preceding one: If m = F(ℓ)
then
(F(m)(φ) = m(F−1(φ)) = ℓ(F−1(F−1(φ)).
But
F−2(φ)(x) = φ(−x).
So if m = F(ℓ) then F(m) = ˘ℓwhere
˘ℓ(φ) := ℓ(φ(−•)).

94
CHAPTER 3. THE FOURIER TRANSFORM.
• The Fourier transform of the function x: This assigns to every ψ ∈S the
value
1
√
2π
Z
ψ(ξ)eixξxdξdx =
1
√
2π
Z
ψ(ξ)1
i
d
dξ
 eixξ
dξdx =
i
1
√
2π
Z dψ(ξ)
dx
eixξdξdx = i

F

(F−1
dψ(ξ)
dx

(0) = iδ
dψ(ξ)
dx

.
Now for an element of S we have
Z dφ
dx · fdx = −
1
√
2π
Z
φ df
dxdx.
So we deﬁne the derivative of an ℓ∈S′ by
dℓ
dx(φ) = ℓ

−dφ
dx

.
So the Fourier transform of x is −i dδ
dx.

Chapter 4
Measure theory.
4.1
Lebesgue outer measure.
We recall some results from the chapter on metric spaces: For any subset A ⊂R
we deﬁned its Lebesgue outer measure by
m∗(A) := inf
X
ℓ(In) : In are intervals with A ⊂
[
In.
(4.1)
Here the length ℓ(I) of any interval I = [a, b] is b −a with the same deﬁnition
for half open intervals (a, b] or [a, b), or open intervals. Of course if a = −∞
and b is ﬁnite or +∞, or if a is ﬁnite and b = +∞the length is inﬁnite. So the
inﬁmum in (4.1) is taken over all covers of A by intervals. By the usual ϵ/2n
trick, i.e. by replacing each Ij = [aj, bj] by (aj −ϵ/2j+1, bj + ϵ/2j+1) we may
assume that the inﬁmum is taken over open intervals. (Equally well, we could
use half open intervals of the form [a, b), for example.).
It is clear that if A ⊂B then m∗(A) ≤m∗(B) since any cover of B by
intervals is a cover of A. Also, if Z is any set of measure zero, then m∗(A∪Z) =
m∗(A). In particular, m∗(Z) = 0 if Z has measure zero. Also, if A = [a, b] is an
interval, then we can cover it by itself, so
m∗([a, b]) ≤b −a,
and hence the same is true for (a, b], [a, b), or (a, b). If the interval is inﬁnite, it
clearly can not be covered by a set of intervals whose total length is ﬁnite, since
if we lined them up with end points touching they could not cover an inﬁnite
interval. We recall the proof that
m∗(I) = ℓ(I)
(4.2)
if I is a ﬁnite interval: We may assume that I = [c, d] is a closed interval by
what we have already said, and that the minimization in (4.1) is with respect
to a cover by open intervals. So what we must show is that if
[c, d] ⊂
[
i
(ai, bi)
95

96
CHAPTER 4. MEASURE THEORY.
then
d −c ≤
X
i
(bi −ai).
We ﬁrst applied Heine-Borel to replace the countable cover by a ﬁnite cover.
(This only decreases the right hand side of preceding inequality.) So let n be
the number of elements in the cover. We needed to prove that if
[c, d] ⊂
n
[
i=1
(ai, bi) then d −c ≤
n
X
i=1
(bi −ai),
and we did this this by induction on n. If n = 1 then a1 < c and b1 > d so
clearly b1 −a1 > d −c.
Suppose that n ≥2 and we know the result for all covers (of all intervals
[c, d] ) with at most n −1 intervals in the cover. If some interval (ai, bi) is
disjoint from [c, d] we may eliminate it from the cover, and then we are in the
case of n −1 intervals. So every (ai, bi) has non-empty intersection with [c, d].
Among the the intervals (ai, bi) there will be one for which ai takes on the
minimum possible value. By relabeling, we may assume that this is (a1, b1).
Since c is covered, we must have a1 < c. If b1 > d then (a1, b1) covers [c, d] and
there is nothing further to do. So assume b1 ≤d. We must have b1 > c since
(a1, b1) ∩[c, d] ̸= ∅. Since b1 ∈[c, d], at least one of the intervals (ai, bi), i > 1
contains the point b1. By relabeling, we may assume that it is (a2, b2). But now
we have a cover of [c, d] by n −1 intervals:
[c, d] ⊂(a1, b2) ∪
n
[
i=3
(ai, bi).
So by induction
d −c ≤(b2 −a1) +
n
X
i=3
(bi −ai).
But b2 −a1 ≤(b2 −a2) + (b1 −a1) since a2 < b1. QED
We repeat that the intervals used in (4.1) could be taken as open, closed or
half open without changing the deﬁnition. If we take them all to be half open,
of the form Ii = [ai, bi), we can write each Ii as a disjoint union of ﬁnite or
countably many intervals each of length < ϵ. So it makes no diﬀerence to the
deﬁnition if we also require the
ℓ(Ii) < ϵ
(4.3)
in (4.1). We will see that when we pass to other types of measures this will
make a diﬀerence.
We have veriﬁed, or can easily verify the following properties:
1.
m∗(∅) = 0.

4.1. LEBESGUE OUTER MEASURE.
97
2.
A ⊂B ⇒m∗(A) ≤m∗(B).
3.
m∗(
[
i
Ai) ≤
X
i
m∗(Ai).
4. If dist (A, B) > 0 then
m∗(A ∪B) = m∗(A) + m∗(B).
5.
m∗(A) = inf{m∗(U) : U ⊃A,
U open}.
6. For an interval
m∗(I) = ℓ(I).
The only items that we have not done already are items 4 and 5. But these are
immediate: for 4 we may choose the intervals in (4.1) all to have length < ϵ
where 2ϵ < dist (A, B) so that there is no overlap. As for item 5, we know from
2 that m∗(A) ≤m∗(U) for any set U, in particular for any open set U which
contains A. We must prove the reverse inequality: if m∗(A) = ∞this is trivial.
Otherwise, we may take the intervals in (4.1) to be open and then the union on
the right is an open set whose Lebesgue outer measure is less than m∗(A) + δ
for any δ > 0 if we choose a close enough approximation to the inﬁmum.
I should also add that all the above works for Rn instead of R if we replace
the word “interval” by “rectangle”, meaning a rectangular parallelepiped, i.e a
set which is a product of one dimensional intervals. We also replace length by
volume (or area in two dimensions). What is needed is the following
Lemma 4.1.1 Let C be a ﬁnite non-overlapping collection of closed rectangles
all contained in the closed rectangle J. Then
vol J ≥
X
I∈C
vol I.
If C is any ﬁnite collection of rectangles such that
J ⊂
[
I∈C
I
then
vol J ≤
X
I∈C
vol (I).
This lemma occurs on page 1 of Strook, A concise introduction to the theory of
integration together with its proof. I will take this for granted. In the next few
paragraphs I will talk as if we are in R, but everything goes through unchanged
if R is replaced by Rn.

98
CHAPTER 4. MEASURE THEORY.
4.2
Lebesgue inner measure.
Item 5. in the preceding paragraph says that the Lebesgue outer measure of
any set is obtained by approximating it from the outside by open sets. The
Lebesgue inner measure is deﬁned as
m∗(A) = sup{m∗(K) : K ⊂A, K compact }.
(4.4)
Clearly
m∗(A) ≤m∗(A)
since m∗(K) ≤m∗(A) for any K ⊂A. We also have
Proposition 4.2.1 For any interval I we have
m∗(I) = ℓ(I).
(4.5)
Proof. If ℓ(I) = ∞the result is obvious. So we may assume that I is a ﬁnite
interval which we may assume to be open, I = (a, b). If K ⊂I is compact, then
I is a cover of K and hence from the deﬁnition of outer measure m∗(K) ≤ℓ(I).
So m∗(I) ≤ℓ(I). On the other hand, for any ϵ > 0, ϵ < 1
2(b −a) the interval
[a + ϵ, b −ϵ] is compact and m∗([a −ϵ, a + ϵ]) = b −a −2ϵ ≤m∗(I). Letting
ϵ →0 proves the proposition. QED
4.3
Lebesgue’s deﬁnition of measurability.
A set A with m∗(A) < ∞is said to measurable in the sense of Lebesgue if
m∗(A) = m∗(A).
(4.6)
If A is measurable in the sense of Lebesgue, we write
m(A) = m∗(A) = m∗(A).
(4.7)
If K is a compact set, then m∗(K) = m∗(K) since K is a compact set con-
tained in itself. Hence all compact sets are measurable in the sense of Lebesgue.
If I is a bounded interval, then I is measurable in the sense of Lebesgue by
Proposition 4.2.1.
If m∗(A) = ∞, we say that A is measurable in the sense of Lebesgue if all
of the sets A ∩[−n, n] are measurable.
Proposition 4.3.1 If A = S Ai is a (ﬁnite or) countable disjoint union of sets
which are measurable in the sense of Lebesgue, then A is measurable in the sense
of Lebesgue and
m(A) =
X
i
m(Ai).

4.3. LEBESGUE’S DEFINITION OF MEASURABILITY.
99
Proof. We may assume that m(A) < ∞- otherwise apply the result to A ∩
[−n, n] and Ai ∩[−n, n] for each n. We have
m∗(A) ≤
X
n
m∗(An) =
X
n
m(An).
Let ϵ > 0, and for each n choose compact Kn ⊂An with
m∗(Kn) ≥m∗(An) −ϵ
2n = m(An) −ϵ
2n
since An is measurable in the sense of Lebesgue.
The sets Kn are pairwise
disjoint, hence, being compact, at positive distances from one another. Hence
m∗(K1 ∪· · · ∪Kn) = m∗(K1) + · · · + m∗(Kn)
and K1 ∪· · · ∪Kn is compact and contained in A. Hence
m∗(A) ≥m∗(K1) + · · · + m∗(Kn),
and since this is true for all n we have
m∗(A) ≥
X
n
m(An) −ϵ.
Since this is true for all ϵ > 0 we get
m∗(A) ≥
X
m(An).
But then m∗(A) ≥m∗(A) and so they are equal, so A is measurable in the sense
of Lebesgue, and m(A) = P m(Ai). QED
Proposition 4.3.2 Open sets and closed sets are measurable in the sense of
Lebesgue.
Proof. Any open set O can be written as the countable union of open intervals
Ii, and
Jn := In \
n−1
[
i=1
Ii
is a disjoint union of intervals (some open, some closed, some half open) and O
is the disjont union of the Jn. So every open set is a disjoint union of intervals
hence measurable in the sense of Lebesgue.
If F is closed, and m∗(F) = ∞, then F ∩[−n, n] is compact, and so F is
measurable in the sense of Lebesgue. Suppose that
m∗(F) < ∞.

100
CHAPTER 4. MEASURE THEORY.
For any ϵ > 0 consider the sets
G1,ϵ
:=
[−1 + ϵ
22 , 1 −ϵ
22 ] ∩F
G2,ϵ
:=
([−2 + ϵ
23 , −1] ∩F) ∪([1, 2 −ϵ
23 ] ∩F)
G3,ϵ
:=
([−3 + ϵ
24 , −2] ∩F) ∪([2, 3 −ϵ
24 ] ∩F)
...
and set
Gϵ :=
[
i
Gi,ϵ.
The Gi,ϵ are all compact, and hence measurable in the sense of Lebesgue, and
the union in the deﬁnition of Gϵ is disjoint, so is measurable in the sense of
Lebesgue.
Furthermore, the sum of the lengths of the “gaps” between the
intervals that went into the deﬁnition of the Gi,ϵ is ϵ. So
m(Gϵ) + ϵ = m∗(Gϵ) + ϵ ≥m∗(F) ≥m∗(Gϵ) = m(Gϵ) =
X
i
m(Gi,ϵ).
In particular, the sum on the right converges, and hence by considering a ﬁnite
number of terms, we will have a ﬁnite sum whose value is at least m(Gϵ) −ϵ.
The corresponding union of sets will be a compact set Kϵ contained in F with
m(Kϵ) ≥m∗(F) −2ϵ.
Hence all closed sets are measurable in the sense of Lebesgue. QED
Theorem 4.3.1 A is measurable in the sense of Lebesgue if and only if for
every ϵ > 0 there is an open set U ⊃A and a closed set F ⊂A such that
m(U \ F) < ϵ.
Proof.
Suppose that A is measurable in the sense of Lebesgue with m(A) < ∞.
Then there is an open set U ⊃A with m(U) < m∗(A) + ϵ/2 = m(A) + ϵ/2, and
there is a compact set F ⊂A with m(F) ≥m∗(A) −ϵ = m(A) −ϵ/2. Since
U \ F is open, it is measurable in the sense of Lebesgue, and so is F as it is
compact. Also F and U \ F are disjoint. Hence by Proposition 4.3.1,
m(U \ F) = m(U) −m(F) < m(A) + ϵ
2 −

m(A) −ϵ
2

= ϵ.
If A is measurable in the sense of Lebesgue, and m(A) = ∞, we can apply
the above to A ∩I where I is any compact interval.
So we can ﬁnd open
sets Un ⊃A ∩[−n −2δn+1, n + 2δn+1] and closed sets Fn ⊂A ∩[−n, n] with
m(Un \ Fn) < ϵ/2n. Here the δn are suﬃciently small positive numbers. We

4.3. LEBESGUE’S DEFINITION OF MEASURABILITY.
101
may enlarge each Fn if necessary so that Fn ∩[−n + 1, n −1] ⊃Fn−1. We may
also decrease the Un if necessary so that
Un ∩(−n + 1 −δn, n −1 + δn) ⊂Un−1.
Indeed, if we set Cn := [−n + 1 −δn, n −1 + δn] ∩U c
n−1 then Cn is a closed set
with Cn ∩A = ∅. Then Un ∩Cc
n is still an open set containing [−n −2δn+1, n +
2δn+1] ∩A and
(Un ∩Cc
n) ∩(−n + 1 −δn, n −1 + δn) ⊂Cc
n ∩(−n + 1 −δn, n −1 + δn) ⊂Un−1.
Take U := S Un so U is open. Take
F :=
[
(Fn ∩([−n, −n + 1] ∪[n −1, n])).
Then F is closed, U ⊃A ⊃F and
U \ F ⊂
[
(Un/Fn) ∩([−n, −n + 1] ∪[n −1, n]) ⊂
[
(Un \ Fn)
In the other direction, suppose that for each ϵ, there exist U ⊃A ⊃F with
m(U \ F) < ϵ. Suppose that m∗(A) < ∞. Then m(F) < ∞and m(U) ≤
m(U \ F) + m(F) < ϵ + m(F) < ∞. Then
m∗(A) ≤m(U) < m(F) + ϵ = m∗(F) + ϵ ≤m∗(A) + ϵ.
Since this is true for every ϵ > 0 we conclude that m∗(A) ≥m∗(A) so they are
equal and A is measurable in the sense of Lebesgue.
If m∗(A) = ∞, we have U ∩(−n −ϵ, n + ϵ) ⊃A ∩[−n, n] ⊃F ∩[−n, n] and
m((U ∩(−n −ϵ, n + ϵ) \ (F ∩[−n, n]) < 2ϵ + ϵ = 3ϵ
so we can proceed as before to conclude that m∗(A∩[−n, n]) = m∗(A∩[−n, n]).
QED
Several facts emerge immediately from this theorem:
Proposition 4.3.3 If A is measurable in the sense of Lebesgue, so is its com-
plement Ac = R \ A.
Indeed, if F ⊂A ⊂U with F closed and U open, then F c ⊃Ac ⊃U c with F c
open and U c closed. Furthermore, F c \U c = U \F so if A satisﬁes the condition
of the theorem so does Ac.
Proposition 4.3.4 If A and B are measurable in the sense of Lebesgue so is
A ∩B.
For ϵ > 0 choose UA ⊃A ⊃FA and UB ⊃B ⊃FB with m(UA \ FA) <
ϵ/2 and m(UB \ FB) < ϵ/2. Then (UA ∩UB) ⊃(A ∩B) ⊃(FA ∩FB) and
(UA ∩UB) \ (FA ∩FB) ⊂(UA \ FA) ∪(UB \ FB).QED
Putting the previous two propositions together gives

102
CHAPTER 4. MEASURE THEORY.
Proposition 4.3.5 If A and B are measurable in the sense of Lebesgue then
so is A ∪B.
Indeed, A ∪B = (Ac ∩Bc)c.
Since A \ B = A ∩Bc we also get
Proposition 4.3.6 If A and B are measurable in the sense of Lebesgue then
so is A \ B.
4.4
Caratheodory’s deﬁnition of measurability.
A set E ⊂R is said to be measurable according to Caratheodory if for
any set A ⊂R we have
m∗(A) = m∗(A ∩E) + m∗(A ∩Ec)
(4.8)
where we recall that Ec denotes the complement of E. In other words, A∩Ec =
A \ E. This deﬁnition has many advantages, as we shall see. Our ﬁrst task is
to show that it is equivalent to Lebesgue’s:
Theorem 4.4.1 A set E is measurable in the sense of Caratheodory if and only
if it is measurable in the sense of Lebesgue.
Proof.
We always have
m∗(A) ≤m∗(A ∩E) + m∗(A \ E)
so condition (4.8) is equivalent to
m∗(A ∩E) + m∗(A \ E) ≤m∗(A)
(4.9)
for all A.
Suppose E is measurable in the sense of Lebesgue.
Let ϵ > 0.
Choose
U ⊃E ⊃F with U open, F closed and m(U/F) < ϵ which we can do by
Theorem 4.3.1. Let V be an open set containing A. Then A \ E ⊂V \ F and
A ∩E ⊂(V ∩U) so
m∗(A \ E) + m∗(A ∩E)
≤
m(V \ F) + m(V ∩U)
≤
m(V \ U) + m(U \ F) + m(V ∩U)
≤
m(V ) + ϵ.
(We can pass from the second line to the third since both V \ U and V ∩U
are measurable in the sense of Lebesgue and we can apply Proposition 4.3.1.)
Taking the inﬁmum over all open V containing A, the last term becomes m∗(A),
and as ϵ is arbitrary, we have established (4.9) showing that E is measurable in
the sense of Caratheodory.

4.4. CARATHEODORY’S DEFINITION OF MEASURABILITY.
103
In the other direction, suppose that E is measurable in the sense of Caratheodory.
First suppose that
m∗(E) < ∞.
Then for any ϵ > 0 there exists an open set U ⊃E with m(U) < m∗(E) + ϵ.
We may apply condition (4.8) to A = U to get
m(U) = m∗(U ∩E) + m∗(U \ E) = m∗(E) + m∗(U \ E)
so
m∗(U \ E) < ϵ.
This means that there is an open set V ⊃(U \E) with m(V ) < ϵ. But we know
that U \ V is measurable in the sense of Lebesgue, since U and V are, and
m(U) ≤m(V ) + m(U \ V )
so
m(U \ V ) > m(U) −ϵ.
So there is a closed set F ⊂U \V with m(F) > m(U)−ϵ. But since V ⊃U \E,
we have U \ V ⊂E. So F ⊂E. So F ⊂E ⊂U and
m(U \ F) = m(U) −m(F) < ϵ.
Hence E is measurable in the sense of Lebesgue.
If m(E) = ∞, we must show that E ∩[−n, n] is measurable in the sense of
Caratheodory, for then it is measurable in the sense of Lebesgue from what we
already know. We know that the interval [−n, n] itself, being measurable in the
sense of Lebesgue, is measurable in the sense of Caratheodory. So we will have
completed the proof of the theorem if we show that the intersection of E with
[−n, n] is measurable in the sense of Caratheodory.
More generally, we will show that the union or intersection of two sets which
are measurable in the sense of Caratheodory is again measurable in the sense
of Caratheodory. Notice that the deﬁnition (4.8) is symmetric in E and Ec so
if E is measurable in the sense of Caratheodory so is Ec. So it suﬃces to prove
the next lemma to complete the proof.
Lemma 4.4.1 If E1 and E2 are measurable in the sense of Caratheodory so is
E1 ∪E2.
For any set A we have
m∗(A) = m∗(A ∩E1) + m∗(A ∩Ec
1)
by (4.8) applied to E1. Applying (4.8) to A ∩Ec
1 and E2 gives
m∗(A ∩Ec
1) = m∗(A ∩Ec
1 ∩E2) + m∗(A ∩Ec
1 ∩Ec
2).

104
CHAPTER 4. MEASURE THEORY.
Substituting this back into the preceding equation gives
m∗(A) = m∗(A ∩E1) + m∗(A ∩Ec
1 ∩E2) + m∗(A ∩Ec
1 ∩Ec
2).
(4.10)
Since Ec
1 ∩Ec
2 = (E1 ∪E2)c we can write this as
m∗(A) = m∗(A ∩E1) + m∗(A ∩Ec
1 ∩E2) + m∗(A ∩(E1 ∪E2)c).
Now A ∩(E1 ∪E2) = (A ∩E1) ∪(A ∩(Ec
1 ∩E2) so
m∗(A ∩E1) + m∗(A ∩Ec
1 ∩E2) ≥m∗(A ∩(E1 ∪E2)).
Substituting this for the two terms on the right of the previous displayed equa-
tion gives
m∗(A) ≥m∗(A ∩(E1 ∪E2)) + m∗(A ∩(E1 ∪E2)c)
which is just (4.9) for the set E1 ∪E2. This proves the lemma and the theorem.
We let M denote the class of measurable subsets of R - “measurability”
in the sense of Lebesgue or Caratheodory these being equivalent. Notice by
induction starting with two terms as in the lemma, that any ﬁnite union of sets
in M is again in M
4.5
Countable additivity.
The ﬁrst main theorem in the subject is the following description of M and the
function m on it:
Theorem 4.5.1 M and the function m : M →R have the following properties:
• R ∈M.
• E ∈M ⇒Ec ∈M.
• If En ∈M for n = 1, 2, 3, . . . then S
n En ∈M.
• If Fn ∈M and the Fn are pairwise disjoint, then F := S
n Fn ∈M and
m(F) =
∞
X
n=1
m(Fn).
Proof.
We already know the ﬁrst two items on the list, and we know that a
ﬁnite union of sets in M is again in M. We also know the last assertion which
is Proposition 4.3.1. But it will be instructive and useful for us to have a proof
starting directly from Caratheodory’s deﬁnition of measurablity:
If F1 ∈M, F2 ∈M and F1 ∩F2 = ∅then taking
A = F1 ∪F2,
E1 = F1,
E2 = F2

4.5. COUNTABLE ADDITIVITY.
105
in (4.10) gives
m(F1 ∪F2) = m(F1) + m(F2).
Induction then shows that if F1, . . . , Fn are pairwise disjoint elements of M then
their union belongs to M and
m(F1 ∪F2 ∪· · · ∪Fn) = m(F1) + m(F2) + · · · + m(Fn).
More generally, if we let A be arbitrary and take E1 = F1, E2 = F2 in (4.10)
we get
m∗(A) = m∗(A ∩F1) + m∗(A ∩F2) + m∗(A ∩(F1 ∪F2)c).
If F3 ∈M is disjoint from F1 and F2 we may apply (4.8) with A replaced by
A ∩(F1 ∪F2)c and E by F3 to get
m∗(A ∩(F1 ∪F2)c)) = m∗(A ∩F3) + m∗(A ∩(F1 ∪F2 ∪F3)c),
since
(F1 ∪F2)c ∩F c
3 = F c
1 ∩F c
2 ∩F c
3 = (F1 ∪F2 ∪F3)c .
Substituting this back into the preceding equation gives
m∗(A) = m∗(A ∩F1) + m∗(A ∩F2) + m∗(A ∩F3) + m∗(A ∩(F1 ∪F2 ∪F3)c).
Proceeding inductively, we conclude that if F1, . . . , Fn are pairwise disjoint ele-
ments of M then
m∗(A) =
n
X
1
m∗(A ∩Fi) + m∗(A ∩(F1 ∪· · · ∪Fn)c).
(4.11)
Now suppose that we have a countable family {Fi} of pairwise disjoint sets
belonging to M. Since
 n
[
i=1
Fi
!c
⊃
 ∞
[
i=1
Fi
!c
we conclude from (4.11) that
m∗(A) ≥
n
X
1
m∗(A ∩Fi) + m∗
 
A ∩
 ∞
[
i=1
Fi
!c!
and hence passing to the limit
m∗(A) ≥
∞
X
1
m∗(A ∩Fi) + m∗
 
A ∩
 ∞
[
i=1
Fi
!c!
.
Now given any collection of sets Bk we can ﬁnd intervals {Ik,j} with
Bk ⊂
[
j
Ik,j

106
CHAPTER 4. MEASURE THEORY.
and
m∗(Bk) ≤
X
j
ℓ(Ik,j) + ϵ
2k .
So
[
k
Bk ⊂
[
k,j
Ik,j
and hence
m∗[
Bk

≤
X
m∗(Bk),
the inequality being trivially true if the sum on the right is inﬁnite. So
∞
X
i=1
m∗(A ∩Fk) ≥m∗
 
A ∩
 ∞
[
i=1
Fi
!!
.
Thus
m∗(A) ≥
∞
X
1
m∗(A ∩Fi) + m∗
 
A ∩
 ∞
[
i=1
Fi
!c!
≥
≥m∗
 
A ∩
 ∞
[
i=1
Fi
!!
+ m∗
 
A ∩
 ∞
[
i=1
Fi
!c!
.
The extreme right of this inequality is the left hand side of (4.9) applied to
E =
[
i
Fi,
and so E ∈M and the preceding string of inequalities must be equalities since
the middle is trapped between both sides which must be equal. Hence we have
proved that if Fn is a disjoint countable family of sets belonging to M then
their union belongs to M and
m∗(A) =
X
i
m∗(A ∩Fi) + m∗
 
A ∩
 ∞
[
i=1
Fi
!c!
.
(4.12)
If we take A = S Fi we conclude that
m(F) =
∞
X
n=1
m(Fn)
(4.13)
if the Fj are disjoint and
F =
[
Fj.
So we have reproved the last assertion of the theorem using Caratheodory’s
deﬁnition. For the third assertion, we need only observe that a countable union
of sets in M can be always written as a countable disjoint union of sets in M.
Indeed, set
F1 := E1, F2 := E2 \ E1 = E1 ∩Ec
2

4.5. COUNTABLE ADDITIVITY.
107
F3 := E3 \ (E1 ∪E2)
etc.
The right hand sides all belong to M since M is closed under taking
complements and ﬁnite unions and hence intersections, and
[
j
Fj =
[
Ej.
We have completed the proof of the theorem.
A number of easy consequences follow: The symmetric diﬀerence between
two sets is the set of points belonging to one or the other but not both:
A∆B := (A \ B) ∪(B \ A).
Proposition 4.5.1 If A ∈M and m(A∆B) = 0 then B ∈M and m(A) =
m(B).
Proof.
By assumption A \ B has measure zero (and hence is measurable)
since it is contained in the set A∆B which is assumed to have measure zero.
Similarly for B \ A. Also (A ∩B) ∈M since
A ∩B = A \ (A \ B).
Thus
B = (A ∩B) ∪(B \ A) ∈M.
Since B \ A and A ∩B are disjoint, we have
m(B) = m(A ∩B) + m(B \ A) = m(A ∩B) = m(A ∩B) + m(A \ B) = m(A).
QED
Proposition 4.5.2 Suppose that An ∈M and An ⊂An+1 for n = 1, 2, . . . .
Then
m
[
An

= lim
n→∞m(An).
Indeed, setting Bn := An \ An−1 (with B1 = A1) the Bi are pairwise disjoint
and have the same union as the Ai so
m
[
An

=
∞
X
i=1
m(Bi) = lim
n→∞
n
X
i=1
m(Bn) = lim
n→∞m
 n
[
i=1
Bi
!
= lim
n→∞m(An).
QED
Proposition 4.5.3 If Cn ⊃Cn+1 is a decreasing family of sets in M and
m(C1) < ∞then
m
\
Cn

= lim
n→∞m(Cn).

108
CHAPTER 4. MEASURE THEORY.
Indeed, set A1 := ∅, A2 := C1 \ C2, A3 := C1 \ C3 etc. The A’s are increasing
so
m
[
(C1 \ Ci)

= lim
n→∞m(C1 \ Cn) = m(C1) −lim
n→∞m(Cn)
by the preceding proposition. Since m(C1) < ∞we have
m(C1 \ Cn) = m(C1) −m(Cn).
Also
[
n
(C1 \ Cn) = C1 \
 \
n
Cn
!
.
So
m
 [
n
(C1 \ Cn)
!
= m(C1) −m
\
Cn

= m(C1) −lim
n→∞m(Cn).
Subtracting m(C1) from both sides of the last equation gives the equality in the
proposition. QED
4.6
σ-ﬁelds, measures, and outer measures.
We will now take the items in Theorem 4.5.1 as axioms: Let X be a set. (Usually
X will be a topological space or even a metric space). A collection F of subsets
of X is called a σ ﬁeld if:
• X ∈F,
• If E ∈F then Ec = X \ E ∈F, and
• If {En} is a sequence of elements in F then S
n En ∈F,
The intersection of any family of σ-ﬁelds is again a σ-ﬁeld, and hence given
any collection C of subsets of X, there is a smallest σ-ﬁeld F which contains it.
Then F is called the σ-ﬁeld generated by C.
If X is a metric space, the σ-ﬁeld generated by the collection of open sets is
called the Borel σ-ﬁeld, usually denoted by B or B(X) and a set belonging to
B is called a Borel set.
Given a σ-ﬁeld F a (non-negative) measure is a function
m : F →[0, ∞]
such that
• m(∅) = 0 and
• Countable additivity: If Fn is a disjoint collection of sets in F then
m
 [
n
Fn
!
=
X
n
m(Fn).

4.7. CONSTRUCTING OUTER MEASURES, METHOD I.
109
In the countable additivity condition it is understood that both sides might be
inﬁnite.
An outer measure on a set X is a map m∗to [0, ∞] deﬁned on the collection
of all subsets of X which satisﬁes
• m(∅) = 0,
• Monotonicity: If A ⊂B then m∗(A) ≤m∗(B), and
• Countable subadditivity: m∗(S
n An) ≤P
n m∗(An).
Given an outer measure, m∗, we deﬁned a set E to be measurable (relative
to m∗) if
m∗(A) = m∗(A ∩E) + m∗(A ∩Ec)
for all sets A. Then Caratheodory’s theorem that we proved in the preceding
section asserts that the collection of measurable sets is a σ-ﬁeld, and the re-
striction of m∗to the collection of measurable sets is a measure which we shall
usually denote by m.
There is an unfortunate disagreement in terminology, in that many of the
professionals, especially in geometric measure theory, use the term “measure”
for what we have been calling “outer measure”. However we will follow the
above conventions which used to be the old fashioned standard.
An obvious task, given Caratheodory’s theorem, is to look for ways of con-
structing outer measures.
4.7
Constructing outer measures, Method I.
Let C be a collection of sets which cover X. For any subset A of X let
ccc(A)
denote the set of (ﬁnite or) countable covers of A by sets belonging to C. In
other words, an element of ccc(A) is a ﬁnite or countable collection of elements
of C whose union contains A.
Suppose we are given a function
ℓ: C →[0, ∞].
Theorem 4.7.1 There exists a unique outer measure m∗on X such that
• m∗(A) ≤ℓ(A) for all A ∈C and
• If n∗is any outer measure satisfying the preceding condition then n∗(A) ≤
m∗(A) for all subsets A of X.

110
CHAPTER 4. MEASURE THEORY.
This unique outer measure is given by
m∗(A) =
inf
D∈ccc(A)
X
D∈D
ℓ(D).
(4.14)
In other words, for each countable cover of A by elements of C we compute the
sum above, and then minimize over all such covers of A.
If we had two outer measures satisfying both conditions then each would have
to be ≤the other, so the uniqueness is obvious.
To check that the m∗deﬁned by (4.14) is an outer measure, observe that
for the empty set we may take the empty cover, and the convention about an
empty sum is that it is zero, so m∗(∅) = 0. If A ⊂B then any cover of B is a
cover of A, so that m∗(A) ≤m∗(B). To check countable subadditivity we use
the usual ϵ/2n trick: If m∗(An) = ∞for any An the subadditivity condition is
obviously satisﬁed. Otherwise, we can ﬁnd a Dn ∈ccc(An) with
X
D∈Dn
ℓ(D) ≤m∗(An) + ϵ
2n .
Then we can collect all the D together into a countable cover of A so
m∗(A) ≤
X
n
m∗(An) + ϵ,
and since this is true for all ϵ > 0 we conclude that m∗is countably subadditive.
So we have veriﬁed that m∗deﬁned by (4.14) is an outer measure. We must
check that it satisﬁes the two conditions in the theorem. If A ∈C then the
single element collection {A} ∈ccc(A), so m∗(A) ≤ℓ(A), so the ﬁrst condition
is obvious. As to the second condition, suppose n∗is an outer measure with
n∗(D) ≤ℓ(D) for all D ∈C. Then for any set A and any countable cover D of
A by elements of C we have
X
D∈D
ℓ(D) ≥
X
D∈D
n∗(D) ≥n∗
 [
D∈D
D
!
≥n∗(A),
where in the second inequality we used the countable subadditivity of n∗and
in the last inequality we used the monotonicity of n∗.
Minimizing over all
D ∈ccc(A) shows that m∗(A) ≥n∗(A). QED
This argument is basically a repeat performance of the construction of
Lebesgue measure we did above. However there is some trouble:
4.7.1
A pathological example.
Suppose we take X = R, and let C consist of all half open intervals of the form
[a, b). However, instead of taking ℓto be the length of the interval, we take it
to be the square root of the length:
ℓ([a, b)) := (b −a)
1
2 .

4.7. CONSTRUCTING OUTER MEASURES, METHOD I.
111
I claim that any half open interval (say [0, 1)) of length one has m∗([a, b)) = 1.
(Since ℓis translation invariant, it does not matter which interval we choose.)
Indeed, m∗([0, 1)) ≤1 by the ﬁrst condition in the theorem, since ℓ([0, 1)) = 1.
On the other hand, if
[0, 1) ⊂
[
i
[ai, bi)
then we know from the Heine-Borel argument that
X
(bi −ai) ≥1,
so squaring gives
X
(bi −ai)
1
2
2
=
X
i
(bi −ai) +
X
i̸=j
(bi −ai)
1
2 (bj −aj)
1
2 ≥1.
So m∗([0, 1)) = 1.
On the other hand, consider an interval [a, b) of length 2. Since it covers
itself, m∗([a, b)) ≤
√
2.
Consider the closed interval I = [0, 1]. Then
I ∩[−1, 1) = [0, 1)
and Ic ∩[−1, 1) = [−1, 0)
so
m∗(I ∩[−1, 1)) + m∗(Ic ∩[−1, 1) = 2 >
√
2 ≥m∗([−1, 1)).
In other words, the closed unit interval is not measurable relative to the outer
measure m∗determined by the theorem. We would like Borel sets to be measur-
able, and the above computation shows that the measure produced by Method
I as above does not have this desirable property. In fact, if we consider two half
open intervals I1 and I2 of length one separated by a small distance of size ϵ,
say, then their union I1 ∪I2 is covered by an interval of length 2 + ϵ, and hence
m∗(I1 ∪I2) ≤
√
2 + ϵ < m∗(I1) + m∗(I2).
In other words, m∗is not additive even on intervals separated by a ﬁnite dis-
tance. It turns out that this is the crucial property that is missing:
4.7.2
Metric outer measures.
Let X be a metric space. An outer measure on X is called a metric outer
measure if
m∗(A ∪B) = m∗(A) + m∗(B) whenver d(A, B) > 0.
(4.15)
The condition d(A, B) > 0 means that there is an ϵ > 0 (depending on A and
B) so that d(x.y) > ϵ for all x ∈A, y ∈B. The main result here is due to
Caratheodory:

112
CHAPTER 4. MEASURE THEORY.
Theorem 4.7.2 If m∗is a metric outer measure on a metric space X, then all
Borel sets of X are m∗measurable.
Proof. Since the σ-ﬁeld of Borel sets is generated by the closed sets, it is enough
to prove that every closed set F is measurable in the sense of Caratheodory, i.e.
that for any set A
m∗(A) ≥m∗(A ∩F) + m∗(A \ F).
Let
Aj := {x ∈A|d(x, F) ≥1
j }.
We have d(Aj, A ∩F) ≥1/j so, since m∗is a metric outer measure, we have
m∗(A ∩F) + m∗(Aj) = m∗((A ∩F) ∪Aj) ≤m∗(A)
(4.16)
since (A ∩F) ∪Aj ⊂A. Now
A \ F =
[
Aj
since F is closed, and hence every point of A not belonging to F must be at a
positive distance from F. We would like to be able to pass to the limit in (4.16).
If the limit on the left is inﬁnite, there is nothing to prove. So we may assume
it is ﬁnite.
Now if x ∈A \ (F ∪Aj+1) there is a z ∈F with d(x, z) < 1/(j + 1) while if
y ∈Aj we have d(y, z) ≥1/j so
d(x, y) ≥d(y, z) −d(x, z) ≥1
j −
1
j + 1 > 0.
Let B1 := A1 and B2 := A2 \ A1, B3 = A3 \ A2 etc. Thus if i ≥j + 2, then
Bj ⊂Aj and
Bi ⊂A \ (F ∪Ai−1) ⊂A \ (F ∪Aj+1)
and so d(Bi, Bj) > 0. So m∗is additive on ﬁnite unions of even or odd B’s:
m∗
 n
[
k=1
B2k−1
!
=
n
X
k=1
m∗(B2k−1),
m∗
 n
[
k=1
B2k
!
=
n
X
k=1
m∗(B2k).
Both of these are ≤m∗(A2n) since the union of the sets involved are contained
in A2n. Since m∗(A2n) is increasing, and assumed bounded, both of the above

4.8. CONSTRUCTING OUTER MEASURES, METHOD II.
113
series converge. Thus
m∗(A/F)
=
m∗[
Ai

=
m∗

Aj ∪
[
k≥j+1
Bj


≤
m∗(Aj) +
∞
X
k=j+1
m∗(Bj)
≤
lim
n→∞m∗(An) +
∞
X
k=j+1
m∗(Bj).
But the sum on the right can be made as small as possible by choosing j large,
since the series converges. Hence
m∗(A/F) ≤lim
n→∞m∗(An)
QED.
4.8
Constructing outer measures, Method II.
Let C ⊂E be two covers, and suppose that ℓis deﬁned on E, and hence, by
restriction, on C. In the deﬁnition (4.14) of the outer measure m∗
ℓ,C associated to
ℓand C, we are minimizing over a smaller collection of covers than in computing
the metric outer measure m∗
ℓ,E using all the sets of E. Hence
m∗
ℓ,C(A) ≥m∗
ℓ,E(A)
for any set A.
We want to apply this remark to the case where X is a metric space, and
we have a cover C with the property that for every x ∈X and every ϵ > 0 there
is a C ∈C with x ∈C and diam(C) < ϵ. In other words, we are assuming that
the
Cϵ := {C ∈C| diam (C) < ϵ}
are covers of X for every ϵ > 0. Then for every set A the
mℓ,Cϵ(A)
are increasing, so we can consider the function on sets given by
m∗
II(A) := sup
ϵ→0
mℓ,Cϵ(A).
The axioms for an outer measure are preserved by this limit operation, so m∗
II
is an outer measure. If A and B are such that d(A, B) > 2ϵ, then any set of
Cϵ which intersects A does not intersect B and vice versa, so throwing away
extraneous sets in a cover of A ∪B which does not intersect either, we see that
m∗
II(A ∪B) = m∗
II(A) + m∗
II(B). The method II construction always yields a
metric outer measure.

114
CHAPTER 4. MEASURE THEORY.
4.8.1
An example.
Let X be the set of all (one sided) inﬁnite sequences of 0’s and 1’s. So a point
of X is an expression of the form
a1a2a3 · · ·
where each ai is 0 or 1. For any ﬁnite sequence α of 0’s or 1’s, let [α] denote
the set of all sequences which begin with α. We also let |α| denote the length
of α, that is, the number of bits in α. For each
0 < r < 1
we deﬁne a metric dr on X by: If
x = αx′,
y = αy′
where the ﬁrst bit in x′ is diﬀerent from the ﬁrst bit in y′ then
dr(x, y) := r|α|.
In other words, the distance between two sequence is rk where k is the length
of the longest initial segment where they agree. Clearly dr(x, y) ≥0 and = 0 if
and only if x = y, and dr(y, x) = dr(x, y). Also, for three x, y, and z we claim
that
dr(x, z) ≤max{dr(x, y), dr(y, z)}.
Indeed, if two of the three points are equal this is obvious. Otherwise, let j
denote the length of the longest common preﬁx of x and y, and let k denote
the length of the longest common preﬁx of y and z. Let m = min(j, k). Then
the ﬁrst m bits of x agree with the ﬁrst m bits of z and so dr(x, z) ≤rm =
max(rj, rk). QED
A metric with this property (which is much stronger than the triangle in-
equality) is called an ultrametric.
Notice that
diam [α] = rα.
(4.17)
The metrics for diﬀerent r are diﬀerent, and we will make use of this fact
shortly. But
Proposition 4.8.1 The spaces (X, dr) are all homeomorphic under the identity
map.
It is enough to show that the identity map is a continuous map from (X, dr) to
(X, ds) since it is one to one and we can interchange the role of r and s. So,
given ϵ > 0, we must ﬁnd a δ > 0 such that if dr(x, y) < δ then ds(x, y) < ϵ. So
choose k so that sk < ϵ. Then letting rk = δ will do.
So although the metrics are diﬀerent, the topologies they deﬁne are the same.

4.8. CONSTRUCTING OUTER MEASURES, METHOD II.
115
There is something special about the value r = 1
2: Let C be the collection of
all sets of the form [α] and let ℓbe deﬁned on C by
ℓ([α]) = (1
2)|α|.
We can construct the method II outer measure associated with this function,
which will satisfy
m∗
II([α]) ≥m∗
I([α])
where m∗
I denotes the method I outer measure associated with ℓ. What is special
about the value 1
2 is that if k = |α| then
ℓ([α]) =
1
2
k
=
1
2
k+1
+
1
2
k+1
= ℓ([α0]) + ℓ([α1]).
So if we also use the metric d 1
2 , we see, by repeating the above, that every [α] can
be written as the disjoint union C1∪· · ·∪Cn of sets in Cϵ with ℓ([α])) = P ℓ(Ci).
Thus m∗
ℓ,Cϵ([α]) ≤ℓ(α) and so m∗
ℓ,Cϵ([α])(A) ≤m∗
I(A) or m∗
II = m∗
I. It also
follows from the above computation that
m∗([α]) = ℓ([α]).
There is also something special about the value s = 1
3: Recall that one of the
deﬁnitions of the Cantor set C is that it consists of all points x ∈[0, 1] which
have a base 3 expansion involving only the symbols 0 and 2. Let
h : X →C
where h sends the bit 1 into the symbol 2, e.g.
h(011001 . . .) = .022002 . . . .
In other words, for any sequence z
h(0z) = h(z)
3
,
h(1z) = h(z) + 2
3
.
(4.18)
I claim that:
1
3d 1
3 (x, y) ≤|h(x) −h(y)| ≤d 1
3 (x, y)
(4.19)
Proof.
If x and y start with diﬀerent bits, say x = 0x′ and y = 1y′ then
d 1
3 (x, y) = 1 while h(x) lies in the interval [0, 1
3] and h(y) lies in the interval
[ 2
3, 1] on the real line. So h(x) and h(y) are at least a distance 1
3 and at most
a distance 1 apart, which is what (4.19) says.
So we proceed by induction.
Suppose we know that (4.19) is true when x = αx′ and y = αy′ with x′, y′
starting with diﬀerent digits, and |α| ≤n. (The above case was where |α| = 0.)

116
CHAPTER 4. MEASURE THEORY.
So if |α| = n + 1 then either and α = 0β or α = 1β and the argument for either
case is similar: We know that (4.19) holds for βx′ and βy′ and
d 1
3 (x, y) = 1
3d 1
3 (βx′, βy′)
while |h(x) −h(y)| =
1
3|h(βx′) −h(βy′)| by (4.18).
Hence (4.19) holds by
induction. QED
In other words, the map h is a Lipschitz map with Lipschitz inverse from
(X, d 1
3 ) to the Cantor set C.
In a short while, after making the appropriate deﬁnitions, these two com-
putations, one with the measure associated to ℓ([α]) =
  1
2
|α| and the other
associated with d 1
3 will show that the “Hausdorﬀdimension” of the Cantor set
is log 2/ log 3.
4.9
Hausdorﬀmeasure.
Let X be a metric space. Recall that if A is any subset of X, the diameter of
A is deﬁned as
diam(A) = sup
x,y∈A
d(x, y).
Take C to be the collection of all subsets of X, and for any positive real number
s deﬁne
ℓs(A) = diam(A)s
(with 0s = 0). Take C to consist of all subsets of X. The method II outer
measure is called the s-dimensional Hausdorﬀouter measure, and its re-
striction to the associated σ-ﬁeld of (Caratheodory) measurable sets is called
the s-dimensional Hausdorﬀmeasure. We will let m∗
s,ϵ denote the method
I outer measure associated to ℓs and ϵ, and let H∗
s denote the Hausdorﬀouter
measure of dimension s, so that
H∗
s(A) = lim
ϵ→0 m∗
s,ϵ(A).
For example, we claim that for X = R, H1 is exactly Lebesgue outer mea-
sure, which we will denote here by L∗. Indeed, if A has diameter r, then A
is contained in a closed interval of length r. Hence L∗(A) ≤r. The Method
I construction theorem says that m∗
1,ϵ is the largest outer measure satisfying
m∗(A) ≤diam A for sets of diameter less than ϵ. Hence m∗
1,ϵ(A) ≥L∗(A) for
all sets A and all ϵ, and so
H∗
1 ≥L∗.
On the other hand, any bounded half open interval [a, b) can be broken up into
a ﬁnite union of half open intervals of length < ϵ, whose sum of diameters is
b −a. So m∗
1,ϵ([a, b) ≤b −a. But the method I construction theorem says that
L∗is the largest outer measure satisfying
m∗([a, b)) ≤b −a.

4.10. HAUSDORFF DIMENSION.
117
Hence H∗
1 ≤L∗So they are equal.
In two or more dimensions, the Hausdorﬀmeasure Hk on Rk diﬀers from
Lebesgue measure by a constant. This is essentially because they assign diﬀerent
values to the ball of diameter one. In two dimensions for example, the Hausdorﬀ
measure H2 assigns the value one to the disk of diameter one, while its Lebesgue
measure is π/4. For this reason, some authors prefer to put this “correction
factor” into the deﬁnition of the Hausdorﬀmeasure, which would involve the
Gamma function for non-integral s. I am following the convention that ﬁnds it
simpler to drop this factor.
Theorem 4.9.1 Let F ⊂X be a Borel set. Let 0 < s < t. Then
Hs(F) < ∞⇒Ht(F) = 0
and
Ht(F) > 0
⇒Hs(F) = ∞.
Indeed, if diam A ≤ϵ, then
m∗
t,ϵ(A) ≤(diam A)t ≤ϵt−s(diam A)s
so by the method I construction theorem we have
m∗
t,ϵ(B) ≤ϵt−sm∗
s,ϵ(B)
for all B. If we take B = F in this equality, then the assumption Hs(F) < ∞
implies that the limit of the right hand side tends to 0 as ϵ →0, so Ht(F) = 0.
The second assertion in the theorem is the contrapositive of the ﬁrst.
4.10
Hausdorﬀdimension.
This last theorem implies that for any Borel set F, there is a unique value s0
(which might be 0 or ∞) such that Ht(F) = ∞for all t < s0 and Hs(F) = 0
for all for all s > s0. This value is called the Hausdorﬀdimension of F. It is
one of many competing (and non-equivalent) deﬁnitions of dimension. Notice
that it is a metric invariant, and in fact is the same for two spaces diﬀerent by
a Lipschitz homeomorphism with Lipschitz inverse. But it is not a topological
invariant. In fact, we shall show that the space X of all sequences of zeros and
one studied above has Hausdorﬀdimension 1 relative to the metric d 1
2 while
it has Hausdorﬀdimension log 2/ log 3 if we use the metric d 1
3 . Since we have
shown that (X, d 1
3 ) is Lipschitz equivalent to the Cantor set C, this will also
prove that C has Hausdorﬀdimension log 2/ log 3.
We ﬁrst discuss the d 1
2 case and use the following lemma
Lemma 4.10.1 If diam(A) > 0, then there is an α such that A ⊂[α] and
diam([α]) = diam A.

118
CHAPTER 4. MEASURE THEORY.
Proof. Given any set A, it has a “longest common preﬁx”. Indeed, consider
the set of lengths of common preﬁxes of elements of A. This is ﬁnite set of
non-negative integers since A has at least two distinct elements. Let n be the
largest of these, and let α be a common preﬁx of this length. Then it is clearly
the longest common preﬁx of A. Hence A ⊂[α] and diam([α]) = diam A.QED
Let C denote the collection of all sets of the form [α] and let ℓbe the function
on C given by
ℓ([α]) = (1
2)|α|,
and let ℓ∗be the associated method I outer measure, and m the associated
measure; all these as we introduced above. We have
ℓ∗(A) ≤ℓ∗([α]) = diam([α]) = diam(A).
By the method I construction theorem, m∗
1,ϵ is the largest outer measure with
the property that n∗(A) ≤diam A for sets of diameter < ϵ. Hence ℓ∗≤m∗
1,ϵ,
and since this is true for all ϵ > 0, we conclude that
ℓ∗≤H∗
1.
On the other hand, for any α and any ϵ > 0, there is an n such that 2−n < ϵ
and n ≥|α|. The set [α] is the disjoint union of all sets [β] ⊂[α] with |β| ≥n,
and there are 2n−|α| of these subsets, each having diameter 2−n. So
m∗
1,ϵ([α]) ≤2−|α|.
However ℓ∗is the largest outer measure satisfying this inequality for all [α].
Hence m∗
1,ϵ ≤ℓ∗for all ϵ so H∗
1 ≤ℓ∗. In other words
H1 = m.
But since we computed that m(X) = 1, we conclude that
The Hausdorﬀdimension of (X, d 1
2 ) is 1.
Now let us turn to (X, d 1
3 ). Then the diameter diam 1
2 relative to the metric
d 1
2 and the diameter diam 1
3 relative to the metric d 1
3 are given by
diam 1
2 ([α]) =
1
2
k
,
diam 1
3 ([α]) =
1
3
k
,
k = |α|.
If we choose s so that 2−k = (3−k)s then
diam 1
2 ([α]) = (diam 1
3 ([α]))s.
This says that relative to the metric d 1
3 , the previous computation yields
Hs(X) = 1.

4.11. PUSH FORWARD.
119
Hence s = log 2/ log 3 is the Hausdorﬀdimension of X.
The material above (with some slight changes in notation) was taken from
the book Measure, Topology, and Fractal Geometry by Gerald Edgar, where a
thorough and delightfully clear discussion can be found of the subjects listed in
the title.
4.11
Push forward.
The above discussion is a sampling of introductory material to what is known
as “geometric measure theory”. However the construction of measures that we
will be mainly working with will be an abstraction of the “simulation” approach
that we have been developing in the problem sets. The setup is as follows: Let
(X, F, m) be a set with a σ-ﬁeld and a measure on it, and let (Y, G) be some
other set with a σ-ﬁeld on it. A map
f : X →Y
is called measurable if
f −1(B) ∈F
∀B ∈G.
We may then deﬁne a measure f∗(m) on (Y, G) by
(f∗)m(B) = m(f −1(B)).
For example, if Yλ is the Poisson random variable from the exercises, and u
is the uniform measure (the restriction of Lebesgue measure to) on [0, 1], then
f∗(u) is the measure on the non-negative integers given by
f∗(u)({k}) = e−λ λk
k! .
It will be this construction of measures and variants on it which will occupy us
over the next few weeks.
4.12
The Hausdorﬀdimension of fractals
4.12.1
Similarity dimension.
Contracting ratio lists.
A ﬁnite collection of real numbers
(r1, . . . , rn)
is called a contracting ratio list if
0 < ri < 1
∀i = 1, . . . , n.

120
CHAPTER 4. MEASURE THEORY.
Proposition 4.12.1 Let (r1, . . . , rn) be a contracting ratio list. There exists a
unique non-negative real number s such that
n
X
i=1
rs
i = 1.
(4.20)
The number s is 0 if and only if n = 1.
Proof. If n = 1 then s = 0 works and is clearly the only solution. If n > 1,
deﬁne the function f on [0, ∞) by
f(t) :=
n
X
i=1
rt
i.
We have
f(0) = n
and
lim
t→∞f(t) = 0 < 1.
Since f is continuous, there is some postive solution to (4.20). To show that
this solution is unique, it is enough to show that f is monotone decreasing. This
follows from the fact that its derivative is
n
X
i=1
rt
i log ri < 0.
QED
Deﬁnition 4.12.1 The number s in (4.20) is called the similarity dimension
of the ratio list (r1, . . . , rn).
Iterated function systems and fractals.
A map f : X →Y between two metric spaces is called a similarity with
similarity ratio r if
dY (f(x1), f(x2)) = rdX(x1, x2) ∀x1, x2 ∈X.
(Recall that a map is called Lipschitz with Lipschitz constant r if we only had
an inequality, ≤, instead of an equality in the above.)
Let X be a complete metric space, and let (r1, . . . , rn) be a contracting ratio
list. A collection
(f1, . . . , fn),
fi : X →X
is called an iterated function system which realizes the contracting ratio
list if
fi : X →X,
i = 1, . . . , n
is a similarity with ratio ri. We also say that (f1, . . . , fn) is a realization of
the ratio list (r1, . . . , rn).
It is a consequence of Hutchinson’s theorem, see below, that

4.12. THE HAUSDORFF DIMENSION OF FRACTALS
121
Proposition 4.12.2 If (f1, . . . , fn) is a realization of the contracting ratio list
(r1, . . . , rn) on a complete metric space, X, then there exists a unique non-empty
compact subset K ⊂X such that
K = f1(K) ∪· · · ∪fn(K).
In fact, Hutchinson’s theorem asserts the corresponding result where the fi are
merely assumed to be Lipschitz maps with Lipschitz constants (r1, . . . , rn).
The set K is sometimes called the fractal associated with the realization
(f1, . . . , fn) of the contracting ratio list (r1, . . . , rn).
The facts we want to
establish are: First,
dim(K) ≤s
(4.21)
where dim denotes Hausdorﬀdimension, and s is the similarity dimension of
(r1, . . . , rn). In general, we can only assert an inequality here, for the the set
K does not ﬁx (r1, . . . , rn) or its realization. For example, we can repeat some
of the ri and the corresponding fi. This will give us a longer list, and hence
a larger s, but will not change K. But we can demand a rather strong form
of non-redundancy known as Moran’s condition: There exists an open set O
such that
O ⊃fi(O) ∀i and fi(O) ∩fj(O) = ∅∀i ̸= j.
(4.22)
Then
Theorem 4.12.1 If (f1, . . . , fn) is a realization of (r1, . . . , rn) on Rd and if
Moran’s condition holds then
dim K = s.
The method of proof of (4.21) will be to construct a “model” complete metric
space E with a realization (g1, . . . , gn) of (r1, . . . , rn) on it, which is “universal”
in the sense that
• E is itself the fractal associated to (g1, . . . , gn).
• The Hausdorﬀdimension of E is s.
• If (f1, . . . , fn) is a realization of (r1, . . . , rn) on a complete metric space
X then there exists a unique continuous map
h : E →X
such that
h ◦gi = fi ◦h.
(4.23)
• The image h(E) of h is K.
• The map h is Lipschitz.
This is clearly enough to prove (4.21).
A little more work will then prove
Moran’s theorem.

122
CHAPTER 4. MEASURE THEORY.
4.12.2
The string model.
Construction of the model.
Let (r1, . . . , rn) be a contracting ratio list, and let A denote the alphabet con-
sisting of the letters {1, . . . , n}. Let E denote the space of one sided inﬁnite
strings of letters from the alphabet A. If α denotes a ﬁnite string (word) of
letters from A, we let wα denote the product over all i occurring in α of the ri.
Thus
w∅= 1
where ∅is the empty string, and, inductively,
wαe = wα · we,
e ∈A.
If x ̸= y are two elements of E, they will have a longest common initial string
α, and we then deﬁne
d(x, y) := wα.
This makes E into a complete ultrametic space. Deﬁne the maps gi : E →E
by
gi(x) = ix.
That is, gi shifts the inﬁnite string one unit to the right and inserts the letter i
in the initial position. In terms of our metric, clearly (g1, . . . , gn) is a realization
of (r1, . . . , rn) and the space E itself is the corresponding fractal set.
We let [α] denote the set of all strings beginning with α, i.e. whose ﬁrst
word (of length equal to the length of α) is α. The diameter of this set is wα.
The Hausdorﬀdimension of E is s.
We begin with a lemma:
Lemma 4.12.1 Let A ⊂E have positive diameter. Then there exists a word α
such that A ⊂[α] and
diam(A) = diam[α] = wα.
Proof. Since A has at least two elements, there will be a γ which is a preﬁx of
one and not the other. So there will be an integer n (possibly zero) which is the
length of the longest common preﬁx of all elements of A. Then every element
of A will begin with this common preﬁx α which thus satisﬁes the conditions of
the lemma. QED
The lemma implies that in computing the Hausdorﬀmeasure or dimension,
we need only consider covers by sets of the form [α]. Now if we choose s to be
the solution of (4.20), then
(diam[α])s =
n
X
i=1
(diam[αi])s = (diam[α])s
n
X
i=1
rs
i .

4.12. THE HAUSDORFF DIMENSION OF FRACTALS
123
This means that the method II outer measure assosicated to the function A 7→
(diam A)s coincides with the method I outer measure and assigns to each set
[α] the measure ws
α. In particular the measure of E is one, and so the Hausdorﬀ
dimension of E is s.
The universality of E.
Let (f1, . . . , fn) a realization of (r1, . . . , rn) on a complete metric space X.
Choose a point a ∈X and deﬁne h0 : E →X by
h0(z) :≡a.
Inductively deﬁne the maps hp by deﬁning hp+1 on each of the open sets [{i}]
by
hp+1(iz) := fi(hp(z)).
The sequence of maps {hp} is Cauchy in the uniform norm. Indeed, if y ∈[{i}]
so y = gi(z) for some z ∈E then
dX (hp+1(y), hp(y)) = dX (fi(hp(z)), fi(hp−1(z))) = ridX (hp(z), hp−1(z))).
So if we let c := maxi(ri) so that 0 < c < 1, we have
sup
y∈E
dX (hp+1(y), hp(y)) ≤c sup
x∈E
dX (hp(x), hp−1(x))
for p ≥1 and hence
sup
y∈E
dX (hp+1(y), hp(y)) < Ccp
for a suitable constant C. This shows that the hp converge uniformly to a limit
h which satisﬁes
h ◦gi = fi ◦h.
Now
hk+1(E) =
[
i
fi (hk(E)) ,
and the proof of Hutchinson’s theorem given below - using the contraction ﬁxed
point theorem for compact sets under the Hausdorﬀmetric - shows that the
sequence of sets hk(E) converges to the fractal K.
Since the image of h is K which is compact, the image of [α] is fα(K) where
we are using the obvious notation fij = fi ◦fj, fijk = fi ◦fj ◦fk etc. The set
fα(K) has diameter wα · diam(K). Thus h is Lipschitz with Lipschitz constant
diam(K).
The uniqueness of the map h follows from the above sort of argument.

124
CHAPTER 4. MEASURE THEORY.
4.13
The Hausdorﬀmetric and Hutchinson’s the-
orem.
Let X be a complete metric space. Let H(X) denote the space of non-empty
compact subsets of X. For any A ∈H(X) and any positive number ϵ, let
Aϵ = {x ∈X|d(x, y) ≤ϵ, for some y ∈A}.
We call Aϵ the ϵ-collar of A. Recall that we deﬁned
d(x, A) = inf
y∈A d(x, y)
to be the distance from any x ∈X to A, then we can write the deﬁnition of the
ϵ-collar as
Aϵ = {x|d(x, A) ≤ϵ}.
Notice that the inﬁmum in the deﬁnition of d(x, A) is actually achieved, that
is, there is some point y ∈A such that
d(x, A) = d(x, y).
This is because A is compact. For a pair of non-empty compact sets, A and B,
deﬁne
d(A, B) = max
x∈A d(x, B).
So
d(A, B) ≤ϵ
⇔
A ⊂Bϵ.
Notice that this condition is not symmetric in A and B. So Hausdorﬀintroduced
h(A, B)
=
max{d(A, B), d(B, A)}
(4.24)
=
inf{ϵ | A ⊂Bϵ and B ⊂Aϵ}.
(4.25)
as a distance on H(X). He proved
Proposition 4.13.1 The function h on H(X) × H(X) satsiﬁes the axioms for
a metric and makes H(X) into a complete metric space. Furthermore, if
A, B, C, D ∈H(X)
then
h(A ∪B, C ∪D) ≤max{h(A, C), h(B, D)}.
(4.26)
Proof. We begin with (4.26). If ϵ is such that A ⊂Cϵ and B ⊂Dϵ then clearly
A ∪B ⊂Cϵ ∪Dϵ = (C ∪D)ϵ. Repeating this argument with the roles of A, C
and B, D interchanged proves (4.26).
We prove that h is a metric: h is symmetric, by deﬁnition. Also, h(A, A) = 0,
and if h(A, B) = 0, then every point of A is within zero distance of B, and

4.13. THE HAUSDORFF METRIC AND HUTCHINSON’S THEOREM. 125
hence must belong to B since B is compact, so A ⊂B and similarly B ⊂A. So
h(A, B) = 0 implies that A = B.
We must prove the triangle inequality. For this it is enough to prove that
d(A, B) ≤d(A, C) + d(C, B),
because interchanging the role of A and B gives the desired result. Now for any
a ∈A we have
d(a, B)
=
min
b∈B d(a, b)
≤
min
b∈B (d(a, c) + d(c, b) ∀c ∈C
=
d(a, c) + min
b∈B d(c, b) ∀c ∈C
=
d(a, c) + d(c, B) ∀c ∈C
≤
d(a, c) + d(C, B) ∀c ∈C.
The second term in the last expression does not depend on c, so minimizing
over c gives
d(a, B) ≤d(a, C) + d(C, B).
Maximizing over a on the right gives
d(a, B) ≤d(A, C) + d(C, B).
Maximizing on the left gives the desired
d(A, B) ≤d(A, C) + d(C, A).
We sketch the proof of completeness. Let An be a sequence of compact non-
empty subsets of X which is Cauchy in the Hausdorﬀmetric. Deﬁne the set
A to be the set of all x ∈X with the property that there exists a sequence of
points xn ∈An with xn →x. It is straighforward to prove that A is compact
and non-empty and is the limit of the An in the Hausdorﬀmetric.
Suppose that κ : X →X is a contraction. Then κ deﬁnes a transformation
on the space of subsets of X (which we continue to denote by κ):
κ(A) = {κx|x ∈A}.
Since κ is continuous, it carries H(X) into itself. Let c be the Lipschitz constant
of κ. Then
d(κ(A), κ(B))
=
max
a∈A[min
b∈B d(κ(a), κ(b))]
≤
max
a∈A[min
b∈B cd(a, b)]
=
cd(A, B).
Similarly, d(κ(B), κ(A)) ≤c d(B, A) and hence
h(κ(A), κ(B)) ≤c h(A, B).
(4.27)

126
CHAPTER 4. MEASURE THEORY.
In other words, a contraction on X induces a contraction on H(X).
The previous remark together with the following observation is the key to
Hutchinson’s remarkable construction of fractals:
Proposition 4.13.2 Let T1, . . . , Tn be a collection of contractions on H(X)
with Lipschitz constants c1, . . . , cn, and let c = max ci. Deﬁne the transforma-
tion T on H(X) by
T(A) = T1(A) ∪T2(A) ∪· · · ∪Tn(A).
Then T is a contraction with Lipschitz constant c.
Proof. By induction, it is enough to prove this for the case n = 2. By (4.26)
h(T(A), T(B))
=
h(T1(A) ∪T2(A), T1(B) ∪T2(B))
≤
max{h(T1(A), h(T1(B)), h(T2(A), T2(B))}
≤
max{c1h(A, B), c2h(A, B)}
=
h(A, B) max{c1, c2} = c · h(A, B)
.
Putting the previous facts together we get Hutchinson’s theorem;
Theorem 4.13.1 Let T1, . . . , Tn be contractions on a complete metric space
and let c be the maximum of their Lipschitz contants. Deﬁne the Hutchinoson
operator T on H(X) by
T(A) := T1(A) ∪· · · ∪Tn(A).
Then T is a contraction with Lipschtz constant c.
4.14
Aﬃne examples
We describe several examples in which X is a subset of a vector space and each
of the Ti in Hutchinson’s theorem are aﬃne transformations of the form
Ti : x 7→Aix + bi
where bi ∈X and Ai is a linear transformation.
4.14.1
The classical Cantor set.
Take X = [0, 1], the unit interval. Take
T1 : x 7→x
3 ,
T2 : x 7→x
3 + 2
3.
These are both contractions, so by Hutchinson’s theorem there exists a unique
closed ﬁxed set C. This is the Cantor set.

4.14. AFFINE EXAMPLES
127
To relate it to Cantor’s original construction, let us go back to the proof of
the contraction ﬁxed point theorem applied to T acting on H(X). It says that
if we start with any non-empty compact subset A0 and keep applying T to it,
i.e. set An = T nA0 then An →C in the Hausdorﬀmetric, h. Suppose we take
the interval I itself as our A0. Then
A1 = T(I) = [0, 1
3] ∪[2
3, 1].
in other words, applying the Hutchinson operator T to the interval [0, 1] has
the eﬀect of deleting the “middle third” open interval ( 1
3, 2
3). Applying T once
more gives
A2 = T 2[0, 1] = [0, 1
9] ∪[2
9, 1
3] ∪[2
3, 7
9] ∪[8
9, 1].
In other words, A2 is obtained from A1 by deleting the middle thirds of each
of the two intervals of A1 and so on. This was Cantor’s original construction.
Since An+1 ⊂An for this choice of initial set, the Hausdorﬀlimit coincides with
the intersection.
But of course Hutchinson’s theorem (and the proof of the contractions ﬁxed
point theorem) says that we can start with any non-empty closed set as our
initial “seed” and then keep applying T. For example, suppose we start with
the one point set B0 = {0}. Then B1 = TB0 is the two point set
B1 = {0, 2
3},
B2 consists of the four point set
B2 = {0, 2
9, 2
3, 8
9}
and so on. We then must take the Hausdorﬀlimit of this increasing collection
of sets.
To describe the limiting set c from this point of view, it is useful to use
triadic expansions of points in [0, 1]. Thus
0
=
.0000000 · · ·
2/3
=
.2000000 · · ·
2/9
=
.0200000 · · ·
8/9
=
.2200000 · · ·
and so on. Thus the set Bn will consist of points whose triadic expansion has
only zeros or twos in the ﬁrst n positions followed by a string of all zeros. Thus
a point will lie in C (be the limit of such points) if and only if it has a triadic
expansion consisting entirely of zeros or twos. This includes the possibility of
an inﬁnite string of all twos at the tail of the expansion. for example, the point
1 which belongs to the Cantor set has a triadic expansion 1 = .222222 · · · .
Similarly the point 2
3 has the triadic expansion 2
3 = .0222222 · · · and so is in

128
CHAPTER 4. MEASURE THEORY.
the limit of the sets Bn. But a point such as .101 · · · is not in the limit of the
Bn and hence not in C. This description of C is also due to Cantor. Notice
that for any point a with triadic expansion a = .a1a2a2 · · ·
T1a = .0a1a2a3 · · · ,
while
T2a = .2a1a2a3 · · · .
Thus if all the entries in the expansion of a are either zero or two, this will also
be true for T1a and T2a. This shows that the C (given by this second Cantor
description) satisﬁes TC ⊂C. On the other hand,
T1(.a2a3 · · · ) = .0a2a3 · · · ,
T2(.a2a3 · · · ) = .2a2a3 · · ·
which shows that .a1a2a3 · · · is in the image of T1 if a1 = 0 or in the image of
T2 if a1 = 2. This shows that TC = C. Since C (according to Cantor’s second
description) is closed, the uniqueness part of the ﬁxed point theorem guarantees
that the second description coincides with the ﬁrst.
The statement that TC = C implies that C is “self-similar”.
4.14.2
The Sierpinski Gasket
Consider the three aﬃne transformations of the plane:
T1 :
 x
y

7→1
2
 x
y

,
T2 :
 x
y

7→1
2
 x
y

+ 1
2
 1
0

,
T3 :
 x
y

7→1
2
 x
y

+ 1
2
 0
1

.
The ﬁxed point of the Hutchinson operator for this choice of T1, T2, T3 is called
the Sierpinski gasket, S. If we take our initial set A0 to be the right triangle
with vertices at

0
0

,

1
0

, and
 0
1

then each of the TiA0 is a similar right triangle whose linear dimensions are one-
half as large, and which shares one common vertex with the original triangle.
In other words,
A1 = TA0
is obtained from our original triangle be deleting the interior of the (reversed)
right triangle whose vertices are the midpoints of our origninal triangle. Just
as in the case of the Cantor set, successive applications of T to this choice of
original set amounts to successive deletions of the “middle” and the Hausdorﬀ
limit is the intersection of all of them: S = T Ai.
We can also start with the one element set
B0
 0
0


4.14. AFFINE EXAMPLES
129
Using a binary expansion for the x and y coordinates, application of T to B0
gives the three element set

0
0

,

.1
0

,

0
.1

.
The set B2 = TB1 will contain nine points, whose binary expansions are ob-
tained from the above three by shifting the x and y exapnsions one unit to the
right and either inserting a 0 before both expansions (the eﬀect of T1), insert a
1 before the expansion of x and a zero before the y or vice versa. Proceding in
this fashion, we see that Bn consists of 3n points which have all 0 in the binary
expansion of the x and y coordinates, past the n-th position, and which are
further constrained by the condition that at no earler point do we have both
xi = 1 and yi = 1. Passing to the limit shows that S consists of all points for
which we can ﬁnd (possible iniﬁnite) binary expansions of the x and y coordi-
nates so that xi = 1 = yi never occurs. (For example x = 1
2, y = 1
2 belongs
to S because we can write x = .10000 · · · , y = .011111 . . . ). Again, from this
(second) description of S in terms of binary expansions it is clear that TS = S.
4.14.3
Moran’s theorem
If A is any set such that f[A] ⊂A, then clearly f p[A] ⊂A by induction. If A
is non-empty and closed, then for any a ∈A, and any x ∈E, the limit of the
fγ(a) belongs to K as γ ranges over the ﬁrst words of size p of x, and so belongs
to K and also to A. Since these points consititute all of K, we see that
K ⊂A
and hence
fβ(K) ⊂fβ(A)
(4.28)
for any word β.
Now suppose that Moran’s open set condition is satisﬁed, and let us write
Oα := fα(O).
Then
Oα ∩Oβ = ∅
if α is not a preﬁx of β or β is not a preﬁx of α. Furthermore,
fβ(O) = fβ(O)
so we can use the symbol
Oβ
unambiguously to denote these two equal sets. By virtue of (4.28) we have
Kβ ⊂Oβ

130
CHAPTER 4. MEASURE THEORY.
where we use Kβ to denote fβ(K). Suppose that α is not a preﬁx of β or vice
versa. Then Kβ ∩Oα = ∅since Oβ ∩Oα = ∅.
Let m denote the measure on the string model E that we constructed above,
so that m(E) = 1 and more generally m([α]) = ws
α. Then we will have proved
that the Hausdorﬀdimension of K is ≥s, and hence = s if we can prove that
there exists a constant b such that for every Borel set B ⊂K
m(h−1(B)) ≤b · diam(B)s,
(4.29)
where h : E →K is the map we constructed above from the string model to K.
Let us introduce the following notation: For any (ﬁnite) non-empty string
α, let α−denote the string (of cardinality one less) obtained by removing the
last letter in α.
Lemma 4.14.1 There exists an integer N such that for any subset B ⊂K the
set QB of all ﬁnite strings α such that
Oα ∩B ̸= ∅
and
diam Oα < diam B ≤diam Oα−
has at most N elements.
Proof. Let
D := diam O.
The map fα is a similarity with similarity ratio diam[α] so
diam Oα = D · diam[α].
Let r := mini ri. Then if α ∈QB we have
diam Oα = D · diam[α] ≥D · r diam[α−] = r diam Oα−≥r diam B.
Let V denote the volume of O relative to the d-dimensional Hausdorﬀmeasure
of Rd, i.e., up to a constant factor the Lebesgue measure. Let Vα denote the
volume of Oα so that Vα = wd
αV = V ·(diam Oα)/ diam O)d. From the preceding
displayed equation it follows that
Vα ≥V rd
Dd (diam B)d.
If x ∈B, then every y ∈Oα is within a distance diam B + diam Oα ≤2 diam B
of x. So if m denotes the number of elements in QB, we have m disjoint sets
with volume at least V rd
Dd (diam B)d all within a ball of radius 2 · diam B. We
have normalized our volume so that the unit ball has volume one, and hence
the ball of radius 2 · diam B has volume 2d(diam B)d. Hence
m · V rd
Dd (diam B)d ≤2d(diam B)d

4.14. AFFINE EXAMPLES
131
or
m ≤2dDd
V rd .
So any integer greater that the right hand side of this inequality (which is
independent of B) will do.
□
Now we turn to the proof of (4.29) which will then complete the proof of
Moran’s theorem. Let B be a Borel subset of K. Then
B ⊂
[
α∈QB
Oα
so
h−1(B) ⊂
[
α∈QB
[α].
Now
([α]) = (diam[α])s =
 1
D diam(Oα)
s
≤1
Ds (diam B)s
and so
m(h−1(B)) ≤
X
α∈QB
m(α) ≤N · 1
Ds (diam B)s
and hence we may take
b = N · 1
Ds (diam B)s
and then (4.29) will hold.

132
CHAPTER 4. MEASURE THEORY.

Chapter 5
The Lebesgue integral.
In what follows, (X, F, m) is a space with a σ-ﬁeld of sets, and m a measure on
F. The purpose of this chapter is to develop the theory of the Lebesgue integral
for functions deﬁned on X. The theory starts with simple functions, that is
functions which take on only ﬁnitely many non-zero values, say {a1, . . . , an} and
where
Ai := f −1(ai) ∈F.
In other words, we start with functions of the form
φ(x) =
n
X
i=1
ai1Ai
Ai ∈F.
(5.1)
Then, for any E ∈F we would like to deﬁne the integral of a simple function
φ over E as
Z
E
φdm =
n
X
i=1
aim(Ai ∩E)
(5.2)
and extend this deﬁnition by some sort of limiting process to a broader class of
functions.
I haven’t yet speciﬁed what the range of the functions should be. Certainly,
even to get started, we have to allow our functions to take values in a vector
space over R, in order that the expression on the right of (5.2) make sense. In
fact, I will eventually allow f to take values in a Banach space. However the
theory is a bit simpler for real valued functions, where the linear order of the
reals makes some arguments easier. Of course it would then be no problem to
pass to any ﬁnite dimensional space over the reals. But we will on occasion
need integrals in inﬁnite dimensional Banach spaces, and that will require a
little reworking of the theory.
133

134
CHAPTER 5. THE LEBESGUE INTEGRAL.
5.1
Real valued measurable functions.
Recall that if (X, F) and (Y, G) are spaces with σ-ﬁelds, then
f : X →Y
is called measurable if
f −1(E) ∈F
∀E ∈G.
(5.3)
Notice that the collection of subsets of Y for which (5.3) holds is a σ-ﬁeld, and
hence if it holds for some collection C, it holds for the σ-ﬁeld generated by C.
For the next few sections we will take Y = R and G = B, the Borel ﬁeld. Since
the collection of open intervals on the line generate the Borel ﬁeld, a real valued
function f : X →R is measurable if and only if
f −1(I) ∈F
for all open intervals I.
Equally well, it is enough to check this for intervals of the form (−∞, a) for all
real numbers a.
Proposition 5.1.1 If F : R2 →R is a continuous function and f, g are two
measurable real valued functions on X, then F(f, g) is measurable.
Proof.
The set F −1(−∞, a) is an open subset of the plane, and hence can be
written as the countable union of products of open intervals I × J. So if we set
h = F(f, g) then h−1((−∞, a)) is the countable union of the sets f −1(I)∩g−1(J)
and hence belongs to F. QED
From this elementary proposition we conclude that if f and g are measurable
real valued functions then
• f + g is measurable (since (x, y) 7→x + y is continuous),
• fg is measurable (since (x, y) 7→xy is continuous), hence
• f1A is measurable for any A ∈F hence
• f + is measurable since f −1([0, ∞]) ∈F and similarly for f −so
• |f| is measurable and so is |f −g|. Hence
• f ∧g and f ∨g are measurable
and so on.
5.2
The integral of a non-negative function.
We are going to allow for the possibility that a function value or an integral
might be inﬁnite. We adopt the convention that
0 · ∞= 0.

5.2. THE INTEGRAL OF A NON-NEGATIVE FUNCTION.
135
Recall that φ is simple if φ takes on a ﬁnite number of distinct non-negative
(ﬁnite) values, a1, . . . , an, and that each of the sets
Ai = φ−1(ai)
is measurable. These sets partition X:
X = A1 ∪· · · ∪An.
Of course since the values are distinct,
Ai ∩Aj = ∅for i ̸= j.
With this deﬁnition, a simple function can be written as in (5.1) and this ex-
pression is unique. So we may take (5.2) as the deﬁnition of the integral of a
simple function. We now extend the deﬁnition to an arbitrary ([0, ∞] valued)
function f by
Z
E
fdm := sup I(E, f)
(5.4)
where
I(E, f) =
Z
E
φdm : 0 ≤φ ≤f, φ simple

.
(5.5)
In other words, we take all integrals of expressions of simple functions φ such
that φ(x) ≤f(x) at all x. We then deﬁne the integral of f as the supremum of
these values.
Notice that if A := f −1(∞) has positive measure, then the simple functions
n1A are all ≤f and so
R
X fdm = ∞.
Proposition 5.2.1 For simple functions, the deﬁnition (5.4) coincides with
deﬁnition (5.2).
Proof. Since φ is ≤itself, the right hand side of (5.2) belongs to I(E, φ) and
hence is ≤
R
E φdm as given by (5.5). We must show the reverse inequality:
Suppose that ψ = P bj1Bj ≤φ. We can write the right hand side of (5.2) as
X
bjm(E ∩Bj) =
X
i,j
bjm(E ∩Ai ∩Bj)
since E ∩Bj is the disjoint union of the sets E ∩Ai∩Bj because the Ai partition
X, and m is additive on disjoint ﬁnite (even countable) unions. On each of the
sets Ai ∩Bj we must have bj ≤ai. Hence
X
i,j
bjm(E ∩Ai ∩Bj) ≤
X
i,j
aim(E ∩Ai ∩Bj) =
X
aim(E ∩Ai)
since the Bj partition X. QED
In the course of the proof of the above proposition we have also established
ψ ≤φ for simple functions implies
Z
E
ψdm ≤
Z
E
φdm.
(5.6)

136
CHAPTER 5. THE LEBESGUE INTEGRAL.
Suppose that E and F are disjoint measurable sets. Then
m(Ai ∩(E ∪F)) = m(Ai ∩E) + m(Ai ∩F)
so each term on the right of (5.2) breaks up into a sum of two terms and we
conclude that
If φ is simple and E ∩F = ∅,
then
Z
E∪F
φdm =
Z
E
φdm +
Z
F
φdm.
(5.7)
Also, it is immediate from (5.2) that if a ≥0 then
If φ is simple then
Z
E
aφdm = a
Z
E
φdm.
(5.8)
It is now immediate that these results extend to all non-negative measurable
functions. We list the results and then prove them. In what follows f and g
are non-negative measurable functions, a ≥0 is a real number and E and F are
measurable sets:
f ≤g
⇒
Z
E
fdm ≤
Z
E
gdm.
(5.9)
Z
E
fdm
=
Z
X
1Efdm
(5.10)
E ⊂F
⇒
Z
E
fdm ≤
Z
F
fdm.
(5.11)
Z
E
afdm
=
a
Z
E
fdm.
(5.12)
m(E) = 0
⇒
Z
E
fdm = 0.
(5.13)
E ∩F = ∅
⇒
Z
E∪F
fdm =
Z
E
fdm +
Z
F
fdm.
(5.14)
f = 0 a.e.
⇔
Z
X
fdm = 0.
(5.15)
f ≤g a.e.
⇒
Z
X
fdm ≤
Z
X
gdm.
(5.16)
Proofs.
(5.9):I(E, f) ⊂I(E, g).
(5.10):
If φ is a simple function with φ ≤f, then multiplying φ by 1E
gives a function which is still ≤f and is still a simple function. The set I(E, f)
is unchanged by considering only simple functions of the form 1Eφ and these
constitute all simple functions ≤1Ef.
(5.11):
We have 1Ef ≤1F f and we can apply (5.9) and (5.10).
(5.12): I(E, af) = aI(E, f).
(5.13):
In the deﬁnition (5.2) all the terms on the right vanish since
m(E ∩Ai) = 0. So I(E, f) consists of the single element 0.

5.2. THE INTEGRAL OF A NON-NEGATIVE FUNCTION.
137
(5.14): This is true for simple functions, so I(E ∪F, f) = I(E, f) + I(F, f)
meaning that every element of I(E ∪F, f) is a sum of an element of I(E, f) and
an element of I(F, f). Thus the sup on the left is ≤the sum of the sups on the
right, proving that the left hand side of (5.14) is ≤its right hand side. To prove
the reverse inequality, choose a simple function φ ≤1Ef and a simple function
ψ ≤1F f. Then φ + ψ ≤1E∪F f since E ∩F = ∅. So φ + ψ is a simple function
≤f and hence
Z
E
φdm +
Z
F
ψdm ≤
Z
E∪F
fdm.
If we now maximize the two summands separately we get
Z
E
fdm +
Z
F
fdm ≤
Z
E∪F
fdm
which is what we want.
(5.15): If f = 0 almost everywhere, and φ ≤f then φ = 0 a.e.
since
φ ≥0. This means that all sets which enter into the right hand side of (5.2)
with ai ̸= 0 have measure zero, so the right hand side vanishes. So I(X, f)
consists of the single element 0. This proves ⇒in (5.15). We wish to prove the
reverse implication. Let A = {x|f(x) > 0}. We wish to show that m(A) = 0.
Now
A =
[
An
where
An := {x|f(x) > 1
n}.
The sets An are increasing, so we know that m(A) = limn→∞m(An). So it is
enough to prove that m(An) = 0 for all n. But
1
n1An ≤f
and is a simple function. So
1
n
Z
X
1Andm = 1
nm(An) ≤
Z
X
fdm = 0
implying that m(An) = 0.
(5.16):
Let E = {x|f(x) ≤g(x)}. Then E is measurable and Ec is of
measure zero. By deﬁnition, 1Ef ≤1Eg everywhere, hence by (5.11)
Z
X
1Efdm ≤
Z
X
1Egdm.
But
Z
X
1Efdm +
Z
X
1Ecfdm =
Z
E
fdm +
Z
Ec fdm =
Z
X
fdm
where we have used (5.14) and (5.13). Similarly for g. QED

138
CHAPTER 5. THE LEBESGUE INTEGRAL.
5.3
Fatou’s lemma.
This says:
Theorem 5.3.1 If {fn} is a sequence of non-negative functions, then
lim
n→∞inf
k≥n
Z
fkdm ≥
Z 
lim
n→∞inf
k≥n fk

dm.
(5.17)
Recall that the limit inferior of a sequence of numbers {an} is deﬁned as follows:
Set
bn := inf
k≥n ak
so that the sequence {bn} is non-decreasing, and hence has a limit (possibly
inﬁnite) which is deﬁned as the lim inf. For a sequence of functions, lim inf fn
is obtained by taking lim inf fn(x) for every x.
Consider the sequence of simple functions {1[n,n+1]}. At each point x the
lim inf is 0, in fact 1[n,n+1](x) becomes and stays 0 as soon as n > x. Thus the
right hand side of (5.17) is zero. The numbers which enter into the left hand
side are all 1, so the left hand side is 1.
Similarly, if we take fn = n1(0,1/n], the left hand side is 1 and the right hand
side is 0.
So without further assumptions, we generally expect to get strict
inequality in Fatou’s lemma.
Proof:
Set
gn := inf
k≥n fk
so that
gn ≤gn+1
and set
f := lim
n→∞inf
k≥n fn = lim
n→∞gn.
Let
φ ≤f
be a simple function. We must show that
Z
φdm ≤lim
n→∞inf
k≥n
Z
fkdm.
(5.18)
There are two cases to consider:
a) m ({x : φ(x) > 0}) = ∞. In this case
R
φdm = ∞and hence
R
fdm = ∞
since φ ≤f. We must show that lim inf
R
fndm = ∞. Let
D := {x : φ(x) > 0}
so m(D) = ∞.
Choose some positive number b < all the positive values taken by φ. This is
possible since there are only ﬁnitely many such values.

5.3. FATOU’S LEMMA.
139
Let
Dn := {x|gn(x) > b}.
The Dn ↗D since b < φ(x) ≤limn→∞gn(x) at each point of D.
Hence
m(Dn) →m(D) = ∞. But
bm(Dn) ≤
Z
Dn
gndm ≤
Z
Dn
fkdm k ≥n
since gn ≤fk for k ≥n. Now
Z
fkdm ≥
Z
Dn
fkdm
since fk is non-negative. Hence lim inf
R
fndm = ∞.
b) m ({x : φ(x) > 0}) < ∞. Choose ϵ > 0 so that it is less than the minimum
of the positive values taken on by φ and set
φϵ(x) =

φ(x) −ϵ
if
φ(x) > 0
0
if
φ(x) = 0.
Let
Cn := {x|gn(x) ≥φϵ}
and
C = {x : f(x) ≥φϵ}.
Then Cn ↗C. We have
Z
Cn
φϵdm
≤
Z
Cn
gndm
≤
Z
Cn
fkdm
k ≥n
≤
Z
C
fkdm
k ≥n
≤
Z
fkdm
k ≥n.
So
Z
Cn
φϵdm ≤lim inf
Z
fkdm.
We will next let n →∞: Let ci be the non-zero values of φϵ so
φϵ =
X
ci1Bi
for some measurable sets Bi ⊂C. Then
Z
Cn
φϵdm =
X
cim(Bi ∩Cn) →
X
cim(Bi) =
Z
φϵdm

140
CHAPTER 5. THE LEBESGUE INTEGRAL.
since (Bi ∩Cn) ↗Bi ∩C = Bi. So
Z
φϵdm ≤lim inf
Z
fkdm.
Now
Z
φϵdm =
Z
φdm −ϵm ({x|φ(x) > 0}) .
Since we are assuming that m ({x|φ(x) > 0}) < ∞, we can let ϵ →0 and
conclude that
R
φdm ≤lim inf
R
fkdm. QED
5.4
The monotone convergence theorem.
We assume that {fn} is a sequence of non-negative measurable functions, and
that fn(x) is an increasing sequence for each x. Deﬁne f(x) to be the limit
(possibly +∞) of this sequence. We describe this situation by fn ↗f. The
monotone convergence theorem asserts that:
fn ≥0,
fn ↗f
⇒
lim
n→∞
Z
fndm =
Z
fdm.
(5.19)
The fn are increasing and all ≤f so the
R
fndm are monotone increasing and
all ≤
R
fdm. So the limit exists and is ≤
R
fdm. On the other hand, Fatou’s
lemma gives
Z
fdm ≤lim inf
Z
fndm = lim
Z
fndm.
QED
In the monotone convergence theorem we need only know that
fn ↗f a.e.
Indeed, let C be the set where convergence holds, so m(Cc) = 0. Let gn = 1Cfn
and g = 1Cf. Then gn ↗g everywhere, so we may apply (5.19) to gn and g.
But
R
gndm =
R
fndm and
R
gdm =
R
fdm so the theorem holds for fn and f
as well.
5.5
The space L1(X, R).
We will say an R valued measurable function is integrable if both
R
f +dm < ∞
and
R
f −dm < ∞. If this happens, we set
Z
fdm :=
Z
f +dm −
Z
f −dm.
(5.20)
Since both numbers on the right are ﬁnite, this diﬀerence makes sense. Some
authors prefer to allow one or the other numbers (but not both) to be inﬁnite,

5.5. THE SPACE L1(X, R).
141
in which case the right hand side of (5.20) might be = ∞or −∞. We will stick
with the above convention.
We will denote the set of all (real valued) integrable functions by L1 or
L1(X) or L1(X, R) depending on how precise we want to be.
Notice that if f ≤g then f + ≤g+ and f −≥g−all of these functions being
non-negative. So
Z
f +dm ≤
Z
g+dm,
Z
f −dm ≥
Z
g−dm
hence
Z
f +dm −
Z
f −dm ≤
Z
g+dm −
Z
g−dm
or
f ≤g
⇒
Z
fdm ≤
Z
gdm.
(5.21)
If a is a non-negative number, then (af)± = af ±. If a < 0 then (af)± =
(−a)f ∓so in all cases we have
Z
afdm = a
Z
fdm.
(5.22)
We now wish to establish
f, g ∈L1 ⇒f + g ∈L1 and
Z
(f + g)dm =
Z
fdm +
Z
gdm.
(5.23)
Proof. We prove this in stages:
• First assume f = P ai1Ai, g = P bi1Bi are non-negative simple func-
tions, where the Ai partition X as do the Bj. Then we can decompose
and recombine the sets to yield:
Z
(f + g)dm
=
X
i,j
(ai + bj)m(Ai ∩Bj)
=
X
i
X
j
aim(Ai ∩Bj) +
X
j
X
i
bjm(Ai ∩Bj)
=
X
i
aim(Ai) +
X
j
bjm(Bj)
=
Z
fdm +
Z
gdm
where we have used the fact that m is additive and the Ai∩Bj are disjoint
sets whose union over j is Ai and whose union over i is Bj.

142
CHAPTER 5. THE LEBESGUE INTEGRAL.
• Next suppose that f and g are non-negative measurable functions with
ﬁnite integrals. Set
fn :=
22n
X
k=0
k
2n 1f −1[ k
2n , k+1
2n ].
Each fn is a simple function ≤f, and passing from fn to fn+1 involves
splitting each of the sets f −1([ k
2n , k+1
2n ]) in the sum into two, and choosing
a larger value on the second portion.
So the fn are increasing.
Also,
if f(x) < ∞, then f(x) < 2m for some m, and for any n > m fn(x)
diﬀers from f(x) by at most 2−n. Hence fn ↗f a.e., since f is ﬁnite
a.e because its integral is ﬁnite. Similarly we can construct gn ↗g. Also
(fn + gn) ↗f + g a.e.
By the a.e. monotone convergence theorem
Z
(f+g)dm = lim
Z
(fn+gn)dm = lim
Z
fndm+lim
Z
gndm =
Z
fdm+
Z
gdm,
where we have used (5.23) for simple functions. This argument shows that
R
(f + g)dm < ∞if both integrals
R
fdm and
R
gdm are ﬁnite.
• For any f ∈L1 we conclude from the preceding that
Z
|f|dm =
Z
(f + + f −)dm < ∞.
Similarly for g. Since |f + g| ≤|f| + |g| we conclude that both (f + g)+
and (f + g)−have ﬁnite integrals. Now
(f + g)+ −(f + g)−= f + g = (f + −f −) + (g+ −g−)
or
(f + g)+ + f −+ g−= f + + g+ + (f + g)−.
All expressions are non-negative and integrable. So integrate both sides
to get (5.23).QED
We have thus established
Theorem 5.5.1 The space L1(X, R) is a real vector space and f 7→
R
fdm is
a linear function on L1(X, R).
We also have
Proposition 5.5.1 If h ∈L1 and
R
A hdm ≥0 for all A ∈F then h ≥0 a.e.
Proof: Let An : {x|h(x) ≤−1
n}. Then
Z
An
hdm ≤
Z
An
−1
n dm = −1
nm(An)

5.6. THE DOMINATED CONVERGENCE THEOREM.
143
so m(An) = 0.
But if we let A := {x|h(x) < 0} then An ↗A and hence
m(A) = 0.QED
We have deﬁned the integral of any function f as
R
fdm =
R
f +dm −
R
f −dm, and
R
|f|dm =
R
f +dm +
R
f −dm. Since for any two non-negative
real numbers a −b ≤a + b we conclude that

Z
fdm
 ≤
Z
|f|dm.
(5.24)
If we deﬁne
∥f∥1 :=
Z
|f|dm
we have veriﬁed that
∥f + g∥1 ≤∥f∥1 + ∥g∥1,
and have also veriﬁed that
∥cf∥1 = |c|∥f∥1.
In other words, ∥· ∥1 is a semi-norm on L1. From the preceding proposition
we know that ∥f∥1 = 0 if and only if f = 0 a.e. The question of whether we
want to pass to the quotient and identify two functions which diﬀer on a set of
measure zero is a matter of taste.
5.6
The dominated convergence theorem.
This says that
Theorem 5.6.1 Let fn be a sequence of measurable functions such that
|fn| ≤g a.e.,
g ∈L1.
Then
fn →f
a.e. ⇒f ∈L1 and
Z
fndm →
Z
fdm.
Proof.
The functions fn are all integrable, since their positive and negative
parts are dominated by g. Assume for the moment that fn ≥0. Then Fatou’s
lemma says that
Z
fdm ≤lim inf
Z
fndm.
Fatou’s lemma applied to g −fn says that
Z
(g −f)dm ≤lim inf
Z
(g −fn)dm = lim inf
Z
gdm −
Z
fndm

=
Z
gdm −lim sup
Z
fndm.

144
CHAPTER 5. THE LEBESGUE INTEGRAL.
Subtracting
R
gdm gives
lim sup
Z
fndm ≤
Z
fdm.
So
lim sup
Z
fndm ≤
Z
fdm ≤lim inf
Z
fndm
which can only happen if all three are equal.
We have proved the result for non-negative fn. For general fn we can write
our hypothesis as
−g ≤fn ≤g a.e..
Adding g to both sides gives
0 ≤fn + g ≤2g a.e..
We now apply the result for non-negative sequences to g +fn and then subtract
oﬀ
R
gdm.
5.7
Riemann integrability.
Suppose that X = [a, b] is an interval.
What is the relation between the
Lebesgue integral and the Riemann integral?
Let us suppose that [a, b] is
bounded and that f is a bounded function, say |f| ≤M. Each partition
P : a = a0 < a1 < · · · < an = b
into intervals Ii = [ai−1, ai] with
mi := m(Ii) = ai −ai−1,
i = 1, . . . , n
deﬁnes a Riemann lower sum
LP =
X
kimi
ki = inf
x∈Ii f(x)
and a Riemann upper sum
UP =
X
Mimi
Mi := sup
x∈Ii
f(x)
which are the Lebesgue integrals of the simple functions
ℓP :=
X
ki1Ii
and uP :=
X
Mi1Ii
respectively.
According to Riemann, we are to choose a sequence of partitions Pn which
reﬁne one another and whose maximal interval lengths go to zero. Write ℓi for
ℓPi and ui for uPi. Then
ℓ1 ≤ℓ2 ≤· · · ≤f ≤· · · ≤u2 ≤u1.

5.8. THE BEPPO - LEVI THEOREM.
145
Suppose that f is measurable. All the functions in the above inequality are
Lebesgue integrable, so dominated convergence implies that
lim Un = lim
Z b
a
undx =
Z b
a
udx
where u = lim un with a similar equation for the lower bounds. The Riemann
integral is deﬁned as the common value of lim Ln and lim Un whenever these
limits are equal.
Proposition 5.7.1 f is Riemann integrable if and only if f is continuous al-
most everywhere.
Proof.
Notice that if x is not an endpoint of any interval in the partitions,
then f is continuous at x if and only if u(x) = ℓ(x). Riemann’s condition for
integrability says that
R
(u−ℓ)dm = 0 which implies that f is continuous almost
everywhere.
Conversely, if f is continuous a.e. then u = f = ℓa.e.. Since u is measurable
so is f, and since we are assuming that f is bounded, we conclude that f
Lebesgue integrable. As ℓ= f = u a.e. their Lebesgue integrals coincide. But
the statement that the Lebesgue integral of u is the same as that of ℓis precisely
the statement of Riemann integrability.QED
Notice that in the course of the proof we have also shown that the Lebesgue
and Riemann integrals coincide when both exist.
5.8
The Beppo - Levi theorem.
We begin with a lemma:
Lemma 5.8.1 Let {gn} be a sequence of non-negative measurable functions.
Then
Z
∞
X
n=1
gn dm =
∞
X
n=1
Z
gndm.
Proof.
We have
Z
n
X
k=1
gkdm =
n
X
k=1
Z
gkdm
for ﬁnite n by the linearity of the integral. Since the gk ≥0, the sums under
the integral sign are increasing, and by deﬁnition converge to P∞
k=1 gk. The
monotone convergence theorem implies the lemma. QED
But both sides of the equation in the lemma might be inﬁnite.
Theorem 5.8.1 Beppo-Levi. Let fn ∈L1 and suppose that
∞
X
k=1
Z
|fk|dm < ∞.

146
CHAPTER 5. THE LEBESGUE INTEGRAL.
Then P fk(x) converges to a ﬁnite limit for almost all x, the sum is integrable,
and
Z
∞
X
k=1
fk dm =
∞
X
k=1
Z
fkdm.
Proof. Take gn := |fn| in the lemma. If we set g = P∞
n=1 gn = P∞
n=1 |fn| then
the lemma says that
Z
gdm =
∞
X
n=1
Z
|fn|dm,
and we are assuming that this sum is ﬁnite. So g is integrable, in particular the
set of x for which g(x) = ∞must have measure zero. In other words,
X
n=1
|fn(x)| < ∞
a.e. .
If a series is absolutely convergent, then it is convergent, so we can say that
P fn(x) converges almost everywhere. Let
f(x) =
∞
X
n=1
fn(x)
at all points where the series converges, and set f(x) = 0 at all other points.
Now

∞
X
n=0
fn(x)
 ≤g(x)
at all points, and hence by the dominated convergence theorem, f ∈L1 and
Z
fdm =
Z
lim
n→∞
n
X
k=1
fk dm = lim
n→∞
X Z
fkdm =
∞
X
k=1
Z
fkdm
QED
5.9
L1 is complete.
This is an immediate corollary of the Beppo-Levi theorem and Fatou’s lemma.
Indeed, suppose that {hn} is a Cauchy sequence in L1. Choose n1 so that
∥hn −hn1∥≤1
2
∀n ≥n1.
Then choose n2 > n1 so that
∥hn −hn2∥≤1
22
∀n ≥n2.

5.10. DENSE SUBSETS OF L1(R, R).
147
Continuing this way, we have produced a subsequence hnj such that
∥hnj+1 −hnj∥≤1
2j .
Let
fj := hnj+1 −hnj.
Then
Z
|fj|dm < 1
2j
so the hypotheses of the Beppo-Levy theorem are satisﬁed, and P fj converges
almost everywhere to some limit f ∈L1. But
hn1 +
k
X
j=1
fj = hnk+1.
So the subsequence hnk converges almost everywhere to some h ∈L1.
We must show that this h is the limit of the hn in the ∥· ∥1 norm. For this
we will use Fatou’s lemma.
For a given ϵ > 0, choose N so that ∥hn −hm∥< ϵ for k, n > N. Since
h = lim hnj we have, for k > N,
∥h −hk∥1 =
Z
|h −hk|dm =
Z
lim
j→∞|hnj −hk|dm ≤lim inf
Z
|hnj −hk|dm
= lim inf ∥hnj −hk∥< ϵ.
QED
5.10
Dense subsets of L1(R, R).
Up until now we have been studying integration on an arbitrary measure space
(X, F, m). In this section and the next, we will take X = R, F to be the
σ-ﬁeld of Lebesgue measurable sets, and m to be Lebesgue measure, in order to
simplify some of the formulations and arguments.
Suppose that f is a Lebesgue integrable non-negative function on R. We
know that for any ϵ > 0 there is a simple function φ such that
φ ≤f
and
Z
fdm −
Z
φdm =
Z
(f −φ)dm = ∥f −φ∥1 < ϵ.
To say that φ is simple implies that
φ =
X
ai1Ai

148
CHAPTER 5. THE LEBESGUE INTEGRAL.
(ﬁnite sum) where each of the ai > 0 and since
R
φdm < ∞each Ai has ﬁnite
measure. Since m(Ai∩[−n, n]) →m(Ai) as n →∞, we may choose n suﬃciently
large so that
∥f −ψ∥1 < 2ϵ
where ψ =
X
ai1Ai∩[−n,n].
For each of the sets Ai ∩[−n, n] we can ﬁnd a bounded open set Ui which
contains it, and such that m(Ui/Ai) is as small as we please. So we can ﬁnd
ﬁnitely many bounded open sets Ui such that
∥f −
X
ai1Ui∥1 < 3ϵ.
Each Ui is a countable union of disjoint open intervals, Ui = S
j Ii,j, and since
m(Ui) = P
j m(Ii,j), we can ﬁnd ﬁnitely many Ii,j, j ranging over a ﬁnite set of
integers, Ji such that m
S
j∈Ji

is as close as we like to m(Ui). So let us call a
step function a function of the form P bi1Ii where the Ii are bounded intervals.
We have shown that we can ﬁnd a step function with positive coeﬃcients which
is as close as we like in the ∥·∥1 norm to f. If f is not necessarily non-negative,
we know (by deﬁnition!) that f + and f −are in L1, and so we can approximate
each by a step function. the triangle inequality then gives
Proposition 5.10.1 The step functions are dense in L1(R, R).
If [a, b], a < b is a ﬁnite interval, we can approximate 1[a,b] as closely as we
like in the ∥· ∥1 norm by continuous functions: just choose n large enough so
that 2
n < b −a, and take the function which is 0 for x < a, rises linearly from 0
to 1 on [a, a + 1
n], is identically 1 on [a + 1
n, b −1
n], and goes down linearly from
1 to 0 from b −1
n to b and stays 0 thereafter. As n →∞this clearly tends to
1[a,b] in the ∥· ∥1 norm. So
Proposition 5.10.2 The continuous functions of compact support are dense in
L1(R, R).
As a consequence of this proposition, we see that we could have avoided all of
measure theory if our sole purpose was to deﬁne the space L1(R, R). We could
have deﬁned it to be the completion of the space of continuous functions of
compact support relative to the ∥· ∥1 norm.
5.11
The Riemann-Lebesgue Lemma.
We will state and prove this in the “generalized form”. Let h be a bounded
measurable function on R. We say that h satisﬁes the averaging condition if
lim
|c|→∞
1
|c|
Z c
0
hdm →0.
(5.25)

5.11. THE RIEMANN-LEBESGUE LEMMA.
149
For example, if h(t) = cos ξt, ξ ̸= 0, then the expression under the limit sign in
the averaging condition is
1
cξ sin ξt
which tends to zero as |c| →∞. Here the oscillations in h are what give rise to
the averaging condition. As another example, let
h(t) =
 1
|t| ≤t
1/|t|
|t| ≥1.
Then the left hand side of (5.25) is
1
|c|(1 + log |c|),
|c| ≥1.
Here the averaging condition is satisﬁed because the integral in (5.25) grows
more slowly that |c|.
Theorem 5.11.1 [Generalized Riemann-Lebesgue Lemma].
Let f ∈L1([c, d], R), −∞≤c < d ≤∞.
If h satisﬁes the averaging
condition (5.25) then
lim
r→∞
Z d
c
f(t)h(rt)dt = 0.
(5.26)
Proof. Our proof will use the density of step functions, Proposition 5.10.1.
We ﬁrst prove the theorem when f = 1[a,b] is the indicator function of a ﬁnite
interval. Suppose for example that 0 ≤a < b.Then the integral on the right
hand side of (5.26) is
Z ∞
0
1[a.b]h(rt)dt
=
Z b
a
h(rt)dt,
or setting x = rt
=
1
r
Z br
0
h(x)dx −1
r
Z ra
0
h(x)dx
and each of these terms tends to 0 by hypothesis. The same argument will work
for any bounded interval [a, b] we will get a sum or diﬀerence of terms as above.
So we have proved (5.26) for indicator functions of intervals and hence for step
functions.
Now let M be such that |h| ≤M everywhere (or almost everywhere) and
choose a step function s so that
∥f −s∥1 ≤
ϵ
2M .
Then fh = (f −s)h + sh

Z
f(t)h(rt)dt

=

Z
(f(t) −s(t)h(rt)dt +
Z
s(t)h(rt)dt

≤

Z
(f(t) −s(t))h(rt)dt
 +

Z
s(t)h(rt)dt

≤
ϵ
2M M +

Z
s(t)h(rt)dt
 .

150
CHAPTER 5. THE LEBESGUE INTEGRAL.
We can make the second term < ϵ
2 by choosing r large enough. QED
5.11.1
The Cantor-Lebesgue theorem.
This says:
Theorem 5.11.2 If a trigonometric series
a0
2 +
X
n
dn cos(nt −φn)
dn ∈R
converges on a set E of positive Lebesgue measure then
dn →0.
(I have written the general form of a real trigonometric series as a cosine series
with phases since we are talking about only real valued functions at the present.
Of course, applied to the real and imaginary parts, the theorem asserts that if
P aneinx converges on a set of positive measure, then the an →0. Also, the
notation suggests - and this is my intention - that the n’s are integers. But in
the proof below all that we will need is that the n’s are any sequence of real
numbers tending to ∞.)
Proof. The proof is a nice application of the dominated convergence theorem,
which was invented by Lebesgue in part precisely to prove this theorem.
We may assume (by passing to a subset if necessary) that E is contained in
some ﬁnite interval [a, b]. If dn ̸→0 then there is an ϵ > 0 and a subsequence
|dnk| > ϵ for all k. If the series converges, all its terms go to 0, so this means
that
cos(nkt −φk) →0
∀t ∈E.
So
cos2(nkt −φk) →0
∀t ∈E.
Now m(E) < ∞and cos2(nkt −φk) ≤1 and the constant 1 is integrable on
[a, b]. So we may take the limit under the integral sign using the dominated
convergence theorem to conclude that
lim
k→∞
Z
E
cos2(nkt −φk)dt =
Z
E
lim
k→∞cos2(nkt −φk)dt = 0.
But
cos2(nkt −φk) = 1
2[1 + cos 2(nkt −φk)]
so
Z
E
cos2(nkt −φk)dt
=
1
2
Z
E
[1 + cos 2(nkt −φk)]dt
=
1
2

m(E) +
Z
E
cos 2(nkt −φk)

=
1
2m(E) + 1
2
Z
R
1E cos 2(nkt −φk)dt.

5.12. FUBINI’S THEOREM.
151
But 1E ∈L1(R, R) so the second term on the last line goes to 0 by the Riemann
Lebesgue Lemma. So the limit is 1
2m(E) instead of 0, a contradiction. QED
5.12
Fubini’s theorem.
This famous theorem asserts that under suitable conditions, a double integral is
equal to an iterated integral. We will prove it for real (and hence ﬁnite dimen-
sional) valued functions on arbitrary measure spaces. (The proof for Banach
space valued functions is a bit more tricky, and we shall omit it as we will not
need it. This is one of the reasons why we have developed the real valued theory
ﬁrst.) We begin with some facts about product σ-ﬁelds.
5.12.1
Product σ-ﬁelds.
Let (X, F) and (Y, G) be spaces with σ-ﬁelds. On X × Y we can consider the
collection P of all sets of the form
A × B,
A ∈F, B ∈G.
The σ-ﬁeld generated by P will, by abuse of language, be denoted by
F × G.
If E is any subset of X × Y , by an even more serious abuse of language we will
let
Ex := {y|(x, y) ∈E}
and (contradictorily) we will let
Ey := {x|(x, y) ∈E}.
The set Ex will be called the x-section of E and the set Ey will be called the
y-section of E.
Finally we will let C ⊂P denote the collection of cylinder sets, that is sets
of the form
A × Y
A ∈F
or
X × B,
B ∈G.
In other words, an element of P is a cylinder set when one of the factors is the
whole space.
Theorem 5.12.1 .
• F × G is generated by the collection of cylinder sets C.

152
CHAPTER 5. THE LEBESGUE INTEGRAL.
• F × G is the smallest σ-ﬁeld on X × Y such that the projections
prX : X × Y →X
prX(x, y) = x
prY : X × Y →Y
prY (x, y) = y
are measurable maps.
• For each E ∈F ×G and all x ∈X the x-section Ex of E belongs to G and
for all y ∈Y the y-section Ey of E belongs to F.
Proof.
A × B = (A × Y ) ∩(X × B) so any σ-ﬁeld containing C must also
contain P. This proves the ﬁrst item.
Since pr−1
X (A) = A × Y , the map prX is measurable, and similarly for Y .
But also, any σ-ﬁeld containing all A × Y and X × B must contain P by what
we just proved. This proves the second item.
As to the third item, any set E of the form A × B has the desired section
properties, since its x section is B if x ∈A or the empty set if x ̸∈A. Similarly
for its y sections. So let H denote the collection of subsets E which have the
property that all Ex ∈G and all Ey ∈F. If we show that H is a σ-ﬁeld we are
done.
Now Ec
x = (Ex)c and similarly for y, so G is closed under taking comple-
ments. Similarly for countable unions:
 [
n
En
!
x
=
[
n
(En)x.
QED
5.12.2
π-systems and λ-systems.
Recall that the σ-ﬁeld σ(C) generated by a collection C of subsets of X is the
intersection of all the σ-ﬁelds containing C. Sometimes the collection C is closed
under ﬁnite intersection. In that case, we call C a π-system. Examples:
• X is a topological space, and C is the collection of open sets in X.
• X = R, and C consists of all half inﬁnite intervals of the form (−∞, a].
We will denote this π system by π(R).
A collection H of subsets of X will be called a λ-system if
1. X ∈H,
2. A, B ∈H with A ∩B = ∅⇒A ∪B ∈H,
3. A, B ∈H and B ⊂A ⇒(A \ B) ∈H, and
4. {An}∞
1 ⊂H and An ↗A ⇒A ∈H.

5.12. FUBINI’S THEOREM.
153
From items 1) and 3) we see that a λ-system is closed under complementa-
tion, and since ∅= Xc it contains the empty set. If B is both a π-system and a
λ system, it is closed under any ﬁnite union, since A∪B = A∪(B/(A∩B) which
is a disjoint union. Any countable union can be written in the form A =↗An
where the An are ﬁnite disjoint unions as we have already argued. So we have
proved
Proposition 5.12.1 If H is both a π-system and a λ-system then it is a σ-ﬁeld.
Also, we have
Proposition 5.12.2 [Dynkin’s lemma.] If C is a π-system, then the σ-ﬁeld
generated by C is the smallest λ-system containing C.
Let M be the σ-ﬁeld generated by C, and H the smallest λ-system containing
C. So M ⊃H. By the preceding proposition, all we need to do is show that H
is a π-system.
Let
H1 := {A| A ∩C ∈H ∀C ∈C}.
Clearly H1 is a λ-system containing C, so H ⊂H1 which means that A∩C ∈H
for all A ∈H and C ∈C.
Let
H2 := {A| A ∩H ∈H ∀H ∈H}.
H2 is again a λ-system, and it contains C by what we have just proved. So
H2 ⊃H, which means that the intersection of two elements of H is again in H,
i.e. H is a π-system. QED
5.12.3
The monotone class theorem.
Theorem 5.12.2 Let B be a class of bounded real valued functions on a space
Z satisfying
1. B is a vector space over R.
2. The constant function 1 belongs to B.
3. B contains the indicator functions 1A for all A belonging to a π-system
I.
4. If {fn} is a sequence of non-negative functions in B and fn ↗f where
fis a bounded function on Z, then f ∈B.
Then B contains every bounded M measurable function, where M is the σ-ﬁeld
generated by I.
Proof.
Let H denote the class of subsets of Z whose indicator functions belong
to B. Then Z ∈H by item 2). If B ⊂A are both in H, then 1A\B = 1A−1B and
so A \ B belongs to H by item 1). Similarly, if A ∩B = ∅then 1A∪B = 1A + 1B

154
CHAPTER 5. THE LEBESGUE INTEGRAL.
and so if A and B belong to H so does A∪B when A∩B = ∅. Finally, condition
4) in the theorem implies condition 4) in the deﬁnition of a λ-system. So we
have proved that that H is a λ-system containing I. So by Dynkin’s lemma, it
contains M.
Now suppose that 0 ≤f ≤K is a bounded M measurable function, where
we may take K to be an integer. For each integer n ≥0 divide the interval
[0, K] up into subintervals of size 2−n, and let
A(n, i) := {z|i2−n ≤f(z) < (i + 1)2−n}
where i ranges from 0 to K2n. Let
sn(z) :=
K2n
X
i=0
i
2n 1A(n,i).
Since f is assumed to be M-measurable, each A(n, i) ∈M, so by the preceding,
and condition 1), fn ∈B. But 0 ≤sn ↗f, and hence by condition 4), f ∈B.
For a general bounded M measurable f, both f + and f −are bounded and
M measurable, and hence by the preceding and condition 1), f = f + −f −∈
B.QED
We now want to apply the monotone class theorem to our situation of a
product space. So Z = X ×Y , where (X, F) and (Y, G) are spaces with σ-ﬁelds,
and where we take I = P to be the π-system consisting of the product sets
A × B,
A ∈F, B ∈G.
Proposition 5.12.3 Let B consist of all bounded real valued functions f on
X × Y which are F × G-measurable, and which have the property that
• for each x ∈X, the function y 7→f(x, y) is G-measurable, and
• for each y ∈Y the function x 7→f(x, y) is F-measurable.
Then B consists of all bounded F × G measurable functions.
Indeed, y 7→1A×B(x, y) = 1B(y) if x ∈A and = 0 otherwise; and similarly for
x 7→1A×B(x, y). So condition 3) of the monotone class theorem is satisﬁed, and
the other conditions are immediate. Since F × G was deﬁned to be the σ-ﬁeld
generated by P, the proposition is an immediate consequence of the monotone
class theorem.
5.12.4
Fubini for ﬁnite measures and bounded functions.
Let (X, F, m) and (Y, G, n) be measure spaces with m(X) < ∞and n(Y ) < ∞.
For every bounded F × G-measurable function f, we know that the function
f(x, ·) : y 7→f(x, y)

5.12. FUBINI’S THEOREM.
155
is bounded and G measurable. Hence it has an integral with respect to the
measure n, which we will denote by
Z
Y
f(x, y)n(dy).
This is a bounded function of x (which we will prove to be F measurable in just
a moment). Similarly we can form
Z
X
f(x, y)m(dx)
which is a function of y.
Proposition 5.12.4 Let B denote the space of bounded F ×G measurable func-
tions such that
•
R
Y f(x, y)n(dy) is a F measurable function on X,
•
R
X f(x, y)m(dx) is a G measurable function on Y and
•
Z
X
Z
Y
f(x, y)n(dy)

m(dx) =
Z
Y
Z
X
f(x, y)m(dx)

n(dy).
(5.27)
Then B consists of all bounded F × G measurable functions.
Proof. We have veriﬁed that the ﬁrst two items hold for 1A×B. Both sides
of (5.27) equal m(A)n(B) as is clear from the proof of Proposition 5.12.3. So
conditions 1-3 of the monotone class theorem are clearly satisﬁed, and condition
4) is a consequence of two double applications of the monotone convergence
theorem. QED
Now for any C ∈F × G we deﬁne
(m×n)(C) :=
Z
X
Z
Y
1C(x, y)n(dy)

m(dx) =
Z
Y
Z
X
1C(x, y)m(dx)

n(dy),
(5.28)
both sides being equal on account of the preceding proposition. This measure
assigns the value m(A)n(B) to any set A×B ∈P, and since P generates F ×G
as a sigma ﬁeld, any two measures which agree on P must agree on F × G.
Hence m × n is the unique measure which assigns the value m(A)n(B) to sets
of P.
Furthermore, we know that
Z
X×Y
f(x, y)(m×n) =
Z
X
Z
Y
f(x, y)n(dy)

m(dx) =
Z
Y
Z
X
f(x, y)m(dx)

n(dy)
(5.29)
is true for functions of the form 1A×B and hence by the monotone class theorem
it is true for all bounded functions which are measurable relative to F × G.
The above assertions are the content of Fubini’s theorem for bounded mea-
sures and functions. We summarize:

156
CHAPTER 5. THE LEBESGUE INTEGRAL.
Theorem 5.12.3 Let (X, F, m) and (Y, G, n) be measure spaces with m(X) <
∞and n(Y ) < ∞. There exists a unique measure on F × G with the property
that
(m × n)(A × B) = m(A)n(B)
∀A × B ∈P.
For any bounded F × G measurable function, the double integral is equal to the
iterated integral in the sense that (5.29) holds.
5.12.5
Extensions to unbounded functions and to σ-ﬁnite
measures.
Suppose that we temporarily keep the condition that m(X) < ∞and n(Y ) < ∞.
Let f be any non-negative F × G-measurable function. We know that (5.29)
holds for all bounded measurable functions, in particular for all simple functions.
We know that we can ﬁnd a sequence of simple functions sn such that sn ↗f.
Hence by several applications of the monotone convergence theorem, we know
that (5.29) is true for all non-negative F × G-measurable functions in the sense
that all three terms are inﬁnite together, or ﬁnite together and equal. Now we
have agreed to call a F × G-measurable function f integrable if and only if f +
and f −have ﬁnite integrals. In this case (5.29) holds.
A measure space (X, F, m) is called σ-ﬁnite if X = S
n Xn where m(Xn) <
∞. In other words, X is σ-ﬁnite if it is a countable union of ﬁnite measure
spaces. As usual, we can then write X as a countable union of disjoint ﬁnite
measure spaces. So if X and Y are σ-ﬁnite, we can write the various integrals
that occur in (5.29) as sums of integrals which occur over ﬁnite measure spaces.
A bit of standard argumentation shows that Fubini continues to hold in this
case.
If X or Y is not σ-ﬁnite, or, even in the ﬁnite case, if f is not non-negative
or m × n integrable, then Fubini need not hold. I hope to present the standard
counter-examples in the problem set.

Chapter 6
The Daniell integral.
Daniell’s idea was to take the axiomatic properties of the integral as the start-
ing point and develop integration for broader and broader classes of functions.
Then derive measure theory as a consequence. Much of the presentation here
is taken from the book Abstract Harmonic Analysis by Lynn Loomis. Some of
the lemmas, propositions and theorems indicate the corresponding sections in
Loomis’s book.
6.1
The Daniell Integral
Let L be a vector space of bounded real valued functions on a set S closed under
∧and ∨. For example, S might be a complete metric space, and L might be
the space of continuous functions of compact support on S.
A map
I : L →R
is called an Integral if
1. I is linear: I(af + bg) = aI(f) + bI(g)
2. I is non-negative: f ≥0 ⇒I(f) ≥0 or equivalently f ≥g ⇒I(f) ≥I(g).
3. fn ↘0 ⇒I(fn) ↘0.
For example, we might take S = Rn, L = the space of continuous functions of
compact support on Rn, and I to be the Riemann integral. The ﬁrst two items
on the above list are clearly satisﬁed. As to the third, we recall Dini’s lemma
from the notes on metric spaces, which says that a sequence of continuous
functions of compact support {fn} on a metric space which satisﬁes fn ↘0
actually converges uniformly to 0. Furthermore the supports of the fn are all
contained in a ﬁxed compact set - for example the support of f1. This establishes
the third item.
157

158
CHAPTER 6. THE DANIELL INTEGRAL.
The plan is now to successively increase the class of functions on which the
integral is deﬁned.
Deﬁne
U := {limits of monotone non-decreasing sequences of elements of L}.
We will use the word “increasing” as synonymous with “monotone non-decreasing”
so as to simplify the language.
Lemma 6.1.1 If fn is an increasing sequence of elements of L and if k ∈L
satisﬁes k ≤lim fn then lim I(fn) ≥I(k).
Proof. If k ∈L and lim fn ≥k, then
fn ∧k ≤k and fn ≥fn ∧k
so I(fn) ≥I(fn ∧k) while
[k −(fn ∧k)] ↘0
so
I([k −fn ∧k]) ↘0
by 3) or
I(fn ∧k) ↗I(k).
Hence lim I(fn) ≥lim I(fn ∧k) = I(k). QED
Lemma 6.1.2 [12C] If {fn} and {gn} are increasing sequences of elements of
L and lim gn ≤lim fn then lim I(gn) ≤lim I(fn).
Proof. Fix m and take k = gm in the previous lemma. Then I(gm) ≤lim I(fn).
Now let m →∞. QED
Thus
fn ↗f and gn ↗f
⇒lim I(fn) = lim I(gn)
so we may extend I to U by setting
I(f) := lim I(fn)
for fn ↗f.
If f ∈L, this coincides with our original I, since we can take gn = f for all n
in the preceding lemma.
We have now extended I from L to U. The next lemma shows that if we
now start with I on U and apply the same procedure again, we do not get any
further.
Lemma 6.1.3 [12D] If fn ∈U and fn ↗f then f ∈U and I(fn) ↗I(f).

6.1. THE DANIELL INTEGRAL
159
Proof.
For each ﬁxed n choose gm
n ↗m fn. Set
hn := gn
1 ∨· · · ∨gn
n
so
hn ∈L
and hn is increasing
with
gn
i ≤hn ≤fn
for i ≤n.
Let n →∞. Then
fi ≤lim hn ≤f.
Now let i →∞. We get
f ≤lim hn ≤f.
So we have written f as a limit of an increasing sequence of elements of L, So
f ∈U. Also
I(gn
i ) ≤I(hn) ≤I(f)
so letting n →∞we get
I(fi) ≤I(f) ≤lim I(fn)
so passing to the limits gives I(f) = lim I(fn). QED
We have
I(f + g) = I(f) + I(g)
for f, g ∈U.
Deﬁne
−U := {−f| f ∈U}
and
I(f) := −I(−f)
f ∈−U.
If f ∈U and −f ∈U then I(f)+I(−f) = I(f−f) = I(0) = 0 so I(−f) = −I(f)
in this case. So the deﬁnition is consistent.
−U is closed under monotone decreasing limits. etc.
If g ∈−U and h ∈U with g ≤h then −g ∈U so h −g ∈U and h −g ≥0
so I(h) −I(g) = I(h + (−g)) = I(h −g) ≥0.
A function f is called I-summable if for every ϵ > 0, ∃g ∈−U, h ∈U
with
g ≤f ≤h,
|I(g)| < ∞, |I(h)| < ∞and I(h −g) ≤ϵ.
For such f deﬁne
I(f) = glb I(h) = lub I(g).
If f ∈U take h = f and fn ∈L with fn ↗f. Then −fn ∈L ⊂U so fn ∈−U.
If I(f) < ∞then we can choose n suﬃciently large so that I(f) −I(fn) < ϵ.
The space of summable functions is denoted by L1. It is clearly a vector space,
and I satisﬁes conditions 1) and 2) above, i.e. is linear and non-negative.

160
CHAPTER 6. THE DANIELL INTEGRAL.
Theorem 6.1.1 [12G] Monotone convergence theorem. fn ∈L1, fn ↗f
and lim I(fn) < ∞⇒f ∈L1 and I(f) = lim I(fn).
Proof.
Replacing fn by fn −f0 we may assume that f0 = 0. Choose
hn ∈U,
such that fn −fn−1 ≤hn and I(hn) ≤I(fn −fn−1) + ϵ
2n .
Then
fn ≤
n
X
1
hi
and
n
X
i=1
I(hi) ≤I(fn) + ϵ.
Since U is closed under monotone increasing limits,
h :=
∞
X
i=1
hi ∈U,
f ≤h
and I(h) ≤lim I(fn) + ϵ.
Since fm ∈L1 we can ﬁnd a gm ∈−U with I(fm) −I(gm) < ϵ and hence for m
large enough I(h) −I(gm) < 2ϵ. So f ∈L1 and I(f) = lim I(fn). QED
6.2
Monotone class theorems.
A collection of functions which is closed under monotone increasing and mono-
tone decreasing limits is called a monotone class.
B is deﬁned to be the
smallest monotone class containing L.
Lemma 6.2.1 Let h ≤k. If M is a monotone class which contains (g ∨h) ∧k
for every g ∈L, then M contains all (f ∨h) ∧k for all f ∈B.
Proof.
The set of f such that (f ∨h) ∧k ∈M is a monotone class containing
L by the distributive laws.QED
Taking h = k = 0 this says that the smallest monotone class containing L+,
the set of non-negative functions in L, is the set B+, the set of non-negative
functions in B.
Here is a series of monotone class theorem style arguments:
Theorem 6.2.1 f, g ∈B ⇒af + bg ∈B, f ∨g ∈B and f ∧g ∈B.
For f ∈B, let
M(f) := {g ∈B|f + g, f ∨g, f ∧g ∈B}.
M(f) is a monotone class. If f ∈L it includes all of L, hence all of B. But
g ∈M(f) ⇔f ∈M(g).
So L ⊂M(g) for any g ∈B, and since it is a monotone class B ⊂M(g). This
says that f, g ∈B ⇒f + g ∈B, f ∧g ∈B and f ∨g ∈B. Similarly, let M be
the class of functions for which cf ∈B for all real c. This is a monotone class
containing L hence contains B. QED

6.3. MEASURE.
161
Lemma 6.2.2 If f ∈B there exists a g ∈U such that f ≤g.
Proof. The limit of a monotone increasing sequence of functions in U belongs
to U. Hence the set of f for which the lemma is true is a monotone class which
contains L. hence it contains B. QED
A function f is L-bounded if there exists a g ∈L+ with |f| ≤g. A class
F of functions is said to be L-monotone if F is closed under monotone limits of
L-bounded functions.
Theorem 6.2.2 The smallest L-monotone class including L+ is B+.
Proof.
Call this smallest family F. If g ∈L+, the set of all f ∈B+ such that
f ∧g ∈F form a monotone class containing L+, hence containing B+ hence
equal to B+. If f ∈B+ and f ≤g then f ∧g = f ∈F. So F contains all L
bounded functions belonging to B+. Let f ∈B+. By the lemma, choose g ∈U
such that f ≤g, and choose gn ∈L+ with gn ↗g. Then f ∧gn ≤gn and so is
L bounded, so f ∧gn ∈F. Since (f ∧gn) →f we see that f ∈F. So
B+ ⊂F.
We know that B+ is a monotone class, in particular an L-monotone class. Hence
F = B+. QED
Deﬁne
L1 := L1 ∩B.
Since L1 and B are both closed under the lattice operations,
f ∈L1 ⇒f ± ∈L1 ⇒|f| ∈L1.
Theorem 6.2.3 If f ∈B then f ∈L1 ⇔∃g ∈L1 with |f| ≤g.
We have proved ⇒: simply take g = |f|. For the converse we may assume that
f ≥0 by applying the result to f + and f −. The family of all h ∈B+ such that
h ∧g ∈L1 is monotone and includes L+ so includes B+. So f = f ∧g ∈L1.
QED
Extend I to all of B+ be setting it = ∞on functions which do not belong
to L1.
6.3
Measure.
Loomis calls a set A integrable if 1A ∈B. The monotone class properties of
B imply that the integrable sets form a σ-ﬁeld. Then deﬁne
µ(A) :=
Z
1A
and the monotone convergence theorem guarantees that µ is a measure.

162
CHAPTER 6. THE DANIELL INTEGRAL.
Add Stone’s axiom
f ∈L ⇒f ∧1 ∈L.
Then the monotone class property implies that this is true with L replaced by
B.
Theorem 6.3.1 f ∈B and a > 0 ⇒then
Aa := {p|f(p) > a}
is an integrable set. If f ∈L1 then
µ(Aa) < ∞.
Proof. Let
fn := [n(f −f ∧a)] ∧1 ∈B.
Then
fn(x) =



1
if
f(x) ≥a + 1
n
0
if
f(x) ≤a
n(f(x) −a)
if
a < f(x) < a + 1
n
.
We have
fn ↗1Aa
so 1Aa ∈B and 0 ≤1Aa ≤1
af +. QED
Theorem 6.3.2 If f ≥0 and Aa is integrable for all a > 0 then f ∈B.
Proof. For δ > 1 deﬁne
Aδ
m := {x|δm < f(x) ≤δm+1}
for m ∈Z and
fδ :=
X
m
δm1Aδ
m.
Each fδ ∈B. Take
δn = 22−n.
Then each successive subdivision divides the previous one into “octaves” and
fδm ↗f. QED
Also
fδ ≤f ≤δfδ
and
I(fδ) =
X
δnµ(Aδ
m) =
Z
fδdµ.
So we have
I(fδ) ≤I(f) ≤δI(fδ)

6.4. H ¨OLDER, MINKOWSKI , LP AND LQ.
163
and
Z
fδdµ ≤
Z
fdµ ≤δ
Z
fδdµ.
So if either of I(f) or
R
fdµ is ﬁnite they both are and
I(f) −
Z
fdµ
 ≤(δ −1)I(fδ) ≤(δ −1)I(f).
So
Z
fdµ = I(f).
If f ∈B+ and a > 0 then
{x|f(x)a > b} = {x|f(x) > b
1
a }.
So f ∈B+ ⇒f a ∈B+ and hence the product of two elements of B+ belongs to
B+ because
fg = 1
4

(f + g)2 −(f −g)2
.
6.4
H¨older, Minkowski , Lp and Lq.
The numbers p, q > 1 are called conjugate if
1
p + 1
q = 1.
This is the same as
pq = p + q
or
(p −1)(q −1) = 1.
This last equation says that if
y = xp−1
then
x = yq−1.
The area under the curve y = xp−1 from 0 to a is
A = ap
p
while the area between the same curve and the y-axis up to y = b
B = bq
q .

164
CHAPTER 6. THE DANIELL INTEGRAL.
Suppose b < ap−1 to ﬁx the ideas. Then area ab of the rectangle is less than
A + B or
ap
p + bq
q ≥ab
with equality if and only if b = ap−1. Replacing a by a
1
p and b by b
1
q gives
a
1
p b
1
q ≤a
p + b
q .
Let Lp denote the space of functions such that |f|p ∈L1. For f ∈Lp deﬁne
∥f∥p :=
Z
|f|pdµ
 1
p
.
We will soon see that if p ≥1 this is a (semi-)norm.
If f ∈Lp and g ∈Lq with ∥f∥p ̸= 0 and ∥g∥q ̸= 0 take
a = |f|p
∥f∥p
,
b = |g|q
∥g∥q
as functions. Then
Z
(|f||g|)dµ ≤∥f∥p∥g∥q
1
p
1
∥f∥p
p
Z
|f|pdµ + 1
q
1
∥g∥q
q
Z
|g|qdµ

= ∥f∥p∥g∥q.
This shows that the left hand side is integrable and that

Z
fgdµ
 ≤∥f∥p∥g∥q
(6.1)
which is known as H¨older’s inequality.
(If either ∥f||p or ∥g∥q = 0 then
fg = 0 a.e. and H¨older’s inequality is trivial.)
We write
(f, g) :=
Z
fgdµ.
Proposition 6.4.1 [Minkowski’s inequality] If f, g ∈Lp, p ≥1 then f+g ∈
Lp and
∥f + g∥p ≤∥f∥p + ∥g∥p.
For p = 1 this is obvious. If p > 1
|f + g|p ≤[2 max(|f|, |g|)]p ≤2p [|f|p + |g|p]
implies that f + g ∈Lp. Write
∥f + g∥p
p ≤I(|f + g|p−1|f|) + I(|f + g|p−1|g|).
Now
q(p −1) = qp −q = p

6.4. H ¨OLDER, MINKOWSKI , LP AND LQ.
165
so
|f + g|p−1 ∈Lq
and its ∥· ∥q norm is
I(|f + g|p)
1
q = I(|f + q|p)1−1
p = I(|f + g|p)
p−1
p
= ∥f + g∥p−1
p
.
So we can write the preceding inequality as
∥f + g∥p
p ≤(|f|, |f + g|p−1) + (|g|, |f + g|p−1)
and apply H¨older’s inequality to conclude that
∥f + g∥p ≤∥f + g∥p−1(∥f∥p + ∥g∥p).
We may divide by ∥f +g∥p−1
p
to get Minkowski’s inequality unless ∥f +g∥p = 0
in which case it is obvious. QED
Theorem 6.4.1 Lp is complete.
Proof. Suppose fn ≥0, fn ∈Lp, and P ∥fn∥p < ∞Then
kn :=
n
X
1
fj ∈Lp
by Minkowski and since kn ↗f we have |kn|p ↗f p and hence by the monotone
convergence theorem f := P∞
j=1 fn ∈Lp and ∥f∥p = lim ∥kn∥p ≤P ∥fj∥p.
Now let {fn} be any Cauchy sequence in Lp. By passing to a subsequence
we may assume that
∥fn+1 −fn∥p < 1
2n .
So P∞
n |fi+1 −fi| ∈Lp and hence
gn := fn −
∞
X
n
|fi+1 −fi| ∈Lp and hn := fn +
∞
X
n
|fi+1 −fi| ∈Lp.
We have
gn+1 −gn = fn+1 −fn + |fn+1 −fn| ≥0
so gn is increasing and similarly hn is decreasing. Hence f := lim gn ∈Lp and
∥f −fn∥p ≤∥hn −gn∥p ≤2−n+2 →0. So the subsequence has a limit which
then must be the limit of the original sequence. QED
Proposition 6.4.2 L is dense in Lp for any 1 ≤p < ∞.
Proof. For p = 1 this was a deﬁning property of L1. More generally, suppose
that f ∈Lp and that f ≥0. Let
An := {x : 1
n < f(x) < n},

166
CHAPTER 6. THE DANIELL INTEGRAL.
and let
gn := f · 1An.
Then (f−gn) ↘0 as n →∞. Choose n suﬃciently large so that ∥f−gn∥p < ϵ/2.
Since
0 ≤gn ≤n1An and µ(An) < npI(|f|p) < ∞
we conclude that
gn ∈L1.
Now choose h ∈L+ so that
∥h −gn∥1 <
 ϵ
2n
p
and also so that h ≤n. Then
∥h −gn∥p
=
(I(|h −gn|p))1/p
=
 I(|h −gn|p−1|h −gn|)
1/p
≤
 I(np−1|h −gn|)
1/p
=
 np−1∥h −gn∥1
1/p
<
ϵ/2.
So by the triangle inequality ∥f −h∥< ϵ. QED
In the above, we have not bothered to pass to the quotient by the elements
of norm zero. In other words, we have not identiﬁed two functions which diﬀer
on a set of measure zero. We will continue with this ambiguity. But equally
well, we could change our notation, and use Lp to denote the quotient space (as
we did earlier in class) and denote the space before we pass to the quotient by
Lp to conform with our earlier notation. I will continue to be sloppy on this
point, in conformity to Loomis’ notation.
6.5
∥· ∥∞is the essential sup norm.
Suppose that f ∈B has the property that it is equal almost everywhere to a
function which is bounded above. We call such a function essentially bounded
(from above). We can then deﬁne the essential least upper bound of f to be
the smallest number which is an upper bound for a function which diﬀers from
f on a set of measure zero. If |f| is essentially bounded, we denote its essential
least upper bound by ∥f∥∞. Otherwise we say that ∥f∥∞= ∞. We let L∞
denote the space of f ∈B which have ∥f∥∞< ∞. It is clear that ∥· ∥∞is a
semi-norm on this space. The justiﬁcation for this notation is
Theorem 6.5.1 [14G] If f ∈Lp for some p > 0 then
∥f∥∞= lim
q→∞∥f∥q.
(6.2)

6.6. THE RADON-NIKODYM THEOREM.
167
Remark. In the statement of the theorem, both sides of (6.2) are allowed to
be ∞.
Proof. If ∥f∥∞= 0, then ∥f∥q = 0 for all q > 0 so the result is trivial in this
case. So let us assume that ∥f∥∞> 0 and let a be any positive number smaller
that ∥f∥∞. In other words,
0 < a < ∥f∥∞.
Let
Aa := ∥x : |f(x)| > a}.
This set has positive measure by the choice of a, and its measure is ﬁnite since
f ∈Lp. Also
∥f∥q ≥
Z
Aa
|f|q
1/q
≥aµ(Aa)1/q.
Letting q →∞gives
lim inf
q→∞∥f∥q ≥a
and since a can be any number < ∥f∥∞we conclude that
lim inf
q→∞∥f∥q ≥∥f∥∞.
So we need to prove that
lim ∥f∥q ≤∥f∥∞.
This is obvious if ∥f∥∞= ∞. So suppose that ∥f∥∞is ﬁnite. Then for q > p
we have
|f|q ≤|f|p(∥f∥∞)q−p
almost everywhere. Integrating and taking the q-th root gives
∥f∥q ≤(∥f∥p)
p
q (∥f∥∞)1−p
q .
Letting q →∞gives the desired result. QED
6.6
The Radon-Nikodym Theorem.
Suppose we are given two integrals, I and J on the same space L. That is, both
I and J satisfy the three conditions of linearity, positivity, and the monotone
limit property that went into our deﬁnition of the term “integral”. We say that
J is absolutely continuous with respect to I if every set which is I null (i.e.
has measure zero with respect to the measure associated to I) is J null.
The integral I is said to be bounded if
I(1) < ∞,
or, what amounts to the same thing, that
µI(S) < ∞

168
CHAPTER 6. THE DANIELL INTEGRAL.
where µI is the measure associated to I.
We will ﬁrst formulate the Radon-Nikodym theorem for the case of bounded
integrals, where there is a very clever proof due to von-Neumman which reduces
it to the Riesz representation theorem in Hilbert space theory.
Theorem 6.6.1 [Radon-Nikodym] Let I and J be bounded integrals, and
suppose that J is absolutely continuous with respect to I. Then there exists an
element f0 ∈L1(I) such that
J(f) = I(ff0)
∀f ∈L1(J).
(6.3)
The element f0 is unique up to equality almost everywhere (with respect to µI).
Proof.(After von-Neumann.) Consider the linear function
K := I + J
on L. Then K satisﬁes all three conditions in our deﬁnition of an integral, and in
addition is bounded. We know from the case p = 2 of Theorem 6.4.1 that L2(K)
is a (real) Hilbert space. (Assume for this argument that we have passed to the
quotient space so an element of L2(K) is an equivalence class of of functions.)
The fact that K is bounded, says that 1 := 1S ∈L2(K). If f ∈L2(K) then the
Cauchy-Schwartz inequality says that
K(|f|) = K(|f| · 1) = (|f|, 1)2,K ≤∥f∥2,K∥1∥2,K < ∞
so |f| and hence f are elements of L1(K).
Furthermore,
|J(f)| ≤J(|f|) ≤K(|f|) ≤∥f∥2,K∥1∥2,K
for all f ∈L. Since we know that L is dense in L2(K) by Proposition 6.4.2, J
extends to a unique continuous linear functional on L2(K). We conclude from
the real version of the Riesz representation theorem, that there exists a unique
g ∈L2(K) such that
J(f) = (f, g)2,K = K(fg).
If A is any subset of S of positive measure, then J(1A) = K(1Ag) so g is non-
negative. (More precisely, g is equivalent almost everywhere to a function which
is non-negative.) We obtain inductively
J(f)
=
K(fg) =
I(fg) + J(fg)
=
I(fg) + I(fg2) + J(fg2) =
...
=
I
 
f ·
n
X
i=1
gi
!
+ J(fgn).
Let N be the set of all x where g(x) ≥1. Taking f = 1N in the preceding string
of equalities shows that
J(1N) ≥nI(1N).
Since n is arbitrary, we have proved

6.6. THE RADON-NIKODYM THEOREM.
169
Lemma 6.6.1 The set where g ≥1 has I measure zero.
We have not yet used the assumption that J is absolutely continuous with
respect to I. Let us now use this assumption to conclude that N is also J-null.
This means that if f ≥0 and f ∈L1(J) then fgn ↘0 almost everywhere (J),
and hence by the dominated convergence theorem
J(fgn) ↘0.
Plugging this back into the above string of equalities shows (by the monotone
convergence theorem for I) that
f
∞
X
i=1
gn
converges in the L1(I) norm to J(f). In particular, since J(1) < ∞, we may
take f = 1 and conclude that P∞
i=1 gi converges in L1(I). So set
f0 :=
∞
X
i=1
gi ∈L1(I).
We have
f0 =
1
1 −g
almost everywhere
so
g = f0 −1
f0
almost everywhere
and
J(f) = I(ff0)
for f ≥0, f ∈L1(J). By breaking any f ∈L1(J) into the diﬀerence of its
positive and negative parts, we conclude that (6.3) holds for all f ∈L1(J). The
uniqueness of f0 (almost everywhere (I)) follows from the uniqueness of g in
L2(K). QED
The Radon Nikodym theorem can be extended in two directions. First of
all, let us continue with our assumption that I and J are bounded, but drop the
absolute continuity requirement. Let us say that an integral H is absolutely
singular with respect to I if there is a set N of I-measure zero such that
J(h) = 0 for any h vanishing on N.
Let us now go back to Lemma 6.6.1. Deﬁne Jsing by
Jsing(f) = J(1Nf).
Then Jsing is singular with respect to I, and we can write
J = Jcont + Jsing
where
Jcont = J −Jsing = J(1Nc·).

170
CHAPTER 6. THE DANIELL INTEGRAL.
Then we can apply the rest of the proof of the Radon Nikodym theorem to Jcont
to conclude that
Jcont(f) = I(ff0)
where f0 = P∞
i=1(1Ncg)i is an element of L1(I) as before. In particular, Jcont
is absolutely continuous with respect to I.
A second extension is to certain situations where S is not of ﬁnite measure.
We say that a function f is locally L1 if f1A ∈L1 for every set A with
µ(A) < ∞. We say that S is σ-ﬁnite with respect to µ if S is a countable union
of sets of ﬁnite µ measure. This is the same as saying that 1 = 1S ∈B. If S
is σ-ﬁnite then it can be written as a disjoint union of sets of ﬁnite measure.
If S is σ-ﬁnite with respect to both I and J it can be written as the disjoint
union of countably many sets which are both I and J ﬁnite. So if J is absolutely
continuous with respect I, we can apply the Radon-Nikodym theorem to each of
these sets of ﬁnite measure, and conclude that there is an f0 which is locally L1
with respect to I, such that J(f) = I(ff0) for all f ∈L1(J), and f0 is unique
up to almost everywhere equality.
6.7
The dual space of Lp.
Recall that H¨older’s inequality (6.1) says that

Z
fgdµ
 ≤∥f∥p∥g∥q
if f ∈Lp and g ∈Lq where
1
p + 1
q = 1.
For the rest of this section we will assume without further mention that this
relation between p and q holds. H¨older’s inequality implies that we have a map
from
Lq →(Lp)∗
sending g ∈Lq to the continuous linear function on Lp which sends
f 7→I(fg) =
Z
fgdµ.
Furthermore, H¨older’s inequality says that the norm of this map from Lq →
(Lp)∗is ≤1. In particular, this map is injective.
The theorem we want to prove is that under suitable conditions on S and
I (which are more general even that σ-ﬁniteness) this map is surjective for
1 ≤p < ∞.
We will ﬁrst prove the theorem in the case where µ(S) < ∞, that is when I
is a bounded integral. For this we will will need a lemma:

6.7. THE DUAL SPACE OF LP .
171
6.7.1
The variations of a bounded functional.
Suppose we start with an arbitrary L and I. For each 1 ≤p ≤∞we have the
norm ∥· ∥p on L which makes L into a real normed linear space. Let F be a
linear function on L which is bounded with respect to this norm, so that
|F(f)| ≤C∥f∥p
for all f ∈L where C is some non-negative constant. The least upper bound of
the set of C which work is called ∥F∥p as usual. If f ≥0 ∈L, deﬁne
F +(f) := lub{F(g) : 0 ≤g ≤f,
g ∈L}.
Then
F +(f) ≥0
and
F +(f) ≤∥F∥p∥f∥p
since F(g) ≤|F(g)| ≤∥F∥p∥g∥p ≤∥F∥p∥f∥p for all 0 ≤g ≤f, g ∈L, since
0 ≤g ≤f implies |g|p ≤|f|p for 1 ≤p < ∞and also implies ∥g∥∞≤∥f∥∞.
Also
F +(cf) = cF +(f)
∀c ≥0
as follows directly from the deﬁnition. Suppose that f1 and f2 are both non-
negative elements of L. If g1, g2 ∈L with
0 ≤g1 ≤f1 and 0 ≤g2 ≤f2
then
F +(f1 + f2) ≥lub F(g1 + g1) = lub F(g1) + lub F(g2) = F +(f1) + F +(f2).
On the other hand, if g ∈L satisﬁes 0 ≤g ≤(f1 +f2) then 0 ≤g ∧f1 ≤f1, and
g∧f1 ∈L. Also g−g∧f1 ∈L and vanishes at points x where g(x) ≤f1(x) while
at points where g(x) > f1(x) we have g(x) −g ∧f1(x) = g(x) −f1(x) ≤f2(x).
So
g −g ∧f1 ≤f2
and so
F +(f1 + f2) = lub F(g) ≤lub F(g ∧f1) + lub F(g −g ∧f1) ≤F +(f1) + F +(f2).
So
F +(f1 + f2) = F +(f1) + F +(f2)
if both f1 and f2 are non-negative elements of L. Now write any f ∈L as
f = f1 −g1 where f1 and g1 are non-negative. (For example we could take
f1 = f + and g1 = f −.) Deﬁne
F +(f) = F +(f1) −F +(g1).

172
CHAPTER 6. THE DANIELL INTEGRAL.
This is well deﬁned, for if we also had f = f2 −g2 then f1 + g2 = f2 + g1 so
F +(f1) + F +(g2) = F +(f1 + g2) = F +(f2 + g1) = F +(f2) + F +(g1)
so
F +(f1) −F +(g1) = F +(f2) −F +(g2).
From this it follows that F + so extended is linear, and
|F +(f)| ≤F +(|f|) ≤∥F∥p∥f∥p
so F + is bounded.
Deﬁne F −by
F −(f) := F +(f) −F(f).
As F −is the diﬀerence of two linear functions it is linear. Since by its deﬁnition,
F +(f) ≥F(f) if f ≥0, we see that F −(f) ≥0 if f ≥0. Clearly ∥F −∥≤
∥F +∥p + ∥F∥≤2∥F∥p. We have proved:
Proposition 6.7.1 Every linear function on L which is bounded with respect
to the ∥· ∥p norm can be written as the diﬀerence F = F + −F −of two lin-
ear functions which are bounded and take non-negative values on non-negative
functions.
In fact, we could formulate this proposition more abstractly as dealing with a
normed vector space which has an order relation consistent with its metric but
we shall refrain from this more abstract formulation.
6.7.2
Duality of Lp and Lq when µ(S) < ∞.
Theorem 6.7.1 Suppose that µ(S) < ∞and that F is a bounded linear func-
tion on Lp with 1 ≤p < ∞. Then there exists a unique g ∈Lq such that
F(f) = (f, g) = I(fg).
Here q = p/(p −1) if p > 1 and q = ∞if p = 1.
Proof. Consider the restriction of F to L. We know that F = F + −F −where
both F + and F −are linear and non-negative and are bounded with respect to
the ∥·∥p norm on L. The monotone convergence theorem implies that if fn ↘0
then ∥fn∥p →0 and the boundedness of F + with respect to the ∥· ∥p says that
∥fn∥p →0
⇒
F +(fn) →0.
So F + satisﬁes all the axioms for an integral, and so does F −. If f vanishes
outside a set of I measure zero, then ∥f∥p = 0. Applied to a function of the form
f = 1A we conclude that if A has µ = µI measure zero, then A has measure
zero with respect to the measures determined by F + or F −. We can apply the

6.7. THE DUAL SPACE OF LP .
173
Radon-Nikodym theorem to conclude that there are functions g+ and g−which
belong to L1(I) and such that
F ±(f) = I(fg±)
for every f which belongs to L1(F ±). In particular, if we set g := g+ −g−then
F(f) = I(fg)
for every function f which is integrable with respect to both F + and F −, in
particular for any f ∈Lp(I). We must show that g ∈Lq.
We ﬁrst treat the case where p > 1. Suppose that 0 ≤f ≤|g| and that f is
bounded. Then
I(f q) ≤I(f q−1 · sgn(g)g) = F(f q−1 · sgn(g)) ≤∥F∥p∥f q−1∥p.
So
I(f q) ≤∥F∥p(I(f (q−1)p))
1
p .
Now (q −1)p = q so we have
I(f q) ≤∥F∥pI(f q)
1
p = ∥F∥pI(f q)1−1
q .
This gives
∥f∥q ≤∥F∥p
for all 0 ≤f ≤|g| with f bounded. We can choose such functions fn with
fn ↗|g|. It follows from the monotone convergence theorem that |g| and hence
g ∈Lq(I). This proves the theorem for p > 1.
Let us now give the argument for p = 1. We want to show that ∥g∥∞≤∥F∥1.
Suppose that ∥g∥∞≥∥F∥1 + ϵ where ϵ > 0. Consider the function 1A where
A := {x : |g(x) ≥∥F∥1 + ϵ
2}.
Then
(∥F∥1 + ϵ
2)µ(A) ≤I(1A|g|) = I(1Asgn(g)g) = F(1Asgn(g))
≤∥F∥1∥1Asgn(g)∥1 = ∥F∥1µ(A)
which is impossible unless µ(A) = 0, contrary to our assumption. QED
6.7.3
The case where µ(S) = ∞.
Here the cases p > 1 and p = 1 may be diﬀerent, depending on “how inﬁnite S
is”.
Let us ﬁrst consider the case where p > 1. If we restrict the functional F to
any subspace of Lp its norm can only decrease. Consider a subspace consisting
of all functions which vanish outside a subset S1 where µ(S1) < ∞. We get

174
CHAPTER 6. THE DANIELL INTEGRAL.
a corresponding function g1 deﬁned on S1 (and set equal to zero oﬀS1) with
∥g1∥q ≤∥F∥p and F(f) = I(fg1) for all f belonging to this subspace. If (S2, g2)
is a second such pair, then the uniqueness part of the theorem shows that g1 = g2
almost everywhere on S1 ∩S2. Thus we can consistently deﬁne g12 on S1 ∪S2.
Let
b := lub{∥gα∥q}
taken over all such gα. Since this set of numbers is bounded by ∥F∥p this least
upper bound is ﬁnite. We can therefore ﬁnd a nested sequence of sets Sn and
corresponding functions gn such that
∥gn∥q ↗b.
By the triangle inequality, if n > m then
∥gn −gm∥q ≤∥gn∥q −∥gm∥q
and so, as in your proof of the L2 Martingale convergence theorem, this sequence
is Cauchy in the ∥· ∥q norm. Hence there is a limit g ∈Lq and g is supported
on
S0 :=
[
Sn.
There can be no pair (S′, g′) with S disjoint from S0 and g′ ̸= 0 on a subset
of positive measure of S′. Indeed, if this were the case, then we could consider
g + g′ on S ∪S′ and this would have a strictly larger ∥· ∥q norm than ∥g∥q = b,
contradicting the deﬁnition of b. (It is at this point in the argument that we use
q < ∞which is the same as p > 1.) Thus F vanishes on any function which is
supported outside S0. We have thus reduced the theorem to the case where S
is σ-ﬁnite.
If S is σ-ﬁnite, decompose S into a disjoint union of sets Ai of ﬁnite measure.
Let fm denote the restriction of f ∈Lp to Am and let hm denote the restriction
of g to Am. Then
∞
X
m=1
fm = f
as a convergent series in Lp and so
F(f) =
X
m
F(fm) =
X
m
Z
Am
fmhm
and this last series converges to I(fg) in L1.
So we have proved that (Lp)∗= Lq in complete generality when p > 1, and
for σ-ﬁnite S when p = 1.
It may happen (and will happen when we consider the Haar integral on the
most general locally compact group) that we don’t even have σ-ﬁniteness. But
we will have the following more complicated condition: Recall that a set A is
called integrable (by Loomis) if 1A ∈B. Now suppose that
S =
[
α
Sα

6.8. INTEGRATION ON LOCALLY COMPACT HAUSDORFF SPACES.175
where this union is disjoint, but possibly uncountable, of integrable sets, and
with the property that every integrable set is contained in at most a countable
union of the Sα. A set A is called measurable if the intersections A ∩Sα are
all integrable, and a function is called measurable if its restriction to each Sα
has the property that the restriction of f to each Sα belongs to B, and further,
that either the restriction of f + to every Sα or the restriction of f −to every
Sα belongs to L1.
If we ﬁnd ourselves in this situation, then we can ﬁnd a gα on each Sα since
Sα is σ-ﬁnite, and piece these all together to get a g deﬁned on all of S. If
f ∈L1 then the set where f ̸= 0 can have intersections with positive measure
with only countably many of the Sα and so we can apply the result for the
σ-ﬁnite case for p = 1 to this more general case as well.
6.8
Integration on locally compact Hausdorﬀspaces.
Suppose that S is a locally compact Hausdorﬀspace. As in the case of Rn,
we can (and will) take L to be the space of continuous functions of compact
support. Dini’s lemma then says that if fn ∈L ↘0 then fn →0 in the uniform
topology.
If A is any subset of S we will denote the set of f ∈L whose support is
contained in A by LA.
Lemma 6.8.1 A non-negative linear function I is bounded in the uniform norm
on LC whenever C is compact.
Proof. Choose g ≥0 ∈L so that g(x) ≥1 for x ∈C. If f ∈LC then
|f| ≤∥f∥∞g
so
|I(f)| ≤I(|f|) ≤I(g) · ∥f∥∞. QED.
6.8.1
Riesz representation theorems.
This is the same Riesz, but two more theorems.
Theorem 6.8.1 Every non-negative linear functional I on L is an integral.
Proof. This is Dini’s lemma together with the preceding lemma. Indeed, by
Dini we know that fn ∈L ↘0 implies that ∥fn∥∞↘0. Since f1 has compact
support, let C be its support, a compact set. All the succeeding fn are then
also supported in C and so by the preceding lemma I(fn) ↘0. QED
Theorem 6.8.2 Let F be a bounded linear function on L (with respect to the
uniform norm). Then there are two integrals I+ and I−such that
F(f) = I+(f) −I−(f).

176
CHAPTER 6. THE DANIELL INTEGRAL.
Proof. We apply Proposition 6.7.1 to the case of our L and with the uniform
norm, ∥· ∥∞. We get
F = F + −F −
and an examination of he proof will show that in fact
∥F ±∥∞≤∥F∥∞.
By the preceding theorem, F ± are both integrals. QED
6.8.2
Fubini’s theorem.
Theorem 6.8.3 Let S1 and S2 be locally compact Hausdorﬀspaces and let I
and J be non-negative linear functionals on L(S1) and L(S2) respectively. Then
Ix(Jyh(x, y)) = Jy(Ix(h(x, y))
for every h ∈L(S1 × S2) in the obvious notation, and this common value is an
integral on L(S1 × S2).
Proof via Stone-Weierstrass. The equation in the theorem is clearly true
if h(x, y) = f(x)g(y) where f ∈L(S1) and g ∈L(S2) and so it is true for any
h which can be written as a ﬁnite sum of such functions. Let h be a general
element of L(S1 × S2). then we can ﬁnd compact subsets C1 ⊂S1 and C2 ⊂S2
such that h is supported in the compact set C1 × C2. The functions of the form
X
fi(x)gi(y)
where the fi are all supported in C1 and the gi in C2, and the sum is ﬁnite,
form an algebra which separates points. So for any ϵ > 0 we can ﬁnd a k of the
above form with
∥h −k∥∞< ϵ.
Let B1 and B2 be bounds for I on L(C1) and J on L(C2) as provided by Lemma
6.8.1. Then
|Jyh(x, y) −
X
J(gi)fi(x)| = |[Jy(f −k)](x)| < ϵB2.
This shows that Jyh(x, y) is the uniform limit of continuous functions supported
in C1 and so Jyh(x, y) is itself continuous and supported in C1. It then follows
that Ix(Jy(h) is deﬁned, and that
|Ix(Jyh(x, y) −
X
I(f)iJ(gi)| ≤ϵB1B2.
Doing things in the reverse order shows that
Ix(Jyh(x, y)) −Jy(Ix(h(x, y))| ≤2ϵB1B2.

6.9. THE RIESZ REPRESENTATION THEOREM REDUX.
177
Since ϵ is arbitrary, this gives the equality in the theorem. Since this (same)
functional is non-negative, it is an integral by the ﬁrst of the Riesz representation
theorems above. QED
Let X be a locally compact Hausdorﬀspace, and let L denote the space of
continuous functions of compact support on X. Recall that the Riesz represen-
tation theorem (one of them) asserts that any non-negative linear function I on
L satisﬁes the starting axioms for the Daniell integral, and hence corresponds
to a measure µ deﬁned on a σ-ﬁeld, and such that I(f) is given by integration
of f relative to this measure for any f ∈L.
6.9
The Riesz representation theorem redux.
I want to give an alternative proof of the Riesz representation theorem which
will give some information about the possible σ-ﬁelds on which µ is deﬁned. In
particular, I want to show that we can ﬁnd a µ (which is possibly an extension
of the µ given by our previous proof of the Riesz representation theorem) which
is deﬁned on a σ-ﬁeld which contains the Borel ﬁeld B(X). Recall that B(X) is
the smallest σ-ﬁeld which contains the open sets.
Let F be a σ-ﬁeld which contains B(X). A (non-negative valued) measure
µ on F is called regular if
1. µ(K) < ∞for any compact subset K ⊂X.
2. For any A ∈F
µ(A) = inf{µ(U) : A ⊂U, U open}
3. If U ⊂X is open then
µ(U) = sup{µ(K) : K ⊂U,
K compact }.
The second condition is called outer regularity and the third condition is
called inner regularity.
6.9.1
Statement of the theorem.
Here is the improved version of the Riesz representation theorem:
Theorem 6.9.1 Let X be a locally compact Hausdorﬀspace, L the space of
continuous functions of compact support on X, and I a non-negative linear
functional on L. Then there exists a σ-ﬁeld F containing B(X) and a non-
negative regular measure µ on F such that
I(f) =
Z
fdµ
(6.4)
for all f ∈L. Furthermore, the restriction of µ to B(X) is unique.

178
CHAPTER 6. THE DANIELL INTEGRAL.
The proof of this theorem hinges on some topological facts whose true place is
in the chapter on metric spaces, but I will prove them here. The importance
of the theorem is that it will allow us to derive some conclusions about spaces
which are very huge (such as the space of “all” paths in Rn) but are nevertheless
locally compact (in fact compact) Hausdorﬀspaces. It is because we want to
consider such spaces, that the earlier proof, which hinged on taking limits of
sequences in the very deﬁnition of the Daniell integral, is insuﬃcient to get at
the results we want.
6.9.2
Propositions in topology.
Proposition 6.9.1 Let X be a Hausdorﬀspace, and let H and K be disjoint
compact subsets of X. Then there exist disjoint open subsets U and V of X
such that H ⊂U and K ⊂V .
This we actually did prove in the chapter on metric spaces.
Proposition 6.9.2 Let X be a locally compact Hausdorﬀspace, x ∈X, and U
an open set containing x. Then there exists an open set O such that
• x ∈O
• O is compact, and
• O ⊂U.
Proof. Choose an open neighborhood W of x whose closure is compact, which
is possible since we are assuming that X is locally compact. Let Z = U ∩W so
that Z is compact and hence so is H := Z \ Z. Take K := {x} in the preceding
proposition. We then get an open set V containing x which is disjoint from an
open set G containing Z \ Z. Take O := V ∩Z. Then x ∈O and O ⊂Z is
compact and O has empty intersection with Z \ Z, and hence is is contained in
Z ⊂U. QED
Proposition 6.9.3 Let X be a locally compact Hausdorﬀspace, K ⊂U with
K compact and U open subsets of X. Then there exists a V with
K ⊂V ⊂V ⊂U
with V open and V compact.
Proof. Each x ∈K has a neighborhood O with compact closure contained
in U, by the preceding proposition. The set of these O cover K, so a ﬁnite
subcollection of them cover K and the union of this ﬁnite subcollection gives
the desired V .
Proposition 6.9.4 Let X be a locally compact Hausdorﬀspace, K ⊂U with K
compact and U open. Then there exists a continuous function h with compact
support such that
1K ≤h ≤1U

6.9. THE RIESZ REPRESENTATION THEOREM REDUX.
179
and
Supp(h) ⊂U.
Proof. Choose V as in Proposition 6.9.3. By Urysohn’s lemma applied to the
compact space V we can ﬁnd a function h : V →[0, 1] such that h = 1 on K
and f = 0 on V \V . Extend h to be zero on the complement of V . Then h does
the trick.
Proposition 6.9.5 Let X be a locally compact Hausdorﬀspace, f ∈L, i.e. f
is a continuous function of compact support on X. Suppose that there are open
subsets U1, . . . Un such that
Supp(f) ⊂
n
[
i=1
Ui.
Then there are f1, . . . , fn ∈L such that
Supp(fi) ⊂Ui
and
f = f1 + · · · + fn.
If f is non-negative, the fi can be chosen so as to be non-negative.
Proof. By induction, it is enough to consider the case n = 2. Let K := Supp(f),
so K ⊂U1 ∪U2. Let
L1 := K \ U1,
L2 := K \ U2.
So L1 and L2 are disjoint compact sets. By Proposition 6.9.1 we can ﬁnd disjoint
open sets V1, V2 with
L1 ⊂V1,
L2 ⊂V2.
Set
K1 := K \ V1,
K2 := K \ V2.
Then K1 and K2 are compact, and
K = K1 ∪K2,
K1 ⊂U1, K2 ⊂U2.
Choose h1 and h2 as in Proposition 6.9.4. Then set
φ1 := h1,
φ2 := h2 −h1 ∧h2.
Then Supp(φ1) = Supp(h1) ⊂U1 by construction, and Supp(φ2) ⊂Supp(h2) ⊂
U2, the φi take values in [0, 1], and, if x ∈K = Supp(f)
φ1(x) + φ2(x) = (h1 ∨h2)(x) = 1.
Then set
f1 := φ1f,
f2 := φ2f.
QED

180
CHAPTER 6. THE DANIELL INTEGRAL.
6.9.3
Proof of the uniqueness of the µ restricted to B(X).
It is enough to prove that
µ(U)
=
sup{I(f) : f ∈L, 0 ≤f ≤1U}
(6.5)
=
sup{I(f) : f ∈L, 0 ≤f ≤1U,
Supp(f) ⊂U}
(6.6)
for any open set U, since either of these equations determines µ on any open
set U and hence for the Borel ﬁeld.
Since f ≤1U and both are measurable functions, it is clear that µ(U) =
R
1U
is at least as large as the expression on the right hand side of (6.5). This in
turn is as least as large as the right hand side of (6.6) since the supremum in
(6.6) is taken over as smaller set of functions that that of (6.5). So it is enough
to prove that µ(U) is ≤the right hand side of (6.6).
Let a < µ(U). Interior regularity implies that we can ﬁnd a compact set
K ⊂U with
a < µ(K).
Take the f provided by Proposition 6.9.4. Then a < I(f), and so the right hand
side of (6.6) is ≥a. Since a was any number < µ(U), we conclude that µ(U) is
≤the right hand side of 6.6). QED
6.10
Existence.
We will
• deﬁne a function m∗deﬁned on all subsets,
• show that it is an outer measure,
• show that the set of measurable sets in the sense of Caratheodory include
all the Borel sets, and that
• integration with respect to the associated measure µ assigns I(f) to every
f ∈L.
6.10.1
Deﬁnition.
Deﬁne m∗on open sets by
m∗(U) = sup{I(f) : f ∈L, 0 ≤f ≤1U, Supp(f) ⊂U}.
(6.7)
Clearly, if U ⊂V are open subsets, m∗(U) ≤m∗(V ). Next deﬁne m∗on an
arbitrary subset by
m∗(A) = inf{m∗(U) : A ⊂U, U open}.
(6.8)
Since U is contained in itself, this does not change the deﬁnition on open sets.
It is clear that m∗(∅) = 0 and that A ⊂B implies that m∗(A) ≤m∗(B). So

6.10. EXISTENCE.
181
to prove that m∗is an outer measure we must prove countable subadditivity.
We will ﬁrst prove countable subadditivity on open sets, and then use the ϵ/2n
argument to conclude countable subadditivity on all sets:
Suppose {Un} is a sequence of open sets. We wish to prove that
m∗
 [
n
Un
!
≤
X
n
m∗(Un).
(6.9)
Set
U :=
[
n
Un,
and suppose that
f ∈L, 0 ≤f ≤1U, Supp(f) ⊂U.
Since Supp(f) is compact and contained in U, it is covered by ﬁnitely many of
the Ui. In other words, there is some ﬁnite integer N such that
Supp(f) ⊂
N
[
n=1
Un.
By Proposition 6.9.5 we can write
f = f1 + · · · + fN,
Supp(fi) ⊂Ui,
i = 1, . . . , N.
Then
I(f) =
X
I(fi) ≤
X
m∗(Ui),
using the deﬁnition (6.7). Replacing the ﬁnite sum on the right hand side of
this inequality by the inﬁnite sum, and then taking the supremum over f proves
(6.9), where we use the deﬁnition (6.7) once again.
Next let {An} be any sequence of subsets of X. We wish to prove that
m∗
 [
n
An
!
≤
X
n
m∗(An).
This is automatic if the right hand side is inﬁnite. So assume that
X
n
m∗(An) < ∞
and choose open sets Un ⊃An so that
m∗(Un) ≤m∗(An) + ϵ
2n .
Then U := S Un is an open set containing A := S An and
m∗(A) ≤m∗(U) ≤
X
m∗(U)i ≤
X
n
m∗(An) + ϵ.
Since ϵ is arbitrary, we have proved countable subadditivity.

182
CHAPTER 6. THE DANIELL INTEGRAL.
6.10.2
Measurability of the Borel sets.
Let F denote the collection of subsets which are measurable in the sense of
Caratheodory for the outer measure m∗. We wish to prove that F ⊃B(X).
Since B(X) is the σ-ﬁeld generated by the open sets, it is enough to show that
every open set is measurable in the sense of Caratheodory, i.e. that
m∗(A) ≥m∗(A ∩U) + m∗(A ∩U c)
(6.10)
for any open set U and any set A with m∗(A) < ∞: If ϵ > 0, choose an open
set V ⊃A with
m∗(V ) ≤m∗(A) + ϵ
which is possible by the deﬁnition (6.8). We will show that
m∗(V ) ≥m∗(V ∩U) + m∗(V ∩U c) −2ϵ.
(6.11)
This will then imply that
m∗(A) ≥m∗(A ∩U) + m∗(A ∩U c) −3ϵ
and since ϵ > 0 is arbitrary, this will imply (6.10).
Using the deﬁnition (6.7), we can ﬁnd an f1 ∈L such that
f1 ≤1V ∩U
and
Supp(f1) ⊂V ∩U
with
I(f1) ≥m∗(V ∩U) −ϵ.
Let K := Supp(f1). Then K ⊂U and so Kc ⊃U c and Kc is open. Hence
V ∩Kc is an open set and
V ∩Kc ⊃V ∩U c.
Using the deﬁnition (6.7), we can ﬁnd an f2 ∈L such that
f2 ≤1V ∩Kc
and
Supp(f2) ⊂V ∩Kc
with
I(f2) ≥m∗(V ∩Kc) −ϵ.
But m∗(V ∩Kc) ≥m∗(V ∩U c) since V ∩Kc ⊃V ∩U c. So
I(f2) ≥m∗(V ∩U c) −ϵ.
So
f1 + f2 ≤1K + 1V ∩Kc ≤1V
since K = Supp(f1) ⊂V and Supp(f2) ⊂V ∩Kc. Also
Supp(f1 + f2) ⊂(K ∪V ∩Kc) = V.
Thus f = f1 + f2 ∈L and so by (6.7),
I(f1 + f2) ≤m∗(V ).
This proves (6.11) and hence that all Borel sets are measurable.

6.10. EXISTENCE.
183
6.10.3
Compact sets have ﬁnite measure.
Let µ be the measure associated to m on the σ-ﬁeld F of measurable sets. We
will now prove that µ is regular. The condition of outer regularity is automatic,
since this was how we deﬁned µ(A) = m∗(A) for a general set.
If K is a compact subset of X, we can ﬁnd an f ∈L such that 1K ≤f by
Proposition 6.9.4. Let 0 < ϵ < 1 and set
Uϵ := {x : f(x) > 1 −ϵ}.
Then Uϵ is an open set containing K. If 0 ≤g ∈L satisﬁes g ≤1Uϵ, then g = 0
on U c
ϵ , and for x ∈Uϵ, g(x) ≤1 while f(x) > 1 −ϵ. So
g ≤
1
1 −ϵf
and hence, by (6.7)
m∗(Uϵ) ≤
1
1 −ϵI(f).
So, by (6.8)
µ(K) ≤m∗(Uϵ) ≤
1
1 −ϵI(f) < ∞.
Reviewing the preceding argument, we see that we have in fact proved the
more general statement
Proposition 6.10.1 If A is any subset of X and f ∈L is such that
1A ≤f
then
m∗(A) ≤I(f).
6.10.4
Interior regularity.
We now prove interior regularity, which will be very important for us. We wish
to prove that
µ(U) = sup{µ(K) : K ⊂U,
K compact },
for any open set U, where, according to (6.7),
m∗(U) = sup{I(f) : f ∈L, 0 ≤f ≤1U, Supp(f) ⊂U}.
Since Supp(f) is compact, and contained in U, we will be done if we show that
f ∈L,
0 ≤f ≤1 ⇒I(f) ≤µ(Supp(f)).
(6.12)
So let V be an open set containing Supp(f). By deﬁnition (6.7),
µ(V ) ≥I(f)

184
CHAPTER 6. THE DANIELL INTEGRAL.
and, since V is an arbitrary open set containing Supp(f), we have
µ(Supp(f)) ≥I(f)
using the deﬁnition (6.8) of m∗(Supp(f)).
In the course of this argument we have proved
Proposition 6.10.2 If g ∈L, 0 ≤g ≤1K where K is compact, then
I(g) ≤µ(K).
6.10.5
Conclusion of the proof.
Finally, we must show that all the elements of L are integrable with respect to
µ and
I(f) =
Z
fdµ.
(6.13)
Since the elements of L are continuous, they are Borel measurable. As every
f ∈L can be written as the diﬀerence of two non-negative elements of L, and as
both sides of (6.13) are linear in f, it is enough to prove (6.13) for non-negative
functions.
Following Lebesgue, divide the “y-axis” up into intervals of size ϵ. That is,
let ϵ be a positive number, and, for every positive integer n set
fn(x) :=



0
if
f(x) ≤(n −1)ϵ
f(x) −(n −1)ϵ
if
(n −1)ϵ < f(x) ≤nϵ
ϵ
if
nϵ < f(x)
If (n−1)ϵ ≥∥f∥∞only the ﬁrst alternative can occur, so all but ﬁnitely many of
the fn vanish, and they all are continuous and have compact support so belong
to L. Also
f =
X
fn
this sum being ﬁnite, as we have observed, and so
I(f) =
X
I(fn).
Set K0 := Supp(f) and
Kn := {x : f(x) ≥nϵ} n = 1, 2, . . . .
Then the Ki are a nested decreasing collection of compact sets, and
ϵ1Kn ≤fn ≤ϵ1Kn−1.
By Propositions 6.10.1 and6.10.2 we have
ϵµ(Kn) ≤I(fn) ≤ϵµ(Kn−1).

6.10. EXISTENCE.
185
On the other hand, the monotonicity of the integral (and its deﬁnition) imply
that
ϵµ(Kn) ≤
Z
fndµ ≤ϵµ(Kn−1).
Summing these inequalities gives
ϵ
N
X
i=1
µ(Kn)
≤I(f)
≤ϵ
N−1
X
i=0
µ(Kn)
ϵ
N
X
i=1
µ(Kn)
≤
R
fdµ
ϵ
N−1
X
i=0
µ(Kn)
where N is suﬃciently large. Thus I(f) and
R
fdµ lie within a distance
ϵ
N−1
X
i=0
µ(Kn) −ϵ
N
X
i=1
µ(Kn) = ϵµ(K0) −ϵµ(KN) ≤ϵµ(Supp(f))
of one another. Since ϵ is arbitrary, we have proved (6.13) and completed the
proof of the Riesz representation theorem.

186
CHAPTER 6. THE DANIELL INTEGRAL.

Chapter 7
Wiener measure, Brownian
motion and white noise.
7.1
Wiener measure.
We begin by constructing Wiener measure following a paper by Nelson, Journal
of Mathematical Physics 5 (1964) 332-343.
7.1.1
The Big Path Space.
Let ˙Rn denote the one point compactiﬁcation of Rn. Let
Ω:=
Y
0≤t<∞
˙Rn
(7.1)
be the product of copies of ˙Rn, one for each non-negative t. This is an uncount-
able product, and so a huge space, but by Tychonoﬀ’s theorem, it is compact
and Hausdorﬀ. We can think of a point ω of Ωas being a function from R+ to
˙Rn, i.e. as as a “curve” with no restrictions whatsoever.
Let F be a continuous function on the m-fold product:
F :
m
Y
i=1
˙Rn →R,
and let t1 ≤t2 ≤· · · ≤tm be ﬁxed “times”. Deﬁne
φ = φF ;t1,...,tm : Ω→R
by
φ(ω) := F(ω(t1), . . . , ω(tm)).
We can call such a function a ﬁnite function since its value at ω depends only
on the values of ω at ﬁnitely many points. The set of such functions satisﬁes our
187

188CHAPTER 7. WIENER MEASURE, BROWNIAN MOTION AND WHITE NOISE.
abstract axioms for a space on which we can deﬁne integration. Furthermore,
the set of such functions is an algebra containing 1 and which separates points,
so is dense in C(Ω) by the Stone-Weierstrass theorem. Let us call the space of
such functions Cfin(Ω).
If we deﬁne an integral I on Cfin(Ω) then, by the Stone-Weierstrass theorem
it extends to C(Ω) and therefore, by the Riesz representation theorem, gives us
a regular Borel measure on Ω.
For each x ∈Rn we are going to deﬁne such an integral, Ix by
Ix(φ) =
Z
· · ·
Z
F(x1, x2, . . . , xm)p(x, x1; t1)p(x1, x2; t2−t1) · · · p(xm−1, xm, tm−tm−1)dx1 . . . dxm
when φ = φF,t1,...,tm where
p(x, y; t) =
1
(2πt)n/2 e−(x−y)2/2t
(7.2)
(with p(x, ∞) = 0) and all integrations are over ˙Rn. In order to check that this
is well deﬁned, we have to verify that if F does not depend on a given xi then
we get the same answer if we deﬁne φ in terms of the corresponding function of
the remaining m −1 variables. This amounts to the computation
Z
p(x, y; s)p(y, z, t)dy = p(x, z; s + t).
If n = 1 this is the computation
1
2πt
Z
R
e−(x−y)2/2se−(y−z)22tdy =
1
2π(s + t)e(x−z)2/2(s+t).
If we make the change of variables u = x −y this becomes
nt ⋆ns = nt+s
where
nr(x) :=
1
√re−x2/2r.
In terms of our “scaling operator” Sa given by Saf(x) = f(ax) we can write
nr = r−1
2 Sr−1
2 n
where n is the unit Gaussian n(x) = e−x2/2. Now the Fourier transform takes
convolution into multiplication, satisﬁes
(Saf)ˆ= (1/a)S1/a ˆf,

7.1. WIENER MEASURE.
189
and takes the unit Gaussian into the unit Gaussian. Thus upon Fourier trans-
form, the equation nt ⋆ns = nt+s becomes the obvious fact that
e−sξ2/2e−tξ2/2 = e−(s+t)ξ2/2.
The same proof (or an iterated version of the one dimensional result) applies in
n-dimensions.
So, for each x ∈Rn we have deﬁned a measure on Ω.
We denote the
measure corresponding to Ix by prx. It is a probability measure in the sense
that prx(Ω) = 1.
The intuitive idea behind the deﬁnition of prx is that it assigns probability
prx(E) :=
Z
E1
· · ·
Z
Em
p(x, x1; t1)p(x1, x2; t2 −t1) · · · p(xm−1, xm, tm −tm−1)dx1 . . . dxm
to the set of all paths ω which start at x and pass through the set E1 at time
t1, the set E2 at time t2 etc. and we have denoted this set of paths by E.
7.1.2
The heat equation.
We pause to reﬂect upon the computation we did in the preceding section.
Deﬁne the operator Tt on the space S (or on S′) by
(Ttf)(x) =
Z
Rn p(x, y, t)f(y)dy.
(7.3)
In other words, Tt is the operation of convolution with
t−n/2e−x2/2t.
We have veriﬁed that
Tt ◦Ts = Tt+s.
(7.4)
Also, we have veriﬁed that when we take Fourier transforms,
(Ttf)ˆ(ξ) = e−tξ2/2 ˆf(ξ).
(7.5)
If we let t →0 in this equation we get
lim
t→0 Tt = Identity.
(7.6)
Using some language we will introduce later, conditions (7.4) and (7.6) say that
the Tt form a continuous semi-group of operators. If we diﬀerentiate (7.5) with
respect to t, and let
u(t, x) := (Ttf)(x)
we see that u is a solution of the “heat equation”
∂2u
(∂t)2 =
∂2u
(∂x1)2 + · · · +
∂2u
(∂xn)2

190CHAPTER 7. WIENER MEASURE, BROWNIAN MOTION AND WHITE NOISE.
with the initial conditions u(0, x) = f(x). In terms of the operator
∆:= −

∂2
(∂x1)2 + · · · +
∂2
(∂xn)2

we are tempted to write
Tt = e−t∆,
in analogy to our study of elliptic operators on compact manifolds. We will
spend lot of time justifying these kind of formulas in the non-compact setting
later on in the course.
7.1.3
Paths are continuous with probability one.
The purpose of this subsection is to prove that if we use the measure prx, then
the set of discontinuous paths has measure zero.
We begin with some technical issues. We recall that the statement that a
measure µ is regular means that for any Borel set A
µ(A) = inf{µ(G) : A ⊂G, G open }
and for any open set U
µ(U) = sup{µ(K) : K ⊂U, K compact}.
This second condition has the following consequence: Suppose that Γ is any
collection of open sets which is closed under ﬁnite union. If
O =
[
G∈Γ
G
then
µ(O) = sup
G∈Γ
µ(G)
since any compact subset of O is covered by ﬁnitely many sets belonging to Γ.
The importance of this stems from the fact that we can allow Γ to consist of
uncountably many open sets, and we will need to impose uncountably many
conditions in singling out the space of continuous paths, for example. Indeed,
our ﬁrst task will be to show that the measure prx is concentrated on the space
of continuous paths in Rn which do not go to inﬁnity too fast.
We begin with the following computation in one dimension:
pr0({|ω(t)| > r}) = 2 ·
 1
2πt
1/2 Z ∞
r
e−x2/2tdx ≤
 2
πt
1/2 Z ∞
r
x
r e−x2/2tdx =
 2
πt
1/2 t
r
Z ∞
r
x
t e−x2/2tdx =
2t
π
1/2 e−r2/2t
r
.

7.1. WIENER MEASURE.
191
For ﬁxed r this tends to zero (very fast) as t →0. In n-dimensions ∥y∥> ϵ
(in the Euclidean norm) implies that at least one of its coordinates yi satisﬁes
|yi| > ϵ/√n so we ﬁnd that
prx({|ω(t) −x| > ϵ}) ≤ce−ϵ2/2nt
for a suitable constant depending only on n. In particular, if we let ρ(ϵ, δ) denote
the supremum of the above probability over all 0 < t ≤δ then
ρ(ϵ, δ) = o(δ).
(7.7)
Lemma 7.1.1 Let 0 ≤t1 ≤· · · ≤tm with tm −t1 ≤δ. Let
A := {ω| |ω(tj) −ω(t1)| > ϵ
for some j = 1, . . . m}.
Then
prx(A) ≤2ρ(1
2ϵ, δ)
(7.8)
independently of the number m of steps.
Proof. Let
B := {ω| |ω(t1) −ω(tm)| > 1
2ϵ}
let
Ci := {ω| |ω(ti) −ω(tm)| > 1
2ϵ}
and let
Di := {ω| |ω(t1) −ω(ti)| > ϵ and |ω(t1) −ω(tk)| ≤ϵ k = 1, . . . i −1}.
If ω ∈A, then ω ∈Di for some i by the deﬁnition of A, by taking i to be the
ﬁrst j that works in the deﬁnition of A. If ω ̸∈B and ω ∈Di then ω ∈Ci
since it has to move a distance of at least 1
2ϵ to get back from outside the ball
of radius ϵ to inside the ball of radius 1
2ϵ. So we have
A ⊂B ∪
m
[
i=1
(Ci ∩Di)
and hence
prx(A) ≤prx(B) +
m
X
i=1
prx(Ci ∩Di).
(7.9)
Now we can estimate prx(Ci∩Di) as follows. For ω to belong to this intersection,
we must have ω ∈Di and then the path moves a distance at least ϵ
2 in time
tn −ti and these two events are independent, so prx(Ci ∩Di) ≤ρ( ϵ
2, δ) prx(Di).
Here is this argument in more detail: Let
F = 1{(y,z)| |y−z|> 1
2 ϵ}

192CHAPTER 7. WIENER MEASURE, BROWNIAN MOTION AND WHITE NOISE.
so that
1Ci = φF,ti,tn.
Similarly, let G be the indicator function of the subset of ˙Rn × ˙Rn × · · · × ˙Rn
(i copies) consisting of all points with
|xk −x1| ≤ϵ,
k = 1, . . . , i −1,
|x1 −xi| > ϵ
so that
1Di = φG,t1,...,tj.
Then
prx(Ci ∩Di) =
Z
. . .
Z
p(x, x1; t1) · · · p(xi−1, xi; ti−ti−1)F(x1, . . . , xi)G(xi, xn)p(xi, xn; tn−ti)dx1 · · · dxn.
The last integral (with respect to xn) is ≤ρ( 1
2ϵ, δ). Thus
prx(Ci ∩Di) ≤ρ( ϵ
2, δ) prx(Di).
The Di are disjoint by deﬁnition, so
X
prx(Di) ≤prx(
[
Di) ≤1.
So
prx(A) ≤prx(B) + ρ(1
2ϵ, δ) ≤2ρ(1
2ϵ, δ).
QED
Let
E : {ω||ω(ti) −ω(tj)| > 2ϵ for some 1 ≤j < k ≤m}.
Then E ⊂A since if |ω(tj) −ω(tk)| > 2ϵ then either |ω(t1) −ω(tj)| > ϵ or
|ω(t1) −ω(tk)| > ϵ (or both). So
prx(E) ≤2ρ(1
2ϵ, δ).
(7.10)
Lemma 7.1.2 Let 0 ≤a < b with b −a ≤δ. Let
E(a, b, ϵ) := {ω| |ω(s) −ω(t)| > 2ϵ for some s, t ∈[a, b]}.
Then
prx(E(a, b.ϵ)) ≤2ρ(1
2ϵ, δ).
Proof.
Here is where we are going to use the regularity of the measure. Let
S denote a ﬁnite subset of [a, b] and and let
E(a, b, ϵ, S) := {ω| |ω(s) −ω(t)| > 2ϵ for some s, t ∈S}.

7.1. WIENER MEASURE.
193
Then E(a, b, ϵ, S) is an open set and prx(E(a, b, ϵ, S)) < 2ρ( 1
2ϵ, δ) for any S. The
union over all S of the E(a, b, ϵ, S) is E(a, b, ϵ). The regularity of the measure
now implies the lemma. QED
Let k and n be integers, and set
δ := 1
n.
Let
F(k, ϵ, δ) := {ω| |ω(t) −ω(s)| > 4ϵ for some t, s ∈[0, k], with |t −s| < δ}.
Then we claim that
prx(F(k, ϵ, δ)) < 2k ρ( 1
2ϵ, δ)
δ
.
(7.11)
Indeed, [0, k] is the union of the nk = k/δ subintervals [0, δ], [δ, 2δ], . . . , [k−δ, δ].
If ω ∈F(k, ϵ, δ) then |ω(s) −ω(t)| > 4ϵ for some s and t which lie in either
the same or in adjacent subintervals. So ω must lie in E(a, b, ϵ) for one of these
subintervals, and there are kn of them. QED
Let ω ∈Ωbe a continuous path in Rn. Restricted to any interval [0, k]
it is uniformly continuous. This means that for any ϵ > 0 it belongs to the
complement of the set F(k, ϵ, δ) for some δ. We can let ϵ = 1/p for some integer
p. Let C denote the set of continuous paths from [0, ∞) to Rn. Then
C =
\
k
\
ϵ
[
δ
F(k, ϵ, δ)c
so the complement Cc of the set of continuous paths is
[
k
[
ϵ
\
δ
F(k, ϵ, δ),
a countable union of sets of measure zero since
prx
 \
δ
F(k, ϵ, δ)
!
≤lim
δ→0 2kρ(1
2ϵ, δ)/δ = 0.
We have thus proved a famous theorem of Wiener:
Theorem 7.1.1 [Wiener.] The measure prx is concentrated on the space of
continuous paths, i.e. prx(C) = 1. In particular, there is a probability measure
on the space of continuous paths starting at the origin which assigns probability
pr0(E) =
Z
E1
· · ·
Z
Em
p(0, x1; t1)p(x1, x2; t2 −t1) · · · p(xm−1, xm, tm −tm−1)dx1 . . . dxm
to the set of all paths ω which start at 0 and pass through the set E1 at time t1,
the set E2 at time t2 etc. and we have denoted this set of paths by E.

194CHAPTER 7. WIENER MEASURE, BROWNIAN MOTION AND WHITE NOISE.
7.1.4
Embedding in S′.
For convenience in notation let me now specialize to the case n = 1. Let
W ⊂C
consist of those paths ω with ω(0) = 0 and
Z ∞
0
(1 + t)−2w(t)dt < ∞.
Proposition 7.1.1 [Stroock] The Wiener measure pr0 is concentrated on W.
Indeed, we let E(|ω(t)|) denote the expectation of the function |ω(t)| of ω with
respect to Wiener measure, so
E(|ω(t)|) =
1
√
2πt
Z
R
|x|e−x2/2tdx =
1
√
2πt · t
Z ∞
0
x
t e−x2/tdx = Ct1/2.
Thus, by Fubini,
E
Z ∞
0
(1 + t)−2|w(t)|dt

=
Z ∞
0
(1 + t)−2E(|w(t)|) < ∞.
Hence the set of ω with
R ∞
0 (1+t)−2|w(t)|dt = ∞must have measure zero. QED
Now each element of W deﬁnes a tempered distribution, i.e. an element of
S′ according to the rule
⟨ω, φ⟩=
Z ∞
0
ω(t)φ(t)dt.
(7.12)
We claim that this map from W to S′ is measurable and hence
the Wiener measure pushes forward to give a measure on S′.
To see this, let us ﬁrst put a diﬀerent topology (of uniform convergence) on
W. In other words, for each ω ∈W let Uϵ(ω) consist of all ω1 such that
sup
t≥0
|ω1(t) −ω(t)| < ϵ,
and take these to form a basis for a topology on W. Since we put the weak
topology on S′ it is clear that the map (7.12) is continuous relative to this new
topology. So it will be suﬃcient to show that each set Uϵ(ω) is of the form
A ∩W where A is in B(Ω), the Borel ﬁeld associated to the (product) topology
on Ω.
So ﬁrst consider the subsets Vn,ϵ(ω) of W consisting of all ω1 ∈W such that
sup
t≥0
|ω1(t) −ω(t)| ≤ϵ −1
n.

7.2. STOCHASTIC PROCESSES AND GENERALIZED STOCHASTIC PROCESSES.195
Clearly
Uϵ(ω) =
[
n
Vn,ϵ(ω),
a countable union, so it is enough to show that each Vn,ϵ(ω) is of the form
An ∩W where An ∈B(X). Now by the deﬁnition of the topology on Ω, if r is
any real number, the set
An,r := {ω1| |ω1(r) −ω(r)| ≤ϵ −1
n
is closed. So if we let r range over the non-negative rational numbers Q+, then
An =
\
r∈Q+
An,r
belongs to B(Ω). But if ω1 is continuous, then if ω1 ∈An then supt∈R+ |ω1(t) −
ω(t)| ≤ϵ −1
n, and so
An ∩W = Vn,ϵ(ω)
as was to be proved.
7.2
Stochastic processes and generalized stochas-
tic processes.
In the standard probability literature a stochastic process is deﬁned as follows:
one is given an index set T and for each t ∈T one has a random variable X(t).
More precisely, one has some probability triple (Ω, F, P) and for each t ∈T a
real valued measurable function on (Ω, F). So a stochastic process X is just
a collection X = {X(t), t ∈T} of random variables. Usually T = Z or Z+ in
which case we call X a discrete time random process or T = R or R+ in
which case we call X a continuous time random process. Thus the word
process means that we are thinking of T as representing the set of all times.
A realization of X, that is the set X(t)(ω) for some ω ∈Ωis called a sample
path. If T is one of the above choices, then X is said to have independent
increments if for all t0 < t1 < t2 < · · · < tn the random variables
X(t1) −X(t0), X(t1) −X(t1), . . . , X(tn) −X(tn−1)
are independent.
For example, consider Wiener measure, and let X(t)(ω) = ω(t) (say for n =
1). This is a continuous time stochastic process with independent increments
which is known as (one dimensional) Brownian motion. The idea (due to
Einstein) is that one has a small (visible) particle which, in any interval of time
is subject to many random bombardments in either direction by small invisible
particles (say molecules) so that the central limit theorem applies to tell us
that the change in the position of the particle is Gaussian with mean zero and
variance equal to the length of the interval.

196CHAPTER 7. WIENER MEASURE, BROWNIAN MOTION AND WHITE NOISE.
Suppose that X is a continuous time random variable with the property that
for almost all ω, the sample path X(t)(ω) is continuous. Let φ be a continuous
function of compact support. Then the Riemann approximating sums to the
integral
Z
T
X(t)(ω)φ(t)dt
will converge for almost all ω and hence we get a random variable
⟨X, φ⟩
where
⟨X, φ⟩(ω) =
Z
T
X(t)(ω)φ(t)dt,
the right hand side being deﬁned (almost everywhere) as the limit of the Rie-
mann approximating sums.
The same will be true if φ vanishes rapidly at inﬁnity and the sample paths
satisfy (a.e.)
a slow growth condition such as given by Proposition 7.1.1 in
addition to being continuous a.e.
The notation ⟨X, φ⟩is justiﬁed since ⟨X, φ⟩clearly depends linearly on φ.
But now we can make the following deﬁnition due to Gelfand.
We may
restrict φ further by requiring that φ belong to D or S. We then consider a rule
Z which assigns to each such φ a random variable which we might denote by Z(φ)
or ⟨Z, φ⟩and which depends linearly on φ and satisﬁes appropriate continuity
conditions. Such an object is called a generalized random process. The
idea is that (just as in the case of generalized functions) we may not be able to
evaluated Z(t) at a given time t, but may be able to evaluate a “smeared out
version” Z(φ).
The purpose of the next few sections is to do the following computation: We
wish to show that for the case Brownian motion, ⟨X, φ⟩is a Gaussian random
variable with mean zero and with variance
Z ∞
0
Z ∞
0
min(s, t)φ(s)φ(t)dsdt.
First we need some results about Gaussian random variables.
7.3
Gaussian measures.
7.3.1
Generalities about expectation and variance.
Let V be a vector space (say over the reals and ﬁnite dimensional). Let X be
a V -valued random variable. That is, we have some measure space (M, F, µ)
(which will be ﬁxed and hidden in this section) where µ is a probability measure
on M, and X : M →V is a measurable function. If X is integrable, then
E(X) :=
Z
M
Xdµ

7.3. GAUSSIAN MEASURES.
197
is called the expectation of X and is an element of V .
The function X ⊗X is a V ⊗V valued function, and if it is integrable, then
Var(X) = E(X ⊗X) −E(X) ⊗E(X) = E (X −E(X)) ⊗((X −E(X))
is called the variance of X and is an element of V ⊗V . It is by its deﬁnition
a symmetric tensor, and so can be thought of as a quadratic form on V ∗.
If A : V →W is a linear map, then AX is a W valued random variable, and
E(AX) = AE(X),
Var(AX) = (A ⊗A) Var(X)
(7.13)
assuming that E(X) and Var(X) exist. We can also write this last equation as
Var(AX)(η) = Var(X)(A∗η),
η ∈W ∗
(7.14)
if we think of the variance as quadratic function on the dual space.
The function on V ∗given by
ξ 7→E(eiξ·X)
is called the characteristic function associated to X and is denoted by φX.
Here we have used the notation ξ·v to denote the value of ξ ∈V ∗on v ∈V . It is a
version of the Fourier transform (with the conventions used by the probabilists).
More precisely, let X∗µ denote the push forward of the measure µ by the map
X, so that X∗µ is a probability measure on V . Then φX is the Fourier transform
of this measure except that there are no powers of 2π in front of the integral
and a plus rather than a minus sign is before the i in the exponent. These are
the conventions of the probabilists. What is important for us is the fact that
the Fourier transform determines the measure, i.e. φX determines X∗µ. The
probabilists would say that the law of the random variable (meaning X∗µ) is
determined by its characteristic function.
To get a feeling for (7.14) consider the case where A = ξ is a linear map
from V to R. Then Var(X)(ξ) = Var(ξ · X) is the usual variance of the scalar
valued random variable ξ · X. Thus we see that Var(X)(ξ) ≥0, so Var(X) is
non-negative deﬁnite symmetric bilinear form on V ∗. The variance of a scalar
valued random variable vanishes if and only if it is a constant. Thus Var(X) is
positive deﬁnite unless X is concentrated on hyperplane.
Suppose that A : V →W is an isomorphism, and that X∗µ is absolutely
continuous with respect to Lebesgue measure, so
X∗µ = ρdv
where ρ is some function on V (called the probability density of X).
Then
(AX)∗µ is absolutely continuous with respect to Lebesgue measure on W and
its density σ is given by
σ(w) = ρ(A−1w)| det A|−1
(7.15)
as follows from the change of variables formula for multiple integrals.

198CHAPTER 7. WIENER MEASURE, BROWNIAN MOTION AND WHITE NOISE.
7.3.2
Gaussian measures and their variances.
Let d be a positive integer. We say that N is a unit (d-dimensional) Gaussian
random variable if N is a random variable with values in Rd with density
(2π)−d/2e−(x2
1···+x2
d)/2.
It is clear that E(N) = 0 and, since
(2π)−d/2
Z
xixje−(x2
1···+x2
d)/2dx = δij,
that
Var(N) =
X
i
δi ⊗δi
(7.16)
where δ1, . . . , δd is the standard basis of Rd. We will sometimes denote this
tensor by Id. In general we have the identiﬁcation V ⊗V with Hom(V ∗, V ), so
we can think of the Var(X) as an element of Hom(V ∗, V ) if X is a V -valued
random variable. If we identify Rd with its dual space using the standard basis,
then Id can be thought of as the identity matrix.
We can compute the characteristic function of N by reducing the computa-
tion to a product of one dimensional integrals yielding
φN(t1, . . . , td) = e−(t2
1+···+t2
d)/2.
(7.17)
A V -valued random variable X is called Gaussian if (it is equal in law to a
random variable of the form)
AN + a
where
A : Rd →V
is a linear map, where a ∈V , and where N is a unit Gaussian random variable.
Clearly
E(X) = a,
Var(X) = (A ⊗A)(Id)
or, put another way,
Var(X)(ξ) = Id(A∗ξ)
and hence
φX(ξ) = φN(A∗ξ)eiξ·a = e−1
2 Id(A∗ξ)eiξ·a
or
φX(ξ) = e−Var(X)(ξ)/2+iξ·E(X).
(7.18)

7.3. GAUSSIAN MEASURES.
199
It is a bit of a nuisance to carry along the E(X) in all the computations, so we
shall restrict ourselves to centered Gaussian random variables meaning that
E(X) = 0. Thus for a centered Gaussian random variable we have
φX(ξ) = e−Var(X)(ξ)/2.
(7.19)
Conversely, suppose that X is a V valued random variable whose characteristic
function is of the form
φX(ξ) = e−Q(ξ)/2,
where Q is a quadratic form. Since |φX(ξ)| ≤1 we see that Q must be non-
negative deﬁnite. Suppose that we have chosen a basis of V so that V is identiﬁed
with Rq where q = dim V . By the principal axis theorem we can always ﬁnd
an orthogonal transformation (cij) which brings Q to diagonal form. In other
words, if we set
ηj :=
X
i
cijξi
then
Q(ξ) =
X
j
λjη2
j .
The λj are all non-negative since Q is non-negative deﬁnite. So if we set
aij := λ
1
2
j cij, and A = (aij)
we ﬁnd that Q(ξ) = Iq(A∗ξ). Hence X has the same characteristic function as
a Gaussian random variable hence must be Gaussian.
As a corollary to this argument we see that
A random variable X is centered Gaussian if and only if ξ·X is a real valued
Gaussian random variable with mean zero for each ξ ∈V ∗.
7.3.3
The variance of a Gaussian with density.
In our deﬁnition of a centered Gaussian random variable we were careful not
to demand that the map A be an isomorphism. For example, if A were the
zero map then we would end up with the δ function (at the origin for centered
Gaussians) which (for reasons of passing to the limit) we want to consider as a
Gaussian random variable.
But suppose that A is an isomorphism. Then by (7.15), X will have a density
which is proportional to
e−S(v)/2
where S is the quadratic form on V given by
S(v) = Jd(A−1v)
and Jd is the unit quadratic form on Rd:
Jd(x) = x2
1 · · · + x2
d

200CHAPTER 7. WIENER MEASURE, BROWNIAN MOTION AND WHITE NOISE.
or, in terms of the basis {δ∗
i } of the dual space to Rd,
Jd =
X
i
δ∗
i ⊗δ∗
i .
Here Jd ∈(Rd)∗⊗(Rd)∗= Hom(Rd, (Rd)∗). It is the inverse of the map Id.
We can regard S as belonging to Hom(V, V ∗) while we also regard Var(X) =
(A ⊗A) ◦Id as an element of Hom(V ∗, V ). I claim that Var(X) and S are
inverses to one another. Indeed, dropping the subscript d which is ﬁxed in this
computation, Var(X)(ξ, η) = I(A∗ξ, A∗η) = η · (A ◦I ◦A∗)ξ when thought of as
a bilinear form on V ∗⊗V ∗, and hence
Var(X) = A ◦I ◦A∗
when thought of as an element of Hom(V ∗, V ). Similarly thinking of S as a
bilinear form on V we have S(v, w) = J(A−1v, A−1w) = J(A−1v) · A−1w so
S = A−1∗◦J ◦A−1
when S is thought of as an element of Hom(V, V ∗). Since I and J are inverses
of one another, the two above displayed expressions for S and Var(X) show that
these are inverses on one another.
This has the following very important computational consequence:
Suppose we are given a random variable X with (whose law has) a density
proportional to e−S(v)/2 where S is a quadratic form which is given as a “matrix”
S = (Sij) in terms of a basis of V ∗. Then Var(X) is given by S−1 in terms of
the dual basis of V .
7.3.4
The variance of Brownian motion.
For example, consider the two dimensional vector space with coordinates (x1, x2)
and probability density proportional to
exp −1
2
x2
1
s + (x2 −x1)2
t −s

where 0 < s < t. This corresponds to the matrix

t
s(t−s)
−
1
t−s
−
1
t−s
1
t−s

=
1
t −s
 t
s
−1
−1
1

whose inverse is
s
s
s
t

which thus gives the variance.
So, if we let
B(s, t) := min(s, t)
(7.20)

7.3. GAUSSIAN MEASURES.
201
we can write the above variance as
B(s, s)
B(s, t)
B(t, s)
B(t, t)

.
Now suppose that we have picked some ﬁnite set of times 0 < s1 < · · · < sn
and we consider the corresponding Gaussian measure given by our formula for
Brownian motion on a one-dimensional space for a path starting at the origin
and passing successively through the points x1 at time s1, x2 at time s2 etc.
We can compute the variance of this Gaussian to be
(B(si, sj))
since the projection onto any coordinate plane (i.e. restricting to two values si
and sj) must have the variance given above.
Let φ ∈S.
We can think of φ as a (continuous) linear function on S′.
For convenience let us consider the real spaces S and S′, so φ is a real valued
linear function on S′. Applied to Stroock’s version of Brownian motion which
is a probability measure living on S′ we see that φ gives a real valued random
variable. Recall that this was given by integrating φ · ω where ω is a continuous
path of slow growth, and then integrating over Wiener measure on paths.
This is the limit of the Gaussian random variables given by the Riemann
approximating sums
1
n(φ(s1)x1 + · · · + φ(sn2)xn2)
where sk = k/n, k = 1, . . . , n2, and (x1, . . . , xn2) is an n2 dimensional centered
Gaussian random variable whose variance is (min(si, sj)). Hence this Riemann
approximating sum is a one dimensional centered Gaussian random variable
whose variance is
1
n2
X
i,j
min(si, sj)φ(si)φ(sj).
Passing to the limit we see that integrating φ · ω deﬁnes a real valued centered
Gaussian random variable whose variance is
Z ∞
0
Z ∞
0
min(s, t)φ(s)φ(t)dsdt = 2
Z ∞
0
Z
0≤s≤t
sφ(s)φ(t)dsdt,
(7.21)
as claimed .
Let us say that a probability measure µ on S′ is a centered generalized
Gaussian process if every φ ∈S, thought of as a function on the probability
space (S′, µ) is a real valued centered Gaussian random variable; in other words
φ∗(µ) is a centered Gaussian probability measure on the real line. If we denote
this process by Z, then we may write Z(φ) for the random variable given by
φ. We clearly have Z(aφ + bψ) = aZ(φ) + bZ(ψ) in the sense of addition of
random variables, and so we may think of Z as a rule which assigns, in a linear
fashion, random variables to elements of S.
With some slight modiﬁcation

202CHAPTER 7. WIENER MEASURE, BROWNIAN MOTION AND WHITE NOISE.
(we, following Stroock, are using S instead of D as our space of test functions)
this notion was introduced by Gelfand some ﬁfty years ago. (See Gelfand and
Vilenkin, Generalized Functions volume IV.)
If we have generalized random process Z as above, we can consider its deriva-
tive in the sense of generalized functions, i.e.
˙Z(φ) := Z(−˙φ).
7.4
The derivative of Brownian motion is white
noise.
To see how this derivative works, let us consider what happens for Brownian
motion. Let ω be a continuous path of slow growth, and set
ωh(t) := 1
h(ω(t + h) −ω(t)).
The paths ω are not diﬀerentiable (with probability one) so this limit does not
exist as a function. But the limit does exist as a generalized function, assigning
the value
Z ∞
0
−˙φ(t)ω(t)dt
to φ.
Now if s < t the random variables ω(t + h) −ω(t) and ω(s + h) −
ω(s) are independent of one another when h < t −s since Brownian motion
has independent increments.
Hence we expect that this limiting process be
independent at all points in some generalized sense. (No actual, as opposed to
generalized, process can have this property. We will see more of this point in a
moment when we compute the variance of ˙Z.)
In any event, ˙Z(φ) is a centered Gaussian random variable whose variance
is given (according to (7.21)) by
2
Z ∞
0
Z t
0
s ˙φ(s)ds

˙φ(t)dt.
We can integrate the inner integral by parts to obtain
Z t
0
s ˙φ(s)ds = tφ(t) −
Z t
0
φ(s)ds.
Integration by parts now yields
Z ∞
0
tφ(t) ˙φ(t)dt = −1
2
Z ∞
0
φ(t)2dt
and
−
Z ∞
0
Z t
0
φ(s)ds

˙φ(t)dt =
Z ∞
0
φ(t)2dt.

7.4. THE DERIVATIVE OF BROWNIAN MOTION IS WHITE NOISE. 203
We conclude that the variance of ˙Z(φ) is given by
Z ∞
0
φ(t)2dt
which we can write as
Z ∞
0
Z ∞
0
δ(s −t)φ(s)φ(t)dsdt.
Notice that now the “covariance function” is the generalized function δ(s −t).
The generalized process (extended to the whole line) with this covariance is
called white noise because it is a Gaussian process which is stationary under
translations in time and its covariance “function” is δ(s−t), signifying indepen-
dent variation at all times, and the Fourier transform of the delta function is a
constant, i.e. assigns equal weight to all frequencies.

204CHAPTER 7. WIENER MEASURE, BROWNIAN MOTION AND WHITE NOISE.

Chapter 8
Haar measure.
A topological group is a group G which is also a topological space such that
the maps
G × G →G,
(x, y) 7→xy
and
G →G,
x 7→x−1
are continuous. If the topology on G is locally compact and Hausdorﬀ, we say
that G is a locally compact, Hausdorﬀ, topological group.
If a ∈G is ﬁxed, then the map ℓa
ℓa : G →G,
ℓa(x) = ax
is the composite of the multiplication map G × G →G and the continuous map
G →G × G,
x 7→(a, x).
So ℓa is continuous, one to one, and with inverse ℓa−1. If µ is a measure G,
then we can push it forward by ℓa, that is, consider the pushed forward measure
(ℓa)∗µ. We say that the measure µ is left invariant if
(ℓa)∗µ = µ
∀a ∈G.
The basic theorem on the subject, proved by Haar in 1933 is
Theorem 8.0.1 If G is a locally compact Hausdorﬀtopological group there ex-
ists a non-zero regular Borel measure µ which is left invariant. Any other such
measure diﬀers from µ by multiplication by a positive constant.
This chapter is devoted to the proof of this theorem and some examples and
consequences.
205

206
CHAPTER 8. HAAR MEASURE.
8.1
Examples.
8.1.1
Rn.
Rn is a group under addition, and Lebesgue measure is clearly left invariant.
Similarly Tn.
8.1.2
Discrete groups.
If G has the discrete topology then the counting measure which assigns the value
one to every one element set {x} is Haar measure.
8.1.3
Lie groups.
We can reformulate the condition of left invariance as follows: Let I denote the
integral associated to the measure µ:
I(f) =
Z
fdµ.
Then
Z
fd(ℓa)∗µ = I(ℓ∗
af)
where
(ℓ∗
af)(x) = f(ax).
(8.1)
Indeed, this is most easily checked on indicator functions of sets, where
(ℓa)∗1A = 1ℓ−1
a A
and
Z
1Ad(ℓa)∗µ = ((ℓa)∗µ)(A) := µ(ℓ−1
a A) =
Z
1ℓ−1
a Adµ.
So the left invariance condition is
I(ℓ∗
af) = I(f)
∀a ∈G.
(8.2)
Suppose that G is a diﬀerentiable manifold and that the multiplication map
G × G →G and the inverse map x 7→x−1 are diﬀerentiable.
Now if G is n-dimensional, and we could ﬁnd an n-form Ωwhich does not
vanish anywhere, and such that
ℓ∗
aΩ= Ω
(in the sense of pull-back on forms) then we can choose an orientation relative
to which Ωbecomes identiﬁed with a density, and then
I(f) =
Z
G
fΩ

8.1. EXAMPLES.
207
is the desired integral. Indeed,
I((ℓa)∗f)
=
Z
((ℓa)∗f)Ω
=
Z
((ℓa)∗f)((ℓa)∗Ω) since ((ℓa)∗Ω) = Ω
=
Z
(ℓa)∗(fΩ)
=
Z
fΩ
=
I(f).
We shall replace the problem of ﬁnding a left invariant n-form Ωby the ap-
parently harder looking problem of ﬁnding n left invariant one-forms ω1, . . . , ωn
on G and then setting
Ω:= ω1 ∧· · · ∧ωn.
The general theory of Lie groups says that such one forms (the Maurer-Cartan
forms) always exist, but I want to sow how to compute them in important
special cases.
Suppose that we can ﬁnd a homomorphism
M : G →Gl(d)
where Gl(d) is the group of d × d invertible matrices (either real or complex).
So M is a matrix valued function on G satisfying
M(e) = id
where e is the identity element of G and id is the identity matrix, and
M(xy) = M(x)M(y)
where multiplication on the left is group multiplication and multiplication on the
right is matrix multiplication. We can think of M as a matrix valued function
or as a matrix M(x) = (Mij(x)) of real (or complex) valued functions. Suppose
that all of these functions are diﬀerentiable. Then we can form
dM := (dMij)
which is a matrix of linear diﬀerential forms on G, or, equivalently, a matrix
valued linear diﬀerential form on G.
Finally, consider
M −1dM.
Again, this is a matrix valued linear diﬀerential form on G (or what is the same
thing a matrix of linear diﬀerential forms on G). Explicitly it is the matrix
whose ik entry is
X
j
(M(x))−1)ijdMjk.

208
CHAPTER 8. HAAR MEASURE.
I claim that every entry of this matrix is a left invariant linear diﬀerential form.
Indeed,
(ℓ∗
aM)(x) = M(ax) = M(a)M(x).
Let us write
A = M(a).
Since a is ﬁxed, A is a constant matrix, and so
(ℓ∗
aM)−1 = (AM)−1 = M −1A−1
while
ℓ∗
adM = d(AM) = AdM
since A is a constant. So
ℓ∗
a(M −1dM) = (M −1A−1AdM) = M −1dM.
Of course, if the size of M is too small, there might not be enough linearly
independent entries. (In the complex case we want to be able to choose the
real and imaginary parts of these entries to be linearly independent.) But if,
for example, the map x 7→M(x) is an immersion, then there will be enough
linearly independent entries to go around.
For example, consider the group of all two by two real matrices of the form
 a
b
0
1

,
a ̸= 0.
This group is sometimes known as the “ax + b group” since
 a
b
0
1
  x
1

=
 ax + b
1

.
In other words, G is the group of all translations and rescalings (and re-orientations)
of the real line.
We have

a
b
0
1
−1
=

a−1
−a−1b
0
1

and
d
 a
b
0
1

=
 da
db
0
0

so
 a
b
0
1
−1
d
 a
b
0
1

=
 a−1da
a−1db
0
0

and the Haar measure is (proportional to)
dadb
a2
(8.3)

8.1. EXAMPLES.
209
As a second example, consider the group SU(2) of all unitary two by two
matrices with determinant one.
Each column of a unitary matrix is a unit
vector, and the columns are orthogonal. We can write the ﬁrst column of the
matrix as
 α
β

where α and β are complex numbers with
|α|2 + |β|2 = 1.
(8.4)
The second column must then be proportional to
 −β
α

and the condition that the determinant be one ﬁxes this constant of proportion-
ality to be one. So we can write
M =
 α
−β
β
α

where (8.4) is satisﬁed.
So we can think of M as a complex matrix valued
function on the group SU(2). Since M is unitary, M −1 = M ∗so
M −1 =

α
β
−β
α

and
M −1dM =

α
β
−β
α
  dα
−dβ
dβ
dα

=

αdα + βdβ
−αdβ + βdα
−βdα + αdβ
αdα + βdβ

.
Each of the real and imaginary parts of the entries is a left invariant one form.
But let us multiply three of these entries directly:
(αdα + βdβ) ∧(−αdβ + βdα) ∧(−βdα + αdβ)
= −(|α|2 + |β|2)dα ∧dβ ∧(−βdα + αdβ)
−dα ∧dβ ∧(−βdα + αdβ).
We can simplify this expression by diﬀerentiating the equation
αα + ββ = 1
to get
αdα + αdα + βdβ + βdβ = 0.
So for β ̸= 0 we can solve for dβ:
dβ = −1
β (αdα + αdα + βdβ).

210
CHAPTER 8. HAAR MEASURE.
When we multiply by dα ∧dβ the terms involving dα and dβ disappear. We
thus get
−dα ∧dβ ∧(−βdα + αdβ) = dα ∧dβ ∧(βdα + αα
β dα).
If we write
βdα = ββ
β dα
and use |α|2 + |β|2 = 1 the above expression simpliﬁes further to
1
β dα ∧dβ ∧dα
(8.5)
as a left invariant three form on SU(2). You might think that this three form
is complex valued, but we shall now give an alternative expression for it which
will show that it is in fact real valued.
For this introduce polar coordinates in four dimensions as follows: Write
α
=
w + iz
β
=
x + iy so x2 + y2 + z2 + w2 = 1,
w
=
cos θ
z
=
sin θ cos ψ
x
=
sin θ sin ψ cos φ
y
=
sin θ sin ψ sin φ
0 ≤θ ≤π, 0 ≤ψ ≤π, 0 ≤φ ≤2π.
Then
dα ∧dα = (dw + idz) ∧(dw −idz) = −2idw ∧dz
= −2id(cos θ) ∧d(sin θ · cos ψ) = −2i sin2 θdθ ∧dψ.
Now
β = sin θ sin ψeiφ
so
dβ = iβdφ + · · ·
where the missing terms involve dθ and dψ and so will disappear when multiplied
by dα ∧dα. Hence
dα ∧dβ ∧dα = −2β sin2 θ sin ψdθ ∧dψ ∧dφ.
Finally, we see that the three form (8.5) when expressed in polar coordinates is
−2 sin2 θ sin ψdθ ∧dψ ∧dφ.
Of course we can multiply this by any constant. If we normalize so that µ(G) = 1
the Haar measure is
1
2π2 sin2 θ sin ψdθdψdφ.

8.2. TOPOLOGICAL FACTS.
211
8.2
Topological facts.
Since ℓa is a homeomorphism, if V is a neighborhood of the identity element e,
then aV is a neighborhood of a, and if U is a neighborhood of U then a−1U is
a neighborhood of e. Here we are using the obvious notation aV = ℓa(V ) etc.
Suppose that U is a neighborhood of e. Then so is
U −1 := {x−1 : x ∈U}
and hence so is
W = U ∩U −1.
But
W −1 = W.
Proposition 8.2.1 Every neighborhood of e contains a symmetric neighbor-
hood, i.e. one that satisﬁes W −1 = W.
Let U be a neighborhood of e. The inverse image of U under the multiplication
map G × G →G is a neighborhood of (e, e) in G × G and hence contains an
open set of the form V × V . Hence
Proposition 8.2.2 Every neighborhood U of e contains a neighborhood V of e
such that V 2 = V · V ⊂U.
Here we are using the notation
A · B = {xy : x ∈A, y ∈B}
where A and B are subsets of G.
If A and B are compact, so is A × B as a subset of G × G, and since the
image of a compact set under a continuous map is compact, we have
Proposition 8.2.3 If A and B are compact, so is A · B.
Proposition 8.2.4 If A ⊂G then A, the closure of A, is given by
A =
\
V
AV
where V ranges over all neighborhoods of e.
Proof.
If a ∈A and V is a neighborhood of e, then aV −1 is an open set
containing a, and hence containing a point of A. So a ∈AV , and the left hand
side of the equation in the proposition is contained in the right hand side. To
show the reverse inclusion, suppose that x belongs to the right hand side. Then
xV −1 intersects A for every V . But the sets xV −1 range over all neighborhoods
of x. So x ∈A. QED
Recall that (following Loomis as we are) L denotes the space of continuous
functions of compact support on G.

212
CHAPTER 8. HAAR MEASURE.
Proposition 8.2.5 Suppose that G is locally compact. If f ∈L then f is uni-
formly left (and right) continuous. That is, given ϵ > 0 there is a neighborhood
V of e such that
s ∈V
⇒|f(sx) −f(x)| < ϵ.
Equivalently, this says that
xy−1 ∈V
⇒|f(x) −f(y)| < ϵ.
Proof. Let
C := Supp(f)
and let U be a symmetric compact neighborhood of e. Consider the set Z of
points s such that
|f(sx) −f(x)| < ϵ ∀x ∈UC.
I claim that this contains an open neighborhood W of e. Indeed, for each ﬁxed
y ∈UC the set of s satisfying this condition at y is an open neighborhood
Wy of e, and this Wy works in some neighborhood Oy of y. Since UC is com-
pact, ﬁnitely many of these Oy cover UC, and hence the intersection of the
corresponding Wy form an open neighborhood W of e. Now take
V := U ∩W.
If s ∈V and x ∈UC then |f(sx) −f(x)| < ϵ.
If x ̸∈UC, then sx ̸∈C
(since we chose U to be symmetric) and x ̸∈C, so f(sx) = 0 and f(x) = 0, so
|f(sx) −f(x)| = 0 < ϵ. QED
In the construction of the Haar integral, we will need this proposition. So it
is exactly at this point where the assumption that G is locally compact comes
in.
8.3
Construction of the Haar integral.
Let f and g be non-zero elements of L+ and let mf and mg be their respective
maxima. At each
x ∈Supp(f),
we have
f(x) ≤mf
mg
mg
so if
c > mf
mg
and s is chosen so that g achieves its maximum at sx, then
f(y) ≤cg(sx)

8.3. CONSTRUCTION OF THE HAAR INTEGRAL.
213
in a neighborhood of x. Since Supp(f) is compact, we can cover it by ﬁnitely
many such neighborhoods, so that there exist ﬁnitely many ci and si such that
f(x) ≤
X
cig(six) ∀x.
(8.6)
If we choose x so that f(x) = mf, then the right hand side is at most P
i cimg
and thus we see that
X
i
ci ≥mf/mg > 0.
So let us deﬁne the “size of f relative to g” by
(f; g) := g.l.b.{
X
ci : ∃si such that (8.6) holds}.
(8.7)
We have veriﬁed that
(f; g) ≥mf
mg
.
(8.8)
It is clear that
(ℓ∗
af; g)
=
(f; g) ∀a ∈G
(8.9)
(f1 + f2; g)
≤
(f1, g) + (f2; g)
(8.10)
(cf; g)
=
c(f; g) ∀c > 0
(8.11)
f1 ≤f2
⇒
(f1; g) ≤(f2; g).
(8.12)
If f(x) ≤P cig(six) for all x and g(y) ≤P djh(tjy) for all y then
f(x) ≤
X
ij
cidjh(tjsix) ∀x.
Taking greatest lower bounds gives
(f; h) ≤(f; g)(g; h).
(8.13)
To normalize our integral, ﬁx some
f0 ∈L+,
f0 ̸= 0.
Deﬁne
Ig(f) := (f; g)
(f0; g).
Since, according to (8.13) we have
(f0; g) ≤(f0; f)(f, g),
we see that
1
(f0; f) ≤Ig(f).

214
CHAPTER 8. HAAR MEASURE.
Since (8.13) says that (f; g) ≤(f; f0)(f0; g) we see that
Ig(f) ≤(f; f0).
So for each non-zero f ∈L+ let Sf denote the closed interval
Sf :=

1
(f0; f), (f; f0)

,
and let
S :=
Y
f∈L+,f̸=0
Sf.
This space is compact by Tychonoﬀ. Each non-zero g ∈L+ determines a point
Ig ∈S whose coordinate in Sf is Ig(f).
For any neighborhood V of e, let CV denote the closure in S of the set
Ig, g ∈V . We have
CV1 ∩· · · ∩CVn = CV1∩···∩Vn ̸= ∅.
The CV are all compact, and so there is a point I in the intersection of all the
CV :
I ∈C :=
\
V
CV .
The idea is that I somehow is the limit of the Ig as we restrict the support of
g to lie in smaller and smaller neighborhoods of the identity. We shall prove
that as we make these neighborhoods smaller and smaller, the Ig are closer and
closer to being additive, and so their limit I satisﬁes the conditions for being
an invariant integral. Here are the details:
Lemma 8.3.1 Given f1 and f2 in L+ and ϵ > 0 there exists a neighborhood V
of e such that
Ig(f1) + Ig(f2) ≤Ig(f1 + f2) + ϵ
for all g with Supp(g) ⊂V .
Proof. Choose φ ∈L such that φ = 1 on Supp(f1 + f2). For a given δ > 0 to
be chosen later, let
f := f1 + f2 + δφ,
h1 := f1
f ,
h2 := f2
f .
Here h1 and h2 were deﬁned on Supp(f) and vanish outside Supp(f1 + f2), so
extend them to be zero outside Supp(φ). For an η > 0 and δ > 0 to be chosen
later, ﬁnd a neighborhood V = Vδ,η so that
|h1(x) −h1(y)| < η and |h2(x) −h2(y)| < η
when x−1y ∈V which is possible by Prop. 8.2.5 if G is locally compact.

8.3. CONSTRUCTION OF THE HAAR INTEGRAL.
215
Let g be a non-zero element of L+ with Supp(g) ⊂V . If
f(x) ≤
X
cjg(sjx)
then g(sjx) ̸= 0 implies that
|hi(x) −hi(s−1
j )| < η,
i = 1, 2
so
fi(x) = f(x)hi(x) ≤
X
cjg(sjx)hi(x) ≤
X
cjg(sjx)[hi(s−1
j ) + η],
i = 1, 2.
This implies that
(fi; g) ≤
X
j
cj[hi(s−1
j ) + η]
and since 0 ≤hi ≤1 by deﬁnition,
(f1; g) + (f2; g) ≤
X
cj[1 + 2η].
We can choose the cj and sj so that P cj is as close as we like to (f; g). Hence
(f1; g) + (f2; g) ≤(f; g)[1 + 2η].
Dividing by (f0; g) gives
Ig(f1) + Ig(f2) ≤Ig(f)[1 + 2η]
≤[Ig(f1 + f2) + δIg(φ)][1 + 2η],
where, in going from the second to the third inequality we have used the deﬁ-
nition of f, (8.10) applied to (f1 + f2) and δφ and (8.11). Now
Ig(f1 + f2) ≤(f1 + f2; f0)
and Ig(φ) ≤(φ, f0). So choose δ and η so that
2η(f1 + f2; f0) + δ(1 + 2η)(φ; f0) < ϵ.
This completes the proof of the lemma.
For any ﬁnite number of fi ∈L+ and any neighborhood V of the identity,
there is a non-zero g with Supp(g) ∈V and
|I(fi) −Ig(fi)| < ϵ,
i = 1, . . . , n.
Applying this to f1, f2 and f3 = f1 + f2 and the V supplied by the lemma, we
get
I(f1 + f2) −ϵ ≤Ig(f1 + f2) ≤Ig(f1) + Ig(f2) ≤I(f1) + I(f2) + 2ϵ

216
CHAPTER 8. HAAR MEASURE.
and
I(f1) + I(f2) ≤Ig(f1) + Ig(f2) + 2ϵ ≤Ig(f1 + f2) + 3ϵ ≤I(f1 + f2) + 4ϵ.
In short, I satisﬁes
I(f1 + f2) = I(f1) + I(f2)
for all f1, f2 in L+, is left invariant, and I(cf) = cI(f) for c ≥0. As usual,
extend I to all of L by
I(f1 −f2) = I(f1) −I(f2)
and this is well deﬁned.
Since for f ∈L+ we have
I(f) ≤(f; f0) ≤mf/mf0 = ∥f∥∞/mf0
we see that I is bounded in the sup norm. So it is an integral (by Dini’s lemma).
Hence, by the Riesz representation theorem, if G is Hausdorﬀ, we get a regular
left invariant Borel measure. This completes the existence part of the main
theorem.
From the fact that µ is regular, and not the zero measure, we conclude that
there is some compact set K with µ(K) > 0. Let U be any non-empty open set.
The translates xU, x ∈K cover K, and since K is compact, a ﬁnite number,
say n of them, cover K. But they all have the same measure, µ(U) since µ is
left invariant. Thus
µ(K) ≤nµ(U)
implying
µ(U) > 0 for any non-empty open set U
(8.14)
if µ is a left invariant regular Borel measure.
If f ∈L+ and f ̸= 0, then f > ϵ > 0 on some non-empty open set U, and
hence its integral is > ϵµ(U). So
f ∈L+, f ̸= 0 ⇒
Z
fdµ > 0
(8.15)
for any left invariant regular Borel measure µ.
8.4
Uniqueness.
Let µ and ν be two left invariant regular Borel measures on G.
Pick some
g ∈L+, g ̸= 0 so that both
R
gdµ and
R
gdν are positive. We are going to use
Fubini to prove that for any f ∈L we have
R
fdν
R
gdν =
R
fdµ
R
gdµ .
(8.16)

8.4. UNIQUENESS.
217
This clearly implies that ν = cµ where
c =
R
gdν
R
gdµ.
To prove (8.16), it is enough to show that the right hand side can be expressed
in terms of any left invariant regular Borel measure (say ν) because this implies
that both sides do not depend on the choice of Haar measure. Deﬁne
h(x, y) :=
f(x)g(yx)
R
g(tx)dν(t).
The integral in the denominator is positive for all x and by the left uniform
continuity the integral is a continuous function of x.
Thus h is continuous
function of compact support in (x, y) so by Fubini,
Z Z
h(x, y)dν(y)dµ(x) =
Z Z
h(x, y)dµ(x)dν(y).
In the inner integral on the right replace x by y−1x using the left invariance of
µ. The right hand side becomes
Z
h(y−1x, y)dµ(x)dν(y).
Use Fubini again so that this becomes
Z
h(y−1x, y)dν(y)dµ(x).
Now use the left invariance of ν to replace y by xy. This last iterated integral
becomes
Z
h(y−1, xy)dν(y)dµ(x).
So we have
Z Z
h(x, y)dν(y)dµ(x) =
Z
h(y−1, xy)dν(y)dµ(x).
From the deﬁnition of h the left hand side is
R
f(x)dµ(x). For the right hand
side
h(y−1, xy) = f(y−1)
g(x)
R
g(ty−1)dν(t).
Integrating this ﬁrst with respect to dν(y) gives
kg(x)
where k is the constant
k =
Z
f(y−1)
R
g(ty−1)dν(t)dν(y).

218
CHAPTER 8. HAAR MEASURE.
Now integrate with respect to µ. We get
R
fdµ = k
R
gdµ so
R
fdµ
R
gdµ ,
the right hand side of (8.16), does not depend on µ, since it equals k which is
expressed in terms of ν. QED
8.5
µ(G) < ∞if and only if G is compact.
Since µ is regular, the measure of any compact set is ﬁnite, so if G is compact
then µ(G) < ∞. We want to prove the converse. Let U be an open neighborhood
of e with compact closure, K. So µ(K) > 0. The fact that µ(G) < ∞implies
that one can not have m disjoint sets of the form xiK if
m > µ(G)
µ(K).
Let n be such that we can ﬁnd n disjoint sets of the form xiK but no n + 1
disjoint sets of this form. This says that for any x ∈G, xK can not be disjoint
from all the xiK. Thus
G =
 [
i
xiK
!
· K−1
which is compact. QED
If G is compact, the Haar measure is usually normalized so that µ(G) = 1.
8.6
The group algebra.
If f, g ∈L deﬁne their convolution by
(f ⋆g)(x) :=
Z
f(xy)g(y−1)dµ(y),
(8.17)
where we have ﬁxed, once and for all, a (left) Haar measure µ. The left invariance
(under left multiplication by x−1) implies that
(f ⋆g)(x) =
Z
f(y)g(y−1x)dµ(y).
(8.18)
In what follows we will write dy instead of dµ(y) since we have chosen a ﬁxed
Haar measure µ.
If A := Supp(f) and B := Supp(g) then f(y)g(y−1x) is continuous as a
function of y for each ﬁxed x and vanishes unless y ∈A and y−1x ∈B. Thus
f ⋆g vanishes unless x ∈AB. Also
|f ⋆g(x1) −f ⋆g(x2)| ≤∥ℓ∗
x1f −ℓ∗
x2∥∞
Z
|g(y−1)|dy.

8.6. THE GROUP ALGEBRA.
219
Since x 7→ℓ∗
xf is continuous in the uniform norm, we conclude that
f, g ∈L ⇒f ⋆g ∈L
and
Supp(f ⋆g) ⊂(Supp(f)) · (Supp(g)).
(8.19)
I claim that we have the associative law: If, f, g, h ∈L then the claim is that
(f ⋆g) ⋆h = f ⋆(g ⋆h)
(8.20)
Indeed, using the left invariance of the Haar measure and Fubini we have
((f ⋆g) ⋆h)(x)
:=
Z
(f ⋆g)(xy)h(y−1)dy
=
Z Z
f(xyz)g(z−1)h(y−1)dzdy
=
Z Z
f(xz)g(z−1y)h(y−1)dzdy
=
Z Z
f(xz)g(z−1y)h(y−1)dydz
=
Z
f(xz)(g ⋆h)(z−1)dz
=
(f ⋆(g ⋆h))(x).
It is easy to check that ⋆is commutative if and only if G is commutative.
I now want to extend the deﬁnition of ⋆to all of L1, and here I will follow
Loomis and restrict our deﬁnition of L1 so that our integrable functions belong
to B, the smallest monotone class containing L. When we were doing the Wiener
integral, we needed all Borel sets. Here it is more convenient to operate with
this smaller class, for technical reasons which will be practically invisible. For
most groups one encounters in real life there is no diﬀerence between the Borel
sets and the Baire sets. For example, if the Haar measure is σ-ﬁnite one can
forget about these considerations.
If f and g are functions on G deﬁne the function f • g on G × G by
(f • g)(x, y) := f(y)g(y−1x).
Theorem 8.6.1 [31A in Loomis] If f, g ∈B+ then f • g ∈B+(G × G) and
∥f ⋆g∥p ≤∥f∥1∥g∥p
(8.21)
for any p with 1 ≤p ≤∞.
Proof. If f ∈L+ then the set of g ∈B+ such that f • g ∈B+(G × G) is
L-monotone and includes L+, so includes B+. So if g is an L-bounded function
in B+, the set of f ∈B+ such that f • g ∈B+(G × G) includes L+ and is
L-monotone, and so includes B+. So f • g ∈B+(G × G) whenever f and g are

220
CHAPTER 8. HAAR MEASURE.
L-bounded elements of B+. But the most general element of B+ can be written
as the limit of an increasing sequence of L bounded elements of B+, and so the
ﬁrst assertion in the theorem follows.
As f and g are non-negative, Fubini asserts that the function y 7→f(y)g(y−1x)
is integrable for each ﬁxed x, that f ⋆g is integrable as a function of x and that
∥f ⋆g∥1 =
Z Z
f(y)g(y−1x)dxdy = ∥f∥1∥g∥1.
This proves (8.21) (with equality) for p = 1. For p = ∞(8.21) is obvious from
the deﬁnitions.
For 1 < p < ∞we will use H¨older’s inequality and the duality between Lp
and Lq. We know that the product of two elements of B+(G × G) is an element
of B+(G×G). So if f, g, h ∈B+(G) then the function (x, y) 7→f(y)g(y−1x)h(x)
is an element of B+(G × G), and by Fubini
(f ⋆g, h) =
Z
f(y)
Z
g(y−1x)h(x)dx

dy.
We may apply H¨older’s inequality to estimate the inner integral by ∥g∥p∥h∥q.
So for general h ∈Lq we have
|(f ⋆g, h)| ≤∥f∥1∥g∥p∥h∥q.
If ∥f∥1 or ∥g∥p are inﬁnite, then (8.21) is trivial. If both are ﬁnite, then
h 7→(f ⋆g, h)
is a bounded linear functional on Lq and so by the isomorphism Lp = (Lq)∗we
conclude that f ⋆g ∈Lp and that (8.21) holds. QED
We deﬁne a Banach algebra to be an associative algebra (possibly without
a unit element) which is also a Banach space, and such that
∥fg∥≤∥f∥∥g∥.
So the special case p = 1 of Theorem 8.21 asserts that L1(G) is a Banach
algebra.
8.7
The involution.
8.7.1
The modular function.
Instead of considering the action of G on itself by left multiplication, a 7→ℓa we
can consider right multiplication, rb where
rb(x) = xb−1.
It is one of the basic principles of mathematics, that on account of the associative
law, right and left multiplication commute:
ℓa ◦rb = rb ◦ℓa.
(8.22)

8.7. THE INVOLUTION.
221
Indeed, both sides send x ∈G to
axb−1.
If µ is a choice of left Haar measure, then it follows from (8.22) that rb∗µ is
another choice of Haar measure, and so must be some positive multiple of µ.
The function ∆on G deﬁned by
rb∗µ = ∆(b)µ
is called the modular function of G. It is immediate that this deﬁnition does
not depend on the choice of µ.
Example. In the case that we are dealing with manifolds and integration of
n-forms,
I(f) =
Z
fΩ,
then the push-forward of the measure associated to I under a diﬀeomorphism
φ assigns to any function f the integral
I(φ∗f) =
Z
(φ∗f)Ω=
Z
φ∗(f(φ−1)∗Ω) =
Z
f(φ−1)∗Ω.
So the push forward measure corresponds to the form
(φ−1)∗Ω.
Thus in computing ∆(z) using diﬀerential forms, we have to compute the pull-
back under right multiplication by z, not z−1. For example, in the ax+b group,
we have
 a
b
0
1
  x
y
0
1

=
 ax
ay + b
0
1

so
da ∧db
a2
7→xda ∧db
x2a2
and hence the modular function is given by
∆
 x
y
0
1

= 1
x.
In all cases the modular function is continuous (as follows from the uniform
right continuity, Proposition 8.2.5), and from its deﬁnition, it follows that
∆(st) = ∆(s)∆(t).
In other words, ∆is a continuous homomorphism from G to the multiplicative
group of positive real numbers.
The group G is called unimodular if ∆≡1. For example, a commutative
group is obviously unimodular. Also, a compact group is unimodular, because
G has ﬁnite measure, and is carried into itself by right multiplication so
∆(s)µ(G) = (rs∗(µ)(G) = µ(r−1
s (G)) = µ(G).

222
CHAPTER 8. HAAR MEASURE.
8.7.2
Deﬁnition of the involution.
For any complex valued continuous function f of compact support deﬁne ˜f by
˜f(x) := f(x−1)∆(x−1).
(8.23)
It follows immediately from the deﬁnition that
( ˜f) ˜ = f.
That is, applying ˜ twice is the identity transformation. Also,
(rs( ˜f))(x) = f(sx−1)∆(x−1)∆(s)
so
rs ˜f = ∆(s)(ℓsf)˜.
(8.24)
Similarly,
(rsf)˜(x) = f(x−1s−1)∆(x−1) = ∆(s)ℓs( ˜f)
or
(rsf)˜ = ∆(s)ℓs ˜f.
(8.25)
Suppose that f is real valued, and consider the functional
J(f) := I( ˜f).
Then from (8.24) and the deﬁnition of ∆we have
J(ℓsf) = ∆(s−1)I(rs ˜f) = ∆(s−1)∆(s)I( ˜f) = I( ˜f) = J(f).
In other words, J is a left invariant integral on real valued functions, and hence
must be some constant multiple of I,
J = cI.
Let V be a symmetric neighborhood of e chosen so small that |1 −∆(s)| < ϵ
which is possible for any given ϵ > 0, since ∆(e) = 1 and ∆is continuous. If we
take f = 1V then f(x) = f(x−1) and
|J(f) −I(f)| ≤ϵI(f).
Dividing by I(f) shows that |c −1| < ϵ, and since ϵ is arbitrary, we have proved
that
I( ˜f) = I(f).
(8.26)
We can derive two immediate consequences:
Proposition 8.7.1 Haar measure is inverse invariant if and only if G is uni-
modular,
and
Proposition 8.7.2 The involution f 7→˜f extends to an anti-linear isometry
of L1
C.

8.8. THE ALGEBRA OF FINITE MEASURES.
223
8.7.3
Relation to convolution.
We claim that
(f ⋆g)˜ = ˜g ⋆˜f
(8.27)
Proof.
(f ⋆g)˜(x)
=
Z
f(x−1y)g(y−1)dy∆(x−1)
=
Z
g(y−1)∆(y−1)f((y−1x)−1)∆((y−1x)−1)dy
=
(˜g ⋆˜f)(x). QED
8.7.4
Banach algebras with involutions.
For a general Banach algebra B (over the complex numbers) a map
x 7→x†
is called an involution if it is antilinear and anti-multiplicative, i.e. satisﬁes
(xy)† = y†x†
and its square is the identity.
Thus the map f 7→˜f is an involution on L1(G).
8.8
The algebra of ﬁnite measures.
In general, the algebra L1(G) will not have an identity element, since the only
candidate for the identity element would be the δ-“function”
⟨δ, f⟩= f(e),
and this will not be an honest function unless the topology of G is discrete.
So we need to introduce a diﬀerent algebra if we want to have an algebra with
identity. If G were a Lie group we could consider the algebra of all distributions.
For a general locally compact Hausdorﬀgroup we can proceed as follows: Let
M(G) denote the space of all ﬁnite complex measures on G: A non-negative
measure ν is called ﬁnite if µ(G) < ∞. A real valued measure is called ﬁnite
if its positive and negative parts are ﬁnite, and a complex valued measure is
called ﬁnite if its real and imaginary parts are ﬁnite.
Given two ﬁnite measures µ and ν on G we can form the product measure
µ ⊗ν on G × G and then push this measure forward under the multiplication
map
m : G × G →G,
and so deﬁne their convolution by
µ ⋆ν := m∗(µ ⊗ν).

224
CHAPTER 8. HAAR MEASURE.
One checks that the convolution of two regular Borel measures is again a regular
Borel measure, and that on measures which are absolutely continuous with re-
spect to Haar measure, this coincides with the convolution as previously deﬁned.
One can also make the algebra of regular ﬁnite Borel measures under convolu-
tion into a Banach algebra (under the “total variation norm”). This algebra
does include the δ-function (which is a measure!) and so has an identity. I will
not go into this matter here except to make a number of vague but important
points.
8.8.1
Algebras and coalgebras.
An algebra A is a vector space (over the complex numbers) together with a map
m : A ⊗A →A
which is subject to various conditions (perhaps the associative law, perhaps the
commutative law, perhaps the existence of the identity, etc.). The “dual” object
would be a co-algebra, consisting of a vector space C and a map
c : C →C ⊗C
subjects to a series of conditions dual to those listed above. If A is ﬁnite di-
mensional, then we have an identiﬁcation of (A ⊗A)∗with A⋆⊗A⋆, and so
the dual space of a ﬁnite dimensional algebra is a coalgebra and vice versa. For
inﬁnite dimensional algebras or coalgebras we have to pass to certain topological
completions.
For example, consider the space Cb(G) denote the space of continuous bounded
functions on G endowed with the uniform norm
∥f∥∞= l.u.b.x∈G{|f(x)|}.
We have a bounded linear map
c : Cb(G) →Cb(G × G)
given by
c(f)(x, y) := f(xy).
In the case that G is ﬁnite, and endowed with the discrete topology, the space
Cb(G) is just the space of all functions on G, and Cb(G × G) = Cb(G) ⊗Cb(G)
where Cb(G) ⊗Cb(G) can be identiﬁed with the space of all functions on G × G
of the form
(x, y) 7→
X
i
fi(x)gi(y)
where the sum is ﬁnite.
In the general case, not every bounded continuous
function on G × G can be written in the above form, but, by Stone-Weierstrass,
the space of such functions is dense in Cb(G × G). So we can say that Cb(G)
is “almost” a co-algebra, or a “co-algebra in the topological sense”, in that the

8.9. INVARIANT AND RELATIVELY INVARIANT MEASURES ON HOMOGENEOUS SPACES.225
map c does not carry C into C ⊗C but rather into the completion of C ⊗C.
If A denotes the dual space of C, then A becomes an (honest) algebra.
To
make all this work in the case at hand, we need yet another version of the Riesz
representation theorem. I will state and prove the appropriate theorem, but not
go into the further details:
Let X be a topological space, let Cb := Cb(X, R) be the space of bounded
continuous real valued functions on X. For any f ∈Cb and any subset A ⊂X
let
∥f∥∞,A := l.u.b.x∈A{|f(x)|}.
So
∥f∥∞= ∥f∥∞,X.
A continuous linear function ℓis called tight if for every δ > 0 there is a compact
set Kδ and a positive number Aδ such that
|ℓ(f)| ≤Aδ∥f∥∞,Kδ + δ∥f∥∞.
Theorem 8.8.1 [Yet another Riesz representation theorem.] If ℓ∈C∗
b
is a tight non-negative linear functional, then there is a ﬁnite non-negative mea-
sure µ on (X, B(X)) such that
⟨ℓ, f⟩=
Z
X
fdµ
for all f ∈Cb.
Proof. We need to show that fn ↘0 ⇒⟨ℓ, fn⟩↘0. Given ϵ > 0, choose
δ :=
ϵ
1 + 2∥f1∥∞
.
So
δ∥f1∥∞≤1
2ϵ.
This same inequality then holds with f1 replaced by fn since the fn are mono-
tone decreasing. We have the Kδ as in the deﬁnition of tightness, and by Dini’s
lemma, we can choose N so that
∥fn∥∞,Kδ ≤
ϵ
2Aδ
∀n > N.
Then |⟨ℓ, fn⟩| ≤ϵ for all n > N. QED
8.9
Invariant and relatively invariant measures
on homogeneous spaces.
Let G be a locally compact Hausdorﬀtopological group, and let H be a closed
subgroup. Then G acts on the quotient space G/H by left multiplication, the

226
CHAPTER 8. HAAR MEASURE.
element a sending the coset xH into axH. By abuse of language, we will continue
to denote this action by ℓa. So
ℓa(xH) := (ax)H.
We can consider the corresponding action on measures
κ 7→ℓa∗κ.
The measure κ is said to be invariant if
ℓa∗κ = κ ∀a ∈G.
The measure κ on G/H is said to be relatively invariant with modulus D
if D is a function on G such that
ℓa∗κ = D(a)κ ∀a ∈G.
From its deﬁnition it follows that
D(ab) = D(a)D(b),
and it is not hard to see from the ensuing discussion that D is continuous. We
will only deal with positive measures here, so D is continuous homomorphism
of G into the multiplicative group of real numbers. We call such an object a
positive character. The questions we want to address in this section are what
are the possible invariant measures or relatively invariant measures on G/H,
and what are their modular functions.
For example, consider the ax + b group acting on the real line. So G is the
ax+b group, and H is the subgroup consisting of those elements with b = 0, the
“pure rescalings”. So H is the subgroup ﬁxing the origin in the real line, and we
can identify G/H with the real line. Let N ⊂G be the subgroup consisting of
pure translations, so N consists of those elements of G with a = 1. The group
N acts as translations of the line, and (up to scalar multiple) the only measure
on the real line invariant under all translations is Lebesgue measure, dx. But
h =
 a
0
0
1

acts on the real line by sending x 7→ax and hence
ℓh∗(dx) = a−1dx.
(The push forward of the measure µ under the map φ assigns the measure
µ(φ−1(A)) to the set A.) So there is no measure on the real line invariant under
G. On the other hand, the above formula shows that dx is relatively invariant
with modular function
D
 a
b
0
1

= a−1.

8.9. INVARIANT AND RELATIVELY INVARIANT MEASURES ON HOMOGENEOUS SPACES.227
Notice that this is the same as the modular function ∆, of the group G, and
that the modular function δ for the subgroup H is the trivial function δ ≡1
since H is commutative.
We now turn to the general study, and will follow Loomis in dealing with
the integrals rather than the measures, and so denote the Haar integral of G
by I, with ∆its modular function, denote the Haar integral of H by J and its
modular function by χ. We will let K denote an integral on G/H, and D a
positive character on G.
If f ∈C0(G), then we will let Jtf(xt) denote that function of x obtained
by integrating the function t 7→f(xt) on H with respect to J.
By the left
invariance of J, we see that if s ∈H then
Jt(xst) = Jt(xt).
In other words, the function Jtf(xt) is constant on cosets of H and hence
deﬁnes a function on G/H (which is easily seen to be continuous and of compact
support). Thus J deﬁnes a map
J : C0(G) →C0(G/H).
We will prove below that this map is surjective.
The main result we are aiming for in this section (due to A. Weil) is
Theorem 8.9.1 In order that a positive character D be the modular function
of a relatively invariant integral K on G/H it is necessary and suﬃcient that
D(s) = ∆(s)
χ(s)
∀s ∈H.
(8.28)
If this happens, then K is uniquely determined up to scalar multiple, in fact,
K(J(fD)) = cI(f)
∀f ∈C0(G)
(8.29)
where c is some positive constant.
We begin with some preliminaries. Let π : G →G/H denote the projection
map which sends each element x ∈G into its right coset
π(x) = xH.
The topology on G/H is deﬁned by declaring a set U ⊂(G/H) to be open if and
only if π−1(U) is open. The map π is then not only continuous (by deﬁnition)
but also open, i.e. sends open sets into open sets. Indeed, if O ⊂G is an open
subset, then
π−1(π(O)) =
[
h∈H
Oh
which is a union of open sets, hence open, hence π(O) is open.

228
CHAPTER 8. HAAR MEASURE.
Lemma 8.9.1 If B is a compact subset of G/H then there exists a compact set
A ⊂B such that
π(A) = B,
Proof. Since we are assuming that G is locally compact, we can ﬁnd an open
neighborhood O of e in G whose closure C is compact. The sets π(xO), x ∈G
are all open subsets of G/H since π is open, and their images cover all of G/H.
In particular, since B is compact, ﬁnitely many of them cover B, so
B ⊂
[
i
π(xiO) ⊂
[
i
π(xiC) = π
 [
i
xiC
!
the unions being ﬁnite. The set
K =
[
i
xiC
is compact, being the ﬁnite union of compact sets. The set π−1(B) is closed
(since its complement is the inverse image of an open set, hence open). So
A := K ∩π−1(B)
is compact, and its image is B. QED
Proposition 8.9.1 J is surjective.
Let F ∈C0(G/H) and let B = Supp(F). Choose a compact set A ⊂G with
π(A) = B as in the lemma. Choose φ ∈C0(G) with φ ≥0 and φ > 0 on A. If
x ∈AH = π−1(B)
then φ(xh) > 0 for some h ∈H, and so J(φ) > 0 on B. So we may extend the
function
z 7→
F(z)
J(φ)(z)
to a continuous function, call it γ, by deﬁning it to be zero outside B = Supp(F).
The function g = π∗γ, i.e.
g(x) = γ(π(x))
is hence a continuous function on G, and hence
f := gφ
is a continuous function of compact support on G. Since g is constant on H
cosets,
J(f)(z) = γ(z)J(h)(z) = F(z). QED

8.9. INVARIANT AND RELATIVELY INVARIANT MEASURES ON HOMOGENEOUS SPACES.229
Now to the proof of the theorem. Suppose that K is an integral on C0(G/H)
with modular function D. Deﬁne
M(f) = K(J(fD))
for f ∈C0(G). By applying the monotone convergence theorem for J and K
we see that M is an integral. We must check that it is left invariant, and hence
determines a Haar measure which is a multiple of the given Haar measure.
M(ℓ∗
a(f))
=
K(J((ℓ∗
af)D))
=
D(a)−1K((J(ℓ∗
a(fD))))
=
D(a)−1K(ℓ∗
a(J(fD))))
=
D(a)−1D(a)K(J(fD)))
=
M(f).
This shows that if K is relatively invariant with modular function D then K is
unique up to scalar factor. Let us multiply K be a scalar if necessary (which
does not change D) so that
I(f) = K(J(fD)).
We now argue more or less as before: Let h ∈H. Then
∆(h)I(f)
=
I(r∗
hf)
=
K(J((r∗
hf)D))
=
D(h)K(J(r∗
h(fD)))
=
D(h)χ(h)K(J(fd))
=
D(h)χ(h)I(f),
proving that (8.28) holds.
Conversely, suppose that (8.28) holds, and try to deﬁne K by
K(J(f)) = I(fD−1).
Since J is surjective, this will deﬁne an integral on C0(G/H) once we show that
it is well deﬁned, i.e. once we show that
J(f) = 0 ⇒I(fD−1) = 0.
Suppose that J(f) = 0, and let φ ∈C0(G). Then
φ(x)D(x)−1π∗(J(f))(x) = 0
for all x ∈G, and so taking I of the above expression will also vanish. We will
now use Fubini: We have
0 = Ix
 φ(x)D−1(x)Jh(f(xh))

= IxJh
 φ(x)D−1(x)(f(xh))

=

230
CHAPTER 8. HAAR MEASURE.
JhIx
 φ(x)D−1(x)(f(xh))

We can write the expression that is inside the last Ix integral as
r∗
h−1(φ(xh−1)D−1(xh−1)(f(x)))
and hence
JhIx
 φ(x)D−1(x)(f(xh))

= JhIx
 φ(xh−1)D−1(xh−1)(f(x)∆(h−1))

by the deﬁning properties of ∆. Now use the hypothesis that ∆= Dχ to get
JhIx
 χ(h−1)φ(xh−1)D−1(x)(f(x))

and apply Fubini again to write this as
Ix
 D−1(x)f(x)Jh(χ(h−1)φ(xh−1)))

.
By equation (8.26) applied to the group H, we can replace the J integral above
by Jh(φ(xh)) so ﬁnally we conclude that
Ix
 D−1(x)f(x)Jh(φ(xh))

= 0
for any φ ∈C0(G).
Now choose ψ ∈C0(G/H) which is non-negative and
identically one on π(Supp(f)), and choose φ ∈C0(G) with J(φ) = ψ. Then the
above expression is I(D−1f). So we have proved that
J(f) = 0 ⇒I(fD−1) = 0,
and hence that K : C0(G/H) →C deﬁned by
K(F) = I(D−1f) if
J(f) = F
is well deﬁned. We still must show that K deﬁned this way is relatively invariant
with modular function K. We compute
K(ℓ∗
aF)
=
I(D−1ℓ∗
a(f))
=
D(a)I(ℓ∗
a(D−1f))
=
D(a)I(D−1f)
=
D(a)K(F). QED
Of particular importance is the case where G and H are unimodular, for
example compact. Then, up to scalar factor, there is a unique measure on G/H
invariant under the action of G.

Chapter 9
Banach algebras and the
spectral theorem.
In this chapter, all rings will be assumed to be associative and to have an identity
element, usually denoted by e. If an element x in the ring is such that (e −x)
has a right inverse, then we may write this inverse as (e −y), and the equation
(e −x)(e −y) = e
expands out to
x + y −xy = 0.
Following Loomis, we call y the right adverse of x and x the left adverse of
y. Loomis introduces this term because he wants to consider algebras without
identity elements. But it will be convenient to use it even under our assumption
that all our algebras have an identity. If an element has both a right and left
inverse then they must be equal by the associative law, so if x has a right and
left adverse these must be equal. When we say that an element has (or does
not have) an inverse, we will mean that it has (or does not have) a two sided
inverse. Similarly for adverse.
All algebras will be over the complex numbers. The spectrum of an element
x in an algebra is the set of all λ ∈C such that (x −λe) has no inverse. We
denote the spectrum of x by Spec(x).
Proposition 9.0.2 If P is a polynomial then
P(Spec(x)) = Spec(P(x)).
(9.1)
Proof. The product of invertible elements is invertible. For any λ ∈C write
P(t) −λ as a product of linear factors:
P(t) −λ = c
Y
(t −µi).
Thus
P(x) −λe = c
Y
(x −µie)
231

232CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
in A and hence (P(x) −λe)−1 fails to exist if and only if (x −µie)−1 fails to
exist for some i, i.e. µi ∈Spec(x). But these µi are precisely the solutions of
P(µ) = λ.
Thus λ ∈Spec(P(x)) if and only if λ = P(µ) for some µ ∈Spec(x) which is
precisely the assertion of the proposition. QED
9.1
Maximal ideals.
9.1.1
Existence.
Theorem 9.1.1 Every proper right ideal in a ring is contained in a maximal
proper right ideal. Similarly for left ideals. Also any proper two sided ideal is
contained in a maximal proper two sided ideal.
Proof by Zorn’s lemma. The proof is the same in all three cases: Let I be
the ideal in question (right left or two sided) and F be the set of all proper ideals
(of the appropriate type) containing I ordered by inclusion. Since e does not
belong to any proper ideal, the union of any linearly ordered family of proper
ideals is again proper, and so has an upper bound. Now Zorn guarantees the
existence of a maximal element. QED
9.1.2
The maximal spectrum of a ring.
For any ring R we let Mspec(R) denote the set of maximal (proper) two sided
ideals of R. For any two sided ideal I we let
Supp(I) := {M ∈Mspec(R) : I ⊂M}.
Notice that
Supp({0}) = Mspec(R)
and
Supp(R) = ∅.
For any family Iα of two sided ideals, a maximal ideal contains all of the Iα if
and only if it contains the two sided ideal P
α Iα. In symbols
\
α
Supp(Iα) = Supp
 X
α
Iα
!
.
Thus the intersection of any collection of sets of the form Supp(I) is again of
this form. Notice also that if
A = Supp(I)
then
A = Supp(J) where J =
\
M∈A
M.

9.1. MAXIMAL IDEALS.
233
(Here I ⊂J, but J might be a strictly larger ideal.) We claim that
A = Supp
 \
M∈A
M
!
and B = Supp
 \
M∈B
M
!
⇒A ∪B = Supp
 
\
M∈A∪B
M
!
.
(9.2)
Indeed, if N is a maximal ideal belonging to A ∪B then it contains the inter-
section on the right hand side of (9.2) so the left hand side contains the right.
We must show the reverse inclusion. So suppose the contrary. This means that
there is a maximal ideal N which contains the intersection on the right but
does not belong to either A or B. Since N does not belong to A, the ideal
J(A) := T
M∈A M is not contained in N, so J(A) + N = R, and hence there
exist a ∈J(A) and m ∈N such that a + m = e. Similarly, there exist b ∈J(B)
and n ∈N such that b + n = e. But then
e = e2 = (a + m)(b + n) = ab + an + mb + mn.
Each of the last three terms on the right belong to N since it is a two sided
ideal, and so does ab since
ab ∈
 \
M∈A
M
!
∩
 \
M∈B
M
!
=
 
\
M∈A∪B
M
!
⊂N.
Thus e ∈N which is a contradiction.
The above facts show that the sets of the form Supp(I) give the closed sets
of a topology.
If A ⊂Mspec(R) is an arbitrary subset, its closure is given by
A = Supp
 \
M∈A
M
!
.
(For the case of commutative rings, a major advance was to replace maximal
ideals by prime ideals in the preceding construction - giving rise to the notion
of Spec(R) - the prime spectrum of a commutative ring. But the motivation for
this development in commutative algebra came from these constructions in the
theory of Banach algebras.)
9.1.3
Maximal ideals in a commutative algebra.
Proposition 9.1.1 An ideal M in a commutative algebra is maximal if and
only if R/M is a ﬁeld.
Proof. If J is an ideal in R/M, its inverse image under the projection R →R/M
is an ideal in R. If J is proper, so is this inverse image. Thus M is maximal if

234CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
and only if F := R/M has no ideals other than 0 and F. Thus if 0 ̸= X ∈F,
the set of all multiples of X must be all of F if M is maximal. In particular
every non-zero element has an inverse. Conversely, if every non-zero element of
F has an inverse, then F has no proper ideals. QED
9.1.4
Maximal ideals in the ring of continuous functions.
Let S be a compact Hausdorﬀspace, and let C(S) denote the ring of continuous
complex valued functions on S. For each p ∈S, the map of C(S) →C given by
f 7→f(p)
is a surjective homomorphism. The kernel of this map consists of all f which
vanish at p. By the preceding proposition, this is then a maximal ideal, which
we shall denote by Mp.
Theorem 9.1.2 If I is a proper ideal of C(S), then there is a point p ∈S such
that
I ⊂Mp.
In particular every maximal ideal in C(S) is of the form Mp so we may identify
Mspec(C(S)) with S as a set. This identiﬁcation is a homeomorphism between
the original topology of S and the topology given above on Mspec(C(S)).
Proof. Suppose that for every p ∈S there is an f ∈I such that f(p) ̸= 0.
Then |f|2 = ff ∈I and |f(p)|2 > 0 and |f|2 ≥0 everywhere. Thus each point
of S is contained in a neighborhood U for which there exists a g ∈I with g ≥0
everywhere, and g > 0 on U. Since S is compact, we can cover S with ﬁnitely
many such neighborhoods. If we take h to be the sum of the corresponding g’s,
then h ∈I and h > 0 everywhere. So h−1 ∈C(S) and e = 1 = hh−1 ∈I so
I = C(S), a contradiction. This proves the ﬁrst part of the the theorem.
To prove the last statement, we must show that the closure of any subset
A ⊂S in the original topology coincides with its closure in the topology derived
from the maximal ideal structure. That is, we must show that
closure of A in the topology of S = Supp
 \
M∈A
M
!
.
Now
\
M∈A
M
consists exactly of all continuous functions which vanish at all points of A. Any
such function must vanish on the closure of A in the topology of S. So the left
hand side of the above equation is contained in the right hand side. We must
show the reverse inclusion. Suppose p ∈S does not belong to the closure of A
in the topology of S. Then Urysohn’s Lemma asserts that there is an f ∈C(S)
which vanishes on A and f(p) ̸= 0. Thus p ̸∈Supp(T
M∈A M). QED

9.2. NORMED ALGEBRAS.
235
Theorem 9.1.3 Let I be an ideal in C(S) which is closed in the uniform topol-
ogy on C(S). Then
I =
\
M∈Supp(I)
M.
Proof. Supp(I) consists of all points p such that f(p) = 0 for all f ∈I. Since
f is continuous, the set of zeros of f is closed, and hence Supp(I) being the
intersection of such sets is closed. Let O be the complement of Supp(I) in S.
Then O is a locally compact space, and the elements of T
M∈Supp(I) M when
restricted to O consist of all functions which vanish at inﬁnity. I, when restricted
to O is a uniformly closed subalgebra of this algebra. If we could show that the
elements of I separate points in O then the Stone-Weierstrass theorem would
tell us that I consists of all continuous functions on O which “vanish at inﬁnity”,
i.e. all continuous functions which vanish on Supp(I), which is the assertion of
the theorem. So let p and q be distinct points of O, and let f ∈C(S) vanish on
Supp(I) and at q with f(p) = 1. Such a function exists by Urysohn’s Lemma,
again. Let g ∈I be such that g(p) ̸= 0. Such a g exists by the deﬁnition of
Supp(I). Then gf ∈I, (gf)(q) = 0, and (gf)(p) ̸= 0. QED
9.2
Normed algebras.
A normed algebra is an algebra (over the complex numbers) which has a norm
as a vector space which satisﬁes
∥xy∥≤∥x∥∥y∥.
(9.3)
Since e = ee this implies that
∥e∥≤∥e∥2
so
∥e∥≥1.
Consider the new norm
∥y∥N := lub∥x∦=0∥yx∥/∥x∥.
This still satisﬁes (9.3). Indeed, if x, y, and z are such that yz ̸= 0 then
∥xyz∥
∥z∥
= ∥xyz∥
∥yz∥· ∥yz∥
∥z∥≤∥x∥N · ∥y∥N
and the inequality
∥xyz∥
∥z∥
≤∥x∥N · ∥y∥N
is certainly true if yz = 0. So taking the sup over all z ̸= 0 we see that
∥xy∥N ≤∥x∥N · ∥y∥N.

236CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
From (9.3) we have
∥y∥N ≤∥y∥.
Under the new norm we have
∥e∥N = 1.
On the other hand, from its deﬁnition
∥y∥/∥e∥≤∥y∥N.
Combining this with the previous inequality gives
∥y∥/∥e∥≤∥y∥N ≤∥y∥.
In other words the norms ∥
∥and ∥∥N are equivalent. So with no loss of
generality we can add the requirement
∥e∥= 1
(9.4)
to our axioms for a normed algebra.
Suppose we weaken our condition and allow ∥∥to be only a pseudo-norm.
this means that we allow the possible existence of non-zero elements x with
∥x∥= 0. Then (9.3) implies that the set of all such elements is an ideal, call
it I. Then ∥∥descends to A/I . Furthermore, any continuous (i.e. bounded)
linear function must vanish on I so also descends to A/I with no change in
norm. In other words, A∗can be identiﬁed with (A/I)∗.
If A is a normed algebra which is complete (i.e. A is a Banach space as a
normed space) then we say that A is a Banach algebra.
9.3
The Gelfand representation.
Let A be a normed vector space. The space A∗of continuous linear functions
on A becomes a normed vector space under the norm
∥ℓ∥:= sup
∥x∦=0
|ℓ(x)|/∥x∥.
Each x ∈A deﬁnes a linear function on A∗by
x(ℓ) := ℓ(x)
and
|x(ℓ)| ≤∥ℓ∥∥x∥
so x is a continuous function of ℓ(relative to the norm introduced above on A∗).
Let B = B1(A∗) denote the unit ball in A∗. In other words B = {ℓ: ∥ℓ∥≤
1}. The functions x(·) on B induce a topology on B called the weak topology.
Proposition 9.3.1 B is compact under the weak topology.

9.3. THE GELFAND REPRESENTATION.
237
Proof. For each x ∈A, the values assumed by the set of ℓ∈B at x lie in the
closed disk D∥x∥of radius ∥x∥in C. Thus
B ⊂
Y
x∈A
D∥x∥
which is compact by Tychonoﬀ’s theorem - being the product of compact spaces.
To prove that B is compact, if is suﬃcient to show that B is a closed subset of
this product space. Suppose that f is in the closure of B. For any x and y in
A and any ϵ > 0, we can ﬁnd an ℓ∈B such that
|f(x) −ℓ(x)| < ϵ,
|f(y) −ℓ(y)| < ϵ, and |f(x + y) −ℓ(x + y)| < ϵ.
Since ℓ(x + y) = ℓ(x) + ℓ(y) this implies that
|f(x + y) −f(x) −f(y)| < 3ϵ.
Since ϵ is arbitrary, we conclude that
f(x + y) = f(x) + f(y).
Similarly, f(λx) = λf(x). In other words, f ∈B. QED
Now let A be a normed algebra. Let ∆⊂A∗denote the set of all continuous
homomorphisms of A onto the complex numbers. In other words, in addition
to being linear, we demand of h ∈∆that
h(xy) = h(x)h(y)
and
h(e) = 1.
Let E := h−1(1). Then E is closed under multiplication. In particular, if
x ∈E we can not have ∥x∥< 1 for otherwise xn is a sequence of elements in
E tending to 0, and so by the continuity of h we would have h(0) = 1 which
is impossible. So ∥x∥≥1 for all x ∈E. If y is such that h(y) = λ ̸= 0, then
x := y/λ ∈E so
|h(y)| ≤∥y∥,
and this clearly also holds if h(y) = 0. In other words,
∆⊂B.
Since the conditions for being a homomorphism will hold for any weak limit of
homomorphisms (the same proof as given above for the compactness of B), we
conclude that ∆is compact.
Once again we can turn the tables and think of y ∈A as a function ˆy on ∆
via
ˆy(h) := h(y).
This map from A into an algebra of functions on ∆is called the Gelfand
representation.
The inequality |h(y)| ≤∥y∥for all h translates into
∥ˆy∥∞≤∥y∥.
(9.5)
Putting it all together we get

238CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
Theorem 9.3.1 ∆is a compact subset of A∗and the Gelfand representation
y 7→ˆy is a norm decreasing homomorphism of A onto a subalgebra ˆA of C(∆).
The above theorem is true for any normed algebra - we have not used any
completeness condition. For Banach algebras, i.e. complete normed algebras,
we can proceed further and relate ∆to Mspec(A).
Recall that an element
of Mspec(A) corresponds to a homomorphism of A onto some ﬁeld.
In the
commutative Banach algebra case we will show that this ﬁeld is C and that any
such homomorphism is automatically continuous. So for commutative Banach
algebras we can identify ∆with Mspec(A).
9.3.1
Invertible elements in a Banach algebra form an
open set.
In this section A will be a Banach algebra.
Proposition 9.3.2 If ∥x∥< 1 then x has an adverse x′ given by
x′ = −
∞
X
n=1
xn
so that e −x has an inverse given by
e −x′ = e +
∞
X
n=1
xn.
Both are continuous functions of x
Proof. Let
sn := −
n
X
1
xi.
Then if m < n
∥sm −sn∥≤
n
X
m+1
∥x∥i < ∥x∥m
1
1 −∥x∥→0
as m →∞. Thus sn is a Cauchy sequence and
x + sn −xsn = xn+1 →0.
Thus the series −P∞
1 xi as stated in the theorem converges and gives the ad-
verse of x and is continuous function of x. The corresponding statements for
(e −x)−1 now follow. QED
The proof shows that the adverse x′ of x satisﬁes
∥x′∥≤
∥x∥
1 −∥x∥.
(9.6)

9.3. THE GELFAND REPRESENTATION.
239
Theorem 9.3.2 Let y be an invertible element of A and set
a :=
1
∥y−1∥.
Then y + x is invertible whenever
∥x∥< a.
Furthermore
∥(x + y)−1 −y−1∥≤
∥x∥
(a −∥x∥)a.
(9.7)
Thus the set of elements having inverses is open and the map x →x−1 is
continuous on its domain of deﬁnition.
Proof. If ∥x∥< ∥y−1∥−1 then
∥y−1x∥≤∥y−1∥∥x∥< 1.
Hence e + y−1x has an inverse by the previous proposition. Hence y + x =
y(e + y−1x) has an inverse. Also
(y + x)−1 −y−1 =
 (e + y−1x)−1 −e

y−1 = −(−y−1x)′y−1
where (−y−1x)′ is the adverse of −y−1x.
From (9.6) and the above expression for (x + y)−1 −y−1 we see that
∥(x + y)−1 −y−1∥≤∥(−y−1x)′∥∥y−1∥≤
∥x∥∥y−1∥2
1 −∥x∥∥y−1∥=
∥x∥
a(a −∥x∥).
QED
Proposition 9.3.3 If I is a proper ideal then ∥e −x∥≥1 for all x ∈I.
Proof. Otherwise there would be some x ∈I such that e −x has an adverse,
i.e. x has an inverse which contradicts the hypothesis that I is proper.
Proposition 9.3.4 The closure of a proper ideal is proper. In particular, every
maximal ideal is closed.
Proof. The closure of an ideal I is clearly an ideal, and all elements in the
closure still satisfy ∥e −x∥≥1 and so the closure is proper. QED
Proposition 9.3.5 If I is a closed ideal in A then A/I is again a Banach
algebra.
Proof. The quotient of a Banach space by a closed subspace is again a Banach
space. The norm on A/I is given by
∥X∥= min
x∈X ∥x∥

240CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
where X is a coset of I in A. The product of two cosets X and Y is the coset
containing xy for any x ∈X, y ∈Y . Thus
∥XY ∥=
min
x∈X, y∈Y ∥xy∥≤
min
x∈X, y∈Y ∥x∥∥y∥= ∥X∥∥Y ∥.
Also, if E is the coset containing e then E is the identity element for A/I and
so
∥E∥≤1.
But we know that this implies that ∥E∥= 1. QED
Suppose that A is commutative and M is a maximal ideal of A. We know
that A/M is a ﬁeld, and the preceding proposition implies that A/M is a normed
ﬁeld containing the complex numbers. The following famous result implies that
A/M is in fact norm isomorphic to C. It deserves a subsection of its own:
The Gelfand-Mazur theorem.
A division algebra is a (possibly not commutative) algebra in which every non-
zero element has an inverse.
Theorem 9.3.3 Every normed division algebra over the complex numbers is
isometrically isomorphic to the ﬁeld of complex numbers.
Let A be the normed division algebra and x ∈A. We must show that x = λe
for some complex number λ. Suppose not. Then by the deﬁnition of a division
algebra, (x −λe)−1 exists for all λ ∈C and all these elements commute. Thus
(x −(λ + h)e)−1 −(x −λe)−1 = h(x −(λ + h)e)−1(x −λe)−1
as can be checked by multiplying both sides of this equation on the right by
x−λe and on the left by x−(λ+h)e. Thus the strong derivative of the function
λ 7→(x −λe)−1
exists and is given by the usual formula (x−λe)−2. In particular, for any ℓ∈A∗
the function
λ 7→ℓ((x −λe)−1)
is analytic on the entire complex plane. On the other hand for λ ̸= 0 we have
(x −λe)−1 = λ−1( 1
λx −e)−1
and this approaches zero as λ →∞. Hence for any ℓ∈A∗the function λ 7→
ℓ((x −λe)−1) is an everywhere analytic function which vanishes at inﬁnity, and
hence is identically zero by Liouville’s theorem.
But this implies that (x −
λe)−1 ≡0 by the Hahn Banach theorem, a contradiction. QED

9.3. THE GELFAND REPRESENTATION.
241
9.3.2
The Gelfand representation for commutative Banach
algebras.
Let A be a commutative Banach algebra. We know that every maximal ideal is
the kernel of a homomorphism h of A onto the complex numbers. Conversely,
suppose that h is such a homomorphism. We claim that
|h(x)| ≤∥x∥
for any x ∈A. Indeed, suppose that |h(x)| > ∥x∥for some x. Then
∥x/h(x)∥< 1
so e −x/h(x) is invertible; in particular h(e −x/h(x)) ̸= 0 which implies that
1 = h(e) ̸= h(x)/h(x), a contradiction.
In short, we can identify Mspec(A) with ∆and the map x 7→ˆx is a norm
decreasing map of A onto a subalgebra ˆA of C(Mspec(A)) where we use the
uniform norm ∥∥∞on C(Mspec(A)). A complex number is in the spectrum of
an x ∈A if and only if (x −λe) belongs to some maximal ideal M, in which
case ˆx(M) = λ. Thus
∥ˆx∥∞= l.u.b. {|λ| : λ ∈Spec(x)}.
(9.8)
9.3.3
The spectral radius.
The right hand side of (9.8) makes sense in any algebra, and is called the spec-
tral radius of x and is denoted by |x|sp. We claim that
Theorem 9.3.4 In any Banach algebra we have
|x|sp = lim
n→∞∥xn∥
1
n .
(9.9)
Proof. If |λ| > ∥x∥then e −x/λ is invertible, and therefore so is x −λe so
λ ̸∈Spec(x). Thus
|x|sp ≤∥x∥.
We know from (9.1) that λ ∈Spec(x) ⇒λn ∈Spec(xn), so the previous
inequality applied to xn gives
|x|sp ≤∥xn∥
1
n
and so
|x|sp ≤lim inf ∥xn∥
1
n .
We must prove the reverse inequality with lim sup. Suppose that |µ| < 1/|x|sp
so that µ := 1/λ satisﬁes |λ| > |x|sp and hence e−µx is invertible. The formula
for the adverse gives
(µx)′ = −
∞
X
1
(µx)n

242CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
where we know that this converges in the open disk of radius 1/∥x∥. However,
we know that (e −µx)−1 exists for |µ| < 1/|x|sp. In particular, for any ℓ∈A∗
the function µ 7→ℓ((µx)′) is analytic and hence its Taylor series
−
X
ℓ(xn)µn
converges on this disk. Here we use the fact that the Taylor series of a function
of a complex variable converges on any disk contained in the region where it is
analytic. Thus
|ℓ(µnxn)| →0
for each ﬁxed ℓ∈A∗if |µ| < 1/|x|sp. Considered as a family of linear functions
of ℓ, we see that
ℓ7→ℓ(µnxn)
is bounded for each ﬁxed ℓ, and hence by the uniform boundedness principle,
there exists a constant K such that
∥µnxn∥< K
for each µ in this disk, in other words
∥xn∥
1
n ≤K
1
n (1/|µ|)
so
lim sup ∥xn∥
1
n ≤1/|µ| if 1/|µ| > |x|sp.
QED
In a commutative Banach algebra we can combine (9.9) with (9.8) to con-
clude that
∥ˆx∥∞= lim
n→∞∥xn∥
1
n .
(9.10)
We say that x is a generalized nilpotent element if lim ∥xn∥
1
n = 0. From
(9.9) we see that x is a generalized nilpotent element if and only if ˆx ≡0. This
means that x belongs to all maximal ideals. The intersection of all maximal
ideals is called the radical of the algebra. A Banach algebra is called semi-
simple if its radical consists only of the 0 element.
9.3.4
The generalized Wiener theorem.
Theorem 9.3.5 Let A be a commutative Banach algebra. Then x ∈A has an
inverse if and only if ˆx never vanishes.
Proof. If xy = e then ˆxˆy ≡1. So if x has an inverse, then ˆx can not vanish
anywhere.
Conversely, suppose x does not have an inverse.
Then Ax is a
proper ideal. So x is contained in some maximal ideal M (by Zorn’s lemma).
So ˆx(M) = 0.

9.3. THE GELFAND REPRESENTATION.
243
Example. Let G be a countable commutative group given the discrete topology.
Then we may choose its Haar measure to be the counting measure. Thus L1(G)
consists of all complex valued functions on G which are absolutely summable,
i.e. such that
X
a∈G
|f(a)| < ∞.
Recall that L1(G) is a Banach algebra under convolution:
(f ⋆g)(x) :=
X
y∈G
f(y−1x)g(y).
We repeat the proof: Since L1(G) ⊂L2(G) this sum converges and
X
x∈G
|(f ⋆g)(x)|
≤
X
x,y∈G
|f(xy−1)| · |g(y)|
=
X
y∈G
|g(y)|
X
x∈G
|f(xy−1)|
=
(
X
y∈G
|g(y)|)(
X
w∈G
|f(w)|)
i.e.
∥f ⋆g∥
≤
∥f∥∥g∥.
If δx ∈L1(G) is deﬁned by
δx(t) =

1
if t = x
0
otherwise
then
δx ⋆δy = δxy.
We know that the most general continuous linear function on L1(G) is ob-
tained from multiplication by an element of L∞(G) and then integrating =
summing. That is it is given by
f 7→
X
x∈G
f(x)ρ(x)
where ρ is some bounded function. Under this linear function we have
δx 7→ρ(x)
and so, if this linear function is to be multiplicative, we must have
ρ(xy) = ρ(x)ρ(y).
Since ρ(xn) = ρ(x)n and |ρ(x)| is to be bounded, we must have |ρ(x)| ≡1.
A function ρ satisfying these two conditions:
ρ(xy) = ρ(x)ρ(y) and
|ρ(x)| ≡1

244CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
is called a character of the commutative group G. The space of characters is
itself a group, denoted by ˆG.
We have shown that Mspec(L1(G)) = ˆG. In particular we have a topology
on ˆG and the Gelfand transform f 7→ˆf sends every element of L1(G) to a
continuous function on ˆG.
For example, if G = Z under addition, the condition to be a character says
that
ρ(m + n) = ρ(m)ρ(n),
|ρ| ≡1.
So
ρ(n) = ρ(1)n
where
ρ(1) = eiθ
for some θ ∈R/(2πZ). Thus
ˆf(θ) =
X
n∈Z
f(n)einθ
is just the Fourier series with coeﬃcients f(n). The image of the Gelfand trans-
form is just the set of Fourier series which converge absolutely. We conclude
from Theorem 9.3.5 that if F is an absolutely convergent Fourier series which
vanishes nowhere, then 1/F has an absolutely convergent Fourier series. Before
Gelfand, this was a deep theorem of Wiener.
To deal with the version of this theorem which treats the Fourier transform
rather than Fourier series, we would have to consider algebras which do not
have an identity element. Most of what we did goes through with only mild
modiﬁcations, but I do not to go into this, as my goals are elsewhere.
9.4
Self-adjoint algebras.
Let A be a semi-simple commutative Banach algebra.
Since “semi-simple”
means that the radical is {0}, we know that the Gelfand transform is injec-
tive. A is called self adjoint if for every x ∈A there exists an x∗∈A such
that
(x∗)ˆ= ˆx.
By the injectivity of the Gelfand transform, the element x∗is uniquely speciﬁed
by this equation.
In general, for any Banach algebra, a map f 7→f † is called an involutory
anti-automorphism if
• (fg)† = g†f †
• (f + g)† = f † + g†
• (λf)† = λf † and

9.4. SELF-ADJOINT ALGEBRAS.
245
• (f †)† = f.
For example, if A is the algebra of bounded operators on a Hilbert space, then
the map T 7→T ∗sending every operator to its adjoint is an example of an
involutory anti-automorphism. Another example is L1(G) under convolution,
for a locally compact Hausdorﬀgroup G where the involution was the map
f 7→˜f.
If A is a semi-simple self-adjoint commutative Banach algebra, the map
x 7→x∗is an involutory anti-automorphism. It has this further property:
f = f ∗⇒1 + f 2
is invertible.
indeed, if f = f ∗then ˆf is real valued, so 1+ ˆf 2 vanishes nowhere, and so 1+f 2
is invertible by Theorem 9.3.5. Conversely
Theorem 9.4.1 Let A be a commutative semi-simple Banach algebra with an
involutory anti-automorphism f 7→f † such that 1 + f 2 is invertible whenever
f = f †. Then A is self-adjoint and † = ∗.
Proof. We must show that (f †)ˆ= ˆf. We ﬁrst prove that if we set
g := f + f †
then ˆg is real valued. Suppose the contrary, that
ˆg(M) = a + ib,
b ̸= 0
for some M ∈Mspec(A).
Now g† = f † + (f †)† = g and hence (g2)† = g2 so
h := ag2 −(a2 −b2)g
b(a2 + b2)
satisﬁes
h† = h.
We have
h(M) = a(a + ib)2 −(a2 −b2)(a + ib)
b(a2 + b2)
= i.
So
1 + h(M)2 = 0
contradicting the hypothesis that 1 + h2 is invertible. Now let us apply this
result to 1
2f and to
1
2if. We have
f = g + ih
where g = 1
2(f + f †),
h = 1
2i(f −f †)
and we know that ˆg and ˆh are real and satisfy g† = g and h† = h. So
ˆf = ˆg + iˆh = ˆg −iˆh = (f †)ˆ.
QED

246CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
Theorem 9.4.2 Let A be a commutative Banach algebra with an involutory
anti-automorphism † which satisﬁes the condition
∥ff †∥= ∥f∥2
∀f ∈A.
(9.11)
Then the Gelfand transform f 7→ˆf is a norm preserving surjective isomorphism
which satisﬁes
(f †)ˆ= ˆf.
In particular, A is semi-simple and self-adjoint.
Proof.
∥f∥2 = ∥ff †∥≤∥f∥∥f †∥so ∥f∥≤∥f †∥. Replacing f by f † gives
∥f †∥≤∥f∥. so
∥f∥= ∥f †∥
and
∥ff †∥= ∥f∥2 = ∥f∥∥f †∥.
(9.12)
Now since A is commutative,
ff † = f †f
and
f 2(f 2)† = f 2(f †)2 = (ff †)(ff †)†
(9.13)
and so applying (9.12) to f 2 and then applying it once again to f we get
∥f 2∥∥(f †)2∥= ∥ff †(ff †)†∥= ∥ff †∥∥ff †∥= ∥f∥2∥f †∥2
or
∥f 2∥2 = ∥f∥4.
Thus
∥f 2∥= ∥f∥2,
and therefore
∥f 4∥= ∥f 2∥2 = ∥f∥4
and by induction
∥f 2k∥= ∥f∥2k
for all non-negative integers k.
Hence letting n = 2k in the right hand side of (9.10) we see that ∥ˆf∥∞= ∥f∥
so the Gelfand transform is norm preserving, and hence injective. To show that
† = ∗it is enough to show that if f = f † then ˆf is real valued, as in the proof
of the preceding theorem. Suppose not, so ˆf(M) = a + ib, b ̸= 0. For any real
number c we have
(f + ice)ˆ(M) = a + i(b + c)
so
|(f + ice)ˆ(M)|2 = a2 + (b + c)2 ≤∥f + ice∥2 = ∥(f + ice)(f −ice)∥

9.4. SELF-ADJOINT ALGEBRAS.
247
= ∥f 2 + c2e∥≤∥f∥2 + c2.
This says that
a2 + b2 + 2bc + c2 ≤∥f∥2 + c2
which is impossible if we choose c so that 2bc > ∥f∥2.
So we have proved that † = ∗. Now by deﬁnition, if f(M) = f(N) for all
f ∈A, the maximal ideals M and N coincide. So the image of elements of A
under the Gelfand transform separate points of Mspec(A). But every f ∈A can
be written as
f = 1
2(f + f ∗) + i 1
2i(f −f ∗)
i.e. as a sum g+ih where ˆg and ˆf are real valued. Hence the real valued functions
of the form ˆg separate points of Mspec(A). Hence by the Stone Weierstrass the-
orem we know that the image of the Gelfand transform is dense in C(Mspec(A)).
Since A is complete and the Gelfand transform is norm preserving, we conclude
that the Gelfand transform is surjective. QED
9.4.1
An important generalization.
A Banach algebra with an involution † such that (9.11) holds is called a C∗-
algebra. Notice that we are not assuming that this Banach algebra is commu-
tative. But an element x of such an algebra is called normal if
xx† = x†x,
in other words if x does commute with x†. Then we can repeat the argument
at the beginning of the proof of Theorem 9.4.2 to conclude that if x is a normal
element of a C∗algebra, then
∥x2k∥= ∥x∥2k
and hence by (9.9)
|x|sp = ∥x∥.
(9.14)
An element x of an algebra with involution is called self-adjoint if x† = x. In
particular, every self-adjoint element is normal.
Again, a rerun of a previous argument shows that if x is self-adjoint, meaning
that x† = x then
Spec(x) ⊂R
(9.15)
Indeed, suppose that a + ib ∈Spec(x) with b ̸= 0, and let
y := 1
b (x −ae)
so that y = y† and i ∈Spec(y). So e + iy is not invertible. So for any real
number r,
(r + 1)e −(re −iy) = e + iy

248CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
is not invertible. This implies that
|r + 1| ≤∥re −iy∥
and so
(r + 1)2 ≤∥re −iy∥2 = ∥(re −iy)(re + iy)∥.
by (9.11). Thus
(r + 1)2 ≤∥r2e + y2∥≤r2 + ∥y∥2
which is not possible if 2r −1 > ∥y∥2.
So we have proved:
Theorem 9.4.3 Let A be a C∗algebra. If x ∈A is normal, then
|x|sp = ∥x∥.
If x ∈A is self-adjoint, then
Spec(x) ⊂R.
9.4.2
An important application.
Proposition 9.4.1 If T is a bounded linear operator on a Hilbert space, then
∥TT ∗∥= ∥T∥2.
(9.16)
In other words, the algebra of all bounded operators on a Hilbert space is a
C∗-algebra under the involution T 7→T ∗.
Proof.
∥TT ∗∥
=
sup
∥φ∥=1
∥TT ∗φ∥
=
sup
∥φ∥=1,∥ψ∥=1
|(TT ∗φ, ψ)|
=
sup
∥φ∥=1,∥ψ∥=1
|(T ∗φ, T ∗ψ)|
≥
sup
∥φ∥=1
(T ∗φ, T ∗φ)
=
∥T ∗∥2
so
∥T ∗∥2 ≤∥TT ∗∥≤∥T∥∥T ∗∥
so
∥T ∗∥≤∥T∥.
Reversing the role of T and T ∗gives the reverse inequality so ∥T∥= ∥T ∗∥.
Inserting into the preceding inequality gives
∥T∥2 ≤∥TT ∗∥≤∥T∥2

9.5. THE SPECTRAL THEOREM FOR BOUNDED NORMAL OPERATORS, FUNCTIONAL CALCULUS FORM
so we have the equality (9.16). QED
Thus the map T 7→T ∗sending every bounded operator on a Hilbert space
into its adjoint is an anti-involution on the Banach algebra of all bounded op-
erators, and it satisﬁes (9.11). We can thus apply Theorem 9.4.2 to conclude:
Theorem 9.4.4 Let B be any commutative subalgebra of the algebra of bounded
operators on a Hilbert space which is closed in the strong topology and with
the property that T ∈B ⇒T ∗∈B.
Then the Gelfand transform T 7→ˆT
gives a norm preserving isomorphism of B with C(M) where M = Mspec(B).
Furthermore, (T ∗)ˆ = ˆT for all T ∈B. In particular, if T is self-adjoint, then
ˆT is real valued.
9.5
The Spectral Theorem for Bounded Normal
Operators, Functional Calculus Form.
As a special case of the deﬁnition we gave earlier, a (bounded) operator T on a
Hilbert space H is called normal if
TT ∗= T ∗T.
We can then consider the subalgebra of the algebra of all bounded operators
which is generated by e, the identity operator, T and T ∗. Take the closure, B,
of this algebra in the strong topology. We can apply the preceding theorem to
B to conclude that B is isometrically isomorphic to the algebra of all continuous
functions on the compact Hausdorﬀspace
M = Mspec(B).
Remember that a point of M is a homomorphism h : B →C and that
h(T ∗) = (T ∗)ˆ(h) = ˆT(h) = h(T).
Since h is a homomorphism, we see that h is determined on the algebra generated
by e, T and T ∗by the value h(T), and since it is continuous, it is determined
on all of B by the knowledge of h(T). We thus get a map
M →C,
M ∋h 7→h(T),
(9.17)
and we know that this map is injective. Now
h(T −h(T)e) = h(T) −h(T) = 0
so T −h(T)e belongs to the maximal ideal h, and hence is not invertible in the
algebra B. Thus the image of our map lies in SpecB(T). Here I have added the
subscript B, because our general deﬁnition of the spectrum of an element T in
an algebra B consists of those complex numbers z such that T −ze does not
have an inverse in B. If we let A denote the algebra of all bounded operators on

250CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
H, it is logically conceivable that T −ze has an inverse in A which does not lie
in B. In fact, this can not happen. But this requires a proof, which I will give
later. So for the time being I will stick with the temporary notation SpecB.
So the map h 7→h(T) actually maps M to the subset SpecB(T) of the
complex plane. If λ ∈SpecB(T), then by deﬁnition, T −λe is not invertible in
B, so lies in some maximal ideal h, so λ ∈SpecB(T). So the map (9.17) maps M
onto SpecB(T). Since the topology on M is inherited from the weak topology,
the map h 7→h(T) is continuous. Since M is compact and C is Hausdorﬀ,
the fact that h is bijective and continuous implies that h−1 is also continuous.
Indeed we must show that if U is an open subset of M, then h(U) is open in
SpecB(T). But M \ U is compact, hence its image under the continuous map
h is compact, hence closed, and so the complement of this image which is h(U)
is open.
Thus h is a homeomorphism, and hence we have a norm-preserving ∗-
isomorphism T 7→ˆT of B with the algebra of continuous functions on SpecB(T).
Furthermore the element T corresponds the function z 7→z (restricted to
SpecB(T)).
Since B is determined by T, let me use the notation σ(T) for SpecB(T),
postponing until later the proof that σ(T) = SpecA(T). Let me set
φ = h−1
and now follow the customary notation in Hilbert space theory and use I to
denote the identity operator.
9.5.1
Statement of the theorem.
Theorem 9.5.1 Let T be a bounded normal operator on a Hilbert space H. Let
B(T) denote the closure in the strong topology of the algebra generated by I, T
and T ∗. Then there is a unique continuous ∗isomorphism
φ : C(σ(T)) →B(T)
such that
φ(1) = I
and
φ(z 7→z) = T.
Furthermore,
Tψ = λψ,
ψ ∈H ⇒φ(f)ψ = f(λ)ψ.
(9.18)
If f ∈C(σ(T)) is real valued then φ(f) is self-adjoint, and if f ≥0 then φ(f) ≥0
as an operator.
The only facts that we have not yet proved (aside from the big issue of proving
that σ(T) = SpecA(T)) are (9.18) and the assertions which follow it. Now (9.18)
is clearly true if we take f to be a polynomial, in which case φ(f) = f(T). Then

9.5. THE SPECTRAL THEOREM FOR BOUNDED NORMAL OPERATORS, FUNCTIONAL CALCULUS FORM
just apply the Stone-Weierstrass theorem to conclude (9.18) for all f. If f is
real then f = f and therefore φ(f) = φ(f)∗. If f ≥0 then we can ﬁnd a real
valued g ∈C(σ(T) such that f = g2 and the square of a self-adjoint operator is
non-negative. QED
In view of this theorem, there is a more suggestive notation for the map φ.
Since the image of the monomial z is T, and since the image of any polynomial
P (thought of as a function on σ(T)) is P(T), we are safe in using the notation
f(T) := φ(f)
for any f ∈C(σ(T)).
9.5.2
SpecB(T) = SpecA(T).
Here is the main result of this section:
Theorem 9.5.2 Let A be a C∗algebra and let B be a subalgebra of A which is
closed under the involution. Then for any x ∈B we have
SpecB(x) = SpecA(x).
(9.19)
Remarks:
1.
Applied to the case where A is the algebra of all bounded operators on a
Hilbert space, and where B is the closed subalgebra by I, T and T ∗we get the
spectral theorem for normal operators as promised.
2.
If x −ze has no inverse in A it has no inverse in B. So
SpecA(x) ⊂SpecB(x).
We must show the reverse inclusion. We begin by formulating some general
results and introducing some notation.
For any associative algebra A we let G(A) denote the set of elements of A
which are invertible (the “group-like” elements).
Proposition 9.5.1 Let B be a Banach algebra, and let xn ∈G(B) be such that
xn →x and x ̸∈G(B). Then
∥x−1
n ∥→∞.
Proof. Suppose not. Then there is some C > 0 and a subsequence of elements
(which we will relabel as xn) such that
∥x−1
n ∥< C.
Then
x = xn(e + x−1
n (x −xn))
with x −xn →0. In particular, for n large enough
∥x−1
n ∥· ∥x −xn∥< 1,
so (e + x−1
n (x −xn)) is invertible as is xn and so x is invertible contrary to
hypothesis. QED

252CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.
Proposition 9.5.2 Let B be a closed subalgebra of a Banach algebra A con-
taining the unit e. Then
• G(B) is the union of some of the components of B ∩G(A).
• If x ∈B then SpecB(x) is the union of SpecA(x) and a (possibly empty)
collection of bounded components of C \ SpecA(x).
• If SpecA(x) does not separate the complex plane then
SpecB(x) = SpecA(x).
Proof.
We know that G(B) ⊂G(A) ∩B and both are open subsets of B.
We claim that G(A) ∩B contains no boundary points of G(B). If x were such
a boundary point, then x = lim xn for xn ∈G(B), and by the continuity of
the map y 7→y−1 in A we conclude that x−1
n
→x−1 in A, so in particular
the ∥xn∥−1 are bounded which is impossible by Proposition 9.5.1. Let O be a
component of B ∩G(A) which intersects G(B), and let U be the complement
of G(B). Then O ∩G(B) and O ∩U are open subsets of B and since O does
not intersect ∂G(B), the union of these two disjoint open sets is O. So O ∩U
is empty since we assumed that O is connected. Hence O ⊂G(B). This proves
the ﬁrst assertion.
For the second assertion, let us ﬁx the element x, and let
GA(x) = C \ SpecA(x)
so that GA(x) consists of those complex numbers z for which x−ze is invertible
in A, with a similar notation for GB(x).
Both of these are open subsets of
C and GB(x) ⊂GA(x). Furthermore, as before, GB(x) ⊂GA(x) and GA(x)
can not contain any boundary points of GB(x). So again, GB(x) is a union of
some of the connected components of GA(x). Therefore SpecB(x) is the union
of SpecA(x) and the remaining components. Since SpecB(x) is bounded, it will
not contain any unbounded components.
The third assertion follows immediately from the second. QED
But now we can prove Theorem 9.5.2. We need to show that if x ∈B is
invertible in A then it is invertible in B. If x is invertible in A then so are x∗and
xx∗. But xx∗is self-adjoint, hence its spectrum is a bounded subset of R, so
does not separate C. Since 0 ̸∈SpecA(xx∗) we conclude from the last assertion
of the proposition that 0 ̸∈SpecB(xx∗) so xx∗has an inverse in B. But then
x∗(xx∗)−1 ∈B
and
x
 x∗(xx∗)−1
= e.
QED.

9.5. THE SPECTRAL THEOREM FOR BOUNDED NORMAL OPERATORS, FUNCTIONAL CALCULUS FORM
9.5.3
A direct proof of the spectral theorem.
I started out this chaper with the general theory of Banach algebras, went to
the Gelfand representation theorem, the special properties of C∗algebras, and
then some general facts about how the spectrum of an element can vary with
the algebra containing it. I took this route because of the impact the Gelfand
representation theorem had on the course of mathematics, especially in algebraic
geometry. But the key ideas are
• (9.9), which, for a bounded operator T on a Banach space says that
max
λ∈Spec(T ) |λ| = lim
n→∞∥T n∥
1
n
,
• (9.16) which says that if T is a bounded operator on a Hilbert space then
∥TT ∗∥= ∥T∥2, and
• If T is a bounded operator on a Hilbert space and TT ∗= T ∗T then it
follows from (9.16) that
∥T 2k∥= ∥T∥2k.
We could prove these facts by the arguments given above and conclude that if
T is a normal bounded operator on a Hilbert space then
max
λ∈Spec(T ) |λ| = ∥T∥.
(9.20)
Suppose (for simplicity) that T is self-adjoint: T = T ∗. Then the argument
given several times above shows that Spec(T) ⊂R. Let P be a polynomial.
Then (9.1) combined with the preceding equation says that
∥P(T)∥=
max
λ∈Spec(T ) |P(λ)|.
(9.21)
The norm on the right is the restriction to polynomials of the uniform norm
∥· ∥∞on the space C(Spec(T)).
Now the map
P 7→P(T)
is a homomorphism of the ring of polynomials into bounded normal operators
on our Hilbert space satisfying
P 7→P(T)∗
and
∥P(T)∥= ∥P∥∞,Spec(T ).
The Weierstrass approximation theorem then allows us to conclude that this
homomorphism extends to the ring of continuous functions on Spec(T) with all
the properties stated in Theorem 9.5.1 .

254CHAPTER 9. BANACH ALGEBRAS AND THE SPECTRAL THEOREM.

Chapter 10
The spectral theorem.
The purpose of this chapter is to give a more thorough discussion of the spectral
theorem, especially for unbounded self-adjoint operators,
We begin by giving a slightly diﬀerent discussion showing how the Gelfand
representation theorem, especially for algebras with involution, implies the spec-
tral theorem for bounded self-adjoint (or, more generally normal) operators on
a Hilbert space. Recall that an operator T is called normal if it commutes
with T ∗. More generally, an element T of a Banach algebra A with involution
is called normal if TT ∗= T ∗T.
Let B be the closed commutative subalgebra generated by e, T and T ∗. We
know that B is isometrically isomorphic to the ring of continuous functions
on M, the space of maximal ideals of B, which is the same as the space of
continuous homomorphisms of B into the complex numbers.
We shall show
again that M can also be identiﬁed with SpecA(T), the set of all λ ∈C such that
(T −λe) is not invertible. This means that every continuous continuous function
ˆf on M = SpecA(T) corresponds to an element f of B. In the case where A
is the algebra of bounded operators on a Hilbert space, we will show that this
homomorphism extends to the space of Borel functions on SpecA(T).(In general
the image of the extended homomorphism will lie in A, but not necessarily in
B.) We now restrict attention to the case where A is the algebra of bounded
operators on a Hilbert space.
If U is a Borel subset of SpecA(T), let us denote the element of A corre-
sponding to 1U by P(U). Then
P(U)2 = P(U)
and P(U)∗= P(U)
so P(U) is a self adjoint (i.e. “orthogonal”) projection. Also, if U ∩V = ∅then
P(U)P(V ) = 0 and
P(U ∪V ) = P(U) + P(V ).
Thus U 7→P(U) is ﬁnitely additive. In fact, it is countably additive in the weak
sense that for any pair of vectors x, y in our Hilbert space H the map
µx,y :
U 7→(P(U)x, y)
255

256
CHAPTER 10. THE SPECTRAL THEOREM.
is a complex valued measure on M. We shall prove these results in partially
reversed order, in that we ﬁrst prove the existence of the complex valued measure
µx,y using the Riesz representation theorem describing all continuous linear
functions on C(M), and then deduce the existence of the resolution of the
identity or projection valued measure
U 7→P(U),
(more precise deﬁnition below) from which we can recover T. The key tool, in
addition to the Gelfand representation theorem and the Riesz theorem describ-
ing all continuous linear functions on C(M) as being signed measures is our
old friend, the Riesz representation theorem for continuous linear functions on
a Hilbert space.
10.1
Resolutions of the identity.
In this section B denotes a closed commutative self-adjoint subalgebra of the
algebra of all bounded linear operators on a Hilbert space H.
(Self-adjoint
means that T ∈B
⇒T ∗∈B.) By the Gelfand representation theorem we
know that B is isometrically isomorphic to C(M) under a map we denote by
T 7→ˆT
and we know that
T ∗7→ˆT.
Fix
x, y ∈H.
The map
ˆT 7→(Tx, y)
is a linear function on C(M) with
|(Tx, y)| ≤∥T∥∥x∥∥y∥= ∥ˆT∥∞∥x∥∥y∥.
In particular it is a continuous linear function on C(M). Hence, by the Riesz
representation theorem, there exists a unique complex valued bounded measure
µx,y
such that
(Tx, y) =
Z
M
ˆTdµx,y
∀ˆT ∈C(M).
When ˆT is real, T = T ∗so (Tx, y) = (x, Ty) = (Ty, x). The uniqueness of the
measure implies that
µy,x = µx,y.

10.1. RESOLUTIONS OF THE IDENTITY.
257
Thus, for each ﬁxed Borel set U ⊂M its measure µx,y(U) depends linearly on
x and anti-linearly on y. We have
µ(M) =
Z
M
1dµx,y = (ex, y) = (x, y)
so
|µx,y(M)| ≤∥x∥∥y∥.
So if f is any bounded Borel function on M, the integral
Z
M
fdµx,y
is well deﬁned, and is bounded in absolute value by ∥f∥∞∥x∥∥y∥. If we hold f
and x ﬁxed, this integral is a bounded anti-linear function of y, and hence by
the Riesz representation theorem there exists a w ∈H such that this integral
is given by (w, y). The w in question depends linearly on f and on x because
the integral does, and so we have deﬁned a linear map O from bounded Borel
functions on M to bounded operators on H such that
(O(f)x, y) =
Z
M
fdµx,y
and
∥O(f)∥≤∥f∥∞.
On continuous functions we have
O( ˆT) = T
so O is an extension of the inverse of the Gelfand transform from continuous
functions to bounded Borel functions. So we know that O is multiplicative and
takes complex conjugation into adjoint when restricted to continuous functions.
Let us prove these facts for all Borel functions.
If f is real we know that
(O(f)y, x) is the complex conjugate of (O(f)x, y) since µy,x = µx,y.
Hence
O(f) is self-adjoint if f is real from which we deduce that
O(f) = O(f)∗.
Now to the multiplicativity: For S, T ∈B we have
Z
M
ˆS ˆTdµx,y = (STx, y) =
Z
M
ˆSdµT x,y.
Since this holds for all ˆS ∈C(M) (for ﬁxed T, x, y) we conclude by the unique-
ness of the measure that
µT x,y = ˆTµx,y.
Therefore, for any bounded Borel function f we have
(Tx, O(f)∗y) = (O(f)Tx, y) =
Z
M
fdµT x,y =
Z
M
ˆTfdµx,y.

258
CHAPTER 10. THE SPECTRAL THEOREM.
This holds for all ˆT ∈C(M) and so by the uniqueness of the measure again, we
conclude that
µx,O(f)∗y = fµx,y
and hence
(O(fg)x, y) =
Z
M
gfdµx,y =
Z
M
gdµx,O(f)∗y = (O(g)x, O(f)∗y) = (O(f)O(g)x, y)
or
O(fg) = O(f)O(g)
as desired.
We have now extended the homomorphism from C(M) to A to a homo-
morphism from the bounded Borel functions on M to bounded operators on
H.
Now deﬁne:
P(U) := O(1U)
for any Borel set U. The following facts are immediate:
1. P(∅) = 0
2. P(M) = e the identity
3. P(U ∩V ) = P(U)P(V ) and P(U)∗= P(U). In particular, P(U) is a
self-adjoint projection operator.
4. If U ∩V = ∅then P(U ∪V ) = P(U) + P(V ).
5. For each ﬁxed x, y ∈H the set function Px,y : U 7→(P(U)x, y) is a
complex valued measure.
Such a P is called a resolution of the identity. It follows from the last item
that for any ﬁxed x ∈H, the map U 7→P(U)x is an H valued measure.
We have shown that any commutative closed self-adjoint subalgebra B of
the algebra of bounded operators on a Hilbert space H gives rise to a unique
resolution of the identity on M = Mspec(B) such that
T =
Z
M
ˆTdP
(10.1)
in the “weak” sense that
(Tx, y) =
Z
M
ˆTdµx,y
µx,y(U) = (P(U)x, y).
Actually, given any resolution of the identity we can give a meaning to the
integral
Z
M
fdP

10.1. RESOLUTIONS OF THE IDENTITY.
259
for any bounded Borel function f in the strong sense as follows: if
s =
X
αi1Ui
is a simple function where
M = U1 ∪· · · ∪Un,
Ui ∩Uj = ∅,
i ̸= j
and α1, . . . , αn ∈C, deﬁne
O(s) :=
X
αiP(Ui) =:
Z
M
sdP.
This is well deﬁned on simple functions (is independent of the expression) and
is multiplicative
O(st) = O(s)O(t).
Also, since the P(U) are self adjoint,
O(s) = O(s)∗.
It is also clear that O is linear and
(O(s)x, y) =
Z
M
sdPx,y.
As a consequence, we get
∥O(s)x∥2 = (O(s)∗O(s)x, x) =
Z
M
|s|2dPx,x
so
∥O(s)x)∥2 ≤|s∥∞∥x∥2.
If we choose i such that |αi| = ∥s∥∞and take x = P(Ui)y ̸= 0, then we see that
∥O(s)∥= ∥s∥∞
provided we now take ∥f∥∞to denote the essential supremum which means
the following:
It follows from the properties of a resolution of the identity that if Un is a
sequence of Borel sets such that P(Un) = 0, then P(U) = 0 if U = S Un. So if f
is any complex valued Borel function on M, there will exist a largest open subset
V ⊂C such that P(f −1(V )) = 0. We deﬁne the essential range of f to be
the complement of V , say that f is essentially bounded if its essential range
is compact, and then deﬁne its essential supremum ∥f∥∞to be the supremum
of |λ| for λ in the essential range of f. Furthermore we identify two essentially
bounded functions f and g if ∥f −g∥∞= 0 and call the corresponding space
L∞(P).

260
CHAPTER 10. THE SPECTRAL THEOREM.
Every element of L∞(P) can be approximated in the ∥∥∞norm by simple
functions, and hence the integral
O(f) =
Z
M
fdP
is deﬁned as the strong limit of the integrals of the corresponding simple func-
tions. The map f 7→O(f) is linear, multiplicative, and satisﬁes
O(f) = O(f)∗
and
∥O(f)∥= ∥f∥∞
as before.
If S is a bounded operator on H which commutes with all the O(f) then it
commutes with all the P(U) = O(1U). Conversely, if S commutes with all the
P(U) it commutes with all the O(s) for s simple and hence with all the O(f).
Putting it all together we have:
Theorem 10.1.1 Let B be a commutative closed self adjoint subalgebra of the
algebra of all bounded operators on a Hilbert space H.
Then there exists a
resolution of the identity P deﬁned on M = Mspec(B) such that (10.1) holds.
The map ˆT 7→T of C(M) →B given by the inverse of the Gelfand transform
extends to a map O from L∞(P) to the space of bounded operators on H
O(f) =
Z
M
fdP.
Furthermore, P(U) ̸= 0 for any non-empty open set U and an operator S com-
mutes with every element of B if and only if it commutes with all the P(U) in
which case it commutes with all the O(f).
We must prove the last two statements. If U is open, we may choose T ̸= 0
such that ˆT is supported in U (by Urysohn’s lemma). But then (10.1) implies
that T = 0, a contradiction.
For any bounded operator S and any x, y ∈H and T ∈B we have
(STx, y) = (Tx, S∗y) =
Z
ˆTdPx,S∗y
while
(TSx, y) =
Z
ˆTdPSx,y.
If ST = TS for all T ∈B this means that the measures PSx,y and Px,S∗y are
the same, which means that
(P(U)Sx, y) = (P(U)x, S∗y) = (SP(U)x, y)
for all x and y which means that
SP(U) = P(U)S
for all U. We already know that SP(U) = P(U)S for all S implies that SO(f) =
O(f)S for all f ∈L∞(P). QED

10.2. THE SPECTRAL THEOREM FOR BOUNDED NORMAL OPERATORS.261
10.2
The spectral theorem for bounded normal
operators.
Let T be a bounded operator on a Hilbert space H satisfying
TT ∗= T ∗T.
Recall that such an operator is called normal.
Let B be the closure of the
algebra generated by e, T and T ∗. We can apply the theorem of the preceding
section to this algebra. The one useful additional fact is that we may identify
M with Spec(T). Indeed, deﬁne the map
M →Spec(T)
by
h 7→h(T).
We know that h(T −h(T)e) = 0 so T −h(T)e lies in the maximal ideal cor-
responding to h and so is not invertible, consequently h(T) ∈Spec(T). So the
map is indeed into Spec(T).
If λ ∈Spec(T) then by deﬁnition T −λe is not invertible, hence lie in
some maximal ideal, hence λ = h(T) for some h so this map is surjective. If
h1(T) = h2(T) then h1(T ∗) = h1(T) = h2(T ∗). Since h1 agrees with h2 on T
and T ∗they agree on all of B, hence h1 = h2. In other words the map h 7→h(T)
is injective. From the deﬁnition of the topology on M it is continuous. Since
M is compact, this implies that it is a homeomorphism. QED
Thus in the theorem of the preceding section, we may replace M by Spec T
when B is the closed algebra generated by T and T ∗where T is a normal
operator.
In the case that T is a self-adjoint operator, we know that Spec T ⊂R, so
our resolution of the identity P is deﬁned as a projection valued measure on R
and (10.1) gives a bounded selfadjoint operator as
T =
Z
λdP
relative to a resolution of the identity deﬁned on R.
10.3
Stone’s formula.
Let T be a bounded self-adjoint operator. We know that
T =
Z
R
λdP(λ)
for some projection valued measure P on R. We also know that every bounded
Borel function on R gives rise to an operator. In particular, if z is a complex
number which is not real, the function
λ 7→
1
λ −z

262
CHAPTER 10. THE SPECTRAL THEOREM.
is bounded, and hence corresponds to a bounded operator
R(z, T) =
Z
R
(z −λ)−1dP(λ).
Since
(ze −T) =
Z
R
(z −λ)dP(λ)
and our homomorphism is multiplicative, we have
R(z, T) = (z −T)−1.
A conclusion of the above argument is that this inverse does indeed exist for all
non-real z. The operator (valued function) R(z, T) is called the resolvent of
T. Stone’s formula gives an expression for the projection valued measure in
terms of the resolvent. It says that for any real numbers a < b we have
s- lim
ϵ→0
1
2πi
Z b
a
[R(λ −iϵ, T) −R(λ + iϵ, T)] dλ = 1
2 (P((a, b)) + P([a, b])) .
(10.2)
Although this formula cries out for a “complex variables” proof, and I plan to
give one later, we can give a direct “real variables” proof in terms of what we
already know. Indeed, let
fϵ(x) :=
1
2πi
Z b
a

1
x −λ −iϵ −
1
x −λ + iϵ

dλ.
We have
fϵ(x) = 1
π
Z b
a
ϵ
(x −λ)2 + ϵ2 dλ = 1
π

arctan
x −a
ϵ

−arctan
x −b
ϵ

.
The expression on the right is uniformly bounded, and approaches zero if x ̸∈
[a, b], approaches 1
2 if x = a or x = b, and approaches 1 if x ∈(a, b). In short,
lim
ϵ→0 fϵ(x) = 1
2(1(a,b) + 1[a,b]).
We may apply the dominated convergence theorem to conclude Stone’s formula.
QED
10.4
Unbounded operators.
Many important operators in Hilbert space that arise in physics and mathe-
matics are “unbounded”. For example the operator D = 1
i
d
dx on L2(R). This
operator is not deﬁned on all of L2, and where it is deﬁned it is not bounded
as an operator. One of the great achievements of Wintner in the late 1920’s,

10.5. OPERATORS AND THEIR DOMAINS.
263
followed by Stone and von Neumann was to prove a version of the spectral
theorem for unbounded self-adjoint operators.
There are two (or more) approaches we could take to the proof of this the-
orem. Both involve the resolvent
Rz = R(z, T) = (zI −T)−1.
(10.3)
After spending some time explaining what an unbounded operator is and giving
the very subtle deﬁnition of what an unbounded self-adjoint operator is, we
will prove that the resolvent of a self-adjoint operator exists and is a bounded
normal operator for all non-real z.
We could then apply the spectral theorem for bounded normal operators
to derive the spectral theorem for unbounded self-adjoint operators. This is
the fastest approach, but depends on the whole machinery of the Gelfand rep-
resentation theorem that we have developed so far. Or, we could could prove
the spectral theorem for unbounded self-adjoint operators directly using (a mild
modiﬁcation of) Stone’s formula. We will present both methods. In the second
method we will follow the treatment by Lorch.
10.5
Operators and their domains.
Let B and C be Banach spaces. We make B ⊕C into a Banach space via
∥{x, y}∥= ∥x∥+ ∥y∥.
Here we are using {x, y} to denote the ordered pair of elements x ∈B and
y ∈C so as to avoid any conﬂict with our notation for scalar product in a
Hilbert space. So {x, y} is just another way of writing x ⊕y.
A subspace
Γ ⊂B ⊕C
will be called a graph (more precisely a graph of a linear transformation) if
{0, y} ∈Γ
⇒y = 0.
Another way of saying the same thing is
{x, y1} ∈Γ and {x, y2} ∈Γ
⇒y1 = y2.
In other words, if {x, y} ∈Γ then y is determined by x. So let
D(Γ) denote the set of all x ∈B such that there is a y ∈C with {x, y} ∈Γ.
Then D(Γ) is a linear subspace of B, but, and this is very important, D(Γ) is
not necessarily a closed subspace. We have a linear map
T(Γ) : D(Γ) →C,
Tx = y where {x, y} ∈Γ.

264
CHAPTER 10. THE SPECTRAL THEOREM.
Equally well, we could start with the linear transformation: Suppose we are
given a (not necessarily closed) subspace D(T) ⊂B and a linear transformation
T : D(T) →C.
We can then consider its graph Γ(T) ⊂B ⊕C which consists of all
{x, Tx}.
Thus the notion of a graph, and the notion of a linear transformation deﬁned
only on a subspace of B are logically equivalent. When we start with T (as
usually will be the case) we will write D(T) for the domain of T and Γ(T) for
the corresponding graph. There is a certain amount of abuse of language here,
in that when we write T, we mean to include D(T) and hence Γ(T) as part of
the deﬁnition.
A linear transformation is said to be closed if its graph is a closed subspace
of B ⊕C. Let us disentangle what this says for the operator T. It says that if
fn ∈D(T) then
fn →f and Tfn →g
⇒f ∈D(T) and Tf = g.
This is a much weaker requirement than continuity. Continuity of T would say
that fn →f alone would imply that Tfn converges to Tf. Closedness says that
if we know that both fn converges and gn = Tfn converges then we can conclude
that f = lim fn lies in D(T) and that Tf = g.
An important theorem, known as the closed graph theorem says that if T is
closed and D(T) is all of B then T is bounded. As we will not need to use this
theorem in this lecture, we will not present its proof here.
10.6
The adjoint.
Suppose that we have a linear operator T : D(T) →C and let us make the
hypothesis that
D(T) is dense in B.
Any element of B∗is then completely determined by its restriction to D(T).
Now consider
Γ(T)∗⊂C∗⊕B∗
deﬁned by
{ℓ, m} ∈Γ(T)∗
⇔⟨ℓ, Tx⟩= ⟨m, x⟩
∀x ∈D(T).
(10.4)
Since m is determined by its restriction to D(T), we see that Γ∗= Γ(T ∗) is
indeed a graph. (It is easy to check that it is a linear subspace of C∗⊕B∗.) In
other words we have deﬁned a linear transformation
T ∗:= T(Γ(T)∗)

10.7. SELF-ADJOINT OPERATORS.
265
whose domain consists of all ℓ∈C∗such that there exists an m ∈B∗for which
⟨ℓ, Tx⟩= ⟨m, x⟩
∀x ∈D(T).
If ℓn →ℓand mn →m then the deﬁnition of convergence in these spaces
implies that for any x ∈D(T) we have
⟨ℓ, Tx⟩= lim⟨ℓn, Tx⟩= lim⟨mn, x⟩= ⟨m, x⟩.
If we let x range over all of D(T) we conclude that Γ∗is a closed subspace of
C∗⊕B∗. In other words we have proved
Theorem 10.6.1 If T : D(T) →C is a linear transformation whose domain
D(T) is dense in B, it has a well deﬁned adjoint T ∗whose graph is given by
(10.4). Furthermore T ∗is a closed operator.
10.7
Self-adjoint operators.
Now let us restrict to the case where B = C = H is a Hilbert space, so we
may identify B∗= C∗= H∗with H via the Riesz representation theorem. If
T : D(T) →H is an operator with D(T) dense in H we may identify the domain
of T ∗as consisting of all {g, h} ∈H ⊕H such that
(Tx, g) = (x, h)
∀x ∈D(T)
and then write
(Tx, g) = (x, T ∗g)
∀x ∈D(T),
g ∈D(T ∗).
We now come to the central deﬁnition: An operator A deﬁned on a domain
D(A) ⊂H is called self-adjoint if
• D(A) is dense in H,
• D(A) = D(A∗), and
• Ax = A∗x ∀x ∈D(A).
The conditions about the domain D(A) are rather subtle, and we shall go into
some of their subtleties in a later lecture. For the moment we record one imme-
diate consequence of the theorem of the preceding section:
Proposition 10.7.1 Any self adjoint operator is closed.
If we combine this proposition with the closed graph theorem which asserts
that a closed operator deﬁned on the whole space must be bounded, we derive
a famous theorem of Hellinger and Toeplitz which asserts that any self adjoint
operator deﬁned on the whole Hilbert space must be bounded. This shows that
for self-adjoint operators, being globally deﬁned and being bounded amount
to the same thing. At the time of its appearance in the second decade of the
twentieth century, this theorem of Hellinger and Toeplitz was considered an
astounding result. It was only after the work of Banach, in particular the proof
of the closed graph theorem, that this result could be put in proper perspective.

266
CHAPTER 10. THE SPECTRAL THEOREM.
10.8
The resolvent.
The following theorem will be central for us.
Theorem 10.8.1 Let A be a self-adjoint operator on a Hilbert space H with
domain D = D(A). Let
c = λ + iµ,
µ ̸= 0
be a complex number with non-zero imaginary part. Then
(cI −A) : D(A) →H
is bijective. Furthermore the inverse transformation
(cI −A)−1 : H →D(A)
is bounded and in fact
∥(cI −A)−1∥≤1
|µ|.
(10.5)
Remark. In the case of a bounded self adjoint operator this is an immediate
consequence of the spectral theorem, more precisely of the fact that Gelfand
transform is an isometric isomorphism of the closed algebra generated by A
with the algebra C(Spec A). Indeed, the function λ 7→1/(c −λ) is bounded
on the whole real axis with supremum 1/|µ|. Since Spec(A) ⊂R we conclude
that (cI −A)−1 exists and its norm satisﬁes (10.5). We will now give a direct
proof of this theorem valid for general self-adjoint operators, and will use this
theorem for the proof of the spectral theorem in the general case.
Proof.
Let g ∈D(A) and set
f = (cI −A)g = [λI −A]g + iµg.
Then ∥f∥2 = (f, f) =
∥[cI −A]g∥2 + µ2∥g∥2 + ([λI −A]g, iµg) + (iµg, [λI −A]g).
I claim that these last two terms cancel. Indeed, since g ∈D(A) and A is self
adjoint we have
(µg, [λI −A]g) = (µ[λI −A]g, g) = ([λI −A]g, µg)
since µ is real. Hence
([λI −A]g, iµg) = −i(µg, [λI −A]g).
We have thus proved that
∥f∥2 = ∥(λI −A)g∥2 + µ2∥g∥2.
(10.6)

10.8. THE RESOLVENT.
267
In particular
∥f∥2 ≥µ2∥g∥2
for all g ∈D(A). Since |µ| > 0, we see that f = 0 ⇒g = 0 so (cI −A) is
injective on D(A), and furthermore that that (cI −A)−1 (which is deﬁned on
im (cI −A))satisﬁes (10.5). We must show that this image is all of H.
First we show that the image is dense. For this it is enough to show that
there is no h ̸= 0 ∈H which is orthogonal to im (cI −A). So suppose that
([cI −A]g, h) = 0
∀g ∈D(A).
Then
(g, ch) = (cg, h) = (Ag, h) ∀g ∈D(A)
which says that h ∈D(A∗) and A∗h = ch. But A is self adjoint so h ∈D(A)
and Ah = ch. Thus
c(h, h) = (ch, h) = (Ah, h) = (h, Ah) = (h, ch) = c(h, h).
Since c ̸= c this is impossible unless h = 0. We have now established that the
image of cI −A is dense in H.
We now prove that it is all of H. So let f ∈H. We know that we can ﬁnd
fn = (cI −A)gn,
gn ∈D(A)
with fn →f.
The sequence fn is convergent, hence Cauchy, and from (10.5) applied to ele-
ments of D(A) we know that
∥gm −gn∥≤|µ|−1∥fn −fm∥.
Hence the sequence {gn} is Cauchy, so gn →g for some g ∈H. But we know
that A is a closed operator. Hence g ∈D(A) and (cI −A)g = f. QED
The operator
Rz = Rz(A) = (zI −A)−1
is called the resolvent of A when it exists as a bounded operator. The set
of z ∈C for which the resolvent exists is called the resolvent set and the
complement of the resolvent set is called the spectrum of the operator. The
preceding theorem asserts that the spectrum of a self-adjoint operator is a subset
of the real numbers.
Let z and w both belong to the resolvent set. We have
wI −A = (w −z)I + (zI −A).
Multiplying this equation on the left by Rw gives
I = (w −z)Rw + Rw(zI −A),

268
CHAPTER 10. THE SPECTRAL THEOREM.
and multiplying this on the right by Rz gives
Rz −Rw = (w −z)RwRz.
From this it follows (interchanging z and w) that RzRw = RwRz, in other words
all resolvents Rz commute with one another and we can also write the preceding
equation as
Rz −Rw = (w −z)RzRw.
(10.7)
This equation, which is known as the resolvent equation dates back to the
theory of integral equations in the nineteenth century.
It follows from the resolvent equation that z 7→Rz (for ﬁxed A) is a contin-
uous function of z. Once we know that the resolvent is a continuous function of
z, we may divide the resolvent equation by (z −w) if z ̸= w and, if w is interior
to the resolvent set, conclude that
lim
z→w
Rz −Rw
z −w
= −R2
w.
This says that the “derivative in the complex sense” of the resolvent exists and is
given by −R2
z. In other words, the resolvent is a “holomorphic operator valued”
function of z.
To emphasize this holomorphic character of the resolvent, we have
Proposition 10.8.1 Let z belong to the resolvent set. The the open disk of
radius ∥Rz∥−1 about z belongs to the resolvent set and on this disk we have
Rw = Rz(I + (z −w)Rz + (z −w)2R2
z + · · · ).
(10.8)
Proof.
The series on the right converges in the uniform topology since |z −
w| < ∥Rz∥−1. Multiplying this series by (zI −A) −(z −w)I gives I. But
zI −A −(z −w)I = wI −A. So the right hand side is indeed Rw. QED
This suggests that we can develop a “Cauchy theory” of integration of func-
tions such as the resolvent, and we shall do so, eventually leading to a proof of
the spectral theorem for unbounded self-adjoint operators.
However we ﬁrst give a proof (following the treatment in Reed-Simon) in
which we derive the spectral theorem for unbounded operators from the Gelfand
representation theorem applied to the closed algebra generated by the bounded
normal operators (±iI −A)−1.
10.9
The multiplication operator form of the spec-
tral theorem.
We ﬁrst state this theorem for closed commutative self-adjoint algebras of (bounded)
operators. Recall that “self-adjoint” in this context means that if T ∈B then
T ∗∈B.

10.9. THE MULTIPLICATION OPERATOR FORM OF THE SPECTRAL THEOREM.269
Theorem 10.9.1 Let B be a commutative closed self-adjoint subalgebra of the
algebra of all bounded operators on a separable Hilbert space H. Then there
exists a measure space (M, F, µ) with µ(M) < ∞, a unitary isomorphism
W : H →L2(M, µ),
and a map
B →
bounded measurable functions on M,
T 7→˜T
such that
[(WTW −1)f](m) = ˜T(m)f(m).
In fact, M can be taken to be a ﬁnite or countable disjoint union of M =
Mspec(B)
M =
N
[
1
Mi,
Mi = M
N ∈Z+ ∪∞and
˜T(m) = ˆT(m)
if m ∈Mi = M.
In short, the theorem says that any such B is isomorphic to an algebra of
multiplication operators on an L2 space. We prove the theorem in two stages.
10.9.1
Cyclic vectors.
An element x ∈H is called a cyclic vector for B if Bx = H. In more mundane
terms this says that the space of linear combinations of the vectors Tx, T ∈B
are dense in H.
For example, if B consists of all multiples of the identity operator, then Bx
consists of all multiples of x, so B can not have a cyclic vector unless H is one
dimensional. More generally, if H is ﬁnite dimensional and B is the algebra
generated by a self-adjoint operator, then B can not have a cyclic vector if A
has a repeated eigenvalue.
Proposition 10.9.1 Suppose that x is a cyclic vector for B. Then it is a cyclic
vector for the projection valued measure P on M associated to B in the sense
that the linear combinations of the vectors P(U)x are dense in H as U ranges
over the Borel sets on M.
Proof.
Suppose not. Then there exists a non-zero y ∈H such that
(P(U)x, y) = 0
for all Borel subset U of M. Then
(Tx, y) =
Z
M
ˆTd(P(U)x, y) = 0

270
CHAPTER 10. THE SPECTRAL THEOREM.
which contradicts the assumption that the linear combinations of the Tx are
dense in H. QED
Let us continue with the assumption that x is a cyclic vector for B. Let
µ = µx,x
so
µ(U) = (P(U)x, x).
This is a ﬁnite measure on M, in fact
µ(M) = ∥x∥2.
(10.9)
We will construct a unitary isomorphism of H with L2(M, µ) starting with the
assignment
Wx = 1 = 1M.
We would like this to be a B morphism, even a morphism for the action of
multiplication by bounded Borel functions. This forces the deﬁnition
WP(U)x = 1U1 = 1U.
This then forces
W[c1P(U1)x + · · · cnP(Un)x] = s
for any simple function
s = c11U1 + · · · cn1Un.
A direct check shows that this is well deﬁned for simple functions. We can write
this map as
W [O(s)x] = s,
and another direct check shows that
∥W [O(s)x] ∥= ∥s∥2
where the norm on the right is the L2 norm relative to the measure µ. Since
the simple functions are dense in L2(M, µ) and the vectors O(s)x are dense in
H this extends to a unitary isomorphism of H onto L2(M, µ). Furthermore,
W −1(f) = O(f)x
for any f ∈L2(M, µ). For simple functions, and therefore for all f ∈L2(M, µ)
we have
W −1( ˆTf) = O( ˆTf)x = TO(f)x = TW −1(f)
or
(WTW −1)f = ˆTf
which is the assertion of the theorem.
In other words we have proved the
theorem under the assumption of the existence of a cyclic vector.

10.9. THE MULTIPLICATION OPERATOR FORM OF THE SPECTRAL THEOREM.271
10.9.2
The general case.
Start with any non-zero vector x1 and consider H1 = Bx1 = the closure of
linear combinations of Tx1, T ∈B. The space H1 is a closed subspace of H
which is invariant under B, i.e. TH1 ⊂H1 ∀T ∈B. Therefore the space H⊥
1
is also invariant under B since if (x1, y) = 0 then
(x1, Ty) = (T ∗x1, y) = 0 since T ∗∈B.
Now if H1 = H we are done, since x1 is a cyclic vector for B acting on H1.
If not choose a non-zero x2 ∈H2 and repeat the process. We can choose a
collection of non-zero vectors zi whose linear combinations are dense in H - this
is the separability assumption. So we may choose our xi to be obtained from
orthogonal projections applied to the zi. In other words we have
H = H1 ⊕H2 ⊕H3 ⊕· · ·
where this is either a ﬁnite or a countable Hilbert space (completed) direct sum.
Let us also take care to choose our xn so that
X
∥xn∥2 < ∞
which we can do, since cnxn is just as good as xn for any cn ̸= 0. We have a
unitary isomorphism of Hn with L2(M, µn) where µn(U) = (P(U)xn, xn). In
particular,
µn(M) = ∥xn∥2.
So if we take M to be the disjoint union of copies Mn of M each with measure
µn then the total measure of M is ﬁnite and
L2(M) =
M
L2(Mn, µn)
where this is either a ﬁnite direct sum or a (Hilbert space completion of) a
countable direct sum. Thus the theorem for the cyclic case implies the theorem
for the general case. QED
10.9.3
The spectral theorem for unbounded self-adjoint
operators, multiplication operator form.
We now let A be a (possibly unbounded) self-adjoint operator, and we apply the
previous theorem to the algebra generated by the bounded operators (±iI−A)−1
which are the adjoints of one another. Observe that there is no non-zero vector
y ∈H such that
(A + iI)−1y = 0.
Indeed if such a y ∈H existed, we would have
0 = (x, (A + iI)−1y) = ((A −iI)−1x, y) = −((iI −A)−1x, y)
∀x ∈H

272
CHAPTER 10. THE SPECTRAL THEOREM.
and we know that the image of (iI −A)−1 is D(A) which is dense in H.
Now consider the function
 (A + iI)−1
˜ on M given by Theorem 10.9.1. It
can not vanish on any set of positive measure, since any function supported on
such a set would be in the kernel of the operator consisting of multiplication by
 (A + iI)−1
˜.
Thus the function
˜A :=
 (A + iI)−1
˜
−1 −i
is ﬁnite almost everywhere on M relative to the measure µ although it might
(and generally will) be unbounded. Our plan is to show that under the unitary
isomorphism W the operator A goes over into multiplication by ˜A.
First we show
Proposition 10.9.2 x ∈D(A) if and only if ˜AWx ∈L2(M, µ).
Proof. Suppose x ∈D(A). Then x = (A + iI)−1y for some y ∈H and so
Wx =
 (A + iI)−1
˜f,
f = Wy.
But
˜A
 (A + iI)−1
˜ = 1 −ih
where
h =
 (A + iI)−1
˜
is a bounded function. Thus ˜AWx ∈L2(M, µ).
Conversely, if ˜AWx ∈L2(M, µ), then ( ˜A + iI)Wx ∈L2(M, µ), which means
that there is a y ∈H such that Wy = ( ˜A + iI)Wx. Therefore
 (A + iI)−1
˜( ˜A + iI)Wx = Wx
and hence
x = (A + iI)−1y ∈D(A).
QED
Proposition 10.9.3 If h ∈W(D(A)) then ˜Ah = WAW −1h.
Proof.
Let x = W −1h which we know belongs to D(A) so we may write
x = (A + iI)−1y for some y ∈H, and hence
Ax = y −ix
and Wy =
 (A + iI)−1
˜
−1 h.
So
WAx
=
Wy −iWx
=
 (A + iI)−1
˜
−1 h −ih
=
˜Ah
QED

10.9. THE MULTIPLICATION OPERATOR FORM OF THE SPECTRAL THEOREM.273
The function ˜A must be real valued almost everywhere since if its imaginary
part were positive (or negative) on a set U of positive measure, then ( ˜A1U, 1U)2
would have non-zero imaginary part contradicting the fact that multiplication
by ˜A is a self adjoint operator, being unitarily equivalent to the self adjoint
operator A.
Putting all this together we get
Theorem 10.9.2 Let A be a self adjoint operator on a separable Hilbert space
H.
Then there exists a ﬁnite measure space (M, µ), a unitary isomorphism
W : H →L2(M, µ) and a real valued measurable function ˜A which is ﬁnite
almost everywhere such that x ∈D(A) if and only if ˜AWx ∈L2(M, µ) and if
h ∈W(D(A)) then ˜Ah = WAW −1h.
10.9.4
The functional calculus.
Let f be any bounded Borel function deﬁned on R. Then
f ◦˜A
is a bounded function deﬁned on M. Multiplication by this function is a bounded
operator on L2(M, µ) and hence corresponds to a bounded self-adjoint operator
on H. With a slight abuse of language we might denote this operator by O(f◦˜A).
However we will use the more suggestive notation
f(A).
The map
f 7→f(A)
• is an algebraic homomorphism,
• f(A) = f(A)∗,
• ∥f(A)∥≤∥f∥∞where the norm on the left is the uniform operator norm
and the norm on the right is the sup norm on R
• if Ax = λx then f(A)x = f(λ)x,
• if f ≥0 then f(A) ≥0 in the operator sense,
• if fn →f pointwise and if ∥fn∥∞is bounded, then fn(A) →f(A) strongly,
and
• if fn is a sequence of Borel functions on the line such that |fn(λ)| ≤|λ|
for all n and for all λ ∈R, and if fn(λ) →λ for each ﬁxed λ ∈R then for
each x ∈D(A)
fn(A)x →Ax.

274
CHAPTER 10. THE SPECTRAL THEOREM.
All of the above statements are obvious except perhaps for the last two which
follow from the dominated convergence theorem. It is also clear from the pre-
ceding discussion that the map f 7→f(A) is uniquely determined by the above
properties.
Multiplication by the function eit ˜
A is a unitary operator on L2(M, µ) and
eis ˜
Aeit ˜
A = ei(s+t) ˜
A.
Hence from the above we conclude
Theorem 10.9.3 [Half of Stone’s theorem.] For an self adjoint operator A
the operator eitA given by the functional calculus as above is a unitary operator
and
t 7→eitA
is a one parameter group of unitary transformations.
The full Stone’s theorem asserts that any unitary one parameter groups is
of this form. We will discuss this later.
10.9.5
Resolutions of the identity.
For each measurable subset X of the real line we can consider its indicator
function 1X and hence 1X(A) which we shall denote by P(X). In other words
P(X) := 1X(A).
It follows from the above that
P(X)∗
=
P(X)
P(X)P(Y )
=
P(X ∩Y )
P(X ∪Y )
=
P(X) + P(Y ) if X ∩Y = 0
P(X)
=
s −lim
N
X
1
P(Xi) if Xi ∩Xj = ∅if i ̸= j and X =
[
Xi
P(∅)
=
0
P(R)
=
I.
For each x, y ∈H we have the complex valued measure
Px,y(X) = (P(X)x, y)
and for any bounded Borel function f we have
(f(A)x, y) =
Z
R
f(λ)dPx,y.

10.9. THE MULTIPLICATION OPERATOR FORM OF THE SPECTRAL THEOREM.275
If g is an unbounded (complex valued) Borel function on R we deﬁne D(g(A))
to consist of those x ∈H for which
Z
R
|g(λ)|2dPx,x < ∞.
The set of such x is dense in H and we deﬁne g(A) on D(A) by
(g(A)x, y) =
Z
R
g(λ)dPx,y
for x, y ∈D(g(A)) (and the Riesz representation theorem).
This is written
symbolically as
g(A) =
Z
R
g(λ)dP.
In the special case g(λ) = λ we write
A =
Z
R
λdP.
this is the spectral theorem for self adjoint operators.
In the older literature one often sees the notation
Eλ := P(−∞, λ).
A translation of the properties of P into properties of E is
E2
λ
=
Eλ
(10.10)
E∗
λ
=
Eλ
(10.11)
λ < µ
⇒
EλEµ = Eλ
(10.12)
λn→−∞
⇒
Eλn →0 strongly
(10.13)
λn →+∞
⇒
Eλn →I strongly
(10.14)
λn ↗λ
⇒
En →Eλ strongly.
(10.15)
One then writes the spectral theorem as
A =
Z ∞
−∞
λdEλ.
(10.16)
We shall now give an alternative proof of this formula which does not depend
on either the Gelfand representation theorem or any of the limit theorems of
Lebesgue integration. Instead, it depends on the Riesz-Dunford extension of the
Cauchy theory of integration of holomorphic functions along curves to operator
valued holomorphic functions.

276
CHAPTER 10. THE SPECTRAL THEOREM.
10.10
The Riesz-Dunford calculus.
Suppose that we have a continuous map z 7→Sz deﬁned on some open set
of complex numbers, where Sz is a bounded operator on some ﬁxed Banach
space and by continuity, we mean continuity relative to the uniform metric on
operators. If C is a continuous piecewise diﬀerentiable (or more generally any
rectiﬁable) curve lying in this open set, and if t 7→z(t) is a piecewise smooth (or
rectiﬁable) parametrization of this curve, then the map t 7→Sz(t) is continuous.
For any partition 0 = t0 ≤t1 ≤· · · ≤tn = 1 of the unit interval we can form
the Cauchy approximating sum
n
X
i=1
Sz(ti(z(ti) −z(ti−1),
and the usual proof of the existence of the Riemann integral shows that this
tends to a limit as the mesh becomes more and more reﬁned and the mesh
distance tends to zero. The limit is denoted by
Z
C
Szdz
and this notation is justiﬁes because the change of variables formula for an
ordinary integral shows that this value does not depend on the parametrization,
but only on the orientation of the curve C.
We are going to apply this to Sz = Rz, the resolvent of an operator, and
the main equations we shall use are the resolvent equation (10.7) and the power
series for the resolvent (10.8) which we repeat here:
Rz −Rw = (w −z)RzRw
and
Rw = Rz(I + (z −w)Rz + (z −w)2R2
z + · · · ).
We proved that the resolvent of a self-adjoint operator exists for all non-real
values of z.
But a lot of the theory goes over for the resolvent
Rz = R(z, T) = (zI −T)−1
where T is an arbitrary operator on a Banach space, so long as we restrict
ourselves to the resolvent set, i.e. the set where the resolvent exists as a bounded
operator. So, following Lorch Spectral Theory we ﬁrst develop some facts about
integrating the resolvent in the more general Banach space setting (where our
principal application will be to the case where T is a bounded operator).
For example, suppose that C is a simple closed curve contained in the disk
of convergence about z of (10.8) i.e. of the above power series for Rw. Then we
can integrate the series term by term. But
Z
C
(z −w)ndw = 0

10.10. THE RIESZ-DUNFORD CALCULUS.
277
for all n ̸= −1 so
Z
C
Rwdw = 0.
By the usual method of breaking any any deformation up into a succession of
small deformations and then breaking any small deformation up into a sequence
of small “rectangles” we conclude
Theorem 10.10.1 If two curves C0 and C1 lie in the resolvent set and are
homotopic by a family Ct of curves lying entirely in the resolvent set then
Z
C0
Rzdz =
Z
C1
Rzdz.
Here are some immediate consequences of this elementary result.
Suppose that T is a bounded operator and |z| > ∥T∥. Then
(zI −T)−1 = z−1(I −z−1T)−1 = z−1(I + z−1T + z−2T 2 + · · · )
exists because the series in parentheses converges in the uniform metric.
In
other words, all points in the complex plane outside the disk of radius ∥T∥lie
in the resolvent set of T. From this it follows that the spectrum of any bounded
operator can not be empty (if the Banach space is not {0}). (Recall the the
spectrum is the complement of the resolvent set.) Indeed, if the resolvent set
were the whole plane, then the circle of radius zero about the origin would be
homotopic to a circle of radius > ∥T∥via a homotopy lying entirely in the
resolvent set. Integrating Rz around the circle of radius zero gives 0. We can
integrate around a large circle using the above power series.
In performing
this integration, all terms vanish except the ﬁrst which give 2πiI by the usual
Cauchy integral (or by direct computation). Thus 2πI = 0 which is impossible
in a non-zero vector space.
Here is another very important (and easy) consequence of the preceding
theorem:
Theorem 10.10.2 Let C be a simple closed rectiﬁable curve lying entirely in
the resolvent set of T. Then
P :=
1
2πi
Z
C
Rzdz
(10.17)
is a projection which commutes with T, i.e.
P 2 = P
and PT = TP.
Proof.
Choose a simple closed curve C′ disjoint from C but suﬃciently close
to C so as to be homotopic to C via a homotopy lying in the resolvent set. Thus
P =
1
2πi
Z
C′ Rwdw

278
CHAPTER 10. THE SPECTRAL THEOREM.
and so
(2πi)2P 2 =
Z
C
Rzdz
Z
C′ Rwdw =
Z
C
Z
C′(Rw −Rz)(z −w)−1dwdz
where we have used the resolvent equation (10.7). We write this last expression
as a sum of two terms,
Z
C′ Rw
Z
C
1
z −wdzdw −
Z
C
Rz
Z
C′
1
z −wdwdz.
Suppose that we choose C′ to lie entirely inside C. Then the ﬁrst expression
above is just (2πi)
R
C′ Rwdw while the second expression vanishes, all by the
elementary Cauchy integral of 1/(z −w). Thus we get
(2πi)2P 2 = (2πi)2P
or P 2 = P. This proves that P is a projection. It commutes with T because it
is an integral whose integrand Rz commutes with T for all z. QED
The same argument proves
Theorem 10.10.3 Let C and C′ be simple closed curves each lying in the re-
solvent set, and let P and P ′ be the corresponding projections given by (10.17).
Then PP ′ = 0 if the curves lie exterior to one another while PP ′ = P ′ if C′ is
interior to C.
Let us write
B′ := PB,
B′′ = (I −P)B
for the images of the projections P and I −P where P is given by (10.17). Each
of these spaces is invariant under T and hence under Rz because PT = TP and
hence PRz = RzP.
For any transformation S commuting with P let us write
S′ := PS = SP = PSP
and S′′ = (I −P)S = S(I −P) = (I −P)S(I −P)
so that S′ and S′ are the restrictions of S to B′ and B′′ respectively.
For example, we may consider R′
z = PRz = RzP. For x′ ∈B′ we have
R′
z(zI −T ′)x′ = RzP(zI −TP)x′ = Rz(zI −T)Px′ = x′. In other words R′
z is
the resolvent of T ′ (on B′) and similarly for R′′
z. So if z is in the resolvent set
for T it is in the resolvent set for T ′ and T ′′.
Conversely, suppose that z is in the resolvent set for both T ′ and T ′′. Then
there exists an inverse A1 for zI′ −T ′ on B′ and an inverse A2 for zI′′ −T ′′ on
B′′ and so A1 ⊕A2 is the inverse of zI −T on B = B′ ⊕B′′.
So a point belongs to the resolvent set of T if and only if it belongs to the
resolvent set of T ′ and of T ′′. Since the spectrum is the complement of the
resolvent set, we can say that a point belongs to the spectrum of T if and only
if it belongs either to the spectrum of T ′ or of T ′′:
Spec(T) = Spec(T ′) ∪Spec(T ′′).

10.11. LORCH’S PROOF OF THE SPECTRAL THEOREM.
279
We now show that this decomposition is in fact the decomposition of Spec(T)
into those points which lie inside C and outside C.
So we must show that if z lies exterior to C then it lies in the resolvent set
of T ′. This will certainly be true if we can ﬁnd a transformation A on B which
commutes with T and such that
A(zI −T) = P
(10.18)
for then A′ will be the resolvent at z of T ′. Now
(zI −T)Rw = (wI −T)Rw + (z −w)Rw = I + (z −w)Rw
so
(zI −T) ·
1
2πi
Z
C
Rw ·
1
z −wdw =
=
1
2πi
Z
C
1
z −wdw · I +
1
2πi
Z
C
Rwdw = 0 + P = P.
We have thus proved
Theorem 10.10.4 Let T be a bounded linear transformation on a Banach space
and C a simple closed curve lying in its resolvent set. Let P be the projection
given by (10.17) and
B = B′ ⊕B′′,
T = T ′ ⊕T ′′
the corresponding decomposition of B and of T. Then Spec(T ′) consists of those
points of Spec(T) which lie inside C and Spec(T ′′) consists of those points of
Spec(T) which lie exterior to C.
We now begin to have a better understanding of Stone’s formula: Suppose A
is a self-adjoint operator. We know that its spectrum lies on the real axis. If
we draw a rectangle whose upper and lower sides are parallel to the axis, and
if its vertical sides do not intersect Spec(A), we would get a projection onto a
subspace M of our Hilbert space which is invariant under A, and such that the
spectrum of A when restricted to M lies in the interval cut out on the real axis
by our rectangle. The problem is how to make sense of this procedure when the
vertical edges of the rectangle might cut through the spectrum, in which case
the integral (10.17) might not even be deﬁned. This is resolved by the method
of Lorch (the exposition is taken from his book) which we explain in the next
section.
10.11
Lorch’s proof of the spectral theorem.
10.11.1
Positive operators.
Recall that if A is a bounded self-adjoint operator on a Hilbert space H then we
write A ≥0 if (Ax, x) ≥0 for all x ∈H and (by a slight abuse of language) call

280
CHAPTER 10. THE SPECTRAL THEOREM.
such an operator positive. Clearly the sum of two positive operators is positive
as is the multiple of a positive operator by a non-negative number. Also we
write A1 ≥A2 for two self adjoint operators if A1 −A2 is positive.
Proposition 10.11.1 If A is a bounded self-adjoint operator and A ≥I then
A−1 exists and
∥A−1∥≤1.
Proof.
We have
∥Ax∥∥x∥≥(Ax, x) ≥(x, x) = ∥x∥2
so
∥Ax∥≥∥x∥
∀x ∈H.
So A is injective, and hence A−1 is deﬁned on im A and is bounded by 1 there.
We must show that this image is all of H.
If y is orthogonal to im A we have
(x, Ay) = (Ax, y) = 0 ∀x ∈H
so Ay = 0 so (y, y) ≤(Ay, y) = 0 and hence y = 0. Thus im A is dense in H.
Suppose that Axn →z. Then the xn form a Cauchy sequence by the estimate
above on ∥A−1∥and so xn →x and the continuity of A implies that Ax = z.
QED
Suppose that A ≥0. Then for any λ > 0 we have A + λI ≥λI, and by the
proposition (A + λI)−1 exists, i.e. −λ belongs to the resolvent set of A. So we
have proved.
Proposition 10.11.2 If A ≥0 then Spec(A) ⊂[0, ∞).
Theorem 10.11.1 If A is a self-adjoint transformation then
∥A∥≤1
⇔
−I ≤A ≤I.
(10.19)
Proof.
Suppose ∥A∥≤1. Then using Cauchy-Schwarz and then the deﬁnition
of ∥A∥we get
([I −A]x, x) = (x, x) −(Ax, x) ≥∥x∥2 −∥Ax∥∥x∥≥∥x∥2 −∥A∥∥x∥2 ≥0
so (I −A) ≥0 and applied to −A gives I + A ≥0 or −I ≤A ≤I.
Conversely, suppose that −I ≤A ≤I.
Since I −A ≥0 we know that
Spec(A) ⊂(−∞, 1] and since I + A ≥0 we have Spec(A) ⊂(−1, ∞]. So
Spec(A) ⊂[−1, 1]
so that the spectral radius of A is ≤1. But for self adjoint operators we have
∥A2∥= ∥A∥2 and hence the formula for the spectral radius gives ∥A∥≤1. QED

10.11. LORCH’S PROOF OF THE SPECTRAL THEOREM.
281
An immediate corollary of the theorem is the following: Suppose that µ is a
real number. Then ∥A −µI∥≤ϵ is equivalent to (µ −ϵ)I ≤A ≤(µ + ϵ)I. So
one way of interpreting the spectral theorem
A =
Z ∞
−∞
λdEλ
is to say that for any doubly inﬁnite sequence
· · · < λ−2 < λ−1 < λ0 < λ1 < λ2 < · · ·
with λ−n →−∞and λn →∞there is a corresponding Hilbert space direct
sum decomposition
H =
M
Hi
invariant under A and such that the restriction of A to Hi satisﬁes
λiI ≤A|Hi ≤λi+1I.
If µi := 1
2(λi + λi+1) then another way of writing the preceding inequality is
∥A|Hi −µiI∥≤1
2(λi+1 −λi).
10.11.2
The point spectrum.
We now let A denote an arbitrary (not necessarily bounded) self adjoint trans-
formation. We say that λ belongs to the point spectrum of A if there exists
an x ∈D(A) such that x ̸= 0 and Ax = λx. In other words if λ is an eigen-
value of A. Notice that eigenvectors corresponding to distinct eigenvalues are
orthogonal: if Ax = λx and Ay = µy then
λ(x, y) = (λx, y) = (Ax, y) = (x, Ay) = (x, µy) = µ(x, y)
implying that (x, y) = 0 if λ ̸= µ.
Also, the fact that a self-adjoint operator is closed implies that the space of
eigenvectors corresponding to a ﬁxed eigenvalue is a closed subspace of H. We
let Nλ denote the space of eigenvectors corresponding to an eigenvalue λ.
We say that A has pure point spectrum if its eigenvectors span H, in
other words if
H =
M
Nλi
where the λi range over the set of eigenvalues of A. Suppose that this is the
case. Then let
Mλ :=
M
µ<λ
Nµ
where this denotes the Hilbert space direct sum, i.e. the closure of the algebraic
direct sum. Let Eλ denote projection onto Mλ. Then it is immediate that the
Eλ satisfy (10.10)-(10.15) and that (10.16) holds with the interpretation given
in the preceding section.
We thus have a proof of the spectral theorem for
operators with pure point spectrum.

282
CHAPTER 10. THE SPECTRAL THEOREM.
10.11.3
Partition into pure types.
Now consider a general self-adjoint operator A, and let
H1 :=
M
Nλ
(Hilbert space direct sum) and set
H2 := H⊥
1 .
The space H1 and hence the space H2 are invariant under A in the sense that
A maps D(A) ∩H1 to H1 and similarly for H2.
We let P denote orthogonal projection onto H1 so I −P is orthogonal pro-
jection onto H2. We claim that
P[D(A)] = D(A) ∩H1
and
(I −P)[D(A)] = D(A) ∩H2.
(10.20)
Suppose that x ∈D(A). We must show that Px ∈D(A) for then x = Px +
(I −P)x is a decomposition of every element of D(A) into a sum of elements of
D(A) ∩H1 and D(A) ∩H2.
By deﬁnition, we can ﬁnd an orthonormal basis of H1 consisting of eigen-
vectors ui of A, and then
Px =
X
aiui
ai := (x, ui).
The sum on the right is (in general) inﬁnite. Let y denote any ﬁnite partial
sum. Since eigenvectors belong to D(A) we know that y ∈D(A). We have
(A[x −y], Ay) −([x −y], A2y) = 0
since x −y is orthogonal to all the eigenvectors occurring in the expression for
y. We thus have
∥Ax∥2 = ∥A(x −y)∥2 + ∥Ay∥2
From this we see (as we let the number of terms in y increase) that both y
converges to Px and the Ay converge. Hence Px ∈D(A) proving (10.20).
Let A1 denote the operator A restricted to P[D(A)] = D(A) ∩H1 with
similar notation for A2. We claim that A1 is self adjoint (as is A2). Clearly
D(A1) := P(D(A)) is dense in H1, for if there were a vector y ∈H1 orthogonal
to D(A1) it would be orthogonal to D(A) in H which is impossible. Similarly
D(A2) := D(A) ∩H2 is dense in H2.
Now suppose that y1 and z1 are elements of H1 such that
(A1x1, y1) = (x1, z1) ∀x1 ∈D(A1).
Since A1x1 = Ax1 and x1 = x −x2 for some x ∈D(A), and since y1 and z1 are
orthogonal to x2, we can write the above equation as
(Ax, y1) = (x, z1)
∀x ∈D(A)
which implies that y1 ∈D(A) ∩H1 = D(A1) and A1y1 = Ay1 = z1.
In other words, A1 is self-adjoint. Similarly, so is A2. We have thus proved

10.11. LORCH’S PROOF OF THE SPECTRAL THEOREM.
283
Theorem 10.11.2 Let A be a self-adjoint transformation on a Hilbert space
H. Then
H = H1 ⊕H2
with self-adjoint transformations A1 on H1 having pure point spectrum and A2
on H2 having no point spectrum such that
D(A) = D(A1) ⊕D(A2)
and
A = A1 ⊕A2.
We have proved the spectral theorem for a self adjoint operator with pure point
spectrum. Our proof of the full spectral theorem will be complete once we prove
it for operators with no point spectrum.
10.11.4
Completion of the proof.
In this subsection we will assume that A is a self-adjoint operator with no point
spectrum, i.e. no eigenvalues.
Let λ < µ be real numbers and let C be a closed piecewise smooth curve in
the complex plane which is symmetrical about the real axis and cuts the real
axis at non-zero angle at the two points λ and µ (only). Let m > 0 and n > 0
be positive integers, and let
Kλµ(m, n) :=
1
2πi
Z
C
(z −λ)m(z −µ)nRzdz.
(10.21)
In fact, we would like to be able to consider the above integral when m = n = 0,
in which case it should give us a projection onto a subspace where λI ≤A ≤µI.
But unfortunately if λ or µ belong to Spec(A) the above integral need not
converge with m = n = 0.
However we do know that ∥Rz∥≤(|im z|)−1
so that the blow up in the integrand at λ and µ is killed by (z −λ)m and
(µ −z)n since the curve makes non-zero angle with the real axis. Since the
curve is symmetric about the real axis, the (bounded) operator Kλµ(m, n) is
self-adjoint. Furthermore, modifying the curve C to a curve C′ lying inside C,
again intersecting the real axis only at the points λ and µ and having these
intersections at non-zero angles does not change the value: Kλµ(m, n).
We will now prove a succession of facts about Kλµ(m, n):
Kλµ(m, n) · Kλµ(m′, n′) = Kλµ(m + m′, n + n′).
(10.22)
Proof.
Calculate the product using a curve C′ for Kλµ(m′, n′) as indicated
above.
Then use the functional equation for the resolvent and Cauchy’s in-
tegral formula exactly as in the proof of Theorem 10.10.2: (2πi)2Kλµ(m, n) ·
Kλµ(m′, n′) =
Z
C
Z
C′(z −λ)m(µ −z)n(w −λ)m′(µ −w)n′
1
z −w[Rw −Rz]dzdw

284
CHAPTER 10. THE SPECTRAL THEOREM.
which we write as a sum of two integrals, the ﬁrst giving (2πi)2Kλµ(m+m′, n+
n′) and the second giving zero. QED
A similar argument (similar to the proof of Theorem 10.10.3) shows that
Kλµ(m, n) · Kλ′µ′(m′, n′) = 0 if (λ, µ) ∩(λ′, µ′) = ∅.
(10.23)
Proposition 10.11.3 There exists a bounded self-adjoint operator Lλµ(m, n)
such that
Lλµ(m, n)2 = Kλµ(m, n).
Proof.
The function z 7→(z −λ)m/2(µ −z)n/2 is deﬁned and holomorphic on
the complex plane with the closed intervals (−∞, λ] and [µ, ∞) removed. The
integral
Lλµ(m, n) =
1
2πi
Z
C
(z −λ)m/2(µ −z)n/2Rzdz
is well deﬁned since, if m = 1 or n = 1 the singularity is of the form |im z|−1
2
at worst which is integrable. Then the proof of (10.22) applies to prove the
proposition. QED
For each complex z we know that Rzx ∈D(A). Hence
(A −λI)Rzx = (A −zI)Rzx + (z −λ)Rzx = x + (z −λ)Rzx.
By writing the integral deﬁning Kλµ(m, n) as a limit of approximating sums,
we see that (A −λI)Kλµ(m, n) is deﬁned and that it is given by the sum of two
integrals, the ﬁrst of which vanishes and the second gives Kλµ(m + 1, n).
We have thus shown that Kλµ(m, n) maps H into D(A) and
(A −λI)Kλµ(m, n) = Kλµ(m + 1, n).
(10.24)
Similarly
(µI −A)Kλµ(m, n) = Kλµ(m, n + 1).
(10.25)
We also have
λ(x, x) ≤(Ax, x) ≤µ(x, x) for x ∈im Kλµ(m, n).
(10.26)
Proof.
We have
([A −λI]Kλµ(m, n)y, Kλµ(m, n)y)
=
(Kλµ(m + 1, n)y, Kλµ(m, n)y)
=
(Kλµ(m, n)Kλµ(m + 1, n)y, y)
=
(Kλµ(2m + 1, 2n)y, y)
=
(Lλµ(2m + 1, 2n)2y, y)
=
(Lλµ(2m + 1, 2n)y, Lλµ(2m + 1, 2n)y) ≥0.
⇒
A ≥λI on im Kλµ(m, n).

10.11. LORCH’S PROOF OF THE SPECTRAL THEOREM.
285
A similar argument shows that A ≤µI there. QED
Thus if we deﬁne Mλµ(m, n) to be the closure of im Kλµ(m, n) we see that
A is bounded when restricted to Mλµ(m, n) and
λI ≤A ≤µI
there.
We let Nλµ(m, n) denote the kernel of Kλµ(m, n) so that Mλµ(m, n) and
Nλµ(m, n) are the orthogonal complements of one another.
So far we have not made use of the assumption that A has no point spectrum.
Here is where we will use this assumption: Since
(A −λI)Kλµ(m, n) = Kλµ(m + 1, n)
we see that if Kλµ(m+1, n)x = 0 we must have (A−λI)Kλµ(m, n)x = 0 which,
by our assumption implies that Kλµ(m, n)x = 0. In other words,
Proposition 10.11.4
The space Nλµ(m, n),
and hence its orthogonal com-
plement Mλµ(m, n) is independent of m and n.
We will denote the common space Mλµ(m, n) by Mλµ. We have proved that A
is a bounded operator when restricted to Mλµ and satisﬁes
λI ≤A ≤µI on Mλµ
there.
We now claim that
If λ < ν < µ then
Mλµ = Mλν ⊕Mνµ.
(10.27)
Proof.
Let Cλµ denote the rectangle of height one parallel to the real axis
and cutting the real axis at the points λ and µ. Use similar notation to deﬁne
the rectangles Cλν and Cνµ. Consider the integrand
Sz := (z −λ)(z −µ)(z −ν)Rz
and let
Tλµ :=
1
2πi
Z
Cλµ
Szdz
with similar notation for the integrals over the other two rectangles of the same
integrand. Then clearly
Tλµ = Tλν + Tνµ
and Tλν · Tνµ = 0.
(10.28)
Also, writing zI −A = (z −ν)I + (νI −A) we see that
(νI −A)Kλν(1, 1) = Tλµ
Since A has no point spectrum, the closure of the image of Tλµ is the same as
the closure of the image of Kλµ(1, 1), namely Mλµ. The proposition now follows
from (10.28).

286
CHAPTER 10. THE SPECTRAL THEOREM.
If we now have a doubly inﬁnite sequence as in our reformulation of the
spectral theorem, and we set Mi := Mλiλi+1 we have proved the spectral theorem
(in the no point spectrum case - and hence in the general case) if we show that
M
Mi = H.
In view of (10.27) it is enough to prove that the closure of the limit of M−rr is
all of H as r →∞, or, what amounts to the same thing, if y is perpendicular
to all K−rr(1, 1)x then y must be zero. Now
(K−rr(1, 1)x, y) = (x, K−rr(1, 1)y)
so we must show that if K−rry = 0 for all r then y = 0. Now
K−rr =
1
2πi
Z
C
(z + r)(r −z)Rzdz = −1
2πi
Z
(z2 −r2)Rz
where we may take C to be the circle of radius r centered at the origin. We also
have
1 =
1
2πir2
Z
C
r2 −z2
z
dz.
So
y =
1
2πir2
Z
C
(r2 −z2)[z−1I −Rz]dz · y.
Now (zI −A)Rz = I so −ARz = I −zRz or
z−1I −Rz = −z−1ARz
so (pulling the A out from under the integral sign) we can write the above
equation as
y = Agr
where gr =
1
2πir2
Z
C
(r2 −z2)z−1Rzdz · y.
Now on C we have z = reiθ so z2 = r2e2iθ = r2(cos 2θ + i sin 2θ) and hence
z2 −r2 = r2(cos 2θ −1 + i sin 2θ) = 2r2(−sin2 θ + i sin θ cos θ).
Now ∥Rz∥≤|r sin θ|−1 so we see that
∥(z2 −r2)Rz∥≤4r.
Since |z−1| = r−1 on C, we can bound ∥gr∥by
∥gr| ≤(2πr2)−1 · r−1 · 4r · 2πr∥y∥= 4r−1∥y∥→0
as r →∞. Since y = Agr and A is closed (being self-adjoint) we conclude that
y = 0. This concludes Lorch’s proof of the spectral theorem.

10.12. CHARACTERIZING OPERATORS WITH PURELY CONTINUOUS SPECTRUM.287
10.12
Characterizing operators with purely con-
tinuous spectrum.
Suppose that A is a self-adjoint operator with only continuous spectrum. Let
Eµ := P((−∞, µ))
be its spectral resolution. For any ψ ∈H the function
µ 7→(Eµψ, ψ)
is continuous. It is also a monotone increasing function of µ. For any ϵ > 0 we
can ﬁnd a suﬃciently negative a such that |(Eaψ, ψ)| < ϵ/2 and a suﬃciently
large b such that ∥ψ∥2 −(Enψ, ψ) < ϵ/2. On the compact interval [a, b] any con-
tinuous function is uniformly continuous. Therefore the function µ 7→(Eµψ, ψ)
is uniformly continuous on R.
Now let φ and ψ be elements of H and consider the product measure
d(Eλφ, φ)d(Eµψ, ψ)
on the plane R2, the λ, µ plane.
Lemma 10.12.1 The diagonal line λ = µ has measure zero relative to the
above product measure.
Proof.
We may assume that φ ̸= 0. For any ϵ > 0 we can ﬁnd a δ > 0 such
that
(Eµ+δψ, ψ) −Eµ−δψ, ψ) <
ϵ
∥φ∥2
for all µ ∈R. So
Z
R
d(Eλφ, φ)
Z λ+δ
λ−δ
d(Eµψ, ψ) < ϵ.
This says that the measure of the band of width δ about the diagonal has
measure less that ϵ.
Letting δ shrink to 0 shows that the diagonal line has
measure zero.
□
We can restate this lemma more abstractly as follows: Consider the Hilbert
space Hˆ⊗H (the completion of the tensor product H ⊗H). The Eλ and Eµ
determine a projection valued measure Q on the plane with values in Hˆ⊗H.
The spectral measure associated with the operator A ⊗I −I ⊗A is then Fρ :=
Q({(λ, µ)| λ −µ < ρ}). So an abstract way of formulating the lemma is
Proposition 10.12.1 A has only continuous spectrum if and only if 0 is not
an eigenvalue of A ⊗I −I ⊗A on Hˆ⊗H,

288
CHAPTER 10. THE SPECTRAL THEOREM.
10.13
Appendix. The closed graph theorem.
Lurking in the background of our entire discussion is the closed graph theorem
which says that if a closed linear transformation from one Banach space to
another is everywhere deﬁned, it is in fact bounded. We did not actually use
this theorem, but its statement and proof by Banach greatly clariﬁed the notion
of a what an unbounded self-adjoint operator is, and explained the Hellinger
Toeplitz theorem as I mentioned earlier. So here I will give the standard proof
of this theorem (essentially a Baire category style argument) taken from Loomis.
In what follows X and Y will denote Banach spaces,
Bn := Bn(X) = {x ∈X; ∥x∥≤n}
denotes the ball of radius n about the origin in X and
Ur = Br(Y ) = {y ∈Y : ∥y∥≤r}
the ball of radius r about the origin in Y .
Lemma 10.13.1 Let
T : X →Y
be a bounded (everywhere deﬁned) linear transformation. If T[B1] ∩Ur is dense
in Ur then
Ur ⊂T[B1].
Proof. The set T[B1] is closed, so it will be enough to show that
Ur(1−δ) ⊂T[B1]
for any δ > 0, or, what is the same thing, that
Ur ⊂
1
1 −δ T[B1] = T[B
1
1−δ ].
So ﬁx δ > 0.
Let z ∈Ur.
Set y0 := 0, and choose y1 ∈T[B1] ∩Ur such
that ∥z −y1∥< δr. Since δ (T[B1] ∩Ur) is dense in δUr we can ﬁnd y2 −y1 ∈
δ (T[B1] ∩Ur) within distance δ2r of z −y1 which implies that ∥y2 −z∥< δ2r.
Proceeding inductively we ﬁnd a sequence {yn ∈Y such that
yn+1 −yn ∈δn (T[B1] ∩Ur)
and
∥yn+1 −z∥, δn+1r.
We can thus ﬁnd xn ∈X such that
T(xn+1 = yn+1 −yn
and
∥xn+1∥< δn.
If
x :=
∞
X
1
xn
then ∥x∥< 1/(1 −δ) and Tx = z. QED

10.13. APPENDIX. THE CLOSED GRAPH THEOREM.
289
Lemma 10.13.2 If T[B1] is dense in no ball of positive radius in Y , then T[X]
contains no ball of positive radius in Y .
Proof. Under the hypotheses of the lemma, T[Bn] is also dense in no ball of
positive radius of Y . So given any ball U ⊂Y , we can ﬁnd a (closed) ball
Ur1,y1 of radius r1 about y1 such that Ur1,y1 ⊂U and is disjoint from T[B1].
By induction, we can ﬁnd a nested sequence of balls Urn,yn ⊂Urn−1yn−1 such
that Urn,yn is disjoint form T[Bn] and can also arrange that rn →0. Choosing
a point in each of these balls we get a Cauchy sequence which converges to a
point y ∈U which lies in none of the T[Bn], i.e. y ̸ inT[X]. So u ̸⊂T[X]. QED
Theorem 10.13.1 [The bounded inverse theorem.]
If T : X →Y is
bounded and bijective, then T −1 is bounded.
Proof. By Lemma 10.13.2, T[B1] is dense in some ball Ur,y1 and hence
T[B1 + B1] = T[B1 −B1]
is dense in a ball of radius r about the origin. Since B1 +B1 ⊂B2 so T[B2]∩Ur
is dense in Ur. By Lemma 10.13.1, this implies that
T[B2] ⊃Ur
i.e. that
T −1[Ur] ⊂B2
which says that
∥T −1∥≤2
r .
QED
Theorem 10.13.2 If T : X →Y is deﬁned on all of X and is such that
graph(T) is a closed subspace of X ⊕Y , then T is bounded.
Proof. Let Γ ⊂X ⊕Y denote the graph of T. By assumption, it is a closed
subspace of the Banach space X ⊕Y under the norm ∥{x, y}∥= ∥x∥+ ∥y∥. So
Γ is a Banach space and the projection
Γ →X,
{x, y} 7→x
is bijective by the deﬁnition of a graph, and has norm ≤1. So its inverse is
bounded. Similarly the projection onto the second factor is bounded. So the
composite map
X →Y
x 7→{x, y} 7→y = Tx
is bounded. QED

290
CHAPTER 10. THE SPECTRAL THEOREM.

Chapter 11
Stone’s theorem
Recall that if A is a self-adjoint operator on a Hilbert space H we can form the
one parameter group of unitary operators
U(t) = eiAt
by virtue of a functional calculus which allows us to construct f(A) for any
bounded Borel function deﬁned on R (if we use our ﬁrst proof of the spectral
theorem using the Gelfand representation theorem) or for any function holomor-
phic on Spec(A) if we use our second proof. In any event, the spectral theorem
allows us to write
U(t) =
Z ∞
−∞
eitλdEλ
and to verify that
U(0) = I,
U(s + t) = U(s)U(t)
and that U depends continuously on t. We called this assertion the ﬁrst half of
Stone’s theorem. The second half (to be stated more precisely below) asserts
the converse: that any one parameter group of unitary transformations can be
written in either, hence both, of the above forms.
The idea that we will follow hinges on the following elementary computation
Z ∞
0
e(−z+ix)tdt = e(−z+ix)t
−z + ix

∞
t=0
=
1
z −ix if Re z > 0
valid for any real number x. If we substitute A for x and write U(t) instead of
eiAt this suggests that
R(z, iA) = (zI −iA)−1 =
Z ∞
0
e−ztU(t)dt if Re z > 0.
Since A is self-adjoint, its spectrum is real. So the spectrum of iA is purely
imaginary, and hence any z not on the imaginary axis is in the resolvent set of
iA. The above formula gives us an expression for the resolvent in terms of U(t)
291

292
CHAPTER 11. STONE’S THEOREM
for z lying in the right half plane. We can obtain a similar formula for the left
half plane.
Our previous studies encourage us to believe that once we have found all
these putative resolvents, it should not be so hard to reconstruct A and then
the one-parameter group U(t) = eiAt.
This program works! But because of some of the subtleties involved in the
deﬁnition of a self-adjoint operator, we will begin with an important theorem
of von-Neumann which we will need, and which will also greatly clarify exactly
what it means to be self-adjoint.
A second matter which will lengthen these proceedings is that while we are at
it, we will prove a more general version of Stone’s theorem valid in an arbitrary
Frechet space F and for “uniformly bounded semigroups” rather than unitary
groups. Stone proved his theorem to meet the needs of quantum mechanics,
where a unitary one parameter group corresponds, via Wigner’s theorem to
a one parameter group of symmetries of the logic of quantum mechanics. In
more pedestrian terms, unitary one parameter groups arise from solutions of
Schrodinger’s equation. But many other important equations, for example the
heat equations in various settings, require the more general result.
The treatment here will essentially follow that of Yosida, Functional Analysis
especially Chapter IX, Nelson, Topics in dynamics I: Flows, and Reed and
Simon Methods of Mathematical Physics, II. Fourier Analysis, Self-Adjointness.
11.1
von Neumann’s Cayley transform.
The group Gl(2, C) of all invertible complex two by two matrices acts as “frac-
tional linear transformations” on the plane: the matrix
a
b
c
d

sends
z 7→az + b
cz + d.
Two diﬀerent matrices M1 and M2 give the same fractional linear transformation
if and only if M1 = λM2 for some (non-zero complex) number λ as is clear from
the deﬁnition. Since
1
−i
1
i
  i
i
−1
1

= 2i
1
0
0
1

,
the fractional linear transformations corresponding to
1
−i
1
i

and
 i
i
−1
1

are inverse to one another.
It is a theorem in the elementary theory of complex variables that fractional
linear transformations are the only orientation preserving transformations of
the plane which carry circles and lines into circles and lines.
Even without
this general theory, an immediate computation shows that
1
−i
1
i

carries the
(extended) real axis onto the unit circle, and hence its inverse carries the unit

11.1. VON NEUMANN’S CAYLEY TRANSFORM.
293
circle onto the extended real axis. (“Extended” means with the point ∞added.)
Indeed in the expression
z = x −i
x + i
when x is real, the numerator is the complex conjugate of the denominator and
hence |z| = 1. Under this transformation, the cardinal points 0, 1, ∞of the
extended real axis are mapped as follows:
0 7→−1,
1 7→−i,
and
∞7→1.
We might think of (multiplication by) a real number as a self-adjoint trans-
formation on a one dimensional Hilbert space, and (multiplication by) a number
of absolute value one as a unitary operator on a one dimensional Hilbert space.
This suggests in general that if A is a self adjoint operator, then
(A −iI)(A + iI)−1
should be unitary. In fact, we can be much more precise. First some deﬁnitions:
An operator U, possibly deﬁned only on a subspace of a Hilbert space H is
called isometric if
∥Ux∥= ∥x∥
for all x in its domain of deﬁnition.
Recall that in order to deﬁne the adjoint T ∗of an operator T it is necessary
that its domain D(T) be dense in H. Otherwise the equation
(Tx, y) = (x, T ∗y) ∀x ∈D(T)
does not determine T ∗y. A transformation T (in a Hilbert space H) is called
symmetric if D(T) is dense in H so that T ∗is deﬁned and
D(T) ⊂D(T ∗) and Tx = T ∗x
∀x ∈D(T).
Another way of saying the same thing is T is symmetric if D(T) is dense
and
(Tx, y) = (x, Ty)
∀x, y ∈D(T).
A self-adjoint transformation is symmetric since D(T) = D(T ∗) is one of the
requirements of being self-adjoint. Exactly how and why a symmetric operator
can fail to be self-adjoint will be clariﬁed in the ensuing discussion. All of the
results of this section are due to von Neumann.
Theorem 11.1.1 Let T be a closed symmetric operator. Then (T + iI)x = 0
implies that x = 0 for any x ∈D(T) so (T + iI)−1 exists as an operator on its
domain
D

(T + iI)−1
= im(T + iI).
This operator is bounded on its domain and the operator
UT := (T −iI)(T + iI)−1
with D(UT ) = D

(T + iI)−1
= im(T + iI)

294
CHAPTER 11. STONE’S THEOREM
is isometric and closed. The operator (I −UT )−1 exists and
T = i(UT + I)(UT −I)−1.
In particular, D(T) = im(I −UT ) is dense in H.
Conversely, if U is a closed isometric operator such that im(I −U) is dense
in H then T = i(U + I)(I −U)−1 is a symmetric operator with U = UT .
Proof.
For any x ∈D(T) we have
([T ± iI]x, [T ± iI]x) = (Tx, Tx) ± (Tx, ix) ± (ix, Tx) + (x, x).
The middle terms cancel because T is symmetric. Hence
∥[T ± iI]x∥2 = ∥Tx∥2 + ∥x∥2.
(11.1)
Taking the plus sign shows that (T + iI)x = 0 ⇒x = 0 and also shows that
∥[T + iI]x∥≥∥x∥so
∥[T + iI]−1y∥≤∥y∥for y ∈[T + iI](D(T)).
If we write x = [T + iI]−1y then (11.1) shows that
∥UT y∥2 = ∥Tx∥2 + ∥x∥2 = ∥y∥2
so UT is an isometry with domain consisting of all y = (T + iI)x, i.e. with
domain D([T + iI]−1) = im[T + iI].
We now show that UT is closed.
So we must show that if yn →y and
zn →z where zn = UT yn then y ∈D(UT ) and UT y = z. The yn form a Cauchy
sequence and yn = [T + iI]xn since yn ∈im(T + iI). From (11.1) we see that
the xn and the Txn form a Cauchy sequence, so xn →x and Txn →w which
implies that x ∈D(T) and Tx = w since T is assumed to be closed. But then
(T +iI)x = w +ix = y so y ∈D(UT ) and w −ix = z = UT y. So we have shown
that UT is closed.
Subtract and add the equations
y
=
(T + iI)x
UT y
=
(T −iI)x to get
1
2(I −UT )y
=
ix
and
1
2(I + UT )y
=
Tx.
The third equation shows that
(I −UT )y = 0 ⇒x = 0 ⇒Tx = 0 ⇒(I + UT )y = 0
by the fourth equation. So
y = 1
2([I −UT ]y + [I + UT ]y) = 0.

11.1. VON NEUMANN’S CAYLEY TRANSFORM.
295
Thus (I −UT )−1 exists, and y = (I −UT )−1(2ix) from the third of the four
equations above, and the last equation gives
Tx = 1
2(I + UT )y = 1
2(I + UT )(I −UT )−12ix
or
T = i(I + UT )(I −UT )−1
as required. Furthermore, every x ∈D(T) is in im(I −UT ). This completes the
proof of the ﬁrst half of the theorem.
Now suppose we start with an isometry U and suppose that (I −U)y = 0
for some y ∈D(U). Let z ∈im(I −U) so z = w −Uw for some w. We have
(y, z) = (y, w) −(y, Uw) = (Uy, Uw) −(y, Uw) = (Uy −y, Uw) = 0.
Since we are assuming that im(I −U) is dense in H, the condition (y, z) =
0 ∀z ∈im(I −U) implies that y = 0. Thus (I −U)−1 exists, and we may deﬁne
T = i(I + U)(I −U)−1
with
D(T) = D
 (I −U)−1
= im(I −U)
dense in H. Suppose that x = (I −U)u, y = (I −U)v ∈D(T) = im(I −U).
Then
(Tx, y) = (i(I + U)u, (I −U)v) = i [(Uu, v) −(u, Uv)] + i [(u, v) −(Uu, Uv)] .
The second expression in brackets vanishes since U is an isometry. So (Tx, y) =
i(Uu, v) −i(u, Uv) = (−Uu, iv) + (u, iUv) = ([I −U]u, i[I + U]v) = (x, Ty).
This shows that T is symmetric.
To see that UT = U we again write x = (I −U)u. We have
Tx = i(I + U)u so (T + iI)x = 2iu and (T −iI)x = 2iUu.
Thus D(UT ) = {2iu u ∈D(U)} = D(U) and
UT (2iu) = 2iUu = U(2iu).
Thus U = UT .
We must still show that T is a closed operator. T maps xn = (I −U)un
to (I + U)un. If both (I −U)un and (I + U)un converge, then un and Uun
converge. The fact that U is closed implies that if u = lim un then u ∈D(U) and
Uu = lim Uun. But this that (I −U)un →(I −U)u and i(I +U)un →i(I +U)u
so T is closed. QED
The map T 7→UT from symmetric operators to isometries is called the
Cayley transform.

296
CHAPTER 11. STONE’S THEOREM
Recall that an isometry is unitary if its domain and image are all of H.
If U is a closed isometry, then xn ∈D(U) and xn →x implies that Uxn is
convergent, hence x ∈D(U) and Ux = lim Uxn. Similarly, if Uxn →y then
the xn are Cauchy, hence convergent to an x with Ux = y. So for any closed
isometry U the spaces D(U)⊥and im(U)⊥measure how far U is from being
unitary: If they both reduce to the zero subspace then U is unitary.
For a closed symmetric operator T deﬁne
H+
T = {x ∈H|T ∗x = ix} and H−
T = {x ∈H|T ∗x = −ix}.
(11.2)
The main theorem of this section is
Theorem 11.1.2 Let T be a closed symmetric operator and U = UT its Cayley
transform. Then
H+
T = D(U)⊥
and
H−
T = (im(U))⊥.
Every x ∈D(T ∗) is uniquely expressible as
x = x0 + x+ + x−
with x0 ∈D(T), x+ ∈H+
T and x−∈H−
T , so
T ∗x = Tx0 + ix+ −ix−.
In particular, T is self adjoint if and only if U is unitary.
Proof.
To say that x ∈D(U)⊥= D
 (T + iI)−1⊥says that
(x, (T + iI)y) = 0
∀y ∈D(T).
This says that
(x, Ty) = −(x, iy) = (ix, y)
∀y ∈D(T).
This is precisely the assertion that x ∈D(T ∗) and T ∗x = ix. We can read these
equations backwards to conclude that H+
T = D(U)⊥. Similarly, if x ∈im(U)⊥
then (x, (T −iI)z) = 0 ∀z ∈D(T) implying T ∗x = −ix and conversely.
We know that D(U) and im(U) are closed subspaces of H so any w ∈H can
be written as the sum of an element of D(U) and an element of D(U)⊥. Taking
w = (T ∗+ iI)x for some x ∈D(T ∗) gives
(T ∗+ iI)x = y0 + x1,
y0 ∈D(U) = im(T + iI), x1 ∈D(U)⊥.
We can write y0 = (T + iI)x0, x0 ∈D(T) so
(T ∗+ iI)x = (T + iI)x0 + x1.
Since T ∗= T on D(T) and T ∗x1 = ix1as x1 ∈D(U)⊥we have
T ∗x1 + ix1 = 2ix1.

11.1. VON NEUMANN’S CAYLEY TRANSFORM.
297
So if we set
x+ = 1
2ix1
we have
x1 = (T ∗+ iI)x+,
x+ ∈D(U)⊥.
so
(T ∗+ iI)x = (T ∗+ iI)(x0 + x+)
or
T ∗(x −x0 −x+) = −i(x −x0 −x+).
This implies that (x −x0 −x+) ∈H−
T = im(U)⊥. So if we set
x−:= x −x0 −x+
we get the desired decomposition x = x0 + x+ + x−.
To show that the decomposition is unique, suppose that
x0 + x+ + x−= 0.
Applying (T ∗+ iI) gives
0 = (T + iI)x0 + 2ix+.
But (T + iI)x0 ∈D(U) and x+ ∈D(U)⊥so both terms above must be zero,
so x+ = 0. Also, from the preceding theorem we know that (T + iI)x0 = 0 ⇒
x0 = 0. Hence since x0 = 0 and x+ = 0 we must also have x−= 0. QED
11.1.1
An elementary example.
Take H = L2([0, 1]) relative to the standard Lebesgue measure. Consider the
operator 1
i
d
dt which is deﬁned on all elements of H whose derivative, in the sense
of distributions, is again in L2([0, 1]). For any two such elements we have the
integration by parts formula
1
i
d
dtx, y

= x(1)y(1) −x(0)y(0) +

x, 1
i
d
dty

.
(Even though in general the value at a point of an element in L2 makes no sense,
if x is such that x′ ∈L2 then 1
h
R h
0 x(t)dt makes sense, and integration by parts
using a continuous representative for x shows that the limit of this expression
is well deﬁned and equal to x(0) for our continuous representative.) Suppose
we take T = 1
i
d
dt but with D(T) consisting of those elements whose derivatives
belong to L2 as above, but which in addition satisfy
x(0) = x(1) = 0.

298
CHAPTER 11. STONE’S THEOREM
This space is dense in H = L2 but if y is any function whose derivative is in H,
we see from the integration by parts formula that
(Tx, y) =

x, 1
i
d
dty

.
In other words, using the Riesz representation theorem, we see that
T ∗= 1
i
d
dt
deﬁned on all y with derivatives in L2. Notice that
T ∗e±t = ∓ie±t
so in fact the spaces H±
T are both one dimensional.
For each complex number eiθ of absolute value one we can ﬁnd a “self adjoint
extension” Aθ of T, that is an operator Aθ such that
D(T) ⊂D(Aθ) ⊂D(T ∗)
with D(Aθ) = D(A∗
θ), Aθ = A∗
θ and Aθ = T on D(T). Indeed, let D(Aθ) consist
of all x with derivatives in L2 and which satisfy the “boundary condition”
x(1) = eiθx(0).
Let us compute A∗
θ and its domain. Since D(T) ⊂D(Aθ), if (Aθx, y) = (x, A∗
θy)
we must have y ∈D(T ∗) and A∗
θy = 1
i
d
dty. But then the integration by parts
formula gives
(Ax, y) −(x, 1
i
d
dty) = eiθx(0)y(1) −x(0)y(0).
This will vanish for all x ∈D(Aθ) if and only if y ∈D(Aθ). So we see that Aθ
is self adjoint.
The moral is that to construct a self adjoint operator from a diﬀerential
operator which is symmetric, we may have to supplement it with appropriate
boundary conditions.
On the other hand, consider the same operator 1
i
d
dt considered as an un-
bounded operator on L2(R).
We take as its domain the set of all elements
of x ∈L2(R) whose distributional derivatives belong to L2(R) and such that
limt→±∞x = 0. The functions e±t do not belong to L2(R) and so our operator
is in fact self-adjoint. So the issue of whether or not we must add boundary
conditions depends on the nature of the domain where the diﬀerential operator
is to be deﬁned. A deep analysis of this phenomenon for second order ordinary
diﬀerential equations was provided by Hermann Weyl in a paper published in
1911. It is safe to say that much of the progress in the theory of self-adjoint
operators was in no small measure inﬂuenced by a desire to understand and
generalize the results of this fundamental paper.

11.2. EQUIBOUNDED SEMI-GROUPS ON A FRECHET SPACE.
299
11.2
Equibounded semi-groups on a Frechet space.
A Frechet space F is a vector space with a topology deﬁned by a sequence
of semi-norms and which is complete. An important example is the Schwartz
space S. Let F be such a space. We want to consider a one parameter family of
operators Tt on F deﬁned for all t ≥0 and which satisfy the following conditions:
• T0 = I
• Tt ◦Ts = Tt+s
• limt→t0 Ttx = Tt0x ∀t0 ≥0 and x ∈F.
• For any deﬁning seminorm p there is a deﬁning seminorm q and a constant
K such that p(Ttx) ≤Kq(x) for all t ≥0 and all x ∈F.
We call such a family an equibounded continuous semigroup.
We will
usually drop the adjective “continuous” and even “equibounded” since we will
not be considering any other kind of semigroup.
11.2.1
The inﬁnitesimal generator.
We are going to begin by showing that every such semigroup has an “ inﬁnites-
imal generator”, i.e. can be written in some sense as Tt = eAt. It is important
to observe that we have made a serious change of convention in that we are
dropping the i that we have used until now. With this new notation, for ex-
ample, the inﬁnitesimal generator of a group of unitary transformations will be
a skew-adjoint operator rather than a self-adjoint operator. In quantum me-
chanics, where an “observable” is a self-adjoint operator, there is a good reason
for emphasizing the self-adjoint operators, and hence including the i. There
are many good reasons for deviating from the physicists’ notation, not the least
having to do with the theory of Lie algebras. I do not want to go into these
reasons now. Some will emerge from the ensuing notation. But the presence or
absence of the i is a cultural divide between physicists and mathematicians.
So we deﬁne the operator A as
Ax = lim
t↘0
1
t (Tt −I)x.
That is A is the operator deﬁned on the domain D(A) consisting of those x for
which the limit exists.
Our ﬁrst task is to show that D(A) is dense in F. For this we begin as
promised with the putative resolvent
R(z) :=
Z ∞
0
e−ztTtdt
(11.3)
which is deﬁned (by the boundedness and continuity properties of Tt) for all z
with Re z > 0. We begin by checking that every element of im R(z) belongs to

300
CHAPTER 11. STONE’S THEOREM
D(A): We have
1
h(Th −I)R(z)x = 1
h
Z ∞
0
e−ztTt+hxdt −1
h
Z ∞
0
e−ztTtxdt =
1
h
Z ∞
h
e−z(r−h)Trxdr−1
h
Z ∞
0
e−ztTtxdt
= ezh −1
h
Z ∞
h
e−ztTtxdt−1
h
Z h
0
e−ztTtxdt
= ezh −1
h
"
R(z)x −
Z h
0
e−ztTtdt
#
−1
h
Z h
0
e−ztTtxdt.
If we now let h →0, the integral inside the bracket tends to zero, and the
expression on the right tends to x since T0 = I. We thus see that
R(z)x ∈D(A)
and
AR(z) = zR(z) −I,
or, rewriting this in a more familiar form,
(zI −A)R(z) = I.
(11.4)
This equation says that R(z) is a right inverse for zI −A. It will require a lot
more work to show that it is also a left inverse.
We will ﬁrst prove that D(A) is dense in F by showing that im(R(z)) is
dense. In fact, taking s to be real, we will show that
lim
s→∞sR(s)x = x
∀x ∈F.
(11.5)
Indeed,
Z ∞
0
se−stdt = 1
for any s > 0. So we can write
sR(s)x −x = s
Z ∞
0
e−st[Ttx −x]dt.
Applying any seminorm p we obtain
p(sR(s)x −x) ≤s
Z ∞
0
e−stp(Ttx −x)dt.
For any ϵ > 0 we can, by the continuity of Tt, ﬁnd a δ > 0 such that
p(Ttx −x) < ϵ ∀0 ≤t ≤δ.
Now let us write
s
Z ∞
0
e−stp(Ttx −x)dt = s
Z δ
0
e−stp(Ttx −x)dt + s
Z ∞
δ
e−stp(Ttx −x)dt.

11.3. THE DIFFERENTIAL EQUATION
301
The ﬁrst integral is bounded by
ϵs
Z δ
0
e−stdt ≤ϵs
Z ∞
0
e−stdt = ϵ.
As to the second integral, let M be a bound for p(Ttx) + p(x) which exists by
the uniform boundedness of Tt. The triangle inequality says that p(Ttx −x) ≤
p(Ttx) + p(x) so the second integral is bounded by
M
Z ∞
δ
se−stdt = Me−sδ.
This tends to 0 as s →∞, completing the proof that sR(s)x →x and hence
that D(A) is dense in F.
11.3
The diﬀerential equation
Theorem 11.3.1 If x ∈D(A) then for any t > 0
lim
h→0
1
h[Tt+h −Tt]x = ATtx = TtAx.
In colloquial terms, we can formulate the theorem as saying that
d
dtTt = ATt = TtA
in the sense that the appropriate limits exist when applied to x ∈D(A).
Proof. Since Tt is continuous in t, we have
TtAx = Tt lim
h↘0
1
h[Th −I]x = lim
h↘0
1
h[TtTh −Tt]x =
lim
h↘0
1
h[Tt+h −Tt]x = lim
h↘0
1
h[Th −I]Ttx
for x ∈D(A). This shows that Ttx ∈D(A) and
lim
h↘0
1
h[Tt+h −Tt]x = ATtx = TtAx.
To prove the theorem we must show that we can replace h ↘0 by h →0.
Our strategy is to show that with the information that we already have about
the existence of right handed derivatives, we can conclude that
Ttx −x =
Z t
0
TsAxds.

302
CHAPTER 11. STONE’S THEOREM
Since Tt is continuous, this is enough to give the desired result. In order to
establish the above equality, it is enough, by the Hahn-Banach theorem to prove
that for any ℓ∈F∗we have
ℓ(Ttx) −ℓ(x) =
Z t
0
ℓ(TsAx)ds.
In turn, it is enough to prove this equality for the real and imaginary parts of ℓ.
So it all boils down to a lemma in the theory of functions of a real variable:
Lemma 11.3.1 Suppose that f is a continuous real valued function of t with
the property that the right hand derivative
d+
dt f := lim
h↘0
f(t + h) −f(t)
h
= g(t)
exists for all t and g(t) is continuous. Then f is diﬀerentiable with f ′ = g.
Proof.
We ﬁrst prove that d+
dt f ≥0 on an interval [a, b] implies that f(b) ≥
f(a). Suppose not. Then there exists an ϵ > 0 such that
f(b) −f(a) < −ϵ(b −a).
Set
F(t) := f(t) −f(a) + ϵ(t −a).
Then F(a) = 0 and
d+
dt F > 0.
At a this implies that there is some c > a near a with F(c) > 0. On the other
hand, since F(b) < 0, and F is continuous, there will be some point s < b
with F(s) = 0 and F(t) < 0 for s < t ≤b. This contradicts the fact that
[ d+
dt F](s) > 0.
Thus if d+
dt f ≥m on an interval [t1, t2] we may apply the above result to
f(t) −mt to conclude that
f(t2) −f(t1) ≥m(t2 −t1),
and if d+
dt f(t) ≤M we can apply the above result to Mt −f(t) to conclude that
f(t2) −f(t1) ≤M(t2 −t1). So if m = min g(t) = min d+
dt f on the interval [t1, t2]
and M is the maximum, we have
m ≤f(t2) −f(t1)
t2 −t1
≤M.
Since we are assuming that g is continuous, this is enough to prove that f is
indeed diﬀerentiable with derivative g. QED

11.3. THE DIFFERENTIAL EQUATION
303
11.3.1
The resolvent.
We have already veriﬁed that
R(z) =
Z ∞
0
e−ztTtdt
maps F into D(A) and satisﬁes
(zI −A)R(z) = I
for all z with Re z > 0, cf (11.4).
We shall now show that for this range of z
(zI −A)x = 0
⇒x = 0
∀x ∈D(A)
so that (zI −A)−1 exists and that it is given by R(z). Suppose that
Ax = zx
x ∈D(A)
and choose ℓ∈F∗with ℓ(x) = 1. Consider
φ(t) := ℓ(Ttx).
By the result of the preceding section we know that φ is a diﬀerentiable function
of t and satisﬁes the diﬀerential equation
φ′(t) = ℓ(TtAx) = ℓ(Ttzx) = zℓ(Ttx) = zφ(t),
φ(0) = 1.
So
φ(t) = ezt
which is impossible since φ(t) is a bounded function of t and the right hand
side of the above equation is not bounded for t ≥0 since the real part of z is
positive.
We have from (11.4) that
(zI −A)R(z)(zI −A)x = (zI −A)x
and we know that R(z)(zI −A)x ∈D(A). From the injectivity of zI −A we
conclude that R(z)(zI −A)x = x.
From (zI −A)R(z) = I we see that zI −A maps im R(z) ⊂D(A) onto F so
certainly zI −A maps D(A) onto F bijectively. Hence
im(R(z)) = D(A),
im(zI −A) = F
and
R(z) = (zI −A)−1.
We have already established the following:

304
CHAPTER 11. STONE’S THEOREM
The resolvent R(z) = R(z, A) :=
R ∞
0
e−ztTtdt is deﬁned as a strong limit for
Re z > 0 and, for this range of z:
D(A)
=
im(R(z, A))
(11.6)
AR(z, A)x = R(z, A)Ax
=
(zR(z, A) −I)x
x ∈D(A)
(11.7)
AR(z, A)x
=
(zR(z, A) −I)x
∀x ∈F
(11.8)
lim
z↗∞zR(z, A)x
=
x
for z real ∀x ∈F.
(11.9)
We also have
Theorem 11.3.2 The operator A is closed.
Proof. Suppose that xn ∈D(A), xn →x and yn →y where yn = Axn. We
must show that x ∈D(A) and Ax = y. Set
zn := (I −A)xn
so zn →x −y.
Since R(1, A) = (I −A)−1 is a bounded operator, we conclude that
x = lim xn = lim(I −A)−1zn = (I −A)−1(x −y).
From (11.6) we see that x ∈D(A) and from the preceding equation that (I −
A)x = x −y so Ax = y. QED
Application to Stone’s theorem.
We now have enough information to complete the proof of Stone’s theorem:
Suppose that U(t) is a one-parameter group of unitary transformations on
a Hilbert space. We have (U(t)x, y) = (x, U(t)−1y) = (x, U(−t)y) and so diﬀer-
entiating at the origin shows that the inﬁnitesimal generator A, which we know
to be closed, is skew-symmetric:
(Ax, y) = (x, Ay)
∀x, y ∈D(A).
Also the resolvents (zI −A)−1 exist for all z which are not purely imaginary,
and (zI −A) maps D(A) onto the whole Hilbert space H.
Writing A = iT we see that T is symmetric and that its Cayley transform
UT has zero kernel and is surjective, i.e. is unitary. Hence T is self-adjoint.
This proves Stone’s theorem that every one parameter group of unitary trans-
formations is of the form eiT t with T self-adjoint.
11.3.2
Examples.
For r > 0 let
Jr := (I −r−1A)−1 = rR(r, A)
so by (11.8) we have
AJr = r(Jr −I).
(11.10)

11.3. THE DIFFERENTIAL EQUATION
305
Translations.
Consider the one parameter group of translations acting on L2(R):
[U(t)x](s) = x(s −t).
(11.11)
This is deﬁned for all x ∈S and is an isometric isomorphism there, so extends
to a unitary one parameter group acting on L2(R). Equally well, we can take
the above equation in the sense of distributions, where it makes sense for all
elements of S′, in particular for all elements of L2(R). We know that we can
diﬀerentiate in the distributional sense to obtain
A = −d
ds
as the “inﬁnitesimal generator” in the distributional sense. Let us see what the
general theory gives. Let yr := Jrx so
yr(s) = r
Z ∞
0
e−rtx(s −t)dt = r
Z s
−∞
e−r(s−u)x(u)du.
The right hand expression is a diﬀerentiable function of s and
y′
r(s) = rx(s) −r2
Z s
−∞
e−r(s−u)x(u)du = rx(s) −ryr(s).
On the other hand we know from (11.10) that
Ayr = AJrx = r(yr −x).
Putting the two equations together gives
A = −d
ds
as expected. This is a skew-adjoint operator in accordance with Stone’s theorem.
We can now go back and give an intuitive explanation of what goes wrong
when considering this same operator A but on L2[0, 1] instead of on L2(R). If
x is a smooth function of compact support lying in (0, 1), then x can not tell
whether it is to be thought of as lying in L2([0, 1]) or L2(R), so the only choice
for a unitary one parameter group acting on x (at least for small t > 0) if the
shift to the right as given by (11.11). But once t is large enough that the support
of U(t)x hits the right end point, 1, this transformation can not continue as is.
The only hope is to have what “goes out” the right hand side come in, in some
form, on the left, and unitarity now requires that
Z 1
0
|x(s −t)|2dt =
Z 1
0
|x(t)|2dt
where now the shift in (11.11) means mod 1. This still allows freedom in the
choice of phase between the exiting value of the x and its incoming value. Thus
we specify a unitary one parameter group when we ﬁx a choice of phase as the
eﬀect of “passing go”. This choice of phase is the origin of the θ that are needed
to introduce in ﬁnding the self adjoint extensions of 1
i
d
dt acting on functions
vanishing at the boundary.

306
CHAPTER 11. STONE’S THEOREM
The heat equation.
Let F consist of the bounded uniformly continuous functions on R. For t > 0
deﬁne
[Ttx](s) =
1
√
2πt
Z ∞
−∞
e−(s−v)/2tx(v)dv.
In other words, Tt is convolution with
nt(u) =
1
√
2πte−u2/2t.
We have already veriﬁed in our study of the Fourier transform that this is a
continuous semi-group (when we set T0 = I) when acting on S. In fact, for
x ∈S, we can take the Fourier transform and conclude that
[Ttx]ˆ(σ) = e−iσ2t/2ˆx(σ).
Diﬀerentiating this with respect to t and setting t = 0 (and taking the inverse
Fourier transform) shows that
 d
dtTtx

t=0
= 1
2
d2
ds2 x
for x ∈S. We wish to arrive at the same result for Tt acting on F. It is easy
enough to verify that the operators Tt are continuous in the uniform norm and
hence extend to an equibounded semigroup on F. We will now verify that the
inﬁnitesimal generator A of this semigroup is
A = 1
2
d2
ds2
with domain consisting of all twice diﬀerentiable functions.
Let us set yr = Jrx so
yr(s)
=
Z ∞
−∞
x(v)
Z ∞
0
r
1
√
2πte−rt−(s−v)2/2tdt

dv
=
Z ∞
−∞
x(v)
Z ∞
0
2√r
1
√
2π e−σ2−r(s−v)2/2σ2dσ

dv setting t = σ2/r
=
Z ∞
−∞
x(v)(r/2)
1
2 e−
√
2r|s−v|dv
since for any c > 0 we have
Z ∞
0
e−(σ2+c2/σ2)dσ =
√π
2 e−2c.
(11.12)
Let me postpone the calculation of this integral to the end of the subsection.
Assuming the evaluation of this integral we can write
yr(s) =
r
2
 1
2 Z ∞
s
x(v)e−
√
2r(v−s)dv +
Z s
−∞
x(v)e−
√
2r(s−v)dv

.

11.3. THE DIFFERENTIAL EQUATION
307
This is a diﬀerentiable function of s and we can diﬀerentiate to obtain
y′
r(s) = r
Z ∞
s
x(v)e−
√
2r(v−s)dv −
Z s
−∞
x(v)e−
√
2r(s−v)dv

.
This is also diﬀerentiable and compute its derivative to obtain
y′′
r (s) = −2rx(s) + r3/2√
2
Z ∞
−∞
x(v))e−
√
2r|v−s|dv,
or
y′′
r = 2r(yr −x).
Comparing this with (11.10) which says that Ayr = r(yr −x) we see that indeed
A = 1
2
d2
ds2 .
Let us now verify the evaluation of the integral in (11.12): Start with the
known integral
Z ∞
0
e−x2dx =
√π
2 .
Set x = σ −c/σ so that dx = (1 + c/σ2)dσ and x = 0 corresponds to σ = √c.
Thus
√π
2 =
Z ∞
√c
e−(σ−c/σ)2(1 + c/σ)2dσ = e2c
Z ∞
√c
e−(σ2+c2/σ2)(1 + c/σ2)dσ
= e2c
Z ∞
√c
e−(σ2+c2/σ2)dσ +
Z ∞
√c
e−(σ2+c2/σ2) c
σ2 dσ

.
In the second integral inside the brackets set t = −c/σ so dt =
c
σ2 dσ and this
second integral becomes
Z √c
0
e−(t2+c2/t2)dt
and hence
√π
2
= e2c
Z ∞
0
e−(σ2+c2/σ2)dσ
which is (11.12).
Bochner’s theorem.
A complex valued continuous function F is called positive deﬁnite if for every
continuous function φ of compact support we have
Z
R
Z
R
F(t −s)φ(t)φ(s)dtds ≥0.
(11.13)

308
CHAPTER 11. STONE’S THEOREM
We can write this as
(F ⋆φ, φ) ≥0
where the convolution is taken in the sense of generalized functions. If we write
F = ˆG and φ = ˆψ then by Plancherel this equation becomes
(Gψ, ψ) ≥0
or
⟨G, |ψ|2⟩≥0
which will certainly be true if G is a ﬁnite non-negative measure. Bochner’s
theorem asserts the converse: that any positive deﬁnite function is the Fourier
transform of a ﬁnite non-negative measure. We shall follow Yosida pp. 346-347
in showing that Stone’s theorem implies Bochner’s theorem.
Let F denote the space of functions on R which have ﬁnite support, i.e.
vanish outside a ﬁnite set. This is a complex vector space, and has the semi-
scalar product
(x, y) :=
X
t,s
F(t −s)x(t)y(s).
(It is easy to see that the fact that F is a positive deﬁnite function implies that
(x, x) ≥0 for all x ∈F.) Passing to the quotient by the subspace of null vectors
and completing we obtain a Hilbert space H.
Let Ur be deﬁned by [Urx](t) = x(t −r) as usual. Then
(Urx, Ury) =
X
t,s
F(t−s)x(t−r)y(s −r) =
X
t,s
F(t+r−(s+r))x(t)y(s) = (x, y).
So Ur descends to H to deﬁne a unitary operator which we shall continue to
denote by Ur. We thus obtain a one parameter group of unitary transformations
on H. According to Stone’s theorem there exists a resolution Eλ of the identity
such that
Ut =
Z ∞
−∞
eitλdEλ.
Now choose δ ∈F to be deﬁned by
δ(t) =
 1
if
t = 0
0
if
t ̸= 0 .
Let x be the image of δ in H. Then
(Urx, x) =
X
F(t −s)δ(t −r)δ(s) = F(r).
But by Stone we have
F(r) =
Z ∞
−∞
eirλdµx,x =
Z ∞
−∞
eirλd∥Eλx∥2

11.4. THE POWER SERIES EXPANSION OF THE EXPONENTIAL.
309
so we have represented F as the Fourier transform of a ﬁnite non-negative
measure. QED
The logic of our argument has been - the Spectral Theorem implies Stone’s
theorem implies Bochner’s theorem. In fact, assuming the Hille-Yosida theorem
on the existence of semigroups to be proved below, one can go in the opposite
direction.
Given a one parameter group U(t) of unitary transformations, it
is easy to check that for any x ∈H the function t 7→(U(t)x, x) is positive
deﬁnite, and then use Bochner’s theorem to derive the spectral theorem on the
cyclic subspace generated by x under U(t). One can then get the full spectral
theorem in multiplication operator form as we did in the handout on unbounded
self-adjoint operators.
11.4
The power series expansion of the expo-
nential.
In ﬁnite dimensions we have the formula
etB =
∞
X
0
tk
k!Bk
with convergence guaranteed as a result of the convergence of the usual expo-
nential series in one variable. (There are serious problems with this deﬁnition
from the point of view of numerical implementation which we will not discuss
here.)
In inﬁnite dimensional spaces some additional assumptions have to be placed
on an operator B before we can conclude that the above series converges. Here
is a very stringent condition which nevertheless suﬃces for our purposes.
Let F be a Frechet space and B a continuous map of F →F. We will assume
that the Bk are equibounded in the sense that for any deﬁning semi-norm p
there is a constant K and a deﬁning semi-norm q such that
p(Bkx) ≤Kq(x)
∀k = 1, 2, . . .
∀x ∈F.
Here the K and q are required to be independent of k and x.
Then
p(
n
X
m
tk
k!Bkx) ≤
n
X
m
tk
k!p(Bkx) ≤Kq(x)
n
X
n
tk
k!
and so
n
X
0
tk
k!Bkx
is a Cauchy sequence for each ﬁxed t and x (and uniformly in any compact
interval of t). It therefore converges to a limit. We will denote the map x 7→
P∞
0
tk
k! Bkx by
exp(tB).

310
CHAPTER 11. STONE’S THEOREM
This map is linear, and the computation above shows that
p(exp(tB)x) ≤K exp(t)q(x).
The usual proof (using the binomial formula) shows that t 7→exp(tB) is a one
parameter equibounded semi-group. More generally, if B and C are two such
operators then if BC = CB then exp(t(B + C)) = (exp tB)(exp tC).
Also, from the power series it follows that the inﬁnitesimal generator of
exp tB is B.
11.5
The Hille Yosida theorem.
Let us now return to the general case of an equibounded semigroup Tt with
inﬁnitesimal generator A on a Frechet space F where we know that the resolvent
R(z, A) for Re z > 0 is given by
R(z, A)x =
Z ∞
0
e−ztTtxdt.
This formula shows that R(z, A)x is continuous in z. The resolvent equation
R(z, A) −R(w, A) = (w −z)R(z, A)R(w, A)
then shows that R(z, A)x is complex diﬀerentiable in z with derivative −R(z, A)2x.
It then follows that R(z, A)x has complex derivatives of all orders given by
dnR(z, A)x
dzn
= (−1)nn!R(z, A)n+1x.
On the other hand, diﬀerentiating the integral formula for the resolvent n- times
gives
dnR(z, A)x
dzn
=
Z ∞
0
e−zt(−t)nTtdt
where diﬀerentiation under the integral sign is justiﬁed by the fact that the Tt
are equicontinuous in t. Putting the previous two equations together gives
(zR(z, A))n+1x = zn+1
n!
Z ∞
0
e−zttnTtxdt.
This implies that for any semi-norm p we have
p((zR(z, A))n+1x) ≤zn+1
n!
Z ∞
0
e−zttn sup
t≥0
p(Ttx)dt = sup
t≥0
p(Ttx)
since
Z ∞
0
e−zttndt =
n!
zn+1 .
Since the Tt are equibounded by hypothesis, we conclude

11.5. THE HILLE YOSIDA THEOREM.
311
Proposition 11.5.1 The family of operators {(zR(z, A))n} is equibounded in
Re z > 0 and n = 0, 1, 2, . . . .
We now come to the main result of this section:
Theorem 11.5.1 [Hille -Yosida.] Let A be an operator with dense domain
D(A), and such that the resolvents
R(n, A) = (nI −A)−1
exist and are bounded operators for n = 1, 2, . . . . Then A is the inﬁnitesimal
generator of a uniquely determined equibounded semigroup if and only if the
operators
{(I −n−1A)−m}
are equibounded in m = 0, 1, 2 . . . and n = 1, 2, . . . .
Proof.
If A is the inﬁnitesimal generator of an equibounded semi-group then
we know that the {(I −n−1A)−m} are equibounded by virtue of the preceding
proposition. So we must prove the converse.
Set
Jn = (I −n−1A)−1
so Jn = n(nI −A)−1 and so for x ∈D(A) we have
Jn(nI −A)x = nx
or
JnAx = n(Jn −I)x.
Similarly (nI −A)Jn = nI so AJn = n(Jn −I). Thus we have
AJnx = JnAx = n(Jn −I)x
∀x ∈D(A).
(11.14)
The idea of the proof is now this: By the results of the preceding section, we
can construct the one parameter semigroup s 7→exp(sJn). Set s = nt. We can
then form e−nt exp(ntJn) which we can write as exp(tn(Jn −I)) = exp(tAJn)
by virtue of (11.14). We expect from (11.5) that
lim
n→∞Jnx = x
∀
x ∈F.
(11.15)
This then suggests that the limit of the exp(tAJn) be the desired semi-group.
So we begin by proving (11.15). We ﬁrst prove it for x ∈D(A). For such x
we have (Jn −I)x = n−1JnAx by (11.14) and this approaches zero since the Jn
are equibounded. But since D(A) is dense in F and the Jn are equibounded we
conclude that (11.15) holds for all x ∈F.
Now deﬁne
T (n)
t
= exp(tAJn) := exp(nt(Jn −I)) = e−nt exp(ntJn).

312
CHAPTER 11. STONE’S THEOREM
We know from the preceding section that
p(exp(ntJn)x) ≤
X (nt)k
k!
p(Jk
nx) ≤entKq(x)
which implies that
p(T (n)
t
x) ≤Kq(x).
(11.16)
Thus the family of operators {T (n)
t
} is equibounded for all t ≥0 and n = 1, 2, . . . .
We next want to prove that the {T (n)
t
} converge as n →∞uniformly on each
compact interval of t:
The Jn commute with one another by their deﬁnition, and hence Jn com-
mutes with T (m)
t
. By the semi-group property we have
d
dtT m
t x = AJmT (m)
t
x = T (m)
t
AJmx
so
T (n)
t
x −T (m)
t
x =
Z t
0
d
ds(T (m)
t−s T (n)
s
)xds =
Z t
0
T (m)
t−s (AJn −AJm)T (n)
s
xds.
Applying the semi-norm p and using the equiboundedness we see that
p(T (n)
t
x −T (m)
t
x) ≤Ktq((Jn −Jm)Ax).
From (11.15) this implies that the T (n)
t
x converge (uniformly in every compact
interval of t) for x ∈D(A), and hence since D(A) is dense and the T (n)
t
are
equicontinuous for all x ∈F. The limiting family of operators Tt are equicon-
tinuous and form a semi-group because the T (n)
t
have this property.
We must show that the inﬁnitesimal generator of this semi-group is A. Let
us temporarily denote the inﬁnitesimal generator of this semi-group by B, so
that we want to prove that A = B. Let x ∈D(A). We claim that
lim
n→∞T (n)
t
AJnx = TtAx
(11.17)
uniformly in in any compact interval of t. Indeed, for any semi-norm p we have
p(TtAx −T (n)
t
AJnx)
≤
p(TtAx −T (n)
t
Ax) + p(T (n)
t
Ax −T (n)
t
AJnx)
≤
p((Tt −T (n)
t
)Ax) + Kq(Ax −JnAx)
where we have used (11.16) to get from the second line to the third. The second
term on the right tends to zero as n →∞and we have already proved that
the ﬁrst term converges to zero uniformly on every compact interval of t. This
establishes (11.17).

11.6. CONTRACTION SEMIGROUPS.
313
We thus have, for x ∈D(A),
Ttx −x
=
lim
n→∞(T (n)
t
x −x)
=
lim
n→∞
Z t
0
T (n)
s
AJnxds
=
Z t
0
( lim
n→∞T (n)
s
AJnx)ds
=
Z t
0
TsAxds
where the passage of the limit under the integral sign is justiﬁed by the uniform
convergence in t on compact sets. It follows from Ttx −x =
R t
0 TsAxds that x
is in the domain of the inﬁnitesimal operator B of Tt and that Bx = Ax. So B
is an extension of A in the sense that D(B) ⊃D(A) and Bx = Ax on D(A).
But since B is the inﬁnitesimal generator of an equibounded semi-group, we
know that (I −B) maps D(B) onto F bijectively, and we are assuming that
(I −A) maps D(A) onto F bijectively. Hence D(A) = D(B). QED
In case F is a Banach space, so there is a single norm p = ∥∥, the hypotheses
of the theorem read: D(A) is dense in F, the resolvents R(n, A) exist for all
integers n = 1, 2, . . . and there is a constant K independent of n and m such
that
∥(I −n−1A)−m∥≤K ∀n = 1, 2, . . . , m = 1, 2, . . . .
(11.18)
11.6
Contraction semigroups.
In particular, if A satisﬁes
∥(I −n−1A)−1∥≤1
(11.19)
condition (11.18) is satisﬁed, and such an A then generates a semi-group. Under
this stronger hypothesis we can draw a stronger conclusion: In (11.16) we now
have p = q = ∥· ∥and K = 1. Since limn→∞T n
t x = Ttx we see that under the
hypothesis (11.19) we can conclude that
∥Tt∥≤1
∀t ≥0.
A semi-group Tt satisfying this condition is called a contraction semi-group.
We will study another useful condition for recognizing a contraction semigroup
in the following subsection.
We have already given a direct proof that if S is a self-adjoint operator on
a Hilbert space then the resolvent exists for all non-real z and satisﬁes
∥R(z, S)∥≤
1
|Im (z)|.

314
CHAPTER 11. STONE’S THEOREM
This implies (11.19) for A = iS and −iS giving us an independent proof of
the existence of U(t) = exp(iSt) for any self-adjoint operator S. As we men-
tioned previously, we could then use Bochner’s theorem to give a third proof
of the spectral theorem for unbounded self-adjoint operators. I might discuss
Bochner’s theorem in the context of generalized functions later probably next
semester if at all. Once we give an independent proof of Bochner’s theorem then
indeed we will get a third proof of the spectral theorem.
11.6.1
Dissipation and contraction.
Let F be a Banach space. Recall that a semi-group Tt is called a contraction
semi-group if
∥Tt∥≤1
∀t ≥0,
and that (11.19) is a suﬃcient condition on operator with dense domain to
generate a contraction semi-group.
The Lumer-Phillips theorem to be stated below gives a necessary and suﬃ-
cient condition on the inﬁnitesimal generator of a semi-group for the semi-group
to be a contraction semi-group. It is generalization of the fact that the resolvent
of a self-adjoint operator has ±i in its resolvent set.
The ﬁrst step is to introduce a sort of fake scalar product in the Banach space
F. A semi-scalar product on F is a rule which assigns a number ⟨⟨x, z⟩⟩to
every pair of elements x, z ∈F in such a way that
⟨⟨x + y, z⟩⟩
=
⟨⟨x, z⟩⟩+ ⟨⟨y, z⟩⟩
⟨⟨λx, z⟩⟩
=
λ⟨⟨x, z⟩⟩
⟨⟨x, x⟩⟩
=
∥x∥2
|⟨⟨x, z⟩⟩|
≤
∥x∥· ∥z∥.
We can always choose a semi-scalar product as follows: by the Hahn-Banach
theorem, for each z ∈F we can ﬁnd an ℓz ∈F∗such that
∥ℓz∥= ∥z∥and ℓz(z) = ∥z∥2.
Choose one such ℓz for each z ∈F and set
⟨⟨x, z⟩⟩:= ℓz(x).
Clearly all the conditions are satisﬁed. Of course this deﬁnition is highly unnat-
ural, unless there is some reasonable way of choosing the ℓz other than using the
axiom of choice. In a Hilbert space, the scalar product is a semi-scalar product.
An operator A with domain D(A) on F is called dissipative relative to a
given semi-scalar product ⟨⟨·, ·⟩⟩if
Re ⟨⟨Ax, x⟩⟩≤0
∀x ∈D(A).
For example, if A is a symmetric operator on a Hilbert space such that
(Ax, x) ≤0 ∀x ∈D(A)
(11.20)

11.6. CONTRACTION SEMIGROUPS.
315
then A is dissipative relative to the scalar product.
Theorem 11.6.1 [Lumer-Phillips.] Let A be an operator on a Banach space
F with D(A) dense in F. Then A generates a contraction semi-group if and
only if A is dissipative with respect to any semi-scalar product and
im(I −A) = F.
Proof.
Suppose ﬁrst that D(A) is dense and that im(I −A) = F. We wish
to show that (11.19) holds, which will guarantee that A generates a contraction
semi-group. Let s > 0. Then if x ∈D(A) and y = sx −Ax then
s∥x∥2 = s⟨⟨x, x⟩⟩≤s⟨⟨x, x⟩⟩−Re ⟨⟨Ax, x⟩⟩= Re ⟨⟨y, x⟩⟩
implying
s∥x∥2 ≤∥y∥∥x∥.
(11.21)
We are assuming that im(I −A) = F. This together with (11.21) with s = 1
implies that R(1, A) exists and
∥R(1, A)∥≤1.
In turn, this implies that for all z with |z −1| < 1 the resolvent R(z, A) exists
and is given by the power series
R(z, A) =
∞
X
n=0
(z −1)nR(1, A)n+1
by our general power series formula for the resolvent. In particular, for s real and
|s −1| < 1 the resolvent exists, and then (11.21) implies that ∥R(s, A)∥≤s−1.
Repeating the process we keep enlarging the resolvent set ρ(A) until it includes
the whole positive real axis and conclude from (11.21) that ∥R(s, A)∥≤s−1
which implies (11.19). As we are assuming that D(A) is dense we conclude that
A generates a contraction semigroup.
Conversely, suppose that Tt is a contraction semi-group with inﬁnitesimal
generator A. We know that Dom(A) is dense. Let ⟨⟨·, ·⟩⟩be any semi-scalar
product. Then
Re ⟨⟨Ttx −x, x⟩⟩= Re ⟨⟨Ttx, x⟩⟩−∥x∥2 ≤∥Ttx∥∥x∥−∥x∥2 ≤0.
Dividing by t and letting t ↘0 we conclude that Re ⟨⟨Ax, x⟩⟩≤0 for all
x ∈D(A), i.e. A is dissipative for ⟨⟨·, ·⟩⟩. QED
Once again, this gives a direct proof of the existence of the unitary group
generated generated by a skew adjoint operator.
A useful way of verifying the condition im(I −A) = F is the following: Let
A∗: F∗→F∗be the adjoint operator which is deﬁned if we assume that D(A)
is dense.

316
CHAPTER 11. STONE’S THEOREM
Proposition 11.6.1 Suppose that A is densely deﬁned and closed, and suppose
that both A and A∗are dissipative. Then im(I −A) = F and hence A generates
a contraction semigroup.
Proof. The fact that A is closed implies that (I −A)−1 is closed, and since we
know that (I −A)−1 is bounded from the fact that A is dissipative, we conclude
that im(I −A) is a closed subspace of F. If it were not the whole space there
would be an ℓ∈F ∗which vanished on this subspace, i.e.
⟨ℓ, x −Ax⟩= 0
∀x ∈D(A).
This implies that that ℓ∈D(A∗) and A∗ℓ= ℓwhich can not happen if A∗is
dissipative by (11.21) applied to A∗and s = 1. QED
11.6.2
A special case: exp(t(B −I)) with ∥B∥≤1.
Suppose that B : F →F is a bounded operator on a Banach space with ∥B∥≤1.
Then for any semi-scalar product we have
Re ⟨⟨(B −I)x, x⟩⟩= Re ⟨⟨Bx, x⟩⟩−∥x∥2 ≤∥Bx∥∥x∥−∥x∥2 ≤0
so B−I is dissipative and hence exp(t(B−I)) exists as a contraction semi-group
by the Lumer-Phillips theorem. We can prove this directly since we can write
exp(t(B −I)) = e−t
∞
X
k=0
tkBk
k! .
The series converges in the uniform norm and we have
∥exp(t(B −I))∥≤e−t
∞
X
k=0
tk∥B∥k
k!
≤1.
For future use (Chernoﬀ’s theorem and the Trotter product formula) we
record (and prove) the following inequality:
∥[exp(n(B −I)) −Bn]x∥≤√n∥(B −I)x∥
∀x ∈F, and ∀n = 1, 2, 3 . . . .
(11.22)

11.7. CONVERGENCE OF SEMIGROUPS.
317
Proof.
∥[exp(n(B −I)) −Bn]x∥
=
∥e−n
∞
X
k=0
nk
k! (Bk −Bn)x∥
≤
e−n
∞
X
k=0
nk
k! ∥(Bk −Bn)x∥
≤
e−n
∞
X
k=0
nk
k! ∥(B|k−n| −I)x∥
=
e−n
∞
X
k=0
nk
k! ∥(B −I)(I + B + · · · + B(|k−n|−1)x∥
≤
e−n
∞
X
k=0
nk
k! |k −n|∥(B −I)x∥.
So to prove (11.22) it is enough establish the inequality
e−n
∞
X
k=0
nk
k! |k −n| ≤√n.
(11.23)
Consider the space of all sequences a = {a0, a1, . . . } with ﬁnite norm relative to
scalar product
(a, b) := e−n
∞
X
k=0
nk
k! akbk.
The Cauchy-Schwarz inequality applied to a with ak = |k−n| and b with bk ≡1
gives
e−n
∞
X
k=0
nk
k! |k −n| ≤
v
u
u
te−n
∞
X
k=0
nk
k! (k −n)2 ·
v
u
u
te−n
∞
X
k=0
nk
k! .
The second square root is one, and we recognize the sum under the ﬁrst square
root as the variance of the Poisson distribution with parameter n, and we know
that this variance is n. QED
11.7
Convergence of semigroups.
We are going to be interested in the following type of result. We would like
to know that if An is a sequence of operators generating equibounded one pa-
rameter semi-groups exp tAn and An →A where A generates an equibounded
semi-group exp tA then the semi-groups converge, i.e. exp tAn →exp tA. We
will prove such a result for the case of contractions. But before we can even
formulate the result, we have to deal with the fact that each An comes equipped
with its own domain of deﬁnition, D(An). We do not want to make the overly

318
CHAPTER 11. STONE’S THEOREM
restrictive hypothesis that these all coincide, since in many important applica-
tions they won’t.
For this purpose we make the following deﬁnition. Let us assume that F
is a Banach space and that A is an operator on F deﬁned on a domain D(A).
We say that a linear subspace D ⊂D(A) is a core for A if the closure A of A
and the closure of A restricted to D are the same: A = A|D. This certainly
implies that D(A) is contained in the closure of A|D. In the cases of interest to
us D(A) is dense in F, so that every core of A is dense in F.
We begin with an important preliminary result:
Proposition 11.7.1 Suppose that An and A are dissipative operators, i.e. gen-
erators of contraction semi-groups. Let D be a core of A. Suppose that for each
x ∈D we have that x ∈D(An) for suﬃciently large n (depending on x) and
that
Anx →Ax.
(11.24)
Then for any z with Re z > 0 and for all y ∈F
R(z, An)y →R(z, A)y.
(11.25)
Proof.
We know that the R(z, An) and R(z, A) are all bounded in norm
by 1/Re z. So it is enough for us to prove convergence on a dense set. Since
(zI −A)D(A) = F, it follows that (zI −A)D is dense in F since A is closed.
So in proving (11.25) we may assume that y = (zI −A)x with x ∈D. Then
∥R(z, An)y −R(z, A)y∥
=
∥R(z, An)(zI −A)x −x∥
=
∥R(z, An)(zI −An)x + R(z, An)(Anx −Ax) −x∥
=
∥R(z, An)(An −A)x∥
≤
1
Re z ∥(An −A)x∥→0,
where, in passing from the ﬁrst line to the second we are assuming that n is
chosen suﬃciently large that x ∈D(An). QED
Theorem 11.7.1 Under the hypotheses of the preceding proposition,
(exp(tAn))x →(exp(tA))x
for each x ∈F uniformly on every compact interval of t.
Proof.
Let
φn(t) := e−t[((exp(tAn))x −(exp(tA))x)] for t ≥0
and set φ(t) = 0 for t < 0. It will be enough to prove that these F valued
functions converge uniformly in t to 0, and since D is dense and since the
operators entering into the deﬁnition of φn are uniformly bounded in n, it is
enough to prove this convergence for x ∈D which is dense. We claim that

11.7. CONVERGENCE OF SEMIGROUPS.
319
for ﬁxed x ∈D the functions φn(t) are uniformly equi-continuous. To see this
observe that
d
dtφn(t) = e−t[(exp(tAn))Anx −(exp(tA))Ax] −e−t[(exp(tAn))x −(exp(tA))x]
for t ≥0 and the right hand side is uniformly bounded in t ≥0 and n.
So to prove that φn(t) converges uniformly in t to 0, it is enough to prove
this fact for the convolution φn ⋆ρ where ρ is any smooth function of compact
support, since we can choose the ρ to have small support and integral
√
2π, and
then φn(t) is close to (φn ⋆ρ)(t).
Now the Fourier transform of φn⋆ρ is the product of their Fourier transforms:
ˆ
φnˆρ. We have ˆ
φn(s) =
1
√
2π
Z ∞
0
e(−1−is)t[(exp tAn)x−(exp(tA))x]dt =
1
√
2π [R(1+is, An)x−R(1+is, A)x].
Thus by the proposition
ˆ
φn(s) →0,
in fact uniformly in s. Hence using the Fourier inversion formula and, say, the
dominated convergence theorem (for Banach space valued functions),
(φn ⋆ρ)(t) =
1
√
2π
Z ∞
−∞
ˆ
φn(s)ˆρ(s)eistds →0
uniformly in t. QED
The preceding theorem is the limit theorem that we will use in what follows.
However, there is an important theorem valid in an arbitrary Frechet space, and
which does not assume that the An converge, or the existence of the limit A,
but only the convergence of the resolvent at a single point z0 in the right hand
plane!
In the following F is a Frechet space and {exp(tAn)} is a family of of equi-
bounded semi-groups which is also equibounded in n, so for every semi-norm p
there is a semi-norm q and a constant K such that
p(exp(tAn)x) ≤Kq(x)
∀x ∈F
where K and q are independent of t and n. I will state the theorem here, and
refer you to Yosida pp.269-271 for the proof.
Theorem 11.7.2 [Trotter-Kato.] Suppose that {exp(tAn)} is an equibounded
family of semi-groups as above, and suppose that for some z0 with positive real
part there exist an operator R(z0) such that
lim
n→∞R(z0, An) →R(z0)
and
im R(z0) is dense in F.

320
CHAPTER 11. STONE’S THEOREM
Then there exists an equibounded semi-group exp(tA) such that
R(z0) = R(z0, A)
and
exp(tAn) →exp(tA)
uniformly on every compact interval of t ≥0.
11.8
The Trotter product formula.
In what follows, F is a Banach space. Eventually we will restrict attention to a
Hilbert space. But we will begin with a classical theorem of Lie:
11.8.1
Lie’s formula.
Let A and B be linear operators on a ﬁnite dimensional Hilbert space. Lie’s
formula says that
exp(A + B) = lim
n→∞[(exp A/n)(exp B/n)]n .
(11.26)
Proof.
Let Sn := exp( 1
n(A + B)) so that
Sn
n = exp(A + B).
Let Tn = (exp A/n)(exp B/n). We wish to show that
Sn
n −T n
n →0.
Notice that the constant and the linear terms in the power series expansions for
Sn and Tn are the same, so
∥Sn −Tn∥≤C
n2
where C = C(A, B). We have the telescoping sum
Sn
n −T n
n =
n−1
X
k=0
Sk−1
n
(Sn −Tn)T n−1−k
so
∥Sn
n −T n
n ∥≤n∥Sn −Tn∥(max(∥Sn∥, ∥Tn∥))n−1 .
But
∥Sn∥≤exp 1
n(∥A∥+ ∥B∥)
and ∥Tn∥exp 1
n(∥A∥+ ∥B∥)
and

exp 1
n(∥A∥+ ∥B∥)
n−1
= exp n −1
n
(∥A∥+ ∥B∥) ≤exp(∥A∥+ ∥B∥)

11.8. THE TROTTER PRODUCT FORMULA.
321
so
∥Sn
n −T n
n ∥≤C
n exp(∥A∥+ ∥B∥.
□
This same proof works if A and B are self-adjoint operators such that A + B
is self-adjoint on the intersection of their domains. For a proof see Reed-Simon
vol. I pages 295-296. For applications this is too restrictive. So we give a more
general formulation and proof following Chernoﬀ.
11.8.2
Chernoﬀ’s theorem.
Theorem 11.8.1 [Chernoﬀ.] Let f : [0, ∞) →bounded operators on F be a
continuous map with
∥f(t)∥≤1
∀t
and
f(0) = I.
Let A be a dissipative operator and exp tA the contraction semi-group it gener-
ates. Let D be a core of A. Suppose that
lim
h↘0
1
h[f(h) −I]x = Ax
∀x ∈D.
Then for all y ∈F
lim

f
 t
n
n
y = (exp tA)y
(11.27)
uniformly in any compact interval of t ≥0.
Proof.
For ﬁxed t > 0 let
Cn := n
t

f
 t
n

−I

.
Then t
nCn generates a contraction semi-group by the special case of the Lumer-
Phillips theorem discussed in Section 11.6.2, and therefore (by change of vari-
able), so does Cn. So Cn is the generator of a semi-group
exp tCn
and the hypothesis of the theorem is that Cnx →Ax for x ∈D. Hence by the
limit theorem in the preceding section
(exp tCn)y →(exp tA)y
for each y ∈F uniformly on any compact interval of t. Now
exp(tCn) = exp n

f
 t
n

−I


322
CHAPTER 11. STONE’S THEOREM
so we may apply (11.22) to conclude that
∥

exp(tCn) −f
 t
n
n
x∥≤√n∥

f
 t
n

−I

x∥=
t
√n∥n
t

f
 t
n

−I

x∥.
The expression inside the ∥· ∥on the right tends to Ax so the whole expression
tends to zero. This proves (11.27) for all x in D. But since D is dense in F and
f(t/n) and exp tA are bounded in norm by 1 it follows that (11.27) holds for all
y ∈F. QED
11.8.3
The product formula.
Let A and B be the inﬁnitesimal generators of the contraction semi-groups
Pt = exp tA and Qt = exp tB on the Banach space F. Then A + B is only
deﬁned on D(A)∩D(B) and in general we know nothing about this intersection.
However let us assume that D(A) ∩D(B) is suﬃciently large that the closure
A + B is a densely deﬁned operator and A + B is in fact the generator of a
contraction semi-group Rt. So D := D(A) ∩D(B) is a core for A + B.
Theorem 11.8.2 [Trotter.] Under the above hypotheses
Rty = lim

P t
n Q t
n
n
y
∀y ∈F
(11.28)
uniformly on any compact interval of t ≥0.
Proof. Deﬁne
f(t) = PtQt.
For x ∈D we have
f(t)x = Pt(I + tB + o(t))x = (I + At + Bt + o(t))x
so the hypotheses of Chernoﬀ’s theorem are satisﬁed. The conclusion of Cher-
noﬀ’s theorem asserts (11.28). QED
A symmetric operator on a Hilbert space is called essentially self adjoint
if its closure is self-adjoint. So a reformulation of the preceding theorem in the
case of self-adjoint operators on a Hilbert space says
Theorem 11.8.3 Suppose that S and T are self-adjoint operators on a Hilbert
space H and suppose that S + T (deﬁned on D(S) ∩D(T)) is essentially self-
adjoint. Then for every y ∈H
exp(it((S + T))y = lim
n→∞

exp( t
niA)(exp t
niB)
n
y
(11.29)
where the convergence is uniform on any compact interval of t.

11.8. THE TROTTER PRODUCT FORMULA.
323
11.8.4
Commutators.
An operator A on a Hilbert space is called skew-symmetric if A∗= −A on D(A).
This is the same as saying that iA is symmetric. So we call an operator skew
adjoint if iA is self-adjoint. We call an operator A essentially skew adjoint
if iA is essentially self-adjoint.
If A and B are bounded skew adjoint operators then their Lie bracket
[A, B] := AB −BA
is well deﬁned and again skew adjoint.
In general, we can only deﬁne the Lie bracket on D(AB)∩D(BA) so we again
must make some rather stringent hypotheses in stating the following theorem.
Theorem 11.8.4 Let A and B be skew adjoint operators on a Hilbert space H
and let
D := D(A2) ∩D(B2) ∩D(AB) ∩D(BA).
Suppose that the restriction of [A, B] to D is essentially skew-adjoint. Then for
every y ∈H
exp t[A, B]y = lim
n→∞
 
(exp −
r
t
nA)(exp −
r
t
nB)(exp
r
t
nA)(exp
r
t
nB)
!n
y
(11.30)
uniformly in any compact interval of t ≥0.
Proof.
The restriction of [A, B] to D is assumed to be essentially skew-adjoint,
so [A, B] itself (which has the same closure) is also essentially skew adjoint.
We have
exp(tA)x = (I + tA + t2
2 A2)x + o(t2)
for x ∈D with similar formulas for exp(−tA) etc.
Let
f(t) := (exp −tA)(exp −tB)(exp tA)(exp tB).
Multiplying out f(t)x for x ∈D gives a whole lot of cancellations and yields
f(s)x = (I + s2[A, B])x + o(s2)
so (11.30) is a consequence of Chernoﬀ’s theorem with s =
√
t. QED
We still need to develop some methods which allow us to check the hypothe-
ses of the last three theorems.
11.8.5
The Kato-Rellich theorem.
This is the starting point of a class of theorems which asserts that that if A is
self-adjoint and if B is a symmetric operator which is “small” in comparison to
A then A + B is self adjoint.

324
CHAPTER 11. STONE’S THEOREM
Theorem 11.8.5 [Kato-Rellich.] Let A be a self-adjoint operator and B a
symmetric operator with
D(B) ⊃D(A)
and
∥Bx∥≤a∥Ax∥+ b∥x∥
0 ≤a < 1,
∀x ∈D(A).
Then A + B is self-adjoint, and is essentially self-adjoint on any core of A.
Proof.
[Following Reed and Simon II page 162.]
To prove that A + B is
self adjoint, it is enough to prove that im(A + B ± iµ0) = H. We do this for
A + B + iµ0. The proof for A + B −iµ0 is identical.
Let µ > 0. Since A is self-adjoint, we know that
∥(A + iµ)x∥2 = ∥Ax∥2 + µ2∥x∥2
from which we concluded that (A + iµ)−1 maps H onto D(A) and
∥(A + iµ)−1∥≤1
µ,
∥A(A + iµ)−1∥≤1.
Applying the hypothesis of the theorem to x = (A + iµ)−1y we conclude that
∥B(A + iµ)−1y∥≤a∥A((A + iµ)−1y∥+ b∥(A + iµ)−1y∥≤

a + b
µ

∥y∥.
Thus for µ >> 1, the operator
C := B(A + iµ)−1
satisﬁes
∥C∥< 1
since a < 1. Thus −1 ̸∈Spec(A) so im(I +C) = H. We know that im(A+µI) =
H hence
H = im(I + C) ◦(A + iµI) = im(A + B + iµI)
proving that A + B is self-adjoint.
If D is any core for A, it follows immediately from the inequality in the
hypothesis of the theorem that the closure of A + B restricted to D contains
D(A) in its domain. Thus A + B is essentially self-adjoint on any core of A.
QED
11.8.6
Feynman path integrals.
Consider the operator
H0 :
L2(R3) →L2(R3)
given by
H0 := −
 ∂2
∂x2
1
+ ∂2
∂x2
2
+ ∂2
∂x2
3

.

11.8. THE TROTTER PRODUCT FORMULA.
325
Here the domain of H0 is taken to be those φ ∈L2(R3) for which the diﬀerential
operator on the right, taken in the distributional sense, when applied to φ gives
an element of L2(R3).
The operator H0 is called the “free Hamiltonian of non-relativistic quantum
mechanics”. The Fourier transform F is a unitary isomorphism of L2(R3) into
L2(R3) and carries H0 into multiplication by ξ2 whose domain consists of those
ˆφ ∈L2(R3) such that ξ2 ˆφ(ξ) belongs to L2(R3). The operator consisting of
multiplication by e−itξ2 is clearly unitary, and provides us with a unitary one
parameter group. Transferring this one parameter group back to L2(R3) via
the Fourier transform gives us a one parameter group of unitary transformations
whose inﬁnitesimal generator is −iH0.
Now the Fourier transform carries multiplication into convolution, and the
inverse Fourier transform (in the distributional sense) of e−iξ2t is (2it)−3/2eix2/4t.
Hence we can write, in a formal sense,
(exp(−itH0)f)(x) = (4πit)−3/2
Z
R3 exp
i(x −y)2
4t

f(y)dy.
Here the right hand side is to be understood as a long winded way of writing
the left hand side which is well deﬁned as a mathematical object. The right
hand side can also be regarded as an actual integral for certain classes of f, and
as the L2 limit of such such integrals. We shall discuss this interpretation in
Section 11.10.
Let V be a function on R3. We denote the operator on L2(R3) consisting of
multiplication by V also by V . Suppose that V is such that H0 +V is again self-
adjoint. For example, if V were continuous and of compact support this would
certainly be the case by the Kato-Rellich theorem. (Realistic “potentials” V will
not be of compact support or be bounded, but nevertheless in many important
cases the Kato-Rellich theorem does apply.)
Then the Trotter product formula says that
exp −it(H0 + V ) = lim
n→∞

exp(−i t
nH0)(exp −i t
nV )
n
.
We have

(exp −i t
nV )f

(x) = e−i t
n V (x)f(x).
Hence we can write the expression under the limit sign in the Trotter prod-
uct formula, when applied to f and evaluated at x0 as the following formal
expression:
4πit
n
−3n/2 Z
R3 · · ·
Z
R3 exp(iSn(x0, . . . , xn))f(xn)dxn · · · dx1
where
Sn(x0, x1, . . . , xn, t) :=
n
X
i=1
t
n
"
1
4
(xi −xi−1)
t/n
2
−V (xi)
#
.

326
CHAPTER 11. STONE’S THEOREM
If X : s 7→X(s), 0 ≤s ≤t is a piecewise diﬀerentiable curve, then the
action of a particle of mass m moving along this curve is deﬁned in classical
mechanics as
S(X) :=
Z t
0
m
2
˙X(s)2 −V (X(s))

ds
where ˙X is the velocity (deﬁned at all but ﬁnitely many points).
Take m = 1
2 and let X be the polygonal path which goes from x0 to x1, from
x1 to x2 etc., each in time t/n so that the velocity is |xi −xi−1|/(t/n) on the
i-th segment. Also, the integral of V (X(s)) over this segment is approximately
t
nV (xi). The formal expression written above for the Trotter product formula
can be thought of as an integral over polygonal paths (with step length t/n) of
eiSn(X)f(X(t))dnX where Sn approximates the classical action and where dnX
is a measure on this space of polygonal paths.
This suggests that an intuitive way of thinking about the Trotter product
formula in this context is to imagine that there is some kind of “measure” dX
on the space Ωx0 of all continuous paths emanating from x0 and such that
exp(−it(H0 + V )f)(x) =
Z
Ωx0
eiS(X)f(X(t))dX.
This formula was suggested in 1942 by Feynman in his thesis (Trotter’s
paper was in 1959), and has been the basis of an enormous number of important
calculations in physics, many of which have given rise to exciting mathematical
theorems which were then proved by other means. I am unaware of any general
mathematical justiﬁcation of these “path integral” methods in the form that
they are used.
11.9
The Feynman-Kac formula.
An important advance was introduced by Mark Kac in 1951 where the unitary
group exp −it(H0+V ) is replaced by the contraction semi-group exp −t(H0+V ).
Then the techniques of probability theory (in particular the existence of Wiener
measure on the space of continuous paths) can be brought to bear to justify
a formula for the contractive semi-group as an integral over path space. I will
state and prove an elementary version of this formula which follows directly
from what we have done. The assumptions about the potential are physically
unrealistic, but I choose to regard the extension to a more realistic potential as
a technical issue rather than a conceptual one.
Let V be a continuous real valued function of compact support. To each
continuous path ω on Rn and for each ﬁxed time t ≥0 we can consider the
integral
Z t
0
V (ω(s))ds.
The map
ω 7→
Z t
0
V (ω(s))ds
(11.31)

11.9. THE FEYNMAN-KAC FORMULA.
327
is a continuous function on the space of continuous paths, and we have
t
m
m
X
j=1
V

ω
jt
m

→
Z t
0
V (ω(s))ds
(11.32)
for each ﬁxed ω.
Theorem 11.9.1 The Feynman-Kac formula. Let V be a continuous real
valued function of compact support on Rn. Let
H = ∆+ V
as an operator on H = L2(Rn). Then H is self-adjoint and for every f ∈H
 e−tHf

(x) =
Z
Ωx
f(ω(t)) exp
Z t
0
V (ω(s))ds

dxω
(11.33)
where Ωx is the space of continuous paths emanating from x and dxω is the
associated Wiener measure.
Proof. [From Reed-Simon II page 280.] Since multiplication by V is a bounded
self-adjoint operator, we can apply the Kato-Rellich theorem (with a = 0!) to
conclude that H is self-adjoint, and with the same domain as ∆. So we may
apply the Trotter product formula to conclude that
(e−Ht)f = lim
m→∞

e−t
m ∆e−t
m V m
f.
This convergence is in L2, but by passing to a subsequence we may also assume
that the convergence is almost everywhere. Now
h
e−t
m ∆e−t
m V m
f
i
(x)
=
Z
Rn · · ·
Z
Rn p

x, xm, t
m

· · · p

x, xm, t
m

f(x)1 exp

−
m
X
j=1
t
mV (xj)

dx1 · · · dxm.
By the very deﬁnition of Wiener measure, this last expression is
Z
Ωx
exp

t
m
m
X
j=1
V

ω
jt
m

f(ω(t))dxω.
The integrand (with respect to the Wiener measure dxω) converges on all con-
tinuous paths, that is to say almost everywhere with respect to dxµ to the
integrand on right hand side of (11.33). So to justify (11.33) we must prove
that the integral of the limit is the limit of the integral. We will do this by the
dominated convergence theorem:
Z
Ωx

exp

t
m
m
X
j=1
V

ω
jt
m

f(ω(t))

dxω

328
CHAPTER 11. STONE’S THEOREM
≤et max |V |
Z
Ωx
|f(ω(t))|dxω = et max |V |  e−t∆|f|

(x) < ∞
for almost all x. Hence, by the dominated convergence theorem, (11.33) holds
for almost all x. QED
11.10
The free Hamiltonian and the Yukawa po-
tential.
In this section I want to discuss the following circle of ideas.
Consider the
operator
H0 :
L2(R3) →L2(R3)
given by
H0 := −
 ∂2
∂x2
1
+ ∂2
∂x2
2
+ ∂2
∂x2
3

.
Here the domain of H0 is taken to be those φ ∈L2(R3) for which the diﬀerential
operator on the right, taken in the distributional sense, when applied to φ gives
an element of L2(R3).
The operator H0 has a fancy name. It is called the “free Hamiltonian of non-
relativistic quantum mechanics”. Strictly speaking we should add “for particles
of mass one-half in units where Planck’s constant is one”.
The Fourier transform is a unitary isomorphism of L2(R3) into L2(R3) and
carries H0 into multiplication by ξ2 whose domain consists of those ˆφ ∈L2(R3)
such that ξ2 ˆφ(ξ) belongs to L2(R3). The operators
V (t) : L2(R3) →L2(R3),
ˆφ(ξ) 7→e−itξ2 ˆφ
form a one parameter group of unitary transformations whose inﬁnitesimal gen-
erator in the sense of Stone’s theorem is operator consisting of multiplication by
ξ2 with domain as given above. [The minus sign before the i in the exponential
is the convention used in quantum mechanics. So we write exp −itA for the
one-parameter group associated to the self-adjoint operator A. I apologize for
this (rather irrelevant) notational change, but I want to make the notation in
this section consistent with what you will see in physics books.]
Thus the operator of multiplication by ξ2, and hence the operator H0 is a
self-adjoint transformation. The operator of multiplication by ξ2 is clearly non-
negative and so every point on the negative real axis belongs to its resolvent
set. Let us write a point on the negative real axis as −µ2 where µ > 0. Then
the resolvent of multiplication by ξ2 at such a point on the negative real axis is
given by multiplication by −f where
f(ξ) = fµ(ξ) :=
1
µ2 + ξ2 .
We can summarize what we “know” so far as follows:

11.10. THE FREE HAMILTONIAN AND THE YUKAWA POTENTIAL.329
1. The operator H0 is self adjoint.
2. The one parameter group of unitary transformations it generates via Stone’s
theorem is
U(t) = F−1V (t)F
where V (t) is multiplication by e−itξ2.
3. Any point −µ2,
µ > 0 lies in the resolvent set of H0 and
R(−µ2, H0) = −F−1mfF
where mf denotes the operation of multiplication by f and f is as given
above.
4. If g ∈S and mg denotes multiplication by g, then the the operator
F−1mgF consists of convolution by ˇg. Neither the function e−itξ2 nor
the function f belongs to S, so the operators U(t) and R(−µ2, H0) can
only be thought of as convolutions in the sense of generalized functions.
11.10.1
The Yukawa potential and the resolvent.
Nevertheless, we will be able to give some slightly more explicit (and very in-
structive) representations of these operators as convolutions. For example, we
will use the Cauchy residue calculus to compute ˇf and we will ﬁnd, up to factors
of powers of 2π that ˇf is the function
Yµ(x) := e−µr
r
where r denotes the distance from the origin, i.e.
r2 = x2.
This function
has an integrable singularity at the origin, and vanishes rapidly at inﬁnity. So
convolution by Yµ will be well deﬁned and given by the usual formula on elements
of S and extends to an operator on L2(R3).
The function Yµ is known as the Yukawa potential. Yukawa introduced
this function in 1934 to explain the forces that hold the nucleus together. The
exponential decay with distance contrasts with that of the ordinary electromag-
netic or gravitational potential 1/r and, in Yukawa’s theory, accounts for the
fact that the nuclear forces are short range. In fact, Yukawa introduced a “heavy
boson” to account for the nuclear forces. The role of mesons in nuclear physics
was predicted by brilliant theoretical speculation well before any experimental
discovery. Here are the details:
Since f ∈L2 we can compute its inverse Fourier transform as
(2π)−3/2 ˇf = lim
R→∞(2π)−3
Z
|ξ|≤R
eiξ·x
µ2 + ξ2 dξ.
(11.34)

330
CHAPTER 11. STONE’S THEOREM
0
−R
R
R + i
√
R
−R + i
√
R
-
6

?
Here lim means the L2 limit and |ξ| denotes the length of the vector ξ, i.e.
|ξ| =
p
ξ2 and we will use similar notation |x| = r for the length of x. Assume
x ̸= 0. Let
u := ξ · x
|ξ||x|
so u is the cosine of the angle between x and ξ. Fix x and introduce spherical
coordinates in ξ space with x at the north pole and s = |ξ| so that
(2π)−3
Z
|ξ|≤R
eiξ·x
µ2 + ξ2 dξ = (2π)−2
Z R
0
Z 1
−1
eis|x|u
s2 + µ2 s2duds
=
1
(2π)2i|x|
Z R
−R
seis|x|
(s + iµ)(s −iµ)ds.
This last integral is along the bottom of the path in the complex s-plane con-
sisting of the boundary of the rectangle as drawn in the ﬁgure.
On the two vertical sides of the rectangle, the integrand is bounded by some
constant time 1/R, so the contribution of the vertical sides is O(1/
√
R). On the
top the integrand is O(e−
√
R). So the limits of these integrals are zero. There
is only one pole in the upper half plane at s = iµ, so the integral is given by
2πi× this residue which equals
2πiiµe−µ|x|
2iµ
= πie−µ|x|.
Inserting this back into (11.34) we see that the limit exists and is equal to
(2π)−3/2 ˆf = 1
4π
e−µ|x|
|x|
.
We conclude that for φ ∈S
[(H0 + µ2)−1φ](x) = 1
4π
Z
R3
e−µ|x−y|
|x −y| φ(y)dy,
and since (H0 + µ2)−1 is a bounded operator on L2 this formula extends in the
L2 sense to L2.

11.10. THE FREE HAMILTONIAN AND THE YUKAWA POTENTIAL.331
11.10.2
The time evolution of the free Hamiltonian.
The “explicit” calculation of the operator U(t) is slightly more tricky.
The
function ξ 7→e−itξ2 is an “imaginary Gaussian”, so we expect is inverse Fourier
transform to also be an imaginary Gaussian, and then we would have to make
sense of convolution by a function which has absolute value one at all points.
There are several ways to proceed. One involves integration by parts, and I
hope to explain how this works later on in the course in conjunction with the
method of stationary phase.
Here I will follow Reed-Simon vol II p.59 and add a little positive term to
t and then pass to the limit. In other words, let α be a complex number with
positive real part and consider the function
ξ 7→e−ξ2α
This function belongs to S and its inverse Fourier transform is given by the
function
x 7→(2α)−3/2e−x2/4α.
(In fact, we veriﬁed this when α is real, but the integral deﬁning the inverse
Fourier transform converges in the entire half plane Re α > 0 uniformly in any
Re α > ϵ and so is holomorphic in the right half plane. So the formula for real
positive α implies the formula for α in the half plane.)
We thus have
(e−H0αφ)(x) =
 1
4πα
3/2 Z
R3 e−|x−y|2/4αφ(y)dy.
Here the square root in the coeﬃcient in front of the integral is obtained by
continuation from the positive square root on the positive axis. For example, if
we take α = ϵ + it so that −α = −i(t −iϵ) we get
(U(t)φ)(x) = lim
ϵ↘0(U(t−iϵ)φ)(x) = lim
ϵ↘0(4πi(t−iϵ))−3
2
Z
e−|x−y|2/4i(t−iϵ)φ(y)dy.
Here the limit is in the sense of L2. We thus could write
(U(t))(φ)(x) = (4πi)−3/2
Z
ei|x−y|2/4tφ(y)dy
if we understand the right hand side to mean the ϵ ↘0 limit of the preceding
expression.
Actually, as Reed and Simon point out, if φ ∈L1 the above integral exists
for any t ̸= 0, so if φ ∈L1 ∩L2 we should expect that the above integral is
indeed the expression for U(t)φ. Here is their argument: We know that
exp(−i(t −iϵ))φ →U(t)φ
in the sense of L2 convergence as ϵ ↘0. Here we use a theorem from measure
theory which says that if you have an L2 convergent sequence you can choose

332
CHAPTER 11. STONE’S THEOREM
a subsequence which also converges pointwise almost everywhere. So choose a
subsequence of ϵ for which this happens. But then the dominated convergence
theorem kicks in to guarantee that the integral of the limit is the limit of the
integrals.
To sum up: The function
P0(x, y; t) := (4πit)−3/2ei|x−y|/4t
is called the free propagator. For φ ∈L1 ∩L2
[U(t)φ](x) =
Z
R3 P0(x, y; t)φ(y)dy
and the integral converges. For general elements ψ of L2 the operator U(t)ψ
is obtained by taking the L2 limit of the above expression for any sequence
of elements of L1 ∩L2 which approximate ψ in L2. Alternatively, we could
interpret the above integral as the ϵ ↘limit of the corresponding expression
with t replaced by t −iϵ.

Chapter 12
More about the spectral
theorem
In this chapter we present more applications of the spectral theorem and Stone’s
theorem, mainly to problems arising from quantum mechanics.
Most of the
material is taken from the book Spectral theory and diﬀerential operators by
Davies and the four volume Methods of Modern Mathematical Physics by Reed
and Simon. The material in the ﬁrst section is take from the two papers: W.O.
Amrein and V. Georgescu, Helvetica Physica Acta 46 (1973) pp. 636 - 658. and
W. Hunziker and I. SigalJ. Math. Phys.41(2000) pp. 3448-3510.
12.1
Bound states and scattering states.
It is a truism in atomic physics or quantum chemistry courses that the eigen-
states of the Schr¨odinger operator for atomic electrons are the bound states,
the ones that remain bound to the nucleus, and that the “scattering states”
which ﬂy oﬀin large positive or negative times correspond to the continuous
spectrum. The purpose of this section is to give a mathematical justiﬁcation
for this truism. The key result is due to Ruelle, (1969), using ergodic theory
methods. The more streamlined version presented here comes from the two pa-
pers mentioned above. The ergodic theory used is limited to the mean ergodic
theorem of von-Neumann which has a very slick proof due to F. Riesz (1939)
which I shall give.
12.1.1
Schwartzschild’s theorem.
There is a classical precursor to Ruelle’s theorem which is due to Schwartzschild
(1896). This is the same Schwartzschild who, some twenty years later, gave the
famous Schwartzschild solution to the Einstein ﬁeld equations. Schwartzschild’s
theorem says, roughly speaking, that in a mechanical system like the solar sys-
tem, the trajectories which are “captured”, i. e. which come in from inﬁnity at
333

334
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
negative time but which remain in a ﬁnite region for all future time constitute
a set of measure zero. Schwartzschild derived his theorem from the Poincar´e
recurrence theorem. I learned these two theorems from a course on celestial
mechanics by Carl Ludwig Siegel that I attended in 1953. These theorems ap-
pear in the last few pages of Siegel’s famous Vorlesungen ¨uber Himmelsmechanik
which developped out of this course. For proofs I refer to the treatment given
there.
The Poincar´e recurrence theorem.
This says the following:
Theorem 12.1.1 [The Poincar´e recurrence theorem.] Let St be a measure
preserving ﬂow on a measure space (M, µ). Let A be a subset of M contained
in an invariant set of ﬁnite measure. Then outside of a subset of A of measure
zero, every point p of A has the property that Stp ∈A for inﬁnitely many times
in the future.
The idea is quite simple. If this were not the case, there would be an inﬁnite
sequence of disjoint sets of positive measure all contained in a ﬁxed set of ﬁnite
measure.
Schwartzschild’s theorem.
Consider the same set up as in the Poincar´e recurrence theorem, but now let
M be a metric space with µ a regular measure, and assume that the St are
homeomorphisms. Let A be an open set of ﬁnite measure, and let B consist of
all p such that Stp ∈A for all t ≥0. Let C consist of all p such that tp ∈A for
all t ∈R. Clearly C ⊂B.
Theorem 12.1.2 [Schwartzchild’s theorem.] The measure of B \C is zero.
Again, the proof is straightforward and I refer to Siegel for details. Phrased
in more intuitive language, Schwartzschild’s theorem says that outside of a set
of measure zero, any point p ∈A which has the property that Stp ∈A for all
t ≥0 also has the property that Stp ∈A for all t < 0. The “capture orbits’
have measure zero.
Of course, the catch in the theorem is that one needs to prove that B has
positive measure for the theorem to have any content.
Siegel calls the set B the set of points which are weakly stable for the future
(with respect to A ) and C the set of points which are weakly stable for all time.
Application to the solar system?
Suppose one has a mechanical system with kinetic energy T and potential energy
V .

12.1. BOUND STATES AND SCATTERING STATES.
335
If the potential energy is bounded from below, then we can ﬁnd a bound for
the kinetic energy in terms of the total energy:
T ≤aH + b
which is the classical analogue of the key operator bound in quantum version,
see equation (12.7) below. A region of the form
∥x∥≤R,
H(x, p) ≤E
then forms a bounded region of ﬁnite measure in phase space. Liouville’s theo-
rem asserts that the ﬂow on phase space is volume preserving. So Schwartzschild’s
theorem applies to this region.
I quote Siegel as to the possible application to the solar system:
Under the unproved assumption that the planetary system is weakly
stable with respect to all time, we can draw the following conclusion:
If the planetary system captures a particle coming in from inﬁnity,
say some external matter, then the new system with this additional
particle is no longer weakly stable with respect to just future time,
and it follows that the particle - or a planet or the sun- must again
be expelled, or a collision must take place. For an interpretation of
the signiﬁcance of this result, one must, however, consider that we
do not even know whether for n > 2 the solutions of the n-body
problem that are weakly stable with respect to all time form a set
of positive measure.
12.1.2
The mean ergodic theorem
We will need the continuous time version: Let H be a self-adjoint operator on
a Hilbert space H and let
Vt = exp(−itH)
be the one parameter group it generates (by Stone’s theorem). von Neumann’s
mean ergodic theorem asserts that for any f ∈H the limit
lim
T →∞
1
T
Z T
0
Vtfdt
exists, and the limit is an eigenvector of H corresponding to the eigenvalue 0.
Clearly, if Hf = 0, then Vtf = f for all t and the above limit exists trivially
and is equal to f. If f is orthogonal to the image of H, i.e. if
Hg = 0 ∀g ∈Dom(H)
then f ∈Dom(H∗) = Dom(H) and H∗f = Hf = 0. So if we decompose H into
the zero eigenspace of H and its orthogonal complement, we are reduced to the
following version of the theorem which is the one we will actually use:

336
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
Theorem 12.1.3 Let H be a self-adjoint operator on a Hilbert space H, and
assume that H has no eigenvectors with eigenvalue 0, so that the image of H is
dense in H. Let Vt = exp(−itH) be the one parameter group generated by H.
Then
lim
T →∞
1
T
Z T
0
Vtfdt = 0
for all f ∈H.
Proof.
If h = −iHg then
Vth = d
dtVtg
so
1
T
Z T
0
Vthdt = 1
T (Vtg −g) →0.
By hypothesis, for any f ∈H we can, for any ϵ > 0 , ﬁnd an h of the above
form such that ∥f −h∥< 1
2ϵ so

1
T
Z T
0
Vtfdt
 ≤1
2ϵ +

1
T
Z T
0
Vthdt
 .
By then choosing T suﬃciently large we can make the second term less than
1
2ϵ.
□
12.1.3
General considerations.
Let H be a self-adjoint operator on a separable Hilbert space H and let Vt be
the one parameter group generated by H so
Vt := exp(−iHt).
Let
H = Hp ⊕Hc
be the decomposition of H into the subspaces corresponding to pure point spec-
trum and continuous spectrum of H.
Let {Fr}, r = 1, 2, . . . be a sequence of self-adjoint projections. (In the
application we have in mind we will let H = L2(Rn) and take Fr to be the
projection onto the completion of the space of continuous functions supported
in the ball of radius r centered at the origin, but in this section our considerations
will be quite general.) We let F ′
r be the projection onto the subspace orthogonal
to the image of Fr so
F ′
r := I −Fr.
Let
M0 := {f ∈H| lim
r→∞sup
t∈R
∥(I −Fr)Vtf∥2 = 0},
(12.1)

12.1. BOUND STATES AND SCATTERING STATES.
337
and
M∞:=
(
f ∈H
 lim
T →∞
1
T
Z T
0
∥FrVtf∥2dt = 0, for all r = 1, 2, . . .
)
.
(12.2)
Proposition 12.1.1 The following hold:
1. M0 and M∞are linear subspaces of H.
2. The subspaces M0 and M∞are closed.
3. M0 is orthogonal to M∞.
4. Hp ⊂M0.
5. M∞⊂Hc.
The following inequality will be used repeatedly: For any f, g ∈H
∥f + g∥2 ≤∥f + g∥2 + ∥f −g∥2 = 2∥f∥2 + 2∥g∥2
(12.3)
where the last equality is the theorem of Appolonius.
Proof of 1. Let f1, f2 ∈M0. Then for any scalars a and b and any ﬁxed r and
t we have
∥(I −Fr)Vt(af1 + bf2)∥2 ≤2|a|2∥((I −Fr)Vtf1∥2 + 2|b|2∥(I −Fr)Vtf2∥2
by (12.3). Taking separate sups over t on the right side and then over t on the
left shows that
sup
t ∥(I −Fr)Vt(af1 + bf2)∥2
≤2|a|2 sup
t ∥((I −Fr)Vtf1∥2 + 2|b|2 sup
t ∥((I −Fr)Vtf2∥2
for ﬁxed r. Letting r →∞then shows that af1 + bf2 ∈M0.
Let f1, f2 ∈M∞. For ﬁxed r we use (12.3) to conclude that
1
T
Z T
0
∥FrVt(af1 + bf2)∥2dt
≤2|a|2
T
Z T
0
∥FrVtf1∥2dt + 2|b|2
T
Z T
0
∥FrVtf2∥2dt.
Each term on the right converges to 0 as T →∞proving that af1 +bf2 ∈M∞.
This proves 1).
Proof of 2. Let fn ∈M0 and suppose that fn →f. Given ϵ > 0 choose N so
that ∥fn −f∥2 < 1
4ϵ for all n > N. This implies that
∥(I −Fr)Vt(f −fn)∥2 < 1
4ϵ

338
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
for all t and n since Vt is unitary and I −Fr is a contraction. Then
sup
t ∥(I −Fr)Vtf∥2 ≤1
2ϵ + 2 sup
t ∥(I −Fr)Vtfn∥2
for all n > N and any ﬁxed r. We may choose r suﬃciently large so that the
second term on the right is also less that 1
2ϵ. This proves that f ∈M0.
Let fn ∈M∞and suppose that fn →f. Given ϵ > 0 choose N so that
∥fn −f∥2 < 1
4ϵ for all n > N. Then
1
T
Z T
0
∥FrVrf∥2dt ≤2
T
Z T
0
∥FrVr(f −fn)∥2dt
+ 2
T
Z T
0
∥FrVrfn∥2dt
≤1
2ϵ + 2
T
Z T
0
∥FrVrfn∥2dt.
Fix n. For any given r we can choose T0 large enough so that the second term
on the right is < 1
2ϵ. This shows that for any ﬁxed r we can ﬁnd a T0 so that
1
T
Z T
0
∥FrVrf∥2dt < ϵ
for all T > T0, proving that f ∈M∞. This proves 2).
Proof of 3.
Let f ∈M0 and g ∈M∞both ̸= 0. Then
|(f, g)|2
=
1
T
Z T
0
|(f, g)|2dt
=
1
T
Z T
0
|(Vtf, Vtg|2dt
=
1
T
Z T
0
|(F ′
rVtf, g) + (Vtf, Frg)|2dt
≤
2
T
Z T
0
|(F ′
rVtf, Vtg)|2dt + 2
T
Z T
0
|(Vtf, Frg)|2dt
≤
2
T ∥g∥2
Z
|F ′
rVtf∥2dt + 2
T ∥f∥2
Z T
0
∥FrVtg∥2dt
where we used the Cauchy-Schwarz inequality in the last step.
For any ϵ > 0 we may choose r so that
∥F ′
rVtf∥2 ≤
ϵ
4∥g∥2
for all t. We can choose a T such that
1
T
Z T
0
∥FrVtg∥2dt <
ϵ
4∥f∥2 .

12.1. BOUND STATES AND SCATTERING STATES.
339
Plugging back into the last inequality shows that
|(f, g)|2 < ϵ.
Since this is true for any ϵ > 0 we conclude that f ⊥g. This proves 3.
Proof of 4. Suppose Hf = Ef. Then
∥F ′
rVtf∥2 = ∥F ′
r(e−iEtf)∥2 = ∥e−iEtF ′
rf∥2 = ∥F ′
rf∥2.
But we are assuming that F ′
r →0 in the strong topology. So this last expression
tends to 0 proving that f ∈M0 which is the assertion of 4).
Proof of 5. By 3) we have M∞⊂M⊥
0 . By 4) we have M⊥
0 ⊂H⊥
p = Hc.
□
Proposition 12.1.1 is valid without any assumptions whatsoever relating H
to the Fr. The only place where we used H was in the proof of 4) where we
used the fact that if f is an eigenvector of H then it is also an eigenvector of of
Vt and so we could pull out a scalar.
The goal is to impose suﬃcient relations between H and the Fr so that
Hc ⊂M∞.
(12.4)
If we prove this then part 5) of Proposition 12.1.1 implies that
Hc = M∞
and then part 3) says that
M0 ⊂M⊥
∞= H⊥
c = Hp.
Then part 4) gives
M0 = Hp.
As a preliminary we state a consequence of the mean ergodic theorem:
12.1.4
Using the mean ergodic theorem.
Recall that the mean ergodic theorem says that if Ut is a unitary one parameter
group acting without (non-zero) ﬁxed vectors on a Hilbert space G then
lim
T →∞
1
T
Z T
0
Utψdt = 0
for all ψ ∈G. Let
G = Hc ˆ⊗Hc.
We know from our discussion of the spectral theorem (Proposition 10.12.1)
that H ⊗I −I ⊗H does not have zero as an eigenvalue acting on G. We may
apply the mean ergodic theorem to conclude that
lim
T →∞
1
T
Z T
0
e−itHf ⊗eitHedt = 0

340
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
for any e, f ∈Hc. We have
|(e, e−itHf)|2 = (e ⊗f, e−itHf ⊗eitHe).
We conclude that
lim
T →∞
1
T
Z T
0
|(e, Vtf)|2dt = 0
∀e ∈H,
f ∈Hc.
(12.5)
Indeed, if e ∈Hc this follows from the above, while if e ∈Hp the integrand is
identically zero.
12.1.5
The Amrein-Georgescu theorem.
We continue with the previous notation, and let Ec : H →Hc denote orthogonal
projection.
We let Sn and S be a collection of bounded operators on H such that
• [Sn, H] = 0,
• Sn →S in the strong topology,
• The range of S is dense in H, and
• FrSnEc is compact for all r and n.
Theorem 12.1.4 [Armein-Georgescu.] Under the above hypotheses (12.4)
holds.
Proof. Since M∞is a closed subspace of H, to prove that (12.4) holds, it is
enough to prove that
D ⊂M∞
for some set D which is dense in Hc. Since S leaves the spaces Hp and Hc
invariant, the fact that the range of S is dense in H by hypothesis, says that
SHc is dense in Hc. So we have to show that
g = Sf,
f ∈Hc ⇒
lim
T →∞
1
T
Z T
0
∥FrVtg∥2dt = 0
for any ﬁxed r. We may assume f ̸= 0.
Let ϵ > 0 be ﬁxed. Choose n so large that
∥(S −Sn)f∥2 < ϵ
6.
Any compact operator in a separable Hilbert space is the norm limit of ﬁnite
rank operators. So we can ﬁnd a ﬁnite rank operator TN such that
∥FrSnEc −TN∥2 <
ϵ
12∥f∥2 .

12.1. BOUND STATES AND SCATTERING STATES.
341
Writing g = (S −Sn)f + Snf we conclude that
1
T
Z T
0
∥FrVtg∥2dt
≤
2
T
Z T
0
∥FrVt(S −Sn)f∥2dt + 2
T
Z T
0
∥FrVtSnf∥2dt
≤
ϵ
3 + 4
T
Z T
0
∥FrSnEc −TN∥2∥Vtf∥2dt + 4
T
Z T
0
∥TNVt∥2dt
≤
2
3ϵ + 4
T
Z T
0
∥TNVt∥2dt.
To say that TN is of ﬁnite rank means that there are gi, hi ∈H, i = 1, . . . N < ∞
such that
TNf =
N
X
i=1
(f, hi)gi.
Substituting this into 4
T
R T
0 ∥TNVt∥2dt. gives
4
T
Z T
0
∥TNVt∥2dt = 4
T
Z T
0

N
X
i=0
(Vtf, hi)gi

2
dt
≤2N−1 · 4 ·
X
∥gi∥2 1
T
Z T
0
|(hi, Vtf)|2dt.
By (12.5) we can choose T0 so large that this expression is < ϵ
3 for all T > T0.
□
Of course a special case of the theorem will be where all the Sn = S as will
be the case for Ruelle’s theorem for Kato potentials.
12.1.6
Kato potentials.
Let X = Rn for some n. A locally L2 real valued function on X is called a
Kato potential if for any α > 0 there is a β = β(α) such that
∥V ψ∥≤α∥∆ψ∥+ β∥ψ∥
(12.6)
for all ψ ∈C∞
0 (X).
Clearly the set of all Kato potentials on X form a real vector space.
Examples of Kato potentials.
V ∈L2(R3).
For example, suppose that X = R3 and V ∈L2(X). We claim that V is a Kato
potential. Indeed,
∥V ψ∥:= ∥V ψ∥2 ≤∥V ∥2∥ψ∥∞.
So we will be done if we show that for any a > 0 there is a b > 0 such that
∥ψ∥∞≤a∥∆ψ∥2 + b∥ψ∥2.

342
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
By the Fourier inversion formula we have
∥ψ∥∞≤∥ˆψ∥1
where ˆψ denotes the Fourier transform of ψ. Now the Fourier transform of ∆ψ
is the function
ξ 7→∥ξ∥2 ˆψ(ξ)
where ∥ξ∥denotes the Euclidean norm of ξ. Since ˆψ belongs to the Schwartz
space S, the function
ξ 7→(1 + ∥ξ∥2) ˆψ(ξ)
belongs to L2 as does the function
ξ 7→(1 + ∥ξ∥2)−1
in three dimensions. Let λ denote the function
ξ 7→∥ξ∥.
By the Cauchy-Schwarz inequality we have
∥ˆψ∥1 = |((1 + λ2)−1, (1 + λ2) ˆψ)|
≤c∥(λ2 + 1) ˆψ∥≤c∥λ2 ˆψ∥2 + c∥ˆψ∥2
where
c2 = ∥(1 + λ2)−1∥2.
For any r > 0 and any function φ ∈S let φr be deﬁned by
ˆφr(ξ) = r3 ˆφ(rξ).
Then
∥ˆφr∥1 = ∥ˆφ∥1,
∥ˆφr∥2 = r
3
2 ∥ˆφ∥2,
and ∥λ2 ˆφr∥2 = r−1
2 ∥λ2φ∥2.
Applied to ψ this gives
∥ˆψ∥1 ≤cr−1
2 ∥λ2 ˆψ∥2 + cr
3
2 ∥ˆψ∥2.
By Plancherel
∥λ2 ˆψ∥2 = ∥∆ψ∥2
and
∥ˆψ∥2 = ∥ψ∥2.
This shows that any V ∈L2(R3) is a Kato potential.
V ∈L∞(X).
Indeed
∥V ψ∥2 ≤∥V ∥∞∥ψ∥2.
If we put these two examples together we see that if V = V1 + V2 where
V1 ∈L2(R3) and V2 ∈L∞(R3) then V is a Kato potential.

12.1. BOUND STATES AND SCATTERING STATES.
343
The Coulomb potential.
The function
V (x) =
1
∥x∥
on R3 can be written as a sum V = V1+V2 where V1 ∈L2(R3) and V2 ∈L∞(R3)
and so is Kato potential.
Kato potentials from subspaces.
Suppose that X = X1 ⊕X2 and V depends only on the X1 component where it
is a Kato potential. Then Fubini implies that V is a Kato potential if and only
if V is a Kato potential on X1.
So if X = R3N and we write x ∈X as x = (x1, . . . , xN) where xi ∈R3 then
Vij =
1
∥xi −xj∥
are Kato potentials as are any linear combination of them. So the total Coulomb
potential of any system of charged particles is a Kato potential.
By example 12.1.6, the restriction of this potential to the subspace {x| P mixi =
0} is a Kato potential. This is the “atomic potential” about the center of mass.
12.1.7
Applying the Kato-Rellich method.
Theorem 12.1.5 Let V be a Kato potential. Then
H = ∆+ V
is self-adjoint with domain D = Dom(∆) and is bounded from below. Further-
more, we have an operator bound
∆≤aH + b
(12.7)
where
a =
1
1 −α
and b = β(α)
1 −α,
0 < α < 1.
Proof.
As a multiplication operator, V is closed on its domain of deﬁnition
consisting of all ψ ∈L2 such that V ψ ∈L2. Since C∞
0 (X) is a core for ∆, we
can apply the Kato condition (12.6) to all ψ ∈Dom(∆). Thus H is deﬁned
as a symmetric operator on Dom(∆). For Re z < 0 the operator (z −∆)−1 is
bounded. So for Re z < 0 we can write
zI −H = [I −V (zI −∆)−1](zI −∆).
By the Kato condition (12.6) we have
∥V (zI −∆)−1∥≤α + β|Rez|−1.

344
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
If we choose α < 1 and then Re z suﬃciently negative, we can make the right
hand side of this inequality < 1. For this range of z we see that R(z, H) =
(zI −H)−1 is bounded so the range of zI −H is all of L2. This proves that H
is self-adjoint and that its resolvent set contains a half plane Re z << 0 and so
is bounded from below. Also, for ψ ∈Dom(∆) we have
∆ψ = Hψ −V ψ
so
∥∆ψ∥≤∥Hψ∥+ ∥V ψ∥≤∥Hψ∥+ α∥∆ψ∥+ β∥ψ∥
which proves (12.7).
□
12.1.8
Using the inequality (12.7).
Proposition 12.1.2 Let H be a self-adjoint operator on L2(X) satisfying (12.7)
for some constants a and b. Let f ∈L∞(X) be such that f(x) →0 as x →∞.
Then for any z in the resolvent set of H the operator
fR(z, H)
is compact, where, as usual, f denotes the operator of multiplication by f,
Proof.
Let pj = 1
i
∂
∂xj as usual, and let g ∈L∞(X∗) so the operator g(p) is
deﬁned as the operator which send ψ into the function whose Fourier transform
is ξ 7→g(ξ) ˆψ(ξ). The operator f(x)g(p) is the norm limit of the operators fngn
where fn is obtained from f by setting fn = 1Bnf where Bn is the ball of radius
1 about the origin, and similarly for g. The operator fn(x)gn(p) is given by the
square integrable kernel
Kn(x, y) = fn(x)ˆgn(x −y)
and so is compact. Hence f(x)g(p) is compact. We will take
g(p) =
1
1 + p2 = (1 + ∆)−1.
The operator (1 + ∆)R(z, H) is bounded. Indeed, by (12.7)
∥(1 + ∆)(zI −H)−1ψ∥≤(1 + a)∥H(zI −H)−1ψ∥+ b∥(R(z, H)ψ)∥
≤∥(1 + a)ψ∥+ (a|z| + b)∥R(z, H)ψ∥.
So
f(x)R(z, H) = f(x)
1
1 + p2 · (1 + ∆)R(z, H)
is compact, being the product of a compact operator and a bounded operator.

12.2. NON-NEGATIVE OPERATORS AND QUADRATIC FORMS.
345
12.1.9
Ruelle’s theorem.
Let us take H = ∆+ V where V is a Kato potential. Let Fr be the operator of
multiplication by 1Br so Fr is projection onto the space of functions supported
in the ball Br of radius r centered at the origin. Take S = R(z, H), where z
has suﬃciently negative real part. Then FrSEc is compact, being the product
of the operator FrR(z, H) (which is compact by Proposition 12.1.2) and the
bounded operator Ec. Also the image of S is all of H. So we may apply the
Amrein Georgescu theorem to conclude that M0 = Hp and M∞= Hc.
12.2
Non-negative operators and quadratic forms.
12.2.1
Fractional powers of a non-negative self-adjoint op-
erator.
Let H be a self-adjoint operator on a separable Hilbert space H with spectrum
S. The spectral theorem tells us that there is a ﬁnite measure µ on S × N and
a unitary isomorphism
U : H →L2 = L2(S × N, µ)
such that UHU −1 is multiplication by the function h(s, n) = s and such that
ξ ∈H lies in Dom(H) if and only if h · (Uξ) ∈L2.
Clearly
(Hξ, ξ) ≥0
for all ξ ∈H if and only if µ assigns measure zero to the set {(s, n), s < 0}
in which case the spectrum of multiplication by h, which is the same as saying
that the spectrum of H is contained in [0, ∞). When this happens, we say that
H is non-negative.
We say that H ≥c if H −cI is non-negative.
If H is non-negative, and λ > 0, we would like to deﬁne Hλ as being unitarily
equivalent to multiplication by hλ. As the spectral theorem does not say that
the µ, L2, and U are unique, so we have to check that this is well deﬁned.
For this consider the function f on R deﬁned by
f(x) =
1
|x|λ + 1.
By the functional calculus, f(H) is well deﬁned, and in any spectral representa-
tion goes over into multiplication by f(h) which is injective. So K = f(H)−1−I
is a well deﬁned (in general unbounded) self-adjoint operator whose spectral rep-
resentation is multiplication by hλ. But the expression for K is independent of
the spectral representation. This shows that Hλ = K is well deﬁned.
Proposition 12.2.1 Let H be a self-adjoint operator on a Hilbert space H and
let Dom(H) be the domain of H. Let 0 < λ < 1. Then f ∈Dom(H) if and only
if f ∈Dom(Hλ) and Hλf ∈Dom(H1−λ) in which case
Hf = H1−λHλf.

346
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
In particular, if λ = 1
2, and we deﬁne BH(f, g) for f, g ∈Dom(H
1
2 ) by
BH(f, g) := (H
1
2 f, H
1
2 g),
then f ∈Dom(H) if and only if f ∈Dom(H
1
2 ) and also there exists a k ∈H
such that
BH(f, g) = (k, g)
∀g ∈Dom(H
1
2 )
in which case
Hf = k.
Proof.
For the ﬁrst part of the Proposition we may use the spectral represen-
tation: The Proposition then asserts that f ∈L2 satisﬁes
R
|h|2|f|2dµ < ∞if
and only if
Z
(1 + |h|2λ)|f|2dµ < ∞and
Z
(1 + |h|2(1−λ))|hλf|2dµ < ∞
which is obvious, as is the assertion that then hf = h1−λ(hλf).
The assertion that there exists a k such that BH(f, g) = (k, g)
∀g ∈
Dom(H
1
2 ) is the same as saying that H
1
2 f ∈Dom((H
1
2 )∗) and (H
1
2 )∗H
1
2 f = k.
But H
1
2 = (H
1
2 )∗so the second part of the proposition follows from the ﬁrst. □
12.2.2
Quadratic forms.
The second half of Proposition 12.2.1 suggests that we study non-negative
sesquilinear forms deﬁned on some dense subspace D of a Hilbert space H.
So we want to study
B : D × D →C
such that
• B(f, g) is linear in f for ﬁxed g,
• B(g, f) = B(f, g), and
• B(f, f) ≥0.
Of course, by the usual polarization trick such a B is determined by the corre-
sponding quadratic form
Q(f) := B(f, f).
We would like to ﬁnd conditions on B (or Q) which guarantee that B = BH for
some non-negative self adjoint operator H as given by Proposition 12.2.1.
That some condition is necessary is exhibited by the following

12.2. NON-NEGATIVE OPERATORS AND QUADRATIC FORMS.
347
counterexample.
Let H = L2(R) and let D consist of all continuous functions of compact support.
Let
B(f, g) = f(0)g(0).
The only candidate for an operator H which satisﬁes B(f, g) = (Hf, g) is the
“operator” which consists of multiplication by the delta function at the origin.
But there is no such operator.
Consider a sequence of uniformly bounded continuous functions fn of com-
pact support which are all identically one in some neighborhood of the ori-
gin and whose support shrinks to the origin.
Then fn →0 in the norm
of H.
Also, Q(fn −fm, fn −fm) ≡0, so Q(fn −fm, fn −fm) →0.
But
Q(fn, fn) ≡1 ̸= 0 = Q(0, 0). So D is not complete for the norm ∥· ∥1
∥f∥1 := (Q(f) + ∥f∥2
H)
1
2 .
Consider a function g ∈D which equals one on the interval [−1, 1] so that
(g, g) = 1. Let gn := g −fn with fn as above. Then gn →g in H yet Q(gn) ≡0.
So Q is not lower semi-continuous as a function on D.
We recall the deﬁnition of lower semi-continuity:
12.2.3
Lower semi-continuous functions.
Let X be a topological space, and let Q : X →R be a real valued function. Let
x0 ∈X. We say that Q is lower semi-continuous at x0 if, for every ϵ > 0
there is a neighborhood U = U(x0, ϵ) of x0 such that
Q(x) < Q(x0) + ϵ
∀x ∈U.
We say that Q is lower semi-continuous if it is lower semi-continuous at all
points of X.
Proposition 12.2.2 Let {Qα}α∈I be a family of lower semi-continuous func-
tions. Then
Q := sup
α Qα
is lower semi-continuous.
In particular, the pointwise limit of an increasing
sequence of lower-semicontinuous functions is lower semi-continuous.
Proof.
Let x0 ∈X and ϵ > 0. There exists an index α such that Qα(x0) >
Q(x0) −1
2ϵ.
Then there exists a neighborhood U of x0 such that Qα(x) >
Qα(x0) −1
2ϵ for all x ∈U and hence
Q(x) ≥Qα(x) > Q(x0) −ϵ ∀x ∈U.
□
It is easy to check that the sum and the inf of two lower semi-continuous func-
tions is lower semi-continuous.

348
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
12.2.4
The main theorem about quadratic forms.
Let H be a separable Hilbert space and Q a non-negative quadratic form deﬁned
on a dense domain D ⊂H. We may extend the domain of deﬁnition of Q by
setting it equal to +∞at all points of H \ D. Then we can say that the domain
of Q consists of those f such that Q(f) < ∞. This will be a little convenient in
the formulation of the next theorem.
Theorem 12.2.1 The following conditions on Q are equivalent:
1. There is a non-negative self-adjoint operator H on H such that D =
Dom(H
1
2 ) and
Q(f) = ∥H
1
2 f∥2.
2. Q is lower semi-continuous as a function on H.
3. D = Dom(Q) is complete relative to the norm
∥f∥1 :=
 ∥f∥2 + Q(f)
 1
2 .
Proof.
1. implies 2. As H is non-negative, the operators nI + H are invertible with
bounded inverse, and (nI + H)−1 maps H onto the domain of H. Consider the
quadratic forms
Qn(f) :=
 nH(nI + H)−1f, f

=
 H(I + n−1H)−1f, f

which are bounded and continuous on all of H. In the spectral representation
of H, the space H is unitarily equivalent to L2(S, µ) where S = Spec(H) × N
and H goes over into multiplication by the function h where
h(s, k) = s.
The quadratic forms Qn thus go over into the quadratic forms ˜Qn where
˜Qn(g) =
Z
nh
n + hg · gdµ
for any g ∈L2(S, µ). The functions
nh
n + h
form an increasing sequence of functions on S, and hence the functions Qn form
an increasing sequence of continuous functions on H. Hence their limit is lower
semi-continuous. In the spectral representation, this limit is the quadratic form
g 7→
Z
hg · gdµ

12.2. NON-NEGATIVE OPERATORS AND QUADRATIC FORMS.
349
which is the spectral representation of the quadratic form Q.
2. implies
3. Let {fn} be a Cauchy sequence of elements of D relative to
∥· ∥1. Since ∥· ∥≤∥· ∥1, {fn} is Cauchy with respect to the norm ∥· ∥of H
and so converges in this norm to an element f ∈H. We must show that f ∈D
and that fn →f in the ∥· ∥1 norm. Let ϵ > 0. Choose N such that
∥fm −fn∥2
1 = Q(fm −fn) + ∥fm −fn∥2 < ϵ2
∀m, n > N.
Let m →∞. By the lower semi-continuity of Q we conclude that
Q(f −fn) + ∥f −fn∥2 ≤ϵ2
and hence f ∈D and ∥f −fn∥1 < ϵ.
□
3.
implies 1. Let H1 denote the Hilbert space D equipped with the ∥· ∥1
norm. Notice that the scalar product on this Hilbert space is
(f, g)1 = B(f, g) + (f, g)
where B(f, f) = Q(f). The original scalar product (·, ·) is a bounded quadratic
form on H1, so there is a bounded self-adjoint operator A on H1 such that
0 ≤A ≤1 and
(f, g) = (Af, g)1
∀f, g ∈H1.
Now apply the spectral theorem to A. So there is a unitary isomorphism U of
H1 with L2(S, µ) where S = [0, 1] × N such that UAU −1 is multiplication by
the function a where a(s, k) = s. Since (Af, f)1 = 0 ⇒f = 0 we see that the
set {0, k)} has measure zero relative to µ so a > 0 except on a set of µ measure
zero. So the function
h = a−1 −1
is well deﬁned and non-negative almost everywhere relative to µ.
We have
a = (1 + h)−1 and
(f, g) =
Z
S
1
1 + h
ˆfˆgdµ
while
Q(f, g) + (f, g) = (f, g)1 =
Z
S
fgdµ.
Deﬁne the new measure ν on S by
ν =
1
1 + hµ.
Then the two previous equations imply that H is unitarily equivalent to L2(S, ν),
i.e.
(f, g) =
Z
S
fgdν

350
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
and
Q(f, g) =
Z
S
hfgdν.
This last equation says that Q is the quadratic form associated to the operator
H corresponding to multiplication by h.
□
12.2.5
Extensions and cores.
A form Q satisfying the condition(s) of Theorem 12.2.1 is said to be closed.
A form Q2 is said to be an extension of a form Q1 if it has a larger domain
but coincides with Q1 on the domain of Q1. A form Q is said to be closable if
it has a closed extension, and its smallest closed extension is called its closure
and is denoted by Q. If Q is closable, then the domain of Q is the completion
of Dom(Q) relative to the metric ∥· ∥1 in Theorem 12.2.1.
In general, we
can consider this completion; but only for closable forms can we identify the
completion as a subset of H. A subset D of Dom(Q) where Q is closed is called
a core of Q if Q is the completion of the restriction of Q to D.
Proposition 12.2.3 Let Q1 and Q2 be quadratic forms with the same dense
domain D and suppose that there is a constant c > 1 such that
c−1Q1(f) ≤Q2(f) ≤cQ1(f)
∀f ∈D.
If Q1 is the form associated to a non-negative self-adjoint operator H1 as in
Theorem 12.2.1 then Q2 is associated with a self-adjoint operator H2 and
Dom(H
1
2
1 ) = Dom(H
1
2
2 ) = D.
Proof.
The assumption on the relation between the forms implies that their
associated metrics on D are equivalent. So if D is complete with respect to
one metric it is complete with respect to the other, and the domains of the
associated self-adjoint operators both coincide with D.
12.2.6
The Friedrichs extension.
Recall that an operator A deﬁned on a dense domain D is called symmetric if
(Af, g) = (f, Ag)
∀f, g ∈D.
A symmetric operator is called non-negative if
(Af, f) ≥0
Theorem 12.2.2 [Friedrichs.] Let Q be the form deﬁned on the domain D of
a symmetric operator A by
Q(f) = (Af, f).
Then Q is closable and its closure is associated with a self-adjoint extension H
of A.

12.3. DIRICHLET BOUNDARY CONDITIONS.
351
Proof.
Let H1 be the completion of D relative to the metric ∥· ∥1 as given in
Theorem 12.2.1. The ﬁrst step is to show that we can realize H1 as a subspace
of H. Since ∥f∥≤∥f∥1, the identity map f 7→f extends to a contraction
C : H1 →H. We want to show that this map is injective. Suppose not, so that
Cf = 0 for some f ̸= 0 ∈H1. Thus there exists a sequence fn ∈D such that
∥f −fn∥1 →0
and
∥fn∥→0.
So
∥f∥2
1
=
lim
m→∞lim
n→∞(fm, fn)1
=
lim
m→∞lim
n→∞{(Afm, fn) + (fm, fn)}
=
lim
m→∞[(Afm, 0) + (fm, 0)] = 0.
So C is injective and hence Q is closable. Let H be the self-adjoint operator
associated with the closure of Q. We must show that H is an extension of A.
For f, g ∈D ⊂Dom(H) we have
(H
1
2 f, H
1
2 g) = Q(f, g) = (Hf, g).
Since D is dense in H1, this holds for f ∈D and g ∈H1. By Proposition 12.2.1
this implies that f ∈Dom(H). In other words, H is an extension of A.
□
12.3
Dirichlet boundary conditions.
In this section Ωwill denote a bounded open set in RN, with piecewise smooth
boundary, c > 1 is a constant, b is a continuous function deﬁned on the closure
Ωof Ωsatisfying
c−1 < b(x) < c
∀x ∈Ω
and
a = (aij) = (aij(x))
is a real symmetric matrix valued function of x deﬁned and continuously diﬀer-
entiable on Ωand satisfying
c−1I ≤a(x) ≤cI
∀x ∈Ω.
Let
Hb := L2(Ω, bdNx).
We let C∞(Ω) denote the space of all functions f which are C∞on Ωand all
of whose partial derivatives can be extended to be continuous functions on Ω.
We let
C∞
0 (Ω) ⊂C∞(Ω)
denote those f satisfying f(x) = 0 for x ∈∂Ω.

352
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
For f ∈C∞
0 (Ω) we deﬁne Af by
Af(x) := −b(x)−1
N
X
i,j=1
∂
∂xi

aij(x) ∂f
∂xj

.
Of course this operator is deﬁned on C∞(Ω) but for f, g ∈C∞
0 (Ω) we have, by
Gauss’s theorem (integration by parts)
(Af, g)b = −
Z
Ω


N
X
i,j=1
∂
∂xi

aij(x) ∂f
∂xj

gdNx
=
Z
Ω
X
ij
aij
∂f
∂xi
∂g
∂xj
dNx = (f, Ag)b.
So if we deﬁne the quadratic form
Q(f, g) :=
Z
Ω
X
ij
aij
∂f
∂xi
∂g
∂xj
dNx,
(12.8)
then Q is symmetric and so deﬁnes a quadratic form associated to the non-
negative symmetric operator H. We may apply the Friedrichs theorem to con-
clude the existence of a self adjoint extension H of A which is associated to the
closure of Q.
The closure of Q is complete relative to the metric determined by Theorem
12.2.1. But our assumptions about b and a guarantee the metrics of quadratic
forms coming from diﬀerent choices of b and a are equivalent and all equivalent
to the metric coming from the choice b ≡1 and a ≡(δij) which is
∥f∥2
1 =
Z
Ω
 |f|2 + |∇f|2
dNx,
(12.9)
where
∇f = ∂1f ⊕∂2f ⊕· · · ⊕∂Nf
and
|∇f|2(x) = (∂1f(x))2 + · · · + (∂Nf(x))2 .
To compare this with Proposition 12.2.3, notice that now the Hilbert spaces Hb
will also vary (but are equivalent in norm) as well as the metrics on the domain
of the closure of Q.
12.3.1
The Sobolev spaces W 1,2(Ω) and W 1,2
0 (Ω).
Let us be more explicit about the completion of C∞(Ω) and C∞
0 (Ω) relative to
this metric. If f ∈L2(Ω, dNx) then f deﬁnes a linear function on the space of
smooth functions of compact support contained in Ωby the usual rule
ℓf(φ) :=
Z
Ω
fφdNx
∀φ ∈C∞
c (Ω).

12.3. DIRICHLET BOUNDARY CONDITIONS.
353
We can then deﬁne the partial derivatives of f in the sense of the theory of
distributions, for example
ℓ∂if(φ) = −
Z
Ω
f(∂iφ)dNx.
These partial derivatives may or may not come from elements of L2(Ω, dNx).
We deﬁne the space W 1,2(Ω) to consist of those f ∈L2(Ω, dNx) whose ﬁrst
partial derivatives (in the distributional sense) ∂if = ∂f/∂xi all come form
elements of L2(Ω, dNx). We deﬁne a scalar product ( , )1 on W 1,2(Ω) by
(f, g)1 :=
Z
Ω
n
f(x)g(x) + ∇f(x) · ∇g(x)
o
dNx.
(12.10)
It is easy to check that W 1,2(Ω) is a Hilbert space, i.e. is complete. Indeed,
if fn is a Cauchy sequence for the corresponding metric ∥˙∥1, then fn and the
∂ifn are Cauchy relative to the metric of L2(Ω, dNx), and hence converge in
this metric to limits, i.e.
fn →f
and ∂ifn →gi
i = 1, . . . N
for some elements f and g1, . . . gN of L2(Ω, dNx). We must show that gi = ∂if.
But for any φ ∈C∞
c (Ω) we have
ℓgi(φ)
=
(gi, φ)
=
lim
n→∞(∂ifn, φ)
=
−lim
n→∞(fn, ∂iφ)
=
−(f, ∂iφ)
which says that gi = ∂if.
We deﬁne W 1,2
0
(Ω) to be the closure in W 1,2(Ω) of the subspace C∞
c (Ω).
Since C∞
c (Ω) ⊂C∞
0 (Ω) the domain of Q, the closure of the form Q deﬁned by
(12.8) on C∞
0 (Ω) contains W 1,2
0
(Ω).
We claim that
Lemma 12.3.1 C∞
c (Ω) is dense in C∞
0 (Ω) relative to the metric ∥· ∥1given by
(12.9).
Proof. By taking real and imaginary parts, it is enough to prove this theorem
for real valued functions. For any ϵ > 0 let Fϵ be a smooth real valued function
on R such that
• Fϵ(x) = x ∀|x| > 2ϵ
• Fϵ(x) = 0
∀|x| < ϵ
• |Fϵ(x)| ≤|x| ∀x ∈R

354
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
• 0 ≤F ′
ϵ(x) ≤3
∀x ∈R.
For f ∈C∞
0 (Ω) deﬁne
fϵ(x) := Fϵ(f(x)),
so Fϵ ∈C∞
c (Ω). Also,
|fϵ(x)| ≤|f(x)|
and
lim
ϵ→0 fϵ(x) = f(x) ∀x ∈Ω.
So the dominated convergence theorem implies that ∥f −fϵ∥2 →0. We have to
establish convergence in L2 of the derivatives.
Consider the set B ⊂Ωwhere f = 0 and ∇(f) ̸= 0. By the implicit function
theorem, this is a union of hypersurfaces, and so has measure zero. We have
Z
Ω
|∇(f) −∇(fϵ)|2dNx =
Z
Ω\B
|∇(f) −∇(fϵ)|2dNx.
On all of Ωwe have |∂i(fϵ)| ≤3|∂if| and on Ω\ B we have ∂ifϵ(x) →∂if(x).
So the dominated convergence theorem proves the L2 convergence of the partial
derivatives.
□
As a consequence, we see that the domain of Q is precisely W 1,2
0
(Ω).
12.3.2
Generalizing the domain and the coeﬃcients.
Let Ωbe any open subset of Rn, let b be any measurable function deﬁned on Ω
and satisfying
c−1 < b(x) < c
∀x ∈Ω
for some c > 1 and a a measurable matrix valued function deﬁned on Ωand
satisfying
c−1I ≤(x) ≤cI
∀x ∈Ω.
We can still deﬁne the Hilbert space
Hb := L2(Ω, bdNx)
as before, but can not deﬁne the operator A as above. Nevertheless we can
deﬁne the closed form
Q(f) =
Z
Ω
X
ij
aij
∂f
∂xi
∂g
∂xj
dNx,
on W 1,2
0
(Ω) which we know to be closed because the metric it determines by
Theorem 12.2.1 is equivalent as a metric to the norm on W 1,2
0
(Ω). Therefore,
by Theorem 12.2.1, there is a non-negative self-adjoint operator H such that
(H
1
2 f, H
1
2 g)b = Q(f, g)
∀f, g ∈W 1,2
0
(Ω).

12.3. DIRICHLET BOUNDARY CONDITIONS.
355
12.3.3
A Sobolev version of Rademacher’s theorem.
Rademacher’s theorem says that a Lipschitz function on RN is diﬀerentiable al-
most everywhere with a bound on its derivative given by the Lipschitz constant.
The following is a variant of this theorem which is useful for our purposes.
Theorem 12.3.1 Let f be a continuous real valued function on RN which van-
ishes outside a bounded open set Ωand which satisﬁes
|f(x) −f(y)| ≤c∥x −y∥
∀x, y ∈RN
(12.11)
for some c < ∞. Then f ∈W 1,2
0
(Ω).
We break the proof up into several steps:
Proposition 12.3.1 Suppose that f satisﬁes (12.11) and the support of f is
contained in a compact set K. Then
f ∈W 1,2(RN)
and
∥f∥2
1 =
Z
RN
 |f|2 + |∇f|2
dNx ≤|K|c2(N + diam(K))
where |K| denotes the Lebesgue measure of K.
Proof.
Let k be a C∞function on RN such that
• k(x) = 0 if ∥x∥≥1,
• k(x) > 0 if ∥x∥< 1, and
•
R
RN k(x)dNx = 1.
Deﬁne ks by
ks(x) = s−Nk
x
s

.
So
• ks(x) = 0 if ∥x∥≥s,
• ks(x) > 0 if ∥x∥< s, and
•
R
RN ks(x)dNx = 1.
Deﬁne ps by
ps(x) :=
Z
RN ks(x −z)f(z)dNy
so ps is smooth,
supp ps ⊂Ks = {x| d(x, K) ≤s}
and
ps(x) −ps(y) =
Z
RN (f(x −z) −f(y −z)) ks(z)dNz

356
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
so
|ps(x) −ps(y)| ≤c∥x −y∥.
This implies that ∥∇ps(x)∥≤c so the mean value theorem implies that supx∈RN |ps(x)| ≤
c · diam Ks and so
∥ps∥2
1 ≤|Ks|c2(diam K2
s + N).
By Plancherel
∥ps∥2
1 =
Z
RN (1 + ∥ξ∥2)|ˆps(ξ)|2dNξ
and since convolution goes over into multipication
ˆps(ξ) = ˆf(ξ)h(sξ)
where
h(ξ) =
Z
RN k(x)e−ix·ξdNx.
The function h is smooth with h(0) = 1 and |h(ξ)| ≤1 for all ξ. By Fatou’s
lemma
∥f∥1
=
Z
RN (1 + ∥ξ∥2)| ˆf(ξ)|2dNξ
≤
lim inf
s→0
Z
RN (1 + ∥ξ∥2)|h(sy)|2| ˆf(ξ)|2dNξ
=
lim inf
s→0 ∥ps∥2
1
≤
|K|c2(N + diam(K)2).
□
The dominated convergence theorem implies that
∥f −ps∥2
1 →0
as s →0. But the support of ps is slightly larger than the support of f, so we
are not able to conclude directly that f ∈W 1,2
0
(Ω). So we ﬁrst must cut f down
to zero where it is small. We do this by deﬁning the real valued functions φϵ on
R by
φϵ(s) =







0
if
|s| ≤ϵ
s
if
|s| ≥2ϵ
2(s −ϵ)
if
ϵ ≤s ≤2ϵ
2(s + ϵ)
if
−2ϵ ≤s ≤−ϵ
.
Then set fϵ = φϵ(f).
If O is the open set where f(x) ̸= 0 then fϵ has its
support contained in the set Sϵ consisting of all points whose distance from the
complement of O is > ϵ/c. Also
|fϵ(x) −fϵ(y)| ≤2|f(x) −f(y)| ≤2∥x −y|.
So we may apply the preceding result to fϵ to conclude that fϵ ∈W 1,2(RN) and
∥f∥2
1 ≤4|Sϵ|c2(N + diam (O)2)

12.4. RAYLEIGH-RITZ AND ITS APPLICATIONS.
357
and then by Fatou applied to the Fourier transforms as before that
∥f∥2
1 ≤4|O|c2(N + diam (O)).
Also, for ϵ suﬃciently small fϵ ∈W 1,2
0
(Ω). So we will be done if we show that
∥fϵ −f∥→0 as ϵ →0. The set Lϵ on which this diﬀerence is ̸= 0 is contained
in the set of all x for which 0 < |f(x)| < 2ϵ which decreases to the empty set as
ϵ →0. The above argument shows that
∥f −fϵ∥1 ≤4|Lϵc2(N + diam (Lϵ)2) →0.
□
12.4
Rayleigh-Ritz and its applications.
12.4.1
The discrete spectrum and the essential spectrum.
Let H be a self-adjoint operator on a Hilbert space H and let σ = σ(H) ⊂R
denote is spectrum.
The discrete spectrum of H is deﬁned to be those eigenvalues λ of H
which are of ﬁnite multiplicity and are also isolated points of the spectrum.
This latter condition says that there is some ϵ > 0 such that the intersection of
the interval (λ −ϵ, λ + ϵ) with σ consists of the single point {λ}. The discrete
spectrum of H will be denoted by σd(H) or simply by σd when H is ﬁxed in
the discussion.
The complement in σd(H) in σ(H) is called the essential spectrum of H
and is denoted by σess(H) or simply by σess when H is ﬁxed in the discussion.
12.4.2
Characterizing the discrete spectrum.
If λ ∈σd(H) then for suﬃciently small ϵ > 0 the spectral projection P =
P((λ−ϵ, λ+ϵ)) has the property that it is invariant under H and the restriction
of H to the image of P has only λ in its spectrum and hence P(H) is ﬁnite
dimensional, since the multiplicity of λ is ﬁnite by assumption.
Conversely, suppose that λ ∈σ(H) and that P(λ −ϵ, λ + ϵ) is ﬁnite di-
mensional.
This means that in the spectral representation of H, the subset
E(λ−ϵ,λ+ϵ) of
S = σ × N
consisting of all
(s, n)|λ −ϵ < s < lλ + ϵ}
has the property that
L2(E(λ−ϵ,λ+ϵ), dµ)
is ﬁnite dimensional. If we write
E(λ−ϵ,λ+ϵ) =
[
n∈N
(λ −ϵ, λ + ϵ) × {n}

358
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
then since
L2(E(λ−ϵ,λ+ϵ)) = ˆ
M
n
L2((λ −ϵ, λ + ϵ), {n})
we conclude that all but ﬁnitely many of the summands on the right are zero,
which implies that for all but ﬁnitely many n we have
µ ((λ −ϵ, λ + ϵ) × {n}) = 0.
For each of the ﬁnite non-zero summands, we can apply the case N = 1 of the
following lemma:
Lemma 12.4.1 Let ν be a measure on RN such that L2(RN, ν) is ﬁnite dimen-
sional. Then ν is supported on a ﬁnite set in the sense that there is some ﬁnite
set of m distinct points x1, . . . , xm each of positive measure and such that the
complement of the union of these points has ν measure zero.
Proof.
Partition RN into cubes whose vertices have all coordinates of the form
t/2r for an integer r and so that this is a disjoint union. The corresponding
decomposition of the L2 spaces shows that only ﬁnite many of these cubes have
positive measure, and as we increase r the cubes with positive measure are
nested downward, and can not increase in number beyond n = dim L2(RN, ν).
Hence they converge in measure to at most n distinct points each of positive ν
measure and the complement of their union has measure zero.
□
We conclude from this lemma that there are at most ﬁnitely many points
(sr, k) with sr ∈(λ −ϵ, λ + ϵ) which have ﬁnite measure in the spectral repre-
sentation of H, each giving rise to an eigenvector of H with eigenvalue sr, and
the complement of these points has measure zero. This shows that λ ∈σd(H).
We have proved
Proposition 12.4.1 λ ∈σ(H) belongs to σd(H) if and only if there is some
ϵ > 0 such that P((λ −ϵ, λ + ϵ))(H) is ﬁnite dimensional.
12.4.3
Characterizing the essential spectrum
This is simply the contrapositive of Prop. 12.4.1:
Proposition 12.4.2 λ ∈σ(H) belongs to σess(H) if and only if for every ϵ > 0
the space
P((λ −ϵ, λ + ϵ))(H)
is inﬁnite dimensional.
12.4.4
Operators with empty essential spectrum.
Theorem 12.4.1 The essential spectrum of a self adjoint operator is empty if
and only if there is a complete set of eigenvectors of H such that the correspond-
ing eigenvalues λn have the property that |λn| →∞as n →∞.

12.4. RAYLEIGH-RITZ AND ITS APPLICATIONS.
359
Proof.
If the essential spectrum is empty, then the spectrum consists of
eigenvalues of ﬁnite multiplicity which have no accumulation ﬁnite point, and
so must converge in absolute value to ∞. Enumerate the eigenvalues according
to increasing absolute value. Each has ﬁnite multiplicity and so we can ﬁnd
an orthonormal basis of the ﬁnite dimensional eigenspace corresponding to each
eigenvalue. The eigenvectors corresponding to distinct eigenvalues are orthogo-
nal. So what we must show is that the space spanned by all these eigenvectors is
dense. Suppose not. The space L orthogonal to all the eigenvectors is invariant
under H. If this space is non-zero, the spectrum of H restricted to this subspace
is not empty, and is a subset of the spectrum of H. So there will be eigenvectors
in L, contrary to the deﬁnition of L.
Conversely, suppose that the conditions hold. Let fn be the complete set
of eigenvectors. Since the set of eigenvalues is isolated, we will be done if we
show that they constitute the entire spectrum of H. Suppose that z does not
coincide with any of the λn. We must show that the operator zI −H has a
bounded inverse on the domain of H, which consists of all f = P
n anfn such
that P |an|2 < ∞and P λ2
n|an|2 < ∞. But for these f
∥(zI −H)f∥2 =
X
n
|z −λn|2|an|2 ≥c2∥f∥2
where c = minn |λn −z| > 0.
□
There are some immediate consequences which are useful to state explicitly.
Corollary 12.4.1 Let H be a non-negative self adjoint operator on a Hilbert
space H. The following conditions on H are equivalent:
1. The essential spectrum of H is empty.
2. There exists an orthonormal basis of H consisting of eigenvectors fn of
H, each with ﬁnite multiplicity with eigenvalues λn →∞.
3. The operator (I + H)−1 is compact.
Since there are no negative eigenvalues, we know that 1) and 2) are equivalent.
We must show that 2) and 3) are equivalent. If (I + H)−1 is compact, we know
that there is an orthonormal basis {fn} of H consisting of eigenvectors with
eigenvalues µn →0. (We know from the spectral theorem that (I + H)−1 is
unitarily equivalent to multiplication by the positive function 1/(1 + h) and so
(I + H)−1 has no kernel.) Then the {fn} constitute an orthonormal basis of H
consisting of eigenvectors with eigenvalues λn = µ−1
n
→∞.
Conversely, suppose that 2) holds. Consider the ﬁnite rank operators An
deﬁned by
Anf :=
n
X
j=1
1
1 + λj
(f, fj)fj.
Then
∥(I + H)−1f −Anf∥= ∥
∞
X
j=n+1
1
1 + λj
(f, fj)fj)∥≤
1
1 + λn
∥f∥.

360
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
This shows that n(I + H)−1 can be approximated in operator norm by ﬁnite
rank operators. So we need only apply the following characterization of compact
operators which we should have stated and proved last semester:
12.4.5
A characterization of compact operators.
Theorem 12.4.2 An operator A on a separable Hilbert space H is compact
if and only if there exists a sequence of operators An of ﬁnite rank such that
An →A in operator norm.
Proof.
Suppose there are An →A in operator norm. We will show that the
image A(B) of the unit ball B of H is totally bounded: Given ϵ > 0, choose
n suﬃciently large that ∥A −An∥< 1
2ϵ, so the image of B under A −An is
contained in a ball of radius 1
2ϵ. Since An is of ﬁnite rank, An(B) is contained in
a bounded region in a ﬁnite dimensional space, so we can ﬁnd points x1, . . . , xk
which are within a distance 1
2ϵ of any point of An(B). Then the x1, . . . , xk are
within distance ϵ of any point of A(B) which says that A(B) is totally bounded.
Conversely, suppose that A is compact. Choose an orthonormal basis {fk}
of H. Let Pn be orthogonal projection onto the space spanned by the ﬁrst n
elements of of this basis. Then An := PnA is a ﬁnite rank operator, and we will
prove that An →A. For this it is enough to show that (I −Pn) converges to
zero uniformly on the compact set A(B). Choose x1, . . . , xk in this image which
are within 1
2ϵ distance of any point of A(B). For each ﬁxed j we can ﬁnd an
n such that ∥Pnx −x∥< 1
2ϵ. This follows from the fact that the {fk∥form an
orthonormal basis. Choose n large enough to work for all the xj. Then for any
x ∈A(B) we have
∥Pnx −x∥≤∥x −xj∥+ ∥Pnxj −xj∥.
We can choose j so that the ﬁrst term is < 1
2ϵ and the second term is < 1
2ϵ for
any j.
□
12.4.6
The variational method.
Let H be a non-negative self-adjoint operator on a Hilbert space H. For any
ﬁnite dimensional subspace L of H with L ⊂D = Dom(H) deﬁne
λ(L) := sup{(Hf, f)|f ∈L and ∥f∥= 1}.
Deﬁne
λn = inf{λ(L),
|L ⊂D, and dim L = n}.
(12.12)
The λn are an increasing family of numbers. We shall show that they constitute
that part of the discrete spectrum of H which lies below the essential spectrum:
Theorem 12.4.3 Let H be a non-negative self-adjoint operator on a Hilbert
space H. Deﬁne the numbers λn = λn(H) by (12.12). Then one of the following
three alternatives holds:

12.4. RAYLEIGH-RITZ AND ITS APPLICATIONS.
361
1. H has empty essential spectrum.
In this case the λn →∞and coin-
cide with the eigenvalues of H repeated according to multiplicity and listed
in increasing order, or else H is ﬁnite dimensional and the λn coincide
with the eigenvalues of H repeated according to multiplicity and listed in
increasing order.
2. There exists an a < ∞such that λn < a for all n, and limn→∞λn =
a. In this case a is the smallest number in the essential spectrum of H
and σ(H) ∩[0, a) consists of the λn which are eigenvalues of H repeated
according to multiplicity and listed in increasing order.
3. There exists an a < ∞and an N such that λn < a for n ≤N and λm = a
for all m > N. Then a is the smallest number in the essential spectrum
of H and σ(H) ∩[0, a) consists of the λ1, . . . , λN which are eigenvalues of
H repeated according to multiplicity and listed in increasing order.
Proof.
Let b be the smallest point in the essential spectrum of H (so b = ∞
in case 1.). So H has only isolated eigenvalues of ﬁnite multiplicity in [0, b)
and these constitute the entire spectrum of H in this interval.
Let {fk} be
an orthonormal set of these eigenvectors corresponding to these eigenvalues µk
listed (with multiplicity) in increasing order.
Let Mn denote the space spanned by the ﬁrst n of these eigenvectors, and
let f ∈Mn. Then f = Pn
j=1(f, fj)fj so
Hf =
n
X
j=1
µj(f, fj)fj
and so
(Hf, f) =
n
X
j=1
µj|(f, fj)|2 ≤µn
n
X
j=1
|(f, fj)|2 = µn∥f∥2
so
λn ≤µn.
In the other direction, let L be an n-dimensional subspace of Dom(H) and let
P denote orthogonal projection of H onto Mn−1 so that
Pf =
n−1
X
j=1
(f, fj)fj.
The image of P restricted to L has dimension n−1 while L has dimension n. So
there must be some f ∈L with Pf = 0. By the spectral theorem, the function
˜f = Uf corresponding to f is supported in the set where h ≥µn and hence
(Hf, f) ≥µn∥f∥2 so
λn ≥µn.
There are now three cases to consider: If b = +∞(i.e. the essential spectrum of
H is empty) the λn = µn can have no ﬁnite accumulation point so we are in case

362
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
1). If there are inﬁnitely many µn in [0, b) they must have ﬁnite accumulation
point a ≤b, and by deﬁnition, a is in the essential spectrum. Then we must
have a = b and we are in case 2). The remaining possibility is that there are
only ﬁnitely many µ1, . . . µM < b. Then for k ≤M we have λk = µk as above,
and also λm ≥b for m > M. Since b ∈σess(H), the space
K := P(b −ϵ, b + ϵ)H
is inﬁnite dimensional for all ϵ > 0. Let {f1, f2, . . . , } be an orthonormal basis
of K, and let L be the space spanned by the ﬁrst m of these basis elements. By
the spectral theorem, (Hf, f) ≤(b + ϵ)∥f∥2 for any f ∈L. so for all m we have
λm ≤b + ϵ. So we are in case 3).
□
In applications (say to chemistry) one deals with self-adjoint operators which
are bounded from below, rather than being non-negative. But this requires just
a trivial shift in stating and applying the preceding theorem. In some of these
applications the bottom of the essential spectrum is at 0, and one is interested
in the lowest eigenvalue λ1 which is negative.
12.4.7
Variations on the variational formula.
An alternative formulation of the formula.
Instead of (12.12) we can determine the λn as follows: We deﬁne λ1 as before:
λ1 = min
f̸=0
(Hf, f)
(f, f) .
Suppose that f1 is an f which attains this minimum. We then know that f1 is
an eigenvector of H with eigenvalue λ1. Now deﬁne
λ2 :=
min
f̸=0,f⊥f1
(Hf, f)
(f, f) .
This λ2 coincides with the λ2 given by (12.12) and an f2 which achieves the
minimum is an eigenvector of H with eigenvalue λ2. Proceeding this way, af-
ter ﬁnding the ﬁrst n eigenvalues λ1, . . . , λn and corresponding eigenvectors
f1, . . . , fn we deﬁne
λn+1 =
min
f̸=0,f⊥f1,f⊥f2,...,f⊥fn
(Hf, f)
(f, f) .
This gives the same λk as (12.12).
Variations on the condition L ⊂Dom(H).
In some applications, the condition L ⊂Dom(H) is unduly restrictive, especially
when we want to compare eigenvalues of diﬀerent self adjoint operators. In these

12.4. RAYLEIGH-RITZ AND ITS APPLICATIONS.
363
applications, one can frequently ﬁnd a common core D for the quadratic forms
Q associated to the operators. That is,
D ⊂Dom(H
1
2 )
and D is dense in Dom(H
1
2 ) for the metric ∥· ∥1 given by
∥|f∥2
1 = Q(f, f) + ∥f∥2
where
Q(f, f) = (Hf, f).
Theorem 12.4.4 Deﬁne
λn
=
inf{λ(L),
|L ⊂Dom(H)
λ′
n
=
inf{λ(L),
|L ⊂D
λ′′
n
=
inf{λ(L),
|L ⊂Dom(H
1
2 ).
Then
λn = λ′
n = λ′′
n.
Proof.
We ﬁrst prove that λ′
n = λ′′
n. Since D ⊂Dom(H
1
2 ) the condition
L ⊂D implies L ⊂Dom(H
1
2 ) so
λ′
n ≥λ′′
n
∀n.
Conversely, given ϵ > 0 let L ⊂Dom(H
1
2 ) be such that L is n-dimensional and
λ(L) ≤λ′′
n + ϵ.
Restricting Q to L × L, we can ﬁnd an orthonormal basis f1, . . . , fn of L such
that
Q(fi, fj) = γiδij,
0 ≤γ1 ≤· · · , γn = λ(L).
We can then ﬁnd gi ∈D such that ∥gi −fi∥1 < ϵ for all i = 1, . . . , n. This
means that
|aij −δij| < cnϵ,
where aij := (gi, gj)
and
|bij −γiδij| < c′
nϵ where bij := Q(gi, gj),
and the constants cn and c′
n depend only on n.
Let L′ be the space spanned by the gi. Then L′ is an n-dimensional subspace
of D and
λ(L′) = sup{
n
X
ij=1
bijzizj|
n
X
ij
aijzizj ≤1}
satisﬁes
|λ(L′) −λ′′
n| < c′′
nϵ

364
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
where c′′
n depends only on n. Letting ϵ →0 shows that λ′
n ≤λ′′
n.
To complete the proof of the theorem, it suﬃces to show that Dom(H) is a
core for Dom(H
1
2 ). This follows from the spectral theorem: The domain of H
is unitarily equivalent to the space of all f such that
Z
S
(1 + h(s, n)2)|f(s, n)|2dµ < ∞
where h(s, n) = s. This is clearly dense in the space of f for which
∥f∥1 =
Z
S
(1 + h)|f|2dµ < ∞
since h is non-negative and ﬁnite almost everywhere.
12.4.8
The secular equation.
The deﬁnition (12.12) makes sense in a real ﬁnite dimensional vector space. If
Q is a real quadratic form on a ﬁnite dimensional real Hilbert space V , then we
can write Q(f) = (Hf, f) where H is a self-adjoint (=symmetric) operator, and
then ﬁnd an orthonormal basis according to (12.12). In terms of such a basis
f1, . . . , fn, we have
Q(f) =
X
k
λkr2
k
where
f =
X
rkfk.
If we consider the problem of ﬁnding an extreme point of Q(f) subject to the
constraint that (f, f) = 1, this becomes (by Lagrange multipliers), the problem
of ﬁnding λ and f such that
dQf = λdSf, where S(f) = (f, f).
In terms of the coordinates (r1, . . . , rn) we have
1
2dQf = (µ1r1, . . . , µnrn) while
1
2dSf = (r1, . . . , rn).
So the only possible values of λ are λ = µi for some i and the corresponding f
is given by rj = 0, j ̸= i and ri ̸= 0. This is a watered down version version of
Theorem 12.4.3. In applications, one is frequently given a basis of V which is
not orthonormal. Thus (in terms of the given basis)
Q(f) =
X
Hijrirj,
and
S(f) =
X
ij
Sijrirj
where
f =
X
rifi.
The problem of ﬁnding an extreme point of Q(f) subject to the constraint
S(f) = 1 becomes that of ﬁnding λ and r = (r1, . . . , rn) such that
dQf = λdSf

12.5. THE DIRICHLET PROBLEM FOR BOUNDED DOMAINS.
365
i.e.



H11 −λS11
H12 −λS12
· · ·
H1n −λS1n
...
...
...
...
Hn1 −λSn1
Hn2 −λSn2
· · ·
Hnn −λSnn






r1
...
rn


= 0.
As a condition on λ this becomes the algebraic equation
det



H11 −λS11
H12 −λS12
· · ·
H1n −λS1n
...
...
...
...
Hn1 −λSn1
Hn2 −λSn2
· · ·
Hnn −λSnn


= 0
which is known as the secular equation due to its previous use in astronomy to
determine the periods of orbits.
12.5
The Dirichlet problem for bounded domains.
Let Ωbe an open subset of Rn. The Sobolev space W 1,2(Ω) is deﬁned as the
set of all f ∈L2(Ω, dx) (where dx is Lebesgue measure) such that all ﬁrst order
partial derivatives ∂if in the sense of generalized functions belong to L2(Ω, dx).
On this space we have the Sobolev scalar product
(f, g)1 :=
Z
ω
(f(x)g(x) + ∇f(x) · ∇g(x))dx.
It is not hard to check (and we will do so within the next three lectures) that
W 1,2(Ω) with this scalar product is a Hilbert space. We let C∞
0 (Ω) denote the
space of smooth functions of compact support whose support is contained in Ω,
and let W 1,2
0
(Ω) denote the completion of C∞
0 (Ω) with respect to the norm ∥·∥1
coming from the scalar product (·, ·)1.
We will show that ∆deﬁnes a non-negative self-adjoint operator with domain
W 1,2
0
(Ω) known as the Dirichlet operator associated with Ω. I want to postpone
the proofs of these general facts and concentrate on what Rayleigh-Ritz tells us
when Ωis a bounded open subset which we will assume from now on.
We are going apply Rayleigh-Ritz to the domain D(Ω) and the quadratic
form Q(f) = Q(f, f) where
Q(f, g) :=
Z
Ω
∇f(x) · ∇g(x)dx.
Deﬁne
λn(Ω) := inf{λ(L)|L ⊂C∞
0 (Ω),
dim(L) = n}
where
λ(L) = sup Q(f), f ∈L,
∥f∥= 1
as before.

366
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
Here is the crucial observation: If Ω⊂Ω′ are two bounded open regions
then
λn(Ω) ≥λn(Ω′)
since the inﬁmum for Ωis taken over a smaller collection of subspaces than for
Ω′.
Suppose that Ωis an interval (0, a) on the real line. Fourier series tells us that
the functions fk = sin(πkx/a) form a basis of L2(Ω, dx) and are eigenvectors
of ∆with eigenvalues k2a2. By Fubini we get a corresponding formula for any
cube in Rn which shows that (I + ∆)−1 is a compact operator for the case of a
cube. Since any Ωcontains a cube and is contained in a cube, we conclude that
the λn(Ω) tend to ∞and so Ho = ∆(with the Dirichlet boundary conditions)
have empty essential spectra and (I + H0)−1 are compact.
Furthermore the λn(Ω) aer the eigenvalues of H0 arranged in increasing
order.
Proposition 12.5.1 If Ωm is an increasing sequence of open sets contained in
Ωwith
Ω=
[
m
Ωm
then
lim
m→∞λn(Ωm) = λn(Ω)
for all n.
Proof.
For any ϵ > 0 there exists an n-dimensional subspace L of C∞
0 (Ω) such
that λ(L) ≤λn(Ω) + ϵ. There will be a compact subset K ⊂Ωsuch that all
the elements of L have support in K. We can then choose m suﬃciently large
so that K ⊂Ωm. Then
λn(Ω) ≤λn(Ωm) ≤λn(Ω) + ϵ.
□
12.6
Valence.
The minimum eigenvalue λ1 is determined according to (12.12) by
λ1 = inf
ψ̸=0
(Hψ, ψ)
(ψ, ψ) .
Unless one has a clever way of computing λ1 by some other means, minimizing
the expression on the right over all of H is a hopeless task. What is done in
practice is to choose a ﬁnite dimensional subspace and apply the above mini-
mization over all ψ in that subspace (and similarly to apply (12.12) to subspaces
of that subspace for the higher eigenvalues). The hope is that this yield good
approximations to the true eigenvalues.
If M is a ﬁnite dimensional subspace of H, and P denotes projection onto
M, then applying (12.12) to subspaces of M amounts to ﬁnding the eigenvalues

12.6. VALENCE.
367
of PHP, which is an algebraic problem as we have seen. A chemical theory
( when H is the Schr¨odinger operator) then amounts to cleverly choosing such
a subspace.
12.6.1
Two dimensional examples.
Consider the case where M is two dimensional with a basis ψ1 and ψ2. The
idea is that we have some grounds for believing that that the true eigenfunction
has characteristics typical of these two elements and is likely to be some linear
combination of them. If we set
H11 := (Hψ1, ψ1),
H12 := (Hψ1, ψ2) = H21,
H22 := (Hψ2, ψ2)
and
S11 := (Sψ1, ψ1),
S12 := (ψ1, ψ2) = S21,
S22 := (ψ2, ψ2)
then if these quantities are real we can apply the secular equation
det
H11 −λS11
H12 −λS12
H21 −λS21
H22 −λS22

= 0
to determine λ.
Suppose that S11 = S22 = 1, i.e. that ψ1 and ψ2 are separately normalized.
Also assume that ψ1 and ψ2 are linearly independent. Let
β := S12 = S21.
This β is sometimes called the “overlap integral” since if our Hilbert space is
L2(R3) then β =
R
R3 ψ1ψ2dx. Now
H11 = (Hψ1, ψ1)
is the guess that we would make for the lowest eigenvalue (= the lowest “energy
level”) if we took L to be the one dimensional space spanned by ψ1. So let us
call this value E1. So E1 := H11 and similarly deﬁne E2 = H22. The secular
equation becomes
(λ −E1)(λ −E2) −(H12 −λβ)2 = 0.
If we deﬁne F(λ) := (λ −E1)(λ −E2) −(H12 −λβ)2 then F is positive for large
values of |λ| since |β| < 1 by Cauchy-Schwarz. F(λ) is non-positive at λ = E1 or
E2 and in fact generically will be strictly negative at these points. So the lower
solution of the secular equations will generically lie strictly below min(E1, E2)
and the upper solution will generically lie strictly above max(E1, E2). This is
known as the no crossing rule and is of great importance in chemistry. I
hope to explain the higher dimensional version of this rule (due to Teller-von
Neumann and Wigner) later.

368
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
12.6.2
H¨uckel theory of hydrocarbons.
In this theory the space M is the n-dimensional space where each carbon atom
contributes one electron. (The other electrons being occupied with the hydrogen
atoms.) It is assumed that the S in the secular equation is the identity matrix.
This amounts to the assumption that the basis given by the electrons associ-
ated with each carbon atom is an orthonormal basis. It is also assumed that
(Hf, f) = α is the same for each basis element. In a crude sense this measures
the electron-attracting power of each carbon atom and hence is assumed to be
the same for all basis elements. If (Hfr, fs) ̸= 0, the atoms r and s are said to
be “bonded”. It is assumed that only “nearest neighbor” atoms are bonded, in
which case it is assumed that (Hfr, fs) = β is independent of r and s. So PHP
has the form
αI + βA
where A is the adjacency matrix of the graph whose vertices correspond to the
carbon atoms and whose edges correspond to the bonded pairs of atoms. If we
set
x := E −α
β
then ﬁnding the energy levels is the same as ﬁnding the eigenvalues x of the
adjacency matrix A. In particular this is so if we assume that the values of α
and β are independent of the particular molecule.
12.7
Davies’s proof of the spectral theorem
In this section we present the proof given by Davies of the spectral theorem,
taken from his book Spectral Theory and Diﬀerential Operators.
12.7.1
Symbols.
These are functions which vanish more (or grow less) at inﬁnity the more you
diﬀerentiate them. More precisely, for any real number β we let Sβ denote the
space of smooth functions on R such that for each non-negative integer n there
is a constant cn (depending on f) such that
|f (n)(x)| ≤cn(1 + |x|2)(β−n)/2.
It will be convenient to introduce the function
⟨z⟩:= (1 + |z|2)
1
2 .
So we can write the deﬁnition of Sβ as being the space of all smooth functions
f such that
|f (n)(x)| ≤cn⟨x⟩β−n
(12.13)
for some cn and all integers n ≥0. For example, a polynomial of degree k belongs
to Sk since every time you diﬀerentiate it you lower the degree (and eventually

12.7. DAVIES’S PROOF OF THE SPECTRAL THEOREM
369
get zero).
More generally, a function of the form P/Q where P and Q are
polynomials with Q nowhere vanishing belongs to Sk where k = deg P −deg Q.
The name “symbol” comes from the theory of pseudo-diﬀerential operators.
12.7.2
Slowly decreasing functions.
Deﬁne
A :=
[
β<0
Sβ.
For each n ≥1 deﬁne the norm ∥· ∥n on A by
∥f∥n :=
n
X
r=0
Z
R
|f (r)(x)|⟨x⟩r−1dx.
(12.14)
If f ∈Sβ, β < 0 then f ′ is integrable and f(x) =
R x
−∞f(t)dt so
sup
x∈R
|f(x)| ≤∥f∥1
and convergence in the ∥· ∥1 norm implies uniform convergence.
Lemma 12.7.1 The space of smooth functions of compact support is dense in
A for each of the norms ∥· ∥n+1.
Proof. Choose a smooth φ of compact support in [−2, 2] such that φ ≡1 on
[−1, 1]. Deﬁne
φm := φ
 s
m

so φ is identically one on [−m, m] and is of compact support. Notice that for
any k ≥1 we have
φ(k)
m (x)
 ≤Kk⟨x⟩−k1|x|≥m(x)
for suitable constants Kk.
We claim that φmf →f in the norm ∥· ∥n+1 for any f ∈A. Indeed,
∥f −φmf∥n+1 =
n+1
X
r=0
Z
R

dr
dxr {f(x)(1 −φm(x)}
 ⟨x⟩r−1dx.
By Leibnitz’s formula and the previous inequality this is bounded by some
constant times
n+1
X
r=0
Z
|x|>m
|f (r)(x)|⟨x⟩r−1dx
which converges to zero as m →∞.
□

370
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
12.7.3
Stokes’ formula in the plane.
Consider complex valued diﬀerentiable functions in the (x, y) plane. Deﬁne the
diﬀerential operators
∂
∂z := 1
2
 ∂
∂x + i ∂
∂y

,
and ∂
∂z := 1
2
 ∂
∂x −i ∂
∂y

.
Deﬁne the complex valued linear diﬀerential forms
dz := dx + idy,
dz := dx −idy
so
dx = 1
2(dz + dz),
dy = 1
2i(dz −dz).
So we can write any complex valued diﬀerential form adx + bdy as Adz + Bdz
where
A = 1
2(a −ib),
B = 1
2(a + ib).
In particular, for any diﬀerentiable function f we have
df = ∂f
∂xdx + ∂f
∂y dy = ∂f
∂z dz + ∂f
∂z dz.
Also
dz ∧dz = −2idx ∧dy.
So if U is any bounded region with piecewise smooth boundary, Stokes theorem
gives
Z
∂U
fdz =
Z
U
d(fdz) =
Z
U
∂f
∂z dz ∧dz = 2i
Z
U
∂f
∂z dxdy.
The function f can take values in any Banach space. We will apply to functions
with values in the space of bounded operators on a Hilbert space.
A function f is holomorphic if and only if ∂f
∂z = 0. So the above formula
implies the Cauchy integral theorem.
Here is a variant of Cauchy’s integral theorem valid for a function of compact
support in the plane:
1
π
Z
C
∂f
∂z ·
1
z −wdxdy = −f(w).
(12.15)
Indeed, the integral on the left is the limit of the integral over C \ Dδ where Dδ
is a disk of radius δ centered at w. Since f has compact support, and since
∂
∂z

1
z −w

= 0,
we may write the integral on the left as
−1
2πi
Z
∂Dδ
f(z)
z −wdz →−f(w).
□

12.7. DAVIES’S PROOF OF THE SPECTRAL THEOREM
371
12.7.4
Almost holomorphic extensions.
Let φ be as above, and deﬁne
σ(x, y) := φ(y/⟨x⟩).
Let f be a complex valued C∞function on R. Deﬁne
˜f(z) =
˜
fσ,n(z) :=
( n
X
r=0
f (r)(x)(iy)r
r!
)
σ(x, y)
(12.16)
for n ≥1. Then
∂˜fσ,n
∂z
= 1
2
( n
X
r=0
f (r)(x)(iy)r
r!
)
{σx + iσy} + 1
2f (n+1)(x)(iy)n
n! σ.
(12.17)
So

∂˜fσ,n
∂z
 = O(|y|n),
and, in particular,
∂˜fσ,n
∂z (x, 0) = 0.
We call ˜fσ,n an almost holomorphic extension of f.
12.7.5
The Heﬄer-Sj¨ostrand formula.
Let H be a self-adjoint operator on a Hilbert space, and let f ∈A. Deﬁne
f(H) := −1
π
Z
C
∂˜f
∂z R(z, H)dxdy,
(12.18)
where ˜f = ˜fσ,n. One of our tasks will be to show that the notation is justiﬁed
in that the right hand side of the above expression is independent of the choice
of σ and n. But ﬁrst we have to show that the integral is well deﬁned.
Lemma 12.7.2 The integral (12.18) is norm convergent and
∥f(H)∥≤cn∥f∥n+1.
Proof. We know that R(z, H) is holomorphic in z for z ∈C\R, in particular is
norm continuous there. So the integral is well deﬁned over any compact subset
of C \ R.
Let
U = {z|⟨x⟩< |y| < 2⟨x⟩}.
The partial derivatives of σ are supported in U and
|σx(z) + iσy(z)| ≤c⟨x⟩−11U(z),
∀z ∈C.
(12.19)

372
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
The norm of R(z, H) is bounded by |y|−1, and σ is supported on the closure of
V := {z|0 < |y| < 2⟨x⟩}.
So the integrand in (12.18) is dominated on C \ R by
c
n
X
r=0
|f (r)(x)|⟨x⟩r−21U(x, y) + c|f (n+1)(x)||y|n−11V (x, y).
So if n ≥1 the dominated converges theorem applies. Integrating then yields
the estimate in the lemma.
□
Theorem 12.7.1 The deﬁnition of ˜f in (12.18) is independent of φ and of
n ≥1.
For this we prove the following lemma:
Lemma 12.7.3 If F is a smooth function of compact support on the plane and
F(x, y) = O(y2)
as y →0
then
−1
π
Z
C
∂F
∂z R(z, H)dxdy = 0.
Proof of the lemma. Chooose N large enough so that the support of F is
contained in the square |x| < N, |y| < N. So the integration is over this square.
Let Qδ denote this square with the strip |y| < δ removed, so Qδ consists of two
rectangular regions, Qδ = R+
δ ∪R−
δ , and it is enough to show that the limit
of the integrals over each of these regions vanishes. By Stokes’ theorem, the
integral over R+
δ is equal to
i
2π
Z
∂R+
δ
F(z)R(z, H)dz.
But F(z) vanishes on the top and on the vertical sides of R+
δ while along the
bottom we have ∥R(z, H)∥≤δ−1 while F = O(δ2). So the integral allong the
bottom path tends to zero, and the same for R−
δ . This proves the lemma.
Proof of the theorem. Since the smooth functions of compact support are
dense in A it is enough to prove the theorem for f compactly supported, If we
make two choices, φ1 and φ2 then the corresponding ˜fσ1,n and ˜fσ2,n agree in
some neighborhood of the x-axis, so ˜fσ1,n −˜fσ2,n vanishes in a neighborhood of
the x-axis so the lemma implies that
˜fσ1,n(A) = ˜fσ2,n(A).
This shows that the deﬁnition is independent of the choice of φ. If m > n ≥1
then ˜fσ,m −˜fσ,n = O(y2) so another application of the lemma proves that ˜f(H)
is independent of the choice of n.
□
Notice that the proof shows that we can choose σ to be any smooth function
which is identically one in a neighborhood of the real axis and which is compactly
supported in the imaginary direction.

12.7. DAVIES’S PROOF OF THE SPECTRAL THEOREM
373
12.7.6
A formula for the resolvent.
Let w be a complex number with a non-zero imaginary part, and consider the
function rw on R given by
rw(x) =
1
w −x
This function clearly belongs to A and so we can form rw(H). The purpose of
this section is to prove that
rw(H) = R(w, H).
We will choose the σ in the deﬁnition of ˜rw so that w ̸∈supp σ. To be speciﬁc,
choose σ = φ(λ|y|/⟨x⟩) for large enough λ so that w ̸∈supp σ.
We will choose the n in the deﬁnition of ˜rw as n = 1.
For each real number m consider the region
Ωm :=

(x, y)||x| < m and m−1⟨x⟩< |y| < 2m
	
.
Again, Ωm consists of two regions, each of which has three straight line segment
sides (one horizontal at the top (or bottom) and two vertical) and a parabolic
side, and we can write the integral over C as the limit of the integral over Ωm
as m →∞. So by Stokes,
rm(H) = lim
m→∞
Z
∂Ωm
˜rw(z)R(z, H)dz.
If we could replace ˜rw by rw in this integral then we would get R(w, H) by the
Cauchy integral formula. So we must show that as m →∞we make no error
by replacing ˜rw by rw.
On each of the four vertical line segments we have
rw(z) −˜rw(z) = (1 −σ(z))rw(z) + σ(z)(rw(z) −rw(x) −r′
w(x)iy).
The ﬁrst summand on the right vanishes when λ|y| ≤⟨x⟩. We can apply Taylor’s
formula with remainder to the function y 7→rw(x + iy) in the second term. So
we have the estimate
|rw(z) −˜rw(z)| ≤c1⟨x⟩<λ|y| + c |y|2
⟨x⟩3
along each of the four vertical sides. So the integral of the diﬀerence along the
vertical sides is majorized by
c
Z 2m
λ−1⟨m⟩
dy
my + c
Z 2m
λ−1⟨m⟩
ydy
m3 = O(m−1).
Along the two horizontal lines (the very top and the very bottom) σ vanishes
and ∥rw(z)(z −H)−1∥is of order m−2 so these integrals are O(m−1). Along
the parabolic curves σ ≡1 and the Taylor expansion yields
|rw(z) −˜rw(z)| ≤c y2
⟨x⟩3

374
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
as before. The integrals over each of these curves γ is majorized by
c
Z
γ
y2
⟨x⟩3
1
|y||dz| = cm−1
Z
γ
1
⟨x⟩2 |dz| = O(m−1).
□
12.7.7
The functional calculus.
We now show that the map f 7→f(H) has the desired properties of a functional
calculus, see Theorem 12.7.2 below. First some lemmas:
Lemma 12.7.4 If f is a smooth function of compact support which is disjoint
from the spectrum of H then f(H) = 0.
Proof.
We may ﬁnd a ﬁnite number of piecewise smooth curves which are
disjoint from the spectrum of H and which bound a region U which contains
the support of ˜f. Then by Stokes
f(H) = −1
π
Z
U
∂˜f
∂z R(z, H)dxdy =
−i
2π
Z
∂U
˜f(z)R(z, H)dz = 0
since ˜f vanishes on ∂U.
□
Lemma 12.7.5 For all f, g ∈A
(fg)(H) = f(H)g(H).
Proof. It is enough to prove this when f and g are smooth functions of compact
support. The product on the right is given by
1
π2
Z
K×L
∂˜f
∂z
∂˜g
∂wR(z, H)R(w, H)dxdydudv
where K := supp ˜f and L := supp ˜g are compact subsets of C. Apply the
resolvent identity in the form
R(z, H)R(w, H) = (z −w)−1R(w, H) −(z −w)−1R(z, w)
to the integrand to write the above integral as the sum of two integrals.
Using (12.15) the two “double” integrals become “single” integrals and the
whole expression becomes
f(H)g(H) = −1
π
Z
K∪L
(
˜f ∂˜g
∂z + ˜g ∂˜f
∂z
)
R(z, H)dxdy
= −1
π
Z
C
∂( ˜f˜g)
∂z
R(z, H)dxdy.

12.7. DAVIES’S PROOF OF THE SPECTRAL THEOREM
375
But (fg)(H) is deﬁned as
−1
π
Z
C
∂(fg)˜
∂z
R(z, H)dxdy.
But
(fg)˜−˜f˜g
is of compact support and is O(y2) so Lemma 12.7.3 implies our lemma.
□
Lemma 12.7.6
f(H) = f(H)∗.
This follows from R(z, H)∗= R(z, H).
□
Lemma 12.7.7
∥f(H)∥≤∥f∥∞
where ∥f∥∞denotes the sup norm of f.
Proof.
Choose c > ∥f∥∞and deﬁne
g(s) := c −
p
c2 −|f(s)|2.
Then g ∈A and
g2 = 2cg −|f|2
or
ff −cg −cg + g2 = 0.
By Lemma 12.7.5 and the preceding lemma this implies that
f(H)f(H)∗+ (c −g(H))∗(c −g(H)) = c2.
But then for any ψ in our Hilbert space,
∥f(H)ψ∥2 ≤∥f(H)ψ∥2 + ∥(c −g(H)ψ∥2 = c2∥ψ∥2
proving the lemma.
□
Let C0(R) denote the space of continuous functions which vanish at ∞with
∥·∥∞the sup norm. The algebra A is dense in C0(R) by Stone Weierstrass, and
the preceding lemma allows us to extend the map f 7→f(H) to all of C0(R).
Theorem 12.7.2 If H is a self-adjoint operator on a Hilbert space H then there
exists a unique linear map
f 7→f(H)
from C0(R) to bounded operators on H such that
1. The map f 7→f(H) is an algebra homomorphism,
2. f(H) = f(H)∗,

376
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
3. ∥f(H)∥≤∥f∥∞,
4. If w is a complex number with non-zero imaginary part and rw(x) = (w −
x)−1 then
rw(H) = R(w, H)
5. If the support of f is disjoint from the spectrum of H then f(H) = 0.
We have proved everything except the uniqueness. But item 4) determines the
map on the functions rw and the algebra generated by these functions is dense
by Stone Weierstrass.
□
In order to get the full spectral theorem we will have to extend this functional
calculus from C0(R) to a larger class of functions, for example to the class of
bounded measurable functions. In fact, Davies proceeds by using the theorem
we have already proved to get the spectral theorem in the form that says that
a self-adjoint operator is unitarily equivalent to a multiplication operator on
an L2 space and then the extended functional calculus becomes evident. First
some deﬁnitions:
12.7.8
Resolvent invariant subspaces.
Let H be a self-adjoint operator on a Hilbert space H, and let L ⊂H be a
closed subspace. We say that L is resolvent invariant if for all non-real z we
have R(z, H)L ⊂L.
If H is a bounded operator and L is invariant in the usual sense, i.e. HL ⊂L,
then for |z| > ∥H∥the Neumann expansion
R(z, H) = (zI −H)−1 = z−1(I −z−1H)−1 =
∞
X
n=0
z−n−1Hn
shows that R(z, H)L ⊂L. By analytic continuation this holds for all non-real z.
So if H is a bounded operator, if L is invariant in the usual sense it is resolvent
invariant.
We shall see shortly that conversely, if L is a resolvent invariant
subspace for a bounded self-adjoint operator then it is invariant in the usual
sense.
Lemma 12.7.8 If L is a resolvent invariant subspace for a (possibly unbounded)
self-adjoint operator then so is its orthogonal complement.
Proof.
If ψ ∈L⊥then for any φ ∈L we have
(R(z, H)ψ, φ) = (ψ, R(z, H)φ) = 0
if Im z ̸= 0 so R(z, H)ψ ∈L⊥.
□
Now suppose that H is a bounded self-adjoint operator and that L is a
resolvent invariant subspace. For f ∈L decompose Hf as Hf = g + h where
g ∈L and h ∈L⊥. The Lemma says that R(z, H)h ∈L⊥. But
R(z, H)h = R(z, H)(Hf −g) = R(z, H)(Hf −zf + zf −g)

12.7. DAVIES’S PROOF OF THE SPECTRAL THEOREM
377
= −f + R(z, H)(zf −g) ∈L
since f ∈L, zf −g ∈L and L is invariant under R(z, H). Thus R(z, H)h ∈
L∩L⊥so R(z, H)h = 0. But R(z, H) is injective so h = 0. We have shown that
if H is a bounded self-adjoint operator and L is a resolvent invariant subspace
then it is invariant under H.
So from now on we can drop the word “resolvent”. We will take the word “in-
variant” to mean “resolvent invariant” when dealing with possibly unbounded
operators. On bounded operators this coincides with the old notion of invari-
ance.
12.7.9
Cyclic subspaces.
We are going to perform a similar manipulation with the word “cyclic”.
Let v ∈H and H a (possibly unbounded) self-adjoint operator on H. We
deﬁne the cyclic subspace L generated by v to be the closure of the set of all
linear combinations of
R(z, H)v.
Lemma 12.7.9 v belongs to the cyclic subspace L that it generates.
Proof.
From the Hellfer-Sj¨ostrand formula it follows that f(H)v ∈L for all
f ∈A and hence for all f ∈C0(R). Choose fn ∈C0(R) such that 0 ≤fn ≤1
and such that fn →1 point-wise and uniformly on any compact subset as
n →∞. We claim that
lim
n→∞fn(H)v = v,
which would prove the lemma. To prove this, choose a sequence vm ∈Dom(H)
with vm →v and choose some non-real number z. Set
wm := (zI −H)vm,
so that vn = R(z, H)wn. Let rz be the function rz(s) = (z−s)−1 on R as above,
so vm = rz(H)wm.

378
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
Then
fn(H)v
=
fn(H)vm + fn(H)(v −vm)
=
fn(H)rz(H)wm + fn(H)(v −vm)
=
(fnrz)(H)wn + fn(H)(v −vm).
So
fn(H)v −v = [(fnrz)(H) −rz(H)]wm + (vm −v) + fn(H)(v −vm).
Now fnrz →rz in the sup norm on C0(R). So given ϵ > 0 we can ﬁrst choose
m so large that ∥vm −v∥< 1
3ϵ. Since the sup norm of fn is ≤1, the third
summand above is also less in norm that 1
3ϵ. We can then choose n suﬃciently
large that the ﬁrst term is also ≤1
3ϵ.
□
Clearly, L is the smallest (resolvent) invariant subspace which contains v.
Hence, if H is a bounded self-adjoint operator, L is the smallest closed subspace
containing all the Hnv.
So for bounded self-adjoint operators, we have not
changed the deﬁnition of cyclic subspace.
Proposition 12.7.1 Let H be a (possibly unbounded) self-adjoint operator on
a separable Hilbert space H. Then there exist a (ﬁnite or countable) family of
orthogonal cyclic subspaces Ln such that H is the closure of
M
n
Ln.
Proof.
Let fn be a countable dense subset of H and let L1 be the cyclic
subspace generated by f1. If L1 = H we are done. If not, there must be some
m for which fm ̸∈L1. Choose the smallest such m and let g2 be the orthogonal
projection of fm onto L⊥
1 . Let L2 be the cyclic subspace generated by g2. If
L1 ⊕L2 = H we are done. If not, there is some m for which fm ̸∈L1 ⊕L2.
choose the smallest such m and let g3 be the projection of fm onto the orthogonal
complement of L1 ⊕L2. Proceed inductively. Either this comes to an end with
H a ﬁnite direct sum of cyclic subspaces or it goes on indeﬁnitely. In either case
all the fi belong to the algebraic direct sum in the proposition and hence the
closure of this sum is all of H.
□

12.7. DAVIES’S PROOF OF THE SPECTRAL THEOREM
379
In terms of the decomposition given by the Proposition, let
Dn := Dom(H) ∩Ln
Let Hn denote the restriction of H to Dn. We claim that
• Dn is dense in Ln.
• Hn maps Dn into Ln and hence deﬁnes an operator on the Hilbert space
Ln.
• The operator Hn on the Hilbert space Ln with domain Dn is self-adjoint.
Proofs. For the ﬁrst item: let v be such that Ln is the closure of the span of
R(z, H)v, z ̸∈R. So R(z, H)v ∈Ln and R(z, H) ∈Dom(H). So the vectors
R(z, H)v belong to Dn and so Dn is dense in Ln.
For the second item, suppose that w ∈Dn. Let u = (zI −H)w for some
z ̸∈R so that w = R(z, H)u. In particular R(z, H)u ∈Ln. If we show that
u ∈Ln then it follows that Hw ∈Ln. Let u′ be the projection of u onto L⊥
n .
We want to show that u′ = 0. Since Ln is invariant and u −u′ ∈Ln we know
that R(z, H)(u −u′) ∈Ln and hence that R(z, H)u′ ∈Ln. But L⊥
n is invariant
by the lemma, and so R(z, H)u′ ∈Ln ∩L⊥
n so R(z, H)u′ = 0 and so u′ = 0.
To prove the third item we ﬁrst prove that if w ∈Dom(H) then the orthog-
onal projection of w onto Ln also belongs to Dom(H) and hence to Dn.
As in the proof of the second item, let u = (zI −H)w and u′ the orthogonal
projection of u onto the orthogonal complement of Ln. So w = R(z, H)u =
R(z, H)u′+R(z, H)(u−u′). But R(z, H)u′ is orthogonal to Ln and R(z, H)(u−
u′) ∈Ln. So the orthogonal projection of w onto Ln is R(z, H)(u −u′) which
belongs to Dom(H).
If w′ denotes the orthogonal projection of w onto the orthogonal complement
of Ln then Hw′ = HR(z, H)u′ = −u′ + zw′ and so Hw′ is orthogonal to Ln.
Now suppose that x ∈Ln is in the domain of H∗
n. This means that H∗
nx ∈Ln
and (H∗
nx, y) = (x, Hy) for all y ∈Dn. We want to show that x ∈Dom(H∗) =
Dom(H) for then we would conclude that x ∈Dn and so Hn is self-adjoint. But
for any w ∈Dom(H) we have
(x, Hw) = (x, Hw′ + H(w −w′)) = (x, H(w −w′))
= (x, Hn(w −w′)) = (H∗
nx, w)
since, by assumption, H∗
nx ∈Ln. This shows that x ∈Dom(H∗) and H∗x =
H∗
nx.
□
Now let us go back the the decomposition of H as given by Propostion 12.7.1.
This means that every f ∈H can be written uniquely as the (possibly inﬁnite)
sum
f = f1 + f2 + · · ·
with fi ∈Li.

380
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
Proposition 12.7.2 f ∈Dom(H) if and only if fi ∈Dom(Hi) for all i and
X
i
∥Hifi∥2 < ∞.
If this happens then the decompostion of Hf is given by
Hf = H1f1 + H2f2 + · · · .
Proof.
Suppose that f ∈Dom(H). We know that fn ∈Dom(Hn) and also
that the projection of Hf onto Ln is Hnfn. Hence
Hf = H1f1 + h2f2 + · · ·
and, in particular, P ∥Hnfn∥2 < ∞.
Conversely, suppose that fi ∈Dom(Hi) and P ∥Hnfn∥2 < ∞. Then f is
the limit of the ﬁnite sums f1 +· · ·+fN and the limit of the H(f1 +· · ·+fN) =
H1f1 + · · · HNfN exist. Since H is closed this implies that f ∈Dom(H) and
Hf is given by the inﬁnite sum Hf = H1f1 + H2 + · · · .
□
12.7.10
The spectral representation.
Let H be a self-adjoint operator on a seperable Hilbert space H, and let S
denote the spectrum of H. We will let h : S →R denote the function given by
h(s) = s.
We ﬁrst formulate and prove the spectral representation if H is cyclic.

12.7. DAVIES’S PROOF OF THE SPECTRAL THEOREM
381
Proposition 12.7.3 Suppose that H is cyclic with generating vector v. Then
there exists a ﬁnite measure µ on S and a unitary isomorphism
U : H →L2(S, µ)
such that ψ ∈H belongs to Dom(H) if and only if hU(ψ) ∈L2(S, µ). If so,
then with f = U(ψ) we have
UHU −1f = hf.
Proof.
Deﬁne the linear functional φ on C0(R) as
Φ(f) := (f(H)v, v).
We have φ(f) = φ(f). I f is non-negative and we set g := f
1
2 then φ(f) =
∥g(H)v∥2 ≥0. So by the Riesz representation theorem on linear functions on
C0 we know that there exists a ﬁnite non-negative countably additive measure
µ on R such that
(f(H)v, v) =
Z
R
fdµ
for all f ∈C0(R). If the support of f is disjoint from S then f(H) = 0. this
shows that µ is supported on S, the spectrum of H.
We have
Z
fgdµ = (g∗(H)f(H)v, v) = (f(H)v, g(H)v)
for f, g ∈C0(R).
Let M denote the linear subspace of H consisting of all f(H)v, f ∈C0(R).
The above equality says that there is an isometry U from M to C0(R) (relative
to the L2 norm) such that
U(f(H)) = f.
Since M is dense in H by hypothesis, this extends to a unitary operator U form
H to L2(S, µ).
Let f1, f2, f ∈C0(R) and set ψ2 = f1(H)v, ψ2 = f2(H)v. So fi = Uψi, i =
1, 2. Then
(f(H)ψ1, ψ2) =
Z
S
ff1f 2dµ.
Taking f = rw so that f(H) = R(w, H) we see that
UR(w, H)U −1g = rwg
for all g ∈L2(S, µ) and all non-real w. In particular, U maps the range of
R(w, H) which is Dom(H) onto the range of the operator of multiplication by
rx which is the set of all g such that xg ∈L2.
If f ∈L2(S, µ) then g = rwf ∈Dom(h) and every element of Dom(h) is of
this form. We now use our old friend, the formula
HR(w, H) = wR(w, H) −I.

382
CHAPTER 12. MORE ABOUT THE SPECTRAL THEOREM
Applied to U −1g this gives
HU −1g
=
HR(w, H)U −1f
=
−U −1f + wR(w, H)U −1f
=
−U −1f + U −1wrwf
=
U −1

w
w −x −1

f
=
U −1(hrwf)
=
U −1(hg).
□
We can now state and prove the general form of the spectral representation
theorem. Using the decomposition of H into cyclic subspaces and taking the
generating vectors to have norm 2−n we can proceed as we did last semester. We
can get the extension of the homomorphism f 7→f(H) to bounded measurable
functions by proving it in the L2 representation via the dominated convergence
theorem. This then gives projection valued measures etc.

Chapter 13
Scattering theory.
The purpose of this chapter is to give an introduction to the ideas of Lax and
Phillips which is contained in their beautiful book Scattering theory.
Throughout this chapter K will denote a Hilbert space and t 7→S(t), t ≥0
a strongly continuous semi-group of contractions deﬁned on K which tends
strongly to 0 as t →∞in the sense that
lim
t→∞∥S(t)k∥= 0
for each k ∈K.
(13.1)
13.1
Examples.
13.1.1
Translation - truncation.
Let N be some Hilbert space and consider the Hilbert space
L2(R, N).
Let Tt denote the one parameter unitary group of right translations:
[Ttf](x) = f(x −t)
and let P denote the operator of multiplication by 1(−∞,0] so P is projection
onto the subspace G consisting of the f which are supported on (−∞, 0]. We
claim that
t 7→PTt
is a semi-group acting on G satisfying our condition (13.1):
The operator PTt is a strongly continuous contraction since it is unitary
operator on L2(R, N) followed by a projection.
Also
∥PTtf∥2 =
Z −t
−∞
|f(x)|2dx
tends strongly to zero.
383

384
CHAPTER 13. SCATTERING THEORY.
We must check the semi-group property. Clearly PT0 =Id on G. We have
PTsPTtf = PTs[Ttf + g] = PTs+tf + PTsg
where
g = PTtf −Ttf
so
g ⊥G.
But
T−s : G →G
for s ≥0. Hence g ⊥G ⇒Tsg = T ∗
−sg ⊥G since
(T ∗
−sg, ψ) = (g, T−sψ) = 0
∀ψ ∈G.
13.1.2
Incoming representations.
The last argument is quite formal. We can axiomatize it as follows: Let H be a
Hilbert space, and t 7→U(t) a strongly continuous group one parameter group
of unitary operators on H. A closed subspace D ⊂H is called incoming with
respect to U if
U(t)D
⊂
D
for t ≤0
(13.2)
\
t
U(t)D
=
0
(13.3)
[
t
U(t)D
=
H.
(13.4)
Let PD : H →D denote orthogonal projection. The preceding argument goes
over unchanged to show that S deﬁned by
S(t) := PDU(t)
is a strongly continuous semi-group. We repeat the argument: The operator
S(t) is clearly bounded and depends strongly continuously on t. For s and t ≥0
we have
PDU(s)PDU(t)f = PDU(s)[U(t)f + g] = PDU(t + s)f + PDg
where
g := PDU(t)f −U(t)f ∈D⊥.
But g ∈D⊥⇒U(s)g ∈D⊥for s ≥0 since U(s)g = U(−s)∗g and
(U(−s)∗g, ψ) = (g, U(−s)ψ) = 0
∀ψ ∈D
by (13.2).

13.1. EXAMPLES.
385
We must prove that it converges strongly to zero as t →∞, i.e. that (13.1)
holds. First observe that (13.2) implies that
U(−s)D ⊃U(−t)D
if s < t
and since U(−s)D⊥= [U(−s)D]⊥we get
U(−s)D⊥⊂U(−t)D⊥.
We claim that
[
t>0
U(−t)D⊥
is dense in H. If not, there is an 0 ̸= h ∈H such that h ∈[U(−t)D⊥]⊥for all
t > 0 which says that U(t)h ⊥D⊥for all t > 0 or U(t)h ∈D for all t > 0 or
h ∈U(−t)D
for all t > 0
contradicting (13.3). Therefore, if f ∈D and ϵ > 0 we can ﬁnd g ⊥D and an
s > 0 so that
∥f −U(−s)g∥< ϵ
or
∥U(s)f −g∥< ϵ.
Since g ⊥D we have PD[U(s)f −g] = PDU(s)f and hence
∥PDU(s)f∥< ϵ,
proving that PDU(s) tends strongly to zero.
Comments about the axioms. Conditions (13.2)-(13.4) arise in several seem-
ingly unrelated areas of mathematics.
• In scattering theory - either classical where the governing equation is the
wave equation, or quantum mechanical where the governing equation is the
Schr¨odinger equation - one can imagine a situation where an “obstacle” or
a “potential” is limited in space, and that for any solution of the evolution
equation, very little energy remains in the regions near the obstacle as
t →−∞or as t →+∞. In other words, the obstacle (or potential) has
very little inﬂuence on the solution of the equation when |t| is large. We
can therefore imagine that for t << 0 the solution behaves as if it were a
solution of the “free” equation, one with no obstacle or potential present.
Thus the meaning of the space D in this case is that it represents the
subspace of the space of solutions which have not yet had a chance to
interact with the obstacle. The meaning of the conditions should be fairly
obvious,
• In data transmission: we are all familiar with the way an image comes in
over the internet; ﬁrst blurry and then with an increasing level of detail. In
wavelet theory we will encounter the concept of “multiresolution analysis”,
where the operators U provide an increasing level of detail.

386
CHAPTER 13. SCATTERING THEORY.
• We can allow for the possibility of more general concepts of “information”,
for example in martingale theory where the spaces U(t)D represent the
space of random variables available based on knowledge at time ≤t.
In the second example, it is more natural to allow t to range over the integers,
rather than over the real numbers. But in this lecture we will deal with the
continuous case rather than the discrete case. In the third example, we might
want to dispense with U(t) altogether, and just deal with an increasing family
of subspaces.
13.1.3
Scattering residue.
In the scattering theory example, we want to believe that at large future times
the “obstacle” has little eﬀect and so there should be both an “incoming space”
describing the situation long before the interaction with the obstacle, and also an
“outgoing space” reﬂecting behavior long after the interaction with the obstacle.
The residual behavior - i.e. the eﬀect of the obstacle - is what is of interest.
For example, in elementary particle physics, this might be observed as a blip in
the scattering cross-section describing a particle of a very short life-time. See
the very elementary discussion of the blip arising in the Breit-Wigner formula
below.
So let t 7→U(t) be a strongly continuous one parameter unitary group on
a Hilbert space H, let D−be an incoming subspace for U and let D+ be an
outgoing subspace (i.e. incoming for t 7→U(−t)). Suppose that
D−⊥D+
and let
K := [D−⊕D+]⊥= D⊥
−∩D⊥
+.
Let
P± :=
orthogonal projection onto D⊥
±.
Let
Z(t) := P+U(t)P−,
t ≥0.
Claim:
Z(t) : K →K.
Proof. Since P+ occurs as the leftmost factor in the deﬁnition of Z, the image
of Z(t) is contained in D⊥
+. We must show that
x ∈D⊥
−→P+U(t)x ∈D⊥
−
since Z(t)x = P+U(t)x as P−x = x if x ∈D⊥
−. Now U(−t) : D−→D−for
t ≥0 is one of the conditions for incoming, and so
U(t) : D⊥
−→D⊥
−.

13.2. BREIT-WIGNER.
387
So
U(t)x ∈D⊥
−.
Since D−⊂D⊥
+ the projection P+ is the identity on D−, in particular
P+ : D−→D−
and hence, since P+ is self-adjoint,
P+ : D⊥
−7→D⊥
−.
Thus P+U(t)x ∈D⊥
−as required. QED
By abuse of language, we will now use Z(t) to denote the restriction of Z(t)
to K. We claim that t 7→Z(t) is a semi-group. Indeed, we have
P+U(t)P+x = P+U(t)x + P+U(t)[P+x −x] = P+U(t)x
since [P+x −x] ∈D+ and U(t) : D+ →D+ for t ≥0. Also Z(t) = P+U(t) on
K since P−is the identity on K. Therefore we may drop the P−on the right
when restricting to K and we have
Z(s)Z(t) = P+U(s)P+U(t) = P+U(s)U(t) = P+U(s + t) = Z(s + t)
proving that Z is a semigroup.
We now show that Z is strongly contracting. For any x ∈H and any ϵ > 0
we can ﬁnd a T > 0 and a y ∈D+ such that
∥x −U(−T)y∥< ϵ
since S
t<0 U(t)D+ is dense. For x ∈K we get
∥Z(t)x −P+U(t)U(−T)y∥= ∥P+U(t)[x −U(−T)y]∥< ϵ.
But for t > T
U(t)U(−T)y = U(t −T)y ∈D+
so P+U(t)U(−T)y = 0
and hence
∥Z(t)x∥< ϵ.
We have proved that Z is a strongly contractive semi-group on K which tends
strongly to zero, i.e. that(13.1) holds.
13.2
Breit-Wigner.
The example in this section will be of primary importance to us in computations
and will also motivate the Lax-Phillips representation theorem to be stated and
proved in the next section.

388
CHAPTER 13. SCATTERING THEORY.
Suppose that K is one dimensional, and that
Z(t)d = e−µtd
for d ∈K where
ℜµ > 0.
This is obviously a strongly contractive semi-group in our sense. Consider the
space L2(R, N) where N is a copy of K but with the scalar product whose norm
is
∥d∥2
N = 2ℜµ∥d∥2.
Let
fd(t) =

eµtd
t ≤0
0
t > 0.
Then
∥fd∥2 =
Z 0
−∞
e2ℜµt(2ℜµ)∥d∥2dt = ∥d∥2
so the map
R : K →L2(R, N) d 7→fd
is an isometry. Also
P(Ttfd)(s) = Pfd(s −t) = e−µtfd(s)
so
(PTt) ◦R = R ◦Z(t).
This is an example of the representation theorem in the next section.
If we take the Fourier transform of fd we obtain the function
σ 7→
1
√
2π
1
µ −iσ d
whose norm as a function of σ is proportional to the Breit-Wigner function
1
µ2 + σ2 .
It is this “bump” appearing in graph of a scattering experiment which signiﬁes a
“resonance”, i.e. an “unstable particle” whose lifetime is inversely proportional
to the width of the bump.
13.3
The representation theorem for strongly con-
tractive semi-groups.
Let t 7→S(t) be a strongly contractive semi-group on a Hilbert space K. We
want to prove that the pair K, S is isomorphic to a restriction of Example 1.

13.3. THE REPRESENTATION THEOREM FOR STRONGLY CONTRACTIVE SEMI-GROUPS.389
Theorem 13.3.1 [Lax-Phillips.]
There exists a Hilbert space N and an
isometric map R of K onto a subspace of PL2(R, N) such that
S(t) = R−1PTtR
for all t ≥0.
Proof.
Let B be the inﬁnitesimal generator of S, and let D(B) denote the
domain of B. The sesquilinear form f, g 7→
−(Bf, g) −(f, Bg)
is non-negative deﬁnite since B satisﬁes
Re (Bf, f) ≤0.
Dividing out by the null vectors and completing gives us a Hilbert space N
whose scalar product we will denote by ( , )N. If k ∈D(B) so is S(t)k for every
t ≥0. Let us deﬁne
fk(−t) = [S(t)k]
where [S(t)k] denotes the element of N corresponding to S(t)k. For simplicity
of notation we will drop the brackets and simply write
fk(−t) = S(t)k
and think of f as a map from (−∞, 0] to N. We have
∥f(−t)∥2
N = ∥S(t)k∥2
N = −2Re (BS(t)k, S(t)k)N = −d
dt∥S(t)k∥2.
Integrating this from 0 to r gives
Z 0
−r
∥f(s)∥2
N = ∥k∥2 −∥S(r)k∥2.
By hypothesis, the second term on the right tends to zero as r →∞. This
shows that the map
R : k 7→fk
is an isometry of D(B) into L2((−∞, 0], N), and since D(B) is dense in K, we
conclude that it extends to an isometry of D with a subspace of PL2(R, N) (by
extension by zero, say). Also
RS(t)k = fS(t)k
is given by
fS(t)k(s) = S(−s)S(t)k = S(t −s)k = S(−(s −t)k) = fk(s −t)
for s < 0, and t > 0 so
RS(t)k = PTtRk.
Thus R(K) is an invariant subspace of PL2(R, N) and the intertwining equation
of the theorem holds. QED
We can strengthen the conclusion of the theorem for elements of D(B):

390
CHAPTER 13. SCATTERING THEORY.
Proposition 13.3.1 If k ∈D(B) then fk is continuous in the N norm for
t ≤0.
Proof.
For s, t > 0 we have
∥fk(−s) −fk(−t)∥2
N = −2Re (B[S(t) −S(s)]k, [S(t) −S(s)]k)
≤2∥[S(t) −S(s)]Bk∥∥[S(t) −S(s)]k∥
by the Cauchy-Schwarz inequality. Since S is strongly continuous the result
follows. QED
Let us apply this construction to the semi-group associated to an incoming
space D for a unitary group U on a Hilbert space H. Let d ∈D and fd = Rd
as above. We know that U(−r)d ∈D for r > 0 by (13.2). Notice also that
S(r)U(−r)d = PU(r)U(−r)d = Pd = d
for d ∈D. Then for t ≤−r we have, by deﬁnition,
fU(−r)d(t) = S(−t)U(−r)d = PU(−t)U(−r)d
= S(−t −r)d = fd(t + r)
and so by the Lax-Phillips theorem,
∥U(−r)d∥2
D =
Z 0
−∞
∥fU(−r)d∥2
Ndx ≥
Z −r
−∞
∥fU(−r)d(x)∥2
Ndx
=
Z 0
−∞
|fd(x)|2
Ndx = ∥d∥2.
Since U(−r) is unitary, we have equality throughout which implies that
fU(−r)d(t) = 0
if t > −r.
We have thus proved that if
r > 0
then
fU(−r)d(t) =
 fd(t + r)
if
t ≤−r
0
if
−r < t ≤0 .
(13.5)
13.4
The Sinai representation theorem.
This says that

13.4. THE SINAI REPRESENTATION THEOREM.
391
Theorem 13.4.1 If D is an incoming subspace for a unitary one parameter
group, t 7→U(t) acting on a Hilbert space H then there is a Hilbert space N, a
unitary isomorphism
R : H →L2(R, N)
such that
RU(t)R−1 = Tt
and
R(D) = PL2(R, N),
where P is projection onto the subspace consisting of functions which vanish on
(0, ∞] a.e.
Proof.
We apply the results of the last section. For each d ∈D we have
obtained a function fd ∈L2((−∞, 0], N) and we extend fd to all of R by
setting fd(s) = 0 for s > 0. We thus deﬁned an isometric map R from D onto
a subspace of L2(R, N). Now extend R to the space U(r)D by setting
R(U(r)d)(t) = fd(t −r).
Equation (13.5) assures us that this deﬁnition is consistent in that if d is such
that U(r)d ∈D then this new deﬁnition agrees with the old one. We have thus
extended the map R to S U(t)D as an isometry satisfying
RU(t) = TtR.
Since S U(t)D is dense in H the map R extends to all of H. Also by construction
R ◦PD = P ◦R
where P is projection onto the space of functions supported in (−∞, 0] as in
the statement of the theorem.
We must still show that R is surjective. For this it is enough to show that
we can approximate any simple function with values in N by an element of
the image of R. Recall that the elements of the domain of B, the inﬁnitesimal
generator of PDU(t), are dense in N, and for d ∈D(B) the function fd is
continuous, satisﬁes f(t) = 0 for t > 0, and f(0) = n where n is the image of d
in N. Hence
(I −P)U(δ)d
is mapped by R into a function which is approximately equal to n on [0, δ] and
zero elsewhere. Since the image of R is translation invariant, we see that we can
approximate any simple function by an element of the image of R, and since R
is an isometry, the image of R must be all of L2(R, N).

392
CHAPTER 13. SCATTERING THEORY.
13.5
The Stone - von Neumann theorem.
Let us show that the Sinai representation theorem implies a version (for n = 1)
of the Stone - von Neumann theorem:
Theorem 13.5.1 Let {U(t)} be a one parameter group of unitary operators,
and let B be a self-adjoint operator on a Hilbert space H. Suppose that
U(t)BU(−t) = B −tI.
(13.6)
Then we can ﬁnd a unitary isomorphism R of H with L2(R, N) such that
RU(t)R−1 = Tt
and
RBR−1 = mx,
where mx is multiplication by the independent variable x.
Remark. If iA denotes the inﬁnitesimal generator of U, then diﬀerentiating
(13.6) with respect to t and setting t = 0 gives
[A, B] = iI
which is a version of the Heisenberg commutation relations.
So (13.6) is a
“partially integrated” version of these commutation relations, and the theorem
asserts that (13.6) determines the form of U and B up to the possible “multi-
plicity” given by the dimension of N.
Proof. By the spectral theorem, write
B =
Z
λdEλ
where {Eλ} is the spectral resolution of B, and so we obtain the spectral reso-
lutions
U(t)BU(−t) =
Z
λd[U(t)EλU(−t)]
and
B −tI =
Z
(λ −t)dEλ =
Z
λdEλ+t
by a change of variables.
We thus obtain
U(t)EλU(−t) = Eλ+t.
Remember that Eλ is orthogonal projection onto the subspace associated to
(−∞, λ] by the spectral measure associated to B. Let D denote the image of E0.
Then the preceding equation says that U(t)D is the image of the projection Et.
The standard properties of the spectral measure - that the image of Et increase
with t, tend to the whole space as t →∞and tend to {0} as t →−∞are exactly
the conditions that D be incoming for U(t). Hence the Sinai representation

13.5. THE STONE - VON NEUMANN THEOREM.
393
theorem is equivalent to the Stone - von -Neumann theorem in the above form.
QED
Historically, Sinai proved his representation theorem from the Stone - von
Neumann theorem. Here, following Lax and Phillips, we are proceeding in the
reverse direction.

