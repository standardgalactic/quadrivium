FREE 
DOWNLOAD
Designing for 
the Internet 
of Things
Simon King & Kuen Chang
Understanding 
Industrial  
Design
PRINCIPLES FOR UX AND  
INTERACTION DESIGN
Claire Rowland,
Elizabeth Goodman,
Martin Charlier,
Alfred Lui & Ann Light
Designing 
Connected 
Products
UX FOR THE CONSUMER  
INTERNET OF THINGS
s
The Implications
Software Above 
the Level of  
a Single Device
Tim O’Reilly
Adam Connor & 
 Aaron Irizarry
 Discussing 
Design
IMPROVING COMMUNICATION  
& COLLABORATION THROUGH CRITIQUE
A Curated Collection of Chapters 
from the O’Reilly Design Library

©2016 O’Reilly Media, Inc. The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. D1813
Short. Smart. 
Seriously useful.
Free ebooks and reports from O’Reilly 
at oreil.ly/fr-design
Data-Informed 
Product Design
Pamela Pavliscak
Laura Klein
Design for  
Voice Interfaces
Building Products that Talk
Free ebooks, reports and other articles​ on UX design,
data-informed design, and design for the IoT.
Get insights from industry experts and stay current
with the latest developments from O’Reilly.

	  
Designing for the Internet of Things 
A Curated Collection of Chapters  
from the O'Reilly Design Library 
Learning the latest methodologies, tools, and techniques is critical for 
IoT design, whether you’re involved in environmental monitoring, 
building automation, industrial equipment, remote health monitoring 
devices, or an array of other IoT applications. The O’Reilly Design Library 
provides experienced designers with the knowledge and guidance you 
need to build your skillset and stay current with the latest trends. 
This free ebook gets you started. With a collection of chapters from the 
library’s published and forthcoming books, you’ll learn about the scope 
and challenges that await you in the burgeoning IoT world, as well as 
the methods and mindset you need to adopt. The ebook includes 
excerpts from the following books. 
	  
	  

	  
	  
For more information on current and forthcoming Design content, 
check out www.oreilly.com/design 
 
Mary Treseler 
Strategic Content Lead 
mary@oreilly.com 
 
 
 

	  
Designing for Emerging Technologies 
Available now: http://shop.oreilly.com/product/0636920030676.do 
Chapter 5. Learning and Thinking with Things 
Chapter 13. Architecture as Interface 
Chapter 14. Design for the Networked World 
Designing Connected Products 
Available in Early Release: http://shop.oreilly.com/product/0636920031109.do 
Chapter 4. Product/Service Definition and Strategy 
Chapter 9. Cross-Device Interactions and Interusability 
 
Discussing Design 
Available in Early Release: http://shop.oreilly.com/product/0636920033561.do 
Chapter 1. Understanding Critique 
Chapter 2. What Critique Looks Like 
Understanding Industrial Design 
Available soon  
Chapter 1. Introduction: Historical Background on Industrial and    
Interaction Design 
Chapter 2. Sensorial: Engage as Many Senses as Possible 
Software Above the Level of a Single Device 
Available now: http://www.oreilly.com/iot/free/software-above-device.csp 
 
 
 

Jonathan Follett, Editor
Foreword by Saul Kaplan
Designing for 
Emerging 
Technologies
UX FOR GENOMICS, ROBOTICS, AND 
THE INTERNET OF THINGS 

Beijing · Cambridge · Farnham · Köln · Sebastopol · Tokyo
Designing for Emerging 
Technologies
UX for Genomics, Robotics, and the 
Internet of Things
Edited by Jonathan Follett

 vii
[ Contents ]
Foreword . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . . . . . . . . . . . . . . . . . . . . . . . . xiii
Preface . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . . . . . . . . . . . . . . . . . . . . . . . . . xv
Chapter 1	
Designing for Emerging Technologies . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 1
by Jonathan Follett
A Call to Arms. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 1
Design for Disruption. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 3
Eight Design Tenets for Emerging Technology. .  .  .  .  .  .  .  .  . 8
Changing Design and Designing Change. .  .  .  .  .  .  .  .  .  .  .  .  26
Chapter 2	
Intelligent Materials: Designing Material Behavior . .  .  27
by Brook Kennedy
Bits and Atoms . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  27
Emerging Frontiers in Additive Manufacturing. .  .  .  .  .  .  32
Micro Manufacturing . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  33
Dynamic Structures and Programmable Matter. .  .  .  .  .  34
Connecting the Dots: What Does Intelligent 
Matter Mean for Designers?. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  37
Conclusion. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  41
Chapter 3	
Taking Control of Gesture Interaction. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  43
by Gershom Kutliroff and Yaron Yanai
Reinventing the User Experience. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  43
Analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .46
Prototyping. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  47
A Case Study: Gesture Control. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  50
Trade-offs. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  61
Looking Ahead . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  62

viii  |   CONTENTS
Chapter 4	
Fashion with Function: Designing for Wearables. . . . . .65
by Michal Levin
The Next Big Wave in Technology. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  65
The Wearables Market Segments. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  66
Wearables Are Not Alone. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  71
UX (and Human) Factors to Consider. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  73
Summary. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  113
Chapter 5	
Learning and Thinking with Things . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  115
by Stephen P. Anderson
Tangible Interfaces. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  115
(Near) Future Technology . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  125
Timeless Design Principles?. . . . . . . . . . . . . . . . . . . . . . . . . .130
Farther Out, a Malleable Future. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  136
Nothing New Under the Sun. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  137
Closing . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  138
Chapter 6	
Designing for Collaborative Robotics. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  139
by Jeff Faneuff
Introduction. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  139
Designing Safety Systems for Robots. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  143
Humanlike Robots . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  154
Human-Robot Collaboration . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  158
Testing Designs by Using Robotics Platforms. .  .  .  .  .  .  .  165
Future Challenges for Robots Helping People . .  .  .  .  .  .  172
Conclusion. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  174
Robotics Resources. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  175
Chapter 7	
Design Takes on New Dimensions:
Evolving Visualization Approaches for 
Neuroscience and Cosmology . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  177
by Hunter Whitney
The Brain Is Wider Than the Sky . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  177
Section 1: An Expanding Palette for Visualization . .  .  179
Section 2: Visualizing Scientific Models (Some 
Assembly Required). .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  188

 CONTENTS   |  ix
Section 3: Evolving Tools, Processes, 
and Interactions. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  194
Conclusion. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 202
Chapter 8	
Embeddables: The Next Evolution of 
Wearable Tech. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  205
by Andy Goodman
Technology That Gets Under Your Skin. .  .  .  .  .  .  .  .  .  .  .  .  . 205
Permeable Beings: The History of Body 
Modification. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 208
Decoration, Meaning, and Communication. .  .  .  .  .  .  .  .  . 209
Optimization and Repair. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  213
The Extended Human. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  216
Just Science Fiction, Right?. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  224
Key Questions to Consider . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  224
Chapter 9	
Prototyping Interactive Objects. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 225
by Scott Sullivan
Misconceptions Surrounding Designers 
Learning to Code. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 226
Chapter 10	
Emerging Technology and Toy Design . .  .  .  .  .  .  .  .  .  .  .  .  .  .  237
by Barry Kudrowitz
The Challenge of Toy Design. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  237
Toys and the S-Curve. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  239
Toys and Intellectual Property. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  241
Emerging Technologies in Toy Design. .  .  .  .  .  .  .  .  .  .  .  .  .  .  242
Inherently Playful Technology. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  247
Sensors and Toy Design. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 248
Emerging Technology in Production and 
Manufacturing . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  250
Summary. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  253
Chapter 11	
Musical Instrument Design . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  255
by Camille Goudeseune
Experience Design and Musical Instruments. .  .  .  .  .  .  .  255
The Evolution of the Musician. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  258
Conclusion. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  272

x  |   CONTENTS
Chapter 12	
Design for Life. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 273
by Juhan Sonin
Bloodletting to Bloodless. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  273
The Surveillance Invasion. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  278
Life First—Health a Distant Second. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  281
Stage Zero Detection. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 284
From Protein to Pixel to Policy . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 286
Final Thoughts . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 287
Chapter 13	
Architecture as Interface: Advocating a Hybrid 
Design Approach for Interconnected 
Environments . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  289
by Erin Rae Hoffer
The Blur of Interconnected Environments. .  .  .  .  .  .  .  .  .  . 289
Theorizing Digital Culture: New Models of 
Convergence. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  292
Hybrid Design Practice. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  295
Changing Definitions of Space. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 300
A Framework for Interconnected Environments . .  .  .  .  301
Spheres of Inquiry. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  303
An Exercise in Hybrid Design Practice. .  .  .  .  .  .  .  .  .  .  .  .  .  . 305
Architecture as Interface. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  307
Conclusion. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 309
References. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  310
Chapter 14	
Design for the Networked World: A Practice for 
the Twenty-First Century. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  313
by Matt Nish-Lapidus
The Future of Design. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  313
New Environment, New Materials. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  316
New Tools for a New Craft. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  325

 CONTENTS   |  xi
Chapter 15	
New Responsibilities of the Design Discipline: 
A Critical Counterweight to the Coming 
Technologies?. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  331
by Martin Charlier
Critiquing Emerging Technology. . . . . . . . . . . . . . . . . . . . .331
Emerging Technologies . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  333
New Responsibilities of the Design Discipline. .  .  .  .  .  .  343
Bibliography. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  345
Chapter 16	
Designing Human-Robot Relationships. .  .  .  .  .  .  .  .  .  .  .  .  .  347
by Bill Hartman
Me Man, You Robot: Designers Creating 
Powerful Tools. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 348
Me Man, You Robot? Developing Emotional 
Relationships with Robots. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  354
Me Robot? On Becoming Robotic. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  358
Into the Future . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 360
Your Robot: Consider Nielsen, Maslow, and 
Aristotle . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  361
Conclusion. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 364
Chapter 17	
Tales from the Crick: Experiences and Services 
When Design Fiction Meets Synthetic Biology. .  .  .  .  .  .  365
by Marco Righetto and Andy Goodman
Design Fictions as a Speculative Tool to Widen 
the Understanding of Technology. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  365
The Building Bricks of the Debate . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 366
Healthcare Narratives: From Scenarios to 
Societal Debates. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  373
Living Objects: Symbiotic Indispensable 
Companions. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  376
Chapter 18	
Beyond 3D Printing: The New Dimensions of 
Additive Fabrication . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  379
by Steven Keating
MIT and the Mediated Matter Group: Previous 
and Current Additive Fabrication Research . .  .  .  .  .  .  .  .  .  379
The Dimensions of Additive Fabrication. .  .  .  .  .  .  .  .  .  .  .  . 380
Conclusion. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 402

xii  |   CONTENTS
Chapter 19	
Become an Expert at Becoming an Expert. .  .  .  .  .  .  .  .  .  .  . 407
by Lisa deBettencourt
Into the Fire . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 408
Eating the Elephant. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  410
Onward. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  425
Chapter 20	
The Changing Role of Design. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  427
by Dirk Knemeyer
On the Impact of Emerging Technologies. .  .  .  .  .  .  .  .  .  .  .  427
Design Complexity and Emerging Technologies. .  .  .  .  431
Design Trends for Emerging Technologies. .  .  .  .  .  .  .  .  .  .  433
User Experience: Finding Its Level. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  436
The Future for Me, the Future for You . .  .  .  .  .  .  .  .  .  .  .  .  .  .  437
Appendix A: Companies, Products, and Links . .  .  .  .  . . . . . 439
Index. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . . . . . . . . . . . . . . . . . . . . . . . . . 445

115
[ 5 ]
Learning and Thinking with Things
STEPHEN P. ANDERSON
Tangible Interfaces
The study of how humans learn is nothing new and not without many 
solid advances. And yet, in the rush to adopt personal computers, tab­
lets, and similar devices, we’ve traded the benefits of hands-on learn­
ing and instruction for the scale, distribution, and easy data collection 
that’s part and parcel to software programs. The computational bene­
fits of computers have come at a price; we’ve had to learn how to interact 
with these machines in ways that would likely seem odd to our ances­
tors: mice, keyboards, awkward gestures, and many other devices and 
rituals that would be nothing if not foreign to our predecessors. But 
what does the future hold for learning and technology? Is there a way 
to reconcile the separation between all that is digital with the diverse 
range of interactions for which our bodies are capable? And how does 
the role of interaction designer change when we’re working with smart, 
potentially shape-shifting, objects? If we look at trends in technology, 
especially related to tangible computing (where physical objects are 
interfaced with computers), they point to a sci-fi future in which inter­
actions with digital information come out from behind glass to become 
things we can literally grasp.
One such sign of this future comes from Vitamins, a multidisciplinary 
design and invention studio based in London. As Figure 5-1 shows, it 
has developed a rather novel system for scheduling time by using… 
what else… Lego bricks!

116  |   DESIGNING FOR EMERGING TECHNOLOGIES
Figure 5-1. Vitamins Lego calendar1
Vitamins describes their Lego calendar as the following:
…a wall-mounted time planner, made entirely of Lego blocks, but if you 
take a photo of it with a smartphone, all of the events and timings will 
be magically synchronized to an online digital calendar.
Although the actual implementation (converting a photo of colored 
bricks into Google calendar information) isn’t in the same technical 
league as nanobots or mind-reading interfaces, this project is quite sig­
nificant in that it hints at a future in which the distinctions between 
physical and digital are a relic of the past. 
Imagine ordinary objects—even something as low-tech as Lego 
bricks—augmented with digital properties. These objects could iden­
tify themselves, trace their history, and react to different configura­
tions. The possibilities are limitless. This is more than an “Internet of 
Things,” passively collecting data; this is about physical objects catch­
ing up to digital capabilities. Or, this is about digital computing get­
ting out from behind glass. However you look at this, it’s taking all 
that’s great about being able to pick up, grasp, squeeze, play with, spin, 
1	 http://www.lego-calendar.com

 5. Learning and Thinking with Things   |  117
push, feel, and do who-knows-what-else to a thing, while simultane­
ously enjoying all that comes with complex computing and sensing 
capabilities.
Consider two of the studio’s design principles (from the company’s 
website) that guided this project:
• It had to be tactile: “We loved the idea of being able to hold a bit of 
time, and to see and feel the size of time”
• It had to work both online and offline: “We travel a lot, and we want 
to be able to see what’s going on wherever we are.”
According to Vitamins, this project “makes the most of the tangibility 
of physical objects, and the ubiquity of digital platforms, and it also 
puts a smile on our faces when we use it!”2 Although this project and 
others I’ll mention hint at the merging of the physical and the digital, 
it’s important to look back and assess what has been good in the move 
from physical to digital modes of interaction—and perhaps what has 
been lost.
KANBAN WALLS, CHESS, AND OTHER TANGIBLE INTERACTIONS
Oddly enough, it is the software teams (the folks most immersed in 
the world of virtual representations) who tend to favor tangibility when 
it comes to things such as project planning; it’s common for Agile or 
Scrum development teams to create Kanban walls, such as that shown 
in Figure 5-2. Imagine sticky notes arranged in columns, tracking the 
progress of features throughout the development cycle, from backlog 
through to release. Ask most teams and they will say there is some­
thing about the tangibility of these sticky notes that cannot be repli­
cated by virtual representations.
There’s something about moving and arranging this sticky little square, 
feeling the limitations of different size marker tips with respect to how 
much can be written, being able to huddle around a wall of these sticky 
notes as a team—there’s something to the physical nature of working 
with sticky notes. But, is there any explanation as to “why” this tangi­
ble version might be advantageous, especially where understanding is 
a goal?
2	 http://www.special-projects-studio.com

118  |   DESIGNING FOR EMERGING TECHNOLOGIES
Figure 5-2. Kanban walls3 and chess4
3	 Photo by Jennifer Morrow (https://www.flickr.com/photos/asadotzler/8447477253) CC-
BY-2.0 (http://creativecommons.org/licenses/by/2.0)
4	 Photo by Dean Strelau (https://www.flickr.com/photos/dstrelau/5859068224) CC-BY-2.0 
(http://creativecommons.org/licenses/by/2.0)

 5. Learning and Thinking with Things   |  119
Before answering that question, first consider this question: where 
does thinking occur?
If your answer is along the lines of “in the brain,” you’re not alone. This 
view of a mind that controls the body has been the traditional view of 
cognition for the better part of human history. In this view, the brain 
is the thinking organ, and as such it takes input from external stimuli, 
processes those stimuli, and then directs the body as to how to respond.
Thinking; then doing.
But, a more recent and growing view of cognition rejects this notion of 
mind-body dualism. Rather than thinking and then doing, perhaps we 
think through doing. 
Consider the game of chess. Have you ever lifted up a chess piece, 
hovered over several spots where you could move that piece, only to 
return that piece to the original space, still undecided on your move? 
What happened here? For all that movement, there was no pragmatic 
change to the game. If indeed we think and then do (as mind-body 
dualism argues), what was the effect of moving that chess piece, given 
that there was no change in the position? If there is no outward change 
in the environment, why do we instruct our bodies to do these things? 
The likely answer is that we were using our environment to extend our 
thinking skills. By hovering over different options, we are able to more 
clearly see possible outcomes. We are extending the thinking space to 
include the board in front of us.
Thinking through doing.
This is common in chess. It’s also common in Scrabble, in which a 
player frequently rearranges tiles in order to see new possibilities.
Let’s return to our Kanban example.
Even though many cognitive neuroscientists (as well as philosophers 
and linguists) would likely debate a precise explanation for the appeal 
of sticky notes as organizational tools, the general conversation would 
shift the focus away from the stickies themselves to the role of our 
bodies in this interaction, focusing on how organisms and the human 
mind organize themselves by interacting with their environment. This 
perspective, generally described as embodied cognition, postulates that 
thinking and doing are so closely linked as to not be serial processes. 
We don’t think and then do; we think through doing.

120  |   DESIGNING FOR EMERGING TECHNOLOGIES
But there’s more to embodied cognition than simply extending our 
thinking space. When learning is embodied, it also engages more of 
our senses, creating stronger neural networks in the brain, likely to 
increase memory and recall.
Moreover, as we continue to learn about cognition ailments such as 
autism, ADHD, or sensory processing disorders, we learn about this 
mind-body connection. With autism for example, I’ve heard from par­
ents who told me that learning with tangible objects has been shown to 
be much more effective for kids with certain types of autism.
Our brain is a perceptual organ that relies on the body for sensory 
input, be it tangible, auditory, visual, spatial, and so on. Nowhere is the 
value of working with physical objects more understood than in early 
childhood education, where it is common to use “manipulatives”—tan­
gible learning objects—to aid in the transfer of new knowledge.
MANIPULATIVES IN EDUCATION
My mother loves to recall my first day at Merryhaven Montessori, the 
elementary school I attended through the sixth grade. I recall her ask­
ing, “What did you learn today?” I also remember noticing her curios­
ity at my response: “I didn’t learn anything—we just played!”
Of course “playing” consisted of tracing sandpaper letters, cutting a 
cheese slice into equal parts, and (my favorite) counting beads; I could 
count with single beads, rods consisting of 10 beads, the flat squares of 
100 beads (or 10 rods, I suppose), and the mammoth of them all: a giant 
cube of 1000 beads! (See Figure 5-3.) These “manipulatives” are core to 
the Montessori method of education, and all examples—dating back to 
the late 1800s—of learning through tangible interactions. Playing is 
learning, and these “technologies” (in the anthropological sense) make 
otherwise abstract concepts quite, concrete.
But why is this so?
Jean Piaget, the influential Swiss developmental psychologist, talks 
about stages of development, and how learning is—at the earliest 
ages—physical (sensorimotor). As babies, we grasp for things and 
make sense of the world through our developing senses. At this stage, 
we learn through physical interactions with our environment. This 
psychological theory, first proposed in the 1960s, is supported by recent 
advances in cognitive neuroscience and theories about the mind and 
body. 

 5. Learning and Thinking with Things   |  121
Figure 5-3. Montessori beads5
Essentially, we all start off understanding the world only through phys­
ical (embodied) interactions. As infants, even before we can see, we are 
grasping at things and seeking tactile comforts. We learn through our 
physical interactions with our environment.
Contrast this with the workbooks and photocopied assignments com­
mon in most public schools. These pages represent “what” students 
should be learning, but ignore the cognitive aspects of “how” we learn, 
namely through interactions. Much of learning is cause and effect. 
Think of the young child who learns not to touch a hot stove either 
through her own painful experience or that of a sibling. It is through 
interactions and experimentation (or observing others) that we begin 
to recognize patterns and build internal representations of otherwise 
abstract ideas.
Learning is recognizing or adding to our collection of patterns. 
5	 As featured on Montessori Outlet (http://www.montessorioutlet.com)

122  |   DESIGNING FOR EMERGING TECHNOLOGIES
In this regard, computers can be wonderful tools for exploring pos­
sibilities. This is true of young children playing with math concepts, 
to geneticists looking for patterns in DNA strands. Interactive models 
and simulations are some of the most effective means of sensemak­
ing. Video games also make for powerful learning tools because they 
create possibility spaces where players can explore potential outcomes. 
Stories such as Ender’s Game (in which young children use virtual 
games to explore military tactics) are a poignant testimony to the nat­
ural risk-taking built into simulations. “What happens if I push this?” 
“Can we mix it with…?” “Let’s change the perspective.” Computers 
make it possible for us to explore possibilities much more quickly in a 
playful, risk-free manner. In this regard, physical models are crude and 
limiting. Software, by nature of being virtual, is limited only by what 
can be conveyed on a screen.
But, what of the mind-body connection? What about the means by 
which we explore patterns through a mouse or through our fingertips 
sliding across glass? Could this be improved? What about wood splin­
ters and silky sheets and hot burners and stinky socks and the way 
some objects want to float in water—could we introduce sensations like 
these into our interactions? For all the brilliance of virtual screens, they 
lack the rich sensory associations inherent in the physical world.
VIRTUAL MANIPULATIVES
For me, it was a simple two-word phrase that brought these ideas into 
collision: “virtual manipulatives.” During an interview with Bill Gates, 
Jessie Woolley-Wilson, CEO of DreamBox, shared a wonderful exam­
ple of the adaptive learning built in to their educational software. Her 
company’s online learning program will adapt which lesson is recom­
mended next based not only the correctness of an answer, but by “cap­
turing the strategies that students [use] to solve problems, not just that 
they get it right or wrong.” Let’s suppose we’re both challenged to count 
out rods and beads totaling 37. As Wooley-Wilson describes it:
You understand groupings and you recognize 10s, and you very quickly 
throw across three 10’s, and a 5 and two 1’s as one group. You don’t ask 
for help, you don’t hesitate, your mouse doesn’t hesitate over it. You 
do it immediately, ready for the next. I, on the other hand, am not as 
confident, and maybe I don’t understand grouping strategies. But I do 

 5. Learning and Thinking with Things   |  123
know my 1’s. So I move over 37 single beads. Now, you have 37 and I 
have 37, and maybe in a traditional learning environment we will both 
go to the next lesson. But should we?
By observing how a student arrives at an answer, by monitoring move­
ments of the mouse and what students “drag” over, the system can 
determine if someone has truly mastered the skill(s) needed to move 
on. This is certainly an inspiring example of adaptive learning, and a 
step forward toward the holy grail of personalized learning. But, it was 
the two words that followed that I found jarring: she described this 
online learning program, using a representation of the familiar count­
ing beads, as virtual manipulatives. Isn’t the point of a manipulative 
that it is tangible? What is a virtual manipulative then, other than an 
oxymoron? 
But this did spark an idea: what if we could take the tangible count­
ing beads, the same kind kids have been playing with for decades, and 
endow them with the adaptive learning properties Woolley-Wilson 
describes? How much better might this be for facilitating understand­
ing? And, with the increasing ubiquity of cheap technology (such as 
RFID tags and the like), is this concept really that far off? Imagine get­
ting all the sensory (and cognitive) benefits of tangible objects, and all 
the intelligence that comes with “smart” objects.
EMBODIED LEARNING
You might wonder, “Why should we care about tangible computing?” 
Isn’t interacting with our fingers or through devices such as a mouse or 
touchscreens sufficient? In a world constrained by costs and resources, 
isn’t it preferable to ship interactive software (instead of interactive 
hardware), that can be easily replicated and doesn’t take up physical 
space? If you look at how media has shifted from vinyl records to cas­
sette tapes to compact discs and finally digital files, isn’t this the direc­
tion in which everything is headed? 
Where learning and understanding is required, I’d argue no. And, a 
definite no wherever young children are involved. Piaget established 
four stages of learning (sensorimotor, pre-operational, concrete oper­
ational, and formal operational), and argued that children “learn best 
from concrete [sensorimotor] activities.” This work was preceded by 
American psychologist and philosopher John Dewey, who empha­
sized firsthand learning experiences. Other child psychologists such 

124  |   DESIGNING FOR EMERGING TECHNOLOGIES
as Bruner or Dienne have built on these “constructivist” ideas, creating 
materials used to facilitate learning. In a review of studies on the use 
of manipulatives in the classroom, researchers Marilyn Suydam and 
Jon Higgins concluded that “studies at every grade level support the 
importance and use of manipulative materials.” Taking things one step 
further, educator and artificial intelligence pioneer Seymour Papert 
introduced constructionism (not to be confused with constructivism), 
which holds that learning happens most effectively when people are 
also active in making tangible objects in the real world. 
OK. But what of adults, who’ve had a chance to internalize most of these 
concepts? Using Piaget’s own model, some might argue that the body 
is great for lower-level cognitive problems, but not for more abstract or 
complex topics. This topic is one of some debate, with conversations 
returning to “enactivism” and the role of our bodies in constructing 
knowledge. The central question is this: if learning is truly embodied, 
why or how would that change with age? Various studies continue to 
reveal this mind-body connection. For example, one study found that 
saying words such as “lick, pick, and kick” activates the correspond­
ing brain regions associated with the mouth, hand, and foot, respec­
tively. I’d add that these thinking tools extend our thinking, the same 
way objects such as pen and paper, books, or the handheld calculator 
(abacus or digital variety—you choose) have allowed us to do things we 
couldn’t do before. Indeed, the more complex the topic, the more neces­
sary it is to use our environment to externalize our thinking.
Moreover, there is indeed a strong and mysterious connection between 
the brain and the body. We tend to gesture when we’re speaking, even 
if on a phone when no one else can see us. I personally have observed 
different thinking patterns when standing versus sitting. In computer 
and retail environments, people talk about “leaning in” versus “leaning 
back” activities. In high school, I remember being told to look up, if I 
was unsure of how to answer a question—apparently looking up had, 
in some study, been shown to aid in the recall of information! Athletes, 
dancers, actors—all these professions talk about the yet unexplained 
connections between mind and body.
As magical as the personal computer and touchscreen devices are, there 
is something lost when we limit interactions to pressing on glass or 
clicking a button. Our bodies are capable of so much more. We have the 
capacity to grasp things, sense pressure (tactile or volumetric), identify 

 5. Learning and Thinking with Things   |  125
textures, move our bodies, orient ourselves in space, sense changes 
in temperature, smell, listen, affect our own brain waves, control our 
breathing—so many human capabilities not recognized by most digital 
devices. In this respect, the most popular ways in which we now inter­
act with technology, namely through the tips of our fingers, will some­
day seem like crude, one-dimensional methods.
Fortunately, the technology to sense these kinds of physical interac­
tions already exists or is being worked on in research labs.
(Near) Future Technology
Let’s consider some of the ways that physical and digital technologies 
are becoming a reality, beginning with technologies and products that 
are already available to us:
• In 2012, we saw the release of the Leap Motion Controller, a highly 
sensitive gestural interface, followed closely by Mylo, an armband 
that accomplishes similar Minority Report–style interactions, but 
using changes in muscles rather than cameras. 
• When it comes to touchscreens, Senseg uses electrostatic impulses 
to create the sensation of different textures. Tactus Technologies 
takes a different approach, and has “physical buttons that rise up 
from the touchscreen surface on demand.” 
• To demonstrate how sensors are weaving themselves into our daily 
lives, Lumo Back is a sensor band worn around the waist to help 
improve posture. 
• We’ve got the Ambient umbrella, which alerts you if it will be 
needed, based on available weather data. 
• A recent Kickstarter project aims to make DrumPants (the name 
says it all!) a reality. 
• In the wearables space, we have technologies such as conductive 
inks, muscle wire, thermochromic pigments, electrotextiles, and 
light diffusing acrylic (see Figure 5-4). Artists are experimenting 
with these new technologies, creating things like a quilt that dou­
bles as a heat-map visualization of the stock market (or whatever 
dynamic data you link to it).

126  |   DESIGNING FOR EMERGING TECHNOLOGIES
Figure 5-4. A collage of near-future tech (from left to right, top to bottom): 
Ambient umbrella, DrumPants, the Leap Motion Controller, Lumo Back, Mylo 
armband, Senseg, and Tactus tablet

 5. Learning and Thinking with Things   |  127
If we look a bit further out:
• Sites such as Sparkfun, Parallax, or Seeed offer hundreds of dif­
ferent kinds of sensors (RFID, magnetic, thermal, and so on) and 
associated hardware with which hobbyists and businesses can tin­
ker. Crowdfunding sites such as Kickstarter have turned many of 
these hobbyist projects into commercial products. 
• Smartphones have a dozen or more different sensors (GPS, accel­
erometer, and so on) built in to them, making them a lot more 
“aware” than most personal computers (and ready for the imagina­
tive entrepreneur). And while most of us are focused on the apps 
we can build on top of these now-ubiquitous smartphone sensors, 
folks like Chris Harrison, a researcher at Disney Research Labs, 
have crafted a way to recognize the differences between various 
kinds of touch—fingertip, knuckle, nail, and pad—using acoustics 
and touch sensitivity; the existing sensors can be exploited to create 
new forms of interaction.
• Indeed, places such as Disney Research Labs in Pittsburgh or the 
MIT Media Lab are hotspots for these tangible computing proj­
ects. Imagine turning a plant into a touch surface, or a surface 
that can sense different grips. Look further out, and projects like 
ZeroN show an object floating in midair, seemingly defying grav­
ity; when moved, information is recorded and you can play back 
these movements!
• How about a robotic glove covered with sensors and micro-ultra­
sound machines? Med Sensation is inventing just such a device 
that would allow the wearer to assess all kinds of vital information 
not detectable through normal human touch. 
There is no shortage of exciting technologies primed to be the next big 
thing!
We live in a time full of opportunity for imaginative individuals. In 
our lifetime, we will witness the emergence of more and varied forms 
of human-computer interaction than ever before. And, if history is any 
indication (there’s generally a 20-year incubation period from inven­
tion in a laboratory to commercial product), these changes will happen 
inside of the next few decades. 

128  |   DESIGNING FOR EMERGING TECHNOLOGIES
I can’t help but wonder what happens when ordinary, physical objects, 
such as the sandpaper letters or counting beads of my youth, become 
endowed with digital properties? How far off is a future in which ordi­
nary learning becomes endowed with digital capabilities?
THINKING WITH THINGS, TODAY!
Whereas much of this is conjecture, there are a handful of organiza­
tions exploring some basic ways to make learning both tangible and 
digital.
Sifteo Cubes
The most popular of these technologies is, of course, the Sifteo Cubes 
(see Figure 5-5). Announced at the February 2009 TED conference, 
these “toy tiles that talk to each other” have opened the doors to new 
kinds of play and interaction. Each cube, aside from having a touch­
screen, has the added ability to interact with other cubes based on its 
proximity to a neighboring cube, cube configurations, rotation, and 
even orientation and gesture. In various games, players essentially 
reposition blocks to create mazes, roll a (virtual) ball into the next 
block, and do any number of other things accomplished by interact­
ing with these blocks the way you would dominoes. They’ve been aptly 
described as “alphabet blocks with an app store.” Commenting on what 
Sifteo Cubes represent, founder Dave Merrill has said “What you can 
expect to see going forward are physical games that really push in the 
direction of social play.”
Motion Math
Similar to Sifteo Cubes, in that interaction comes through motion, is 
the fractions game Motion Math (Figure 5-5). This simple app for the 
iPhone and Android uses the accelerometer to teach fractions. Rather 
than tapping the correct answer or hitting a submit button, as you 
would with other math software, players tilt their devices left or right to 
direct a bouncing ball to the spot correctly matching the identified frac­
tion; you learn fractions using hand-eye coordination and your body (or 
at least your forearm). And, rather than an “incorrect” response, the 
feedback loop of a bouncing ball allows you to playfully guide your ball 
to the correct spot.

 5. Learning and Thinking with Things   |  129
Figure 5-5. Edu tech (from top to bottom): GameDesk’s Areo, the Motion Math 
app, and Sifteo Cubes

130  |   DESIGNING FOR EMERGING TECHNOLOGIES
GameDesk
As exciting as Sifteo and Motion Math are, some of the best examples 
of whole body learning with technology would be the learning games 
developed by GameDesk. Take Aero, as an example. Codesigned with 
Bill Nye the Science Guy, Aero teachers sixth graders fundamental 
principles in physics and aerodynamics. How? According to GameDesk 
founder Lucient Vattel:
In this game, you outstretch your arms and you become a bird. It’s an 
accurate simulation of bird flight. And through that you get to under­
stand the vectors: gravity, lift, drag, thrust. These concepts are not 
normally taught at the sixth grade level…
Vattel goes on to add that “a game can allow the concepts to be visual­
ized, experienced…” And this is what is remarkable: that students are 
experiencing learning, with their entire body and having a blast while 
they’re at it—who doesn’t want to transform into a bird and fly, if only 
in a simulation?
GameDesk also works with other organizations that are exploring sim­
ilar approaches to learning. One of those organizations is SMALLab 
Learning, which has a specific focus on creating embodied learning 
environments. SMALLab uses motion-capture technology to track stu­
dents’ movements and overlay this activity with graphs and equations 
that represent their motions in real time. In a lesson on centripetal 
force, students swing an object tethered to a rope while a digital projec­
tion on the ground explains the different forces at play. Students can 
“see” and experience scientific principles. “They feel it, they enact it,” 
says David Birchfield, co-founder of SMALLab Learning. 
The technology in these examples is quite simple—for Aero a Wiimote 
is hidden inside each of the wings—but the effect is dramatic. Various 
studies by SMALLab on the effectiveness of this kind of embodied 
learning show a sharp increase as evidenced by pre-, mid-, and post-
test outcomes for two different control groups.
Timeless Design Principles?
Technology will change, which is why I’ve done little more here than 
catalog a handful of exciting advancements. What won’t change, and 
is needed, are principles for designing things with which to think. For 

 5. Learning and Thinking with Things   |  131
this, I take an ethnographer’s definition of technology, focusing on the 
effect of these artifacts on a culture. Based on my work as an educator 
and designer, I propose the following principles for designing learning 
objects. 
A good learning object:
Encourages playful interactions
Aside from being fun or enjoyable, playfulness suggests you can 
play with it, that there is some interactivity. Learning happens 
through safe, nondestructive interactions, in which experimenta­
tion is encouraged. Telling me isn’t nearly as effective as letting 
me “figure it out on my own.” Themes of play, discovery, experi­
mentation, and the like are common to all of the learning exam­
ples shared here. Sifteo founder Dave Merrill comments that “Like 
many games, [Sifteo] exercises a part of your brain, but it engages 
a fun play experience first and foremost.”
Supports self-directed learning (SDL)
When learners are allowed to own their learning—determining 
what to learn, and how to go about filling that gap in their knowl­
edge—they become active participants in the construction of 
new knowledge. This approach to learning encourages curiosity, 
helps to develop independent, intrinsically motivated learners, and 
allows for more engaged learning experiences. Contrary to what 
is suggested, SDL can be highly social, but agency lies in hands of 
the learner.
Allows for self-correction 
An incorrect choice, whether intended, unintended, or the result of 
playful interactions should be revealed quickly (in real time if pos­
sible) so that learners can observe cause-and-effect relationships. 
This kind of repeated readjusting creates a tight feedback loop, ulti­
mately leading to pattern recognition.
Makes learning tangible
Nearly everything is experienced with and through our bodies. We 
learn through physical interactions with the world around us and 
via our various senses. Recognizing the physicality of learning, 
and that multimodal learning is certainly preferable, we should 
strive for manipulatives and environments that encourage embod­
ied learning. 

132  |   DESIGNING FOR EMERGING TECHNOLOGIES
Offers intelligent recommendations 
The unique value of digital objects is their ability to record data and 
respond based on that data. Accordingly, these “endowed objects” 
should be intelligent, offering instruction or direction based on 
passively collected data.
Each of these principles is meant to describe a desired quality that is 
known or believed to bring about noticeable learning gains, compared 
to other learning materials. So, how might we use these principles? 
Let’s apply these to a few projects, old and new.
CYLINDER BLOCKS: GOOD LEARNING OBJECTS
In many ways, the manipulatives designed by Maria Montessori more 
than a century ago satisfy nearly all of these principles. Setting aside 
any kind of inherent intelligence, they are very capable objects. 
Consider the cylinder blocks shown in Figure 5-6. You have several cyl­
inders varying in height and/or diameter that fit perfectly into desig­
nated holes drilled into each block. One intent is to learn about volume 
and how the volume of a shallow disc can be the same as that of a nar­
row rod. Additionally, these cylinder block toys help develop a child’s 
visual discrimination of size and indirectly prepare a child for writing 
through the handling of the cylinders by their knobs.
Figure 5-6. Montessori cylinder blocks6
How do these blocks hold up?
6	 As featured on Montessori Outlet (http://www.montessorioutlet.com)

 5. Learning and Thinking with Things   |  133
As with nearly all of Maria Montessori’s manipulative materials, these 
objects are treated like toys, for children to get off the shelf and play 
with, satisfying our first principle, playful interactions. Because chil­
dren are encouraged to discover these items for themselves, and pursue 
uninterrupted play (learning) time with the object, we can say it satis­
fies the second principle: self-directed learning. Attempting to place a 
cylinder into the wrong hole triggers the learning by either not fitting 
into the hole (too big), or standing too tall and not filling the space; stu­
dents are able to quickly recognize this fact and move cylinders around 
until a fitting slot is found, allowing for self-correction, our third prin­
ciple. As you play with wooden cylinders, using your hands, we can 
safely say this satisfies our fourth principle: tangibility. As far as intel­
ligence, this is the only missing piece.
With this kind of orientation in mind, I’d like to share a personal proj­
ect I’m working on (along with a friend much more versed in the tech­
nical aspects).
Case Study: An appcessory for early math concepts
When my kids were younger, I played a math game that never ceased 
to amuse them (or me, at least). The “game,” if you can call it that, con­
sisted of grabbing a handful of Teddy Grahams snack crackers (usually 
off of their plate) and counting them out, one by one. I’d then do sim­
ple grouping exercises, moving crackers between two piles or count­
ing by placing them into pairs. The real fun kicked in when we’d play 
subtraction. “You have seven Teddy Grahams. If Daddy eats one Teddy 
Graham, how many do you have left?” I think I enjoyed this more than 
my kids did (to be fair, I’d also make a few additional Teddy Grahams 
appear out of nowhere, to teach addition). All in all, this was a great way 
to explore early math concepts such as counting, grouping, subtraction, 
and addition.
So, how does this game stack up on the design principles? The learn­
ing is playful (if not downright mischievous). And the Teddy Grahams 
are tangible. On these two attributes my game is successful. However, 
the game doesn’t fare so well on the remaining principles: although my 
presence is not a bad thing, this doesn’t encourage self-directed learn­
ing, and the correction comes entirely from me and is not discovered. 
As for the intelligence, it’s dependent on my presence.

134  |   DESIGNING FOR EMERGING TECHNOLOGIES
This left me wondering if this simple game, not all that effective with­
out my presence, could be translated into the kinds of experiences I’m 
describing here? Could this be improved, to satisfy the identified five 
design principles?
Here’s my concept: what if we combined my pre-math Teddy Graham 
game with an iPad? As depicted in Figure 5-7, what if we exchanged the 
crackers for a set of short cylinders (like knobs on a stereo), and what 
if we figured out how to get these knobs talking to the iPad. Could that 
work? Is that possible? Even though this could be accomplished with a 
set of Sifteo blocks, the costs would be prohibitive for such a singular 
focus, especially where you’d want up to 10 knobs. I’m treating these 
as single-purpose objects, with the brains offloaded to the device on 
which they sit (in this case the iPad). Hence, the “appcessory” label.
Figure 5-7. Appcessory concept and walkthrough

 5. Learning and Thinking with Things   |  135
Here’s a walkthrough of how the interactions might work:
• Placing one of these knobs onto the surface of the iPad would pro­
duce a glowing ring and the number 1. 
• Adding a second knob in close proximity would make this ring 
larger, encircling both knobs (and changing the number to 2). 
• Let’s suppose you added a third knob farther away, which would 
create a new ring with the corresponding number 1. 
• Now you have two rings, one totaling 2, the other totaling 1. If you 
slide the lone knob close to the first two, you’d end up now with 
one ring, totaling 3. In this manner, and as you start to add more 
knobs (the iPad supports up to 10, double that of other platforms), 
you start to learn about grouping. 
• In this case, the learning is quite concrete, with the idea of numeric 
representations being the only abstract concept. You could then 
switch to an addition mode that would add up the total of however 
many groups of knobs are on the surface.
I could go on, but you get the idea. By simply placing and moving knobs 
on a surface the child begins to play with fundamental math concepts. 
As of this writing, we have proven out the functional technology, but 
have yet to test this with children. Although the app I’m describing 
could be built very quickly, my fundamental thesis is that by making 
these knobs something you can grasp, place, slide, move, remove, and 
so on, learning will be multimodal and superior to simply dragging flat 
circles behind glass. 
How does this stack up on the five principles?
As with the earlier Teddy Grahams version, it is interactive and tangi­
ble. Moving this game to a tablet device allows for self-directed learn­
ing and feedback loops in the form of the rings and numerical values. 
As far as intelligence goes, there is no limit to the kinds of data one 
could program the iPad to monitor and act upon.
So where might this thinking lead, one day?

136  |   DESIGNING FOR EMERGING TECHNOLOGIES
Farther Out, a Malleable Future
In the opening scenes of the Superman movie Man of Steel, one of 
the many pieces of Kryptonian technology we see are communica­
tion devices whose form and shape is constantly reshaping—a tangi­
ble, monochromatic hologram, if you will. Imagine thousands of tiny 
metal beads moving and reshaping as needed. Even though this makes 
for a nice bit of sci-fi eye candy, it’s also technology that MIT’s Tangible 
Media Group, led by Professor Hiroshi Ishii, is currently exploring. In 
their own words, this work “explores the ‘Tangible Bits’ vision to seam­
lessly couple the dual world of bits and atoms by giving physical form 
to digital information.” They are creating objects (the “tangible bits”) 
that can change shape!
Even though the team’s vision of “radical atoms” is still in the realm 
of the hypothetical, the steps they are taking to get there are no less 
inspiring. Their latest example of tangible bits is a table that can render 
3D content physically, so users can interact with digital information in 
a tangible way. In their video demonstration, a remote participant in a 
video conference moves his hands, and in doing so reshapes the surface 
of a table, rolling a ball around. The technology is at once both awe-in­
spiring and crude; the wooden pegs moving up and down to define 
form aren’t that unlike the pin art toys we see marketed to children. 
Having said that, it’s easy to imagine something like this improving 
in fidelity over time, in the same way that the early days of monochro­
matic 8-bit pixels gave way to retina displays and photorealistic images.
I mention this example because it’s easy to diminish the value of tan­
gible interactions when compared to mutability of pixels behind glass; 
a single device such as a smartphone or tablet can become so many 
things, if only at the cost of tangibility. Our current thinking says, 
“Why create more ‘stuff’ that only serves a single purpose?” And this 
makes sense. I recall the first app for musicians that I downloaded 
to my iPhone—a simple metronome. For a few dollars, I was able to 
download the virtual equivalent of an otherwise very expensive piece of 
hardware. It dawned on me: if indeed the internal electronics are com­
parable to those contained in the hardware, there will be a lot of compa­
nies threatened by this disruption. This ability to download for free an 
app that as an object would have cost much more (not to mention add 
clutter) is a great shift for society. 

 5. Learning and Thinking with Things   |  137
But…
What if physical objects could reshape themselves in the same way that 
pixels do? What if one device, or really a blob of beads, could reshape 
into a nearly infinitesimal number of things? What if the distinctions 
between bits and atoms become nearly indistinguishable? Can we have 
physical interactions that can also dynamically change form to be 1,000 
different things? Or, at a minimum, can the interface do more than 
resemble buttons; perhaps it could shape itself into the buttons and 
switches of last century and then flatten out again into some new form. 
How does the role of interaction designer change when you’re interface 
is a sculpted, changing thing? So long as we’re looking out into possi­
ble futures, this kind of thinking isn’t implausible, and should set some 
direction.
Nothing New Under the Sun
While much of this looks to a future in which physical and digital con­
verge, there is one profession that has been exploring this intersection 
for some time now: museums. 
Museums are amazing incubators for what’s next in technology. These 
learning environments have to engage visitors through visuals, inter­
actions, stories, and other means, which often leads to (at least in the 
modern museum) spaces that are both tangible and take advantage of 
digital interactions. The self-directed pace that visitors move through 
an exhibit pressures all museum designers to create experiences that 
are both informative and entertaining. And, many artists and technol­
ogist are eager to, within the stated goals of an exhibit, try new things.
Take for example the Te Papa Tongarewa museum, in Wellington, New 
Zealand. Because New Zealand is an island formed from the collision 
of two tectonic plates, you can expect volcanoes, earthquakes, and all 
things geothermal to get some attention. As visitors move about the 
space, they are invited to learn about various topics in some amazing 
and inventive ways. When it comes to discussions of mass and den­
sity, there are three bowling ball–sized rocks ready for you to lift; they 
are all the same in size, but the weight varies greatly. When learning 
about tectonic shifts, you turn a crank that then displaces two halves of 
a map (along with sound effects), effectively demonstrating what has 
happened to New Zealand over thousands of years, and what is likely 
to happen in the future. Visitors are encouraged to step into a house in 

138  |   DESIGNING FOR EMERGING TECHNOLOGIES
which they can experience the simulation of an earthquake. The com­
mon denominator between these and dozens more examples is that 
through a combination of technology and tangible interactions, visitors 
are encouraged to interact with and construct their own knowledge.
Closing
Novelist William Gibson once commented that future predictions 
are often guilty of selectively amplifying the observed present. Steam 
power. Robots. Many of us are being handed a future preoccupied 
with touchscreens and projections. In “A Brief Rant on the Future of 
Interaction Design” designer and inventor Bret Victor offers a brilliant 
critique of this “future behind glass,” and reminds us that there are 
many more forms of interaction of which we have yet to take advantage. 
As he says, “Why aim for anything less than a dynamic medium that 
we can see, feel, and manipulate?” 
To limit our best imaginings of the future, and the future of learning, 
to touching a flat surface ignores 1) a body of research into tangible 
computing, 2) signs of things to come, and 3) centuries of accumulated 
knowledge about how we—as human creatures—learn best. Whether 
it’s the formal learning of schools or the informal learning required of 
an information age, we need to actively think about how to best make 
sense of our world. And all that we know (and are learning) about our 
bodies and how we come to “know” as human beings cries out for more 
immersive, tangible forms of interaction. I look forward to a union of 
sorts, when bits versus atoms will cease to be a meaningful distinction. 
I look to a future when objects become endowed with digital proper­
ties, and digital objects get out from behind the screen. The future is 
in our grasp.

289
[ 13 ]
Architecture as Interface: 
Advocating a Hybrid Design 
Approach for Interconnected 
Environments 
ERIN RAE HOFFER
The Blur of Interconnected Environments
We spend 90 percent of our lives indoors.1 The built environment has 
a huge impact on human health, social interaction, and our potential 
for innovation. In return, human innovation pushes our buildings con­
tinually in new directions as occupants demand the highest levels of 
comfort and functionality.
Our demand for pervasive connectivity has led us to weave the Internet 
throughout our lives, to insist that all spaces link us together along 
with our handheld devices, that all environments be interconnected. 
Internet-enabled devices creep into the spaces we inhabit, and these 
devices report back on spatial conditions such as light, radiation, air 
quality and temperature, count the number of people stopping at retail 
displays minute by minute, detect intruders and security breaches, 
monitor locations and track characteristics of equipment and supply 
chain elements, enable us to open locked doors remotely using our 
mobile devices, and pass terabytes of data to backend systems that ana­
lyze, report, and modify the environments we occupy.
1	 http://www.arb.ca.gov/research/resnotes/notes/94-6.htm

290  |   DESIGNING FOR EMERGING TECHNOLOGIES
The space that surrounds us is transforming to a series of intercon­
nected environments, forcing designers of space to rethink the role of 
architecture and the rules for its formulation. Similarly, designers of 
emerging technologies are rethinking the role of interfaces and the 
rules for their creation. During this period of experimentation and con­
vergence, practical construction, and problem solving, architects must 
reinvent their roles and become hybrid designers, creating meaningful 
architecture with an awareness of the human implications of emerging 
technologies.
DESIGN TRADITIONS FROM ARCHITECTURE
Architects begin with a human need and develop solutions through 
inspiration and information—human, social, natural, economic and 
technological. The architect is charged to envision a new reality that 
addresses explicit and tacit needs, to create an expansive solution set 
that suits this vision. For millennia, architects have been given the task 
of imagining spaces to support people and human interaction, describ­
ing design intent, and producing concrete instructions for realizing 
designs as objects in the physical environment. Admittedly, many 
spaces are designed by builders or lay people, not by licensed archi­
tects. Whatever the professional and academic background of the cre­
ator, a building design stems from centuries of traditional practice and 
refined interaction models. 
Upon encountering a device for the first time a user or occupant builds a 
conceptual model about it. The same approach plays out when humans 
encounter new environments. To design a space, an architect makes 
assumptions about the building’s future occupants. As cognitive sci­
entist and design critic, Donald A. Norman points out, “Good design 
is a communication between the designer and the user.” This mani­
fests through the appearance of the device (object or space) itself.2 In 
terms of the built environment, Japanese philosopher Kojin Karatani 
observes that the dialogue between an architect and an occupant of a 
space occurs through a system of communication without commonly 
understood rules.3 
2	 Norman (2002)
3	 Karatani and Speaks (1995)

 13. ARCHITECTURE AS INTERFACE   |  291
Over time, architectural problems have become increasingly complex, 
driven by economics, technological innovation, and changing societal 
needs for buildings to support new functions and offer innovative fea­
tures to improve efficiency and safety. Practitioners rely on a body of 
design theory that influences the products of architectural design, and 
highlights the duality of a profession whose aspirations are to create 
artifacts that serve practical needs at the same time that they encode 
meaning for individuals and communities.
The pervasion of Internet-enabled elements into the physical space of 
everyday life and work forces us to rethink both the requirements of 
our world and the way we design it. Today’s consumers can connect 
a smartphone-enabled door to a system of security; comfort-focused 
devices that transmit video sense and adjust temperature and lighting. 
As interactive environments proliferate and these choices expand in 
the future, designers must expand theory to apply these new modes of 
interaction and meaning to our most pressing objectives.
ARCHITECTURAL DESIGN THEORY: MODELS 
OF INTERACTION AND MEANING
Architectural theory analyzes and describes architectural design in 
terms of appropriate elements, their relationships to cultural under­
standing, and the process of devising them. In this context, theory is an 
explanation that does not proscribe a specific end result. It is a structure 
of concepts, categories, and relationships intended to explain things or 
to advocate, not a defined roadmap or a step-by-step methodology.
No single comprehensive structure of ideas can be applied in the same 
rigorous way to resolve all design problems in architecture. It is unlikely 
that a formal set of rules lie behind all of the many complex decisions 
that produce an existing building. However, practitioners have long val­
ued theory in making decisions on complex projects or to retrospec­
tively clarify a body of work.
Architectural theory can be traced back to the first century BC. The 
Roman writer and architect Vitruvius4 wrote a treatise that laid out 
the salient aspects of Roman architecture in a series of volumes. The 
Ten Books of Vitruvius illustrated the principles of design and construc­
4	 Vitruvius (1999)

292  |   DESIGNING FOR EMERGING TECHNOLOGIES
tion and emphasized the three “laws” placing architecture above mere 
building, namely that a work of architecture must possess the qualities 
of Firmness, Commodity, and Delight.5 These three laws clarified that 
a work of good design must be physically and structurally sound, must 
support the functional and practical needs of its occupants, and must 
be aesthetically pleasing to the viewer.
By comparison, Hewlett-Packard User Experience Lead Jim Nieters’s 
blog on Interaction Design lists the goals of an interaction model 
as being Discoverability, Learnability, Efficiency, Productivity, 
Responsiveness, and, not coincidentally, Delight.6 Although these two 
thinkers lived in different times, these somewhat analogous sets of 
“laws” underscore the relevance of aligning UX design with the design 
of interaction and experience in physical space.
Since the time of Vitruvius, architectural theory has relied on classi­
fications and definitions—grouping buildings into types, defining 
accepted applications of morphology, focusing on uses, appearances, 
and the appropriateness of combining elements from different periods, 
styles, or construction types. Theory has even suggested that the com­
ponents of architecture exist as elements of a language that has a par­
ticular grammar, as elaborated in A Pattern Language: Towns, Buildings, 
Construction by Christopher Alexander et al. Alexander laid out the idea 
of pattern and usage as a way of building what he called “timeless.” He 
states, “Towns and buildings will not be able to come alive, unless they 
are made by all the people in society, and unless these people share a 
common pattern language, within which to make these buildings, and 
unless this common pattern language is alive itself.”7
Theorizing Digital Culture: New 
Models of Convergence
In more recent times, computers became prevalent in society and 
architects theorized about the impacts of digital culture. Observers of 
the design professions considered the implications of digital technol­
ogy, both for the environments we would occupy alongside these new 
5	 As translated by Sir Henry Wotton in the 17th Century
6	 Nieters, Jim, “Defining an Interaction Model: The Cornerstone of Application Design” blog 
post, http://bit.ly/1nTB1h5.
7	 Alexander et al. (1977) and Alexander (1979)

 13. ARCHITECTURE AS INTERFACE   |  293
devices, and for the process of design itself. Theorists in the 1960s and 
1970s discussed cybernetics,8 digital approaches to systems of work and 
habitation, and explored through programming Negroponte’s concept 
of “the architecture machine,”9 a theory about the ability of machines 
to learn about architecture as opposed to being programmed to com­
plete architectural tasks.
More recent investigations of the merger of digital and architectural 
realms have been undertaken since the 1990s, with research consid­
ering the concept of adaptive feedback loops,10 of environments such 
as Rodney Brooks’ Intelligent Room Project,11 or environments such 
as the Adaptive House.12 These experiments explored the principles 
of combining digital with architectural environments and processes. 
Malcolm McCullough observed an impending future of opportunity 
when computing pervades architecture and activities are mediated 
in new ways. He commented that, “The rise of pervasive computing 
restores an emphasis on geometry.… In locally intensified islands of 
smarter space, interactivity becomes a richer experience.”13
Theories and manifestos proliferated with a focus on the cultural 
and societal imperatives that should guide practitioners in navigat­
ing the choppy waters between meaningful and merely practical 
arrangements of space. As Michael Speaks described in his introduc­
tion to Kojin Karatani’s Architecture as Metaphor, a tug of war ensues 
between two metaphors, “Architecture as Art” versus “Architecture as 
Construction.”14 If we are to believe Vitruvius, the aspiration of archi­
tecture has always gone beyond function and effectiveness to incorpo­
rate the difficult-to-define idea of “delight,” a notion beyond aesthetics. 
In today’s post-modern age, we expect a work of architecture to mean 
something to inhabitants and observers. Architecture has always con­
8	 Frazer (1993)
9	 Negroponte (1970 )
10	 Eastman, in Cross (1972)
11	 R. A. Brooks. 1997. The Intelligent Room project. In Proceedings of the 2nd International 
Conference on Cognitive Technology (CT ’97). IEEE Computer Society, Washington, DC, 
USA, 271-. http://people.csail.mit.edu/brooks/papers/aizu.pdf.
12	 http://bit.ly/1nTB2BH
13	 McCullough (2004)
14	 Karatani and Speaks (1995)

294  |   DESIGNING FOR EMERGING TECHNOLOGIES
veyed meaning, or “spoken to us” through form, since the time when 
illiterate occupants needed the cathedral to convey the meaning of reli­
gious texts. Alain de Botton stated that, “Belief in the significance of 
architecture is premised on the notion that we are, for better or worse, 
different people in different places—and on the conviction that it is 
architecture’s task to render vivid to us who we might ideally be.”15 
ENTER INTERCONNECTED ENVIRONMENTS
Our intention as architects to design meaning into space broadens 
when we conceive of spaces as interconnected environments, linking 
devices to devices, and thereby connecting occupants with remote indi­
viduals, communities, and information sources. Although we have long 
incorporated the practical opportunities of automation—environmen­
tal control systems that manipulate building heat and cooling, raise 
and lower window shades, and control other architectural elements and 
systems with little or no human intervention—emerging technology 
can move us beyond digital integration with architecture as “practical 
construction” to digital integration with architecture as “art.”
We are surrounded by smart homes, schools, workplaces, shopping 
malls, and even the city itself with its smart grid. These anticipatory 
models purport to make all decisions and do all the work for us. But, 
our models for digital interaction have evolved, and the conceptual 
models for user interaction now stretch to accommodate decentral­
ized structures that include mobile “anywhere” access, feedback and 
input from “the crowd,” increased transparency, simulation, and anal­
ysis. We are moving from anticipatory centralized models such as the 
Encyclopaedia Brittanica16 to adaptive decentralized ones along the 
lines of Wikipedia.17
Christian Norberg-Schulz said that the job of the architect was to visu­
alize the spirit of the place and to create meaningful places for peo­
ple to inhabit.18 Perhaps the modern person is less able to understand 
the meaning of architecture because our education and training no 
longer emphasizes this appreciation. Nevertheless, architects still 
15	 De Botton (2006)
16	 http://www.britannica.com/
17	 http://www.wikipedia.org/
18	 Norberg-Schulz (1980)

 13. ARCHITECTURE AS INTERFACE   |  295
aspire to produce buildings and spaces that go beyond function and 
effectiveness, which can become meaningful to people who occupy or 
encounter them. With the advent of digitally connected architecture, 
we have an opportunity to reinvent architecture as a source of meaning. 
Pervasive computing will provide feedback about perceptions and phys­
ical experiences as our bodies interact with our spaces. Documentation 
and analysis of feedback will increase our awareness of what it means 
to embody and occupy space. To move to this next stage, digital experi­
ence designers and architects must enlighten one another and collabo­
rate to inspire hybrid models of design practice (Figure 13-1).
Figure 13-1. Hybrid design will emerge when the patterns of digital experience 
designers and architects converge (courtesy of the author)
Hybrid Design Practice
Traditionally, architects are trained to think about interaction in terms 
of form and physical occupation, activity, and movement bounded by 
space—walls, floors, and ceilings, illuminated by sun or artificial light, 
defined by materiality. There is no dominant theory that governs the 
work of all architects. Rather, practitioners follow a range of meth­
ods and apply design theories based on their academic training and 
compliance with firm methods in keeping with their own personal 
approaches. After spending time gathering information about the con­
text and deepening their understanding of the problem, some archi­
tects aggregate programmatic elements into systems. Others might 

296  |   DESIGNING FOR EMERGING TECHNOLOGIES
begin with a metaphor and work to fit client requirements into physical 
forms that represent their vision. Tomorrow’s spaces will be formed 
from interconnected and intelligent components that are aware of the 
human presence, able to communicate, assess, and act. The role of the 
designer must evolve to incorporate both sets of skills—architect and 
interaction designer—so that we can create meaningful places that 
support systems of linked intelligent devices. This mix of methods and 
sensibilities can be termed hybrid design practice.
Hybrid design practice will augment metaphor or context awareness 
with maps of information and communication from digital sources 
and delivery systems. The work of hybrid design calls for new theo­
ries to help us create meaning from electronic communications and 
digital resources as well as physical ones. As McCullough observed, 
“The more that principles of locality, embodiment, and environmen­
tal perception underlie pervasive computing, the more it all seems like 
architecture.”19
TRAPELO ROAD CASE STUDY
Figure 13-2 shows a rendering of Autodesk, Inc.’s Trapelo Road20 office 
just outside Boston. This fit-out is an example of a project that aspires 
to integrate Internet monitoring and control systems in the architec­
tural design of a commercial office interior. Sensors that collect data 
about comfort and energy utilization are linked to the building auto­
mation system, which taps into weather data from an external system. 
Data provided by the sensors helps facility managers realize energy effi­
ciency improvements by refining the sequence of operation for build­
ing HVAC equipment while continuing to meet temperature require­
ments at business start time each day. Experimental projects applying 
sensor data at Trapelo illustrate how designers can become smarter 
about the way space and systems need to be laid out to enable sophisti­
cated measurement and increased efficiency. Better data gained from 
interconnected devices embedded in architecture enables continu­
ous diagnostics and automated commissioning so that anomalies in 
the system can be flagged more quickly and addressed sooner. The 
19	 McCullough (2004)
20	 “Autodesk’s East Coast Headquarters Draws Accolades for its Sustainable Design and 
Collaborative Building Process,” EDC Magazine, August 2010, http://bit.ly/1nTBik8.

 13. ARCHITECTURE AS INTERFACE   |  297
insight gained from sensors is now displayed to employees and visitors 
through a prominently placed plasma screen, potentially shifting occu­
pant behavior as individuals “see” the impacts of their actions.
Figure 13-2. A Building Information Model of the Autodesk HQ provides 
a framework for information about usage and resources (courtesy of 
KlingStubbins)
Ultimately, this experiment suggests the way that the entire space 
could be reconfigured to put both information and means of control at 
the fingertips of all occupants at all times. But beyond the practicality 
of an application designed to drive energy efficiency, how will occu­
pants of the space interpret the meaning inherent in the display—both 
in terms of the practicality of efficient use of energy and of the signifi­
cance of the initiative in the context of the social community and issues 
of climate change?
HUMAN TO MACHINE, MACHINE TO MACHINE
The explosion of Internet and web creates new interaction models that 
lead to dynamic configurations of people, networks and machines. The 
hybrid design practice will accommodate these new interaction mod­
els. To our traditional human to human (H2H) and human to archi­
tecture (H2A) interactions, we’ve added human to machine (H2M) and 
machine to machine (M2M).

298  |   DESIGNING FOR EMERGING TECHNOLOGIES
H2M interaction models connect humans to machines in “everywhere” 
mode—from any device, at any time and place. Manufacturers of build­
ing elements—garage doors,21 ceiling fans,22 appliances,23 and many 
other automation systems—are smartphone-enabling spatial elements 
so that people can control devices and receive messages and images. 
Our machines are speaking to us. “The garage door was left open.” 
“Your dog Ella’s heart rate is elevated. She has found the stash of choc­
olate hidden inside the upstairs closet.”
With M2M, a sensor or monitor device can capture an “event” (such 
as the state of temperature of light, or other environmental or asset 
conditions). The state can be transmitted over the Internet or a local 
network to a cloud-, desktop-, or server-based software application 
that analyzes, stores, or processes the information, or applies it to a 
downstream action. Apple Computer’s iBeacons, based on Bluetooth 
Low Energy (BLE) technology, enable place-aware applications to light 
up when you enter a room (or at least when your smartphone does).24 
Beacons embedded in architecture can sense when you approach and 
reach out to you in location-specific ways. 
EMERGING MODELS OF CONVERGENT DESIGN
Beyond machines, spaces themselves can speak to us. Alex Hawkinson 
of SmartThings25 connected the architectural elements—floors, walls, 
ceilings, windows, and doors—of his home based on low-power sensor 
network standards such as Zigbee.26 Wired editor Bill Wasik described 
this house as he predicted three phases of evolution on the path of ubiq­
uitous and full integration of devices and digital intelligence into the 
physical world—proliferation (more devices, more sensors), interdepen­
dence (devices learn to rely on one another to take action), and integra­
tion (sets of devices organized into programmable systems).27 Wasik’s 
vision of the third stage of fully integrated devices suggests that hybrid 
design practitioners will be called upon to map space in terms of the 
21	 http://www.liftmaster.com/lmcv2/pages/productfamily.aspx?famid=213
22	 http://bit.ly/1nTBiAL
23	 http://www.whirlpool.com/smart-appliances/
24	 http://bit.ly/1nTBm3q
25	 http://www.smartthings.com/
26	 http://www.zigbee.org/Standards/Overview.aspx
27	 http://www.wired.com/gadgetlab/2013/05/internet-of-things/

 13. ARCHITECTURE AS INTERFACE   |  299
system of data and decision flows as well as the flow of people and 
human activity, to work simultaneously as interaction designers as well 
as designers of physical space.
The age of space populated by integrated and interconnected devices 
will require an important skillset, which can be labeled network under­
standing. Albert-László Barabási of Northeastern University observed, 
“Today, we increasingly recognize that nothing happens in isolation. 
Most events and phenomena are connected, caused by, and interact­
ing with a huge number of other pieces of a complex universal puzzle. 
We have come to see that we live in a small world, where everything is 
linked to everything else.”28 Barabási applies tools of network science 
to increase understanding of the way the information network of the 
Web is structured and how it develops. The complex linkages of the 
individual to a community, society, and a world are becoming mani­
fest through architecture. Beyond providing opportunities for efficient 
communication and problem solving, this manifestation will change 
the nature of our relationship to architecture. Network understanding, 
or insight about the way elements exist in dynamic patterns of cause 
and effect, will be needed alongside traditional architectural skills. The 
hybrid design practice will incorporate network understanding along­
side knowledge of technical requirements for particular spaces for 
human occupation.
Interconnectedness in the design process opens up opportunities to 
invite stakeholders or “the crowd” into decision making. Hybrid design 
practitioners will understand how to tap the wisdom of communities 
through a connected design process. Design influence by consensus is 
not new. It is often applied when projects require community support to 
thrive. Christopher Day, in his book Consensus Design,29 discussed the 
benefits and pain of socially inclusive processes. A design professional 
gives up control over project decisions, faces the challenge of getting a 
group to align around the needs of a situation, and reaps the value of 
the contribution of many voices to strengthen a project. This practice 
requires leadership, social skills, and conviction in the outcome. Yet, 
28	 Barabasi (2003), http://www.barabasilab.com/
29	 Day (2003)

300  |   DESIGNING FOR EMERGING TECHNOLOGIES
how these skills will be translated into situations in which the crowd 
is geographically distributed and linked by the Internet remains to be 
seen.
Changing Definitions of Space
As interconnected environments become commonplace and our inter­
faces move from H2A to H2M to M2M and beyond to aggregations that 
link people and machines and architecture into emerging systems—
H2M2M2A2H—we need to consider the meaning inherent in design 
decisions. Successful hybrid design demands insight about how peo­
ple interact with space as much as knowledge about digital interfaces. 
The connectedness represented by these new models compels design­
ers to understand the simultaneous effects of digital and spatial experi­
ence, to anticipate the effects of design on human, machine, and archi­
tectural contexts. And beyond successful problem solving to achieve 
functionality, the designer must consider what conceptual model of the 
future community is encoded in the solution. 
Hybrid designers will embed architecture with programmable inter­
connected devices and apply knowledge, content, and interpretation 
that make interconnectedness meaningful in a social context as well 
as practical in a physical context. As increasingly sophisticated systems 
of information inherent in social networks are integrated into physical 
spaces, interconnected environments will do more than sense the need 
for change in environmental controls. Layers of information—virtual 
geometry and relevant data—will be interpreted and presented to us 
as we scan space with augmented reality devices. When we encounter 
architectural elements, we will have the opportunity to unpack history 
and connect to counterparts elsewhere in space or time. Upon arriv­
ing at my hotel room for the first time, I look out the window and have 
access to digital messages and artifacts left by decades of past occu­
pants, pointing out noteworthy features of the city outside. The win­
dow can inform me of the best approaches to reducing the energy foot­
print during my stay by manipulating the window position, shading, 
or reflectivity. But the way this information is positioned relative to the 
room will make important statements about the relationship between 
these individuals and my occupation of this particular space at this 
specific time.

 13. ARCHITECTURE AS INTERFACE   |  301
Space itself will become malleable, capable of reconfiguring to suit our 
profiles—presenting differences in lighting, materiality, even form 
as we move from place to place. The design of interaction between 
architecture and machine—A2M—incorporates the technology of 
smart buildings, structures whose systems are automated in order to 
improve their efficiency. In fact, the earliest building automation sys­
tems and “smart building” examples provide an important foundation 
for hybrid design. But emerging technologies—pervasive and mobile 
access, social community, and augmented reality, among others—will 
highlight new opportunities for innovation and development of A2M 
models.
Lorraine Daston noted the importance of objects in the environment 
and the deep connection of things to human communication. Daston 
states, “Imagine a world without things… without things, we would 
stop talking. We would become as mute as things are alleged to be. If 
things are “speechless,” perhaps it is because they are drowned out by 
all the talk about them.”30 As we move toward a world filled with articu­
late things, a categorization of these new environmental elements posi­
tioned by their sphere of application will help us gauge the progress 
we’ve made, give us ideas for innovation, and start us on a path toward 
a hybrid design theory for interconnected environments.
A Framework for Interconnected Environments
To categorize the contribution of interconnected sensors and devices, 
observe that the modes of H2M interaction are already a primary dif­
ferentiator for the applications that have emerged in the marketplace. A 
framework can help clarify opportunities that might exist at the inter­
section between modes of interaction—the different ways that humans 
engage with machine-enabled architecture—and spheres of inquiry—
the different objectives that we have, or the purpose for engagement. 
By interrogating each cell of this framework, shown in Figure 13-3, a 
range of directions for hybrid design practice will emerge.
30	 Daston (2004)

302  |   DESIGNING FOR EMERGING TECHNOLOGIES
MODES OF INTERACTION
There are a number of modes of interaction, spanning information 
gathering, understanding, transmission, manipulation, and stor­
age. Different interaction modes suggest the types of information to 
be stored, processed, and exchanged. Each mode addresses a specific 
question, and as a collection they offer the potential to build sequences 
of interactions, eventually linked to form increasingly sophisticated col­
lections of tools, or systems.
1.	 Awareness: what can we measure, what can we learn?
At a fundamental level, sensors track a condition in the environ­
ment. Sensors can report on the presence or movement of individ­
uals or objects in a space. They can determine temperature, light 
levels, or detect moisture. Awareness of a condition is a fundamen­
tal step required for reporting and decision making.
2.	 Analysis: what useful knowledge can we glean from data?
When an environmental condition is detected, the interconnected 
environment can make this information useful by using it in a pre­
defined algorithm that layers data about the condition with a judg­
ment about the implications of that condition. If the sensor reports 
light, the algorithm might compare the illuminated condition with 
data about current weather conditions, time, or solar positions. 
If it is nighttime, the office is closed, and the room is suddenly 
illuminated, this might mean that someone has entered a space 
unexpectedly. The Analysis interaction mode might include more 
sophisticated algorithms, for example to calculate the amount of 
energy used by the light, or heat that the light could predictably 
generate.
3.	Communication: how should insight be reported?
The judgment call stemming from the Analysis mode of interaction 
would activate the next mode in the sequence: Communication. If 
illumination is not anticipated, the next interaction is to send a 
message or flag an alert in a system that is monitoring the status 
of the environment. Messages would be directed to people or other 
machines. A system of integrated sensors, assessment, and com­
munications could be designed to produce a complex set of effects 
based on situations and reactions.

 13. ARCHITECTURE AS INTERFACE   |  303
4.	 Action: what action can a system initiate based on insight?
In addition to Communication, a myriad of Actions could be inte­
grated into a system of cause and effect. Such actions might impact 
the space in which a condition is being observed. For example, an 
unexpected light might be analyzed and found to produce excess 
heat in a space, which would call for draperies to be repositioned, 
or for a cooling system to be engaged.
5.	Feedback: how can we assess the impact and learn from action?
Ultimately, the detection, analysis, and action loop reaches a 
point where Feedback at a systemic scale becomes useful. After 
prolonged observation and analysis, assessment might deter­
mine a pattern of lights going on and off during certain periods. 
Appropriate judgments could be made and actions taken, based on 
this more holistic assessment. Ongoing assessment and prolonged 
interaction would improve decision making and suggest the most 
appropriate actions so that the space could reach an ideal environ­
mental state.
6.	 Recollection: how can we retain knowledge for later access?
As the system proceeds through cycles of interaction, there will 
be value in maintaining a record of observations and changes. 
Storing the details and organizing the data into patterns provides a 
resource that can be tapped to improve the intelligence and perfor­
mance of the overall system as it evolves.
Spheres of Inquiry
Across all modes of interaction, three spheres of inquiry describe the 
different objectives that we have for understanding or transforming the 
world through physical or human systems. As developers and design­
ers of tools, inspecting the opportunities through the lens of objectives 
helps to suggest the prominent marketplace for tools based on inter­
connected environments (see Figure 13-3).
1.	 Environmental: how can we optimize and minimize use of 
resources to produce ideal conditions by combining data gathered 
through monitoring with external data sources?

304  |   DESIGNING FOR EMERGING TECHNOLOGIES
Interconnected applications naturally gravitate toward tracking 
and improving the environmental conditions they are ideally 
suited to monitor. Applications can alert individuals to dangerous 
conditions in a surrounding space, for example if toxins are build­
ing up in a confined room,31 if noise levels have increased,32 if a 
space is threatened by flooding when water is detected on the floor. 
Environmental alerts can range in scale from a single room, to a 
building, complex, or community scale. Environmental conditions 
for a specific building or campus can alert individuals or systems 
to take action to control energy usage, for example.
Figure 13-3. A framework for connected environments with examples of 
potential tools at the intersection of each interaction mode and sphere of 
inquiry
2.	 Behavioral: can we incent preferred behaviors? Can we monitor 
human interactions, and assess and modify conditions based on 
knowledge of preferences?
Environments are capable of exerting pressure on individuals and 
shaping behavior. Data about behavior or environmental condi­
tions force individuals to confront situations and these confronta­
tions can drive change. The proliferation of interconnected devices 
to drive improved health behaviors (such as WiFi-connected 
31	 https://www.alertme.com/
32	 http://www.widetag.com/widenoise/

 13. ARCHITECTURE AS INTERFACE   |  305
pedometers and scales)33 and other monitoring systems enable 
people to track themselves, fostering improvement in behav­
ior from diet and nutrition health34 to greener environmentally 
friendly living.35 
3.	Social: how can we produce network-based discussion and action 
through social connection? Can we modify settings to be condu­
cive to human interaction?
Architectural history teaches us that environments have tre­
mendous power over the actions of communities and groups. 
They can be designed with the power to divide us, or to unite us. 
Interconnected environments will be capable of monitoring and 
impacting social patterns of interaction. Ranging from obser­
vation to assessment and action, the social sphere of application 
raises questions about how systems should be designed to provide 
the information and actions to the group and its constituents in a 
useful manner.
An Exercise in Hybrid Design Practice
Apply the Interconnected Environments Framework to design a space 
and an experience (see Table 13-1). You can use this sample narrative 
as a model:
Begin by considering an indoor place that has been meaningful for you. 
This might be a room from your childhood or a space you recently vis­
ited where a significant event occurred. 
1.	 Write a brief narrative describing how this meaning is connected 
to your relationships and to clusters of knowledge that you possess 
or seek to tap.
2.	 Launch your design process with key questions. How do the 
answers contribute to the engagement of the visitor with the mean­
ing of the space—in the past, and in the future?
33	 http://www.fitbit.com/
34	 http://quantifiedself.com/about/
35	 http://www.makemesustainable.com/

306  |   DESIGNING FOR EMERGING TECHNOLOGIES
3.	Design the space and outfit it with a series of Internet-enabled 
devices. Be specific about the devices; specify the data they gather. 
What does each device do to process, store, analyze, or transmit 
information?
4.	 Next, design an interaction for a visitor to this space that takes 
advantage of emerging technology to convey meaning and engage 
visitors through experience. Script or storyboard this interaction.
TABLE 13-1. Sample
ENV
BEH
SOC
SENSING
What light, sound, 
smells, and 
temperature should 
the visitor experience? 
How can sensors 
augment what 
the visitor should 
be aware of while 
occupying the space?
Who is the visitor? 
What is the purpose 
of the visit?
What interactions 
should occur 
between multiple 
visitors arriving at 
the same time, or 
one after another?
ANALYSIS
What analysis should 
be done on the 
environment—changes 
in light, accumulation 
of heat?
What insights 
should the space 
produce about the 
visitor’s behavior? 
What actions of 
others outside the 
space should be 
considered? How 
should they be 
analyzed?
COMMUNICATION
How should spatial 
conditions be 
communicated and 
conveyed? How 
should the space be 
organized to present 
these reports?
How should 
behaviors be 
reported? 
Which social 
interactions should 
be reported? How 
can they be useful 
to visitors to the 
space?

 13. ARCHITECTURE AS INTERFACE   |  307
ENV
BEH
SOC
ACTION
What actions should 
the space take when 
certain environmental 
conditions occur?
How can the space 
drive the visitor 
to take a specific 
action? Should it?
How will the visitor 
be connected to 
others? How will 
others shape the 
visitor’s experience 
in the space?
FEEDBACK
What response 
should the space 
provide based on 
the visitor’s physical 
movement, gestures, 
directional gaze, 
facial expressions, or 
vocalizations?
Can the space 
provide feedback 
on the effectiveness 
of the configuration 
to support desired 
outcomes?
Can feedback be 
collected on the 
impact of the space 
on driving desired 
social interactions?
RECOLLECT
Would it be useful 
to record the 
environmental 
changes in the space 
over time?
How can the space 
record, document, 
and recall the 
actions of visitors?
Should visitor 
responses be 
collected and 
presented over 
time?
Architecture as Interface
The process of spatial design evolves continually and emerging technol­
ogy opens up new modes of inquiry in design on a regular basis. Today, 
rapid prototyping of physical components is possible with cost-effec­
tive 3D printing of a wide range of materials.36 Some designers adopt 
a fabrication-based design process by aggregating manufactured or 3D 
printed components. Form-generating experimentation driven by algo­
rithms37 is as valid as by heuristics. The existing world can be captured, 
rendered digital, and used as a backdrop for design and experimenta­
tion in virtual environments.38
36	 “California duo create ‘world’s first 3D printed architecture,’” dezeen Magazine, http://bit.
ly/1nTBYpN.
37	 http://bit.ly/1nTBXly
38	 http://autode.sk/1sSidAJ

308  |   DESIGNING FOR EMERGING TECHNOLOGIES
The adoption of a model-driven design process enables architects to 
consider issues of geometry and issues of information simultane­
ously through building information modeling (BIM).39 With BIM, the 
designers employ digital elements conceived as architecture—with 
parametric geometry that parallels each spatial entity, attached to data 
that describes the entity in terms of costs, manufacture, and physical 
properties. A new breed of BIM tools will be needed so that designers 
can assess the impact of spatial and user interaction decisions across 
different modes of inquiry.
Augmented reality, which layers digital visualizations with real space, 
as shown in Figure 13-4, must next incorporate an information visual­
ization aspect so that environments and interfaces can be experienced 
virtually before they are actually constructed and programmed.40
Figure 13-4. Layering of digital and information visualization (courtesy of the 
author)
39	 Eastman, Charles and Sanguinetti, Paola “BIM Technologies That Inform Concept 
Design,” AIA Conference 2009, http://bit.ly/1nTC28Z.
40	 Sanchez (2013)

 13. ARCHITECTURE AS INTERFACE   |  309
Perhaps it is time to revisit Alexander’s notion of patterns in the envi­
ronment and to develop a pattern language for the age of interconnected 
environments. In this new pattern language, each pattern would be a 
formal response to a design problem linking interactive systems with 
spatial environments. As a starting point, the framework suggests a 
range of patterns that can be developed to link modes of interaction 
with spheres of inquiry.
Consider the bevy of building types that we inhabit and reimagine 
them in new ways—whether homes, workplaces, or industrial, ceremo­
nial, or social settings. A museum that responds to your background 
and interests by highlighting key exhibits modifies the text that accom­
panies the artifacts to suit your knowledge of history. An exhibit might 
connect you to others with similar responses or comments, spawning a 
network of virtual relationships. Consider a nightclub that reconfigures 
to accommodate an impromptu gathering and points you to a room 
filled with graduates of your college when the club’s “operating system” 
assesses the profiles of all visitors and finds commonalities. As you 
enter, the walls of the room have already shifted to reflect your group’s 
publically posted images of your time together, along with music of 
the time period. Surgical rooms maintain awareness of the presence 
and movement of particles linked to infectious diseases, which leads 
to movement of equipment and lighting and modification of airflow to 
protect the patient from harmful conditions and inform clinical profes­
sionals of medical history and environmental changes.
Conclusion
Tomorrow’s spaces will be formed from interconnected and intelligent 
components that are aware of the human presence, and are able to com­
municate, assess, and act. The role of the hybrid designer must evolve 
to incorporate both sets of skills—architect and interaction designer—
so that we can create meaningful places that support systems of inter­
connected intelligent devices.
The hybrid designer will not be responsible solely for “concretization” 
of the building as an object, as described by Christian Norberg-Schulz, 
but rather for orchestrating a new context—a dynamic system of ele­
ments that flex and adapt to support our needs for environmental, 
behavioral, and social settings. Its choreography will be influenced by 
an evolving set of actors. As Nishat Awan states, “The dynamic, and 

310  |   DESIGNING FOR EMERGING TECHNOLOGIES
hence temporal, nature of space means that spatial production must be 
understood as part of an evolving sequence, with no fixed start or fin­
ish, and that multiple actors contribute at various stages.”41
The hybrid designer will go beyond problem solving and practicality, to 
write the manifesto and express what it means to live in an intercon­
nected society through architecture. To articulate how our buildings 
have become gateways to communities of connection and alternative 
experience. Or, to personify each building as a character in the story of 
a life, responding to you, shaping your environment to suit your needs, 
analyzing situations, providing feedback, and recalling past experi­
ence. In fact, by giving voice to architecture through interconnected­
ness, we may re-create a time when humans had a closer relationship 
to space and its meaning. If nothing else, at least we can become better 
listeners. 
References
Alexander C, et al. A Pattern Language: Towns, Buildings, Construction. 
New York, Oxford University Press, 1977.
Alexander C. The Timeless Way of Building. New York, Oxford University 
Press, 1979.
Awan N, et al. Spatial Agency: Other Ways of Doing Architecture. 
Abingdon, Oxon, England; New York, Routledge, 2011.
Barabási A-Ls. Linked: How Everything Is Connected to Everything Else 
and What It Means for Business, Science, and Everyday Life. New York, 
Plume, 2003.
Brand S. How Buildings Learn: What Happens After They’re Built. New 
York, Viking, 1994.
Brawne M. Architectural Thought: The Design Process and the Expectant 
Eye. Amsterdam; Boston, Elsevier: Architectural Press, 2005.
Carpo M. The Alphabet and the Algorithm. Cambridge, Mass., MIT 
Press, 2011.
41	 Awan (2011).

 13. ARCHITECTURE AS INTERFACE   |  311
Conklin, E. J. Dialogue Mapping: Building Shared Understanding of 
Wicked Problems. Chichester, England; Hoboken, NJ, Wiley, 2006.
Conrads U. Programmes and Manifestoes on 20th-Century Architecture. 
London, Lund Humphries, 1970.
Daston L. Things That Talk: Object Lessons from Art and Science. New 
York; Cambridge, Mass., Zone Books; MIT Press distributor, 2004.
Day C, Parnell R. Consensus Design: Socially Inclusive Process. Oxford, 
Architectural, 2003.
De Botton A. The Architecture of Happiness. London; New York, Hamish 
Hamilton, an imprint of Penguin Books, 2006.
Frazer JH. “The architectural relevance of cybernetics.” [Univ of U., 
Belfast (United Kingdom)]. Systems Research. Retrieved from http://
www.osti.gov/scitech/servlets/purl/457730, 1993.
Eastman CM. Adaptive-Conditional Architecture in Design Participation, 
edited by Nigel Cross. London. Academic Editions. 1992;51-7.
Fox M, Kemp M. Interactive Architecture. New York, Princeton 
Architectural Press, 2009.
Hays KM. Architecture Theory since 1968. Cambridge, Mass., The MIT 
Press, 1998.
Jencks C, Kropf K. Theories and Manifestoes of Contemporary Architecture. 
Chichester, England; Hoboken, NJ, Wiley-Academy, 2006.
Jones JC. Design Methods. New York, Van Nostrand Reinhold, 1992.
Karatani KJ, Speaks M. Architecture as Metaphor: Language, Number, 
Money. Cambridge, Mass.; London, MIT Press, 1995.
Lawson B. How Designers Think. London; Boston, Butterworth 
Architecture, 1990.
LaVine L. Mechanics and Meaning in Architecture. Minneapolis, 
University of Minnesota Press, 2001.
McCullough M. Digital Ground: Architecture, Pervasive Computing, and 
Environmental Knowing. Cambridge, Mass., MIT Press, 2004.
Mayerovitch H. How Architecture Speaks and Fashions Our Lives. 
Montreal, Robert Davies, 1996.

312  |   DESIGNING FOR EMERGING TECHNOLOGIES
Mückenheim MA., Demel JA. Inspiration: Contemporary Design 
Methods in Architecture. Amsterdam, BIS; Enfield: Publishers Group 
UK [distributor].
Negroponte N. The Architecture Machine. Cambridge, Mass., MIT 
Press, 1970.
Nesbitt K. Theorizing a New Agenda for Architecture: An Anthology of 
Architectural Theory, 1965–1995. New York, Princeton Architectural 
Press, 1996.
Norberg-Schulz C. Genius Loci: Towards a Phenomenology of Architecture. 
New York, Rizzoli, 1980.
Norman DA. The Design of Everyday Things. New York, Basic Books, 
2002.
Rowe PG. Design Thinking. Cambridge, Mass., MIT Press, 1987.
Sánchez RA, et al. “Construction processes using mobile augmented 
reality: a study case in building engineering degree.” In Advances in 
Information Systems and Technologies, Rocha Á, Correia AM, Wilson T, 
Stroetmann KA (Eds.). Springer Berlin-Heidelberg. 2013;206:1053-62.
Vitruvius P, et al. Vitruvius: Ten Books on Architecture. New York, 
Cambridge University Press, 1999.

313
[ 14 ]
Design for the Networked 
World: A Practice for the 
Twenty-First Century
MATT NISH-LAPIDUS
The Future of Design
Bruce Sterling wrote in Shaping Things (MIT Press) that the world is 
becoming increasingly connected, and the devices by which we are con­
necting are becoming smarter and more self-aware. When every object 
in our environment contains data collection, communication, and 
interactive technology, how do we as human beings learn how to navi­
gate all of this new information? We need new tools as both designers, 
and humans, to work with all of this information and the new devices 
that create, consume, and store it.
Today, there’s a good chance that your car can park itself. Your phone 
likely knows where you are. You can walk through the interiors of 
famous buildings on the Web. Everything around us is constantly col­
lecting data, running algorithms, calculating outcomes, and accumu­
lating more raw data than we can handle.
We all carry minicomputers in our pockets, often more than one; pub­
lic and private infrastructure collects terabytes of data every minute; 
and personal analytics has become so commonplace that it’s more con­
spicuous to not collect data about yourself than to record every waking 
moment. In many ways we’ve moved beyond Malcolm McCullough’s 
ideas of ubiquitous computing put forth in Digital Ground (MIT Press) 
and into a world in which computing isn’t only ubiquitous and invisi­
ble, but pervasive, constant, and deeply embedded in our everyday lives.

314  |   DESIGNING FOR EMERGING TECHNOLOGIES
Augmented reality (AR) is here, already deeply engrained in our under­
standing of the world. The screen-based AR espoused by apps such as 
Layar is primitive compared to the augmentations that we all use on a 
daily basis. Google Maps, Twitter, Facebook, Nike FuelBand, and more 
are prime examples of how we are already augmenting our reality in 
fundamental ways that are less obvious and intrusive than digital over­
lays (which will see their day eventually, I’m sure). We have been aug­
menting our reality since the invention of clothing allowed us to live 
in harsher climates, and now we are augmenting it with networked 
technology giving us not just a sixth sense, but a seventh, eighth, and 
ninth, as well.
As augmentation and networks change our understanding of reality, 
we begin to understand old technology through our lens of new media. 
A chair is no longer solely a physical object that exists in our environ­
ment, it is now an interactive object by which specific behavior and per­
son-to-person relationships can emerge from its use (Buchanan, 2011). 
A building is no longer only a collection of materials that defines a 
place, it is also understood through its interactions with people, the 
interactions it facilitates, and how it interacts or interferes with our net­
worked augmentations. We are McLuhan-esque cyborgs, with media 
devices that extend our body and mind from the outside. Objects that 
exist as part of this network become more than their discrete pieces; we 
internalize their behavior and it changes the way we understand our 
world and ourselves. 
We can see shifts in common language that allude to these changes. 
We talk about “downloading” knowledge from one person to another 
and “interfacing” with organizations. Words like “interface,” “down­
load,” and “stream,” once not commonly used outside of technologi­
cal circles, are now part of our daily lexicon, used in reference to their 
technological meaning as well as applied to much older concepts in the 
physical world.
A 2007 study on mobile phone usage conducted by Nokia concluded 
that the mobile phone is now one of the most essential items for daily 
use around the world, putting it in the same social category as wallets 

 14. DESIGN FOR THE NETWORKED WORLD   |  315
and keys.1 They identified that it wasn’t only the object itself that is 
important to people, it is the social identity it provides that people value. 
The phone is more than an object—it is a lifeline, a gateway through 
which people connect with their family, friends, livelihood, and com­
munity. This is even truer now with the prevalence of smartphones 
with always-on Internet access. The smartphone has become one of the 
current embodiments of the networked world; more than its function, 
more than its form, it is a social safety net that allows people to travel or 
live further away from their home and still feel connected.
The smartphone is still a tangible object, one that we can understand 
through our hands and eyes, and it has connections to the network that 
we can see and feel. A greater shift is occurring now through objects 
that connect in less visible ways—objects that act on our behalf, or 
against us, without our explicit knowledge. The ethical implications 
and choices made by algorithms that determine the flow of traffic, our 
food supply chain, market pricing, and how you measure your fitness 
are present in our lives but are largely below the surface. As connected 
systems spring up around the world, often bypassing the more out­
dated infrastructure we are dealing with here in North America, we 
need to begin considering the biases and implications of our choices 
when designing these systems, objects, and networks. For example, 
the current sensors used to trigger traffic lights often rely on induc­
tion pads embedded in the road. These sensors only detect cars and 
other large vehicles, and are unable to sense bicycles and pedestrians. 
There’s an implicit decision made about the relative importance of dif­
ferent modes of transportation. A traffic system built on an inductive 
sensor network will always prioritize car and truck traffic over cyclists, 
for example, making the city a less hospitable place to ride a bike. This 
can in turn impact population density, pollution, congestion, parking, 
employment, injury rates, and more.
As we move even further into a networked world, we as designers of 
these new devices and services need to understand all aspects of our 
new environment. The complexity of design and architecture will only 
continue to grow and require a new definition of design foundations, 
practice, and theory. 
1	 Cui, Yanqing, Jan Chipchase, and Fumiko Ichikawa. 2007. “A Cross Culture Study on 
Phone Carrying and Physical Personalization.” Nokia Research, https://research.nokia.
com/files/45590483.pdf.

316  |   DESIGNING FOR EMERGING TECHNOLOGIES
This might seem daunting, but no more so than the nature of mass 
manufacturing and new materials seemed to the early industrial 
designers and architects of the twentieth century. We must look to new 
media art practice, design history, and new research in order to apply 
our craft to our current context. Designers make things that reflect 
their environment, but also shape that same environment through the 
objects that they create, laying the foundation for the future.
We have strong foundations stretching back over a century of art, archi­
tecture, and industrial design. We don’t need to begin again, but we do 
need to continue to evolve our practice to incorporate new techniques, 
tools, and capabilities that help us understand the potential of today’s 
technology.
What are the aesthetics of feedback, immersion, and communication? 
How can we apply foundations of interaction, such as time and meta­
phor, to the exchange of data between machines that facilitates an ath­
lete learning how to perform better? What is a beautiful network and 
how do we recognize and critique it? These are the questions we now 
face, ones that we will continue to explore through our work and try to 
answer with objects, systems, places, and conversations.
New Environment, New Materials
[W]e have witnessed a paradigm shift from cyberspace to pervasive 
computing. Instead of pulling us through the looking glass into some 
sterile, luminous world, digital technology now pours out beyond the 
screen, into our messy places, under our laws of physics; it is built 
into our rooms, embedded in our props and devices—everywhere.
—MALCOLM MCCOLLOUGH, DIGITAL GROUND (MIT PRESS), P 9
Over the past couple of decades, our environment has changed 
significantly.
Screens are everywhere all the time. This means that the complex inter­
actions afforded by screens are even more important to understand and 
design properly.
Physical objects are now imbued with “smart” features using sensors, 
networks, and physical interactions that are often invisible, having no 
screen whatsoever. This makes physical object design more and more 
important for designing modern products, shifting focus back toward 
industrial design and architecture and away from the myopic attention 
to screens that interaction design has had recently.

 14. DESIGN FOR THE NETWORKED WORLD   |  317
Machine to machine communication is at the heart of many interac­
tions and systems that we can’t live without. This means that designers 
need to think about not just the human actors in a system, but also the 
objects, networks, and algorithms that run our environments.
This puts the modern designer in a bit of a sticky situation. As an exam­
ple, a project on which we recently embarked at Normative includes a 
mobile app that communicates with a physical box of electronics affixed 
to the back of a ski that is laced with embedded sensors, as shown in 
Figure 14-1. That box also needs to be aesthetically pleasing and fit the 
skier’s understanding of how a ski accessory should look and feel. The 
skier needs to enjoy working with the companion mobile app in a way 
that enhances the skiing experience. The box of electronics that reads 
the data from the sensors embedded in the ski needs to communicate 
that data to the mobile device, and has to communicate that it is doing 
something to the person on the skis through a simple display of LEDs 
and recessed buttons. All of this needs to happen in a way that makes 
sense to the skier, doesn’t detract from skiing, and withstands the envi­
ronment of the slopes.
Figure 14-1. An early ski prototype2
2	 Copyright Normative, 2013

318  |   DESIGNING FOR EMERGING TECHNOLOGIES
In this example there are many types of design at work—industrial 
design for the skis and the electronics box; graphic design for the labels, 
ski graphics, packaging, and mobile app interface; interaction design 
for the mobile app; system integration; and coordinated communica­
tion between the app and the box. This is in addition to all the engi­
neering involved in the hardware and software to make this all work.
What we witness in projects such as this one is a shift in the way 
we’re working from the industrial model of design → build → sell to a 
post-industrial model wherein all those things happen simultaneously 
in an integrated and iterative way within a small team. The initial pro­
totype of the circuit was created by an interaction designer using an 
Arduino, and then an engineer and the designer worked together to 
refine the circuit through iteration. An integrated team of designers 
from different practices, creative technologists, engineers, and fabrica­
tors is required to design, build, and iterate on a system this complex.
At the heart of this team is a design practice that coordinates all the 
moving pieces, keeps the overall system in mind, and is the arbiter of 
the aesthetic and functional coherence of the final product. The lead 
designer needs to have a refined sense of aesthetics as it relates to the 
appearance of the physical product, the software, and the system that 
makes them work together. Figure 14-2 demonstrates this team effort 
at work as the prototype begins to transition toward a more polished 
product.
The overall aesthetics and quality of the interactive system, product, 
and associated software is the purview of this new breed of designer, 
including the impact and implications of the product. The modern 
designer needs to have a foundation in traditional design disciplines 
and interaction foundations, which acts as a framework for thinking 
about the form of objects and interfaces, as well as good understand­
ing of systems theory, cybernetics (the study of feedback, relationships, 
and communication within a system), and culture, including a basic 
grasp of ethnography and anthropology in order to understand differ­
ent contexts and cultures.

 14. DESIGN FOR THE NETWORKED WORLD   |  319
Figure 14-2. A higher fidelity prototype of the electronics and enclosure for the 
skis3
HAPPENINGS, CONVERSATIONS, AND EXPLORATION
In late 1968 Jack Burnham, a writer and art history professor, wrote the 
following in his paper System Esthetics:
The specific function of modern didactic art has been to show that art 
does not reside in material entities, but in relations between people 
and between people and the components of their environments.
He was looking at the emergence of large-scale interactive artworks 
and art events in the 1960s. Artists began to see their work as more 
than the object itself; they began to think about how the object interacts 
with the audience and environment to create a conversation.
Artist David Rokeby explored the emotion and aesthetics of environ­
mental feedback systems in his early works Reflexions, Body Language, 
and Very Nervous System in the 1980s. Rokeby created one of the earli­
est examples of gestural interface by building his own 8 x 8 pixel digital 
camera and programming his own software to read the video input and 
3	 Copyright Normative, 2013

320  |   DESIGNING FOR EMERGING TECHNOLOGIES
create feedback in the form of sound and video.4 To fully understand 
the aspects of movement and feedback systems he was interested in, he 
had to learn new technologies, create innovative solutions to unknown 
problems, and build his own sensors and output devices. If this sounds 
familiar, it’s because these are exactly the same types of activities and 
problems facing designers and artists today. Figure 14-3 presents a 
series of images illustrating the results of people interacting with the 
system.
Figure 14-3. Various people interacting with David Rokeby’s Very Nervous 
System (1986 – 2004) at aceartinc., Winnipeg, Canada5
To explore new concepts, behaviors, and environments, artists and 
designers need to develop a new set of tools and skills. Architects and 
interior designers use physical models, known as a maquette, to exper­
iment with form, materials, lighting, orientation, and other properties 
of their designs. Similarly, designers working with emerging technol­
ogies need tools to experiment, mold, and model the elements of net­
worked devices, software, and complex systems.
4	 Rokeby, David. 1982–1984. “Reflexions,” http://www.davidrokeby.com/reflex.html.
5	 Photos by William Eakin, Liz Garlicki and Risa Horowitz. Image arrray design Mike 
Carroll. 2003.

 14. DESIGN FOR THE NETWORKED WORLD   |  321
The success of new design tools to help work with somewhat intangible 
materials has to be measured based on how well it helps the designer 
understand the parameters of her design, and make choices based on 
experiencing aspects of the design in context. These tools should allow 
for different levels of generative and synthetic activities, varying fidel­
ity, working with high-level abstract notions all the way down to the 
small functional and aesthetic details of the final product.
The current generation of digital design tools (CAD, Adobe Creative 
Suite) created new ways of working on traditional types of outputs. 
They gave us the ability to create many more variations of layouts, the 
safety of undo and file versions, and access to previously impossible or 
difficult processes for creating effects and working with new source 
material. However, they did not fundamentally change the component 
pieces of the designer’s process, toolbox, or output.
These tools are coming up short as designers are beginning to work 
with complex communications between people and machines, interac­
tions and movement that happens over long periods of time and many 
individual devices, and large data sets that can’t easily be visualized 
using manual methods.
To add to this complexity, the entire notion of finality has changed. 
Designers traditionally create outputs that remain static, or have a 
small set of variations, once produced. Modality in traditional prod­
ucts was more a result of context, use, customization, or modification. 
In new types of products there is no “final version,” rather the product 
itself is a system, reacting to its environment and interactions, contin­
ually changing and evolving with use.
TWENTY-FIRST CENTURY FOUNDATION
Designers in the twentieth century needed to internalize and deeply 
comprehend things like 2D and 3D form, physical environments, and 
typography (to name a few areas of practice). The twenty-first century 
designer needs to build on these foundations with a number of new 
elements. The traditional elements of design were well established by 
Rowena Reed-Kostellow and her colleagues in the 1930s: line, plane, 
color, volume, value, and texture. She used these as the basis for her 

322  |   DESIGNING FOR EMERGING TECHNOLOGIES
groundbreaking design foundations pedagogy at Carnegie Tech.6 Dave 
Malouf presented an initial set of interaction design foundations in 
an article for Boxes and Arrows in 2007,7 and then expanded upon 
it in a presentation at Interaction’09. He includes elements of time, 
abstraction, metaphor, negativity, and motion in his set of expanded 
foundations.
The things we design now are beyond screens and objects and we are 
challenged to think of the next set of foundations for designing these 
systems. We can begin to draw inspiration and knowledge from cyber­
netics, soft systems theory, and urbanism along with more commonly 
referenced practices such as architecture and anthropology. 
When working with invisible technology and systems that cannot be 
observed easily, visualizations become even more important. Often, 
the only way that a system and all of its interactions and decisions can 
be understood is through illustrations and narratives that look at the 
impact as well as the cause of each part of the interaction.
As we examine these systems we should pay special attention to the 
qualities, aesthetics, of the elements of the system. A set of aesthet­
ics qualities of a system includes new foundational elements that 
build upon traditional design foundations and Malouf’s interaction 
foundations.
Texture
What is the connectivity of the system? How do the pieces interact with 
one another, both human and nonhuman? The texture of the network 
is what we think about when we look at how easy it is to interface with 
its different parts. If the connections are obvious and accessible, we 
might describe the interface as smooth; if the connection points are 
difficult or confusing, that could be described as rough.
The notion of texture can be applied to graphical interfaces, gestural 
or spatial interfaces, hardware controls, and APIs alike, among other 
things. How might one describe the qualities of their bank’s system? 
6	 Hannah, Gail Greet. 2002. Elements of Design: Rowena Reed Kostellow and The Structure of 
Visual Relationships, Princeton Architectural Press.
7	 Malouf, Dave. 2007. Foundations of Interaction Design. Boxes and Arrows, http://
boxesandarrows.com/foundations-of-interaction-design/.

 14. DESIGN FOR THE NETWORKED WORLD   |  323
This could include their ATMs, customer service, transfer between 
institutions, and more. Often a designer (or critic) will only be con­
cerned with a subset of a network system, but it’s always good to pay 
attention to how that piece interacts with the whole and how the system 
responds to those inputs.
Agency
What is the component’s capacity to act on the other parts of the net­
work or the system as a whole? Can a person interfacing with the prod­
uct influence the rules of the system? Or, are his potential actions con­
strained by other aspects of the system? How much freedom does each 
network component have within the system? 
The agency of each actor within the system depends on its role. From 
a human perspective, agency can describe how much power a user 
can exert on other parts of the network, versus being limited to spe­
cific actions in specific contexts. Different actors will have different 
amounts of agency at different times.
Opacity
How clear is the network from the perspective of a participant or 
observer? Are the connections easily visible or are they hidden? The 
opacity of a network can influence how much agency each actor has 
and help to create the desired texture. 
In our traffic-light example, we see a very opaque system, one where 
the means of interacting are often completely hidden. It would be easy 
to interact with the system and still not even know that it exists. In this 
example, the opacity has a direct impact on a person’s agency, but if the 
system behaves properly, the texture might still be smooth. Roughness 
will become apparent if the system misbehaves and nobody can see 
what is happening.
Reflexivity
How do you know what is happening in the network? How does it 
inform the different actors, both human and nonhuman, what state it 
is in and if there are any problems? Feedback and communication is a 
vital piece of any system.
Reflexivity is the way in which the particular system provides feed­
back based on states, actions, and behaviors. This is an indication that 
the rules of the system are enforced. By providing feedback when a 

324  |   DESIGNING FOR EMERGING TECHNOLOGIES
component attempts an action the system can let all of its parts know 
what is happening, if the action was completed, and what the new state 
looks like. The quality of this feedback is important to crafting the aes­
thetic of the system. Is it friendly? Verbose? Human readable? All of 
these things will change the overall feel of the products and services 
that are part of the network.
These are some possible aesthetic elements we can begin to use to dis­
cuss the qualities of a network system. None are inherently good or 
bad; they are the basis for a common language that lets us discuss the 
aspects of a network that affect its quality. An opaque network with lit­
tle agency creates a certain type of interaction, one largely dictated by 
its owner. A low-opacity network with a lot of agency allows for more 
flexibility and potential wrangling by the person interfacing with the 
system. 
The types of systems and products described by the above aesthetic lan­
guage can be understood in two important ways (among others):
1.	 As a hard system: a system model that is concrete and constructed 
to achieve an objective. These types of systems are easy to analyze 
and model because they are generally made up of discrete pieces 
that each plays a set part, most often actual things that exist in the 
physical world.
2.	 As a soft system: a system model that is fuzzy and focuses on the 
understanding of the system from many perspectives. In this type 
of model each piece of the system is based on a subjective under­
standing of the whole, rather than specific objects that exist in the 
world.
For the type of design discussed in this chapter we are more concerned 
with soft systems, although both soft and hard must exist in order to 
fully understand and build a product or service in our networked world.
Soft systems methodology (SSM), a framework for thinking about epis­
temological systems, gives us tools to help understand an unstructured 
complex problem through modeling actions and subjective under­
standing of the situation. Unlike hard systems, soft systems models 
aren’t about classification; instead the practice seeks to explain differ­
ent relationships by describing them as they are seen, understood, and 
acted upon. A single set of objects and relationships could be described 
in many different ways, each one equally valid from a different 

 14. DESIGN FOR THE NETWORKED WORLD   |  325
perspective. Soft systems have always had a close tie to the way design­
ers work. Peter Checkland, one of the SSM pioneers, said the following 
in his book Systems Thinking, Systems Practice:
Its rationale lies in the fact that the complexity of human affairs is 
always a complexity of multiple interacting relationships; and pictures 
are a better medium than linear prose for expressing relationships. Pic­
tures can be taken in as a whole and help to encourage holistic rather 
than reductionist thinking about a situation
Design’s tradition of visualization and sketching fit very well with 
SSM’s tendency toward visualization from the perspective of an actor 
within the system. In the networked world the designer’s ability to 
understand, explore, and explain complex interactions between people 
and machines, and machines to machines, becomes even more import­
ant. SSM gives us a starting point to understand how to reframe com­
plex situations through a process that begins by embedding oneself 
into the situation, expressing what you observe and understand that 
situation to be, and then creating diagrams that express that under­
standing. Once the system is visualized it can be compared to observed 
reality to understand which definition fits best in the given context and 
what actions one should take to affect the system, described in SSM as 
feasible and desirable changes. The use of visual tools helps the design­
ers and stakeholders build the same mental model, rather than the 
ambiguity of individual conceptions.
Tools like this one become a primary piece of the twenty-first cen­
tury designer’s kit. Making sense of and expressing complex systems 
of relationships, communication, and feedback lay the foundation for 
good design decisions when dealing with complex networks, invisible 
interfaces, and nuanced interactions.
New Tools for a New Craft
Although much of the core design process is fundamentally the same 
as it was 30 years ago—beginning with exploratory methods includ­
ing research and sketching, moving through models and prototypes of 
different fidelities toward a final product—the types of problems we’re 
trying to solve and the tools we need to explore those solutions con­
tinue to change and evolve. New types of products require new types of 

326  |   DESIGNING FOR EMERGING TECHNOLOGIES
models and prototypes. Animation, electronics, 3D printing, and inter­
active programming are all necessary parts of the designer’s repertoire 
when working with emerging technologies and twenty-first century 
products. 
Tools traditionally thought of as the domain of engineers, data scien­
tists, and hackers are now entering the designer’s toolbox. For example, 
a designer working with emerging technologies such as sensor net­
works, data collection, and microcontrollers benefits greatly by learn­
ing some basic electronics. Being able to put together a quick proto­
type by using a platform such as Arduino means that the designer can 
experiment with the possibilities available to him based on the types 
of sensors and data at his disposal. Even if the final product will use 
a different engineering solution, this basic toolset gives designers the 
capability to model the interactions, data, and physical aspects of a new 
product at a high level, and with practice, at a detailed level.
Working with large and complex data sets is becoming the norm for 
designers working on new products. This data can come from custom 
collectors, such as sensors embedded in products, or from the tangle of 
information available through web services. When working with large 
data sets, there is no substitute for working with the data itself. Tools 
such as Processing or JavaScript and the browser canvas object provide 
an easy way to start creating rich interactive visualizations from any 
data.
Rapid fabrication starts to shift industrial design away from being 
industrial and back to a more artisanal craft. Designers can now imag­
ine a new physical form, model it with traditional tools such as clay, do 
a digital CAD drawing, and have it fabricated in plastic or metal within 
a few hours. This facilitates a kind of rapid iteration and prototyping 
for complex objects that would have been difficult 10 years ago. It also 
allows for small run production; whereas purely artisan craftspeople 
could produce only a few objects, and industrial production could only 
produce high volumes of objects, these new methods make it possible 
for designers to produce dozens of objects, each the same or slightly 
different.
These methods can be thought of as a similar process to industrial 
designers making clay or paper models, or architects using foam-core 
to make scale models of a new building. None of these things is analo­
gous to the final form, but they are hands-on ways of exploring integral 

 14. DESIGN FOR THE NETWORKED WORLD   |  327
aspects of the design in a fast, cheap, and easy way. Including this in 
the design process helps illuminate new possibilities and filter out 
ideas that don’t translate. These are ways of sketching with interactiv­
ity, responsiveness, and movement, iterating to a model of the product 
or pieces of the product.
Along with new tools come new collaborations. The Maker community 
and local hack-labs, both groups of people who deeply experiment with 
new technology for creative purposes, are now home to many technol­
ogists and designers working together to make interesting and future 
focused things. These collaborations result in products such as Berg’s 
Little Printer, the plug-and-play robotics kit, Moti, and DIY home auto­
mation tools like Twine. Bio-hack labs are also beginning to pop up, 
pushing into biology and chemistry, and experimenting with bioen­
gineering in an accessible way. One such group in Toronto, DIYBio 
Toronto, hosts regular workshops. Companies such as Synbiota, an 
open source repository for bio-hacking, are forming to support the 
community.
These are just the beginning, as startups and large companies move 
into this new space. One of the most successful examples on the mar­
ket today is the Nest thermostat, which combines innovative physical 
controls with small screens, microprocessors, and software to add a 
level of smart automation to the home. A product that started out as a 
better thermostat is poised to be the hub of a much larger home con­
trol system.
How do we begin to work with these new technologies, networks, and 
systems? There are a few ways to dive in that will help to understand 
the potential, constraints, and complexities involved.
Experiment
Arduino and similar platforms are easy to find at local stores or online, 
and they are cheap. Pick one up, find a tutorial, and dive in. Have an 
idea for a project you’d like to try? Just try it, don’t worry if it seems com­
plicated. Start with the simplest piece. These systems give you all the 
pieces you need to build network-connected objects.

328  |   DESIGNING FOR EMERGING TECHNOLOGIES
Learn new skills
If you’ve never programmed before, pick up a JavaScript, Processing, or 
Ruby tutorial. If you’ve never designed a physical object, get some mod­
eling clay and sculpting tools and try to make some interesting shapes. 
If you’ve never designed software before, try to map out a flow or design 
an interface; start with pencil and paper.
Be critical
When you’ve made your first new thing, take some time to think 
about its qualities using some of the frameworks discussed earlier 
in this chapter. Use what you learn from this reflection in your next 
experiments.
Always think about how your new device, software, or system fits into 
the larger connected world. What possibilities does it create? What 
potential does it remove? What does it give to people, and what does it 
take away?
You won’t be satisfied with your first attempt, but design is all about 
iteration. These types of new skills open many possibilities for your 
practice as a designer, allowing you to incorporate new technology, pro­
cesses, and techniques into your work. 
MAKING THE FUTURE IN WHICH WE WANT TO LIVE
The active ingredient of the work is its interface. The interface is 
unusual because it is invisible and very diffuse, occupying a large 
volume of space, whereas most interfaces are focussed [sic] and 
definite. Though diffuse, the interface is vital and strongly textured 
through time and space. The interface becomes a zone of experience, 
of multi-dimensional encounter. The language of encounter is initial­
ly unclear, but evolves as one explores and experiences.
—DAVID ROKEBY ON VERY NERVOUS SYSTEM8
David Rokeby used the preceding statement to describe the nature of 
his Very Nervous System interactive installation. These same words 
now describe our relationship to an ever-increasing amount of invisi­
ble architecture acting around us. The metaphorical handles and but­
tons that we design into these largely invisible systems will determine 
8	 Rokeby, David. 2010. “Very Nervous System,” http://www.davidrokeby.com/vns.html.

 14. DESIGN FOR THE NETWORKED WORLD   |  329
people’s ability to comprehend, manage, and benefit from the things 
we design. Returning to our traffic sensor example, when a hidden sen­
sor at a busy traffic intersection is designed to trigger the lights based 
on certain physical aspects of a vehicle, the designer of that system 
needs to decide what types of vehicles are allowed to trigger the lights. 
Will it work for cars, bicycles, or humans? That choice is a decision that 
will impact the shape of the urban environment in a way that most peo­
ple using the intersection will never fully see. How do you indicate the 
system’s texture, agency, opacity, and reflexivity? Do you add symbols 
to the road to indicate the existence of a sensor and what will activate it? 
Do you opt for a different solution entirely because of the needs of the 
city? These are design problems at a systems scale and are becoming 
more and more common in the work we do every day. We need to make 
sure we are arming designers with the tools they need to make these 
types of decisions intentionally.
Design is a special craft, one that allows us to imagine the future as 
we would like to see it, and then make the things that will help get us 
there. Pre-industrial products were the output of a single craftsperson, 
and expressed their understanding and view of the world. Industrial 
products represented a move to mass production and consumption, 
where a designer could envision a product and millions of people could 
receive an identical object. This was the expression of the collective—
the design of objects shaped our environment and culture on a large 
scale. 
As we move deeper into a post-industrial era new products are the 
expression of the network. Small groups can now cocreate and produce 
objects at industrial scales, or can create complex objects at minute 
scales for their own needs. Where pre-industrial objects represented a 
one-to-one relationship between creator and consumer and industrial 
objects were one-to-many, post-industrial moves into a many-to-many 
world. Everybody is enabled to create and consume. With this comes a 
great freedom, but also a great dilemma. Do all these new objects help 
us create a better future? Do they represent the world we want to live 
in? Each new creation warrants a consideration of these questions as 
we continue to redefine our environment using new technology, and to 
see the world through our new, networked lens.
This era of post-industrial design brings with it new opportunities and 
more complex challenges, and we should dive in headfirst.

Claire Rowland,
Elizabeth Goodman,
Martin Charlier,
Alfred Lui & Ann Light
Designing 
Connected 
Products
UX FOR THE CONSUMER 
INTERNET OF THINGS

Designing for Connected Products:  
UX for the Consumer Internet of Things 
 
Chapter 1 What's different about UX design for the internet 
of things 
Chapter 2 Things: the technology of connected devices 
Chapter 3 Networks: the technology of connectivity 
Chapter 4 Product/service definition and strategy 
Chapter 5 Understanding Users 
Chapter 6 Translating research into product definitions 
Chapter 7 Embedded Device Design 
Chapter 8 Interface Design 
Chapter 9 Cross-Device Interactions and Interusability 
Chapter 10 Interoperability  
Chapter 11 Responsible IoT Design  
Chapter 12 Supporting Key interactions  
Chapter 13 Designing with Data  
Chapter 14 Evaluation and Iterative Design methods  
Chapter 15 Designing Complex Interconnected Products 
and Services  
	  

 
 
4 
Product/service definition  
and strategy 
Claire Rowland 
Introduction 
We all aspire to create the killer product or service that people want to buy and 
love using. The key to this is ensuring that the product solves an actual 
problem that people have, in a way that appeals to them. At a pinch, it might 
provide them with something new and wonderful that they never knew they 
needed. It sounds simple and obvious, but it can be remarkably difficult to get 
this right. Right now, the IoT market is skewed towards innovators and early 
adopters. There’s huge potential to create great new products for consumers, 
but they may have to contend with new types of complexity. 
 
This chapter introduces: 
O 
Productization as part of IoT design (see page 2). 
O 
What makes a good product for different audiences (see page 7). 
O 
How products differ from tools (see page 14). 
O 
What makes a good product (see page 19). 
O 
Building service offerings around products (see page 28). 
O 
Business models in IoT (see page 35). 

 
 
 
 
This chapter addresses the following issues: 
O 
Why a clear value proposition is a prerequisite to great UX design (see 
page 4). 
O 
Why products designed by and for innovators aren’t necessarily right for 
general consumers (see page 7). 
O 
Why consumers want products, not tools (see page 14). 
O 
Why it’s important to design the service offering around a product (see 
page 33). 
O 
How business models can shape UX (see page 35). 
O 
How digital business models may start to appear in real world products 
(see page 37). 
Making good products 
What is productization? 
Productization is the extent to which the supplier makes the user value of the 
product explicit and easy to understand. Compelling products don’t just look 
good or otherwise fuel some underlying need for status (although those things 
are often important). They make it immediately apparent to their intended 
audience that they do a thing of real value for them: preferably something new 
than serves a previously unmet need. 
 
Nest is probably the most famous IoT productization success story. Consumers 
were resigned to thermostats and smoke alarms being ugly, annoying boxes 
with usability flaws. It hadn’t occurred to most people that they could be 
better. Nest products promise to do the job better than most of the competition, 
in the form of attractive and desirable hardware that users are happy to have on 
show at home (see figure 4.1). Of course, they are premium products with a 
premium price tag. The point here is not that all products should be expensive, 
but that a good product should fulfill a clear need for the target audience, with 
a usable and appealing design. This is the product’s value proposition: the 
user’s understanding of what the product does for them and why they 
might want it.  

 
 
 
Figure 4.1: Nest thermostat shown in home (image: Nest) 
 
“Never underestimate the power of a simple explanation, or a product that 
looks nice. If people can understand it, they can want one for themselves. 
They’re not scared of it. It stops being a weird thing that geeks do.” Denise 
Wilton, designer (and former creative director of design agency BERG)1 
 
Products can be services 
When we talk about IoT, we tend to focus on the edge devices: the activity 
monitors, thermostats, connected pet feeders, and more. This is especially true 
when the devices themselves look novel (such as the Nabaztag rabbit shown in 
chapter 2) or striking (such as the Nest thermostat). 
 
But while the devices are a key part of the UX, they are not the whole picture. 
They are all dependent on an internet service. This makes the user’s 
relationship with the product much more dynamic. Instead of the traditional 
one-off purchase of a traditional physical product, the user interacts with the 
provider on an ongoing basis. The user’s experience isn’t just shaped by the 
device, it’s shaped by the whole service. There might not even be a physical 
product at all: just as you can now pay for Dropbox storage or personal fitness 
                                                             
1 From a talk at UX Brighton, November 2012 

 
 
training, so you may pay for software or storage to help you make the most of 
connected devices, or personalized health or energy saving advice based 
around data gathered from your devices.  
 
Author’s note: In this book, we use the term ‘product’ loosely to refer to a 
packaged set of functionalities that solves a problem for people or fits neatly 
into their lives. That could be a physical device, a service, or frequently a 
combination of both.   
 
Why is this in a UX book? 
To some of you, this may seem outside the remit you normally associate with 
UX design. You may work in a company where productization is handled by 
product management, or perhaps marketing. In others, it might be considered 
strategic design. UX is not always involved in identifying the opportunity and 
framing the solution. But most UX designers would walk over hot coals to be 
involved from the start, especially if they have first hand knowledge of user 
needs from conducting research.  
 
Whoever is responsible for it in your organization, it provides the strategic 
foundation for UX design. It’s not possible to design a great product or 
service experience if users don’t want, or understand, the service in the 
first place.  
 
Value propositions help sell products. But they also drive UX. A clear 
proposition helps users decide whether to buy it in the first place, but also 
helps frame their mental model of the system and what it does (see figure 4.2). 
When users are confident that they understand what the system does for them, 
they have a good basis for figuring out how it works (the conceptual model), 
and then how to use it (the interaction model). All the clever design in the 
world can’t overcome a murky or unappealing value proposition. 
 

 
 
 
Figure 4.2: A good clear value proposition is fundamental to a great UX.  
Why is this in an IoT book? 
Productization is of course not a challenge that is unique to IoT. It is included 
in this book as it is a particular challenge for the consumer IoT field right now. 
Many products and services aren’t yet offering good, practical solutions for 
proven consumer problems. Even where they are, the value isn’t always 
apparent from the product itself or clearly stated in terms target users would 
understand.   
 
This isn’t a criticism of the many clever and talented people working in this 
field. Most of them are aware that consumer experience is a challenge.  
 
It’s a result of the novelty and inherent complexity of the products and 
services. We’re still figuring out what we can do with the technology, and 
we’re asking users to wrap their brains around some novel devices and 
capabilities. 
 
It also reflects that new technology products and services are often conceived 
and developed by people with an engineering mindset who value highly 
configurable functionality. These initiatives can often seem complex and 
unclear in purpose to consumers because, in trying to do so much, they fail to 
communicate a clear value for using the service. 
 
There is, of course, a market for products developed to meet the needs of 
highly technical users. There’s also great value in products and services that 
help a wider range of people move beyond passive consumption of technology 
and learn how to construct their own solutions. For example, If This Then That 
offers an accessible way to coordinate different web services and even 
connected devices (see figure 4.3). This is functionality that would previously 
only have been available to those with good programming skills.  

 
 
 
Figure 4.3: An If This Then That recipe for saving Gmail attachments to 
Dropbox 
 

 
 
But the bigger challenge is in creating products and services that work for 
mass-market consumers. For this audience, the functionality – what the system 
does and how to use it - should be transparent. The underlying technology 
should be invisible. The user should be able to focus on getting the benefit 
from the product that they were promised, not on configuring it and 
maintaining it. 
 
From innovation to mass market 
The primary focus of this book is on creating consumer IoT products and 
services. In this section, we take a brief look at how technological innovations 
cross over into the mass market and consider what lessons there may be in 
here for IoT. 
 
Innovators are not consumers 
In 1962, the sociologist Everett Rogers introduced the idea of the technology 
lifecycle adoption curve, based on studies in agriculture2. Rogers proposed that 
technologies are adopted in successive phases by different audience groups, 
based on a bell curve (see figure 4.4). This theory has gained wide traction in 
the technology industry. Successive thinkers have built upon it, such as the 
organizational consultant Geoffrey Moore in his book ‘Crossing the Chasm’3. 
 
In Rogers’s model, the early market for a product is composed of innovators 
(or technology enthusiasts) and early adopters. These people are inherently 
interested in the technology and willing to invest a lot of effort in getting the 
product to work for them.  Innovators, especially, may be willing to accept a 
product with flaws as long as it represents a significant or interesting new idea.  
 
The next two groups - the early and late majority - represent the mainstream 
market. Early majority users may take a chance on a new product if they have 
seen it used successfully by others whom they know personally. Late majority 
users are skeptical and will adopt a product only after seeing that the majority 
                                                             
2 Everett M Rogers, 2003, ‘Diffusion of Innovations’ (5th edition), Simon & Schuster. 
3 Geoffrey Moore, 1991, ‘Crossing the Chasm’, HarperBusiness. 

 
 
of other people are already doing so. Both groups are primarily interested in 
what the product can do for them, unwilling to invest significant time or effort 
in getting it to work, and intolerant of flaws. Different individuals can be in 
different groups for different types of product. A consumer could be an early 
adopter of video game consoles, but a late majority customer for microwave 
ovens. 
 
 
 
Figure 4.4: The diffusion of innovations according to Everett Rogers. The blue 
line represents the successive groups adopting the technology, the yellow line 
the market share (Image: Tungsten, via Wikicommons). 
 
Geoffrey Moore identified a ‘chasm’ between the early adopter and early 
majority market (which he called visionaries and pragmatists). These groups 
have different needs and different buying habits. Mainstream customers don’t 
buy products for the same reasons as early adopters. They don’t perceive early 
adopters as having the same needs as themselves. Mainstream customers may 
be aware that early adopters are using the product. But this will not convince 
them to try it out themselves unless they see it as meeting their own, different, 
needs. So products can be successful with an early market, yet fail to find a 
mainstream audience. 
 

 
 
An example of this in the IoT space is the home automation market. Systems 
such as those based on the power line protocol X10 have been around for close 
to 40 years.  (Early examples ran over electrical power lines and analogue 
phone lines). The example in figure 4.5, from 1986, shows a system that 
allowed users to program and remotely control their heating, lighting and 
appliances over a (landline) phone. These are all applications that still seem 
novel and innovative to us; they would have excited the innovators of the 
1980s even more.   
 
Figure 4.5: Advertisement for X10 Powerhouse for the Commodore 64, from 
the January 1986 edition of Compute! Magazine (image via commodore.ca). 

 
 
 
However, home automation remained a niche market. It was expensive. It 
required significant technical skill to set up and maintain. Even those 
mainstream consumers who had heard of home automation did not see much 
value in programming their heating, lighting and appliances. Had it been more 
affordable or easier to use, more people might have been willing to try it out. 
But only now are consumers starting to see the utility of connected home 
products. This is arguably driven by the rise of the smartphone, giving us a 
metaphor for the ‘remote control for your life’. 
 
What’s different about consumers? 
Mainstream consumers are now more aware of connected devices, but they 
need to be convinced that these products will actually do something valuable 
for them. A product that appeals to an audience that loves technology for its 
own sake cannot simply be made easier to use or better looking. To appeal to a 
mass-market audience, it may need to serve a different set of needs with a 
different value proposition. Chapter 5, Understanding Users, covers learning 
about user needs and some of the special considerations you might encounter 
when designing for IoT. 
 
Mass-market product propositions have to spell out the value very clearly.  
Users will be subconsciously trying to estimate the benefit they’d get from 
your product as offset by the cost/effort involved in acquiring, setting up and 
using it, and you need to be realistic about the amount of effort they will be 
prepared to invest in your product. The further along the curve they are, the 
more users need products with a clear and specific value proposition, which 
require little effort to understand or use. And they have a very low tolerance 
for unreliability. Your product has made a promise to do something for them, 
and it must deliver on that promise. 
 
This is not simply a question of lacking technical knowledge, and certainly not 
of users being dumb. That 10-step configuration process to set the heating 
schedule might seem trivial in the context of your single product. But it can 
feel overwhelmingly complex in the context of a busy life with many other 
more pressing concerns. For this reason, consumers tend to be most attracted 
by products that seem as if they will fit into their existing patterns of behavior 
and don’t require extra effort. For example, ATM cards and mobile phones 

 
 
were arguably successful because they reduced the need to plan ahead in daily 
activities (getting cash from the bank, or arranging to meet). 
 
Value propositions for IoT 
The guidelines above can of course be applied to any type of product or 
service. But connected products can be complex and often do novel things that 
are hard to communicate succinctly.  
 
Core value propositions should be straightforward, e.g. a company offering 
smart meters may promise to “tell you where your energy spend is going”, 
which is relatively simple. A good test of an IoT product proposition is that 
end users should not need to focus on its connectivity or onboard computing: it 
should just make sense.  
 
But there may be complicating factors that users need to understand before 
buying. You may have to explain which other systems can interoperate with 
yours, or who owns the user’s data and what they can do with it. (The 
technology and value of interoperability is discussed in further detail in 
chapter 10). You might have to guarantee how far into the future you will 
maintain the internet service (if your company is acquired, goes bust or 
discontinues the product).  
 
The entrepreneur and academic Steve Blank describes 4 types of market in 
which a product can operate4 (see figure 4-6). The type of market influences 
how you position the value of your product. Below, we look at what this might 
mean for IoT products:  
                                                             
4 Steve Blank, 2005: “The Four Steps to the Epiphany: Successful Strategies for 
Products that Win” (K&S Ranch Press) 
 

 
 
 
Figure 4-6: 4 types of market in which a product can operate 
 
A new product in a new market 
Embedded connectivity and intelligence will fuel the appearance of new 
classes of product and new markets. In consumer terms, the challenge is often 
to convince users of your vision. You have solved a problem they didn’t 
realize they had, or had just accepted as ’the way things were’. The Glowcaps 
pill bottle top, mentioned in chapter 2, reminds users to take their medication 
and helps the patient’s doctor track how frequently it is taken. 
 
A new type of product in an existing market 
Here, the challenge is to convince users that your product is the best solution 
to the problem. Perhaps it has better features or better performance. In IoT, 
these products may be familiar physical devices newly enhanced with sensing 
or connectivity (e.g. the Withings bathroom scales). Users need to understand 
the value that is added by the enhancements, such as easier weight tracking. 
They need to decide whether it’s something they want, especially if it costs 
extra.  
 
It might also be a technology that offers a step change in experience design. 
For example, airport terminals can be large and confusing. You would 
normally rely on signage to find your way around, but this isn’t always clear, 
consistent or guaranteed to tell you what you need as and when you need it. 
You don’t want to miss your flight, but nor do you want to end up sitting 
around at the gate for too long because you were cautious and got there too 
early. Apple’s iBeacons technology (described in chapter 2) offers precise 
indoor location. Several airlines have been trialing the use of iBeacons to 
provide passengers with in-context information and directions (see figure 4.7). 

 
 
Passengers can be directed to the correct gate more easily, based on their 
current location in the airport. If they are running late but are very close to the 
gate, knowing their location might help the crew decide to wait. And if their 
plane is delayed, the app could provide them with a voucher to a nearby 
restaurant or café.  
 
Figure 4.7: Illustration of an airport iBeacon trial (Image: SITA).   
 
A low cost entrant to an existing market  
The falling cost of embedded computing enables cheaper alternatives to 
systems that used to be prohibitively expensive. For example, Lowes Iris (see 
figure 4.8) and Smart Things offer DIY home automation kits at a far lower 
cost than professionally installed systems. You may be aiming the system at 
people who could not previously afford this category of device, or trying to 
convince those who could that you’re offering a worthwhile saving. Either 
way, it’s important to convince users that the system performs the basic 
functionality just as well as more expensive options. Any compromise needs to 
be something that doesn’t matter too much. You need to be clear upfront how 
you have achieved the cost saving: is the hardware cheaper? Does the system 

 
 
involve more work from the user (e.g. DIY setup)? Does it provide them with 
less personal (e.g. automated or lower bandwidth) customer service? 
 
Figure 4.8: Lowes Iris Safe and Secure DIY home security kit (hub, motion 
sensor, two contact sensors, alarm keypad). (Image: Lowes). 
 
A niche entrant to an existing market  
Augmenting an existing product type with connectivity and potentially 
intelligence can create opportunities to address previously unmet user needs in 
an existing market. It may target a niche with specialist interests: for example, 
an energy monitoring system designed for those who generate their own 
electricity and may sell it back to the grid. Or it may introduce a premium 
product for those willing to pay more. The Nest thermostat offered the first 
intelligent heating solution with high-end hardware and polished UX design in 
a market previously dominated by ugly, unusable plastic boxes. This reshaped 
consumer expectations of what a heating controller could be, even in the part 
of the market that couldn’t or didn’t want to pay extra for a Nest. 
Tools vs. products 
For some specific connected devices, like a heating controller, there’s a close 
mapping between function and value. It’s easy for people to understand what it 
does. That’s not enough to make it a good heating controller. But it’s pretty 

 
 
clear what it does, and why you might want it. It will keep the house at a 
comfortable temperature and, perhaps, save money. Devices that are enhanced 
versions of pre-existing product types, like bathroom scales or baby monitors, 
have the advantage of being recognizable as things that meet a defined, 
familiar set of needs. You may have to convince customers as to why that 
product benefits from connectivity. And you may have to address concerns 
they have about adding connectivity or technical complexity to the product, 
such as security, privacy or usability. But at least the product is familiar. 
 
Mass-market consumers, in areas in which they do not have deep technical or 
domain knowledge, generally expect a product to come designed and 
engineered to fulfill a specific need. The Nest Protect smoke detector and 
carbon monoxide alarm is a good example of a product5. The marketing 
website focuses on the ways in which it is a better safety alarm (see figure 
4.9). Connectivity is only mentioned at the end, to say you’ll be alerted on 
your phone if there’s a problem when you’re away from home. 
 
                                                             
5 Nest Protect has suffered from some interaction design problems. A Heads Up feature 
originally allowed users to disable false alarms (such as those caused by burnt toast) by 
waving at the alarm.  But no-one had thought that, in the case of a genuine fire, users 
might also wave their arms (in panic). The alarm was therefore too easy to disable. 
Units were recalled and Heads Up was deactivated. But the Protect is still a good 
example of a clear product concept. 

 
 
 
Figure 4.9: Excerpt from the Nest Protect marketing website. (Image: Nest) 
 
But many IoT services and devices can be configured to meet all kinds of 
needs. The onus is on the user to define their own needs and configure the 
device (or service) to achieve them. These are not products, but tools. Tools 
are often general-purpose devices, such as contact or motion sensors. The 
device has no inherent value to the user. The value comes when they are 
applied to solve a particular need, such as detecting intruders in the home, or 
warning you that you left a window open. 
 
The Belkin WeMo smart plug (see figure 4.10) is a tool. It can be used to turn 
power to any appliance on and off remotely from a smartphone, or using an 
automated schedule. But it’s up to the user to define their own problem, realize 
that a smart plug could help, and configure it to solve the problem. An 
imaginative leap is required. In reality, many smart plugs end up being used on 
lamps. In our own research, users struggled to think of other uses for them 
(although ensuring hair straighteners/curling tongs were turned off was 
popular).  
 
Figure 4.10:  WeMo smart plug and app 
 

 
 
Services can be tools as well. The aforementioned If This Then That (which 
can also be used to control WeMo smart plugs), aims to make it easier for non-
technical users to link up and program devices and services. 
 
Tools aren’t bad. They can be very powerful for users with technical or 
domain knowledge. Users who have the time and motivation to configure a 
system to meet their own very specific needs and aren’t daunted by the need to 
learn the system may really enjoy this process. This could be the home brewer 
who enjoys rigging his or her own fermentation chamber out of an old fridge 
(see figure 4.11). Or a horticulturalist might be motivated to learn about the 
technology to configure a remotely controlled plant monitoring, watering and 
feeding system. Tools give us the possibility to be creative and take control of 
our environment. 
 

 
 
 
 
Figure 4.11: BrewPi is a fermentation temperature controller for brewing 
beer or wine. Running on a Raspberry Pi computer and Arduino6, it comes 
with a kit to convert a standard home fridge or freezer into a fermentation 
chamber and is controllable via a web interface. (Images: Anthony Plunkett). 
 
The IoT market, to date, has tended to create tools for innovators and early 
adopters. In an immature market that is exploring possibilities, that’s fine. But 
it has tended to assume that the way to reach a mass audience is to make 
better-designed tools.  
 
You can’t turn a tool into a million-selling product just by making it usable. 
The WeMo plug comes with a well-designed smartphone app that walks users 
through the setup process fairly clearly and makes it easy to set up rules to 
control the plug. But the onus is still on the user to use the plug creatively. It’s 
not actually the plug they want to control: it’s the appliance. Controllable 
plugs are simply a first step in the journey towards controllable appliances.  
 
In spring 2014, WeMo released a controllable appliance: the WeMo Crock Pot 
slow cooker (see figure 4.12). This allows the user to control the temperature 
and cooking time of a Crock Pot remotely from a smartphone app. Slow 
cookers might not be for everyone, but the context of use is a perfect fit for 
connectivity and remote control. Their value proposition is convenience: the 
meal that cooks itself while you’re out all day. Remote control increases that 
convenience by allowing you to adjust the timing if you’re home late. And 
                                                             
6 At the time of writing the Arduino model is being phased out for a newer version 
based on the Spark Core development board.  

 
 
being able to keep an eye on the device alleviates any anxiety about leaving a 
hot thing unattended in an empty house. It may be a niche appliance, but it’s a 
well-formed product solution. 
 
Figure 4.12: WeMo Crock Pot and smartphone app. 
 
Mass-market consumers don’t necessarily lack the knowledge, skill or 
imagination to solve their own problems. They may be perfectly capable of 
doing so but simply lack the time or have other priorities. At best they might 
only have time to solve a few of them. 
There is a rich market for products that solve their problems for them!  
 
What makes a good product? 
Good products seem to appeal to common sense, and new good products are 
often greeted with the reaction ‘well why didn’t someone think of that 
before?’. But developing good products can be far harder than our 20/20 
hindsight might lead us to think. This section looks at the general qualities of a 
good consumer product before considering what features come with IoT. 
 
The product solves a real problem people have (and 
makes this clear) 
Most products are acquired in order to solve a problem for the user. A good 
definition of the problem, and the audience, are essential to creating a clear 
value proposition. This is the definition of what your product does for people, 
and why they might want it. 
 
A clearly communicated value proposition is fundamental to user experience. 
When people come across a product (or service), they try to form a quick 
judgment about its purpose, and whom it is for. If it’s not immediately clear 
what the value proposition is, it may be dismissed: either because it is too hard 
to figure out, or because it does not appear to do anything of value for that 
person at that time. Worse, potential users may wrongly assume it is able to 
fulfill a purpose for which it is not really suited and waste time and/or money 
on a fruitless endeavor.  (You may be happy to take their money in the short 

 
 
term, but over time too many unhappy customers will damage your 
reputation!).   
 
It’s all too easy to end up with a poor or unclear value proposition despite 
good intentions. This is often the result of failing to identify the right problem 
for the right audience. You might have added features to show off what the 
system can do, or because they are simple to build, dictated too much by the 
capabilities of the technology at the expense of the original purpose and user 
needs. Or maybe there are competing interests involved in feature scoping. It’s 
common for systems to try to do lots of things. That may create a great tool for 
early adopters who like to tinker and customise, but it risks muddying the 
value proposition for a mass-market audience. Imagine you’re making a wrist-
top device for outdoor pursuits like hiking or climbing. The core features are 
an altimeter, barometer, compass, and perhaps GPS. It might be quite 
straightforward softwarewise to add on a calendar, to do list and, maybe, 
games. You can probably imagine a situation in which someone, somewhere, 
might use those features. But you’ll be at risk of obscuring the key purpose of 
the device: helping users find their way and stay safe. Too much flippant 
functionality might even undermine the perception that the device offers good 
quality in its core functionality. And it will make it harder for users to access 
the key features they most want and need. 
 
If your device can fulfill multiple purposes for the user, you’ll have to invest 
extra effort in helping users understand its value. A home contact sensor is a 
generic piece of hardware with no inherent value to the user. The value is in 
the function it enables: used to detect when an intruder has forced a door open, 
or when a medicine cabinet has been opened. Early adopters may love the 
flexibility to use the sensor as a tool that can do all kinds of things. But you’ll 
have to help mass market users understand what it could be for. For example, 
your app might offer specific window or cupboard alarm functionality to go 
with the device, even if these do much the same thing under the hood. 
 
Connected products intended for the mass-market need to demonstrate a clear 
advantage over any predecessors. Connected things are not inherently better 
than non-connected things, just because they are connected. Despite being 
demo-ed at consumer electronics fairs year after year, the much-maligned 
internet fridge concept has so far felt like a solution in search of a problem. 
Research shows that people can imagine using intelligent fridges that provide 

 
 
information about their contents, nutrition and health, but this has not 
translated into demand.7 Tasks such as managing shopping lists and looking up 
recipes simply don’t feel as if they require a new, fridge-based screen. The 
idea of the fridge that automatically orders more shopping when goods run out 
is fraught with potential for irritating errors. If you have to make the fridge 
sync with your calendar or heating thermostat to see when you’re on holiday 
in order to stop your regular milk order, maybe it’s just simpler to buy your 
own milk after all. 
 
Connected sensors enable many kinds of data in the world to be captured, 
quantified and made visible. Fitness tracking and energy monitoring (see e.g. 
figure 4.13) are obvious consumer examples of this. But beware you’re not 
just counting things. Data should be used to provide genuine insights that users 
can act on. 
 
                                                             
7 Matthias Rothensee, User acceptance of the intelligent fridge: empirical results from a 
simulation, IOT'08 Proceedings of the 1st international conference on The internet of 
things, 123-139 

 
 
Fig. 4.13: The Efergy energy monitoring service helps users understand their 
electricity consumption. (Image: Efergy) 
 
For more information on designing with data, see chapter 13. 
 
Connectivity can enable remote control of devices. The core value of 
connected sockets and door locks is usually remote control (see figure 4.14).  
 
Fig 4.14 The August door lock, app and hub (plugged into outlet). 
 
Connected home systems that allow automated rules to be created are 
examples of products whose main value is in automation (see figure 4.16). 
Intelligent systems such as the Nest thermostat may promise to do the job 
(such as setting a heating schedule that best fits home occupancy) better than a 
human.  

 
 
 
Fig. 4.15: An automated ‘coming home’ smart rule in the AT&T Digital Life 
tablet app 
 
Tags or sensors embedded in objects allow them to be trackable and 
identifiable. The FedEx SenseAware service (figure 4.16) embeds a multi-
sensor device inside sensitive shipments (such as medical supplies), allowing 
the sender to track the location of a parcel and the temperature, light levels, 
humidity and atmospheric pressure to which it has been exposed. If any of 
these fall outside a set range, a replacement parcel can be dispatched.  

 
 
 
Fig 4.16: FedEx Senseaware sensor and web app 
 
It goes almost without saying that your system needs to be reliable enough to 
fulfill its promise. Glitches and outages are inevitable in most systems and 
early adopters will forgive these more readily. But if there are contexts of use 
in which you cannot afford failure, the product must be 100% reliable. For 
example, emergency alarms for elderly or vulnerable people must always 
work. You’ll need a backup power supply and connectivity (see figure 4.17), 
and regular checks to ensure these work.   

 
 
 
Fig 4.17 The hub of the Scout security system has a backup battery and 3G 
cellular chip so it won’t stop running during power and internet outages. 
 
The product comes at a cost (financial, or effort 
exerted) which seems in proportion to the perceived 
value 
A good product needs to balance the cost and effort required from the user 
against the value it delivers. If the value is very high, users may be prepared to 
pay more, or invest more time in configuration.  
 
Determining a price point is a tricky matter in itself. You'll have to consider 
manufacturing costs, competition and market conditions, and what users are 
prepared to pay. 
 

 
 
You’ll also need to consider the cost to the user of switching from whatever 
they were using previously. Household technology, like heating and alarm 
systems, tends to last years and users won’t want to replace working boilers, 
sensors or other kit at great expense without a significant benefit8. If you can 
support retrofit – new technology that can easily be integrated into old systems 
– without greatly increasing the cost of your product, you’ll increase the 
potential market for the product. 
 
In the context of UX, the perceived cognitive effort to use your product and 
the time it will take to get it set up and working affect who will buy it, and 
why. Be careful in your judgment here. In the thick of a project when you are 
excited about your idea, it’s easy to overestimate how motivated users are to 
invest time in your product.  
 
Smart homes are a typical example here. It’s been possible to connect up 
lighting, heating, appliances and entertainment systems for around 40 years, as 
we saw earlier. But you needed to be an enthusiast to set it up and program it 
(or wealthy enough to pay someone else to do that). A niche of users has taken 
great pride in their automated homes, but others have found them fraught with 
support issues, technology failures, and a poor fit with the needs of other 
guests and residents. Mass-market users often view home automation with 
suspicion: home is a very personal context, and one in which we are often 
loath to introduce novel technologies that might break our established routines. 
Most of us don’t want to have to do a load of programming just so we can turn 
lights on and off. We manage that well enough already and it’s an effort to 
switch unless the benefits are really evident.  
 
Adding extra cognitive effort to everyday tasks is a common risk. The UX 
strategist Scott Jenson proposes the idea of the ‘surprise package’: the mature 
consumer product that is ‘enhanced’ technologically, turning it back into an 
early adopter product. As Jenson puts it: “Companies take product concepts 
                                                             
8 C.F. the model of shearing layers, which describes buildings as a set of components 
that evolve and obsolesce over different timescales. ‘Services’, like HVAC and 
plumbing, are expected to last 7-15 years. This concept originates from architect Frank 
Duffy and was developed by Stewart Brand in his book ‘How Buildings Learn: What 
Happens After They’re Built’(1994, Viking Press). 
 

 
 
that are now far into the laggard range of stability and established behavior, 
and they change the product significantly. … The new product is effectively 
repositioned ‘back to the front’ of the curve, creating a high-tech product that 
can only be used or appreciated by the forgiving and accomplished early-
adopter group of consumers. This is where much of the consumer backlash 
appears, as safely mature and benign products such as TVs, radios, 
thermostats, home phones and even cars are turned back into early adopter 
products, and then sold to an unsuspecting laggard audience.” 9 
 
TV is a great example. TV used to be an instant-on experience. We may have 
had less choice of channels and no on-demand services, but you could be 
watching something within a second or two of turning it on. It can now take 
minutes. You may be faced with software updates for your set-top box and/or 
connected TV (perhaps for apps you don’t even want but can’t delete), then 
minutes of navigating around a program guide or on-demand service using a 
cheap remote control poorly equipped for the job.  
 
If your product is replacing an existing consumer product or way of getting 
something done, pay attention to what was good about the old way of doing 
things. Try to preserve that and enhance the experience, rather than adding 
new complexity. 
 
The product is pleasing to use 
The hard-headed cost/benefit analysis is important for any product, but the 
best products speak to us on an emotional level too. This is partly about 
aesthetics, but it’s not just about bolting pretty design on top of functionality. 
We form an integrated impression of the functionality and design of the 
product, and how well that fulfills our practical and emotional needs and fits 
(and perhaps communicates) our sense of who we are10. Figuring out the right 
                                                             
9Scott Jenson, 2002, ‘The Simplicity Shift’ (Cambridge University Press). Available 
from  http://www.jensondesign.com/The-Simplicity-Shift.pdf 
10 Lionel Tiger’s ‘The Pursuit of Pleasure’ is an interesting viewpoint on the 
anthropology of what makes products appeal. (Lionel Tiger, 1992, ‘The Pursuit of 
Pleasure’. Boston: Little, Brown 1992). 
 

 
 
experience is about design as well as product strategy, which is covered in 
more depth in chapter 5, ‘Translating Research into Product Definitions’.  
 
Services in IoT 
Devices and services 
At the start of the chapter, we set out that an IoT ‘product’ is frequently a 
hybrid of physical device(s) and service provision. At the very least, the 
connections that keep the connected device connected are services and there 
may be others to consider in making a product good.   
 
When people buy a product, they expect to have the right to use it for as long 
as they like. When the product is dependent on an internet service, there is a 
reasonable expectation that that service will continue to be available, for 
taking it away would render the product at worst useless and at best limited. 
After all, you would not expect your home heating or lighting to cease to 
function because the company that produced the original system had gone out 
of business, or no longer wished to support you. (There is an inherent tension 
here between the old world of physical products, and the new world of 
internet/web services. On the web, new services appear and old ones are 
‘sunsetted’ on a regular basis. This is acclaimed as progress. A physical 
product is likely to come with expectations that it will last for at least a few 
years. If the service stops working, the lifespan of the device is shortened, 
creating landfill (and unhappy users). Service providers have a responsibility 
to ensure that they are able to  maintain and improve their internet services, so 
that the product has a reasonable lifespan.) 
 
 
The service forms part of that experience.  The relationship between the device 
and service can vary. <-EXPLAIN MORE 
 
Connected heating controllers and door locks are examples of systems where 
the device is likely to be the focus: we might call them service-enabled 
devices. Users view the device as the most salient part of the system. For 
example, Nest users are likely to say ‘I have a Nest’, referring to the 

 
 
thermostat to represent the entire system. (It’s far less likely you’d hear 
someone saying ‘I use Nest’, ‘I have Nest or ‘I have a Nest system’.) Because 
the device is so central to the UX, users will have high expectations of its 
design and functionality. The service enables remote access and smarter 
functioning, but in the user’s mind it is a way to control the device (Seefigure 
4-18).  
 
4-18 – example of produdct advert with device front and centre, e.g. Nest? 
 
A security alarm is an example of a system where the service is the focus: we 
might call it a device-enabled service. The alarm service is what users care 
about. The sensors and other devices are generally low profile and most of the 
intelligence sits in the internet service or gateway software. You could add or 
swap out devices without affecting the core functions of the service.  
 
Key factors that indicate that the service may be the focus of your user 
experience, not the device itself, may be that: 
O 
Interactions are distributed across multiple devices, so no single device is 
the center of attention 
O 
Most functionality lives in the cloud service or gateway software (perhaps 
because local devices don’t have much computing power); and/or 
O 
Devices can be added, removed or swapped without changing the core 
functioning of the system;  
As the UX expert Mike Kuniavsky describes it, the device is an avatar for the 
service.11 
The Oyster travel card (see figure 4.19 below) is a stored value contactless 
smart card used on London public transport. It can hold various types of 
tickets or a credit balance for travel on the underground, trains, buses, trams 
and boat services. (‘Stored value’ means that the credit is notionally held on 
the card itself, rather than in a separate account, as with a debit card.)  
 
Passengers add tickets or money to the card itself via online purchase, ticket 
machines at stations or by setting up regular debits from their bank accounts. 
                                                             
11 Mike Kuniavsky, ‘Smart Things: Ubiquitous Computing User Experience Design’, 
Morgan Kaufmann 2010 

 
 
They swipe the card on a reader at the start and end of journeys to validate 
their tickets or deduct credit.  The Oyster saves time and money processing 
ticket office transactions and reduces the number of paper tickets. To 
encourage use, fares are substantially cheaper than paper tickets.  
 
Figure 4.19: the London Oyster card 
 
The Oyster card itself is not much of a smart object. It’s just a piece of plastic 
containing an RFID chip and a small amount of memory. The RFID chip 
passes a unique ID to a reader when a passenger swipes in. The memory holds 
information about the tickets or money stored on it, so the reader does not 
need to contact the back office service in real time every time the user swipes 
the card. This speeds up the rate at which passengers can pass through ticket 
barriers, which is vital during rush hour. Readers transmit transactions to the 
back office in batches. 
 
The Oyster card is an icon of London life, but it is really just an avatar for the 
service. Without the card readers or the ability to top it up it wouldn’t be much 
use to you. The Oyster service involves smooth coordination between many 
different channels, such as the Transport for London website, the ticket 
machines, ticket offices and shops that sell top ups, the readers themselves, 
and the back office systems (see ‘Service ecosystems’, below). 
 
Technically, the Oyster card itself is not even an essential part of the service: 
Oyster can also be used via NFC enabled phones and bankcards. In future, the 
dedicated Oyster card might even disappear, but the service will remain. But 
services are intangible, and avatars can provide a concrete, tangible focus that 
helps us understand the service.  
 
Right now, IoT systems are still pretty novel and not well understood, at least 
by consumers. It’s easy to look to individual devices as a handle to understand 
the system, whether or not this is accurate. (We’ve heard smart meter users 
refer to the in-home counter-top display as the ‘smart meter’, and the actual 
smart meter as the ‘computer under the stairs’: see figure 4.20). You might 
need to play up the role of the devices in communicating what your system 
does (presenting it as a service-enabled device), just to help consumers 
understand it. 
 

 
 
Figure 4-20: In-home display 
 
Over time, as we all become more accustomed to the products around us 
having intelligence and connectivity, our ability to understand connected 
products as services without depending on physical manifestations may 
become more sophisticated. The idea of a heating system without a visible 
controller, or a door lock without a visible lock may seem strange right now, 
but in time, as long as they work, we might be more open to such things.  
 
It will probably always be appropriate for some systems to have highly visible 
devices, and for some to focus more on service design (see figure 4.21). The 
key is to pitch your UX to best suit your product, and the needs of your users.  
 
If your service is the focus of the UX, you can still make beautiful devices but 
make sure the service design is at least as good. And if the device is the hero 
of your UX, make sure it’s attractive, usable and does what it needs to do, 
elegantly. 
 
4-21: Diagram or table: service enabled device vs device enabled service. 
Service ecosystems 
Services are delivered through the interactions of networks of people, 
organizations, infrastructure and physical components. The devices, and even 
the digital components, are only part of the experience. A part of the Oyster 
experience is the interactions you may have with station staff when buying a 
ticket or asking for help. In order to help you they will have been trained to 
provide good customer service, but they will also need access to good 
information about the transactions on your card and system information. 
Making this whole system work smoothly is a lot more complicated than just 
making cards, machines and a website: it requires someone to take a holistic 
view of how the service is experienced, and make sure all the components 
work reasonably smoothly together (see figure 4-22). 
 
Figure 4.22: the London Oyster ecosystem 
 
Complex IoT services, such as a connected home, require the co-ordination of 
multiple devices working together, perhaps even using a degree of intelligence 
to automate some functions without explicit user instructions (for example, 

 
 
turning off the electricity supply if a gas leak is detected). There may be 
multiple digital interfaces. There may even be co-ordination between multiple 
digital and physical services, for example, a heating system may use data from 
a 3rd party weather service, and the user might have the option of taking out a 
service and repair contract. 
 
This is called an ecosystem. 
 
If you’re designing a service, you’ll need to take a more complete view of all 
the parts of your service, and the relationships between them.  For example, 
you may need to think about handling software and component upgrades 
across your devices. Ovens may require new controller boards, and washing 
machines may demand firmware upgrades (see figure 4.23). You’ll need to 
design processes for handling these issues with consumers. 
 
Figure 4.23: The Samsung WW9000 connected washing machine supports 
over the air firmware updates. (Image: Samsung). 
 
There may well be customer support, marketing, sales, and perhaps 
professional installation and maintenance too. 
 
"You see companies that have poached Apple designers, and they come up 
with sexy interfaces or something interesting, but it doesn't necessarily move 
the needle for their business or their product. That's because all the designer 
did was work on an interface piece, but to have a really well-designed 
product in the way Steve would say, this 'holistic' thing, is everything. It's not 
just the interface piece. It's designing the right business model into it. 
Designing the right marketing and the copy, and the way to distribute it. All of 

 
 
those pieces are critical." Mark Kawano, founder of Storehouse and former 
Apple User Experience Evangelist12] 
 
Building a service offering 
Thinking at the service experience level encourages us to take a broader look 
at user needs, not just the interactions with the website, mobile app or 
embedded devices. Chapter 5 explores understanding user needs in more 
detail. In this chapter we’ll consider how this might create new opportunities 
to look at the wider service package you may offer customers. 
For example, take home security. We typically think of alarm systems as 
something that makes a loud noise and act as a visible deterrent on the home. 
A connected system can tell you when someone is breaking in, and perhaps 
film them. But if you’re not able to get home, and no-one else can respond, 
you can’t do anything about it. Connectivity has alerted you to the problem but 
also enabled you to feel powerless to act. 
 
In this case, you might have the option of paying for a professional monitoring 
service. The security firm (with your permission) can view your cameras 
before sending someone out.  
 
IoT services often provide opportunities to capture data, which can be used to 
improve the service offered, perhaps through better customer service or 
smarter support. For example, diagnostic data about the functioning of a boiler 
could be used to identify systems at risk of breakdown and schedule an 
engineer visit before they fail. You might even package the cost of the service 
contract with the monthly fee for maintaining the service. Users may be 
happier to pay for something like this than to cover the cost of maintaining 
your internet servers! 
 
Professional installation or configuration may also be an opportunity for 
complex systems such as home automation technology. Time It Right13, 
                                                             
12 Mark Wilson, 4 Myths about Apple Design, From an Ex-Apple Designer, Fast 
Company July/August 2014 (http://www.fastcodesign.com/3030923/4-myths-about-
apple-design-from-an-ex-apple-designer) 
13 http://autotimeonline.com/ 

 
 
designed for the needs of the Orthodox Jewish community, is a culturally 
specific example (see figure 4.24) There may in future even be a role for 
independent IoT ‘plumbers’ who specialize in helping consumers install, 
maintain and repair connected home systems: a kind of role the technology 
blogger Anil Dash refers to as ‘blue collar coders’14.   
 
 
Figure 4.24: Time It Right comes with a professional installation and 
configuration service (Image: Autotime). 
 
Another service opportunity may involve helping users secure lower prices or 
better service from 3rd parties, or otherwise benefit from the data that comes 
from your system.  In the sustainable housing development of Little Kelham in 
Sheffield, northern England residents have smart meters to track energy use 
and band together to bulk buy electricity (see the connected home case study 
between chapters 4 and 5). 
 
Personal services, such as installation or intensive customer support, are not 
necessary for all services and may not be practical within your business model. 
But it’s worth considering the bigger context of user’s expectations around the 
service you’re offering, and how their needs will change over time, to make 
                                                             
14 http://dashes.com/anil/2012/10/the-blue-collar-coder.html 

 
 
sure your service isn’t missing something they think they need, or to spot 
opportunities to improve the overall experience. 
 
Business models 
Establishing the relationship between your system and the surrounding service 
is, in part, deciding on your business model. Put crudely, this can be 
summarized in two questions: what will people pay for? And what do you 
need for production to be sustainable? 
What is a business model? 
A business model is the blueprint for how a business creates value for 
customers, and makes money. For example, a classic business model is the 
‘bait and hook’ one used by printer manufacturers. They charge a relatively 
low price for the initial hardware but make money on toner cartridges.  
 
The model maps out how the business will make money, either from 
increasing revenue (selling more) or decreasing costs. Increasing revenue can 
be approached by:  
O 
Generating new business from new customers 
O 
Generating more business from existing customers  
And even a not-for-profit organization needs a sustainable business model in 
order to survive. 
 
How do business models affect UX? 
Business models shape the way users perceive the value of the service and the 
fairness of pricing. This can make the product proposition more or less 
appealing. Users will approach the product or service with a positive, trusting 
mindset, or a more skeptical or even negative one. This sets the tone for the 
rest of their interaction.   
 
For example, the major energy companies in the UK have recently come under 
pressure for perceived unfair pricing practices. All are rolling out smart energy 
meters, which generate data that can be used to offer customers tips on saving 
energy and therefore money. But customers who feel that prices have not been 

 
 
set fairly treat this money saving advice with skepticism. This has a knock-on 
effect on the perceived UX of the energy saving service. Issues of trust need to 
be tackled upfront in the design, perhaps through presenting pricing in more 
transparent ways. 
 
Device and service models 
In the traditional product business model, the provider charges once, upfront, 
for hardware. This is how we are used to buying, for example, cars, or 
household appliances. For a long time, this was also how we bought software. 
 
In service models (of which many digital models are examples), the provider 
charges for ongoing service provision. Music subscription services such as 
Spotify or storage like Dropbox are examples of service business models. A 
non-connected product can be supplied as a service; for example, renting a car 
through a traditional rental company is a service. The customer pays for use of 
a car, not for ownership of a particular car. Adding connectivity to objects 
increases the potential for service models.  
 
The choice of business model is a balancing act between where the customer 
perceives the value to be and what they expect to pay for, and what it costs 
you to provide. IoT is new, which means that what the customer expects to pay 
for is not always a reflection of the costs you may incur! 
 
For example, your connected heating controller requires an internet service to 
provide you with remote control via your smartphone app. That costs money 
to maintain, especially when you consider that the lifespan of a heating 
controller might be 10 years or more. The provider might factor that cost into 
the price they charge you for the product upfront, but that might make it more 
expensive compared to competitor products. Or they might choose to charge 
you a regular fee for ongoing service provision. But they might find that 
customers aren’t used to paying an ongoing fee to keep their heating working! 
In that case, the company might try to add value to this service, by turning it 
into a platform that also supports other devices (like connected lighting or 
energy monitoring), or adding extra service components, like a maintenance 
contract. 
 

 
 
As discussed above, the perceived value may rest in different places for 
different types of connected device/IoT system. Is it the overall service users 
think is most valuable, or one or more of the devices that deliver it?  
 
IoT is immature and there’s perhaps a tendency for users to focus more on 
devices, as these are novel (as we suggested earlier). Service providers may 
focus on more on services, as that’s where the potential for long-term 
customer engagement sits. You may think that you are offering a health 
management service, but if your users see beautiful bathroom scales then 
persuading them to pay for an ongoing service may be tough. The key for a 
business model is that customers feel they are paying a fair price (whether in 
terms of money or sharing their data) for the value they receive, and you are 
making the money you need.  
 
Bringing digital business models to physical 
products 
Building digital services around physical products enables suppliers to apply 
novel business models, more commonly found in the digital realm, to physical 
products.   
 
Combining physical devices and services is likely to lead to some interesting, 
novel and disruptive business models that challenge our preconceived ideas of 
what it is to own and use a product.  
 
Business models we are accustomed to in the digital realm might make their 
way into the physical world. For example, we are accustomed to using 
websites that are free at point of use but make money from selling eyeballs to 
advertisers. It’s not a huge stretch to imagine that physical devices might be 
given away in exchange for advertising or user data. The ubiquitous 
computing researcher Pertti Huuskonen jokes about the freemium fridge. Your 
supermarket gives you a free fridge with a screen that forces you to watch an 
advert every time you open it. Or the fridge might track the products you put 
in it and eat, and where you bought them, and share that data with the 
supermarket, and other advertisers. Users could buy their own fridges, 
essentially paying for ad free experiences or privacy, or get free or cheaper 

 
 
appliances in exchange for their eyeballs and data. In future, privacy may be a 
rich person’s luxury15. 
 
More positively, there are benefits to digital service business models. There 
are opportunities to develop ongoing relationships with customers, understand 
more about the people who buy your products and what they do with them, 
and tailor services better to their needs. Users are accustomed to (and mostly 
comfortable with) web-based services that capture and store information about 
them to provide a better service. The sensing and processing capabilities of 
IoT devices open up potential to extend these personalized services to the 
physical world.  
 
You may be able to capture user behavior that wasn’t previously visible, 
perhaps in real time: e.g. how people are using energy via smart metering, 
identifying and tracking people in a physical space, or monitoring traffic levels 
via aggregated data about the density and speed of movement of drivers’ 
smartphones. Knowing how often or intensively a product is used, and what 
for, enables you to tailor the service, sell supplies, improve the next version, or 
offer additional services. For example, some Nespresso coffee machines now 
come with a SIM card, allowing Nespresso automatically to send more 
capsules when the customer is running low (see figure 4.25 below).  
 
                                                             
15 Pertti Huuskonen, personal communication and 2007, ‘Run to the Hills! Ubiquitous 
Computing Meltdown”, Proceedings of the 2007 conference on Advances in Ambient 
Intelligence, Pages 157-172 (available at 
http://www.cs.swan.ac.uk/~csmax/csrsRG.pdf) 
 

 
 
 
Figure 4.25: The Nespresso Zenius coffee machine comes with a SIM card. 
(Image: Nestle Nespresso) 

 
 
 
You could charge users based on their behavior. For example, car insurance 
policies such as Insure the Box in the UK, base pricing on actual driver 
behavior rather than demographics. This may benefit responsible drivers who 
are in a demographic category considered to be at high risk of accidents, such 
as under 25s. 
 
Products can proactively maintain themselves or provide data to enable 
smarter support: as discussed earlier, boilers could identify when they are 
developing a fault and be serviced before they break down; appliances could 
share fault data with the manufacturer so customer support can help users 
diagnose and fix more of their own problems. It is possible to vary pricing 
based on time of use, for example charging more for electricity at certain times 
of day to manage demand. 
 
A good UX design needs to balance the needs of the business with the needs 
of the user. Even if you are not shaping the business model of the product you 
are working on, you at least need to understand it. The best business models 
serve the interests of customers as well as the business. The car insurance 
example above provides cheaper insurance to drivers who would otherwise be 
penalized on grounds of age, but also allows the company to reduce costs and 
uncertainty through more accurate risk profiling. User and business needs can 
be in tension: for example, a connected home service might rely on heavy 
upselling of new products. Here, design can make the difference between the 
upsell advertising being either useful or at least minimally intrusive, or 
downright irritating or something that causes users to stop using the system 
altogether. 
 
Summary  
A clear value proposition ensures users understand what your product does, 
and whether they want it. This is essential in order for them to understand how 
it works, and how to use it.  
Innovators and early adopters are inherently interested in technology and 
forgiving of imperfections. Mass-market consumers often have different 
needs. 

 
 
Many IoT systems are tools: they require the user to frame their own problem 
and configure the system to solve it. Consumers tend to look for products that 
promise to solve a particular problem for user and come already configured to 
do that.  They expect the cost and effort of using the product to be in 
proportion to the value it brings them. 
IoT creates new opportunities for information gathering, sharing, remote 
control and automation. But there are common pitfalls that can limit a product 
to early adopter markets. In particular, be careful of introducing new 
complexity to mature consumer products. 
 
The UX of an IoT product might be focused around the device or the service. 
All IoT systems depend on some kind of digital service, and perhaps offline 
service components too, like professional installation, maintenance or 
customer support helplines. Ensuring these work well together is an important 
part of the overall UX.  
 
Business models shape the way users perceive the value of the service and thus 
the UX. Bringing connectivity and intelligence into devices may lead to digital 
business models appearing in the physical world. 
 
 

 
 
9 
Cross-device interactions  
and interusability 
 
Claire Rowland 
Introduction 
In systems where functionality and interactions are distributed across more 
than one device, it’s not enough to design individual UIs in isolation. 
Designers need to create a coherent UX across all the devices with which the 
user interacts. That means thinking about how UIs work together to create a 
coherent understanding of the overall system, and how the user may move 
between using different devices. 
This chapter explores interusability - the user experience of interconnected 
devices and cross-platform interactions – and how to make a bunch of diverse 
devices feel like they are working in concert.   
This chapter introduces: 
 
Sentence about cross-platform UX and usability (see page 2) 
 
What is interusability? (see page 4) 
 
The role of conceptual models in understanding what a system does, and 
why these are especially complex in IoT (see page 5) 
 
Composition: distributing functionality between devices (see page 14) 
 
Consistency across multiple UIs (see page 24) 
 
Continuity of data and interactions across devices (see page 30) 
 
Applying interusability thinking to broader contexts (see page 42) 

 
 
This chapter addresses the following issues:  
 
What makes a cross-device system feel coherent (see page 4) 
 
Why it’s complicated to understand how an IoT system works, and how 
we might help users with this (see page 7) 
 
Deciding on the best way to distribute functionality between different 
devices in the system (see page 14).  
 
Determining which UI elements and interactions need to be consistent 
across devices, and which don’t (see page 25).  
 
Dealing with data and content synchronization issues in the UI (see page 
31).  
 
Designing interactions that require switching between devices (see page 
39).  
 
Cross-platform UX and usability 
Many of the tools of UX design and HCI originate from a time when an 
interaction was usually a single user using a single device. This was almost 
always a desktop computer, which they’d be using to complete a work-like 
task, giving it more or less their full attention.  
The reality of our digital lives moved on from this long ago. Many of us own 
multiple internet-capable devices such as smartphones, tablets and connected 
TVs, used for leisure as well as work. They have different form factors, may 
be used in different contexts and some of them come with specific sensing 
capabilities, such as mobile location. 
Cross-platform UX is an area of huge interest to the practitioner community. 
But academic researchers have given little attention to defining the properties 
of good cross-platform UX. This has left a gap between practice and theory 
that needs addressing.  
In industry practice cross-platform UX has often proceeded device by device. 
Designers begin with a key reference device and subsequent interfaces are 
treated as adaptations. In the early days of smartphones this reference device 
was often the desktop. In recent years the ‘mobile first’ approach has 

 
 
encouraged us to start with mobile web or apps as a way to focus on 
optimizing key functionality and minimize ‘featuritis’.  Such services usually 
have overarching design guidelines spanning all platforms to ensure a degree 
of consistency. The aim is usually on making the different interfaces feel like a 
family, rather than on how devices work together as a system.  
This works when each device is delivering broadly the same functionality. 
Evernote, eBay and Dropbox (see figure 9.1) are typical examples: each offers 
more or less the same features via a responsive website and smartphone apps. 
The design is optimized for each device, but provides the same basic service 
functionality (bar a few admin functions that may only be available on the 
desktop). 
Figure 9.1: Evernote offers broadly the same service functionality across 
different device types  
But this approach breaks down when the system involves very diverse devices 
with different capabilities working in concert. In IoT, many devices do not 
even have screens, or an on-device user interface. Multiple devices may have 
UIs with very different forms or specialized functionality (see figure 9.2). 
Even if the UI is only on one device, the service still depends on all the 
devices working together in concert. 
Figure 9.2: The Smart Things ecosystem contains a range of specialized 
devices that complement each other. 
It’s not possible to design a system like this by thinking about one device at a 
time: this is likely to create a disjointed experience. 
In order to use it effectively, the user has to form a coherent mental image of 
the overall system. This includes its various parts, what each does and how 
different objectives can be achieved using the system as a whole. Traditional 
single-device usability doesn’t tell us very much about how to do this.  
 
 

 
 
What is interusability? 
Charles Denis and Laurent Karsenty first coined the term ‘inter-usability’ in 
2004 to describe UX across multiple devices1. Conventional usability theory is 
under-equipped to cope with cross-platform design. However, one 2010 paper 
by Minna Wäljas, Katarina Segerståhl, Kaisa Väänänen-Vainio-Mattila and 
Harri Oinas-Kukkonen proposes a practical model of interusability2.  
Wäljas et al propose that the ultimate goal of cross-platform design is that the 
experience should feel coherent. Does the service feel like the devices are 
working in concert, or does the UX feel fragmented? 
They define three key concepts for cross-platform service UX, which together 
ensure a coherent experience: 
P 
Composition: how devices and functionality are organized 
P 
Appropriate consistency of interfaces across different devices 
P 
Continuity of content and data to ensure smooth transitions between 
platforms 
The paper was published in 2010 and the services evaluated (including Nike+ 
and Nokia Sportstracker) now inevitably feel a little dated. But we have found 
the model still holds up well in our own work designing IoT services, and it’s 
a key reference for the rest of this chapter.   
                                                             
1 Denis, C. and Karsenty, L. (2005) Inter-Usability of Multi-Device Systems – A 
Conceptual Framework, in Multiple User Interfaces: Cross-Platform Applications and 
Context-Aware Interfaces (eds A. Seffah and H. Javahery), John Wiley & Sons, Ltd, 
Chichester, UK 
 
2 Wäljas, M., Segerståhl, K., Väänänen-Vainio-Mattila, K., Oinas-Kukkonen, H.: 
Cross-platform service user experience: a field study and an initial framework. In: 
Proceedings of the 12th International Conference on Human Computer Interaction with 
Mobile Devices and Services, MobileHCI 2010, p. 219. ACM, New York (2010). I’ll 
refer to this paper several times in the rest of this chapter as Wäljas et al, although I 
understand that Katarina Segerståhl was the primary researcher. Her PhD, available at 
http://herkules.oulu.fi/isbn9789514297274/isbn9789514297274.pdf, builds on the same 
concepts. 
 

 
 
Conceptual models and composition 
In this section, we’ll look at two related concepts that help us design systems 
spanning multiple devices. 
Conceptual models refer to the way humans understand the overall system 
(and its interfaces) to work. Users need some understanding of how the system 
works in order to figure out how to interact with it. As we saw above, 
composition is a dimension of interusability. It refers to the way user-facing 
functionality is distributed between different devices: which device does what. 
The two concepts are related in cross-platform design: understanding which 
device does what is part of forming an effective conceptual model. 
Conceptual models 
The user model and the design model 
The conceptual model may refer to the way the user understands the system, or 
the way the designers (or engineers) think about the system. Users develop a 
mental model of the system (a user model) that enables them to understand 
what it does, how to interact with it, and how it will behave. At first, this will 
be based on prior experience of other systems or similar activities. Over time 
they will develop the model through their experiences with the system itself. 
The way the designers or engineers think about the system will be reflected in 
the design model (this distinction was defined in Don Norman, 1988)3. 
As Norman puts it: ‘The problem is to design the system so that, first, it 
follows a consistent, coherent conceptualization - a design model – and 
second, so that the user can develop a mental model of the system – a user 
model – consistent with the design model.’  
The similarity between the design model and the user’s mental model is a core 
determinant of usability in any system, not just IoT. How easy is it for the user 
to figure out how to achieve a particular goal using the system (which Norman 
                                                             
3  Norman, Donald (1988). The Design of Everyday Things. New York: Basic Books. 
 

 
 
refers to as bridging ‘the gulf of execution’4)? How easy is it for the user to 
understand what the system does in response (‘the gulf of evaluation’)?  (See 
figure 9.3). 
 
Figure 9.3: The gulfs of evaluation and execution. (User icon by Simon Child, 
computer icon by Alyssa Mahlberg, both from the Noun Project) 
Ideally, the user model maps closely onto the design model. But frequently, 
the design model may not be a good fit for what the user wants to do, or users 
may only partially understand it. If the system doesn’t conform to any prior 
expectations, users must develop a new mental model, based on trying to infer 
the design model. Users learn about the design model through the interface, 
behaviors of the system and documentation – which Norman refers to as the 
system image (see figure 9.4). 
Figure 9.4: Diagram: the user, system and design model (redrawn from 
http://www.jnd.org/dn.mss/design_as_communication.html) 
                                                             
4 Chapter 3 ‘Cognitive Engineering’ in ‘User Centered System Design: New 
Perspectives on Human-Computer Interaction’, ed. Norman and Draper, Lawrence 
Erlbaum Associates, 1986 

 
 
You can’t design the user’s mental model directly. But you can design the 
system image to convey the design model clearly (see figure 9.5). You should 
also define your design model explicitly; to make sure it’s clear, consistent and 
not overly technical or complex for your audience. 
 
Figure 9.5: A system image: The Sunsprite Tracklight helps users monitor 
their daylight exposure. The instructions explain what it does, how to interact 
and data is displayed using the LEDs5. (Image from 1 
https://www.sunsprite.com/tracklight/). 
Multi-device services are conceptually more complex 
Back when Norman first wrote about conceptual models, a system was 
generally a software application running on a standalone computer. Multi-
device services make conceptual models more complicated. There are not just 
more interfaces, but more places where processing and functionality can live 
and where data can be stored. Because there are more nodes and connections, 
there are more points of failure and ways to fail. This is often where 
complexity is exposed: when the system is working well, it may not matter 
where your data or preferences are stored. But when parts or connections fail, 
the user has to understand something about how the system works in order to 
understand what is happening and why. 
                                                             
 

 
 
Take the example of a lighting system. The mental model of a lamp is simple: 
it has power, a switch, a fitting and a bulb (see figure 9.6). If the lamp doesn’t 
work it’s probably because the power has failed or the bulb has blown.  
 
Figure 9.6: A conventional lamp has a simple conceptual model  
A connected lighting system has bulbs, switches, fittings and power too 
(typically either the bulbs or switches will be connected). It also has an 
internet service, probably hosted remotely. It has a smartphone app and 
perhaps a web app too. It probably also has a gateway device. It has more parts 
(see figure 9.7) and more different kinds of part. It can also do more. It may 
run automated rules to turn lights on and off at certain times, or when certain 
trigger events happen (such as the security alarm being activated). The 
intelligence that controls the system may live in several places: in the bulb or 
switch itself, in the gateway, in the internet service, or even in the smartphone 
app. 
 

 
 
Figure 9.7: connected lighting can do more than conventional lighting, but the 
conceptual model is more complex. (Lightbulb by Marek Polakovic, wireless 
icon by Spencer Harrison. plug by Vithin Viswanathan, light switch by Sarah 
Hutchinson, all from the Noun Project.) MAY NEED WIFI GATEWAY 
ADDING 
When everything is working well and connected, users don’t need to concern 
themselves with which code is running where. But if a part of the system 
develops a fault or loses connectivity or the network is slow, the impact will 
depend on what that device is doing. Will the lights (or intruder alarm, or 
heating) stop working if the user’s phone battery runs out or they have no 
signal? Or will they keep running even if the user cannot remotely access the 
home at that point? What if the home internet connection goes down? Will 
lighting rules continue to work locally? If they are stored in the gateway or 
edge device, they will. If they are stored in the internet service or smartphone, 
they will not (see figure 9.8). 
 
 

 
 
Figure 9.8: Home automation routines stored in the cloud will not run if the 
internet connection goes down. If they are stored locally, they will continue to 
run (although the user won’t be able to see this or control devices remotely). 
(Clock icon by Christoph Robausch from the Noun Project) BOTH NEED 
WIFI GATEWAY ADDING 
How you choose to distribute system intelligence is a system architecture 
issue, as discussed in chapter 3. What’s most appropriate for your system will 
depend on what it does and your users’ expectations. An intruder alarm should 
not fail completely because the internet went down. But it’s not a disaster if 
your energy monitoring system is occasionally unavailable for short periods of 
time, as long as data is not lost. 
The new challenge for UX is that this is a lot of complexity that users didn’t 
previously have to worry about (see the discussion of the ‘surprise package’ in 
chapter 4). There are two ways to deal with this complexity: you can explain 
it, or try to hide it.  
Although BERG are now defunct, the BERG Cloud bridge, the gateway for 
Little Printer, was a simple example of a device that explained how the system 
was working.. It had LEDs to show whether the device had power and an 
Ethernet connection, and upstream and downstream connectivity (see figure 
9.9). It was labeled to explain that upstream meant that the bridge could see 
the BERG cloud internet service, and downstream meant that the ZigBee 
network used to connect to local devices was running. The gateway was 
communicating the system image.  

 
 
Figure 9.9: the BERG Cloud Bridge.(Image: BERG). 
The more complex the system, the more overwhelming it may be to explain in 
detail. In that case, it would be better to allow the user to work from a 
simplified mental model. Automatic gearboxes are complex mechanical 
systems that require only a simplified mental model in order to use (see figure 
9.10). But this is a hard trick to pull off. The gearbox is mature technology and 
only performs one basic function. Also, consumers have lots of prior 
experience of driving cars on which to draw. IoT technology is newer, and 
often does things that are less familiar to users. Many IoT systems also have 
multiple functions, so it can be harder to reduce them to a simplified 
conceptual model.  

 
 
 
Figure 9.10: automatic gearbox controls hide the complexity of the system 
behind a simplified conceptual model 
One example of a product with a simplified conceptual model is Apple 
iBeacons (introduced in chapters 2 and 4). Imagine a user walks into a store 
for which they have a an app installed, their location is detected using 
iBeacons, and they are sent a push notification about a special offer. It’s good 
enough for that user to understand that the store knows they are there, thanks 
to the beacons, and the store has sent them a message.  

 
 
Apple’s own description of iBeacons is "a new class of low-powered, low-cost 
transmitters that can notify nearby iOS devices of their presence6". This can be 
read as implying that the beacons notify the iOS device of its location. This is 
a good enough model but it skims over some complexity. 
 
What actually happens is: the beacon broadcasts a unique ID. The iOS device 
detects the ID,  and looks up its location in an online database. It notes its own 
position by its proximity to the beacon. In looking up the beacon, it informs 
Apple of its location, and Apple then send the push notification.  
9-11: iBeacons diagram: what the user needs to know, and what’s actually 
happening 
UX researchers at Ericsson have suggested that it is particularly difficult for 
users to understand networks of devices. Their informal research indicated that 
users currently think of connections between devices as being ‘invisible 
wires’. As Ann Light, co-author of chapter 15, puts it: “Most people are 
disposed to think of things, not links; of nodes rather than relations”7. But this 
way of understanding is not helpful in making sense of complex networks with 
many interconnections and interdependencies8. To understand a system, 
users must understand the links as well as the nodes. 
In 1983, the HCI specialist Larry Tesler (then at Apple) proposed the Law of 
Conservation of Complexity. Interviewed in Dan Saffer’s book ‘Designing 
Interactions’, Tesler says: “I postulated that every application must have an 
inherent amount of irreducible complexity. The only question is who will have 
to deal with it9.” His point was that shielding users from complexity would 
involve extra work from designers and developers. 
                                                             
6 https://developer.apple.com/ios7/, which now redirects to iOS8, original text retrieved 
via http://en.wikipedia.org/wiki/IBeacon#cite_note-5 
7 In conversation. 
8Joakim Formo, The Internet of Things for Mere Mortals, 
http://www.ericsson.com/uxblog/2012/04/the-internet-of-things-for-mere-mortals/ 
9 Dan Saffer, Designing for interaction, 2006, New Riders. Larry Tesler interview 
available at http://www.designingforinteraction.com/tesler.html 

 
 
User understanding will improve over time with familiarity, but only if we, as 
designers, help them with clear system images. We need to figure out what 
complexity users will need to deal with, and where products and tools can be 
simplified. As a general rule, if the task or activity the user wants to perform is 
complex or requires a high level of skill, it’s appropriate for the user to engage 
with that complexity. Or perhaps it’s a job for a professional. If the task or 
activity can be expressed simply but the technology is complicated, there’s a 
good case for designing around a simplified mental model.  
We don’t yet know what that looks like for IoT. For starters, if you need to 
explain to the user that part of the system is not working, it’s important to 
explain why and what this means. For example, if you are alerting them that 
the security alarm has lost internet connectivity, you might choose to tell them 
that the cameras and alarm sounder are still active but that they will not 
receive alerts. Or if the user is travelling in a different timezone, you might 
want to show the current time at home on the heating control app, to indicate 
that schedule changes are based on the local timezone of the controller, not 
where they are now. 
Composition 
Patterns of composition 
Composition refers to the way the functionality of a service – especially the 
user-facing functionality - is distributed across devices.   
Good composition distributes functionality between devices to make the most 
of the capabilities of each device. Designers should take into account the 
context in which each device will be used, and what users expect each to do.  
There are some common patterns to composition. Web services delivered 
across smartphones, desktops, tablets and connected TVs are often multi-
channel. Each device provides the same, or very similar, functionality (in other 
words, there is a high level of redundancy between devices. Kindle, Netflix 
(see figure 9.12), BBC iPlayer, Facebook and eBay are all examples. Devices 
with small screens or limited input capabilities may only provide a subset of 
key functionality. But each device offers a similar basic experience of the 
service. Many users won’t own or use all the possible devices on which the 
service could be used and this doesn’t matter. It’s perfectly possible to use the 
service via a single device and still have a good experience.  

 
 
 
Figure 9.12: Netflix is a multi-channel service 
However, many IoT services run on a mix of devices with different 
capabilities. Service functionality and user interactions will be distributed 
across different devices. Some functionality may be exclusive to a specific 
device. For example, in the Withings ecosystem, only the scale can measure 
body mass and only the blood pressure monitor can measure blood pressure. 
Some devices may be custom designed for the service. We’ve seen many 
examples of these already throughout the book, from connected door locks to 
smart watches and thermostats.  
For reasons of cost, or practicality, these may have limited inputs and outputs 
that are quite different from a conventional ‘computer’ UI. A door lock may 
have a keypad and handle and perhaps an LED to show whether it is connected 
or not. It probably doesn’t have a screen. In these systems, we have to figure 
out which device handles which functionality. Each device (and the internet 
service itself) may have a different role in terms of providing user interactions, 
connectivity, information gathering, processing or display. In the terminology 
of Wäljas et al. this is a cross-media system (figure 9.13 is an example).  
Figure 9.13: Withings is a cross-media ecosystem 
For example, a heating service as shown in figure 9.14 below may comprise: 

 
 
 
A boiler that heats the water 
 
An in-home controller/thermostat that tells the boiler when to switch on or 
off (this may be a separate thermostat and programmer, or just one 
device). 
 
A gateway that provides a low power connection to the controller and 
bridge out to the internet 
 
A cloud service that stores user account information and remote access to 
the system 
 
Smartphone and web apps that connect to the cloud service. 
Figure 9.14: system diagram of a heating system (Thermostat by Iconathon, 
boiler by Axeny Virtinsky, radiator by Jose Hernandez from the Noun Project) 
Both the Tado and British Gas Hive systems work in this way, but user-facing 
functionality is distributed differently. The Tado thermostat/heating controller 
has almost no UI (see figure 9.15). User can view the current temperature and 
set or alter the setpoint, but most interactions are handled on the smartphone10. 
This may keep manufacturing costs down. Smartphone interfaces are much 
cheaper to develop than physical interfaces, as components like screens and 
buttons are relatively expensive. It’s an elegant choice for a small household 
occupied mainly by smartphone owners but there are trade-offs. If you don’t 
have your phone to hand, or the battery is dead, or you’re a guest in the house 
without access to the phone UI, you have limited control.  
                                                             
10 The first generation Tado controller had no onboard controls at all: all interactions 
were via the smartphone. 

 
 
 
Figure 9.15: The Tado heating controller and smartphone app 
The Hive Active Thermostat heating controller is a standard thermostat with 
on-device controls (see figure 9.16). The device is designed to be competitive 
on cost with non-connected heating controllers. So interaction design has to 
work within the constraints of an LCD screen and limited number of buttons. 
However heating can also be controlled by phone and web apps, which are 
probably easier for most people to use than the hardware. This means that 
heating controls are available to anyone in the house, whether they have access 
to the smartphone app or not. 

 
 
Figure 9.16: The Hive Active Thermostat heating controller and smartphone 
app (Images: British Gas). 
Some devices may not support any user interactions at all (see figure 9.17). 
Some devices may be simple sensors which simply provide data to the service, 
as in an air quality monitoring system. In this case, you may simply hand off 
all functionality onto a single mobile or web app. Although the overall service 
may be complex, the web or smartphone UI in this case is in some ways 
simpler to design as there is only one interface to consider. (Chapter 8, 
Interface and interaction design, considers the pros and cons of handling 
functionality via a mobile device versus a specialized embedded device). 
Figure 9.17: The Greenbox garden irrigation controller is entirely controlled 
by a smartphone app (need alternative – 403 on greenboxhq.com). 
When key tasks are available across multiple devices, users may still be able to 
use the service even when some devices are unavailable. For example, the 
Withings smartphone app can use the onboard accelerometer to measure 
activity, so even if the user has forgotten their dedicated activity monitor, they 
need not lose data (see figure 9.16).  

 
 
 
Figure 9.18: The Withings mobile app can use accelerometer data to measure 
activity. 
Even where different devices support the same tasks, they may be used in 
different situations. For example, the key advantage of connected heating 
systems is that the smartphone app enables control from anywhere, whether 
that’s the other side of the world or the user’s bed.  
However, this isn’t a recommendation to duplicate every piece of functionality 
across every device – redundancy isn’t necessarily a good thing. Too many 
functions on a single device can make the UI harder to use, especially if the 
device has limited input/output capabilities.  And user interaction components, 
such as screens and buttons, add significantly to manufacturing costs of 
embedded devices. The right decision will balance the usefulness, cost, and 
usability of putting various features on different devices. 

 
 
For many systems, it makes sense to use a network of devices that are 
specialized for particular functions. For example, the Lively elderly care 
service uses specialized sensors to monitor the pillbox, fridge and the kitchen 
(see figure 9.19). This is referred to as synergistic specificity11: specialized 
components working together to deliver a service that is more than the sum of 
those components.  
Figure 9.19: Lively elderly care system: safety watch for summoning help, 
with pedometer and medication reminders, hub, sensors for fridge and 
pillboxes and a custom sensor containing an accelerometer to detect 
movement. (Image: Lively) 
Users may also want to add (or remove) devices to suit their individual needs, 
or combine them in different ways to fulfill different purposes – this is a 
modular system. In some cases, different devices can be used to perform 
different functions as part of different services. For example, a home 
monitoring system may offer contact, temperature, moisture, smoke and 
motion sensors. These could be used to detect occupancy for heating, lighting, 
and potential safety problems or intruders. A highly modular system can be 
very powerful, but may be more complex for users to understand, configure 
and use. To use the distinction from chapter 4, it’s likely to be more of a tool 
                                                             
11 Schilling, M. A. 2000. Toward a General Modular Systems Theory and Its 
Application  
to Interfirm Product Modularity. Academy of Management Review, 25 

 
 
for early adopters than a product that majority consumers will configure 
themselves. It’s also more complex for designers to communicate which 
devices are doing what at each point. 
Determining the right composition 
For any service, there is often more than one possible suite of devices that 
could be used to deliver the service. The decision as to which is most practical 
will be influenced by the following factors. You may wish to prioritize, per 
task, which devices are optimal for each task, acceptable for the task, or not 
possible for this task. 
What best fits the situation and context? 
The most important consideration is what best fits the activity, situation and 
user needs. Certain devices need to live in one place where only one function 
is required, e.g. blind/window shade controllers or light switches. Others are 
used in a context that places constraints on form factors and interaction 
modalities. For example, climbers need their hands free, so delivering altitude, 
weather and location information to a wrist top makes sense. Using a mobile 
phone’s music controls while driving would be dangerous. Key functionality 
should be mirrored on the car dashboard in a way that minimizes demands on 
attention. Features that are essential to one device may be inessential or even 
inappropriate for others.  
The availability and reliability of the network connection is also key. If you 
have a good reliable connection you can afford to centralize more 
functionality, e.g. putting your irrigation system controls on a smartphone. If 
not, and you can’t afford to lose access to functionality, you may need user 
controls (and perhaps more onboard intelligence) in the edge devices. 
Can you work with pre-existing devices?  
What hardware can you assume your user base already has and is familiar with 
using? For example, if users all have smartphones you can use these to handle 
complex interactions, determine location and identity, and in some cases 
handle local and internet connectivity.  
Smartphones come with onboard sensors (such as accelerometers), which can 
be used for tasks such as activity tracking without additional hardware. 
However, custom form factors (such as wristbands) may provide a better 

 
 
experience in some contexts of use, such as the forthcoming clip-on fall sensor 
for the Lively safety watch for older adults. Specialist equipment may also 
tend to offer better performance through better quality parts, such as more 
powerful GPS chips or better battery life.  
What interaction capabilities do the various devices have (or could you 
cost-effectively include on a custom device?)  
You may be able to consider adding or removing interaction capabilities (like 
screens, buttons, audio beeps or LEDs) to embedded devices. However, these 
typically add to production costs, so you will probably need to keep these to a 
minimum and offload more complex functionality onto a mobile or web UI. If 
you’re not able to influence the design of the embedded devices, you’ll have to 
work with the interaction capabilities you have. 
You may also decide that just because a device could support a particular 
function, it does not have to. Keeping things simple may make the device 
interface easier to understand. For example, a heating controller with a low-
resolution screen and limited buttons might be best used for status information 
and in-the-moment controls (turn the heating up now!). You could offload 
more complex tasks such as schedule setting onto a web or mobile interface. 
The bigger screen size and richer interaction capabilities will enable a better 
design. You can also provide a ‘good’ way to do the task on a fuller featured 
device and a limited or compromised version on a less capable device which 
must occasionally work alone. For example, an intruder alarm system may 
provide an easy way to view which sensors triggered the alarm on a mobile 
interface. The task may also need to be possible on the alarm panel via a basic 
LCD screen, even though this is likely to involve many more button presses, 
perhaps navigating menus and modal states. 
Does the system need to work if some devices are unavailable?  
What happens if a device is unavailable, e.g. a smartphone is lost or the battery 
is dead?  Does it need to be used by 3rd parties who may not have access to a 
web or mobile app, such as visitors to the home? Can the device work offline? 
How accurate does sensing need to be? 
If a service needs to know the rough location of its user, a smartphone can 
estimate this from for GPS/celltower signals. If it needs to know which room 

 
 
the user is in at home e.g. to turn the lights on and off, a smartphone could be 
used via Bluetooth LE connections, but will only be accurate if the user carries 
it with them at all times. 
Do users have set expectations of devices? 
Users may expect certain devices to conform to familiar form factors, or 
provide familiar functionality. For example, they are likely to expect a heating 
controller to have some way of turning the heating on, or up. 
How do you balance cost, upgradeability and flexibility? 
User interface components, such as screens and buttons, are expensive to add 
to embedded devices. You may therefore decide to limit interactions on the 
embedded devices themselves and do most of the interaction “heavy lifting” 
via mobile apps or web interfaces. 
It can be difficult to add new features to devices that are already out in the 
field, especially if this requires modifications to the interface. Again, 
offloading interactions to smartphone and web apps, which can be modified 
relatively cheaply and quickly, may make sense.  
What connectivity and power issues do you need to consider? 
It may also be simpler to handle information processing in the cloud, as with 
the Withings scales and fitness trackers, which simply take readings, display 
them in real-time, but handle all other functionality in the online service. A 
weight and fitness service can handle temporary losses of connectivity 
gracefully, by storing data locally and syncing when the connection is 
available again. However, for other types of service this will not be acceptable, 
e.g. where safety or security is at stake. If a monitoring system for an elderly 
person loses connectivity, it might be acceptable for motion sensor data to be 
temporarily unavailable to the carer, as long as it is clear that connectivity has 
been lost and live data is not available.  However, it would be completely 
unacceptable for the elderly person to be unable to use their emergency alarm 
during this time: the alarm should be able to fall back to using another form of 
connectivity. 
In other words, the designer has to make an informed call on which tasks need 
to be available in different conditions: offline? With no power?  Does the 

 
 
system make no sense if connectivity is lost?  Is a suitable fallback available? I 
should not have to worry about being unable to enter and leave my own house 
because the front door lock has lost connectivity or has no power – and many 
other household functions must also be taken for granted to be effective. 
What is the physical context of use? 
Do any parts of the system need to have particular form factors/be used in 
certain contexts: e.g. worn on wrist, weatherproofed, used one handed?   
How central to the service are the devices? 
Are devices central to the conceptual model, or not?  This may not affect the 
distribution of functionality, but it will affect the way in which you 
communicate the composition of the system.   
9-20: (Summary table of composition patterns?) 
Consistency 
“Users should not have to wonder whether different words, situations, or 
actions mean the same thing. Follow platform conventions.” Jakob Nielsen, 
199412 
Consistency is well known as a general UI design heuristic. It’s a simple 
concept to grasp. But knowing what needs to be consistent, and what does not, 
can be tricky. You may have to trade off one type of consistency for another. 
Do you make all the buttons look the same so they are easy to identify as 
buttons? Or does that cause confusion by implying that certain functions are 
similar, when in fact they are not? Too much consistency, or consistency 
between the wrong things, can be as damaging as too little. 
                                                             
12 Nielsen, J. (1994b). Heuristic evaluation. In Nielsen, J., and Mack, R.L. 
(Eds.), Usability Inspection Methods, John Wiley & Sons, New York, NY. 
 

 
 
Consistency across multiple devices 
In the case of cross-platform systems, designers also need to consider 
consistency across different devices. Consistency works to create a sense of 
coherence of the overall system.  
Words, data and actions that are the same across devices should be understood 
to be the same. Words, data and actions that are different should be understood 
to be different. This helps users form a clear mental model of the system and 
its capabilities. Knowledge that users have gained about the system from one 
device can be transferred to help them learn how to use other devices.   
Other elements that may need to be consistent to some degree across devices 
include 
 
Aesthetic/visual design (to make the devices look, feel and sound like a 
family) 
 
Interaction architecture (how functionality is organized) and  
 
Interaction logic (how tasks are structured or the types of control used). 
 
Guidelines for consistency 
Use consistent terminology 
As a rule of thumb, the highest priority is to use consistent wording across 
devices. This ensures that data and actions across different platforms are 
understood to be the same thing. Whatever the display capabilities of each 
device, you can always give functions or data the same label even if you can’t 
make them look the same.  
For example, imagine you are working on a connected heating controller that 
offers 3 mode options: ON (heating is on continuously), AUTO (heating is 
running to a pre-programmed schedule), and OFF (see e.g. figure 9.21). These 
are already set in the fixed segment LCD display and cannot be changed. You 
might think that ON and AUTO are not the clearest terms. You’d prefer to 
change them to CONTINUOUS and TIMER or SCHEDULE in the 
smartphone app interface. However, this would create a disconnect: users then 
have to understand that ON and CONTINUOUS are the same thing.  

 
 
Users are often intimidated by heating controllers and expect them to be 
confusing. And they might not have a strong enough mental model of the 
system to infer that CONTINUOUS and ON are the same thing. Having tested 
systems with similar issues, we found it was more important that these options 
were consistently named across devices. The value of better terminology in the 
mobile app is undermined if users don’t understand that the functions are the 
same. 
 
Figure 9.21: The Hive Active Heating controller is an example of a device 
with fixed segment LCD labels mapped to physical buttons. 
Follow platform conventions 
The second priority is for each UI to be consistent to the platform conventions 
of the device.  
Mobile OS UI conventions are well documented in styleguides, e.g. the iOS 
Human Interface Guidelines13 and Android Design14. There are some key 
                                                             
13 
https://developer.apple.com/library/ios/documentation/UserExperience/Conceptual/Mo
bileHIG/ 

 
 
differences, for example Android users may expect contextual menus on long 
press, a convention which does not exist on iOS, where the same menu would 
be displayed on another screen (see figure 9.22).  
Figure 9.22: Android and iOS screens from the same mobile app showing 
different platform conventions  
In general, for mobile devices and others that have established platform 
conventions, following these conventions will make it much easier for users to 
use your app even if it means some things are done in a different way than 
they are on any specialized connected devices. A heating control app for iOS 
must be a good iOS app as well as recognizably part of the heating service. It 
does not have to be a skeuomorphic representation of a heating controller. But 
this works both ways: a heating controller does not have to pretend to be an 
iPhone just because it has an iPhone app. The goal is to ensure that interfaces 
are appropriate to each device, yet also feel like parts of a coherent service. 
Interaction elements such as buttons, menus and switches should be 
recognizable according to the platform conventions of the device. An iOS 
button should generally follow conventions for button styles on iOS rather 
than trying to look like the physical button on an embedded device. 
Most importantly, specific interaction controls should be optimized to the 
platform. If a physical control uses a wheel, slider or handle, there is no need 
to replicate this on a small touchscreen device where it could be harder and 
more imprecise to use.   
For example, the Nest thermostat incorporates a rotating bezel, which is used 
(amongst other things) to increase and decrease the temperature. The bezel 
makes a clicking noise as it is rotated. But the iOS app up/down controls are 
arrows. The designers could have shown a representation of a bezel onscreen 
for the user to tap and drag around. But the arrows are a much more efficient 
and precise control on a touchscreen (see figure 9.23). Adjustments to 
domestic temperature are typically within a degree or two, so precision is 
important to avoid overshooting.  
                                                                                                                                     
14 https://developer.android.com/design/index.htmlio 
 

 
 
Figure 9.23: The Nest thermostat and iOS app (showing Celsius 
temperatures). 
 
Aesthetic styling 
A consistent visual and aesthetic style across all platforms reinforces the 
perception of a coherent service. Consistent fonts and colors across devices are 
nice but may not always be practical. For example, the Nest thermostat uses 
the same font and colors to indicate temperature on the wall thermostat as the 
iOS app. But this isn’t always going to be possible: a cheap monochrome LCD 
screen won’t support a choice of fonts anyway. Replicating the LCD font on a 
web or smartphone app may impact readability. It’s also a definite retro 
statement that may not be the look you’re after. It’s nearly always aesthetically 
clunky to make a screen design resemble a physical device. 
Audio is another way to use aesthetic design to create a sense of coherence. 
Tapping the down/up arrows on the Nest smartphone app produces the same 
clicking noise per increment as the bezel on the wall thermostat. This is an 
elegant touch that adds a common aesthetic to each interaction without 

 
 
intruding on usage. It adds to the sense that the devices are a family and helps 
users form a conceptual model of how the system works. 
Where visual elements also convey meaning it is vital that they are used in the 
same way. This is called semantic consistency. To continue with the heating 
example, you may use red/orange/blue colors to indicate temperature. Or a 
particular icon might indicate that the water tank is heating up. The icon may 
be higher resolution on devices with better screens, but it must be recognizably 
the same thing (see figure 9.24). 
Figure 9.24: An icon (tbc) shown on a smartphone screen and Pebble watch 
 
Interaction architecture and functionality 
Interaction architecture is the logical hierarchy (or other structure) of the UI as 
mapped to the controls. This is likely to be less consistent across devices and 
more platform-dependent.  Devices may have different functions in the 
service. Even where there is an overlap between functions, they may be 
optimized for different purposes. A wall thermostat might be optimized for 
small adjustments and switching mode (e.g. turning on the hot water). It might 
need to support changing the heating schedule, but that’s always going to be a 
better experience on the mobile or web app. In optimizing the thermostat for 
quick adjustments, the designers might knowingly create a less-good UX for 
schedule changes. But they might view this as acceptable if users are likely to 
change schedules on a smartphone or website anyway.  
As devices are used for different things, it’s not necessarily desirable to group 
functions in exactly the same way. For example, a mobile or tablet screen can 
provide one touch access to many functions, facilitating a broad, shallow 
functional hierarchy. Fitting the same functions into a heating controller with 
an LCD screen plus 3 buttons may require a narrower, deeper hierarchy.   
You may also need to use modes, in which the same buttons perform different 
actions in different states. Modes are typically more difficult to use, but they 
may be an essential compromise if you’re stuck with the hardware (see e.g. 
figure 9.25). Structure your mobile or tablet app to be a great solution for that 
device, and don’t let it be constrained by the limitations of the embedded 
device. 
Figure 9.25: heating controller with modal functions 

 
 
UIs on different devices don’t all have to have the same features, but where 
they do, the functionality should be consistent. For example, if a heating 
controller supports a 6 phase schedule (6 phases throughout the day) but the 
companion phone app only supports 4, users will wonder what happened to the 
other two (see figure 9.26). 
9.26 – Diagram: 6 versus 4 phase operation… 
Consider the most likely combinations of devices 
As a designer, you may have to think about design across a large ecosystem of 
devices. Users may not have all of these. Focus your effort to achieve 
consistency on the combinations of devices users are most likely to have. To 
stick with the example of a heating system, all your users might have a 
controller and smartphone app, but few will regularly use both iOS and 
Android apps. So it’s important that the smartphone apps are both 
appropriately consistent with the controller. It’s less important that knowledge 
users acquire from using one smartphone app is transferable to the other. For 
example, the location of the menu button, or the way that system settings are 
grouped and accessed, need not be the same across mobile platforms but 
should conform to the platform conventions (as discussed above under ‘Follow 
platform conventions’). Few users will use both and those who do are likely to 
be familiar with both conventions. 
 
Continuity 
What is continuity? 
In the film industry, continuity editing ensures that different shots flow in a 
coherent sequence, even if they were filmed in a different order.  It would be 
disrupting to the narrative if a character’s hairstyle changed within a scene, 
furniture moved around, or a broken window was suddenly intact again15. 
In cross-platform interaction design, continuity refers to the flow of data and 
interactions in a coherent sequence across devices. The user should feel as if 
                                                             
15Spotting continuity errors in movies is a sport. Sharp-eyed viewers share the errors 
they have spotted on websites such as http://www.moviemistakes.com,. 

 
 
they are interacting with the service through the devices, not with a bunch of 
separate devices. There are two key components here. Data and content must 
be synchronized, and cross-device interactions must be clearly signposted. In 
my experience, some of the biggest usability challenges in IoT are continuity 
issues. 
Data and content synchronization  
It sounds obvious that different device UIs should each give the same 
information on system state.  
Kindle Whispersync is a great example of synchronization. You can switch 
between reading on different devices - even swapping between the book and 
the audiobook - and your place in the book is always up to date (see figure 
9.27). 

 
 
 
Figure 9.27: Kindle Whispersync UI dialog (Image by Kei Noguchi). 
You’d expect this from any other connected device too. For example, your 
wall thermostat says it’s 21C and the heating is on. You’d therefore expect 
your smartphone heating app to say the same thing, and not to tell you that it’s 
actually 22C and the heating is off. 
If you turn the heating off from the wall, then you’d expect the smartphone 
app to reflect that change in state right away. Right? 
Unfortunately in IoT, as discussed in chapters 2 and 3, this isn’t always 
possible. Devices that need to conserve power, such as those that run on 
batteries, often cannot maintain constant connections to the network as this 

 
 
uses a lot of power. Instead, they will connect intermittently, checking in for 
new data. This can cause delays and result in situations where some interfaces 
do not reflect the ‘correct’ state of the system. Network latency is also an 
issue: it’s possible for the user to know that something has worked before the 
UI does. For example, they may be physically sitting near a light that they 
have just turned on and have to wait for a smartphone app UI to tell them what 
they already know.  
To return to the heating example: in the UK, it’s common for heating 
controllers to run off a battery16. So a heating controller may need to connect 
via a low powered network like ZigBee to a gateway, and only connect 
intermittently to check in for new instructions. There might be a delay of 
perhaps two minutes between a setting being changed on the smartphone app 
and the heating controller receiving that instruction.  
This causes discontinuities in the UX. If a user changes the settings on the 
smartphone app (say, turning the temperature up from 19C to 21C), there may 
be a period of up to two minutes before the heating controller checks in to the 
service and receives the updated instruction. During this period, the phone UI 
could show that the system is set to 21C, and the controller UI will show that it 
is set to 19C. If the user is standing in front of the controller with the 
smartphone app, they will see two conflicting pieces of information about the 
current status of the system (see figure 9.28). This violates one of the most 
fundamental of Nielsen’s usability heuristics, visibility of system status: “The 
system should always keep users informed about what is going on, through 
appropriate feedback within reasonable time.”17 
                                                             
16 UK heating engineers prefer battery powered wireless controllers as they can be 
installed easily and sited anywhere without risk that rewiring will be needed. In the 
UK, mains power is 240V AC and any mains electrical work must be done by a 
qualified electrician. Even replacing an existing mains controller in the same location 
requires an electrician. This isn’t an issue in the US, where HVAC controllers typically 
run on a special low voltage circuit, making them safe for homeowners to install 
themselves. This means that in the US, it’s feasible to offer a controller that maintains a 
constant connection to a WiFi network, and the system can always be in sync.  
 
17 Nielsen, J. (1994b). Heuristic evaluation. In Nielsen, J., and Mack, R.L. 
(Eds.), Usability Inspection Methods, John Wiley & Sons, New York, NY. 

 
 
 
Figure 9.28: In some situations, devices may temporarily report conflicting 
information about the state of the system. (Hand/phone by Siddarth Dasari, 
thermometer by Saneef Ansari) 
What can you do about this? You could fix this by making the controller check 
in more frequently. But that would run the battery down within days. Users 
don’t expect to have to change batteries in heating controllers several times a 
week. So that’s not practical. 
Your next option is to consider how you can design the smartphone UI to 
account for this two minute period. There are two possible approaches.§ 
Firstly, you could show the updated settings the user wanted to apply: the 
temperature setting of 21C, even though it might (for a short time) give a 
misleading impression of the system state. If the instruction cannot be applied 
for some reason (e.g. temporary internet outage at the property), you can alert 
the user and then revert the UI to the old state. In essence, you pretend that it 
has worked while you wait for confirmation from the controller. 
Instagram employ similar ‘white lies’ to make their mobile app feel more 
responsive. For example, Instagram registers likes and comments in the app UI 
while the request is still being sent to the service. The user is notified if the 
action fails. They call this ‘performing actions optimistically’18 (see figure 
9.29). 
                                                                                                                                     
 
18 Krieger, M ‘Secrets to Lightning-Fast Mobile Design’, Warm Gun conference 2011. 
https://speakerdeck.com/mikeyk/secrets-to-lightning-fast-mobile-design 

 
 
 
Figure 9.29: Instagram registers likes or comments in the UI even while the 
status bar spinner shows the request is technically still being sent 
When everything works OK with our heating example, the responsiveness 
allows the user to feel as if they are interacting with the service, not just the 
phone UI. They have direct control of the heating.   
The second approach is to be more transparent about what is technically 
happening. You show the instruction as being in the process of being sent. 
This is the approach used by the Lowes Iris system (as also shown in chapter 
3): a status message at the top of the screen is shown to indicate that an 
instruction is being sent. When confirmation is received that the controller 
received the instruction, a confirmation message is displayed (see figure 9.30). 

 
 
 
The temperature is set to 109F. The 
user turns this up to 129F 
The system registers that the new 
temperature should be 129F, and 
that the current temperature is still 
109F. A status message indicates 
that the instruction is still being sent. 

 
 
A status message confirms that the 
target temperature has been changed. 
The water heater has turned on to 
heat the water to 129F. 
Image 1:  
Figure 9.30: The Lowes Iris water heater UI, showing the status message 
Here, the UI is showing the data as being in the process of being sent. In 
essence, the system is saying to the user: ’thanks for your instruction, let me 
see whether I can do that’. This requires the user to know a little more about 
how the system works in order to understand why the instruction isn’t just 
acted upon. It also introduces the possibility of failure to every interaction, 
successful or not.  

 
 
There are no standards here yet, and no right or wrong answer for every 
situation. In our first example, the primary use case for the system is to support 
remote access. If the user is out and about and turns the heating on remotely 
using the phone app, the 2 minute delay is not noticeable. The house will be 
warm when the user gets home. Even if the user is in, heating is the type of 
system that operates on a timescale of hours, so unlike a light switch, down to 
the second responsiveness isn’t necessarily needed. If the user is standing in 
front of the heating controller with the smartphone app, it may be confusing, 
but the compromise may be acceptable. 
In other situations, any delay or uncertainty about whether a command has 
been executed might be dangerous. For example, a person who presses an 
emergency alarm button must be absolutely confident their call for help has 
been sent and received. In this case, the UI should not make it appear that the 
system has received and acted on their command until it has definitely done 
so. 
The frequency with which data is synchronized around the system can heavily 
shape the user value of the service. For example, dual fuel smart meters 
monitoring gas and electricity usage may report data at different frequencies 
for each fuel. The device monitoring electricity usage can run on mains power, 
so it can report data every few seconds. However, it would be dangerous to 
place a mains powered electrical device on a gas pipe. So the gas monitoring 
device will be battery powered. To maintain acceptable battery life, gas data 
will be reported less frequently than electricity data, perhaps only every 30 
minutes.  
With live electricity data, users can turn devices on and off and use a display 
(see figure 9.31) or smartphone to view almost immediately the energy impact 
each device had. The system can be used to understand the energy 
consumption of specific appliances and behaviors, such as boiling a kettle, or 
turning on a clothes dryer. 
Figure 9.31: an in-home display  
With gas data in half hour chunks, it’s harder for the user to relate 
consumption to specific gas consuming activities in the home. You can’t see 
the immediate impact of turning on a gas cooker. Was the last half hour’s 
consumption high because the oven was on, or because the heating or hot 
water was in use? So the system data does not directly answer the question 

 
 
‘how much gas does my oven consume’?  As relatively few activities in the 
home run on gas as compared to electricity, it’s possible for users to make 
some rough guesses from the data. For example, if no one is at home but gas is 
being consumed, that might mean that the heating is on (and thus that the 
schedule should be changed). But for more detailed insights, the system would 
need to analyze longer-term patterns in gas consumption data and estimate 
likely usage by appliance. 
When it’s not possible for all system data to be perfectly synchronized or 
‘live’, it’s important to indicate how old data or status information may be. For 
example, you might show a timestamp for a sensor reading, or the time that the 
latest status information was received. 
In the energy monitoring example above, it’s important that users understand 
that the two energy readings are not equally ‘live’. You could display a 
timestamp for each reading, but you might also choose to display information 
in a different format. You might use a line graph for electricity (because you 
have near continuous readings) but a bar chart for gas, where readings are only 
intermittent. (See e.g. figure 9.32). 
Figure 9.32: gas vs electricity displays showing timestamps. (mock up) 
It’s important to ensure that system status information is as accurate as it needs 
to be for the context of use. In a safety critical system, it should be clear when 
data may be out of date or an instruction may not yet have been received or 
acted on. A remote door locking system should not pretend that it has locked 
the door until proven otherwise! Perhaps the biggest challenge design-wise is 
how to design these behaviors for a system that needs to do multiple things 
with different responsiveness demands, such as heating, lighting and safety 
alarms. It’s safest to err on the side of communicating what is actually 
happening, but in some circumstances that may feel inelegant. 
Handling cross-device interactions and task 
migration 
Cross-device interactions require users to switch between devices in order to 
achieve a goal. Examples might include syncing data from a wearable fitness 
tracker to a smartphone, or connecting home sensors to a gateway. 
Transitions between devices should be smooth and well-signposted. The word 
‘seamless’ is often used in cross-platform UX, but it’s probably misleading. 

 
 
Where a task requires the user to interact with more than one device, they need 
to be aware of the seams: the different role of each device, and the point at 
which the handover happens. This is especially important to help reinforce the 
user’s mental model of the system, and what each part does. The less familiar 
they are with it (e.g. during setup when devices are new and unfamiliar), the 
more explanation is required. Below, we set out some key requirements for 
effective, usable cross-device interactions. 
In the first place, the user needs to know that they need to switch to another 
device to complete their intended task. They may have to identify the correct 
device from amongst several: for example, there may be several identical light 
bulbs. Then they need to know what they’re being asked to do, and any 
information that’s needed to interact effectively with the other device. They 
also need to know why they’re being asked to switch. For example, are they 
transferring data, or pairing the devices? 
For example, the Misfit Shine syncing process tells the user to place or tap the 
Shine on the iPhone screen (see figure 9.33). (Data is transferred over 
Bluetooth LE but the sync is initiated by the phone recognizing the Shine on 
the touchscreen). 
Figure 9.33: Misfit Shine syncing 
(https://www.youtube.com/watch?v=wmUOczrb9J4 - 
http://i.ytimg.com/vi/wmUOczrb9J4/maxresdefault.jpg) 
The Bluetooth pairing process to connect a Jaguar car to a smartphone displays 
a 4 digit code on the dashboard that needs to be entered in the phone (if not 
already displayed) (see figure 9.34). (See chapter 12, Key interactions, for 
more on Bluetooth pairing interactions).  

 
 
 
Figure 9.34: Jaguar syncing with Bluetooth device (low res grab from 
jaguar.com, get high res when Allan back from holiday). 
The user also needs to know what reaction to expect from the other device. 
This is especially important if it has a very limited UI. For example, hitting a 
button on the web UI may make an LED flash for two seconds on a motion 
sensor to help you know which one it is, but you need to know where to look 
(see figure 9.35). 
 
Figure 9.35: Identifying a sensor from the AlertMe web interface 
If the interaction is not an integral part of a process (i.e. not something the user 
has to do), provide enough context/content to enable them to decide whether 

 
 
it’s important right now. For example, the Pebble Smartwatch can notify the 
user of new emails, texts and Twitter alerts, and shows some of the content 
(see figure 9.36) . The user might not be able to see the whole message, but 
there’s usually enough information to decide whether it’s important to get out 
the phone and read the whole thing there and then. A wearable that only tells 
you if you have a message, and not who it is from or what it might be, would 
not offer much over the phone’s audio alert or vibrate function. 
Figure 9.36: A Pebble notification 
With a multi-device interaction, it is very easy to lose track of your progress in 
a task, or for one or more devices to lose connectivity. Where possible, design 
for interrupted use. Try to avoid locking users into lengthy processes (such as 
setup) which must be completed in one sitting or in a specific order. Provide 
some flexibility: if the user has to break off and return later, don’t lose their 
progress - allow them to resume part way through. Guide them back to the 
parts that need to be completed when they return. For example, a home 
automation system setup process might require users to associate a gateway 
with an online account and then pair devices. If the user is interrupted after 
creating the online account but before pairing the devices, make sure that 
when they log in there is a clear route to resume and add devices, not just a 
blank screen! (See chapter 12, Supporting key interactions, for more 
information on designing effective setup experiences). 
 
Broader contexts of interusability 
This chapter has focused on cross-device digital interactions. However, these 
principles can also be applied to more holistic service design thinking across 
both on- and offline interactions. This broadens the focus of UX to include 
marketing and sales materials which set expectations of what the product does, 
packaging and setup guides which shape initial impressions of the UX, to 
customer support.    
As with cross-device interaction design, the individual parts can be good, but 
if they don’t work together well the overall experience can still be 
unsatisfactory or confusing.  
You might consider composition when figuring out which setup instructions to 
put onscreen and which in a print booklet. You would need to consider 

 
 
consistency of language, information graphics and aesthetics across online and 
print materials. And you might also need to consider the continuity of any 
processes that require users to refer between materials. Again, setup is a key 
example: if your instruction booklet says ‘now the LED will blink for 2 
seconds’, that’s a pointer to look at the other device. (Setup is covered in more 
detail in chapter 10, Key interactions). Setting user expectations accurately is 
also a form of continuity: if your marketing materials highlight a feature, it 
should be easy to find the UI. If not, that’s a form of discontinuity. 
The interusability model may not be complete for the broader service context, 
but I have found it useful for thinking about interactions than span digital and 
non-digital media.  
 
Chapter summary 
Conventional usability/UX is concerned with interactions between a user and a 
single UI. Interusability deals with interactions across multiple devices. The 
aim is to create a coherent UX across the whole system even when devices 
have very different characteristics. 
Users need to form a clear mental model of the overall system, although it can 
be challenging for them to understand the interconnections between devices. 
Designers need to distribute functionality between devices, to suit the 
capabilities of each and context of use (composition).   
They also need to determine which elements of the design should be consistent 
across which parts of the system, for example terminology, platform 
conventions, aesthetic styling and interaction architecture.  
Data and content can sometimes be out of sync around the system, causing 
continuity issues. Designers may need to find creative ways of dealing with 
this in the UI. When interactions begin on one device and switch to another, 
clear signposting is needed. 
 
 

Adam Connor &
 Aaron Irizarry
 Discussing 
Design
IMPROVING COMMUNICATION 
& COLLABORATION THROUGH CRITIQUE

Discussing Design: Improving Communication 
and Collaboration through Critique  
 
Chapter 1: Understanding Critique  
Chapter 2: What Critique Looks Like  
Chapter 3: Making Critique a Part of Your Process 
Chapter 4: Critiquing in Different Environments 
Chapter 5: Facilitating Critique 
Chapter 6: Critiquing with Difficult People and Challenging 
Situations 
Chapter 7: Closing 
 
	  

 
1 
Understanding Critique  
We’ve all been there… 
Whether you’re a developer, project manager, designer, business analyst, etc. 
it’s more than likely that you’ve been in a meeting where the topic of “design” 
has come up explicitly or otherwise. If you’re on a project that involves the 
creation of something – a tool, a service, a product, a brochure, a logo, 
whatever it may be – you’re going to be involved in conversations about how 
it works, what it can do, what it contains, how it looks and so on.  
Collaboration and coordination are critical elements in the success of projects 
in most (if not all) modern organizations. There isn’t a single individual who 
will be responsible for coming up with an idea, designing it, building it, selling 
it and supporting it. Instead these responsibilities and the expertise that come 
with them are divided amongst a variety of contributors who each bring their 
knowledge to the team. So we need to work together, combining our skills and 
expertise. And to work together, we need to talk with each other. We need to 
discuss what it is we’re creating, why we’re creating it and how it will all 
come together. 
But as many of us have witnessed, these conversations can turn painful. In 
most cases, as these discussions go wrong, the worst they do is delay progress. 
They seem to go nowhere as people disagree and argue and team members 
walk away not sure what to do next. And so measures need to be taken to plot 
next steps. While individual instances like this may not seem like a huge deal, 
it’s the culmination of discussions that go this way that really impacts a team. 

 
Over time as the delays grow and grow, the lack of momentum, the repeated 
questioning of what to do next and a sense that team members just can’t seem 
to agree has a tremendous impact on people. They stop wanting to collaborate. 
They begin to care less and less about the project. And in some cases they 
begin to silo themselves, feeling that since they can only control their own 
output, that will be their sole focus without regard to the other team members 
and how it impacts them. 
In some cases though, these conversations can become much, much worse. As 
people talk about what they think should or should not be a part of the design, 
it’s not uncommon for their emotions to become engaged. And for some this 
can be difficult to control, which can lead to people getting defensive, tempers 
flaring, yelling, berating and lines being crossed. 
The intent of this book is to help teams take a step back to look at the 
conversations that are happening in their projects and improve them. These 
discussions about what we’re working on are always happening, whether it’s 
because we called a meeting to discuss something specific or they happen 
casually as we’re walking to grab a cup of coffee. 
But we don’t often take time to examine these conversations and understand 
what makes them good or bad. This book will look at the elements of these 
conversations and the patterns through which they arise and describe best 
practices for making them more productive to projects and toward 
strengthening a team’s ability to collaborate through incorporation of critique, 
an often-overlooked component of the design process. 
The problem with “feedback” 
As we’ve described, conversations about what we’re creating in our projects 
can come about through a number of ways. One of the most common ways 
design discussions are initiated is for a team member to ask for feedback on 
something they’ve created or an idea they have. They might just grab someone 
at a nearby desk because they want to take a break from putting something 
together and think about what they’ve done so far. Or it could be part of a 
planned milestone or date in the project’s timeline, often called Design 
Reviews. 
It’s not that either of these is a bad time to get other’s thoughts. Rather, the 
first real problem we encounter is from the word “feedback” itself. It’s a word 
that’s become engrained in our vocabulary. We use it all the time, a la “I’d 
love to get your feedback on something…” 

 
What is feedback? 
The issue with the term “feedback” lies in its broadness. Feedback itself is 
nothing more than a reaction or response. Designers talk about feedback and 
feedback loops all the time in their work. The user of a system or product 
interacts with it in some way, perhaps by clicking a button, and the system 
changes in one way or another. It could be that an animated loading bar 
appears while some new data is fetched and displayed, or maybe some 
elements in the interface move their position. See figure 1-1. 
[Illustration of feedback in a UI] 
That reaction by the system is the feedback. It is the system’s response to what 
the user has done. Feedback is a reaction that occurs as a result of us doing 
something. In human-to-human interactions like the conversations we have in 
our projects, feedback can be nothing more than a gut reaction to whatever is 
being presented. And to be quite honest, even though we might not want to 
admit it, that’s often all it is. 
Reactions might tell us a bit about how someone feels about what has 
happened or been created, and that can be useful in some cases, but it also 
presents us with some challenges. As we’ll discuss more in chapter 2, a 
reaction doesn’t go far enough to be really helpful in allowing us to improve 
our creations and move forward in our projects. Not only that, the reaction 
itself is most likely built upon the biases and preferences of the individual 
doing the reacting, and in many cases that individual, whether it’s a developer, 
designer, stakeholder, etc. is not a representative of the audience for our 
creation. There is a popular line in many design communities: “You are not the 
user.” It’s important to keep that in mind when we’re discussing things we’re 
creating and deciding what should or shouldn’t be a part of them. 
The problem with asking for feedback is that, most times, we aren’t being 
specific enough in describing what we really want feedback on. Sometimes we 
might get a gut reaction. Sometimes we might get a list of instructions or 
suggestions on what to change. Sometime we might get comments that 
describe how what we’ve created doesn’t match what the critic would have 
created, and so on. And weeding through all of that feedback to try to 
determine what’s of use to us — what will help us identify the aspects of our 
design that we should iterate upon — can be a struggle. 
Three kinds of feedback 
As Aaron and I have seen in our own experiences and through watching and 
working with other teams, there are key characteristics that separate 3 forms of 
feedback, all of which vary in their level of usefulness to us in the design 

 
process. Understanding these three kinds of feedback can help us understand 
the conversations we have with our teams and improve our own ability to react 
to and use feedback to strengthen our creations. 
The First 2 Types of Feedback 
Reaction 
Good lord! That’s awful! An inebriated cocker spaniel could have 
done better! 
Reaction-based feedback tends to be emotional and/or visceral. It happens 
quickly, instinctively. Feedback of this type can often be the most passionate, 
as it’s driven by an individual’s own expectations, desires and values. 
Essentially, it’s a gut reaction. 
There is a second kind of reaction-based feedback that is driven by the 
individual’s understanding of what they are expected to say, typically driven 
by a cultural understanding or what they think the presenter wants to hear. In 
this case, the reaction itself isn’t in regard to what’s being presented, but rather 
to the situation of simply being asked for feedback in the first place. Examples 
of this kind of feedback often take the form of: 
That’s wonderful! Great work! 
I love what you did with… 
Why it can be an issue: At best, this kind of feedback tells us about the 
subconscious reaction the viewer has to what you’ve created. These kinds of 
reactions are something we do want to understand when creating a product or 
service. It’s not ideal to try to sell something potential customers or users 
cringe at or grumble about the second they see it. But are the people you’ve 
asked for feedback from reflective of your design’s actual audience? Are they 
looking at it the same way your potential users would? Does this reaction tell 
you anything specific about any of the design decisions you’ve made so far or 
their effectiveness? 
Direction 
You should have made all of those radio buttons a drop down 
[because…] 
Direction-based feedback typically begins with an instruction or suggestion. In 
many cases that’s also where it ends. In this form of feedback, the individual 
providing it is often looking for ways to bring the creation more in line with 
their own expectations of what the solution should be. You might also have 
encountered examples of this kind of feedback that start with phrasing similar 
to: If I were to do this… or I would have… or I wish… 

 
In all of these, the individual giving the feedback is trying to communicate his 
or her own vision for the creation. It may be because they have their own 
detailed solution already in their mind, or it may be that they feel a problem 
they perceive is not adequately being solved. In some cases, the individual will 
go on to describe why they are making the suggestion, which can shed a bit 
more light on their thinking and motives. 
Why it can be an issue: Similar to reaction-based feedback, direction-based 
feedback without any explanation tells you nothing about the effectiveness of 
your decisions in meeting the design’s objectives. Sure, if the person giving 
you feedback is the one who will ultimately approve the design, it might 
supply you with a to-do list that you could act upon to get their approval, but 
getting that approval and creating an effective design are not necessarily the 
same thing.  
In the situations where the individual also gives some explanation as to why 
they are making the suggestion, you at least begin to understand the impetus 
and perhaps the issue they’re trying to address with it. But it still does not help 
you understand how or why the design you have is or is not effective at 
addressing that problem. 
Additionally, when left unchecked, this type of feedback leads to problem 
solving which, while an important part of the design process, is counter-
productive to the conversation you’re trying to have. It’s not that the direction 
itself that is being given is a bad idea, but at this point it’s out of place. We’ll 
talk more about problem solving and it’s impact later on in Chapter 3. 
We’ll talk more about how to deal with these forms of feedback in chapters 4 
and 5. For now what’s most important is to understand what these forms lack 
in terms of their usefulness to us in helping us improve our creations. 
What we really need is critical thinking 
Critical thinking is the process of taking a statement and determining if it is 
true or false. When we’re designing something, we’re doing so to meet or 
achieve some set of objectives. When looking for feedback on our creations, 
what we should be working to understand is whether we think it’s true or not 
that what has been created and the in which it’s been created will work to 
achieve those objectives. We’re looking for a form of analysis to take place. 
And that’s exactly what critique is. 
Critique: The third form of feedback 
If the objective is for users to seriously consider the impact to their 
bank balance before making a purchase, placing the balance at the 
bottom of the screen at the same size as all the other numbers isn’t 
effective because it gets lost in all of the other information. 

 
 
It’s this form of feedback that is most helpful to us in understanding the impact 
of our design decisions. Critique isn’t about that instant reaction you might 
feel when seeing something, or about how you would change someone’s 
creation to better solve an issue.  
Critique is a form of analysis that uses critical thinking to determine whether a 
creation is expected to achieve its desired outcomes (and adhere to any 
pertinent bet practices/heuristics). Those outcomes can be any number of types 
of things. They can be about utility, for example giving someone the ability to 
complete a task. They can be about metrics and measurement, as in increasing 
the number of conversions for a particular call to action. Or they can be 
experiential, for example making someone feel excited or surprised by 
something. 
For example, I once worked on a project for a financial services company 
whose goals for an update to their site’s design included getting more visitors 
to spend time viewing their articles and commentary and more specifically to 
increase the average number of articles and commentary pieces viewed by a 
user within a visit. But the primary goal was an increased completion rate for a 
short contact form that helped generate leads. With these objectives agreed 
upon by the team we were able to focus our conversations on the aspects of the 
design ideas we came up with that we felt would or would not work to produce 
these results. 
Good critique is comprised of 3 key details: 
 
It identifies a specific aspect of the idea or a design decision in the 
creation being analyzed. 
 
It relates that aspect or decision to an objective or best practice. 
 
It describes how and why the aspect or decision work to support or 
not support the objective or best practice. 
We’ll talk more later in chapter 3 about the role of these objectives in design 
projects and in setting the foundation for productive conversations, but 
hopefully this begins to give you a sense of how critique differs from the very 
broad and reactionary basis of feedback. 
Knowing what we want and what we’re asking for makes all the difference in 
how our conversations play out. It may seem like little more than semantics, 
and it’s damn hard to let go of using the word “feedback” when asking to talk 
with people about an idea or creation (hell, we’ll be using it over and over 
again in this book). But as you’ll see as you read the coming chapters, what’s 
important is to understand the difference and to use that understanding to 
inform how you ask people and facilitate the resulting conversations. 

 
Critiquing Solo 
This book centers on critique as a form of, and tool within, the conversations 
we have with our teams. But it’s important to note that an individual alone can 
critique as well.  While an individual critiquing another’s work on their own 
(without the creator) can be challenging (more on this in [reference]) 
Individuals can, and should, critique their own work. When creating 
something, the brain operates as a toggle, switching between creative thinking 
– where individuals are generating ideas or assembling parts of ideas, and 
analytical thinking – where they are determining whether what they’ve created 
so far is inline with what they are trying to achieve. As experienced designers, 
artists, engineers, etc. they have learned how to be deliberate in controlling 
when to make this toggle. 
Why critique is so important 
Throughout this book we’ll dive deeper into the various ways critique fits into 
the design process, but as we get started, it’s important to identify these 
patterns and benefits in order to keep in mind the broader application of the 
concept. 
Critique builds shared vocabularies 
Ever noticed how, as people spend more and more time together, they begin to 
talk like one another? They begin to use the same phrasing of words and 
names for things. This is a natural occurrence in social groupings – part of a 
process called acculturation. Intuitively we seek out efficiency in 
communication with others. Communication between individuals grew out of 
a need of one individual to produce action by another. And it isn’t very 
effective if we have to spend all of our time getting our point across. So as we 
come to build a shared understanding of what words and phrases mean 
amongst the group we instinctively use them over other words that may mean 
the same thing but that aren’t as easily recognized by the others, streamlining 
and improving the quality of conversations. 
One challenge project teams face in collaboration is the variety of language 
used by people in different roles. Members from IT, design and business may 
all have different ways of referring to the same thing. By bringing your project 
team together to critique on a recurring basis, you provide a venue for this 
shared vocabulary to be built within.  And as that vocabulary is being built, it’s 
happening across roles and silos, improving the ability of team members to 
communicate more efficiently with members of other roles. 

 
Critique as consensus building 
Design-by-committee and frankensteining are much-hated phenomena in the 
design community. Both are often used to imply the misguided amalgamation 
of ideas into a final creation without any attention paid to their disharmony or 
whether they really work to achieve the desired outcomes. In environments 
where this takes place, the driving force has become to get those involved, 
particularly stakeholders, all saying yes to what is being created without regard 
to whether what is being created is actually the best solution. And so bits and 
pieces are added to appease the various influencers of the project. 
In these environments, critique may still be happening, but it’s typically found 
happening in a small corner of the project team. A few people, maybe the 
designers and developers are doing it, but the entire team isn’t doing it. 
Remember that the team includes stakeholders. 
What Aaron and I have found in teams that carry a culture of critique is that at 
any time, these discussions may involve members of the team from all areas. It 
becomes a natural part of the way they talk with each other. And so, as the 
project progresses and decisions are made, members are consistently focused 
on and discussing the elements of the design that work best to achieve its 
goals. Consensus begins to be built around which ideas are stronger or weaker, 
and the design is strengthened as a result. 
Years back, on a project that involved the creation of a new insurance 
application and processing platform, I got a call from one of the developers. 
She had been working on building out some of the functionality I had 
prototyped for the initial submission of an application. While doing so, she 
was stopped by a stakeholder who had an idea for a new piece of functionality 
that they were hoping could be added to the screens. In a few minutes, the 
developer had given me a call (I worked in another office), set up a screen 
share, and she, the stakeholder and I were discussing the new functionality and 
the ideas for its inclusion in the design. 
As we did, we referred back to the task flows and scenarios we’d created for 
this particular set of functionally as well as the goals we had for individuals 
using it. In doing so, we quickly realized that the functionality itself didn’t fit 
the objectives we were after. It would have created an awkward branch in the 
task flow and more work for the user. We also saw though, that the main point 
of this new functionality was to give the users, insurance agents; view of a key 
piece of data that had been missing from our designs. Once we realized that 
and agreed that being able to see that data was important to our objectives, we 
were able to generate a few ideas for adding the data value to the screen in an 
effective manner. The entire process took less than 30 minutes and afterwards, 

 
the stakeholder, developer and myself all walked away, confident that we had 
improved the design. 
Critique as iteration driver 
Critique is part and parcel of an iterative process. We’ll talk more about 
iteration in chapter 3, but it can’t be understated how closely these two are 
tied. If we’re going to look at design as an iterative process, something that 
takes a creation and evolves it from idea to executed creation and further, then 
there need to be points in our process that drive that evolution and indicate 
what should change moving forward (i.e. the next iteration). 
Many organizations use various testing and observation methods such as 
usability studies and beta releases to do this today, but depending on your 
market and audience, those can often take a lot of time. Sometimes you just 
need a quick step back. In the early stages of design my team at Mad*Pow 
might iterate 3 or 4 times on a design in a single day.  All we do is make sure 
that after sketching and developing ideas for a period of time, maybe as short 
as 10-15 minutes, or as long as 1-2 hours, we stop and examine what we have 
so far against our objectives and best practices. Iterations don’t always have to 
be huge readjustments of the entire creation. Sometimes they might be much 
smaller, focused on a handful or even just one interaction, or flow or design 
element. 
In these cases, the drivers to our iterations are the critiques our teams regularly 
go through. Most are self-induced, as in not dictated by a date in someone’s 
project plan, by the designer or design team when they feel like it’s time to 
take a break from creating and look critically at what they have so far. 
Critique as a life skill 
By now, I hope that some of you are thinking about the processes your own 
organization goes through in projects. That’s exactly what this book is about, 
but hopefully you’ve noticed that what we’re really talking about here is 
something that applies beyond the boundaries of a business or organization. It 
applies to any time you want to improve on something. Whether it be a new 
recipe, your skills in Ultimate Frisbee, playing the ukulele, painting portraits 
of people’s pets with macaroni, hot glue and food coloring, whatever it is, you 
can incorporate critique to help you improve upon it. 
As mentioned above, critique is really about critical thinking. As we work 
toward doing or creating something with a set of objectives in mind, we 
always have the opportunity to stop and analyze what we’ve done so far in 
order to better inform how we might go forward. Critique is an act of 

 
reflection. It is part of the learning process. If Aaron and I might be so bold as 
to say, critique is a life skill, not a “design” skill. 
Why critique is often overlooked 
If critique is so important, why don’t people pay more attention to it? Why 
don’t teams take time to practice and talk about it? 
When your team has a “post-mortem” for a project, what do you talk about? 
Most likely you talk about the decisions that were made, maybe a little about 
the process with regard to the kinds of meetings you had or when they 
happened. Have you ever talked about the language you use when talking to 
one another? Have you ever talked about how specific conversations were 
framed and facilitated? 
When we think about our processes we tend to focus on a level higher than 
where the quality of critique is really influenced. Talking is something we take 
for granted and so the details of how we do it are often glossed over. But there 
is that obnoxious old cliché: the devil is in the details. Or more accurately, it 
should be that the devil is in ignoring the details. 
Even when critique does come up in organizations, Aaron and I have watched 
it get dismissed or ignored for a number of reasons. The first being that in 
media today, the term “critique” has become almost meaningless. Media 
personalities, writers, pundits – anyone, really –  can offer their “perspective” 
on a new product, service or policy and call it a “critique.” It’s come to mean 
nothing more than one person or group’s thoughts on what another person or 
group has done. The aspects of critical thinking and of focusing on what the 
originating person or group’s intents were have gone out the window. 
Another thing we’ve seen happen is that critique can sometimes be thrown into 
the “creative professional” silo as something only artists, designers and their 
like do. It’s not for everyone else. 
Bullshit. 
What these organizations fail to realize is that when a project is tasked with 
making something, no matter what it is, every single team member is a part of 
the creative process. The creating doesn’t just happen in the design 
department. It happens with every decision about what will or won’t be part of 
the final creation, whether that’s a feature, a paragraph of content, a color 
pallet, a UI pattern, anything. 
I’m ranting a bit here aren’t I?  

 
The point is, that if we truly want to improve our processes and improve the 
way our team members work together, we can’t ignore the details and we can’t 
silo our critical thinking. Yes, there are roles and responsibilities that each 
team member will carry based on their expertise and knowledge, but critical 
thinking about what we’re creating and how we’re creating it is a part of every 
member’s role. 
Incorporating critique and moving 
forward 
The remainder of this book is about that role and the best practices and 
methods you have at your disposal for making sure it’s fulfilled. As we dive 
deeper into the details, you’ll start to see just how pervasive critique can be, 
how may places it can pop up and how many parts of your process it can help 
you improve upon. 
The ultimate goal for teams that are interested in improving conversations and 
collaboration with critique is not to add one more tool or type of meeting to 
their ever growing toolbox. Instead it’s to change the way we talk about what 
we’ve created regardless of the type of meeting or conversation we’re in. 
The quality that has stood out the most to Aaron and I amongst teams that 
have incorporated critique well is that critique itself becomes a natural part of 
how they talk to one another. Yes, they might, and often do, have critique 
meetings (or sessions, if you hate the “m” word), but outside of the meetings, 
whenever they begin to talk about what they’re creating, their exchanges are 
framed around the objectives and goals they are working to achieve. 
Critique itself is often referred to as a soft skill. Soft skills are often seen as 
personality traits that determine how people interact with others. Whereas 
“hard skills” tend to be applicable to a specific task, action or type of work, 
soft skills apply broadly across most activities and work. As we examine 
critique throughout the book, it’s important to keep in mind two key aspects: 
critical thinking —the examination of what we’re critiquing against the 
objectives for it’s creation, and delivery — how we are presenting that critical 
thinking to the designer and others we’re working with. 
It should also be noted that critique isn’t just about pictures. Often it can be 
seen as a process that only applies to a wireframe, or a visual design mockup 
or maybe a prototype, but in reality critique can be applied to just about 
anything. Any time you or your team construct something or make a decision 
about something in order to reach a specific goal or fulfill a certain objective, 
it is something that can be critiqued. For example, you’re team may establish a 

 
set of design principles to help guide you in deciding between ideas for an 
interface. There are best practices for establishing and using design principles. 
For example, a good design principle should help you eliminate more ideas 
than you pursue and it should be specific and avoid overly subjective and 
ambiguous terms like “fun”. As such, with best practices like these, when your 
team creates principles for your next creation or project, you have an 
opportunity for critiquing your principles against them.  
Chapter Summary 
In order to work together, team members will have countless conversations 
throughout the course of a project. Many of those conversations will involve 
discussions about what they’re creating: its features, its content, its look and 
feel, etc. Often, these conversations can be unproductive or even painful and 
detrimental to the project and team. 
Many of the reasons for these problems can stem from our understanding of 
“feedback” which is often how these conversations (or elements of them) are 
labeled. There are a few problems with “feedback” 
 
Use of “feedback” as a label is fairly ambiguous. It can be used to 
label any response to what someone has done or created. 
 
By definition feedback is nothing more than a reaction. And reactions 
themselves often aren’t helpful to helping us understand what is or 
isn’t working in what we’ve created. 
 
Feedback does not inherently include the two elements most 
important to helping us understand what is or isn’t working in what 
we’ve created: critical thinking and a focus on the creations 
objectives. 
 
Feedback itself can be categorized in 3 forms: reaction, direction and 
critique. 
Critique is a form of analysis that uses critical thinking to ask whether what 
we’ve created will work to achieve the goals and objectives we are designing 
for. It can, and should, be a part of any formal or informal discussion we have 
about what we’re creating.  It’s important that we learn about critique because 
it’s useful to us for a number of reasons: 
 
It builds shared vocabularies: by regularly having conversations 
focused on critical thinking and objectives for the product, teams will 
begin to use the same labels and language when describing things, 
leading to more efficient communication. 

 
 
It builds consensus naturally around the strongest options: when 
done by cross functional teams, including decision makers and 
stakeholders, attention is focused on which options are the strongest 
toward the product’s objectives, and so consensus is built naturally 
around those options. 
 
It informs and drives iteration: critique allows us to use our 
expertise and understanding of a domain and an audience to iterate 
more frequently. It doesn’t replace other methods we have for 
analyzing our design decisions, but rather augments them and adds to 
our options. 
 
It’s a life skill: critique doesn’t just apply to businesses and 
organizations creating products and services. It applies to any 
situation where we create or do something in order to reach a set of 
objectives. 
Unfortunately, critique is often overlooked for a number of reasons, but by 
recognizing its value and spending a little time understanding what it is and 
how it fits within our teams and processes we can improve the quality of the 
conversations our team members have and make critique a natural part of our 
communication and process. 
  

 
 
2 
What Critique Looks Like 
The Two Sides Of Critique And The 
Importance Of Intent 
There are two sides, or roles, in any critique: 
Recipient: The individual(s) receiving the critique (i.e. the creator or 
presenter of whatever is being analyzed) who will take the perspectives 
and information raised during the critique, process it and act upon it in 
some way. 
Giver: The individual(s) giving the critique, who are being asked to think 
critically about the creation and provide their thoughts and perspectives. 
Within both of these roles there is the discrete aspect of intention: why are we 
asking for/receiving/giving feedback. Intent is the initiator of the conversation 
and is often what separates successful critiques and feedback discussions from 
problematic ones. 
For the best discussions, the intent of each participant, regardless of whether 
they are receiving or giving critique needs to be appropriate. If we aren’t 
careful, critique with the wrong, or inappropriate, intent on either side can lead 
to problems not only in our designs, but also in our ability to work with our 
teammates. 

 
 
Receiving critique with the appropriate intent is about wanting to understand 
whether the decisions you’ve made are working toward your product’s (and its 
design’s) established objectives. 
Giving critique with the appropriate intent is about wanting to help the creator 
understand the impacts of their choices with regard to their effectiveness 
toward reaching the design’s objectives. 
Both acts are done with the intention of using the information and perspectives 
raised during the critique to iterate upon and strengthen the design. This is an 
important aspect of the discussion. Many of us have experienced meetings 
where we’re asked to give our thoughts on something like a design, or a 
process, or maybe even a project (ex: a post-mortem) and over time, if these 
discussions repeatedly fail to produce action and changes, our desire to 
participate and provide our perspectives wanes. 
Part of what makes for strong critiques is the desire to participate, to help. It 
isn’t the case that everything said in a critique will produce a discrete 
modification to the design, but overall, participants should feel that the 
discussion, which they actively contributed to, played a role in improving the 
design, not just changing it, but strengthening its ability to produce the desired 
objectives. 
Prior to beginning a critique, whether you’re the giver or receiver, it’s best to 
make sure that you’re going in with the right intent.   
Giving Critique 
As mentioned, giving critique with the right intent is about wanting to 
contribute to the improvement of the creation by helping the creator 
understand the relative success their design choices have in working towards 
objectives. When we start our feedback discussions from this mindset we think 
critically not just about what we’re saying but why we’re saying it, which is 
important to productive dialogues. 
To better understand what giving a good critique looks like, let’s first look at 
some characteristics of bad critique. For more tips on handling and working 
with unhelpful feedback and unwanted critique, see Chapter 5: Critiquing with 
Difficult People and Challenging Situations. 

 
 
Characteristics of Bad Critique 
Selfish 
The wrong intentions for giving critique are often selfish. They’re focused on 
personal goals and desires for attention at the expense of the team or other 
individuals, specifically the creator of whatever is being discussed. 
Selfish critique comes from the motivation of the giver to not only be heard 
and attract attention, but also to be recognized as smarter or superior, or 
further personal goals. 
The most recognizable examples of this can be seen on social networks like 
Twitter or Facebook whenever there is a change to a popular app, device etc. 
A new feature is added or something is changed, and people immediately 
begin slamming decisions, calling them ridiculous and stupid and stating how 
things “should have been designed.” 
But in most of these situations, the commenters have only a cursory 
understanding of what the designer or team was working towards and the 
constraints they were working within. How is this helpful? 
When we do this (and Aaron and I are guilty of it too, as do most people) are 
we really trying to help someone improve their design? Or are we more 
interested in showing others in our community or organization how smart we 
are on a certain topic? 
This type of feedback happens on project teams as well. Maybe you’ve 
encountered it at work, are thinking of a colleague who’s done it to you, or 
maybe you’ve done it yourself.  
Sometimes, this kind of feedback comes from having our own ideas of what 
we think the design should be but not having had a chance to share it with the 
team. So we set about to use feedback as a way to diminish the design being 
presented and (in some cases) propose our own alternative. While Aaron and I 
are firm believers that a great idea can come from anywhere, and team 
members in any role should be given an opportunity to share their ideas, this 
path to doing so is detrimental to a critique. 
As we’ll discuss more in Chapter 4, critique is not the place for exploring new 
ideas. Its purpose is to analyze the design as it has been created so far. Shifting 
a group from an analytical mindset to an explorative one is best done with 
deliberate facilitation. 
Untimely 
Despite what we may think, and what some people may even say, people 
aren’t always looking to hear feedback on their work. Unless someone has 
specifically told you they’d like your feedback, it’s unwise to think your 

 
 
conversation is a great opportunity to share your analysis with them. If 
someone is telling people about their creation, it may just be to get the word 
out or simply that they’re excited about what they’re working on. 
In order for the receiver to really listen, process and make use of critique, they 
need to be in the proper mindset. Whether at a team member’s desk, in a 
meeting, or on social channels, when critique is uninvited it can lead to 
defensiveness, communication breakdowns, and often paints the person giving 
it as a “know it all”. 
Incomplete 
For critique to be useful, the creator(s) need to understand not just the potential 
outcome or reaction to an element of their creation, but the “why” behind it. 
We often see feedback in the form of things like: 
“I think the button is better than the link.” 
“Nobody is going to click on that.” 
Or, even worse: 
“This is terrible…” 
This type of feedback typically comes from the reactive form of feedback we 
discussed in Chapter 1. It lacks the extended critical thinking that allows those 
working on the design to understand what they might need to change in their 
next iteration. In order for these critiques to become valuable they need to be 
followed by an explanation as to “why” the giver is having that reaction or 
foresees a certain outcome. For example:  
“Nobody is going to click on that because the current page design 
leads the eye down the left side of the screen away from the call-to-
action.” 
 
Good critique is actionable. When the “why” behind the feedback is included, 
the comment can now be fully understood and the creator can take action. That 
is to say that the creator has enough of an understanding of what is/isn’t 
working and why that they can explore alternatives or make other adjustments. 
 
Note though that this is different from prescription or direction. It is not the 
case that critique should tell the creator how to act on something or 
specifically what changes they should make (i.e. the directive form of 
feedback). Good critique tries to avoid problem solving as it can detract and 
distract from the analytical focus of the discussion. For more on this, check out 
Chapter 4. 

 
 
Preferential 
Another common characteristic of bad critique is feedback that is justified by 
the giver from purely preferential thinking. We’ve all heard horror stories 
about this kind of feedback: designs are torn apart, not because a particular 
aspect isn’t working toward its objective, but rather it doesn’t match exactly 
what the feedback giver “likes”, for example: a website design gets canned 
because the color scheme reminds a stakeholder of a Christmas sweater his ex-
wife had given him. 
Though it might seem ridiculous, this kind of feedback is common, though 
maybe not always so extreme. It usually feels like it’s coming out of nowhere 
and has no relevance to the work we’re doing, but sometimes, it really just 
boils down to a personal preference. 
This kind of feedback is not only unhelpful, as it does nothing to analyze a 
creation with regard to objectives, it can be distracting and counterproductive. 
This is especially the case when it comes from team members or stakeholders 
who are in a position of approval. In these situations, the team begins, 
consciously or subconsciously, to prioritize that individual’s tastes alongside 
or above project and user goals even if they conflict. 
Best Practices For Giving Critique 
Where critique with the wrong intent (done knowingly or not) is harmful, 
damaging teams, processes, and most importantly the product. Useful, 
productive critique has the ability to strengthen relationships and 
collaboration, improve productivity and lead to better designs. In order give 
the best critique possible, think about the following best practices when giving 
feedback. 
Lead with questions. Get more information to base your feedback on and 
show an interest in their thinking. 
Chances are, before being asked for your feedback, the creator(s) will give a 
brief explanation of what they’ve put together so far and how it would work. 
This gives you some context and understanding of the objectives they have 
and the elements of the design they’ve put in place to achieve them. But 
chances are they haven’t explained everything. Actually, as we’ll talk about 
shortly, HOPEFULLY they haven’t explained everything. 
This is your chance to open up the dialogue. By asking questions you give 
yourself more information on which to base your analysis and give stronger, 
actionable feedback. And if done in a non-interrogative way, it shows the 
creator that you’re genuinely interested in, not only their work, but their 
thinking behind it, which can make discussing it and listening to feedback a bit 
easier for them. 

 
 
Examples of questions you might ask: 
 
Can you tell me more about what your objectives were for [specific 
aspect or element of the creation]? 
 
What other options did you consider for [aspect/element]? 
 
Why did you choose this approach for [aspect/element]? 
 
Were there any influencers or constraints that affected your choices? 
Remember though, the dual purpose of asking these questions of the creator: 
1. to get you more information and… 
2. to get them more comfortable talking about their thought process and 
decisions.  
To that extent, how you ask these questions can have a huge impact? Asking 
every question beginning with “Why…” can feel abrasive or like an attack. 
Use lighter, more inviting phrasing such as, “tell me more about…”  
Use a filter. Hold on to your initial reactions, investigate them and discuss 
them in the proper context as appropriate. 
You’re going to have reactions. As the work is being presented to you there 
will be things that make you think “huh?” or “that’s cool” or “I don’t get it” or 
maybe something worse. Hold onto those reactions and remember that 
reactions don’t typically make for useful feedback. Ask yourself why you’re 
reacting in that way. Ask the presenters additional questions if necessary. 
Once you understand your reaction and what caused it, think about whether it 
makes sense to discuss. Does it relate to the objectives of the product, the 
audience for it or any particular best practices that should be followed? Or is it 
more about your personal preference or wishes for how you’d like to have 
seen it designed? 
If your feedback is related to the product’s objectives or best practices, and not 
about your personal reaction or preferences, then it definitely has a place in the 
conversation. Sometimes though, you may find yourself with feedback that, 
while not a best practice or preference, is also not specific to a best practice or 
a stated objective. Maybe it’s something new that you think should be 
considered. What should you do in those situations? 
In these cases it may still be useful to bring your feedback into the 
conversation. These kinds of thoughts can be useful in determining additional 
objectives or constraints for the project that need to be exposed. It may be 
something you can discuss quickly and then continue on with the critique, or it 
may prove to be something sizeable that needs a separate, dedicated discussion 
so that the critique isn’t derailed.  

 
 
Don’t assume. Find out the thinking or constraints behind choices. 
“To assume makes an ass out of you and me.” Most of us have probably heard 
that line a few times in our lives. It’s one of my father’s favorites, and it’s 
stuck with me.  
Assumptions can be one of the worst things to happen in a discussion that is 
meant to be productive. When we make assumptions we begin to form our 
thoughts, questions and statements around them, without ever knowing if 
they’re true or not. And before you know it, the participants of the discussion 
go on their way to do their work based on very different ideas and producing 
work that doesn’t align with each other or reality.  
When you make assumptions in a critique about what an objective or 
constraint might have been, or maybe that there were no constraints and the 
designer could have done anything, you begin to offer feedback that can be 
less useful because it isn’t based on the real situation. 
To get around this is simple. The quickest way to eliminate assumptions is to 
ask about them. 
Yup. More questions. Put your assumption out there and ask if it’s accurate. If 
it is, continue on with your insights. If it isn’t, you may find that you need to 
adjust your thinking a little. 
Don’t invite yourself. Get in touch and ask to talk about the design. 
Recall in the previous section that we talked about untimely feedback as one 
of the types of unhelpful critique. If the recipient of the critique isn’t in a 
mindset where they want and are ready to listen to the feedback and use it, 
chances are it’ll be ignored or potentially cause a rift in your working 
relationship with them.  
If you have thoughts about someone’s creation and they haven’t explicitly 
asked for your feedback or critique, get in touch with them first and let them 
know. Tell them that, when they’re at a point when your thoughts might be 
helpful to them, you’d be happy to share them. Give them the opportunity to 
get themselves ready to listen. 
Talk about strengths. Critique isn’t just about what’s not working. 
As a culture and society, we have a tendency to focus on negatives, the things 
that cause us problems, get in our way and that we’d like to see changed. We 
often take the positive for granted. In our project meeting and design 
discussions it’s often no different, we spend the vast majority of time talking 
about what isn’t working. But that can be harmful. Remember that critique in 
about honest analysis. It’s balanced focusing on the design and it’s objectives, 
regardless of their success. It’s just as important to talk about what is working 
as why, as it is what isn’t working. 

 
 
Often when talking about the role of “positive feedback” in critique, we see 
discussions center on the importance of discussing strengths as a mechanism 
for making critical feedback easier the receiver to take. There is a common 
structure often discussed called the “OREO” or “sandwich” method in which 
you begin by offering a positive piece of feedback, followed by a negative 
one, followed by another positive one. It’s a fairly useful technique, which 
we’ll talk more about in Chapter 5, and there have been studies showing its 
effectiveness. 
But there are other reasons for making sure that critiques include discussion on 
what aspects of the design are working toward objectives and why/how. 
Part of the creative process involves the decomposition and abstraction of 
ideas and then recombining them in different ways or with ideas from 
somewhere else. It’s a common way in which we take a familiar concept 
where there is room for improvement or added value and innovate. When we 
talk about aspects of a product or design that are working, there is the potential 
for the creators to examine those areas and abstract concepts or elements from 
them that could be used to strengthen other areas of the design that might not 
be working as well. 
Additionally, with the understanding that the creator(s) will iterate upon their 
design after a critique, how much would it suck if at the next critique you 
noticed that an aspect of the design that seemed great previously had now been 
changed and wasn’t quite as effective, all because it hadn’t been talked about 
and so the team didn’t see a reason not to change it. 
Think about perspective. From whose “angle” are you analyzing the 
design? 
In the previous section we talked about preferential critique, or feedback that’s 
based on personal preferences rather than being tied to objectives for what 
we’re creating. When we’re analyzing a product, it can be easy to forget that 
we most likely aren’t representative of the product’s target audience. Even if 
we are a potential user, we know far more about it than the average user. 
As you analyze a design it’s important for you to try to balance your expertise 
with the user’s perspective. It can be a difficult balance to strike, but by simply 
asking yourself “how am I looking at this” when you examine an aspect of the 
design and making compare your perspective to what you think the user’s 
might be, you’ve got a good start. From there you may find that one is clearly 
more appropriate than the other, (ie your visceral hatred of the shade of green 
being used probably doesn’t matter) or perhaps it might be best to bring both 
up in the discussion. For example: 
“From the user’s perspective, I think all of the steps in this flow make sense 
and are understandable and useable. But from an interaction design 

 
 
perspective I think there may be some redundancy and opportunities to 
simplify…” 
A Simple Framework For Critique 
It’s helpful to have a sense of what the structure of a good critique sounds or 
looks like. As we shared in Chapter 1, critique contains 3 important details: 
 
It identifies a specific aspect of the idea or a design decision in the 
creation being analyzed. 
 
It relates that aspect or decision to an objective or best practice. 
 
It describes how and why the aspect or decision work to support or 
not support the objective or best practice. 
To make sure that, uncover and include all of these details there is a simple 
framework of four questions that we can ask ourselves, or the other individuals 
participating in the critique. 
 
What was the creator trying to achieve? 
 
How did they try to achieve it? 
 
How effective were their choices? 
 
Why is, or isn’t, what they did effective? 
 
These four questions flow together to generate feedback in the form of 
critique. By asking these questions we collect the necessary information that 
allows us to think critically about the creation we’re examining. Lets take a 
look at these questions individually. 
What was the creator trying to achieve? 
We want to understand what we’re to be analyzing the creation 
against so that we can focus our attention on things that are pertinent 
to the conversation and the improvement and success of the creation. 
So we try to identify the objectives that they creator was aiming to 
accomplish through the choices they made. What are the objectives of 
the project or creation that have been agreed upon by the team?  

 
 
How did they try to achieve it? 
Next we identify the choices that the creator made to try to reach the 
objectives they have and produce the work we’re looking at. Whether 
the creator spent time going back and forth between options to 
determine which was better, or something was done just based on 
instinct or given little conscious thought at all, everything being 
looked at is the result of a choice. 
How effective were their choices? 
Now that you are thinking about specific objectives and choices that 
the creator made it’s time to ask whether you think the choices they 
made will work to achieve the objective they set? This is the crux of 
critical thinking.  
Why is, or isn’t, what they did effective? 
Finally, think about the result that you think the choice will actually 
produce. How close is it to the actual objective? Is it completely 
different? Does it work counter to the objective. Maybe it won’t work 
to achieve the objective on it’s own but it contributes, in conjunction 
with other elements of the design, to the objective.  
Note that the first two questions can be reversed in order depending on how 
the design is being presented. These questions form the foundation for the 
critical thinking that comprises good critique. As such, these questions can be 
asked and answered internally by individuals giving feedback, or they can be 
exposed and asked directly of the creator. As mentioned in the section on best 
practices for giving critique it’s great to lead with questions, and questions that 
ask about what choices were made and what objectives those choices were 
intended to achieve make a great way to start the conversation.  
Other questions to think about 
The four questions above will help you formulate feedback that a creator can 
use to better understand the effectiveness of their choices in regards to their 
objectives, but what about other aspects of the design, what about other 
questions that come up. For example:  
 
What new problems, complications, or successes might arise from the 
choices being proposed? 
 
What other objectives should the creator have been considering, but 
didn’t? 
Raising these kinds of questions can be important. Ignoring them may mean 
missing something that becomes problematic later on down the project’s 

 
 
timeline, or it might give rise to a new objective for the team to discuss and 
agree to (or discuss and agree isn’t an objective). 
With additional questions like these however, it’s important to keep in mind 
scope – both the scope of the project/creation and the scope of the feedback 
discussion. These questions may lead to spending too much time discussing 
things that are outside the scope of the project or creation itself, like perhaps a 
known issue that the creation isn’t intended to solve. Or questions like these 
may take the focus off of the aspects of this design that the presenter is looking 
for feedback on and instead use up valuable time on elements of the design 
that haven’t been fully thought out yet and are likely to change anyway. 
This means that the group, both the recipient and the givers need to be 
conscious of this and be prepared to end, or parking-lot, a discussion when it 
begins to moves out of scope. More on this in Chapter 4: Facilitating Critique. 
Receiving Critique 
Listening to people comment on something you’ve created can be scary. It can 
be difficult enough to present something to a group of people, never mind the 
possibility that they then might start to pick it apart. 
When I was in film school, at the end of my each year we were required to 
present our final film to an audience of classmates, instructors, family and 
friends. At the end of my first year, I presented my work, a short film that 
debated which was the better superhero: Batman or Superman (the answer is 
Batman, of course). Following the credits, I walked to the front of the room, 
talked for a few minutes about it and waited for the comments. I didn’t wait 
long, one of the professors began to tear into it, commenting on how pointless 
it was, how little depth it had, how the actors didn’t move enough yet we’re 
working in a medium called “movies”. 
Those 12 minutes still haunt me. And for a very long time after that, I was 
terrified of showing my work – any work. I’ve had multiple instances over the 
years where that fear has gotten so significant that I’ve thrown out everything I 
created. Even when I moved into the business world, the prospect of standing 
there and listening to feedback terrified me. And I had numerous encounters 
with co-workers that reaffirmed that fear.  
Many of you may have had similar experiences, or have hear enough horror 
stories that you’ve feel like it’s happened to you too. All of this fear and 
trepidation can lead to patterns in our behaviors and expectations when 
presenting work that cause us to ask for feedback and critique with less than 
genuine intentions. 

 
 
Just like giving critique, receiving it in a way that is useful and productive 
requires the recipient(s) to have the right intentions. Recipients of critique 
should be in a mindset of stepping back from their creative thinking to 
examine the choices they’ve made so far in order to better understand how to 
proceed and take their creation further. And they should value the expertise 
and perspectives of their teammates in doing so. 
Often though, we see individuals and teams go through the process for the 
wrong reasons. And whether it’s done consciously or not, it leads to issues 
down the road as the project progresses, both for the product and the team’s 
relationships. 
Critique Anti-patterns 
Asking For Feedback Without Listening 
Sometimes we ask for feedback because we feel like it’s the right thing to do, 
or because we feel like we have to. While Aaron and I believe that stepping 
back and forth between creative thinking and analytical thinking is a key 
component of a successful design process, it isn’t the case that you are always 
in a position mentally or tactically, to listen, consider and utilize feedback to 
improve your designs. 
Asking for critique at these times leads to unproductive discussions. By not 
listening to our teammates we miss valuable insights that can help us improve 
our designs. The people critiquing our work are likely to pick up on our 
disinterest and as a result will feel uninterested in sharing their thoughts. And 
over time they’ll be less likely to participate in these kinds of conversations at 
all. 
Depending on the process your organization follows, you may have specific 
times when you’re required to present your work and collect feedback. 
Sometimes, these sessions might be useful to the design, but you’re brain just 
isn’t ready to make the switch to analysis, and so you aren’t ready to listen to 
critique. 
In these situations, it’s important to recognize where your own thoughts are at 
and understand why the meeting is being held. Make the most of it by focusing 
your presentation and the discussion on aspects of your design that are more 
fleshed-out. If conversation turns toward things you haven’t had the chance to 
explore yet, make note of people’s questions or comments and either facilitate 
the discussion back toward aspects that can be analyzed. 
Remember the importance of being able to switch between creative and 
analytical thought. While it might not always feel comfortable, getting 
yourself used to making this switch and how to use it effectively, by making 
critiques a scheduled part of your process, can go a long way to strengthening 
you and your team’s skills as designers. 

 
 
For more on formal critiques and the design process, see Chapter 3. 
Asking for Feedback For Praise or Validation 
Creating something can feel awesome. Whether we do it alone or as part of a 
team it’s not unusual to want to be recognized for our creations. But when it’s 
our motivation for asking for feedback, it can bite us in the ass.  
And yet we do it often. We share our work with statements like “Hey! Check 
out this thing I just made! I’d love your thoughts on it.” When really, the only 
thoughts we want to hear are: “Way to go!” Looks awesome!” and 
“Congratulations!” 
So we wait for the cheers. Some come, and it feels great. But then we get some 
feedback about things that aren’t so great, things we could have done better, 
and it hurts. No matter how valid the points may be, we aren’t in a mindset 
where we want to hear them. So we get defensive. Maybe we argue and try to 
discredit the feedback. Maybe we ignore the comments. But either way, we 
haven’t done a very good job at receiving critique even though we’ve asked 
for it. 
Best Practices For Receiving Critique 
As we’ve described, receiving critique in a way that’s productive goes beyond 
just asking for it and then sitting back to let others give you their thoughts. 
When receiving critique, keep the following best practices in mind: 
Remember the purpose. Critique is about understanding and 
improvement, not judgment. 
There is no such thing as a perfect solution. There is always room for 
improvement. A goal of a critique is to help identify where those opportunities 
are. The conversations we have during critique act as road-signs along the 
evolution of our ideas and creations, helping us to understand which paths 
might take us closer to our end goals. Critique isn’t about pass or fail, approval 
or rejection. They are a reflection used to inform a next step. 
Listen and think before responding. 
Many of us have a bad habit of not really listening when someone is speaking 
to us. Instead we hear the first few words they say, and then instead of 
listening to them continue to speak, we begin to formulate a response and wait 
for the first opportunity to start talking. 
What this means is that while the person we should be paying attention to is 
explaining their thought, instead of listening to and processing that explanation 
we’ve essentially ignored it. It’s not that we’ve done so maliciously, this is a 
common occurrence and most of us do it. Obviously though, this is 
counterproductive to what we’re trying to do in a critique. When receiving 

 
 
critique it’s important for you to consciously work toward preventing any 
natural tendencies to form rebuttals and instead focus on listening to people’s 
entire thoughts. To help make sure you understand what people are telling you 
ask them follow up questions or repeat what they’ve told you as you’ve 
understood it and ask them if your interpretation is accurate. This is called 
active listening. 
Return to the foundation. 
As people share their thoughts with you, you may encounter feedback that 
seems out of place, as though it has little to do with what you’re trying to 
create or the objectives you have. It may be that the person you’re hearing 
from is just having difficulty connecting their thoughts, or it may be that 
they’ve started to offer feedback that is based more on their own preferences 
or goals. 
To help you find out you can use previously agreed upon objectives. If you 
can’t determine for yourself how the feedback relates to the product or 
project’s objectives, try to work with them on relating it back by asking them 
follow up questions related to the objectives. 
If over time you’re able to determine a connection, then you’ll better 
understand the feedback and can use it moving forward. If not, then you know 
that the feedback likely isn’t valuable to your next iteration.  
Participate 
One of the best things a creator can do during a critique is to become a critic 
themselves. Being able to shift our mindset from thinking creatively to being 
analytical about what we’re creating is a key creative skill. Participating in a 
critique of our own work has multiple benefits. 
First, the more we exercise intentionally switching our mindset like this the 
easier it becomes to control this mindset “toggle.” Switching from creative 
thinking to analytical will be easier, faster and something we can do whenever 
we feel like it’s helpful, whether we’re alone at our desks, or we grab the 
person sitting next to us, or we’re in a meeting. 
Second, one of the common challenges people have with giving critique is a 
fear of hurting the creator’s feelings. By participating in the analysis and 
openly talking about the aspects of our product that could be improved upon, 
we can make others feel more comfortable participating in these discussions. 
Aim for dialogue 
One of the worst mechanisms for meaningful critique is email, yet it’s also one 
of the most often used. The problem with email is that it isn’t conducive to 
dialogue. Instead of an in-time back and forth of questions and answers 

 
 
between the presenter and critic, email tends to push people to generate longer 
lists of comments, each of which might spur it’s own conversation.  
It’s almost always true that the best method for critique is a real conversation, 
but that isn’t to say that you can’t collect useful critique through email or other 
digital means. Just make sure that when you do, you pick platforms, or 
structure your requests in ways that maximize the opportunities for back-and-
forth discussion of discrete aspects or elements in your creation. Products and 
services that allow you to annotate documents with comments are often a good 
start for this.  
Critique, Conversation and Questions 
Our hope, as you’ve read this chapter is that it’s become clear that good 
critique, critiques that are productive for the entire team, are the result of 
dialogue. The giver and receiver request and exchange information back and 
forth, and from those exchanges come useful, actionable insights. This means 
that, in a productive critique, there are often a lot of questions asked by both 
parties. 
In fact, great critiques are often more about questions asked than statements 
made. Questions being asked means that assumptions can be validated, 
eliminated or further examined collaboratively. Which means that the 
feedback being collected is based upon a mutually understood foundation 
rather than individual’s different interpretations. It’s also useful for the 
recipient to pay attention to the questions being asked as they can be signs as 
to what elements of the creation may be clear or confusing to others. 
This should also tell you something about how best to ask for feedback and 
which communication platforms make the most sense. It’s common for 
designers or teams to send their creations to other members of the team via 
email and ask for feedback. It’s also common for these kinds of exchanges to 
become problematic. Email isn’t a great conduit for anything resembling real 
time conversations. It isn’t designed to work that way, but being able to 
quickly ask questions and get back responses that allow you to further your 
thinking and either ask additional questions, or provide insights is key. When 
dealing with multiple people giving feedback, these deficiencies become even 
more pronounced as now you need to manage threads, keep track of who gets 
what information via replies and reply-alls, etc. We’ve all likely experienced 
situations where feedback was originally solicited by email, and after one or 
two replies, a conference call or in-person meeting was called because it just 
seemed easier than trying to make sense of the lists of questions and comments 
coming back. 
Online feedback tools like inVision app and others do their best to try to work 
around this, by allowing people to comment on specific aspects of a design 

 
 
and keeping those threads together. This works better, but the non-real-time 
nature can prove challenging as well as individuals try to give their comments 
but have to do so based on assumptions that they haven’t been able to validate 
or eliminate yet. 
That isn’t to say that critique isn’t possible through these mechanisms. It very 
much is, but, if we’re going to use tools like this, perhaps because we’re in a 
situation where we have no other choice, we need to make sure we’re doing 
our best to make them as conversational and focused as possible. When 
requesting feedback through a mechanism like this, be specific about what you 
want feedback on in your request, and specify what the objectives for your 
creation were. Allow for as many questions back and forth as you can. When 
making assumptions in order to offer an insight, make sure to state that 
assumption so that the recipient can see it and verify that it’s true or let you 
know that it isn’t. It takes more work, and can often take a bit longer, but it can 
be done. We do recommend though that, when you can, it’s best to use a 
platform in which everyone can talk in real-time and look at the creation 
together. With some good facilitation (see Chapter 4) you’ll find that sessions 
like this, whether their in-person or through a conferencing tool like WebEx or 
Google Hangouts, you’ll do much better at collecting useful feedback, keeping 
the team in sync and building a sense of collaboration. 
Chapter Summary 
The intention of individual(s) in both roles of a critique discussion, giving 
feedback and receiving it, has a direct impact on not only the quality and 
usefulness of feedback shared in a design discussion, but also on the 
relationships of team members and their ability to collaborate. 
Proper intention is about wanting to understand the impacts of choices made in 
order to better determine what to keep, change, eliminate and strengthen as we 
iterate on our creations and move them forward.   
Whether done intentionally or not, characteristics that make feedback 
unhelpful are: 
 
It’s derived from personal goals: The individual giving the critique is 
doing so because they are looking to be recognized or because they 
have their own ideas on how or what should have been created.  
 
It’s untimely: It’s given without regard to whether the recipient(s) are 
in a mindset or position to listen and make use of the insights.  
 
It’s incomplete: It’s a reaction or prediction without a description of 
what has caused it. 

 
 
 
It’s based on preference: It’s based on what the individual giving the 
feedback personally likes rather than being based on context of use 
and the product’s audience. 
To help ensure your feedback is useful and works toward improving the 
product: 
 
Lead with questions. Get more information to base your feedback on 
and show an interest in their thinking. 
 
Use a filter. Hold on to your initial reactions, investigate them and 
discuss them in the proper context as appropriate. 
 
Don’t assume. Find out the thinking or constraints behind choices. 
 
Don’t invite yourself. Get in touch and ask to talk about the design. 
 
Talk about strengths. Critique isn’t just about what’s not working. 
 
Think about perspective. From whose “angle” are you analyzing the 
design? 
Similarly when asking for feedback, be sure that you aren’t: 
 
Asking with no intention of listening. 
 
Asking when you’re really just looking for validation or praise. 
When asking for critique, keep the following in mind: 
 
Remember the purpose. Critique is about understanding and 
improvement, not judgment. 
 
Listen and think before responding. Do you understand what the 
critics are saying and why? 
 
Return to the foundation. Use agreed upon objectives as a tool to 
make sure feedback stays focused on objectives. 
 
Participate. Critique the work alongside everyone else. 
If we understand the best practices for giving and receiving critique, we also 
notice a few things about how we collect feedback through various platforms. 
The more we’re able to facilitate real-time asking and answering of questions 
across the group, the better the exchange is likely to be. This is why in in-
person and teleconferences with visual capabilities tend to be best. However, 
feedback tools and email can still be used, they just take more planning and 
careful facilitation. 
 

Simon King & Kuen Chang
Understanding 
Industrial 
Design
PRINCIPLES FOR UX AND 
INTERACTION DESIGN

Understanding Industrial Design: Principles for 
UX and Interaction Design  
 
Chapter 1: Introduction: Historical Perspective 
and Industrial Design Principles for Designing Interactions 
Chapter 2: Beautiful: achieve a state beyond utility   
Chapter 3: Iconic: strive to move beyond memorable  
Chapter 4: Sensorial: engage as many senses as possible 
Chapter 5: Timeless: design for longevity 
Chapter 6: Simple: do more with less 
Chapter 7: Playful: find occasions for levity 
Chapter 8: Sustainable: reduce environmental impact 
Chapter 9: Honest: be forthright in purpose and materials  
Chapter 10: Thoughtful: delight beyond the first impression 
Chapter 11: Holistic: make every detail part of the whole 
Chapter 12: Conclusion: Practicing Design Across 
Disciplines 
 
	  

Chapter 1 
Introduction 
Historical background on Industrial and Interaction 
Design 
 
Throughout the last century, the discipline of Industrial Design 
has refined an understanding of how to design physical products 
for people. More recently, as computation and network 
connectivity extend beyond the screen, Interaction Designers 
and UX professionals also find themselves addressing design 
problems in the physical world. Although the context is new, 
much can be learned by looking to the long-standing principles of 
Industrial Design. Technology evolves rapidly, but the underlying 
qualities that define the products we love have not changed. 
 
In this book, we will look at ten principles of Industrial Design that 
can inspire new ways of approaching UX challenges, both on-
screen and in the physical world. Each principle will be explored 
through numerous product examples, both historical and 
contemporary, and related to present or near-future Interaction 
Design challenges. 
 
This chapter will provide a brief grounding in the history of 
Industrial and Interaction Design. We will cover key people and 
moments in each discipline, highlighting pivotal events and 
noting points of divergence and convergence. The history of 
personal computing will be used to trace advances in Interaction 
Design, with particular attention given to the virtual or physical 
nature of different computing platforms. Additional background 
on Industrial Design is interspersed throughout the book in 
conjunction with the examples that illuminate each principle. 

Industrial Revolution 
For most of history, when people needed a particular object, they 
either created it themselves or found someone to make it for 
them. Individuals may have specialized in their production, such 
as shoemakers or carpenters, but their output was still largely a 
unique creation. 
 
There is evidence that generalized fabrication was used to 
standardize crossbows and other weaponry as early as the 4th 
century BC in China.1 However, it was the rapid improvement of 
manufacturing capabilities during the Industrial Revolutions of 
the 18th and 19th centuries that signaled the radical shift to 
mass production of identical goods. For the first time, the act of 
design became separated from the act of making. 
 
Driven by this change in technology, the field of Industrial Design 
emerged to specialize in the design of commercial products that 
appealed to a broad audience and could be manufactured at 
scale. In contrast to the craftsmen of the past, these designers 
were challenged with meeting the needs of a large population, 
balancing functionality, aesthetics, ergonomics, durability, cost, 
manufacturability, and marketability. 
 
The Industrial Designers Society of America (IDSA) describes 
Industrial Design as a professional service that optimizes 
“function, value, and appearance for the mutual benefit of both 
user and manufacturer.”2 It is the study of form and function, 
designing the relationship between objects, humans, and 
spaces. Most commonly, Industrial Designers work on smaller 
scale physical products, the kind you buy and use every day, 
                                                
1 Needham, Joseph. 1954. Science and Civilisation in China: Volume 1, Introductory 
Orientations. United Kingdom: Cambridge University Press. 
2 2015. What Is Industrial Design? Accessed January 22. 
http://www.idsa.org/education/what-is-id. 

rather than larger scale complex environments like buildings or 
ships. 
 
Whether you realize it or not, Industrial Design is all around you, 
supporting and shaping your everyday life. You are likely to 
recognize numerous examples cited throughout this book, 
perhaps from your childhood, your office, or even sitting next to 
you as you read this. The mobile phone you are fidgeting with, 
the clock on your wall, the coffee maker brewing in your kitchen, 
and the chair you are sitting on. Everything you see, touch, and 
are surrounded by was designed by someone, and thus 
influenced by Industrial Design. 
 
Throughout the 20th century, along with balancing the needs of 
the user and manufacturer, differences in politics and culture 
were evident in the design of objects. A rising consumer culture 
in the post-WWII period meant that manufactured goods doubled 
as a cultural proxy, intertwining national pride and economic 
reinvention. Along with regional differences, numerous 
philosophical and stylistic periods created distinct and 
recognizable eras within Industrial Design, including the 
Bauhaus school, Art Deco, Modernism, and Postmodernism. 
Design for Business 
 
On a more individual level, there are many famous Industrial 
Designers who have had an outsized influence on the history of 
the discipline. Raymond Loewy, a French-born American, is 
often referred to as the “Father of Industrial Design.”3 Loewy is 
widely considered to have revolutionized the field by pioneering 
the role of designer as consultant, working for a wide variety of 
industries and mediums.  
 
                                                
3 ‘Raymond Loewy’. 2015. The Official Site of Raymond Loewy. Accessed January 22. 
http://www.raymondloewy.com/. 

Loewy designed everything from streamlined pencil sharpeners, 
Coca-Cola vending machines, Studebaker automobiles, and 
NASA spacecraft interiors. He brought design into the 
mainstream business spotlight, gracing the cover of Time 
magazine in October of 1949, where they noted that he “made 
products irresistible at a time when nobody really wanted to pay 
for anything.”4 Loewy intertwined culture, capitalism, and style, 
establishing a template for how design and business could be 
mutually beneficial. 
Design for People 
 
Henry Dreyfuss is another famous American Industrial Designer 
whose work and influence from the mid-20th century are still felt 
today. Among his iconic designs are the Honeywell T87 
thermostat, the Big Ben alarm clock, the Western Electric 500 
desk telephone, and the Polaroid SX-70 camera.5 
 
Figure 1.x Henry Dreyfuss measurement image 
 
Dreyfuss was renowned not only for his attention to formal 
details, but his focus on the user’s needs. He founded the field of 
ergonomics and pioneered research into how human factors 
should be considered and incorporated into Industrial Design. 
After retiring, this focus on anthropometry and usability led him to 
author two seminal books: Designing for People in 1955 and The 
Measure of Man in 1960. His interest in universal accessibility 
extended to graphics as well, as evidenced by Symbol 
Sourcebook: An Authoritative Guide to International Graphic 
Symbols, in which Dreyfuss catalogs and promotes the use of 
internationally recognizable symbols over written words. 
                                                
4 ‘Google Doodle Honors Raymond Loewy, the “Father of Industrial Design”.’ 2015. 
TIME.com. Accessed January 22. http://newsfeed.time.com/2013/11/05/google-doodle-
honors-raymond-loewy-the-father-of-industrial-design/. 
5 ‘Henry Dreyfuss, FIDSA’. 2015. IDSA. Accessed January 22. 
http://www.idsa.org/content/henry-dreyfuss-fidsa. 

 
Dreyfuss felt that “well-designed, mass-produced goods 
constitute a new American art form and are responsible for the 
creation of a new American culture.”6 But he emphasized that 
good design was for everyone, that “these products of the 
applied arts are a part of everyday American living and working, 
not merely museum pieces to be seen on a Sunday afternoon.”7 
He promoted this approach through his own work, but also more 
broadly in his role as a founding member of the American 
Society of Industrial Design. In 1965 he became the first 
president of the IDSA. 
Design for Technology 
 
Along with the needs of business and users, the history of 
Industrial Design has been strongly shaped by the introduction of 
new technologies, which present an opportunity to redesign and 
improve products. Industrial Design has always been a conduit 
for innovation, translating the latest discoveries of science to 
meet the needs of everyday people. 
 
Figure 1.x Composite image of chairs highlighted in text below 
 
Take for an example the humble chair, a ubiquitous object that 
has become a laboratory for variation in form and materials. 
Figure 1.x shows four chairs, each highlighting a shift in the 
possibilities of material use and manufacturing capability.  
 
The No. 18 Thonet chair (1876), was an evolution of 
experimentation begun by Michael Thonet, with this variation 
released after his death in 1971.8 Thonet pioneered a new 
process of bending beech wood to reduce the number of parts 
involved, simplifying and strengthening the chair while increasing 
                                                
6 Dreyfuss, Henry. Designing for People. New York: Simon and Schuster, 1955. 82-83. 
7 Ibid. 
8 ‘History - Thonet’. 2015. Accessed January 22. http://www.thonet.com.au/history/. 

efficiency in shipping and assembly. The aesthetic was 
influenced by the technology, with generous curves honestly 
reflecting the bent wood process.  
 
The Eames Molded Fiberglass chair (1950) features a smooth 
and continuous organic form, unique in appearance and 
extremely comfortable. It was originally designed in stamped 
metal, which proved too costly and prone to rust. Instead, a new 
manufacturing technique was utilized that allowed fiberglass to 
cure at room temperature. A boat builder, who was familiar with 
fiberglass, helped build early prototypes to prove out the 
concept.9 
 
Jasper Morrison’s Air chair (1999) takes reduction of parts to the 
extreme, since it is constructed out of a single piece of injection-
molded polypropylene. Inert gas is pumped into the center of 
molten plastic, resulting in a solid, light, and economical product 
that comes off the assembly line fully formed. 
 
Konstantin Grcic’s Chair_One (2004) uses a die-cast aluminum 
process to achieve an original form that is at once full of voids, 
yet very solid; angular and sculptural at a glance, yet surprisingly 
more comfortable than it looks. Grcic says that “a bad chair is 
one that performs all the requirements, but remains just a chair. 
One that I use to sit on, but then I get up and it didn’t mean 
anything to me.”10 He believes that what makes good design is 
something hidden in the relationship you have with the object. 
Design for Context 
 
Of the chairs mentioned above, the fiberglass model by the 
husband and wife design team of Charles and Ray Eames 
                                                
9 ‘Molded Plastic Chairs | Eames Designs’. 2015. Accessed January 22. 
http://eamesdesigns.com/library-entry/molded-plastic-chairs/. 
10 NOWNESS’. 2015. Accessed January 22. https://www.nowness.com/series/on-
design/on-design-konstantin-grcic. 

deserves further attention. The Eames are known for their 
enduringly popular classic furniture designs, most of which are 
still being manufactured by Herman Miller. Their work often 
utilized new materials such as molded plywood, wire mesh, and 
the aforementioned fiberglass. 
 
The Eames Molded Fiberglass chair won second prize in the 
1949 International Low-Cost Furniture Competition, primarily for 
its innovative base that allows it to adapt to different uses and 
environments such as nursery, office, home, or school. This 
notion of adaptability to context is a theme that runs through 
much of Eames’ multidisciplinary work, which spanned products, 
photography, film, and architecture. 
 
Figure 1.x Powers of Ten image 
 
In 1977, Charles and Ray made Powers of Ten, a short 
documentary film that explores context by examining the effect of 
scale. The film begins at the level of human perception, with a 
couple having a picnic on the Chicago lakeshore, and then 
zooms out by consecutive factors of ten to reveal the entire 
universe before zooming inward to the scale of a single atom. 
The film has been influential in encouraging designers to 
consider adjacent levels of context — the details of how a design 
relates to the next level of scale, whether that’s a room or a body 
part. These details are often overlooked, but as Charles once 
explained, “The details are not the details, they make the 
product.”11 
Designing for Behavior 
 
Continuous evolution of manufacturing capabilities, business 
needs, human factors, materials, and contexts created a wide 
spectrum of ways in which Industrial Designers could express a 
                                                
11 ‘Designers Charles and Ray Eames - Herman Miller’. 2015. Accessed January 22. 
http://www.hermanmiller.com/designers/eames.html. 

particular product. However, it was the embedding of electronics 
into products that resulted in the most radical shift in both design 
possibilities and people's relationships with objects. For the first 
time, the potential behavior and functionality of a product was 
disconnected from its physical form. 
 
Consider the difference between a chair and a radio. Although 
chairs vary widely in form and materials, the way that a person 
uses them is largely self-evident, without instruction or confusion. 
With a radio, the functionality is more abstract. The shape of a 
knob may communicate its ability to turn, but not necessarily 
what it controls. 
 
A designer of electronic products uses a mix of different controls, 
displays, colors, and words to communicate the purpose of 
various components and provide clarity in how they work 
together. Done poorly, a user can be overwhelmed and confused 
by the possibilities and interrelationships, requiring them to read 
a manual before operating a product. 
 
Figure 1.x Dieter Rams image (TBD) 
 
German Industrial Designer Dieter Rams is a master at 
simplifying these complex electronic products to their essential 
form. Rams designed simple, iconic products for German 
household appliance company Braun for over 40 years, where 
he served as the Chief Design Officer until his retirement in 
1995. His understated approach and principle of “less but better” 
resulted in products with a timeless and universal nature. He was 
restrained in the amount of language used to label knobs and 
switches, relying on color and information graphics to 
communicate a product’s underlying behavior in an intuitive 
manner. 
 

In a similar spirit to this book, Dieter Rams has compiled a list of 
“Ten Principles of Good Design”12 that is rooted in his Industrial 
Design experience, but relevant to designers of any discipline. 
Our principles overlap with Rams’ choices, emphasizing those 
that best relate to UX and Interaction Design challenges. Much 
has been written about Rams’ ten principles, and we encourage 
you to review it as a jumping off point for further learning and 
inspiration.  
 
Rams’ has influenced many contemporary designers, and 
between 2008 and 2012 the Less and More retrospective of his 
work travelled around the world, showcasing over 200 examples 
of his landmark designs for Braun.13 During an interview with 
Gary Hustwit for his 2009 film Objectified, Dieter Rams said that 
Apple is one of the few companies today that consistently 
creates products in accordance with his principles of good 
design. 
 
Figure 1.x Apple / Jonathan Ive example (TBD) 
 
It’s no surprise that Jonathan Ive, Apple’s Senior Vice President 
of Design, is a fan of Rams’ work and ethos. Since joining Apple 
in the early 1990s, the British industrial designer has overseen 
the launch of radical new product lines with unique and 
groundbreaking designs, including the iMac, iPod, and iPhone. 
Regarding these disruptive innovations, he emphasizes that 
being different does not equate to being better. In reference to 
the first iMac design, Ive has said that "the goal wasn't to look 
different, but to build the best integrated consumer computer we 
                                                
12 ‘Dieter Rams: Ten Principles for Good Design’. 2015. Vitsoe. Accessed January 22. 
https://www.vitsoe.com/gb/about/good-design. 
13 ‘Less and More: The Design Ethos of Dieter Rams’. 2015. SFMOMA. Accessed 
January 22. http://www.sfmoma.org/exhib_events/exhibitions/434. 

could. If as a consequence the shape is different, then that's how 
it is."14 
 
Ive’s approach seems to echo and build upon Rams’ motto of 
“less but better,” although the products that Apple makes are 
significantly more complex than the ones that Rams’ designed 
for Braun. The physical enclosure and input controls of a 
computing device are similar to legacy electronics, but the 
mutable functionality of software on a screen is its own world of 
complexity. The introduction of the personal computer 
significantly widened the separation of form and function. 
 
In 2012, Ive was knighted by Queen Elizabeth for his landmark 
achievements. In the same year Sir Jonathan Ive’s role at Apple 
expanded, from leading Industrial Design to providing direction 
for all Human Interface design across the company.15 This 
consolidation of design leadership across physical and digital 
products speaks to the increasing overlap between these two 
mediums. The best user experience relies on a harmonious 
integration of hardware and software, an ongoing challenge 
throughout the history of computing. 
Computing Revolution 
 
Interaction with the first personal computers was entirely text-
based. Users typed commands and the computer displayed the 
result, acting as little more than an advanced calculator. 
Computers had shrunk in size, but this direct input and output 
echoed the older mainframe technology. Even the common 
screen width of 80 characters per line was a reference to the 
                                                
14 Kahney, Leander. 2013. Jony Ive: The Genius Behind Apple’s Greatest Products. 
United States: Penguin Putnam Inc. 
15 ‘Apple Announces Changes to Increase Collaboration Across Hardware, Software & 
Services’. 2015. Apple Inc. Accessed January 22. 
https://www.apple.com/pr/library/2012/10/29Apple-Announces-Changes-to-Increase-
Collaboration-Across-Hardware-Software-Services.html. 

number of holes in a punch card. In the relationship between 
people and technology, these early computers favored the 
machine, prioritizing efficient use of the small amount of 
available processing power. 
 
This early personal computing era can be likened to the time 
before the Industrial Revolution, with digital craftsmen making 
machines primarily for themselves or their friends. These 
computers were the domain of hobbyists, built from kits or 
custom assembled by enthusiasts who shared their knowledge in 
local computer clubs. 
 
In 1968, at the Fall Joint Computer Conference in San Francisco, 
Douglas Engelbart held what became known as “The Mother of 
All Demos,” in which he introduced the oN-Line System, or NLS. 
This 90-minute demonstration was a shockingly prescient display 
of computing innovation, introducing for the first time modern 
staples such as realtime manipulation of a graphical user 
interface, hypertext, and the computer mouse. 
 
Early computing pioneer David Liddle talks about the three 
stages of technology adoption: enthusiasts, professionals, and 
consumers. It was the introduction of the graphical user 
interface, or GUI, that allowed the personal computer to begin its 
advancement through these phases.  
 
The GUI was the key catalyst in bringing design to software. 
Even in its earliest incarnations, it signaled what computers 
could be if they prioritized people, increasing usability and 
accessibility despite the incredible amount of processing power 
required. But making software visual did not automatically make 
computers usable by ordinary people. That would require 
designers to focus their efforts on the world behind the screen. 
 
In his book Designing Interactions, IDEO co-founder Bill 
Moggridge relates a story about designing the first laptop 

computer, the GRiD Compass, in 1979.16 The industrial design of 
the Compass had numerous innovations, including the first 
clamshell keyboard cover. It ran a custom operating system 
called GRiD-OS, which featured an early graphical user 
interface, but with no pointing device. Using this GUI prompted 
him to realize for the first time that his role as a designer 
shouldn’t stop at the physical form, but include the experiences 
that people have with software as well. 
 
Years later, Bill Moggridge, along with Bill Verplank, would coin 
the term “Interaction Design” as a way of distinguishing 
designers who focus on digital and interactive experiences from 
traditional Industrial Design.  
 
Pioneering computer scientist and HCI researcher Terry 
Winograd has said that he thinks “Interaction Design overlaps 
with [Industrial Design], because they both take a very strong 
user-oriented view. Both are concerned with finding a user 
group, understanding their needs, then using that understanding 
to come up with new ideas.”17 Today we take for granted this 
approach of designing software by focusing on people, but in 
Silicon Valley of the 1980s the seeds of human-centered 
computing were only just being planted. 
The Bifurcation of Physical and Digital 
 
In the 1970’s, influenced by Douglas Engelbart’s NLS 
demonstration, numerous research projects at Xerox PARC 
explored similar topics. The Xerox Star, released in 1981, was 
the first commercially available computer with a GUI that utilized 
the now familiar desktop metaphor. This structure of a virtual 
office correlated well with the transition that computing was 
attempting to make from enthusiasts to professional users. 
                                                
16 Moggridge, Bill. Designing Interactions. Cambridge, Mass.: MIT, 2007. 
17 Preece, Jenny, Yvonne Rogers, and Helen Sharp. Interaction Design: Beyond Human-
computer Interaction. New York, NY: J. Wiley & Sons, 2002. 

 
The graphical desktop of the Star featured windows, folders, and 
icons, along with a “What You See Is What You Get” 
(WYSIWYG) approach that allowed users to visually see and 
manipulate text and images in a manner that represented how 
they would be printed. These features, amongst others, were a 
direct influence on both Apple and Windows as they developed 
their own GUI-based operating systems. 
 
In 1983 Apple released the Lisa, their first computer to utilize a 
GUI. A year later they launched the Mac, which became the first 
GUI-based computer to gain wide commercial success. Microsoft 
debuted Windows 1.0 in 1985 as a GUI overlay on its DOS 
operating system, but adoption was slow until 1990 with the 
release of the much-improved Windows 3.0. 
 
Although their operating systems had many similarities, the 
business models of Apple and Microsoft could not have been 
more different. Apple was a product company, and made money 
by selling computers as complete packages of hardware and 
software. Microsoft made no hardware at all. Instead, they 
licensed Windows to run on compatible computers made by 
third-party hardware manufacturers that competed on both 
features and price. 
 
As businesses embraced computers in every office they 
overwhelmingly chose Windows as a more cost effective and 
flexible option than the Mac. This majority market share in turn 
created an incentive for software developers to write programs 
for Windows. Bill Gates had found a way to create a business 
model for software that was completely disconnected from the 
hardware it ran on. In the mid-1990s even Apple briefly 
succumbed to pressure and licensed their Mac OS to officially 
run on Macintosh “clones.” 
 

The potential for design integration that Bill Moggridge had seen 
between hardware and software was difficult within this business 
reality. The platform approach of the Windows operating system 
had bifurcated the physical and digital parts of the personal 
computer. Companies tended to focus on hardware or software 
exclusively, and designers could make few assumptions about 
how they were combined by end users. 
 
Although the GUI used a spatial metaphor, the variety of monitor 
sizes and resolutions made it difficult to know how the on-screen 
graphics would be physically represented. The mouse and the 
standard 102-key keyboard acted as a generic duo of input 
devices, dependable but limited. Software emerged as a distinct 
and autonomous market, which contributed to the largely 
separate evolution of Interaction and Industrial Design. 
 
As software took on new and varied tasks, Interaction Designers 
sought inspiration and expertise not only from traditional design 
fields but from psychology, sociology, communication, and 
computer science. Meanwhile, Industrial Designers continued to 
focus primarily on the physical enclosures of computers and 
input devices. After all, computing was only one of the full range 
of industries within Industrial Design’s purview. 
Information Revolution 
 
In 1982 the Association for Computing Machinery (ACM) 
recognized the growing need to consider users in the design of 
software by creating the Special Interest Group on Computer–
Human Interaction (SIGCHI). Shortly after, the field of Human-
Computer Interaction (HCI) emerged as a recognized sub-
discipline of computer science. 
 
Because designing how people use digital systems was so new, 
and because the task required integrating so many fields of 
knowledge, it became a vibrant research area within multiple 

fields of study (psychology, cognitive science, architecture, 
library science, etc.).  
However, at the end of the day, making software always required 
the skills of a software engineer. That changed in 1993 with the 
launch of the Mosaic web browser, which brought to life Tim 
Berners-Lee’s vision for the World Wide Web. 
 
The web was an entirely new medium, designed from the ground 
up around networks and virtuality. It presented a clean slate of 
possibility, open to new forms of interaction, new interface 
metaphors, and new possibilities for interactive visual 
expression. More importantly, it was accessible to anyone who 
wanted to create their own corner of the web, using nothing more 
than the simple HyperText Markup Language (HTML). 
 
From the beginning, web browsers always came with a “View 
Source” capability that allowed anyone to see how a page was 
constructed. This openness, combined with the low-learning 
curve of HTML, meant a flood of new people with no background 
in computer science or design began shaping how we interact 
with the web. 
 
The web hastened the information revolution and accelerated the 
idea that “information wants to be free.” Free to share, free to 
copy, and free of physicality. Microsoft Windows had distanced 
software from the machine it ran on, but the web pushed 
interactive environments into an entirely virtual realm. A website 
could be accessed from any computer, regardless of size, type, 
or brand. 
 
By the mid-1990s Wired Magazine described web users as 
Netizens, socializing in virtual reality was an aspiration, and 
there was growing excitement that e-commerce could replace 
brick-and-mortar stores. The narrative of progress in the late 
20th century was tied to this triumph of the virtual over the 
physical. The future of communication, culture, and economics 

increasingly looked like it would play out in front of a keyboard, in 
the world on the other side of the screen. 
 
Standing on the shoulders of previous pioneers, the flood of 
designers native to the web used the very medium they were 
building to define new interaction patterns and best practices.  
The web had brought about the consumer phase of computing, 
expanding the scope and influence of Interaction Design to a 
level approaching its older, Industrial cousin. 
Smartphones 
 
Early mobile phones had limited functionality, primarily centered 
on making voice calls and sending SMS messages. The 
introduction of the Wireless Application Protocol (WAP) brought 
a primitive browser to phones so they could access limited 
information services like stocks, sports scores, and news 
headlines. But WAP was not a full web experience, and its 
limited capabilities, combined with additional usage charges, led 
to low adoption. 
 
Even as mobile phones began accumulating additional features 
such as color screens and high-quality ringtones, their software 
interactions remained primitive. One contributing factor was the 
restrictive environment imposed by the carriers. The dominant 
wireless networks (AT&T, Sprint, T-Mobile, and Verizon) didn’t 
make the operating systems that powered their phones, but they 
controlled how they were configured and dictated what software 
was pre-installed. 
 
Decisions about which applications to include were often tied to 
business deals and marketing packages, not consumer need or 
desire. The limited capabilities and difficult installation process 
for third-party apps meant that they were not widely used. This 
restrictive environment was the opposite of the openness on the 

web, a discrepancy that was strikingly clear by 2007 when Apple 
launched the iPhone and disrupted the mobile phone market. 
 
Just as Microsoft’s Windows OS created a platform for desktop 
software to evolve, it was Apple’s turn to wield a new business 
model that would dramatically shift the landscape of software 
and interaction. 
 
Although the original iPhone was restricted to the AT&T network, 
the design of the hardware and software was entirely controlled 
by Apple. This freedom from the shackles of the carrier’s 
business decisions gave the iPhone an unprecedented 
openness.  
 
For the original release, that openness was focused on the web. 
Mobile Safari was the first web browser on a phone to render the 
full web, not a limited WAP experience. A year later, an update 
to iOS allowed third-party applications to be installed. This was 
the beginning of yet another new era for Interaction Design, as 
the focus shifted not only to a mobile context but to the 
reintroduction of physicality as an important constraint and 
design opportunity. 
 
The interaction paradigm on the iPhone, and the wave of 
smartphones that have since emerged, uses direct touch 
manipulation to select, swipe, and pinch as you navigate 
between and within apps. Touchscreens had existed for 
decades, but this mass standardization on one particular screen 
size awoke Interaction Designers to consider the physical world 
in a way that desktop software and the web never did. 
Respecting the physical dimensions of the screen became 
critically important to ensure that on-screen elements were large 
enough for the range of hands that would interact with them. 
 
Knowing the physical dimensions of the touchscreen also led to 
new opportunities, allowing designers to craft pixel-perfect 

interface layouts with confidence in how they would be displayed 
to the end user. This ability to map screen graphics to physical 
dimensions was concurrent with the rise of a new graphical 
interface style that directly mimicked the physical world. This 
visual style, often called skeuomorphism, presents software 
interfaces as a mimic of physical objects, using simulated 
textures and shadow to invoke rich materials such as leather and 
metal. 
 
Although often heavy-handed and occasionally in bad taste, 
these graphical references to physical objects, combined with 
direct touch manipulation, reduced the learning curve for this 
new platform. Katherine Hayles, in her book How We Became 
Posthuman describes skeuomorphs as "threshold devices, 
smoothing the transition between one conceptual constellation 
and another.”18 The skeuomorphic user interface helped 
smartphones become the most rapidly adopted new computing 
platform ever.19 
 
Today, skeuomorphic interface styles have fallen out of favor. 
One reason is that we no longer need their strong metaphors to 
understand how touchscreens work; we have become 
comfortable with the medium. Another factor is that touchscreen 
devices now come in such a wide variety of sizes that designers 
can no longer rely on their design rendering with the kind of 
physical exactness that the early years of the iPhone afforded. 
 
The iPhone was also a bellwether of change for Industrial 
Design. Smartphones are convergence devices, embedding 
disparate functions that render a variety of single-purpose 
devices redundant. Examples of separate, physical devices that 
                                                
18 Hayles, Katherine. How We Became Posthuman: Virtual Bodies in Cybernetics, 
Literature, and Informatics. Chicago, IL: University of Chicago Press, 1999. 17. 
19 DeGusta, Michael. "Are Smart Phones Spreading Faster than Any Technology in 
Human History?" Accessed January 20, 2015. 
http://www.technologyreview.com/news/427787/are-smart-phones-spreading-faster-than-
any-technology-in-human-history/. 

are commonly replaced with apps include the calculator, alarm 
clock, audio recorder, and camera. Products that traditionally 
relied on Industrial Designers to provide a unique physical form 
were being dematerialized, a phenomena that investor Marc 
Andreessen refers to as “software eating the world.”20 
 
At the same time, the physical form of the smartphone was very 
neutral, designed to disappear as much as possible, with a 
fullscreen app providing the device’s momentary purpose and 
identity. This was a shift from the earlier mobile phones, where 
the carriers differentiated their models primarily through physical 
innovation such as the way a phone flipped open or slid out to 
reveal the keypad. 
 
Even as Interaction Designers introduced physical constraints 
and metaphors into their work, Industrial Designers saw their 
expertise underutilized. The rise of the smartphone made 
inventor and entrepreneur Benny Landa’s prediction that 
“everything that can become digital, will become digital” seem 
truer than ever. For Industrial Design, which throughout the 20th 
century had always defined the latest product innovations, this 
was a moment of potential identity crisis. 
Smart Everything 
 
The general purpose smartphone continues to thrive, but today 
these convergence devices are being complemented by an array 
of single-use “smart” devices. Sometimes referred to as the 
Internet of Things, these devices use embedded sensors and 
network connectivity to enhance and profoundly change our 
interactions with the physical world. 
 
This introduces design challenges and possibilities well beyond a 
new screen size. Smart devices can augment our natural 
                                                
20 "The Man Who Makes the Future: Wired Icon Marc Andreessen | WIRED." Wired.com. 
Accessed December 17, 2014. http://www.wired.com/2012/04/ff_andreessen/5/. 

interactions that are already happening in the world, recording 
them as data or interpreting them as input and taking action. For 
example: 
 
● The Fitbit activity tracker is worn on your wrist, turning 
every step into data.  
● The Nest Protect lets you wave away a smoke alarm 
caused by a faulty detection, like when it’s accidently set 
off while cooking. 
● The August Smart Lock senses your approach and 
automatically unlocks the door.  
● The Apple Watch lets you pay for goods by simply raising 
your wrist to a checkout reader. 
 
The smartphone required designers to consider the physicality of 
users in terms of their fingertips. These new connected devices 
require a broader consideration of a person’s full body and 
presence in space. 
 
Over the last few decades, opinions have oscillated on the 
superiority of general purpose technology platforms versus self-
contained “information appliances.” Today’s “smart devices” 
represent a middle ground, since these highly specialized 
objects often work in conjunction with a smartphone or web 
server that provides access to configuration, information display, 
and remote interactions.  
 
Open APIs allow devices to connect to and affect each other, 
using output from one as the input to another. Services such as 
IFTTT (IF This Then That) make automating tasks between 
connected devices trivial. For example, one IFTTT recipe turns 
on a Philips Hue light bulb in the morning when your Jawbone 
UP wristband detects that you have woken up. 
 
Unfortunately, seamless experiences between connected 
devices are rare and too often the smartphone is treated as the 

primary point of interaction. This makes sense when you want to 
change your home’s temperature while at the office, or check the 
status of your garage door while on vacation. But if adjusting 
your bedroom lighting requires opening an app, it certainly 
doesn't deserve the label “smart.” 
 
We find ourselves in yet another transitional technology period, 
where physical and digital blur together in compelling but 
incomplete ways. There is potential for connected devices to 
enhance our lives, giving us greater control, flexibility, and 
security in our interactions with everyday objects and 
environments. There is promise that we can seamlessly combine 
our digital and physical lives, reducing the need for constant 
engagement with a glowing screen in favor of more ambient and 
natural interactions within our surroundings. But there is also a 
danger that connecting all of our things simply amplifies and 
extends the complexity, frustration, and security concerns of the 
digital world. 
 
The technical hurdles for the Internet of Things are being rapidly 
overturned. The primary challenge today lies in designing a great 
user experience. 
Industrial Design Principles for UX and 
Interaction Design 
 
Connected devices represent a new era for both Industrial and 
Interaction Design. Because this new paradigm intertwines 
physical and digital, designing a good experience will require the 
two disciplines to overlap like never before. Industrial Designers 
will need new sensitivities towards complex system states, 
remote interactions, privacy considerations, and the open-ended 
potential of how input can map to output. Interaction Designers 
will need to embrace physical and spatial possibilities, consider a 
person’s whole body, and use new forms of feedback less reliant 
on a screen. 

 
In the past, we could often draw a clean line between hardware 
and software. As that line blurs, both Industrial and Interaction 
Design will need to combine their expertise. In the 1990s the 
emergence of the web led designers to develop new interaction 
patterns for an entirely new medium. A similar definition of best 
practices for connected devices will need to occur, but this time 
the process can be more integrative, drawing from knowledge 
embedded in both disciplines. The principles that have informed 
and defined Industrial Design for the last century are a good 
starting point for Interaction Designers to find new ways of 
approaching, framing, and evaluating their work.  
 
The ten principles in this book represent ways that Industrial 
Designers have approached design problems across a diverse 
array of industries and eras. Each principle is explained and 
situated within Industrial Design history, and then reframed for a 
modern Interaction Design context. The chapters can be read in 
any order, so you can return to and review relevant principles 
when starting a new project. 
 
The goal is not that Interaction Designers should all become 
Industrial Designers, or vise versa, but that these two design 
disciplines should find an overlap of skills and approaches 
appropriate to a world where the traditional distinctions between 
physical and virtual are increasingly blurred. 
 
 

Chapter 2 
Sensorial 
Engage as many senses as possible 
 
We connect with the world around us through our senses, and 
describe the process of understanding something new as 
“making sense of it.” The pervasiveness of sensing makes it 
easy to take for granted, as we integrate our five common 
senses of touch, hearing, sight, smell, and taste without 
conscious thought or effort. Similarly, as designers create 
objects and interactions, it can be easy for them to overlook the 
richness of human sensorial capabilities. By primarily 
considering the unavoidable senses of sight and touch, many 
designers seem to treat humans as little more than eyeballs and 
fingers. 
 
Industrial Designers, because of the physicality of their work, 
have historically been able to engage a broader range of senses 
than Interaction Designers. We obviously see and touch objects, 
but we also hear something when we place an object on a 
surface, or even smell certain materials when we hold them 
closely. We generally don’t eat our objects, but increasingly 
designers are collaborating with chefs and food companies to 
support the smell and taste of our eating experiences. 
 
Beyond the traditional five senses, we perceive our presence in 
the physical world through non-traditional and combinatorial 
senses as well. We have a sense of balance that helps us walk 
and carry objects, a sense of pain that keeps us from over 
damaging our body, and a sense of temperature that is finely 
tuned to our human tolerances. Our kinesthetic sense tells us the 
position of our body parts relative to each other, and helps us 
detect weight and tension when we grasp and hold an object. 
 

All of these senses are commonly used with intention by 
Industrial Designers. The weight of a fountain pen, the balance 
of a snow shovel, the smell of a leather wallet, and the warm 
welcome of a heated car seat are all purposefully designed. In 
this chapter, we will demonstrate how sensoriality is central to 
Industrial Design by looking at the core foundations of the 
discipline such as formgiving, color, materials, and finish. We’ll 
look at products that transition between multiple states, where 
engaging the senses through action feels good enough to be 
addictive. We’ll look at ways that products can delight us through 
sensorial reaction to our input, and how designers may even 
influence the smell and taste of food. 
 
As digital systems escape the screen, the sensorial methods that 
Interaction Designers can utilize for both input and output will 
expand. Engaging this full range of human senses, in ways both 
obvious and subtle, is one of the most important things that 
Interaction Designers and UX professionals can learn from 
Industrial Design. 
 
Formgiving 
 
Fundamental to Industrial Design is idea of formgiving, the 
process of determining the best shape, proportion, and physical 
architecture for a three-dimensional object. This additional 
dimension, beyond the flat 2D world of a screen, presents a 
multitude of new challenges and sensorial possibilities. This is 
why Industrial Designers often start sketching physically first, 
shaving foam or wood with their hands to craft the basic depth, 
dimensionality, and proportions of an object before modeling it 
on a computer. Should an object be thick and narrow, or thin and 
wide? Feeling the difference in your hand is often the only way to 
know. 
 

In giving an object form, a designer is trying to both meet a 
human need and create a product with character, something that 
is unique, differentiated, and better in the marketplace. As the 
form evolves through the design process it must be evaluated 
holistically, seeing how each change affects the front, back, and 
sides from every angle. Additional constraints might be informed 
by the way an object will be held, or what function it performs. 
Certain challenges, such as accommodating bulky embedded 
electronics, might be addressed by prioritizing particular viewing 
angles, creating the illusion of an object being thicker or thinner 
when viewed from particular sightlines. A good example of this is 
the wedged-shaped side profile of the MacBook Air. 
 
On-screen elements in a user interface tend to default to 
rectangular shapes: windows, buttons, bars, and lists. Obviously, 
it is possible to make interfaces with other shapes, but the very 
idea that there is a default can influence and limit Interaction 
Designers. Even if less conventional shapes are used within an 
interface they are framed within a larger system of rectangles 
that a designer has little control over, not least of which is the 
screen itself. While some physical objects are part of a branded 
family, most are standalone forms that free Industrial Designers 
to consider a much wider range of shapes. This allows shape to 
become a defining personality for an object, whether round, 
square, sharp, soft, or organic. A product’s shape is the first 
thing you see. 
 
Rarely is a product constructed from a single shape, so 
formgiving usually includes a process of composition as well, 
shaping various individual elements and then arranging them 
into a greater form. Consider a simple FM radio with a frequency 
dial, volume knob, screen, and speaker grill. The overall shape 
of the radio may be a starting point, but the form is not complete 
until all of the elements are composed in relationship to the 
whole. 
 

Similar to composition, the way that elements connect to each 
other is a key consideration in more complex formgiving. The 
joint on a chair, the hinge on a laptop, the clamshell or slider on 
a mobile phone. For products with moving parts, these 
connections and architectures are fundamental to the overall 
form and act as a bridge between multiple states of the product. 
A laptop can be open or closed, and both of those states should 
feel related and work together. 
Color, Materials, Finish (CMF) 
 
Along with formgiving, Industrial Designers craft sensorial 
experiences by utilizing the building blocks of color, materials, 
and finish, or CMF. Combining these three in an acronym makes 
sense since they are often chosen and used in combination with 
each other to create a perception of quality, indicate affordances 
for use, and communicate brand identity.  
 
All three elements involve consideration for the sense of vision, 
but materials and finishes provide designers with the additional 
opportunity to purposefully engage the sense of touch. Should 
an object feel hard or soft when you touch it? Should it be cold or 
warm against your skin? Should it be glossy or matte? Light or 
heavy? These are all carefully considered and often combined to 
create a desired product experience. 
 
The unique properties of a material can be the catalyst for a 
design idea, even before explorations of formgiving have begun. 
However, this inspiration requires that designers have physical 
access to new materials so they can feel and experiment with 
them. In 1999, IDEO started their Tech Box project,1 which 
collects examples of interesting materials and mechanisms from 
a range of products and industries and distributes them to all the 
company’s offices. Designers can rummage through the 
                                                
1 "Tech Box." IDEO. Accessed January 25, 2015. http://www.ideo.com/work/tech-box/. 

collection for inspiration when starting a new project. This kind of 
reference library is an important tool in allowing materials to 
spark new design ideas. 
 
Like formgiving, CMF is a balancing act between the desired 
sensorial experience, feasibility of manufacturing at scale, and 
overall cost of the product. To achieve that balance, designers 
must maximize the impact of every CMF choice. An example of a 
company that has made the most from simple materials and 
color is Fiskars, whose classic orange-handled scissors have 
sold more than 1 billion units since their introduction in 1967. 
 
Figure 2.x: Fiskars “Classic” orange-handled scissors 
 
Fiskars has been making scissors since the 1830s,2 originally for 
professional use, with wrought iron handles that matched the 
material of the blades, and later with brass to increase comfort. 
In the 1960s, new manufacturing capabilities made it possible to 
create scissors with ground metal blades that could outperform 
their forged counterparts. These lightweight blades were paired 
with another mid-century innovation, the molded plastic handle. 
The combination of these two materials allowed Fiskars to offer 
higher quality, more comfortable scissors at a price that was 
affordable to everyone, not just tailors and seamstresses. 
 
The recognizable orange color of the scissor’s handle has a 
serendipitous origin story. At the time that the first plastic-
handled scissor prototypes were made, Fiskars also had a line of 
juicers in production. The injection molding machine had leftover 
orange dye in it, so the initial handles were produced in orange. 
Other colors were tried as well, including red, green, and black, 
but orange was selected by the Fiskars board in a final vote of 9 
to 7. That decision has had a profound influence on the 
company. 
                                                
2 Kulvik, Barbro, and Antti Siltavuori. The DNA of a Design: 40 Years, 1967-2007. 
Helskinki: Fiskars, 2007. 

 
Today, the Fiskars Orange® color is an essential part of the 
company’s brand. It was registered as a trademark in the USA in 
2007, following its Finish trademark in 2003.3 The color has 
successfully extended beyond the scissor line to other Fiskars 
products, making their garden tools and crafting supplies 
instantly recognizable, even at a distance. In recognition of their 
simple appeal and design legacy the Classic orange-handled 
scissors are part of the permanent collection of the Museum of 
Modern Art (MoMA) in New York.4 
 
Another company whose innovative handle design can be found 
in the MoMA collection is OXO,5 whose soft rubber grips with 
ribbed finishes transformed the commodity utensil category and 
launched an entire product portfolio built around the sense of 
touch. 
 
Figure 2.x: OXO Good Grips Peeler 
 
The origin story of OXO comes not from the introduction of new 
manufacturing capabilities like Fiskars, but with observation of an 
unmet need in the marketplace. Founder Sam Farber, who was 
ostensibly retired from a career in the kitchenware business, was 
inspired by seeing his wife Betsy struggle when using a standard 
metal vegetable peeler. Betsy was suffering from arthritis in her 
hands, and the design of the all-metal implement was optimized 
not for comfort or support, but to be manufactured as cheaply 
and easily as possible. 
 
                                                
3 "Orange-Handled Scissors: Superior Cutting Since 1967." Fiskars. Accessed January 
25, 2015. http://www2.fiskars.com/content/download/22952/394664/file/OHS 
Backgrounder.pdf. 
4 "Olof Backstrom. Scissors (1960)." MoMA.org. Accessed January 25, 2015. 
http://www.moma.org/collection/object.php?object_id=3250. 
5 "Smart Design, New York. Good Grips Peeler (1989)." MoMA.org. Accessed January 
25, 2015. http://www.moma.org/collection/object.php?object_id=3758. 

Farber worked with Smart Design in New York to make a better 
handle based on the principles of Universal Design, a philosophy 
that prioritizes designing for the broadest group of people 
possible, including those with special or marginalized needs.6 
Smart Design prototyped forms that would be easy to hold, 
regardless of hand size, and explored materials that would 
support varying levels of physical capability. 
 
The final design is a handle made of a soft rubber called 
Santoprene,7 in an oval shape that evenly distributes the user’s 
force during use. The non-slip material provides comfort and 
grip, even when wet, while withstanding exposure to kitchen oils 
and dishwashers. On the sides, small ribs or “fins” are cut into 
the rubber, providing an affordance for where to hold. These 
tactile elements make the OXO brand recognizable at first touch, 
even without looking. 
 
The Good Grips handle design has been applied to 100s of 
products since its introduction 1990. But unlike Fiskars, which 
used materials innovation to reduce the cost of the scissors, 
OXO products are often more expensive than their traditional 
counterparts.8 It’s a compelling demonstration that people are 
willing to pay for good design, and that taking a Universal Design 
approach can lead to products with broad appeal. 
 
The stories of both Fiskars and OXO show how simple and 
disciplined use of colors, materials, and finishes can define a 
brand that extends across an entire product line. This might 
remind Interaction Designers of the consistency that permeates 
an operating system, where signature elements such as menu 
bars or drop-down lists are presented in a consistent manner so 
                                                
6 "About OXO." About Us. Accessed January 25, 2015. 
http://www.oxo.com/AboutOXO.aspx. 
7 "FAQs." OXO. Accessed January 25, 2015. http://www.oxouk.com/faq.aspx. 
8 "Identifying New Ideas for Breakthrough Products." Accessed January 25, 2015. 
http://www.ftpress.com/articles/article.aspx?p=24132&seqNum=4. 

that users know immediately what to expect and how to perform 
similar actions. 
 
Beyond consistency though, it is often the CMF of a product that 
draws us to it. As objects become increasingly connected and 
computational, it's important not to lose these positive, tactile 
qualities that makes us want to have them in our lives. For 
example, instead of a raw LED providing feedback, a light might 
be placed under a frosted glass surface. Or, instead of a 
touchscreen for input, sensors might be placed under a thin 
veneer of wood. This is not about hiding technology, but finding 
ways to integrate it with the same rigor that goes into all CMF 
selections. 
Multi-sensorial and Luxury Products 
 
Straightforward use of color or a single material can be an 
innovative advancement for simple tools, but just as most digital 
products require multiple interconnected states to result in a 
good experience, a more complex physical product requires 
bringing together a mix of sensorial moments. By engaging 
multiple senses, at every scale and detail, the overall experience 
can transcend its parts. 
 
Figure 2.x: Leica Camera 
 
“Shooting with a Leica is like a long tender kiss, like firing an 
automatic pistol, like an hour on the analyst's couch.” —Henri 
Cartier-Bresson 
 
Cameras can inspire intense loyalty from photographers based 
not only on how they perform, but also how they feel. A good 
camera becomes an extension of the photographer's sense of 
vision, capturing what they see with minimal interruption. Few 
brands have spawned as much obsession amongst 
photographers as the German manufacturer Leica. 

 
Leica has been making cameras since the mid-1800s, and even 
though today’s models are digital, they feature tactile, analog 
controls similar to the earliest models. This decision is driven by 
more than nostalgia, since familiar physical controls allow a 
photographer to keep their eye looking through the viewfinder 
while they adjust the dials for shutter speed, aperture, and focus. 
Unlike selecting on-screen menu items, twisting an aperture 
control can be done without looking, and the reassuring click of 
each demarcation on the dial can be felt and heard. 
 
A Leica is a triumph of engineering, but also of form and finish, 
the feel of each dial and marking on the camera body building 
muscle memory through use, avoiding a fumble that could lead 
to a missed shot. It’s the integration of these tiny details, along 
with the build quality and craftsmanship that fosters such passion 
and commands a premium price. 
 
Leica craftsmanship is celebrated to the point of fetish. For 
example, the Leica T camera body is machined out of a solid 
block of aluminum.9 The marketing materials for the camera 
boast that the body is hand polished, and a video ad10 released 
on their website showcases the entire 45 minute process in 
closely cropped shots of gloved hands at work. The ad’s 
voiceover boasts that it takes “around 4,700 strokes to finish 
each body,” asking the viewer in the end if they can see the 
difference, and reassuring them that “you can most certainly feel 
it.” 
 
                                                
9 "Leica T Camera System." Accessed January 25, 2015. http://us.leica-
camera.com/Photography/Leica-T/Leica-T-Camera-System. 
10 "The Most Boring Ad Ever Made?" Vimeo. Accessed January 25, 2015. 
http://vimeo.com/92073118. 

The Leica M9-P, Edition Hermès11 is an example of how detailed 
finishes and subtle sensorial experiences can elevate a product 
to the level of luxury. In collaboration with the eponymous 
Parisian fashion house, this limited edition camera is wrapped in 
a soft, ochre-colored calfskin leather. The metal body 
underneath was redesigned for this special edition by the 
automotive designer Walter de’Silva, and the exposed portions 
of the metal are even smoother than the well polished standard 
edition. The contrast of materials heightens the user’s 
awareness of each as their fingers shift from holding the warm, 
soft, natural leather to adjusting the cold, hard aluminum 
controls. 
 
The sensorial experience extends beyond the camera itself 
though, with a strap made of matching calfskin, an Hermes 
designed camera bag, and a two-volume book of photographs 
from Jean-Louis Dumas, shot with a Leica M. These items are 
packaged alongside the camera lenses, in a fabric-coated 
custom display box that includes a set of white gloves, further 
emphasizing the museum-like quality of the overall package. All 
of this can be yours for only $25,000 or $50,000, depending on 
which limited edition package you choose. 
 
As we’ve seen, there are examples of CMF choices that can 
make a product more affordable, or push it well out of reach for 
all but the most wealthy. The more senses that a product 
engages, through high-quality materials or finishes, the more 
luxurious it can appear.  
 
Lightweight scissors that still cut well are desirable, but a 
lightweight luxury item might appear “cheap.” Even with the use 
of aluminum bodies, Leica cameras are known for their 
significant heft. It’s well documented that people perceive weight 
                                                
11 "Leica Creates M9-P Hermès 18MP Rangefinder Special Editions." DPRreview. 
Accessed January 25, 2015. http://www.dpreview.com/articles/5424047475/leica-creates-
m9-hermes-edition-18mp-full-frame-rangefinder-camera. 

as a signifier of quality. One of the studies documenting this 
phenomena can be found in 2009 issue of the journal 
Psychological Science,12 where researchers published a paper 
entitled “Weight as an Embodiment of Importance.” In their 
study, they found that varying the weight of a clipboard used by 
participants altered their behavior and influenced their opinions. 
Designers wishing to capitalize on this kind of psychological 
influence can make the appropriate materials decisions, though 
care should be taken that these choices are still authentic to the 
purpose of the product. This topic is explored in more depth 
within the Honesty chapter. 
 
On top of high-quality design, scarcity is often utilized to further 
differentiate a standard and luxurious product. This invocation of 
luxury is something that has traditionally been very difficult for 
Interaction Designers to achieve. After all, what is a luxurious 
interaction? For purely digital products, the ability to create 
unlimited copies of digital resources makes scarcity too artificial 
to resonate as luxurious. Offering a limited edition with an 
improved user experience also comes off as more unfair than 
special. Digital experiences seem to be evaluated through a 
more egalitarian lens.  
 
However, for the increasing number of products that integrate 
digital and physical, there are many untapped opportunities to 
explore and define luxurious interactions. For all of its fine 
materials and finishes the Leica M9-P, Edition Hermès uses the 
same firmware, on-screen graphics, and interactions on its digital 
screen as the less luxurious standard edition. How might the on-
screen interactions better match the overall feel of the camera? 
How might digital and physical be integrated in a way that seems 
inherent and specific to this particular camera? At what point will 
luxury consumer’s changing perception of quality require 
                                                
12 Jostmann, Nils B., Daniël Lakens, and Thomas W. Schubert. "Weight as an 
Embodiment of Importance." Psychological Science: 1169-174. 

stronger digital and physical integration to command a premium 
price? 
Addictive Action 
 
Many products reveal their full set of sensorial qualities only 
through use. For physical products with multiple states, such as 
open/closed or on/off, the transition between those states can 
itself be sensorially satisfying, something more than a means to 
an end. 
 
The opening and closing of a Zippo lighter feels good. Zippo has 
used the same design throughout its 80-year history and the 
“click” of a Zippo flipping open is recognizable enough to serve 
as a dramatic moment in over 1,500 television shows and films.13 
Smokers who use Zippo lighters find themselves addicted to 
more than their cigarettes, absentmindedly flipping their lighter 
open and closed repeatedly. It would be hard to estimate the 
ratio of Zippo clicks to lit cigarettes, but it’s safe to say that it is 
far from 1:1. 
 
What fosters this kind of delightfully addictive feeling? What 
triggers us to do something repeatedly with no apparent 
purpose? Is this kind of enjoyable transition something that 
happens by accident, or can it be intentionally designed for? In 
1933, the differentiating characteristic in the design of the Zippo 
lighter was not its resistance to wind, but the ease of opening 
and lighting it with one hand. It was a success because of the 
experience it provided, including that distinctive click. It’s not 
surprising that the company founder, George G. Blaisdell, made 
up the word “Zippo” primarily because he liked the way it 
sounded. 
 
                                                
13 "Zippo : Then and Now." Zippo. Accessed January 25, 2015. 
http://www.zippo.com/about/article.aspx?id=1574. 

Figure 2.x MonAmi 153 ballpoint pen (composite image with two 
states, open and closed) 
 
Another addictive transition with a satisfying sound is the 
repeated clicking of a ballpoint pen, the metronome for office 
workers everywhere. With each repeated click, the ink reservoir 
protrudes or retracts from the body of the pen, not always to 
ready the pen for writing, but simply because it feels and sounds 
good. The most common addictive clicker is a toggle at the top of 
the pen, although the classic Korean design of the MonAmi 153 
ballpoint pen is even more satisfying and sensorial. 
 
The MonAmi, which means “my friend” in French, is one of the 
most common items ever produced in Korea,14 with over 3.3 
billion in sales since its introduction in 1963.15 The ballpoint tip of 
the MonAmi is revealed by pressing down on the top of the pen, 
but its retraction back into the body is triggered with a sliding 
control on the side. These two separate mechanisms create a 
more natural mapping between the force of the action and the 
direction of the ink cartridge; the shape of the spring-loaded 
slider seems like it’s just asking to be triggered. Each control 
results in a unique sound, and the possibility of alternating 
between single- and two-finger operation adds to the addictive 
cadence.  
 
A more high-tech product category where satisfying transitions 
played a differentiating role is the mobile phone market of the 
early 21st century. The first mobile phones are often referred to 
as “bricks,” in reference to their bulky size as well as their 
horizontal shape. As phones miniaturized, this basic “bar” form 
was maintained for many phones, with keyboard and screen 
always exposed and at the ready. 
                                                
14 "Prominent Designs Symbolize Generations of Korean Lives." Korea.net. Accessed 
January 25, 2015. http://www.korea.net/NewsFocus/Culture/view?articleId=74101. 
15 "[        ] '     '     153." Chosun.com. Accessed January 25, 2015. 
http://www.chosun.com/site/data/html_dir/2009/02/15/2009021500723.html. 

 
The Motorola StarTAC, released in 1996, was the first phone 
with a clamshell or “flip” design that protected the keyboard while 
significantly reducing the overall height. Motorola not only 
invented the flip phone, but 8 years later designed perhaps its 
most iconic representation, the Motorola RAZR V3. The thin 
design, innovative use of materials, and durable flip action 
helped the V3 model become the best selling flip phone of all 
time.16 
 
The flip design made mobile phones more sensorial. Answering 
a call with a bar shaped phone was a matter of pressing a 
button, but on a flip phone the conversation could begin with a 
physical action, a satisfying flick of the wrist to split the clamshell 
as you lifted the handset to your ear. Given that people carry 
their mobile phones with them everywhere, it’s no surprise that 
this flipping action became an addictive transition that people 
repeatedly performed even when not answering a call. 
 
Mobile phone manufacturers, keen to capitalize on the success 
of the flip phone, began a rapid exploration to patent and release 
phones with unique and innovative form factors. By the time that 
touchscreen devices eclipsed the market there was a nearly 
exhaustive set of possible transition types available. Phones 
could flip, slide, and swivel, but also half-swivel, flip both ways, 
and bottom pivot.17 
 
Figure 2.x Motorola RIZR Z3 slider phone (composite image with 
two states, open and closed) 
 
                                                
16 "The 20 Bestselling Mobile Phones of All Time." The Telegraph. Accessed January 25, 
2015. http://www.telegraph.co.uk/technology/picture-galleries/9818080/The-20-
bestselling-mobile-phones-of-all-time.html?frame=2458999. 
17 "Mobile Phone Evolution: Story of Shapes and Sizes." GSMArena.com. Accessed 
January 25, 2015. http://www.gsmarena.com/mobile_phone_evolution-review-493.php. 

All of these transitions were physical, but not all felt good enough 
to foster repeated, non-functional fiddling. Perhaps most 
successful by this metric were the slider phones, such as the 
Motorola RIZR Z3. In this form factor, the numeric keypad was 
hidden underneath the slider mechanism, with a 5-way 
directional pad available in a closed state. This allowed many 
actions to be performed without actually sliding open the phone. 
In practice though, it wasn’t functional necessity that caused 
people to slide the phone open and closed repeatedly 
throughout the day. They did it because it felt and sounded good. 
 
Why does this mechanism feel good enough to invite repeated 
non-functional triggering? For one, the sliding movement is 
dampened, with a spring providing slight resistance until it 
reaches a catch point where the force is reversed and the cover 
is accelerated to its final open state. This avoids accidental 
opening, but also results in a satisfying “pop” sound as the 
mechanism takes over and amplifies your action. Sliding is also 
easy to perform discreetly with one hand, without requiring wrist 
or arm movements. 
 
Figure 2.x iOS list view scrolled upwards beyond its final list item 
 
Purely digital products can also exhibit moments that cause 
delight in repetition. One example is the “bounce” animation at 
the bottom of a scroll view in Apple’s iOS. As the user swipes 
their finger upward the list scrolls up and off the screen, but 
when the user reaches the bottom it doesn’t just stop abruptly. 
There is a subtle animation, where the whole list pulls up slightly 
farther than the last item, before easing back to let the final entry 
sit at the bottom of the screen. 
 
The functional reason for the scroll view bounce is to act as 
feedback that the user has reached the bottom of the list. 
However, even though the animation is purely visual, it “feels” 
good enough that one can find themselves scrolling again and 

again to watch the list bounce back. Some apps have built upon 
this expectation to provide unique and equally addictive 
animations. For example, Yahoo! News Digest has a large image 
at the top of each story that zooms in and then snaps back to 
normal size as the user scrolls upward and lets go. 
 
In many mobile apps, a downward pulling gesture at the top of a 
list triggers a refresh of content from the server, usually 
accompanied by an animation. Although done for functional 
reasons, this action can be addictive as well, leading to repeated 
pulling well before any realistic expectation of new content being 
available. A client with a mobile app that has millions of users 
once told us that repeated pull-to-refresh was so pervasive they 
had to limit the actual server request to only once every 30 
seconds, faking the animated feedback for repeated requests 
within that time period. It’s a good reminder that addictive actions 
can bring delight and appeal to a product, but one should be 
careful of their unintended consequences, whether it’s the need 
for a physical hinge that’s rated for a much high number of 
openings or avoiding a server overload. 
Delightful Reaction 
 
Lids, switches, and sliders can be satisfying to use, providing 
direct sensorial feedback that confirms an action and, in the best 
instances, feel good in the process. However, direct feedback is 
only one way a product can engage our senses. By reacting to 
our presence, intention, and continued engagement, a product 
can be inviting and delightful, coming to life in unique and 
surprising ways. 
 
Figure 2.x Beosystem 2500 
 
The Danish high-end audio manufacturer Bang & Olufsen (B&O), 
is known for their unique product designs that push the limits of 
technology to explore new form factors and interaction 

paradigms. In 1991, as popular music was shifting from analog 
to digital formats, B&O released the Beosystem 2500, designed 
by the late David Lewis. The Beosystem 2500 is an all-in-one 
stereo featuring a CD-player, cassette deck, and AM/FM radio in 
an extremely flat vertical design, flanked by a pair of equally flat 
speakers. 
 
Doors made of smoked glass cover the front of the Beosystem 
2500, further emphasizing the flatness of the design. Raising 
your hand within 10 centimeters of the doors causes them to 
automatically glide open and turns on an interior light, 
illuminating the now accessible audio controls. Upon retracting 
your hand, the doors closes automatically after a 15 second 
delay, with the lights remaining on to accompany the audio, or 
turning off if no music is playing.18 
 
The use of automatic motion to signal readiness and recognition 
of intention gives the Beosystem 2500 a sense of life and 
personality. It lends the stereo a magical quality, and reframes 
the doors as the “face” of the product, giving them a character 
beyond their merely functional purpose. The detection of 
presence and corresponding motion is fairly limited and crude in 
comparison to today’s advanced capabilities, and yet it is enough 
to provide a sense of animation and lifelike personality. 
 
Another design element that contributes to the sensorial quality 
of the Beosystem 2500 is the transparent cover on the vertically 
oriented compact disc holder. As the CD plays, the spinning 
artwork can be seen through the glass doors, providing a unique 
visual reference to accompany the audio experience. This 
celebration of the disc itself is a departure from the popular CD 
tray mechanisms of the time, which completely enclosed the 
disc, treating it as a hidden key to unlock the audio. 
 
                                                
18 "Beosystem 2500." BeoPhile.com. Accessed January 25, 2015. 
http://beophile.com/?page_id=1122. 

Figure 2.x Axor Stark V 
 
The Axor Starck V faucet by Hansgrohe also uses transparency 
to bring an experience to life, but in a more natural and analog 
way. Created in collaboration with the French designer Philippe 
Starck, this clear faucet is made of crystal glass that showcases 
a unique water vortex created by its base. The faucet design is 
minimal, acting as a platform to support and celebrate the natural 
beauty of the swirling water, the texture of its motion, and the 
sound it creates as the vortex moves upwards and flows into the 
basin. 
 
Turning on the faucet is a delightful experience because of the 
way it engages your senses unexpectedly. You assume that 
water will begin flowing, but are caught off guard by the richness 
of what is normally a mundane experience of liquid moving 
silently through an opaque pipe. The Axor Starck V highlights the 
notion of design as an amplification of what is already there, 
recognizing the potential of water to engage the senses more 
than it normally does, and providing the support for that unique 
experience to happen. 
Reaction vs. Feedback 
 
These two very different products instill delight through their 
reaction to a person’s presence and actions, which goes beyond 
mapping input to output. They foster more of a conversation, 
where a person signals intent and the product takes over to 
enable or perform a multi-part sensorial experience. Whether it’s 
the choreographed movement of doors and lighting, or the 
swirling vortex of water with its dramatic beginning and ending 
scenes, the response takes place over time and relies heavily on 
motion to engage and communicate with us. It is a conversation, 
and the speaking role has briefly passed to the product, while 
still feeling under our control. 
 

In a purely digital product a change of state can be done 
instantaneously, but it has become common for interaction 
designers to utilize physics-based motion algorithms to design 
transitions that feel more “natural.” One example is Tweetbot 3.0 
for iPhone, which allows a user to close out of an image detail 
view by flicking the photo in any direction, causing it to animate 
off screen in proportion to the speed, direction, and angle of the 
user’s gesture. The result feels much richer than a simple close 
button, although ultimately this animated reaction is an 
abstraction that relates only generically to physical forces, with 
no intrinsic relationship to the content being acted upon. 
 
As physical products become increasingly embedded with 
computation and network connectivity they are able to react not 
only to a user’s direct physical presence, but to changes in 
remote data as well. Designers of such products should hew 
towards reactions with an innate connection to the specific 
material or subject they are working with, resisting the full 
abstraction that the digital world makes possible.  
 
It’s great that our products can keep track of changes in remote 
data, but when the object reacts to that change, and starts a 
conversation with us, it should be done in a manner that strongly 
communicates the meaning of the data itself. Otherwise our 
environments will be full of objects trying to engage our senses 
without us knowing how to interpret their message. An instructive 
comparison can be found in two of the simplest and earliest 
explorations of physical objects representing remote data: 
Ambient Orb and Availabot. 
 
Figure 2.x Ambient Orb 
 
Ambient Orb, created in 2002 as the first product by the 
company Ambient Objects, is a frosted glass orb with a glowing 
programmable light inside of it. The color of the light can be 
associated with variable data sources, and the value of the data 

is mapped to the glowing hue of the orb. The concept behind the 
design is to provide glanceable information without a screen, 
which the Ambient Orb achieves, but only through abstraction 
that requires a person to have a clear mental model of the 
programmed ruleset. It works well as an early demonstration of 
what might be possible with networked objects, but scales poorly 
in a world full of such objects. Imagine everyone in your family 
having to remember why the orb on the kitchen counter is now 
glowing green when it used to be blue. Does it mean the same 
thing as the green orb in the bedroom? 
 
Figure 2.x Availabot 
 
On the other side of the spectrum, moving from abstract to 
concrete representation, is the Availabot,19 a physical 
representation of your friend’s instant messenger presence. 
Created by Schulze & Webb in 2007, Availabot is a bendy, 
plastic avatar customized to look similar to a specific person. 
This hinged likeness unambiguously communicates your friend’s 
availability, standing straight at attention when they are online, or 
collapsing in a heap when they go away. The idea was that 
Availabot could utilize rapid prototyping capabilities to 
economically create one-off representations that were truly 
unique for each person they represented, though unfortunately 
the product was never brought to market after initial talks with a 
toy company.20 Regardless, it is instructive as an example of a 
delightful physical reaction to remote data, though of course it 
has the opposite problem of the Ambient Orb in that it can only 
ever represent one thing. 
 
Somewhere between these poles is the sweet spot for Internet of 
Things devices that react to remote data. Too much abstraction, 
                                                
19 "Availabot." BERG. Accessed January 20, 2015. 
http://berglondon.com/projects/availabot. 
20 "OFF=ON, Or, Whatever Happened to Availabot?" BERG. Accessed January 14, 
2015. http://berglondon.com/blog/2008/09/02/whatever-happened-to-availabot/. 

and the device is speaking in hidden codes that feel too 
machine-like and mysterious. Too concrete and the device is too 
limited to find commercial success or justify space in a person’s 
home. 
New Frontiers: Designing for Smell and 
Taste 
 
Two of our richest senses, smell and taste, are not often 
associated with design. However, the creation of objects that 
support these senses is an ancient practice, embodied best by 
the tea set, where rituals of assembly and service lead to hints of 
the aroma. Holding the tea cup warms your hand without burning 
it, and the slow sipping of the tea forms a communal bond with 
other participants. Outside of classic and common serving items, 
designers today are increasingly finding new ways to collaborate 
with chefs and food companies to design with smell and taste in 
mind, forging a new frontier for sensorial design. 
 
Martin Kastner is the founder and principal of Crucial Detail, a 
studio in Chicago that specializes in custom pieces to support 
unique culinary experiences. Martin is best known for his work 
designing serviceware concepts for Alinea, the 3-star Michelin 
restaurant founded by chef Grant Achatz. That collaboration has 
extended to other restaurants owned by Achatz, including The 
Aviary, a cocktail bar that prides itself on serving drinks with the 
same level of attention as a fine dinner. 
 
Figure 2.x Porthole Infuser 
 
At The Aviary, one of the most popular creations by Crucial 
Studio is the Porthole Infuser,21 a round vessel that presents the 
ingredients of a patron’s cocktail between two flat panes of glass, 
                                                
21 "The Porthole Infuser by Crucial Detail." Accessed January 25, 2015. 
http://www.theportholeinfuser.com/. 

emphasizing the transformative action of the steeping process 
and building anticipation for the cocktail’s taste. The Porthole 
Infuser takes a part of the preparation process that is normally 
hidden and brings it directly to the person’s table, providing time 
for the drinker to contemplate the ingredients on display, creating 
a mental checklist for their tongue to seek out when they take 
their first sip. 
 
The popularity of the Porthole Infuser at the Aviary led Kastner to 
create a Kickstarter campaign22 to fund the additional design and 
manufacturing required to release it as a commercial product. 
Support for the project was dramatic, achieving 25 times more 
funding than originally asked. This backing set the course for a 
redesign that allowed the infuser to be manufactured at scale 
and sold for $100, down from the several hundred dollars that 
each custom constructed Aviary version cost. 
 
The Porthole Infuser is marketed as more than a cocktail tool, 
working equally well to support the smell and taste of oils, teas, 
or any other infusion recipe. It’s an example of how designers 
can enhance the dining experience, not by crafting the smell or 
taste of the food itself, but working in collaboration with a chef to 
heighten our awareness of those senses. 
 
Figure 2.x “Haptic” Juice Skin 
 
Much of what we eat today comes in a package, rectangular 
boxes that homogenize our food into the same shapes and 
textures without regard to their smell or taste. Japanese designer 
Naoto Fukasaswa explored how food packaging could more fully 
engage our senses in his “Haptic” Juice Skin submission to the 
Takeo Paper Show 2014. 
 
                                                
22 "The Porthole." Kickstarter. Accessed January 25, 2015. 
https://www.kickstarter.com/projects/692213374/the-porthole. 

Fukasaswa created various juice boxes, each with a covering 
and structure that invokes the skin of the relevant fruit. The 
banana milk package has the rubbery texture of a real banana 
skin, along with faceted edges and the ubiquitous oval sticker on 
the side. The strawberry juice box is square in shape, but richly 
textured using real seeds. The kiwifruit juice box, as you might 
expect, is brown and fuzzy to emulate the unique feeling of that 
fruit’s natural shell. 
 
In simulating the color and texture of the fruit’s skin, Fukasawa 
hoped to reproduce the feeling of real skin, invoking a more 
holistic sensory moment as the juice was consumed.23 Although 
designed as a concept for an exhibition, the banana packaging 
was actually produced commercially for a limited time by the 
TaKaRa company. The production run looked quite similar to the 
exhibition version, but unfortunately without the simulated 
texture.24 
 
How might Interaction Designers support smell and taste? This is 
truly a new and underexplored territory, but there are signs of 
interest and one-off experiments happening that point towards a 
potential role. One of the most engaging speakers at the IxDA 
Interaction 2014 conference in Amsterdam was Bernard 
Lahousse, who gave a talk entitled "Food = Interaction."25 
Lahousse, who has a bio-engineering background, works at the 
intersection of food and science to truly design for taste itself. He 
founded the The Foodpairing Company,26 which provides an 
online tool and API for chefs, mixologists, and foodies to explore 
                                                
23 Fukasawa, Naoto. Naoto Fukasawa. London: Phaidon, 2007. 112-113. 
24 "Naoto Fukasawa JUICEPEEL Packaging (revisited)." Box Vox. September 16, 2014. 
Accessed January 25, 2015. http://www.beachpackagingdesign.com/wp/2014/09/naoto-
fukasawa-juicepeel-revisited.html. 
25 "Food Interaction - Thursday - Program." Interaction14. Accessed January 25, 2015. 
http://interaction14.ixda.org/program/thursday/528-food-interaction. 
26 "Homepage." Foodpairing. Accessed January 25, 2015. http://www.foodpairing.be. 

and be inspired by potential food combinations through a 
science-based recommendation engine.  
 
In Lahousse’s Interaction ‘14 presentation, he shared how it’s not 
only the flavor pairings themselves that contribute to the smell 
and taste, but that the environment and manner in which we eat 
can have a dramatic effect. The design of packaging and utensils 
is one part of this, but he also gave examples of chefs who are 
creating interactive, even game-like eating experiences. One 
restaurant he highlighted uses room temperature, sound, and 
projections to design an environment that alters and enhances 
the smell and taste of the food. These augmented dining 
environments are one area in which Interaction Designers could 
contribute their expertise to support the full range of human 
senses. 
 
An Orchestration of the Senses 
 
Interaction Designers have always tried to engage people’s 
senses but in comparison to the tangible output of Industrial 
Design, the options to do so have historically been limited. When 
designing for the screen, the best option has often been 
simulation, using metaphor and connotation to invoke a sensorial 
experience beyond what can truly be offered. 
 
The introduction of the graphical user interface was the first 
major advancement in engaging the senses through a screen. 
The next leap forward was the “multimedia” era, bringing sound, 
motion, and interactivity together in unique and immersive 
environments. Multimedia was initially made possible through 
cheap CD-ROM storage, which offered access to large graphics 
and video files that were impractical to store on small hard drives 
or download over slow internet connections. 
 
Interaction Designers of the multimedia era often utilized the new 
capabilities of CD-ROMs to break away from standard interface 

conventions and mimic as many sensorial, real world elements 
as possible. Map interfaces looked like faded and stained 
treasure maps, deep drop-shadows created virtual depth, and 
richly textured environments launched users into immersive 3D 
worlds. This was a time of widely variable interface 
experimentation, as designers combined text, graphics, audio, 
video and animation in unique ways to make encyclopedias, 
video games, and educational programs that simply weren’t 
practical before CD-ROMs. 
 
Figure 2.x Brushed metal UI example 
 
The invocation of physical materials and properties also found its 
way into standard programs and operating systems. Apple first 
introduced a brushed metal interface style with Quicktime 4.0, 
which later became a dominant feature of their OS X operating 
system. By 2004, Apple had canonized the brushed metal in 
their Human Interface Guidelines (HIG), encouraging designers 
to use the visual treatment if their program “strives to recreate a 
familiar physical device — Calculator or DVD player, for 
example.”
27 This visual reference to a physical material was less 
sensorial than metaphorical, acting as a bridge to ostensibly 
enhance usability and understanding as behaviors transitioned 
from physical to digital devices. This was the same rationale 
employed for the early versions of Apple’s iOS and, over time, 
both operating systems evolved to use simpler UI styles once 
users became familiar with the platforms. 
 
Referencing physical materials through a visual treatment 
obviously cannot engage our senses in the same way as their 
physical counterparts. Graphics that look like leather, felt, steel, 
or linen are often little more than interface decoration. The 
sensorial limitations of these graphic treatments highlight the 
distinction between Interface and Interaction Design. Static 
                                                
27 "Brushed Metal and The HIG." Daring Fireball. Accessed January 25, 2015. 
http://daringfireball.net/2004/10/brushedmetal. 

pixels on a screen can only engage us visually, and in most 
instances should avoid invoking additional senses they can’t 
deliver on. But Interaction Design goes beyond the interface to 
encompass all the moments of interaction that a person has with 
a system over time. 
 
This is why Interaction Designers tend to think of their work in 
terms of “flows,” focusing equally or more on the connections 
between states, the various inputs and outputs that are possible 
at that moment. This focus on the in-between makes time itself a 
kind of design material. It is not so much that Interaction 
Designers are manipulating a user’s sense of time, though 
sometimes elements like progress bars do try to ease waiting, 
but that they are using this fourth dimension as a connective 
platform to combine information, choices, and responses.28 Time 
is a kind of stage from which to orchestrate sensorial 
engagement into a set of dynamic movements. 
 
On a computer, or mobile device, this orchestration of interaction 
possibilities and system feedback can utilize animation, 
translucency, figure/ground relationships, color, sound, and 
standardized notifications to facilitate engagement with the 
system over time. But how does this work when we move 
beyond the screen? When a physical product is embedded with 
computation and network connectivity it transforms from an 
object to a system. A traditional product has discrete and 
predictable interactions that take place within a defined session, 
but once it becomes a system the sequence of interactions are 
less predictable and take place over a longer period of time. 
 
Consider the previously discussed Beosystem 2500, where the 
opening and closing of the stereo’s doors represents three clear 
states to form a beginning, middle, and end to the experience. 
Compare that to the range of possible states and behaviors that 
                                                
28 "Defining Interaction Design." LukeW. Accessed January 25, 2015. 
http://www.lukew.com/ff/entry.asp?327. 

a connected, computationally controlled stereo might have. 
Beyond reacting to your raised hand, it could detect your 
presence in the room as a specific individual. It could respond to 
your gestures or voice, highlight or hide relevant modes based 
on nearby media or subscription status, allow for use of remote 
speakers, adapt the volume based on time of day, offer you new 
music by your favorite bands, start music playing just before you 
enter the house — it is almost limitless to consider the 
possibilities. 
 
How should this hypothetical stereo enable and allow for this 
expanded set of interaction possibilities? One approach is to put 
the majority of interactions on a screen, a tablet on a stand in the 
living room. However, as David Rose of the MIT Media Lab 
refers to it, the next era of computing is more likely to be full of 
“enchanted objects,”29 where interactions with our products and 
environment are more natural, physical, and less reliant on a 
glowing rectangle to control everything.  
 
As physical products become increasingly integrated with digital 
systems, Interaction Designers should avoid defaulting to a 
screen for everything. Computational sensors can be used as 
richer and more natural inputs, detecting and making inferences 
from changes in light, temperature, motion, location, proximity, 
and touch. Output can move beyond a screen with voice 
feedback, haptic actuators, light arrays, and projection. 
 
In utilizing this mix of inputs and outputs, screen-based 
interaction patterns should not always be translated directly into 
the physical environment. Getting a notification on your phone 
might be unobtrusive, but having it spoken aloud in your living 
room might be less desirable. In the same way, there is a danger 
in assuming that a gesture or sensor-based input is necessarily 
more natural. If a user needs to develop a new mental model of 
                                                
29 Rose, David. Enchanted Objects: What They Are, How to Create Them, and How 
They Will Improve Our Lives. New York: Scribner, 2014. 

how a product “sees” them, or detects their presence, then the 
illusion has broken down. An example of this can be found in 
many airport or hotel bathrooms, where people wave their hands 
in frustration near unfamiliar sink fixtures in an attempt to 
discover how the sensor is triggered. 
 
The technology may be new, but designers need not start from 
scratch as they wrestle with orchestrating good experiences that 
span digital and physical. As more complex behaviors move off 
the screen, Interaction Designers should augment their 
knowledge of digital systems with over a century’s worth of 
Industrial Design lessons on how to engage the full range of 
human senses. 
 
 

The Implications
Software Above 
the Level of 
a Single Device
Tim O’Reilly

Tim O’Reilly
Software Above the Level
of a Single Device
The Implications

978-1-449-37451-8
[LSI]
Software Above the Level of a Single Device: The Implications
by Tim O’Reilly
Copyright © 2015 O’Reilly Media. All rights reserved.
Printed in the United States of America.
Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA
95472.
O’Reilly books may be purchased for educational, business, or sales promotional use.
Online editions are also available for most titles (http://safaribooksonline.com). For
more 
information, 
contact 
our 
corporate/institutional 
sales 
department:
800-998-9938 or corporate@oreilly.com.
Adapted by: Troy Mott
Editor: Brian Sawyer
Production Editor: Melanie Yarbrough
Interior Designer: David Futato
Cover Designer: Karen Montgomery
Illustrator: Rebecca Demarest
February 2015:
 First Edition
Revision History for the First Edition
2015-01-26: First Release
The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Software Above
the Level of a Single Device, the cover image, and related trade dress are trademarks
of O’Reilly Media, Inc.
While the publisher and the author have used good faith efforts to ensure that the
information and instructions contained in this work are accurate, the publisher and
the author disclaim all responsibility for errors or omissions, including without limi‐
tation responsibility for damages resulting from the use of or reliance on this work.
Use of the information and instructions contained in this work is at your own risk. If
any code samples or other technology this work contains or describes is subject to
open source licenses or the intellectual property rights of others, it is your responsi‐
bility to ensure that your use thereof complies with such licenses and/or rights.

Table of Contents
Software Above the Level of a Single Device: The Implications. . . . .  1
Multiple Smart Things                                                                        2
Importance of Human Input                                                              4
Implicit Versus Explicit Input                                                            5
Types of Sensors                                                                                   6
The System as a User Interface                                                          6
A Network of Devices                                                                         7
The Robustness Principle                                                                   8
Software Above the Level of a Single Device                                   9
System of Interaction                                                                          9
How the World “Should” Work                                                       10
Think About Things That Seem Hard                                            11
iii


Software Above the Level of a
Single Device: The Implications
The following document is adapted from the keynote address by Tim
O’Reilly, Software Above the Level of a Single Device: The Implica‐
tions, given at the Solid 2014 conference. Follow along to learn how
you can best take advantage of new technology known as the Internet
of Things.
Highlights
• Humans and machines work together in a complex pattern,
where data is captured through human activity, stored in the
cloud, pre-processed, and then used by a robot in the Internet
of Things.
• If we really want it to be an Internet, as opposed to a set of
Intranets, we have to think about interoperability.
• The smartphone that we carry in our pockets is filled with sen‐
sors, and it’s filled with capabilities, which is the key compo‐
nent to so many of these things.
There is some pretty amazing stuff we are seeing here at the Solid
2014 Conference. I want to give you a little bit of perspective,
though.
One of my favorite quotes is this one from Edwin Schlossberg. If
you’ve heard me talk, you’ve heard it before: “The skill of writing is
to create a context in which other people can think.”
1

And that means that the way we talk about things is a kind of map.
And like any map, it can either take us to the right place, or it can
lead us astray. I want to talk a little bit about some of the words that
we use in the current context and start thinking about what we
might be missing.
I did a word cloud of the Internet of Things article on Wikipedia
and as you can see, things is a really big word in the cloud, and not
only that but devices and objects also appear a lot. And sure enough,
there are some pretty amazing smart things. That word, smart, also
shows up in the word cloud.
Multiple Smart Things
Out front in the demo hall of the building, you probably saw the
Taktia smart router. I’m a home craftsman, and I want one of these.
I’m not as good as I’d like to be, and this thing would make me bet‐
ter. It’s a human augmentation, and it is super awesome.
2 
| 
Software Above the Level of a Single Device: The Implications

The Onewheel: I tried it yesterday, not very well, but it is also pretty
awesome.
And of course the Makani airborne wind turbines use incredible
smart control to generate power. This is an invention originally
made by my son-in-law, Saul Griffith, so I’m very proud of that.
Multiple Smart Things 
| 
3

Importance of Human Input
There is something missing in this word cloud, because we shouldn’t
just be talking about smart things. People and time are also concepts
in there. But they are way, way too small. I think one of the things I’d
like to have as an outcome of this talk is that the people in this room
go read that Wikipedia entry and make it better, because I really
don’t think it actually captures so many of the concepts that we need
to be thinking about today.
I want to talk a little bit about these aspects of people and time that
are too small in that graph.
When we think of the Internet of Smart Things, we tend to imagine
that these things—the Nest thermostat or the Google self-driving car
—they’re sensor and data driven, they are autonomous, not really
needing human input, and they are operating in real time. That is
really our first blush imagination.
But in fact, one of the super interesting things about the Google self-
driving car is its connection to the human-driven Google street view
vehicle that did all of the initial mapping. What you see here is
actually humans and machines operating together in a complex pat‐
tern in which data is captured through human activity, stored in the
cloud, pre-processed, and then used by a robot.
And I think that pattern is a really, really important one to pay atten‐
tion to as you design applications. Think about how data, generated
4 
| 
Software Above the Level of a Single Device: The Implications

by humans, is captured over time and is stored and acted upon later
by a device. It is not all real time.
Implicit Versus Explicit Input
The human input is critical, and it may also be implicit rather than
explicit. So, when you see the web page for the Nest learning ther‐
mostat, the whole pitch is that it learns implicitly from you, but it
also learns explicitly: you set the temperature. (By the way, Nest, you
really need to use energy-friendly temperatures in your advertise‐
ments!)
The Nest auto-detects when you’ve been away for awhile and turns
off the heat or air conditioning. Okay, that’s sort of our image of the
smart thing, but we have to remember that we are still giving that
input, it’s just through a different kind of interface. We are so used to
talking about how we give input through a keyboard. Then we are
giving input through a mouse and now we are giving it through a
touch screen. And now, we say “Wow! When we don’t show up in
the room, that is user input to this device.” It is still user input!
Think of this as a user experience problem and not an autonomous
device problem. And of course you have multiple input modalities,
since you have a Nest app. And one of the things I’ve noticed is that
once I set the schedule using this app, the device doesn’t seem to
learn any more. The interaction between the explicit, the implicit,
and what modes of implicit really matter.
Implicit Versus Explicit Input 
| 
5

Types of Sensors
Think a little bit more broadly about the kinds of sensors that you
have. When sensors first appear, we don’t use them that often, and as
a result they still seem magical. And then we take them for granted,
until someone figures out a new way to make them more power‐
ful. Some of the most important sensors that we have that are now
entering this rediscovery phase are the camera and the microphone
in our phones. Both Siri and Google Now are using the microphone
as the key to very, very powerful new interfaces, and ones that are
going to get better very rapidly. They are going to be a big part of the
user interface mix for this Internet of Things.
The point is that sensors allow us to create new kinds of user inter‐
faces. But you still need to remember that it is a user interface.
The System as a User Interface
I do have an example of a bad user interface. And that is this won‐
derful smart key for my Tesla. And it does wonderful things. I walk
up to my car and the car automatically opens. I don’t have to stick it
in a tiny slot or turn it, or any of those things we were so used to in
the mechanical age.
6 
| 
Software Above the Level of a Single Device: The Implications

But it’s got one really bad flaw, which is all over the forums, which is
you can’t hang it on a key ring. That’s actually a stupid device,
because it didn’t think about how I might want to use it. And any
time I leave my car in valet at the airport it comes back in a little
plastic bag because they can’t hang it on the hook. Sometimes they
lose it. The entire system in which we operate is the user interface.
There’s this great sticker that was given to me by Liam Maxwell, who
is the CTO of the British government.
They’ve really focused hard on this idea: what is the user need? And,
they made that the first of their design principles, to start with
needs.
As we design this new world we need to think about user needs first.
A Network of Devices
Coming back to this Internet of Things word cloud, I want to move
on and pick out one of the big words that we use, and that is Inter‐
net. And the Internet really matters. When you look at that smart
device, it’s not a standalone device. Yes, it’s controlled by its smart‐
phone, and yes, Nest now offers other devices connected to the net‐
work with the thermostat as its hub, and they talk to each other. In
fact, all of these things are connected to satellites and data centers,
and potentially to other similar devices or other smart devices.
A Network of Devices 
| 
7

And, by the way, even in that data center, you actually have smart
networks of things. The cooling is actually controlled semi-
autonomously. So there is this big network all over. There’s a net‐
work of data centers all over the world, so the Internet is clearly very
involved. But let’s remember the original ground rules of the Inter‐
net.
The Robustness Principle
We used to call the Internet “The Network of Networks,” because it
was this magical thing that connected all of these incompatible net‐
works. And interoperability was the focus. One of the things I worry
about as we move into this new world is that we may have forgotten
that interoperability. We have vendors who are trying to own it all,
building systems that talk to their devices, but not to everyone else’s.
We have to think a lot about interoperability.
And we have to think about this wonderful principle that was put
out by one of the saints of the early Internet, Jon Postel. (I wonder
sometimes what would have happened if he hadn’t died too young of
a heart attack.) He wrote in the TCP RFC, “Be conservative in what
you send, be liberal in what you accept from others.” It’s become
known as the Robustness Principle. 
That is such an important principle, and I want those of you who are
designing devices or systems to think about interoperability and to
remember if we really want it to be an Internet, as opposed to a set
of Intranets, you have to think about interoperability.
8 
| 
Software Above the Level of a Single Device: The Implications

Software Above the Level of a Single Device
The next thing I want to cover briefly is the notion of software above
the level of a single device. This is a phrase that I got from Dave
Stutz, who wrote a fabulous letter when he left Microsoft back in
2003. It was his parting advice. And it ended with the line, “Useful
software written above the level of the single device will command
high margins for a long time to come." 
This was very, very prescient, because a lot of focus was still on the
PC and even on the network; it was very small thinking. And his
notion of software above the level of a single device stuck in my
head. I’ve used it for years. It was part of my core Web 2.0 principles.
But I want to bring it out in the example of the Uber app.
System of Interaction
Let’s not get too taken up with new wearables. Uber is a smart things
app. We forget that the phone is our most widely used smart thing.
This thing that we carry in our pockets is filled with sensors, and it’s
filled with capabilities.
But what’s really interesting about Uber is, of course, that it doesn’t
work in isolation. There’s an app for the passenger, but there’s also
an app for the driver. And those two things are coordinating in real
time using a kind of Internet operating system. There are various
types of functions for communication, and for GPS to locate every‐
body, and to track progress. There is a payment and a rating system.
Software Above the Level of a Single Device 
| 
9

All of these things are part of a “system of interaction.” That’s a won‐
derful phrase that was coined by someone at IBM.
What I want you to think about here is that once you have new UI
capabilities and new augmentations of humans via sensors, you can
actually start to think about things differently.
There’s a wonderful quote from Aaron Levie at Box that I saw on
Twitter. He said, “Uber is the lesson in building for how the world
should work, instead of optimizing for how the world does work.”
That’s our opportunity with this new technology that we’ve been
given.
How the World “Should” Work
We can start thinking about how the world should work, instead of
optimizing how the world does work. So, back to the Makani wind
turbine out there. The idea is that, instead of having a turbine sitting
on the ground like we’ve had since the Dutch windmills, you could
actually put one in the sky using this incredible control technology.
Now, they are still working on it, but the notion that this thing has
to be able to fly autonomously for thousands of hours, and has to be
able to take off and land by itself, and it’s generating power up high
where there is always wind. That’s thinking about how the world
should work, rather than how the world does work.
This notion is critical and the sensors let us do new things. A com‐
pany that we are invested in at O’Reilly Alpha Tech Ventures is
Cover. 
10 
| 
Software Above the Level of a Single Device: The Implications

Because you are registered with the cloud, and because the applica‐
tion is able to tell where you are, you can walk into a restaurant and
sit down. You are identified, fed, and when you are done with the
meal you walk out and your credit card is charged. It’s kind of
magic. Because of sensors, we can rethink the way things work.
Another great example is Makespace: your closet in the cloud. This
is an example of how sensors don’t have to be complicated. These
guys have realized that if you can actually take pictures of what you
put in the boxes when you put stuff in storage, and you can identify
what’s in that box, you can put this stuff away in a warehouse where
space is cheap. They can then bring you just the box you want. You
don’t have to go rooting through your storage closet, because you
can effectively go into a robotic warehouse. Once again, they are
rethinking a familiar process, because we now have new capabilities.
Think About Things That Seem Hard
Where I want to go with this is a final piece of advice, which is don’t
just try to re-create the experiences and the technologies that we
have today. Try to think about new things, and in particular, think
about things that seem hard—things that might have seemed impos‐
sible before you had these new capabilities.
One of the things I’m most excited about in this technology revolu‐
tion is how it is giving us amazing new capabilities to affect the
physical world. And the physical world, in the end, is where we all
live, and where the biggest problems that we face as a society are to
be found.
Think About Things That Seem Hard 
| 
11

We have to feed the world. We have to generate energy. We have to
deal with climate change. We have to deal with the problems of our
society. And there are amazing new capabilities, and I want you to
not just make cute, cool, and amazing consumer devices. I want you
to think about hard problems that you can solve. Take this technol‐
ogy and make the world a better place.
Thank you.
12 
| 
Software Above the Level of a Single Device: The Implications

