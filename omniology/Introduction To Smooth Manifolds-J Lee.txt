INTRODUCTION TO
SMOOTH MANIFOLDS
by John M. Lee
University of Washington
Department of Mathematics


John M. Lee
Introduction to
Smooth Manifolds
Version 3.0
December 31, 2000

iv
John M. Lee
University of Washington
Department of Mathematics
Seattle, WA 98195-4350
USA
lee@math.washington.edu
http://www.math.washington.edu/˜lee
c⃝2000 by John M. Lee

Preface
This book is an introductory graduate-level textbook on the theory of
smooth manifolds, for students who already have a solid acquaintance with
general topology, the fundamental group, and covering spaces, as well as
basic undergraduate linear algebra and real analysis. It is a natural sequel
to my earlier book on topological manifolds [Lee00].
This subject is often called “diﬀerential geometry.” I have mostly avoided
this term, however, because it applies more properly to the study of smooth
manifolds endowed with some extra structure, such as a Riemannian met-
ric, a symplectic structure, a Lie group structure, or a foliation, and of the
properties that are invariant under maps that preserve the structure. Al-
though I do treat all of these subjects in this book, they are treated more as
interesting examples to which to apply the general theory than as objects
of study in their own right. A student who ﬁnishes this book should be
well prepared to go on to study any of these specialized subjects in much
greater depth.
The book is organized roughly as follows. Chapters 1 through 4 are
mainly deﬁnitions. It is the bane of this subject that there are so many
deﬁnitions that must be piled on top of one another before anything in-
teresting can be said, much less proved. I have tried, nonetheless, to bring
in signiﬁcant applications as early and as often as possible. The ﬁrst one
comes at the end of Chapter 4, where I show how to generalize the classical
theory of line integrals to manifolds.
The next three chapters, 5 through 7, present the ﬁrst of four major
foundational theorems on which all of smooth manifolds theory rests—the
inverse function theorem—and some applications of it: to submanifold the-

vi
Preface
ory, embeddings of smooth manifolds into Euclidean spaces, approximation
of continuous maps by smooth ones, and quotients of manifolds by group
actions.
The next four chapters, 8 through 11, focus on tensors and tensor ﬁelds
on manifolds, and progress from Riemannian metrics through diﬀerential
forms, integration, and Stokes’s theorem (the second of the four founda-
tional theorems), culminating in the de Rham theorem, which relates dif-
ferential forms on a smooth manifold to its topology via its singular coho-
mology groups. The proof of the de Rham theorem I give is an adaptation
of the beautiful and elementary argument discovered in 1962 by Glen E.
Bredon [Bre93].
The last group of four chapters, 12 through 15, explores the circle of
ideas surrounding integral curves and ﬂows of vector ﬁelds, which are the
smooth-manifold version of systems of ordinary diﬀerential equations. I
prove a basic version of the existence, uniqueness, and smoothness theo-
rem for ordinary diﬀerential equations in Chapter 12, and use that to prove
the fundamental theorem on ﬂows, the third foundational theorem. After
a technical excursion into the theory of Lie derivatives, ﬂows are applied
to study foliations and the Frobenius theorem (the last of the four founda-
tional theorems), and to explore the relationship between Lie groups and
Lie algebras.
The Appendix (which most readers should read ﬁrst, or at least skim)
contains a very cursory summary of prerequisite material on linear algebra
and calculus that is used throughout the book. One large piece of prereq-
uisite material that should probably be in the Appendix, but is not yet,
is a summary of general topology, including the theory of the fundamental
group and covering spaces. If you need a review of that, you will have to
look at another book. (Of course, I recommend [Lee00], but there are many
other texts that will serve at least as well!)
This is still a work in progress, and there are bound to be errors and
omissions. Thus you will have to be particularly alert for typos and other
mistakes. Please let me know as soon as possible when you ﬁnd any errors,
unclear descriptions, or questionable statements. I’ll post corrections on
the Web for anything that is wrong or misleading.
I apologize in advance for the dearth of illustrations. I plan eventually
to include copious drawings in the book, but I have not yet had time to
generate them. Any instructor teaching from this book should be sure to
draw all the relevant pictures in class, and any student studying from them
should make an eﬀort to draw pictures whenever possible.
Acknowledgments. There are many people who have contributed to the de-
velopment of this book in indispensable ways. I would like to mention es-
pecially Judith Arms and Tom Duchamp, both of whom generously shared
their own notes and ideas about teaching this subject; Jim Isenberg and
Steve Mitchell, who had the courage to teach from these notes while they

Preface
vii
were still in development, and who have provided spectacularly helpful
suggestions for improvement; and Gary Sandine, who after having found
an early version of these notes on the Web has read them with incredible
thoroughness and has made more suggestions than anyone else for improv-
ing them, and has even contributed several ﬁrst-rate illustrations, with a
promise of more to come.
Happy reading!
John M. Lee
Seattle

viii
Preface

Contents
Preface
v
1
Smooth Manifolds
1
Topological Manifolds . . . . . . . . . . . . . . . . . . . . . . . .
3
Smooth Structures . . . . . . . . . . . . . . . . . . . . . . . . . .
6
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
Local Coordinate Representations
. . . . . . . . . . . . . . . . .
18
Manifolds With Boundary . . . . . . . . . . . . . . . . . . . . . .
19
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2
Smooth Maps
23
Smooth Functions and Smooth Maps . . . . . . . . . . . . . . . .
24
Smooth Covering Maps
. . . . . . . . . . . . . . . . . . . . . . .
28
Lie Groups
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
Bump Functions and Partitions of Unity . . . . . . . . . . . . . .
34
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
3
The Tangent Bundle
41
Tangent Vectors
. . . . . . . . . . . . . . . . . . . . . . . . . . .
42
Push-Forwards . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
Computations in Coordinates . . . . . . . . . . . . . . . . . . . .
49
The Tangent Space to a Manifold With Boundary
. . . . . . . .
52
Tangent Vectors to Curves . . . . . . . . . . . . . . . . . . . . . .
53
Alternative Deﬁnitions of the Tangent Space
. . . . . . . . . . .
55

x
Contents
The Tangent Bundle . . . . . . . . . . . . . . . . . . . . . . . . .
57
Vector Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
4
The Cotangent Bundle
65
Covectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
Tangent Covectors on Manifolds
. . . . . . . . . . . . . . . . . .
68
The Cotangent Bundle . . . . . . . . . . . . . . . . . . . . . . . .
69
The Diﬀerential of a Function . . . . . . . . . . . . . . . . . . . .
71
Pullbacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
Line Integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
Conservative Covector Fields . . . . . . . . . . . . . . . . . . . .
82
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
5
Submanifolds
93
Submersions, Immersions, and Embeddings . . . . . . . . . . . .
94
Embedded Submanifolds . . . . . . . . . . . . . . . . . . . . . . .
97
The Inverse Function Theorem and Its Friends
. . . . . . . . . .
105
Level Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
Images of Embeddings and Immersions . . . . . . . . . . . . . . .
118
Restricting Maps to Submanifolds
. . . . . . . . . . . . . . . . .
121
Vector Fields and Covector Fields on Submanifolds . . . . . . . .
122
Lie Subgroups . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
124
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
126
6
Embedding and Approximation Theorems
129
Sets of Measure Zero in Manifolds
. . . . . . . . . . . . . . . . .
130
The Whitney Embedding Theorem . . . . . . . . . . . . . . . . .
133
The Whitney Approximation Theorem . . . . . . . . . . . . . . .
138
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
7
Lie Group Actions
145
Group Actions on Manifolds . . . . . . . . . . . . . . . . . . . . .
145
Equivariant Maps . . . . . . . . . . . . . . . . . . . . . . . . . . .
149
Quotients of Manifolds by Group Actions
. . . . . . . . . . . . .
152
Covering Manifolds . . . . . . . . . . . . . . . . . . . . . . . . . .
157
Quotients of Lie Groups . . . . . . . . . . . . . . . . . . . . . . .
160
Homogeneous Spaces . . . . . . . . . . . . . . . . . . . . . . . . .
161
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
167
8
Tensors
171
The Algebra of Tensors
. . . . . . . . . . . . . . . . . . . . . . .
172
Tensors and Tensor Fields on Manifolds . . . . . . . . . . . . . .
179
Symmetric Tensors . . . . . . . . . . . . . . . . . . . . . . . . . .
182
Riemannian Metrics . . . . . . . . . . . . . . . . . . . . . . . . .
184

Contents
xi
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
196
9
Diﬀerential Forms
201
The Heuristics of Volume Measurement
. . . . . . . . . . . . . .
202
The Algebra of Alternating Tensors
. . . . . . . . . . . . . . . .
204
The Wedge Product
. . . . . . . . . . . . . . . . . . . . . . . . .
208
Diﬀerential Forms on Manifolds . . . . . . . . . . . . . . . . . . .
212
Exterior Derivatives
. . . . . . . . . . . . . . . . . . . . . . . . .
214
Symplectic Forms . . . . . . . . . . . . . . . . . . . . . . . . . . .
219
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
225
10 Integration on Manifolds
229
Orientations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
230
Orientations of Hypersurfaces . . . . . . . . . . . . . . . . . . . .
235
Integration of Diﬀerential Forms
. . . . . . . . . . . . . . . . . .
240
Stokes’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . .
248
Manifolds with Corners
. . . . . . . . . . . . . . . . . . . . . . .
251
Integration on Riemannian Manifolds
. . . . . . . . . . . . . . .
257
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
265
11 De Rham Cohomology
271
The de Rham Cohomology Groups . . . . . . . . . . . . . . . . .
272
Homotopy Invariance . . . . . . . . . . . . . . . . . . . . . . . . .
274
Computations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
277
The Mayer–Vietoris Theorem . . . . . . . . . . . . . . . . . . . .
285
Singular Homology and Cohomology . . . . . . . . . . . . . . . .
291
The de Rham Theorem
. . . . . . . . . . . . . . . . . . . . . . .
297
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
303
12 Integral Curves and Flows
307
Integral Curves . . . . . . . . . . . . . . . . . . . . . . . . . . . .
307
Flows
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
309
The Fundamental Theorem on Flows . . . . . . . . . . . . . . . .
314
Complete Vector Fields
. . . . . . . . . . . . . . . . . . . . . . .
316
Proof of the ODE Theorem . . . . . . . . . . . . . . . . . . . . .
317
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
325
13 Lie Derivatives
327
The Lie Derivative . . . . . . . . . . . . . . . . . . . . . . . . . .
327
Lie Brackets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
329
Commuting Vector Fields . . . . . . . . . . . . . . . . . . . . . .
335
Lie Derivatives of Tensor Fields . . . . . . . . . . . . . . . . . . .
339
Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
343
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
352

xii
Contents
14 Integral Manifolds and Foliations
355
Tangent Distributions
. . . . . . . . . . . . . . . . . . . . . . . .
356
Integral Manifolds and Involutivity . . . . . . . . . . . . . . . . .
357
The Frobenius Theorem . . . . . . . . . . . . . . . . . . . . . . .
359
Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
361
Foliations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
364
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
369
15 Lie Algebras and Lie Groups
371
Lie Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
371
Induced Lie Algebra Homomorphisms
. . . . . . . . . . . . . . .
378
One-Parameter Subgroups . . . . . . . . . . . . . . . . . . . . . .
381
The Exponential Map . . . . . . . . . . . . . . . . . . . . . . . .
385
The Closed Subgroup Theorem . . . . . . . . . . . . . . . . . . .
392
Lie Subalgebras and Lie Subgroups . . . . . . . . . . . . . . . . .
394
The Fundamental Correspondence
. . . . . . . . . . . . . . . . .
398
Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
400
Appendix: Review of Prerequisites
403
Linear Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . .
403
Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
424
References
441
Index
445

1
Smooth Manifolds
This book is about smooth manifolds. In the simplest terms, these are
spaces that locally look like some Euclidean space Rn, and on which one
can do calculus. The most familiar examples, aside from Euclidean spaces
themselves, are smooth plane curves such as circles and parabolas, and
smooth surfaces R3 such as spheres, tori, paraboloids, ellipsoids, and hy-
perboloids. Higher-dimensional examples include the set of unit vectors in
Rn+1 (the n-sphere) and graphs of smooth maps between Euclidean spaces.
You are probably already familiar with manifolds as examples of topo-
logical spaces: A topological manifold is a topological space with certain
properties that encode what we mean when we say that it “locally looks
like” Rn. Such spaces are studied intensively by topologists.
However, many (perhaps most) important applications of manifolds in-
volve calculus. For example, the application of manifold theory to geometry
involves the study of such properties as volume and curvature. Typically,
volumes are computed by integration, and curvatures are computed by for-
mulas involving second derivatives, so to extend these ideas to manifolds
would require some means of making sense of diﬀerentiation and integration
on a manifold. The application of manifold theory to classical mechanics in-
volves solving systems of ordinary diﬀerential equations on manifolds, and
the application to general relativity (the theory of gravitation) involves
solving a system of partial diﬀerential equations.
The ﬁrst requirement for transferring the ideas of calculus to manifolds is
some notion of “smoothness.” For the simple examples of manifolds we de-
scribed above, all subsets of Euclidean spaces, it is fairly easy to describe
the meaning of smoothness on an intuitive level. For example, we might

2
1. Smooth Manifolds
want to call a curve “smooth” if it has a tangent line that varies continu-
ously from point to point, and similarly a “smooth surface” should be one
that has a tangent plane that varies continuously from point to point. But
for more sophisticated applications, it is an undue restriction to require
smooth manifolds to be subsets of some ambient Euclidean space. The am-
bient coordinates and the vector space structure of Rn are superﬂuous data
that often have nothing to do with the problem at hand. It is a tremen-
dous advantage to be able to work with manifolds as abstract topological
spaces, without the excess baggage of such an ambient space. For exam-
ple, in the application of manifold theory to general relativity, spacetime
is thought of as a 4-dimensional smooth manifold that carries a certain
geometric structure, called a Lorentz metric, whose curvature results in
gravitational phenomena. In such a model, there is no physical meaning
that can be assigned to any higher-dimensional ambient space in which the
manifold lives, and including such a space in the model would complicate
it needlessly. For such reasons, we need to think of smooth manifolds as
abstract topological spaces, not necessarily as subsets of larger spaces.
As we will see shortly, there is no way to deﬁne a purely topological
property that would serve as a criterion for “smoothness,” so topological
manifolds will not suﬃce for our purposes. As a consequence, we will think
of a smooth manifold as a set with two layers of structure: ﬁrst a topology,
then a smooth structure.
In the ﬁrst section of this chapter, we describe the ﬁrst of these structures.
A topological manifold is a topological space with three special properties
that express the notion of being locally like Euclidean space. These prop-
erties are shared by Euclidean spaces and by all of the familiar geometric
objects that look locally like Euclidean spaces, such as curves and surfaces.
In the second section, we introduce an additional structure, called a
smooth structure, that can be added to a topological manifold to enable us
to make sense of derivatives. At the end of that section, we indicate how
the two-stage construction can be combined into a single step.
Following the basic deﬁnitions, we introduce a number of examples of
manifolds, so you can have something concrete in mind as you read the
general theory. (Most of the really interesting examples of manifolds will
have to wait until Chapter 5, however.) We then discuss in some detail how
local coordinates can be used to identify parts of smooth manifolds locally
with parts of Euclidean spaces. At the end of the chapter, we introduce
an important generalization of smooth manifolds, called manifolds with
boundary.

Topological Manifolds
3
Topological Manifolds
This section is devoted to a brief overview of the deﬁnition and properties
of topological manifolds. We assume the reader is familiar with the basic
properties of topological spaces, at the level of [Lee00] or [Mun75], for
example.
Suppose M is a topological space. We say M is a topological manifold of
dimension n or a topological n-manifold if it has the following properties:
• M is a Hausdorﬀspace: For every pair of points p, q ∈M, there are
disjoint open subsets U, V ⊂M such that p ∈U and q ∈V .
• M is second countable: There exists a countable basis for the topology
of M.
• M is locally Euclidean of dimension n: Every point has a neighbor-
hood that is homeomorphic to an open subset of Rn.
The locally Euclidean property means that for each p ∈M, we can ﬁnd
the following:
• an open set U ⊂M containing p;
• an open set eU ⊂Rn; and
• a homeomorphism ϕ: U →eU (i.e, a continuous bijective map with
continuous inverse).
Exercise 1.1.
Show that equivalent deﬁnitions of locally Euclidean spaces
are obtained if, instead of requiring U to be homeomorphic to an open subset
of Rn, we require it to be homeomorphic to an open ball in Rn, or to Rn
itself.
The basic example of a topological n-manifold is, of course, Rn. It is
Hausdorﬀbecause it is a metric space, and it is second countable because
the set of all open balls with rational centers and rational radii is a count-
able basis.
Requiring that manifolds share these properties helps to ensure that
manifolds behave in the ways we expect from our experience with Euclidean
spaces. For example, it is easy to verify that in a Hausdorﬀspace, one-
point sets are closed and limits of convergent sequences are unique. The
motivation for second countability is a bit less evident, but it will have
important consequences throughout the book, beginning with the existence
of partitions of unity in Chapter 2.
In practice, both the Hausdorﬀand second countability properties are
usually easy to check, especially for spaces that are built out of other man-
ifolds, because both properties are inherited by subspaces and products, as
the following exercises show.

4
1. Smooth Manifolds
Exercise 1.2.
Show that any topological subspace of a Hausdorﬀspace is
Hausdorﬀ, and any ﬁnite product of Hausdorﬀspaces is Hausdorﬀ.
Exercise 1.3.
Show that any topological subspace of a second countable
space is second countable, and any ﬁnite product of second countable spaces
is second countable.
In particular, it follows easily from these two exercises that any open
subset of a topological n-manifold is itself a topological n-manifold (with
the subspace topology, of course).
One of the most important properties of second countable spaces is ex-
pressed the following lemma, whose proof can be found in [Lee00, Lemma
2.15].
Lemma 1.1. Let M be a second countable topological space. Then every
open cover of M has a countable subcover.
The way we have deﬁned topological manifolds, the empty set is a topo-
logical n-manifold for every n. For the most part, we will ignore this special
case (sometimes without remembering to say so). But because it is useful
in certain contexts to allow the empty manifold, we have chosen not to
exclude it from the deﬁnition.
We should note that some authors choose to omit the the Hausdorﬀ
property or second countability or both from the deﬁnition of manifolds.
However, most of the interesting results about manifolds do in fact require
these properties, and it is exceedingly rare to encounter a space “in nature”
that would be a manifold except for the failure of one or the other of these
hypotheses. See Problems 1-1 and 1-2 for a couple of examples.
Coordinate Charts
Let M be a topological n-manifold. A coordinate chart (or just a chart) on
M is a pair (U, ϕ), where U is an open subset of M and ϕ: U →eU is a
homeomorphism from U to an open subset eU = ϕ(U) ⊂Rn (Figure 1.1).
If in addition eU is an open ball in Rn, then U is called a coordinate ball.
The deﬁnition of a topological manifold implies that each point p ∈M is
contained in the domain of some chart (U, ϕ). If ϕ(p) = 0, we say the chart
is centered at p. Given p and any chart (U, ϕ) whose domain contains p,
it is easy to obtain a new chart centered at p by subtracting the constant
vector ϕ(p).
Given a chart (U, ϕ), we call the set U a coordinate domain, or a co-
ordinate neighborhood of each of its points. The map ϕ is called a (local)
coordinate map, and the component functions of ϕ are called local coordi-
nates on U. We will sometimes write things like “(U, ϕ) is a chart containing
p” as a shorthand for “(U, ϕ) is a chart whose domain U contains p.”

Topological Manifolds
5
U
eU
ϕ
FIGURE 1.1. A coordinate chart.
We conclude this section with a brief look at some examples of topological
manifolds.
Example 1.2 (Spheres).
Let Sn denote the (unit) n-sphere, which is
the set of unit-length vectors in Rn+1:
Sn = {x ∈Rn+1 : |x| = 1}.
It is Hausdorﬀand second countable because it is a subspace of Rn. To
show that it is locally Euclidean, for each index i = 1, . . . , n + 1, let U +
i
denote the subset of Sn where the ith coordinate is positive:
U +
i = {(x1, . . . , xn+1) ∈Sn : xi > 0}.
Similarly, U −
i
is the set where xi < 0.
For each such i, deﬁne maps ϕ±
i : U ±
i →Rn by
ϕ±
i (x1, . . . , xn+1) = (x1, . . . , bxi, . . . , xn+1),
where the hat over xi indicates that xi is omitted. Each ϕ±
i is evidently a
continuous map, being the restriction to Sn of a linear map on Rn+1. It is
a homeomorphism onto its image, the unit ball Bn ⊂Rn, because it has a
continuous inverse given by
(ϕ±
i )−1(u1, . . . , un) =

u1, . . . , ui−1, ±
p
1 −|u|2, ui, . . . , un
.

6
1. Smooth Manifolds
Since every point in Sn+1 is in the domain of one of these 2n+2 charts, Sn
is locally Euclidean of dimension n and is thus a topological n-manifold.
Example 1.3 (Projective Spaces).
The n-dimensional real projective
space, denoted by Pn (or sometimes RPn), is deﬁned as the set of 1-
dimensional linear subspaces of Rn+1. We give it the quotient topology
determined by the natural map π: Rn+1 ∖{0} →Pn sending each point
x ∈Rn+1 ∖{0} to the line through x and 0. For any point x ∈Rn+1 ∖{0},
let [x] = π(x) denote the equivalence class of x in Pn.
For each i = 1, . . . , n + 1, let eUi ⊂Rn+1 ∖{0} be the set where xi ̸= 0,
and let Ui = π(eUi) ⊂Pn. Since eUi is a saturated open set (meaning that it
contains the full inverse image π−1(π(p)) for each p ∈eUi), Ui is open and
π: eUi →Ui is a quotient map. Deﬁne a map ϕi : Ui →Rn by
ϕi[x1, . . . , xn+1] =
x1
xi , . . . , xi−1
xi , xi+1
xi , . . . , xn+1
xi

.
This map is well-deﬁned because its value is unchanged by multiplying x
by a nonzero constant, and it is continuous because ϕi ◦π is continuous.
(The characteristic property of a quotient map π is that a map f from
the quotient space is continuous if and only if the composition f ◦π is
continuous; see [Lee00].) In fact, ϕi is a homeomorphism, because its inverse
is given by
ϕ−1
i
(u1, . . . , un) = [u1, . . . , ui−1, 1, ui, . . . , un],
as you can easily check. Geometrically, if we identify Rn in the obvious way
with the aﬃne subspace where xi = 1, then ϕi[x] can be interpreted as the
point where the line [x] intersects this subspace. Because the sets Ui cover
Pn, this shows that Pn is locally Euclidean of dimension n. The Hausdorﬀ
and second countability properties are left as exercises.
Exercise 1.4.
Show that Pn is Hausdorﬀand second countable, and is
therefore a topological n-manifold.
Smooth Structures
The deﬁnition of manifolds that we gave in the preceding section is suﬃ-
cient for studying topological properties of manifolds, such as compactness,
connectedness, simple connectedness, and the problem of classifying man-
ifolds up to homeomorphism. However, in the entire theory of topological
manifolds, there is no mention of calculus. There is a good reason for this:
Whatever sense we might try to make of derivatives of functions or curves
on a manifold, they cannot be invariant under homeomorphisms. For ex-
ample, if f is a function on the circle S1, we would want to consider f to

Smooth Structures
7
be diﬀerentiable if it has an ordinary derivative with respect to the an-
gle θ. But the circle is homeomorphic to the unit square, and because of
the corners the homeomorphism and its inverse cannot simultaneously be
diﬀerentiable. Thus, depending on the homeomorphism we choose, there
will either be functions on the circle whose composition with the homeo-
morphism is not diﬀerentiable on the square, or vice versa. (Although this
claim may seem plausible, it is probably not obvious at this point how to
prove it. After we have developed some more machinery, you will be asked
to prove it in Problem 5-11.)
To make sense of derivatives of functions, curves, or maps, we will need
to introduce a new kind of manifold called a “smooth manifold.” (Through-
out this book, we will use the word “smooth” to mean C∞, or inﬁnitely
diﬀerentiable.)
From the example above, it is clear that we cannot deﬁne a smooth
manifold simply to be a topological manifold with some special property,
because the property of “smoothness” (whatever that might be) cannot be
invariant under homeomorphisms.
Instead, we are going to deﬁne a smooth manifold as one with some
extra structure in addition to its topology, which will allow us to decide
which functions on the manifold are smooth. To see what this additional
structure might look like, consider an arbitrary topological n-manifold M.
Each point in M is in the domain of a coordinate map ϕ: U →eU ⊂Rn.
A plausible deﬁnition of a smooth function on M would be to say that
f : M →R is smooth if and only if the composite function f ◦ϕ−1 : eU →R
is smooth. But this will make sense only if this property is independent
of the choice of coordinate chart. To guarantee this, we will restrict our
attention to “smooth charts.” Since smoothness is not a homeomorphism-
invariant property, the way to do this is to consider the collection of all
smooth charts as a new kind of structure on M. In the remainder of this
chapter, we will carry out the details.
Our study of smooth manifolds will be based on the calculus of maps
between Euclidean spaces. If U and V are open subsets of Euclidean spaces
Rn and Rm, respectively, a map F : U →V is said to be smooth if each
of the component functions of F has continuous partial derivatives of all
orders. If in addition F is bijective and has a smooth inverse map, it is called
a diﬀeomorphism. A diﬀeomorphism is, in particular, a homeomorphism. A
review of some of the most important properties of smooth maps is given
in the Appendix.
Let M be a topological n-manifold. If (U, ϕ), (V, ψ) are two charts such
that U ∩V ̸= ∅, then the composite map ψ ◦ϕ−1 : ϕ(U ∩V ) →ψ(U ∩V )
(called the transition map from ϕ to ψ) is a composition of homeomor-
phisms, and is therefore itself a homeomorphism (Figure 1.2). Two charts
(U, ϕ) and (V, ψ) are said to be smoothly compatible if either U ∩V = ∅
or the transition map ψ ◦ϕ−1 is a diﬀeomorphism. (Since ϕ(U ∩V ) and
ψ(U ∩V ) are open subsets of Rn, smoothness of this map is to be inter-

8
1. Smooth Manifolds
U
V
eU
eV
ϕ
ψ
ψ ◦ϕ−1
FIGURE 1.2. A transition map.
preted in the ordinary sense of having continuous partial derivatives of all
orders.)
We deﬁne an atlas for M to be a collection of charts whose domains cover
M. An atlas A is called a smooth atlas if any two charts in A are smoothly
compatible with each other.
In practice, to show that the charts of an atlas are smoothly compatible,
it suﬃces to check that the transition map ψ ◦ϕ−1 is smooth for every
pair of coordinate maps ϕ and ψ, for then reversing the roles of ϕ and ψ
shows that the inverse map (ψ ◦ϕ−1)−1 = ϕ ◦ψ−1 is also smooth, so each
transition map is in fact a diﬀeomorphism. We will use this observation
without further comment in what follows.
Our plan is to deﬁne a “smooth structure” on M by giving a smooth atlas,
and to deﬁne a function f : M →R to be smooth if and only if f ◦ϕ−1 is
smooth (in the ordinary sense of functions deﬁned on open subsets of Rn)
for each coordinate chart (U, ϕ) in the atlas. There is one minor technical
problem with this approach: In general, there will be many possible choices
of atlas that give the “same” smooth structure, in that they all determine
the same collection of smooth functions on M. For example, consider the

Smooth Structures
9
following pair of atlases on Rn:
A1 = {(Rn, Id)}
A2 = {(B1(x), Id) : x ∈Rn},
where B1(x) is the unit ball around x and Id is the identity map. Although
these are diﬀerent smooth atlases, clearly they determine the same collec-
tion of smooth functions on the manifold Rn (namely, those functions that
are smooth in the sense of ordinary calculus).
We could choose to deﬁne a smooth structure as an equivalence class of
smooth atlases under an appropriate equivalence relation. However, it is
more straightforward to make the following deﬁnition. A smooth atlas A
on M is maximal if it is not contained in any strictly larger smooth atlas.
This just means every chart that is smoothly compatible with every chart
in A is already in A. (Such a smooth atlas is also said to be complete.)
Now we can deﬁne the main concept of this chapter. A smooth structure
on a topological n-manifold M is a maximal smooth atlas. A smooth mani-
fold is a pair (M, A), where M is a topological manifold and A is a smooth
structure on M. When the smooth structure is understood, we usually omit
mention of it and just say “M is a smooth manifold.” Smooth structures are
also called diﬀerentiable structures or C∞structures by some authors. We
will use the term smooth manifold structure to mean a manifold topology
together with a smooth structure.
We emphasize that a smooth structure is an additional piece of data
that must be added to a topological manifold before we are entitled to talk
about a “smooth manifold.” In fact, a given topological manifold may have
many diﬀerent smooth structures (we will return to this issue in the next
chapter). And it should be noted that it is not always possible to ﬁnd any
smooth structure—there exist topological manifolds that admit no smooth
structures at all.
It is worth mentioning that the notion of smooth structure can be gen-
eralized in several diﬀerent ways by changing the compatibility require-
ment for charts. For example, if we replace the requirement that charts be
smoothly compatible by the weaker requirement that each transition map
ψ ◦ϕ−1 (and its inverse) be of class Ck, we obtain the deﬁnition of a Ck
structure. Similarly, if we require that each transition map be real-analytic
(i.e., expressible as a convergent power series in a neighborhood of each
point), we obtain the deﬁnition of a real-analytic structure, also called a
Cω structure. If M has even dimension n = 2m, we can identify R2m with
Cm and require that the transition maps be complex analytic; this deter-
mines a complex analytic structure. A manifold endowed with one of these
structures is called a Ck manifold, real-analytic manifold, or complex man-
ifold, respectively. (Note that a C0 manifold is just a topological manifold.)
We will not treat any of these other kinds of manifolds in this book, but
they play important roles in analysis, so it is useful to know the deﬁnitions.

10
1. Smooth Manifolds
Without further qualiﬁcation, every manifold mentioned in this book
will be assumed to be a smooth manifold endowed with a speciﬁc smooth
structure. In particular examples, the smooth structure will usually be
obvious from the context. If M is a smooth manifold, any chart contained
in the given maximal smooth atlas will be called a smooth chart, and the
corresponding coordinate map will be called a smooth coordinate map.
It is generally not very convenient to deﬁne a smooth structure by ex-
plicitly describing a maximal smooth atlas, because such an atlas contains
very many charts. Fortunately, we need only specify some smooth atlas, as
the next lemma shows.
Lemma 1.4. Let M be a topological manifold.
(a) Every smooth atlas for M is contained in a unique maximal smooth
atlas.
(b) Two smooth atlases for M determine the same maximal smooth atlas
if and only if their union is a smooth atlas.
Proof. Let A be a smooth atlas for M, and let A denote the set of all charts
that are smoothly compatible with every chart in A. To show that A is a
smooth atlas, we need to show that any two charts of A are compatible with
each other, which is to say that for any (U, ϕ), (V, ψ) ∈A, ψ ◦ϕ−1 : ϕ(U ∩
V ) →ψ(U ∩V ) is smooth.
Let x = ϕ(p) ∈ϕ(U ∩V ) be arbitrary. Because the domains of the charts
in A cover M, there is some chart (W, θ) ∈A such that p ∈W. Since every
chart in A is smoothly compatible with (W, θ), both the maps θ ◦ϕ−1 and
ψ ◦θ−1 are smooth where they are deﬁned. Since p ∈U ∩V ∩W, it follows
that ψ ◦ϕ−1 = (ψ ◦θ−1)◦(θ ◦ϕ−1) is smooth on a neighborhood of x. Thus
ψ ◦ϕ−1 is smooth in a neighborhood of each point in ϕ(U ∩V ). Therefore
A is a smooth atlas. To check that it is maximal, just note that any chart
that is smoothly compatible with every chart in A must in particular be
smoothly compatible with every chart in A, so it is already in A. This
proves the existence of a maximal smooth atlas containing A. If B is any
other maximal smooth atlas containing A, each of its charts is smoothly
compatible with each chart in A, so B ⊂A. By maximality of B, B = A.
The proof of (b) is left as an exercise.
Exercise 1.5.
Prove Lemma 1.4(b).
For example, if a topological manifold M can be covered by a single
chart, the smooth compatibility condition is trivially satisﬁed, so any such
chart automatically determines a smooth structure on M.

Examples
11
Examples
Before proceeding further with the general theory, let us establish some
examples of smooth manifolds.
Example 1.5 (Euclidean spaces). Rn is a smooth n-manifold with the
smooth structure determined by the atlas consisting of the single chart
(Rn, Id). We call this the standard smooth structure, and the resulting co-
ordinate map standard coordinates. Unless we explicitly specify otherwise,
we will always use this smooth structure on Rn.
Example 1.6 (Finite-dimensional vector spaces).
Let V
be any
ﬁnite-dimensional vector space. Any norm on V determines a topology,
which is independent of the choice of norm (Exercise A.21 in the Appen-
dix). With this topology, V has a natural smooth structure deﬁned as fol-
lows. Any (ordered) basis (E1, . . . , En) for V deﬁnes a linear isomorphism
E : Rn →V by
E(x) =
n
X
i=1
xiEi.
This map is a homeomorphism, so the atlas consisting of the single chart
(V, E−1) deﬁnes a smooth structure. To see that this smooth structure
is independent of the choice of basis, let ( eE1, . . . , eEn) be any other basis
and let eE(x) = P
j xj eEj be the corresponding isomorphism. There is some
invertible matrix (Aj
i) such that Ei = P
j Aj
i eEj for each j. The transition
map between the two charts is then given by eE−1 ◦E(x) = ex, where
ex = (ex1, . . . , exn) is determined by
n
X
j=1
exj eEj =
n
X
i=1
xiEi =
n
X
i,j=1
xiAj
i eEj.
It follows that exj = P
i Aj
ixi. Thus the map from x to ex is an invertible
linear map and hence a diﬀeomorphism, so the two charts are smoothly
compatible. This shows that the union of the two charts determined by
any two bases is still a smooth atlas, and thus all bases determine the same
smooth structure. We will call this the standard smooth structure on V .
The Einstein Summation Convention
This is a good place to pause and introduce an important notational con-
vention that we will use throughout the book. Because of the proliferation
of summations such as P
i xiEi in this subject, we will often abbreviate
such a sum by omitting the summation sign, as in
E(x) = xiEi.

12
1. Smooth Manifolds
We interpret any such expression according to the following rule, called
the Einstein summation convention: If the same index name (such as i in
the expression above) appears twice in any term, once as an upper index
and once as a lower index, that term is understood to be summed over
all possible values of that index, generally from 1 to the dimension of the
space in question. This simple idea was introduced by Einstein to reduce
the complexity of the expressions arising in the study of smooth manifolds
by eliminating the necessity of explicitly writing summation signs.
Another important aspect of the summation convention is the positions
of the indices. We will always write basis vectors (such as Ei) with lower
indices, and components of a vector with respect to a basis (such as xi) with
upper indices. These index conventions help to ensure that, in summations
that make mathematical sense, any index to be summed over will typically
appear twice in any given term, once as a lower index and once as an upper
index.
To be consistent with our convention of writing components of vectors
with upper indices, we need to use upper indices for the coordinates of
a point (x1, . . . , xn) ∈Rn, and we will do so throughout this book. Al-
though this may seem awkward at ﬁrst, in combination with the summa-
tion convention it oﬀers enormous advantages when working with compli-
cated indexed sums, not the least of which is that expressions that are not
mathematically meaningful often identify themselves quickly by violating
the index convention. (The main exceptions are the Euclidean dot product
x · y = P
i xiyi, in which i appears twice as an upper index, and certain
expressions involving matrices. We will always explicitly write summation
signs in such expressions.)
More Examples
Now we continue with our examples of smooth manifolds.
Example 1.7 (Matrices).
Let M(m × n, R) denote the space of m × n
matrices with real entries. It is a vector space of dimension mn under ma-
trix addition and scalar multiplication. Thus M(m×n, R) is a smooth mn-
dimensional manifold. Similarly, the space M(m × n, C) of m × n complex
matrices is a vector space of dimension 2mn over R, and thus a manifold
of dimension 2mn. In the special case m = n (square matrices), we will
abbreviate M(n × n, R) and M(n × n, C) by M(n, R) and M(n, C), respec-
tively.
Example 1.8 (Open Submanifolds). Let U be any open subset of Rn.
Then U is a topological n-manifold, and the single chart (U, Id) deﬁnes a
smooth structure on U.

Examples
13
More generally, let M be a smooth n-manifold and U ⊂M any open
subset. Deﬁne an atlas on U by
AU = {smooth charts (V, ϕ) for M such that V ⊂U}.
It is easy to verify that this is a smooth atlas for U. Thus any open subset
of a smooth n-manifold is itself a smooth n-manifold in a natural way. We
call such a subset an open submanifold of M.
Example 1.9 (The General Linear Group).
The
general
linear
group GL(n, R) is the set of invertible n × n matrices with real entries.
It is an n2-dimensional manifold because it is an open subset of the n2-
dimensional vector space M(n, R), namely the set where the (continuous)
determinant function is nonzero.
Example 1.10 (Matrices of Maximal Rank).
The previous example
has a natural generalization to rectangular matrices of maximal rank. Sup-
pose m < n, and let Mm(m × n, R) denote the subset of M(m × n, R)
consisting of matrices of rank m. If A is an arbitrary such matrix, the fact
that rank A = m means that A has some nonsingular m × m minor. By
continuity of the determinant function, this same minor has nonzero de-
terminant on some neighborhood of A in M(m × n, R), which implies that
A has a neighborhood contained in Mm(m × n, R). Thus Mm(m × n, R) is
an open subset of M(m × n, R), and therefore is itself an mn-dimensional
manifold. A similar argument shows that Mn(m × n, R) is an mn-manifold
when n < m.
Exercise 1.6.
If k is an integer between 0 and min(m, n), show that the
set of m × n matrices whose rank is at least k is an open submanifold of
M(m × n, R).
Example 1.11 (Spheres). We showed in Example 1.2 that the n-sphere
Sn ⊂Rn+1 is a topological n-manifold. We put a smooth structure on Sn
as follows. For each i = 1, . . . , n + 1, let (U ±
i , ϕ±
i ) denote the coordinate
chart we constructed in Example 1.2. For any distinct indices i and j, the
transition map ϕ±
j ◦(ϕ±
i )−1 is easily computed. In the case i < j, we get
ϕ±
j ◦(ϕ±
i )−1(u1, . . . , un) =

u1, . . . , bui, . . . , ±
p
1 −|u|2, . . . , un
,
and a similar formula holds when i > j. When i = j, an even simpler com-
putation gives ϕ±
i ◦(ϕ±
i ) = IdBn. Thus the collection of charts {(U ±
i , ϕ±
i )}
is a smooth atlas, and so deﬁnes a smooth structure on Sn. We call this
its standard smooth structure. The coordinates deﬁned above will be called
graph coordinates, because they arise from considering the sphere locally
as the graph of the function ui = ±
p
1 −|u|2.

14
1. Smooth Manifolds
Exercise 1.7.
By identifying R2 with C in the usual way, we can think
of the unit circle S1 as a subset of the complex plane. An angle function on
a subset U ⊂S1 is a continuous function θ: U →R such that eiθ(p) = p
for all p ∈U. Show that there exists an angle function θ on an open subset
U ⊂S1 if and only if U ̸= S1. For any such angle function, show that (U, θ)
is a smooth coordinate chart for S1 with its standard smooth structure.
Example 1.12 (Projective spaces). The n-dimensional real projective
space Pn is a topological n-manifold by Example 1.3. We will show that
the coordinate charts (Ui, ϕi) constructed in that example are all smoothly
compatible. Assuming for convenience that i > j, it is straightforward to
compute that
ϕj ◦ϕ−1
i
(u1, . . . , un)
=
u1
uj , . . . , uj−1
uj , uj+1
uj , . . . , ui−1
uj , 1
uj , ui+1
uj , . . . , un
uj

,
which is a diﬀeomorphism from ϕi(Ui ∩Uj) to ϕj(Ui ∩Uj).
Example 1.13 (Product Manifolds).
Suppose
M1, . . . , Mk
are
smooth manifolds of dimensions n1, . . . , nk respectively. The product
space M1 × · · · × Mk is Hausdorﬀby Exercise 1.2 and second countable
by Exercise 1.3. Given a smooth chart (Ui, ϕi) for each Mi, the map
ϕ1 × · · · × ϕk : U1 × · · · × Uk →Rn1+···+nk is a homeomorphism onto its
image, which is an open subset of Rn1+···+nk. Thus the product set is a
topological manifold of dimension n1 + · · · + nk, with charts of the form
(U1 ×· · ·×Uk, ϕ1 ×· · ·×ϕk). Any two such charts are smoothly compatible
because, as is easily veriﬁed,
(ψ1 × · · · × ψk) ◦(ϕ1 × · · · × ϕk)−1 = (ψ1 ◦ϕ−1
1 ) × · · · × (ψk ◦ϕ−1
k ),
which is a smooth map. This deﬁnes a natural smooth manifold structure
on the product, called the product smooth manifold structure. For example,
this yields a smooth manifold structure on the n-dimensional torus Tn =
S1 × · · · × S1.
In each of the examples we have seen so far, we have constructed a smooth
manifold structure in two stages: We started with a topological space and
checked that it was a topological manifold, and then we speciﬁed a smooth
structure. It is often more convenient to combine these two steps into a
single construction, especially if we start with a set or a topological space
that is not known a priori to be a topological manifold. The following
lemma provides a shortcut.
Lemma 1.14 (One-Step Smooth Manifold Structure).
Let M be a
set, and suppose we are given a collection {Uα} of subsets of M, together
with an injective map ϕα : Uα →Rn for each α, such that the following
properties are satisﬁed.

Examples
15
(i) For each α, eUα = ϕα(Uα) is an open subset of Rn.
(ii) For each α and β, ϕα(Uα ∩Uβ) and ϕβ(Uα ∩Uβ) are open in Rn.
(iii) Whenever Uα ∩Uβ ̸= ∅, ϕβ ◦ϕ−1
α : ϕα(Uα ∩Uβ) →ϕβ(Uα ∩Uβ) is
smooth.
(iv) Countably many of the sets Uα cover M.
(v) Whenever p, q are distinct points in M, either there exists some Uα
containing both p and q or there exist disjoint sets Uα, Uβ with p ∈Uα
and q ∈Uβ.
Then M has a unique smooth manifold structure such that each (Uα, ϕα)
is a smooth chart.
Proof. We deﬁne the topology by taking the sets of the form ϕ−1
α (V ), where
V ⊂eUα is open, as a basis. To prove that this is a basis for a topology, let
ϕ−1
α (V ) and ϕ−1
β (W) be two such basis sets. Properties (ii) and (iii) imply
that ϕα ◦ϕ−1
β (W) is an open subset of ϕα(Uα ∩Uβ), and therefore also of
eUα. Thus if p is any point in ϕ−1
α (V ) ∩ϕ−1
β (W), then
ϕ−1
α (V ∩ϕα ◦ϕ−1
β (W)) = ϕ−1
α (V ) ∩ϕ−1
β (W)
is a basis open set containing p. Each of the maps ϕα is then a homeomor-
phism (essentially by deﬁnition), so M is locally Euclidean of dimension n.
If {Uαi} is a countable collection of the sets Uα covering M, each of the
sets Uαi has a countable basis, and the union of all these is a countable
basis for M, so M is second countable, and the Hausdorﬀproperty follows
easily from (v). Finally, (iii) guarantees that the collection {(Uα, ϕα)} is a
smooth atlas. It is clear that this topology and smooth structure are the
unique ones satisfying the conclusions of the lemma.
Example 1.15 (Grassmann Manifolds).
Let V be an n-dimensional
real vector space. For any integer 0 ≤k ≤n, we let Gk(V ) denote the set
of all k-dimensional linear subspaces of V . We will show that Gk(V ) can be
naturally given the structure of a smooth manifold of dimension k(n −k).
The construction is somewhat more involved than the ones we have done
so far, but the basic idea is just to use linear algebra to construct charts for
Gk(V ) and then use Lemma 1.14 to show that these charts yield a smooth
manifold structure. Since we will give a more straightforward proof that
Gk(V ) is a smooth manifold after we have developed more machinery in
Chapter 7, you may skip the details of this construction on ﬁrst reading if
you wish.
Let P and Q be any complementary subspaces of V of dimensions k and
(n−k), respectively, so that V decomposes as a direct sum: V = P ⊕Q. The

16
1. Smooth Manifolds
graph of any linear map A: P →Q is a k-dimensional subspace Γ(A) ⊂V ,
deﬁned by
Γ(A) = {x + Ax : x ∈P}.
Any such subspace has the property that its intersection with Q is the zero
subspace. Conversely, any subspace with this property is easily seen to be
the graph of a unique linear map A: P →Q.
Let L(P, Q) denote the vector space of linear maps from P to Q, and
let UQ denote the subset of Gk(V ) consisting of k-dimensional subspaces
whose intersection with Q is trivial. Deﬁne a map ψ: L(P, Q) →UQ by
ψ(A) = Γ(A).
The discussion above shows that ψ is a bijection. Let ϕ = ψ−1 : UQ →
L(P, Q). By choosing bases for P and Q, we can identify L(P, Q) with
M((n−k)×k, R) and hence with Rk(n−k), and thus we can think of (UQ, ϕ)
as a coordinate chart. Since the image of each chart is all of L(P, Q), con-
dition (i) of Lemma 1.14 is clearly satisﬁed.
Now let (P ′, Q′) be any other such pair of subspaces, and let ψ′, ϕ′ be
the corresponding maps. The set ϕ(UQ ∩UQ′) ⊂L(P, Q) consists of all
A ∈L(P, Q) whose graphs intersect both Q and Q′ trivially, which is easily
seen to be an open set, so (ii) holds. We need to show that the transition
map ϕ′ ◦ϕ−1 = ϕ′ ◦ψ is smooth on this set. This is the trickiest part of
the argument.
Suppose A ∈ϕ(UQ ∩UQ′) ⊂L(P, Q) is arbitrary, and let S denote the
subspace ψ(A) = Γ(A) ⊂V . If we put A′ = ϕ′◦ψ(A), then A′ is the unique
linear map from P ′ to Q′ whose graph is equal to S. To identify this map,
let x′ ∈P ′ be arbitrary, and note that A′x′ is the unique element of Q′
such that x′ + A′x′ ∈S, which is to say that
x′ + A′x′ = x + Ax
for some x ∈P.
(1.1)
(See Figure 1.3.) There is in fact a unique x ∈P for which this holds,
characterized by the property that
x + Ax −x′ ∈Q′.
If we let IA : P →V denote the map IA(x) = x + Ax and let πP ′ : V →P ′
be the projection onto P ′ with kernel Q′, then x satisﬁes
0 = πP ′(x + Ax −x′) = πP ′ ◦IA(x) −x′.
As long as A stays in the open subset of maps whose graphs intersect both
Q and Q′ trivially, πP ′ ◦IA : P →P ′ is invertible, and thus we can solve
this last equation for x to obtain x = (πP ′ ◦IA)−1(x′). Therefore, A′ is
given in terms of A by
A′x′ = IAx −x′ = IA ◦(πP ′ ◦IA)−1(x′) −x′.
(1.2)

Examples
17
P
Q
S
P ′
Q′
x
x′
Ax
A′x′
FIGURE 1.3. Smooth compatibility of coordinates on Gk(V ).
If we choose bases (E′
i) for P ′ and (F ′
j) for Q′, the columns of the matrix
representation of A′ are the components of A′E′
i. By (1.2), this can be
written
A′E′
i = IA ◦(πP ′ ◦IA)−1(E′
i) −E′
i.
The matrix entries of IA clearly depend smoothly on those of A, and thus so
also do those of πP ′ ◦IA. By Cramer’s rule, the components of the inverse of
a matrix are rational functions of the matrix entries, so the expression above
shows that the components of A′E′
i depend smoothly on the components
of A. This proves that ϕ′ ◦ϕ−1 is a smooth map, so the charts we have
constructed satisfy condition (iii) of Lemma 1.14.
To check the countability condition (iv), we just note that Gk(V ) can in
fact be covered by ﬁnitely many of the sets UQ: For example, if (E1, . . . , En)
is any ﬁxed basis for V , any partition of the basis elements into two subsets
containing k and n −k elements determines appropriate subspaces P and
Q, and any subspace S must have trivial intersection with Q for at least
one of these partitions (see Exercise A.4). Thus Gk(V ) is covered by the
ﬁnitely many charts determined by all possible partitions of a ﬁxed basis.
Finally, the Hausdorﬀcondition (v) is easily veriﬁed by noting that for any
two k-dimensional subspaces P, P ′ ⊂V , it is possible to ﬁnd a subspace Q
of dimension n −k whose intersections with both P and P ′ are trivial, and
then P and P ′ are both contained in the domain of the chart determined
by, say, (P, Q).
The smooth manifold Gk(V ) is called the Grassmann manifold of k-
planes in V , or simply a Grassmannian. In the special case V = Rn, the
Grassmannian Gk(Rn) is often denoted by some simpler notation such as
Gk,n or G(k, n). Note that G1(Rn+1) is exactly the n-dimensional projective
space Pn.

18
1. Smooth Manifolds
U
eU
ϕ
FIGURE 1.4. A coordinate grid.
Exercise 1.8.
Let 0 < k < n be integers, and let P, Q ⊂Rn be the
subspaces spanned by (e1, . . . , ek) and (ek+1, . . . , en), respectively, where ei
is the ith standard basis vector. For any k-dimensional subspace S ⊂Rn
that has trivial intersection with Q, show that the coordinate representation
ϕ(S) constructed in the preceding example is the unique (n−k)×k matrix B
such that S is spanned by the columns of the matrix
ÿIk
B
þ
, where Ik denotes
the k × k identity matrix.
Local Coordinate Representations
Here is how one usually thinks about local coordinate charts on a smooth
manifold. Once we choose a chart (U, ϕ) on M, the coordinate map ϕ: U →
eU ⊂Rn can be thought of as giving an identiﬁcation between U and eU.
Using this identiﬁcation, we can think of U simultaneously as an open
subset of M and (at least temporarily while we work with this chart) as
an open subset of Rn. You can visualize this identiﬁcation by thinking of a
“grid” drawn on U representing the inverse images of the coordinate lines
under ϕ (Figure 1.4). Under this identiﬁcation, we can represent a point
p ∈M by its coordinates (x1, . . . , xn) = ϕ(p), and think of this n-tuple as
being the point p. We will typically express this by saying “(x1, . . . , xn) is
the (local) coordinate representation for p” or “p = (x1, . . . , xn) in local
coordinates.”

Manifolds With Boundary
19
FIGURE 1.5. A manifold with boundary.
Another way to look at it is that by means of our identiﬁcation U ↔eU,
we can think of ϕ as the identity map and suppress it from the notation.
This takes a bit of getting used to, but the payoﬀis a huge simpliﬁcation
of the notation in many situations. You just need to remember that the
identiﬁcation depends heavily on the choice of coordinate chart.
For example, if M = R2, let U = {(x, y) : x > 0} be the open right
half-plane, and let ϕ: U →R2 be the polar coordinate map ϕ(x, y) =
(r, θ) = (
p
x2 + y2, arctan y/x). We can write a given point p ∈U ei-
ther as p = (x, y) in standard coordinates or as p = (r, θ) in po-
lar coordinates, where the two coordinate representations are related by
(r, θ) = (
p
x2 + y2, arctany/x) and (x, y) = (r cos θ, r sin θ).
Manifolds With Boundary
For some purposes, we will need the following generalization of manifolds.
An n-dimensional topological manifold with boundary is a second count-
able Hausdorﬀspace in which every point has a neighborhood homeo-
morphic to an open subset of the closed n-dimensional upper half space
Hn = {(x1, . . . , xn) ∈Rn : xn ≥0} (Figure 1.5). An open subset U ⊂M
together with a homeomorphism ϕ from U to an open subset of Hn is called
a generalized chart for M.
The boundary of Hn in Rn is the set of points where xn = 0. If M is a
manifold with boundary, a point that is in the inverse image of ∂Hn under
some generalized chart is called a boundary point of M, and a point that is
in the inverse image of IntHn is called an interior point. The boundary of
M (the set of all its boundary points) is denoted ∂M; similarly its interior
is denoted Int M.

20
1. Smooth Manifolds
Be careful to observe the distinction between this use of the terms
“boundary” and “interior” and their usage to refer to the boundary and
interior of a subset of a topological space. A manifold M with boundary
may have nonempty boundary in this new sense, irrespective of whether it
has a boundary as a subset of some other topological space. If we need to
emphasize the diﬀerence between the two notions of boundary, we will use
the terms topological boundary or manifold boundary as appropriate.
To see how to deﬁne a smooth structure on a manifold with boundary,
recall that a smooth map from an arbitrary subset A ⊂Rn is deﬁned
to be one that extends smoothly to an open neighborhood of A (see the
Appendix). Thus if U is an open subset of Hn, a smooth map F : U →Rk
is a map that extends to a smooth map eF : eU →Rk, where eU is some open
subset of Rn containing U. If F is such a map, by continuity all the partial
derivatives of F at points of ∂Hn are determined by their values in Hn,
and therefore in particular are independent of the choice of extension. It is
a fact (which we will neither prove nor use) that F : U →Rk has such a
smooth extension if and only if F is continuous, F|U∩Int Hn is smooth, and
each of the partial derivatives of F|U∩Int Hn has a continuous extension to
U ∩Hn.
For example, let B2 ⊂R2 denote the unit disk, let U = B2 ∩H2, and
deﬁne f : U →R by f(x, y) =
p
1 −x2 −y2. Because f extends to all of
B2 (by the same formula), f is a smooth function on U. On the other hand,
although g(x, y) = √y is continuous on U and smooth in U ∩Int H2, it has
no smooth extension to any neighborhood of U in R2 because ∂g/∂y →∞
as y →0. Thus g is not a smooth function on U.
Given a topological manifold with boundary M, we deﬁne an atlas for
M as before to be a collection of generalized charts whose domains cover
M. Two such charts (U, ϕ), (V, ψ) are smoothly compatible if ψ ◦ϕ−1 is
smooth (in the sense just described) wherever it is deﬁned. Just as in the
case of manifolds, a smooth atlas for M is an atlas all of whose charts are
smoothly compatible with each other, and a smooth structure for M is a
maximal smooth atlas.
It can be shown using homology theory that the interior and boundary
of a topological manifold with boundary are disjoint (see [Lee00, Problem
13-9], for example). We will not need this result, because the analogous
result for smooth manifolds with boundary is much easier to prove (or will
be, after we have developed a bit more machinery). A proof is outlined in
Problem 5-19.
Since any open ball in Rn admits a diﬀeomorphism onto an open sub-
set of Hn, a smooth n-manifold is automatically a smooth n-manifold with
boundary (whose boundary is empty), but the converse is not true: A man-
ifold with boundary is a manifold if and only if its boundary is empty. (This
will follow from the fact that interior points and boundary points are dis-
tinct.)

Problems
21
Problems
1-1. Let X be the set of all points (x, y) ∈R2 such that y = ±1, and
let M be the quotient of X by the equivalence relation generated by
(x, −1) ∼(x, 1) for all x ̸= 0. Show that M is locally Euclidean and
second countable, but not Hausdorﬀ. [This space is called the line
with two origins.]
1-2. Show that the disjoint union of uncountably many copies of R is
locally Euclidean and Hausdorﬀ, but not second countable.
1-3. Let N = (0, . . . , 0, 1) be the “north pole” and S = −N the “south
pole.” Deﬁne stereographic projection σ: Sn ∖{N} →Rn by
σ(x1, . . . , xn+1) = (x1, . . . , xn)
1 −xn+1
.
Let eσ(x) = σ(−x) for x ∈Sn ∖{S}.
(a) Show that σ is bijective, and
σ−1(u1, . . . , un) = (2u1, . . . , 2un, |u|2 −1)
|u|2 + 1
.
(b) Compute the transition map eσ ◦σ−1 and verify that the atlas
consisting of the two charts (Sn ∖{N}, σ) and (Sn ∖{S}, eσ)
deﬁnes a smooth structure on Sn. (The coordinates deﬁned by
σ or eσ are called stereographic coordinates.)
(c) Show that this smooth structure is the same as the one deﬁned
in Example 1.11.
1-4. Let M be a smooth n-manifold with boundary. Show that Int M is
a smooth n-manifold and ∂M is a smooth (n −1)-manifold (both
without boundary).
1-5. Let M = Bn, the closed unit ball in Rn. Show that M is a mani-
fold with boundary and has a natural smooth structure such that its
interior is the open unit ball with its standard smooth structure.

22
1. Smooth Manifolds

2
Smooth Maps
The main reason for introducing smooth structures was to enable us to
deﬁne smooth functions on manifolds and smooth maps between manifolds.
In this chapter, we will carry out that project.
Although the terms “function” and “map” are technically synonymous,
when studying smooth manifolds it is often convenient to make a slight dis-
tinction between them. Throughout this book, we will generally reserve the
term “function” for a map whose range is R (a real-valued function) or Rk
for some k > 1 (a vector-valued function). The word “map” or “mapping”
can mean any type of map, such as a map between arbitrary manifolds.
We begin by deﬁning smooth real-valued and vector-valued functions,
and then generalize this to smooth maps between manifolds. We then study
diﬀeomorphisms, which are bijective smooth maps with smooth inverses. If
there is a diﬀeomorphism between two manifolds, we say they are diﬀeomor-
phic. The main objects of study in smooth manifold theory are properties
that are invariant under diﬀeomorphisms.
Later in the chapter, we study smooth covering maps, and their relation-
ship to the continuous covering maps studied in topology; and we introduce
Lie groups, which are smooth manifold that are also groups in which mul-
tiplication and inversion are smooth maps.
At the end of the chapter, we introduce some powerful tools for smoothly
piecing together local smooth objects, called bump functions and partitions
of unity. They will be used throughout the book for building global smooth
objects out of ones that are initially deﬁned only locally.

24
2. Smooth Maps
Smooth Functions and Smooth Maps
If M is a smooth manifold, a function f : M →Rk is said to be smooth
if, for every smooth chart (U, ϕ) on M, the composite function f ◦ϕ−1
is smooth on the open subset ϕ(U) ⊂Rn. The most important special
case is that of smooth real-valued functions f : M →R; the set of all such
functions is denoted by C∞(M). Because sums and constant multiplies of
smooth functions are smooth, C∞(M) is a vector space. In fact, it is a ring
under pointwise multiplication, as you can easily verify.
Although by deﬁnition smoothness of f means that its composition with
every smooth coordinate map is smooth, in practice it suﬃces to check
smoothness in each of the charts of some smooth atlas, as the next lemma
shows.
Lemma 2.1. Suppose {(Uα, ϕα)} is a smooth atlas for M. If f : M →Rk
is a function such that f ◦ϕ−1
α
is smooth for each α, then f is smooth.
Proof. We just need to check that f ◦ϕ−1 is smooth for any smooth chart
(U, ϕ) on M. It suﬃces to show it is smooth in a neighborhood of each
point x = ϕ(p) ∈ϕ(U). For any p ∈U, there is a chart (Uα, ϕα) in the
atlas whose domain contains p. Since (U, ϕ) is smoothly compatible with
(Uα, ϕα), the transition map ϕα◦ϕ−1 is smooth on its domain of deﬁnition,
which includes x. Thus f ◦ϕ−1 = (f ◦ϕ−1
α ) ◦(ϕα ◦ϕ−1) is smooth in a
neighborhood of x.
Given a function f : M →Rk and a chart (U, ϕ) for M, the function
bf : ϕ(U) →Rk deﬁned by bf(x) = f ◦ϕ−1(x) is called the coordinate rep-
resentation of f. For example, consider f(x, y) = x2 + y2 on the plane.
In polar coordinates, it has the coordinate representation bf(r, θ) = r2. In
keeping with our practice of using local coordinates to identify U with a
subset of Euclidean space, in cases where it will cause no confusion we will
often not even observe the distinction between bf and f itself, and write
f(r, θ) = r2 in polar coordinates. Thus, we might say “f is smooth on U
because its coordinate representation f(r, θ) = r2 is smooth.”
The deﬁnition of smooth functions generalizes easily to maps between
manifolds. Let M, N be smooth manifolds, and let F : M →N be any
map. We say F is a smooth map if, for any smooth charts (U, ϕ) for M and
(V, ψ) for N, the composite map ψ◦F ◦ϕ−1 is smooth from ϕ(U ∩F −1(V ))
to ψ(V ). Note that our previous deﬁnition of smoothness of real-valued
functions can be viewed as a special case of this one, by taking N = Rk
and ψ = Id.
Exercise 2.1 (Smoothness is Local).
Let F : M →N be a map be-
tween smooth manifolds, and suppose each point p ∈M has a neighborhood
U such that F|U is smooth. Show that F is smooth.

Smooth Functions and Smooth Maps
25
We call bF = ψ◦F ◦ϕ−1 the coordinate representation of F with respect to
the given coordinates. As with real-valued or vector-valued functions, once
we have chosen speciﬁc local coordinates in both the domain and range, we
can often ignore the distinction between F and bF.
Just as for functions, to prove that a map is smooth it suﬃces to show
that its coordinate representatives with respect to a particular smooth atlas
are smooth. The proof is analogous to that of Lemma 2.1 and is left as an
exercise.
Lemma 2.2. Let M, N be smooth manifolds and let F : M →N be any
map. If {(Uα, ϕα)} and {(Vβ, ψβ)} are smooth atlases for M and N, re-
spectively, and if for each α and β, ψβ ◦F ◦ϕ−1
α
is smooth on its domain
of deﬁnition, then F is smooth.
Exercise 2.2.
Prove Lemma 2.2.
Lemma 2.3. Any composition of smooth maps between manifolds is
smooth.
Proof. Given smooth maps F : M →N and G: N →P, let (U, ϕ) and
(V, ψ) be any charts for M and P respectively. We need to show that
ψ◦(G◦F)◦ϕ−1 is smooth where it is deﬁned, namely on ϕ(U∩(G◦F)−1(V )).
For any point p ∈U ∩(G◦F)−1(V ), there is a chart (W, θ) for N such that
F(p) ∈W. Smoothness of F and G means that θ ◦F ◦ϕ−1 and ψ ◦G ◦θ−1
are smooth where they are deﬁned, and therefore ψ ◦(G ◦F) ◦ϕ−1 =
(ψ ◦G ◦θ−1) ◦(θ ◦F ◦ϕ−1) is smooth.
Example 2.4 (Smooth maps).
(a) Consider the n-sphere Sn with its standard smooth structure. The
inclusion map ι: Sn ,→Rn+1 is certainly continuous, because it is
the inclusion map of a topological subspace. It is a smooth map be-
cause its coordinate representation with respect to any of the graph
coordinates of Example 1.11 is
bι(u1, . . . , un) = ι ◦(ϕ±
i )−1(u1, . . . , un)
=

u1, . . . , ui−1, ±
p
1 −|u|2, ui, . . . , un
,
which is smooth on its domain (the set where |u|2 < 1).
(b) The quotient map π: Rn+1 ∖{0} →Pn is smooth, because its coor-
dinate representation in terms of the coordinates for Pn constructed
in Example 1.12 and standard coordinates on Rn+1 ∖{0} is
bπ(x1, . . . , xn+1) = ϕi ◦π(x1, . . . , xn+1) = ϕi[x1, . . . , xn+1]
=
x1
xi , . . . , xi−1
xi , xi+1
xi , . . . , xn+1
xi

.

26
2. Smooth Maps
(c) Deﬁne p: Sn →Pn as the restriction of π: Rn+1 ∖{0} →Pn to
Sn ⊂Rn+1 ∖{0}. It is a smooth map, because it is the composition
p = π ◦ι of the maps in the preceding two examples.
Exercise 2.3.
Let M1, . . . , Mk and N be smooth manifolds. Show that a
map F : N →M1 ×· · ·×Mk is smooth if and only if each of the “component
maps” Fi = πi ◦F : N →Mi is smooth. (Here πi : M1 × · · · × Mk →Mi is
the projection onto the ith factor.)
The deﬁnitions of smooth functions and smooth maps on a manifold
with boundary are exactly the same as for manifolds; you can work out the
details for yourself.
Diﬀeomorphisms
A diﬀeomorphism between manifolds M and N is a smooth map F : M →
N that has a smooth inverse. We say M and N are diﬀeomorphic if there
exists a diﬀeomorphism between them. Sometimes this is symbolized by
M ≈N. For example, if Bn denotes the open unit ball in Rn, the map
F : Bn →Rn given by F(x) = x/(1 −|x|2) is easily seen to be a diﬀeomor-
phism, so Bn ≈Rn.
Exercise 2.4.
Show that “diﬀeomorphic” is an equivalence relation.
More generally, F : M →N is called a local diﬀeomorphism if every
point p ∈M has a neighborhood U such that F(U) is open in N and
F : U →F(U) is a diﬀeomorphism. It is clear from the deﬁnition that a
local diﬀeomorphism is, in particular, a local homeomorphism and therefore
an open map.
Exercise 2.5.
Show that a map F : M →N is a diﬀeomorphism if and
only if it is a bijective local diﬀeomorphism.
Just as two topological spaces are considered to be “the same” if they
are homeomorphic, two smooth manifolds are essentially indistinguishable
if they are diﬀeomorphic. The central concern of smooth manifold theory
is the study of properties of smooth manifolds that are preserved by dif-
feomorphisms.
One question that naturally arises is to what extent a smooth structure
on a given topological manifold might be unique. There are really two
diﬀerent questions here: The ﬁrst is whether a given manifold M admits
distinct smooth structures, and the second is whether it admits smooth
structures that are not diﬀeomorphic to each other.
Let us begin by addressing the ﬁrst question. It is easy to see that two
smooth structures A1, A2 on a given manifold M are the same if and only
if the identity map of M is a diﬀeomorphism from (M, A1) to (M, A2).

Smooth Functions and Smooth Maps
27
In general, a given topological manifold will admit very many distinct
smooth structures. For example, consider the two homeomorphisms ϕ: R →
R and ψ: R →R given by
ϕ(x) = x,
ψ(x) = x3.
Each of the atlases {(R, ϕ)} and {(R, ψ)} determines a smooth structure
on R. (Since there is only one chart in each case, the smooth compati-
bility condition is trivially satisﬁed.) These two charts are not smoothly
compatible with each other, because ϕ ◦ψ−1(y) = y1/3 is not smooth at
the origin. Therefore the two smooth structures on R determined by these
atlases are distinct. Using similar ideas, it is not hard to construct many
diﬀerent smooth structures on any given manifold.
The second question, whether two given smooth structures are diﬀeomor-
phic to each other, is more subtle. Consider the same two smooth structures
on R, and for the moment let Rϕ denote R with the smooth structure deter-
mined by ϕ (this is just the standard smooth structure) and Rψ the same
topological manifold but with the smooth structure determined by ψ. It
turns out that these two manifolds are diﬀeomorphic to each other. Deﬁne
a map F : Rϕ →Rψ by F(x) = x1/3. The coordinate representation of this
map is bF(t) = ψ ◦F ◦ϕ−1(t) = t, which is clearly smooth. Moreover, the
coordinate representation of its inverse is d
F −1(y) = ϕ ◦F −1 ◦ψ−1(y) = y,
which is also smooth, so F is a diﬀeomorphism. (This is one case in which it
is important to maintain the distinction between a map and its coordinate
representation!)
It turns out, as you will see later, that there is only one smooth struc-
ture on R up to diﬀeomorphism (see Problem 12-5). More precisely, if A1
and A2 are any two smooth structures on R, there exists a diﬀeomorphism
F : (R, A1) →(R, A2). In fact, it follows from work of Edwin Moise [Moi77]
and James Munkres [Mun60] that every topological manifold of dimension
less than or equal to 3 has a smooth structure that is unique up to dif-
feomorphism. The analogous question in higher dimensions turns out to
be quite deep, and is still largely unanswered. Even for Euclidean spaces,
the problem was not completely solved until late in the twentieth century.
The answer is somewhat surprising: As long as n ̸= 4, Rn has a unique
smooth structure (up to diﬀeomorphism); but R4 has uncountably many
distinct smooth structures, no two of which are diﬀeomorphic to each other!
The existence of nonstandard smooth structures on R4 (called fake R4s)
was ﬁrst proved by Simon Donaldson and Michael Freedman in 1984 as
a consequence of their work on the geometry and topology of compact
4-manifolds; the results are described in [DK90] and [FQ90].
For compact manifolds, the situation is even more interesting. For ex-
ample, in 1963, Michel Kervaire and John Milnor [KM63] showed that, up
to diﬀeomorphism, S7 has exactly 28 non-diﬀeomorphic smooth structures.

28
2. Smooth Maps
On the other hand, in all dimensions greater than 3 there are compact
topological manifolds that have no smooth structures at all. (The ﬁrst ex-
ample was found in 1960 by Kervaire [Ker60].) The problem of identifying
the number of smooth structures (if any) on topological 4-manifolds is an
active subject of current research.
Smooth Covering Maps
You are probably already familiar with the notion of a covering map be-
tween topological spaces: This is a surjective continuous map π: f
M →M
between connected, locally path connected spaces, with the property that
every point p ∈M has a neighborhood U that is evenly covered, meaning
that each component of π−1(U) is mapped homeomorphically onto U by
π. In this section, we will assume familiarity with the basic properties of
covering maps, as described for example in [Lee00, Chapters 11 and 12].
In the context of smooth manifolds, it is useful to introduce a slightly
more restrictive type of covering map. If f
M and M are connected smooth
manifolds, a smooth covering map π: f
M →M is a smooth surjective map
with the property that every p ∈M has a neighborhood U such that each
component of π−1(U) is mapped diﬀeomorphically onto U by π. In this
context, we will also say that U is evenly covered. The manifold M is
called the base of the covering, and f
M is called a covering space of M.
To distinguish this new deﬁnition from the previous one, we will often call
an ordinary (not necessarily smooth) covering map a topological covering
map. A smooth covering map is, in particular, a topological covering map.
However, it is important to bear in mind that a smooth covering map is
more than just a topological covering map that happens to be smooth—the
deﬁnition of smooth covering map requires in addition that the restriction
of π to each component of the inverse image of an evenly covered set be a
diﬀeomorphism, not just a smooth homeomorphism.
Proposition 2.5 (Properties of Smooth Coverings).
(a) Any smooth covering map is a local diﬀeomorphism and an open map.
(b) An injective smooth covering map is a diﬀeomorphism.
(c) A topological covering map is a smooth covering map if and only if it
is a local diﬀeomorphism.
Exercise 2.6.
Prove Proposition 2.5.
If π: f
M →M is any continuous map, a section of π is a continuous map
σ: M →f
M such that π ◦σ = IdM. A local section is a continuous map
σ: U →f
M deﬁned on some open set U ⊂M and satisfying the analogous
relation π ◦σ = IdU. Many of the important properties of smooth covering
maps arise from the existence of smooth local sections.

Smooth Covering Maps
29
Lemma 2.6 (Local Sections of Smooth Coverings).
Suppose
π: f
M →M is a smooth covering map. Every point of f
M is in the image
of a smooth local section of π. More precisely, for any q ∈f
M, there is a
neighborhood U of p = π(q) and a smooth local section σ: U →f
M such
that σ(p) = q.
Proof. Let U ⊂M be an evenly covered neighborhood of p. If eU is the
component of π−1(U) containing q, then π| e
U : eU →U is by hypothesis a
diﬀeomorphism. It follows that σ = (π| e
U)−1 : U →eU is a smooth local
section of π such that σ(p) = q.
One important application of local sections is the following proposition,
which gives a very simple criterion for deciding which maps out of the base
space of a covering are smooth.
Proposition 2.7. Suppose π: f
M →M is a smooth covering map and
N is any smooth manifold. A map F : M →N is smooth if and only if
F ◦π: f
M →M is smooth:
M
N.
-
F
F ◦π
@
@
@@
R
f
M
?
π
Proof. One direction is obvious by composition. Suppose conversely that
F ◦π is smooth, and let p ∈M be arbitrary. By the preceding lemma, there
is a neighborhood U of p and a smooth local section σ: U →f
M, so that
π ◦σ = IdU. Then the restriction of F to U satisﬁes
F|U = F ◦IdU = F ◦(π ◦σ) = (F ◦π) ◦σ,
which is a composition of smooth maps. Thus F is smooth on U. Since F
is smooth in a neighborhood of each point, it is smooth.
The next proposition shows that every covering space of a smooth man-
ifold is itself a smooth manifold.
Proposition 2.8. If M is a smooth manifold and π: f
M →M is any
topological covering map, then f
M has a unique smooth manifold structure
such that π is a smooth covering map.
Proof. Because π is, in particular, a local homeomorphism, it is clear that
f
M is locally Euclidean.
Let p, q be distinct points in f
M. If π(p) = π(q) and U ⊂M is an
evenly covered open set containing π(p), then the components of π−1(U)
containing p and q are disjoint open subsets of f
M separating p and q.

30
2. Smooth Maps
On the other hand, if π(p) ̸= π(q), there are disjoint open sets U and V
containing π(p) and π(q), respectively, and then π−1(U) and π−1(V ) are
open subsets of f
M separating p and q. Thus f
M is Hausdorﬀ.
The ﬁbers of π are countable, because the fundamental group of M is
countable and acts transitively on each ﬁber [Lee00, Theorems 8.11 and
11.21]. Thus if {Ui}i∈N is a countable basis for the topology of f
M, it is easy
to check that the set of all components of π−1(Ui) as i ranges over N forms
a countable basis for the topology of f
M, so f
M is second countable.
Any point p ∈M has an evenly covered neighborhood U. Shrinking U if
necessary, we may assume also that it is the domain of a coordinate map
ϕ: U →Rn. Letting eU be a component of π−1(U) and eϕ = ϕ◦π: eU →Rn,
it is clear that (eU, eϕ) is a chart on f
M. If two such charts (eU, eϕ) and (eV , eψ)
overlap, the transition map can be written
eψ ◦eϕ−1 = (ψ ◦π| e
U∩eV ) ◦(ϕ ◦π| e
U∩eV )−1
= ψ ◦π| e
U∩eV ◦(π| e
U∩eV )−1 ◦ϕ−1
= ψ ◦ϕ−1,
which is smooth. Thus the collection of all such charts deﬁnes a smooth
structure on f
M. The uniqueness of this smooth structure is left as an
exercise.
Exercise 2.7.
Prove that the smooth structure constructed above on f
M
is the unique one such that π is a smooth covering map. [Hint: Use the
existence of smooth local sections.]
Lie Groups
A Lie group is a smooth manifold G that is also a group in the algebraic
sense, with the property that the multiplication map m: G × G →G and
inversion map i: G →G, given by
m(g, h) = gh,
i(g) = g−1,
are both smooth. Because smooth maps are continuous, a Lie group is, in
particular, a topological group (a topological space with a group structure
such that the multiplication and inversion maps are continuous).
The group operation in an arbitrary Lie group will be denoted by juxta-
position, except in certain abelian groups such as Rn in which the operation
is usually written additively. It is traditional to denote the identity element
of an arbitrary Lie group by the symbol e (for German Einselement, “unit
element”), and we will follow this convention, except in speciﬁc examples
in which there are more common notations (such as I or In for the identity
matrix in a matrix group, or 0 for the identity element in Rn).

Lie Groups
31
The following alternative characterization of the smoothness condition
is sometimes useful.
Lemma 2.9. Suppose G is a smooth manifold with a group structure such
that the map G × G →G given by (g, h) 7→gh−1 is smooth. Then G is a
Lie group.
Exercise 2.8.
Prove Lemma 2.9.
Example 2.10 (Lie Groups).
Each of the following manifolds is a Lie
group with the indicated group operation.
(a) The general linear group GL(n, R) is the set of invertible n×n matri-
ces with real entries. It is a group under matrix multiplication, and
it is an open submanifold of the vector space M(n, R) as we observed
in Chapter 1. Multiplication is smooth because the matrix entries of
a product matrix AB are polynomials in the entries of A and B. In-
version is smooth because Cramer’s rule expresses the entries of A−1
as rational functions of the entries of A.
(b) The complex general linear group GL(n, C) is the group of complex
n×n matrices under matrix multiplication. It is an open submanifold
of M(n, C) and thus a 2n2-dimensional smooth manifold, and it is a
Lie group because matrix products and inverses are smooth functions
of the real and imaginary parts of the matrix entries.
(c) If V is any real or complex vector space, we let GL(V ) denote the
group of invertible linear transformations from V to itself. If V is
ﬁnite-dimensional, any basis for V determines an isomorphism of
GL(V ) with GL(n, R) or GL(n, C), with n = dim V , so GL(V ) is
a Lie group.
(d) The real number ﬁeld R and Euclidean space Rn are Lie groups un-
der addition, because the coordinates of x −y are smooth (linear!)
functions of (x, y).
(e) The set R∗of nonzero complex numbers is a 1-dimensional Lie group
under multiplication. (In fact, it is exactly GL(1, R), if we identify
a 1 × 1 matrix with the corresponding real number.) The subset R+
of positive real numbers is an open subgroup, and is thus itself a
1-dimensional Lie group.
(f) The set C∗of nonzero complex numbers is a 2-dimensional Lie group
under complex multiplication, which can be identiﬁed with GL(1, C).
(g) The circle S1 ⊂C∗is a smooth manifold and a group under complex
multiplication. Using appropriate angle functions as local coordinates
on open subsets of S1, multiplication and inversion have the smooth
coordinate expressions (θ1, θ2) 7→θ1 + θ2 and θ 7→−θ, and therefore
S1 is a Lie group, called the circle group.

32
2. Smooth Maps
(h) Any product of Lie groups is a Lie group with the product manifold
structure and the direct product group structure, as you can easily
check.
(i) The n-torus Tn = S1   
S1 is an n-dimensional abelian Lie group.
(j) Any nite or countable group with the discrete topology is a zero-
dimensional Lie group. We will call any such group a
discrete group .
Let G be an arbitrary Lie group. Any element
g 2 G denes maps
Lg; Rg : G !
G, called left translation
and right translation , respectively,
by
Lg(h) = gh;
R g(h) = hg:
Because Lg can be written as the composition of smooth maps
G
 g
 !
G  G
m
 !
G;
where g(h) = ( g; h) and m is multiplication, it follows that
Lg is smooth.
It is actually a dieomorphism of
G, because Lg 1 is a smooth inverse for






























62
3. The Tangent Bundle
Proof. Let (xi) be coordinates on a neighborhood U of p, and let Xi∂/∂xi|p
be the coordinate expression for X. If ϕ is a bump function supported in
U and with ϕ(p) = 1, the vector ﬁeld e
X deﬁned by
e
Xq =





ϕ(q)Xi
∂
∂xi

q
q ∈U,
0
q ̸∈U,
is easily seen to be a smooth vector ﬁeld whose value at p is equal to X.
We will use the notation T(M) to denote the set of all smooth vector
ﬁelds on M. It is clearly a real vector space under pointwise addition and
scalar multiplication. Moreover, vector ﬁelds can be multiplied by smooth
functions: If f ∈C∞(M) and Y ∈T(M), we obtain a new vector ﬁeld fY
by
(fY )p = f(p)Yp.
(Many authors use the notation X(M) instead of T(M). However, T(M)
is more amenable to generalization—as a rule, we will use the script letter
corresponding to the name of a bundle to denote the its space of smooth
sections.)
Exercise 3.7.
If f ∈C∞(M) and Y ∈T(M), show that fY is a smooth
vector ﬁeld.
Exercise 3.8.
Show that T(M) is a module over the ring C∞(M).
If M is a smooth manifold, we will use the term local frame for M to
mean a local frame for TM over some open subset U ⊂M. Similarly, a
global frame for M is a global frame for TM. We say M is parallelizable if
it admits a smooth global frame, which is equivalent to TM being a trivial
bundle (see Problem 3-5).
A vector ﬁeld on a manifold with boundary is deﬁned in exactly the same
way as on a manifold. All of the results of this section hold equally well in
that case.
Push-forwards of Vector Fields
If F : M →N is a smooth map and Y is a smooth vector ﬁeld on M,
then for each point p ∈M, we obtain a vector F∗Yp ∈TF (p)N by pushing
forward Yp. However, this does not in general deﬁne a vector ﬁeld on N.
For example, if F is not surjective, there is no way to decide what vector to
assign to a point q ∈N ∖F(M). If F is not injective, then for some points
of N there may be several diﬀerent vectors obtained as push-forwards of Y
from diﬀerent points of M.

Vector Fields
63
If F : M →N is smooth and Y ∈T(M), suppose there happens to be a
vector ﬁeld Z ∈T(N) with the property that for each p ∈M, F∗Yp = ZF (p).
In this case, we say the vector ﬁelds Y and Z are F-related.
Here is a useful criterion for checking that two vector ﬁelds are F-related.
Lemma 3.17. Suppose F : M →N is a smooth map, X ∈T(M), and
Y ∈T(N). Then X and Y are F-related if and only if for every smooth
function f deﬁned on an open subset of N,
X(f ◦F) = (Xf) ◦F.
(3.7)
Proof. For any p ∈M,
X(f ◦F)(p) = Xp(f ◦F)
= (F∗Xp)f,
while
(Xf) ◦F(p) = (Xf)(F(p))
= XF (p)f.
Thus (3.7) is true for all f if and only if F∗Xp = XF (p) for all p, i.e., if and
only if X and X are F-related.
It is important to remember that for a given vector ﬁeld Y and map F,
there may not be any vector ﬁeld on N that is F-related to Y . There is
one special case, however, in which there is always such a vector ﬁeld, as
the next proposition shows.
Proposition 3.18. Suppose F : M →N is a diﬀeomorphism. For every
smooth vector ﬁeld Y ∈T(M), there is a unique smooth vector ﬁeld on N
that is F-related to Y .
Proof. For Z ∈T(N) to be F-related to Y means that F∗Yp = ZF (p) for
every p ∈M. If F is a diﬀeomorphism, therefore, we deﬁne Z by
Zq = F∗(YF −1(q)).
It is clear that Z, so deﬁned, is the unique vector ﬁeld that is F-related to
Y , and it is smooth because it is equal to the composition
N
F −1
−−−→M
Y
−→TM
F∗
−→TN.
(See Exercise 3.4.)
In the situation of the preceding lemma, we will denote the unique vector
ﬁeld that is F-related to Y by F∗Y , and call it the push-forward of Y by
F. Remember, it is only when F is a diﬀeomorphism that F∗Y is deﬁned.

64
3. The Tangent Bundle
Problems
3-1. Suppose M and N are smooth manifolds with M connected, and
F : M →N is a smooth map such that F∗: TpM →TF (p)N is the
zero map for each p ∈M. Show that F is a constant map.
3-2. Let M1, . . . , Mk be smooth manifolds, and let πj : M1 × · · · × Mk →
Mj be the projection onto the jth factor. For any choices of points
pi ∈Mi, i = 1, . . . , k, show that the map
α: T(p1,...,pk)(M1 × · · · × Mk) →Tp1M1 × · · · × TpkMk
deﬁned by
α(X) = (π1∗X, . . . , πk∗X)
is an isomorphism, with inverse
α−1(X1, . . . , Xk) = (j1∗X1, . . . , jk∗Xk),
where
ji : Mi
→
M1 × · · · × Mk
is
given
by
ji(q)
=
(p1, . . . , pi−1, q, pi+1, . . . , pk). [Using this isomorphism, we will rou-
tinely identify TpM, for example, as a subspace of T(p,q)(M × N).]
3-3. If a nonempty n-manifold is diﬀeomorphic to an m-manifold, prove
that n = m.
3-4. Show that there is a smooth vector ﬁeld on S2 that vanishes at exactly
one point. [Hint: Try using stereographic projection.]
3-5. Let E be a smooth vector bundle over M. Show that E admits a
local frame over an open subset U ⊂M if and only if it admits a
local trivialization over U, and E admits a global frame if and only
if it is trivial.
3-6. Show that S1, S3, and Tn = S1 × · · · × S1 are all parallelizable. [Hint:
Consider the vector ﬁelds
X1 = −x ∂
∂w + w ∂
∂x −z ∂
∂y + y ∂
∂z,
X2 = −y ∂
∂w + z ∂
∂x + w ∂
∂y −x ∂
∂z ,
X3 = −z ∂
∂w −y ∂
∂x + x ∂
∂y + w ∂
∂z .
on S3.]
3-7. Let M be a smooth manifold and p ∈M. Show that TpM is naturally
isomorphic to the space of derivations of C∞
p
(the space of germs of
smooth functions at p).

4
The Cotangent Bundle
In this chapter, we introduce a construction that is not typically seen in
elementary calculus: tangent covectors, which are linear functionals on the
tangent space at a point p ∈M. The space of all covectors at p is a vector
space called the cotangent space at p; in linear-algebraic terms, it is the
dual space to TpM. The union of all cotangent spaces at all points of M is
a vector bundle called the cotangent bundle.
Whereas tangent vectors give us a coordinate-free interpretation of deriv-
atives of curves, it turns out that derivatives of real-valued functions on a
manifold are most naturally interpreted as tangent covectors. Thus we will
deﬁne the diﬀerential of a function as a covector ﬁeld (a smooth section of
the cotangent bundle); it is a sort of coordinate-invariant analogue of the
classical gradient.
At the end of the chapter, we deﬁne line integrals of covector ﬁelds. This
allows us to generalize the classical notion of line integrals to manifolds.
Then we explore the relationships among three closely related types of
covector ﬁelds: exact (those that are the diﬀerentials of functions), conser-
vative (those whose line integrals around closed curves are zero), and closed
(those that satisfy a certain diﬀerential equation in coordinates).
Covectors
Let V be a ﬁnite-dimensional vector space. (As usual, all of our vector
spaces are assumed to be real.) We deﬁne a covector on V to be a real-

66
4. The Cotangent Bundle
valued linear functional on V , that is, a linear map ω: V →R. The space of
all covectors on V is itself a real vector space under the obvious operations
of pointwise addition and scalar multiplication. It is denoted by V ∗and
called the dual space to V .
The most important fact about V ∗is expressed in the following propo-
sition.
Proposition 4.1. Let
V
be
a
ﬁnite-dimensional
vector
space.
If
(E1, . . . , En) is any basis for V , then the covectors (ε1, . . . , εn), deﬁned
by
εi(Ej) = δi
j =
(
1 if i = j,
0 if i ̸= j,
form a basis for V ∗, called the dual basis to (Ei). Therefore dim V ∗=
dim V .
Remark. The symbol δi
j used in this proposition, meaning 1 if i = j and 0
otherwise, is called the Kronecker delta.
Exercise 4.1.
Prove Proposition 4.1.
For example, if (ei) denotes the standard basis for Rn, we denote the dual
basis by (e1, . . . , en) (note the upper indices), and call it the standard dual
basis. These basis covectors are the linear functions from Rn to R given by
ej(v) = ej(v1, . . . , vn) = vj.
In other words, ej is just the linear functional that picks out the jth com-
ponent of a vector. In matrix notation, a linear map from Rn to R is
represented by a 1 × n matrix, i.e., a row matrix. The basis covectors can
therefore also be thought of as the linear functionals represented by the
row matrices
e1 = (1 0 . . . 0),
. . .
,
en = (0 . . . 0 1).
In general, if (Ei) is a basis for V and (εj) is its dual basis, then Propo-
sition 4.1 shows that we can express an arbitrary covector ω ∈V ∗in terms
of the dual basis as
ω = ωiεi,
where the components ωi are determined by
ωi = ω(Ei).
Then the action of ω on a vector X = XiEi is
ω(X) = ωiXi.
(4.1)

Covectors
67
We will always write basis covectors with lower indices, and components
of a covector with upper indices, because this helps to ensure that mathe-
matically meaningful expressions such as (4.1) will always follow our index
conventions: Any index that is to be summed over in a given term appears
twice, once as a subscript and once as a superscript.
Suppose V and W are vector spaces and A: V →W is a linear map. We
deﬁne a linear map A∗: W ∗→V ∗, called the dual map or transpose of A,
by
(A∗ω)(X) = ω(AX),
for ω ∈W ∗, X ∈V .
Exercise 4.2.
Show that A∗ω is actually a linear functional on V , and
that A∗is a linear map.
Proposition 4.2. The dual map satisﬁes the following properties.
(a) (A ◦B)∗= B∗◦A∗.
(b) Id∗: V ∗→V ∗is the identity map of V ∗.
Exercise 4.3.
Prove the preceding proposition.
(For those who are familiar with the language of category theory, this
proposition can be summarized by saying that the assignment that sends
a vector space to its dual space and a linear map to its dual map is a
contravariant functor from the category of real vector spaces to itself. See,
for example, [Lee00, Chapter 7].)
Aside from the fact that the dimension of V ∗is the same as that of V ,
the next most important fact about the dual space is the following.
Proposition 4.3. Let V be a ﬁnite-dimensional vector space. There is a
canonical (basis-independent) isomorphism between V and its second dual
space V ∗∗= (V ∗)∗.
Proof. Given a vector X ∈V , deﬁne a linear functional e
X on V ∗by
e
X(ω) = ω(X),
for ω ∈V ∗.
It is easy to check that e
X(ω) depends linearly on ω, so that e
X ∈V ∗∗,
and that the map X 7→e
X is linear from V to V ∗∗. To show that it is an
isomorphism, it suﬃces for dimensional reasons to verify that it is injective.
Suppose X ∈V is not zero. Extend X to a basis (X = E1, . . . , En) for V ,
and let (ε1, . . . , εn) denote the dual basis for V ∗. Then
e
X(ε1) = ε1(X) = ε1(E1) = 1 ̸= 0,
so e
X ̸= 0.

68
4. The Cotangent Bundle
Because of this proposition, the real number ω(X) obtained by applying
a covector ω to a vector X is sometimes denoted by either of the notations
⟨ω, X⟩or ⟨X, ω⟩; both expressions can be thought of either as the action of
the covector ω ∈V ∗on the vector X ∈V , or as the action of the covector
e
X ∈V ∗∗on the element ω ∈V ∗.
There is also a symmetry between bases and dual bases of a ﬁnite-
dimensional vector space V : Any basis for V determines a dual basis for
V ∗, and conversely any basis for V ∗determines a dual basis for V ∗∗= V .
It is easy to check that if (εi) is the basis for V ∗dual to a basis (Ei) for
V , then (Ei) is the basis dual to (εi).
Tangent Covectors on Manifolds
Now let M be a smooth manifold. For each p ∈M, we deﬁne the cotangent
space at p, denoted by T ∗
p M, to be the dual space to TpM:
T ∗
p M = (TpM)∗.
Elements of T ∗
p M are called tangent covectors at p, or just covectors at p.
If (xi) are local coordinates on an open subset U ⊂M, then for each
p ∈U, the coordinate basis (∂/∂xi|p) gives rise to a dual basis (εi
p). Any
covector ξ ∈T ∗
p M can thus be written uniquely as ξ = ξiεi
p, where
ξi = ξ
 
∂
∂xi

p
!
.
Suppose now that (exj) are another set of coordinates whose domain over-
laps U, and let (eεj
p) denote the basis for T ∗
p M dual to (∂/∂exj|p). We can
compute the components of the same covector ξ with respect to the new co-
ordinate system as follows. First observe that the computations in Chapter
3 show that the coordinate vector ﬁelds transform as follows:
∂
∂xi

p
= ∂exj
∂xi (p)
∂
∂exj

p
.
(4.2)
Writing ξ in both systems as
ξ = ξiεi
p = eξjeεj
p,
we can use (4.2) to compute the components ξi in terms of eξj:
ξi = ξ
 
∂
∂xi

p
!
= ξ
 
∂exj
∂xi (p)
∂
∂exj

p
!
= ∂exj
∂xi (p)eξj.
(4.3)

The Cotangent Bundle
69
As we mentioned in Chapter 3, in the early days of smooth manifold
theory, before most of the abstract coordinate-free deﬁnitions we are using
were developed, mathematicians tended to think of a tangent vector at a
point p as an assignment of an n-tuple of real numbers to each coordinate
system, with the property that the n-tuples (X1, . . . , Xn) and ( e
X1, . . . , e
Xn)
assigned to two diﬀerent coordinate systems (xi) and (exj) were related by
the transformation law that we derived in Chapter 3:
e
Xj = ∂exj
∂xi (p)Xi.
Similarly, a tangent covector was thought of as an n-tuple (ξ1, . . . , ξn) that
transforms, by virtue of (4.3), according to the following slightly diﬀerent
rule:
ξi = ∂exj
∂xi (p)eξj.
(4.4)
Since the transformation law (4.2) for the coordinate partial derivatives
follows directly from the chain rule, it can be thought of as fundamental.
Thus it became customary to call tangent covectors covariant vectors be-
cause their components transform in the same way as (“vary with”) the
coordinate partial derivatives, with the Jacobian matrix (∂exj/∂xi) multi-
plying the objects associated with the “new” coordinates (exj) to obtain
those associated with the “old” coordinates (xi). Analogously, tangent vec-
tors were called contravariant vectors, because their components transform
in the opposite way. (Remember, it was the component n-tuples that were
thought of as the objects of interest.) Admittedly, it does not make a lot of
sense, but by now the terms are well entrenched, and we will see them again
in Chapter 8. Note that this use of the terms covariant and contravariant
has nothing to do with the covariant and contravariant functors of category
theory.
The Cotangent Bundle
The disjoint union
T ∗M =
a
p∈M
T ∗
p M
is called the cotangent bundle of M.
Proposition 4.4. The cotangent bundle of a smooth manifold has a nat-
ural structure as a vector bundle of rank n over M.
Proof. The proof is essentially the same as the one we gave for the tangent
bundle. Let π: T ∗M →M be the natural projection that sends ξ ∈T ∗
p M

70
4. The Cotangent Bundle
to p ∈M. Given a coordinate chart (U, (xi)) on M, we deﬁne a chart
Φ: π−1(U) →R2n by
Φ(ξiεi
p) = (x1(p), . . . , xn(p), ξ1, . . . , ξn),
where (x1(p), . . . , xn(p)) is the coordinate representation of p ∈M, and (εi
p)
is the dual coordinate basis for T ∗
p M. (In this situation, we must forego our
insistence that coordinate functions have upper indices, because the ﬁber
coordinates ξi are already required by our index conventions to have lower
indices.)
If two charts (U, (xi)) and (eU, (exj)) overlap, then clearly exj are smooth
functions of (x1, . . . , xn), and (4.3) can be solved for eξj (by invert-
ing the Jacobian matrix) to show that eξj is a smooth function of
(x1, . . . , xn, ξ1, . . . , ξn). The arguments of Lemmas 3.12 and 3.13 then ap-
ply almost verbatim to give T ∗M the structure of a smooth vector bundle
over M.
A section of T ∗M is called a covector ﬁeld on M. As we did with vector
ﬁelds, we will write the value of a covector ﬁeld σ at a point p ∈M as
σp instead of σ(p), to avoid conﬂict with the notation for the action of
a covector on a vector. If (εi
p) is the dual coordinate basis for TpM at
each point p in some open set U ⊂M, then σ can be expressed locally as
σp = σi(p)εi
p for some functions σ1, . . . , σn : U →R, called the component
functions of σ.
A covector ﬁeld is said to be smooth if it is smooth as a map from M to
T ∗M. Smooth covector ﬁelds are called (diﬀerential) 1-forms. (The reason
for the latter terminology will become clear in Chapter 9, when we deﬁne
diﬀerential k-forms for k > 1.)
Just as in the case of vector ﬁelds, there are several ways to check for
smoothness of a covector ﬁeld. The proof is quite similar to the proof of
the analogous fact for vector ﬁelds (Lemma 3.14).
Lemma 4.5. Let M be a smooth manifold, and let σ: M →T ∗M be a
map (not assumed to be continuous) such that σp ∈T ∗
p M for each p ∈M.
The following are equivalent.
(a) σ is smooth.
(b) In any coordinate chart, the component functions σi of σ are smooth.
(c) If X is a smooth vector ﬁeld deﬁned on any open subset U ⊂M, then
the function ⟨σ, X⟩: U →R, deﬁned by
⟨σ, X⟩(p) = ⟨σp, Xp⟩= σp(Xp)
is smooth.
Exercise 4.4.
Prove Lemma 4.5.

The Diﬀerential of a Function
71
An ordered n-tuple of smooth covector ﬁelds (σ1, . . . , σn) deﬁned on some
open set U ⊂M is called a local coframe on U if (σi
p) forms a basis for
T ∗
p M at each point p ∈U. If U = M, it is called a global coframe. (A local
coframe is just a local frame for T ∗M, in the terminology introduced in
Chapter 3.) Given a local frame (E1, . . . , En) for TM over an open set U,
there is a uniquely determined smooth local coframe (ε1, . . . , εn) satisfying
εi(Ej) = δi
j. It is smooth by part (c) of the preceding lemma. This coframe
is called the dual coframe to the given frame.
Note that Lemma 4.5(b) implies, in particular, that each coordinate cov-
ector ﬁeld εi (whose value at p is the ith dual basis element εi
p) is smooth,
because each of its component functions is either identically 1 or identically
0. Thus (ε1, . . . , εn) is a smooth local coframe on the coordinate domain,
called a coordinate coframe.
We denote the set of all smooth covector ﬁelds on M by T∗(M). Given
smooth covector ﬁelds σ, τ ∈T∗(M), any linear combination aσ + bτ with
real coeﬃcients is obviously again a smooth covector ﬁeld, so T∗(M) is a
vector space. Moreover, just like vector ﬁelds, covector ﬁelds can be mul-
tiplied by smooth functions: If f ∈C∞(M) and σ ∈T∗(M), we deﬁne a
covector ﬁeld fσ by
(fσ)p = f(p)σp.
(4.5)
A simple veriﬁcation using either part (b) or part (c) of Lemma 4.5 shows
that fσ is smooth. Thus T∗(M) is a module over C∞(M).
Geometrically, we think of a vector ﬁeld on M as a rule that attaches
an arrow to each point of M. What kind of geometric picture can we
form of a covector ﬁeld? The key idea is that a nonzero linear functional
ξ ∈T ∗
p M is completely determined by two pieces of data: its kernel, which
is a codimension-1 linear subspace of TpM (a hyperplane), and the set of
vectors X for which ξ(X) = 1, which is an aﬃne hyperplane parallel to
the kernel. (Actually, the set where ξ(X) = 1 alone suﬃces, but it is useful
to visualize the two parallel hyperplanes.) The value of ξ(X) for any other
vector X is then obtained by linear interpolation or extrapolation.
Thus you can visualize a covector ﬁeld as deﬁning a pair of aﬃne hyper-
planes in each tangent space, one through the origin and another parallel to
it, and varying smoothly from point to point. At points where the covector
ﬁeld takes on the value zero, one of the hyperplanes goes oﬀto inﬁnity.
The Diﬀerential of a Function
In elementary calculus, the gradient of a smooth function f on Rn is deﬁned
as the vector ﬁeld whose components are the partial derivatives of f. Un-
fortunately, in this form, the gradient does not make coordinate-invariant
sense.

72
4. The Cotangent Bundle
Exercise 4.5.
Let f(x, y) = x on R2, and let X be the vector ﬁeld
X = grad f = ∂
∂x.
Compute the coordinate expression of X in polar coordinates (on some open
set on which they are deﬁned) using (4.2) and show that it is not equal to
∂f
∂r
∂
∂r + ∂f
∂θ
∂
∂θ .
The most important use of covector ﬁelds is to deﬁne a coordinate-
invariant analogue of the gradient.
Let f be a smooth function on a manifold M. (As usual, all of this
discussion applies to functions deﬁned on an open subset U ⊂M, simply
by replacing M by U throughout.) We deﬁne a covector ﬁeld df, called the
diﬀerential of f, by
dfp(Xp) = Xpf
for Xp ∈TpM.
Lemma 4.6. The diﬀerential of a smooth function is a smooth covector
ﬁeld.
Proof. First we need to verify that at each point p ∈M, dfp(Xp) depends
linearly on Xp, so that dfp is indeed a covector at p. This is a simple
computation: For any a, b ∈R and Xp, Yp ∈TpM,
dfp(aXp + bYp)
= (aXp + bYp)f = a(Xpf) + b(Ypf) = a dfp(Xp) + b dfp(Yp).
Next we show that df is smooth. Let (xi) be local coordinates on an open
subset U ⊂M, and let (εi) be the corresponding coordinate coframe on U.
Writing df in coordinates as dfp = Ai(p)εi
p for some functions Ai : U →R,
the deﬁnition of df implies
Ai(p) = dfp
 
∂
∂xi

p
!
=
∂
∂xi

p
f = ∂f
∂xi (p).
Since this last expression depends smoothly on p, it follows that the com-
ponent functions Ai of df are smooth, so df is smooth.
One consequence of the preceding proof is a formula for the coordinate
representation of df:
dfp = ∂f
∂xi (p)εi
p.
(4.6)
Thus the components of df in any coordinate system are the partial deriv-
atives of f with respect to those coordinates. Because of this, we can think

The Diﬀerential of a Function
73
of df as an analogue of the classical gradient, reinterpreted in a way that
makes coordinate-invariant sense on a manifold.
If we apply (4.6) to the special case in which f is one of the coordinate
functions xj : U →R, we ﬁnd
dxj
p = ∂xj
∂xi (p)εi
p = δj
i εi
p = εj
p.
In other words, the coordinate covector ﬁeld εj is none other than dxj!
Therefore, the formula (4.6) for dfp can be rewritten as
dfp = ∂f
∂xi (p)dxi
p,
or as an equation between covector ﬁelds instead of covectors:
df = ∂f
∂xi dxi.
(4.7)
In particular, in the one-dimensional case, this reduces to
df = df
dxdx.
Thus we have recovered the familiar classical expression for the diﬀerential
of a function f in coordinates. Henceforth, we will abandon the notation
εi for the coordinate coframe, and use dxi instead.
Example 4.7. If f(x, y) = x2y cos x on R2, then df is given by the formula
df = ∂(x2y cos x)
∂x
dx + ∂(x2y cos x)
∂y
dy
= (2xy cos x −x2y sin x)dx + x2 cos x dy.
Proposition 4.8 (Properties of the Diﬀerential).
Let
M
be
a
smooth manifold, and let f, g ∈C∞(M).
(a) For any constants a, b, d(af + bg) = a df + b dg.
(b) d(fg) = f dg + g df.
(c) d(f/g) = (g df −f dg)/g2 on the set where g ̸= 0.
(d) If J ⊂R is an interval containing the image of f, and h: J →R is
a smooth function, then d(h ◦f) = (h′ ◦f) df.
(e) If f is constant, then df = 0.
Exercise 4.6.
Prove Proposition 4.8.

74
4. The Cotangent Bundle
One very important property of the diﬀerential is the following charac-
terization of smooth functions with vanishing diﬀerentials.
Proposition 4.9 (Functions with Vanishing Diﬀerentials).
If f is
a smooth function on a smooth manifold M, then df = 0 if and only if f
is constant on each component of M.
Proof. It suﬃces to assume that M is connected and show that df = 0 if
and only if f is constant. One direction is immediate: If f is constant, then
df = 0 by Proposition 4.8(e). Conversely, suppose df = 0, let p ∈M, and
let C = {q ∈M : f(q) = f(p)}. If q is any point in C, let U be a connected
coordinate domain centered at q. From (4.7) we see that ∂f/∂xi ≡0 in U
for each i, so by elementary calculus f is constant on U. This shows that
C is open, and since it is closed by continuity it must be all of M. Thus f
is everywhere equal to the constant f(p).
In elementary calculus, one thinks of df as an approximation for the
small change in the value of f caused by small changes in the independent
variables xi. In our present context, df has the same meaning, provided we
interpret everything appropriately. Suppose that f is deﬁned and smooth
on an open subset U ⊂Rn, and let p be a point in U. Recall that dxi
p is
the linear functional that picks out the ith component of a tangent vector
at p. Writing ∆f = f(p + v) −f(p) for v ∈Rn, Taylor’s theorem shows
that ∆f is well approximated when v is small by
∆f ≈∂f
∂xi (p)vi = ∂f
∂xi (p)dxi
p(v) = dfp(v).
In other words, dfp is the linear functional that best approximates ∆f near
p. The great power of the concept of the diﬀerential comes from the facts
that we can deﬁne df invariantly on any manifold, and can do so without
resorting to any vague arguments involving inﬁnitesimals.
The next result is an analogue of Proposition 3.11 for the diﬀerential.
Proposition 4.10. Suppose γ : J →M is a smooth curve and f : M →
R is a smooth function. Then the derivative of the real-valued function
f ◦γ : R →R is given by
(f ◦γ)′(t) = dfγ(t)(γ ′(t)).
(4.8)
Proof. Directly from the deﬁnitions, for any t0 ∈J,
dfγ(t0)(γ ′(t0)) = γ ′(t0)f
(deﬁnition of df)
=

γ∗
d
dt

t0

f
(deﬁnition of γ ′(t))
= γ∗
d
dt

t0
(f ◦γ)
(deﬁnition of γ∗)
= (f ◦γ)′(t0)
(deﬁnition of (f ◦γ)′),

Pullbacks
75
which was to be proved.
It is important to observe that for a smooth real-valued function f : M →
R, we have now deﬁned two diﬀerent kinds of derivative of f at a point
p ∈M. In the preceding chapter, we deﬁned the push-forward f∗as a linear
map from TpM to Tf(p)R. In this chapter, we deﬁned the diﬀerential dfp as a
covector at p, which is to say a linear map from TpM to R. These are really
the same object, once we take into account the canonical identiﬁcation
between R and its tangent space at any point; one easy way to see this is
to note that both are represented in coordinates by the row matrix whose
components are the partial derivatives of f.
Similarly, if γ is a smooth curve in M, we have two diﬀerent meanings
for the expression (f ◦γ)′(t). On the one hand, f ◦γ can be interpreted
as a smooth curve in R, and thus (f ◦γ)′(t) is its tangent vector at the
point f ◦γ(t), an element of the tangent space Tf◦γ(t)R. Proposition 3.11
shows that this tangent vector is equal to f∗(γ ′(t)). On the other hand,
f ◦γ can also be considered simply as a real-valued function of one real
variable, and then (f ◦γ)′(t) is just its ordinary derivative. Proposition 4.10
shows that this derivative is equal to the real number dfγ(t)(γ ′(t)). Which
of these interpretations we choose will depend on the purpose we have in
mind.
Pullbacks
As we have seen, a smooth map yields a linear map on tangent vectors
called the push-forward. Dualizing this leads to a linear map on covectors
going in the opposite direction.
Let F : M →N be a smooth map, and let p ∈M be arbitrary. The
push-forward map
F∗: TpM →TF (p)N
yields a dual map
(F∗)∗: T ∗
F (p)N →T ∗
p M.
To avoid a proliferation of stars, we write this map, called the pullback
associated with F, as
F ∗: T ∗
F (p)N →T ∗
p M.
Unraveling the deﬁnitions, F ∗is characterized by
(F ∗ξ)(X) = ξ(F∗X),
for ξ ∈T ∗
F (p)N, X ∈TpM.

76
4. The Cotangent Bundle
When we introduced the push-forward map, we made a point of noting
that vector ﬁelds do not push forward to vector ﬁelds, except in the special
case of a diﬀeomorphism. The surprising thing about pullbacks is that they
always pull smooth covector ﬁelds back to smooth covector ﬁelds. Given
a smooth map G: M →N and a smooth covector ﬁeld σ on N, deﬁne a
covector ﬁeld G∗σ on M by
(G∗σ)p = G∗(σG(p)).
(4.9)
Observe that there is no ambiguity here about what point to pull back
from, in contrast to the vector ﬁeld case. We will prove in Proposition 4.12
below that G∗σ is smooth. Before doing so, let us examine two important
special cases.
Lemma 4.11. Let G: M →N be a smooth map, and suppose f ∈C∞(N)
and σ ∈T∗(N). Then
G∗df = d(f ◦G);
(4.10)
G∗(fσ) = (f ◦G)G∗σ.
(4.11)
Proof. To prove (4.10), we let Xp ∈TpM be arbitrary, and compute
(G∗df)p(Xp) = (G∗dfG(p))(Xp)
(by (4.9))
= dfG(p)(G∗Xp)
(by deﬁnition of G∗)
= (G∗Xp)f
(by deﬁnition of df)
= Xp(f ◦G)
(by deﬁnition of G∗)
= d(f ◦G)p(Xp)
(by deﬁnition of d(f ◦G)).
Similarly, for (4.11), we compute
(G∗(fσ))p = G∗((fσ)G(p))
(by (4.9))
= G∗(f(G(p))σG(p))
(by (4.5))
= f(G(p))G∗(σG(p))
(because G∗is linear)
= f(G(p))(G∗σ)p
(by (4.9))
= ((f ◦G)G∗σ)p
(by (4.5)),
which was to be proved.
Proposition 4.12. Suppose G: M →N is smooth, and let σ be a smooth
covector ﬁeld on N. Then G∗σ is a smooth covector ﬁeld on M.
Proof. Let p ∈M be arbitrary, and choose local coordinates (xi) for M
near p and (yj) for N near G(p). Writing σ in coordinates as σ = σjdyj

Pullbacks
77
for smooth functions σj deﬁned near G(p) and using Lemma 4.11 twice, we
compute
G∗σ = G∗(σjdyj)
= (σj ◦G)G∗dyj
= (σj ◦G)d(yj ◦G).
Because this expression is smooth, it follows that G∗σ is smooth.
In the course of the preceding proof, we derived the following formula
for the pullback of a covector ﬁeld with respect to coordinates (xi) on the
domain and (yj) on the range:
G∗σ = G∗(σjdyj) = (σj ◦G)d(yj ◦G) = (σj ◦G)dGj,
(4.12)
where Gj is the jth component function of G in these coordinates. This
formula makes the computation of pullbacks in coordinates exceedingly
simple, as the next example shows.
Example 4.13. Let G: R3 →R2 be the map given by
(u, v) = G(x, y, z) = (x2y, y sin z),
and let σ ∈T∗(R2) be the covector ﬁeld
σ = u dv + v du.
According to (4.12), the pullback G∗σ is given by
G∗σ = (u ◦G)d(v ◦G) + (v ◦G)d(u ◦G)
= (x2y)d(y sin z) + (y sin z)d(x2y)
= x2y(sin z dy + y cos z dz) + y sin z(2xy dx + x2 dy)
= 2xy2 sin z dx + 2x2y sin z dy + x2y2 cos z dz.
In other words, to compute G∗σ, all you need to do is substitute the
component functions of G for the coordinate functions of N everywhere
they appear in σ!
This also yields an easy way to remember the transformation law for a
covector ﬁeld under a change of coordinates. Again, an example will convey
the idea better than a general formula.
Example 4.14. Let (r, θ) be polar coordinates on, say, the upper half-
plane H = {(x, y) : y > 0}. We can think of the change of coordinates
(x, y) = (r cos θ, r sin θ) as the coordinate expression for the identity map
of H, but using (r, θ) as coordinates for the domain and (x, y) for the
range. Then the the pullback formula (4.12) tells us that we can compute

78
4. The Cotangent Bundle
the polar coordinate expression for a covector ﬁeld simply by substituting
x = r cos θ, y = r sin θ. For example,
x dx + y dy = Id∗(x dx + y dy)
= (r cos θ)d(r cos θ) + (r sin θ)d(r sin θ)
= (r cos θ)(cos θ dr −r sin θ dθ) + (r sin θ)(sin θ dr + r cos θ dθ)
= (r cos2 θ + r sin2 θ)dr + (−r2 cos θ sin θ + r2 sin θ cos θ)dθ
= r dr.
Line Integrals
Another important application of covector ﬁelds is to make coordinate-
independent sense of the notion of a line integral.
We begin with the simplest case: an interval in the real line. Suppose
[a, b] ⊂R is a compact interval, and ω is a smooth covector ﬁeld on [a, b].
(This means that the component function of ω admits a smooth extension
to some neighborhood of [a, b].) If we let t denote the standard coordinate
on R, ω can be written ωt = f(t) dt for some smooth function f : [a, b] →
R. The similarity between this and the standard notation
R
f(t) dt for an
integral suggests that there might be a connection between covector ﬁelds
and integrals, and indeed there is. We deﬁne the integral of ω over [a, b] to
be
Z
[a,b]
ω =
Z b
a
f(t) dt.
The next proposition indicates that this is more than just a trick of nota-
tion.
Proposition 4.15 (Diﬀeomorphism Invariance of the Integral).
Let ω be a smooth covector ﬁeld on the compact interval [a, b] ⊂R. If
ϕ: [c, d] →[a, b] is an increasing diﬀeomorphism (meaning that t < t′
implies ϕ(t) < ϕ(t′)), then
Z
[c,d]
ϕ∗ω =
Z
[a,b]
ω.
Proof. If we let s denote the standard coordinate on [c, d] and t that on
[a, b], then (4.12) shows that the pullback ϕ∗ω has the coordinate expres-
sion (ϕ∗ω)s = f(ϕ(s))ϕ′(s) ds. Inserting this into the deﬁnition of the line
integral and using the change of variables formula for ordinary integrals,
we obtain
Z
[c,d]
ϕ∗ω =
Z d
c
f(ϕ(s))ϕ′(s) ds =
Z b
a
f(t) dt =
Z
[a,b]
ω,

Line Integrals
79
which was to be proved.
Exercise 4.7.
If ϕ: [c, d] →[a, b] is a decreasing diﬀeomorphism, show
that
R
[c,d] ϕ∗ω = −
R
[a,b] ω.
Now let M be a smooth manifold. By a curve segment in M we mean
a continuous curve γ : [a, b] →M whose domain is a compact interval.
It is a smooth curve segment if it is has a smooth extension to an open
set containing [a, b]. A piecewise smooth curve segment is a curve segment
γ : [a, b] →M with the property that there exists a ﬁnite subdivision
a = a0 < a1 < · · · < ak = b of [a, b] such that γ|[ai−1,ai] is smooth for
each i. Continuity of γ means that γ(t) approaches the same value as t
approaches any of the points ai (other than a0 or ak) from the left or the
right. Smoothness of γ on each subinterval means that γ has one-sided tan-
gent vectors at each such ai when approaching from the left or the right,
but these one-sided tangent vectors need not be equal.
Lemma 4.16. If M is a connected smooth manifold, any two points of M
can be joined by a piecewise smooth curve segment.
Proof. Let p be an arbitrary point of M, and deﬁne a subset C ⊂M
by C = {q ∈M : there is a piecewise smooth curve in M from p to q}.
Clearly p ∈C, so C is nonempty. To show C = M, we need to show it is
open and closed.
Let q ∈C be arbitrary, which means that there is a piecewise smooth
curve segment γ going from p to q. Let U be a coordinate ball centered at q.
If q′ is any point in U, then it is easy to construct a piecewise smooth curve
segment from p to q′ by ﬁrst following γ from p to q, and then following
a straight-line path in coordinates from q to q′. Thus U ⊂C, which shows
that C is open. On the other hand, if q ∈∂C, let U be a coordinate ball
around q as above. The fact that q is a boundary point of C means that
there is some point q′ ∈C ∩U. In this case, we can construct a piecewise
smooth curve from p to q by ﬁrst following one from p to q′ and then
following a straight-line path in coordinates from q′ to q. This shows that
q ∈C, so C is also closed.
If γ is a smooth curve segment in M and ω is a smooth covector ﬁeld on
M, we deﬁne the line integral of ω over γ to be the real number
Z
γ
ω =
Z
[a,b]
γ∗ω.
Because γ∗ω is a smooth covector ﬁeld on [a, b], this deﬁnition makes sense.
More generally, if γ is piecewise smooth, we deﬁne
Z
γ
ω =
k
X
i=1
Z
[ai−1,ai]
γ∗ω,

80
4. The Cotangent Bundle
where [ai−1, ai], i = 1, . . . , k, are the intervals on which γ is smooth.
This deﬁnition gives a rigorous meaning to classical line integrals such
as
R
γ P dx + Q dy in the plane or
R
γ P dx + Q dy + R dz in R3.
Proposition 4.17 (Properties of Line Integrals).
Let
M
be
a
smooth manifold. Suppose γ : [a, b] →M is a piecewise smooth curve
segment and ω, ω1, ω2 ∈T∗(M).
(a) For any c1, c2 ∈R,
Z
γ
(c1ω1 + c2ω2) = c1
Z
γ
ω1 + c2
Z
γ
ω2.
(b) If γ is a constant map, then
R
γ ω = 0.
(c) If a < c < b, then
Z
γ
ω =
Z
γ1
ω +
Z
γ2
ω,
where γ1 = γ|[a,c] and γ2 = γ|[c,b].
(d) The line integral of ω over γ can also be expressed as the ordinary
integral
Z
γ
ω =
Z b
a
ωγ(t)(γ ′(t)) dt.
Exercise 4.8.
Prove Proposition 4.17.
Example 4.18. Let M = R2 ∖{0}, let ω be the covector ﬁeld on M given
by
ω = x dy −y dx
x2 + y2
,
and let γ : [0, 2π] →M be the curve segment deﬁned by
γ(t) = (cos t, sin t).
Since γ∗ω can be computed by substituting x = cos t and y = sin t every-
where in the formula for ω, we ﬁnd that
Z
γ
ω =
Z
[0,2π]
cos t(cos t dt) −sin t(−sin t dt)
sin2 t + cos2 t
=
Z 2π
0
dt = 2π.

Line Integrals
81
One of the most signiﬁcant features of line integrals is that they are in-
dependent of parametrization, in a sense we now deﬁne. If γ : [a, b] →M
and eγ : [c, d] →M are smooth curve segments, we say that eγ is a reparam-
etrization of γ if eγ = γ ◦ϕ for some diﬀeomorphism ϕ: [c, d] →[a, b]. If ϕ
is an increasing function, we say eγ is a forward reparametrization, and if ϕ
is decreasing, it is a backward reparametrization. (More generally, one can
allow ϕ to be piecewise smooth, but we will have no need for this extra
generalization.)
Proposition 4.19 (Parameter Independence of Line Integrals).
Suppose M is a smooth manifold, ω is a smooth covector ﬁeld on M, and
γ is a piecewise smooth curve segment in M. For any reparametrization eγ
of γ, we have
Z
eγ
ω =









Z
γ
ω
if eγ is a forward reparametrization,
−
Z
γ
ω
if eγ is a backward reparametrization.
Proof. First assume that γ : [a, b] →M is smooth, and suppose ϕ: [c, d] →
[a, b] is an increasing diﬀeomorphism. Then Proposition 4.15 implies
Z
eγ
ω =
Z
[c,d]
(γ ◦ϕ)∗ω
=
Z
[c,d]
ϕ∗γ∗ω
=
Z
[a,b]
γ∗ω
=
Z
γ
ω.
When ϕ is decreasing, the analogous result follows from Exercise 4.7. If γ is
only piecewise smooth, the result follows simply by applying the preceding
argument on each subinterval where γ is smooth.
Exercise 4.9.
Suppose F : M →N is any smooth map, ω ∈T∗(N), and
γ is a piecewise smooth curve segment in M. Show that
Z
γ
F ∗ω =
Z
F ◦γ
ω.
There is one special case in which a line integral is trivial to compute:
the line integral of a diﬀerential.
Theorem 4.20 (Fundamental Theorem for Line Integrals).
Let
M be a smooth manifold. Suppose f is a smooth function on M and

82
4. The Cotangent Bundle
γ : [a, b] →M is a piecewise smooth curve segment in M. Then
Z
γ
df = f(γ(b)) −f(γ(a)).
Proof. Suppose ﬁrst that γ is smooth. By Proposition 4.10 and Proposition
4.17(d),
Z
γ
df =
Z b
a
dfγ(t)(γ ′(t)) dt =
Z b
a
(f ◦γ)′(t) dt.
By the one-variable version of the fundamental theorem of calculus, this is
equal to f ◦γ(b) −f ◦γ(a).
If γ is merely piecewise smooth, let a = a0 < · · · < ak = b be the
endpoints of the subintervals on which γ is smooth. Applying the above
argument on each subinterval and summing, we ﬁnd that
Z
γ
df =
k
X
i=1
 f(γ(ai)) −f(γ(ai−1))

= f(γ(b)) −f(γ(a)),
because the contributions from all the interior points cancel.
Conservative Covector Fields
Theorem 4.20 shows that the line integral of any covector ﬁeld ω that can be
written as the diﬀerential of a smooth function can be computed extremely
easily once the smooth function is known. For this reason, there is a special
term for covector ﬁelds with this property. We say a smooth covector ﬁeld ω
on a manifold M is exact on M if there is a function f ∈C∞(M) such that
ω = df. In this case, the function f is called a potential for ω. The potential
is not uniquely determined, but by Lemma 4.9, the diﬀerence between any
two potentials for ω must be constant on each component of M.
Because exact diﬀerentials are so easy to integrate, it is important to
develop criteria for deciding whether a covector ﬁeld is exact. Theorem
4.20 provides an important clue. It shows that the line integral of an exact
covector ﬁeld depends only on the endpoints p = γ(a) and q = γ(b): Any
other curve segment from p to q would give the same value for the line
integral. In particular, if γ is a closed curve segment, meaning that γ(a) =
γ(b), then the integral of df over γ is zero.
We say a smooth covector ﬁeld ω is conservative if the line integral of ω
over any closed piecewise smooth curve segment is zero. This terminology
comes from physics, where a force ﬁeld is called conservative if the change
in energy caused by the force acting along any closed path is zero (“energy
is conserved”). (In elementary physics, force ﬁelds are usually thought of as
vector ﬁelds rather than covector ﬁelds; see Problem 4-5 for the connection.)

Conservative Covector Fields
83
The following lemma gives a useful alternative characterization of con-
servative covector ﬁelds.
Lemma 4.21. A smooth covector ﬁeld ω is conservative if and only if the
line integral of ω depends only on the endpoints of the curve, i.e.,
R
γ ω =
R
eγ ω whenever γ and eγ are piecewise smooth curve segments with the same
starting and ending points.
Exercise 4.10.
Prove Lemma 4.21. [Observe that this would be much
harder to prove if we deﬁned conservative ﬁelds in terms of smooth curves
instead of piecewise smooth ones.]
Theorem 4.22. A smooth covector ﬁeld is conservative if and only if it is
exact.
Proof. If ω ∈T∗(M) is exact, Theorem 4.20 shows that it is conservative, so
we need only prove the converse. Suppose therefore that ω is conservative,
and assume for the moment that M is connected. Because the line integrals
of ω are path independent, we can adopt the following notation: For any
points p, q ∈M, we will use the notation
R q
p ω to denote the line integral
R
γ ω, where γ is any piecewise smooth curve segment from p to q. Observe
that Proposition 4.17(c) implies that
Z p2
p1
ω +
Z p3
p2
ω =
Z p3
p1
ω
(4.13)
for any three points p1, p2, p3 ∈M.
Now choose any base point p0 ∈M, and deﬁne a function f : M →R by
f(q) =
Z q
p0
ω.
We will show that df = ω. To accomplish this, let q0 ∈M be an arbitrary
point, let (U, (xi)) be a coordinate chart centered at q0, and write the
coordinate representation of ω as ω = ωidxi. We will show that
∂f
∂xj (q0) = ωj(q0)
for j = 1, . . . , n, which implies that dfq0 = ωq0.
Fix j, and let γ : [−ε, ε] →U be the smooth curve segment deﬁned in
coordinates by γ(t) = (0, . . . , t, . . . , 0), with t in the jth place, and with ε
chosen small enough that γ[−ε, ε] ⊂U. Let p1 = γ(−ε), and deﬁne a new
function ef : M →R by ef(q) = R q
p1 ω. Note that (4.13) implies
ef(q) −f(q) =
Z q
p1
ω −
Z q
p0
ω =
Z p1
p0
ω,

84
4. The Cotangent Bundle
which does not depend on q. Thus ef and f diﬀer by a constant, so it suﬃces
to show that ∂ef/∂xj(q0) = ωj(q0).
Now γ ′(t) = ∂/∂xj|γ(t) by construction, so
ωγ(t)(γ ′(t)) = ωγ(t)

∂
∂xj

γ(t)

= ωj(γ(t)).
Since the restriction of γ to [−ε, t] is a smooth curve from p1 to γ(t), we
have
ef ◦γ(t) =
Z γ(t)
p1
ω
=
Z t
−ε
ωγ(s)(γ ′(s)) ds
=
Z t
−ε
ωj(γ(s)) ds.
Thus by the fundamental theorem of calculus,
∂ef
∂xj (q0) = γ ′(0) ef
= d
dt

t=0
ef ◦γ(t)
= d
dt

t=0
Z t
−ε
ωj(γ(s)) ds
= ωj(γ(0)) = ωj(q0).
This completes the proof that df = ω.
Finally, if M is not connected, let {Mi} be the components of M. The
argument above shows that for each i there is a smooth function fi ∈
C∞(Mi) such that dfi = ω on Mi. Letting f : M →R be the function that
is equal to fi on Mi, we have df = ω, thus completing the proof.
It would be nice if every smooth covector ﬁeld were exact, for then the
evaluation of any line integral would just be a matter of ﬁnding a potential
function and evaluating it at the endpoints, a process analogous to eval-
uating an ordinary integral by ﬁnding an indeﬁnite integral or primitive.
However, this is too much to hope for.
Example 4.23. The covector ﬁeld ω of Example 4.18 cannot be exact on
R2 ∖{0}, because it is not conservative: The computation in that example
showed that R
γ ω = 2π ̸= 0, where γ is the unit circle traversed counter-
clockwise.
Because exactness has such important consequences for the evaluation
of line integrals, we would like to have an easy way to check whether a

Conservative Covector Fields
85
given covector ﬁeld is exact. Fortunately, there is a very simple necessary
condition, which follows from the fact that partial derivatives of smooth
functions can be taken in any order.
To see what this condition is, suppose that ω is exact. Let f be any
potential function for ω, and let (U, (xi)) be any coordinate chart on M.
Because f is smooth, it satisﬁes the following identity on U:
∂2f
∂xi∂xj =
∂2f
∂xj∂xi .
(4.14)
Writing ω = ωidxi in coordinates, the fact that ω = df is equivalent to
ωi = ∂f/∂xi. Substituting this into (4.14), we ﬁnd that the component
functions of ω satisfy
∂ωj
∂xi = ∂ωi
∂xj .
(4.15)
We say that a smooth covector ﬁeld ω is closed if its components in
every coordinate chart satisfy (4.15). The following lemma summarizes the
computation above.
Lemma 4.24. Every exact covector ﬁeld is closed.
The signiﬁcance of this result is that the property of being closed is one
that can be easily checked. First we need the following result, which says
that it is not necessary to check the closedness condition in every coordinate
chart, just in a collection of charts that cover the manifold. The proof of this
lemma is a tedious computation; later you will be able to give a somewhat
more conceptual proof (see Problem 4-4 and also Chapter 9), so you are
free to skip the proof of this lemma if you wish.
Lemma 4.25. A smooth covector ﬁeld is closed if and only if it satisﬁes
(4.15) in some coordinate chart around every point.
Proof. If ω is closed, then by deﬁnition it satisﬁes (4.15) in every coordi-
nate chart. Conversely, suppose (4.15) holds in some chart around every
point, and let (U, (xi)) be an arbitrary coordinate chart. For each p ∈U,
the hypothesis guarantees that there are some coordinates (exj) deﬁned
near p in which the analogue of (4.15) holds. Using formula (4.4) for the
transformation of the components of ω together with the chain rule, we

86
4. The Cotangent Bundle
ﬁnd
∂ωi
∂xj −∂ωj
∂xi =
∂
∂xj
∂exk
∂xi eωk

−∂
∂xi
∂exk
∂xj eωk

=
 ∂2exk
∂xj∂xi eωk + ∂exk
∂xi
∂eωk
∂xj

−
 ∂2exk
∂xi∂xj eωk + ∂exk
∂xj
∂eωk
∂xi

=
∂2exk
∂xj∂xi eωk + ∂exk
∂xi
∂exl
∂xj
∂eωk
∂exl −
∂2exk
∂xi∂xj eωk −∂exk
∂xj
∂exl
∂xi
∂eωk
∂exl
=
 ∂2exk
∂xj∂xi −
∂2exk
∂xi∂xj

eωk + ∂exk
∂xi
∂exl
∂xj
∂eωk
∂exl −∂eωl
∂exk

= 0 + 0,
where the fourth equation follows from the third by interchanging the roles
of k and l in the last term.
For example, consider the following covector ﬁeld on R2:
ω = y cos xy dx + x cos xy dy.
It is easy to check that
∂(y cos xy)
∂y
= ∂(x cos xy)
∂x
= cos xy −xy sin xy,
so ω is closed. In fact, you might guess that ω = d(sin xy).
The question then naturally arises whether the converse of Lemma 4.24 is
true: is every closed covector ﬁeld exact? The answer is almost yes, but there
is an important restriction. It turns out that the answer to the question
depends in a subtle way on the shape of the domain, as the next example
illustrates.
Example 4.26. Look once again at the covector ﬁeld ω of Example 4.7.
A straightforward computation shows that ω is closed; but as we observed
above, it is not exact on R2 ∖{0}. On the other hand, if we restrict the
domain to the right half-plane U = {(x, y) : x > 0}, a computation shows
that ω = d(tan−1 y/x) there. This can be seen more clearly in polar coordi-
nates, where ω = dθ. The problem, of course, is that there is no smooth (or
even continuous) angle function on all of R2 ∖{0}, which is a consequence
of the “hole” in the center.
This last example illustrates a key fact: The question of whether a par-
ticular covector ﬁeld is exact is a global one, depending on the shape of the
domain in question. This observation is the starting point for de Rham co-
homology, which expresses a deep relationship between smooth structures
and topology. We will pursue this relationship in more depth in Chapter
11, but for now we can prove the following result. A subset V ⊂Rn is said

Conservative Covector Fields
87
to be star-shaped with respect to a point c ∈V if for every x ∈V , the
line segment from c to x is entirely contained in V . For example, a convex
subset is star-shaped with respect to each of its points.
Proposition 4.27. If M is diﬀeomorphic to a star-shaped open subset of
Rn, then every closed covector ﬁeld on M is exact.
Proof. It is easy to check that a diﬀeomorphism pulls back closed covector
ﬁelds to closed covector ﬁelds and exact covector ﬁelds to exact ones; thus
it suﬃces to prove the proposition when M actually is a star-shaped open
subset of Rn. So suppose M ⊂Rn is star-shaped with respect to c ∈M,
and let ω = ωidxi be a closed covector ﬁeld on M.
As in the proof of Theorem 4.22, we will construct a potential function
for ω by integrating along smooth curve segments from c. However, in this
case we do not know a priori that the line integrals are path-independent,
so we must integrate along speciﬁc paths.
For any point x ∈M, let γx : [0, 1] →M denote the line segment from c
to x, parametrized as follows:
γx(t) = c + t(x −c).
The hypothesis guarantees that the image of γx lies entirely in M for each
x ∈M. Deﬁne a function f : M →R by
f(x) =
Z
γx
ω.
We will show that f is a potential for ω, or equivalently that ∂f/∂xi = ωi
for i = 1, . . . , n. To begin, we compute
f(x) =
Z 1
0
ωγx(t)(γ′
x(t)) dt
=
Z 1
0
ωi(c + t(x −c))(xi −ci) dt.
To compute the partial derivatives of f, we note that the integrand is
smooth in all variables, so it is permissible to diﬀerentiate under the integral
sign to obtain
∂f
∂xj (x) =
Z 1
0

t∂ωi
∂xj (c + t(x −c))(xi −ci) + ωj(c + t(x −c))

dt.

88
4. The Cotangent Bundle
Because ω is closed, this reduces to
∂f
∂xj (x) =
Z 1
0

t∂ωj
∂xi (c + t(x −c))(xi −ci) + ωj(c + t(x −c))

dt
=
Z 1
0
d
dt
 tωj(c + t(x −c))

dt
=

tωj(c + t(x −c))
t=1
t=0
= ωj(x),
which was to be proved.
The key to the above construction is that we can reach every point
x ∈M by a deﬁnite path γx from c to x, chosen in such a way that γx
varies smoothly as x varies. That is what fails in the case of the closed
covector ﬁeld ω on the punctured plane (Example 4.23): Because of the
hole, it is impossible to choose a smoothly-varying family of paths starting
at a ﬁxed base point and reaching every point of the domain. In Chapter
11, we will generalize Proposition 4.27 to show that every closed covector
ﬁeld is exact on any simply connected manifold.
When you actually have to compute a potential function for a given
covector ﬁeld that is known to be exact, there is a much simpler procedure
that almost always works. Rather than describe it in complete generality,
we illustrate it with an example.
Example 4.28. Let ω be a smooth covector ﬁeld on R3, say
ω = ey2dx + 2xyey2dy −2z dz.
You can check that ω is closed. If f is a potential for ω, we must have
∂f
∂x = ey2,
∂f
∂y = 2xyey2,
∂f
∂z = −2z.
Holding y and z ﬁxed and integrating the ﬁrst equation with respect to x,
we obtain
f(x, y, z) =
Z
ey2dx = xey2 + C1(y, z),

Conservative Covector Fields
89
where the “constant” of integration C1(y, z) may depend on the choice of
(y, z). Now the second equation implies
2xyey2 = ∂
∂y
 xey2 + C1(y, z)

= 2xyey2 + ∂C1
∂y ,
which forces ∂C1/∂y = 0, so C1 is actually a function of z only. Finally,
the third equation implies
−2z = ∂
∂z
 xey2 + C1(z)

= ∂C1
∂z ,
from which we conclude that C1(z) = −2z2 + C, where C is an arbitrary
constant. Thus a potential function for ω is given by f(x, y, z) = xey2 −2z2.
Any other potential diﬀers from this one by a constant.
You should convince yourself that the formal procedure we followed in
this example is equivalent to choosing an arbitrary base point c ∈R3,
and deﬁning f(x, y, z) by integrating ω along a path from c to (x, y, z)
consisting of three straight line segments parallel to the axes. This works
for any closed covector ﬁeld deﬁned on an open rectangle in Rn (which we
know must be exact, because a rectangle is convex). In practice, once a
formula is found for f on some open rectangle, the same formula typically
works for the entire domain. (This is because most of the covector ﬁelds
for which one can explicitly compute the integrals as we did above are real-
analytic, and real-analytic functions are determined by their behavior in
any open set.)

90
4. The Cotangent Bundle
Problems
4-1. In each of the cases below, M is a smooth manifold and f : M →R
is a smooth function. Compute the coordinate representation for df,
and determine the set of all points p ∈M at which dfp = 0.
(a) M = {(x, y) ∈R2 : x > 0}; f(x, y) = x/(x2 + y2). Use standard
coordinates (x, y).
(b) M and f are as in part (a); this time use polar coordinates (r, θ).
(c) M = S2 ⊂R3; f(p) = z(p) (the z-coordinate of p, thought of as
a point in R3). Use stereographic coordinates.
(d) M = Rn; f(x) = |x|2. Use standard coordinates.
4-2. Let M be a smooth manifold.
(a) Given a smooth covector ﬁeld σ on M, show that the map
eσ : T(M) →C∞(M) deﬁned by
eσ(X)(p) = σp(Xp)
is linear over C∞(M), in the sense that for any smooth functions
f, f ′ ∈C∞(M) and smooth vector ﬁelds X, X′,
eσ(fX + f ′X′) = feσ(X) + f ′eσ(X′).
(b) Show that a map
eσ : T(M) →C∞(M)
is induced by a smooth covector ﬁeld as above if and only if it
is linear over C∞(M).
4-3. The length of a smooth curve γ : [a, b] →Rn is deﬁned to be the value
of the (ordinary) integral
L(γ) =
Z b
a
|γ′(t)| dt.
Show that there is no smooth covector ﬁeld ω ∈T∗(Rn) with the
property that
R
γ ω = L(γ) for every smooth curve γ.
4-4. Use Proposition 4.27 to give a simpler proof of Lemma 4.25.
4-5. Line Integrals of Vector Fields: Suppose X is a smooth vector
ﬁeld on an open set U ⊂Rn, thought of as a smooth function from

Problems
91
Rn to Rn. For any piecewise smooth curve segment γ : [a, b] →U,
deﬁne the line integral of X over γ by
Z
γ
X · ds =
Z b
a
X(γ(t)) · γ ′(t) dt,
and say X is conservative if its line integral around any closed curve
is zero.
(a) Show that X is conservative if and only if there exists a smooth
function f ∈C∞(U) such that X = grad f. [Hint: Consider
the covector ﬁeld ωx(Y ) = X(x)· Y , where the dot denotes the
Euclidean dot product.]
(b) If n = 3 and X is conservative, show curl X = 0, where
curl X =
∂X3
∂x2 −∂X2
∂x3
 ∂
∂x1 +
∂X1
∂x3 −∂X3
∂x1
 ∂
∂x2
+
∂X2
∂x1 −∂X1
∂x2

∂
∂x3 .
(c) If U ⊂R3 is star-shaped, show that X is conservative on U if
and only if curl X = 0.
4-6. If M is a compact manifold and f ∈C∞(M), show that df vanishes
somewhere on M.
4-7. Is there a smooth covector ﬁeld on S2 that vanishes at exactly one
point? If so, can it be chosen to be exact?
4-8. Let Tn = S1 × · · · × S1 denote the n-torus. For each i = 1, . . . , n, let
γi : [0, 1] →Tn be the curve segment
γi(t) = (1, . . . , e2πit, . . . , 1)
(with e2πit in the ith place),
where we think of Tn as a subset of Cn ∼= R2n. Show that a closed
covector ﬁeld ω on Tn is exact if and only if
R
γi ω = 0 for i = 1, . . . , n.
[Hint: Consider ﬁrst E∗ω, where E : Rn →Tn is the covering map
E(x1, . . . , xn) = (e2πix1, . . . , e2πixn).]
4-9. If F : M →N is a smooth map, show that F ∗: T ∗N →T ∗M is
smooth.
4-10. Consider the smooth function det: GL(n, R) →R.
(a) Using matrix entries (Aj
i) as global coordinates on GL(n, R),
show that the partial derivatives of the determinant map
det: GL(n, R) →R are given by
∂
∂Aj
i
det(A) = (det A)(A−1)i
j.

92
4. The Cotangent Bundle
[Hint: Expand det A by minors along the ith column and use
Cramer’s rule.]
(b) Conclude that the diﬀerential of the determinant function is
d(det)A(B) = (det A) tr(A−1B)
for A ∈GL(n, R) and B ∈TA GL(n, R) ∼= M(n, R), where tr A =
P
i Ai
i is the trace of A.

5
Submanifolds
Many of the most familiar examples of manifolds arise naturally as subsets
of other manifolds—for example, the n-sphere is a subset of Rn+1 and the
n-torus Tn = S1 × · · · × S1 is a subset of C × · · · × C = Cn. In this chapter,
we will explore conditions under which a subset of a smooth manifold can
be considered as a smooth manifold in its own right. As you will soon
discover, the situation is quite a bit more subtle than the analogous theory
of topological subspaces.
Because submanifolds are typically presented as images or level sets of
smooth maps, a good portion of the chapter is devoted to analyzing the
conditions under which such sets are smooth manifolds. We begin by in-
troducing three special types of maps whose level sets and images are well
behaved: submersions, immersions, and embeddings. Then we deﬁne the
most important type of smooth submanifolds, called embedded submani-
folds. These are modeled locally on linear subspaces of Euclidean space.
Next, in order to show how submersions, immersions, and embeddings
can be used to deﬁne submanifolds, we will prove an analytic result that
will prove indispensable in the theory of smooth manifolds: the inverse
function theorem. This theorem and its corollaries show that, under certain
hypotheses on the rank of its push-forward, a smooth map behaves locally
like its push-forward.
The remainder of the chapter consists of various applications of the in-
verse function theorem to the study of submanifolds. We show that level
sets of submersions, level sets of constant-rank smooth maps, and images
of embeddings are embedded submanifolds. We also observe that the image
of an injective immersion looks locally like an embedded submanifold, but

94
5. Submanifolds
may not be one globally; this leads to the deﬁnition of a more general kind
of submanifold, called an immersed submanifold.
At the end of the chapter, we apply the theory of submanifolds to study
conditions under which an algebraic subgroup of a Lie group is itself a Lie
group.
Submersions, Immersions, and Embeddings
Because the push-forward of a smooth map F at a point p represents the
“best linear approximation” to F near p, we can learn something about
F itself by studying linear-algebraic properties of its push-forward at each
point. The most important such property is its rank (the dimension of its
image).
If F : M →N is a smooth map, we deﬁne the rank of F at p ∈M to
be the rank of the linear map F∗: TpM →TF (p)N; it is of course just the
rank of the matrix of partial derivatives of F in any coordinate chart, or
the dimension of Im F∗⊂TF (p)N. If F has the same rank k at every point,
we say it has constant rank, and write rank F = k.
An immersion is a smooth map F : M →N with the property that F∗
is injective at each point (or equivalently rank F = dim M). Similarly, a
submersion is a smooth map F : M →N such that F∗is surjective at
each point (equivalently, rank F = dim N). As we will see in this chapter,
immersions and submersions behave locally like injective and surjective
linear maps, respectively.
One special kind of immersion is particularly important. A (smooth)
embedding is an injective immersion F : M →N that is also a topologi-
cal embedding, i.e., a homeomorphism onto its image F(M) ⊂N in the
subspace topology. Since this is the primary kind of embedding we will
be concerned with in this book, the term “embedding” will always mean
smooth embedding unless otherwise speciﬁed.
Example 5.1 (Submersions, Immersions, and Embeddings).
(a) If M1, . . . , Mk are smooth manifolds, each of the projections πi : M1×
· · · × Mk
→Mi is a submersion. In particular, the projection
π: Rn+k →Rn onto the ﬁrst n coordinates is a submersion.
(b) Similarly, with M1, . . . , Mk as above, if pi ∈Mi are arbitrarily chosen
points, each of the maps ιj : Mj →M1 × · · · × Mk given by
ιj(q) = (p1, . . . , pj−1, q, pj+1, . . . , pk)
is an embedding. In particular, the inclusion map Rn ,→Rn+k given
by sending (x1, . . . , xn) to (x1, . . . , xn, 0, . . . , 0) is an embedding.

Submersions, Immersions, and Embeddings
95
(c) If γ : J →M is a smooth curve in a smooth manifold M, then γ is
an immersion if and only if γ ′(t) ̸= 0 for all t ∈J.
(d) Any smooth covering map π: f
M →M is both an immersion and a
submersion.
(e) If E is a smooth vector bundle over a smooth manifold M, the pro-
jection map π: E →M is a submersion.
(f) Let T2 = S1 × S1 denote the torus. The smooth map F : T2 →R3
given by
F(eiϕ, eiθ) = ((2 + cos ϕ) cos θ, (2 + cosϕ) sin θ, sin ϕ)
is a smooth embedding of T2 into R3 whose image is the doughnut-
shaped surface obtained by revolving the circle (y−2)2 +z2+1 about
the z-axis.
Exercise 5.1.
Verify the claims in the preceding example.
To understand more fully what it means to be an embedding, it is useful
to bear in mind some examples of injective immersions that are not embed-
dings. The next two examples illustrate two rather diﬀerent ways in which
an injective immersion can fail to be an embedding.
Example 5.2. Consider the map γ : (−π/2, 3π/2) →R2 given by
γ(t) = (sin 2t, cost).
Its image is a curve that looks like a ﬁgure eight in the plane (Figure
5.1). (It is the locus of points (x, y) where x2 = 4y2(1 −y2), as you can
check.) It is easy to check that it is an injective immersion because γ ′(t)
never vanishes; but it is not a topological embedding, because its image is
compact in the subspace topology while its domain is not.
Example 5.3. Let T2 = S1 × S1 ⊂C2 denote the torus, and let c by any
irrational number. The map γ : R →T2 given by
γ(t) = (e2πit, e2πict)
is an immersion because γ ′(t) never vanishes. It is also injective, because
γ(t1) = γ(t2) implies that both t1 −t2 and ct1 −ct2 are integers, which is
impossible unless t1 = t2.
Consider the set γ(Z) = {γ(n) : n ∈Z}. If γ were a homeomorphism
onto its image, this set would have no limit point in γ(R), because Z has
no limit point in R. However, we will show that γ(0) is a limit point of
γ(Z). To prove this claim, we need to show that given any ε > 0, there is
a nonzero integer k such that |γ(k) −γ(0)| < ε.

96
5. Submanifolds
−π/2
0
π/2
π
3π/2
γ
FIGURE 5.1. The ﬁgure eight curve of Example 5.2.
Since S1 is compact, the inﬁnite set {e2πicn : n ∈Z} has a limit point,
say z0 ∈S1. Given ε > 0, we can choose distinct integers n1 and n2 such
that |e2πicnj −z0| < ε/2, and therefore |e2πicn1 −e2πicn2| < ε. Taking
k = n1 −n2, this implies that
|e2πick −1| = |e−2πin2(e2πicn1 −e2πicn2)| = |e2πicn1 −e2πicn2| < ε,
and so
|γ(k) −γ(0)| = |(1, e2πick) −(1, 1)| < ε.
In fact, it is not hard to show that the image set γ(R) is actually dense in
T2 (see Problem 5-4).
As the next lemma shows, one simple criterion that rules out such cases
is to require that F be a closed map (i.e., V closed in M implies F(V )
closed in N), for then it follows easily that it is a homeomorphism onto
its image. Another is that F be a proper map, which means that for any
compact set K ⊂N, the inverse image F −1(K) is compact.
Proposition 5.4. Suppose F : M →N is an injective immersion. If any
one of the following conditions holds, then F is an embedding with closed
image.
(a) F is a closed map.
(b) F is a proper map.
(c) M is compact.
Proof. For set-theoretic reasons, there exists an inverse map F −1 : F(M) →
M, and F is an embedding if and only if F −1 is continuous. If F is closed,

Embedded Submanifolds
97
then for every closed set V ⊂M, (F −1)−1(V ) = F(V ) is closed in N and
therefore also in F(M). This implies F −1 is continuous, and proves (a).
Every proper map between manifolds is closed (see [Lee00, Prop. 4.32]), so
(a) implies (b). Finally, a simple topological argument (see [Lee00, Lemma
4.25] shows that every continuous map from a compact space to a Hausdorﬀ
space is closed, so (a) implies (c) as well.
Exercise 5.2.
Show that a composition of submersions is a submersion,
a composition of immersions is an immersion, and a composition of embed-
dings is an embedding.
Embedded Submanifolds
Smooth submanifolds are modeled locally on the standard embedding of
Rk into Rn, identifying Rk with the subspace
{(x1, . . . , xk, xk+1, . . . , xn) : xk+1 = · · · = xn = 0}
of Rn. Somewhat more generally, if U is an open subset of Rn, a k-slice of
U is any subset of the form
S = {(x1, . . . , xk, xk+1, . . . , xn) ∈U : xk+1 = ck+1, . . . , xn = cn}
for some constants ck+1, . . . , cn. Clearly any k-slice is homeomorphic to an
open subset of Rk. (Sometimes it is convenient to consider slices deﬁned by
setting some other subset of the coordinates equal to constants instead of
the last ones. The meaning should be clear from the context.)
Let M be a smooth n-manifold, and let (U, ϕ) be a smooth chart on M.
We say a subset S ⊂U is a k-slice of U if ϕ(S) is a k-slice of ϕ(U). A
subset N ⊂M is called an embedded submanifold of dimension k (or an
embedded k-submanifold or a regular submanifold) of M if for each point
p ∈N there exists a chart (U, ϕ) for M such that p ∈U and U ∩N
is a k-slice of U. In this situation, we call the chart (U, ϕ) a slice chart
for N in M, and the corresponding coordinates (x1, . . . , xn) are called
slice coordinates. The diﬀerence n −k is called the codimension of N in
M. By convention, we consider an open submanifold to be an embedded
submanifold of codimension zero.
The deﬁnition of an embedded submanifold is a local one. It is useful to
express this formally as a lemma.
Lemma 5.5. Let M be a smooth manifold and N a subset of M. Suppose
every point p ∈N has a neighborhood U ⊂M such that U ∩N is an
embedded submanifold of U. Then N is an embedded submanifold of M.
Exercise 5.3.
Prove Lemma 5.5.

98
5. Submanifolds
The next proposition explains the reason for the name “embedded sub-
manifold.”
Proposition 5.6. Let N ⊂M be an embedded k-dimensional submanifold
of M. With the subspace topology, N is a topological manifold of dimension
k, and it has a unique smooth structure such that the inclusion map N ,→
M is a smooth embedding.
Proof. N is automatically Hausdorﬀand second countable because M is,
and both properties are inherited by subspaces. To see that it is locally
Euclidean, we will construct an atlas. For this proof, let π: Rn →Rk denote
the projection onto the ﬁrst k coordinates. For any slice chart (U, ϕ), let
V = U ∩N,
eV = π ◦ϕ(V ),
ψ = π ◦ϕ|V : V →eV .
Then ψ is easily seen to be a homeomorphism, because it has a continuous
inverse given by ϕ−1 ◦j|eV , where j : Rk →Rn is the smooth map
j(x1, . . . , xk) = (x1, . . . , xk, ck+1, . . . , cn).
Thus N is a topological k-manifold, and the inclusion map ι: N ,→M is a
topological embedding (i.e., a homeomorphism onto its image).
To see that N is a smooth manifold, we need to check that the charts
constructed above are smoothly compatible. Suppose (U, ϕ) and (U ′, ϕ′) are
two slice charts for N in M, and let (V, ψ), (V ′, ψ′) be the corresponding
charts for N. The transition map is given by ψ′ ◦ψ−1 = π ◦ϕ′ ◦ϕ−1 ◦j,
which is a composition of the smooth maps π, ϕ′ ◦ϕ−1, and j. Thus the
atlas we have constructed is in fact a smooth atlas, and deﬁnes a smooth
structure on N. In any such chart, the inclusion map N ,→M has the
coordinate representation
(x1, . . . , xk) 7→(x1, . . . , xk, ck+1, . . . , cn),
which is obviously an immersion. Since the inclusion is an injective immer-
sion and a topological embedding, it is a smooth embedding as claimed.
The last thing we have to prove is that this is the unique smooth struc-
ture making the inclusion map a smooth embedding. Suppose that A is a
(possibly diﬀerent) smooth structure on N with the property that N ,→M
is a smooth embedding. To show that the given smooth structure is the
same as the one we have constructed, it suﬃces to show that each of the
charts we constructed above is compatible with every chart in A. Thus let
(U, ϕ) be a slice chart for N in M, let (V, ψ) be the corresponding chart for
N constructed above, and let (W, θ) be an arbitrary chart in A. We need
to show that ψ ◦θ−1 : θ(W ∩V ) →ψ(W ∩V ) is a diﬀeomorphism.

Embedded Submanifolds
99
Observe ﬁrst that ψ ◦θ−1 is a homeomorphism, and is smooth because
it can be written as the following composition of smooth maps:
θ(W ∩V )
θ−1
−→W ∩V
ι,→U
ϕ
−→Rn
π
−→Rk,
where we think of W ∩V as an open subset of N (with the smooth structure
A) and U as an open subset of M. To prove that it is a diﬀeomorphism,
we will show that ψ ◦θ−1 is an immersion and appeal to Proposition 5.7
below, which says that such a map is automatically a diﬀeomorphism. To
show it is an immersion, we must show that its push-forward is injective.
By the argument above, (ψ ◦θ−1)∗= π∗◦ϕ∗◦ι∗◦(θ−1)∗. Each of the linear
maps ϕ∗, ι∗, and (θ−1)∗is injective—in fact ϕ∗and (θ−1)∗are bijective—
and thus their composition is injective. Although π∗is not injective, the
composition will be injective provided Im(ϕ ◦ι ◦θ−1)∗∩Ker π∗= ∅(see
Exercise A.10(b) in the Appendix). Since ι takes its values in N, ϕ◦ι◦θ−1
takes its values in the slice where the coordinates xk+1, . . . , xn are constant:
ϕ ◦ι ◦θ−1(y1, . . . , yk) = (x1(y), . . . , xk(y), ck+1, . . . , cn).
It follows easily that the push-forward of this map at any point takes
its values in the span of (e1, . . . , ek), which has trivial intersection with
Ker π∗= span(ek+1, . . . , en).
In general, a smooth homeomorphism need not have a smooth inverse.
A simple counterexample is the map F : R →R given by F(x) = x3, whose
inverse map is not diﬀerentiable at the origin. The problem in this example
is that the derivative of F vanishes at the origin, which forces the derivative
of the inverse map to blow up. As the next proposition shows, if a smooth
homeomorphism is also an immersion, the inverse map will be smooth.
Proposition 5.7 (Smoothness of Inverse Maps). Suppose M and N
are smooth manifolds of the same dimension, and F : M →N is a homeo-
morphism that is also a smooth immersion. Then F −1 is smooth, so F is
a diﬀeomorphism.
Proof. The only thing that needs to be proved is that F −1 is smooth, which
is a local property, so by restricting to coordinate domains and replacing
F with its coordinate representation, we may as well assume that M and
N are open subsets of Rn.
The assumption that F is an immersion means that the total derivative
DF(a) is injective for each a ∈M, and therefore is invertible for dimen-
sional reasons. If F −1 were diﬀerentiable at b ∈N, the chain rule would
imply
Id = D(F ◦F −1)(b)
= DF(F −1(b)) ◦DF −1(b),

100
5. Submanifolds
from which it would follow that DF −1(b) = DF(F −1(b))−1. We will be-
gin by showing that F −1 is diﬀerentiable at each point of N, with total
derivative given by this formula.
Let b ∈N and set a = F −1(b) ∈M. For v, w ∈Rn small enough that
a + v ∈M and b + w ∈N, deﬁne R(v) and S(w) by
R(v) = F(a + v) −F(a) −DF(a)v,
S(w) = F −1(b + w) −F −1(b) −DF(a)−1w.
Because F
is smooth, it is diﬀerentiable at a, which means that
limv→0 R(v)/|v| = 0. We need to show that limw→0 S(w)/|w| = 0.
For suﬃciently small w ∈Rn, deﬁne
v(w) = F −1(b + w) −F −1(b) = F −1(b + w) −a.
It follows that
F −1(b + w) = F −1(b) + v(w) = a + v(w),
w = (b + w) −b = F(a + v(w)) −F(a),
(5.1)
and therefore
S(w) = F −1(b + w) −F −1(b) −DF(a)−1w
= v(w) −DF(a)−1w
= DF(a)−1(DF(a)v(w) −w)
= DF(a)−1(DF(a)v(w) + F(a) −F(a + v(w)))
= −DF(a)−1R(v(w)).
We will show below that there are positive constants c and C such that
c|w| ≤|v(w)| ≤C|w|
(5.2)
for all suﬃciently small w. In particular, this implies that v(w) ̸= 0 when
w is suﬃciently small and nonzero. From this together with the result of
Exercise A.24 in the Appendix, we conclude that
|S(w)|
|w|
≤|DF(a)−1| |R(v(w))|
|w|
= |DF(a)−1| |R(v(w))|
|v(w)|
|v(w)|
|w|
≤C|DF(a)−1| |R(v(w))|
|v(w)|
,
which approaches zero as w →0 because v(w) →0 and F is diﬀerentiable.

Embedded Submanifolds
101
To complete the proof that F −1 is diﬀerentiable, it remains only to prove
(5.2). From the deﬁnition of R(v) and (5.1),
v(w) = DF(a)−1DF(a)v(w)
= DF(a)−1(F(a + v(w)) −F(a) −R(v(w)))
= DF(a)−1(w −R(v(w))),
which implies
|v(w)| ≤|DF(a)−1| |w| + |DF(a)−1| |R(v(w))|.
Because |R(v)|/|v| →0 as v →0, there exists δ1 > 0 such that |v| < δ1
implies |R(v)| ≤|v|/(2|DF(a)−1|). By continuity of F −1, there exists δ2 >
0 such that |w| < δ2 implies |v(w)| < δ1, and therefore
|v(w)| ≤|DF(a)−1| |w| + (1/2)|v(w)|.
Subtracting (1/2)|v(w)| from both sides, we obtain
|v(w)| ≤2|DF(a)−1| |w|
whenever |w| < δ2. This is the second inequality of (5.2). To prove the ﬁrst,
we use (5.1) again to get
w = F(a + v(w)) −F(a) = DF(a)v(w) + R(v(w)).
Therefore, when |w| < δ2,
|w| ≤|DF(a)| |v(w)| + |R(v(w))| ≤

|DF(a)| +
1
2|DF(a)−1|

|v(w)|.
This completes the proof that F −1 is diﬀerentiable.
By Exercise A.25, the partial derivatives of F −1 are deﬁned at each point
y ∈N. Observe that the formula DF −1(y) = DF(F −1(y))−1 implies that
the map DF −1 : N →GL(n, R) can be written as the composition
N
F −1
−→M
DF
−→GL(n, R)
i
−→GL(n, R),
(5.3)
where i(A) = A−1. Matrix inversion is a smooth map, because GL(n, R) is
a Lie group. Also, DF is a smooth map because its component functions
are the partial derivatives of F, which are assumed to be smooth. Because
DF −1 is a composition of continuous maps, it is continuous, and therefore
the partial derivatives of F −1 are continuous, which means that F −1 is of
class C1.
Now assume by induction that we have shown F −1 is of class Ck. This
means that each of the maps in (5.3) is of class Ck. Because DF −1 is
a composition of Ck functions, it is itself Ck; this implies that the partial
derivatives of F −1 are of class Ck, so F −1 itself is of class Ck+1. Continuing
by induction, we conclude that F −1 is smooth.

102
5. Submanifolds
The Tangent Space to an Embedded Submanifold
If N is an embedded submanifold of Rn, we intuitively think of the tangent
space TpN at a point of N as a subspace of the tangent space TpRn. Sim-
ilarly, the tangent space to a submanifold of an abstract smooth manifold
can be viewed as a subspace of the tangent space to the ambient manifold,
once we make appropriate identiﬁcations.
Let M be a smooth manifold, and let N ⊂M be an embedded sub-
manifold. Since the inclusion map ι: N ,→M is an immersion, at each
point p ∈N we have an injective linear map ι∗: TpN →TpM. We will
adopt the convention of identifying TpN with its image under this map,
thereby thinking of TpN as a certain linear subspace of TpM. Thought of
as a derivation, a vector X ∈TpN, identiﬁed with ι∗X ∈TpM, acts on
smooth functions on M in the following way:
Xf = (ι∗X)f = X(f ◦ι) = X (f|N) .
The next proposition gives a useful way to characterize TpN as a subspace
of TpM.
Proposition 5.8. Suppose N ⊂M is an embedded submanifold and p ∈
N. As a subspace of TpM, the tangent space TpN is given by
TpN = {X ∈TpM : Xf = 0 whenever f ∈C∞(M) and f|N ≡0}.
Proof. First suppose X ∈TpN ⊂TpM. This means, more precisely, that
X = ι∗Y for some Y ∈TpN. If f is any smooth function on M that
vanishes on N, then f ◦ι ≡0, so
Xf = (ι∗Y )f = Y (f ◦ι) ≡0.
Conversely, if X ∈TpM satisﬁes Xf = 0 whenever f vanishes on N,
we need to show that there is a vector Y ∈TpN such that X = ι∗Y . Let
(x1, . . . , xn) be slice coordinates for N in some neighborhood U of p, so
that U ∩N is the subset of U where xk+1 = · · · = xn = 0, and (x1, . . . , xk)
are coordinates for U ∩N. Because the inclusion map ι: N ∩U ,→M has
the coordinate representation
ι(x1, . . . , xk) = (x1, . . . , xk, 0, . . . , 0)
in these coordinates, it follows that TpN (that is, ι∗TpN) is exactly the sub-
space of TpM spanned by ∂/∂x1|p, . . . , ∂/∂xk|p. If we write the coordinate
representation of X as
X =
n
X
i=1
Xi
∂
∂xi

p
,
we see that X ∈TpN if and only if Xi = 0 for i > k.

Embedded Submanifolds
103
Let ϕ be a bump function supported in U that is equal to 1 in a neighbor-
hood of p. Choose an index j > k, and consider the function f(x) = ϕ(x)xj,
extended to be zero on M ∖U. Then f vanishes identically on N, so
0 = Xf =
n
X
i=1
Xi ∂(ϕ(x)xj)
∂xi
(p) = Xj.
Thus X ∈TpN as desired.
Examples of Embedded Submanifolds
One straightforward way to construct embedded submanifolds is by using
the graphs of smooth functions. Let U ⊂Rn be an open set, and let F : U →
Rk be a smooth function. The graph of F is the subset of Rn × Rk deﬁned
by
Γ(F) = {(x, y) ∈Rn × Rk : x ∈U and y = F(x)}.
Lemma 5.9 (Graphs as Submanifolds).
If U
⊂Rn is open and
F : U →Rk is smooth, then the graph of F is an embedded n-dimensional
submanifold of Rn+k.
Proof. Deﬁne a map ϕ: U × Rk →U × Rk by
ϕ(x, y) = (x, y −F(x)).
It is clearly smooth, and in fact it is a diﬀeomorphism because its inverse
can be written explicitly:
ϕ−1(u, v) = (u, v + F(u)).
Because ϕ(Γ(F)) is the slice {(u, v) : v = 0} of U × Rk, this shows that
Γ(F) is an embedded submanifold.
Example 5.10 (Spheres). To show that Sn is an embedded submanifold
of Rn+1, we use the preceding lemma together with Lemma 5.5. Let Bn be
the open unit ball in Rn, and deﬁne functions F ± : Bn →R by
F ±(u) = ±
p
1 −|u|2.
For any i ∈{1, . . . , n}, the intersection of Sn with the open set where xi > 0
is the graph of the smooth function
xi = F +(x1, . . . , xi−1, xi+1, . . . , xn+1).
Similarly, the intersection of Sn with {x : xi < 0} is the graph of F −. Since
every point in Sn is in one of these sets, Lemma 5.5 shows that Sn is an

104
5. Submanifolds
embedded submanifold of Rn+1. The smooth structure thus induced on Sn
is the same as the one we deﬁned in Chapter 1: In fact, the coordinates
for Sn deﬁned by these slice charts are exactly the graph coordinates we
deﬁned in Example 1.11.
Exercise 5.4.
Let U = {(x, y, z) : x, y, z > 0} ⊂R3. and let Φ: U →R3
be the spherical coordinate map
Φ(x, y, z) = (ρ, ϕ, θ)
=
 p
x2 + y2 + z2, cos−1
z
p
x2 + y2 + z2 , cos−1
x
p
x2 + y2
!
.
Show that (U, Φ) is a slice chart for S2 in R3.
As Example 5.10 illustrates, showing directly from the deﬁnition that a
subset of a manifold is an embedded submanifold can be somewhat cum-
bersome. In practice, submanifolds are usually presented to us in one of
the following two ways:
• Level set of a smooth map: Many submanifolds are most natu-
rally deﬁned as the set of points where some smooth map takes on a
ﬁxed value, called a level set of the map. For example, the n-sphere
Sn ⊂Rn+1 is deﬁned as the level set f −1(1), where f : Rn+1 →R is
the function f(x) = |x|2.
• Image of a smooth map: In some cases, it is more natural to de-
scribe a submanifold as the image of a smooth map. For example,
the map F : R2 →R3 given by F(θ, ϕ) = ((2 + cos ϕ) cos θ, (2 +
cos ϕ) sin θ, sin ϕ) has as its image a doughnut-shaped torus of revo-
lution.
Thus two important questions we will need to address are:
• When is a level set of a smooth map an embedded submanifold?
• When is the image of a smooth map an embedded submanifold?
It is easy to construct examples of both cases that are not embedded
submanifolds. For example, the smooth map F : R →R2 deﬁned by
F(t) = (t2, t3) has as its image a curve that has a “cusp” or “kink” at
the origin. Similarly, the map Φ: R2 →R given by Φ(x, y) = xy has the
union of the x and y axes as its zero level set. As Problem 5-5 shows, neither
of these sets is an embedded submanifold of R2.
The rest of this chapter is devoted to the study of these two questions,
and in particular to developing suﬃcient conditions under which both kinds
of sets are embedded submanifolds.

The Inverse Function Theorem and Its Friends
105
The Inverse Function Theorem and Its Friends
The key to answering the questions at the end of the previous section is
understanding how the local behavior of a smooth map is modeled by the
behavior of its push-forward. To set the stage, we will consider a linear
version of the problem: Let S be a k-dimensional linear subspace of Rn,
and let us examine how we might use linear maps to deﬁne it.
First, every subspace S is the kernel of some linear map. (Such a linear
map is easily constructed by choosing a basis for S and extending it to
a basis for Rn.) By the rank-nullity law, if S = KerL, then Im L must
have dimension n −k. Therefore, a natural way to deﬁne a k-dimensional
subspace S ⊂Rn is to give a surjective linear map L: Rn →Rn−k whose
kernel is S. The vector equation Lx = 0 is equivalent to n −k scalar
equations, each of which can be thought of as “cutting out” one more
dimension of S.
On the other hand, every subspace is also the image of some linear map. A
choice of basis for S can be used to deﬁne an injective linear map E : Rk →
Rn whose image is S. Such a map can be thought of as a “parametrization”
of S.
In the context of smooth manifolds, the analogue of a surjective linear
map is a submersion, and the analogue of an injective linear map is an
immersion. Let M be an n-manifold. By analogy with the linear situation,
we might expect that a level set of a submersion from M to an (n −k)-
manifold is an embedded k-dimensional submanifold of M. We will see
below that this is the case. Analogously, we might expect that the image of
a smooth embedding from a k-manifold to M is an embedded k-dimensional
submanifold. This is also the case.
The basis for all these results is the following analytic theorem. It is
the simplest of several results we will develop in this section that show
how the local behavior of a smooth map is modeled by the behavior of its
push-forward.
Theorem 5.11 (Inverse Function Theorem).
Suppose M and N are
smooth manifolds and F : M →N is a smooth map. If F∗is invertible at
a point p ∈M, then there exist connected neighborhoods U0 of p and V0 of
F(p) such that F : U0 →V0 is a diﬀeomorphism.
The proof of this theorem is based on the following elementary result
about metric spaces. If X is a metric space, a map G: X →X is said to be
a contraction if there is a constant λ < 1 such that d(G(x), G(y)) ≤λd(x, y)
for all x, y ∈X. Clearly any contraction is continuous.
Lemma 5.12 (Contraction Lemma).
Let X be a complete metric
space. Every contraction G: X →X has a unique ﬁxed point, i.e., a point
x ∈X such that G(x) = x.

106
5. Submanifolds
Proof. Uniqueness is immediate, for if x and x′ are both ﬁxed points of
G, the contraction property implies d(x, x′) = d(G(x), G(x′)) ≤λd(x, x′),
which is possible only if x = x′.
To prove the existence of a ﬁxed point, let x0 be an arbitrary point in
X, and deﬁne a sequence {xn} inductively by xn+1 = G(xn). For any i ≥1
we have d(xi, xi+1) = d(G(xi−1), G(xi)) ≤λd(xi−1, xi), and therefore by
induction
d(xi, xi+1) ≤λid(x0, x1).
If j ≥i ≥N,
d(xi, xj) ≤d(xi, xi+1) + d(xi+1, xi+2) + · · · + d(xj−1, xj)
≤(λi + · · · + λj−1)d(x0, x1)
≤λi
 ∞
X
n=0
λn

d(x0, x1)
≤
λN
1 −λd(x0, x1).
Since this last expression can be made as small as desired by choosing
N large, the sequence {xn} is Cauchy and therefore converges to a limit
x ∈X. Because G is continuous,
G(x) = G

lim
n→∞xn

= lim
n→∞G(xn) = lim
n→∞xn+1 = x,
so x is the desired ﬁxed point.
Proof of the inverse function theorem.
The fact that F∗: TpM →TF (p)N
is an isomorphism implies that M and N have the same dimension n.
Choose coordinate domains U centered at p and V centered at F(p); con-
sidering the coordinate maps as identiﬁcations as usual, we may as well
assume that U and V are actually open subsets of Rn and F(0) = 0. The
map F1 = DF(0)−1◦F satisﬁes F1(0) = 0 and DF1(0) = Id. If the theorem
is true for F1, then it is true for F = DF(0) ◦F1. Henceforth, replacing F
by F1, we will assume that F is deﬁned in a neighborhood of 0, F(0) = 0,
and DF(0) = Id.
Let H(x) = x −F(x). Then DH(0) = Id −Id = 0. Because the matrix
entries of DH(x) are continuous functions of x, there is a number ε > 0
such that |DH(x)| ≤1/2 for all x ∈Bε(0). If x, x′ ∈Bε(0), the Lipschitz
estimate for smooth functions (Proposition A.28 in the Appendix) implies
|H(x′) −H(x)| ≤1
2|x′ −x|.
(5.4)
Since x′ −x = F(x′) −F(x) + H(x′) −H(x), it follows that
|x′ −x| ≤|F(x′) −F(x)| + |H(x′) −H(x)| ≤|F(x′) −F(x)| + 1
2|x′ −x|.

The Inverse Function Theorem and Its Friends
107
Subtracting 1
2|x′ −x| from both sides, we conclude that
|x′ −x| ≤2|F(x′) −F(x)|
(5.5)
for all x, x′ ∈Bε(0). In particular, this shows that F is injective on Bε(0).
Now let y ∈Bε/2(0) be arbitrary. We will show that there exists x ∈
Bε(0) such that F(x) = y. Let G(x) = H(x) + y = x −F(x) + y, so that
G(x) = x if and only if F(x) = y. If |x| ≤ε, (5.4) implies
|G(x)| ≤|H(x)| + |y| < 1
2|x| + ε
2 ≤ε,
(5.6)
so G maps Bε(0) to itself. It follows from (5.4) that |G(x) −G(x′)| =
|H(x) −H(x′)| ≤1
2|x′ −x|, so G is a contraction. Since Bε(0) is compact
and therefore complete, the contraction lemma implies that G has a unique
ﬁxed point x ∈Bε(0). From (5.6), |x| = |G(x)| < ε, so in fact x ∈Bε(0),
thus proving the claim.
Let U = Bε(0)∩F −1(Bε/2(0)). Then U is open, and the argument above
shows that F : U →Bε/2(0) is bijective, so F −1 : Bε/2(0) →U exists.
Substituting x = F −1(y) and x′ = F −1(y′) into (5.5) shows that F −1 is
continuous. Let U0 be the connected component of U containing 0, and
V0 = F(U0). Then F : U0 →V0 is a homeomorphism, and Proposition 5.7
shows that it is a diﬀeomorphism.
For our purposes, the most important consequence of the inverse function
theorem is the following, which says that a constant-rank smooth map can
be placed locally into a particularly simple canonical form by a change of
coordinates. It is a nonlinear version of the canonical form theorem for
linear maps (Theorem A.4).
Theorem 5.13 (Rank Theorem). Suppose M and N are smooth mani-
folds of dimensions m and n, respectively, and F : M →N is a smooth map
with constant rank k. For each p ∈M there exist coordinates (x1, . . . , xm)
centered at p and (v1, . . . , vn) centered at F(p) in which F has the following
coordinate representation:
F(x1, . . . , xm) = (x1, . . . , xk, 0, . . . , 0).
(5.7)
Proof. Replacing M and N by coordinate domains U ⊂M near p and
V ⊂N near F(p) and replacing F by its coordinate representation, we
may as well assume that F : U →V where U is an open subset of Rm and
V is an open subset of Rn. The fact that DF(p) has rank k implies that
its matrix has some k × k minor with nonzero determinant. By reordering
the coordinates, we may assume that it is the upper left minor, (∂F i/∂xj)
for i, j = 1, . . . , k. Let us relabel the standard coordinates as (x, y) =
(x1, . . . , xk, y1, . . . , ym−k) in Rm and (v, w) = (v1, . . . , vk, w1, . . . , wn−k) in
Rn. If we write F(x, y) = (Q(x, y), R(x, y)), then our hypothesis is that
(∂Qi/∂xj) is nonsingular at p.

108
5. Submanifolds
Deﬁne ϕ: U →Rm by
ϕ(x, y) = (Q(x, y), y).
Its total derivative at p is
Dϕ(p) =



∂Qi
∂xj (p)
∂Qi
∂yj (p)
0
Im−k


,
which is nonsingular because its columns are independent. Therefore, by
the inverse function theorem, there are connected neighborhoods U0 of p
and V0 of ϕ(p) such that ϕ: U0 →V0 is a diﬀeomorphism. Writing the
inverse map as ϕ−1(x, y) = (A(x, y), B(x, y)) for some smooth functions
A: V0 →Rk and B : V0 →Rm−k, we compute
(x, y) = ϕ(ϕ−1(x, y))
= ϕ(A(x, y), B(x, y))
= (Q(A(x, y), B(x, y)), B(x, y)).
(5.8)
Comparing y components, it follows that B(x, y) = y, and therefore ϕ−1
has the form
ϕ−1(x, y) = (A(x, y), y).
We will take ϕ: U0 →Rm as our coordinate chart near p. Observe that
ϕ ◦ϕ−1 = Id implies Q(A(x, y), y) = x, and therefore F ◦ϕ−1 has the form
F ◦ϕ−1(x, y) = (x, eR(x, y)),
where we have put eR(x, y) = R(A(x, y), y).
The Jacobian matrix of this map at an arbitrary point (x, y) ∈ϕ(U0) is
D(F ◦ϕ−1)(x, y) =




Ik
0
∂eRi
∂xj
∂eRi
∂yj



.
Since composing with a diﬀeomorphism does not change the rank of a
map, this matrix has rank exactly equal to k everywhere in U0. Since the
ﬁrst k columns are obviously independent, the rank can be k only if the
partial derivatives ∂eRi/∂yj vanish identically on U0, which implies that eR
is actually independent of (y1, . . . , ym−k). Thus in fact
F ◦ϕ−1(x, y) = (x, eR(x)).

The Inverse Function Theorem and Its Friends
109
To complete the proof, we need to choose coordinates for Rn near F(p).
Deﬁne ψ: V0 →Rn by
ψ(v, w) = (v, w −eR(v)).
This is a diﬀeomorphism onto its image, because its inverse is given explic-
itly by ψ−1(v, w) = (v, w + eR(v)); thus ψ is a coordinate chart on V0. In
terms of the coordinate maps ϕ for the domain and ψ for the range, F has
the coordinate representation
ψ ◦F ◦ϕ−1(x, y) = ψ(x, eR(x)) = (x, eR(x) −eR(x)) = (x, 0),
which was to be proved.
The following corollary can be viewed as a somewhat more invariant
statement of the rank theorem.
Corollary 5.14. Let F : M →N be a smooth map, and suppose M is
connected. Then the following are equivalent:
(a) For each p ∈M there exist coordinates near p and F(p) in which the
coordinate representation of F is linear.
(b) F has constant rank.
Proof. First suppose F has a linear coordinate representation in a neigh-
borhood of each point. Since any linear map has constant rank, it follows
that the rank of F is constant in a neighborhood of each point, and thus
by connectedness it is constant on all of M. Conversely, if F has constant
rank, the rank theorem shows that it has the linear coordinate representa-
tion (5.7) in a neighborhood of each point.
Another useful consequence of the inverse function theorem is the implicit
function theorem, which gives conditions under which a level set of a smooth
map is locally the graph of a smooth function.
Theorem 5.15 (Implicit Function Theorem).
Let U ⊂Rn × Rk be
an open set, and let (x, y) = (x1, . . . , xn, y1, . . . , yk) denote the standard
coordinates on U. Suppose Φ: U →Rk is a smooth map, (a, b) ∈U, and
c = Φ(a, b). If the k × k matrix
∂Φi
∂yj (a, b)

is nonsingular, then there exist neighborhoods V0 of a and W0 of b and a
smooth map F : V0 →W0 such that Φ−1(c) ∩V0 × W0 is the graph of F,
i.e., Φ(x, y) = c for (x, y) ∈V0 × W0 if and only if y = F(x).

110
5. Submanifolds
Proof. Under the hypotheses of the theorem, consider the smooth map
Ψ: U →Rn × Rk deﬁned by Ψ(x, y) = (x, Φ(x, y)). Its total derivative at
(a, b) is
DΨ(a, b) =



In
0
∂Φi
∂xj (a, b)
∂Φi
∂yj (a, b)


,
which is nonsingular by hypothesis. Thus by the inverse function theorem
there exist connected neighborhoods U0 of (a, b) and Y0 of (a, c) such that
Ψ: U0 →Y0 is a diﬀeomorphism. Shrinking U0 and Y0 if necessary, we may
assume U0 = V × W is a product neighborhood. Arguing exactly as in the
proof of the rank theorem (but with the roles of x and y reversed), the
inverse map has the form
Ψ−1(x, y) = (x, B(x, y))
for some smooth map B : Y0 →W.
Now let V0 = {x ∈V : (x, c) ∈Y0} and W0 = W, and deﬁne F : V0 →W0
by F(x) = B(x, c). Comparing y components in the relation (x, c) = Ψ ◦
Ψ−1(x, c) yields
c = Φ(x, B(x, c)) = Φ(x, F(x))
whenever x ∈V0, so the graph of F is contained in Φ−1(c). Conversely,
suppose (x, y) ∈V0 × W0 and Φ(x, y) = c. Then Ψ(x, y) = (x, Φ(x, y)) =
(x, c), so
(x, y) = Ψ−1(x, c) = (x, B(x, c)) = (x, F(x)),
which implies that y = F(x). This completes the proof.
First Consequences
When we apply the inverse function theorem and its consequences to maps
between manifolds, we obtain a wealth of important results. The ﬁrst one
is a signiﬁcant strenghthening of Proposition 5.7.
Proposition 5.16. Suppose M and N are smooth manifolds of the same
dimension, and F : M →N is a smooth immersion. Then F is a local
diﬀeomorphism. If F is bijective, it is a diﬀeomorphism.
Proof. The fact that F is an immersion means that F∗is bijective at each
point for dimensional reasons. Then the fact that F is a local diﬀeomor-
phism is an immediate consequence of the inverse function theorem. If F
is bijective, then it is a diﬀeomorphism by Exercise 2.5.

The Inverse Function Theorem and Its Friends
111
The next proposition is a powerful consequence of the rank theorem. (In
Chapter 6, we will generalize this proposition to characterize surjective and
bijective maps of constant rank.)
Proposition 5.17. Let F : M →N be a smooth map of constant rank. If
F is injective, then it is an immersion.
Proof. Let m = dim M, n = dim N, and suppose F has constant rank k. If
F is not an immersion, then k < m. By the rank theorem, in a neighborhood
of any point there is a chart in which F has the coordinate representation
F(x1, . . . , xm) = (x1, . . . , xk, 0, . . . , 0).
(5.9)
It follows that F(0, . . . , 0, ε) = F(0, . . . , 0, 0) for any suﬃciently small ε, so
F is not injective.
Another important application of the rank theorem is to vastly expand
our understanding of the properties of submersions. As the next few results
show, surjective submersions play a role in smooth manifold theory closely
analogous to the role played by quotient maps in topology.
Proposition 5.18 (Properties of Submersions).
Let π: M →N be
a submersion.
(a) π is an open map.
(b) Every point of M is in the image of a smooth local section of π.
(c) If π is surjective, it is a quotient map.
Proof. Given p ∈M, let q = π(p) ∈N. Because a submersion has con-
stant rank, by the rank theorem we can choose coordinates (x1, . . . , xm)
centered at p and (y1, . . . , yk) centered at q in which π has the coordi-
nate representation π(x1, . . . , xm) = (x1, . . . , xk). If ε is a suﬃciently small
positive number, the coordinate cube
Cε = {x : |xi| < ε for i = 1, . . . , m}
is a neighborhood of p whose image under π is the cube
C′
ε = {y : |yi| < ε for i = 1, . . . , k}.
The map σ: C′
ε →Cε whose coordinate representation is σ(x1, . . . , xk) =
(x1, . . . , xk, 0, . . . , 0) is a smooth local section of π satisfying σ(q) = p. This
proves (b).
Suppose W is any open subset of M and q ∈π(W). For any p ∈W such
that π(p) = q, W contains an open coordinate cube Cε centered at p as
above, and thus π(W) contains an open coordinate cube centered at π(p).
This proves that W is open, so (a) holds. Because a surjective open map is
automatically a quotient map, (c) follows from (a).

112
5. Submanifolds
The next three propositions provide important tools that we will use
frequently when studying submersions. The general philosophy is one that
we will see repeatedly in this book: to “push” a smooth object (such as
a smooth map) down via a submersion, pull it back via local sections. It
is convenient to introduce the following terminology: If π: M →N is any
surjective map, the ﬁber of π over q ∈N is the set π−1(q) ⊂M.
Proposition 5.19. Suppose M, N, and P are smooth manifolds, π: M →
N is a surjective submersion, and F : N →P is any map. Then F is smooth
if and only if F ◦π is smooth:
N
P.
-
F
F ◦π
@
@
@@
R
M
?
π
Proof. If F is smooth, then F ◦π is smooth by composition. Conversely,
suppose that F ◦π is smooth. For any q ∈N, let σ: U →M be a smooth
section of π deﬁned on a neighborhood U of q. Then π ◦σ = IdU implies
F|U = F ◦IdU = (F ◦π) ◦σ,
which is a composition of smooth maps. This shows that F is smooth in a
neighborhood of each point, so it is smooth.
The next proposition gives a very general suﬃcient condition under which
a smooth map can be “pushed down” by a submersion.
Proposition 5.20 (Passing Smoothly to the Quotient).
Suppose
π: M →N is a surjective submersion. If F : M →P is a smooth map
that is constant on the ﬁbers of π, then there is a unique smooth map
eF : N →P such that eF ◦π = F:
N
P.
-
eF
F
@
@
@@
R
M
?
π
Proof. Clearly, if eF exists, it will have to satisfy eF(q) = F(p) whenever
p ∈π−1(q). We use this to deﬁne eF: Given q ∈M, let eF(q) = F(p), where
p ∈M is any point in the ﬁber over q. (Such a point exists because we are
assuming that π is surjective.) This is well-deﬁned because F is constant
on the ﬁbers of π, and it satisﬁes eF ◦π = F by construction. Thus eF is
smooth by Proposition 5.19.

Level Sets
113
Our third proposition can be interpreted as a uniqueness result for
smooth manifolds deﬁned as quotients of other smooth manifolds by sub-
mersions.
Proposition 5.21. Suppose π1 : M →N1 and π2 : M →N2 are surjective
submersions that are constant on each other’s ﬁbers (i.e., π1(p) = π1(p′)
if and only if π2(p) = π2(p′)). Then there exists a unique diﬀeomorphism
F : N1 →N2 such that F ◦π1 = π2:
N1
N2.
-
F
M
π1
   	
π2
@
@@
R
Exercise 5.5.
Prove Proposition 5.21.
Level Sets
Using the tools we have developed so far, we can now give some very general
criteria for level sets to be submanifolds.
Theorem 5.22 (Constant Rank Level Set Theorem).
Let M and
N be smooth manifolds, and let F : M →N be a smooth map with constant
rank k. Each level set of F is a closed embedded submanifold of codimension
k in M.
Proof. Let c ∈N be arbitrary, and let S denote the level set F −1(c) ⊂
M. Clearly S is closed in M by continuity. To show it is an embedded
submanifold, we need to show that for each p ∈S there is a slice chart for
S in M near p. From the rank theorem, there are coordinate charts (U, ϕ)
centered at p and (V, ψ) centered at c = F(p) in which F has the coordinate
representation (5.7), and therefore S ∩U is the slice {(x1, . . . , xn) ∈U :
x1 = · · · = xk = 0}.
Corollary 5.23 (Submersion Theorem).
If F : M →N is a submer-
sion, then each level set of F is a closed embedded submanifold whose codi-
mension is equal to the dimension of N.
Proof. A submersion has constant rank equal to the dimension of N.
This result is extremely useful, because many submanifolds are most nat-
urally presented as level sets of submersions. In fact, it can be strengthened
considerably, because we need only check the rank condition on the level
set we are interested in. If F : M →N is a smooth map, a point p ∈M
is said to be a regular point of F if F∗: TpM →TF (p)N is surjective; it is
a critical point otherwise. (This means, in particular, that every point is

114
5. Submanifolds
critical if dim M < dim N.) A point c ∈N is said to be a regular value of
F if every point of the level set F −1(c) is a regular point, and a critical
value otherwise. In particular, if F −1(c) = ∅, c is regular. Finally, a level
set F −1(c) is called a regular level set if c is a regular value; in other words,
a regular level set is a level set consisting entirely of regular points.
Corollary 5.24 (Regular Level Set Theorem).
Every regular level
set of a smooth map is a closed embedded submanifold whose codimension
is equal to the dimension of the range.
Proof. Let F : M →N be a smooth map and let c ∈N be a regular value
such that F −1(c) ̸= ∅. The fact that c is a regular value means that F∗has
rank equal to the dimension of N at every point of F −1(c). To prove the
corollary, it suﬃces to show that the set U of points where rankF∗= dim N
is open in M, for then we can apply the preceding corollary with M replaced
by U.
To see that U is open, let m = dim M, n = dim N, and suppose p ∈U.
Choosing coordinates near p and F(p), the assumption that rank F∗= n
at p means that the n × m matrix representing F∗in coordinates has an
n×n minor whose determinant is nonzero. By continuity, this determinant
will be nonzero in some neighborhood of p, which means that F has rank
n in this whole neighborhood.
Exercise 5.6.
If f : M →R is a smooth real-valued function, show that
p ∈M is a regular point of f if and only if dfp ̸= 0.
Example 5.25 (Spheres).
Using Corollary 5.24, we can give a much
easier proof that Sn is an embedded submanifold of Rn+1. The sphere is
easily seen to be a regular level set of the function f : Rn+1 →R given by
f(x) = |x|2, since df = 2 P
i xi dxi vanishes only at the origin, and thus it
is an embedded n-dimensional submanifold of Rn+1.
Example 5.26 (The Orthogonal Group).
A real n × n matrix A is
said to be orthogonal if the linear map A: Rn →Rn preserves the Euclidean
inner product:
(Ax) · (Ay) = x · y.
The set O(n) of all orthogonal n × n matrices is clearly a subgroup of
GL(n, R), called the n-dimensional orthogonal group.
It is easy to see that a matrix A is orthogonal if and only if it takes the
standard basis of Rn to an orthonormal basis, which is equivalent to the
columns of A being orthonormal. Since the (i, j)-entry of the matrix AT A
is the dot product of the ith and jth columns of A, this condition is also
equivalent to the requirement that AT A = In. We will show that O(n) is
an embedded submanifold of GL(n, R).

Level Sets
115
Let S(n, R) denote the set of symmetric n × n matrices, which is easily
seen to be a linear subspace of M(n, R) of dimension n(n + 1)/2 because
each symmetric matrix is uniquely determined by its values on and above
the main diagonal. Deﬁne Φ: GL(n, R) →S(n, R) by
Φ(A) = AT A.
We will show that the identity matrix In is a regular value of Φ, from which
it follows that O(n) = Φ−1(In) is an embedded submanifold of codimension
n(n + 1)/2, that is, of dimension n2 −n(n + 1)/2 = n(n −1)/2.
Let A ∈O(n) be arbitrary, and let us compute the push-forward
Φ∗: TA GL(n, R) →TΦ(A) S(n, R). We can identify the tangent spaces
TA GL(n, R) and TΦ(A) S(n, R) with M(n, R) and S(n, R), respectively, be-
cause GL(n, R) is an open subset of the vector space M(n, R) and S(n, R)
is itself a vector space. For any B ∈M(n, R), the curve γ(t) = A + tB
satisﬁes γ(0) = A and γ ′(0) = B. We compute
Φ∗B = Φ∗γ ′(0) = (Φ ◦γ)′(0) = d
dt

t=0
Φ(A + tB)
= d
dt

t=0
(A + tB)T (A + tB) = BT A + AT B.
If C ∈S(n, R) is arbitrary,
Φ∗( 1
2AC) = 1
2CT AT A + 1
2AT AC = 1
2C + 1
2C = C.
Thus Φ∗is surjective, which proves the claim.
Example 5.27 (The Special Linear Group). The special linear group
SL(n, R) is the set of n × n matrices with determinant equal to 1. Because
the determinant function satisﬁes det(AB) = det A det B, SL(n, R) is a
subgroup of GL(n, R). We will show that det: GL(n, R) →R is a smooth
submersion, from which it follows that SL(n, R) = det−1(1) is an embedded
submanifold. Let A ∈GL(n, R) be arbitrary. Problem 4-10 shows that
the diﬀerential of det is given by d(det)A(B) = (det A) tr(A−1B) for B ∈
TA GL(n, R) ∼= M(n, R). Choosing B = A yields
d(det)A(A) = (det A) tr(A−1A) = (det A) tr(In) = n det A ̸= 0.
This shows that d(det) never vanishes on GL(n, R), so det is a submersion
and SL(n, R) is an embedded submanifold of dimension n2 −1 in GL(n, R).
Not all embedded submanifolds are naturally given as level sets of sub-
mersions as in these examples. However, the next proposition shows that
every embedded submanifold is at least locally of this form.

116
5. Submanifolds
Proposition 5.28. Let S be a subset of a smooth n-manifold M. Then
S is an embedded k-submanifold of M if and only if every point p ∈S
has a neighborhood U in M such that U ∩S is a level set of a submersion
F : U →Rn−k.
Proof. First suppose S is an embedded k-submanifold. If (x1, . . . , xn) are
slice coordinates for S on an open set U ⊂M, the map F : U →Rn−k given
in coordinates by F(x) = (xk+1, . . . , xn) is easily seen to be a submersion
whose zero level set is S ∩U. Conversely, suppose that around every point
p ∈S there is a neighborhood U and a submersion F : U →Rn−k such that
S∩U = F −1(c) for some c ∈Rn−k. By the submersion theorem, S∩U is an
embedded submanifold of U, and so by Lemma 5.5, S is itself an embedded
submanifold.
If S ⊂M is an embedded submanifold, a smooth map F : M →N such
that S is a regular level set of F is called a deﬁning map for S. In the special
case N = Rn−k (so that F is a real-valued or vector-valued function), it is
usually called a deﬁning function. Examples 5.25 through 5.27 show that
f(x) = |x|2 is a deﬁning function for the sphere, Φ(A) = AT A is a deﬁning
function for O(n), and the determinant is a deﬁning function for SL(n, R).
More generally, if U is an open subset of M and F : U →N is a smooth
map such that S ∩U is a regular level set of F, then F is called a local
deﬁning map (or local deﬁning function if N = Rn−k) for S. Proposition
5.28 says that every embedded submanifold admits a local deﬁning function
in a neighborhood of each point.
The next lemma shows that deﬁning maps give a concise characterization
of the tangent space to an embedded submanifold.
Lemma 5.29. Suppose S ⊂M is an embedded submanifold. If F : U →N
is any local deﬁning map for S, then TpS = Ker F∗: TpM →TF (p)N for
each p ∈U.
Proof. Recall that we identify TpS with the subspace ι∗(TpS) ⊂TpM,
where ι: S ,→M is the inclusion map. Because F ◦ι is constant on S ∩U,
it follows that F∗◦ι∗is the zero map from TpS to TF (p)N, and therefore
Im ι∗⊂Ker F∗. On the other hand, F∗is surjective by the deﬁnition of a
deﬁning map, so the rank-nullity law implies that
dim Ker F∗= dim TpM −dim TF (p)N = dim TpS = dim Im ι∗,
which implies that Im ι∗= Ker F∗.
Our next example is a bit more complicated. It will be of use to us in
the next chapter.
Example 5.30 (Matrices of ﬁxed rank).
As in Chapter 1, let M(m ×
n, R) denote the mn-dimensional vector space of m × n real matrices. For

Level Sets
117
any k, let Mk(m × n, R) denote the subset of M(m × n, R) consisting of
matrices of rank k. We showed in Example 1.10 that Mk(m × n, R) is an
open submanifold of M(m × n, R) when k = min(m, n). Now we will show
that when 0 ≤k ≤min(m, n), Mk(m × n, R) is an embedded submanifold
of codimension (m −k)(n −k) in M(m × n, R).
Let E0 be an arbitrary m × n matrix of rank k. This implies that E0
has some k × k minor with nonzero determinant. For the time being, let us
assume that it is the upper left minor. Writing E0 in block form as
E0 =

A0
B0
C0
D0

,
where A0 is a k×k matrix and D0 is of size (m−k)×(n−k), our assumption
is that A0 is nonsingular.
Let U be the set
U =
A
B
C
D

∈M(m × n, R) : det A ̸= 0

.
By continuity of the determinant function, U is an open subset of M(m ×
n, R) containing E0. Given E = ( A B
C D ) ∈U, consider the invertible n × n
matrix
P =
A−1
−A−1B
0
In−k

.
Since multiplication by an invertible matrix does not change the rank of a
matrix, the rank of E is the same as that of
EP =

A
B
C
D
 
A−1
−A−1B
0
In−k

=

Ik
0
CA−1
D −CA−1B

.
(5.10)
Clearly EP has rank k if and only if D −CA−1B is the zero matrix. (To
understand where P came from, observe that E has rank k if and only if
it can be reduced by elementary column operations to a matrix whose last
n −k columns are zero. Since elementary column operations correspond to
right multiplication by invertible matrices, it is natural to look for a matrix
P satisfying (5.10).)
Thus we are led to deﬁne F : U →M(m −k × n −k, R) by
F

A
B
C
D

= D −CA−1B.
Clearly F is smooth. To show that it is a submersion, we need to show
that DF(E) is surjective for each E ∈U. Since M(m −k × n −k, R) is
a vector space, tangent vectors at F(E) can be naturally identiﬁed with

118
5. Submanifolds
(m −k) × (n −k) matrices. Given E = ( A B
C D ) and any matrix X ∈M(m −
k × n −k, R), deﬁne a curve γ : (−ε, ε) →U by
γ(t) =
A
B
C
D + tX

.
Then
F∗γ ′(0) = (F ◦γ)′(t) = d
dt

t=0
(D + tX −CA−1B) = X.
Thus F is a submersion and so Mk(m × n, R) ∩U is an embedded subman-
ifold of U.
Now if E′
0 is an arbitrary matrix of rank k, just note that it can be
transformed to one in U by a rearrangement of its rows and columns. Such
a rearrangement is a linear isomorphism R: M(m × n, R) →M(m × n, R)
that preserves rank, so U ′ = R−1(U) is a neighborhood of E′
0 and F ◦
R: U ′ →M(m −k × n −k, R) is a submersion whose zero level set is
Mk(m × n, R) ∩U ′. Thus every point in Mk(m × n, R) has a neighborhood
U ′ in M(m×n, R) such that U ′∩Mk(m×n, R) is an embedded submanifold
of U ′, so Mk(m × n, R) is an embedded submanifold by Lemma 5.5.
Images of Embeddings and Immersions
The next question we want to address is when the image of a smooth
map is an embedded submanifold. The most important case is that of an
embedding, for which the answer is provided by the following theorem.
Theorem 5.31. The image of a smooth embedding is an embedded sub-
manifold.
Proof. Let F : N →M be an embedding. We need to show that each point
of F(N) has a coordinate neighborhood U ⊂M in which F(N) ∩U is a
slice.
Let p ∈N be arbitrary, and let (U, ϕ), (V, ψ) be coordinate charts cen-
tered at p and F(p) in which F|U : U →V has the coordinate representation
(5.7). In particular (shrinking U and V if necessary), this implies that F(U)
is a slice in V . Because an embedding is a homeomorphism onto its image
with the subspace topology, the fact that F(U) is open in F(N) means
that there is an open set W ⊂M such that F(U) = W ∩F(N). Replacing
V by eV = V ∩W, we obtain a slice chart (eV , ψ|eV ) containing F(p) such
that eV ∩F(N) = eV ∩F(U) is a slice of eV .
The preceding theorem combined with Proposition 5.6 can be summa-
rized by the following corollary.
Corollary 5.32. Embedded submanifolds are precisely the images of em-
beddings.

Images of Embeddings and Immersions
119
Immersed Submanifolds
Although embedded submanifolds are the most natural and common sub-
manifolds and suﬃce for most purposes, it is sometimes important to con-
sider a more general notion of submanifold. In particular, when we study Lie
groups later in this chapter and foliations in chapter 14, we will encounter
subsets of smooth manifolds that are images of injective immersions, but
not necessarily of embeddings. To see what kinds of phenomena occur, look
back again at the two examples we introduced earlier of injective immer-
sions that are not embeddings. The “ﬁgure eight curve” of Example 5.2
and the dense curve on the torus of Example 5.3 are both injective im-
mersions but not embeddings. In fact, their image sets are not embedded
submanifolds (see Problems 5-3 and 5-4).
So as to have a convenient language for talking about examples like
these, we make the following deﬁnition. Let M be a smooth manifold. An
immersed submanifold of dimension k (or immersed k-submanifold) of M
is a subset N ⊂M endowed with a k-manifold topology (not necessarily
the subspace topology) together with a smooth structure such that the
inclusion map ι: N ,→M is a smooth immersion.
Immersed submanifolds usually arise in the following way. Given an in-
jective immersion F : N →M, we can give the image set F(N) ⊂M a
topology simply by declaring a set U ⊂F(N) to be open if and only if
F −1(U) ⊂N is open. With this topology, F(N) is clearly a topological
k-manifold homeomorphic to N, and there is a unique smooth structure on
it such that F : N →F(N) is a diﬀeomorphism. (The smooth coordinate
maps are just the maps of the form ϕ◦F −1, where ϕ is a smooth coordinate
map for N.) With this topology and smooth structure, ι: F(N) ,→M is
clearly a smooth immersion, because it is equal to the composition of a
diﬀeomorphism followed by an immersion:
F(N)
F −1
−→N
F
−→M.
Example 5.33 (Immersed Submanifolds).
Because the ﬁgure eight
of Example 5.2 and the dense curve of Example 5.3 are images of injec-
tive immersions, they are immersed submanifolds when given appropriate
topologies and smooth structures. As smooth manifolds, they are diﬀeomor-
phic to R. They are not embedded, because neither one has the subspace
topology.
Since the inclusion map of an immersed submanifold is by deﬁnition
an injective immersion, this discussion shows that immersed submanifolds
are precisely the images of injective immersions. Clearly every embedded
submanifold is also an immersed submanifold. The converse is not true:
An immersed submanifold is embedded precisely when it has the subspace
topology, or equivalently when the immersion is an embedding.

120
5. Submanifolds
The following lemma shows that the local structure of an immersed sub-
manifold is the same as that of an embedded one.
Lemma 5.34. Let F : N →M be an immersion. Then F is locally an
embedding: For any p ∈N, there exists a neighborhood U of p in N such
that F|U : U →M is an embedding.
Exercise 5.7.
Prove Lemma 5.34.
It is important to be clear about what this lemma does and does not say.
Given an immersed submanifold N ⊂M and a point p ∈N, it is possible
to ﬁnd a neighborhood U of p (in N) such that U is embedded; but it may
not be possible to ﬁnd a neighborhood V of p in M such that V ∩N is
embedded.
Because immersed submanifolds are the more general of the two types of
submanifolds, the term “submanifold” without further qualiﬁcation means
an immersed submanifold, which includes an embedded submanifold as a
special case. If there is room for confusion, it is usually better to specify
explicitly which type of submanifold is meant, particularly because some
authors do not follow this convention, but instead reserve the unqualiﬁed
term “submanifold” to mean what we call an embedded submanifold.
Even though an immersed submanifold N ⊂M is not a topological sub-
space of M, its tangent space at any point p ∈N can nonetheless be viewed
as a linear subspace of TpM, as for an embedded submanifold. If ι: N →M
is the inclusion map, then ι is a smooth immersion, so ι∗: TpN →TpM is
injective. Just as in the case of embedded submanifolds, we will routinely
identify TpN with the subspace ι∗TpN ⊂TpM.
The Case of Manifolds with Boundary
The deﬁnitions of this chapter extend easily to manifolds with boundary.
First, if M and N are manifolds with boundary, a smooth map F : M →N
is said to be a immersion if F∗is injective at each point, a submersion if
F∗is surjective at each point, and an embedding if it is an immersion and
a homeomorphism onto its image (with the subspace topology. A subset
S ⊂M is said to be an immersed submanifold of M if S is endowed with
a smooth manifold structure such that the inclusion map is an immersion,
and an embedded submanifold if in addition S has the subspace topology.
(We do not necessarily require the existence of slice coordinates for em-
bedded submanifolds, because such coordinates can be problematic if S
contains boundary points of M.)
More generally, an immersed or embedded submanifold with boundary
in M is deﬁned in exactly the same way, except that now S itself is allowed
to have a boundary.
Exercise 5.8.
If M is a smooth manifold with boundary, show that ∂M
is a smooth submanifold of M.

Restricting Maps to Submanifolds
121
Restricting Maps to Submanifolds
Given a smooth map F : M →N, it is important to know whether F is
still smooth when its domain or range is restricted to a submanifold. In the
case of restricting the domain, the answer is easy.
Proposition 5.35 (Restricting the Domain of a Smooth Map).
If
F : M →N is a smooth map and S ⊂M is an (immersed or embedded)
submanifold, then F|S : S →N is smooth.
Proof. The inclusion map ι: S ,→M is smooth by deﬁnition of an immersed
submanifold. Since F|S = F ◦ι, the result follows.
When the range is restricted, however, the resulting map may not be
smooth, as the following example shows.
Example 5.36. Let N ⊂R2 be the ﬁgure eight submanifold, with the
topology and smooth structure induced by the immersion γ of Example
5.2. Deﬁne a smooth map G: R →R2 by
G(t) = (sin 2t, cost).
(This is the same formula that we used to deﬁne γ, but now the domain
is the whole real line instead of just a subinterval.) It is easy to check that
the image of G lies in N. However, as a map from R to N, G is not even
continuous, because γ−1 ◦G is not continuous at t = −π/2.
The next proposition gives suﬃcient conditions for a map to be smooth
when its range is restricted to an immersed submanifold. It shows that the
failure of continuity is the only thing that can go wrong.
Proposition 5.37 (Restricting the Range of a Smooth Map).
Let
S ⊂N be an immersed submanifold, and let F : M →N be a smooth map
whose image is contained in S. If F is continuous as a map from M to S,
then F : M →S is smooth.
Proof. Let p ∈M be arbitrary and let q = F(p) ∈S. Because the inclusion
map ι: S ,→N is an immersion, Lemma 5.34 guarantees that there is a
neighborhood V of q in S such that ι|V : V ,→N is an embedding. Thus
there exists a slice chart (W, ψ) for V in N centered at q. (Of course, it
might not be a slice chart fo S in N.) The fact that (W, ψ) is a slice chart
means that (V0, eψ) is a chart for V , where V0 = W ∩V and eψ = π ◦ψ, with
π: Rn →Rk the projection onto the ﬁrst k = dim S coordinates. Since
V0 = (ι|V )−1(W) is open in V , it is open in N in its given topology, and
so (V0, eψ) is also a chart for N.
Let U = F −1(V0) ⊂M, which is an open set containing p. (Here is where
we use the hypothesis that F is continuous.) Choose a coordinate chart

122
5. Submanifolds
(U0, ϕ) for M such that p ∈U0 ⊂U. Then the coordinate representation
of F : M →S with respect to the charts (U0, ϕ) and (V0, eψ) is
eψ ◦F ◦ϕ−1 = π ◦(ψ ◦F ◦ϕ−1),
which is smooth because F : M →N is smooth.
In the special case in which the submanifold S is embedded, the conti-
nuity hypothesis is always satisﬁed.
Corollary 5.38 (Embedded Case).
Let S ⊂N be an embedded sub-
manifold. Then any smooth map F : M →N whose image is contained in
S is also smooth as a map from M to S.
Proof. When S ⊂N has the subpace topology, a continuous map F : M →
N whose image is contained in S is automatically continuous into S. (This
is the characteristic property of the subspace topology—see [Lee00].)
Vector Fields and Covector Fields on Submanifolds
If N ⊂M is an immersed or embedded submanifold, a vector ﬁeld X on
M does not necessarily restrict to a vector ﬁeld on N, because Xp may not
lie in the subspace TpN ⊂TpM at a point p ∈N. A vector ﬁeld X on M
is said to be tangent to N if Xp ∈TpN ⊂TpM for each p ∈N.
Lemma 5.39. Let N ⊂M be an immersed or embedded submanifold, and
let ι: N ,→M denote the inclusion map. If X is a smooth vector ﬁeld on
M that is tangent to N, then there is a unique smooth vector ﬁeld on N,
denoted by X|N, that is ι-related to X.
Proof. For a vector ﬁeld Z ∈T(N) to be ι-related to X means that ι∗Zp =
Xp for each p ∈N. Because the injective linear map ι∗: TpN →TpM is
just inclusion (under our identiﬁcation of TpN with a subspace of TpM),
this means that the uniqe vector ﬁeld Z that is ι-related to X, if one exists,
must be given by Zp = Xp for all p ∈N. So we need only check that this
deﬁnes a smooth vector ﬁeld on N.
Let p be any point in N. Since an immersed submanifold is locally em-
bedded, there is a neighborhood V of p in N that is embedded in M. Let
(y1, . . . , ym) be slice coordinates for V in a neighborhood U of p in M, such
that V ∩U is the set where yn+1 = · · · = ym = 0. We can write X locally
on U as
Xq =
m
X
i=1
Xi(q)
∂
∂yi

q
,
q ∈U.

Vector Fields and Covector Fields on Submanifolds
123
At points q ∈V ∩U, TqN = TqV is spanned by ∂/∂y1|q, . . . , ∂/∂yn|q, so the
condition that X be tangent to N means that Xn+1(q) = · · · = Xm(q) = 0
at any point q ∈V ∩U. Thus our vector ﬁeld Z has the local coordinate
expression
Zq =
n
X
i=1
Xi(q)
∂
∂yi

q
,
q ∈V ∩U.
Since the component functions Xi are restrictions of smooth functions on
U, they are smooth, and thus Z is smooth.
The restriction of covector ﬁelds to submanifolds is much simpler. Sup-
pose N ⊂M is an immersed submanifold, and let ι: N ,→M denote the
inclusion map. If σ is any smooth covector ﬁeld on M, the pullback by
ι yields a smooth covector ﬁeld ι∗σ on N. To see what this means, let
Xp ∈TpN be arbitrary, and compute
(ι∗σ)p(Xp) = σp(ι∗Xp)
= σp(Xp),
since ι∗: TpN →TpM is just the inclusion map, under our usual identiﬁca-
tion of TpN with a subspace of TpM. Thus ι∗σ is just the restriction of σ
to vectors tangent to N. For this reason we often write σ|N in place of ι∗σ,
and call it the restriction of σ to N. Be warned, however, that σ|N might
equal zero at a given point of N, even though considered as a covector
ﬁeld on M, σ might not vanish there. An example will help to clarify this
distinction.
Example 5.40. Let σ = dy on R2, and let N be the x-axis, considered as
a submanifold of R2. As a covector ﬁeld on R2, σ does not vanish at any
point, because one of its components is always 1. However, the restriction
σ|N is identically zero:
σ|N = ι∗dy = d(y ◦ι) = 0,
because y vanishes identically on N.
To distinguish the two ways in which we might interpret the statement
“σ vanishes on N,” we will say that σ vanishes along N or vanishes at
points of N if σp = 0 for every point p ∈N. The weaker condition that
σ|N = 0 will be expressed by saying that the restriction of σ to N vanishes.
Exercise 5.9.
Suppose M is a smooth manifold and N ⊂M is an im-
mersed submanifold. If f ∈C∞(M), show that d(f|N) = (df)|N. Conclude
that if f is constant on N, then the restriction of df to N is zero.

124
5. Submanifolds
Lie Subgroups
A Lie subgroup of a Lie group G is a subgroup of G endowed with a topology
and smooth structure making it into a Lie group and an immersed subman-
ifold of G. The following proposition shows that embedded subgroups are
automatically Lie subgroups.
Proposition 5.41. Let G be a Lie group, and suppose H ⊂G is a sub-
group that is also an embedded submanifold. Then H is a closed Lie sub-
group of G.
Proof. We need only check that multiplication H × H →H and inversion
H →H are smooth maps. Because multiplication is a smooth map from
G×G into G, its restriction is clearly smooth from H×H into G (this is true
even if H is merely immersed). Because H is a subgroup, multiplication
takes H × H into H, and since H is embedded, this is a smooth map into
H by Corollary 5.38. A similar argument applies to inversion. This proves
that H is a Lie subgroup.
To prove that H is closed, suppose that {hi} is a sequence of points in
H converging to a point g ∈G. Let U be the domain of a slice chart for
H containing the identity, and let W be a smaller neighborhood of e such
that W ⊂U. Since the map µ: G × G →G given by µ(g1, g2) = g−1
1 g2
is continuous, there is a neighborhood V of the identity with the property
that V × V ⊂µ−1(W), which means that g−1
1 g2 ∈W whenever g1, g2 ∈V .
Because g−1hi →e, by discarding ﬁnitely many terms of the sequence
we may assume that g−1hi ∈V for all i. This implies that
h−1
j hi = (g−1hj)−1(g−1hi) ∈W
for all i and j. Fixing j and letting i →∞, we ﬁnd h−1
j hi →h−1
j g ∈W ⊂U.
Since H ∩U is a slice, it is closed in U, and therefore h−1
j g ∈H, which
implies g ∈H. Thus H is closed.
We will see in Chapter 15 that this proposition has an important con-
verse, called the closed subgroup theorem.
Example 5.42 (Lie Subgroups).
(a) The subset GL+(n, R) ⊂GL(n, R) consisting of real n × n ma-
trices with positive determinant is a subgroup because det(AB) =
(det A)(det B). It is an open subset of GL(n, R) by continuity of the
determinant function, and therefore it is an embedded Lie subgroup
of dimension n2.
(b) The circle group S1 is a Lie subgroup of C∗because it is a subgroup
and an embedded submanifold.

Lie Subgroups
125
(c) The orthogonal group O(n) (the group of n × n orthogonal matrices)
is an embedded Lie subgroup of GL(n, R) (see Example 5.26). It
is a compact group because it is a closed and bounded subset of
M(n, R): closed because it is a level set of the continuous map Φ(A) =
AT A, and bounded because each column of an orthogonal matrix
has norm 1, which implies that the Euclidean norm of A ∈O(n) is
(P
ij(Aj
i)2)1/2 = √n.
(d) The special linear group SL(n, R) (the set of n × n real matrices
of determinant 1) is a subgroup and an embedded submanifold of
codimension 1 in GL(n, R) by Example 5.27. Therefore it is a Lie
subgroup.
(e) The special orthogonal group is deﬁned as SO(n) = O(n)∩SL(n, R) ⊂
GL(n, R). Because every matrix A ∈O(n) satisﬁes
1 = det In = det(AT A) = (det A)(det AT ) = (det A)2,
it follows that det A = ±1 for all A ∈O(n). Therefore, SO(n) is the
open subgroup of O(n) consisting of matrices of positive determinant,
and is therefore also an embedded Lie subgroup of dimension n(n −
1)/2 in GL(n, R). It is a compact group because it is a closed subset
of O(n).
(f) Let H ⊂T2 be the dense immersed submanifold of the torus that is
the image of the immersion γ : R →T2 deﬁned in Example 5.3. It is
easy to check that γ is a group homomorphism and therefore H is
a subgroup of T2. Because the smooth structure on H is deﬁned so
that γ : R →H is a diﬀeomorphism, H is a Lie group (in fact, Lie
isomorphic to R) and is therefore a Lie subgroup of T2.

126
5. Submanifolds
Problems
5-1. Let F : R2 →R be deﬁned by
F(x, y) = x3 + xy + y3 + 1.
Which level sets of F are embedded submanifolds of R2?
5-2. Deﬁne a map F : P2 →R4 by
F[x, y, z] = (x2 −y2, xy, xz, yz)
x2 + y2 + z2
.
Show that F is a smooth embedding.
5-3. Show that the image of the curve γ : (−π/2, 3π/2) →R2 of Example
5.2 is not an embedded submanifold of R2.
5-4. Let γ : R →T2 be the curve of Example 5.3.
(a) Show that the image set γ(R) is dense in T2.
(b) Show that γ(R) is not an embedded submanifold of the torus.
5-5. Let F : R →R2 and Φ: R2 →R be deﬁned by
F(t) = (t2, t3),
Φ(x, y) = xy.
(a) Show that neither F(R) nor Φ−1(0) is an embedded submanifold
of R2.
(b) Can either set be given a topology and smooth structure making
it into an immersed submanifold of R2? [Hint: Consider tangent
vectors to the submanifold at the origin.]
5-6. Show that an embedded submanifold is closed if and only if the in-
clusion map is proper.
5-7. Suppose M is a smooth manifold, p ∈M, and y1, . . . , yn are smooth
real-valued functions deﬁned on a neighborhood of p in M.
(a) If dy1
p, . . . , dyn
p form a basis for TpM, show that (y1, . . . , yn) are
coordinates for M in some neighborhood of p.
(b) If dy1
p, . . . , dyn
p are independent, show that there are functions
yn+1, . . . , ym such that (y1, . . . , ym) are coordinates for M in
some neighborhood of p.
(c) If dy1
p, . . . , dyn
p span T ∗
p M, show that there are indices i1, . . . , ik
such that (yi1, . . . , yik) are coordinates for M in some neighbor-
hood of p.

Problems
127
5-8. Let M be a smooth compact manifold. Show that there is no smooth
submersion F : M →Rk for any k > 0.
5-9. Suppose π: M →N is a smooth map such that every point of M is in
the image of a smooth local section of π. Show that π is a submersion.
5-10. Consider the map F : R4 →R2 deﬁned by
F(x, y, s, t) = (x2 + y, x2 + y2 + s2 + t2 + y).
Show that (0, 1) is a regular value of F, and that the level set
F −1(0, 1) is diﬀeomorphic to S2.
5-11. Let S ⊂R2 be the square of side 2 centered at the origin:
S = {(x, y) : max(|x|, |y|) = 1}.
If F : S1 →S is any homeomorphism, show that either F or F −1 is
not smooth.
5-12. Show that every bijective bundle map is a bundle isomorphism. More
precisely, if E and E′ are vector bundles over a smooth manifold M,
and F : E →E′ is a bijective bundle map, show that F −1 is also a
bundle map.
5-13. Let F : M →N be a smooth map of constant rank k, and let
S = F(M). Show that S can be given a topology and smooth struc-
ture such that it is an immersed k-dimensional submanifold of N
and F : M →S is smooth. Are the topology and smooth structure
uniquely determined by these conditions?
5-14. Decide whether each of the following statements is true or false, and
discuss why.
(a) If F : M →N is a smooth map, c ∈N, and F −1(c) is an em-
bedded submanifold of M whose codimension is equal to the
dimension of N, then c is a regular value of F.
(b) If S ⊂M is a closed embedded submanifold, there is a smooth
map F : M →P such that S is a regular level set of F.
5-15. Let M ⊂N be a closed embedded submanifold.
(a) Suppose f ∈C∞(M). (This means that f is smooth when con-
sidered as a function on M, not as a function on a closed subset
of N.) Show that f is the restriction of a smooth function on N.
(b) If X ∈T(M), show that there is a smooth vector ﬁeld Y on N
such that X = Y |M.

128
5. Submanifolds
(c) Find counterexamples to both results if the hypothesis that M
is closed is omitted.
5-16. Let N ⊂M be a connected immersed submanifold. Show that a
function f ∈C∞(M) is constant on N if and only if (df)|N = 0.
5-17. If N ⊂M is an embedded submanifold and γ : J →M is a smooth
curve whose image happens to lie in N, show that γ′(t) is in the
subspace Tγ(t)N of Tγ(t)M for all t ∈J. Give a counterexample if N
is not embedded.
5-18. Let M be a smooth manifold. Two embedded submanifolds N1, N2 ⊂
M are said to be transverse (or to intersect transversely) if for each
p ∈N1 ∩N2, the tangent spaces TpN1 and TpN2 together span TpM.
If N1 and N2 are transverse, show that N1 ∩N2 is either empty or an
embedded submanifold of M. Give a counterexample when N1 and
N2 are not transverse.
5-19. Let M be a smooth n-manifold with boundary. Recall from Chapter
1 that a point p ∈M called a boundary point of M if ϕ(p) ∈∂Hn for
some generalized chart (U, ϕ), and an interior point if ϕ(p) ∈Int Hn
for some generalized chart. Show that the set of boundary points
and the set of interior points are disjoint. [Hint: If ϕ(p) ∈∂Hn and
ψ(p) ∈Int Hn, show that ϕ ◦ψ−1 is an open map into Rn and derive
a contradiction.]
5-20. Let M1, M2 be connected smooth manifolds of dimension n. For
i = 1, 2, let (Wi, ϕi) be a coordinate domain centered at some point
pi ∈Mi such that ϕi(Wi) = B2(0) ⊂Rn. Deﬁne Ui = ϕ−1
i
(B1(0)) ⊂
Wi and M ′
i = Mi ∖Ui. The connected sum of M1 and M2, denoted
by M1#M2, is the quotient space of M ′
1 ⨿M ′
2 obtained by identifying
each q ∈∂U1 with ϕ−1
2
◦ϕ1(q) ∈∂U2. Show that M1#M2 is con-
nected, and has a unique smooth n-manifold structure such that the
restriction of the quotient map to each M ′
i is an embedding (where
M ′
i is thought of as a smooth manifold with boundary). Show that
there are open subsets f
M1, f
M2 ⊂M1#M2 that are diﬀeomorphic to
M1 ∖{p1} and M2 ∖{p2}, respectively, and such that f
M1 ∩f
M2 is
diﬀeomorphic to B2(0) ∖{0}.

6
Embedding and Approximation
Theorems
The purpose of this chapter is to address two fundamental questions about
smooth manifolds. The questions may seem unrelated at ﬁrst, but their
solutions are closely related.
The ﬁrst question is “Which smooth manifolds can be smoothly embed-
ded in Euclidean spaces?” The answer, as we will see, is that they all can.
This justiﬁes our habit of visualizing manifolds as subsets of Rn.
The second question is “To what extent can continuous maps between
manifolds be approximated by smooth ones?” We will give two diﬀerent
answers, both of which are useful in diﬀerent contexts. Stated simply, we
will show that any continuous map from a smooth manifold into Rn can be
uniformly approximated by a smooth map, and that any continuous map
from one smooth manifold to another is homotopic to a smooth map.
The essential strategy for answering both questions is the same: ﬁrst use
analysis in Rn to construct a “local” solution in a ﬁxed coordinate chart;
then use partitions of unity to piece together the local solutions into a
global one.
Before we begin, we need extend the notion of sets of measure zero to
manifolds. These are sets that are “small” in the sense that is closely related
to having zero volume (even though we do not yet have a way to measure
volume quantitatively on manifolds), and include things like countable sets
and submanifolds of lower dimension.

130
6. Embedding and Approximation Theorems
Sets of Measure Zero in Manifolds
Recall what it means for a set A ⊂Rn to have measure zero (see the
Appendix): for any δ > 0, A can be covered by a countable collection of
open cubes whose total volume is less than δ. The next lemma shows that
cubes can be replaced by balls in the deﬁnition.
Lemma 6.1. A subset A ⊂Rn has measure zero if and only if, for every
δ > 0, A can be covered by a countable collection of open balls whose total
volume is less than δ.
Proof. This is based on the easily-veriﬁed geometric fact that every open
cube of volume v is contained in an open ball of volume cnv, and every
open ball of volume v is contained in an open cube of volume c′
nv, where
cn and c′
n are constants depending only on n. Thus if A has measure zero,
there is a countable cover of A by open cubes with total volume less than
δ. Enclosing each cube in a ball whose volume is cn times that of the cube,
we obtain an open cover of A by open balls of total volume less than cnδ,
which can be made as small as desired by taking δ suﬃciently small. The
converse is similar.
We wish to extend the notion of measure zero in a diﬀeomorphism-
invariant fashion to subsets of manifolds. Because a manifold does not
come with a metric, volumes of cubes or balls do not make sense, so we
cannot simply use the same deﬁnition. However, the key is provided by the
next lemma, which implies that the condition of having measure zero is
diﬀeomorphism-invariant for subsets of Rn.
Lemma 6.2. Suppose A ⊂Rn has measure zero and F : A →Rn is a
smooth map. Then F(A) has measure zero.
Proof. By deﬁnition, F has an extension, still called F, to a smooth func-
tion on a neighborhood W of A in Rn. Let B be any closed ball contained
in W. Since B is compact, there is a constant C such that |DF(x)| ≤C for
all x ∈B. Using the Lipschitz estimate for smooth functions (Proposition
A.28), we have
|F(x) −F(x′)| ≤C|x −x′|
(6.1)
for all x, x′ ∈B.
Given δ > 0, we can choose a countable cover {Bj} of A ∩B by open
balls satisfying
X
j
Vol(Bj) < δ.
Then by (6.1), F(Bj) is contained in a ball eBj whose radius is no more
than C times that of Bj. Since the volume of a ball in Rn is proportional

Sets of Measure Zero in Manifolds
131
to the nth power of its radius, we conclude that F(A ∩B) is contained in
the collection of balls { eBj}, whose total volume is no greater than
X
j
Vol( eBj) < Cnδ.
Since this can be made as small as desired, it follows that F(A ∩B) has
measure zero. Since F(A) is the union of countably many such sets, it too
has measure zero.
Lemma 6.3. Suppose F : U →Rn is a smooth map, where U is an open
subset of Rm and m < n. Then F(U) has measure zero in Rn.
Proof. Let π: Rn →Rm denote the projection onto the ﬁrst m coordinates,
and let eU = π−1(U). The result follows by applying the preceding lemma
to eF = F ◦π: eU →Rn, because F(U) = eF(eU ∩Rm), which is the image of
a set of measure zero.
We say a subset A of a smooth n-manifold M has measure zero if for
every smooth chart (U, ϕ) for M, the set ϕ(A∩U) has measure zero in Rn.
It follows immediately from Lemma A.30(c), that any set of measure zero
has dense complement, because if M ∖A is not dense then A contains an
open set, which would imply ψ(A ∩V ) would contain an open set for some
coordinate chart (V, ψ).
The following lemma shows that we need only check this condition for a
single collection of charts whose domains cover A.
Lemma 6.4. Suppose A is a subset of a smooth n-manifold M, and for
some collection {(Uα, ϕα)} of charts whose domains cover A, ϕα(A ∩Uα)
has measure zero in Rn for each α. Then A has measure zero in M.
Proof. Let (V, ψ) be an arbitrary coordinate chart. We need to show that
ψ(A ∩V ) has measure zero. Some countable collection of the Uα’s covers
A ∩V . For each such Uα, we have
ψ(A ∩V ∩Uα) = (ψ ◦ϕ−1
α ) ◦ϕα(A ∩V ∩Uα).
Now ϕα(A ∩V ∩Uα) is a subset of ϕα(A ∩Uα), which has measure zero by
hypothesis. By Lemma 6.2 applied to ψ ◦ϕ−1
α , therefore, ψ(A∩V ∩Uα) has
measure zero. Since ψ(A ∩V ) is the union of countably many such sets, it
too has measure zero.
As our ﬁrst application of sets of measure zero in manifolds, we prove
the following proposition, which is an analogue of Proposition 5.17.
Proposition 6.5. Let F : M →N be a smooth map of constant rank.
(a) If F is surjective, then it is a submersion.

132
6. Embedding and Approximation Theorems
(b) If F is bijective, then it is a diﬀeomorphism.
Proof. As in the proof of Proposition 5.17, let m = dim M, n = dim N, and
k = rank F. If F is not a submersion, then k < n. By the rank theorem,
each point has a coordinate neighborhood in which F has the coordinate
representation
F(x1, . . . , xm) = (x1, . . . , xk, 0, . . . , 0).
(6.2)
Since any open cover of a manifold has a countable subcover, we can choose
countably many charts {(Ui, ϕi)} for M and corresponding charts {(Vi, ψi)}
for N such that the sets {Ui} cover M, F maps Ui into Vi, and the coordi-
nate representation of F : Ui →Vi is as in (6.2). Since F(Ui) is contained
in a k-dimensional slice of Vi, it has measure zero in N. Because F(M) is
equal to the countable union of sets F(Ui) of measure zero, F(M) itself has
measure zero in N, which implies that F cannot be surjective. This proves
(a).
To prove (b), note that a bijective map of constant rank is a submersion
by part (a) and an immersion by Proposition 5.17, so M and N have the
same dimension. Then Proposition 5.16 implies that F is a diﬀeomorphism.
The next theorem is the main result of this section.
Theorem 6.6. Suppose M and N are smooth manifolds with dim M <
dim N, and F : M →N is a smooth map. Then F(M) has measure zero
in N. In particular, N ∖F(M) is dense in N.
Proof. Write m = dim M and n = dim N, and let {(Ui, ϕi)} be a countable
covering of M by coordinate charts. Given any coordinate chart (V, ψ) for
N, we need to show that ψ(F(M)∩V ) has measure zero in Rn. Observe that
this set is the countable union of sets of the form ψ ◦F ◦ϕ−1
i (ϕi(F −1(V ) ∩
Ui)), each of which has measure zero by Lemma 6.3.
Corollary 6.7. If M is a smooth manifold and N ⊂M is an immersed
submanifold of positive codimension, then N has measure zero in M.
Theorem 6.6 can be considered as a special case of the following deeper
(and somewhat harder to prove) theorem due to Arthur Sard.
Theorem 6.8 (Sard’s Theorem).
If F : M →N is any smooth map,
the set of critical values of F has measure zero in N.
We will neither use nor prove this theorem in this book. For a proof, see
[Mil65], [Ste64], or [Bre93].

The Whitney Embedding Theorem
133
The Whitney Embedding Theorem
Our ﬁrst major task in this chapter is to show that every smooth n-manifold
can be embedded in R2n+1. We will begin by proving that if m ≥2n, any
smooth map into Rm can be perturbed slightly to be an immersion.
Theorem 6.9. Let F : M →Rm be any smooth map, where M is a smooth
n-manifold and m ≥2n. For any ε > 0, there is a smooth immersion
eF : M →Rm such that supM | eF −F| ≤ε.
Proof. Let {Wi} be any regular open cover of M as deﬁned in Chapter 2 (for
example, a regular reﬁnement of the trivial cover consisting of M alone).
Then each Wi is the domain of a chart ψi : Wi →B3(0), and the precompact
sets Ui = ψ−1
i
(B1(0)) still cover M. For each k ∈N, let Mk = Sk
i=1 Ui. We
interpret M0 to be the empty set. We will modify F inductively on one set
Wi at a time.
Let {ϕi} be a partition of unity subordinate to {Wi}. Let F0 = F, and
suppose by induction we have deﬁned smooth maps Fj : M →Rm for
j = 1, . . . , k −1 satisfying
(i) supM |Fj −F| < ε;
(ii) Fj(x) = Fj−1(x) unless x ∈Wj;
(iii) (Fj)∗is injective at each point of M j.
For any m × n matrix A, deﬁne a new map FA : M →Rm as follows: On
M ∖supp ϕk, FA = Fk−1; and on Wk, FA is the map given in coordinates
by
FA(x) = Fk−1(x) + ϕk(x)Ax,
where A: Rn →Rm is thought of as a linear map. (When computing in
Wk, we simplify the notation by identifying maps with their coordinate
representations as usual.) Since both deﬁnitions agree on the set Wk ∖
supp ϕk where they overlap, this deﬁnes a smooth map. We will eventually
set Fk = FA for a suitable choice of A.
Because (i) holds for j = k −1, there is a constant ε0 < ε such that
|Fk−1(x) −F(x)| ≤ε0 for x in the compact set supp ϕk. By continuity,
therefore, there is some δ > 0 such that |A| < δ implies
sup
M
|FA −Fk−1| =
sup
x∈supp ϕk
|ϕk(x)Ax| < ε −ε0,
and therefore
sup
M
|FA −F| ≤sup
M
|FA −Fk−1| + sup
M
|Fk−1 −F| < (ε −ε0) + ε0 = ε.

134
6. Embedding and Approximation Theorems
Let P : Wk ×M(m×n, R) →M(m×n, R) be the matrix-valued function
P(x, A) = DFA(x).
By the inductive hypothesis, P(x, A) has rank n when (x, A) is in the
compact set (supp ϕk∩M k−1)×{0}. By choosing δ even smaller if necessary,
we may also ensure that rank P(x, A) = n whenever x ∈supp ϕk ∩M k−1
and |A| < δ.
The last condition we need to ensure is that rank(FA)∗= n on Uk and
therefore on M k = Mk−1 ∪U k. Notice that DFA(x) = DFk−1(x) + A for
x ∈Uk because ϕk ≡1 there, and therefore DFA(x) has rank n in Uk if and
only if A is not of the form B−DFk−1(x) for any x ∈U k and any matrix B
of rank less than n. To ensure this, let Q: Wk×M(m×n, R) →M(m×n, R)
be the smooth map
Q(x, B) = B −DFk−1(x).
We need to show that there is some matrix A with |A| < δ that is not of
the form Q(x, B) for any x ∈U k and any matrix B of rank less than n.
For each j = 0, . . . , n−1, the set Mj(m×n, R) of m×n matrices of rank j
is an embedded submanifold of M(m × n, R) of codimension (m −j)(n −j)
by Example 5.30. By Theorem 6.6, therefore, Q(Wk × Mj(m × n, R)) has
measure zero in M(m×n, R) provided the dimension of Wk ×Mj(m×n, R)
is strictly less than the dimension of M(m × n, R), which is to say
n + mn −(m −j)(n −j) < mn
or equivalently
n −(m −j)(n −j) < 0.
(6.3)
When j = n−1, n−(m−j)(n−j) = 2n−m−1, which is negative because
we are assuming m ≥2n. For j ≤n −1, n −(m −j)(n −j) is increasing in
j because its derivative with respect to j is positive there. Thus (6.3) holds
whenever 0 ≤j ≤n −1. This implies that for each j = 0, . . . , n −1, the
image under Q of Wk × Mj(m × n, R) has measure zero in M(m × n, R).
Choosing A such that |A| < δ and A is not in the union of these image
sets, and setting Fk = FA, we obtain a map satisfying the three conditions
of the inductive hypothesis for j = k.
Now let eF(x) = limk→∞Fk(x). By local ﬁniteness of the cover {Wj}, for
each k there is some N(k) > k such that Wk ∩Wj = ∅for all j ≥N(k),
and then condition (ii) implies that FN(k) = FN(k)+1 = · · · = Fi on Wk for
all i ≥N(k). Thus the sequence {Fk(x)} is eventually constant for x in a
neighborhood of any point, and so eF : M →Rm is a smooth map. It is an
immersion because eF = FN(k) on Wk, which has rank n by (iii).

The Whitney Embedding Theorem
135
Corollary 6.10 (Whitney Immersion Theorem).
Every smooth n-
manifold admits an immersion into R2n.
Proof. Just apply the preceding theorem to any smooth map F : M →R2n,
for example a constant map.
Next we show how to perturb our immersion to be injective. The intu-
ition behind this theorem is that, due to the rank theorem, the image of
an immersion looks locally like an n-dimensional aﬃne subspace (after a
suitable change of coordinates), so if F(M) ⊂Rm has self-intersections,
they will look locally like the intersection between two n-dimensional aﬃne
subspaces. If m is at least 2n + 1, such aﬃne subspaces of Rm can be
translated slightly so as to be disjoint, so we might hope to remove the
self-intersections by perturbing F a little. The details of the proof are a bit
more involved, but the idea is the same.
Theorem 6.11. Let M be a smooth n-manifold, and suppose m ≥2n + 1
and F : M →Rm is an immersion. Then for any ε > 0 there is an injective
immersion eF : M →Rm such that supM | eF −F| ≤ε.
Proof. Because an immersion is locally an embedding, there is an open
cover {Wi} of M such that the restriction of F to each Wi is injective.
Passing to a reﬁnement, we may assume that it is a regular cover. As in
the proof of the previous theorem, let ψi : Wi →B3(0) be the associated
charts, Ui = ψ−1
i
(B1(0)), and let {ϕi} be a partition of unity subordinate
to {Wi}. Let Mk = Sk
i=1 Uk.
As before, we will modify F inductively to make it injective on succes-
sively larger sets. Let F0 = F, and suppose by induction we have deﬁned
smooth maps Fj : M →Rm for j = 1, . . . , k −1 satisfying
(i) Fj is an immersion;
(ii) supM |Fj −F| < ε;
(iii) Fj(x) = Fj−1(x) unless x ∈Wj;
(iv) Fj is injective on M j;
(v) Fj is injective on Wi for each i.
Deﬁne the next map Fk : M →Rm by
Fk(x) = Fk−1(x) + ϕk(x)b,
where b ∈Rm is to be determined.
We wish to choose b such that Fk(x) ̸= Fk(y) when x and y are distinct
points of Mk. To begin, by an argument analogous to that of Theorem 6.9,
there exists δ such that |b| < δ implies
sup
M
|Fk −F| ≤
sup
supp ϕk
|Fk −Fk−1| + sup
M
|Fk−1 −F| < ε.

136
6. Embedding and Approximation Theorems
Choosing δ smaller if necessary, we may also ensure that (Fk)∗is injective
at each point of the compact set supp ϕk; since (Fk)∗= (Fk−1)∗is already
injective on the rest of M, this implies that Fk is an immersion.
Next, observe that if Fk(x) = Fk(y), then exactly one of the following
two cases must hold:
Case I: ϕk(x) ̸= ϕk(y) and
b = −Fk−1(x) −Fk−1(y)
ϕk(x) −ϕk(y)
.
(6.4)
Case II: ϕk(x) = ϕk(y) and therefore also Fk−1(x) = Fk−1(y).
Deﬁne an open subset U ⊂M × M by
U = {(x, y) : ϕk(x) ̸= ϕk(y)},
and let R: U →Rm be the smooth map
R(x, y) = −Fk−1(x) −Fk−1(y)
ϕk(x) −ϕk(y)
.
Because dim U = dim(M × M) = 2n < m, Theorem 6.6 implies that R(U)
has measure zero in Rm. Therefore there exists b ∈Rm with |b| < δ such
that (6.4) does not hold for any (x, y) ∈U. With this b, (i)–(iii) hold with
j = k. We need to show that (iv) and (v) hold as well.
If Fk(x) = Fk(y) for some x, y ∈Mk, case I above cannot hold
by our choice of b. Therefore we are in case II: ϕk(x) = ϕk(y) and
Fk−1(x) = Fk−1(y). If ϕk(x) = ϕk(y) = 0, then x, y ∈M k ∖U k ⊂M k−1,
contradicting the fact that Fk−1 is injective on M k−1 by the inductive
hypothesis. On the other hand, if ϕk(x) and ϕk(y) are nonzero, then
x, y ∈supp ϕk ⊂Wk, which contradicts the fact that Fk−1 is injective
on Wk by (v). Similarly, if Fk(x) = Fk(y) for some x, y ∈Wi, the same
argument shows that Fk−1(x) = Fk−1(y), contradicting (v).
Now we let eF(x) = limj→∞Fj(x). As before, for any k, this sequence
is constant on Wk for j suﬃciently large, so deﬁnes a smooth function. If
eF(x) = eF(y), choose k such that x, y ∈M k. For suﬃciently large j, eF = Fj
on M k, so the injectivity of Fj on M k implies that x = y.
We can now prove the main result of this section.
Theorem 6.12 (Whitney Embedding Theorem).
Every smooth n-
manifold admits an embedding into R2n+1 as a closed submanifold.
Proof. Let M be a smooth n-manifold. By Proposition 5.4(b), a proper
injective immersion is an embedding with closed image. We will begin by
constructing a smooth proper map F0 : M →R2n+1 and using the previous
two theorems to perturb it to a proper injective immersion.

The Whitney Embedding Theorem
137
To construct a proper map, let {Vj} be any countable open cover of M
by precompact open sets, and let {ϕj} be a subordinate partition of unity.
Deﬁne f ∈C∞(M) by
f(p) =
∞
X
j=1
jϕj(p).
For any positive integer N, if p ̸∈SN
j=1 V j, then ϕj(p) = 0 for 1 ≤j ≤N,
so
|f(p)| = f(p) =
∞
X
j=N+1
jϕj(p) >
∞
X
j=N+1
Nϕj(p) ≥N
∞
X
j=1
ϕj(p) = N.
Therefore f −1[−N, N] is contained in the compact set SN
j=1 V j. This im-
plies that f is proper and so is the map F0 : M →R2n+1 deﬁned by
F0 = (f, 0, . . . , 0).
Now by Theorem 6.9, there is an immersion F1 : M →R2n+1 satisfying
supM |F1 −F0| ≤1. And by Theorem 6.11, there is an injective immersion
F2 : M →R2n+1 satisfying supM |F2 −F1| ≤1. If K ⊂R2n+1 is any
compact set, it is contained in some ball BR(0), and thus if F2(p) ∈K we
have
|F0(p)| ≤|F0(p) −F1(p)| + |F1(p) −F2(p)| + |F2(p)| ≤1 + 1 + R,
which implies F −1
2
(K) is a closed subset of F −1
0
(B2+R(0)), which is compact
because F0 is proper. Thus F2 is a proper injective immersion and hence
an embedding.
This theorem, ﬁrst proved by Hassler Whitney in 1936 [Whi36], answered
a question that had been nagging mathematicians since the notion of an
abstract manifold was ﬁrst introduced: Are there abstract smooth mani-
folds that are not diﬀeomorphic to embedded submanifolds of Euclidean
space? Although this version of the theorem will be quite suﬃcient for our
purposes, it is interesting to note that eight years later [Whi44b, Whi44a],
using much more sophisticated techniques of algebraic topology, Whitney
was able to obtain the following improvements.
Theorem 6.13 (Strong Whitney Immersion Theorem).
If n > 1,
every smooth n-manifold admits an immersion into R2n−1.
Theorem 6.14 (Strong Whitney Embedding Theorem).
Every
smooth n-manifold admits an embedding into R2n.

138
6. Embedding and Approximation Theorems
The Whitney Approximation Theorem
In this section we prove the two theorems mentioned at the beginning of
the chapter on approximation of continuous maps by smooth ones.
We begin with the case of maps into Euclidean spaces. The following
theorem shows, in particular, that any continuous map from a smooth
manifold M into Rk can be uniformly approximated by a smooth map.
In fact, for later use, we will prove something stronger. If δ: M →R is a
positive continuous function, we say two maps F, eF : M →Rk are δ-close
if |F(x) −eF(x)| < δ(x) for all x ∈M.
Theorem 6.15 (Whitney Approximation Theorem).
Let M be a
smooth manifold and let F : M →Rk be a continuous map. Given a positive
continuous function δ: M →R, there exists a smooth map eF : M →Rk
that is δ-close to F. If F is smooth on a closed subset A ⊂M, then eF can
be chosen to be equal to F on A.
Proof. If F is smooth on the closed set A, then by deﬁnition there is some
neighborhood U of A on which F|A has a smooth extension; call this ex-
tension F0. (If there is no such set, we just take U = A = ∅.) Let
U0 = {y ∈U : |F0(y) −F(y)| < δ(y)}.
It is easy to verify that U0 is an open set containing A.
We will show that there is a countable open cover {Ui} of M ∖A and
points vi ∈Rk such that
|F(y) −vi| < δ(y) for all y ∈Ui.
(6.5)
To see this, for any x ∈M ∖A, let Ux be a neighborhood of x contained
in M ∖A and small enough that
δ(y) > 1
2δ(x) and
|F(y) −F(x)| < 1
2δ(x)
for all y ∈Ux. Then if y ∈Ux, we have
|F(y) −F(x)| < 1
2δ(x) < δ(y).
The collection of all such sets Ux as x ranges over points of M ∖A is an open
cover of M ∖A. Choose a countable subcover {Uxi}∞
i=1. Setting Ui = Uxi
and vi = F(xi), we have (6.5).
Let {ϕ0, ϕi} be a partition of unity subordinate to the cover {U0, Ui} of
M, and deﬁne eF : M →Rk by
eF(y) = ϕ0(y)F0(y) +
X
i≥1
ϕi(y)vi.

The Whitney Approximation Theorem
139
Then clearly eF is smooth, and is equal to F on A. For any y ∈M, the fact
that P
i≥0 ϕi ≡1 implies that
| eF(y) −F(y)| =

ϕ0(y)F0(y) +
X
i≥1
ϕi(y)vi −

ϕ0(y) +
X
i≥1
ϕi(y)

F(y)

≤ϕ0(y)|F0(y) −F(y)| +
X
i≥1
ϕi(y)|vi −F(y)|
< ϕ0(y)δ(y) +
X
i≥1
ϕi(y)δ(y)
= δ(y),
which shows that eF is δ-close to F.
Next we wish to consider a continuous map F : N →M between smooth
manifolds. Using the Whitney embedding theorem, we can consider M as
an embedded submanifold of some Euclidean space Rm, and approximate
F by a smooth map into Rm. However, in general, the image of this smooth
map will not lie in M. To correct for this, we need to know that there is a
smooth retraction from some neighborhood of M onto M. For this purpose,
we introduce a few more deﬁnitions.
Let M ⊂Rm be an embedded n-dimensional submanifold. Identifying
the tangent space TpM at a point p ∈M with a subspace of TpRm ∼= Rm, we
deﬁne the normal space to M at p to be the subspace NpM ⊂Rm consisting
of all vectors that are orthogonal to TpM with respect to the Euclidean dot
product. The normal bundle of M is the subset NM ⊂Rm × Rm deﬁned
by
NM =
a
p∈M
NpM = {(p, v) ∈Rm × Rm : p ∈M and v ∈NpM}.
Lemma 6.16. For any embedded submanifold M ⊂Rm, the normal bun-
dle NM is an embedded m-dimensional submanifold of Rm × Rm.
Proof. Let n = dim M. Given any point p ∈M, there exist slice coordinates
(y1, . . . , ym) on a neighborhood U of p in Rm such that U ∩M is deﬁned
by yn+1 = · · · = ym = 0. Deﬁne Φ: U × Rm →Rm−n × Rn by
Φ(x, v) =

yn+1(x), . . . , ym(x), v ·
∂
∂y1

x
, . . . , v ·
∂
∂yn

x

.
Then NM ∩(U × Rm) = Φ−1(0) because the vectors ∂/∂y1|x, . . . , ∂/∂yn|x
span TxM at each point x ∈U. Using the usual change of basis formula
for coordinate derivatives, the dot product v · ∂/∂yi|x can be expanded as
v ·
∂
∂yi

x
=

vj ∂
∂xj

·
∂xk
∂yi (y(x))
∂
∂xk

x

=
m
X
j=1
vj ∂xj
∂yi (y(x)).

140
6. Embedding and Approximation Theorems
(We write the summation explicitly in the last term because the positions
of the indices do not conform to the summation convention, as is usual
when dealing with the Euclidean dot product.) Thus the Jacobian of Φ at
a point x ∈U is the m × 2m matrix
DΦ(x) =



∂yj
∂xi (x)
0
∗
∂xj
∂yi (y(x))


.
The m rows of this matrix are obviously independent, so Φ is a submersion
and therefore NM ∩(U ×Rm) is an embedded submanifold. Since the same
is true in a neighborhood of each point of NM, the result follows.
The subset M × {0} ⊂NM is clearly diﬀeomorphic to M. We will
identify this subset with M, and thus consider M itself as a subset of NM.
The normal bundle comes with a natural projection map π: NM →M
deﬁned by π(x, v) = x; it is clearly smooth because it is the restriction of
the projection Rm × Rm →Rm onto the ﬁrst factor.
Deﬁne a map E : NM →Rm by
E(x, v) = x + v.
This just maps each normal space NxM aﬃnely onto the aﬃne subspace
through x and orthogonal to TxM. Clearly E is smooth because it is the
restriction of the addition map Rm × Rm →Rm to NM. A tubular neigh-
borhood of M is a neighborhood U of M in Rm that is the diﬀeomorphic
image under E of an open subset V ⊂NM of the form
V = {(x, v) ∈NM : |v| < δ(x)},
(6.6)
for some positive continuous function δ: M →R.
Theorem 6.17 (Tubular Neighborhood Theorem).
Every embed-
ded submanifold of Rm has a tubular neighborhood.
Proof. We begin by showing that E is a diﬀeomorphism in a neighborhood
of each point of M ⊂NM. Because NM and Rm have the same dimension,
it suﬃces to show that E∗is surjective at each point. If v ∈TxM, there
is a smooth curve γ : (−ε, ε) →M such that γ(0) = x and γ′(0) = v. Let
eγ : (−ε, ε) →NM be the curve eγ(t) = (γ(t), 0). Then
E∗v = (E ◦eγ)′(0) = d
dt

t=0
(γ(t) + 0) = v.

The Whitney Approximation Theorem
141
On the other hand, if w ∈NxM, then deﬁning σ: (−ε, ε) →NM by
σ(t) = (x, tw), we obtain
E∗w = (E ◦σ)′(0) = d
dt

t=0
(x + tw) = w.
Since TxM and NxM span Rm, this shows E∗is surjective. By the inverse
function theorem, E is a diﬀeomorphism on a neighborhood of x in NM,
which we can take to be of the form Vδ(x) = {(x′, v′) : |x−x′| < δ, |v′| < δ}
for some δ > 0. (This uses the fact that M is embedded and therefore its
topology is induced by the Euclidean metric.)
To complete the proof, we need to show that there is an open set V of the
form (6.6) on which E is a global diﬀeomorphism. For each point x ∈M, let
r(x) be the supremum of all δ such that E is a diﬀeomorphism on Vδ(x), or
r(x) = 1 if this supremum is greater than 1. Then r: M →R is continuous
for the following reason. Given x, x′ ∈M, if |x −x′| < r(x), then by the
triangle inequality Vδ(x′) is contained in Vr(x)(x) for δ = r(x) −|x −x′|,
which implies that r(x′) ≥r(x) −|x −x′|, or r(x) −r(x′) ≤|x −x′|. The
same is true trivially if |x −x′| ≥r(x). Reversing the roles of x and x′
yields the opposite inequality, which shows that |r(x) −r(x′)| ≤|x −x′|,
so r is continuous.
Now let V = {(x, v) ∈NM : |v| <
1
2r(x)}. We will show that E is
injective on V . Suppose that (x, v) and (x′, v′) are points in V such that
E(x, v) = E(x′, v′). Assume without loss of generality that r(x′) ≤r(x).
Then |v′| < 1
2r(x′) ≤1
2r(x), and it follows from x + v = x′ + v′ that
|x −x′| = |v −v′| ≤|v| + |v′| < 1
2r(x) + 1
2r(x′) ≤r(x).
This implies that both (x, v) and (x′, v′) are in the set Vr(x)(x) on which
E is injective, so (x, v) = (x′, v′). Setting U = E(V ), we conclude that
E : V →U is a smooth bijection and a local diﬀeomorphism, hence a
diﬀeomorphism by Proposition 5.7. Thus U is a tubular neighborhood of
M.
The principal reason we are interested in tubular neighborhoods is be-
cause of the next proposition. Recall that a retraction of a topological space
X onto a subspace M ⊂X is a continuous map r: X →M such that r|M
is the identity map of M.
Proposition 6.18. Let M ⊂Rm be an embedded submanifold and let U
be a tubular neighborhood of M. Then there exists a smooth retraction of
U onto M.
Proof. By deﬁnition, there is an open subset V ⊂NM containing M such
that E : V →U is a diﬀeomorphism. Just deﬁne r: U →M by r = π◦E−1,

142
6. Embedding and Approximation Theorems
where π: NM →M is the natural projection. Clearly r is smooth. For
x ∈M, note that E(x, 0) = x, so r(x) = π ◦E−1(x) = π(x, 0) = x, which
shows that r is a retraction.
The next theorem gives a form of smooth approximation for continuous
maps between manifolds. It will have important applications later when we
study de Rham cohomology. If F, G: M →N are continuous maps, recall
that a homotopy from F to G is a continuous map H : M × I →N (where
I = [0, 1] is the unit interval) such that
H(x, 0) = F(x),
H(x, 1) = G(x)
for all x ∈M. If H(x, s) = F(x) = G(x) for all s ∈I and all x in some
subset A ⊂M, the homotopy is said to be relative to A. If there exists a
homotopy from F to G, we say that F and G are homotopic (or homotopic
relative to A if appropriate).
Theorem 6.19 (Whitney Approximation on Manifolds).
Let
N
and M be smooth manifolds, and let F : N →M be a continuous map.
Then F is homotopic to a smooth map eF : N →M. If F is smooth on a
closed subset A ⊂N, then the homotopy can be taken to be relative to A.
Proof. By the Whitney embedding theorem, we may as well assume that
M is an embedded submanifold of Rm. Let U be a tubular neighborhood
of M in Rm, and let r: U →M be the smooth retraction given by Lemma
6.18. For any x ∈M, let
δ(x) = sup{ε ≤1 : Bε(x) ⊂U}.
By a triangle-inequality argument entirely analogous to the one in the proof
of the tubular neighborhood theorem, δ: M →R is continuous.
Let eδ = δ ◦F : N →R. By the Whitney approximation theorem, there
exists a smooth map eF : N →Rm that is a eδ-approximation to F, and
is equal to F on A (which might be the empty set). Deﬁne a homotopy
H : N × I →M by
H(p, t) = r((1 −t)F(p) + t eF(p)).
This is well deﬁned, because our condition on eF guarantees that for each
p, | eF(p) −F(p)| < eδ(p) = δ(F(p)), which means that eF(p) is contained in

The Whitney Approximation Theorem
143
the ball of radius δ(F(p)) around F(p); since this ball is contained in U, so
is the entire line segment from F(p) to eF(p).
Thus H is a homotopy between H0(p) = H(p, 0) and H1(p) = H(p, 1). It
satisﬁes H(p, t) = F(p) for all p ∈A, since F = eF there. Clearly H0 = F
from the deﬁnition, and H1(p) = r( eF (p)) is smooth.
If M and N are smooth manifolds, two smooth maps F, G: M →N are
said to be smoothly homotopic if there is a smooth map H : M × I →N
that is a homotopy between F and G.
Proposition 6.20. If F, G: M →N are homotopic smooth maps, then
they are smoothly homotopic. If F is homotopic to G relative to some closed
subset A ⊂M, then they are smoothly homotopic relative to A.
Proof. Let H : M × I →M be a homotopy from F to G (relative to A,
which may be empty). We wish to show that H can be replaced by a smooth
homotopy.
Because Theorem 6.19 does not apply directly to manifolds with bound-
ary, we ﬁrst need to extend H to a manifold without boundary containing
M × I. Let J = (−ε, 1 + ε) for some ε > 0, and deﬁne H : M × J →M by
H(x, t) =





H(x, t)
t ∈[0, 1]
H(x, 0)
t ≤0
H(x, 1)
t ≥1.
This is continuous by the gluing lemma [Lee00, Lemma 3.8]. Moreover, the
restriction of H to M × {0} ∪M × {1} is smooth, because it is equal to
F ◦π1 on M × {0} and G ◦π1 on M × {1} (where π1 : M × I →M is the
projection on the ﬁrst factor). If F ≃G relative to A, H is also smooth
on A × I. Therefore, Theorem 6.19 implies that there is a smooth map
eH : M × J →N (homotopic to H, but we do not need that here) whose
restriction to M × {0} ∪M × {1} ∪A × I equals H (and therefore H).
Restricting back to M ×I again, we see that eH|M×I is a smooth homotopy
(relative to A) between F and G.

144
6. Embedding and Approximation Theorems
Problems
6-1. Show that any two points in a connected smooth manifold can be
joined by a smooth curve segment.
6-2. Let M ⊂Rm be an embedded submanifold, let U be a tubular neigh-
borhood of M, and let r: U →M be the retraction deﬁned in Propo-
sition 6.18. Show that U can be chosen small enough that for each
x ∈U, r(x) is the point in M closest to x. [Hint: First show that
each point x ∈U has a closest point y ∈M, and this point satisﬁes
(x −y) ⊥TyM.]
6-3. If M ⊂Rm is an embedded submanifold and ε > 0, let Mε be the set
of points in Rm whose distance from M is less than ε. If M is com-
pact, show that for suﬃciently small ε, ∂Mε is a compact embedded
submanifold of Rm, and Mε is a smooth manifold with boundary.
6-4. Let M ⊂Rm be an embedded submanifold of dimension n. For each
p ∈M, show that there exist a neighborhood U of p in M and smooth
maps X1, . . . , Xm−n: U →Rm such that (X1(q), . . . , Xm−n(q)) form
an orthonormal basis for NqM at each point q ∈U. [Hint: Let (yi)
be slice coordinates and apply the Gram-Schmidt algorithm to the
vectors ∂/∂yi.]
6-5. Let M ⊂Rm be an embedded submanifold, and let NM be its normal
bundle. Show that NM is a vector bundle with projection π: NM →
M. [Hint: Use Problem 6-4.]

7
Lie Group Actions
In this chapter, we continue our study of Lie groups. Because their most
important applications involve actions by Lie groups on other manifolds,
this chapter concentrates on properties of Lie group actions.
We begin by deﬁning Lie group actions on manifolds and explaining
some of their main properties. The main result of the chapter is a theorem
describing conditions under which the quotient of a smooth manifold by
a group action is again a smooth manifold. At the end of the chapter,
we explore two classes of such actions in more detail: actions by discrete
groups, which are closely connected with covering spaces, and transitive
actions, which give rise to homogeneous spaces.
Group Actions on Manifolds
The importance of Lie groups stems primarily from their actions on mani-
folds. Let G be a Lie group and M a smooth manifold. A left action of G
on M is a map G × M →M, often written as (g, p) 7→g · p, that satisﬁes
g1 · (g2 · p) = (g1g2)· p,
e · p = p.
(7.1)

146
7. Lie Group Actions
A right action is deﬁned analogously as a map M × G →M with compo-
sition working in the reverse order:
(p · g1)· g2 = p · (g1g2),
p · e = p.
A manifold M endowed with a speciﬁc G-action is called a (left or right)
G-space.
Sometimes it is useful to give a name to an action, such as θ: G×M →M,
with the action of a group element g on a point p usually written θg(p). In
terms of this notation, the conditions (7.1) for a left action read
θg1 ◦θg2 = θg1g2,
θe = IdM,
(7.2)
while for a right action the ﬁrst equation is replaced by
θg1 ◦θg2 = θg2g1.
For left actions, we will generally use the notations g · p and θg(p) inter-
changeably. The latter notation contains a bit more information, and is use-
ful when it is important to specify the speciﬁc action under consideration,
while the former is often more convenient when the action is understood.
For right actions, the notation p · g is generally preferred because of the
way composition works.
A right action can always be converted to a left action by the trick of
deﬁning g · p to be p · g−1; thus any results about left actions can be
translated into results about right actions, and vice versa. We will usually
focus our attention on left actions, because their group law (7.2) has the
property that multiplication of group elements corresponds to composition
of functions. However, there are some circumstances in which right actions
arise naturally; we will see several such actions later in this chapter.
Let us introduce some basic terminology regarding Lie group actions. Let
θ: G×M →M be a left action of a Lie group G on a smooth manifold M.
(The deﬁnitions for right actions are analogous.)
• The action is said to be smooth if it is smooth as a map from G × M
into M, that is, if θg(p) depends smoothly on (g, p). If this is the case,
then for each g ∈G, the map θg : M →M is a diﬀeomorphism, with
inverse θg−1.
• For any p ∈M, the orbit of p under the action is the set
G · p = {g · p : g ∈G},
the set of all images of p under elements of G.

Group Actions on Manifolds
147
• The action is transitive if for any two points p, q ∈M, there is a group
element g such that g· p = q, or equivalently if the orbit of any point
is all of M.
• Given p ∈M, the isotropy group of p, denoted by Gp, is the set of
elements g ∈G that ﬁx p:
Gp = {g ∈G : g · p = p}.
• The action is said to be free if the only element of G that ﬁxes any
element of M is the identity: g · p = p for some p ∈M implies g = e.
This is equivalent to the requirement that Gp = {e} for every p ∈M.
• The action is said to be proper if the map G×M →M ×M given by
(g, p) 7→(g · p, p) is a proper map (i.e., the preimage of any compact
set is compact). (Note that this is not the same as requiring that the
map G × M →M deﬁning the action be a proper map.)
It is not always obvious how to tell whether a given action is proper. The
following alternative characterization of proper actions is often useful.
Lemma 7.1. Suppose a Lie group G acts smoothly on a smooth manifold
M. The action is proper if and only if for every compact subset K ⊂M,
the set GK = {g ∈G: (g · K) ∩K ̸= ∅} is compact.
Proof. Let Θ: G × M →M × M denote the map Θ(g, p) = (g · p, p).
Suppose ﬁrst that Θ is proper. Then for any compact set K ⊂M, it is easy
to check that
GK = {g ∈G : there exists p ∈K such that g · p ∈K}
= {g ∈G : there exists p ∈M such that Θ(g, p) ∈K × K}
= πG
 Θ−1(K × K)

,
where πG : G×M →G is the projection. Thus GK is compact. Conversely,
suppose GK is compact for every compact set K ⊂M. If L ⊂M × M is
compact, let K = π1(L) ∪π2(L) ⊂M, where π1, π2 : M × M →M are the
projections on the ﬁrst and second factors, respectively. Then
Θ−1(L) ⊂Θ−1(K × K) ⊂{(g, p) : g · p ∈K and p ∈K} ⊂GK × K.
Since Θ−1(L) is closed by continuity, it is a closed subset of the compact
set GK × K and is therefore compact.
One special case in which this condition is automatic is when the group
is compact.
Corollary 7.2. Any smooth action by a compact Lie group on a smooth
manifold is proper.

148
7. Lie Group Actions
Proof. Let G be a compact Lie group acting smoothly on M. For any
compact set K ⊂M, the set GK is closed in G by continuity, and therefore
is compact.
Example 7.3 (Lie group actions).
(a) The natural action of GL(n, R) on Rn is the left action given by
matrix multiplication: (A, x) 7→Ax, considering x ∈Rn as a column
matrix. This is an action because matrix multiplication is associative:
(AB)x = A(Bx). It is smooth because the components of Ax depend
polynomially on the matrix entries of A and the components of x.
Because any nonzero vector can be taken to any other by a linear
transformation, there are exactly two orbits: {0} and Rn ∖{0}.
(b) The restriction of the natural action to O(n) × Rn →Rn deﬁnes a
smooth left action of O(n) on Rn. In this case, the orbits are the
origin and the spheres centered at the origin. To see why, note that
any orthogonal linear transformation preserves norms, so O(n) takes
the sphere of radius R to itself; on the other hand, any vector of
length R can be taken to any other by an orthogonal matrix. (If v
and v′ are such vectors, complete v/|v| and v′/|v′| to orthonormal
bases and let A and A′ be the orthogonal matrices whose columns
are these orthonormal bases; then it is easy to check that A′A−1 takes
v to v′.)
(c) Further restricting the natural action to O(n) × Sn−1 →Sn−1, we
obtain a transitive action of O(n) on Sn−1. It is smooth by Corollary
5.38, because Sn−1 is an embedded submanifold of Rn.
(d) The natural action of O(n) restricts to an action of SO(n) on Sn−1.
When n = 1, this action is trivial because SO(1) is the trivial group
consisting of the matrix (1) alone. But when n > 1, SO(n) acts tran-
sitively on Sn−1. To see this, it suﬃces to show that for any v ∈Sn,
there is a matrix A ∈SO(n) taking the ﬁrst standard basis vector e1
to v. Since O(n) acts transitively, there is a matrix A ∈O(n) taking
e1 to v. Either det A = 1, in which case A ∈SO(n), or det A = −1,
in which case the matrix obtained by multiplying the last column of
A by −1 is in SO(n) and still takes e1 to v.
(e) Any representation of a Lie group G on a ﬁnite-dimensional vector
space V is a smooth action of G on V .
(f) Any Lie group G acts smoothly, freely, and transitively on itself by
left or right translation. More generally, if H is a Lie subgroup of G,
then the restriction of the multiplication map to H × G →G deﬁnes
a smooth, free (but generally not transitive) left action of H on G;
similarly, restriction to G × H →G deﬁnes a free right action of H
on G.

Equivariant Maps
149
(g) An action of a discrete group Γ on a manifold M is smooth if and
only if for each g ∈Γ, the map p 7→g · p is a smooth map from M
to itself. Thus, for example, Zn acts smoothly on the left on Rn by
translation:
(m1, . . . , mn)· (x1, . . . , xn) = (m1 + x1, . . . , mn + xn).
Equivariant Maps
Suppose M and N are both (left or right) G-spaces. A smooth map
F : M →N is said to be equivariant with respect to the given G-actions if
for each g ∈G,
F(g · p) = g · F(p)
(for left actions),
F(p · g) = F(p)· g
(for right actions).
Equivalently, if θ and ϕ are the given actions on M and N, respectively, F
is equivariant if the following diagram commutes for each g ∈G:
M
N.
-
F
M
N
-
F
?
θg
?
ϕg
This condition is also expressed by saying that F intertwines the two G-
actions.
Example 7.4. Let G and H be Lie groups, and let F : G →H be a
Lie homomorphism. There is a natural left action of G on itself by left
translation. Deﬁne a left action θ of G on H by
θg(h) = F(g)h.
To check that this is an action, we just observe that θe(h) = F(e)h = h,
and
θg1 ◦θg2(h) = F(g1)(F(g2)h) = (F(g1)F(g2))h = F(g1g2)h = θg1g2(h)
because F is a homomorphism. With respect to these G-actions, F is
equivariant because
θg ◦F(g′) = F(g)F(g′) = F(gg′) = F ◦Lg(g′).

150
7. Lie Group Actions
The following theorem is an extremely useful tool for proving that certain
sets are embedded submanifolds.
Theorem 7.5 (Equivariant Rank Theorem).
Let
M
and
N
be
smooth manifolds and let G be a Lie group. Suppose F : M →N is a smooth
map that is equivariant with respect to a transitive smooth G-action on M
and any smooth G-action on N. Then F has constant rank. In particular,
its level sets are closed embedded submanifolds of M.
Proof. Let θ and ϕ denote the G-actions on M and N, respectively, and let
p0 be any point in M. For any other point p ∈M, choose g ∈G such that
θg(p0) = p. (Such a g exists because we are assuming G acts transitively
on M.) Because ϕg ◦F = F ◦θg, the following diagram commutes:
TpM
TF (p)N.
-
F∗
Tp0M
TF (p0)N
-
F∗
?
θg∗
?
ϕg∗
Because the vertical linear maps in this diagram are isomorphisms, the
horizontal ones have the same rank. In other words, the rank of F∗at an
arbitrary point p is the same as its rank at p0, so F has constant rank.
Here are some applications of the equivariant rank theorem.
Proposition 7.6. Let F : G →H be a Lie group homomorphism. The
kernel of F is an embedded Lie subgroup of G, whose codimension is equal
to the rank of F.
Proof. As in Example 7.4, F is equivariant with respect to suitable G-
actions on G and H. Since the action on G by left translation is transitive,
it follows that F has constant rank, so its kernel F −1(0) is an embedded
submanifold. It is thus a Lie subgroup by Proposition 5.41.
As another application, we describe some important Lie subgroups of
GL(n, C). For any complex matrix A, let A∗denote the adjoint or conjugate
transpose of A: A∗= AT . Observe that (AB)∗= (AB)T = BT AT = B∗A∗.
Consider the following subgroups of GL(n, C):
• The Complex Special Linear Group:
SL(n, C) = {A ∈GL(n, C) : det A = 1}.
• The Unitary Group:
U(n) = {A ∈GL(n, C) : A∗A = In}.

Equivariant Maps
151
• The Special Unitary Group:
SU(n) = U(n) ∩SL(n, C).
Exercise 7.1.
Show that SL(n, C), U(n), and SU(n) are subgroups of
GL(n, C) (in the algebraic sense).
Exercise 7.2.
Show that a matrix is in U(n) if and only if its columns
form an orthonormal basis for Cn with respect to the Hermitian dot product
z · w = P
i ziwi.
Proposition 7.7. The unitary group U(n) is an embedded n2-dimensional
Lie subgroup of GL(n, C).
Proof. Clearly U(n) is a level set of the map Φ: GL(n, C) →M(n, C)
deﬁned by
Φ(A) = A∗A.
To show that Φ has constant rank and therefore that U(n) is an embedded
Lie subgroup, we will show that Φ is equivariant with respect to suitable
right actions of GL(n, C). Let GL(n, C) act on itself by right multiplication,
and deﬁne a right action of GL(n, C) on M(n, C) by
X · B = B∗XB
for X ∈M(n, C), B ∈GL(n, C).
It is easy to check that this is a smooth action, and Φ is equivariant because
Φ(AB) = (AB)∗(AB) = B∗A∗AB = B∗Φ(A)B = Φ(A) · B.
Thus U(n) is an embedded Lie subgroup of GL(n, C).
To determine its dimension, we need to compute the rank of Φ. Because
the rank is constant, it suﬃces to compute it at the identity In ∈GL(n, C).
Thus for any B ∈TIn GL(n, C) = M(n, C), let γ : (−ε, ε) →GL(n, C) be
the curve γ(t) = In + tB, and compute
Φ∗B = d
dt

t=0
Φ ◦γ(t)
= d
dt

t=0
(In + tB)∗(In + tB)
= B∗+ B.
The image of this linear map is the set of all Hermitian n × n matrices,
i.e., the set of A ∈M(n, C) satisfying A = A∗. This is a (real) vector space
of dimension n2, as you can check. Therefore U(n) is an embedded Lie
subgroup of dimension 2n2 −n2 = n2.

152
7. Lie Group Actions
Proposition 7.8. The complex special linear group SL(n, C) is an embed-
ded (2n2 −2)-dimensional Lie subgroup of GL(n, C).
Proof. Just note that SL(n, C) is the kernel of the Lie group homomor-
phism det: GL(n, C) →C∗. It is easy to check that the determinant is
surjective onto C∗, so it is a submersion by Proposition 6.5(a). Therefore
SL(n, C) = Ker(det) is an embedded Lie subgroup whose codimension is
equal to dim C∗= 2.
Proposition 7.9. The special unitary group SU(n) is an embedded (n2 −
1)-dimensional Lie subgroup of GL(n, C).
Proof. We will show that SU(n) is an embedded submanifold of U(n). Since
the composition of embeddings SU(n) ,→U(n) ,→GL(n, C) is again an
embedding, SU(n) is also embedded in GL(n, C).
If A ∈U(n), then
1 = det In = det(A∗A) = (det A)(det A∗) = (det A)(det A) = | det A|2.
Thus det: U(n) →C∗actually takes its values in S1. It is easy to check
that it is surjective onto S1, so it is a submersion by Proposition 6.5(a).
Therefore its kernel SU(n) is an embedded Lie subgroup of codimension 1
in U(n).
Exercise 7.3.
Use the techniques developed in this section to give simpler
proofs that O(n) and SL(n, R) are Lie subgroups of GL(n, R).
Quotients of Manifolds by Group Actions
Suppose a Lie group G acts on a manifold M (on the left, say). The set
of orbits of G in M is denoted by M/G; with the quotient topology, it is
called the orbit space of the action. Equivalently, M/G is the quotient space
of M determined by the equivalence relation p1 ∼p2 if and only if there
exists g ∈G such that g · p1 = p2. It is of great importance to determine
conditions under which an orbit space is a smooth manifold.
One simple but important example to keep in mind is the action of Rk
on Rk ×Rn by translation in the Rk factor: θv(x, y) = (v +x, y). The orbits
are the aﬃne subspaces parallel to Rk, and the orbit space (Rk × Rn)/Rk
is diﬀeomorphic to Rn. The quotient map π: Rk × Rn →(Rk × Rn)/Rk is
a smooth submersion.
It is worth noting that some authors use distinctive notations such as
M/G and G\M to distinguish between orbit spaces determined by left
actions and right actions. We will rely on the context, not the notation, to
distinguish between the two cases.
The following theorem gives a very general suﬃcient condition for the
quotient of a smooth manifold by a group action to be a smooth manifold.

Quotients of Manifolds by Group Actions
153
It is one of the most important applications of the inverse function theorem
that we will see.
Theorem 7.10 (Quotient Manifold Theorem).
Suppose a Lie group
G acts smoothly, freely, and properly on a smooth manifold M. Then
the orbit space M/G is a topological manifold of dimension equal to
dim M −dim G, and has a unique smooth structure with the property that
the quotient map π: M →M/G is a smooth submersion.
Proof. First we prove the uniqueness of the smooth structure. Suppose
M/G has two diﬀerent smooth structures such that π: M →M/G is a
smooth submersion. Let (M/G)1 and (M/G)2 denote M/G with the ﬁrst
and second smooth structures, respectively. By Proposition 5.19, the iden-
tity map is smooth from (M/G)1 to (M/G)2:
(M/G)1
(M/G)2.
-
Id
π
@
@
@
@@
R
M
?
π
The same argument shows that it is also smooth in the opposite direction,
so the two smooth structures are identical.
Next we prove that M/G is a topological manifold. Assume for deﬁnite-
ness that G acts on the left, and let θ: G × M →M denote the action and
Θ: G × M →M × M the proper map Θ(g, p) = (g · p, p). For any open
set U ⊂M, π−1(π(U)) is equal to the union of all sets of the form θg(U)
as g ranges over G. Since θg is a diﬀeomorphism, each such set is open,
and therefore π−1(π(U)) is open in M. Because π is a quotient map, this
implies that π(U) is open in M/G, and therefore π is an open map.
If {Ui} is a countable basis for the topology of M, then {π(Ui)} is a
countable collection of open subsets of M/G, and it is easy to check that
it is a basis for the topology of M/G. Thus M/G is second countable.
To show that M/G is Hausdorﬀ, deﬁne the orbit relation O ⊂M ×M by
O = Θ(G × M) = {(g · p, p) ∈M × M : p ∈M, g ∈G}.
(It is called the orbit relation because (q, p) ∈O if and only if p and q are
in the same G-orbit.) Since proper maps are closed, it follows that O is a
closed subset of M ×M. If π(p) and π(q) are distinct points in M/G, then p
and q lie in distinct orbits, so (p, q) ̸∈O. If U ×V is a product neighborhood
of (p, q) in M ×M that is disjoint from O, then π(U) and π(V ) are disjoint
open subsets of M/G containing π(p) and π(q), respectively. Thus M/G is
Hausdorﬀ.
Before proving that M/G is locally Euclidean, we will show that the
G-orbits are embedded submanifolds of M diﬀeomorphic to G. For any

154
7. Lie Group Actions
p ∈M, deﬁne a smooth map θ(p) : G →M by θ(p)(g) = g · p. Note that
the image of θ(p) is exactly the orbit of p. We will show that θ(p) is an
embedding. First, if θ(p)(g′) = θ(p)(g), then g′ · p = g · p, which implies
(g−1g′) · p = p. Since we are assuming G acts freely on M, this can only
happen if g−1g′ = e, which means g = g′; thus θ(p) is injective. Observe
that
θ(p)(g′g) = (g′g)· p = g′ · (g · p) = g′ · θ(p)(g),
so θ(p) is equivariant with respect to left translation on G and the given
action on M. Since G acts transitively on itself, this implies that θ(p) has
constant rank. Since it is also injective, it is an immersion by Proposition
5.17.
If K ⊂M is a compact set, then (θ(p))−1(K) is closed in G by continuity,
and since it is contained in GK = {g ∈G : (g · K) ∩K ̸= ∅}, it is compact
by Lemma 7.1. Therefore, θ(p) is a proper map. We have shown that θ(p) is
a proper injective immersion, so it is an embedding by Proposition 5.4(b).
Let k = dim G and n = dim M−dim G. Let us say that a coordinate chart
(U, ϕ) on M, with coordinate functions (x, y) = (x1, . . . , xk, y1, . . . , yn), is
adapted to the G-action if
(i) ϕ(U) is a product open set U1 × U2 ⊂Rk × Rn, and
(ii) each orbit intersects U either in the empty set or in a single slice of
the form {y1 = c1, . . . , yn = cn}.
We will show that for any p ∈M, there exists an adapted coordinate
chart centered at p. To prove this, we begin by choosing any slice chart
(W, ψ) centered at p for the orbit G·p in M. Write the coordinate functions
of ψ as (u1, . . . , uk, v1, . . . , vn), so that (G · p) ∩U is the slice {v1 = · · · =
vn = 0}. Let S be the submanifold of U deﬁned by u1 = · · · = uk = 0.
(This is the slice “perpendicular” to the orbit in these coordinates.) Thus
TpM decomposes as the following direct sum:
TpM = Tp(G · p) ⊕TpS,
where Tp(G · p) is the span of (∂/∂ui) and TpS is the span of (∂/∂vi).
Let ψ: G × S →M denote the restriction of the action θ to G × S ⊂
G × M. We will use the inverse function theorem to show that ψ is a
diﬀeomorphism in a neighborhood of (e, p) ∈G × S. Let ip : G →G × S
be the embedding given by ip(g) = (g, p). The orbit map θ(p) : G →M is
equal to the composition
G
ip
−→G × S
ψ
−→M.
Since θ(p) is an embedding whose image is the orbit G · p, it follows that
θ(p)
∗(TeG) is equal to the subspace Tp(G· p) ⊂TpM, and thus the image of

Quotients of Manifolds by Group Actions
155
ψ∗: T(e,p)(G × S) →TpM contains Tp(G· p). Similarly, if je : S →G × S is
the embedding je(q) = (e, q), then the inclusion ι: S ,→M is equal to the
composition
S
je
−→G × S
ψ
−→M.
Therefore, the image of ψ∗also includes TpS ⊂TpM. Since Tp(G · p) and
TpS together span TpM, ψ∗: T(e,p)(G × S) →TpM is surjective, and for
dimensional reasons, it is bijective. By the inverse function theorem, there
exist a neighborhood (which we may assume to be a product neighborhood)
X × Y of (e, p) in G × S and a neighborhood U of p in M such that
ψ: X × Y →U is a diﬀeomorphism. Shrinking X and Y if necessary, we
may assume that X and Y are precompact sets that are diﬀeomorphic to
Euclidean balls in Rk and Rn, respectively.
We need to show that Y can be chosen small enough that each G-orbit
intersects Y in at most a single point. Suppose this is not true. Then if {Yi}
is a countable neighborhood basis for Y at p (e.g., a sequence of Euclidean
balls whose diameters decrease to 0), for each i there exist distinct points
pi, p′
i ∈Yi that are in the same orbit, which is to say that gi · pi = p′
i for
some gi ∈G. Now, the points Θ(gi, pi) = (gi · pi, pi) = (p′
i, pi) all lie in the
compact set Y ×Y , so by properness of Θ, their inverse images (gi, pi) must
lie in a compact set L ⊂G × M. Thus the points gi all lie in the compact
set πG(L) ⊂G. Passing to a subsequence, we may assume that gi →g ∈G.
Note also that both sequences {pi} and {p′
i} converge to p, since pi, p′
i ∈Yi
and {Yi} is a neighborhood basis at p. By continuity, therefore,
g · p = lim
i→∞gi · pi = lim
i→∞p′
i = p.
Since G acts freely, this implies g = e. When i gets large enough, therefore,
gi ∈X. But this contradicts the fact that θ is injective on X × Y , because
θgi(pi) = p′
i = θe(p′
i),
and we are assuming pi ̸= p′
i.
Choose diﬀeomorphisms α: Bk →X and β : Bn →Y (where Bk and Bn
are the open unit balls in Rk and Rn, respectively), and deﬁne γ : Bk ×
Bn →U by γ(x, y) = θα(x)(β(y)). Because γ is equal to the composition of
diﬀeomorphisms
Bk × Bn α×β
−→X × Y
ψ
−→U,
γ is a diﬀeomorphism. The map ϕ = γ−1 is therefore a coordinate map on
U. We will show that ϕ is adapted to the G-action. Condition (i) is obvious
from the deﬁnition. Observe that each y = constant slice is contained in a
single orbit, because it is of the form θ(X × {p0}) ⊂θ(G × {p0}) = G· p0,

156
7. Lie Group Actions
where p0 ∈Y is the point whose y-coordinate is the given constant. Thus if
an arbitrary orbit intersects U, it does so in a union of y = constant slices.
However, since an orbit can intersect Y at most once, and each y = constant
slice has a point in Y , it follows that each orbit intersects U in precisely
one slice if at all. This completes the proof that adapted coordinate charts
exist.
To ﬁnish the proof that M/G is locally Euclidean, let q = π(p) be an
arbitrary point of M/G, and let (U, ϕ) be an adapted coordinate chart
centered at p, with ϕ(U) = U1 × U2 ⊂Rk × Rm. Let V = π(U), which is
an open subset of M/G because π is an open map. Writing the coordinate
functions of ϕ as (x1, . . . , xk, y1, . . . , yn) as before, let Y ⊂U be the slice
{x1 = · · · = xk = 0}. Note that π: Y →V is bijective by the deﬁnition of
an adapted chart. Moreover, if W is an open subset of Y , then
π(W) = π
 {(x, y) : (0, y) ∈W}

is open in M/G, and thus π|Y is a homeomorphism. Let σ = (π|Y )−1 : V →
Y ⊂U, which is a local section of π.
Deﬁne a map η: V →U2 by sending the equivalence class of a point (x, y)
to y; this is well deﬁned by the deﬁnition of an adapted chart. Formally,
η = π2 ◦ϕ ◦σ, where π2 : U1 × U2 →U2 ⊂Rn is the projection onto the
second factor. Because σ is a homeomorphism from V to Y and π2 ◦ϕ is a
homeomorphism from Y to U2, it follows that η is a homeomorphism. This
completes the proof that M/G is a topological n-manifold.
Finally, we need to show that M/G has a smooth structure such that
π is a submersion. We will use the atlas consisting of all charts (V, η) as
constructed in the preceding paragraph. With respect to any such chart
for M/G and the corresponding adapted chart for M, π has the coordinate
representation π(x, y) = y, which is certainly a submersion. Thus we need
only show that any two such charts for M/G are smoothly compatible.
Let (U, ϕ) and (eU, eϕ) be two adapted charts for M, and let (V, η) and
(eV , eη) be the corresponding charts for M/G. First consider the case in
which the two adapted charts are both centered at the same point p ∈M.
Writing the adapted coordinates as (x, y) and (ex, ey), the fact that the co-
ordinates are adapted to the G-action means that two points with the
same y-coordinate are in the same orbit, and therefore also have the same
ey-coordinate. This means that the transition map between these coordi-
nates can be written (ex, ey) = (A(x, y), B(y)), where A and B are smooth
functions deﬁned on some neighborhood of the origin. The transition map
eη ◦η−1 is just ey = B(y), which is clearly smooth.
In the general case, suppose (U, ϕ) and (eU, eϕ) are adapted charts for M,
and p ∈U, ep ∈eU are points such that π(p) = π(ep) = q. Modifying both
charts by adding constant vectors, we can assume that they are centered at
p and ep, respectively. Since p and ep are in the same orbit, there is a group
element g such that g· p = ep. Because θg is a diﬀeomorphism taking orbits

Covering Manifolds
157
to orbits, it follows that eϕ′ = eϕ ◦θg is another adapted chart centered at
p. Moreover, eσ′ = θ−1
g
◦eσ is the local section corresponding to eϕ′, and
therefore eη′ = π2 ◦eϕ′ ◦eσ′ = π2 ◦eϕ ◦θg ◦θ−1
g
◦eσ = π2 ◦eϕ ◦eσ = eη. Thus we
are back in the situation of the preceding paragraph, and the two charts
are smoothly compatible.
Covering Manifolds
Proposition 2.8 showed that any covering space of a smooth manifold is
again a smooth manifold. It is often important to know when a space
covered by a smooth manifold is itself a smooth manifold. To understand
the answer to this question, we need to study the covering group of a
covering space. In this section, we assume knowledge of the basic properties
of topological covering maps, as developed for example in [Lee00, Chapters
11 and 12].
Let f
M and M be topological spaces, and let π: f
M →M be a covering
map. A covering transformation of π is a homeomorphism ϕ: f
M →f
M such
that π ◦ϕ = π:
f
M
f
M
-
ϕ
M.
π@@
R
π
  	
The set Cπ(f
M) of all covering transformations, called the covering group
of π, is a group under composition, acting on f
M on the left. The covering
group is the key to constructing smooth manifolds covered by f
M.
We will see below that for a smooth covering π: f
M →M, the covering
group acts smoothly, freely, and properly on the covering space f
M. Before
proceeding, it is useful to have an alternative characterization of properness
for actions of discrete groups.
Lemma 7.11. Suppose a discrete group Γ acts continuously on a topolog-
ical manifold f
M. The action is proper if and only if the following condition
holds:
Any two points p, p′ ∈f
M have neighborhoods U, U ′ such
that the set {g ∈Γ : (g · U) ∩U ′ ̸= ∅} is ﬁnite.
(7.3)
Proof. First suppose that Γ acts properly, and let Θ: Γ × f
M →f
M × f
M
be the map Θ(g, p) = (g · p, p). Let U, U ′ be precompact neighborhoods
of p and p′, respectively. If (7.3) does not hold, then there exist inﬁnitely
many distinct elements gi ∈Γ and points pi ∈U such that gi · pi ∈U ′.
Because the pairs (gi · pi, pi) = Θ(gi, pi) lie in the compact set U ′ × U, the
preimages (gi, pi) lie in a compact subset of Γ × f
M, and therefore have a

158
7. Lie Group Actions
convergent subsequence. But this is impossible, because {gi} is an inﬁnite
sequence of distinct points in a discrete space.
Conversely, suppose (7.3) holds. If L is any compact subset of f
M × f
M,
we need to show that Θ−1(L) ⊂Γ × f
M is compact. It suﬃces to show
that any sequence {(gi, pi)} ⊂Θ−1(L) has a convergent subsequence. Thus
suppose Θ(gi, pi) = (gi · pi, pi) ∈L for all i. By compactness of L, we can
replace this sequence by a subsequence such that pi →p and gi · pi →p′.
Let U, U ′ be neighborhoods of p and p′, respectively, satisfying property
(7.3). For all suﬃciently large i, pi ∈U and gi · pi ∈U ′. Since there are
only ﬁnitely many g ∈Γ for which (g · U) ∩U ′ ̸= ∅, this means that there
is some g ∈Γ such that gi = g for inﬁnitely many i; in particular, some
subsequence of (gi, pi) converges.
Exercise 7.4.
Suppose Γ is a discrete group acting continuously on a topo-
logical manifold f
M. Show that the action is proper if and only if both of the
following conditions are satisﬁed:
(i)
Each p ∈f
M has a neighborhood U such that (g · U) ∩U = ? for all
but ﬁnitely many g ∈Γ.
(ii)
If p, p′ ∈f
M are not in the same Γ-orbit, there exist neighborhoods U
of p and U ′ of p′ such that (g · U) ∩U ′ = ? for all g ∈Γ.
A continuous discrete group action satisfying conditions (i) and (ii) of the
preceding exercise (or condition (7.3) of Lemma 7.11, or something closely
related to these) has traditionally been called properly discontinuous. Be-
cause the term “properly discontinuous” is self-contradictory (properly dis-
continuous group actions are, after all, continuous!), and because there is
no general agreement about exactly what the term should mean, we will
avoid using this terminology and stick with the more general term “proper
action” in this book.
Proposition 7.12. Let π: f
M →M be a smooth covering map. With the
discrete topology, the covering group Cπ(f
M) is a zero-dimensional Lie group
acting smoothly, freely, and properly on f
M.
Proof. To show that Cπ(f
M) is a Lie group, we need only verify that it is
countable. Let ep ∈f
M be arbitrary and let p = π(ep). Because the ﬁber
π−1(p) is a discrete subset of the manifold f
M, it is countable. Since each
element of Cπ(f
M) is uniquely determined by what it does to ep [Lee00,
Proposition 11.27(a)], the map ϕ 7→ϕ(ep) is an injection of Γ into π−1(p);
thus Γ is countable.
Smoothness of the action follows from the fact that any covering trans-
formation ϕ can be written locally as ϕ = σ ◦π for a suitable smooth local
section σ. The action is free because the only covering transformation that
ﬁxes any point is the identity.

Covering Manifolds
159
To show that the action is proper, we will show that it satisﬁes condi-
tions (i) and (ii) of Exercise 7.4. If p ∈f
M, let U be an evenly covered
neighborhood of π(p), and let eU be the component of π−1(U) containing
p. Because each element of the covering group permutes the components
of π−1(U) [Lee00, Proposition 11.27(d)], it follows that eU satisﬁes (i). (In
fact, it satisﬁes the stronger condition that (g · U) ∩U = ∅for all g ∈G
except g = e.)
Let p, p′ ∈
f
M be points in separate orbits. If π(p) ̸= π(p′), then
there are disjoint open sets U containing π(p) and U ′ containing π(p′),
so π−1(U), π−1(U ′) are disjoint open sets satisfying (ii). If π(p) = π(p′),
let U be an evenly covered neighborhood of π(p), and let eU, eU ′ be the
components of π−1(U) containing p and p′, respectively. If ϕ is a covering
transformation such that ϕ(eU)∩eU ′ ̸= ∅, then ϕ(eU) = eU ′ because covering
transformations permute the components of π−1(U); therefore, since each
component contains exactly one point of π−1(p), it follows that ϕ(p) = p′,
which contradicts the assumption that p and p′ are in diﬀerent orbits. Thus
eU and eU ′ satisfy (ii).
The quotient manifold theorem yields the following converse to this
proposition.
Theorem 7.13. Suppose f
M is a connected smooth manifold, and a dis-
crete Lie group Γ acts smoothly, freely, and properly on f
M. Then f
M/Γ
is a topological manifold and has a unique smooth structure such that
π: f
M →f
M/Γ is a smooth covering map.
Proof. It follows from the quotient manifold theorem that f
M/Γ has a
unique smooth manifold structure such that π is a smooth submersion.
Because dim f
M/Γ = dim f
M −dim Γ = dim f
M, this implies that π is a local
diﬀeomorphism. On the other hand, it follows from the theory of covering
spaces [Lee00, Corollary 12.12] that π is a topological covering map. Thus
π is a smooth covering map. Uniqueness of the smooth structure follows
from the uniqueness assertion of the quotient manifold theorem, because a
smooth covering map is in particular a submersion.
Example 7.14 (Proper Discrete Group Actions).
(a) The discrete Lie group Zn acts smoothly and freely on Rn by trans-
lation (Example 7.3(g)). To check that the action is proper, one
can verify that condition (7.3) is satisﬁed by suﬃciently small balls
around p and p′. The quotient manifold Rn/Zn is homeomorphic to
the n-torus Tn, and Theorem 7.13 says that there is a unique smooth
structure on Tn making the quotient map into a smooth covering
map. To verify that this smooth structure on Tn is the same as the
one we deﬁned previously (thinking of Tn as the product manifold
S1 × · · · × S1), we just check that the covering map Rn →Tn given

160
7. Lie Group Actions
by (x1, . . . , xn) 7→(e2πix1, . . . , e2πixn) is a local diﬀeomorphism with
respect to the product smooth structure on Tn, and apply the result
of Proposition 5.21.
(b) The two-element group {±1} acts on Sn by multiplication. This action
is obviously smooth and free, and it is proper because the group is
compact. This deﬁnes a smooth structure on Sn/{±1}. In fact, this
quotient manifold is diﬀeomorphic to Pn with the smooth structure
we deﬁned in Chapter 1, which can be seen as follows. Consider the
map π′ : Sn →Pn deﬁned as the composition of the inclusion ι: Sn ,→
Rn+1 ∖{0} followed by the projection π0 : Rn+1 ∖{0} 7→Pn deﬁning
Pn. This is a smooth covering map (see Problem 7-1), and makes the
same identiﬁcations as π. By the result of Problem 5.21, Sn/{±1} is
diﬀeomorphic to Pn.
Quotients of Lie Groups
Another important application of the quotient manifold theorem is to the
study quotients of Lie groups by Lie subgroups. Let G be a Lie group and
let H ⊂G be a Lie subgroup. If we let H act on G by right translation,
then an element of the orbit space is the orbit of an element g ∈G, which
is a set of the form gH = {gh : h ∈H}. In other words, an orbit under
the right action by H is a left coset of H. We will use the notation G/H to
denote the orbit space by this right action (the left coset space).
Theorem 7.15. Let G be a Lie group and let H be a closed Lie subgroup
of G. The action of H on G by right translation is smooth, free, and proper.
Therefore the left coset space G/H is a smooth manifold, and the quotient
map π: G →G/H is a smooth submersion.
Proof. We already observed in Example 7.3(f) that H acts smoothly and
freely on G. To see that the action is proper, let Θ: G × H →G × G
be the map Θ(g, h) = (gh, g), and suppose L ⊂G × G is a compact set.
If {(gi, hi)} is a sequence in Θ−1(L), then passing to a subsequence if
necessary we may assume that the sequences {gihi} and {gi} converge. By
continuity, therefore, hi = g−1
i
(gihi) converges to a point in G, and since
H is closed in G it follows that {(gi, hi)} converges in G × H.
A discrete subgroup of a Lie group is a subgroup that is a discrete set in
the subspace topology (and is thus an embedded zero-dimensional Lie sub-
group). The following corollary is an immediate consequence of Theorems
7.13 and 7.15.
Corollary 7.16. Let G be a Lie group, and let Γ ⊂G be a discrete sub-
group. Then the quotient map π: G →G/Γ is a smooth covering map.

Homogeneous Spaces
161
Example 7.17. Let C be the unit cube centered at the origin in R3. The
set Γ of positive-determinant orthogonal transformations of R3 that take
C to itself is a ﬁnite subgroup of SO(3), and the quotient SO(3)/Γ is a
connected smooth 3-manifold whose universal cover is S3 (see Problem 7-
13). Similar examples are obtained from the symmetry group of any regular
polyhedron, such as a regular tetrahedron, dodecahedron, or icosahedron.
Homogeneous Spaces
One of the most interesting kinds of group action is that in which a group
acts transitively. A smooth manifold endowed with a transitive smooth
action by a Lie group G is called a homogeneous G-space, or a homogeneous
space or homogeneous manifold if it is not important to specify the group.
In most examples, the group action preserves some property of the man-
ifold (such as distances in some metric, or a class of curves such as straight
lines in the plane); then the fact that the action is transitive means that
the manifold “looks the same” everywhere from the point of view of this
property. Often, homogeneous spaces are models for various kinds of geo-
metric structures, and as such they play a central role in many areas of
diﬀerential geometry.
Here are some important examples of homogeneous spaces.
Example 7.18 (Homogeneous Spaces).
(a) The natural action of O(n) on Sn−1 is transitive, as we observed in
Example 7.3. So is the natural action of SO(n) on Sn−1 when n ≥2.
Thus for n ≥2, Sn−1 is a homogeneous space of either O(n) or SO(n).
(b) Let E(n) denote the subgroup of GL(n + 1, R) consisting of matrices
of the form
A
b
0
1

: A ∈O(n), b ∈Rn

,
where b is considered as an n×1 column matrix. It is straightforward
to check that E(n) is an embedded Lie subgroup. If S ⊂Rn+1 denotes
the aﬃne subspace deﬁned by xn+1 = 1, then a simple computation
shows that E(n) takes S to itself. Identifying S with Rn in the obvious
way, this induces an action of E(n) on Rn, in which the matrix
  A b
0 1

sends x to Ax + b. It is not hard to prove that these are precisely
the transformations that preserve the Euclidean inner product (see
Problem 7-17). For this reason, E(n) is called the Euclidean group.
Because any point in Rn can be taken to any other by a translation,
E(n) acts transitively on Rn, so Rn is a homogeneous E(n)-space.

162
7. Lie Group Actions
(c) The group SL(2, R) acts smoothly and transitively on the upper half-
plane H = {z ∈C : Im z > 0} by the formula
a
b
c
d

· z = az + b
cz + d.
The resulting complex-analytic transformations of H are called
M¨obius transformations.
(d) If G is any Lie group and H is a closed Lie subgroup, the space G/H
of left cosets is a smooth manifold by Theorem 7.15. We deﬁne a left
action of G on G/H by
g1 · (g2H) = (g1g2)H.
This action is obviously transitive, and Proposition 5.20 implies that
it is smooth.
Exercise 7.5.
Show that both U(n) and SU(n) act smoothly and transi-
tively on S2n−1, thought of as the set of unit vectors in Cn.
Example 7.18(d) above turns out to be of central importance because,
as the next theorem shows, every homogeneous space is equivalent to one
of this type.
Theorem 7.19 (Characterization of Homogeneous Spaces).
Let
M be a homogeneous G-space, and let p be any point of M. Then
the isotropy group Gp is a closed Lie subgroup of G, and the map
F : G/Gp →M deﬁned by F(gGp) = g · p is an equivariant diﬀeomor-
phism.
Proof. For simplicity, let us write H = Gp. First we will show that H is
a closed Lie subgroup. Deﬁne a map Φ: G →M by Φ(g) = g · p. This is
obviously smooth, and H = Φ−1(p). Observe that
Φ(g′g) = (g′g)· p = g′ · (g · p) = g′ · Φ(g),
so Φ is equivariant with respect to the action by G on itself by left multipli-
cation and the given G-action on M. This implies that H is an embedded
submanifold of G and therefore a closed Lie subgroup.
To see that F is well deﬁned, assume that g1H = g2H, which means that
g−1
1 g2 ∈H. Writing g−1
1 g2 = h, we see that
F(g2H) = g2 · p = g1h · p = g1 · p = F(g1H).
Also, F is equivariant, because
F(g′gH) = (g′g)· p = g′ · F(gH).

Homogeneous Spaces
163
It is smooth because it is obtained from Φ by passing to the quotient (see
Proposition 5.20).
Next we show that F is bijective. Given any point q ∈M there is a group
element g ∈G such that F(gH) = g · p = q by transitivity. On the other
hand, if F(g1H) = F(g2H), then g1 · p = g2 · p implies g−1
1 g2 · p = p, so
g−1
1 g2 ∈H, which implies g1H = g2H.
Because F is a bijective smooth map of constant rank, it is a diﬀeomor-
phism by Proposition 6.5.
This theorem shows that the study of homogeneous spaces can be reduced
to the largely algebraic problem of understanding closed Lie subgroups of
Lie groups. Because of this, some authors deﬁne a homogeneous space to
be a quotient manifold of the form G/H, where G is a Lie group and H is
a closed Lie subgroup of G.
Applying this theorem to the examples of transitive group actions we
developed earlier, we see that some familiar spaces can be expressed as
quotients of Lie groups by closed Lie subgroups.
Example 7.20 (Homogeneous Spaces Revisited).
(a) Consider again the natural action of O(n) on Sn−1. If we choose
our base point in Sn−1 to be the “north pole” N = (0, . . . , 0, 1),
it is easy to check that the isotropy group is O(n −1), thought of
as orthogonal transformations of Rn that ﬁx the last variable. Thus
Sn−1 is diﬀeomorphic to the quotient manifold O(n)/ O(n −1). For
the action of SO(n) on Sn−1, the isotropy group is SO(n−1), so Sn−1
is also diﬀeomorphic to SO(n)/ SO(n −1).
(b) Similarly, using the result of Exercise 7.5, we conclude that S2n−1 ≈
U(n)/ U(n −1) ≈SU(n)/ SU(n −1).
(c) Because the Euclidean group E(n) acts smoothly and transitively on
Rn, and the isotropy group of the origin is the subgroup O(n) ⊂E(n)
(identiﬁed with the (n + 1) × (n + 1) matrices of the form
  A 0
0 1

with
A ∈O(n)), Rn is diﬀeomorphic to E(n)/ O(n).
Application: Sets with Transitive Group Actions
A highly useful application of the characterization theorem is to put smooth
structures on sets that admit transitive Lie group actions.
Proposition 7.21. Suppose X is a set, and we are given a transitive ac-
tion of a Lie group G on X, such that the isotropy group of a point p ∈X
is a closed Lie subgroup of G. Then X has a unique manifold topology and
smooth structure such that the given action is smooth.

164
7. Lie Group Actions
Proof. Let H denote the isotropy group of p, so that G/H is a smooth
manifold by Theorem 7.15. The map F : G/H →X deﬁned by F(gH) =
g·p is an equivariant bijection by exactly the same argument as we used in
the proof of the characterization theorem. (That part did not use the fact
that M was a manifold at all.) If we deﬁne a topology and smooth structure
on X by declaring F to be a diﬀeomorphism, then the given action of G
on X is smooth because it can be written (g, x) 7→F(g · F −1(x)).
If e
X denotes the set X with any smooth manifold structure such that
the given action is smooth, then by the homogeneous space characterization
theorem, e
X is equivariantly diﬀeomorphic to G/H and therefore to X, so
the topology and smooth structure are unique.
Example 7.22 (Grassmannians).
Let G(k, n) denote the set of k-
dimensional subspaces of Rn as in Example 1.15. The general linear group
GL(n, R) acts transitively on G(k, n): Given two subspaces A and A′,
choose bases for both subspaces and extend them to bases for Rn, and
then the linear transformation taking the ﬁrst basis to the second also
takes A to A′. The isotropy group of the subspace Rk ⊂Rn is
H =
A
B
0
D

: A ∈GL(k, R), D ∈GL(n −k, R),
B ∈M(k × (n −k), R)

,
which is a closed Lie subgroup of GL(n, R). Therefore G(k, n) has a unique
smooth manifold structure making the natural GL(n, R) action smooth.
Problem 7-19 shows that this is the same smooth structure we deﬁned in
Example 1.15.
Example 7.23 (Flag Manifolds).
Let V be a real vector space of di-
mension n > 1, and let K = (k1, . . . , km) be a ﬁnite sequence of integers
satisfying 0 < k1 < · · · < km < n. A ﬂag in V of type K is a sequence
of linear subspaces S1 ⊂S2 ⊂· · · ⊂Sm ⊂V , with dim Si = ki for each
i. The set of all ﬂags of type K in V is denoted FK(V ). (For example,
if K = (k), then FK(V ) is the Grassmannian Gk(V ).) It is not hard to
show that GL(V ) acts transitively on FK(V ) with a closed Lie subgroup as
isotropy group (see Problem 7-23), so FK(V ) has a unique smooth manifold
structure making it into a homogeneous GL(V )-space. With this structure,
FK(V ) is called a ﬂag manifold.
Application: Connectivity of Lie Groups
Another application of homogeneous space theory is to identify the con-
nected components of many familiar Lie groups. The key result is the fol-
lowing proposition.

Homogeneous Spaces
165
Proposition 7.24. Suppose a Lie group G acts smoothly, freely, and prop-
erly on a manifold M. If G and M/G are connected, then M is connected.
Proof. Suppose M is not connected. This means that there are nonempty,
disjoint open sets U, V ⊂M whose union is M. Because the quotient
map π: M →M/G is an open map (Proposition 5.18), π(U) and π(V )
are nonempty open subsets of M/G. If π(U) ∩π(V ) ̸= ∅, there is a G-
orbit that contains points of both U and V . However, each orbit is an
embedded submanifold diﬀeomorphic to G, which is connected, so each
orbit lies entirely in one of the sets U or V . Thus {π(U), π(V )} would
be a separation of M/G, which contradicts the assumption that M/G is
connected.
Proposition 7.25. For any n, the Lie groups SO(n), U(n), and SU(n)
are connected. The group O(n) has exactly two components, one of which
is SO(n).
Proof. We begin by proving that SO(n) is connected by induction on n.
For n = 1 this is obvious, because SO(1) is the trivial group. Now suppose
we have shown that SO(n −1) is connected for some n ≥2. Because the
homogeneous space SO(n)/ SO(n−1) is diﬀeomorphic to Sn−1 and therefore
is connected, Proposition 7.24 and the induction hypothesis imply that
SO(n) is connected. A similar argument applies to U(n) and SU(n), using
the facts that U(n)/ U(n −1) ≈SU(n)/ SU(n −1) ≈S2n−1.
Note that O(n) is equal to the union of the two open sets O+(n) and
O−(n) consisting of orthogonal matrices whose determinant is +1 or −1,
respectively. As we noted earlier, O+(n) = SO(n), which is connected. On
the other hand, if A is any orthogonal matrix whose determinant is −1, then
left translation LA is a diﬀeomorphism from O+(n) to O−(n), so O−(n) is
connected as well. Therefore {O+(n), O−(n)} are exactly the components
of O(n).
Determining the components of the general linear groups is a bit more
involved. Let GL+(n, R) and GL−(n, R) denote the subsets of GL(n, R)
consisting of matrices with positive determinant and negative determinant,
respectively.
Proposition 7.26. The components of GL(n, R) are GL+(n, R) and
GL−(n, R).
Proof. We begin by showing that GL+(n, R) is connected. It suﬃces to
show that it is path connected, which will follow once we show that there
is a continuous path in GL+(n, R) from any A ∈GL+(n, R) to the identity
matrix In.
Let A ∈GL+(n, R) be arbitrary, and let (A1, . . . , An) denote the
columns of A, considered as vectors in Rn. The Gram-Schmidt algorithm

166
7. Lie Group Actions
(Proposition A.17 in the Appendix) shows that there is an orthonormal
basis (Q1, . . . , Qn) for Rn with the property that span(Q1, . . . , Qk) =
span(A1, . . . , Ak) for each k = 1, . . . , n. Thus we can write
A1 = R1
1Q1,
A2 = R1
2Q1 + R2
2Q2,
...
An = R1
nQ1 + R2
nQ2 + · · · + Rn
nQn,
for some constants Rj
i . Replacing each Qi by −Qi if necessary, we may
assume that Ri
i > 0 for each i. In matrix notation, this is equivalent to
A = QR, where R is upper triangular with positive entries on the diagonal.
Since the determinant of R is the product of its diagonal entries and det A =
(det Q)(det R) > 0, it follows that Q ∈SO(n). (This QR decomposition
plays an important role in numerical linear algebra.)
Let Rt = tIn +(1−t)R. It is immediate that Rt is upper triangular with
positive diagonal entries for all t ∈[0, 1], so Rt ∈GL+(n, R). Therefore,
the path γ : [0, 1] →GL+(n, R) given by γ(t) = QRt satisﬁes γ(0) = A
and γ(1) = Q ∈SO(n). Because SO(n) is connected, there is a path in
SO(n) from Q to the identity matrix. This shows that GL+(n, R) is path
connected.
Now, as in the case of O(n), any matrix B with det B < 0 yields a
diﬀeomorphism LB : GL+(n, R) →GL−(n, R), so GL−(n, R) is connected
as well. This completes the proof.

Problems
167
Problems
7-1. Let π: Sn →Pn be the map that sends x ∈Sn to the line through the
origin and x, thought of as a point in Pn. Show that π is a smooth
covering map.
7-2. Deﬁne a map F : P2 →R4 by
F[x, y, z] = (x2 −y2, xy, xz, yz).
Show that F is a smooth embedding.
7-3. Let G be a Lie group and H ⊂G a closed normal Lie subgroup. Show
that G/H is a Lie group and the quotient map π: G →G/H is a Lie
homomorphism.
7-4. If F : G →H is a surjective Lie group homomorphism, show that H
is Lie isomorphic to G/ Ker F.
7-5. Let G be a connected Lie group, and suppose F : G →H is a surjec-
tive Lie group homomorphism with discrete kernel. Show that F is a
smooth covering map.
7-6. Let G be a Lie group, and suppose π: eG →G is any covering map.
For any point ee ∈π−1(e), show that eG has a unique Lie group struc-
ture such that ee is the identity element of eG and π is a Lie group
homomorphism.
7-7.
(a) Show that there exists a Lie group homomorphism ρ : S1 →U(n)
such that det ◦ρ = IdS1.
(b) Show that U(n) is diﬀeomorphic to S1 × SU(n). [Hint: Consider
the map ϕ : S1 × SU(n) →U(n) given by ϕ(z, A) = ρ(z)A.]
(c) Show that U(n) and S1 × SU(n) are not isomorphic Lie groups.
7-8. Show that SU(2) is diﬀeomorphic to S3.
7-9. Let G be a Lie group, and let G0 denote the connected component
of the identity (called the identity component of G).
(a) Show that G0 is an embedded Lie subgroup of G, and that each
connected component of G is diﬀeomorphic to G0.
(b) If H is any connected open subgroup of G, show that H = G0.
7-10. Suppose a Lie group acts smoothly on a manifold M.
(a) Show that each orbit is an immersed submanifold of M.

168
7. Lie Group Actions
(b) Give an example of a Lie group acting smoothly on a mani-
fold M in which two diﬀerent orbits have diﬀerent dimensions
even though neither orbit has dimension equal to zero or to the
dimension of M.
7-11. Prove the following partial converse to the quotient manifold theorem:
If a Lie group G acts smoothly and freely on a smooth manifold M
and the orbit space M/G has a smooth manifold structure such that
the quotient map π: M →M/G is a smooth submersion, then G acts
properly.
7-12. Give an example of a smooth, proper action of a Lie group on a
smooth manifold such that the orbit space is not a topological man-
ifold.
7-13. Prove that SO(3) is Lie isomorphic to SU(2)/{±I} and diﬀeomorphic
to P3, as follows.
(a) Let H denote the set of 2 × 2 Hermitian matrices whose trace is
zero. (The trace of a matrix is the sum of its diagonal entries.)
Show that H is a 3-dimensional vector space over R, and
E1 =
1
0
0
−1

,
E2 =
0
1
1
0

,
E3 =
 0
i
−i
0

is a basis for H.
(b) If we give H the inner product for which (E1, E2, E3) is an or-
thonormal basis, show that |A|2 = −det A for all A ∈H.
(c) Identifying GL(3, R) with the set of invertible real-linear maps
H →H by means of the basis (E1, E2, E3), deﬁne a map
ρ: SU(2) →GL(3, R) by
ρ(X)A = XAX−1,
X ∈SU(2), A ∈H.
Show that ρ is a Lie group homomorphism whose image is SO(3)
and whose kernel is {±I}. [Hint: To show that the image is all
of SO(3), show that ρ is open and closed and use the results of
Problem 7-9.]
(d) Prove the result.
7-14. Determine which of the following Lie groups are compact: GL(n, R),
SL(n, R), GL(n, C), SL(n, C), U(n), SU(n).
7-15. Show that GL(n, C) is connected.
7-16. Show that SL(n, R) and SL(n, C) are connected.

Problems
169
7-17. Prove that the set of maps from Rn to itself given by the action of
E(n) on Rn described in Example 7.18(b) is exactly the set of all
maps from Rn to itself that preserve the Euclidean inner product.
7-18. Prove that the Grassmannian G(k, n) is compact for any k and n.
7-19. Show that the smooth structure on the Grassmannian G(k, n) deﬁned
in Example 7.22 is the same as the one deﬁned in Example 1.15.
7-20. Show that the image of a Lie group homomorphism is a Lie subgroup.
7-21.
(a) Let G and H be Lie groups. Suppose ρ: H ×G →G is a smooth
left action of H on G with the property that ρh : G →G is a Lie
group homomorphism for every h ∈H. Deﬁne a group structure
on the manifold G × H by
(g, h)(g′, h′) = (gρh(g′), hh′).
Show that this turns G×H into a Lie group, called the semidirect
product of G and H induced by ρ, and denoted by G ⋊ρ H.
(b) If G is any Lie group, show that G is Lie isomorphic to a semi-
direct product of a connected Lie group with a discrete group.
7-22. Deﬁne an action of Z on R2 by
n · (x, y) = (x + n, (−1)ny).
(a) Show that the action is smooth, free and proper. Let E = R2/Z
denote the quotient manifold.
(b) Show that the projection on the ﬁrst coordinate π1 : R2 →R
descends to a smooth map π: E →S1.
(c) Show that E is a rank-1 vector bundle over S1 with projection
π. (It is called the M¨obius bundle.)
(d) Show that E is not a trivial bundle.
7-23. Let FK(V ) be the set of ﬂags of type K in a ﬁnite-dimensional vector
space V as in Example 7.23. Show that GL(V ) acts transitively on
FK(V ), and that the isotropy group of a particular ﬂag is a closed
Lie subgroup of GL(V ).
7-24. The n-dimensional complex projective space, denoted by CPn, is the
set of 1-dimensional complex subspaces of Cn+1. Show that CPn
has a unique topology and smooth structure making it into a 2n-
dimensional compact manifold and a homogeneous space of U(n).
7-25. Show that CP1 is diﬀeomorphic to S2.

170
7. Lie Group Actions
7-26. Considering S2n+1 as the unit sphere in Cn+1, deﬁne an action of S1
on S2n+1 by
z · (w1, . . . , wn+1) = (zw1, . . . , zwn+1).
Show that this action is smooth, free, and proper, and that the orbit
space S2n+1/S1 is diﬀeomorphic to CPn. [Hint: Consider the restric-
tion of the natural quotient map Cn+1 ∖{0} →CPn to S2n+1. The
quotient map π: S2n+1 →CPn is known as the Hopf map.]
7-27. Let c be an irrational number, and let R act on T2 = S1 × S1 by
t · (w, z) = (e2πitw, e2πictz).
Show that this is a smooth free action, but the quotient T2/R is not
Hausdorﬀ.

8
Tensors
Much of the machinery of smooth manifold theory is designed to allow the
concepts of linear algebra to be applied to smooth manifolds. For example,
a tangent vector can be thought of as a linear approximation to a curve; the
tangent space to a submanifold can be thought of as a linear approximation
to the submanifold; and the push-forward of a smooth map can be thought
of as a linear approximation to the map itself. Calculus tells us how to
approximate smooth objects by linear ones, and the abstract deﬁnitions of
manifold theory give a way to interpret these linear approximations in a
coordinate-invariant way. In this chapter, we carry this idea much further,
by generalizing from linear objects to multlinear ones. This leads to the
concepts of tensors and tensor ﬁelds on manifolds.
We begin with tensors on a vector space, which are multilinear general-
izations of covectors; a covector is the special case of a tensor of rank one.
We give two alternative deﬁnitions of tensors on a vector space: On the
one hand, they are real-valued multilinear functions of several vectors; on
the other hand, they are elements of the abstract “tensor product” of the
dual vector space with itself. Each deﬁnition is useful in certain contexts.
We then discuss the diﬀerence between covariant and contravariant tensors,
and give a brief introduction to tensors of mixed variance.
We then move to smooth manifolds, and deﬁne tensors, tensor ﬁelds,
and tensor bundles. After describing the coordinate representations of ten-
sor ﬁelds, we describe how they can be pulled back by smooth maps. We
introduce a special class of tensors, the symmetric ones, whose values are
unchanged by permutations of their arguments.

172
8. Tensors
The last section of the chapter is an introduction to one of the most
important kinds of tensor ﬁelds, Riemannian metrics. A thorough treatment
of Riemannian geometry is beyond the scope of this book, but we can at
least lay the groundwork by giving the basic deﬁnitions and proving that
every manifold admits Riemannian metrics.
The Algebra of Tensors
Suppose V1, . . . , Vk and W are vector spaces. A map F : V1×· · ·×Vk →W is
said to be multilinear if it is linear as a function of each variable separately:
F(v1, . . . , avi + a′v′
i, . . . , vk)
= aF(v1, . . . , vi, . . . , vk) + a′F(v1, . . . , v′
i, . . . , vk).
(A multilinear function of two variables is generally called bilinear.) Al-
though linear maps are paramount in diﬀerential geometry, there are many
situations in which multilinear maps play an important geometric role.
Here are a few examples to keep in mind:
• The dot product in Rn is a scalar-valued bilinear function of two vec-
tors, used to compute lengths of vectors and angles between them.
• The cross product in R3 is a vector-valued bilinear function of two
vectors, used to compute areas of parallelograms and to ﬁnd a third
vector orthogonal to two given ones.
• The determinant is a real-valued multilinear function of n vectors in
Rn, used to detect linear independence and to compute the volume
of the parallelepiped spanned by the vectors.
In this section, we will develop a uniﬁed language for talking about mul-
tilinear functions—the language of tensors. In a little while, we will give a
very general and abstract deﬁnition of tensors. But it will help to clarify
matters if we start with a more concrete deﬁnition.
Let V be a ﬁnite-dimensional real vector space, and k a natural number.
(Many of the concepts we will introduce in this section—at least the parts
that do not refer explicitly to ﬁnite bases—work equally well in the inﬁnite-
dimensional case; but we will restrict our attention to the ﬁnite-dimensional
case in order to keep things simple.)
A covariant k-tensor on V is a real-valued multilinear function of k ele-
ments of V :
T : V × · · · × V
|
{z
}
k copies
→R.

The Algebra of Tensors
173
The number k is called the rank of T . A 0-tensor is, by convention, just a
real number (a real-valued function depending multilinearly on no vectors!).
The set of all covariant k-tensors on V , denoted by T k(V ), is a vector space
under the usual operations of pointwise addition and scalar multiplication:
(aT )(X1, . . . , Xk) = a(T (X1, . . . , Xk)),
(T + T ′)(X1, . . . , Xk) = T (X1, . . . , Xk) + T ′(X1, . . . , Xk).
Let us look at some examples.
Example 8.1 (Covariant Tensors).
(a) Every linear map ω: V →R is multilinear, so a covariant 1-tensor is
just a covector. Thus T 1(V ) is naturally identiﬁed with V ∗.
(b) A covariant 2-tensor on V is a real-valued bilinear function of two
vectors, also called a bilinear form. One example is the dot product
on Rn. More generally, any inner product on V is a covariant 2-tensor.
(c) The determinant, thought of as a function of n vectors, is a covariant
n-tensor on Rn.
(d) Suppose ω, η ∈V ∗. Deﬁne a map ω ⊗η: V × V →R by
ω ⊗η(X, Y ) = ω(X)η(Y ),
where the product on the right is just ordinary multiplication of real
numbers. The linearity of ω and η guarantees that ω ⊗η is a bilinear
function of X and Y , i.e., a 2-tensor.
The last example can be generalized to tensors of any rank as follows. Let
V be a ﬁnite-dimensional real vector space and let S ∈T k(V ), T ∈T l(V ).
Deﬁne a map
S ⊗T : V × · · · × V
|
{z
}
k+l copies
→R
by
S ⊗T (X1, . . . , Xk+l) = S(X1, . . . , Xk)T (Xk+1, . . . , Xk+l).
It is immediate from the multilinearity of S and T that S ⊗T depends
linearly on each argument Xi separately, so it is a covariant (k + l)-tensor,
called the tensor product of S and T .
Exercise 8.1.
Show that the tensor product operation is bilinear and as-
sociative. More precisely, show that S ⊗T depends linearly on each of the
tensors S and T, and that (R ⊗S) ⊗T = R ⊗(S ⊗T).

174
8. Tensors
Because of the result of the preceding exercise, we can write the tensor
product of three or more tensors unambiguously without parentheses. If
T1, . . . , Tl are tensors of ranks k1, . . . , kl respectively, their tensor product
T1 ⊗· · ·⊗Tl is a tensor of rank k = k1 + · · ·+ kl, whose action on k vectors
is given by inserting the ﬁrst k1 vectors into T1, the next k2 vectors into
T2, and so forth, and multiplying the results together. For example, if R
and S are 2-tensors and T is a 3-tensor, then
R ⊗S ⊗T (X1, . . . , X7) = R(X1, X2)S(X3, X4)T (X5, X6, X7).
Proposition 8.2. Let V be a real vector space of dimension n, let (Ei) be
any basis for V , and let (εi) be the dual basis. The set of all k-tensors of
the form εi1 ⊗· · · ⊗εik for 1 ≤i1, . . . , ik ≤n is a basis for T k(V ), which
therefore has dimension nk.
Proof. Let B denote the set {εi1 ⊗· · · ⊗εik : 1 ≤i1, . . . , ik ≤n}. We need
to show that B is independent and spans T k(V ). Suppose T ∈T k(V ) is
arbitrary. For any k-tuple (i1, . . . , ik) of integers such that 1 ≤ij ≤n,
deﬁne a number Ti1...ik by
Ti1...ik = T (Ei1, . . . , Eik).
(8.1)
We will show that
T = Ti1...ikεi1 ⊗· · · ⊗εik
(with the summation convention in eﬀect as usual), from which it follows
that B spans V . We compute
Ti1...ikεi1 ⊗· · · ⊗εik(Ej1, . . . , Ejk) = Ti1...ikεi1(Ej1) · · · εik(Ejk)
= Ti1...ikδi1
j1 · · · δik
jk
= Tj1...jk
= T (Ej1, . . . , Ejk).
By multilinearity, a tensor is determined by its action on sequences of basis
vectors, so this proves the claim.
To show that B is independent, suppose some linear combination equals
zero:
Ti1...ikεi1 ⊗· · · ⊗εik = 0.
Apply this to any sequence (Ej1, . . . , Ejk) of basis vectors. By the same
computation as above, this implies that each coeﬃcient Tj1...jk is zero.
Thus the only linear combination of elements of B that sums to zero is the
trivial one.

The Algebra of Tensors
175
The proof of this proposition shows, by the way, that the components
Ti1...ik of a tensor T in terms of the basis tensors in B are given by (8.1).
It is useful to see explicitly what this proposition means for tensors of
low rank.
• k = 0: T 0(V ) is just R, so dim T 0(V ) = 1 = n0.
• k = 1: T 1(V ) = V ∗has dimension n = n1.
• k = 2: T 2(V ) is the space of bilinear forms on V . Any bilinear form
can be written uniquely as T = Tijεi ⊗εj, where (Tij) is an arbitrary
n × n matrix. Thus dim T 2(V ) = n2.
Abstract Tensor Products of Vector Spaces
Because every covariant k-tensor can be written as a linear combination of
tensor products of covectors, it is suggestive to write
T k(V ) = V ∗⊗· · · ⊗V ∗,
where we think of the expression on the right-hand side as a shorthand for
the set of all linear combinations of tensor products of elements of V ∗.
We will now give a construction that makes sense of this notation in a
much more general setting. The construction is a bit involved, but the idea
is simple: Given vector spaces V and W, we will construct a vector space
V ⊗W that consists of linear combinations of objects of the form v ⊗w for
v ∈V , w ∈W, deﬁned in such a way that v ⊗w depends bilinearly on v
and w.
Let S be a set. The free vector space on S, denoted R⟨S⟩, is the set of
all ﬁnite formal linear combinations of elements of S with real coeﬃcients.
More precisely, a ﬁnite formal linear combination is a function F: S →R
such that F(s) = 0 for all but ﬁnitely many s ∈S. Under pointwise addition
and scalar multiplication, R⟨S⟩becomes a real vector space. Identifying
each element x ∈S with the function that takes the value 1 on x and zero
on all other elements of S, any element F ∈R⟨S⟩can be written uniquely
in the form F = Pm
i=1 aixi, where x1, . . . , xm are the elements of S for
which F(xi) ̸= 0, and ai = F(xi). Thus S is a basis for R⟨S⟩, which is
therefore ﬁnite-dimensional if and only if S is a ﬁnite set.
Exercise 8.2 (Characteristic Property of Free Vector Spaces).
Let S be a set and W a vector space. Show that any map F : S →W has a
unique extension to a linear map F : R⟨S⟩→W .
Now let V and W be ﬁnite-dimensional real vector spaces, and let R be
the subspace of the free vector space R⟨V × W⟩spanned by all elements of

176
8. Tensors
the following forms:
a(v, w) −(av, w),
a(v, w) −(v, aw),
(v, w) + (v′, w) −(v + v′, w),
(v, w) + (v, w′) −(v, w + w′),
(8.2)
for a ∈R, v, v′ ∈V , and w, w′ ∈W. Deﬁne the tensor product of V and W,
denoted by V ⊗W, to be the quotient space R⟨V ×W⟩/R. The equivalence
class of an element (v, w) in V ⊗W is denoted by v ⊗w, and is called the
tensor product of v and w. From the deﬁnition, tensor products satisfy
a(v ⊗w) = av ⊗w = v ⊗aw,
v ⊗w + v′ ⊗w = (v + v′) ⊗w,
v ⊗w + v ⊗w′ = v ⊗(w + w′).
Note that the deﬁnition implies that every element of V ⊗W can be written
as a linear combination of elements of the form v ⊗w for v ∈V , w ∈W;
but it is not true in general that every element of V ⊗W is of this form.
Proposition 8.3 (Characteristic Property of Tensor Products).
Let V and W be ﬁnite-dimensional real vector spaces. If A: V × W →Y
is a bilinear map into any vector space Y , there is a unique linear map
eA: V ⊗W →Y such that the following diagram commutes:
V × W
Y
-
A
V ⊗W,
?
π
eA
    
(8.3)
where π(v, w) = v ⊗w.
Proof. First note that any map A: V × W →X extends uniquely to a
linear map A: R⟨V × W⟩→X by the characteristic property of the free
vector space. This map is characterized by the fact that A(v, w) = A(v, w)
whenever (v, w) ∈V × W ⊂R⟨V × W⟩. The fact that A is bilinear means
precisely that the subspace R is contained in the kernel of A, because
A(av, w) = A(av, w)
= aA(v, w)
= aA(v, w)
= A(a(v, w)),
with similar considerations for the other expressions in (8.2). Therefore,
A descends to a linear map eA: V ⊗W = R⟨V × W⟩/R →X satisfying

The Algebra of Tensors
177
eA ◦π = A. Uniqueness follows from the fact that every element of V ⊗W
can be written as a linear combination of elements of the form v ⊗w,
and eA is uniquely determined on such elements by eA(v ⊗w) = A(v, w) =
A(v, w).
The reason this is called the characteristic property is that it uniquely
characterizes the tensor product up to isomorphism; see Problem 8-1.
Proposition 8.4 (Other Properties of Tensor Products).
Let V ,
W, and X be ﬁnite-dimensional real vector spaces.
(a) The tensor product V ∗⊗W ∗is canonically isomorphic to the space
B(V, W) of bilinear maps from V × W into R.
(b) If (Ei) is a basis for V and (Fj) is a basis for W, then the set of all
elements of the form Ei ⊗Fj is a basis for V ⊗W, which therefore
has dimension equal to (dim V )(dim W).
(c) There is a unique isomorphism V ⊗(W ⊗X) →(V ⊗W)⊗X sending
v ⊗(w ⊗x) to (v ⊗w) ⊗x.
Proof. The canonical isomorphism between V ∗⊗W ∗and B(V, W) is con-
structed as follows. First, deﬁne a map Φ: V ∗× W ∗→B(V, W) by
Φ(ω, η)(v, w) = ω(v)η(w).
It is easy to check that Φ is bilinear, so by the characteristic property it
descends uniquely to a linear map eΦ: V ∗⊗W ∗→B(V, W).
To see that eΦ is an isomorphism, we will construct an inverse for it. Let
(Ei) and (Fj) be any bases for V and W, respectively, with dual bases
(εi) and (ϕj). Since V ∗⊗W ∗is spanned by elements of the form ω ⊗η
for ω ∈V ∗and η ∈W ∗, every τ ∈V ∗⊗W ∗can be written in the form
τ = τijεi ⊗ϕj. (We are not claiming yet that this expression is unique.)
Deﬁne a map Ψ: B(V, W) →V ∗⊗W ∗by setting
Ψ(b) = b(Ek, Fl)εk ⊗ϕl.
We will show that Ψ and eΦ are inverses. First, for τ = τijεi⊗ϕj ∈V ∗⊗W ∗,
Ψ ◦eΦ(τ) = eΦ(τ)(Ek, Fl)εk ⊗ϕl
= τij eΦ(εi ⊗ϕj)(Ek, Fl)εk ⊗ϕl
= τijΦ(εi, ϕj)(Ek, Fl)εk ⊗ϕl
= τijεi(Ek)ϕj(Fl)εk ⊗ϕl
= τijεi ⊗ϕj
= τ.

178
8. Tensors
On the other hand, for b ∈B(V, W), v ∈V , and w ∈W,
eΦ ◦Ψ(b)(v, w) = eΦ
 b(Ek, Fl)εk ⊗ϕl
(v, w)
= b(Ek, Fl)eΦ(εk ⊗ϕl)(v, w)
= b(Ek, Fl)εk(v)ϕl(w)
= b(Ek, Fl)vkwl
= b(v, w).
Thus Ψ = eΦ−1. (Note that although we used bases to prove that eΦ is
invertible, eΦ itself is canonically deﬁned without reference to any basis.)
We have already observed above that the elements of the form εi ⊗ϕj
span V ∗⊗W ∗. On the other hand, it is easy to check that dim B(V, W) =
(dim V )(dim W) (because any bilinear form is uniquely determined by its
action on pairs of basis elements), so for dimensional reasons the set {εi ⊗
ϕj} is a basis for V ∗⊗W ∗.
Finally, the isomorphism between V ⊗(W ⊗X) and (V ⊗W) ⊗X is
constructed as follows. For each x ∈X, the map αx : V ×W →V ⊗(W ⊗X)
deﬁned by
αx(v, w) = v ⊗(w ⊗x)
is obviously bilinear, and thus by the characteristic property of the tensor
product it descends uniquely to a linear map eαx : V ⊗W →V ⊗(W ⊗X)
satisfying eαx(v ⊗w) = v ⊗(w ⊗x). Similarly, the map β : (V ⊗W) × X →
V ⊗(W ⊗X) given by
β(τ, x) = eαx(τ)
determines a linear map eβ : (V ⊗W) ⊗X →V ⊗(W ⊗X) satisfying
eβ((v ⊗w) ⊗x) = v ⊗(w ⊗x).
Because V ⊗(W ⊗X) is spanned by elements of the form v ⊗(w ⊗x),
β is clearly surjective, and therefore it is an isomorphism for dimensional
reasons. It is clearly the unique such isomorphism, because any other would
have to agree with β on the set of elements of the form (v ⊗w) ⊗x, which
spans (V ⊗W) ⊗X.
The next corollary explains the relationship between this abstract tensor
product of vector spaces and the more concrete covariant k-tensors we
deﬁned earlier.
Corollary 8.5. If V is a ﬁnite-dimensional real vector space, the space
T k(V ) of covariant k-tensors on V is canonically isomorphic to the k-fold
tensor product V ∗⊗· · · ⊗V ∗.

Tensors and Tensor Fields on Manifolds
179
Exercise 8.3.
Prove Corollary 8.5.
Using these results, we can generalize the notion of covariant tensors on
a vector space as follows. For any ﬁnite-dimensional real vector space V ,
deﬁne the space of contravariant tensors of rank k to be
Tk(V ) = V ⊗· · · ⊗V
|
{z
}
k copies
.
Because of the canonical identiﬁcation V = V ∗∗and Corollary 8.5, an
element of Tk(V ) can be canonically identiﬁed with a multilinear function
from V ∗× · · · × V ∗into R. In particular, T1(V ) ∼= V ∗∗∼= V , the space of
“contravariant vectors.”
More generally, for any k, l ∈N, the space of mixed tensors on V of type
 k
l

is deﬁned as
T k
l (V ) = V ∗⊗· · · ⊗V ∗
|
{z
}
k copies
⊗V ⊗· · · ⊗V
|
{z
}
l copies
.
From the discussion above, T k
l (V ) can be identiﬁed with the set of real-
valued multilinear functions of k vectors and l covectors.
In this book, we will be concerned primarily with covariant tensors, which
we will think of primarily as multilinear functions of vectors, in keeping with
our original deﬁnition. Thus tensors will always be understood to be covari-
ant unless we explicitly specify otherwise. However, it is important to be
aware that contravariant and mixed tensors play an important role in more
advanced parts of diﬀerential geometry, especially Riemannian geometry.
Tensors and Tensor Fields on Manifolds
Now let M be a smooth manifold. We deﬁne the bundle of covariant k-
tensors on M by
T kM =
a
p∈M
T k(TpM).
Similarly, we deﬁne the bundle of contravariant l-tensors by
TlM =
a
p∈M
Tl(TpM),
and the bundle of mixed tensors of type
 k
l

by
T k
l M =
a
p∈M
T k
l (TpM).

180
8. Tensors
Clearly there are natural identiﬁcations
T 0M = T0M = M × R,
T 1M = T ∗M,
T1M = TM,
T k
0 M = T kM,
T 0
l M = TlM.
Exercise 8.4.
Show that T kM, TlM, and T k
l M have natural structures
as smooth vector bundles over M, and determine their ranks.
Any one of these bundles is called a tensor bundle over M. (Thus the tan-
gent and cotangent bundles are special cases of tensor bundles.) A section
of a tensor bundle is called a (covariant, contravariant, or mixed) tensor
ﬁeld on M. A smooth tensor ﬁeld is a section that is smooth in the usual
sense of smooth sections of vector bundles. We denote the vector spaces of
smooth sections of these bundles by
Tk(M) = {smooth sections of T kM};
Tl(M) = {smooth sections of TlM};
Tk
l (M) = {smooth sections of T k
l M}.
In any local coordinates (xi), sections of these bundles can be written (using
the summation convention) as
σ =













σi1...ikdxi1 ⊗· · · ⊗dxik;
σ ∈Tk(M),
σj1...jl
∂
∂xj1 ⊗· · · ⊗
∂
∂xjl ;
σ ∈Tl(M),
σj1...jl
i1...ikdxi1 ⊗· · · ⊗dxik ⊗
∂
∂xj1 ⊗· · · ⊗
∂
∂xjl ;
σ ∈Tk
l (M).
The functions σi1...ik, σj1...jl, or σj1...jl
i1...ik are called the component functions
of σ in these coordinates.
Lemma 8.6. Let M be a smooth manifold, and let σ: M →T kM be a
map (not assumed to be continuous) such that σp ∈T k(TpM) for each
p ∈M. The following are equivalent.
(a) σ is smooth.
(b) In any coordinate chart, the component functions of σ are smooth.
(c) If X1, . . . , Xk are vector ﬁelds deﬁned on any open subset U ⊂M,
then the function σ(X1, . . . , Xk): U →R, deﬁned by
σ(X1, . . . , Xk)(p) = σp(X1|p, . . . , Xk|p),
is smooth.

Tensors and Tensor Fields on Manifolds
181
Exercise 8.5.
Prove Lemma 8.6.
Exercise 8.6.
Formulate and prove smoothness criteria analogous to
those of Lemma 8.6 for contravariant and mixed tensor ﬁelds.
Smooth covariant 1-tensor ﬁelds are just covector ﬁelds. Recalling that a
0-tensor is just a real number, a 0-tensor ﬁeld is the same as a real-valued
function.
Lemma 8.7. Let M be a smooth manifold, and suppose σ ∈Tk(M), τ ∈
Tl(M), and f ∈C∞(M). Then fσ and σ ⊗τ are also smooth tensor ﬁelds,
whose components in any local coordinate chart are
(fσ)i1...ik = fσi1...ik,
(σ ⊗τ)i1...ik+l = σi1...ikτik+1...ik+l.
Exercise 8.7.
Prove Lemma 8.7.
Pullbacks
Just like smooth covector ﬁelds, smooth covariant tensor ﬁelds can be pulled
back by smooth maps to yield smooth tensor ﬁelds.
If F : M →N is a smooth map and σ is a smooth covariant k-tensor
ﬁeld on N, we deﬁne a k-tensor ﬁeld F ∗σ on M, called the pullback of σ,
by
(F ∗σ)p(X1, . . . , Xk) = σF (p)(F∗X1, . . . , F∗Xk).
Proposition 8.8. Suppose F : M →N and G: N →P are smooth maps,
σ ∈Tk(N), τ ∈Tl(N), and f ∈C∞(N).
(a) F ∗is linear over R.
(b) F ∗(fσ) = (f ◦F)F ∗σ.
(c) F ∗(σ ⊗τ) = F ∗σ ⊗F ∗τ.
(d) (G ◦F)∗= F ∗◦G∗.
(e) Id∗τ = τ.
Exercise 8.8.
Prove Proposition 8.8.
If f is a smooth function (i.e., a 0-tensor ﬁeld) and σ is a smooth k-tensor
ﬁeld, then it is consistent with our deﬁnitions to interpret f ⊗σ as fσ, and
F ∗f as f ◦F. With these interpretations, property (b) of this proposition
is really just a special case of (c).
Observe that properties (d) and (e) imply that the assignments M 7→
T kM and F 7→F ∗yield a contravariant functor from the category of

182
8. Tensors
smooth manifolds to itself. Because of this, the convention of calling ele-
ments of T kM covariant tensors is particularly unfortunate; but this ter-
minology is so deeply entrenched that one has no choice but to go along
with it.
The following corollary is an immediate consequence of Proposition 8.8.
Corollary 8.9. Let F : M →N be smooth, and let σ ∈Tk(N). If p ∈M
and (yj) are coordinates for N on a neighborhood of F(p), then F ∗σ has
the following expression near p:
F ∗(σj1...jkdyj1 ⊗· · · ⊗dyjk) = (σj1...jk ◦F)d(yj1 ◦F) ⊗· · · ⊗d(yjk ◦F).
Therefore F ∗σ is smooth.
In words, this corollary just says that F ∗σ is computed by the same tech-
nique we described in Chapter 4 for computing the pullback of a covector
ﬁeld: Wherever you see yj in the expression for σ, just substitute the jth
component function of F and expand. We will see examples of this in the
next section.
Symmetric Tensors
Symmetric tensors—those whose values are unchanged by rearranging their
arguments—play an extremely important role in diﬀerential geometry. We
will describe only covariant symmetric tensors, but similar considerations
apply to contravariant ones.
It is useful to start, as usual, in the linear algebraic setting. Let V be a
ﬁnite-dimensional vector space. A covariant k-tensor T on V is said to be
symmetric if its value is unchanged by interchanging any pair of arguments:
T (X1, . . . , Xi, . . . , Xj, . . . , Xk) = T (X1, . . . , Xj, . . . , Xi, . . . , Xk)
whenever 1 ≤i, j ≤k.
Exercise 8.9.
Show that the following are equivalent for a covariant k-
tensor T:
(a)
T is symmetric.
(b)
For any vectors X1, . . . , Xk ∈V , the value of T(X1, . . . , Xk) is un-
changed when X1, . . . , Xk are rearranged in any order.
(c)
The components Ti1...ik of T with respect to any basis are unchanged
by any permutation of the indices.
We denote the set of symmetric covariant k-tensors on V by Σk(V ).
It is obviously a vector subspace of T k(V ). There is a natural projection
Sym: T k(V ) →Σk(V ) called symmetrization, deﬁned as follows. First,

Symmetric Tensors
183
let Sk denote the symmetric group on k elements, that is, the group of
permutations of {1, . . . , k}. Given a k-tensor T and a permutation σ ∈Sk,
we deﬁne a new k-tensor T σ by
T σ(X1, . . . , Xk) = T (Xσ(1), . . . , Xσ(k)).
Then we deﬁne Sym T by
Sym T = 1
k!
X
σ∈Sk
T σ.
Lemma 8.10 (Properties of Symmetrization).
(a) For any covariant tensor T , Sym T is symmetric.
(b) T is symmetric if and only if Sym T = T .
Proof. Suppose T ∈T k(V ). If τ ∈Sk is any permutation, then
(Sym T )(Xτ(1), . . . , Xτ(k)) = 1
k!
X
σ∈Sk
T σ(Xτ(1), . . . , Xτ(k))
= 1
k!
X
σ∈Sk
T στ(X1, . . . , Xk)
= 1
k!
X
η∈Sk
T η(X1, . . . , Xk)
= (Sym T )(X1, . . . , Xk),
where we have substituted η = στ in the second-to-last line and used
the fact that η runs over all of Sk as σ does. This shows that Sym T is
symmetric.
If T is symmetric, then Exercise 8.9 shows that T σ = T for every σ ∈Sk,
so it follows immediately that Sym T = T . On the other hand, if Sym T =
T , then T is symmetric because part (a) shows that Sym T is.
If S and T are symmetric tensors on V , then S ⊗T is not symmetric
in general. However, using the symmetrization operator, it is possible to
deﬁne a new product that takes symmetric tensors to symmetric tensors.
If S ∈Σk(V ) and T ∈Σl(V ), we deﬁne their symmetric product to be the
(k + l)-tensor ST (denoted by juxtaposition with no intervening product
symbol) given by
ST = Sym(S ⊗T ).
More explicitly, the action of ST on vectors X1, . . . , Xk+l is given by
ST (X1, . . . , Xk+l)
=
1
(k + l)!
X
σ∈Sk+l
S(Xσ(1), . . . , Xσ(k))T (Xσ(k+1), . . . , Xσ(k+l)).

184
8. Tensors
Proposition 8.11 (Properties of the Symmetric Product).
(a) The symmetric product is symmetric and bilinear: For all symmetric
tensors R, S, T and all a, b ∈R,
ST = TS,
(aR + bS)T = aRT + bST = T (aR + bS)
(b) If ω and η are covectors, then
ωη = 1
2(ω ⊗η + η ⊗ω).
Exercise 8.10.
Prove Proposition 8.11.
A symmetric tensor ﬁeld on a manifold is simply a covariant tensor ﬁeld
whose value at any point is a symmetric tensor. The symmetric product of
two or more tensor ﬁelds is deﬁned pointwise, just like the tensor product.
Riemannian Metrics
The most important examples of symmetric tensors on a vector space are
inner products (see the Appendix). Any inner product allows us to deﬁne
lengths of vectors and angles between them, and thus to do Euclidean
geometry.
Transferring these ideas to manifolds, we obtain one of the most impor-
tant applications of tensors to diﬀerential geometry. Let M be a smooth
manifold. A Riemannian metric on M is a smooth symmetric 2-tensor
ﬁeld that is positive deﬁnite at each point. A Riemannian manifold is a
pair (M, g), where M is a smooth manifold and g is a Riemannian metric
on M. One sometimes simply says “M is a Riemannian manifold” if M is
understood to be endowed with a speciﬁc Riemannian metric.
Note that a Riemannian metric is not the same thing as a metric in the
sense of metric spaces, although the two concepts are closely related, as
we will see below. Because of this ambiguity, we will usually use the term
“distance function” when considering a metric in the metric space sense,
and reserve “metric” for a Riemannian metric. In any event, which type of
metric is being considered should always be clear from the context.
If g is a Riemannian metric on M, then for each p ∈M, gp is an inner
product on TpM. Because of this, we will often use the notation ⟨X, Y ⟩g
to denote the real number gp(X, Y ) for X, Y ∈TpM.
In any local coordinates (xi), a Riemannian metric can be written
g = gijdxi ⊗dxj,

Riemannian Metrics
185
where gij is a symmetric positive deﬁnite matrix of smooth functions. Ob-
serve that the symmetry of g allows us to write g also in terms of symmetric
products as follows:
g = gijdxi ⊗dxj
= 1
2(gijdxi ⊗dxj + gjidxi ⊗dxj)
(since gij = gji)
= 1
2(gijdxi ⊗dxj + gijdxj ⊗dxi)
(switch i ↔j in the second term)
= gijdxidxj
(deﬁnition of symmetric product).
Example 8.12. The simplest example of a Riemannian metric is the
Euclidean metric g on Rn, deﬁned in standard coordinates by
g = δijdxidxj.
It is common to use the abbreviation ω2 for the symmetric product of a
tensor ω with itself, so the Euclidean metric can also be written
g = (dx1)2 + · · · + (dxn)2.
Applied to vectors v, w ∈TpRn, this yields
gp(v, w) = δijviwj =
n
X
i=1
viwi = v · w.
In other words, g is the 2-tensor ﬁeld whose value at each point is the
Euclidean dot product. (As you may recall, we warned in Chapter 1 that
expressions involving the Euclidean dot product are likely to violate our
index conventions and therefore to require explicit summation signs. This
can usually be avoided by writing the metric coeﬃcients δij explicitly, as
in δijviwj.)
To transform a Riemannian metric under a change of coordinates, we use
the same technique as we used for covector ﬁelds: Think of the change of
coordinates as the identity map expressed in terms of diﬀerent coordinates
for the domain and range, and use the formula of Corollary 8.9. As before,
in practice this just amounts to substituting the formulas for one set of
coordinates in terms of the other.
Example 8.13. To illustrate, let us compute the coordinate expression
for the Euclidean metric on R2 in polar coordinates. The Euclidean metric
is g = dx2 + dy2. (By convention, the notation dx2 means the symmetric
product dx dx, not d(x2)). Substituting x = r cos θ and y = r sin θ and

186
8. Tensors
expanding, we obtain
g = dx2 + dy2
= d(r cos θ)2 + d(r sin θ)2
= (cos θ dr −r sin θ dθ)2 + (sin θ dr + r cos θ dθ)2
= (cos2 θ + sin2 θ)dr2 + (r2 sin2 θ + r2 cos2 θ)dθ2
+ (−2r cos θ sin θ + 2r sin θ cos θ)dr dθ
= dr2 + r2 dθ2.
(8.4)
Below are just a few of the geometric constructions that can be deﬁned
on a Riemannian manifold (M, g).
• The length or norm of a tangent vector X ∈TpM is deﬁned to be
|X|g = ⟨X, X⟩1/2
g
= gp(X, X)1/2.
• The angle between two nonzero tangent vectors X, Y ∈TpM is the
unique θ ∈[0, π] satisfying
cos θ = ⟨X, Y ⟩g
|X|g |Y |g
.
• Two tangent vectors X, Y
∈TpM are said to be orthogonal if
⟨X, Y ⟩g = 0.
• If γ : [a, b] →M is a piecewise smooth curve segment, the length of γ
is
Lg(γ) =
Z b
a
|γ′(t)|g dt.
Because |γ′(t)|g is continuous at all but ﬁnitely many values of t, the
integral is well-deﬁned.
Exercise 8.11.
If γ : [a, b] →M is a piecewise smooth curve segment and
a < c < b, show that
Lg(γ) = Lg
ÿ
γ|[a,c]
þ
+ Lg
ÿ
γ|[c,b]
þ
.
It is an extremely important fact that length is independent of parametri-
zation in the following sense. In chapter 4, we deﬁned a reparametrization
of a smooth curve segment γ : [a, b] →M to be a curve segment of the form
eγ = γ ◦ϕ, where ϕ: [c, d] →[a, b] is a diﬀeomorphism. More generally, if
γ is piecewise smooth, we allow ϕ to be a homeomorphism whose restric-
tion to each subinterval [ci−1, ci] is a diﬀeomorphism onto its image, where
c = c0 < c1 < · · · < ck = d is some ﬁnite subdivision of [c, d].

Riemannian Metrics
187
Proposition 8.14 (Parameter Independence of Length).
Let
(M, g) be a Riemannian manifold, and let γ : [a, b] →M be a piece-
wise smooth curve segment. If eγ is any reparametrization of γ, then
Lg(eγ) = Lg(γ).
Proof. First suppose that γ is smooth, and ϕ: [c, d] →[a, b] is a diﬀeomor-
phism such that eγ = γ ◦ϕ. The fact that ϕ is a diﬀeomorphism implies
that either ϕ′ > 0 or ϕ′ < 0 everywhere. Let us assume ﬁrst that ϕ′ > 0.
We have
Lg(eγ) =
Z d
c
|eγ′(t)|g dt
=
Z d
c

d
dt(γ ◦ϕ)(t)

g
dt
=
Z d
c
|ϕ′(t)γ′(ϕ(t))|g dt
=
Z d
c
|γ′(ϕ(t))|g ϕ′(t) dt
=
Z b
a
|γ′(s)|g ds
= Lg(γ),
where the second-to-last equality follows from the change of variables for-
mula for ordinary integrals.
In case ϕ′ < 0, we just need to introduce two sign changes into the
above calculation. The sign changes once when ϕ′(t) is moved outside the
absolute value signs, because |ϕ′(t)| = −ϕ′(t). Then it changes again in the
last step, because ϕ reverses the direction of the integral. Since the two
sign changes cancel each other, the result is the same.
If γ and ϕ are only piecewise smooth, we can subdivide [c, d] into ﬁnitely
many subintervals on which both eγ and ϕ are smooth, and then the result
follows by applying the above argument on each such subinterval.
Suppose (M, g) and (f
M, eg) are Riemannian manifolds. A smooth map
F : M →f
M is called an isometry if it is a diﬀeomorphism that satisﬁes
F ∗eg = g. If there exists an isometry between M and f
M, we say that M
and f
M are isometric as Riemannian manifolds. More generally, F is called
a local isometry if every point p ∈M has a neighborhood U such that F|U
is an isometry of U onto an open subset of f
M. A metric g on M is said to
be ﬂat if every point p ∈M has a neighborhood U ⊂M such that (U, g|U)
is isometric to an open subset of Rn with the Euclidean metric.
Riemannian geometry is the study of properties of Riemannian mani-
folds that are invariant under isometries. See, for example, [Lee97] for an
introduction to some of its main ideas and techniques.

188
8. Tensors
Exercise 8.12.
Show that lengths of curves are isometry invariants of Rie-
mannian manifolds. More precisely, suppose (M, g) and (f
M, eg) are Riemann-
ian manifolds, and F : M →f
M is an isometry. Show that Leg(F ◦γ) = Lg(γ)
for any piecewise smooth curve segment γ in M.
Another extremely useful tool on Riemannian manifolds is orthonormal
frames. Let (M, g) be an n-dimensional Riemannian manifold. A local frame
(E1, . . . , En) for M deﬁned on some open subset U ⊂M is said to be
orthonormal if (E1|p, . . . , En|p) is an orthonormal basis for TpM at each
point p ∈U, or in other words if ⟨Ei, Ej⟩g = δij.
Example 8.15. The coordinate frame (∂/∂xi) is a global orthonormal
frame on Rn.
Proposition 8.16 (Existence of Orthonormal Frames).
Let (M, g)
be a Riemannian manifold. For any p ∈M, there is a smooth orthonormal
frame on a neighborhood of p.
Proof. Let (xi) be any coordinates on a neighborhood U of p. Applying
the Gram-Schmidt algorithm (Proposition A.17) to the coordinate frame
(∂/∂xi), we obtain a new frame (Ei), given inductively by the formula
Ej =
∂/∂xj −Pj−1
i=1 ⟨Ej, Ei⟩gEi
∂/∂xj −Pn−1
i=1 ⟨Ej, Ei⟩gEi

g
.
Because span(E1, . . . , Ej−1)
=
span(∂/∂x1, . . . , ∂/∂xj−1), the vector
whose norm appears in the demoninator above is nowhere zero on U. Thus
this formula deﬁnes Ej as a smooth vector ﬁeld on U, and a computation
shows that the resulting frame (Ei) is orthonormal.
Observe that Proposition 8.16 did not show that there are coordinates
near p for which the coordinate frame is orthonormal. Problem 8-13 shows
that there are such coordinates in a neighborhood of each point only if the
metric is ﬂat.
The Riemannian Distance Function
Using curve segments as “measuring tapes,” we can deﬁne a notion of
distance between points on a Riemannian manifold. If (M, g) is a connected
Riemannian manifold and p, q ∈M, the (Riemannian) distance between
p and q, denoted by dg(p, q), is deﬁned to be the inﬁmum of Lg(γ) over
all piecewise smooth curve segments γ from p to q. Because any pair of
points in a connected manifold can be joined by a piecewise smooth curve
segment (Lemma 4.16), this is well-deﬁned.

Riemannian Metrics
189
Example 8.17. On Rn with the Euclidean metric g, one can show that
any straight line segment is the shortest piecewise smooth curve segment
between its endpoints (Problem 8-14). Therefore, the distance function dg
is equal to the usual Euclidean distance:
dg(x, y) = |x −y|.
Exercise 8.13.
If (M, g) and (f
M, eg) are connected Riemannian manifolds
and F : M →f
M is an isometry, show that deg(F(p), F(q)) = dg(p, q) for all
p, q ∈M.
We will see below that the Riemannian distance function turns M into
a metric space whose topology is the same as the given manifold topology.
The key is the following technical lemma, which shows that any Riemannian
metric is locally comparable to the Euclidean metric in coordinates.
Lemma 8.18. Let g be any Riemannian metric on an open set U ⊂Rn.
For any compact subset K ⊂U, there exist positive constants c, C such
that for all x ∈K and all v ∈TxM,
c|v|g ≤|v|g ≤C|v|g.
(8.5)
Proof. For any compact subset K ⊂U, let L ⊂T Rn be the set
L = {(x, v) ∈T Rn : x ∈K, |v|g = 1}.
Since L is a product of compact sets in T Rn ∼= Rn × Rn, L is compact.
Because the norm |v|g is continuous and strictly positive on L, there are
positive constants c, C such that c ≤|v|g ≤C whenever (x, v) ∈L. If x ∈K
and v is any nonzero vector in TxRn, let λ = |v|g. Then (x, λ−1v) ∈L, so
by homogeneity of the norm,
|v|g = λ|λ−1v|g ≤λC = C|v|g.
A similar computation shows that |v|g ≥c|v|g. The same inequalities are
trivially true when v = 0.
Proposition 8.19 (Riemannian Manifolds as Metric Spaces).
Let
(M, g) be a connected Riemannian manifold. With the Riemannian distance
function, M is a metric space whose metric topology is the same as the
original manifold topology.
Proof. It is immediate from the deﬁnition that dg(p, q) ≥0 for any p, q ∈
M. Because any constant curve segment has length zero, it follows that
dg(p, p) = 0, and dg(p, q) = dg(q, p) follows from the fact that any curve
segment from p to q can be reparametrized to go from q to p. Suppose γ1 and
γ2 are piecewise smooth curve segments from p to q and q to r, respectively,

190
8. Tensors
and let γ be a piecewise smooth curve segment that ﬁrst follows γ1 and
then follows γ2 (reparametrized if necessary). Then
dg(p, r) ≤Lg(γ) = Lg(γ1) + Lg(γ2).
Taking the inﬁmum over all such γ1 and γ2, we ﬁnd that dg(p, r) ≤dg(p, q)+
dg(q, r). (This is one reason why it is important to deﬁne the distance
function using piecewise smooth curves instead of just smooth ones.)
To complete the proof that (M, dg) is a metric space, we need only show
that dg(p, q) > 0 if p ̸= q. For this purpose, let p, q ∈M be distinct
points, and let U be any coordinate domain containing p but not q. Use
the coordinate map as usual to identify U with an open subset in Rn, and
let g denote the Euclidean metric in these coordinates. If V is a coordinate
ball of radius ε centered at p such that V ⊂U, Lemma 8.18 shows that
there are positive constants c, C such that
c|X|g ≤|X|g ≤C|X|g
whenever q ∈V and X ∈TqM. Then for any piecewise smooth curve
segment γ lying entirely in V , it follows that
cLg(γ) ≤Lg(γ) ≤CLg(γ).
Suppose γ : [a, b] →M is a piecewise smooth curve segment from p to q.
Let t0 be the inﬁmum of all t ∈[a, b] such that γ(t) /∈V . It follows that
γ(t0) ∈∂V by continuity, and γ(t) ∈V for a ≤t ≤t0. Thus
Lg(γ) ≥Lg
 γ|[a,t0]

≥cLg
 γ|[a,t0]

≥cdg(p, γ(t0)) = cε.
Taking the inﬁmum over all such γ, we conclude that dg(p, q) ≥cε > 0.
Finally, to show that the metric topology generated by dg is the same as
the given manifold topology on M, we will show that the open sets in the
manifold topology are open in the metric topology and vice versa. Suppose
ﬁrst that U ⊂M is open in the manifold topology. Let p be any point of
U, and let V be a coordinate ball of radius ε around p such that V ⊂U as
above. The argument in the previous paragraph shows that dg(p, q) ≥cε
whenever q /∈V . The contrapositive of this statement is that dg(p, q) < cε
implies q ∈V ⊂U, or in other words the metric ball of radius cε around p
is contained in U. This shows that U is open in the metric topology.
Conversely, suppose that W is open in the metric topology, and let p ∈
W. Let V be any closed coordinate ball around p, let g be the Euclidean
metric on V determined by the given coordinates, and let c, C be positive
constants such that (8.5) is satisﬁed for X ∈TqM, q ∈V . For any ε > 0,
let Vε be the set of points whose Euclidean distance from p is less than
ε. If q ∈Vε, let γ be the straight-line segment in coordinates from p to q.
Arguing as above, (8.5) implies
dg(p, q) ≤Lg(γ) ≤CLg(γ) = Cε.

Riemannian Metrics
191
If we choose ε small enough that the closed metric ball of radius Cε around
p is contained in W, this shows that Vε ⊂W. Since Vε is a neighborhood
of p in the manifold topology, this shows that W is open in the manifold
topology as well.
A topological space is said to be metrizable if it admits a distance function
whose metric topology is the same as the given topology. The next corollary
is an immediate consequence of the preceding proposition.
Corollary 8.20. Every smooth manifold is metrizable.
Riemannian Submanifolds
If (M, g) is a Riemannian manifold and S ⊂M is an immersed submanifold,
we can deﬁne a smooth symmetric 2-tensor g|S on S by g|S = ι∗g, where
ι: S ,→M is the inclusion map. By deﬁnition, this means for X, Y ∈TpS
(g|S)(X, Y ) = ι∗g(X, Y ) = g(ι∗X, ι∗Y ) = g(X, Y ),
so g|S is just the restriction of g to vectors tangent to S. Since the restric-
tion of an inner product to a subspace is still positive deﬁnite, g|S is a
Riemannian metric on S, called the induced metric. In this case, S is called
a Riemannian submanifold of M.
Example 8.21. The metric ◦g = g|Sn induced on Sn from the Euclidean
metric by the usual inclusion Sn ,→Rn+1 is called the round metric on the
sphere.
If S is a Riemannian submanifold of (M, g), it is usually easiest to com-
pute the induced metric g|S in terms of a local parametrization of S, which
is a smooth embedding X : U →M whose image is an open subset of S.
The coordinate representation of g|S with respect to the coordinate chart
ϕ = X−1 is then the pullback metric X∗g. The next two examples will
illustrate the procedure.
Example 8.22 (Riemannian Metrics in Graph Coordinates).
Let
U
⊂Rn be an open set, and let M
⊂Rn+1 be the graph of the
smooth function f : U →R. Then the map X : U →Rn+1 given by
X(u1, . . . , un) = (u1, . . . , un, f(u)) is a (global) parametrization of M, and
the induced metric on M is given in graph coordinates by
X∗g = X∗((dx1)2 + · · · + (dxn+1)2)
= (du1)2 + · · · + (dun)2 + df 2.
Example 8.23. Let D ⊂R3 be the embedded torus obtained by revolving
the circle (y −2)2 + z2 = 1 around the z-axis. If X : R2 →R3 is the map
X(ϕ, θ) = ((2 + cos ϕ) cos θ, (2 + cos ϕ) sin θ, sin ϕ),

192
8. Tensors
then the restriction of X to any suﬃciently small open set U ⊂R2 is a local
parametrization of D. The metric induced on D by the Euclidean metric
is computed as follows:
X∗g = X∗(dx2 + dy2 + dz2)
= d((2 + cos ϕ) cos θ)2 + d((2 + cos ϕ) sin θ)2 + d(sin ϕ)2
= (−sin ϕ cos θ dt −(2 + cos ϕ) sin θ dθ)2
+ (−sin ϕ sin θ dt + (2 + cos ϕ) cos θ dθ)2
+ (cos ϕ dt)2
= (sin2 ϕ cos2 θ + sin2 ϕ sin2 θ + cos2 ϕ)dϕ2
+ ((2 + cos ϕ) sin ϕ cos θ sin θ −(2 + cos ϕ) sin ϕ cos θ sin θ)dϕ dθ
+ ((2 + cos ϕ)2 sin2 θ + (2 + cos ϕ)2 cos2 θ)dθ2
= dϕ2 + (2 + cos ϕ)2dθ2.
If (M, g) is an n-dimensional Riemannian manifold and S
⊂
M
is a k-dimensional Riemannian submanifold, a local orthonormal frame
(E1, . . . , En) for M on an open set U ⊂M is said to be adapted to S if
(E1|p, . . . , Ek|p) is an orthonormal basis for TpS at each p ∈U ∩S.
Proposition 8.24 (Existence of Adapted Orthonormal Frames).
Let S ⊂M be an embedded Riemannian submanifold of the Riemannian
manifold (M, g). For each p ∈S, there is an adapted orthonormal frame
on a neighborhood U of p in M.
Proof. Let (x1, . . . , xn) be slice coordinates for S on a neighborhood U
of p, so that S ∩U is the set where xk+1 = · · · = xn = 0. Applying
the Gram-Schmidt algorithm to the frame (∂/∂xi), we obtain an ortho-
normal frame (E1, . . . , En) with the property that span(E1|p, . . . , Ek|p) =
span(∂/∂x1|p, . . . , ∂/∂xk|p) = TpS at each p ∈S.
The Tangent-Cotangent Isomorphism
Another very important feature of Riemannian metrics is that they provide
a natural correspondence between tangent and cotangent vectors. Given a
Riemannian metric g on a manifold M, deﬁne a bundle map eg: TM →
T ∗M by
eg(X)(Y ) = gp(X, Y )
for X, Y ∈TpM.
(Recall that a bundle map is a smooth map whose restriction to each ﬁber
is a linear map from TpM to T ∗
p M.)
Exercise 8.14.
Show that eg is a bundle map.

Riemannian Metrics
193
Note that eg is injective, because eg(X) = 0 implies 0 = eg(X)(X) =
gp(X, X), which in turn implies X = 0. For dimensional reasons, therefore,
eg is bijective, and so it is a bundle isomorphism (see Problem 5-12).
In coordinates,
eg(X)(Y ) = gij(p)XiY j,
which implies that the covector eg(X) has the coordinate expression
eg(X) = gij(p)Xidyj.
In other words, the restriction of eg to TpM is the linear map whose matrix
with respect to the coordinate bases for TpM and T ∗
p M is just the same as
the matrix of g.
It is customary to denote the components of the covector eg(X) by
Xj = gij(p)Xi,
so that
eg(X) = Xjdyj.
Because of this, one says that eg(X) is obtained from X by lowering an
index. The notation X♭is frequently used for eg(X), because the symbol ♭
(“ﬂat”) is used in musical notation to indicate that a tone is to be lowered.
Similarly, the inverse map eg−1 : T ∗
p M →TpM is represented by the inverse
of the matrix (gij). The components of this inverse matrix are usually
denoted by gij, so that
gijgjk = gkjgji = δi
k.
Thus for a cotangent vector ξ ∈T ∗
p M, eg−1(ξ) has the coordinate represen-
tation
eg−1(ξ) = ξi ∂
∂xi ,
where ξi = gij(p)ξj.
We use the notation ξ# (“ξ-sharp”) for eg−1(ξ), and say that ξ# is obtained
from ξ by raising an index.
The most important use of the sharp operation is to recover the notion
of the gradient as a vector ﬁeld on Riemannian manifolds. For any smooth
function f on a Riemannian manifold (M, g), we deﬁne a vector ﬁeld gradf,
called the gradient of f, by
grad f = (df)# = eg−1(df).
Unraveling the deﬁnitions, for any X ∈TpM, it satisﬁes
⟨grad f|p, X⟩g = eg(grad f|p)(X) = dfp(X) = Xf.

194
8. Tensors
Thus grad f is the unique vector ﬁeld that satisﬁes
⟨gradf, X⟩g = Xf
for every vector ﬁeld X,
or equivalently,
⟨grad f,·⟩g = df.
In coordinates, gradf has the expression
grad f = gij ∂f
∂xi
∂
∂xj .
In particular, on Rn with the Euclidean metric, this is just
gradf = δij ∂f
∂xi
∂
∂xj =
n
X
i=1
∂f
∂xi
∂
∂xi .
Thus our new deﬁnition of the gradient in this case coincides with the gra-
dient from elementary calculus, which is the vector ﬁeld whose components
are the partial derivatives of f. In other coordinates, however, the gradient
will not generally have the same form.
Example 8.25. Let us compute the gradient of a function f ∈C∞(R2)
in polar coordinates. From (8.4), we see that the matrix of g in polar
coordinates is
  1 0
0 r2

, so its inverse matrix is
  1
0
0 1/r2 
. Inserting this into
the formula for the gradient, we obtain
gradf = ∂f
∂r
∂
∂r + 1
r2
∂f
∂θ
∂
∂θ.
Existence of Riemannian Metrics
We end this section by proving the following important result.
Proposition 8.26 (Existence of Riemannian Metrics).
Every
smooth manifold admits a Riemannian metric.
Proof. We give two proofs. For the ﬁrst, we begin by covering M by coor-
dinate charts (Uα, ϕα). In each coordinate domain, there is a Riemannian
metric gα given by the Euclidean metric δijdxidxj in coordinates. Now let
{ψα} be a partition of unity subordinate to the cover {Uα}, and deﬁne
g =
X
α
ψαgα.
Because of the local ﬁniteness condition for partitions of unity, there are
only ﬁnitely many nonzero terms in a neighborhood of any point, so this

Riemannian Metrics
195
expression deﬁnes a smooth tensor ﬁeld. It is obviously symmetric, so only
positivity needs to be checked. If X ∈TpM is any nonzero vector, then
gp(X, X) =
X
α
ψα(p)gα|p(X, X).
This sum is nonnegative, because each term is nonnegative. At least one of
the functions ψα is strictly positive at p (because they sum to 1). Because
gα|p(X, X) > 0, it follows that gp(X, X) > 0.
The second proof is shorter, but relies on the Whitney embedding the-
orem, which is far less elementary. We simply embed M in RN for some
N, and then the Euclidean metric induces a Riemannian metric g|M on
M.
Pseudo-Riemannian Metrics
An important generalization of Riemannian metrics is obtained by relaxing
the requirement that the metric be positive deﬁnite. A 2-tensor g on a vector
space V is said to be nondegenerate if it satisﬁes any of the following three
equivalent conditions:
• g(X, Y ) = 0 for all Y ∈V if and only if X = 0.
• The map eg: V →V ∗deﬁned by eg(X)(Y ) = g(X, Y ) is invertible.
• The matrix of g with respect to any basis is nonsingular.
Just as any inner product can be transformed to the Euclidean one by
switching to an orthonormal basis, every nondegenerate symmetric 2-tensor
can be transformed by a change of basis to one whose matrix is diagonal
with all entries equal to ±1. The numbers of positive and negative diag-
onal entries are independent of the choice of basis; thus the signature of
g, deﬁned as the sequence (−1, . . . , −1, +1, . . ., +1) of diagonal entries in
nondecreasing order, is an invariant of g.
A pseudo-Riemannian metric on a manifold M is a smooth symmet-
ric 2-tensor ﬁeld that is nondegenerate at each point. Pseudo-Riemannian
metrics whose signature is (−1, +1, . . ., +1) are called Lorentz metrics; they
play a central role in physics, where they are used to model gravitation in
Einstein’s general theory of relativity.
We will not pursue the subject of pseudo-Riemannian metrics any fur-
ther, except to note that neither of the proofs above of the existence of
Riemannian metrics carries over to the pseudo-Riemannian case: in partic-
ular, it is not always true that the restriction of a nondegenerate 2-tensor to
a subspace is nondegenerate, nor is it true that a linear combination of non-
degenerate 2-tensors with positive coeﬃcients is necessarily nondegenerate.
Indeed, it is not true that every manifold admits a Lorentz metric.

196
8. Tensors
Problems
8-1. Let V and W be ﬁnite-dimensional real vector spaces. Show that
the tensor product V ⊗W is uniquely determined up to canonical
isomorphism by its characteristic property (Proposition 8.3). More
precisely, suppose eπ : V ×W →Z is a bilinear map into a vector space
Z with following property: For any bilinear map A: V ×W →Y , there
is a unique linear map eA: Z →Y such that the following diagram
commutes:
V × W
Y
-
A
Z.
?
eπ
eA
    
Then there is a unique isomorphism Φ: V ⊗W →Z such that eπ = Φ◦
π. [This shows that the details of the construction used to deﬁne the
tensor product are irrelevant, as long as the resulting space satisﬁes
the characteristic property.]
8-2. If V is any ﬁnite-dimensional real vector space, prove that there are
canonical isomorphisms R ⊗V ∼= V ∼= V ⊗R.
8-3. Let V and W be ﬁnite-dimensional real vector spaces. Prove that
there is a canonical (basis-independent) isomorphism between V ∗⊗W
and the space Hom(V, W) of linear maps from V to W.
8-4. Let M be a smooth n-manifold, and σ a covariant k-tensor ﬁeld on
M. If (xi) and (exj) are overlapping coordinate charts on M, we can
write
σ = σi1...ikdxi1 ⊗· · · ⊗dxik = σ = eσj1...jkdexj1 ⊗· · · ⊗dexjk.
Compute a transformation law analogous to (4.4) expressing the com-
ponent functions σi1...ik in terms of eσj1...jk.
8-5. Generalize the change of coordinate formula of Problem 8-4 to mixed
tensors of any rank.
8-6. Let M be a smooth manifold.
(a) Given a smooth covariant k-tensor ﬁeld τ ∈Tk(M), show that
the map T(M) × · · · × T(M) →C∞(M) deﬁned by
(X1, . . . , Xk) 7→τ(X1, . . . , Xk)

Problems
197
is multilinear over C∞(M), in the sense that for any smooth
functions f, f ′ ∈C∞(M) and smooth vector ﬁelds Xi, X′
i,
τ(X1, . . . , fXi + f ′X′
i, . . . , Xk)
= fτ(X1, . . . , Xi, . . . , Xk) + f ′τ(X1, . . . , X′
i, . . . , Xk).
(b) Show that a map
eτ : T(M) × · · · × T(M) →C∞(M)
is induced by a smooth tensor ﬁeld as above if and only if it is
multilinear over C∞(M).
8-7. Let V be an n-dimensional real vector space. Show that
dim Σk(V ) =
n + k −1
k

= (n + k −1)!
k!(n −1)! .
8-8.
(a) Let T be a covariant k-tensor on a ﬁnite-dimensional real vector
space V . Show that Sym T is the unique symmetric k-tensor
satisfying
(Sym T )(X, . . . , X) = T (X, . . . , X)
for all X ∈V .
(b) Show that the symmetric product is associative: For all symmet-
ric tensors R, S, T ,
(RS)T = R(ST ).
(c) If ω1, . . . , ωk are covectors, show that
ω1 · · · ωk = 1
k!
X
σ∈Sk
ωσ(1) ⊗· · · ⊗ωσ(k).
8-9. Let ◦g = g|Sn denote the round metric on the n-sphere, i.e., the metric
induced from the Euclidean metric by the usual inclusion of Sn into
Rn+1.
(a) Derive an expression for ◦g in stereographic coordinates by com-
puting the pullback (σ−1)∗g.
(b) In the case n = 2, do the analogous computation in spherical
coordinates (x, y, z) = (sin ϕ cos θ, sin ϕ sin θ, cos ϕ).

198
8. Tensors
8-10. Let M be any smooth manifold.
(a) Show that TM and T ∗M are isomorphic vector bundles.
(b) Show that the isomorphism of part (a) is not canonical, in the
following sense: There does not exist a rule that assigns to every
smooth manifold M a bundle isomorphism λM : TM →T ∗M in
such a way that for every smooth map F : M →N, the following
diagram commutes:
T ∗M
T ∗N.

F ∗
TM
TN
-
F∗
?
λM
?
λN
8-11. Let Γ be a discrete group acting smoothly, freely, and properly on a
smooth manifold f
M, and let M = f
M/Γ. Show that a Riemannian
metric eg on f
M is the pullback of a metric on M by the quotient map
π: f
M →M if and only if eg is invariant under Γ (i.e., γ∗eg = eg for
every γ ∈Γ).
8-12. Let (M, g) and (f
M, eg) be Riemannian manifolds. Suppose F : M →
f
M is a smooth map such that F ∗eg = g. Show that F is an immersion.
8-13. Let (M, g) be a Riemannian manifold. Show that the following are
equivalent:
(a) Each point of M has a coordinate neighborhood in which the
coordinate frame is orthonormal.
(b) g is ﬂat.
8-14. Show that the shortest path between two points in Euclidean space
is a straight line. More precisely, for x, y ∈Rn, let γ : [0, 1] →Rn be
the curve segment
γ(t) = (1 −t)x + ty,
and show that any other piecewise smooth curve segment eγ from x
to y satisﬁes Lg(eγ) ≥Lg(γ). [Hint: First consider the case in which
both x and y lie on the x1-axis.]
8-15. Let M = R2 ∖{0} with the Euclidean metric g, and let p = (1, 0),
q = (−1, 0). Show that there is no piecewise smooth curve segment γ
from p to q in M such that Lg(γ) = dg(p, q).
8-16. Let (M, g) be a Riemannian manifold, and let f ∈C∞(M).

Problems
199
(a) For any p ∈M, show that among all unit vectors X ∈TpM, the
directional derivative Xf is greatest when X points in the same
direction as grad f|p, and the length of gradf|p is equal to the
value of the directional derivative in that direction.
(b) If p is a regular point of f, show that grad f|p is orthogonal to
the level set of f through p.
8-17. Let Tn = S1 × · · · × S1 ⊂Cn, and let g be the metric on Tn induced
from the Euclidean metric on Cn (identiﬁed with R2n). Show that g
is ﬂat.
8-18. Let (M, g) be a Riemannian manifold and let S ⊂M be a Riemannian
submanifold. If p ∈S, a vector N ∈TpM is said to be normal to S
if N is orthogonal to TpS with respect to g. Show that the set of
all vectors normal to S is a smooth vector bundle over S, called the
normal bundle to S. [Hint: use adapted orthonormal frames.]
8-19. If S ⊂M is an embedded submanifold, a smooth map N : S →TM
such that Np ∈TpM for each p ∈S is called a vector ﬁeld along
S. If (M, g) is a Riemannian manifold and S ⊂M is a Riemannian
submanifold of codimension 1, show that every p ∈S has a neighbor-
hood on which there exist exactly two unit-length vector ﬁelds along
S that are normal to S.

200
8. Tensors

9
Diﬀerential Forms
In the previous chapter, we introduced symmetric tensors—those whose val-
ues are unchanged by interchanging any pair of arguments. In this chapter,
we explore the complementary notion of alternating tensors, whose values
change sign whenever two arguments are interchanged. The main focus of
the chapter is diﬀerential forms, which are just alternating tensor ﬁelds.
These innocent-sounding objects play an unexpectedly important role in
smooth manifold theory, through two applications. First, as we will see in
Chapter 10, they are the objects that can be integrated in a coordinate-
independent way over manifolds or submanifolds; second, as we explore in
Chapter 11, they provide a link between analysis and topology by way of
the de Rham theorem.
We begin the chapter with a heuristic discussion of the measurement of
volume, to motivate the central role played by alternating tensors. We then
proceed to study the algebra of alternating tensors. The most important
algebraic construction is a product operation called the wedge product,
which takes alternating tensors to alternating tensors. Then we transfer
this to manifolds, and introduce the exterior derivative, which is a natural
diﬀerential operator on diﬀerential forms.
At the end of the chapter, we introduce symplectic forms, which are a
particular type of diﬀerential form that play an important role in geometry,
analysis, and mathematical physics.

202
9. Diﬀerential Forms
The Heuristics of Volume Measurement
In Chapter 4, we introduced line integrals of covector ﬁelds, which general-
ize ordinary integrals to curves in manifolds. As we will see in subsequent
chapters, it is also useful to generalize the theory of multiple integrals to
manifolds.
How might we make coordinate-independent sense of multiple integrals?
First, observe that there is no way to deﬁne integrals of functions in a
coordinate-independent way on a manifold. It is easy to see why, even in
the simplest possible case: Suppose C ⊂Rn is an n-dimensional cube, and
f : C →R is the constant function f(x) ≡1. Then
Z
C
f dV = Vol(C),
which is clearly not invariant under coordinate transformations, even if we
just restrict attention to linear ones.
Let us think a bit more geometrically about why covector ﬁelds are the
natural ﬁelds to integrate along curves. A covector ﬁeld assigns a number to
each tangent vector, in such a way that multiplying the tangent vector by
a constant has the eﬀect of multiplying the resulting number by the same
constant. Thus a covector ﬁeld can be thought of as assigning a “signed
length meter” to each one-dimensional subspace of the tangent space, and
it does so in a coordinate-independent way. Computing the line integral of
a covector ﬁeld, in eﬀect, assigns a “length” to a curve by using this varying
measuring scale along the points of the curve.
Now we wish to seek a kind of “ﬁeld” that can be integrated in a
coordinate-independent way over submanifolds of dimension k > 1. Its
value at each point should be something that we can interpret as a “signed
volume meter” on k-dimensional subspaces of the tangent space—a ma-
chine Ωthat accepts any k tangent vectors (X1, . . . , Xk) at a point and
returns a number Ω(X1, . . . , Xk) that we might think of as the “signed vol-
ume” of the parallelepiped spanned by those vectors, measured according
to a scale determined by Ω.
The most obvious example of such a machine is the determinant in Rn.
For example, it is shown in most linear algebra texts that for any two vectors
X1, X2 ∈R2, det(X1, X2) is, up to a sign, the area of the parallelogram
spanned by X1, X2. It is not hard to show (see Problem 9-1) that the
analogous fact is true in all dimensions. The determinant, remember, is an
example of a tensor. In fact, it is a tensor of a very speciﬁc type: It changes
sign whenever two of its arguments are interchanged. A covariant k-tensor
T on a ﬁnite-dimensional vector space V is said to be alternating if it has
this property:
T (X1, . . . , Xi, . . . , Xj, . . . , Xk) = −T (X1, . . . , Xj, . . . , Xi, . . . , Xk).

The Heuristics of Volume Measurement
203
X1
X2
cX2
FIGURE 9.1. Scaling by a constant.
X1
X2
X′
2
X2 + X′
2
FIGURE 9.2. Sum of two vectors.
Let us consider what properties we might expect a general “signed vol-
ume meter” Ωto have. To be consistent with our ordinary ideas of volume,
we would expect that multiplying any one of the vectors by a constant c
should cause the volume to be scaled by that same constant (Figure 9.1),
and that the parallelepiped formed by adding together two vectors in the
ith place results in a volume that is the sum of the volumes of the two
parallelepipeds with the original vectors in the ith place (Figure 9.2):
Ω(X1, . . . , cXi, . . . , Xn) = cΩ(X1, . . . , Xi, . . . , Xn),
Ω(X1, . . . , Xi + X′
i, . . . , Xn) = Ω(X1, . . . , Xi, . . . , Xn)
+ Ω(X1, . . . , X′
i, . . . , Xn).
These two requirements suggest that Ωshould be multilinear, and thus
should be a covariant k-tensor.
There is one more essential property that we should expect: Since n lin-
early dependent vectors span a parallepiped of zero n-dimensional volume,
Ωshould give the value zero whenever it is applied to n linearly dependent
vectors. As the next lemma shows, this forces Ωto be an alternating tensor.
Lemma 9.1. Suppose Ωis a k-tensor on a vector space V with the property
that Ω(X1, . . . , Xk) = 0 whenever X1, . . . , Xk are linearly dependent. Then
Ωis alternating.

204
9. Diﬀerential Forms
Proof. The hypothesis implies, in particular, that Ωgives the value zero
whenever two of its arguments are the same. This in turn implies
0 = Ω(X1, . . . , Xi + Xj, . . . , Xi + Xj, . . . , Xn)
= Ω(X1, . . . , Xi, . . . , Xi, . . . , Xn) + Ω(X1, . . . , Xi, . . . , Xj, . . . , Xn)
+ Ω(X1, . . . , Xj, . . . , Xi, . . . , Xn) + Ω(X1, . . . , Xj, . . . , Xj, . . . , Xn)
= Ω(X1, . . . , Xi, . . . , Xj, . . . , Xn) + Ω(X1, . . . , Xj, . . . , Xi, . . . , Xn).
Thus Ωis alternating.
Because of these considerations, alternating tensor ﬁelds are promising
candidates for objects that can be integrated in a coordinate-independent
way. We will develop these ideas rigorously in the remainder of this chapter
and the next; as we do, you should keep this geometric motivation in mind.
The Algebra of Alternating Tensors
In this section, we set aside heuristics and start developing the technical
machinery for working with alternating tensors. For any ﬁnite-dimensional
real vector space V , let Λk(V ) denote the subspace of T k(V ) consisting
of alternating tensors. [Warning: Some authors use the notation Λk(V ∗)
in place of Λk(V ) for this space; see Problem 9-8 for a discussion of the
reasons why.] An alternating k-tensor is sometimes called a k-covector.
Recall that for any permutation σ ∈Sk, the sign of σ, denoted by sgn σ,
is equal to +1 if σ is even (i.e., can be written as a composition of an even
number of transpositions), and −1 if σ is odd.
The following exercise is an analogue of Exercise 8.9.
Exercise 9.1.
Show that the following are equivalent for a covariant k-
tensor T:
(a)
T is alternating.
(b)
For any vectors X1, . . . , Xk and any permutation σ ∈Sk,
T(Xσ(1), . . . , Xσ(k)) = (sgn σ)T(X1, . . . , Xk).
(c)
T gives zero whenever two of its arguments are equal:
T(X1, . . . , Y, . . . , Y, . . . , Xk) = 0.
(d)
T(X1, . . . , Xk) = 0 whenever the vectors (X1, . . . , Xk) are linearly in-
dependent.
(e)
With respect to any basis, the components Ti1...ik of T change sign
whenever two indices are interchanged.

The Algebra of Alternating Tensors
205
Notice that part (d) implies that there are no nonzero alternating k-
tensors on V if k > dim V , for then every k-tuple of vectors is dependent.
Every 0-tensor (which is just a real number) is alternating, because there
are no arguments to interchange. Similarly, every 1-tensor is alternating.
An alternating 2-tensor is just a skew-symmetric bilinear form on V . It is
interesting to note that any 2-tensor T can be expressed as the sum of an
alternating tensor and a symmetric one, because
T (X, Y ) = 1
2(T (X, Y ) −T (Y, X)) + 1
2(T (X, Y ) + T (Y, X))
= A(X, Y ) + S(X, Y ),
where A(X, Y ) =
1
2(T (X, Y ) −T (Y, X)) is alternating, and S(X, Y ) =
1
2(T (X, Y ) + T (Y, X)) is symmetric. This is not true for tensors of higher
rank, as Problem 9-2 shows.
The tensor S deﬁned above is just Sym T , the symmetrization of T de-
ﬁned in the preceding chapter. We deﬁne a similar projection Alt: T k(V ) →
Λk(V ), called the alternating projection, as follows:
Alt T = 1
k!
X
σ∈Sk
(sgn σ)T σ.
More explicitly, this means
(Alt T )(X1, . . . , Xk) = 1
k!
X
σ∈Sk
(sgn σ)T (Xσ(1), . . . , Xσ(k)).
Example 9.2. If T is any 1-tensor, then Alt T = T . If T is a 2-tensor,
then
Alt T (X, Y ) = 1
2(T (X, Y ) −T (Y, X)).
For a 3-tensor T ,
Alt T (X, Y, Z) = 1
6(T (X, Y, Z) + T (Y, Z, X) + T (Z, X, Y )
−T (Y, X, Z) −T (X, Z, Y ) −T (Z, Y, X)).
The next lemma is the analogue of Lemma 8.10.
Lemma 9.3 (Properties of the Alternating Projection).
(a) For any tensor T , Alt T is alternating.
(b) T is alternating if and only if Alt T = T .
Exercise 9.2.
Prove Lemma 9.3.

206
9. Diﬀerential Forms
Elementary Alternating Tensors
Let k be a positive integer. An ordered k-tuple I = (i1, . . . , ik) of positive
integers is called a multi-index of length k. If I and J are multi-indices such
that J is obtained from I by a permutation σ ∈Sk, in the sense that
j1 = iσ(1), . . . , jk = iσ(k),
then we write J = σI. It is useful to extend the Kronecker delta notation
in the following way. If I and J are multi-indices of length k, we deﬁne
δJ
I =









sgn σ
if neither I nor J has a repeated index
and J = σI for some σ ∈Sk,
0
if I or J has a repeated index
or J is not a permutation of I.
Let V be an n-dimensional vector space, and suppose (ε1, . . . , εn) is
any basis for V ∗. We will deﬁne a collection of alternating tensors on
V that generalize the determinant function on Rn. For each multi-index
I = (i1, . . . , ik) of length k such that 1 ≤i1, . . . , ik ≤n, deﬁne a covariant
k-tensor εI by
εI(X1, . . . , Xk) = det



εi1(X1)
. . .
εi1(Xk)
...
...
εik(X1)
. . .
εik(Xk)



= det



Xi1
1
. . .
Xi1
k
...
...
Xik
1
. . .
Xik
k


.
(9.1)
In other words, if X denotes the matrix whose columns are the components
of the vectors X1, . . . , Xk with respect to the basis (Ei) dual to (εi), then
εI(X1, . . . , Xk) is the determinant of the k × k minor consisting of rows
i1, . . . , ik of X. Because the determinant changes sign whenever two columns
are interchanged, it is clear that εI is an alternating k-tensor. We will call
εI an elementary alternating tensor or elementary k-covector.
For example, in terms of the standard dual basis (e1, e2, e3) for (R3)∗,
we have
e13(X, Y ) = X1Y 3 −Y 1X3;
e123(X, Y, X) = det(X, Y, Z).
Lemma 9.4. Let (Ei) be a basis for V , let (εi) be the dual basis for V ∗,
and let εI be as deﬁned above.
(a) If I has a repeated index, then εI = 0.

The Algebra of Alternating Tensors
207
(b) If J = σI for some σ ∈Sk, then εI = (sgn σ)εJ.
(c) The result of evaluating εI on a sequence of basis vectors is
εI(Ej1, . . . , Ejk) = δI
J.
Proof. If I has a repeated index, then for any vectors X1, . . . , Xk, the
determinant in (9.1) has two identical rows and thus is equal to zero, which
proves (a). On the other hand, if J is obtained from I by interchanging
two indices, then the corresponding determinants have opposite signs; this
implies (b).
To prove (c), we consider several cases. First, if I has a repeated index,
then εI = 0 by part (a). If J has a repeated index, then εI(Ej1, . . . , Ejk) =
0 by Exercise 9.1(c). If neither multi-index has any repeated indices but
J is not a permutation of I, then the determinant in the deﬁnition of
εI(Ej1, . . . , Ejk) has at least one row of zeros, so it is zero. If J = I,
then εI(Ej1, . . . , Ejk) is the determinant of the identity matrix, which is 1.
Finally, if J = σI, then
εI(Ej1, . . . , Ejk) = (sgn σ)εJ(Ej1, . . . , Ejk) = sgn σ
by part (b).
The signiﬁcance of the elementary k-covectors is that they provide a con-
venient basis for Λk(V ). Of course, the εI are not all independent, because
some of them are zero and the ones corresponding to diﬀerent permutations
of the same multi-index are constant multiples of each other. But, as the
next lemma shows, we can get a basis by restricting attention to an appro-
priate subset of multi-indices. A multi-index I = (i1, . . . , ik) is said to be
increasing if i1 < · · · < ik. It will be useful to use a primed summation sign
to denote a sum over only increasing multi-indices, so that, for example,
X′
I
TIεI =
X
{I:1≤i1<···<ik≤n}
TIεI.
Lemma 9.5. Let V be an n-dimensional vector space. If (εi) is any basis
for V ∗, then the collection of k-covectors
{εI : I is increasing}
is a basis for Λk(V ). Therefore,
dim Λk(V ) =
n
k

=
n!
k!(n −k)!.

208
9. Diﬀerential Forms
Proof. Let (Ei) be the basis for V
dual to (εi), and let E = {εI :
I is increasing}. We need to show that the set E spans Λk(V ) and is inde-
pendent.
To show that E spans, let T ∈Λk(V ) be arbitrary. For each multi-index
I = (i1, . . . , ik), deﬁne a real number TI by
TI = T (Ei1, . . . , Eik).
The fact that T is alternating implies that TI = 0 if I contains a repeated
multi-index, and TJ = (sgn σ)TI if J = σI for σ ∈Sk. For any multi-index
J, Lemma 9.4 gives
X′
I
TIεI(Ej1, . . . , Ejk) =
X′
I
TIδI
J = TJ = T (Ej1, . . . , Ejk).
Therefore, P′
I TIεI = T , so E spans Λk(V ).
To show that E is an independent set, suppose
X′
I
TIεI = 0
for some coeﬃcients TI. Let J be any increasing multi-index. Applying
both sides to (Ej1, . . . , Ejk) and using Lemma 9.4,
0 =
X′
I
TIεI(Ej1, . . . , Ejk) = TJ.
Thus each coeﬃcient TJ is zero.
In particular, for an n-dimensional vector space V , this lemma implies
that Λn(V ) is 1-dimensional, and is spanned by ε1...n. By deﬁnition, this
elementary n-covector acts on vectors (X1, . . . , Xn) by taking the deter-
minant of the component matrix X = (Xi
j). For example, on Rn with the
standard basis, e1...n is precisely the determinant function. Since there are
no increasing multi-indices of length greater than n, the space Λk(V ) is
trivial for k > n.
The Wedge Product
In Chapter 8, we deﬁned the symmetric product, which takes a pair of
symmetric tensors S, T and yields another symmetric tensor ST = Sym(S⊗
T ) whose rank is the sum of the ranks of the original ones.
In this section, we will deﬁne a similar product operation for alternat-
ing tensors. One way to deﬁne it would be to mimic what we did in the
symmetric case and deﬁne the product of alternating tensors ω and η to

The Wedge Product
209
be Alt(ω ⊗η). However, we will use a diﬀerent deﬁnition that looks more
complicated at ﬁrst but turns out to be much better suited to computation.
If ω ∈Λk(V ) and η ∈Λl(V ), we deﬁne the wedge product or exterior
product of ω and η to be the alternating (k + l)-tensor
ω ∧η = (k + l)!
k!l!
Alt(ω ⊗η).
(9.2)
The mysterious coeﬃcient is motivated by the simplicity of the statement
of the following lemma.
Lemma 9.6. For any multi-indices I = (i1, . . . , ik) and J = (j1, . . . , jl),
εI ∧εJ = εIJ,
(9.3)
where IJ is the multi-index (i1, . . . , ik, j1, . . . , jl) obtained by concatenating
I and J.
Proof. By multilinearity, it suﬃces to show that
εI ∧εJ(Ep1, . . . , Epk+l) = εIJ(Ep1, . . . , Epk+l)
(9.4)
for any sequence (Ep1, . . . , Epk+l) of basis vectors. We consider several cases.
Case I: P = (p1, . . . , pk+l) has a repeated index. In this case, both sides
of (9.4) are zero by Exercise 9.1(c).
Case II: P contains an index that does not appear in either I or J. In
this case, the right-hand side is zero by Lemma 9.4(c). Similarly, each term
in the expansion of the left-hand side involves either εI or εJ evaluated on
a sequence of basis vectors that is not a permutation of I or J, respectively,
so the left-hand side is also zero.
Case III: P = IJ and P has no repeated indices. In this case, the right-
hand side of (9.4) is equal to 1 by Lemma 9.4(c), so we need to show that
the left-hand side is also equal to 1. By deﬁnition,
εI ∧εJ(Ep1, . . . , Epk+l)
= (k + l)!
k!l!
Alt(εI ⊗εJ)(Ep1, . . . , Epk+l)
=
1
k!l!
X
σ∈Sk+l
(sgn σ)εI(Epσ(1), . . . , Epσ(k))εJ(Epσ(k+1), . . . , Epσ(k+l)).
By Lemma 9.4 again, the only terms in the sum above that give nonzero
values are those in which σ permutes the ﬁrst k indices and the last l
indices of P separately. In other words, σ must be of the form σ = τη,
where τ ∈Sk acts by permuting {1, . . . , k} and η ∈Sl acts by permuting

210
9. Diﬀerential Forms
{k + 1, . . . , k + l}. Since sgn(τη) = (sgn τ)(sgn η), we have
εI ∧εJ(Ep1, . . . , Epk+l)
=
1
k!l!
X
τ∈Sk
η∈Sl
(sgn τ)(sgn η)εI(Epτ(1), . . . , Epτ(k))εJ(Epη(k+1), . . . , Epη(k+l))
=
 1
k!
X
τ∈Sk
(sgn τ)εI(Epτ(1), . . . , Epτ(k))

×
 1
l!
X
η∈Sl
(sgn η)εJ(Epη(k+1), . . . , Epη(k+l))

= (Alt εI)(Ep1, . . . , Epk) (Alt εJ)(Epk+1, . . . , Epk+l)
= εI(Ep1, . . . , Epk)εJ(Epk+1, . . . , Epk+l)
= 1.
Case IV: P is a permutation of IJ. In this case, applying a permutation
to P brings us back to Case III. Since the eﬀect of the permutation is to
multiply both sides of (9.4) by the same sign, the result holds in this case
as well.
Proposition 9.7 (Properties of the Wedge Product).
(a) Bilinearity:
(aω + a′ω′) ∧η = a(ω ∧η) + a′(ω′ ∧η),
η ∧(aω + a′ω′) = a(η ∧ω) + a′(η ∧ω′).
(b) Associativity:
ω ∧(η ∧ξ) = (ω ∧η) ∧ξ.
(c) Anticommutativity: For ω ∈Λk(V ) and η ∈Λl(V ),
ω ∧η = (−1)klη ∧ω.
(d) If (ε1, . . . , εn) is any basis for V ∗and I = (i1, . . . , ik) is any multi-
index,
εi1 ∧· · · ∧εik = εI.
(9.5)
(e) For any covectors ω1, . . . , ωk and vectors X1, . . . , Xk,
ω1 ∧· · · ∧ωk(X1, . . . , Xk) = det(ωi(Xj)).
(9.6)

The Wedge Product
211
Proof. Bilinearity follows immediately from the deﬁnition, because the ten-
sor product is bilinear and Alt is linear. To prove associativity, note that
Lemma 9.6 gives
(εI ∧εJ) ∧εK = εIJ ∧εK = εIJK = εI ∧εJK = εI ∧(εJ ∧εK).
The general case follows from bilinearity. Similarly, using Lemma 9.6 again,
we get
εI ∧εJ = εIJ = (sgn τ)εJI = (sgn τ)εJ ∧εI,
where τ is the permutation that sends IJ to JI. It is easy to check that
sgn τ = (−1)kl, because τ can be decomposed as a composition of kl trans-
positions (each index of I must be moved past each of the indices of J).
Anticommutativity then follows from bilinearity.
Part (d) is an immediate consequence of Lemma 9.6 and induction. To
prove part (e), we note that the special case in which each ωj is one of
the basis covectors εij just reduces to (9.5). Since both sides of (9.6) are
multilinear in (ω1, . . . , ωk), this suﬃces.
Because of part (d) of this lemma, we will generally use the notations εI
and εi1 ∧· · · ∧εik interchangeably.
The deﬁnition and computational properties of the wedge product can
seem daunting at ﬁrst sight. However, the only properties that you need
to remember for most practical purposes are that it is bilinear, associative,
and anticommutative, and satisﬁes (9.6). In fact, these properties determine
the wedge product uniquely, as the following exercise shows.
Exercise 9.3.
Show that the wedge product is the unique associative, bi-
linear, and anticommutative map Λk(V )×Λl(V ) →Λk+l(V ) satisfying (9.6).
As we observed at the beginning of this section, one could also deﬁne
the wedge product without the unwieldy coeﬃcient of (9.2). Many authors
choose this alternative deﬁnition of the wedge product, which we denote
by ∧:
ω ∧η = Alt(ω ⊗η).
(9.7)
Using this deﬁnition, (9.3) is replaced by
εI ∧εJ =
k!l!
(k + l)!εIJ
and (9.6) is replaced by
ω1 ∧· · · ∧ωk(X1, . . . , Xk) = 1
k! det(ωi(Xj))
(9.8)
whenever ω1, . . . , ωk are covectors, as you can check.

212
9. Diﬀerential Forms
Because of (9.6), we will call the wedge product deﬁned by (9.2) the
determinant convention for the wedge product, and the wedge product
deﬁned by (9.7) the Alt convention. Although the deﬁnition of the Alt
convention is perhaps a bit more natural, the computational advantages of
the determinant convention make it preferable for most applications, and
we will use it exclusively in this book.
Diﬀerential Forms on Manifolds
Now we turn our attention to an n-dimensional smooth manifold M. The
subset of T kM consisting of alternating tensors is denoted by ΛkM:
ΛkM =
a
p∈M
Λk(TpM).
Exercise 9.4.
Show that ΛkM is a smooth subbundle of T kM, and is
therefore a smooth vector bundle of rank
ÿn
k
þ
over M.
A smooth section of ΛkM is called a diﬀerential k-form, or just a k-form;
this is just a smooth tensor ﬁeld whose value at each point is an alternating
tensor. We denote the vector space of sections of ΛkM by Ak(M). (We
ordinarily denote the space of sections of a vector bundle by the upper-
case script letter corresponding to the name of the bundle; in this case, we
use A because of the typographical similarity between A and Λ.)
In any coordinate chart, a k-form ω can be written locally as
ω =
X′
I
ωIdxi1 ∧· · · ∧dxik =
X′
I
ωIdxI,
where the coeﬃcients ωI are smooth functions deﬁned on the coordinate
neighborhood, and we use dxI as an abbreviation for dxi1 ∧· · · ∧dxik (not
to be mistaken for the diﬀerential of a function xI). In terms of diﬀerential
forms, the result of Lemma 9.4(c) translates to
dxi1 ∧· · · ∧dxik
 ∂
∂xj1 , . . . ,
∂
∂xjk

= δI
J.
The wedge product of a k-form with an l-form is a (k + l)-form. A 0-form
is just a real-valued function, and we interpret the wedge product f ∧η of
a 0-form f with a k-form η to mean the product fη.
Example 9.8. A 1-form is just a smooth covector ﬁeld. On R3, some ex-
amples of 2-forms are given by
ω = (sin xy) dy ∧dz;
η = dx ∧dy + dx ∧dz + dy ∧dz.

Diﬀerential Forms on Manifolds
213
Every n-form on Rn is a smooth function times dx1 ∧· · · ∧dxn, because
there is only one increasing multi-index of length n.
If F : M →N is a smooth map and ω is a diﬀerential form on N, the
pullback F ∗ω is a diﬀerential form on M, deﬁned as for any smooth tensor
ﬁeld:
F ∗ω(X1, . . . , Xk) = ω(F∗X1, . . . , F∗Xk).
In particular, if ι: N ,→M is the inclusion map of an immersed submani-
fold, then we usually use the notation ω|N for ι∗ω.
Lemma 9.9. Suppose F : M →N is smooth.
(a) F ∗(ω ∧η) = (F ∗ω) ∧(F ∗η).
(b) In any coordinate chart,
F ∗
X′
I
ωIdyi1 ∧· · · ∧dyik

=
X′
I
(ωI ◦F) d(yi1 ◦F) ∧· · · ∧d(yik ◦F).
Exercise 9.5.
Prove this lemma.
This lemma gives a computational rule for pullbacks of diﬀerential forms
similar to the one we developed for arbitrary tensor ﬁelds in the preceding
chapter. As before, it can also be used to compute the expression for a
diﬀerential form in another coordinate chart.
Example 9.10. Let ω be the 2-form dx∧dy on R2. Thinking of the trans-
formation to polar coordinates x = r cos θ, y = r sin θ as an expression for
the identity map with respect to diﬀerent coordinates on the domain and
range, we ﬁnd
ω = dx ∧dy
= d(r cos θ) ∧d(r sin θ)
= (cos θ dr −r sin θ dθ) ∧(sin θ dr + r cos θ dθ)
= r cos2 θ dr ∧dθ −r sin2 θ dθ ∧dr,
where we have used the fact that dr∧dr = dθ∧dθ = 0 by anticommutativity.
Because dθ ∧dr = −dr ∧dθ, this simpliﬁes to
dx ∧dy = r dr ∧dθ.
The similarity between this formula and the formula for changing a dou-
ble integral from Cartesian to polar coordinates is striking. More generally,
we have the following lemma:

214
9. Diﬀerential Forms
Lemma 9.11. Let F : M →N be a smooth map between n-manifolds. If
(xi) and (yj) are coordinates on open sets U ⊂M and V ⊂N, respectively,
and u is a smooth function on V , then the following holds on U ∩F −1(V ):
F ∗ u dy1 ∧· · · ∧dyn
= (u ◦F) det
∂F j
∂xi

dx1 ∧· · · ∧dxn.
(9.9)
Proof. Because the ﬁber of ΛnM is spanned by dx1 ∧· · · ∧dxn at each
point, it suﬃces to show that both sides of (9.9) give the same result when
evaluated on (∂/∂x1, . . . , ∂/∂xn). From Lemma 9.9,
F ∗ u dy1 ∧· · · ∧dyn
= (u ◦F)dF 1 ∧· · · ∧dF n.
Proposition 9.7(e) shows that
dF 1 ∧· · · ∧dF n
 ∂
∂x1 , . . . ,
∂
∂xn

= det

dF j
 ∂
∂xi

= det
∂F j
∂xi

.
Therefore, the left-hand side of (9.9) gives (u ◦F) det(∂F j/∂xi) when ap-
plied to (∂/∂x1, . . . , ∂/∂xn). On the other hand, the right-hand side gives
the same thing, because dx1 ∧· · · ∧dxn(∂/∂x1, . . . , ∂/∂xn) = 1.
Exterior Derivatives
In this section, we deﬁne a natural diﬀerential operator on forms, called the
exterior derivative. It is a generalization of the diﬀerential of a function.
To give some idea where the motivation for the exterior derivative comes
from, let us look back at a question we addressed in Chapter 4. Recall
that not all smooth covector ﬁelds are diﬀerentials of functions: Given ω,
a necessary condition for the existence of a function f such that ω = df is
that ω be closed, which means that it satisﬁes
∂ωj
∂xi −∂ωi
∂xj = 0
(9.10)
in every coordinate system. Since this is a coordinate-independent property
by Lemma 4.25, one might hope to ﬁnd a more invariant way to express it.
The key is that the expression in (9.10) is antisymmetric in the indices i
and j, so it can be interpreted as the ij-component of an alternating tensor
ﬁeld, i.e., a 2-form. We will deﬁne a 2-form dω by
dω =
X
i<j
∂ωj
∂xi −∂ωi
∂xj

dxi ∧dxj,
so it follows that ω is closed if and only if dω = 0.

Exterior Derivatives
215
This formula has a signiﬁcant generalization to diﬀerential forms of all
degrees. For any manifold, we will show that there is a diﬀerential operator
d: Ak(M) →Ak+1(M) satisfying d(dω) = 0 for all ω. Thus it will follow
that a necessary condition for a k-form ω to be equal to dη for some (k−1)-
form η is that dω = 0.
The deﬁnition of d in coordinates is straightforward:
d
X′
I
ωIdxI

=
X′
I
dωI ∧dxI,
(9.11)
where dωI is just the diﬀerential of the function ωI. In somewhat more
detail, this is
d
X′
I
ωIdxi1 ∧· · · ∧dxik

=
X′
I
X
i
∂ωI
∂xi dxi ∧dxi1 ∧· · · ∧dxik.
Observe that when ω is a 1-form, this becomes
d(ωj dxj) = ∂ωj
∂xi dxi ∧dxj =
X
i<j
∂ωj
∂xi −∂ωi
∂xj

dxi ∧dxj,
using the fact that dxi ∧dxj = −dxj ∧dxi, so this is consistent with our
earlier deﬁnition.
Proving that this deﬁnition is independent of the choice of coordinates
takes a little work. This is the content of the next theorem.
Theorem 9.12 (The Exterior Derivative).
On any smooth manifold
M, there is a unique linear map d: Ak(M) →Ak+1(M) for each k ≥0
satisfying the following conditions:
(i) If f is a smooth function (a 0-form), then df is the diﬀerential of f,
deﬁned as usual by
df(X) = Xf.
(ii) If ω ∈Ak(M) and η ∈Al(M), then
d(ω ∧η) = dω ∧η + (−1)kω ∧dη.
(iii) d2 = 0. More precisely, for any k-form ω, d(dω) = 0.
In any local coordinates, d is given by (9.11).
Proof. First we will prove uniqueness. Suppose d: Ak(M) →Ak+1(M) is
a linear operator satisfying (i), (ii), and (iii). We will show that it also sat-
isﬁes (9.11) in any local coordinate chart, which implies that it is uniquely
determined.

216
9. Diﬀerential Forms
We begin by showing that d is local, in the following sense: If ω and eω are
k-forms on M that agree on an open subset U ⊂M, then dω = deω on U.
Writing η = eω −ω, it clearly suﬃces to show that dη = 0 on U if η vanishes
on U. Let p ∈U be arbitrary, and let ϕ ∈C∞(M) be a bump function
that is equal to 1 in a neighborhood of p and supported in U. Then ϕη is
identically zero on M, so
0 = d(ϕη)p = dϕp ∧ηp + ϕ(p)dηp = dηp,
because ϕ ≡1 in a neighborhood of p. Since p was an arbitrary point of U,
this shows that dη = 0 on U.
Suppose (xi) are coordinates on an open subset U ⊂M. Let ω ∈Ak(M),
and write ω = P′
I ωIdxI in coordinates on U. We will show that (9.11)
holds at each point p ∈U. By the extension lemma (Lemma 2.20), we
can extend the coordinate functions xi to smooth functions exi on all of
M that agree with xi in some neighborhood of p. Likewise, we extend the
component functions ωI to functions eωI on M. The k-form eω = P′
I eωIdexi1∧
· · ·∧dexik is globally deﬁned on M and agrees with ω near p. Using linearity
of d together with (i) and (ii), we compute
deω = d
X′
I
eωIdexi1 ∧· · · ∧dexik

=
X′
I
deωI ∧dexi1 ∧· · · ∧dexik + (−1)0X′
I
eωId(dexi1 ∧· · · ∧dexik),
because eωI is a 0-form. Now using (ii) again, the last term expands into a
sum of terms, each of which contains a factor of the form d(dexip), which is
zero by (iii). Therefore, since d is local,
dωp = deωp =
X′
I
deωI|p ∧dexi1
p ∧· · · ∧dexik
p =
X′
I
dωI|p ∧dxi1
p ∧· · · ∧dxik
p .
Since p was arbitrary, (9.11) holds on all of U. This proves that dω is
uniquely determined.
Now to prove that such an operator exists, we begin by assuming that
M is covered by a single coordinate chart, and deﬁne d by (9.11). It is
clearly linear and satisﬁes (i). We need to check that it satisﬁes (ii) and
(iii). Before doing so, we need to know that d satisﬁes
d(f dxi1 ∧· · · ∧dxik) = df ∧dxi1 ∧· · · ∧dxik
for any multi-index I, not just increasing ones. If I has repeated indices,
then clearly both sides are zero. If not, let σ be the permutation sending I
to an increasing multi-index J. Then
d(f dxi1 ∧· · · ∧dxik) = (sgn σ)d(f dxj1 ∧· · · ∧dxjk)
= (sgn σ)df ∧dxj1 ∧· · · ∧dxjk
= df ∧dxi1 ∧· · · ∧dxik.

Exterior Derivatives
217
To prove (ii), it suﬃces to consider terms of the form ω = f dxI =
f dxi1 ∧· · · ∧dxik and η = g dxJ. We compute
d(ω ∧η) = d((f dxI) ∧(g dxJ))
= d(fg dxI ∧dxJ)
= (g df + f dg) ∧dxI ∧dxJ
= (df ∧dxI) ∧(g dxJ) + (−1)k(f dxI) ∧(dg ∧dxJ)
= dω ∧η + (−1)kω ∧dη,
where the (−1)k comes from dg ∧dxI = (−1)kdxI ∧dg.
We will prove (iii) ﬁrst for the special case of a 0-form, i.e., a smooth
real-valued function. In this case,
d(df) = d
 ∂f
∂xj dxj

=
∂2f
∂xi∂xj dxi ∧dxj
=
X
i<j

∂2f
∂xi∂xj −
∂2f
∂xj∂xi

dxi ∧dxj
= 0.
For the general case, we use the k = 0 case together with (ii) to compute
d(dω) = d
X′
I
dωI ∧dxi1 ∧· · · ∧dxik

=
X′
I
d(dωI) ∧dxi1 ∧· · · ∧dxik
+
X′
I
k
X
j=1
(−1)jdωI ∧dxi1 ∧· · · ∧d(dxij ) ∧· · · ∧dxik
= 0.
Finally, we consider the case of an arbitrary manifold M. On any coordi-
nate domain U ⊂M, we have a unique linear operator dU deﬁned as above
and satisfying (i)–(iii). On any set U ∩U ′ where two charts overlap, the
restrictions of dUω and dU′ω to U ∩U ′ must agree by uniqueness; therefore,
deﬁning dω by (9.11) in each coordinate chart, we get a globally-deﬁned
operator satisfying (i)–(iii).
The operator d whose existence and uniqueness are asserted in this theo-
rem is called exterior diﬀerentiation, and dω is called the exterior derivative
of ω. The exterior derivative of a real-valued function f is, of course, just
its diﬀerential df.

218
9. Diﬀerential Forms
Example 9.13. Let us work out the exterior derivatives of arbitrary 1-
forms and 2-forms on R3. Any 1-form can be written
ω = P dx + Q dy + R dz
for some smooth functions P, Q, R. Using (9.11) and the fact that the wedge
product of any 1-form with itself is zero, we compute
dω = dP ∧dx + dQ ∧dy + dR ∧dz
=
∂P
∂x dx + ∂P
∂y dy + ∂P
∂z dz

∧dx +
∂Q
∂x dx + ∂Q
∂y dy + ∂Q
∂z dz

∧dy
+
∂R
∂x dx + ∂R
∂y dy + ∂R
∂z dz

∧dz
=
∂Q
∂x −∂P
∂y

dx ∧dy +
∂P
∂z −∂R
∂x

dz ∧dx
+
∂R
∂y −∂Q
∂z

dy ∧dz.
It is interesting to note that the components of this 2-form are exactly the
components of the curl of the vector ﬁeld with components (P, Q, R) (except
perhaps in a diﬀerent order and with diﬀerent signs). We will explore this
connection in more depth later in the book.
An arbitrary 2-form on R3 can be written
ω = α dx ∧dy + β dx ∧dz + γ dy ∧dz.
A similar computation shows
dω =
∂α
∂z −∂β
∂y + ∂γ
∂x

dx ∧dy ∧dz.
One important feature of the exterior derivative is that it behaves well
with respect to pullbacks, as the next lemma shows.
Lemma 9.14. If G: M →N is a smooth map, then the pullback map
G∗: Ak(N) →Ak(M) commutes with d: For all ω ∈Ak(N),
G∗(dω) = d(G∗ω)
(9.12)
Proof. Let ω ∈Ak(N) be arbitrary. Because d is local, if (9.12) holds in
a neighborhood of each point, then it holds on all of M. In a coordinate
neighborhood, ω can be written as a sum of terms like f dxi1 ∧· · · ∧dxik,
so by linearity it suﬃces to check (9.12) for a form of this type.
For such a form, the left-hand side of (9.12) is
G∗d(f dxi1 ∧· · · ∧dxik) = G∗(df ∧dxi1 ∧· · · ∧dxik)
= d(f ◦G) ∧d(xi1 ◦G) ∧· · · ∧d(xik ◦G),

Symplectic Forms
219
while the right-hand side is
dG∗(f dxi1 ∧· · · ∧dxik) = d((f ◦G) d(xi1 ◦G) ∧· · · ∧d(xik ◦G))
= d(f ◦G) ∧d(xi1 ◦G) ∧· · · ∧d(xik ◦G).
Extending the terminology that we introduced for covector ﬁelds in
Chapter 4, we say that a diﬀerential form ω ∈Ak(M) is closed if dω = 0,
and exact if there exists a (k −1)-form η on M such that ω = dη. The fact
that d2 = 0 implies that every exact form is closed. The converse may not
be true, as we saw already in Chapter 4 the case of covector ﬁelds. We will
return to these ideas in Chapter 11.
Symplectic Forms
In this section, we introduce symplectic forms, a special kind of 2-form
that plays a leading role in many applications of smooth manifold theory
to analysis and physics.
We begin with some linear algebra. Recall that a 2-tensor ω on a ﬁnite-
dimensional real vector space V is said to be nondegenerate if ω(X, Y ) = 0
for all Y ∈V implies X = 0.
Exercise 9.6.
Show that the following are equivalent for a 2-tensor ω on
a ﬁnite-dimensional vector space V :
(a)
ω is nondegenerate.
(b)
The matrix (ωij) representing ω in terms of any basis is nonsingular.
(c)
The linear map eω : V →V ∗deﬁned by eω(X)(Y ) = ω(X, Y ) is invert-
ible.
A nondegenerate alternating 2-tensor is called a symplectic tensor. A vec-
tor space V endowed with a speciﬁc symplectic tensor is called a symplectic
vector space.
Example 9.15. Let V be a vector space of dimension 2n. Choose any basis
for V , and denote the basis by (A1, B1, . . . , An, Bn) and the corresponding
dual basis for V ∗by (α1, β1, . . . , αn, βn). Let ω ∈Λ2(V ) be the 2-covector
deﬁned by
ω =
n
X
i=1
αi ∧βi.
(9.13)
Note that the action of ω on basis vectors is given by
ω(Ai, Bj) = −ω(Bj, Ai) = δij,
ω(Ai, Aj) = ω(Bi, Bj) = 0.
(9.14)

220
9. Diﬀerential Forms
Suppose X = aiAi + biBi ∈V satisﬁes ω(X, Y ) = 0 for all Y ∈V . Then
0 = ω(X, Bi) = ai and 0 = ω(X, Ai) = −bi, which implies that X = 0.
Thus ω is nondegenerate.
It is useful to consider the special case in which dim V = 2. In this case,
every 2-covector is a multiple of α1 ∧β1, which is nondegenerate by the
argument above. Thus every nonzero 2-covector on a 2-dimensional vector
space is symplectic.
If (V, ω) is a symplectic vector space and S ⊂V is any subspace, we
deﬁne the symplectic complement of S, denoted by S⊥, to be the subspace
S⊥= {X ∈V : ω(X, Y ) = 0 for all Y ∈S}.
As the notation suggests, the symplectic complement is analogous to the
orthogonal complement in an inner product space. For example, just as in
the inner product case, the dimension of S⊥is the codimension of S, as
the next lemma shows.
Lemma 9.16. Let (V, ω) be a symplectic vector space. For any subspace
S ⊂V , dim S + dim S⊥= dim V .
Proof. If
(E1, . . . , Ek)
is
any
basis
for
S,
then
the
covectors
eω(E1), . . . , eω(Ek) ⊂V ∗are independent because eω is injective. Therefore,
the map Φ: V →Rk given by
Φ(X) = (eω(E1)(X), . . . , eω(Ek)(X))
is surjective, so S⊥= Ker Φ has dimension equal to dim V −dim Rk by the
rank-nullity law.
Symplectic complements diﬀer from orthogonal complements in one im-
portant respect: Although it is always true that S ∩S⊥= {0} in an inner
product space, this need not be true in a symplectic vector space. Indeed,
if S is 1-dimensional, the fact that ω is alternating forces ω(X, X) = 0 for
every X ∈S, so S ⊂S⊥. Carrying this idea a little further, subspaces of
V can be classiﬁed in the following way. A subspace S ⊂V is said to be
• symplectic if S ∩S⊥= {0};
• isotropic if S ⊂S⊥;
• coisotropic if S ⊃S⊥;
• Lagrangian if S = S⊥.
Exercise 9.7.
Let (V, ω) be a symplectic vector space, and let S ⊂V be
a subspace.
(a)
Show that (S⊥)⊥= S.

Symplectic Forms
221
(b)
Show that S is symplectic if and only if ω|S is nondegenerate.
(c)
Show that S is isotropic if and only if ω|S = 0.
(d)
Show that S is Lagrangian if and only if ω|S = 0 and dim S = n.
The symplectic tensor ω deﬁned in Example 9.15 turns out to be the
prototype of all symplectic tensors, as the next proposition shows. This
can be viewed as a symplectic version of the Gram-Schmidt algorithm.
Proposition 9.17 (Canonical Form for a Symplectic Tensor).
Let
ω be a symplectic tensor on an m-dimensional vector space V . Then V has
even dimension m = 2n, and there exists a basis for V in which ω has the
form (9.13).
Proof. It is easy to check that ω has the form (9.13) with respect to a basis
(A1, B1, . . . , An, Bn) if and only if the action of ω on basis vectors is given
by (9.14). Thus we will prove the theorem by induction on m = dim V , by
showing that there exists a basis of this form.
For m = 0 there is nothing to prove. Suppose (V, ω) is a symplectic
vector space of dimension m ≥1, and assume the proposition is true for all
symplectic vector spaces of dimension less than m. Let A1 be any nonzero
vector in V . Since ω is nondegenerate, there exists B1 ∈V such that
ω(A1, B1) ̸= 0. Multiplying B1 by a constant if necessary, we may assume
that ω(A1, B1) = 1. Because ω is alternating, B1 cannot be a multiple of
A1, so the set {A1, B1} is independent.
Let S ⊂V be the subspace spanned by {A1, B1}. Then dim S⊥= m −2
by Lemma 9.16. Since ω|S is obviously nondegenerate, by Exercise 9.7
it follows that S is symplectic. This means S ∩S⊥= {0}, so S⊥is
also symplectic. By induction S⊥is even-dimensional and there is a ba-
sis (A2, B2, . . . , An, Bn) for S⊥such that (9.14) is satisﬁed for 2 ≤i, j ≤n.
It follows easily that (A1, B1, A2, B2, . . . , An, Bn) is the required basis for
V .
Because of this proposition, if (V, ω) is a symplectic vector space, a basis
(A1, B1, . . . , An, Bn) for V is called a symplectic basis if (9.14) holds, which
is equivalent to ω being given by (9.13) in terms of the dual basis. The
proposition then says that every symplectic vector space has a symplectic
basis.
Now let us turn to manifolds. A symplectic form on a smooth manifold M
is a closed, nondegenerate 2-form. In other words, a 2-form ω is symplectic
if and only if it is closed and ωp is a symplectic tensor for each p ∈M. A
smooth manifold endowed with a speciﬁc choice of symplectic form is called
a symplectic manifold. A choice of symplectic form is also sometimes called
a symplectic structure on M. Proposition 9.17 implies that a symplectic
manifold must be even-dimensional. If (M, ω) and (f
M, eω) are symplectic
manifolds, a diﬀeomorphism F : M →f
M satisfying F ∗eω = ω is called a

222
9. Diﬀerential Forms
symplectomorphism. The study of properties of symplectic manifolds that
are invariant under symplectomorphisms is known as symplectic geometry.
Example 9.18 (Symplectic Manifolds).
(a) If we denote the standard coordinates on R2n by (x1, y1, . . . , xn, yn),
the 2-form
ω =
n
X
i=1
dxi ∧dyi
is symplectic: It is obviously closed, and its value at each point is
the standard symplectic tensor of Example 9.15. This is called the
standard symplectic structure (or standard symplectic form) on R2n.
(b) Suppose Σ is any smooth 2-manifold and Ωis any nonvanishing 2-
form on Σ. Then Ωis closed because dΩis a 3-form, and every 3-form
on a 2-manifold is zero. Moreover, as we observed above, every nonva-
nishing 2-form is nondegenerate, so (Σ, Ω) is a symplectic manifold.
Suppose (M, ω) is a symplectic manifold. An (immersed or embedded)
submanifold N ⊂M is said to be symplectic, isotropic, coisotropic, or
Lagrangian if TpN (thought of as a subspace of TpM) has this property
at each point p ∈N. More generally, an immersion F : N →M is said to
have one of these properties if the subspace F∗(TpN) ⊂TF (p)M has the
corresponding property for every p ∈N. Thus a submanifold is symplectic
(isotropic, etc.) if and only if its inclusion map has the same property.
Exercise 9.8.
Suppose (M, ω) is a symplectic manifold, and F : N →M
is an immersion. Show that F is isotropic if and only if F ∗ω = 0, and F is
symplectic if and only if F ∗ω is a symplectic form.
The most important example of a symplectic manifold is the total space
of the cotangent bundle of any smooth manifold M, which carries a canon-
ical symplectic structure that we now deﬁne. First, there is a natural 1-
form τ on the total space of T ∗M, called the tautologous 1-form, deﬁned
as follows. A point in T ∗M is a covector η ∈T ∗
p M for some p ∈M; we
will denote such a point by the notation (p, η). The natural projection
π: T ∗M →M is then just π(p, η) = p, and its pullback is a linear map
π∗: T ∗
p M →T(p,η)(T ∗M). We deﬁne τ ∈Λ1(T ∗M) by
τ(p,η) = π∗η.
In other words, the value of τ at (p, η) ∈T ∗M is the pullback with respect
to π of the covector η itself. If X is a tangent vector in T(p,η)(T ∗M), then
τ(p,η)(X) = η(π∗X).

Symplectic Forms
223
Proposition 9.19. Let M be a smooth manifold. The tautologous 1-form
τ is smooth, and ω = −dτ is a symplectic form on the total space of T ∗M.
Proof. Let (xi) be any coordinates on M, and let (xi, ξi) denote the corre-
sponding standard coordinates on T ∗M as deﬁned in Proposition 4.4. Re-
call that the coordinates of (p, η) ∈T ∗M are deﬁned to be (xi, ξi), where
(xi) is the coordinate representation of p and ξi dxi is the coordinate repre-
sentation of η. In terms of these coordinates, the projection π: T ∗M →M
has the coordinate expression π(x, ξ) = x, and therefore the coordinate
representation of τ is
τ(x,ξ) = π∗(ξi dxi) = ξi dxi.
It follows immediately that τ is smooth, because its component functions
are linear.
Clearly ω is closed, because it is exact. Moreover,
ω = −dτ =
X
i
dxi ∧dξi.
Under the identiﬁcation of an open subset of T ∗M with an open sub-
set of R2n by means of these coordinates, ω corresponds to the standard
symplectic form on R2n (with ξi substituted for yi). It follows that ω is
symplectic.
The symplectic structure deﬁned in this proposition is called the canoni-
cal symplectic structure on T ∗M. One of its many uses is in giving a some-
what more “geometric” picture of what it means for a 1-form to be closed,
as shown by the following proposition.
Proposition 9.20. Let M be a smooth manifold, and let σ be a 1-form on
M. Thought of as a smooth map from M to T ∗M, σ is an embedding, and
σ is closed if and only if its image σ(M) is a Lagrangian submanifold of
T ∗M.
Proof. Throughout this proof, we need to remember that σ is playing two
roles: On the one hand, it is a 1-form on M, and on the other hand, it is
a smooth map between manifolds. Since they are literally the same map,
we will not use diﬀerent notations to distinguish between them; but you
should be careful to think about which role σ is playing at each step of the
argument.
In terms of any local coordinates (xi) for M and the corresponding stan-
dard coordinates (xi, ξi) for T ∗M, the map σ: M →T ∗M has the coordi-
nate representation
σ(x1, . . . , xn) = (x1, . . . , xn, σ1(x), . . . , σn(x)),

224
9. Diﬀerential Forms
where σi dxi is the coordinate representation of σ as a 1-form. It follows
immediately that σ is an immersion, and the fact that it is injective follows
from π ◦σ = IdM.
To show that it is an embedding, it suﬃces by Proposition 5.4 to show
that it is a proper map. This follows easily from the fact that π◦σ = IdM: If
K ⊂T ∗M is a compact set, then σ−1(K) is a closed subset of the compact
set π(K), and so is compact.
Because σ(M) is n-dimensional, it is Lagrangian if and only if it is
isotropic, which is the case if and only if σ∗ω = 0. The pullback of the
tautologous form τ under σ is
σ∗τ = σ∗(ξi dxi) = σi dxi = σ.
This can also be seen somewhat more invariantly from the computation
(σ∗τ)p(X) = τσ(p)(σ∗X) = σp(π∗σ∗X) = σp(X),
which follows from the deﬁnition of τ and the fact that π ◦σ = IdM.
Therefore,
σ∗ω = −σ∗dτ = −d(σ∗τ) = −dσ.
It follows that σ is a Lagrangian embedding if and only if dσ = 0.

Problems
225
Problems
9-1. Let v1, . . . , vn be any n vectors in Rn, and let P be the n-dimensional
parallelepiped spanned by them:
P = {t1v1 + · · · + tnvn : 0 ≤ti ≤1}.
Show that Vol(P) = det(v1, . . . , vn).
9-2. Let (e1, e2, e3) be the standard dual basis for (R3)∗. Show that e1 ⊗
e2⊗e3 is not equal to a sum of an alternating tensor and a symmetric
tensor.
9-3. Show that covectors ω1, . . . , ωk on a ﬁnite-dimensional vector space
are linearly dependent if and only if ω1 ∧· · · ∧ωk = 0.
9-4. Show that two k-tuples {ω1, . . . , ωk} and {η1, . . . , ηk} of independent
covectors have the same span if and only if
ω1 ∧· · · ∧ωk = c η1 ∧· · · ∧ηk
for some nonzero real number c.
9-5. A k-covector η on a ﬁnite-dimensional vector space V is said to be
decomposable if it can be written
η = ω1 ∧· · · ∧ωk,
where ω1, . . . , ωk are covectors. Is every 2-covector on V decompos-
able? Your answer will depend on the dimension of V .
9-6. Deﬁne a 2-form Ωon R3 by
Ω= x dy ∧dz + y dz ∧dx + z dx ∧dy.
(a) Compute
Ω
in
spherical
coordinates
(ρ, ϕ, θ)
deﬁned
by
(x, y, z) = (sin ϕ cos θ, sin ϕ sin θ, cos ϕ).
(b) Compute dΩin both Cartesian and spherical coordinates and
verify that both expressions represent the same 3-form.
(c) Compute the restriction Ω|S2 = ι∗Ω, using coordinates (ϕ, θ), on
the open subset where these coordinates are deﬁned.
(d) Show that Ω|S2 is nowhere zero.
9-7. In each of the following problems, g: M →N is a smooth map be-
tween manifolds M and N, and ω is a diﬀerential form on N. In each
case, compute g∗ω and dω, and verify by direct computation that
g∗(dω) = d(g∗ω).

226
9. Diﬀerential Forms
(a) g: R2 →R2 by
(x, y) = g(s, t) = (st, et);
ω = x dy.
(b) g: {(r, θ) : r > 0} →R2 by
(x, y) = (r cos θ, r sin θ);
ω = dy ∧dx.
(c) g: R2 →R3 by
(x, y, z) = g(θ, ϕ) = ((cos ϕ + 2) cosθ, (cos ϕ + 2) sin θ, sin ϕ);
ω = y dz ∧dx.
(d) g: {(u, v) : u2 + v2 < 1} →R3 ∖{0} by
(x, y, z) = (u, v,
p
1 −u2 −v2);
ω = (x2 + y2 + z2)−3/2(x dy ∧dz + y dz ∧dx + z dx ∧dy).
(e) g: {(r, θ, ϕ) : r > 0} →R3 by
(x, y, z) = (r cos θ sin ϕ, r sin θ sin ϕ, r cos ϕ);
ω = x dy ∧dz + y dz ∧dx + z dx ∧dy.
9-8. Let V be a ﬁnite-dimensional real vector space. We have two ways
to think about the tensor space T k(V ): concretely, as the space of
k-multilinear functionals on V ; and abstractly, as the tensor product
space V ∗⊗· · · ⊗V ∗. However, we have deﬁned alternating and sym-
metric tensors only in terms of the concrete deﬁnition. This problem
outlines an abstract approach to alternating tensors.
Let A denote the subspace of V ∗⊗· · · ⊗V ∗spanned by all elements
of the form α ⊗ω ⊗ω ⊗β for covectors ω and arbitrary tensors α, β,
and let Ak(V ∗) denote the quotient vector space V ∗⊗· · · ⊗V ∗/A.
Deﬁne a wedge product on Ak(V ∗) by ω ∧η = π(eω ⊗eη), where
π: V ∗⊗· · · ⊗V ∗→Ak(V ∗) is the projection, and eω, eη are arbitrary
tensors such that π(eω) = ω, π(eη) = η. Show that this wedge product
is well deﬁned, and that there is a unique isomorphism F : Ak(V ∗) →
Λk(V ) such that the following diagram commutes:
Ak(V ∗)
Λk(V ),
-
F
V ∗⊗· · · ⊗V ∗
T k(V )
-
∼=
?
π
?
Alt

Problems
227
and show that F takes the wedge product we just deﬁned on Ak(V ∗)
to the Alt convention wedge product on Λk(V ). [This is one reason
why some authors consider the Alt convention for the wedge product
to be more natural than the determinant convention. It also explains
why some authors prefer the notation Λk(V ∗) instead of Λk(V ) for
the space of alternating covariant k-tensors, since it is a quotient of
the kth tensor product of V ∗with itself.]
9-9. Let (V, ω) be a symplectic vector space of dimension 2n, and let S ⊂V
be a subspace. Show that V has a symplectic basis (Ai, Bi) with the
following property:
(a) If S is symplectic, S = span(A1, B1, . . . , Ak, Bk) for some k.
(b) If S is isotropic, S = span(A1, . . . , Ak) for some k.
(c) If S is coisotropic, S = span(A1, . . . , An, B1, . . . , Bk) for some
k.
(d) If S is Lagrangian, S = span(A1, . . . , An).
9-10. Let M be a smooth manifold, and let N be an embedded submanifold
of the total space of T ∗M. Show that M is the image of a closed 1-
form on M if and only if N is Lagrangian and the projection map
π: T ∗M →M restricts to a diﬀeomorphism N →M.
9-11. Show that there is no 1-form σ on M such that the tautologous form
τ ∈Λ1(T ∗M) is equal to the pullback π∗σ.
9-12. Let (M, ω) and (f
M, eω) be symplectic manifolds. Deﬁne a 2-form Ω
on M × f
M by
Ω= π∗ω −eπ∗eω,
where π: M × f
M →M and eπ : M × f
M →f
M are the projections. For
a smooth map F : M →N, let Γ(F) ⊂M × f
M be the graph of F:
Γ(F) = {(x, y) ∈M × f
M : y = F(x)}.
Show that F is a symplectomorphism if and only if Γ(F) is a La-
grangian submanifold of (M × f
M, Ω).
9-13. The (real) symplectic group is the subgroup Sp(2n, R) ⊂GL(2n, R)
of matrices leaving the standard symplectic form ω = Pn
i=1 dxi ∧dyi
invariant, that is, the set of invertible linear maps A: R2n →R2n
such that A∗ω = ω.
(a) Show that a matrix A is in Sp(2n, R) if and only if it takes the
standard basis to a symplectic basis.

228
9. Diﬀerential Forms
(b) Show that A ∈Sp(2n, R) if and only if AT JA = J, where J is
given in block form as
J =
 0
In
−In
0

.
(c) Show that Sp(2n, R) is an embedded Lie subgroup of GL(2n, R),
and determine its dimension.
9-14. Let Λn ⊂G(n, 2n) denote the set of Lagrangian subspaces of R2n.
(a) Show that Sp(2n, R) acts transitively on Λn.
(b) Show that Λn has a unique smooth manifold structure such that
the action of Sp(2n, R) is smooth, and determine its dimension.

10
Integration on Manifolds
We introduced diﬀerential forms in the previous chapter with a promise
that they would turn out to be objects that can be integrated on manifolds
in a coordinate-independent way. In this chapter, we fulﬁll that promise by
deﬁning the integral of a diﬀerential n-form over a smooth n-manifold.
Before doing so, however, we need to address a serious issue that we have
so far swept under the rug. This is the small matter of the positive and
negative signs that arise when we try to interpret a k-form as a machine
for measuring k-dimensional volumes. In the previous chapter, we brushed
this aside by saying that the value of a k-form applied to k vectors has to
be interpreted as a “signed volume” of the parallelepiped spanned by the
vectors. These signs will cause problems, however, when we try to integrate
diﬀerential forms on manifolds, for the simple reason that the transforma-
tion law (9.9) for an n-form involves the determinant of the Jacobian, while
the change of variables formula for multiple integrals involves the absolute
value of the determinant. In the ﬁrst part of this chapter, we develop the
theory of orientations, which which is a systematic way to restrict to co-
ordinate transformations with positive determinant, thus eliminating the
sign problem.
Next we address the theory of integration. First we deﬁne the integral
of a diﬀerential form over a domain in Euclidean space, and then we show
how to use diﬀeomorphism invariance and partitions of unity to extend this
deﬁnition to the integral of a compactly supported k-form over an oriented
k-manifold. The key feature of the deﬁnition is that it is invariant under
orientation-preserving diﬀeomorphisms.

230
10. Integration on Manifolds
Next we prove one of the most fundamental theorems in all of diﬀerential
geometry. This is Stokes’s theorem, which is a generalization of the funda-
mental theorem of calculus, as well as of the three great classical theorems
of vector analysis: Green’s theorem for vector ﬁelds in the plane; the di-
vergence theorem for vector ﬁelds in space; and (the classical version of)
Stokes’s theorem for surface integrals in R3. We also describe an extension
of Stokes’s theorem to manifolds with corners, which will be useful in our
treatment of the de Rham theorem in Chapter 11.
In the last section of the chapter, we show how these ideas play out on a
Riemannian manifold. In particular, we prove Riemannian versions of the
divergence theorem and of Stokes’s theorem for surface integrals, of which
the classical theorems are special cases.
Orientations
The word “orientation” has some familiar meanings from our everyday ex-
perience, which can be interpreted as rules for singling out certain bases
of R1, R2, and R3. For example, most people would understand an “ori-
entation” of a line to mean a choice of preferred direction along the line,
so we might declare an oriented basis for R1 to be one that points to the
right (i.e., in the positive direction). A natural class of bases for R2 is the
ones for which the rotation from the ﬁrst vector to the second is in the
counterclockwise direction. And every student of vector calculus encoun-
ters “right-handed” bases in R3: These are the bases (E1, E2, E3) with the
property that when the ﬁngers of your right hand curl from E1 to E2, your
thumb points in the direction of E3.
Although “to the right,” “counterclockwise,” and “right-handed” are not
mathematical terms, it is easy to translate the rules for selecting oriented
bases of R1, R2, and R3 into rigorous mathematical terms: You can check
that in all three cases, the preferred bases are the ones whose transition
matrix from the standard basis has positive determinant.
In an abstract vector space for which there is no canonical basis, we no
longer have any way to determine which bases are “correctly oriented.” For
example, if V is the space of polynomials of degree at most 2, who is to
say which of the ordered bases (1, x, x2) or (x2, x, 1) is “right-handed”? All
we can say in general is what it means for two bases to have the “same
orientation.”
Thus we are led to introduce the following deﬁnition. Let V be a vector
space of dimension n ≥1. We say two ordered bases (E1, . . . , En) and
( eE1, . . . , eEn) are consistently oriented if the transition matrix (Bi
j), deﬁned
by
Ei = Bj
i eEj,
(10.1)

Orientations
231
has positive determinant.
Exercise 10.1.
Show that being consistently oriented is an equivalence
relation on the set of all ordered bases for V , and show that there are exactly
two equivalence classes.
If dim V = n ≥1, we deﬁne an orientation for V as an equivalence class
of ordered bases. If (E1, . . . , En) is any ordered basis for V , we denote the
orientation that it determines by [E1, . . . , En]. A vector space together with
a choice of orientation is called an oriented vector space. If V is oriented,
then any ordered basis (E1, . . . , En) that is in the given orientation is said
to be oriented or positively oriented. A basis that is not oriented is said to
be negatively oriented.
For the special case of a 0-dimensional vector space V , we deﬁne an
orientation of V to be simply a choice of one of the numbers ±1.
Example 10.1. The orientation [e1, . . . , en] of Rn determined by the stan-
dard basis is called the standard orientation. You should convince yourself
that, in our usual way of representing the axes graphically, an oriented ba-
sis for R is one that points to the right; an oriented basis for R2 is one for
which the rotation from the ﬁrst vector to the second is counterclockwise;
and an oriented basis for R3 is a right-handed one. (These can be taken
as mathematical deﬁnitions for the words “right,” “counterclockwise,” and
“right-handed.”) The standard orientation for R0 is deﬁned to be +1.
There is an important connection between orientations and alternating
tensors, expressed in the following lemma.
Lemma 10.2. Let V be a vector space of dimension n ≥1, and suppose Ω
is a nonzero element of Λn(V ). The set of ordered bases (E1, . . . , En) such
that Ω(E1, . . . , En) > 0 is an orientation for V .
Proof. Let OΩdenote the set of ordered bases on which Ωgives positive
values. We need to show that OΩis exactly one equivalence class.
Choose one basis (E1, . . . , En) such that Ω(E1, . . . , En) > 0. (Such a basis
can always be found by starting with an arbitrary basis and replacing E1 by
−E1 if necessary.) Let (ε1, . . . , εn) denote the dual basis. Since ε1 ∧· · ·∧εn
is a basis for Λn(V ), there is some (necessarily positive) number c such that
Ω= cε1 ∧· · · ∧εn.
Now if ( eE1, . . . , eEn) is any other basis, with transition matrix (Ai
j) de-
ﬁned by
eEj = Ai
jEi,
we have
Ω( eE1, . . . , eEn) = cε1 ∧· · · ∧εn( eE1, . . . , eEn)
= c det(εi( eEj))
= c det(Ai
j).

232
10. Integration on Manifolds
It follows that ( eEj) is consistently oriented with (Ei) if and only if
Ω( eE1, . . . , eEn) > 0, and therefore OΩ= [E1, . . . , En].
If V is an oriented vector space and Ωis an n-covector that determines
the orientation of V as described in this lemma, we say that Ωis an oriented
(or positively oriented) n-covector. For example, the n-covector e1 ∧· · ·∧en
is positively oriented for the standard orientation on Rn.
Orientations of Manifolds
Let M be a smooth manifold. We deﬁne a pointwise orientation on M to
be a choice of orientation of each tangent space. By itself, this is not a very
useful concept, because the orientations of nearby points may have no rela-
tion to each other. For example, a pointwise orientation on Rn might switch
randomly from point to point between the standard orientation and its op-
posite. In order for orientations to have some relationship with the smooth
structure, we need an extra condition to ensure that the orientations of
nearby tangent spaces are consistent with each other.
Suppose M is a smooth n-manifold with a given pointwise orientation.
Recall that a local frame for M is an n-tuple of smooth vector ﬁelds
(E1, . . . , En) on an open set U ⊂M such that (Ei|p) forms a basis for TpM
at each p ∈U. We say that a local frame (Ei) is (positively) oriented if
(E1|p, . . . , En|p) is a positively oriented basis for TpM at each point p ∈U.
A negatively oriented frame is deﬁned analogously.
A pointwise orientation is said to be continuous if every point is in the
domain of an oriented local frame. An orientation of M is a continuous
pointwise orientation. An oriented manifold is a smooth manifold together
with a choice of orientation. We say M is orientable if there exists an
orientation for it, and nonorientable if not.
If M is 0-dimensional, this deﬁnition just means that an orientation of
M is a choice of ±1 attached to each of its points. The local constancy
condition is vacuous in this case, and the notion of oriented frames is not
useful. Clearly every 0-manifold is orientable.
Exercise 10.2.
If M is an oriented manifold of dimension n ≥1, show
that every local frame with connected domain is either positively oriented
or negatively oriented.
The next two propositions give ways of specifying orientations on mani-
folds that are somewhat more practical to use than the deﬁnition. A smooth
coordinate chart (U, ϕ) is said to be (positively) oriented if the coordinate
frame (∂/∂xi) is positively oriented, and negatively oriented if the coordi-
nate frame is negatively oriented. A collection of charts {(Uα, ϕα)} is said
to be consistently oriented if for each α, β, the transition map ϕβ ◦ϕ−1
α
has
positive Jacobian determinant everywhere on ϕα(Uα ∩Uβ).

Orientations
233
Proposition 10.3. Let M be a smooth positive-dimensional manifold, and
suppose we are given an open cover of M by consistently oriented charts
{(Uα, ϕα)}. Then there is a unique orientation for M with the property that
each chart ϕα is oriented. Conversely, if M is oriented, then the collection
of all oriented charts is a consistently oriented cover of M.
Proof. For any p ∈M, the consistency condition means that the transition
matrix between the coordinate bases determined by any two of the charts
in the given collection has positive determinant. Thus the coordinate bases
for all of the given charts determine the same orientation on TpM. This
deﬁnes a pointwise orientation on M. Each point of M is in the domain of
at least one of the given charts, and the corresponding coordinate frame
is oriented by deﬁnition, so this pointwise orientation is continuous. The
converse is similar, and is left as an exercise.
Exercise 10.3.
Complete the proof of Proposition 10.3.
Proposition 10.4. Let M be a smooth manifold of dimension n ≥1. A
nonvanishing n-form Ω∈An(M) determines a unique orientation of M
for which Ωis positively oriented at each point. Conversely, if M is given
an orientation, then there is a nonvanishing n-form on M that is positively
oriented at each point.
Remark. Because of this proposition, any nonvanishing n-form on an n-
manifold is called an orientation form. If M is an oriented manifold and Ω
is an orientation form determining the given orientation, we also say that Ω
is (positively) oriented. It is easy to check that if Ωand eΩare two positively
oriented forms on the same orientated manifold M, then eΩ= fΩfor some
strictly positive smooth function f.
If M is a 0-manifold, the proposition remains true if we interpret an
orientation form as a nonvanishing function Ω, which assigns the orientation
+1 to points where Ω> 0 and −1 to points where Ω< 0.
Proof. Let Ωbe a nonvanishing n-form on M. Then Ωdeﬁnes a pointwise
orientation by Lemma 10.2, so all we need to check is that it is continuous.
Let (xi) be any local coordinates on a connected domain U ⊂M. Writing
Ω= f dx1 ∧· · · ∧dxn on U, the fact that Ωis nonvanishing means that f
is nonvanishing, and therefore
Ω
 ∂
∂x1 , . . . ,
∂
∂xn

= f ̸= 0
at all points of U. Since U is connected, it follows that this expression is
either always positive or always negative on U, and therefore the coordi-
nate chart is either positively oriented or negatively oriented. If negatively,
we can replace x1 by −x1 to obtain a new coordinate chart for which the

234
10. Integration on Manifolds
coordinate frame is positively oriented. Thus the pointwise orientation de-
termined by Ωis continuous.
Conversely, suppose M is oriented. Let {(Uα, ϕα)} be the collection of
all oriented charts for M. In each coordinate domain Uα, the n-form Ωα =
dx1 ∧· · · ∧dxn is positively oriented. Let {ψα} be a partition of unity
subordinate to the cover {Uα}, and deﬁne
Ω=
X
α
ψαΩα.
By the usual argument, Ωis a smooth n-form on M. To complete the proof,
we need to show that Ωnever vanishes.
Let p ∈M be arbitrary, and let (E1, . . . , En) be an oriented basis for
TpM. For each α such that p ∈Uα, we have Ωα|p(E1, . . . , En) > 0. Since
ψα(p) = 0 for all other α and there is at least one α for which ψα(p) > 0,
we have
Ωp(E1, . . . , En) =
X
{α:p∈Uα}
ψα(p)Ωα|p(E1, . . . , En) > 0,
Thus Ωp ̸= 0.
Exercise 10.4.
Show that any open subset of an orientable manifold is
orientable, and any product of orientable manifolds is orientable.
Recall that a smooth manifold is said to be parallelizable if it admits a
global frame.
Proposition 10.5. Every parallelizable manifold is orientable.
Proof. Suppose M is parallelizable, and let (E1, . . . , En) be a global frame
for M. Deﬁne a pointwise orientation by declaring (E1|p, . . . , En|p) to be
positively oriented at each p ∈M. This pointwise orientation is continuous,
because every point of M is in the domain of the (global) oriented frame
(Ei).
Example 10.6. The preceding proposition shows that Euclidean spaces
Rn, the n-torus Tn, the spheres S1 and S3, and products of them are all
orientable, because they are all parallelizable. Therefore any open subset
of one of these manifolds is also orientable.
Let M and N be oriented positive-dimensional manifolds, and let
F : M →N be a local diﬀeomorphism. We say F is orientation-preserving
if for each p ∈M, F∗takes oriented bases of TpM to oriented bases of
TF (p)N, and orientation-reversing if it takes oriented bases of TpM to neg-
atively oriented bases of TF (p)N.
Exercise 10.5.
Show that a smooth map F : M →N is orientation-
preserving if and only if its Jacobian matrix with respect to any oriented
coordinate charts for M and N has positive determinant, and orientation-
reversing if and only if it has negative determinant.

Orientations of Hypersurfaces
235
Orientations of Hypersurfaces
If M is an oriented manifold and N is a submanifold of M, N may not
inherit an orientation from M, even if N is embedded. Clearly it is not
suﬃcient to restrict an orientation form from M to N, since the restriction
of an n-form to a manifold of lower dimension must necessarily be zero. A
useful example to consider is the M¨obius band, which is not orientable (see
Problem 10-5), even though it can be embedded in R3.
In this section, we will restrict our attention to (immersed or embedded)
submanifolds of codimension 1, commonly called hypersurfaces. With one
extra piece of information (a certain kind of vector ﬁeld along the hyper-
surface), we can use an orientation on M to induce an orientation on any
hypersurface N ⊂M.
We start with some deﬁnitions. Let V be a ﬁnite-dimensional vector
space, and let X ∈V . We deﬁne a linear map iX : ΛkV →Λk−1V , called
interior multiplication or contraction with X, by
iXω(Y1, . . . , Yk−1) = ω(X, Y1, . . . , Yk−1).
In other words, iXω is obtained from ω by inserting X into the ﬁrst slot.
By convention, we interpret iXω to be zero when ω is a 0-covector (i.e., a
number). Another common notation is
X
ω = iXω.
Interior multiplication shares two important properties with exterior dif-
ferentiation: They are both antiderivations whose square is zero, as the
following lemma shows.
Lemma 10.7. Let V be a ﬁnite-dimensional vector space and X ∈V .
(a) iX ◦iX = 0.
(b) iX is an antiderivation: If ω is a k-covector and η is an l-covector,
iX(ω ∧η) = (iXω) ∧η + (−1)kω ∧(iXη).
Proof. On k-covectors for k ≥2, part (a) is immediate from the deﬁnition,
because any alternating tensor gives zero when two of its arguments are
identical. On 1-covectors and 0-covectors, it follows from the fact that iX ≡
0 on 0-covectors.
To prove (b), it suﬃces to consider the case in which both ω and η
are wedge products of covectors (such an alternating tensor is said to be
decomposable), since every alternating tensor can be written locally as a
linear combination of decomposable ones. It is easy to verify that (b) will
follow in this special case from the following general formula for covectors

236
10. Integration on Manifolds
ω1, . . . , ωk:
X
(ω1 ∧· · · ∧ωk) =
k
X
i=1
(−1)i−1ωi(X)ω1 ∧· · · ∧bωi ∧· · · ∧ωk,
(10.2)
where the hat indicates that ωi is omitted.
To prove (10.2), let us write X1 = X and apply both sides to vectors
(X2, . . . , Xk); then what we have to prove is
(ω1 ∧· · · ∧ωk)(X1, . . . , Xk)
=
k
X
i=1
(−1)i−1ωi(X1)(ω1 ∧· · · ∧bωi ∧· · · ∧ωk)(X2, . . . , Xk).
(10.3)
The left-hand side of (10.3) is the determinant of the matrix X whose
(i, j)-entry is ωi(Xj). To simplify the right-hand side, let Xi
j denote the
(k −1) × (k −1) minor of X obtained by deleting the ith row and jth
column. Then the right-hand side of (10.3) is
k
X
i=1
(−1)i−1ωi(X1) det Xi
1.
This is just the expansion of det X by minors along the ﬁrst column
(ω1(X1), . . . , ωk(X1)), and therefore is equal to det X.
It should be noted that when the wedge product is deﬁned using the Alt
convention, interior multiplication has to be deﬁned with an extra factor
of k:
iXω(Y1, . . . , Yk−1) = kω(X, Y1, . . . , Yk−1).
This deﬁnition ensures that interior multiplication iX is still an antideriva-
tion; the factor of k is needed to compensate for the diﬀerence between the
factors of 1/k! and 1/(k −1)! that occur when the left-hand and right-hand
sides of (10.3) are evaluated using the Alt convention.
On a smooth manifold M, interior multiplication extends naturally to
vector ﬁelds and diﬀerential forms, simply by letting iX act pointwise: if
X ∈T(M) and ω ∈Ak(M), deﬁne a (k −1)-form X
ω = iXω by
(X
ω)p = Xp
ωp.
Exercise 10.6.
If X is a smooth vector ﬁeld and ω is a diﬀerential form,
show that X
ω is smooth.
Now suppose M is a smooth manifold and S ⊂M is a hypersurface
(immersed or embedded). A vector ﬁeld along S is a continuous map

Orientations of Hypersurfaces
237
N : S →TM with the property that Np ∈TpM for each p ∈S. (Note
the diﬀerence between this and a vector ﬁeld on S, which would have the
property that Np ∈TpS at each point.) A vector Np ∈TpM is said to
be transverse (to S) if TpM is spanned by Np and TpS for each p ∈S.
Similarly, a vector ﬁeld N along S is transverse if Np is transverse at each
p ∈S.
For example, any smooth vector ﬁeld on M restricts to a smooth vector
ﬁeld along S; it is transverse if and only if it is nowhere tangent to S.
Proposition 10.8. Suppose M is an oriented smooth n-manifold, S is
an immersed hypersurface in M, and N is a smooth transverse vec-
tor ﬁeld along S. Then S has a unique orientation with the prop-
erty that (E1, . . . , En−1) is an oriented basis for TpS if and only if
(Np, E1, . . . , En−1) is an oriented basis for TpM. If Ωis an orientation
form for M, then (N
Ω)|S is an orientation form for S with respect to
this orientation.
Remark. When n = 1, since S is a 0-manifold, this proposition should be
interpreted as follows: At each point p ∈S, we assign the orientation +1 to
p if Np is an oriented basis for TpM, and −1 if Np is negatively oriented.
With this understanding, the proof below goes through in this case without
modiﬁcation.
Proof. Let Ωbe a smooth orientation form for M. Then ω = (N
Ω)|S is
a smooth (n −1)-form on S. It will be an orientation form for S if we can
show that it never vanishes. Given any basis (E1, . . . , En−1) for TpS, the
fact that N is transverse to S implies that (Np, E1, . . . , En−1) is a basis for
TpM. The fact that Ωis nonvanishing implies that
ωp(E1, . . . , En−1) = Ωp(Np, E1, . . . , En−1) ̸= 0.
Since ωp(E1, . . . , En−1) > 0 if and only if Ωp(Np, E1, . . . , En) > 0, the
orientation determined by ω is the one deﬁned in the statement of the
proposition.
Example 10.9. Considering Sn as a hypersurface in Rn+1, the vector ﬁeld
N = xi∂/∂xi along Sn is easily seen to be transverse. (In fact, this vector
ﬁeld is orthogonal to Sn with respect to the Euclidean metric.) Thus it
induces an orientation on Sn. This shows that all spheres are orientable.
(The orientation on S0 given by this construction is the one that assigns
the orientation +1 to the point +1 ∈S0 and −1 to −1 ∈S0.)
Manifolds with Boundary
An important application of this construction is to deﬁne a canonical ori-
entation on the boundary of any oriented manifold with boundary. First,
we note that an orientation of a smooth manifold with boundary can be

238
10. Integration on Manifolds
deﬁned exactly as in the case of a smooth manifold, with “chart” replaced
by “generalized chart” as necessary.
One situation that arises frequently is the following. If M is a smooth n-
manifold, a compact, embedded n-dimensional submanifold with boundary
D ⊂M is called a regular domain in M. An orientation on M immediately
yields an orientation on D, for example by restricting an orientation n-
form to D. Examples are the closed unit ball in Rn and the closed upper
hemisphere in Sn, each of which inherits an orientation from its containing
manifold.
If M is a smooth manifold with boundary, ∂M is easily seen to be an
embedded hypersurface in M. Recall that any point p ∈M is in the domain
of a generalized chart (U, ϕ), which means that ϕ is a diﬀeomorphism from
U onto an open subset eU ⊂Hn. Since ∂M is locally characterized by
xn = 0 in such charts, generalized charts play a role for ∂M analogous to
slice charts for ordinary embedded submanifolds.
Let p ∈∂M. A vector N ∈TpM is said to be inward-pointing if N /∈
Tp∂M and for some ε > 0 there exists a smooth curve segment γ : [0, ε] →
M such that γ(0) = p and γ′(0) = N. It is said to be outward-pointing if
−N is inward-pointing. The following lemma gives another characterization
of inward-pointing vectors, which is usually much easier to check.
Lemma 10.10. Suppose M is a smooth manifold with boundary and p ∈
∂M. A vector N ∈TpM is inward-pointing if and only if N has strictly
positive xn-component in every generalized chart (x1, . . . , xn).
Exercise 10.7.
Prove Lemma 10.10.
A vector ﬁeld along ∂M (deﬁned just as for ordinary hypersurfaces) is
said to be inward-pointing or outward-pointing if its value at each point
has that property.
Lemma 10.11. If M is any smooth manifold with boundary, there is a
smooth outward-pointing vector ﬁeld along ∂M.
Proof. Cover a neighborhood of ∂M by generalized coordinate charts
{(Uα, ϕα)}. In each such chart Uα, Nα = −∂/∂xn|∂M∩Uα is a smooth
vector ﬁeld along ∂M ∩Uα, which is outward-pointing by Lemma 10.10.
Let {ψα} be a partition of unity subordinate to the cover {Uα ∩∂M} of
∂M, and deﬁne a global vector ﬁeld N along ∂M by
N =
X
α
ψαNα.
Clearly N is a smooth vector ﬁeld along ∂M. To show that it is outward-
pointing, let (y1, . . . , yn) be any generalized coordinates in a neighborhood
of p ∈∂M. Because each Nα is outward-pointing, it satisﬁes dyn(Nα) < 0.

Orientations of Hypersurfaces
239
Therefore, the yn-component of N at p satisﬁes
dyn(Np) =
X
α
ψα(p)dyn(Nα|p).
This sum is strictly negative, because each term is nonpositive and at least
one term is negative.
Proposition 10.12 (The Induced Orientation on a Boundary).
Let M be an oriented smooth manifold with boundary. The orientation
on ∂M determined by any outward-pointing vector ﬁeld along ∂M is
independent of the choice of vector ﬁeld.
Remark. As a consequence of this proposition, there is a unique orientation
on ∂M determined by the orientation of M. We call this orientation the
induced orientation or the Stokes orientation on ∂M. (The second term is
chosen because of the role this orientation will play in Stokes’s theorem, to
be described later in this chapter.)
Proof. Let Ωbe an orientation form for M, and let (x1, . . . , xn) be general-
ized coordinates for M in a neighborhood of p ∈M. Replacing x1 by −x1
if necessary, we may assume they are oriented coordinates, which implies
that Ω= f dx1 ∧· · · ∧dxn (locally) for some strictly positive function f.
Suppose N is an outward-pointing vector ﬁeld along ∂M. The orientation
of ∂M determined by N is given by the orientation form (N
Ω)|∂M.
Because xn = 0 along ∂M, the restriction dxn|∂M is equal to zero (Prob-
lem 5-16). Therefore, using the antiderivation property of iN,
(N
Ω)|∂M = f
n
X
i=1
(−1)i−1dxi(N)dxi|∂M ∧· · · ∧c
dxi|∂M ∧· · · ∧dxn|∂M
= (−1)n−1fdxn(N)dxi|∂M ∧· · · ∧dxn−1|∂M.
Because dxn(N) = N n < 0, this is a positive multiple of (−1)ndxi|∂M ∧
· · · ∧dxn−1|∂M. If e
N is any other outward-pointing vector ﬁeld, the same
computation shows that ( e
N
Ω)|∂M is a positive multiple of the same
(n −1)-form, and thus a positive multiple of (N
Ω)|∂M. This proves that
N and e
N determine the same orientation on ∂M.
Example 10.13. This proposition gives a simpler proof that Sn is ori-
entable, because it is the boundary of the closed unit ball.
Example 10.14. Let us determine the induced orientation on ∂Hn when
Hn itself has the standard orientation inherited from Rn. We can identify
∂Hn with Rn under the correspondence (x1, . . . , xn−1, 0) ↔(x1, . . . , xn−1).
Since the vector ﬁeld −∂/∂xn is outward-pointing along ∂Hn, the stan-
dard coordinate frame for Rn−1 is positively oriented for ∂Hn if and only

240
10. Integration on Manifolds
if [−∂/∂xn, ∂/∂x1, . . . , ∂/∂xn−1] is the standard orientation for Rn. This
orientation satisﬁes
[−∂/∂xn, ∂/∂x1, . . . , ∂/∂xn−1] = −[∂/∂xn, ∂/∂x1, . . . , ∂/∂xn−1]
= (−1)n[∂/∂x1, . . . , ∂/∂xn−1, ∂/∂xn].
Thus the induced orientation on ∂Hn is equal to the standard orientation
on Rn−1 when n is even, but it is opposite to the standard orientation
when n is odd. In particular, the standard coordinates on ∂Hn ≈Rn−1 are
positively oriented if and only if n is even. (This fact will play an important
role in the proof of Stokes’s theorem below.)
Integration of Diﬀerential Forms
In this section, we will deﬁne in an invariant way the integrals of diﬀerential
forms over manifolds. You should be sure you are familiar with the basic
properties of multiple integrals in Rn, as summarized in the Appendix.
We begin by considering diﬀerential forms on subsets of Rn. For the time
being, let us restrict attention to the case n ≥1. Let D ⊂Rn be a compact
domain of integration, and let ω be a smooth n-form on D. (Remember,
this means that ω has a smooth extension to some open set containing D.)
Any such form can be written as
ω = f dx1 ∧· · · ∧dxn
for a function f ∈C∞(D). We deﬁne the integral of ω over D to be
Z
D
ω =
Z
D
f dV.
This can be written more suggestively as
Z
D
f dx1 ∧· · · ∧dxn =
Z
D
f dx1 · · · dxn.
In simple terms, to compute the integral of a form such as f dx1 ∧· · ·∧dxn,
we just “erase the wedges”!
Somewhat more generally, let U be an open set in Rn. We would like to
deﬁne the integral of any compactly supported n-form ω over U. However,
since neither U nor supp ω may be a domain of integration in general, we
need the following lemma.
Lemma 10.15. Suppose K ⊂U ⊂Rn, where U is an open set and K
is compact. Then there is a compact domain of integration D such that
K ⊂D ⊂U.

Integration of Diﬀerential Forms
241
Proof. For each p ∈K, there is an open ball containing p whose closure is
contained in U. By compactness, ﬁnitely many such open balls U1, . . . , Um
cover K. Since the boundary of an open ball is a codimension-1 submani-
fold, it has measure zero by Theorem 6.6, and so each ball is a domain of
integration. The set D = U 1 ∪· · · ∪U m is the required domain of integra-
tion.
Now if U ⊂Rn is open and ω is a compactly supported n-form on U, we
deﬁne
Z
U
ω =
Z
D
ω,
where D is any domain of integration such that supp ω ⊂D ⊂U. It is an
easy matter to verify that this deﬁnition does not depend on the choice of
D. Similarly, if V is an open subset of the upper half-space Hn and ω is a
compactly supported n-form on V , we deﬁne
Z
V
ω =
Z
D∩Hn ω,
where D is chosen in the same way.
It is worth remarking that it is possible to extend the deﬁnition to inte-
grals of noncompactly supported forms, and integrals of such forms play an
important role in many applications. However, in such cases the resulting
multiple integrals are improper, so one must pay close attention to conver-
gence issues. For the purposes we have in mind, the compactly supported
case will be more than suﬃcient.
The motivation for this deﬁnition is expressed in the following proposi-
tion.
Proposition 10.16. Let D and E be domains of integration in Rn, and let
ω be an n-form on E. If G: D →E is a smooth map whose restriction to
Int D is an orientation-preserving or orientation-reversing diﬀeomorphism
onto Int E, then
Z
E
ω =









Z
D
G∗ω
if G is orientation-preserving,
−
Z
D
G∗ω
if G is orientation-reversing.
Proof. Let us use (y1, . . . , yn) to denote standard coordinates on E, and
(x1, . . . , xn) to denote those on D. Suppose ﬁrst that G is orientation-
preserving. Writing ω = f dy1 ∧· · · ∧dyn, the change of variables formula

242
10. Integration on Manifolds
together with the formula of Lemma 9.11 for pullbacks of n-forms yield
Z
E
ω =
Z
E
f dV
=
Z
D
(f ◦G)
det
∂Gi
∂xj
 dV
=
Z
D
(f ◦G) det
∂Gi
∂xj

dV
=
Z
D
(f ◦G) det
∂Gi
∂xj

dx1 ∧· · · ∧dxn
=
Z
D
G∗ω.
If G is orientation-reversing, the same computation holds except that a
negative sign is introduced when the absolute value signs are removed.
Corollary 10.17. Suppose U, V are open subsets of Rn, G: U →V is
an orientation-preserving diﬀeomorphism, and ω is a compactly supported
n-form on V . Then
Z
V
ω =
Z
U
G∗ω.
Proof. Let E ⊂V be a domain of integration containing supp ω. Since
smooth maps take sets of measure zero to sets of measure zero, D =
G−1(E) ⊂U is a domain of integration containing supp G∗ω. Therefore,
the result follows from the preceding proposition.
Using this result, it is easy to make invariant sense of the integral of a
diﬀerential form over an oriented manifold. Let M be a smooth, oriented
n-manifold and ω an n-form on M. Suppose ﬁrst that ω is compactly
supported in the domain of a single oriented coordinate chart (U, ϕ). We
deﬁne the integral of ω over M to be
Z
M
ω =
Z
ϕ(U)
(ϕ−1)∗ω.
Since (ϕ−1)∗ω is a compactly supported n-form on the open subset ϕ(U) ⊂
Rn, its integral is deﬁned as discussed above.
Proposition 10.18. With ω as above,
R
M ω does not depend on the choice
of oriented coordinate chart whose domain contains supp ω.
Proof. Suppose (eU, eϕ) is another oriented chart such that supp ω ⊂eU.
Because eϕ◦ϕ−1 is an orientation-preserving diﬀeomorphism from ϕ(U ∩eU)

Integration of Diﬀerential Forms
243
to eϕ(U ∩eU), Corollary 10.17 implies that
Z
eϕ( e
U)
(eϕ−1)∗ω =
Z
e
ϕ(U∩e
U)
(eϕ−1)∗ω
=
Z
ϕ(U∩e
U)
(eϕ ◦ϕ−1)∗(eϕ−1)∗ω
=
Z
ϕ(U∩e
U)
(ϕ−1)∗(eϕ)∗(eϕ−1)∗ω
=
Z
ϕ(U)
(ϕ−1)∗ω.
Thus the two deﬁnitions of R
M ω agree.
If M is an oriented smooth n-manifold with boundary, and ω is an n-form
on M that is compactly supported in the domain of a generalized chart,
the deﬁnition of
R
M ω and the statement and proof of Proposition 10.18
go through unchanged, provided we interpret all the coordinate charts as
generalized charts, and compute the integrals over open subsets of Hn in
the way we described above.
To integrate over an entire manifold, we simply apply this same deﬁnition
together with a partition of unity. Suppose M is an oriented smooth n-
manifold (possibly with boundary) and ω is a compactly supported n-form
on M. Let {(Ui, ϕi)} be a ﬁnite cover of supp ω by oriented coordinate
charts (generalized charts if M has a nonempty boundary), and let {ψi}
be a subordinate partition of unity. We deﬁne the integral of ω over M to
be
Z
M
ω =
X
i
Z
M
ψiω.
(10.4)
Since for each i, the n-form ψiω is compactly supported in Ui, each of
the terms in this sum is well-deﬁned according to our discussion above. To
show that the integral is well-deﬁned, therefore, we need only examine the
dependence on the charts and the partition of unity.
Lemma 10.19. The deﬁnition of
R
M ω given above does not depend on the
choice of oriented charts or partition of unity.
Proof. Suppose {(eUj, eϕj)} is another ﬁnite collection of oriented charts
whose domains cover supp ω, and { eψj} is a subordinate partition of unity.
For each i, we compute
Z
M
ψiω =
Z
M
 X
j
eψj

ψiω
=
X
j
Z
M
eψjψiω.

244
10. Integration on Manifolds
Summing over i, we obtain
X
i
Z
M
ψiω =
X
i,j
Z
M
eψjψiω.
Observe that each term in this last sum is the integral of a form compactly
supported in a single (generalized) chart (Ui, for example), so by Proposi-
tion 10.18 each term is well-deﬁned, regardless of which coordinate map we
use to compute it. The same argument, starting with
R
M eψjω, shows that
X
j
Z
M
eψjω =
X
i,j
Z
M
eψjψiω.
Thus both deﬁnitions yield the same value for
R
M ω.
As usual, we have a special deﬁnition in the 0-dimensional case. The
integral of a compactly supported 0-form (i.e., a function) f over an oriented
0-manifold M is deﬁned to be the sum
Z
M
f =
X
p∈M
±f(p),
where we take the positive sign at points where the orientation is positive
and the negative sign at points where it is negative. The assumption that
f is compactly supported implies that there are only ﬁnitely many nonzero
terms in this sum.
If N ⊂M is an oriented immersed k-dimensional submanifold (with or
without boundary), and ω is a k-form on M, we interpret
R
N ω to mean
R
N(ω|N). In particular, if M is a compact oriented manifold with boundary,
then ∂M is a compact embedded (n −1)-manifold (without boundary).
Thus if ω is an (n −1)-form on M, we can interpret
R
∂M ω unambiguously
as the integral of ω|∂M over ∂M, where ∂M is always understood to have
the induced orientation.
Proposition 10.20 (Properties of Integrals of Forms).
Suppose M
and N are oriented smooth n-manifolds with or without boundaries, and
ω, η are compactly supported n-forms on M.
(a) Linearity: If a, b ∈R, then
Z
M
aω + bη = a
Z
M
ω + b
Z
M
η.
(b) Orientation Reversal: If M denotes M with the opposite orien-
tation, then
Z
M
ω = −
Z
M
ω.

Integration of Diﬀerential Forms
245
(c) Positivity: If ω is an orientation form for M, then
R
M ω > 0.
(d) Diffeomorphism Invariance: If F : N →M is an orientation-
preserving diﬀeomorphism, then
R
M ω =
R
N F ∗ω.
Proof. Parts (a) and (b) are left as an exercise. Suppose that ω is an orien-
tation form for M. This means that for any oriented chart (U, ϕ), (ϕ∗)−1ω
is a positive function times dx1∧· · ·∧dxn. Thus each term in the sum (10.4)
deﬁning R
M ω is nonnegative, and at least one term is strictly positive, thus
proving (c).
To prove (d), it suﬃces to assume that ω is compactly supported in a
single coordinate chart, because any n-form on M can be written as a ﬁnite
sum of such forms by means of a partition of unity. Thus suppose (U, ϕ)
is an oriented coordinate chart on M whose domain contains the support
of ω. It is easy to check that (F −1(U), ϕ ◦F) is an oriented coordinate
chart on N whose domain contains the support of F ∗ω, and the result then
follows immediately from Corollary 10.17.
Exercise 10.8.
Prove parts (a) and (b) of the preceding proposition.
Although the deﬁnition of the integral of a form based on partitions
of unity is very convenient for theoretical purposes, it is useless for doing
actual computations. It is generally quite diﬃcult to write down a partition
of unity explicitly, and even when one can be written down, one would
have to be exceptionally lucky to be able to compute the resulting integrals
(think of trying to integrate e−1/x). For computational purposes, it is much
more convenient to “chop up” the manifold into a ﬁnite number of pieces
whose boundaries are sets of measure zero, and compute the integral on
each one separately. One way to do this is described below.
A subset D ⊂M is called a domain of integration if D is compact and ∂D
has measure zero (in the sense described in Chapter 6). For example, any
regular domain (i.e., compact embedded n-submanifold with boundary) in
an n-manifold is a domain of integration.
Proposition 10.21. Let M be a compact, oriented, smooth n-manifold
with or without boundary, and let ω be an n-form on M. Suppose E1, . . . , Ek
are compact domains of integration in M; D1, . . . , Dk are compact domains
of integration in Rn; and for i = 1, . . . , k, Fi : Di →M are smooth maps
satisfying
(i) Fi(Di) = Ei, and Fi|Int Di is an orientation-preserving diﬀeomor-
phism from Int Di onto Int Ei.
(ii) M = E1 ∪· · · ∪Ek.
(iii) For each i ̸= j, Ei and Ej intersect only on their boundaries.

246
10. Integration on Manifolds
Then
Z
M
ω =
X
i
Z
Di
F ∗
i ω.
Proof. As in the preceding proof, it suﬃces to assume that ω is compactly
supported in the domain of a single oriented chart (U, ϕ). In fact, by starting
with a cover of M by suﬃciently nice charts, we may assume that ∂U has
measure zero, and that ϕ extends to a diﬀeomorphism from U to a compact
domain of integration K ⊂Hn.
For each i, let
Ai = U ∩Ei ⊂M.
Then Ai is a compact subset of M whose boundary has measure zero, since
∂Ai ⊂∂U ∪Fi(∂Di). Deﬁne compact subsets Bi, Ci ⊂Rn by
Bi = F −1
i
(Ai),
Ci = ϕ(Ai).
Since smooth maps take sets of measure zero to sets of measure zero, both
Bi and Ci are domains of integration, and ϕ ◦Fi maps Bi to Ci and re-
stricts to a diﬀeomorphism from Int Bi to Int Ci. Therefore Proposition
10.16 implies that
Z
Ci
(ϕ−1)∗ω =
Z
Bi
F ∗
i ω.
Summing over i, and noting that the interiors of the various sets Ai are
disjoint, we obtain
Z
M
ω =
Z
K
(ϕ−1)∗ω
=
X
i
Z
Ci
(ϕ−1)∗ω
=
X
i
Z
Bi
F ∗
i ω
=
X
i
Z
Di
F ∗
i ω.
Example 10.22. Let us use this technique to compute the integral of a
2-form over S2, oriented by means of the outward-pointing vector ﬁeld
N = x ∂/∂x + y ∂/∂y + z ∂/∂z. Let ω be the following 2-form:
ω = x dy ∧dz + y dz ∧dx + z dx ∧dy.

Integration of Diﬀerential Forms
247
If we let D be the rectangle [0, π] × [0, 2π] and F : D →S2 be the spherical
coordinate map
F(ϕ, θ) = (sin ϕ cos θ, sin ϕ sin θ, cos ϕ),
then the single map F : D →S2 satisﬁes the hypotheses of Proposition
10.21, provided that it is orientation-preserving. Assuming this for the mo-
ment, we note that
F ∗dx = cos ϕ cos θ dϕ −sin ϕ sin θ dθ,
F ∗dy = cos ϕ sin θ dϕ + sin ϕ cos θ dθ,
F ∗dz = −sin ϕ dϕ.
Therefore,
Z
S2 ω =
Z
D
F ∗ω
=
Z
D
−sin3 ϕ cos2 θ dθ ∧dϕ + sin3 ϕ sin2 θ dϕ ∧dθ
+ cos2 ϕ sin ϕ cos2 θ dϕ ∧dθ −cos2 ϕ sin ϕ sin2 θ dθ ∧dϕ
=
Z
D
sin ϕ dϕ ∧dθ
=
Z 2π
0
Z π
0
sin ϕ dϕ dθ
= 4π.
To check that F
is orientation-preserving, we need to show that
(F∗∂/∂ϕ, F∗∂/∂θ) is an oriented basis for S2 at each point, which means by
deﬁnition that (N, F∗∂/∂ϕ, F∗∂/∂θ) is an oriented basis for R3. Calculating
at an arbitrary point (x, y, z) = F(ϕ, θ), we ﬁnd
N = sin ϕ cos θ ∂
∂x + sin ϕ sin θ ∂
∂y + cos ϕ ∂
∂z ;
F∗
∂
∂ϕ = cos ϕ cos θ ∂
∂x + cos ϕ sin θ ∂
∂y −sin ϕ ∂
∂z ;
F∗
∂
∂θ = −sin ϕ sin θ ∂
∂x + sin ϕ cos θ ∂
∂y.
The transition matrix is therefore


sin ϕ cos θ
sin ϕ sin θ
cos ϕ
cos ϕ cos θ
cos ϕ sin θ
−sin ϕ
−sin ϕ sin θ
sin ϕ cos θ
0

,
which has determinant sin ϕ > 0.

248
10. Integration on Manifolds
Stokes’s Theorem
In this section we will state and prove the central result in the theory of
integration on manifolds: Stokes’s theorem for manifolds. This is a far-
reaching generalization of the fundamental theorem of calculus and of the
classical theorems of vector calculus.
Theorem 10.23 (Stokes’s Theorem).
Let
M
be
an
oriented
n-
dimensional manifold with boundary, and let ω be a compactly supported
(n −1)-form on M. Then
Z
M
dω =
Z
∂M
ω.
(10.5)
The statement of this theorem is concise and elegant, but it requires a
bit of interpretation. First, as usual, ∂M is understood to have the induced
(Stokes) orientation, and ω is understood to be restricted to ∂M on the
right-hand side. If ∂M = ∅, then the right-hand side is to be interpreted
as zero. When M is 1-dimensional, the right-hand integral is really just a
ﬁnite sum.
With these understandings, we proceed with the proof of the theorem.
You should check as you read through the proof that it works correctly
when n = 1.
Proof. We begin by considering a very special case: Suppose M is the upper
half space Hn itself. Then the fact that ω has compact support means that
there is a number R > 0 such that supp ω is contained in the rectangle
A = [−R, R]×· · ·×[−R, R]×[0, R]. We can write ω in standard coordinates
as
ω =
n
X
i=1
ωi dx1 ∧· · · ∧c
dxi ∧· · · ∧dxn,
where the hat means that dxi is omitted. Therefore,
dω =
n
X
i=1
dωi ∧dx1 ∧· · · ∧c
dxi ∧· · · ∧dxn
=
n
X
i,j=1
∂ωi
∂xj dxj ∧dx1 ∧· · · ∧c
dxi ∧· · · ∧dxn
=
n
X
i=1
(−1)i−1 ∂ωi
∂xi dx1 ∧· · · ∧dxn.

Stokes’s Theorem
249
Thus we compute
Z
Hn dω =
n
X
i=1
(−1)i−1
Z
A
∂ωi
∂xi dx1 ∧· · · ∧dxn
=
n
X
i=1
(−1)i−1
Z R
0
Z R
−R
· · ·
Z R
−R
∂ωi
∂xi (x)dx1 · · · dxn.
We can rearrange the order of integration in each term so as to do the
xi integration ﬁrst. By the fundamental theorem of calculus, the terms for
which i ̸= n reduce to
n−1
X
i=1
(−1)i−1
Z R
0
Z R
−R
· · ·
Z R
−R
∂ωi
∂xi (x)dx1 · · · dxn
=
n−1
X
i=1
(−1)i−1
Z R
0
Z R
−R
· · ·
Z R
−R
∂ωi
∂xi (x)dxi dx1 · · · c
dxi · · · dxn
=
n−1
X
i=1
(−1)i−1
Z R
0
Z R
−R
· · ·
Z R
−R
ωi(x)

xi=R
xi=−R
dx1 · · · c
dxi · · · dxn
= 0,
because we have chosen R large enough that ω = 0 when xi = ±R. The
only term that might not be zero is the one for which i = n. For that term
we have
Z
Hn dω = (−1)n−1
Z R
−R
· · ·
Z R
−R
Z R
0
∂ωn
∂xn (x)dxn dx1 · · · dxn−1
= (−1)n−1
Z R
−R
· · ·
Z R
−R
ωi(x)

xn=R
xn=0
dx1 · · · dxn−1
= (−1)n
Z R
−R
· · ·
Z R
−R
ωi(x1, . . . , xn−1, 0) dx1 · · · dxn−1,
(10.6)
because ωn = 0 when xn = R.
To compare this to the other side of (10.5), we compute as follows:
Z
∂Hn ω =
X
i
Z
A∩∂Hn ωi(x1, . . . , xn−1, 0) dx1 ∧· · · ∧c
dxi ∧· · · ∧dxn.
Because xn vanishes on ∂Hn, the restriction of dxn to the boundary is
identically zero. Thus the only term above that is nonzero is the one for
which i = n, which becomes
Z
∂Hn ω =
Z
A∩∂Hn ωn(x1, . . . , xn−1, 0) dx1 ∧· · · ∧dxn−1.

250
10. Integration on Manifolds
Taking into account the fact that the coordinates (x1, . . . , xn−1) are posi-
tively oriented for ∂Hn when n is even and negatively oriented when n is
odd (Example 10.14), this becomes
Z
∂Hn ω = (−1)n
Z R
−R
· · ·
Z R
−R
ωn(x1, . . . , xn−1, 0) dx1 · · · dxn−1,
which is equal to (10.6).
Next let M be an arbitrary manifold with boundary, but consider an
(n −1)-form ω that is compactly supported in the domain of a single (gen-
eralized) chart (U, ϕ). Assuming without loss of generality that ϕ is an
oriented chart, the deﬁnition yields
Z
M
dω =
Z
Hn(ϕ−1)∗dω =
Z
Hn d((ϕ−1)∗ω),
since (ϕ−1)∗dω is compactly supported on Hn. By the computation above,
this is equal to
Z
∂Hn(ϕ−1)∗ω,
(10.7)
where ∂Hn is given the induced orientation. Since ϕ∗takes outward-
pointing vectors on ∂M to outward-pointing vectors on Hn (by Lemma
10.10), it follows that ϕ|U∩∂M is an orientation-preserving diﬀeomorphism
onto ϕ(U)∩∂Hn, and thus (10.7) is equal to
R
∂M ω. This proves the theorem
in this case.
Finally, let ω be an arbitrary compactly supported (n−1)-form. Choosing
a cover of supp ω by ﬁnitely many oriented (generalized) coordinate charts
{(Ui, ϕi)}, and choosing a subordinate partition of unity {ψi}, we can apply
the preceding argument to ψiω for each i and obtain
Z
∂M
ω =
X
i
Z
∂M
ψiω
=
X
i
Z
M
d(ψiω)
=
X
i
Z
M
dψi ∧ω + ψidω
=
Z
M
d
 X
i
ψi

∧ω +
Z
M
 X
i
ψi

dω
= 0 +
Z
M
dω,
because P
i ψi ≡1.

Manifolds with Corners
251
Two special cases of Stokes’s theorem are worthy of special note. The
proofs are immediate.
Corollary 10.24. Suppose M is a compact manifold without boundary.
Then the integral of every exact form over M is zero:
Z
M
dω = 0
if ∂M = ∅.
Corollary 10.25. Suppose M is a compact smooth manifold with bound-
ary. If ω is a closed form on M, then the integral of ω over ∂M is zero:
Z
∂M
ω = 0
if dω = 0 on M.
Example 10.26. Let N be a smooth manifold and suppose γ : [a, b] →N
is an embedding, so that M = γ[a, b] is an embedded 1-submanifold with
boundary in N. If we give M the orientation such that γ is orientation-
preserving, then for any smooth function f ∈C∞(N), Stokes’s theorem
says
Z
[a,b]
γ∗ω =
Z
M
df = f(γ(b)) −f(γ(b)).
Thus Stokes’s theorem reduces to the fundamental theorem for line in-
tegrals (Theorem 4.20) in this case. In particular, when γ : [a, b] →R is
the inclusion map, then Stokes’s theorem is just the ordinary fundamental
theorem of calculus.
Another application of Stokes’s theorem is to prove the classical result
known as Green’s theorem.
Theorem 10.27 (Green’s Theorem).
Suppose D is a regular domain
in R2, and P, Q are smooth real-valued functions on D. Then
Z
D
∂Q
∂x −∂P
∂y

dx dy =
Z
∂D
P dx + Q dy.
Proof. This is just Stokes’s theorem applied to the 1-form P dx+Q dy.
We will see other applications of Stokes’s theorem later in this chapter.
Manifolds with Corners
In many applications of Stokes’s theorem, it is necessary to deal with geo-
metric objects such as triangles, squares, or cubes that are topological
manifolds with boundary, but are not smooth manifolds with boundary

252
10. Integration on Manifolds
because they have “corners.” It is easy to generalize Stokes’s theorem to
this situation, and we do so in this section. We will use this generalization
only in our discussion of de Rham cohomology in Chapter 11.
Let Rn
+ denote the closed positive “quadrant” of Rn:
Rn
+ = {(x1, . . . , xn) ∈Rn : x1 ≥0, . . . , xn ≥0}.
This space is the model for the type of corners we will be concerned with.
Exercise 10.9.
Prove that Rn
+ is homeomorphic to the upper half-space
Hn.
Suppose M is a topological n-manifold with boundary. A chart with
corners for M is a pair (U, ϕ), where U is an open subset of M, and ϕ is a
homeomorphism from U to a (relatively) open set eU ⊂Rn
+. Two charts with
corners (U, ϕ), (V, ψ) are said to be smoothly compatible if the composite
map ϕ ◦ψ−1 : ψ(U ∩V ) →ϕ(U ∩V ) is smooth. (As usual, this means that
it admits a smooth extension to an open set in Rn.)
A smooth structure with corners on a topological manifold with boundary
is a maximal collection of smoothly compatible charts with corners whose
domains cover M. A topological manifold with boundary together with a
smooth structure with corners is called a smooth manifold with corners.
If M is a smooth manifold with corners, any chart with corners (U, ϕ)
in the given smooth structure with corners is called a smooth chart with
corners for M.
Example 10.28. Any closed rectangle in Rn is a smooth n-manifold with
corners.
Because of the result of Exercise 10.9, charts with corners are indistin-
guishable topologically from generalized charts in the sense of topological
manifolds with boundary. Thus from the topological view there is no dif-
ference between manifolds with boundary and manifolds with corners. The
diﬀerence is in the smooth structure, because the compatibility condition
for charts with corners is diﬀerent from that for generalized charts.
It is easy to check that the boundary of Rn
+ in Rn is the set of points at
which at least one coordinate vanishes. The points in Rn
+ at which more
than one coordinate vanishes are called its corner points.
Lemma 10.29. Let M be a smooth n-manifold with corners, and let p ∈
M. If ϕ(p) is a corner point for some smooth chart with corners (U, ϕ),
then the same is true for every such chart whose domain contains p.
Proof. Suppose (U, ϕ) and (V, ψ) are two charts with corners such that
ϕ(p) is a corner point but ψ(p) is not. To simplify notation, let us assume
without loss of generality that ϕ(p) has coordinates (x1, . . . , xk, 0, . . . , 0)
with k ≤n −2. Then ψ(V ) contains an open subset of some (n −1)-
dimensional linear subspace S ⊂Rn, with ψ(p) ∈S. (If ψ(p) is a boundary

Manifolds with Corners
253
point, S can be taken to be the unique subspace of the form xi = 0 that
contains ψ(p). If ψ(p) is an interior point, any (n−1)-dimensional subspace
containing ψ(p) will do.)
Let α: S ∩ψ(V ) →Rn be the restriction of ϕ◦ψ−1 to S ∩ψ(V ). Because
ϕ ◦ψ−1 is a diﬀeomorphism, α is a smooth immersion. Let T = α∗S ⊂Rn.
Because T is (n−1)-dimensional, it must contain a vector X such that one
of the last two components Xn−1 or Xn is nonzero (otherwise T would be
contained in a codimension-2 subspace). Renumbering the coordinates and
replacing X by −X if necessary, we may assume that Xn < 0.
Now let γ : (−ε, ε) →S be a smooth curve such that γ(0) = p and
α∗γ′(0) = X. Then α(γ(t)) has negative xn coordinate for small t > 0,
which contradicts the fact that α takes its values in Rn
+.
If M is a smooth manifold with corners, a point p ∈M is called a corner
point if ϕ(p) is a corner point in R
n
+ with respect to some (and hence every)
smooth chart with corners (U, ϕ). It is clear that every smooth manifold
with or without boundary is also a smooth manifold with corners (but with
no corner points). Conversely, a smooth manifold with corners is a smooth
manifold with boundary if and only if it has no corner points. The boundary
of a smooth manifold with corners, however, is in general not a smooth
manifold with corners (think of the boundary of a cube, for example). In
fact, even the boundary of Rn
+ itself is not a smooth manifold with corners.
It is, however, a union of ﬁnitely many such: ∂Rn
+ = H1 ∪· · · ∪Hn, where
Hi = {(x1, . . . , xn) ∈Rn
+ : xi = 0}
is an (n −1)-dimensional smooth manifold with corners contained in the
subspace deﬁned by xi = 0.
The usual ﬂora and fauna of smooth manifolds—smooth maps, partitions
of unity, tangent vectors, covectors, tensors, diﬀerential forms, orientations,
and integrals of diﬀerential forms—can be deﬁned on smooth manifolds
with corners in exactly the same way as we have done for smooth manifolds
and smooth manifolds with boundary, using smooth charts with corners in
place of smooth charts or generalized charts. The details are left to the
reader.
In addition, for Stokes’s theorem we will need to integrate a diﬀeren-
tial form over the boundary of a smooth manifold with corners. Since the
boundary is not itself a smooth manifold with corners, this requires a spe-
cial deﬁnition. Let M be an oriented smooth n-manifold with corners, and
suppose ω is an (n −1)-form on ∂M that is compactly supported in the
domain of a single oriented smooth chart with corners (U, ϕ). We deﬁne
the integral of ω over ∂M by
Z
∂M
ω =
n
X
i=1
Z
Hi
(ϕ−1)∗ω,

254
10. Integration on Manifolds
where each Hi is given the induced orientation as part of the boundary of
the set where xi ≥0. In other words, we simply integrate ω in coordinates
over the codimension-1 portion of the boundary. Finally, if ω is an arbitrary
compactly supported (n −1)-form on M, we deﬁne the integral of ω over
∂M by piecing together with a partition of unity just as in the case of a
manifold with boundary.
In practice, of course, one does not evaluate such integrals by using par-
titions of unity. Instead, one “chops up” the boundary into pieces that can
be parametrized by compact Euclidean domains of integration, just as for
ordinary manifolds with or without boundary. If M is a smooth manifold
with corners, we say a subset A ⊂∂M has measure zero in ∂M if for every
smooth chart with corners (U, ϕ), each set ϕ(A) ∩Hi has measure zero in
Hi for i = 1, . . . , n. A domain of integration in ∂M is a subset E ⊂∂M
whose boundary has measure zero in ∂M. The following proposition is an
analogue of Proposition 10.21.
Proposition 10.30. The statement of Proposition 10.21 is true if M is
replaced by the boundary of a compact, oriented, smooth n-manifold with
corners.
Exercise 10.10.
Show how the proof of Proposition 10.21 needs to be
adapted to prove Proposition 10.30.
Example 10.31. Let I × I = [0, 1] × [0, 1] be the unit square in R2, and
suppose ω is a smooth 1-form on ∂(I × I). Then it is not hard to check
that the maps Fi : I →I × I given by
F1(t) = (t, 0),
F2(t) = (1, t),
F3(t) = (1 −t, 1),
F4(t) = (0, 1 −t)
(10.8)
satisfy the hypotheses of Proposition 10.30. (These four curve segments in
sequence traverse the boundary of I ×I in the counterclockwise direction.)
Therefore,
Z
∂(I×I)
ω =
Z
F1
ω +
Z
F2
ω +
Z
F3
ω +
Z
F4
ω.
(10.9)
Exercise 10.11.
Verify the claims of the preceding example.
The next theorem is the main result of this section.
Theorem 10.32 (Stokes’s Theorem on Manifolds with Corners).
Let M be a smooth n-manifold with corners, and let ω be a compactly
supported (n −1)-form on M. Then
Z
M
dω =
Z
∂M
ω.

Manifolds with Corners
255
Proof. The proof is nearly identical to the proof of Stokes’s theorem proper,
so we will just indicate where changes need to be made. By means of smooth
charts with corners and a partition of unity just as in that proof, we may
reduce the theorem to the case in which M = Rn
+. In that case, calculating
exactly as in the proof of Theorem 10.23, we obtain
Z
Rn
+
dω =
n
X
i=1
(−1)i−1
Z R
0
· · ·
Z R
0
∂ωi
∂xi (x)dx1 · · · dxn
=
n
X
i=1
(−1)i−1
Z R
0
· · ·
Z R
0
∂ωi
∂xi (x)dxi dx1 · · · c
dxi · · · dxn
=
n
X
i=1
(−1)i−1
Z R
0
· · ·
Z R
0
ωi(x)

xi=R
xi=0
dx1 · · · c
dxi · · · dxn
=
n
X
i=1
(−1)i
Z R
0
· · ·
Z R
0
ωn(x1, . . . , 0, . . . , xn) dx1 · · · c
dxi · · · dxn
=
n
X
i=1
Z
Hi
ω
=
Z
∂Rn
+
ω.
(The factor (−1)i disappeared because the induced orientation on Hi is
(−1)i times that of the standard coordinates (x1, . . . , bxi, . . . , xn).) This
completes the proof.
Here is an immediate application of this result, which we will use
when we study de Rham cohomology in the next chapter. Recall that
two curve segments γ0, γ1 : [a, b] →M are said to be path homotopic if
they are homotopic relative to their endpoints, that is, homotopic via a
homotopy H : [a, b] × I →M such that H(a, t) = γ0(a) = γ1(a) and
H(b, t) = γ0(b) = γ1(b) for all t ∈I.
Theorem 10.33. Suppose M is a smooth manifold, and γ0, γ1 : [a, b] →M
are path homotopic piecewise smooth curve segments. For every closed 1-
form ω on M,
Z
γ0
ω =
Z
γ1
ω.
Proof. By means of an aﬃne reparametrization, we may as well assume for
simplicity that [a, b] = [0, 1]. Assume ﬁrst that γ0 and γ1 are smooth. By
Proposition 6.20, γ0 and γ1 are smoothly homotopic relative to {0, 1}. Let
H : I × I →M be such a smooth homotopy. Since ω is closed, we have
Z
I×I
d(H∗ω) =
Z
I×I
H∗dω = 0.

256
10. Integration on Manifolds
On the other hand, I × I is a manifold with corners, so Stokes’s theorem
implies
0 =
Z
I×I
d(H∗ω) =
Z
∂(I×I)
H∗ω.
By Example 10.31 together with the diﬀeomorphism invariance of line in-
tegrals (Exercise 4.9), therefore,
0 =
Z
∂(I×I)
H∗ω
=
Z
F1
H∗ω +
Z
F2
H∗ω +
Z
F3
H∗ω +
Z
F4
H∗ω
=
Z
H◦F1
ω +
Z
H◦F2
ω +
Z
H◦F3
ω +
Z
H◦F4
ω,
where F1, F2, F3, F4 are deﬁned by (10.8). The fact that H is relative to
{0, 1} means that H ◦F2 and H ◦F4 are constant maps, and therefore the
second and fourth terms above are zero. The theorem then follows from
the facts that H ◦F1 = γ0 and H ◦F3 is a backward reparametrization of
γ1.
Next we consider the general case of piecewise smooth curves. We cannot
simply apply the preceding result on each subinterval where γ0 and γ1
are smooth, because the restricted curves may not start and end at the
same points. Instead, we will prove the following more general claim: Let
γ0, γ1 : I →M be piecewise smooth curve segments (not necessarily with
the same endpoints), and suppose H : I × I →M is any homotopy between
them. Deﬁne curve segments σ0, σ1 : I →M by
σ0(t) = H(0, t),
σ1(t) = H(1, t),
and let eσ0, eσ1 be any smooth curve segments that are path homotopic to
σ0, σ1 respectively. Then
Z
γ1
ω −
Z
γ0
ω =
Z
σ1
ω −
Z
σ0
ω.
(10.10)
When specialized to the case in which γ0 and γ1 are path homotopic, this
implies the theorem, because σ0 and σ1 are constant maps in that case.
Since γ0 and γ1 are piecewise smooth, there are only ﬁnitely many points
(a1, . . . , am) in (0, 1) at which either γ0 or γ1 is not smooth. We will prove
the claim by induction on the number m of such points. When m = 0, both
curves are smooth, and by Proposition 6.20 we may replace the given ho-
motopy H by a smooth homotopy eH. Recall from the proof of Proposition
6.20 that the smooth homotopy eH can actually be taken to be homotopic

Integration on Riemannian Manifolds
257
to H relative to I ×{0}∪I ×{1}. Thus for i = 0, 1, the curve eσi(t) = eH(i, t)
is a smooth curve segment that is path homotopic to σi. In this setting,
(10.10) just reduces to (10.9). Note that the integrals over eσ0 and eσ1 do not
depend on which smooth curves path homotopic to σ0 and σ1 are chosen,
by the smooth case of the theorem proved above.
Now let γ0, γ1 be homotopic piecewise smooth curves with m nonsmooth
points (a1, . . . , am), and suppose the claim is true for curves with fewer
than m such points. For i = 0, 1, let γ′
i be the restriction of γi to [0, am],
and let γ′′
i be its restriction to [am, 1]. Let σ: I →M be the curve segment
σ(t) = H(am, t),
and let eσ by any smooth curve segment that is path homotopic to σ. Then,
since γ′
i and γ′′
i have fewer than m nonsmooth points, the inductive hy-
pothesis implies
Z
γ1
ω −
Z
γ0
ω =
 Z
γ′
1
ω −
Z
γ′
0
ω
!
+
 Z
γ′′
1
ω −
Z
γ′′
0
ω
!
=
Z
eσ
ω −
Z
eσ0
ω

+
Z
eσ1
ω −
Z
eσ
ω

=
Z
eσ1
ω −
Z
eσ0
ω.
This completes the proof.
Integration on Riemannian Manifolds
In this section, we explore how the theory of orientations and integration
can be specialized to Riemannian manifolds. Thinking of R2 and R3 as
Riemannian manifolds, this will eventually lead us to the classical theorems
of vector calculus as consequences of Stokes’s theorem.
The Riemannian Volume Form
We begin with orientations. Let (M, g) be an oriented Riemannian mani-
fold. We know from Proposition 8.16 that there is a smooth orthonormal
frame (E1, . . . , En) in a neighborhood of each point of M. By replacing
E1 by −E1 if necessary, we can ﬁnd an oriented orthonormal frame in a
neighborhood of each point.
Proposition 10.34. Suppose
(M, g)
is
an
oriented
Riemannian
n-
manifold. There is a unique orientation form Ω∈An(M) such that
Ωp(E1, . . . , En) = 1
(10.11)
for every p ∈M and every oriented orthonormal basis (Ei) for TpM.

258
10. Integration on Manifolds
Remark. The n-form whose existence and uniqueness are guaranteed by
this proposition is called the Riemannian volume form, or sometimes the
Riemannian volume element. Because of the role it plays in integration on
Riemannian manifolds, as we will see shortly, it is often denoted by dVg (or
dAg or dsg in the 2-dimensional or 1-dimensional case, respectively). Be
warned, however, that this notation is not meant to imply that the volume
form is the exterior derivative of an (n −1)-form; in fact, as we will see in
Chapter 11, this is never the case on a compact manifold. You should just
interpret dVg as a notational convenience.
Proof. Suppose ﬁrst that such a form Ωexists. If (E1, . . . , En) is any local
oriented orthonormal frame and (ε1, . . . , εn) is the dual coframe, we can
write Ω= f ε1 ∧· · · ∧εn locally. The condition (10.11) then reduces to
f = 1, so
Ω= ε1 ∧· · · ∧εn.
(10.12)
This proves that such a form is uniquely determined.
To prove existence, we would like to deﬁne Ωin a neighborhood of each
point by (10.12). If ( eE1, . . . , eEn) is another oriented orthonormal frame,
with dual coframe (eε1, . . . , eεn), let
eΩ= eε1 ∧· · · ∧eεn.
We can write
eEi = Aj
iEj
for some matrix (Aj
i) of smooth functions. The fact that both frames are
orthonormal means that (Aj
i(p)) ∈O(n) for each p, so det(Aj
i) = ±1, and
the fact that the two frames are consistently oriented forces the positive
sign. We compute
Ω( eE1, . . . , eEn) = det(εj( eEi))
= det(Aj
i)
= 1
= eΩ( eE1, . . . , eEn).
Thus Ω= eΩ, so deﬁning Ωin a neighborhood of each point by (10.12)
with respect to some oriented orthonormal frame yields a global n-form.
The resulting form is clearly smooth and satisﬁes (10.11) for every oriented
orthonormal basis.
Although the expression for the Riemannian volume form with respect
to an oriented orthonormal frame is particularly simple, it is also useful to
have an expression for it in coordinates.

Integration on Riemannian Manifolds
259
Lemma 10.35. Let (M, g) be an oriented Riemannian manifold. If (xi) is
any oriented coordinate chart, then the Riemannian volume form has the
local coordinate expression
dVg =
q
det(gij) dx1 ∧· · · ∧dxn,
where gij are the components of g in these coordinates.
Proof. Let (xi) be oriented coordinates near p ∈M. Then locally Ω=
f dx1 ∧· · ·∧dxn for some positive coeﬃcient function f. To compute f, let
(Ei) be any oriented orthonormal frame deﬁned on a neighborhood of p,
and let (εi) be the dual coframe. If we write the coordinate frame in terms
of the orthonormal frame as
∂
∂xi = Aj
iEj,
then we can compute
f = Ω
 ∂
∂x1 , . . . ,
∂
∂xn

= ε1 ∧· · · ∧εn
 ∂
∂x1 , . . . ,
∂
∂xn

= det

εj
 ∂
∂xi

= det(Aj
i ).
On the other hand, observe that
gij =
 ∂
∂xi , ∂
∂xj

= ⟨Ak
i Ek, Al
jEl⟩
= Ak
i Al
j⟨Ek, El⟩
=
X
k
Ak
i Ak
j .
This last expression is the (i, j)-entry of the matrix product AT A, where
A = (Aj
i). Thus
det(gij) = det(AT A) = det AT det A = (det A)2,
from which it follows that f = det A = ±
p
det(gij). Since both frames
(∂/∂xi) and (Ej) are oriented, the sign must be positive.

260
10. Integration on Manifolds
We noted earlier that real-valued functions cannot be integrated in a
coordinate-independent way on an arbitrary manifold. However, with the
additional structures of a Riemannian metric and an orientation, we can
recover the notion of the integral of a function.
Suppose (M, g) is an oriented Riemannian manifold (with or without
boundary), and let dVg denote its Riemannian volume form. If f is a com-
pactly supported smooth function on M, then f dVg is an n-form, so we
can deﬁne the integral of f over M to be R
M f dVg. (This, of course, is the
reason we chose the notation dVg for the Riemannian volume form.) If M
itself is compact, we deﬁne the volume of M by
Vol(M) =
Z
M
dVg.
Lemma 10.36. Let (M, g) be an oriented Riemannian manifold. If f is a
compactly supported smooth function on M and f ≥0, then
R
M f dVg ≥0,
with equality if and only if f ≡0.
Proof. Clearly
R
M f dVg = 0 if f is identically zero. If f ≥0 and f is
positive somewhere, then f dVg is an orientation form on the open subset
U ⊂M where f > 0, so the result follows from Proposition 10.20(c).
Hypersurfaces in Riemannian Manifolds
Let (M, g) be an oriented Riemannian manifold, and suppose S ⊂M is a
submanifold. A vector ﬁeld N along S is said to be normal to S if Np ⊥TpS
for each p ∈S. If S is a hypersurface, then any unit normal vector ﬁeld
along S is clearly transverse to S, so it determines an orientation of S by
Proposition 10.8. The next proposition gives a very simple formula for the
volume form of the induced metric on S with respect to this orientation.
Proposition 10.37. Let (M, g) be an oriented Riemannian manifold, let
S ⊂M be an immersed hypersurface, and let eg denote the induced metric
on S. Suppose N is a smooth unit normal vector ﬁeld along S. With respect
to the orientation of S determined by N, the volume form of (S, eg) is given
by
dVeg = (N
dVg)|S.
Proof. By Proposition 10.8, the (n−1)-form N
dVg is an orientation form
for S. To prove that it is the volume form for the induced Riemannian
metric, we need only show that it gives the value 1 whenever it is applied
to an oriented orthonormal frame for S. Thus let (E1, . . . , En−1) be such a
frame. At each point p ∈S, the basis (Np, E1|p, . . . , En−1|p) is orthonormal,
and is oriented for TpM (this is the deﬁnition of the orientation determined
by N). Thus
(N
dVg)|S(E1, . . . , En−1) = dVg(N, E1, . . . , En−1) = 1,

Integration on Riemannian Manifolds
261
which proves the result.
The following lemma will be useful in our proofs of the classical theorems
of vector analysis below.
Lemma 10.38. With notation as in Proposition 10.37, if X is any vector
ﬁeld along S, we have
X
dVg|S = ⟨X, N⟩dVeg.
(10.13)
Proof. Deﬁne two vector ﬁelds X⊤and X⊥along S by
X⊥= ⟨X, N⟩N,
X⊤= X −X⊥.
Then X = X⊥+ X⊤, where X⊥is normal to S and X⊤is tangent to it.
Using this decomposition,
X
dVg = X⊥
dVg + X⊤
dVg.
Using Corollary 10.40, the ﬁrst term simpliﬁes to
(X⊥
dVg)|f
M = ⟨X, N⟩(N
dVg)|f
M = ⟨X, N⟩dVeg.
Thus (10.13) will be proved if we can show that (X⊤
dVg)|f
M = 0. If
X1, . . . , Xn−1 are any vectors tangent to f
M, then
(X⊤
dVg)(X1, . . . , Xn−1) = dVg(X⊤, X1, . . . , Xn−1) = 0,
because any n vectors in an (n −1)-dimensional vector space are linearly
dependent.
The result of Proposition 10.37 takes on particular importance in the
case of a Riemannian manifold with boundary, because of the following
proposition.
Proposition 10.39. Suppose M is any Riemannian manifold with bound-
ary. There is a unique smooth outward-pointing unit normal vector ﬁeld N
along ∂M.
Proof. First we prove uniqueness. At any point p ∈∂M, the vector space
(Tp∂M)⊥⊂TqM is 1-dimensional, so there are exactly two unit vectors
at p that are normal to ∂M. Since any unit normal vector N is obviously
transverse to ∂M, it must have nonzero xn-component. Thus exactly one
of the two choices of unit normal has negative xn-component, which is
equivalent to being outward-pointing.
To prove existence, we will show that there exists a smooth outward
unit normal ﬁeld in a neighborhood of each point. By the uniqueness result

262
10. Integration on Manifolds
above, these vector ﬁelds all agree where they overlap, so the resulting
vector ﬁeld is globally deﬁned.
Let p ∈∂M. By Proposition 8.24, there exists an adapted orthonormal
frame for M in a neighborhood U of p: This is a local frame (E1, . . . , En)
such that (E1, . . . , En−1) restricts to an orthonormal frame for ∂M. This
implies that En is a (smooth) unit normal vector ﬁeld along ∂M in a
neighborhood of p. It is obviously transverse to ∂M. If we assume (by
shrinking U if necessary) that U is connected, then En must be either
inward-pointing or outward-pointing on all of ∂M ∩U. Replacing En by
−En if necessary, we obtain a smooth outward-pointing unit normal vector
ﬁeld deﬁned near p. This completes the proof.
The next corollary is immediate.
Corollary 10.40. If (M, g) is an oriented Riemannian manifold with
boundary and eg is the induced Riemannian metric on ∂M, then the volume
form of eg is
dVeg = (N
dVg)|∂M,
where N is the unit outward normal vector ﬁeld along ∂M.
Next we will show how Stokes’s theorem reduces to familiar results in
various special cases.
The Divergence Theorem
Let (M, g) be an oriented Riemannian manifold. Multiplication by the Rie-
mannian volume form deﬁnes a map ∗: C∞(M) →An(M):
∗f = f dVg.
If (Ei) is any local oriented orthonormal frame, then f can be recovered
from ∗f locally by
f = (∗f)(E1, . . . , En).
Thus ∗is an isomorphism.
Deﬁne the divergence operator div: T(M) →C∞(M) by
div X = ∗−1d(X
dVg),
or equivalently,
d(X
dVg) = (div X)dVg.
In the special case of a domain with smooth boundary in R3, the following
theorem is due to Gauss and is often referred to as Gauss’s theorem.

Integration on Riemannian Manifolds
263
Theorem 10.41 (The Divergence Theorem).
Let M be a compact,
oriented Riemannian manifold with boundary. For any smooth vector ﬁeld
X on M,
Z
M
(div X) dVg =
Z
∂M
⟨X, N⟩dVeg,
where N is the outward-pointing unit normal vector ﬁeld along ∂M and eg
is the induced Riemannian metric on ∂M.
Proof. By Stokes’s theorem,
Z
M
(div X) dVg =
Z
M
d(X
dVg)
=
Z
∂M
X
dVg.
The theorem then follows from Lemma 10.38.
Surface Integrals
The original theorem that bears the name of Stokes concerned “surface
integrals” of vector ﬁelds over surfaces in R3. Using the diﬀerential-forms
version of Stokes’s theorem, this can be generalized to surfaces in Riemann-
ian 3-manifolds. (For reasons that will be explained later, the restriction to
dimension 3 cannot be removed.)
Let (M, g) be an oriented Riemannian 3-manifold, and let β : TM →
Λ2M denote the bundle map deﬁned by β(X) = X
dVg. It is easily seen
to be a bundle isomorphism by checking its values on the elements of any
orthonormal frame.
Deﬁne an operator curl: T(M) →T(M) by
curl X = β−1d(X♭),
or equivalently,
curl X
dVg = d(X♭).
(10.14)
The following commutative diagram summarizes the relationships among
the gradient, divergence, curl, and exterior derivative operators:
C∞(M)
-
grad T(M)
T(M)
-
curl
C∞(M)
-
div
?
Id
?
♭
?
β
?
∗
C∞(M)
-
d
A1(M)
A2(M)
-
d
A3(M),
-
d
(10.15)
Problem 10-22 shows that the composition of any two horizontal arrows in
this diagram is zero.

264
10. Integration on Manifolds
Now suppose S ⊂M is a compact, embedded, 2-dimensional submanifold
with or without boundary in M, and N is a smooth unit normal vector
ﬁeld along S. Let dA denote the induced Riemannian volume form on S
with respect to the induced metric g|S and the orientation determined by
N, so that dA = (N
dVg)|S by Proposition 10.37. For any smooth vector
ﬁeld X deﬁned on M, the surface integral of X over S (with respect to the
given choice of normal ﬁeld) is deﬁned as
Z
S
⟨X, N⟩dA.
The next result, in the special case in which M = R3, is the original
theorem proved by Stokes.
Theorem 10.42 (Stokes’s Theorem for Surface Integrals).
Sup-
pose S is a compact, embedded, 2-dimensional submanifold with boundary
in a Riemannian 3-manifold M, and suppose N is a smooth unit normal
vector ﬁeld along S. For any smooth vector ﬁeld X on M,
Z
S
⟨curl X, N⟩dA =
Z
∂S
⟨X, T ⟩ds,
where ds is the Riemannian volume form and T is the unique positively
oriented unit tangent vector ﬁeld on ∂S (with respect to the metric and
orientation induced from S).
Proof. The general version of Stokes’s theorem applied to the 1-form X♭
yields
Z
S
d(X♭) =
Z
∂S
X♭.
Thus the theorem will follow from the following two equations:
d(X♭)|S = ⟨curl X, N⟩dA,
(10.16)
X♭|∂S = ⟨X, T ⟩ds.
(10.17)
Equation (10.16) is just the deﬁning equation (10.14) for the curl com-
bined with the result of Lemma 10.38. To prove (10.17), we note that
X♭|∂S is a 1-form on a 1-manifold, and thus must be equal to f ds for some
smooth function f on ∂S. To evaluate f, we note that ds(T ) = 1, and so
the deﬁnition of X♭yields
f = f ds(T ) = X♭(T ) = ⟨X, T ⟩.
This proves (10.17) and thus the theorem.
The curl operator is deﬁned only in dimension 3 because it is only in that
case that Λ2M is isomorphic to TM (via the map β : X 7→X
dVg). In
fact, it was largely the desire to generalize the curl and the classical version
of Stokes’s theorem to higher dimensions that led to the entire theory of
diﬀerential forms.

Problems
265
Problems
10-1. Prove that every smooth 1-manifold is orientable.
10-2. Suppose M is a smooth manifold that is the union of two open sub-
sets, each of which is diﬀeomorphic to an open subset of Rn, and
whose intersection is connected. Show that M is orientable. Use this
to give another proof that Sn is orientable.
10-3. Suppose π: f
M →M is a smooth covering map and M is orientable.
Show that f
M is also orientable.
10-4. Suppose M is a connected, oriented smooth manifold and Γ is a
discrete group acting freely and properly on M. We say the action is
orientation-preserving if for each γ ∈Γ, the diﬀeomorphism x 7→γ·x
is orientation-preserving. Show that M/Γ is orientable if and only if
Γ is orientation-preserving.
10-5. Let E be the total space of the M¨obius bundle, which is the quotient
of R2 by the Z-action n·(x, y) = (x + n, (−1)ny) (see Problem 7-22).
The M¨obius band is the subset M ⊂E that is the image under the
quotient map of the set {(x, y) ∈R2 : |y| ≤1}. Show that neither E
nor M is orientable.
10-6. Suppose M is a connected nonorientable smooth manifold. Deﬁne a
set f
M by
f
M =
a
p∈M
{orientations of TpM},
and let π: f
M →M be the obvious map that sends an orientation
of TpM to p. Show that f
M has a unique smooth manifold structure
such that π is a local diﬀeomorphism. With this structure, show that
f
M is connected and orientable, and π is a 2-sheeted smooth covering
map. [The covering π: f
M →M is called the orientation covering of
M.]
10-7. Let T2 = S1 × S1 ⊂R4 denote the 2-torus, deﬁned by w2 + x2 =
y2 +z2 = 1, with the orientation determined by its product structure
(see Exercise 10.4). Compute
R
T2 ω, where ω is the following 2-form
on R4:
ω = wy dx ∧dz.
10-8. For each of the following 2-forms ω on R3, compute
R
S2 Ω, where S2
is oriented by its outward unit normal.
(a) ω = x dy ∧dz + y dz ∧dx + z dx ∧dy.

266
10. Integration on Manifolds
(b) ω = xz dy ∧dz + yz dz ∧dx + x2 dx ∧dy.
10-9. Let D denote the surface of revolution in R3 obtained by revolving the
circle (x−2)2+z2 = 1 around the z-axis, with its induced Riemannian
metric, and with the orientation induced by the outward unit normal.
(a) Compute the surface area of D.
(b) Compute the integral over D of the function f(x, y, z) = z + 1.
(c) Compute the integral over D of the 2-form ω of Problem 10-8(b).
10-10. Let ω be the (n −1)-form on Rn ∖{0} deﬁned by
ω = |x|−n
n
X
i=1
(−1)i−1xi dx1 ∧· · · ∧c
dxi ∧· · · ∧dxn.
(10.18)
(a) Show that ω|Sn−1 is the Riemannian volume element of Sn−1
with respect to the round metric.
(b) Show that ω is closed but not exact.
10-11. Suppose M is an oriented Riemannian manifold, and S ⊂M is an
oriented hypersurface (with or without boundary). Show that there
is a unique smooth unit normal vector ﬁeld along S that determines
the given orientation of S.
10-12. Suppose S is an oriented embedded 2-manifold with boundary in
R3, and let C = ∂S with the induced orientation. By Problem 10-
11, there is a unique smooth unit normal vector ﬁeld N on S that
determines the orientation. Let T be the oriented unit tangent vector
ﬁeld on C; let V be the unique vector ﬁeld tangent to S along C that
is outward-pointing; and let W be the restriction of N to C. Show
that (Tp, Vp, Wp) is an oriented basis for R3 at each p ∈C.
10-13. Let (M, g) be an oriented Riemannian n-manifold. With respect to
any local coordinates (xi), show that
div

Xi ∂
∂xi

=
1
p
det(gij)
∂
∂xi

Xiq
det(gij)

,
where gij are the components of g. Conclude that on Rn with the
Euclidean metric,
div

Xi ∂
∂xi

=
n
X
i=1
∂Xi
∂xi .

Problems
267
10-14. Show that the divergence operator on an oriented Riemannian mani-
fold does not depend on the choice of orientation, and conclude that
it is invariantly deﬁned on all Riemannian manifolds.
10-15. Let (M, g) be a compact, oriented Riemannian manifold with bound-
ary, let eg denote the induced Riemannian metric on ∂M, and let N
be the outward unit normal vector ﬁeld along ∂M.
(a) Show that the divergence operator satisﬁes the following product
rule for f ∈C∞(M), X ∈T(M):
div(fX) = f div X + ⟨grad f, X⟩.
(b) Prove the following “integration by parts” formula:
Z
M
⟨gradf, X⟩dVg =
Z
∂M
f⟨X, N⟩dVeg −
Z
M
(f div X) dVg.
10-16. Let (M, g) be an oriented Riemannian manifold. The operator
∆: C∞(M) →C∞(M) deﬁned by ∆u = div(gradu) is called the
Laplace operator, and ∆u is called the Laplacian of u. A function
u ∈C∞(M) is said to be harmonic if ∆u = 0.
(a) If M is compact, prove Green’s identities:
Z
M
u∆v dVg +
Z
M
⟨grad u, gradv⟩dVg =
Z
∂M
u Nv dVeg.
(10.19)
Z
M
(u∆v −v∆u) dVg =
Z
∂M
(u Nv −v Nu)dVeg,
(10.20)
where N and eg are as in Problem 10-15.
(b) If M is connected and ∂M = ∅, show that the only harmonic
functions on M are the constants.
(c) If M is connected, ∂M ̸= ∅, and u, v are harmonic functions on
M whose restrictions to ∂M agree, show that u ≡v.
10-17. Let (M, g) be a compact, connected, oriented Riemannian manifold,
and let ∆be its Laplace operator. A real number λ is called an eigen-
value of ∆if there exists a smooth function u on M, not identically
zero, such that ∆u = λu. In this case, u is called an eigenfunction
corresponding to λ.
(a) Prove that 0 is an eigenvalue of ∆, and that all other eigenvalues
are strictly negative.

268
10. Integration on Manifolds
(b) If u and v are eigenfunctions corresponding to distinct eigenval-
ues, show that
R
M uv dVg = 0.
10-18. Let (M, g) be an oriented Riemannian n-manifold. This problem
outlines an important generalization of the operator ∗: C∞(M) →
An(M) deﬁned in this chapter.
(a) For each k = 1, . . . , n, show that there is a unique inner prod-
uct on Λk(TpM) with the following property: If (Ei) is any
orthonormal basis for TpM and (εi) is the dual basis, then
{εI : I is increasing} is an orthonormal basis for Λk(TpM).
(b) For each k = 0, . . . , n, show that there is a unique bundle map
∗: ΛkM →Λn−kM satisfying
ω ∧∗η = ⟨ω, η⟩dVg.
This map is called the Hodge star operator. [Hint: First prove
uniqueness, and then deﬁne ∗on elementary covectors deﬁned
with respect to an orthonormal basis.]
(c) Show that ∗: Λ0(M) →Λn(M) is given by ∗c = c dVg.
(d) Show that ∗∗ω = (−1)k(n−k)ω if ω is a k-form.
10-19. Let (M, g) be a Riemannian manifold and X ∈T(M).
(a) Show that
X
dVg = ∗X♭.
(b) Show that
div X = ∗d ∗X♭.
(c) If M is 3-dimensional, show that
curl X = (∗dX♭)#.
10-20. Prove that Pn is orientable if and only if n is odd. [Hint: suppose η is
a nonvanishing n-form on Pn. Let π : Sn →Pn denote the universal
covering map, and α : Sn →Sn the antipodal map α(x) = −x. Then
compute α∗π∗η two ways.]
10-21. If ω is a symplectic form on a 2n-manifold, show that ω ∧· · ·∧ω (the
n-fold wedge product of ω with itself) is a nonvanishing 2n-form on
M, and thus every symplectic manifold is orientable.
10-22. Show that curl ◦grad ≡0 and div ◦curl ≡0 on any Riemannian
3-manifold.

Problems
269
10-23. On R3 with the Euclidean metric, show that
curl

P ∂
∂x + Q ∂
∂y + R ∂
∂z

=
∂R
∂y −∂Q
∂z
 ∂
∂x +
∂P
∂z −∂R
∂x
 ∂
∂y +
∂Q
∂x −∂P
∂y
 ∂
∂z .
10-24. Show that any ﬁnite product M1 × · · · × Mk of smooth manifolds
with corners is again a smooth manifold with corners. Give a coun-
terexample to show that a ﬁnite product of smooth manifolds with
boundary need not be a smooth manifold with boundary.
10-25. Suppose M is a smooth manifold with corners, and let C denote the
set of corner points of M. Show that M ∖C is a smooth manifold
with boundary.

270
10. Integration on Manifolds

11
De Rham Cohomology
In Chapter 9 we deﬁned closed and exact forms: A diﬀerential form ω is
closed if dω = 0, and exact if it is of the form dη. Because d2 = 0, every
exact form is closed. In this chapter, we explore the implications of the
converse question: Is every closed form exact? The answer, in general, is
no: In Example 4.23 we saw an example of a closed 1-form on Rn∖{0} that
was closed but not exact. In that example, the failure of exactness seemed
to be a consequence of the “hole” in the center of the domain. For higher-
degree forms, the answer to the question depends on subtle topological
properties of the manifold, connected with the existence of “holes” of higher
dimensions. Making this dependence quantitative leads to a new set of
invariants of smooth manifolds, called the de Rham cohomology groups,
which are the subject of this chapter.
There are many situations in which knowledge of which closed forms are
exact has important consequences. For example, Stokes’s theorem implies
that if ω is exact, then the integral of ω over any compact submanifold with-
out boundary is zero. Proposition 4.22 showed that a 1-form is conservative
if and only if it is exact.
We begin by deﬁning the de Rham cohomology groups and proving some
of their basic properties, including diﬀeomorphism invariance. Then we
prove that they are in fact homotopy invariants, which implies in partic-
ular that they are topological invariants. Using elementary methods, we
compute some de Rham groups, including the zero-dimensional groups of
all manifolds, the one-dimensional groups of simply connected manifolds,
the top-dimensional groups of compact manifolds, and all of the de Rham
groups of star-shaped open subsets of Rn. Then we prove a general theorem

272
11. De Rham Cohomology
that expresses the de Rham groups of a manifold in terms of those of its
open subsets, called the Mayer–Vietoris theorem, and use it to compute all
the de Rham groups of spheres.
At the end of the chapter, we turn our attention to the de Rham theorem,
which expresses the equivalence of the de Rham groups with another set
of groups deﬁned purely topologically, the singular cohomology groups.
To set the stage, we ﬁrst give a brief summary of singular homology and
cohomology theory, and prove that singular homology can be computed by
restricting attention only to smooth simplices. In the last section, we prove
the de Rham theorem.
The de Rham Cohomology Groups
In Chapter 4, we studied the closed 1-form
ω = x dy −y dx
x2 + y2
,
(11.1)
and showed that it is not exact on R2 ∖{0}, but it is exact on some smaller
domains such as the right half-plane H = {(x, y) : x > 0}, where it is equal
to dθ (see Example 4.26).
As we will see in this chapter, this behavior is typical: closed p-forms are
always locally exact, so the question of whether a given closed form is exact
depends on the global shape of the domain, not on the local properties of
the form.
Let M be a smooth manifold. Because d: Ap(M) →Ap+1(M) is linear,
its kernel and image are linear subspaces. We deﬁne
Zp(M) = Ker[d: Ap(M) →Ap+1(M)] = {closed p-forms},
Bp(M) = Im[d: Ap−1(M) →Ap(M)] = {exact p-forms}.
By convention, we consider Ap(M) to be the zero vector space when p < 0
or p > n = dim M, so that that, for example, B0(M) = 0 and Zn(M) =
An(M).
The fact that every exact form is closed implies that Bp(M) ⊂Zp(M).
Thus it makes sense to deﬁne the pth de Rham cohomology group (or just
de Rham group) of M to be the quotient vector space
Hp
dR(M) = Zp(M)
Bp(M).
(It is, in particular, a group under vector addition. Perhaps “de Rham
cohomology space” would be a more appropriate term, but because most
other cohomology theories produce only groups it is traditional to use the
term group in this context as well, bearing in mind that these “groups” are

The de Rham Cohomology Groups
273
actually real vector spaces.) For any closed form ω on M, we let [ω] denote
the equivalence class of ω in this quotient space, called the cohomology class
of ω. Clearly Hp
dR(M) = 0 for p > dim M, because Ap(M) = 0 in that case.
If [ω] = [ω′] (that is, if ω and ω′ diﬀer by an exact form), we say that ω
and ω′ are cohomologous.
The ﬁrst thing we will show is that the de Rham groups are diﬀeomor-
phism invariants.
Proposition 11.1 (Induced Cohomology Maps).
For any smooth
map G: M →N, the pullback G∗: Ap(N) →Ap(M) carries Zp(N) into
Zp(M) and Bp(N) into Bp(M). It thus descends to a linear map, still de-
noted by G∗, from Hp
dR(N) to Hp
dR(M), called the induced cohomology map.
It has the following properties:
(a) If F : N →P is another smooth map, then
(F ◦G)∗= G∗◦F ∗: Hp
dR(P) →Hp
dR(M).
(b) If IdM denotes the identity map of M, then (IdM)∗is the identity
map of Hp
dR(M).
Proof. If ω is closed, then
d(G∗ω) = G∗(dω) = 0,
so G∗ω is also closed. If ω = dη is exact, then
G∗ω = G∗(dη) = d(G∗η),
which is also exact. Therefore, G∗maps Zp(N) into Zp(M) and Bp(N) into
Bp(M). The induced cohomology map G∗: Hp
dR(N) →Hp
dR(M) is deﬁned
in the obvious way: For a closed p-form ω, let
G∗[ω] = [G∗ω].
If ω′ = ω + dη, then [G∗ω′] = [G∗ω + d(G∗η)] = [G∗ω], so this map is
well-deﬁned. Properties (a) and (b) follow immediately from the analogous
properties for the pullback map on forms.
The next two corollaries are immediate.
Corollary 11.2 (Functoriality). For each integer p ≥0, the assignment
M 7→Hp
dR(M), F 7→F ∗is a contravariant functor from the category of
smooth manifolds and smooth maps to the category of real vector spaces
and linear maps.
Corollary 11.3 (Diﬀeomorphism Invariance).
Diﬀeomorphic mani-
folds have isomorphic de Rham cohomology groups.

274
11. De Rham Cohomology
Homotopy Invariance
In this section, we will present a profound generalization of Corollary 11.3,
one surprising consequence of which will be that the de Rham cohomology
groups are actually topological invariants. In fact, they are something much
more: homotopy invariants.
Recall that a continuous map F : M →N between topological spaces is
said to be a homotopy equivalence if there is a continuous map G: N →M
such that F ◦G ≃IdN and G◦F ≃IdM. Such a map G is called a homotopy
inverse for F. If there exists a homotopy equivalence between M and N, the
two spaces are said to be homotopy equivalent. For example, the inclusion
map ι: Sn−1 ,→Rn ∖{0} is a homotopy equivalence with homotopy inverse
r(x) = x/|x|, because r ◦ι = IdSn−1 and the identity map of Rn ∖{0} is
homotopic to ι◦r via the straight-line homotopy H(x, t) = x+(1−t)x/|x|.
The underlying fact that will allow us to prove the homotopy invari-
ance of de Rham cohomology is that homotopic smooth maps induce the
same cohomology map. To motivate the proof, suppose F, G: M →N are
smoothly homotopic maps, and let us think about what needs to be shown.
Given a closed p-form ω on N, we need somehow to produce a (p−1)-form
η on M such that
dη = F ∗ω −G∗ω.
(11.2)
One might hope to construct η in a systematic way, resulting in a map h
from closed p-forms on M to (p −1)-forms on N that satisﬁes
d(hω) = F ∗ω −G∗ω.
(11.3)
Instead of deﬁning hω only when ω is closed, it turns out to be far simpler
to deﬁne for each p a map h from the space of all p-forms on N to the space
of (p−1)-forms on M. Such maps cannot satisfy (11.3), but instead we will
ﬁnd maps that satisfy
d(hω) + h(dω) = F ∗ω −G∗ω.
(11.4)
This implies (11.3) when ω is closed.
In general, if F, G: M →N are smooth maps, a collection of linear maps
h: Ap(N) →Ap−1(M) such that (11.4) is satisﬁed for each p is called a
homotopy operator between F ∗and G∗. (The term cochain homotopy is
used more frequently in the algebraic topology literature.) The key to our
proof of homotopy invariance will be to construct a homotopy operator
ﬁrst in the following special case. For each t ∈[0, 1], let it : M →M × I be
the embedding
it(x) = (x, t).
Clearly i0 is homotopic to i1. (The homotopy is the identity map of M ×I!)

Homotopy Invariance
275
Lemma 11.4 (Existence of a Homotopy Operator).
For
any
smooth manifold M, there exists a homotopy operator between the maps i0
and i1 deﬁned above.
Proof. For each p, we need to deﬁne a linear map h: Ap(M×I) →Ap−1(M)
such that
h(dω) + d(hω) = i∗
1ω −i∗
0ω.
(11.5)
We deﬁne h by the formula
hω =
Z 1
0
 ∂
∂t
ω

dt,
where t is the coordinate on I. More explicitly, hω is the (p −1)-form on
M whose action on vectors X1, . . . , Xp−1 ∈TqM is
(hω)q(X1, . . . , Xp−1) =
Z 1
0
 ∂
∂t
ω(q,t)

(X1, . . . , Xp−1) dt
=
Z 1
0
ω(q,t)(∂/∂t, X1, . . . , Xp−1) dt.
To show that h satisﬁes (11.5), we consider separately the cases in which
ω = f(x, t) dt ∧dxi1 ∧· · · ∧dxip−1 and ω = f(x, t) dxi1 ∧· · · ∧dxip; since h
is linear and every p-form on M ×I can be written as a sum of such forms,
this suﬃces.
Case I: ω = f(x, t) dt∧dxi1 ∧· · ·∧dxip−1. In this case, because dt∧dt = 0,
d(hω) = d
Z 1
0
f(x, t) dt

dxi1 ∧· · · ∧dxip−1

=
∂
∂xj
Z 1
0
f(x, t) dt

dxj ∧dxi1 ∧· · · ∧dxip−1
=
Z 1
0
∂f
∂xj (x, t) dt

dxj ∧dxi1 ∧· · · ∧dxip−1.
On the other hand,
h(dω) = h
 ∂f
∂xj dxj ∧dt ∧dxi1 ∧· · · ∧dxip−1

=
Z 1
0
∂f
∂xj (x, t) ∂
∂t
(dxj ∧dt ∧dxi1 ∧· · · ∧dxip−1) dt
= −
Z 1
0
∂f
∂xj (x, t) dt

dxj ∧dxi1 ∧· · · ∧dxip−1
= −d(hω).

276
11. De Rham Cohomology
Thus the left-hand side of (11.5) is zero in this case. The right-hand side
is zero as well, because i∗
0dt = i∗
1dt = 0 (since t ◦i0 and t ◦i1 are constant
functions).
Case II: ω = f dxi1 ∧· · · ∧dxip. Now ∂/∂t
ω = 0, which implies that
d(hω) = 0. On the other hand, by the fundamental theorem of calculus,
h(dω) = h
∂f
∂t dt ∧dxi1 ∧· · · ∧dxip + terms without dt

=
Z 1
0
∂f
∂t (x, t)dt

dxi1 ∧· · · ∧dxip
= (f(x, 1) −f(x, 0))dxi1 ∧· · · ∧dxip
= i∗
1ω −i∗
0ω,
which proves (11.5) in this case.
Proposition 11.5. Let F, G: M →N be homotopic smooth maps. For
every p, the induced cohomology maps F ∗, G∗: Hp
dR(N) →Hp
dR(M) are
equal.
Proof. By Proposition 6.20, there is a smooth homotopy H : M × I →
N from F to G. This means that H ◦i0 = F and H ◦i1 = G, where
i0, i1 : M →M × I are deﬁned as above. Let eh be the composite map
eh = h ◦H∗: Ap(N) →Ap−1(M):
Ap(N)
H∗
−→Ap(M × I)
h
−→Ap−1(M),
where h is the homotopy operator constructed in Lemma 11.4.
For any ω ∈Ap(N), we compute
eh(dω) + d(ehω) = h(H∗dω) + d(hH∗ω)
= hd(H∗ω) + dh(H∗ω)
= i∗
1H∗ω −i∗
0H∗ω
= (H ◦i1)∗ω −(H ◦i0)∗ω
= G∗ω −F ∗ω.
Thus if ω is closed,
G∗[ω] −F ∗[ω] = [G∗ω −F ∗ω]
= [eh(dω) + d(ehω)]
= 0,
where the last line follows from dω = 0 and the fact that the cohomology
class of any exact form is zero.
The next theorem is the main result of this section.

Computations
277
Theorem 11.6 (Homotopy Invariance of de Rham Cohomology).
If
M
and
N
are
homotopy
equivalent
smooth
manifolds,
then
Hp
dR(M) ∼= Hp
dR(N) for each p.
Proof. Suppose F : M →N is a homotopy equivalence, with homotopy
inverse G: N →M. By Theorem 6.19, there are smooth maps eF : M →N
homotopic to F and eG: N →M homotopic to G. Because homotopy is
preserved by composition, it follows that eF ◦eG ≃F ◦G ≃IdN and eG◦eF ≃
G ◦F ≃IdM, so eF and eG are homotopy inverses of each other.
Now Proposition 11.5 shows that, on cohomology,
eF ∗◦eG∗= ( eG ◦eF)∗= (IdM)∗= IdHp
dR(M) .
The same argument shows that
eG∗◦eF ∗
is also the identity, so
eF ∗: Hp
dR(N) →Hp
dR(M) is an isomorphism.
Corollary 11.7. The de Rham cohomology groups are topological invari-
ants: If M and N are homeomorphic smooth manifolds, then their de Rham
groups are isomorphic.
This result is remarkable, because the deﬁnition of the de Rham groups
of M is intimately tied up with its smooth structure, and we had no reason
to expect that diﬀerent diﬀerentiable structures on the same topological
manifold should give rise to the same de Rham groups.
Computations
The direct computation of the de Rham groups is not easy in general.
However, in this section, we will compute them in several special cases.
We begin with disjoint unions.
Proposition 11.8 (Cohomology of Disjoint Unions). Let {Mj} be a
countable collection of smooth manifolds, and let M = `
j Mj. For each p,
the inclusion maps ιj : Mj →M induce an isomorphism from Hp
dR(M) to
the direct product space Q
j Hp
dR(Mj).
Proof. The pullback maps ι∗
j : Ap(M) →Ap(Mj) already induce an iso-
morphism from Ap(M) to Q
j Ap(Mj), namely
ω 7→(ι∗
1ω, ι∗
2ω, . . . ) = (ω|M1, ω|M2, . . . ).
This map is injective because any p-form whose restriction to each Mj is
zero must itself be zero, and it is surjective because giving an arbitrary
p-form on each Mj deﬁnes one on M.

278
11. De Rham Cohomology
Because of this proposition, each de Rham group of a disconnected man-
ifold is just the direct product of the corresponding groups of its compo-
nents. Thus we can concentrate henceforth on computing the de Rham
groups of connected manifolds.
Our next computation gives an explicit characterization of zero-
dimensional cohomology.
Proposition 11.9 (Zero-Dimensional Cohomology).
If M is a con-
nected manifold, H0
dR(M) is equal to the space of constant functions and is
therefore one-dimensional.
Proof. Because there are no (−1)-forms, B0(M) = 0. A closed 0-form is a
smooth function f such that df = 0, and since M is connected this is true
if and only if f is constant. Thus H0
dR(M) = Z0(M) = {constants}.
Corollary 11.10 (Cohomology of Zero-Manifolds).
If M is a 0-
dimensional manifold, the dimension of H0
dR(M) is equal to the cardinality
of M, and all other de Rham cohomology groups vanish.
Proof. By Propositions 11.8 and 11.9, H0
dR(M) is isomorphic to the direct
product of one copy of R for each component of M, which is to say each
point.
Next we examine the de Rham cohomology of Euclidean space, and more
generally of its star-shaped open subsets. (Recall that a subset V ⊂Rn is
said to be star-shaped with respect to a point q ∈V if for every x ∈V , the
line segment from q to x is entirely contained in V .) In Proposition 4.27,
we showed that every closed 1-form on a star-shaped open subset of Rn is
exact. The next theorem is a generalization of that result.
Theorem 11.11 (The Poincar´e Lemma). Let U be a star-shaped open
subset of Rn. Then Hp
dR(U) = 0 for p ≥1.
Proof. Suppose U ⊂Rn is star-shaped with respect to q. The key feature
of star-shaped sets is that they are contractible, which means the identity
map of U is homotopic to the constant map sending U to q, by the obvious
straight-line homotopy:
H(x, t) = q + t(x −q).
Thus the inclusion of {q} into U is a homotopy equivalence. The Poincar´e
lemma then follows from the homotopy invariance of Hp
dR together with the
obvious fact that Hp
dR({q}) = 0 for p > 0 because {q} is a 0-manifold.
Exercise 11.1.
If U ⊂Rn is open and star-shaped with respect to 0 and
ω = P′ ωI dxI is a closed p-form on U, show by tracing through the proof of

Computations
279
the Poincar´e lemma that the (p −1)-form η given explicitly by the formula
η =
X′
I
p
X
q=1
(−1)q−1
íZ 1
0
tp−1ωI(tx)dt
ì
xiq dxi1 ∧· · · ∧d
dxiq ∧· · · ∧dxip
satisﬁes dη = ω. When ω is a 1-form, show that η is equal to the potential
function f deﬁned in Proposition 4.27.
The next two results are easy corollaries of the Poincar´e lemma.
Corollary 11.12 (Cohomology of Euclidean Space).
For all p ≥1,
Hp
dR(Rn) = 0.
Proof. Euclidean space Rn is star-shaped.
Corollary 11.13 (Local Exactness of Closed Forms).
Let M be a
smooth manifold, and let ω be a closed p-form on M, p ≥1. For any
q ∈M, there is a neighborhood U of q on which ω is exact.
Proof. Every q ∈M has a neighborhood diﬀeomorphic to an open ball
in Rn, which is star-shaped. The result follows from the diﬀeomorphism
invariance of de Rham cohomology.
One of the most interesting special cases is that of simply connected
manifolds, for which we can compute the ﬁrst cohomology explicitly.
Theorem 11.14. If M is a simply connected smooth manifold, then
H1
dR(M) = 0.
Proof. Let ω be a closed 1-form on M. We need to show that ω is exact. By
Theorem 4.22, this is true if and only ω is conservative, that is, if and only
if all line integrals of ω depend only on endpoints. Since any two piecewise
smooth curve segments with the same endpoints are path homotopic, the
result follows from Theorem 10.33.
Finally, we turn our attention to the top-dimensional cohomology of
compact manifolds. We begin with the orientable case. Suppose M is
an orientable compact smooth manifold. There is a natural linear map
I : An(M) →R given by integration over M:
I(ω) =
Z
M
ω.
Because the integral of any exact form is zero, I descends to a linear map,
still denoted by the same symbol, from Hn
dR(M) to R. (Note that every
n-form on an n-manifold is closed.)

280
11. De Rham Cohomology
Theorem 11.15 (Top Cohomology, Orientable Case).
For
any
compact,
connected,
orientable,
smooth
n-manifold
M,
the
map
I : Hn
dR(M) →R is an isomorphism. Thus Hn
dR(M) is one-dimensional,
spanned by the cohomology class of any orientation form.
Proof. The 0-dimensional case is an immediate consequence of Corollary
11.10, so we may assume that n ≥1. Let Ωbe an orientation form for M,
and set c =
R
M Ω. By Proposition 10.20(c), c > 0. Therefore, for any a ∈R,
I[aω] = ac, so I : Hn
dR(M) →R is surjective. To complete the proof, we
need only show that it is injective. In other words, we have to show the
following: If ω is any n-form satisfying
R
M ω = 0, then ω is exact.
Let {U1, . . . , Um} be a ﬁnite cover of M by open sets that are diﬀeo-
morphic to Rn, and let Mk = U1 ∪· · · ∪Uk for k = 1, . . . , m. Since
M is connected, by reordering the sets if necessary, we may assume that
Mk ∩Uk+1 ̸= ∅for each k. We will prove the following claim by induction
on k: If ω is a compactly supported n-form on Mk that satisﬁes
R
Mk ω = 0,
then there exists a compactly supported (n −1)-form η on Mk such that
dη = ω. When k = m, this is the statement we are seeking to prove,
because every form on a compact manifold is compactly supported.
For k = 1, since M1 = U1 is diﬀeomorphic to Rn, the claim reduces
to a statement about compactly supported forms on Rn. The proof of this
statement is somewhat technical, so we postpone it to the end of this section
(Lemma 11.19). Assuming this for now, we continue with the induction.
Assume the claim is true for some k ≥1, and suppose ω is a compactly
supported n-form on Mk+1 = Mk ∪Uk+1 that satisﬁes
R
Mk+1 ω = 0. Choose
an auxiliary n-form Ω∈An(Mk+1) that is compactly supported in Mk ∩
Uk+1 and satisﬁes R
Mk+1 Ω= 1. (Such a form is easily constructed by using
a bump function in coordinates.) Let {ϕ, ψ} be a partition of unity for
Mk+1 subordinate to the cover {Mk, Uk+1}.
Let c =
R
Mk+1 ϕω. Observe that ϕω −cΩis compactly supported in
Mk, and its integral is equal to zero by our choice of c. Therefore, by the
induction hypothesis, there is a compactly supported (n −1)-form α on
Mk such that dα = ϕω −cΩ. Similarly, ψω + cΩis compactly supported in
Uk+1, and its integral is
Z
Uk+1
(ψω + cΩ) =
Z
Mk+1
(1 −ϕ)ω + c
Z
Mk+1
Ω
=
Z
Mk+1
ω −
Z
Mk+1
ϕω + c
= 0.
Thus by Lemma 11.19, there exists another (n −1)-form β, compactly
supported in Uk+1, such that dβ = ψω+cΩ. Both α and β can be extended

Computations
281
by zero to smooth compactly supported forms on Mk+1. We compute
d(α + β) = (ϕω −cΩ) + (ψω + cΩ) = (ϕ + ψ)ω = ω,
which completes the inductive step.
We now have enough information to compute the de Rham cohomology
of the circle and the punctured plane completely.
Corollary 11.16 (Cohomology of the Circle).
The de Rham coho-
mology groups of the circle are as follows: H0
dR(S1) and H1
dR(S1) are both
1-dimensional, spanned by the function 1 and the cohomology class of the
form ω deﬁned by (11.1), respectively.
Proof. Because the restriction of ω to S1 never vanishes, it is an orientation
form.
Corollary 11.17 (Cohomology of the Punctured Plane).
Let M =
R2 ∖{0}. Then H0
dR(M) and H1
dR(M) are both 1-dimensional, spanned by
the function 1 and the cohomology class of the form ω deﬁned by (11.1),
respectively.
Proof. Because the inclusion map ι: S1 ,→M is a homotopy equivalence,
ι∗: H1
dR(M) →H1
dR(S1) is an isomorphism. The result then follows from
the preceding corollary.
Next we consider the nonorientable case.
Theorem 11.18 (Top Cohomology, Nonorientable Case).
Let M
be
a
compact,
connected,
nonorientable,
smooth
n-manifold.
Then
Hn
dR(M) = 0.
Proof. We have to show that every n-form on M is exact. By the result of
Problem 10-6, there is an orientable manifold f
M and a 2-sheeted smooth
covering map π: f
M →M. Let α: f
M →M be the map that interchanges
the two points in each ﬁber of π. If U ⊂M is any evenly covered open set,
then α just interchanges the two components of π−1(U), so α is a smooth
covering transformation; in fact, it is the unique nontrivial covering trans-
formation of π. Now, α cannot be orientation-preserving—if it were, the
entire covering group {Idf
M, α} would be orientation-preserving, and then
M would be orientable by the result of Problem 10-4. By connectedness of
f
M and the fact that α is a diﬀeomorphism, it follows that α is orientation-
reversing.
Suppose ω is any n-form on M, and let Ω= π∗ω ∈An(f
M). Then
π ◦α = π implies
α∗Ω= α∗π∗ω = (π ◦α)∗ω = π∗ω = Ω.

282
11. De Rham Cohomology
Because α is orientation-reversing, therefore, we conclude from Proposition
10.16 that
Z
f
M
Ω= −
Z
f
M
α∗Ω= −
Z
f
M
Ω.
This implies that
R
f
M Ω= 0, so by Theorem 11.15, there exists η ∈
An−1(f
M) such that dη = Ω. Let eη =
1
2(η + α∗η). Using the fact that
α ◦α = Idf
M, we compute
α∗eη = 1
2(α∗η + (α ◦α)∗η) = eη
and
deη = 1
2(dη + dα∗η)
= 1
2(dη + α∗dη)
= 1
2(Ω+ α∗Ω)
= Ω.
Now let U ⊂M be any evenly covered open set. There are exactly
two smooth local sections σ1, σ2 : U →f
M over U, which are related by
σ2 = α ◦σ1. Observe that
σ∗
2 eη = (α ◦σ1)∗eη = σ∗
1α∗eη = σ∗
1eη.
Therefore, we can deﬁne a global (n−1)-form γ on M by setting γ = σ∗eη for
any local section σ. To determine its exterior derivative, choose a smooth
local section σ in a neighborhood of any point, and compute
dγ = dσ∗eη = σ∗deη = σ∗Ω= σ∗π∗ω = (π ◦σ)∗ω = ω,
because π ◦σ = IdU.
Finally, here is the technical lemma that is needed to complete the proof
of Theorem 11.15. It can be thought of as a reﬁnement of the Poincar´e
lemma for compactly supported n-forms.
Lemma 11.19. Let n ≥1, and suppose ω is a compactly supported n-
form on Rn such that
R
Rn ω = 0. Then there exists a compactly supported
(n −1)-form η on Rn such that dη = ω.
Remark. Of course, we know that ω is exact by the Poincar´e lemma, so the
novelty here is the claim that we can ﬁnd a compactly supported (n−1)-form
η such that dη = ω.
Proof. We will carry out the proof by induction on n. For n = 1, we can
write ω = f dx for some smooth compactly supported function f. Choose
R > 0 such that supp f ⊂[−R, R], and deﬁne F : R →R by
F(x) =
Z x
−R
f(t) dt.

Computations
283
Then clearly dF = F ′(x) dx = f dx = ω. When x < −R, F(x) = 0 by our
choice of R. When x > R, the fact that
R
R ω = 0 translates to
0 =
Z R
−R
f(t) dt =
Z x
−R
f(t) dt = F(x),
so in fact supp F ⊂[−R, R]. This completes the proof for the case n = 1.
Now let n ≥1, and suppose the lemma is true on Rn. Let us consider
Rn+1 as the product space R×Rn, with coordinates (y, x) = (y, x1, . . . , xn).
Let Ω= dx1 ∧· · · ∧dxn, considered as an n-form on R × Rn.
Suppose ω is any compactly supported (n+1)-form on R×Rn such that
Z
R×Rn ω = 0.
Then ω can be written
ω = f dy ∧Ω
for some compactly supported smooth function f. Choose R > 0 such that
supp f is contained in the set {(y, x) : |y| ≤R and |x| ≤R}.
Let ϕ: R →R be any bump function supported in [−R, R] and satisfying
R
R ϕ(y) dy = 1. Deﬁne smooth functions e, E, F, eF : R×Rn →R as follows:
e(y, x) = ϕ(y);
E(y, x) =
Z y
−R
ϕ(t) dt;
F(y, x) =
Z y
−R
f(t, x) dt;
eF(y, x) =
Z R
−R
f(t, x) dt = F(R, x).
These functions have the properties
∂e
∂xj = ∂E
∂xj = 0;
∂E
∂y = e;
∂F
∂y = f;
∂eF
∂y = 0.
Let Σ denote the n-form ι∗( eF Ω) on Rn, where ι: Rn ,→R × Rn is the
embedding ι(x) = (0, x). Its integral satisﬁes
Z
Rn Σ =
Z
Rn
eF(0, x) dx1 · · · dxn
=
Z
Rn
Z
R
f(y, x) dy dx1 · · · dxn
=
Z
R×Rn ω
= 0.

284
11. De Rham Cohomology
Therefore, by the inductive hypothesis, there exists a compactly supported
(n −1)-form σ on Rn such that dσ = Σ.
Now deﬁne an n-form η on R × Rn by
η = (F −eFE)Ω−e dy ∧π∗σ,
where π: R × Rn →Rn is the projection. When y < R, we have F ≡eF ≡
e ≡0, so η vanishes there. When y > R, then e ≡0, E ≡1, and F ≡eF,
so η = 0 there also. Finally, when |x| is suﬃciently large, then F, eF, and
σ are all zero, so η = 0 there as well. Thus η is compactly supported.
To show that dη = ω, we compute
dη = dF ∧Ω−eF dE ∧Ω−E d eF ∧Ω−de ∧dy ∧π∗σ + e dy ∧d(π∗σ).
We consider each of these ﬁve terms separately. The ﬁrst term is
dF ∧Ω=
∂F
∂y dy + ∂F
∂xj dxj

∧Ω
= f dy ∧Ω
= ω,
because dxj ∧Ω= 0. For the second term we have
−eF dE ∧Ω= −eF ∂E
∂y dy ∧Ω= −eFe dy ∧Ω.
Because ∂eF/∂y = 0, the third term reduces to
−E d eF ∧Ω= −E ∂eF
∂xj dxj ∧Ω= 0.
The fourth term is likewise zero because de∧dy = ϕ′(y)dy∧dy = 0. For the
ﬁfth term, we observe that π∗ι∗eF = eF because eF is independent of y, and
π∗ι∗Ω= Ωby direct computation, and therefore π∗Σ = eFΩ. Therefore,
e dy ∧d(π∗σ) = e dy ∧π∗(dσ)
= e dy ∧π∗(Σ)
= eFe dy ∧Ω.
Thus the second and ﬁfth terms cancel, and we are left with dη = ω.
For some purposes, it is useful to deﬁne a generalization of the de Rham
cohomology groups using only compactly supported forms. Let Ap
c(M) de-
note the space of compactly-supported p-forms on M. The pth de Rham
cohomology group of M with compact support is the quotient space
Hp
c (M) = Ker[d: Ap
c(M) →Ap+1
c
(M)]
Im[d: Ap−1
c
(M) →Ap
c(M)]
.

The Mayer–Vietoris Theorem
285
Of course, when M is compact, this just reduces to ordinary de Rham co-
homology. But for noncompact manifolds, the two groups can be diﬀerent,
as the next exercise shows.
Exercise 11.2.
Using Lemma 11.19, show that Hn
c (Rn) is 1-dimensional.
We will not use compactly supported cohomology in this book, but it
plays an important role in algebraic topology.
The Mayer–Vietoris Theorem
In this section, we prove a very general theorem that can be used to compute
the de Rham cohomology groups of many spaces, by expressing them as
unions of open submanifolds with simpler cohomology.
For this purpose, we need to introduce some simple algebraic concepts.
More details about the ideas introduced here can be found in [Lee00, Chap-
ter 13] or in any textbook on algebraic topology.
Let R be a commutative ring, and let A∗be any sequence of R-modules
and linear maps:
· · · →Ap−1
d−→Ap
d−→Ap+1 →· · · .
(In all of our applications, the ring will be either Z, in which case we are
looking at abelian groups and homomorphisms, or R, in which case we
have vector spaces and linear map. The terminology of modules is just a
convenient way to combine the two cases.)
Such a sequence is said to be a complex if the composition of any two
successive applications of d is the zero map:
d ◦d = 0: Ap →Ap+2
for each p.
It is called an exact sequence if the image of each d is equal to the kernel
of the next:
Im[d: Ap−1 →Ap] = Ker[d: Ap →Ap+1].
Clearly every exact sequence is a complex, but the converse need not be
true. If A∗is a complex, then the image of each map d is contained in the
kernel of the next, so we deﬁne the pth cohomology group of A∗to be the
quotient module
Hp(A∗) = Ker[d: Ap →Ap+1]
Im[d: Ap−1 →Ap] .
It can be thought of as a quantitative measure of the failure of exactness
at Ap. (In algebraic topology, a complex as we have deﬁned it is usually

286
11. De Rham Cohomology
called a cochain complex, while a chain complex is deﬁned similarly except
that the maps go in the direction of decreasing indices:
· · · →Ap+1
∂−→Ap
∂−→Ap−1 →· · · .
In that case, the term homology is used in place of cohomology.)
If A∗and B∗are complexes, a cochain map from A∗to B∗, denoted by
F : A∗→B∗, is a collection of linear maps F : Ap →Bp (it is easiest to
use the same symbol for all of the maps) such that the following diagram
commutes for each p:
· · ·
-
· · ·
-
Bp
Bp+1
-
d
Ap
Ap+1
-
d
?
F
?
F
· · · .
-
· · ·
-
The fact that F ◦d = d ◦F means that any cochain map induces a linear
map on cohomology F ∗: Hp(A∗) →Hp(B∗) for each p, just as in the case
of de Rham cohomology.
A short exact sequence of complexes consists of three complexes
A∗, B∗, C∗, together with cochain maps
0 →A∗
F
−→B∗
G
−→C∗→0
such that each sequence
0 →Ap
F
−→Bp
G
−→Cp →0
is exact. This means F is injective, G is surjective, and Im F = Ker G.
Lemma 11.20 (The Zigzag Lemma).
Given a short exact sequence of
complexes as above, for each p there is a linear map
δ: Hp(C∗) →Hp+1(A∗),
called the connecting homomorphism, such that the following sequence is
exact:
· · ·
δ−→Hp(A∗)
F ∗
−−→Hp(B∗)
G∗
−−→Hp(C∗)
δ−→Hp+1(A∗)
F ∗
−−→· · · .
(11.6)
Proof. We will sketch only the main idea; you can either carry out the
details yourself or look them up.

The Mayer–Vietoris Theorem
287
The hypothesis means that the following diagram commutes and has
exact horizontal rows:
0
- Ap
-
F
Bp
Cp
-
G
0
-
?
d
?
d
?
d
0
- Ap+1
-
F
Bp+1
Cp+1
-
G
0
-
?
d
?
d
?
d
0
- Ap+2
-
F
Bp+2
Cp+2
-
G
0.
-
Suppose cp ∈Cp represents a cohomology class; this means that dcp = 0.
Since G: Bp →Cp is surjective, there is some element bp ∈Bp such that
Gbp = cp. Because the diagram commutes, Gdbp = dGbp = dcp = 0, and
therefore dbp ∈Ker G = Im F. Thus there exists ap+1 ∈Ap+1 satisfying
Fap+1 = dbp. By commutativity of the diagram again, Fdap+1 = dFap+1 =
ddbp = 0. Since F is injective, this implies dap+1 = 0, so ap+1 represents a
cohomology class in Hp+1(A∗). The connecting homomorphism δ is deﬁned
by setting δ[cp] = [ap+1] for any such ap+1 ∈Ap+1, that is, provided there
exists bp ∈Bp such that
Gbp = cp,
Fap+1 = dbp.
A number of facts have to be veriﬁed: that the cohomology class [ap+1]
is well-deﬁned, independently of the choices made along the way; that the
resulting map δ is linear; and that the resulting sequence (11.6) is exact.
Each of these veriﬁcations is a routine “diagram chase” like the one we
used to deﬁne δ; the details are left as an exercise.
Exercise 11.3.
Complete (or look up) the proof of the zigzag lemma.
The situation in which we will apply this lemma is the following. Suppose
M is a smooth manifold, and U, V are open subsets of M such that M =
U ∪V . We have the following diagram of inclusions:
j@
@@
R
U
U ∩V
i
   
V
l
   
M,
k
@
@@
R
(11.7)

288
11. De Rham Cohomology
which induce pullback maps on diﬀerential forms:
l∗@
@@
R
Ap(U)
Ap(M)
k∗
   
Ap(V )
j∗
   
Ap(U ∩V ),
i∗
@
@@
R
as well as corresponding induced cohomology maps. Note that these pull-
back maps are really just restrictions: For example, k∗ω = ω|U. We will
consider the following sequence:
0 →Ap(M)
k∗⊕l∗
−−−−→Ap(U) ⊕Ap(V )
i∗−j∗
−−−−→Ap(U ∩V ) →0,
(11.8)
where
(k∗⊕l∗)ω = (k∗ω, l∗ω),
(i∗−j∗)(ω, η) = i∗ω −j∗η.
(11.9)
Because pullbacks commute with d, these maps descend to linear maps on
the corresponding de Rham cohomology groups.
Theorem 11.21 (Mayer–Vietoris).
Let M be a smooth manifold, and
let U, V be open subsets of M whose union is M. For each p, there is a
linear map δ: Hp
dR(U ∩V ) →Hp+1
dR (M) such that the following sequence is
exact:
· · ·
δ−→Hp
dR(M)
k∗⊕l∗
−−−−→Hp
dR(U) ⊕Hp
dR(V )
i∗−j∗
−−−−→Hp
dR(U ∩V )
δ−→Hp+1
dR (M)
k∗⊕l∗
−−−−→· · ·
(11.10)
Remark. The sequence (11.10) is called the Mayer–Vietoris sequence for
the open cover {U, V }.
Proof. The heart of the proof will be to show that the sequence (11.8) is
exact for each p. Because pullback maps commute with the exterior deriv-
ative, (11.8) therefore deﬁnes a short exact sequence of chain maps, and
the Mayer–Vietoris theorem follows immediately from the zigzag lemma.
We begin by proving exactness at Ap(M), which just means showing
that k∗⊕l∗is injective. Suppose that σ ∈Ap(M) satisﬁes (k∗⊕l∗)σ =
(σ|U, σ|V ) = (0, 0). This means that the restrictions of σ to U and V are
both zero. Since {U, V } is an open cover of M, this implies that σ is zero.
To prove exactness at Ap(U) ⊕Ap(V ), ﬁrst observe that
(i∗−j∗) ◦(k∗⊕l∗)(σ) = (i∗−j∗)(σ|U, σ|V ) = σU∩V −σ|U∩V = 0,

The Mayer–Vietoris Theorem
289
which shows that Im(k∗⊕l∗) ⊂Ker(i∗−j∗). Conversely, suppose (η, η′) ∈
Ap(U) ⊕Ap(V ) and (i∗−j∗)(η, η′) = 0. This means η|U∩V = η′|U∩V , so
there is a global smooth p-form σ on M deﬁned by
σ =
(
η
on U,
η′
on V .
Clearly (η, η′) = (k∗⊕l∗)σ, so Ker(i∗−j∗) ⊂Im(k∗⊕l∗).
Exactness at Ap(U ∩V ) means that i∗−j∗is surjective. This the only
nontrivial part of the proof, and the only part that really uses any properties
of smooth manifolds.
Let ω ∈Ap(U ∩V ) be arbitrary. We need to show that there exist
η ∈Ap(U) and η′ ∈Ap(V ) such that
ω = (i∗−j∗)(η, η′) = i∗η −j∗η′ = η|U∩V −η′|U∩V .
Let {ϕ, ψ} be a partition of unity subordinate to the open cover {U, V },
and deﬁne η ∈Ap(V ) by
η =
(
ψω,
on U ∩V ,
0
on U ∖supp ψ.
(11.11)
On the set (U ∩V )∖supp ψ where these deﬁnitions overlap, they both give
zero, so this deﬁnes η as a smooth p-form on U. Similarly, deﬁne η′ ∈Ap(V )
by
η′ =
(
−ϕω,
on U ∩V ,
0
on V ∖supp ϕ.
(11.12)
Then we have
η|U∩V −η′|U∩V = ψω −(−ϕω) = (ψ + ϕ)ω = ω,
which was to be proved.
For later use, we record the following corollary to the proof, which ex-
plicitly characterizes the connecting homomorphism δ.
Corollary 11.22. The connecting homomorphism δ: Hp
dR(U ∩V )
→
Hp+1
dR (M) is deﬁned as follows. Given ω ∈Zp(U ∩V ), there are p-forms
η ∈Ap(U) and η′ ∈Ap(V ) such that ω = η|U∩V −η′|U∩V , and then
δ[ω] = [dη], where dη is extended by zero to all of M.
Proof. A characterization of the connecting homomorphism was given in
the proof of the zigzag lemma. Specializing this characterization to the

290
11. De Rham Cohomology
situation of the short exact sequence (11.8), we ﬁnd that δ[ω] = [σ] provided
there exist (η, η′) ∈Ap(U) ⊕Ap(V ) such that
i∗η −j∗η′ = ω,
(k∗σ, l∗σ) = (dη, dη′).
(11.13)
Arguing just as in the proof of the Mayer–Vietoris theorem, if {ϕ, ψ}
is a partition of unity subordinate to {U, V }, then formulas (11.11) and
(11.12) deﬁne smooth forms η ∈Ap(U) and η′ ∈Ap(V ) satisfying the ﬁrst
equation of (11.13). Let σ be the form on M obtained by extending dη to
be zero outside of U ∩V . Because ω is closed,
σ|U∩V = dη|U∩V = d(ω + η′)|U∩V = dη′|U∩V ,
and the second equation of (11.13) follows easily.
Our ﬁrst application of the Mayer–Vietoris theorem will be to compute
all of the de Rham cohomology groups of spheres. In the last section of
this chapter, we will use the theorem again as an essential ingredient in the
proof of the de Rham theorem.
Theorem 11.23. For n ≥1, the de Rham cohomology groups of Sn are
Hp
dR(Sn) ∼=
(
R
if p = 0 or p = n,
0
if 0 < p < n.
Proof. We already know H0
dR(Sn) and Hn
dR(Sn) from the preceding section.
For good measure, we give here another proof for Hn
dR(Sn).
Let N and S be the north and south poles in Sn, respectively, and let
U = Sn ∖{S}, V = Sn ∖{N}. By stereographic projection, both U and V
are diﬀeomorphic to Rn, and thus U ∩V is diﬀeomorphic to Rn ∖{0}.
Part of the Mayer–Vietoris sequence for {U, V } reads
Hp−1
dR (U) ⊕Hp−1
dR (V ) →Hp−1
dR (U ∩V ) →Hp
dR(Sn) →Hp
dR(U) ⊕Hp
dR(V ).
Because U and V are diﬀeomorphic to Rn, the groups on both ends are
trivial when p > 1, which implies that Hp
dR(Sn) ∼= Hp−1
dR (U ∩V ). Moreover,
U ∩V is diﬀeomorphic to Rn ∖{0} and therefore homotopy equivalent to
Sn−1, so in the end we conclude that
Hp
dR(Sn) ∼= Hp−1
dR (Sn−1)
for p > 1.
We will prove the theorem by induction on n. The case n = 1 is taken
care of by Corollary 11.16, so suppose n ≥2 and assume the theorem is
true for Sn−1. Clearly H0
dR(Sn) ∼= R by Proposition 11.9, and H1
dR(Sn) = 0

Singular Homology and Cohomology
291
because Sn is simply connected. For p > 1, the inductive hypothesis then
gives
Hp
dR(Sn) ∼= Hp−1
dR (Sn−1) ∼=
(
0
if p < n,
R
if p = n.
This completes the proof.
Singular Homology and Cohomology
The topological invariance of the de Rham groups suggests that there
should be some purely topological way of computing them. There is in-
deed, and the connection between the de Rham groups and topology was
ﬁrst proved by de Rham himself in the 1930s. The theorem that bears his
name is a major landmark in the development of smooth manifold theory.
We will give a proof in the next section.
In the category of topological spaces, there are a number of ways of deﬁn-
ing cohomology groups that measure the existence of “holes” in diﬀerent
dimensions, but that have nothing to do with diﬀerential forms or smooth
structures. In this section, we describe the most straightforward one, called
singular cohomology. Because a complete treatment of singular cohomol-
ogy would be far beyond the scope of this book, we can only summarize
the basic ideas here. For more details, you can consult a standard textbook
on algebraic topology, such as [Bre93, Mun84, Spa89]. (See also [Lee00,
Chapter 13] for a more concise treatment.)
Suppose v0, . . . , vp are any p + 1 points in some Euclidean space Rn.
They are said to be in general position if they are not contained in any
(p −1)-dimensional aﬃne subspace. A geometric p-simplex is a subset of
Rn of the form
 X
i=0
tivi : 0 ≤ti ≤1 and
k
X
i=0
ti = 1

,
for some (p + 1)-tuple (v0, . . . , vp) in general position. The points vi are
called the vertices of the simplex, and the geometric simplex with vertices
v0, . . . , vp is denoted by ⟨v0, . . . , vp⟩. It is a compact convex set, in fact the
smallest convex set containing {v0, . . . , vp}. The standard p-simplex is the
simplex ∆p = ⟨e0, e1, . . . , ep⟩⊂Rp, where e0 = 0 and ei is the ith standard
basis vector. For example, ∆0 = {0}, ∆1 = [0, 1], and ∆2 is the triangle
with vertices (0, 0), (1, 0), and (0, 1).
Exercise 11.4.
Show that a geometric p-simplex is a p-dimensional
smooth manifold with corners smoothly embedded in Rn.

292
11. De Rham Cohomology
Let M be a topological space. A continuous map σ: ∆p →M is called
a singular p-simplex in M. The singular chain group of M in dimension
p, denoted by Cp(M), is the free abelian group generated by all singular
p-simplices in M. An element of this group, called a singular p-chain, is
just a ﬁnite formal linear combination of singular p-simplices with integer
coeﬃcients.
One special case that arises frequently is that in which the space M is a
convex subset of some Euclidean space Rm. In that case, for any ordered
(p + 1)-tuple of points (w0, . . . , wp) in M (not necessarily in general po-
sition), there is a unique aﬃne map from Rp to Rm that takes ei to wi
for i = 0, . . . , p. The restriction of this aﬃne map to ∆p is denoted by
α(w0, . . . , wp), and is called an aﬃne singular simplex in M.
For each i = 0, . . . , p, we deﬁne the ith face map in ∆p to be the aﬃne
singular (p −1)-simplex Fi,p : ∆p−1 →∆p deﬁned by
Fi,p = α(e0, . . . , bei, . . . , ep).
(As usual, the hat indicates that ei is omitted.) It maps ∆p−1 homeomor-
phically onto the (p−1)-dimensional boundary face of ∆p opposite ei. The
boundary of a singular p-simplex σ: ∆p →M is the singular (p −1)-chain
∂σ deﬁned by
∂σ =
p
X
i=0
(−1)iσ ◦Fi,p.
This extends uniquely to a group homomorphism ∂: Cp(M) →Cp−1(M),
called the singular boundary operator. The basic fact about the boundary
operator is the following lemma.
Lemma 11.24. If c is any singular chain, then ∂(∂c) = 0.
Proof. The starting point is the fact that
Fi,p ◦Fj,p−1 = Fj,p ◦Fi−1,p−1
(11.14)
when i > j, which can be veriﬁed by following what both compositions do
to each of the vertices of ∆p−2. Using this, the proof of the lemma is just
a straightforward computation.
A singular p-chain c is called a cycle if ∂c = 0, and a boundary if c = ∂b
for some singular (p + 1)-chain b. Let Zp(M) denote the set of singular
p-cycles in M, and Bp(M) the set of singular p-boundaries. Because ∂is a
homomorphism, Zp(M) and Bp(M) are subgroups of Cp(M), and because
∂◦∂= 0, Bp(M) ⊂Zp(M). The pth singular homology group of M is the
quotient group
Hp(M) = Zp(M)
Bp(M).

Singular Homology and Cohomology
293
To put it another way, the sequence of abelian groups and homomorphisms
· · · →Cp+1(M)
∂−→Cp(M)
∂−→Cp−1(M) →· · ·
is a complex, called the singular chain complex, and Hp(M) is the homology
of this complex.
Any
continuous
map
F : M
→
N
induces
a
homomorphism
F# : Cp(M) →Cp(N) on each singular chain group, deﬁned by F#(σ) =
σ ◦F for any singular simplex σ and extended by linearity to chains.
An easy computation shows that F ◦∂= ∂◦F, so F is a chain map,
and therefore induces a homomorphism on singular homology, denoted
by F∗: Hp(M) →Hp(N). It is immediate that (G ◦F)∗= G∗◦F∗and
(IdM)∗= IdHp(M), so singular homology deﬁnes a covariant functor from
the category of topological spaces and continuous maps to the category of
abelian groups and homomorphisms. In particular, homeomorphic spaces
have isomorphic singular homology groups.
Proposition 11.25 (Properties of Singular Homology).
(a) For any one-point space {q}, H0({q}) is the inﬁnite cyclic group gen-
erated by the cohomology class of the unique singular 0-simplex map-
ping ∆0 to q, and Hp({q}) = 0 for all p ̸= 0.
(b) Let {Mj} be any collection of topological spaces, and let M = `
j Mj.
The inclusion maps ιj : Mj ,→M induce an isomorphism from
⊕jHp(Mj) to Hp(M).
(c) Homotopy equivalent spaces have isomorphic singular homology
groups.
Sketch of Proof. In a one-point space {q}, there is exactly one singular p-
simplex for each p, namely the constant map. The result of part (a) follows
from an analysis of the boundary maps. Part (b) is immediate because the
maps ιj already induce an isomorphism on the chain level: ⊕jCp(Mj) ∼=
Cp(M).
The main step in the proof of homotopy invariance is the construction
for any space M of a linear map h: Cp(M) →Cp+1(M × I) satisfying
h ◦∂+ ∂◦h = (i1)# −(i0)#,
(11.15)
where ιj : M →M × I is the injection ιj(x) = (x, j). From this it follows
just as in the proof of Proposition 11.5 that homotopic maps induce the
same homology homomorphism, and then in turn that homotopy equivalent
spaces have isomorphic singular cohomology groups.
In addition to the properties above, singular homology satisﬁes the fol-
lowing version of the Mayer–Vietoris theorem. Suppose M is a topological

294
11. De Rham Cohomology
space and U, V ⊂M are open subsets whose union is M. The usual diagram
(11.7) of inclusions induces homology homomorphisms:
j∗@
@@
R
Hp(U)
Hp(U ∩V )
i∗
   
Hp(V )
l∗
   
Hp(M).
k∗
@
@@
R
(11.16)
Theorem 11.26 (Mayer–Vietoris for Singular Homology).
Let M
be a topological space and let U, V be open subsets of M whose union is M.
For each p there is a homomorphism ∂∗: Hp(M) →Hp−1(U ∩V ) such that
the following sequence is exact:
· · ·
∂∗
−→Hp(U ∩V )
α
−→Hp(U) ⊕Hp(V )
β
−→Hp(M)
∂∗
−→Hp−1(U ∩V )
α
−→· · · ,
(11.17)
where
α[c] = (i∗[c], −j∗[c]),
β([c], [c′]) = k∗[c] + l∗[c′],
and ∂∗[e] = [c] provided there exist d ∈Hp(U) and d′ ∈Hp(V ) such that
k∗d + l∗d′ is homologous to e and
(i∗c, −j∗c) = (∂d, ∂d′).
Sketch of Proof.
The basic idea, of course, is to construct a short exact
sequence of complexes and use the zigzag lemma. The hardest part of the
proof is showing that any homology class [e] ∈Hp(M) can be represented in
the form [k∗d−l∗d′], where d and d′ are chains in U and V , respectively.
Note that the maps α and β in this Mayer–Vietoris sequence can be
replaced by
eα[c] = (i∗[c], j∗[c]),
eβ([c], [c′]) = k∗[c] −l∗[c′],
and the same proof goes through. We have chosen the deﬁnition given
in the statement of the theorem because it leads to a cohomology exact
sequence that is compatible with the Mayer–Vietoris sequence for de Rham
cohomology; see the proof of the de Rham theorem below.

Singular Homology and Cohomology
295
Singular Cohomology
In addition to the singular homology groups, for any abelian group G one
can deﬁne a closely related sequence of groups Hp(M; G) called the sin-
gular cohomology groups with coeﬃcients in G. The precise deﬁnition is
unimportant for our purposes; we will only be concerned with the spe-
cial case G = R, in which case it can be shown that Hp(M; R) is a real
vector space that is isomorphic to the space Hom(Hp(M), R) of group
homomorphisms from Hp(M) into R. (If you like, you can take this as
a deﬁnition of Hp(M, R).) Any continuous map F : M →N induces a
linear map F ∗: Hp(N; R) →Hp(M; R) by (F ∗γ)[c] = γ(F∗[c]) for any
γ ∈Hp(N; R) ∼= Hom(Hp(M), R) and any singular p-chain c. The functo-
rial properties of F∗carry over to cohomology: (G ◦F)∗= F ∗◦G∗and
(IdM)∗= IdHp(M;R).
The following properties of the singular cohomology groups follow easily
from the deﬁnitions and Proposition 11.25.
Proposition 11.27 (Properties of Singular Cohomology).
(a) For any one-point space {q}, Hp({q}; R) is trivial except when p = 0,
in which case it is one-dimensional.
(b) If {Mj} is any collection of topological spaces and M = `
j Mj, then
Hp(M; R) ∼= Q
j Hp(Mj; R).
(c) Homotopy equivalent spaces have isomorphic singular homology
groups.
The key fact about the singular cohomology groups that we will need is
that they too satisfy a Mayer–Vietoris theorem.
Theorem 11.28 (Mayer–Vietoris for Singular Cohomology).
Suppose M, U, and V satisfy the hypotheses of Theorem 11.26. For each
p there is a homomorphism ∂∗: Hp(U ∩V ; R) →Hp+1(M; R) such that
the following sequence is exact:
· · ·
δ−→Hp(M; R)
k∗⊕l∗
−−−−→Hp(U; R) ⊕Hp(V ; R)
i∗−j∗
−−−−→Hp(U ∩V ; R)
δ−→Hp+1(M; R)
k∗⊕l∗
−−−−→· · · ,
(11.18)
where the maps k∗⊕l∗and i∗−j∗are deﬁned as in (11.9), and ∂∗γ = γ◦∂∗,
with ∂∗as in Theorem 11.26.
Sketch of Proof. For any homomorphism F : A →B between abelian
groups, there is a dual homomorphism F ∗: Hom(B, R) →Hom(A, R) given
by F ∗γ = γ ◦F. Applying this to the Mayer–Vietoris sequence (11.17) for
singular homology, we obtain the cohomology sequence (11.18). The exact-
ness of the resulting sequence is a consequence of the fact that the functor

296
11. De Rham Cohomology
A 7→Hom(A, R) is exact, meaning that it takes exact sequences to exact
sequences. This in turn follows from the fact that R is an injective group:
Whenever H is a subgroup of an abelian group G, every homomorphism
from H into R extends to all of G.
Smooth Singular Homology
The connection between singular and de Rham cohomology will be estab-
lished by integrating diﬀerential forms over singular chains. More precisely,
given a singular p-simplex σ in a manifold M and a p-form on M, we would
like to pull ω back by σ and integrate the resulting form over ∆p. However,
there is an immediate problem with this approach, because forms can only
be pulled back by smooth maps, while singular simplices are in general only
continuous. (Actually, since only ﬁrst derivatives of the map appear in the
formula for the pullback, it would be suﬃcient to consider C1 maps, but
merely continuous ones deﬁnitely will not do.) In this section we overcome
this problem by showing that singular homology can be computed equally
well with smooth simplices.
If M is a smooth manifold, a smooth p-simplex in M is a smooth map
σ: ∆p →M. The subgroup of Cp(M) generated by smooth simplices is
denoted by C∞
p (M) and called the smooth chain group in dimension p; ele-
ments of this group, which are ﬁnite formal linear combinations of smooth
simplices, are called smooth chains. Because the boundary of a smooth
simplex is a smooth chain, we can deﬁne the pth smooth singular homology
group of M to be the quotient group
H∞
p (M) = Ker[∂: C∞
p (M) →C∞
p−1(M)]
Im[∂: C∞
p+1(M) →C∞
p (M)] .
The inclusion map ι: C∞
p (M) ,→Cp(M) obviously commutes with the
boundary operator, and so induces a map on homology: ι∗: H∞
p (M) →
Hp(M).
Theorem 11.29. For any smooth manifold M, the map ι∗: H∞
p (M) →
Hp(M) induced by inclusion is an isomorphism.
Proof. [Author’s note: This proof still needs to be written. The basic idea
is to construct, with the help of the Whitney approximation theorem, a
smoothing operator s: Cp(M) →C∞
p (M) such that s ◦∂= ∂◦s and s ◦ι
is the identity on C∞
p (M), and a homotopy operator that shows that ι ◦s
induces the identity map on Hp(M).]

The de Rham Theorem
297
The de Rham Theorem
In this section we will state and prove the de Rham theorem. Before getting
to the theorem itself, we need one more algebraic lemma. Its proof is another
diagram chase like the proof of the zigzag lemma.
Lemma 11.30 (The Five Lemma).
Consider the following commuta-
tive diagram of modules and linear maps:
A1
-
α1
A2
-
α2
A3
A4
-
α3
A5
-
α4
?
f1
?
f2
?
f3
?
f4
?
f5
B1
-
β1
B2
-
β2
B3
B4
-
β3
B5.
-
β4
If the horizontal rows are exact and f1, f2, f4, and f5 are isomorphisms,
then f3 is also an isomorphism.
Exercise 11.5.
Prove (or look up) this lemma.
Suppose M is a smooth manifold, ω is a closed p-form on M, and σ is a
smooth p-simplex in M. We deﬁne the integral of ω over σ to be
Z
σ
ω =
Z
∆p
σ∗ω.
This makes sense because ∆p is a smooth p-submanifold with corners em-
bedded in Rp, and inherits the orientation of Rp. (Or we could just consider
∆p as a domain of integration in Rp.) (When p = 1, this is the same as
the line integral of ω over the smooth curve segment σ: [0, 1] →M.) If
c = Pk
i=1 ciσi is a smooth p-chain, the integral of ω over c is deﬁned as
Z
c
ω =
k
X
i=1
ci
Z
σi
ω.
Theorem 11.31 (Stokes’s Theorem for Chains).
If c is a smooth p-
chain in a smooth manifold M, and ω is a (p −1)-form on M, then
Z
∂c
ω =
Z
c
dω.
Proof. It suﬃces to prove the theorem when c is just a smooth simplex σ.
Since ∆p is a manifold with corners, Stokes’s theorem says
Z
σ
dω =
Z
∆p
σ∗dω =
Z
∆p
dσ∗ω =
Z
∂∆p
σ∗ω.
The maps {Fi,p : 0 = 1, . . . , p} are parametrizations of the boundary faces
of ∆p satisfying the conditions of Proposition 10.30, except possibly that

298
11. De Rham Cohomology
they might not be orientation preserving. To check the orientations, note
that Fi,p is the restriction to ∆p ∩∂Hp of the aﬃne diﬀeomorphism sending
⟨e0, . . . , ep⟩to ⟨e0, . . . , bei, . . . , ep, ei⟩. This is easily seen to be orientation
preserving if and only if (e0, . . . , bei, . . . , ep, ei) is an even permutation of
(e0, . . . , ep), which is the case if and only if p−i is even. Since the standard
coordinates on ∂Hp are positively oriented if and only if p is even, the
upshot is that Fi,p is orientation preserving for ∂∆p if and only if i is even.
Thus, by Proposition 10.30.
Z
∂∆p
σ∗ω =
p
X
i=0
(−1)i
Z
∆p−1
F ∗
i,pσ∗ω
=
p
X
i=0
(−1)i
Z
∆p−1
(σ ◦Fi,p)∗ω
=
p
X
i=0
(−1)i
Z
σ◦Fi,p
ω.
By deﬁnition of the singular boundary operator, this is equal to
R
∂σ ω.
Using this theorem, we can deﬁne a natural linear map I: Hp
dR(M) →
Hp(M; R), called the de Rham homomorphism, as follows. For any [ω] ∈
Hp
dR(M) and [c] ∈Hp(M) ∼= H∞
p (M), we deﬁne
I[ω][c] =
Z
ec
ω,
(11.19)
where ec is any smooth p-cycle representing the homology class [c]. This is
well-deﬁned, because if ec is the boundary of a smooth (p −1)-chain eb, then
Z
ec
ω =
Z
∂eb
ω =
Z
eb
dω = 0,
while if ω = dη is exact, then
Z
ec
ω =
Z
ec
dη =
Z
∂ec
ω = 0.
(Note that ∂ec = 0 and dω = 0 because they represent a homology class
and a cohomology class, respectively.) Clearly I[ω][c+c′] = I[ω][c]+I[ω][c′],
and the resulting homomorphism I[ω]: Hp(M) →R depends linearly on ω.
Thus I[ω] is a well-deﬁned element of Hom(Hp(M), R), which we identify
with Hp(M; R).

The de Rham Theorem
299
Lemma 11.32. If F : M →N is a smooth map, then the following dia-
gram commutes:
Hp(N;R)
Hp(M;R).
-
F ∗
Hp
dR(N)
Hp
dR(M)
-
F ∗
?
I
?
I
Proof. Directly from the deﬁnitions, if σ is a smooth p-simplex in M and
ω is a p-form on N,
Z
σ
F ∗ω =
Z
∆p
σ∗F ∗ω =
Z
∆p
(F ◦σ)∗ω =
Z
F ◦σ
ω.
This is equivalent to I(F ∗[ω])[σ] = I[ω](F∗[σ]).
Lemma 11.33. If M is a smooth manifold and U, V are open subsets of
M whose union is M, then the following diagram commutes:
Hp−1(U ∩V ;R)
Hp(M;R),
-
∂∗
Hp−1
dR (U ∩V )
Hp
dR(M)
-
δ
?
I
?
I
(11.20)
where δ and ∂∗are the connecting homomorphisms of the Mayer–Vietoris
sequences for de Rham and singular cohomology, respectively.
Proof. Identifying Hp(M; R) with Hom(Hp(M), R) as usual, commutativ-
ity of (11.20) reduces to the following equation for any [ω] ∈Hp−1
dR (U ∩V )
and any [e] ∈Hp(M):
I(δ[ω])[e] = (∂∗I[ω])[e] = I[ω](∂∗[e]).
If σ is a (p −1)-form representing δ[ω] and [c] is a p-chain representing
∂∗[e], this is the same as
Z
e
σ =
Z
c
ω.
By the characterizations of δ and ∂∗given in Corollary 11.22 and Theorem
11.26, we can choose σ = dη (extended by zero to all of M), where η ∈
Ap(U) and η′ ∈Ap(U) are forms such that ω = η|U∩V −η′|U∩V ; and c = ∂d,
where d, d′ are smooth simplices in U and V , respectively, such that d + d′
represents the same homology class as e. Then, because ∂d + ∂d′ = ∂e = 0

300
11. De Rham Cohomology
and dη|U∩V −dη′|U∩V = dω = 0, we have
Z
c
ω =
Z
∂d
ω
=
Z
∂d
η −
Z
∂d
η′
=
Z
∂d
η +
Z
∂d′ η′
=
Z
d
dη +
Z
d′ dη′
=
Z
d
σ +
Z
d′ σ
=
Z
e
σ.
Thus the diagram commutes.
Theorem 11.34 (de Rham).
For any smooth manifold M and any
p ≥0, the de Rham homomorphism I: Hp
dR(M) →Hp(M; R) is an iso-
morphism.
Proof. Let us say that a smooth manifold M is a de Rham manifold if the
de Rham homomorphism I: Hp
dR(M) →Hp(M; R) is an isomorphism for
each p. Since the de Rham homomorphism commutes with the cohomol-
ogy maps induced by smooth maps (Lemma 11.32), any manifold that is
diﬀeomorphic to a de Rham manifold is also de Rham. The theorem will
be proved once we show that every smooth manifold is de Rham.
If M is any smooth manifold, an open cover {Ui} of M is called a de
Rham cover if each open set Ui is a de Rham manifold, and every ﬁnite
intersection Ui1 ∩· · · ∩Uik is de Rham. A de Rham cover that is also a
basis for the topology of M is called a de Rham basis for M.
Step 1: If {Mj} is any countable collection of de Rham manifolds, then
their disjoint union is de Rham. By Propositions 11.8 and 11.27(c), for
both de Rham and singular cohomology, the inclusions ιj : Mj ,→`
j Mj
induce isomorphisms between the cohomology groups of the disjoint union
and the direct product of the cohomology groups of the manifolds Mj. By
Lemma 11.32, I respects these isomorphisms.
Step 2: Every convex open subset of Rn is de Rham. Let U be such
a subset. By the Poincar´e lemma, Hp
dR(U) is trivial when p ̸= 0. Since
U is homotopy equivalent to a one-point space, Proposition 11.27 implies
that the singular cohomology groups of U are also trivial for p ̸= 0. In the
p = 0 case, H0
dR(U) is the one-dimensional space consisting of the constant
functions, and H0(U; R) = Hom(H0(U), R) is also one-dimensional because
H0(U) is spanned by any singular 0-simplex. If σ: ∆0 →M is a 0-simplex

The de Rham Theorem
301
(which is smooth because any map from a 0-manifold is smooth), and f is
the constant function equal to 1, then
I[f][σ] =
Z
∆0
σ∗f = (f ◦σ)(0) = 1.
This shows that I: H0
dR(U) →H0(U; R) is not the zero map, so it is an
isomorphism.
Step 3: If M has a ﬁnite de Rham cover, then M is de Rham. Suppose
M = U1 ∪· · · ∪Uk, where the open sets Ui and their ﬁnite intersections are
de Rham. We will prove the result by induction on k. Suppose ﬁrst that M
has a de Rham cover consisting of two sets {U, V }. Putting together the
Mayer–Vietoris sequences for de Rham and singular cohomology, we obtain
the following commutative diagram in which the horizontal rows are exact
and the vertical maps are all given by de Rham homomorphisms:
Hp−1
dR (U) ⊕Hp−1
dR (V )
- Hp−1
dR (U ∩V )
Hp
dR(M)
-
-
?
?
?
Hp−1(U;R) ⊕Hp−1(V ;R) - Hp−1(U ∩V ;R)
Hp(M;R)
-
-
Hp
dR(U) ⊕Hp
dR(V )
Hp
dR(U ∩V )
-
?
?
Hp(U;R) ⊕Hp(V ;R)
Hp(U ∩V ;R).
-
The commutativity of the diagram is an immediate consequence of Lemmas
11.32 and 11.33. By hypothesis the ﬁrst, second, fourth, and ﬁfth vertical
maps are all isomorphisms, so by the ﬁve lemma the middle map is an
isomorphism, which proves that M is de Rham.
Now assume the claim is true for smooth manifolds admitting a de Rham
cover with k ≥2 sets, and suppose {U1, . . . , Uk+1} is a de Rham cover of
M. Put U = U1 ∪· · · ∪Uk and V = Uk+1. The hypothesis implies that U
and V are de Rham, and so is U ∩V because it has a k-fold de Rham cover
given by {U1 ∩Uk+1, . . . , Uk ∩Uk+1}. Thus M = U ∪V is also de Rham by
the argument above.
Step 4: If M has a de Rham basis, then M is de Rham. Suppose {Uα}
is a de Rham basis for M. Let f : M →R be a continuous proper function,
such as the one constructed in the proof of the Whitney embedding theorem
(Theorem 6.12). For each integer m, deﬁne subsets Am and A′
m of M by
Am = {q ∈M : m ≤f(q) ≤m + 1},
A′
m = {q ∈M : m −1
2 < f(q) < m + 1 + 1
2}.
For each point q ∈Am, there is a basis open set containing q and contained
in A′
m. The collection of all such basis sets is an open cover of Am. Since
f is proper, Am is compact, and therefore it is covered by ﬁnitely many of

302
11. De Rham Cohomology
these basis sets. Let Bm be the union of this ﬁnite collection of sets. This
is a ﬁnite de Rham cover of Bm, so by Step 3, Bm is de Rham.
Observe that Bm ⊂A′
m, so Bm intersects B e
m nontrivially only when
em = m −1, m, or m + 1. Therefore, if we deﬁne
U =
[
m odd
Bm,
then U is de Rham by Step 1, because it is the disjoint union of the de
Rham manifolds Bm. Similarly,
V =
[
m even
Bm
is de Rham. Finally, M = U ∪V is de Rham by Step 3.
Step 5: Any open subset of Rn is de Rham. If U ⊂Rn is such a subset,
then U has a basis consisting of Euclidean balls. Because each ball is convex,
it is de Rham, and because any ﬁnite intersection of balls is again convex,
ﬁnite intersections are also de Rham. Thus U has a de Rham basis, so it is
de Rham by Step 4.
Step 6: Every smooth manifold is de Rham. Any smooth manifold has a
basis of coordinate domains. Since every coordinate domain is diﬀeomorphic
to an open subset of Rn, as are ﬁnite intersections of coordinate domains,
this is a de Rham basis. The claim therefore follows from Step 4.
This result expresses a deep connection between the topological and ana-
lytic properties of a smooth manifold, and plays a central role in diﬀerential
geometry. If one has some information about the topology of a manifold
M, the de Rham theorem can be used to draw conclusions about solutions
to diﬀerential equations such as dη = ω on M. Conversely, if one can prove
that such solutions do or do not exist, then one can draw conclusions about
the topology.

Problems
303
Problems
11-1. Let M be a smooth manifold, and ω ∈Ap(M), η ∈Aq(M). Show
that the de Rham cohomology class of ω ∧η depends only on the de
Rham cohomology classes of ω and η, and thus there is a well-deﬁned
bilinear map ∪: Hp
dR(M) × Hq
dR(M) →Hp+q
dR (M) given by
[ω] ∪[η] = [ω ∧η].
(This bilinear map is called the cup product.)
11-2. Let M be an orientable smooth manifold and suppose ω is a closed
p-form on M.
(a) Show that ω is exact if and only if the integral of ω over every
smooth p-cycle is zero.
(b) Now suppose that Hp(M) is generated by the homology classes
of ﬁnitely many smooth p-cycles {c1, . . . , cm}. The numbers
P1(ω), . . . , Pm(ω) deﬁned by
Pi =
Z
ci
ω
are called the periods of ω with respect to this set of generators.
Show that ω is exact if and only if all of its periods are zero.
11-3. Let M be a smooth n-manifold and suppose S ⊂M is an immersed,
compact, oriented, p-dimensional submanifold. A smooth triangula-
tion of S is a smooth p-cycle c = P
i niσi in M with the following
properties:
• Each σi is an orientation-preserving embedding of ∆p into S.
• If i ̸= j, then σi(Int ∆p) ∩σj(Int ∆p) = ∅.
• S = S
i σi(∆p).
(It can be shown that every smooth orientable submanifold admits
a smooth triangulation, but we will not use that fact.) Two p-
dimensional submanifolds S, S′ ⊂M are said to be homologous if
there exist smooth triangulations c for S and c′ for S′ such that c−c′
is a boundary.
(a) If c is a smooth triangulation of S and ω is any p-form on M,
show that
R
c ω =
R
S ω.
(b) If ω is closed and S, S′ are homologous, show that
R
S ω =
R
S′ ω.

304
11. De Rham Cohomology
11-4. Suppose (M, g) is a Riemannian n-manifold. A p-form ω on M is
called a calibration if ω is closed and ωq(X1, . . . , Xp) ≤1 whenever
(X1, . . . , Xp) are orthonormal vectors in some tangent space TqM.
A smooth submanifold S ⊂M is said to be calibrated if there is a
calibration ω such that ω|S is the volume form for the induced Rie-
mannian metric on S. If S ⊂M is a smoothly triangulated calibrated
submanifold, show that the volume of S (with respect to the induced
Riemannian metric) is less than or equal to that of any other subman-
ifold homologous to S. (Calibrations were invented in 1985 by Reese
Harvey and Blaine Lawson [HL82]; they have become increasingly
important in recent years because in many situations a calibration is
the only known way of proving that a given submanifold is volume
minimizing in its homology class.)
11-5. Let D ⊂R3 be the torus of revolution obtained by revolving the circle
(x −2)2 + z2 = 1 around the z-axis, with the induced Riemannian
metric. Show that the inner circle {(x, y, z) : z = 0, x2 + y2 = 1}
is calibrated, and therefore has the shortest length in its homology
class.
11-6. Let M be a compact, connected, orientable, smooth n-manifold, and
let p be any point of M. Let V be a neighborhood of p diﬀeomorphic
to Rn and let U = M ∖{p}.
(a) Show that the connecting homomorphism δ: Hn−1
dR (U ∩V ) →
Hn
dR(M) is an isomorphism. [Hint: Consider the (n −1)-form ω
on U ∩V ≈Rn ∖{0} deﬁned in coordinates by (10.18) (Problem
10-10).]
(b) Use the Mayer–Vietoris sequence of {U, V } to show that
Hn
dR(M ∖{p}) = 0.
11-7. Let M be a compact, connected, smooth manifold of dimension
n ≥3. For any p ∈M and 0 ≤k < n, show that the map
Hk
dR(M) →Hk
dR(M ∖{p}) induced by inclusion M ∖{p} ,→M
is an isomorphism. [Hint: Use a Mayer–Vietoris sequence together
with the result of Problem 11-6. The cases k = 1 and k = n −1 will
require special handling.]
11-8. Let M1, M2 be smooth, connected, orientable manifolds of dimension
n ≥2, and let M1#M2 denote their smooth connected sum (see
Problem 5-20). Show that Hk
dR(M1#M2) ∼= Hk
dR(M1)⊕Hk
dR(M2) for
0 < k < n.
11-9. Suppose (M, ω) is a 2n-dimensional symplectic manifold.
(a) Show that ωn = ω ∧· · · ∧ω (the n-fold wedge product of ω with
itself) is not exact. [Hint: See Problem 10-21.]

Problems
305
(b) Show that H2k
dR(M) ̸= 0 for k = 1, . . . , n.
(c) Show that the only sphere that admits a symplectic structure is
S2.

306
11. De Rham Cohomology

12
Integral Curves and Flows
In this chapter, we begin to explore vector ﬁelds in more depth. The primary
objects associated with vector ﬁelds are “integral curves,” which are smooth
curves whose tangent vector at each point is equal to the value of the
vector ﬁeld there. We will show in this chapter that a vector ﬁeld on a
manifold determines a unique integral curve through each point; the proof
is an application of the existence and uniqueness theorem for solutions of
ordinary diﬀerential equations.
The collection of all integral curves of a given vector ﬁeld on a manifold
determines a family of diﬀeomorphisms of (open subsets of) the manifold,
called a “ﬂow.” Any smooth R-action is a ﬂow, for example; but we will
see that there are ﬂows that are not R-actions because the diﬀeomorphisms
may not be deﬁned for all t ∈R or all points in the manifold.
In subsequent chapters, we will begin to study some of the profound
applications of these ideas.
Integral Curves
A smooth curve γ : J →M determines a tangent vector γ′(t) ∈Tγ(t)M at
each point of the curve. In this section we describe a way to work backwards:
Given a tangent vector at each point, we seek a curve that has those tangent
vectors.
Let M be a smooth manifold and let V be a smooth vector ﬁeld on M.
An integral curve of V is a smooth curve γ : J →M deﬁned on an open

308
12. Integral Curves and Flows
interval J ⊂R such that
γ′(t) = Vγ(t)
for all t ∈J.
In other words, the tangent vector to γ at each point is equal to the value
of V at that point. If 0 ∈J, the point p = γ(0) is called the starting point
of γ. (The reason for the term “integral curve” will be explained shortly.)
Example 12.1 (Integral Curves).
(a) Let V = ∂/∂x be the ﬁrst coordinate vector ﬁeld on R2. It is easy to
check that any curve of the form γ(t) = (t + a, b) for constants a and
b is an integral curve of V , satisfying γ(0) = (a, b). Thus there is an
integral curve passing through each point of the plane.
(b) Let W = x ∂/∂x + y ∂/∂y on R2. If γ : R →R2 is a smooth curve,
written in standard coordinates as γ(t) = (x(t), y(t)), then the con-
dition γ′(t) = Wγ(t) for γ to be an integral curve translates to
x′(t) ∂
∂x

(x(t),y(t))
+ y′(t) ∂
∂y

(x(t),y(t))
= x(t) ∂
∂x

(x(t),y(t))
+ y(t) ∂
∂y

(x(t),y(t))
.
Comparing the components of these vectors, this is equivalent to the
pair of ordinary diﬀerential equations
x′(t) = x(t),
y′(t) = y(t).
These equations have the solutions x(t) = aet and y(t) = bet
for arbitrary constants a and b, and thus each curve of the form
γ(t) = (aet, bet) is an integral curve of W. Since γ(0) = (a, b), we see
once again that there is an integral curve passing through each point
(a, b) ∈R2
As the second example above illustrates, ﬁnding integral curves boils
down to solving a system of ordinary diﬀerential equations in a coordinate
chart. More generally, let γ : J →M be any smooth curve. Writing γ in
local coordinates as γ(t) = (γ1(t), . . . , γn(t)), the condition γ′(t) = Vγ(t)
that γ be an integral curve of a smooth vector ﬁeld V can be written in
local coordinates on an open set U as
(γi)′(t)
∂
∂xi

γ(t)
= V i(γ(t))
∂
∂xi

γ(t)
,

Flows
309
which reduces to the system of ordinary diﬀerential equations (ODEs)
(γ1)′(t) = V 1(γ1(t), . . . , γn(t)),
. . .
(γn)′(t) = V n(γ1(t), . . . , γn(t)),
where the component functions V i are smooth on U. The fundamental
fact about such systems, which we will state precisely and prove later
in the chapter, is that there is a unique solution, at least for t in a
small time interval (−ε, ε), satisfying any initial condition of the form
(γ1(0), . . . , γn(0)) = (a1, . . . , an) for (a1, . . . , an) ∈U. (This the reason
for the terminology “integral curves,” because solving a system of ODEs
is often referred to as “integrating” the system.) For now, we just note
that this implies there is a unique integral curve, at least for a short time,
starting at any point in the manifold. Moreover, we will see that up to
reparametrization, there is a unique integral curve passing through each
point.
The following simple lemma shows how an integral curve can be repara-
metrized to change its starting point.
Lemma 12.2 (Translation Lemma). Let V be a smooth vector ﬁeld on
a smooth manifold M, let J ⊂R be an open interval containing 0, and let
γ : J →M be an integral curve of V . For any a ∈J, let eJ = {t ∈R :
t + a ∈J}. Then the curve eγ : eJ →M deﬁned by eγ(t) = γ(t + a) is an
integral curve of V starting at γ(a).
Proof. One way to see this is as a straightforward application of the chain
rule in local coordinates. Somewhat more invariantly, we can examine the
action of eγ′(t) on a smooth function f deﬁned in a neighborhood of a point
eγ(t0). By the chain rule and the fact that γ is an integral curve,
eγ′(t0)f = d
dt

t=t0
(f ◦eγ)(t)
= d
dt

t=t0
(f ◦γ)(t + a)
= (f ◦γ)′(t0 + a)
= γ′(t0 + a)f = Vγ(t0+a)f = Veγ(t0)f.
Thus eγ is an integral curve of V .
Flows
There is another way to visualize the family of integral curves associated
with a vector ﬁeld. Let V be a vector ﬁeld on a smooth manifold M, and

310
12. Integral Curves and Flows
suppose it has the property that for each point p ∈M there is a unique
integral curve θ(p) : R →M starting at p. (It may not always be the case
that all of the integral curves are deﬁned for all t ∈R, but for purposes of
illustration let us assume for the time being that they are.) For each t ∈R,
we can deﬁne a map θt from M to itself by sending each point p ∈M to
the point obtained by following the curve starting at p for time t:
θt(p) = θ(p)(t).
This deﬁnes a family of maps θt : M →M for t ∈R. If q = θ(p)(s), the
translation lemma implies that the integral curve starting at q satisﬁes
θ(q)(t) = θ(p)(t + s). When we translate this into a statement about the
maps θt, it becomes
θt ◦θs(p) = θt+s(p).
Together with the equation θ0(p) = θ(p)(0) = p, which holds by deﬁnition,
this implies that the map θ: R×M →M is an action of the additive group
R on M.
Motivated by these considerations, we deﬁne a global ﬂow on M (some-
times also called a one-parameter group action) to be a smooth left action
of R on M; that is, a smooth map θ: R × M →M satisfying the following
properties for all s, t ∈R and all p ∈M:
θ(t, θ(s, p)) = θ(t + s, p),
θ(0, p) = p.
(12.1)
Given a global ﬂow θ on M, we deﬁne two collections of maps as follows.
• For each t ∈R, deﬁne θt : M →M by
θt(p) = θ(t, p).
The deﬁning properties (12.1) are equivalent to the group laws:
θt ◦θs = θt+s,
θ0 = IdM .
(12.2)
As is the case for any smooth group action, each map θt : M →M is
a diﬀeomorphism.
• For each p ∈M, deﬁne a smooth curve θ(p) : R →M by
θ(p)(t) = θ(t, p).
The image of this curve is just the orbit of p under the group action.
Because any group action on a set partitions the set into disjoint
orbits, it follows that M is the disjoint union of the images of these
curves.

Flows
311
The next proposition shows that every global ﬂow arises as the set of
integral curves of some vector ﬁeld.
Proposition 12.3. Let θ: R × M →M be a global ﬂow. For each p ∈M,
deﬁne a tangent vector Vp ∈TpM by
Vp = θ(p)′(0) = ∂
∂t

t=0
θ(t, p).
The assignment p 7→Vp is a smooth vector ﬁeld on M, and each curve θ(p)
is an integral curve of V .
The vector ﬁeld V deﬁned in this proposition is called the inﬁnitesimal
generator of θ, for reasons we will explain below.
Proof. To show that V is smooth, it suﬃces to show that V f is smooth
for any smooth function f deﬁned on an open subset of M. For any such
function, just note that
V f(p) = Vpf = θ(p)′(0)f = d
dt

t=0
f(θ(p)(t)) = d
dt

t=0
f(θ(t, p)).
Because θ(t, p) depends smoothly on (t, p), so does f(θ(t, p)) by composi-
tion, and therefore so also does the derivative of f(θ(t, p)) with respect to
t. (You can interpret this derivative as the action of the smooth vector ﬁeld
∂/∂t on the smooth function f ◦θ: R × M →R.) If follows that V f(p)
depends smoothly on p, so V is smooth.
To show that θ(p) is an integral curve of V , we need to show that
θ(p)′(t) = Vθ(p)(t)
for all p ∈M and all t ∈R. Let t0 ∈R be arbitrary, and set q = θ(p)(t0) =
θt0(p), so that what we have to show is θ(p)′(t0) = Vq. By the group law,
for all t,
θ(q)(t) = θt(q)
= θt(θt0(p))
= θt+t0(p)
= θ(p)(t + t0).
Therefore, for any smooth function f deﬁned in a neighborhood of q,
Vqf = θ(q)′(0)f
= d
dt

t=0
f(θ(q)(t))
= d
dt

t=0
f(θ(p)(t + t0))
= θ(p)′(t0)f,

312
12. Integral Curves and Flows
which was to be shown.
Another important property of the inﬁnitesimal generator is that it is
invariant under the ﬂow, in the following sense. Let V be a smooth vector
ﬁeld on a smooth manifold M, and let F : M →M be a diﬀeomorphism.
We say that V is invariant under F if F∗V = V . Unwinding the deﬁnition
of the push-forward of a vector ﬁeld, this means that for each p ∈M,
F∗Vp = VF (p).
Proposition 12.4. Let θ be a global ﬂow on M and let V be its inﬁnites-
imal generator. Then V is invariant under θt for each t ∈R.
Proof. Let p ∈M and t0 ∈R be arbitrary, and set q = θt0(p). We need to
show that
(θt0)∗Vp = Vq.
Applying the left-hand side to a smooth function f deﬁned in a neighbor-
hood of q and using the deﬁnition of V , we obtain
(θt0 ∗Vp)f = Vp(f ◦θt0)
= d
dt

t=0
f ◦θt0 ◦θ(p)(t)
= d
dt

t=0
f(θt0(θt(p))
= d
dt

t=0
f(θt0+t(p))
= d
dt

t=0
f(θ(p)(t0 + t))
= θ(p)′(t0)f.
Since θ(p) is an integral curve of V , θ(p)′(t0) = Vq.
We have seen that every global ﬂow gives rise to a smooth vector ﬁeld
whose integral curves are precisely the curves deﬁned by the ﬂow. Con-
versely, we would like to be able to say that every smooth vector ﬁeld is
the inﬁnitesimal generator of a global ﬂow. However, it is easy to see that
this cannot be the case, because there are vector ﬁelds whose integral curves
are not deﬁned for all t ∈R, as the following examples show.
Example 12.5. Let M = {(x, y) ∈R2 : x < 0}, and let V = ∂/∂x. Rea-
soning as in Example 12.1(a), we see that the integral curve of V starting
at (a, b) ∈M is γ(t) = (t + a, b). However, in this case, γ is deﬁned only
for t < −a.

Flows
313
Example 12.6. For a somewhat more subtle example, let M be all of R2
and let W = x2∂/∂x. You can check easily that the unique integral curve
of W starting at (1, 0) is
γ(t) =

1
1 −t, 0

.
This curve is deﬁned only for t < 1.
For this reason, we make the following deﬁnitions. If M is a smooth
manifold, a ﬂow domain for M is an open subset D ⊂R × M with the
property that for each p ∈M, the set Dp = {t ∈R : (t, p) ∈D} is an open
interval containing 0. A ﬂow on M is a smooth map θ: D →M, where
D ⊂R × M is a ﬂow domain, that satisﬁes
θ(0, p) = p for all p ∈M,
θ(t, θ(s, p)) = θ(t + s, p) whenever s ∈Dp and t ∈Dθ(s,p).
We sometimes call θ a local ﬂow to distinguish it from a global ﬂow as
deﬁned earlier. The unwieldy term local one-parameter group action is also
commonly used.
If θ is a ﬂow, we deﬁne θt(p) = θ(p)(t) = θ(t, p) whenever (t, p) ∈D, just
as for a local ﬂow. Similarly, the inﬁnitesimal generator of θ is deﬁned by
Vp = θ(p)′(0).
Lemma 12.7 (Properties of Flows).
Let D be a ﬂow domain for M,
and let θ: D →M be a ﬂow.
(a) For each t ∈R, the set Mt = {p ∈M : (t, p) ∈D} is open in M, and
θt : Mt →M is a diﬀeomorphism onto an open subset of M.
(b) The following relation holds whenever the left-hand side is deﬁned:
θt ◦θs = θt+s.
(c) The inﬁnitesimal generator V of θ is a smooth vector ﬁeld.
(d) For each p ∈M, θ(p) : Dp →M is an integral curve of V starting at
p.
(e) For each t ∈R, θt∗V = V on the open set θt(Mt).
Exercise 12.1.
Prove Lemma 12.7.
Another important property of ﬂows is the following.
Lemma 12.8. Suppose θ is a ﬂow on M with inﬁnitesimal generator V ,
and p ∈M. If Vp = 0, then θ(p) is the constant curve θ(p)(t) ≡p. If Vp ̸= 0,
then θ(p) : Dp →M is an immersion.

314
12. Integral Curves and Flows
Proof. For simplicity, write γ = θ(p). Let t ∈Dp be arbitrary, and put
q = γ(t). Note that the push-forward γ∗: TtR →TqM is zero if and only
if γ′(t) = 0. Part (e) of Lemma 12.7 shows that Vq = θt∗Vp. Therefore
γ′(t) = Vq = 0 if and only if γ′(0) = Vp = 0; in other words, if γ′(t)
vanishes for some t ∈Dp it vanishes for all such t. Thus if Vp = 0, then γ
is a smooth map whose push-forward at each point is zero, which implies
that it is a constant map (because its domain is connected). On the other
hand, if Vp ̸= 0, then γ∗is nonzero, hence injective, at each point, so γ is
an immersion.
The Fundamental Theorem on Flows
In this section we will see that every smooth vector ﬁeld gives rise to a
ﬂow, which is unique if we require it to be maximal, which means that it
cannot be extended to any larger ﬂow domain.
Theorem 12.9 (Fundamental Theorem on Flows).
Let
V
be
a
smooth vector ﬁeld on a smooth manifold M. There is a unique maximal
ﬂow whose inﬁnitesimal generator is V .
The ﬂow whose existence is asserted in this theorem is called the ﬂow
generated by V .
The term “inﬁnitesimal generator” comes from the following picture. In
a local coordinate chart, a reasonably good approximation to the ﬂow can
be obtained by composing very many small aﬃne translations, with the
direction and length of each successive motion determined by the value
of the vector ﬁeld at the point arrived at in the previous step. Long ago,
mathematicians thought of a ﬂow as being composed of inﬁnitely many
inﬁnitesimally small linear steps.
As we saw earlier in this chapter, ﬁnding integral curves of V (and there-
fore ﬁnding the ﬂow generated by V ) boils down to solving a system of
ordinary diﬀerential equations, at least locally. Thus before beginning the
proof, let us state a basic theorem about solutions of ordinary diﬀerential
equations. We will give the proof of this theorem in the last section of the
chapter.
Theorem 12.10 (ODE Existence, Uniqueness, and Smoothness).
Let U ⊂Rn be open, and let V : U →Rn be a smooth map. For any
(t0, x0) ∈R × U and any suﬃciently small ε > 0, there exist an open set
U0 ⊂U containing x0 and a smooth map θ: (t0 −ε, t0 + ε) × U0 →U such
that for each x ∈U0, the curve γ(t) = θ(t, x) is the unique solution on
(t0 −ε, t0 + ε) to the initial-value problem
γi′(t) = V i(γ(t)),
γi(t0) = xi.

The Fundamental Theorem on Flows
315
Using this result, we now prove the fundamental theorem on ﬂows.
Proof of Theorem 12.9.
We begin by noting that the existence assertion
of the ODE theorem implies that there exists an integral curve starting at
each point p ∈M, because the equation for an integral curve is a system
of ODEs in any local coordinates around p.
Now suppose γ, eγ : J →M are two integral curves deﬁned on the same
open interval J such that γ(t0) = eγ(t0) for some t0 ∈J. Let S be the set
of t ∈J such that γ(t) = eγ(t). Clearly S is nonempty because t0 ∈S by
hypothesis, and it is closed in J by continuity. On the other hand, suppose
t1 ∈S. Then in a coordinate neighborhood around the point p = γ(t1),
γ and eγ are both solutions to same ODE with the same initial condition
γ(t1) = eγ(t1) = p. By the ODE theorem, there is a neighborhood (t1 −
ε, t1 + ε) of t1 on which there is a unique solution to this initial-value
problem. Thus γ ≡eγ on (t1 −ε, t1 + ε), which implies that S is open in J.
Since J is connected, S = J, which implies that γ = eγ on all of J. Thus any
two integral curves that agree at one point agree on their common domain.
For each p ∈M, let Dp be the union of all intervals J ⊂R containing 0
on which an integral curve starting at p is deﬁned. Deﬁne θ(p) : Dp →M
by letting θ(p)(t) = γ(t), where γ is any integral curve starting at p and
deﬁned on an open interval containing 0 and t. Since all such integral curves
agree at t by the argument above, θ(p) is well deﬁned, and is obviously the
unique maximal integral curve starting at p.
Now, let D(V ) = {(t, p) ∈R×M : t ∈Dp}, and deﬁne θ: D(V ) →M by
θ(t, p) = θ(p)(t). As usual, we also write θt(p) = θ(t, p). Clearly θ0 = IdM
by deﬁnition. We will verify that θ satisﬁes the group law
θt ◦θs(p) = θt+s(p)
(12.3)
whenever the left-hand side is deﬁned. Fix any s ∈Dp, and write q =
θs(p) = θ(p)(s). Deﬁne γ(t) = θt+s(p) = θ(p)(t + s) wherever the latter
is deﬁned. Then γ(0) = q, and the translation lemma shows that γ is
an integral curve of V . Thus by the uniqueness assertion above γ must be
equal to θ(q) wherever both are deﬁned, which shows that (12.3) holds when
both sides are deﬁned. Since both θ(p) and θ(q) are maximal, it follows that
t ∈Dq if and only if t+s ∈Dp; in particular, if the left-hand side of (12.3)
is deﬁned, then so is the right-hand side.
Next we will show that D(V ) is open in R×M and that θ: D(V ) →M is
smooth. This implies D(V ) is a ﬂow domain; since it is obviously maximal
by deﬁnition, this will complete the proof.
Deﬁne a subset W ⊂D(V ) as the set of all (t, p) ∈D(V ) such that θ
is deﬁned and smooth on a product open set J × U ⊂R × M, where J
is an open interval containing 0 and t. Clearly W is open in R × M and
the restriction of θ to W is smooth, so it suﬃces to show that W = D(V ).
Suppose this is not the case. Then there exists some point (t0, p0) ∈D(V )∖
W. For simplicity, let us assume t0 > 0; the argument for t0 < 0 is similar.

316
12. Integral Curves and Flows
Let τ = sup{t ∈R : (t, p0) ∈W}. By the ODE theorem (applied in
coordinates around p0), θ is deﬁned and smooth in some neighborhood of
(0, p0), so τ > 0. Let q0 = θ(p0)(τ). By the ODE theorem again, there is
some ε > 0 and a neighborhood U0 of q0 such that θ: (−ε, ε) × U0 →M
is deﬁned and smooth. We will use the group law to show that θ extends
smoothly to a neighborhood of (τ, p0), which contradicts our choice of τ.
Choose some t1 < τ such that t1 +ε > τ and θ(p0)(t1) ∈U0. Since t1 < τ,
(t1, p0) ∈W, and so there is a product neighborhood (−δ, t1 + δ) × U1 of
(t1, p0) on which θ is deﬁned and smooth. Because θ(t1, p0) ∈U0, we can
choose U1 small enough that θ maps {t1} × U1 into U0. Because θ satisﬁes
the group law, we have
θt(p) = θt−t1 ◦θt1(p)
whenever the right-hand side is deﬁned. By our choice of t1, θt1(p) is deﬁned
for p ∈U1, and depends smoothly on p. Moreover, since θt1(p) ∈U0 for
all such p, it follows that θt−t1 ◦θt1(p) is deﬁned whenever p ∈U1 and
|t −t1| < ε, and depends smoothly on (t, p). This gives a smooth extension
of θ to the product set (−δ, t1 + ε) × U1, which contradicts our choice of τ.
This completes the proof that W = D(V ).
Complete Vector Fields
As we noted above, not every vector ﬁeld generates a global ﬂow. The ones
that do are important enough to deserve a name. We say a vector ﬁeld is
complete if it generates a global ﬂow, or equivalently if each of its integral
curves is deﬁned for all t ∈R.
It is not always easy to determine by looking at a vector ﬁeld whether
it is complete or not. If you can solve the ODE explicitly to ﬁnd all of
the integral curves, and they all exist for all time, then the vector ﬁeld is
complete. On the other hand, if you can ﬁnd a single integral curve that
cannot be extended to all of R, as we did for the vector ﬁeld of Example
12.6, then it is not complete. However, it is often impossible to solve the
ODE explicitly, so it is useful to have some general criteria for determining
when a vector ﬁeld is complete.
In this section we will show that all vector ﬁelds on a compact manifold
are complete. (Problem 12-1 gives a more general suﬃcient condition.) The
proof will be based on the following lemma.
Lemma 12.11 (Escape Lemma).
Let M be a smooth manifold and let
V be a vector ﬁeld on M. If γ is an integral curve of V whose maximal
domain is not all of R, then the image of γ cannot lie in any compact subset
of M.
Proof. Suppose γ is deﬁned on a maximal domain of the form (a, b), and
assume that b < ∞. (The argument for the case a > −∞is similar.) We

Proof of the ODE Theorem
317
will show that if γ[0, b) lies in a compact set, then γ can be extended past
b, which is a contradiction.
Let p = γ(0) and let θ denote the ﬂow of V , so γ = θ(p) by the uniqueness
of integral curves. If {ti} is any sequence of times approaching b from below,
then the sequence {γ(ti)} lies in a compact subset of M, and therefore has
a subsequence converging to a point q ∈M. Choose a neighborhood U of
q and a positive number ε such that θ is deﬁned on (−ε, ε) × U. Pick some
i large enough that γ(ti) ∈U and ti > b −ε, and deﬁne σ: [0, ti + ε) →M
by
σ(t) =
(
γ(t),
0 ≤t < b,
θt−ti ◦θti(p),
ti −ε < t < ti + ε.
These two deﬁnitions agree where they overlap, because θt−ti ◦θti(p) =
θt(p) = γ(t) by the group law for θ. Thus σ is an integral curve extending
γ, which contradicts the maximality of γ. Therefore, γ[0, b) cannot lie in
any compact set.
Theorem 12.12. Suppose M is a compact manifold. Then every vector
ﬁeld on M is complete.
Proof. If M is compact, the escape lemma implies that no integral curve
can have a maximal domain that is not all of R, because the image of any
integral curve is contained in the compact set M.
Proof of the ODE Theorem
In this section we prove the ODE existence, uniqueness, and smoothness
theorem (Theorem 12.10). Actually, it will be useful to prove the existence
theorem under the somewhat weaker hypothesis that the vector ﬁeld is only
Lipschitz continuous (see the Appendix).
We will prove Theorem 12.10 in several parts: The uniqueness assertion
follows from the next theorem, existence from Theorem 12.13, and smooth-
ness from Theorem 12.16. Throughout this section, U ⊂Rn will be an open
set, and V : U →Rn will be a Lipschitz continuous map. For any t0 ∈R
and any x ∈U we will study the initial-value problem
γi′(t) = V i(γ(t)),
γi(t0) = xi.
(12.4)
Theorem 12.13 (Uniqueness of ODE Solutions). Any two solutions
to (12.4) are equal on their common domain.

318
12. Integral Curves and Flows
Proof. Suppose γ, eγ : J →U are two solutions to the ODE on the same
open interval J, not necessarily with the same initial conditions. The
Schwartz inequality and the Lipschitz estimate for V imply
d
dt|eγ(t) −γ(t)|2 = 2(eγ(t) −γ(t)) · (V (eγ(t)) −V (γ(t)))
≤2|eγ(t) −γ(t))| |V (eγ(t)) −V (γ(t))|
≤2C|eγ(t) −γ(t)|2.
It follows easily that
d
dt(e−2Ct|eγ(t) −γ(t)|2) ≤0,
and so
e−2Ct|eγ(t) −γ(t)|2 ≤e−2Ct0|eγ(t0) −γ(t0)|2,
t ≥t0.
Similarly, using the estimate
d
dt|eγ(t) −γ(t)|2 ≥−2C|eγ(t) −γ(t)|2,
we conclude that
e2Ct|eγ(t) −γ(t)|2 ≤e2Ct0|eγ(t0) −γ(t0)|2,
t ≤t0.
Putting these two estimates together, we obtain the following for all t ∈J:
|eγ(t) −γ(t)| ≤eC|t−t0||eγ(t0) −γ(t0)|.
(12.5)
Thus γ(t0) = eγ(t0) implies γ ≡eγ on all of J.
Theorem 12.14 (Existence of ODE Solutions). For each t0 ∈R and
x0 ∈U, there exist an open interval J0 containing t0, an open set U0 ⊂
U containing x0, and for each x ∈U0 a diﬀerentiable curve γ : J0 →U
satisfying the initial-value problem (12.4).
Proof. If γ is any continuous curve in U, the fundamental theorem of cal-
culus implies that γ is a solution to the initial-value problem (12.4) if and
only if it satisﬁes the integral equation
γ(t) = x +
Z t
t0
V (γ(s)) ds,
(12.6)
where the integral of the vector-valued function V (γ(s)) is obtained by
integrating each component separately. For any such γ we deﬁne a new
curve Aγ by
Aγ(t) = x +
Z t
t0
V (γ(s)) ds.
(12.7)

Proof of the ODE Theorem
319
Then we are led to seek a ﬁxed point for A in a suitable metric space of
curves.
Let C be a Lipschitz constant for V . Given t0 ∈R and x0 ∈U, choose
r > 0 such that Br(x0) ⊂U, and let M be the supremum of |V (x)| on
Br(x0). Set J0 = (t0 −ε, t0 +ε) and U0 = Bδ(x0), where ε and δ are chosen
small enough that
δ ≤r
2,
ε < min
 r
2M , 1
C

.
For any x ∈U0, let Mx denote the set of all continuous maps γ : J0 →
Br(x0) satisfying γ(0) = x. We deﬁne a metric on Mx by
d(γ, eγ) = sup
t∈J0
|γ(t) −eγ(t)|.
Any sequence of maps in Mx that is Cauchy in this metric is uniformly
convergent, and therefore has a continuous limit γ. Clearly, the conditions
that γ take its values in Br(x0) and γ(0) = x are preserved in the limit.
Therefore, Mx is a complete metric space.
We wish to deﬁne a map A: Mx →Mx by formula (12.7). The ﬁrst
thing we need to verify is that A really does map Mx into itself. It is clear
from the deﬁnition that Aγ(0) = x and Aγ is continuous (in fact, it is
diﬀerentiable by the fundamental theorem of calculus). Thus we need only
check that Aγ takes its values in Br(x0). If γ ∈Mx, then for any t ∈J0,
|Aγ(t) −x0| = |x +
Z t
t0
V (γ(s)) ds −x0|
≤|x −x0| +
Z t
t0
|V (γ(s))| ds
< δ + Mε ≤r
by our choice of δ and ε.
Next we check that A is a contraction. If γ, eγ ∈Mx, then using the
Lipschitz condition on V , we obtain
d(Aγ, Aeγ) = sup
t∈J0

Z t
t0
V (γ(s)) ds −
Z t
t0
V (eγ(s)) ds

≤sup
t∈J0
Z t
t0
|V (γ(s)) −V (eγ(s))| ds
≤sup
t∈J0
Z t
t0
C|γ(s) −eγ(s)| ds
≤Cεd(γ, eγ).

320
12. Integral Curves and Flows
Because we have chosen ε so that Cε < 1, this shows that A is a contraction.
By the contraction lemma, A has a ﬁxed point γ ∈Mx, which is a solution
to (12.4).
As a preliminary step in proving smoothness of the solution, we need the
following continuity result.
Lemma 12.15 (Continuity of ODE Solutions).
Suppose J0 is an
open interval containing t0, U0 ⊂U is an open set, and θ: J0 × U0 →U is
any map such that for each x ∈U0, γ(t) = θ(t, x) solves (12.4). Then θ is
continuous.
Proof. It suﬃces to show that θ is continuous in a neighborhood of each
point, so by shrinking J0 and U0 slightly we might as well assume that J0
is precompact in R and U0 is precompact in U.
First we note that θ is Lipschitz continuous in x, with a constant that is
independent of t, because (12.5) implies
|θ(t, ex) −θ(t, x)| ≤eCT|ex −x|
for all x, ex ∈U0,
(12.8)
where T = supJ0 |t −t0|.
Now let (t, x), (et, ex) ∈J0 × U0 be arbitrary. Using the fact that every
solution to the initial-value problem satisﬁes the integral equation (12.6),
we ﬁnd
|θ(et, ex) −θ(t, x)| ≤|ex −x| +

Z et
t0
V (θ(s, ex)) ds −
Z t
t0
V (θ(s, x)) ds

≤|ex −x| +
Z t
t0
|V (θ(s, ex)) −V (θ(s, x))| ds
+
Z et
t
|V (θ(s, ex))| ds
≤|ex −x| + C
Z t
t0
|θ(s, ex) −θ(s, x)| ds +
Z et
t
M ds
≤|ex −x| + CTeCT|ex −x| + M|et −t|,
where M is the supremum of |V | on U 0. It follows that θ is continuous.
Theorem 12.16 (Smoothness of ODE Solutions). Let θ be as in the
preceding theorem. If V is smooth, then so is θ.
Proof. We will prove the following claim by induction on k:
If V is of class Ck+1, then θ is of class Ck.
(12.9)

Proof of the ODE Theorem
321
From this it follows that if V is smooth, then θ is of class Ck for every k,
and thus is smooth.
The hardest part of the proof is the k = 1 step. Expressed in terms of θ,
the initial-value problem (12.4) reads
∂
∂tθi(t, x) = V i(θ(t, x)),
θi(t0, x) = xi.
(12.10)
Let us pretend for a moment that everything in sight is smooth, and dif-
ferentiate both of these equations with respect to xj. Since mixed partial
derivatives of smooth functions commute, we obtain
∂
∂t
∂θi
∂xj (t, x) = ∂V i
∂xk (θ(t, x))∂θk
∂xj (t, x),
∂θi
∂xj (t0, x) = δi
j =
(
1
if i = j,
0
if i ̸= j.
The idea of the proof for k = 1 is to show that the partial derivatives
∂θi/∂xj exist and solve this system of equations, and then to use the con-
tinuity lemma to conclude that these partial derivatives are continuous.
To that end, we let G: U →M(n, R) denote the matrix-valued function
G(x) = DV (x). The assumption that V is C2 implies that G is C1, so
(shrinking U0 if necessary) the map U0 × M(n, R) →M(n, R) given by
(x, y) 7→G(x)y is Lipschitz.
Consider the following initial-value problem for the n + n2 unknown
functions (θi, ψi
j):
∂
∂tθ(t, x) = V (θ(t, x)),
∂
∂tψ(t, x) = G(θ(t, x))ψ(t, x);
θ(t0, x) = x,
ψ(t0, x) = In.
(12.11)
This system is called the variational equation for the system (12.4). By
the existence and continuity theorems, for any x0 ∈U0 there exist an
interval J1 ⊂J0 containing t0, a neighborhood of (x0, In) in U0 × M(n, R)
(which we may assume to be a product set U1 × W1), and a continuous
map (θ, ψ): J1 × U1 × W1 →U0 × M(n, R) satisfying (12.11). If we can
show that ∂θi/∂xj exists for each i and j and equals ψi
j on J1 × U1, then
∂θi/∂xj is continuous there. Moreover, (12.4) implies ∂θi/∂t is continuous,
so it follows that θ is C1, at least on the set J1 × U1.
We will show that ∂θi/∂xj exists by working directly with the deﬁnition
of the derivative. For any suﬃciently small h ∈R∖{0}, let ∆h : J1 ×U1 →

322
12. Integral Curves and Flows
M(n, R) be the diﬀerence quotient
(∆h)i
j(t, x) = θi(t, x + hej) −θi(t, x)
h
.
Then ∂θi/∂xj(t, x) = limh→0(∆h)i
j(t, x) if the limit exists.
Because a C2 map is diﬀerentiable, for suﬃciently small δ > 0 there is a
map R: Bδ(0) →Rn such that
V (ex) −V (x) = DV (x)(ex −x) + R(ex −x)
(12.12)
and
lim
v→0
R(v)
|v|
= 0.
(12.13)
Let us compute the t-derivative of ∆h using (12.12):
∂
∂t(∆h)i
j(t, x) = 1
h
 ∂
∂tθi(t, x + hej) −∂
∂tθi(t, x)

= 1
h
 V i(θ(t, x + hej)) −V i(θ(t, x))

= 1
h
∂V i
∂xk (θ(t, x))(θk(t, x + hej) −θk(t, x))
+ Ri(θ(t, x + hej) −θ(t, x))

= Gi
k(θ(t, x))(∆h)k
j (t, x)) + Ri(θ(t, x + hej) −θ(t, x))
h
.
By 12.13, given any ε > 0 there exists δ > 0 such that |v| < δ implies
|R(v)|/|v| < ε. The Lipschitz estimate (12.8) for θ says that
|θ(t, x + hej) −θ(t, x))| ≤K|hej| = K|h|
for some constant K, and therefore |h| < δ/K implies that

R(θ(t, x + hej) −θ(t, x))
h
 ≤ε.
Summarizing, we have shown that for h suﬃciently small, ∆h is an “ε-
approximate solution” to the second equation of (12.11), in the sense that
∂
∂t∆h(t, x) = G(θ(t, x))∆h(t, x) + E(t, x),
where |E(t, x)| < ε. It also satisﬁes the initial condition ∆h(t0, x) = In for
each x.

Proof of the ODE Theorem
323
Let (θ, ψ) be the exact solution to (12.11). We will show that ∆h con-
verges to ψ as h →0. To do so, we note that
∂
∂t|ψ(t, x) −∆h(t, x)|2
= 2(ψ(t, x) −∆h(t, x)) ·
 G(θ(t, x))ψ(t, x) −G(θ(t, x))∆h(t, x) −E(t, x)

≤2|ψ(t, x) −∆h(t, x)|
 |G(θ(t, x)| |ψ(t, x) −∆h(t, x)| + ε

≤2B|ψ(t, x) −∆h(t, x)|2 + 2ε|ψ(t, x) −∆h(t, x)|
≤(2B + 1)|ψ(t, x) −∆h(t, x)|2 + ε2,
where B = sup |G|, and the last line follows from the inequality 2ab ≤
a2+b2, which is proved just by expanding (a−b)2 ≥0. Thus if J1 ⊂[−T, T ],
∂
∂t
 e−(2B+1)t|ψ(t, x) −∆h(t, x)|2
≤ε2e−(2B+1)t ≤ε2e(2B+1)T .
Since ψ(t0, x) = ∆h(t0, x), it follows by elementary calculus that
e−(2B+1)t|ψ(t, x) −∆h(t, x)|2 ≤ε2e(2B+1)T |t −t0|.
In particular, since ε can be made as small as desired by choosing h suﬃ-
ciently small, this shows that limh→0 ∆h(t, x) = ψ(t, x). Therefore, θ is C1
on the set J1 × U1.
To show that θ is actually C1 on its entire domain J0 × U0, we proceed
just as in the proof of Theorem 12.9. For each x0 ∈U0, the argument
above shows that θ is C1 in some neighborhood J1 × U1 of (t0, x0). Let
τ be the supremum of the set of t > t0 such that θ is C1 on a product
neighborhood of [t0, t] × {x0}. If (τ, x0) ∈U0, we will show that θ is C1 on
a product neighborhood of [t0, τ]×{x0}, which contradicts our choice of τ.
(The argument for t < t0 is similar.)
By the argument above, there exist ε > 0, a neighborhood U2 of θ(τ, x0),
and a C1 map β : (−ε, +ε) × U2 →U0 such that
∂
∂tβi(t, x) = V i(β(t, x)),
βi(0, x) = xi.
Choose t1 ∈(τ −ε, τ) such that θ(t1, x0) ∈U2. Then θ(t, x) = β(t −
t1, θ(t1, x)) where both are deﬁned, because they both solve the same ODE
and are equal to θ(t1, x) when t = t1. Since the right-hand side is smooth
for x ∈U2 and t1 −ε < t < t1 + ε, this shows that θ is C1 on [t0, t1 + ε) ×

324
12. Integral Curves and Flows
(U2 ∩U1), which contradicts our choice of τ. Therefore, θ is C1 on its whole
domain, thus proving (12.9) for k = 1. Moreover, we have also shown that
(θi, ∂θi/∂xj) solves the variational equation (12.11).
Now assume by induction that (12.9) is true for 1 ≤k < k0, and suppose
V is of class Ck0+1. By the argument above, (θi, ∂θi/∂xj) solves the varia-
tional equation. Since the ﬁrst partial derivatives of V are of class Ck0, the
inductive hypothesis applied to (12.11) shows that (θi, ∂θi/∂xj) is of class
Ck0−1. Since θ is of class Ck0−1 by the inductive hypothesis and therefore
∂θi/∂t is Ck0−1 by (12.10), it follows that all of the partial derivatives of
θ are Ck0−1, so θ itself is Ck0, thus completing the induction.

Problems
325
Problems
12-1. Show that every smooth vector ﬁeld with compact support is com-
plete.
12-2. Let M be a compact Riemannian n-manifold, and f ∈C∞(M). Sup-
pose f has only ﬁnitely many critical points {p1, . . . , pk} with cor-
responding critical values {c1, . . . , ck}. (Assume without loss of gen-
erality that c1 ≤· · · ≤ck.) For any a, b ∈R, deﬁne Ma = f −1(a)
and M[a,b] = f −1([a, b]). If a is a regular value, note that Ma is an
embedded hypersurface in M.
(a) Let X be the vector ﬁeld X
= gradf/| gradf|2 on M ∖
{p1, . . . , pk}, and let θ denote the ﬂow of X. Show that
f(θt(p)) = f(p) + t whenever θt(p) is deﬁned.
(b) Let [a, b] ⊂R be an interval containing no critical values of f.
Show that
θ : [0, b −a] × Ma →M[a,b]
is a diﬀeomorphism, whose inverse is p 7→
 f(p) −a, θ(a −
f(p), p)

.
[Remark: This result shows that M can be decomposed as a union
of simpler “building blocks”—the product manifolds M[ci+ε,ci+1−ε] ≈
I × Mci+ε, and the neighborhoods f −1((ci −ε, ci + ε)) of the critical
points. This is the starting point of Morse theory, which is one of
the deepest applications of diﬀerential geometry to topology. It is
enlightening to think about what this means when M is a torus of
revolution in R3 obtained by revolving a circle around the z-axis, and
f(x, y, z) = x.]
12-3. Let M be a connected smooth manifold. Show that the group of
diﬀeomorphisms of M acts transitively on M. More precisely, for any
two points p, q ∈M, show that there is a diﬀeomorphism F : M →M
such that F(p) = q. [Hint: First prove the following lemma: If p, q ∈
Bn (the open unit ball in Rn), there is a compactly supported vector
ﬁeld on Bn whose ﬂow θ satisﬁes θ1(p) = q.]
12-4. Let M be a smooth manifold. A smooth curve γ : R →M is said to
be periodic if there exists T > 0 such that γ(t) = γ(t′) if and only if
t −t′ = kT for some k ∈Z. Suppose X ∈T(M) and γ is a maximal
integral curve of X.
(a) Show that exactly one of the following holds:
• γ is constant.
• γ is injective.

326
12. Integral Curves and Flows
• γ is periodic.
(b) Show that the image of γ is an immersed submanifold of M.
12-5. Show that there is only one smooth structure on R up to diﬀeomor-
phism. More precisely, if M is any smooth manifold that is home-
omorphic to R, show that M is diﬀeomorphic to R (with its stan-
dard smooth structure). [Hint: First show that M admits a nowhere-
vanishing smooth vector ﬁeld. See Problem 10-1.]
12-6. Let θ be a ﬂow on an oriented manifold. Show that for each t ∈R, θt
is orientation-preserving wherever it is deﬁned.
12-7. All of the systems of diﬀerential equations considered in this chapter
have been of the form
γi′(t) = V i(γ(t)),
in which the functions V i do not depend explicitly on the independent
variable t. (Such a system is said to be autonomous.) If instead V is
a function of (t, x) in some subset of R × Rn, the resulting system is
called nonautonomous; it can be thought of as a “time-dependent vec-
tor ﬁeld” on a subset of Rn. This problem shows that local existence,
uniqueness, and smoothness for a nonautonomous system follow from
the corresponding results for autonomous ones. Suppose U ⊂Rn is an
open set, J ⊂R is an open interval, and V : J × U →Rn is a smooth
map. For any (t0, x0) ∈J × U and any suﬃciently small ε > 0, show
that there exists a neighborhood U0 of x0 in U and a unique smooth
map ψt0 : (t0 −ε, t0 + ε) × U0 →U such that for each x ∈U0, the
curve γ(t) = ψt0(t, x) is the unique solution on (t0 −ε, t0 + ε) to the
nonautonomous initial-value problem
γi′(t) = V i(t, γ(t)),
γi(t0) = xi.
[Hint: Replace this system of ODEs by an autonomous system in
Rn+1.]

13
Lie Derivatives
This chapter is devoted primarily to the study of a particularly important
construction involving vector ﬁelds, the Lie derivative. This is a method
of computing the “directional derivative” of one vector ﬁeld with respect
to another. We will see in this and later chapters that this construction
has applications to ﬂows, symplectic manifolds, Lie groups, and partial
diﬀerential equations, among other subjects.
The Lie Derivative
We already know how to compute “directional derivatives” of functions on
a manifold: Indeed, a tangent vector Vp is by deﬁnition an operator that
acts on a smooth function f to give a number Vpf, which we interpret as
the directional derivative of f in the direction Vp.
What about the directional derivative of a vector ﬁeld? In Euclidean
space, we have a perfectly good way of making sense of this: If V is a
tangent vector at p ∈Rn, and W is a smooth vector ﬁeld on Rn, we can
deﬁne the “directional derivative” of W in the direction of V as the vector
DV W = d
dt

t=0
Wp+tV = lim
t→0
Wp+tV −Wp
t
.
(13.1)

328
13. Lie Derivatives
A standard calculation using the chain rule shows that DV W can be cal-
culated by applying V to each component of W separately:
DV W(p) = V W i(p)
∂
∂xi

p
.
Unfortunately, as we will see, this does not deﬁne a coordinate-
independent operation. If we search for a way to make invariant sense of
(13.1) on a manifold, we will see very quickly what the problem is. To begin
with, we can replace p + tV by any curve γ(t) that starts at p and whose
initial tangent vector is V . But even with this substitution, the diﬀerence
quotient still makes no sense because Wγ(t) and Wγ(0) are elements of diﬀer-
ent vector spaces (Tγ(t)M and Tγ(0)M). We got away with it in Euclidean
space because there is a canonical identiﬁcation of each tangent space with
Rn itself; but on a manifold there is no such identiﬁcation. Thus there is
no coordinate-invariant way to make sense of the directional derivative of
W in the direction of the vector V .
Now suppose that V itself is a vector ﬁeld instead of a single vector. In
this case, we can use the ﬂow of V to push values of W back to p and then
diﬀerentiate. Thus, for any smooth vector ﬁelds V and W on a manifold
M, let θ be the ﬂow of V , and deﬁne a vector (LV W)p at each p ∈M,
called the Lie derivative of W with respect to V , by
(LV W)p = d
dt

t=0
(θ−t)∗Wθt(p) = lim
t→0
(θ−t)∗Wθt(p) −Wp
t
,
(13.2)
provided the derivative exists. For small t ̸= 0, the diﬀerence quotient
makes sense at least, because θt is deﬁned in a neighborhood of p and both
(θ−t)∗Wθt(p) and Wp are elements of TpM.
Exercise 13.1.
If V ∈Rn and W is a smooth vector ﬁeld on an open
subset of Rn, show that the directional derivative DV W (p) deﬁned by (13.1)
is equal to (L e
V W )p, where eV is the vector ﬁeld eV = V i∂/∂xi with constant
coeﬃcients in standard coordinates.
This deﬁnition raises a number of questions: Does (θ−t)∗Wθt(p) always
depend diﬀerentiably on t, so that the derivative in (13.2) always exists?
If so, does the assignment p 7→(LV W)p deﬁne a smooth vector ﬁeld on
M? And most importantly, is there a reasonable way to compute (LV W)p,
given that the only way to ﬁnd the integral curves of V is to solve a system
of ODEs, and most such systems cannot be solved explicitly? Fortunately,
there are good answers to all these questions, but we will need to develop
a few more tools in order to describe them.

Lie Brackets
329
Lie Brackets
We begin by deﬁning another way to combine two vector ﬁelds to obtain a
new vector ﬁeld, seemingly unrelated to the Lie derivative.
Let V and W be smooth vector ﬁelds on a smooth manifold M. Given
a smooth function f : M →R, we can apply V to f and obtain another
smooth function V f, to which we can then apply the vector Wp to obtain
a real number Wp(V f); of course we can also do the same thing the other
way around. Applying both of these operators to f and subtracting, we
obtain an operator [V, W]p : C∞(M) →R, called the Lie bracket of V and
W, deﬁned by
[V, W]pf = Vp(Wf) −Wp(V f).
Lemma 13.1. For any two vector ﬁelds V, W ∈T(M), the Lie bracket
[V, W]p satisﬁes the following properties.
(a) [V, W]p ∈TpM.
(b) The assignment p 7→[V, W]p deﬁnes a smooth vector ﬁeld [V, W] on
M, which satisﬁes
[V, W]f = V Wf −WV f.
(13.3)
(c) If (xi) are any local coordinates on M, then [V, W] has the coordinate
expression
[V, W] =

V i ∂W j
∂xi −W i ∂V j
∂xi
 ∂
∂xj ,
(13.4)
or more concisely,
[V, W] = (V W j −WV j) ∂
∂xj .
Proof. First we prove that [V, W]p is a tangent vector, i.e., a linear deriva-
tion on the space of germs of functions at p. Clearly [V, W]pf depends only
on the values of f in a neighborhood of p, so it is well-deﬁned on germs.
As a map from C∞(p) to R, it is obviously linear over R, so only the prod-
uct rule needs to be checked. If f and g are smooth functions deﬁned in a
neighborhood of p, then
[V, W]p(fg) = Vp(W(fg)) −Wp(V (fg))
= Vp(fWg + gWf) −Wp(fV g + gV f)
= (Vpf)(Wpg) + f(p)Vp(Wg) + (Vpg)(Wpf) + g(p)Vp(Wf)
−(Wpf)(Vpg) −f(p)Wp(V g) −(Wpg)(Vpf) −g(p)Wp(V f)
= f(p)(Vp(Wg) −Wp(V g)) + g(p)(Vp(Wf) −Wp(V f))
= f(p)[V, W]pg + g(p)[V, W]pf.

330
13. Lie Derivatives
This shows that [V, W]p satisﬁes the product rule and therefore deﬁnes a
tangent vector at p.
Formula (13.3) is immediate from the deﬁnition of the Lie bracket, and it
follows from this that [V, W] is a smooth vector ﬁeld, because (13.3) deﬁnes
a smooth function whenever f is smooth in an open subset of M.
To prove (c), we just write V = V i∂/∂xi and W = W j∂/∂xj in coordi-
nates, and compute:
[V, W]f = V i ∂
∂xi

W j ∂f
∂xj

−W j ∂
∂xj

V i ∂f
∂xi

= V i ∂W j
∂xi
∂f
∂xj + V iW j
∂2f
∂xi∂xj −W j ∂V i
∂xj
∂f
∂xi −W jV i
∂2f
∂xj∂xi
= V i ∂W j
∂xi
∂f
∂xj −W j ∂V i
∂xj
∂f
∂xi ,
where in the last step we have used the fact that mixed partial derivatives of
a smooth function commute. Reversing the roles of the summation indices
i and j in the second term, we obtain (13.4).
Exercise 13.2.
For each of the following pairs of vector ﬁelds V, W deﬁned
on R3, compute the Lie bracket [V, W ].
(a)
V = y ∂
∂z −2xy2 ∂
∂y ;
W = ∂
∂y .
(b)
V = x ∂
∂y −y ∂
∂x;
W = y ∂
∂z −z ∂
∂y .
(c)
V = x ∂
∂y −y ∂
∂x;
W = x ∂
∂y + y ∂
∂x.
Lemma 13.2 (Properties of the Lie Bracket).
The Lie bracket sat-
isﬁes the following identities:
(a) Bilinearity: For a1, a2 ∈R, [a1V1 + a2V2, W] = a1[V1, W] +
a2[V2, W] and [V, a1W1 + a2W2] = a1[V, W1] + a2[V, W2].
(b) Antisymmetry: [V, W] = −[W, V ].
(c) Jacobi Identity: [V, [W, X]] + [W, [X, V ]] + [X, [V, W]] = 0.
Proof. Bilinearity and antisymmetry are obvious consequences of the deﬁ-
nition. The proof of the Jacobi identity is just a computation:
[V,[W, X]]f + [W, [X, V ]]f + [X, [V, W]]f
= V [W, X]f −[W, X]V f + W[X, V ]f
−[X, V ]Wf + X[V, W]f −[V, W]Xf
= V WXf −V XWf −WXV f + XWV f + WXV f −WV Xf
−XV Wf + V XWf + XV Wf −XWV f −V WXf + WV Xf.
In this last expression, all the terms cancel in pairs.

Lie Brackets
331
Proposition 13.3 (Naturality of the Lie Bracket).
Let F : M →N
be a smooth map, and let V1, V2 ∈T(M) and W1, W2 ∈T(N) be vector
ﬁelds such that Vi is F-related to Wi, i = 1, 2. Then [V1, V2] is F-related to
[W1, W2]. If F is a diﬀeomorphism, then F∗[V1, V2] = [F∗V1, F∗V2].
Proof. Using Lemma 3.17 and fact that Vi and Wi are F-related,
V1V2(f ◦F) = V1((W2f) ◦F)
= (W1W2f) ◦F.
Similarly,
V2V1(f ◦F) = (W2W1f) ◦F.
Therefore,
[V1, V2](f ◦F) = V1V2(f ◦F) −V2V1(f ◦F)
= (W1W2f) ◦F −(W2W1f) ◦F
= ([W1, W2]f) ◦F.
The result then follows from the lemma. The statement when F is a diﬀeo-
morphism is an obvious consquence of the general case, because Wi = F∗Vi
in that case.
Proposition 13.4. Let N be an immersed submanifold of M, and suppose
V, W ∈T(M). If V and W are tangent to N, then so is [V, W].
Proof. This is a local question, so we may replace N by an open subset of
N that is embedded. Then Proposition 5.8 shows that a vector X ∈TpM
is in TpN if and only if Xf = 0 whenever f ∈C∞(M) vanishes on N.
Suppose f is such a function. Then the fact that V and W are tangent to
N implies that V f|N = Wf|N = 0, and so
[V, W]pf = Vp(Wf) −Wp(V f) = 0.
This shows that [V, W]p ∈TpN, which was to be proved.
We will see shortly that the Lie bracket [V, W] is equal to the Lie deriv-
ative LV W, even though the two quantities are deﬁned in ways that seem
totally unrelated. Before doing so, we need to prove one more result, which
is of great importance in its own right. If V is a smooth vector ﬁeld on M,
a point p ∈M is said to be a singular point for V if Vp = 0, and a regular
point otherwise.
Theorem 13.5 (Canonical Form for a Regular Vector Field).
Let
V be a smooth vector ﬁeld on a smooth manifold M, and let p ∈M be a
regular point for V . There exist coordinates (xi) on some neighborhood of
p in which V has the coordinate expression ∂/∂x1.

332
13. Lie Derivatives
Proof. By the way we have deﬁned coordinate vector ﬁelds on a manifold, a
coordinate chart (U, ϕ) will satisfy the conclusion of the theorem provided
that (ϕ−1)∗(∂/∂x1) = V , which will be true if and only if ϕ−1 takes lines
parallel to the x1 axis to the integral curves of V . The ﬂow of V is ideally
suited to this purpose.
Begin by choosing any coordinates (yi) on a neighborhood U of p, with
p corresponding to 0. By composing with a linear transformation, we may
assume that Vp = ∂/∂y1|p. Let θ: D(V ) →M be the ﬂow of V . There
exists ε > 0 and a neighborhood U0 ⊂U of p such that the product open
set (−ε, ε) × U0 is contained in D(V ) and is mapped by θ into U.
Let S ⊂Rn−1 be the set
S = {(x2, . . . , xn) : (0, x2, . . . , xn) ∈U0},
and deﬁne a smooth map ψ: (−ε, ε) × S →U by
ψ(t, x2, . . . , xn) = θ(t, (0, x2, . . . , xn)).
Geometrically, for each ﬁxed (x2, . . . , xn), ψ maps the interval (−ε, ε) ×
{(x2, . . . , xn)} to the integral curve through (0, x2, . . . , xn).
First we will show that ψ pushes ∂/∂t forward to V . We have
 
ψ∗
∂
∂t

(t0,x0)
!
f = ∂
∂t

(t0,x0)
(f ◦ψ)
= ∂
∂t

t=t0
(f(θ(t, (0, x0)))
= Vψ(t0,x0)f,
(13.5)
where we have used the fact that t 7→θ(t, (0, x0)) is an integral curve
of V . On the other hand, when restricted to {0} × S, ψ(0, x2, . . . , xn) =
θ(0, (0, x2, . . . , xn)) = (0, x2, . . . , xn), so
ψ∗
∂
∂xi

(0,0)
=
∂
∂yi

(0,0)
.
Since ψ∗: T(0,0)((−ε, ε)×S) →TpM takes a basis to a basis, it is an isomor-
phism. Therefore, by the inverse function theorem, there are neighborhoods
W of (0, 0) and Y of p such that ψ: W →Y is a diﬀeomorphism.
Let ϕ = ψ−1 : Y →W. Equation (13.5) says precisely that V is equal
to the coordinate vector ﬁeld ∂/∂t in these coordinates. Renaming t to x1,
this is what we wanted to prove.
This theorem implies that the integral curves of V near a regular point
behave, up to diﬀeomorphism, just like the x1-lines in Rn, so that all of
the interesting local behavior is concentrated near the singular points. Of

Lie Brackets
333
course, the ﬂow near singular points can exhibit a wide variety of behav-
iors, such as closed orbits surrounding the singular point, orbits converging
exponentially or spiraling into the singular point as t →∞or −∞, and
many more complicated phenomena, as one can see in any good diﬀerential
equations text that treats systems of ODEs in the plane. This is the start-
ing point for the subject of smooth dynamical systems, which is the study
of the global and long-time behavior of ﬂows of vector ﬁelds.
We are now in a position to prove the promised formula for computing
Lie derivatives.
Theorem 13.6. For any smooth vector ﬁelds V and W on a smooth man-
ifold M, LV W = [V, W].
Proof. We will show that (LV W)p = [V, W]p for each p ∈M. We consider
two cases.
Case I: p is a regular point for V . In this case, we can choose coordinates
(xi) near p such that V = ∂/∂x1 in coordinates. In this case, the ﬂow of V
is easy to compute explicitly:
θt(x) = (x1 + t, x2, . . . , xn).
Therefore, for each ﬁxed t, the matrix of (θt)∗in these coordinates (the
Jacobian matrix of θt) is the identity at every point. Consequently,
(θ−t)∗Wθt(p) = (θ−t)∗
 
W j(x1 + t, x2, . . . , xn)
∂
∂xj

θt(p)
!
= W j(x1 + t, x2, . . . , xn)
∂
∂xj

p
.
Using the deﬁnition of the Lie derivative,
(LV W)p = d
dt

t=0
W j(x1 + t, x2, . . . , xn)
∂
∂xj

p
= ∂W j
∂x1 (x1, . . . , xn)
∂
∂xj

p
.
On the other hand, using the formula (13.4) for the Lie bracket in coordi-
nates, [V, W]p is easily seen to be equal to the same expression.
Case II: p is a singular point for V . In this case, we cannot write down
the ﬂow explicitly. However, it does have the property that θt(p) = p for
all t ∈R (Lemma 12.8), and therefore (θ−t)∗maps TpM to itself. Since the
matrix entries of (θ−t)∗: TpM →TpM in any coordinate system are partial
derivatives of θ and therefore are smooth functions of t, it follows that the
components of the TpM-valued function t 7→(θ−t)∗Wθt(p) = (θ−t)∗Wp with
respect to the coordinate basis are also smooth functions of t. If t 7→X(t)

334
13. Lie Derivatives
is any smooth curve in TpM, then for any smooth function f deﬁned on a
neighborhood of p,
 d
dtX(t)

f =
 d
dtXj(t)
 ∂f
∂xj (p)
=
 d
dtXj(t) ∂f
∂xj (p)

= d
dt(X(t)f).
Applying this to (θ−t)∗Wp and using the deﬁnition of the Lie derivative,
(LV W)pf =
 d
dt

t=0
(θ−t)∗Wp

f
= d
dt

t=0
((θ−t)∗Wpf)
= d
dt

t=0
(Wp(f ◦θ−t))
= d
dt

t=0
 
W j(p)
∂
∂xj

p
(f ◦θ−t)
!
= W j(p) ∂
∂t

t=0
∂
∂xj

x=p
f(θ−t(x))
= W j(p)
∂
∂xj

x=p
∂
∂t

t=0
f(θ−t(x))
= W j(p)
∂
∂xj

p
(−V f)
= −Wp(V f).
On the other hand, since Vp = 0, we have
[V, W]pf = Vp(Wf) −Wp(V f) = −Wp(V f),
which is equal to (LV W)pf.
Corollary 13.7. If V and W are as in the statement of the theorem, then
(a) The assignment p 7→(LV W)p is a smooth vector ﬁeld on M.
(b) LV W = −LW V .
(c) If F : M →N is a diﬀeomorphism, then F∗(LV W) = LF∗V F∗W.
Exercise 13.3.
Prove this corollary.

Commuting Vector Fields
335
Commuting Vector Fields
Two smooth vector ﬁelds are said to commute if [V, W] ≡0, or equivalently
if V Wf = WV f for every smooth function f. One simple example of
a pair of commuting vector ﬁelds is ∂/∂xi and ∂/∂xj in any coordinate
system: because their component functions are constants, their Lie bracket
is identically zero.
We will see that commuting vector ﬁelds are closely related to another
important concept. Suppose W is a smooth vector ﬁeld on M, and θ is a
ﬂow on M. We say W is invariant under θ if (θt)∗W = W on the image of
θt. More explicitly, this means that
(θt)∗Wp = Wθt(p)
for all (t, p) in the domain of θ.
We will show that commuting vector ﬁelds are invariant under each
other’s ﬂows. The key is the following somewhat more general result about
F-related vector ﬁelds.
Lemma 13.8. Suppose F : M →N is a smooth map, V ∈T(M), and
W ∈T(N), and let θ be the ﬂow of V and ψ the ﬂow of W. Then V and
W are F-related if and only if for each t ∈R, ψt◦F = F ◦θt on the domain
of θt:
M
N
-
F
M
N
-
F
?
θt
?
ψt
Proof. The commutativity of the diagram means that the following holds
for all (t, p) in the domain of θ:
ψt ◦F(p) = F ◦θt(p).
If we let Dp ⊂R denote the domain of θ(p), this is equivalent to
ψ(F (p))(t) = F ◦θ(p)(t),
t ∈Dp.
(13.6)
Suppose ﬁrst that V and W are F-related. If we deﬁne γ : Dp →N by
γ = F ◦θ(p), then
γ′(t) = (F ◦θ(p))′(t)
= F∗(θ(p)′(t))
= F∗Vθ(p)(t)
= WF ◦θ(p)(t)
= Wγ(t),

336
13. Lie Derivatives
so γ is an integral curve of W starting at F ◦θ(p)(0) = F(p). By uniqueness
of integral curves, therefore, the maximal integral curve ψ(F (p)) must be
deﬁned at least on the interval Dp, and γ(t) = ψ(F (p))(t) on that interval.
This proves (13.6).
Conversely, if (13.6) holds, then for each p ∈M we have
F∗Vp = F∗(θ(p)′(0))
= (F ◦θ(p))′(0)
= ψ(F (p))′(0)
= WF (p),
which shows that V and W are F-related.
Proposition 13.9. Let V and W be smooth vector ﬁelds on M, with ﬂows
θ and ψ, respectively. The following are equivalent:
(a) V and W commute.
(b) LV W = LW V = 0.
(c) W is invariant under the ﬂow of V .
(d) V is invariant under the ﬂow of W.
(e) θs ◦ψt = ψt ◦θs wherever either side is deﬁned.
Proof. Clearly (a) and (b) are equivalent because LV W
= [V, W] =
−LW V . Part (c) means that (θ−t)∗Wθt(p) = Wp whenever (−t, p) is in
the domain of θ, which obviously implies (b) directly from the deﬁnition of
LV W. The same argument shows that (d) implies (b).
To prove that (b) implies (c), let p ∈M be arbitrary, let Dp ⊂R denote
the domain of the integral curve θ(p), and consider the map X : Dp →TpM
given by the time-dependent vector
X(t) = (θ−t)∗
 Wθt(p)

∈TpM.
(13.7)
This can be considered as a smooth curve in the vector space TpM. We
will show that X(t) is independent of t. Since X(0) = Wp, this implies that
X(t) = Wp for all t ∈Dp, which says that W is invariant under θt.
The assumption that LV W = 0 means precisely that the t-derivative of
(13.7) is zero when t = 0; we need to show that this derivative is zero for

Commuting Vector Fields
337
all values of t. Making the change of variables t = t0 + s, we obtain
X′(t0) = d
dt

t=t0
(θ−t)∗Wθt(p)
= d
ds

s=0
(θ−t0−s)∗Wθs+t0 (p)
= d
ds

s=0
(θ−t0)∗(θ−s)∗Wθs(θt0 (p))
= (θ−t0)∗
d
ds

s=0
(θ−s)∗Wθs(θt0(p))
= (θ−t0)∗(LV W)θt0 (p) = 0.
(13.8)
(The equality on the next-to-last line follows because (θ−t0)∗: Tθt0(p)M →
TpM is a linear map that is independent of s.) The same proof also shows
that (b) implies (d).
To prove that (c) and (e) are equivalent, we let Mt denote the domain
of θt and use Lemma 13.8 applied to the map F = θt : Mt →θt(Mt).
According to that lemma, θt ◦ψs = ψs ◦θt on the set where θt ◦ψs is
deﬁned if and only if (θt)∗W = W on θt(Mt), which is to say if and only
if W is invariant under θ. By reversing the roles of V and W, we see that
this is also true on the set where ψs ◦θt is deﬁned.
As we mentioned above, one example of a family of commuting vector
ﬁelds is given by the coordinate vector ﬁelds ∂/∂xi, i = 1, . . . , n. The next
theorem shows that up to diﬀeomorphism, any collection of independent
commuting vector ﬁelds is of this form locally.
Theorem 13.10 (Canonical Form for Commuting Vector Fields).
Let M be a smooth n-manifold, and let V1, . . . , Vk be smooth vector ﬁelds
on an open subset of M whose values are linearly independent at each
point. Then the following are equivalent:
(a) There exist coordinates (xi) in a neighborhood of each point such that
Vi = ∂/∂xi, i = 1, . . . , k.
(b) [Vi, Vj] ≡0 for all i and j.
Proof. The fact that (a) implies (b) is obvious because the coordinate vec-
tor ﬁelds commute and the Lie bracket is coordinate-independent.
To prove the converse, suppose V1, . . . , Vk are vector ﬁelds satisfying (b).
The basic outline of the proof is entirely analogous to that of the canonical
form theorem for one nonvanishing vector ﬁeld (Theorem 13.5), except that
we have to do a bit of work to make use of the hypothesis that the vector
ﬁelds commute.
Choose coordinates (yi) on a neighborhood U of p such that p corre-
sponds to 0 and Vi = ∂/∂yi at 0 for i = 1, . . . , k. Let θi be the ﬂow of

338
13. Lie Derivatives
Vi for i = 1, . . . , k. There exists ε > 0 and a neighborhood W of p such
that the composition (θk)tk ◦(θk−1)tk−1 ◦· · · ◦(θ1)t1 is deﬁned on W and
maps W into U whenever |t1|, . . . , |tk| are all less than ε. (Just choose
ε1 > 0 and U1 ⊂U such that θ1 maps (−ε1, ε1) × U1 into U, and then
inductively choose εi and Ui such that θi maps (−εi, εi) × Ui into Ui−1.
Taking ε = min{εi} and W = Uk does the trick.)
As in the proof of the canonical form theorem for one nonvanishing vector
ﬁeld, let
S = {(xk+1, . . . , xn) : (0, . . . , 0, xk+1, . . . , xn) ∈W}.
Deﬁne ψ: (−ε, ε)k × W →U by
ψ(x1, . . . , xk, xk+1, . . . , xn)
= (θk)xk ◦· · · ◦(θ1)x1(0, (0, . . . , 0, xk+1, . . . , xn)).
We will show ﬁrst that
ψ∗
∂
∂xi = Vi,
i = 1, . . . , k.
Because all the ﬂows θi commute with each other, we have

ψ∗
∂
∂xi

f =
∂
∂xi
 f(ψ(x1, . . . , xn))

=
∂
∂xi
 f((θk)xk ◦· · · ◦(θ1)x1(0, (0, . . . , 0, xk+1, . . . , xn))

=
∂
∂xi

f((θi)xi ◦(θk)xk ◦· · ·
◦\
(θi)xi ◦· · · ◦(θ1)x1(0, (0, . . . , 0, xk+1, . . . , xn))

,
where the hat means that (θi)xi is omitted. Now, for any p ∈M, t 7→
(θi)t(p) is an integral curve of Vi, so this last expression is equal to (Vi)ψ(x)f,
which proves the claim.
Next we will show that ψ∗is invertible at p. The computation above
shows that for i = 1, . . . , k,
ψ∗
∂
∂xi

0
= Vp =
∂
∂yi

p
.
On
the
other
hand,
since
ψ(0, . . . , 0, xk+1, . . . , xn)
=
(0, . . . , 0, xk+1, . . . , xn), it follows immediately that
ψ∗
∂
∂xi

0
=
∂
∂yi

p
for i = k+1, . . . , n as well. Thus ψ∗takes a basis to a basis, and is therefore
a diﬀeomorphism in a neighborhood of 0. It follows that ϕ = ψ−1 is the
desired coordinate map.

Lie Derivatives of Tensor Fields
339
Lie Derivatives of Tensor Fields
The Lie derivative operation can be extended to tensors of arbitrary rank.
As usual, we focus on covariant tensors; the analogous results for contravari-
ant or mixed tensors require only minor modiﬁcations.
Let X be a smooth vector ﬁeld on a smooth manifold M, and let θ be its
ﬂow. Near any p ∈M, if t is suﬃciently close to zero, θt is a diﬀeomorphism
from a neighborhood of p to a neighborhood of θt(p). Thus θ∗
t pulls back
smooth tensor ﬁelds near θt(p) to ones near p.
Given a covariant tensor ﬁeld τ on M, we deﬁne the Lie derivative of τ
with respect to X, denoted by LXτ, as
(LXτ)p = ∂
∂t

t=0
(θ∗
t τ)p = lim
t→0
θ∗
t τθt(p) −τp
t
.
Because the expression being diﬀerentiated lies in T k(TpM) for all t,
(LXτ)p makes sense as an element of T k(TpM). We will show below that
LXτ is actually a smooth tensor ﬁeld. First we prove the following impor-
tant properties of Lie derivatives of tensors.
Proposition 13.11. Let M be a smooth manifold. Suppose X, Y are
smooth vector ﬁelds on M, σ, τ are smooth covariant tensor ﬁelds, ω, η
are diﬀerential forms, and f is a smooth function (thought of as a 0-tensor
ﬁeld).
(a) LXf = Xf.
(b) LX(fσ) = (LXf)σ + fLXσ.
(c) LX(σ ⊗τ) = (LXσ) ⊗τ + σ ⊗LXτ.
(d) LX(ω ∧η) = LXω ∧η + ω ∧LXη.
(e) LX(Y
ω) = (LXY )
η + Y
LXω.
(f ) For any smooth vector ﬁelds Y1, . . . , Yk,
LX(σ(Y1, . . . , Yk)) = (LXσ)(Y1, . . . , Yk)
+ σ(LXY1, . . . , Yk) + · · · + σ(Y1, . . . , LXYk).
(13.9)
Proof. The ﬁrst assertion is just a reinterpretation of the deﬁnition in the
case of a 0-tensor. Because θ∗
t f = f ◦θt, the deﬁnition implies
LXf(p) = ∂
∂t

t=0
f(θt(p)) = Xf(p).

340
13. Lie Derivatives
The proofs of (b), (c), (d), (e), and (f) are essentially the same, so we
will prove (c) and leave the others to you.
(LX(σ ⊗τ))p = lim
t→0
θ∗
t (σ ⊗τ)θt(p) −(σ ⊗τ)p
t
= lim
t→0
θ∗
t σθt(p) ⊗θ∗
t τθt(p) −σp ⊗τp
t
= lim
t→0
θ∗
t σθt(p) ⊗θ∗
t τθt(p) −θ∗
t σθt(p) ⊗τp
t
+ lim
t→0
θ∗
t σθt(p) ⊗τp −σp ⊗τp
t
= lim
t→0 θ∗
t σθt(p) ⊗θ∗
t τθt(p) −τp
t
+ lim
t→0
θ∗
t σθt(p) −σp
t
⊗τp
= σp ⊗(LXτ)p + (LXσ)p ⊗τp.
The other parts are similar, and are left as an exercise.
Exercise 13.4.
Complete the proof of the preceding proposition.
Corollary 13.12. If X is a smooth vector ﬁeld and σ is a smooth covariant
tensor ﬁeld, then LXσ can be computed by the following expression:
(LXσ)(Y1, . . . , Yk)) = X(σ(Y1, . . . , Yk) −σ([X, Y1], Y2, . . . , Yk) −. . .
−σ(Y1, . . . , Yk−1, [X, Yk]).
(13.10)
It follows that LXσ is smooth.
Proof. Formula (13.10) is obtained simply by solving (13.9) for LXσ, and
replacing LXf by Xf and LXYi by [X, Yi]. It then follows immediately
that LXσ is smooth, because its action on smooth vector ﬁelds yields a
smooth function.
Corollary 13.13. If f ∈C∞(M), then LX(df) = d(LXf).
Proof. Using (13.10), we compute
(LXdf)(Y ) = X(df(y)) −df[X, Y ]
= XY f −[X, Y ]f
= XY f −(XY f −Y Xf)
= Y Xf
= d(Xf)(Y )
= d(LXf)(Y ).

Lie Derivatives of Tensor Fields
341
Diﬀerential Forms
In the case of diﬀerential forms, the exterior derivative yields a much more
powerful formula for computing Lie derivatives. Although Corollary 13.12
gives a general formula for computing the Lie derivative of any tensor ﬁeld,
this formula has a serious drawback: In order to calculate what LXσ does
to vectors Y1, . . . , Yk at a point p ∈M, it is necessary ﬁrst to extend the
vectors to vector ﬁelds in a neighborhood of p. The formula in the next
proposition overcomes this disadvantage.
Proposition 13.14. For any vector ﬁeld X and any diﬀerential k-form ω
on a smooth manifold M,
LXω = X
(dω) + d(X
ω).
(13.11)
Proof. The proof is by induction on k. We begin with a 0-form f, in which
case
X
(df) + d(X
f) = X
df = df(X) = Xf = LXf,
which is (13.11).
Any 1-form can be written locally as a sum of terms of the form u dv
for smooth functions u and v, so to prove (13.11) for 1-forms, it suﬃces
to consider the case ω = u dv. In this case, using Proposition 13.11(d) and
Corollary 13.13, the left-hand side of (13.11) reduces to
LX(u dv) = (LXu)dv + u(LXdv)
= (Xu)dv + u d(Xv).
On the other hand, using the fact that interior multiplication is an anti-
derivation, the right-hand side is
X
d(u dv) + d(X
(u dv)) = X
(du ∧dv) + d(uXv)
= (X
du) ∧dv −du ∧(X
dv)
+ u d(Xv) + (Xv)du
= (Xu)dv −(Xv)du + u d(Xv) + (Xv)du.
(Remember that X
du = du(X) = Xu, and a wedge product with a
0-form is just ordinary multiplication.) After cancelling the two (Xv)du
terms, this is equal to LX(u dv).
Now let k > 1, and suppose (13.11) has been proved for forms of degree
less than k. Let ω be an arbitrary k-form, written in local coordinates as
ω =
X′
I
ωI dxi1 ∧· · · ∧dxik.
Writing α = ωI dxi1 and β = dxi2 ∧· · ·∧dxik, we see that ω can be written
as a sum of terms of the form α ∧β, where α is a 1-form and β is a (k −1)-
form. For such a term, Proposition 13.11(d) and the induction hypothesis

342
13. Lie Derivatives
imply
LX(α ∧β) = (LXα) ∧β + α ∧(LXβ)
= (X
dα + d(X
α)) ∧β + α ∧(X
dβ + d(X
β)).
(13.12)
On the other hand, using the fact that both d and iX are antiderivations,
we compute
X
d(α ∧β) + d(X
(α ∧β))
= X
(dα ∧β −α ∧dβ) + d((X
α) ∧β −α ∧(X
β))
= (X
dα) ∧β + dα ∧(X
β) −(X
α) ∧dβ
+ α ∧(X
dβ) + d(X
α) ∧β + (X
α) ∧dβ
−dα ∧(X
β) + α ∧d(X
β).
After the obvious cancellations are made, this is equal to (13.12).
Corollary 13.15. If X is a vector ﬁeld and ω is a diﬀerential form, then
LX(dω) = d(LXω).
Proof. This follows from the preceding proposition and the fact that d2 = 0:
LXdω = X
d(dω) + d(X
dω)
= d(X
dω);
dLXω = d(X
dω + d(X
ω))
= d(X
dω).
As promised, Proposition 13.14 gives a formula for the Lie derivative
of a diﬀerential form that can be computed easily in local coordinates,
without having to go to the trouble of letting the form act on vector ﬁelds.
In fact, this leads to an easy algorithm for computing Lie derivatives of
arbitrary tensor ﬁelds, since any tensor ﬁeld can be written locally as a
linear combination of tensor products of 1-forms. This is easiest to illustrate
with an example.
Example 13.16. Suppose T is an arbitrary smooth symmetric 2-tensor
ﬁeld on a smooth manifold M, and let Y be a smooth vector ﬁeld. We will
compute the Lie derivative LY T in coordinates (xi). First, we observe that
LY dxi = d(Y
dxi) + Y
d(dxi) = dY i. Therefore,
LY T = LY (Tij)dxi ⊗dxj + Tij(LY dxi) ⊗dxj + Tij dxi ⊗(LY dxj)
= Y Tij dxi + Tij dY i ⊗dxj + Tij dxi ⊗dY j
=

Y Tij + Tjk
∂Y k
∂xi + Tik
∂Y k
∂xj

dxi ⊗dxj.

Applications
343
Applications
What is the meaning of the Lie derivative of a tensor ﬁeld with respect to
a vector ﬁeld X? We have already seen that the Lie derivative of a vector
ﬁeld Y with respect to X is zero if and only if Y is invariant along the ﬂow
of X. It turns out that the Lie derivative of a covariant tensor ﬁeld has
exactly the same interpretation. We say that a tensor ﬁeld σ is invariant
under a ﬂow θ if θ∗
t σ = σ on the domain of θt.
The next lemma shows how the Lie derivative can be used to compute
t-derivatives at times other than t = 0; it is a generalization of formula
(13.8) to tensor ﬁelds.
Lemma 13.17. Let M be a smooth manifold, X ∈T(M), and let θ be the
ﬂow of X. For any smooth covariant tensor ﬁeld τ and any (t0, p) in the
domain of θ,
d
dt

t=t0
θ∗
t (τθt(p)) = θ∗
t0(LXτ)θt0 (p).
Proof. Just as in the proof of Proposition 13.9, the change of variables
t = t0 + s yields
d
dt

t=t0
θ∗
t (τθt(p)) = d
ds

s=0
(θt0+s)∗τθs+t0 (p)
= d
ds

s=0
(θt0)∗(θs)∗τθs(θt0(p))
= (θt0)∗d
ds

s=0
(θs)∗τθs(θt0(p))
= (θt0)∗(LV W)θt0 (p).
Proposition 13.18. Let M be a smooth manifold and let X ∈T(M). A
smooth covariant tensor ﬁeld τ is invariant under the ﬂow of X if and only
if LXτ = 0.
Proof. Let θ denote the ﬂow of X. If τ is invariant under θ, then θ∗
t τ = τ
for all t. Inserting this into the deﬁnition of the Lie derivative, we see
immediately that LXτ = 0.
Conversely, suppose LXτ = 0. For any p ∈M, let Dp denote the domain
of θ(p), and consider the smooth curve T : Dp →T k(TpM) deﬁned by
T (t) = θ∗
t (τθt(p)).
Lemma 13.17 shows that T ′(t) = 0 for all t ∈Dp. Because Dp is a connected
interval containing zero, this implies that T (t) = T (0) = τp for all t ∈Dp.

344
13. Lie Derivatives
This is the same as
θ∗
t (τθt(p)) = τp,
which says precisely that τ is invariant under θ.
Killing Fields
Let (M, g) be a Riemannian manifold. A vector ﬁeld Y on M is called a
Killing ﬁeld for g if g is invariant under the ﬂow of Y . By Proposition 13.18,
this is the case if and only if LY g = 0.
Example 13.16 applied to the case T = g gives the following coordinate
expression for LY g:
(LY g)
 ∂
∂xi , ∂
∂xj

= Y gij + gjk
∂Y k
∂xi + gik
∂Y k
∂xj .
(13.13)
Example 13.19 (Euclidean Killing Fields).
Let g be the Euclidean
metric on Rn. In standard coordinates, the condition for a vector ﬁeld to
be a Killing ﬁeld with respect to g reduces to
∂Y j
∂xi + ∂Y i
∂xj = 0.
It is easy to check that all constant vector ﬁelds satisfy this equation, as
do the vector ﬁelds
xi ∂
∂xj −xj ∂
∂xi ,
which generate rotations in the (xi, xj)-plane.
The Divergence
For our next application, we let (M, g) be an oriented Riemannian n-
manifold. Recall that the divergence of a smooth vector ﬁeld X ∈T(M) is
the smooth function div X characterized by
(div X)dVg = d(X
dVg).
Now we can give a geometric interpretation to the divergence, which ex-
plains the choice of the term “divergence.” Observe that formula (13.11)
for the Lie derivative of a diﬀerential form implies
LXdVg = X
d(dVg) + d(X
dVg) = (div X)dVg,
because the exterior derivative of any n-form on an n-manifold is zero.

Applications
345
A ﬂow θ on M is said to be volume preserving if for every compact
domain of integration D ⊂M and every t ∈R such that D is contained in
the domain of θt, Vol(θt(D)) = Vol(D). It is volume increasing if for any
such D with positive volume, Vol(θt(D)) is a strictly increasing function of
t, and volume decreasing if it is strictly decreasing. Note that the properties
of ﬂow domains ensure that, if D is contained in the domain of θt for some
t, then the same is true for all times between 0 and t. The next proposition
shows that the divergence of a vector ﬁeld is a quantitative measure of the
tendency of its ﬂow to “spread out” or diverge.
Proposition 13.20. Let M be an oriented Riemannian manifold and let
X ∈T(M).
(a) The ﬂow of X is volume preserving if and only if div X ≡0.
(b) If div X > 0, then the ﬂow of X is volume increasing, and if div X <
0, then it is volume decreasing.
Proof. Let θ be the ﬂow of X, and for each t let Mt be the domain of θt.
If D is a compact domain of integration contained in Mt, then
Vol(θt(D)) =
Z
θt(D)
dVg =
Z
D
θ∗
t dVg.
Because the integrand is a smooth function of t, we can diﬀerentiate this ex-
pression with respect to t by diﬀerentiating under the integral sign. (Strictly
speaking, we should use a partition of unity to express the integral as a sum
of integrals over domains in Rn, and then diﬀerentiate under the integral
signs there. The details are left to you.) Using Lemma 13.17, we obtain
d
dt

t=t0
Vol(θt(D)) =
Z
D
∂
∂t

t=t0
(θ∗
t dVg)
=
Z
D
θ∗
t0(LXdVg)
=
Z
D
θ∗
t0((div X)dVg)
=
Z
θt0(D)
(div X)dVg.
It follows that div X ≡0 implies that Vol(θt(D)) is a constant function
of t, while div X > 0 or div X < 0 implies that it is strictly increasing or
strictly decreasing, respectively.
Now assume that θ is volume preserving. If div X ̸= 0 at some point
p ∈M, then there is some open set U containing p on which div X does
not change sign. If div X > 0 on U, then X generates a volume increasing
ﬂow on U by the argument above. In particular, for any coordinate ball

346
13. Lie Derivatives
B such that B ⊂U and any t > 0 suﬃciently small that θt(B) ⊂U, we
have Vol(θt(B)) > Vol(B), which contradicts the assumption that θ is vol-
ume preserving. The argument in the case div X < 0 is exactly analogous.
Therefore div X ≡0.
Symplectic Manifolds
Let (M, ω) be a symplectic manifold. (Recall that this means a smooth
manifold M endowed with a symplectic form ω, which is a closed nonde-
generate 2-form.) One of the most important constructions on symplec-
tic manifolds is a symplectic analogue of the gradient, deﬁned as follows.
Because of the nondegeneracy of ω, the bundle map eω: TM →T ∗M
given by eω(X)(Y ) = ω(X, Y ) is an isomorphism. For any smooth func-
tion f ∈C∞(M), we deﬁne the Hamiltonian vector ﬁeld of f to be the
vector ﬁeld Xf deﬁned by
Xf = eω−1(df),
so Xf is characterized by
ω(Xf, Y ) = df(Y ) = Y f
for any vector ﬁeld Y . Another way to write this is
Xf
ω = df.
Example 13.21. On R2n with the standard symplectic form ω
=
Pn
i=1 dxi ∧dyi, Xf can be computed explicitly as follows. Writing
Xf =
n
X
i=1
Ai ∂
∂xi + Bi ∂
∂yi
for some coeﬃcient functions (Ai, Bi) to be determined, we compute
Xf
ω =
n
X
j=1

Aj ∂
∂xj + Bj ∂
∂yj

n
X
i=1
dxi ∧dyi
=
n
X
i=1
Ai dyi −Bi dxi.
(When working with the standard symplectic form, like the Euclidean met-
ric, it is usually necessary to insert explicit summation signs.) On the other
hand,
df =
n
X
i=1
∂f
∂xi dxi + ∂f
∂yi dyi.

Applications
347
Setting these two expressions equal to each other, we ﬁnd that Ai = ∂f/∂yi
and Bi = −∂f/∂xi, which yields the following formula for the Hamiltonian
vector ﬁeld of f:
Xf =
n
X
i=1
∂f
∂yi
∂
∂xi −∂f
∂xi
∂
∂yi .
(13.14)
Although the deﬁnition of the Hamiltonian vector ﬁeld is formally analo-
gous to that of the gradient on a Riemannian manifold, Hamiltonian vector
ﬁelds diﬀer from gradients in some very signiﬁcant ways, as the next lemma
shows.
Proposition 13.22 (Properties of Hamiltonian Vector Fields).
Let (M, ω) be a symplectic manifold and let f ∈C∞(M).
(a) f is constant along the ﬂow of Xf, i.e., if θ is the ﬂow, then f◦θt(p) =
f(p) for all (t, p) in the domain of θ.
(b) At each regular point of f, the Hamiltonian vector ﬁeld Xf is tangent
to the level set of f.
Proof. Both assertions follow from the fact that
Xff = df(Xf) = ω(Xf, Xf) = 0
because ω is alternating.
A vector ﬁeld X on M is said to be symplectic if ω is invariant under the
ﬂow of X. It is said to be Hamiltonian (or globally Hamiltonian) if there
exists a smooth function f such that X = Xf, and locally Hamiltonian
if every point p has a neighborhood on which X is Hamiltonian. Clearly
every globally Hamiltonian vector ﬁeld is locally Hamiltonian.
Proposition 13.23 (Hamiltonian and Symplectic Vector Fields).
Let (M, ω) be a symplectic manifold. A smooth vector ﬁeld on M is sym-
plectic if and only if it is locally Hamiltonian. Every locally Hamiltonian
vector ﬁeld on M is globally Hamiltonian if and only if H1
dR(M) = 0.
Proof. By Proposition 13.18, a vector ﬁeld X is symplectic if and only if
LXω = 0. Using formula (13.11) for the Lie derivative of a diﬀerential form,
we compute
LXω = d(X
ω) + X
(dω) = d(X
ω).
(13.15)
Therefore X is symplectic if and only if the 1-form X
ω is closed. On the
one hand, if X is locally Hamiltonian, then in a neighborhood of each point
there is a function f such that X = Xf, so X
ω = Xf
ω = df, which
is certainly closed. Conversely, if X is symplectic, then by the Poincar´e

348
13. Lie Derivatives
lemma each point p ∈M has a neighborhood U on which the closed 1-form
X
ω is exact. This means there is a smooth function f deﬁned on U such
that X
ω = df, which means X = Xf on U.
Now suppose H1
dR(M) = 0. Then every closed form is exact, so for any
locally Hamiltonian (hence symplectic) vector ﬁeld X there is a smooth
function f such that X ω = df. This means that X = Xf, so X is globally
Hamiltonian. Conversely, suppose every locally Hamiltonian vector ﬁeld is
globally Hamiltonian. Let η be a closed 1-form, and let X be the vector
ﬁeld X = eω−1η. Then (13.15) shows that LXω = 0, so X is symplectic
and therefore locally Hamiltonian. By hypothesis, there is a global smooth
function f such that X = Xf, and then unwinding the deﬁnitions, we ﬁnd
that η = df.
Using Hamiltonian vector ﬁelds, we deﬁne an operation on functions
similar to the Lie bracket of vector ﬁelds. Given f, g ∈C∞(M), we deﬁne
their Poisson bracket {f, g} ∈C∞(M) by
{f, g} = Xf g = ω(Xg, Xf).
Two functions are said to Poisson commute if their Poisson bracket is zero.
Example 13.24. Using the result of Example 13.21, we can easily com-
pute the Poisson bracket of two functions f, g on R2n:
{f, g} =
n
X
i=1
∂f
∂yi
∂g
∂xi −∂f
∂xi
∂g
∂yi .
(13.16)
Proposition 13.25 (Properties of the Poisson Bracket).
Let
(M, ω) be a symplectic manifold, and f, g ∈C∞(M).
(a) {f, g} = −{g, f}.
(b) g is constant along the ﬂow of Xf if and only if {f, g} = 0.
(c) X{f,g} = [Xf, Xg].
Proof. Part (a) is evident from the characterization {f, g} = ω(Xg, Xf),
and (b) from {f, g} = Xfg. The proof of (c) is a computation using Propo-
sition 13.11(e):
d{f, g} = d(Xfg)
= d(LXf g)
= LXf dg
= LXf (Xg
ω)
= (LXf Xg)
ω + Xg
LXf ω
= [Xf, Xg]
ω,
which is equivalent to (c).

Applications
349
Our next theorem, called the Darboux theorem, is central in the theory
of symplectic structures. It is a nonlinear analogue of the canonical form
for a symplectic tensor given in Proposition 9.17.
Theorem 13.26 (Darboux).
Let (M, ω) be a 2n-dimensional symplectic
manifold. Near every point p ∈M, there are coordinates (x1, y1, . . . , xn, yn)
in which ω is given by
ω =
n
X
i=1
dxi ∧dyi.
(13.17)
Any coordinates satisfying the conclusion of the Darboux theorem are
called Darboux coordinates, symplectic coordinates, or canonical coordi-
nates. Before we begin the proof, let us prove the following lemma, which
shows that Darboux coordinates are characterized by the Poisson brackets
of the coordinate functions.
Lemma 13.27. Let (M, ω) be a symplectic manifold. Coordinates (xi, yi)
on an open set U ⊂M are Darboux coordinates if and only if their Poisson
brackets satisfy
{xi, xj} = {yi, yj} = 0;
{xi, yj} = −δij.
(13.18)
Proof. One direction is easy: If ω is given by (13.17), then formula
(13.16) shows that the Poisson brackets of the coordinate functions sat-
isfy (13.18). Conversely, If (xi, yi) are coordinates whose Poisson brackets
satisfy (13.18), then the Hamiltonian ﬁelds of the coordinates satisfy
dxj(Xxi) = Xxi(xj) = {xi, xj} = 0,
dyj(Xxi) = Xxi(yj) = {xi, yj} = −δij,
dxj(Xyi) = Xyi(xj) = {yi, xj} = δij,
dyj(Xyi) = Xyi(yj) = {yi, yj} = 0.
This implies that
Xxi = −∂
∂yi ,
Xyi =
∂
∂xi .
If we write
ω = Aijdxi ∧dxj + Bijdxi ∧dyj + Cijdyi ∧dyj,
with Aij = −Aji and Cij = −Cji, then the coeﬃcients are determined by
Aij = 1
2ω
 ∂
∂xi , ∂
∂xj

= 1
2ω(Xyi, Xyj) = 1
2{yj, yi} = 0.
Bij = ω
 ∂
∂xi , ∂
∂yj

= −ω(Xyi, Xxj) = −{xj, yi} = δij.
Cij = 1
2ω
 ∂
∂yi , ∂
∂yj

= 1
2ω(Xxi, Xxj) = 1
2{xj, xi} = 0.

350
13. Lie Derivatives
This shows that ω has the form (13.17).
Proof of the Darboux Theorem.
We will show by induction on k that for
each k = 0, . . . , n there are functions (x1, y1, . . . , xk, yk) satisfying (13.18)
near p such that {dx1, dy1, . . . , dxk, dyk} are independent at p. When k = n,
this proves the theorem.
For n = 0, there is nothing to prove. So suppose we have such
(x1, y1, . . . , xk, yk). Observe that the Hamiltonian vector ﬁeld of any con-
stant function is zero. Therefore, because all of the Poisson brackets of the
coordinates are constants, the Hamiltonian vector ﬁelds of the coordinates
satisfy
[Xxi, Xxj] = X{xi,xj} = 0,
[Xxi, Xyj] = X{xi,yj} = 0,
[Xyi, Xyj] = X{yi,yj} = 0.
Because eω: TpM →T ∗
p M is an isomorphism and the diﬀerentials {dxi, dyi}
are independent, these Hamiltonian vector ﬁelds are all independent in a
neighborhood of p. Thus by the normal form theorem for commuting vector
ﬁelds, there are coordinates (u1, . . . , u2n) near p such that
∂
∂ui = Xxi,
∂
∂ui+k = Xyi,
i = 1, . . . , k.
(13.19)
Let xk+1 = u2k+1 in this coordinate system. Then xk+1 Poisson commutes
with xi and yi for i = 1, . . . , k, because
{xi, xk+1} = Xxi(xk+1) =
∂
∂ui u2k+1 = 0,
{yi, xk+1} = Xyi(xk+1) =
∂
∂ui+k u2k+1 = 0.
(13.20)
The restriction of ω to span{Xxi, Xyi, i = 1, . . . , k} is nondegenerate, as
can easily be veriﬁed by computing the action of ω on these vectors using
(13.18). Therefore, Xxk+1 is independent of {Xxi, Xyi, i = 1, . . . , k} because
(13.20) implies ω(Xxk+1, Xxi) = ω(Xxk+1, Xyi) = 0. Just as before, the
2k + 1 Hamiltonian vector ﬁelds of the functions (x1, y1, . . . , xk, yk, xk+1)
all commute, so we can ﬁnd new coordinates (vi) such that
∂
∂vi = Xxi,
i = 1, . . . , k + 1,
∂
∂vi+k+1 = Xyi,
i = 1, . . . , k.

Applications
351
Finally, let yk+1 = −vk+1 in these coordinates. The independence condition
is satisﬁed as before, and we compute
{xk+1, yk+1} = Hxk+1yk+1 =
∂
∂vk+1 (−vk+1) = −1.
{xj, yk+1} = −Hxjyk+1 =
∂
∂vj vk+1 = 0,
j = 1, . . . , k,
{yj, yk+1} = −Hyjyk+1 =
∂
∂vj+k+1 vk+1 = 0,
j = 1, . . . , k.
This completes the inductive step.
This theorem was ﬁrst proved in 1882 by Darboux. A much more elegant
proof was discovered in the 1960s by J¨urgen Moser [Mos65] and Alan We-
instein [Wei69]. It requires a bit more machinery than we have developed,
but you can look it up, for example, in [Wei77] or [AM78].
The theory of symplectic manifolds is central to the study of classical
mechanics. Many classical dynamical systems moving under the inﬂuence
of Newton’s laws of motion can be modeled naturally as the ﬂow of a
Hamiltonian vector ﬁeld on a symplectic manifold. If one can ﬁnd one or
more functions that Poisson commute with the Hamiltonian, then they
must be constant along the ﬂow, so by restricting attention to a common
level set of these functions one can often reduce the problem to one with
fewer degrees of freedom. For much more on these ideas, see [AM78].

352
13. Lie Derivatives
Problems
13-1. Let V, W, X ∈T(M) and f, g ∈C∞(M). Show that
(a) [fV, gW] = fg[V, W] + f(V g)W −g(Wf)V .
(b) LV (fW) = (V f)W + fLV W.
(c) L[V,W]X = LV LW X −LW LV X.
13-2. Let V and W be the vector ﬁelds of Exercise 13.2(b). Compute the
ﬂows θ, ψ of V and W, and verify that they do not commute by
ﬁnding explicit times s and t such that θs ◦ψt ̸= ψt ◦θs.
13-3. Give an example of vector ﬁelds V , eV , and W on R2 such that V =
eV = ∂/∂x along the x-axis but LV W ̸= LeV W at the origin. [This
shows that it is really necessary to know the vector ﬁeld V to compute
(LV W)p; it is not suﬃcient just to know the vector Vp, or even to
know the values of V along an integral curve of V .]
13-4. Determine all Killing ﬁelds on (Rn, g).
13-5. Let M be a smooth manifold and ω a 1-form on M. Show that for
any smooth vector ﬁelds X, Y ,
dω(X, Y ) = X(ω(Y )) −Y (ω(X)) −ω[X, Y ].
13-6. Generalize the result of Problem 13-5 to a k-form ω by showing that
dω(X1, . . . , Xk+1) =
X
1≤i≤k+1
(−1)i−1Xi(ω(X1, . . . , b
Xi, . . . , Xk+1))
+
X
1≤i<j≤k+1
(−1)i+jω([Xi, Xj], X1, . . . , b
Xi, . . . , b
Xj, . . . , Xk+1),
where the hats indicate omitted arguments. [This formula can be used
to give a coordinate-free deﬁnition of the exterior derivative. However,
this deﬁnition has the serious ﬂaw that, in order to compute the action
of dω on vectors (X1, . . . , Xk) at a point p ∈M, one must ﬁrst extend
them to vector ﬁelds in a neighborhood of p. It is not evident from
this formula that the resulting value is independent of the extensions
chosen.]
13-7. For each k-tuple of vector ﬁelds on R3 shown below, either ﬁnd coor-
dinates (u1, u2, u3) in a neighborhood of (1, 0, 0) such that Vi = ∂/∂ui
for i = 1, . . . , k, or explain whey there are none.
(a) k = 1; V1 = x ∂
∂y −y ∂
∂x.

Problems
353
(b) k = 2; V1 = ∂
∂x, V2 = ∂
∂x + ∂
∂y .
(c) k = 2; V1 = x ∂
∂y −y ∂
∂x, V2 = x ∂
∂x + y ∂
∂y.
(d) k = 3; V1 = x ∂
∂y −y ∂
∂x, V2 = y ∂
∂z −z ∂
∂y, V3 = z ∂
∂x −x ∂
∂z .
13-8. Let (M, ω) be a symplectic manifold. Show that the Poisson bracket
satisﬁes the following identity for all f, g, h ∈C∞(M):
{{f, g}, h} + {{g, h}, f} + {{h, f}, g} = 0.

354
13. Lie Derivatives

14
Integral Manifolds and Foliations
Suppose V is a nonvanishing vector ﬁeld on a manifold M. The results
of Chapter 12 tell us that each integral curve of V is an immersion, and
that locally the images of the integral curves ﬁt together nicely like parallel
lines in Euclidean space. In particular, the fundamental theorem on ﬂows
tells us that these curves are determined by the knowledge of their tangent
vectors.
In this chapter we explore an important generalization of this idea to
higher-dimensional submanifolds. The general setup is this: Suppose we
are given a k-dimensional subspace of TpM at each point p ∈M, varying
smoothly from point to point. (Such a collection of subspaces is called a
“tangent distribution.”) Is there a k-dimensional submanifold (called an
“integral manifold” of the tangent distribution) whose tangent space at
each point is the given subspace? The answer in this case is more compli-
cated than in the case of vector ﬁelds: There is a necessary condition, called
involutivity, that must be satisﬁed by the tangent distribution. The main
theorem of this chapter, the Frobenius theorem, tells us that this condition
is also suﬃcient.
We will prove the Frobenius theorem in two forms: a local form, which
says that a neighborhood of every point is ﬁlled up with integral manifolds,
ﬁtting together nicely like parallel subspaces of Rn, and a global form, which
says that the entire manifold is the disjoint union of immersed integral
manifolds.

356
14. Integral Manifolds and Foliations
Tangent Distributions
Let M be a smooth manifold. Given a smooth vector bundle π: E →M, a
(smooth) subbundle of E is a subset D ⊂E with the following properties:
(i) D is an embedded submanifold of E.
(ii) For each p ∈M, the ﬁber Dp = D ∩π−1(p) is a linear subspace of
Ep = π−1(p).
(iii) With the vector space structure on each Dp inherited from Ep and
the projection π|D : D →M, D is a smooth vector bundle over M.
Note that the condition that D be a vector bundle implies that the projec-
tion π|D : D →M must be surjective, and that all the ﬁbers Dp must have
the same dimension.
Exercise 14.1.
If D ⊂E is a smooth subbundle, show that the inclusion
map ι: D →E is a bundle map.
A subbundle of TM is called a tangent distribution on M, or just a
distribution if there is no opportunity for confusion with the use of the term
“distribution” for generalized functions in analysis. Other common names
for distributions are tangent subbundles or plane ﬁelds. The dimension of
each ﬁber of D is called dimension of the distribution.
The following lemma gives a convenient condition for checking that a
collection of subspaces {Dp ⊂TpM : p ∈M} is a distribution.
Lemma 14.1. Let M be a smooth manifold, and suppose for each p ∈
M we are given a k-dimensional linear subspace Dp ⊂TpM. Then D =
`
p∈M Dp ⊂TM is a distribution if and only if the following condition is
satisﬁed:
Each point p ∈M has a neighborhood U on which there
are smooth vector ﬁelds Y1, . . . , Yk : U →TM such that
Y1|p, . . . , Yk|p form a basis for Dp at each p ∈U.
(14.1)
Proof. If D is a distribution, then by deﬁnition any p ∈M has a neighbor-
hood U over which there exists a local trivialization of D, and by Problem
3-5 there exists a smooth local frame for D over any such set U. Such a local
frame is by deﬁnition a collection of smooth sections σ1, . . . , σk : U →D
whose images form a basis for Dp at each point p ∈U. The smooth vector
ﬁelds we seek are given by Yj = ι ◦σj, where ι: D ,→TM is inclusion.
Conversely, suppose that D satisﬁes (14.1). Condition (ii) in the deﬁ-
nition of a subbundle is true by hypothesis, so we need to show that D
satisﬁes conditions (i) and (iii).
To prove that D is an embedded submanifold, it suﬃces to show that
each point p ∈M has a neighborhood U such that D ∩π−1(U) is an

Integral Manifolds and Involutivity
357
embedded submanifold of π−1(U) ⊂TM. Given p ∈M, let Y1, . . . , Yk
be vector ﬁelds deﬁned on a neighborhood of p and satisfying (14.1). The
independent vectors Y1|p, . . . , Yk|p can be extended to a basis Y1|p, . . . , Yn|p
for TpM, and then Yk+1|p, . . . , Yn|p can be extended to vector ﬁelds in a
neighborhood of p. By continuity, they will still be independent in some
neighborhood U of p, so they form a local frame for TM over U. By Problem
3-5 again, this yields a local trivialization π−1(U) →U × Rn deﬁned by
yiYi|q 7→(q, (y1, . . . , yn)).
In terms of this trivialization, D ∩π−1(U) corresponds to U × Rk =
{(q, (y1, . . . , yk, 0, . . . , 0))} ⊂U ×Rn, which is obviously a regular subman-
ifold. Moreover, the map Φ|D∩π−1(U) : D ∩π−1(U) →U × Rk is obviously
a local trivialization of D, showing that D is itself a vector bundle.
In the situation of the preceding lemma, we say D is the distribution
(locally) spanned by the vector ﬁelds Y1, . . . , Yk.
Integral Manifolds and Involutivity
Suppose D ⊂TM is a distribution. An immersed submanifold N ⊂M is
called an integral manifold of D if TpN = Dp at each point p ∈N. The
main question we want to address in this chapter is the existence of integral
manifolds.
Before we proceed with the general theory, let us describe some examples
of distributions and integral manifolds that you should keep in mind.
Example 14.2 (Tangent distributions).
(a) If V is any nowhere-vanishing vector ﬁeld on a manifold M, then
V spans a 1-dimensional distribution on M (i.e., Dp = span(Vp) for
each p ∈M). The smoothness criterion (14.1) is obviously satisﬁed.
The image of any integral curve of V is an integral manifold of D.
(b) In Rn, the vector ﬁelds ∂/∂x1, . . . , ∂/∂xk span a k-dimensional distri-
bution. The k-dimensional aﬃne subspaces parallel to Rk are integral
manifolds.
(c) Deﬁne a distribution on R3 ∖{0} by letting Dp be the tangent space
to the sphere through p and centered at 0. Away from the north
and south poles, D is locally spanned by the coordinate vector ﬁelds
∂/∂θ and ∂/∂ϕ in spherical coordinates; near the poles, we can use
spherical coordinates composed with a suitable rotation. Thus D is
a 2-dimensional distribution on R3 ∖{0}. Through each point p ∈
R3 ∖{0}, the sphere of radius |p| around 0 is an integral manifold.

358
14. Integral Manifolds and Foliations
(d) Let X and Y be the following vector ﬁelds on R3:
X = ∂
∂x + y ∂
∂z
Y = ∂
∂y,
and let D be the distribution spanned by X and Y . It turns out that
D has no integral manifolds. To get an idea why, suppose N is an
integral manifold through the origin. Because X and Y are tangent
to N, any integral curve of X or Y that starts in N will have to
stay in N, at least for a short time. Thus N contains an open subset
of the x-axis (which is an integral curve of X). It also contains, for
each suﬃciently small x, an open subset of the line parallel to the
y-axis and passing through (x, 0, 0) (which is an integral curve of Y ).
Therefore N contains an open subset of the (x, y)-plane. However,
the tangent planes to points of the (x, y)-plane at points oﬀof the
x-axis are not contained in D. Therefore, no such integral manifold
exists.
The last example shows that, in general, integral manifolds may fail to
exist. The reason for this failure is expressed in the following proposition.
We say that a tangent distribution D is involutive if given any pair of local
sections of D (i.e., vector ﬁelds X, Y deﬁned on an open subset of M such
that Xp, Yp ∈Dp for each p), their Lie bracket is also a section of D. We say
D is integrable if through each point of M there exists an integral manifold
of D.
Proposition 14.3. Every integrable distribution is involutive.
Proof. Suppose X and Y are local sections of D deﬁned on some open
subset U ⊂M. Let p be any point in U, and let N be an integral manifold
of D passing through p. The fact that X and Y are sections of D means
that X and Y are tangent to N. By Proposition 13.4, [X, Y ] is also tangent
to N, and therefore [X, Y ]p ∈Dp.
The next lemma shows that the involutivity condition does not have to
be checked for every pair of vector ﬁelds, just those of a local frame near
each point.
Lemma 14.4. Let D ⊂TM be a distribution. If in a neighborhood of every
point of M there exists a local frame (V1, . . . , Vk) for D such that [Vi, Vj]
is a section of D for each i, j = 1, . . . , k, then D is involutive.
Proof. Suppose the hypothesis holds, and suppose X and Y are sections
of D over some open subset U ⊂M. Given p ∈M, choose a local frame
(V1, . . . , Vk) satisfying the hypothesis in a neighborhood of p, and write
X = XiVi and Y = Y iVi. Then (using the result of Problem 13-1),
[X, Y ] =

XiVi, Y jVj

= XiY j[Vi, Vj] + Xi(ViY j)Vj −Y j(VjXi)Vi.

The Frobenius Theorem
359
It follows from the hypothesis that this last expression is a section of D.
The Frobenius Theorem
In Example 14.2, all of the tangent distributions we deﬁned except the last
one had the property that there was an integral manifold through each
point. Moreover, these submanifolds all “ﬁt together” nicely like parallel
aﬃne subspaces of Rn. Given a k-dimensional distribution D ⊂TM, let
us say that a coordinate chart (U, ϕ) on M is ﬂat for D if at points of U,
D is spanned by the ﬁrst k coordinate vector ﬁelds ∂/∂x1, . . . , ∂/∂xk. It is
obvious that each slice of the form xk+1 = ck+1, . . . , xn = cn for constants
ck+1, . . . , cn is an integral manifold of D. This is the nicest possible local
situation for integral manifolds We say that a distribution D ⊂TM is
completely integrable if there exists a ﬂat chart for D in a neighborhood
of every point of M. Obviously every completely integrable distribution is
integrable and therefore involutive.
The next theorem is the main result of this chapter, and indeed one
of the central theorems in smooth manifold theory. (The others are the
inverse function theorem, the fundamental theorem on ﬂows, and Stokes’s
theorem.)
Theorem 14.5 (Frobenius). Every involutive distribution is completely
integrable.
Proof. The canonical form theorem for commuting vector ﬁelds (Theorem
13.10) implies that any distribution locally spanned by commuting vector
ﬁelds is completely integrable. Thus it suﬃces to show that any involutive
distribution is locally spanned by commuting vector ﬁelds.
Let D be a k-dimensional involutive distribution on an n-dimensional
manifold M. Given p ∈M, choose a neighborhood U of p on which there
exist coordinates (x1, . . . , xn) centered at p and a local frame Y1, . . . , Yk for
D. By a linear change of coordinates, we may assume that ∂/∂xi|p = Yi|p.
Let Π: U →Rk be the smooth map whose coordinate representation is
the projection onto the ﬁrst k coordinates: Π(x1, . . . , xn) = (x1, . . . , xk).
This induces a smooth map Π∗: TU →T Rk, which can be written
Π∗

n
X
i=1
vi
∂
∂xi

q

=
k
X
i=1
vi
∂
∂xi

Π(q)
.
(Notice that the summation is only over i = 1, . . . , k on the right-hand side.)
Clearly, the restriction of Π∗to Dp ⊂TpM is an isomorphism, and thus by
continuity the same is true of Π∗: Dq →TΠ(q)Rk for q in a neighborhood
of p. The matrix entries of Π∗|D with respect to the frames {Yi|q} and
{∂/∂xj|Π(q)} are smooth functions of q, and thus so are the matrix entries

360
14. Integral Manifolds and Foliations
of
 Π∗|Dq
−1 : TΠ(q)Rk →Dq. Deﬁne a new local frame X1, . . . , Xk for D
near p by
Xi|q =
 Π∗|Dq
−1
∂
∂xi

Π(q)
.
(14.2)
The theorem will be proved if we can show that [Xi, Xj] = 0 for all i, j.
First observe that Xi and ∂/∂xi are Π-related, because (14.2) implies
that
∂
∂xi

Π(q)
=
 Π∗|Dq

Xi|q = Π∗Xi|q.
Therefore, by the naturality of Lie brackets,
Π∗[Xi, Xj]q =
 ∂
∂xi , ∂
∂xj

Π(q)
= 0.
Since [Xi, Xj] takes its values in D by involutivity, and Π∗is injective on
D, this implies that [Xi, Xj]q = 0 for each q, thus completing the proof.
One immediate consequences of the theorem is the following lemma,
which we will use repeatedly.
Proposition 14.6 (Local Structure of Integral Manifolds).
Let D
be an involutive k-dimensional distribution on a smooth manifold M, and
let (U, ϕ) be a ﬂat chart for D. If N is any integral manifold of D, then
N ∩U is a countable disjoint union of open subsets of k-dimensional slices
of U, each of which is open in N and embedded in M.
Proof. Because the inclusion map ι: N ,→M is continuous, N∩U = ι−1(U)
is open in N, and thus consists of a countable disjoint union of connected
components, each of which is open in N.
Let V be any component of N ∩U. We will show ﬁrst that V is contained
in a single slice. Choosing some p ∈V , it suﬃces to show that xi(q) = xi(p)
for i = k + 1, . . . , n for any q ∈V . Since V is connected, there exists a
path γ in V from p to q, which we may take to be smooth by Problem
6-1. Because γ lies in V and V is an integral manifold of D, we have
γ′(t) ∈Tγ(t)V = Dγ(t). Because D is spanned by ∂/∂x1, . . . , ∂/∂xk in U,
this implies that the last n −k components of γ′(t) are zero: (γi)′(t) ≡0
for i ≥k + 1. Since the domain of γ is connected, this means γi is constant
for these values of i, so p and q lie in a single slice S.
Because S is embedded in M, the inclusion map V ,→M is also smooth
as a map into S by Corollary 5.38. The inclusion V ,→S is thus an injective
immersion between manifolds of the same dimension, and therefore a local
diﬀeomorphism, an open map, and a homeomorphism onto an open subset
of S.

Applications
361
This local characterization of integral manifolds implies the following
strengthening of our theorem about restricting the range of a smooth map.
(This result will be used in Chapter 15.)
Proposition 14.7. Suppose H ⊂N is an integral manifold of an invo-
lutive distribution D on N. If F : M →N is a smooth map such that
F(M) ⊂H, then F is smooth as a map from M to H.
Proof. Let p ∈M be arbitrary, and set q = F(p) ∈H. Let (y1, . . . , yn)
be ﬂat coordinates for D on a neighborhood U of q. Choose coordinates
(xi) for M on a connected neighborhood B of p. Writing the coordinate
representation of F as
(y1, . . . , yn) = (F 1(x), . . . , F n(x)),
the fact that F(B) ⊂H means that the coordinate functions F k+1, . . . , F n
take on only countably many values. Because B is connected, the intermedi-
ate value theorem implies that these coordinate functions are constant, and
thus F(B) lies in a single slice. On this slice, (y1, . . . , yk) are coordinates
for H, so F : N →H has the local coordinate representation
(y1, . . . , yk) = (F 1(x), . . . , F k(x)),
which is smooth.
Applications
In the next chapter, we will see some geometric applications of the Frobe-
nius theorem. In this chapter, we concentrate on some applications to the
study of partial diﬀerential equations (PDEs).
Our ﬁrst application is not so much an application as a simple rephrasing
of the theorem. Because explicitly ﬁnding integral manifolds boils down to
solving a system of PDEs, we can interpret the Frobenius theorem as an
existence and uniqueness result for such equations.
Suppose we are given n−1 smooth vector ﬁelds Y1, . . . , Yn−1 on an open
subset of Rn, and suppose we seek a smooth function f that satisﬁes the
system of equations Y1f = · · · Yn−1f = 0. Away from the critical points of
f, the level sets of f will be integral manifolds of the distribution spanned
by the Yi’s. Thus the involutivity of this distribution is a necessary and
suﬃcient condition for the existence of a solution f on any open set.
Example 14.8. Consider the system
−2z2 ∂f
∂x + 2x∂f
∂z = 0,
−3z2 ∂f
∂y + 2y ∂f
∂z = 0
(14.3)

362
14. Integral Manifolds and Foliations
of PDEs for a real-valued function f of three variables. It is an example of a
linear, ﬁrst-order system of PDEs for f (linear because the left-hand sides
of (14.3) depend linearly on f, and ﬁrst-order because it involves only ﬁrst
derivatives of f). It is also overdetermined, because there are more equations
than unknown functions. In general, overdetermined systems have solutions
only if they satisfy certain compatibility conditions; in this case, involutivity
is the key.
To see whether (14.3) has nonconstant solutions, we let X and Y denote
the vector ﬁelds
X = −2z2 ∂
∂x + 2x ∂
∂z ,
Y = −3z2 ∂
∂y + 2y ∂
∂z.
These span a 2-dimensional distribution D on the subset U of R3 where
z ̸= 0, as you can easily check. By direct computation, if z ̸= 0,
[X, Y ] = −12xz ∂
∂y + 8yz ∂
∂x = 4x
z Y −4y
z X,
which shows that D is involutive on U. Therefore, on a neighborhood of
any point (x0, y0, z0) with z0 ̸= 0, there are ﬂat coordinates (u, v, w) for D;
because X and Y are tangent to the level sets of w it follows that f = w
is a solution to (14.3) deﬁned in a neighborhood of (x0, y0, z0). In this ﬂat
chart, (14.3) is equivalent to ∂f/∂u = ∂f/∂v = 0, because ∂/∂u and ∂/∂v
also span D. Therefore, (assuming that the w-slices are connected, which
will be the case if U is small enough), the solutions in U are precisely those
smooth functions that depend on w alone in these coordinates, i.e., those
of the form f(x, y, z) = g(w(x, y, z)) for some smooth function g of one
variable.
Exercise 14.2.
What can you say about solutions in a neighborhood of a
point (x0, y0, 0)?
The next application is more substantial. We introduce it ﬁrst in the case
of a single function f(x, y) of two independent variables, in which case the
notation is considerably simpler.
Suppose we seek a solution f to the system
∂f
∂x(x, y) = α(x, y, f(x, y)),
∂f
∂y (x, y) = β(x, y, f(x, y)),
(14.4)
where α and β are smooth functions deﬁned on some open subset U ⊂R3.
This is an overdetermined system of (possibly nonlinear) ﬁrst-order partial
diﬀerential equations.

Applications
363
To determine the necessary conditions that α and β must satisfy for
solvability of (14.4), assume f is a solution on some open set in R2. Because
∂2f/∂x∂y = ∂2f/∂y∂x, (14.4) implies
∂
∂y
 α(x, y, f(x, y))

= ∂
∂x
 β(x, y, f(x, y))

and therefore by the chain rule
∂α
∂y + β ∂α
∂z = ∂β
∂x + α∂β
∂z .
(14.5)
This is true at any point (x, y, z) ∈U provided there is a smooth solution
f with f(x, y) = z. In particular, (14.5) is a necessary condition for (14.4)
to have a solution in a neighborhood of any point (x0, y0) with arbitrary
initial value f(x0, y0) = z0. Using the Frobenius theorem, we can show that
this condition is suﬃcient.
Proposition 14.9. Suppose α and β are smooth functions deﬁned on some
open set U ⊂R3 and satisfying (14.5) there. For any (x0, y0, z0) ∈U,
there is a neighborhood V of (x0, y0) in R2 and a unique smooth function
f : V →R satisfying (14.4) and f(x0, y0) = z0.
Proof. The idea of the proof is that the system (14.4) determines the partial
derivatives of f in terms of its values, and therefore determines the tangent
plane to the graph of f at each point in terms of the coordinates of the
point on the graph. This collection of tangent planes deﬁnes a 2-dimensional
distribution on U, and (14.5) is equivalent to the involutivity condition for
this distribution.
If there were a solution f on an open set V ⊂R2, the map Φ: V →R3
given by
Φ(x, y) = (x, y, f(x, y))
would be a diﬀeomorphism onto the graph Γ(f) ⊂R2. At any point p =
Φ(x, y), the tangent space TpΓ(f) is spanned by the vector ﬁelds
Φ∗
∂
∂x

(x,y)
= ∂
∂x

p
+ ∂f
∂x(x, y) ∂
∂z

p
,
Φ∗
∂
∂y

(x,y)
= ∂
∂y

p
+ ∂f
∂y (x, y) ∂
∂z

p
.
(14.6)
The system (14.4) is satisﬁed if and only if
Φ∗
∂
∂x

(x,y)
= ∂
∂x

p
+ α(x, y, f(x, y)) ∂
∂z

p
,
Φ∗
∂
∂y

(x,y)
= ∂
∂y

p
+ β(x, y, f(x, y)) ∂
∂z

p
.
(14.7)

364
14. Integral Manifolds and Foliations
Let X and Y be the vector ﬁelds
X = ∂
∂x + α(x, y, z) ∂
∂z ,
Y = ∂
∂y + β(x, y, z) ∂
∂z
on U, and let D be the distribution on U spanned by X and Y . A little
linear algebra will convince you that (14.7) holds if and only if Γ(f) is an
integral manifold of D. A straightforward computation using (14.5) shows
that [X, Y ] ≡0, so through each point p = (x0, y0, z0) ∈U there is an
integral manifold N of D. Let F : W →R be a deﬁning function for N
on some neighborhood W of p; for example, we could take F to be the
third coordinate function in a ﬂat chart. The tangent space to N at each
point p ∈N (namely Dp) is equal to the kernel of F∗: TpR3 →TpR. Since
∂/∂z|p ̸∈Dp at any point p, this implies that ∂F/∂z ̸= 0 at p, so by the
implicit function theorem N is the graph of a smooth function z = f(x, y)
in some neighborhood of p. You can verify easily that f is a solution to the
problem. Uniqueness follows immediately from Proposition 14.6.
There is a straightforward generalization of this result to higher dimen-
sions. The general statement of the theorem may seem hopelessly compli-
cated, but verifying the necessary conditions in speciﬁc examples usually
just amounts to computing mixed partial derivatives and applying the chain
rule.
Proposition 14.10. Suppose αi
j, i = 1, . . . , k, j = 1, . . . , n are smooth
functions deﬁned on some open set U ⊂Rn+k and satisfying
∂αi
j
∂xk + αl
k
∂αi
j
∂zl = ∂αi
k
∂xj + αl
j
∂αi
k
∂zl ,
where we use (x, z) = (x1, . . . , xn, z1, . . . , zk) to denote a point in Rn+k.
For any (x0, z0) ∈U, there is a neighborhood V of x0 in Rn and unique
smooth map f : V →Rk satisfying
∂f i
∂xj (x1, . . . , xn) = αi
j(x1, . . . , xn, f 1(x), . . . , f k(x))
and f(x0) = z0.
Exercise 14.3.
Prove Proposition 14.10.
Foliations
When we put together all the maximal integral manifolds of a k-dimensional
involutive distribution D, we obtain a decomposition of M into k-
dimensional submanifolds that “ﬁt together” locally like the slices in a
ﬂat chart.

Foliations
365
We deﬁne a foliation of dimension k on an n-manifold M to be a col-
lection F of disjoint, connected, immersed k-dimensional submanifolds of
M (called the leaves of the foliation), whose union is M, and such that in
a neighborhood of each point p ∈M there is a chart (U, (xi)) such that
each leaf of the foliation intersects U in either the empty set or a countable
union of k-dimensional slices of the form xk+1 = ck+1, . . . , xn = cn. (Such
a chart is called a ﬂat chart for the foliation.)
Example 14.11 (Foliations).
(a) The collection of all k-dimensional aﬃne subspaces of Rn parallel to
Rk is a k-dimensional foliation of Rn.
(b) The collection of all open rays of the form {λx0 : λ > 0} is a 1-
dimensional foliation of Rn ∖{0}.
(c) The collection of all spheres centered at 0 is an (n −1)-dimensional
foliation of Rn ∖{0}.
(d) The collection of all circles of the form S1 × {q} ⊂T2 as q ranges
over S1 yields a foliation of the torus T2. A diﬀerent foliation of T2
is given by the collection of circles of the form {p} × S1 as p ranges
over S1.
(e) If α is a ﬁxed irrational number, the images of all curves of the form
γθ(t) = (cos t, sin t, cos(αt + θ), sin(αt + θ))
as θ ranges over [0, 2π) form a 1-dimensional foliation of the torus in
which each leaf is dense (cf. Example 5.3 and Problem 5-4).
(f) The collection of curves in R2 satisfying one of the following equations
is a foliation of the plane:
y = sec(x + kπ) + c,
k ∈Z, c ∈R;
x = π
2 + l,
l ∈Z.
(g) If we rotate the curves of the previous example around the z-axis, we
obtain a 2-dimensional foliation of R3 in which some of the leaves are
diﬀeomorphic to disks and some are diﬀeomorphic to annuli.
The main fact about foliations is that they are in one-to-one correspon-
dence with involutive distributions. One direction, expressed in the next
lemma, is an easy consequence of the deﬁnition.
Lemma 14.12. Let F be a foliation of a smooth manifold M. The collec-
tion of tangent spaces to the leaves of F forms an involutive distribution on
M.

366
14. Integral Manifolds and Foliations
Exercise 14.4.
Prove Lemma 14.12.
The Frobenius theorem allows us to conclude the following converse,
which is much more profound. By the way, it is worth noting that this result
is one of the two main reasons why the notion of immersed submanifold
has been deﬁned.
Theorem 14.13 (Global Frobenius Theorem).
Let D be an involu-
tive k-dimensional tangent distribution on a smooth manifold M. The col-
lection of all maximal connected integral manifolds of D forms a foliation
of M.
The theorem will be a consequence of the following lemma.
Lemma 14.14. Let {Nα}α∈A be any collection of connected integral man-
ifolds of D with a point p in common. Then N = S
α Nα has a unique
smooth manifold structure making it into a connected integral manifold of
D in which each Nα is an open submanifold.
Proof. Deﬁne a topology on N by declaring a subset U of N to be open
if and only if U ∩Nα is open in Nα for each α. It is easy to check that
this is a topology. To prove that each Nα is open in N, we need to show
that Nα ∩Nβ is open in Nβ for each β. Let q be an arbitrary point of
Nα ∩Nβ, and choose a ﬂat chart for D on a neighborhood U of q. Let Vα,
Vβ denote the components of Nα ∩U and Nβ ∩U, respectively, containing
q. By the preceding lemma, Vα and Vβ are open subsets of single slices with
the subspace topology, and since both contain q, they both must lie in the
same slice S. Thus Vα ∩Vβ is open in S and also in both Nα and Nβ. Since
each q ∈Nα ∩Nβ has a neighborhood in Nβ contained in the intersection,
it follows that Nα ∩Nβ is open in Nβ as claimed. Clearly this is the unique
topology on N with the property that each Nα is a subspace of N.
With this topology, N is locally Euclidean of dimension k, because each
point q ∈N has a Euclidean neighborhood V in some Nα, and V is an
open subset of N because its intersection with each Nβ is open in Nβ by
the argument in the preceding paragraph. Moreover, the inclusion map
N ,→M is continuous: For any open subset U ⊂M, U ∩N is open in N
because U ∩Nα is open in Nα for each α.
To see that N is Hausdorﬀ, let q, q′ ∈N be given. There are disjoint
open sets U, U ′ ⊂M containing q and q′, respectively, and then (because
inclusion N ,→M is continuous) N ∩U and N ∩U ′ are disjoint open subsets
of N containing q.
Next we show that N is second countable. We can cover M with count-
ably many ﬂat charts for D, say {Wi}i∈N. It suﬃces to show that N ∩Wi is
contained in a countable union of slices for each i, for then we can choose
a countable basis for the portion of N in each such slice, and the union of
all such bases forms a countable basis for the topology of N.

Foliations
367
Suppose Wk is one of these ﬂat charts and S ⊂Wk is a slice containing
a point q ∈N. There is some connected integral manifold Nα containing
p and q. Because connected manifolds are path connected (***appendix?),
there is a continuous path γ : [0, 1] →Nα connecting p and q. Since γ[0, 1]
is compact, there exist ﬁnitely many numbers 0 = t0 < t1 < · · · < tm = 1
such that γ[tj−1, tj] is contained in one of the ﬂat charts Wij for each
j. Since γ[tj−1, tj] is connected, it is contained in a single component of
Wij ∩Nα and therefore in a single slice Sij ⊂Wij.
Let us say that a slice S of some Wk is accessible from p if there is a
ﬁnite sequence of indices i0, . . . , im and for each ij a slice Sij ⊂Wij, with
the properties that p ∈Si0, Sim = S, and Sij ∩Sij+1 ̸= ∅for each j. The
discussion in the preceding paragraph showed that every slice that contains
a point of N is accessible from p. To complete the proof of second count-
ability, we just note that Sij is itself an integral manifold, and therefore
it meets at most countably many slices of Wij+1 by Proposition 14.6; thus
there are only countably many slices accessible from p. Therefore, N is a
topological manifold of dimension k. It is connected because it is a union
of connected subspaces with a point in common.
To construct a smooth structure on N, we deﬁne an atlas consisting of
all charts of the form (S ∩N, ψ), where S is a single slice of some ﬂat chart,
and ψ: S →Rk is the map whose coordinate representation is projection
onto the ﬁrst k coordinates: ψ(x1, . . . , xn) = (x1, . . . , xk). Because any slice
is an embedded submanifold, its smooth structure is uniquely determined,
and thus whenever two such slices S, S′ overlap the transition map ψ′ ◦ψ
is smooth.
With respect to this smooth structure, the inclusion map N ,→M is
an immersion (because it is an embedding on each slice), and the tangent
space to N at each point q ∈N is equal to Dq (because this is true for
slices). The smooth structure is uniquely determined by the requirement
that the inclusion N ,→M be an immersion, because this implies N is
locally embedded and thus its smooth structure must match those of the
slices on small enough open sets.
Proof of the global frobenius theorem. For each p ∈M, let Lp be the union
of all connected integral manifolds of D containing p. By the preceding
lemma, Lp is a connected integral manifold of D containing p, and it is
clearly maximal. If any two such maximal integral manifolds Lp and Lp′
intersect, their union Lp ∪Lp′ is an integral manifold containing both p
and p′, so by maximality Lp = Lp′. Thus the various maximal integral
manifolds are either disjoint or identical.
If (U, ϕ) is any ﬂat chart for D, then Lp ∩U is a countable union of open
subsets of slices by Proposition 14.6. For any such slice S, if Lp∩S is neither
empty nor all of S, then Lp ∪S is a connected integral manifold properly
containing Lp, which contradicts the maximality of Lp. Therefore, Lp ∩U

368
14. Integral Manifolds and Foliations
is precisely a countable union of slices, so the collection {Lp : p ∈M} is
the desired foliation.
Exercise 14.5.
If M and N are smooth manifolds, show that TM and TN
deﬁne integrable distributions on M × N, whose leaves are diﬀeomorphic to
M and N, respectively.

Problems
369
Problems
14-1. If G is a connected Lie group acting smoothly, freely, and properly
on a smooth manifold M, show that the orbits of G form a foliation
of M.
14-2. Let D be the distribution on R3 spanned by
X = ∂
∂x + yz ∂
∂z,
Y = ∂
∂y
(a) Find an integral submanifold of D passing through the origin.
(b) Is D involutive? Explain your answer in light of part (a).
14-3. Of the systems of partial diﬀerential equations below, determine
which ones have solutions z(x, y) (or, for part (c), z(x, y) and w(x, y))
in a neighborhood of the origin for arbitrary positive values of z(0, 0)
(respectively, z(0, 0) and w(0, 0)).
(a) ∂z
∂x = z cos y;
∂z
∂y = −z log z tan y.
(b) ∂z
∂x = exz;
∂z
∂y = xeyz.
(c) ∂z
∂x = z;
∂z
∂y = w;
∂w
∂x = w;
∂w
∂y = z.
14-4. This problem outlines an alternative characterization of involutivity
in terms of diﬀerential forms. Suppose D is a k-dimensional tangent
distribution on an n-manifold M.
(a) Show that near any point of M there are n −k independent
1-forms ω1, . . . , ωn−k such that X ∈D if and only if ωi(X) = 0
for i = 1, . . . , k.
(b) Show that D is involutive if and only if whenever (ω1, . . . , ωn−k)
are forms as above, there are 1-forms {αi
j : i, j = 1, . . . , n −k}
such that
dωi =
k
X
j=1
αi
j ∧ωj.
[Hint: Use Problem 13-5.]
(c) Let A∗(M) denote the vector space A0(M)⊕· · ·⊕An(M). With
the wedge product, A∗(M) is an associative ring. Show that the
set
I(D) = {ω ∈A∗(M) : ω|D = 0}
is an ideal in A∗(M).

370
14. Integral Manifolds and Foliations
(d) An ideal I is said to be a diﬀerential ideal if d(I) ⊂I, that is, if
whenever ω ∈I, dω ∈I as well. Show that D is involutive if and
only if I(D) is a diﬀerential ideal.

15
Lie Algebras and Lie Groups
The set of vector ﬁelds on a Lie group that are invariant under all left
translations forms a ﬁnite-dimensional vector space, which carries a nat-
ural bilinear product making it into an algebraic structure known as a Lie
algebra. Many of the properties of a Lie group are reﬂected in the algebraic
structure of its Lie algebra.
In this chapter, we introduce the deﬁnition of an abstract Lie algebra, de-
ﬁne the Lie algebra of a Lie group, and explore some of its important prop-
erties, including the relationships among Lie algebras, homomorphisms of
Lie groups, and one-parameter subgroups of Lie groups. Later we introduce
the exponential map, a smooth map from the Lie algebra into the group
that shows in a very explicit way how the group structure near the identity
is reﬂected in the algebraic structure of the Lie algebra. The culmination
of the chapter is a complete description of the fundamental correspondence
between Lie groups and Lie algebras: There is a one-to-one correspondence
between ﬁnite-dimensional Lie algebras and simply-connected Lie groups,
and all of the connected Lie groups with a given Lie algebra are quotients
of the simply connected one by discrete normal subgroups.
Lie Algebras
A Lie algebra is a real vector space b endowed with a bilinear map b×b →b,
denoted by (X, Y ) 7→[X, Y ] and called the bracket of X and Y , satisfying
the following two properties for all X, Y, Z ∈b:

372
15. Lie Algebras and Lie Groups
(i) Antisymmetry: [X, Y ] = −[Y, X].
(ii) Jacobi Identity: [X, [Y, Z]] + [Y, [Z, X]] + [Z, [X, Y ]] = 0.
Notice that the Jacobi identity is a substitute for associativity, which does
not hold in general for brackets in a Lie algebra.
Example 15.1 (Lie algebras).
(a) The vector space M(n, R) of n × n real matrices is an n2-dimensional
Lie algebra under the commutator bracket
[A, B] = AB −BA.
Antisymmetry is obvious from the deﬁnition, and the Jacobi iden-
tity follows from a straightforward calculation. When we are thinking
of M(n, R) as a Lie algebra with this bracket, we will denote it by
gl(n, R).
(b) Similarly, gl(n, C) is the 2n2-dimensional (real) Lie algebra obtained
by endowing M(n, C) with the commutator bracket.
(c) The space T(M) of all smooth vector ﬁelds on a smooth manifold
M is an inﬁnite-dimensional Lie algebra under the Lie bracket by
Lemma 13.1.
(d) If (M, ω) is a symplectic manifold, the space C∞(M) becomes a Lie
algebra under the Poisson bracket. Problem 13-8 shows that this
bracket satisﬁes the Jacobi identity.
(e) Any vector space V becomes a Lie algebra if we deﬁne all brack-
ets to be zero. Such a Lie algebra is said to be abelian. (The name
refers to the fact that the bracket in most Lie algebras, as in the two
preceding examples, is deﬁned as a commutator operation in terms
of an underlying associative product; so “abelian” refers to the fact
that all brackets are zero precisely when the underlying product is
commutative.)
(f) If g and h are Lie algebras, then g×h is a Lie algebra with the bracket
operation deﬁned by
[(X, Y ), (X′, Y ′)] = ([X, X′], [Y, Y ′]).
With this bracket, g × h is called a product Lie algebra.
If b is a Lie algebra, a linear subspace a ⊂b is called a Lie subalgebra of
b if it is closed under Lie brackets. In this case a is itself a Lie algebra with
the same bracket operation.
If a and b are Lie algebras, a linear map A: a →b is called a Lie algebra
homomorphism if it preserves brackets: A[X, Y ] = [AX, AY ]. An invertible

Lie Algebras
373
Lie algebra homomorphism is called a Lie algebra isomorphism. If there
exists a Lie algebra isomorphism from a to b, we say they are isomorphic
as Lie algebras.
Exercise 15.1.
Verify that the kernel and image of a Lie algebra homo-
morphism are Lie subalgebras.
Exercise 15.2.
If g and h are Lie algebras and A: g →h is a linear map,
show that A is a Lie algebra homomorphism if and only if A[Ei, Ej] =
[AEi, AEj] for some basis (E1, . . . , En) of g.
Now suppose G is a Lie group. Recall that each element g ∈G deﬁnes a
diﬀeomorphism Lg : G →G called left translation, given by Lg(h) = gh. A
smooth vector ﬁeld X ∈T(G) is said to be left-invariant if it is invariant
under all left translations: Lg∗X = X for every g ∈G. (Because Lg is a
diﬀeomorphism, Lg∗X is a well-deﬁned vector ﬁeld on G, and Lg∗X = X
means Lg∗(Xg′) = Xgg′ for every pair g, g′ of elements of G.)
Lemma 15.2. Let G be a Lie group, and let g denote the set of all left-
invariant vector ﬁelds on G. Then g is a Lie subalgebra of T(M).
Proof. Because Lg∗(aX + bY ) = aLg∗X + bLg∗Y , it is clear that g is a
linear subspace of T(M). By the naturality of Lie brackets, if X, Y ∈g,
Lg∗[X, Y ] = [Lg∗X, Lg∗Y ] = [X, Y ].
Thus g is closed under Lie brackets.
The Lie algebra g is called the Lie algebra of the Lie group G, and is de-
noted by Lie(G). The fundamental fact is that Lie(G) is ﬁnite-dimensional,
and in fact has the same dimension as G itself, as the following theorem
shows.
Theorem 15.3. Let G be a Lie group and let g = Lie(G). The evaluation
map g →TeG, given by X 7→Xe, is a vector space isomorphism. Thus g
is ﬁnite-dimensional, with dimension equal to dim G.
Proof. We will prove the theorem by constructing an inverse to the evalu-
ation map. For each V ∈TeG, deﬁne a section eV of TG by
eVg = Lg∗V.
If there is a left-invariant vector ﬁeld on G whose value at the identity is
V , clearly it has to be given by this formula.
First we need to check that eV is in fact a smooth vector ﬁeld. By Lemma
3.14(c) it suﬃces to show that eV f is smooth whenever f is a smooth

374
15. Lie Algebras and Lie Groups
function on an open set U ⊂G. Choose a smooth curve γ : (−ε, ε) →G
such that γ(0) = e and γ′(0) = V . Then for g ∈U,
(eV f)(g) = eVgf
= (Lg∗V )f
= V (f ◦Lg)
= γ′(0)(f ◦Lg)
= d
dt

t=0
(f ◦Lg ◦γ)
= d
dtf(gγ(t))

t=0
.
The expression ϕ(g, t) = f(gγ(t)) depends smoothly on (g, t), because it
is a composition of group multiplication, f, and γ. Thus its t-derivative
depends smoothly on g, and so eV f is smooth.
Next we need to verify that eV is left-invariant, which is to say that
Lh∗eVg = eVhg for all g, h ∈G. This follows from the deﬁnition of eV and the
fact that Lh ◦Lg = Lhg:
Lh∗eVg = Lh∗(Lg∗V ) = Lhg∗V = Vhg.
Thus eV ∈g.
Finally, we check that the map τ : V 7→eV is an inverse for the evaluation
map ε: X 7→Xe. On the one hand, given a vector V ∈TeG,
ε(τ(V )) = (eV )e = Le∗V = V,
which shows that ε ◦τ is the identity on TeG. On the other hand, given a
vector ﬁeld X ∈g,
τ(ε(X))g = f
Xe|g = Lg∗Xe = Xg,
which shows that τ ◦ε = Idg.
Example 15.4. Let us compute the Lie algebras of some familiar Lie
groups.
(a) Euclidean space Rn: Left translation by an element b ∈Rn is given by
the aﬃne map Lb(x) = x + b, whose push-forward Lb∗is represented
by the identity matrix in standard coordinates. This implies that
a vector ﬁeld V i∂/∂xi is left-invariant if and only if its coeﬃcients
V i are constants. Because any two constant-coeﬃcient vector ﬁelds
commute (by formula (13.4)), the Lie algebra of Rn is abelian, and
is isomorphic to Rn itself with the trivial bracket operation. In brief,
Lie(Rn) ∼= Rn.

Lie Algebras
375
(b) The circle group S1: There is a unique unit tangent vector ﬁeld T on S1
that is positively oriented with respect to the orientation induced by
the outward normal. (If θ is any local angle coordinate on an open set
U ⊂S1, then T = ∂/∂θ on U.) Because left translations are rotations,
which preserve T , it follows that T is left-invariant, and therefore T
spans the Lie algebra of S1. This Lie algebra is 1-dimensional and
abelian, and therefore Lie(S1) ∼= R.
(c) Product groups: If G and H are Lie groups, it is easy to check that
the Lie algebra of the product group G×H is the product Lie algebra
Lie(G) × Lie(H).
(d) The n-torus Tn: Since Tn is the n-fold product of S1 with itself, its
Lie algebra is isomorphic to R × · · · × R = Rn. In particular, it is
abelian. If Ti is the oriented unit vector ﬁeld on the ith S1 factor,
then (T1, . . . , Tn) is a basis for Lie(Tn).
Theorem 15.3 has several useful corollaries. Recall that a smooth mani-
fold is said to be parallelizable if its tangent bundle admits a global frame,
or equivalently if its tangent bundle is trivial.
Corollary 15.5. Every Lie group is parallelizable.
Proof. Let G be a Lie group and let g be its Lie algebra. Choosing any basis
X1, . . . , Xn for g, Theorem 15.3 shows that X1|e, . . . , Xn|e form a basis for
TeG. For each g ∈G, Lg∗: TeG →TgG is an isomorphism taking Xi|e to
Xi|g, so X1|g, . . . , Xn|g form a basis for TgG at each g ∈G. In other words
(Xi) is a global frame for G.
The proof of the preceding corollary actually shows that any basis for
the Lie algebra of G is a global frame consisting of left-invariant vector
ﬁelds. We will call any such frame a left-invariant frame.
Corollary 15.6. Every Lie group is orientable.
Proof. Proposition 10.5 shows that every parallelizable manifold is ori-
entable.
A tensor or diﬀerential form σ on a Lie group is said to be left-invariant
if L∗
gσ = σ for all g ∈G.
Corollary 15.7. Every compact oriented Lie group G has a unique left-
invariant orientation form Ωwith the property that
R
G Ω= 1.
Proof. Let E1, . . . , En be a left-invariant global frame on G. By replacing
E1 with −E1 if necessary, we may assume this frame is positively oriented.
Let ε1, . . . , εn be the dual coframe. Left invariance of Ej implies that
(L∗
gεi)(Ej) = εi(Lg∗Ej) = εi(Ej),

376
15. Lie Algebras and Lie Groups
which shows that L∗
gεi = εi, so εi is left-invariant.
Let Ω= ε1 ∧· · · ∧εn. Then
L∗
gΩ= L∗
gε1 ∧· · · ∧L∗
gεn = ε1 ∧· · · ∧εn = Ω,
so Ωis left-invariant as well. Because Ω(E1, . . . , En) = 1 > 0, Ωis an
orientation form for the given orientation. Clearly any positive constant
multiple of Ωis also a left-invariant orientation form. Conversely, if eΩis
any other left-invariant orientation form, we can write eΩe = cΩe for some
positive number c. Using left-invariance, we ﬁnd that
eΩg = L∗
g−1 eΩe = cL∗
g−1Ωe = cΩg,
which proves that eΩis a positive constant multiple of Ω.
Since G is compact and oriented,
R
G Ωmakes sense, so we can deﬁne
eΩ= (R
G Ω)−1Ω. Clearly eΩis the unique left-invariant orientation form for
which G has unit volume.
Remark. The n-form whose existence is asserted in this proposition is called
the Haar volume form on G, and is often denoted dV . Similarly, the map
f 7→
R
G f dV is called the Haar integral. Observe that the proof above did
not use the fact that G was compact until the last paragraph; thus every
Lie group has a left-invariant orientation form that is uniquely deﬁned up
to a positive constant. It is only in the compact case, however, that we can
use the volume normalization to single out a unique one.
The General Linear Group
Before going on with the general theory, we will explore one more funda-
mental example: the general linear group. In this chapter, let us denote the
n × n identity matrix by I instead of In for brevity. Theorem 15.3 gives a
vector space isomorphism between Lie(GL(n, R)) and TI GL(n, R) as usual.
Because GL(n, R) is an open subset of the vector space gl(n, R), its tangent
space is naturally isomorphic to gl(n, R) itself. The composition of these two
isomorphisms gives a vector space isomorphism Lie(GL(n, R)) ∼= gl(n, R).
Both Lie(GL(n, R) and gl(n, R) have independently deﬁned Lie algebra
structures—the ﬁrst coming from Lie brackets of vector ﬁelds and the sec-
ond from commutator brackets of matrices. The next proposition shows
that the natural vector space isomorphism between these spaces is in fact
a Lie algebra isomorphism. Problem 15-14 shows that the analogous result
holds for the complex general linear group.
Proposition 15.8 (Lie Algebra of the General Linear Group).
The composite map
gl(n, R) →TI GL(n, R) →Lie(GL(n, R))
(15.1)

Lie Algebras
377
gives a Lie algebra isomorphism between Lie(GL(n, R)) and the matrix al-
gebra gl(n, R).
Proof. Using the matrix entries Ai
j as global coordinates on GL(n, R) ⊂
gl(n, R), the natural isomorphism gl(n, R) ←→TI GL(n, R) takes the form
(Bi
j) ←→
X
ij
Bi
j
∂
∂Ai
j

I
.
(Because of the dual role of the indices i, j as coordinate indices and matrix
row and column indices, it is impossible to use our summation conventions
consistently in this context, so we will write the summation signs explicitly.)
Let g denote the Lie algebra of GL(n, R). For any matrix B = (Bi
j) ∈
gl(n, R), the left-invariant vector ﬁeld eB ∈g corresponding to B is given
by
eBA = LA∗B = LA∗
 X
ij
Bi
j
∂
∂Ai
j

I

.
Since LA is the restriction of the linear map B 7→AB on gl(n, R), its push-
forward is represented in coordinates by exactly the same linear map. In
other words,
eBA =
X
ijk
Ai
jBj
k
∂
∂Ai
k

A
.
(15.2)
Given two matrices B, C ∈gl(n, R), the Lie bracket of the corresponding
left-invariant vector ﬁelds is given by
[ eB, eC] =
 X
ijk
Ai
jBj
k
∂
∂Ai
k
,
X
pqr
Ap
qCq
r
∂
∂Ap
r

=
X
ijkpqr
Ai
jBj
k
∂
∂Ai
k
(Ap
qCq
r) ∂
∂Ap
r
−
X
ijkpqr
Ap
qCq
r
∂
∂Ap
r
(Ai
jBj
k) ∂
∂Ai
k
=
X
ijkr
Ai
jBj
kCk
r
∂
∂Air
−
X
pqrk
Ap
qCq
rBr
k
∂
∂Ap
k
=
X
ijkr
(Ai
jBj
kCk
r −Ai
jCj
kBk
r ) ∂
∂Air
,
where we have used the fact that ∂(Ap
q)/∂Ai
k is equal to one if p = i and
q = k and zero otherwise, and Bi
j and Ci
j are constants. Evaluating this

378
15. Lie Algebras and Lie Groups
last expression when A is equal to the identity matrix, we get
[ eB, eC]I =
X
ikr
(Bi
kCk
r −Ci
kBk
r )
∂
∂Air

I
.
This is the vector corresponding to the matrix commutator bracket [B, C].
Since the left-invariant vector ﬁeld [ eB, eC] is determined by its value at the
identity, this implies that
[ eB, eC] = ^
[B, C],
which is precisely the statement that the composite map (15.1) is a Lie
algebra isomorphism.
Induced Lie Algebra Homomorphisms
In this section, we show that a Lie homomorphism between Lie groups in-
duces a Lie algebra homomorphism between their Lie algebras, and explore
some of the consequences of this fact.
Theorem 15.9. Let G and H be Lie groups and g and h their Lie algebras,
and suppose F : G →H is a Lie group homomorphism. For every X ∈g,
there is a unique vector ﬁeld in h that is F-related to X. The map F∗: g →h
so deﬁned is a Lie algebra homomorphism.
Proof. If there is any vector ﬁeld Y ∈h that is F-related to X, it must
satisfy Ye = F∗Xe, and thus it must be uniquely deﬁned by
Y = ^
F∗Xe.
To show that this Y is F-related to X, we note that the fact that F is a
homomorphism implies
F(g1g2) = F(g1)F(g2)
=⇒F(Lg1g2) = LF (g1)F(g2)
=⇒F ◦Lg = LF (g) ◦F
=⇒F∗◦Lg∗= LF (g)∗◦F∗.
Thus
F∗Xg = F∗(Lg∗Xe)
= LF (g)∗F∗Xe
= LF (g)∗Ye
= YF (g).

Induced Lie Algebra Homomorphisms
379
This says precisely that X and Y are F-related.
Now, for each X ∈g, let F∗X denote the unique vector ﬁeld in h that is F-
related to X. It then follows immediately from the naturality of Lie brackets
that F∗[X, Y ] = [F∗X, F∗Y ], so F∗is a Lie algebra homomorphism.
The map F∗: g →h whose existence is asserted in this theorem will be
called the induced Lie algebra homomorphism.
Proposition 15.10 (Properties of the Induced Homomorphism).
(a) The homomorphism IdG∗: Lie(G) →Lie(G) induced by the identity
map of G is the identity of Lie(G).
(b) If F1 : G →H and F2 : H →K are Lie group homomorphisms, then
(F2 ◦F1)∗= (F2)∗◦(F1)∗: Lie(G) →Lie(K).
Proof. Both of these relations hold for push-forwards, and the value of the
induced homomorphism on a left-invariant vector ﬁeld X is deﬁned by the
push-forward of Xe.
In the language of category theory, this proposition says that the as-
signment G 7→Lie(G), F 7→F∗is a covariant functor from the category
of Lie groups to the category of Lie algebras. The following corollary is
immediate.
Corollary 15.11. Isomorphic Lie groups have isomorphic Lie algebras.
The next corollary has a bit more substance to it.
Corollary 15.12 (The Lie Algebra of a Lie Subgroup).
Suppose
H ⊂G is a Lie subgroup. The subset eh ⊂Lie(G) deﬁned by
eh = {X ∈Lie(G) : Xe ∈TeH}
is a Lie subalgebra of Lie(G) canonically isomorphic to Lie(H).
Proof. Let g = Lie(G) and h = Lie(G). It is clear that the inclusion map
ιH : H ,→G is a Lie group homomorphism, so ιH∗(h) is a Lie subalgebra
of g. By the way we deﬁned the induced Lie algebra homomorphism, this
subalgebra is precisely the set of left-invariant vector ﬁelds on G whose
value at the identity is of the form ιH∗V for some V ∈TeH. Since the
push-forward map ιH∗: TeH →TeG is the inclusion of TeH as a subspace
in TeG, it follows that ιH∗(h) = eh. To complete the proof, therefore, we
need only show that ιH∗: h →g is injective, so that it is an isomorphism
onto its image. If ιH∗X = 0, then in particular ιH∗Xe = 0. Since ιH is an
immersion, this implies that Xe = 0 and therefore by left-invariance X = 0.
Thus ιH∗is injective as claimed.

380
15. Lie Algebras and Lie Groups
Using this corollary, whenever H is a Lie subgroup of G, we will generally
identify Lie(H) as a subalgebra of Lie(G). It is important to remember that
elements of Lie(H) are only vector ﬁelds on H, and so, strictly speaking, are
not elements of Lie(G). However, by the preceding lemma, every element of
Lie(H) corresponds to a unique element of Lie(G), determined by its value
at the identity, and the injection of Lie(H) into Lie(G) thus determined
respects Lie brackets; so by thinking of Lie(H) as a subalgebra of Lie(G)
we are not committing a grave error.
This identiﬁcation is especially illuminating in the case of Lie subgroups
of GL(n, R).
Example 15.13. Consider O(n) as a Lie subgroup of GL(n, R). By Ex-
ample 5.26, it is equal to the level set F −1(I), where F : GL(n, R) →
S(n, R) is the submersion F(A) = AT A. By Lemma 5.29, TI O(n) =
Ker F∗: TI GL(n, R) →TI S(n, R). By the computation in Example 5.26,
this push-forward is F∗B = BT + B, so
TI O(n) = {B ∈gl(n, R) : BT + B = 0}
= {skew-symmetric n × n matrices}.
We denote this subspace of gl(n, R) by o(n). The preceding corollary then
implies that o(n) is a Lie subalgebra of gl(n, R) isomorphic to Lie(O(n)).
Notice that we did not even have to verify directly that o(n) is a subalgebra.
As another application, we consider Lie covering groups. A Lie group
homomorphism F : G →H that is also a smooth covering map is called a
covering homomorphism, and we say G is a (Lie) covering group of H. By
Problem 7-5, if G is connected and F : G →H is a surjective Lie group
homomorphism with discrete kernel, then F is a covering homomorphism.
Every connected Lie group G has a universal covering space eG, which is
naturally a smooth manifold by Proposition 2.8 and a Lie group by Problem
7-6. We call eG the universal covering group of G.
The next proposition shows how Lie algebras behave under covering ho-
momorphisms.
Proposition 15.14. Suppose G and H are Lie groups and F : G →H is a
covering homomorphism. Then F∗: Lie(G) →Lie(H) is an isomorphism.
Proof. Because a smooth covering map is a local diﬀeomorphism, the push-
forward from TeG to TeH is an isomorphism, and therefore the induced Lie
algebra homomorphism is an isomorphism.

One-Parameter Subgroups
381
One-Parameter Subgroups
In this section, we explore another set of relationships among Lie algebras,
vector ﬁelds, and Lie groups. It will give us yet another characterization of
the Lie algebra of a Lie group.
Let G be a Lie group. We deﬁne a one-parameter subgroup of G to be a
Lie group homomorphism F : R →G. Notice that, by this deﬁnition, a one-
parameter subgroup is not a Lie subgroup of G, but rather a homomorphism
into G. (However, as Problem 15-5 shows, the image of a one-parameter
subgroup is a Lie subgroup.)
We will see shortly that the one-parameter subgroups are precisely the
integral curves of left-invariant vector ﬁelds starting at the identity. Before
we do so, however, we need the following lemma.
Lemma 15.15. Every left-invariant vector ﬁeld on a Lie group is com-
plete.
Proof. Let g be the Lie algebra of the Lie group G, let X ∈g, and let θ
denote the ﬂow of X. Suppose some maximal integral curve θ(g) is deﬁned
on an interval (a, b) ⊂R, and assume that b < ∞. (The case a > −∞is
handled similarly.) We will use left-invariance to deﬁne an integral curve
on a slightly larger interval.
By Lemma 13.8, left-invariance of X means that
Lg ◦θt = θt ◦Lg
(15.3)
whenever the left-hand side is deﬁned. Observe that the integral curve θ(e)
starting at the identity is deﬁned at least on some interval (−ε, ε) for ε > 0.
Choose some s ∈(b −ε, b), and deﬁne a new curve γ : (a, s + ε) →G by
γ(t) =
(
θ(g)(t)
t ∈(a, b)
Lθs(g)(θt−s(e))
t ∈(s −ε, s + ε).
By (15.3), when s ∈(a, b) and |t −s| < ε, we have
Lθs(g)(θt−s(e)) = θt−s(Lθs(g)(e))
= θt−s(θs(g))
= θt(g)
= θ(g)(t),
so the two deﬁnitions of γ agree where they overlap.

382
15. Lie Algebras and Lie Groups
Now, γ is clearly an integral curve of X on (a, b), and for t0 ∈(s−ε, s+ε)
we use left-invariance of X to compute
γ′(t0) = d
dt

t=t0
Lθs(g)(θt−s(e))
= Lθs(g)∗
d
dt

t=t0
θ(e)(t −s)
= Lθs(g)∗Xθ(e)(t0−s)
= Xγ(t0).
Thus γ is an integral curve of X deﬁned for t ∈(a, s + ε). Since s + ε > b,
this contradicts the maximality of θ(g).
Proposition 15.16. Let G be a Lie group, and let X ∈Lie(G). The inte-
gral curve of X starting at e is a one-parameter subgroup of G.
Proof. Let θ be the ﬂow of X, so that θ(e) : R →G is the integral curve in
question. Clearly θ(e) is smooth, so we need only show that it is a group
homomorphism, i.e., that θ(e)(s + t) = θ(e)(s)θ(e)(t) for all s, t ∈R. Using
(15.3) once again, we compute
θ(e)(s)θ(e)(t) = Lθ(e)(s)θt(e)
= θt(Lθ(e)(s)(e))
= θt(θ(e)(s))
= θt(θs(e))
= θt+s(e)
= θ(e)(t + s).
The main result of this section is that all one-parameter subgroups are
obtained in this way.
Theorem 15.17. Every one-parameter subgroup of a Lie group is an in-
tegral curve of a left-invariant vector ﬁeld. Thus there are one-to-one cor-
respondences
{one-parameter subgroups of G} ←→Lie(G) ←→TeG.
In particular, a one-parameter subgroup is uniquely determined by its initial
tangent vector in TeG.
Proof. Let F : R →G be a one-parameter subgroup, and let X
=
F∗(d/dt) ∈Lie(G), where we think of d/dt as a left-invariant vector ﬁeld on

One-Parameter Subgroups
383
R. To prove the theorem, it suﬃces to show that F is an integral curve of
X. Recall that F∗(d/dt) is deﬁned as the unique left-invariant vector ﬁeld
on G that is F-related to d/dt. Therefore, for any t0 ∈R,
F ′(t0) = F∗
d
dt

t0
= XF (t0),
so F is an integral curve of X.
Given X ∈Lie(G), we will call the one-parameter subgroup determined
in this way the one-parameter subgroup generated by X.
The one-parameter subgroups of the general linear group are not hard
to compute explicitly.
Proposition 15.18. For any B ∈gl(n, R), let
eB =
∞
X
k=0
1
k!Bk.
(15.4)
This series converges to an invertible matrix eB ∈GL(n, R), and the one-
parameter subgroup of GL(n, R) generated by B ∈gl(n, R) is F(t) = etB.
Proof. First we verify convergence. From Exercise A.24 in the Appendix,
matrix multiplication satisﬁes |AB| ≤|A| |B|, where the norm is the Euclid-
ean norm on gl(n, R) under its obvious identiﬁcation with Rn2. It follows
by induction that |Bk| ≤|B|k. The Weierstrass M-test shows that (15.4)
converges uniformly on any bounded subset of gl(n, R) (by comparison with
the series P
k(1/k!)Ck = eC).
Fix B ∈gl(n, R). The one-parameter subgroup generated by B is an
integral curve of the left-invariant vector ﬁeld eB, and therefore satisﬁes the
ODE initial value problem
F ′(t) = eBF (t),
F(0) = I.
Using formula (15.2) for eB, the condition for F to be an integral curve can
be rewritten as
(F i
k)′(t) = F i
j (t)Bj
k,
or in matrix notation
F ′(t) = F(t)B.
We will show that F(t) = etB satisﬁes this equation. Since F(0) = I, this
implies that F is the unique integral curve of eB starting at the identity
and is therefore the desired one-parameter subgroup.

384
15. Lie Algebras and Lie Groups
To see that F is diﬀerentiable, we note that diﬀerentiating the series
(15.4) formally term-by-term yields the result
F ′(t) =
∞
X
k=1
k
k!tk−1Bk
=
 ∞
X
k=1
1
(k −1)!tk−1Bk−1

B
= F(t)B.
Since the diﬀerentiated series converges uniformly on compact sets (because
it is the same series!), the term-by-term diﬀerentiation is justiﬁed. A similar
argument shows that F ′(t) = BF(t). By smoothness of solutions to ODEs,
F is a smooth curve.
It remains only to show that F(t) is invertible for all t, so that F actually
takes its values in GL(n, R). If we let σ(t) = F(t)F(−t) = etBe−tB, then
σ is a smooth curve in gl(n, R), and by the previous computation and the
product rule it satisﬁes
σ′(t) = (F(t)B)F(−t) −F(t)(BF(−t)) = 0.
Therefore σ is the constant curve σ(t) ≡σ(0) = I, which is to say that
F(t)F(−t) = I. Substituting −t for t, we obtain F(−t)F(t) = I, which
shows that F(t) is invertible and F(t)−1 = F(−t).
Next we would like to compute the one-parameter subgroups of sub-
groups of GL(n, R), such as O(n). To do so, we need the following result.
Proposition 15.19. Suppose H
⊂
G is a Lie subgroup. The one-
parameter subgroups of H are precisely those one-parameter subgroups of
G whose initial tangent vectors lie in TeH.
Proof. Let F : R →H be a one-parameter subgroup. Then the composite
map
R
F
−→H ,→G
is a Lie group homomorphism and thus a one-parameter subgroup of G,
which clearly satisﬁes F ′(0) ∈TeH.
Conversely, suppose F : R →G is a one-parameter subgroup whose initial
tangent vector lies in TeH. Let eF : R →H be the one-parameter subgroup
of H with the same initial tangent vector eF ′(0) = F ′(0) ∈TeH ⊂TeG. As
in the preceding paragraph, by composing with the inclusion map, we can
also consider eF as a one-parameter subgroup of G. Since F and eF are both
one-parameter subgroups of G with the same initial tangent vector, they
must be equal.

The Exponential Map
385
Example 15.20. If H is a Lie subgroup of GL(n, R), the preceding propo-
sition shows that the one-parameter subgroups of H are precisely the maps
of the form F(t) = etB for B ∈h, where h ⊂gl(n, R) is the subalge-
bra corresponding to Lie(H) as in Corollary 15.12. For example, taking
H = O(n), this shows that the exponential of any skew-symmetric matrix
is orthogonal.
The Exponential Map
In the preceding section, we saw that the matrix exponential maps gl(n, R)
to GL(n, R) and takes each line through the origin to a one-parameter
subgroup. This has a powerful generalization to arbitrary Lie groups.
Given a Lie group G with Lie algebra g, deﬁne a map exp: g →G, called
the exponential map of G, by letting exp X = F(1), where F is the one-
parameter subgroup generated by X, or equivalently the integral curve of
X starting at the identity.
Example 15.21. The results of the preceding section show that the expo-
nential map of GL(n, R) (or any Lie subgroup of it) is given by exp A = eA.
This, obviously, is the reason for the term exponential map.
Proposition 15.22 (Properties of the Exponential Map). Let G be
a Lie group and g its Lie algebra.
(a) The exponential map is smooth.
(b) For any X ∈g, F(t) = exp tX is the one-parameter subgroup of G
generated by X.
(c) For any X ∈g, exp(s + t)X = exp sX exp tX.
(d) The push-forward exp∗: T0g →TeG is the identity map, under the
canonical identiﬁcations of both T0g and TeG with g itself.
(e) The exponential map is a diﬀeomorphism from some neighborhood of
0 in g to a neighborhood of e in G.
(f ) For any Lie group homomorphism F : G →H, the following diagram
commutes:
G
H
-
F
g
h
-
F∗
?
exp
?
exp
(g) The ﬂow θ of a left-invariant vector ﬁeld X is given by θt = Rexp tX
(right multiplication by exp tX).

386
15. Lie Algebras and Lie Groups
Proof. For this proof, for any X ∈g we let θ(X) denote the ﬂow of X. To
prove (a), we need to show that the expression θ(e)
(X)(1) depends smoothly
on X, which amounts to showing that the ﬂow varies smoothly as the vector
ﬁeld varies. This is a situation not covered by the fundamental theorem on
ﬂows, but we can reduce it to that theorem by the following trick. Deﬁne
a smooth vector ﬁeld Ξ on the product manifold G × g by
Ξ(g,X) = (Xg, 0) ∈TgG × TXg ∼= T(g,X)(G × g).
It is easy to verify that the ﬂow Θ of Ξ is given by
Θt(g, X) = (θ(X)t(g), X).
By the fundamental theorem on ﬂows, Θ is a smooth map. Since exp X =
π1(Θ1(e, X)), where π1 : G × g →G is the projection, it follows that exp is
smooth.
Since the one-parameter subgroup generated by X is equal to the integral
curve of X starting at e, to prove (b) it suﬃces to show that exp tX =
θ(e)
(X)(t), or in other words that
θ(e)
(tX)(1) = θ(e)
(X)(t).
(15.5)
In fact, we will prove that for all s, t ∈R,
θ(e)
(tX)(s) = θ(e)
(X)(st),
(15.6)
which clearly implies (15.5).
To prove (15.6), ﬁx t ∈R and deﬁne a smooth curve γ : R →G by
γ(s) = θ(e)
(X)(st).
By the chain rule,
γ′(s) = t(θ(e)
(X))′(st) = tXγ(s),
so γ is an integral curve of the vector ﬁeld tX. Since γ(0) = e, by uniqueness
of integral curves we must have γ(s) = θ(e)
(tX)(s), which is (15.6). This proves
(b).
Next, (c) follows immediately from (b), which shows that t 7→exp tX is
a group homomorphism.
To prove (d), let X ∈g be arbitrary, and let σ: R →g be the curve
σ(t) = tX. Then σ′(0) = X, and (b) implies
exp∗X = exp∗σ′(0)
= (exp ◦σ)′(0)
= d
dt

t=0
exp tX
= X.

The Exponential Map
387
Part (e) then follows immediately from (d) and the inverse function theo-
rem.
Next, to prove (f) we need to show that exp(F∗X) = F(exp X) for any
X ∈g. In fact, we will show that for all t ∈R,
exp(tF∗X) = F(exp tX).
The left-hand side is, by (b), the one-parameter subgroup generated by
F∗X. Thus, if we put σ(t) = F(exp tX), it suﬃces to show that σ is a
group homomorphism satisfying σ′(0) = F∗X. We compute
σ′(0) = d
dt

t=0
F(exp tX) = F∗
d
dt

t=0
exp tX = F∗X
and
σ(s + t) = F(exp(s + t)X)
= F(exp sX exp tX)
(by (c))
= F(exp sX)F(exp tX)
(since F is a homomorphism)
= σ(s)σ(t).
Finally, to show that θ(X)t = Rexp tX, we use part (b) and (15.3) to show
that for any g ∈G,
Rexp tX(g) = g exp tX
= Lg(exp tX)
= Lg(θ(X)t(e))
= θ(X)t(Lg(e))
= θ(X)t(g).
In the remainder of this chapter, we present a variety of important ap-
plications of the exponential map. The ﬁrst is a powerful technique for
computing the Lie algebra of a subgroup.
Lemma 15.23. Let G be a Lie group, and let H ⊂G be a Lie subgroup.
Inclusion H ,→G induces an isomorphism between Lie(H) and the subal-
gebra h ⊂Lie(G) given by
h = {X ∈Lie(G) : exp tX ∈H for all t ∈R}.
Proof. Let X be an arbitrary element of Lie(G). Suppose ﬁrst that X ∈h.
Letting γ denote the curve γ(t) = exp tX, the fact that γ(t) lies in H for
all t means that Xe = γ′(0) ∈TeH, which means that X is in the image
of Lie(H) under inclusion (see Corollary 15.12). Conversely, if X is in the
image of Lie(H), then Xe ∈TeH, which implies by Proposition 15.19 that
exp tX ∈H for all t.

388
15. Lie Algebras and Lie Groups
Corollary 15.24. Let G ⊂GL(n, R) be a Lie subgroup, and deﬁne a subset
g ⊂gl(n, R) by
g = {B ∈gl(n, R) : etB ∈G for all t ∈R}.
Then g is a Lie subalgebra of gl(n, R) canonically isomorphic to Lie(G).
As an application, we will determine the Lie algebra of SL(n, R). First
we need the following lemma.
Lemma 15.25. The matrix exponential satisﬁes the identity
det eA = etr A.
(15.7)
Proof. Let A ∈gl(n, R) be arbitrary, and consider the smooth function
τ : R →R given by
τ(t) = e−tr tA det etA.
We compute the derivatives of the two factors separately. First, using the
result of Problem 4-10 and the chain rule,
d
dt(det etA) = d(det)etA
 d
dtetA

= d(det)etA(etAA)
= (det etA) tr
 (etA)−1(etAA)

= (det etA) tr A.
Then, because the trace is linear,
d
dt(e−tr tA) = e−tr tA d
dt(−tr tA)
= e−tr tA(−tr A).
Therefore, by the product rule,
τ ′(t) = e−tr tA d
dt(det etA) + det etA d
dt(e−tr tA)
= e−tr tA det etA tr A + det etAe−tr tA(−tr A)
= 0.
Consequently τ(t) = τ(0) = 1 for all t. In particular, taking t = 1, this
implies (15.7).
Example 15.26. Let sl(n, R) ⊂gl(n, R) be the set of trace-free matrices:
sl(n, R) ⊂gl(n, R) = {B ∈gl(n, R) : tr B = 0}.

The Exponential Map
389
If B ∈sl(n, R), then the preceding lemma shows that det etB = etrtB = 1,
so etB ∈SL(n, R) for all t. Conversely, if etB ∈SL(n, R) for all t, then
1 = det etB = etr tB = et tr B, which immediately implies that tr B = 0.
Thus by Corollary 15.24, sl(n, R) is a Lie subalgebra of gl(n, R), isomorphic
to Lie(SL(n, R)).
The next lemma is a technical result that will be used below.
Lemma 15.27. Let G be a Lie group and g its Lie algebra.
(a) If m: G × G →G denotes the multiplication map, then m∗: TeG ×
TeG →TeG is given by m∗(X, Y ) = X + Y .
(b) If A, B ⊂g are complementary linear subspaces of g, then the map
A×B →G given by (X, Y ) 7→exp X exp Y is a diﬀeomorphism from
some neighborhood of (0, 0) in A × B to a neighborhood of e in G.
Exercise 15.3.
Prove this lemma.
The following proposition shows how the group structure of a Lie group
is reﬂected “inﬁnitesimally” in the algebraic structure of its Lie algebra.
The second formula, in particular, shows how the Lie bracket expresses the
leading term in the Taylor series expansion of a group commutator.
In the statement of the proposition, we use the following standard nota-
tion from analysis: The expression O(tk) means any g-valued function of t
that is bounded by a constant multiple of |t|k as t →0. (The bound can be
expressed in terms of any norm on g; since all norms on a ﬁnite-dimensional
vector space are equivalent, the deﬁnition is independent of which norm is
chosen.)
Proposition 15.28. Let G be a Lie group and g its Lie algebra. For any
X, Y ∈g, the exponential map satisﬁes
(exp tX)(exp tY ) = exp(t(X + Y ) + 1
2t2[X, Y ] + O(t3)),
(15.8)
(exp tX)(exp tY )(exp −tX)(exp −tY ) = exp(t2[X, Y ] + O(t3)),
(15.9)
whenever t ∈R is suﬃciently close to 0.
Proof. Let X ∈g, and let θ denote the ﬂow of X. If f is any smooth
function deﬁned on an open subset of G,
d
dtf(g exp tX) = d
dtf(θt(g)) = Xθt(g)f = Xf(g exp tX),
(15.10)
because t 7→g exp tX = θt(g) is an integral curve of X. Applying this same
formula to the function Xf yields
d2
dt2 f(g exp tX) = d
dtXf(g exp tX) = X2f(g exp tX).

390
15. Lie Algebras and Lie Groups
In particular, if f is deﬁned in a neighborhood of the identity, evaluating
these equations at g = e and t = 0 yields
d
dtf(exp tX)

t=0
= Xf(e),
(15.11)
d2
dt2 f(exp tX)

t=0
= X2f(e).
(15.12)
By Taylor’s theorem in one variable, therefore, we can write
f(exp tX) = f(e) + tXf(e) + 1
2t2X2f(e) + O(t3).
(15.13)
Now, let X, Y ∈g be ﬁxed, and deﬁne a function u: R2 →R by u(s, t) =
f(exp sX exp tY ). We will prove the proposition by analyzing the Taylor
series of u(t, t) about t = 0. First, by the chain rule and (15.11),
d
dtu(t, t)

t=0
= ∂u
∂s (0, 0) + ∂u
∂t (0, 0) = Xf(e) + Y f(e).
(15.14)
By (15.12), the pure second derivatives of u are given by
∂2u
∂t2 (0, 0) = X2f(e),
∂2u
∂s2 (0, 0) = Y 2f(e).
To compute the mixed second derivative, we apply (15.10) twice to obtain
∂2u
∂s∂t(0, 0) = ∂
∂s

s=0
 ∂
∂t

t=0
f(exp sX exp tY )

= ∂
∂s

s=0
Y f(exp sX)
= XY f(e).
(15.15)
Therefore, by the chain rule,
d2
dt2 u(t, t)

t=0
= ∂2u
∂s2 (0, 0) + 2 ∂2u
∂s∂t(0, 0) + ∂2u
∂t2 (0, 0)
= X2f(e) + 2XY f(e) + Y 2f(e).
Taylor’s theorem then yields
f(exp tX exp tY ) = u(t, t)
= u(0, 0) + t d
dtu(t, t)

t=0
+ 1
2t2 d2
dt2 u(t, t)

t=0
+ O(t3)
= f(e) + t(Xf(e) + Y f(e))
+ 1
2t2(X2f(e) + 2XY f(e) + Y 2f(e)) + O(t3).
(15.16)

The Exponential Map
391
Because the exponential map is a diﬀeomorphism on some neighbor-
hood U of the origin in g, there is a smooth curve in U deﬁned by
γ(t) = exp−1(exp tX exp tY ) for t suﬃciently near zero. It obviously satis-
ﬁes γ(0) = 0 and
exp tX exp tY = exp γ(t).
The implied constant in the O(t3) error term in (15.13) can be taken to be
independent of X as long as X stays in a compact subset of g, as can be
seen by expressing the error explicitly in terms of the remainder term in
the Taylor series of the smooth function f ◦exp (in terms of any basis for
g). Therefore, writing the Taylor series of γ(t) as
γ(t) = tA + t2B + O(t3)
for some ﬁxed A, B ∈g, we can substitute γ(t) for tX in (15.13) and expand
to obtain
f(exp tX exp tY ) = f(exp γ(t))
= f(e) + tAf(e) + t2Bf(e) + 1
2t2A2f(e) + O(t3).
(15.17)
Comparing like powers of t in (15.17) and (15.16), we see that
Af(e) = Xf(e) + Y f(e),
Bf(e) + 1
2A2f(e) = 1
2(X2f(e) + 2XY f(e) + Y 2f(e)).
Since this is true for every f, the ﬁrst equation implies A = X+Y . Inserting
this into the second equation, we obtain
Bf(e) = 1
2(X2f(e) + 2XY f(e) + Y 2f(e)) −1
2(X + Y )2f(e)
= 1
2X2f(e) + XY f(e) + 1
2Y 2f(e)
−1
2X2f(e) −1
2XY f(e) −1
2Y Xf(e) −1
2Y 2f(e)
= 1
2(XY f(e) −Y Xf(e))
= 1
2[X, Y ]f(e).
This implies B = 1
2[X, Y ], which completes the proof of (15.8).
Finally, (15.9) is proved by applying (15.8) twice:
(exp tX)(exp tY )(exp −tX)(exp −tY )
= exp(t(X + Y ) + 1
2t2[X, Y ] + O(t3)) ×
exp(t(−X −Y ) + 1
2t2[X, Y ] + O(t3))
= exp(t2[X, Y ] + O(t3)).

392
15. Lie Algebras and Lie Groups
The formulas above are special cases of a much more general formula,
called the Baker-Campbell-Hausdorﬀformula, which gives recursive expres-
sions for all the terms of the Taylor series of γ(t) in terms of X, Y , [X, Y ],
and iterated brackets such as [X, [X, Y ]] and [Y, [X, [X, Y ]]]. The full for-
mula can be found in [Var84].
The Closed Subgroup Theorem
The next theorem is one of the most powerful applications of the expo-
nential map. For example, it allows us to strengthen Theorem 7.15 about
quotients of Lie groups, because we need only assume that the subgroup H
is topologically closed in G, not that it is a closed Lie subgroup. A similar
remark applies to Proposition 7.21.
Theorem 15.29 (Closed Subgroup Theorem).
Suppose G is a Lie
group and H ⊂G is a subgroup that is also a closed subset. Then H is an
embedded Lie subgroup.
Proof. By Proposition 5.41, it suﬃces to show that H is an embedded
submanifold of G. We begin by identifying a subspace of the Lie algebra of
G that will turn out to be the Lie algebra of H.
Let g denote the Lie algebra of G, and deﬁne a subset h ⊂g by
h = {X ∈g : exp tX ∈H for all t ∈R}.
We need to show that h is a vector subspace of g. It is obvious from the
deﬁnition that if X ∈h, then tX ∈h for all t ∈R. To see that h is closed
under vector addition, let X, Y ∈h be arbitrary. Observe that (15.8) implies
that for any t ∈R and n ∈N,
exp t
nX exp t
nY = exp
 t
n(X + Y ) + O
 t2
n2

,
and a simple induction using (15.8) again shows that

exp t
nX exp t
nY
n
=

exp
 t
n(X + Y ) + O
 t2
n2
n
= exp

t(X + Y ) + O
t2
n

.
Taking the limit as n →∞, we obtain
exp t(X + Y ) = lim
n→∞

exp t
nX exp t
nY
n
,

The Closed Subgroup Theorem
393
which is in H because H is closed in G. Thus X + Y ∈h, and so h is a
subspace. (In fact, (15.9) can be used in a similar way to prove that h is a
Lie subalgebra, but we will not need this.)
Next we will show that there is a neighborhood U of the origin in g on
which the exponential map of G is a diﬀeomorphism, and which has the
property that
exp(U ∩h) = (exp U) ∩H.
(15.18)
This will enable us to construct a slice chart for H near the identity, and
we will then use left translation to get a slice chart in a neighborhood of
any point of H.
If U is any neighborhood of 0 ∈g on which exp is a diﬀeomorphism, then
exp(U ∩h) ⊂(exp U) ∩H by deﬁnition of h. So to ﬁnd a neighborhood
satisfying (15.18), all we need to do is to show that U can be chosen small
enough that (exp U)∩H ⊂exp(U ∩h). Assume this is not possible. Let {Ui}
be any countable neighborhood basis at 0 ∈g (for example, a countable
sequence of coordinate balls whose radii approach zero). The assumption
implies that for each i, there exists hi ∈(exp Ui) ∩H such that hi /∈
exp(Ui ∩h).
Choose a basis E1, . . . , Ek for h and extend it to a basis E1, . . . , Em for
g. Let b be the subspace spanned by Ek+1, . . . , Em, so that g = h × b as
vector spaces. By Lemma 15.27, as soon as i is large enough, the map from
h × b to G given by (X, Y ) 7→exp X exp Y is a diﬀeomorphism from Ui to
a neighborhood of e in G. Therefore we can write
hi = exp Xi exp Yi
for some Xi ∈Ui ∩h and Yi ∈Ui ∩b, with Yi ̸= 0 because hi /∈exp(Ui ∩
h). Since {Ui} is a neighborhood basis, Yi →0 as i →∞. Observe that
exp Xi ∈H by deﬁnition of h, so it follows that exp Yi = (exp Xi)−1hi ∈H
as well.
The basis {Ej} induces a vector space isomorphism E : g ∼= Rm. Let
|· | denote the Euclidean norm induced by this isomorphism and deﬁne
ci = |Yi|, so that ci →0 as i →∞. The sequence {c−1
i Yi} lies in the unit
sphere in b with respect to this norm, so replacing it by a subsequence we
may assume that c−1
i Yi →Y ∈b, with |Y | = 1 by continuity. In particular,
Y ̸= 0. We will show that exp tY ∈H for all t ∈R, which implies that
Y ∈h. Since h ∩b = {0}, this is a contradiction.
Let t ∈R be arbitrary, and for each i, let ni be the greatest integer less
than or equal to t/ci. Then
ni −t
ci
 ≤1,
which implies
|nici −t| ≤ci →0,

394
15. Lie Algebras and Lie Groups
so nici →t. Thus
niYi = (nici)(c−1
i
Yi) →tY,
which implies exp niYi →exp tY by continuity. But exp niYi = (exp Yi)n ∈
H, so the fact that H is closed implies exp tY ∈H. This completes the
proof of the existence of U satisfying (15.18).
The composite map ϕ = E ◦exp−1 : exp U →Rm is easily seen to be a
coordinate chart for G, and by our choice of basis, ϕ((exp U)∩H) = E(U ∩
h) is the slice obtained by setting the last m −k coordinates equal to zero.
Moreover, if h ∈H is arbitrary, left multiplication Lh is a diﬀeomorphism
from exp U to a neighborhood of h. Since H is a subgroup, Lh(H) = H,
and so
Lh((exp U) ∩H) = Lh(exp U) ∩H,
and ϕ ◦L−1
h
is easily seen to be a slice chart for H in a neighborhood of h.
Thus H is a regular submanifold of G, hence a Lie subgroup.
The following corollary summarizes the closed subgroup theorem and
Proposition 5.41.
Corollary 15.30. If G is a Lie group and H is any subgroup of G, the
following are equivalent:
(a) H is closed in G.
(b) H is an embedded Lie subgroup.
Lie Subalgebras and Lie Subgroups
Earlier in this chapter, we saw that a Lie subgroup of a Lie group gives rise
to a Lie subalgebra of its Lie algebra. In this section, we show that the con-
verse is true: Every Lie subalgebra corresponds to some Lie subgroup. This
result has important consequences that we will explore in the remainder of
the chapter.
Theorem 15.31. Suppose G is a Lie group with Lie algebra g. If h is any
Lie subalgebra of g, then there is a unique connected Lie subgroup of G
whose Lie algebra is h (under the canonical identiﬁcation of the Lie algebra
of a subgroup with a Lie subalgebra of g).
Proof. Deﬁne a distribution D ⊂TG by
Dg = {Xg ∈TgG : X ∈h}.

Lie Subalgebras and Lie Subgroups
395
If (X1, . . . , Xk) is any basis for h, then clearly Dg is spanned by
X1|g, . . . , Xk|g at any g ∈G. Thus D is locally (in fact, globally) spanned
by smooth vector ﬁelds, so it is a smooth subbundle of TG. Moreover, be-
cause [Xi, Xj] ∈h for each i, j, D is involutive. Let H denote the foliation
determined by D, and for any g ∈G, let Hg denote the leaf of H containing
g.
If g, g′ are arbitrary elements of G, then
Lg∗(Dg′) = span(Lg∗X1|g′, . . . , Lg∗Xk|g′)
= span(X1|gg′, . . . , Xk|gg′)
= Dgg′,
so D is invariant under all left translations. If M is any connected integral
manifold of D, then so is Lg(M), since
Tg′Lg(M) = Lg∗(Tg−1g′M) = Lg∗(Dg−1g′) = Dg′.
If M is maximal, it is easy to see that Lg(M) is as well. It follows that left
multiplication takes leaves to leaves: Lg(Hg′) = Hgg′ for any g, g′ ∈G.
Deﬁne H = He, the leaf containing the identity. We will show that H is
the desired Lie subgroup.
First, to see that H is a subgroup, observe that for any h, h′ ∈H,
hh′ = Lh(h′) ∈Lh(H) = Lh(He) = Hh = H.
Similarly,
h−1 = h−1e ∈Lh−1(He) = Lh−1(Hh) = Hh−1h = H.
To show that H is a Lie group, we need to show that the map µ: (h, h′) 7→
hh′−1 is smooth as a map from H×H to H. Because H×H is a submanifold
of G × G, it is immediate that µ: H × H →G is smooth. Since H is an
integral manifold of an involutive distribution, Proposition 14.7 shows that
µ is also smooth as a map into H.
The fact that H is a leaf of H implies that the Lie algebra of H is h,
because the tangent space to H at the identity is De = {Xe : X ∈h}. To
see that H is the unique connected subgroup with Lie algebra h, suppose eH
is any other connected subgroup with the same Lie algebra. Any such Lie
subgroup is easily seen to be an integral manifold of D, so by maximality
of H, we must have eH ⊂H. On the other hand, if U is the domain of a ﬂat
chart for D near the identity, then by Proposition 14.6. eH ∩U is a union
of open subsets of slices. Since the slice containing e is an open subset of
H, this implies that eH contains a neighborhood V of the identity in H.

396
15. Lie Algebras and Lie Groups
Moreover, for any other point h ∈eH, Lh(V ) is an open subset of H that is
also contained in eH, so eH is open in H. By Problem 7-9, this implies that
eH = H.
The most important application of Theorem 15.31 is in the proof of the
next theorem.
Theorem 15.32. Suppose G and H are Lie groups with G simply con-
nected, and let g and h denote their Lie algebras. For any Lie algebra homo-
morphism ϕ: g →h, there is a unique Lie group homomorphism Φ: G →H
such that Φ∗= ϕ.
Proof. The Lie algebra of G × H is the product Lie algebra g × h. Let
k ⊂g × h be the graph of ϕ:
k = {(X, ϕX) : X ∈g}.
Then k is a vector subspace of g × h because ϕ is linear, and in fact it is a
Lie subalgebra because ϕ is a homomorphism:
[(X, ϕX), (X′, ϕX′)] = ([X, X′], [ϕX, ϕX′]) = ([X, X′], ϕ[X, X′]) ∈k.
Therefore, by the preceding theorem, there is a unique connected Lie sub-
group K ⊂G × H whose Lie algebra is k.
The restrictions to K of the projections
π1|K : K →G,
π2|K : K →H
are Lie group homomorphisms because π1 and π2 are. Let Π = π1|K : K →
G. We will show that Π is a smooth covering map. Since G is simply
connected, this will imply that Π is a diﬀeomorphism and thus a Lie group
isomorphism.
To show that Π is a smooth covering map, it suﬃces by Problem 7-5 to
show that Π is surjective and has discrete kernel. Consider the sequence of
maps
K ,→G × H
π1
−→G
whose composition is Π. The induced Lie algebra homomorphism Π∗is just
inclusion followed by projection on the algebra level:
k ,→g × h
π1
−→g.
This last composition is nothing more than the restriction to k of the pro-
jection g × h →g. Because k ∩h = {0} (since k is a graph), it follows that
Π∗: k →g is an isomorphism. Because Π is a Lie group homomorphism, it

Lie Subalgebras and Lie Subgroups
397
has constant rank, and therefore it is a local diﬀeomorphism and an open
map. Moreover, its kernel is an embedded Lie subgroup of dimension zero,
which is to say a discrete group. Because Π(K) is an open subgroup of the
connected Lie group G, it is all of G by Problem 7-9. Thus Π is a surjective
Lie group homomorphism with discrete kernel, so it is a smooth covering
map and thus a Lie group isomorphism.
Deﬁne a Lie group homomorphism Φ: G →H by Φ = π2|K ◦Π−1. Note
that the deﬁnition of Φ implies that
π2|K = Φ ◦π1|K.
Because the Lie algebra homomorphism induced by the projection π1 : G×
H →H is just the linear projection π1 : g × h →h, this implies
π2|k = Φ∗◦π1|k : k →h.
Thus if X ∈g is arbitrary,
ϕX = π2|k(X, ϕX)
= Φ∗◦π1|k(X, ϕX)
= Φ∗X,
which shows that Φ∗= ϕ.
The proof is completed by showing that Φ is the unique homomorphism
with this property. This is left as an exercise.
Exercise 15.4.
Show that the homomorphism Φ constructed in the pre-
ceding proof is the unique Lie group homomorphism such that Φ∗= ϕ.
[Hint: Consider the graph.]
Corollary 15.33. If G and H are simply connected Lie groups with iso-
morphic Lie algebras, then G and H are Lie isomorphic.
Proof. Let g, h be the Lie algebras, and let ϕ: g →h be a Lie algebra
isomorphism between them. By the preceding theorem, there are Lie group
homomorphisms Φ: G →H and Ψ: H →G satisfying Φ∗= ϕ and Ψ∗=
ϕ−1. Both the identity map of G and the composition Ψ ◦Φ are maps
from G to itself whose induced homomorphisms are equal to the identity,
so the uniqueness part of Theorem 15.32 implies that Ψ◦Φ = Id. Similarly,
Φ ◦Ψ = Id, so Φ is a Lie group isomorphism.
A version of this theorem was proved in the nineteenth century by Sophus
Lie. However, since global topological notions such as simple connectedness
had not yet been formulated, what he was able to prove was essentially a

398
15. Lie Algebras and Lie Groups
local version of this corollary. Two Lie groups G and H are said to be
locally isomorphic if there exist neighborhoods of the identity U ⊂G and
V ⊂H, and a diﬀeomorphism F : U →V such that F(g1g2) = F(g1)F(g2)
whenever g1, g2, and g1g2 are all in U.
Theorem 15.34 (Fundamental Theorem of Sophus Lie).
Two Lie
groups are locally isomorphic if and only if they have isomorphic Lie alge-
bras.
The proof in one direction is essentially to follow the arguments in Theo-
rem 15.32 and Corollary 15.33, except that one just uses the inverse function
theorem to show that Φ is a local isomorphism instead of appealing to the
theory of covering spaces. The details are left as an exercise.
Exercise 15.5.
Carry out the details of the proof of Lie’s fundamental
theorem.
The Fundamental Correspondence Between Lie
Algebras and Lie Groups
Many of the results of this chapter show how essential properties of a Lie
group are reﬂected in its Lie algebra. This raises a natural question: To
what extent is the correspondence between Lie groups and Lie algebras (or
at least between their isomorphism classes) one-to-one? We have already
seen in Corollary 15.11 that isomorphic Lie groups have isomorphic Lie
algebras. The converse is easily seen to be false: Both Rn and Tn have n-
dimensional abelian Lie algebras, which are obviously isomorphic, but Rn
and Tn are certainly not isomorphic Lie groups. However, if we restrict our
attention to simply connected Lie groups, then we do obtain a one-to-one
correspondence. The central result is the following theorem.
Theorem 15.35 (Lie Group–Lie Algebra Correspondence).
There is a one-to-one correspondence between isomorphism classes of
ﬁnite-dimensional Lie algebras and isomorphism classes of simply con-
nected Lie groups, given by associating each simply connected Lie group
with its Lie algebra.
The proof of this theorem will tie together all the work we have done so
far on Lie groups and their Lie algebras, together with one deep algebraic
result that we will state without proof. Let us begin by describing the
algebraic result.
Let g be a Lie algebra. A representation of g is a Lie algebra homomor-
phism ρ: g →gl(n, R) for some n. If ρ is injective, it is said to be a faithful
representation. In this case, it is easy to see that g is isomorphic to ρ(g),
which is a Lie subalgebra of gl(n, R).

The Fundamental Correspondence
399
Theorem 15.36 (Ado’s Theorem).
Every Lie algebra has a faithful
representation.
The proof is long, hard, and very algebraic. It can be found in [Var84].
Proof of Theorem 15.35.
We need to show that the association that sends
a simply connected Lie group to its Lie algebra is both surjective and in-
jective up to isomorphism. Injectivity is precisely the content of Corollary
15.33. To prove surjectivity, suppose g is any ﬁnite-dimensional Lie alge-
bra. Replacing g with its isomorphic image under a faithful representation
ρ: g →gl(n, R), we may assume that g is a Lie subalgebra of gl(n, R). By
Theorem 15.31, there is a unique Lie subgroup G ⊂GL(n, R) that has g as
its Lie algebra. Letting eG be the universal covering group of G, Proposition
15.14 shows that Lie( eG) ∼= Lie(G) ∼= g.
What happens when we allow non-simply-connected groups? Because
every Lie group has a simply connected covering group, the answer in the
connected case is easy to describe. (For disconnected groups, the answer is
described in Problem 15-4.)
Theorem 15.37. Let g be a ﬁnite-dimensional Lie algebra. The connected
Lie groups whose Lie algebras are isomorphic to g are (up to isomorphism)
precisely those of the form G/Γ, where G is the simply connected Lie group
with Lie algebra g, and Γ is a discrete normal subgroup of G.
Proof. Given g, let G be a simply connected Lie group with Lie algebra
isomorphic to g. Suppose H is any other Lie group whose Lie algebra is
isomorphic to g, and let ϕ: Lie(G) →Lie(H) be a Lie algebra isomor-
phism. Theorem 15.32 guarantees that there is a Lie group homomorphism
Φ: G →H such that Φ∗= ϕ. Because ϕ is an isomorphism, Φ is a local dif-
feomorphism, and therefore Γ = KerΦ is a discrete normal subgroup of G.
Since Φ is a surjective Lie homomorphism with kernel Γ, H is isomorphic
to G/Γ by Problem 7-4.
Exercise 15.6.
Show that two connected Lie groups are locally isomor-
phic if and only if they have isomorphic universal covering groups.

400
15. Lie Algebras and Lie Groups
Problems
15-1. Let G be a connected Lie group, and U ⊂G any neighborhood of the
identity. Show that U generates G, i.e., that every element of G can
be written as a ﬁnite product of elements of U.
15-2. Compute the exponential maps of the abelian Lie groups Rn and Tn.
15-3. Consider S3 as the unit sphere in R4 with coordinates (w, x, y, z).
Show that there is a Lie group structure on S3 in which the vector
ﬁelds
X1 = −x ∂
∂w + w ∂
∂x −z ∂
∂y + y ∂
∂z,
X2 = −y ∂
∂w + z ∂
∂x + w ∂
∂y −x ∂
∂z ,
X3 = −z ∂
∂w −y ∂
∂x + x ∂
∂y + w ∂
∂z .
form a left-invariant frame. [See Problems 7-8 and 3-6. It was shown
in 1958 by Raoul Bott and John Milnor [BM58] using more advanced
methods that the only spheres that are parallelizable are S1, S3, and
S7. Thus these are the only spheres that can possibly admit Lie group
structures. The ﬁrst two do, as we have seen; it turns out that S7 has
no Lie group structure.]
15-4. Let g be a ﬁnite-dimensional Lie algebra, and let G be the simply
connected Lie group whose Lie algebra is g. Describe all Lie groups
whose Lie algebra is g in terms of G and discrete groups.
15-5. Let G be a Lie group.
(a) Show that the images of one-parameter subgroups in G are pre-
cisely the connected Lie subgroups of dimension less than or
equal to 1.
(b) If H ⊂G is the image of a one-parameter subgroup, show that
H is Lie isomorphic to one of the following: the trivial group
{e}, R, or S1.
15-6. Prove that there is exactly one nonabelian 2-dimensional Lie algebra
up to isomorphism.
15-7. Let A and B be the following elements of gl(2, R):
A =

0
1
−1
0

;
B =

0
1
0
0

.
Compute the one-parameter subgroups of GL(2, R) generated by A
and B.

Problems
401
15-8. Let GL+(n, R) be the subgroup of GL(n, R) consisting of matrices
with positive determinant. (By Proposition 7.26, it is the identity
component of GL(n, R).)
(a) Suppose A ∈GL+(n, R) is of the form eB for some B ∈gl(n, R).
Show that A has a square root, i.e., a matrix C ∈GL+(n, R)
such that C2 = A.
(b) Let
A =
−1
0
0
−2

.
Show that the exponential map exp: gl(2, R) →GL+(2, R) is
not surjective, by showing that A is not in its image.
15-9. Let {i, j, k} denote the standard basis of R3, and let H = R × R3,
with basis {1, i, j, k}. Deﬁne a bilinear multiplication H × H →H by
setting
1q = q1 = q for all q ∈H,
ij = −ji = k,
jk = −kj = i,
ki = −ik = j,
i2 = j2 = k2 = −1,
and extending bilinearly. With this multiplication, H is called the ring
of quaternions.
(a) Show that quaternionic multiplication is associative.
(b) Show that the set S of unit quaternions (with respect to the
Euclidean metric) is a Lie group under quaternionic multiplica-
tion, and is Lie isomorphic to SU(2).
(c) For any point q ∈H, show that the quaternions iq, jq, and kq
are orthogonal to q. Use this to deﬁne a left-invariant frame on
S, and show that it corresponds under the isomorphism of (b)
to the one deﬁned in Problem 15-3.
15-10. Look up the Cayley numbers, and prove that S7 is parallelizable by
mimicking as much as you can of Problem 15-9. Why do the unit
Cayley numbers not form a Lie group?
15-11. Let A ⊂T(R3) be the subspace with basis {X, Y, Z}, where
X = y ∂
∂z −z ∂
∂y,
Y = z ∂
∂x −x ∂
∂z ,
Z = x ∂
∂y −y ∂
∂x.

402
15. Lie Algebras and Lie Groups
Show that A is a Lie subalgebra of T(R3), which is Lie algebra iso-
morphic to R3 with the cross product, and also to the Lie algebra
o(3) of O(3).
15-12. Let G be a connected Lie group and g its Lie algebra.
(a) If X, Y ∈g, show that [X, Y ] = 0 if and only if
exp tX exp sY = exp sY exp tX for all s, t ∈R.
(b) Show that G is abelian if and only if g is abelian.
(c) Give a counterexample when G is not connected.
15-13. Show that every connected abelian Lie group is Lie isomorphic to
Rk × Tl for some nonnegative integers k and l.
15-14. Deﬁne a map β : GL(n, C) →GL(2n, R) by identifying (x1 +
iy1, . . . , xn + iyn) ∈Cn with (x1, y1, . . . , xn, yn) ∈R2n.
(a) Show that β is an injective Lie group homomorphism, so that
we can identify GL(n, C) with the Lie subgroup of GL(2n, R)
consisting of matrices built up out of 2 × 2 blocks of the form
  a −b
b
a

.
(b) Under our usual (vector space) isomorphisms TI GL(n, C) ∼=
gl(n, C) and TI GL(n, R) ∼= gl(n, R), show that the induced
Lie algebra homomorphism β∗: Lie(GL(n, C)) →Lie(GL(n, R))
induces an injective Lie algebra homomorphism gl(n, C) →
gl(n, R) (considering both as Lie algebras with the commutator
bracket). Conclude that Lie(GL(n, C)) is Lie algebra isomorphic
to the matrix algebra gl(n, C).
(c) Determine the Lie algebras sl(n, C), u(n), and su(n) of SL(n, C),
U(n), and SU(n), respectively, as matrix subalgebras of gl(n, C).
15-15. Show by giving an explicit isomorphism that su(2) and o(3) are iso-
morphic Lie algebras.

Appendix
Review of Prerequisites
The essential prerequisites for reading this book are a thorough acquain-
tance with abstract linear algebra, advanced multivariable calculus, and
basic topology. The topological prerequisites include basic properties of
topological spaces, topological manifolds, the fundamental group, and cov-
ering spaces; these are covered fully in my book Introduction to Topological
Manifolds [Lee00]. In this appendix, we summarize the most important
facts from linear algebra and advanced calculus that are used throughout
this book.
Linear Algebra
For the basic properties of vector spaces and linear maps, you can consult
almost any linear algebra book that treats vector spaces abstractly, such as
[FIS97]. Here we just summarize the main points, with emphasis on those
aspects that will prove most important in the study of smooth manifolds.
Vector Spaces
Let R denote the ﬁeld of real numbers. A vector space over R (or real vector
space) is a set V endowed with two operations: vector addition V ×V →V ,
denoted by (X, Y ) 7→X +Y , and scalar multiplication R×V →V , denoted
by (a, X) 7→aX; the operations are required to satisfy
(i) V is an abelian group under vector addition.

404
Appendix: Review of Prerequisites
(ii) Scalar multiplication satisﬁes the following identities:
a(bX) = (ab)X
for all X ∈V and a, b ∈R;
1X = X
for all X ∈V .
(iii) Scalar multiplication and vector addition are related by the following
distributive laws:
(a + b)X = aX + bX
for all X ∈V and a, b ∈R;
a(X + Y ) = aX + aY
for all X, Y ∈V and a ∈R.
The elements of V are usually called vectors. When necessary to distinguish
them from vectors, real numbers are sometimes called scalars.
This deﬁnition can be generalized in two directions. First, replacing R by
an arbitrary ﬁeld F everywhere, we obtain the deﬁnition of a vector space
over F. Second, if R is replaced by a ring R, this becomes the deﬁnition of
a module over R. We will be concerned almost exclusively with real vector
spaces, but it is useful to be aware of these more general deﬁnitions. Unless
we specify otherwise, all vector spaces will be assumed to be real.
If V is a vector space, a subset W ⊂V that is closed under vector
addition and scalar multiplication is itself a vector space, and is called a
subspace of V .
Let V be a vector space. A ﬁnite sum of the form Pk
i=1 aiXi, where
ai ∈R and Xi ∈V , is called a linear combination of the vectors X1, . . . , Xk.
(The reason we write the coeﬃcients ai with superscripts instead of sub-
scripts is to be consistent with the Einstein summation convention, which
is explained in Chapter 1.) If S is an arbitrary subset of V , the set of all
linear combinations of elements of S is called the span of S and is denoted
by span(S); it is easily seen to be the smallest subspace of V containing S.
If V = span(S), we say S spans V . By convention, a linear combination of
no elements is considered to sum to zero, and the span of the empty set is
{0}.
Bases and Dimension
A subset S is said to be linearly dependent if there exists a linear relation
of the form Pk
i=1 aiXi = 0, where X1, . . . , Xk are distinct elements of S
and at least one of the coeﬃcients ai is nonzero; it is said to be linearly
independent otherwise. In other words, S is linearly independent if and only
if the only linear combination of distinct elements of S that sums to zero
is the one in which all the scalar coeﬃcients are zero. Note that any set
containing the zero vector is linearly dependent. By convention, the empty
set is considered to be linearly independent.
Exercise A.1.
Let V be a vector space and S ⊂V .

Linear Algebra
405
(a)
If S is linearly independent, show that any subset of S is linearly
independent.
(b)
If S is linearly dependent or spans V , show that any subset of V that
properly contains S is linearly dependent.
(c)
Show that S is linearly dependent if and only if some element X ∈S
can be expressed as a linear combination of elements of S r {X}.
(d)
If (X1, . . . , Xm) is a ﬁnite, ordered, linearly dependent subset of V ,
show that some Xi can be written as a linear combination of the pre-
ceding vectors (X1, . . . , Xi−1).
A basis for V is a subset S ⊂V that is linearly independent and spans
V . If S is a basis for V , every element of V has a unique expression as a
linear combination of elements of S. If V has a ﬁnite basis, then V is said to
be ﬁnite-dimensional, and otherwise it is inﬁnite-dimensional. The trivial
vector space {0} (which we denote by R0) is ﬁnite-dimensional, because it
has the empty set as a basis.
Lemma A.1. Let V be a ﬁnite-dimensional vector space. If V is spanned
by n vectors, then every subset of V containing more than n vectors is
linearly dependent.
Proof. Suppose the vectors {X1, . . . , Xn} span V . To prove the lemma, it
clearly suﬃces to show that any n+1 vectors {Y1, . . . , Yn+1} are dependent.
Suppose not. By Exercise A.1(b), the set {Y1, X1, . . . , Xn} is dependent.
This means there is an equation of the form b1Y1+P
i aiXi = 0 in which not
all of the coeﬃcients are equal to zero. If b1 is the only nonzero coeﬃcient,
then Y1 = 0 and clearly the set of Yis is dependent. Otherwise, some ai is
nonzero; renumbering the Xis if necessary, we may assume it is a1. Since we
can solve for X1 in terms of Y1 and the other Xis, the set {Y1, X2, . . . , Xn}
still spans V .
Now suppose by induction that {Y1, Y2, . . . , Yk−1, Xk, . . . , Xn} spans V .
As before, the set {Y1, Y2, . . . , Yk−1, Yk, Xk, . . . , Xn} is dependent, so there
is a relation of the form
k
X
i=1
biYi +
n
X
i=k
aiXi = 0
with not all coeﬃcients equal to zero. If all the ais are zero, the Yis are
clearly dependent, so we may assume at least one of the ais is nonzero,
and after reordering we may assume it is ak. Solving for Xk as before, we
conclude that the set {Y1, Y2, . . . , Yk, Xk+1, . . . , Xn} still spans V . Contin-
uing by induction, we conclude that the vectors {Y1, . . . , Yn} span V , which
means that {Y1, . . . , Yn+1} are dependent by Exercise A.1(b).
Proposition A.2. If V is a ﬁnite-dimensional vector space, all bases of
V contain the same number of elements.

406
Appendix: Review of Prerequisites
Proof. If {E1, . . . , En} is a basis for V , then Lemma A.1 implies that any
set containing more than n elements is dependent, so no basis can have more
than n elements. Conversely, if there were a basis containing fewer than n
elements, then Lemma A.1 would imply that {E1, . . . , En} is dependent,
which is a contradiction.
Because of the preceding proposition, it makes sense to deﬁne the di-
mension of a ﬁnite-dimensional vector space to be the number of elements
in a basis.
Exercise A.2.
Suppose V is a ﬁnite-dimensional vector space.
(a)
Show that every set that spans V contains a basis, and every linearly
independent subset of V is contained in a basis.
(b)
If S ⊂V is a subspace, show that S is ﬁnite-dimensional and dim S ≤
dim V , with equality if and only if S = V .
An ordered basis of a ﬁnite-dimensional vector space is a basis endowed
with a speciﬁc ordering of the basis vectors. For most purposes, ordered
bases are more useful than bases, so we will assume without comment that
each basis comes with a given ordering. We will denote an ordered basis by
a notation such as (E1, . . . , En) or (Ei).
If (E1, . . . , En) is an (ordered) basis for V , each vector X ∈V has a
unique expression as a linear combination of basis vectors:
X =
n
X
i=1
XiEi.
The numbers Xi are called the components of X with respect to this basis,
and the ordered n-tuple (X1, . . . , Xn) is called its basis representation.
(Here is an example of a deﬁnition that requires an ordered basis.)
The fundamental example of a ﬁnite-dimensional vector space is of course
Rn = R × · · · × R, which we call n-dimensional Euclidean space. It is
a vector space under the usual operations of vector addition and scalar
multiplication. We will denote a point in Rn by any of the notations x or
(xi) or (x1, . . . , xn); the numbers xi are called the coordinates of x. They
are also the components of x with respect to the standard basis (e1, . . . , en),
where ei = (0, . . . , 1, . . . , 0) is the vector with a 1 in the ith place and zeros
elsewhere.
Notice that we always write the coordinates of a point (x1, . . . , xn) ∈
Rn with upper indices, not subscripts as is usually done in linear algebra
and calculus books, so as to be consistent with the Einstein summation
convention (see Chapter 1).
If S and T are subspaces of a vector space V , the notation S +T denotes
the set of all vectors of the form X + Y , where X ∈S and Y ∈T . It is
easily seen to be a subspace, and in fact is the subspace spanned by S ∪T .

Linear Algebra
407
If S + T = V and S ∩T = {0}, V is said to be the direct sum of S and T ,
and we write V = S ⊕T .
If S is any subspace of V , another subspace T ⊂V is said to be com-
plementary to S if V = S ⊕T . In this case, it is easy to check that every
vector in V has a unique expression as a sum of an element of S plus an
element of T .
Exercise A.3.
Suppose S and T are subspaces of a ﬁnite-dimensional vec-
tor space V .
(a)
Show that S ∩T is a subspace of V .
(b)
Show that dim(S + T) = dim S + dim T −dim(S ∩T).
(c)
If V = S+T, show that V = S⊕T if and only if dim V = dim S+dim T.
Exercise A.4.
Let V be a ﬁnite-dimensional vector space. Show that
every subspace S ⊂V has a complementary subspace in V . In fact, if
(E1, . . . , En) is any basis for V , show that there is some subset {i1, . . . , ik}
of the integers {1, . . . , n} such that span(Ei1, . . . , Eik) is a complement to
S. [Hint: Choose a basis (F1, . . . , Fm) for S, and apply Exercise A.1(d) to
the ordered (m + n)-tuple (F1, . . . , Fm, E1, . . . , En).]
Suppose S ⊂V is a subspace. For any vector x ∈V , the coset of S
determined by x is the set
x + S = {x + y : y ∈S}.
A coset is also sometimes called an aﬃne subspace of V parallel to S. The
set V/S of cosets of S is called the quotient of V by S.
Exercise A.5.
Suppose V is a vector space and S is a subspace of V .
Deﬁne vector addition and scalar multiplication of cosets by
(x + S) + (y + S) = (x + y) + S;
c(x + S) = (cx) + S.
(a)
Show that the quotient V/S is a vector space under these operations.
(b)
If V is ﬁnite-dimensional, show that dim V/S = dim V −dim S.
Linear Maps
Let V and W be vector spaces. A map T : V →W is linear if T (aX+bY ) =
aTX + bT Y for all vectors X, Y ∈V and all scalars a, b. The kernel of T ,
denoted by Ker T , is the set {X ∈V : TX = 0}, and its image, denoted by
Im T or T (V ), is {Y ∈W : Y = TX for some X ∈V }.
One simple but important example of a linear map arises in the following
way. Given a subspace S ⊂V and a complementary subspace T , there is a
unique linear map π: V →S deﬁned by
π(X + Y ) = X for X ∈S, Y ∈T .

408
Appendix: Review of Prerequisites
This map is called the projection onto S with kernel T .
A bijective linear map T : V →W is called an isomorphism. In this case,
there is a unique inverse map T −1: W →V , and the following computation
shows that T −1 is also linear:
aT −1X + bT −1Y = T −1T (aT −1X + bT −1Y )
= T −1(aT T −1X + bTT −1Y )
(by linearity of T )
= T −1(aX + bY ).
For this reason, a bijective linear map is also said to be invertible. If there
exists an isomorphism T : V →W, then V and W are said to be isomorphic.
Isomorphism is easily seen to be an equivalence relation.
Example A.3. Let V
be any n-dimensional vector space, and let
(E1, . . . , En) be any ordered basis for V . Deﬁne a map E : Rn →V by
E(x1, . . . , xn) = x1E1 + . . . xnEn.
Then E is bijective, so it is an isomorphism, called the basis isomorphism
determined by this basis. Thus every n-dimensional vector space is isomor-
phic to Rn.
Exercise A.6.
Let V and W be vector spaces, and suppose (E1, . . . , En)
is a basis for V . For any n elements X1, . . . , Xn ∈W , show that there is a
unique linear map T : V →W satisfying T(Ei) = Xi for i = 1, . . . , n.
Exercise A.7.
Let S : V →W and T : W →X be linear maps.
(a)
Show that Ker S and Im S are subspaces of V and W , respectively.
(b)
Show that S is injective if and only if Ker S = {0}.
(c)
If S is an isomorphism, show that dim V = dim W (in the sense that
these dimensions are either both inﬁnite or both ﬁnite and equal).
(d)
If S and T are both injective or both surjective, show that T ◦S has
the same property.
(e)
If T ◦S is surjective, show that T is surjective; give an example to show
that S may not be.
(f)
If T ◦S is injective, show that S is injective; give an example to show
that T may not be.
(g)
If V and W are ﬁnite-dimensional vector spaces of the same dimension
and S is either injective or surjective, show that it is an isomorphism.
Exercise A.8.
Suppose V is a vector space and S is a subspace of V , and
let π: V →V/S denote the projection onto the quotient space. If T : V →W
is a linear map, show that there exists a linear map eT : V/S →W such that
eT ◦π = T if and only if S ⊂Ker T.

Linear Algebra
409
Now suppose V and W are ﬁnite-dimensional vector spaces with ordered
bases (E1, . . . , En) and (F1, . . . , Fm), respectively. If T : V →W is a linear
map, the matrix of T with respect to these bases is the m × n matrix
A = (Aj
i) =



A1
1
. . .
A1
n
...
...
...
Am
1
. . .
Am
n



whose ith column consists of the components of TEi with respect to the
basis (Fj):
TEi =
m
X
j=1
Aj
iFj.
By linearity, the action of T on any vector X = P
i XiEi is then given by
T
 n
X
i=1
XiEi
!
=
n
X
i=1
m
X
j=1
Aj
i XiFj.
If we write the components of a vector with respect to a basis as a column
matrix, then the matrix representation of Y = TX is given by matrix
multiplication:



Y 1
...
Y m


=



A1
1
. . .
A1
n
...
...
...
Am
1
. . .
Am
n






X1
...
Xn


,
or, more succinctly,
Y j =
n
X
i=1
Aj
iXi.
It is straightforward to check that the composition of two linear maps is
represented by the product of their matrices, and the identity tranformation
of any n-dimensional vector space V is represented with respect to any basis
by the n × n identity matrix, which we denote by In; it is the matrix with
ones on the main diagonal and zeros elsewhere.
The set M(m × n, R) of all m × n real matrices is easily seen to be a real
vector space of dimension mn. In fact, by stringing out the matrix entries
in a single row, we can identify it in a natural way with Rmn. Similarly,
because C is a real vector space of dimension 2, the set M(m × n, C) of
m × n complex matrices is a real vector space of dimension 2mn.
Suppose A is an n × n matrix. If there is a matrix B such that AB =
BA = In, then A is said to be invertible or nonsingular; it is singular
otherwise.

410
Appendix: Review of Prerequisites
Exercise A.9.
Suppose A is a nonsingular matrix.
(a)
Show that there is a unique matrix B such that AB = BA = In. This
matrix is denoted by A−1 and is called the inverse of A.
(b)
If A is the matrix of an invertible linear map T : V →W with respect
to some bases for V and W , show that A is invertible and A−1 is the
matrix of T −1 with respect to the same bases.
Because Rn comes endowed with the canonical basis (ei), we can unam-
biguously identify linear maps from Rn to Rm with m × n matrices, and
we will often do so without further comment.
In this book, we often need to be concerned with how various objects
transform when we change bases. Suppose (Ei) and ( eEj) are two bases
for a ﬁnite-dimensional vector space V . Then each basis can be written
uniquely in terms of the other, so there is an invertible matrix B, called
the transition matrix between the two bases, such that
Ei =
n
X
j=1
Bj
i eEj,
eEj =
n
X
i=1
(B−1)i
jEi.
(A.1)
Now suppose V and W are ﬁnite-dimensional vector spaces and T : V →
W is a linear map. With respect to bases (Ei) for V and (Fj) for W, T
is represented by some matrix A = (Aj
i). If ( eEi) and ( eFj) are any other
choices of bases for V and W, respectively, let B and C denote the transition
matrices satisfying (A.1) and
Fi =
m
X
j=1
Cj
i eFj,
eFj =
m
X
i=1
(C−1)i
jFi.
Then a straightforward computation shows that the matrix eA representing
T with respect to the new bases is related to A by
eAj
i =
X
k,l
Cj
l Al
k(B−1)k
i ,
or, in matrix form,
eA = CAB−1.
In particular, if T is a map from V to itself, we usually use the same basis
in the domain and the range. In this case, if A denotes the matrix of T

Linear Algebra
411
with respect to (Ei), and eA with respect to ( eEi), we have
eA = BAB−1.
If V and W are vector spaces, the set L(V, W) of linear maps from V to
W is a vector space under the operations
(S + T )X = SX + TX;
(cT )X = c(TX).
If dim V = n and dim W = m, then any choice of bases for V and W gives
us a map L(V, W) →M(m×n, R), by sending each linear map to its matrix
with respect to the chosen bases. This map is easily seen to be linear and
bijective, so dim L(V, W) = dim M(m × n, R) = mn.
If T : V →W is a linear map between ﬁnite-dimensional spaces, the
dimension of Im T is called the rank of T , and the dimension of KerT is
called its nullity.
Exercise A.10.
Suppose V, W, X are ﬁnite-dimensional vector spaces, and
let S : V →W and T : W →X be linear maps.
(a)
Show that S is injective if and only if rank S = dim V , and S is sur-
jective if and only if rank S = dim W .
(b)
Show that rank(T ◦S) ≤rank S, with equality if and only if Im S ∩
Ker T = {0}. [Hint: Replace W by the quotient space W/ Ker T.]
(c)
Show that rank(T ◦S) ≤rank T, with equality if and only if Im S +
Ker T = W .
(d)
If S is an isomorphism, show that rank(T ◦S) = rank T, and if T is an
isomorphism, show that rank(T ◦S) = rank S.
The following theorem shows that, up to choices of bases, a linear map
is completely determined by its rank together with the dimensions of its
domain and range.
Theorem A.4 (Canonical Form for a Linear Map). Suppose V and
W are ﬁnite-dimensional vector spaces, and T : V →W is a linear map of
rank r. Then there are bases for V and W with respect to which T has the
following matrix representation (in block form):
Ir
0
0
0

.
Proof. Choose any bases (F1, . . . , Fr) for Im T and (K1, . . . , Kk) for Ker T .
Extend (Fj) arbitrarily to a basis (F1, . . . , Fm) for W. By deﬁnition of the
image, there are vectors E1, . . . , Er ∈V such that TEi = Fi for i = 1, . . . , r.
We will show that (E1, . . . , Er, K1, . . . , Kk) is a basis for V ; once we know
this, it follows easily that T has the desired matrix representation.
Suppose ﬁrst that P
i aiEi + P
j bjKj = 0. Applying T to this equation
yields Pr
i=1 aiFi = 0, which implies that all the coeﬃcients ai are zero.

412
Appendix: Review of Prerequisites
Then it follows also that all the bjs are zero because the Kjs are indepen-
dent. Therefore, the vectors (E1, . . . , Er, K1, . . . , Kk) are independent.
To show that they span V , let X ∈V be arbitrary. We can express
TX ∈Im T as a linear combination of (F1, . . . , Fr):
TX =
r
X
i=1
ciFi.
If we put Y = P
i ciEi ∈V , it follows that TY = TX, so Z = X −Y ∈
Ker T . Writing Z = P
j djKj, we obtain
X = Y + Z =
r
X
i=1
ciEi +
k
X
j=1
djKj,
so (E1, . . . , Er, K1, . . . , Kk) do indeed span V .
This theorem says that any linear map can be put into a particularly nice
diagonal form by appropriate choices of bases in the domain and range.
However, it is important to be aware of what the theorem does not say: If
T : V →V is a linear map from a ﬁnite-dimensional vector space to itself,
it may not be possible to choose a single basis for V with respect to which
the matrix of T is diagonal.
The next result is central in applications of linear algebra to smooth
manifold theory; it is a corollary to the proof of the preceding theorem.
Corollary A.5 (Rank-Nullity Law). Suppose T : V →W is any linear
map. Then
dim V = rank T + nullity T
= dim(Im T ) + dim(Ker T ).
Proof. The preceding proof showed that V has a basis consisting of k + r
elements, where k = dim Ker T and r = dim Im T .
Suppose A is an m × n matrix. The transpose of A is the n × m matrix
AT obtained by interchanging the rows and columns of A: (AT )j
i = Ai
j. (It
can be interpreted abstractly as the matrix of the dual map; see Chapter
3.) The matrix A is said to be symmetric if A = AT and skew-symmetric
if A = −AT .
Exercise A.11.
If A and B are matrices of dimensions m × n and n × k,
respectively, show that (AB)T = BT AT .
The rank of an m × n matrix A is deﬁned to be its rank as a linear map
from Rn to Rm. Because the columns of A, thought of as vectors in Rm, are
the images of the standard basis vectors under this linear map, the rank of

Linear Algebra
413
A can also be thought of as the dimension of the span of its columns, and
is sometimes called its column rank. Analogously, we deﬁne the row rank
of A to be the dimension of the span of its rows, thought of similarly as
vectors in Rn.
Proposition A.6. The row rank of any matrix is equal to its column rank.
Proof. Let A be an m × n matrix. Because the row rank of A is equal to
the column rank of AT , we must show that rank A = rank AT .
Suppose the (column) rank of A is k. Thought of as a linear map from
Rn to Rm, A factors through Im A as follows:
Rn
Rm
-
A
Im A,
eA@@
R
ι
  
where eA is just the map A with its range restricted to Im A, and ι is the
inclusion of Im A into Rm. Choosing a basis for the k-dimensional subspace
Im A, we can write this as a matrix equation A = BC, where B and C are
the matrices of ι and eA with respect to the chosen basis. Taking transposes,
we ﬁnd AT = CT BT , from which it follows that rank AT ≤rank BT . Since
BT is a k × m matrix, its column rank is at most k, which shows that
rank AT ≤rank A. Reversing the roles of A and AT and using the fact that
(AT )T = A, we conclude that rank A = rank AT .
Suppose A = (Aj
i) is an m × n matrix. By choosing nonempty subsets
{i1, . . . , ik} ⊂{1, . . . , m} and {j1, . . . , jl} ⊂{1, . . ., n}, we obtain a k × l
matrix whose entry in the pth row and qth column is Aip
jq:



Ai1
j1
. . .
Ai1
jl
...
...
...
Aik
j1
. . .
Aik
jl


.
Such a matrix is called a k × l minor of A. Looking at minors gives a
convenient criterion for checking the rank of a matrix.
Proposition A.7. Suppose A is an m×n matrix. Then rank A ≥k if and
only if some k × k minor of A is nonsingular.
Proof. We consider A as usual as a linear map from Rn to Rm. A sub-
space of Rn or Rm spanned by some subset of the standard basis vectors
will be called a coordinate subspace. Suppose {i1, . . . , ik} ⊂{1, . . ., m} and
{j1, . . . , jk} ⊂{1, . . ., n}, and let M denote the k × k minor of A deter-
mined by these subsets. If P ⊂Rn is the coordinate subspace spanned
by (ej1, . . . , ejk), and Q ⊂Rm is the coordinate subspace spanned by

414
Appendix: Review of Prerequisites
(ei1, . . . , eik), it is easy to check that M is the matrix of the composite
map
P
ι,→Rn A
→Rm
π→Q,
where ι is inclusion of P into Rn and π is the coordinate projection of Rm
onto Q. Thus to prove the proposition it suﬃces to show that rank A ≥k
if and only if there are k-dimensional coordinate subspaces P and Q such
that π ◦A ◦ι has rank k.
One direction is easy. If there are such subspaces, then rankι = rank π =
k, and k = rank(π ◦A◦ι) ≤min(k, rank A), which implies that rank A ≥k.
Conversely, suppose that rank A = r ≥k. By Exercise A.4, there exists a
coordinate subspace eP ⊂Rn complementary to Ker A. Since dim eP = n −
dim Ker A = r ≥k by the rank-nullity law, we can choose a k-dimensional
coordinate subspace P ⊂eP. Then A|P is injective, so if ι: P →Rn denotes
inclusion, it follows that A ◦ι is injective and has rank k.
Now let S ⊂Rm be any coordinate subspace complementary to Im(A◦ι),
and let Q be the coordinate subspace complementary to S (i.e., the span of
the remaining basis elements). If π: Rm →Q is the projection onto Q with
kernel S, then Im(A ◦ι) intersects Ker π = S trivially, so rank(π ◦A ◦ι) =
rank A ◦ι = k by Exercise A.10(b).
The Determinant
There are a number of ways of deﬁning the determinant of a square matrix,
each of which has advantages in diﬀerent contexts. The deﬁnition we will
give here, while perhaps not pedagogically the most straightforward, is the
simplest to state and ﬁts nicely with our treatment of alternating tensors
in Chapter 9.
We let Sn denote the group of permutations of the set {1, . . ., n}, called
the symmetric group on n elements. The properties of Sn that we will need
are summarized in the following lemma; proofs can be found in any good
undergraduate algebra text such as [Hun90] or [Her75]. A transposition is
a permutation obtained by interchanging two elements and leaving all the
others ﬁxed. A permutation that can be written as a composition of an
even number of transpositions is called even, and one that can be written
as a composition of an odd number of transpositions is called odd.
Lemma A.8 (Properties of the Symmetric Group).
(a) Every element of Sn can be decomposed as a ﬁnite sequence of trans-
positions.
(b) For any σ ∈Sn, the parity (evenness or oddness) of the number of
transpositions in any decomposition of σ as a sequence of transposi-
tions is independent of the choice of decomposition.

Linear Algebra
415
(c) The map sgn: Sn →{±1} given by
sgn(σ) =
(
1
if σ is even,
−1
if σ is odd
is a surjective group homomorphism, where we consider {±1} as a
group under multiplication.
Exercise A.12.
Prove (or look up) Lemma A.8.
If A = (Aj
i ) is an n × n (real or complex) matrix, the determinant of A
is deﬁned by the expression
det A =
X
σ∈Sn
(sgn σ)Aσ1
1 · · · Aσn
n .
(A.2)
For simplicity, we assume throughout this section that our matrices are
real. The statements and proofs, however, hold equally well in the complex
case. In our study of Lie groups we will also have occasion to consider
determinants of complex matrices.
Although the determinant is deﬁned as a function of matrices, it is also
useful to think of it as a function of n vectors in Rn: If A1, . . . , An ∈Rn,
we interpret det(A1, . . . , An) to mean the determinant of the matrix whose
columns are (A1, . . . , An):
det(A1, . . . , An) = det



A1
1
. . .
A1
n
...
...
...
An
1
. . .
An
n


.
It is obvious from the deﬁning formula (A.2) that the function det: Rn ×
· · · × Rn →R so deﬁned is multilinear, which means that it is linear as a
function of each vector when all the other vectors are held ﬁxed.
Proposition A.9 (Properties of the Determinant).
Let A be an n×
n matrix.
(a) If one column of A is multiplied by a scalar c, the determinant is
multiplied by the same scalar:
det(A1, . . . , cAi, . . . , An) = c det(A1, . . . , Ai, . . . , An).
(b) The determinant changes sign when two columns are interchanged:
det(A1, . . . , Aq, . . . , Ap, . . . , An)
= −det(A1, . . . , Ap, . . . , Aq, . . . , An).
(A.3)

416
Appendix: Review of Prerequisites
(c) The determinant is unchanged by adding a scalar multiple of one
column to any other column:
det(A1, . . . , Ai, . . . , Aj + cAi, . . . , An)
= det(A1, . . . , Ai, . . . , Aj . . . , An).
(d) For any scalar c, det(cA) = cn det A.
(e) If any two columns of A are identical, then det A = 0.
(f ) det AT = det A.
(g) If rank A < n, then det A = 0.
Proof. Part (a) is part of the deﬁnition of multilinearity, and (d) follows
immediately from (a). To prove (b), suppose p < q and let τ ∈Sn be
the transposition that interchanges p and q, leaving all other indices ﬁxed.
Then the left-hand side of (A.3) is equal to
det(A1, . . . , Aq, . . . , Ap, . . . , An) =
X
σ∈Sn
(sgn σ)Aσ1
1 · · · Aσp
q · · · Aσq
p · · · Aσn
n
=
X
σ∈Sn
(sgn σ)Aσ1
1 · · · Aσq
p · · · Aσp
q · · · Aσn
n
=
X
σ∈Sn
(sgn σ)Aστ1
1
· · · Aστn
n
= −
X
σ∈Sn
(sgn(στ))Aστ1
1
· · · Aστn
n
= −
X
η∈Sn
(sgn η)Aη1
1 · · · Aηn
n
= −det(A1, . . . , An),
where the next-to-last line follows by substituting η = στ and noting that
η runs over all elements of Sn as σ does. Part (e) is then an immediate
consequence of (b), and (c) follows by multilinearity:
det(A1, . . . , Ai, . . . , Aj + cAi, . . . , An)
= det(A1, . . . , Ai, . . . , Aj . . . , An) + c det(A1, . . . , Ai, . . . , Ai . . . , An)
= det(A1, . . . , Ai, . . . , Aj . . . , An) + 0.

Linear Algebra
417
Part (f) follows directly from the deﬁnition of the determinant:
det AT =
X
σ∈Sn
(sgn σ)A1
σ1 · · · An
σn
=
X
σ∈Sn
(sgn σ)Aσ−1σ1
σ1
· · · Aσ−1σn
σn
=
X
σ∈Sn
(sgn σ)Aσ−11
1
· · · Aσ−1n
n
(multiplication is commutative)
=
X
η∈Sn
(sgn η)Aη1
1 · · · Aηn
n
(substituting η = σ−1)
= det A.
Finally, to prove (g), suppose rank A < n. Then the columns of A are
dependent, so at least one column can be written as a linear combination of
the others: Aj = P
i̸=j ciAi. The result then follows from the multilinearity
of det and (e).
The operations on matrices described in parts (a), (b), and (c) of the
preceding proposition (multiplying one column by a scalar, interchanging
two columns, and adding a multiple of one column to another) are called
elementary column operations. Part of the proposition, therefore, describes
precisely how a determinant is aﬀected by elementary column operations.
If we deﬁne elementary row operations analogously, the fact that the deter-
minant of AT is equal to that of A implies that the determinant behaves
similarly under elementary row operations.
Each elementary column operation on a matrix A can be realized by mul-
tiplying A on the right by a suitable matrix, called an elementary matrix.
For example, multiplying the ith column by c is achieved by multiplying A
by the matrix Ec that is equal to the identity matrix except for a c in the
(i, i) position:








A1
1
. . .
A1
i
. . .
A1
n
...
...
...
Aj
1
. . .
Aj
i
. . .
Aj
n
...
...
...
An
1
. . .
An
i
. . .
An
n
















1
. . .
0
. . .
0
...
c
...
0
. . .
0
. . .
1








=








A1
1
. . .
cA1
i
. . .
A1
n
...
...
...
Aj
1
. . .
cAj
i
. . .
Aj
n
...
...
...
An
1
. . .
cAn
i
. . .
An
n








.

418
Appendix: Review of Prerequisites
Observe that det Ec = c.
Exercise A.13.
Show that interchanging two columns of a matrix is
equivalent to multiplying on the right by a matrix whose determinant is
−1, and adding a multiple of one column to another is equivalent to multi-
plying on the right by a matrix of determinant 1.
Exercise A.14.
Suppose A is a nonsingular n × n matrix.
(a)
Show that A can be reduced to the identity In by a sequence of ele-
mentary column operations.
(b)
Show that A is equal to a product of elementary matrices.
Elementary matrices form a key ingredient in the proof of the following
theorem, which is arguably the deepest and most important property of
the determinant.
Theorem A.10. If A and B are n × n matrices, then
det(AB) = (det A)(det B).
Proof. If B is singular, then rank B < n, which implies that rank AB <
n. Therefore both det B and det AB are zero by Proposition A.9(g). On
the other hand, parts (a), (b), and (c) of Proposition A.9 combined with
Exercise A.13 show that the theorem is true when B is an elementary
matrix. If B is an arbitrary nonsingular matrix, then B can be written as
a product of elementary matrices by Exercise A.14, and then the result
follows by induction.
Corollary A.11. If A is a nonsingular n × n matrix, then det(A−1) =
(det A)−1.
Proof. Just note that 1 = det In = det(AA−1) = (det A)(det A−1).
Corollary A.12. A square matrix is nonsingular if and only if its deter-
minant is nonzero.
Proof. One direction follows from Proposition A.9(g); the other from Corol-
lary A.11.
For actual computations of determinants, the formula in the following
proposition is usually more useful than the deﬁnition.
Proposition A.13 (Expansion by Minors). Let A be an n×n matrix,
and for each i, j let M j
i denote the (n−1)×(n−1) minor obtained by deleting
the ith column and jth row of A. For any ﬁxed i between 1 and n inclusive,
det A =
n
X
j=1
(−1)i+jAj
i det M j
i .
(A.4)

Linear Algebra
419
Proof. It is useful to consider ﬁrst a special case: Suppose A is an n × n
matrix that has the block form
A =
B
0
C
1

,
(A.5)
where B is an (n −1) × (n −1) matrix and C is a 1 × n row matrix.
Then in the deﬁning formula (A.2) for det A, the factor Aσn
n
is equal to
1 when σn = n and zero otherwise, so in fact the only terms that are
nonzero are those in which σ ∈Sn−1, thought of as the subgroup of Sn
consisting of elements that permute {1, . . ., n −1} and leave n ﬁxed. Thus
the determinant of A simpliﬁes to
det A =
X
σ∈Sn−1
(sgn σ)Aσ1
1 · · · Aσ(n−1)
n−1
= det B.
Now let A be arbitrary, and ﬁx i between 1 and n. For each j = 1, . . . , n,
let Xj
i denote the matrix obtained by replacing the ith column of A by
the basis vector ej. Since the determinant is a multilinear function of its
columns,
det A = det

A1, . . . , Ai−1,
n
X
j=1
Aj
iej, Ai+1, . . . , An


=
n
X
j=1
Aj
i det(A1, . . . , Ai−1, ej, Ai+1, . . . , An)
=
n
X
j=1
Aj
i det Xj
i .
(A.6)
On the other hand, by interchanging columns n −i times and then in-
terchanging rows n −j times, we can transform Xj
i to a matrix of the
form (A.5) with B = M j
i . Therefore, by the observation in the preceding
paragraph,
det Xj
i = (−1)n−i+n−j det M j
i = (−1)i+j det M j
i .
Inserting this into (A.6) completes the proof.
Formula (A.4) is called the expansion of det A by minors along the ith
column. Since det A = det AT , there is an analogous expansion along any
row. The factor (−1)i+j det M j
i multiplying Aj
i in (A.4) is called the cofac-
tor of Aj
i, and is denoted by cof j
i.
Proposition A.14 (Cramer’s Rule). Let A be a nonsingular n×n ma-
trix. Then A−1 is equal to 1/(det A) times the transposed cofactor matrix
of A:
(A−1)i
j =
1
det Acof j
i =
1
det A(−1)i+j det M j
i .
(A.7)

420
Appendix: Review of Prerequisites
Proof. Let Bi
j denote the expression on the right-hand side of (A.7). Then
n
X
j=1
Bi
jAj
k =
1
det A
n
X
j=1
(−1)i+jAj
k det M j
i .
(A.8)
When k = i, the summation on the right-hand side is precisely the expan-
sion of det A by minors along the ith column, so the right-hand side of
(A.8) is equal to 1. On the other hand, if k ̸= i, the summation is equal to
the determinant of the matrix obtained by replacing the ith column of A
by the kth column. Since this matrix has two identical columns, its deter-
minant is zero. Thus (A.8) is equivalent to the matrix equation BA = In,
where B is the matrix (Bj
i ). Multiplying both sides on the right by A−1,
we conclude that B = A−1.
A square matrix A = (Aj
i) is said to be upper triangular if Aj
i = 0 for
j > i (i.e., the only nonzero entries are on and above the main diago-
nal). Determinants of upper triangular matrices are particularly easy to
compute.
Proposition A.15 (Determinant of an Upper Triangular Matrix).
If A is an upper triangular n × n matrix, then the determinant of A is the
product of its diagonal entries:
det A = A1
1 · · · An
n.
Proof. When n = 1, this is trivial. So assume the result is true for (n −
1) × (n −1) matrices, and let A be an upper triangular n × n matrix. In
the expansion of det A by minors along the ﬁrst column, there is only one
nonzero entry, namely A1
1 det M 1
1 . By induction det M 1
1 = A2
2 · · · An
n, which
proves the proposition.
Suppose X is an (m + k) × (m + k) matrix. We say X is block upper
triangular if X has the form
X =

A
B
0
C

(A.9)
for some matrices A, B, C of sizes m × m, m × k, and k × k, respectively.
Proposition A.16. If X is the block upper triangular matrix given by
(A.9), then det X = (det A)(det C).
Proof. If A is singular, then clearly the columns of X are linearly depen-
dent, which implies that det X = 0 = (det A)(det C). So let us assume that
A is nonsingular.
Consider ﬁrst the following special case:
X =
Im
0
0
C

.

Linear Algebra
421
Expanding by minors along the ﬁrst column, an easy induction shows that
det X = det C in this case. A similar argument shows that
det

A
0
0
Ik

= det A.
The general case follows from these two observations together with the
factorization
A
B
0
C

=
A
0
0
Ik
 Im
0
0
C
 Im
A−1B
0
Ik

,
noting that the last matrix above is upper triangular with ones along the
main diagonal.
Inner Products and Norms
If V is a real vector space, an inner product on V is a map from V ×V →V ,
usually written (X, Y ) 7→⟨X, Y ⟩, that is
(i) Symmetric:
⟨X, Y ⟩= ⟨Y, X⟩.
(ii) Bilinear:
⟨aX + a′X′, Y ⟩= a⟨X, Y ⟩+ a′⟨X′, Y ⟩,
⟨X, bY + b′Y ′⟩= b⟨X, Y ⟩+ b′⟨X, Y ′⟩.
(iii) Positive definite:
⟨X, X⟩> 0 unless X = 0.
A vector space endowed with a speciﬁc inner product is called an inner
product space. The standard example is, of course, Rn with its dot product
or Euclidean inner product:
⟨x, y⟩= x · y =
n
X
i=1
xiyi.
Suppose V is an inner product space. For any X ∈V , the length of X
is the number |X| =
p
⟨X, X⟩. A unit vector is a vector of length 1. The
angle between two nonzero vectors X, Y ∈V is deﬁned to be the unique
θ ∈[0, π] satisfying
cos θ = ⟨X, Y ⟩
|X| |Y |.
Two vectors X, Y ∈V are said to be orthogonal if the angle between them
is π/2, or equivalently if ⟨X, Y ⟩= 0.

422
Appendix: Review of Prerequisites
Exercise A.15.
Let V be an inner product space. Show that the length
function associated with the inner product satisﬁes
|X| > 0,
X ∈V, X ̸= 0;
|cX| = |c| |X|,
c ∈R, X ∈V ;
|X + Y | ≤|X| + |Y |,
X, Y ∈V.
Suppose V
is a ﬁnite-dimensional inner product space. A basis
(E1, . . . , En) of V is said to be orthonormal if each Ei is a unit vector
and Ei is orthogonal to Ej when i ̸= j.
Proposition A.17 (The Gram-Schmidt Algorithm).
Every ﬁnite-
dimensional inner product space V has an orthonormal basis. In fact, if
(E1, . . . , En) is any basis of V , there is an orthonormal basis ( eE1, . . . , eEn)
with the property that
span(E1, . . . , Ek) = span( eE1, . . . , eEk) for k = 1, . . . , n.
(A.10)
Proof. The proof is by induction on n = dim V . If n = 1, there is only one
basis element E1, and then eE1 = E1/|E1| is an orthonormal basis.
Suppose the result is true for inner product spaces of dimension n −1,
and let V have dimension n. Then W = span(E1, . . . , En−1) is an (n −1)-
dimensional inner product space with the inner product restricted from
V , so there is an orthonormal basis ( eE1, . . . , eEn−1) satisfying (A.10) for
k = 1, . . . , n −1. Deﬁne eEn by
eEn = En −Pn−1
i=1 ⟨En, eEi⟩eEi
En −Pn−1
i=1 ⟨En, eEi⟩eEi

.
A computation shows that ( eE1, . . . , eEn) is the desired orthonormal basis.
An isomorphism T : V →W between inner product spaces is called an
isometry if it takes the inner product of V to that of W:
⟨TX, TY ⟩= ⟨X, Y ⟩.
Exercise A.16.
Show that any isometry is a homeomorphism that pre-
serves lengths, angles, and orthogonality, and takes orthonormal bases to
orthonormal bases.
Exercise A.17.
If (Ei) is any basis for the ﬁnite-dimensional vector space
V , show that there is a unique inner product on V for which (Ei) is ortho-
normal.
Exercise A.18.
Suppose V is a ﬁnite-dimensional inner product space
and E : Rn →V is the basis map determined by any orthonormal basis.
Show that E is an isometry, where Rn is endowed with the Euclidean inner
product.

Linear Algebra
423
The preceding exercise shows that ﬁnite-dimensional inner product
spaces are topologically and geometrically indistinguishable from the
Euclidean space of the same dimension. Thus any such space automatically
inherits all the usual properties of Euclidean space, such as compactness of
closed and bounded subsets.
If V is a ﬁnite-dimensional inner product space and S ⊂V is a subspace,
the orthogonal complement of S in V is the set
V ⊥= {X ∈V : ⟨X, Y ⟩= 0 for all Y ∈S.}.
Exercise A.19.
Let V be a ﬁnite-dimensional inner product space and
S ⊂V any subspace. Show that V = S ⊕S⊥.
Thanks to the result of the preceding exercise, for any subspace S of an
inner product space V , there is a natural projection π: V →S with kernel
S⊥. This is called the orthogonal projection of V onto S.
A norm on a vector space V is a function from V to R, written X 7→|X|,
satisfying
(i) Positivity: |X| ≥0 for every X ∈V , and |X| = 0 if and only if
X = 0.
(ii) Homogeneity: |cX| = |c| |X| for every c ∈R and X ∈V .
(iii) Triangle inequality: |X + Y | ≤|X| + |Y | for all X, Y ∈V .
A vector space together with a speciﬁc choice of norm is called a normed
linear space. Exercise A.15 shows that the length function associated with
any inner product is a norm.
If V is a normed linear space, then for any p ∈V and any r > 0 we
deﬁne the open ball and closed ball of radius r around p, denoted by Br(p)
and Br(p), respectively, by
Br(p) = {x ∈V : |x −p| < r},
Br(p) = {x ∈V : |x −p| ≤r}.
Given a norm on V , the function d(X, Y ) = |X −Y | is a metric, yielding
a topology on V called the norm topology. The set of all open balls is easily
seen to be a basis for this topology. Two norms | · |1 and | · |2 are said to
be equivalent if there are positive constants c, C such that
c|X|1 ≤|X|2 ≤C|X|1 for all X ∈V .
Exercise A.20.
Show that equivalent norms on a vector space V deter-
mine the same topology.
Exercise A.21.
Show that any two norms on a ﬁnite-dimensional vector
space are equivalent. [Hint: ﬁrst choose an inner product on V , and show
that the unit ball in any norm is compact with respect to the topology
determined by the inner product.]

424
Appendix: Review of Prerequisites
If V and W are normed linear spaces, a linear map T : V →W is said
to be bounded if there exists a positive constant C such that
|TX| ≤C|X| for all X ∈V .
Exercise A.22.
Show that a linear map between normed linear spaces is
bounded if and only if it is continuous.
Exercise A.23.
Show that every linear map between ﬁnite-dimensional
normed linear spaces is continuous.
The vector space M(m × n, R) of m × n real matrices has a natural
Euclidean inner product, obtained by identifying a matrix with a point in
Rmn:
A· B =
X
i,j
Ai
jBi
j.
This yields a Euclidean norm on matrices:
|A| =
qP
i,j(Aj
i)2.
(A.11)
Whenever we use a norm on a space of matrices, it will always be assumed
to be this Euclidean norm.
Exercise A.24.
For any matrices A ∈M(m × n, R) and B ∈M(n × k, R),
show that
|AB| ≤|A| |B|.
Calculus
In this section, we summarize the main results from multivariable calculus
and real analysis that are needed in this book. For details on most of the
ideas touched on here, you can consult [Rud76] or [Apo74].
If U ⊂Rn is any subset and F : U →Rm is any map, we write the
components of F(x) as F(x) = (F 1(x), . . . , F m(x)); this deﬁnes n functions
F 1, . . . , F n : U →R called the component functions of F. Note that F i =
πi ◦F, where πi : Rm →R is the projection on the ith coordinate:
πi(x1, . . . , xn) = xi.
For maps between Euclidean spaces, there are two separate but closely
related types of derivatives: partial derivatives and total derivatives. We
begin with partial derivatives.

Calculus
425
Partial Derivatives
Suppose U ⊂Rn is open and f : U →R is any real-valued function. For
any a = (a1, . . . , an) ∈U and any j = 1, . . . , n, the jth partial derivative
of f at a is deﬁned by diﬀerentiating with respect to xj and holding the
other variables ﬁxed:
∂f
∂xj (a) = lim
h→0
f(a1, . . . , aj + h, . . . , an)
h
= lim
h→0
f(a + hej)
h
,
if the limit exists. For a vector-valued function F : U →Rm, the partial
derivatives of F are deﬁned simply to be the partial derivatives ∂F i/∂xj of
the component functions of F. The matrix (∂F i/∂xj) of partial derivatives
is called the Jacobian matrix of F.
If F : U →Rm is a map for which each partial derivative exists at each
point in U and the functions ∂F i/∂xj : U →R so deﬁned are all continuous,
then F is said to be of class C1 or continuously diﬀerentiable. If this is the
case, we can diﬀerentiate the functions ∂F i/∂xj to obtain second-order
partial derivatives
∂2F i
∂xk∂xj =
∂
∂xk
∂F i
∂xj

,
if they exist. Continuing this way leads to higher-order partial derivatives—
the partial derivatives of F of order k are the partial derivatives of those
of order k −1, when they exist.
In general, for k ≥0, a function F : U →Rm is said to be of class
Ck or k times continuously diﬀerentiable if all the partial derivatives of
F of order less than or equal to k exist and are continuous functions on
U. (Thus a function of class C0 is just a continuous function.) A function
that is of class Ck for every k ≥0 is said to be of class C∞, smooth, or
inﬁnitely diﬀerentiable. Because existence and continuity of derivatives are
local properties, clearly F is C1 (or Ck or smooth) if and only if it has that
property in a neighborhood of each point in U.
We will often be most concerned with real-valued functions, that is, func-
tions whose range is R. If U ⊂Rn is open, the set of all real-valued functions
of class Ck on U is denoted by Ck(U), and the set of all smooth real-valued
functions by C∞(U). By virtue of the following exercise, C∞(U) is a vector
space under pointwise addition and multiplication by constants:
(f + g)(x) = f(x) + g(x)
(cf)(x) = c(f(x)).
In fact, it is also a ring, with multiplication deﬁned pointwise:
(fg)(x) = f(x)g(x).

426
Appendix: Review of Prerequisites
Exercise A.25.
Let U ⊂Rn be an open set, and suppose f, g : U →Rn
are smooth.
(a)
Show that f + g is smooth.
(b)
Show that fg is smooth.
(c)
If g never vanishes on U, show that f/g is smooth.
The following important result shows that, for most interesting maps,
the order in which we take partial derivatives is irrelevant. For a proof, see
[Rud76].
Proposition A.18 (Equality of Mixed Partial Derivatives).
If U
is an open subset of Rn and F : U →Rm is a map of class C2, then
the mixed second-order partial derivatives of F do not depend on the order
of diﬀerentiation:
∂2F i
∂xj∂xk =
∂2F i
∂xk∂xj .
Corollary A.19. If F : U →Rm is smooth, then mixed partial derivatives
of any order are independent of the order of diﬀerentiation.
Another important property of smooth functions is that integrals of
smooth functions can be diﬀerentiated under the integral sign. A precise
statement is given in the next theorem; this is not the best that can be
proved, but it is more than suﬃcient for our purposes. For a proof, see
[Rud76].
Theorem A.20 (Diﬀerentiation Under an Integral Sign). Let U ⊂
Rn be an open set, a, b ∈R, and let f : U × [a, b] →R be a continuous
function such that the partial derivative ∂f/∂t: U × [a, b] →R is also
continuous. Deﬁne F : U →R by
F(x) =
Z b
a
f(x, t) dt.
Then F is of class C1, and its partial derivatives can be computed by dif-
ferentiating under the integral sign:
∂F
∂xi (x) =
Z b
a
∂f
∂xi (x, t) dt.
Theorem A.21 (Taylor’s Formula with Remainder).
Let U ⊂Rn
be a convex open set, and suppose f is a smooth real-valued function on
U. For any integer m ≥0, any a ∈U, and all v ∈Rn small enough that

Calculus
427
a + v ∈U,
f(a + v) =
m
X
k=0
X
i1,...,ik
1
k!
∂kf
∂xi1 · · · ∂xik (a)vi1 · · · vik
+
X
i1,...,im+1
Z 1
0
1
m!(1 −t)m
∂m+1f
∂xi1 · · · ∂xim+1 (a + tv)vi1 · · · vim+1 dt,
(A.12)
where each index ij runs from 1 to n.
Proof. The proof is by induction on m. When m = 0, it follows from the
fundamental theorem of calculus and the chain rule:
f(a + v) −f(a) =
Z 1
0
∂
∂tf(a + tv) dt =
n
X
i=1
Z 1
0
∂f
∂xi (a + tv)vi dt.
So suppose the formula holds for some m ≥0. To prove it for m + 1, we
integrate by parts in (A.12), with
u =
X
i1,...,im+1
∂m+1f
∂xi1 · · · ∂xim+1 (a + tv)vi1 · · · vim+1,
du =
X
i1,...,im+2
∂m+2f
∂xi1 · · · ∂xim+2 (a + tv)vi1 · · · vim+2 dt,
v = −
1
(m + 1)!(1 −t)m+1,
dv = 1
m!(1 −t)m dt,
to obtain
X
i1,...,im+1
Z 1
0
1
m!(1 −t)m
∂m+1f
∂xi1 · · · ∂xim+1 (a + tv)vi1 · · · vim+1 dt
=

−
1
(m + 1)!(1 −t)m+1
X
i1,...,im+1
∂m+1f
∂xi1 · · · ∂xim+1 (a + tv)vi1 · · · vim+1


t=1
t=0
+
Z 1
0
1
(m + 1)!(1 −t)m+1
X
i1,...,im+2
∂m+2f
∂xi1 · · · ∂xim+2 (a + tv)vi1 · · · vim+2dt
=
X
i1,...,im+1
1
(m + 1)!
∂m+1f
∂xi1 · · · ∂xim+1 (a)vi1 · · · vim+1
+
X
i1,...,im+2
Z 1
0
1
(m + 1)!(1 −t)m+1
∂m+2f
∂xi1 · · · ∂xim+2 (a + tv)vi1 · · · vim+2dt.
Inserting this into (A.12) completes the proof.

428
Appendix: Review of Prerequisites
Corollary A.22 (First-Order Taylor Formula).
With f, a, and v as
above,
f(a + v) = f(a) +
n
X
i=1
∂f
∂xi (a)vi +
n
X
i=1
gi(v)vi,
for some smooth functions g1, . . . , gn deﬁned on U.
The notation O(|x|k) is used to denote any function G(x) deﬁned on a
neighborhood of the origin in Rn which satisﬁes |G(x)| ≤C|x|k for some
constant C and all suﬃciently small x.
Corollary A.23 (Second-Order Taylor Formula).
With f, a, and v
as above,
f(a + v) = f(a) +
n
X
i=1
∂f
∂xi (a)vi + 1
2
n
X
i,j=1
∂2f
∂xi∂xj (a)vivj + O(|v|3).
Exercise A.26.
Prove the previous two corollaries.
We will sometimes need to consider smooth maps on subsets of Rn that
are not open. If A ⊂Rn is any subset, a map F : A →Rm is said to be
smooth if it extends to a smooth map U →Rk on some open neighborhood
U of A.
The Total Derivative
For maps between (open subsets of) ﬁnite-dimensional vector spaces, there
is another very important notion of derivative, called the total derivative.
Let V, W be ﬁnite-dimensional vector spaces, which we may assume to
be endowed with norms. If U ⊂V is an open set, a map F : U →W is said
to be diﬀerentiable at a ∈U if there exists a linear map L: V →W such
that
lim
v→0
F(a + v) −F(a) −Lv
|v|
= 0.
(A.13)
Because all norms on a ﬁnite-dimensional vector space are equivalent, this
deﬁnition is independent of the choices of norms on V and W.
Exercise A.27.
Suppose F : U →W is diﬀerentiable. Show that the lin-
ear map L satisfying (A.13) is unique.
If F is diﬀerentiable at a, the linear map L satisfying (A.13) is denoted
by DF(a) and is called the total derivative of F at a. Condition (A.13) can
also be written
F(a + v) = F(a) + DF(a)v + R(v),
(A.14)

Calculus
429
where the remainder term R(v) satisﬁes R(v)/|v| →0 as v →0. One
thing that makes the total derivative so powerful is that it makes sense
for arbitrary ﬁnite-dimensional vector spaces, without the need to choose
a basis or even a norm.
Exercise A.28.
Suppose V, W are ﬁnite-dimensional vector spaces; U ⊂
V is an open set; a ∈U; F, G: U →W ; and f, g : U →R.
(a)
If F is diﬀerentiable at a, show that F is continuous at a.
(b)
If F and G are diﬀerentiable at a, show that F + G is also, and
D(F + G)(a) = DF(a) + DG(a).
(c)
If f and g are diﬀerentiable at a ∈U, show that fg is also, and
D(fg)(a) = f(a)Dg(a) + g(a)Df(a).
(d)
If f is diﬀerentiable at a and f(a) ̸= 0, show that 1/f is diﬀerentiable
at a, and
D(1/f)(a) = −(1/f(a)2)Df(a).
Proposition A.24 (The Chain Rule for Total Derivatives).
Sup-
pose V, W, X are ﬁnite-dimensional vector spaces, U ⊂V and eU ⊂W are
open sets, and F : U →eU and G: eU →X are maps. If F is diﬀerentiable
at a ∈U and G is diﬀerentiable at F(a) ∈eU, then G ◦F is diﬀerentiable
at a, and
D(G ◦F)(a) = DG(F(a)) ◦DF(a).
Proof. Let A = DF(a) and B = DG(F(a)). We need to show that
lim
v→0
G ◦F(a + v) −G ◦F(a) −BAv
|v|
= 0.
(A.15)
We can rewrite the quotient in (A.15) as
G(F(a + v)) −G(F(a)) −B(F(a + v) −F(a))
|v|
+ B
F(a + v) −F(a) −Av
|v|

.
(A.16)
As v →0, F(a + v) −F(a) →0 by continuity of F. Therefore the diﬀeren-
tiability of G at F(a) implies that, for any ε > 0, we can make
|G(F(a + v)) −G(F(a)) −B(F(a + v) −F(a))| ≤ε|F(a + v) −F(a)|

430
Appendix: Review of Prerequisites
as long as |v| lies in a small enough neighborhood of 0. Thus for |v| small
(A.16) is bounded by
ε|F(a + v) −F(a)|
|v|
+
B
F(a + v) −F(a) −Av
|v|
 .
(A.17)
Restricting |v| to an even smaller neighborhood of 0, we can ensure that
|F(a + v) −F(a) −Av| ≤ε|v|,
because of the diﬀerentiability of F at a. Since the linear map B is contin-
uous, it follows that (A.17) can be made as small as desired by choosing
|v| small enough, thus completing the proof.
Now let us specialize to the case of maps between Euclidean spaces.
Suppose U ⊂Rn is open and F : U →Rm is diﬀerentiable at a ∈U.
As a linear map between Euclidean spaces Rn and Rm, DF(a) can be
identiﬁed with an m × n matrix. The next lemma identiﬁes that matrix as
the Jacobian of F.
Lemma A.25. Let U ⊂Rn be open, and suppose F : U →Rm is diﬀer-
entiable at a ∈U. Then all of the partial derivatives of F at a exist, and
DF(a) is the linear map whose matrix is the Jacobian of F at a:
DF(a) =
∂F j
∂xi (a)

.
Proof. Let B = DF(a). Applying the deﬁnition of diﬀerentiability with
v = tei, we obtain
0 = lim
t→0
F j(a + tei) −F j(a) −tBj
i
|t|
.
Considering t > 0 and t < 0 separately, we ﬁnd
0 = lim
t↘0
F j(a + tei) −F j(a) −tBj
i
t
= lim
t↘0
F j(a + tei) −F j(a)
t
−Bj
i .
0 = −lim
t↗0
F j(a + tei) −F j(a) −tBj
i
t
= −

lim
t↗0
F j(a + tei) −F j(a)
t
−Bj
i

.
Combining these results, we obtain ∂F j/∂xi(a) = Bj
i as claimed.

Calculus
431
Exercise A.29.
Suppose U ⊂Rn is open. Show that a map F : U →Rm
is diﬀerentiable at a ∈U if and only if each of its component functions
F 1, . . . , F m is diﬀerentiable at a, and
DF(a) =
0
B
@
DF 1(a)
...
DF m(a)
1
C
A .
The next proposition gives the most important suﬃcient condition for
diﬀerentiability; in particular, it shows that all of the usual functions of
elementary calculus are diﬀerentiable. For a proof, see [Rud76].
Proposition A.26. Let U ⊂Rn be open. If F : U →Rm is of class C1,
then it is diﬀerentiable at each point of U.
Exercise A.30.
If T : Rn →Rm is a linear map, show that T is diﬀeren-
tiable at each a ∈Rn, with DT(a) = T.
In the case of maps between Euclidean spaces, the chain rule can be
rephrased in terms of partial derivatives.
Corollary A.27 (The Chain Rule for Partial Derivatives).
Let
U ⊂Rn and eU ⊂Rm be open sets, and let x = (x1, . . . , xn) denote the
coordinates on U and y = (y1, . . . , ym) those on eU.
(a) Any composition of C1 functions F : U →eU and G: eU →Rp is again
of class C1, with partial derivatives given by
∂(Gi ◦F)
∂xj
(x) =
m
X
k=1
∂Gi
∂yk (F(x))∂F k
∂xj (x).
(b) If F and G are smooth, then G ◦F is smooth.
Exercise A.31.
Prove Corollary A.27.
From the chain rule and induction one can derive formulas for the higher
partial derivatives of a composite map as needed, provided the maps in
question are suﬃciently diﬀerentiable.
Now suppose f : U →R is a smooth real-valued function on an open
set U ⊂Rn, and a ∈U. For any vector v ∈Rn, we deﬁne the directional
derivative of f in the direction v at a to be the number
Dvf(a) = d
dt

t=0
f(a + tv).
(A.18)
(This deﬁnition makes sense for any vector v; we do not require v to be a
unit vector as one sometimes does in elementary calculus.)

432
Appendix: Review of Prerequisites
Since Dvf(a) is the ordinary derivative of the composite map t 7→a +
tv 7→f(a + tv), by the chain rule the directional derivative can be written
more concretely as
Dvf(a) =
n
X
i=1
vi ∂f
∂xi (a) = Df(a)v.
The next result gives an important estimate for the local behavior of a
C1 function in terms of its derivative. If U ⊂Rn is any subset, a function
F : U →Rm is said to be Lipschitz continuous on U if there is a constant
C such that
|F(x) −F(y)| ≤C|x −y|
for all x, y ∈U.
(A.19)
Any such C is called a Lipschitz constant for F.
Proposition A.28 (Lipschitz Estimate for C1 Functions).
Let
U ⊂Rn be an open set, and let F : U →Rm be of class C1. Then F is
Lipschitz continuous on any closed ball B ⊂U, with Lipschitz constant
M = supa∈B |DF(a)| (where the norm on DF(a) is the Euclidean norm
(A.11) for matrices).
Proof. Let a, b ∈B be arbitrary, and deﬁne v = b−a and G(t) = F(a+tv).
Because B is convex, G is deﬁned and of class C1 for t ∈[0, 1]. The mean-
value theorem of one-variable calculus implies
G(1) −G(0) = G′(t0)(1 −0) = G′(t0)
for some t0 ∈[0, 1]. Using the deﬁnition of G, the chain rule, and Exercise
A.24, this yields
|F(b) −F(a)| = |DF(a + t0v)v|
≤|DF(a + t0v)||v|
≤M|b −a|,
which was to be proved.
Multiple Integrals
In this section, we give a brief review of some basic facts regarding multiple
integrals in Rn. For our purposes, the Riemann integral will be more than
suﬃcient. Readers who are familiar with the theory of Lebesgue integration
are free to interpret all of our integrals in the Lebesgue sense, because the
two integrals are equal for the types of functions we will consider. For
more details on the aspects of integration theory described here, you can
consult nearly any text that treats multivariable calculus rigorously, such
as [Apo74, Fle77, Mun91, Rud76, Spi65].

Calculus
433
A rectangle in Rn (also called a closed rectangle) is a product set of
the form [a1, b1] × · · · × [an, bn], for real numbers ai < bi. Analogously,
an open rectangle is the interior of a closed rectangle, a set of the form
(a1, b1)×· · ·×(an, bn). The volume of a rectangle A of either type, denoted
by Vol(A), is deﬁned to be the product of the lengths of its component
intervals:
Vol(A) = (b1 −a1) · · · (bn −an).
A rectangle is called a cube if all of its side lengths |bi −ai| are equal.
A partition of a closed interval [a, b] is a ﬁnite set P = {a0, . . . , ak}
of real numbers such that a = a0 < a1 < · · · < ak = b. Each of the
intervals [ai−1, ai] for i = 1, . . . , k is called a subinterval of the partition.
Similarly, a partition P of a rectangle A = [a1, b1] × · · · × [an, bn] is an n-
tuple (P1, . . . , Pn), where each Pi is a partition of [ai, bi]. Each rectangle of
the form I1×· · ·×In, where Ij is a subinterval of Pj, is called a subrectangle
of P. Clearly A is the union of all the subrectangles in any partition, and
distinct subrectangles overlap only on their boundaries.
Suppose A ⊂Rn is a closed rectangle and f : A →R is a bounded
function. For any partition P of A, we deﬁne the lower sum of f with
respect to P by
L(f, P) =
X
j
(inf
Rj f) Vol(Rj),
where the sum is over all the subrectangles Rj of P. Similarly, the upper
sum is
U(f, P) =
X
j
(sup
Rj
f) Vol(Rj).
The lower sum with respect to P is obviously less than or equal to the
upper sum with respect to the same partition. In fact, more is true.
Lemma A.29. Let A ⊂Rn be a rectangle, and let f : A →R be a bounded
function. For any pair of partitions P and P ′ of A,
L(f, P) ≤U(f, P ′).
Proof. Write P = (P1, . . . , Pn) and P ′ = (P ′
1, . . . , P ′
n), and let Q be the
partition Q = (P1 ∪P ′
1, . . . , Pn ∪P ′
n). Each subrectangle of P or P ′ is a
union of ﬁnitely many subrectangles of Q. An easy computation shows
L(f, P) ≤L(f, Q) ≤U(f, Q) ≤U(f, P ′),
from which the result follows.

434
Appendix: Review of Prerequisites
The lower integral of f over A is
Z
A
f dV = sup{L(f, P) : P is a partition of A},
and the upper integral is
Z
A
f dV = inf{U(f, P) : P is a partition of A}.
Clearly both numbers exist because f is bounded, and Lemma A.29 implies
that the lower integral is less than or equal to the upper integral.
If the upper and lower integrals of f are equal, we say that f is (Riemann)
integrable, and their common value, denoted by
Z
A
f dV,
is called the integral of f over A. The “dV ” in this notation, like the “dx”
in the notation for single integrals, does not have any meaning in and of
itself; it is just a “closing bracket” for the integral sign. Other notations in
common use are
Z
A
f
or
Z
A
f dx1 · · · dxn
or
Z
A
f(x1, . . . , xn) dx1 · · · dxn.
In R2, the symbol dV is often replaced by dA.
There is a simple criterion for a bounded function to be Riemann inte-
grable. It is based on the following notion. A subset A ⊂Rn is said to have
measure zero if for any δ > 0, there exists a countable cover of A by open
cubes {Ci} such that P
i Vol(Ci) < δ. (For those who are familiar with the
theory of Lebesgue measure, this is equivalent to the condition that the
Lebesgue measure of A is equal to zero.)
Lemma A.30 (Properties of Measure Zero Sets).
(a) A countable union of sets of measure zero in Rn has measure zero.
(b) Any subset of a set of measure zero in Rn has measure zero.
(c) A set of measure zero in Rn can contain no open set.
(d) Any proper aﬃne subspace of Rn has measure zero in Rn.
Exercise A.32.
Prove Lemma A.30.
Part (d) of this lemma illustrates that having measure zero is a property
of a set in relation to a particular Euclidean space containing it, not of a
set in and of itself—for example, an open interval in the x-axis has measure

Calculus
435
zero as a subset of R2, but not when considered as a subset of R1. For this
reason, we sometimes say a subset of Rn has n-dimensional measure zero
if we wish to emphasize that it has measure zero as a subset of Rn.
The following proposition gives a suﬃcient condition for a function to be
integrable. It shows, in particular, that every bounded continuous function
is integrable.
Proposition A.31 (Lebesgue’s Integrability Criterion).
Let A ⊂
Rn be a rectangle, and let f : A →R be a bounded function. If the set
S = {x ∈A : f is not continuous at x}
has measure zero, then f is integrable.
Proof. Let ε > 0 be given. By deﬁnition of measure zero sets, S can be
covered by a countable collection of open cubes {Ci} with total volume
less than ε.
For each point q ∈A ∖S, since f is continuous at q, there is a cube Dq
centered at q such that |f(x) −f(q)| < ε for all x ∈Dq ∩A. This implies
supDq f −infDq f ≤2ε.
The collection of all open cubes of the form Int Ci or Int Dq is an open
cover of A. By compactness, ﬁnitely many of them cover A. Let us relabel
these cubes as {C1, . . . , Ck, D1, . . . , Dl}. Replacing each Ci or Dj by its
intersection with A, we may assume that each Ci and each Dj is a rectangle
contained in A.
Since there are only ﬁnitely many rectangles {Ci, Dj}, there is a partition
P with the property that each Ci or Dj is equal to a union of subrectangles
of P. (Just use the union of all the endpoints of the component intervals of
the rectangles Ci and Dj to deﬁne the partition.) We can divide the sub-
rectangles of P into two disjoint sets C and D such that every subrectangle
in C is contained in Ci for some i, and every subrectangle in D is contained
in Dj for some j. Then
U(f, P) −L(f, P)
=
X
i
(sup
Ri
f) Vol(Ri) −
X
i
(inf
Ri f) Vol(Ri)
=
X
Ri∈C
(sup
Ri
f −inf
Ri f) Vol(Ri) +
X
Ri∈D
(sup
Ri
f −inf
Ri f) Vol(Ri)
≤(sup
A
f −inf
A f)
X
Ri∈C
Vol(Ri) + 2ε
X
Ri∈D
Vol(Ri)
≤(sup
A
f −inf
A f)ε + 2ε Vol(A).
It follows that
Z
A
f dV −
Z
A
f dV ≤(sup
A
f −inf
A f)ε + 2ε Vol(A),

436
Appendix: Review of Prerequisites
which can be made as small as desired by taking ε suﬃciently small. This
implies that the upper and lower integrals of f must be equal, so f is
integrable.
Remark. In fact, the Lebesgue criterion is both necessary and suﬃcient for
Riemann integrability, but we will not need that.
Now suppose D ⊂Rn is any bounded set, and f : D →R is a bounded
function. Let A be any rectangle containing D, and deﬁne fD : A →R by
fD(x) =
(
f(x)
x ∈D,
0
x ∈A ∖D.
(A.20)
If the integral
Z
A
fD dV
(A.21)
exists, f is said to be integrable over D, and the integral (A.21) is denoted
by
R
D f dV and called the integral of f over D. It is easy to check that the
value of the integral does not depend on the rectangle chosen.
In practice, we will be interested only in integrals of bounded continuous
functions. However, since we will sometimes need to integrate them over
domains other than rectangles, it is necessary to consider also integrals of
discontinuous functions such as the function fD deﬁned by (A.20). The
main reason for proving Proposition A.31 is that it allows us to give a
simple description of domains on which all bounded continuous functions
are integrable.
A subset D ⊂Rn will be called a domain of integration if D is bounded
and ∂D has n-dimensional measure zero. It is easy to check (using Lemma
A.30) that any set whose boundary is contained in a ﬁnite union of proper
aﬃne subspaces is a domain of integration, and ﬁnite unions and inter-
sections of domains of integration are again domains of integration. Thus,
for example, any ﬁnite union of open or closed rectangles is a domain of
integration.
Proposition A.32. If D ⊂Rn is a domain of integration, then every
bounded continuous function on D is integrable over D.
Proof. Let f : D →R be bounded and continuous, and let A be a rectangle
containing D. To prove the theorem, we need only show that the function
fD : A →R deﬁned by (A.20) is continuous except on a set of measure
zero.
If x ∈Int D, then fD = f on a neighborhood of x, so fD is continous at
x. Similarly, if x ∈A ∖D, then fD ≡0 on a neighborhood of x, so again
f is continuous at x. Thus the set of points where fD is discontinuous is
contained in ∂D, and therefore has measure zero.

Calculus
437
Of course, if D is compact, then the assumption that f is bounded in
the preceding proposition is superﬂuous.
If D is a domain of integration, the volume of D is deﬁned to be
Vol(D) =
Z
D
1 dV.
The integral on the right-hand side is often abbreviated
R
D dV .
The next two propositions collect some basic facts about volume and
integrals of continuous functions.
Proposition A.33 (Properties of Volume).
Let D ⊂Rn be a domain
of integration.
(a) Vol(D) ≥0, with equality if and only if D has measure zero.
(b) If D1, . . . , Dk are domains of integration whose union is D, then
Vol(D) ≤Vol(D1) + · · · + Vol(Dk),
with equality if and only if Di ∩Dj has measure zero for each i, j.
(c) If D1 is a domain of integration contained in D, then Vol(D1) ≤
Vol(D), with equality if and only if D ∖D1 has measure zero.
Proposition A.34 (Properties of Integrals).
Let D ⊂Rn be a do-
main of integration, and let f, g: D →R be continuous and bounded.
(a) For any a, b ∈R,
Z
D
(af + bg) dV = a
Z
D
f dV + b
Z
D
g dV.
(b) If D has measure zero, then
R
D f dV = 0.
(c) If D1, . . . , Dk are domains of integration whose union is D and whose
pairwise intersections have measure zero, then
Z
D
f dV =
Z
D1
f dV + · · · +
Z
Dk
f dV.
(d) If f ≥0 on D, then
R
D f dV ≥0, with equality if and only if f ≡0
on Int D.
(e) (inf
D f) Vol(D) ≤
Z
D
f dV ≤(sup
D
f) Vol(D).
(f )

Z
D
f dV
 ≤
Z
D
|f| dV .

438
Appendix: Review of Prerequisites
Exercise A.33.
Prove Propositions A.33 and A.34.
There are two more fundamental properties of multiple integrals that we
will need. The proofs are too involved to be included in this summary, but
you can look them up in the references listed at the beginning of this section
if you are interested. Each of these theorems can be stated in various ways,
some stronger than others. The versions we give here will be quite suﬃcient
for our applications.
Theorem A.35 (Change of Variables).
Suppose D and E are com-
pact domains of integration in Rn, and G: D →E is a continuous map
such that G|Int D : Int D →Int E is a bijective C1 map with C1 inverse.
For any bounded continuous function f : E →R,
Z
E
f dV =
Z
D
(f ◦G)
det
∂Gi
∂xj
 dV.
Theorem A.36 (Evaluation by Iterated Integration).
Suppose
E ⊂Rn is a compact domain of integration and g0, g1: E →R are
continuous functions such that g0 ≤g1 everywhere on E. Let D ⊂Rn+1
be the subset
D = {(x1, . . . , xn, y) ∈Rn+1 : x ∈E and g0(x) ≤y ≤g1(x)}.
Then D is a domain of integration, and
Z
D
f dV =
Z
E
 Z g1(x)
g0(x)
f(x, y) dy
!
dV.
Of course, there is nothing special about the last variable in this formula;
an analogous result holds for any domain D that can be expressed as the
set on which one variable is bounded between two continuous functions of
the remaining variables.
If the domain E in the preceding theorem is also a region between two
graphs, the same theorem can be applied again to E. In particular, the
following formula for an integral over a rectangle follows easily by induction.
Corollary A.37. Let A = [a1, b1] × · · · × [an, bn] be a closed rectangle in
Rn, and let f : A →R be continuous. Then
Z
A
f dV =
Z bn
an
 
· · ·
 Z b1
a1 f(x1, . . . , xn) dx1
!
· · ·
!
dxn,
and the same is true if the variables in the iterated integral on the right-
hand side are reordered in any way.

Calculus
439
Sequences and Series of Functions
We conclude with a summary of the most important facts about sequences
and series of functions on Euclidean spaces.
Let S ⊂Rn be any subset, and for each integer i ≥1 suppose that
fi : S →Rm is a function on S. The sequence {fi} is said to converge
pointwise to f : S →Rm if for each a ∈S and each ε > 0, there exists an
integer N such that i ≥N implies |fi(a)−f(a)| < ε. Pointwise convergence
is denoted simply by fi →f. The sequence is said to converge uniformly
to f if N can be chosen independently of the point a: for each ε > 0 there
exists N such that i ≥N implies |fi(a) −f(a)| < ε for every a ∈U. We
will usually indicate uniform convergence by writing “fi →f uniformly.”
Theorem A.38 (Properties of Uniform Convergence).
Let S
⊂
Rn, and let fi : S →Rm for each integer i ≥1.
(a) If each fi is continuous and fi →f uniformly, then f is continuous.
(b) If each fi is continuous and fi →f uniformly, then for any closed
domain of integration D ⊂S,
lim
i→∞
Z
D
fi dV =
Z
D
f dV.
(c) If S is open, each fi is of class C1, fi →f pointwise, and the sequence
{∂fi/∂xj} converges uniformly on S as i →∞, then ∂f/∂xj exists
on S and
∂f
∂xj = lim
i→∞
∂fi
∂xj .
For a proof, see [Rud76]. An inﬁnite series of functions P∞
i=0 fi on S ⊂Rn
is said to converge pointwise to a function g if the corresponding sequence
of partial sums converges pointwise:
g(x) = lim
M→∞
M
X
i=0
fi(x) for all x ∈S.
The series is said to converge uniformly if the partial sums converge uni-
formly.
Proposition A.39 (Weierstrass M-test). Suppose S ⊂Rn is any sub-
set, and fi : S →Rk are functions. If there exist positive real numbers Mi
such that supS |fi| ≤Mi and P
i Mi converges, then P
i fi converges uni-
formly on A.
Exercise A.34.
Prove Proposition A.39.

440
Appendix: Review of Prerequisites

References
[AM78]
Ralph Abraham and Jerrold E. Marsden. Foundations of Me-
chanics.
Benjamin/Cummings, Reading, MA, second edition,
1978.
[Apo74]
Tom M. Apostol.
Mathematical Analysis.
Addison-Wesley,
Reading, Massachusetts, second edition, 1974.
[BM58]
Raoul Bott and John Milnor.
On the parallelizability of the
spheres. Bull. Amer. Math. Soc., 64:87–89, 1958.
[Bre93]
Glen E. Bredon. Topology and Geometry. Springer-Verlag, New
York, 1993.
[DK90]
S. K. Donaldson and P. B. Kronheimer. The geometry of four-
manifolds. Clarendon Press, New York, 1990.
[FIS97]
Stephen H. Friedberg, Arnold J. Insel, and Lawrence E. Spence.
Linear Algebra. Prentice Hall, Upper Saddle River, NJ, third
edition, 1997.
[Fle77]
Wendell Fleming.
Functions of Several Variables.
Springer-
Verlag, New York, second edition, 1977.
[FQ90]
Michael Freedman and Frank Quinn. Topology of 4-manifolds.
Princeton University Press, Princeton, 1990.
[Her75]
Israel N. Herstein. Topics in Algebra. Wiley, New York, second
edition, 1975.

442
References
[HL82]
Reese Harvey and H. Blaine Lawson, Jr. Calibrated geometries.
Acta Math., 148:47–157, 1982.
[Hun90]
Thomas W. Hungerford.
Abstract Algebra: An Introduction.
Saunders College Publishing, Philadelphia, 1990.
[Ker60]
Michel A. Kervaire. A manifold which does not admit any dif-
ferentiable structure. Comment. Math. Helv., 34:257–270, 1960.
[KM63]
Michel A. Kervaire and John W. Milnor. Groups of homotopy
spheres: I. Annals of Math., 77:504–537, 1963.
[Lee97]
John M. Lee. Riemannian Manifolds: An Introduction to Cur-
vature. Springer-Verlag, New York, 1997.
[Lee00]
John M. Lee. Introduction to Topological Manifolds. Springer-
Verlag, New York, 2000.
[Mil65]
John W. Milnor.
Topology from the Diﬀerentiable Viewpoint.
Princeton University Press, Princeton, 1965.
[Moi77]
Edwin E. Moise. Geometric Topology in Dimensions 2 and 3.
Springer-Verlag, New York, 1977.
[Mos65]
J¨urgen Moser. On the volume elements on a manifold. Trans.
Amer. Math. Soc., 120, 1965.
[Mun60]
James R. Munkres. Obstructions to the smoothing of piecewise
diﬀerentiable homeomorphisms. Annals of Math., 72:521–554,
1960.
[Mun75]
James R. Munkres. Topology: A First Course. Prentice Hall,
Englewood Cliﬀs, New Jersey, 1975.
[Mun84]
James R. Munkres. Elements of Algebraic Topology. Addison-
Wesley, Menlo Park, California, 1984.
[Mun91]
James R. Munkres.
Analysis on Manifolds.
Addison-Wesley,
Redwood City, California, 1991.
[Rud76]
Walter Rudin. Principles of Mathematical Analysis. McGraw-
Hill, New York, third edition, 1976.
[Spa89]
Edwin H. Spanier.
Algebraic Topology.
Springer-Verlag, New
York, 1989.
[Spi65]
Michael Spivak. Calculus on Manifolds. W. A. Benjamin, New
York, 1965.
[Ste64]
Shlomo Sternberg. Lectures on Diﬀerential Geometry. Prentice
Hall, Englewood Cliﬀs, New Jersey, 1964.

References
443
[Var84]
V. S. Varadarajan. Lie Groups, Lie Algebras, and Their Repre-
sentations. Springer-Verlag, New York, 1984.
[Wei69]
Alan Weinstein.
Symplectic structures on Banach manifolds.
Bull. Amer. Math. Soc., 75:1040–1041, 1969.
[Wei77]
Alan Weinstein. Lectures on Symplectic Manifolds. American
Mathematical Society, Providence, R.I., 1977. CBMS Regional
Conf. Ser. in Math., No. 29.
[Whi36]
Hassler Whitney. The word problem and the isomorphism prob-
lem for groups. Ann. of Math. (2), 37:645–680, 1936.
[Whi44a] Hassler Whitney. The self-intersections of a smooth n-manifold
in 2n-space. Ann. of Math. (2), 45:220–246, 1944.
[Whi44b] Hassler Whitney. The singularities of a smooth n-manifold in
(2n −1)-space. Ann. of Math. (2), 45:247–293, 1944.

444
References

Index
1-form, 70
abelian Lie algebra, 372
accessible slice, from a point, 367
action
by discrete group, 149
by left translation, 148
by right translation, 148
is free, 160
is proper, 160
is smooth, 160
free, 147
group
local one-parameter, 313
one-parameter, 310
left, 145
natural, of GL(n, R), 148
natural, of O(n), 148
of O(n) on Sn−1, 148
of a group, 145
proper, 147
of a discrete group, 157
properly discontinuous, 158
right, 146
smooth, 146
transitive, 147
adapted
chart, 154
orthonormal frame, 192, 262
addition, vector, 403
adjoint matrix, 150
Ado’s theorem, 398
aﬃne
singular
simplex, 292
subspace, 407
algebra, Lie, 371
induced homomorphism,
379
of a Lie group, 373
product, 372
along a submanifold, 123
Alt (alternating projection), 205
Alt convention, 212
alternating
projection, 205
tensor, 202
and orientation, 231
basis for space of, 207
elementary, 206

446
Index
alternative deﬁnitions of the
tangent space, 55
angle, 186, 421
function, 14
antisymmetry of bracket, 371
approximation
linear
and the diﬀerential, 74
approximation linear, 41
approximation theorem
Whitney, 138
on manifolds, 142
atlas, 8
for a manifold with
boundary, 20
smooth, 8
complete, 9
maximal, 9
autonomous system of ODEs,
326
backward reparametrization, 81
Baker-Campbell-Hausdorﬀ
formula, 392
ball
closed, 423
is a manifold with
boundary, 21, 40
coordinate, 4
open, 423
band, M¨obius, 265
base
of a covering, 28
of a vector bundle, 59
basis
dual, 66
standard, for Rn, 66
for a vector space, 405
isomorphism, 11, 408
ordered, 406
representation of a vector,
406
standard, 406
bilinear, 172
form, 173
block upper triangular, 420
boundary
induced volume form, 262
manifold, 20
manifold with, 19
push-forward, 53
tangent space, 53
topological, 19
vector ﬁeld on, 62
of a manifold with
boundary, 19, 128
disjoint from interior, 20
is a manifold, 21
is a submanifold, 120
of a singular simplex, 292
operator, singular, 292
singular, 292
topological, 20
bounded linear map, 424
bracket
commutator, 372
in a Lie algebra, 371
Lie, 329
antisymmetry, 330
bilinearity, 330
coordinate expression, 329
equals Lie derivative, 333
is smooth, 329
Jacobi identity, 330
naturality, 331
tangent to submanifold,
331
Poisson, 348
on Rn, 348
Bredon, Glen E., vi
bump function, 35, 39
existence, 38
bundle
cotangent, 69
is a vector bundle, 69
isomorphic, 60
isomorphism, 60, 127
M¨obius, 265
map, 60, 192
bijective, 127

Index
447
normal, 139
is a submanifold, 139
of tensors, 179
tangent, 57
is a vector bundle, 59
projection, 57
smooth structure, 57
standard coordinates, 58
trivial, 62
tensor, 180
trivial, 59
tangent, 62
vector, 58
projection is a
submersion, 95
restriction of, 59
section of, 59
C(M) (space of continuous
functions), 40
C∗(nonzero complex numbers),
31
C1 (continuously diﬀerentiable),
425
Ck (k times continuously
diﬀerentiable), 425
manifold, 9
structure, 9
Ck(U), 425
CPn (complex projective space),
169
C∞(inﬁnitely diﬀerentiable), 7,
425
structure, 9
C∞(M), 24
C∞(U), 425
Cω structure, 9
calibrated submanifold, 304
calibration, 304
canonical
coordinates, 349
form
for commuting vector
ﬁelds, 337
for nonvanishing vector
ﬁeld, 331
for symplectic tensor, 221
symplectic structure on
T ∗M, 223
Cayley numbers, 401
centered at a point, 4
chain
complex, 286
singular, 293
group
singular, 292
smooth, 296
singular, 292
smooth, 296
chain rule
for partial derivatives, 431
for total derivatives, 429
change of variables, 438
characterization of homogeneous
spaces, 162
chart, 4
centered at a point, 4
generalized, 19
negatively oriented, 232
oriented, 232
positively oriented, 232
slice, 97
smooth, 7, 10
on a manifold with
corners, 252
with corners, 252
with corners, 252
smooth, 252
smoothly compatible, 252
circle, 6, 14
as a Lie group, 31
de Rham cohomology, 281
group, 31
Lie algebra of, 374
subgroup of C∗, 124
homeomorphic to square, 7
not diﬀeomorphic to square,
127
class C1, 425

448
Index
class Ck, 425
class C∞, 425
closed
1-form, 85
coordinate independence,
85
ball, 423
is a manifold with
boundary, 21, 40
covector ﬁeld, 85, 214
coordinate independence,
85
vs. exact, 85–87
curve segment, 82
form, 219
local exactness, 279
rectangle, 433
subgroup, 124
is embedded, 394
subgroup theorem, 392
submanifold, 126
closest point to a submanifold,
144
cochain
complex, 286
homotopy, 274
map, 286
codimension, 97
cofactor, 419
coframe
coordinate, 71
dual, 71
global, 71
local, 71
cohomologous, 273
cohomology
class, 273
de Rham, 272
of nonorientable manifold,
281
of orientable manifold,
279
with compact support,
284
group, de Rham, 272
map, induced, 273
of a complex, 285
singular, 295
coisotropic
immersion, 222
submanifold, 222
subspace, 220
column
operations, elementary, 417
rank, 413
combination, linear, 404
commutator bracket, 372
commute, 335
commuting vector ﬁelds, 335,
336
canonical form, 337
compact support, 34
de Rham cohomology with,
284
compactly supported
forms, 282
function, 34
section, 59
compatible, smoothly, 7
charts with corners, 252
complement
orthogonal, 423
symplectic, 220
complementary
subspace, 407
complete
smooth atlas, 9
vector ﬁeld, 316
on a compact manifold,
317
completely integrable, 359
vs. involutive, 359
complex, 285
analytic structure, 9
chain, 286
cochain, 286
general linear group, 31
Lie algebra of, 402
manifold, 9
projective space, 169

Index
449
short exact sequence of, 286
singular chain, 293
special linear group, 150
component
covector, transformation
law, 68, 69, 77
functions, 424
of a covector ﬁeld, 70
of a tensor ﬁeld, 180
of a vector ﬁeld, 60
identity, of a Lie group, 167
map, 26
of a covector, 66
of a vector, 50
vector, transformation law,
52, 69
with respect to a basis, 406
composite function, diﬀerential
of, 74
composition
and tangent vectors, 55
of embeddings, 97
of immersions, 97
of smooth maps, 25
of submersions, 97
computation in coordinates, 49
connected
manifold
points joined by piecewise
smooth curves, 79
points joined by smooth
curves, 144
sum, 128
connecting homomorphism, 286
conservative, 82
vector ﬁeld, 91
vs. exact, 83
consistently oriented, 230
charts, 232
constant
function, and zero
diﬀerential, 74
rank, 94
and diﬀeomorphism, 131
and immersion, 111
and submersion, 131
image, 127
level set theorem, 113
continuous pointwise orientation,
232
continuously diﬀerentiable, 425
contractible, 278
contraction, 105, 235
lemma, 105
contravariant
functor, 67
tensor, 179
tensor ﬁeld, 180
vector, 69
convergence
of series of functions, 439
pointwise, 439
uniformly, 439
coordinate
ball, 4
chart, 4
centered at a point, 4
smooth, 7
coframe, 71
computations, 49
domain, 4
map, 4
smooth, 10
neighborhood, 4
representation
for a point, 18
of a function, 24
of a map, 25
subspace, 413
vector, 50
transformation law, 52, 68
vector ﬁeld, 61
coordinates, 406
canonical, 349
Darboux, 349
local, 4
slice, 97
spherical, 104
standard
on Rn, 11

450
Index
on the tangent bundle, 58
stereographic, 21
symplectic, 349
corner point, 252, 253
corners
chart with, 252
smoothly compatible, 252
smooth manifold with, 252
smooth structure with, 252
correspondence
between Lie groups and Lie
algebras, 398
coset, 407
cotangent
bundle, 69
canonical symplectic
structure, 223
is a vector bundle, 69
symplectic structure, 222
space, 68
tangent isomorphism, 192,
197
not canonical, 198
countable
group, 32
second
product, 4
subspace, 4
subcover, 4
counterclockwise, 230
covariant
tensor, 172
tensor ﬁeld, 180
transformation law, 196
vector, 69
covector, 65, 204
components, 66
transformation law, 68,
69, 77
ﬁeld, 70
closed, 85, 214
closed vs. exact, 85–87
conservative, 82
conservative vs. exact, 83
exact, 82
pullback, 76
restriction, 123
smooth, 70
smoothness criteria, 70
space of, 71
tangent, 68
covector ﬁeld
exact, on the torus, 91
integral
diﬀeomorphism
invariance, 78
in R, 78
cover, regular open, 36
covered, evenly, 28
covering
base of, 28
group, 157, 380
acts properly, 158
has isomorphic Lie
algebra, 380
is a Lie group, 158
Lie, 380
universal, 380
homomorphism, 380
manifold, smooth structure,
29
map, 28
injective, 28
topological, 28
orientation, 265
smooth, 28
is a local diﬀeomorphism,
28
is an immersion, 95
is open, 28
local sections of, 28
smooth maps from base,
29
vs. topological, 28
space, 28
of Lie group, 167
orientable, 265
transformation, 157
Cramer’s Rule, 31
critical

Index
451
point, 113
value, 114
cross product, 172
cube, 433
symmetry group of, 161
cup product, 303
curl, 263
curvature, 1
curve
and the diﬀerential, 74
closed, 82
in submanifold, 128
integral, 307
is immersed, 313
length of
in Rn, 90
segment, 79
closed, 82
length of, 186
piecewise smooth, 79
smooth, 79
smooth, 54
is an immersion, 94
tangent vector to, 54
cusp, 104
cutoﬀfunction, 35
cycle, singular, 292
d (diﬀerential of a function), 72
d (exterior derivative), 215
δi
j (Kronecker delta), 66
δJ
I (Kronecker delta for
multi-indices), 206
δ-close, 138
Darboux
coordinates, 349
theorem, 349
de Rham
basis, 300
cohomology, 86, 272
diﬀeomorphism
invariance, 273
functoriality, 273
homotopy invariance, 276
induced map, 273
is a topological invariant,
274
of a simply connected
manifold, 279
of disjoint union, 277
of Euclidean space, 279
of nonorientable manifold,
281
of orientable manifold,
279
of spheres, 290
of the circle, 281
of zero-manifolds, 278
top dimensional, 279, 281
topological invariance,
277
with compact support,
284
zero-dimensional, 278
cover, 300
group, 272
homomorphism, 298
manifold, 300
theorem, 300
decomposable, 225, 235
deﬁning
function, 116
existence, 115
local, 116
map, 116
and tangent space, 116
local, 116
representation
of GL(n, C), 33
of GL(n, R), 33
delta, Kronecker, 66
dense
curve on the torus, 95, 126
as immersed submanifold,
119
is not embedded, 126
subgroup of the torus, 125
dependent, linearly, 404
derivation, 43, 45
derivative

452
Index
directional, 43
exterior, 214, 215, 217
is local, 216
Lie
of a tensor ﬁeld, 339
of a vector ﬁeld, 328
of a determinant, 91
of a map, 51
partial, 425
higher order, 425
order of, 425
second order, 425
total, 428
determinant, 172, 202
and volume, 225
convention, 212
derivative of, 91
diﬀerential of, 92
is a Lie group
homomorphism, 33
is a submersion, 115
is a tensor, 173
of a matrix, 415
diﬀeomorphic, 26
is an equivalence relation,
26
diﬀeomorphism
and constant rank, 131
between Euclidean spaces, 7
between manifolds, 26
group acts transitively, 325
invariance of de Rham
cohomology, 273
local, 26
diﬀerentiable, 428
continuously, 425
inﬁnitely, 425
structure, 9
diﬀerential
and linear approximation,
74
and push-forward, 75
equation
and the Frobenius
theorem, 361
integrating, 309
ordinary, 308, 309
form, 70, 212
and orientation, 233
closed, 85
closed vs. exact, 85–87
conservative, 82
conservative vs. exact, 83
exact, 82
left-invariant, 375
Lie derivative, 341
geometry, v
ideal, 370
of a constant, 73
of a determinant, 92
of a function, 72
coordinate formula, 72, 73
of a map, 51
of a product, 73
of a quotient, 73
of a sum, 73
of function composed with
curve, 74
zero, 74
diﬀerentiation, exterior, 217
dimension, 406
invariance of, 64
of a tangent distribution,
356
direct sum, 407
directional derivative, 43
in Rn, 43, 431
of vector ﬁeld, 327
discontinuous, properly, 158
discrete
group, 32
action, 149
proper action, 157
quotient by, 159
subgroup, 160
quotient by, 160
distance on a Riemannian
manifold, 188
distribution, 356
and smooth sections, 356

Index
453
determined by a foliation,
365
dimension of, 356
examples, 357
integrable, 358
is involutive, 358
involutive, 358
spanned by vector ﬁelds,
357
tangent, 356
divergence, 262, 344
and volume decreasing
ﬂows, 345
and volume increasing ﬂows,
345
and volume preserving
ﬂows, 345
on nonoriented manifold,
266
product rule, 267
theorem, 262
domain
coordinate, 4
ﬂow, 313
of integration, 436
in a manifold, 245
in the boundary of a
manifold with corners,
254
regular, 238
restricting, 121
Donaldson, Simon, 27
dot product, 12, 172, 421
dual
basis, 66
standard, for Rn, 66
coframe, 71
homomorphism, 295
map, 67
space, 66
second, 67
dV (in integral notation), 434
dVg (Riemannian volume form),
258
dynamical systems, 333
e (identity of a Lie group), 30
E(n) (Euclidean group), 161
eigenfunction of Laplace
operator, 267
eigenvalue of Laplace operator,
267
Einselement, 30
Einstein summation convention,
12
element, function, 56
elementary
column operations, 417
k-covector, 206
matrix, 417
row operations, 417
embedded
subgroup, 124
submanifold, 97
closed, 126
image of embedding, 98,
118
local characterization, 97
of a manifold with
boundary, 120
open, 97
uniqueness of smooth
structure, 98
embedding, 94
composition of, 97
image is an embedded
submanifold, 118
smooth, 94
theorem, Whitney, 136
strong, 137
topological, 94
equation, variational, 321
equivalent norms, 423
equivariant
map, 149
rank theorem, 150
escape lemma, 316
Euclidean
dot product, 12
group, 161
inner product, 421

454
Index
locally, 3
metric, 185
space, 11, 406
as a Lie group, 31
as a manifold, 11
Lie algebra of, 374
smooth structure, 11
standard coordinates, 11
uniqueness of smooth
structure, 27
evaluation map, 373
even permutation, 414
evenly covered, 28
exact
1-form, 82
covector ﬁeld, 82
on the torus, 91
form, 219
functor, 296
sequence, 285
of complexes, 286
vs. conservative, 83, 85–87
existence of Riemannian metric,
194
expansion by minors, 419
exponential map, 385
and one-parameter
subgroups, 385
is a local diﬀeomorphism,
385
of GL(n, R), 385
of a Lie group, 385
push-forward, 385
smoothness, 385
exponential of a matrix, 383
extension
lemma, 39
of smooth function, 39
exterior
derivative, 214, 215, 217
and Lie brackets, 352
and pullback, 218
is local, 216
diﬀerentiation, 217
product, 209
F ∗(pullback)
of covectors, 75
of forms, 213
of functions, 40
of tensors, 181
F∗(push-forward)
in coordinates, 50
induced Lie algebra
homomorphism, 378
of vector ﬁelds, 63
of vectors, 46
F-related, 63
face map, 292
faithful representation, 398
fake R4, 27
ﬁber
of a map, 112
of a vector bundle, 58
ﬁeld
plane, 356
ﬁgure eight, 95
as immersed submanifold,
119
is not embedded, 126
ﬁnite group
as a Lie group, 32
ﬁnite, locally, 36
ﬁnite-dimensional
representation, 33
vector space, 405
ﬁrst-order system of PDEs, 362
ﬂag, 164
manifold, 164
ﬂat, 193
chart, 359
for a foliation, 365
metric, 187, 198
on torus, 199
ﬂow, 313
domain, 313
fundamental theorem on,
314
proof, 315
generated by a vector ﬁeld,
314

Index
455
global, 310
arises from vector ﬁeld,
311
is orientation preserving,
326
local, 313
maximal, 314
volume decreasing, 345
and divergence, 345
volume increasing, 345
and divergence, 345
volume preserving, 345
and divergence, 345
foliation, 365
determines involutive
distribution, 365
examples, 365
leaves of, 365
form
bilinear, 173
closed, 85
vs. exact, 85–87
conservative, 82
vs. exact, 83
diﬀerential, 70, 212
and orientation, 233
exact, 82
vs. closed, 85–87
vs. conservative, 83
left-invariant, 375
Lie derivative, 341
forward reparametrization, 81
frame
global
and trivial bundle, 64
for a manifold, 62
left-invariant, 375
local, 60
and local trivialization, 64
for a manifold, 62
negatively oriented, 232
oriented, 232
orthonormal, 188
adapted, 192, 262
existence, 188
positively oriented, 232
free
group action, 147
vector space, 175
characteristic property,
175
Freedman, Michael, 27
Frobenius theorem, 359
and partial diﬀerential
equations, 361
global, 366
proof, 367
function
element, smooth, 56
real-valued, 23
smooth
coordinate representation,
24
extension of, 39
on a manifold, 24
vector-valued, 23
vs. map, 23
functional, linear, 65
functor, 67
exact, 296
fundamental correspondence
between Lie groups and
Lie algebras, 398
fundamental theorem for line
integrals, 81
fundamental theorem of Sophus
Lie, 398
fundamental theorem on ﬂows,
314
proof, 315
GL+(n, R), 124
GL(n, C), see complex general
linear group
GL(n, R), see general linear
group
GL(V ), 31
G-space, 146
homogeneous, 161
left, 146

456
Index
right, 146
Gauss’s theorem, 262
general linear group, 13, 31
complex, 31
Lie algebra of, 402
components, 165
connected, 168
is a manifold, 13
Lie algebra of, 376
natural action, 148
one-parameter subgroups,
383
general position, 291
generalized chart, 19
generator, inﬁnitesimal
of a ﬂow, 313
of a global ﬂow, 311
geometric
simplex, 291
tangent space, 42
tangent vector, 42
geometry
diﬀerential, v
Riemannian, 187
germ, 56
global
coframe, 71
ﬂow, 310
arises from vector ﬁeld,
311
frame
and trivial bundle, 64
for a manifold, 62
Frobenius theorem, 366
proof, 367
trivialization, 59
and global frame, 64
globally Hamiltonian, 347
gradient, 71, 193
orthogonal to level set, 199
graph
coordinates
on spheres, 13
Riemannian metric in,
191
is an embedded
submanifold, 103
of a smooth function, 103
Grassmann manifold, 15, 17, 164
is compact, 169
Grassmannian, 15, 17, 164
is compact, 169
Green’s
identities, 267
theorem, 251
group
action, 145
free, 147
local one-parameter, 313
one-parameter, 310
orientation-preserving,
265
proper, 147
properly discontinuous,
158
smooth, 146
transitive, 147
circle, 31
circle, subgroup of C∗, 124
complex general linear, 31
de Rham, 272
discrete, 32
general linear, 31
injective, 296
laws, 310
of a ﬂow, 313
Lie, 30
special linear, 115
symmetric, 414
topological, 30
Hn (upper half space), 19
Haar
integral, 376
volume form, 376
half space, upper, 19
Hamiltonian
globally, 347
locally, 347
vector ﬁeld, 346, 347

Index
457
on R2n, 346
tangent to level sets, 347
harmonic function, 267
Hausdorﬀ
product, 3
space, 3
subspace, 3
Hermitian, 151
higher-order partial derivative,
425
Hodge star operator, 268
Hom(V, W) (space of linear
maps), 196
homeomorphism
smooth, 99
homeomorphism, smooth, 99
homogeneous
G-space, 161
manifold, 161
space, 161
characterization theorem,
162
homologous submanifolds, 303
homology
of a complex, 286
singular, 292
smooth, 296
homomorphism
covering, 380
dual, 295
induced Lie algebra, 379
Lie, 32
Lie algebra, 372
induced, 378
Lie group, 32
is equivariant, 149
homotopic, 142
maps are smoothly
homotopic, 143
path, 255
relative to a set, 142
smoothly, 143
homotopy, 142
cochain, 274
equivalence, 274
equivalent, 274
invariance of de Rham
cohomology, 276
inverse, 274
operator, 274
relative to a set, 142
Hopf map, 170
hyperplane, 71
hypersurface, 235
in a Riemannian manifold,
260
induced volume form, 260
orientability, 237
In (identity matrix), 409
ideal, diﬀerential, 370
identity
component, 167
matrix, 409
of a Lie group, 30
image, 407
of a Lie group
homomorphism, 169
of an embedding, 118
of constant rank map, 127
immersed submanifold, 119
of a manifold with
boundary, 120
immersion, 94
and constant rank, 111
between manifolds with
boundary, 120
composition of, 97
is locally an embedding, 120
theorem, Whitney, 134
strong, 137
vs. embedding, 96
implicit function theorem, 109
improper integral, 241
increasing multi-index, 207
independent, linearly, 404
index
conventions, 12
for covectors, 67
lower, 12

458
Index
position, 12
upper, 12
induced
cohomology map, 273
Lie algebra homomorphism,
378, 379
metric, 191
orientation
on a boundary, 239
orientation on a boundary,
239
inﬁnite-dimensional vector
space, 405
inﬁnitely diﬀerentiable, 425
inﬁnitesimal generator, 311, 313
invariant under ﬂow, 312,
313
of a ﬂow, 313
of a global ﬂow, 311
injective
group, 296
immersion vs. embedding,
96
inner product, 184, 421
Euclidean, 421
space, 421
integrable, 434
completely, 359
vs. involutive, 359
distribution, 358
is involutive, 358
over a bounded set, 436
integral
curve, 307
and one-parameter
subgroup, 382
is immersed, 313
improper, 241
line, 78, 79
fundamental theorem, 81
of a vector ﬁeld, 91
parameter independence,
81
lower, 434
manifold, 357
union of, 366
uniqueness, 360
of a covector ﬁeld
diﬀeomorphism
invariance, 78
in R, 78
of a diﬀerential form
computing, 245
diﬀeomorphism
invariance, 241, 245
linearity, 244
orientation reversal, 244
over a manifold, 242
over a smooth chain, 297
over a smooth simplex,
297
positivity, 244
of a function
on a rectangle, 434
on a Riemannian
manifold, 260
over a bounded set, 436
of an n-form in Rn, 240
on a manifold, 243
on a manifold with corners,
253
over a 0-manifold, 244
over a boundary, 244
over a submanifold, 244
upper, 434
integrating a system of ODEs,
309
integration
by parts, 267
domain of, 436
in a manifold, 245
iterated, 438
on Lie groups, 375
interior
multiplication, 235
is an antiderivation, 235
of a manifold with
boundary, 19, 128
disjoint from boundary,
20

Index
459
is a manifold, 21
intersection, transverse, 128
intertwine, 149
invariant
left-, 373
tensor ﬁeld, 343
and Lie derivative, 343
under a ﬂow, 343
vs. Lie derivative, 343
vector ﬁeld, 312, 335
inverse
function theorem, 105
map, smoothness of, 99
of a matrix, 410
inversion map, 30
invertible
linear map, 408
matrix, 409
involutive, 358
distribution
and diﬀerential forms, 369
vs. completely integrable,
359
inward-pointing, 238
isometric, 187
isometry, 187, 422
isomorphic
Lie algebras, 373
locally, 398
vector bundles, 60
vector spaces, 408
isomorphism, 408
basis, 408
bundle, 60
determined by a basis, 11
Lie, 32
Lie algebra, 373
Lie group, 32
vector bundle, 60
isotropic
immersion, 222
submanifold, 222
subspace, 220
isotropy group, 147
iterated integration, 438
Jacobi identity, 330, 372
for Poisson bracket, 353
Jacobian matrix, 51, 425
k-covector, 204
elementary, 206
k-form, 212
k-slice
in Rn, 97
in a manifold, 97
kernel, 407
of Lie homomorphism
is a subgroup, 150
Kervaire, Michel, 27
Killing ﬁeld, 344
Euclidean, 344, 352
kink, 104
Kronecker delta, 66
for multi-indices, 206
Lg (left translation), 32
Lagrangian
immersion, 222
submanifold, 222
and closed 1-form, 223
subspace, 220
Laplace operator, 267
Laplacian, 267
leaf of a foliation, 365
Lebesgue measure, 434
left
action, 145
G-space, 146
translation, 32, 373
left-invariant
diﬀerential form, 375
frame, 375
tensor, 375
vector ﬁeld, 373
is complete, 381
length
of a curve segment, 186
in Rn, 90
isometry invariant, 187

460
Index
parameter independence,
186
of a tangent vector, 186
of a vector, 421
level set, 104
of submersion, 113
regular, 114
is a submanifold, 114
of a real-valued function,
114
theorem, 114
theorem, constant rank, 113
Lie
algebra, 371
abelian, 372
and one-parameter
subgroups, 382
homomorphism, 372, 396
homomorphism, induced,
378, 379
isomorphic, 373
isomorphism, 373
of SL(n, R), 388
of a Lie group, 373
of a subgroup, 379, 387
product, 372
representation, 398
bracket, 329
antisymmetry, 330
bilinearity, 330
coordinate expression, 329
equals Lie derivative, 333
is smooth, 329
Jacobi identity, 330
naturality, 331
tangent to submanifold,
331
covering group, 380
has isomorphic Lie
algebra, 380
derivative
and invariant tensor ﬁeld,
343
equals Lie bracket, 333
of a tensor ﬁeld, 339
of a vector ﬁeld, 328
of diﬀerential form, 341
group, 30
countable, 32
covering of, 167
discrete, 32
ﬁnite, 32
homomorphism, 32, 396
homomorphism is
equivariant, 149
homomorphism, image of,
169
homomorphism, with
discrete kernel, 167
identity component, 167
integration on, 375
is orientable, 375
is parallelizable, 375
isomorphism, 32
product of, 32
simply connected, 397
homomorphism, 32
isomorphism, 32
subalgebra, 372
subgroup, 124
associated with Lie
subalgebra, 394
closed, 124
embedded, 124
Lie, Sophus, 398
fundamental theorem, 398
line integral, 78, 79
fundamental theorem, 81
of a vector ﬁeld, 91
parameter independence, 81
line with two origins, 21
linear
approximation, 41
and the diﬀerential, 74
combination, 404
functional, 65
group
complex general, 31
complex special, 150
general, 31

Index
461
special, 115, 125
map, 407
over C∞(M), 90
system of PDEs, 362
linearly
dependent, 404
independent, 404
Lipschitz
constant, 432
continuous, 432
local
coframe, 71
coordinate map, 4
coordinate representation
for a point, 18
coordinates, 4
deﬁning function, 116
existence, 115
deﬁning map, 116
diﬀeomorphism, 26
exactness of closed forms,
279
ﬂow, 313
frame, 60
and local trivialization, 64
for a manifold, 62
orthonormal, 188
isometry, 187
one-parameter group action,
313
operator, 216
parametrization, 191
section, 28, 59
existence of, 111
of smooth covering, 28
trivialization, 59
and local frame, 64
locally
Euclidean, 3
ﬁnite, 36
cover, 36
Hamiltonian, 347
isomorphic, 398
Lorentz metric, 2, 195
lower
integral, 434
sum, 433
lowering an index, 193
M(m × n, C) (space of complex
matrices), 12
M(m × n, R) (space of matrices),
12
M(n, C) (space of square
complex matrices), 12
M(n, R) (space of square
matrices), 12
manifold
boundary, 20
Ck, 9
complex, 9
is metrizable, 191
is paracompact, 37
oriented, 232
real-analytic, 9
Riemannian, 184
smooth, 1, 9
is a manifold with
boundary, 20
with corners, 252
topological, 1, 3
with boundary
boundary point, 128
interior point, 128
product of, 269
push-forward, 53
smooth atlas, 20
smooth structure, 20
submanifold of, 120
tangent space, 53
topological, 19
vector ﬁeld on, 62
with corners, 252
product of, 269
Stokes’s theorem, 254
map vs. function, 23
map, smooth, between
manifolds, 24
mapping vs. function, 23
matrices

462
Index
of ﬁxed rank, 116
of maximal rank, 13
matrix
exponential, 383
Lie algebra, 372
of a linear map, 409
skew-symmetric, 412
symmetric, 115, 412
upper triangular, 420
maximal
rank, matrices of, 13
smooth atlas, 9
maximal ﬂow, 314
Mayer–Vietoris sequence, 288
connecting homomorphism,
289
Mayer–Vietoris theorem
for de Rham cohomology,
288
for singular cohomology, 295
for singular homology, 294
measure zero, 254
in Rn, 130, 434
and smooth maps, 130,
131
in manifolds, 131
and smooth maps, 132
n-dimensional, 435
submanifolds, 132
metric, 184
associated to a norm, 423
Euclidean, 185
ﬂat, 187, 198
induced, 191
pseudo-Riemannian, 195
Riemannian, 184
existence, 194
in graph coordinates, 191
round, 191, 197
in stereographic
coordinates, 197
space, 184
metrizable, 191
Milnor, John, 27
minor of a matrix, 413
mixed
tensor, 179
tensor ﬁeld, 180
M¨obius
band, 265
bundle, 169, 265
transformation, 162
module, 404
Moise, Edwin, 27
Morse theory, 325
Moser, J¨urgen, 351
multi-index, 206
increasing, 207
multilinear, 172, 415
map
and tensor product, 178
over C∞(M), 197
multiplication
map, 30
scalar, 403
Munkres, James, 27
n-dimensional measure zero, 435
n-sphere, 5
n-torus, 14
as a Lie group, 32
natural
action of GL(n, R), 148
action of O(n), 148
naturality of the Lie bracket, 331
negatively
oriented, 231
chart, 232
frame, 232
neighborhood, coordinate, 4
nonautonomous system of
ODEs, 326
nondegenerate 2-tensor, 195, 219
nonorientable manifold, 232
de Rham cohomology, 281
nonsingular matrix, 409
norm, 423
associated metric, 423
equivalent, 423
of a tangent vector, 186

Index
463
topology, 423
normal
bundle, 139, 199
is a submanifold, 139
is a vector bundle, 144
orthonormal frame, 144
outward-pointing, 261
space, 139
vector, 199
vector ﬁeld, 260
normed linear space, 423
north pole, 21
nullity, 411
O(n), see orthogonal group
O(tk), 389
odd
permutation, 414
ODE, see ordinary diﬀerential
equation
one-parameter group action, 310
local, 313
one-parameter subgroup, 381
and integral curve, 382
and Lie algebra, 382
generated by X, 383
of GL(n, R), 383
of Lie subgroup, 384
open
ball, 423
cover, regular, 36
rectangle, 433
submanifold, 12, 13
is embedded, 97
orientable, 234
tangent space, 47
orbit, 146
is an immersed submanifold,
167
relation, 153
space, 152
order of a partial derivative, 425
ordered basis, 406
ordinary diﬀerential equation,
308, 309
autonomous, 326
continuity theorem, 320
existence theorem, 314, 318
integrating, 309
nonautonomous, 326
smoothness theorem, 314,
320
uniqueness theorem, 314,
317
orientability
of hypersurfaces, 237
of parallelizable manifolds,
234
orientable, 232
Lie group, 375
manifold, de Rham
cohomology, 279
open submanifold, 234
orientation, 230
and alternating tensors, 231
and nonvanishing n-form,
233
covering, 265
form, 233
induced on a boundary, 239
of a manifold, 232
0-dimensional, 232, 233
of a vector space, 231
0-dimensional, 231
pointwise, 232
continuous, 232
standard, of Rn, 231
Stokes, 239
orientation-preserving, 234
group action, 265
orientation-reversing, 234
oriented
basis, 231
chart, 232
negatively, 232
positively, 232
consistently, 230
form, 233
frame, 232
negatively, 232

464
Index
positively, 232
manifold, 232
n-covector, 232
negatively, 231
vector space, 231
orthogonal, 186, 421
complement, 423
group, 114, 125
action on Sn−1, 148
components, 165
is a Lie subgroup, 125
is an embedded
submanifold, 114
Lie algebra of, 380
natural action, 148
special, 125
special, is connected, 165
matrix, 114
projection, 423
orthonormal
basis, 422
frame, 188
adapted, 192, 262
existence, 188
outward-pointing, 238
unit normal, 261
vector ﬁeld on boundary,
238
overdetermined, 362
Pn (real projective space), 6
paracompact, 36
manifolds are, 37
parallelizable, 62, 375
implies orientable, 234
Lie group, 375
spheres, 64
torus, 64
parametrization, 105
local, 191
partial
derivative
higher order, 425
order of, 425
second order, 425
partial derivative, 425
partial diﬀerential equations
and the Frobenius theorem,
361
partition
of a rectangle, 433
of an interval, 433
of unity, 37
existence, 37
passing to quotient, 112
path homotopic, 255
PDE (partial diﬀerential
equation), 361
period of a diﬀerential form, 303
periodic curve, 325
permutation, 183, 204, 206
even, 414
odd, 414
piecewise smooth curve segment,
79
plane ﬁeld, 356
Poincar´e lemma, 278
for compactly supported
forms, 282
pointwise
convergence, 439
orientation, 232
continuous, 232
Poisson
bracket, 348
Jacobi identity, 353
on Rn, 348
commute, 348
polar coordinate map, 19
pole
north, 21
south, 21
positions of indices, 12
positively oriented, 231
chart, 232
form, 233
frame, 232
n-form, 232
potential, 82
computing, 88

Index
465
precompact, 36
product
inner, 184, 421
Lie algebra, 372
manifold
embedding into, 94
projection is a
submersion, 94
smooth map into, 26
smooth structure, 14
tangent space, 64
of Hausdorﬀspaces, 3
of Lie groups, 32
Lie algebra of, 375
of manifolds with boundary,
269
of manifolds with corners,
269
of second countable spaces,
4
rule, 43
semidirect, 169
smooth manifold structure,
14
symmetric, 183
associativity, 197
projection
of a vector bundle, 59
of product manifold
is a submersion, 94
of the tangent bundle, 57
onto a subspace, 408
orthogonal, 423
projective space
complex, 169
covering of, 167
is a manifold, 6
is Hausdorﬀ, 6
is second countable, 6
orientability, 268
quotient map is smooth, 25,
26
real, 6, 14
smooth structure, 14
proper
action, 147
of a discrete group, 157
inclusion map
vs. embedding, 126
map, 96
properly discontinuous, 158
pseudo-Riemannian metric, 195
pullback, 75
of a 1-form, 76
in coordinates, 77
of a covector ﬁeld, 76
in coordinates, 77
of a tensor ﬁeld, 181
in coordinates, 182
of exterior derivative, 218
of form, 213
in coordinates, 213
push-forward, 46
and the diﬀerential, 75
between manifolds with
boundary, 53
in coordinates, 50
of a vector ﬁeld, 62
by a diﬀeomorphism, 63
of tangent vector to curve,
55
smoothness of, 58
QR decomposition, 166
quaternions, 401
quotient
by discrete group action,
159
by discrete subgroup, 160
manifold theorem, 153
of a vector space, 407
of Lie group by closed
normal subgroup, 167
passing to, 112
uniqueness of, 113
R∗(nonzero real numbers), 31
R4
fake, 27

466
Index
nonuniqueness of smooth
structure, 27
Rg (right translation), 32
Rn, see Euclidean space
RPn (real projective space), 6
raising an index, 193
range, restricting, 121
embedded case, 122
rank
column, 413
constant, 94
level set theorem, 113
matrices of maximal, 13
of a linear map, 94, 411
of a matrix, 412
of a smooth map, 94
of a tensor, 173
of a vector bundle, 58
row, 413
theorem, 107
equivariant, 150
invariant version, 109
rank-nullity law, 105
real projective space, 6, 14
is a manifold, 6
is Hausdorﬀ, 6
is second countable, 6
smooth structure, 14
real vector space, 403
real-analytic
manifold, 9
structure, 9
real-valued function, 23
rectangle, 433
as a manifold with corners,
252
closed, 433
open, 433
reﬁnement, 36
regular, 37
regular
domain, 238
level set, 114
is a submanifold, 114
of a real-valued function,
114
theorem, 114
open cover, 36
point, 113
for a vector ﬁeld, 331
reﬁnement, 37
submanifold, 97
value, 114
related, see F-related
relative homotopy, 142
reparametrization, 81, 186
backward, 81
forward, 81
of piecewise smooth curve,
186
representation
deﬁning
of GL(n, C), 33
of GL(n, R), 33
faithful, 398
ﬁnite-dimensional, 33
of a Lie algebra, 398
of a Lie group, 33
restricting
the domain of a map, 121
the range of a map, 121
embedded case, 122
into a leaf of a foliation,
361
restriction
of a covector ﬁeld, 123
of a vector bundle, 59
of a vector ﬁeld, 122
retraction, 141
Rham, de, see de Rham
Riemann
integrable, 434
integral, 434
Riemannian
distance, 188
geometry, 187
manifold, 184
as metric space, 189
metric, 184

Index
467
existence, 194
in graph coordinates, 191
submanifold, 191
volume element, 258
volume form, 258
in coordinates, 258
right, 230
action, 146
is free, 160
is proper, 160
is smooth, 160
G-space, 146
translation, 32
right-handed basis, 230
round metric, 191, 197
in stereographic
coordinates, 197
row operations, elementary, 417
row rank, 413
S1, see circle
Sk (symmetric group), 204, 206
SL(n, C) (complex special linear
group), 150
SL(n, R), see special linear group
Sn, see sphere
S(n, R) (symmetric matrices),
115
SO(3) is diﬀeomorphic to P3, 168
SO(n) (special orthogonal
group), 125
Sp(2n, R) (symplectic group),
227
SU(2) is diﬀeomorphic to S3, 167
SU(n) (special unitary group),
150
Sard’s theorem, 132
Sard, Arthur, 132
scalar, 404
multiplication, 403
second countable, 3
product, 4
subspace, 4
second-order partial derivative,
425
section
local, 28
existence of, 111
of a vector bundle, 59
of smooth covering, 28
of a map, 28
of a vector bundle, 59
smooth, 59
zero, 59
segment, curve, 79
piecewise smooth, 79
smooth, 79
semidirect product, 169
series of functions, convergence,
439
sgn (sign of a permutation), 204
sharp, 193
short exact sequence of
complexes, 286
sign of a permutation, 204
signature of a bilinear form, 195
simplex
aﬃne singular, 292
geometric, 291
singular, 292
boundary of, 292
smooth, 296
standard, 291
simply connected
Lie group, 397
manifold, cohomology of,
279
simply connected manifold, 279
singular
boundary, 292
boundary operator, 292
chain, 292
complex, 293
group, 292
cohomology, 295
cycle, 292
homology, 292
group, 292
isomorphic to smooth
singular, 296

468
Index
smooth, 296
matrix, 409
point for a vector ﬁeld, 331
simplex, 292
aﬃne, 292
boundary of, 292
skew-symmetric matrix, 412
slice
chart, 97
coordinates, 97
in Rn, 97
in a manifold, 97
smooth, 7
atlas, 8
complete, 9
maximal, 9
on a manifold with
boundary, 20
chain, 296
chain group, 296
chart, 7, 10
on a manifold with
corners, 252
with corners, 252
coordinate map, 10
covector ﬁeld, 70
covering map, 28
injective, 28
is a local diﬀeomorphism,
28
is open, 28
vs. topological, 28
curve, 54
dynamical systems, 333
embedding, 94
function
coordinate representation,
24
extension of, 39
on a manifold, 24
function element, 56
group action, 146
homeomorphism, 99
manifold, 1, 9
is a manifold with
boundary, 20
structure, 9
map
between Euclidean
spaces, 7, 425
between manifolds, 24
composition of, 25
coordinate representation,
25
from a subset of Rn, 428
from base of covering, 29
into a product manifold,
26
is a local property, 24, 25
section, 59
simplex, 296
singular homology, 296
isomorphic to singular,
296
structure, 9
on Rn, 11
on a manifold with
boundary, 20
on a vector space, 11
on spheres, 27
on the tangent bundle, 57
uniqueness, 26
uniqueness, on R, 326
uniqueness, on Rn, 27
with corners, 252
triangulation, 303
vector ﬁeld, 60
smoothly compatible charts, 7
with corners, 252
smoothly homotopic, 143
smoothness is local, 24, 25
smoothness of inverse maps, 99
south pole, 21
space, vector, 403
over an arbitrary ﬁeld, 404
real, 403
span, 404
special
linear group, 115, 125

Index
469
complex, 150
connected, 168
Lie algebra of, 388, 402
orthogonal group, 125
is connected, 165
unitary group, 150
is connected, 165
Lie algebra of, 402
sphere, 5
de Rham cohomology, 290
diﬀerent smooth structures
on, 27
is an embedded
submanifold, 103, 114
is orientable, 237, 239, 265
parallelizable, 64
standard smooth structure,
13
stereographic coordinates,
21
vector ﬁelds on, 64
spherical coordinates, 104
square
homeomorphic to circle, 7
not diﬀeomorphic to circle,
127
standard
basis, 406
coordinates
on Rn, 11
on the tangent bundle, 58
dual basis for Rn, 66
orientation of Rn, 231
simplex, 291
smooth structure
on Rn, 11
on Sn, 13
on a vector space, 11
symplectic form, 222
symplectic structure, 222
star operator, Hodge, 268
star-shaped, 87, 278
starting point of an integral
curve, 308
stereographic
coordinates, 21
round metric in, 197
projection, 21
Stokes orientation, 239
Stokes’s theorem, 248
for surface integrals, 264
on manifolds with corners,
254
subalgebra, Lie, 372
subbundle, 356
tangent, 356
subcover, countable, 4
subgroup
closed
is embedded, 394
of a Lie group, 392
dense, of the torus, 125
discrete, 160
quotient by, 160
Lie, 124
one-parameter, 381
subinterval, 433
submanifold, 120
calibrated, 304
closest point, 144
embedded, 97
curve in, 128
local characterization, 97
open, 97
restricting a map to, 122
uniqueness of smooth
structure, 98
has measure zero, 132
immersed, 119
of a manifold with
boundary, 120
open, 12, 13
is embedded, 97
tangent space, 47
regular, 97
restricting a map to, 121
embedded case, 122
Riemannian, 191
tangent space, 101, 102
and deﬁning maps, 116

470
Index
transverse, 128
submersion, 94
and constant rank, 131
composition of, 97
into Rk, 127
is a quotient map, 111
is open, 111
level set of, 113
passing to quotient, 112
theorem, 113
subordinate to a cover, 37
subrectangle, 433
subspace
aﬃne, 407
coordinate, 413
of a vector space, 404
of Hausdorﬀspace, 3
of second countable space, 4
projection onto, 408
sum
connected, 128
direct, 407
lower, 433
upper, 433
summation convention, 12
support
compact, 34
of a function, 34
of a section, 59
supported in a set, 34
surface integral, 264
Stokes’s theorem for, 264
Sym (symmetrization), 182, 205
symmetric
group, 183, 204, 206, 414
matrix, 115, 412
product, 183
associativity, 197
tensor, 182
ﬁeld, 184
symmetrization, 182, 205
symplectic
basis, 221
complement, 220
coordinates, 349
form, 221, 346
standard, 222
geometry, 222
group, 227
immersion, 222
manifold, 221, 346
orientable, 268
structure, 221
canonical, on T ∗M, 223
on cotangent bundle, 222
standard, 222
submanifold, 222
subspace, 220
tensor, 219
canonical form, 221
vector ﬁeld, 347
vector space, 219
symplectomorphism, 222
T∗(M) (space of covector ﬁelds),
71
T2, see torus
T(M) (space of vector ﬁelds), 62
Tn, see torus
Tn (n-torus), 32
tangent
bundle, 57
is a vector bundle, 59
projection, 57
smooth structure, 57
standard coordinates, 58
trivial, 62
cotangent isomorphism, 192,
197
not canonical, 198
covector, 68
distribution, 356
and smooth sections, 356
determined by a foliation,
365
examples, 357
spanned by vector ﬁelds,
357
space
alternative deﬁnitions, 55

Index
471
geometric, 42
to a manifold, 45
to a manifold with
boundary, 53
to a submanifold, 101,
102, 116
to a vector space, 48
to an open submanifold,
47
to product manifold, 64
subbundle, 356
to a submanifold, 122
vector
geometric, 42
in Euclidean space, 42
local nature, 47
on a manifold, 45
to a curve, 54
to composite curve, 55
to curve, push-forward of,
55
tautologous 1-form, 222
Taylor’s formula, 45
tensor
alternating, 202
and orientation, 231
elementary, 206
bundle, 179, 180
contravariant, 179
covariant, 172
ﬁeld, 180
contravariant, 180
covariant, 180
invariant under a ﬂow,
343
Lie derivative of, 339
mixed, 180
smooth, 180
symmetric, 184
transformation law, 196
left-invariant, 375
mixed, 179
product
and multilinear maps, 178
characteristic property,
176
of tensors, 173
of vector spaces, 176
of vectors, 176
uniqueness, 196
symmetric, 182
time-dependent vector ﬁeld, 326
top-dimensional cohomology
of nonorientable manifold,
281
of orientable manifold, 279
topological
boundary, 20
covering map, 28
vs. smooth, 28
embedding, 94
group, 30
invariance of de Rham
cohomology, 277
manifold, 1, 3
with boundary, 19
topology, norm, 423
torus, 14
as a Lie group, 32
dense curve on, 95, 126
as immersed submanifold,
119
is not embedded, 126
dense subgroup of, 125
exact covector ﬁelds on, 91
ﬂat metric on, 199
Lie algebra of, 375
of revolution, 191, 266
parallelizable, 64
smooth structure on, 14
total derivative, 428
total space, 59
trace, 168
transformation
of coordinate vectors, 52, 68
of covector components, 68,
69, 77
of vector components, 52, 69
transition

472
Index
map, 7
matrix, 230, 410
transitive group action, 147
translation
left, 32
lemma, 309
right, 32
transpose
of a linear map, 67
of a matrix, 412
transposition, 414
transverse
intersection, 128
submanifolds, 128
vector, 237
vector ﬁeld, 237
triangular matrix, upper, 420
triangulation, 303
smooth, 303
trivial bundle, 59
and global frame, 64
tangent, 62
trivialization
global, 59
local, 59
and local frame, 64
tubular neighborhood, 140
theorem, 140
U(n) (unitary group), 150
uniform convergence, 439
uniqueness
of quotients, 113
of smooth structure, 26
on embedded
submanifold, 98
unit
circle, 14
element of a Lie group, 30
sphere, 5
vector, 421
unitary group, 150
diﬀeomorphic to
S1 × SU(n), 167
is connected, 165
Lie algebra of, 402
special, 150
special, is connected, 165
special, Lie algebra of, 402
unity, partition of, 37
existence, 37
universal covering group, 380
upper
half space, 19
integral, 434
sum, 433
triangular matrix, 420
V ∗(dual space), 66
V ∗∗(second dual space), 67
isomorphic to V , 67
vanishes
along a submanifold, 123
at points of a submanifold,
123
variational equation, 321
vector, 404
addition, 403
bundle, 58
isomorphic, 60
isomorphism, 60
projection is a
submersion, 95
restriction of, 59
section of, 59
components, 50
transformation law, 52, 69
contravariant, 69
coordinate, 50
covariant, 69
ﬁeld, 60
along a submanifold, 199,
236
canonical form, 331
commuting, 335–337
complete, 316, 317
component functions of,
60
conservative, 91
coordinate, 61

Index
473
directional derivative of,
327
globally Hamiltonian, 347
Hamiltonian, 347
invariant under a ﬂow,
335
invariant under a map,
312
invariant under its own
ﬂow, 312, 313
Lie algebra of, 372
line integral of, 91
locally Hamiltonian, 347
on a manifold with
boundary, 62
push-forward, 62, 63
restriction, 122
smooth, 60
smoothness criteria, 60
space of, 62
symplectic, 347
time-dependent, 326
transverse, 237
geometric tangent, 42
space, 403
ﬁnite-dimensional, 405
inﬁnite-dimensional, 405
oriented, 231
over an arbitrary ﬁeld,
404
real, 403
smooth structure on, 11
tangent space to, 48
tangent
local nature, 47
on a manifold, 45
to composite curve, 55
transverse, 237
vector-valued function, 23
vertex of a simplex, 291
volume, 1, 437
and determinant, 225
decreasing ﬂow, 345
and divergence, 345
element, Riemannian, 258
form, Riemannian, 258
in coordinates, 258
on a boundary, 262
on a hypersurface, 260
increasing ﬂow, 345
and divergence, 345
measurement, 201
of a rectangle, 433
of a Riemannian manifold,
260
preserving ﬂow, 345
and divergence, 345
wedge product, 209
Alt convention, 212
anticommutativity, 210
associativity, 210
bilinearity, 210
determinant convention, 212
uniqueness, 211
Weinstein, Alan, 351
Whitney
approximation theorem, 138
on manifolds, 142
embedding theorem, 136
strong, 137
immersion theorem, 134
strong, 137
Whitney, Hassler, 137
X♭(X ﬂat), 193
ξ# (ξ sharp), 193
zero section, 59
zigzag lemma, 286

474
Index

