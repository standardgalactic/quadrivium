
 
 
 
Differential Calculus using
 
MATHEMATICA
 
 
 
 
 
 
CÉSAR PÉREZ LÓPEZ
 

INDEX
LIMITS AND CONTINUITY. ONE AND SEVERAL VARIABLES
1.1 LIMITS OF SEQUENCES
1.2 LIMITS OF FUNCTIONS. LATERAL LIMITS
1.3 CONTINUITY
1.4 SEVERAL VARIABLES: LIMITS AND CONTINUITY.  CHARACTERIZATION THEOREMS
1.5 ITERATED AND DIRECTIONAL LIMITS
1.6 CONTINUITY IN SEVERAL VARIABLES
NUMERICAL SERIES AND POWER SERIES
2.1 SERIES. CONVERGENCE CRITERIA
2.2 NUMERICAL SERIES WITH NON-NEGATIVE TERMS
2.3 ALTERNATING NUMERICAL SERIES
2.4 POWER SERIES
2.5 POWER SERIES EXPANSIONS AND FUNCTIONS
2.6 TAYLOR AND LAURENT EXPANSIONS
DERIVATIVES AND APPLICATIONS. ONE AND SEVERAL VARIABLES
3.1 THE CONCEPT OF THE DERIVATIVE
3.2 CALCULATING DERIVATIVES
3.3 TANGENTS, ASYMPTOTES, CONCAVITY, CONVEXITY, MAXIMA AND MINIMA, INFLECTION POINTS AND
GROWTH
3.4 APPLICATIONS TO PRACTICAL PROBLEMS
3.5 PARTIAL DERIVATIVES
3.6 IMPLICIT DIFFERENTIATION
DERIVABILITY IN SEVERAL VARIABLES
4.1 DIFFERENTIATION OF FUNCTIONS OF SEVERAL VARIABLES
4.2 MAXIMA AND MINIMA OF FUNCTIONS OF SEVERAL VARIABLES
4.3 CONDITIONAL MINIMA AND MAXIMA. THE METHOD OF “LAGRANGE MULTIPLIERS”
4.4 SOME APPLICATIONS OF MAXIMA AND MINIMA IN SEVERAL VARIABLES
VECTOR DIFFERENTIAL CALCULUS AND THEOREMS IN SEVERAL VARIABLES
5.1 CONCEPTS OF VECTOR DIFFERENTIAL CALCULUS
5.2 THE CHAIN RULE
5.3 THE IMPLICIT FUNCTION THEOREM
5.4 THE INVERSE FUNCTION THEOREM
5.5 THE CHANGE OF VARIABLES THEOREM
5.6 TAYLOR’S THEOREM WITH N VARIABLES
5.7 VECTOR FIELDS. CURL, DIVERGENCE AND THE LAPLACIAN
5.8 COORDINATE TRANSFORMATION
DIFFERENTIAL EQUATIONS

6.1 SEPARATION OF VARIABLES
6.2 HOMOGENEOUS DIFFERENTIAL EQUATIONS
6.3 EXACT DIFFERENTIAL EQUATIONS
6.4 LINEAR DIFFERENTIAL EQUATIONS
6.5 NUMERICAL SOLUTIONS TO DIFFERENTIAL EQUATIONS OF THE FIRST ORDER
6.6 ORDINARY HIGH-ORDER EQUATIONS
6.7 HIGHER-ORDER LINEAR HOMOGENEOUS EQUATIONS WITH CONSTANT COEFFICIENTS
6.8 NON-HOMOGENEOUS EQUATIONS WITH CONSTANT COEFFICIENTS. VARIATION OF PARAMETERS
6.9 NON-HOMOGENEOUS LINEAR EQUATIONS WITH VARIABLE COEFFICIENTS. CAUCHY-EULER EQUATIONS
6.10 THE LAPLACE TRANSFORM
6.11 SYSTEMS OF LINEAR HOMOGENEOUS EQUATIONS WITH CONSTANT COEFFICIENTS
6.12 SYSTEMS OF LINEAR NON-HOMOGENEOUS EQUATIONS WITH CONSTANT COEFFICIENTS
6.13 HIGHER ORDER EQUATIONS AND APPROXIMATION METHODS
6.14 THE EULER METHOD
6.15 THE RUNGE–KUTTA METHOD
6.16 DIFFERENTIAL EQUATIONS SYSTEMS BY APPROXIMATE METHODS
6.17 DIFFERENTIAL EQUATIONS IN PARTIAL DERIVATIVES
6.18 ORTHOGONAL POLYNOMIALS
APPENDIX. VARIABLES AND FUNCTIONS
7.1 VARIABLES
7.2 FUNCTIONS DEFINITION
7.3 RECURSIVE FUNCTIONS
7.4 PIECEWISE FUNCTIONS
7.5 OPERATIONS WITH FUNCTIONS
7.6 DATA TYPES USED IN THE DEFINITION OF THE FUNCTIONS
 

Chapter 1.
LIMITS AND CONTINUITY. ONE AND SEVERAL
VARIABLES
Mathematica provides commands that allow you to calculate virtually all types of
limits. The same functions are used to calculate limits of sequences and limits of
functions. The commands for the analysis of one and several variables are similar. In this
chapter we will present numerous exercises which illustrate Mathematica’s capabilities in
this field. The syntax of the commands concerning limits are presented below:
Limit(sequence, n->infinity)            calculates the limit as n tends to infinity of the
sequence defined by its general term.
Nlimit(sequence, n->infinity)     calculates the limit as n tends to infinity of the sequence
defined by its general term. This function is implemented in the
package “Numerical Math” and is used when the Limit function
can not solve the problem
Limit(function, x->a)                        calculates the limit of the function of the variable x,
indicated by its analytical expression, as the variable x tends
towards the value a.
Nlimit(function, x->a)                       calculates the limit of the function of the variable x,
indicated by its analytical expression, as the variable x tends
towards the value a. This function is implemented in the package
“Numerical Math” and is used when the Limit function can not
solve the problem
Limit(function, x->a, Direction->1)
calculates the limit of the function of the variable x, indicated
by its analytical expression, as the variable x tends to the value a
from the right .

Limit(function, x->a, Direction->1)
calculates the limit of the function of the variable x, indicated
by its analytical expression, as the variable x tends to the value a
from the left .

1.1 LIMITS OF SEQUENCES
We present some exercises on the calculation of limits of sequences.
Exercise 1-1. Calculate the following limits:
 
,   
,    
,
In the first two limits we face the typical uncertainty given by the quotient 
:
In[1]:= Limit[((2n-3)/(3n-7))^4, n->Infinity]
16/81
In[2]:= Limit[(3 n^3+7 n^2+1)/(4 n^3-8 n+5), n->Infinity]
3
-
4
The last two limits present an uncertainty of the form 
 and 
:
In[1]:= Limit[((n+1)/2)((n^4+1)/n^5), n->Infinity]
1
-
2
In[2]:= Limit[((n+1)/n^2)^(1/n), n->Infinity]
1

Exercise 1-2. Calculate the following limits:
 
,   
,   
,   
,
The first two examples are indeterminate of the form 
:
In[1]:= Limit[((n+3)/(n-1))^n,n->Infinity]
4
E
In[2]:= Limit[(1-2/(n+3))^n,n->Infinity]
-2
E
The next two limits are of the form 
 and 
:
In[1]:= Limit[(1/n)^(1/n),n->Infinity]
1
In[2]:= Limit[((n+1)^(1/3)-n^(1/3))/((n+1)^(1/2)-n^(1/2)), n->Infinity]
0
The last limit is of the form 
:
In[2]:= Limit[n!/n^n,n->Infinity]
Series::esss:
  Essential singularity encountered in
         1           3
   Gamma[- + 1 + O[n] ].

         n
Series::esss:
  Essential singularity encountered in
         1           3
   Gamma[- + 1 + O[n] ].
         n
     n!
Limit[—, n -> Infinity]
      n
     n
The Limit function does not solve the problem. We use Nlimit, and load the appropriate
package, if it is not already in memory.
In[3]:=<<NumericalMath`NLimit`
In[4]:= NLimit[n!/n^n,n->Infinity]
0.

1.2 LIMITS OF FUNCTIONS. LATERAL LIMITS
To calculate the limits of functions one uses the same Mathematica commands as for limits
of sequences.  For functions, Mathematica allows you to calculate the limit at a point, and left
and right limits (if these limits exist). If a function has a limit at a point then it necessarily has
left and right limits at that point, and they coincide. If the left and right limits do not coincide
then the function does not have a limit at the given point. Below are several exercises which
illustrate how to calculate function limits. Some exercises are accompanied by graphics. The
use of graphics is advisable if there are any doubts concerning the results.
Exercise 1-3. Calculate the following limits:
 
 
Initially, we have four indeterminates of type 
 and one of the form 
:
In[1]:= Limit[(x-1)/(x^(1/2)-1),x->1]
2
In[2]:= Limit[(x-(x+2)^(1/2))/((4x+1)^(1/2)-3),x->2]
9
-
8
In[1]:=  Limit[(1+x)^(1/x),x->0]

E
In[3]:=Limit[Sin[a x]^2/x^2,x->0]
 2
a
 
Exercise 1-4. Calculate the following function limits:
 
 
The first limit is calculated as follows:
In[1]:=Limit[Abs[x]/Sin[x],x->0]
Limit[Abs[x] Csc[x], x -> 0]
In[2]:=Limit[Abs[x]/Sin[x],x->0,Direction->1]
Limit[Abs[x] Csc[x], x -> 0, Direction -> 1]
In[3]:=Limit[Abs[x]/Sin[x],x->0,Direction->-1]
Limit[Abs[x] Csc[x], x -> 0, Direction -> -1]
We note that we can not calculate directly, or the limit of the function, or the lateral
limits.
If we represent the function (Figure 1-1), we have an idea of what is the limit
In[4]:= Plot[Abs[x]/Sin[x],{x,-1,1}]

Figure 1-1
By simple observation it is that the limit on the right is 1 and the limit on the left is
-1, as shown below.
In[1]:=Limit[x/Sin[x],x->0]
1
In[2]:=Limit[-x/Sin[x],x->0]
-1
Then the function has no limit if x->0.
For the next two limits we have:
In[1]:= Limit[Abs[x^2-x-7],x->3]
                   2
Limit[Abs[-7 - x + x ], x -> 3]
Directly, Mathematica does not offer the result of this limit, but we know that the
limit of a function module is the limit module function.
 
In[2]:= Abs[Limit[x^2-x-7,x->3]]
1

Another way to solve this problem is to use the Nlimit
In[3]:= NLimit[Abs[x^2-x-7],x->3]
1.00002
With Nlimit function an approximate result is obtained
In[4]:= Limit[(x-1)/(x^n-1),x->1]
1
-
n
For the last limit we have the following:
In[1]:= Limit[E^(1/x),x->0,Direction->1]
0
In[2]:= Limit[E^(1/x),x->0,Direction->-1]
Infinity
We have found that the limits on the right and left do not match, as shown in Figure 1-2
In[3]:= Plot[E^(1/x),{x,-25,25}]

Figure 1-2
Then, there is no limit at 
.
We see that the function becomes (positive) infinite at 0 when approaching from the
right, and it tends to 0 when approaching from the left. Thus we conclude that the function
has no limit at 
.

1.3 CONTINUITY
A function  is continuous at the point 
 if:
Otherwise, it is discontinuous at the point. In other words, in order for a function  to
be continuous at  it must be defined at  and the limit of the function at  must be equal
to the value of the function at .
If the limit of 
 as  tends to  exists but is different to 
, then  is discontinuous
at , and we say  has an avoidable discontinuity at . The discontinuity is resolved by
redefining 
 to coincide with the limit.
If the two lateral limits of 
 at  exist (whether finite or infinite) but are different, then
the discontinuity of  at  is said to be of the first kind. The difference between the two lateral
limits is the jump. If the jump is finite then the discontinuity is said to be of the first kind with
finite jump, otherwise it is of the first kind with infinite jump.
If either of the lateral limits do not exist, then the discontinuity is said to be of the
second kind.
We illustrate these concepts with several exercises:
Exercise 1-7. Study the continuity of the following functions of a real variable:
 
 
In[1]:= Limit[Sin[x]/x,x->a]
Sin[a]
––
 a

The function f is continuous at any non-zero point a, so for any such point we have that 
 
The problem arises at the point x = 0, at which the function  f is not defined. Therefore,
the function is discontinuous at x = 0. This discontinuity can be avoided by redefining the
function at x = 0 with a value equal to 
.
In[2]:= Limit[Sin[x]/x,x->0]
1
Thus we conclude that the function 
 presents an avoidable
discontinuity at 
 that is avoided by defining 
. The function is continuous at
all non-zero points.
The function  is continuous at any non-zero point , so 
 
In[1]:= Limit[Sin[1/x],x->a]
Sin[1/a]
The problem arises at the point 
, where the function  is not defined. Therefore,
the function is discontinuous at 
. To try to avoid the discontinuity, we calculate  
.
In[2]:= Limit[Sin[1/x],x->0]
Interval[{-1, 1}]
In[3]:= Limit[Sin[1/x],x->0,Direction->1]
Interval[{-1, 1}]
In[4]:= Limit[Sin[1/x],x->0,Direction->-1]
Interval[{-1, 1}]
We see that the limit does not exist at 
 (the limit has to be unique and here the

result given is all points in the interval [- 1,1]), and neither of the lateral limits exist. Thus
the function has a discontinuity of the second kind at 
.
Mathematica responded to the calculation of the above limits with the expression “- 1..
1”. This is because the graph of 
 presents infinitely many oscillations between - 1
and 1. This is illustrated in Figure 1-3:
» fplot (‘sin (1/x)’, [- 1, 1])
Figure 1-3
 
Exercise 1-8. Study the continuity of the following function of a real variable:
 
   if 
 and 
 if 
.
 
The only problematic point is 
. Now, the function does exist at 
 (it has the
value 1). We will try to find the lateral limits as x tends to 0:
In[1]:= Limit[1/(1+E^(1/x)),x->0,Direction-> 1]
1
In[2]:= Limit[1/(1+E^(1/x)),x->0,Direction->-1]
0

As the lateral boundaries are different, the limit of the function at 0 does not exist.
However, the lateral boundaries are both finite, so the discontinuity at 0 is of the first kind
with a finite jump. We illustrate this result in Figure 1-4.
In[3]:= Plot[1/(1+E^(1/x)),{x,-10,10}]
Figure 1-4
Exercise 1-9. Study the continuity of the following function of a real variable:
 
 if 
 and 
 if 
.
 
The only problematic point is 
. The function is defined at 
 (it has the value
1).  We will try to find the lateral limits at 0:
In[1]:= Limit[E^(1/x),x->0,Direction-> 1]
¥
In[2]:= Limit[E^(1/x),x->0,Direction->-1]
0
           As the lateral boundaries are different, the limit of the function as x tends to 0 does
not exist. As the right lateral limit is infinite, the discontinuity of the first kind at x = 0 is an
infinite jump. We illustrate this result in Figure 1-5 above.
In[3]:= Plot[E^(1/x),{x,-10,10}]

Figure 1-5

1.4 SEVERAL VARIABLES: LIMITS AND CONTINUITY.
 CHARACTERIZATION THEOREMS
                  
The sequence  
 of points in m-dimensional space, where n runs
through the natural numbers, has as limit the point   
   if, and only if:
This characterization theorem allows us to calculate limits of sequences of points in m-
dimensional space.
There is another theorem, similar to the above, which characterizes the limits of
functions between spaces of more than one dimension. This theorem enables us to
calculate the limits of multivariable functions.
If 
  is a function whose m components are 
. Then it  follows that:
if and only if
…,

Exercise 1-10. Calculate the limit of the following three-dimensional sequence:
In[1]:= Limit[{(n+1)/n,(1+1/n)^(2n),n/(2n-1)},n->Infinity]
    2  1
{1, E , -}
       2
Exercise 1-11. Calculate the limit as n®¥ of the following four-dimensional sequence:
In[1]:= Limit[{(n/(n^2+1))^(1/n),(1/n)^(1/n),(5n)^(1/n),(n^2+1)/n^2},n->Infinity]
                     
{1, 1, 1, 1}
Exercise 1-12. For the function 
 defined below, find 
:
 
 
In[1]:= Limit[{Sin[x]/x,(1+x)^(1/x)},x->0]
{1, E}    
Exercise 1-13. For the function 
 defined below, find 
:
 

In[1]:= Limit[{Sin[x]/x+2(1-Cos[y])/y^2,(1+x)^(1/x)-Tan[y]/y},x->0]
          y 2
    4 Sin[-]
          2        Tan[y]
{1 + –––, E - ––}
        2            y
       y
Limit[{%},y->0]
{{2, -1 + E}, {2, -1 + E}}
 
 

1.5 ITERATED AND DIRECTIONAL LIMITS
Given a function 
 an iterated limit of  at the point 
    is the value
of the limit (if it exists):
or any of the other limits obtained by permuting the order of the component limits.
The directional limit of f at the point 
depends on the direction of the curve  
, where 
, and is defined to be the
value:
A necessary condition for a function of several variables to have a limit at a point is that
all the iterated limits have the same value (which will be equal to the value of the limit of
the function, if it exists).
It can also happen that the directional limit of a function will vary according to the
curve used, so that a different limit exists for different curves, or the limit exists for some
curves and not others.
Another necessary condition for a function of several variables to have a limit at a point
is that all directional limits, i.e. the limit for all curves, have the same value.
Therefore, to prove that a function has no limit at a point it is enough to show that either an
iterated limit does not exist or that two iterated limits have a different value, or we can show
that a directional limit does not exist or that two directional limits have different values.
A practical procedure for calculating the limit of a function of several variables is to
change from cartesian to polar coordinates.

Exercise 1-14. Find
for the function f: R2® R defined by:
In[1]:= Limit[Limit[(x y)/(x^2+y^2),x->0],y->0]
0
In[2]:= Limit[Limit[(x y)/(x^2+y^2),y->0],x->0]
0
Thus the two iterated limits are the same. Next we calculate the directional limits
corresponding to the family of straight lines y = mx:
In[3]:= Limit[(x)(m x)/(x^2+(m^2)(x^2)),x->0]
 m
––
    2
1 + m
The directional limits depend on the parameter m, which will be different for different
values of m (corresponding to different straight lines). Thus, we conclude that the function
has no limit at (0,0).
Exercise 1-15. Find
for the  function f:R2®  R defined by:
In[1]:=Limit[Limit[(y^2-x^2)^2/(y^4+x^2),x->0],y->0]
1

In[2]:=Limit[Limit[(y^2-x^2)^2/(y^4+x^2),y->0],x->0]
0
As the two iterated limits are different, we conclude that the function has no limit at the
point (0,0).
Exercise 1-16. Find
for the  function f:R2®  R defined by:
 
In[1]:= Limit[Limit[(y^2-x)^2/(y^4+x^2),x->0],y->0]
1
In[2]:= Limit[Limit[(y^2-x)^2/(y^4+x^2),y->0],x->0]
1
Thus the two iterated limits are the same. Next we calculate the directional limits
corresponding to the family of straight lines y = mx:
In[3]:= Limit[((m x)^2-x)^2/((m x)^4+x^2),x->0]
1
The directional limits corresponding to the family of straight lines y = mx do not
depend on m and coincide with the iterated limits. Next we find the directional limits
corresponding to the family of parabolas y ^ 2 = mx:
In[4]:= Limit[((m x)-x)^2/((m x)^2+x^2),x->0]
       2
(-1 + m)
–––
     2

1 + m
Thus the directional limits corresponding to this family of parabolas depend on the
parameter m, so they are different. This leads us to conclude that the function has no limit at
(0,0).
Exercise 1-17. Find
for the  function f:R2®  R defined by:
In[1]:= Limit[Limit[(x^2 y)/(x^2+y^2),x->0],y->0]
0
In[2]:= Limit[Limit[(x^2 y)/(x^2+y^2),y->0],x->0]
0
In[3]:= Limit[(x^2)(m x)/(x^2+(m^2)(x^2)),x->0]
0
In[4]:= Limit[Limit[((m y) y)/(m y +y^2),y->0],x->0]
0
We see that the iterated limits and directional limits corresponding to the given family of
lines and parabolas coincide and are all zero. This leads us to suspect that the limit of the
function may be zero. To confirm this, we transform to polar coordinates and find the limit:
In[5]:= Limit[Limit[((r^2) (Cos[a]^2) (r) (Sin[a]))/((r^2) (Cos[a]^2) + 
                           (r^2) (Sin[a]^2)),r->0],a->0]
0
Therefore we conclude that the limit of the function is zero at the point (0,0).
This is an example where, as a last resort, we had to transform to polar coordinates. In the
above examples we used families of lines and parabolas, but other curves can be used. The

change to polar coordinates can be crucial in determining limits of functions of several
variables. As we have seen, there are sufficient criteria to show that a function has no limit at
a point. However, we do not have necessary and sufficient conditions to ensure the existence
of the limit.
Exercise 1-18. Find 
for the function  f: R2® R defined by:
In[1]:= Limit[Limit[y^2(x-1)^2/(y^2+(x-1)^2),x->1],y->0]
0
In[2]:= Limit[Limit[y^2(x-1)^2/(y^2+(x-1)^2),y->0],x->1]
0
In[3]:= Limit[(m x)^2(x-1)^2/((m x)^2+(x-1)^2),x->1]
0
In[4]:= Limit[(m x)(x-1)^2/((m x)+(x-1)^2),x->1]
0
We see that the iterated and directional limits coincide. We calculate the limit by
converting to polar coordinates:
In[5]:= Limit[Limit[(r^2 Sin[a]^2) (r Cos[a]-1)^2/((r^2 Sin[a]^2) +
                            (r Cos[a]-1)^2),r->1],a->0]
0
The limit is zero at the point (1,0).

1.6 CONTINUITY IN SEVERAL VARIABLES
A function  
  is said to be continuous at the point  
 if:
Exercise 1-19. Let the function f: R2® R be defined by:
 
 
Find
and study the continuity of f.
The only problematic point is the origin. We will analyze the continuity of the function
at the origin by calculating its limit there.
In[1]:= Limit[Limit[(x^3+y^3)/(x^2+y^2),x->0],y->0]
0
In[2]:= Limit[Limit[(x^3+y^3)/(x^2+y^2),y->0],x->0]
0
In[3]:= Limit[(x^3+(m x)^3)/(x^2+(m x)^2),x->0]
0
We see that the iterated and the linear directional limits coincide. We try to calculate the
limit by converting to polar coordinates:
In[4]:=Limit[Limit[((r 
Cos[a])^3+(r 
Sin[a])^3)/((r 
Cos[a])^2+(r
Sin[a])^2),                              r->0],a->0]
0
Exercise 1-20. Define the function 
 by

 
 if 
 and 
 
 
and study its continuity at the point (1,2).
In[1]:= Limit[Limit[(x^2+2y),x->1],y->2]
5
In[2]:= Limit[Limit[(x^2+2y),y->2],x->1]
5
We see that if the limit at (1,2) exists, then it should be 5. But the function has the value
0 at the point (1,2). Thus, the function is not continuous at the point (1,2).
Exercise 1-21. Consider the function 
 defined by:
 
 if 
 and  
 
 
Study the continuity of f at the point (0,0).
In[1]:= Limit[Limit[(1-Cos[x])Sin[y]/(x^3+y^3),x->0],y->0]
0
In[2]:= Limit[Limit[(1-Cos[x])Sin[y]/(x^3+y^3),y->0],x->0]
0
In[3]:= Limit[(1-Cos[x])Sin[m x]/(x^3+(m x)^3),x->0]

   m
–––-
       3
2 (1 + m )
We see that the limit at (0,0) does not exist, as there are different directional limits for
different directions. Thus, the function is not continuous at (0,0). At the rest of the points
in the plane, the function is continuous.
 

Chapter 2.
NUMERICAL SERIES AND POWER SERIES
This chapter demonstrates the wide range of features that Mathematica offers which can be
used to treat numerical series. These include the determination of the radius of convergence
of a power series, summation of convergent series, alternating series and so on.

2.1 SERIES. CONVERGENCE CRITERIA
We distinguish between numerical series which have non-negative terms and series which
have alternating terms. Some examples of the more classical criteria to determine whether
a series of non-negative terms converges or diverges will be presented first, then we will
go on to analyze alternating series.

2.2 NUMERICAL SERIES WITH NON-NEGATIVE
TERMS
Among the most common of the convergence criteria is the ratio test or d’Alembert
criterion, which reads as follows:
is convergent if
is divergent if
If the limit is 1, we don’t know whether the series converges or diverges.
Another widely used criterion is the Cauchy criterion or root test, which reads as
follows:
is convergent if
is divergent if
Again, if the limit is 1, we cannot say whether the series diverges or converges.
If a limit of 1 is obtained in both the ratio and root test, we can often use the criterion
of Raabe or Duhamel, which reads as follows:
is convergent if
is divergent if

However, if the limit is 1, we still cannot conclude anything about the convergence or
divergence of the series.
Another useful criterion is the following:
 and 
 either both diverge or both converge.
Other criteria such as Gauss majorization, comparison tests and so on can also be
implemented via Maple. We will see some examples below:
Exercise 2-1. Study the convergence and, if possible, find the sum of the following
series:
 
We will apply the ratio test:
In[1]:= a[n_]=(n+1)/(n(n+2)(n+3));
In[2]:= Limit[a[n+1]/a[n],n->Infinity]
1
We see that the limit is 1, so we can’t yet say anything about the convergence or
divergence of the series. We will apply Raabe’s criterion:
In[3]:= Limit[n(1-a[n+1]/a[n]),n->Infinity]
2
As the limit is greater than 1, the series converges and will be summable:
In[4]:= <<Algebra`SymbolicSum`

In[5]:= Sum[a[n],{n,1,Infinity}]
17
–
36
Exercise 2-2. Study the convergence and, if possible, find the sum of the following
series:
           
           
We apply the ratio test to the first series:
In[1]:= a[n_]=n/2^n;
In[2]:= Limit[a[n+1]/a[n],n->Infinity]
1
-
2
The limit is less than 1, so the series converges. We find its sum:
» maple(‘sum(a(n),n=1..+infinity)’)
In[3]:= Sum[a[n],{n,1,Infinity}]
2
We apply the ratio test to the second series:
In[4]:= a[n_]=n^n/n!;

In[5]:= Limit[a[n+1]/a[n],n->Infinity]
Series::esss:
  Essential singularity encountered in
         1           3
   Gamma[- + 1 + O[n] ].
         n
Series::esss:
  Essential singularity encountered in
         1           3
   Gamma[- + 2 + O[n] ].
         n
Series::esss:
  Essential singularity encountered in
         1           3
   Gamma[- + 1 + O[n] ].
         n
General::stop:
  Further output of Series::esss
    will be suppressed during this calculation.
            1 + n
     (1 + n)      n!
Limit[–––––, n -> Infinity]
        n
       n  (1 + n)!
This limit has not been resolved by Mathematica. As the expression contains factor
numerator 
and 
denominator, 
we 
load 
the 
package
DiscreteMath`CombinatorialSimplification` calculate the limit and try again.
In[6]:= <<DiscreteMath`CombinatorialSimplification`

In[7]:= Limit[a[n+1]/a[n],n->Infinity]
Infinity::indet:
  Indeterminate expression ComplexInfinity + <<1>>
    encountered.
Infinity::indet:
  Indeterminate expression ComplexInfinity + <<1>>
    encountered.
Infinity::indet:
  Indeterminate expression ComplexInfinity + <<1>>
    encountered.
General::stop:
  Further output of Infinity::indet
    will be suppressed during this calculation.
            n
     (1 + n)
Limit[––—, n -> Infinity]
         n
        n
The limit remains problematic. Now we load the Numerical Math`NLimit` package
and try to calculate the limit order.
As the limit is greater than 1, the series diverges.
We apply the ratio test to the third series:
In[8]:= <<NumericalMath`Nlimit`
In[9]:= NLimit[a[n+1]/a[n],n->Infinity]
2.71828

As the limit is greater than 1 the series diverges and is not summable.
We apply the ratio test for the third series.
In[10]:= a[n_]=(n^n/((n!)(3^n)));
In[11]:= Limit[a[n+1]/a[n],n->Infinity]
Infinity::indet:
  Indeterminate expression ComplexInfinity + <<1>>
    encountered.
Infinity::indet:
  Indeterminate expression ComplexInfinity + <<1>>
    encountered.
Infinity::indet:
  Indeterminate expression ComplexInfinity + <<1>>
    encountered.
General::stop:
  Further output of Infinity::indet
    will be suppressed during this calculation.
            n
     (1 + n)
Limit[––—, n -> Infinity]
          n
       3 n
We have seen that the limit presents difficulties of calculation. Down hereafter we
use the function NLimit.
 
In[12]:=NLimit[a[n+1]/a[n],n->Infinity]

0.906094
 
The limit is less than 1, so the series is convergent.
Exercise 2-3. Study the convergence and, if possible, find the sum of the following
series:
 
p = parameter
We apply the ratio test to the first series:
In[1]:= a[n_]=(2n+3)/(n(n+1)(7^n));
In[2]:= Limit[a[n+1]/a[n],n->Infinity]
1
-
7
As the limit is less than 1, the series is convergent. We will calculate its sum. The result
that is returned will sometimes be complicated:
In[3]:= Sum[a[n],{n,1,Infinity}]
7 + 28 Log[6] - 28 Log[7]
––––––––-
           7
In[4]:= %//N
0.383397
Now we apply the ratio test to the second series:
  
  

In[5]:= a[n_]=n/(p^n);
In[6]:= Limit[a[n+1]/a[n],n->Infinity]
1
-
p
Thus, if p > 1, the series converges, and if p < 1, the series diverges. If p = 1, we get the
series with general term n, which diverges. For p greater than 1, we find the sum of the
series:
In[7]:= Sum[a[n],{n,1,Infinity}]
   1
–––-
    1 2
(1 - -)  p
    p
We apply the ratio test to the third series:
In[8]:=a[n_]=(n+p)!/(p!n!(p^n));
In[9]:= Limit[a[n+1]/a[n],n->Infinity]
1
-
p

Thus, if p > 1, the series converges, if p < 1, the series diverges and if p = 1, we get the
series with general term n + 1, which diverges.
In[10]:= Sum[a[n],{n,1,Infinity}]
                        1 -1 - p
                   (1 - -)       p Gamma[2 + p]
 p Gamma[2 + p]         p
-(––––—) + –––––––––-
     1 + p                    1 + p
––––––––––––––––
                     p p!
Exercise 2-4. Study the convergence and, if possible, find the sum of the following
series:
For the first series we apply the ratio test:
In[1]:= a[n_]=(1+1/n)^(-n^2);
In[2]:= Limit[(a[n])^(1/n),n->Infinity]
1
-
E
As the limit is less than 1, the series converges.
In[3]:=NSum[a[n],{n,1,Infinity}]
0.817419
   

We apply the ratio test to the second series:
In[4]:= a[n_]=(((n+1)/n)^(n+1)-(n+1)/n)^(-n);
In[5]:= Limit[(a[n])^(1/n),n->Infinity]
         1 + n     1 + n 1 + n -n 1/n
Limit[((-(–—) + (–—)     )  )   , n -> Infinity]
           n         n
As the exact boundary can not be obtained, Nlimit apply the function, which
provides an approximate limit:
In[6]:=NLimit[(a[n])^(1/n),n->Infinity]
0.581977
As the limit is less than 1, the series converges. The sum can be found with
Mathematica:
In[8]:= NSum[a[n],{n,1,Infinity}]
1.17459
Exercise 2-5. Study the convergence and, if possible, find the sum of the following
series:
For the first series, we apply the root test:
In[1]:= a[n_]=5/(2^n);
In[2]:= Limit[(a[n])^(1/n),n->Infinity]
   
   

1
-
2
As the limit is less than 1, the series is convergent:
In[3]:= Sum[a[n],{n,1,Infinity}]
5
Now we apply the root test to the second series:
In[4]:= a[n_]=(n^(1/n)-1)^n;
In[5]:= Limit[(a[n])^(1/n),n->Infinity]
0
As the limit is less than 1, the series is convergent, but neither the exact nor an accurate
approximate sum are calculable.
In[7]:= NSum[a[n],{n,1,Infinity}]
0.297597
Now we apply the root test to the third series:
In[8]:= a[n_]=((n^2+2 n+1)/(n^2+n-1))^(n^2);
In[9]:=Limit[(a[n])^(1/n),n->Infinity]
                  2  2
       1 + 2 n + n  n  1/n
Limit[((––––)  )   , n -> Infinity]
                 2
       -1 + n + n

The exact limit can not be calculated, but it is possible an approximation:
In[10]:= NLimit[(a[n])^(1/n),n->Infinity]
2.71828
 
As the limit is greater than 1, the series diverges.
Exercise 2-6. Study the convergence and, if possible, find the sum of the following
series:
 
 
We apply the root test:
In[1]:= a[n_]=(Tan[p+q/n])^n;
In[2]:= Limit[(a[n])^(1/n),n->Infinity]
              q n 1/n
Limit[(Tan[p + -] )   , n -> Infinity]
              n
The exact limit can not be calculated. We will try to find the approximate:
NLimit::notnum:
   The expression Tan[p + 1. q]
    is not numerical at the point n == 1..
Not is it possible to calculate the approximate limit. We will try to simplify as much
as possible expressions.
In[4]:= PowerExpand[(a[n])^(1/n)]//Simplify
       q

Tan[p + -]
       n
In[5]:= Limit[%%,n->Infinity]
Tan[p]
Then, for values of p such that tan(p)< 1 the series converges. These values are 0 < p <
Pi/4. And for values of p such that tan(p)> 1 the series diverges. These values are Pi/4 < p
< Pi/2.
Exercise 2-7. Study the convergence and, if possible, find the sum of the following
series:
p = parameter > 0
 
We apply the criterion that the series 
 and 
 either both diverge or
both converge.
In[1]:= a[n_]=1/(n Log[n]);
In[2]:= b[n_]=(2^n)a[2^n]
  1
––-
    n
Log[2 ]
In[3]:= c[n_]=1/(n Log[2])
1
––—
n Log[2]
     
   

As the general term is a constant multiple of the general term of the divergent harmonic
series, this series diverges, and we conclude that the original series diverges.
Let us now apply the same criteria to the second series:
In[4]:= a[n_]=1/(n (Log[n])^p);
In[5]:= b[n_]=(2^n)a[2^n]
    n  -p
Log[2 ]
In[6]:= c[n_]=1/(n Log[2])^p
-p
(n Log[2])
In[7]:= PowerExpand[%]
   1
–––-
p       p
n  Log[2]
When p < 1, this series dominates the series with general term n-p = 1/np.  Thus the
initial series also diverges.
When p > 1, this series is dominated by the convergent series with general term n-p =
1/np. Thus the initial series also converges.
When p = 1, the series reduces to the series studied above, i.e. it diverges.
Exercise 2-8. Study the convergence and, if possible, find the sum of the following
series:

We will begin by studying the second series. We try to apply the ratio, Raabe and
root tests:
In[1]:= a[n_]=1/(1+n^(1/2))^2;
In[2]:= Limit[a[n+1]/a[n],n->Infinity]
1
In[3]:= Limit[n(1-a[n+1]/a[n]),n->Infinity]
1
In[4]:= Limit[a[n]^(1/n),n->Infinity]
1
Thus all the limits are 1. Therefore, at the moment, we cannot conclude anything about
the convergence of the series.
We now compare our series with the divergent harmonic series by finding the limit of
the quotient of the respective general terms:
In[5]:= Limit[a[n]/(1/n),n->Infinity]
1
As the limit is greater than zero, the initial series is also divergent.
We will now analyze the first series of the problem directly, comparing it with the
convergent series with general term 1/n3  by examining the limit of the quotient of the
general terms:
In[6]:= Limit[a[n]/(1/n^3),n->Infinity]
1
 
     

As the limit is greater than 0, the initial series is also convergent:
In[7]:= <<Algebra`SymbolicSum`
In[8]:= Sum[a[n],{n,1,Infinity}]
 4
Pi
– + Zeta[3] + 2 Zeta[5]
30
Now, we try to approximate the result:
In[9]:= %//N
6.52288
We could have tried to determine whether the first series converges or diverges by using the
ratio, root and Raabe criteria:
In[1]:= Limit[a[n+1]/a[n],n->Infinity]
1
In[2]:= Limit[n(1-a[n+1]/a[n]),n->Infinity]
3
The root and ratio tests tells us nothing, but since the limit is greater than 1, the Raabe
criterion tells us that the series converges.

2.3 ALTERNATING NUMERICAL SERIES
We now consider numerical series that have alternating positive and negative terms.
A series åa(n) is absolutely convergent if the series å |a(n)| is convergent. As the series
of moduli is a series of positive terms, we already know how to analyze it.
Every absolutely convergent series is convergent.
Apart from the criteria described earlier, there are, among others, two classical criteria
that allow us to analyze the nature of alternating series, which will allow us to resolve
most convergence problems concerning alternating series.
The Dirichlet test says that if the sequence of partial sums of åa(n) is bounded and
{b(n)} is a decreasing sequence that has limit 0, then the series åa(n)b(n) is convergent.
Abel’s test says that if åa(n) is convergent and {b(n)} is a monotone convergent
sequence, then the series åa(n)b(n) is convergent.
Exercise 2-9. Study the convergence of the following series:
 
This is an alternating series. Let us consider the series of moduli and analyze its
character:
In[1]:= a[n_]=1/(2n^2+1)
  1
––—
      2
1 + 2 n
We apply to this series of positive terms the criteria of comparison of the second kind,
comparing with the convergent series with general term 1/n2 :

In[2]:=Limit[a[n]/(1/n^2),n->Infinity]
1
-
2
As the limit is greater than zero, the given series of positive terms is convergent, so the
initial series is absolutely convergent and, therefore, convergent.
Exercise 2-10. Study the convergence of the following series:
 
           Defining   
  and 
, we have that 
 has bounded
partial sums and {b(n)} is monotone decreasing with limit 0.
Using the Dirichlet test we conclude that the series is convergent.
For the second series we similarly proceed as follows.
Defining   
  and 
, we have that 
 has bounded partial
sums and 
 is monotone decreasing with limit 0.
Using the Dirichlet test we conclude that the series is convergent.
 
                

2.4 POWER SERIES
Given the power series 
, the most presssing issue is to calculate the range of
convergence, i.e., the range of values of x for which the series is convergent.
The most common convergence criteria that we use are the root and ratio tests applied to
the series of moduli (absolute values). If we can show the series is convergent then the
original series is absolutely convergent and hence convergent.
Exercise 2-11. Study the range of convergence of the following power series:
We apply the ratio test:
In[1]:= a[n_]=4^(2n)(x-3)^n/(n+2)
2 n         n
4    (-3 + x)
––––—
   2 + n
In[2]:= Limit[a[n+1]/a[n],n->Infinity]
16 (-3 + x)
The series will be convergent when |16 (- 3 + x) | < 1:
In[3]:= Solve[%==1,x]
      49
{{x -> —}}
      16

In[4]:= Solve[%%==-1,x]
      47
{{x -> —}}
      16
Thus, the condition 
 is equivalent to the following:
We already know that for values of  in the previous interval the series is convergent.
Now we need to analyze the behavior of the series at the end points of the interval. We
first consider x = 49/16:
In[5]:= a1[n_]=a[n] /. x->49/16
 1  n  2 n
(—)  4
16
–––-
 2 + n
We first apply convergence tests for non-negative series to see if any of them determine
the convergence or divergence of the series.
In[6]:= Limit[a1[n+1]/a1[n],n->Infinity]
1
In[7]:= Limit[n(1-a1[n+1]/a1[n]),n->Infinity]
1
In[8]:= Limit[PowerExpand[a1[n]^(1/n)],n->Infinity]
1

The ratio, Raabe and root tests do not solve the problem. Next we apply the criterion of
comparison of the second kind, comparing the series of the problem with the divergent
harmonic series with general term 1/n:
In[9]:= NLimit[PowerExpand[a1[n]/(1/n)],n->Infinity]
1.
As the limit is greater than zero, the series is divergent.
We now analyze the behavior of the series at the other end point x = 47/16:
In[10]:= a2[n_]=a[n] /. x->47/16
  1   n  2 n
(-(—))  4
  16
––––-
   2 + n
Simplifying we have to analyze the alternating series
.
The series with general term (- 1)n has bounded partial sums, and the sequence with
general term 1 / (n + 2) is decreasing toward 0. Then, by the Dirichlet test, the alternating
series converges. Therefore the interval of convergence of the power series is the half-closed
interval [47/16, 49/16).
Exercise 2-12. Study the range of convergence of the following power series:
We apply the root test:
In[1]:= a[n_]=x^(2n+1)/(-5)^n

1 + 2 n
x
––—
    n
(-5)
In[2]:= Limit[PowerExpand[a[n]^(1/n)],n->Infinity]
 2
-x
–
5
The series is absolutely convergent when |-x ^ 2/5| < 1.
The condition |-x ^ 2/5| < 1 is equivalent to -Sqrt (5) < x < Sqrt (5). Thus, we have
determined a possible interval of convergence of the power series. We will now analyze
the end points:
In[3]:= Solve[x^2/5==1,x]
{{x -> -Sqrt[5]}, {x -> Sqrt[5]}}
In[4]:= Plot[{1,x^2/5},{x,-3,3}]

Figure 2-1
Figure 2.1 clarifies that the condition | -x ^ 2/5 | <1 is equivalent to -sqrt (5) <x
<Sqrt (5). Then we have determined the possible range of convergence of the power
series. Now analyze the ends starting wih x=-sqrt(5).
 
In[5]:= a1[n_]=PowerExpand[a[n] /. x->-Sqrt[5]]//Simplify
     2 n  1/2 + n
 (-1)    5
-(–––––-)
          n
      (-5)
Have the simplified series with general term (-1)n Sqrt (5), which obviously is a
divergent alternating series.
We now analyze the convergence of the series in the other endpoint x = sqrt (5).
 
In[6]:= a2[n_]=PowerExpand[a[n] /. x->Sqrt[5]]//Simplify
1/2 + n
5
––—
    n
(-5)
Have the simplified series with general term (-1)n Sqrt (5), which obviously is a
divergent alternating series.
 
Therefore the range of convergence of the power series is -sqrt (5) <x <Sqrt (5)
 
 Both series are obviously divergent alternating series. Therefore, the interval of
convergence of the power series is the open interval 


2.5 POWER SERIES EXPANSIONS AND FUNCTIONS
A local approximation of a real function of a real variable at a point replaces the
definition of the function in a neighborhood of the point by a simpler function. The most
commonly used local approximations replace an arbitrary function 
 by a polynomial 
 (a truncated power series), so that for any  close to the point, 
 is close to 
.

2.6 TAYLOR AND LAURENT EXPANSIONS
Taylor’s theorem gives us a way of approximating a function 
 by a polynomial at a
point 
. The series that is truncated to give such a polynomial is called the Taylor
series of the function 
 at the point 
. The Taylor series of 
 at 
 is called
the MacLaurin series of 
.
Taylor’s theorem says that if 
 is an 
 times differentiable function defined on
an interval that contains the point , then 
 can be approximated in a neighborhood of 
 by the following polynomial:
where z is a number between a and x.
The above expression is the Taylor series expansion of 
 at the point 
. The last
term of the expression is the remainder term, and represents a measure of the error of the
approximation.
The Laurent expansion allows a finite number of negative powers in the series
expansion of a function.
The Padé expansion approximates the function as a ratio of polynomials whose
numerator and denominator have fixed degrees m and n.
The Chebyshev expansion approximates the function using Chebyshev polynomials.
The Chebyshev-Padé expansion mixes both types.
There are commands that allow you to specify which type of expansion should be used.
The syntax is as follows:
series(f,var=a)                                  Returns the Taylor series expansion of the function f
at the point a
Normal(expression)             Returns the Taylor series expansion of the expression
without rest

Exercise 2-13. Find the Taylor series up to 13th order of sinh (x) at the point x = 0. Also
find the Taylor expansion of 1 /(1+x) up to 10th order at the point x=0. Find the
corresponding Laurent and Euler-McLaurin series. Find the Chebychev-Padé
approximation of degree (4,3) in the interval [0,1].
In[1]:= Series[Sinh[x],{x,0,13}]
    3    5      7       9        11
   x    x      x       x        x
x + — + – + –- + –– + ––— +
   6    120   5040   362880   39916800
    13
   x             14
–––- + O[x]
6227020800
In[2]:= Series[1/(1+x),{x,0,10}]
       2    3    4    5    6    7    8    9    10
1 - x + x  - x  + x  - x  + x  - x  + x  - x  + x   +
    11
O[x]
Exercise 2-14. Find the Laurent expansion of 1 / (x sin (x)) at the point x = 0 up to
degree 10. Also find the Padé approximation of degree (3,4) at the same point and the
Taylor expansion of log (x) at the point x = 2 up to degree 5.
In[1]:= Series[Sinh[x],{x,0,13}]

    3    5      7       9        11
   x    x      x       x        x
x + — + – + –- + –– + ––— +
   6    120   5040   362880   39916800
      
    13
   x             14
–––- + O[x]
6227020800
In[2]:= Series[1/(1+x),{x,0,10}]
        2    3    4    5    6    7    8    9    10
1 - x + x  - x  + x  - x  + x  - x  + x  - x  + x   +
    11
O[x]
Exercise 2-16. Find the Taylor expansion of the function 1 /(2-x) at the point x = 1 up to
order 10. Also find the Taylor expansion of sin(x) at pi/2 up to order 8, and the same for
the function log (x) at the point x = 2 up to degree 5.
In[1]:= Series[1/(2-x),{x,1,10}]
                       2           3           4
1 + (-1 + x) + (-1 + x)  + (-1 + x)  + (-1 + x)  +
        5           6           7           8
(-1 + x)  + (-1 + x)  + (-1 + x)  + (-1 + x)  +
        9           10            11
(-1 + x)  + (-1 + x)   + O[-1 + x]
In[2]:= Normal[%]

       2           3           4           5
(-1 + x)  + (-1 + x)  + (-1 + x)  + (-1 + x)  +
        6           7           8           9
(-1 + x)  + (-1 + x)  + (-1 + x)  + (-1 + x)  +
        10
(-1 + x)   + x
In[3]:= Simplify[%]
              2       3        4        5        6
1 - 5 x + 25 x  - 70 x  + 130 x  - 166 x  + 148 x  -
    7       8      9    10
91 x  + 37 x  - 9 x  + x
In[4]:= Series[Sin[x],{x,Pi/2,8}]
    -Pi     2    -Pi     4    -Pi     6
   (– + x)    (– + x)    (– + x)
     2            2            2
1 - –––- + –––- - –––- +
       2            24          720
  -Pi     8
(– + x)
  2            -Pi     9
–––- + O[– + x]
  40320         2
In[5]:= Normal[%]//Simplify
    -Pi     2    -Pi     4    -Pi     6    -Pi     8
   (– + x)    (– + x)    (– + x)    (– + x)
     2            2            2            2
1 - –––- + –––- - –––- + –––-
       2            24          720         40320

In[6]:= N[%]//Simplify
                                        2
0.0000247373 + 0.999843 x + 0.000447261 x  -
          3               4               5
0.167421 x  + 0.00083204 x  + 0.00770694 x  +
             6                7                 8
0.000324584 x  - 0.000311666 x  + 0.0000248016 x
In[7]:= Series[Log[x],{x,2,5}]
                         2           3           4
        -2 + x   (-2 + x)    (-2 + x)    (-2 + x)
Log[2] + –– - ––– + ––– - ––– +
          2          8          24          64
         5
(-2 + x)             6
––– + O[-2 + x]
   160
Normal[%]//Simplify
                 2      3      4    5
 137    5 x   5 x    5 x    5 x    x
-(–) + – - –- + –- - –- + – + Log[2]
 60      2     4      12     64    160 
 
Exercise 2-17. Find the Maclaurin polynomial of degree 3 of the function arctan (x) and
the same for function x ^ (a> 0) Grade 7. Find the Taylor expansion x = 2 grade 4 for a
generic function f (x).
 
In[1]:= Series[ArcTan[x],{x,0,3}]

    3
   x        4
x - — + O[x]
   3
In[2]:= Series[a^x,{x,0,7}]
                    2  2         3  3         4  4
              Log[a]  x    Log[a]  x    Log[a]  x
1 + Log[a] x + –––- + –––- + –––- +
                  2            6            24
      5  5         6  6         7  7
Log[a]  x    Log[a]  x    Log[a]  x        8
–––- + –––- + –––- + O[x]
   120          720          5040
In[3]:= Series[f[x],{x,2,4}]
                                      2
                       f”[2] (-2 + x)
f[2] + f’[2] (-2 + x) + –––––- +
                              2
 (3)            3    (4)            4
f   [2] (-2 + x)    f   [2] (-2 + x)             5
–––––— + –––––— + O[-2 + x]
        6                  24

Chapter 3.
DERIVATIVES AND APPLICATIONS. ONE AND
SEVERAL VARIABLES

3.1 THE CONCEPT OF THE DERIVATIVE
The derivative of a real function at a point is the instantaneous rate of change of that
function in a neighborhood of the point; i.e., it is a measure of how the dependent variable
changes as a result of a small change in the independent variable.
Geometrically, the derivative of a function at a point represents the gradient of the
tangent to the function at the point. The origin of the idea of the derivative comes
precisely from the attempt to draw the tangent line at a given point on a curve.
A function 
 defined in a neighborhood of a point 
 is differentiable at  if the
following limit exists:
The value of the limit, if it exists, is denoted by 
, and is called the derivative of the
function f at the point a. If  is differentiable at every point of its domain, it is simply said
to be differentiable.
The continuity of a function is a necessary condition for its differentiablity, and all
differentiable functions are continuous.
Exercise 3-1. Study the differentiability of the function:
 
 if 
 and 
 if 
 
First of all, we study the differentiability at the point 
:
In[1]:= Limit[(h Sin[1/h] - 0)/h,h->0]
Interval[{-1, 1}]
The limit does not exist, since in any neighborhood of 0 the function 
 takes both

values - 1 and 1 infinitely many times. Hence Mathematica responds to the calculation of
this limit with -1..1.
Let’s see what happens at a non-zero point 
:
In[1]:= f[x_]=x Sin[1/x];
In[2]:= Limit[(f[a+h]-f[a])/h,h->0]
     1
 Cos[-]
     a         1
-(––) + Sin[-]
   a           a
Thus we have found the value of the derivative for any non-zero point 
. The
function is plotted in Figure 3-1:
In[3]:= Plot[f[x],{x,-1/10,1/10}]
Figure 3-1
Exercise 3-2. Study the differentiability of the function:
 
 if 
 and 
 if 
 
In[1]:= f[x_]=x^3/Abs[x];

In[2]:=<<NumericalMath`NLimit`
In[3]:= NLimit[(f[0+h]-0)/h,h->0,Direction-> 1]
0.
In[4]:= NLimit[(f[0+h]-0)/h,h->0,Direction->-1]
0.
Thus we see that the derivative at zero exists and has the value zero. The function is
plotted in Figure 3-2, from which we see that it appears to be differentiable at all points of
its domain:
In[3]:= Plot[f[x],{x,-1/10,1/10}]
Figure 3-2
In[5]:= f’[x]
   2     3
3 x     x  Abs’[x]
–– - –––-
Abs[x]          2
         Abs[x]

3.2 CALCULATING DERIVATIVES
Mathematica provides several commands that allow you to calculate derivatives. We have:
F’[x]                            Is the derivative of the function f with respect to x
D[f[x],x]                      is the derivative of the function f with respect to x
          
D[f[x],{x,n}]                            is the nth derivative of the function f with respect to x
D[expresion],variable]                    
is the derivative of the expression with respect to x
          
D[expresion],{variable,n}]              
                                              is the nth derivative of the expression with respect to x
Exercise 3-3. Calculate the derivative with respect to x of the following functions:
 
 
In[1]:= D[Log[Sin[2 x]],x]
2 Cot[2 x]
In[2]:= D[x^Tan[x],x]
Tan[x]              2    -1 + Tan[x]
x       Log[x] Sec[x]  + x            Tan[x]
In[3]:= Factor[%]

-1 + Tan[x]                 2
x            (x Log[x] Sec[x]  + Tan[x])
In[4]:= D[(4/3) Sqrt[(x^2-1)/(x^2+2)],x]//Simplify
         4 x
–––––––—
          2
    -1 + x         2 2
Sqrt[––-] (2 + x )
         2
    2 + x
In[5]:= D[Log[x+Sqrt[x^2+1]],x]//Simplify
    1
––––
         2
Sqrt[1 + x ]
Exercise 3-4. Calculate the nth derivative of the following functions:
 
In[1]:=f[x_]=1/x;
In[2]:= D[f[x],{x,1}]
 -2
-x

In[3]:= D[f[x],{x,2}]
2
—
3
x
In[4]:= D[f[x],{x,3}]
-6
—
4
X
In[5]:= D[f[x],{x,4}]
24
—
5
x
We see from the pattern here that the nth derivative is given by 
 .
In[6]:= g[x_]=E^(x/2);
In[7]:= {g’[x],g”[x],g”’[x],g””[x],g””’[x]}
 x/2   x/2   x/2   x/2   x/2
 E     E     E     E     E

{–-, –-, –-, –-, –-}
 2     4     8     16    32
Thus the nth derivative is 
 .
In[8]:= g[x_]=(1+x)/(1-x);
In[9]:= {g’[x],g”[x],g”’[x],g””[x],g””’[x]}//Together
    2         -4         12         -48
{–––, –––, –––, –––,
        2          3          4          5
(-1 + x)   (-1 + x)   (-1 + x)   (-1 + x)
   240
–––}
        6
(-1 + x)
Thus, the nth derivative is given by 
 .

3.3 TANGENTS, ASYMPTOTES, CONCAVITY,
CONVEXITY, MAXIMA AND MINIMA, INFLECTION
POINTS AND GROWTH
If  is a function which is differentiable at 
, then 
 is the slope of the tangent line
to the curve 
 at the point 
. The equation of the tangent will be 
.
The horizontal asymptotes of the curve 
 are limit tangents, as 
, which
are horizontal. They are defined by the equation 
The vertical asymptotes of the curve 
 are limit tangents, as 
, which
are vertical. They are defined by the equation 
, where 
 is a value such that  
.
The oblique asymptotes to the curve 
 at the point 
 have the equation 
, where
  and  
.
 
If  is a function for which 
 and 
 both exist, then, if 
 and 
, the function has a local maximum at the point 
.
If  is a function for which 
 and 
 both exist, then, if 
 and 
, the function  has a local minimum at the point 
.
If  is a function for which 
, 
 and 
 exist, then, if 
 and 
 and 
, the function has a turning point at the point 
.
If  is differentiable, then the values of  for which the function  is increasing are
those for which 
 is greater than zero.
If  is differentiable, then the values of  for which the function  is decreasing are

those for which 
 is less than zero.
If  is twice differentiable, then the values of  for which the function  is concave are
those for which 
 is greater than zero.
If  is twice differentiable, then the values of  for which the function  is convex are
those for which 
 is less than zero.
Exercise 3-5. Find the equation of the tangent to the curve:
 
 at 
.
 
Also find the x for which the tangents to the curve 
 are horizontal and
vertical. Find their asymptotes.
In[1]:= f[x_]=2x^3+3x^2-12x+7;
In[2]:= f’[x]
              2
-12 + 6 x + 6 x
In[3]:= f’[-1]
-12
In[4]:= f[-1]
20
Thus the slope of the tangent line at the point 
 is 
, and the function at 
 has the value 20. Therefore the equation of the tangent to the curve at the point 
 is:

We plot the curve and its tangent on the same axes (see Figure 3-3):
In[5]:= Plot[{f[x],f’[-1](x+1)+20},{x,-4,4}]
Figure 3-3
 
To calculate the horizontal tangent to the curve 
, we find the values 
 for
which 
. The equation of this tangent will then be 
.
 
To calculate the vertical tangent to the curve 
, we find the values 
 for which 
. The equation of this tangent will then be 
.
In[6]:= g[x_]=(x^2-x+4)/(x-1);
In[7]:=Together[g’[x]]
           2
-3 - 2 x + x
––––-
         2
 (-1 + x)

In[8]:= Solve[g’[x]==0,x]
{{x -> -1}, {x -> 3}}
In[9]:= g[-1]
-3
In[10]:= g[3]
5
The two horizontal tangents will have equations:
, that is, 
 
, that is, 
The horizontal tangents are not asymptotes because the corresponding values of 
 are
finite (they are - 1 and 3).
We can represent, together with the function and on the same axes (Figure 3-4)
In[11]:= Plot[{g[x],g’[-1](x+1)-3,g’[3](x-3)+5},{x,-5,5}]

Figure 3-4
The horizontal tangents are not asymptotes because the values of x0 are finite (are -1
and 3).
We now find the vertical tangents. To do this, we calculate the values of  for which 
 (i.e. values for which the denominator of 
is zero, but does not cancel with the
numerator):
In[12]:= Solve[x-1==0,x]
{{x -> 1}}
Therefore, the vertical tangent has equation 
.
For 
, the value of 
 is infinite (see below), so the vertical tangent is a vertical
asymptote.
In[13]:= g[1]
                                1
Power::infy: Infinite expression - encountered.
                                0
ComplexInfinity
As 
, there are no horizontal asymptotes.
Now let us see if there are any oblique asymptotes:
In[14]:= Limit[g[x]/x,x->Infinity]
1
In[15]:= Limit[g[x]-x,x->Infinity]
0
Thus, the diagonal 
 is an asymptote.

We plot the curve with its asymptotes and tangents:
Using the default command Plot,  we represent on the same axes (see Figure 3-5) the
curve whose equation is 
, the horizontal tangents with
equations  
 and 
, and the oblique asymptote with equation 
:
» Plot[{f[x]=(x^2-x+4)/(x-1), f[x]=-3, f[x]=5, f[x]=x}, {x,-20,20}]
Figure 3-5
Exercise 3-6. Find the asymptotes, maxima, minima, inflection points, intervals of
growth and decrease and intervals of concavity and convexity for the function:
 
 
In[1]:= f[x_]=x^3/(x^2-1);
In[2]:= Limit[f[x],x->Infinity]
Infinity
Therefore, there are no horizontal asymptotes. To see if there are any vertical
asymptotes, let us look at the values of x that make y infinite:

In[3]:= Solve[x^2-1==0,x]
{{x -> -1}, {x -> 1}}
Thus the vertical asymptotes are the lines x = 1 and x =-1. Now let us see if there are
any oblique asymptotes:
In[4]:= Limit[f[x]/x,x->Infinity]
1
In[5]:= Limit[f[x]-x,x->Infinity]
0
The line y = x is an oblique asymptote. Now we shall find the maxima and minima,
inflection points and intervals of concavity:
In[6]:= f’[x]
     4          2
 -2 x        3 x
–––- + ––-
      2 2         2
(-1 + x )    -1 + x
In[7]:= Together[%]
   2    4
-3 x  + x
–––-
      2 2
(-1 + x )
In[8]:= Solve[f’[x]==0,x]

{{x -> 0}, {x -> 0}, {x -> -Sqrt[3]}, {x -> Sqrt[3]}}
The first derivative vanishes at x = 0, x =Ö3 and x = -Ö3. These include maximum and
minimum candidates. To verify if they are maxima or minima, we find the value of the
second derivative at these points:
In[9]:= {f”[0],f”[-Sqrt[3]],f”[Sqrt[3]]}
  -3 Sqrt[3]  3 Sqrt[3]
{0, –––-, –––}
       2           2
Therefore, at  x= –Ö3 there is a maximum and at x =Ö3 there is a minimum. At x = 0
we know nothing:
In[10]:= f[Sqrt[3]]
3 Sqrt[3]
–––
   2
In[11]:= f[-Sqrt[3]]
-3 Sqrt[3]
–––-
   2
Therefore, the maximum point is (-Ö3, -2.5981) and the minimum point is 
(Ö3, 2.5981).
We will now analyze the points of inflection:
In[12]:= f”[x]//Together

        3
2 (3 x + x )
––––
       2 3
(-1 + x )
In[13]:= Solve[f”[x]==0,x]
{{x -> 0}, {x -> -I Sqrt[3]}, {x -> I Sqrt[3]}}
The only possible turning point occurs at x = 0, and as f (0) = 0, the possible turning
point is (0,0):
In[14]:= f”’[0]
-6
As the third derivative at x = 0 is non-zero, the origin really is a turning point.
The curve is increasing when y ‘ > 0, i.e., in the intervals (-¥-Ö3) and (Ö3,¥).
The curve is decreasing when y ‘ < 0, i.e., in the intervals (-Ö3,-1),  (-1,0),  (0,1) and (1,
Ö3).
The curve will be concave when y “> 0, i.e., in the intervals (-1,0) and (1, ¥ ).
The curve is convex when y “< 0, i.e. in the intervals (0,1) and (- ¥ , - 1).
The curve has a horizontal tangent at the three points at which the first derivative is
zero. The equations of the horizontal tangents are y = 0, y = -2.5981 and y = 2.5981.
The curve has vertical tangents at the points that make the first deriviative infinite.
These are x = 1 and x =-1. Therefore, the vertical tangents coincide with the two vertical
asymptotes.
We plot the curve together with its asymptotes (see Figure 3-6):

In[15]:= Plot[{f[x],f[x]=x},{x,-5,5}]
Figure 3-6
 
We can also represent the curve, its asymptotes and its horizontal and vertical tangents
in the same graph (Figure 3-7):
In[16]:=Plot[{f[x]=x^3/(x^2-1), f[x]=3Sqrt[3]/2, f[x]=-3Sqrt[3]/2,}, {x,- 5,5}]
Figure 3-7
 
Exercise 3-7. Find the asymptotes, maxima, minima, inflection points, intervals of
growth and decrease and intervals of concavity and convexity for the function:
 
 
 

In[1]:= f[x_]=(2x^2-3x+5)/(3x^2+5x-12);
In[2]:= Limit[f[x],x->Infinity]
2
-
3
The horizontal asymptote has equation y = 2/3. To find the vertical asymptotes seek
the values of x that make f (x) infinite.
In[3]:= Solve[3x^2+5x-12==0,x]
                 4
{{x -> -3}, {x -> -}}
                 3
The vertical asymptotes are x=-3 y x=4/3
In[4]:= Limit[f[x]/x,x->Infinity]
0
In[5]:= Limit[f[x]-x,x->Infinity]
-Infinity
There are not oblique asymptotes. We will now calculate the maximum, minimum and
inflection points
In[6]:= f’[x]
                         2
 (5 + 6 x) (5 - 3 x + 2 x )        -3 + 4 x
-(––––––––—) + –––––-
                    2 2                       2

    (-12 + 5 x + 3 x )         -12 + 5 x + 3 x
In[7]:= Together[%]
                2
11 - 78 x + 19 x
––––––-
               2 2
(-12 + 5 x + 3 x )
In[8]:= Solve[f’[x]==0,x]
      78 - 8 Sqrt[82]         78 + 8 Sqrt[82]
{{x -> –––––}, {x -> –––––}}
            38                      38
In[9]:= {f”[(78-8 Sqrt[82])/38],f”[(78+8 Sqrt[82])/38]}//N
{-0.57703, 0.0241084}
In[10]:= Solve[f’[x]==0,x]//N
{{x -> 0.146235}, {x -> 3.95903}}
In x = 0.146235 curve has a maximum at x = 3.95903 and the curve has a minimum
In[11]:= {f[0.146235],f[3.95903]}
{-0.410906, 0.446409}
The maximum is on the point (0.146235, -0.410906) and the minimum is at point
(3.95903,0.446409). We will now calculate the turning points.
In[12]:= f”[x]//Together
                    2       3
2 (413 - 99 x + 351 x  - 57 x )
––––––––––-

                     2 3
     (-12 + 5 x + 3 x )
The curve is increasing if y ‘>0, that is, in intervals (-¥, -3), (-3, 0.14)  and  (3.95,  ¥).
 
The curve is decreasing if y ‘<0, that is, in intervals (0.14,4 / 3) and (4 / 3,3.95).
The curve is concave if y ”> 0, that is, in intervals (-¥, -3) and (4/3, 6.06)
The curve is convex if and ‘<0, that is, in intervals (-3.4 / 3) and (6.06, ¥)
In[13]:= Solve[f”[x]==0,x]//N
{{x -> 6.06844}, {x -> 0.0447281 - 1.09178 I},
 {x -> 0.0447281 + 1.09178 I}}
In[14]:= f”’[6.06844]
-0.00199857
In[15]:= f[6.06844]
0.469233
Then there is a turning point coordinates (6.06844,0.469233). Let us now represent the
curve with their asymptotes (Figure 3-8).
In[16]:= Plot[{f[x]=(2x^2-3x+5)/(3x^2+5x-12),g[x]=2/3},{x,-15,15}]

Figure 3-8
 
Exercise 3-8. Find the asymptotes, maxima, minima, inflection points, intervals of
growth and decrease and intervals of concavity and convexity for the function:
This curve can be set as y = x sqrt [(x-1) / (x + 1)]. But as the square root has two
signs, first we represent the curve with a positive sign and then on the same graph represent
the curve with a negative sign.
In[1]:= f[x_]=x Sqrt[(x-1)/(x+1)];
In[2]:= Limit[f[x],x->Infinity]
Infinity
No horizontal asymptotes. Presents the vertical asymptote x = -1, which is the value
that make f(x) infinite.
In[3]:= Limit[f[x]/x,x->Infinity]
1
In[4]:= Limit[f[x]-x,x->Infinity]
-1
Oblique asymptote has equation y = x-1. Now we calculate the maximum, minimum

and inflection points.
In[5]:= f’[x]//Simplify
    -1 + x              x
Sqrt[––] + –––––––
    1 + x          -1 + x         2
              Sqrt[––] (1 + x)
                   1 + x
In[6]:= Together[%]
              2
    -1 + x + x
–––––––
    -1 + x         2
Sqrt[––] (1 + x)
    1 + x
In[7]:= Solve[f’[x]==0,x]
     -1 - Sqrt[5]         -1 + Sqrt[5]
{{x -> ––––}, {x -> ––––}}
           2                    2
Solve[f’[x]==0,x]//N
{{x -> -1.61803}, {x -> 0.618034}}
{f”[-1.61803],f”[0.618034]}
{-2.84437, 0. - 1.75789 I}

           We see that at the point of abscissa x = -1.61803 no maximum.
In[8]:= f”[x]//Simplify
     -2 + x
––––––—
-1 + x 3/2        4
(––)    (1 + x)
1 + x
In[9]:= Solve[f”[x]==0,x]
{{x -> 2}}
In[10]:= f”’[2]
   1
–––
9 Sqrt[3]
We see that at the point of abscissa x = 2 is a turning point. If we represent the
positive part of the curve we have the graph in Figure 3-9.
In[11]:= Plot[f[x],{x,-4,4}]

Figure 3-9
 
So far we have only represented half of the curve. To represent the other half, there
will be another test, but with the equation.
g(x)= - x Sqrt[(x-1)/(x+1)]
This curve will be vertical asymptote x = 1 and y = -x + 1 oblique, will present at
least at the point of abscissa x = -1.61803 and a turning point in the point of abscissa x = 2.
When do we graphing Figure 3-10.
In[11]:= Plot[g[x],{x,-4,4}]
Figure 3-10
If we represent the two sides of the curve on the same axes, we have the complete
curve (Figure 3-11).

In[12]:= Plot[{g[x],-g[x]},{x,-4,4}]
Figure 3-11
 
This curve could have been presented using implicit coordinates.
In[13]:= <<Graphics`ImplicitPlot`
In[14]:= ImplicitPlot[x^2(x-1)/(x+1)==y^2,{x,-4,4}]

3.4 APPLICATIONS TO PRACTICAL PROBLEMS
Many practical problems can be expressed in terms of a function which we need to
maximize or minimize, where these maxima and minima have some applied interpretation.
Let’s see some examples:
Exercise 3-9. Write a positive number a as the sum of two summands in such a way that
the sum of their cubes is minimal.
Let  be one of the summands. The other will be 
. We require the sum 
 to be minimized.
In[1]:= f[x_]=x^3+(a-x)^3
      3    3
(a - x)  + x
In[2]:= Solve[f’[x]==0,x]
      a
{{x -> -}}
      2
The possible maximum or minimum is at 
. We use the second derivative to
verify that it is indeed a minimum:
In[3]:= f”[a/2]
6 a
As 
 (by hypothesis), 
, which means 
 is a minimum.
Therefore the two summands must be equal to 
.

Exercise 3-10. Suppose you want to purchase a rectangular plot of 1600 square meters
and then fence it. Knowing that the fence costs 200 cents per meter, what dimensions
must the plot of land have to ensure that the fencing is most economical?
If the surface area is 1600 square feet and one of its dimensions, unknown, is x, and the
other will be 1600/x.
The perimeter of the rectangle is 
, and the cost is given by 
:
In[1]:= p[x_]=2x+2(1600/x)
3200
–- + 2 x
x
The cost will be:
In[2]:= c[x_]=200 p[x]
    3200
200 (–- + 2 x)
     x
This is the function to minimize:
In[3]:= Solve[c’[x]==0,x]
{{x -> -40}, {x -> 40}}
The possible maxima and minima are presented for 
 and 
. To
determine their nature, we look at the second derivative at these points.

In[4]:= c”[40]
20
In[5]:= c”[-40]
-20
 is a minimum, and 
 is a maximum. Thus, one of the sides of the
rectangular field must be 40 meters, and the other will measure 1600/40 = 40 meters.
Therefore the optimal rectangle is a square with sides of 40 meters.

3.5 PARTIAL DERIVATIVES
As we know, Mathematica can differentiate functions with the command diff, but we
can also make use of the differentiation operator D, which calculates derivatives of
functions, as well as partial derivatives for functions that depend on more than one
variable.
D[f[x,y,z,….],x]           Defines the partial derivative of f with respect to the variable x
D[f[x,y,z,….],{x,n}]     Define the nth partial derivative of f with respect to the variable
x.
D[f[x,y,z,…],x,y,z…]   Defines the partial derivative of f with respect to the variables x,
y, z,…
Derivative[n,m][f][x,y]
Calculate the nth partial derivative of f with respect to variable x and
the nth partial derivative of f with respect to variable x.
Exercise 3-9. Given the function f(x,y) =sin (xy) + cos(xy2), calculate:
 
¶f/¶ x, ¶ f/¶y, ¶2f/¶x2, ¶2f/¶y2, ¶2f/¶x¶y, ¶2f/¶y¶x  and  ¶4f/¶2x¶2y.
In[1]:= f[x_,y_]=Sin[x y];
In[2]:= D[f[x,y],x]
y Cos[x y]
In[3]:= D[f[x,y],y]
x Cos[x y]
In[4]:= D[f[x,y],x,y]

Cos[x y] - x y Sin[x y]
In[5]:= D[f[x,y],y,x]
Cos[x y] - x y Sin[x y]
In[6]:=D[f[x,y],{x,2}]
    2
-(y  Sin[x y])
In[7]:= D[f[x,y],{y,2}]
    2
-(x  Sin[x y])

3.6 IMPLICIT DIFFERENTIATION
 
The differential operator D allows you to find derivatives of functions defined implicitly by
an equation.
Exercise 3-10. Let the function Cos(x+Sen(y))=Sen(y) calculated y´=dy/dx and y´´
 
In[1]:= a=Cos[x+Sin[y]]==Sin[y]
Cos[x + Sin[y]] == Sin[y]
In[2]:= b=Dt[a,x]
-((1 + Cos[y] Dt[y, x]) Sin[x + Sin[y]])==Cos[y] Dt[y, x]
In[3]:= Solve[b,Dt[y,x]]
                    Sin[x + Sin[y]]
{{Dt[y, x] -> ––––––––––—}}
             -Cos[y] - Cos[y] Sin[x + Sin[y]]
Ya hemos calculado y’=dy/dx = Dt[y,x]
In[4]:= c=Dt[a,{x,2}]
                                     2
-(Cos[x + Sin[y]] (1 + Cos[y] Dt[y, x]) ) -
                               2
(Cos[y] Dt[y, {x, 2}] - Dt[y, x] Sin[y])Sin[x + Sin[y]] ==
                               2
Cos[y] Dt[y, {x, 2}] - Dt[y, x]  Sin[y]
In[5]:= s=Solve[c,Dt[y,{x,2}]]

{{Dt[y,{x,2}]->-((-Cos[x+Sin[y]]- 2Cos[y]Cos[x+Sin[y]]
               2                        2        2
Dt[y,x] - Cos[y]  Cos[x + Sin[y]] Dt[y,x]+Dt[y, x]Sin[y] +
                2
       Dt[y, x]  Sin[y] Sin[x + Sin[y]]) /
     (-Cos[y] - Cos[y] Sin[x + Sin[y]]))}}
We have the value of y ‘= Dt [y, {x, 2}]. But this value is a function of y ‘= Dt [y, x].
We can replace and ‘for its value to obtain a closed expression for y’ ‘
In[6]:= s /. Dt[y,x]->Sin[x+Sin[y]]/(-Cos[y]-Cos[y]Sin[x+Sin[y]])
{{Dt[y, {x, 2}] ->  -((-Cos[x + Sin[y]] -
             2                                2
       Cos[y]  Cos[x + Sin[y]] Sin[x + Sin[y]]
       –––––––––––––- +
                                           2
         (-Cos[y] - Cos[y] Sin[x + Sin[y]])
                                   2
             Sin[y] Sin[x + Sin[y]]
       –––––––––––— +
                                         2
       (-Cos[y] - Cos[y] Sin[x + Sin[y]])
                                   3
             Sin[y] Sin[x + Sin[y]]
       –––––––––––— -
                                         2
       (-Cos[y] - Cos[y] Sin[x + Sin[y]])
       2 Cos[y] Cos[x + Sin[y]] Sin[x + Sin[y]]
       –––––––––––––-) /
           -Cos[y] - Cos[y] Sin[x + Sin[y]]

     (-Cos[y] - Cos[y] Sin[x + Sin[y]]))}}
Exercise 3-11. Find the tangents to the ellipse 2 x2 - 2xy + y2 + x+2y + 1 = 0 at the point
x =-3/2.
First we have to find the values that correspond to x = -3/2.
 
In[1]:= a=2x^2-2x y+y^2+x+2y+1==0
           2                  2
1 + x + 2 x  + 2 y - 2 x y + y  == 0
In[2]:= a /. x->-3/2
          2
4 + 5 y + y  == 0
In[3]:= Solve[%,y]
{{y -> -4}, {y -> -1}}
Then the points of the curve in which we find the tangents are (-3/2,-1) and (-3/2,-4)
In[4]:= b=Dt[a,x]
1+4 x-2 y + 2 Dt[y, x] - 2 x Dt[y, x] + 2 y Dt[y, x]==0
In[5]:=c=Solve[b,Dt[y,x]]
             -(1 + 4 x - 2 y)

{{Dt[y, x] -> –––––-}}
              2 (1 - x + y)
We have the value of y ‘= Dt [y, x]. Now we estimate its value at the point of
tangency for the slopes of the two tangents
In[6]:= f[x_,y_]=-(1+4x-2y)/(2(1-x+y))
-(1 + 4 x - 2 y)
–––––-
2 (1 - x + y)
In[7]:= f[-3/2,-1]
1
In[8]:= f[-3/2,-4]
1
The equations of the tangents are:
y +1 = x + 3/2 
y +4 = x + 3/2
The two tangents are parallel. We represent the curve and two tangents on the same
graph (Figure 3-12).
In[9]:= <<Graphics`ImplicitPlot`
In[10]:= ImplicitPlot[{2x^2-2xy+y^2+x+2y+1==0,y+1==x+3/2,
             y+4==x+3/2} , {x,-5,2}]

Figure 3-12
 
 
 
The equations of the two tangents to the curve at 
 are then:
 and 
.
We graphically represent the ellipse, the tangents and the coordinate axes (see Figure 3-
12). As the curve is given in implicit coordinates, we first modify it. To do this, we try to
complete the squares in order to find a trigonometric parameterization that eliminates
possible fractional powers arising when trying to separate a variable.
 

Chapter 4.
DERIVABILITY IN SEVERAL VARIABLES

4.1 DIFFERENTIATION OF FUNCTIONS OF SEVERAL
VARIABLES
We now present some of the features that Mathematica offers to treat differentiation of
functions of several variables.
Given a function f: R2®  R, the partial derivative of f with respect to the variable x at
the point (a, b) is defined as follows:
Similarly, the partial derivative of f with respect to the variable y at the point (a, b) is
defined as:
Generally speaking, we can define the partial derivative with respect to any variable for
a function of n variables.
Given the function f: Rn®  R, the partial derivative of f with respect to the variable xi (i
= 1, 2,…, n) at the point 
 is defined as follows:
The function f is differentiable if all partial derivatives with respect to xi (i = 1, 2,…, n)
exist and are continuous.
All differentiable functions are continuous, and if a function is not continuous, it cannot
be differentiable.
The directional derivative of the function f with respect to the vector v=(v1,v2,…,vn) is
defined as the following scalar product:

 
is called the gradient vector of f.
The directional derivative of the function f with respect to the vector v =(dx1,dx2,
…,dxn) is called the total differential of f. Its value is:
All differentiable functions are continuous, and if a function is not continuous then it is
not differentiable.
At the beginning of the chapter (under the heading “Calculating derivatives”) we defined
the functions that Mathematica implements to find partial derivatives. Using these functions,
we have the following:
D[f[x,y,z,….],x]           Defines the partial derivative of f with respect to the variable x
D[f[x,y,z,….],{x,n}]     Define the nth partial derivative of f with respect to the variable
x.
D[f[x,y,z,…],x,y,z…]   Define the partial derivative of f with respect to the variables x,
y, z,…
Derivative[n][f][x]      Calculate the nth derivative of f with respect to x
Derivative[n][f][a]      Calculate the nth derivative of f with respect to x at the point a.
Derivative[n,m][f][x,y]
Calculate the nth partial derivative of f with respect to x and m-th

partial derivative with respect to y.
Derivative[n,m][f][a,b]
Calculate the nth partial derivative of f with respect to x and m-th
partial derivative with respect to y, and in the result replaces x by a
and y by b.
Derivative[n,m,p,…][f][x,y,z,…]
Calculate the nth partial derivative of f with respect to x, and m-th
partial derivative with respect to y,  and p-th partial derivative with
respect to z……..
Derivative[n,m,p,…][f][a,b,c,…]
Calculate the nth partial derivative of f with respect to x, and m-th
partial derivative with respect to y,  and p-th partial derivative with
respect to z…… and in the result replaces x by a, and y by b, and p
by z…..
D[f,x, NonConstants -> {c1, c2, …}]
Calculate the partial derivative of f with respect to x, assuming c1, c2,
… functions dependent of x.
Dt[f[x,y,z,..]]               Calculate the total derivative of f
Dt[f[x,y,z,..],x,y,z..]    Computes the implicit derivative of f with respect to the variables
x, y, z, ..
Dt[f,x, Constants -> {c1, c2, …}]
Computes the implicit derivative of f with respect to x,assuming c1,

c2, … constants.
Exercise 4-1. Given the real-valued two-variable function f defined by:
 
 if 
 and 
 if 
 
calculate the partial derivatives of f at the origin. Study the differentiability of f.
In[1]:= f[x_,y_]= (x y)/(x^2+y^2)
To find ¶f/¶x  and ¶f/¶y  at the point (0,0), we directly apply the definition of a partial
derivative at a point:
In[1]:= Limit[(f[h,0]-0)/h, h->0]
0
In[2]:= Limit[(f[0,k]-0)/k, k->0]
0
The limits of the two previous expressions as h - > 0 and k - > 0, respectively, are both
zero.
We see that the two partial derivatives at the origin are the same and have value zero.
But the function is not differentiable at the origin, because it is not continuous at (0,0),
since there is no limit as (x, y) tends to (0,0):
In[3]:= Limit[(m x)^2/(x^2+(m x)^2),x->0]
  2
 m
––

    2
1 + m
The limit does not exist at (0,0), because approaching the origin along different straight
lines y = mx yields different results depending on the parameter m.
Exercise 4.2 Study the differentiability of the following function:
 
 if 
 and 
 
The function is differentiable if it has continuous partial derivatives at every point. We
will consider any point other than the origin and calculate the partial derivative with
respect to the variable x:
In[1]:= f[x_,y_]=(2 x y)/(x^2+y^2)^(1/2)
In[2]:= D[f[x,y],x]//Simplify
      3
   2 y
––––
 2    2 3/2
(x  + y )
Now, let’s see if this partial derivative is continuous at the origin:
In[3]:= g= % /. y->m x
      3  3
   2 m  x

–––––
 2    2  2 3/2
(x  + m  x )
In[4]:= Limit[g,x->0]
    3
  2 m
–––—
     2 3/2
(1 + m )
The limit does not exist at (0,0), because approaching the origin along different straight
lines y = mx yields different results depending on the parameter m. Therefore, the partial
derivative is not continuous at the origin.
We conclude that the function is not differentiable.
However, the function is continuous, since the only problematic point is the origin, and
the limit of the function at the origin is 0 = f (0,0):
In[1]:= Limit[Limit[f[x,y],x->0],y->0]
0
In[2]:= Limit[Limit[f[x,y],y->0],x->0]
0
In[3]:= Limit[f[x,(m x)],x->0]
0
In[4]:= Limit[f[x,(m x)^(1/2)],x->0]
0

In[5]:= Limit[f[(r Cos[a]),(r Sin[a])],r->0]
0
The iterated limits and the directional limits are all zero, and by changing the function
to polar coordinates, the limit at the origin turns out to be zero, which coincides with the
value of the function at the origin.
This is therefore an example of a non-differentiable continuous function.
Exercise 4-3. Study the differentiability of the following function:
 
 
In[1]:= f[x_,y_]= (x^2+y^2) Sin[1/(x^2+y^2)]
In[2]:=Limit[Limit[f[x,y],x->0],y->0]
0
In[3]:= Limit[Limit[f[x,y],y->0],x->0]
0
In[4]:= Limit[f[x, x],x->0]
0
In[5]:= Limit[f[x, x^(1/2)],x->0]
0
In[6]:= Limit[Limit[f[(r Cos[a]),(r Sin[a])],a->0],r->0]
0
The limit of the function at the origin is 0, since the limits iterated, directional and
polar worth all zero. As the value of the function at the origin is also zero, the function is

continuous.
To see if it is derivable see if the partial derivatives exist and are continuous. Consider
the partial derivative with respect to x at any point other than the origin.
 
In[7]:= D[f[x,y],x]//Simplify
1
-2 x Cos[––-]
2    2
x  + y                1
–––––— + 2 x Sin[––-]
2    2                 2    2
x  + y                 x  + y
This partial derivative is continuous at every point. The only sticking point is the
origin
In[8]:= h[x_,y_]=%;
In[9]:= Limit[Limit[h[x,y],x->0],y->0]
0
In[10]:=Limit[Limit[h[x,y],y->0],x->0]
0
In[11]:= Limit[h[x, x],x->0]
In[12]:= Limit[Limit[h[(r Cos[a]),(r Sin[a])],a->0],r->0]
0
We see that the limit on the origin of the partial respect to x exists and is 0, the same
as the partial in (0.0). Then the partial derivative function is continuous at (0,0).

By symmetry, the analysis for the partial derivative with respect to and be the same.
We have studied the existence and continuity of the partial derivatives of the initial
function at any point other than the origin. Now we will study what happens in the home
We will now calculate partial derivatives at source for the initial function
 
In[13]:= Limit[(f[h,0]-0)/h, h->0]
0
In[14]:= Limit[(f[0,k]-0)/k, k->0]
0
The two sets are zero at the origin, as well as its limit at any point, then are
continuous.
We then have, at the origin, the initial function and also has partial derivatives are
continuous.
We then have the initial function has, at every point, continuous partial derivatives,
which is differentiable.
In addition, we have also seen that the initial function is continuous at all points.
Exercise 4-4.  Calculate the total differential of the following functions:
 
 
In[1]:= f[x_,y_]=x^3-2x^2 y+3;
In[2]:= Dt[f[x,y]]

  2                          2
3 x  Dt[x] - 4 x y Dt[x] - 2 x  Dt[y]
In[3]:= r[x_,y_]= x^2+Log[x y];
In[4]:= Dt[r[x,y]]//Simplify
Dt[x]               Dt[y]
–— + 2 x Dt[x] + –—
 x                   y
In[5]:= s[x_,y_]=Cos[2x-3y]^2;
In[6]:= Dt[s[x,y]]
-2 Cos[2 x - 3 y] (2 Dt[x] - 3 Dt[y]) Sin[2 x - 3 y]
Exercise 4-5. Verify that if 
then 
 .
In[1]:= f[x_,y_,z_]=1/(x^2+y^2+z^2)^(1/2)
       1
––––––
     2    2    2
Sqrt[x  + y  + z ]
In[2]:= D[f[x,y,z],{x,2}]+D[f[x,y,z],{y,2}]+D[f[x,y,z],{z,2}]

        2                   2
     3 x                 3 y
–––––— + –––––— +
 2    2    2 5/2     2    2    2 5/2
(x  + y  + z )      (x  + y  + z )
         2
      3 z                   3
–––––— - –––––—
  2    2    2 5/2     2    2    2 3/2
(x  + y  + z )      (x  + y  + z )
In[3]:= Simplify[%]
0
Exercise 4-6.  Find the total differential of second order of the function:
 
 
In[1]:=f[x_,y_]= E^(a x) Cos[b y];
In[2]:= SetAttributes[a, Constant]
In[3]:= SetAttributes[b, Constant]
In[4]:= u=Dt[f[x,y]]
  a x                     a x
a E    Cos[b y] Dt[x] - b E    Dt[y] Sin[b y]
a and b are constants

In[5]:= v=Dt[u]
 2  a x               2    2  a x               2
a  E    Cos[b y] Dt[x]  - b  E    Cos[b y] Dt[y]  +
   a x
a E    Cos[b y] Dt[Dt[x]] -
       a x
2 a b E    Dt[x] Dt[y] Sin[b y] -
   a x
b E    Dt[Dt[y]] Sin[b y]
In[6]:= Simplify[%]
a x   2               2    2               2
E    (a  Cos[b y] Dt[x]  - b  Cos[b y] Dt[y]  +
  a Cos[b y] Dt[Dt[x]] -
  2 a b Dt[x] Dt[y] Sin[b y] - b Dt[Dt[y]] Sin[b y])
Exercise 4-7.  Find the directional derivative of the function:
 

 
at the point (2,1,1), with respect to the vector v = (1,1,0).
In[1]:= f[x_,y_,z_]=1/(x^2+y^2+z^2)^(1/2);
In[2]:= grad[x_,y_,z_]={D[f[x,y,z],x],D[f[x,y,z],y],D[f[x,y,z],z]}
         x                     y
{-(–––––—), -(–––––—),
    2    2    2 3/2       2    2    2 3/2
  (x  + y  + z )        (x  + y  + z )
          z
-(–––––—)}
    2    2    2 3/2
  (x  + y  + z )
In[3]:= grad[2,1,1]
   -1         -1         -1
{–––, –––, –––}
3 Sqrt[6]  6 Sqrt[6]  6 Sqrt[6]
In[4]:=% . {1,1,0}
  -1
–––
2 Sqrt[6]

Exercise 4-8. Given the function:
 
 
calculate:
 
 
and find its value at the point (3p, 6p).
In[1]:= f[x_,y_]=Exp[-(x^2+y^2)/8] (Cos[x]^2+Sin[y]^2);
In[2]:= Derivative[1,0][f][x,y]
      2    2
   (-x  - y )/8
-2 E             Cos[x] Sin[x] -
    2    2
 (-x  - y )/8          2         2
E             x (Cos[x]  + Sin[y] )
–––––––––––—
                 4
The previous partial derivative can also be calculated with D[f[x,y],x]
In[3]:= Simplify[%]
    2    2
 (-x  - y )/8
(E             (-2 x - x Cos[2 x] + x Cos[2 y] - 8 Sin[2 x])) / 8
In[4]:= Derivative[1,0][f][Pi/3,Pi/6]

  -Sqrt[3]            Pi
––––— - –––––
       2                 2
  (5 Pi )/288       (5 Pi )/288
2 E              24 E
In[5]:= N[%]
-0.839938
In[6]:= Derivative[0,1][f][x,y]//Simplify
    2    2
 (-x  - y )/8
(E             (-2 y - y Cos[2 x] + y Cos[2 y] + 8 Sin[2 y])) / 8
In[7]:= Derivative[0,1][f][Pi/3,Pi/6]//N
0.674508
In[8]:= Derivative[1,1][f][x,y]//Simplify
    2    2
 (-x  - y )/8
(E             (2 x y + x y Cos[2 x] - x y Cos[2 y] +
    8 y Sin[2 x] - 8 x Sin[2 y])) / 32
In[9]:= Derivative[1,1][f][Pi/3,Pi/6]//N
-0.0810746
In[10]:= Derivative[2,0][f][x,y]//Simplify
    2    2

 (-x  - y )/8          2
(E             (-8 + 2 x  - 68 Cos[2 x] +
     2                          2
    x  Cos[2 x] + 4 Cos[2 y] - x  Cos[2 y] +
    16 x Sin[2 x])) / 32
In[11]:= Derivative[2,0][f][Pi/3,Pi/6]//N
1.14813
In[12]:= Derivative[0,2][f][x,y]//Simplify
    2    2
 (-x  - y )/8          2
(E             (-8 + 2 y  - 4 Cos[2 x] +
     2                           2
    y  Cos[2 x] + 68 Cos[2 y] - y  Cos[2 y] -
    16 y Sin[2 y])) / 32
In[13]:= Derivative[0,2][f][Pi/3,Pi/6]//N
0.553409
In[14]:= Derivative[1,2][f][x,y]//Simplify
    2    2
 (-x  - y )/8             2
(E             (8 x - 2 x y  + 4 x Cos[2 x] -
       2                               2

    x y  Cos[2 x] - 68 x Cos[2 y] + x y  Cos[2 y] +
                     2
    32 Sin[2 x] - 8 y  Sin[2 x] + 16 x y Sin[2 y])) / 128
In[15]:= Derivative[1,2][f][Pi/3,Pi/6]//N
0.0250284
In[16]:= Derivative[2,2][f][x,y]//Simplify
    2    2
 (-x  - y )/8          2      2      2  2
(E             (32 - 8 x  - 8 y  + 2 x  y  +
                      2                2
    272 Cos[2 x] - 4 x  Cos[2 x] - 68 y  Cos[2 x] +
     2  2                               2
    x  y  Cos[2 x] - 272 Cos[2 y] + 68 x  Cos[2 y] +
       2             2  2
    4 y  Cos[2 y] - x  y  Cos[2 y] - 64 x Sin[2 x] +
          2
    16 x y  Sin[2 x] + 64 y Sin[2 y] -
        2
    16 x  y Sin[2 y])) / 512
In[17]:= Derivative[2,2][f][Pi/3,Pi/6]//N
-0.385583

In[18]:= Derivative[3,2][f][x,y]//Simplify
    2    2
 (-x  - y )/8             3         2      3  2
(E             (-96 x + 8 x  + 24 x y  - 2 x  y  - 
                        3
    816 x Cos[2 x] + 4 x  Cos[2 x] +
           2             3  2
    204 x y  Cos[2 x] - x  y  Cos[2 x] +
                         3
    816 x Cos[2 y] - 68 x  Cos[2 y] -
          2             3  2
    12 x y  Cos[2 y] + x  y  Cos[2 y] -
                        2
    2432 Sin[2 x] + 96 x  Sin[2 x] +
         2                2  2
    608 y  Sin[2 x] - 24 x  y  Sin[2 x] -
                           3
    192 x y Sin[2 y] + 16 x  y Sin[2 y])) / 2048
In[18]:= Derivative[3,2][f][Pi/3,Pi/6]//N
-0.519315

The advantage of using the function D instead of the command D[f] is that it is much
faster at directly calculating the value of the derivative at a point.

4.2 MAXIMA AND MINIMA OF FUNCTIONS OF
SEVERAL VARIABLES
A function f: Rn®R, which maps the point (x1, x2,…, xn)ÎR to f(x1,x2,…,xn)ÎR, has an
extreme point at 
 if the gradient vector 
is zero at 
.
By setting all the first order partial derivatives equal to zero and solving the resulting
system, we can find the possible maxima and minima.
To determine the nature of the extreme point, it is necessary to construct the Hessian
matrix, which is defined as follows:
First, suppose that the determinant of H is non-zero at the point 
. In this
case, we say that the point is non-degenerate and, in addition, we can determine the nature
of the extreme point via the following conditions:
If the Hessian matrix at the point 
  is positive definite, then the function
has a minimum at that point.
If the Hessian matrix at the point 
 is negative definite, then the function
has a maximum at that point.
In any other case, the function has a saddle point at 
.
If the determinant of H is zero at the point 
, we say that the point is
degenerate.

Exercise 4-18. Find and classify the extreme points of the function:
 
 
First, we find the extreme points, setting the partial derivatives (the components of the
gradient vector of f) to zero and solving the resulting system:
In[1]:= f[x_,y_]=-120x^3-30x^4+18x^5+5x^6+30x y^2;
In[2]:= Solve[{D[f[x,y],x]==0,D[f[x,y],y]==0}]
{{y -> 0, x -> -3}, {y -> 0, x -> -2},
 {y -> 0, x -> 0}, {y -> 0, x -> 0},
 {y -> 0, x -> 0}, {y -> 0, x -> 0},
 {y -> 0, x -> 2}}
Thus, the extreme points are: (- 2,0), (2,0), (0,0) and (- 3.0).
To classify the extreme points, we construct the Hessian matrix, and calculate its value
at each point:
In[3]:= M[x_,y_]={{D[f[x,y],{x,2}],D[f[x,y],x,y]},
                            {D[f[x,y],x,y],D[f[x,y],{y,2}]}}        
               2        3        4
{{-720 x - 360 x  + 360 x  + 150 x , 60 y}, {60 y, 60 x}}
In[4]:= M[0,0]//MatrixForm
0   0

0   0
In[5]:= Det[M[0,0]]
0
The origin turns out to be a degenerate point, as the determinant of the Hessian matrix
is zero at (0,0).
In[6]:= M[-2,0]//MatrixForm
-480   0
0      -120
In[7]:= Det[M[-2,0]]
57600
In[8]:= Eigenvalues[M[-2,0]]
{-480, -120}
The Hessian matrix at the point (- 2,0) has non-zero determinant, and is also negative
definite, because all its eigenvalues are negative. Therefore, the point (- 2,0) is a
maximum of the function.
In[9]:= M[2,0]//MatrixForm
2400   0
0      120
In[10]:= Det[M[2,0]]
288000

In[11]:= Eigenvalues[M[2,0]]
{120, 2400}
The Hessian matrix at the point (2,0) has non-zero determinant, and is furthermore
positive definite, because all its eigenvalues are positive. Therefore, the point (2,0) is a
minimum of the function.
In[12]:= M[-3,0]//MatrixForm
1350   0
0      -180
In[13]:= Det[M[-3,0]]
-243000
In[14]:= Eigenvalues[M[-3,0]]
{-180, 1350}
The Hessian matrix at the point (- 3,0) has non-zero determinant, and, in addition, is
neither positive definite nor negative definite, because its eigenvalues are not all positive
or all negative. Therefore (- 3.0) is a saddle point of the function.
We’ll represent the curve (Figure 4-1).

Figure 4-1
Exercise 4-19. Find and classify the extreme points of the function:
 
First, we set the partial derivatives (the components of the gradient vector of f) to zero
and solve the resulting system:
In[1]:= f[x_,y_,z_]=x^2+y^2+z^2+x y;
In[2]:= Solve[{D[f[x,y,z],x]==0,D[f[x,y,z],y]==0,D[f[x,y,z],z]==0}]
{{z -> 0, x -> 0, y -> 0}}
The single extreme point is the origin (0,0,0). We determine what kind of extreme point
it is. To do this, we calculate the Hessian matrix and express it as a function of x, y and z:
In[3]:= M[x_,y_,z_]={{D[f[x,y,z],{x,2}],D[f[x,y,z],x,y],D[f[x,y,z],x,z]},
                               {D[f[x,y,z],x,y],D[f[x,y,z],{y,2}],D[f[x,y,z],y,z] },
                               {D[f[x,y,z],x,z],D[f[x,y,z],y,z],D[f[x,y,z],{z,2}] }}  
{{2, 1, 0}, {1, 2, 0}, {0, 0, 2}}

In[4]:= MatrixForm[%]
2   1   0
1   2   0
0   0   2
In[5]:= Det[%]
6
We see that the Hessian matrix is constant (it does not depend on the point (x,y,z)),
therefore its value at the origin is already found. The determinant is non-zero, so the origin
is non-degenerate.
In[6]:= Eigenvalues[M[0,0,0]]
{1, 2, 3}
The Hessian matrix at the origin is positive definite, because all its eigenvalues are
positive. Thus we conclude that the origin is a minimum of the function.
          

4.3 CONDITIONAL MINIMA AND MAXIMA. THE
METHOD OF “LAGRANGE MULTIPLIERS”
Suppose we want to optimize (i.e. maximize or minimize) the function f(x1,x2,…,xn) ,
called the objective function, but subject to certain restrictions given by the equations:
 
g1(x1,x2,…,xn)=0
 
g2(x1,x2,…,xn)=0
……………………..
gk(x1,x2,…,xn)=0
This is the setting in which the Lagrangian is introduced. The Lagrangian is a linear
combination of the objective function and the constraints, and has the following form:
L(x1,x2,…,xn,l) = f(x1,x2,…,xn) + 

The extreme points are found by solving the system by setting the components of the
gradient vector of L to zero, that is, Ñ L(x1,x2,…,xn,l) =(0,0,…,0). Which translates into:
By setting the partial derivatives to zero and solving the resulting system, we obtain the
values of x1, x2,…, xn, l1, l2,…,lk corresponding to possible maxima and minima.
To determine the nature of the points (x1, x2,…, xn) found above, the following
bordered Hessian matrix is used:
The nature of extreme points can be determined by studying the set of bordered Hessian
matrices:
      
…   Hn = H
For a single restriction g1, if H1 < 0, H2 < 0, H3 < 0,…, H < 0, then the extreme point
is a minimum.
For a single restriction g1, if H1 > 0, H2 < 0, H3 > 0, H4 < 0, H5 > 0, … then the
extreme point is a maximum.
For a collection of restrictions gi(x1,…, xn) (i = 1, 2,…, k) the lower right 0 will be a

block of zeros and the conditions for a mimimum will all have sign (-1)k, while the
conditions for a maximum will have alternating signs with H1 having sign (-1)k+1 . When
considering several restrictions at the same time, it is easier to determine the nature of the
extreme point by simple inspection.
Exercise 4-20. Find and classify the extreme points of the function:
 
 subject to the constraint
.
We write the equation of Lagrange:
In[1]:= f[x_,y_,z_,l_]=x + z + l(x^2+y^2+z^2-1)
In[2]:= g[x,y,z]=x^2+y^2+z^2-1;
First find the possible end points, equating to zero the partial (componenetes gradient
vector f) and solving the resulting system
In[3]:=Solve[{D[f[x,y,z,l],x]==0,D[f[x,y,z,l],y]==0,D[f[x,y,z,l],z]==0,                               
          D[f[x,y,z,l],l]==0 }]
           1                      1
{{l -> -(––-), y -> 0, x -> ––-,
        Sqrt[2]                Sqrt[2]
         1               1
 z -> ––-}, {l -> ––-, y -> 0,
      Sqrt[2]         Sqrt[2]
           1                1
 x -> -(––-), z -> -(––-)}}
        Sqrt[2]          Sqrt[2]

We have that potential end points are:
(-1 / Sqrt [2], 0, -1 / Sqrt [2]) corresponding to = 1 / Sqrt [2] and
(1 / Sqrt [2], 0, 1 / Sqrt [2]) corresponding to = -1 / Sqrt [2]
Now let’s see what kind of ends are. To do this we consider the matrix gives us the
sufficient condition of end.
In[4]:=M[x_,y_,z_,l_]=
             {{D[f[x,y,z,l],{x,2}],D[f[x,y,z,l],x,y],D[f[x,y,z,l],x,z],  D[g[x,y,z],x]},
              {D[f[x,y,z,l],x,y],D[f[x,y,z,l],{y,2}],D[f[x,y,z,l],y,z],D[g[x,y,z],y] },
              {D[f[x,y,z,l],x,z],D[f[x,y,z,l],y,z],D[f[x,y,z,l],{z,2}],D[g[x,y,z],z] },
              {D[g[x,y,z],x],D[g[x,y,z],y],D[g[x,y,z],z], 0 }}  
{{2 l, 0, 0, 2 x}, {0, 2 l, 0, 2 y},  {0, 0, 2 l, 2 z}, {2 x, 2 y, 2 z, 0}}
In[5]:= MatrixForm[%]
2 l   0     0     2 x
0     2 l   0     2 y
0     0     2 l   2 z
2 x   2 y   2 z   0
Once we know the matrix, we apply in each candidate end point. We begin with the
point (-1 / Sqrt [2], 0, -1 / Sqrt [2]).
In[6]:= M[-1/Sqrt[2],0,-1/Sqrt[2],1/Sqrt[2]]//MatrixForm
Sqrt[2]    0          0          -Sqrt[2]
0          Sqrt[2]    0          0

0          0          Sqrt[2]    -Sqrt[2]
-Sqrt[2]   0          -Sqrt[2]   0
From this matrix we form successive determinants and check their signs.
In[7]:= Det[{{Sqrt[2],-Sqrt[2]},{-Sqrt[2],0}}]
-2
In[8]:= Det[{{Sqrt[2],0,-Sqrt[2]},{0,Sqrt[2],0},{-Sqrt[2],0,0}}]
-2 Sqrt[2]
In[9]:= Det[M[-1/Sqrt[2],0,-1/Sqrt[2],1/Sqrt[2]]]
-8
All determinants are negative, then the point (-1 / Sqrt [2], 0, -1 / Sqrt [2]) function
has a minimum.
Now let’s consider the other point: (1 / Sqrt [2] 0.1 / Sqrt [2])
 
In[10]:= M[1/Sqrt[2],0,1/Sqrt[2],-1/Sqrt[2]]//MatrixForm
-Sqrt[2]   0          0          Sqrt[2]
0          -Sqrt[2]   0          0
0          0          -Sqrt[2]   Sqrt[2]
Sqrt[2]    0          Sqrt[2]    0
In[11]:= Det[{{-Sqrt[2],Sqrt[2]},{Sqrt[2],0}}]
-2
In[12]:= Det[{{-Sqrt[2],0,Sqrt[2]},{0,-Sqrt[2],0},{Sqrt[2],0,0}}]
2 Sqrt[2]
In[12]:= Det[M[1/Sqrt[2],0,1/Sqrt[2],-1/Sqrt[2]]]
-8

As the determinants alternate in sign starting with a negative sign, we are in the
presence of a maximum at the point (1 / Sqrt [2] 0.1 / Sqrt [2]).
Then, at the point (-Ö2 /2, 0,-Ö2 /2) the function has a minimum, and there is a
maximum at the point (Ö2/2,0,Ö2/2).

4.4 SOME APPLICATIONS OF MAXIMA AND MINIMA IN
SEVERAL VARIABLES
As in the case of a single variable, many practical problems involving several variables
inevitably lead to the consideration of derivatives.
Exercise 4-22. Find the dimensions of the rectangular cuboid of maximum volume
which has a surface area of 10 square meters.
          
If x, y, z are the dimensions of the block, its volume will be V = xyz. As we know
that it has a surface area of 10 square meters, the restriction will be 2xy + 2xz + 2yz = 10.
We therefore have to maximize the objective function V = xyz subject to the condition 2xy
+ 2xz + 2yz-10 = 0. We will use the method of Lagrange multipliers:
In[1]:= f[x_,y_,z_,l_]=x y z + l(2x y+2x z+2y z-10)
x y z + l (-10 + 2 x y + 2 x z + 2 y z)
In[2]:= g[x,y,z]=2x y+2x z+2y z-10
-10 + 2 x y + 2 x z + 2 y z
In[3]:=Solve[{D[f[x,y,z,l],x]==0,D[f[x,y,z,l],y]==0,D[f[x,y,z,l],z]==0,
                    D[f[x,y,z,l],l]==0 }]
                                         5
                                    Sqrt[-]
            5              5             3
{{x -> -Sqrt[-], y -> -Sqrt[-], l -> ––-,
            3              3           4

            5               5             5
 z -> -Sqrt[-]}, {x -> Sqrt[-], y -> Sqrt[-],
            3               3             3
             5
      -Sqrt[-]
            3             5
 l -> ––—, z -> Sqrt[-]}}
         4                3
Thus the extreme points are:
(-Ö15/3, -Ö15/3, -Ö15/3) and (Ö15/3, Ö15/3, Ö15/3).
The only point which is a meaningful solution is the second, because there can be no
sides of negative length. But it remains to be confirmed that (Ö15/3, Ö15/3, Ö15/3) is
indeed a maximum:
In[4]:=M[x_,y_,z_,l_]=
            {{D[f[x,y,z,l],{x,2}],D[f[x,y,z,l],x,y],D[f[x,y,z,l],x,z],D[g[x,y,z],x]},
             {D[f[x,y,z,l],x,y],D[f[x,y,z,l],{y,2}],D[f[x,y,z,l],y,z],D[g[x,y,z],y] },
             {D[f[x,y,z,l],x,z],D[f[x,y,z,l],y,z],D[f[x,y,z,l],{z,2}],D[g[x,y,z],z] },
             {D[g[x,y,z],x],D[g[x,y,z],y],D[g[x,y,z],z], 0 }}  
{{0, 2 l + z, 2 l + y, 2 y + 2 z}, 
{2 l + z, 0, 2 l + x, 2 x + 2 z},
{2 l + y, 2 l + x, 0, 2 x + 2 y},
{2 y + 2 z, 2 x + 2 z, 2 x + 2 y, 0}}
In[5]:=MatrixForm[%]
0           2 l + z     2 l + y     2 y + 2 z

2 l + z     0           2 l + x     2 x + 2 z
2 l + y     2 l + x     0           2 x + 2 y
2 y + 2 z   2 x + 2 z   2 x + 2 y   0
In[6]:= M[Sqrt[5/3],Sqrt[5/3],Sqrt[5/3],-Sqrt[5/3]/4]//MatrixForm
                5           5
           Sqrt[-]     Sqrt[-]
                3           3             5
           ––-     ––-     4 Sqrt[-]
0              2           2               3
    5                       5
Sqrt[-]                 Sqrt[-]
    3                       3             5
––-                 ––-     4 Sqrt[-]
  2        0              2               3
    5           5
Sqrt[-]     Sqrt[-]
    3           3                         5
––-     ––-                 4 Sqrt[-]
  2           2        0                  3
      5           5           5
4 Sqrt[-]   4 Sqrt[-]   4 Sqrt[-]
      3           3           3    0
In[7]:= Det[{{0,4Sqrt[5/3]},{4Sqrt[5/3],0}}]
 80
-(—)
 3
In[8]:=Det[{{0,Sqrt[5/3]/2,4Sqrt[5/3]},{Sqrt[5/3]/2,0,4Sqrt[5/3]},

                       {4Sqrt[5/3],4Sqrt[5/3],0}}]
       5
80 Sqrt[-]
       3
–––-
   3
In[9]:= Det[M[Sqrt[5/3],Sqrt[5/3],Sqrt[5/3],-Sqrt[5/3]/4]]
   100
-(–)
  3
Indeed is the determining alternate in sign, starting with the negative sign. Then
there is a maximum at the point:
(Ö15/3, Ö15/3, Ö15/3)
We see that the point is indeed a maximum, and so the maximal volume rectangular
cuboid with fixed surface area is a cube (x = y = z).
 

Chapter 5.
VECTOR DIFFERENTIAL CALCULUS AND
THEOREMS IN SEVERAL VARIABLES

5.1 CONCEPTS OF VECTOR DIFFERENTIAL
CALCULUS
Consider a function 
 : Rm®  Rn:
(x1, x2,…, xm) ® [F1(x1, x2,…, xm),…,Fn(x1, x2,…, xm)]
The vector function 
 is said to be differentiable at the point a =(a1,…,am) if each of the
component functions F1, F2,…, Fn is differentiable.
The Jacobian matrix of the above function is defined as:
The Jacobian of a vector function is an extension of the concept of a partial derivative
for a single-component function.
Mathematica has the command Outer which enables you to calculate the Jacobian
matrix of a function:
Outer[D, {F1,F2,….,Fn}, {x1,x2,….,xn}]  returns
Exercise 5-1. Calculate the Jacobian matrix for the following function:
 
 

and find its value at the point (0,-p /2, 0).
In[1]:= f[x_,y_,z_]={E^x,Cos[y],Sin[z]}
 x
{E , Cos[y], Sin[z]}
In[2]:=J[x_,y_,z_]=Outer[D,f[x,y,z],{x,y,z}]
 x
{{E , 0, 0}, {0, -Sin[y], 0}, {0, 0, Cos[z]}}
In[3]:= MatrixForm[%]
x
E         0         0
0         -Sin[y]   0
0         0         Cos[z]
In[4]:= J[0,-Pi/2,0]//MatrixForm
1   0   0
0   1   0
0   0   1
We see that the Jacobian matrix evaluated at the given point is the identity matrix.

5.2 THE CHAIN RULE
The chain rule allows you to differentiate the composition of vector functions. The
chain rule is one of the most familiar rules of differential calculus. It is often first
introduced in the case of single variable real functions, and is then generalized to vector
functions. It says the following:
Suppose we have two vector functions
 and 
.
where U and V are open and consider the composite function 
.
If  is differentiable at 
 and  is differentiable at 
, then 
 is differentiable
at 
and we have the following:
Mathematica will directly apply the chain rule when instructed to differentiate
composite functions.
 
Exercise 5-2. Consider the functions 
 and 
.
  If 
  calculate 
at  u = 0.
In[1]:= f[x_,y_]=x^2+y
2
x  + y

  _
Now we define the vector function h(u) as follows:
In[2]:= {h1[u_],h2[u_]}={Sin[3u],Cos[8u]}
{Sin[3 u], Cos[8 u]}
Now we propose directly to Mathematica’s composite function:
 
In[3]:=g[u_]=f[h1[u],h2[u]]
                     2
Cos[8 u] + Sin[3 u]
Now we derive the composite function and find its value u = 0:
In[4]:= d[u_]=D[g[u],u]
6 Cos[3 u] Sin[3 u] - 8 Sin[8 u]
In[5]:= d[0]
0
Exercise 5-3. Calculate   and  
 given that:
 
 and 
 
In[1]:= f[u_,v_]=(u^2+v^2)/(u^2-v^2)
Now we define the following vector function:
In[2]:= {h1[x_,y_],h2[x_,y_]}={E^(x-y),E^(x y)}

We define the function z as the composite of the previous two functions:
In[3]:= z[x_,y_]=f[h1[x,y],h2[x,y]]
2 x - 2 y    2 x y
E          + E
––––––-
2 x - 2 y    2 x y
E          - E
Finally, we differentiate the composite function. Mathematica automatically
differentiates composite functions via the usual syntax:
In[4]:= D[z[x,y],x]//Simplify
  2 (x + y + x y)
4 E                (-1 + y)
–––––––––
    2 x    2 (1 + x) y 2
 (-E    + E           )
In[5]:= D[z[x,y],y]//Simplify
   2 (x - y)      2 x y
-2 E          + 2 E      x
––––––––— +
   2 (x - y)    2 x y
  E          - E
    2 x    2 (1 + x) y    2 x    2 (1 + x) y
2 (E    + E           ) (E    + E            x)

–––––––––––––––—
               2 x    2 (1 + x) y 2
            (-E    + E           )

5.3 THE IMPLICIT FUNCTION THEOREM
           Consider the vector function 
 : A Ì Rn + m® R m  where A is an open subset of Rn
+ m
If Fi (i = 1, 2,…, m) are differentiable with continuous derivatives up to order r and the
Jacobian matrix J = ¶ (F1,…, Fm) / ¶ (y1,…, ym) has non-zero determinant at a point 
 such that 
, then there is an open UÌRn containing 
and an open VÌ
Rm containing to 
 and a single-valued function : U® V such that 
 ”x ÎU
and  is differentiable of order r with continuous derivatives. 
This theorem guarantees the existence of certain derivatives of implicit functions.
Mathematica allows differentiation of implicit functions and offers the results in those
cases where the hypothesis of the theorem are met.
Exercise 5-4. Find the conditions on x, y, z so that the surface defined by the following
equation defines an implicit function z = z(x,y) where z is a differentiable function:
Calculate:
In[1]:= f[x_,y_,z_]=x^3+3y^2+8x z^2-3z^3 y-1;
In order for the hypotheses of the implicit function theorem to be met, the partial
derivative of f with respect to the variable z must be non-zero.
In[2]:= D[f[x,y,z],z]
             2
16 x z - 9 y z
Thus the required condition is 16xz ¹ 9yz2 .

Now we can calculate the partial derivatives, assuming that the above condition is met.
In[3]:= f[x_,y_,z_[x_,y_]]=x^3+3y^2+8x z^2-3z^3 y-1;
We consider the implicit derivative of f with respect to x and from it we get the
partial of z with respect to x.
In[4]:= Solve[Dt[f[x,y,z],x]==0,Dt[z,x]]
                  2      2                     3
               3 x  + 8 z  + 6 y Dt[y, x] - 3 z  Dt[y, x]
{{Dt[z, x] -> -(––––––––––––––)}}
                                          2
                            16 x z - 9 y z
As y does not depend on x (x and y are, by hypothesis, independent variables, and the
variable z depends on x and y), we put D(y) = 0 in the expression for D (z) / D (x):
In[5]:= % /. Dt[y,x]->0
                    2      2
                 3 x  + 8 z
{{Dt[z, x] -> -(–––––)}}
                             2
               16 x z - 9 y z
This gives the expression for ¶z/¶x. For ¶z/¶y, we similarly calculate the following:
In[6]:= Solve[Dt[f[x,y,z],y]==0,Dt[z,y]]
                        3      2               2
               6 y - 3 z  + 3 x  Dt[x, y] + 8 z  Dt[x, y]
{{Dt[z, y] -> -(––––––––––––––)}}
                                          2
                            16 x z - 9 y z
In[7]:= % /. Dt[x,y]->0
                          3
                 6 y - 3 z

{{Dt[z, y] -> -(–––––)}}
                             2
               16 x z - 9 y z
To calculate ¶ 2z /¶x2, we find the partial derivative of ¶z/¶x with respect to x:
In[8]:= Solve[Dt[f[x,y,z],x,x]==0,Dt[z,x,x]]
{{Dt[z, {x, 2}] ->
                     2                          3
  -((6 x + 6 Dt[y, x]  + 6 y Dt[y, {x, 2}] - 3 z  Dt[y, {x, 2}] +
                            2                                  2
       32 z Dt[z, x] - 18 z  Dt[y, x] Dt[z, x] + 16 x Dt[z, x]  -
                       2                   2
       18 y z Dt[z, x] ) / (16 x z - 9 y z ))}}
Now we nullify Dt [y, x] and Dt [y, {x, 2}] (that and not depend on x) and substitute
Dt [z, x] by value found above.
In[9]:= % /. {Dt[y,x]->0,Dt[y,{x,2}]->0,Dt[z,x]-> (-3x^2-8z^2)/(16x z -                        9y 
z^2)}//Simplify
{{Dt[z, {x, 2}] ->
5       4            3  2        2    3          4         2  4
(6 (24 x  - 27 x  y z + 128 x  z  - 288 x  y z  - 512 x z  + 81 x y  z  +
5       3                3
192 y z )) / (z  (-16 x + 9 y z) )}}
To calculate ¶ 2z /¶y2, we find the partial derivative of ¶z/¶y with respect to y:
In[10]:= Solve[Dt[f[x,y,z],y,y]==0,Dt[z,y,y]]

{{Dt[z, {y, 2}] ->
2      2                    2
-((6 + 6 x Dt[x, y]  + 3 x  Dt[x, {y, 2}] + 8 z  Dt[x, {y, 2}] -
2                                                  2
18 z  Dt[z, y] + 32 z Dt[x, y] Dt[z, y] + 16 x Dt[z, y]  -
2                   2
18 y z Dt[z, y] ) / (16 x z - 9 y z ))}}
Now nullify Dt [x, y] and Dt [x, {y 2}] (because x does not depend on y) and
replace Dt [z, y] for the value found previously.
In[11]:= % /. {Dt[x,y]->0,Dt[x,{y,2}]->0,Dt[z,y]-> (-6y+3z^3)/(16x z-                           9y
z^2)}//Simplify
{{Dt[z, {y, 2}] ->
2        3          2  2           3       2  4          6
(6 (96 x y  - 108 y  z + 256 x  z  - 96 x y z  + 27 y  z  - 120 x z  +
7       3                3
54 y z )) / (z  (-16 x + 9 y z) )}}
Exercise 5-5. Show that near the point (x, y, u, v) = (1,1,1,1) the system
 
                                   
                                   
 
can be solved uniquely for u and v as functions of x and y (u = u(x,y), v = v(x,y)).
Calculate δu/δx, δu/δy, δv/δx, and δv/δy

First, we check that the hypotheses of the implicit function theorem are met at the point
(1,1,1,1).
The functions are differentiable and have continuous derivatives. We need to show that
the corresponding Jacobian determinant is non-zero at the point (1,1,1,1):
In[1]:= f1[x_,y_,u_,v_]= x y +y v u^2-2;
In[2]:= f2[x_,y_,u_,v_]=x u^3+y^2 v^4-2;
In[3]:= J[x_,y_,u_,v_]=Outer[D,{f1[x,y,u,v],f2[x,y,u,v]},{u,v}]
           2         2       3  2
{{2 u v y, u  y}, {3 u  x, 4 v  y }}
In[4]:= J[1,1,1,1]
{{2, 1}, {3, 4}}
In[5]:= Det[%]
5
Thus the assumptions of the implicit function theorem are met and the proposed system
can be solved uniquely.
We will now calculate partial derivatives are ordered by implicit differentiation.
In[6]:= f1[x_,y_,u[x_,y_],v[x_,y_]]= x y +y v u^2-2
In[7]:= f2[x_,y_,u[x_,y_],v[x_,y_]]=x u^3+y^2 v^4-2
We use the derivatives of f1 and f2 implied with respect to x and y, and are obtained
from the system formed, partial u and v with respect to x and y

In[8]:=Solve[{Dt[f1[x,y,u[x,y],v[x,y]],x]==0,
                    Dt[f1[x,y,u[x,y],v[x,y]],y]==0,
                    Dt[f2[x,y,u[x,y],v[x,y]],x]==0,
                    Dt[f2[x,y,u[x,y],v[x,y]],y]==0},
                    {Dt[u,x],Dt[v,x],Dt[u,y],Dt[v,y]}]
3      4
-(u  + 2 v  y Dt[y, x])
{{Dt[u, x] -> –––––––— +
2
3 u  x
3  2     2         2
(4 v  y  (3 u  x (y + u  v Dt[y, x] + x Dt[y, x]) -
3      4                     2       4            4  3
2 u v y (u  + 2 v  y Dt[y, x]))) / (3 u  x (3 u  x y - 8 u v  y )),
      2         2
 Dt[v, x] -> -((3 u  x (y + u  v Dt[y, x] + x Dt[y, x]) -
3      4                    4            4  3
2 u v y (u  + 2 v  y Dt[y, x])) / (3 u  x y - 8 u v  y )),
4      3
-(2 v  y + u  Dt[x, y])
 Dt[u, y] -> –––––––— +
2
3 u  x
3  2               4      3
(4 v  y  (-2 u v y (2 v  y + u  Dt[x, y]) +
2     2                             2       4            4  3
3 u  x (u  v + x + y Dt[x, y]))) / (3 u  x (3 u  x y - 8 u v  y )),
4      3

 Dt[v, y] -> -((-2 u v y (2 v  y + u  Dt[x, y]) +
2     2                            4            4  3
3 u  x (u  v + x + y Dt[x, y])) / (3 u  x y - 8 u v  y ))}}
Now we impose the condition that Dt [x, y] = 0, and x and y are independent
variables (x does not depend on y)
In[9]:= % /. {Dt[y,x]->0,Dt[x,y]->0}
3  2      4          2
-u    4 v  y  (-2 u  v y + 3 u  x y)
{{Dt[u, x] -> – + ––––––––––,
3 x      2       4            4  3
3 u  x (3 u  x y - 8 u v  y )
4          2
-2 u  v y + 3 u  x y
 Dt[v, x] -> -(––––––—),
4            4  3
3 u  x y - 8 u v  y
4        3  2     2     2               5  2
-2 v  y   4 v  y  (3 u  x (u  v + x) - 4 u v  y )
 Dt[u, y] -> ––- + –––––––––––––,
2              2       4            4  3
3 u  x         3 u  x (3 u  x y - 8 u v  y )
2     2               5  2
3 u  x (u  v + x) - 4 u v  y
 Dt[v, y] -> -(–––––––––—)}}
4            4  3
      3 u  x y - 8 u v  y
We have calculated the expression of all ordered derivatives. Now let’s calculate the
value in (1,1,1,1).
 

In[10]:= % /.{x->1,y->1,u->1,v->1}
3               1                6               2
{{Dt[1, 1] -> -(-), Dt[1, 1] -> -, Dt[1, 1] -> -(-), Dt[1, 1] -> -}}
5               5                5               5
 
 
 
 

5.4 THE INVERSE FUNCTION THEOREM
         Consider the vector function  : U Ì Rn®  Rn where U is an open subset of R n
(x1, x2,…, xn) ® [f1(x1, x2,…, xn),…,fn(x1, x2,…, xn)]
and assume it is differentiable with continuous derivative.
If there is an 
 such that |J| = |¶(f1,…,fn) / ¶(x1,…,xn)| ¹ 0 at x0, then there is an open
set A containing 
and an open set B containing 
 such that 
 and  has an
inverse function 
 that is differentiable with continuous derivative. In addition
we have:
and if J = ¶ (f1,…, fn) / ¶ (x1,…, xn) then |J-1| = 1 / |J|.
Mathematica automatically performs the calculations related to the inverse function
theorem, provided that the assumptions are met.
Exercise 5-6. Given the vector function (u(x,y), v(x,y)) where:
 
 
find the conditions under which the inverse vector function (x(u,v), y(u,v)) with x = x(u,
v) and y = y(u,v) exists and find the derivative of the inverse transformation. Find its
value at (p/4,-p/4).
The conditions to be met are precisely the hypotheses of the inverse function theorem. The
functions are differentiable with continuous derivatives, except perhaps at 
x= 0. Now let’s consider the Jacobian of the transformation ¶ (u(x,y), v(x,y)) /¶(x, y):
In[1]:= Outer[D,{(x^4+y^4)/x,Sin[x]+Cos[y]},{x,y}]//MatrixForm

4    4
2   x  + y       3
4 x  - ––-   4 y
2      –-
x        x
Cos[x]           -Sin[y]
In[2]:= Det[%]
3                         4
-4 y  Cos[x]      2          y  Sin[y]
–––– - 3 x  Sin[y] + –––
x                           2
x
In[3]:= m[x_,y_]=Outer[D,{(x^4+y^4)/x,Sin[x]+Cos[y]},{x,y}]
4    4     3
2   x  + y   4 y
{{4 x  - ––-, –-}, {Cos[x], -Sin[y]}}
2      x
x
In[4]:= Inverse[m[x,y]]//Simplify
                2
                x  Sin[y]
{{–––––––––––––,
      3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
                       3

                 4 x y
 –––––––––––––},
      3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
                 2
                x  Cos[x]
{–––––––––––––,
      3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
                   4    4
               -3 x  + y
 –––––––––––––}}
      3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
In[5]:= Det[Inverse[m[x,y]]]//Simplify
2
x
-(–––––––––––––)
3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
Therefore, at the points where this expression is non-zero, x and y can be expressed in
terms of u and v. In addition, we must have x¹0.
We calculate the derivative of the inverse function. Its value is the inverse of the
Jacobian matrix and the determinant of the inverse Jacobian matrix is the reciprocal of the
determinant of the Jacobian matrix:
In[3]:= m[x_,y_]=Outer[D,{(x^4+y^4)/x,Sin[x]+Cos[y]},{x,y}]
4    4     3

2   x  + y   4 y
{{4 x  - ––-, –-}, {Cos[x], -Sin[y]}}
2      x
x
In[4]:= Inverse[m[x,y]]//Simplify
                2
                x  Sin[y]
{{–––––––––––––,
      3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
                       3
                 4 x y
 –––––––––––––},
      3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
                 2
                x  Cos[x]
{–––––––––––––,
      3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
                   4    4
               -3 x  + y
 –––––––––––––}}
      3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
In[5]:= Det[Inverse[m[x,y]]]//Simplify
2
x
-(–––––––––––––)

3             4           4
 4 x y  Cos[x] + 3 x  Sin[y] - y  Sin[y]
Observe that this is indeed the reciprocal of the determinant found above.
Next we find the value of the inverse Jacobian at the point (p/4,-p/4) :
In[6]:= m[Pi/4,-Pi/4]
   2     2
 Pi   -Pi        1        1
{{–, –-}, {––-, ––-}}
  8    4      Sqrt[2]  Sqrt[2]
In[7]:= Det[%]
     2
 3 Pi
–––
8 Sqrt[2]
In[8]:= Inverse[m[Pi/4,-Pi/4]]
   8    2 Sqrt[2]     -8    Sqrt[2]
{{–—, –––}, {–—, ––-}}
     2      3            2     3
 3 Pi                3 Pi
In[9]:=Det[%]
8 Sqrt[2]
–––
     2
 3 Pi

Here it is clear that the determinant of the Jacobian of the inverse function is the
reciprocal of the determinant of the Jacobian of the function.
Exercise 5-7. Demonstrate that the transformation between cartesian and polar
coordinates complies with the assumptions of the inverse function theorem.
We know that the transformation equations are:
.
Obviously, the functions have continuous partial derivatives. Let’s see if the
determinant of the Jacobian of the transformation is non-zero:
In[1]:= f1[a_,b_]=a Cos[b]
In[2]:= f2[a_,b_]=a Sin[b]
In[3]:= Outer[D,{f1[a,b],f2[a,b]},{a,b}]//MatrixForm
Cos[b]        -(a Sin[b])
Sin[b]        a Cos[b]
In[4]:= Det[%]//Simplify
a
We see that the Jacobian of the transformation is non-zero (a¹0). Thus, the inverse
function theorem is applicable. The determinant of the Jacobian of the inverse
transformation will be 1/a.
Mathematica habilita varias funciones en el package “Calculus`VectorAnalysis”, que
permiten disponer de los jacobianos de todo tipo de transformaciones entre los sistemas de
coordenadas más conocidos.
JacobianMatrix[ ]                             It gives the Jacobian matrix for the default
coordinate system.
JacobianMatrix[Point]          It gives the Jacobian matrix for the default coordinate
system at the given point.

JacobianMatrix[system]      It gives the Jacobian matrix for the specified coordinate
system.
JacobianMatrix[system, P]  It gives the Jacobian matrix for the coordinate system and
the specified point.
JacobianDeterminant[%]     it gives determinants for all the above matrices (% is
variable argument).
          
Here are some examples of how the Jacobian matrices and determinants of the
transformations between different coordinate systems are easily calculated with
Mathematica are presented in order to enable verification of compliance with the
assumptions of the inverse function theorem, when define the inverse transformations
In[1]:= <<Calculus`VectorAnalysis`
In[2]:= JacobianMatrix[ ]//MatrixForm
1   0   0
0   1   0
0   0   1
Obviously the Jacobian of the transformation of the coordinate system default, which
is the Cartesian coordinates to Cartesian is the identity matrix.
 
In[3]:= JacobianMatrix[Cylindrical]//MatrixForm
Cos[theta]        -(r Sin[theta])   0
Sin[theta]        r Cos[theta]      0
0                 0                 1
In[4]:= JacobianMatrix[Spherical]

{{Cos[phi] Sin[theta], r Cos[phi] Cos[theta],  -(r Sin[phi] Sin[theta])},
 {Sin[phi] Sin[theta], r Cos[theta] Sin[phi], r Cos[phi] Sin[theta]},
 {Cos[theta], -(r Sin[theta]), 0}}
In the last two examples we are calculated step Jacobian matrices and cylindrical to
Cartesian spherical to Cartesian.
In[5]:= JacobianMatrix[{1,Pi/2,Pi/4},Spherical]//MatrixForm
  1                           1
––-                   -(––-)
Sqrt[2]      0              Sqrt[2]
  1                         1
––-                   ––-
Sqrt[2]      0            Sqrt[2]
0            -1           0
In[6]:= JacobianMatrix[{1,Pi/2,Pi/4},Cylindrical]//MatrixForm
0    -1   0
1    0    0
0    0    1
Here we calculate the values of the Jacobian matrices at a given point.
In[7]:= JacobianDeterminant[Spherical]
2
r  Sin[theta]
In[8]:= JacobianDeterminant[Cylindrical]

r
In[9]:= JacobianDeterminant[{1,Pi/2,Pi/4},Spherical]
1
In recent examples we have been calculated Jacobian determinants of certain
matrices.

5.5 THE CHANGE OF VARIABLES THEOREM
Suppose we have a function f(x,y) that depends on the variables x and y, and that meets
all the conditions of differentiation and continuity necessary for the inverse function
theorem to hold. We introduce new variables u and v, relating to the above, regarding them
as functions u = u(x,y) and v = v(x,y), so that u and v also fulfil the necessary conditions of
differentiation and continuity (described by the inverse function theorem) to be able to
express x and y as functions of u and v: x=x (u,v) and y=y(u,v).
Under the above conditions, it is possible to express the initial function  f as a function
of the new variables u and v using the expression:
f(u,v) = f (x(u,v), y(u,v))|J| where J is the Jacobian ¶ (x (u, v), y(u,v)) /¶(u, v).
The theorem generalizes to vector functions of n components.
Exercise 5-8. Consider the function 
 and the transformation 
u = u(x,y) = x + y, v = v(x,y) = x. Calculate f(u,v).
In[1]:= f[x_,y_]=E^(-x-y)
-x - y
E
This transformation fulfils the conditions of the inverse function theorem (continuous
partial derivatives and a Jacobian with non-zero determinant).
We find the inverse transformation and its Jacobian to apply the change of variables
theorem:
In[2]:= Solve[{u==x+y,v==x},{x,y}]
{{y -> u - v, x -> v}}
In[3]:= Outer[D,{v,u-v},{u,v}]
{{0, 1}, {1, -1}}

In[4]:= f[u_,v_]=f[v,u-v] Abs[Det[Outer[D,{v,u-v},{u,v}]]]
-u
E
The requested function is f(u,v)= e2v-u.

5.6  TAYLOR’S THEOREM WITH N VARIABLES
Let 
, (x1,…,xn) ® f(x1,…,xn),  be differentiable k times with continuous
partial derivatives.
The Taylor series expansion of order k of 
 at the point 
 is as follows:
Here 
 
R = remainder.
Normally, the series are given up to order 2.
Exercise 5-9. Find the Taylor series of order 2 at the point (1,0) of the function:
 
.
In[1]:= f[x_,y_]=E^((x-1)^2) Cos[y];
In[2]=g[x,y]=f[1,0]+Derivative[1,0][f][1,0](x-1)+Derivative[0,1][f][1,0](y)
      +(1/2!)(Derivative[2,0][f][1,0](x-1)^2+2Derivative[1,1][f][1,0](x-1)y+
       Derivative[0,2][f][1,0](y)^2)                             
         2    2
2 (-1 + x)  - y

–––––-
      2
Exercise 5-10. Find the Taylor series of order 2 at the origin of the function:
 
In[1]:= f[x_,y_]=E^(x+y^2);
In[2]:=                   g[x,y]=f[0,0]+Derivative[1,0][f][0,0](x)+Derivative[0,1][f][0,0](y)+
+(1/2!)(Derivative[2,0][f][0,0](x)^2+2Derivative[1,1][f][0,0](x)y+
Derivative[0,2][f][0,0](y)^2)
                                  
        2      2
       x  + 2 y
1 + x + –––
           2

5.7 VECTOR FIELDS. CURL, DIVERGENCE AND THE
LAPLACIAN
We recall some basic definitions:
Definition of gradient: If h = f(x,y,z), then the gradient of f, which is denoted by    
, is the vector:
Definition of a scalar potential of a vector field: A vector field  is called conservative if
there is a differentiable function f such that 
 . The function  is known as a scalar
potential function for  .
Definition of the curl of a vector field:The curl of a vector  field 
is the following:
Definition of a vector potential of a vector field: A vector field F is a vector potential of
another vector field G if F = curl (G).
Definition of the divergence of a vector field: The divergence of the vector field 
 is the following:
Definition of the Laplacian: The Laplacian is the differential operator defined by:

Mathematica provides the following commands for the above operations:
Div[f]              gives the divergence of f in the default coordinate system.
Curl[f]             gives the curl of f in the default system.
Laplacian[f]   gives the Laplacian of f in the default system.
Grad[f]            gives the gradient of f in the default system.
Exercise 5-11. Calculate the gradient and Laplacian of the function 
 .
In[1]:= <<Calculus`VectorAnalysis`
In[2]:= Grad[(1-x^2-y^2-z^2)^(1/2)]
          x                      y
{–––––––, –––––––,
      2    2    2 3/2        2    2    2 3/2
(1 - x  - y  - z )     (1 - x  - y  - z )
          z
–––––––}
      2    2    2 3/2
(1 - x  - y  - z )
Therefore, we can write:

Grad[(1‑x^2‑y^2‑z^2)^(‑1/2)]=
¡Error! Argumento de modificador
no especificado.
Exercise 
5-12. 
Calculate 
the 
divergence 
potential 
of 
the 
vector 
field 
 .
In[1]:= Div[{Sin[x],Cos[y],z^2}]
2 z + Cos[x] - Sin[y]
We can write:
div
¡Error! 
Argumento 
de 
modificador 
no
especificado.
Exercise 5-13. Calculate the curl and the divergence of the vector field:
 
 
In[1]:= Curl[{ArcTan[x/y],Log[(x^2+y^2)^(1/2)],1}]//Simplify
        2 x
{0, 0, ––-}
       2    2
      x  + y

We can write:
¡Error! Argumento de modificador no
especificado.
Exercise 5-14. Calculate the laplacian of :
 
In[1]:= Laplacian[x+y^2+z^3]
2 + 6 z
We can write:
¡Error! Argumento de modificador no especificado.

5.8 COORDINATE TRANSFORMATION
In this section we will see how to convert cylindrical and spherical coordinates to
rectangular coordinates, cylindrical coordinates to spherical coordinates, and their inverse
transformations. Given the simplicity of the functions we will define them ourselves.
First we recall the definitions of cylindrical and spherical coordinates:
In a cylindrical coordinate system, a point P in the space is represented by a triplet (r, q,
z), where:
r is the distance from the origin (O) to the projection P’ of P in the XY plane
q is the angle between the X axis and the segment OP’
z is the distance PP’
In a spherical coordinate system, a point P in the space is represented by a triplet  (r, q,
f), where:
r is the distance from P to the origin
q is the same angle as the one used in cylindrical coordinates
f is the angle between the positive Z axis and the segment OP
The following conversion equations are easily found:
Cylindrical to rectangular:
Rectangular to cylindrical:
                                           
               
Spherical to rectangular:

Rectangular to spherical:
Therefore, in Mathematica we can define the following functions:
CoordinateSystem               Returns the default coordinate system.
SetCoordinates[sistema]     Place the coordinate system specified as default. Possible
systems are: Bipolar, Bispherical, ConfocalEllipsoidal,
ConfocalParaboidal, Conical, Cylindrical, EllipticCylindrical,
OblateSpheroidal, ParabolicCylindrical, Paraboloidal,
ProlateSpheroidal, Spherical, Toroidal and Cartesian.
CoordinatesToCartesian[P] gives the Cartesian coordinates of the point P, which is
expressed in the default system.
CoordinatesToCartesian[P, sistema]
It gives the Cartesian coordinates of point P  expressed in the
specified system.
CoordinatesFromCartesian[P]
gives the coordinates in the system default of point P, which is
given in Cartesian.
CoordinatesFromCartesian[P, sistema]
It gives the coordinates in the specified system of the point P,
which is given in Cartesian.

Exercise 5-15. Express the point given in spherical coordinates by (4,π/6,π/4 ) in
rectangular and cylindrical coordinates.
In[1]:= <<Calculus`VectorAnalysis`
In[2]:= CoordinatesToCartesian[{4,Pi/6,Pi/4}, Spherical]           
{Sqrt[2], Sqrt[2], 2 Sqrt[3]}{Sqrt[2], Sqrt[2], 2 Sqrt[3]}
Exercise 5-16. Express the point given in cylindrical coordinates by (4,5π/6,3) in
rectangular and spherical coordinates.
In[1]:= CoordinatesToCartesian[{4,5 Pi/6,3}, Cylindrical]
{-2 Sqrt[3], 2, 3}
Exercise 5-17. Express the point given in rectangular coordinates by (-2,2Sqrt(3),4) in
spherical coordinates.
In[1]:= : CoordinatesFromCartesian[{-2,2Sqrt[3],4}, Spherical]//N
{5.65685, 0.785398, 2.0944}
Exercise 5-17. Express the point given in rectangular coordinates by (1,Sqrt(3),2) in
cilindrical coordinates.
In[1]:= CoordinatesFromCartesian[{1,Sqrt[3],2}, Cylindrical]//N
{2., 1.0472, 2.}
 

Chapter 6.
DIFFERENTIAL EQUATIONS
Although it implements only a relatively small number of commands related to this
topic, Mathematica treatment of differential equations is nevertheless very efficient. We
shall see how we can use these commands to solve each type of differential equation
algebraically. Numerical methods for the approximate solution of equations and systems
of equations are also implemented.
Solving differential equations in partial derivatives is also possible with the program.
The packages are Calculus`PDSolve` and Calculus`PDSolve1`. The first increases the
number of equations to be solved directly with the DSolve function, and the second
implemeta functions to solve partial differential equations..
The most important Mathematica commands that solve differential equations are the
following:
DSsolve(equation, y[x], x)           Solves the given differential equation for y[x]. This
returns only explicit solutions.
DSolve({equ1, equ2,…}, {y1, y2,…}, x)
                                                          Solve de list of differential equations
DSsolve(equation, initial conditions, y[x], x)
Solves the given differential equation subject to the specified
initial condition
           Examples are given below.
In[1]:= DSolve[2y’[x]+2y[x]==1,y[x],x]
         1   C[1]

{{y[x] -> - + –-}}
         2     x
              E
In[2]:= DSolve[{y[x]==-z’[x],z[x]==-y’[x]},{y,z},x]//Simplify
{{y -> Function[x,
            2 x                2 x
    C[1] + E    C[1] + C[2] - E    C[2]
    –––––––––––—],
                      x
                   2 E
 z -> Function[x,
            2 x                2 x
    C[1] - E    C[1] + C[2] + E    C[2]
    –––––––––––—]}}
                      x
                   2 E
In[3]:= DSolve[{3y’[x]==2y[x],y[0]==1},y[x],x]
          (2 x)/3
{{y[x] -> E       }}

6.1 SEPARATION OF VARIABLES
A differential equation is said to have separable variables if it can be written in the form  f(x)
dx = g(y) dy.
This type of equation can be solved immediately by putting ò f(x) dx = ò g(y) dy + C.
If Mathematica cannot directly solve a differential equation with the function DSolve, then
we can try to express it in the above form and solve the given integrals algebraically, which
does not present particular difficulties for the program, given its versatility in symbolic
computation.
Exercise 6-1. Solve the differential equation:
 
y cos(x) dx -(1 + y2 ) dy = 0, y(0) = 1.
First of all we try to solve it directly. The equation can be written in the form:
In[1]:= ecuacion=y’[x]==y[x] Cos[x]/(1+y[x]^2)
In[2]:= DSolve[ecuacion,y[x],x]
Solve::tdep:
  The equations appear to involve transcendental
    functions of the variables in an essentially
    non-algebraic way.
Solve::tdep:
  The equations appear to involve transcendental
    functions of the variables in an essentially
    non-algebraic way.

                              2
                          y[x]
Solve[Log[y[x]] - Sin[x] + –— == C[1], y[x]]
                            2
Thus the differential equation appears not to be solvable with DSolve. However, in this
case, the variables are separable, so we can solve the equation as follows:
In[1]:= solucion=Integrate[Cos[x],x]==Integrate[(1+y^2)/y,y]+c
              2
             y
Sin[x] == c + — + Log[y]
             2
In[2]:= constante=solucion /. {x->0,y->1}
    1
0 == - + c
    2
In[3]:= Solve[constante]
        1
{{c -> -(-)}}
        2
In[4]:= Soluciongeneral=solucion /. c->1/2
              2
         1   y
Sin[x] == - + — + Log[y]

         2   2

6.2 HOMOGENEOUS DIFFERENTIAL EQUATIONS
Consider a general differential equation of first degree and first order of the form
M(x,y) dx = N(x,y) dy.
This equation is said to be homogeneous of degree n if the functions M and N satisfy:
M(tx, ty) = t n M(x,y),
 
N(tx, ty) = t n N(x,y).
For this type of equation, we can transform the initial differential equation (with
variables x and y), via the change of variable x = vy, into another (separable) equation
(with variables v and y). The new equation is solved by separation of variables and then
the solution of the original equation is found by reversing the change of variable.
Exercise 6-2. Solve the differential equation:
 
(x 2 - y2) dx + x y dy = 0.
 
We are trying to solve the equation directly with DSolve.
In[1]:= ecuacion=x y y’[x]==y[x]^2-x^2;
In[2]:=DSolve[ecuacion,y[x],x]
                     2       2
DSolve[x y y’[x] == -x  + y[x] , y[x], x]
The DSolve function not offers solution, so let’s solve the equation by ordinary
algebraic method.
 

First we check if the equation is homogeneous:
In[3]:= m[x_,y_]=x^2-y^2;
n[x_,y_]=x y;
In[4]:= m[t x,t y]//Factor
2
t  (x - y) (x + y)
In[5]:= n[t x,t y]//Factor
2
t  x y
Thus the equation is homogeneous of degree 2. To solve it we apply the change of
variable x = vy.
In[6]:= expresion1=m[x,y]Dt[x]+n[x,y]Dt[y]
  2            2    2  2
v y  Dt[y] + (-y  + v  y ) (y Dt[v] + v Dt[y])
In[7]:= x=v y;
In[8]:= expresion2=expresion1//ExpandAll
  3           2  3          3  2
-(y  Dt[v]) + v  y  Dt[v] + v  y  Dt[y]
In[9]:= expresion3=Collect[expresion2,{Dt[v],Dt[y]}]

  3    2  3           3  2
(-y  + v  y ) Dt[v] + v  y  Dt[y]
If we divide the previous expression by v3y3, and group the terms in d(v) and d(y), we
already have an equation in separated variables.
In[10]:= expresion4=Cancel[Apart[expresion3/(y^3 v^3)]]
      2
(-1 + v ) Dt[v]   Dt[y]
––––– + –—
      3            y
     v
Now, we solve the equation:
In[11]:=expresion5=Integrate[(v^2-1)/v^3,v]+Integrate[1/y,y]
1
–- + Log[v] + Log[y]
  2
2 v
Finally we reverse the change of variable:
In[12]:= Clear[x,v,y]
In[13]:= expresion6=expresion5 /. v->x/y //PowerExpand
 2
y
–- + Log[x]
  2

2 x
In[14]:= solucion=expresion6==c
 2
y
–- + Log[x] == c
  2
2 x
Thus the general solution of the original differential equation is:
Now we can represent the solutions of this differential equation graphically. To do this
we graph the solutions with parameter C, which is equivalent to the following contour plot
of the function defined by the left-hand side of the above general solution (see Figure 6-1):
In[15]:= ContourPlot[y^2/(2 x^2) + Log[x],{x,0.1,3},{y,-5,5},
             PlotRange->{-3,10},ContourShading->False,Frame->False,
            Axes->Automatic,AxesOrigin->{0,0}]
Figure 6-1

 

6.3 EXACT DIFFERENTIAL EQUATIONS
 
The differential equation
M(x,y) dx+N(x,y) dy = 0
is said to be exact if  ¶N/¶x = ¶M/¶y. If the equation is exact, then there exists a function F
such that its total differential dF coincides with the left-hand side of the above equation,
i.e.:
dF = M(x,y) dx+N(x,y) dy
therefore the family of solutions is given by F(x,y) = C.
The exercise below follows the usual steps of an algebraic solution to this type of
equation.
Exercise 6-3. Solve the differential equation:
 
(-1 + y exy + y cos(xy)) dx +(1 + x exy + x cos(xy)) dy = 0.
 
First, we try to solve the equation with DSolve:
In[1]:= m[x_,y_]=-1+y E^(x y)+y Cos[x y];
In[2]:= n[x_,y_]=1+x E^(x y)+x Cos[x y];
In[3]:= ecuacion=DSolve[m[x,y[x]]+n[x,y[x]]*y’[x]==0,y[x],x]
Solve::tdep:
  The equations appear to involve transcendental
    functions of the variables in an essentially
    non-algebraic way.
Solve::tdep:
  The equations appear to involve transcendental

    functions of the variables in an essentially
    non-algebraic way.
      x y[x]
Solve[E       - x + Sin[x y[x]] + y[x] == C[1], y[x]]
Thus the function DSolve does not give a solution to the proposed equation. We are
going to try to solve the equation using the classical algebraic method.
First we check that the proposed differential equation is exact.
In[4]:= D[m[x,y],y]==D[n[x,y],x]
True
Since the equation is exact, we can find the solution in the following way:
In[5]:= solucion1=Integrate[m[x,y],x]+g[y]
x y
E    - x + g[y] + Sin[x y]
Now we find the function g(y) via the following condition:
diff(int(m(x,y), x) + g(y), y) = n(x,y).
In[6]:= expresion1=D[solucion1,y]
x y
E    x + x Cos[x y] + g’[y]
In[7]:=Solve[expresion1==n[x,y],g’[y]]
{{g’[y] -> 1}}

The final solution is:
In[8]:= solucion=solucion1 /. g[y]->Integrate[1,y]
x y
E    - x + y + Sin[x y]
To graphically represent the family of solutions, we draw the following contour plot of
the above expression (Figure 6-2):
In[9]:=ContourPlot[solucion,{x,-Pi,Pi},{y,-Pi,Pi},
                               PlotRange->{-10,10},ContourShading->False]
Figure 6-2
In the following section we will see how any reducible differential equation can be
transformed to an exact equation using an integrating factor.

6.4 LINEAR DIFFERENTIAL EQUATIONS
 
A linear first order differential equation is an equation of the form:
dy/dx + P(x) y = Q(x)
where P(x) and Q(x) are given functions of x.
Differential equations of this type can be transformed into exact equations by
multiplying both sides of the equation by the integrating factor:
 
and the general solution is then given by the expression:
.
Mathematica implements these solutions of linear differential equations, and offers them
whenever the integral appearing in the integrating factor can be found.
Exercise 6-4. Solve the differential equation:
 
x dy/dx + 3 y = x sin(x).
 
Make the graphs of the solutions to the following constant values: -6,-4,-2,0,2,4,6
 
In[1]:= solucion=DSolve[x y’[x]+3y[x]==x Sin[x], y[x],x]
         C[1]
{{y[x] -> –- +

           3
          x
                  3                        2
    6 x Cos[x] - x  Cos[x] - 6 Sin[x] + 3 x  Sin[x]
    –––––––––––––––—}}
                           3
                          x
In[2]=Plot[Evaluate[Table[solucion[[1,1,2]] /.C[1]->{i,-6,6,2,-2,4,-4,0}]],            
                        {x,0.01,3Pi/2}, PlotRange->{-5,5}]
Figure 6-3
 

6.5 NUMERICAL SOLUTIONS TO DIFFERENTIAL
EQUATIONS OF THE FIRST ORDER
Mathematica enable the DSolve function that calculates numerical solutions of
differential equations equation approaches. This function is very useful, especially in
nonlinear equations. The function syntax is:
NDSolve[{ecuacion, condiciones iniciales}, {x, xmin, xmax}]   
Exercise 6-5. Solve and graph the solution of the differential equation:
dy/dx = Sen(2x - y)      y(0)=0.5    in the interval [0,15]
In[1]:= ecuation=y’[x]==Sin[2x-y[x]];
In[2]:= solution=NDSolve[{ecuation,y[0]==0.5},y[x],{x,0,15}]
{{y[x] -> InterpolatingFunction[{0., 15.}, <>][x]}}
Now we plot the function obtained as a solution (Figure 6-4)
In[3]:= Plot[y[x] /. solucion, {x,0,15}]
Figure 6-4


6.6 ORDINARY HIGH-ORDER EQUATIONS
An ordinary linear differential equation of order n has the following general form:
If the function 
 is identically zero, the equation is called homogeneous. Otherwise,
the equation is called non-homogeneous. If the functions 
 are constant,
the equation is said to have constant coefficients.
A concept of great importance in this context is that of a set of linearly independent
functions. A set of functions 
 is linearly independent if, for any  in
their common domain of definition, the Wronskian determinant of the functions is non-
zero. The Wronskian determinant of the given set of functions, at a point  of their
common domain of definition, is defined as follows:
A set 
 of linearly independent non-trivial solutions of a
homogeneous linear equation of order n
is called a set of fundamental solutions of the equation.
If the functions 
 are continuous in an open interval , then the
homogeneous equation has a set of fundamental solutions 
  in .

In addition, the general solution of the homogeneous equation will then be given by the
function:
where 
 is a set of arbitrary constants.
The equation:
is called the characteristic equation of the homogeneous differential equation with
constant coefficients. The solutions of this characteristic equation determine the general
solutions of the corresponding differential equation.
Exercise 6-5. Show that the set of functions
 
is linearly independent.
In[1]:= funciones={Exp[x],x Exp[x], x^2 Exp[x]}
 x   x     x  2
{E , E  x, E  x }
In[2]:= matriz={funciones,D[funciones,x],D[funciones,{x,2}]}
  x   x     x  2     x   x    x       x      x  2
{{E , E  x, E  x }, {E , E  + E  x, 2 E  x + E  x },

  x     x    x       x      x      x  2
{E , 2 E  + E  x, 2 E  + 4 E  x + E  x }}
In[3]:= Det[matriz]
  3 x
2 E
This gives us the value of the Wronskian, which is obviously always non-zero.
Therefore the set of functions is linearly independent.
We can put the Wronskian in matrix form as follows:
In[4]:= TableForm[matriz]
x    x             x  2
E    E  x          E  x
x    x    x          x      x  2
E    E  + E  x     2 E  x + E  x
x      x    x        x      x      x  2
E    2 E  + E  x   2 E  + 4 E  x + E  x

6.7 HIGHER-ORDER LINEAR HOMOGENEOUS
EQUATIONS WITH CONSTANT COEFFICIENTS     
The homogeneous linear differential equation of order n
is said to have constant coefficients if the functions  
 are all constant
(i.e. they do not depend on the variable ).
The equation:
is called the characteristic equation of the above differential equation. The solutions 
 of this characteristic equation determine the general solution of the
associated differential equation.
If the 
 are all different, the general solution of the homogeneous
equation with constant coefficients is:
where  
 are arbitrary constants.
If some 
 is a root of multiplicity k of the characteristic equation, then it determines
the following k terms of the solution:

.
If the characteristic equation has a complex root mj=a+bi , then its complex conjugate
mj+1=a-bi is also a root.  These two roots determine a pair of terms in the general solution
of the homogeneous equation:
Mathematica directly applies this method to obtain the solutions of homogeneous linear
equations with constant coefficients, using the command DSolve.
Exercise 6-6. Solve the following equations:
 
 
 
In[1]:= solucion=DSolve[3y”[x]+2y’[x]-5y[x]==0,y[x],x]
           C[1]      x
{{y[x] -> ––— + E  C[2]}}
          (5 x)/3
         E
In[2]:=solucion=DSolve[{2y”[x]+5y’[x]+5y[x]==0,y[0]==0,
                                    y’[0]==1/2},y[x],x]
            ((-5 - I Sqrt[15]) x)/4
         I E
{{y[x] -> ––––––––— -
                  Sqrt[15]

      ((-5 + I Sqrt[15]) x)/4
   I E
   ––––––––—}}
            Sqrt[15]
In[3]:= solucionsimplificada= solucion[[1,1,2]]//ComplexExpand
     Sqrt[15] x
2 Sin[–––-]
         4
–––––—
         (5 x)/4
Sqrt[15] E
Exercise 6-7. Solve the differential equation
 
In[1]=solucion=DSolve[9D[y[x],{x,4}]-6D[y[x],{x,3}]+46y’’+37y==0,                 
      y[x],x}
                        x/3
{{y[x] -> C[2] Cos[x] + E    C[4] Cos[2 x] -
                  x/3
   C[1] Sin[x] - E    C[3] Sin[2 x]}}
Looking at the solution, it is evident that the characteristic equation has two pairs of
complex conjugate solutions.

In[2]:= Solve[9x^4-6x^3+46x^2-6x+37==0]
                           1               1
{{x -> -I}, {x -> I}, {x -> - - 2 I}, {x -> - + 2 I}}
                           3               3

6.8 NON-HOMOGENEOUS EQUATIONS WITH CONSTANT
COEFFICIENTS. VARIATION OF PARAMETERS
Consider the non-homogeneous linear equation with constant coefficients:
Suppose 
is a linearly independent set of solutions of the
corresponding homogeneous equation:
A particular solution of the non-homogeneous equation is given by:
where the functions 
 are obtained as follows:
Here 
 is the determinant of the matrix obtained by replacing the
i-th column of the Wronskian matrix 
 by the transpose of the
vector (0,0,…, 0, 1).
The solution of the non-homogeneous equation is then given by combining the
general solution of the homogeneous equation with the particular solution of the non-
homogeneous equation. If the roots 
 of the characteristic equation of the homogeneous
equation are all different, the general solution of the non-homogeneous equation is:

If some of the roots are repeated, we refer to the general form of the solution of a
homogeneous equation discussed earlier.
Exercise 6-8. Solve the following differential equations:
 
 
 
We will follow the algebraic method of variation of parameters to solve the first
equation. We first consider the characteristic equation of the homogeneous equation to
obtain a set of linearly independent solutions.
In[2]:= Solve[m^2+4m+13==0]
{{m -> -2 - 3 I}, {m -> -2 + 3 I}}
In[2]:= f[x_]=x Cos[3x]^2;
In[3]:= y1[x_]=Exp[-2x]Cos[3x];
In[4]:=y2[x_]=Exp[-2x]Sin[3x];
In[5]:= wronskiano=Det[{{y1[x],y2[x]},D[{y1[x],y2[x]},x]}]//Simplify
3
–-
4 x

E
We see that the Wronskian is non-zero, indicating that the functions are linearly
independent. Now we calculate the functions 
In[6]:= W1[x_]=Det[{{0,y2[x]},{1,D[y2[x],x]}}]//Simplify
 Sin[3 x]
-(––—)
    2 x
   E
In[7]:=W2[x_]=Det[{{y1[x],0},{D[y1[x],x],1}}]//Simplify
Cos[3 x]
––—
  2 x
 E
Now we calculate the particular solution of the non-homogeneous equation.
In[8]:= u1[x_]=Integrate[f[x] W1[x]/wronskiano,x]//Simplify
 2 x
(E    (-86700 Cos[3 x] + 281775 x Cos[3 x] -
     6084 Cos[9 x] + 129285 x Cos[9 x] -
     36125 Sin[3 x] - 187850 x Sin[3 x] -
     13013 Sin[9 x] - 28730 x Sin[9 x])) / 14652300
In[9]:= u2[x_]=Integrate[f[x] W2[x]/wronskiano,x]//Simplify
 2 x

(E    (108375 Cos[3 x] + 563550 x Cos[3 x] +
     13013 Cos[9 x] + 28730 x Cos[9 x] -
     260100 Sin[3 x] + 845325 x Sin[3 x] -
     6084 Sin[9 x] + 129285 x Sin[9 x])) / 14652300
In[10]:= yp[x_]=y1[x] u1[x]+y2[x] u2[x]//Simplify
(-28900 + 93925 x + 13436 Cos[6 x] -
   25415 x Cos[6 x] + 3852 Sin[6 x] + 26520 x Sin[6 x]
   ) / 2442050
Then we can write the general solution of the non-homogeneous equation:
In[11]:= y[x_]=c1 y1[x] + c2 y2[x] + yp[x] //Simplify
c1 Cos[3 x]   c2 Sin[3 x]
–––— + –––— +
   2 x           2 x
  E             E
(-28900 + 93925 x + 13436 Cos[6 x] -
   25415 x Cos[6 x] + 3852 Sin[6 x] +
   26520 x Sin[6 x]) / 2442050
Now we graphically represent a set of solutions, for certain values of c1 and c2 (see
Figure 6-5)
In[12]:= Plot[Evaluate[Table[y[x],{c1,-5,5,5},{c2,-4,4,2}]],{x,-1,1},
                   PlotRange->{-20,20}, PlotPoints->100]

Figure 6-5
 
For the second differential equation we directly apply DSolve, obtaining the solution.
First, we find the general solution of the homogeneous equation:
In[1]:= Clear [x,y]
In[2]:= DSolve[y”[x]-2y’[x]+y[x]==Exp[x] Log[x], y[x], x]
             x  2
         -3 E  x     x         x
{{y[x] -> ––— + E  C[1] + E  x C[2] +
            4
    x  2
   E  x  Log[x]
   ––––}}
        2

6.9 NON-HOMOGENEOUS LINEAR EQUATIONS WITH
VARIABLE COEFFICIENTS. CAUCHY-EULER
EQUATIONS
A non-homogeneous linear equation with variable coefficients of the form
is called a Cauchy–Euler equation.
This equation can be reduced to a homogeneous linear equation with constant
coefficients by replacing x = et.
This leads us to solve the equation:
 
The roots ki of multiplicity ai correspond to the solutions:
 
The complex roots p ± qi of multiplicity a correspond to the solutions:
Mathematica solves this type of equation directly with the command DSolve.

Exercise 6-9. Solve the following differential equation:
 
In[1]:=DSolve[x^3 y”’[x]+16x^2 y”[x]+79x y’[x]+125y[x]==0,y[x],x]
         C[1]   C[3] Cos[3 Log[x]]
{{y[x] -> –- + –––––– -
           5             4
          x             x
    C[2] Sin[3 Log[x]]
   ––––––}}
            4
           x

6.10 THE LAPLACE TRANSFORM
Suppose 
 is a function defined in the interval 
. The Laplace transform of 
is the function 
 defined by:
We say that 
 is the inverse Laplace transform of 
, so that 
.
Mathematica has the Calculus`Laplace Transform` package that enables functions to
calculate the Laplace transform and vice versa.
The LaplaceTransform [g [t], t, s] function calculates the Laplace transform of g (t) as
a function of s.
 
The InverseLaplaceTransform [f [s], s, t] function calculates the inverse Laplace
transform of f (s) as a function of t.
The Laplace transform and its inverse are used to solve certain differential equations.
The method is to calculate the Laplace transform of each term of the equation to obtain a
new differential equation, which we then solve. Finally, we find the solution of the
original equation by applying the inverse Laplace transform to the solutions just found.
Exercise 6-10. Solve the differential equation
 
 
using the Laplace transform method.
In[1]:= <<Calculus`LaplaceTransform`
First, we calculate the Laplace transform of each side of the differential equation,
and we apply the initial conditions.

In[2]:=paso1=LaplaceTransform[y”[x]+2y’[x]+4y[x],x,s]
1
- + 4 LaplaceTransform[y[x], x, s] +
2
 2
s  LaplaceTransform[y[x], x, s] +
2 (s LaplaceTransform[y[x], x, s] - y[0]) - s y[0]
In[3]:= paso2=paso1 /. {y[0]->1,y’[0]->1}
1
- - s + 4 LaplaceTransform[y[x], x, s] +
2
 2
s  LaplaceTransform[y[x], x, s] +
2 (-1 + s LaplaceTransform[y[x], x, s])
We then solve the Laplace transformed differential equation:
In[4]:=paso3=Solve[paso2==Integrate[(x-E^x) 
E^(-s 
x),{x,0,Infinity}],
                    LaplaceTransform[y[x],x,s]]
General::intinit:
  Loading integration packages — please wait.
{{LaplaceTransform[y[x], x, s] ->

                 2    3      4
  -(2 - 2 s + 5 s  - s  - 2 s )
  –––––––––—}}
              2             2
  2 (-1 + s) s  (4 + 2 s + s )
This gives the solution of the Laplace transformed equation. To calculate the solution of
the original equation we calculate the inverse Laplace transform of the solution obtained
in the previous step.
In[5]:= paso4=paso3[[1,1,2]]
              2    3      4
-(2 - 2 s + 5 s  - s  - 2 s )
–––––––––—
           2             2
2 (-1 + s) s  (4 + 2 s + s )
In[6]:= solucion=InverseLaplaceTransform[paso4,s,x]
       x
 1    E    x    36 Sqrt[3] Sin[Sqrt[3] x]
-(-) - — + - + (––––––––- +
 8    7    4                x
                           E
       Cos[Sqrt[3] x]   Sin[Sqrt[3] x]
   71 (––––— - ––––—)) / 56
              x                    x
             E            Sqrt[3] E

6.11 SYSTEMS OF LINEAR HOMOGENEOUS
EQUATIONS WITH CONSTANT COEFFICIENTS
 
A system of differential equations, written as 
, has a general solution of
the form:
where the eigenvalues 
 
 corresponding to the eigenvectors 
 of the
matrix  of the system are all assumed to be different.
If an eigenvalue 
 is a complex number 
, then it generates the following
component of the overall solution:
where:
Here 
 is the eigenvector corresponding to the eigenvalue 
 and 
  is its conjugate.
If there is an eigenvalue  of multiplicity 
, then it will generate a portion of the
general solution of the form:

         Mathematica can solve this type of system directly, simply by using the command
dsolve or maple(‘dsolve’) with the folowing syntax:
DSolve[{ecuation1, …., ecuationn}, {vd1, ….,vdn}, vi}
Solve the differential equation system ecuation1, …., ecuationn, with
dependent variables: vd1,….,vdn and the independent variable x.
Exercise 6-11. Solve the following system of equations:
 
 
In[1]:= solucion =DSolve[{x’[t]==-5x[t]+3y[t],
                                           y’[t]==-2x[t]-10y[t]},{x[t],y[t]},t]
           -2     3             -3     3
{{x[t] -> (–- + –-) C[1] + (–- + –-) C[2],
           8 t    7 t           8 t    7 t
          E      E             E      E
           2      2             3      2
 y[t] -> (–- - –-) C[1] + (–- - –-) C[2]}}
           8 t    7 t           8 t    7 t
          E      E             E      E

6.12 SYSTEMS OF LINEAR NON-HOMOGENEOUS
EQUATIONS WITH CONSTANT COEFFICIENTS
Now let us consider systems of non-homogeneous differential equations with constant
coefficients of the form 
.
The general solution of the homogeneous system 
 takes the form 
.
A particular solution of the non-homogeneous system is:
The general solution of the non-homogeneous system will be 
, which is,
using the previous expression:
This method is a generalization to systems of equations of the method of variation of
parameters for simple equations.
Mathematica can solve such systems of equations directly with the command DSolve,
provided the integrals that appear in the solution can be evaluated.
Exercise 6-12. Solve the following system of equations:
 
 
with initial conditions 
 and 
.
 
In[1]:=DSolve[{x’[t]-y’[t]==E^(-t),y’[t]+5x[t]+2y[t]==Sin[3t],                                
  y[0]==y0,x[0]==x0},{x[t],y[t]},t]

                  41     5 x0   2 y0
                -(–) + –- + –-
          -1      609     7      7
{{x[t] -> –- + ––––––— -
            t            7 t
         6 E            E
   2 (-1 - x0 + y0)   3 Cos[3 t]   7 Sin[3 t]
   –––––- - –––- + –––-,
          7               58           58
                  41     5 x0   2 y0
                -(–) + –- + –-
          5       609     7      7
 y[t] -> –- + ––––––— +
            t            7 t
         6 E            E
   5 (-1 - x0 + y0)   3 Cos[3 t]   7 Sin[3 t]
   –––––- - –––- + –––-}}
          7               58           58

6.13 HIGHER ORDER EQUATIONS AND
APPROXIMATION METHODS
 
When the known algebraic methods for solving differential equations and systems of
differential equations offer no solution, we usually resort to methods of approximation.
The approximation methods can involve both symbolic and numerical work. The symbolic
approach yields approximate algebraic solutions, and its most representative technique is
the Euler series method. The numerical approach yields a solution in the form of a finite
set of solution points, to which a curve can be fitted by various algebraic methods
(interpolation, regression,…). This curve will be an approximate solution of the
differential equation. Among the most common numerical methods is the Runge–Kutta
method.
Approximation methods are most commonly employed to find the solution of equations
and systems of differential equations of order and degree greater than one, where the exact
solution cannot be obtained by other methods.

6.14 THE EULER METHOD
 
This method provides a set of points on the solution of the differential equation of
the type dy / dx = f (x, y), y(x0) = y0.
The set of points is defined by the recurrence relation:
x(n) = n h
y(n+1) = y(n) + f(x(n),y(n))h
for initial values: (x0, y0)
A more sophisticated variant of Euler, which defines the solution by the following
recurrence relation:
X(n) = n h
y(n+1) = y(n) +1/2 [f(x(n),y(n)) + f(x(n+1), y(n) + f(x(n),y(n))h) ]h
for initial values (x0, y0)
 
Exercise 6-13. Solve the following two equations by the Euler method:
 
dy/dx = xy,  y(0)=1  h=0.1
In[1]:= Clear[f,x,y,h]
In[2]:= f[x_,y_]=x y;
In[3]:= h=0.1; y[0]=1;
In[4]:= x[n_]=n h;
In[5]:= y[n_]:=y[n]=y[n-1]+h f[x[n-1],y[n-1]];
In[6]:=puntos=Table[{x[i-1],Table[y[i],{i,0,10}][[i]]},                                           
                     {i,1,Length[Table[y[i],{i,0,10}]]}]

{{0, 1}, {0.1, 1}, {0.2, 1.01}, {0.3, 1.0302},
 {0.4, 1.06111}, {0.5, 1.10355}, {0.6, 1.15873},
 {0.7, 1.22825}, {0.8, 1.31423}, {0.9, 1.41937},
 {1., 1.54711}}
Now let’s plot the set of points of the solution
In[7]:= Grafico=ListPlot[puntos,PlotJoined->True]
.
Figure 6-6
 
Now we will use the advanced method of Euler:
In[1]:= Clear[x,y,h]
In[2]:= f[x_,y_]=x y;
In[2]:= h=0.1; y[0]=1;
In[4]:= x[n_]=n h;
In[5]:= y[n_]:=y[n]=y[n-1]+(h/2) (f[x[n-1],y[n-1]]+f[x[n-1],y[n-1]+
                                                                              h f[x[n-1],y[n-1]]]);
In[6]:=puntos=Table[{x[i-1],Table[y[i],{i,0,10}][[i]]},                                           
                     {i,1,Length[Table[y[i],{i,0,10}]]}]

{{0, 1}, {0.1, 1}, {0.2, 1.01005}, {0.3, 1.03045}, {0.4, 1.06183},
{0.5, 1.10515}, {0.6, 1.16179}, {0.7, 1.23359}, {0.8, 1.32296},
{0.9, 1.43304}, {1., 1.56781}}
Ahora vamos a graficar este conjunto de puntos de la solución (Figure 6-7)
In[7]:= Grafico=ListPlot[puntos,PlotJoined->True]
Figure 6-7

6.15 THE RUNGE–KUTTA METHOD
The Runge–Kutta method gives a set of data points to which you can fit a curve,
approximating the solution of a differential equation. Initially used the method known as
order 2 used, but now often used the order 4. In this case the iterative algorithm used is as
follows:
x(n+1) = nh
y(n+1) = y(n) + h/6 (k1+2k2+2k3+k4)
were k1=f(x(n),y(n)), k2=f(x(n)+h/2,yn+hk1/2), k3=f(x(n)+h/2,y(n)+hk2/2)
k4=f(x(n+1),y(n)+hk3)
The value of h is given and the initial conditions (x0, y (x0))
maple (‘dsolve (equation, func (var), ‘numeric’))
Exercise 6-14. Solve the following two equations by the Euler method:
 
dy/dx = xy,  y(0)=1  h=0.1
In[1]:= x[n_]:=n h
In[2]:= f[x_,y_]=x y;
In[4]:= h=0.1;
In[5]:= rk4[0]=1;
In[6]:=rk4[n_]:=Module[{k1,k2,k3,k4},
               k1=f[x[n-1],rk4[n-1]];

               k2=f[x[n-1]+h/2,rk4[n-1]+(h k1)/2];
               k3=f[x[n-1]+h/2,rk4[n-1]+(h k2)/2];
               k4=f[x[n],rk4[n-1]+h k3];
                       rk4[n]=rk4[n-1]+(h/6)(k1+2k2+2k3+k4)]
In[7]:= solucion=Table[{x[i-1],Table[rk4[i],{i,0,10}][[i]]},
           {i,1,Length[Table[rk4[i],{i,0,10}]]}]  
{{0, 1}, {0.1, 1.00501}, {0.2, 1.0202},
{0.3, 1.04603}, {0.4, 1.08329}, {0.5, 1.13315},
{0.6, 1.19722}, {0.7, 1.27762}, {0.8, 1.37713},
{0.9, 1.4993}, {1., 1.64872}}
We have a set of points of the solution can be adjusted to a curve through any known
method. This curve is an approximation to the solution of the differential equation.

6.16 DIFFERENTIAL EQUATIONS SYSTEMS BY
APPROXIMATE METHODS
The Runge-Kutta methods and Euler can be extended to solving systems of
differential equations.
To solve the system:
dx/dt=f(t,x,y)
dy/dt=g(t,x,y)
x(t0)=x0, y(t0)=y0
Euler considered the following law of recurrence for a set of points {(xn,yn)} the
approximate solution:
x(n+1)=x(n)+hf(t(n),x(n),y(n))
y(n+1)=y(n)+hg(t(n),x(n),y(n))
where t(n)=t0+nh
Runge-Kutta consider the following law of recurrence:
x(n+1) = x(n)+h/6 (k1+2k2+2k3+k4)
y(n+1) = y(n)+h/6 (m1+2m2+2m3+m4)
donde k1=f(t(n),x(n),y(n)),
k2=f(t(n)+h/2,x(n)+hk1/2,y(n)+hm1/2),
k3=f(t(n)+h/2,x(n)+hk2/2,y(n+hm2/2)
k4=f(t(n)+h,x(n)+hk3,y(n)+hm3)
m1=g(t(n),x(n),y(n)),
m2=g(t(n)+h/2,x(n)+hk1/2,y(n)+hm1/2),
m3=g(t(n)+h/2,x(n)+hk2/2,y(n)+hm2/2)

m4=g(t(n)+h,x(n)+hk3,y(n)+hm3)
the value of h is given.
Exercise 6-15. Solve the following system of differential equations by Euler method and
Runge-Kutta:
                                               t
dx/dt = x-y+1,  dy/dt =x+3y+ e ,  x(0)=0, y(0)=1  for h= 0.1
We started using the algorithm of Euler.
In[1]:=f[t_,x_,y_]:=x-y+1;
In[2]:=g[t_,x_,y_]:=x+3y+E^(-t);
In[3]:=h=0.1;
In[4]:=x[0]=0;
In[5]:=y[0]=1;
In[6]:=t[n_]=h n;
In[7]:=x[n_]:=x[n]=x[n-1]+h(f[t[n-1],x[n-1],y[n-1]])
In[8]:=y[n_]:=y[n]=y[n-1]+h(g[t[n-1],x[n-1],y[n-1]])
In[9]:=solucion=Table[{t[i],x[i],y[i]},{i,0,10}]
{{0, 0, 1}, {0.1, 0, 1.4}, {0.2, -0.04, 1.91048},
{0.3, -0.135048, 2.5615}, {0.4, -0.304703, 3.39053},
{0.5, -0.574227, 4.44425},
{0.6, -0.976074, 5.78076}, {0.7, -1.55176, 7.47226},
{0.8, -2.35416, 9.60842}, {0.9, -3.45042, 12.3005},
 {1., -4.9255, 15.6862}}

We have a set of points of the system solution.
We will now apply the Runge-Kutta algorithm.
In[1]:=f[t_,x_,y_]:=x-y+1;
In[2]:=g[t_,x_,y_]:=x+3y+E^(-t);
In[3]:=h=0.1;
In[4]:=xrk[0]=0;
In[5]:=yrk[0]=1;
In[6]:=t[n_]=h n;
In[7]:=xrk[n_]:= Module[{k1,k2,k3,k4},
   k1=f[t[n-1],xrk[n-1],yrk[n-1]];
   m1=g[t[n-1],xrk[n-1],yrk[n-1]];
   k2=f[t[n-1]+h/2,xrk[n-1]+(h k1)/2,yrk[n-1]+(h m1)/2];
   m2=g[t[n-1]+h/2,xrk[n-1]+(h k1)/2,yrk[n-1]+(h m1)/2]; 
   k3=f[t[n-1]+h/2,xrk[n-1]+(h k2)/2,yrk[n-1]+(h m2)/2];
   m3=g[t[n-1]+h/2,xrk[n-1]+(h k2)/2,yrk[n-1]+(h m2)/2];
   k4=f[t[n-1]+h/2,xrk[n-1]+(h k3),yrk[n-1]+(h m3)];
   m4=g[t[n-1]+h/2,xrk[n-1]+(h k3),yrk[n-1]+(h m3)];
   xrk[n]=xrk[n-1]+(h/6)(k1+2k2+2k3+k4)]                        
In[8]:=yrk[n_]:= Module[{k1,k2,k3,k4},
   k1=f[t[n-1],xrk[n-1],yrk[n-1]];
   m1=g[t[n-1],xrk[n-1],yrk[n-1]];
   k2=f[t[n-1]+h/2,xrk[n-1]+(h k1)/2,yrk[n-1]+(h m1)/2];
   m2=g[t[n-1]+h/2,xrk[n-1]+(h k1)/2,yrk[n-1]+(h m1)/2]; 
   k3=f[t[n-1]+h/2,xrk[n-1]+(h k2)/2,yrk[n-1]+(h m2)/2];
   m3=g[t[n-1]+h/2,xrk[n-1]+(h k2)/2,yrk[n-1]+(h m2)/2];
   k4=f[t[n-1]+h/2,xrk[n-1]+(h k3),yrk[n-1]+(h m3)];
   m4=g[t[n-1]+h/2,xrk[n-1]+(h k3),yrk[n-1]+(h m3)];

   yrk[n]=yrk[n-1]+(h/6)(m1+2m2+2m3+m4)]                               
In[9]:=solution=Table[{t[i],xrk[i],yrk[i]},{i,0,10}]
{{0, 0, 1}, {0.1, -0.0226878, 1.46108},
{0.2, -0.103414, 2.06715},
{0.3, -0.265698, 2.86193}, {0.4, -0.54073, 3.90121},
{0.5, -0.969603, 5.25605}, {0.6, -1.60617, 7.0168},
{0.7, -2.52065, 9.29823}, {0.8, -3.80425, 12.2459},
{0.9, -5.57502, 16.0441}, {1., -7.98522, 20.926}}

6.17 DIFFERENTIAL EQUATIONS IN PARTIAL
DERIVATIVES
 
Mathematica directly addresses several types of differential equations in partial
derivatives. The program enables Calculus`PDSolve1 package, which solves some
differential equations in partial derivatives of the first order.
We are considering the equation of the form:
 
a(x,y,u) ¶u/¶x + b(x,y,z) ¶u/¶y = c(x,y,u)
called quasilinear equation, most of the time it will be possible to find a solution directly.
Otherwise it is used with Mathematica classical algebraic method of characteristics to
solve this type of equations. Likewise you can use the classic metods for other types
dieferenciales partial differential equations.
If c (x, y) = 0, the equation is called homogeneous, and if c (x, y, u) = d (x, y) u + s (x, y) is
called a linear equation.
Within the package PDSolve1 we have the following functions:
DSolve[ ecuación, u[x,y,…], {x,y,..}]           solves a quasi-linear equation in u[x,y,..]
CompleteIntegral[ecuación, u[x,y,…], {x,y,..}]
builds a complete integral of the partial differential
equation for u[x,y,…]
FirsIntegrals[{ec1,ec2,…},{u[x],v[x],..},x]   It gives a list of first integrals for the given
system in terms of u[x], v[x], ….. y   x
FirsIntegrals[{ec1,ec2,…},{u,v,..},x]

It gives a list of first integrals for the given system
in terms of u, v, ….. y   x
Exercise 6-16. Solve the following differential equations in partial derivatives:
                  
-(-x-y+u)2  + x2ux - uy  = 0
- xyz + z2uz  + y2uy  + x2ux  = 0
In[1]:=<<Calculus`PDSolve1`
For the first equation we propose the following:
In[2]:=DSolve[-(-x-y+u[x,y])^2+x^2*(D[u[x,y],x]-D[u[x,y],y])==0,                      
           u[x,y],{x,y}]
{{u[x, y] -> 
               2
    2 x + y - x  C[1][x + y] - x y C[1][x + y]
  -(––––––––––––––)}}
                -1 + x C[1][x + y]
Now we will integrate the second partial differential equation:
In[1]:= DSolve[-x y z + z^2 D[w[x,y,z],z]+y^2 D[w[x,y,z],y]+
                          x^2 D[w[x,y,z],x]==0,w[x,y,z],{x,y,z}]
{{w[x, y, z] ->
            2       x
         x y  z Log[-]
                    y
  -(–––––––—) +

              2
    -(x y) + y  + x z - y z
             2     x
        x y z  Log[-]
                   z              1   1  1   1
   –––––––— + C[1][- - -, - - -]}}
                         2        x   y  x   z
   -(x y) + x z + y z - z
Exercise 6-17. Calculate a complete integral to the following differential equations in
partial derivatives:
(x2  ux
2  )/ y + u = uy
-u + (2+y) uy  +  x ux  + 3 ux
2  = 0
-c + b uy  + a y ux  + ux
2   = 0
For the first equation we propose the following:
In[1]:=CompleteIntegral[Derivative[0,1][u][x,y]==(u[x,y]+
                                       x^2*Derivative[1,0][u][x,y]^2)/y,u[x,y],{x,y}]
                 2                                2
            -B[1]             B[1] Log[x]   Log[x]
{{u[x, y] -> –– + y B[2] - –––— - ––-}}
              4                    2           4
Now we will integrate the second partial differential equation:

CompleteIntegral[-u[x,y]+(2+y)*Derivative[0,1][u][x,y]+                                      
x*Derivative[1,0][u][x,y]+3*Derivative[1,0][u][x,y]^2==0,
           u[x,y],{x,y},IntegralConstants->F]
                         2
            x F[1]   F[1]
{{u[x, y] -> –– + –— + 2 F[2] + y F[2]}}
              6       12
In attempting to solve the third equation with DSolve automatically it invokes the
function CompleteIntegral.
In[1]= DSolve[-c+b*Derivative[0,1][u][x,y]+
                       a*y*Derivative[1,0][u][x,y]+
                       Derivative[1,0][u][x,y]^2==0,u[x,y],{x,y}]
DSolve::nlpde:
  This is a nonlinear partial differential equation.
    General solution   is not available. Trying to
    build a complete integral instead.
{{u[x, y] ->
                    2              2
  c y            a y  B[1]   y B[1]
  – + x B[1] - ––– - ––- + B[2] + y B[2]}}
   b                2 b         b
Exercise 6-18. Calculating the first integral to the following system of differential
equations:
u’ = - u(u+v)
v’ =  v(u+v)

In[1]:= FirstIntegrals[{u’[x]==-(u[x] (u[x]+v[x])),
                                    v’[x]==v[x] (u[x]+v[x])},{u,v},x]
                          u      
{-Sqrt[u v] x + ArcTan[–––], u v}
                                          Sqrt[u v]

6.18 ORTHOGONAL POLYNOMIALS
 
Two different functions f (x) and g (x) are said to be orthogonal on an interval [a, b] if
their inner product is 0, ie if
 
¡Error! Argumento de modificador no especificado.
An example of orthogonal functions can be family
fn(x)=sen(nx)  and  gn(x)=cos(nx), n=1,2,3,… in the interval [-p,p].
Mathematica provides an extensive list of orthogonal polynomials, which will be very
useful in solving certain nonlinear differential equations of higher order. The functions for
working with these polynomials are:
ChebyshevT[n,x]      Chebyshev polynomials of the first specie.
ChebyshevU[n,x]      Chebyshev polynomials of the second specie.
LegendreP[n,x]         Legendre polynomials
LegendreP[n,m,x]     Legendre associates polynomials.
HermiteH[n,x]                        Hermite polynomials.
LaguerreL[n,x]          Laguerre polynomials.
LaguerreL[n,a,x]       Laguerre generalized polynomials.
JacobiP[n,a,b,x]        Jacobi polynomials.

Gegenbauer[n,m,x]   Gegenbauer polynomials.
SphericalHarmonicY[l,m,n,a,b]
                                  Spherical harmonic polynomials
Let us now his relationship with the differential equations. Precisely this relationship
is what allows us to find solutions of certain nonlinear equations of higher order.
Chebyshev polynomials of first and second species
Chebyshev polynomials of the first specie are the solutions of the differential equation:
Legendre polynomials
They are solutions of the Legendre differential equation:
Legendre associate polynomials
They are solutions of differential equation:
¡Error! Argumento de modificador no especificado.
Hermite polynomials
They are solutions of the Hermite differential equation:

Laguerre generalized polynomials
They are the solutions of the Laguerre differential equation:
:
x y’’ + (a+1-x) y’ + n y = 0
Laguerre polynomials
They are the solutions of the Laguerre differential equation:
.
Jacobi polynomials
 
They are the solutions of the Jacobi differential equation:
                   α, β > -1
Gegenbauer polynomials
Gegenbauer polynomials are particular solutions of the Gegenbauer differential
equation:
Exercise 6-19. Finding solutions to differential equations:
¡Error! Argumento de modificador no especificado.

In[1]:= ChebyshevT[7,x]
          3        5       7
-7 x + 56 x  - 112 x  + 64 x
In[2]:= LegendreP[6,x]
         2        4        6
-5 + 105 x  - 315 x  + 231 x
–––––––––—
            16
In[3]:= HermiteH[5,x]
            3       5
120 x - 160 x  + 32 x
In[4]:= LaguerreL[5,x]
                  2        3       4    5
120 - 600 x + 600 x  - 200 x  + 25 x  - x
––––––––––––––
                  120
AIRY AND BESSEL FUNCTIONS
Are called Airy functions linearly independent solutions of linear second-order
differential equation:

y’’ - x y = 0  (Airy equation)
Are called Bessel functions linearly independent solutions of the differential equation:
2    2   2
y’’ + y’/x + (k  - n  /x  ) y = 0   (Bessel equation)
Are called modified Bessel functions of the linearly independent solutions of the
differential equation:
2    2   2
y’’ + y’/x - (k  + n  /x  ) y = 0   (modified Bessel equation)
About Mathematica implements the following functions:
AiryAi[z] y AiryBi[z]                         obtain independent solutions of the Airy
equation.
AiryAiPrime[z] y AiryBiPrime[z]
obtain derivatives of independent solutions of the Airy
equation.
 
BesselJ[n,z] y BesselY[n,z]
                                                          obtain independent solutions of the Bessel
equation.
BesselI[n,z] y BesselK[n,z] 
obtain independent solutions of the modified Bessel equation.

          
Exercise 6-20. Finding solutions to the differential equation:
x2  y’’ + x y’ + (x2 - 1/4)y = 0
This is the Bessel differential equation for n = 1/2. We obtain two linearly
independent solutions as follows:
In[1]:= BesselJ[1/2,x]
             1
Sqrt[2] Sqrt[–-] Sin[x]
            Pi x
In[2]:= BesselY[1/2,x]
               1
-(Sqrt[2] Sqrt[–-] Cos[x])
              Pi x
 

7 
APPENDIX. VARIABLES AND FUNCTIONS

7.1 VARIABLES
In Mathematica, variables are declared via the following syntax:
·      x = a, assigns the value “a” to the variable x.
 
·      Set [x, a], assigns the value a the variable x.
·      x = y = a, assigns the value “a” to the variables x and at the same time.
·      {x, y} = {a1, a2}, assigns different values to x and y at the same time.
·      {x, y} = {y, x}, exchanges the values of x and y
·      Clear [x] (or x =.), deletes the value assigned to x
For example, we can define the variable x and assign it the value 6 in the following way:
In [1]: = x = 6
Out [1] = 6
Equivalent to the above syntax would be as follows:
In [2]: = Set [x, 6]
Out [2] = 6

7.2 FUNCTIONS DEFINITION
Mathematica offers the possibility to define custom functions using the following syntax:
f [x_]: = expression: defines the function f for single variable x
g [x_, y_]: = expression: define function g in the variables x and y.
The general form of a function definition is:
f [variable1_, variable2_,…]: = expression
clear[f]: clears the function f.
Let’s see how to define the function f (x) = x ^ 3.
In [1]: = f [x_]: = x ^ 3
Now we calculate the values f (a+1), f (4) and f(3x+x^2).
In[2]:= f[a+1]
                    3
Out[2]=(1+a)
In[3]:= f[4]
Out[3]= 64
In[4]:= f[3x+x^2]

                         2 3
Out[4]:= (3 x + x )

7.3 RECURSIVE FUNCTIONS
Recursive definitions of functions you can use in Mathematica. For example, to define
the function factorial of as follows:
In[18]:= fact[1]=1;
In[19]:= fact[n_]:=n*fact[n-1]
To calculate the factorial of 40, we will use the following syntax:
In [20]: = fact [5]
Out [20] = 120
Also is you can set recursive functions on the basis of n values above and according to n
initial conditions. For example:
In [1]: = f [x_]: = f [x] = f [x - 1] + f [x - 2]
In [2]: = f [0] = f [1] = 1
Out [2] = 1
To calculate f (5) we use:
In [3]: = f [5]
Out [3] = 8

7.4 PIECEWISE FUNCTIONS
Piecewise functions tend to be defined in different ways for different intervals of
variation in the independent variable. Mathematica enables correct work with this type of
functions, which are defined, in the majority of cases, relying on the conditional commands,
as If, Which, etc. In Mathematica functions such flooring defined cablul especially operator
condicuionla If using adopts the following syntax:
If [condition, expression1, expression2]
           When the condition is true evaluates expression1, and when false expression2 is
evaluated.
As an application example we define the function:
In[12]:= Delta[x_] := If [x==0, 1, 0]
This function is set to 1 if x = 0 and in any other case,  0.
We then define the following function:
In [13]: = f [x_]: = If [x > 0, 1, 0]
This function takes the value 1 for all x greater than 0, and takes the value 0 for all x less
than or equal to 0.
To graphically represent this function, we propose:
In[14]:= Plot [f[x], {x, -1, 1}, Axes->{0, 0.5}]
Out [14] = see Figure 7.1

Figure 7.1
When it is necessary to control the function, rather than across a single condition, but of
several, is available the operator condicuional Wich with the following syntax:
Which [condition1, expression1,…, conditionn, expressionn]
           If the conditioni is true the expressioni is evaluated (i=1, 2, …,n). Putting True
as the last condition, gets evaluate the last expression if none of the previous conditions
have been certain.
As an example we consider the piecewise-defined function look:
In[15]:=g[x_]:=Which[-2<=x<=2, x^2, -3<x<-2, x^3, x<=-3, 0,                                        
   2<x<3,x, 3<=x, 0, True,x^2]
The function g to pieces at intervals is defined (-¥, - 3) (- 3, - 2), (- 2.2), (2.3), (3,¥).
We can graphically represent the function g as follows:
In [16]: = Plot [g [x], {x, - 4, 4}]
Out [16] = see Figure 7.2

Figure 7.2
Also we can graphically represent the function for the function g as follows:
In[16]:= Plot[g’[x], {x, -4, 4}]
We will now define a function, called rect, which is set to 1 in the interval [-1/3, 1/3] and
which is worth $ 0 in the rest of the real line. We will use the notation /, which can be
interpreted as “such that” or “whenever”.
In[23]:= rect[x_] := 1 /. (-1/3 <= x && x <= 1/3)
In[24]:= rect[x_] := 0 /. Abs[x] > 1/3
This function can also be written in the following way:
In[22] := Clear[rect];
In[23] := rect[x_ /. (-1/3 <= x && x >= 1/3)] := 1
In[24] := rect[x_ /. Abs[x] > 1/3] := 0

7.5 OPERATIONS WITH FUNCTIONS
Utilizae Mathematica the following functional operators:
InverseFunction [f]               inverse of the function f.
Composition [f, g,…]            Composed of f, g,…
Identity                                  identity function.
Identity [expr]                       applies the function identity to expr.
Nest [f, x, n]                           applies the function f on x, n times.
NestList [f, x, n]                    generates the list {x, f [x], f [f [x]]… n times].
Operate [f [x] p]                    calculates p [f] [x]
Operate [p, f [x], n]               applies the operator p in f n times.
As examples we have the following:
In[1]:= InverseFunction[ArcSin]
Out[1]= Sin
In[2]:= f[x_]:= x^2+x
In[3]:= g[x]:= x^3+1
In[4]:= Composition[f,g][x]
Out[4:= 1+x^3+(1+x^3)^2

In[5]:= Composition[g,f][x-1]
Out[5]= 1+(-1+(-1+x)^2+x)^3
In[6]:= Composition[f,Sin][x]
Out [5] = [x] + Sin [x] ^ 2
In[9]:= Clear[f,g]
In[1]:=Nest[f, x, 4]
Out[1]= f[f[f[f[x]]]]
In[2]:= NestList[f, x, 4]
Out[2]= {x, f[x], f[f[x]], f[f[f[x]]], f[f[f[f[x]]]]}
In[18]:= t = ((1 + a)(1 + b))[x]
Out[18] = ((1 + a) (1 + b))[x]
In[20]:= Operate[p, t]
Out[20]= p[(1 + a) (1 + b)][x]

7.6 DATA TYPES USED IN THE DEFINITION OF THE
FUNCTIONS
We already know that in Mathematica there is no need to declare the type of the variables
or functions, as in C or FORTRAN. Mathematica manipulates data more as the APL
programming language: deducing the type of data based on how you are using. Each
expression that defines a function is composed of objects in one or more of the following
atomic types: Integer, Real, Rational, Complex, Symbol, and String. The following table
gives an example of each of these indivisible types and their descriptions
Type                           description                            example
–––––––––––––––––––––––––––––––––––-
Integer                       integer number                                             3
Real                            real number in the way nn.mm                   3.4
Rational                     rational number a/b, a and b integers        3/4
Complex                    complex number of the form a + bI            3 + 4.2 I
Symbol                      value represented by a symbol                  Pi
String                         a string                                                          “red”
           Exercise 1. Define the functions f (x) = x ^ 2, g (x) = x ^(1/2) and h (x) = x + Sin
(x). Calculate f(2), g(4), h(pi/2), f(a-b^2) and ((x+h) - f (x) f) / h
In[1]:= clear[f, g, h]
In[1]:= f[x_]= x^2
               2
Out[1]= x

In[2]:= g[x_]= Sqrt[x]
Out[2]= Sqrt[x]
In[3]:= h[x_]= x+Sin[x]
In[4]:= f[2]
Out[4]= 4
In[5]:= g[4]
Out[5]= 2
In[6]:= h[Pi/2]
Out[6]= 1 + Pi/2
In[7]:= f[a-b^2]
                    2 2
Out[7]= (a- b )
In[8]:= (f[x+h]-f[x])/h
                  2                2
             - x     +  (h + x)
Out[8]=–––––––––
                         h
           Exercise 2. Given the function h defined by:
h(x,y) = (cos(x^2-y^2), sin(x^2-y^2))
Calculate h(1,2), h(-Pi,Pi), and h(cos(a^2), cos(1-a^2))

In [1]: = Clear [h]
In [2]: = h [x_, y_] = (Cos(x^2-y^2), Sin(x^2-y^2))
                          2   2         2   2
Out [2] = (Cos [x - y]-Sin [x - y])
In[3]:= h[1,2]
Out[3]= (Cos[3], Sin[3])
In[4]:= h[-Pi,Pi]
Out[4]= (1, 0)
In [5]: = h (cos(a^2), cos(1-a^2))
                               2 2                  2  2                 2                  2 2
Out [5] = (Cos [Cos [a] - Cos [1 - a]], Sin (Cos [a] - Cos [1 - a]])
           
Exercise 3. Sean f (x) = x ^ 2 + x, g (x) = x ^ 3 + 1 and k (x) = Sinx + Cosx.
Calculate:
f (g (x)), g (f(x-1)), f (k(Pi/3)), f (Sinx) and f (Sin (x+iy)).
In[1]:= Clear[f,g,h]
In[2]:= f[x_]=x^2+x; g[x_]=x^3+1; k[x_]=Sinx+Cosx;
In[3]:= Composition[f, g][x]

                     3            3  2
Out[3]= 1 + x  + (1 + x   ) 
In[4]:= Composition[g, f][x-1]
                                        2       3
Out[4]= 1 + (-1  + (-1 + x )  + x )
In[5]:= Composition[f, k][Pi/3]//Simplify
Out[5]= 3/2 + Sqrt[3]
In[6]:= Composition[f, Sin][x]
                                 2
Out [6] = [x] + Sin [x]
In[7]:= Composition[f, Sin][x + I y]
                                                2
Out [7] = [x + I y] + Sin [x + I y]
           Exercise 4. Is the function given by f (x) = x ^ 2 + x. calculate f (f (f (x))) and Sin
(Sin (Sin (Sin (Sin (Sinx)))
In[1]:= Nest[f,x,3]
                     2            2  2              2            2 2  2
Out[1]:= x + x + (x + x   )   + (x + x  + (x +  x  )   )
In [2]: = Nest [Sin, x, 6]
Out [2] = Sin [Sin [Sin [Sin [Sin [Sinx]]]
           
Exercise 5. Fibonacci succession {an} is defined by the law of recurrence
following:

a1 = 1, a2 = 1, an = a (n-1) + a (n-2)
Represent this succession by a recurrent function and calculate a5.
In[1]:= Clear[f]
In[2]:= f[x_] := f[x] = f[x - 1] + f[x -2];
In [3]: = f [0] = f [1] = 1
Out [3] = 1
We can now calculate f (5).
In [3]: = f [5]
Out [3] = 8
           Exercise 6. Define a function f (x), which is set to 1 in the interval [-1/2, 1/2] and
that is set to 0 if x is greater than 1/2, and that it is set to - 1 if x is less than         - 1/2.
Represent it graphically.
We will use the notation /, which can be interpreted as such that, or whenever (some
versions of the program have this option obsolete).
In[1]:= Clear[f]
In[2]:= f[x_]:= -1 /. x < -1/2
In[3]:= f[x_] := 1 /. (-1/2 <= x && x <= 1/2)
In[4]:= f[x_] := 0 /. x > 1/2
Another way to express this function would be as follows:
In[3]:= f[x_]:= Wich[x<-1/2, -1, (-1/2<=x && x<1/2), 1, x>1/2, 0]

We now represent the function between - 3 and 3
In [4]: = Plot [f [x], {x, - 3, 3}]
 
Exercise 7. Calculating the compose function of f (x) = [x+Cox [x]] and its inverse.
Verify that the result is correct.
In[1]:= Clear[f]
In[2]:= f[x_]:= Sin[x+Cox[x]];
In[3]:= g[x_]:=InverseFunction[f][x]
In[4]:= Composition[f, g][x]
Out [4] = x
Obviously, the result is the identity function.
 

 

