
This page intentionally left blank

Lambda-Calculus and Combinators, an Introduction
Combinatory logic and λ-calculus were originally devised in the 1920s for
investigating the foundations of mathematics using the basic concept of ‘operation’
instead of ‘set’. They have since evolved into important tools for the development and
study of programming languages.
The authors’ previous book Introduction to Combinators and λ-Calculus served as
the main reference for introductory courses on λ-calculus for over twenty years: this
long-awaited new version offers the same authoritative exposition and has been
thoroughly revised to give a fully up-to-date account of the subject.
The grammar and basic properties of both combinatory logic and λ-calculus are
discussed, followed by an introduction to type-theory. Typed and untyped versions of
the systems, and their differences, are covered. λ-calculus models, which lie behind
much of the semantics of programming languages, are also explained in depth.
The treatment is as non-technical as possible, with the main ideas emphasized and
illustrated by examples. Many exercises are included, from routine to advanced, with
solutions to most of them at the end of the book.
Review of Introduction to Combinators and λ-Calculus:
‘This book is very interesting and well written, and is highly recommended to
everyone who wants to approach combinatory logic and λ-calculus (logicians or
computer scientists).’
Journal of Symbolic Logic
‘The best general book on λ-calculus (typed or untyped) and the theory of
combinators.’
G´erard Huet, INRIA


Lambda-Calculus and Combinators,
an Introduction
J. ROGER HINDLEY
Department of Mathematics,
Swansea University, Wales, UK
JONATHAN P. SELDIN
Department of Mathematics and Computer Science,
University of Lethbridge, Alberta, Canada

CAMBRIDGE UNIVERSITY PRESS
Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São Paulo
Cambridge University Press
The Edinburgh Building, Cambridge CB2 8RU, UK
First published in print format
ISBN-13    978-0-521-89885-0
ISBN-13
978-0-511-41423-7
© Cambridge University Press 2008
2008
Information on this title: www.cambridge.org/9780521898850
This publication is in copyright. Subject to statutory exception and to the provision of 
relevant collective licensing agreements, no reproduction of any part may take place 
without the written permission of Cambridge University Press.
Cambridge University Press has no responsibility for the persistence or accuracy of urls 
for external or third-party internet websites referred to in this publication, and does not 
guarantee that any content on such websites is, or will remain, accurate or appropriate.
Published in the United States of America by Cambridge University Press, New York
www.cambridge.org
eBook (EBL)
hardback

To Carol, Goldie
and
Julie

Contents
Preface
page ix
1
The λ-calculus
1
1A
Introduction
1
1B
Term-structure and substitution
5
1C
β-reduction
11
1D
β-equality
16
2
Combinatory logic
21
2A
Introduction to CL
21
2B
Weak reduction
24
2C
Abstraction in CL
26
2D
Weak equality
29
3
The power of λ and combinators
33
3A
Introduction
33
3B
The ﬁxed-point theorem
34
3C
B¨ohm’s theorem
36
3D
The quasi-leftmost-reduction theorem
40
3E
History and interpretation
43
4
Representing the computable functions
47
4A
Introduction
47
4B
Primitive recursive functions
50
4C
Recursive functions
56
4D
Abstract numerals and Z
61
5
The undecidability theorem
63
6
The formal theories λβ and CLw
69
6A
The deﬁnitions of the theories
69
6B
First-order theories
72
vi

Contents
vii
6C
Equivalence of theories
73
7
Extensionality in λ-calculus
76
7A
Extensional equality
76
7B
βη-reduction in λ-calculus
79
8
Extensionality in combinatory logic
82
8A
Extensional equality
82
8B
Axioms for extensionality in CL
85
8C
Strong reduction
89
9
Correspondence between λ and CL
92
9A
Introduction
92
9B
The extensional equalities
95
9C
New abstraction algorithms in CL
100
9D
Combinatory β-equality
102
10
Simple typing, Church-style
107
10A
Simple types
107
10B
Typed λ-calculus
109
10C
Typed CL
115
11
Simple typing, Curry-style in CL
119
11A
Introduction
119
11B
The system TA→
C
122
11C
Subject-construction
126
11D
Abstraction
127
11E
Subject-reduction
130
11F
Typable CL-terms
134
11G
Link with Church’s approach
137
11H
Principal types
138
11I
Adding new axioms
143
11J
Propositions-as-types and normalization
147
11K
The equality-rule Eq′
155
12
Simple typing, Curry-style in λ
159
12A
The system TA→
λ
159
12B
Basic properties of TA→
λ
165
12C
Typable λ-terms
170
12D
Propositions-as-types and normalization
173
12E
The equality-rule Eq
′
176
13
Generalizations of typing
180
13A
Introduction
180
13B
Dependent function types, introduction
181

viii
Contents
13C
Basic generalized typing, Curry-style in λ
183
13D
Deductive rules to deﬁne types
187
13E
Church-style typing in λ
191
13F
Normalization in PTSs
202
13G
Propositions-as-types
209
13H
PTSs with equality
217
14
Models of CL
220
14A
Applicative structures
220
14B
Combinatory algebras
223
15
Models of λ-calculus
229
15A
The deﬁnition of λ-model
229
15B
Syntax-free deﬁnitions
236
15C
General properties of λ-models
242
16
Scott’s D∞and other models
247
16A
Introduction: complete partial orders
247
16B
Continuous functions
252
16C
The construction of D∞
256
16D
Basic properties of D∞
261
16E
D∞is a λ-model
267
16F
Some other models
271
Appendix A1
Bound variables and α-conversion
276
Appendix A2
Conﬂuence proofs
282
Appendix A3
Strong normalization proofs
293
Appendix A4
Care of your pet combinator
305
Appendix A5
Answers to starred exercises
307
References
323
List of symbols
334
Index
337

Preface
The λ-calculus and combinatory logic are two systems of logic which
can also serve as abstract programming languages. They both aim to
describe some very general properties of programs that can modify other
programs, in an abstract setting not cluttered by details. In some ways
they are rivals, in others they support each other.
The λ-calculus was invented around 1930 by an American logician
Alonzo Church, as part of a comprehensive logical system which included
higher-order operators (operators which act on other operators). In fact
the language of λ-calculus, or some other essentially equivalent notation,
is a key part of most higher-order languages, whether for logic or for
computer programming. Indeed, the ﬁrst uncomputable problems to be
discovered were originally described, not in terms of idealized computers
such as Turing machines, but in λ-calculus.
Combinatory logic has the same aims as λ-calculus, and can express
the same computational concepts, but its grammar is much simpler. Its
basic idea is due to two people: Moses Sch¨onﬁnkel, who ﬁrst thought of
it in 1920, and Haskell Curry, who independently re-discovered it seven
years later and turned it into a workable technique.
The purpose of this book is to introduce the reader to the basic meth-
ods and results in both ﬁelds.
The reader is assumed to have no previous knowledge of these ﬁelds,
but to know a little about propositional and predicate logic and recursive
functions, and to have some experience with mathematical induction.
Exercises are included, and answers to most of them (those marked ∗)
are given in an appendix at the end of the book. In the early chapters
there are also some extra exercises without answers, to give more routine
practice if needed.
ix

x
Preface
References for further reading are included at the ends of appropriate
chapters, for the reader who wishes to go deeper.
Some chapters on special topics are included after the initial basic
chapters. However, no attempt has been made to cover all aspects of
λ-calculus and combinatory logic; this book is only an introduction, not
a complete survey.
This book is essentially an updated and re-written version of [HS86].1
It assumes less background knowledge. Those parts of [HS86] which are
still relevant have been retained here with only minor changes, but other
parts have been re-written considerably. Many errors have been cor-
rected. More exercises have been added, with more detailed answers,
and the references have been brought up to date. Some technical details
have been moved from the main text to a new appendix.
The three chapters on types in [HS86] have been extensively re-written
here. Two of the more specialized chapters in [HS86], on higher-order
logic and the consistency of arithmetic, have been dropped.
Acknowledgements
The authors are very grateful to all those who
have made comments on [HS86] which have been very useful in preparing
the present book, especially G´erard Berry, Steven Blake, Naim C¸aˇgman,
Thierry Coquand, Clemens Grabmayer, Yexuan Gui, Benedetto Intrig-
ila, Kenichi Noguchi, Hiroakira Ono, Gabriele Ricci, Vincenzo Scianni,
John Shepherdson, Lewis Stiller, John Stone, Masako Takahashi, Peter
Trigg and Pawel Urzyczyn.
Their comments have led to many improvements and the correction
of several errors. (Any errors that remain are entirely the authors’ re-
sponsibility, however.)
On the production side, the authors wish to thank Larissa Kowbuz for
her very accurate typing of an early draft, the designers of LATEX and its
associated software for the actual type-setting, and M. Tatsuta for the
use of his macro ‘proof.sty’. We are also very grateful to Chris Whyley
for technical help, and to Cambridge University Press, especially David
Tranah, for their expert input.
On the ﬁnancial side we thank the National Sciences and Engineering
Research Council of Canada for a grant which enabled a consultation
visit by Hindley to Seldin in 2006, and the Department of Mathemat-
ics and Computer Science of the University of Lethbridge for helpful
hospitality during that visit.
1 Which itself was developed from [HLS72] which was written with Bruce Lercher.

Preface
xi
Last but of course not least, the authors are very grateful to their
wives, Carol Hindley and Goldie Morgentaler, for much encouragement
and patient tolerance during this book’s preparation.
Notes on the text
This book uses a notation for functions and
relations that is fairly standard in logic: ordered pairs are denoted by
‘⟨, ⟩’, a binary relation is regarded as a set of ordered pairs, and a
function as a binary relation such that no two of its pairs have the
same ﬁrst member. If any further background material is needed, it can
be found in textbooks on predicate logic; for example [Dal97], [Coh87],
[End00], [Men97] or [Rau06].
The words ‘function’, ‘mapping’ and ‘map’ are used interchangeably,
as usual in mathematics.
But the word ‘operator’ is reserved for a
slightly diﬀerent concept of function. This is explained in Chapter 3,
though in earlier chapters the reader should think of ‘operator’ and
‘function’ as meaning the same.
As usual in mathematics, the domain of a function φ is the set of all
objects a such that φ(a) is deﬁned, and the range of φ is the set of all
objects b such that (∃a)(b = φ(a)). If A and B are sets, a function from
A to B is a function whose domain is A and whose range is a subset of B.
Finally, a note about ‘we’ in this book: ‘we’ will almost always mean
the reader and the authors together, not the authors alone.


1
The λ-calculus
1A
Introduction
What is usually called λ-calculus is a collection of several formal systems,
based on a notation invented by Alonzo Church in the 1930s. They are
designed to describe the most basic ways that operators or functions can
be combined to form other operators.
In practice, each λ-system has a slightly diﬀerent grammatical struc-
ture, depending on its intended use. Some have extra constant-symbols,
and most have built-in syntactic restrictions, for example type-restrict-
ions. But to begin with, it is best to avoid these complications; hence
the system presented in this chapter will be the ‘pure’ one, which is
syntactically the simplest.
To motivate the λ-notation, consider the everyday mathematical ex-
pression ‘x −y’. This can be thought of as deﬁning either a function f
of x or a function g of y;
f(x) = x −y,
g(y) = x −y,
or
f :
x →x −y,
g :
y →x −y.
And there is a need for a notation that gives f and g diﬀerent names
in some systematic way. In practice, mathematicians usually avoid this
need by various ‘ad-hoc’ special notations, but these can get very clumsy
when higher-order functions are involved (functions which act on other
functions).
Church’s notation is a systematic way of constructing, for each expres-
sion involving ‘x’, a notation for the corresponding function of x (and
similarly for ‘y’, etc.). Church introduced ‘λ’ as an auxiliary symbol and
1

2
The λ-calculus
wrote
f = λx . x −y
g = λy . x −y.
For example, consider the equations
f(0) = 0 −y,
f(1) = 1 −y.
In the λ-notation these become
(λx . x −y)(0) = 0 −y,
(λx . x −y)(1) = 1 −y.
These equations are clumsier than the originals, but do not be put oﬀ
by this; the λ-notation is principally intended for denoting higher-order
functions, not just functions of numbers, and for this it turns out to be
no worse than others.1 The main point is that this notation is system-
atic, and therefore more suitable for incorporation into a programming
language.
The λ-notation can be extended to functions of more than one vari-
able. For example, the expression ‘x −y’ determines two functions h
and k of two variables, deﬁned by
h(x, y) = x −y,
k(y, x) = x −y.
These can be denoted by
h = λxy . x −y,
k = λyx . x −y.
However, we can avoid the need for a special notation for functions of
several variables by using functions whose values are not numbers but
other functions. For example, instead of the two-place function h above,
consider the one-place function h⋆deﬁned by
h⋆= λx . (λy . x −y).
For each number a, we have
h⋆(a) = λy . a −y;
hence for each pair of numbers a, b,
(h⋆(a))(b)
=
(λy . a −y)(b)
=
a −b
=
h(a, b).
1 For example, one fairly common notation in mathematics is f = x →x −y, which
is essentially just the λ-notation in disguise, with ‘x →’ instead of ‘λx’.

1A Introduction
3
Thus h⋆can be viewed as ‘representing’ h. For this reason, we shall
largely ignore functions of more than one variable in this book.
From now on, ‘function’ will mean ‘function of one variable’ unless
explicitly stated otherwise. (The use of h⋆instead of h is usually called
currying.2)
Having looked at λ-notation in an informal context, let us now con-
struct a formal system of λ-calculus.
Deﬁnition 1.1 (λ-terms)
Assume that there is given an inﬁnite se-
quence of expressions v0, v00, v000, . . . called variables, and a ﬁnite,
inﬁnite or empty sequence of expressions called atomic constants, dif-
ferent from the variables. (When the sequence of atomic constants is
empty, the system will be called pure, otherwise applied.) The set of
expressions called λ-terms is deﬁned inductively as follows:
(a) all variables and atomic constants are λ-terms (called atoms);
(b) if M and N are any λ-terms, then (MN) is a λ-term (called an
application);
(c) if M is any λ-term and x is any variable, then (λx.M) is a λ-term
(called an abstraction).
Example 1.2 (Some λ-terms)
(a)
(λv0.(v0v00)) is a λ-term.
If x, y, z are any distinct variables, the following are λ-terms:
(b)
(λx.(xy)),
(d) (x (λx.(λx.x))),
(c)
((λy.y)(λx.(xy))),
(e) (λx.(yz)).
In (d), there are two occurrences of λx in one term; this is allowed by
Deﬁnition 1.1, though not encouraged in practice. Part (e) shows a term
of form (λx.M) such that x does not occur in M; this is called a vacuous
abstraction, and such terms denote constant functions (functions whose
output is the same for all inputs).
By the way, the expression ‘λ’ by itself is not a term, though it may
occur in terms; similarly the expression ‘λx’ is not a term.
2 Named after Haskell Curry, one of the inventors of combinatory logic.
Curry
always insisted that he got the idea of using h⋆from M. Sch¨onﬁnkel’s [Sch24] (see
[CF58, pp. 8, 10]), but most workers seem to prefer to pronounce ‘currying’ rather
than ‘sch¨onﬁnkeling’. The idea also appeared in 1893 in [Fre93, Vol. 1, Section 4].

4
The λ-calculus
Notation 1.3 Capital letters will denote arbitrary λ-terms in this chap-
ter. Letters ‘x’, ‘y’, ‘z’, ‘u’, ‘v’, ‘w’ will denote variables throughout the
book, and distinct letters will denote distinct variables unless stated
otherwise.
Parentheses will be omitted in such a way that, for example, ‘MNPQ’
will denote the term (((MN)P)Q). (This convention is called associa-
tion to the left.) Other abbreviations will be
λx.PQ
for
(λx.(PQ)),
λx1x2 . . . xn .M
for
(λx1.(λx2.(. . . (λxn .M) . . .))).
Syntactic identity of terms will be denoted by ‘≡’; in other words
M ≡N
will mean that M is exactly the same term as N. (The symbol ‘=’ will
be used in formal theories of equality, and for identity of objects that
are not terms, such as numbers.) It will be assumed of course that if
MN ≡PQ then M ≡P and N ≡Q, and if λx.M ≡λy.P then x ≡y
and M ≡P. It will also be assumed that variables are distinct from
constants, and applications are distinct from abstractions, etc.
Such
assumptions are always made when languages are deﬁned, and will be
left unstated in future.
The cases k = 0, n = 0 in statements like ‘P ≡MN1 . . . Nk (k ≥0)’
or ‘T has form λx1 . . . xn .PQ (n ≥0)’ will mean ‘P ≡M’ or ‘T has
form PQ’.
‘λ’ will often be used carelessly to mean ‘λ-calculus in general’.
‘Iﬀ’ will be used for ‘if and only if’.
Exercise 1.4 ∗Insert the full number of parentheses and λ’s into the
following abbreviated λ-terms:
(a)
xyz(yx),
(d)
(λu.vuu)zy,
(b)
λx.uxy,
(e)
ux(yz)(λv.vy),
(c)
λu.u(λx.y),
(f)
(λxyz.xz(yz))uvw.
Informal interpretation 1.5 Not all systems based on λ-calculus use
all the terms allowed by Deﬁnition 1.1, and in most systems, some terms
are left uninterpreted, as we shall see later. But the interpretations of
those λ-terms which are interpreted may be given as follows, roughly
speaking.

1B Terms and substitution
5
In general, if M has been interpreted as a function or operator, then
(MN) is interpreted as the result of applying M to argument N, pro-
vided this result exists.3
A term (λx.M) represents the operator or function whose value at an
argument N is calculated by substituting N for x in M.
For example, λx.x(xy) represents the operation of applying a function
twice to an object denoted by y; and the equation
(λx.x(xy))N = N(Ny)
holds for all terms N, in the sense that both sides have the same inter-
pretation.
For a second example, λx.y represents the constant function that
takes the value y for all arguments, and the equation
(λx.y)N = y
holds in the same sense as before.
This is enough on interpretation for the moment; but more will be
said in Chapter 3, Discussion 3.27.
1B
Term-structure and substitution
The main topic of the chapter will be a formal procedure for calculating
with terms, that will closely follow their informal meaning. But before
deﬁning it, we shall need to know how to substitute terms for variables,
and this is not entirely straightforward. The present section covers the
technicalities involved. The details are rather boring, and the reader
who is just interested in main themes should read only up to Deﬁnition
1.12 and then go to the next section.
By the way, in Chapter 2 a simpler system called combinatory logic
will be described, which will avoid most of the boring technicalities; but
for this gain there will be a price to pay.
Deﬁnition 1.6
The length of a term M (called lgh(M)) is the total
number of occurrences of atoms in M. In more detail, deﬁne
3 The more usual notation for function-application is M (N), but historically (M N)
has become standard in λ-calculus. This book uses the (M N) notation for formal
terms (following Deﬁnition 1.1(b)), but reverts to the common notation, e.g. f(a),
in informal discussions of functions of numbers, etc.

6
The λ-calculus
(a)
lgh(a)
= 1
for atoms a;
(b)
lgh(MN)
= lgh(M) + lgh(N);
(c)
lgh(λx.M) = 1 + lgh(M).
The phrase ‘induction on M’ will mean ‘induction on lgh(M)’.
For example, if M ≡x(λy.yux) then lgh(M) = 5.
Deﬁnition 1.7 For λ-terms P and Q, the relation P occurs in Q (or P
is a subterm of Q, or Q contains P) is deﬁned by induction on Q, thus:
(a)
P occurs in P;
(b)
if P occurs in M or in N, then P occurs in (MN);
(c)
if P occurs in M or P ≡x, then P occurs in (λx.M).
The meaning of ‘an occurrence of P in Q’ is assumed to be intu-
itively clear. For example, in the term ((xy)(λx.(xy))) there are two
occurrences of (xy) and three occurrences of x.4
Exercise 1.8 ∗(Hint: in each part below, ﬁrst write the given terms
in full, showing all parentheses and λ’s.)
(a) Mark all the occurrences of xy in the term λxy.xy.
(b) Mark all the occurrences of uv in x(uv)(λu.v(uv))uv.
(c) Does λu.u occur in λu.uv ?
Deﬁnition 1.9 (Scope) For a particular occurrence of λx.M in a term
P, the occurrence of M is called the scope of the occurrence of λx on
the left.
Example 1.10 Let
P ≡(λy.yx(λx.y(λy.z)x))vw.
The scope of the leftmost λy in P is yx(λx.y(λy.z)x), the scope of λx
is y(λy.z)x, and that of the rightmost λy is z.
Deﬁnition 1.11 (Free and bound variables)
An occurrence of a
variable x in a term P is called
• bound if it is in the scope of a λx in P,
4 The reader who wants more precision can deﬁne an occurrence of P in Q to be a
pair ⟨P, p⟩where p is some indicator of the position at which P occurs in Q. There
are several deﬁnitions of suitable position indicators in the literature, for example
in [Ros73, p. 167] or [Hin97, pp. 140–141]. But it is best to avoid such details for
as long as possible.

1B Terms and substitution
7
• bound and binding, iﬀit is the x in λx,
• free otherwise.
If x has at least one binding occurrence in P, we call x a bound variable
of P. If x has at least one free occurrence in P, we call x a free variable
of P. The set of all free variables of P is called
FV(P).
A closed term is a term without any free variables.
Examples Consider the term xv(λyz.yv)w: this is really

(xv)(λy.(λz.(yv)))

w

,
and in it the x on the left is free, the leftmost v is free, the leftmost y
is both bound and binding, the only z is the same, the rightmost y is
bound but not binding, the rightmost v is free, and the only w is free.
In the term P in Example 1.10, all four y’s are bound, the leftmost
and rightmost y’s are also binding, the left-hand x is free, the central x
is bound and binding, the right-hand x is bound but not binding, and
z, v, w are free; hence
FV(P) = {x, z, v, w}.
Note that x is both a free and a bound variable of P; this is not normally
advisable in practice, but is allowed in order to keep the deﬁnition of
‘λ-term’ simple.
Deﬁnition 1.12 (Substitution)
For any M, N, x, deﬁne [N/x]M to
be the result of substituting N for every free occurrence of x in M, and
changing bound variables to avoid clashes. The precise deﬁnition is by
induction on M, as follows (after [CF58, p. 94]).
(a) [N/x] x
≡N;
(b) [N/x] a
≡a
for all atoms a ̸≡x;
(c) [N/x](PQ)
≡

[N/x]P [N/x]Q

;
(d) [N/x](λx.P) ≡λx.P;
(e) [N/x](λy.P) ≡λy.P
if x ̸∈FV(P);
(f) [N/x](λy.P) ≡λy.[N/x]P
if x ∈FV(P) and y ̸∈FV(N);
(g) [N/x](λy.P) ≡λz.[N/x][z/y]P
if x ∈FV(P) and y ∈FV(N).
(In 1.12(e)–(g), y ̸≡x; and in (g), z is chosen to be the ﬁrst variable
̸∈FV(NP).)

8
The λ-calculus
Remark 1.13 The purpose of clause 1.12(g) is to prevent the intuitive
meaning of [N/x](λy.P) from depending on the bound variable y. For
example, take three distinct variables w, x, y and look at
[w/x](λy.x).
The term λy.x represents the constant function whose value is always
x, so we should intuitively expect [w/x](λy.x) to represent the constant
function whose value is always w. And this is what we get; by 1.12(f)
and (a) we have
[w/x](λy.x) ≡λy.w.
Now consider [w/x](λw.x). The term λw.x represents the constant
function whose value is x, just as λy.x did. So we should hope that
[w/x](λw.x) would represent the constant function whose value is always
w.
But if [w/x](λw.x) was evaluated by (f), our hope would fail; we
would have
[w/x](λw.x) ≡λw.w,
which represents the identity function, not a constant function. Clause
(g) rescues our hope. By (g) with N ≡y ≡w, we have
[w/x](λw.x)
≡
λz.[w/x][z/w]x
≡
λz.[w/x]x
by 1.12 (b)
≡
λz.w,
which represents the desired constant function.
Exercise 1.14 ∗Evaluate the following substitutions:
(a)
[(uv)/x] (λy.x(λw.vwx)),
(b)
[(λy.xy)/x] (λy.x(λx.x)),
(c)
[(λy.vy)/x] (y (λv.xv)),
(d)
[(uv)/x] (λx.zy).
Lemma 1.15 For all terms M, N and variables x:
(a)
[x/x]M ≡M;
(b)
x ̸∈FV(M)
=⇒
[N/x]M ≡M;
(c)
x ∈FV(M)
=⇒
FV([N/x]M) = FV(N) ∪

FV(M) −{x}

;
(d)
lgh([y/x]M) = lgh(M).

1B Terms and substitution
9
Proof Easy, by checking the clauses of Deﬁnition 1.12.
Lemma 1.16 Let x, y, v be distinct (the usual notation convention),
and let no variable bound in M be free in vPQ. Then
(a) [P/v][v/x]M ≡[P/x]M
if v ̸∈FV(M);
(b) [x/v][v/x]M
≡M
if v ̸∈FV(M);
(c) [P/x][Q/y]M ≡[([P/x]Q)/y][P/x]M if y ̸∈FV(P);
(d) [P/x][Q/y]M ≡[Q/y][P/x]M
if y ̸∈FV(P), x ̸∈FV(Q);
(e) [P/x][Q/x]M ≡[([P/x]Q)/x]M.
Proof
The restriction on variables bound in M ensures that 1.12(g)
is never used in the substitutions.
Parts (a), (c), (e) are proved by
straightforward but boring inductions on M. Part (b) follows from (a)
and 1.15(a), and (d) follows from (c) and 1.15(b).
Deﬁnition 1.17 (Change of bound variables, congruence)
Let
a term P contain an occurrence of λx.M, and let y ̸∈FV(M). The act
of replacing this λx.M by
λy.[y/x]M
is called a change of bound variable or an α-conversion in P. IﬀP can
be changed to Q by a ﬁnite (perhaps empty) series of changes of bound
variables, we shall say P is congruent to Q, or P α-converts to Q, or
P ≡α Q.
Example 1.18
λxy.x(xy)
≡
λx.(λy.x(xy))
≡α
λx.(λv.x(xv))
≡α
λu.(λv.u(uv))
≡
λuv.u(uv).
Deﬁnition 1.17 comes from [CF58, p. 91].
The name ‘α-converts’
comes from the same book, as do other Greek-letter names that will
be used later; some will look rather arbitrary but they have become
standard notation.
Lemma 1.19
(a) If P ≡α Q then FV(P) = FV(Q);

10
The λ-calculus
(b) The relation ≡α is reﬂexive, transitive and symmetric. That is,
for all P, Q, R, we have:
(reﬂexivity)
P ≡α P,
(transitivity)
P ≡α Q, Q ≡α R
=⇒
P ≡α R,
(symmetry)
P ≡α Q
=⇒
Q ≡α P.
Proof
For (a), see A1.5(f) in Appendix A1. For (b): reﬂexivity and
transitivity are obvious; for symmetry, if P goes to Q by a change of
bound variable, further changes can be found that bring Q back to P;
details are in Appendix A1, A1.5(e).
Lemma 1.20 If we remove from Lemma 1.16 the condition on variables
bound in M, and replace ‘≡’ by ‘≡α’, that lemma stays true.
Proof By [CF58, p. 95, Section 3E Theorem 2(c)].
Lemma 1.21 M ≡α M ′, N ≡α N ′ =⇒[N/x]M ≡α [N ′/x]M ′.
Proof By Appendix A1’s Lemma A1.10.
Note 1.22
Lemma 1.21 can be viewed as saying that the opera-
tion of substitution is well-behaved with respect to α-conversion: if we
α-convert the inputs of a substitution, then the output will not change
by anything more complicated than ≡α. All the operations to be intro-
duced later will also be well-behaved in a similar sense. (More details are
in Appendix A1.) Thus, when a bound variable in a term P threatens
to cause some trouble, for example by making a particular substitution
complicated, we can simply change it to a new harmless variable and
use the resulting new term instead of P.
Further, two α-convertible terms play identical roles in nearly all ap-
plications of λ-calculus, and are always given identical interpretations;
so it makes sense to think of them as identical. In fact most writers use
‘P ≡Q’ to mean ‘P ≡α Q’; the present book will do the same from
Chapter 3 onward.
Remark 1.23 (Simultaneous substitution)
It is possible to modify
the deﬁnition of [N/x]M in 1.12 to deﬁne simultaneous substitution
[N1/x1, . . . , Nn/xn]M
for n ≥2. We shall not need the details here, as only very simple special

1C β-reduction
11
cases of simultaneous substitution will be used in this book.
A full
deﬁnition is in [Sto88, Section 2]; the key is to ﬁrst change any bound
variables in M that might cause problems.
By the way, [N1/x1, . . . , Nn/xn]M should not be confused with the
result of n successive substitutions
[N1/x1](. . . ([Nn/xn]M) . . .).
For example, take n = 2, N1 ≡u, N2 ≡x1, M ≡x1x2; then
[u/x1]([x1/x2]M)
≡
[u/x1](x1x1)
≡
uu,
[u/x1, x1/x2]M
≡
ux1.
1C
β-reduction
The topic of this section is the calculation procedure that lies at the
heart of λ-calculus and gives it its power.
A term of form (λx.M)N represents an operator λx.M applied to an
argument N. In the informal interpretation of λx.M, its value when
applied to N is calculated by substituting N for x in M, so (λx.M)N
can be ‘simpliﬁed’ to [N/x]M. This simpliﬁcation-process is captured
in the following deﬁnition.
Deﬁnition 1.24 (β-contracting, β-reducing) Any term of form
(λx.M)N
is called a β-redex and the corresponding term
[N/x]M
is called its contractum. Iﬀa term P contains an occurrence of (λx.M)N
and we replace that occurrence by [N/x]M, and the result is P ′, we say
we have contracted the redex-occurrence in P, and P β-contracts to P ′
or
P ▷1β P ′.
IﬀP can be changed to a term Q by a ﬁnite (perhaps empty) series of

12
The λ-calculus
β-contractions and changes of bound variables, we say P β-reduces to
Q, or
P ▷β Q.
Example 1.25
(a)
(λx.x(xy))N
▷1β
N(Ny).
(b)
(λx.y)N
▷1β
y.
(c)
(λx.(λy.yx)z)v
▷1β
[v/x] ((λy.yx)z)
≡(λy.yv)z
▷1β
[z/y] (yv)
≡zv.
(d)
(λx.xx)(λx.xx)
▷1β
[(λx.xx)/x] (xx) ≡(λx.xx)(λx.xx)
▷1β
[(λx.xx)/x] (xx) ≡(λx.xx)(λx.xx)
. . .
etc.
(e)
(λx.xxy)(λx.xxy) ▷1β
(λx.xxy)(λx.xxy)y
▷1β
(λx.xxy)(λx.xxy)yy
. . .
etc.
Example 1.25(d) shows that the ‘simpliﬁcation’ process need not al-
ways simplify. Even worse, (e) shows that it can actually complicate.
These examples also show that the ‘simpliﬁcation’ process need not ter-
minate; in fact, it terminates iﬀit reaches a term containing no redexes.
Deﬁnition 1.26
A term Q which contains no β-redexes is called a
β-normal form (or a term in β-normal form or just a β-nf ). The class
of all β-normal forms is called β-nf or λβ-nf. If a term P β-reduces to a
term Q in β-nf, then Q is called a β-normal form of P.
The ‘β’ may be omitted when this causes no confusion.
Example 1.27
(a) In 1.25(c), zv is a β-normal form of (λx.(λy.yx)z)v.
(b) Let L ≡(λx.xxy)(λx.xxy). By 1.25(e) we have
L ▷1β Ly ▷1β Lyy ▷1β . . .
This sequence is inﬁnite and there is no other way that L can be
β-reduced, so L has no β-normal form.
(c) Let P ≡(λu.v)L for the above L. Then P can be reduced in two
diﬀerent ways (at least), thus:

1C β-reduction
13
(i)
P ≡(λu.v)L ▷1β
[L/u]v
≡
v;
(ii)
P ▷1β (λu.v)(Ly)
by contracting L
▷1β (λu.v)(Lyy) by contracting L again
. . .
etc.
So P has a normal form v, but also has an inﬁnite reduction.
(d) The term (λx.xx)(λx.xx) in 1.25(d) is usually called Ω. It is
not a normal form; indeed it does not reduce to one (because it
reduces always to itself). But Ωis ‘minimal’ in the sense that it
cannot be reduced to any diﬀerent term. (In [Ler76] it is proved
that no other redex is minimal in this sense.)
Exercise 1.28 ∗Reduce the following terms to β-normal forms:
(a)
(λx.xy)(λu.vuu),
(b)
(λxy.yx)uv,
(c)
(λx . x(x(yz))x)(λu.uv),
(d)
(λx.xxy)(λy.yz),
(e)
(λxy.xyy)(λu.uyx),
(f)
(λxyz.xz(yz))((λxy.yx)u)((λxy.yx)v) w.
Remark 1.29
Some terms can be reduced in more than one way.
One such term, from Example 1.25(c), is (λx.(λy.yx)z)v. It has two
reductions:
(λx.(λy.yx)z)v ▷1β
(λy.yv)z
by contracting (λx.(λy.yx)z) v
▷1β
zv
by contracting (λy.yv)z;
(λx.(λy.yx)z)v ▷1β
(λx.zx)v
by contracting (λy.yx)z
▷1β
zv.
In this case both reductions reach the same normal form. Is this al-
ways true? Certainly, for any system claiming to represent computation
the end-result should be independent of the path. So if this property
failed for β-reduction, any claim by λ-calculus to be like a programming
language would fail from the start.
The Church–Rosser theorem below will show that the normal form of
a term is indeed unique, provided we ignore changes of bound variables.
It will have many other applications too; in fact it is probably the most
often quoted theorem on λ-calculus.

14
The λ-calculus
Before the theorem, here are two lemmas: the ﬁrst says that nothing
new can be introduced during a reduction, in a certain sense, and the
second that the reducibility relation ▷β is preserved by substitution.
Lemma 1.30
P ▷β Q
=⇒
FV(P) ⊇FV(Q).
Proof
First, FV((λx.M)N) ⊇FV([N/x]M) by 1.15(b) and (c). Also
α-conversions do not change FV(P), by 1.19(a).
Lemma 1.31 (Substitution and ▷β) If P ▷β P ′ and Q ▷β Q′, then
[P/x]Q ▷β [P ′/x]Q′.
Proof By Appendix A1’s A1.15.
Theorem 1.32 (Church–Rosser theorem for ▷β)
If P ▷β M and
P ▷β N (see Figure 1:1), then there exists a term T such that
M ▷β T
and
N ▷β T.
v
P
v
M
v N
e
∃T





=
ZZZZZ
~
Z
Z
Z
~



=
Fig. 1:1
Proof See Appendix A2’s Theorem A2.11.
Note The property described in the Church–Rosser theorem, that if a
term can be reduced to two diﬀerent terms then these two terms can be
further reduced to one term, is called conﬂuence. The theorem states
that β-reduction is conﬂuent.

1C β-reduction
15
As mentioned before, the most important application of this theo-
rem is to show that a computation in λ-calculus cannot produce two
essentially diﬀerent results. This is done in the following corollary.
Corollary 1.32.1 If P has a β-normal form, it is unique modulo ≡α;
that is, if P has β-normal forms M and N, then M ≡α N.
Proof Let P ▷β M and P ▷β N. By 1.32, M and N reduce to a term T.
But M and N contain no redexes, so M ≡α T and N ≡α T.
The following is an alternative characterization of β-normal forms
which will be used in a later chapter.
Lemma 1.33 The class β-nf is the smallest class such that
(a)
all atoms are in β-nf;
(b)
M1, . . . , Mn ∈β-nf =⇒aM1 . . . Mn ∈β-nf for all atoms a;
(c)
M ∈β-nf =⇒λx.M ∈β-nf.
Proof
By induction on M, it is easy to prove that M is in the class
deﬁned by (a) – (c) iﬀM contains no redexes.
Note 1.34
If M ≡aM1 . . . Mn where a is an atom, and M ▷β N, then
N must have form
N ≡aN1 . . . Nn
where Mi ▷β Ni for i = 1, . . . , n. To see this, note that M is really
((. . . ((aM1)M2) . . .)Mn)
when its parentheses are fully shown; hence each β-redex in M must
be in an Mi. Also the same holds for each subterm λx.P whose bound
variable might be changed in the reduction of M.
Exercise 1.35 ∗Do not confuse being a β-nf with having a β-nf: ﬁrst
prove that
(a)
[N/x]M is a β-nf =⇒M is a β-nf ;
then, in contrast (harder), ﬁnd terms M and N such that [N/x]M has
a β-nf but M does not; this will prove that
(b)
[N/x]M has a β-nf ̸=⇒M has a β-nf.

16
The λ-calculus
Exercise 1.36 ∗(Harder) Find terms P, Q such that neither of P, Q
has a β-nf, but PQ has a β-nf.
1D β-equality
Reduction is non-symmetric, but it generates the following symmetric
relation.
Deﬁnition 1.37
We say P is β-equal or β-convertible to Q (notation
P =β Q) iﬀQ can be obtained from P by a ﬁnite (perhaps empty) se-
ries of β-contractions and reversed β-contractions and changes of bound
variables. That is, P =β Q iﬀthere exist P0, . . . , Pn (n ≥0) such that
(∀i ≤n −1)

Pi ▷1β Pi+1 or Pi+1 ▷1β Pi or Pi ≡α Pi+1

,
P0 ≡P,
Pn ≡Q.
Exercise 1.38 ∗Prove that (λxyz.xzy)(λxy.x) =β
(λxy.x)(λx.x).
Lemma 1.39 If P =β Q and P ≡α P ′ and Q ≡α Q′, then P ′ =β Q′.
Lemma 1.40 (Substitution lemma for β-equality)
M =β M ′, N =β N ′ =⇒[N/x]M =β [N ′/x]M ′.
Theorem 1.41 (Church–Rosser theorem for =β) If P =β Q, then
there exists a term T such that
M ▷β T
and
N ▷β T.
Proof By induction on the number n in 1.37. The basis, n = 0, is trivial.
For the induction step, n to n + 1, we assume:
P =β Pn,
Pn ▷1β Pn+1
or
Pn+1 ▷1β Pn
(see Figure 1:2); and the induction hypothesis gives a term Tn such that
P ▷β Tn,
Pn ▷β Tn.
We want a T such that P ▷β T and Pn+1 ▷β T. If Pn+1 ▷1β Pn, choose
T ≡Tn. If Pn ▷1β Pn+1, apply 1.32 to Pn, Tn, Pn+1 as shown in Figure
1:2.

1D β-equality
17
u Pn + 1
u
Pn
u
u
u
u
u
P
u
Tn
e
∃T




@
@@
R




@
@@
R




@
@@
R
@
@
@
@
@@
R














@
@
R
Fig. 1:2
The Church–Rosser theorem shows that two β-convertible terms both
intuitively represent the same operator, since they can both be reduced
to the same term. (This is why β-convertibility is called ‘=’.)
Corollary 1.41.1 If P =β Q and Q is a β-normal form, then P ▷β Q.
Proof
By the Church–Rosser theorem, P and Q both reduce to some
T. But Q contains no redexes, so Q ≡α T. Hence P ▷β Q.
Corollary 1.41.2 If P =β Q, then either P and Q both have the same
β-normal form or both P and Q have no β-normal form.
Corollary 1.41.3 If P, Q ∈β-nf and P =β Q, then P ≡α Q.
By Corollary 1.41.3 the relation =β is non-trivial, in the sense that
not all terms are β-convertible to each other. For example, λxy.xy and
λxy.yx are both in β-nf and λxy.xy ̸≡α λxy.yx, so the corollary implies
that λxy.xy ̸=β λxy.yx.
Corollary 1.41.4 (Uniqueness of nf) A term is β-equal to at most
one β-normal form, modulo changes of bound variables.
The following more technical corollary will be needed later. Without
using the Church–Rosser theorem it would be very hard to prove.

18
The λ-calculus
Corollary 1.41.5 If a and b are atoms and aM1 . . . Mm =β bN1 . . . Nn,
then a ≡b and m = n and Mi =β Ni for all i ≤m.
Proof By 1.41, both terms reduce to some T. By 1.34, T ≡aT1 . . . Tm,
where Mi ▷β Ti for i = 1, . . . , m. Similarly, T ≡bT ′
1 . . . T ′
n where Nj ▷β T ′
j
for j = 1, . . . , n. Thus aT1 . . . Tm ≡T ≡bT ′
1 . . . T ′
n, so a ≡b, m = n,
and Ti ≡T ′
i for i = 1, . . . , m. Hence result.
Exercise 1.42 ∗
(a) Prove that if the equation λxy.x = λxy.y was
added as an extra axiom to the deﬁnition of β-equality, then all terms
would become equal. (Adding an equation P = Q as an extra axiom
means allowing any occurrence of P in a term to be replaced by Q and
vice versa.)
(b) Do the same for the equation λx.x = λxy.yx.
Remark 1.43 (λI-terms)
Terms without normal forms are like ex-
pressions which can be computed for ever without reaching a result. It
is natural to think of such terms as meaningless, or at least as carrying
less meaning than terms with normal forms. But it is possible for a term
T to have a normal form, while one of its subterms has none. (An ex-
ample is T ≡(λu.v)Ω, where Ω≡(λx.xx)(λx.xx) from 1.25(d).) Thus
a meaningful term can have a part which might be thought meaningless.
To some logicians (including Church at certain stages of his work), this
has seemed undesirable. From this viewpoint, it is better to work with
a restricted set of terms called λI-terms, whose deﬁnition is the same as
1.1 except that λx.M is only allowed to be a λI-term when x occurs free
in M. This restriction is enough to exclude the above term T, and by
[CF58, Section 4E, Corollary 2.1], if a λI-term has a normal form then
so do all its subterms.
There is an account of the λI-system in [Bar84, Chapter 9]. All the
results stated so far are valid for the λI-system as well as for the full
λ-system, but this will not always hold true for all future results.
Sometimes, to emphasise the contrast with the λI-system, the full
system is called the λK-system and its terms are called λK-terms.
Exercise 1.44
(Extra practice)
(a) Insert all missing parentheses and λ’s into the following abbrevi-
ated λ-terms:

1D β-equality
19
(i) xx(xxx)x,
(ii) vw(λxy.vx),
(iii) (λxy.x)uv,
(iv) w(λxyz.xz(yz))uv.
(b) Mark all the occurrences of xy in the following terms:
(i) (λxy.xy)xy,
(ii) (λxy.xy)(xy),
(iii) λxy.xy(xy).
(c) Do any of the terms in (a) or (b) contain any of the following
terms as subterms? If so, which contains which?
(i) λy.xy,
(ii) y(xy),
(iii) λxy.x.
(d) Evaluate the following substitutions:
(i) [vw/x] (x(λy.yx)),
(ii) [vw/x] (x(λx.yx)),
(iii) [ux/x] (x(λy.yx)),
(iv) [uy/x] (x(λy.yx)).
(e) Reduce the following terms to β-normal forms:
(i) (λxy.xyy)uv,
(ii) (λxy.yx)(uv)zw,
(iii) (λxy.x)(λu.u),
(iv) (λxyz.xz(yz))(λuv.u).
We shall leave λ-calculus now, and return again in Chapter 3.
In
fact Chapter 3 and most later chapters will apply equally well to both
λ-calculus and combinatory logic.
Further reading
Before we move on, here are a few suggestions for supplementary reading.
All of them are general works on λ-calculus; books on special subtopics
will be mentioned in later chapters.
First, the Internet is a useful source: typing ‘lambda calculus’ into a
search engine will show plenty of online introductions and summaries,
as well as links to more specialized subtopics.
Also, most introductions to functional programming contain at least
a quick introduction to λ-calculus. For example, [Mic88] and [Pie02] are
well-written books of this kind.
[Chu41] is the ﬁrst-ever textbook on λ, by the man who originated
the subject. Its notation and methods are outdated now, but the early
pages are still worth reading for motivation and some basic ideas.
[CF58] treats combinators and λ in parallel, and includes details such
as substitution lemmas which many later accounts omit, as well as his-
torical notes. But most of the book has long been superceded.
[Bar84] is an encyclopaedic and well-organized account of λ-calculus
as known before 1984. It presents the deeper ideas underlying much

20
The λ-calculus
of the theory, and even after over 20 years it is still essential for the
intending specialist. (It does not cover type theory.)
[Kri93] is a sophisticated and smooth introduction (originally pub-
lished in French). It covers less than the present book but treats several
topics that will only be mentioned in passing here, such as intersection-
types and B¨ohm’s theorem. It also treats Girard’s type-system F.
[Han04] is a short computer-science-oriented introduction.
Its core
topics overlap the present book. They are covered in less detail, but
some useful extra topics are also included.
[R´ev88] is a computer-science-oriented introduction demanding slight-
ly less mathematical experience from the reader than the present book
and covering less material. There are some exercises (but no answers). In
Section 2.5 there is an interesting variant of β-reduction which generates
the same equality as the usual one, and is conﬂuent, but does not depend
on a preliminary deﬁnition of substitution.
[Tak91] is a short introduction for Japanese readers on about the same
level as the present book. It also contains an introduction to recursive
functions, but does not treat types or combinatory logic.
[Wol04] is a Russian-language textbook of which a large part is an in-
troduction to λ-calculus and combinators, covering the ﬁrst ﬁve chapters
of the present book as well as some more special topics such as types.
[Rez82] is a bibliography of all the literature up to 1982 on λ-calculus
and combinators, valuable for the reader interested in history. It has
very few omissions, and includes many unpublished manuscripts.
[Bet99] is a bibliography of works published from 1980 to 1999, based
largely on items reviewed in the journal Mathematical Reviews. It is an
electronic ‘.ps’ ﬁle, for on-screen reading. (Printing-out is not recom-
mended; it has over 500 pages!)

2
Combinatory logic
2A
Introduction to CL
Systems of combinators are designed to do the same work as systems
of λ-calculus, but without using bound variables. In fact, the annoying
technical complications involved in substitution and α-conversion will be
avoided completely in the present chapter. However, for this technical
advantage we shall have to sacriﬁce the intuitive clarity of the λ-notation.
To motivate combinators, consider the commutative law of addition
in arithmetic, which says
(∀x, y) x + y = y + x.
The above expression contains bound variables ‘x’ and ‘y’. But these
can be removed, as follows. We ﬁrst deﬁne an addition operator A by
A(x, y) = x + y
(for all x, y),
and then introduce an operator C deﬁned by
(C(f))(x, y) = f(y, x)
(for all f, x, y).
Then the commutative law becomes simply
A = C(A).
The operator C may be called a combinator; other examples of such
operators are the following:
B,
which composes two functions:
(B(f, g))(x) = f(g(x));
B′, a reversed composition operator:
(B′(f, g))(x) = g(f(x));
I,
the identity operator:
I(f) = f;
K,
which forms constant functions:
(K(a))(x) = a;
21

22
Combinatory logic
S,
a stronger composition operator:
(S(f, g))(x) = f(x, g(x));
W, for doubling or ‘diagonalizing’:
(W(f))(x) = f(x, x).
Instead of trying to deﬁne ‘combinator’ rigorously in this informal
context, we shall build up a formal system of terms in which the above
‘combinators’ can be represented. Just as in the previous chapter, the
system to be studied here will be the simplest possible one, with no
syntactical complications or restrictions, but with the warning that sys-
tems used in practice are more complicated. The ideas introduced in
the present chapter will be common to all systems, however.
Deﬁnition 2.1 (Combinatory logic terms, or CL-terms)
Assume
that there is given an inﬁnite sequence of expressions v0, v00, v000, . . .
called variables, and a ﬁnite or inﬁnite sequence of expressions called
atomic constants, including three called basic combinators: I, K, S. (If
I, K and S are the only atomic constants, the system will be called pure,
otherwise applied.) The set of expressions called CL-terms is deﬁned
inductively as follows:
(a) all variables and atomic constants, including I, K, S, are CL-
terms;
(b) if X and Y are CL-terms, then so is (XY ).
An atom is a variable or atomic constant. A non-redex constant is an
atomic constant other than I, K, S. A non-redex atom is a variable or a
non-redex constant. A closed term is a term containing no variables. A
combinator is a term whose only atoms are basic combinators. (In the
pure system this is the same as a closed term.)
Examples of CL-terms (the one on the left is a combinator):
((S(KS))K),
((S(Kv0))((SK)K)).
Notation 2.2
Capital Roman letters will denote CL-terms in this
chapter, and ‘term’ will mean ‘CL-term’.
‘CL’ will mean ‘combinatory logic’, i.e. the study of systems of CL-
terms. (In later chapters, particular systems will be called ‘CLw’, ‘CLξ’,
etc., but never just ‘CL’.)
The rest of the notation will be the same as in Chapter 1. In particular
‘x’, ‘y’, ‘z’, ‘u’, ‘v’, ‘w’ will stand for variables (distinct unless otherwise
stated), and ‘≡’ for syntactic identity of terms. Also parentheses will
be omitted following the convention of association to the left, so that
(((UV )W)X) will be abbreviated to UV WX.

2A Introduction to CL
23
Deﬁnition 2.3
The length of X (or lgh(X)) is the number of occur-
rences of atoms in X:
(a)
lgh(a) = 1 for atoms a;
(b)
lgh(UV ) = lgh(U) + lgh(V ).
For example, if X ≡xK(SSxy), then lgh(X) ≡6.
Deﬁnition 2.4
The relation X occurs in Y , or X is a subterm of Y ,
is deﬁned thus:
(a)
X occurs in X;
(b)
if X occurs in U or in V , then X occurs in (UV ).
The set of all variables occurring in Y is called FV(Y ). (In CL-terms all
occurrences of variables are free, because there is no λ to bind them.)
Example 2.5 Let Y ≡K(xS)((xSyz)(Ix)). Then xS and x occur in Y
(and xS has two occurrences and x has three). Also
FV(Y ) ≡{x, y, z}.
Deﬁnition 2.6 (Substitution)
[U/x]Y is deﬁned to be the result of
substituting U for every occurrence of x in Y : that is,
(a) [U/x]x ≡U,
(b) [U/x]a ≡a for atoms a ̸≡x,
(c) [U/x](V W) ≡([U/x]V [U/x]W).
For all U1, . . . , Un and mutually distinct x1, . . . , xn, the result of simul-
taneously substituting U1 for x1, U2 for x2, . . . , Un for xn in Y is called
[U1/x1, . . . , Un/xn]Y.
Example 2.7
(a) [(SK)/x](yxx) ≡y(SK)(SK),
(b) [(SK)/x, (KI)/y](yxx) ≡KI(SK)(SK).
Exercise 2.8∗(a) Give a deﬁnition of [U1/x1, . . . , Un/xn]Y by induc-
tion on Y .
(b) An example in Remark 1.23 shows that the identity
[U1/x1, . . . , Un/xn]Y
≡[U1/x1]

[U2/x2]

. . . [Un/xn]Y

. . .

can fail. State a non-trivial condition suﬃcient to make this identity
true.

24
Combinatory logic
2B
Weak reduction
In the next section, we shall see how I, K and S can be made to play
a rˆole that is essentially equivalent to ‘λ’. We shall need the following
reducibility relation.
Deﬁnition 2.9 (Weak reduction)
Any term IX, KXY or SXY Z
is called a (weak) redex. Contracting an occurrence of a weak redex in
a term U means replacing one occurrence of
IX
by
X,
or
KXY
by
X,
or
SXY Z
by
XZ(Y Z).
Iﬀthis changes U to U ′, we say that U (weakly) contracts to U ′, or
U ▷1w U ′.
IﬀV is obtained from U by a ﬁnite (perhaps empty) series of weak
contractions, we say that U (weakly) reduces to V , or
U ▷w V.
Deﬁnition 2.10
A weak normal form (or weak nf or term in weak
normal form) is a term that contains no weak redexes. Iﬀa term U
weakly reduces to a weak normal form X, we call X a weak normal
form of U.
(Actually the Church–Rosser theorem later will imply that a term
cannot have more than one weak normal form.)
Example 2.11
Deﬁne B ≡S(KS)K. Then BXY Z ▷w X(Y Z) for all
terms X, Y and Z, since
BXY Z ≡
S(KS)KXY Z
▷1w
KSX(KX)Y Z by contracting S(KS)KX to KSX(KX)
▷1w
S(KX)Y Z
by contracting KSX to S
▷1w
KXZ(Y Z)
by contracting S(KX)Y Z
▷1w
X(Y Z)
by contracting KXZ.

2B Weak reduction
25
Example 2.12 Deﬁne C ≡S(BBS)(KK). Then CXY Z ▷w XZY , since
CXY Z
≡
S(BBS)(KK)XY Z
▷1w
BBSX(KKX)Y Z
by contracting S(BBS)(KK)X
▷1w
BBSXKY Z
by contracting KKX
▷w
B(SX)KY Z
by 2.11
▷w
SX(KY )Z
by 2.11
▷1w
XZ(KY Z)
by contracting SX(KY )Z
▷1w
XZY
by contracting KY Z.
Incidentally, in line 4 of this reduction, a redex KY Z seems to occur;
but this is not really so, since, when all its parentheses are inserted,
B(SX)KY Z is really ((((B(SX))K)Y )Z).
Exercise 2.13 ∗Reduce the following CL-terms to normal forms:
(i)
SIKx,
(ii)
SSKxy,
(iii) S(SK)xy,
(iv) S(KS)Sxyz,
(v)
SBBIxy.
Lemma 2.14 (Substitution lemma for ▷w)
(a)
X ▷w Y
=⇒
FV(X) ⊇FV(Y );
(b)
X ▷w Y
=⇒
[X/v]Z ▷w [Y/v]Z;
(c)
X ▷w Y
=⇒
[U1/x1, . . . , Un/xn]X ▷w [U1/x1, . . . , Un/xn]Y .
Proof
For (a): for all terms U, V , W, we have: FV(IU) ⊇FV(U),
FV(KUV ) ⊇FV(U), and FV(SUV W) ⊇FV(UW(V W)).
For (b): any contractions made in X can also be made in the substi-
tuted X’s in [X/v]Z.
For (c): if R is a redex and contracts to T, then [U1/x1, . . . , Un/xn]R
is also a redex and contracts to [U1/x1, . . . , Un/xn]T.
Theorem 2.15 (Church–Rosser theorem for ▷w)
If U ▷w X and
U ▷w Y , then there exists a CL-term T such that
X ▷w T
and
Y
▷w T.
Proof Appendix A2, Theorem A2.13.
Corollary 2.15.1 (Uniqueness of nf) A CL-term can have at most
one weak normal form.

26
Combinatory logic
Exercise 2.16
Prove that SKKX ▷w X for all terms X. (Hence, by
letting I ≡SKK, we obtain a term composed only of S and K which
behaves like the combinator I. Thus CL could have been based on just
two atoms, K and S. However, if we did this, a very simple correspon-
dence between normal forms in CL and λ would fail; see Remark 8.23
and Exercise 9.19 later.)
Exercise 2.17 ∗(Tricky) Construct combinators B′ and W such that
B′XY Z
▷w
Y (XZ)
(for all X, Y, Z),
WXY
▷w
XY Y
(for all X, Y ).
2C
Abstraction in CL
In this section, we shall deﬁne a CL-term called ‘[x].M’ for every x and
M, with the property that
([x].M)N ▷w [N/x]M.
(1)
Thus the term [x].M will play a role like λx.M. It will be a combination
of I’s, K’s, S’s and parts of M, built up as follows.
Deﬁnition 2.18 (Abstraction)
For every CL-term M and every
variable x, a CL-term called [x].M is deﬁned by induction on M, thus:
(a)
[x].M
≡KM
if x ̸∈FV(M);
(b)
[x].x
≡I;
(c)
[x].Ux
≡U
if x ̸∈FV(U);
(f)
[x].UV
≡S([x].U)([x].V )
if neither (a) nor (c) applies.1
Example 2.19
[x].xy
≡
S([x].x)([x].y)
by 2.18(f)
≡
SI(Ky)
by 2.18 (b) and (a).
1 These clauses are from [CF58, Section 6A, clauses(a)–(f)], deleting (d)–(e), which
are irrelevant here.
The notation ‘[x]’ is from [CF58, Section 6A]. In [Ros55],
[Bar84] and [HS86] the notation ‘λ⋆x’ was used instead, to stress similarities be-
tween CL and λ-calculus. But the two systems have important diﬀerences, and
‘λ⋆x’ has since acquired some other meanings in the literature, so the ‘[x]’ notation
is used here.

2C Abstraction in CL
27
Warning 2.20 In λ-calculus an expression λx can be part of a λ-term,
for example the term λx.xy. But in CL, the corresponding expression
[x] is not part of the formal language of CL-terms at all. In the above
example, the expression [x].xy is not itself a CL-term, but is merely a
short-hand to denote the CL-term SI(Ky).
Theorem 2.21 The clauses in Deﬁnition 2.18 allow us to construct
[x].M for all x and M. Further, [x].M does not contain x, and, for all
N,
([x].M)N ▷w [N/x]M.
Proof By induction on M we shall prove that [x].M is always deﬁned,
does not contain x, and that
([x].M) x ▷w M.
The theorem will follow by substituting N for x and using 2.14(c).
Case 1: M ≡x. Then Deﬁnition 2.18(b) applies, and
([x].x) x ≡I x ▷w x.
Case 2: M is an atom and M ̸≡x. Then 2.18(a) applies, and
([x].M) x ≡KMx ▷w M.
Case 3: M ≡UV . By the induction hypothesis, we may assume
([x].U) x ▷w U,
([x].V ) x ▷w V.
Subcase 3(i): x ̸∈FV(M). Like Case 2.
Subcase 3(ii): x ̸∈FV(U) and V ≡x. Then
([x].M) x
≡
([x].Ux) x
≡
Ux
by 2.18(c),
≡
M.
Subcase 3(iii): Neither of the above two subcases applies. Then
([x].M) x
≡
S([x].U)([x].V ) x
by 2.18(f)
▷1w
([x].U) x (([x].V ) x)
▷w
UV
by induction hypothesis
≡
M.
(Note how the redexes and contractions for I, K, and S in 2.9 ﬁt in with
the cases in this proof; in fact this is their purpose.)

28
Combinatory logic
Exercise 2.22 ∗Evaluate
[x].u(vx),
[x].x(Sy),
[x].uxxv.
Remark 2.23
There are several other possible deﬁnitions of abstrac-
tion besides the one in Deﬁnition 2.18. For example, [Bar84, Deﬁni-
tion 7.1.5] omits 2.18(c). But this omission enormously increases the
lengths of terms [x1].(. . . ([xn].M) . . .) for most x1, . . . , xn, M. Some
alternative deﬁnitions of abstraction will be compared in Chapter 9.
Deﬁnition 2.24
For all variables x1, . . . , xn (not necessarily distinct),
[x1, . . . , xn].M ≡[x1].([x2].(. . . ([xn].M) . . .)).
Example 2.25
(a)
[x, y].x ≡
[x].([y].x)
≡
[x].(Kx)
by 2.18(a) for [y]
≡K
by 2.18(c).
(b)
[x, y, z].xz(yz) ≡
[x].

[y].

[z].xz(yz)

≡
[x].

[y].

S([z].xz)([z].yz)

by 2.18(f) for [z]
≡
[x].

[y].Sxy

by 2.18(c) for [z]
≡
[x].Sx
by 2.18(c) for [y]
≡S
by 2.18(c).
Exercise 2.26 ∗Evaluate
[x, y, z].xzy,
[x, y, z].y(xz),
[x, y].xyy.
Compare [x, y, z].xzy with the combinator C in Example 2.12. Note that
[x, y, z].y(xz) and [x, y].xyy give answers to Exercise 2.17, combinators
B′ and W. There are other possible answers to that exercise, but the
the abstraction algorithm in Deﬁnition 2.18 has changed the formerly
tricky task of ﬁnding an answer into a routine matter.
Theorem 2.27 For all variables x1, . . . , xn (mutually distinct),
([x1, . . . , xn].M) U1 . . . Un
▷w
[U1/x1, . . . , Un/xn]M.
Proof By 2.14(c) it is enough to prove ([x1, . . . , xn].M)x1 . . . xn ▷w M.
And this comes from 2.21 by an easy induction on n.

2D Weak equality
29
Lemma 2.28 (Substitution and abstraction)
(a)
FV([x].M) = FV(M) −{x}
if x ∈FV(M);
(b)
[y].[y/x]M ≡[x].M
if y ̸∈FV(M);
(c)
[N/x]([y].M) ≡[y].[N/x]M
if y ̸∈FV(xN).
Proof
Straightforward induction on M.
Comment Part (b) of Lemma 2.28 shows that the analogue in CL of
the λ-calculus relation ≡α is simply identity. Part (c) is an approximate
analogue of Deﬁnition 1.12(f).
The last few results have shown that [x] has similar properties to
λx.
But it must be emphasized again that, in contrast to λx, [x] is
not part of the formal system of terms; [x].M is deﬁned in the meta-
theory by induction on M, and is constructed from I, K, S, and parts
of M.
2D
Weak equality
Deﬁnition 2.29 (Weak equality or weak convertibility)
We shall
say X is weakly equal or weakly convertible to Y , or X =w Y , iﬀY can be
obtained from X by a ﬁnite (perhaps empty) series of weak contractions
and reversed weak contractions. That is, X =w Y iﬀthere exist X0, . . . ,
Xn (n ≥0) such that
(∀i ≤n −1) ( Xi ▷1w Xi+1 or Xi+1 ▷1w Xi ),
X0 ≡X,
Xn ≡Y.
Exercise 2.30∗Prove that, if B, W are the terms in Example 2.11 and
Exercise 2.17, then
BWBIx =w SIIx.
Lemma 2.31
(a)
X =w Y
=⇒
[X/v]Z =w [Y/v]Z;
(b)
X =w Y
=⇒
[U1/x1, . . . , Un/xn]X =w [U1/x1, . . . , Un/xn]Y .

30
Combinatory logic
Theorem 2.32 (Church–Rosser theorem for =w) If X =w Y , then
there exists a term T such that
X ▷w T
and
Y
▷w T.
Proof From 2.15, like the proof of 1.41 from 1.32.
Corollary 2.32.1 If X =w Y and Y is a weak normal form, then we
have X ▷w Y .
Corollary 2.32.2 If X =w Y , then either X and Y have no weak
normal form, or they both have the same weak normal form.
Corollary 2.32.3 If X and Y are distinct weak normal forms, then
X ̸=w Y ; in particular S ̸=w K. Hence =w
is non-trivial in the sense
that not all terms are weakly equal.
Corollary 2.32.4 (Uniqueness of nf) A term can be weakly equal to
at most one weak normal form.
Corollary 2.32.5 If a and b are atoms other than I, K and S, and
aX1 . . . Xm =w bY1 . . . Yn,
then a ≡b and m = n and Xi =w Yi for all
i ≤m.
Warning 2.33 Although the above results show that =w in CL behaves
very like =β in λ, the two relations do not correspond exactly. The main
diﬀerence is that =β has the property which [CF58] calls (ξ), namely
(ξ)
X =β Y
=⇒
λx.X =β λx.Y .
(This holds in λ because any contraction or change of bound variable
made in X can also be made in λx.X.) When translated into CL, (ξ)
becomes
X =w Y
=⇒
[x].X =w [x].Y.
But for CL-terms, [x] is not part of the syntax, and (ξ) fails. For exam-
ple, take
X ≡Sxyz,
Y ≡xz(yz);
then X =w Y , but
[x].X ≡S(SS(Ky))(Kz),
[x].Y
≡S(SI(Kz))(K(yz)).

2D Weak equality
31
These are normal forms and distinct, so by 2.32.3 they are not weakly
equal.
For many purposes the lack of (ξ) is no problem and the simplicity of
weak equality gives it an advantage over λ-calculus. This is especially
true if all we want to do is deﬁne a set of functions in a formal theory,
for example the recursive functions in Chapter 5. But for some other
purposes (ξ) turns out to be indispensable, and weak equality is too
weak. We then either have to abandon combinators and use λ, or add
new axioms to weak equality to make it stronger. Possible extra axioms
will be discussed in Chapter 9.
Exercise 2.34 ∗
(a) Construct a pairing-combinator D and two projections D1, D2
such that
D1(Dxy) ▷w x,
D2(Dxy) ▷w y.
(b) Show that there is no combinator that distinguishes between
atoms and composite terms; i.e. show that there is no A such
that
AX =w S
if X is an atom,
AX =w K
if X ≡UV for some U, V .
(Operations involving decisions that depend on the syntactic
structure of terms can hardly ever be done by combinators.)
(c) Prove that a term X is in weak normal form iﬀX is minimal with
respect to weak reduction, i.e. iﬀ
X ▷w Y
=⇒Y ≡X.
(Contrast λ-calculus, 1.27(d).) Show that this would be false if
there were an atom W with an axiom-scheme
WXY ▷w XY Y.
Extra practice 2.35
(a) Reduce the following CL-terms to weak normal forms. (For some
of them, use the reductions for B, C and W shown in Examples
2.11 and 2.12 and Exercise 2.17.)
(i)
KSuxyz,
(ii)
S(Kx)(KIy)z,
(iii)
CSIxy,
(iv)
S(CI)xy,

32
Combinatory logic
(v)
B(BS)Bxyzu,
(vi)
BB(BB)uvwxy,
(vii) B(BW(BC))(BB(BB))xyzu.
(b) Evaluate the following:
[x].xu(xv),
[y].ux(uy),
[x, y].ux(uy).
(c) Prove that SKxy =w KIxy. (Cf. Example 8.16(a).)
Further reading
There are many informative websites: just type ‘combinatory’ into a
search engine. Also several introductions to λ include CL as well. The
following are some references that focus mainly on CL.
[Ste72], [Bun02] and [Wol03] are introductions to CL aimed at about
the same level as the present book. If the reader is dissatisﬁed with this
book, he or she might ﬁnd one of these more useful!
[Bar84] contains only one chapter on CL explicitly (Chapter 7). But
most of the ideas in that book apply to CL as well as λ.
[Smu85] contains a humorous and clever account of combinators and
self-application, and is especially good for examples and exercises on the
interdeﬁnability of various combinators.
[Sch24] is the ﬁrst-ever exposition of combinators, by the man who
invented them, and is a very readable non-technical short sketch.
[CF58] was the only book on CL for many years, and is still valuable
for a few things, for example its discussion of particular combinators
and interdeﬁnability questions (Chapter 5), alternative deﬁnitions of
[x] (Section 6A), strong equality and reduction (Sections 6B–6F), and
historical comments at the ends of chapters.
[CHS72] is a continuation and updating of [CF58], and contains proofs
of the main properties of weak reduction (Section 11B). Deﬁnitions of
[x] are discussed in Section 11C. References for other topics will be given
as they crop up later in the present book.
[Bac78] has historical interest; it is a strong plea for a functional style
of programming, using combinators as an analogy, and led to an upsurge
of interest in combinators, and to several combinator-based program-
ming languages. (But Backus was not the ﬁrst to advocate this; some
precursors were [Fit58], [McC60], [Lan65], [Lan66], [BG66] and [Tur76].)

3
The power of λ and combinators
3A
Introduction
The purpose of this chapter and the next two is to show some of the
expressive power of both λ and CL.
The present chapter describes three interesting theorems which hold
for both λ and combinators, and are used frequently in the published lit-
erature: the ﬁxed-point theorem, B¨ohm’s theorem, and a theorem which
helps in proving that a term has no normal form.
After these results, Section 3E will outline the history of λ and CL,
and will discuss the question of whether they have any meaning, or are
just uninterpretable formal systems.
Then Chapter 4 will show that all recursive functions are deﬁnable in
both systems, and Chapter 5 will deduce from this a general undecid-
ability theorem.
Notation 3.1 This chapter is written in a neutral notation, which may
be interpreted in either λ or CL, as follows.
Notation
Meaning for λ
Meaning for CL
term
λ-term
CL-term
X ≡Y
X ≡α Y
X is identical to Y
X ▷β,w Y
X ▷β Y
X ▷w Y
X =β,w Y
X =β Y
X =w Y
λx
λx
[x]
Deﬁnition 3.2 A combinator is (in λ) a closed pure term, i.e. a term
containing neither free variables nor atomic constants, and (in CL) a
33

34
The power of λ and CL
term whose only atoms are the basic combinators I, K, S. In λ, the
following combinators are given special names:
B ≡λxyz.x(yz),
B′ ≡λxyz.y(xz),
C ≡λxyz.xzy,
I ≡λx.x,
K ≡λxy.x,
S ≡λxyz.xz(yz),
W ≡λxy.xyy.
3B
The ﬁxed-point theorem
A ﬁxed point of an operator or function is an object which does not
change when the operator is applied to it. For example, the operation of
squaring numbers has two ﬁxed points 0 and 1, since 02 = 0 and 12 = 1;
and the successor-function has none, since n + 1 ̸= n for all n.
The next theorem shows that every operator in λ and CL has a ﬁxed
point. More precisely, for every term X there is a term P (depending
on X) such that
XP =β,w P.
Furthermore, there is a combinator Y which ﬁnds these ﬁxed points, i.e.
such that, for every term X, the term YX is a ﬁxed point of X.
Theorem 3.3 (Fixed-point theorem) In both λ and CL, there is a
combinator Y such that
(a)
Yx =β,w x(Yx).
In fact, there is a Y with the stronger property
(b)
Yx ▷β,w x(Yx).
Proof A suitable Y was invented by Alan Turing in 1937. It is
Y ≡UU,
where U ≡λux.x(uux).
It satisﬁes (b) (and therefore also (a)), because
Yx ≡
(λu.(λx.x(uux)))Ux by the deﬁnition of U
▷β,w
[U/u]

λx.x(uux)

x
by Deﬁnition 1.24 or Theorem 2.21
≡
(λx.x(UUx))x
by Deﬁnition 1.12 or Lemma 2.28(c)
(noting that FV(U) is empty)
▷β,w
x(UUx)
by Deﬁnition 1.24 or Theorem 2.21

3B The ﬁxed-point theorem
35
≡
x(Yx).
Note that the above reduction is correct for both λ and CL. For λ, each
of the two steps above is a single contraction; for CL, each is a reduction
given by Theorem 2.21.
Corollary 3.3.1 In λ and CL: for every Z and n ≥0, the equation
xy1 . . . yn = Z
can be solved for x. That is, there is a term X such that
Xy1 . . . yn
=β,w
[X/x]Z.
Proof Choose X ≡Y(λxy1 . . . yn .Z).
Comments The ﬁxed-point theorem is most often used via this corol-
lary. In the corollary, Z may contain any or none of x, y1, . . . , yn, al-
though the most interesting cases occur when Z contains x.
The corollary can be used in representing the recursive functions by
terms in λ or CL (Chapter 4, Note 4.15). In logical systems based on
λ or CL, if the system’s designer is not extremely careful the corollary
may cause paradoxes (see [CF58, Section 8A]).
On a more trivial level, it provides the world of λ and CL with a
garbage-disposer X1 which swallows all arguments presented to it,
X1y
=β,w
X1,
and a bureaucrat X2 which eternally permutes its arguments with no
other eﬀect,
X2yz
=β,w
X2zy.
Corollary 3.3.2 (Double ﬁxed-point theorem)
In λ and CL: for
every pair of terms X, Y there exist P, Q such that
XPQ =β,w P,
Y PQ =β,w Q.
Proof
(From [Bar84, Section 6.5].)
By Exercise 3.5(b) below, with
n = k = 2, there exist terms X1, X2 such that (for i = 1, 2)
Xi y1y2
=β,w
yi (X1y1y2)(X2y1y2).
Choose P ≡X1XY and Q ≡X2XY .

36
The power of λ and CL
Remark Turing’s combinator Y in the proof of the ﬁxed-point theorem
is not the only possible one. The following deﬁnition gives another, ﬁrst
published by Paul Rosenbloom in [Ros50, pp. 130–131, Exs. 3e, 5f], but
hinted at in 1929 by Curry in a letter.
It is simpler than Turing’s,
but does not have the extra property 3.3(b). Some others are given in
[CHS72, Section 11F7] and [Bar84, Section 6.5].
Deﬁnition 3.4
A ﬁxed-point combinator is any combinator Y such
that YX =β,w X(YX) for all terms X. Deﬁne
YTuring ≡UU,
where U ≡λux.x(uux),
YCurry−Ros ≡λx.V V ,
where V
≡λy.x(yy).
Exercise 3.5∗
(a) Prove that YCurry−Ros is a ﬁxed-point combinator.
(b) (Complicated) Extend Corollary 3.3.1 to prove that, in both λ
and CL, every ﬁnite set of simultaneous equations of form



x1y1 . . . yn
=
Z1
. . .
. . .
xky1 . . . yn
=
Zk



(n ≥0, k ≥1)
is solvable for x1, . . . , xk. The terms Z1, . . . , Zn may contain any or
none of x1, . . . , xk, y1, . . . , yn.
Extra practice 3.6
(a) Prove that the following terms are ﬁxed-point
combinators (in both λ and CL):
Y0 ≡WS(BWB),
Y1 ≡WI(B(SI)(WI)).
(b) Prove that if a term Y is a ﬁxed-point combinator, then
(i)
SIY =β,w Y (and so SIY is a ﬁxed-point combinator),
(ii) Y (SI) is a ﬁxed-point combinator.
More on ﬁxed points can be found in [Bar84, Sections 6.1, 6.5, 19.3].
3C
B¨ohm’s theorem
The next theorem shows that the members of a signiﬁcant class of normal
forms can be distinguished from each other in a very powerful way. It is
due to Corrado B¨ohm [B¨oh68], and has applications in both the syntax
and semantics of λ and CL.

3C B¨ohm’s theorem
37
To prepare for the theorem, the relevant class of normal forms will
now be deﬁned, ﬁrst in λ and then in CL. These two classes will gain
further signiﬁcance in later chapters, but for the moment they are simply
aids to stating B¨ohm’s theorem.
Deﬁnition 3.7 (βη-normal forms)
In λ-calculus, a term of form
λx.Mx with x ̸∈FV(M) is called an η-redex and is said to η-contract
to M. (Such redexes will be studied in Chapter 7.) A λ-term X which
contains no β-redexes and no η-redexes is called a βη-normal form. The
class of all such λ-terms is called βη-nf or λβη-nf.
Example The λ-term λux.ux is in β-nf but not in βη-nf. (It is really
λu.(λx.ux), which η-contracts to λu.u.)
Deﬁnition 3.8 (Strong normal forms)
In CL, the class strong nf
is deﬁned inductively as follows. Its members are called strong normal
forms.
(a) All atoms other than I, K and S are in strong nf;
(b) if X1, . . . , Xn are in strong nf, and a is any atom ̸≡I, K, S, then
aX1 . . . Xn is in strong nf;
(c) if X is in strong nf, then so is [x].X.
Exercise 3.9
(a) Notice that Deﬁnition 3.8 is like Lemma 1.33.
(b) Prove that the class strong nf contains I, K, S and all terms whose
only atoms are variables.
Lemma 3.10 In CL, every strong normal form is also a weak normal
form.
Proof Induction on Deﬁnition 3.8.
Theorem 3.11 (B¨ohm’s theorem)
In λ and CL: let M and N be
combinators, either in βη-normal form (in λ) or in strong normal form
(in CL). If M ̸≡N, then there exist n ≥0 and combinators L1, . . . , Ln
such that
ML1 . . . Lnxy
▷β,w
x,
NL1 . . . Lnxy
▷β,w
y.
Roughly speaking, B¨ohm’s theorem says that M and N can be distin-
guished, not just by their structure, but by their behaviour. By feeding

38
The power of λ and CL
them a suitable diet, the same for both, they can be forced to behave in
recognisably diﬀerent ways, i.e. to act as diﬀerent selectors.
Proof For λ, the original proof is in [B¨oh68]. More accessible proofs are
in [Kri93, Chapter 9], [Bar84, Theorem 10.4.2], [CHS72, Section 11F8],
and (in Japanese) [Tak91, Theorem 3.4.26, p. 148]. There are thorough
analyses of the theorem and the principles behind it in [Bar84, Chapter
10] and [Hue93]. The above version of the theorem is the special case
P ≡λxy.x, Q ≡λxy.y, of Theorem 10.4.2(ii) in [Bar84].
For CL, the theorem can be deduced from the λ-theorem as in [Hin79].
Alternatively, a careful check of the λ-proofs in [B¨oh68] or [CHS72] shows
that all the reductions in these proofs become correct weak reductions
when translated from λ into CL.
(The theorem can be extended to three or more normal forms, see
[BDPR79].)
Corollary 3.11.1 In λ or CL: let M and N be distinct combinators in
βη-nf (in λ) or strong nf (in CL). If we add the equation M = N as a
new axiom to the deﬁnition of =β or =w, then all terms become equal.
Proof
The phrase ‘add the equation M = N as a new axiom’ means
allowing any occurrence of M in a term to be replaced by N, and vice
versa. Then, for all X, Y :
X
=β,w
ML1 . . . LnXY
by B¨ohm’s theorem for M, N,
=β,w
NL1 . . . LnXY
by the new axiom M = N,
=β,w
Y
by B¨ohm’s theorem for M, N.
The above corollary is, in a sense, an extension of the Church–Rosser
theorem. In λ, that theorem implied, via Corollary 1.32.1, that if two
distinct combinators M and N are β-nfs the equation M = N cannot
be proved for =β, and the present corollary says that, furthermore, if M
and N are βη-nfs the equation cannot even be added as an extra axiom
(without the system collapsing to triviality). Similarly for CL and =w.
Corollary 3.11.2 In λ or CL: if M is a combinator in βη-nf (in λ) or
strong nf (in CL), and P is any other combinator whatever, then there

3C B¨ohm’s theorem
39
exist m ≥0 and combinators H1, . . . , Hm such that
MH1 . . . Hm
▷β,w
P.
Proof By Theorem 3.11 with N any normal form distinct from M, there
exist n ≥0 and L1, . . . , Ln such that ML1 . . . Lnxy ▷β,w x. Choose m =
n + 2 and H1, . . . , Hm to be L1, . . . , Ln, P, I.
Exercise 3.12 ∗
(a) In λ, prove the following two special cases of B¨ohm’s theorem
directly, without using the general theorem:
(i)
M ≡λxyz.xz(yz),
N ≡λxyz.x(yz);
(ii)
M ≡λxy.x(yy),
N ≡λxy.x(yx).
(Hint for (ii): choose a value of n ≥3. The main diﬃculty in the
proof of B¨ohm’s theorem is to deal with repeated variables such
as the x in (ii).)
(b) In CL, prove that no combinator Y in strong normal form can
satisfy the ﬁxed-point equation
Y x =w x(Y x).
Hence, to say that a CL-combinator is in strong nf is some re-
striction on the kind of operator it can represent.
(c) In contrast to (b), weak normal forms have no similar restriction.
Show that the CL-version of YCurry−Ros, which satisﬁes the ﬁxed-
point equation, is a weak nf. Show further that all combinators
can be imitated in CL by weak nfs; that is, prove that, if
Xy1 . . . yn =w Z,
where n ≥1 and Z is a given combination of y1, . . . , yn and
constants, then there is a weak nf X′ such that
X′y1 . . . yn =w Z.
(Hint: why are terms such as YCurry−Ros and [x, y, z].y(xz) in
weak nf?)

40
The power of λ and CL
3D
The quasi-leftmost-reduction theorem
The topic of this section is the problem of proving that a given term X
has no normal form. On the surface, this seems very hard: one must
reduce X in all possible ways and show that all the reductions can be
continued for ever. Fortunately there is a theorem which simpliﬁes this
task. It says that if just one of a certain restricted class of reductions
called quasi-leftmost reductions is inﬁnite, then all reductions of X can
be continued for ever. This reduces the problem of testing all reductions
to testing very few.
In this section we shall deﬁne quasi-leftmost reductions and state the
above theorem precisely.
The results will apply to ▷β and β-normal
forms in λ, and ▷w and weak normal forms in CL.
But ﬁrst we need to say precisely what a contraction or a reduction
is, as follows.
Deﬁnition 3.13 (Contractions) Given a λ- or CL-term X, a contrac-
tion in X is an ordered triple ⟨X, R, Y ⟩, where R is an occurrence of a
redex in X, and Y is the result of contracting R in X. (For ‘occurrence’,
see the end of Deﬁnition 1.7; for ‘contracting’, see 1.24 and 2.9.) Instead
of ‘⟨X, R, Y ⟩’, we may write
X ▷R Y.
Example 3.14
In Remark 1.29, two contractions were shown in the
λ-term (λx.(λy.yx)z)v; they are
(λx.(λy.yx)z)v ▷(λx. (λy . yx)z)v (λy.yv)z,
(λx.(λy.yx)z)v ▷(λy . yx)z
(λx.zx)v.
Deﬁnition 3.15 (Reductions)
In CL, a reduction ρ is a ﬁnite or
inﬁnite series of contractions, thus:
X1 ▷R1 X2 ▷R2 X3 ▷R3 . . .
In λ, a reduction ρ is a ﬁnite or inﬁnite series of contractions separated
by α-conversions (perhaps empty), thus:
X1 ▷R1 Y1 ≡α X2 ▷R2 Y2 ≡α X3 ▷R3 . . .
In λ or CL, the start of ρ is X1, and the length of ρ is the number of
its contractions (ﬁnite or ∞), not counting α-steps. If the length of ρ is
ﬁnite, say n, then Xn+1 is called the reduction’s end or terminus.

3D The quasi-leftmost reduction theorem
41
Deﬁnition 3.16 A reduction ρ has maximal length iﬀeither ρ is inﬁnite
or its terminus contains no redexes (i.e. iﬀρ continues as long as there
are redexes to be contracted).
Example 3.17 (a) In CL, the length of the following weak reduction
is 2. It is not maximal because the reduction can be continued one step
further. (The redex-occurrence contracted at each step is underlined.)
S(I(Kxy))(Iz)
▷1w
S(I(Kxy)) z
▷1w
S(Kxy) z.
(b)
In λ, let X1 ≡(λx.xx)(λx.xx). Then the only redex in X1 is
R1 ≡X1, and contracting R1 does not change X1. The following is
counted as an inﬁnite reduction with Xi ≡Ri ≡X1 for all i ≥1:
X1
▷1w
X1
▷1w
X1
▷1w
. . . .
Deﬁnition 3.18 An occurrence of a redex in a term X1 is called maxi-
mal iﬀit is not contained in any other redex-occurrence in X1. It is left-
most maximal iﬀit is the leftmost of the maximal redex-occurrences in
X1. A reduction ρ such that, for each i, the contracted redex-occurrence
Ri is leftmost maximal in Xi, and which has maximal length, is called
the leftmost reduction of X1, or the normal reduction of X1.
(It is
uniquely determined, given X1.)
Example 3.19
In CL, let X1 ≡S(I(Kxy))(Iz). Then X1 contains
three redex-occurrences,
I(Kxy),
Kxy,
Iz,
and I(Kxy), Iz are maximal, and of these, I(Kxy) is leftmost. The left-
most reduction of X1 is
S(I(Kxy))(Iz) ▷1w S(Kxy)(Iz) ▷1w Sx(Iz) ▷1w Sxz.
In 1958 Curry proved that if the leftmost reduction of a λ-term X1 is
inﬁnite, then all reductions starting at X1 can be continued for ever, i.e.
X1 has no normal form. (See [Bar84, Theorem 13.2.2].) Thus leftmost
reductions neatly solve the problem of proving that a term has no normal
form. But in practice, when writing out a leftmost reduction, it is often
convenient to make a few non-leftmost steps between the leftmost steps,
as in the following example.
Example 3.20 In CL, let X1 ≡SII(SII). Then the leftmost reduction
of X1 is inﬁnite and proceeds as follows:

42
The power of λ and CL
X1 ≡
SII(SII)
▷1w
I(SII)(I(SII)) ▷1w
SII(I(SII))
▷1w I(I(SII))(I(I(SII)))
▷1w
etc.
But by inserting some non-leftmost steps between the leftmost ones, we
can make a repetitive pattern obvious, thus:
X1 ≡
SII(SII)
▷1w
I(SII)(I(SII)) ▷1w
SII(I(SII))
▷1w SII(SII)
▷1w
etc.
Examples like this led Henk Barendregt in [Bar84, Deﬁnition 8.4.8] to
deﬁne the following class of reductions.
Deﬁnition 3.21 A quasi-leftmost reduction of a term X1 is a reduction
ρ with maximal length, such that, for each i, if Xi is not the terminus
then there exists j ≥i such that Rj is leftmost maximal.
Informally speaking, an inﬁnite reduction is quasi-leftmost iﬀan in-
ﬁnity of its contractions are leftmost maximal, and is leftmost iﬀthey
all are. In the preceding example, the ﬁrst reduction is leftmost and the
second one is only quasi-leftmost.
Theorem 3.22 (Quasi-leftmost-reduction theorem) For λ-terms
and ▷β, or CL-terms and ▷w: if a term X has a normal form X⋆, then
every quasi-leftmost reduction of X is ﬁnite and ends at X⋆.
Corollary 3.22.1 A term X has no normal form iﬀsome quasi-leftmost
reduction of X is inﬁnite.
Proof See the proof of [Bar84, Theorem 13.2.6]. That proof is written
for λ but is also valid for CL.
Exercise 3.23
In λ, prove that the Y-combinators in Deﬁnition 3.4
have no β-normal form, by ﬁnding inﬁnite quasi-leftmost reductions for
them. (By the way, these inﬁnite reductions in λ have no analogues for
▷w in CL, and in fact the CL-versions of YTuring and YCurry−Ros both
have weak normal forms; furthermore, YCurry−Ros is actually in weak
normal form, see Exercise 3.12(c).)
Remark 3.24
The proof of Theorem 3.22 depends on a fact about
reductions, called the Standardization theorem, which is proved for λ
in [Bar84, Section 11.4, Theorem 11.4.7] and for CL in [CHS72, Sec-
tion 11B3]. The study of reductions was begun as far back as 1936 by

3E History and interpretation
43
Church and Rosser with their proof of the conﬂuence of ▷β, and was
greatly deepened in the 1970s by Jan-Willem Klop and Jean-Jacques
L´evy. Some of their results are reported in [Bar84, Chapters 3, 11–14].
(That account is written for λ, but most of its theorems hold also for
CL and ▷w.)
Remark 3.25 The study of reductions in λ and CL led Klop and his
colleagues in the 1980s to look at reductions generated by diﬀerent kinds
of redexes in systems other than λ and CL. The outcome of this work
was a very general theory of reductions and conﬂuence on which a lot
of work has been done. Good overall surveys are in [Klo92] (on systems
like CL) and [KvOvR93] (on systems more like λ), and an introductory
textbook is [BN98].
3E
History and interpretation
Historical comment 3.26
Although CL has been introduced after λ
in this book, it actually originated several years before λ. Combinators
were invented in 1920 by a Ukrainian, Moses Sch¨onﬁnkel, who described
his idea in a talk which was published in [Sch24]. But Sch¨onﬁnkel suf-
fered from bouts of mental illness and did not develop his ideas; indeed
[Sch24] was actually written for him by a helpful colleague who had at-
tended his talk. He himself did little more mathematical work and died
in poverty in a Moscow hospital in 1942.
Combinators were re-invented in 1927 by an American, Haskell Curry,
who had not seen Sch¨onﬁnkel’s paper. Curry was the ﬁrst to deﬁne CL
as a precise system, and became responsible for the main line of work
on it until about 1970.
The λ-calculus was invented by another American, Alonzo Church,
in the early 1930s, and developed with the aid of his students Barkley
Rosser and Stephen Kleene. In 1936 it was used as the key to the ﬁrst-
ever proof that ﬁrst-order predicate logic is undecidable (see Remark
5.7).
Both λ and CL were originally introduced as parts of strong systems
of higher-order logic designed to provide a type-free foundation for all of
mathematics. But the systems of Church and Curry in the 1930s turned
out to be inconsistent. This led Church to turn to type theory; and

44
The power of λ and CL
he published a neat system of typed λ in 1940, [Chu40]. On the other
hand, Curry was still attracted by the generality of type-free logic, and
turned to analysing its foundations with great care, through a series of
very general but very weak systems.
Until about 1960, λ and CL were only studied by a few small groups.
But around that time, logicians working on computability began to ex-
pand their interest from functions of numbers to functions of functions,
and to ask what it meant for such a higher-order function to be com-
putable. Formal systems were devised to try to express the properties
of higher-order computable functions precisely, and most of these were
based on some form of applied λ or CL. The same question also inter-
ested some of the leaders in the then-young subject of computer science,
including John McCarthy in the late 1950s, who was one of the ﬁrst
advocates for the functional style of programming. McCarthy designed
a higher-order programming language LISP which used a form of λ-
notation.
From then on, interest in λ and CL began to grow.
In 1969, the American logician Dana Scott, while designing a formal
theory of higher-order computation, realized, to his own surprise, that
he could build a model for pure untyped λ and CL using only standard
set-theoretical concepts. Until then, untyped λ and CL had been seen as
incompatible with generally-accepted set-theories such as the well-known
system ZF. Scott’s model changed this view, and many logicians and
computer-scientists began to study his model, and other models which
were invented soon after. (See Chapter 16 below, or [Bar84, Chapters
18–20].)
Scott’s model also stimulated an increased interest in the syntax of
pure λ and CL. The leader in syntactical studies in the 1970s was Henk
Barendregt in the Netherlands, and he and his students and colleagues
made many new discoveries, particularly about the relationships between
diﬀerent reductions from the same term, see Remarks 3.24 and 3.25.
Today, λ and CL have become important topics in logic and com-
puter science. Functional programming languages, and formal systems
of higher-order logic, all need a version of λ or CL or something equiv-
alent, as part of their syntax.
Conversely, the main value of λ and CL comes from their service as
parts of other systems, so recent studies have focussed mainly on applied
versions of λ and CL.
CL and λ are rather like the chassis of a bus, which gives the bus
essential support but is deﬁnitely not the whole bus. Just as the chassis

3E History and interpretation
45
gains its purpose from the purpose to which the whole bus is put, so λ
and CL gain their main purpose as parts of other systems of higher-order
logic and programming.
Discussion 3.27 (Interpreting pure λ and CL) Up to now, this
book has presented λ and CL as uninterpreted formal systems.
However, these systems were originally developed to formalize primi-
tive properties of functions or operators. In particular, I represents the
identity operator, K an operator which forms constant-functions, and S
a substitution-and-composition operator.
But just what kind of operators are these? Most mathematicians think
of functions as being sets of ordered pairs in some ‘classical’ set theory,
for example Zermelo–Fraenkel set theory (ZF). To such a mathematician,
I, K and S simply do not exist.
In ZF, each set S has an identity-
function IS with domain S, but there is no ‘universal’ identity which
can be applied to everything. (Similarly for K and S.)
In many practical applications of CL or λ this question does not arise:
as we shall see in Chapter 10 the rules for building the systems’ terms
may be limited by type-restrictions, and then instead of one ‘univer-
sal’ identity-term I there would be a diﬀerent term Iτ for each type-
expression τ. Type-expressions would denote sets, and Iτ would denote
the identity-function on the set denoted by τ.
But type-free systems also have their uses, and for these systems the
question must still be faced: what kind of functions do the terms repre-
sent?
One possible answer was explained very clearly by Church in the in-
troduction to his book [Chu41]. In the 1920s when λ and CL began,
logicians did not automatically think of functions as sets of ordered
pairs, with domain and range given, as mathematicians are trained to
do today. Throughout mathematical history, right through to computer
science, there has run another concept of function, less precise at ﬁrst but
strongly inﬂuential always; that of a function as an operation-process (in
some sense) which may be applied to certain objects to produce other
objects. Such a process can be deﬁned by giving a set of rules describing
how it acts on an arbitrary input-object. (The rules need not produce an
output for every input.) A simple example is the permutation-operation
φ deﬁned by
φ(⟨x, y, z⟩) = ⟨y, z, x⟩.
Nowadays one would think of a computer program, though the ‘operat-

46
The power of λ and CL
ion-process’ concept was not originally intended to have the ﬁniteness
and eﬀectiveness limitations that are involved with computation.
From now on, let us reserve the word ‘operator’ to denote this impre-
cise function-as-operation-process concept, and ‘function’ and ‘map’ for
the set-of-ordered-pairs concept.
Perhaps the most important diﬀerence between operators and func-
tions is that an operator may be deﬁned by describing its action with-
out deﬁning the set of inputs for which this action produces results, i. e.
without deﬁning its domain. In a sense, operators are ‘partial functions’.
A second important diﬀerence is that some operators have no restric-
tion on their domain; they accept any inputs, including themselves. The
simplest example is I, which is deﬁned by the operation of doing noth-
ing at all. If this is accepted as a well-deﬁned concept, then surely the
operation of doing nothing can be applied to it. We simply get
I I
=
I.
Other examples of self-applicable operators are K and S; in formal CL
we have
KKxyz =w y,
SSxyz =w yz (xyz),
which suggest natural meanings for KK and SS. Of course, it is not
claimed that every operator is self-applicable; this would lead to contra-
dictions. But the self-applicability of at least such simple operators as
I, K and S seems very reasonable.
The operator concept lies behind programming languages such as ML,
in which a single piece of code may be applied to many diﬀerent types
of inputs. Such languages are called polymorphic.
It can be formalized in set theory if we weaken the axiom of foundation
which prevents functions from being applied to themselves; see (1) in
Remark 16.68.
The operator concept can be modelled in standard ZF set theory if,
roughly speaking, we interpret operators as inﬁnite sequences of func-
tions (satisfying certain conditions), instead of as single functions. This
was discovered by Dana Scott in 1969; see Chapter 16.
However, it must be emphasized that no experience with the operator
concept, or sympathy with it, will be needed in the rest of this book.

4
Representing the computable
functions
4A
Introduction
In this chapter, a sequence of pure terms will be chosen to represent the
natural numbers. It is then reasonable to expect that some of the other
terms will represent functions of natural numbers, in some sense. This
sense will be deﬁned precisely below. The functions so representable will
turn out to be exactly those computable by Turing machines.
In the 1930s, three concepts of computability arose independently:
‘Turing-computable function’, ‘recursive function’ and ‘λ-deﬁnable func-
tion’.
The inventors of these three concepts soon discovered that all
three gave the same set of functions. Most logicians took this as strong
evidence that the informal notion of ‘computable function’ had been
captured exactly by these three formally-deﬁned concepts.
Here we shall look at the recursive functions, and prove that all these
functions can be represented in λ and CL. (We shall not work with
the Turing-computable functions because their representability-proof is
longer.)
An outline deﬁnition of the recursive functions will be given here;
more details and background can be found in many textbooks on com-
putability or textbooks on logic which include computability, for exam-
ple [Coh87], [Men97] or the old but thorough [Kle52].
Notation 4.1
This chapter is written in the same neutral notation as
the last one, and its results will hold for both λ and CL unless explicitly
stated otherwise.
Recall that a combinator in λ or CL is any closed pure term.
The phrase ‘X has a normal form’ will mean (in λ) that X β-reduces
47

48
Computable functions
to a β-normal form, and (in CL) that X weakly reduces to a weak normal
form.
Natural numbers will be denoted by ‘i’, ‘j’, ‘k’, ‘m’, ‘n’, ‘p’, ‘q’, and
the set of all natural numbers by ‘IN’. (We shall assume 0 ∈IN.)
An n-argument function will be a function from a subset of INn into
IN. It will be convenient to include the case n = 0; a 0-argument function
will be simply a natural number.
In computability theory it is standard to use the name ‘partial func-
tion’ for any function φ from a subset of INn into IN, and to call φ ‘total’
iﬀφ(m1, . . . , mn) exists for all m1, . . . , mn ∈IN, and ‘properly partial’
otherwise.
For λ- or CL-terms X and Y , we shall use the abbreviations
Xn Y
≡
X(X(. . . . .(X


 Y ) . . .))
if n ≥1,
n ‘X’s
X0 Y
≡
Y.





(1)
(Warning: the expression ‘Xn’ by itself will have no meaning in this
book; the notation ‘XnY ’ will never be split, and will not mean the
application of a term Xn to a term Y .)
Deﬁnition 4.2 (The Church numerals)
For every n ∈IN, the
Church numeral for n is a term we shall call n or sometimes nCh,1
deﬁned (in λ) by
(a)
n
≡
λxy.xny,
and (in CL) by
(b)
n
≡
(SB)n (KI)
( B ≡S(KS)K ).
Note 4.3
In both λ and CL, the Church numerals have the useful
property that, for all terms F, X,
n FX
▷β,w
F nX.
(2)
Note 4.4
In CL, why are the Church numerals not chosen to be n ≡
[x, y].xny, the exact analogue of those in λ? Well, in fact [x, y].xny ≡
(SB)n(KI) for all n ̸= 1, by Deﬁnition 2.4. But for n = 1 this fails; we
get [x, y].xy ≡I ̸=w SB(KI). Thus, if we deﬁned n ≡[x, y].xny in CL,
1 In some books n is called ⌈n⌉or n, in Curry’s work it was called Zn .

4A Introduction
49
SB would not represent the successor function so neatly. (See Example
4.6.)
The λ-version of the Church numerals comes from [Chu41, p. 28].
Other representations of the natural numbers have also been proposed
in the literature; for examples, see [CHS72, Section 13A1] and [Bar84,
Deﬁnition 6.2.9, §6.4]. Each has its own technical advantages and dis-
advantages.
Deﬁnition 4.5 (Representability)
Let φ be an n-argument partial
function, i.e. a function from a subset of INn into IN (n ≥0). A term X
in λ or CL is said to represent φ iﬀ, for all m1, . . . , mn ∈IN,
(a) φ(m1, . . . , mn) = p
=⇒
X m1 . . . mn
=β,w
p,
and
(b) φ(m1, . . . , mn) does not exist =⇒X m1 . . . mn
has no nf.
Example 4.6
The successor function σ is deﬁned by σ(n) = n + 1 for
all n ∈IN. It can be represented in λ by a term which we shall call σ:
σ ≡λuxy.x(uxy).
In fact it is easy to check that, for all n ∈IN,
σ n
▷β
n + 1.
In CL, deﬁne σ ≡[u, x, y].x(uxy). Then σ ≡SB, so σ represents σ,
because
σ n ≡n + 1.
Remark 4.7
The main theorem of this chapter will be that every
partial recursive function can be represented in both λ and CL.
The converse is also true, that every function representable in λ or
CL is partial recursive. But its proof is too boring to include in this
book. It comes from the fact that the deﬁnitions of =β and =w can be
re-written as recursively axiomatized formal theories (see Chapter 6),
and such theories can be coded into number-theory in such a way that
their syntax can be described using recursive functions. This was ﬁrst
done for λ in [Kle36].
So, for both λ and CL, the representable partial functions are exactly
the partial recursive functions.
After proving the main representability theorem, we shall extend it
to say that every representable function can be represented by a normal
form. This will turn out to be easy in CL, but not in λ.

50
Computable functions
The ﬁrst step towards proving the representability of all partial recur-
sive functions will be to prove the representability of the more restricted
set of functions in the next deﬁnition.
4B
Primitive recursive functions
Deﬁnition 4.8 (Primitive recursive functions)
The set of all
primitive recursive functions of natural numbers is deﬁned by induction
as follows, compare [Coh87, Section 3.1], [Kle52, Section 44, Remark 1,
Basis B], [Men97, Chapter 3, Section 3], [Rau06, Section 6.1].
(I) The successor function σ is primitive recursive.
(II) The number 0 is a 0-argument primitive recursive function.
(III) For each n ≥1 and k ≤n, the following projection function Πn
k
is primitive recursive:
Πn
k (m1, . . . , mn) = mk
(for all m1, . . . , mn ∈IN).
(IV) If n, p ≥1, and ψ, χ1, . . . , χp are primitive recursive, then so is
the function φ deﬁned by composition as follows:
φ(m1, . . . , mn) = ψ

χ1(m1, . . . , mn), . . . , χp(m1, . . . , mn)

.
(V) If n ≥0 and ψ and χ are primitive recursive, then so is the
function φ deﬁned by recursion as follows:
φ(0, m1, . . . , mn)
= ψ(m1, . . . , mn),
φ(k + 1, m1, . . . , mn) = χ(k, φ(k, m1, . . . , mn), m1, . . . , mn).
(By checking the clauses of the above deﬁnition it can be seen that all
primitive recursive functions are total.)
Example 4.9
The predecessor function π is deﬁned thus:
π(0) = 0,
π(k + 1) = k.
(3)
It is primitive recursive. To prove this in detail, we ﬁrst make its deﬁ-
nition ﬁt the pattern of (V) exactly, thus:
π(0) = 0,
π(k + 1) = Π2
1(k, π(k)),
(4)
where Π2
1(m1, m2) = m1 for all m1, m2 ∈IN. By (III), Π2
1 is primitive re-
cursive. By (II), 0 is primitive recursive. Hence π is primitive recursive,

4B Primitive recursion
51
by (V) with
n = 0,
ψ = 0,
χ = Π2
1.
Exercise 4.10 ∗The cut-oﬀsubtraction function
·
is often used in-
stead of subtraction in work with natural numbers, because subtraction
is not a total function. (In the world of natural numbers, 2 −5 does not
exist, for example.) Its deﬁnition is
m · n = m −n
if m ≥n,
m · n = 0
otherwise.
Prove, using Deﬁnition 4.8(I)–(V), that · is primitive recursive. (Hint:
use the predecessor function.)
Theorem 4.11 (Representation of primitive recursion) In λ with
=β or CL with =w: every primitive recursive function φ can be repre-
sented by a combinator φ.
Proof The term φ is chosen by induction, corresponding to the clauses
in Deﬁnition 4.8.
(I) Choose σ ≡λuxy.x(uxy), as in Example 4.6.
(II) Choose 0 ≡λxy.y, the Church numeral for 0.
(III) Choose Πn
k ≡λx1 . . . xn . xk.
(IV) Given ψ, χ1, . . . , χp representing ψ, χ1, . . . , χp respectively, choose
φ ≡λx1 . . . xn .

ψ (χ1 x1 . . . xn) . . . (χp x1 . . . xn)

.
(V) Given ψ and χ representing ψ and χ respectively, choose
φ ≡λux1 . . . xn .

R (ψ x1 . . . xn)(λuv.χ uvx1 . . . xn) u

,
(5)
where R is a term to be constructed below, called a recursion
combinator. This R will have the property that, for all X, Y, k,
RXY 0
=β,w
X,
RXY (k + 1)
=β,w
Y k (RXY k ).

(6)
If an R exists satisfying (6), then the term φ in (5) will represent the
function φ in Case (V) of Deﬁnition 4.8; because
φ 0 x1 . . . xn
=β,w
R (ψx1 . . . xn)(λuv.χuvx1 . . . xn) 0
=β,w
ψx1 . . . xn
by (6),
and

52
Computable functions
φ (k + 1)x1 . . . xn
=β,w R (ψx1 . . . xn)(λuv.χuvx1 . . . xn) (k + 1)
=β,w (λuv.χuvx1 . . . xn) k

R (ψx1 . . . xn)(λuv.χuvx1 . . . xn) k

by (6)
=β,w (λuv.χuvx1 . . . xn) k (φ k x1 . . . xn)
by deﬁnition of φ
=β,w χ k (φ k x1 . . . xn) x1 . . . xn .
We shall now construct an R to satisfy (6). There are many ways
of doing this, see [CHS72, Section 13A3]; the one chosen here is from
[Chu41, p. 39] and is due to Paul Bernays. It is one of the easiest to
motivate, and gives an R which is shorter than most others, has a normal
form, and is also typable in the sense of Chapters 11 and 12.
To motivate Bernays’ R, consider for example a primitive recursive
function φ deﬁned by
φ(0) = m,
φ(k + 1) = χ(k, φ(k)).
(7)
One way of calculating φ(k) is to ﬁrst write down the ordered pair ⟨0, m⟩
and then iterate k times the function Next such that
Next(⟨n, x⟩) = ⟨n + 1, χ(n, x) ⟩,
(8)
and ﬁnally take the second member of the last pair produced. R will
imitate this calculation-procedure.
The ﬁrst step in constructing Bernays’ R is to deﬁne a pairing com-
binator (compare Exercise 2.34):
D ≡λxyz.z(Ky)x.
(9)
It is easy to check that, for all terms X and Y ,
DXY 0
▷β,w
X,
DXY k + 1
▷β,w
Y.

(10)
We can think of Dp q as an analogue of an ordered pair ⟨p, q⟩, since (10)
gives a method of picking out the ﬁrst or second member.
Using D, we now make a λ-analogue of the function Next in (8). Deﬁne
Q ≡λyv. D(σ (v0 )) (y (v0 )(v1 )),
(11)
where σ was deﬁned in Example 4.6. Then, for all X, Y , n,
QY (DnX)
▷β,w
D (σ (DnX0 )) (Y (DnX0 ) (DnX1 ))
▷β,w
D (σ n) (Y nX)
by (10)
▷β,w
D(n + 1)(Y nX)
by 4.6.





(12)

4B Primitive recursion
53
Thus QY would imitate the function Next, if Y represented the function
χ in (7) and (8). Also, by using (12) repeatedly, we get, for all X, Y
and all k ≥0,
(QY )k(D0X) ▷β,w DkXk
(13)
for some term Xk, whose details will not matter.
Now deﬁne
RBernays ≡λxyu. u(Qy)(D0x)1.
(14)
Then, if R is RBernays, we have, for all X, Y :
RXY k
▷β,w
k (QY )(D0X)1
▷β,w
(QY )k(D0X)1
by (2)
▷β,w
D k Xk 1
by (13)
▷β,w
Xk
by (10).









(15)
From this, the two parts of (6) follow, thus:
RXY 0
▷β,w
(QY )0(D0X)1
by (14) and (2)
▷β,w
D 0 X 1
by (1), def. of ( )0( )
▷β,w
X
by (10);
RXY k + 1
▷β,w
(QY )k+1(D0X) 1
by (14) and (2)
▷β,w
(QY )

(QY )k(D0X)

1
by (1)
▷β,w
QY (DkXk)1
by (13)
▷β,w
D(k + 1)(Y kXk)1
by (12)
▷β,w
Y kXk
by (10)
=β,w Y k (RXY k)
by (15).
Note 4.12 All the reductions in the preceding proof hold for ▷w in CL
as well as for ▷β in λ. This is rather tedious to check in detail, but after
Chapter 6 it will become clear that only one fact need be checked: never
is a redex-occurrence contracted when it is in the scope of a λ. In fact,
with one exception, all contractions in the proof of Theorem 4.11 have
form
P1 . . . Pr

(λx.M)NQ1 . . . Qs

▷
P1 . . . Pr

([N/x]M)Q1 . . . Qs


54
Computable functions
(r, s ≥0), and such contractions translate into CL as correct weak re-
ductions. The same will hold for other combined proofs for λ and CL
later.
The one exception is σ n ▷β n + 1; but that reduction translates into
CL as an identity, as mentioned in Example 4.6.
Example 4.13
The predecessor function π is deﬁned thus: π(0) = 0,
π(k + 1) = k. It is primitive recursive, as we saw in Example 4.9. We
can build a term π to represent π by applying the proof of Theorem 4.11
to the equations
π(0) = 0,
π(k + 1) = k.
The result is
πBernays
≡
RBernays0 K.
It is easy to check that this term represents π; it is enough to prove,
using (6), that, if π is πBernays, then
π 0 =β,w 0,
π (σ k) =β,w k.
(16)
By the way, πBernays is not the shortest known representative of π; in fact
it becomes rather long when RBernays is written out fully. The following
term, due independently to Martin Bunder and F. Urbanek, is shorter
and can easily be checked to represent π in both λ and CL:
πBund−Urb
≡
λx.

x (λuv.v(uσ))(K0) I

.
Note 4.14
For the pairing combinator D ≡λxyz.z(Ky)x deﬁned in
(9), we can deﬁne two projection combinators D1, D2, thus:
D1 ≡λx.x0,
D2 ≡λx.x1.
Then, by (10),
D1(DX1X2) ▷β,w X1,
D2(DX1X2) ▷β,w X2.
Sometimes D is called a conditional operator, and DXY n is called
If n = 0 then X, else Y.
Note 4.15 (Recursion using ﬁxed points) An alternative to Bern-
ays’ R can be made using any ﬁxed-point combinator Y. Let π be any
representative of π, and consider the equation
Rxyz =

If z = 0 then x, else y(πz)(Rxy(πz))

,

4B Primitive recursion
55
or equivalently, the equation
Rxyz = D x (y(πz)(Rxy(πz))) z.
By Corollary 3.3.1, this has a solution, which we shall call ‘RFix’:
RFix ≡Y

λuxyz. D x (y(πz)(uxy(πz))) z

.
This deﬁnition has an attractive simplicity of structure; and if a simple
enough π could be found, RFix would be shorter than RBernays.2 How-
ever, RFix has no normal form in λ-calculus, and this is sometimes a
disadvantage.
Exercise 4.16 ∗
(a) Let φ(m) = 3m + 2 for all m ≥0; this φ is primitive recursive,
and we have φ(0) = 2 and φ(k +1) = 3+φ(k); use R in the proof
of Theorem 4.11 to build a combinator that represents φ.
(b) Do the same for the functions Add, Mult and Exp, where
Add(m, n) = m + n,
Mult(m, n) = m × n,
Exp(m, n) = mn.
(c) Do the same for the cut-oﬀsubtraction function
·
deﬁned in
Exercise 4.10.
(d) (Harder) Although the proof of Theorem 4.11 gives a systematic
way of representing every primitive recursive function, it does not
claim to give the shortest possible representative. For the three
functions in (b), ﬁnd representatives without using R that are
much shorter than those built with R.
Extra practice 4.17 The following functions are primitive recursive;
use R in the proof of Theorem 4.11 to build combinators that represent
them:
(a) the function φ deﬁned by φ(m) = m2 + 2m + 3,
(b) the factorial function Fac(m) = m!, where 0! = 1 and
(k + 1)! = (k + 1) × k × . . . × 2 × 1.
2 In [Bar84] the numerals were chosen specially to make π simple, see [Bar84, Lemma
6.2.10]; but most other writers prefer the Church numerals.

56
Computable functions
4C
Recursive functions
Deﬁnition 4.18 (Recursive total functions)
A total function φ
from INn into IN (n ≥0) is called recursive iﬀthere exist primitive
recursive functions ψ and χ such that, for all m1, . . . , mn ∈IN,
φ(m1, . . . , mn) = ψ

µk[ χ(m1, . . . , mn, k) = 0]

,
where
(i) there exists a k such that χ(m1, . . . , mn, k) = 0,
(ii) µk[χ(m1, . . . , mn, k) = 0] is the least such k.3
Note 4.19 Condition (i) ensures that φ(m1, . . . , mn) exists for all m1,
. . . , mn ∈IN.
The above deﬁnition of ‘recursive’ has been chosen to make the next
theorem’s proof as easy as possible. The standard deﬁnition can be found
in books on recursion theory, for example [Men97, Chapter 3 Section 3,
Chapter 5 Section 3], and the above one is equivalent to it by Kleene’s
Normal Form theorem, [Kle52, Section 58] or [Men97, Corollary 5.11].
Theorem 4.20 (Representation of total recursion) In λ with =β
or CL with =w: every recursive total function φ can be represented by a
combinator φ.
Proof Let ψ, χ be primitive recursive, and, for all m1, . . . , mn ∈IN, let
φ(m1, . . . , mn) = ψ

µk[ χ(m1, . . . , mn, k) = 0]

.
By Theorem 4.11, ψ and χ are representable by terms ψ and χ.
One way of computing µk[χ(m1, . . . , mn, k) = 0] is to try to program
a function θ such that θ(k) outputs k if χ(m1, . . . , mn, k) = 0, and moves
on to θ(k + 1) otherwise; when this program is started with k = 0, it
will output the ﬁrst k such that χ(m1, . . . , mn, k) = 0. The λ-analogue
or CL-analogue of such a program would be a term H satisfying the
following equation:
Hx1...xny =

If χx1...xny = 0 then y, else Hx1...xn(σy)

.
(17)
Given such an H, the following term could represent φ:
φ ≡λx1 . . . xn . ψ(Hx1 . . . xn0 ).
(18)
3 Recursive functions may also be called total recursive or general recursive.

4C Recursive functions
57
A suitable H can be found by applying Corollary 3.3.1 to solve Equa-
tion (17), using any ﬁxed-point combinator Y, thus:
H ≡Y

λux1 . . . xny. D y (ux1 . . . xn(σy))(χ x1 . . . xny)

.
(19)
However, the λ-version of the above H has no normal form.
The
following H is more complicated, but will be used in a later proof on
representability by normal forms. First deﬁne
T
≡
λx. D 0

λuv. u (x(σv))u(σv)

,
P
≡
λxy. Tx(xy)(Tx)y.

(20)
Then, for all terms X and Y , we have
PXY =β,w Y
if XY =β,w 0,
PXY =β,w PX(σY )
if XY =β,w m + 1 for some m.

(21)
To prove (21), note ﬁrst that
PXY =β,w TX(XY )(TX)Y
=β,w D 0 (λuv. u(X(σv))u(σv)) (XY ) (TX) Y
where u, v ̸∈FV(XY ). If XY =β,w 0, then, by (10),
PXY =β,w 0 (TX)Y
=β,w Y
because 0 ≡λxy.y.
If XY =β,w m + 1, then, by (10),
PXY =β,w (λuv. u(X(σv))u(σv)) (TX) Y
=β,w TX(X(σY ))(TX)(σY )
=β,w PX(σY ).
This proves (21). Now deﬁne
H ≡λx1 . . . xny. P(χx1 . . . xn)y.
(22)
Then, for all X1,. . . , Xn, Y , we have by (21),
HX1 . . . XnY =β,w P(χX1 . . . Xn)Y
=β,w

Y
if χX1 . . . XnY =β,w 0,
HX1 . . . Xn(σY )
if χX1 . . . XnY =β,w m + 1.
Finally, using H, deﬁne φ by (18). Thus all recursive total functions can
be represented in λ and CL.

58
Computable functions
Deﬁnition 4.21 (Partial recursive functions)
A function φ from
a subset of INn into IN (n ≥0) is called partial recursive4 iﬀthere exist
primitive recursive ψ and χ such that, for all m1, . . . , mn ∈IN,
φ(m1, . . . , mn) = ψ

µk[ χ(m1, . . . , mn, k) = 0]

,
where µk[χ(m1, . . . , mn, k) = 0] is the least k such that χ(m1, . . . , mn, k)
= 0, if such a k exists, and is undeﬁned if no such k exists.
Example 4.22 The subtraction function is partial recursive. Because
m1 −m2 = µk[((m2 + k) · m1) = 0],
where
·
is the cut-oﬀsubtraction introduced in Example 4.10. Note
that when m1 < m2, we have (m2 + k) · m1 > 0 for all k ≥0, so
µk[((m2 + k) · m1) = 0] does not exist. This agrees with m1 −m2 not
existing when m1 < m2.
Theorem 4.23 (Representation of partial recursion)
In λ with
=β or CL with =w: every partial recursive function φ can be represented
by a combinator φ.
Proof Let ψ, χ be primitive recursive, and, for all m1,. . . , mn ∈IN, let
φ(m1, . . . , mn) = ψ

µk[ χ(m1, . . . , mn, k) = 0]

.
We shall modify the proof of Theorem 4.20, to construct a φ such
that φ m1 . . . mn has no normal form when there is no k such that
χ(m1, . . . , mn, k) = 0.
We shall use a device due to Bruce Lercher,
[Ler63].
First take the φ from the proof of Theorem 4.20 and call it ‘F’:
F ≡λx1 . . . xn . ψ (Hx1 . . . xn0 ),
where H is deﬁned by (19) or (22). For all m1, . . . , mn ∈IN, we have
F m1 . . . mn =β,w φ(m1, . . . , mn).
(23)
Next, take the term P from (20) and deﬁne
φ ≡λx1 . . . xn . P(χx1 . . . xn) 0 I (Fx1 . . . xn).
(24)
To justify this choice of φ, suppose ﬁrst that m1, . . . , mn are such that
χ(m1, . . . , mn, k) = 0 for some k, and let j be the least such k. Then
4 ‘Recursive partial’ would be more systematic but ‘partial recursive’ is standard.

4C Recursive functions
59
φ m1 . . . mn
=β,w
j I (F m1 . . . mn )
by the proof of 4.20
=β,w
I j (F m1 . . . mn )
by (2)
=β,w
F m1 . . . mn
by the deﬁnition of I
=β,w
φ(m1, . . . , mn)
by (23).
On the other hand, suppose m1, . . . , mn are such that there is no k
such that χ(m1, . . . , mn, k) = 0. We must prove that φ m1 . . . mn has no
normal form.
First, since χ is total (being primitive recursive), for every k there is
a pk ≥0 such that
χ(m1, . . . , mn, k) = pk + 1.
Let X ≡χ m1 . . . mn. Then X k =β,w pk + 1. Furthermore,
X k ▷β,w pk + 1,
(25)
by the Church–Rosser theorem, because the Church numerals are in
normal form in both λ and CL.
To prove that φ m1 . . . mn has no nf, it is enough to ﬁnd an inﬁnite
quasi-leftmost reduction of this term, by Corollary 3.22.1 (which holds
for both ▷β and ▷w). Consider the following reduction (not every con-
traction is shown, and F m1 . . . mn is written as ‘G’ for short):
φ m1 . . . mn
▷β,w PX 0 IG
by (24)
▷β,w TX(X 0 )(TX) 0 IG
by (20)
▷β,w TX(p0 + 1 )(TX) 0 IG
by (25) (k = 0)
▷β,w

λuv.u(X(σv))u(σv)

(TX)0 IG by defs. of T, D
▷β,w TX(X(σ 0 ))(TX)(σ 0 )I G
▷β,w TX(X 1 )(TX) 1 I G
by def. of σ
▷β,w . . .
▷β,w TX(X 2 )(TX)2 I G
similarly
▷β,w . . . etc.
Clearly this reduction is inﬁnite, and there is at least one leftmost max-
imal contraction in each part with form
TX(X i )(TX) i I G ▷β,w TX(X (i + 1))(TX) (i + 1) I G.
The preceding theorem can be strengthened as follows.

60
Computable functions
Theorem 4.24 (Representation by normal forms) In λ with =β
or CL with =w: every partial recursive function φ can be represented by
a combinator φ in normal form.5
Proof
In CL, the job is easy.
Take the φ from (24) in the proof of
Theorem 4.23, and apply to it the procedure in the answer to Exercise
3.12(c). (Note that the notation ‘λx1 . . . xn’ in (24) means ‘[x1 . . . xn]’
in CL.) The result is a weak normal form which represents φ.
In λ, the normal forms are a more restricted class, and the job of
ﬁnding one to represent φ is less trivial. The following is based on a
proof by Lercher, [Ler63]; details are omitted here.
Step 1: Prove the following general lemma about β-normal forms, for
all variables y, z, by induction on lgh(M) using Lemma 1.33:
M, N in nf
=⇒
[(zN)/y]M in nf and Mz has nf.
(26)
Step 2:
To prove the theorem for primitive recursive functions φ,
consider the ﬁve cases in the proof of Theorem 4.11. In Cases (I)–(III),
the terms φ shown in the proof of 4.11 are clearly nfs.
In Case (IV), φ was
λx1 . . . xn .

ψ (χ1 x1 . . . xn) . . . (χp x1 . . . xn)

.
Assume that ψ, χ1, . . . , χp are nfs. By (26), we can reduce (χ1 x1 . . . xn),
. . . , (χp x1 . . . xn) to nfs, call them N1, . . . Np. Choose
φ ≡λx1 . . . xn . (x1 I ψ N1 . . . Np).
(27)
(Note that n ≥1 in Case (IV) of Deﬁnition 4.8.) This is a nf. And it
represents φ, because, for all m1 ≥0, we have
m1 I ψ
▷β
Im 1 ψ
▷β
ψ.
In Case (V), the φ in (5) in the proof of 4.11 contains the terms D,
Q and RBernays deﬁned in (9), (11) and (14). All these, including φ, can
be proved to have nfs, using (26).
Step 3:
For recursive total functions, look at the proof of 4.20. The
terms T and P in (20) can be shown to have nfs, using (26). Instead of
the H in (22), the following term has the same eﬀect and has a nf:
H ≡λx1 . . . xny . x1 I P (χx1 . . . xn) y.
5 In [HS86] the proof of representation by nfs was incomplete.
The authors are
grateful to John Shepherdson for pointing this out.

4D Abstract numerals
61
Instead of the φ in (18), use the normal form of the following:
λx1 . . . xn . x1 I ψ (Hx1 . . . xn0 ).
(28)
Step 4:
For partial recursive functions, modify the proof of 4.23 by
changing the φ in (24) to the normal form of
λx1 . . . xn . x1 I P(χx1 . . . xn) 0 I (Fx1 . . . xn),
(29)
where F is the φ obtained in Step 3.
4D
Abstract numerals and Z
Discussion 4.25 Instead of using pure terms to represent the numbers
in λ or CL, it is possible to add two new atomic constants 0 and σ to
the deﬁnition of ‘term’, and to represent each number n by
n
≡
σ n 0.
(30)
These are called the abstract numerals.
For these numerals, there is no way of constructing an R with the
property (6), nor even of representing the predecessor function (see Ex-
ercise 4.27 below).
However, suppose we add a third new atom Z, and add to the deﬁni-
tion of ▷β or ▷w the following new contractions (one for each n ≥0):
Z n
▷1
nCh,
(31)
where nCh is the Church numeral for n. (Z is called an iteration oper-
ator.) Let ▷β,w Z be the resulting new reducibility relation. For both λ
and CL, this relation is conﬂuent (Appendix A2, Theorem A2.15). It
can also be shown to satisfy a standardization theorem (using a mod-
iﬁed deﬁnition of ‘standard reduction’), and a theorem rather like the
quasi-leftmost reduction theorem [Hin78, Theorems 1, 8].
Further, from Z we can build a recursion operator R. The following
construction is from [CHS72, Section 13A3 p. 224, term R(Be)] and is
very like that of RBernays in (11) and (14):
Q
≡
λyv. D (σ(v0Ch)) (y(v0Ch)(v1Ch)),
R
≡
λxyu. Z u (Qy)(D0x) 1Ch,

(32)

62
Computable functions
where D ≡λxyz.z(Ky)x as in Note 4.14. By following the proof of (6),
this R can be shown to satisfy
R X Y 0
▷β,w Z
X,
R X Y ( 
k + 1)
=β,w Z
Y k (RXY k ).

(33)
Also a term P like that in (20) can be constructed:
T
≡
λx. D 0Ch

λuv. u (x(σv))u(σv)

,
P
≡
λxy. Tx(Z(xy))(Tx)y.

(34)
It is straightforward to check that, for all terms X and Y ,
PXY
=β,w Z Y
if XY =β,w Z 0,
PXY
=β,w Z PX(σY )
if XY =β,w Z 
m + 1.

(35)
Thus, if the numerals are abstract, all recursive total functions can be
represented in terms of Z.
For partial functions a representation theorem like Theorem 4.23 can
probably be proved by a method like 4.23, but we have not seen a proof.
Deﬁnition 4.26 (Arithmetical extension) For λ or CL, the arith-
metical extension λβZ or CLwZ, is obtained by adding to the set of
terms three new atoms 0, σ and Z, as suggested above, and adding to
the deﬁnition of ▷β or ▷w the following new contractions:
Z n
▷1
nCh
(n = 0, 1, 2, . . . ),
where nCh is the Church numeral λxy.xny or (SB)n(KI).
The new
reduction is called ▷βZ (in λ) or ▷wZ (in CL).
Exercise 4.27 ∗
In λ or CL with abstract numerals, prove that if
Z is absent then the predecessor-function π (such that π(0) = 0 and
π(k + 1) = k) cannot be represented by a term.

5
The undecidability theorem
The aim of this chapter is to prove a general undecidability theorem
which will show in particular that the relation =β is recursively unde-
cidable, and that there is no recursive way of deciding whether a λ-term
has a normal form or not. These two were the ﬁrst ever undecidability
results to be discovered, and it was from them that Church deduced the
undecidability of pure ﬁrst-order predicate logic in 1936, answering a
question posed by the leading mathematician David Hilbert over thirty
years before (Hilbert’s Entscheidungsproblem).
But the more general theorem we shall describe was ﬁrst proved by
Dana Scott in 1963 (in unpublished notes, but see [Bar84, Section 6.6]),
and rediscovered independently by Curry [CHS72, Section 13B2].
It
applies to CL as well as to λ.
Notation 5.1 This chapter will use the neutral notation of the preced-
ing two chapters, which can be read in both λ and CL. All functions of
natural numbers will here be total, i.e. will give outputs for all n ∈IN.
Numerals will be those of Church:
n ≡λxy.xny in λ-calculus,
n ≡(SB)n(KI) in CL.
Assumption 5.2
We assume that every term X has been given a
number n by some coding algorithm. There are many possible such al-
gorithms; indeed there is one in every word-processing software package,
to translate expressions on the computer screen into the numbers with
which the computer actually works. A simple coding algorithm is de-
scribed in [Men97, Chapter 3, Section 4], though it is not intended to
be practical or eﬃcient. However, coding details will not matter here.
The number assigned to X will be called the G¨odel number of X, or
63

64
Undecidability
gd(X), in honour of the man who ﬁrst made use of such a coding. We
shall assume that
(a) there is a recursive total function τ of natural numbers, such that,
for all terms X, Y ,
τ

gd(X), gd(Y )

= gd

(XY )

;
(b) there is a recursive total function ν such that, for all n ∈IN,
ν(n) = gd(n).
For example, suitable functions τ and ν can be proved to exist for the
coding algorithm in [Men97, Chapter 3, Section 4]; the underlying reason
is that the operation of building a term (XY ) from terms X and Y is
eﬀectively computable, and so is the operation of building n from n.
Deﬁnition 5.3 For all terms X, the Church numeral corresponding to
gd(X) will be called ‘⌈X⌉’:
⌈X⌉≡gd(X).
Note If X is a term, then gd(X) is a number and ⌈X⌉is a term. For
example, if the coding-algorithm assigns the number 5 to the term uv,
then
gd(uv) = 5,
⌈uv⌉≡λxy.x(x(x(x(xy)))).
Deﬁnition 5.4
A pair of sets A, B of natural numbers is called re-
cursively separable iﬀthere is a recursive total function φ whose only
output-values are 0 and 1, such that
n ∈A
=⇒
φ(n) = 0,
n ∈B
=⇒
φ(n) = 1.
A pair of sets of terms is called recursively separable iﬀthe corresponding
sets of G¨odel numbers are recursively separable. A set A (of numbers
or terms) is called recursive or decidable iﬀA and its complement are
recursively separable.
Informally speaking, a pair A, B is recursively separable iﬀA ∩B is
empty and there is an algorithm which decides whether a number or
term is in A or in B.

Undecidability
65
Deﬁnition 5.5 In λ with =β or CL with =w, a set A of terms is said
to be closed under conversion (or equality) iﬀ, for all terms X, Y ,
X ∈A and Y =β,w X
=⇒
Y ∈A.
Theorem 5.6 (Scott–Curry undecidability theorem) For sets of
terms in λ with =β or CL with =w: no pair of non-empty sets which
are closed under conversion is recursively separable.
Proof Let A, B be sets of terms, non-empty and closed under conversion.
Suppose there is a recursive total function φ whose only output-values
are 0 and 1, which separates A from B; i.e. such that
X ∈A
=⇒
φ(gd(X)) = 0,
(1)
X ∈B
=⇒
φ(gd(X)) = 1.
(2)
By Theorem 4.20, there is a combinator F which represents φ. Then
X ∈A
=⇒
F⌈X⌉=β,w 0,
(3)
X ∈B
=⇒
F⌈X⌉=β,w 1.
(4)
Also the functions τ and ν in Assumption 5.2(a) and (b) are recursive, so
they can be represented by combinators, call them T and N respectively.
So, for all X, Y , n,
T⌈X⌉⌈Y ⌉=β,w ⌈(XY )⌉,
(5)
N n =β,w ⌈n⌉.
(6)
Choose any terms A ∈A and B ∈B. We shall build a term J (which
will depend on A and B), such that
F⌈J⌉=β,w 0
=⇒
J =β,w B,
(7)
F⌈J⌉=β,w 1
=⇒
J =β,w A.
(8)
This will cause a contradiction. To see this, let j = gd(J); then φ(j) = 0
or φ(j) = 1, and (since φ is a function) not both at once. But
φ(j) = 0
=⇒
F⌈J⌉=β,w 0
since ⌈J⌉≡j and F represents φ,
=⇒
J =β,w B
by (7),
=⇒
J ∈B
since B is closed under =β,w,
=⇒
φ(j) = 1
by (2);

66
Undecidability
φ(j) = 1
=⇒
F⌈J⌉=β,w 1
since ⌈J⌉≡j and F represents φ,
=⇒
J =β,w A
by (8),
=⇒
J ∈A
since A is closed under =β,w,
=⇒
φ(j) = 0
by (1).
Now (7) and (8) would hold if we could obtain
J =β,w DBA(F⌈J⌉),
(9)
where D is the pairing combinator from (9), D ≡λxyz.z(Ky)x. Because,
by (10) in Chapter 4,
DBA 0 =β,w B,
DBA 1 =β,w A.
To build a J satisfying (9), choose y ̸∈FV(AB) and deﬁne
H
≡
λy.DBA(F(Ty(Ny))),
J
≡
H⌈H⌉.

(10)
This J satisﬁes (9), because
J =β,w
D B A (F (T⌈H⌉(N⌈H⌉)))
by the deﬁnitions of J, H,
=β,w
D B A (F (T⌈H⌉⌈⌈H⌉⌉))
by (6),
=β,w
D B A (F ⌈(H⌈H⌉)⌉)
by (5),
≡
D B A (F⌈J⌉)
since J ≡H⌈H⌉.
Corollary 5.6.1 In λ with =β or CL with =w: if a set A of terms is
closed under conversion and both A and its complement are non-empty,
then A is not decidable.
Proof In Theorem 5.6 let B be the complement of A, i.e. the set of all
terms not in A.
Corollary 5.6.2 In λ with =β or CL with =w: the set of all terms
which have normal forms is not decidable.
Roughly speaking, there is no algorithm which will decide, in ﬁnite
time, whether a term X has a normal form or not.

Undecidability
67
Corollary 5.6.3 The relations =β and =w are not decidable. That is,
there is no recursive total function ψ such that
X =β,w Y
=⇒
ψ(gd(X), gd(Y )) = 0,
X ̸=β,w Y
=⇒
ψ(gd(X), gd(Y )) = 1.
Proof In 5.6.1, let A be the set of all terms convertible to one particular
term (I, for example).
Remark 5.7 (Entscheidungsproblem)
As mentioned earlier,
Church proved in 1936 that pure classical ﬁrst-order predicate logic is
undecidable. His proof can be summarized as follows. When λ-terms
are given G¨odel numbers, then =β corresponds to a relation between
natural numbers. Natural numbers can be coded by terms in a pure
predicate language which has function symbols, by choosing a variable
z and a function-symbol f and letting
z
represent
0,
f(z)
represent
1,
f(f(z))
represent
2,
etc.
Let n be the representative of n in this coding. The deﬁnition of =β
can be re-written as a formal theory with eight axiom-schemes and
rules of inference, as we shall see in the next chapter (the theory λβ).
These axiom-schemes and rules can be translated, via G¨odel-numbering,
into eight predicate-calculus formulas F1, . . . , F8 containing a predicate-
symbol E, such that the formula

F1 ∧. . . ∧F8

→E(m, n)
is provable in pure predicate logic iﬀm, n are G¨odel numbers of inter-
convertible terms.
Hence, if we could decide all questions of provability in pure predicate
logic, then we could decide whether arbitrary λ-terms are interconvert-
ible, contrary to Corollary 5.6.3.
(The details of Church’s proof are in [Chu36b] and [Chu36a]; in the
former he proved the undecidability of =β, and in the latter he deduced
that of predicate logic.)
Exercise 5.8 ∗Church’s proof of the undecidability of =β in [Chu36b]
was more direct than our proof via the Scott–Curry theorem. And the
version of λ he used was the λI-calculus, described in Remark 1.43.

68
Undecidability
Prove that the general Scott–Curry theorem is not in fact true for this
calculus. (Hint: to do this, you must ﬁnd two non-empty sets of λI-
terms which are closed under conversion yet are recursively separable;
one approach is to use the fact that if X =β Y in the λI-calculus, then
FV(X) = FV(Y ).)
Exercise 5.9 ∗(a) In λ or CL, the range of a combinator F may be
deﬁned to be the set of all combinators Y such that Y =β,w FX for
some combinator X. Prove that the range of F is either inﬁnite or a
singleton, modulo =β,w. (This was conjectured by B¨ohm and proved by
Barendregt, [Bar84, Theorem 20.2.5]. Its proof is a neat application of
Theorem 5.6 for a reader who knows some recursion theory.)
(b)
The second ﬁxed-point theorem, [Bar84, Theorem 6.5.9], states
that for every λ- or CL-term F there exists a term XF such that
F⌈XF ⌉=β,w XF .
Prove this theorem. (Hint: modify J in the proof of Theorem 5.6.)

6
The formal theories λβ and CLw
6A
The deﬁnitions of the theories
The relations of reducibility and convertibility were deﬁned in Chapters
1 and 2 via contractions of redexes. The present chapter gives alternative
deﬁnitions, via formal theories with axioms and rules of inference.
These theories will be used later in describing the correspondence be-
tween λ and CL precisely, and will help to make the distinction between
syntax and semantics clearer in the chapters on models to come. They
will also give a more direct meaning to such phrases as ‘add the equation
M = N as a new axiom to the deﬁnition of =β . . . ’ (Corollary 3.11.1).
In books on logic, formal theories come in two kinds (at least): Hil-
bert-style and Gentzen-style. The theories in this chapter will be the
former.
Notation 6.1
(Hilbert-style formal theories) A (Hilbert-style)
formal theory T consists of three sets: formulas, axioms and rules (of
inference). Each rule has one or more premises and one conclusion, and
we shall write its premises above a horizontal line and its conclusion
under this line; for examples, see the rules in Deﬁnition 6.2 below.
If Γ is a set of formulas, a deduction of a formula B from Γ is a tree of
formulas, with those at the tops of branches being axioms or members
of Γ, the others being deduced from those immediately above them by a
rule, and the bottom one being B. Non-axioms at the tops of branches
are called assumptions. Iﬀsuch a deduction exists, we say
T , Γ ⊢B,
or
Γ ⊢T
B.
IﬀΓ is empty, we call the deduction a proof, call B a provable formula
69

70
Formal theories
or theorem of T , and say
T
⊢B,
or
⊢T
B.
Finally, in this book an axiom-scheme will be any set of axioms which
all conform to some given pattern.
(This sense of ‘formal theory’ comes from [Men97, Chapter 1, Section
4], except that deductions were viewed there as linear sequences, not
trees.)
Deﬁnition 6.2 (λβ, formal theory of β-equality)
The formulas
of λβ are just equations M = N, for all λ-terms M and N. The axioms
are the particular cases of (α), (β) and (ρ) below, for all λ-terms M, N,
and all variables x, y. The rules are (µ), (ν), (ξ), (τ) and (σ) below.
(Their names are from [CF58].)
Axiom-schemes:
(α)
λx.M = λy.[y/x]M
if y ̸∈FV(M);
(β)
(λx.M)N = [N/x]M;
(ρ)
M = M.
Rules of inference:
(µ)
M = M ′
NM = NM ′ ;
(τ)
M = N
N = P
M = P
;
(ν)
M = M ′
MN = M ′N ;
(σ)
M = N
N = M ;
(ξ)
M = M ′
λx.M = λx.M ′ .
Iﬀan equation M = N is provable in λβ, we say
λβ
⊢
M = N.
Deﬁnition 6.3 (λβ, formal theory of β-reduction)
This theory
is called λβ like the previous one. (The context will always make clear
which theory the name ‘λβ’ means.) Its formulas are expressions M ▷N,
for all λ-terms M and N. Its axiom-schemes and rules are the same as
in Deﬁnition 6.2, but with ‘=’ changed to ‘▷’ and rule (σ) omitted. Iﬀ
an expression M ▷N is provable in λβ, we say
λβ
⊢
M ▷N.

6A The theories λβ and CLw
71
Lemma 6.4
(a)
M ▷β N
⇐⇒
λβ ⊢M ▷N;
(b)
M =β N
⇐⇒
λβ ⊢M = N.
Proof Straightforward and boring.
Deﬁnition 6.5 (CLw, formal theory of weak equality)
The
formulas of CLw are equations X = Y , for all CL-terms X and Y . The
axioms are the particular cases of the four axiom-schemes below, for all
CL-terms X, Y and Z. The rules are (µ), (ν), (τ) and (σ) below.
Axiom-schemes:
(I)
IX = X;
(K)
KXY
= X;
(S)
SXY Z = XZ(Y Z);
(ρ)
X = X.
Rules of inference:
(µ)
X = X′
ZX = ZX′ ;
(τ)
X = Y
Y = Z
X = Z
;
(ν)
X = X′
XZ = X′Z ;
(σ)
X = Y
Y = X .
Iﬀan equation X = Y is provable in CLw, we say
CLw
⊢
X = Y.
Deﬁnition 6.6 (CLw, formal theory of weak reduction)
The
formulas of CLw are expressions X ▷Y , for all CL-terms X and Y . The
axiom-schemes and rules are the same as in Deﬁnition 6.5, but with ‘=’
changed to ‘▷’ and (σ) omitted. IﬀX ▷Y is provable in CLw, we say
CLw
⊢
X ▷Y.
Lemma 6.7
(a)
X ▷w Y
⇐⇒
CLw ⊢X ▷Y ;
(b)
X =w Y ⇐⇒
CLw ⊢X = Y .

72
Formal theories
Remark 6.8 By the Church–Rosser theorems and Lemmas 6.4 and 6.7,
the theories λβ and CLw are consistent in the sense that not all their
formulas are provable. (It is standard in logic to call a theory without
negation ‘inconsistent’ when all formulas in its language are provable.)
6B
First-order theories
This section and the next one contain some general background material
from logic and proof-theory that will be used later.
Notation 6.9 (First-order theories) Most textbooks on predicate
logic, for example [Dal97, Chapter 2], [Men97, Chapter 2] or [End00,
Chapter 2], are concerned with ﬁrst-order languages. With minor vari-
ations, such a language has three kinds of expressions: terms, built up
from atomic constants and variables by some given operations, atomic
formulas in which terms are related by some given predicates (for ex-
ample ‘=’), and composite formulas built up from atomic ones using
connectives such as ‘∧’, ‘∨’, ‘→’, ‘↔’, ‘¬’, and the quantiﬁers ‘∀’, ‘∃’.
Following [Men97, Chapter 2, Sections 3 and 8], a ﬁrst-order theory
T is a special kind of Hilbert-style formal theory. Its formulas are the
formulas of a given ﬁrst-order language.
Its axioms are divided into
two classes: proper axioms, which are peculiar to T , and logical axioms,
which are the usual axioms of classical predicate logic (including axioms
for ‘=’). The rules of T are the usual rules of predicate logic.
Remark 6.10
Neither of the equality-theories λβ and CLw is a
ﬁrst-order theory, because they contain no connectives or quantiﬁers.
However, could they be made into ﬁrst-order theories by simply adding
connectives and quantiﬁers to their languages and adding appropriate
rules?
For λβ, the answer is ‘no’, because each ‘λ’ in a λ-term binds a vari-
able, and operators that bind variables are not allowed in ﬁrst-order
terms.
But in CL-terms there are no variable-binding operators, and CLw
can easily be extended to a ﬁrst-order theory CLw +, as follows.
Deﬁnition 6.11 (The ﬁrst-order theory CLw +)
The terms of
CLw + are CL-terms. The atomic formulas are equations X = Y , and

6C Equivalence of theories
73
composite formulas are built from them using connectives and quanti-
ﬁers in the normal way. The rules of inference and logical axioms are
the usual ones for classical ﬁrst-order logic with equality (e.g.
those
in [Men97, Chapter 2, Sections 3 and 8] or [End00, Section 2.4]). The
proper axioms are the following three:
(a)
(∀x, y)

Kxy = x

,
(b)
(∀x, y, z)

Sxyz = xz(yz)

,
(c)
¬

S = K

.
Lemma 6.12 CLw+ has the same set of provable equations as CLw.
Proof By [Bar73, Theorem 2.12]. (Axiom (c) can be included in CLw +
because, by the Church–Rosser theorem, S = K is not provable in CLw.)
Note The diﬀerence between CLw + and CLw lies in their languages.
In CLw we can prove two separate equations such as II = I and IK = K;
but we cannot prove their conjunction (II = I ∧IK = K); in fact we
cannot even express it, because ‘∧’ is not in the language of CLw. In
CLw + we can prove logical combinations of equations, but, by the above
lemma, we cannot prove any more single equations than in CLw. CLw +
is said to be a ‘conservative extension’ of CLw.
6C
Equivalence of theories
Suppose we have a Hilbert-style formal theory T , and we consider ex-
tending T by adding a new rule R. It is natural to ask ﬁrst whether
R is already derivable in T .
But what exactly does ‘R is derivable’
mean? Mainstream proof-theory gives several answers to this question
(e.g. in [TS00, Deﬁnition 3.4.4]), and those that have turned out useful
in comparing λ with CL will be described here.
But ﬁrst, what does ‘a new rule R’ mean? Let F be the set of all
formulas of the language of T , and let n ≥1. Then every function φ
from a subset of F n to F determines a rule R(φ) thus: each n-tuple of
formulas ⟨A1, . . . , An⟩in the domain of φ may be called a sequence of
premises, and if φ(A1, . . . , An) = B, then B is called the corresponding

74
Formal theories
conclusion, and the expression
A1, . . . , An
B
is called an instance of the rule R(φ).
Deﬁnition 6.13 (Derivable and admissible rules) Let R be a rule
determined by a function φ from a subset of F n to F, as above. R is
said to be derivable in T iﬀ, for each instance of R, its conclusion is
deducible in T from its premises: i.e.
T , A1, . . . An
⊢
B.
R is said to be admissible in T iﬀadding R to T as a new rule will
not increase the set of theorems of T .
R is said to be correct in T iﬀ, for each instance of R, if all the
premises are provable in T then so is the conclusion; i.e. iﬀ

T ⊢A1

, . . . ,

T ⊢An

=⇒

T ⊢B

.
Finally, a single formula C, for example a proposed new axiom, is said
to be both derivable and admissible in T iﬀ
T
⊢C.
Lemma 6.14 In a Hilbert-style formal theory T , let R be a rule deter-
mined by a function φ as above.
(a) R is admissible in T iﬀR is correct in T .
(b) If R is derivable in T , it is also admissible in T .
(c) If R is derivable in T , then R is derivable in every extension of
T obtained by adding new axioms or rules.
Proof Straightforward.
Lemma 6.14(b) says, in eﬀect, that derivability is a stronger property
than admissibility. In fact it is strictly stronger, i.e. for some theories
there exist rules which are admissible but not derivable. An example
will occur in Remark 15.2, in the language of CL.
Deﬁnition 6.15 (Equivalence of theories) Let T and T ′ be Hilbert-
style formal theories with the same set of formulas. We shall call T and
T ′ theorem-equivalent iﬀevery rule and axiom of T is admissible in

6C Equivalence of theories
75
T ′ and vice versa, and rule-equivalent iﬀevery rule and axiom of T is
derivable in T ′ and vice versa.
Clearly, theorem-equivalence is weaker than rule-equivalence.
The
following easy lemma shows why it is called ‘theorem-equivalence’.
Lemma 6.16 Let T and T ′ be Hilbert-style formal theories with the
same set of formulas. Then T and T ′ are theorem-equivalent iﬀthey
have the same set of theorems.
Deﬁnition 6.17
Let T be a Hilbert-style formal theory whose set of
formulas includes some equations X = Y , where X and Y are terms
according to some deﬁnition. The equality relation determined by T is
called =T and is deﬁned by
X =T Y
⇐⇒
T
⊢X = Y.
Lemma 6.18 Let T and T ′ be Hilbert-style formal theories with the
same set of formulas, and let this set include some equations. If T and
T ′ are theorem-equivalent, then they both determine the same equality-
relation.
A more detailed treatment of derivability, admissability and correct-
ness of rules can be found in the thesis [Gra05, Section 4.2.4].

7
Extensionality in λ-calculus
7A
Extensional equality
The concept of function-equality used in most of mathematics is what is
called ‘extensional’; that is, it includes the assumption that for functions
φ and ψ with the same domain,
(∀x)

φ(x) = ψ(x)

=⇒
φ = ψ.
In contrast, in computing, the main subjects are programs, whose
equality is ‘intensional’; i.e. if two programs compute the same math-
ematical function, we do not say they are the same program. (One of
them may be more eﬃcient than the other.)
The theory λβ is also intensional: there exist two terms F and G such
that
λβ
⊢
FX = GX
(for all terms X),
but not λβ ⊢F = G. For example, take any variable y and choose
F ≡y,
G ≡λx.yx.
This chapter is about adding an extensionality rule to the theory λβ.
In the next chapter we shall do the same for CL.
The discussion of extensionality will help to clarify the relationship
between λ and CL, and this relationship will be examined in Chapter 9.
Notation 7.1
In this chapter, ‘term’ means ‘λ-term’. Recall that a
closed term is one without free variables. Recall also the formal theory
λβ of β-equality, Deﬁnition 6.2.
The following two rules and one axiom-scheme have been proposed at
various times to express the concept of extensionality in λ-calculus.
76

7A Extensional equality
77
(ζ)
Mx = Nx
M = N
if x ̸∈FV(MN);
(ext)
MP = NP
for all terms P
M = N
;
(η)
λx.Mx = M
if x ̸∈FV(M).
Rule (ζ) says, roughly speaking, that if M and N have the same eﬀect
on an unspeciﬁed object x, then M = N.
Rule (ext) has an inﬁnite number of premises, namely a premise MP =
NP for each term P, so deductions involving this rule are inﬁnite trees.
Such deductions are beyond the scope of this book, but it can be shown
that the theory obtained by adding (ext) to λβ is theorem-equivalent to
that obtained by adding (ζ). So nothing would be gained by studying
(ext) instead of (ζ), and we shall ignore (ext) from now on.
Axiom-scheme (η) is of course simpler than any rule, and the idea of
expressing extensionality by a single axiom-scheme is very attractive. In
fact, Theorem 7.4 will show that (η) is just as strong as (ζ) and (ext).
(By the way, in (η) the notation ‘λx.Mx’ means, as always, ‘λx.(Mx)’
not ‘(λx.M)x’.)
Deﬁnition 7.2 Let λβ be the theory of equality in Deﬁnition 6.2; we
deﬁne two new formal theories of equality:
λβζ :
add rule (ζ) to λβ;
λβη :
add axiom-scheme (η) to λβ.
(Adding (η) means adding all equations λx.Mx = M as new axioms,
for all terms M and all x ̸∈FV(M).)
Remark 7.3 (Rule (ω))
In 1950, Paul Rosenbloom suggested the
following variant of rule (ext) [Ros50, Chapter 3, rule E5]:
(ω)
MQ = NQ for all closed terms Q
M = N.
Rule (ω) is stronger than rules (ext) and (ζ), in the sense that (ext)
and (ζ) are easily derivable from (ω) but (ω) is not derivable, nor even
admissible, in the theory λβζ. (The non-admissibility of (ω) was proved
by Gordon Plotkin in [Plo74]; he constructed terms M and N such that

78
Extensionality in λ-calculus
MQ = NQ was provable in λβζ (even in λβ) for all closed Q, yet λβζ
̸ ⊢M = N.)
Rule (ω) has been discussed in detail in [Bar84, Sections 17.3, 17.4],
and a little in [HL80, Sections 5ﬀ.]; it will not be studied further here.
Theorem 7.4
The theories λβζ and λβη are rule-equivalent in the
sense of Deﬁnition 6.15, and hence also theorem-equivalent. Thus both
theories determine the same equality-relation.
Proof
First, rule (ζ) is derivable in the theory λβη. Because, from a
premise Mx = Nx with x ̸∈FV(MN), we can deduce λx.Mx = λx.Nx
by rule (ξ) in 6.2, and hence, by (η) twice,
M = λx.Mx = λx.Nx = N.
Conversely, every (η)-axiom λx.Mx = M (with x ̸∈FV(M)) is prov-
able in λβζ; because the equation
(λx.Mx)x = Mx
is provable by (β) in 6.2, and λx.Mx = M follows by (ζ).
Deﬁnition 7.5 (Extensional (βη) equality in λ)
The equality
determined by the theories λβζ and λβη will be called =ext or =βη (or
=λext or =λβη if confusion with CL needs to be avoided); i.e. we deﬁne
M =ext N
⇐⇒
λβζ
⊢M = N,
M =βη N
⇐⇒
λβη
⊢M = N.
By Theorem 7.4,
M =ext N
⇐⇒M =βη N, so ‘=ext’ and ‘=βη’
both denote the same relation, and we can use whichever notation we
like for it. The main tool for proving results about this relation is the
reduction to be described in the next section.
Exercise 7.6 ∗
The theory λβζ includes all the rules of λβ in Deﬁ-
nition 6.2, in particular rule (ξ). Let λβ−ξ+ζ be the theory of equality
obtained by deleting (ξ) from λβ and adding (ζ) instead. Prove that
λβ−ξ+ζ is rule-equivalent to λβζ. Thus, roughly speaking, (ζ) renders
(ξ) redundant.

7B βη-reduction
79
7B
βη-reduction in λ-calculus
Deﬁnition 7.7 (η-reduction)
An η-redex is any λ-term
λx.Mx
with x ̸∈FV(M). Its contractum is
M.
The phrases ‘P η-contracts to Q’ and ‘P η-reduces to Q’ are deﬁned by
replacing η-redexes by their contracta, like ‘β-contracts’ and ‘β-reduces’
in Deﬁnition 1.24, with notation
P ▷1η Q,
P ▷η Q.
Deﬁnition 7.8 (βη-reduction) A βη-redex is a β-redex or an η-redex.
The phrases ‘P βη-contracts to Q’ and ‘P βη-reduces to Q’ are deﬁned
like ‘β-contracts’ and ‘β-reduces’ in Deﬁnition 1.24, with notation
P ▷1βη Q,
P ▷βη Q.
Deﬁnition 7.9 (βη-normal forms)
(Same as Deﬁnition 3.7) A λ-
term Q containing no βη-redexes is said to be in βη-normal form (or
βη-nf ), and we say such a term Q is a βη-normal form of P iﬀP ▷βη Q.
Deﬁnition 7.10 (The formal theory λβη of βη-reduction)
This
is deﬁned by adding to the theory of β-reduction in Deﬁnition 6.3 the
axiom-scheme
(η)
λx.Mx ▷M
(if x ̸∈FV(M)).
Lemma 7.11 For all P, Q:
P ▷βη Q
⇐⇒
λβη ⊢P ▷Q.
Lemma 7.12
(a)
P ▷βη Q
=⇒
FV(P) ⊇FV(Q);
(b)
P ▷βη Q
=⇒
[P/x]M ▷βη [Q/x]M;
(c)
P ▷βη Q
=⇒
[N/x]P ▷βη [N/x]Q.
Proof For β-steps, use 1.30 and 1.31. For an η-step λy.Hy ▷1η H with
y ̸∈FV(H), we have FV(λy.Hy) = FV(H), giving (a). Also, if λy.Hy
is an η-redex, so is [N/x](λy.Hy), giving (c). Part (b) is easy.

80
Extensionality in λ-calculus
Theorem 7.13 (Church–Rosser theorem for ▷βη) If P ▷βη M and
P ▷βη N, then there exists a λ-term T such that
M ▷βη T
and
N ▷βη T.
Proof See Appendix A2, Theorem A2.12.
Corollary 7.13.1 If P has a βη-normal form, it is unique modulo ≡α.
Proof Like Corollary 1.32.1.
Theorem 7.14 A λ-term has a βη-normal form iﬀit has a β-normal
form.
Proof First, if P ▷β N and N is a β-nf, we can change N to a βη-nf by
simply η-reducing N. (By checking cases, it can be proved that an η-
contraction cannot create new β-redexes in a term. Also an η-reduction
cannot continue for ever, because η-contractions make terms shorter.)
The converse part of the theorem looks easy, but actually is not; for a
proof of it, see [CHS72, Section 11E, Lemma 13.1], [Bar84, Section 15.1]
or [Tak95, end of Section 3].
Theorem 7.15 (η-postponement)
In a βη-reduction, all the η-
contractions can be postponed to the end; i.e. if M ▷βη N then there
exists a P such that
M ▷β P ▷η N.
Proof [Bar84, Corollary 15.1.6] or [Tak95, Theorem 3.5].
The following theorem connects ▷βη with extensional equality.
Theorem 7.16 For all λ-terms P and Q: P =ext Q iﬀQ can be obtained
from P by a ﬁnite (perhaps empty) series of βη-contractions and reversed
βη-contractions and changes of bound variables.
Proof Straightforward, using 7.4.
Corollary 7.16.1 (Church–Rosser theorem for =ext) If P =βη Q,
then there exists a λ-term T such that
M ▷βη T
and
N ▷βη T.

7B βη-reduction
81
Proof By 7.13 and 7.16, like the proof of 1.41.
Corollary 7.16.2 (Consistency of =βη) There exist λ-terms M and
N such that M ̸=βη N.
Corollary 7.16.3 (Uniqueness of nf) A λ-term is extensionally equal
to at most one βη-nf, modulo changes of bound variables.
Remark 7.17
The above results show that ▷βη is very well behaved,
almost as easy to use as ▷β. In fact, it is a bit surprising that we have
managed to add extensionality to λ with so little eﬀort. However, in
the deeper theory of reductions, ▷βη gets signiﬁcantly more diﬃcult; for
example, although there is an analogue of the quasi-leftmost-reduction
theorem for ▷βη, its proof is much harder than for ▷β [Klo80, Chapter
IV, Corollary 5.13].
Also, it is not certain that (ζ), (ext), (η), (ω) or any other rule in
pure λ can describe the concept of extensionality exactly.
(We have
highlighted (ζ) and (η) here because they are fairly easy to work with
and the reader might meet them in the literature.) Another approach to
extensionality will be made in Chapter 14 and the two approaches will
be compared in Remark 14.25.

8
Extensionality in
combinatory logic
8A
Extensional equality
In this chapter we shall look at axioms and rules to add to weak equality
in CL to make it extensional.
Notation 8.1 ‘Term’ means ‘CL-term’ in this chapter. We shall study
here the following two rules and one axiom-scheme:
(ζ)
Xx = Y x
X = Y
if x ̸∈FV(XY );
(ξ)
X = Y
[x].X = [x].Y ;
(η)
[x].Ux = U
if x ̸∈FV(U).
The ﬁrst rule, (ζ), is the same as in the λ-calculus. But the other two,
(ξ) and (η), will turn out to have a diﬀerent status in CL from that in λ.
Deﬁnition 8.2 Let CLw be the theory of weak equality, Deﬁnition 6.5;
we deﬁne two new formal theories of equality:
CLζ :
add rule (ζ) to CLw;
CLξ :
add rule (ξ) to CLw.
Exercise 8.3∗Prove that neither (ζ) nor (ξ) is admissible in the theory
CLw. Hence both the theories CLζ and CLξ contain provable equations
that are not provable for weak equality.
Remark 8.4 The following rule could also be studied:
82

8A Extensional equality
83
(ext)
XZ = Y Z for all terms Z
X = Y
;
but it gives the same set of provable equations as (ζ), although the proof
of that fact is beyond the scope of this book.1
We shall give the name ‘extensional equality’ to the equality deter-
mined by rule (ζ), just as we did in λ-calculus.
Deﬁnition 8.5 (Extensional equality in CL) The relation =ext (or
=Cext when confusion with λ needs to be avoided)2 is deﬁned thus:
X =ext Y
⇐⇒
CLζ ⊢X = Y.
Example 8.6
(a)
SK =ext KI.
This is proved by applying rule (ζ) twice to the weak equation
SKxy =w KIxy, which is proved thus:
SKxy
=w
Ky(xy)
by axiom-scheme (S) in 6.5,
=w
y
by (K) in 6.5,
=w
Iy
by (I) and rule (σ),
=w
KIxy
by (K) and rules (σ), (µ).
(b)
S(KX)(KY ) =ext K(XY )
for all terms X, Y .
To prove this, choose v ̸∈FV(XY ) and apply (ζ) to the weak
equation S(KX)(KY )v =w K(XY )v, which comes thus:
S(KX)(KY )v
=w
KXv(KY v)
by (S) in 6.5,
=w
XY
by (K) twice and (µ), (ν),
=w
K(XY )v
by (K) and (σ).
1 It was set as an exercise in [HS86, p. 79], but to prove (ζ) admissible in CLw+(ext),
one must ﬁrst prove that deductions in CLw+(ext) remain correct deductions after
simultaneous substitutions, and this is not trivial (since such deductions may be
inﬁnite). In λ this complication is avoided by using rule (ξ), which is not available
in CLw+(ext).
2 This relation is often called =β η in the literature, by supposed analogy with λ-
calculus, but that notation is misleading; we shall see below that the meaning of
(η) in CL diﬀers from that in λ.

84
Extensionality in CL
(c)
S(KX)I =ext X
for all terms X.
This is proved by applying (ζ) to the following, for v ̸∈FV(X):
S(KX)Iv
=w
KXv(Iv)
by (S) in 6.5,
=w
Xv
by (K), (I), (µ), (ν).
Remark 8.7 (The rˆoles of (ξ) and (η)) In CL, (η) says [x].Ux = U
if x ̸∈FV(U).
In λ, we saw that (η) acted as an extensionality-principle equivalent to
(ζ). But in the proof of that fact (Theorem 7.4), the step from (η) to (ζ)
used rule (ξ) as well as (η). This passed without comment in λ-calculus,
where (ξ) is a permanent underlying assumption for equality.
But in CL, the deﬁnition of =w does not include (ξ), and (η) by itself
is not an extensionality principle at all. Indeed, (η) holds in CL as an
identity:
[x].Ux ≡U
if x ̸∈FV(U)
(by Deﬁnition 2.18(c)), but despite this, =w is not extensional, as we
saw in Exercise 8.3. All we can get from (η) in CL is that every term is
equal to an abstraction: U = [x].Ux.
However, if we extended the theory CLw by adding rule (ξ), the
strengthened theory CLξ would be extensional by the argument in the
proof of Theorem 7.4.
In CL, (ξ) can be regarded as a weak form of extensionality principle
that asserts
Xx = Y x
⊢
X = Y
whenever X and Y are abstractions. (Because, if X ≡[x].V and Y ≡
[x].W, then Xx =w V and Y x =w W, so from Xx = Y x we could
deduce V = W in CLw, and then (ξ) would imply X = Y .)
Roughly speaking, (ξ) says that extensionality holds for abstractions,
while (η) says that all terms are equal to abstractions, so the two together
give extensionality for all terms.
Theorem 8.8 The theory CLξ determines the same equality-relation
=ext as CLζ does.
Proof It is enough to prove CLξ theorem-equivalent to CLζ. We shall
actually prove rule-equivalence.

8B Extensionality axioms
85
First we derive (ζ) in the theory CLξ (see 8.7 and 7.4). Given an
equation Xx = Y x with x ̸∈FV(XY ), apply (ξ) to give
[x].Xx = [x].Y x,
and this is X = Y by the deﬁnition of [x]-abstraction, 2.18(c).
Next we derive (ξ) in CLζ. Given X = Y , deduce
([x].X)x
=
X
by 2.21
=
Y
given
=
([x].Y )x
by 2.21;
then [x].X = [x].Y follows by (ζ).
Remark 8.9 In some accounts of CL, abstraction is deﬁned by clauses
(a), (b) and (f) of Deﬁnition 2.18 without clause (c); see for example
[Bar84, Deﬁnition 7.1.5]. For this deﬁnition of abstraction, the above
proof would fail and the corresponding theory CLξ would determine an
equality weaker than =ext, as shown in [BHS89]. (To get =ext we would
have to add (η) as well as (ξ), just as in λ-calculus.)
8B
Axioms for extensionality in CL
We now have two ways of ‘strengthening’ weak equality to make exten-
sional equality: via CLζ or via CLξ. But unfortunately neither of these
theories is very easy to work with.
However, as far back as the 1920s, Curry discovered a simpler theory.
He found that the same eﬀect as rule (ζ) could be obtained by adding
just a ﬁnite set of axioms to the theory of weak equality, [Cur30, p. 832
Satz 4]. Each axiom was an equation A = B where A and B were closed
terms. These terms were rather long, but it is still interesting that a
rule such as (ζ) can be replaced by just a small set of equations.
(By the way, in the last chapter we seemed to do better than that,
replacing (ζ) by just one equation (η); but in fact (η) was an axiom-
scheme not an axiom, and represented an inﬁnite number of axioms,
one for each choice of M, x. In the present section the total number of
axioms, not just of axiom-schemes, will be ﬁnite.)
The axioms to be given here will be taken from [CF58, p. 203, the
set ωη] with some modiﬁcations.
There is a diﬀerent set in [Bar84,

86
Extensionality in CL
Corollary 7.3.15, the set Aβη], and several axiomatizations are compared
in [CHS72, Section 11D].
Deﬁnition 8.10 (Extensionality axioms)
The theory CLextax is
deﬁned by adding to CLw (Deﬁnition 6.5) the following ﬁve axioms:
E-ax 1:
S (S (KS) (S(KK)(S(KS)K))) (KK) = S(KK);
E-ax 2:
S (S(KS)K) (KI) = I;
E-ax 3:
S(KI) = I;
E-ax 4:
S(KS)(S(KK)) = K;
E-ax 5:
S (K(S(KS))) (S(KS)(S(KS))) =
S (S (KS) (S(KK)(S(KS)(S(K(S(KS)))S)))) (KS).
Note 8.11
These mysterious axioms can be made very slightly less
mysterious by expressing them thus:
E-ax 1: [x, y, v].(Kxv)(Kyv) = [x, y, v].xy,
or [x, y].S(Kx)(Ky) = [x, y].K(xy);
E-ax 2: [x, v].(Kxv)(Iv) = [x, v].xv,
or [x].S(Kx)I = [x].x;
E-ax 3: [x, v].I(xv) = [x, v].xv,
or [x].S(KI)x = [x].x;
E-ax 4: [x, y, v].K(xv)(yv) = [x, y, v].xv,
or [x, y].S(S(KK)x)y = [x, y].x;
E-ax 5: [x, y, z, v].S(xv)(yv)(zv) = [x, y, z, v].xv(zv)(yv(zv)),
or [x, y, z].S(S(S(KS)x)y)z =
[x, y, z].S(Sxz)(Syz).
Discussion 8.12 But how on earth can the above axioms be connected
with extensionality?
Well, to add extensionality to CLw, it is enough to ﬁnd axioms which
make CLextax theorem-equivalent to CLζ or CLξ. We choose CLξ. So
we must ﬁnd axioms which will make rule (ξ) admissible in CLextax;
that is, which will give
CLextax ⊢X = Y
=⇒
CLextax ⊢[v].X = [v].Y
(1)

8B Extensionality axioms
87
for all variables v.
In particular, for the special case that the equation X = Y is an axiom
from (I), (K) or (S) in Deﬁnition 6.5, the new axioms must be strong
enough to give, for all U, V , W, v,
CLextax ⊢
[v].IU = [v].U,
CLextax ⊢
[v].KUV
= [v].U,
CLextax ⊢
[v].SUV W = [v].UW(V W).
The proof of the next theorem will show that E-axs 3–5 do this job.
Before that theorem, a lemma will show the use of E-axs 1–2.
Lemma 8.13 For all X, Y , v:
CLextax
⊢
[v].XY
= S([v].X)([v].Y ).
Proof By the deﬁnition of [v] in 2.18, the desired equation is already an
identity, unless either (a) v ̸∈FV(XY ), or (c) v ̸∈FV(X) and Y ≡v.
The purpose of E-axs 1–2 is to deal with these two exceptional cases, as
follows.
Case (a): [v].XY ≡
K(XY )
by 2.18(a)
=w ([x, y].K(xy))XY
by 2.27
=
([x, y].S(Kx)(Ky))XY by E-ax 1 as in 8.11
=w S(KX)(KY )
by 2.27
≡
S([v].X)([v].Y )
by 2.18(a).
Case (c): [v].XY ≡X
by 2.18(c) ( Y ≡v ̸∈FV(X) )
= S(KX)I
by 2.27 and E-ax 2 as in 8.11
≡S([v].X)([v].v) by 2.18(a), (b).
Theorem 8.14 The theory CLextax is theorem-equivalent to the theo-
ries CLζ and CLξ, and hence determines the same equality-relation as
they do, namely =ext.
Proof
It is enough to prove CLextax theorem-equivalent to CLξ, i.e.
every equation provable in one is provable in the other.
First, every equation provable in CLextax is provable in CLξ. In fact
each of E-axs 1 – 5 can easily be proved in CLξ, using 8.11, and the

88
Extensionality in CL
other axioms and rules of CLextax are just those of CLw, which are also
in CLξ.
For the converse, we must prove rule (ξ) admissible in CLextax; that
is, we must show that if an equation X = Y is provable in CLextax by a
proof with, say, n steps, then [v].X = [v].Y is also provable in CLextax
for every v. This we shall do by induction on n. Recall the axioms and
rules of CLextax (given in 8.10), which include those of CLw (in 6.5).
If n = 1, the equation X = Y is an axiom of CLextax. If it is one of
E-axs 1–5, then no variables occur in XY , so in CLextax we have
[v].X
≡
KX
by 2.18(a),
=
KY
by rule (µ) in CLw (see 6.5),
≡
[v].Y
by 2.18(a).
The other axioms of CLextax are instances of axiom-schemes (I), (K),
(S), (ρ) in 6.5. Suppose X = Y is an instance of (K). Then X ≡KUV
and Y ≡U for some U and V , and we must prove [v].KUV = [v].U in
CLextax. This is done as follows.
[v].KUV
=
S (S(KK)([v].U)) ([v].V )
using 8.13
=
([x, y].S(S(KK)x)y) ([v].U) ([v].V )
by 2.27
=
([x, y].x)([v].U)([v].V )
by E-ax 4 in 8.11
=
[v].U
by 2.27.
The cases of (I) and (S) are similar. The case of (ρ) is trivial.
For the induction step, suppose n ≥2 and the equation X = Y is
the conclusion of rule (µ), (ν), (τ) or (σ) in 6.5. If the rule is (µ), then
X ≡ZU and Y ≡ZV for some Z, U, V , and there is an n −1 -step
proof that
CLextax
⊢
U = V.
The induction-hypothesis is that
CLextax
⊢
[v].U = [v].V.
From this, in CLextax we can prove
[v].X
=
S([v].Z)([v].U)
by 8.13
=
S([v].Z)([v].V )
by induc. hyp. and rule (µ)
=
[v].Y
by 8.13.
Rule (ν) is handled like (µ). Rules (τ) and (σ) are easy.

8C Strong reduction
89
Warning The above proof has shown only that rule (ξ) is admissible in
the theory CLextax, not that it is derivable (see Deﬁnition 6.13). That
is, we have proved
CLextax ⊢X = Y
=⇒
CLextax ⊢[v].X = [v].Y,
but not that the equation [v].X = [v].Y can be deduced from X = Y
in CLextax for all X, Y and v. Such a strong statement is not needed
in proving the above theorem.
8C
Strong reduction
Corresponding to =ext in λ-calculus in the last chapter there was a
reduction ▷βη with useful properties, such as conﬂuence and an easily-
decidable set of normal forms, so it is natural to try to deﬁne a reduction
here for =ext in CL.
Deﬁnition 8.15 (Strong reduction,
>−)
The formal theory of
strong reduction has as formulas all expressions X >−Y , for all CL-
terms X and Y . Its axiom-schemes and rules are the same as those for
CLw in Deﬁnition 6.5, but with ‘=’ changed to ‘ >−’, rule (σ) omitted,
and the following new rule added:
(ξ)
X >−Y
[x].X >−[x].Y .
IﬀX >−Y is provable in this theory, we say X strongly reduces to Y ,
or just
X >−Y.
Example 8.16
(a) SK >−KI.
To prove this, ﬁrst note that SKxy ▷w Ky(xy) ▷w y. Since the
axiom-schemes and rules for >−include those for ▷w, this gives
SKxy >−y.
Hence, by rule (ξ) twice,
[x, y].SKxy >−[x, y].y.
But [x, y].SKxy ≡SK and [x, y].y ≡KI.

90
Extensionality in CL
(b) S(KX)(KY ) >−K(XY ).
To prove this for all terms X, Y , choose v ̸∈FV(XY ); then
S(KX)(KY ) ≡[v].(KXv)(KY v),
K(XY ) ≡[v].XY.
Also (KXv)(KY v) ▷w
XY , so by (ξ),
[v].(KXv)(KY v) >−[v].XY.
(c) S(KX)I >−X.
To prove this for all terms X, choose v ̸∈FV(X); then
S(KX)I ≡[v].(KXv)(Iv),
X ≡[v].Xv.
Also (KXv)(Iv) ▷w Xv, so by (ξ),
[v].(KXv)(Iv) >−[v].Xv.
(d) For each of E-axs 1–5 in Deﬁnition 8.10, the left side strongly re-
duces to the right side. In fact, each of these axioms was obtained
by applying (ξ) to a weak reduction, as shown in 8.11.
Lemma 8.17 The relation >−is transitive and reﬂexive. Also
(a)
X >−Y
=⇒FV(X) ⊇FV(Y );
(b)
X >−Y
=⇒[X/v]Z >−[Y/v]Z;
(c)
X >−Y
=⇒[U1/x1, . . . , Un/xn]X >−[U1/x1, . . . , Un/xn]Y ;
(d) the equivalence relation generated by >−is the same as =ext;
that is, X =ext Y iﬀX goes to Y by a ﬁnite series of strong
reductions and reversed strong reductions.
Proof Straightforward.
Theorem 8.18 (Church–Rosser theorem for >−) The relation >−
is conﬂuent; i.e. if U >−X and U >−Y , there exists Z such that
X >−Z
and
Y >−Z.
Proof
See Exercise 9.19(a). (That exercise deduces the conﬂuence of
>−from that of ▷β via a translation between CL and λ. The authors
do not know of a proof that is independent of λ.)
Deﬁnition 8.19 X is called strongly irreducible iﬀ, for all Y ,
X >−Y
=⇒
Y
≡X.

8C Strong reduction
91
Theorem 8.20 The strongly irreducible CL-terms are exactly the terms
in the class strong nf deﬁned thus (from 3.8 and like 1.33):
(a) all atoms other than I, K and S are in strong nf;
(b) if X1, . . . , Xn are in strong nf, and a is any atom ̸≡I, K, S, then
aX1 . . . Xn is in strong nf;
(c) if X is in strong nf, then so is [x].X.
Proof [Ler67b].
Deﬁnition 8.21
X has a strong nf X⋆iﬀX⋆is a strong nf and
X >−X⋆.
Lemma 8.22 (a) A CL-term cannot have more than one strong nf.
(b) If X⋆is a strong nf and U =ext X⋆, then U >−X⋆.
(c) X⋆is the strong nf of X iﬀX⋆is a strong nf and X =ext X⋆.
Proof By 8.18 and 8.20.
A few more facts about strong nfs will be given in Exercise 9.19.
Remark 8.23
By the way, why do we not simplify the basis of CL
by deﬁning I ≡SKK? (See Exercise 2.16.) One reason is that, if this
was done, Theorem 8.20 would fail. I would still be in strong nf since
I ≡[x].x, but I would become (inﬁnitely) reducible, since
I ≡SKK
>−
KIK
since SK >−KI by 8.16(a)
>−
K(KIK)K
etc.
Remark 8.24
So far, strong reduction is behaving reasonably well.
However, the proof that the irreducibles are exactly the normal forms is
by no means easy, and it is a bit worrying that no λ-independent proof
of conﬂuence is known. In fact, further properties of >−turn out to
be just as messy to prove as those of ▷βη in λ, perhaps more so, and, as
a result, >−has attracted very little interest.
However, some signiﬁcant properties were proved in the 1960s. A clear
short account was given in [HLS72, Chapter 7], and a more detailed one
in [CHS72, Section 11E]. The latter contains a standardization theo-
rem. Also rule (ξ) for >−can be replaced by axioms (an inﬁnite but
recursively decidable set), and this can be used to simplify the charac-
terization proof for the irreducibles [Hin67, Ler67a, HL70].

9
Correspondence between λ and CL
9A
Introduction
Everything done so far has emphasized the close correspondence between
λ and CL, in both motivation and results, but only now do we have the
tools to describe this correspondence precisely. This is the aim of the
present chapter.
The correspondence between the ‘extensional’ equalities will be de-
scribed ﬁrst, in Section 9B.
The non-extensional equalities are less straightforward. We have =β in
λ-calculus and =w in combinatory logic, and despite their many parallel
properties, these diﬀer crucially in that rule (ξ) is admissible in the
theory λβ but not in CLw.
To get a close correspondence, we must
deﬁne a new relation in CL to be like β-equality, and a new relation in λ
to be like weak equality. The former will be done in Section 9D below.
(An account of the latter can be found in [C¸H98].)
Notation 9.1 This chapter is about both λ- and CL-terms, so ‘term’
will never be used without ‘λ-’ or ‘CL-’.
For λ-terms we shall ignore changes of bound variables, and ‘M ≡α
N’ will be written as ‘M ≡N’. (So, in eﬀect, the word ‘λ-term’ will
mean ‘α-convertibility class of λ-terms’, i.e. the class of all λ-terms α-
convertible to a given one.)
Deﬁne
Λ
=
the class of all (α-convertibility classes of) λ-terms,
C
=
the class of all CL-terms.
We shall assume that the variables in C are the same as those in Λ.
For CL-terms, in this chapter the [x].M of Deﬁnition 2.18 will be
92

9A Introduction
93
called ‘[x]η .M’, to distinguish it from a modiﬁed deﬁnition of abstraction
to be described later in the chapter.
The letters ‘I’, ‘K’ and ‘S’ will denote only the atomic combinators of
CL, not anything in λ.
Recall the four main equality relations deﬁned earlier; two in λ:
=β
(determined by the theory λβ in 6.2),
=λext or =λβη (determined by λβζ or λβη in 7.2),
and two in CL:
=w
(determined by the theory CLw in 6.5),
=Cext (determined by any of CLζ, CLξ, CLextax in 8.2, 8.10).
The following very natural mapping is the basis of the correspondence
between λ and CL.
Deﬁnition 9.2 (The λ-mapping) With each CL-term X we associate
a λ-term Xλ called its λ-transform, by induction on X, thus:
(a)
xλ
≡x,
(b)
Iλ
≡λx.x,
Kλ ≡λxy.x,
Sλ ≡λxyz.xz(yz),
(c)
(XY )λ ≡XλYλ.
Note 9.3
Clearly Xλ is uniquely deﬁned (modulo changes of bound
variables). Also X ̸≡Y implies Xλ ̸≡Yλ, so the λ-mapping is one-to-
one. It maps C onto a subclass of Λ, which will be called Cλ:
Cλ =

Xλ : X ∈C

.
The class Cλ is not the whole of Λ; for example, it is easy to see that the
λ-term λx.y is not the λ-transform of any CL-term.
Lemma 9.4 For all CL-terms X, Z and variables v:
(a)
FV(Xλ) = FV(X);
(b)
([Z/v]X)λ ≡[Zλ/v](Xλ).
Proof Part (a) is easy, and (b) is proved by induction on X.
Lemma 9.5 For all CL-terms X and Y :
(a)
X ▷w Y
=⇒
Xλ ▷β Yλ;

94
Correspondence between λ and CL
(b)
X =w Y
=⇒
Xλ =β Yλ;
(c)
X =Cext Y
=⇒
Xλ =λext Yλ;
Proof
Part (a) is proved by induction on the axioms and rules of the
theory CLw in 6.5, 6.6. Cases (ρ), (µ), (ν), (τ) are trivial, because these
rules are also valid for ▷β. The other cases are (S), (K), (I), as follows.
Case (S): (SXY Z)λ ≡(λxyz.xz(yz)) XλYλZλ
▷β XλZλ(YλZλ)
≡(XZ(Y Z))λ.
Case (K): (KXY )λ
≡
(λxy.x) XλYλ
▷β
Xλ.
Case (I):
(IX)λ
≡
(λx.x) Xλ
▷β
Xλ.
For (b), the proof is similar. Finally, (c) comes by induction on the rules
of the theory CLζ deﬁned in 8.2.
The following terms in CL play a rˆole rather like abstractions λx.M.
Deﬁnition 9.6 (Functional CL-terms) A CL-term with one of the
six forms SXY (for some X, Y ), SX, KX, S, K, I, is called functional
or fnl.
Lemma 9.7 For all functional CL-terms U:
(a)
Uλ ▷β λx.M
for some λ-term M;
(b)
U ▷w V
=⇒V is functional.
Lemma 9.8 A CL-term X is weakly equal to a functional term iﬀXλ
is β-equal to an abstraction-term (i.e. a λ-term of form λx.M).
Proof
First, let X =w U and U be fnl. Then, by 2.32, X ▷w V and
U ▷w V for some V . By 9.7(b), V is fnl. Hence, by 9.7(a), Vλ ▷β λx.M
for some M. But Xλ ▷β Vλ by 9.5(a), so Xλ ▷β λx.M.
For the converse, see Exercise 9.28.

9B The extensional equalities
95
9B
The extensional equalities
Remark 9.9 Via the λ-mapping, the extensional equality relation =λext
in λ-calculus induces the following relation between CL-terms:
X =ext-induced Y
⇐⇒
Xλ =λext Yλ.
The main aim of the present section is to prove that this induced relation
is the same as the relation =Cext deﬁned in 8.5, i.e. to prove
X =Cext Y
⇐⇒
Xλ =λext Yλ.
Our principal tool is the following mapping from Λ to C.
Deﬁnition 9.10 (The Hη-mapping) With each λ-term M we asso-
ciate a CL-term called MHη (or just MH when no confusion is likely),
thus:
(a)
xHη
≡x,
(b)
(MN)Hη
≡MHη NHη ,
(c)
(λx.M)Hη ≡
[x]η .(MHη ).
(‘[x]η’ is the ‘[x]’ deﬁned in 2.18.)
Lemma 9.11 For all CL-terms X:

Xλ

Hη
≡X.
Proof
Induction on X. The cases X ≡x, X ≡Y Z are trivial. The
other cases are X ≡S, K or I, and for these we have:
Sλ H
≡

λxyz.xz(yz)

H
≡
[x, y, z]η .xz(yz)
≡S
by 2.25(b);
Kλ H
≡

λxy.x

H
≡
[x, y]η .x
≡K by 2.25(a);
Iλ H
≡

λx.x

H
≡
[x]η .x
≡I
by 2.18(b).
Remark 9.12 Lemma 9.11 says the Hη-mapping reverses the eﬀect of
the λ-mapping; it is called a left inverse of the λ-mapping.
If we also had (MHη )λ ≡M for all λ-terms M, then Hη would be the

96
Correspondence between λ and CL
C
Cλ
Λ



9










Hη -map
-
λ-map

Hη -map
-
λ-map

Hη -map
X
X
X
y
X
X
X
X
X
X
X
X
X
X
Hη -map
ppppp
pppppppp
ppppppppp
pppppppppp
pppppppppp
pppppppppp
ppppppppppp
pppppppppppp
ppppppppppppp
pppppppppppp
ppppppppppppp
pp
ppp
ppp
ppp
pp
ppp
ppp
ppp
pp
ppp
ppp
ppp
pp
ppp
ppppppppppppp
pppppppppppp
ppppppppppppp
pppppppppppp
ppppppppppp
ppppppppppp
pppppppppp
pppppppppp
pppppppp
ppppppp
ppppp
ppppp
pppppppp
ppppppppp
pppppppppp
pppppppppp
ppppppppppp
ppppppppppp
pppppppppppp
ppppppppppppp
pppppppppppp
ppppppppppppp
pppppppp
pppppppp
pppppppppppp
ppppppppppppp
pppppppppppp
ppppppppppp
ppppppppppp
pppppppppp
pppppppppp
ppppppppp
ppppppp
ppppp
Fig. 9:1
(two-sided) inverse of the λ-mapping. But we do not have this, since,
for example,

(λu.vu)Hη

λ ≡

[u].vu

λ ≡vλ ≡v,
and v ̸≡λu.vu.
The λ-mapping takes C to Cλ ⊂Λ; see Figure 9:1. In Note 9.3 we
saw that this mapping is one-to-one but its range is not the whole of Λ.
On the other hand, by Lemma 9.11 the range of the Hη-mapping is the
whole of C.
It is easy to see that the Hη-mapping is not one-to-one. But when
the domain of this mapping is restricted to Cλ, it becomes one-to-one,
and this restricted Hη-mapping becomes the two-sided inverse of the
λ-mapping. (Because, for every M ∈Cλ we have M ≡Xλ for an X ∈C,
and hence

MHη

λ ≡

(Xλ)Hη

λ
≡Xλ
by Lemma 9.11
≡M.)
The next two lemmas will be needed in proving that =Cext corresponds
to =λext. In Lemma 9.13, part (b) is a special case of (d), but (b) must
be proved before (d) can be proved.
Lemma 9.13 For all λ-terms M and N:
(a)
FV(MHη ) = FV(M);
(b)

[y/x]M

Hη
≡[y/x]

MHη

if y does not occur in M;

9B The extensional equalities
97
(c)
M ≡α N
=⇒
MHη ≡NHη ;
(d)

[N/x]M

Hη
≡[NHη /x]

MHη

.
Proof Parts (a) and (b) come by straightforward inductions on M.
For (c): it is enough to prove that (λx.M)Hη ≡(λy.[y/x]M)Hη if y
̸∈FV(M). This is done as follows.

λx.M

H
≡
[x]η .

MH

≡
[y]η .

[y/x]

MH

by 2.28(b)
≡
[y]η .

[y/x]M

H

by (b) above
≡

λy.[y/x]M

H .
For (d): by (b) and (c), it is enough to prove (d) when no variable
bound in M is free in xN. This is done by induction on M. The cases
that M is an atom or an application are routine. The remaining case is
that M ≡λy.P and y ̸∈FV(xN); then

[N/x](λy.P)

H
≡

λy.[N/x]P

H
by 1.12(f)
≡
[y]η .

[N/x]P

H

by 9.10(c)
≡
[y]η .

[NH /x]

PH

by induc. hypoth.
≡
[NH /x]

[y]η .(PH )

by 2.28(c)
≡
[NH /x]

λy.P

H

by 9.10(c).
Lemma 9.14 For all λ-terms M and N:
λβζ ⊢M = N
=⇒
CLζ ⊢MHη = NHη .
Proof
By 7.4 we can use λβη instead of λβζ.
We use induction on
the deﬁnition of λβη in 6.2 and 7.2. Cases (ρ), (µ), (ν), (τ), (σ) are
trivial because these rules of λβη are also rules of CLζ. For case (α),
use 9.13(c). For case (ξ): this rule is admissible in CLζ by 8.8.
Case (β): Let M ≡(λx.P)Q and N ≡[Q/x]P. Then
MH
≡
([x]η . PH )QH
=w
[QH /x](PH )
by 2.21
≡
NH
by 9.13(d).
Case (η): Let M ≡λx.Nx and x ̸∈FV(N). Then
MH
≡
[x]η .(NH x)
≡
NH
by 2.18(c).

98
Correspondence between λ and CL
Theorem 9.15 (Equivalence of extensional equalities) For all CL-
terms X and Y ,
X =Cext Y
⇐⇒
Xλ =λext Yλ.
Proof Part ‘⇒’ is 9.5(c), and ‘⇐’ comes from 9.11 and 9.14.
By the way, [ ]η and the Hη-mapping have not been mentioned at all
in the preceding theorem; they have simply been tools in its proof.
On the other hand, the next theorem will summarize all the main
points of the correspondence between extensional λ and CL, including
points involving Hη. Its proof will need the following lemma.
Lemma 9.16 For all CL-terms Y :

[x]η .Y

λ =λext λx.(Yλ).
Proof

[x]η .Y

λ
=η
λx.

[x]η .Y

λx

by (η),
≡
λx.

([x]η .Y )x

λ
by 9.2(c), (a)
=β
λx.(Yλ)
by 9.5(b) since ([x]η .Y )x =w Y.
Theorem 9.17 (Linking extensional λ and CL) For all CL-terms
X, Y and all λ-terms M, N:
(a)

Xλ

Hη
≡X;
(b)

MHη

λ =λext M;
(c)
X =Cext Y
⇐⇒
Xλ =λext Yλ;
(d)
M =λext N
⇐⇒
MHη
=Cext NHη .
Proof
Part (a) is 9.11 and (c) is 9.15. For (d), ‘⇒’ is 9.14, and ‘⇐’
comes from (b) and (c). Part (b) is proved by induction on M. For
example, if M ≡λx.P, then

MH

λ
≡

[x]η .(PH )

λ
=λext
λx.

(PH )λ

by 9.16
=λext
λx.P
by induc. hypoth. and (ξ).

9B The extensional equalities
99
Discussion 9.18 (Reduction) The correspondence between λ and CL
is nowhere near as neat for reduction as for equality. In λ, the ‘exten-
sional’ reduction is ▷βη (Deﬁnition 7.8), and in CL it is >−(Deﬁnition
8.15). It is easy to prove a one-way connection
M ▷βη N
=⇒
MHη
>−NHη
(1)
by a proof like that of Lemma 9.14. But if we ask for the converse of (1),
we shall be disappointed, because X >−Y does not imply Xλ ▷βη Yλ,
but only Xλ =λext Yλ (Exercise 9.19(b) below). Some of the problems
involved were discussed in [Hin77, Section 3].
The lack of a two-way correspondence between the two reductions
is no great drawback, however. Equality is the main thing, and all we
should ask of a reduction-concept is that it helps in the study of equality
(and, perhaps, that it behaves in some sense like the informal process of
calculating the value of a function). Reduction’s main use is to help us
get results of the form ‘X = Y is not provable in the theory of equality’.
Exercise 9.19 (Strong reduction and strong nfs)
(a) *
Prove that the relation >−is conﬂuent (Theorem 8.18).
(Hint: use 9.18(1) and the conﬂuence of ▷βη, 7.13.)
(b) *
Find CL-terms X, Y such that X >−Y but Xλ ̸ ▷βηYλ.
(c) *
Prove that, for all CL-terms X,
X is in strong nf
⇐⇒
X ≡MHη for some M in βη-nf
⇐⇒
X ≡MHη for some M in β-nf.
(d) Using (c) and 8.22(c) and 9.17, prove that, for all CL-terms X
and λ-terms M,
(i)
X has a strong nf iﬀXλ has a βη-nf;
(ii)
M has a βη-nf iﬀMHη has a strong nf.
(e) Using (d)(i) and 3.23, prove that, in CL, the Y-combinators in
Deﬁnition 3.4 have no strong nf. (Though, as remarked in 3.23,
they have weak nfs, and one is actually in weak nf.)
(f) In CL just as in λ, do not confuse having a nf with being in nf.
Although every CL-term in strong nf is also in weak nf, it is
possible for a CL-term X to have a strong nf without having a
weak nf. Prove that SK(SII(SII)) is one such X.

100
Correspondence between λ and CL
9C New abstraction algorithms in CL
Having successfully connected the extensional equalities in λ and CL, it
is natural to look next at β-equality.
However, for this we shall need a new deﬁnition of [ ]-abstraction in
CL. The one used so far, Deﬁnition 2.18, contains the clause
(c)
[x].Ux
≡U
if x ̸∈FV(U)
which is like axiom-scheme (η), and the latter is not admissible in the
theory λβ. So, if we wish to ﬁnd a correspondence between λβ and CL,
we are unlikely to be helped much by [ ]η and Hη: we must restrict or
omit clause (c).
The following [ ]-deﬁnition is from [CF58, Section 6A algorithm (abf)]
and [Bar84, Deﬁnition 7.1.5]; it simply omits (c).
Deﬁnition 9.20 (Weak abstraction)
For all CL-terms Y , [x]w .Y is
deﬁned thus:
(a)
[x]w .Y
≡KY
if x ̸∈FV(Y );
(b)
[x]w .x
≡I;
(f)
[x]w .UV ≡S([x]w .U)([x]w .V )
if x ∈FV(UV ).
Remark 9.21
Weak abstraction was not used in Chapter 2 because
the terms [x]w .Y it produces are in many cases much longer than [x]η .Y .
For example, calculate and compare
[x, y, z]w .xz(yz),
[x, y, z]η .xz(yz).
Lemma 9.22 For all CL-terms Y and Z:
(a)
[x]w .Y is deﬁned for all x and Y , and does not contain x;
(b)
([x]w .Y )Z ▷w [Z/x]Y ;
(c)
[z]w .[z/x]Y
≡[x]w .Y
if z ̸∈FV(Y );
(d)
[Z/v]([x]w .Y ) ≡[x]w .([Z/v]Y )
if x ̸∈FV(vZ);
(e)

[x]w .Y

λ =β λx.(Yλ).
Proof Parts (a) and (b) are proved together just like 2.21. Parts (c) and
(d) are proved by a straightforward induction on Y , like 2.28(c). Part
(e) also comes by induction on Y .

9C Abstraction algorithms in CL
101
Lemma 9.23 For all CL-terms Y , [x]w .Y is functional in the sense of
Deﬁnition 9.6.
Proof Obvious from the deﬁnition of [ ]w. (This lemma does not hold
for [ ]η, as the example [x]η .ux ≡u shows.)
Deﬁnition 9.24 (The Hw-mapping) For all λ-terms M, deﬁne MHw
as in Deﬁnition 9.10, but using [ ]w instead of [ ]η; in particular, deﬁne
(λx.M)Hw
≡[x]w .(MHw ).
Lemma 9.25 For all λ-terms M and N:
(a)
FV(MHw ) = FV(M);
(b)
M ≡α N
=⇒
MHw ≡NHw ;
(c)

[N/x]M

Hw
≡[NHw /x]

MHw

.
Proof Like the proof of 9.13. (The proof of (c) uses 9.22(d).)
The above lemma shows that Hw has the same basic properties as
Hη. We shall use these properties in the next section. But before doing
that, it might be of interest to look at two other possible deﬁnitions of
[ ]-abstraction.
Remark 9.26 (Abstraction [ ]fab)
The deﬁnition of [ ]w could be
made neater by restricting clause 9.20(a) to the case that Y is an atom,
as in [CF58, Section 6A algorithm (fab)]. But this would make Lemma
9.22(d) fail. For example, calculate and compare
[uz/v]([x]f ab.v),
[x]f ab.[uz/v]v .
And 9.22(d) is useful for comparing λ with CL, as it says substitution
and [x]w behave very like substitution and λx in λ.
Remark 9.27 (Abstraction [ ]β)
The Hw-mapping is not a left in-
verse of the λ-mapping, since by the example in Remark 9.21, (Sλ)Hw ̸≡
S. In [CHS72, p. 71], Curry deﬁned an abstraction, today called ‘[ ]β’,
which does not admit clause (c) in all cases but in just enough cases to
give the property
(Xλ)Hβ
≡X
to its associated mapping Hβ. His deﬁnition consists of clauses 9.20(a)
and (b), plus the following:

102
Correspondence between λ and CL
(cβ)
[x]β .Ux ≡U
if U is fnl and x ̸∈FV(U);
(fβ)
[x]β .UV ≡S([x]η .U)([x]η .V ) if neither (a) nor (cβ) applies.
Note the two ‘η’s in (fβ); their eﬀect is to say that clause (c) can be used
unrestrictedly in computing [x]β .Y if it is not the ﬁrst clause used in
the computation. (To see this, compute [x, y, z]β .xz(yz) and show that
(Sλ)Hβ ≡S.)
This deﬁnition is more complicated than [ ]η and [ ]w but has some of
the virtues of both: like [ ]w, [x]β .Y is functional for all Y , and like Hη,
Hβ is a left inverse of the λ-mapping.
But a cost of getting these virtues is that the useful Lemma 9.22(d)
has to be weakened to

∀non-fnl Z
 
[Z/v]([x]β .Y ) ≡[x]β .([Z/v]Y ) if x ̸∈FV(vZ)

.
By the way, both the Hβ- and Hη-mappings are left inverses of the
λ-mapping, but this does not imply that the two H-mappings are the
same, because a mapping can have many left inverses (although it cannot
have more than one two-sided inverse).
Exercise 9.28∗For the reader who knows the standardization theorem,
[Bar84, Theorem 11.4.7]: prove, using this theorem, that, for all CL-
terms X, if Xλ =β λx.M for some M, then X is weakly equal to a fnl
term. (Hint: [ ]β and its associated Hβ-mapping may be useful.)
9D Combinatory β-equality
The relation of β-equality in λ-calculus induces the following equality
between CL-terms.
Deﬁnition 9.29 (Combinatory β-equality)
For all CL-terms X
and Y , deﬁne
X =Cβ Y
⇐⇒
Xλ =β Yλ.
The aim of this section is to ﬁnd a new deﬁnition of =Cβ which is
entirely within CL and does not mention λ.
Exercise 9.30 ∗It is easy to prove that =Cβ is intermediate between
=w and =Cext; i.e. to prove that

9D CLβ-equality
103
(a)
X =w Y
=⇒
X =Cβ Y
=⇒
X =Cext Y .
Show that these implications cannot be reversed, by proving
(b)
SK =Cβ KI,
SK ̸=w KI;
(c)
S(KI) =Cext I,
S(KI) ̸=Cβ I.
Exercise 9.31 For all CL-terms X, prove that K(KX) is a ﬁxed point
of S with respect to =Cβ. That is, prove S(K(KX)) =Cβ K(KX).
To re-deﬁne =Cβ without mentioning λ, we shall use the following
formal theory. It is a modiﬁcation of the theory CLζ in the previous
chapter.
Deﬁnition 9.32 (The formal theory CLζβ)
CLζβ is obtained
by adding the following rule to the theory CLw of weak equality in
Deﬁnition 6.5:
(ζβ)
Ux = V x
U = V
if x ̸∈FV(UV ) and U, V are fnl.
Example 9.33 CLζβ ⊢SK = KI.
To see this, ﬁrst note that the following can be proved in CLw:
SKyz = Kz(yz) = z = Iz.
Then rule (ζβ) can be applied, since SKy and I are fnl, to give
SKy = I.
But CLw ⊢I = KIy, so CLζβ ⊢SKy = KIy. Since SK and KI are fnl,
rule (ζβ) can be applied to give
SK = KI.
Lemma 9.34 For all CL-terms X, Y and λ-terms M, N:
(a)
CLζβ ⊢X = Y
=⇒
λβ ⊢Xλ = Yλ;
(b)
λβ ⊢M = N
=⇒
CLζβ ⊢MHw = NHw .
Proof (a) We use induction on the axiom-schemes and rules deﬁning
CLζβ in 9.32 and 6.5. For those in CLw, see the proof of 9.5.
For rule (ζβ): let x ̸∈FV(UV ) and U, V be fnl CL-terms, and suppose,

104
Correspondence between λ and CL
as induction hypothesis, that (Ux)λ =β (V x)λ. We must deduce that
Uλ =β Vλ. By 9.7(a), there exist λ-terms M, N such that
Uλ ▷β λx.M,
Vλ ▷β λx.N.
Hence
Uλ
=β
λx.M
=β
λx.((λx.M)x)
since (λx.M)x ▷β M,
=β
λx.(Uλx)
since Uλ ▷β λx.M,
=β
λx.(Vλx)
by induc. hypoth.,
=β
Vλ
similarly.
(b)
We use induction on the deﬁnition of λβ in 6.2. For cases (α)
and (β), use 9.25(b) and (c). Cases (ρ), (µ), (ν), (τ), (σ) are easy.
For case (ξ): suppose, as induction hypothesis, that
CLζβ
⊢
MHw = NHw .
We must deduce (λx.M)Hw = (λx.N)Hw , that is [x]w.MHw = [x]w.NHw .
Now, by 2.21,
([x]w .MHw )x =w MHw ,
and similarly for N; so
CLζβ
⊢
([x]w .MHw )x = ([x]w .NHw )x.
But [x]w .MHw and [x]w .NHw are fnl by 9.23, so rule (ζβ) applies, giving
CLζβ
⊢
[x]w .MHw
= [x]w .NHw .
Lemma 9.35 For all CL-terms X:
CLζβ
⊢

Xλ

Hw = X.
Proof We use induction on X. The cases X ≡Y Z, X ≡x and X ≡I
are easy, and the case X ≡K is like X ≡S. For X ≡S, we have

Sλ

Hw uvw
≡

[x, y, z]w .xz(yz)

uvw
=w
uw(vw)
=w
Suvw.
Also Suv, Su, S and (Sλ)Hw are fnl, and (Sλ)Hw uv and (Sλ)Hw u can
easily be weakly reduced to fnl terms, so rule (ζβ) can be applied three
times to give
CLζβ
⊢

Sλ

Hw = S.

9D CLβ-equality
105
Theorem 9.36 (Equivalence of β-equalities) The equality =Cβ, in-
duced on CL-terms by =β in λ-calculus, is the same as the equality
determined by the formal theory CLζβ; i.e. for all CL-terms X and Y ,
X =Cβ Y
⇐⇒
Xλ =β Yλ
⇐⇒
CLζβ ⊢X = Y.
Proof The ﬁrst ‘⇐⇒’ is Deﬁnition 9.29. For the second: ‘⇐’ is 9.34(a),
and ‘⇒’ comes from 9.34(b) and 9.35.
Theorem 9.37 (Summary) For all CL-terms X and Y , and λ-terms
M and N:
(a)

Xλ

Hw
=Cβ X;
(b)

MHw

λ =β M;
(c)
X =Cβ Y
⇐⇒
Xλ =β Yλ
⇐⇒
CLζβ ⊢X = Y ;
(d)
M =β N
⇐⇒
MHw
=Cβ NHw .
Proof Part (a) is 9.35 with 9.36, and (c) is just 9.36. Part (b) is proved
by induction on M like 9.17(b), using 9.22(e).
For (d): ‘⇐’ comes from (b) and (c), and ‘⇒’ is 9.34(b).
Remark 9.38 (Axioms for β-equality)
It is possible to ﬁnd axioms
for =Cβ, just as was done for extensional equality in Section 8B. A suit-
able set of ﬁve axioms is in [CF58, Section 6C4, p. 203]. Another set (for
the version of CL in which I is not an atom) is the set Aβ in [Bar84, Def-
inition 7.3.6]. (Two members of that set are redundant, namely (A.1′)
and (A.2′), as stated in the proof of [Bar84, Corollary 7.3.15].)
We shall never need the details of these axioms in the present book,
but the formal theory obtained by adding them to CLw will be men-
tioned several times; it will be called
CLβax.
Remark 9.39 (Rule (ξ) again)
A CL-version of rule (ξ) was in-
troduced in the last chapter (Notation 8.1); in the present chapter’s
notation, it says
(ξ)
X = Y
[x]η .X = [x]η .Y .

106
Correspondence between λ and CL
The corresponding theory CLξ was proved equivalent to CLζ.
It is
natural to ask whether there is a modiﬁed version of (ξ) that would
produce a theory equivalent to CLζβ.
An obvious ﬁrst attempt is to change [ ]η to [ ]w.
But this fails:
the resulting theory CLξ turns out strictly weaker than CLζβ, [BHS89,
Section 6]. A second attempt is to change [ ]η to the [ ]β that was deﬁned
in Remark 9.27. This succeeds.
In more detail: let the formal theory CLξβ be deﬁned by adding to
CLw (the theory of weak equality in Deﬁnition 6.5) the rule
(ξβ)
X = Y
[x]β .X = [x]β .Y .
Then the following theorem holds.
Theorem 9.40 The equality determined by CLξβ is the same as =Cβ;
i.e., for all CL-terms X, Y ,
CLξβ ⊢X = Y
⇐⇒
X =Cβ Y.
Proof By 9.36, it is enough to prove that CLξβ
⊢X = Y iﬀCLζβ ⊢
X = Y . This is done in [BHS89, Theorem 4].
Remark 9.41 (β-strong reduction)
Several deﬁnitions of reduction
have been proposed for =Cβ, but unfortunately none is very easy to work
with. If we simply modiﬁed the deﬁnition of strong reduction (Deﬁnition
8.15) by changing abstraction from [ ]η to [ ]w, we would get a reduction
that is not conﬂuent (pointed out by Bruce Lercher in correspondence
and discussed in [Hin77, Section 3]). If we changed abstraction to [ ]β,
we would get conﬂuence but not some other desirable properties.
Several other alternative β-strong reductions have been proposed. The
one deﬁned by Mohamed Mezghiche in [Mez89, Section 2] has the fewest
snags; it depends on an ingenious modiﬁcation to the deﬁnition of [ ].

10
Simple typing, Church-style
10A
Simple types
In mathematics the deﬁnition of a particular function usually includes a
statement of the kind of inputs it will accept, and the kind of outputs it
will produce. For example, the squaring function accepts integers n as
inputs and produces integers n2 as outputs, and the zero-test function
accepts integers and produces Boolean values (‘true’ or ‘false’ according
as the input is zero or not).
Corresponding to this way of deﬁning functions, λ and CL can be
modiﬁed by attaching expressions called ‘types’ to terms, like labels to
denote their intended input and output sets. In fact almost all program-
ming languages that use λ and CL use versions with types.
This chapter and the next two will describe two diﬀerent approaches
to attaching types to terms: (i) called Church-style or sometimes explicit
or rigid, and (ii) called Curry-style or sometimes implicit. Both are used
extensively in programming.
The Church-style approach originated in [Chu40], and is described in
the present chapter. In it, a term’s type is a built-in part of the term
itself, rather like a person’s ﬁngerprint or eye-colour is a built-in part of
the person’s body. (In Curry’s approach a term’s type will be assigned
after the term has been built, like a passport or identity-card may be
given to a person some time after birth.)
The ﬁrst step is to deﬁne expressions called ‘types’ (or ‘simple types’
to distinguish them from other more complicated type-systems.)
Deﬁnition 10.1 (Simple types)
Assume we have a ﬁnite or inﬁnite
sequence of symbols called atomic types; then we deﬁne types as follows.
107

108
Simple typing, Church-style
(a) every atomic type is a type;
(b) if σ and τ are types, then the expression (σ→τ) is a type, called
a function type.
Comments 10.2
An atomic type is intended to denote a particular
set; for example we may have the atomic type N for the set of natural
numbers, and H for the set of Boolean values {‘true’, ‘false’}. In general,
the atomic types will depend on the intended use of the system we wish
to build.1
A function type (σ→τ) is intended to denote some given set of func-
tions from σ to τ. That is, functions which accept as inputs the members
of the set denoted by σ, and produce outputs in the set denoted by τ. In
mathematical language, the domain of such a function is the set denoted
by σ, and its range is a subset of the set denoted by τ.
The exact set of functions denoted by (σ →τ) will depend on the
intended use of whatever system of typed terms we build. For example,
it might be the set of all functions from σ to τ, or just the computable
functions from σ to τ. When this set of functions is speciﬁed, then every
type comes to denote a set of individuals or functions. For example,
(N →N):
functions from numbers to numbers;
(N →H):
functions from numbers to Boolean values;
(N →(N →N)):
functions from numbers to functions;
((N →N) →N):
functions from functions to numbers;
((N →N) →(N →N)): functions from functions to functions;
etc.
Notation
Lower-case Greek letters will denote arbitrary types. We
shall use the abbreviations
σ →τ
for
(σ →τ),
ρ →σ →τ
for
(ρ →(σ →τ)),
σ1 →. . . →σn →τ
for
(σ1 →(. . . →(σn →τ) . . .)).
(Warning:
an expression such as ‘σ →τ’ containing Greek letters is
not itself a type; it is only a name in the meta-language for an unspeciﬁed
type.)2
1 In many works on type-theory an atomic type 0 is used for the set of all natural
numbers. We use N here instead to avoid confusion with the number zero.
2 By the way, although ‘σ →τ ’ is now the standard notation for function-types, older
writers used diﬀerent notations: for example ‘Fστ ’ (used by Curry and, in early
works, by the present authors), ‘τσ’ (used by Church and his former students),
also ‘στ ’, ‘τ σ ’ and ‘σ τ ’ (by various writers).

10B Typed λ-calculus
109
10B
Typed λ-calculus
Deﬁnition 10.3 (Typed variables)
Assume that there is given an
inﬁnite sequence of expressions v0, v00, v000, . . . called untyped variables
(compare Deﬁnition 1.1). We make typed variables xτ by attaching type-
superscripts to untyped variables, in such a way that
(a) (consistency condition) no untyped variable receives more than
one type, i.e. we do not make xτ , xσ with τ ̸≡σ;
(b) every type τ is attached to an inﬁnite sequence of variables.
Note 10.4
We call xτ a variable of type τ;
it is intended to denote
an arbitrary member of whatever set is denoted by τ. Condition (a)
ensures that, for example, if we make a typed variable xN, to denote an
arbitrary number, we cannot also make xN→N, which would denote a
function.
Condition (b) ensures that, roughly speaking, for every τ, there are
enough variables to discuss as many members of this set as we
like.
There are many ways of attaching types to variables to satisfy (a) and
(b). The details will not matter in this book, but here is one way of
doing it. First, list all the untyped variables, without repetitions (call
them v1, v2, v3, . . . for convenience, instead of v0, v00, v000, . . . ), and
list all the types, without repetitions (call them τ1, τ2, τ3, . . . ). Then,
for each i ≥1, attach τi to all of
vψ(i,1), vψ(i,2), vψ(i,3), . . . ,
where ψ is a function that maps INpos × INpos one-to-one onto INpos,
where INpos = {1, 2, 3, . . .}. Many such functions ψ are known; one is
ψ(i, j)
=
j + (i + j −2)(i + j −1)
2
.
Deﬁnition 10.5 (Simply typed λ-terms)
Assume that, besides the
typed variables, we have a (perhaps empty) ﬁnite or inﬁnite sequence
of expressions called typed atomic constants, cτ , each with an attached
type. Then the set of all typed λ-terms is deﬁned as follows:
(a) all typed variables xτ and atomic constants cτ are typed λ-terms
of type τ;

110
Simple typing, Church-style
(b) if M σ→τ and N σ are typed λ-terms of types σ→τ and σ respec-
tively, then the following is a typed λ-term of type τ:
(M σ→τ N σ)τ ;
(c) if xσ is a variable of type σ and M τ is a typed λ-term of type τ,
then the following is a typed λ-term of type σ→τ:
(λxσ .M τ )σ→τ .
Note 10.6 A typed term M τ is intended to denote a member of what-
ever set is denoted by τ. The clauses of the above deﬁnition have been
chosen with this intention in mind; for example, in (b), if M σ→τ denotes
a function φ from σ to τ, and N σ denotes a member a of σ, then the
term (M σ→τ N σ)τ denotes φ(a), which is in τ.
The atomic constants might include atoms 0
N and σ N→N to denote
zero and the successor function.
When writing typed terms, type-superscripts will often be omitted
when it is obvious from the context what they should be. Other notation-
conventions for terms will be the same as in Chapter 1.
Example 10.7 For every type σ, the following is a typed term:
Iσ
≡(λxσ .xσ)σ→σ.
It may be written informally as (λxσ .x)σ→σ or (λx.x)σ→σ or simply
λxσ .x.
Example 10.8 For every pair of types σ and τ, the following is a typed
term:
Kσ,τ
≡

λxσ .(λyτ .xσ)τ →σσ→(τ →σ).
It may be written as (λxσyτ .x)σ→(τ →σ) or (λxy.x)σ→(τ →σ) or
λxσyτ .x.
Example 10.9 For every triple of types ρ, σ and τ, the following is a
typed term, called Sρ,σ,τ :

λxρ→σ→τ .

λyρ→σ .

λzρ .

(xρ→σ→τ zρ)σ→τ (yρ→σzρ)στ ρ→τ δ θ
,

10B Typed λ-calculus
111
where
δ
≡
(ρ →σ) →(ρ →τ),
θ
≡
(ρ →σ →τ) →(ρ →σ) →ρ →τ.
To check that this expression satisﬁes the deﬁnition of typed term, it is
best to look at its construction step by step. First, xρ→σ→τ , yρ→σ and
zρ are typed terms by Deﬁnition 10.5(a). Then the expressions
(xρ→σ→τ zρ)σ→τ ,
(yρ→σzρ)σ
are typed terms by 10.5(b). Hence the expression

(xρ→σ→τ zρ)σ→τ (yρ→σzρ)στ
is a typed term, again by 10.5(b). Next, the expression

λzρ .

(xρ→σ→τ zρ)σ→τ (yρ→σzρ)στ ρ→τ
is a typed term by 10.5(c). Finally, by 10.5(c) used twice more, the
whole expression Sρ,σ,τ is a typed term.
This procedure, for constructing Sρ,σ,τ and checking that types are
correct at each step, can be displayed as a tree-diagram, see below. The
same procedure will crop up again in a diﬀerent context in the next
chapter.
xρ→σ→τ
zρ
(xz)σ→τ
yρ→σ
zρ
(yz)σ
(xz(yz))τ

λzρ .(xz(yz))τ ρ→τ

λyρ→σ .(λz.xz(yz))ρ→τ δ

λxρ→σ→τ .(λyz.xz(yz))δ θ.
Notation As mentioned before, type-superscripts are often omitted; for
example, this was done in several places in the preceding tree-diagram
to avoid obscuring the main structure. The term Sρ,σ,τ may be written
as
(λxyz.xz(yz))(ρ→σ→τ )→(ρ→σ)→ρ→τ
or
λxρ→σ→τ yρ→σzρ .xz(yz).

112
Simple typing, Church-style
Deﬁnition 10.10 (Substitution)
[N σ/xσ](M τ ) is deﬁned in the
same way as the substitution of untyped terms in Deﬁnition 1.12.
It is routine to check that [N σ/xσ](M τ ) is a typed term of type τ.
Note that we do not deﬁne [N ρ/xσ](M τ ) when ρ ̸≡σ.
Lemma 10.11
(a) In a typed term M τ , if we replace an occurrence of a typed term
P σ by another term of type σ, then the result is a typed term of
type τ.
(b) (for α-conversion) If (λxσ .M τ )σ→τ is a typed term, then so is
(λyσ .[yσ/xσ]M τ )σ→τ , and both terms have the same type.
(c) (for β-conversion) If

(λxσ .M τ )σ→τ N στ is a typed term, then
so is [N σ/xσ]M τ , and both terms have the same type.
Proof Tedious but straightforward.
All the lemmas on substitution and α-conversion in Chapter 1 and
Appendix A1 hold for typed terms, with unchanged proofs.
Deﬁnition 10.12 (Simply typed β-equality and reduction) The
formal theory of simply typed β-equality will be called λβ →.3 It has
equations M σ = N σ as its formulas, and the following as its axiom-
schemes and rules:
(α)
λxσ .M τ
= λyσ .[yσ/xσ]M τ
if yσ ̸∈FV(M τ );
(β)

(λxσ .M τ )σ→τ N στ
= [N σ/xσ]M τ ;
(ρ)
M σ = M σ;
(µ)
M σ = N σ
⊢
P σ→τ M σ = P σ→τ N σ;
(ν)
M σ→τ = N σ→τ
⊢
M σ→τ P σ = N σ→τ P σ;
(ξ)
M τ = N τ
⊢
λxσ .M τ = λxσ .N τ ;
(τ)
M σ = N σ,
N σ = P σ
⊢
M σ = P σ.
(σ)
M σ = N σ
⊢
N σ = M σ;
3 It is very like the systems called ‘λ→-Church’ in [Bar92, Section 3.2] and ‘λ→’ in
[Mit96].

10B Typed λ-calculus
113
The formal theory of simply typed β-reduction will be called λβ →like
that of equality. Its axioms and rules are the same as above but with
(σ) omitted and ‘=’ replaced by ‘▷’.
For provability in these theories we shall write
λβ →⊢M σ = N σ,
λβ →⊢M σ ▷N σ.
Note 10.12.1 By induction on the above clauses it can be seen that
if M σ = N τ or M σ ▷N τ is provable in λβ →, then σ ≡τ. Hence, if
σ ̸≡τ then no equation M σ = N τ can be proved in λβ →. In particular,
if σ ̸≡τ then
(λxσ .xσ)σ→σ ̸≡α (λyτ .yτ )τ →τ .
Remark 10.13 Redex, contraction, reduction (▷β), and β-normal form
are deﬁned in typed λ exactly as in untyped λ, see 1.24 and 1.26. It is
routine to prove that
(a)
M σ ▷β N τ
=⇒
σ ≡τ,
(b)
M σ ▷β N σ
⇐⇒
λβ →⊢M σ ▷N σ.
Also, β-equality (=β) is deﬁned as in 1.37, and it is routine to prove that
(c)
M σ =β N σ
⇐⇒
λβ →⊢M σ = N σ.
All the other properties of reduction and equality in Chapter 1 hold for
typed terms, with the same proofs as before.
Note in particular the
substitution lemmas (1.31 and 1.40), the Church–Rosser theorems (1.32,
1.41 and A2.16), and the uniqueness of normal forms (1.41.4).
Besides these properties, typed λ has one extra property that untyped
λ does not have, and which plays a key role in all its applications. It will
be stated in the next theorem. First recall the deﬁnitions of reductions
and reductions with maximal length in 3.15 and 3.16.
Deﬁnition 10.14 (Normalizability, WN, SN)
In a typed or un-
typed λ-calculus, a term M is called normalizable or weakly normalizable
or WN iﬀit has a normal form. It is called strongly normalizable or SN
iﬀall reductions starting at M have ﬁnite length.
Clearly SN implies WN. To illustrate, consider the untyped terms
Ω≡(λx.xx)(λx.xx),
T2 ≡(λx.y)Ω,
T3 ≡(λx.y)(λx.x).
The ﬁrst has an inﬁnite reduction Ω▷1Ω▷1 etc., and has no normal form,

114
Simple typing, Church-style
so it is neither SN nor WN. The second has (at least) two reductions,
one ﬁnite and the other inﬁnite:
(λx.y)Ω▷1 y,
(λx.y)Ω▷1 (λx.y)Ω▷1 . . .
Thus T2 is WN but not SN. Finally, T3 has no inﬁnite reduction, so T3
is both SN and WN.
One can think of an SN term as being ‘safe’ in the sense that it cannot
lead to an endless computation. And in this view a WN term is a term
T that can be reduced to a safe term (although, like T2 above, T itself
might not be safe).
Theorem 10.15 (SN for simply typed ▷β) In the simply typed λ-
calculus λβ →, all terms are SN, i.e. no inﬁnite β-reductions are possible.
Proof See Appendix A3, Theorem A3.3.
Corollary 10.15.1 (WN for simply typed ▷β)
Every typed term
M τ in λβ →has a β-normal form M ⋆τ . Further, all β-reductions of M τ
which have maximal length end at M ⋆τ .
Proof By 10.15 and the Church–Rosser conﬂuence theorem.
Corollary 10.15.2 In simply typed λ-calculus the relation =β is decid-
able.
Proof (Decidability was deﬁned at the end of 5.4.) To decide whether
M σ =β N τ , reduce both terms to their normal forms, by 10.15.1, and
decide whether these are identical. By 1.41.2, this is enough.
The above theorem and its corollaries contrast strongly with untyped
λ, in which reductions may be inﬁnitely long and there is no decision-
procedure for the relation =β (Corollary 5.6.3). They say that the world
of typed terms is completely safe, in the sense that all computations
terminate and their results are unique.
Having looked at typed β, we turn next to βη (compare Chapter 7).
Deﬁnition 10.16 (Simply typed βη) The equality-theory λβη →is
deﬁned by adding to Deﬁnition 10.12 (λβ →) the following axiom-scheme:
(η)

λxσ .(M σ→τ xσ)τ σ→τ
= M σ→τ
if xσ ̸∈FV(M σ→τ ).

10C Typed CL
115
The reduction-theory λβη →is deﬁned similarly (using ‘▷’ instead of ‘=’).
The notations η-redex, η-contraction, η-reduction, ▷η, βη-reduction, ▷βη
and βη-normal form are deﬁned as in 7.7–7.9.
Remark 10.17
The main properties of the untyped βη-system were
stated in 7.11–7.16; these hold for the typed system as well, and the
proofs are the same. The SN theorem also holds for typed βη-reductions;
see Theorem A3.13 in Appendix A3.
Hence Corollaries 10.15.1 and
10.15.2 also extend to βη.
Remark 10.18 (Representability of functions)
In Chapter 4 it
was shown that all recursive functions can be represented in untyped λ,
in the sense of Deﬁnition 4.5. It is natural to ask what subset of these
functions can be represented by typed terms.
By Corollary 10.15.1, every function that is representable by a typed
term must be total.
In [Sch76], Helmut Schwichtenberg showed that if we represent the
natural numbers by typed analogues of the Church numerals in Deﬁni-
tion 4.2, the functions representable by typed terms form a very limited
class; namely the polynomials and the conditional function ‘if x = 0
then y else z’, and certain simple combinations of these. This class is
often called the extended polynomials; see [TS00, p. 21] for its precise
deﬁnition.
10C
Typed CL
The types for typed CL-terms are the same as those for λ-terms, see
Deﬁnition 10.1.
Deﬁnition 10.19 (Simply typed CL-terms) Assume we have typed
variables as in Deﬁnition 10.3. Assume we have an inﬁnite number of
typed atomic constants, including the following ones, called basic combi-
nators, with types as shown:
Iσ→σ
(one constant for each type σ);
Kσ→τ →σ
(one for each pair σ, τ);
S(ρ→σ→τ )→(ρ→σ)→ρ→τ
(one for each triple ρ, σ, τ).
Then we deﬁne typed CL-terms as follows:

116
Simple typing, Church-style
(a) all the typed variables and typed atomic constants (including the
basic combinators) are typed CL-terms;
(b) if Xσ→τ and Y σ are typed CL-terms, with types as shown, then
the following is a typed CL-term of type τ:
(Xσ→τ Y σ)τ .
Notation 10.20
Type-superscripts will often be omitted. The nota-
tion conventions for CL-terms from Chapter 2 will be used.
The typed basic combinators will often be abbreviated to
Iσ,
Kσ,τ ,
Sρ,σ,τ .
Their types are motivated by the types of their λ-counterparts in Ex-
amples 10.7–10.9.4
Deﬁnition 10.21
Substitution [U σ/xσ](Y τ ) is deﬁned just as for un-
typed terms in Deﬁnition 2.6. (We do not deﬁne [U ρ/xσ](Xτ ) when
ρ ̸≡σ.)
Just as for λ-terms, [U σ/xσ](Xτ ) can be shown to be a typed term
with the same type as Xτ .
Deﬁnition 10.22 (Simply typed weak equality and reduction)
The formal theory of simply typed weak equality will be called CLw →.
It has equations Xσ = Y σ as its formulas, and the following as its ax-
iom-schemes and rules:
(I)
IσXσ = Xσ;
(K)
Kσ,τ XσY τ
= Xσ;
(S)
Sρ,σ,τ Xρ→σ→τ Y ρ→σZρ = Xρ→σ→τ Zρ(Y ρ→σZρ);
(ρ)
Xσ = Xσ;
(µ)
Xσ = Y σ
⊢
Zσ→τ Xσ = Zσ→τ Y σ;
(ν)
Xσ→τ = Y σ→τ
⊢
Xσ→τ Zσ = Y σ→τ Zσ;
(τ)
Xσ = Y σ,
Y σ = Zσ
⊢
Xσ = Zσ;
(σ)
Xσ = Y σ
⊢
Y σ = Xσ.
4 An alternative motivation independent of λ was given in [CF58, Section 8C].

10C Typed CL
117
The formal theory of simply typed weak reduction will be called CLw →
like that of equality. Its axioms and rules are the same as above but
with (σ) omitted and ‘=’ replaced by ‘▷’.
For provability in these theories we shall write
CLw →⊢Xσ = Y σ,
CLw →⊢Xσ ▷Y σ.
Remark 10.23
Redex, contraction, reduction, ▷w and weak normal
form are deﬁned in typed CL exactly as in untyped CL, see 2.9 and 2.10.
It is routine to prove that
(a)
Xσ ▷w Y τ
=⇒
σ ≡τ,
(b)
Xσ ▷w Y σ
⇐⇒
CLw →⊢Xσ ▷Y σ.
Also, weak equality (=w) is deﬁned as in 2.29, and it is routine to prove
(c)
Xσ =w Y σ
⇐⇒
CLw →⊢Xσ = Y σ.
All the other properties of reduction and equality in Chapter 2 hold for
typed CL with the same proofs as in Chapter 2. Note in particular the
substitution lemmas (2.14 and 2.31), the Church–Rosser theorems (2.15,
2.32 and A2.16), and the uniqueness of normal forms (2.32.4).
Deﬁnition 10.24 (Abstraction)
For every typed term Xτ and vari-
able xσ, a term called [xσ ].Xτ is deﬁned by induction on the length of
Xτ as follows (compare Deﬁnition 2.18).
(a)
[xσ ].Xτ ≡Kσ,τ Xτ
if xσ ̸∈FV(Xτ );
(b)
[xσ ].xσ ≡Iσ;
(c)
[xσ ].(U σ→τ xσ) ≡U σ→τ
if xσ ̸∈FV(U σ→τ );
(f)
[xσ ].(U ρ→τ V ρ) ≡Sσ,ρ,τ ([xσ ].U ρ→τ )([xσ ].V ρ)
if neither (a) nor (c) applies.
Exercise 10.25 Write all the missing type-superscripts into the above
deﬁnition, and verify that [xσ ].Xτ always has type σ→τ.
Abstraction of typed terms has the same properties as untyped ab-
straction in Chapter 2, with the same proofs as in that chapter. Note in
particular Theorems 2.21 and 2.27 and Lemma 2.28.
Typed CL-terms also have the following ‘safety’ properties with re-
spect to ▷w. Just as for λ in Deﬁnition 10.14, a term is called SN iﬀ
all weak reductions starting at that term are ﬁnite, and WN iﬀit has a
normal form.

118
Simple typing, Church-style
Theorem 10.26 (SN for simply typed ▷w) In simply typed CL, all
terms are SN, i.e. there are no inﬁnite weak reductions.
Proof Appendix A3, Theorem A3.14.
Corollary 10.26.1 (WN for simply typed ▷w) Every simply typed
CL-term has a weak normal form.
Corollary 10.26.2 In simply typed CL the relation =w is decidable.
Remark 10.27 (Strong reduction)
A typed version of >−can
be deﬁned and a WN theorem proved for it; the proof is like Theorem
11.28. However, for SN, no theorem in known. The ﬁrst step towards
such a theorem would be to give a satisfactory deﬁnition of the concept
of SN for strong reduction, and this is not as easy as it looks.
Further reading
See the end of Chapter 12.

11
Simple typing, Curry-style
in CL
11A
Introduction
The typed terms in Chapter 10 correspond to functions as they are
usually deﬁned in set theory and mathematics.
On the other hand,
if one takes the ‘functions as operators’ approach of Discussion 3.27,
Chapter 10 leaves one with the feeling that something essential to the
interpretation of untyped λ-terms has been lost.
For example, for diﬀerent pairs σ, τ of types, the terms Kσ,τ ≡
λxσyτ .xσ are all distinct. But in a sense they all represent special cases
of the same operation, that of forming constant-functions. An even sim-
pler example is given by the terms Iσ ≡λxσ .xσ, which are distinct for
diﬀerent types σ but which all represent special cases of the one oper-
ation of doing nothing. If we feel that these two operations are single
intuitive concepts, then a theory that tries to formalize them by splitting
them into an inﬁnity of special cases seems to be heading in the wrong
direction.
It seems better to aim for a formalism in which each operation is
represented by a single term, and this term is given an inﬁnite number
of types. This is what will be done in the present chapter. We shall take
the untyped terms as given, and state a set of axioms and rules that
will assign certain types to certain terms. Most terms that receive types
will receive inﬁnitely many of them, corresponding to the idea that they
represent operators with an inﬁnite number of special cases. (But some
terms, such as λx.xx, will receive no types.)
A type-system in which a term may have many types is called poly-
morphic.
A type-system in which a term’s types are not part of its
structure, but are assigned to it after the term is built, is called
119

120
Simple typing, Curry-style in CL
Curry-style, or sometimes implicit, in contrast to Chapter 10’s Church-
style systems.
In a Curry-style system a type assigned to a term is like a label to tell
the kinds of combinations that can ‘safely’ be made with the term. Al-
though at ﬁrst Curry’s approach will seem very diﬀerent from Church’s,
it will turn out that if we take the same types here as were used in
Chapter 10 and adopt the simplest rules to assign them to terms, then
a term X will receive a type τ in the present chapter if and only if there
is a corresponding typed term Xτ in Chapter 10.
A Curry-style system will not be a mere notational variant of Church’s
style, however; it will have more expressive power and more ﬂexibility.
For example, a natural question to ask about an untyped term X is
whether it has any typed analogues (just as K had the typed analogues
Kσ,τ in Chapter 10, for all σ and τ); but although this question is about
Church’s system, it turns out that the easiest way to answer it is to
re-state it in Curry’s language. Then we shall see that its answer can be
given for each X by a fairly simple algorithm.
Furthermore, Curry-style systems can be generalized in ways that
Church’s style cannot; an example will be given in 11.43.1
The present chapter will treat only CL-terms. The rules for λ-terms
are slightly more complicated and will be postponed to the next chapter.
We shall begin by extending the deﬁnition of simple types in 10.1 by
adding type-variables. An expression containing type-variables may be
used to describe an inﬁnite set of types all at once.
Deﬁnition 11.1 (Parametric types) Assume that we have an inﬁnite
sequence of type-variables and a ﬁnite, inﬁnite or empty sequence of type-
constants. Then we deﬁne parametric types as follows:2
(a) all type-constants and type-variables are (atomic) parametric
types;
(b) if σ and τ are types, then (σ →τ) is a parametric (function-)
type.
In the rest of this chapter we shall omit ‘parametric’ since no other types
will be discussed.
A closed type will be a type containing no type-var-
iables. An open type will be a type containing only type-variables.
1 The name ‘Curry-style’ arose because this kind of type-assignment originated with
Curry in the 1930s, and he was its main advocate until Robin Milner used it in
the programming language ML in the 1970s, [Mil78].
2 In [HS86], parametric types were called ‘type-schemes’.

11A Introduction
121
Notation 11.2
Lower-case Greek letters will denote types, and the
same abbreviations will be used here as in Chapter 10. In discussing the
types of the Church numerals we shall use the abbreviation
Nτ
≡(τ →τ) →τ →τ.
Type-variables will be denoted by letters ‘a’, ‘b’, ‘c’, ‘d’, ‘e’.
The
variables in terms will be called here term-variables. (Type-variables
and term-variables need not be diﬀerent.)
The result of simultaneously substituting types σ1, . . . , σn for type-
variables a1, . . . , an in a type τ will be called
[σ1/a1, . . . , σn/an]τ.
The type-constants may include the symbol N for the set of all natural
numbers and H for truth-values. In this case, some examples of types
would be
N →H,
N →N,
N →N →H,
a →b,
N →b,
(b →a) →a,
etc.
Terms in this chapter will be CL-terms (i.e. the untyped terms from
Chapter 2, not the typed terms from Chapter 10). As usual, a non-
redex atom is an atom other than S, K and I. A non-redex constant is a
constant other than S, K and I. A pure term is a term whose only atoms
are S, K, I and variables. A combinator is a term whose only atoms are
S, K, I.
Remark 11.3
In this chapter and the next, a function-type σ→τ is
intended to denote some set of operators φ such that
x ∈σ =⇒φ(x) is deﬁned and φ(x) ∈τ.
This contrasts with Chapter 10: there, a claim that φ was in σ →τ
implied that the domain of φ was exactly σ, but here it only implies
that the domain ⊇σ. This comes from our intention that one operator
φ may have many types σ →τ; correspondingly, the domain of φ may
include many diﬀerent sets σ.

122
Simple typing, Curry-style in CL
11B
The system TA→
C
Deﬁnition 11.4
A type-assignment formula or TA→
C -formula is any
expression
X : τ ,
where X is a CL-term and τ is a type. We call X its subject and τ its
predicate.
A formula X :τ can be read informally as ‘we assign to X the type τ’
or ‘X receives type τ’, or very informally as ‘X is a member of τ’.3
Deﬁnition 11.5 (The type-assignment system TA→
C )
TA→
C is
a formal theory in the sense of Notation 6.1. Its axioms are given by
three axiom-schemes, motivated by the types of Iσ, Kσ,τ and Sρ,σ,τ in
Deﬁnition 10.19; they are:
(→I)
I : σ →σ,
(→K)
K : σ →τ →σ,
(→S)
S : (ρ →σ →τ) →(ρ →σ) →ρ →τ.
The only rule of TA→
C is called the →-elimination rule, or (→e); it is
motivated by Deﬁnition 10.19(b), and says:
(→e)
X : σ →τ
Y : σ
XY : τ .
Notation Let Γ be any ﬁnite, inﬁnite or empty set of TA→
C -formulas. Iﬀ
there exists a deduction of a formula X :τ whose non-axiom assumptions
are all in Γ, we write
Γ ⊢TA→
C
X :τ ,
or just Γ ⊢X :τ when no confusion is likely. IﬀΓ is empty, we call the
deduction a (TA→
C -) proof and write
⊢TA→
C
X : τ .
3 [HS86] used the notation ‘X ∈τ ’ for type-assignment formulas, but ‘X : τ ’ has
now come into standard use. Some older works used ‘τ X’ or ‘⊢τ X’ (thinking of
τ as a propositional function rather than a set).

11B The system TA→
C
123
Example 11.6
The term SKK, which behaves like I (since SKKX ▷
X), also has all the types that I has. That is, for all σ,
⊢TA→
C
SKK : σ →σ .
Proof Let σ be any type. In axiom-scheme (→S), take ρ, σ, τ to be σ,
σ→σ, σ respectively; this gives us an axiom
S : (σ →(σ→σ) →σ) →(σ →σ→σ) →σ →σ .
Also, from axiom-scheme (→K) we can get the following two axioms:
K : σ →(σ→σ) →σ ,
K : σ →σ →σ .
Using these three axioms and rule (→e), we make the TA→
C -proof below:
(→S)
S : (σ→(σ→σ)→σ)→(σ→σ→σ)→σ→σ
(→K)
K : σ→(σ→σ)→σ
SK : (σ→σ→σ)→σ→σ
(→K)
K : σ→σ→σ
SKK : σ→σ .
Example 11.7
Recall that B ≡S(KS)K. Then, for all ρ, σ, τ:
⊢TA→
C
B : (σ →τ) →(ρ →σ) →ρ →τ .
Proof
The required proof is shown below. To make it ﬁt into the width
of the page, it uses the following abbreviations:
θ
≡
(ρ →σ →τ) →(ρ →σ) →ρ →τ,
µ ≡
σ →τ,
ν ≡
ρ →σ →τ,
π ≡
(ρ →σ) →ρ →τ.
(We have ν
≡
ρ →µ, so the formula
K : µ →ν
is an axiom under
axiom-scheme (→K). Also ν →π ≡θ, so µ→ν →π ≡µ→θ.)
(→S)
S : (µ→ν →π)→(µ→ν)→µ→π
(→K)
K : θ→µ→θ
(→S)
S : θ
KS : µ→θ
S(KS) : (µ→ν)→µ→π
(→K)
K : µ→ν
S(KS)K : µ→π .

124
Simple typing, Curry-style in CL
Exercise 11.8∗For each of the terms on the left in the following table,
give a TA→
C -proof to show it has all the types on the right (one type for
each ρ, σ, τ).
Term
Type
(a)
0
≡KI
(see 4.2)
τ →σ →σ
(b)
σ
≡SB
(see 4.6)
((σ→τ)→ρ→σ) →(σ→τ)→ρ→τ
(c)
W ≡SS(KI) (see 2.17)
(σ →σ →τ) →σ →τ
(d)
KK
ρ →σ →τ →σ
(e)
0
≡KI
Nτ
( Nτ
≡(τ →τ) →τ →τ.)
(f)
σ
≡SB
Nτ →Nτ
(g)
n
≡(SB)n(KI)
Nτ .
Exercise 11.9 ∗Give TA→
C -deductions to show that, for all ρ, σ, τ,
(a)
U :ρ→σ→τ, V :ρ→σ, W :ρ
⊢
SUV W :τ,
(b)
U :ρ→σ→τ, V :ρ→σ, W :ρ
⊢
UW(V W):τ,
(c)
U :ρ, V :σ
⊢
KUV :ρ,
(d)
U :ρ
⊢
IU :ρ,
(e)
x:ρ→σ, x:ρ
⊢
xx:σ.
These examples and exercises raise some points which will be discussed
below, before we move on to the main properties of TA→
C .
Note 11.10
(Axioms)
The three axiom-schemes for TA→
C in Deﬁ-
nition 11.5 are not axioms, but just patterns to show what the axioms
look like. The actual axioms are particular cases of these three schemes.
For example, if the type-constants include N, the axioms for I are
I : a→a,
I : (c→c)→(c→c),
I : N→N,
I : ((a→b)→c)→((a→b)→c),
I : (a→b)→(a→b),
etc.
Thus there are an inﬁnite number of axioms.
Also, if we perform a
substitution in an axiom, say by substituting b →c for a in the axiom
I:(a→b)→(a→b), we get
I : ((b→c)→b)→((b→c)→b) ,

11B The system TA→
C
125
and this is another axiom: the set of axioms is closed under substitution.
The following lemma takes this remark further; it says in eﬀect that
the set of all deductions is closed under substitution.
Lemma 11.11 (Closure under type-substitutions) Let Γ be any
set of TA→
C -formulas, and let
Γ ⊢TA→
C
X :τ .
For any types σ1, . . . , σk and type-variables a1, . . . , ak (distinct as usual),
let [σ1/a1, . . . , σk/ak]Γ be the result of substituting σ1, . . . , σk for a1,. . . ,
ak simultaneously in all the predicates in Γ. Then
[σ1/a1, . . . , σk/ak]Γ
⊢TA→
C
X : [σ1/a1, . . . , σk/ak]τ .
Proof
Substitute [σ1/a1, . . . , σk/ak] throughout the given deduction.
The result is still a genuine deduction, because substitution creates from
an axiom for I, K or S a new axiom of the same kind, and from an
instance of rule (→e) a new instance of this rule.
Note 11.12 (Principal axioms) All the axioms for I are substitution-
instances of the single axiom I : a →a; this axiom is called a principal
axiom for I. Similarly, K and S have the following as principal axioms:
K : a→b→a,
S : (a→b→c)→(a→b)→a→c .
(A principal axiom plays a similar role to an axiom-scheme, though on
a diﬀerent level: the axiom I : a →a is an expression in the formal
language of TA→
C , while the axiom-scheme ‘I:σ →σ’ is an expression in
the informal meta-language in which we are discussing TA→
C .)
Note 11.13 (Deductions from assumptions) Exercise 11.9 shows
an interesting way in which the Curry-style approach to types is more
expressive than Church’s: in TA→
C we can already answer questions of
a kind that could not even have been asked in Chapter 10, namely
“What type would X have if certain parts of X had certain types?”.
The possibility of making deductions from assumptions is an important
advantage of the present approach. (See Section 11I.)

126
Simple typing, Curry-style in CL
11C
Subject-construction
Looking again at Examples 11.6 and 11.7 and your answers to Exercises
11.8 and 11.9, notice that the deduction of a formula X :τ closely follows
the construction of X. Rule (→e) says
X : σ →τ
Y : σ
XY : τ ,
and in this rule the subject of the conclusion is built from the subjects
of the premises. Hence, as we move down a deduction the subject grows
in length and contains all earlier subjects.
In more detail: let D be a tree-form deduction of a formula X :τ from
some assumptions
(a)
U1 :π1, . . . , Un :πn
(n ≥0),
such that each of these formulas actually occurs in D.
Suppose, for the moment, that each Ui is a non-redex atom. Then
{U1, . . . , Un} will be exactly the set of non-redex atoms occurring in X,
and if we strip all types from D, we shall get the construction-tree for
X (i.e. the tree which shows how X is built up from U1, . . . , Un and
perhaps also some occurrences of I, K and S). To each occurrence of
Ui in X there will correspond an assumption Ui : πi in D, and to each
occurrence of I, K or S in X there will correspond an axiom in D. (Hence
n = 0 iﬀX is a combinator.) In general, if Z is any subterm of X, then
to each occurrence of Z in X there will correspond a formula in D with
Z as subject.
For example, look at the deduction for Exercise 11.9(b):
(b)
U : ρ→σ→τ
W : ρ
UW : σ→τ
(→e)
V : ρ→σ
W : ρ
V W : σ
(→e)
UW(V W) : τ .
(→e)
Here X ≡UW(V W), and there are three assumptions (so n = 3 in (a)):
U :ρ→σ→τ,
V :ρ→σ,
W :ρ.
Stripping the types away, we get the following tree, which is the con-
struction-tree of X if U, V, W are atoms:

11D Abstraction
127
(c)
U
W
UW
V
W
V W
UW(V W) .
On the other hand, returning to (a), suppose some of U1, . . . , Un are
not atoms. Then X will be an applicative combination of U1, . . . , Un
and I, K, S, and the stripped tree will show how X is built up from
these terms; it will not be the whole construction-tree of X, but only a
lower part. Each term-occurrence Z in X will either
(i) be inside an occurrence of a Ui corresponding to an assumption
Ui :πi, or
(ii) be an applicative combination of U1, . . . , Un, I, K, S, and have a
corresponding formula in D with Z as subject.
For example, in (b) above, if U ≡V (V W) and
X
≡
V (V W) W (V W),
Z ≡V W,
then there are two occurrences of Z in X: the ﬁrst is in U and has no
corresponding formula in (b), but the second corresponds to the formula
V W :σ in (b).
The correspondence between deductions and term-constructions is the
key to the study of TA→
C , and will be used repeatedly throughout this
chapter.
(It has been described formally in the Subject-construction
theorem of [CF58, Section 9B].)
One of its corollaries is that if Γ ⊢TA→
C X : τ and all the subjects in
Γ are atoms, then every non-redex atom q in X must occur as a subject
of a formula in Γ, say q:π for some type π.
11D
Abstraction
The aim of this section is to show that the type of [x].X is exactly what
one would expect from the informal interpretation of [x].X as a function.
Its main theorem will show how to deduce the type of [x].X from the
types of x and X, and will help in assigning types quickly to complex
terms.4
4 It was called the Stratiﬁcation Theorem in [CF58, Section 9D Corollary 1.1], and
is an analogy of the deduction theorem for Hilbert-style versions of propositional
logic.

128
Simple typing, Curry-style in CL
Theorem 11.14 (Abstraction and types) Let Γ be any set of TA→
C -
formulas. If x does not occur in any subject in Γ, and
Γ, x:σ
⊢TA→
C
X :τ ,
then
Γ
⊢TA→
C
[x].X : σ→τ ,
where [ ] is any of the three abstraction algorithms [ ]η, [ ]w, [ ]β deﬁned
in 9.1 (with 2.18), 9.20, 9.27 respectively.
Proof We use induction on X, with cases corresponding to Deﬁnition
2.18, which includes all the cases in 9.20 and 9.27. Let D be the given
deduction of X : τ from x : σ and members of Γ. The restriction that x
not occur in Γ implies that whenever x occurs in D, its type must be σ.
Case 1: x ̸∈FV(X) and [x].X ≡KX. Since x ̸∈FV(X), the assump-
tion x:σ is not used in D, so D is a deduction of
Γ
⊢
X :τ .
Now by axiom-scheme (→K) we have an axiom K : τ →σ →τ. Hence,
by rule (→e),
Γ
⊢
KX : σ→τ .
Case 2: X ≡x and [x].X ≡I. By axiom-scheme (→I) we have an
axiom I : σ →σ. But X ≡x, so τ ≡σ, and the axiom says I : σ →τ.
Hence
Γ
⊢
I : σ→τ .
Case 3: X ≡Ux with x ̸∈FV(U), and [x].X ≡U. Then, by the cor-
respondence between deductions and constructions, D must have form
D1
U : σ→τ
x : σ
Ux : τ ,
(→e)
where D1 is a deduction in which x does not occur. (The above notation
means that D1 is a deduction of the formula U : σ →τ, and D is the
result of applying (→e) to D1 and an assumption x:σ.) But [x].X ≡U.
Hence D1 gives
Γ
⊢
[x].X : σ →τ .

11D Abstraction
129
Case 4: X ≡X1X2 and [x].X
≡S([x]′.X1)([x]′.X2), where [ ]′ is
the same as [ ] if [ ] is [ ]η or [ ]w, but [ ]′ is [ ]η if [ ] is [ ]β.
In D, the formula X1X2 :τ must be the conclusion of rule (→e). (The
only other possibility is that it be in Γ; but then, by assumption, X1X2
would not contain x and we would be in Case 1 not Case 4.) Therefore
D must have form
D1
X1 : ρ→τ
D2
X2 : ρ
X1X2 : τ ,
(→e)
for some ρ. We are proving the theorem for three forms of [x] at once,
so in the induction hypothesis we can assume
Γ
⊢
([x]′.X1) : σ→ρ→τ,
Γ
⊢
([x]′.X2) : σ→ρ.
Now by axiom-scheme (→S) we have an axiom
S : (σ→ρ→τ)→(σ→ρ)→σ→τ.
Hence, by (→e) twice we get
Γ
⊢
S ([x]′.X1) ([x]′.X2) : σ→τ.
This completes Case 4 and the proof.
Note
The axiom-schemes for I, K and S exactly ﬁt the cases in the
preceding proof. If they had not already been motivated by analogy
with Iσ, Kσ,τ and Sρ,σ,τ in Chapter 10 (which were motivated by a λ-
analogy), this proof would have been their principal motivation.
Corollary 11.14.1 Let Γ be any set of TA→
C -formulas. If no subject in
Γ contains any of the (distinct) variables x1, . . . , xn, and
Γ, x1 :σ1, . . . , xn :σn
⊢TA→
C
X : τ,
and [ ] is any of [ ]η, [ ]w, [ ]β, then
Γ
⊢TA→
C
([x1, . . . , xn].X) : σ1 →. . .→σn →τ.
Corollary 11.14.2 If all subjects in Γ are atoms, the above theorem
and corollary extend to the abstraction algorithm [ ]f ab deﬁned in 9.26.

130
Simple typing, Curry-style in CL
Proof The proof of 11.14 needs no change. (But if Γ contained a compos-
ite subject, the statement in Case 4 that X1X2 :τ must be the conclusion
of rule (→e) would fail for [ ]f ab, and so would the theorem.)
Exercise 11.15∗Using Corollary 11.14.1, prove the following in TA→
C .
(a) Let C ≡[x, y, z].xzy; prove (for all types ρ, σ, τ):
C : (ρ →σ →τ) →σ →ρ →τ.
(b) Let D ≡[x, y, z].z(Ky)x, as deﬁned in (9) in Chapter 4, and
let Nτ
≡(τ →τ)→τ →τ. Prove, for all types τ:
D : τ →τ →Nτ →τ.
(c) Let RBernays be as deﬁned in Chapter 4 (11) and (14), i.e.
RBernays ≡[x, y, u]. u(Qy)(D0x)1,
where 0 ≡KI, σ ≡SB, 1 ≡(SB)(KI), and
Q ≡[y, v]. D (σ (v0)) (y (v0)(v1)).
For every type τ let τ ⋆≡NNτ →Nτ . Prove, for all τ:
RBernays : Nτ →(Nτ →Nτ →Nτ ) →Nτ ⋆→Nτ .
(Hint: since 0 ≡KI, it can be given an inﬁnite number of types
in TA→
C , and in your proof, two occurrences of 0 in RBernays must
be given two diﬀerent types, Nτ and NNτ .)
Exercise 11.16 The advantage of using Corollary 11.14.1 can be seen
by writing out the term C in Exercise 11.15(a) in terms of S, K and I, and
proving (a) directly from Theorem 11.14 without using that corollary.
11E
Subject-reduction
The second main theorem about TA→
C will show that type-assignments
are preserved by both weak and strong reduction. (If one thinks of a
type as a safety-label and reduction as a computation-process, it will
say that a term will not lose any labels during a computation; i.e. it will
not become less safe.)
The theorem’s proof will need the following deﬁnition and lemma.

11E Subject-reduction
131
Deﬁnition 11.17 (Inert assumptions)
A CL-term U will be called
[weakly or strongly] inert iﬀit is a normal form [weak or strong, respec-
tively] whose leftmost atom is a non-redex atom; i.e. iﬀit has form
U ≡qV1 . . . Vk
where q is an atom ̸≡I, K, S, and V1, . . . , Vk are normal forms. A set Γ
of TA→
C -formulas {U1 : π1, U2 : π2, . . .} will be called inert iﬀall of U1,
U2, etc. are inert.5
The following lemma says, roughly speaking, that if we replace a part
V of a term X by a new term W with the same type as V , then the
type of X will not change.
Lemma 11.18 (Replacement) Let Γ1 and Γ2 be any sets of TA→
C -
formulas, and let D be a deduction giving
Γ1 ⊢TA→
C
X :τ.
Let V be a term-occurrence in X, such that there is a formula V : ρ in
D in the same position as V has in the construction-tree of X. Let X⋆
be the result of replacing V by a term W such that
Γ2 ⊢TA→
C
W :ρ.
Then
Γ1 ∪Γ2 ⊢TA→
C
X⋆:τ.
Proof
First cut oﬀfrom D the subtree above the formula V : ρ. The
result is a deduction D1 with form
V : ρ
D1
X : τ.
(This notation means that D1 has conclusion X :τ and one of its assump-
tions is the formula V :ρ.) Then replace V by W in the assumption V :ρ
and make corresponding replacements in all formulas below it in D1.
The result is a deduction D1
⋆with form
W : ρ
D1
⋆
X⋆: τ.
5 In [HS86], ‘normal-subjects’ was used instead of ‘inert’.

132
Simple typing, Curry-style in CL
Then take the given deduction of W : ρ (call this deduction D2), and
place it over the assumption W :ρ in D1
⋆. The result is a deduction
D2
W : ρ
D1
⋆
X⋆: τ
as desired.
Theorem 11.19 (Subject-reduction)
Let Γ be a weakly [strongly]
inert set of TA→
C -formulas. If
Γ
⊢TA→
C
X :τ
and X ▷w X′ [X >−X′], then
Γ
⊢TA→
C
X′ :τ.
Proof The proofs for ▷w and >−ﬁrst appeared in [CF58, Sections 9C2,
9C6] and [CHS72, Section 14B2]. We shall keep to ▷w here for simplicity.
By the replacement lemma, it is enough to take care of the case that
X is a redex and X′ is its contractum.
Case 1: X ≡IX′. Let D be a deduction of IX′ : τ from Γ. By the
given condition on Γ, the formula IX′ : τ itself cannot be in Γ, nor can
the leftmost I in IX′ be a subject in Γ; hence this I must correspond to
an instance of axiom-scheme (→I). Therefore, using the correspondence
between deductions and term-constructions, D must have form
(→I)
I : τ →τ
D1
X′ : τ
IX′ : τ.
(→e)
That is, D must contain a deduction D1 of X′ :τ. Thus Γ ⊢X′ :τ.
Case 2: X ≡KX′Y . Let D be a deduction of KX′Y : τ from Γ. By
the given condition on Γ, none of KX′Y , KX′, K can be a subject in Γ;
hence the leftmost K in KX′Y must correspond to an instance of axiom-
scheme (→K). Therefore, using the correspondence between deductions
and term-constructions, D must have form (for some σ):
(→K)
K : τ →σ→τ
D1
X′ : τ
KX′ : σ→τ
(→e)
D2
Y : σ
KX′Y : τ.
(→e)

11E Subject-reduction
133
Therefore D must contain a deduction D1 of X′ :τ. Thus Γ ⊢X′ :τ.
Case 3: X ≡SUV W and X′ ≡UW(V W). Let D be a deduction of
SUV W :τ from Γ. None of SUV W, SUV , SU, S can be a subject in Γ,
so D must have the following form (for some ρ, σ):
(→S)
S : (ρ→σ→τ)→(ρ→σ)→ρ→τ
D1
U : ρ→σ→τ
SU : (ρ→σ)→ρ→τ
D2
V : ρ→σ
SUV : ρ→τ
D3
W : ρ
SUV W : τ.
From D1, D2, D3 we can construct a deduction of UW(V W):τ thus:
D1
U : ρ→σ→τ
D3
W : ρ
UW : σ→τ
D2
V : ρ→σ
D3
W : ρ
V W : σ
UW(V W) : τ.
Remark 11.20 (Subject-expansion)
It is natural to ask whether
the subject-reduction theorem can be reversed; that is, if X reduces to
X′, whether
Γ ⊢X′ :τ
=⇒
Γ ⊢X :τ.
The answer is that reversal is possible only under certain very restrictive
conditions, [CF58, Section 9C3].
For an example where reversal is not possible, take
(a)
X ≡SKSI,
X′ ≡KI(SI).
Here X ▷w X′, and ⊢TA→
C
X′ : σ →σ for all types σ, but, by Exercise
11.38 later, it is only possible to prove X :σ→σ for composite σ.
A stronger example of non-reversal is
(b)
X ≡SIII,
X′ ≡II(II).
In this case we can prove X′ :σ →σ for every σ, but X has no types at
all (by Example 11.37 later).
The non-reversibility of Theorem 11.19 means that the set of types
assigned to a term is not invariant under conversion. Thus the system
TA→
C is not as tidy as we might like. One way to tidy it up would be to

134
Simple typing, Curry-style in CL
add an equality-invariance rule to TA→
C , and this will be done in Section
11K. Since convertibility is not a recursively decidable relation, the new
rule will not be decidable, but we shall see that this apparently serious
problem will have less eﬀect than we might expect.
11F
Typable CL-terms
In this section we study pure terms, i.e. terms whose only atoms are
combinators and variables.
Some untyped terms have typed analogues in Chapter 10, for example
B, K and xz(yz); but others have not, for example xx. In this section
and the next, the set of untyped pure terms that have typed analogues
will be characterized precisely. This set will turn out to be decidable.
Deﬁnition 11.21 (Type-contexts)
A (type-)context is a ﬁnite or
inﬁnite set of TA→
C -formulas Γ = {x1 :ρ1, x2 :ρ2, . . .} whose subjects are
variables, and which is consistent in the sense that no variable receives
more than one type in Γ, i.e.
xi ≡xj =⇒ρi ≡ρj.
(1)
If X is a term, an FV(X)-context is a context whose subjects are exactly
the variables in FV(X).6
Note 11.22
(a)
The consistency condition says that a context is
essentially just a mapping from a set of term-variables, to types. For
example, the assumptions used in assigning a type to xx in Exercise
11.9(e) were x:ρ, x:ρ→σ; this pair does not form a context, because
it is not consistent.
(b) Contexts are inert, in the sense of Deﬁnition 11.17 (both weakly
and strongly). Hence the subject-reduction theorem applies to deduc-
tions from contexts.
Deﬁnition 11.23 (Typable pure terms)
Let X be any pure CL-
term, with FV(X) = {x1, . . . , xn} (n ≥0). We say X is typable7 iﬀ
6 The word ‘context’ has also another meaning in many books on λ and CL: a term
with ‘holes’ in it, cf. [Bar84, Deﬁnition 2.1.18].
For this reason, type-contexts
are often called ‘type-environments’. But the word ‘environment’ has also other
meanings, so ‘context’ is preferred in this book.
7 In Curry’s works and [HS86], typable terms were called ‘stratiﬁed’.

11F Typable CL-terms
135
there exist a context {x1 :ρ1, . . . , xn :ρn} and a type τ such that
x1 :ρ1, . . . , xn :ρn
⊢TA→
C
X :τ.
In particular, if n = 0, X is typable iﬀthere exists τ such that
⊢TA→
C
X :τ.
Example 11.24
(a) The following closed terms are typable (by 11.5–11.8 and 11.15):
I,
K,
S,
B,
W,
KK,
SB,
KI,
n,
D,
RBernays.
(b) The non-closed terms x and xz(yz) are typable, since
x:a ⊢TA→
C
x:a,
x:a→b→c, y:a→b, z :a
⊢TA→
C
xz(yz) : c.
(c) In contrast, xx is not typable. A TA→
C -deduction which assigned
a type to xx would have to have form
x : σ→τ
x : σ
xx : τ ,
(→e)
compare Exercise 11.9(e). But, as noted earlier, the two assump-
tions x:σ→τ, x:σ are not consistent.
In a sense, xx represents the most general possible self-app-
lication.
Self-applications were not allowed at all in Chapter
10; they were regarded as too ‘risky’.
But in this chapter we
allow ourselves to come closer to danger; some particular self-
applications such as KK are typable, but not xx.
Lemma 11.25
(a) A pure CL-term X is typable iﬀevery subterm of X is typable.
(b) A pure CL-term X is typable iﬀthere exist closed types ρ1, . . . ,
ρn, τ satisfying Deﬁnition 11.23.
(c) The set of all typable pure CL-terms is closed under weak and
strong reduction, but not expansion.
(d) The set of all typable pure CL-terms is closed under [ ]-abstract-
ion, but not under application.

136
Simple typing, Curry-style in CL
Proof (a) By the subject-construction property in Section 11C.
(b) By the type-substitution lemma, 11.11.
(c) By the subject-reduction theorem (11.19), and Remark 11.20.
(d) By 11.14 and 11.14.2, and the result in 11.24 that x is typable
but xx is not.
Theorem 11.26 (Decidability of typability) The set of all typable
pure CL-terms is decidable.
Proof
The principal-type algorithm in [Cur69] or [Hin69, Theorem 1]
includes a decision-procedure to tell whether a term is typable; see The-
orem 11.36 below.
Theorem 11.27 (SN theorem for ▷w) Every typable pure CL-term
is strongly normalizable with respect to ▷w. Further, if Γ is weakly inert
and Γ ⊢TA→
C X :τ, then X is SN with respect to ▷w.
Proof See Corollary 11.56.1 later.
Corollary 11.27.1 (WN theorem for ▷w)
Every typable pure CL-
term has a weak normal form.
Theorem 11.28 (WN theorem for >−) Every typable pure CL-term
has a strong normal form.8
Proof A proof is in [HLS72, Italian edition, Theorems 9.19–9.21].9
Corollary 11.28.1 In CL, the ﬁxed-point combinators YTuring and
YCurry−Ros in Deﬁnition 3.4 are untypable.
Proof By 9.19(e), these combinators have no strong nf.
8 No SN theorem for strong reduction is known; see Remark 10.27.
9 In Theorem 9.19, the second ‘M’ should be ‘X’. The English edition has a less
trivial error: the Y in the conclusion of Theorem 9.19 should be a Y ⋆such that
Y >−Y ⋆, and Theorem 9.20 needs a similar change; but Theorem 9.21 is correct.

11G Link with Church’s approach
137
11G
Link with Church’s approach
The deﬁnition of ‘typable term’ in 11.23 was obviously intended to imi-
tate the deﬁnition of ‘typed term’ in Chapter 10. And indeed, for closed
terms the connection is straightforward, as will be shown below. But
for terms containing variables, there will be a slight complication.
We assume here that the type-constants in Deﬁnition 11.1 are the
same as the atomic types in Chapter 10.
Deﬁnition 11.29 For every typed CL-term Y τ , deﬁne |Y τ | to be the
untyped term obtained by deleting all type-superscripts from Y τ . In
particular, deﬁne
|S(ρ→σ→τ )→(ρ→σ)→ρ→τ | ≡S,
|Kσ→τ →σ| ≡K,
|Iσ→σ| ≡I,
|xτ | ≡x.
If X is untyped and |Y τ | ≡X, we call Y τ a typed analogue of X.
A single untyped term may have many typed analogues, for example
I ≡|IN→N| ≡|I(N→N)→(N→N)| ≡etc.
So the correspondence between terms in Chapters 10 and 11 is not one-
to-one. However, if in Chapter 11 we pass from terms to TA→
C -proofs,
the correspondence between the two chapters becomes one-to-one, at
least for closed pure terms and closed types. (A closed type contains no
type-variables, and hence is a genuine type in both Chapters 10 and 11.)
Let τ be closed. By following the clauses in Deﬁnition 10.5, we can see
that every closed pure typed term Y τ can be re-written as a TA→
C -proof.
Conversely, every TA→
C -proof of a formula X : τ can be re-written as a
typed term Y τ with |Y τ | ≡X. In fact, closed pure typed terms and
TA→
C -proofs are just diﬀerent notations for the same ideas.
This gives the following lemma.
Lemma 11.30 A closed pure CL-term X is typable iﬀit has a typed
analogue, i.e. a Y τ such that |Y τ | ≡X.
Proof By 11.25(b) and by comparing Deﬁnitions 10.5, 11.23 and 11.29.10
10 In [HS86] the condition ‘closed’ was wrongly omitted from the lemma on p. 186
corresponding to 11.30.

138
Simple typing, Curry-style in CL
Discussion 11.31 (Non-closed terms) Let Y τ be a pure typed term
containing variables, say FV(Y τ ) = {xρ1
1 , . . . , xρn
n } (n ≥1). Then Y τ
can easily be re-written as a TA→
C -deduction, giving
x1 :ρ1, . . . , xn :ρn
⊢TA→
C
X :τ
(where X ≡|Y τ |).
However, the converse procedure, re-writing TA→
C -deductions as typed
terms, needs a little care, because not every TA→
C -deduction D corre-
sponds to a typed term, even when all types in D are closed. To see
this, let xτ be any typed variable and let σ ̸≡τ. Then, by the consis-
tency condition in Deﬁnition 10.3, xσ is not a typed variable. Hence the
one-step deduction which gives
x:σ
⊢
x:σ
does not correspond to a typed term.
In fact, referring to Note 10.4, the only TA→
C -deductions that corre-
spond to typed terms are those whose assumptions are in the inﬁnite
set

vψ(i,j) :τi
: 1 ≤i, 1 ≤j

.
For such deductions, the correspondence with typed terms is one-to-one.
11H
Principal types
The axioms and rule of TA→
C allow more than one type to be assigned
to a term; this raises the natural question of what the set of types
assigned to a term looks like. The present section will show that if a
pure term is typable, all its types turn out to be substitution-instances
of one ‘principal type’. Thus the situation described for I, K and S in
Note 11.12 holds for composite terms as well as atoms.
Deﬁnition 11.32 (Principal type, p.t.)
Let X be any pure CL-
term, with FV(X) = {x1, . . . , xn} (n ≥0).
(a) If n = 0: a principal type or p.t. of X is any type π such that
(i) ⊢TA→
C X :π, and
(ii) if ⊢TA→
C X :τ then τ is a substitution-instance of π.
(b) If n ≥0: a pair ⟨Γ, π⟩is a principal pair (p.p.) of X, and π is a
p.t. of X, iﬀ

11H Principal types
139
(i) Γ is an FV(X)-context and Γ ⊢TA→
C X :π, and
(ii) if Γ′ ⊢TA→
C X : τ for some FV(X)-context Γ′ and type τ,
then ⟨Γ′, τ⟩is a substitution-instance of ⟨Γ, π⟩.
Notation In the above deﬁnition a substitution-instance of a pair ⟨Γ, π⟩
is a pair ⟨Γ′, π′⟩that is the result of a simultaneous substitution
[ρ1/a1, . . . , ρk/ak]
of types for type-variables in π and the predicates in Γ. The subjects in
Γ are unchanged.
Example 11.33 The term SKK has a principal type a→a.
Proof
If there exists a TA→
C -proof of SKK : τ for some τ, that proof
must follow the construction of SKK, so it must have form
(→S)
S : ρ→σ→τ
(→K)
K : ρ
SK : σ→τ
(→e)
(→K)
K : σ
SKK : τ .
(→e)
(2)
for some ρ, σ, τ. The formula K:σ must be an instance of axiom-scheme
(→K). Hence σ must have form µ →ν →µ for some µ, ν. We record
this ‘equation’:
σ ≡µ→ν →µ.
(3)
Next, the formula S : ρ →σ →τ must be an (→S)-axiom, and all such
axioms have form
S : (ξ →η→ζ)→(ξ →η)→ξ →ζ ;
hence, for some ξ, η, ζ,
ρ ≡ξ →η→ζ,
σ ≡ξ →η,
τ ≡ξ →ζ .
(4)
Also the formula K:ρ must be a (→K)-axiom, so
ρ ≡ξ →η→ξ.
(5)
A type can be assigned to SKK iﬀthe ﬁve equations in (3)–(5) can
be solved simultaneously, and the p.t. of SKK will be given by the most
general possible solution of these equations.
The two equations for ρ in (4) and (5), and those for σ in (3) and (4),
imply that
ζ ≡ξ,
ξ ≡µ,
η ≡ν →µ.
(6)

140
Simple typing, Curry-style in CL
These equations can be solved by taking any types µ, ν, and setting
ζ ≡ξ ≡µ and η ≡ν →µ. Then (4) can be satisﬁed by setting
ρ ≡µ→(ν →µ)→µ,
τ ≡µ→µ.
(7)
To get the most general solution we take µ, ν to be type-variables a, b.
This gives the following TA→
C -proof:
(→S)
S : (a→(b→a)→a)→(a→b→a)→a→a
(→K)
K:a→(b→a)→a
SK:(a→b→a)→a→a
(→K)
K:a→b→a
SKK : a→a .
Example 11.34
The term xI has a principal type b and a principal
pair
 
x:(a→a)→b

, b

.
Proof If there exists a deduction giving Γ ⊢TA→
C xI : τ for some τ and
some FV(xI)-context Γ, it must have form
x : ξ →τ
(→I)
I : ξ
xI : τ
(→e)
for some ξ. But I : ξ must be an (→I)-axiom, so ξ ≡η →η for some η.
Hence the deduction must have form
x : (η→η)→τ
(→I)
I : η→η
xI : τ .
(→e)
(8)
Conversely, for all types η, τ, the above is a genuine TA→
C -deduction.
By taking the special case η ≡a, τ ≡b, we get a deduction
x : (a→a)→b
(→I)
I : a→a
xI : b .
(→e)
(9)
Hence
x:(a→a)→b
⊢TA→
C
xI:b.
(10)

11H Principal types
141
Also, if x:ρ ⊢TA→
C xI:τ for some ρ and τ, then ρ ≡(η →η)→τ by (8),
so the pair ⟨{x:ρ}, τ ⟩must be a substitution-instance of
 
x:(a→a)→b

, b

.
Remark 11.35 (Pseudo-uniqueness of p.t.) Example 11.33 showed
that a→a is a p.t. of SKK. Clearly c→c and d→d, etc. are also p.t.s.
So the p.t. of a term is not unique. However, it is easy to see that the
p.t.s of a term X diﬀer only by the substitution of distinct variables for
distinct variables, and it is normal to say ‘the p.t. of X’ as if it was
unique.
Theorem 11.36 (Principal-types theorem) Every typable pure CL-
term has a principal type and a principal pair.
Proof Full proofs are in [Cur69] and [Hin69, Theorem 1]; they also give
Theorem 11.26, the decidability of typability.
We just outline the method here. The key is the subject-construction
property in Section 11C, that the deduction-tree for a formula X :τ must
follow the structure of the construction-tree of X. To decide whether a
pure term X is typable, one writes down the construction-tree of X and
tries to ﬁll in a suitable type at each stage, conforming to the patterns
demanded by the axiom-schemes and rule (→e).
If there is no way to ﬁll in the types that is consistent with these
patterns, the attempt will lead to a contradiction, and one can conclude
that X is not typable. But if suitable types can be ﬁlled in throughout
the tree, the process of ﬁlling them in will indicate the most general
possible type at each stage, and the type at the bottom of the tree will
be a principal type for X.
The method can be seen in action in the examples before this theorem.
In an example below it will be applied to prove that a particular term
is untypable.
This procedure can be written out as a formal algorithm, known as
the principal-type algorithm (or the type-reconstruction or type-infer-
ence algorithm). It is part of the type-inference algorithm used in the
programming language ML, see [Mil78]. A comprehensive introduction
to the algorithm is in [Pie02, Chapter 22].
A detailed account of a
version for pure λ-terms is in [Hin97, Chapter 3], including a proof that
the algorithm works.

142
Simple typing, Curry-style in CL
Example 11.37 The term SII is untypable.
Proof A TA→
C -proof of SII:τ would have form
(→S)
S : ρ→σ→τ
(→I)
I : ρ
SI : σ→τ
(→e)
(→I)
I : σ
SII : τ .
(→e)
(11)
Reading upward: ﬁrst, the formula I:σ would have to be an (→I)-axiom,
so, for some type ν,
σ ≡ν →ν.
(12)
The formula I:ρ would also have to be an (→I)-axiom, so, for some µ,
ρ ≡µ→µ.
(13)
Finally, the (→S)-axiom in the above proof would have to have form
S : (ξ →η→ζ)→(ξ →η)→ξ →ζ
for some ξ, η, ζ; hence
ρ ≡ξ →η→ζ,
σ ≡ξ →η,
τ ≡ξ →ζ.
(14)
The two equations for ρ in (13) and (14), and the two for σ in (12) and
(14), imply that
µ ≡ξ,
µ ≡η→ζ,
ν ≡ξ,
ν ≡η.
(15)
Hence
η→ζ
≡
µ
≡
ξ
≡
ν
≡
η ,
which is impossible because η→ζ is a longer expression than η.
Exercise 11.38
Prove that SKSI is typable and has a principal type
(a→b)→a→b.
Summary 11.39
The following is a table of some pure terms and
their principal types. (The term RBernays from Example 11.15(c) is not
included; the type assigned to it in that example was not principal.)
Term
Principal type
I
a→a
K
a→b→a

11I Adding new axioms
143
S
(a→b→c)→(a→b)→a→c
B
(≡S(KS)K)
(b→c)→(a→b)→a→c
C
(≡S(BBS)(KK))
(a→b→c)→b→a→c
W
(≡SS(KI))
(a→a→b)→a→b
CI
a→(a→b)→b
CB
(a→b)→(b→c)→a→c
SKSI
(a→b)→a→b
σ
(≡SB)
((b→c)→a→b)→(b→c)→a→c
0
(≡KI)
a→b→b
1
(≡SB(KI))
(a→b)→a→b
n
(n ≥2)
(a→a)→a→a
(≡Na)
D
(≡[x, y, z].z(Ky)x)
a1 →a2 →((b→a2)→a1 →c)→c.
11I
Adding new axioms
The system TA→
C can be extended by adding extra axioms, either by
adding new atomic terms with appropriate type-assignment axioms for
each new atom, or by assigning new types to old terms to express some
special role these terms may have.
We shall call a set of proposed new axioms a basis.
Example 11.40 (The arithmetical basis BZ)
The arithmetical extension of CL was introduced in Discussion 4.25
and Deﬁnition 4.26. It was made by adding three new atoms 0, σ, Z to
the deﬁnition of term (for zero, successor and iterator) and adding the
following contractions to the deﬁnition of weak reduction:
Z n
▷wZ n

n ≡(SB)n(KI), n = 0, 1, 2, . . .

.
(16)
Corresponding to this, let the arithmetical basis BZ be the following set
of formulas:
0 : N,
σ : N →N,
Z : N →Nτ ,
(17)
where N is a type-constant and Nτ is (τ →τ) →τ →τ (cf. Exercise
11.8(g)). In the third part of (17) there is one formula for each type
τ. Hence BZ is an inﬁnite set. But all the formulas Z : N →Nτ are

144
Simple typing, Curry-style in CL
substitution-instances of Z:N→Na, so these formulas could be summa-
rized by one ‘principal axiom’.
Exercise 11.41 Given 0, σ, Z as above, let R be the recursion operator
deﬁned in Chapter 4 (32), namely
Q
≡
[y, v]. D (σ(v0)) (y(v0)(v1)),
R
≡
[x, y, u]. Z u (Qy)(D0x) 1 ,



(18)
where n ≡(SB)n(KI) and D ≡[x, y, z].z(Ky)x. Prove that
BZ
⊢TA→
C
R : N→(N→N→N)→N→N.
(19)
Example 11.42 (Two bases for the Church numerals) Suppose
we take pure terms, and a type-constant N, and look at the Church
numerals. It seems natural to wish to add axioms assigning the following
new types to the combinators for zero and successor:
KI : N,
SB : N →N.
(20)
Alternatively, the following could be added as an inﬁnite set of new
axioms:
(SB)n(KI) : N
(n = 0, 1, 2, . . .).
(21)
Example 11.43 (Proper inclusions)
A new axiom with the form
I : µ→ν
(22)
for some types µ, ν with µ ̸≡ν, says intuitively that the identity operator
maps µ into ν, i.e. that µ is a subset of ν. Such an axiom is called a
proper inclusion. By rule (→e),
X :µ, I:µ→ν
⊢
IX :ν.
To use proper inclusions eﬀectively, one needs to be able to deduce X :ν
from IX : ν. But we cannot do this by the subject-reduction theorem,
since a proper inclusion is not inert in the sense of Deﬁnition 11.17. In
fact there is no way to deduce X :ν in TA→
C as it stands, so when proper
inclusions are of interest a rule of equality-invariance of types has to be
added to TA→
C ; see Section 11K below.

11I Adding new axioms
145
Deﬁnition 11.44 (Monoschematic bases)
A set of TA→
C -formulas
B =

U1 :π1,
U2 :π2,
U3 :π3, . . .

is called a monoschematic basis iﬀeach Ui is a non-redex constant and
B contains a ‘principal axiom’ for each Ui like the principal axioms for
I, K and S in Note 11.12. More precisely, B is monoschematic iﬀeach
Ui is a non-redex constant and, for each constant U occurring as a
subject in B (say U ≡Ui1 ≡Ui2 ≡Ui3 ≡. . .), there is one ij such that
{πi1 , πi2 , πi3 , . . .} is exactly the set of all substitution-instances of πij .
(The formula Uij :πij is called the principal axiom for U in B.)
Remark 11.45 An example of a monoschematic basis is BZ in Example
11.40. But the bases in Examples 11.42–11.43 are not monoschematic,
because their subjects are not non-redex constants.
If a basis is monoschematic, it has many of the convenient properties
of the axioms for I, K and S. For example, it is closed under substitu-
tion, so in Lemma 11.11, if Γ is a monoschematic basis we can replace
‘[σ1/a1, . . . , σk/ak]Γ’ by just ‘Γ’.
Every monoschematic basis is inert (because its subjects are non-redex
constants).
Deﬁnition 11.46 (Relative typability)
Let B be any set of TA→
C -
formulas. Let X be any CL-term, with FV(X) = {x1, . . . , xn} (n ≥0).
(a) We call X typable relative to B iﬀthere exist a context {x1 :ρ1,
. . . , xn :ρn} and a type τ such that
B, x1 :ρ1, . . . , xn :ρn
⊢TA→
C
X :τ.
(b) We call a type π a principal type of X relative to B, and a pair
⟨Γ, π⟩a p.p. of X relative to B, iﬀ
(i) Γ is an FV(X)-context and B ∪Γ ⊢TA→
C X :π, and
(ii) if B ∪Γ′ ⊢TA→
C X :τ for some FV(X)-context Γ′ and type
τ, then ⟨Γ′, τ⟩is a substitution-instance of ⟨Γ, π⟩.
Remarks 11.47 (Extending previous theorems) Suppose TA→
C is
extended by adding a basis B, and suppose B is monoschematic or inert.
Then the abstraction-and-types theorem (11.14) can easily be shown
to still hold.
The principal-types theorem (11.36) holds for p.t. and p.p. relative to
B, if B is monoschematic.

146
Simple typing, Curry-style in CL
The decidability of typability (11.26) does not extend to relative typ-
ability unless B satisﬁes some decidability conditions.
The strong normalization theorem (11.27) still holds for ▷w if B is
weakly inert. That is, every term typable relative to a weakly inert B is
SN with respect to ▷w.
Further, for the particular basis BZ in 11.40, the SN theorem ex-
tends in another sense. Let ▷wZ be the modiﬁed reduction suggested
in 11.40(16); then the subject-reduction theorem and SN theorem both
hold for ▷wZ. (The former is easy to prove; for the latter, see Theorem
A3.22 in Appendix A3.)
Remark 11.48 (Extending subject-reduction)
Let TA→
C be ex-
tended by adding a basis B.
(a) If B is weakly or strongly inert, then the subject-reduction theo-
rem (11.19) still holds, for ▷w or >−as appropriate, since the union of
two inert assumption-sets is clearly inert.
Further, this theorem also holds for some non-inert bases. For exam-
ple, its proof still works if the condition on the set Γ in 11.19 is relaxed
slightly, to say that every subject in Γ is in nf, and if a subject in Γ
begins with S, K or I, then every type that Γ gives to it is atomic. An
example of such a set Γ is the basis

(SB)n(KI):N : n = 0, 1, 2, . . .

in Example 11.42 (21), so the subject-reduction theorem holds for that
basis, even though it is not inert.
(b) In contrast, an example of a basis for which the theorem’s con-
clusion fails, yet might have some interest, is
0 : N,
BW(BB) : N →N ,
where 0 ≡KI as usual. The interest is that BW(BB) behaves rather
like σ, since
BW(BB)nxy
▷w
W(BBn)xy
where n ≡(SB)n(KI),
▷w
BBnxxy
▷w
B(nx)xy
▷w
nx(xy)
▷w
xn(xy)
by 4.3
≡
xn+1y.
The theorem’s conclusion fails for this basis because, although we can

11J Propositions-as-types
147
easily deduce BW(BB)0 : N from this basis, and easily see that
BW(BB)0 ▷w W(BB0) ,
there is no way to deduce W(BB0):N from this basis.
11J
Propositions-as-types and normalization
Discussion 11.49 (Propositions as types) A type such as a→b→a,
which is open, i.e. contains no type-constants, can be interpreted as a
formula of propositional calculus by reading ‘→’ as implication.
Further, if D is a TA→
C -deduction whose types are all open, and we
remove all subjects from D, then the result will be a deduction in propo-
sitional calculus. This is because the above transformation changes rule
(→e), which says
X :σ→τ
Y :σ
XY :τ ,
to the propositional rule of modus ponens, which says
σ→τ
σ
τ ,
and changes the axiom-schemes (→I), (→K) and (→S) to provable
formula-schemes of propositional calculus, namely
σ→σ,
σ→τ →σ,
(ρ→σ→τ)→(ρ→σ)→ρ→τ .
For example, if this transformation is carried out on the deduction of
SKK : σ →σ in Example 11.6, the result is the following propositional
deduction of σ→σ:
(σ→(σ→σ)→σ)→(σ→σ→σ)→σ→σ
σ→(σ→σ)→σ
(σ→σ→σ)→σ→σ
σ→σ→σ
σ→σ .
Furthermore, the term SKK which has been deleted from the conclu-
sion determines the tree-structure of the propositional deduction. Even
better, the whole propositional deduction can be coded as a single typed
term
Sσ,σ→σ,σKσ,σ→σKσ,σ

148
Simple typing, Curry-style in CL
in the system of Chapter 10, if we extend that system by allowing its
types to contain variables.
Thus, roughly speaking, open types correspond to propositional for-
mulas, and typed terms correspond to propositional deductions.
More precisely, the correspondence is not with the propositional cal-
culus which arises from classical truth-table logic, but with that which
arises from intuitionistic logic, which is weaker but plays a crucial role in
studying the foundations of computing. Intuitionistic logic is described
in several books and websites, for example, [TS00, Section 2.1.1, system
Ni] and [SU06, Chapter 2]. In it, certain classical tautologies are not
provable, for example the formula known as Peirce’s law (after Charles
Sanders Peirce),
((a→b)→a)→a.
This logic has other connectives besides implication, but since simple
types have only ‘→’, they correspond only to the implicational fragment
of intuitionistic logic.
This correspondence is called the propositions-as-types or Curry–How-
ard correspondence. The propositions-to-types part was ﬁrst hinted at in
[Cur34, p. 588] and ﬁrst described explicitly in [CF58, Section 9E]. The
deductions-to-terms part was described in [How80] (written in 1969). A
number of other people also noticed the correspondence in the 1960s
and extended it to other connectives and quantiﬁers. Some sources are
[L¨au65], [L¨au70] and [Sco70a], also [Bru70], in which it was used as the
basis of the proof-system Automath.
Deﬁnition 11.50 A type σ is said to be inhabited if and only if there
is a closed term M such that
⊢M : σ.
Under the propositions-as-types correspondence, inhabited types cor-
respond to provable propositional formulas, and the closed terms which
inhabit them correspond to propositional proofs.
Non-closed terms, i.e. terms containing free variables, correspond, not
to proofs, but to deductions from assumptions.
The correspondence between terms and deductions plays an important
role in the study of deductions and their structure. Indeed, in the proof-
theory book [TS00] it is introduced in the ﬁrst chapter, and in at least
three other books it has been made the main theme: [GLT89], [Sim00]
and [SU06].

11J Propositions-as-types
149
Discussion 11.51 (Reducing deductions) The deductions-to-terms
correspondence suggests that we should be able to reduce or simplify
deductions just like terms, and perhaps deﬁne a concept of irreducible
or ‘simplest’ deduction of a formula, corresponding to terms in normal
form, and even prove conﬂuence and normalization theorems for deduc-
tions, corresponding to those theorems for typed terms. And indeed all
this can be done, [TS00, Chapter 6].
In fact, the theory of proof-reductions was begun independently of the
correspondence with terms, by Dag Prawitz in 1965 [Pra65], and it is
now a standard tool in proof-theory. The correspondence with terms has
helped illuminate parts of this theory, and it, in turn, has illuminated
parts of the theory of typed terms, for example the strong normalization
theorem, 10.26.
To get a little of its ﬂavour, let us just sketch the basic deﬁnitions for
a reduction-theory of deductions. Since the present book is not about
propositional logic, we shall do it for TA→
C -deductions, not propositional
deductions. (The latter are described, for example, in [Pra65] and [TS00,
Chapter 6].)
Deﬁnition 11.52 (Deduction-reductions for TA→
C )
A reduction
of one deduction to another consists of a sequence of replacements by
the following three reduction-rules.
I-reductions for deductions:
A deduction of the form
I:τ →τ
D1
X :τ
IX :τ
(→e)
D2
may be reduced to
D1
X :τ
D2′ ,
where D2′ is obtained from D2 by replacing appropriate occur-
rences of IX by X.

150
Simple typing, Curry-style in CL
K-reductions for deductions:
A deduction of the form
K:τ →σ→τ
D1
X :τ
KX :σ→τ
(→e)
D2
Y :σ
KXY :τ
(→e)
D3
may be reduced to
D1
X :τ
D3′ ,
where D3′ is obtained from D3 by replacing appropriate occur-
rences of KXY by X.
S-reductions for deductions:
A deduction of the form
S:(ρ→σ→τ)→(ρ→σ)→ρ→τ
D1
X :ρ→σ→τ
SX :(ρ→σ)→ρ→τ
D2
Y :ρ→σ
SXY :ρ→τ
D3
Z :ρ
SXY Z : τ
D4
may be reduced to
D1
X :ρ→σ→τ
D3
Z :ρ
XZ :σ→τ
D2
Y :ρ→σ
D3
Z :ρ
Y Z :σ
XZ(Y Z) : τ
D4′ ,
where D4′ is obtained from D4 by replacing appropriate occur-
rences of SXY Z by XZ(Y Z).
Remark 11.53
Let Γ be any set of TA→
C -formulas, and let D be a
deduction giving
Γ
⊢TA→
C
X :τ .
(a) From the above deﬁnition it is clear that if a reduction of D is

11J Propositions-as-types
151
possible, then X must contain a weak redex. Also, if D reduces to D′,
then X will be weakly reduced to a term X′, and D′ will give
Γ
⊢TA→
C
X′ :τ
(X ▷w X′) .
(b)
Conversely, if X contains a weak redex, and Γ is weakly inert,
then by the proof of the subject-reduction theorem (11.19) a reduction
of D is possible. And if X ▷w Y , then D can be reduced to a deduction
giving
Γ
⊢TA→
C
Y :τ .
(c) A deduction that cannot be reduced is called normal.
One of the most important properties of deduction-reductions is that
they cannot go on for ever. This can be proved directly, but here it will
be deduced from the corresponding property for typed terms (Theorem
10.26), via the following deﬁnition and lemma.
Deﬁnition 11.54 (Assignment of typed terms to deductions) To
each deduction D in TA→
C , assign a typed term T(D) as follows. This
T(D) will encode just enough of the structure of D to serve in the proof
of the SN theorem and no more.
First, choose any atomic type from the deﬁnition of types in 10.1 (call
it c), and substitute c for all type-variables in D. Call the result D′.
Then, for each type τ, choose one typed term-variable, call it vτ .
Assign a typed term to each part of D′, thus:
(a) to an assumption x:ρ, assign vρ;
(b) to an assumption U :ρ where U is not a variable, assign vρ;
(c) to an axiom I:σ→σ, assign Iσ;
(d) to an axiom K:σ→τ →σ, assign Kσ,τ ;
(e) to an axiom S:(ρ→σ→τ)→(ρ→σ)→ρ→τ, assign Sρ,σ,τ ;
(f) to the conclusion of an application of rule (→e), say
U : σ→τ
V : σ
UV : τ ,
(→e)
assign (Xσ→τ Y σ)τ , where Xσ→τ
has been assigned to the
premise U :σ→τ, and Y σ to the premise V :σ.

152
Simple typing, Curry-style in CL
The typed term T(D) contains only one variable of each type (though
that variable may occur many times), and contains no non-redex con-
stants. But it contains all the occurrences of S, K and I that have been
introduced into D by axioms, and this is enough to give us the following
key lemma.
Lemma 11.55 Let D, E be any TA→
C -deductions, and let D reduce to E
by one of the replacements in Deﬁnition 11.52. Then T(D) reduces to
T(E) by one weak contraction.
Proof Straightforward.
Theorem 11.56 (SN for deductions)
Every reduction of a TA→
C -
deduction is ﬁnite.
Proof
Suppose we had an inﬁnite reduction of deductions. Then, by
Lemma 11.55, we would get an inﬁnite weak reduction of typed terms.
But this would contradict the SN theorem for these terms, Theorem
10.26.
Corollary 11.56.1 (SN for CL-terms) Let Γ be weakly inert, and let
Γ ⊢TA→
C X :τ. Then all weak reductions of X are ﬁnite.
Proof By the theorem and Remark 11.53(b).
Remark 11.57
If the inertness condition in the above corollary is
omitted, the corollary might fail. In fact we could have a deduction D
giving
Γ ⊢TA→
C X :τ ,
such that D was normal but X had an inﬁnite reduction. For example,
let X ≡YK where Y is a ﬁxed-point combinator, and let Γ = {YK:τ}
for some τ; then Γ ⊢YK:τ by a one-step normal deduction; but YK has
no weak normal form.
However, there are some non-inert assumption-sets for which the con-
clusion of the corollary is true or partly true. Two such sets have been
used in the literature as bases of axioms for extensions of TA→
C ; they are
discussed in the following two remarks.

11J Propositions-as-types
153
Remark 11.58 (Bases with a universal type)
Suppose there is a
type-constant ω (standing for the universal set), and suppose a basis B
contains a formula X :ω for every term X. Then B is clearly not inert.
However, suppose the part of B left over after all the formulas X :ω are
removed is weakly inert. Then, if D is a normal deduction giving, say,
B ⊢TA→
C Y :τ ,
all weak redexes in Y will be in components which receive type ω in D.
(See [Sel77, pp. 26–27], where, as in the work of Curry, ω is called E.)
With a basis B that assigns a type ω to every term, types no longer
serve as ‘safety labels’; instead, they become labels describing a term’s
behaviour in some more complex way. For example, the system called
intersection types that originated in [Sal78] and [CDS79] contains such a
basis; in that system, the rules allow other types to be assigned besides
ω, and it can be proved that the positions of the ω’s in a term’s types
indicate certain aspects of the term’s reduction-behaviour, for example
whether it has a normal form. (More references on this system are in
the list of further reading at the end of Chapter 12.)
Remark 11.59 (Bases with proper inclusions)
Suppose a basis
B contains a proper inclusion I : µ →ν (see Example 11.43). Then B is
clearly not inert. Further, if an assumption I:µ→ν is used in a normal
deduction D of a formula Y :τ, there can easily be a redex in Y .
For example, let a, b, c, d be type-variables, let G and H be non-redex
atoms, and let
B
=

I : (a→b)→c→d,
G:b,
H :c

.
Then, using the axiom K:b→a→b, we can easily deduce
B
⊢TA→
C
I(KG)H :d
by a normal deduction. Yet I(KG) is a redex; furthermore, if this redex
is contracted to KG, then the term becomes KGH, which is also a redex.
This shows that contracting all redexes of the form IU need not lead to
a term in normal form.
However, if that part of B left over when the proper inclusions are
removed is inert, then it can be proved that B ⊢Y : τ implies that Y
has a normal form, provided that each proper inclusion I : µ →ν in B
satisﬁes either of the following two conditions: (1) ν is a type-constant;
or (2) for each term U such that B ⊢U : µ and for each n ≥0, each
reduction of Ux1 . . . xn proceeds entirely inside U. (See [Sel77, Remark
2, p. 23].)

154
Simple typing, Curry-style in CL
Proper inclusions satisfying (1) can occur in a system of transﬁnite
type theory, where a type constant T is made into a transﬁnite type by
postulating I:µ→T for every ﬁnite type µ. (See [And65].)
To see an application of condition (2), it is necessary to consider a type
theory that is to include statements about types. In this case each type
must be a term. This can be accomplished by making each type-constant
a non-redex constant, each type-variable an ordinary term-variable, and
taking another non-redex constant, say F (Curry’s notation), so that
σ →τ will be regarded as an abbreviation for Fστ. Then if H is the
type-constant of propositions, we can turn each type into a propositional
function by making a new type-constant L, postulating τ :L for each type
τ in which L does not occur, and postulating the proper inclusion
I : L→τ →H
for each type τ in which L does not occur. (See [CHS72, Chapter 17].)
Remark 11.60 (βη-reducing a deduction)
It is possible to add
to the deﬁnition of deduction-reduction (11.52) the following new rule,
analogous to the deﬁnition of strong reduction of terms (Deﬁnition 8.15):
βη-strong reductions for deductions If
x:σ
D1
X :τ
reduces to
x:σ
D2
Y :τ
and the corresponding deductions obtained by Theorem 11.14
are
D1′
[x]η .X : σ→τ
and
D2′
[x]η .Y : σ→τ ,
then
D1′
[x]η .X : σ→τ
D3
reduces to
D2′
[x]η .Y : σ→τ
D3′,
where D3′ is obtained from D3 by replacing appropriate occur-
rences of [x].X by [x].Y .
It has been proved [Sel77, Remark 3, p. 24] that every deduction from
a strongly inert basis has a normal form with respect to this ‘strong’
reduction.

11K The equality-rule Eq ′
155
11K
The equality-rule Eq′
As we have seen in Remark 11.20, TA→
C is not invariant under combi-
natory equality. For example, SKSI does not have all of the types that
KI(SI) has; furthermore, although II(II) has p.t. a→a, SIII is untypable.
In a system using combinators this is a defect, because the usefulness
of combinators comes from the transformations that can be carried out
using their reduction properties. To remedy this defect we can add the
following rule:
Rule Eq′
X : τ
X =⋆Y
Y : τ ,
where ‘=⋆’ stands for =w, =Cβ, or the extensional equality =Cext. Of
course this is really three rules; when we need to distinguish them, they
will be called, respectively,
Eq′
w ,
Eq′
β ,
Eq′
ext .
Deﬁnition 11.61 (The systems TA→
C=)
The systems TA→
C=w,
TA→
C=β and TA→
C=ext are deﬁned by adding the above rules Eq′w, Eq′β
and Eq′ext, respectively, to the deﬁnition of TA→
C (Deﬁnition 11.5).
The name TA→
C= will mean any or all of these systems, according to
context.
Remark 11.62 (Undecidability)
Note that the relation ⊢X : τ
in TA→
C= is undecidable, unlike that in TA→
C
which is decidable (see
Theorem 11.26). The underlying reason for this is that in systems with
rule Eq′, deductions need not follow the constructions of the terms as
they do in TA→
C (see Section 11C), because it is possible for a deduction
in TA→
C= to consist of a TA→
C -deduction followed by an inference by rule
Eq′. Since combinatory equality is undecidable, so is TA→
C=.
Discussion 11.63 It might seem that, since rule Eq′ can occur anywhere
in a deduction, TA→
C= is a much richer system than TA→
C . But this is
not the case. Every deduction in TA→
C= can be replaced by one in which
rule Eq′ occurs only at the end.
For, suppose an inference by Eq′ occurs before the end of a deduction.
Then its conclusion is a premise for an inference by (→e), or else for
another inference by Eq′. Since equality is transitive, successive infer-
ences by Eq′ can always be combined into one; so we may assume that

156
Simple typing, Curry-style in CL
the next rule is (→e), and assume our deduction has one of the forms
D1
X : σ→τ
X =⋆Y
Y : σ→τ
Eq′
D2
Z : σ
Y Z : τ
D3
(→e)
or
D2
Z : σ→τ
D1
X : σ
X =⋆Y
Y : σ
Eq′
ZY : τ
D3 .
(→e)
These deductions can be replaced, respectively, by
D1
X : σ→τ
D2
Z : σ
XZ : τ
(→e)
(X =⋆Y )
XZ =⋆Y Z
Y Z : τ
D3
Eq′
or
D2
Z : σ→τ
D1
X : σ
ZX : τ
(→e)
(X =⋆Y )
ZX =⋆ZY
ZY : τ
D3 .
Eq′
If these replacements are made systematically in a deduction, beginning
at the top, and if consecutive inferences by rule Eq′ are combined when-
ever they occur in this process, we will eventually wind up with a new
deduction of the same formula, in which there is at most one inference
by Eq′, and that inference occurs at the end. This proves the following
theorem.
Theorem 11.64 (Eq′-postponement) If =⋆is =w or =Cβ or =Cext,
and Γ ia any set of formulas, and
Γ
⊢TA→
C =
X :τ ,
then there is a term Y such that Y =⋆X and
Γ
⊢TA→
C
Y :τ .

11K The equality-rule Eq ′
157
Corollary 11.64.1 (WN theorem for TA→
C=)
Let Γ be weakly
[strongly] inert.
If
Γ ⊢X : τ in TA→
C=w [TA→
C=ext], then X has a
weak [strong] normal form.
Proof By 11.27.1 and 11.28.
Remarks 11.65
(a) An extension of Corollary 11.64.1 to =Cβ would depend on the
theory of β-strong reduction, see Remark 9.41.
(b) Corollary 11.64.1 cannot be strengthened to conclude that X is
SN. To see this, take a term X which has a normal form but also has an
inﬁnite reduction, say X ≡Y(KI). This X has a normal form, since
X ▷w KIX ▷w I;
but it also has the inﬁnite reduction
X ▷w KIX ▷w KI(KIX) ▷w KI(KI(KIX)) ▷w etc.
Now I:a→a is provable in TA→
C , so by rule Eq′, X :a→a is provable in
TA→
C=w. But X is not SN.
Deﬁnition 11.66 (Typability in TA→
C=)
The deﬁnitions of typable,
p.t. and p.p. for TA→
C= are exactly the same as for TA→
C (Deﬁnitions
11.23 and 11.32), but with ⊢TA→
C = instead of ⊢TA→
C .
However, the class of typable terms in TA→
C= diﬀers from that in TA→
C .
The following theorem gives the relation between the two classes.
Theorem 11.67
Let =⋆be =w or =ext. Then a pure CL-term X is
typable in TA→
C= iﬀX has a normal form X⋆which is typable in TA→
C .
Further, the types that TA→
C= assigns to X are exactly those that TA→
C
assigns to X⋆.
Proof
Exercise. (Hint: use the Eq′-postponement and WN theorems,
with the p.t. theorem for TA→
C (11.36).)
Theorem 11.68 (Principal types in TA→
C=) Let =⋆be =w or =Cβ
or =Cext.
(a) Every pure CL-term that is typable in TA→
C= has a p.t. and a p.p.
in TA→
C=.

158
Simple typing, Curry-style in CL
(b) If B is a monoschematic basis of axioms, then every term typable
relative to B has a p.t. and a p.p. relative to B.
Proof From 11.67. (The proof is valid for both (a) and (b), see Discus-
sion 11.47.)
Warning 11.69
Although the above theorem may appear to be the
same as the p.t. theorem for TA→
C , it is not quite. This is because a term
may be typable in both TA→
C and TA→
C=, but have diﬀerent principal
types in both systems. For example, SKSI is typable in TA→
C and its
p.t. is (a →b) →a →b (by Exercise 11.38); but SKSI ▷w I, so in TA→
C=
its p.t. is a→a.
However, despite this warning, the Eq′-postponement theorem has
essentially reduced the study of TA→
C= to the study of TA→
C . The latter
is much easier, which is why so much of the present chapter has been
devoted to it, despite the fact that TA→
C is incomplete with respect to
equality.
Further reading See the end of the next chapter.

12
Simple typing, Curry-style
in λ
12A
The system TA→
λ
This chapter will do for λ-terms what Chapter 11 did for CL-terms.
There is not a major diﬀerence between the two chapters in either the
basic ideas or the main results, but there is a major technical compli-
cation in the proofs for λ, caused by the fact that λ-terms have bound
variables while CL-terms do not.
In this chapter the terms are λ-terms exactly as deﬁned in Chapter 1
(not the typed terms of Chapter 10). Recall the abbreviations
I ≡λx.x,
K ≡λxy.x,
S ≡λxyz.xz(yz).
Types are deﬁned here exactly as in Deﬁnition 11.1 (parametric types).
The basic conventions for these types are those of Notation 11.2, and
the types are interpreted exactly as in Remark 11.3.
Type-assignment formulas are as deﬁned in Deﬁnition 11.4, except
that now their subjects are λ-terms, not CL-terms.
The →-elimination rule from Deﬁnition 11.5 will be used also in the
present chapter; for λ-terms M and N, it says
M : σ →τ
N : σ
MN : τ .
(→e)
Discussion 12.1 (The →introduction rule) A comparison of Def-
initions 11.5 and 10.19 shows that the axiom-schemes (→I), (→K) and
(→S) of the former correspond to the constants Iσ, Kσ,τ and Sρ,σ,τ of the
latter, and that rule (→e) of the former corresponds to the construction
of application-terms (M σ→τ N σ)τ in the latter.
To assign types to λ-terms, we shall not need (→I), (→K) and (→S),
159

160
Simple typing, Curry-style in λ
but instead we shall need a new rule corresponding to the construction
of
(λxσ .M τ )σ→τ
in the deﬁnition of typed λ-terms (10.5). This new rule will not be a
straightforward rule like (→e), but will be like the implication-introduc-
tion rule in Gerhard Gentzen’s ‘Natural Deduction’ system of proposi-
tional logic.1
The new rule is called →-introduction or (→i), and says
(→i)











If x /∈FV(L1 . . . Ln) and
L1 :ρ1, . . . , Ln :ρn, x:σ
⊢
M :τ ,
then
L1 :ρ1, . . . , Ln :ρn
⊢
(λx.M):(σ →τ) .
It is usually written thus:
[x : σ]
M : τ
(λx.M) : (σ →τ) .
(→i)
This needs some explanation. Gentzen’s Natural Deduction systems
are very like formal theories as deﬁned in Chapter 6, but they are not
quite the same. A deduction is a tree of formulas just like deductions
in Notation 6.1, but Gentzen allowed that some of the assumptions in
branch-tops may be only temporary assumptions, to be employed at an
early stage in the deduction and then ‘discharged’ (or ‘cancelled’) at a
later stage. After an assumption has been discharged, it is marked in
some way; we shall enclose it in brackets.
In such a system, rule (→i) is read as ‘If x /∈FV(L1 . . . Ln), and the
formula M :τ is the conclusion of a deduction whose not-yet-discharged
assumptions are L1 :ρ1, . . . , Ln :ρn, x:σ, then you may deduce
(λx.M) : (σ →τ),
and wherever the assumption x : σ occurs undischarged at a branch-top
above M :τ, you must enclose it in brackets to show that it has now been
discharged.’
When an assumption has been discharged, it ceases to count as an
assumption. More formally, in a completed deduction-tree in a Natural
1 Natural Deduction is described in several textbooks and websites, for example
[Dal97, Section 1.4], [Coh87, Section 11.4], [RC90], [SU06, Section 2.2].

12A The system TA→
λ
161
Deduction system, some formulas at branch-tops may be enclosed in
brackets; and if Γ is any set of formulas, the notation
Γ ⊢M :τ
is deﬁned to mean that there is a deduction-tree whose bottom formula
is M : τ, and whose unbracketed top-formulas are members of Γ. As
usual, when Γ is empty, we say
⊢M :τ.
Here are three examples.
Example 12.2 In this chapter, S ≡λxyz.xz(yz). In any system whose
rules include (→e) and (→i), we have, for all types ρ, σ, τ,
⊢S : (ρ →σ →τ) →(ρ →σ) →ρ →τ.
Proof
First, we can assume x : ρ →σ →τ, y : ρ →σ and z : ρ, and
make a deduction for xz(yz) thus.
(For ease of reference later, each
assumption is numbered.)
1
x : ρ →σ →τ
2
z : ρ
xz : σ →τ
(→e)
3
y : ρ →σ
2
z : ρ
yz : σ
(→e)
xz(yz) : τ
(→e)
Then we can apply rule (→i) three times. The result is the following de-
duction. In it, whenever rule (→i) is used, the number of the assumption
it discharges is shown, e.g. ‘(→i – 2)’.
1
[x : ρ →σ →τ]
2
[z : ρ]
xz : σ →τ
(→e)
3
[y : ρ →σ]
2
[z : ρ]
yz : σ
(→e)
xz(yz) : τ
(→e)
λz.xz(yz) : (ρ →τ)
(→i −2)
λyz.xz(yz) : (ρ →σ) →ρ →τ
(→i −3)
λxyz.xz(yz) : (ρ →σ →τ) →(ρ →σ) →ρ →τ.
(→i −1)
2
Comments on Example 12.2
(a) Although all the branch-top
formulas have brackets in the completed deduction above, each one starts
its life without brackets, and only receives brackets when it is discharged
after a use of (→i).

162
Simple typing, Curry-style in λ
(b) Only formulas at branch-tops can be discharged, never those in
the body of a deduction.
(c) If an assumption occurs several times at branch-tops, such as z :ρ
above, rule (→i) discharges every branch-top occurrence that is above
the place where (→i) is applied.
(d)
The rule-names and the numbers shown in the deduction are
included for the reader’s convenience, but are not really part of the
deduction and are not actually necessary; if they were omitted, the form
of each rule would still show which rule it was, and which assumptions
(if any) it discharged.
Example 12.3 In this chapter, K ≡λxy.x. In any system whose rules
include (→e) and (→i), we have, for all σ, τ,
⊢K : σ →τ →σ.
Proof
Here is a deduction of the required formula.
In it, the ﬁrst
application of (→i) discharges all assumptions y:τ that occur. But none
in fact occur, so nothing is discharged. This is perfectly legitimate; it is
called a ‘vacuous discharge’, and is shown by ‘(→i – v)’.
1
[x : σ]
λy.x : τ →σ
(→i −v)
λxy.x : σ →τ →σ.
(→i −1)
2
Example 12.4
In this chapter, I ≡λx.x. In any system with rule
(→i), we have, for all σ,
⊢I : σ →σ.
Proof
The following deduction begins with a one-step deduction x : σ,
whose conclusion is the same as its only assumption. A deduction with
only one step is a genuine deduction, and rule (→i) can legitimately be
applied to it.
1
[x : σ]
λx.x : σ →σ.
(→i −1)
2
Discussion 12.5 Before we come to deﬁne the type-assignment system,
we need to consider one further rule, for α-conversion. Since two α-con-
vertible terms are intended to represent the same operation, any two

12A The system TA→
λ
163
such terms should be assigned exactly the same types. That is, we want
an α-invariance property:
Γ ⊢M :τ,
M ≡α N
=⇒
Γ ⊢N :τ
(1)
(where Γ is any set of formulas). If all the terms in Γ are atoms, then
α-invariance will turn out to be provable by induction on the lengths
of deductions. But sometimes it will be interesting to consider more
general sets Γ. For example, if there is an atomic type N for the natural
numbers, and 0 is represented by λxy.y, we shall want to assume
λxy.y : N.
The α-invariance property will then fail unless we also assume
λxz.z : N,
λuv.v : N,
etc.
But this makes our set of assumptions inﬁnite, in a rather boring way.
To avoid this, we shall postulate a formal rule which, in eﬀect, closes
every set of assumptions under α-conversion. (It is tempting to simply
postulate (1) as an unrestricted rule, but this would make the subject-
construction property harder to state and use.)
Deﬁnition 12.6 (The type-assignment system TA→
λ )
TA→
λ
is
a Natural Deduction system. Its formulas, called TA→
λ -formulas, are
expressions M : τ for all λ-terms M and all types τ. (M is called the
formula’s subject and τ its predicate.) TA→
λ
has no axioms. It has the
following three rules:
(→e)
M : σ→τ
N : σ
MN : τ
(→i)
[x : σ]
M : τ
(λx.M) : σ→τ
Condition: x:σ is the only un-
discharged assumption in whose
subject x occurs free. After rule
(→i) is used, every occurrence of
x:σ at branch-tops above M :τ is
called ‘discharged’ and enclosed
in brackets
(≡
′
α)
M : τ
M ≡α N
N : τ
Condition: M ̸≡N, and M :τ is
not the conclusion of a rule.
(Strictly speaking, TA→
λ
also contains axioms and rules to deﬁne α-
conversion, but we shall leave these to the imagination.) For any ﬁnite

164
Simple typing, Curry-style in λ
or inﬁnite set Γ of formulas, the notation
Γ ⊢TA→
λ
M : τ
means that there is a deduction of M :τ whose undischarged assumptions
are members of Γ. If Γ is empty, we say simply
⊢TA→
λ
M : τ.
Example 12.7 Recall that B ≡λxyz.x(yz). Then, for all ρ, σ, τ,
⊢TA→
λ
B : (σ →τ) →(ρ →σ) →ρ →τ.
Proof
3
[x : σ →τ]
2
[y : ρ →σ]
1
[z : ρ]
yz : σ
(→e)
x(yz) : τ
(→e)
λz.x(yz) : (ρ →τ)
(→i −1)
λyz.x(yz) : (ρ →σ) →ρ →τ
(→i −2)
λxyz.x(yz) : (σ →τ) →(ρ →σ) →ρ →τ.
(→i −3)
Remark 12.8
The condition in rule (→i) prevents the term λx.xx
from having a type.
This is because any TA→
λ -deduction for λx.xx
would have to begin with a deduction for xx, and then apply (→i), like
this:
1
x : σ→τ
2
x : σ
xx : τ
(→e)
λx.xx : ρ→τ ,
(→i, discharging 1 or 2 or v)
for some ρ. But the condition in (→i) is that the discharged assumption
is the only one whose subject is x, so neither 1 nor 2 can be discharged
here, nor can a vacuous assumption x:ρ be discharged. (Cf. the remark
about xx in Example 11.24(c).)
Exercise 12.9 ∗
For each of the seven terms shown on the left-hand
side in the following list, give a TA→
λ -deduction to show that it has all
the types shown on the right-hand side (one type for each ρ, σ, τ). Cf.
Exercise 11.8.

12B Basic properties
165
Term
Type
(a)
0 ≡λxy.y
(see 4.2)
τ →σ →σ
(b)
σ ≡λuxy.x(uxy) (see 4.2)
((σ→τ)→ρ→σ)→(σ→τ)→ρ→τ
(c)
W ≡λxy.xyy
(see 3.2)
(σ →σ →τ) →σ →τ
(d)
λxyz.y
ρ →σ →τ →σ
(e)
0 ≡λxy.y
Nτ
( ≡(τ →τ)→τ →τ )
(f)
σ ≡λuxy.x(uxy)
Nτ →Nτ
(g)
n ≡λxy.xny
Nτ .
12B
Basic properties of TA→
λ
Deﬁnition 12.10 (Kinds of assumption-sets)
Let Γ be a set of
TA→
λ -formulas {U1 :π1, U2 :π2, . . .}. We call Γ [β- or βη-] inert iﬀevery
Ui is a normal form [β or βη, respectively] which does not begin with λ.
The deﬁnition of monoschematic basis is the same as for CL, see 11.44.
(Every monoschematic basis is both β- and βη-inert.)
Lemma 12.11 (Closure under type-substitutions) Let Γ be any
set of TA→
λ -formulas, and let
Γ ⊢TA→
λ
M :τ .
Then, for all type-variables a1, . . . , ak and types σ1, . . . , σk,
[σ1/a1, . . . , σk/ak]Γ
⊢TA→
λ
M : [σ1/a1, . . . , σk/ak]τ .
Proof
(Cf. Lemma 11.11.)
Substitute [σ1/a1, . . . , σk/ak] throughout
the predicates in the given deduction. This substitution will change an
instance of rule (→e), (→i) or (≡
′
α) into a new instance of the same rule,
so the result is still a genuine deduction.
Lemma 12.12 (α-invariance) Let Γ be any set of TA→
λ -formulas. If
Γ ⊢TA→
λ
M :τ
and M ≡α N, then
Γ ⊢TA→
λ
N : τ .

166
Simple typing, Curry-style in λ
Proof [CHS72, Section 14D3, Case 1], replacing assumption (ii) in that
proof by rule (≡
′
α).
Remark 12.13
(The subject-construction property)
Similarly
to TA→
C , the deduction of a formula M : τ in TA→
λ
closely follows the
construction of M; see Examples 12.2, 12.3, 12.4 and 12.7. The only
extra complication here is rule (≡
′
α), and this can only be used at the
top of a branch in a deduction-tree. (Indeed, if all the subjects of the
assumptions are atoms, it cannot be used at all.) Just as with TA→
C , we
shall not state the property in full formal detail here, but merely give
some simple examples of its use.2
Example 12.14
Every type assigned to I (≡λx.x) in TA→
λ
has the
form
σ→σ.
Proof Since I ≡λx.x, every type assigned to I must be compound, and
the last inference in the deduction must be by (→i). In other words, if
there is a deduction which gives
⊢TA→
λ
I : σ→τ,
then removing the last inference from the deduction leaves a deduction
giving
x:σ ⊢TA→
λ
x:τ.
But this latter deduction can only be a deduction with one step, and it
follows that τ ≡σ.
Exercise 12.15∗Prove that every type assigned to B (≡λxyz.x(yz))
in TA→
λ has the form
(σ →τ) →(ρ →σ) →ρ →τ.
Exercise 12.16 ∗Prove that there is no type assigned in TA→
λ to the
ﬁxed-point combinator YCurry−Ros (≡λx.V V , where V ≡λy.x(yy),
from Deﬁnition 3.4).
The next theorem will show that, like TA→
C , TA→
λ
preserves types
2 The property for a system without the α-conversion rule is expressed formally in
[CHS72, Section 14D2, Subject-Construction theorem].

12B Basic properties
167
under reductions (though here, of course, reductions will be β- and βη-
reductions). And, as in TA→
C , we shall need a replacement lemma before
the theorem, though here the presence of bound variables will complicate
the lemma’s statement and proof.
Lemma 12.17 (Replacement) Let Γ1 be any set of TA→
λ -formulas,
and D be a deduction giving
Γ1 ⊢TA→
λ
X :τ .
Let V be a term-occurrence in X, and let λx1,. . . ,λxn be those λ’s in
X whose scope contains V . Let D contain a formula V : σ in the same
position as V has in the construction-tree for X, and let
x1 :ρ1, . . . , xn :ρn
be the assumptions above V :σ that are discharged by applications of (→i)
below it. Assume that V : σ is not in Γ1. Let W be a term such that
FV(W) ⊆FV(V ), and let Γ2 be a set of TA→
λ -formulas whose subjects
do not contain x1, . . . , xn free. Let
Γ2, x1 :ρ1, ..., xn :ρn
⊢TA→
λ
W :σ .
Let X⋆be the result of replacing V by W in X. Then
Γ1 ∪Γ2
⊢TA→
λ
X⋆:τ .
Proof A full proof requires a careful induction on X. Here is an outline.
First cut oﬀfrom D the subtree above the formula V : σ. The result is
a tree D1 with form
V : σ
D1
X : τ .
And since V : σ is not in Γ1, the ﬁrst step below V : σ cannot be rule
(≡
′
α); in fact, that rule cannot be used anywhere below V : σ. Replace
V by W in the formula V : σ, and in all formulas below it in D1; then
take the given deduction of W : σ and place it above. The result is a
tree, leading from assumptions in Γ1 ∪Γ2 to the conclusion X⋆:τ. And
each (→i)-step in this tree satisﬁes the conditions required in this rule,
because x1, . . . , xn do not occur in Γ2. So the tree is a correct deduction
of X⋆:τ.

168
Simple typing, Curry-style in λ
Lemma 12.18 Let Γ be any set of TA→
λ -formulas such that x does not
occur in any term of Γ. Let
Γ, x:σ ⊢Y :τ.
(2)
Then for any term U,
Γ, U :σ ⊢[U/x]Y : τ,
(3)
where the number of steps in the deduction of (3) is the same as that in
the deduction of (2).
Proof See [CHS72, Section 14D2 Corollary 1.1].
Theorem 12.19 (Subject-reduction)
Let Γ be a β- [βη-] inert set
of TA→
λ -formulas. If
Γ ⊢TA→
λ
X :τ
and X ▷β X′ [X ▷βη X′], then
Γ ⊢TA→
λ
X′ :τ .
Proof If the step from X to X′ is an α-conversion, use Lemma 12.12.
Now suppose X βη-contracts to X′. By the replacement lemma, it is
enough to take care of the case that X is a redex and X′ is its contrac-
tum. By 12.12, we can assume that no variable bound in XX′ occurs
free in a subject in Γ.
Case 1: X is a β-redex, say (λx.M)N, and X′ is [N/x]M. By the
assumption that the subjects in Γ are normal forms, the formula X : σ
cannot be in Γ, and cannot be the conclusion of rule (≡
′
α). Hence, it is
the conclusion of an inference by (→e), for which the premises are
Γ ⊢λx.M : σ→τ,
Γ ⊢N :σ,
for some σ.
By the assumption that the subjects in Γ do not begin
with λ, the formula λx.M : σ →τ
cannot be in Γ and cannot be the
conclusion of (≡
′
α). Hence it must be the conclusion of an inference by
(→i), the premise for which is
Γ, x:σ ⊢M :τ,
where x does not occur free in any subject in Γ. The conclusion, which
is
Γ ⊢[N/x]M : τ,

12B Basic properties
169
then follows by Lemma 12.18.3
Case 2 (βη-reduction only): X is an η-redex. Then X ≡λx.Mx,
where x does not occur free in M, and X′ ≡M. By the assumption
that the subjects in Γ are βη-normal forms, the formula X : τ is not in
Γ. Hence, it is the conclusion of an inference by (→i), where τ ≡ρ→σ
and the premise is
Γ, x:ρ ⊢Mx:σ.
Since x does not occur free in any subject of Γ, the formula Mx:σ does
not occur in Γ, and is not the conclusion of rule (≡
′
α); hence it must be
the conclusion of an inference by (→e) whose premises are
Γ, x:ρ ⊢M : µ→σ,
Γ, x:ρ ⊢x:µ,
for some µ. By the second of these, and the fact that x does not occur
free in any subject of Γ, we have µ ≡ρ, and hence the ﬁrst of these is
Γ, x:ρ ⊢M :τ.
Since x does not occur free in M or in any subject of Γ, the assumption
x:ρ is not used in this deduction and can thus be omitted from the list
of undischarged assumptions. Hence Γ ⊢M :τ.
Remark 12.20
(a) The above proof will still work if the condition
on Γ is relaxed slightly, to say that every subject in Γ is in normal form
and if a subject in Γ begins with a λ, then every type it receives in Γ is
an atomic constant. An example of such an assumption-set is
Γ =

1:N, 2:N, 3:N, . . .

,
where n ≡λxy.xny. Hence the subject-reduction theorem holds for this
set of assumptions.
(b)
An example of an assumption-set for which the theorem’s con-
clusion fails is

0:N,
σ : N→N

,
where 0 ≡λxy.y and σ ≡λuxy.x(uxy). Both these terms begin with
λ, so the hypothesis of the theorem fails. The conclusion also fails, since
from this assumption-set it is possible to prove σ 0 : N, and σ 0 ▷β 1,
but it is impossible to prove 1:N.
3 The authors would like to thank John Stone for pointing out that in [HS86] the
proof of the corresponding theorem (15.17) was in error in relying on Lemma 12.17
at this point.

170
Simple typing, Curry-style in λ
Remark 12.21
Theorem 12.19 cannot be reversed; it is not, in general,
true that if
⊢X :σ and X′ ▷X then ⊢X′ :σ. For example, let
X ≡0 ≡λxy.y,
X′ ≡λxy.Ky(xy).
Then, as indicated in Exercise 12.9(a), we have ⊢X : τ →σ→σ for any
type τ; but it is not hard to check that ⊢X′ : τ →σ →σ holds only if
τ ≡σ→µ for some µ.
An even stronger example is X ≡I and X′ ≡(λz.zz)I, since we have
⊢X : σ →σ whereas TA→
λ
assigns no type at all to X′ (by Example
12.27 and the fact that TA→
λ assigns a type to a term only if it assigns
a type to each of its subterms).
However, reversal is possible under certain very restricted conditions;
see [CHS72, Section 14D4].
In Section 12E we shall study a system deﬁned by adding a rule of
equality-invariance to TA→
λ .
12C
Typable λ-terms
The notion of typable term will be the same for TA→
λ
as for TA→
C in
Section 11F. And, just as in that section, for simplicity we shall only
consider pure terms.
Following Deﬁnition 11.21, a (type-)context is a ﬁnite or inﬁnite set
Γ ≡{x1 :ρ1, x2 :ρ2, . . . } which gives only one type to each xi, i.e. which
satisﬁes xi ≡xj =⇒ρi ≡ρj. If X is a λ-term, an FV(X)-context is a
context whose subjects are exactly the variables occurring free in X.
If D is a deduction of X :τ from a context Γ, and X is a pure term, then
rule (≡
′
α) cannot occur in D (by the restriction on that rule). However,
the α-invariance lemma (12.12) is still valid; its proof in [CHS72, Section
14D3] covers this situation.
Deﬁnition 12.22 (Typable pure λ-terms) A pure λ-term X, with
FV(X) = {x1, . . . , xn}, is said to be typable iﬀthere exist a context
{x1 :ρ1, . . . , xn :ρn} and a type τ such that
x1 :ρ1, . . . , xn :ρn
⊢TA→
λ
X :τ.
In particular, a closed term X is typable iﬀthere exists τ such that
⊢TA→
λ
X :τ.

12C Typable λ-terms
171
Example 12.23
By 12.2, 12.3, 12.4, 12.7 and 12.9, the following λ-
terms are typable:
S,
K,
I,
B,
W,
n (≡λxy.xny),
σ (≡λuxy.x(uxy)).
It is not hard to show that the following are also typable:
C (≡λxyz.xzy),
D (≡λxyz.z(Ky)x, cf. 11.15(b)),
RBernays (cf. 11.15(c)).
In contrast, xx is untypable in TA→
λ
just as in TA→
C
(see Example
11.24(c), which applies to both systems since it involves no axioms).
Lemma 12.24 In TAλ:
(a) A pure λ-term X is typable iﬀevery subterm of X is typable.
(b) A pure λ-term X is typable iﬀthere exist closed types ρ1, . . . , ρn, τ
satisfying Deﬁnition 12.22.
(c) The set of all typable pure λ-terms is closed under β- and βη-
reduction, but not expansion.
(d) The set of all typable pure λ-terms is closed under abstraction,
but not under application.
Proof (a) By the subject-construction property, 12.13.
(b) By the type-substitution lemma, 12.11.
(c) By the subject-reduction theorem (12.19), and Remark 12.21.
(d) By rule (→i), and the fact that xx is not typable, 12.23.
Deﬁnition 12.25 (Principal type, p.t.)
Let X be any pure λ-term,
with FV(X) = {x1, . . . , xn} (n ≥0).
(a) If n = 0: we call a type π a p.t. of X iﬀ⊢TA→
λ
X : τ holds for a
type τ when and only when τ is a substitution-instance of π.
(b) If n ≥0: we call a pair ⟨Γ, π⟩a principal pair (p.p.) of X, and π a
p.t. of X, iﬀΓ is an FV(X)-context and the relation Γ′ ⊢TA→
λ X :τ
holds for an FV(X)-context Γ′ and a type τ when and only when
⟨Γ′, τ⟩is a substitution-instance of ⟨Γ, π⟩(cf. note after 11.32).
Example 12.26 I has p.t. a→a.
Proof See Example 12.14.

172
Simple typing, Curry-style in λ
Example 12.27 λx.xx is untypable.
Proof
By Example 11.24(c), xx is untypable. The result then follows
by Lemma 12.24(a).
Just as in Chapter 11, beyond these examples lies a general principal-
type algorithm, which will decide whether a term X is typable and, if
it is, will output a p.t. and p.p. for X.
This algorithm is described
in several publications, for example [Mil78], [Hin97, Section 3E], and
[Pie02, Chapter 22]. On it rest the following two theorems. Their proofs
are omitted.
Theorem 12.28 (P.t. theorem) Every typable pure λ-term has a p.t.
and a p.p.
Theorem 12.29 (Decidability of typability) The set of all typable
pure λ-terms is decidable.
Now, if each CL-term in the table in 11.39 is replaced by the corre-
sponding λ-term, it is not hard to show that the result is a table of p.t.s
of λ-terms.
The fact that these corresponding terms have the same p.t.s suggests
that TA→
C and TA→
λ
are equivalent. To state the precise form of this
equivalence, ﬁrst deﬁne, for every assumption-set Γ in TA→
C ,
Γλ
=

formulas Xλ :τ : X :τ is in Γ

.
Similarly, for a set Γ of assumptions in TA→
λ , and any H-transformation,
deﬁne
ΓH
=

formulas XH :τ : X :τ is in Γ

.
Then an easy proof gives the following result.
Theorem 12.30 (Equivalence of TA→
C
and TA→
λ ) Let H be Hη,
Hw, or Hβ (9.10, 9.24, 9.27); then
(a)
Γ
⊢TA→
C
X :τ
=⇒
Γλ
⊢TA→
λ
Xλ :τ,
(b)
Γ
⊢TA→
λ
M :τ
=⇒
ΓH
⊢TA→
C
MH :τ.
Exercise 12.31 ∗
(a) Prove that, for every pure CL-term X, X is typable in TA→
C iﬀ
Xλ is typable in TA→
λ ; also X and Xλ have the same p.t.

12D Propositions-as-types
173
(b) Let H be Hη; ﬁnd a pure λ-term M such that MH has a diﬀerent
p.t. from M.
(c) What are the results for Hw and Hβ corresponding to (b)?
12D
Propositions-as-types and normalization
Deduction-reductions work for TA→
λ
much as they do for TA→
C .
Of
course the S-, K- and I-reductions in the last chapter must be replaced
by β-reductions (deﬁned below), but this is the same sort of replacement
one makes in passing from weak CL-reduction to λβ-reduction in the
world of terms.
Deﬁnition 12.32 (Deduction-reductions for TA→
λ )
A reduction
of one deduction to another consists of a sequence of replacements by
the following reduction-rule:
β-reductions for deductions A deduction of the form
1
[x : σ]
D1(x)
M : τ
λx.M : σ→τ
(→i −1)
D2
N :σ
(λx.M)N : τ
(→e)
D3
may be reduced to
D2
N :σ
D1(N)
[N/x]M : τ
D3′ ,
where D3′ is obtained from D3 by replacing appropriate occur-
rences of (λx.M)N by [N/x]M.
Note that carrying out this reduction step has the eﬀect of performing
one contraction on the subject of the conclusion.

174
Simple typing, Curry-style in λ
For readers who know propositional logic in Gentzen’s ‘Natural De-
duction’ version, it is worth noting that if we delete all subjects from the
preceding reduction-step, the result will be a reduction of Natural De-
ductions in propositional logic. Such reductions were ﬁrst described in
[Pra65]. In fact, the proof of [Pra65, Chapter III Theorem 2] can be com-
bined with the propositions-as-types transformation to show that every
deduction in TAλ can be reduced to a normal (irreducible) deduction;
see [Sel77, Theorem 6, p. 22]. This gives us the following result.
Theorem 12.33 (WN for deductions)
Every TA→
λ -deduction can
be reduced to a normal deduction.
Corollary 12.33.1 (WN for λ-terms) Let Γ be β-inert in the sense
of Deﬁnition 12.10. If Γ ⊢TA→
λ M :τ, then M has a β-normal form.
Proof By 12.33 we can assume the deduction of M :τ is normal. But it
is easy, in the light of the proof of 12.19, to see that if a β-redex occurred
in M, then the deduction could be reduced by a β-reduction; see [Sel77,
Corollary 6.2 p. 23]. (This depends, of course, on the assumption that
Γ is inert.)
Remark 12.34
WN for typable pure λ-terms can be obtained from
the preceding theorem and corollary by taking the special case in which
Γ is a context. Also SN for these terms can probably be obtained by
a similar method of proof.
We have not checked the details of this,
however, because SN can be proved by a slightly diﬀerent method, as
follows.
Theorem 12.35 (SN for λ-terms and ▷β) Every typable pure λ-term
is strongly normalizable with respect to ▷β.
Proof (outline) Let M0 be a pure λ-term and D0 be a TA→
λ -deduction
of M0 : τ from some context Γ, say Γ = {x1 :ρ1, . . . , xn :ρn}. Suppose
there is a reduction of M0 with an inﬁnite number of β-steps:
M0 ▷1β M1 ≡α M ′
1 ▷1β M2 ≡α M ′
2 ▷1β M3 ≡α M ′
3 . . .
(4)
By the subject-reduction theorem, 12.19, for each k ≥0 there exists a
TA→
λ -deduction Dk giving Γ ⊢Mk :τ. Now the subjects in Γ are atoms,
so by the restriction in rule (≡
′
α), that rule cannot occur in Dk. Hence a
Church-style typed term M ⋆τ
k
can be assigned to Dk, by ﬁrst assigning

12D Propositions-as-types
175
to each assumption xi : ρi in Γ a distinct Church-style typed variable
with type ρi, then working down the deduction Dk. Corresponding to
rules (→e) and (→i) in Deﬁnition 12.6, one builds terms

M ⋆σ→τ N ⋆στ ,

λuσ . M ⋆τ σ→τ ,
where uσ is the typed variable assigned to the formula x : σ.
The details of the mapping from Dk to M ⋆τ
k
depend on the Church-
style typed variables chosen to correspond to the assumptions in Γ and
to the bound variables in M0, M1, etc.
We omit those details here.
But a suitable choice can be made so that the reduction (4) changes to
an inﬁnite reduction of the typed term M ⋆τ
0 . This contradicts the SN
theorem for typed terms, Theorem 10.15. Hence M0 cannot have an
inﬁnite β-reduction.
Remark 12.36 (βη-reduction) A deduction-reduction analogous to
βη-reduction can be deﬁned by adding to Deﬁnition 12.32 the following
extra reduction rule.
η-reductions for deductions A deduction of the form
D1
M : σ→τ
1
[x : σ]
Mx : τ
(→e)
λx.Mx : σ→τ
(→i −1)
D2,
where x does not occur free in D1 (and hence does not occur
free in M), may be reduced to
D1
M : σ→τ
D2′ ,
where D2′ is obtained from D2 by replacing appropriate occur-
rences of λx.Mx by M.
The weak normalization theorem for βη-reductions of deductions is
proved in [Sel77, Corollary 6.1, p. 22]. For βη-reductions of terms, WN
comes from WN for ▷β and the fact that a term has a βη-normal form
iﬀit has a β-normal form (7.14).

176
Simple typing, Curry-style in λ
12E
The equality-rule Eq′
The system TA→
λ
is like TA→
C in failing to be invariant under equality
(Remark 12.21). Hence there is interest in adding the following rule:
Rule Eq′
X : τ
X =⋆Y
Y : τ .
This is really two alternative rules: ‘=⋆’ may denote =β or =βη.
Deﬁnition 12.37 (The systems TA→
λ=)
These systems are obtained
from TA→
λ (Deﬁnition 12.6) by adding rule Eq′. If =⋆is =β, we call the
rule Eq′β and the system TA→
λ=β. If =⋆is =βη, we call the rule Eq′βη
and the system TA→
λ=βη. The names Eq′ and TA→
λ= will mean either
and/or both of these rules and systems, according to the context.
Remark 12.38
TA→
λ= is undecidable, because =β and =βη are so.
Discussion 12.39 The Eq′-postponement theorem can be proved for
TA→
λ= by adding to the proof for TA→
C=, in Discussion 11.63, the extra
case in which an inference by Eq′ occurs directly above an inference by
rule (→i). In this case, the given deduction has the following form:
1
[x : σ]
D1(x)
X : τ
X =⋆Y
Y : τ
(Eq′)
λx.Y : σ→τ
(→i −1)
D2 ,
and it can be replaced by
1
[x : σ]
D1(x)
X : τ
λx.X : σ→τ
(→i −1)
λx.X =⋆λx.Y
λx.Y : σ→τ
(Eq′)
D2 .

12E Rule Eq
′
177
If this replacement is used with the others in Discussion 11.63, the result
is a proof of the following theorem.
Theorem 12.40 (Eq′-postponement) Let =⋆be =λβ or =λβη. If Γ
is any set of TA→
λ -formulas, and
Γ ⊢TA→
λ =
X :τ,
then there is a term Y such that Y =⋆X and
Γ ⊢TA→
λ
Y :τ.
Corollary 12.40.1 (WN theorem for TA→
λ=) If the set Γ of TA→
λ -
formulas is β-inert, and Γ ⊢TA→
λ = β X : τ, then X has a β-normal form.
Similarly for βη.
For reasons stated in Remark 11.65(b), this corollary cannot be ex-
tended to conclude that X is SN.
Corollary 12.40.2 (Principal type theorem for TA→
λ=) Let =⋆be
=λβ or =λβη. Then every typable pure λ-term has a p.t. and a p.p. in
TA→
λ=.
Remark 12.41
The deﬁnitions of typable, p.t. and p.p. used in the
above corollary are the same as for TA→
λ , but with TA→
λ=-deducibility re-
placing TA→
λ -deducibility. Note that a term may have a p.t. in TA→
λ= and
a diﬀerent one, or none at all, in TA→
λ (cf. 11.69). The following theo-
rem connects the two systems, and, together with the Eq′-postponement
theorem, goes a long way towards reducing the study of TA→
λ= to that
of TA→
λ .
Theorem 12.42 Let =⋆be =λβ or =λβη. Then a pure λ-term X is
typable in TA→
λ= iﬀX has a normal form X⋆which is typable in TA→
λ .
Further, the types that TA→
λ= assigns to X are exactly those that TA→
λ
assigns to X⋆.
Finally, the systems TA→
λ= are linked to TA→
C= by the following the-
orem.
To state it, let us say that systems TA→
C=, TA→
λ=, and an H-
transformation are compatible iﬀeither they are TA→
C=β, TA→
λ=β, Hβ, or
they are TA→
C=ext, TA→
λ=βη, Hη.

178
Simple typing, Curry-style in λ
Theorem 12.43 (Equivalence of TA→
C= and TA→
λ=) If TA→
λ=, TA→
C=
and H are compatible, then
(a)
Γ ⊢TA→
C = X :τ
⇐⇒
Γλ ⊢TA→
λ =
Xλ :τ ,
(b)
Γ ⊢TA→
λ = X :τ
⇐⇒
ΓH
⊢TA→
C =
XH :τ,
Further reading
There is an enormous literature on types and type-assignment. A few
items have already been mentioned; here are a few more. Many more
can easily be found using an internet search engine.
[Pie02] is a well written comprehensive introduction to λ and types,
for readers with a computing background.
It covers all the material
in the present book’s Chapters 10–12, plus subtyping, recursive types,
higher-order systems, and much more.
[Bar92] is a summary and comparison of some of the most important
type systems based on λ, clearly explaining the relations between them.
(The second half of the account describes Pure Type Systems, to which
we shall give a short introduction in Section 13D.)
[BDS] is an advanced and up-to-date account of three type systems
in lambda calculus – simple types (Church-style and Curry-style), inter-
section types, and recursive types. Besides the syntax of these systems,
decidability questions and semantic aspects are treated thoroughly and
in depth.
[And02, Chapter 5] develops logic and mathematics in a type-system
based on Church’s original system, [Chu40].
Also [And65] describes
an extension of Church’s system with rules which make certain types
transﬁnite.
[Hin97] is a detailed account of TA→
λ focussing on three algorithms –
to ﬁnd the principal type of a term, to ﬁnd a term for which a given
type is principal, and the Ben–Yelles algorithm to count the number of
closed terms with a given type.
[CDV81], [CC90, Section 3] and [Hin92] are introductions to the ex-
tension of TA→
λ called intersection types. This system has, besides σ→τ,
also σ ∩τ. Its types give more information than TA→
λ ; for example, it
assigns to λx.xx the type
(a ∩(a→b)) →b ,
which says that if we wanted to give two types to x, then xx would get
a type, a fact not expressible in TA→
λ
(which simply refuses to assign

12E Rule Eq
′
179
a type to λx.xx). The standard version of the intersection system also
has a universal type ω, which can be used to give further information
(see 11.58), and to make a term’s set of types invariant with respect to
equality (in contrast to TA→
λ , see 12.21). Three pioneering papers on
intersection types are [CD78], [Sal78] and [Pot80]. A modern advanced
account is in [BDS, Part III].
[CC90, Section 2], [CC91] and [Pie02, Chapters 20 & 21] are intro-
ductions to the extension of TA→
λ in which there are recursively deﬁned
types. As mentioned above, a further account of this ﬁeld is in [BDS,
Part II]. More information can be found by searching the internet for
‘recursive types’.
[LS86] describes the close connection between TA→
λ and cartesian clos-
ed categories (and includes a short introduction to the latter). Some
introductions to category theory in general are [Pie91], [Cro94], [Fia05]
and (for more mathematical readers) [Mac71], [AL91].

13
Generalizations of typing
13A
Introduction
In programming languages, there are many applications of typing that
require generalizations of the theories we have considered so far. These
generalizations are the subject of this chapter.
Of course, it is easy to generalize any theory of typing by just adding
new type-forming operations. For example, to relate typing to cartesian
closed categories, one needs ordered pairs in which the ﬁrst and second
elements may have arbitrarily diﬀerent types. This is impossible in TA→
C
and TA→
λ by [Bar74], so it is necessary to introduce a new type-forming
operation × and to postulate
D
:
α →β →(α × β),
D1
:
(α × β) →α,
D2
:
(α × β) →β,
where, as in Note 4.14,
D
≡
λxyz . z(Ky)x,
D1
≡
λx . x0,
D2
≡
λx . x1.
Although an extension like this adds new types and assigns new types to
terms, it does not represent a major change in the way typing operates.
The extensions we will consider in this chapter, however, require major
changes in the foundations of the theories of type assignment.
180

13B Dependent function types
181
13B Dependent function types, introduction
The main novelty in the typing systems considered in this chapter is
the replacement of the function type σ →τ as the main compound
type by the dependent function type (Πx : σ . τ(x)), which can be read
informally as ‘for all x in σ, τ(x).’
Here, σ is a type, but τ(x) is a
function whose values are types for arguments in type σ, so that a term
of type (Πx:σ . τ(x)) represents a function whose arguments are of type
σ and whose value for an argument N is in type τ(N).
The deﬁnition of the types of the various systems will be more com-
plicated than for the systems of Chapters 10, 11 and 12, and will have
to allow for the possibility that term-variables occur free in types. In
this chapter, terms and types will not be separate; a type will be just a
special kind of term.
Informally speaking, in the special case that τ(x) is a constant function
whose value for any argument is a type τ, (Πx:σ . τ(x)) is the type σ→τ.
In the systems considered below, this will occur when the variable x does
not occur free in τ(x). Thus, the typing systems of Chapters 10, 11 and
12 will be subsystems of many of the systems to be considered here.
To express the idea of dependent function type we shall use variants of
the following two rules, which, for convenience, are stated for Curry-style
typing in λ:
(Π e)
M : (Πx:σ . τ(x))
N : σ
MN : τ(N);
(Π i)
[x : σ]
M : τ(x)
(λx.M) : (Πx:σ . τ(x))
Condition: x:σ is the only un-
discharged assumption in whose
subject x occurs free, and x does
not occur free in σ.
For reasons that will be more fully justiﬁed below, we shall also need
the following rule:
(Eq′′)
M : σ
σ =β τ
M : τ
(Until otherwise indicated, in this chapter conversion will be =β in
λ-calculus.)
Notation 13.1
The type (Πx : σ . τ(x)) has also appeared in the lit-
erature as (Πx : σ)τ(x), (Πx ∈σ)τ(x), and (∀x : σ)τ(x), the latter

182
Generalizations of typing
emphasizing the propositions-as-types aspect of the type. It is called
the cartesian product type in [ML75].
Remark 13.2 In terms of the notion of propositions-as-types (Discus-
sion 11.49 and the paragraph before Theorem 12.33), (Πx:σ . τ(x)) not
only represents implication (by its inclusion of the type →), but it also
represents the universal quantiﬁer over a type. The rule (Π e) represents
the elimination rule for the universal quantiﬁer over σ, and the rule (Π i)
represents the introduction rule for that same quantiﬁer.
Remark 13.3 In this chapter we will not take up the use of dependent
types in CL. The subject is far less developed for CL than it is for λ,
and so the systems of this chapter will be for λ only.
To allow for dependent types, the deﬁnition of types will have to be
very diﬀerent from the deﬁnition of types in 11.1. As mentioned earlier,
one of the main diﬀerences is that whereas the deﬁnition of types in
11.1 is completely separate from the deﬁnition of terms, in systems with
the dependent function type, types cannot be completely separate from
terms, and for such systems, all types will be terms. Furthermore, the
deﬁnition will have to allow for variables to occur free in these terms, so
we will be talking not only about types, but also about functions whose
values are types. There are two alternative approaches to the deﬁnition
of types for these systems:
G1. Deﬁning types so that if a term T represents a type and contains
a term-variable x, then [N/x]T represents a type also, no matter what
term N is and what type N has.
G2. Deﬁning types so that [N/x]T will only represent a type if N has
the same type as x.
Remark 13.4
Curry introduced dependent types using the notation
Gστ for (Πx : σ . τx), or Gσ(λx . τ) for (Πx : σ . τ).
This idea ﬁrst
appeared in print in [CHS72, Section 15A8], and was then developed in
[Sel79]; see also [HS86, Chapter 16]. This formalism requires a diﬀerent
form of the rules (Π e) and (Π i):
(G e)
M : Gστ
N : σ
MN : τN;

13C Basic generalized typing
183
(G i)
[x : σ]
M : τ
(λx.M) : Gσ(λx . τ)
Condition: x:σ is the only un-
discharged assumption in whose
subject x occurs free, and x does
not occur free in σ.
13C
Basic generalized typing, Curry-style in λ
We shall now deﬁne a system of dependent types using the approach
G1. This will be called basic generalized typing, and we will deﬁne it in
the Curry-style in λ. (The next section will make it clear how to modify
this system for Church-style typing.) The deﬁnition assumes that we are
given a set (possibly inﬁnite) of atomic type constants, θn
i , each with a
degree n, Each atomic type constant with degree n will represent a type
function intended to take n arguments, the value of which is a type. We
will begin with the deﬁnition of terms.
Deﬁnition 13.5 Terms are deﬁned as follows.
T1. Every variable is a term.
T2. Every atomic type constant is a term.
T3. If M and N are terms, then (MN) is a term.
T4. If x is a variable and M is a term, then (λx . M) is a term.
T5. If M and N are terms and x is a variable which does not occur
free in M, then (Πx:M . N) is a term.
Remark 13.6
In terms of the form (Πx : M . N), the scope of Πx is
said to be N, and Πx binds all free occurrences of x in N. Then the
deﬁnition of substitution is like Deﬁnition 1.12.
We will now deﬁne for this system types and type functions, which
will be denoted by lower case Greek letters.
Deﬁnition 13.7 (Type functions and types)
Type functions of
given degrees and ranks are deﬁned in terms of proper type functions,
which are deﬁned as follows.
B1. An atomic type constant of degree n is an atomic proper type
function of degree n and rank 0.
B2. If σ is a proper type function of degree m > 0 and rank k and M
is any term, then σM is a proper type function of degree m −1
and rank k.

184
Generalizations of typing
B3. If σ is a proper type function of degree m and rank k, then λx . σ
is a proper type function of degree m + 1 and rank k.
B4. If σ and τ are proper type functions of degree 0 and ranks k and
l respectively, and if x ̸∈FV(σ), then (Πx:σ . τ) is a proper type
function of degree 0 and rank 1 + k + l.
The term σ is a type function of rank k and degree m iﬀthere is a
proper type function τ of rank k and degree m and such that σ ▷β τ.
A type is a type function of degree 0.
When there is a need to distinguish the types of this deﬁnition from
the types deﬁned earlier, those types will be called simple types.
A type function of degree m represents a function of m arguments
which accepts types as inputs and produces types as outputs. The rank
of a type function measures the number of occurrences of Π in the normal
form of the term representing it.
Theorem 13.8 The degree and rank of a type function are unique.
For the proof, see [Sel79, Theorem 1.1].
Remark 13.9 The proof of [Sel79, Theorem 1.1] also shows that type
functions have the following properties.
(i) If σ is a type function of degree m and rank k, and if T is any
term such that T =β σ, then T is a type function of degree m and
rank k.
(ii) If σ is a type function of degree m and rank k, then λx . σ is a
type function of degree m + 1 and rank k.
(iii) If σ is a type function of degree m + 1 and rank k and if M is
any term, then σM is a type function of degree m and rank k.
(iv) The term Πx : σ . τ is a type function of degree 0 and rank k if
and only if σ is a type function of degree 0 and rank i, τ is a type
function of degree 0 and rank j, and k = 1 + i + j.
Remark 13.10 It turns out that in order for types to be more general
than simple types, there must be at least one atomic type constant of
degree greater than 0; see [Sel79, Corollary 1.1.1].
Corollary 13.10.1 If every atomic type constant has degree 0, then
every type converts to a simple type of the kind deﬁned in Deﬁnition
10.1, where σ →τ is deﬁned as (Πx:σ . τ) when x ̸∈FV(τ).

13C Basic generalized typing
185
Deﬁnition 13.11 (The type assignment system TAGλ)
The
system TAGλ (generalized type assignment to λ-terms) is a Natural
Deduction system whose formulas have the form
M : σ
for λ-terms M and types σ. TAGλ has no axioms. Its rules are the
following:
(Π e)
M : (Πx:σ . τ)
N : σ
MN : [N/x]τ
(Π i)
[x : σ]
M : τ
(λx.M) : (Πx:σ . τ)
Condition: x:σ is the only un-
discharged assumption in whose
subject x occurs free, and x does
not occur free in σ
(Eq
′′)
M : σ
σ =β τ
M : τ
(≡
′
α)
M : σ
M ≡α N
N : σ
Condition: M is not identical to
N.
Remark 13.12 Note that rule (≡
′
α) is not restricted here the way the
corresponding rule is in TA→
λ , to the case in which M :σ is an assump-
tion. If this restriction were adopted here, then deductions would no
longer be invariant under substitution, as the following example shows:
let θ be an atomic type constant of degree 1, let x and z be distinct
variables, and consider the deduction
1
[z : θx]
(λz . z) : (Πz :θx . θx).
(Π i −1)
Suppose we substitute z for x in this deduction. Since x occurs free only
in the type, and since
[z/x](Πz :θx . θx) ≡(Πu:θz . θz),
where u is the ﬁrst variable (in the given list of variables) distinct from
x and z, we would expect a deduction of
(λz . z) : (Πu:θz . θz).

186
Generalizations of typing
But without rule (≡
′
α) at the end of the deduction, this is impossible;
with (≡
′
α) at the end, the required deduction is
1
[u : θz]
(λu . u) : (Πu:θz . θz)
Π i −1
(λz . z) : (Πu:θz . θz).
(≡
′
α)
It is not hard to prove that rule (≡
′
α) can always be pushed down to the
bottom of a deduction, although at the cost of introducing some new
Eq
′′-steps.
Remark 13.13 The condition on rule (Π i) implies that if a sequence of
assumptions x1 :σ1, . . . , xn :σn is to be discharged in reverse numerical
order, the following condition must be satisﬁed: the variable xi does not
occur free in any of the types σ1, . . . , σi (but it may occur free in any of
the types σi+1, . . . , σn). This means that instead of sets of assumptions,
we will be interested in sequences of assumptions that assign types to
variables.
Deﬁnition 13.14
A context is a ﬁnite sequence of formulas of form
x1 :σ1, . . . , xn :σn, such that x1, . . . , xn are all distinct. (Cf. Deﬁnition
11.21.) It is legal for TAGλ iﬀit also satisﬁes
L1 For each i (1 ≤i ≤n), xi does not occur free in any of the types
σ1, . . . , σi (but it may occur free in any of σi+1, . . . , σn).
Note that contexts do not assign types to terms other than variables.
In systems of generalized typing, assigning types to atomic constants will
be done by axioms. (We will not be interested in axioms assigning types
to compound terms.) This leads to the following alternative formulation
of TAGλ.
Deﬁnition 13.15
The system TAGa
λ, the alternative formulation of
generalized typing, is a system with statements of the form
Γ ⊢M : σ,
where M is a term, σ is a type (in the sense of Deﬁnition 13.7), and Γ is
a context. There may be a set A of axioms of the form c:σ, where c is
an atomic constant and σ is a type. The rules of TAGa
λ are as follows:

13D Deductive rules
187
(axiom)
⊢c : σ
Condition: c:σ ∈A
(start)
Γ, x:σ ⊢x:σ
Condition:
x ̸∈FV(Γ, σ)
(weakening)
Γ ⊢M :τ
Γ, x:σ ⊢M : τ
Condition:
x ̸∈FV(Γ, σ)
(application) Γ ⊢M : (Πx:σ . τ)
Γ ⊢N : σ
Γ ⊢MN : [N/x]τ
(abstraction)
Γ, x:σ ⊢M :τ
Γ ⊢(λx:M) : (Πx:σ . τ)
Condition:
x ̸∈FV(Γ, σ)
(conversion)
Γ ⊢M : σ
σ =β τ
Γ ⊢M : τ
(α-conv)
Γ ⊢M : σ
M ≡α N
Γ ⊢N : σ
Condition: M is not
identical to N.
Note 13.16 With these rules, the assumptions to the left of the symbol
‘⊢’ are automatically built up as legal contexts.
13D
Deductive rules to deﬁne types
We now turn to systems using the approach G2, systems in which a
substitution instance of a type is only a type if the terms substituted for
variables match the types of the variables. In such systems, a statement
that a term is a type is not part of the syntax, but must be proved by the
deductive typing rules. To formulate the rules adequately, the system
must contain at least one type of types.
As an example of how this might work, let us digress for a short space
from dependent types to arrow types. Suppose we modify the system
TA→
λ by adding a new atomic constant ⋆to represent the type of types
(not including ⋆itself).1 This would give us the following system, called
λ →in the literature.2
1 It is necessary to specify that ⋆is not the type of ⋆itself, since ⋆: ⋆leads to a
contradiction.
2 See, for example, [Bar92, Deﬁnition 5.1.10] or [BDS, Section 1.1].

188
Generalizations of typing
Deﬁnition 13.17 The typing system λ →is deﬁned by adding to TA→
λ
(see Deﬁnition 12.6) the constant ⋆, the axioms
θ : ⋆
for each type-constant θ, and the rule
(→f)
σ : ⋆
τ : ⋆
(σ→τ) : ⋆
and then modifying rule (→i) as follows:
(→i)
[x : σ]
M : τ
(σ →τ) : ⋆
(λx . M) : (σ →τ)
Condition: x:σ is the only un-
discharged assumption in whose
subject x occurs free, and x does
not occur free in σ.
If we wanted to extend the system λ→to include the parametric types
of Deﬁnition 11.1, then we would need to add assumptions of the form
v:⋆for each type-variable v. This would mean that we would have
Γ ⊢TA→
λ
M : σ
if and only if
Γ, v1 :⋆, . . . , vn :⋆
⊢λ→M : σ,
where v1, . . . , vn are the type variables which occur in Γ and σ.
In the system λ →, a term M is a type iﬀeither M has type ⋆or
else M is ⋆; see [Bar92, Corollary 5.2.14, part 1].3 Types which play the
role of ⋆are called sorts. As we shall see below, a system can have more
than one sort.
Deﬁnition 13.18 In systems of type assignment in which being a type
is determined by the deductive axioms and rules, the types whose terms
are all types are called sorts.
In some systems rule (→i) is modiﬁed as follows:
(→i)
[x : σ]
M : τ
σ : ⋆
(λx . M) : (σ →τ)
Condition: x:σ is the only un-
discharged assumption in whose
subject x occurs free, and x does
not occur free in σ.
3 This corollary actually applies to pure type systems, or PTSs, which are discussed
below in Deﬁnition 13.34. It applies to this system because it is a PTS.

13D Deductive rules
189
If this rule together with the other rules of the system guarantee that
every term on the right of the colon in every step of a deduction is a
type, then this modiﬁcation does not change the provable formulas in
this system. However, in some systems, it makes a diﬀerence. We shall
see more about this below.
Rule (→f) is sometimes generalized as follows:
(→g)
σ : ⋆
[x : σ]
τ : ⋆
(σ→τ) : ⋆
Condition: x:σ is the only un-
discharged assumption in whose
subject x occurs free, and x does
not occur free in σ.
With this rule, the condition for being able to discharge assumptions
x1 :σ1, . . . , xn :σn in reverse order is as follows: the variables x1, . . . , xn
are all distinct and for each i,
Γ, x1 :σ1, . . . , xi−1 :σi−1
⊢
σi :⋆.
Note that here, variables do not occur in types. If they could occur
in types, we would have to specify that each xi does not occur free in
σ1, . . . , σi, but may occur free in σi+1, . . . , σn. This condition will be
included in the following deﬁnition for later comparison, although it will
have no application here.
Deﬁnition 13.19
A legal context for λ →is a context (i.e. a ﬁnite
sequence x1 :σ1, . . . , xn :σn with x1, . . . , xn distinct) which satisﬁes
L1. For each i (1 ≤i ≤n), xi does not occur free in any of σ1, . . . , σi
(but it may occur free in σi+1, . . . , σn),
L2. For each i (1 ≤i ≤n), either σi ≡⋆or
x1 :σ1, . . . , xi−1 :σi−1
⊢
σi : ⋆.
Then the alternative version of λ→corresponding to TAGa
λ is deﬁned
as follows.
Deﬁnition 13.20 Assume that there is a sequence θ1, . . . , θn, . . . , pos-
sibly inﬁnite, of atomic types, and assume that there is a symbol ⋆,
called a sort, distinct from θ1, . . . , θn, . . . . The typing system λ→a, the
alternative formulation of λ→, is a system with statements of the form
Γ ⊢M : σ,
where M and σ are λ-terms and Γ is a context. There is a set A of
axioms, which consists of θn :⋆for each n. The rules are as follows:

190
Generalizations of typing
(axiom)
⊢θi : ⋆
Condition: θi :⋆∈A
(start1)
Γ ⊢σ : ⋆
Γ, x:σ ⊢x:σ
Condition:
x ̸∈FV(Γ, σ)
(start2)
x:⋆⊢x:⋆
Condition:
x ̸∈FV(Γ)
(weakening1) Γ ⊢M : τ
Γ ⊢σ : ⋆
Γ, x:σ ⊢M : τ
Condition:
x ̸∈FV(Γ, σ)
(weakening2)
Γ ⊢M : τ
Γ, x:⋆⊢M : τ
Condition:
x ̸∈FV(Γ, σ)
(application) Γ ⊢M : σ →τ
Γ ⊢N : σ
Γ ⊢MN : τ
(abstraction) Γ, x:σ ⊢M :τ
Γ ⊢(σ→τ) : ⋆
Γ ⊢(λx:M) : σ→τ
Condition:
x ̸∈FV(Γ, σ)
(product)
Γ ⊢σ : ⋆
Γ, x:σ ⊢τ : ⋆
Γ ⊢(σ →τ) : ⋆
Condition:
x ̸∈FV(Γ, σ)
(conversion)
Γ ⊢M : σ
σ =β τ
Γ ⊢τ : ⋆
Γ ⊢M : τ
(α-conv)
Γ ⊢M : σ
M ≡α N
Γ ⊢N : σ
Condition: M is not
identical to N.
It can be shown that, with these rules, only a legal context can occur
to the left of the symbol ‘⊢’ in a deduction in λ→a.
Discussion 13.21 Let us now extend the G2 approach to types from
→-types to Π-types. To do this, a rule is needed that corresponds to
(→f) in Deﬁnition 13.17, and rule (Π i) in Deﬁnition 13.11 needs to be
modiﬁed. The rule corresponding to (→f) for a system with a dependent
function type would be
(Π f)
σ : ⋆
[x : σ]
τ : ⋆
(Πx:σ . τ) : ⋆
Condition: x : σ is the only un-
discharged assumption in whose
subject x occurs free, and x does
not occur free in σ;

13E Church typing in λ
191
and the modiﬁed form of rule (Π i) would be
(Π i)
[x : σ]
M : τ
(Πx:σ . τ) : ⋆
(λx.M) : (Πx:σ . τ)
Condition: x:σ is the only un-
discharged assumption in whose
subject x occurs free, and x does
not occur free in σ.
In terms of the deﬁnition of types, if the only axioms were of the form
θi : ⋆, then it would not be diﬃcult to see that with these two rules
and (Π e), (Eq′′) and (≡′
α) as in Deﬁnition 13.11, we would not get a
system any more general than λ→a, and in all occurrences of types of
the form (Πx : σ . τ) we would get x ̸∈FV(τ), so that, as indicated in
the third paragraph of Section 13B, this type would really be σ →τ.
Thus, if these were all the changes we made, the system would be no
more general than λ→a.
We could try to obtain a more general system by postulating type
functions of degree 1 or more. But the axioms for such type functions
would have to take the form
θ : (Πx1 :σ1 . Πx2 :σ2 . . . . . Πxn :σn . ⋆).
But with the rules we have so far, it is impossible to prove that
(Πx1 :σ1 . Πx2 :σ2 . . . . . Πxn :σn . ⋆) : ⋆,
and so we would lose an important property: that every term occurring
to the right of a colon in a proof is either a term of type ⋆or else converts
to ⋆. We need another form of generalization.
The other form of generalization which has become standard today is
to have more than one sort, and to adopt axioms that allow some sorts
to be terms of the type of another sort. For example, we can take the
sorts to be ⋆and 2, and postulate as an axiom ⋆: 2.
The systems we consider in the rest of this chapter will be of this kind.
13E
Church-style typing in λ
Most of the generalized systems considered today are really systems of
Church typing.
In Chapter 10, abstractions were written in the form λxσ .M. This
was ﬁne for these systems because the types were formed in such a simple
way. However, in the generalized systems we are considering here, where

192
Generalizations of typing
types are terms which may contain variables and where the deduction
rules determine which of these terms are really types, this turns out to
be inconvenient. Thus, in these systems, abstraction terms are written
λx:σ . M.
For the systems in the present section, the deﬁnition of the terms will
be in two stages: ﬁrst, expressions called pseudoterms will be deﬁned,
and then the deduction rules of each system will determine when a pseu-
doterm is a proper term in that system. For example, in an abstraction
λx:σ . M, σ may be a pseudoterm or a term that is not a type, and the
whole expression may be just a pseudoterm.
Since the types are just terms of a certain kind, from now on we shall
use A, B, etc. for σ, τ. When the types are variables, we shall use
lower-case Roman letters, such as x, y, z, etc.
Deﬁnition 13.22
Pseudoterms are deﬁned as follows.
PT1. Every variable is a pseudoterm.
PT2. Every atomic type constant is a pseudoterm.
PT3. If M and N are pseudoterms, then (MN) is a pseudoterm.
PT4. If x is a variable and M and N are pseudoterms, then (λx:M . N)
is a pseudoterm.
PT5. If M and N are pseudoterms and x is a variable which does not
occur free in M, then (Πx:M . N) is a pseudoterm.
For pseudoterms, reduction is deﬁned by replacing ordinary β-con-
tractions by contractions of the form
(λx:A . M)N
▷[N/x]M.
In his survey paper [Bar92, Section 5], Henk Barendregt introduced a
group of eight typing systems which he called the ‘λ-cube.’ All are based
on the dependent function type, and all are based on two sorts, ⋆and
2. These systems have only one axiom: ⋆: 2. The rules are like those
of λ→a. Here is the formal deﬁnition.
Deﬁnition 13.23 (λ-cube) The eight typing systems of the λ-cube are
all based on pseudoterms. The systems all have two special constants,
⋆and 2, which are called sorts. Each system has one axiom, namely
⋆: 2. Each system also has a set R of special rules, each of which is of
the form (s1, s2), where s1 and s2 are sorts; i.e., each of s1 and s2 is one
of ⋆and 2. The deduction rules of the system are as follows:

13E Church typing in λ
193
(axiom)
⊢⋆: 2
(start)
Γ ⊢A : s
Γ, x:A ⊢x:A
Condition: x ̸∈
FV(Γ, A) and s
is a sort
(weakening) Γ ⊢M :B
Γ ⊢A:s
Γ, x:A ⊢M :B
Condition: x ̸∈
FV(Γ, A) and s
is a sort
(application) Γ ⊢M :(Πx:A . B)
Γ ⊢N :A
Γ ⊢MN :[N/x]B
(abstraction) Γ, x:A ⊢M :B
Γ ⊢(Πx:A . B):s
Γ ⊢(λx:A . M) : (Πx:A . B)
Condition: x ̸∈
FV(Γ, A) and s
is a sort
(product)
Γ ⊢A:s1
Γ, x:A ⊢B :s2
Γ ⊢(Πx:A . B):s2
Condition: x ̸∈
FV(Γ, A) and s1
and s2 are sorts,
and (s1, s2) ∈R
(conversion) Γ ⊢M :A
A =β B
Γ ⊢B :s
Γ ⊢M :B
Condition:
s is
a sort
(α-conv)
Γ ⊢M :A
M ≡α N
Γ ⊢N :A
Condition: M is
not identical to
N.
A pseudocontext is a sequence of formulas of the form x1 :A1, . . . , xn :An,
where x1, . . . , xn are distinct variables and A1, . . . , An are pseudoterms.
A pseudocontext is a legal context iﬀthe following two conditions are
satisﬁed.
L1. The variable xi does not occur free in A1, . . . , Ai (although it
may occur free in Ai+1, . . . , An);
L2. For each i (1 ≤i ≤n), either Ai ≡s or
x1 :A1, . . . , xi−1 :Ai−1
⊢
Ai : s
for some sort s (depending on i).
A pseudoterm M is a term iﬀthere are a legal context Γ and a pseu-
doterm A such that
Γ ⊢M : A.

194
Generalizations of typing
A pseudoterm A is a type iﬀthere are a legal context Γ and a pseudoterm
M such that
Γ ⊢M : A.
The eight speciﬁc systems are determined by the set R of special rules,
as indicated by the following table (from [Bar92, p. 205]):
System
R
λ→
(⋆, ⋆)
λ2
(⋆, ⋆)
(2, ⋆)
λP
(⋆, ⋆)
(⋆, 2)
λP2
(⋆, ⋆)
(2, ⋆)
(⋆, 2)
λω
(⋆, ⋆)
(2, 2)
λω
(⋆, ⋆)
(2, ⋆)
(2, 2)
λPω
(⋆, ⋆)
(⋆, 2)
(2, 2)
λPω = λC
(⋆, ⋆)
(2, ⋆)
(⋆, 2)
(2, 2)
The λ-cube is often represented by the diagram in Figure 13:1.
(   ,   )
λ
λ2
λω
λ
λ
λ
λω
λ
P2
P
P
C
ω
(*,   )
(   ,*)
Fig. 13:1 Barendregt’s λ-cube
Remark 13.24 It can be proved that the rules of these systems guar-
antee that only legal contexts can appear on the left of the symbol ‘⊢’
in any deduction. Furthermore, for Γ to be a legal context is equivalent
to Γ ⊢⋆: 2 being derivable in the system, [Sel97, Theorem 14]. And
if Γ ⊢⋆: 2 is derivable in any of these systems, then for any initial
segment Γ′ of Γ, Γ′ ⊢⋆: 2 is also derivable, [Sel97, Lemma 9]. (The

13E Church typing in λ
195
proofs in [Sel97] are for λC, but they apply to all the systems of the
λ-cube.)
Deﬁnition 13.25 The arrow type A →B is deﬁned to be (Πx:A . B)
where x ̸∈FV(B).
Remark 13.26
Given the above deﬁnition of →, the system called
λ →in the λ-cube is really the same as λ →a in Deﬁnition 13.20. This
is because, by [Bar92, Lemma 5.1.14], if Γ ⊢A : ⋆can be proved in
the λ-cube version of λ →, then A is built up from the set of all terms
B such that B :⋆occurs in Γ, using only →.
The following are some examples of what can can be derived in λ→:4
u : ⋆
⊢
(u →u) : ⋆
u : ⋆, v : ⋆
⊢
(u →v) : ⋆
u : ⋆
⊢
(λx:u . x) : (u →u)
u : ⋆, v : ⋆, y : v
⊢
(λx:u . y) : (u →v)
u : ⋆, y : u
⊢
((λx:u . x)y) : u
u : ⋆, v : ⋆, y : v, z : u
⊢
((λx:u . y)z) : v
u : ⋆, v : ⋆
⊢
(λx:u . λy:v . x) : (u →(v →u)).
For example, the ﬁrst of these can be derived as follows:
⊢⋆:2
(axiom)
u:⋆⊢u:⋆
(start)
⊢⋆:2
(axiom)
u:⋆⊢u:⋆
(start)
⊢⋆:2
(axiom)
u:⋆⊢u:⋆
(start)
u:⋆, x:u ⊢u:⋆
(weakening)
u:⋆⊢(u →u):⋆.
(product)
Note that the only special rule in this system is (⋆, ⋆), which occurs
in all the systems of the λ-cube. It allows the system to say that certain
terms are types, but, in a sense to be explained below, it does not allow
quantiﬁcation over types.
Remark 13.27 The system λ2 has, besides (⋆, ⋆), the special rule (2, ⋆)
(and it is the weakest system in the λ-cube which has this rule). This
rule makes it possible to quantify over ⋆, as the following example will
4 The examples in this and the following remarks come from [Bar92, Exs. 5.1.15].

196
Generalizations of typing
show. From
u : ⋆⊢(u →u) : ⋆,
which can be derived in λ→, and from the axiom
⊢⋆: 2,
we can use the rule (product) to derive
⊢(Πu:2 . u →u) : ⋆.
From this and
u : ⋆⊢(λx:u . x) : u →u
(which can already be derived in λ →), we can now derive by the rule
(abstraction),
⊢(λu:⋆. λx:u . x) : (Πu:⋆. u →u).
(1)
Now (λx:u . x) is the identity function on type u, or what was called Iu
in Chapter 10. Hence
(λu:⋆. λx:u . x)
is a function which, when applied to any type in sort ⋆, gives the identity
function over that type. Thus in λ2 we have quantiﬁcation over types.
Note that (1) implies
v : ⋆
⊢
(λu:⋆. λx:u . x)v : (v →v),
and hence
v : ⋆, y : v
⊢
(λu:⋆. λx:u . x)vy : v.
We also have the following reduction:
(λu:⋆. λx:u . x)vy
▷β
(λx:v . x)y
▷β
y.
Another example shows the connection with second-order logic. Let
⊥≡(Πu : ⋆. u).
Then ⊥represents the usual deﬁnition of falsum
(a generalized contradiction, usually taken to be (∀u)u in second-order
logic). We can derive
⊢(λv:⋆. λx:⊥. xv) : (Πv:⋆. ⊥→v).
When this is considered under the propositions-as-types interpretation,
it says that anything follows from a contradiction, the principle of ex
falso quodlibet.

13E Church typing in λ
197
The system λ2 is a slightly modiﬁed form of the second-order poly-
morphic λ-calculus, or System F, originally introduced independently
by Girard in [Gir71, Gir72] and Reynolds in [Rey74]. In Reynold’s no-
tation, types are obtained from the types of Deﬁnition 11.1 by adding
a new abstraction operator ∆for type variables, so that the type we
are writing as (Πu : ⋆. σ) is written ∆u . σ. Then, for terms, in addi-
tion to the term abstraction λx : σ . M, there is a term abstraction for
type variables of the form Λu . M. Then the term we have written as
(λu:⋆. λx:u . x) would be written (Λu . λx:u . x). Thus, although there
is some interplay between the terms and the types, types can still be
deﬁned separately from the terms.
Note that from the viewpoint of the propositions-as-types idea, ⋆is a
sort of propositions. In some works, ⋆is written as Prop, and in many
of these same works, 2 is written as Type.
Remark 13.28 The system λω is closely related to POLYREC, a lan-
guage with polymorphic and recursive types (see [RdL92]). A recursive
type is one deﬁned by initial elements and constructor functions. In a
language such as ML, the natural number type nat is a recursive type
with initial element 0 and constructor succ (for successor). (The type
nat has the property that only natural numbers inhabit it.) For such
a system, we need type constructors, and the special rule (2, 2) allows
for them. For we have the following derivation:
⊢⋆: 2
(axiom)
⊢⋆: 2
(axiom)
⊢⋆: 2
(axiom)
x : ⋆⊢⋆: 2
(weakening)
⊢(⋆→⋆) : 2.
(product)
The type (⋆→⋆) is the type of type constructors and it is the result of
the above derivation that allows the use of this type in this system. We
can also derive the following examples:
⊢
(λu:⋆. (u →u)) : (⋆→⋆)
v : ⋆
⊢
(λu:⋆. u →u)v
v : ⋆, x : v
⊢
(λy:v . x) : (λu:⋆. u →u)v
u : ⋆, f : ⋆→⋆
⊢
f(fu) : ⋆
u : ⋆
⊢
(λf :(⋆→⋆) . f(fu)) : (⋆→⋆) →⋆.
The term in the last example, (λf :(⋆→⋆) . f(fu)), is an example of a

198
Generalizations of typing
higher-order type constructor: it takes as its argument a type construc-
tor f, and its value is a type.
Remark 13.29 The system λP has the special rule (⋆, 2), which allows
for types which depend on terms. For example, we have the following
derivation:
D
u : ⋆⊢u : ⋆
(start)
D
D
u : ⋆⊢⋆: 2
(wk)
D
u : ⋆⊢u : ⋆
(start)
u : ⋆, x : u ⊢⋆: 2
(wk)
u : ⋆⊢(u →⋆) : 2
(product)
where D is
⊢⋆: 2
(axiom)
and (wk) is (weakening). The type (u →⋆) is a type of types which
depend on terms. Then using rule (application) we can derive
u : ⋆, p : (u →⋆), x : u
⊢
px : ⋆,
so px is a type which depends on the term x.5 If we think of u as a set
with x ∈u, and think of p as a predicate on u, then px is a proposition,
which is true if it is inhabited6 and false otherwise. We can also derive
u : ⋆, p : (u →u →⋆)
⊢
(Πx:u . pxx) : ⋆,
and under an informal propositions-as-types interpretation this says that
if p is a binary predicate on u then (∀x ∈u)pxx is a proposition. We
can also derive
u : ⋆, p : (u →⋆), q : (u →⋆)
⊢
(Πx:u . (px →qx)) : ⋆,
and the type (Πx : u . (px →qx)) is interpreted as the proposition which
states that the predicate p is included in the predicate q. We can also
derive the following:
u : ⋆, p : (u →⋆)
⊢
(Πx:u . (px →px)) : ⋆,
where (Πx:u . (px →px)) is the type which is interpreted as the reﬂex-
ivity of inclusion, and from this we can derive
u : ⋆, p : (u →⋆)
⊢
(λx:u . λy:pa . x) : (Πx:u . (px →px)),
5 Of course, here p and x are variables, but arbitrary terms could be substituted for
them, so that this implies that if Γ ⊢U : ⋆, Γ ⊢P : (U →⋆), and Γ ⊢M : U,
then Γ ⊢P M : ⋆, and then P M is a type which depends on the term M .
6 In the sense of Deﬁnition 11.50.

13E Church typing in λ
199
and (λx : u . λy : pa . x) is interpreted as the proof that inclusion is re-
ﬂexive. Finally, we can derive
u : ⋆, p : (u→⋆), q : ⋆
⊢

(Πx:u . px→q) →(Πx:u . px)→q

: ⋆,
u : ⋆, p : (u→⋆), q : ⋆, z : u
⊢

λv:(Πx:u . px→q) . λw:(Πx:u . px) . vz(wz)

:

Πv:(Πx:u . px→q) . Πw:(Πx:u . px) . q

,
where the last type is equivalent to
(Πx:u . (px →q) →(Πx:u . px) →q),
which is interpreted as saying that the formula
(∀x ∈u)(px →q) →(∀x ∈u)(px) →q
is true in a non-empty structure u.
The system λP is related to the system AUT-QE of [Bru70]7 and the
system LF of [HHP87]. For a more exact description of the relationship,
see [KLN04, Section 4c1, p. 121, footnotes 3 and 4].
Remark 13.30
The system λω, which includes the rules (2, ⋆) and
(2, 2) as well as (⋆, ⋆), combines features of λω and λ2 and is related to
the system Fω of [Gir72]. To see its strength, for u:⋆and v:⋆, deﬁne
u ∧v
≡
Πw:⋆. (u →v →w) →w.
This is the standard second-order deﬁnition of conjunction, as we shall
see in Section 13G, and can be deﬁned in λ2. Then, as can also be done
in λ2, we can derive
u : ⋆, v : ⋆
⊢
u ∧v : ⋆.
(2)
If we now deﬁne
AND ≡λu:⋆. λv:⋆. u ∧v,
and
K ≡λu:⋆. λv:⋆. λx:u . λy:v . x,
then we can derive
⊢AND : (⋆→⋆→⋆)
(3)
and
⊢K : (Πu:⋆. Πv:⋆. u →v →u).
(4)
7 See also [NG94], [Daa94] and [NGdV94].

200
Generalizations of typing
Here, (4) can be derived in λ2, but (3) cannot, since rule (2, 2) is needed
to obtain it by (abstraction) from (2). Also, we can derive
u : ⋆, v : ⋆
⊢
(λx : ANDuv . xu(Kuv)) : (ANDuv →u)
and
u : ⋆, v : ⋆
⊢
(ANDuv →u) : ⋆.
Here, the term (λx : ANDuv . xu(Kuv)) can be interpreted as a proof
that ANDuv →u is a tautology.
Remark 13.31
The system λP2, which includes the rules (2, ⋆) and
(⋆, 2) as well as (⋆, ⋆), combines features of λ2 and λP, and is related to
a system in [LM91]. Informally speaking, it corresponds to second order
predicate logic. In it, the following can be derived:
u : ⋆, p : u →⋆
⊢
(λx:u . px →⊥) : (u →⋆)
and
u : ⋆, p : u →u →⋆
⊢

(Πx:u . Πy:u . pxy →pyx →⊥) →(Πx:u . puu →⊥)

: ⋆.
The second of these says that a binary relation which is asymmetric is
irreﬂexive.
Remark 13.32 The system λPω, which has the rules (⋆, 2) and (2, 2)
as well as (⋆, ⋆), has features of both λP and λω. In this system, it is
possible to derive
u : ⋆⊢(λp : u →u →⋆. λx:u . pxx) : ((u →u →⋆) →(u →⋆))
and
u : ⋆
⊢
((u →u →⋆) →(u →⋆)) : 2.
The term (λp : u →u →⋆. λx : u . pxx) is a constructor which assigns
to a binary relation its ‘diagonalization’. This can be extended so that
it does the same thing uniformly on u:
⊢(λu:⋆. λp:u →u →⋆. λx:u . pxx) :
(Πu:⋆. Πp : u →u →⋆. Πx:u . ⋆)
and
⊢(Πu:⋆. Πp : u →u →⋆. Πx:u . ⋆) : 2.

13E Church typing in λ
201
Remark 13.33 The system λC, which includes the rules (2, ⋆), (⋆, 2)
and (2, 2) as well as (⋆, ⋆), is the calculus of constructions of [CH88],
which under the propositions-as-types interpretation is higher-order in-
tuitionistic logic, and is the basis of the proof assistant Coq. This system
includes features of all the systems of the λ-cube. In it, for example, the
following can be derived:
⊢(λu:⋆. λp:(u →⋆) . λx:u . x →⊥) : (Πu:⋆. (u →⋆) →(u →⋆))
and
⊢(Πu:⋆. (u →⋆) →(u →⋆)) : 2.
The term (λu : ⋆. λp : (u →⋆) . λx : u . x →⊥) is a constructor which
assigns to a type u and a predicate p on u the negation of p. We can
also do universal quantiﬁcation uniformly by deﬁning
ALL ≡(λu:⋆. λp:(u →⋆) . Πx:u . px);
then we have
A : ⋆, P : A →⋆
⊢
ALLAP : ⋆
and
ALLAP =β (Πx:A . Px).
The systems of the λ-cube can be generalized to pure type systems:
Deﬁnition 13.34 (Pure type systems)
Pure type systems (PTSs)
are deﬁned by modifying Deﬁnition 13.23 as follows: arbitrary constants
diﬀerent from all other constants in the system are now allowed as sorts,
there is a set A of axioms of the form s1 : s2, where s1 and s2 are sorts,
the rule (axiom) now has the form
s1 : s2,
for every axiom s1 : s2 ∈A, the special rules in R are now to be taken
in the form (s1, s2, s3), and the rule (product) is now to be taken in the
following form:
(product)
Γ ⊢A : s1
Γ, x : A ⊢B : s2
Γ ⊢(Πx:A . B) : s3
Condition:
x ̸∈FV(Γ, A),
s1,
s2
and s3
are
sorts,
and
(s1, s2, s3) ∈R.

202
Generalizations of typing
In these systems, (s1, s2) is taken to be an abbreviation for the rule
(s1, s2, s2).
The set of sorts is denoted by S, and the pure type system is said to
be determined by S, A, and R.
Clearly, the systems of Barendregt’s λ-cube are all pure type systems.
Another important pure type system is Luo’s extended calculus of con-
structions [Luo90].
Example 13.35 Luo’s extended calculus of constructions, ECC, is the
PTS determined by the following sets:
S
=
{⋆} ∪{2n : n a non-negative integer},
A
=
{⋆: 20} ∪{2n :2n+1 : n a non-negative integer},
R
=
{(⋆, ⋆, ⋆), (⋆, ⋆, 2n), (2n, ⋆, ⋆), (2n, ⋆, 2m) : 0 ≤n ≤m}
∪{(⋆, 2n, 2m) : n ≤m}
∪{(2n, 2m, 2r) : 0 ≤n ≤r and 0 ≤m ≤r}.
13F
Normalization in PTSs
In this section we will take up the basic meta-theory of PTSs. Note
that we have already stated in Deﬁnition 13.23 that the systems of the
λ-cube are based on pseudoterms as deﬁned in Deﬁnition 13.22. This is
also true of PTSs. In what follows, we assume that we are dealing with
a particular PTS.
The deﬁnitions of pseudocontext and legal context are the same for
PTSs in general as for the eight systems of the λ-cube.
We re-state
them here for ease of reference.
Deﬁnition 13.36 A pseudocontext is a sequence of the form
Γ ≡x1 :A1, . . . , xn :An,
where the variables x1, . . . , xn are all distinct. It is said to be a legal
context (for a given PTS) iﬀthere are pseudoterms M and A such that
Γ ⊢M : A.
In the rest of this chapter ‘Γ’ denotes an arbitrary pseudocontext.

13F Normalization in PTSs
203
Deﬁnition 13.37 If Γ ≡xa :A1, . . . , xn :An, we say that a formula
x:A is in Γ, or (x:A) ∈Γ, iﬀx ≡xi and A ≡Ai for some i, 1 ≤i ≤n.
Deﬁnition 13.38 Let ∆≡u1 :B1, . . . , um :Bm be a pseudocontext
with m > 1. Then Γ ⊢∆means
Γ ⊢u1 :B1 and . . . and Γ ⊢um :Bm.
Lemma 13.39 (Restricted weakening)
If Γ ⊢M : A, we may as-
sume that the only applications of the rule (weakening) in the derivation
of Γ ⊢M :A are of the form
Γ ⊢a : B
Γ ⊢B : s
Γ, x : B ⊢a : B,
where s is a sort and a is either a variable or a constant.
Proof [Geu93, Lemma 4.4.21].
Lemma 13.40 (Free variable lemma) Let Γ ≡x1 :A1, . . . , xn :An,
and suppose Γ ⊢M :A. Then
(i) every variable occurring free in M or in A is in {x1, . . . , xn};
(ii) for 1 ≤i ≤n, the variables occurring free in Ai are among
x1, . . . , xi−1 .
Proof [Bar92, Lemma 5.2.8].
Lemma 13.41 (Start lemma) Let Γ ≡x1 :A1, . . . , xn :An be legal
for a PTS whose set of axioms is A. Then
(i) Γ ⊢s1 : s2 for all (s1 : s2) ∈A;
(ii) for each i = 1, . . . , n, Γ ⊢xi : Ai.
Proof [Bar92, Lemma 5.2.9].
Lemma 13.42 (Transitivity lemma) Let Γ and ∆be pseudocontexts.
If Γ ⊢∆and ∆⊢M :A, then
Γ ⊢M : A.
Proof [Bar92, Lemma 5.2.10].

204
Generalizations of typing
Lemma 13.43 (Substitution lemma) If Γ and ∆are pseudocontexts
with no subjects in common, and x ̸∈FV(Γ) and x is not a subject in
∆, and
Γ, x : A, ∆⊢M : B
and
Γ ⊢N : A,
then
Γ, [N/x]∆⊢[N/x]M : [N/x]B.
Proof [Bar92, Lemma 5.2.11]. Note that it follows from that proof that
the derivation of the conclusion does not introduce any new inferences
by (product) that use a special rule (as deﬁned in Deﬁnition 13.23) not
already present in the derivation of the ﬁrst premise of the lemma. We
shall use this fact below.
Lemma 13.44 (Thinning lemma)
If Γ and ∆are legal, and every
(x : A) ∈Γ is also in ∆, and Γ ⊢M : A, then
∆⊢M : A.
Proof [Bar92, Lemma 5.2.12].
Lemma 13.45 (Generation lemma)
(i) If
Γ ⊢s : C, where s is a sort, then there is a sort s′ such that
C =β s′ and s:s′ ∈A.
(ii) If
Γ ⊢x : C, then there are a sort s and a pseudoterm B such
that
B =β C,
Γ ⊢B : s,
(x:B) ∈Γ.
(iii) If
Γ ⊢(Πx:A . B) : C, then there are sorts s1, s2, and s3 such
that (s1, s2, s3) ∈R and
Γ ⊢A : s1,
Γ, x : A ⊢B : s2,
C =β s3.
(iv) If Γ ⊢(λx:A . M) : C, then there are a sort s and a pseudoterm
B such that
Γ ⊢(Πx:A . B) : s,
Γ, x : A ⊢M : B,
C =β (Πx:A . B).
(v) If
Γ ⊢MN : C, then there are pseudoterms A and B such that
Γ ⊢M : (Πx:A . B),
Γ ⊢N : A,
C =β [N/x]B.
Proof [Bar92, Lemma 5.2.13].

13F Normalization in PTSs
205
Remark 13.46
In a sense, this lemma corresponds to the subject-
construction property discussed in Section 11C, and to Curry’s Subject-
construction theorem, [CF58, Theorem 9B1].
Lemma 13.47 (Correctness of types) If Γ ⊢M : A, then there is
a sort s such that A =β s or Γ ⊢A : s.
Proof [Bar92, Corollary 5.2.14, part 1].
Lemma 13.48 If
Γ ⊢M : (Πx:B1 . B2), then there are sorts s1 and
s2 such that
Γ ⊢B1 : s1 and
Γ, x : B1 ⊢B2 : s2.
Proof [Bar92, Corollary 5.2.14, part 2].
Lemma 13.49 If
Γ ⊢A : B or
Γ ⊢B : A, then either (i) there is a
sort s such that A =β s, or (ii) there is a sort s such that
Γ ⊢A : s,
or (iii) there are a sort s and a pseudoterm C such that
Γ ⊢A : C
and
Γ ⊢C : s.
Proof [Bar92, Corollary 5.2.14, part 3].
Deﬁnition 13.50 A pseudoterm A for which there are an environment
Γ and a pseudoterm B such that either Γ ⊢A : B or Γ ⊢B : A is said
to be legal.
Thus, the hypothesis of Lemma 13.49 is that A be legal.
Lemma 13.51 (Subterm lemma)
If A is legal and B is a subterm
of A, then B is legal.
Proof [Bar92, Corollary 5.2.14, part 4].
Theorem 13.52 (Subject-reduction theorem) If
Γ ⊢M : A
and
M
▷β
M ′,
then
Γ ⊢M ′ : A.
Proof [Bar92, Theorem 5.2.15].

206
Generalizations of typing
Corollary 13.52.1 If Γ ⊢M : A and A ▷β A′, then Γ ⊢M : A′.
Proof [Bar92, Corollary 5.2.16, part 1].
Lemma 13.53 (Strengthening lemma) If
Γ, x : A, ∆is a pseu-
docontext and
Γ, x : A, ∆
⊢
M : B
and x ̸∈FV(∆) ∪FV(M) ∪FV(B), then
Γ, ∆⊢M : B.
Proof [vBJ93, Lemma 6.2].
Corollary 13.53.1 For a PTS with a ﬁnite set of sorts, with the prop-
erty that every legal term is weakly or strongly normalizing, the questions
of type checking and typability are decidable.
Proof [vBJ93, Theorem 7.5].
Deﬁnition 13.54 A PTS given by S, A, and R is singly sorted iﬀ
(i) if (s1, s2), (s1, s′
2) ∈A, then s2 ≡s′
2;
(ii) if (s1, s2, s3), (s1, s2, s′
3) ∈R, then s3 ≡s′
3.
Example 13.55
(i) The PTSs of the λ-cube are singly sorted.
(ii) The PTS speciﬁed by
S
=
{⋆, 2, 3}
A
=
{⋆:2, ⋆:3}
R
=
{(⋆, ⋆), (⋆, 2)}
is not singly sorted.
Lemma 13.56 (Unicity of types) In a singly sorted PTS, if
Γ ⊢M : A
and
Γ ⊢M : A′,
then A =β A′.
Proof [Bar92, Lemma 5.2.21].

13F Normalization in PTSs
207
Lemma 13.57 (Strong permutation lemma) If
Γ, x:A, y :B is
a pseudocontext, and
Γ, x : A, y : B
⊢
M : C,
and x ̸∈FV(B), then
Γ, y : B, x : A
⊢
M : C.
See [KLN04, Lemma 4.37, page 122].
Deﬁnition 13.58 (Topsort) A sort s is a topsort iﬀthere is no sort
s′ such that (s, s′) ∈A.
Lemma 13.59 (Topsort lemma) If s is a topsort and Γ ⊢A:s, then
A is not of the form A1A2 or λx:A1 . A2.
See [KLN04, Lemma 4.39, page 123].
Theorem 13.60 (Strong normalization theorem for the λ-cube)
For systems of the λ-cube,
(i) if
Γ ⊢M : A, then M and A are SN;
(ii) if
x1 : A1, . . . , xn : An ⊢M : B, then A1, . . . , An, M and B
are SN.
Proof
[Bar92, Theorems 5.3.32 and 5.3.33]. Note that the theorem is
proved for λC, the strongest system of the cube, from which it follows
for all the other systems.
Remark 13.61
The theorem also holds for Luo’s ECC of Example
13.35; see [Luo90, Corollary 5.12.14]. Since λC is a subsystem of ECC,
the above theorem follows from Luo’s result.
Remark 13.62 The proof of Theorem 13.60 in [Bar92] does not follow
the form of Theorems 11.56 and 12.33 in reducing deductions.
The
proof can be carried out this way by deﬁning reductions of deductions
as follows.

208
Generalizations of typing
Deduction reduction A deduction of the form
Γ, x:A ⊢M :B
Γ ⊢(Πx:A . B) : s
Γ ⊢(λx:A . M) : (Πx:A . B)
(abstraction)
Γ ⊢(λx:A . M) : (Πx:C . D)
(conversion)
Γ ⊢N :C
Γ ⊢(λx:A . M)N : [N/x]D
(a)
where (a) is the rule (application), x ̸∈FV(Γ, A), A =β C, and B =β D,
reduces to
Γ, x:A ⊢M :B
Γ ⊢N :C
Γ ⊢N :A
(conversion)
Γ ⊢[N/x]M : [N/x]B
(substitution lemma, 13.43)
Γ ⊢[N/x]M : [N/x]D.
(conversion)
A proof that every deduction can be strongly normalized with respect to
this reduction rule is given for λC in [Sel97, Theorem 11]. As noted above
in the proof of Lemma 13.43, the transformation of the proof using that
lemma does not introduce any inferences by (product) using a special
rule not already present in the deduction before the substitution, and
hence it follows that the result holds for all systems of the λ-cube. We
conjecture that it also holds for Luo’s ECC, but we have not checked
the details.
Warning 13.63
(βη-conversion) In simply typed λ-calculus it was
easy to add a rule for η-conversion, as in Deﬁnition 10.16. But in a PTS
the syntax of terms is more complex, and if η-reductions were allowed,
the Church–Rosser theorem would fail. This is shown by the following
example, due to Nederpelt [NGdV94, Chapter C.3, Section 7]. Let x, y,
and z be distinct variables, and consider the term λx : y . (λx : z . x)x.
We would have
λx:y . (λx:z . x)x ▷β
λx:y . x
by contracting the β-redex (λx:z . x)x, and we would also have
λx:y . (λx:z . x)x ▷η
λx:z . x
by contracting the η-redex λx:y . (λx:z . x)x. But λx:y . x and λx:z . x
are both irreducible, and they are distinct normal forms.

13G Propositions-as-types
209
13G
Propositions-as-types
Logical connectives and quantiﬁers can be represented in many systems
of the λ-cube.8 These systems can be viewed either as systems of type-
theory, in which an expression M :A says that M has type A, or systems
of logic, in which the A in M :A is interpreted as a logical formula and
M is thought of as encoding a proof of A. When the systems are seen
from the second viewpoint, the logic that they express turns out to be,
not the classical logic of two-valued truth-tables, but the logic of the
intuitionists that was mentioned in Discussion 11.49, and is important
in the theoretical foundations of computing.
The discussion in the present section will apply to λ2 and those sys-
tems stronger than it, namely λP2, λω and λC.
Deﬁnition 13.64 The term F is deﬁned as follows:
F
≡
λu:⋆. λv:⋆. (Πx:u . v).
We use either ‘A →B’ (see Deﬁnition 13.25) or ‘A ⊃B’, as an abbrevi-
ation for FAB, depending on whether we wish to emphasize a particular
expression’s role as a type or a logical formula.
It is easy to show that in λ2 and all stronger systems, →satisﬁes the
rules
Γ ⊢A : ⋆
Γ ⊢B : ⋆
Γ ⊢(A →B) : ⋆,
Γ ⊢M : A →B
Γ ⊢N : A
Γ ⊢MN : B,
and, if x ̸∈FV(B),
Γ, x : A ⊢M : B
Γ ⊢A →B : ⋆
Γ ⊢(λx:A . M) : A →B.
This means, of course, that ⊃satisﬁes rules
Γ ⊢A : ⋆
Γ ⊢B : ⋆
Γ ⊢(A ⊃B) : ⋆,
Γ ⊢M : A ⊃B
Γ ⊢N : A
Γ ⊢MN : B,
8 The material of this section is a revision of the material of [Sel97, Sections 6, 9].

210
Generalizations of typing
and, if x ̸∈FV(B),
Γ, x : A ⊢M : B
Γ ⊢A ⊃B : ⋆
Γ ⊢(λx:A . M) : A ⊃B.
Deﬁnition 13.65 The conjunction proposition operator and its associ-
ated pairing and projection operators are deﬁned as follows:
(a) Λ ≡λu:⋆. λv:⋆.

Πw:⋆. (u →v →w) →w

;
(b) D ≡λu:⋆. λv:⋆. λx:u . λy:v . λw:⋆. λz :(u →v →w) . zxy;
(c) fst ≡λu:⋆. λv:⋆. λx:(Λuv) . xu(λy:u . λz :v . y);
(d) snd ≡λu:⋆. λv:⋆. λx:(Λuv) . xv(λy:u . λz :v . z).
We use ‘A ∧B’ and ‘A × B’ as abbreviations for ΛAB, the former in
logic and the latter in type-theory. (For D, fst and snd, cf. D, D1 and
D2 in the answer to Exercise 2.34(a).)
It is not at all diﬃcult to prove from these deﬁnitions that in λ2 and
stronger systems,
u : ⋆, v : ⋆
⊢
Duv : u →v →(u ∧v),
u : ⋆, v : ⋆
⊢
fstuv : (u ∧v) →u,
u : ⋆, v : ⋆
⊢
snduv : (u ∧v) →v.
Furthermore, it is easy to prove
u : ⋆, v : ⋆, x : u, y : v
⊢
fstuv(Duvxy) : u,
u : ⋆, v : ⋆, x : u, y : v
⊢
snduv(Duvxy) : v
and
fstuv(Duvxy) =β x,
snduv(Duvxy) =β y.
Deﬁnition 13.66 The disjunction proposition operator and its associ-
ated injection and case operators are deﬁned as follows:
(a) V ≡λu:⋆. λv:⋆.

Πw:⋆. (u →w) →((v →w) →w)

;
(b) inl ≡λu:⋆. λv:⋆. λx:u . λw:⋆. λf :(u →w) . λg:(v →w) . fx;
(c) inr ≡λu:⋆. λv:⋆. λy:v . λw:⋆. λf :(u →w) . λg:(v →w) . gy;
(d) case ≡
λu:⋆. λv:⋆. λz :(Vuv) . λw:⋆. λf :(u →w) . λg:(v →w) . zwfg.
We use ‘A ∨B’ as an abbreviation for VAB.

13G Propositions-as-types
211
It is easy to show that in λ2 and stronger systems,
u : ⋆, v : ⋆
⊢
inluv : u →u ∨v,
u : ⋆, v : ⋆
⊢
inruv : v →u ∨v,
u : ⋆, v : ⋆
⊢
caseuv : u ∨v →(Πw:⋆)

(u →w) →((v →w) →w)

.
Furthermore, it is easy to prove
u : ⋆, v : ⋆, w : ⋆, x : u, y : v, f : u →w, g : v →w
⊢caseuv(inluvx)wfg : w,
u : ⋆, v : ⋆, w : ⋆, x : u, y : v, f : u →w, g : v →w
⊢caseuv(inruvy)wfg : w,
and
caseuv(inluvx)wfg =β fx,
caseuv(inruvy)wfg =β gy.
Deﬁnition 13.67 void ≡⊥≡(Πu:⋆. u).
We shall use ‘⊥’ when we are thinking of the proposition and ‘void’
when we are thinking of the type. It is easy to prove in λ2 and stronger
systems that
⊢⊥: ⋆
and
x : ⊥, u : ⋆
⊢
xu : u.
It follows from the second of these that if there is a closed term in ⊥, then
there is a proof of every proposition. Hence, in terms of propositions,
⊥represents a generalized contradiction. However, in systems of the
λ-cube, there is no closed term in ⊥:
Theorem 13.68 (Consistency) In systems of the λ-cube, there is no
closed term M such that
⊢M :⊥.
Proof Suppose there is such a term M. Then the proof of
⊢M :⊥can
be extended as follows:
⊢M : ⊥
u : ⋆⊢u : ⋆
u : ⋆⊢Mu : u.
(application)

212
Generalizations of typing
By Theorem 13.60, Mu has a normal form, say N. By Lemma 13.45 and
the fact that u is a variable, N does not have the form λx:A . P. Hence,
N must have the form aN1 . . . Nn, where a is a variable or a constant,
and
u : ⋆
⊢
a : (Πy1 :A1 . . . . . Πyn :An . ⋆),
(5)
and for i = 1, . . . , n,
u : ⋆⊢Ni : Ai.
In the proof of ⊢N : u, if a is a constant, (5) must be an axiom, and
the only axiom is ⋆: 2, which does not have the right form. If a is a
variable, it must be u, in which case n = 0 and N ≡u; but the only
provable type for u is ⋆, not u. Hence, in these systems, there is no way
to prove (5).
Remark 13.69
The above proof will also apply to PTSs not in the
λ-cube for which Theorem 13.60 holds and for which the axioms are
suﬃciently limited.
Some axioms which would preserve consistency if added are discussed
in [Sel97, Section 7].
Deﬁnition 13.70 The negation proposition operator is deﬁned thus:
¬ ≡λx:⋆. x →⊥.
It is easy to show that if Γ ⊢A:⋆, then in λ2 and stronger systems,
Γ ⊢M : ¬A
Γ ⊢N : A
Γ ⊢MN : ⊥
and
Γ, x:A ⊢M : ⊥
Γ ⊢¬A : ⋆
Γ ⊢(λx : A . M) : ¬A.
Deﬁnition 13.71 The existential quantiﬁer operator and its associated
pairing and projection functions are deﬁned as follows:
(a) Σ ≡λu:⋆. λv:(u →⋆) . (Πw:⋆. (Πx:u . vx →w) →w);
(b) D′ ≡
λu:⋆. λv:(u →⋆) . λx:u . λy:vx . λw:⋆. λz :(Πx:u . vx →w) . zxy;
(c) proj ≡
λu:⋆. λv :(u→⋆) . λw :⋆. λz :(Πx:u . vx→w) . λy :(Πx:u . vx) . ywz.

13G Propositions-as-types
213
We use ‘(∃x:A . B)’ as an abbreviation for ΣA(λx:A . B).
It is not hard to show that in λ2 and stronger systems,
u : ⋆, v : u →⋆
⊢
(∃x:u . vx) : ⋆,
u : ⋆, v : u →⋆
⊢
D′uv : (Πt:u . vt ⊃(∃x:u . vx)),
and
u : ⋆, v : u →⋆
⊢
projuv :

Πw:⋆. (Πy:u . vy →w) ⊃(∃x:u . vx) ⊃w

.
Furthermore, it is easy to prove
u : ⋆, v : u →⋆, w : ⋆, x : u, y : vx, z : (Πx:u . vx →w)
⊢
projuvwz(D′uvxy) : w
and
projuvwz(D′uvxy) =β zxy.
Note that D′ diﬀers from D only in the types postulated for some of
the bound variables. But this diﬀerence is enough to make it impossible
to deﬁne a right projection for D′ that is correctly typed: this point is
discussed in [Car86]. However, a modiﬁed version of fst works as a left
projection function for D′:
fst′ ≡λu:⋆. λv:(u →⋆) . λx:(Σuv) . xu(λy:u . λz :v . y).
These deﬁnitions give us the logical connectives and quantiﬁers. We
can also deﬁne equality over any type:
Deﬁnition 13.72 The equality proposition
M =A N,
is deﬁned to be
QAMN,
where
Q ≡λu:⋆. λx:u . λy:u . (Πz :(u →⋆) . zx ⊃zy).

214
Generalizations of typing
This deﬁnition will only be used when A : ⋆has already been proved
or assumed in a context.
It is not hard to show that in λ2 and stronger systems,
⊢Q : (Πu:⋆. u →u →⋆),
u : ⋆, x : u
⊢

λz :(u →⋆) . (λw:zx . w)

: x =u x,
and
u : ⋆, x : u, y : u, m : (x =u y), z : u →⋆, n : zx
⊢
mzn : zy.
This gives us the reﬂexivity and substitution properties of equality;
these two properties are well known to imply all the usual properties of
equality.
We can also interpret arithmetic in λ2 and stronger systems. The
interpretation is based on the representation of arithmetic in Chapter 4,
with suitable modiﬁcations for the types.
Deﬁnition 13.73 (Basic arithmetic operators) The natural-num-
bers type and basic arithmetical operators are deﬁned as follows:9
(a) N ≡(Πu:⋆. (u →u) →(u →u));
(b) 0 ≡λu:⋆. λx:u→u . λy:u . y;
(c) σ ≡λv:N . λu:⋆. λx:u→u . λy:u . x(vuxy);
(d) π ≡λu:N . snd N N

u(N × N)Q (D N N 0 0)

,
where Q ≡λv:(N × N) . D N N (σ(fst N Nv))(fst N Nv);
(e) R ≡λu:⋆. λx:u . λy:N→u→u . λz :N . z(N →u)P(λw:N . x)z,
where P ≡λv:N →u . λw:N . y(πw)(v(πw)).
The term n, which represents the natural number n, is deﬁned as usual
by
n
≡
σn0
≡
σ(σ(...(σ



n
0)...)).
It is not hard to show that in λ2 and stronger systems
⊢0 : N,
9 For (a), cf. Nτ in 11.2. For (b), cf. the Church numeral 0 in 4.2. For (c), cf. σ
in 4.6. For (d), cf. πBernays in 4.13. For (e), cf. R and (Mτ y) in Appendix A3’s
A3.21(8) and (9).

13G Propositions-as-types
215
⊢σ : N →N,
⊢π : N →N
and
⊢R : (Πu:⋆. u →(N →u →u) →N →u).
It is also easy to show that
n =β λu:⋆. λx:u →u . λy:u . xny,
π0 =β 0,
π(σn) =β n;
and
RAMN0 =β M,
RAMN(σn) =β Nn(RAMNn),
for all A, M, N such that A : ⋆, M : A and N : N →A →A have been
previously proved. It is also not hard to show that
⊢N : ⋆.
It can be shown that Deﬁnition 13.73 is an appropriate way to rep-
resent arithmetic if all we want to do is deﬁne the primitive recursive
functions.
But if we go further, to consider the Peano axioms, we ﬁnd that it
is not possible to prove all the formulas representing these axioms as
theorems.
Four of the Peano axioms are no problem: they are essentially just the
deﬁning equations for + and ×, and follow from the reduction properties
of R and rule (conversion), given suitable λ-representations of + and ×,
cf. Exercise 4.16(b).
The other Peano axioms can be translated most easily and directly
into λ2 as:
(i) Peano1
≡

Πn:N . ¬(σn =N 0)

;
(ii) Peano2
≡

Πm:N . Πn:N . (σm =N σn ⊃m =N n)

;
(iii) Peano3
≡

Πu:N →⋆.
(Πm:N . um ⊃u(σm)) ⊃u0 ⊃(Πn:N . un)

.

216
Generalizations of typing
However, Peano3 in this simple version cannot be derived in λ2. This
rests on the the fact that there is a term with type N in this system
which is not a representative of a natural number:
λA : ⋆. λx : A →A . x.
(6)
True, this term η-converts to 1, but it does not β-convert to n for any n.
It may appear that the problem is the way we have chosen to represent
the natural numbers, but that is not the case. Geuvers [Geu01] shows
that it is not possible to prove induction in the simple form shown.
To get round this problem we must deﬁne a predicate which will say,
in eﬀect, that an object is a natural number. One suitable deﬁnition,
which, in a sense, goes back to Dedekind [Ded87], is as follows:
N ≡λn:N . (Πu : N →⋆)

(Πm:N . um ⊃u(σm)) ⊃u0 ⊃un

.
(7)
It is easy to prove in λ2 and stronger systems that
⊢
N : N →⋆,
⊢
M : N0,
⊢
N : (Πn:N . Nn ⊃N(σn)),
for some suitable closed terms M and N. Furthermore, we can prove
induction in the following form: there is a closed term P such that
⊢P :

Πu:N →⋆.
(Πm:N . um ⊃u(σm)) ⊃u0 ⊃(Πn:N . Nn ⊃un)

.
(8)
This gives us induction within the logic.
This leaves us with the axioms Peano1 and Peano2 as unproved as-
sumptions. However, Peano2 is not really needed, as the second of the
following two lemmas shows that a version of Peano2 involving N can
be proved in λ2.
Lemma 13.74 In λ2 there exists a closed term Q such that
⊢Q :

Πn:N . Nn →π(σn) =N n

.
Proof A direct calculation gives that π(σ(σn)) =β σ(π(σn)). Hence,
there is a term Q1 such that
n : N, x : (π(σn) =N n)
⊢
Q1 : (π(σ(σn)) =N σn).

13H PTSs with equality
217
Hence, by (abstraction), there is a term Q2 such that
⊢Q2 :

Πn:N . (π(σn) =N n) →(π(σ(σn)) =N σn)

.
This is the induction step. The basis is easy, since π(σ0) =β 0. Then
induction (which follows from the deﬁnition of N) gives us the lemma.
Lemma 13.75 In λ2 there exists a closed term R such that
⊢R :

Πn:N . Πm:N . Nn →Nm →(σn =N σm) →(n =N m)

.
Proof We can easily formalize in this logic the following argument, where
n = m represents n =N m: if σn = σm, then π(σn) = π(σm), and so
n = m.
Thus, to obtain the Peano postulates in the weakest possible extension
of λ2, it is suﬃcient to add as an assumption
c : Peano1,
(9)
for a new atomic constant c. In [Sel97, Theorem 21], it is shown that
if this unproved assumption is added to a certain kind of consistent
context, the result is a consistent context.
This approach to arithmetic can be extended to other inductively
deﬁned data types. This is done for λC in [Ber93, Sel00b].
We can make the logic classical logic by adding an unproved assump-
tion of the form
cl : (Πu:⋆. ¬¬u ⊃u),
(10)
where cl is a new constant. In [Sel97, Theorem 23], it is shown that if
cl : (Πu:⋆. ¬¬u ⊃u),
c : Peano1
(11)
are added to a certain kind of consistent context, the result is still a
consistent context.
13H
PTSs with equality
As in the systems of Chapters 11 and 12, typing in PTSs is not invariant
of conversion. Conversion of types is allowed by the rules in Deﬁnition
13.23, but not conversion of terms in general. This suggests that we add

218
Generalizations of typing
a rule corresponding to Eq′. In keeping with the names of the rules of
PTSs, we should probably call it (conversion′). The rule would be the
following:
(conversion′)
Γ ⊢M : A
M =β N
Γ ⊢N : A.
Note that this makes the rule (α-conv) redundant. Note that it also
makes the third premise of the rule (conversion) redundant, since if
A =β B then rule (conversion′) permits an inference from A : s to B : s.
Thus, the rule (conversion) should be replaced by the rule
(conversion′′)
Γ ⊢M : A
A =β B
Γ ⊢M : B.
Deﬁnition 13.76 For every PTS S, the corresponding PTS with equal-
ity, S=, is deﬁned by deleting the rule (α-conv), adding in its place
the rule (conversion′), and replacing the rule (conversion) by the rule
(conversion′′).
Because of Theorems 11.64 and 12.40, it might be expected that a
theorem on the postponement of (conversion′) can be proved for PTSs
with equality. Indeed, Seldin presented such a proof for a formulation of
the calculation of constructions in [Sel00a, Theorem 1]. But the method
of proof, pushing inferences by (conversion′′) followed by another in-
ference down past that inference, will not work without modiﬁcation
in the formulation given here, for there are cases that cause problems.
The most important of these occurs when the inference by (conversion′)
occurs above the right premise for an inference by (abstraction):
Γ, x : A ⊢M : B
Γ ⊢C : s
C =β (Πx:A . B)
Γ ⊢(Πx:A . B) : s
(conversion′)
Γ ⊢(λx:A . M) : (Πx:A . B).
(abstraction)
It is hard to see how to push this inference down from here. So no proof
of postponement of (conversion′) will be given here.
Another diﬀerence between PTSs with equality and ordinary PTSs is
that there are algorithms for type-checking for many PTSs, but because
conversion is undecidable there are no such algorithms for PTSs with
equality.
On the other hand, PTSs with equality seem to be better suited for
representing systems of logic via propositions-as-types.

13H PTSs with equality
219
Furthermore, PTSs with equality seem better suited to express the
idea that one type is a subtype of another. The statement that every
term of type A is also a term of type B can be expressed by the statement
(λx:A . x) : A →B.
(12)
The term (λx : A . x) is called a coercion, because it coerces terms of
type A into terms in type B. However, to use (12) in constructing a
formal inference requires rule (conversion′):
Γ ⊢(λx:A . x) : A →B
Γ ⊢M : A
Γ ⊢(λx:A . x)M : B
(application)
Γ ⊢M : B.
(conversion′)
Note that it follows from this that if Γ ⊢(λx:B . M) : B →C, then for
a variable y ̸∈FV(M),
Γ ⊢(λy:A . (M((λx:A . x)y))) : A →C.
The term (λy : A . (M((λx : A . x)y))) represents the restriction of the
function represented by M to A. It can be β-reduced as follows:
(λy:A . (M((λx:A . x)y))) ▷β
(λy:A . My),
so (λy:A . My) also represents the restriction of M to A.
Remark 13.77
Note that (λy : A . My) resembles an η-redex which
would η-reduce to M; in fact, it corresponds to an ordinary η-redex the
way (λx : A . M)N corresponds to an ordinary β-redex. For the reason
stated in Remark 13.63, we have not been using βη-reduction in this
chapter. The above discussion shows that if we were to ﬁnd a solution
to the problem of the failure of CR discussed in Remark 13.63 and adopt
βη-reduction for PTSs with subtyping, we would wind up with systems
which cannot distinguish functions from their restrictions.

14
Models of CL
14A
Applicative structures
In ﬁrst-order logic, a common question to ask about a formal theory
is ‘what are its models like?’. For the theories λβ and CLw the ﬁrst
person to ask this was Dana Scott in the 1960s, while he was working
on extending the concept of ‘computable’ from functions of numbers to
functions of functions. The ﬁrst non-trivial model, D∞, was constructed
by Scott in 1969.
Since then many other models have been made. The present chapter
will set the scene by introducing a few basic general properties of models
of CLw, and the next will do the same for λβ, whose concept of model
is more complicated. Then Chapter 16 will describe the model D∞in
detail and give outlines and references for some other models. Scott’s
D∞is not the simplest model known, but it is a good introduction, as
the concepts used in building it are also involved in discussions of other
models.
But ﬁrst, a comment: although λ-calculus and combinatory logic were
invented as long ago as the 1920s, there was a 40-year gap before their
ﬁrst model was constructed; why was there this long delay?
There are two main reasons. The ﬁrst is the origin of λβ and CLw.
Both Church and Curry viewed these theories, not from within the se-
mantics that most post-1950 logicians were trained in, but from the
alternative viewpoint described in Discussion 3.27. Their aim was to
formalize a concept of operator which was independent of the concept of
set, and which did not necessarily correspond to the function-concept in
the usual set-theories (e.g. Zermelo–Fraenkel set theory, ZF). In contrast,
the semantics usually taught today presupposes the set-concept, so to
ask for a model of the theory CLw is really asking for an interpretation
220

14A Applicative structures
221
of CLw in ZF. From the Church–Curry point of view this question was
of course interesting, but it was not primary.
The second reason was the complexity of the models. The problem of
constructing set-theoretic objects which behaved like combinators was
far from easy and the resulting structure was not simple (although sim-
pler models were later found).
Notation 14.1 In this chapter, ‘term’ will mean ‘CL-term’. The formal
theories whose models will be studied are:
CLw (see 6.5), which determines weak equality =w;
CLextax (see 8.10), determining extensional equality =Cext;
CLβax (see 9.38), determining β-equality =Cβ (see 9.29).
(Details of the axioms in CLβax will not be needed.)
Identity will, as usual, be written as ‘≡’ for terms, and ‘=’ for all
other objects, in particular for members of a model.
Vars will be the class of all variables. As usual, ‘x’, ‘y’, ‘z’, ‘u’, ‘v’,
‘w’ will denote variables.
In contrast, ‘a’, ‘b’, ‘c’, ‘d’, ‘e’ will denote arbitrary members of a given
set D (see later). If • is a mapping from D2 to D, expressions such as
(((a • b) • c) • d)
will be shortened to a•b•c•d (the convention of association to the left).
Any mapping ρ from Vars to D will be called a valuation (of vari-
ables). For d ∈D and x ∈Vars, the notation
[d/x]ρ
will be used for the valuation ρ⋆which is the same as ρ except that
ρ⋆(x) = d. (In the special case that ρ(x) = d, we have [d/x]ρ = ρ.)
The reader who has already met the usual deﬁnition of model of a
ﬁrst-order theory will ﬁnd it helpful as an analogy and a source of ideas,
though this chapter will not depend formally on it. (The usual deﬁnition
can be found in textbooks such as [Men97, Chapter 2, Sections 2, 3, 8],
[Dal97, Section 2.4] and [End00, Sections 2.2, 2.6].)
Models will here be described in the usual informal set-theory in which
mathematics is commonly written. (If desired, this could be formalized
in Zermelo–Fraenkel set theory with the axiom of choice added.)
In
particular, recall that, as usual, ‘function’, ‘mapping’ and ‘map’ mean
‘a set of ordered pairs such that no two pairs have the same ﬁrst member’.

222
Models of CL
Deﬁnition 14.2 An applicative structure is a pair ⟨D, •⟩where D is a
set (called the domain of the structure) with at least two members, and
• is any mapping from D2 to D.
A model of a theory such as CLw or λβ will be an applicative structure
with certain extra features, and such that • has some of the properties
of function-application. The 2-member condition is just to prevent triv-
iality.
Deﬁnition 14.3 Let ⟨D, •⟩be an applicative structure and let n ≥1.
A function θ : Dn →D is representable in D iﬀD has a member a such
that
(∀d1, . . . , dn ∈D)
a • d1 • d2 • . . . • dn = θ(d1, . . . , dn).
By the association-to-the-left convention this equation really says
(. . . ((a • d1) • d2) • . . .) • dn = θ(d1, . . . , dn) .
Each such a is called a representative of θ. The set of all representable
functions from Dn to D is called

Dn →D

rep.
Note
A representable function may have several representatives. On
the other hand, in general, very few functions on D are representable,
because there are far more functions on a given set than there are mem-
bers to serve as representatives.
Also, every a ∈D represents a function; indeed, for every n ≥1, a
represents a function of n arguments.
Deﬁnition 14.4 For every a ∈D, Fun(a) is the unique one-argument
function that a represents: i.e.
(∀d ∈D)
Fun(a)(d) = a • d.
Conversely, for every one-argument function θ ∈(D →D)rep, the set of
all θ’s representatives in D is called
Reps(θ).
Deﬁnition 14.5 For all a, b ∈D: we say a is extensionally equivalent
to b (notation a ∼b) iﬀ
(∀d ∈D)
a • d = b • d.

14B Combinatory algebras
223
For every a ∈D, the extensional-equivalence-class containing a is
a = {b ∈D : b ∼a}.
The set of all these classes is called D/∼:
D/∼=

a : a ∈D

.
Lemma 14.6 Let ⟨D, •⟩be an applicative structure. Then
(a) a ∼b ⇐⇒Fun(a) = Fun(b);
(b) a ∼b ⇐⇒a = b;
(c) the members of D/∼are non-empty, non-overlapping, and their
union is D;
(d) (D→D)rep corresponds one-to-one with D/∼by the map Reps.
Deﬁnition 14.7 (Extensionality) An applicative structure ⟨D, •⟩is
called extensional iﬀ, for all a, b ∈D,

(∀d ∈D) a • d = b • d

=⇒
a = b.
Lemma 14.8 Extensionality is equivalent to any one of:
(a) (∀a, b ∈D)
a ∼b =⇒a = b;
(b) (∀a ∈D)
a is a singleton;
(c)

∀θ ∈(D→D)rep

Reps(θ) is a singleton;
(d) D corresponds one-to-one with (D→D)rep by the map Fun.
14B
Combinatory algebras
Deﬁnition 14.9 A combinatory algebra is a pair D = ⟨D, •⟩where D is
a set with at least two members, • maps D2 to D, and D has members
k and s such that
(a) (∀a, b ∈D)
k • a • b = a;
(b) (∀a, b, c ∈D)
s • a • b • c = a • c • (b • c).
A model of CLw is a quintuple ⟨D, •, i, k, s⟩such that ⟨D, •⟩is a com-
binatory algebra and k, s satisfy (a), (b), and
i = s • k • k.

224
Models of CL
The deﬁnition of ‘combinatory algebra’ is from [Bar84, Section 5.1].
That of ‘model of CLw’ is very similar and keeps as close as possible to
the usual deﬁnition of ‘model’ in ﬁrst-order logic.
Exercise 14.10 ∗Prove that in every combinatory algebra D,
i ̸= k ̸= s ̸= i.
Deﬁnition 14.11 (Interpretation of a term) Let D = ⟨D, •, i, k, s⟩
where ⟨D, •⟩is an applicative structure and i, k, s ∈D.
Let ρ be a
valuation of variables. Using ρ, we assign to every term X a member of
D called its interpretation or [[X]]D
ρ , thus:
(a) [[x]]D
ρ
= ρ(x);
(b) [[I]]D
ρ
= i,
[[K]]D
ρ
= k,
[[S]]D
ρ
= s;
(c) [[XY ]]D
ρ
= [[X]]D
ρ • [[Y ]]D
ρ .
When no confusion is likely, [[X]]D
ρ will be called just
[[X]]ρ
or
[[X]].
Example If a, b ∈D and ρ(x) = a and ρ(y) = b, then
[[Sx(yK)]]D
ρ
=
s • a • (b • k),
∈D.
Lemma 14.12 If ρ(x) = σ(x) for all x ∈FV(X), then
[[X]]ρ = [[X]]σ .
Corollary 14.12.1 For closed terms X, [[X]]ρ is independent of ρ.
Lemma 14.13 Interpretation commutes with substitution; i.e.
[[[Z/x]X]]ρ = [[X]][b/x]ρ
where b = [[Z]]ρ .
Deﬁnition 14.14 (Satisfaction) Let D = ⟨D, •, i, k, s⟩where ⟨D, •⟩is
an applicative structure and i, k, s ∈D. Let ρ be a valuation of variables.
Deﬁne satisﬁes (notation ‘|=’) thus: for every equation X = Y ,
D, ρ
|= X = Y
⇐⇒
[[X]]D
ρ = [[Y ]]D
ρ ;
D
|= X = Y
⇐⇒
(∀ρ)

D, ρ |= X = Y

.

14B Combinatory algebras
225
Warning The symbol ‘=’ has been used in two senses here; as a formal
symbol in the theory CLw (e.g. ‘X = Y ’), and as a symbol in the meta-
language, for identity (e.g. ‘[[X]]D
ρ = [[Y ]]D
ρ ’).
Deﬁnition 14.15 A model of the theory CLβax is a model ⟨D, •, i, k, s⟩
of CLw that satisﬁes the β-axioms mentioned in 9.38.1
Deﬁnition 14.16 A model of CLextax is a model ⟨D, •, i, k, s⟩of CLw
that satisﬁes the extensionality axioms in 8.10.2
Lemma 14.17 Each model of CLw, CLβax or CLextax satisﬁes all the
provable equations of the corresponding theory.
Proof The axioms are satisﬁed, by deﬁnition. And each rule of inference
is a property of identity.
Remark 14.18 As noted in 6.9–6.11, CLw is not quite a ﬁrst-order the-
ory in the usual sense, but the diﬀerence is trivial and it can be changed
into a ﬁrst-order theory CLw + without changing its set of provable equa-
tions. The models of CLw are exactly the normal models of CLw + in
the usual ﬁrst-order-logic sense. (A model of a ﬁrst-order theory is called
‘normal’ when its interpretation of ‘=’ is the identity relation.)
A similar remark holds for CLβax and CLextax.
Remark 14.19 We now have enough material to build a simple model.
First, CLw + is consistent, because by the Church–Rosser theorem there
are equations such as S = K that have no proofs in CLw, and hence none
in CLw +. And a general theorem in logic says that every consistent
ﬁrst-order theory has a model.
(See, e.g. [Men97, Proposition 2.17],
[Dal97, Lemma 3.1.11] or [End00, Section 2.5].) In the context of CL, a
model like the one produced by the usual proofs of this theorem can be
constructed directly as follows.
Deﬁnition 14.20 (Term models)
Let T
be CLw or CLβax or
CLextax. For each CL-term X, deﬁne
[X] =

Y :
T ⊢X = Y

.
1 These models (with a little extra structure) were called ‘λ-algebras’ in [Bar84] and
‘pseudo-models’ in [HL80]; see [HL80, Proposition 8.9].
2 These models were called ‘Curry algebras’ in [Lam80].

226
Models of CL
The term model of T , called TM(T ), is ⟨D, •, i, k, s⟩, where
D =

[X] : X is a CL-term

,
[X] • [Y ] = [XY ],
i = [I],
k = [K],
s = [S].
Remark 14.21 It is routine to prove that • is well-deﬁned, i.e. that
[X] = [X′], [Y ] = [Y ′]
=⇒
[XY ] = [X′Y ′],
and that TM(T ) is indeed a model of T .
It is also routine to prove that in this model, interpretation is the
same as substitution; i.e. that if FV(X) = {x1, . . . , xn} and ρ(xi) = [Yi]
for each i, then
[[X]]ρ =

[Y1/x1, . . . , Yn/xn]X

.
Thus TM(T ) is in a sense trivial: it is really just a reﬂection of the
syntax of T and tells us very little new about combinators. The models
in Chapter 16 will be much deeper.
Remark 14.22
The following theorem is a standard result from the
model-theory of algebra. It is easy to prove for CL but will fail for λ,
and this will be an interesting way of expressing the diﬀerence between
them (cf. Remark 15.25).
Theorem 14.23 (Submodel theorem) Let T be CLw or CLβax or
CLextax. If ⟨D, •, i, k, s⟩is a model of T , and D′ is a subset of D which
contains i, k and s and is closed under •, then ⟨D′, •, i, k, s⟩is a model
of T .
Proof By assumption, D′ has at least two members (for example s and
k). Next, if the axioms 14.9(a) and (b) hold in D, they must also hold
in D′ since D′ ⊆D. Finally the β- and extensionality axioms are just
equations between constants, so they also hold in D′ if they hold in D.
(The above proof depends on the very simple form of 14.9(a) and (b);
if an axiom contained an existential quantiﬁer the proof would fail.)

14B Combinatory algebras
227
Deﬁnition 14.24 (Interiors)
Let T be CLw, CLβax or CLextax,
and D = ⟨D, •, i, k, s⟩be a model of T .
The interior of D is D◦=
⟨D◦, •, i, k, s⟩, where
D◦=

[[X]] : X closed

.
The interior of a model of T is also a model of T , by Theorem 14.23.
Remark 14.25 (Extensionality)
How does the concept of exten-
sional structure or model deﬁned in 14.7 relate to the theories of exten-
sional equality in Chapter 8? It would be nice to prove that a model of
CLw is extensional iﬀit is a model of CLextax.
Part of this conjecture is reasonably easy. (Exercise: prove that every
extensional model of CLw is a model of CLextax.)
But unfortunately the converse part is false. For a counterexample
take (TM(CLextax))◦, the interior of the term model of CLextax. This
is a model of CLextax by above. But extensionality demands that, for
all closed X and Y ,

(∀closed CL-terms Z) [XZ] = [Y Z]

=⇒
[X] = [Y ].
That is,

(∀closed CL-terms Z) CLextax ⊢XZ = Y Z

=⇒

CLextax ⊢X = Y

.
By Theorem 9.15 this is equivalent to

(∀closed λ-terms Q) XλQ =λext YλQ

=⇒
Xλ =λext Yλ.
And this is false, by Plotkin’s example mentioned in Remark 7.3.
Thus the ‘extensionality’ expressed by the theory CLextax is weaker
than the extensionality concept in Deﬁnition 14.7.
Fuller discussions of extensional models are in [HL80] and [Bar84,
Chapter 20].
Remark 14.26
Recall the concept of ‘combinatory algebra’ that was
deﬁned in 14.9 along with ‘model of CLw’: the only diﬀerence between
these two concepts is that the latter is tied to a particular formalization
of combinatory logic. For example, if I was not an atom in the language
of CLw, then a ‘model’ would have to be re-deﬁned as a quadruple
⟨D, •, k, s⟩instead of a quintuple.
In contrast, ‘combinatory algebra’ is independent of the formalism.

228
Models of CL
This might not be immediately obvious from its deﬁnition, so let us try
to rewrite that deﬁnition to avoid mentioning k, s.
The characteristic property of combinatory algebras is called combi-
natory completeness; it is deﬁned as follows.
Deﬁnition 14.27 A combination of x1, . . . , xn is any CL-term X whose
only atoms are x1, . . . , xn. (X need not contain all of x1, . . . , xn, but
must not contain S, K or I.)
If X is a combination of x1, . . . , xn and ρ is any valuation of variables,
we can interpret X in the natural way, using 14.11(a) and (c) to deﬁne
[[X]]ρ. (Lemmas 14.12 and 14.13 will still hold.)
Deﬁnition 14.28 An applicative structure D = ⟨D, •⟩is called combi-
natorially complete iﬀ: for every sequence u, x1, . . . , xn of distinct vari-
ables, and every combination X of x1, . . . , xn only, the formula
(∃u)(∀x1, . . . , xn)

ux1 . . . xn = X

is true in D. That is, iﬀthere exists a ∈D such that, for all d1, . . . , dn
∈D,
a • d1 • . . . • dn = [[X]][d1 /x1 ]...[dn /xn ]ρ,
where ρ is arbitrary.
Theorem 14.29 An applicative structure ⟨D, •⟩is combinatorially com-
plete iﬀit is a combinatory algebra.
Proof Combinatory completeness follows from the existence of k and s
by an analogue of the algorithm for constructing [x].M in 2.18. Con-
versely, the existence of k and s follows from combinatory completeness
as a special case.
Thus combinatory completeness gives us a way of deﬁning combina-
tory algebras without mentioning i, k or s.
But it is not so easy a
property to handle as the axioms for k and s. For example, in practice,
the quickest way to show that a particular structure is combinatorially
complete is usually to ﬁnd members k and s which satisfy these two ax-
ioms. And standard results in the model theory of algebra (e.g. Theorem
14.23) are harder to deduce directly from the combinatory completeness
deﬁnition.

15
Models of λ-calculus
15A
The deﬁnition of λ-model
The discussion of models in the last chapter was almost too easy, so sim-
ple was the theory CLw. In contrast, the theory λβ has bound variables
and rule (ξ), and these make its concept of model much more complex.
This chapter will look at that concept from three diﬀerent viewpoints.
The deﬁnition of λ-model will be given in 15.3, and two other approaches
will be described in Section 15B to help the reader understand the ideas
lying behind this deﬁnition.
Notation 15.1
In this chapter we shall use the same notation as in
14.1, except that ‘term’ will now mean ‘λ-term’.
The identity-function on a set S will be called IS here.
The composition, φ◦ψ, of given functions φ and ψ, is deﬁned as usual
by the equation
(φ ◦ψ)(a) = φ(ψ(a)),
and its domain is {a : ψ(a) is deﬁned and in the domain of φ}.
If S and S′ are sets, and functions φ : S →S′ and ψ : S′ →S satisfy
(a) ψ ◦φ = IS,
then ψ is called a left inverse of φ, and S is called a retract of S′ by φ
and ψ, and the pair ⟨φ, ψ⟩is called a retraction; see Figure 15:1.
From (a) the following are easy to deduce:
(b) (φ ◦ψ) ◦(φ ◦ψ) = φ ◦ψ,
(c) ψ is onto S (i.e. its range is the whole of S),
(d) φ is one-to-one; thus φ maps S one-to-one onto a subset of S′,
which is called φ(S).
229

230
Models of λ
S
φ(S)
S
′



9






ψ
-
φ

ψ
-
φ
ψ
X
X
X
y
X
X
X
X
X
X
ψ
pppppp
ppppppppp
pppppppppp
ppppppppppp
pppppppppppp
ppppppppppppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppppppppppppp
pppppppppppp
ppppppppppp
pppppppppp
ppppppppp
pppppp
pppppp
ppppppppp
pppppppppp
ppppppppppp
pppppppppppp
ppppppppppppp
pppppppp
pppppppp
pppppppppppp
ppppppppppp
pppppppppp
ppppppppp
pppppp
Fig. 15:1
By the way, in 15.1, (b)–(d) together imply (a). Also, Figure 9:1 in
Remark 9.12 is an example of a retraction. There, φ is the λ-map, ψ is
the Hη-map, S is C, and S′ is Λ.
Remark 15.2
Before deﬁning ‘model of λβ’, let us look at one tempta-
tion and dismiss it. Why not simply identify ‘model of λβ’ with ‘model
of CLβax’? After all, by 9.37 and 9.38 the theories λβ and CLβax have
the same set of provable equations (modulo the λ- and Hβ-maps), so
why should they not have the same models?
The snag is as follows. In the theory λβ we can make deductions by
rule (ξ), for example
λx.yx = y
⊢
λyx.yx = λy.y.
So any reasonable deﬁnition of ‘model of λβ’ should have the property
that if D is such a model, then

D |= λx.yx = y

=⇒

D |= λyx.yx = λy.y

.
But this implication fails for models of CLβax. Two counterexamples
can be found in [HL80, Section 7]; one is the interior of TM(λβ), and
comes from Plotkin’s example mentioned in Remarks 7.3 and 14.25.
This failure is only surprising if we think of CLβax as satisfying (ξ)
in some sense. But it does not. True, it is equivalent to a theory in
which a form of (ξ) is derivable (the theory CLζβ in 9.32 and 9.39), but
the equivalence is only theorem-equivalence, and the above-mentioned
counterexamples show that it cannot be rule-equivalence.
So, the concept of model of λβ is more complicated than that of model
of CLβax.

15A The deﬁnition of λ-model
231
Three alternative deﬁnitions of model will be given in this chapter.
We shall give them diﬀerent names to distinguish them, but they will
really just be the same idea seen from three diﬀerent viewpoints, and
they will be turn out to be equivalent.
The ﬁrst deﬁnition will demand the least prior insight from the reader;
in fact its clauses will correspond very closely to the axioms and rules of
λβ. The second will deﬁne ‘model’ entirely in terms of internal structure
and will not mention λβ at all. The third will be by far the simplest,
though to see why it has any connection to λβ we shall need both the
ﬁrst and the second.
Deﬁnition 15.3 (λ-models)
A λ-model, or model of λβ, is a triple D
= ⟨D, •, [[ ]]⟩, where ⟨D, •⟩is an applicative structure and [[ ]] is a mapping
which assigns, to each λ-term M and each valuation ρ, a member [[M]]ρ
of D such that
(a)
[[x]]ρ = ρ(x) ;
(b)
[[PQ]]ρ = [[P]]ρ • [[Q]]ρ ;
(c)
[[λx.P]]ρ • d = [[P]][d/x]ρ
for all d ∈D ;
(d)
[[M]]ρ = [[M]]σ
if ρ(x) = σ(x) for all x ∈FV(M) ;
(e)
[[λx.M]]ρ = [[λy.[y/x]M]]ρ
if y ̸∈FV(M) ;
(f)
if (∀d ∈D)

[[P]][d/x]ρ = [[Q]][d/x]ρ

,
then [[λx.P]]ρ = [[λx.Q]]ρ .
Notation
[[M]]ρ may also be called [[M]]D
ρ , or simply [[M]] when it is
known to be independent of ρ.
Some writers call the above models ‘environment λ-models’ or ‘syn-
tactical λ-models’, but we shall avoid these notations as the words ‘en-
vironment’ and ‘syntactical’ have too many other meanings.
Comments 15.4
Each of (a)–(f) above is a condition that we might
naturally expect a model of λβ to satisfy, if the model is to imitate the
behaviour of λ-terms.
First, a model of λβ should allow us to interpret every term, i.e.
to deﬁne [[M]]ρ for all M and ρ. In ﬁrst-order logic an interpretation-
mapping [[ ]] is often included as part of the deﬁnition of ‘model’, so we
do the same here.
Clauses (a) and (b) are in fact the deﬁnition of [[M]]ρ in the cases

232
Models of λ
M ≡x and M ≡PQ. The case M ≡λx.P is more diﬃcult, which is
why we need (c)–(f).
Clause (c) expresses in model-theory language the intuitive meaning
behind the λ-notation: it says that [[λx.P]]ρ acts like a function whose
value is calculated by interpreting x as d.
Clause (d) is a standard property in model theory, compare also
Lemma 14.12.
Clause (e) says that the interpretation of a term is independent of
changes of bound variables.
Clause (f) is the interpretation of rule (ξ).
Finally, clauses 15.3(a)–(f) together ensure that every λ-model satis-
ﬁes all the provable equations of λβ. This will be proved in Theorem
15.12 after four lemmas.
Remark 15.5 By the way, clauses 15.3(c) and (f) together imply that
(∀d ∈D)

[[λx.P]]ρ • d = [[λx.Q]]ρ • d

=⇒
[[λx.P]]ρ = [[λx.Q]]ρ ,
or, using the notation ‘∼’ introduced in Deﬁnition 14.5,
[[λx.P]]ρ ∼[[λx.Q]]ρ
=⇒
[[λx.P]]ρ = [[λx.Q]]ρ .
This says that objects of form [[λx.P]]ρ have the extensionality property,
14.7, and (f) is sometimes called the weak extensionality condition (see
near the end of Remark 8.7).
Lemma 15.6 Let D = ⟨D, •, [[ ]]⟩be a λ-model. If y ̸∈FV(M) and
ρ(y) = ρ(x), then
[[ [y/x]M ]]ρ = [[M]]ρ .
Proof Let d = ρ(y) = ρ(x). Then [d/x]ρ = [d/y]ρ = ρ, and
[[M]]ρ = [[M]][d/x]ρ = [[λx.M]]ρ • d
by 15.3(c),
= [[λy.[y/x]M]]ρ • d
by 15.3(e),
= [[[y/x]M]]ρ
by 15.3(c).
Lemma 15.7 Let D = ⟨D, •, [[ ]]⟩be a λ-model.
Let FV(M) ⊆
{x1, . . . , xn} and let y1, . . . , yn, x1, . . . , xn be distinct. If ρ, σ are val-
uations with σ(yi) = ρ(xi) for i = 1, . . . , n, then
[[ [y1/x1] . . . [yn/xn]M ]]σ = [[M]]ρ .

15A The deﬁnition of λ-model
233
Proof Let di = ρ(xi) = σ(yi). Let τ = [d1/y1] . . . [dn/yn]ρ. Then
[[M]]ρ = [[M]]τ
by 15.3(d),
= [[[y1/x1] . . . [yn/xn]M]]τ
by 15.6 repeated,
= [[[y1/x1] . . . [yn/xn]M]]σ
by 15.3(d).
The next lemma is a small but signiﬁcant strengthening of the weak ex-
tensionality property in Remark 15.5, and will be the key to the syntax-
free analysis of models given later. It is due to G´erard Berry.
Lemma 15.8 (Berry’s extensionality property) Let D = ⟨D, •, [[ ]]⟩
be a λ-model. Then, for all P, Q, ρ, σ, and all x, y (not necessarily
distinct),
(a)
if (∀d ∈D)

[[P]][d/x]ρ = [[Q]][d/y]σ

, then [[λx.P]]ρ = [[λy.Q]]σ ;
(b)
[[λx.P]]ρ ∼[[λy.Q]]σ
=⇒
[[λx.P]]ρ = [[λy.Q]]σ .
Proof
Part (b) is equivalent to (a) by 15.3(c). To prove (a), assume
that [[P]][d/x]ρ = [[Q]][d/y]σ for all d ∈D. Suppose
FV(P) −{x} = {x1, . . . , xm},
FV(Q) −{y} = {y1, . . . , yn}.
(The x’s need not be distinct from the ys.) Let ai = ρ(xi) and bj =
σ(yj) for 1 ≤i ≤m and 1 ≤j ≤n. Choose distinct new variables z,
u1, . . . , um, v1, . . . , vn not in any term mentioned above. Deﬁne
P ′ ≡[u1/x1] . . . [um/xm][z/x]P,
Q′ ≡[v1/y1] . . . [vn/yn][z/y]Q,
τ
= [a1/u1] . . . [am/um][b1/v1] . . . [bn/vn]ρ.
Then, for all d ∈D,
[[P ′]][d/z]τ = [[P]][d/x]ρ
by 15.7,
= [[Q]][d/y]σ
by assumption,
= [[Q′]][d/z]τ
by 15.7.
Hence, by 15.3(f),
[[λz.P ′]]τ
=
[[λz.Q′]]τ .
(1)
Then

234
Models of λ
[[λx.P]]ρ
= [[λz.[z/x]P]]ρ
by 15.3(e),
= [[λz.P ′]]τ
by 15.7,
= [[λz.Q′]]τ
by Equation (1),
= [[λy.Q]]σ
by 15.7 and 15.3(e).
Exercise 15.9∗Prove that the three clauses (d)–(f) in Deﬁnition 15.3
could have been replaced by just one clause, Berry’s extensionality prop-
erty 15.8(a). That is, deduce 15.3(d)–(f) from 15.3(a)–(c) and 15.8(a)
(or, equivalently, 15.8(b)).
Lemma 15.10 Let D = ⟨D, •, [[ ]]⟩be a λ-model. Then, for all M, N,
x and ρ,
(a)
[[ [N/x]M ]]ρ = [[M]][b/x]ρ
where b = [[N]]ρ;
(b)
[[ (λx.M)N ]]ρ = [[[N/x]M]]ρ.
Proof (a) We use induction on M. The only non-trivial case is M ≡
λy.P with y ̸≡x. By 15.3(e) we can assume y ̸∈FV(N), so [N/x]M ≡
λy.[N/x]P. For all d ∈D, the induction hypothesis applied to P and
[d/y]ρ implies that
[[ [N/x]P ]][d/y]ρ
=
[[ P ]][b/x][d/y]ρ.
And [b/x][d/y]ρ = [d/y][b/x]ρ since x ̸≡y. Hence, by Lemma 15.8(a)
applied with σ = [b/x]ρ,
[[ λy.[N/x]P ]]ρ
=
[[ λy.P ]][b/x]ρ.
This proves (a) in the case M ≡λy.P.
(b)
[[ (λx.M)N ]]ρ = [[(λx.M)]]ρ • b
by 15.3(b),
= [[M]][b/x]ρ
by 15.3(c),
= [[ [N/x]M ]]ρ
by (a) above.
Deﬁnition 15.11 Let D = ⟨D, •, [[ ]]⟩be a λ-model, ρ a valuation, and
M, N be any terms. Iﬀ[[M]]ρ = [[N]]ρ, we say ρ satisﬁes the equation
M = N, or
D, ρ |= M = N.

15A The deﬁnition of λ-model
235
Iﬀevery valuation in D satisﬁes M = N, we say D satisﬁes M = N, or
D |= M = N.
Theorem 15.12 Every λ-model satisﬁes all the provable equations of
the formal theory λβ.
Proof We use induction on the clauses deﬁning λβ in 6.2. Case (α) is
15.3(e). Case (β) is 15.10(b). Case (ξ) is 15.3(f). The rest are trivial.
Corollary 15.12.1 If ⟨D, •, [[ ]]⟩is a λ-model, then ⟨D, •⟩is a combi-
natory algebra, and hence is combinatorially complete.
Proof (See 14.9 for ‘combinatory algebra’ and 14.28 for ‘combinatorially
complete’.) Deﬁne k = [[λxy.x]], s = [[λxyz.xz(yz)]].
Corollary 15.12.2 If ⟨D, •, [[ ]]⟩is a λ-model, then ⟨D, •, i, k, s⟩is a
model of the theory CLβax, where k and s are deﬁned as above and
i = [[λx.x]].
Proof (For ‘model of CLβax’ see 14.15.) Use the correspondence between
the theories λβ and CLβax given in 9.37 and 9.38.
Remark 15.13
The converses to both these corollaries are false; there
exist combinatory algebras, even models of CLβax, which cannot be
made into λ-models by any deﬁnition of [[ ]]; one is given in [BK80,
Section 3]. Thus the concept of λ-model is strictly stronger than that
of model of CLβax, even though the formal theories λβ and CLβax have
the same provable equations. This agrees with our discussion in Remark
15.2.
Deﬁnition 15.14 (Models of λβη) A model of λβη is a λ-model that
satisﬁes the equation λx.Mx = M for all terms M and all x ̸∈FV(M).
It is easy to see that every model of λβη satisﬁes all the provable
equations of the formal theory λβη; compare Theorem 15.12 and its
proof.
Theorem 15.15 A λ-model D is extensional iﬀit is a model of λβη.

236
Models of λ
Proof Exercise ⋆.
The above theorem contrasts with combinatory algebras: as Remark
14.25 showed, a combinatory algebra can be a model of CLβηax without
being extensional.
Deﬁnition 15.16 (Term models)
Let T be either of the formal
theories λβ, λβη. For every λ-term M, deﬁne
[M] =

N : T ⊢M = N

.
The term model of T , called TM(T ), is deﬁned to be ⟨D, •, [[ ]]⟩, where
D
=

[M] : M is a λ-term

,
[P] • [Q] = [PQ],
[[M]]ρ
= [ [N1/x1, . . . , Nn/xn]M ],
where FV(M) = {x1, . . . , xn} and ρ(xi) = [Ni], and [N1/x1, . . . , Nn/xn]
is simultaneous substitution, compare Remark 1.23.
Remark 15.17
It is routine to prove that • and [[ ]] are well-deﬁned
and that TM(T ) is genuinely a model of T . As noted in Remark 14.21,
term models are just reﬂections of the syntax, so they are in a sense
trivial.
But in fact this very triviality makes them one of the tests for a good
deﬁnition of ‘λ-model’; if the term model of λβ had not satisﬁed the
conditions of Deﬁnition 15.3, those conditions would have had to be
changed. Fortunately they pass the test.
Some non-trivial λ-models will be described in Chapter 16.
15B
Syntax-free deﬁnitions
In this section we shall look at two alternative deﬁnitions of ‘λ-model’.
They will be equivalent to Deﬁnition 15.3, but neither of them will men-
tion λ-terms or the theory λβ. The ﬁrst will be simpler than Deﬁnition
15.3, and the second much simpler, and they will show very neatly the
diﬀerence between λ-models and combinatory algebras. However, they
will not be able to completely replace Deﬁnition 15.3; experience has
shown that if one wants to prove that a particular structure is a λ-
model, it is often more convenient to use that deﬁnition.

15B Syntax-free deﬁnitions
237
Discussion 15.18 (The mapping Λ)
Let D = ⟨D, •, [[ ]]⟩be a λ-
model. A relation ∼called extensional equivalence was deﬁned in 14.5,
namely
a ∼b
⇐⇒
(∀d ∈D)( a • d = b • d ).
For each a ∈D, the extensional-equivalence class a is a set deﬁned by
a =

b ∈D : b ∼a

.
Obviously a ⊆D. Just as with any equivalence relation, the extensional-
equivalence classes partition D into non-overlapping subsets, and a = b
⇐⇒a ∼b.
Now, for each a ∈D, there exist M, x, ρ such that [[λx.M]]ρ ∈a.
For example, take M ≡ux and ρ = [a/u]σ for any valuation σ; then
ρ(u) = a, and [[λx.ux]]ρ is extensionally equivalent to a, because, for all
d ∈D,
[[λx.ux]]ρ • d = [[ux]][d/x]ρ
by 15.3(c),
= a • d
by 15.3(a), (b).
There are an inﬁnity of other examples M, x, ρ with [[λx.M]]ρ ∈a. But
whatever such M, x, ρ we take, the value of [[λx.M]]ρ is always the same
(by Berry’s extensionality property, Lemma 15.8(b)).
In eﬀect, just one member of a is chosen to be the value of [[λx.M]]ρ
for all M, x, ρ such that [[λx.M]]ρ ∈a. Call this member Λ(a):
Λ(a) = [[λx.ux]][a/u]σ for any σ.
(2)
We have thus deﬁned a mapping Λ from D to D.1 Its properties include:
(i)
Λ(a) ∼a
(by above),
(ii)
Λ(a) ∼Λ(b) =⇒Λ(a) = Λ(b)
(by 15.8(b)),
(iii)
a ∼b ⇐⇒Λ(a) = Λ(b)
(by (i), (ii)),
(iv)
Λ(Λ(a)) = Λ(a)
(by (i), (iii)).
Moreover, the map Λ is representable in D; i.e. there exists e ∈D such
that
(v)
e • a = Λ(a)
for all a ∈D.
One suitable such e is the member of D corresponding to the Church
numeral 1:
e = [[ 1 ]] = [[λxy.xy]]σ
(for any σ);
1 Λ(a) is sometimes called ‘λx.ax’, but that notation mixes the formal λ-calculus
language with its meta-language, so we shall not use it here.

238
Models of λ
this e works because
[[λxy.xy]]σ • a = [[λy.xy]][a/x]σ
by 15.3(c)
= Λ(a)
by (2) above and 15.3(e).
Using Λ, the deﬁnition of λ-model can be re-written as follows.
Deﬁnition 15.19 (Syntax-free λ-models) A syntax-free λ-model is
a triple ⟨D, •, Λ⟩where ⟨D, •⟩is an applicative structure, Λ maps D to
D, and
(a)
⟨D, •⟩is combinatorially complete (see 14.28–14.29),
(b)
(∀a ∈D)
Λ(a) ∼a,
(c)
(∀a, b ∈D)
a ∼b
=⇒
Λ(a) = Λ(b),
(d)
(∃e ∈D)(∀a ∈D)
e • a = Λ(a).
Theorem 15.20 ⟨D, •, Λ⟩is a syntax-free λ-model iﬀ⟨D, •, [[ ]]⟩is a
λ-model in the sense of Deﬁnition 15.3. Here [[ ]] is deﬁned from Λ by
(a)
[[x]]ρ = ρ(x),
(b)
[[PQ]]ρ = [[P]]ρ • [[Q]]ρ,
(c)
[[λx.P]]ρ = Λ(a), where (∀d ∈D)(a • d = [[P]][d/x]ρ).
And conversely, Λ is deﬁned from [[ ]] by
(d)
Λ(a) = [[λx.ux]][a/u]σ
for any σ.
Proof For ‘if’, see Discussion 15.18.
For ‘only if’: let ⟨D, •, Λ⟩be a syntax-free λ-model. We must ﬁrst
prove that (a)–(c) deﬁne [[M]]ρ for all M and ρ, and to do this the only
problem is to prove that the object a mentioned in (c) actually exists.
In fact we shall prove the following simultaneously:
(i) clauses (a)–(c) deﬁne [[M]]ρ for all ρ;
(ii) [[M]]ρ is independent of ρ(z) if z ̸∈FV(M);
(iii) for each sequence y1, . . . , yn ⊇FV(M) there exists b ∈D such
that, for all d1, . . . , dn ∈D,
b • d1 • . . . • dn = [[M]][d1 /y1 ]...[dn /yn ]ρ.
The proof of (i)–(iii) is by induction on M.
Case 1: M is a combination of variables. Then (i) and (ii) are trivial,
and (iii) holds by combinatory completeness.

15B Syntax-free deﬁnitions
239
Case 2: M ≡PQ. Then (i) and (ii) are trivial. For (iii), let bP , bQ
satisfy (iii) for P, Q and the given y1, . . . , yn. Deﬁne
g
=
[[λuvy1 . . . yn .(uy1 . . . yn)(vy1 . . . yn)]].
(This g exists by combinatory completeness.)
Then b = g • bP • bQ
satisﬁes (iii).
Case 3: M ≡λx.P. By induction-hypothesis (iii) applied to P and
y1, . . . , yn, x, there exists bP ∈D such that, for all d1, . . . , dn, d ∈D,
bP • d1 • . . . • dn • d = [[P]][d/x][d1 /y1 ]...[dn /yn ]σ
where σ is arbitrary. (The right side is independent of σ by induction
hypothesis (ii).)
To prove (i), it is enough to show that the a in (c) exists. Take any
ρ, let di = ρ(yi), and deﬁne
a = bP • d1 • . . . • dn.
Then a • d = [[P]][d/x]ρ by the equation for bP . This proves (i). Also (ii)
is obvious from this proof of (i).
To prove (iii) for λx.P: take any e ∈D that represents Λ, and deﬁne
b = f • e • bP , where
f = [[λuvy1 . . . yn .u(vy1 . . . yn)]].
(This f exists by combinatory completeness.) For any d1, . . . , dn ∈D,
we can deﬁne
a = bP • d1 • . . . • dn.
Then for all d ∈D we have a • d = [[P]][d/x]ρ, where ρ is deﬁned by
setting ρ(yi) = di. Hence, by (c),
[[λx.P]]ρ = Λ(a).
So
b • d1 • . . . • dn = e • a
by deﬁnition of b and f,
= Λ(a)
since e represents Λ,
= [[λx.P]]ρ
by above.
This ends the proof of (i)–(iii). To complete the theorem, we need only
check that [[ ]] satisﬁes 15.3(a)–(f). This is straightforward.

240
Models of λ
Corollary 15.20.1 The constructions of [[ ]] and Λ in Theorem 15.20
are mutual inverses. That is: if ⟨D, •, [[ ]]′⟩is a λ-model in the sense of
15.3, and we ﬁrst deﬁne Λ from [[ ]]′ by 15.20(d) and then deﬁne [[ ]] by
15.20(a)–(c), we shall get [[ ]] = [[ ]]′; and, conversely, if we start with a
syntax-free λ-model ⟨D, •, Λ′⟩and deﬁne ﬁrst [[ ]] and then Λ, we shall
get Λ = Λ′.
Proof Straightforward.
Remark 15.21 The above corollary says that the two given deﬁnitions
of λ-model are equivalent in a very strong sense.
Deﬁnition 15.19 is clearly independent of the λ-syntax. Even better,
in contrast to the earlier deﬁnition in 15.3, it is essentially just a ﬁnite
set of ﬁrst-order axioms. In fact, its clause (a) is equivalent to
(a′)

∃k, s ∈D

∀a, b, c ∈D
 
k•a•b = a ∧s•a•b•c = a•c•(b•c)

,
and (b) and (c) are equivalent to
(b′)

∀a, b ∈D
 
Λ(a) • b = a • b

,
(c′)

∀a, b ∈D
 
(∀d ∈D)(a • d = b • d)
=⇒
Λ(a) = Λ(b)

.
But the following deﬁnition is simpler still.
It is due to Dana Scott
[Sco80b, pp. 421–425] and Albert Meyer [Mey82, Deﬁnition 1.3], and
instead of focussing on Λ it focusses on one of its representatives in D.
By this means it avoids the need for the function-symbol ‘Λ’.
Deﬁnition 15.22 (Scott–Meyer λ-models)
A loose Scott–Meyer λ-
model is a triple ⟨D, •, e⟩where ⟨D, •⟩is an applicative structure, e ∈D,
and
(a)
⟨D, •⟩is combinatorially complete,
(b)
(∀a, b ∈D)

e • a • b = a • b

,
(c)
(∀a, b ∈D)

(∀d ∈D)(a • d = b • d)
=⇒
e • a = e • b

.
A strict Scott–Meyer λ-model is a loose model such that also
(d)
e • e = e.
Discussion 15.23
Suppose we take a Scott–Meyer model ⟨D, •, e⟩,
strict or loose, and deﬁne Λ to be the function that e represents, i.e.
Λ = Fun(e)
(3)
in the notation of Deﬁnition 14.4; then ⟨D, •, Λ⟩is easily seen to be a
syntax-free λ-model in the sense of Deﬁnition 15.19.

15B Syntax-free deﬁnitions
241
Conversely, if we take a syntax-free λ-model ⟨D, •, Λ⟩and let e be
any representative of Λ, then ⟨D, •, e⟩is a loose Scott–Meyer model. So
the loose Scott–Meyer deﬁnition of model is essentially equivalent to the
earlier deﬁnitions, 15.3 and 15.19.
However, one mapping Λ may have many representatives, so one
model in the sense of 15.19 may give rise to many loose Scott–Meyer
models. But only one of these is strict. To ﬁnd it, choose
e0 = [[ 1 ]] = [[λxy.xy]],
(4)
where [[ ]] is deﬁned from Λ by 15.20(a)–(c). This e0 represents Λ, by
the end of Discussion 15.18, and we also have
e0 • e0 = [[ 1 ]] • [[ 1 ]] = [[ 1 1 ]] = [[ 1 ]] = e0,
(5)
so ⟨D, •, e0⟩is a strict model.
No other representative of Λ gives a strict model. Because if e′ repre-
sents Λ and ⟨D, •, e′⟩is a strict model, we get e′ = e0. In detail:
e′ = e′ • e′
by 15.22(d) for e′,
= Λ(e′)
since e′ represents Λ,
= e0 • e′
since e0 represents Λ,
= e0 • e0
by 15.22(c) for e0 since e′ ∼e0,
= e0
by 15.22(d) for e0.
This discussion can be summed up as follows.
Theorem 15.24 The constructions Λ = Fun(e) and e0 = [[ 1 ]] are
mutual inverses. That is: if ⟨D, •, Λ⟩is a syntax-free λ-model in the
sense of Deﬁnition 15.19, and e0 = [[ 1 ]], then ⟨D, •, e0⟩is a strict
Scott–Meyer λ-model and Fun(e0) = Λ; and, conversely, if ⟨D, •, e⟩is a
strict Scott–Meyer λ-model and Λ = Fun(e), then ⟨D, •, Λ⟩is a syntax-
free λ-model and [[ 1 ]] = e.
Remark 15.25 The Scott–Meyer deﬁnition of model is clearly simpler
than both the previous deﬁnitions, in fact it is almost as simple as the
deﬁnition of ‘combinatory algebra’ in 14.9. All its clauses except (c) can
be expressed in the form
(∃x1, . . . , xm)(∀y1, . . . , yn) (P = Q)
(m, n ≥0).
(6)
But the exception is very important. If every clause had form (6), then
an analogue of the submodel theorem could be proved (Theorem 14.23),

242
Models of λ
and in particular the interior of every λ-model would be a λ-model. But
the latter is not true. (Two counter-examples are given in [HL80, Section
7]; one is the interior of TM(λβη).) So we have gone about as far as we
can go in simplifying the deﬁnition of λ-model.
This fact can be seen from another point of view: every combinatory
algebra contains members e satisfying (b) and (d) of Deﬁnition 15.22,
but there need not be one satisfying (c) as well.
In other words, as
noted in Remark 15.13, not all combinatory algebras can be made into
λ-models.
15C
General properties of λ-models
Discussion 15.26 By concentrating on Λ and its representatives we
came very quickly to a rather simple, almost algebraic, deﬁnition of
λ-model.
But λ-calculus is function-theory, not algebra, so a more
function-oriented view seems also desirable. Here is one such view.
Consider an arbitrary syntax-free λ-model ⟨D, •, Λ⟩. In the notation
of 14.3 and 14.4, (D→D)rep is the set of all its representable one-place
functions, Reps(θ) is the set of all representatives of a function θ ∈
(D→D)rep, and Fun(a) is the one-place function represented by a ∈D.
Of course Reps(θ) may have many members. But Λ gives us a way of
choosing a ‘canonical’ one, which will be called Rep(θ):
Rep(θ) = Λ(a) for any a ∈Reps(θ).
(7)
(This deﬁnition is independent of a by 14.6 and 15.18.) We clearly have
Fun(Rep(θ)) = θ.
(8)
Thus Fun is a left inverse of Rep, so by 15.1, Rep is a one-to-one embed-
ding of (D →D)rep into D, and (D →D)rep is a retract of D. (Figure
15:2.)
It is possible to reverse the above discussion and deﬁne application in
terms of representability. Let D be any set, S be any set of one-place
functions from D to D, and let Rep : S →D, Fun : D →S be any pair
of functions that form a retraction (Notation 15.1). That is, let
Fun ◦Rep = IS,
(9)

15C General properties of λ-models
243
F
(D →D)rep
D
D →D
XXXXXXXXXX
XXX
zFun
-
Fun

Rep
-Fun

Rep


:
Fun
ppppp
pppppppp
ppppppppp
pppppppppp
pppppppppp
pppppppppp
ppppppppppp
pppppppppppp
ppppppppppppp
pppppppppppp
ppppppppppppp
ppppppppppppp
pppppppppppp
ppppppppppppp
pppppppppppp
ppppppppppp
ppppppppppp
pppppppppp
pppppppppp
pppppppp
ppppppp
ppppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppp
ppppp
pppppppp
ppppppppp
pppppppppp
ppppppppppp
ppppppppppp
ppppppppppp
pppppppppppp
ppppppppppppp
ppppppppppppp
pppppppppppp
ppppppppppppp
pppppppppppp
pppppppppppp
pppppppppppp
ppppppppppp
pppppppppp
ppppppppp
pppppppp
ppppp
Fig. 15:2
where ◦is function-composition and IS is the identity-function on S.
Then we can deﬁne application for all a, b ∈D thus:
a • b = (Fun(a))(b).
(10)
It is easy to show that S becomes exactly the set of all functions repre-
sentable in ⟨D, •⟩, when • is deﬁned in this way. Next, deﬁne
Λ = Rep ◦Fun.
(11)
This Λ is easily seen to satisfy (b) and (c) in the deﬁnition of syntax-free
λ-model, 15.19. Now, in the present language the other conditions in
that deﬁnition say:
(i)
D has at least two members;
(ii)
⟨D, •⟩is combinatorially complete, if • is deﬁned by (10);
(iii)
Rep ◦Fun ∈S.
Hence any retraction that satisﬁes (i)–(iii) gives rise to a λ-model.
Discussion 15.27 For the reader who knows some category theory,
the above conditions can be expressed rather neatly. (The classic intro-
duction to category theory is [Mac71]; there are also many others, for
example [LS86], [Pie91] and [AL91].)
Let C be a cartesian closed category ([Mac71, Chapter IV, Section 6],
[Bar84, Deﬁnition 5.5.1], [LS86, Part 0 Section 7] or [AL91, Deﬁnition
2.3.3]).
Suppose also that the objects of C are sets, the arrows of C
are functions, and that the cartesian product, exponentiation, etc. in

244
Models of λ
the deﬁnition of ‘cartesian closed’ are the usual set-theoretic construc-
tions, except that not every function from an object A to an object
B need be an arrow in C, and the object BA corresponding to the
set of all arrows from A to B may be a proper subset of the set of
all functions from A to B.
(Such a C is called ‘strictly concrete’ in
[Bar84, Deﬁnition 5.5.8].)
Suppose C has an object D with at least two members, and suppose
there are two arrows
Fun : D →DD,
Rep : DD →D,
such that ⟨Rep, Fun⟩is a retraction (i.e. Fun ◦Rep = ID D ). Then all
the conditions in the preceding discussion are satisﬁed. In fact 15.26(9)
and (i) are given assumptions, (iii) follows from the fact that categories
are always ‘closed’ with respect to composition, and (ii) comes from the
deﬁnition of ‘cartesian closed’, [Bar84, Proposition 5.5.7(ii) and the note
after 5.5.8].
So every retraction in a strictly concrete cartesian closed category
gives rise to a λ-model, provided its domain has at least two mem-
bers.
Conversely, every λ-model can be described as a retraction in
some strictly concrete cartesian closed category.
Further, the model is extensional iﬀthe retraction is an isomorphism
(between D and DD).
More about a category-theoretic view of λ-models can be found in
[Koy82], [Bar84, Section 5.5], [LS86, Part 1 Sections 15–18], [AL91,
Chapters 8–9] and [Plo93]. For a more general category-theoretic ap-
proach to λ, perhaps the best source is [LS86]. Cartesian closed cate-
gories are also closely related to type-theory; see, for example, [LS86,
Part 1 Section 11], [Cro94] and [Jac99].
Remark 15.28 (The set F )
If ⟨D, •, Λ⟩is a syntax-free λ-model, the
range of Λ is called F. By Discussion 15.18, F has exactly one member
in each extensional-equivalence-class in D, and corresponds one-to-one
with (D →D)rep by the map Rep (see Figure 15:2).
An alternative
characterization of F is
(a)
F =

d ∈D : (∃M, x, ρ) ( d = [[λx.M]]ρ)

.
(Compare Discussion 15.18.) Finally, by Lemma 14.8(b), a λ-model is
extensional iﬀF = D.

15C General properties of λ-models
245
Remark 15.29 (Combinatory algebras and λ-models)
Suppose
we have a combinatory algebra ⟨D, •⟩: how many maps Λ exist such
that ⟨D, •, Λ⟩is a λ-model? The answer depends on the given algebra.
(a) There are examples with none. (See Remark 15.13.)
(b) There are examples with just one. (E.g. any extensional λ-model,
by 15.30 below; also the non-extensional model Pω in 16.65 later,
by [BL84, Section 2].) A ⟨D, •⟩with just one is called lambda-
categorical.
(c) There are examples with more than one. [Lon83, Theorem 4.1
and remarks after 4.3].
More on changing combinatory algebras into λ-models can be found in
[BK80], [Mey82], [Lon83, Section 4], [BL84] and [Bar84, Section 5.2].
If the given algebra is extensional, the task is easy, as the following
theorem shows.
Theorem 15.30 Every extensional combinatory algebra ⟨D, •⟩can be
made into a λ-model ⟨D, •, Λ⟩in exactly one way, namely by deﬁning
Λ(a) = a for all a ∈D. And ⟨D, •, Λ⟩is a model of the theory λβη.
Proof By extensionality, each set a has only one member, so Λ(a) = a
is the only way to deﬁne Λ such that λ(a) ∈a. And if Λ is deﬁned thus,
it does satisfy Deﬁnition 15.19(a)–(d).
Remark 15.31
In an extensional combinatory algebra, how do we
extend the deﬁnition of [[ ]] from CL-terms to λ-terms? The above the-
orem’s proof gives an indirect method, when combined with Theorem
15.20, but the following is a direct method.
(It looks very diﬀerent,
but, by extensionality, all deﬁnitions of [[ ]] that satisfy the conditions of
Deﬁnition 15.3 will give the same value to [[M]]ρ.)
First, ﬁnd s, k, i ∈D satisfying the axioms of the theory CLw, and
deﬁne [[ ]] for CL-terms in the usual way (14.11). Then deﬁne [[ ]] for
λ-terms via the H-transformation, namely:
[[M]]ρ = [[MH ]]ρ .
(12)
It is straightforward to check that this deﬁnition satisﬁes 15.3(a)–(f).
For example, here is the proof of 15.3(c):
[[λx.P]]ρ • d = [[[x].(PH )]]ρ • d
by (12) above
= [[([x].(PH ))x]][d/x]ρ
by 14.11(c), (a)
= [[PH ]][d/x]ρ
by 2.21 and 14.17
= [[P]][d/x]ρ
by (12) above.

246
Models of λ
Summary 15.32 Five main classes of models have been deﬁned in this
chapter and the previous one. We shall denote them as follows:
CLw: combinatory algebras (deﬁned in 14.9, and essentially the same
as models of the theory CLw which was deﬁned in 6.5);
CLβax: models of the theory CLβax (deﬁned in 14.15 and 9.38, and
essentially the same as the ‘λ-algebras’ of [Bar84]);
CLextax: models of the theory CLextax which was deﬁned in 8.10;
λβ: λ-models, as deﬁned in 15.3 (or equivalently, syntax-free λ-models
in 15.19 or Scott–Meyer λ-models in 15.22);
λβη: extensional combinatory algebras (where extensionality was de-
ﬁned in 14.7).
By 15.30 we can say λβη ⊆λβ, in the sense that every extensional
combinatory algebra can be made into a λ-model by adding some extra
structure (namely Λ or [[ ]]). In a similar sense, by 15.12–15.12.2:
(i)
λβη ⊆CLextax ⊆CLβax ⊆CLw,
(ii)
λβη ⊆λβ ⊆CLβax.
All these inclusions except the second one in (i) are known to be proper,
in the sense that there is a model in the right-hand class which is not in
the left-hand class and cannot be made so by an acceptably small change.
(See 14.25 for the ﬁrst one in (i), and [BK80] for the rest. The second
one in (i) lacks an obvious deﬁnition of ‘acceptably small change’.)
Further reading
A fuller account of the general concept of λ-model is in [Bar84, Chapter
5]. Short outline accounts can be found in several books, for example
[Han04, Chapter 5] and [Kri93, Chapter 7]. The basic ideas behind the
concept were explored in a cluster of papers around 1980; these included
[HL80], [BK80], [Sco80a], [Mey82], [Koy82] and [BL84].
However, much of the concept of λ-model goes back 30 years further.
Leon Henkin deﬁned two versions of it in [Hen50, p. 83 ‘standard model’
and p. 84 ‘general model’], and, although his λ-system was limited by
type-restrictions and contained an extensionality axiom (which simpliﬁes
the deﬁnition of model considerably, as we have seen), many of the key
ideas in the present chapter can be traced back to him.
But we have spent long enough studying the general concept of λ-
model without seeing any particular examples. The next chapter will
describe three particular λ-models in detail.

16
Scott’s D∞and other models
16A
Introduction: complete partial orders
Having looked at the abstract deﬁnition of ‘model’ in the last two chap-
ters, let us now study one particular model in detail. It will be a variant
of Dana Scott’s D∞, which was the ﬁrst non-trivial model invented,
and has been a dominant inﬂuence on the semantics of λ-calculus and
programming languages ever since.
Actually, D∞came as quite a surprise to all workers in λ – even to
Scott. In autumn 1969 he wrote a paper which argued vigorously that an
interpretation of all untyped λ-terms in set theory was highly unlikely,
and that those who were interested in making models of λ should limit
themselves to the typed version. (For that paper, see [Sco93].) The pa-
per included a sketch of a new interpretation of typed terms. Then, only
a month later, Scott realized that, by altering this new interpretation
only slightly, he could make it into a model of untyped λ; this was D∞.
D∞is a model of both CLw and λβ, and is also extensional. The
description below will owe much to accounts by Dana Scott and Gordon
Plotkin, and to the well-presented account in [Bar84], but it will give
more details than these and will assume the reader has a less mathemat-
ical background.
The construction of D∞involves notions from topology. These will be
deﬁned below. They are very diﬀerent from the syntactical techniques
used in this book so far, but they are standard tools in the semantics
of programming languages. The reader who wishes to study semantics
further will ﬁnd them essential, and will see in D∞the place where they
were ﬁrst introduced.
At the end of the chapter some other models will be deﬁned in outline,
with references. These are simpler than D∞, and the reader who only
247

248
Scott’s D∞and other models
wishes to see a model without looking any deeper should go straight to
Section 16F. (But be warned, they are not as simple as they look!)
Notation 16.1 In this chapter, IN will be the set of all natural numbers
as usual. The following notation will be new:
D, D′, D′′, X, Y , J :
arbitrary sets;
a, . . . , h :
members of these sets;
φ, ψ, χ :
functions;
⊑, ⊑′, ⊑′′ :
partial orderings (see 16.2) on D, D′, D′′ respectively;
⊒, ⊒′, ⊒′′ :
the reverse orderings (a ⊒b iﬀb ⊑a, etc.);
⊥, ⊥′, ⊥′′ :
the least members of D, D′, D′′ respectively
(⊥is called ‘bottom’);
(D→D′) :
the set of all functions from D to D′, i.e. functions
with domain = D and range ⊆D′;
[D→D′] :
the set of all functions from D to D′ that are
continuous (to be deﬁned in 16.10);
φ(X) :

φ(d) : d ∈X

, where X is a given set;
 X :
the least upper bound (supremum) of X (see 16.3);

n≥p
. . . :
 
· · · : n ≥p

;
 X =  Y :  X exists iﬀ Y exists, and  X =  Y if they
both exist.
An informal λ-notation ‘λλ’ will be used when deﬁning some functions.
For example, suppose two sets D and D′ are given, with a1, . . . , an ∈D,
and suppose φ is a function from Dn+1 to D′. Then there is a function
ψ from D to D′ such that
ψ(d) = φ(a1, . . . , an, d)
for all d ∈D.
This ψ will be called
λλd ∈D. φ(a1, . . . , an, d).
Other examples of the λλ-notation are:
λλd ∈D. φ(χ(d)) for φ ◦χ,
λλd ∈D. b
for ψ such that (∀d ∈D)(ψ(d) = b).
The notation has the following properties:

16A C.p.o.s
249

λλd ∈D.φ(d)

(b) = φ(b),
λλd ∈D.φ(d) = φ.
But note that this notation is not a new formal language. It will only
be used to denote functions that are easy to deﬁne without it (though
their deﬁnitions without it might be tedious). The ‘=’ in the above two
equations is not a formal λ-conversion, but is identity in set-theory as
usual. It means that both sides of the above equations denote the same
function in set-theory, i.e. the same set of ordered pairs.
Deﬁnition 16.2 (Partially ordered sets)
A partially ordered set is
a pair ⟨D, ⊑⟩where D is a set and ⊑is a binary relation on D, which is
(a)
transitive, i.e. a ⊑b and b ⊑c =⇒a ⊑c,
(b)
anti-symmetric, i.e. a ⊑b and b ⊑a =⇒a = b,
(c)
reﬂexive, i.e. a ⊑a.
The least member of D (if D has one) is called ⊥, or bottom; we have
(∀d ∈D)
⊥⊑d.
Deﬁnition 16.3 (Least upper bounds)
Let ⟨D, ⊑⟩be a partially
ordered set and let X ⊆D. An upper bound (u.b.) of X is any b ∈D
such that
(a)
(∀a ∈X)
a ⊑b.
The least upper bound (or l.u.b. or supremum) of X is called  X; it is
an upper bound b of X such that
(b)
(∀c ∈D)

(c is an u.b. of X) =⇒b ⊑c

.
Note that in general a set X need not have an upper bound; and if it
has one, it need not have a least one. Thus  X might not exist. Also,
if it does exist, it might not be in X.
Exercise 16.4 ∗For every partially ordered set ⟨D, ⊑⟩, prove the fol-
lowing.
(a) A subset X of D cannot have two distinct least upper bounds (i.e.
 X is unique if it exists). Hence, if b ∈D, to prove b =  X it
is enough to prove that b satisﬁes 16.3(a) and (b).
(b) D has a bottom (called ⊥) iﬀthe empty set ∅has a l.u.b.; and
⊥=  ∅.

250
Scott’s D∞and other models
(c) If X, Y ⊆D and every member of X is ⊑a member of Y and
vice versa, then
 X =  Y.
(By Notation 16.1, this equation means that the left side exists
iﬀthe right exists, and when they both exist they are equal.
Similarly for the equation in (d) below.)
(d) Let J be a set and

Xj : j ∈J

be a family of subsets of D, each
Xj having a l.u.b.  Xj. If Y is the union of this family, then
 Y
=
   Xj : j ∈J

.
Deﬁnition 16.5 (Directed sets)
Let ⟨D, ⊑⟩be a partially ordered
set. A subset X ⊆D is said to be directed iﬀX ̸= ∅and every pair of
members of X has an upper bound in X, i.e.
(∀a, b ∈X) (∃c ∈X)

a ⊑c and b ⊑c

.
The most important examples of directed sets are ﬁnite or inﬁnite
increasing sequences:
a1 ⊑a2 ⊑a3 ⊑. . .
An example which is not a sequence is the set of all partitions of an
interval [a, b]; it is used in deﬁning the Riemann integral in mathematical
analysis. In mathematics in general, directed sets are used as index-sets
in the theory of convergence on nets, see [Kel55, Chapter 2].
Deﬁnition 16.6 (Complete partial orders, c.p.o.s)
A c.p.o. is a
partially ordered set ⟨D, ⊑⟩such that
(a)
D has a least member (called ⊥);
(b)
every directed subset X ⊆D has a l.u.b. (called  X).
Notation Instead of ‘the c.p.o. ⟨D, ⊑⟩’, we shall write ‘the c.p.o. D’,
and similarly for D′, D′′, etc. We shall always assume that ⊑is the
ordering on D, and ⊑′ on D′ and ⊑′′ on D′′. For example, the ﬁrst line
of Deﬁnition 16.10 below means ‘let ⟨D, ⊑⟩and ⟨D′, ⊑′⟩be c.p.o.s’.
Remark 16.7 The above deﬁnitions might seem to be diverging from
what we would expect the essential components of a λ-model to be, so
let us look at the motivation for introducing partial orderings.
Scott originally built D∞as a model for a theory of computable
higher-type functions (functions of functions).
Standard accounts of

16A C.p.o.s
251
computable functions from IN to IN emphasise partial functions, i.e. func-
tions for which φ(n) need not have a value for all n ∈IN, and at ﬁrst
sight it might seem natural to extend this approach to higher levels. But
in Scott’s theory all the functions were total. Instead of IN, he worked
with
IN+
= IN ∪{⊥}
(⊥̸∈IN),
where ⊥was an arbitrary object introduced to represent ‘undeﬁnedness’
or ‘garbage’.
In this approach, every partial function φ of natural numbers deter-
mines a total function φ+ ∈(IN+ →IN+), deﬁned thus:
(a)



φ+(n) =
 φ(n)
if φ(n) is deﬁned
⊥
otherwise

(∀n ∈IN)
φ+(⊥) = ⊥.
Introducing ⊥has several advantages. One is to allow us to distinguish
between two kinds of constant-function. For each p ∈IN, we can deﬁne
(b)
ψp :
(∀n ∈IN)
ψp(n) = p,
ψp(⊥) = ⊥;
(c)
ψ
′
p :
(∀n ∈IN)
ψ
′
p(n) = p,
ψ
′
p(⊥) = p.
Now ψp = (φp)+, where φp is the constant-function φp(n) = p for all
n ∈IN. In contrast, ψ
′
p does not have the form φ+ for any function
φ, and theories of partial functions often omit it.
Nevertheless it is
programmable in practice, and Scott’s theory therefore includes it.
A disadvantage of introducing ⊥is that, if we are not careful, we
might ﬁnd ourselves treating it as an output-value with the same status
as a natural number. To prevent this, Scott deﬁned the following partial
order on IN+; it corresponds to the intuition that an output φ(n) = ⊥
carries less information than an output φ(n) = m ∈IN.
Deﬁnition 16.8 (The set IN+)
Choose any object ⊥̸∈IN, and deﬁne
IN+ = IN ∪{⊥}. For all a, b ∈IN+, deﬁne
a ⊑b
⇐⇒
(a = ⊥and b ∈IN) or a = b.
(see Figure 16:1.) The pair ⟨IN+, ⊑⟩will be called just IN+.
Lemma 16.9 IN+ is a c.p.o.
Proof It is easy to check that ⊑is a partial order. The only directed
subsets of IN+ are (i) one-member sets, and (ii) pairs {⊥, n} with n ∈IN.
Both these have obvious l.u.b.s.

252
Scott’s D∞and other models
⊥
l
l
l
l
l
l
0
\
\
\
\
1
L
L
L
L
2
3




4




5
ppppppppppppppppppppppppp
.
p p p p p p p p p p p p p p p p p p p p p
.
p p p p p p p p p p p p p p p p p p p p p p
.
p p p p p p p p p p p p p p p p p p p p p p
.
Fig. 16:1
The construction of D∞will begin with the c.p.o. IN+. It will involve
some properties of functions of arbitrary c.p.o.s, to be described in the
next section.
16B
Continuous functions
Deﬁnition 16.10 (Continuity) Let D and D′ be c.p.o.s, and φ be a
function from D to D′. We say φ is monotonic iﬀ
(a)
a ⊑b
=⇒
φ(a) ⊑′ φ(b).
We say φ is continuous iﬀ, for all directed X ⊆D,
(b)
φ( X) = (φ(X)).
In (b), φ(X) =

φ(a) : a ∈X

, and the equation means that (φ(X))
exists and coincides with φ( X). ( X exists because X is directed
and D is a c.p.o.)
Exercise 16.11 ∗Prove that every continuous function from D to D′
is monotonic.
Exercise 16.12 ∗
Prove that there are only two kinds of continuous
functions from IN+ to IN+: those of form φ+ for φ a partial function
from IN to IN, and those of form ψ
′
p in 16.7(c).
Hint: prove that, for all functions χ ∈(IN+ →IN+),
χ continuous
⇐⇒
χ monotonic
⇐⇒
χ(⊥) = ⊥or (∃p ∈IN)(∀a ∈IN+)(χ(a) = p).

16B Continuous functions
253
Exercise 16.13∗Let D and D′ be c.p.o.s and φ : D→D′ be monotonic.
Prove that if X ⊆D is directed then so is φ(X). Hence, since D′ is a
c.p.o., φ(X) has a l.u.b., (φ(X)).
Remark 16.14 Exercise 16.13 will be used below in proofs that certain
functions are continuous.
To prove a function φ continuous, one must prove that if X is directed
then (φ(X)) exists and φ( X) = (φ(X)).
In each of the continuity proofs below, it will be fairly obvious that the
function is monotonic. So by Exercise 16.13 we shall know immediately
that (φ(X)) exists, and the proof will reduce to a fairly straightforward
calculation with l.u.b.s to show that φ( X) = (φ(X)). We shall not
have to worry in this calculation whether the l.u.b.s involved exist.
Remark 16.15 The word ‘continuous’ comes from the study of topol-
ogy, and Scott’s theory of computability was actually formulated in
topological language, [Sco72].
Every c.p.o. has a topology called the
Scott topology, whose continuous functions are exactly those in Deﬁni-
tion 16.10; see [Bar84, Deﬁnition 1.2.3].
Deﬁnition 16.16 (The function-set [D →D′])
For c.p.o.s D and
D′, deﬁne [D →D′] to be the set of all continuous functions from D to
D′. For φ, ψ ∈[D→D′], deﬁne
φ ⊑ψ
⇐⇒
(∀d ∈D)

φ(d) ⊑′ ψ(d)

.
Remark 16.17
Informally, if we think of a ⊑′ b as meaning that a
carries less or the same information as b, then φ ⊑ψ says that each
output-value φ(d) carries less or the same information as ψ(d).
It is easy to check that the relation ⊑deﬁned above is a partial order.
Further, for all φ1, φ2 ∈[D→D′],
(a)
φ1 ⊑φ2, d1 ⊑d2
=⇒
φ1(d1) ⊑′ φ2(d2).
Also [D→D′] has a least member, namely the function ⊥deﬁned by
(∀d ∈D)
⊥(d) = ⊥′.
In the special case D = D′, [D →D] contains the identity function ID,
whose deﬁnition is
(∀d ∈D)
ID(d) = d.

254
Scott’s D∞and other models
Lemma 16.18 Let D and D′ be c.p.o.s Then [D →D′] is a c.p.o.
Furthermore, for every directed set Y ⊆[D→D′] we have
(∀d ∈D)
( Y )(d) =  
φ(d) : φ ∈Y

.
Proof Let Y ⊆[D→D′] be directed. For each d ∈D, deﬁne
Yd =

φ(d) : φ ∈Y

.
(1)
Then Yd is directed. (Proof: if a, b ∈Yd, then a = φ(d) and b = ψ(d)
for some φ, ψ ∈Y , and since Y is directed it contains χ ⊒φ, ψ; then
χ(d) ⊒a, b.) Also Yd ⊆D′ and D′ is a c.p.o. Hence  Yd exists. Thus
the right-hand side of the equation in the lemma is meaningful.
Deﬁne a function ψ from D to D′ thus:
(∀d ∈D)
ψ(d) =  Yd.
(2)
The lemma claims that ψ =  Y . Before proving this claim, we ﬁrst
prove ψ continuous. Let X ⊆D be directed; then
ψ( X)
=
 
Y( X )

by (2)
=
 
φ( X) : φ ∈Y

by (1)
=
  (φ(X)) : φ ∈Y

by continuity of φ
=
 
φ(a) : a ∈X and φ ∈Y

by 16.4(d)
=
   Ya : a ∈X

by 16.4(d)
=
 
ψ(a) : a ∈X

by (2).
(It is easy to check that all the sets above are directed and are ⊆D or
D′; since D and D′ are c.p.o.s, all the l.u.b.s mentioned above do exist.)
Thus ψ is continuous. Hence ψ ∈[D→D′].
Now ψ is an u.b. of Y . Because, for all φ ∈Y and d ∈D, we have
φ(d) ⊑ Yd by (1), = ψ(d) by (2).
Finally, ψ ⊑every other u.b. χ of Y . Because, for all d ∈D, χ(d)
must be an u.b. of Yd and hence ⊒its least u.b., which is ψ(d).
Lemma 16.19 (Composition) The composition of continuous func-
tions is continuous. That is, if D, D′, D′′ are c.p.o.s and ψ ∈[D→D′]
and φ ∈[D′ →D′′], and φ ◦ψ is deﬁned by
(∀d ∈D)
(φ ◦ψ)(d) = φ(ψ(d)),
then
φ ◦ψ ∈[D→D′′].

16B Continuous functions
255
Proof Straightforward.
Deﬁnition 16.20 (Isomorphism)
Let D and D′ be c.p.o.s. We say
D is isomorphic to D′, or D ∼= D′, iﬀthere exist φ ∈[D →D′] and
ψ ∈[D′ →D] such that
ψ ◦φ = ID,
φ ◦ψ = ID ′.
(It is easy to see that any such φ and ψ must be one-to-one and onto.
They are also continuous, and hence are monotonic, i.e. they preserve
order.)
Deﬁnition 16.21 (Projections)
Let D and D′ be c.p.o.s. A projec-
tion from D′ to D is a pair ⟨φ, ψ⟩of functions with φ ∈[D →D′] and
ψ ∈[D′ →D], such that
ψ ◦φ = ID,
φ ◦ψ ⊑ID ′.
We say D′ is projected onto D by ⟨φ, ψ⟩. (See Figure 16:2.)
A projection ⟨φ, ψ⟩is a retraction in the sense of Notation 15.1, but
with the extra properties that φ and ψ are continuous and
φ ◦ψ ⊑ID ′.
It is easy to show that ⟨φ, ψ⟩makes D isomorphic to the set φ(D) ⊆D′.
Also ⟨φ, ψ⟩makes the bottom members of D and D′ correspond:
φ(⊥) = ⊥′,
ψ(⊥′) = ⊥.






B
B
B
B
B
B
D






B
B
B
B
B
B φ(D)









A
A
A
A
A
A
A
A
A
D′

ψ
-
φ
-
φ







)
ψ
Fig. 16:2

256
Scott’s D∞and other models
16C
The construction of D∞
We shall build D∞as the ‘limit’ of a sequence D0, D1, D2, . . . of c.p.o.s,
each of which is the continuous-function set of the one before it. Their
precise deﬁnition is as follows.
Deﬁnition 16.22 (The sequence D0, D1, D2, . . . )
Deﬁne D0 =
IN+ (see Deﬁnition 16.8), and
Dn+1 = [Dn →Dn].
The ⊑-relation on Dn will be called just ‘ ⊑’; it is deﬁned in Deﬁnition
16.16. The least member of Dn will be called ⊥n.
By Lemmas 16.9 and 16.18, every Dn is a c.p.o.
Discussion 16.23 To build a λ-model ⟨D∞, •, [[ ]]⟩in a standard set-
theory such as ZF, we cannot take D∞to be a set of functions and
• to be function-application, because in set-theory no function can be
applied to itself.
Scott avoided this problem by a device which, in principle, is very
simple.
He took the members of D∞to be not just functions, but
inﬁnite sequences of functions:
φ = ⟨φ0, φ1, φ2, . . .⟩
with φn ∈Dn. Application was deﬁned by
φ • ψ
=
⟨φ1(ψ0), φ2(ψ1), φ3(ψ2), . . .⟩.
With this deﬁnition, self-application becomes immediately possible:
φ • φ
=
⟨φ1(φ0), φ2(φ1), φ3(φ2), . . .⟩.
It will be a long way from this simple idea to an actual λ-model, and the
deﬁnition of application will become somewhat more complicated before
it gets there, but the above is its motivation.
Deﬁnition 16.24 (The initial maps) To begin the limit-construction,
we embed D0 into D1 by a map φ0 and deﬁne a reverse map ψ0:
(a)
for all d ∈D0, deﬁne φ0(d) = λλa ∈D0. d ;
(b)
for all g ∈D1, deﬁne ψ0(g) = g(⊥0).

16C The construction of D∞
257
That is, for d ∈D0, φ0(d) is the constant-function with value d.
Constant-functions are obviously continuous, so φ0(d) ∈D1; hence φ0 ∈
(D0 →D1).
Conversely, for g ∈D1 we have g(⊥0) ∈D0, so ψ0 ∈
(D1 →D0). Also ψ0(g) is the least value of g, since each g ∈D1 is
continuous and hence monotonic.
Lemma 16.25 The pair ⟨φ0, ψ0⟩is a projection from D1 to D0; i.e.
(a)
φ0 ∈[D0 →D1] and ψ0 ∈[D1 →D0];
(b)
ψ0 ◦φ0 = ID0 ; i.e. ψ0(φ0(d)) = d for all d ∈D0;
(c)
φ0 ◦ψ0 ⊑ID1 ; i.e. φ0(ψ0(g)) ⊑g for all g ∈D1.
Proof
(a) Just before the Lemma we have seen that φ0 ∈(D0 →D1)
and ψ0 ∈(D1 →D0). To prove (a) we must show further that φ0 and
ψ0 are continuous. This is left as an exercise.⋆
(b) ψ0(φ0(d)) = φ0(d)(⊥0), = d by the deﬁnition of φ0(d).
(c)
Let g ∈D1. Then g is continuous and therefore monotonic, so
g(⊥0) ⊑g(d) for all d ∈D0. Then
φ0(ψ0(g))
=
λλd ∈D0. g(⊥0)
⊑
λλd ∈D0. g(d)
by deﬁnition of ⊑in D1
=
g.
Discussion 16.26 We shall make the above initial projection induce a
projection ⟨φn, ψn⟩from Dn+1 to Dn for each n ≥1, in a very natural
way. Then, in category-theory language, D∞will be the inverse limit
of this sequence of projections in the category of c.p.o.s and continuous
functions (Figure 16:3).
For each n, we shall have Dn ≺[Dn →Dn], where ‘≺’ denotes projec-
tion, and in the limit we shall obtain
D∞∼= [D∞→D∞].
Deﬁnition 16.27 (Maps between Dn and Dn+1) For every n ≥0
we deﬁne a pair of mappings φn, ψn. If n = 0, deﬁne φ0, ψ0 as in 16.24.
If n ≥1 and φn−1, ψn−1 have already been deﬁned, deﬁne φn, ψn thus:
(a)
φn(f) = φn−1 ◦f ◦ψn−1
(∀f ∈Dn),
(b)
ψn(g) = ψn−1 ◦g ◦φn−1
(∀g ∈Dn+1).

258
Scott’s D∞and other models




A
A
A
A
D0





A
A
A
A
AA [D0 →D0]
=
D1







A
A
A
A
A
A
AA
[D1 →D1]
=
D2



qqq
Fig. 16:3
That is
(a′)
φn(f)(b) = φn−1(f(ψn−1(b)))
(∀f ∈Dn, ∀b ∈Dn),
(b′)
ψn(g)(a) = ψn−1(g(φn−1(a)))
(∀g ∈Dn+1, ∀a ∈Dn−1).
Very roughly speaking, φn(f) is a function which acts on members of
Dn by applying f to the ‘corresponding’ members of Dn−1, and ψn(g)
acts on members of Dn−1 by applying g to the ‘corresponding’ members
of Dn.
Lemma 16.28 The pair ⟨φn, ψn⟩is a projection from Dn+1 to Dn; i.e.
(a)
φn ∈[Dn →Dn+1],
ψn ∈[Dn+1 →Dn];
(b)
ψn ◦φn = IDn ;
(c)
φn ◦ψn ⊑IDn + 1 .
Proof We use induction on n. The basis (n = 0) is 16.25.
For the induction-step, let n ≥1, and assume (a)–(c) for n −1. To
prove (a) for n, two things must be veriﬁed:
(a1)
φn ∈(Dn →Dn+1),
ψn ∈(Dn+1 →Dn);
(a2)
φn and ψn are continuous.
To prove (a1) for φn, the main step is to prove φn(f) continuous for
all f ∈Dn. But this follows from 16.19 and the deﬁnition of φn and
part (a2) of the induction-hypothesis for φn−1 and ψn−1. Similarly for
ψn.
We next prove (a2) for φn. (The proof for ψn is similar.) Let X ⊆Dn
be directed. It is not hard to see that φn is monotonic, so the set φn(X)
is directed and hence (φn(X)) exists. Both (φn(X)) and φn( X)
are functions, so to prove them equal we only need prove
(∀b ∈Dn)
φn( X)(b) =
 (φn(X))

(b).
(3)

16C The construction of D∞
259
But
φn( X)(b)
= φn−1

( X)(ψn−1(b))

by 16.27(a′)
= φn−1
  
f(ψn−1(b)) : f ∈X
 
by 16.18
=  
φn−1(f(ψn−1(b))) : f ∈X

by contin. φn−1
=  
φn(f)(b) : f ∈X

by 16.27(a′)
=
 (φn(X))

(b)
by 16.18.
Next we prove (b) for n. We must prove that ψn(φn(f)) = f for all
f ∈Dn; i.e. that ψn(φn(f))(a) = f(a) for all a ∈Dn−1. But
ψn(φn(f))(a)
= ψn−1(φn(f)(φn−1(a)))
by 16.27(b′)
= ψn−1

φn−1(f(ψn−1(φn−1(a))))

by 16.27(a′)
= f(a)
by induc. hyp.
The proof of (c) for n is similar. This ends the induction step.
Lemma 16.29 The maps φn and ψn preserve application, in the fol-
lowing sense: for all a ∈Dn+1 and b ∈Dn,
(a)
ψn−1(a(b)) ⊒ψn(a)(ψn−1(b))
if n ≥1;
(b)
φn(a(b)) = φn+1(a)(φn(b))
if n ≥0.
Proof We prove (a). (The proof of (b) is similar.) By 16.27(b′),
ψn(a)(ψn−1(b)) = ψn−1(a(φn−1(ψn−1(b))))
⊑ψn−1(a(b))
by 16.28(c) for n −1.
Exercise 16.30 ∗If n ≥2, Dn contains the following analogue of K:
kn = λλa ∈Dn−1. λλb ∈Dn−2. ψn−2(a) .
Prove that
(a)
kn ∈Dn
for all n ≥2;
(b)
ψ1(k2) = ID0
and ψ0(ψ1(k2)) = ⊥0;
(c)
ψn(kn+1) = kn
for all n ≥2.
(Hint: a proof of (a) must contain proofs that (a1) for all a ∈Dn−1,
kn(a) is continuous, and (a2) kn is continuous.)

260
Scott’s D∞and other models
Note 16.31 If n ≥3, Dn contains the following analogue of S:
sn = λλa ∈Dn−1. λλb ∈Dn−2. λλc ∈Dn−3. a(φn−3(c))(b(c)) .
It is tedious, but not hard, to prove that
(a)
sn ∈Dn
for all n ≥3;
(b)
ψ2(s3) = λλa ∈D1. λλb ∈D0. a(⊥0),
ψ1(ψ2(s3)) = ID0 ;
(c)
ψn(sn+1) = sn
for all n ≥3.
Deﬁnition 16.32 For every pair m, n ≥0, a map φm,n is deﬁned from
Dm to Dn thus:
φm,n =







φn−1 ◦φn−2 ◦. . . ◦φm+1 ◦φm
if m < n,
IDm
if m = n,
ψn ◦ψn+1 ◦. . . ◦ψm−2 ◦ψm−1
if m > n.
Lemma 16.33
(a)
φm,n ∈[Dm →Dn];
(b)
m ≤n
=⇒
φn,m ◦φm,n = IDm ;
(c)
m > n
=⇒
φn,m ◦φm,n ⊑IDm ;
(d)
φk,n ◦φm,k = φm,n
if k is between m and n.
Proof By 16.19 and 16.28.
Deﬁnition 16.34 (Construction of D∞)
We deﬁne D∞to be the
set of all inﬁnite sequences
d = ⟨d0, d1, d2, . . . ⟩
such that (for all n ≥0) dn ∈Dn and ψn(dn+1) = dn. A relation ⊑on
D∞is deﬁned by setting
d ⊑d′
⇐⇒
(∀n ≥0)(dn ⊑d′
n).
Notation 16.35
In the rest of this chapter, ‘an’, ‘bn’, ‘(a • b)n’, etc.
will denote the n-th member of a sequence a or b or a • b, etc. in D∞.
Also, for X ⊆D∞, Xn is deﬁned by
Xn = {an : a ∈X}.

16D Properties of D∞
261
16D
Basic properties of D∞
Lemma 16.36 D∞is a c.p.o. Its least member is
⊥= ⟨⊥0, ⊥1, ⊥2, . . . ⟩,
where ⊥n is the least member of Dn. And for all directed X ⊆D∞,
 X =
  X0,  X1,  X2, . . .
 
.
Proof
Let X ⊆D∞be directed. Then each Xn is directed, so  Xn
exists in Dn. Further, the sequence ⟨ X0,  X1,  X2, . . .⟩is in D∞,
because
ψn( Xn+1)
= (ψn(Xn+1))
by continuity of ψn
=  
ψn(an+1) : a ∈X

by deﬁnition of Xn+1
=  Xn
since ψn(an+1) = an.
Finally, we must prove that ⟨ X0,  X1,  X2, . . .⟩satisﬁes the two con-
ditions in Deﬁnition 16.3 for being the least upper bound of X. But this
is straightforward.
Deﬁnition 16.37 (Embedding Dn into D∞)
Mappings φ∞,n from
D∞to Dn and φn,∞from Dn to D∞are deﬁned thus:
(∀d ∈D∞)
φ∞,n(d) = dn;
(∀a ∈Dn)
φn,∞(a) = ⟨φn,0(a), φn,1(a), φn,2(a), . . . ⟩.
By the way, the n-th term in the sequence for φn,∞(a) is just a, since
φn,n = IDn .
Lemma 16.38 ⟨φn,∞, φ∞,n⟩is a projection from D∞to Dn; i.e.
(a)
φn,∞∈[Dn →D∞],
φ∞,n ∈[D∞→Dn];
(b)
φ∞,n ◦φn,∞= IDn ;
(c)
φn,∞◦φ∞,n ⊑ID∞.
Also, if m ≤n and d ∈Dm, then
(d)
φn,∞(φm,n(d)) = φm,∞(d).
Proof Straightforward.

262
Scott’s D∞and other models
Lemma 16.39 For all a ∈D∞and all n, r ≥0:
(a)
φn+r,n(an+r) = an;
(b)
φn,∞(an) ⊑φn+1,∞(an+1);
(c)
a =

n≥0
φn,∞(an) =

n≥r
φn,∞(an).
Proof (a) By the deﬁnitions of D∞and φn+r,n.
(b)
φn,∞(an) = φn,∞(ψn(an+1))
since a ∈D∞
= φn+1,∞(φn(ψn(an+1)))
by 16.38(d)
⊑φn+1,∞(an+1)
by 16.28(c).
(c) Let X = {φn,∞(an) : n ≥0}. By (b), X is an increasing sequence.
Hence X is directed, so  X exists. Also, since X is increasing, for all
r ≥0 we have
X =

n≥r
φn,∞(an).
(4)
To prove  X = a, we must prove that ( X)p = ap for all p ≥0. But
  X

p
=
 
n≥p
φn,∞(an)

p
by (4) above
=

n≥p
(φn,∞(an))p
by 16.36
=

n≥p
φn,p(an)
by def. of φn,∞
=
{ap}
by (a)
=
ap .
Remark 16.40 By Lemma 16.28, φn,∞embeds Dn isomorphically into
D∞; i.e. the range of φn,∞is an isomorphic copy of Dn inside D∞. (See
16.20, 16.21 and Figure 16:2.) So it is possible to think of each d in
Dn as being the same as φn,∞(d) in D∞, and speak of d as if it was
a member of D∞. With this convention, Lemma 16.39(b) would imply
that, for each a ∈D∞,
a0 ⊑a1 ⊑a2 ⊑. . . ,
and 16.39(c) would say that
a = {a0, a1, a2, . . . }.

16D Properties of D∞
263
Thus a0, a1, a2, . . . could be thought of as a sequence of better and better
‘approximations’ to a. Also 16.38(d) implies that, modulo isomorphism,
D0 ⊆D1 ⊆D2 ⊆. . . D∞.
Identifying members of Dn with members of D∞may perhaps confuse
a less mathematically experienced reader a little, so it will not be done
in this book; but it is standard practice in most accounts of D∞and
similar models of λ.
Deﬁnition 16.41 (Application in D∞)
For a, b ∈D∞, the set

φn,∞(an+1(bn)) : n ≥0

will be shown in Lemma 16.42 below to be
an increasing sequence; hence it has a l.u.b. Deﬁne
a • b =

n≥0
φn,∞(an+1(bn)).
Viewed in the light of Remark 16.40 above, a • b is the l.u.b. of an
increasing sequence of approximations, an+1(bn). This is the modiﬁca-
tion of the simple deﬁnition of application in Discussion 16.23, that is
needed to make D∞into a λ-model.
Lemma 16.42 For all a, b ∈D∞,
φn,∞(an+1(bn)) ⊑φn+1,∞(an+2(bn+1)).
Proof First,
φn(an+1(bn))
= φn

ψn+1(an+2)(ψn(bn+1))

since a, b ∈D∞
⊑φn

ψn(an+2(bn+1))

by 16.29(a)
⊑an+2(bn+1)
by 16.28(c).
Next, apply φn+1,∞to both sides and use 16.38(d).
Corollary 16.42.1 For all a, b ∈D∞and all r ≥0:
(a)
a • b =

n≥r
φn,∞(an+1(bn));
(b)
(a • b)r =

n≥r
φn,r(an+1(bn));
(c)
(a • b)r ⊒ar+1(br).
Proof
(a) By 16.41 and 16.42.
(b) By (a) and 16.36 and the deﬁnition of φn,∞.
(c) By (b) and 16.42.

264
Scott’s D∞and other models
Deﬁnition 16.43 (Interpreting combinations of variables) Recall
that Vars is the set of all variables in λ and CL. A combination of
variables is a λ- or CL-term built from variables by application only
(i.e. containing no λs or combinators). Let ρ be any mapping from Vars
to D∞. Then ρ generates an interpretation in D∞of every combination
of variables, thus:
(a)
[[x]]ρ = ρ(x);
(b)
[[PQ]]ρ = [[P]]ρ • [[Q]]ρ.
Deﬁnition 16.44
Let n ≥0. Then every mapping ρ from Vars to
D∞generates, for every combination M of variables, not only the inter-
pretation in D∞deﬁned above, but also an interpretation [[M]]n
ρ in Dn
deﬁned as follows:
(a)
[[x]]n
ρ = (ρ(x))n;
(b)
[[PQ]]n
ρ = [[P]]n+1
ρ

[[Q]]n
ρ

.
Example 16.45 Let ρ(x) = a, ρ(y) = b, and ρ(z) = c. Then
(a)
[[xz(yz)]]n
ρ = an+2(cn+1)(bn+1(cn));
(b)
[[xx]]n
ρ = an+1(an).
Remark 16.46
The interpretation [[M]]n
ρ can be thought of as an ‘ap-
proximation’ to [[M]]ρ. In fact Lemma 16.48(a) below will show that as
n increases, [[M]]n
ρ approximates closer and closer to [[M]]ρ, in the sense
that
[[M]]ρ =

n≥0
φn,∞

[[M]]n
ρ

.
This idea of approximation can, with some work, be extended from com-
binations of variables to λ-terms in general. Although it is a semantic
concept, it gave rise in the 1970s to a new technique on the syntac-
tical side, which involved assigning natural-number labels to parts of
λ-terms, and this led to a sort of type-theory. Properties of this ‘la-
belled λ-calculus’ led to deep results about the behaviour of terms in
pure untyped λ-calculus; see [Bar84, Chapter 14].
The following two lemmas will be needed in proving that D∞is a
λ-model.

16D Properties of D∞
265
Lemma 16.47 For all combinations M of variables, all ρ : Vars →D∞,
and all n, r ≥0:
(a)
ψn

[[M]]n+1
ρ

⊒[[M]]n
ρ ;
(b)
φn+r,n

[[M]]n+r
ρ

⊒[[M]]n
ρ ;
(c)
φn+r,∞

[[M]]n+r
ρ

⊒φn,∞

[[M]]n
ρ

.
Proof
(a) By induction on M. The induction step uses 16.29(a).
(b) By (a) iterated.
(c) The key is the case r = 1. For this case,
φn+1,∞

[[M]]n+1
ρ

⊒φn+1,∞

φn

ψn([[M]]n+1
ρ
)

by 16.28(c)
⊒φn+1,∞

φn([[M]]n
ρ )

by (a) above
= φn,∞

[[M]]n
ρ

by 16.38(d).
Lemma 16.48 For all combinations M of variables, all ρ : Vars →D∞,
and all n, r ≥0:
(a)
[[M]]ρ =

n≥r
φn,∞

[[M]]n
ρ

;
(b)

[[M]]ρ

r =

n≥r
φn,r

[[M]]n
ρ

.
Proof
(a) By (b) and 16.47(c) and the deﬁnition of φn,∞.
(b) By induction on M, as follows.
Basis (M ≡x): Let ρ(x) = d ∈D∞. Then φn,r(dn) = dr when n ≥r,
by 16.39(a), so

n≥r
φn,r

[[x]]n
ρ

=

n≥r
φn,r(dn) =

n≥r
dr
= dr.
Induction-step (M ≡PQ): First,

[[PQ]]ρ

r =

n≥r
φn,r

([[P]]ρ)n+1

([[Q]]ρ)n

by 16.42.1(b)
=

n≥r
φn,r


p≥n+1
φp,n+1([[P]]p
ρ)
 
q≥n
φq,n([[Q]]q
ρ)

by induction hypothesis

266
Scott’s D∞and other models
=

n≥r

p≥n+1

q≥n
an,p,q
by continuity,
where
an,p,q = φn,r

φp,n+1([[P]]p
ρ)

φq,n([[Q]]q
ρ)

.
(5)
Now by 16.47(b) applied to P and Q,
an,p,q
⊒φn,r

[[P]]n+1
ρ
([[Q]]n
ρ )

= φn,r([[PQ]]n
ρ ).
This gives us half of (b), namely

[[PQ]]ρ

r
⊒

n≥r
φn,r([[PQ]]n
ρ ).
(6)
To complete (b) we must prove that the left side of (6) ⊑the right side.
For this, it is enough to prove that for each triple n, p, q in (5) there is
an m ≥r such that
an,p,q ⊑φm,r([[PQ]]m
ρ ).
(7)
Choose m = max{p −1, q}. Then m + 1 ≥p ≥n + 1 and m ≥r, and
φp,n+1([[P]]p
ρ)
⊑(φp,n+1 ◦φm+1,p) ([[P]]m+1
ρ
)
by 16.47(b)
= (ψn+1 ◦. . . ◦ψm)([[P]]m+1
ρ
).
Similarly
φq,n([[Q]]q
ρ) ⊑(φq,n ◦φm,q) ([[Q]]m
ρ )
= (ψn ◦. . . ◦ψm−1)([[Q]]m
ρ ).
Hence
an,p,q ⊑φn,r

(ψn+1 ◦... ◦ψm)([[P]]m+1
ρ
)

(ψn ◦... ◦ψm−1)([[Q]]m
ρ )

⊑(φn,r ◦ψn ◦. . . ◦ψm−1)

[[P]]m+1
ρ
([[Q]]m
ρ )

by 16.29(a) iterated
= φm,r

[[PQ]]m
ρ

which proves (7).
Example 16.49
Let M ≡xz(yz), and ρ(x) = a, ρ(y) = b, ρ(z) = c.
Then Lemma 16.48(a) implies that
a • c • (b • c) =

n≥0
φn,∞

an+2(cn+1)(bn+1(cn))

.

16E D∞is a λ-model
267
16E
D∞is a λ-model
To prove that D∞is a λ-model, it is quickest to ﬁrst show that it is an
extensional combinatory algebra and then use Theorem 15.30.
Deﬁnition 16.50 Using the kn from Exercise 16.30, deﬁne
k = ⟨⊥0, ID0 , k2, k3, k4, . . . ⟩.
Lemma 16.51 The above k is a member of D∞. And, for all a, b ∈D∞,
k • a • b = a.
Proof First, k satisﬁes the conditions in 16.34 for membership of D∞,
by 16.30. Next, we apply 16.48(b) to M ≡uxy and ρ(u) = k, ρ(x) = a,
ρ(y) = b. This gives
(k • a • b)r =

n≥r
φn,r

kn+2(an+1)(bn)

by 16.48(b)
=

n≥r
φn,r

ψn(an+1)

by 16.30
= {ar}
by 16.39(a)
= ar
since {ar} is a singleton.
Deﬁnition 16.52 Using the sn from Note 16.31, deﬁne
s = ⟨⊥0, ID0 , ψ2(s3), s3, s4, . . . ⟩.
Lemma 16.53 The above s is a member of D∞. And, for all a, b, c ∈
D∞,
s • a • b • c = a • c • (b • c).
Proof First, s ∈D∞by 16.31. Next, we apply 16.48(b) to M ≡uxyz
and ρ(u) = s, ρ(x) = a, ρ(y) = b, ρ(z) = c. This gives
(s • a • b • c)r =

n≥r
φn,r

sn+3(an+2)(bn+1)(cn)

by 16.48(b)

268
Scott’s D∞and other models
=

n≥r
φn,r

an+2

φn(cn)

bn+1(cn)

by 16.31.
Now φn(cn) = φn(ψn(cn+1)), ⊑cn+1 by 16.28(c), so
(s • a • b • c)r ⊑

n≥r
φn,r

an+2(cn+1)

bn+1(cn)

=

a • c • (b • c)

r
by 16.49.
To complete the lemma, we must prove (s•a•b•c)r ⊒(a•c•(b•c))r. By
above, but taking the l.u.b. for n ≥r + 1 not n ≥r (which is permitted
because the sequence involved is increasing), we have
(s • a • b • c)r
=

n≥r+1
φn,r

an+2

φn(cn)

bn+1(cn)

=

n≥r+1
φn−1,r

ψn−1

an+2(φn(cn))(bn+1(cn))

by def. of φn,r
⊒

n≥r+1
φn−1,r

ψn+1(an+2)

ψn(φn(cn))

ψn(bn+1)(ψn−1(cn))

by 16.29
=

n≥r+1
φn−1,r

an+1(cn)

bn(cn−1)

by 16.28(b) and def. of D∞
= (a • c • (b • c))r
by 16.49 and since

n≥r+1
(. . . (n −1) . . . ) = 
n≥r
(. . . (n) . . . ).
Theorem 16.54 The structure ⟨D∞, •⟩is extensional; i.e. if a • c =
b • c for all c, then a = b.
Proof To prove a = b, it is enough to prove ar+1 = br+1 for all r ≥0.
(This will imply that a0 = b0 too, because a0 = ψ0(a1) = ψ0(b1) = b0.)
Now ar+1 and br+1 are functions, so to prove them equal it is enough to
prove
(∀d ∈Dr)
ar+1(d) = br+1(d).
(8)
Let d ∈Dr; deﬁne c = φr,∞(d), so cn = φr,n(d) for n ≥0. Then
(a • c)r =

n≥r
φn,r

an+1(φr,n(d))

by 16.42.1(b)
= 
n≥r

ψr ◦. . . ◦ψn−2 ◦ψn−1 ◦an+1 ◦φn−1 ◦φn−2 ◦. . . ◦φr

(d)

16E D∞is a λ-model
269
= 
n≥r

ψr ◦. . . ◦ψn−2 ◦(ψn(an+1)) ◦φn−2 ◦. . . ◦φr

(d)
by def. of ψn
= 
n≥r

ψr ◦. . . ◦ψn−2 ◦an ◦φn−2 ◦. . . ◦φr

(d)
since a ∈D∞
= 
n≥r
ar+1(d)
by repeating the above
= ar+1(d).
Similarly (b • c)r = br+1(d). So if a • c = b • c for all c, then ar+1(d) =
br+1(d) for all d ∈Dr. This is (8).
Theorem 16.55 D∞is an extensional λ-model.
Proof By 16.51, 16.53, 16.54 and 15.30.
Now that D∞has been proved to be a λ-model, a few interesting
properties will be stated without proof.
Lemma 16.56 Application in D∞is continuous in both variables; i.e.
(a)
a • ( X) =  
a • b : b ∈X

,
(b)
( X) • b =  
a • b : a ∈X

.
Proof Straightforward. [Bar84, Lemma 1.2.12 and Proposition 18.2.11
(18.3.11 in 1st edn.)].
Theorem 16.57
(a) A function from D∞to D∞is continuous iﬀit is representable
in D∞.
(b) [D∞→D∞] is a c.p.o. and is isomorphic to D∞.
Proof By [Bar84, Theorems 18.2.15 and 18.2.16, or 18.3.15 and 18.3.16
in 1st edn.].
Theorem 16.58 For every c.p.o. D: every φ ∈[D →D] has a ﬁxed-
point (i.e. a member p of D such that φ(p) = p), and the least ﬁxed point
of φ is
pφ =

n≥0
φn(⊥).

270
Scott’s D∞and other models
Proof Straightforward.
Theorem 16.59 For D∞, the operation of ﬁnding the least ﬁxed-point
is ‘representable’ in D∞; in fact if Y is any ﬁxed-point combinator, i.e.
any combinator such that Y x =β x(Y x), then, for all φ ∈[D∞→D∞]
and all f ∈D∞representing φ,
[[Y ]] • f = pφ.
Proof By [Bar84, Section 19.3].
Remark 16.60 It is worth noting that, although the relation ‘D∞|=
M = N’ is a semantic one, it can also be characterized in terms of pure
syntax. The syntactical structures needed to do this are called ‘B¨ohm
trees’ [Bar84, Chapter 10]; they are well beyond the scope of this book,
but here is the characterization theorem anyway.
Theorem 16.61 If M and N are λ-terms, D∞|= M = N iﬀthe B¨ohm
trees of M and N have the same ‘inﬁnite η-normal form’.
Proof By [Bar84, Corollary 19.2.10 (or 19.2.13 in 1st edn.)], based on
the original proofs in [Hyl76] and [Wad76, Wad78].
Remark 16.62
The D∞-construction in this chapter diﬀers slightly
from Scott’s original one, which used complete lattices not c.p.o.s. A
complete lattice is a c.p.o. in which every subset has a l.u.b. (not just
every directed subset), so Scott avoided all problems of proving that
l.u.b.s exist. But c.p.o.s became important in later work on other λ-
models, so they have been introduced and used as the main tool here.
(The c.p.o. approach was ﬁrst advocated by Gordon Plotkin.)
In fact the only diﬀerence between using c.p.o.s and using lattices is
in the starting-set D0.
That set was taken to be IN+ here, but any
other c.p.o. or complete lattice would have done just as well, and the
rest of the construction would not have been aﬀected.
Furthermore,
the proof of Theorem 16.61, which characterizes the set of equations
M = N satisﬁed by D∞, turns out to be independent of D0, so that set
of equations is independent of D0.

16F Other models
271
16F
Some other models
Since D∞was made in 1969, many other ways of building λ-models have
been found. A few will be described brieﬂy after the next deﬁnition.
Deﬁnition 16.63 Two λ-models D1, D2 are called equationally equiv-
alent iﬀthey satisfy the same set of equations M = N (M, N λ-terms).
16.64 The model DA (Engeler)
For any non-empty set A, deﬁne
G(A) to be the smallest set such that
(i) A ⊆G(A),
(ii) if α ⊆G(A) is ﬁnite and m ∈G(A), then (α →m) ∈G(A),
where ‘(α→m)’ denotes any ordered-pair construction (such that
(α→m) ̸∈A).
Deﬁne DA = P(G(A)), the set of all subsets of G(A). Then, for all
a, b ∈DA, deﬁne
a • b
=

m ∈G(A) : (∃ﬁnite β ⊆b) (β →m) ∈a

,
Λ(a)
=

(β →m) : β ﬁnite ⊆G(A) and m ∈a • β

.
Then ⟨DA, •, Λ⟩is a λ-model, by [Lon83, Theorem 2.3]. The terms K,
S and λxy.xy are interpreted in DA thus:
k =

(α→(β →m)) : α, β ﬁnite ⊆G(A) and m ∈α

,
s
=

(α→(β →(γ →m))) : α, β, γ ﬁnite ⊆G(A) and
m ∈α • γ • (β • γ)

,
e
=

(α→(β →m)) : α, β ﬁnite ⊆G(A) and m ∈α • β

.
This DA is the shortest known model-construction, apart from term-
models. It is due to Erwin Engeler [Eng81], though a very similar idea
had occurred earlier to Gordon Plotkin, see [Plo93, Part I Section 2,
written in 1972]. A similar idea had also been invented by Robert Meyer
to build a model of the theory CLw of weak reduction (not equality),
[MBP91, Section 5, ‘Fool’s Model’, dating from about 1973].
Sample properties of DA:
(a) For no set A is DA extensional, [Eng81, Section 2].
(b) DA is equationally equivalent to the B¨ohm tree model mentioned
in 16.67 below, [Lon83, Proposition 2.8].

272
Scott’s D∞and other models
(c) The above deﬁnition of Λ is not the only possible one that makes
⟨DA, •, Λ⟩a λ-model; there exist others which make the resulting
model satisfy diﬀerent sets of equations, [Lon83, Theorem 4.1].
(d) Every applicative structure ⟨B, •⟩can be isomorphically embed-
ded into ⟨DB , •⟩, [Eng81, Section 1].
16.65 The model Pω (Plotkin, Scott)
This model will look at ﬁrst
sight like a special case of DA, with some trivial diﬀerences. But these
diﬀerences will not be as trivial as they seem.
Let Pω be the set of all subsets of IN. Let ⊆be set-inclusion as usual.
For all i, j ∈IN, let ⌈i, j⌉be the number corresponding to the pair ⟨i, j⟩
in some given recursive one-to-one coding of ordered pairs in IN, for
example the coding shown at the end of Note 10.4. Let α0, α1, α2, . . .
be some given recursive enumeration of all the ﬁnite sets of natural
numbers. For each αi and each m ∈IN, the notation ‘(αi →m)’ will be
used for ⌈i, m⌉.
Deﬁne, for a, b ∈Pω,
a • b
=

m ∈IN : (∃αi ⊆b)

(αi →m) ∈a

,
Λ(a)
=

(αi →m) : m ∈a • αi

.
The construction-details can be found in [Bar84, Section 18.1 (18.2
in 1st edn.)]. Proofs of basic properties, including that ⟨Pω, •, Λ⟩is a
λ-model, are in [Bar84, Sections 19.1 and 19.3] and [Sco76].
Sample properties:
(a) Pω is not extensional [Sco76, Theorem 1.2(iii)].
(b) Pω is equationally equivalent to the B¨ohm tree model mentioned
in 16.67 below [Bar84, Corollary 19.1.19(ii)].
(c) Pω is a complete lattice.
Also [Pω →Pω] = (Pω →Pω)rep
[Bar84, Corollary 18.2.8 (18.1.8 in 1st edn.)].
(d) Each of the combinatory algebras ⟨Pω, •⟩and ⟨DA, •⟩can be
isomorphically embedded into the other (if A is countable), but
they are not isomorphic [Lon83, Propositions 4.7, 4.10].
Other properties of Pω can be found in [San79], [BL84, Section 2],
[LM84], and [Koy84]. This model was chosen by Stoy to be the basis of
his textbook on denotational semantics, [Sto77].
Warning: Pω is really a set of models, not just a single model. In fact,
diﬀerent codings ⌈i, m⌉and enumerations α0, α1, α2, . . . give diﬀerent

16F Other models
273
versions of Pω, which all have the above properties, but may diﬀer
interestingly in some other ways; see [BB79] or [Bar84, Exercise 19.4.7].
Models built by the Pω method are called graph models.1
16.66 Filter models (Coppo, Dezani and collaborators)
Types
are usually introduced into λ-calculus to restrict the set of terms which
can be formed, so models of typed λ are in principle simpler to build
than models of untyped λ.
But there is an alternative type-system,
that of intersection types, from which a wide variety of models can be
constructed, called ﬁlter models. And these are models of untyped λ,
although derived from a type-system. The ﬁrst explicit description of
a ﬁlter model was in [BCD83]. But also D∞can be viewed as a ﬁlter
model, see [ADH04, Theorem 6]. For some introductions to intersec-
tion types, see the reading list at the end of Chapter 12 of the present
book; some constructions and studies of ﬁlter models can be found in
[CDHL84], [CDZ87] and [ABD06].
16.67 Some other models
Term models: for each formal theory whose axioms and rules include
those of λβ, the corresponding term model, deﬁned as in 15.16, is a
λ-model.
Barendregt’s B¨ohm-tree model B has trees of syntactical expressions
as its members. (Not all these trees are ﬁnite.) Its construction and
basic properties are described in [Bar84, Section 18.3 (18.4 in 1st edn.)].
One of these properties is
B |= M = N
⇐⇒
M has the same B¨ohm tree as N.
Plotkin’s model T ω was described in [Plo78]. Its properties are similar
to Pω, but it is not a lattice. In [BL80] it is proved to be equationally
equivalent to the B¨ohm tree model, and hence to Pω and DA.
Sanchis’ hypergraph structure is a development of the Pω construc-
tion, see [San79]. It is an interesting example of a combinatory algebra
which is not a λ-model; the latter fact was proved in [Koy84, Chapter
4].
J. Zashev has described two general procedures for generating com-
binatory algebras; see [Zas01, pp. 1733–1734, and comments in Section
5]. He points out that some of these algebras are λ-models, one being
1 By (b) above, all graph models are equationally equivalent.
But this does not
imply that they are isomorphic or even have the same cardinality; there are many
diﬀerences between mathematical structures that cannot be expressed in the lan-
guage of λβ.

274
Scott’s D∞and other models
closely related to Pω, and refers to work of D. Skordev dating back to
1976.
Remark 16.68 (Other approaches to model-building)
Roughly
speaking, in building a λ-model the main problem has been to create a
structure ⟨D, •⟩such that the members of D behave like functions, and
yet a • b is deﬁned for all a, b ∈D. However, there are also some other
approaches to the semantics of λ and CL.
(1) One could change the set-theory in which models are deﬁned and
built. The usual Zermelo–Fraenkel set theory has an axiom of foundation
which prevents self-memberships a ∈a and inﬁnite descending ∈-chains
{an+1 ∈an : n ≥1} from existing. In a non-well-founded set theory
this axiom is altered, such chains can exist, and one can build λ-models
⟨D, •⟩whose members are genuine functions and whose • is genuine
function-application. This was ﬁrst proposed and done by von Rimscha,
[Rim80].
Some comments on non-well-founded models are in [Plo93,
pp. 375–377], and a readable general account of non-well-founded set
theories is the short book [Acz88].
(2) One could abandon the requirement that a • b be deﬁned for all a
and b. This results in structures that may be called partial models. Two
examples are:
(a) Uniformly reﬂexive structures (u.r.s.s). These are models of a
certain axiomatized abstract theory of partial recursive functions.
The simplest u.r.s. is the set IN with a•b deﬁned as {a}(b), where
{a} is the partial recursive function whose G¨odel number is a.
If {a}(b) has no output-value, then a • b is not deﬁned, so the
model is not ‘total’. The u.r.s. concept ﬁrst appeared in [Str68]
and [Wag69], and was also studied in [Fri71, Bye82a, Bye82b] and
the references in them.
(b) Models of typed λ-calculi. As mentioned at the end of Chapter 15,
this concept of model ﬁrst appeared in [Hen50, pp. 83–84]. In it,
a•b is only deﬁned when the types of a and b are suitably related,
otherwise the concept is like that of model of untyped λ.
(3) One could build a model of a theory of reduction instead of equal-
ity. Examples are the ‘Fool’s Model’ in [MBP91, Section 5] for CLw,
and the similar model in [Plo94, Section 4] for λβ.
(4) Another alternative approach originated in the ﬁeld of algebraic
logic: lambda abstraction algebras are related to λ-calculus like boolean
algebras are related to propositional logic, and cylindric and polyadic

16F Other models
275
algebras to predicate logic (roughly speaking). They are described in
[PS95] and [PS98]; also [Sal00] contains a useful short survey (besides
some original results).
Further reading
Chapters 5 and 18–20 of [Bar84] give a more advanced treatment of λ-
models than the present book. Chapter 5 covers the various deﬁnitions
of the model concept; Chapter 18 describes the constructions of Pω, D∞
and the B¨ohm-tree model; Chapter 19 gives some of their key structural
properties, and Chapter 20 looks at a few general properties of models.
For D∞, the relevant passages of [Bar84] are Sections 1.2, 5.4, 18.2,
19.2–3 and parts of Chapter 20. Analyses of the structure of D∞are
included in [Hyl76] and [Wad76, Wad78]. Also [Sco76] is partly about
D∞. Of Scott’s original accounts of D∞, the earliest were only hand-
written and copies are hard to ﬁnd, but those published include [Sco70b],
[Sco72], [Sco73], [Sco80a], [Sco82a] and [Sco82b].
For Pω, the relevant passages of [Bar84] are Sections 18.1, 19.1, 19.3,
and parts of Chapter 20. For discussion and motivation besides technical
results, [Sco76] is still of interest.
Plotkin’s original 1972 proposal for a model like DA was eventually
published in [Plo93, Part I]. A later discussion of DA and Pω and similar
models is in [Plo93, Part II].
For more recent work on graph models two very useful sources are the
survey papers [Ber00] and [Ber05], and the substantial bibliographies
they contain.
Part of the motivation for building λ-models lay in denotational se-
mantics, the approach to the semantics of programming languages which
was ﬁrst proposed in the 1960s by Christopher Strachey in Oxford. The
invention of D∞and Pω turned this subject into a major branch of com-
puter science. The handbook article [Mos90] is a suitable introduction,
and other introductions are in the textbooks [Gun92] and [Win01], as
well as the older book [Sto77] by one of the subject’s pioneers.
In the ﬁeld of mathematics, the ideas involved in D∞also gave rise
to a new subject, domain theory. Introductions to this subject can be
found in [Gun92], [Rey98] and [Win01], and more technical accounts can
be found in, for example, [AJ94] and [GHK+03].

Appendix A1
Bound variables and α-conversion
In Chapter 1 the technicalities of bound variables, substitution and α-
conversion were merely outlined. This is the best approach at the be-
ginning. Indeed, most accounts of λ omit details of these, and simply
assume that clashes between bound and free variables can always be
avoided without problems; see, for example, the ‘variable convention’ in
[Bar84, Section 2.1.13]. The purpose of this appendix is to show how
that assumption can be justiﬁed.
Before starting, it is worth mentioning two points.
First, there is
a notation for λ-calculus that avoids bound variables completely.
It
was invented by N. G. de Bruijn, see [Bru72], and in it each bound
variable-occurrence is replaced by a number showing its ‘distance’ from
its binding λ, in a certain sense. De Bruijn’s notation has been found
useful when coding λ-terms for machine manipulation; examples are in
[Alt93, Hue94, KR95]. But, as remarked in [Pol93, pp. 314–315], it does
not lead to a particularly simple deﬁnition of substitution, and most
human workers still ﬁnd the classical notation easier to read.
For such workers, the details of α-conversion would not be avoided
by de Bruijn’s notation, but would simply be moved from the stage of
manipulating terms to that of translating between the two notations.
The second point to note is shown by the following two examples: if
we simply deleted ≡α from the rules of λ-calculus, we would lose the
conﬂuence of both ▷βη and ▷β. Thus there is no way to entirely avoid
dealing with ≡α in the standard λ-notation.
Example A1.1
Let P ≡λx.((λy.y)x). Then P is an η-redex and
contains a β-redex (λy.y)x, and
P ▷1η λy.y,
P ▷1β λx.x,
and without ≡α these cannot be reduced to the same term.
Example A1.2
Let P ≡(λx.(λy.yx))Q, where Q ≡(λu.v)y. Then
Q is a β-redex and Q ▷1β v, so
276

α-conversion
277
P
▷1β
(λx.(λy.yx))v
▷1β
[v/x] (λy.yx)
≡
λy.yv.
Also P is a β-redex, and
P
▷1β
[Q/x] (λy.yx)
≡
λz. [Q/x][z/y] (yx) by Chapter 1’s 1.12(g),
≡
λz.zQ
where z ̸∈FV (Q(yx)) so z ̸≡y,
▷1β
λz.zv.
Without ≡α, we cannot reduce λy.yv and λz.zv to the same term, so
≡α cannot be avoided if we want conﬂuence. (Also changes of bound
variables cannot be avoided if we want the deﬁnition of substitution to
be as general as possible.)
Exercise A1.3
By the way, the term P in the above example is not
a λI-term; show that in the λI-calculus the following (typable) term
P ′ could serve instead. Let u, v, x, y (in that order) be the ﬁrst four
variables of the language of λ-calculus, and deﬁne
P ′ ≡(λx.S)v,
where
S ≡(λyv.uvy)x.
(Show, using Chapter 1’s 1.12(g) carefully, that P ′ β-reduces without
α-steps to both λy.uyv and λx.uxv.)
Hence a rigorous treatment of λ-calculus in the usual notation must
include α-conversion. To do this rigorously, the commonest approach is
to say that λ-calculus is not really about λ-terms, but about equivalence-
classes of λ-terms under the relation of congruence (≡α). The individ-
ual terms are then viewed as representatives of their classes, and a proof
must be given that they may be replaced by other representatives when-
ever necessary.
The goal of the present appendix is to justify this ‘congruence-class’
approach. The main lemmas will be stated here, but their proofs will
merely be sketched, as they are straightforward and boring. (Full details
have been worked out in several unpublished theses, for example [Sch65,
Part II, Chapter 3] and [Hin64, Chapter 4]; and other careful treatments
of ≡α, with discussions, are in [Pol93] and [VB03].)
The ﬁrst move will be to deﬁne a simpler basic α-conversion step, and
prove that it generates the same relation ≡α as the original one.

278
α-conversion
Deﬁnition A1.4 (α0-contraction, reduction, etc.)
We say that
P α0-contracts to Q, or P ▷1α0 Q, iﬀP can be changed to Q by replacing
an occurrence of a term λx.M by λy.[y/x]M, where y ̸∈FV (xM) and
neither x nor y is bound in M.
We say P α0-reduces to Q, or P ▷α0 Q, iﬀP can be changed to Q by a
ﬁnite (perhaps empty) series of such contractions, and P α0-converts to
Q, or P ≡α0 Q, iﬀP can be changed to Q by a ﬁnite (perhaps empty)
series of α0-contractions and reversed α0-contractions.
Lemma A1.5 If y ̸∈FV (xM) and x, y are not bound in M, then:
(a) [y/x]M is obtained by simply changing x to y throughout M;
(b) x ̸∈FV ([y/x]M), x ̸≡y, and x, y are not bound in [y/x]M;
(c) [x/y][y/x]M ≡M;
(d) λy.[y/x]M ▷1α0 λx.M, so the relation ▷1α0 is symmetric;
(e) P ≡α0 Q ⇐⇒P ▷α0 Q;
(f) P ≡α0 Q =⇒FV (P) = FV (Q);
(g) for all P, x1, . . . , xn, there exists P ′ such that P ▷α0 P ′ and none
of x1, . . . , xn is bound in P ′.
Proof For (a): the conditions on x and y imply that the deﬁnition of
[y/x]M does not use Chapter 1’s 1.12(g), (d).
For (b): use (a) and
the conditions on x and y. For (c): use (a) with x, y reversed (which
holds by (b)), combined with (a). For (d): we have λy.[y/x]M ▷1α0
λx.[x/y][y/x]M by (b), and [x/y][y/x]M ≡M by (c). For (e): use (d).
For (f) and (g): use (a).
Deﬁnition A1.6 (α-contraction)
We say P α-contracts to Q, or
P ▷1α Q, iﬀP can be changed to Q by replacing an occurrence of a term
λx.M by λy.[y/x]M, where y ̸∈FV (M).
The relation ≡α was deﬁned by a ﬁnite series of α-contractions, in
Chapter 1’s Deﬁnition 1.17.
In that deﬁnition of ≡α, reversed contractions were not mentioned, so
the symmetry of ≡α was not immediately obvious, and had to be stated
as a separate lemma, Chapter 1’s Lemma 1.19. The proof of that lemma
was omitted. The ﬁrst application of α0 will be to ﬁll in that gap by
proving the equivalence of ≡α and ≡α0 ; see Lemma A1.8 below.

α-conversion
279
Lemma A1.7
For all M, x and y ̸∈FV (xM), there exists M ′ such
that y is neither free nor bound in M ′ and x is not bound in M ′, and
M ▷α0 M ′,
[y/x]M ▷α0 [y/x]M ′.
Proof
By induction on M (i.e. on the length of M), with cases as in
the deﬁnition of [y/x]M.
Lemma A1.8
Every α-contraction can be done by a series of α0-
contractions. Hence by A1.5(e) the relations ≡α, ≡α0 , ▷α0 are the same.
Proof If y ̸∈FV (xM), then, for the M ′ in A1.7, we get λx.M▷α0 λx.M ′,
which ▷1α0 λy.[y/x]M ′, which ▷α0 λy.[y/x]M by A1.7, A1.5(e).
Exercise A1.9∗Lemma A1.8 implies that an α-contraction can always
be reversed by a series of further α-contractions. Show that it cannot
always be reversed by a single α-contraction (contrary to a claim in
[CF58, bottom of p. 91]).
Now, which of the lemmas in Chapter 1’s Section 1B need to be proved
in this appendix? The ﬁrst two, 1.15 and 1.16, do not mention or depend
on ≡α. The next, 1.19, has just been proved above. Lemma 1.20 rests on
a proof in [CF58, p. 95, Section 3E Theorem 2(c)]; that proof is adequate
without the present appendix, although the use of α0 instead of α might
simplify it a little. Finally, Lemma 1.21, which says substitution is ‘well-
behaved’ with respect to ≡α, comes from the following lemma.
Lemma A1.10
(a) M ≡α M ′ =⇒[N/x]M ≡α [N/x]M ′;
(b) N ≡α N ′ =⇒[N/x]M ≡α [N ′/x]M.
Proof
For (a): use [CF58, Theorem 2(a) p. 95, proof on pp. 96–103].
For (b): by Lemma A1.5(g), change M to a term M ′ whose bound
variables do not occur in NN ′. Then Chapter 1’s 1.12(g) is not used
in [N/x]M ′ or [N ′/x]M ′, so it is easy to prove [N/x]M ′ ≡α [N ′/x]M ′.
Then use (a).
The next four lemmas are needed in the proof of the Church-Rosser
theorem, see Appendix A2. They connect β-redexes, ≡α and substitu-
tion.

280
α-conversion
Notation A1.11 The notation Γ(R) will be used in the next lemmas
for the contractum of an arbitrary redex R.
So, for a β-redex R ≡
(λx.M)N we shall say Γ(R) ≡[N/x]M, and for an η-redex R ≡λx.Mx
we shall say Γ(R) ≡M.
Lemma A1.12 If R is a β-redex and no variable free in xN is bound
in R, then [N/x]R is a β-redex and
Γ([N/x]R) ≡α [N/x](Γ(R)).
Proof Let R ≡(λv.U)V . Then Γ(R) ≡[V/v]U. By assumption, v ̸∈
FV (xN), so, by Chapter 1’s 1.12,
[N/x]R ≡(λv.[N/x]U) [N/x]V.
Hence
Γ([N/x]R) ≡
[ ([N/x]V )/v ] [N/x] U
≡α [N/x] [V/v] U
by Chapter 1’s 1.16(c), 1.20.
Lemma A1.13 If R ≡α R′ and R is a β-redex, then so is R′ and
Γ(R) ≡α Γ(R′).
Proof By A1.8 we can assume R goes to R′ by one replacement λx.M
▷1α0 λy.[y/x]M. Let R ≡(λv.U)V . If λx.M is in U or V , use A1.10.
If λx.M ≡λv.U, the result comes from Chapter 1’s 1.16(a) and 1.20.
Lemma A1.14
Let P ≡α P ′. Let P contain occurrences R1, . . . , Rn
of some β-redexes. Then P ′ contains β-redex-occurrences R′
1, . . . , R′
n,
such that, for all i, j ≤n,
(a) R′
i, R′
j are related (one inside the other, or non-overlapping, or
identical) exactly as Ri, Rj are related;
(b) if contracting Ri changes P to Pi, then contracting R′
i changes
P ′ to a term P ′
i ≡α Pi.
Proof
Let P ▷1α0 P ′ by replacing λx.M by λy.[y/x]M. For those Ri
containing λx.M, use A1.13. For those in M, use A1.12 with N ≡y.

α-conversion
281
Corollary A1.14.1 (Postponement of α-conversions) If P ▷β Q by
k β-contractions with possibly some α-conversions between, then there
exista a term Q′ such that P ▷β Q′ by k β-steps with no α-steps between,
and Q′ ≡α Q.
Proof By A1.14(b), case i = 1, used at most k times.
By the way, Lemma A1.14 does not claim that R′
i ≡α Ri. For example,
let
P ≡λx.(λu.ux)v,
P ′ ≡λy.(λu.uy)v,
R1 ≡(λu.ux)v.
Then R′
1 ≡(λu.uy)v, ̸≡α R1.
Lemma A1.15 If P ▷β P ′ and Q ▷β Q′, then [P/x]Q ▷β [P ′/x]Q′.
Proof It is enough to prove the result when P ▷1β P ′ or P ≡α P ′, and
Q ▷1β Q′ or Q ≡α Q′. We show here only the least easy case.
If P ▷1β P ′ and Q ▷1β Q′, ﬁrst α-convert Q to a term Q⋆in which no
variable free in xP is bound. Then Chapter 1’s 1.12(g) is not used in
[P/x]Q⋆, and, by Chapter 1’s 1.30, the same holds for [P ′/x]Q⋆. Hence
[P/x]Q⋆▷β [P ′/x]Q⋆by simply reducing the substituted occurrences of
P, so, by A1.10,
[P/x]Q ≡α [P/x]Q⋆▷β [P ′/x]Q⋆.
But by A1.14.1 with n = 1, Q⋆▷β Q′ by one β-step followed by α-steps,
so A1.12 and A1.10 give
[P ′/x]Q⋆▷β [P ′/x]Q′.
The other three cases, in which P ≡α P ′ or Q ≡α Q′, are easier.
Analogues of A1.12–A1.15 also hold for ▷η, with easier proofs.

Appendix A2
Conﬂuence proofs
Deﬁnition A2.1 (See Figure A2:1 below.) A binary relation ▷between
λ-terms or CL-terms is said to be conﬂuent iﬀ, for all terms P, M, N,
P ▷M and P ▷N
=⇒
(∃term T) M ▷T and N ▷T.
(1)
t
P
t
M
t
N
d
∃T



=
ZZZ
~
Z
Z
~


=
Fig. A2:1
A2A
Conﬂuence of β-reduction
This section will present a proof of Theorem 1.32 in Chapter 1, which
stated that ▷β in λ-calculus is conﬂuent. The ﬁrst conﬂuence-proof for
▷β was made by Alonzo Church and his student Barkley Rosser in 1935
[CR36, Section 1], but was not particularly simple.
A much simpler
proof was made in 1971 by Per Martin-L¨of using a method originated
by William Tait in 1965. The proof below will be based on this method
and will try to show the principles behind it that make it work. (Other
accounts of the Tait–Martin-L¨of method can be found in [Bar84, Theo-
rem 3.2.8] or [Tak95, Section 1].)
The next section will give outline proofs of conﬂuence for ▷w in CL
and several other reducibility relations, by variants of the same method.
Notation A2.2 Recall from Chapter 3’s Deﬁnition 3.15 that a β-reduc-
tion in λ is a series (perhaps empty or inﬁnite) of β- and α-contractions,
and its length is the number of its β-contractions (perhaps 0 or ∞).
282

A2A β-reduction
283
By Appendix A1’s Lemma A1.8, we can assume all α-contractions in
a reduction are α0-contractions.
In the present appendix, redex always means a particular occurrence
of a redex in a given term. For example, ‘Let R, S be redexes in P’
means ‘Let R, S be occurrences of redexes in P’. For occurrence, see
the note after Chapter 1’s Deﬁnition 1.7.
u
P
u
M
tN1
d
∃T ′
tN2
d
∃T ′′
s q
r qr qr uN
e
∃T
q q q




@
@
@
R
@
@
@
R
@
@
@@
R
@@
R



@@
R


 

 


pppppppppp
pppp
ppppppp
pppppppppppppp
R
u
P
u
M
uN
c
∃T1
d
∃T
s
s
s
M1
s
s
qqqq
qqq
q






@
@
@
@@
R
@
@
@
@
@
R
@
@
@@
R
@
@
@@
R
ppppppppppppp
pppppppppppppppppppp
R
pppppppppppppppppp
Fig. A2:2
Discussion A2.3 (Strategy for proving conﬂuence) We might hope
to prove ▷β conﬂuent by proving the one-step relation ▷1β conﬂuent, i.e.
P ▷1β M, P ▷1β N
=⇒
(∃T) M ▷1β T, N ▷1β T.
(2)
If (2) held, we could deduce (1) by the method sketched in Figure A2:2:
we could ﬁrst prove (1) in the special case that P ▷1β M, by induction
on the length of the reduction from P to N as shown in the left-hand
diagram in Figure A2:2; and we could then deduce the general case by
induction on the length of the reduction from P to M as in the right-
hand part of Figure A2:2.
Unfortunately (2) is not always true. For example, let
P ≡(λy.uyy)(Iz)
(where I ≡(λx.x));
then P ▷1β u(Iz)(Iz) and P ▷1β (λy.uyy)z, and (λy.uyy)z ▷1β uzz, but
u(Iz)(Iz) cannot be reduced to uzz in just one step.
But u(Iz)(Iz) can be reduced to uzz by two non-overlapping steps ‘in
parallel’. So our second hope might be to deﬁne a concept of ‘parallel

284
Conﬂuence proofs
β-reduction’ ▷1par, and prove
P ▷1par M, P ▷1par N
=⇒
(∃T) M ▷1par T, N ▷1par T.
(3)
If ‘parallel’ was deﬁned in such a way that every single contraction was
a special case of a parallel reduction, then the conﬂuence of ▷β would
follow from (3) by the method of Figure A2.2.
Unfortunately the obvious deﬁnition, that a parallel reduction consists
of simultaneous non-overlapping contractions, does not satisfy (3).
Exercise A2.4 ∗
Prove the last sentence above; i.e. ﬁnd P, M, N
for which (3) would fail if ‘parallel’ was deﬁned by simultaneous non-
overlapping contractions.
However, there is a more subtle deﬁnition of ‘parallel’ which does
satisfy (3); it will be given in the next two deﬁnitions, and (3) will be
proved in Lemma A2.10. This will prove the conﬂuence of ▷β.
Deﬁnition A2.5 (Residuals)
Let a λ-term P contain β-redexes R
and S. When R is contracted, let P change to P ′. The residuals of S
with respect to R are redexes in P ′, deﬁned as follows (from [CR36, pp.
473–475]).
Case 1: R, S are non-overlapping parts of P. Then contracting R
leaves S unchanged. We call the unchanged S in P ′ the residual of S.
Case 2: R ≡S. Then contracting R is the same as contracting S.
We say S has no residual in P ′.
Case 3: R is a proper part of S, i.e. R is a part of S and R ̸≡S. Then
S has form (λx.M)N and R is in M or in N. Contracting R changes M
to a term M ′, or N to N ′. This changes S to (λx.M ′)N or (λx.M)N ′
in P ′; we call this the residual of S.
Case 4:1 S is a proper part of R. Then R has form (λx.M)N and S
is in M or in N.
Subcase 4a: S is in M. When [N/x]M is formed from M, then S is
changed to a redex S′ with one of the forms
[N/x]S,
[N/x][z1/y1] . . . [zn/yn]S,
S,
depending on how many times Chapter 1’s clause 1.12(g) is used in
1 Case 4 is not needed in the conﬂuence proof. It is included here only because it is
often used in other studies of reductions.

A2A β-reduction
285
making [N/x]M, and on whether S is in the scope of a λx in M. We
call this S′ the residual of S.
Subcase 4b: S is in N. When [N/x]M is made, there is an occurrence
of S in each substituted N. We call these the residuals of S. (If there
are k ≥0 free occurrences of x in M, then S will have k residuals.)
Deﬁnition A2.6 (Parallel reductions)
Let R1, . . . , Rn (n ≥0) be
redexes in a λ-term P.
An Ri is called minimal in {R1, . . . , Rn} iﬀ
none of R1, . . . , Rn is a proper part of Ri.
A parallel reduction of
{R1, . . . , Rn} in P is a reduction obtained by ﬁrst contracting a minimal
Ri, then a minimal residual of R1, . . . , Rn, and continuing to contract
minimal residuals until no residuals are left, and ﬁnally perhaps doing
some α-conversions. Iﬀa parallel reduction changes P to a term Q, we
say
P ▷1par Q.
Note A2.7 Every non-empty set of redexes in a λ-term has a minimal
member (and possibly more than one). Hence every set of redexes in
a λ-term has at least one parallel reduction. The following are easy to
prove.
(a) A parallel reduction of an n-member set has length exactly n.
(Since the contracted redexes are minimal, only Cases 1–3 of Def-
inition A2.5 apply in determining residuals, so each redex has at
most one residual; hence there are n −1 residuals after the ﬁrst
step, n −2 after the second, etc.)
(b) A parallel reduction of a one-member set of redexes consists of
a single contraction (perhaps followed by some α-steps). Con-
versely, every one-step reduction is a parallel reduction of a one-
member set.
(c) A parallel reduction of the empty set is just a (perhaps empty) se-
ries of α-conversions. Conversely, every α-conversion is a parallel
reduction of the empty set.
(d) An example of a non-parallel reduction is the following; the redex
contracted at the second step is not a residual of any redex in P.
P
≡(λx.xy)(λz.z) ▷1β (λz.z)y
▷1β
y
≡
Q.

286
Conﬂuence proofs
(e) The relation ▷1par is not transitive. For example, in (d) the two
contractions count as two parallel reductions by (b), but there is
not a single parallel reduction from P to Q.
(f) If M ▷1par M ′ and N ▷1par N ′, then MN ▷1par M ′N ′.
(g) If M ▷1par M ′, then λx.M ▷1par λx.M ′.
Lemma A2.8 (Preservation of parallel reductions by ≡α) For
λ-terms and β-reduction:
P ▷1par Q and P ≡α P ′
=⇒
P ′ ▷1par Q.
Proof By induction on the length of the reduction from P to Q, using
Lemma A1.14 in the induction step. (See also A1.14.1.)
Lemma A2.9 (Preservation of parallel reductions by substitu-
tion) For λ-terms and β-reduction:
M ▷1par M ′ and N ▷1par N ′
=⇒
[N/x]M ▷1par [N ′/x]M ′.
Proof By Lemma A2.8 above, and Appendix A1’s Lemma A1.5(g), we
may assume that no variable bound in M is free in xNM, and that the
given reductions of M and N have no α-steps.
We proceed by induction on M. Let M ▷1parM ′ by a parallel reduction
of redexes R1, . . . , Rn in M.
Case 1: M ≡x. Then n must be 0, so M ′ ≡M ≡x. Hence
[N/x]M ≡N ▷1par N ′ ≡[N ′/x]M ′.
Case 2: x ̸∈FV (M). Then x ̸∈FV (M ′) by Chapter 1’s Lemma 1.30,
so
[N/x]M ≡M ▷1par M ′ ≡[N ′/x]M ′.
Case 3: M ≡λy.M1 and y ̸≡x and x ∈FV (M1). Then each β-redex in
M is in M1. We have assumed the given reduction of M has no α-steps,
so M ′ must have form λy.M ′
1 where M1 ▷1par M ′
1. Hence
[N/x]M
≡
[N/x](λy.M1)
≡
λy.[N/x]M1
by Ch. 1’s 1.12(f) since y ̸∈FV (N),
▷1par λy.[N ′/x]M ′
1
by induction hypothesis,
≡
[N ′/x]M ′
by Ch. 1’s 1.12(e), (f)
since y ̸∈FV (N ′) by Ch. 1’s 1.30.

A2A β-reduction
287
Case 4: M ≡M1M2 and each Ri is in M1 or in M2. Then M ′ has form
M ′
1M ′
2 where Mj ▷1par M ′
j for j = 1, 2. Hence
[N/x]M
≡
([N/x]M1)([N/x]M2)
▷1par ([N ′/x]M ′
1)([N ′/x]M ′
2) by ind. hyp. and A2.7(f),
≡
[N ′/x]M ′.
Case 5: M ≡(λy.L)Q and one Ri, say R1, is M itself and the others
are in L or Q. Then R1 contains R2, . . . , Rn, so, by the deﬁnition of
‘parallel reduction’, its residual must be contracted last in the given
parallel reduction of M. Hence this reduction has form
M ≡(λy.L)Q ▷1par (λy.L′)Q′
(L ▷1par L′, Q ▷1par Q′)
▷1β
[Q′/y]L′
≡
M ′.
By the induction hypothesis there exist parallel reductions of [N/x]L
and [N/x]Q; each one may have some α-steps at the end, say
[N/x]L ▷1par L⋆
≡α [N ′/x]L′,
[N/x]Q ▷1par Q⋆
≡α [N ′/x]Q′,
where the reductions to L⋆and Q⋆have no α-steps. Hence
[N/x]M ≡
(λy.[N/x]L)([N/x]Q)
by Ch. 1’s 1.12(c), (f)
since y ̸∈FV (xN),
▷1par (λy.L⋆)Q⋆
without α-steps,
▷1β
[Q⋆/y]L⋆
≡α
[([N ′/x]Q′)/y][N ′/x]L′ by above and Ch. 1’s 1.21,
≡α
[N ′/x][Q′/y]L′
by Ch. 1’s 1.16(c), 1.20, since
y ̸∈FV (xNM) ⊇FV (xN ′Q′),
≡
[N ′/x]M ′.
The above reduction is a parallel reduction, as required.
Lemma A2.10 (Conﬂuence of parallel reductions) For λ-terms
and β-reduction:
P ▷1par A,
P ▷1par B
=⇒
(∃T) A ▷1par T,
B ▷1par T.
Proof
By Lemma A2.8 above, we may assume that the two given re-
ductions of P have no α-steps. We shall use induction on P.
Case 1: P ≡x. Then A ≡B ≡P. Choose T ≡P.

288
Conﬂuence proofs
Case 2: P ≡λx.P1. Then all β-redexes in P are in P1, and we have
assumed the given reductions have no α-steps, so
A ≡λx.A1,
B ≡λx.B1,
where P1 ▷1par A1 and P1 ▷1par B1. By the induction-hypothesis there
exists T1 such that
A1 ▷1par T1,
B1 ▷1par T1.
Choose T ≡λx.T1.
Case 3: P ≡P1P2 and all the redexes involved in the parallel reductions
are in P1, P2. Then the induction-hypothesis gives us T1 and T2; choose
T ≡T1T2.
Case 4: P ≡(λx.M)N and just one of the given parallel reductions
involves contracting P’s residual; say it is P ▷1par A. Then that reduction
has form
P
≡
(λx.M)N
▷1par (λx.M ′)N ′
(M ▷1par M ′, N ▷1par N ′)
▷1β
[N ′/x]M ′
≡
A.
And the other given parallel reduction has form
P
≡
(λx.M)N
▷1par (λx.M ′′)N ′′
(M ▷1par M ′′, N ▷1par N ′′)
≡
B.
The induction-hypothesis applied to M, N gives us M +, N + such that
M ′ ▷1par M +,
M ′′ ▷1par M +;
N ′ ▷1par N +,
N ′′ ▷1par N +.
Choose T ≡[N +/x]M +. Then there is a parallel reduction from A to
T, thus:
A
≡
[N ′/x]M ′
▷1par [N +/x]M +
by Lemma A2.9.
To construct a parallel reduction from B to T, ﬁrst split the parallel
reductions of M ′′ and N ′′ into β-part and α-part, thus:
M ′′ ▷1par M ⋆≡α M +,
N ′′ ▷1par N ⋆≡α N +,

A2B Other reductions
289
where the reductions to M ⋆and N ⋆have no α-steps. Then
B
≡
(λx.M ′′)N ′′
▷1par (λx.M ⋆)N ⋆
without α-steps
▷1β
[N ⋆/x]M ⋆
≡α
[N +/x]M +
by Chapter 1’s 1.21.
Case 5: P ≡(λx.M)N and both the given parallel reductions involve
contracting P’s residual. Then these reductions have form
P
≡
(λx.M)N
P
≡
(λx.M)N
▷1par (λx.M ′)N ′
▷1par (λx.M ′′)N ′′
▷1β
[N ′/x]M ′
▷1β
[N ′′/x]M ′′
≡
A,
≡
B.
Apply the induction-hypothesis to M and N as in Case 4, and choose
T ≡[N +/x]M +.
Then Lemma A2.9 gives the result, similarly to
Case 4.
Theorem A2.11 (= 1.32, Church-Rosser theorem for ▷β) For
λ-terms, the relation ▷β is conﬂuent; i.e.
P ▷β M, P ▷β N
=⇒
(∃T) M ▷β T, N ▷β T.
Proof By A2.7(c) and (b), each α- or β-step is a special case of a parallel
reduction, so P reduces to M by a ﬁnite series of parallel reductions.
Similarly for N.
Then the method sketched in Discussion A2.3 and
Figure A2:2 gives the result.
A2B
Conﬂuence of other reductions
Theorem A2.12 (= 7.13, Church-Rosser theorem for ▷βη) For
λ-terms, the relation ▷βη introduced in Deﬁnitions 7.7 and 7.8 is con-
ﬂuent; i.e.
P ▷βη M, P ▷βη N
=⇒
(∃T) M ▷βη T, N ▷βη T.
Proof
First, extend Deﬁnition A2.5 (Residuals) to cover η-redexes.
Cases 1 and 2 of that deﬁnition do not change. Case 4 is not needed

290
Conﬂuence proofs
here. (If desired, its details are in [CF58, Section 4B2].) Case 3 changes
as follows.
Case 3η: R is a proper part of S. There are four possible subcases:
3a: S ≡(λx.M)N and R is in M or N. Contracting R changes S to
a term (λx.M ′)N or (λx.M)N ′; we call this the residual of S.
3b: S ≡(λx.M)N and R ≡λx.M.
R must be an η-redex and
M ≡Lx for some L with x ̸∈FV (L). Contracting R changes S
to LN; we say S has no residual.
3c: S ≡λx.Mx and R is in M. Contracting R changes S to λx.M ′x,
for some M ′. And x ̸∈FV (M) =⇒x ̸∈FV (M ′) by Chapter 7’s
Lemma 7.12(a). We call λx.M ′x the residual of S.
3d: S ≡λx.Mx and R is a β-redex ≡Mx. Then M ≡(λy.L) for
some L, and contracting R changes S to λx.[x/y]L; we say S has
no residual.
(In subcases 3b and 3d, it can easily be seen that contracting R pro-
duces the same result as contracting S, modulo ≡α.)
Next, deﬁne parallel reductions exactly as in A2.6.
Then Lemmas A2.8, A2.9 and A2.10 can be extended to βη by adding
extra cases to their proofs. (Exercise: Do this.)
The conﬂuence of ▷βη then follows, as in the proof of A2.11.
By the way, a diﬀerent conﬂuence proof for ▷βη is in [Bar84, Section
3.3].
We now turn from λ to CL.
Theorem A2.13 (= 2.15, Church-Rosser theorem for ▷w in CL)
For CL-terms, the relation ▷w is conﬂuent; i.e.
P ▷w M, P ▷w N
=⇒
(∃T) M ▷w T, N ▷w T.
Proof First, adjust Deﬁnition A2.5 (Residuals) to suit weak redexes in
CL. Cases 1 and 2 do not change. Cases 3 and 4 will both turn out to
be irrelevant to the proof, and can be omitted.2
2 Case 3 is that R is a proper part of S. Then S ≡IX or KXY or SXY Z, and R is
in X, Y or Z. Contracting R changes S to a term S′ with one of the forms IX ′,
KX ′Y , KXY ′, SX ′Y Z, SXY ′Z, SXY Z′, for some X ′, Y ′ or Z′; we can call this
S′ the residual of S.
Case 4 is that R ≡IX or KXY or SXY Z, and S is in X, Y or Z. Contracting R
produces X or X or XZ(Y Z) with obvious corresponding occurrences of S. These
may be called the residuals of S. (If S is in Y in KXY then S has no residual; if
S is in Z in SXY Z then S has two residuals; otherwise S has just one.)

A2B Other reductions
291
Next, deﬁne a parallel reduction in a term P to be a simultaneous
contraction of a set of non-overlapping redexes in P. (This deﬁnition
was too simple to serve in a conﬂuence proof in λ, but it will work in
CL, where there are no bound variables.)
Finally, prove Lemma A2.10 by induction on P. The proof is straight-
forward. (Exercise: write it out.)
(The conﬂuence of ▷w was proved ﬁrst in [Ros35, p. 144 Theorem
T12], also in [CHS72, Section 11B2, Theorem 3].)
Remark A2.14 (Reduction with Z)
In Chapter 4’s Discussion 4.25 and Deﬁnition 4.26, three new atoms
0, σ and Z were added to pure λ and CL, and reducibility relations ▷βZ
(in λ) and ▷wZ (in CL) were deﬁned by adding to the deﬁnitions of ▷β
and ▷w the following contractions (one for each n ≥0):
Z n ▷1 nCh,
where n ≡σ n 0 and nCh is the Church numeral for n. The terms Z0,
Z1, Z2, etc. are called Z-redexes.
Theorem A2.15 (Church-Rosser theorem for reduction with Z)
The relations ▷βZ in λ and ▷wZ in CL are conﬂuent.
Proof (for ▷βZ in λ) First, a Z-redex Z n cannot contain any other Z-
or β-redex.
Extend Deﬁnition A2.5 (Residuals) to cover Z-redexes. Cases 1 and
2 do not change, and Case 4 is not needed in the conﬂuence proof.
Case 3Z: R is a proper part of S. Then S cannot be a Z-redex, so S
≡(λx.M)N and R is in M or N. Contracting R changes S to
a term (λx.M ′)N or (λx.M)N ′; we call this term the residual
of S.
Next, deﬁne parallel reductions exactly as in A2.6. Then Lemmas A2.8,
A2.9 and A2.10 can be extended to Z-redexes by adding some easy extra
cases to their proofs. The conﬂuence of ▷βZ then follows.
The proof for ▷wZ in CL is simpler; just as in the proof of Theorem
A2.13, parallel reductions are simultaneous contractions of sets of non-
overlapping redexes.

292
Conﬂuence proofs
Remark A2.16 (Typed terms)
The conﬂuence proofs in this ap-
pendix are valid also for typed terms.
To prove this, all we need to
check is that if P is a typed term, and a redex R in P is contracted,
then the result is a typed term with the same type as P. With care, this
property can be seen to hold for all the typed systems in Chapter 10.
Note A2.17 (Parallel reductions) Parallel reductions as deﬁned in
A2.6 originated in Curry and Feys’ 1958 book [CF58, Section 4C2], and
they were used in an abstract conﬂuence-proof in [Hin69, p. 547] under
the name ‘minimal complete developments’. They were given a particu-
larly simple inductive deﬁnition by Tait and Martin-L¨of, as mentioned
at the start of this appendix, and were used by Takahashi in [Tak95]
to prove, very neatly, not only conﬂuence but most of the main general
theorems about β- and βη-reductions in λ-calculus. The name ‘parallel
reductions’ is due to Takahashi.
Incidentally, although this fact was not needed for the conﬂuence
proofs above, it is fairly easy to prove that, if P contains β-redexes
R1, . . . , Rn, then all parallel reductions of {R1, . . . , Rn} produce the
same term Q (modulo ≡α).
Indeed, this is true of all complete de-
velopments of {R1, . . . , Rn} (i.e. reductions whose steps are residuals of
{R1, . . . , Rn} and in which all residuals are contracted), although the
proof is not so easy [CF58, pp. 113–130].
Deep results on the structure of reductions are described in [Bar84,
Chapters 3, 11–14]. A summary of a machine-readable formalization of
these and later results is in Huet’s [Hue94].
Further reading Studies of conﬂuence in more abstract settings can
be found in the sources mentioned in Remark 3.25.

Appendix A3
Strong normalization proofs
As we have seen in Chapter 10, the main property of typed systems
not possessed by untyped systems is that all reductions are ﬁnite, and
hence every typed term has a normal form. In this appendix we shall
prove this theorem for the simply typed systems in Chapter 10, and for
an extended system from which the consistency of ﬁrst-order arithmetic
can be deduced.
The proofs will be variations on a method due to W. Tait, [Tai67].
(See also [TS00, Sections 6.8, 6.12.2] or [SU06, Sections 5.3.2–5.3.6].)
Simpler methods are known for pure λ and CL, but Tait’s is the easiest
to extend to more complex type-systems.
We begin with two deﬁnitions which have meaning for any reduction-
concept deﬁned by sequences of replacements. The ﬁrst is a repetition
of Deﬁnition 10.14. The second is the key to Tait’s method.
Deﬁnition A3.1 (Normalizable terms)
A typed or untyped CL-
or λ-term X is called normalizable or weakly normalizable or WN with
respect to a given reduction concept, iﬀit reduces to a normal form. It
is called strongly normalizable (SN ) iﬀall reductions starting at X are
ﬁnite.
As noted in Chapter 10, SN implies WN. Also the concept of SN
involves the distinction between ﬁnite and inﬁnite reductions, whereas
WN does not, so SN is a fundamentally more complex concept than WN.
Deﬁnition A3.2 (Computable terms)
For simply typed CL- or
λ-terms, the concept of strongly computable (SC) term is deﬁned by
induction on the number of occurrences of ‘→’ in the term’s type:
(a) a term of atomic type is SC iﬀit is SN;
(b) a term Xρ→σ is SC iﬀ, for every SC term Y ρ, the term (XY )σ is
SC.
Weakly computable (WC) is deﬁned similarly, with ‘WN’ instead of ‘SN’
in (a). (WC terms are usually called just computable.)
293

294
Normalization proofs
A3A
Simply typed λ-calculus
In this section, types are the simple types of Deﬁnition 10.1, and terms
are simply-typed λ-terms as deﬁned in 10.5.
Theorem A3.3 (SN for λβ →, cf. Theorem 10.15) In the simply
typed λ-calculus, there are no inﬁnite β-reductions.
Proof The theorem says that all terms are SN (with respect to ▷β). We
shall prove that
(a)
every SC term is SN,
(b)
every term is SC.
The actual proof will consist of six simple notes and three lemmas, and
the last lemma will be equivalent to the theorem.
Note A3.4 Each type τ can be written in a unique way in the form
τ1 →. . . →τn →θ, where θ is atomic and n ≥0.
Note A3.5 It follows immediately from Deﬁnition A3.2(b) that if
τ ≡τ1 →. . . →τn →θ
where θ is atomic, then a term Xτ is SC iﬀ, for all SC terms
Y τ1
1 , . . . , Y τn
n ,
the term (XY1 . . . Yn)θ is SC. And it follows from Deﬁnition A3.2(a)
that (XY1 . . . Yn)θ is SC iﬀit is SN.
Note A3.6 If Xτ is SC, then every term which diﬀers from Xτ only
by changes of bound variables is also SC. And the same holds for SN.
Note A3.7 By Deﬁnition A3.2(b), if Xρ→σ is SC and Y ρ is SC, then
(XY )σ is SC.
Note A3.8 If Xτ is SN, then every subterm of Xτ is SN, because
any inﬁnite reduction of a subterm of Xτ would give rise to an inﬁnite
reduction of Xτ .
Note A3.9 If [N ρ/xρ]M τ is SN, then so is M τ , because any inﬁnite
reduction of M τ would give rise to an inﬁnite reduction of [N ρ/xρ]M τ
by substituting N ρ into every step (cf. Lemma A1.15).

A3A SN for λ
295
Lemma A3.10 Let τ be any type. Then
(a) every term (aX1 . . . Xn)τ , where a is an atom, n ≥0, and X1, . . . ,
Xn are all SN, is SC;
(b) every atomic term aτ is SC;
(c) every SC term of type τ is SN.
Proof Part (b) is merely the special case n = 0 of (a). We prove (a) and
(c) together by induction on the number of occurrences of ‘→’ in τ.
Basis: τ is an atom. For (a): since X1, . . . , Xn are SN, aX1 . . . Xn
must be SN. Hence it is SC by Deﬁnition A3.2(a).
For (c): Use Deﬁnition A3.2(a).
Induction step: τ ≡ρ →σ. For (a): let Y ρ be SC. By the induction
hypothesis (c), Y ρ is SN. Using the induction hypothesis (a), we get that
(aX1 . . . XnY )σ is SC. Hence, so is (aX1 . . . Xn)τ by Deﬁnition A3.2(b).
For (c): let Xτ be SC, and let xρ not occur (free or bound) in Xτ .
By the induction hypothesis (a) with n = 0, xρ is SC. Hence, by Note
A3.7, (Xx)σ is SC. By the induction hypothesis (c), (Xx)σ is also SN.
But then by Note A3.8, Xτ is SN as well.
Lemma A3.11 If [N ρ/xρ]M σ is SC, then so is (λxρ .M σ)N ρ, provided
that N ρ is SC if xρ is not free in M σ.
(This lemma says that if the contractum of a typed β-redex R is SC,
and all terms (if any) that are cancelled when R is contracted are SC,
then R is SC.)
Proof Let σ ≡σ1 →. . . →σn →θ, where θ is atomic, and let
M σ1
1 , . . . , M σn
n
be SC terms. Since [N ρ/xρ]M σ is SC, it follows by Note A3.5 that
(([N/x]M)M1 . . . Mn)θ
(1)
is SN. The lemma will follow by Note A3.5 if we can prove that
((λx.M)NM1 . . . Mn)θ
(2)
is SN. Now since (1) is SN, so are all its subterms; these include
[N/x]M, M1, . . . , Mn.
Hence M is SN by Note A3.9. Also, by hypothesis and by part (c) of the
preceding lemma, N is SN if it does not occur in [N/x]M. Therefore,

296
Normalization proofs
an inﬁnite reduction of (2) cannot consist entirely of contractions in M,
N, M1, . . . , Mn. Hence, such a reduction must have the form
(λx.M)NM1 . . . Mn
▷β
(λx.M ′)N ′M ′
1 . . . M ′
n
▷1β
([N ′/x]M ′)M ′
1 . . . M ′
n
▷β
. . .
where M ▷β M ′, N ▷β N ′, etc. From the reductions M ▷β M ′ and N ▷β N ′
we get [N/x]M ▷β [N ′/x]M ′ by Lemma A1.15; hence, we can construct
an inﬁnite reduction of (1) thus:
([N/x]M)M1 . . . Mn
▷1β
([N ′/x]M ′)M ′
1 . . . M ′
n
▷β
. . .
This contradicts the fact that (1) is SN. Hence, (2) must be SN.
Lemma A3.12 For every typed term M τ :
(a) M τ is SC;
(b) For all xρ1
1 , . . . , xρn
n
(n ≥1), and all SC terms N ρ1
1 , . . . , N ρn
n
such that (for i = 2, . . . , n) none of x1, . . . , xi−1 occurs free in
Ni, the term M ⋆≡[N1/x1] . . . [Nn/xn]M is SC.
(Part (a) is all that is needed to prove the SN theorem, but the extra
strength of (b) is needed to make the proof of the lemma work. In fact
(a) is a special case of (b), namely Ni ≡xi for i = 1, . . . , n, since every
xi is SC by Lemma A3.10(b).)
Proof We prove (b) by induction on the length of M. (Note that, by
our usual convention, x1, . . . , xn are distinct.)
Case 1. M ≡xi and τ ≡ρi. Then M ⋆≡Ni. (If i = 1, this is
trivial; if i ≥2 then M ⋆≡[N1/x1] . . . [Ni−1/xi−1]Ni, which is Ni by the
assumption in (b).) But Ni is SC by assumption, so M ⋆is SC.
Case 2. M is an atom distinct from x1, x2, . . . , xn. Then M ⋆≡M,
which is SC by Lemma A3.10(b).
Case 3. M ≡M1M2. Then M ⋆≡M ⋆
1 M ⋆
2 . By the induction hypoth-
esis, M ⋆
1 and M ⋆
2 are SC, and so M ⋆is SC by Note A3.7.
Case 4. M τ ≡(λxρ .M σ
1 ), where τ ≡ρ →σ. By Note A3.6, we
can assume that x does not occur free in any of N1, . . . , Nn, x1, . . . , xn.
Then M ⋆≡λx.M ⋆
1 by Deﬁnition 1.12(f).
To show that M ⋆is SC, we must prove that for all SC terms N ρ, the
term M ⋆N is SC. But

A3B SN for CLw
297
M ⋆N
≡
(λx.M ⋆
1 )N
▷1β
[N/x]M ⋆
1
≡
[N/x][N1/x1] . . . [Nn/xn]M1,
which is SC by the induction hypothesis applied to M1 and the sequence
N, N1, . . . Nn. Then M ⋆N is SC by Lemma A3.11.
This completes the proof of Theorem A3.3.
By making a minor change, we can extend this proof to λβη →, as
follows.
Theorem A3.13 (SN for λβη →, cf. Remark 10.17) In the simply
typed λ-calculus, there are no inﬁnite βη-reductions.
Proof
The same as Theorem A3.3 except that in Lemma A3.11, near
the end of the proof, we need to allow for the possibility that an inﬁnite
reduction of (λx.M)NM1 . . . Mn has the form
(λx.M)NM1 . . . Mn
▷βη
(λx.M ′)N ′M ′
1 . . . M ′
n
≡
(λx.Px)N ′M ′
1 . . . M ′
n
▷1η
PN ′M ′
1 . . . M ′
n
▷βη
. . . ,
where M ▷M ′, etc. and x ̸∈FV(P). But in this case we can construct
an inﬁnite reduction of ([N/x]M)M1 . . . Mn as follows:
([N/x]M)M1 . . . Mn
▷βη
([N ′/x]M ′)M ′
1 . . . M ′
n
≡
PN ′M ′
1 . . . M ′
n
▷βη
. . . ,
and this contradicts the fact that (1) in the proof of A3.11 is SN.
A3B
Simply typed CL
In this section, types are the simple types of Deﬁnition 10.1, and terms
are simply-typed CL-terms as deﬁned in 10.19.
Theorem A3.14 (SN for CLw →, cf. Theorem 10.26) In simply
typed CL, there are no inﬁnite weak reductions.

298
Normalization proofs
Proof
Modify the proof of Theorem A3.3 as follows.
In Lemma A3.10(a) and (b), insert an assumption that a is a non-
redex atom (i.e. is not an Sγ,δ,ϵ, Kγ,δ or Iγ for any types γ, δ, ϵ). The
proof of Lemma A3.10 is unchanged.
Delete Lemma A3.11, which is not needed for CL-terms.
In Lemma A3.12, delete (b), which is not needed now. In that lemma’s
proof, Case 4 is not needed. But Case 2 must be augmented by a proof
that the atomic combinators are SC. This comes from the following
lemma.
Lemma A3.15 The atomic combinators Sρ,σ,τ , Kσ,τ , Iτ are SC, for all
types ρ, σ, τ.
Proof
(a) Sρ,σ,τ has type (ρ →σ →τ) →(ρ →σ) →ρ →τ. Let
τ ≡τ1 →. . . →τn →θ,
where θ is atomic and n ≥0, and let Xρ→σ→τ , Y ρ→σ, Zρ, U τ1
1 , . . . , U τn
n
be any SC terms. The term
SXY ZU1 . . . Un
(3)
has type θ, an atom, so, by Note A3.5, to prove S is SC it is enough to
prove (3) is SN.
If an inﬁnite reduction of (3) existed, it could not proceed entirely
inside X, Y , Z, U1, . . . , Un, because these SC terms are SN by Lemma
A3.10(c). Therefore it would have form
SXY ZU1 . . . Un
▷w
SX′Y ′Z′U ′
1 . . . U ′
n
▷1w X′Z′(Y ′Z′)U ′
1 . . . U ′
n
▷w
. . . ,
where X ▷w X′, Y ▷w Y ′, etc. Hence we could make an inﬁnite reduction
starting at XZ(Y Z)U1 . . . Un.
But X, Y , Z are SC, so XZ(Y Z) is SC by Note A3.7. Hence the
term XZ(Y Z)U1 . . . Un is SN, by Note A3.5, and an inﬁnite reduction
starting at this term is impossible. Therefore (3) is SN and so S is SC.
(b) Kσ,τ has type σ →τ →σ. Let σ ≡σ1 →. . . →σn →θ, where
θ is atomic and n ≥0, and let Xσ, Y τ , U σ1
1 , . . . , U σn
n
be any SC terms.
To prove K is SC, it is enough to prove the following term is SN:
KXY U1 . . . Un.
(4)
An inﬁnite reduction of (4) would have form

A3C SN for CLZ→
299
KXY U1 . . . Un
▷w
KX′Y ′U ′
1 . . . U ′
n
▷1w
X′U ′
1 . . . U ′
n
▷w
. . . ,
where X ▷w X′, etc. This would give rise to an inﬁnite reduction starting
at XU1 . . . Un. But this is impossible, because X is SC which implies
XU1 . . . Un is SN by Note A3.5. Therefore (4) is SN and so K is SC.
(c) The proof that Iτ is SC is like those for S and K.
Using the preceding lemma, we can prove that every typed CL-term
M τ is SC by induction on the length of M, as in the proof of Lemma
A3.12, Cases 1–3. This completes the proof of Theorem A3.14.
A3C
Arithmetical system
To show the versatility of Tait’s method, we shall here apply it to an
extension of simply typed CL which has played an important rˆole in
proofs of consistency.
The arithmetical extension of CL was discussed in 4.25 and deﬁned in
4.26. It was proved conﬂuent in Theorem A2.15. Types were assigned
to its terms by the rules of TA→
C shown in Deﬁnition 11.5, augmented
by the basis BZ shown in Example 11.40.
Now, the formal ﬁrst-order theory of natural numbers is usually called
Peano Arithmetic (PA). A deﬁnition is in [SU06, Section 9.2], for exam-
ple. Kurt G¨odel’s famous second incompleteness theorem implies that,
if PA is consistent, every proof of its consistency must contain a ‘non-
arithmetical’ step; i.e., very roughly speaking, a step that is too complex
to be translated into a valid proof in PA when the formulas and syntax
of PA are coded as numbers.
The theory of PA is outside the scope of this book. But it is worth
noting here that one way of proving PA consistent (discovered by G¨odel
himself) is to translate it into a typed version CLZ→of the arithmetical
extension of CL, and deduce its consistency from the conﬂuence and
WN theorems for CLZ→. The deduction of consistency can be done by
‘arithmetical’ means, and so can the conﬂuence proof. Hence the proof
of WN for CLZ→must contain a non-arithmetical step.
In the present section we shall brieﬂy deﬁne CLZ→and prove WN for
it, in fact SN.
More details can be found in other books. For example, there are
outlines of G¨odel’s consistency proof for PA or HA (the intuitionistic
analogue of PA, whose consistency problem is equivalent) in [Sho01,

300
Normalization proofs
Chapter 8] and [HS86, Chapter 18]; there are descriptions of his inter-
pretation of arithmetic in CL in [TD88, Volume 1 Chapter 3 Section
3, Volume 2 Chapter 9] and [SU06, Chapters 9, 10], with normaliza-
tion proofs in [TD88, Volume 2 Chapter 9 Section 2], [SU06, Section
10.3] and [GLT89, Chapter 7]. There is a comprehensive treatment of
G¨odel’s proof in [Tro73]: Sections 1.1.1–1.3.10 deﬁne and discuss HA,
Sections 2.2.1–2.2.35 deﬁne a system like CLZ→and prove SN for it, and
Sections 3.5.1–3.5.4 describe G¨odel’s translation of HA into that system.
G¨odel’s consistency-proof was ﬁrst published in [G¨od58]; but G¨odel gave
no details of λ or CL or WN-proofs, just a few hints.
Deﬁnition A3.16 Types are deﬁned as in 10.1, with only one atomic
type, N (for the set of all natural numbers).
Recall the notation Nτ ≡(τ →τ) →τ →τ for every type τ.
Deﬁnition A3.17 The terms of CLZ→are typed CL-terms as deﬁned
in 10.19, with, besides the combinators, just the following typed atomic
constants:
(a) 0 N to denote zero;
σ(N→N) for the successor function;
(b) atoms Z(N→Nτ ) called iterators, one for each type τ.
Note A3.18 The types of the iterators are the same as those assigned
to Z in the basis BZ in 11.40. We shall call Z(N→Nτ ) just ‘Zτ ’ for short.
Type-superscripts will be omitted unless needed for emphasis.
For m = 0, 1, 2, . . . we shall write m ≡σ m 0 and call m a ‘numeral’.
Clearly m has type N.
Abstraction [ ] is deﬁned as usual by 2.18, or equivalently 10.24.
Other notation conventions are the same as in Chapter 10.
Exercise A3.19 (Typed Church numerals) For every τ, ﬁnd suit-
able typed versions of S, B, K, I such that (SB)m(KI) has type Nτ for all
m ≥0. (Hint: see 11.8(e)–(g).) We shall call this version of (SB)m(KI)
the Church numeral mτ . It is easy to see that, for all Xτ →τ and Y τ ,
mτ XY ▷w XmY.
Deﬁnition A3.20 (Typed wZ-reduction)
Reduction ▷wZ is weak
reduction as deﬁned in 2.9, with extra contractions
Zτ m
▷wZ
mτ
(for all m ≥0 and all types τ), cf. Deﬁnition 4.26. A Z-redex is any

A3C SN for CLZ→
301
term Zτ m, and its contractum is mτ . (Both Zτ m and mτ have type
Nτ .)
Equality =wZ is deﬁned by contractions and reversed contractions as
usual. A wZ-normal form is a term containing no wZ-redexes.
Reduction ▷wZ is conﬂuent (cf. Theorem A2.15), so each term reduces
to at most one wZ-normal form.
Exercise A3.21
This exercise shows some of the scope of CLZ→;
however, it is not needed in the SN proof.
(a) (Predecessor) Let ρ ≡(N →N) →N, and let
π ≡[xN] . Zρ x

[uρ, vN→N] . v (u σ)
 
KN,N→N0

IN
(5)
(cf. πBund−Urb in 4.13). Show that π has type N →N, and that
π 0 ▷wZ 0,
π (σ k) ▷wZ k
(∀k ≥0).
(b) (Recursion combinators) For every type τ, a CLZ→-term Rτ
can be built, with type
τ →(N →τ →τ) →N →τ,
(6)
and such that, for all Xτ , Y N→τ →τ and all k ≥0,
Rτ X Y 0
=wZ
X,
Rτ X Y (σk)
=wZ
Y k (Rτ XY k ).

(7)
Show, using (6), that both sides of the equations in (7) are genuine
typed terms and have the same type, namely τ.
Show that the following Rτ satisﬁes (6) and (7).
(It is from
[CHS72, p.283] and is due mainly to Kleene.)1
Rτ
≡[xτ , y(N→τ →τ ), uN] . Z(N→τ ) u (Mτ y)(Kτ,N x) u ,
(8)
where
Mτ
≡[y(N→τ →τ ), v(N→τ ), wN] . SN,τ,τ y v (πw).
(9)
(c) (Pairing)
For every type τ, construct a CLZ→-term D⋆
τ with
type τ →τ →N →τ, such that, for all Xτ and Y τ ,
D⋆
τ X Y 0 =wZ X,
D⋆
τ X Y 
k + 1 =wZ Y.
(Hint: insert types into [x, y].Rx(K(Ky)). )
1 The R in 4.25 (32) like RBernays is not used here, because an attempt to insert Zτ
and types into that R would only give RN, not Rτ for all τ : see [CHS72, Theorem
13D1, p. 280].

302
Normalization proofs
Theorem A3.22 (SN for CLZ→) No term of CLZ→can be the start
of an inﬁnite wZ-reduction.
Proof
We modify the proof of Theorem A3.3 as follows. In Lemma
A3.10, insert an assumption that a is neither a combinator nor a Zτ (al-
though a is allowed to be 0 or σ); the proof of that lemma is unchanged.
Delete A3.11 and A3.12(b) which are now redundant, and delete Case 4
from A3.12’s proof.
To complete the proof, it only remains to show that all atoms Zτ are
SC; the following lemma does this. (Its part (b) is needed in the proof
of (a).)
Lemma A3.23 Let τ be any type. Then
(a)
Zτ is SC;
(b)
for all m ≥0, the Church numeral mτ is SC.
Proof Let τ ≡τ1 →. . . →τn →N, with n ≥0. Recall that the types
of Zτ and mτ are, respectively,
N →(τ →τ) →τ →τ,
(τ →τ) →τ →τ.
In what follows, V N, Xτ →τ , Y τ , U τ1
1 , . . . , U τn
n
will be any SC terms
of the types shown.
Proof that (b) =⇒(a). To prove that Zτ is SC, it is enough to prove
that the following term is SN:
Zτ V XY U1 . . . Un.
(10)
But V , X, Y , U1, . . . , Un are SN by Lemma A3.10(c), so an inﬁnite
reduction of (10) would have form
Zτ V XY U1 . . . Un
▷wZ Zτ mX′Y ′U ′
1 . . . U ′
n
▷Z
mτ X′Y ′U ′
1 . . . U ′
n
▷w
. . . ,
where V ▷wZ m for some m ≥0, and X ▷wZ X′, etc. Hence we could
make an inﬁnite reduction of mτ XY U1 . . . Un, contrary to (b).
Proof of (b). To prove that mτ is SC, it is enough, by Note A3.5, to
prove the following term is SN (for all SC terms X, Y , U1, . . . , Un):
mτ XY U1 . . . Un.
(11)
We shall do this by induction on m.

A3C SN for CLZ→
303
Basis (m = 0 and m ≡KI). Since X, Y , U1, . . . , Un are SN by
Lemma A3.10(c), an inﬁnite reduction of (11) must have form
KIXY U1 . . . Un
▷wZ IY ′U ′
1 . . . U ′
n
(Y ▷w Y ′, etc.)
▷wZ Y ′′U ′′
1 . . . U ′′
n
(Y ′ ▷w Y ′′, etc.)
▷wZ . . .
This would give rise to an inﬁnite reduction of Y U1 . . . Un, contrary to
the assumption that Y is SC.
Induction step (m to m + 1). Assume (11) is SN for all SC terms X,
Y , U1, . . . , Un. Now m + 1 ≡SBm, and hence an inﬁnite reduction of
the term m + 1XY U1 . . . Un must have form
SBmXY U1 . . . Un ▷wZ SB m X′Y ′U ′
1 . . . U ′
n
(X ▷X′, etc.)
▷1w
BX′(mX′)Y ′U ′
1 . . . U ′
n
▷wZ BX′WY ′U ′
1 . . . U ′
n
(mX′▷some W)
▷wZ BX′′W ′′Y ′′U ′′
1 . . . U ′′
n
(X′ ▷X′′, etc.)
≡
S(KS)KX′′W ′′Y ′′U ′′
1 . . . U ′′
n
▷w
X′′(W ′′Y ′′)U ′′
1 . . . U ′′
n
▷wZ . . .
From this we could make the following inﬁnite reduction:
X(mXY )U1 . . . Un
▷
X′′(W ′′Y ′′)U ′′
1 . . . U ′′
n
▷
. . .
(12)
Now mXY is SC. To prove this, it is enough, by Note A3.5, to show
that mXY U1 . . . Un is SN (for all SC terms U1, . . . , Un); and the latter
holds by the induction hypothesis.
But X is assumed to be SC, so X(mXY ) is SC by Deﬁnition A3.2(b).
Hence X(mXY )U1 . . . Un is SN by Note A3.5. Thus (12) is impossible.
Therefore the analogue of (11) for m + 1 is SN.
This completes the proof of Theorem A3.22.
Remark A3.24 (Arithmetizability)
The discussion at the start of
the present section noted that any proof of SN or WN for CLZ→must
contain at least one ‘non-arithmetical’ step. In fact, it can be shown
that there is such a step right at the start: the deﬁnitions of SC and
WC for CLZ→are not expressible in PA (see [Tro73, Section 2.3.11]).
Also the deﬁnition of SN is not arithmetical, since ‘inﬁnite reduction’
is not a ﬁrst-order arithmetical concept. (For pure λ or CL, the concept
‘X is SN’ can be made arithmetical by re-wording it as ‘there exists n

304
Normalization proofs
(depending on X) such that all reductions of X have less than n steps’.
But for CLZ→this does not work.)
Remark A3.25 (Recursion combinators)
Instead of adding Zτ ,
one can add typed recursion combinators Rτ to CL, each having type
τ →(N →τ →τ) →N →τ and reduction-axioms
Rτ X Y 0
▷wR
X,
Rτ X Y (σk )
▷wR
Y k (Rτ XY k ).

(13)
The system CLR→so deﬁned is equivalent to CLZ→, in the sense that
in CLZ→one can build terms Rτ satisfying (13) with ‘=’ instead of ‘▷’
(see Exercise A3.21(b)), and in CLR→one can build terms Zτ such that
Zτ m ▷wR m. (Try Rτ (KI)(K(SB)) with suitable types.)
SN holds for CLR→. The previous Z-proof can fairly easily be mod-
iﬁed; alternatively, proofs can be found in several sources, for example
[San67], [HS86, Appendix 2, Theorem A2.6] and [TD88, Chapter 9, Sec-
tion 2]. The ﬁrst of these uses a diﬀerent method from Tait’s, invented
independently. The other two use Tait’s method. In the third, WN and
SN are proved separately (Sections 2.10, 2.16).
The advantage of using Rτ instead of Zτ is that deﬁning recursion
is simpler and more direct. The price to pay is technical: a Z-redex
cannot contain other redexes, but an R-redex can, and this makes the
proof of conﬂuence for ▷wR is slightly more complicated than for ▷wZ,
cf. Theorem A2.15.
Remark A3.26 (λ-calculus version) Instead of CL, we could begin
with λ-calculus and add Zτ (or Rτ ). Then we could prove SN for βZ-
or βR-reduction by a proof very like the one given here for CL.
Proofs of SN for ▷βR can be found, for example, in [Ste72, Chapter 4,
Section 8], [Tro73, Chapter II Theorem 2.2.31], [GLT89, Chapter 7] and
[SU06, Section 10.3].

Appendix A4
Care of your pet combinator
This Appendix was contributed by Carol Hindley to [HS86]. We believe
its plain common-sense advice is still very valid despite changing fashions
in care, and therefore reprint it here.
Combinators make ideal pets.
Housing They should be kept in a suitable axiom-scheme, preferably
shaded by B¨ohm trees. They like plenty of scope for their contractions,
and a proved extensionality is ideal for this.
Diet
To keep them in strong normal form a diet of mixed free
variables should be given twice a day. Bound variables are best avoided
as they can lead to contradictions. The exotic R combinator needs a few
Church numerals added to its diet to keep it healthy and active.
House-training
If they are kept well supplied with parentheses,
changed daily (from the left), there should be no problems.
Exercise
They can be safely let out to contract and reduce if kept
on a long corollary attached to a ﬁxed point theorem, but do watch that
they don’t get themselves into a logical paradox while playing around
it.
Discipline
Combinators are generally well behaved but a few rules
of inference should be enforced to keep their formal theories equivalent.
Health
For those feeling less than weakly equal a check up at a
nearby lemma is usually all that is required. In more serious cases a
theorem (Church–Rosser is a good general one) should be called in.
Rarely a trivial proof followed by a short remark may be needed to get
them back on their feet.
Travel
If you need to travel any distance greater than the length
of M with your combinators try to get a comfortable Cartesian Closed
Category. They will feel secure in this and travel quite happily.
Choosing your combinator
Your combinators should be obtained
305

306
Care of your pet combinator
from a reputable combinatory logic monograph. Make sure that you are
given the full syntactic identity of each combinator. A ﬁnal word: do
consider obtaining a recursive function; despite appearances, they can
make charming pets!

Appendix A5
Answers to starred exercises
1.4 (To help the reader, outer parentheses are shown larger; but actu-
ally all parentheses should be the same size.)
(a)

((xy)z)(yx)

,
(d)

λu . ((vu)u)

z

y

,
(b)

λx . ((ux)y)

,
(e)

(ux)(yz)
 
λv.(vy)

,
(c)

λu.

u (λx.y)

,
(f)

λx.

λy.

λz.((xz)(yz))

u

v

w

.
1.8 (a) λxy.xy ≡(λx.(λy.(xy))).
(b) x(uv)(λu.v(uv))uv ≡((((x(uv))(λu.(v(uv)))) u) v).
(c) No. In fact λu.uv ≡(λu.(uv)),
and λu.u ≡(λu.u), which does not occur in (λu.(uv)).
1.14 (a) λy. uv(λw. vw(uv)); (c) y (λz.(λy.vy)z), where z ̸≡v, y, x;
(b) λy. (λy.xy)(λx.x);
(d) λx.zy.
1.28 Here are suitable reductions. (In each term, an underline shows
the redex to be contracted in the next step.) In (c) and (f) there are
other possible reductions. (But they give the same nf’s, modulo ≡α.)
(a) (λx.xy)(λu.vuu)
▷1β
[(λu.vuu)/x] (xy) ≡(λu.vuu) y
▷1β
[y/u] (vuu)
≡vyy.
(b) First, (λxy.yx)uv is really

(λx.(λy . yx) u

v. Then

(λx.(λy.yx)) u

v
▷1β

[u/x] (λy.yx)

v
≡(λy.yu) v
▷1β
[v/y] (yu)
≡vu.
(c) (λx. x(x(yz))x)(λu.uv) ▷1β [(λu.uv)/x] (x(x(yz))x)
≡
(λu.uv)

(λu.uv) (yz)

(λu.uv)
▷1β (λu.uv)

[(yz)/u](uv)

(λu.uv)
≡
(λu.uv) ((yz)v) (λu.uv)
▷1β

[((yz)v)/u] (uv)

(λu.uv)
≡
((yz)v)v (λu.uv) which is a nf ( ≡yzvv(λu.uv) ).
307

308
Answers to starred exercises
(d) (λx.xxy)(λy.yz) ▷1β [(λy.yz)/x](xxy) ≡(λy.yz)(λy.yz) y
▷1β [(λy.yz)/y](yz) y ≡(λy.yz) z y
▷1β ([z/y](yz)) y
≡zzy.
(e) (λxy.xyy)(λu.uyx) ≡(λx.(λy.xyy))(λu.uyx)
▷1β
[(λu.uyx)/x](λy.xyy)
≡
[(λu.uyx)/x](λz.xzz) by def. of substitution, 1.12(g),
≡
λz . (λu.uyx)zz
▷1β
λz . ([z/u](uyx))z ≡λz.zyxz which is a nf.
To avoid having to change y to z while substituting, it is usually
better to change bound variables at the start of the reduction,
thus (β-reductions are allowed to contain α-steps):
(λxy.xyy)(λu.uyx) ≡α (λvw.vww)(λu.uyx) ▷β
λw.wyxw.
(f) First, (λxy.yx)u ≡(λx.(λy.yx))u ▷1β [u/x](λy.yx) ≡λy.yu.
Also (λxy.yx)v ▷1β λy.yv. Hence
(λxyz.xz(yz))((λxy.yx)u)((λxy.yx)v) w
▷β
(λxyz.xz(yz))(λy.yu)(λy.yv) w
▷β
(λy.yu) w ((λy.yv)w)
by three contractions
▷β
wu(wv)
by two contractions.
1.35 (a) If M contained a redex (λu.V )W, then [N/x]M would contain
a redex obtained by substitution from (λu.V )W.
(b) Let Ω≡(λx.xx)(λx.xx), which has no β-nf. Then xΩhas no
β-nf. Choose M ≡xΩ. Choose N ≡λy.z. Then [N/x]M ≡(λy.z)Ω
which reduces to z, which is a nf.
1.36 (Due to B. Intrigila) Let Ω≡(λx.xx)(λx.xx). Choose P to be
λy. y(λuvw.w)Ω, and Q to be λz.zΩ. Then PQ ▷β λw.w.
1.38 To avoid confusion, it is safer to change some bound variables ﬁrst:
(λxyz.xzy)(λxy.x) ≡α (λxyz.xzy)(λuv.u)
▷1β λyz.(λuv.u)zy
▷β
λyz.z;
(λxy.x)(λx.x) ≡α (λxy.x)(λw.w) ▷1β λy.(λw.w)
≡
λyw.w
≡α λyz.z.
1.42 (a) For all M, N: M =β (λxy.x)MN since (λxy.x)MN ▷β M,
=
(λxy.y)MN by proposed new axiom,
=β N.
(b) Let K ≡λxy.x. Then (KX)Y =β X. Hence, for all M, N:

Answers to starred exercises
309
(λxy.yx)(KM)(KN) =β
(KN)(KM) =β N,
(λx.x)(KM)(KN)
=β
(KM)(KN) =β M.
Also (λxy.yx)(KM)(KN) = (λx.x)(KM)(KN) would follow from the
proposed new axiom. These equations together imply M = N.
2.8 (a) Simultaneous substitution is deﬁned in CL thus:
[U1/x1, . . . , Un/xn]xi
≡Ui
for 1 ≤i ≤n;
[U1/x1, . . . , Un/xn]a
≡a
if a is an atom ̸∈{x1, . . . , xn},
[U1/x1, . . . , Un/xn](XY ) ≡

[U1/x1, . . . , Un/xn]X [U1/x1, . . . , Un/xn]Y

.
(b) The given identity is true if (for 1 ≤i ≤n) Ui contains none of x1,
. . . , xn. It is also true under the weaker condition that (for 2 ≤i ≤n)
Ui contains none of x1, . . . , xi−1.
2.13 SIKx ▷1w Ix(Kx) ▷1w x(Kx). This is a nf.
SSKx y ▷1w Sx(Kx) y ▷1w xy(Kxy) ▷1w xyx.
S(SK)xy ▷1w SKy(xy) ▷1w K(xy)(y(xy)) ▷1w xy.
S(KS)S x y z ▷1w KSx(Sx)yz ▷1w S(Sx)yz
▷1w Sxz(yz) ▷1w x(yz)(z(yz)).
SBBI x y ▷1w

BI(BI)x

y ▷w I(BIx) y by Example 2.11,
▷1w BIxy ▷w I(xy) ▷1w xy.
2.17
One answer is: B′ ≡S(K(SB))K, where B ≡S(KS)K; and W ≡
SS(KI). There are other possible answers.
2.22 [x].u(vx) ≡S([x].u)([x].vx) by 2.18(f), ≡S(Ku)v by 2.18(a),(c).
[x].x(Sy) ≡S([x].x)([x].Sy) by 2.18(f), ≡SI(K(Sy)) by 2.18(b),(a).
[x].uxxv ≡S([x].uxx)([x].v) by 2.18(f); then use 2.18(f),(a) to get
≡S(S([x].ux)([x].x))(Kv), ≡S(SuI)(Kv) by 2.18(c),(b).
2.26
[x, y, z].xzy ≡S(S(KS)(S(KK)S))(KK). This ̸≡the C in 2.12,
but has some similarities with it. For [x, y, z].y(xz) and [x, y].xyy we
get exactly the terms B′ and W shown in the answer to 2.17.
2.30 BWBIx ▷w W(BI)x ▷w BIxx ▷w I(xx) ▷1w xx;
also SIIx ▷1w Ix(Ix) ▷1w x(Ix) ▷1w xx.
2.34 (a) The pairing-combinator D most often used in the literature
comes from [Chu41, p. 30]: D ≡[x, y, z].zxy, with its two projections
Di ≡[u].u([x1, x2].xi) for i = 1, 2. Another is given in Note 4.14.
(b) If A exists, then S =w AK =w A(KKK) =w K, contrary to 2.32.3.

310
Answers to starred exercises
(c)
If X is a nf, it is obviously minimal. If X is not a nf, then it
contains a weak redex. But a weak redex never contracts to itself. (This
is obvious for IU ▷w U and KUV ▷w U; for SUV W ▷w UW(V W), if
(SUV )W ≡(UW)(V W) then W ≡V W, which is impossible.) Hence,
if X is not a nf, X must be non-minimal.
If WXY ▷w XY Y was a contraction, we could have WWW ▷w WWW.
3.5 (a) Let Y ≡YCurry−Ros ≡λx.(λy.x(yy))(λy.x(yy)). Then
YX =β,w V V
where V ≡λz.X(zz) where z ̸∈FV (X)
≡
(λz.X(zz))V
since V ≡λz.X(zz),
=β,w X(V V )
=β,w X(YX)
by the ﬁrst line reversed.
(b) The exercise requires terms X1, . . . , Xk such that, for 1 ≤i ≤k,
Xiy1 . . . yn =β,w [X1/x1, . . . , Xk/xk] Zi.
(1)
To get them, we can combine the k given equations into one, solve
the combined equation by applying Corollary 3.3.1, and then split the
solution into k parts. But to make this method work, the details need
care.1
First, make a k-tuple combinator and k projection-combinators, by
analogy with Exercise 2.34: let D(k) ≡λx1 . . . xkz . zx1 . . . xk and D(k)
i
≡λu. u(λx1 . . . xk .xi) (1 ≤i ≤k). These satisfy
D(k)
i

D(k)x1 . . . xk

▷β,w xi.
(2)
Choose a variable x ̸∈FV (x1 . . . xky1 . . . ynZ1 . . . Zk); deﬁne, for 1 ≤
i ≤k,
Ei ≡λy1 . . . yn .D(k)
i
(xy1 . . . yn),
Z⋆
i
≡[E1/x1, . . . , Ek/xk] Zi. (3)
By Corollary 3.3.1, solve the equation xy1 . . . yn = D(k)Z⋆
1 . . . Z⋆
k . This
gives a term X, not containing any of y1, . . . , yn, such that
Xy1 . . . yn =β,w D(k)([X/x]Z⋆
1 ) . . . ([X/x]Z⋆
k ).
(4)
Deﬁne, for 1 ≤i ≤k,
Xi ≡[X/x]Ei ≡λy1 . . . yn .D(k)
i
(Xy1 . . . yn).
(5)
Then, for 1 ≤i ≤k,
[X/x]Z⋆
i
≡[X1/x1, . . . , Xk/xk] Zi.
(6)
1 More care than they received in [HS86]! Its answer was incorrect, as several readers
pointed out.

Answers to starred exercises
311
Finally, for 1 ≤i ≤k,
Xiy1 . . . yn =β,w D(k)
i
(Xy1 . . . yn)
by (5),
=β,w D(k)
i
(D(k)([X/x]Z⋆
1 ) . . . ([X/x]Z⋆
k )) by (4),
=β,w [X/x]Z⋆
i
by (2),
≡
[X1/x1, . . . , Xk/xk] Zi
by (6).
3.12 (a) (i) Choose n = 2 and L1 ≡λxy.y, L2 ≡λxy.x.
(ii) Choose n = 5, L1 ≡λxy.yx, L2 ≡L3 ≡L4 ≡λx.x, L5 ≡λxy.x.
(These answers are by John D. Stone. They have the property that each
Li is either a permutator (such as λxy.yx or λxyz.yxz) or a selector
(such as λxy.x or λx.x or λxyz.y). It is known that suitable L1, . . . , Ln
for B¨ohm’s theorem can always be found with this property. But the
choice of n, L1, . . . , Ln is not unique; e.g. for (ii) above, we could choose
n = 4 and L1 ≡λx.x, L2 ≡λu.u(λxy.y), L3 ≡λxyz.y, L4 ≡λxy.y.)
(b) First, if a closed term Y is a strong nf, then Y x weakly reduces
to a strong nf Z (proof by induction on Deﬁnition 3.8). By Lemma 3.10,
Z is also a weak nf. Hence so is xZ. Therefore by Corollary 2.32.3,
Z ̸=w xZ. But the equation Y x =w x(Y x) would imply Z =w xZ.
(c) In CL, YCurry−Ros ≡SWW, where W ≡S(S(KS)K)(K(SII)). It
seems abstraction often produces weak nfs.
To change ‘often’ to ‘al-
ways’, look at Deﬁnition 2.18: omit clause (c) and restrict clause (a) to
the case that M is an atom. By Remark 2.23, the resulting term (which
we call here ‘[x]f ab .M’) has the property that ([x]f ab .M)X ▷w [X/x]M.
By induction on M, one can prove that [x]f ab.M is always a weak nf,
even when M is not one; e.g. [x]f ab.(IK) ≡S(KI)(KK). Finally, choose
X′ ≡[y1, . . . , yn]f ab .Z.
4.10
First, we prove m · (k + 1) = π(m · k).
(Case 1: if k < m
then k + 1 ≤m, so m · k = m −k and m · (k + 1) = m −(k +
1) = π(m −k) = π(m · k). Case 2: if k ≥m then k + 1 > m, so
m · (k + 1) = 0 = m · k = π(m · k) since π(0) = 0.)
Hence m · (k + 1) = π(Π3
2(k, m · k, m)). Also m · 0 = m = Π1
1(m).
Now Π1
1, Π3
2 are primitive recursive by 4.8(III), and so is π by 4.9. Hence
·
is primitive recursive by 4.8(V) with
n = 1,
ψ = Π1
1,
χ = Π3
2.
4.16 (a) The deﬁnition of φ can be written thus: φ(0) = 2, φ(k + 1) =
3 + φ(k) = σ(σ(σ(φ(k)))). To represent φ, choose:
φ ≡R (σ(σ0)) Y,
where
Y
≡λxy. σ(σ(σy)).
Then φ(0) ≡R2Y 0 =β,w 2 by (6) in the proof of Theorem 4.11. Also

312
Answers to starred exercises
φ (k + 1) ≡R 2 Y k + 1 =β,w Y k (R 2 Y k)
by (6)
=β,w Y k (φ k)
=β,w σ (σ (σ (φ k))).
(b) First: Add(m, 0) = m, Add(m, k + 1) = Add(m, k) + 1;
Mult(m, 0) = 0, Mult(m, k + 1) = Add(Mult(m, k), m);
Exp(m, 0) = 1, Exp(m, k + 1) = Mult(Exp(m, k), m).
Suitable representatives using R:
Add
≡λuv . R u Y v,
where
Y
≡λxy . σ y;
Mult ≡λuv . R 0 Y v,
where
Y
≡λxy . Add u y;
Exp
≡λuv. R 1 Y v,
where
Y
≡λxy. Mult u y.
(c)
For
· : m · (k + 1) = π(m · k) by the answer to 4.10. Also
m · 0 = m. Representative: λx . Rx(λu.π ).
(d) Short representatives, by Rosser [Chu41, pp. 10, 30]: AddRosser
≡λuvxy.ux(vxy), MultRosser ≡λuvx.u(vx), ExpRosser ≡λuv.vu.
4.27 (From [CHS72, Section 13A3, Theorem 2]) Suppose π could be
represented by a term P. Then P0 =β,w 0, P 
k + 1 =β,w k. Since 0 and
σ are atoms, we could substitute any terms for them and the conversions
‘=β,w’ would stay correct. Substitute K for 0 and KS for σ. This makes

k + 1 =β,w S for all k ≥0. Hence, after the substitution, we would get
S =β,w 1 =β,w P 2 =β,w P S =β,w P 1 =β,w 0 ≡K.
5.8
Let A be the set of all closed λI-terms and B be the set of all
non-closed λI-terms.
5.9
(a)
[Bar84, Theorem 20.2.5] Let the range of F have n ≥2
members, say M1, . . . , Mn (modulo =β,w).
Deﬁne Ai to be the set
{X : FX =β,w Mi}.
Then A1, . . . , An are non-empty and closed
under conversion.
As mentioned in 5.7, the theory of =β,w can be written out as formal
axioms and rules. Hence the set {⟨X, Y ⟩: FX =β,w Y } is recursively
enumerable (‘r.e.’), and {X : FX =β,w Mi} is r.e. too. Let B = A2 ∪
. . . ∪An. Then B is r.e. Since its complement is A1 which is also r.e.,
both B and A1 must be recursive, contrary to Theorem 5.6.
(b) Let T, N be as in the proof of 5.6. Choose y ̸∈FV (F) and deﬁne,
by analogy with (10) in Chapter 5,
XF
≡H′⌈H′⌉,
where
H′ ≡λy.F(Ty(Ny)).
7.6
To derive (ξ) in λβ−ξ+ζ , we deduce λx.M = λx.M ′ from an
equation M = M ′ thus. Rule (β) gives (λx.M)x = [x/x]M ≡M. We

Answers to starred exercises
313
assume M = M ′. And (β) with rule (σ) give M ′ = (λx.M ′)x. From
these, rule (τ) gives (λx.M)x = (λx.M ′)x. Then (ζ) gives λx.M =
λx.M ′.
8.3
For (ζ): let X ≡S(Ku)I and Y ≡u. Then Xx =w ux ≡Y x
but X ̸=w Y . For (ξ): let X ≡S(Ku)Ix, Y ≡ux. Then X =w Y but
[x].X ≡S(Ku)I and [x].Y ≡u, so [x].X ̸=w [x].Y .
9.19
(a)
(From [CF58, Section 6F, Theorem 3].)
If U >−X and
U >−Y , then X =Cext Y by 8.17(d), so Xλ =λext Yλ by 9.17(c).
Hence, by 7.16.1, there exists T such that Xλ ▷βη T and Yλ ▷βη T.
Then, by 9.18(1), XλHη >−THη and YλHη >−THη . That is, by 9.17(a),
X >−THη and Y >−THη .
(b) (From [CF58, Section 6F, p. 221].) Choose X ≡SK, Y ≡KI. By
8.16(a), X >−Y . But Xλ ≡(λxyz.xz(yz))(λuv.u), which βη-reduces
in three steps to three terms, none of which is ≡α KλIλ.
(c) By induction on Deﬁnition 3.8, X in strong nf implies X ≡MHη
for some M in β-nf. By 7.14, this M has a βη-nf. Also η-contractions
in M do not change MHη , since
(λx.Px)Hη
≡[x]η .(PHη x) ≡PHη
if x ̸∈FV(P).
Finally, by induction on the clauses of Lemma 1.33, M in β-nf implies
MHη in strong nf.
9.28
Let Xλ =β λx.M. Then by the Church-Rosser theorem, 1.41,
Xλ ▷β T and λx.M ▷β T for some T. From the latter, T must have form
λx.Q with M ▷β Q.
Since Xλ ▷β T ≡λx.Q, the standardization theorem [Bar84, Theorem
11.4.7] gives a standard reduction from Xλ to λx.Q.
In a standard
reduction, no ‘internal’ contraction can precede a ‘head’ contraction,
i.e. a contraction of a redex whose leftmost λ is the leftmost symbol
of the whole term (except for parentheses). And internal contractions
cannot change a non-abstraction-term into an abstraction-term. Hence
the standard reduction from Xλ to λx.Q must ﬁrst change Xλ to an
abstraction-term λx.P by head-contractions, then change P to Q.
Now apply the mapping Hβ. Head-contractions can be seen to trans-
late into CL as weak reductions. Hence
(Xλ)Hβ
▷w
(λx.P)Hβ
≡
[x]β .(PHβ ).
But, by 9.27, (Xλ)Hβ ≡X and [x]β .(PHβ ) is fnl.

314
Answers to starred exercises
9.30
(b)
SK =Cβ KI, because (SK)λ ≡α (λxyz.xz(yz))(λuv.u) ▷β
λyz.z and (KI)λ ≡α (λuv.u)(λx.x) ▷λ λvx.x ≡α λyz.z. Also SK ̸=w KI
by 2.32.3, because SK, KI are distinct weak nfs.
(c) S(KI)yz ▷w KIz(yz) ▷w I(yz) ▷w yz, and Iyz ▷w yz, so
S(KI)yz =w Iyz;
hence, by rule (ζ) twice, S(KI) =Cext I.
Also S(KI) ̸=Cβ I, because
(S(KI))λ ▷β λxy.xy and λxy.xy ̸ ▷β λx.x.
11.8 (a)
(→K)
K : (σ→σ)→τ →σ→σ
(→I)
I : σ→σ
KI : τ →σ→σ .
(→e)
(b) Let µ ≡σ→τ, ν ≡ρ→σ, and π ≡ρ→τ:
(→S)
S : (µ→ν →π)→(µ→ν)→µ→π
By Example 11.7
B : µ→ν →π
SB : (µ→ν) →µ→π .
(→e)
(c) Let µ ≡σ→σ→τ, ν ≡σ→σ, and π ≡σ→τ:
(→S)
S : (µ→ν→π)→(µ→ν)→µ→π
(→S)
S : µ→ν→π
SS : (µ→ν)→µ→π
(→e)
By (a)
KI : µ→ν
SS(KI) : µ→π .
(→e)
(d)
(→K)
K : (σ→τ →σ)→ρ→σ→τ →σ
(→K)
K : σ→τ →σ
KK : ρ→σ→τ →σ .
(→e)
(e) Apply (a), taking the special case that the σ in (a) is the same as
the present type τ, and the τ in (a) is τ →τ for the present τ.
(f) Apply (b), taking the special case ρ ≡τ ≡σ.
(g) Apply rule (→e) repeatedly to (e) and (f).

Answers to starred exercises
315
11.9
(a)
Here is a deduction of SUV W : τ whose only non-axiom
assumptions are U :ρ→σ→τ, V :ρ→σ, W :ρ:
(→S)
S : (ρ→σ→τ)→(ρ→σ)→ρ→τ
U : ρ→σ→τ
SU : (ρ→σ)→ρ→τ
V : ρ→σ
SUV : ρ→τ
W : ρ
SUV W : τ .
(b)
U : ρ→σ→τ
W : ρ
UW : σ→τ
V : ρ→σ
W : ρ
V W : σ
UW(V W) : τ .
(c) and (d)
(→K)
K : ρ→σ→ρ
U : ρ
KU : σ→ρ
V : σ
KUV : ρ ,
(→I)
I : ρ→ρ
U : ρ
IU : ρ .
(e)
x : ρ→σ
x : ρ
xx : σ .
11.15 (a) First, x:ρ→σ→τ, y:σ, z :ρ ⊢TA→
C
xzy:τ thus:
x : ρ→σ→τ
z : ρ
xz : σ→τ
y : σ
xzy : τ .
Hence by Corollary 11.14.1,
⊢TA→
C

[x, y, z].xzy

: (ρ→σ→τ)→σ→ρ→τ .
(b) First, x:τ, y:τ, z :Nτ
⊢TA→
C
z(Ky)x : τ thus:
z : (τ →τ)→τ →τ
(→K)
K : τ →τ →τ
y : τ
Ky : τ →τ
z(Ky) : τ →τ
x : τ
z(Ky)x : τ .

316
Answers to starred exercises
Hence by Corollary 11.14.1,
⊢TA→
C

[x, y, z].z(Ky)x

: τ →τ →Nτ →τ .
(c)
Given any τ, let ξ ≡Nτ ≡(τ →τ) →τ →τ. By 11.8(e) and
(g) applied to ξ instead of τ, we get ⊢0 : Nξ
and ⊢1 : Nξ. Also, by
11.8(f), ⊢σ : Nτ →Nτ . Hence, using 11.15(b), from two assumptions
y:Nτ →Nτ →Nτ and v:Nξ →Nτ
we can deduce
D (σ(v0)) (y(v0)(v1)) : NNτ →Nτ .
Note that NNτ ≡Nξ. Then Corollary 11.14.1 gives
⊢TA→
C
Q : (Nτ →Nτ →Nτ ) →(Nξ →Nτ ) →Nξ →Nτ .
We must make a deduction that will give
x:Nτ , y:Nτ →Nτ →Nτ , u:Nτ ⋆
⊢TA→
C
u(Qy)(D0x)1 : Nτ .
Note that τ ⋆≡NNτ →Nτ
≡Nξ →Nτ ; hence
Nτ ⋆
≡((Nξ →Nτ )→Nξ →Nτ )→(Nξ →Nτ )→Nξ →Nτ .
Note also that ⊢0 : Nτ , by 11.8(e).
Using these facts, the required
deduction is not hard to construct.
12.9 (a)
1
[y : σ]
λy.y : σ→σ
(→i −1)
λxy.y : τ →σ→σ .
(→i −v)
(b)
1
[x:σ→τ]
2
[u:(σ→τ)→ρ→σ]
1
[x:σ→τ]
ux : ρ→σ
(→e)
3
[y:ρ]
uxy : σ
(→e)
x(uxy) : τ
(→e)
λy.x(uxy) : ρ→τ
(→i −3)
λxy.x(uxy) : (σ→τ)→ρ→τ
(→i −1)
λuxy.x(uxy) : ((σ→τ)→ρ→σ)→(σ→τ)→ρ→τ .
(→i −2)

Answers to starred exercises
317
(c)
1
[x : σ→σ→τ]
2
[y : σ]
xy : σ→τ
(→e)
2
[y : σ]
xyy : τ
(→e)
λy.xyy : σ→τ
(→i −2)
λxy.xyy : (σ→σ→τ)→σ→τ .
(→i −1)
(d)
1
y : σ
λz.y : τ →σ
(→i −v)
λyz.y : σ→τ →σ
(→i −1)
λxyz.y : ρ→σ→τ →σ .
(→i −v)
(e) In (a), let the σ in (a) be the present τ, and let the τ in (a) be
the present τ →τ.
(f) In (b), take the special case ρ ≡σ ≡τ.
(g)
Note that x0y ≡y and xny ≡x(xn−1y) for n ≥1. Build, for
every n ≥0, a deduction Dn of xny : τ from assumptions x : τ →τ and
y : τ, thus: D0 is the one-step deduction y : τ, and if Dn−1 has already
been built, build Dn thus:
x : τ →τ
Dn−1
xn−1y : τ
x(xn−1y) : τ .
(→e)
Then apply (→i) twice, thus:
Dn
xny : τ
λy.xny : τ →τ
(→i, discharging y:τ in Dn)
λxy.xny : (τ →τ)→τ →τ .
(→i, discharging x:τ →τ in Dn)
12.15 Since B ≡λxyz.x(yz), any TA→
λ -deduction of a type for B must
begin with a deduction for x(yz) using rule (→e); this must have form
x : σ→τ
y : ρ→σ
z : ρ
yz : σ
(→e)
x(yz) : τ ,
(→e)

318
Answers to starred exercises
where ρ, σ, τ can be any types. The next steps in the deduction must
come from three applications of (→i); hence the result.
12.16 Since YCurry−Ros ≡λx.(λy.x(yy))(λy.x(yy)), any TA→
λ -deduct-
ion of a type for YCurry−Ros must contain a deduction for λy.x(yy). This
must begin with steps of form
x : σ→τ
y : ρ→σ
y : ρ
yy : σ
(→e)
x(yy) : τ .
(→e)
Then (→i) must be applied. But the condition in (→i) prevents this,
because the two assumptions for y have diﬀerent types (see Remark
12.8).
12.31 (a) In Theorem 12.30, take H to be Hη. Then (Xλ)H ≡X by
9.11, so 12.30(a) and 12.30(b) together give the result.
(b) Let M ≡λxy.xy. Then (a→b)→a→b is a p.t. of M. Hence a
shorter type such as c→c cannot be assigned to M. But c→c is a p.t.
of I, and MHη
≡[x].([y].xy) ≡[x].x ≡I.
(c) For Hw and Hβ, MH is typable iﬀM is typable, and both have
the same p.t. In fact, for all environments Γ, Γ ⊢TA→
C MH :τ iﬀΓ ⊢TA→
λ
M :τ.
Proof-outline:
By 12.30(b), it is enough to prove that
Γ ⊢TA→
C
MH :τ
=⇒
Γ ⊢TA→
λ
M :τ.
(7)
We prove (7) by induction on lgh(M). The diﬃcult case is M ≡λx.P,
with MH ≡[x].(PH ).
By 9.23 for Hw and 9.27 for Hβ, [x].(PH ) is
functional. It is easy to see this implies τ is not an atom, so τ ≡ρ→σ.
We may assume x is not a subject in Γ. Then by rule (→e),
Γ, x:ρ ⊢TA→
C
(([x].PH )x):σ.
But ([x].PH )x ▷w PH by 2.21, so by 11.19, Γ, x:ρ ⊢TA→
C PH :σ. Hence
by the induction hypothesis,
Γ, x:ρ ⊢TA→
λ
P :σ,
and the conclusion of (7) follows by rule (→i).
14.10 A combinatory algebra has ≥2 members. But, if i = k or k = s
or s = i, we shall prove d = i for all d ∈D.
First, if i = k then, for all c, d ∈D, c • d = (i • c) • d = (k • c) • d = c.
In particular, taking c = i we get i • d = i and hence d = i • d = i.
Second, if k = s then, for all b, c, d ∈D, b • d = (k • b • c) • d =
(s • b • c) • d = b • d • (c • d). Taking b = k • i and c = i, this gives i =
k • i • d = b • d = b • d • (c • d) = k • i • d • (i • d) = i • (i • d) = d.

Answers to starred exercises
319
Third, if s = i then, for all b, c, d ∈D, b • d • (c • d) = s • b • c • d =
i • b • c • d = b • c • d. Taking b = k and c = i gives d = i.
15.9
Assume 15.3(a)–(c) and 15.8(a) or (b). Clearly 15.8(a) implies
15.3(f).
For 15.3(d), use induction on M. In the case M ≡λx.P the goal is
to prove [[λx.P]]ρ = [[λx.P]]σ. This comes from 15.8(b), since, for all
d ∈D,
[[λx.P]]ρ • d = [[P]][d/x]ρ by 15.3(c), = [[P]][d/x]σ
by induc. hyp.,
= [[λx.P]]σ • d by 15.3(c).
For 15.3(e): by Lemma A1.8 in Appendix A1, it can be assumed that
y ̸∈FV(xM) and neither x nor y is bound in M. By 15.8(b) it is enough
to prove [[λx.M]]ρ • d = [[λy.[y/x]M]]ρ • d for all ρ and all d ∈D. By
15.3(c), this is equivalent to
[[M]][d/x]ρ
=
[[[y/x]M]][d/y]ρ
(for all ρ and all d ∈D).
(8)
We prove (8) by induction on M.
In the case M ≡λv.P, we have
[y/x]M ≡λv.[y/x]P by the assumed restrictions on x, y. By 15.8(a) it
is enough to prove [[λv.P]][d/x]ρ •e = [[λv.[y/x]P]][d/y]ρ •e for all e ∈D.
By 15.3(c), this is equivalent to
[[P]][e/v][d/x]ρ
=
[[[y/x]P]][e/v][d/y]ρ.
(9)
But [e/v][d/x]ρ = [d/x][e/v]ρ since x ̸≡v, and similarly [e/v][d/y]ρ
= [d/y][e/v]ρ. And [[P]][d/x][e/v]ρ = [[[y/x]P]][d/y][e/v]ρ by the induction
hypothesis applied to P and [e/v]ρ. Hence (9) holds, and (8) follows.
(Note: we cannot use Lemma 15.10(a) to prove (8), because the proof
of 15.10(a) uses (e), which we are trying to prove here.)
15.15 If ⟨D, •, [[ ]]⟩is a λ-model, then, for all ρ, M, x ̸∈FV(M), d ∈D:
[[λx.Mx]]ρ • d = [[(λx.Mx)x]][d/x]ρ
by 15.3(b),
= [[Mx]][d/x]ρ
by 15.10(b),
= [[M]]ρ • d
by 15.3(b).
Hence, if ⟨D, •, [[ ]]⟩is extensional, then [[λx.Mx]]ρ = [[M]]ρ.
For the converse, let a•d = b•d for all d ∈D. Take any distinct x, u, v
and let ρ(u) = a and ρ(v) = b. Then [[ux]][d/x]ρ = a • d by 15.3(b), =
b • d by assumption, = [[vx]][d/x]ρ. So, by 15.3(f), [[λx.ux]]ρ = [[λx.vx]]ρ.
Hence, if ⟨D, •, [[ ]]⟩satisﬁes (η), then [[u]]ρ = [[v]]ρ, that is a = b.
16.4 (a) If b1 and b2 are l.u.b.s of X, then by 16.3(b) applied to both
we have b1 ⊑b2 and b2 ⊑b1. Hence b1 = b2 by anti-symmetry, 16.2(b).

320
Answers to starred exercises
(b) Every d ∈D is an u.b. of ∅, because (∀a ∈D)(a ∈∅⇒a ⊑d)
holds vacuously. Hence ⊥(iﬀit exists) is the least u.b. of ∅.
(c) Every u.b. b of Y is an u.b. of X, because if a ∈X then a ⊑some
d ∈Y and hence a ⊑b. Similarly, every u.b. of X is an u.b. of Y . Hence
X and Y have the same set (call it B) of u.b.s. But  X exists iﬀB has
a least member, and similarly for  Y . Hence result.
(d)
Let Y = ! 
Xj : j ∈J

and Z
=
  Xj : j ∈J

. First,
every u.b. b of Y is an u.b. of Z. Because, for every j, Xj ⊆Y so b is
an u.b. of Xj and hence b ⊒ Xj.
Conversely, every u.b. b of Z is an u.b. of Y . Because, if a ∈Y then
a ∈Xj for some j, so a ⊑ Xj which is in Z and hence is ⊑b.
Thus Y and Z have the same set of u.b.s; hence result.
16.11
Let φ : D →D′ be continuous and a ⊑b in D. Then {a, b}
is directed and {a, b} = b. By 16.10(b), φ(b) = {φ(a), φ(b)}. Hence
φ(a) ⊑φ(b).
16.12
In IN+, a ⊑b
⇐⇒
a = b or (a = ⊥and b ∈IN).
So the
only directed subsets of IN+ are singletons {⊥} or {n} or pairs {⊥, n}
(n ∈IN). Hence χ is continuous iﬀχ(⊥) ⊑χ(n) for all n ∈IN.
Thus χ is continuous ⇐⇒χ is monotonic. Also χ is continuous ⇐⇒
either χ(⊥) = ⊥or χ(a) has the same value for all a ∈IN+.
In the latter case, if this value is p ∈IN then χ = ψ
′
p. If χ(⊥) = ⊥,
then χ = φ+, where φ(n) = χ(n) if χ(n) ∈IN and φ(n) has no value if
χ(n) = ⊥.
16.13 If a, b ∈φ(X), then a = φ(e) and b = φ(f) for some e, f ∈X.
Since X is directed, we have e, f ⊑g for some g ∈X. Let c = φ(g).
Then c ∈φ(X) and a, b ⊑c since φ is monotonic.
16.25 (a) To prove φ0 continuous, we must prove φ0( X) = (φ0(X))
for all directed X ⊆D0. Now D0 = IN+, see 16.8. If X is a singleton,
then so is φ0(X) and the result is trivial. If not, then X = {⊥0, n} for
some n ∈IN, so  X = n, and φ0( X) = λλa ∈D0. n. Also φ0(X) =
{λλa ∈D0.⊥0, λλa ∈D0.n}, so  φ0(X) = λλa ∈D0. n.
To prove ψ0 continuous, we must prove ψ0( Y ) = (ψ0(Y )) for all
directed Y ⊆D1. That is, prove ( Y )(⊥0) =  {g(⊥0) : g ∈Y }. But
this equation is true by 16.18.
16.30 (a) Dn = [Dn−1 →Dn−1] and Dn−1 = [Dn−2 →Dn−2]. For all
a ∈Dn−1, kn(a) = λλb ∈Dn−2.ψn−2(a), which is a constant-function
and therefore continuous.
Also ψn−2(a) ∈Dn−2, therefore kn(a) ∈
[Dn−2 →Dn−2], i.e. kn(a) ∈Dn−1. Hence kn ∈(Dn−1 →Dn−1).

Answers to starred exercises
321
To prove kn ∈[Dn−1 →Dn−1], we must prove kn continuous. Let
X ⊆Dn−1 be directed. It is easy to prove kn monotonic, so by 16.13,
(kn(X)) exists ∈Dn−1. To prove kn( X) = (kn(X)): since they
are both functions we must prove that kn( X)(b) = ((kn(X)))(b) for
all b ∈Dn−2. But
kn( X)(b)
= ψn−2( X)
by deﬁnition of kn
= (ψn−2(X))
by continuity of ψn−2
=  
ψn−2(a) : a ∈X

by deﬁnition of ψn−2(X)
=  
kn(a)(b) : a ∈X

by deﬁnition of kn
=
  
kn(a) : a ∈X

(b)
by 16.18
=
  kn(X)

(b)
by deﬁnition of kn(X).
(b) To prove ψ1(k2) = ID0 , prove (∀a ∈D0)

ψ1(k2)(a) = a

, thus:
ψ1(k2)(a)
= ψ0(k2(φ0(a)))
by 16.27(b′)
= k2(φ0(a))(⊥0)
by 16.24(b)
= ψ0(φ0(a))
by deﬁnition of k2
= a
by 16.25(b).
Also ψ0(ψ1(k2)) = ⊥0; because, by above, ψ0(ψ1(k2)) = ψ0(ID0 ),
= ID0 (⊥0) by 16.24(b).
(c) To prove that ψn(kn+1) = kn, let a ∈Dn−1 and b ∈Dn−2. Then
ψn(kn+1)(a)(b)
= ψn−1(kn+1(φn−1(a))) (b)
by 16.27(b′)
= ψn−1

λλc ∈Dn−1. ψn−1(φn−1(a))

(b) by def. of kn+1
= ψn−1(λλc ∈Dn−1. a) (b)
by 16.28(b)
= ψn−2

(λλc ∈Dn−1. a)(φn−2(b))

by 16.27(b′) for ψn−1
= ψn−2(a)
= kn(a)(b)
by deﬁnition of kn.
A1.9 We have λxy.yx ≡λx.(λy.yx) ▷1α λy.[y/x](λy.yx) ≡λyz.zy,
where z is chosen by Chapter 1’s Deﬁnition 1.12(g). For this single α-
contraction we need two steps to reverse it.
A2.4 Choose P ≡(λx.R1)R2, where R1 ≡(λy.xyz)w, R2 ≡(λu.u)v.
Choose M ≡[R2/x]R1 ≡(λy.R2yz)w. Then P ▷1par M by contracting
P itself. Choose N ≡(λx.xwz)v. Then P ▷1par N by contracting R1,
R2 simultaneously. The only terms to which N can be reduced are N
and vwz. Neither of these can be obtained from M by non-overlapping
simultaneous contractions.


References
[ABD06] F. Alessi, F. Barbanera and M. Dezani. Intersection types and lambda
models. Theoretical Computer Science, 355:108–126, 2006.
[Acz88] P. Aczel.
Non-Well-Founded Sets.
CSLI (Centre for the Study of
Language and Information), Ventura Hall, Stanford University, Stanford,
CA 94305-4115, USA, 1988.
[ADH04] F. Alessi, M. Dezani and F. Honsell. Inverse limit models as ﬁlter
models. In D. Kesner, F. van Raamsdonk and J. Wells, editors, HOR’04,
Proceedings of Workshop on Higher Order Rewriting, 2004, pages 3–25,
Aachen, Germany, 2004. Technische Hochschule Aachen. AIB2004-03,
ISSN 0935-3232.
[AJ94] S. Abramsky and A. Jung. Domain theory. In S. Abramsky, D. Gab-
bay and T. Maibaum, editors, Handbook of Logic in Computer Science,
volume 3, pages 1–168. Clarendon Press, Oxford, England, 1994. Also
available online.
[AL91] A. Asperti and G. Longo. Categories, Types and Structures. An Intro-
duction to Category Theory for the Working Computer Scientist. M.I.T.
Press, Cambridge, Mass., USA, 1991.
[Alt93] T. Altenkirch. A formalization of the strong normalization proof for
System F in LEGO. In M. Bezem and J. F. Groote, editors, Typed Lam-
bda Calculi and Applications, volume 664 of Lecture Notes in Computer
Science, pages 13–28. Springer-Verlag, Berlin, 1993.
[And65] P. B. Andrews. A Transﬁnite Type Theory with Type Variables. North-
Holland Co., Amsterdam, 1965.
[And02] P. B. Andrews. An Introduction to Mathematical Logic and Type The-
ory: to Truth Through Proof. Kluwer, Dordrecht, Netherlands, 2002. 2nd
edn. (1st was 1986, Academic Press, USA).
[Bac78] J. Backus.
Can programming be liberated from the von Neumann
style? Communications of the ACM, 21(8):613–641, 1978.
[Bar73] H. P. Barendregt. Combinatory logic and the axiom of choice. Inda-
gationes Mathematicae 35: 203–221, 1973. Journal also appears as Proc.
Nederl. Akad. van Wetenschappen.
[Bar74] H. P. Barendregt. Pairing without conventional restraints. Zeitschrift
f¨ur Mathematische Logik und Grundlagen der Mathematik, 20:289–306,
1974. Journal now called Mathematical Logic Quarterly.
323

324
References
[Bar84] H. P. Barendregt. The Lambda Calculus, its Syntax and Semantics.
North-Holland Co., Amsterdam, 1984. 2nd (revised) edn., reprinted 1997
(1st edn. was 1981).
[Bar92] H. P. Barendregt. Lambda calculi with types. In S. Abramsky, D. Gab-
bay and T. Maibaum, editors, Handbook of Logic in Computer Science,
Volume 2, Background: Computational Structures, pages 117–309. Claren-
don Press, Oxford, England, 1992.
[BB79] J. Baeten and B. Boerboom. Ωcan be anything it shouldn’t be. Inda-
gationes Mathematicae, 41:111–120, 1979. Journal also appears as Proc.
Nederl. Akad. van Wetenschappen.
[BCD83] H. P. Barendregt, M. Coppo and M. Dezani. A ﬁlter lambda model
and the completeness of type assignment.
Journal of Symbolic Logic,
48:931–940, 1983.
[BDPR79] C. B¨ohm, M. Dezani, P. Peretti, and S. Ronchi. A discrimination
algorithm inside λβ-calculus. Theoretical Computer Science, 8:271–291,
1979.
[BDS] H. P. Barendregt, W. Dekkers, and R. Statman. Typed Lambda Calculus,
Volume 1. In preparation.
[Ber93] S. Berardi. Encoding of data types in pure construction calculus: a
semantic justiﬁcation. In H. Huet and G. Plotkin, editors, Logical Envi-
ronments, pages 30–60. Cambridge University Press, 1993.
[Ber00] C. Berline. From computation to foundations via functions and ap-
plication: the λ-calculus and its webbed models. Theoretical Computer
Science, 249:81–161, 2000.
[Ber05] C. Berline. Graph models of λ-calculus at work, and variations. At
website, 2005. Web address hal.ccsd.cnrs.fr/ccsd-00004473/en/.
[Bet99] I. Bethke. Annotated Bibliography of Lambda Calculi, Combinatory
Logics and Type Theory. At website, 1999. File type ‘.ps’. Web address
www.science.uva.nl/˜inge/Bib/.
[BG66] C. B¨ohm and W. Gross. Introduction to the CUCH. In E. Caianiello,
editor, Automata Theory, pages 35–65. Academic Press, New York, 1966.
[BHS89] M. W. Bunder, J. R. Hindley and J. P. Seldin. On adding (ξ) to weak
equality in combinatory logic.
Journal of Symbolic Logic, 54:590–607,
1989.
[BK80] H. P. Barendregt and K. Koymans. Comparing some classes of lambda-
calculus models. In Hindley and Seldin [HS80], pages 287–301.
[BL80] H. P. Barendregt and G. Longo. Equality of λ-terms in the model Tω .
In Hindley and Seldin [HS80], pages 303–337.
[BL84] K. Bruce and G. Longo.
A note on combinatory algebras and their
expansions. Theoretical Computer Science, 31:31–40, 1984.
[BN98] F. Baader and T. Nipkow. Term Rewriting and All That. Cambridge
University Press, England, 1998.
[B¨oh68] C. B¨ohm. Alcune propriet`a delle forme β-η-normali nel λ-K-calcolo.
Pubblicazione no. 696, Istituto per le Applicazioni del Calcolo, C.N.R.,
Roma, 1968.
[Bru70] N. G. de Bruijn.
The mathematical language AUTOMATH.
In
M. Laudet, D. Lacombe, L. Nolin and M. Sch¨utzenberger, editors, Sym-
posium on Automatic Demonstration, IRIA Versailles 1968, volume 125
of Lecture Notes in Mathematics, pages 29–61. Springer-Verlag, Berlin,
1970.

References
325
[Bru72] N. G. de Bruijn. Lambda calculus notation with nameless dummies,
a tool for automatic formula manipulation. Indagationes Mathematicae,
34:381–392, 1972.
[Bun02] M. W. Bunder. Combinators, proofs and implicational logics. In D. M.
Gabbay and F. Guenthner, editors, Handbook of Philosophical Logic, vol-
ume 6, pages 229–286. Springer (Kluwer), Berlin, 2002.
[Bye82a] R. Byerly. An invariance notion in recursion theory. Journal of Sym-
bolic Logic, 47:48–66, 1982.
[Bye82b] R. Byerly.
Recursion theory and the lambda calculus.
Journal of
Symbolic Logic, 47:67–83, 1982.
[Car86] L. Cardelli. A polymorphic λ-calculus with Type : Type. Technical
report, Systems Research Center of Digital Equipment Corporation, Palo
Alto, California, May 1986.
[CC90] F. Cardone and M. Coppo. Two extensions of Curry’s type inference
system. In P. Odifreddi, editor, Logic and Computer Science, volume 31
of APIC Studies in Data Processing, pages 19–76. Academic Press, USA,
1990.
[CC91] F. Cardone and M. Coppo. Type inference with recursive types: syntax
and semantics. Information and Computation, 92(1):48–80, 1991.
[CD78] M. Coppo and M. Dezani. A new type assignment for λ-terms. Archiv
f¨ur Mathematische Logik, 19:139–156, 1978. Journal now called Archive
for Mathematical Logic.
[CDHL84] M. Coppo, M. Dezani, F. Honsell and G. Longo. Extended type
structures and ﬁlter lambda models. In G. Lolli, G. Longo and A. Mar-
cja, editors, Logic Colloquium ’82, pages 241–262. North-Holland Co.,
Amsterdam, 1984.
[CDS79] M. Coppo, M. Dezani and P. Sall´e.
Functional characterization of
some semantic equalities inside λ-calculus.
In H. Maurer, editor, Au-
tomata, Languages and Programming, Sixth Colloquium, volume 71 of
Lecture Notes in Computer Science, pages 133–146. Springer-Verlag,
Berlin, 1979.
[CDV81] M. Coppo, M. Dezani, and B. Venneri. Functional characters of solv-
able terms. Zeitschrift f¨ur Mathematische Logik, 27:45–58, 1981. Journal
now called Mathematical Logic Quarterly.
[CDZ87] M. Coppo, M. Dezani, and M. Zacchi. Type theories, normal forms
and D∞-lambda models. Information and Computation, 72:85–116, 1987.
[CF58] H. B. Curry and R. Feys. Combinatory Logic, Volume I. North-Holland
Co., Amsterdam, 1958. 1st. edn. (3rd edn. 1974).
[CH88] T. Coquand and G. Huet. The calculus of constructions. Information
and Computation, 76:95–120, 1988.
[C¸ H98] N. C¸ aˇgman and J. R. Hindley. Combinatory weak reduction in lambda
calculus. Theoretical Computer Science, 198:239–247, 1998.
[CHS72] H. B. Curry, J. R. Hindley and J. P. Seldin.
Combinatory Logic,
Volume II. North-Holland Co., Amsterdam, 1972.
[Chu36a] A. Church. A note on the Entscheidungsproblem. Journal of Symbolic
Logic, 1:40–41, 1936. See also correction in pp. 101–102.
[Chu36b] A. Church.
An unsolvable problem of elementary number theory.
American Journal of Mathematics, 58:345–363, 1936.
[Chu40] A. Church. A formulation of the simple theory of types. Journal of
Symbolic Logic, 5:56–68, 1940.

326
References
[Chu41] A. Church. The Calculi of Lambda Conversion. Princeton University
Press, Princeton, New Jersey, USA, 1941.
[Coh87] D. E. Cohen. Computability and Logic. Ellis-Horwood, England, 1987.
[CR36] A. Church and J. B. Rosser. Some properties of conversion. Transac-
tions of the American Mathematical Society, 39:472–482, 1936.
[Cro94] R. Crole. Categories for Types. Cambridge University Press, England,
1994.
[Cur30] H. B. Curry. Grundlagen der kombinatorischen Logik. American Jour-
nal of Mathematics, 52:509–536, 789–834, 1930.
[Cur34] H. B. Curry. Functionality in combinatory logic. Proceedings of the
National Academy of Sciences of the USA, 20:584–590, 1934.
[Cur69] H. B. Curry. Modiﬁed basic functionality in combinatory logic. Di-
alectica, 23:83–92, 1969.
[Daa94] D. T. van Daalen. The language theory of Automath, Chapter 1 Sec-
tions 1–5. In Nederpelt et al. [NGdV94], pages 163–200. From author’s
thesis, University of Eindhoven 1980.
[Dal97] D. van Dalen. Logic and Structure. Springer-Verlag, Berlin, 1997. 3rd
edn.
[Ded87] Richard Dedekind. Was sind und was sollen die Zahlen?
Friedrich
Vieweg & Sohn, Braunschweig, 1887. (10th edn. 1965).
[End00] H. B. Enderton. A Mathematical Introduction to Logic. Harcourt/
Academic Press, New York, 2000. 2nd edn.
[Eng81] E. Engeler. Algebras and combinators. Algebra Universalis, 13:389–
392, 1981.
[Fia05] J. L. Fiadero. Categories for Software Engineering. Springer-Verlag,
Berlin, 2005.
[Fit58] F. B. Fitch. Representation of sequential circuits in combinatory logic.
Philosophy of Science, 25:263–279, 1958.
[Fre93] G. Frege. Grundgesetze der Arithmetik. Verlag Hermann Pohle, Jena,
1893. Two vols. Reprinted 1962 as one vol. by Georg Olms, Hildesheim,
Germany, and 1966 as No. 32 in series Olms Paperbacks.
[Fri71] H Friedman. Axiomatic recursive function theory. In R. Gandy and
C. E. M. Yates, editors, Logic Colloquium ’69, pages 113–137. North-
Holland Co., Amsterdam, 1971.
[Geu93] H. Geuvers. Logic and Type Systems. Ph.D. thesis, Catholic University
of Nijmegen, 1993.
[Geu01] H. Geuvers. Induction is not derivable in second order dependent type
theory. In S. Abramsky, editor, Proceedings of Typed Lambda Calculus and
Applications (TLCA 2001), Krakow, Poland, May 2001, volume 2044 of
Lecture Notes in Computer Science, pages 166–181. Springer, 2001.
[GHK+ 03] G. Gierz, K. Hofmann, K. Keimel, J. Lawson, M. Mislove and
D. Scott. Continuous lattices and domains. In Encyclopedia of Math-
ematics and its Applications, volume 93. Cambridge University Press,
England, 2003.
[Gir71] J.-Y. Girard. Une extension de l’interpr´etation de G¨odel `a l’analyse, et
son application `a l’´elimination des coupures dans l’analyse et la th´eorie
des types. In J. E. Fenstad, editor, Proceedings of the Second Scandinavian
Logic Symposium, pages 63–92. North-Holland Co., Amsterdam, 1971.
[Gir72] J.-Y. Girard. Interpr´etation fonctionnelle et ´elimination des coupures
de l’arithm´etique d’ordre sup´erieur. Ph.D. thesis, University of Paris VII,
France, 1972.

References
327
[GLT89] J.-Y. Girard, Y. Lafont, and P. Taylor. Proofs and Types. Cambridge
University Press, England, 1989.
[G¨od58] K. G¨odel. ¨Uber eine bisher noch nicht ben¨utzte Erweiterung des ﬁniten
Standpunktes. Dialectica, 12:280–287, 1958. English translation: On a
hitherto unexploited extension of the ﬁnitary standpoint, in Journal of
Philosophical Logic 9 (1980) pp. 133–142. Two other English translations
with notes: pp. 217–251, 271–280 of Kurt G¨odel Collected Works, Vol. II,
Publications 1938–1974, edited by S. Feferman et al., Oxford University
Press 1990.
[Gra05] C. Grabmeyer. Relating Proof Systems for Recursive Types. Ph.D.
thesis, Free University, Amsterdam, 2005.
[Gun92] C. Gunter. Semantics of Programming Languages. M.I.T. Press, Cam-
bridge, Massachusetts, USA, 1992.
[Han04] C. Hankin. An Introduction to Lambda Calculi for Computer Scien-
tists. King’s College Publications, London, England, 2004. Revised edn.
of Lambda Calculi, Clarendon Press, Oxford, 1994.
[Hen50] L. Henkin. Completeness in the theory of types. Journal of Symbolic
Logic, 15:81–91, 1950.
[HHP87] R. Harper, F. Honsell and G. Plotkin. A framework for deﬁning logics.
In Proceedings Second Symposium of Logic in Computer Science (Ithaca,
NY), pages 194–204. IEEE, 1987.
[Hin64] J. R. Hindley. The Church-Rosser Theorem and a Result in Combina-
tory Logic. Ph.D. thesis, University of Newcastle upon Tyne, England,
1964.
[Hin67] J. R. Hindley. Axioms for strong reduction in combinatory logic. Jour-
nal of Symbolic Logic, 32:224–236, 1967.
[Hin69] J. R. Hindley. The principal type-scheme of an object in combinatory
logic.
Transactions of the American Mathematical Society, 146:29–60,
1969.
[Hin77] J. R. Hindley. Combinatory reductions and lambda reductions com-
pared. Zeitschrift f¨ur Mathematische Logik, 23:169–180, 1977. Journal
now called Mathematical Logic Quarterly.
[Hin78] J. R. Hindley. Reductions of residuals are ﬁnite. Transactions of the
American Mathematical Society, 240:345–361, 1978.
[Hin79] J. R. Hindley. The discrimination theorem holds for combinatory weak
reduction. Theoretical Computer Science, 8:393–394, 1979.
[Hin92] J. R. Hindley. Types with intersection, an introduction. Formal Aspects
of Computing, 4:470–486, 1992.
[Hin97] J. R. Hindley. Basic Simple Type Theory. Cambridge University Press,
England, 1997.
[HL70] J. R. Hindley and B. Lercher. A short proof of Curry’s normal form
theorem. Proceedings of the American Mathematical Society, 24:808–810,
1970.
[HL80] J. R. Hindley and G. Longo. Lambda-calculus models and extensional-
ity. Zeitschrift f¨ur Mathematische Logik, 26:289–310, 1980. Journal now
called Mathematical Logic Quarterly.
[HLS72] J. R. Hindley, B. Lercher and J. P. Seldin. Introduction to Combinatory
Logic. Cambridge University Press, England, 1972. Also Italian (revised)
edn: Introduzione alla Logica Combinatoria, Boringhieri, Torino, 1975.
[How80] W. A. Howard. The formulæ-as-types notion of construction. In Hind-
ley and Seldin [HS80], pages 479–490. Manuscript circulated 1969.

328
References
[HS80] J. R. Hindley and J. P. Seldin, editors. To H. B. Curry, Essays on
Combinatory Logic, Lambda Calculus and Formalism. Academic Press,
London, 1980.
[HS86] J. R. Hindley and J. P. Seldin. Introduction to Combinators and λ-
calculus. Cambridge University Press, England, 1986.
[Hue93] G. Huet. An analysis of B¨ohm’s theorem. Theoretical Computer Sci-
ence, 121:154–167, 1993.
[Hue94] G. Huet. Residual theory in λ-calculus: a formal development. Journal
of Functional Programming, 4:371–394, 1994.
[Hyl76] J. M. E. Hyland. A syntactic characterization of the equality in some
models for the lambda calculus.
Journal of the London Mathematical
Society, Series 2, 12:361–370, 1976.
[Jac99] B. Jacobs. Categorical Logic and Type Theory. North-Holland Co.,
Amsterdam, 1999.
[Kel55] J. L. Kelley. General Topology. Van Nostrand, New York, 1955.
[Kle36] S. C. Kleene.
λ-deﬁnability and recursiveness.
Duke Mathematical
Journal, 2:340–353, 1936.
[Kle52] S. C. Kleene. Introduction to Metamathematics. Van Nostrand, New
York, 1952.
[KLN04] F. Kamareddine, T. Laan and R. Nederpelt. A modern Perspective
on Type Theory: from its Origins until Today. Kluwer, Dordrecht, Boston
and London, 2004.
[Klo80] J. W. Klop. Combinatory Reduction Systems. Ph.D. thesis, University
of Utrecht, 1980. Published by Mathematisch Centrum, 413 Kruislaan,
Amsterdam.
[Klo92] J. W. Klop. Term rewriting systems. In S. Abramsky, D. Gabbay, and
T. Maibaum, editors, Handbook of Logic in Computer Science, Volume 2:
Background, Computational Structures, pages 1–116. Oxford University
Press, England, 1992.
[Koy82] C. P. J. Koymans. Models of the lambda calculus. Information and
Control, 52:306–332, 1982. (Journal now called Information and Compu-
tation).
[Koy84] C. P. J. Koymans.
Models of the Lambda Calculus.
Ph.D. thesis,
University of Utrecht, The Netherlands, 1984.
[KR95] F. Kamareddine and A. Rios. A λ-calculus `a la de Bruijn with explicit
substitutions.
In M. Hermenegildo and S. D. Swierstra, editors, Pro-
gramming Languages, Implementations, Logics and Programs, 7th Inter-
national Symposium, volume 982 of Lecture Notes in Computer Science,
pages 45–62. Springer-Verlag, Berlin, 1995.
[Kri93] J.-L. Krivine.
Lambda-Calculus, Types and Models.
Ellis-Horwood,
U.S.A. and Prentice-Hall, U.K., 1993.
English translation of Lambda-
calcul, Types et Mod`eles, Masson, Paris 1990.
[KvOvR93] J. W. Klop, V. van Oostrom, and F. van Raamsdonk. Combina-
tory reduction systems: introduction and survey. Theoretical Computer
Science, 121(1–2):279–308, 1993.
[Lam80] J. Lambek. From λ-calculus to cartesian closed categories. In Hindley
and Seldin [HS80], pages 375–402.
[Lan65] P. J. Landin.
A correspondence between ALGOL 60 and Church’s
lambda notation. Communications of the ACM, 8:89–101, 158–165, 1965.
[Lan66] P. J. Landin. The next 700 programming languages. Communications
of the ACM, 9(3):157–166, 1966.

References
329
[L¨au65] H. L¨auchli.
Intuitionistic propositional calculus and deﬁnably non-
empty terms. Journal of Symbolic Logic, 30:263, 1965. Abstract only.
[L¨au70] H. L¨auchli. An abstract notion of realizability for which intuitionis-
tic predicate calculus is complete. In A. Kino, J. Myhill and R. Vesley,
editors, Intuitionism and Proof Theory, pages 227–234. North-Holland
Co., Amsterdam, 1970.
Proceedings of conference at Buﬀalo, N.Y.
1968.
[Ler63] B. Lercher.
Strong Reduction and Recursion in Combinatory Logic.
Ph.D. thesis, Mathematics Department, Pennsylvania State University,
USA, 1963.
[Ler67a] B. Lercher. The decidability of Hindley’s axioms for strong reduction.
Journal of Symbolic Logic, 32:237–239, 1967.
[Ler67b] B. Lercher. Strong reduction and normal form in combinatory logic.
Journal of Symbolic Logic, 32:213–223, 1967.
[Ler76] B. Lercher. Lambda-calculus terms that reduce to themselves. Notre
Dame Journal of Formal Logic, 17:291–292, 1976.
[LM84] G. Longo and S. Martini. Computability in higher types and the univer-
sal domain P ω. In M. Fontet and K. Mehlhorn, editors, STACS 84, Sym-
posium of Theoretical Aspects of Computer Science, volume 166 of Lecture
Notes in Computer Science, pages 186–197. Springer-Verlag, Berlin, 1984.
[LM91] G. Longo and E. Moggi. Constructive natural deduction and its ω-set
interpretation. Mathematical Structures in Computer Science, 1(2):215–
254, 1991.
[Lon83] G. Longo.
Set-theoretical models of λ-calculi: theories, expansions,
isomorphisms. Annals of Mathematical Logic, 24:153–188, 1983. Journal
now called Annals of Pure and Applied Logic.
[LS86] J. Lambek and P. J. Scott. Introduction to Higher Order Categorical
Logic. Cambridge University Press, England, 1986.
[Luo90] Z. Luo. An extended calculus of constructions. Ph.D. thesis, Univerisity
of Edinburgh, 1990.
[Mac71] S. MacLane. Categories for the Working Mathematician. Springer-
Verlag, Berlin, 1971.
[MBP91] R. K. Meyer, M. W. Bunder and L. Powers. Implementing the “fool’s
model” of combinatory logic. Journal of Automated Reasoning, 7:597–
630, 1991.
[McC60] J. McCarthy. Recursive functions of symbolic expressions and their
computation by machine.
Communications of the ACM, 3:184–195,
1960.
[Men97] E. Mendelson.
Introduction to Mathematical Logic.
Chapman and
Hall, New York, 1997. 4th edn.
[Mey82] A. R. Meyer. What is a model of the lambda calculus?
Informa-
tion and Control, 52:87–122, 1982. Journal now called Information and
Computation.
[Mez89] M. Mezghiche. On pseudo-Cβ-normal form in combinatory logic. The-
oretical Computer Science, 66:323–331, 1989.
[Mic88] G. Michaelson. An Introduction to Functional Programming through
Lambda Calculus. Addison-Wesley, England and USA, 1988.
[Mil78] R. Milner. A theory of type polymorphism in programming. Journal
of Computer and System Sciences, 17:348–375, 1978.
[Mit96] J. C. Mitchell. Foundations for programming Languages. M.I.T. Press,
Cambridge, Massachusetts, USA, 1996.

330
References
[ML75] P. Martin-L¨of. An intuitionistic theory of types: predicative part. In
H. E. Rose and J. C. Shepherdson, editors, Logic Colloquium ’73, pages
73–118, North-Holland Co., Amsterdam, 1975.
[Mos90] P. Mosses. Denotational semantics. In J. van Leeuwen, editor, Hand-
book of Theoretical Computer Science, Volume B: Formal Methods and
Semantics, pages 575–631. Elsevier, Amsterdam and M.I.T. Press, Cam-
bridge, Massachusetts, USA, 1990.
[NG94] R. P. Nederpelt and J. H. Geuvers. Twenty-Five Years of Automath
Research. In Nederpelt et al. [NGdV94], pages 3–54.
[NGdV94] R. P. Nederpelt, J. H. Geuvers and R. C. de Vrijer, editors. Selected
Papers on Automath. Elsevier, Amsterdam, 1994.
[Pie91] B. C. Pierce. Basic Category Theory for Computer Scientists. M.I.T.
Press, Cambridge, Massachusetts, USA, 1991.
[Pie02] B. C. Pierce. Types and Programming Languages. M.I.T. Press, Cam-
bridge, Massachusetts, USA, 2002.
[Plo74] G. D. Plotkin. The λ-calculus is ω-incomplete. Journal of Symbolic
Logic, 39:313–317, 1974.
[Plo78] G. D. Plotkin. T ω as a universal domain. Journal of Computer and
System Sciences, 17:209–236, 1978.
[Plo93] G. D. Plotkin. Set-theoretical and other elementary models of the λ-
calculus.
Theoretical Computer Science, 121:351–409, 1993.
(Updated
version of a paper informally circulated in 1972).
[Plo94] G. D. Plotkin. A semantics for static type-inference. Information and
Computation, 109:256–299, 1994.
[Pol93] R. Pollack.
Closure under alpha-conversion.
In H. Barendregt and
T. Nipkow, editors, Types for Proofs and Programs, volume 806 of Lecture
Notes in Computer Science, pages 313–332. Springer-Verlag, Berlin, 1993.
[Pot80] G. Pottinger. A type assignment for the strongly normalizable λ-terms.
In Hindley and Seldin [HS80], pages 561–579.
[Pra65] D. Prawitz.
Natural Deduction.
Almqvist and Wiksell, Stockholm,
1965. Reissued in 2006, with new preface and errata-list, by Dover Inc.,
Mineola, N.Y., USA.
[PS95] D. Pigozzi and A. Salibra. Lambda abstraction algebras: representation
theorems. Theoretical Computer Science, 140:5–52, 1995.
[PS98] D. Pigozzi and A. Salibra. Lambda abstraction algebras: coordinatizing
models of lambda calculus. Fundamenta Informaticae, 33:149–200, 1998.
[Rau06] W. Rautenberg.
A Concise Introduction to Mathematical Logic.
Springer-Verlag, Berlin, 2006.
[RC90] S. Reeves and M. Clarke. Logic for Computer Science. Addison-Wesley
Co., U.S.A., 1990.
[RdL92] G. R. Renardel de Lavalette. Strictness analysis via abstract inter-
pretation for recursively deﬁned types. Information and Computation,
99(2):154–177, 1992.
[R´ev88] G. R´ev´esz. Lambda-calculus, Combinators and Functional Program-
ming. Cambridge University Press, England, 1988.
[Rey74] J. C. Reynolds. Towards a theory of type structure. In B. Robinet,
editor, Programming Symposium, volume 19 of Lecture Notes in Computer
Science, pages 408–425. Springer-Verlag, Berlin, 1974.
[Rey98] J. C. Reynolds. Theories of Programming Languages. Cambridge Uni-
versity Press, England, 1998.

References
331
[Rez82] A. Rezus. A Bibliography of Lambda-Calculi, Combinatory Logics and
Related Topics.
Mathematisch Centrum, 413 Kruislaan, Amsterdam,
1982. ISBN 90-6196234-X.
[Rim80] M. von Rimscha. Mengentheoretische Modelle des λK-Kalk¨uls. Archiv
f¨ur Mathematische Logik, 20:65–74, 1980. Journal now called Archive for
Mathematical Logic.
[Ros35] J. B. Rosser. A mathematical logic without variables, Part 1. Annals of
Mathematics, Series 2, 36:127–150, 1935. Also Part 2: Duke Mathematical
Journal 1 (1935), pp. 328–355.
[Ros50] P. Rosenbloom. The Elements of Mathematical Logic. Dover Inc., New
York, 1950.
[Ros55] J. B. Rosser. Deux Esquisses de Logique. Gauthier-Villars, Paris, and
Nauwelaerts, Louvain, 1955.
[Ros73] B. K. Rosen.
Tree manipulating systems and Church-Rosser theo-
rems. Journal of the Association for Computing Machinery, 20:160–187,
1973.
[Sal78] P. Sall´e. Une extension de la th´eorie des types en λ-calcul. In G. Ausiello
and C. B¨ohm, editors, Automata, Languages and Programming, Fifth
Colloquium, volume 62 of Lecture Notes in Computer Science, pages 398–
410. Springer-Verlag, Berlin, 1978.
[Sal00] A. Salibra. On the algebraic models of lambda calculus. Theoretical
Computer Science, 249:197–240, 2000.
[San67] L. E. Sanchis. Functionals deﬁned by recursion. Notre Dame Journal
of Formal Logic, 8:161–174, 1967.
[San79] L. E. Sanchis.
Reducibilities in two models for combinatory logic.
Journal of Symbolic Logic, 44:221–234, 1979.
[Sch24] M. Sch¨onﬁnkel. ¨Uber die Bausteine der mathematischen Logik. Mathe-
matische Annalen, 92:305–316, 1924. English translation: On the building
blocks of mathematical logic, in From Frege to G¨odel, edited by J. van Hei-
jenoort, Harvard University Press, USA 1967, pp. 355–366.
[Sch65] D. E. Schroer.
The Church-Rosser Theorem.
Ph.D. thesis, Cornell
University, 1965. Informally circulated 1963.
[Sch76] H. Schwichtenberg. Deﬁnierbare Funktionen im λ-Kalk¨ul mit Typen.
Archiv f¨ur Mathematische Logik, 17:113–114, 1976.
[Sco70a] D. S. Scott. Constructive validity. In M. Laudet, D. Lacombe, L. No-
lin and M. Sch¨utzenberger, editors, Symposium on Automatic Demon-
stration, volume 125 of Lecture Notes in Mathematics, pages 237–275.
Springer-Verlag, Berlin, 1970. (Proceedings of a conference in Versailles
1968).
[Sco70b] D. S. Scott. Outline of a mathematical theory of computation. In
Proceedings of the Fourth Annual Princeton Conference on Information
Sciences and Systems, pages 169–176. Department of Electrical Engineer-
ing, Princeton University, 1970.
[Sco72] D. S. Scott. Continuous lattices. In F. W. Lawvere, editor, Toposes,
Algebraic Geometry and Logic, volume 274 of Lecture Notes in Mathemat-
ics, pages 97–136, Berlin, 1972. Springer-Verlag. (Informally circulated
in 1970).
[Sco73] D. S. Scott. Models for various type-free calculi. In P. Suppes and
others, editors, Logic, Methodology and Philosophy of Science IV, pages
157–187. North-Holland Co., Amsterdam, 1973. (Proceedings of a con-
ference in 1971).

332
References
[Sco76] D. S. Scott.
Data types as lattices.
SIAM Journal on Computing,
5:522–587, 1976.
[Sco80a] D. S. Scott.
Lambda calculus: some models, some philosophy.
In
J. Barwise et al., editors, The Kleene Symposium, pages 223–265. North-
Holland Co., Amsterdam, 1980.
[Sco80b] D. S. Scott. Relating theories of the λ-calculus. In Hindley and Seldin
[HS80], pages 403–450.
[Sco82a] D. S. Scott.
Domains for denotational semantics.
In M. Nielsen
and E. Schmidt, editors, Automata, Languages and Programming, Ninth
International Colloquium, volume 140 of Lecture Notes in Computer Sci-
ence, pages 577–613. Springer-Verlag, Berlin, 1982.
[Sco82b] D. S. Scott.
Lectures on a mathematical theory of computation.
In M. Broy and G. Schmidt, editors, Theoretical Foundations of Pro-
gramming Methodology. D. Reidel Co., Dordrecht, The Netherlands,
1982.
[Sco93] D. S. Scott. A type-theoretical alternative to ISWIM, CUCH, OWHY.
Theoretical Computer Science, 121:411–440, 1993. (Informally circulated
in 1969).
[Sel77] J. P. Seldin. A sequent calculus for type assignment. Journal of Symbolic
Logic, 42:11–28, 1977.
[Sel79] J. P. Seldin. Progress report on generalized functionality. Annals of
Mathematical Logic, 17:29–59, 1979. Condensed from manuscript Theory
of Generalized Functionality, informally circulated in 1975. Journal now
called Annals of Pure and Applied Logic.
[Sel97] J. P. Seldin. On the proof theory of Coquand’s calculus of constructions.
Annals of Pure and Applied Logic, 83:23–101, 1997.
[Sel00a] J. P. Seldin. A Gentzen-style sequent calculus of constructions with
expansion rules. Theoretical Computer Science, 243:199–215, 2000.
[Sel00b] J. P. Seldin. On lists and other abstract data types in the calculus of
constructions. Mathematical Structures in Computer Science, 10:261–276,
2000.
[Sho01] J. R. Shoenﬁeld. Mathematical Logic. A. K. Peters, USA, 2001. (1st
edn. by Addison-Wesley 1967).
[Sim00] H. Simmons.
Derivation and Computation.
Cambridge University
Press, England, 2000.
[Smu85] R. M. Smullyan. To Mock a Mocking-Bird. Alfred Knopf Inc., U.S.A.,
1985. Also Oxford University Press, England, 1990.
[Ste72] S. Stenlund. Combinators, λ-terms and Proof Theory. D. Reidel Co.,
Dordrecht, The Netherlands, 1972.
[Sto77] J. Stoy. Denotational Semantics: The Scott–Strachey Approach to Pro-
gramming Language Theory.
M.I.T. Press, Cambridge, Massachusetts,
USA, 1977.
[Sto88] A. Stoughton. Substitution revisited. Theoretical Computer Science,
59(3):317–325, 1988.
[Str68] H. R. Strong.
Algebraically generalized recursive function theory.
I.B.M. Journal of Research and Development, 12:465–475, 1968.
[SU06] M. H. Sorensen and P. Urzyczyn. Lectures on the Curry–Howard Iso-
morphism. Elsevier, Amsterdam, 2006.
[Tai67] W. W. Tait. Intensional interpretations of functionals of ﬁnite type.
Journal of Symbolic Logic, 32:198–212, 1967.

References
333
[Tak91] Masako Takahashi. Theory of Computation, Computability and Lam-
bda Calculus. Kindai Kagaku Sha, Tokyo, 1991. In Japanese.
[Tak95] Masako Takahashi. Parallel reductions in λ-calculus. Information and
Computation, 118:120–127, 1995. Earlier version: J. Symbolic Computa-
tion 7 (1989), 113–123.
[TD88] A. S. Troelstra and D. van Dalen. Constructivism in Mathematics, an
Introduction. North-Holland Co., Amsterdam, 1988. (Vols. 1 and 2).
[Tro73] A. S. Troelstra, editor. Metamathematical Investigations of Intuitionis-
tic Arithmetic and Analysis, volume 344 of Lecture Notes in Mathematics.
Springer-Verlag, Berlin, 1973. (Also 2nd edn. 1993, publ. as Preprint no.
X-93-05 by Institute for Logic, Language and Computation, University of
Amsterdam. Plantage Muidergracht 24, 1018TV Amsterdam).
[TS00] A. S. Troelstra and H. Schwichtenberg. Basic Proof Theory. Cambridge
University Press, England, 2000.
[Tur76] D. A. Turner. SASL Language Manual. University of St. Andrews,
Scotland, 1976.
[VB03] R. Vestergaard and J. Brotherton. A formalised ﬁrst-order conﬂuence
proof for the λ-calculus using one-sorted variable names. Information and
Computation, 183:212–244, 2003.
[vBJ93] L. S. van Benthem Jutting. Typing in Pure Type Systems. Information
and Computation, 105:30–41, 1993.
[Wad76] C. P. Wadsworth. The relation between computational and denota-
tional properties for Scott’s D∞models of the lambda-calculus. SIAM
Journal of Computing, 5:488–521, 1976.
[Wad78] C. P. Wadsworth. Approximate reduction and lambda-calculus mod-
els. SIAM Journal of Computing, 7:337–356, 1978.
[Wag69] E. Wagner. Uniformly reﬂexive structures. Transactions of the Amer-
ican Mathematical Society, 144:1–41, 1969.
[Win01] G. Winskel. The Formal Semantics of Programming Languages, an
Introduction. M.I.T. Press, USA, 2001. (1st edn. 1993).
[Wol03] V. E. Wolfengagen.
Combinatory Logic in Programming.
JurInfoR
Ltd., Moscow, Russia, 2003. 2nd edn., in English.
[Wol04] V. E. Wolfengagen. Methods and Means for Computation with Objects.
JurInfoR Ltd., Moscow, Russia, 2004. In Russian.
[Zas01] J. Zashev.
On the recursion theorem in iterative operative spaces.
Journal of Symbolic Logic, 66:1727–1748, 2001.

List of symbols
0, numeral in typing system, 214
0, Church numeral, 48
assigning types, 124, 165
principal type, 143
typed version, 300
0N, 110
0, 61, 143
0N, 300
1 (Church numeral) principal type, 143
n, Church numerals, 48
assigning types, 124, 165
principal type, 143
typed version, 300
σ, 49, 124, 143, 165
= (two senses), 225
=, non-syntactic identity, 4
=A , for equality propositional operator
in a typing system, 213
=β ,w , 33
=β η , 78, 83
=β in λ-calculus, 16
formal theory, 70
models, 229–275
typed, 113
undecidability, 67
=β in CL, see =Cβ
=ext, 78, 83
axioms for, in CL, 86
=λ ext, 78
=λ β η , 78
=T , 75
=ext-induced, 95
=Cβ , 102
axioms for, 105
=Cext, 83
axioms for, 86
=⋆, 155, 176
=w , 29
formal theory CLw, 71
typed, 117
undecidability, 67
≡, syntactic identity, 4
dual use in λ, CL, 33
≡α 0 , 278
≡α , 9, 278
congruence-classes, 277
necessity of, 276
suppression of, 10
(≡
′
α ), rule, 163, 185
▷1α , 278
▷1η , 79
▷1β η , 79
▷1β , β-contracts, 11
▷1w , weak contraction, 24
▷R for redex R, 40
▷α 0 , 278
▷β ,w Z, 61
▷β ,w , 33
▷β η , 79
conﬂuence, 80, 289
▷β R, 304
▷β Z, 61, 62, 291
▷β , 12
conﬂuence, 14
theory λβ, 70
typed, 113
▷η , 79
▷w Z, 61, 62, 291, 300
▷w , 24
conﬂuence, 25, 290
theory CLw, 71
typed, 117
>−, 89
conﬂuence etc., 90, 99
irreducibles, 90
normalization of deductions, 154
⊢, 69, 70, 122
|=, 224
≺, 257
334

List of symbols
335
⊑, 248
deﬁned in D∞, 260
⊒, 248
(→e), rule in TA→
C , 122
(→e), rule in TA→
λ , 159, 163
(→f), rule in λ →, 188
(→g), rule in λ →, 189
(→i), rule in TA→
λ , 159–161, 163
(→i), rule in λ →, 188
∼, extensional equivalence, 223, 237
/ ∼, 223
, extensional-equivalence class, 223,
237
, 248, 252
◦, function-composition, 229
∃, existential quantiﬁer in a typing
system, 213
· , cut-oﬀsubtraction, 51
¬, for negation in a typing system,
212
→, see function-type
×, for type of pairs in type systems,
210
∨, for disjunction in type systems,
210
∧, for conjunction in type systems,
210
2, 191, 192
•, arbitrary, 221
•, in D∞, 263
⊥, falsum constant or empty type, 196,
211
⊥, least member, 248, 249
reasons for use in D∞, 251
⊥n , 256
⋆, 187, 191, 192
( )◦, interior of model, 227
( )λ , 93
( )r ep , 222
[ ], abstraction in CL, 26, 28
[ ]β , 101
[ ]η , 93
[ ]f ab , 101
[ ]w , 100
multiple, 28
typed, 117
[ ], discharging an assumption, 160
[ ], equality-class of terms, 226
⌈⌉, 64
[[ ]], 224, 231
[[ ]]n
ρ , 264
[ / ], substitution, 7, 23, 112, 116
[ / ]ρ, valuation, 221
( →), set of functions, 248
[ →], set of continuous functions, 248,
253
, 61
α-, 9, 278
contraction, 278
conversion, 9, see ≡α
conversion avoided, 276
α-invariance in TA→
λ , 163, 165
α0-contraction etc., 278
(α-conv), rule, 187, 190, 193
(α), axiom-scheme, 70, 112
β-, 11
axioms in CL, 105
contracts, 11, 192
equality, 16, see =β
typed, 113
equality in CL, 102
nf, normal form, 12, 15
redex, 11
typed, 113
reduces, see ▷β
strong reduction in CL, 106
β-reduction of deductions, 173
(β), axiom-scheme, 70, 112
βη-, 37, 78, 79
contracts, 79
nf, normal form, 37, 79
redex, 79
reduces, 79, see ▷β η
strong reduction in CL, 89
βη-conversion, for a PTS, 208
βη-reduction of deductions,
154
(ζ), rule, 77, 82
(ζβ ), rule, 103
η-, 37
contracts, 37, 79
redex, 37, 79
typed, 115, 219
reduces, 79
η-reduction of deductions, 175
(η), axiom-scheme, 77, 82, 114
role in CL, 84
λP, typing system, 198
Λ( ), 237
Λ, class of all λ-terms, 92
Λ, for conjunction, 210
λλ, abstraction in meta-language,
248
λ (for λ-calculus in general), 4
λ (in dual use in λ, CL), 33
λ (motivation of notation), 1–3
λ-algebras, 225
λ-calculus, 1
applied, 3
pure, 3
λ-conversion, see =β , =β η
λ-cube, 192
λ-deﬁnable function, 47
λ-mapping, transform, 93

336
List of symbols
λ-model, 231
also see model, models, 230
category-theoretic view, 243
function-set F, 244
motivation of deﬁnition, 230,
231
Scott–Meyer, 240
syntactical or environment, 231
syntax-free, 238
λ-term, 3
typed (simply), 109
λC, typing system, 201
λI-term, 18
λK-term, 18
λP2, typing system, 200
λPω, typing system, 200
λ2, typing system, 195
λβ, formal theory, 70, 72
models of, see λ-model
theory of =β , 70
theory of ▷β , 70
λβ →, 112, 113
λβη, formal theory, 77, 79
models of, 235
λβη →, 114
λβη-nf, normal form, 37
λβζ, formal theory, 77
λβZ, 62
λω, typing system, 197
λω, typing system, 199
λ →a , typing system, 189
λ →, typing system, 188, 195
(µ), rule, 70, 71, 112, 116
ν, recursive function, 64
(ν), rule, 70, 71, 112, 116
(ξ), rule, 70, 82, 89, 112
role in CL, 84
(ξβ ), rule, 106
Π, 181
(Π e), rule, 181, 185
(Π f), rule, 190
(Π i), rule, 181, 185, 191
π, predecessor, 50, 54, 301, 312
π, predecessor function in typing
system, 214
πBernays, 54
πBund−Urb , 54
(ρ), axiom-scheme, 70, 71, 112,
116
Σ, for existential quantiﬁer in a typing
system, 212
σ, successor function, 49
σ, successor function in typing system,
214
σ, 49
assigning types, 124, 165
principal type, 143
σN→N, 110
σ, 61, 143
(σ), rule, 70, 71, 112, 116
τ , recursive function, 64
(τ ), rule, 70, 71, 112, 116
φ0, φn , 256, 257
φm ,n , 260
ψ0, ψn , 256, 257
Ω, 13, 308
ω, universal type, 153
(ω), rule, 77

Index
abstract numerals, 61
abstraction
in λ, 3
in CL, see [ ], [ ]w , [ ]β , [ ]η
in typed CL, 117
(abstraction), rule, 187, 190, 193
abstraction-and-types theorem,
128
Add, 55, 312
admissible
formula, 74
rule, 74
algebraic logic, 274
algebras
λ-, 225
combinatory, see combinatory
algebras
Curry-, 225
lambda abstraction, 274
algorithm for principal types, 141
alternative generalized typing, 186
analogue, typed, 137
anti-symmetric relation, 249
application, 3
in D∞, 256, 263
(application), rule, 187, 190, 193
applicative structure, 222
applied
λ-calculus, 3
CL, CL-term, 22
approximate interpretation in D∞,
264
arithmetical extension of CL, 61–62,
291
arithmetical basis, 143
typed version, 299–304
association to left in terms, 4
association to right in types, 108
assumptions in deductions, 69
discharged or [ ], 160
atom
in λ, 3
in CL, 22
atomic constant
in λ, 3
in CL, 22
typed, 109, 115
atomic formula, 72
atomic type, 107
atomic type constant, 183
AUT-QE, typing system,
199
Automath, 148
axiom, 192
(axiom), rule, 187, 190, 193
axiom-schemes in general,
70
axiom-schemes
(α), 70, 112
(β), 70, 112
(η), 77, 82, 114
(ρ), 70, 71, 112, 116
(I), 71, 116
(K), 71, 116
(S), 71, 116
(→I), 122
(→K), 122
(→S), 122
axioms in general, 69
axioms, 186
for =Cβ , 105
for CLw+ , 73
for extensionality, see E-axs
logical, 72
of a Pure Type System, 201
principal, 125, 145
proper, 72
B, B¨ohm-tree model, 273
BZ, 143
337

338
Index
B, 21
in λ, 34
assigning types, 164, 166
in CL, 24
principal type, 143
types assigned, 123
B′, 21
in λ, 34
in CL, 26, 309
bases, 143
arithmetical, 143
for Church numerals, 144
monoschematic, 145
with universal type ω, 153
basic combinator, 22, see I, K, S
typed, 115
basic generalized typing, 183
Bernays’ R, 52–53
Berry’s extensionality property, 233
binding, 7
B¨ohm tree, 270
B¨ohm’s theorem, 37
bottom member, see ⊥
bound variable, 6
change, 9, see ≡α
bound, upper, 249
least (l.u.b.), 249
Bruijn, de, notation, 276
C (class of all CL-terms), 92
Cλ , 93
C, 21
in λ, 34
assigning types, 130
in CL, 25
principal type, 143
calculus of constructions, 201
cancelled, see discharged
cartesian product type, 182
case, for use with injections, 210
category theory & λ-models, 243
change of bound variable, 9
Church numerals, 48, see 0, n
typed versions, 300
Church–Rosser theorem
for =ext, 80
for ▷β η , =β η , 80
for ▷β , =β , 14, 16, 282–289
for ▷w , =w , 25, 30, 290
for >−, 90
for reductions with Z, 291
Church-style type-system, 107
for λ, 109
for CL, 115
CL, 22
CLβax , 105
model of, 225
CLξ, 82
CLξβ , 106
CLζ, 82
CLζβ , 103
CL-term, 22
typed, 115
CLextax , 86
model of, 225
CLw
model of, 224
theory of =w , 71, 72
theory of ▷w , 71
typed version, 116, 117
CLw+ , 73
(CLwR)→, 304
CLwZ, 62
(CLwZ)→, 299, 300
cl, classical axiom for a typing system,
217
classical logic, in a typing system, 217
closed term, 7, 22
closed type, 120
closed under conversion or equality, 65
coercion, in typing systems with
subtyping, 219
combination, 228
of variables, 264
combinator
motivation, 21
in λ, 34
in CL, 22, 121
typed, 115
combinatorially complete, 228
combinatory algebras, 223, 235
and λ-models, 244
combinatory logic, see CL
complete partial order, see c.p.o.
complete, combinatorially, 228
composite formulas, 72
composition of functions, 229
computable function, 47
computable term, 293
conclusion of a rule, 69, 74
conditional operator, 54
conﬂuence, 14, 282
conﬂuence theorems, see Church–Rosser
congruent, 9
congruence-classes, 277
conjunction proposition operator, in a
typing system, 210
conservative extension, 73
consistency condition, 109
consistency of a context, 134
constant
in λ, 3
in CL, 22
typed, 109, 115

Index
339
contains, 6
context, 134, 170, 186
legal, 186, 189, 202
continuous function, 252
contraction, 40
α-, 278
α0-, 278
β-, 11
βη-, 79
η-, 79
weak, 24
typed, 113, 117
contractum
of β-redex, 11
of η-redex, 79
conversion
α-, 9, 278, see ≡α
α0-, 278
β-, see =β
closed under conversion, 65
weak equality, see =w
(conversion), rule, 187, 190, 193
(conversion′), rule, 218
(conversion′′), rule, 218
convertibility, see conversion
Coq, proof assistant, 201
correct rule, 74
correctness of types lemma, for PTSs,
205
c.p.o. (complete partial order), 250
Curry algebras, 225
Curry–Howard correspondence, 148
Curry-style type-system, 107, 120
currying, 3
cut-oﬀsubtraction, 51, 55
D/ ∼, 223
D0, D1, D2, Dn , 256
embedding into D∞, 261
DA model, 271–272
D∞model
deﬁnition, 260
reasons for structure, 250, 256
construction, 256–260
history, 220, 247
is a λ-model, 269
properties, 261–270
D, for pairing, 31, 52, 54, 180
built from Z, 301
in λ-cube, 210
of Church, 309
assigning types, 130
principal type, 143
D′, pairing operator for existential
quantiﬁer in typing systems, 212
D1, ﬁrst projection, 31, 54, 180, 309
D2, second projection, 31, 54, 180, 309
data types, inductively deﬁned, 217
de Bruijn notation, 276
decidable set, 64
deduction in a theory, 69
in TA→
C , 122
in TA→
λ , 160
normal, 151
reduction of, 149, 173, 175
deduction reduction, in a PTS, 208
deleting types, 137
denotational semantics, 275
dependent function type, 181
derivable
formula, 74
rule, 74
developments, 292
directed set, 250
discharged assumption, 160
discharging vacuously, 162
disjunction proposition operator, in a
typing system, 210
domain of a function, 108
domain of a structure, 222
domain theory, 275
E-axs, 86
ECC, 202
end of a reduction, 40
Entscheidungsproblem, 67
environment λ-models, 231
Eq′ (rule in TA→
C= ), 155
postponement, 156
Eq′ (rule in TA→
λ = ), 176
postponement, 177
Eq′
β , Eq′
β η (rules in TA→
λ = ), 176
Eq′
β , Eq′
ext, Eq′
w (rules in TA→
C= ), 155
(Eq′′), rule, 181, 185
equality
β-, see =β
PTS with, 218
weak, see =w
determined by a theory, 75
closed under, 65
equality propositional operator, 213
equationally equivalent, 271
existential quantiﬁer operator, 212
Exp, 55, 312
explicit type-system, see Church-style
exponentiation, 55
(ext) rule, 77, 83
extended calculus of constructions, 202
extended polynomials, 115
extensional equality, 78, 83, 95
extensional structures, 223
extensional λ-models, 235
extensional-equivalence class, 237

340
Index
extensionality axioms, see E-axs
extensionality discussed, 76–92, 95–99,
227
extensionality, Berry’s, 233
extensionality, weak, 232
extensionally equivalent, 223
F, 209
F, set, in a λ-model, 244
factorial function, 56
falsum constant (⊥), 196, 211
ﬁlter models, 273
ﬁrst-order (language, etc.), 72
ﬁrst-order logic, undecidability, 67
ﬁxed point, 34
ﬁxed-point combinator, 34, 36, see Y
ﬁxed-point theorem, 34
double, 35
second, 68
fnl (functional), 94
Fool’s Model, 271, 274
formal theories in general, 69
formal theories
λβ, 70
λβη, 77, 79
λβζ, 77
CLξ, 82
CLξβ , 106
CLζ, 82
CLζβ , 103
CLw, 71
of strong reduction, 89
formulas of a theory, 69
of TA→
C , 122
of TA→
λ , 163
formulas-as-types, see
propositions-as-types
free, 7
free variable lemma, for PTSs, 203
fst, left projection for typed pair, 210
fst′, left projection for pairing operator
D′, 213
Fun( ), 222
function
λ-deﬁnable, 47, see representable
function
computable, 47
partial, 48
partial recursive, 58
representation, 58, 60
primitive recursive, 50
representation, 51, 60
properly partial, 48
recursive, 47, 56
representation, 56, 60
representable, see representable
function
total, 48
Turing-computable, 47
function-type, 107, 108, 120, 195
interpretation, 121
functional (fnl), 94
FV( ), 7
FV( )-context, 134, 170
G, 182
G(A), 271
G1, approach to deﬁning types, 182
G2, approach to deﬁning types, 182
G¨odel number, 63
G¨odel’s consistency proof, 299
gd( ), 64
(G e), rule, 182
general recursive function, 56
generalized typing
alternative, 186
axioms, 186
generation lemma, for PTSs, 204
Gentzen’s Natural Deduction, 160–161
(G i), rule, 183
graph models, 273
H, 108, 121
Hβ -mapping ( )H β , 101
Hη -mapping ( )H η , 95
Hw -mapping ( )H w , 101
Hilbert-style theory, 69
hypergraph model, 273
IS , 229
I, 21, 22
in λ, 34
assigning types, 162, 166
in CL, 24
principal type, 142
redundant, 26
Iλ , 93
Iσ (typed term), 110, 115
(I), axiom-scheme, 71, 116
i, in a model, 224
identity function, 229
identity notation, 4
iﬀ(for ‘if and only if’), 4
implicit type-system, see Curry-style
inclusions, proper, 144, 153
induction in a typing system, 216
induction on a term, 6
inductively deﬁned data types, 217
inert, 131, 165
inhabited type, 148
inl, left injection, 210
inr, right injection, 210
instance of a rule, 74
intensional, 76

Index
341
interior of a model, 227, 242
interpretation in a model, 224
interpreting terms informally, 4
inverse, left, 229
irreducibles, see nf, normal form
for >−, 90
isomorphic c.p.o.s, 255
iteration combinator (iterator), see Z
K, 21, 22
in λ, 34
assigning types, 162
in CL, 24
principal type, 142
Kλ , 93
Kσ,τ (typed term), 110, 115
(K), axiom-scheme, 71, 116
k, in a model, 224
in D∞, 267
kn , 259
l.u.b. (least upper bound), 249
lambda abstraction algebras, 274
least member, see ⊥
left inverse, 229
left, association to, 4
leftmost maximal, 41
leftmost reduction, 41
legal context, 186, 189, 202
legal pseudoterm, 205
length
of a reduction, 40
maximal, 41
of a term, see lgh
LF, typing system, 199
lgh( )
in λ, 5
in CL, 23
LISP, programming loanguage, 44
logical axioms, 72
loose Scott–Meyer λ-model, 240
maximal
length, 41
redex-occurrence, 41
leftmost maximal, 41
minimal
complete development (MCD), 292
term, 31
ML, programming language, 120,
141
model
B¨ohm-tree model B, 273
DA , 271–272
D∞, see D∞
ﬁlter models, 273
graph model, 273
hypergraph model, 273
lambda abstraction algebras,
274
non-well-founded, 274
normal models, 225
of λβ, see λ-model
of λβη, 235
of CLβax , 225
of CLextax , 225
of CLw, 224
Pω , 272–273
partial models, 274
Skordev’s and Zashev’s, 273
T ω , 273
term models, 226, 236, 273
models of typed λ, 246
monoschematic bases, 145
monotonic function, 252
M ult, 55, 312
N, natural number predicate for typing
systems, 216
N, 108, 121
N, 214
n, Church numerals, 48
assigning types, 124, 165
principal type, 143
typed version, 300
IN, 48
INp os, 109
IN+ , 251
continuous functions on, 252
Natural Deduction, 160–161
negation proposition operator, in a
typing system, 212
nf
β-, 12, 15
βη-, 37, 79, 80
strong, 37, 91
typed, 113
undecidability of having, 66
uniqueness, 15, 25
weak, 24
non-binding, 7
non-redex atom or constant, 22,
121
non-well-founded set theory, 46, 274
normal deduction, 151
normal form, see nf
normal models, 225
normal reduction, 41
normal-subjects bases, 131
normalizable term, 293
normalizable, normalization
strong, see SN
weak, see WN
number theory (PA), 299

342
Index
numerals
abstract, 61
of Church, 48
occurrences, 6
occurs, 6, 23
open type, 120
operators, 45
ordered pair combinator, see D
Pω model, 272–273
PA (Peano Arithmetic), 299
pairing combinator, see D
parallel reduction, 284, 285
parametric types, 120
parentheses, omission from terms,
4
omission from types, 108
partial function, 48
partial models, 274
partial recursive function, 58
representation, 58, 60
partially ordered set, 249
complete (c.p.o.), 250
Peano1, axiom for typing system,
215
Peano2, axiom for typing system,
215
not needed, 216
Peano3, axiom for typing system
false in standard typing systems,
215
polymorphic, 46, 119
polynomials, extended, 115
POLYREC, 197
postponement of η, 80
postponement of Eq′, 156, 177
predecessor, see π
predicate, 122, 163
premises of a rule, 69, 74
primitive recursion combinator, see R
primitive recursive function, 50
representation, 51, 60
principal axioms, 125, 145
principal pair (p.p.), 138, 171
principal type
algorithm for ﬁnding, 141, 172
in TA→
C= , TA→
λ = , 157, 177
of a λ-term, 171
of a CL-term, 138
of SKK, 139
of xI, 140
of various combinators, 142
relative to a basis, 145
principal-types theorem, 141, 172
(product), rule, 190, 193
proj, projection operator for use with
existential quantiﬁer in a typing
system, 212
projections between c.p.o.s, 255
projections for pairing, see D1, D2
proof in a formal theory, 69
proper axioms, 72
proper inclusions, 144, 153
properly partial function, 48
propositions-as-types, 147, 173–175,
209–217
pseudo-models, 225
pseudocontext, 193, 202
pseudoterms, 192
p.t., see principal type
PTS (Pure Type System), 201
with equality, 218
pure
λ-calculus, λ-term, 3
CL, CL-term, 22, 121
Type System, 201
Q, for equality in a typing system,
213
quasi-leftmost reduction, 42
R, recursion combinator, 51,
214
R built from Z, 62
assigning types, 144
RBernays, 52–53
assigning types, 130
RFix, 55
typed version of R, 301, 304
range of a combinator, 68
range of a function, 108
recursion combinator, see R
recursive function, 47
partial, 58, 60
primitive, 50, 51, 60
total, 56, 60
recursive set, 64
recursive types, 197
recursively separable, 64
redex
β-, 11
βη-, 79
η-, 37, 79
typed, 113, 117
weak in CL, 24
Z-, 300
reduces
α0, 278
β-, see ▷β
βη-, 79
η-, 79
weakly, see ▷w

Index
343
reduction, 40
leftmost, 41
of a deduction in TA→
C , 149
of a deduction in TA→
λ , 173, 175
quasi-leftmost, 42
typed, 113, 117
reﬂexive relation, 10, 249
relative typability, 145
( )rep , 222
Rep( ), 242
Reps( ), 222
representable function, 49, 222
representative in a structure, 222
restricted weakening lemma, for PTSs,
203
restriction, of a function, 219
retract, retraction, 229
rigid type-system, see Church-style
rule, 69, 74
admissible, 74
conclusion of, 69, 74
correct, 74
derivable, 74
instance of, 74
of a ﬁrst-order theory, 72
premises of, 69, 74
special, of a generalized typing
system, 192, 201
rule-equivalent, 75
rules
(α-conv), 187, 190, 193
(ζ), 77, 82
(ζβ ), 103
(µ), 70, 71, 112, 116
(ν), 70, 71, 112, 116
(ξ), 70, 82, 89, 112
(ξβ ), 106
(Π e), 181, 185
(Π f), 190
(Π i), 181, 185, 191
(ρ), 71
(σ), 70, 71, 112, 116
(τ ), 70, 112, 116
(ω), 77
(ext), 77, 83
(abstraction), 187, 190, 193
(application), 187, 190, 193
(axiom), 187, 190, 193, 201
(conversion), 187, 190, 193
(conversion′), 218
(conversion′′), 218
Eq′, 155, 176
Eq′
β , Eq′
β η , 176
Eq′
β , Eq′
ext, Eq′
w , 155
(Eq′′), 181, 185
(G e), 182
(G i), 183
(product), 190, 193, 201
reducing TA→
C -deductions, 149
reducing TA→
λ -deductions, 173
(start), 187, 193
(start1), 190
(start2), 190
(weakening), 187, 193
(weakening1), 190
(weakening2), 190
(≡
′
α ), 163, 185
(→e), 122, 159
(→f), 188
(→g), 189
(→i), 159–161, 188
S, 22
in λ, 34
assigning types, 161
in CL, 24
principal type, 143
Sλ , 93
Sρ,σ,τ (typed term), 110, 115
(S), axiom-scheme, 71, 116
s, in a model, 224
in D∞, 267
sn , 260
satisﬁes, 224
SC, strongly computable, 293
scope, 6
Scott topology, 253
Scott–Curry theorem, 65
Scott–Meyer λ-model, 240
second order polymorphic λ-calculus,
197
separable, recursively, 64
set theory, non-well-founded, 46, 274
simple types, 107
simultaneous substitution, 10, 23, 309
singly sorted PTS, 206
Skordev’s and Zashev’s models, 273
SN, strong normalization, 113
SN terms, 113, 293
SN theorems
for λ-terms, ▷β , 174
for ▷β η , 297
for ▷β Z, 294, 304
for ▷β , 114, 294
for ▷w R, 304
for ▷w Z, 302
for ▷w , 118, 136, 297
for reducing deductions, 152, 208
for the λ-cube, 207
snd, right projection for typed pair, 210
sort, 189
sorts, 188, 192
special rules, 192, 201

344
Index
standardization, 42
(start), rule, 187, 193
start lemma, for PTSs, 203
start of a reduction, 40
(start1), rule, 190
(start2), rule, 190
stratiﬁcation theorem, 127
stratiﬁed (= typable), 134
strengthening lemma, for PTSs, 206
strict Scott–Meyer λ-model, 240
strong normal form (nf), 37, 91
strong normalization, see SN
strong permutation lemma, for PTSs,
207
strong reduction, see >−
strongly computable (SC), 293
strongly inert, 131
strongly normalizable, see SN
subject, 122, 163
subject-construction property, 126, 166
subject-expansion fails, 133
subject-reduction theorem, 132, 168
extensions of, 146
for PTSs, 205
substitution
in λ, 7
in CL, 23
simultaneous, 10, 23, 309
typed, 112, 116
substitution lemmas, 14, 16, 25
for PTSs, 204
subterm, 6, 23
subterm lemma, for PTSs, 205
subtraction, cut-oﬀ, 51, 55
successor function, 49
symmetric relation, 10
syntactical λ-models, 231
T ω model, 273
T( ), 151
TA→
C , type system, 122
TA→
C -deduction, see deduction
TA→
C -formula, 122
TA→
C -proof, 122
TA→
C= , 155
TA→
C= β , TA→
C= ext, TA→
C= w, 155
Eq′-postponement, 156
WN theorem, 157
TA→
λ , type system, 163
TA→
λ -deduction, see deduction
TA→
λ = , 176
TA→
λ = β , TA→
λ = β η , 176
Eq′-postponement, 177
WN theorem, 177
TAGλ, type system, 185
TAGa
λ, type system, 186
term, 193
λ-, 3
pure, 3
CL-, 22
pure, 22, 121
term models, 226, 236
terminus, 40
theorem in a theory, 70
theorem-equivalent, 75
theory, formal, 69
ﬁrst-order, 72
thinning lemma, for PTSs, 204
TM( ), see term models
topsort, 207
total function, 48
transitive relation, 10, 249
transitivity lemma, for PTSs, 203
truncated subtraction, see cut-oﬀ
Turing-computable, 47
typable λ-terms, 170
decidability, 172
in TA→
λ = , 177
normalization, see SN, WN
typable CL-terms, 134–136
decidability, 136
in TA→
C= , 157
normalization, see SN, WN
relative, 145
SII untypable, 142
type, 107–108, 120–121, 184, 194
atomic, 107
type-constant, 120
type-variable, 120
cartesian product, 180, 182
closed, 120
dependent function type, 181
function-, 107, 120
interpretation, 121
H, 108, 121
inhabited, 148
N, 108, 121
open, 120
as proposition, 147, 173–175, 209–217
pair-type, 180
parametric, 120
principal, see principal type
recursive, 197
simple, 107
universal type ω, 153
type-assignment formula, 122, 159
type-checking, example of, 111
type-context, see context
type-deletion, 137
type functions, 183
type-inference algorithm, 141
type-reconstruction algorithm, 141
type-schemes, 120

Index
345
type-system
Curry-style, implicit, 120
TA→
C , 122
TA→
C= , 155
TA→
λ , 163
TA→
λ = , 176
generalizations, 180
polymorphic, 119
typed
λ-terms, simply typed, 109
λβ, 112
λβη, 114
analogue, 137
atomic constants, 109, 115
CL-terms, 115
CLw, 116
redex, 113, 117
η-redex, 115
reduction, 113, 117
variables, 109, 115
types as propositions, 147, 173–175,
209–217
typing, see type-system
basic generalized, 183
undecidability
of =β , =w , 67
of TA→
C= , TA→
λ = , 155, 176
of ﬁrst-order logic, 67
of having a nf, 66
Scott–Curry theorem, 65
unicity of types lemma, for PTSs, 206
upper bound, 249
u.r.s., uniformly reﬂexive structure, 274
V, for disjunction, 210
v0, v00, v000, 3, 109
vacuous discharge, 162
valuation, 221
variables
binding, 7
bound, 6
free, 7
term-, 3, 22
typed, 109, 115
void, empty type, 211
also called ⊥, 196, 211
W, 22
in λ, 34
assigning types, 165
in CL, 26, 31, 309
assigning types, 124
principal type, 143
WC, weakly computable, 293
weak contraction, 24
weak equality, see =w
typed, 117
weak extensionality, 232
weak normal form (nf), 24
typed, 117
weak normalization, see WN
weak redex, 24
typed, 117
weak reduction in CL, see ▷w
(weakening), rule, 187, 193
(weakening1), rule, 190
(weakening2), rule, 190
weakly inert, 131
weakly normalizable, see WN
WN, weak normalization, 113
WN terms, 113, 293
WN theorems
for TA→
C= , 157
for TA→
λ = , 177
for λ-terms, 174
for ▷β , 114
for ▷w , 118, 136
for >−, 136
for reducing deductions, 174
see also SN theorems
Y, ﬁxed-point combinator, 34, 55
weak nf, 42
YCurry−Ros, 36, 39, 42
untypable, 136, 166
YTuring , 34, 36, 42
untypable, 136
Z, 61–62, 143, 291, 299–304
Z-redex, reduction, 291, 300
Zτ (typed version of Z), 300
Zn for Church numerals, 48
Zashev’s and Skordev’s models,
273

