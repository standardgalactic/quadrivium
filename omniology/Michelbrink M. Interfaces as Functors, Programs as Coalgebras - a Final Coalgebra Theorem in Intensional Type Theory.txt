Interfaces as Functors, Programs as
Coalgebras - a Final Coalgebra Theorem in
Intensional Type Theory
Markus Michelbrink 1
Department of Computer Science
University of Wales Swansea
Singleton Park
Swansea
SA2 8PP
United Kingdom
Abstract
In [17,19] Peter Hancock and Anton Setzer introduced rules to extend Martin-L¨of’s
type theory in order to represent interactive programming. The rules essentially re-
ﬂect the existence of weakly ﬁnal coalgebras for a general form of polynomial functor.
The standard rules of dependent type theory allow the deﬁnition of inductive types,
which correspond to initial algebras. Coalgebraic types are not represented in a di-
rect way. In this article we show the existence of ﬁnal coalgebras in intensional type
theory for these kind of functors, where we require uniqueness of identity proofs
(UIP) for the set of states S and the set of commands C which determine the func-
tor. We obtain the result by identifying programs which have essentially the same
behaviour viz are bisimular. This proves the rules of Setzer and Hancock admissi-
ble in ordinary type theory, if we replace deﬁnitional equality by bisimulation. All
proofs 2 are veriﬁed in the theorem prover agda [6,36], which is based on intensional
Martin-L¨of Type Theory.
Key words: Dependent Type Theory, Interactive Programming, Coalgebra
1991 MSC: 03B15, 03F65, 03B70, 16W30, 18A15, 18D15, 68Q60, 68Q85
Email address: email m.michelbrink@swansea.ac.uk (Markus Michelbrink).
1 Supported by EPSRC grant GR/S30450/01.
2 Available at: http://www.cs.swan.ac.uk/∼csmichel/articles/ﬁnco-verif.tar.
Preprint submitted to Elsevier Science
17 October 2005

1
Introduction
Martin-L¨of type theory [28,34] is a very carefully developed framework for
constructive mathematics. It is well suited as a theory for program construc-
tion since it is possible to express both speciﬁcation and programs within the
same formalism. Types in Martin-L¨of type theory can be seen as program
speciﬁcations via the proposition-as-types interpretation. Inhabitants of these
types are programs which fulﬁl the required speciﬁcation. Running such a
program means to evaluate an expression. One of the design features of the
framework is that the evaluation of a well-typed program always terminates.
Further there is no interaction with the environment. In order to introduce
interaction into type theory and to allow the non-termination of programs,
Hancock and Setzer [17,19] introduced the notions of (state dependent) in-
terfaces and interactive programs. Their approach results in an extension of
type theory by rules expressing the existence of weakly ﬁnal coalgebras for the
functors determined by interfaces. This coalgebraic rules give a comfortable
way to reason about interactive programs. However coalgebraic types are not
represented directly in standard type theory. In fact they are classical exam-
ples of impredicative conceptions whereas Martin-L¨of type theory is a strictly
predicative theory. Predicative type theories play a particular role for giving
foundational interpretations of programming languages. They have multiple
mathematical models, notably set theoretic, PER models and denotational
models, that provide precise deﬁnitions of programming language features,
due to their explicit inductive construction.
On the other side one has to be careful adding rules to type theory. That this
may have disastrous consequences can be seen e.g. in Martin-L¨of’s Mathe-
matics of Inﬁnity [29] where it is shown that type theory becomes inconsistent
when the formal laws for the ﬁxed point operator are adjoined to it.
However in this work we show that it is possible to reason about interac-
tive programs in standard predicative type theory as long as we replace the
deﬁnitional equality in the rules [17,19] by bisimulation. This is done by con-
structing ﬁnal coalgebras for the functors mentioned above. The basic idea
for this construction is essentially the same as for the model construction in
Michelbrink/Setzer [33]. However the proof that there is a ﬁnal coalgebra for
this kind of functors is surprisingly hard. This is due to the fact that we work
in intensional type theory, where we have to deal with the problem that types
depending on propositionally equal elements may not be equal. However un-
like the extensional version intensional type theory has a number of desirable
features we do not want to miss: all well-typed expressions normalise and
well-typedness, type-hood, type-checking as well as deﬁnitional equality are
decidable.
The theory of types developed by Per Martin-L¨of “is intended to be a full scale
system for formalizing intuitionistic mathematics” [30]. As a foundational the-
ory it is thought to be open-ended, in the sense that we might extend it by
2

rules for new types provided the informal semantic principles of the theory are
respected. In this article we work with an extension of Martin-L¨of type theory
that accommodates inductive-recursive deﬁnitions. A ﬁrst example of simul-
taneous induction-recursion is Martin-L¨of’s deﬁnition of the ﬁrst universe ´a la
Tarski [28]. The general schema for this kind of deﬁnition is introduced and
investigated by Peter Dybjer [9].
The paper is organised as follows. In section 2 we restate the original deﬁ-
nition of interfaces and programs, try to explain the concept of intensional
identity, the meaning it has for constructive reasoning and describe the dif-
ﬁculties which arise using this concept. We discuss families and predicates
and how they are related and give a new modiﬁed deﬁnition of interfaces. In
section 3 we introduce our category and in the following section 4 the endo-
functor Prog on this category, for which we are going to show that there is
a ﬁnal coalgebra in the category. In section 5 we deﬁne a coalgebra for this
functor, which consist in a family of sets CT, equivalence relations on this sets
and a morphism elim : CT →Prog CT. In section 6 we introduce the unique
morphism. However to prove that the function deﬁned indeed belongs to the
category and that it is the unique morphism making the coalgebra square com-
mute we have to do some more work. In section 7 we deﬁne the repetition of
the unique morphism and prove our Main Lemma. The Main Lemma is then
used to prove that the morphism deﬁned in section 6 belongs to the category
(is extensional) and is the unique morphism making the diagram commute.
In section 8 we point out how to get a ﬁnal coalgebra for the original functor
of Hancock/Setzer from this. In section 10 we conclude by describing some
future and related work.
We use the following notations: t ; t′ for t evaluates to t′, t ↭t′ for t, t′ eval-
uate to the same value, A for the type A is inhabited, id : t .= t′ or id : t .=A t′
for id is an inhabitant of the identity type. We use the notation (x : A) →B x
for the product type and sig m0 : A0, . . . , mn : An m0 . . . mn−1 for sigma
types where the components of a : sig m0 : A0, . . . , mn : An m0 . . . mn−1 are
accessed via ami for i = 0, . . . , n. We denote the canonical elements of the
sigma types by ⟨a0, . . . , an⟩and abbreviate sig fst : A, snd : B fst by P(A, B)
or P(x : A.B x) to emphasise x. The sentential connectives ∀, ∃, ∧, ∨, ⇒for
this type constructors are used in the standard way to emphasise the read-
ing of types as propositions. We sometimes suppress arguments which can
be inferred from other arguments for instance we write subst id b instead of
subst A B a a′ id b. We also use the notation
for missing arguments. We
use the notations False and True for the type with zero and one canonical ele-
ment respectively. To improve readability we overload some function symbols
e.g. st, co. However functions denoted by equal symbols have equal codomains
whereas the argument types may be diﬀerent.
3

2
Basic deﬁnitions and concepts
2.1
Interfaces and interactive programs
In [17] Hancock and Setzer give the following deﬁnition of an interface:
An interface is a quadruple (S, C, R, n) s.t.
• S : Set
• C : S →Set
• R : (s : S, C s) →Set
• n : (s : S, c : C s, R s c) →S.
The elements of the set S are called states, C s is the set of commands in
state s : S, R s c the set of responses to a command c : C s in state s : S, and
n s c r the next state of the system after this interaction.
A program for this interface starting in state s : S is a quadruple (A, c, next, a)
s.t.
• A : S →Set
• c : (s : S, A s) →C s
• next : (s : S, a : A s, r : R s (c s a)) →A (n s (c s a) r)
• a : A s.
The elements of the set A s are understood as programs starting in the state
s. The command c s a is the command issued by the program a : A s, and
next s a r is the program that will be executed, after having obtained for
command c s a the response r : R s (c s a). The execution of a program
a : A s proceeds as follows. First we compute c s a and issue this command.
Then we wait for a response r : R s (c s a) from the real world. When we
have obtained a response r we compute the new program next s a r. This
cycle is repeated until we reach a command c with no responses. It may be
undecidable if this is the case. It should also be noted that a program may
wait forever for a response. See [17] for further motivations.
Note that in the deﬁnition above programs are given by arbitrary families of
sets A : S →Set. That means the whole range of sets can be used to introduce
elements into the set of all programs. In particular the set of programs itself
may be used. This is a violation of the vicious-circle principle: impredicative
deﬁnitions should not be used. That is, an object should not be deﬁned in
terms of a totality to which the object itself belongs. In other words no totality
can contain members deﬁned in terms of itself. The vicious-circle principle is
taken very seriously in Martin-L¨of type theory.
If we combine c s a and next s a we get an element of ProgHS A s := P(c :
C s.(r : R s c) →A (n s c r)). Since there is no way to get the set of all
4

programs directly in a predicative framework, Hancock and Setzer expanded
Martin-L¨of type theory. This results in a type theory where the adjoined rules
express the existence of a (weakly) ﬁnal coalgebra for the functor ProgHS.
We are going to show that under certain assumptions on the sets of states and
commands the existence of this set of programs can be proved in ordinary type
theory. The proof is surprisingly hard. The reason for this is that we work in
intensional type theory.
2.2
Intensional Identity
Under the proposition-as-types interpretation, propositions are nothing other
than types. That a proposition is true means that the type is inhabited. In
order to have an internal representation of equality identity types are intro-
duced. The main purpose of this identity types is to be able to make the
assumption that two objects of a type are identical, i.e. to express identity
of objects on the left side of an implication. Martin-L¨of’s type theory can be
formulated on top of a theory of logical types (logical framework) [34]. This
is a typed λβη-calculus with dependent function types, a special type Set and
a rule which states that each object of Set is also a type. Sets are given by
formation, introduction, elimination and equality rules. The formation rules
say how to build sets, the introduction rules say what the canonical elements
of the set are. Elimination and equality rules say how to eliminate set formers.
β- and η-conversion together with the equality rules give deﬁnitional equality.
There are two main versions of Martin-L¨of type theory: extensional and in-
tensional type theory. The diﬀerence lies in the treatment of the identity type.
In both versions the formation and introduction rules of the identity type are
the same:
A : Set
a, b : A
a .=A b : Set
A : Set
a : A
reﬂa : a .=A a
The diﬀerence is in the elimination and equality rules for the identity type.
The elimination rules in extensional type theory identify propositional and
deﬁnitional identity:
p : a .=A b
a = b : A
This renders type-theory undecidable, i.e. well-typedness, type-checking, type-
hood and deﬁnitional equality become undecidable [22]. This is in contrast to
intensional type theory. There is a deep symmetry between the introduction
rules on the one side and the elimination and equality rules on the other side in
intensional type theory. The elimination rules for all sets can be understood
as structural induction rules: A proposition is true for all elements iﬀthe
5

proposition is true for the canonical elements of the set. In fact elimination
and equality rules can be calculated from the introduction rules [8]. This holds
as well for the identity type:
C : (x, y : A, p : x .=A y) →Set
c : (x : A) →C x x (reﬂx)
a, b : A
p : a .=A b
idpeel C c a b p : C a b p
with equality idpeel C c a a (reﬂa) = c a. Surprisingly this very weak elimi-
nation rule allows to deduce the usual properties of equality, notably Leibniz’
principle (C a implies C b for a .= b). However working with intensional
identity becomes very awkward. The reason for this is that propositional and
deﬁnitional equality do not collapse. That is, two instances of a type family
with indices which are not convertible, just propositionally equal, are not the
same type, i.e. c : C a is in general not an element of C b if a equals b, though
if p : a .= b and c : C a we get an element subst p c : C b. The trouble is that
this element depends on the proof p and there is no general way to conclude
that subst p c equals subst q c for p, q : a .= b.
We frequently use the following well known (and easy to prove) principles:
Principle 1
a0 .= a1 ⇒f a0 .= f a1
for A, B : Set, f : A →B, a0, a1 : A.
Principle 2
⟨a0, b0⟩.=P
(A,B) ⟨a1, b1⟩⇔a0 .=A a1 ∧¯b0 .=B a1 b1
for A : Set, B : A →Set, ai : A, bi : Bi, i = 0, 1 and ¯b0 obtained from b0 by the
inhabitant of a0 .= a1.
2.3
Families and predicates
What makes type theory into dependent type theory is that types may depend
on elements of other types. A family of sets is given by a set IndexP and
a function P : IndexP →Set. The function P may as well be seen as a
predicate on IndexP. On the other hand it is often technically simpler to
work with a more ﬁbration-like view of families: A family is given by two sets
CoIndexF, IndexF and a function F : CoIndexF →IndexF. We call the
former predicate and the latter family. It is possible to switch between these
notions in the following ways: From predicate P to family F (pr0 denotes the
ﬁrst projection):
6

CoIndexF :=
X
(IndexP, P)
IndexF := IndexP
F := pr0 :
X
(IndexP, P) →IndexP.
From family F to predicate P deﬁne IndexP := IndexF and let P i be given
by the following rules:
Formation
Introduction
Elimination
i : IndexF
P i : Set
c : CoIndexF
intro c : P (F c)
i : IndexF
c′ : P i
B : (i : IndexF, c′ : P i) →Set
b : (c : CoIndexF) →B (F c) (intro c)
elim B b i c′ : B i c′
where elim B b (F c) (intro c) evaluates to b c. Note that the latter gives
exactly the rules for intensional identity if we take as family ∆: A →A × A
with ∆a := (a, a). We write PredToFam P and FamToPred F for the predicate
respectively family we gain by the way above. Intuitively we can think about
FamToPred F as the pre-image function F −1.
We say that f : A →B is a bijection iﬀthere is a g : B →A such that
a .= (g(f a)) and b .= (f(g b)) are inhabited for all a : A, b : B. We write
A ≃B iﬀthere is such a bijection. It is easy to establish the following bijec-
tions:
P i ≃FamToPred (PredToFam P) i
iso : CoIndexF ≃(PredToFam (FamToPred F))CoIndexF.
In the second case the functions pr0 ◦iso = (PredToFam (FamToPred F)) ◦iso
and F are pointwise equal.
There is a second approach to get a predicate P from a family F. This approach
uses the identity set: Deﬁne IndexP := IndexF and
P i :=
X
(c : CoIndexF, (F c) .= i)
for i : IndexF. We write FamToPred′ F for this predicate. Again it is not too
hard to establish the following bijections:
P i ≃FamToPred′ (PredToFam P) i
iso : CoIndexF ≃(PredToFam (FamToPred′ F))CoIndexF
and
to
prove
that
in
the
second
case
the
functions
pr0 ◦iso
=
(PredToFam (FamToPred′ F)) ◦iso and F are pointwise equal. Note that the
index set stays the same all the time and that
FamToPred (PredToFam P) i ≃FamToPred′ (PredToFam P) i
(PredToFam (FamToPred F))CoIndex ≃(PredToFam (FamToPred′ F))CoIndexF.
7

This is a little bit remarkable since the second approach seems to multiply
elements due to the fact that there may be more than one inhabitant of (F c) .=
i. The phenomenon is related to the fact that we can prove
Collapse
X
(a : A, a .= a′)
for a′ : A but in general not
Collapse (a .= a′)
for a, a′ : A where Collapse A is ∀a, a′ : A.a .= a′.
2.4
A simpler deﬁnition of interfaces
What makes work with the interface deﬁnition above clumsy is that there are
too many dependencies. The commands depend on the states, the responses on
the commands and the next state on the state, the command and the response.
This seems to be redundant since the information to which state a command
belongs should already be given by the command itself and similarly for the
responses and the next state. Hence the responses should depend only on the
command and the next state on the response. The way to achieve this is to
work with families instead of predicates:
Deﬁnition 3 Interface
An interface is given by sets S, C, R and functions st : C →S, co : R →C,
nxt : R →S.
Given an interface (S, C, R, n) in the sense of Hancock/Setzer we get an in-
terface in the new sense by
st := PredToFam C
co := PredToFam R′
and setting
nxt(((s, c), r)) := n s c r
where R′ is the uncurried version of R. The altered deﬁnition determines a
functor (see section 4 below). We are going to prove that this functor has
a ﬁnal coalgebra and use this result to get a ﬁnal coalgebra for the original
functor of Hancock/Setzer above. However we have not succeeded to prove the
result in its most general form for arbitrary sets S, C. In order for the proof to
go through we need a principle known as uniqueness of identity proofs on the
sets S, C. This principle states that all the inhabitants of a .= a′ are identical,
that is
∀a, a′ : A. Collapse (a .= a′).
8

We write UIP A for ∀a, a′ : A. Collapse (a .= a′). As shown by Martin Hofmann
[21,22] UIP A is not provable for arbitrary sets A. However it is provable for
the enumeration types, the natural number type and preserved by the identity
type and the sum type constructors [21], that is
UIP A ⇒∀a, a′ : A.UIP (a .=A a′)
and
UIP A ⇒(∀a : A.UIP B a) ⇒UIP
X
(A, B).
More general UIP A follows from decidability of identity [20] that is
∀a, a′ : A.(a .=A a′) ∨(a ̸ .=A a′)
which is also preserved by the sum type constructor. Streicher [41] noticed
that UIP A is provable if in the elimination rules for the identity type above
the type of C is changed from (x, y : A, p : x .=A y) →Set to (x : A, p : x .=A
x) →Set. Using this elimination rule is equivalent to pattern matching [31],
which therefore proves UIP as well. However in this cases elimination can not
be justiﬁed as structural induction. In the following we assume UIP for the
sets S and C.
3
The category of S-indexed families of setoids
We are going to deﬁne the category of S-indexed families of setoids. The
ambient category of setoids is a model of intensional type theory [21]. The set
of states S determines the following (presheaf-)category:
Objects are triples
X : S →Set
≡X: (s : S, X s, X s) →Set
eqX : (s : S) →equivalence (≡X s)
where equivalence R says that R is an equivalence (reﬂexive, transitive, sym-
metric) relation.
We use the notations ≡, ≡X and ≡s for the binary relation (s : S)
≡X s ⊆X s × X s.
We say ≡X: (s : S) →X s →X s →Set is an equivalence relation iﬀall
relations ≡s⊆X s × X s are equivalence relations. Morphism f : (X, ≡X
, eqX) →(Y, ≡Y , eqY ) are given by a family of S-indexed extensional functions
in the sense that
f : (s : S) →X s →Y s
and
x ≡X x′ ⇒f s x ≡Y f s x′
9

for s : S, x, x′ : X s. We use the same notation for the morphism and the
function f. If we want to emphasise the relations ≡X, ≡Y we sometimes say
that f is (≡X, ≡Y )-extensional. We identify f, g : (X, ≡X, eqX) →(Y, ≡Y , eqY )
iﬀ
x ≡X x′ ⇒f s x ≡Y g s x′
for all s : S, x, x′ : X s.
It is easily veriﬁed that this gives a category.
4
The Endofunctor Prog
The interface (S, C, R, st, co, nxt) determines the endofunctor Prog given by
Prog X s : Set
=
sig command : C
idS
co : (st c) .= s
nextEl : (r : R, (co r) .= c) →X(nxt r)
for X : S →Set with equivalence relation
Prog ≡X s ⟨c0, ids0, f0⟩⟨c1, ids1, f1⟩: Set
=
sig idc : c0 .= c1
fct : (r : R, idcr : (co r) .= c0) →f0 r idcr ≡(nxt r) f1 r idcr′
where idcr′ := subst idc idcr. We use the notation ≡Prog for this relation. By
some simple calculations it follows that ≡Prog is an equivalence relation if ≡is
an equivalence relation. We allow some abuse of notations. Prog takes a family
of sets X : S →Set, an equivalence relation ≡X on X and a witness for the
fact that ≡X is an equivalence relation and gives a triple consisting of a family
of sets Prog X : S →Set an equivalence relation Prog ≡X on Prog X and a
corresponding witness.
The morphism part of the functor Prog is given by
Prog g s : Prog X s →Prog Y s
Prog g s ⟨c, ids, f⟩= ⟨c, ids, λr : R, idc : (co r) .= c. g (nxt r) (f r idc)⟩
If g is extensional then Prog g is extensional too. To see this, let
⟨c0, ids0, f0⟩≡Prog ⟨c1, ids1, f1⟩3 .
3 Remember that this means that the type is inhabited.
10

Then we have idc : c0 .= c1. Let r : R and idcr : (co r) .= c0. We have
f0 r idcr ≡(nxt r) f1 r idcr′
where idcr′ is obtained from idcr by idc. We must show that
g (nxt r) (f0 r idcr) ≡(nxt r) g (nxt r) (f1 r idcr′).
But this follows by the extensionality of g.
The deﬁning properties for a functor are easily veriﬁed.
5
The coalgebra of computation trees
A possible ﬁrst approach 4 to construct a ﬁnal coalgebra representing the
programs of Hancock/Setzer might be to work in the category of setoids
[21,11]. The ﬁnal coalgebra for the functor Prog ought to be deﬁned by means
of the set (List R) →C together with an appropriate equivalence relation.
Given a morphism g : B →Prog B the idea is now to deﬁne an element
treeg,b : (List R) →C for b : B by
treeg,b () := (g b)command
treeg,b (l, r) :=



(g b′)command
if co r .= treeg,b l
some “junk”
otherwise
where b′ has to be deﬁned simultaneously by means of (g )nextEl. However
this approach does not work. The reason is that we do not have c .= c′ ∨
c ̸ .= c′ for c, c′ : C in general, i.e. identity on C must not be decidable. As a
consequence we can not deﬁne treeg,b by case distinction as above. Instead we
have to prove our envisaged result by doing it the hard way 5 : We are going to
deﬁne the object of the ﬁnal coalgebra as a set of trees containing exactly the
information a program needs to have. These trees are represented by functions
on dependent lists of states, commands and responses into a universe. We start
by deﬁning the set of lists:
Deﬁnition 4 Elements of CTSeq s for s : S are either of the form
(c, ids)
4 One of the referees of this paper suggested to explore this idea.
5 “... the dwarfs found out how to turn lead into gold by doing it the hard way.
The diﬀerence between that and the easy way is that the hard way works.” Terry
Pratchett, The Truth, 2000.
11

where c : C and ids : st c .= s, or of the form
(l, r, idc, c, ids)
where l : CTSeq s, r : R, idc : co r .= co l, c : C, ids : st c .= nxt r and co l
denotes the last command of the sequence l, i.e.
co (c, ids) = co (l, r, idc, c, ids) = c.
Note that we have to deﬁne the function co mutually with the sets CTSeq s,
i.e. the deﬁnition is by induction-recursion [9]. The idea here is that a list
represents an initial part of a possible program execution. The identities ensure
that the list is accurate for the interface. We need some auxiliary notions:
Deﬁnition 5 (Last state, Predecessor)
We denote the last state of the sequence l : CTSeq s by st l, i.e. st (c, ids) :=
s, st (l, r, idc, c, ids) := nxt r. We denote the modiﬁed predecessor of the se-
quence l by pd l, i.e. pd (c, ids) := (c, ids), pd (l, r, idc, c, ids) := l.
Deﬁnition 6 (Append)
We deﬁne mutually
l0 ⋆⟨r, idc⟩⋆l1 : CTSeq s
and an inhabitant of
co l1 .= co (l0 ⋆⟨r, idc⟩⋆l1)
(1)
for s : S, l0 : CTSeq s, r : R, idc : co r .= co l0, l1 : CTSeq (nxt r) by
l0 ⋆⟨r, idc⟩⋆(c, ids) := (l0, r, idc, c, ids)
l0 ⋆⟨r, idc⟩⋆(l, r′, idc′, c, ids) := ((l0 ⋆⟨r, idc⟩⋆l), r′, idc′′, c, ids)
where we obtain idc′′ from idc′ by the inhabitant of 1 which is deﬁned as reﬂc
in both cases.
Note that deﬁnition by cases is necessary in the deﬁnition of the inhabitant
of 1 since otherwise the terms would not evaluate.
Proposition 7 (Associativity of append)
l0 ⋆⟨r0, idc0⟩⋆(l1 ⋆⟨r1, idc1⟩⋆l2) .= (l0 ⋆⟨r0, idc0⟩⋆l1) ⋆⟨r1, idc′
1⟩⋆l2
where idc′
1 is obtained from idc1 by the inhabitant of
co l1 .= co (l0 ⋆⟨r0, idc0⟩⋆l1)
due to 1.
12

Proof: Induction on l2. If l2 ; (c, ids) both sides of the equation evaluate to
the same value. Let l2 ; (l, r, idc, c, ids).
Let c1 := co l1, c′
1 := co (l0 ⋆⟨r0, idc0⟩⋆l1).
Let lleft := l0 ⋆⟨r0, idc0⟩⋆(l1 ⋆⟨r1, idc1⟩⋆l) and lright := (l0 ⋆⟨r0, idc0⟩⋆l1) ⋆
⟨r1, idc′
1⟩⋆l. By I.H. we have
idl : lleft .= lright.
Let cl := co
l, c′
l := co (l1 ⋆⟨r1, idc1⟩⋆l), cleft := co lleft, cright := co lright.
We have inhabitants of
cl .= c′
l
c′
l .= cleft
cl .= cright
by which we obtain inhabitants
idc′
l : co r .= c′
l
idcleft : co r .= cleft
idcright : co r .= cright
from idc. By idl we obtain a second inhabitant
idc′
right : co r .= cright
from idcleft and with UIP C we conclude that idc′
right .= idcright and
⟨lleft, idcleft⟩.= ⟨lright, idcright⟩
(2)
by Principle 2. Now l0 ⋆⟨r0, idc0⟩⋆(l1 ⋆⟨r1 idc1⟩⋆l2) evaluates to
(lleft, r, idcleft, c, ids)
and (l0 ⋆⟨r0, idc0⟩⋆l1) ⋆⟨r1, idc′
1⟩⋆l2 to
(lright, r, idcright, c, ids).
The claim follows by 2 with Principle 1.
Remark: Note that to conclude that 2 holds, we have to prove that idc′
right
equals idcright. We obtained idc′
right from idcleft by shifting it along idl. Since
we know nothing 6 about idl (we got idl from the I.H.) we know nothing about
idc′
right. So to force the needed equality we apply UIP C.
Corollary 8
(c, ids0) ⋆⟨r, idc⟩⋆l .= (c, ids1) ⋆⟨r, idc⟩⋆l
for ids0, ids1 : (st c) .= s.
Proof: With UIP S.
6 At least we do not know if types depending on idl are inhabited.
13

Corollary 9
(c0, ids0) ⋆⟨r, idc⟩⋆l .= (c1, ids1) ⋆⟨r, idc′⟩⋆l
for id : c0 .= c1, idsi : (st ci) .= s (i = 0, 1) and idc′ = subst id idc.
Proof: Case id = reﬂc.
We are going to deﬁne a universe U. The deﬁnition is by induction-recursion
[9]. The universe U is a relatively small universe. It contains names for the
sets S, C, R and is closed only under the identity and sigma type formers. For
the general rˆole of universes in type theory and the proof theoretic strength
gained by (much larger) universes compare [35,40].
Deﬁnition 10 (Universe)
We deﬁne mutually
U : Set
= data NameS | NameC | NameR |
NameId (u : U)(e1, e2 : set u) | NameSig (u : U)(f : (e : set u) →U)
and
set(u : U) : Set
by
set NameS
= S
set NameC
= C
set NameR
= R
set (NameId u e1 e2) = (e1 .=(set u) e2)
set (NameSig u f)
= P(e : (set u).(set (f e)))
We write NIdC for NameId NameC.
We want to deﬁne computation trees as functions T : CTSeq s →U with the
following properties:
(1) There is exactly one root c : C for the tree.
(2) For every l : CTSeq s which is a node of the tree and for every r : R suit-
able for l there is exactly one successor, i.e. one c such that (l, r, idc, c, ids)
is a node of the tree.
(3) For every l : CTSeq s which is a node of the tree the predecessor of l is a
node of the tree too.
14

Where a list l is a node of the tree if set (T l) is inhabited and r : R is suitable
for l if co r .= co l. Technically a computation tree will be a dependent tuple
of a function T together with a witness that the function fulﬁlls the properties
above (Deﬁnition 12). The properties are expressed by sigma types (Deﬁnition
11). We formalise this ideas as follows:
Deﬁnition 11 For s : S, T : CTSeq s →U let Φ1 s T be
sig root
: C
idS
ro
: st root .= s
rootex : set (T(root, idS
ro))
rootuni : ∀c : C, idsc : st c .= s. set (T (c, idsc)) ⇒c .= root
For s : S, T : CTSeq s →U, l : CTSeq s, e : set (T l), r : R and
idcr : co r .= (co l) let Φ2 s T l e r idcr be
sig command
: C
idS
co
: st command .= nxt r
commandex : set (T(l, r, idcr, command, idS
co))
commanduni : ∀c : C, idsc : st c .= nxt r. set (T (l, r, idcr, c, idsc)) ⇒
c .= command
For s : S, T : CTSeq s →U, l : CTSeq s and e : set (T l) let Φ3 s T l e
be
set (T (pd l))
Let Φ s T be (Φ1 s T) ∧(Φ2 s T) ∧(Φ3 s T).
Note the natural way in which we make use of dependent types in this def-
inition: We quantify in Φ only about those l which are nodes of the tree T:
argument e : set (T l) in Φ1 and Φ2. This will play an important rˆole later.
We are now able to deﬁne the family of sets in the object part of the ﬁnal
coalgebra:
Deﬁnition 12 (Computation trees)
CT (s : S) : Set
=
sig tree : CTSeq s →U
phi : Φ s tree
15

Before we deﬁne an equivalence relation on this family we declare the mor-
phism of the ﬁnal coalgebra. We single out the command of each tree by using
the witness for the property Φ1.
Deﬁnition 13 (Command of a computation tree)
For ct : CT s : with ctphi ; (ϕ1, ϕ2, ϕ3)
co ct := ϕ1root
idS
co ct := ϕ1idSro
The program that we obtain after doing one computation step and receiving
a response r is represented by the subtree at branch r. A subtree is given by
taking the tree function on another position. The argument is constructed by
means of the append function on lists.
Deﬁnition 14 (elimtree)
For ct : CT s, r : R and idc : co r .= co ct let
elimtree s ct r idc : CTSeq (nxt r) →U
given by
λl : CTSeq (nxt r) .

cttree

(c, ids) ⋆(r, idc) ⋆l

,
where c = co ct and ids = idS
co ct.
We need to prove that the deﬁned function has the properties Φ1-Φ3.
Proposition 15 For ct : CT s, r : R and idc : (co r) .= (co ct)
Φ1 (nxt r) (elimtree s ct r idc).
Proof: Let c = co ct and ids = idS
co ct. The inhabitant of Φ1 s cttree gives an
inhabitant e : set(cttree s (c, ids)). The inhabitant of Φ2 s cttree (c, ids) e r idc
proves the claim.
Proposition 16 For ct : CT s, r : R and idc : (co r) .= (co ct)
Φ2 (nxt r) (elimtree s ct r idc).
Proof: Let l : CTSeq (nxt r), e : set (elimtree s ct r idc l), r′ : R, idc′ :
(co r′) .= (co l). Let c = co ct and ids = idS
co ct. By 1 we get an inhabitant
idc′′ : (co r′) .= (co ((c, ids) ⋆⟨r, idc⟩⋆l) from idc′ and the inhabitant of
Φ2 s cttree ((c, ids) ⋆⟨r, idc⟩⋆l) e r′ idc′′ proves the claim.
16

Proposition 17 For ct : CT s, r : R and idc : (co r) .= (co ct)
Φ3 (nxt r) (elimtree s ct r idc).
Proof: Induction on l : CTSeq (nxt r).
The morphism part of the ﬁnal coalgebra is now given by:
Deﬁnition 18 (elim)
For ct : CT s we deﬁne
elim s ct : Prog s CT
by
⟨co ct, idS
co ct, nextEl⟩
where nextEl r idc : CT (nxt r) is given by elimtree s ct r idc and Propositions
15-17 for r : R and idc : (co r) .= (co ct).
We write nextEl ct for (elim ct)nextEl.
5.1
Bisimulation
We still need to deﬁne an equivalence relation on CT. The function elim gives
a labelled transition system. There is a transition r : R between trees T0 and
T1 if T1 is the subtree of T0 at branch r. Since this transition system is image
ﬁnite we can deﬁne bisimulation by means of natural induction.
Deﬁnition 19 (Bisimulation)
For ct, ct′ : CT s, n : N we deﬁne
ct ∼n ct′ : Set
by
ct ∼zero ct′
= True
ct ∼succ n ct′ = sig
idc : c .= c′
fct : (r : R, idcr : (co r) .= c) →f r idcr ∼n f ′ r idcr′
and
ct ∼ct′ : Set
= ∀n : N. ct ∼n ct′
17

where elim s ct ; ⟨c, idc, f⟩, elim s ct′ ; ⟨c′, idc′, f ′⟩and idcr′ is obtained
from idcr by idc.
Proposition 20 ∼is an equivalence relation on CT.
Proof: Straight forward.
Proposition 21
ct ∼ct′
⇔
elim s ct ∼Prog elim s ct′
for ct, ct′ : CT s.
Proof: “⇒” Follows with UIP C.
“⇐” Trivial.
Corollary 22 elim : CT →Prog CT is extensional.
This means that elim is a coalgebra morphism. We are going to prove, that
elim : CT →Prog CT is a ﬁnal coalgebra for Prog.
6
The unique morphism T into the ﬁnal coalgebra
Let B : S →Set and g : (s : S, B s) →Prog B s. We keep B, g ﬁxed for
the rest of the article. We write co b, idS
co b and nextEl s b for (g s b)command,
(g s b)idSco, (g s b)nextEl respectively where b : B s. We must ﬁnd a unique
morphism T : B →CT with elim ◦T = Prog T ◦g, i.e. elim s (T s b) ∼Prog
(Prog T) s (g s b) for s : S, b : B s. We get T by deﬁning mutually the function
value Ttree s b l : U for l : CTSeq s and an element of B (nxt r) for those l
which are nodes of Ttree s b where r is a response of co l. This element is
essentially the element which we get if we follow g along the responses which
occur in l including r. The list (c, ids) is a node of the tree Ttree s b if c is the
command played by g at b, i.e. (co b) .= c. The list (l, r, , c, ) is a node of
the tree Ttree s b if l is a node of Ttree s b and c is the command played by g at
the element of B (nxt r) described above. Things again become quite involved
since we have to shift the identities to meet the typing requirements.
Deﬁnition 23 We deﬁne mutually
Ttree s b l : U
and
A s b l r idc e : B (nxt r)
18

for s : S, b : B s, l : CTSeq s, r : R, idc : co r .= co l and e : set (Ttree s b l) by
Ttree s b (c, ids) := NIdC c (co b)
Ttree s b (l′, r′, idc′, c, ids) := NameSig (Ttree s b l′)(λe : set(Ttree s b l′). NIdC c (c′ e))
where c′ e := co (A s b l′ r′ idc′ e) and
A s b (c, ids) r idc e := nextEl s b r idce
A s b (l′, r′, idc′, c, ids) r idc e := nextEl (nxt r′) b′ r idc′′
where in the ﬁrst case idce is the composition of idc and e, and in the second
case b′ := A s b l′ r′ idc′ efst, esnd : c .= (co b′) and idc′′ := subst esnd idc.
We lift UIP C to set(Ttree s b l):
Proposition 24
∀p, q : set(Ttree s b l) ⇒p .= q
for s : S, b : B s, l : CTSeq s.
Proof: If l ; (c, ids) this is UIP C.
Let l ; (l′, r, idc, c, ids), p, q : set(Ttree s b l) with p ; ⟨p′, idcp⟩and q ;
⟨q′, idcq⟩. We have id : p′ .=set(T s b l′) q′ by I.H. and idcp′ .= idcq by UIP C
where we obtain idcp′ from idcp by id. This proves the claim.
Corollary 25
A s b l r idc p .= A s b l r idc q
for s : S, b : B s, l : CTSeq s, r : R, idc : (co r) .= (co l) and p, q :
set (Ttree s b l).
Proof: Immediate from 24.
The following three propositions state that Ttree s b is indeed an element of
CT, i.e. that Ttree s b fulﬁls the properties Φ1 −Φ3.
Proposition 26 For s : S, b : B s
Φ1 s (Ttree s b).
Proof: The following term proves the claim:
⟨co b, idS
co b, reﬂ(co b), rootuniT⟩
where rootuniT c idsc p := p for c : C, idsc : (st c) .= s and p : set(Ttree s b (c, idsc)).
19

Proposition 27 For s : S, b : B s
Φ2 s (Ttree s b).
Proof: Let l : CTSeq s, p : set (Ttree s b l), r : R, idcr : (co r) .= (co l).
For x : set(Ttree s
b l) let b′ x := A s b l r idcr x, c′ x := co (b′ x) and
ids′ x := idS
co (b′ x). The following term proves the claim
⟨c′ p, ids′ p, (p, reﬂc′ p), commanduniT⟩
where commanduniT c idsc q := subst id qsnd and id : qfst .= p the inhabitant
according to Proposition 24 for c : C, idsc : st c .= nxt r and q : set(Ttree s b (l ⋆
⟨r, idcr⟩⋆(c, idsc))).
Proposition 28 For s : S, b : B s
Φ3 s (Ttree s b).
Proof: Obvious
Deﬁnition 29 Let T(s : S)(b : B s) : CT s be
⟨Ttree s b, Tphi s b⟩
where Tphi s b is given by the Propositions 26 - 28.
We postpone the proof that T is extensional.
7
The Repetition of the unique morphism T
We want to prove that T is the unique morphism making the coalgebra square
below commute.
B
g - Prog B
CT
T
?
elim
- Prog CT
Prog T
?
That means we have to prove
b0 ≡b1 ⇒(Prog T ◦g) b0 ∼(elim ◦T) b1
20

for s : S and b0, b1 : B s, where ≡denotes the equivalence relation on B. We
have
ct0 ∼n ct1 ⇔co ct0 .= co ct1 and
nextEl ct0 r0 idcr0 ∼n−1 nextEl ct1 r0 idcr′
0
⇔. . . and
nextEl (nextEl ct0 r0 idcr0) r1 idcr1 ∼n−2
nextEl (nextEl ct1 r0 idcr′
0) r1 idcr′
1
⇔. . .
for ct0, ct1 : CT s. This observation leads to the deﬁnition of the repetition
TRep of T which we use in the following to prove the coalgebra property. We
deﬁne the repetition TRep of T for every sequence l : CTSeq s which belongs
to Ttree s b. Essentially this will be the subtree of Ttree which we get when we
follow the tree along the path l. We want to deﬁne this by recursion on l. Again
this can not be done in a straight forward way, since the elements we get by
the induction hypothesis do not have the desired type. That means we have
to shift them along certain identities which must be deﬁned simultaneously.
Therefore we deﬁne mutually
TRep s b l p : CT(st l)
and identities
co l .=C co (TRep s b l p)
(3)
(TRep s b l p)tree l′ .=U Ttree s b (l#l′)
(4)
where s : S, b : B s, l : CTSeq s, p : set(Ttree s b l), l′ : CTSeq(st l) and
(c, ids)#l′ := l′
(l0, r, idc, c, ids)#l′ := (l0 ⋆⟨r, idc⟩⋆l′).
The second identity (in U) is needed to prove the ﬁrst one (in C).
Deﬁnition 30 (Repetition of T)
We deﬁne mutually
TRep(s : S)(b : B s)(l : CTSeq s)(p : set(Ttree s b l)) : CT (st l)
by
TRep s b (c, ids) p
= T s b
TRep s b (l′ r idc c ids) p = nextEl (TRep s b l′ p′) r idc′
21

where p′ = ϕ3 s b l p, ϕ3 : Φ3 s (Ttree s b) as in Proposition 28 and idc′
obtained from idc by the identity 3.
We deﬁne an inhabitant of
co l .= co (TRep s b l p)
by
p
if l = (c, ids)
ϕ1rootuni c ids p′ if l = (l′, r, idc, c, ids)
where ϕ1 : Φ1 (TRep s b l p) as given by Proposition 26 and p′ obtained from
p by the identity 4.
To complete the deﬁnition we must deﬁne an inhabitant of
(TRep s b l p)tree l′ .= Ttree s b (l#l′)
for s : S, b : B s, l : CTSeq s, p : set(T s b l) and l′ : CTSeq (st l).
In the case l ; (c, ids) an inhabitant of this type is given by
reﬂ(Ttree s b (l#l′))
since both sides of the equation evaluate to the same value.
For l ; (l0, r, idc, c, ids) let p′ as above,
s0 := st l0
cl0 := co (TRep s b l0 p′),
idcsl0 := idS
co (TRep s b l0 p′),
sl0 := (cl0, idcsl0),
sl1 := (c0, idcs0),
where l0 = (. . . , c0, idcs0) and idc′ obtained from idc by the identity 3. Let
left = (TRep s b l0 p′)tree (sl0 ⋆⟨r, idc′⟩⋆l′)
middle = Ttree s b (l0#(sl0 ⋆⟨r, idc′⟩⋆l′))
right = Ttree s b (l0 ⋆⟨r, idc⟩⋆l′).
We must prove left .= right. We have sl0 ⋆⟨r, idc′⟩⋆l′ .= sl1 ⋆⟨r, idc⟩⋆l′ by
Corollary 9 and by I.H.
left .= middle.
If l0 ; (c0, idcs0) then
middle .= right
by Principle 1 and we are done.
If l0 ; (l1, r0, idcr0, c0, idcs0) then
22

l1 ⋆⟨r0, idcr0⟩⋆(sl0 ⋆⟨r, idc⟩⋆l′) .= l1 ⋆⟨r0, idcr0⟩⋆(sl1 ⋆⟨r, idc′⟩⋆l′)
.= (l1 ⋆⟨r0, idcr0⟩⋆sl1) ⋆⟨r, idc′⟩⋆l′
.= l0 ⋆⟨r, idc′⟩⋆l′
where the ﬁrst equation follows by Principle 1 and the second by the associa-
tivity of ⋆. Principle 1 gives
middle .= right
and we are done again.
Remark: Note that we could deﬁne the repetition of ct for arbitrary ct : CT s.
Therefore we can proceed in a similiar way as above. We just need to replace
p by ϕ1rootuni c ids p in the ﬁrst case of the construction of the inhabitant of
the identity 3 where ϕ1 is the witness for Φ1 s ct. However since this greater
generality has no particular advantage for us we work with the deﬁnition
above.
As a corollary to Proposition 24 we get:
Corollary 31
TRep s b l p .= TRep s b l q
for p, q : Ttree s b l.
We need some auxiliary deﬁnitions. Let
nxtS s (c, ids) r := nxt r
nxtS s (l′, r′, idc, c, ids) r := nxtS s l′ r′
pred s (c′, ids′) r idc c ids := (c, ids)
pred s (l′, r′, idc′, c′, ids′) r idc c ids := ((pred s l′ r′ idc′ c′ ids′), r, idcr, c, ids)
where idcr is obtained from idc by the simultaneously deﬁned inhabitant of
c .= co (pred s l r idc c ids)
(5)
which is given in both cases by reﬂc. Note that deﬁnition by cases is neces-
sary again to deﬁne this inhabitant. The operation pred
l cuts oﬀthe ﬁrst
command and response of the list l. Since this is only possible for lists of the
form (l′, r′, idc′, c′, ids′) we use the auxiliary arguments r, idc, c and ids. The
obtained list is an inhabitant of CTSeq (nxtS s l r). Further we deﬁne an
inhabitant of B (nxtS s l r) by
nextB s (c′, ids′) r idc c ids b (id0, id1) := A s b (c′, ids′) r idc id0
nextB s (l′, r′, idc′, c′, ids′) r idc c ids b (p′, id1) := nextB s l′ r′ idc′ c′ ids′ b p′
23

where b : B s and p : set (Ttree s b (l, r, idc, c, ids)) for p ; (id0, id1),
p ; (p′, id1) and l ; (c′, ids′), l ; (l′, r′, idc′, c′, ids′) respectively. The in-
habitant nextB
l r
is calculated by doing essentially only the ﬁrst step in
the calculation of A
l r . Whereas A
l r
gives us an element of B (nxt r)
by following all responses in l including r, nextB
l r
is doing only the ﬁrst
step. The following Proposition states that we get equal elements in B (nxt r0)
whether we apply A on b and a sequence (l, r, idcr, c, idsc) or do one step from
b along this sequence and use the sequence obtained from (l, r, idcr, c, idsc) by
pred above.
Proposition 32 For s : S, l : CTSeq s, r, r0 : R, c : C, b : B s,
idcr : co r
.= co l
idsc : st c
.= nxt r
idcr0 : co r0 .= c
p : set (Ttree s b (l, r, idcr, c, idsc)), q : set (Ttree sn bn lp) where
sn = nxtS s l r
bn = nextB s l r idcr c idsc b p
lp = pred s l r idcr c idsc
we have
A s b (l, r, idcr, c, idsc) r0 idcr0 p .= A sn bn lp r0 idcr′
0 q
where idcr′
0 is obtained from idcr0 by the identity 5.
Proof: Case l ; (c′, ids), p ; (id0, id1).
Then idcr′
0 evaluates to idcr0. Let idcr1, idcr2 obtained from idcr0 by id1, q
respectively. By UIP C we have
idcr1 .= idcr2
and by Principle 1 we get
A s b ((c′, ids), r, idcr, c, idsc) r0 idcr0 (id0, id1) .= f idcr1
.= f idcr2
.= A sn bn lp r0 idcr0 q
where f = (g (nxt r) ((g s b)nextEl r idcr′))nextEl r0 and idcr′ obtained from idcr
by id0.
Case l ; (l′, r′, idc′, c′, ids), p ; (p′, id1), q ; (q′, id2).
24

Then again idcr′
0 evaluates to idcr0. We deﬁne
f : (x : B (nxt r)) →IdC x →B (nxt r0)
where IdC x := ((co r0) .= (co x)) by
f x y = (g (nxt r) x)nextEl r0 y
for x : B (nxt r), y : IdC x.
By I.H. we have
ih : A s b (l′, r′, idc′, c′, ids) r idcr p′
|
{z
}
=: left b
.= A s′
n b′
n l′
p r idcr2 q′
|
{z
}
=: right b
where idcr2 is obtained from idcr by identity 5 and
s′
n := nxtS s l′ r′
b′
n := nextB s l′ r′ idcr′ c′ ids b p′
l′
p := pred s l′ r′ idcr′ c′ ids.
Let idcr1, idcr3 obtained from idcr0 by id1, id2 respectively. By UIP C we get
subst ih idcr1 .= idcr3.
That means
(left b, idcr1) .= (right b, idcr3)
and by Principle 1 we get
A s b (l, r, idcr, c, idsc) r0 idcr0 p .= f left b idcr1
.= f right b idcr3
.= A sn bn lp r0 idcr′
0 q
Corollary 33
co (A s b (l, r, idcr, c, idsc) r0 idcr0 p) .= co (A sn bn lp r0 idcr′
0 q).
Let s : S, l : CTSeq s, r : R, idcr : (co r) .= (co l), c : C, idsc : (st c) .= (nxt r).
We deﬁne an inhabitant of
st (l, r, idcr, c, idsc) .= st (pred s l r idcr c idsc)
(6)
by reﬂ(nxt r) according to the shape of l. Again deﬁnition by cases is nec-
essary to deﬁne this inhabitant. The following Lemma will be our main tool
25

to prove all desired properties of T. Roughly speaking it says that we get the
same trees whether we take the subtree following the tree at b along the path
(l, r, idcr, c, idsc) or do one step from b along this sequence (get a new bn) and
following the tree at bn along the path obtained from (l, r, idcr, c, idsc) by pred
above.
Lemma 34 (Main Lemma)
Let s, l, r, c, b, idcr, idsc, p, q as well as sn, bn, lp as in Proposition 32. Then
TRep
′ s b (l, r, idcr, c, idsc) p ∼TRep sn bn lp q
where we obtain the left term from TRep s b (l, r, idcr, c, idsc) p by the identity
6.
Proof: We have to distinguish cases l ; (c′, ids) and l ; (l′, r′, idc′, c′, ids) in
order to have
TRep
′ s b (l, r, idcr, c, idsc) p ↭TRep s b (l, r, idcr, c, idsc) p.
However the proof proceeds in the same way in both cases:
Let n : N. For n ; zero is nothing to do. Let n ; succ m. Let l+ :=
(l, r, idcr, c, idsc) and
c0 := co (TRep s b l+ p)
c1 := c
c2 := co lp
c3 := co (TRep sn bn lp q)
We have
c0 .= c1 .= c2 .= c3
where the ﬁrst and last equation follow with the identity 3 and the second
with the identity 5.
Now let r0 : R and idcr0 : co r0 .= c0. For i = 0, 1, 2 we obtain elements
idcri+1 : co r0 .= ci+1 from idcri by the identities above. Further we obtain
a second element idcr′
0 : co r0 .= c0 from idcr1 and a second element idcr′
3 :
co r0 .= c3 from idcr0. We have idcr0 .= idcr′
0 and idcr3 .= idcr′
3
7 . Let
nxt lft := nextEl
(TRep s b l+ p) r0
nxt rgt := nextEl
(TRep sn bn lp q) r0
and ct0
:=
nxt lft
idcr′
0, ct1
:=
nxt lft
idcr0, ct2
:=
nxt rgt
idcr3,
ct3 := nxt rgt idcr′
3. We have ct0 .= ct1 and ct2 .= ct3. We have to prove
7 We do not need UIP C for this.
26

ct1 ∼m ct3. Therefore it is enough to prove
ct0 ∼m ct2.
Let
cp := co (A s b l+ r0 idcr1 p),
cp id := idS
co (A s b l+ r0 idcr1 p)
idcp
given by identity 5.
We have
(p, reﬂcp) : set(Ttree s b (l+, r0, idcr1, cp, cp id))
(q, idcp) : set(Ttree sn bn (pred s l+ r0 idcr1 cp cp id))
and
ct0 ↭TRep
′ s b (l+, r0, idcr1, cp, cp id) (p, reﬂcp)
ct2 ↭TRep sn bn (pred s l+ r0 idcr1 cp cp id) (q, idcp).
Therefore the claim follows by I.H. applied to s : S, l+ : CTSeq s, r0 : R,
cp : C, b : B s, idcr1 : co r0 .= c, cp id : st cp .= nxt r0, (p, reﬂcp), (q, idcp) and
m : N.
Corollary 35 For s : S, b : B s, r : R, idcr : (co r) .= co (T s b), we have
(elim s (T s b))nextEl r idcr ∼(Prog T s (g s b))nextEl r idcr.
Proof: Apply the Main Lemma to s, (c0, ids0), r, c1, b, idcr, ids1, (reﬂc0, reﬂc2),
reﬂc3 where
c0 := co (T s b)
ids0 := idS
co (T s b)
c1 := co (nextEl
(T s b) r idcr)
ids1 := idS
co (nextEl
(T s b) r idcr)
c2 := co (A s b (c0, ids0) r idcr (reﬂc0))
c3 := co ((g s b)nextEl r idcr).
Note that (Prog T s (g s b))nextEl r idcr ; T (nxt r) ((g s b)nextEl r idcr).
27

8
Proof of the Final Coalgebra Property
Proposition 36 If g is extensional, then T is extensional.
Proof: We denote the equivalence relation on B by ≡and the witness that g
is extensional by ext. The proof is by natural induction. Let s : S, b0, b1 : B s,
rel : b0 ≡b1, n ; succ m : N. Let
c0 := co (T s b0)
c1 := co (T s b1)
left fun := (g s b0)nextEl
right fun := (g s b1)nextEl
id := (ext s b0 b1 rel)idc : c0 .= c1
The term id gives the ﬁrst component of the inhabitant we have to construct.
For the second component let r : R, idcr : (co r) .= c0. We have to prove
(elim s (T s b0))nextEl r idcr ∼m (elim s (T s b1))nextEl r idcr′
where idcr′ := subst id idcr. Let b′
0 := left fun r idcr, b′
1 := right fun r idcr′
then (ext s b0 b1 rel)fct r idcr gives b′
0 ≡b′
1 and by I.H. we have
T (nxt r) b′
0 ∼m T (nxt r) b′
1.
The claim follows with Corollary 35.
Lemma 37
elim ◦T = Prog T ◦g
Proof: Let s : S, b0, b1 : B s, rel : b0 ≡b1, c0 := ((elim ◦T) s b0)command,
c1 := ((Prog T ◦g) s b1)command. It is id := ext s b0 b1 rel : c0 .= c1. Let n : N,
r : R and idcr : (co r) .= c0. Then follows
((elim ◦T) s b0)nextEl r idcr ∼n ((Prog T ◦g) s b0)nextEl r idcr′
∼n ((Prog T ◦g) s b1)nextEl r idcr′
where idcr′ := subst id idcr and the ﬁrst relation follows by Corollary 35 and
the second by the extensionality of g and Prog T.
Lemma 38 For T′ : B →CT with
elim ◦T′ = Prog T′ ◦g
we have T′ = T.
28

Proof: Natural induction. Let s : S, b0, b1 : B s, rel : b0 ≡b1, n ; succ m : N.
Let comm : elim ◦T′ = Prog T′ ◦g, c0 := ((elim ◦T′) s b0)command, c1 :=
((elim ◦T) s b1)command. Then
id := (comm s b0 b1 rel)idc : c0 .= c1.
Let r : R and idcr : (co r) .= c0 then
(T′ s b0)nextEl r idcr ∼n T′ (nxt r) ((g s b1)nextEl r idcr′)
(7)
∼n T (nxt r) ((g s b1)nextEl r idcr′)
(8)
∼n (T s b1)nextEl r idcr′
(9)
where idcr′ := subst id idcr. The relation 7 follows by (comm s b0 b1 rel)fct r idcr,
the relation 8 by the I.H. and the fact that ≡is reﬂexive and the relation 9
by Corollary 35.
Theorem 39 elim : CT →Prog CT is a ﬁnal coalgebra for Prog
Proof: Lemmata 37 and 38.
9
Carry over the Result to the original Functor of Hancock/Setzer
In this section we are going to translate the result to the original functor
ProgHS of Hancock/Setzer above. We ﬁrst notice that we can write an uncur-
ried version of the functor Prog as
Proguc X s :=
X
(p : (FamToPred′ st) s,
(q : (FamToPred′ co) pfst) →X (nxt qfst)).
We can prove a ﬁnal coalgebra theorem for this functor in the same way
as above (this is just a rearrangement of parentheses). If (S, C, R, st, co, nxt)
comes from an Hancock/Setzer-interface (S, C, R, n) as described in section
2.4, Proguc X s rewrites to
P (p : P(sc : P(S, C), (st sc) .= s),
(q :
P(scr :
P(
P(S, C), R′), (co scr) .=P
(S,C) pfst)) →X (nxt qfst)).
where st and co are the ﬁrst projections and R′ is the uncurried version of R.
We deﬁne functions
u hs : Proguc X s →ProgHS X s
29

by
⟨⟨⟨s′, c⟩, id⟩, f⟩7→⟨c′, f ′⟩
where c′ := subst id c, f ′ r := f ⟨⟨⟨s, c′⟩, r⟩, id′⟩and id′ : ⟨s, c′⟩.= ⟨s′, c⟩
deﬁned by structural induction on id : s′ .= s and
hs u : ProgHS X s →Proguc X s
by
⟨c, f⟩7→⟨⟨⟨s, c⟩, reﬂs⟩, f ′⟩
where f ′ p = (subst psnd f) pfst.
We have p ↭u hs (hs u p) and therefore p .= u hs (hs u p). We deﬁne
equivalence relations ∼= on Proguc X s by
⟨scid0, f0⟩∼= ⟨scid1, f1⟩:⇔∃id : scid0 .= scid1.pointeq (f ′
0 id) f1
where f ′
0 id := subst id f0 and pointeq (f ′
0 id) f1 expresses that (f ′
0 id), f1 are
pointwise equal. By structural induction on id follows that we have
∼= ⊂≡Prog
for arbitrary equivalence relations ≡on X. Further we have
Proposition 40
p ∼= hs u (u hs p)
for p : Proguc X s.
Proof: Let p ; ⟨⟨⟨s′, c′⟩, ids⟩, f⟩. We prove
⟨⟨⟨s′, c′⟩, ids⟩, f⟩∼= hs u (u hs ⟨⟨⟨s′, c′⟩, ids⟩, f⟩)
by structural induction on ids. That means we have to prove
⟨⟨⟨s, c′⟩, reﬂs⟩, f⟩∼= hs u (u hs ⟨⟨⟨s, c′⟩, reﬂs⟩, f⟩).
We get an inhabitant of this type by setting the ﬁrst component
reﬂ⟨⟨s, c′⟩, reﬂs⟩.
The second component must now have type
pointeq f (hs u ⟨c, f ′⟩)snd
where f ′ := λr : R′ ⟨s, c′⟩.f ⟨⟨⟨s, c′⟩, r⟩, reﬂ⟨s, c′⟩⟩. Let sc′ : P(S, C) and
⟨⟨sc, r⟩, idsc⟩:
P(scr :
P(
P(S, C), R′), scrfst .=P
(S,C) sc′). By structural in-
duction on idsc we get
f ⟨⟨sc, r⟩, idsc⟩.= (subst idsc f ′′) r
30

where f ′′ := λr : R′ sc′.f ⟨⟨sc′, r⟩, reﬂsc′⟩. By setting sc′ = ⟨s, c′⟩we get
f ⟨⟨sc, r⟩, idsc⟩.= (hs u ⟨c, f ′⟩)snd ⟨⟨sc, r⟩, idsc⟩.
Corollary 41
p ≡Prog hs u (u hs p)
for p : Proguc X s.
To view ProgHS as a functor in our category we must say what ProgHS is doing
on the equivalence relations ≡on X. Therefore we deﬁne
p ≡ProgHS q :⇔(hs u p) ≡Prog (hs u q).
hs u, u hs are extensional in respect of this relations and we have
hs u(u hs p) ≡Prog p
u hs(hs u q) ≡ProgHS q,
i.e. Proguc X s and ProgHS X s are isomorphic in our category. We have
UIP S, UIP C ⇔UIP S ∧∀s : S.UIP C s.
Therefore we get
Theorem 42 If UIP S ∧∀s : S.UIP C s then u hs ◦elim : CT →ProgHS CT is
a ﬁnal coalgebra for ProgHS.
10
Related and future work
As we have seen, working in intensional type theory becomes quite compli-
cated. The dependency on proof objects for simple equations results in an
intricate argumentation. We also needed the principle UIP for the sets S, C for
our proof to go through. So, what did we gain by the result above? First of
all as already mentioned the result can be seen as a justiﬁcation for the rules
of Hancock/Setzer if we replace deﬁnitional equality by bisimulation and have
UIP for the sets S, C. We are convinced that replacing deﬁnitional identity by
bisimulation is not a serious restriction as long as we are mainly interested in
the behaviour of programs. Results such as those in Michelbrink/Setzer [33]
that the monad rules hold should be provable with the altered rules. There is
also an advantage if we want to prove facts about the behaviour of concrete
interactive programs: We proved that the functor ProgHS has a ﬁnal coalge-
bra whereas the rules of Hancock/Setzer give us a weakly ﬁnal coalgebra only
(uniqueness is missing). This should outweigh that concrete interactive pro-
grams are given by extensional functions X →Prog X whereas in the approach
31

of Hancock/Setzer any such function is suﬃcient. Sets S, C with UIP S, UIP C
may as well be suﬃcient for practical work. However from a theoretical point
of view this restriction is unsatisfactory. It would be nice to improve the above
result by getting rid of these conditions. However the type theory enriched by
the rules for a weakly ﬁnal coalgebra as described in e.g. [33] results in far
more elegant proofs. Note also that more types become deﬁnitional equal by
these rules whereas two types which depend on bisimular programs do not
have to be equal. Secondly a deeper analysis of the proof above and a com-
parison with proofs in other frameworks may shed some light on why working
in intensional type theory is so hard. The same ﬁnal coalgebra construction is
already carried out in ZFC [33] and Gambino/Hyland [13] proved an initial
algebra theorem in extensional type theory. The problem of representing ﬁnal
coalgebras in type theory was addressed by Lindstr¨om [26] for the special case
of Aczel’s non-wellfounded sets. Lindstr¨om used an inverse-limit construction
that requires extensional type theory. What can be said already is that the
lack of a good concept for subsets as in set theory complicates work. Note
that the subset theory discussed in Nordstr¨om et al. [34] may be of less or no
help as long as we work in an intensional setting [38,37]. We think that Luo’s
coercive subtyping [27] may at least be a way to get crisper formulations.
There is an increasing interest in approaches to reason in dependent type the-
ory about imperative programming, interaction, non termination and general
recursion. We would like to mention recent work of Michael Abbott, Thorsten
Altenkirch, Neil Ghani and Conor McBride on containers [1,4,2,3]. The exten-
sion of a container (the result of applying the container construction functor
to a container) is a special variant of our functor ProgHS. More precisely a
container with parameters is a state dependent interface with trivial n where
the command sets do not depend on the state. A main diﬀerence to our work is
that Abbott et al. work in an extensional type theory (the identity type is given
by equalisers). In fact they require their ambient category to be locally carte-
sian closed, with disjoint coproducts, W- and M-sets. Geuvers [12] investigated
formalisations of inductive and coinductive types in diﬀerent lambda calculi,
mainly extensions of the polymorphic lambda calculus. He showed that by
adding a categorical notion of (primitive) recursion, recursion can be deﬁned
by corecursion and vice versa using polymorphism. Thierry Coquand proposed
in [7] to add a guarded proof induction principle to type theory to reason about
inﬁnite objects. He gives a syntactical criterion to ensure that every term has
a head normal form. Gimen´ez, E. [14] formalised an extension of the Calculus
of Construction with inductive and coinductive types using similar ideas. In
Venanzio Capretta’s [5] Ph.D. thesis coinductive types are added to Martin-
L¨of type theory with bisimulation as equality. Jean-Christophe Filiˆatre [10]
interpreted Hoare triples for a programming language with both imperative
and functional features in the Calculus of Inductive Constructions and proved
a correctness result. There is ongoing work following the line initiated by Pe-
ter Hancock and Anton Setzer [16–19,15,33,23] on reasoning about interfaces
and programs using ideas from category theory and functional programming,
32

linear logic, game theory, reﬁnement calculus and formal topology. Interfaces
can be seen as objects in diﬀerent categories and there are many interesting
monads, comonads, adjoint situations and equivalences. In the authors paper
[32] the notion of interfaces is generalised and simpliﬁed. With this simpliﬁed
notion the relationship of interfaces to games becomes apparent. Stateless net-
works like the internet are a natural application area for this simpliﬁed notion.
As shown by Hancock/Hyvernat [15] interfaces (interaction structures) seen
as predicate transformers give a connection to formal topology [39]. In fact
every interface gives a natural example for a non distributive topology. This
gives as well a (until now rather vague) interpretation of safety and liveness
properties of programs [25]. In [23,24] Hyvernat uses interfaces to give a model
of linear logic.
Acknowledgement
The author wishes to thank Anton Setzer and Peter Hancock for fruitful dis-
cussions and encouragement for this work. I also thank two anonymous ref-
erees for their valuable comments and remarks. This article would be much
less readable without their work. Last but not least I thank Ken Johnson for
correcting my english in this article.
References
[1] M. Abbott, T. Altenkirch, N. Ghani, Categories of Containers, in: A. Gordon
(Ed.), Proceedings of FOSSACS 2003, Vol. 2620 of Lecture Notes in Computer
Science, Springer-Verlag, 2003, pp. 23–38.
[2] M. Abbott, T. Altenkirch, N. Ghani, C. McBride, Derivatives of Containers, in:
M. Hofmann (Ed.), Typed Lambda Calculi and Applications, TLCA 2003, Vol.
2701 of Lecture notes in Computer Science, Springer, 2003, pp. 16–30.
[3] M. Abbott, T. Altenkirch, N. Ghani, C. McBride, ∂for data, Fundamenta
Informaticae 65 (1–2) (2005) 1–28.
[4] M. G. Abbott, Categories of Containers, Ph.D. thesis, University of Leicester
(2003).
[5] V. Capretta, Abstraction and Computation: Type Theory, Algebraic Structures,
and Recursive Functions, Ph.D. thesis, University of Nijmegen (2002).
[6] C. Coquand, Agda, Internet.
URL www.cs.chalmers.se/ catarina/agda/
33

[7] T. Coquand, Inﬁnite Objects in Type Theory, in: H. Barendregt, T. Nipkow
(Eds.), Selected Papers 1st Int. Workshop on Types for Proofs and Programs,
TYPES’93, Nijmegen, The Netherlands, 24–28 May 1993, Vol. 806, Springer-
Verlag, Berlin, 1994, pp. 62–78.
URL citeseer.ist.psu.edu/107677.html
[8] P. Dybjer, Inductive Families, Formal Aspects of Computing 6 (1994) 440–465.
[9] P. Dybjer, A General Formulation of Simultaneous Inductive-Recursive
Deﬁnitions in Type Theory, Journal of Symbolic Logic 65 (2) (2000) 525–549.
[10] J.-C. Filliatre, Veriﬁcations of Non-Functional Programs using Interpretations
in Type Theory, Journal of Functional Programming 13 (4) (2003) 709–745.
[11] G. Barthe, V. Capretta, O. Pons, Setoids in Type Theory, JFP 13 (2) (2003)
261 – 193.
[12] J. Geuvers, Inductive and Coinductive Types with Iteration and Recursion, in:
B. Nordstrom, K. Petersson, G. Plotkin (Eds.), Informal proceedings of the
1992 workshop on Types for Proofs and Programs, Bastad, Sweden, 1992, pp.
183 – 207.
[13] N. Gambino, M. Hyland, Wellfounded Trees and Dependent Polynomial
Functors, in: M. C. Stefano Berardi, F. Damiani (Eds.), Types for Proofs and
Programs (TYPES 2003): Third International Workshop, TYPES 2003, Torino,
Italy, April 30 - May 4, 2003, Revised Selected Papers, Vol. 3085 of Lecture
Notes in Computer Science, Springer, 2004.
[14] E. Gimen´ez, Codifying guarded deﬁnitions
with recursive
schemes,
in:
Proceedings of the 1994 Workshop on Types for Proofs and Programs, LNCS
No. 996, 1994, pp. 39–59.
[15] P. Hancock, P. Hyvernat, Programming Interfaces and Basic Topology, accepted
for publication (2004).
[16] P. Hancock, A. Setzer, The IO monad in dependent type theory, in: Electronic
proceedings of the workshop on dependent types in programming, G¨oteborg,
27-28 March, 1999.
URL www.md.chalmers.se/Cs/Research/Semantics/APPSEM/dtp99.html
[17] P. Hancock, A. Setzer, Interactive programs in dependent type theory, in:
P. Clote, H. Schwichtenberg (Eds.), Proc. of 14th Ann. Conf. of EACSL, CSL’00,
Fischbau, Germany, 21–26 Aug 2000, Vol. 1862, Springer-Verlag, Berlin, 2000,
pp. 317–331.
URL citeseer.ist.psu.edu/article/hancock00interactive.html
[18] P. Hancock, A. Setzer, Specifying interactions with dependent types, in:
Workshop on subtyping and dependent types in programming, Portugal, 7 July
2000, 2000, electronic proceedings.
URL www-sop.inria.fr/oasis/DTP00/Proceedings/proceedings.html
34

[19] P. Hancock, A. Setzer, Interactive Programs and Weakly Final Coalgebras
in Dependent Type Theory, in: L. Crosilla, P. Schuster (Eds.), From Sets
and Types to Topology and Analysis. Towards Practicable Foundations for
Constructive Mathematics, Oxford Logic Guides, Clarendon Press, 2005.
URL www.cs.swan.ac.uk/∼csetzer/
[20] M. Hedberg, A coherence theorem for Martin-L¨of’s type theory, Journal of
Functional Programming 8 (4) (1998) 413–436.
[21] M. Hofmann, Extensional Concepts in Intensional Type Theory, Ph.D. thesis,
University of Edinburg (1995).
[22] M. Hofmann, T. Streicher, A groupoid model refutes uniqueness of identity
proofs, in: Proceedings of the 9th Symposium on Logic in Computer Science
(LICS), Paris, 1994.
[23] P.
Hyvernat,
Predicate
Transformers
and
Linear
Logic:
yet
another
Denotational Model, in: J. Marcinkowski, J. Tarlecki (Eds.), 18th International
Workshop CSL 2004, Vol. 3210 of Lecture notes in Computer Science, Springer,
2004.
[24] P. Hyvernat, Synchronous Games, Simulations and λ-calculus, in: D. R. Ghica,
G. McCusker (Eds.), Games for Logic and Programming Languages, GaLoP
(ETAPS 2005), 2005, pp. 1–15.
[25] L.
Lamport,
Proving
the
correctness
of
multiprocess
programs,
IEEE
Transactions on Software Engineering 3 (2) (1977) 125–143.
[26] I. Lindstr¨om, A construction of non-wellfounded sets within Martin-L¨of’s type
theory, Journal of Symbolic Logic 54 (1) (1989) 57–64.
[27] Z. Luo, Coercive subtyping, Journal of Logic and Computation 9 (97 - 13)
(1999) 105–130.
[28] P. Martin-L¨of, Intuitionistic Type Theory, Bibliopolis, Napoli, 1984.
[29] P. Martin-L¨of, Mathematics of Inﬁnity, in: P. Martin-L¨of, G. Mints (Eds.),
COLOG-88, International Conference on Computer Logic, Tallinn, USSR,
December 1988, Proceedings, Vol. 417 of Lecture Notes in Computer Science,
Springer, 1990, pp. 147 – 197.
[30] P. Martin-L¨of, An Intuitionistic Theory of Types, in: G. Sambin, J. Smith
(Eds.), Twenty-Five Years of Constructive Type Theory, Oxford University
Press, 1998.
[31] C. McBride, Dependently Typed Functional Programs and their Proofs, Ph.D.
thesis, University of Edinburg (1999).
[32] M. Michelbrink, Interfaces as games, programs as strategies, in: J.-C. Filliatre,
C. Paulin, B. Werner (Eds.), Types for Proofs and Programs (TYPES 2004),
to appear.
35

[33] M. Michelbrink, A. Setzer, State-dependent IO-monads in type theory, in:
L. Birkedal (Ed.), Proceedings of the 10th Conference on Category Theory
in Computer Science (CTCS 2004), Vol. 122 of Electronic Notes in Theoretical
Computer Science, Elsevier, 2005, pp. 127–146.
[34] B. Nordstr¨om, K. Peterson, J. M. Smith, Programming in Martin-L¨of’s Type
Theory: An Introduction, Clarendon Press, Oxford, 1990.
[35] E. Palmgren, On universes in type theory, in: G. Sambin, J. Smith (Eds.),
Twenty-Five Years of Constructive Type Theory, Oxford University Press, 1998.
[36] K. Peterson, A Programming System for Type Theory, Tech. Rep. S-412 96,
Chalmers University of Technology, G¨oteborg (1982).
[37] A. Salvesen, On Information Discharging and Retrieval in Martin-L¨of’s Type
Theory, Ph.D. thesis, University of Oslo (1989).
[38] A. Salvesen, J. M. Smith, The Strenght of the Subset Type in Martin-L¨of’s
Type Theory, in: Proceedings of LICS’ 88, Edinburgh, 1988.
[39] G. Sambin, The Basic Picture, a structure for topology (the Basic Picture, I)
(2001).
[40] A. Setzer, Proof theory of Martin-L¨of type theory – an overview, Mathematiques
et Sciences Humaines 42 ann´ee, no165 (2004) 59 – 99.
[41] T.
Streicher,
Semantical
Investigation
into
intensional
Type
Theory,
Habilitationsschrift, LMU M¨unchen (1993).
36

