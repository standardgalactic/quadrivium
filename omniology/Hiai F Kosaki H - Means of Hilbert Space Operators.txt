Lecture Notes in Mathematics
1820
Editors:
J.--M. Morel, Cachan
F. Takens, Groningen
B. Teissier, Paris

3
Berlin
Heidelberg
New York
Hong Kong
London
Milan
Paris
Tokyo

Fumio Hiai
Hideki Kosaki
Means of
Hilbert Space Operators
1 3

Authors
Fumio Hiai
Graduate School of Information Sciences
Tohoku University
Aoba-ku, Sendai
980-8579 Japan
e-mail: hiai@math.is.tohoku.ac.jp
Hideki Kosaki
Graduate School of Mathematics
Kyushu University
Higashi-ku, Fukuoka
812-8581 Japan
e-mail: kosaki@math.kyushu-u.ac.jp
Cataloging-in-Publication Data applied for
Bibliographic information published by Die Deutsche Bibliothek
Die Deutsche Bibliothek lists this publication in the Deutsche Nationalbibliografie;
detailed bibliographic data is available in the Internet at http://dnb.ddb.de
Mathematics Subject Classification (2000): 47A30, 47A64, 15A60
ISSN 0075-8434
ISBN 3-540-40680-8 Springer-Verlag Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting,
reproduction on microfilm or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965,
in its current version, and permission for use must always be obtained from Springer-Verlag. Violations are
liable for prosecution under the German Copyright Law.
Springer-Verlag Berlin Heidelberg New York a member of BertelsmannSpringer
Science + Business Media GmbH
http://www.springer.de
c
⃝Springer-Verlag Berlin Heidelberg 2003
Printed in Germany
The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply,
even in the absence of a specific statement, that such names are exempt from the relevant protective laws
and regulations and therefore free for general use.
Typesetting: Camera-ready TEX output by the author
SPIN: 10949634
41/3142/ du - 543210 - Printed on acid-free paper

Preface
Roughly speaking two kinds of operator and/or matrix inequalities are known,
of course with many important exceptions. Operators admit several natural
notions of orders (such as positive semideﬁniteness order, some majorization
orders and so on) due to their non-commutativity, and some operator in-
equalities clarify these order relations. There is also another kind of operator
inequalities comparing or estimating various quantities (such as norms, traces,
determinants and so on) naturally attached to operators.
Both kinds are of fundamental importance in many branches of math-
ematical analysis, but are also sometimes highly non-trivial because of the
non-commutativity of the operators involved. This monograph is mainly de-
voted to means of Hilbert space operators and their general properties with
the main emphasis on their norm comparison results. Therefore, our operator
inequalities here are basically of the second kind. However, they are not free
from the ﬁrst in the sense that our general theory on means relies heavily on
a certain order for operators (i.e., a majorization technique which is relevant
for dealing with unitarily invariant norms).
In recent years many norm inequalities on operator means have been in-
vestigated. We develop here a general theory which enables us to treat them in
a uniﬁed and axiomatic fashion. More precisely, we associate operator means
to given scalar means by making use of the theory of Stieltjes double integral
transformations. Here, Peller’s characterization of Schur multipliers plays an
important role, and indeed guarantees that our operator means are bounded
operators. Basic properties on these operator means (such as the convergence
property and norm bounds) are studied. We also obtain a handy criterion (in
terms of the Fourier transformation) to check the validity of norm comparison
among operator means.
Sendai, June 2003
Fumio Hiai
Fukuoka, June 2003
Hideki Kosaki

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
2
Double integral transformations . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.1
Schur multipliers and Peller’s theorem . . . . . . . . . . . . . . . . . . . . .
8
2.2
Extension to B(H) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.3
Norm estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.4
Technical results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.5
Notes and references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
3
Means of operators and their comparison . . . . . . . . . . . . . . . . . . 33
3.1
Symmetric homogeneous means . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
3.2
Integral expression and comparison of norms . . . . . . . . . . . . . . . . 37
3.3
Schur multipliers for matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
3.4
Positive deﬁnite kernels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
3.5
Norm estimates for means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
3.6
Kernel and range of M(H, K) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.7
Notes and references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
4
Convergence of means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
4.1
Main convergence result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
4.2
Related convergence results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
5
A-L-G interpolation means Mα . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
5.1
Monotonicity and related results . . . . . . . . . . . . . . . . . . . . . . . . . . 65
5.2
Characterization of |||M∞(H, K)X||| < ∞. . . . . . . . . . . . . . . . . . 69
5.3
Norm continuity in parameter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
5.4
Notes and references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
6
Heinz-type means Aα . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
6.1
Norm continuity in parameter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
6.2
Convergence of operator Riemann sums . . . . . . . . . . . . . . . . . . . . 81

VIII
Contents
6.3
Notes and references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
7
Binomial means Bα . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
7.1
Majorization Bα ⪯M∞. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
7.2
Equivalence of |||Bα(H, K)X||| for α > 0 . . . . . . . . . . . . . . . . . . . 93
7.3
Norm continuity in parameter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
7.4
Notes and references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
8
Certain alternating sums of operators . . . . . . . . . . . . . . . . . . . . . 105
8.1
Preliminaries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
8.2
Uniform bounds for norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
8.3
Monotonicity of norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
8.4
Notes and references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
A
Appendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
A.1 Non-symmetric means. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
A.2 Norm inequality for operator integrals. . . . . . . . . . . . . . . . . . . . . . 127
A.3 Decomposition of max{s, t} . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
A.4 Ces`aro limit of the Fourier transform . . . . . . . . . . . . . . . . . . . . . . 136
A.5 Reﬂexivity and separability of operator ideals . . . . . . . . . . . . . . . 137
A.6 Fourier transform of 1/coshα(t) . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145

1
Introduction
The present monograph is devoted to a thorough study of means for Hilbert
space operators, especially comparison of (unitarily invariant) norms of oper-
ator means and their convergence properties in various aspects.
The Hadamard product (or Schur product) A ◦B of two matrices A =
[aij], B = [bij] means their entry-wise product [aijbij]. This notion is a com-
mon and powerful technique in investigation of general matrix (and/or opera-
tor) norm inequalities, and particularly so in that of perturbation inequalities
and commutator estimates. Assume that n × n matrices H, K, X ∈Mn(C)
are given with H, K ≥0 and diagonalizations
H = Udiag(s1, s2, . . . , sn)U ∗and K = V diag(t1, t2, . . . , tn)V ∗.
In our previous work [39], to a given scalar mean M(s, t) (for s, t ∈R+), we
associated the corresponding matrix mean M(H, K)X by
M(H, K)X = U ([M(si, tj)] ◦(U ∗XV )) V ∗.
(1.1)
For a scalar mean M(s, t) of the form n
i=1 fi(s)gi(t) one easily observes
M(H, K)X = n
i=1 fi(H)Xgi(K), and we note that this expression makes
a perfect sense even for Hilbert space operators H, K, X with H, K ≥0.
However, for the deﬁnition of general matrix means M(H, K)X (such as A-
L-G interpolation means Mα(H, K)X and binomial means Bα(H, K)X to
be explained later) the use of Hadamard products or something alike seems
unavoidable.
The ﬁrst main purpose of the present monograph is to develop a reason-
able theory of means for Hilbert space operators, which works equally well
for general scalar means (including Mα, Bα and so on). Here two diﬃcul-
ties have to be resolved: (i) Given (inﬁnite-dimensional) diagonal operators
H, K ≥0, the deﬁnition (1.1) remains legitimate for X ∈C2(H), the Hilbert-
Schmidt class operators on a Hilbert space H, as long as entries M(si, tj)
stay bounded (and M(H, K)X ∈C2(H)). However, what we want is a mean
M(H, K)X (∈B(H)) for each bounded operator X ∈B(H). (ii) General
F. Hiai and H. Kosaki: LNM 1820, pp. 1–6, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

2
1 Introduction
positive operators H, K are no longer diagonal so that continuous spectral
decomposition has to be used. The requirement in (i) says that the concept
of a Schur multiplier ([31, 32, 66]) has to enter our picture, and hence what
we need is a continuous analogue of the operation (1.1) with this concept
built in. The theory of (Stieltjes) double integral transformations ([14]) due
to M. Sh. Birman, M. Z. Solomyak and others is suited for this purpose. With
this apparatus the operator mean M(H, K)X is deﬁned (in Chapter 3) as
M(H, K)X =
 ∥H∥
0
 ∥K∥
0
M(s, t) dEsXdFt
(1.2)
with the spectral decompositions
H =
 ∥H∥
0
s dEs
and
K =
 ∥K∥
0
t dFt.
Double integral transformations as above were actually considered with
general functions M(s, t) (which are not necessarily means). This subject has
important applications to theories of perturbation, Volterra operators, Hankel
operators and so on (see §2.5 for more information including references), and
one of central problems here (besides the justiﬁcation of the double integral
(1.2)) is to determine for which unitarily invariant norm the transformation
X →M(H, K)X is bounded. Extensive study has been made in this direc-
tion, and V. V. Peller’s work ([69, 70]) deserves special mentioning. Namely,
he completely characterized (C1-)Schur multipliers in this setting (i.e., bound-
edness criterion relative to the trace norm ∥· ∥1, or equivalently, the operator
norm ∥·∥by the duality), which is a continuous counterpart of U. Haagerup’s
characterization ([31, 32]) in the matrix setting. Our theory of operator means
is built upon V. V. Peller’s characterization (Theorem 2.2) although just an
easy part is needed. Unfortunately, his work [69] with a proof (while [70] is
an announcement) was not widely circulated, and details of some parts were
omitted. Moreover, quite a few references there are not easily accessible. For
these reasons and to make the monograph as self-contained as possible, we
present details of his proof in Chapter 2 (see §2.1).
As emphasized above, the notions of Hadamard products and double inte-
gral transformations play important roles in perturbation theory and commu-
tator estimates. In this monograph we restrict ourselves mainly to symmetric
homogeneous means (except in Chapter 8 and §A.1) so that these important
topics will not be touched. However, most of the arguments in Chapters 2 and
3 are quite general and our technique can be applicable to these topics (which
will be actually carried out in our forthcoming article [55]). It is needless to
say that there are large numbers of literature on matrix and/or operator norm
inequalities (not necessarily of perturbation and/or commutator-type) based
on closely related techniques. We also remark that the technique here is useful
for dealing with certain operator equations such as Lyapunov-type equations
(see §3.7 and [39, §4]). These related topics as well as relationship to other

1 Introduction
3
standard methods for study of operator inequalities (such as majorization
theory and so on) are summarized at the end of each chapter together with
suitable references, which might be of some help to the reader.
In the rest we will explain historical background at ﬁrst and then more
details on the contents of the present monograph. In the classical work [36]
E. Heinz showed the (operator) norm inequality
∥HθXK1−θ + H1−θXKθ∥≤∥HX + XK∥
(for θ ∈[0, 1])
(1.3)
for positive operators H, K ≥0 and an arbitrary operator X on a Hilbert
space. In the 1979 article [64] A. McIntosh presented a simple proof of
∥H∗XK∥≤1
2∥HH∗X + XKK∗∥,
which is obviously equivalent to the following estimate for positive operators:
∥H1/2XK1/2∥≤1
2∥HX + XK∥
(H, K ≥0).
It is the special case θ = 1/2 of (1.3), and he pointed out that a simple and
uniﬁed approach to so-called Heinz-type inequalities such as (1.3) (and the
“diﬀerence version” (8.7)) is possible based on this arithmetic-geometric mean
inequality. The closely related eigenvalue estimate
µn(H1/2K1/2) ≤1
2µn(H + K)
(n = 1, 2, . . .)
for positive matrices is known ([12]). Here, {µn(·)}n=1,2,··· denotes singular
numbers, i.e., µn(Y ) is the n-th largest eigenvalue (with multiplicities counted)
of the positive part |Y | = (Y ∗Y )1/2. This means |H1/2K1/2| ≤1
2U(H +K)U ∗
for some unitary matrix U so that we have
|||H1/2K1/2||| ≤1
2|||H + K|||
for an arbitrary unitarily invariant norm ||| · |||.
In the 1993 article [10] R. Bhatia and C. Davis showed the following
strengthening:
|||H1/2XK1/2||| ≤1
2|||HX + XK|||
(1.4)
for matrices, which of course remains valid for Hilbert space operators H, K ≥
0 and X by the standard approximation argument. On the other hand, in [3]
T. Ando obtained the matrix Young inequality
µn

H
1
p K
1
q

≤µn

1
pH + 1
q K

(n = 1, 2, . . . )
(1.5)
for p, q > 1 with p−1 + q−1 = 1. Although the weak matrix Young inequality

4
1 Introduction
|||H
1
p XK
1
q ||| ≤κp||| 1
pHX + 1
q XK|||
(1.6)
holds with some constant κp ≥1 ([54]), without this constant the inequality
fails to hold for the operator norm ||| · ||| = ∥· ∥(unless p = 2) as was pointed
out in [2]. Instead, the following slightly weaker inequality holds always:
|||H
1
p XK
1
q ||| ≤1
p|||HX||| + 1
q|||XK|||.
(1.7)
In the recent years the above-mentioned arithmetic-geometric mean and
related inequalities have been under active investigation by several authors,
and very readable accounts on this subject can be found in [2, 8, 84]. Motivated
by these works, in a series of recent articles [54, 38, 39] we have investigated
simple uniﬁed proofs for known (as well as many new) norm inequalities in a
similar nature, and our investigation is summarized in the recent survey article
[40]. We also point out that closely related analysis was made in the recent
article [13] by R. Bhatia and K. Parthasarathy. For example as a reﬁnement
of (1.4) the arithmetic-logarithmic-geometric mean inequality
|||H1/2XK1/2||| ≤|||
 1
0
HxXK1−xdx||| ≤1
2|||HX + XK|||
(1.8)
was obtained in [38]. The technique in this article actually permitted us to
compare these quantities with
||| 1
m
m

k=1
H
k
m+1 XK
m+1−k
m+1 |||,
||| 1
n
n−1

k=0
H
k
n−1 XK
n−1−k
n−1 |||,
(1.9)
and moreover in the appendix to [38] we discussed the ||| · |||-convergence













1
m
m

k=1
H
k
m+1 XK
m+1−k
m+1
→
 1
0
HxXK1−xdx (as m →∞),
1
n
n−1

k=0
H
k
n−1 XK
n−1−k
n−1
→
 1
0
HxXK1−xdx (as n →∞)
(1.10)
under certain circumstances.
The starting point of the analysis made in [39] was an axiomatic treat-
ment on matrix means (i.e., matrix means M(H, K)X (see (1.1)) associated
to scalar means M(s, t) satisfying certain axioms), and a variety of generaliza-
tions of the norm inequalities explained so far were obtained as applications.
As in [39] a certain class of symmetric homogeneous (scalar) means is con-
sidered in the present monograph, but our main concern here is a study of
corresponding means for Hilbert space operators instead. In order to be able
to deﬁne M(H, K)X (∈B(H)) for each X ∈B(H) (by the double integral
transformation (1.2)), our mean M(s, t) has to be a Schur multiplier in ad-
dition. For two such means M(s, t), N(s, t) we introduce the partial order:

1 Introduction
5
M ⪯N if and only if M(ex, 1)/N(ex, 1) is positive deﬁnite. If this is the case,
then for non-singular positive operators H, K we have the integral expression
M(H, K)X =
 ∞
−∞
Hix(N(H, K)X)K−ixdν(x)
(1.11)
with a probability measure ν (see Theorems 3.4 and 3.7 for the precise state-
ment), and of course the Bochner theorem is behind. Under such circum-
stances (thanks to the general fact explained in §A.2) we actually have
|||M(H, K)X||| ≤|||N(H, K)X|||
(1.12)
(even without the non-singularity of H, K ≥0). This inequality actually char-
acterizes the order M ⪯N, and is a source for a variety of concrete norm
inequalities (as was demonstrated in [40]). The order ⪯and (1.11), (1.12)
were also used in [39] for matrices, but much more involved arguments are re-
quired for Hilbert space operators, which will be carried out in Chapter 3. It
is sometimes not an easy task to determine if a given mean M(s, t) is a Schur
multiplier. However, the mean M∞(s, t) = max{s, t} comes to the rescue: (i)
The mean M∞itself is a Schur multiplier. (ii) A mean majorized by M∞
(relative to ⪯) is a Schur multiplier. These are consequences of (1.11), (1.12),
and enable us to prove that all the means considered in [39] are indeed Schur
multipliers. The observation (i) also follows from the discrete decomposition
of max{s, t} worked out in §A.3, which might be of independent interest. Fur-
thermore, a general norm estimate of the transformation X →M(H, K)X
is established for means M ⪯M∞. In Chapter 4 we study the convergence
M(Hn, Kn)X →M(H, K)X (in ||| · ||| or in the strong operator topology)
under the strong convergence Hn →H, Kn →K of the positive operators
involved.
The requirement for the convergence (1.10) in the appendix to [39] was the
following ﬁniteness condition: either |||H|||, |||K||| < ∞or |||X||| < ∞. This
requirement is somewhat artiﬁcial (and too restrictive), and the arguments
presented there were ad hoc. The second main purpose of the monograph is
to present systematic and thorough investigation on such convergence phe-
nomena. In [39] we dealt with the following one-parameter families of scalar
means:
Mα(s, t) = α −1
α
×
sα −tα
sα−1 −tα−1
(−∞≤α ≤∞),
Aα(s, t) = 1
2(sαt1−α + s1−αtα)
(0 ≤α ≤1),
Bα(s, t) =
sα + tα
2
1/α
(−∞≤α ≤∞).
It is straight-forward to see that Mα(s, t), Aα(s, t) are Schur multipliers,
and also so is B1/n(s, t) thanks to the the binomial expansion B1/n(s, t) =

6
1 Introduction
2−n n
k=0
n
k

s
k
n t
n−k
n . We indeed show that all of Bα(s, t) are (by prov-
ing Bα ⪯M∞). Thus, all of the above give rise to operator means. Note
M1/2(s, t) =
√
st (the geometric mean), M2 = 1
2(s + t) (the arithmetic mean)
and
M1(s, t)

= lim
α→1 Mα(s, t)

=
s −t
log s −log t =
 1
0
sxt1−xdx
(the logarithmic mean).
Because of these reasons {Mα(s, t)}−∞≤α≤∞will be referred to as the A-L-G
interpolation means. The convergence (1.10) (see also (5.1)) means
lim
m→∞|||M
m
m+1 (H, K)X −L||| = lim
n→∞|||M
n
n−1 (H, K)X −L||| = 0
with the logarithmic mean L = M1(H, K)X =
 1
0 HxXK1−xdx, and the main
result in Chapter 5 is the following generalization:
lim
α→α0 |||Mα(H, K)X −Mα0(H, K)X||| = 0
under the assumption |||Mβ(H, K)X||| < ∞for some β > α0. This is a
“dominated convergence theorem” for the A-L-G means, the proof of which
is indeed based on Lebesgue’s theorem applied to the relevant integral ex-
pression (1.11) with the concrete form of the density dν(x)/dx. Similar
dominated convergence theorems for the Heinz-type means Aα(H, K)X =
1
2(HαXK1−α + H1−αXKα) (or rather the single components HαXK1−α)
and the binomial means Bα(H, K)X are also obtained together with other
related results in Chapters 6 and 7.
A slightly diﬀerent subject is covered in Chapter 8, that might be of inde-
pendent interest. The homogeneous alternating sums













A(n) =
n

k=1
(−1)k−1H
k
n+1 XK
n+1−k
n+1
(with n = 1, 2, · · ·),
B(m) =
m−1

k=0
(−1)kH
k
m−1 XK
m−1−k
m−1
(with m = 2, 3, · · ·)
are not necessarily symmetric (depending upon parities of n, m), but our
method works and integral expressions akin to (1.11) (sometimes with signed
measures ν) are available. This enables us to determine behavior of unitar-
ily invariant norms of these alternating sums of operators such as mutual
comparison, uniform bounds, monotonicity and so on.
Some technical results used in the monograph are collected in Appen-
dices, and §A.1 is concerned with extension of our arguments to certain non-
symmetric means.

2
Double integral transformations
Throughout the monograph a Hilbert space H is assumed to be separable.
The algebra B(H) of all bounded operators on H is a Banach space with the
operator norm ∥· ∥. For 1 ≤p < ∞let Cp(H) denote the Schatten p-class
consisting of (compact) operators X ∈B(H) satisfying Tr(|X|p) < ∞with
|X| = (X∗X)1/2, where Tr is the usual trace. The space Cp(H) is an ideal of
B(H) and a Banach space with the Schatten p-norm ∥X∥p = (Tr(|X|p))1/p.
In particular, C1(H) is the trace class, and C2(H) is the Hilbert-Schmidt class
which is a Hilbert space with the inner product (X, Y )C2(H) = Tr(XY ∗)
(X, Y ∈C2(H)). The algebra B(H) is faithfully (hence isometrically) rep-
resented on the Hilbert space C2(H) by the left (also right) multiplication:
X ∈C2(H) →AX, XA ∈C2(H) for A ∈B(H). Standard references on these
basic topics (as well as unitarily invariant norms) are [29, 37, 77].
In this chapter we choose and ﬁx positive operators H, K on H with the
spectral decompositions
H =
 ∥H∥
0
s dEs
and
K =
 ∥K∥
0
t dFt
respectively. We will use both of the notations dEs, EΛ (for Borel sets Λ ⊆
[0, ∥H∥]) interchangeably in what follows (and do the same for the other
spectral measure F). Let λ (resp. µ) be a ﬁnite positive measure on the interval
[0, ∥H∥] (resp. [0, ∥K∥]) equivalent (in the absolute continuity sense) to dEs
(resp. dFt). For instance the measures
λ(Λ) =
∞

n=1
1
n2 (EΛen, en)
(Λ ⊆[0, ∥H∥]),
µ(Ξ) =
∞

n=1
1
n2 (FΞen, en)
(Ξ ⊆[0, ∥K∥])
do the job, where {en}n=1,2,··· is an orthonormal basis for H. We choose and
ﬁx a function φ(s, t) in L∞([0, ∥H∥] × [0, ∥K∥]; λ × µ). For each operator
F. Hiai and H. Kosaki: LNM 1820, pp. 7–32, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

8
2 Double integral transformations
X ∈B(H), the algebra of all bounded operators on H, we would like to
justify its “double integral” transformation formally written as
Φ(X) =
 ∥H∥
0
 ∥K∥
0
φ(s, t) dEsXdFt
(see [14]). As long as X ∈C2(H), the Hilbert-Schmidt class operators, desired
justiﬁcation is quite straight-forward and moreover under such circumstances
we have Φ(X) ∈C2(H) with the norm bound
∥Φ(X)∥2 ≤∥φ∥L∞(λ×µ) × ∥X∥2.
(2.1)
In fact, with the left multiplication πℓand the right multiplication πr, πℓ(EΛ)
and πr(FΞ) (with Borel sets Λ ⊆[0, ∥H∥] and Ξ ⊆[0, ∥K∥]) are commut-
ing projections acting on the Hilbert space C2(H) so that πℓ(EΛ)πr(FΞ) is
a projection. It is plain to see that one gets a spectral family acting on the
Hilbert space C2(H) from those “rectangular” projections so that the ordinary
functional calculus via φ(s, t) gives us a bounded linear operator on C2(H).
With this interpretation we set
Φ(X) =
 ∥H∥
0
 ∥K∥
0
φ(s, t) d(πℓ(E)πr(F))

X.
(2.2)
Note that the Hilbert-Schmidt class operator X in the right side here is re-
garded as a vector in the Hilbert space C2(H), and (2.1) is obvious.
In applications of double integral transformations (for instance to stability
problems of perturbation) it is important to be able to specify classes of
functions φ for which the domain of Φ(·) can be enlarged to various operator
ideals (such as Cp-ideals). In fact, some useful suﬃcient conditions (in terms of
certain Lipschitz conditions on φ(·, ·)) were announced in [14] (whose proofs
were sketched in [15]), but unfortunately they are not so helpful for our later
purpose. More detailed information on double integral transformations will
be given in §2.5.
2.1 Schur multipliers and Peller’s theorem
We begin with the deﬁnition of Schur multipliers (acting on operators on H).
Deﬁnition 2.1. When Φ (= Φ | C1(H)) : X →Φ(X) gives rise to a bounded
transformation on the ideal C1(H) (⊆C2(H)) of trace class operators, φ(s, t)
is called a Schur multiplier (relative to the pair (H, K)).
When this requirement is met, by the usual duality B(H) = (C1(H))∗
the transpose of Φ gives rise to a bounded transformation on B(H) (i.e.,
the largest possible domain) as will be explained in the next §2.2. The next
important characterization due to V. V. Peller will play a fundamental role
in our investigation on means of operators:

2.1 Schur multipliers and Peller’s theorem
9
Theorem 2.2. (V.V. Peller, [69, 70]) For φ ∈L∞([0, ∥H∥] × [0, ∥K∥]; λ × µ)
the following conditions are all equivalent :
(i)
φ is a Schur multiplier ;
(ii)
whenever a measurable function k : [0, ∥H∥] × [0, ∥K∥] →C is the kernel
of a trace class operator L2([0, ∥H∥]; λ) →L2([0, ∥K∥]; µ), so is the product
φ(s, t)k(s, t);
(iii) one can ﬁnd a ﬁnite measure space (Ω, σ) and functions α ∈L∞([0, ∥H∥]
×Ω; λ × σ), β ∈L∞([0, ∥K∥] × Ω; µ × σ) such that
φ(s, t) =

Ω
α(s, x)β(t, x)dσ(x)
for all s ∈[0, ∥H∥], t ∈[0, ∥K∥];
(2.3)
(iv) one can ﬁnd a measure space (Ω, σ) and measurable functions α, β on
[0, ∥H∥] × Ω, [0, ∥K∥] × Ωrespectively such that the above (2.3) holds and


Ω
|α(·, x)|2dσ(x)

L∞(λ)


Ω
|β(·, x)|2dσ(x)

L∞(µ) < ∞.
A few remarks are in order. (a) The implication (iii) ⇒(iv) is trivial. (b)
The ﬁniteness condition in (iv) and the Cauchy-Schwarz inequality guarantee
the integrability of the integrand in the right-hand side of (2.3). (c) The
condition (iii) is stronger than what was stated in [69, 70], but the proof
in [69] (presented below) actually says (ii) ⇒(iii).
Unfortunately Peller’s article [69] (with a proof) was not widely circulated.
Because of this reason and partly to make the present monograph as much as
self-contained, the proof of the theorem is presented in what follows.
Proof of (iv) ⇒(i)
Although this is a relatively easy part in the proof, we present detailed ar-
guments here because its understanding will be indispensable for our later
arguments. So let us assume that φ(s, t) admits an integral representation
stated in (iv). For a rank-one operator X = ξ ⊗ηc we have πℓ(EΛ)πr(FΞ)X =
(EΛξ) ⊗(FΞη)c so that from (2.3) we get
Φ(X) =
 ∥H∥
0
 ∥K∥
0

Ω
α(s, x)β(t, x) (dEsξ) ⊗(dFtη)c dσ(x)
=

Ω
ξ(x) ⊗η(x)c dσ(x)
with
ξ(x) =
 ∥H∥
0
α(s, x) dEsξ
and
η(x) =
 ∥K∥
0
β(t, x) dFtη.
(2.4)
More precisely, the above integral can be understood for example in the weak
sense:

10
2 Double integral transformations
(Φ(X)ξ′, η′) =

Ω
((ξ(x) ⊗η(x)c)ξ′, η′) dσ(x)
=

Ω
(ξ′, η(x))(ξ(x), η′) dσ(x).
(2.5)
The above ξ(x), η(x) are vectors for a.e. x ∈Ωas will be seen shortly. We use
Theorem A.5 in §A.2 and the Cauchy-Schwarz inequality to get
∥Φ(ξ ⊗ηc)∥1 ≤

Ω
∥ξ(x) ⊗η(x)c∥1dσ(x) =

Ω
∥ξ(x)∥× ∥η(x)∥dσ(x)
≤

Ω
∥ξ(x)∥2dσ(x)
1/2 
Ω
∥η(x)∥2dσ(x)
1/2
.
(2.6)
Since ∥ξ(x)∥2 =
 ∥H∥
0
|α(s, x)|2d(Esξ, ξ) with the total mass of d(Esξ, ξ) be-
ing ∥ξ∥2, we have

Ω
∥ξ(x)∥2dσ(x) =
 ∥H∥
0

Ω
|α(s, x)|2dσ(x)

d(Esξ, ξ)
≤


Ω
|α(·, x)|2dσ(x)

L∞(λ) × ∥ξ∥2
(2.7)
by the Fubini-Tonneli theorem. A similar bound for

Ω∥η(x)∥2dσ(x) is also
available, and consequently from (2.6), (2.7) we get
∥Φ(ξ ⊗ηc)∥1 ≤∥ξ∥× ∥η∥×


Ω
|α(·, x)|2dσ(x)

1/2
L∞(λ)
×


Ω
|β(·, x)|2dσ(x)

1/2
L∞(µ).
Therefore, we have shown
∥Φ(X)∥1 ≤


Ω
|α(·, x)|2dσ(x)

1/2
L∞(λ)
×


Ω
|β(·, x)|2dσ(x)

1/2
L∞(µ) × ∥X∥1
(2.8)
for rank-one operators X. Note that (2.7) (together with the ﬁniteness re-
quirement in the theorem) shows ∥ξ(x)∥< ∞, i.e., ξ(x) is indeed a vector for
a.e. x ∈Ω. Also (2.8) guarantees that Φ(X) = 
Ωξ(x) ⊗η(x)cdσ(x) falls into
the ideal C1(H) of trace class operators.
We claim that the estimate (2.8) remains valid for ﬁnite-rank operators.
Indeed, thanks to the standard polar decomposition and diagonalization tech-
nique, such an operator X admits a representation X = n
i=1 ξi⊗ηc
i satisfying
∥X∥1 = n
i=1 ∥ξi∥× ∥ηi∥. Then, we estimate

2.1 Schur multipliers and Peller’s theorem
11
∥Φ(X)∥1 ≤
n

i=1
∥Φ(ξi ⊗ηc
i )∥1
≤
n

i=1
∥ξi∥× ∥ηi∥×


Ω
|α(·, x)|2dσ(x)

1/2
L∞(λ)
×


Ω
|β(·, x)|2dσ(x)

1/2
L∞(µ)
(by (2.8) for rank-one operators)
=


Ω
|α(·, x)|2dσ(x)

1/2
L∞(λ) ×


Ω
|β(·, x)|2dσ(x)

1/2
L∞(µ) × ∥X∥1.
We now assume X ∈C1(H). Choose a sequence {Xn}n=1,2,··· of ﬁnite-
rank operators converging to X in ∥· ∥1. Since convergence also takes place
in ∥· ∥2 (≤∥· ∥1), we see that Φ(Xn) tends to Φ(X) in ∥· ∥2 (by (2.1)) and
consequently in the operator norm ∥· ∥. The lower semi-continuity of ∥· ∥1
relative to the ∥· ∥-topology thus yields
∥Φ(X)∥1 ≤lim inf
n→∞∥Φ(Xn)∥1
≤lim inf
n→∞


Ω
|α(·, x)|2dσ(x)

1/2
L∞(λ)
×


Ω
|β(·, x)|2dσ(x)

1/2
L∞(µ) × ∥Xn∥1

(by (2.8) for ﬁnite-rank operators)
=


Ω
|α(·, x)|2dσ(x)

1/2
L∞(λ) ×


Ω
|β(·, x)|2dσ(x)

1/2
L∞(µ)

∥X∥1.
Therefore, Φ(X) belongs to C1(H), and moreover Φ(·) restricted to C1(H) gives
rise to a bounded transformation as desired.
Proof of (i) ⇒(ii)
One can choose a sequence {ξm} in H with 
m ∥ξm∥2 < ∞such that {EΛξm :
Λ ⊆[0, ∥H∥} (m = 1, 2, . . . ) are mutually orthogonal and λ is equivalent
to the measure 
m(EΛξm, ξm). In fact, choose a sequence {ξm} for which

m ∥ξm∥2 < ∞and 
m(EΛξm, ξm) is equivalent to λ. We set
Λm =

s ∈[0, ∥H∥] : d(Esξm, ξm)
dλ(s)
> 0

with the Radon-Nikodym derivative d(Esξm, ξm)/dλ(s) with respect to λ.
Choose mutually disjoint measurable subsets Λ0
m ⊆Λm (m = 1, 2, . . . ) with
	
m Λ0
m = 	
m Λm; then a required sequence is obtained by replacing ξm by
EΛ0mξm. Furthermore, we easily observe that the condition (ii) (as well as (i)) is
unchanged for equivalent measures (by considering the unitary multiplication
operator induced by the square root of the relevant Radon-Nikodym deriva-

12
2 Double integral transformations
tive). So one can assume λ(Λ) = 
m(EΛξm, ξm) with {ξm} as above and sim-
ilarly µ(Ξ) = 
n(FΞηnηn) where 
m ∥ηn∥2 < ∞and {FΞηn : Ξ ⊆[0, ∥K∥]}
(n = 1, 2, . . .) are mutually orthogonal.
Let H1 be the closed subspace of H spanned by {EΛξm : Λ ⊆[0, ∥H∥], m ≥
1} and H2 be spanned by {FΞηn : Ξ ⊆[0, ∥K∥], n ≥1}; then L2(λ) =
L2([0, ∥H∥]; λ) and L2(µ) = L2([0, ∥K∥]; µ) are isometrically isomorphic to
H1 and H2 respectively by the correspondences
χΛ ↔

m
EΛξm
and
χΞ ↔

n
FΞηn.
Assume that a measurable function k on [0, ∥H∥] × [0, ∥K∥] is the kernel
of a trace class operator R : L2(λ) →L2(µ), i.e.,
(Rf)(t) =
 ∥H∥
0
k(s, t)f(s) dλ(s)
for f ∈L2(λ).
The assumption implies in particular that k(s, t) and hence φ(s, t)k(s, t) are
square integrable with respect to λ × µ so that the latter is the kernel of
a Hilbert-Schmidt class operator. We prove under the assumption (i) that
φ(s, t)k(s, t) is indeed the kernel of a trace class operator. Deﬁne X ∈C1(H)
by composing R with the orthogonal projection PH1 as follows:
H
PH1
−→H1 ∼= L2(λ)
R
−→L2(µ) ∼= H2 →H .
Then (i) yields Φ(X) ∈C1(H). For each Λ ⊆[0, ∥H∥] and Ξ ⊆[0, ∥K∥] we
have

Φ(X)

m
EΛξm

,

n
FΞηn

=

m,n

Φ(X), (EΛξm) ⊗(FΞηn)c
C2(H)
=

m,n

X, Φ∗((EΛξm) ⊗(FΞηn)c)

C2(H)
=

m,n

X,
 ∥H∥
0
 ∥K∥
0
φ(s, t) d(πl(Es)πr(Ft))((EΛξm) ⊗(FΞηn)c)

C2(H)
=

m,n

X,

Λ

Ξ
φ(s, t) (dEsξm) ⊗(dFtηn)c
C2(H)
=

m,n

Λ

Ξ
φ(s, t) (XdEsξm, dFtηn)
=

Λ

Ξ
φ(s, t)k(s, t) dλ(s) dµ(t)
because of

2.1 Schur multipliers and Peller’s theorem
13

m,n
(XEΛξm, FΞηn) = (RχΛ, χΞ)L2(µ) =

Λ

Ξ
k(s, t) dλ(s) dµ(t).
We thus conclude that φ(s, t)k(s, t) is the kernel of the trace class operator
L2(λ) →L2(µ) corresponding to Φ(X)|H1 : H1 →H2.
Proof of (ii) ⇒(iii)
This is the most non-trivial part in Peller’s theorem, and requires the notion
of one-integrable operators (between Banach spaces) and the Grothendieck
theorem. Assume that φ satisﬁes (ii) and deﬁne an integral operator T0 :
L1(λ) →L∞(µ) by
(T0f)(t) =
 ∥H∥
0
φ(s, t)f(s) dλ(s)
for f ∈L1(λ).
What we need to show is that T0 falls into the operator ideal I1(L1(λ), L∞(µ))
consisting of one-integral operators in the space of bounded operators L1(λ) →
L∞(µ). Our standard reference for the theory on operator ideals on Banach
spaces is Pietsch’s textbook [72] (see especially [72, §19.2]).
It is known (see [72, 19.2.13]) that I1(L1(λ), L∞(µ)) is dual to the space
of compact operators L∞(µ) →L1(λ). Thanks to [72, 10.3.6 and E.3.1], to
show T0 ∈I1(L1(λ), L∞(µ)), it suﬃces to prove that there exists a constant
C such that
|trace(T0Q)| ≤C∥Q∥
(2.9)
for ﬁnite-rank operators Q : L∞(µ) →L1(λ) of the form Q = l
k=1⟨·, hk⟩gk
with gk ∈L1(λ) and hk ∈L1(µ). Here, ⟨·, · ⟩denotes the duality between
L∞(µ) and L1(µ) and
trace(T0Q) =
n

k=1
⟨T0gk, hk⟩
for T0Q = l
k=1⟨·, hk⟩T0gk.
To show (2.9), one may and do assume that gk, hk are ﬁnite linear combi-
nations of characteristic functions, say gk = m
i=1 αkiχΛi, hk = n
j=1 βkjχΞj
where A = {Λ1, . . . , Λm} and B = {Ξ1, . . . , Ξn} are measurable partitions
of [0, ∥H∥] and [0, ∥K∥] respectively. For p = 1, 2, ∞write Lp(A, λ) for the
(ﬁnite-dimensional) subspace of Lp(λ) consisting of A-measurable functions
(i.e., linear combinations of χΛi’s) and Lp(B, µ) similarly. The conditional
expectation EB : Lp(µ) →Lp(B, µ) is given by
EBf =
n

j=1
µ(Ξj)−1

Ξj
f dµ

χΞj.
Set ˜Q = Q|L∞(B,µ) : L∞(B, µ) →L1(A, λ) so that we have Q = ˜Q ◦EB.

14
2 Double integral transformations
According to [61, Theorem 4.3] (based on the Grothendieck theorem) to-
gether with [61, Proposition 3.1], we see that ˜Q admits a factorization
L∞(B, µ)
˜
M2
−→L2(B, µ)
˜
R
−→L1(A, λ),
(2.10)
where ˜
M2 is the multiplication by a function ˜η ∈L2(B, µ) and ˜R is an operator
such that
∥˜η∥L2(µ) = 1
and
∥˜R∥≤KG∥˜Q∥
(2.11)
with the Grothendieck constant KG. Apply [61, Theorem 4.3] once again to
the transpose ˜Rt : L∞(A, λ) →L2(B, µ) to get the following factorization of
˜Rt:
L∞(A, λ)
ˆ
M1
−→L2(A, λ)
ˆS
−→L2(B, µ),
where ˆ
M1 is the multiplication by a function ˜ξ ∈L2(A, λ) and ˆS is an operator
such that
∥˜ξ∥L2(λ) = 1
and
∥ˆS∥≤KG∥˜Rt∥= KG∥˜R∥.
(2.12)
Hence ˜R is factorized as
L2(B, µ)
˜S= ˆSt
−→L2(A, λ)
˜
M1= ˆ
Mt
1
−→
L1(A, λ),
(2.13)
where ˜
M1 is again the multiplication by ˜ξ. Combining (2.10) and (2.13) implies
that Q is factorized as
L∞(µ)
EB
−→L∞(B, µ)
˜
M2
−→L2(B, µ)
˜S
−→L2(A, λ)
˜
M1
−→L1(A, λ) →L1(λ).
Let S = ˜SEB : L2(µ) →L2(B, µ) →L2(A, λ) ⊆L2(λ) and M1 : L2(λ) →
L1(λ), M2 : L∞(µ) →L2(µ) be the multiplications by ˜ξ, ˜η respectively. Since
Q = ˜
M1 ˜S ˜
M2EB = ˜
M1 ˜SEBM2 = M1SM2,
we ﬁnally obtain a factorization of Q as follows:
L∞(µ)
M2
−→L2(µ)
S
−→L2(λ)
M1
−→L1(λ)
with
∥S∥= ∥˜S∥≤KG∥˜R∥≤K2
G∥˜Q∥= K2
G∥Q∥
(2.14)
thanks to (2.11) and (2.12).
Notice that M2T0M1 : L2(λ) →L2(µ) is the integral operator
(M2T0M1f)(t) =
 ∥H∥
0
φ(s, t)˜ξ(s)˜η(t)f(s) dλ(s).
Since ˜ξ(s)˜η(t) is obviously a kernel of a rank-one operator L2(λ) →L2(µ),
the assumption (ii) implies that M2T0M1 is a trace class operator. Now, it is
easy to see that

2.1 Schur multipliers and Peller’s theorem
15
trace(T0Q) = trace(T0M1SM2) = Tr(M2T0M1S)
(2.15)
with the (ordinary) trace Tr for the trace class operator M2T0M1S on L2(µ).
For every ξ ∈L2(λ) and η ∈L2(µ), the assumption (ii) guarantees that
one can deﬁne a trace class operator A(ξ, η) : L2(λ) →L2(µ) by
(A(ξ, η)f)(t) =
 ∥H∥
0
φ(s, t)ξ(s)η(t)f(s) dλ(s);
in particular, M2T0M1 = A(˜ξ, ˜η). Write C1(L2(λ), L2(µ)) for the Banach space
(with trace norm ∥·∥C1(L2(λ),L2(µ))) consisting of trace class operators L2(λ) →
L2(µ).
Lemma 2.3. There exists a constant ˜C such that
∥A(ξ, η)∥C1(L2(λ),L2(µ)) ≤˜C∥ξ∥L2(λ)∥η∥L2(µ)
(2.16)
for each ξ ∈L2(λ) and η ∈L2(µ).
Proof. For a ﬁxed ξ ∈L2(λ) let us consider the linear map
A(ξ, ·) : η ∈L2(µ) →A(ξ, η) ∈C1(L2(λ), L2(µ)),
whose graph is shown to be closed. We assume
ηn −→η in L2(µ)
and
A(ξ, ηn) −→B in C1(L2(λ), L2(µ)).
Choose and ﬁx f ∈L2(λ), and notice
∥A(ξ, ηn)f −Bf∥L2(µ) ≤∥A(ξ, ηn) −B∥B(L2(λ),L2(µ))∥f∥L2(λ)
≤∥A(ξ, ηn) −B∥C1(L2(λ),L2(µ))∥f∥L2(λ) −→0.
From these L2-convergences, after passing to a subsequence if necessary, we
may and do assume
ηn(t) −→η(t)
and
(A(ξ, ηn)f)(t) −→(Bf)(t)
for µ-a.e. t.
We then estimate
|(A(ξ, ηn)f)(t) −(A(ξ, η)f)(t)|
≤

 ∥H∥
0
φ(s, t)

ηn(t) −η(t)

ξ(s)f(s)dλ(s)

≤|ηn(t) −η(t)| × ∥φ∥∞×
 ∥H∥
0
|ξ(s)f(s)| dλ(s).
The last integral here being ﬁnite (due to ξ, f
∈L2(λ)), we conclude
(Bf)(t) = (A(ξ, η)f)(t) for µ-a.e. t. This means Bf = A(ξ, η)f ∈L2(µ)

16
2 Double integral transformations
and the arbitrariness of f ∈L2(λ) shows B = A(ξ, η) as desired. Therefore,
the closed graph theorem guarantees the boundedness of A(ξ, ·), i.e.,
∥A(ξ, ·)∥= sup

∥A(ξ, η)∥C1(L2(λ),L2(µ)) : η ∈L2(µ), ∥η∥L2(µ) ≤1

< ∞,
∥A(ξ, η)∥C1(L2(λ),L2(µ)) ≤∥A(ξ, ·)∥× ∥η∥L2(µ).
(2.17)
We next consider the linear map
A : ξ ∈L2(λ) →A(ξ, ·) ∈B(L2(µ), C1(L2(λ), L2(µ))).
To show the closedness of the graph again, we assume
ξn −→ξ in L2(λ)
and
A(ξn, ·) −→C in B(L2(µ), C1(L2(λ), L2(µ))).
We need to show A(ξ, ·) = C ∈B(L2(µ), C1(L2(λ), L2(µ))), i.e., A(ξ, η) =
C(η) ∈C1(L2(λ), L2(µ)) (η ∈L2(µ)). For each ﬁxed f ∈L2(λ) (and η ∈
L2(µ)), we have A(ξn, η)f →C(η)f in L2(µ). From this L2-convergence and
the fact η ∈L2(µ), after passing to a subsequence, we have
(A(ξn, η)f)(t) −→(C(η)f)(t)
and
|η(t)| < ∞
for µ-a.e. t.
We estimate
|(A(ξn, η)f)(t) −A(ξ, η)f)(t)|
≤

 ∥H∥
0
φ(s, t)η(t)(ξn(s) −ξ(s))f(s)dλ(s)

≤∥φ∥∞× |η(t)| ×
 ∥H∥
0
|(ξn(s) −ξ(s))f(s)| dλ(s)
≤∥φ∥∞× |η(t)| × ∥ξn −ξ∥L2(λ)∥f∥L2(λ).
Therefore, we have (A(ξ, η)f)(t) = (C(η)f)(t) for µ-a.e. t, showing A(ξ, η)f =
C(η)f ∈L2(µ) (f ∈L2(λ)) and A(ξ, η) = C(η) ∈C1(L2(λ), L2(µ)) (for each
η ∈L2(µ)). Thus, the closed graph theorem shows the boundedness
∥A(ξ, ·)∥≤˜C∥ξ∥L2(λ)
for some ˜C,
which together with (2.17) implies the inequality (2.16).
⊓⊔
We are now ready to prove (iii). By combining the above estimates (2.15),
(2.16), (2.11), (2.12) and (2.14) altogether, we get
|trace(T0Q)| ≤∥A(˜ξ, ˜η)S∥C1(L2(µ)) ≤˜C∥˜ξ∥L2(λ)∥˜η∥L2(µ)∥S∥≤˜CK2
G∥Q∥,
proving (2.9) with a constant C = ˜CK2
G (independent of Q). Thus, T0 ∈
I1(L1(λ), L∞(µ)) is established.
The following fact is known among other characterizations (see [72, 19.2.6]):
a bounded operator T : L1(λ) →L∞(µ) belongs to I1(L1(λ), L∞(µ)) if

2.1 Schur multipliers and Peller’s theorem
17
and only if there exist a probability space (Ω, σ) and bounded operators
T1 : L1(λ) →L∞(Ω; σ), T2 : L1(Ω; σ) →L∞(µ)∗∗such that
L1(λ)
T
−→L∞(µ) →L∞(µ)∗∗
T1 ↓
↑T2
L∞(Ω; σ)
→
L1(Ω; σ)
is commutative. Therefore, we can factorize T0 as follows:
L1(λ)
T1
−→L∞(Ω; σ) →L1(Ω; σ)
T2
−→L∞(µ),
where (Ω, σ) is a ﬁnite measure space and T1, T2 are bounded operators. In-
deed, L∞(µ) is complemented in L∞(µ)∗∗, and this T2 is the composition
of a projection map (actually a norm-one projection due to M. Hasumi’s re-
sult in [35], and also see [76, p. 148, Exercise 22 and p. 299, Exercise 10])
L∞(µ)∗∗→L∞(µ) and the preceding T2 : L1(Ω; σ) →L∞(µ)∗∗.
Thanks to Lemma 2.4 below applied to the preceding bounded operators
T1, T2, there exist α ∈L∞([0, ∥H∥]×Ω; λ×σ) and β ∈L∞([0, ∥K∥]×Ω; µ×σ)
such that
(T1f)(x) =
 ∥H∥
0
α(s, x)f(s) dλ(s)
for f ∈L1(λ),
(T2g)(t) =

Ω
β(t, x)g(x) dσ(x)
for g ∈L1(Ω, σ).
Therefore, we have
(T0f)(t) =

Ω
 ∥H∥
0
α(s, x)β(t, x)f(s) dλ(s) dσ(x)
=
 ∥H∥
0

Ω
α(s, x)β(t, x) dσ(x)

f(s) dλ(s)
for f ∈L1(λ),
which yields (iii) and the proof of Theorem 2.2 is completed.
The next result can be found in [47] as a corollary of a more general result
(see [47, §XI.1, Theorem 6]), and a short direct proof is presented below for
the reader’s convenience.
Lemma 2.4. Let (Ω1, σ1) and (Ω2, σ2) be ﬁnite measure spaces. For a given
bounded operator T : L1(Ω1; σ1) →L∞(Ω2; σ2) there exists a unique τ ∈
L∞(Ω1 × Ω2; σ1 × σ2) satisfying
(Tf)(y) =

Ω1
τ(x, y)f(x) dσ1(x)
for f ∈L1(Ω1; σ1).
Proof. Choose and ﬁx a measurable set Ξ ⊆Ω2. For each f ∈L1(σ1) we
observe the trivial estimate

18
2 Double integral transformations
|⟨Tf, χΞ⟩σ2| ≤σ2(Ξ) × ∥Tf∥L∞(σ2) ≤σ2(Ξ) × ∥T ∥× ∥f∥L1(σ1)
(with the standard bilinear form ⟨·, · ⟩σ2 giving rise to the duality between
L∞(σ2) and L1(σ2)), showing the existence of hΞ ∈L∞(Ω1; σ1) satisfying
∥hΞ∥L∞(σ1) ≤∥T ∥and
⟨Tf, χΞ⟩σ2 = σ2(Ξ) × ⟨hΞ, f⟩σ1
for f ∈L1(σ1).
Let Π denote the set of all ﬁnite measurable partitions of Ω2, which is a
directed set in the order of reﬁnement. For every π ∈Π we set
τπ(x, y) =

Ξ∈π
hΞ(x)χΞ(y),
(x, y) ∈Ω1 × Ω2,
so that a net {τπ}π∈Π in L∞(σ1 × σ2) satisﬁes ∥τπ∥L∞(σ1×σ2) ≤∥T ∥and
⟨Tf, χΞ⟩σ2 = ⟨τπ, f × χΞ⟩σ1×σ2
for f ∈L1(σ1)
for each π-measurable Ξ (i.e., π reﬁnes {Ξ, Ω2 \ Ξ}). Thanks to the w*-
compactness of

φ ∈L∞(σ1 × σ2); ∥φ∥L∞(σ1×σ2) ≤∥T ∥

one can take a
w*-limit point τ of {τπ}π∈Π. Then it is easy to see that
⟨Tf, χΞ⟩σ2 = ⟨τ, f × χΞ⟩σ1×σ2 =

Ξ

Ω1
τ(x, y)f(x) dσ1(x)

dσ2(y)
for each f ∈L1(Ω1; σ1) and each measurable set Ξ ⊆Ω2. This implies the
desired integral expression, and the uniqueness of τ is obvious.
⊓⊔
2.2 Extension to B(H)
We assume the condition (iv) in Theorem 2.2 (i.e., φ(s, t) admits the integral
expression (2.3) with the ﬁniteness condition described in (iv)) and will explain
how to extend Φ(·) to a bounded transformation on B(H) by making use of
the duality B(H) = C1(H)∗via
(X, Y ) ∈C1(H) × B(H) 	→Tr(XY ) ∈C.
To do so, we ﬁrst note that the roles of the variables s, t (and those of dEs
and dFt) are symmetric. Thus, the function
˜φ(t, s) = φ(s, t) =

Ω
β(t, x)α(s, x) dσ(x)
gives rise to the following transformation on C1(H):
˜Φ(X) =
 ∥K∥
0
 ∥H∥
0
˜φ(t, s) dFtXdEs.

2.2 Extension to B(H)
19
We consider its transpose ˜Φt on B(H) = C1(H)∗, that is,
Tr(X ˜Φt(Y )) = Tr( ˜Φ(X)Y )
for X ∈C1(H), Y ∈B(H).
(2.18)
Let us take X = ξ ⊗ηc here. Then, the left side of (2.18) is obviously the
inner product ( ˜Φt(Y )ξ, η). On the other hand, we have
˜Φ(X) =

Ω
˜ξ(x) ⊗˜η(x)c dσ(x)
with
˜ξ(x) =
 ∥K∥
0
β(t, x) dFtξ
and
˜η(x) =
 ∥H∥
0
α(s, x) dEsη
(2.19)
(see (2.4), but recall that the roles of α and β were switched). We claim that
the right side of (2.18) (when X = ξ ⊗ηc) is 
Ω(Y ˜ξ(x), ˜η(x))dσ(x). In fact,
for vectors ξ′, η′ we have
( ˜Φ(X)Y ξ′, η′) =

Ω
(Y ξ′, ˜η(x))(˜ξ(x), η′) dσ(x)
=

Ω
(˜ξ(x), η′)(ξ′, Y ∗˜η(x)) dσ(x)
thanks to (2.5). Let {en}n=1,2,··· be an orthonormal basis for H. Since
˜Φ(X)Y ∈C1(H), from the preceding expression we get
Tr( ˜Φ(X)Y ) =
∞

n=1
( ˜Φ(X)Y en, en) =
∞

n=1

Ω
(˜ξ(x), en)(en, Y ∗˜η(x)) dσ(x)
(see [29, Chapter III, §8]). Here, we would like to switch the order of ∞
n=1
and

Ω, which is guaranteed by the Fubini theorem thanks to the following
integrability estimate:

Ω
∞

n=1
|(˜ξ(x), en)(en, Y ∗˜η(x))| dσ(x)
≤

Ω
 ∞

n=1
|(˜ξ(x), en)|2
1/2  ∞

n=1
|(en, Y ∗˜η(x))|2
1/2
dσ(x)
=

Ω
∥˜ξ(x)∥× ∥Y ∗˜η(x)∥dσ(x) ≤∥Y ∥

Ω
∥˜ξ(x)∥× ∥˜η(x)∥dσ(x) < ∞
(see (2.6) and (2.7)). Hence, we get
Tr( ˜Φ(X)Y ) =

Ω
∞

n=1
(˜ξ(x), en)(en, Y ∗˜η(x)) dσ(x)
=

Ω
(˜ξ(x), Y ∗˜η(x)) dσ(x) =

Ω
(Y ˜ξ(x), ˜η(x)) dσ(x).

20
2 Double integral transformations
Therefore, the claim has been proved, and (for X = ξ ⊗ηc) (2.18) means
( ˜Φt(Y )ξ, η) =

Ω
(Y ˜ξ(x), ˜η(x)) dσ(x)
(2.20)
with the vectors ˜ξ(x) and ˜η(x) deﬁned by (2.19).
When Y = ξ′ ⊗η′c, the right side of (2.20) is

Ω
(˜ξ(x), η′)(ξ′, ˜η(x)) dσ(x)
=

Ω
 ∥K∥
0
β(t, x)dFtξ, η′
 
ξ′,
 ∥H∥
0
α(s, x)dEsη

dσ(x)
=

Ω

ξ,
 ∥K∥
0
β(t, x)dFtη′
  ∥H∥
0
α(s, x)dEsξ′, η

dσ(x)
=

Ω
(Y (x)ξ, η) dσ(x)
with the rank-one operator
Y (x) =
 ∥H∥
0
α(s, x) dEsξ′

⊗
 ∥K∥
0
β(t, x) dFtη′
c
.
But, notice that the two involved vectors here are exactly those deﬁned from
ξ′ and η′ according to the formula (2.4). Therefore, we have shown
˜Φt(Y ) =

Ω
Y (x) dσ(x) = Φ(Y )
(2.21)
for a rank-one (and hence ﬁnite-rank) operator Y .
For a general Hilbert-Schmidt class operator Y , we choose a sequence
{Yn}n=1,2,··· of ﬁnite-rank operators tending to Y in ∥· ∥2. Since the conver-
gence is also valid in the operator norm and ˜Φt (being deﬁned as a transpose) is
bounded relative to the operator norm, we have ˜Φt(Y ) = ∥·∥- limn→∞˜Φt(Yn).
On the other hand, we know
Φ(Y ) = ∥· ∥2- lim
n→∞Φ(Yn) = ∥· ∥2- lim
n→∞
˜Φt(Yn)
thanks to (2.1) and (2.21). Therefore, we conclude ˜Φt(Y ) = Φ(Y ) so that ˜Φt
is indeed an extension of Φ (originally deﬁned on C2(H)).
The discussions so far justify the use of the notation Φ(Y ) (for Y ∈B(H))
for expressing ˜Φt(Y ), and we shall also use the symbolic notation
Φ(Y ) (= ΦH,K(Y )) =
 ∥H∥
0
 ∥K∥
0
φ(s, t) dEsY dFt
(for Y ∈B(H))
in the rest of the monograph.

2.3 Norm estimates
21
Remark 2.5.
(i)
The map Φ : X ∈B(H) →Φ(X) ∈B(H) is always w*-w*-continuous
(i.e., σ(B(H), C1(H))-σ(B(H), C1(H))-continuous) because it was deﬁned
as the transpose of the bounded transformation ˜Φ on C1(H).
(ii) From (2.19) and (2.20) we observe
(Φ(Y )ξ, η) =

Ω
(Y β(K, x)ξ, α(H, x)∗η) dσ(x)
=

Ω
(α(H, x)Y β(K, x)ξ, η) dσ(x)
with the usual function calculus
α(H, x) =
 ∥H∥
0
α(H, x) dEs
and
β(K, x) =
 ∥K∥
0
β(t, x) dFt.
Therefore, Φ(X) (for X ∈B(H)) can be simply written as the integral
Φ(X) =

Ω
α(H, x)Xβ(K, x) dσ(x)
in the weak sense. Remark that the integral expression (2.3) for ϕ(s, t) is far
from being unique. Nevertheless, there is no ambiguity for the deﬁnition of
Φ(X). Indeed, the deﬁnition of ˜Φ(X) (= ˜Φ |C1(H) (X)) for X ∈C1(H) (⊆
C2(H)) does not depend on this expression (see (2.2)), and Φ(X) (for
X ∈B(H) = C(H)∗) was deﬁned as the transpose.
(iii) From the expression in (ii) we obviously have
f(H)(Φ(X))g(K) = Φ(f(H)Xg(K))
for all bounded Borel functions f, g.
2.3 Norm estimates
We begin by investigating a relationship between the two norms
∥Φ∥(∞,∞) = sup{∥Φ(X)∥: ∥X∥≤1},
∥Φ∥(1,1) = sup{∥Φ(X)∥1 : ∥X∥1 ≤1}.
To do so, besides Φ and ˜Φ we also make use of the following auxiliary double
integral operator:
¯Φ(X) =
 ∥H∥
0
 ∥K∥
0
φ(s, t) dEsXdFt.

22
2 Double integral transformations
Proposition 2.6. (M. Sh. Birman and M. Z. Solomyak, [16])
For a Schur
multiplier φ ∈L∞([0, ∥H∥] × [0, ∥K∥]; λ × µ) we have
∥Φ∥(1,1) = ∥Φ∥(∞,∞).
Proof. For X ∈C2(H) we easily observe ¯Φ(X∗)∗= ˜Φ(X) and hence ∥˜Φ∥(1,1) =
∥¯Φ∥(1,1) by restricting the both sides to C1(H) (⊆C2(H)). On the other hand,
∥Φ∥(∞,∞) = ∥˜Φ∥(1,1) is obvious from the deﬁnition, i.e., Φ was deﬁned as a
transpose. Therefore, to prove the proposition it suﬃces to see ∥Φ∥(1,1) =
∥¯Φ∥(1,1).
One expresses H and E in the direct integral form as follows:
H =
 ⊕
[0,∥H∥]
H(s) dλ(s),
EΛ =
 ⊕
[0,∥H∥]
χΛ(s)1H(s) dλ(s)
for Borel sets Λ ⊆[0, ∥H∥]. Note that it is the central decomposition of the
von Neumann algebra {EΛ : Λ ⊆[0, ∥H∥]}′ over its center
{EΛ : Λ ⊆[0, ∥H∥]}′′ ∼= L∞([0, ∥H∥]; λ).
(See [17, Chapter 7, §2] for more “operator-theoretical description”.) Similarly,
one can write
H =
 ⊕
[0,∥K∥]
˜H(t) dµ(t),
FΞ =
 ⊕
[0,∥K∥]
χΞ(t)1 ˜
H(t) dµ(t)
for Borel sets Ξ ⊆[0, ∥K∥]. A standard argument in the theory of direct
integral shows that C2(H) is represented as the direct integral
C2(H) =
 ⊕
[0,∥H∥]×[0,∥K∥]
C2(H(s), ˜
H(t)) d(λ × µ)(s, t)
with the Hilbert-Schmidt class operators C2(H(s), ˜H(t)) from H(s) into ˜H(t).
Take an X =
 ⊕
[0,∥H∥]×[0,∥K∥] X(s, t) d(λ × µ)(s, t) in C2(H). Since
EΛXFΞ =
 ⊕
[0,∥H∥]×[0,∥K∥]
χΛ×Ξ(s, t)X(s, t) d(λ × µ)(s, t)
for Borel sets Λ ⊆[0, ∥H∥] and Ξ ⊆[0, ∥K∥], it is immediate to see that Φ(X)
and ¯Φ(X) are written as
Φ(X) =
 ⊕
[0,∥H∥]×[0,∥K∥]
φ(s, t)X(s, t) d(λ × µ)(s, t),
¯Φ(X) =
 ⊕
[0,∥H∥]×[0,∥K∥]
φ(s, t)X(s, t) d(λ × µ)(s, t)

2.3 Norm estimates
23
respectively. The measurable cross-section theorem guarantees that one can
select measurable ﬁelds
{J(s) : s ∈[0, ∥H∥]}
and
{ ˜J(s) : s ∈[0, ∥K∥]}
of (conjugate linear) involutions J(s) : H(s) →H(s),
˜J(s) : ˜H(s) →˜H(s),
and they give rise to the global involutions
J =
 ⊕
[0,∥H∥]
J(s) dλ(s)
and
˜J =
 ⊕
[0,∥K∥]
˜J(t) dµ(t)
on the Hilbert space H. Then we observe
˜JΦ(X)J =
 ⊕
[0,∥H∥]×[0,∥K∥]
φ(s, t) ˜J(t)X(s, t)J(s) d(λ × µ)(s, t) = ¯Φ( ˜JXJ).
Since the map X →
˜JXJ is obviously isometric on C1(H), the equality
∥Φ∥(1,1) = ∥¯Φ∥(1,1) is now obvious and the proposition has been proved.
⊓⊔
For each unitarily invariant norm ||| · |||, let I|||·||| and I(0)
|||·||| be the associ-
ated symmetrically normed ideals, that is,
I|||·||| = {X ∈B(H) : |||X||| < ∞},
I(0)
|||·||| = the ||| · |||-closure of Iﬁn in I|||·|||,
where Iﬁn is the ideal of ﬁnite-rank operators (see [29, 37, 77] for details). For
a Schur multiplier φ(t, s) we have shown
∥Φ(X)∥1 ≤k∥X∥1 (X ∈C1(H)) and ∥Φ(X)∥≤k∥X∥(X ∈B(H))
(2.22)
with k = ∥Φ∥(1,1) = ∥Φ∥(∞,∞) (Proposition 2.6). The next result says that
φ(s, t) is automatically a “Schur multiplier for all operator ideals I|||·|||, I(0)
|||·|||”
with the same bound for
∥Φ∥(|||·|||,|||·|||) = sup{|||Φ(X)||| : |||X||| ≤1}.
Proposition 2.7. Let φ(s, t) be a Schur multiplier with
κ = ∥Φ∥(1,1) = ∥Φ∥(∞,∞) (< ∞).
For any unitarily invariant norm ||| · ||| we have
|||Φ(X)||| ≤κ|||X||| (≤∞)
for all X ∈B(H) so that Φ maps I|||·||| into itself. Moreover, Φ also maps
the separable operator ideal I(0)
|||·||| into itself. In particular, Φ(X) is a compact
operator as long as X is.

24
2 Double integral transformations
Proof. Recall the following expression for the Ky Fan norm as a K-functional:
|||X|||(n) =
n

k=1
µk(X)
= inf{n∥X0∥+ ∥X1∥1 : X = X0 + X1}
(n = 1, 2, · · ·),
where {µk(·)}k=1,2,··· denotes the singular numbers (see [26, p. 289] for ex-
ample). This expression together with (2.22) clearly shows |||Φ(X)|||(n) ≤
κ|||X|||(n) for each n, which is known to be equivalent to the validity of
|||Φ(X)||| ≤κ|||X||| for each unitarily invariant norm (see [37, Proposition
2.10]).
It remains to show Φ

I(0)
|||·|||

⊆I(0)
|||·|||. When X is a ﬁnite-rank operator,
Φ(X) is of trace class and can be approximated by a sequence {Yn}n=1,2,··· of
ﬁnite-rank operators in the ∥· ∥1-norm. Notice
|||Φ(X) −Yn||| ≤∥Φ(X) −Yn∥1 −→0,
showing Φ(X) ∈I(0)
|||·|||. For a general X ∈I(0)
|||·|||, one chooses a sequence
{Xn}n=1,2,··· of ﬁnite-rank operators satisfying limn→∞|||X −Xn||| = 0. Since
Φ(Xn) ∈I(0)
|||·||| is already shown, the estimate |||Φ(X) −Φ(Xn)||| ≤κ|||X −
Xn||| →0 (as n →∞) guarantees Φ(X) ∈I(0)
|||·|||.
⊓⊔
2.4 Technical results
Here we collect technical results. When we deal with integral expressions of
means of operators in later chapters, a careful handling for supports of relevant
operators will be required and some lemmas are prepared for this purpose. In
the sequel we will denote the support projection of H by sH.
Lemma 2.8. Let φ, ψ be Schur multipliers (relative to (H, K)) with the cor-
responding double integral transformations Φ, Ψ respectively. Then, the point-
wise product φ(s, t)ψ(s, t) is also a Schur multiplier, and the corresponding
double integral transformation is the composition Φ ◦Ψ (= Ψ ◦Φ).
Proof. As in Theorem 2.2, (iv) we can write
φ(s, t) =

Ω
α(s, x)β(t, x) dσ(x),
ψ(s, t) =

Ω′ α′(s, y)β′(t, y) dσ′(y).
We consider the product space Ω× Ω′ equipped with the product measure
σ × σ′, and set

2.4 Technical results
25
a : (s, x, y) ∈[0, ∥H∥] × Ω× Ω′ →α(s, x)α′(s, y),
b : (t, x, y) ∈[0, ∥K∥] × Ω× Ω′ →β(t, x)β′(t, y).
At ﬁrst we note

Ω×Ω′ |a(s, x, y)|2d(σ × σ′)(x, y) =

Ω
|α(s, x)|2dσ(x) ×

Ω′ |α′(s, y)|2dσ′(y)
≤


Ω
|α(·, x)|2dσ(x)

L∞(λ) ×


Ω′ |α′(·, y)|2dσ′(y)

L∞(λ)
(and the similar estimate for b). Secondly, the Cauchy-Schwarz inequality
implies

Ω×Ω′ |a(s, x, y)b(t, x, y)| d(σ × σ′)(x, y)
≤

Ω×Ω′ |a(s, x, y)|2d(σ × σ′)(x, y)
1/2
×

Ω×Ω′ |b(t, x, y)|2d(σ × σ′)(x, y)
1/2
.
From the two estimates we see the σ × σ′-integrability of a(s, x, y)b(t, x, y),
and the Fubini theorem clearly shows

Ω×Ω′ a(s, x, y)b(t, x, y) d(σ × σ′)(x, y)
=

Ω
α(s, x)β(t, x) dσ(x) ×

Ω′ α′(s, y)β′(t, y) dσ′(y) = φ(s, t)ψ(s, t).
Therefore, the conditions stated in Theorem 2.2, (iv) have been checked for
the product φ(s, t)ψ(s, t), and it is indeed a Schur multiplier.
Let Π be the double integral transformation corresponding to φ(s, t)ψ(s, t).
Then, it is straight-forward to see Π(X) = Φ(Ψ(X)) for each rank-one (hence
ﬁnite-rank) operator X. Let {pn}n=1,2,··· be a sequence of ﬁnite-rank projec-
tions tending to 1 in the strong operator topology. Then, for each X ∈B(H)
the sequence {pnXpn} tends to X strongly and hence in the σ(B(H), C1(H))-
topology (because of ∥pnXpn∥≤∥X∥). Since Π(pnXpn) = Φ(Ψ(pnXpn)) as
remarked above, by letting n →∞here, we conclude Π(X) = Φ(Ψ(X)) due
to the continuity stated in Remark 2.5, (i).
⊓⊔
The additive version (which is much easier) is also valid. Namely, when φ, ψ
are Schur multipliers, then so is the sum φ(s, t)+ψ(s, t) and the corresponding
double integral transformation sends X to Φ(X) + Ψ(X).
Lemma 2.9. Let φ(s, t) be a Schur multiplier (relative to (H, K)) with the
corresponding double integral transformation Φ. With the support projections
sH, sK of H, K we have sH(Φ(X))sK = Φ(sHXsK) and

26
2 Double integral transformations
Φ(X) = sHΦ(X)sK + φ(H, 0)sHX(1 −sK) + (1 −sH)XsKφ(0, K)
+φ(0, 0)(1 −sH)X(1 −sK).
Proof. The equation sH(Φ(X))sK = Φ(sHXsK) is seen from Remark 2.5, (iii).
Recall the following expression mentioned in Remark 2.5, (ii):
Φ(X) =

Ω
α(H, x)Xβ(K, x) dσ(x)
in the weak sense. Since
α(H, x) = α(H, x)sH + α(0, x)(1 −sH),
β(K, x) = β(K, x)sK + β(0, x)(1 −sK),
we have
α(H, x)Xβ(K, x)
= α(H, x)sHXsKβ(K, x)
+β(0, x)α(H, x)sHX(1 −sK) + α(0, x)(1 −sH)XsKβ(K, x)
+α(0, x)β(0, x)(1 −sH)X(1 −sK).
The integration of the ﬁrst term over Ωis Φ(sHXsK). The second term gives
us

Ω
β(0, x)α(H, x)sHX(1 −sK) dσ(x)
=

Ω
 ∥H∥
0
α(s, x)β(0, x) dEs dσ(x)

sHX(1 −sK)
=
 ∥H∥
0

Ω
α(s, x)β(0, x) dσ(x) dEs

sHX(1 −sK)
=
 ∥H∥
0
φ(s, 0) dEs

sHX(1 −sK) = φ(H, 0)sHX(1 −sK).
Of course the third term admits a similar integration. The last term gives us

Ω
α(0, x)β(0, x)(1 −sH)X(1 −sK) dσ(x)
=

Ω
α(0, x)β(0, x) dσ(x)

(1 −sH)X(1 −sK)
= φ(0, 0)(1 −sH)X(1 −sK).
The above estimates altogether yield the desired expression for Φ(X).
⊓⊔

2.4 Technical results
27
We can consider sH(ΦH,K(X))sK as an operator from sKH to sHH, and
denote it by ΦHsH ,KsK(sHXsK). It is possible to justify this (symbolic) no-
tation by making use of double integral transformation for operators between
two diﬀerent spaces. The above lemma actually shows
sH(ΦH,K(X))sK = ΦHsH ,KsK(sHXsK),
sH(ΦH,K(X))(1 −sK) = sHφ(H, 0)X(1 −sK),
(1 −sH)(ΦH,K(X))sK = (1 −sH)Xφ(0, K)sK,
(1 −sH)(ΦH,K(X))(1 −sK) = φ(0, 0)(1 −sH)X(1 −sK).
When dealing with means in later chapters we will mainly use Schur mul-
tipliers satisfying φ(s, 0) = φ(0, s) = bs (s ≥0) for some constant b ≥0. Then,
the expression in Lemma 2.9 becomes
ΦH,K(X) = sH(ΦH,K(X))sK + b (HX(1 −sK) + (1 −sH)XK)
(2.23)
thanks to
φ(H, 0)sH = bHsH = bH, φ(0, K)sK = bKsK = bK and φ(0, 0) = 0.
We ﬁx signed measures νk (k = 1, 2, 3) on the real line R with ﬁnite total
variation and also a scalar a. With the Fourier transforms of these measures
we set a bounded function π on [0, ∞) × [0, ∞) as
π(s, t) =







ˆν1(log s −log t) if s, t > 0,
ˆν2(log s)
if s > 0 and t = 0,
ˆν3(−log t)
if s = 0 and t > 0,
a
if s = t = 0.
Lemma 2.10. The above π(s, t) is a Schur multiplier for any pair (H, K) of
positive operators, and the corresponding double integral transformation Π is
given by
Π(X) =
 ∞
−∞
(HsH)ixX(KsK)−ixdν1(x)
+
 ∞
−∞
(HsH)ixX(1 −sK) dν2(x)
+
 ∞
−∞
(1 −sH)X(KsK)−ixdν3(x)
+a(1 −sH)X(1 −sK).
We give a few remarks before proving the lemma. In the above expression,
(HsH)ix for instance denotes a unitary operator on sHH and it is zero on
the orthogonal complement (1 −sH)H, i.e., (HsH)ix = (HsH)ixsH. We will
mainly use this lemma (as well as the next Proposition 2.11) in the following
special circumstances:

28
2 Double integral transformations
π(s, 0) = π(0, t) = c (s > 0, t > 0) for some constant c and π(0, 0) = 0.
This means ν2 = ν3 = cδ0 and a = 0, and hence in this case the expression in
the lemma simply becomes
Π(X) =
 ∞
−∞
(HsH)ixX(KsK)−ixdν1(x)
+c(sHX(1 −sK) + (1 −sH)XsK).
Proof. We decompose the domain {(s, t) : s, t ≥0} into the four regions
{(s, t) : s, t > 0},
{(s, t) : s > 0, t = 0},
{(s, t) : s = 0, t > 0},
{(s, t) : s = t = 0}.
We accordingly set
π1(s, t) =

π(s, t) if s, t > 0,
0
otherwise,
π2(s, t) =

π(s, 0) if s > 0 and t = 0,
0
otherwise,
π3(s, t) =
 π(0, t) if s = 0 and t > 0,
0
otherwise,
π4(s, t) =
π(0, 0) if s = t = 0,
0
otherwise.
So π(s, t) = 4
k=1 πk(s, t) is valid. We consider the following functions on
R+ × R:
α1(s, x) =
six dν1
d|ν1|(x) if s > 0,
0
if s = 0,
β1(t, x) =

t−ix if t > 0,
0
if t = 0,
α2(s, x) =
six dν2
d|ν2|(x) if s > 0,
0
if s = 0,
β2(t, x) =

0 if t > 0,
1 if t = 0,
α3(s, x) =
0 if s > 0,
1 if s = 0,
β3(t, x) =
 t−ix dν3
d|ν3|(x) if t > 0,
0
if t = 0,
α4(s) =
 0 if s > 0,
a if s = 0,
β4(t) =
 0 if t > 0,
1 if t = 0.
Here,
dνk
d|νk|(x) denotes the Radon-Nikodym derivative relative to the absolute
value |νk|. It is plain to observe
πk(s, t) =
 ∞
−∞
αk(s, x)βk(t, x) d|νk|(x)
(for k = 1, 2, 3)
and also π4(s, t) = α4(s)β4(t). The ﬁniteness condition in Theorem 2.2, (iv)
is obviously satisﬁed (since
dνk
d|νk|’s are bounded functions and |νk|’s are ﬁnite
measures) so that all πk’s are Schur multipliers. Thus, so is the sum π as was
mentioned in the paragraph right after Lemma 2.8.
We begin with π1 (with the corresponding double integral transforma-
tion Π1). Since π1(s, t) = 0 for either s = 0 or t = 0, we note Π1(X) =
sH(Π1(X))sK by Lemma 2.9. For a rank-one operator X = ξ ⊗ηc, (2.4)
shows

2.4 Technical results
29
Π1(X) =
 ∞
−∞

(sHH)ixξ

⊗

(sKK)ixη
c dν1
d|ν1|(x) d|ν1|(x)
=
 ∞
−∞
(sHH)ix(ξ ⊗ηc)(sKK)−ixdν1(x)
=
 ∞
−∞
(sHH)ixX(sKK)−ixdν1(x),
which remains of course valid for ﬁnite-rank operators. Actually this inte-
gral expression for Π1(X) is also valid for an arbitrary operator X ∈B(H).
In fact, as in the proof of Lemma 2.8 we approximate X by the sequence
{pnXpn}n=1,2,···. At ﬁrst Π1(pnXpn) tends to Π1(X) in the weak operator
topology as remarked there. Therefore, it suﬃces to show the weak conver-
gence
 ∞
−∞
(HsH)ixpnXpn(KsK)−ixdν1(x) −→
 ∞
−∞
(HsH)ixX(KsK)−ixdν1(x).
However, it simply follows from the Lebesgue dominated convergence theorem.
We next consider π2 (with the double integral transformation Π2). By
Lemma 2.9 (and Remark 2.5) we have
Π2(X) = sH(Π2(X))(1 −sK) = π2(H, 0)sHX(1 −sK).
Recall π2(s, 0) = ˆν2(log s) (s > 0) so that
π2(H, 0)sH =

(0,∥H∥]
ˆν2(log s) dEs
=

(0,∥H∥]
 ∞
−∞
sixdν2(x)

dEs =
 ∞
−∞
(HsH)ixdν2(x)
due to the Fubini theorem. Therefore, we have
Π2(X) =
 ∞
−∞
(HsH)ixX(1 −sK) dν2(x).
Symmetric arguments also show
Π3(X) = (1 −sH)XsKπ3(0, K) =
 ∞
−∞
(1 −sH)X(KsK)−ixdν3(x)
while
Π4(X) = (1 −sH)(Π4(X))(1 −sK) = a(1 −sH)X(1 −sK)
is just trivial. By summing up all the Πk’s computed so far, we get the desired
expression for Π(X).
⊓⊔

30
2 Double integral transformations
Proposition 2.11. Let π(s, t) be the Schur multiplier in the previous lemma.
If φ(s, t) is a Schur multiplier relative to a pair (H, K), then so is the point-
wise product ψ(s, t) = π(s, t)φ(s, t). Furthermore, for each X ∈B(H) the
corresponding double integral transformations Φ(X) and Ψ(X) are related by
Ψ(X) =
 ∞
−∞
(HsH)ix(Φ(X))(KsK)−ixdν1(x)
+
 ∞
−∞
(HsH)ix(Φ(X))(1 −sK) dν2(x)
+
 ∞
−∞
(1 −sH)(Φ(X))(KsK)−ixdν3(x)
+a(1 −sH)(Φ(X))(1 −sK).
Proof. The ﬁrst statement follows from Lemmas 2.8 and 2.10. To get the
expression for Ψ(X), in the formula appearing in Lemma 2.10 we should just
replace X by Φ(X).
⊓⊔
We end the chapter with the following remark on the standard 2×2-matrix
trick, that will be sometimes useful in later chapters:
Remark 2.12. We set ˜H =
H 0
0 K

, and assume that φ is a Schur multiplier
relative to ( ˜H, ˜H) (or equivalently, so is φ relative to (H, H), (H, K) and
(K, K)). Then, φ (on [0, ∥˜H∥] × [0, ∥˜H∥]) admits an integral expression as
(2.3) relative to ( ˜H, ˜H). For ˜X =
0 X
0 0

we compute
α( ˜H, x) ˜Xβ( ˜H, x) =

α(H, x)
0
0
α(K, x)
 
0 X
0 0
 
β(H, x)
0
0
β(K, x)

=
0 α(H, x)Xβ(K, x)
0
0

.
Therefore, the (1, 2)-component of Φ ˜
H, ˜
H
 ˜X

=

Ω
α( ˜H, x) ˜
Xβ( ˜H, x) dσ(x) is
exactly

Ω
α(H, x)Xβ(K, x) dσ(x) = ΦH,K(X).
The support projection of ˜H is of the form
s ˜
H =
sH 0
0 sK

,
and sH(ΦH,K(X))sK is the (1, 2)-component of s ˜
H

Φ ˜
H, ˜
H
 ˜X

s ˜
H.

2.5 Notes and references
31
2.5 Notes and references
Motivated from perturbations of a continuous spectrum, scattering theory
and triangular representations of Volterra operators (see [30]) as well as study
of Hankel operators (see [71] for recent progress of the subject matter), in
[14, 15, 16] M. Sh. Birman and M. Z. Solomyak systematically developed
theory of double integral transformations formally written as
Y =

φ(s, t) dFtXdEs
Besides the deﬁnition given at the beginning of this chapter (ﬁrst deﬁned on
C2(H)), another deﬁnition by repeated integration
Y (s) =

φ(s, t) dFt

X ,
Y =

Y (s) dEs
(2.24)
was also taken by Birman and Solomyak, where the latter integration is un-
derstood as the limit of Riemann-Stieltjes sums. Indeed, the articles [15, 16]
were largely devoted to the well-deﬁnedness of the repeated integration in cer-
tain symmetric operator ideals in cases when φ is a function in some classes
of Lipschitz type or of Sobolev type. For example, the following criterion was
obtained:
Theorem Let φ(s, t) be a bounded Borel function on [a, b] × [c, d] satisfying
Lip α with respect to variable s with a constant (of H¨older continuity of order
α) independent of t. Assume that Es and Ft are supported in [a, b] and [c, d]
respectively. If α > 1
2, then φ is a Schur multiplier and for any X ∈B(H) the
repeated integral (2.24) exists and coincides with Φ(X) (deﬁned in §2.1). If
α ≤1
2, then for any X ∈Cp(H) with 1
p > 1
2 −α the repeated integral (2.24)
exists as a compact operator.
But this type of results are not so useful in the present monograph because
we mostly treat means (introduced in Deﬁnition 3.1) which do not at all satisfy
the Lipschitz type condition.
As was shown in [69, 70] (also [15]), double integral transformations are
closely related to problems of operator perturbations. For a C1-function ϕ on
an interval I (⊆R) and self-adjoint operators A =

s dEs, B =

t dFt with
spectra contained in I we formally have
ϕ(A) −ϕ(B) =

I

I
ϕ[1](s, t) dEs(A −B)dFt
(2.25)
with the divided diﬀerence
ϕ[1](s, t) =





ϕ(s) −ϕ(t)
s −t
(if s ̸= t),
ϕ′(s)
(if s = t).

32
2 Double integral transformations
If ϕ[1](s, t) is known to be a Schur multiplier relative to say some p-Schatten
ideal Cp(H), then (2.25) for A −B sitting in the ideal is justiﬁed and hence
one gets the perturbation norm inequality
∥ϕ(A) −ϕ(B)∥p ≤const. ∥A −B∥p,
(2.26)
showing ϕ(A)−ϕ(B) ∈Cp(H), i.e., the stability of perturbation. The following
is a folk result (whose proof is an easy but amusing exercise): If ϕ(s) is of
the form ϕ(s) =
 ∞
−∞eistdν(t) with a signed measure ν satisfying
 ∞
−∞(1 +
|t|) d|ν|(t) < ∞, then ϕ[1](s, t) is a Schur multiplier relative to C1(H) (and
hence relative to any Cp(H)). On the other hand, in [27] Yu. B. Farforovskaya
obtained an example of ϕ ∈C1(I) for which (2.26) fails to hold for ∥· ∥1. The
next result due to E. B. Davies is very powerful:
Theorem ([24, Theorem 17]) Let ϕ be a function of the form
ϕ(s) = as + b +
 s
−∞
(s −t) dν(t)
with a, b ∈R and a signed measure ν of compact support. Then, the estimate
(2.26) is valid for any p ∈(1, ∞).
The following “unitary version” of (2.25) is also useful: If ϕ is a C1-function
on the unit circle T (with a Schur multiplier ϕ[1](s, t)), then we have
ϕ(U) −ϕ(V ) =

T

T
ϕ[1](ζ, η) dEζ(U −V ) dFη
for unitary operators U =

T ζ dEζ, V =

T η dFη. This technique was often
used in M. G. Krein’s works and is closely related to his famous spectral shift
function.
Peller’s characterization theorem (Theorem 2.2) was given in [69] ([70] is
an announcement) while general results such as Propositions 2.6 and 2.7 were
shown in [15, 16] by M. Sh. Birman and M. Z. Solomyak. Unfortunately these
articles [15, 16, 69] (especially [69]) were not widely circulated. Our arguments
here are basically taken from their articles, but we have tried to present more
details. In fact, for the reader’s convenience we have supplied some arguments
that were omitted in the original articles.

3
Means of operators and their comparison
From now on we will study means M(H, K)X of operators H, K, X with
H, K ≥0 (for certain scalar means M(s, t)). In fact, our operator means
M(H, K)X are deﬁned as double integral transformations studied in Chapter
2 so that corresponding scalar means M(s, t) are required to be Schur multi-
pliers. In this chapter general properties of such operator means are clariﬁed
while some special series of concrete means will be exempliﬁed in later chap-
ters. Here we are mostly concerned with integral expressions (Theorem 3.4),
comparison of norms (Theorem 3.7), norm estimate (Theorem 3.12) and the
determination of the kernel and the closure of the range of the “mean trans-
form” M(H, K) (Theorem 3.16).
3.1 Symmetric homogeneous means
We begin by introducing a class of means for positive scalars and a partial
order among them. This order will be quite essential in the sequel of the
monograph. We conﬁne ourselves to that class of means for convenience sake
while all the results in the next §3.2 remain valid (with obvious modiﬁcation)
for more general means (as will be brieﬂy discussed in §A.1).
Deﬁnition 3.1. A continuous positive real function M(s, t) for s, t > 0 is
called a symmetric homogeneous mean (or simply a mean) if M satisﬁes the
following properties:
(a) M(s, t) = M(t, s),
(b) M(rs, rt) = rM(s, t) for r > 0,
(c) M(s, t) is non-decreasing in s, t,
(d) min{s, t} ≤M(s, t) ≤max{s, t}.
We denote by M the set of all such symmetric homogeneous means.
Deﬁnition 3.2. We assume M, N ∈M. We write M ⪯N when the ratio
M(ex, 1)/N(ex, 1) is a positive deﬁnite function on R, or equivalently, the
F. Hiai and H. Kosaki: LNM 1820, pp. 33–55, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

34
3 Means of operators and their comparison
matrix
M(si, sj)
N(si, sj)

i,j=1,··· ,n
is positive semi-deﬁnite for any s1, . . . , sn > 0
with any size n. By the Bochner theorem it is also equivalent to the existence
of a symmetric probability measure ν on R satisfying M(ex, 1) = ˆν(x)N(ex, 1)
(x ∈R), that is,
M(s, t) = ˆν(log s −log t)N(s, t)
(s, t > 0).
(3.1)
Here, ˆν(x) means the Fourier transform ˆν(x) =
 ∞
−∞
eixydν(y) (x ∈R).
The reason why a symmetric probability ν comes out is that the real func-
tion M(ex, 1)/N(ex, 1) takes value 1 at the origin. (See [39, Theorem 1.1] for
details.) Also, note that the order M ⪯N is strictly stronger than the usual
(point-wise) order M(s, t) ≤N(s, t) (s, t > 0) (see [39, Example 3.5]). The
domain of M ∈M naturally extends to [0, ∞) × [0, ∞) in the following way:
M(s, 0) = lim
t↘0 M(s, t) (s > 0),
M(0, t) = lim
s↘0 M(s, t) (t > 0),
M(0, 0) = lim
s↘0 M(s, 0) = lim
t↘0 M(0, t),
and M(s, t) remains continuous on the extended domain. It is easy to check
M(s, 0) = M(0, s) = sM(1, 0)
(s > 0)
(3.2)
and hence
M(0, 0) = 0.
(3.3)
The most familiar means in M are probably
A(s, t) = s + t
2
(arithmetic mean),
L(s, t) =
s −t
log s −log t =
 1
0
sxt1−xdx
(logarithmic mean),
G(s, t) =
√
st
(geometric mean),
Mhar(s, t) =
2
s−1 + t−1
(harmonic mean).
The largest and smallest means in M
M∞(s, t) = max{s, t}
and
M−∞(s, t) = min{s, t}
will play an important role in our discussions below.
We have the following order relation among the above means:
M−∞⪯Mhar ⪯G ⪯L ⪯A ⪯M∞.
(3.4)
The proof is found in the more general [39, Theorem 2.1] (i.e., (5.2) right
before Theorem 5.1 in Chapter 5; see also [38, Proposition 1 or more generally

3.1 Symmetric homogeneous means
35
Theorem 5]). However, here for the reader’s convenience we prove this special
case by bare-handed computations. Firstly Example 3.6, (c) below shows A ⪯
M∞. For L ⪯A we just note
L(ex, 1)
A(ex, 1) = ex −1
x
×
2
ex + 1 = 2 sinh(x/2)
x cosh(x/2) =
 1
0
cosh(ax/2)
cosh(x/2) da.
Since cosh(ax/2)/ cosh(x/2) is positive deﬁnite for each a ∈[0, 1] (see §6.3,
1), so is the above integral. (The Fourier transform can be also explicitly
determined; see (6.8) or the computations in [38, p. 305].) For G ⪯L we
observe
G(ex, 1)
L(ex, 1) = ex/2 ×
x
ex −1 =
x
2 sinh(x/2).
The well-known formula
 ∞
−∞
x
2 sinh(x/2) eixydx =
1
4 cosh2(πy)
(3.5)
and its inverse transform guarantee the positive deﬁniteness of the ratio. Fi-
nally, both of
Mhar(ex, 1)
G(ex, 1)
=
2
e−x + 1 × e−x/2 =
1
cosh(x/2),
M−∞(ex, 1)
Mhar(ex, 1) = min{ex, 1} × e−x + 1
2
= e−|x| + 1
2
are obviously positive deﬁnite (see (5.8) and (7.3)), and we are done.
Now let H, K be positive operators in B(H) with the spectral decompo-
sitions H =
 ∥H∥
0
s dEs and K =
 ∥K∥
0
t dFt. For a mean M ∈M we would
like to deﬁne the corresponding double integral transformation relative to the
pair (H, K):
M(H, K)X = MH,K(X) =
 ∥H∥
0
 ∥K∥
0
M(s, t) dEsXdFt
for X ∈B(H), and we consider this transformation acting on operators on H
as a “mean of H and K”. The transformation M(H, K) always makes sense
if restricted on the Hilbert-Schmidt class C2(H) (in particular, on the ideal
Iﬁn); it is the function calculus on C2(H) via M(s, t) of the left multiplication
by H and the right multiplication by K. But, to deﬁne M(H, K) = MH,K on
the whole B(H), we have to verify that M is a Schur multiplier relative to
(H, K). For instance, if H, K have ﬁnite spectra so that they have the discrete
spectral decompositions
H =
m

i=1
siPi
and
K =
n

j=1
tjQj

36
3 Means of operators and their comparison
with projections Pi, Qj such that m
i=1 Pi = n
j=1 Qj = 1, then each M ∈M
is a Schur multiplier relative to (H, K) and
M(H, K)X =
m

i=1
n

j=1
M(si, tj)PiXQj
(this is the case even for any Borel function on [0, ∞) × [0, ∞)).
In what follows we simply say that M ∈M is a Schur multiplier if it is so
relative to any pair (H, K) of positive operators. As for the means A, L and
G, the corresponding double integral transformations have the concrete forms
A(H, K)X = 1
2(HX + XK),
L(H, K)X =
 1
0
HxXK1−xdx,
G(H, K)X = H
1
2 XK
1
2 ,
showing that they are indeed Schur multipliers. But it is not so obvious to
determine whether a given M ∈M is a Schur multiplier. The next proposition
provides a handy suﬃcient condition.
Proposition 3.3. Let M, N ∈M and H, K be positive operators.
(a) If M ⪯N and N is a Schur multiplier relative to (H, K), then so is M.
(b) If M ⪯M∞, then M is a Schur multiplier (relative to any (H, K)).
Proof. (a) By Deﬁnition 3.2 there exists a symmetric probability measure ν
satisfying (3.1). Noting M(1, 0) ≤N(1, 0) (following from M(s, t) ≤N(s, t)
when s, t > 0) we set c = M(1, 0)/N(1, 0) if N(1, 0) > 0, otherwise c = 0.
Then, thanks to (3.2) and (3.3) we have M(s, t) = π(s, t)N(s, t) for all s, t ≥0
with
π(s, t) =









ˆν(log s −log t)
if s, t > 0,
c
if s > 0 and t = 0,
c
if s = 0 and t > 0,
0
if s = t = 0.
(3.6)
Hence the assertion is a consequence of Proposition 2.11 (based on Lemma
2.8).
(b) By virtue of (a) it suﬃces to show that M∞is a Schur multiplier. Since
A is obviously a Schur multiplier (as was mentioned above), (a) implies by
(3.4) that M−∞is a Schur multiplier. Hence so is M∞because of the simple
formula
M∞(s, t) = 2A(s, t) −M−∞(s, t)
(3.7)
(see the remark after Lemma 2.8).
⊓⊔

3.2 Integral expression and comparison of norms
37
The fact that M±∞are Schur multipliers can be also seen from the discrete
decompositions explained in §A.3 (see (A.4) and Theorem A.6). All the con-
crete means treated in later chapters satisfy M ⪯M∞so that they are all
Schur multipliers. It is easy to write down examples of M ∈M not satisfying
M ⪯M∞; nevertheless we have so far no explicit example of M ∈M which
is not a Schur multiplier.
3.2 Integral expression and comparison of norms
We begin with the integral expression (Theorem 3.4) for operator means,
which is an adaptation of the integral expression in Proposition 2.11 (also
Lemma 2.9) in the present setting of means in M. (Similar integral expres-
sions for wider classes of means will be worked out in §8.1 and §A.1.) Then,
comparison of norms of means will be an easy consequence.
In [49, p. 138] the following formula appears as an exercise:

t∈R
|µ({t})|2 = lim
T →∞
1
2T
 T
−T
|ˆµ(t)|2dt
for a complex measure µ on R. A related fact will be needed in the proof of
the theorem, and the proofs for this fact as well as the above formula will be
presented in §A.4 for the reader’s convenience.
Theorem 3.4. Let M, N ∈M and H, K be positive operators. If M ⪯N with
the representing measure ν for M(ex, 1)/N(ex, 1) (see Deﬁnition 3.2) and if
N is a Schur multiplier relative to (H, K), then so is M and
M(H, K)X =
 ∞
−∞
(HsH)ix(N(H, K)X)(KsK)−ixdν(x)
+M(1, 0)(HX(1 −sK) + (1 −sH)XK)
(3.8)
for all X ∈B(H). In this case we also have
M(H, K)X =

{x̸=0}
(HsH)ix(N(H, K)X)(KsK)−ixdν(x)
+ν({0})N(H, K)X.
(3.9)
Proof. We use the same notations as in the proof of Proposition 3.3, (a). Use
of Lemma 2.9 (see (2.23)) to N with (3.2) and (3.3) yields
N(H, K)X = sH(N(H, K)X)sK
+N(1, 0)(HX(1 −sK) + (1 −sH)XK).
(3.10)
Since M(s, t) = π(s, t)N(s, t) for all s, t ≥0 with π deﬁned by (3.6), Proposi-
tion 2.11 implies

38
3 Means of operators and their comparison
M(H, K)X =
 ∞
−∞
(HsH)ix(N(H, K)X)(KsK)−ixdν(x)
+c

sH(N(H, K)X)(1 −sK) + (1 −sH)(N(H, K)X)sK

.
Since M(1, 0) = cN(1, 0), the expression (3.8) is obtained by substituting
(3.10) into the above integral expression.
To show (3.9), we begin with the claim M(1, 0) = ν({0})N(1, 0). When
N(1, 0) = 0, we must have M(1, 0) = 0 due to M(1, 0) ≤N(1, 0) and there is
nothing to prove. Thus we may and do assume N(1, 0) > 0. In this case we
note
lim
x→−∞ˆν(x) =
lim
x→−∞
M(ex, 1)
N(ex, 1) = M(0, 1)
N(0, 1)

= M(1, 0)
N(1, 0)

,
lim
x→∞ˆν(x) = lim
x→∞
M(ex, 1)
N(ex, 1) = lim
x→∞
M(1, e−x)
N(1, e−x) = M(1, 0)
N(1, 0) .
Therefore, we conclude
lim
x→±∞ˆν(x) = M(1, 0)
N(1, 0) ,
and the claim follows from Corollary A.8 in §A.4. The claim and (3.8) yield
M(H, K)X
=

{x̸=0}
(HsH)ix(N(H, K)X)(KsK)−ixdν(x)
+ν({0})

sH(N(H, K)X)sK + N(1, 0)(HX(1 −sK) + (1 −sH)XK)

=

{x̸=0}
(HsH)ix(N(H, K)X)(KsK)−ixdν(x) + ν({0})N(H, K)X.
Here, the second equality is due to (3.10).
⊓⊔
From the expression (3.9) in the preceding theorem and Theorem A.5 we
have
Corollary 3.5. Let M, N ∈M (M ⪯N) and H, K be as in the theorem.
Then for any unitarily invariant norm ||| · ||| we have
|||M(H, K)X||| ≤|||N(H, K)X|||
for all X ∈B(H). In particular,
∥M(H, K)∥(|||·|||,|||·|||) ≤∥N(H, K)∥(|||·|||,|||·|||).
Example 3.6. The following examples are applications of the integral expres-
sion in the above theorem to means in (3.4).

3.2 Integral expression and comparison of norms
39
(a) Since the ratio G(ex, 1)/A(ex, 1) =

cosh
 x
2
−1 is the Fourier transform
of

cosh(πx)
−1,
H
1
2 XK
1
2 =
 ∞
−∞
(HsH)ix(HX + XK)(KsK)−ix
dx
2 cosh(πx).
Actually, the observation of this expression is the starting point of our
works on means of operators in a series of recent articles ([54, 38, 39]). We
also point out that the use of this integral transformation was crucial in
[22, 23].
(b) Since M−∞(ex, 1)/G(ex, 1) = e−|x|/2 is the Fourier transform of
1
2π

x2 +
1
4
−1 (see (5.8) and (7.3)),
M−∞(H, K)X =
 ∞
−∞
(HsH)
1
2 +ixX(KsK)
1
2 −ix
dx
2π

x2 + 1
4
.
(c) Since A(ex, 1)/M∞(ex, 1) = 1
2(1 + e−|x|) is the Fourier transform of the
measure 1
2δ0 +
1
2π(x2 + 1)−1 dx,
HX + XK = M∞(H, K)X
+
 ∞
−∞
(HsH)ix(M∞(H, K)X)(KsK)−ix
dx
π(x2 + 1).
The opposite direction of this is also possible. Since M−∞(ex, 1)/A(ex, 1) =
2e−|x|/(1 + e−|x|) = e−|x|/2/ cosh
 x
2

is the Fourier transform of the con-
volution product
f(x) =

1
cosh(πx)

∗

1
2π

x2 + 1
4


,
one obtains thanks to (3.7)
M∞(H, K)X = HX + XK
−1
2
 ∞
−∞
(HsH)ix(HX + XK)(KsK)−ixf(x) dx.
(3.11)
The general comparison theorem for means in M was summarized in [39,
Theorem 1.1] in the setting of matrices, and its extension to the operator
setting was stated at the end of [39]. However, the statement there is quite
rough and its sketch for the proof contains some inaccurate arguments. So,
for completeness let us prove the next theorem in a precise form.
Theorem 3.7. For M, N ∈M the following conditions are all equivalent :
(i)
there exists a symmetric probability measure ν on R with the following
property :
if N is a Schur multiplier relative to (H, K) of non-singular
positive operators, then so is M and

40
3 Means of operators and their comparison
M(H, K)X =
 ∞
−∞
Hix(N(H, K)X)K−ixdν(x)
for all X ∈B(H);
(ii)
if N is a Schur multiplier relative to a pair (H, K) of positive operators,
then so is M and
|||M(H, K)X||| ≤|||N(H, K)X|||
for all unitarily invariant norms and all X ∈B(H);
(iii) ∥M(H, H)X∥≤∥N(H, H)X∥for all H ≥0 and all X ∈Iﬁn;
(iv) M ⪯N.
Proof. (iv) ⇒(i) is contained in Theorem 3.4, and (iv) ⇒(ii) follows from
Corollary 3.5. When H, K and X are of ﬁnite-rank, (ii) and (iii) reduce to
the same condition in the matrix case (of any size). So (ii) ⇒(iv) and (iii) ⇒
(iv) are seen from [39, Theorem 1.1]. (Necessary arguments under a slightly
weaker assumption will be actually presented in the proof of Theorem A.3 in
§A.1.) For (i) ⇒(iv) put H = s1 (s > 0) and K = X = 1; then the integral
expression in (i) reduces to M(s, 1) = ˆν(log s)N(s, 1), i.e., M ⪯N.
It remains to show (iv) ⇒(iii), which is not quite trivial because N in (iii)
is not a priori a Schur multiplier relative to (H, H). At ﬁrst, when H is also
of ﬁnite-rank, the inequality in (iii) follows from (iv) by [39, Theorem 1.1] (or
from (ii) since we have already had (iv) ⇒(ii)). For a general H choose a
sequence {Hn} of ﬁnite-rank positive operators such that ∥Hn∥≤∥H∥and
Hn →H in the strong operator topology. Then πℓ(Hn) →πℓ(H) strongly on
C2(H) because for a rank-one operator ξ ⊗ηc we get
∥πℓ(Hn)(ξ ⊗ηc) −πℓ(H)(ξ ⊗ηc)∥2
= ∥(Hnξ −Hξ) ⊗ηc∥2 = ∥Hnξ −Hξ∥× ∥η∥−→0.
Similarly πr(Hn) →πr(H) strongly on C2(H). Since M(s, t) is uniformly
approximated on [0, ∥H∥] × [0, ∥H∥] by polynomials in two variables s and t,
it follows that M(Hn, Hn) →M(H, H) strongly on C2(H). For every X ∈Iﬁn
(⊆C2(H)) we thus get
∥M(Hn, Hn)X −M(H, H)X∥≤∥M(Hn, Hn)X −M(H, H)X∥2 →0
and the same is true for N too. Hence the required inequality is obtained by
taking the limit from ∥M(Hn, Hn)X∥≤∥N(Hn, Hn)X∥.
⊓⊔
3.3 Schur multipliers for matrices
In estimating the norm of a double integral transformation, it is sometimes
useful to reduce the problem to the matrix case by approximation (though

3.3 Schur multipliers for matrices
41
computing the Schur multiplication norm is usually diﬃcult even in the ma-
trix case). Such an approximation technique is developed here, which will be
indispensable in §3.5.
We begin with basics on Schur multiplication on matrices. Let A =
[aij]i,j=1,2,··· be an inﬁnite complex matrix such that supi,j |aij| < ∞. Then
one can formally deﬁne a Schur multiplication operator SA on the space of
inﬁnite matrices as
SA(X) = A ◦X = [aijxij]
for X = [xij],
where ◦is the Schur product or the Hadamard product (i.e., the entry-wise
product). Consider the Hilbert space ℓ2 with the canonical basis {ei}i=1,2,···
and identify an operator X ∈B(ℓ2) as the matrix

(Xej, ei)

i,j=1,2,···. We then
say that A is a Schur multiplier if SA gives rise to a bounded transformation of
C1(ℓ2) into itself (or equivalently, of B(ℓ2) into itself). A Schur multiplication
operator SA as above is realized as a double integral transformation of discrete
type. In fact, assume that H, K ≥0 are diagonalizable with
H =
∞

i=1
siξi ⊗ξc
i
and
K =
∞

i=1
tiηi ⊗ηc
i
for some orthonormal bases {ξi} and {ηi}. For any Borel function φ on
[0, ∞) × [0, ∞) the corresponding double integral transformation ΦH,K can
be represented as
ΦH,K(UXV ∗) = USA(X)V ∗
for X = [xij] ∈B(ℓ2),
(3.12)
where A = [φ(si, tj)]i,j=1,2,··· and U, V are unitary operators given by Uei =
ξi, V ei = ηi. In this way, φ is a Schur multiplier relative to (H, K) if and only
if A = [φ(si, tj)] is a Schur multiplier, and in this case
∥ΦH,K∥(1,1) = ∥SA∥(1,1).
(3.13)
Moreover, the characterization (iv) of Theorem 2.2 reads as follows: there exist
a Hilbert space K (= L2(Ω, σ) there) and bounded sequences {ui} and {vj}
of vectors in K such that
aij (= φ(si, tj)) = (ui, vj)K
(i, j = 1, 2, . . . ).
This criterion (known as Haagerup’s criterion) was independently obtained
by U. Haagerup (see 4 in §3.7). In particular, when A = [aij]i,j=1,··· ,n is an
n × n matrix, the Schur multiplication operator SA is deﬁned on Mn(C), the
algebra of n × n matrices, and furthermore the following is known (see 4 in
§3.7):
∥SA∥(1,1)

= ∥SA∥(∞,∞)

= min{κ ≥0 : there are ξ1, . . . , ξn, η1, . . . , ηn ∈Cn such that
∥ξi∥≤κ1/2, ∥ηj∥≤κ1/2, aij = (ξi, ηj) for i, j = 1, . . . , n}. (3.14)

42
3 Means of operators and their comparison
If A is a positive semi-deﬁnite matrix, then
∥SA∥(∞,∞) = max
i
aii.
(3.15)
In fact, this is immediately seen from (3.14); if ξ1, . . . , ξn are the row vectors
of A1/2, then aij = (ξi, ξj) for all i, j. (A diﬀerent proof without using (3.14)
can be found in [4, 42].)
Lemma 3.8. An inﬁnite matrix A = [aij]i,j=1,2,··· is a Schur multiplier if and
only if
sup
n≥1
S[aij]i,j=1,··· ,n

(1,1) < ∞.
In this case, ∥SA∥(1,1) is equal to the above supremum.
Proof. If A is a Schur multiplier, then it is obvious that
∥S[aij]i,j=1,··· ,n∥(1,1) ≤∥SA∥(1,1)
(for n = 1, 2, . . . ).
Conversely, assume that
κ = sup
n≥1
∥S[aij]i,j=1,··· ,n∥(1,1) < ∞.
Let pn = n
i=1 ei⊗ec
i with the canonical basis {ei} for ℓ2. For every X ∈C1(ℓ2)
and n = 1, 2, . . . we get
∥SA(pnXpn)∥1 = ∥[aijxij]i,j=1,··· ,n∥1 ≤κ∥pnXpn∥1 ≤κ∥X∥1,
and
∥SA(pmXpm) −SA(pnXpn)∥1 ≤κ∥pmXpm −pnXpn∥1.
By approximating X by ﬁnite-rank operators in the norm ∥· ∥1, one observes
limm,n→∞∥pmXpm−pnXpn∥1 = 0 so that {SA(pnXpn)}n=1,2,··· is Cauchy in
C1(ℓ2) from the second inequality and ∥SA(pnXpn) −Y ∥1 →0 for some Y ∈
C1(ℓ2). Since the convergence also takes place in the weak operator topology,
this limit Y must be equal to SA(X) and consequently
∥SA(X)∥1 = lim
n→∞∥SA(pnXpn)∥1 ≤κ∥X∥1
from the above ﬁrst estimate.
⊓⊔
The next lemma will play a key role in §3.5. The assumption of φ here
may not be best possible, however it is enough for our purpose.
Lemma 3.9. Let φ(s, t) be a function on [0, α] × [0, α] where 0 < α < ∞,
and assume that φ is bounded and continuous at any point possibly except at
(0, 0). Then the following conditions are equivalent :
(i)
φ is a Schur multiplier relative to every pair (H, K) of positive operators
with ∥H∥, ∥K∥≤α;

3.3 Schur multipliers for matrices
43
(ii) sup
S[φ(si,sj)]i,j=1,··· ,n

(1,1) : 0 ≤s1, . . . , sn ≤α, n ≥1

< ∞, where
repetition is allowed for s1, . . . , sn.
Furthermore, if (ii) holds with ﬁnite supremum κ, then ∥ΦH,K∥(1,1) ≤κ for
any (H, K) with ∥H∥, ∥K∥≤α.
Proof. (i) ⇒(ii). By assuming (i) and the failure of (ii), we will obtain a
contradiction. Since (ii) fails to hold, for each n one can choose s(n)
1 , . . . , s(n)
n
from [0, α] in such a way that
sup
n≥1
S
φ(s(n)
i
,s(n)
j
)

i,j=1,··· ,n

(1,1) = ∞.
Let {si}i=1,2,··· be the sequence
s(1)
1 , s(2)
1 , s(2)
2 , s(3)
1 , s(3)
2 , s(3)
3 , · · · , s(n)
1 , . . . , s(n)
n , · · ·
obtained so far. We set A = [φ(si, sj)]i,j=1,2,··· and H = ∞
i=1 siξi ⊗ξc
i where
{ξi} is an orthonormal basis. Then (i) implies that φ is a Schur multiplier
relative to (H, H), so A must be a Schur multiplier as remarked just after
(3.12). But, since

φ(s(n)
i
, s(n)
j
)

i,j=1,··· ,n is a principal submatrix of A, it is
obvious that
S
φ(s(n)
i
,s(n)
j
)

i,j=1,··· ,n

(1,1) ≤∥SA∥(1,1)
for all n. The supremum of the above left-hand side is ∞, a contradiction.
(ii) ⇒(i). Assume that the supremum κ in (ii) is ﬁnite. Let H be a positive
operator with ∥H∥≤α and the spectral decomposition H =
 α
0 s dEs. For
each n = 1, 2, . . . we divide [0, α] into subintervals
Λ(n)
i
=
i −1
n
α, i
nα
	
(i = 1, . . . , n −1)
and
Λ(n)
n
=
n −1
n
α, α

,
and let t(n)
i
= i−1
n α (i = 1, . . . , n). Deﬁne
φn(s, t) =
n

i,j=1
φ(t(n)
i
, t(n)
j
)χΛ(n)
i
×Λ(n)
j (s, t)
for (s, t) ∈[0, α] × [0, α]
and
Hn =
n

i=1
t(n)
i
EΛ(n)
i
.
Then the double integral transformation Φn = ΦHn,Hn corresponding to φn is
given by
Φn(X) =
n

i,j=1
φ(t(n)
i
, t(n)
j
)EΛ(n)
i
XEΛ(n)
j .

44
3 Means of operators and their comparison
Since Hn is obviously diagonalizable, we write Hn = ∞
i=1 s(n)
i
ξ(n)
i
⊗ξ(n)c
i
with an orthonormal basis {ξ(n)
i
}i=1,2,··· and set An =

φ(s(n)
i
, s(n)
j
)

i,j=1,2,···.
Then, thanks to (3.13) we get
∥Φn∥(1,1) = ∥SAn∥(1,1).
By assumption (ii) we apply Lemma 3.8 to conclude ∥SAn∥(1,1) ≤κ so that
∥Φn∥(1,1) ≤κ for all n.
Now let ξ, η, ξ′, η′ ∈H be arbitrary. For Φ = ΦH,H we get
(Φ(ξ ⊗ηc)ξ′, η′) =

Φ(ξ ⊗ηc), η′ ⊗ξ′c
C2(H)
=
 α
0
 α
0
φ(s, t) d

Es(ξ ⊗ηc)Et, η′ ⊗ξ′c
C2(H)
=
 α
0
 α
0
φ(s, t) d(Esξ, η′) d(ξ′, Etη),
and similarly
(Φn(ξ ⊗ηc)ξ′, η′) =
 α
0
 α
0
φn(s, t) d(Esξ, η′) d(ξ′, Etη).
Here, the complex-valued measures d(Esξ, η′), d(ξ′, Etη) are denoted by λ, µ
respectively with their absolute values |λ|, |µ|. By assumption, |φ(s, t)| ≤m (so
|φn(s, t)| ≤m as well) on [0, α] × [0, α] for some m < ∞. For each 0 < δ < α,
since φn(0, 0) = φ(0, 0), we estimate
|(Φn(ξ ⊗ηc)ξ′, η′) −(Φ(ξ ⊗ηc)ξ′, η′)|
≤


([0,α]×[0,α])\([0,δ)×[0,δ))
(φn(s, t) −φ(s, t)) d(λ × µ)(s, t)

+


([0,δ)×[0,δ))\{(0,0)}
φn(s, t) d(λ × µ)(s, t)

+


([0,δ)×[0,δ))\{(0,0)}
φ(s, t) d(λ × µ)(s, t)

≤

([0,α]×[0,α])\([0,δ)×[0,δ))
|φn(s, t) −φ(s, t)| d(|λ| × |µ|)(s, t)
+2m(|λ| × |µ|)

([0, δ) × [0, δ)) \ {(0, 0)}

.
For any δ > 0 the ﬁrst term of the latter expression tends to 0 as n →∞
because φ is continuous (hence uniformly continuous) on

[0, α] × [0, α]

\

[0, δ) × [0, δ)

so that φn →φ uniformly there. But the second term can be
arbitrarily small when δ > 0 is small enough. Therefore, we arrive at
lim
n→∞(Φn(ξ ⊗ηc)ξ′, η′) = (Φ(ξ ⊗ηc)ξ′, η′).

3.4 Positive deﬁnite kernels
45
This implies that Φn(X) →Φ(X) in the weak operator topology for all X ∈
Iﬁn. Since ∥Φn∥(1,1) ≤κ for all n as stated above, the lower semi-continuity
of ∥· ∥1 in the weak operator topology (see [37, Proposition 2.11]) yields
∥Φ(X)∥1 ≤lim inf
n→∞∥Φn(X)∥1 ≤κ∥X∥1
for all X ∈Iﬁn. For each X ∈C1(H) we approximate X by pnXpn with ﬁnite-
rank projections pn ↗1. Then {Φ(pnXpn)} is ∥·∥1-Cauchy and Φ(pnXpn) →
Y ∈C1(H) in the norm ∥· ∥1 as in the proof of Lemma 3.8. However, we
claim Y = Φ(X). In fact, since Φ is a bounded operator on C2(H), we have
∥Φ(pnXpn) −Φ(X)∥2 →0 (as well as ∥Φ(pnXpn) −Y ∥2 →0 thanks to
∥· ∥2 ≤∥· ∥1). Since Y = Φ(X), from the above estimate for operators in
∈Iﬁn we have
∥Φ(X)∥1 = lim
n→∞∥Φ(pnXpn)∥1 ≤κ∥X∥1
for all X ∈C1(H).
Finally, the standard 2×2-matrix trick can be conveniently used to extend
this inequality to a pair (H, K) with ∥H∥, ∥K∥≤α. In fact, with ˜H and ˜X
as in Remark 2.12 we notice
Φ ˜
H, ˜
H( ˜X) =
0 ΦH,K(X)
0
0

,
which implies
∥ΦH,K(X)∥1 = ∥Φ ˜
H, ˜
H( ˜X)∥1 ≤κ∥˜X∥1 = κ∥X∥1
for X
∈C1(H). Thus, φ is a Schur multiplier relative to (H, K) and
∥ΦH,K∥(1,1) ≤κ.
⊓⊔
3.4 Positive deﬁnite kernels
We say that M ∈M is a positive deﬁnite kernel if [M(si, sj)]i,j=1,··· ,n is
positive semi-deﬁnite for any s1, . . . , sn > 0 with any n. If N ∈M is a
positive deﬁnite kernel, then so is M ∈M with M ⪯N. This is an immediate
consequence of the famous Schur theorem on the Schur product of two positive
semi-deﬁnite matrices. The next proposition says that the geometric mean G
is the largest in the order ⪯among means in M that are positive deﬁnite
kernels. When H is a matrix with eigenvalues s1, . . . , sn ≥0, M(H, H) is
essentially equal to the Schur multiplication by [M(si, sj)]i,j=1,··· ,n (up to
unitary conjugation, see (3.12)). So one may consider the property (i) below
as a generalization of the Schur theorem.
Proposition 3.10. The following conditions are equivalent for M ∈M:

46
3 Means of operators and their comparison
(i)
M is a Schur multiplier and M(H, H)X is positive if so are H, X ∈B(H);
(ii)
M is a positive deﬁnite kernel ;
(iii) M ⪯G.
If this is the case, then ∥M(H, K)∥(1,1) ≤

∥H∥× ∥K∥for all H, K ≥0.
Proof. (i) ⇒(ii). Choose an orthonormal basis {ξi}. For each n, by setting
X = n
i,j=1 ξi ⊗ξc
j and H = n
i=1 siξi ⊗ξc
i with s1, . . . , sn ≥0, we get
M(H, H)X =
n

i,j=1
M(si, sj)ξi ⊗ξc
j.
Hence (i) implies the positive deﬁniteness of [M(si, sj)]i,j=1,··· ,n.
(ii) ⇒(iii). This is immediate because of
M(si, sj)
G(si, sj)

= diag(s−1/2
1
, . . . , s−1/2
n
)

M(si, sj)

diag(s−1/2
1
, . . . , s−1/2
n
)
for any s1, . . . , sn > 0.
(iii) ⇒(i). Assume (iii) with the representing measure ν for the ratio
M(ex, 1)/G(ex, 1). Then Theorem 3.4 implies that M is a Schur multiplier
and
M(H, H)X =
 ∞
−∞
(HsH)ix(H1/2XH1/2)(HsH)−ixdν(x),
(because of M(1, 0) = 0), which is positive if so is X. Furthermore, by Corol-
lary 3.5 we get
|||M(H, K)X||| ≤|||H1/2XK1/2||| ≤

∥H∥× ∥K∥|||X|||
for any unitarily invariant norm. Therefore, ∥M(H, K)∥(1,1) ≤

∥H∥× ∥K∥.
⊓⊔
3.5 Norm estimates for means
When M is one of A, L and G, it is straight-forward to see ∥M(H, K)∥(1,1) ≤
M(∥H∥, ∥K∥). In fact, this was noticed for G in the proof of Proposition 3.10,
and for L we have
|||L(H, K)X||| ≤
 1
0
|||HxXK1−x||| dx
≤
 1
0
∥H∥x∥K∥1−x dx × |||X||| = L(∥H∥, ∥K∥) |||X|||
for any unitarily invariant norm. As long as M ⪯M∞we also get the estimate

3.5 Norm estimates for means
47
|||M(H, K)X||| ≤|||M∞(H, K)X||| ≤3
2|||HX + XK|||
≤3
2(∥H∥+ ∥K∥) |||X|||
(3.16)
which is a consequence of Corollary 3.5 and (3.11).
The problem to compute the best possible bound of ∥M(H, K)∥(1,1) (in
terms of ∥H∥and ∥K∥) is not easy in general. In this section the optimal
bound will computed for the mean M = M∞.
Lemma 3.11. For every s1, . . . , sn ≥0,
S[si∨sj]i,j=1,··· ,n

(1,1) ≤
2
√
3

max
i
si −min
i
si

+ min
i
si ≤
2
√
3 max
i
si,
where si ∨tj = max{si, tj}. Moreover, 2/
√
3 is the optimal bound in the above
estimate.
Proof. The explicit formula of ∥SA∥(∞,∞) for a real 2 × 2 matrix A was ob-
tained in [21] by using Haagerup’s criterion (3.14) and it indeed says
S
 1 1
1 0



(∞,∞) =
2
√
3.
(3.17)
(In fact, a direct computation of (3.17) with Haagerup’s criterion is also easy.)
Next, let s1, . . . , sn ≥0. For a permutation γ on {1, 2, . . ., n} with the corre-
sponding permutation matrix Γ we obviously have
S[sγ(i)∨sγ(j)](X) = Γ

S[si∨sj](Γ −1XΓ)

Γ −1.
Thus, we may and do assume s1 ≥s2 ≥· · · ≥sn ≥0, and the matrix [si ∨sj]
can be written as
[si ∨sj] = (s1 −s2)J(n)
1
+ (s2 −s3)J(n)
2
+ · · · + (sn−1 −sn)J(n)
n−1 + snJ(n)
n ,
where
J(n)
k
=


1 · · · 1 1 · · · 1
... ... ...
... ... ...
1 · · · 1 1 · · · 1
1 · · · 1 0 · · · 0
... ... ... ... ... ...
1 · · · 1 0 · · · 0


(the zero block is (n −k) × (n −k)).
According to (3.17) and Haagerup’s criterion, there are u1, u2, v1, v2 ∈C2
such that ∥ui∥2, ∥vj∥2 ≤2/
√
3 and

48
3 Means of operators and their comparison
(u1, v1) = (u1, v2) = (u2, v1) = 1,
(u2, v2) = 0.
For k = 1, . . . , n −1 we get J(n)
k
=

(ξi, ηj)

when ξ1 = · · · = ξk = u1,
ξk+1 = · · · = ξn = u2, η1 = · · · = ηk = v1 and ηk+1 = · · · = ηn = v2. This
implies
∥SJ(n)
k ∥(∞,∞) ≤
2
√
3
(for k = 1, . . . , n −1),
and obviously ∥SJ(n)
n ∥(∞,∞) = 1. Since
S[si∨sj] = (s1 −s2)SJ(n)
1
+ (s2 −s3)SJ(n)
2
+ · · · + (sn−1 −sn)SJ(n)
n−1 + snSJ(n)
n
with positive coeﬃcients, we get
∥S[si∨sj]∥(∞,∞) ≤
2
√
3(s1 −sn) + sn
as desired. Finally the optimality of 2/
√
3 is clear from (3.17).
⊓⊔
The next theorem is a consequence of Lemmas 3.11 and 3.9 (for φ = M∞)
together with Corollary 3.5 (or Theorem 3.7).
Theorem 3.12. If M ∈M satisﬁes M ⪯M∞, then
∥M(H, K)∥(1,1) ≤
2
√
3 max{∥H∥, ∥K∥}
for all H, K ≥0. Consequently, for any unitarily invariant norm ||| · ||| we
have
|||M(H, K)X||| ≤
2
√
3 max{∥H∥, ∥K∥} |||X|||
for all X ∈B(H).
For each mean M ∈M one can deﬁne the mean M (−) ∈M dual to M by
M (−)(s, t) = M(s−1, t−1)−1
for s, t > 0
(3.18)
(see [39, §1]). For M, N ∈M note that M ⪯N is equivalent to N (−) ⪯M (−).
For example, G(−) = G, A(−) = Mhar and M (−)
∞
= M−∞concerning means
in (3.4). It is easy to see that if H, K are invertible positive operators, then
M (−)(H−1, K−1)(M(H, K)X)
= M(H, K)(M (−)(H−1, K−1)X) = X
(3.19)
for all X ∈C2(H). Indeed, this is the application of function calculus to the
equality M (−)(s−1, t−1)M(s, t) = 1. Whenever both M and M (−) are Schur
multipliers, (3.19) remains valid for all X ∈B(H) so that M (−)(H−1, K−1)
is the inverse of M(H, K) on B(H). Hence Theorem 3.12 implies

3.6 Kernel and range of M(H, K)
49
Proposition 3.13. If M ∈M satisﬁes M−∞⪯M ⪯M∞and H, K are
invertible positive operators, then
|||M(H, K)X||| ≥
√
3
2 min{∥H−1∥−1, ∥K−1∥−1} |||X|||
for all unitarily invariant norms and all X ∈B(H).
Remark 3.14. The “mean transform” M(H, K) (when M ⪯M∞for example)
sends I|||·||| (and I(0)
|||·|||) into itself (see Propositions 2.7 and 3.3). However, if
H, K are positive compact operators in some Schatten class, then one can do
better. For example, let us assume H, K ∈Cp0(H) (1 ≤p0 ≤∞) and M = A,
the arithmetic mean. Then, thanks to the (generalized) H¨older inequality
∥XY ∥p2 ≤∥X∥p1∥Y ∥p0

with p−1
1
+ p−1
0
= p−1
2

,
(3.20)
M(H, K) sends the Schatten class Cp1(H) into the smaller one Cp2(H) with
the norm bound
∥A(H, K)X∥p2 ≤1
2(∥HX∥p2 + ∥XK∥p2)
≤1
2(∥H∥p0 + ∥K∥p0) ∥X∥p1 ≤max{∥H∥p0, ∥K∥p0} ∥X∥p1.
We point out that this is a general phenomenon. Namely, let us assume M ⪯
M∞and p−1
1
+ p−1
0
= p−1
2
(1 ≤p0, p1, p2 ≤∞). If positive operators H, K
belong to Cp0(H), then M(H, K) is a bounded linear operator from Cp1(H)
into Cp2(H) satisfying
∥M(H, K)X∥p2 ≤3 max{∥H∥p0, ∥K∥p0} ∥X∥p1.
In fact, the general estimate (3.16) gives
∥M(H, K)X∥p2 ≤3
2∥HX + XK∥p2 ≤3
2(∥HX∥p2 + ∥XK∥p2)
so that the assertion follows from (3.20) as before.
3.6 Kernel and range of M(H, K)
Assume M−∞⪯M ⪯M∞. When both of H, K ≥0 are invertible, the
mean transform M(H, K) : B(H) →B(H) is bijective due to (3.19) (for each
X ∈B(H)). In this section we determine the kernel and the closure of the
range for general positive H, K.
Lemma 3.15. Assume that M ∈M satisﬁes M−∞⪯M ⪯M∞, and let H
be a non-singular positive operator.

50
3 Means of operators and their comparison
(i)
If X ∈B(H) and M(H, H)X = 0, then X = 0.
(ii) The range of M(H, H) is dense in B(H) in the strong operator topology.
Proof. (i) For δ > 0 we note
0 = E(δ,∞)(M(H, H)X)E(δ,∞) = M(HE(δ,∞), HE(δ,∞))(E(δ,∞)XE(δ,∞))
with the spectral projection E(δ,∞) of H. Here, the second equality easily
follows from the integral expression pointed out in Remark 2.5, (ii). By re-
stricting everything to the subspace E(δ,∞)H (where HE(δ,∞) is an invertible
operator), from Proposition 3.13 (and (3.19)) we get E(δ,∞)XE(δ,∞) = 0. We
then see X = 0 because the non-singularity of H yields the strong convergence
E(δ,∞) ↗1 (as δ ↘0).
(ii) Choose and ﬁx X ∈B(H) and δ > 0 at ﬁrst. As above we regard
E(δ,∞)XE(δ,∞) and HE(δ,∞) (≥δ) as operators on E(δ,∞)H. Then, the oper-
ator equation
M(HE(δ,∞), HE(δ,∞))Y = E(δ,∞)XE(δ,∞)
for an unknown operator Y ∈B(E(δ,∞)H) possesses a solution, i.e.,
Y = M (−)((HE(δ,∞))−1, (HE(δ,∞))−1)(E(δ,∞)XE(δ,∞))
(see (3.19)).
However, since Y ∈B(E(δ,∞)H) (⊆B(H)), we observe
M(HE(δ,∞), HE(δ,∞))Y = M(H, H)Y
once again based on the expression in Remark 2.5, (ii). Consequently we have
M(H, H)Y = E(δ,∞)XE(δ,∞), meaning that E(δ,∞)XE(δ,∞) sits in the range
of M(H, H). We thus get the conclusion by letting δ ↘0.
⊓⊔
Theorem 3.16. Assume that M ∈M satisﬁes M−∞⪯M ⪯M∞, and let
H, K be positive operators.
I.
Case M(1, 0) = 0.
(i)
For X ∈B(H) we have M(H, K)X = 0 if and only if sHXsK = 0.
(ii)
The closure of the range of M(H, K) in the strong operator topology
is sHB(H)sK.
II.
Case M(1, 0) > 0.
(iii) For X ∈B(H) we have M(H, K)X = 0 if and only if
sHXsK = sHX(1 −sK) = (1 −sH)XsK = 0.
(iv) The closure of the range of M(H, K) in the strong operator topology
is
{X ∈B(H) : (1 −sH)X(1 −sK) = 0}.

3.6 Kernel and range of M(H, K)
51
Proof. We begin with the special case H = K. We recall
M(H, H)X
= sH(M(H, H)X)sH + M(1, 0)(HX(1 −sH) + (1 −sH)XH)
= M(HsH, HsH)(sHXsH) + M(1, 0)(HX(1 −sH) + (1 −sH)XH)
(see Lemma 2.9 and (3.10)). By restricting everything to the subspace sHH
(where HsH is non-singular) Lemma 3.15, (i) says M(HsH, HsH)(sHXsH) =
0 if and only if sHXsH = 0, showing (i). When M(1, 0) > 0, the additional
requirement HX(1 −sH) = (1 −sH)XH = 0 is needed. However, this is
obviously equivalent to sHX(1−sH) = (1−sH)XsH = 0, which corresponds to
(iii). On the other hand, from Lemma 3.15, (ii) (and the above decomposition)
we easily get (ii) and (iv). Note that to show (iv) we need the following obvious
fact for instance: HB(H)(1 −sH) is strongly dense in
{X ∈B(H) : sHXsH = (1 −sH)XsH = (1 −sH)X(1 −sH) = 0},
i.e., operators with only (non-zero) “(1, 2)-components”.
In the rest of the proof we will deal with the general case. With ˜H, ˜X in
Remark 2.12 we have
M(H, K)X = 0 ⇐⇒M( ˜H, ˜H) ˜X = 0,
which is also equivalent to s ˜
H ˜Xs ˜
H = 0 (with the additional requirement
s ˜
H ˜X(1 −s ˜
H) = (1 −s ˜
H) ˜Xs ˜
H = 0 when M(1, 0) > 0) from the ﬁrst part of
the proof. But, since s ˜
H =
sH 0
0 sK

, we easily get (i) and (iii) (in the general
setting). Indeed, we have
s ˜
H ˜Xs ˜
H = 0 ⇐⇒sHXsK = 0,
s ˜
H ˜X(1 −s ˜
H) = 0 ⇐⇒sHX(1 −sK) = 0,
(1 −s ˜
H) ˜X(1 −s ˜
H) = 0 ⇐⇒(1 −sH)X(1 −sK) = 0.
To investigate the range, we consider the projections
P1 =
1 0
0 0

,
P2 =
0 0
0 1

(in B(H ⊕H)).
The range M(H, K)(B(H)) is P1(M( ˜H, ˜H)(B(H ⊕H))P2 (see Remark 2.12)
with the natural identiﬁcation of the (1, 2)-corner of B(H ⊕H) with B(H).
We claim
P1(M( ˜H, ˜H)(B(H ⊕H))P2 = P1(M( ˜H, ˜H)(B(H ⊕H))P2.
At ﬁrst, ⊇is obvious. To see ⊆, we choose and ﬁx Y from the left-hand side. We
note Y = P1Y P2 and can choose Yλ = M( ˜H, ˜H)Zλ (for some Zλ ∈B(H⊕H))
such that P1YλP2 →Y strongly. But notice

52
3 Means of operators and their comparison
P1YλP2 = P1(M( ˜H, ˜H)Zλ)P2 = M( ˜H, ˜H)(P1ZλP2)
due to the fact that P1 and P2 commute with ˜H (recall the integral ex-
pression in Remark 2.12). Therefore, each P1YλP2 actually belongs to the
range M( ˜H, ˜H)(B(H ⊕H)) so that the limit Y sits in the strong closure
M( ˜H, ˜H)(B(H ⊕H)). Hence, we have
Y = P1Y P2 ∈P1M( ˜H, ˜H)(B(H ⊕H))P2,
and the claim is established.
From the discussions so far we have
M(H, K)(B(H)) = P1(M( ˜H, ˜H)(B(H ⊕H))P2
= P1(M( ˜H, ˜H)(B(H ⊕H))P2.
(3.21)
When M(1, 0) = 0, we have
M(H, K)(B(H)) = P1s ˜
HB(H ⊕H)s ˜
HP2
= s ˜
HP1B(H ⊕H)P2s ˜
H = s ˜
HB(H)s ˜
H.
Here, the ﬁrst equality follows from (3.21) and the ﬁrst part of the proof
(i.e, (ii) in the special case H = K) while the second is a consequence of
the commutativity of P1, P2 with ˜H. The last equality comes from the above-
mentioned natural identiﬁcation. We note that the B(H) (appearing in the far
right side) is the one sitting at the (1, 2)-corner so that s ˜
HB(H)s ˜
H actually
means sHB(H)sK (sitting at the same place). Therefore, we have shown (ii).
On the other hand, when M(1, 0) > 0, from (3.21) (and (iv) in the special
case) we similarly get
M(H, K)(B(H))
= P1

s ˜
HB(H ⊕H)s ˜
H
+(1 −s ˜
H)B(H ⊕H)s ˜
H + s ˜
HB(H ⊕H)(1 −s ˜
H)

P2
= s ˜
HP1B(H ⊕H)P2s ˜
H
+(1 −s ˜
H)P1B(H ⊕H)P2s ˜
H + s ˜
HP1B(H ⊕H)P2(1 −s ˜
H)
= s ˜
HB(H)s ˜
H + (1 −s ˜
H)B(H)s ˜
H + s ˜
HB(H)(1 −s ˜
H).
The B(H) appearing at the end is once again the one at the (1, 2)-corner, and
the same reasoning as in the last part of the preceding paragraph yields (iv)
in the general case.
⊓⊔

3.7 Notes and references
53
3.7 Notes and references
1. Means of operators
In [39] the class M (in Deﬁnition 3.1) of homogeneous symmetric means
was introduced, and for matrices H, K, X (with H, K ≥0) and M ∈M the
matrix mean M(H, K)X was deﬁned by (1.1). With this deﬁnition Theorem
3.7 was obtained for matrices (as [39, Theorem 1.1]), and many norm inequali-
ties were obtained. We cannot determine if every M ∈M is a Schur multiplier
(probably not), and this problem seems to deserve further investigation. Any-
way the criterion M ⪯M∞obtained in Proposition 3.3, (b) is good enough in
almost all circumstances. The implication (iv) ⇒(ii) in Theorem 3.7 (at least
in the matrix case, or equivalently (3.15)) has been known to many special-
ists ([42, p. 343] and [4, p. 363] for example) and indeed used as a standard
tool for showing norm inequalities. We actually have the bi-implication here.
Therefore, the theorem can be also used to check failure of certain norm in-
equalities, which will be carried out in our forthcoming article [55]. In §8.1
and §A.1 we will deal with “operator means” M(H, K)X for functions M in
wider classes. This will make it possible to study norm inequalities for certain
operators which are not operator means in the sense of the present chapter.
Our theory of operator means is useful in study of certain operator equa-
tions. Let us assume the invertibility of H, K ≥0 for simplicity and regard
M(H, K)X = Y
as an operator equation with an unknown operator X. Then, (3.18) and (3.19)
show that X = M (−)(H−1, K−1)Y gives rise to a solution. With this idea
concrete integral expressions for solutions to many operator equations were
obtained in [39, §4]. In [68] related analysis was also made by G. K. Pedersen
from the viewpoint of “operator diﬀerentials” (see also [33, 67]). Theorem 3.16
in §3.6 provides us useful information on uniqueness of solutions to the above
operator equation.
Another important notion of operator means, quite diﬀerent from those
treated in the present monograph, is the one axiomatically introduced by
F. Kubo and T. Ando in [57]. An operator mean in their sense is a bi-
nary operation B(H)+ × B(H)+ →B(H)+, and it bijectively corresponds
to an operator monotone function on R+. For example, the geometric mean
(formerly introduced by W. Pusz and L. Woronowicz in [73]) is given as
H#K = H
1
2 (H−1
2 KH−1
2 )
1
2 H
1
2 for positive invertible H, K ∈B(H) while
our geometric mean G(H, K)X = H
1
2 XK
1
2 is no longer positive even when
X = 1.
2. Arithmetic-geometric mean inequality and related topics
The arithmetic-geometric mean inequality (1.4) for unitarily invariant
norms was ﬁrst noticed by R. Bhatia and C. Davis in [10], and its alternative
proofs (and/or some discussions) were worked out by many authors including

54
3 Means of operators and their comparison
R. A. Horn ([41]), F. Kittaneh ([50, 51]), R. Mathias ([63]) and probably some
others. Proofs presented in [41, 63] are indeed based on the method explained
in 1. The article [13] by R. Bhatia and K. Parthasarathy is closely related to
our previous works [38, 39, 54], and this method was systematically used to
derive an abundance of known and new norm inequalities. The same method
was used by X. Zhan ([83, Theorem 6 and Corollary 7]) to show the following
generalizations of the arithmetic-geometric mean inequality (as well as the
Heinz inequality (1.3)):
(i) for x ∈(−2, 2] and θ ∈[1/4, 3/4],
2 + x
2
|||HθXK1−θ + H1−θXKθ||| ≤|||HX + XK + xH1/2XK1/2|||;
(ii) for x ∈(−2, 2],
(2 + x)|||H1/2XK1/2||| ≤|||HX + XK + xH1/2XK1/2|||.
Similar results (based on the similar method) were also obtained in [78].
The following inequality was obtained by D. Joci´c ([45, Theorem 3.1]) as
an application of the arithmetic-geometric mean inequality:
||| |HX + XK|p ||| ≤2p−1∥X∥p−1||| |H|p−1HX + XK|K|p−1|||
for p ≥3 and self-adjoint operators H, K. It generalizes the earlier result
|||(H −K)2n+1||| ≤22n|||H2n+1 −K2n+1|||
due to D. Joci´c and F. Kittaneh ([46], and also see [7]). In fact, when p = 2n+1
odd, by setting X = 1 and using −K instead one gets |H|2nH = H2n+1 and
(−K)|(−K)|2n = −K2n+1. This perturbation estimate in particular shows
H −K ∈C(2n+1)p as long as H2n+1 −K2n+1 ∈Cp and p ∈[1, ∞), which
improves L. S. Koplienko’s result in [52].
G. Corach, H. Porta and L. Recht studied the set of invertible self-adjoint
operators (and some other sets) as a space equipped with a certain natural
Finsler metric (see [60]). In [19] from the diﬀerential geometry viewpoint they
arrived at the inequality
∥X∥≤1
2∥HXH−1 + H−1XH∥
for an invertible self-adjoint operator H. This corresponds to the norm-
decreasing property of a certain tangential map, and their proof actually uses
Schur products. As noticed in [28, 51] for example (change X to HXH and
use the standard 2 × 2-matrix trick in Remark 2.12), their inequality is noth-
ing but the arithmetic-geometric mean inequality (in the operator norm). In
[20] they also gave a geometric interpretation of the Segal inequality
∥eH+K∥≤∥eH/2eKeH/2∥

≤∥eHeK∥


3.7 Notes and references
55
for self-adjoint operators H, K.
3. Arithmetic-logarithmic-geometric mean inequality
The arithmetic-logarithmic-geometric mean inequality (1.8) (as well as
some further extensions such as monotonicity of the norms (1.9) in m and n)
was proved in [38]. In [9] R. Bhatia pointed out a close connection between the
logarithmic-geometric mean inequality and the Golden-Thompson-type norm
inequality (extending the Segal inequality)
|||eH+K||| ≤|||eHeK|||
for self-adjoint operators H, K based on the diﬀerential geometry viewpoint
(akin to [19, 20]). (See [8, 37, 77] for the Golden-Thompson-type inequality.)
4. Schur multipliers in the matrix case
Haagerup’s criterion and (3.14) were presented in his unpublished notes
[31, 32], and a proof is available in the literature. Namely, the formula was
shown in the article [5] by T. Ando and K. Okubo as a consequence of its
variant for the numerical radius norm. The Ando-Okubo theorem was recently
extended to B(H) by T. Itoh and M. Nagisa in [44].
Materials in §3.3 are somewhat technical. But, we need them (especially
Lemma 3.9) to reduce the proof of Theorem 3.12 in §3.5 to the matrix case. In
fact, this technique enables us to make use of Lemma 3.11 (based on (3.14)).
(Sub)majorization theory for eigenvalues and singular values of matrices
provides a powerful tool in study of matrix (also operator) norm inequalities
for unitarily invariant norms (see [34, 62] and also [1, 2, 8] for surveys on recent
results). Among others, T. Ando, R. A. Horn and C. R. Johnson obtained in
[4] a fundamental majorization for singular values of Hadamard (or Schur)
products of matrices, which implies (3.15) as a corollary. Majorization method
was implicitly used in the proof of Proposition 2.6; however it does not have
much to do with the present monograph.

4
Convergence of means
In this chapter we will investigate continuity properties of means (in operator
variables). In fact, the convergence M(Hn, Kn)X →M(H, K)X in a unitarily
invariant norm is discussed under the strong convergence Hn →H, Kn →K.
Our main result here is Theorem 4.1 in §4.1, and some related convergence
results are also presented in §4.2 as variants of (the proof of) the main theorem.
4.1 Main convergence result
Norm convergence is guaranteed under many circumstances. Although the
conditions imposed in the theorem below may not be optimal, many practical
situations are being covered.
Theorem 4.1. Let M ∈M be such that M ⪯M∞, and ||| · ||| be a unitarily
invariant norm. Let H, K, Hn and Kn (n = 1, 2, . . . ) be positive operators
such that Hn →H and Kn →K in the strong operator topology. Assume in
addition one of the following assumptions:
(a) ||| · ||| is dominated by ∥· ∥2,
(b) sHn →sH and sKn →sK strongly,
(c) M ⪯L, where L denotes the logarithmic mean.
Then we have
lim
n→∞|||M(Hn, Kn)X −M(H, K)X||| = 0
for all X ∈I(0)
|||·|||.
Proof. Thanks to the assumption M ⪯M∞and the boundedness of ∥Hn∥
and ∥Kn∥, Theorem 3.12 implies that there is a κ < ∞such that
|||M(Hn, Kn)X||| ≤κ|||X|||
F. Hiai and H. Kosaki: LNM 1820, pp. 57–63, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

58
4 Convergence of means
for all n = 1, 2, . . . and all X ∈B(H). Since Iﬁn is dense in I(0)
|||·|||, it suﬃces
to show the required norm convergence for rank-one operators X.
Case (a). This case is immediately seen because M(Hn, Kn) →M(H, K)
strongly as operators acting on the Hilbert-Schmidt class C2(H) (see the proof
(iv) ⇒(iii) of Theorem 3.7).
Case (b). Any unitarily invariant norm is dominated by ∥· ∥1, and hence
we may prove the case ||| · ||| = ∥· ∥1. Put ˜Hn = Hn + (1 −sHn) and ˜H =
H +(1−sH), so ˜Hn and ˜H are non-singular positive operators. Since ˜Hn →˜H
strongly, it is well-known that ˜Hix
n →˜Hix strongly for all x ∈R. Hence
(HnsHn)ix = ˜Hix
n sHn −→˜HixsH = (HsH)ix
strongly for all x ∈R. Similarly, (KnsKn)ix →(KsK)ix strongly. For a rank-
one operator X, we claim that
lim
n→∞∥M∞(Hn, Kn)X −M∞(H, K)X∥1 = 0.
(4.1)
In fact, (3.11) shows
M∞(Hn, Kn)X = −1
2
 ∞
−∞
(HnsHn)ix(HnX + XKn)(KnsKn)−ixf(x) dx
+HnX + XKn,
M∞(H, K)X = −1
2
 ∞
−∞
(HsH)ix(HX + XK)(KsK)−ixf(x) dx
+HX + XK.
It is straight-forward to see ∥(HnX + XKn) −(HX + XK)∥1 →0 since X is
of rank-one. So it suﬃces to show
lim
n→∞∥(HnsHn)ix(HnX + XKn)(KnsKn)−ix
−(HsH)ix(HX + XK)(KsK)−ix∥1 = 0
(4.2)
for all x ∈R. Indeed, we can then apply Theorem A.5 and the Lebesgue
dominated convergence theorem to get (4.1). However, the ∥·∥1-norm in (4.2)
is majorized by
∥(HnsHn)ix((HnX + XKn) −(HX + XK))(KnsKn)−ix∥1
+∥((HnsHn)ix −(HsH)ix)(XH + XK)(KnsKn)−ix∥1
+∥(HsH)ix(HX + XK)((KnsKn)−ix −(KsK)−ix)∥1
≤∥(HnX + XKn) −(HX + XK)∥1
+∥((HnsHn)ix −(HsH)ix)(XH + XK)∥1
+∥(HX + XK)((KnsKn)−ix −(KsK)−ix)∥1
so that (4.2) is obtained from the strong convergence

4.1 Main convergence result
59
(HnsHn)ix −→(HsH)ix,
(KnsKn)−ix −→(KsK)−ix.
When M ⪯M∞Theorem 3.4 (see (3.8)) guarantees
M(Hn, Kn)X =
 ∞
−∞
(HnsHn)ix(M∞(Hn, Kn)X)(KnsKn)−ixdν(x)
+M(1, 0)(sHnX(1 −sKn) + (1 −sHn)XsKn),
M(H, K)X =
 ∞
−∞
(HsH)ix(M∞(H, K)X)(KsK)−ixdν(x)
+M(1, 0)(sHX(1 −sK) + (1 −sH)XsK).
The strong convergence sHn →sH, sKn →sK is assumed while the preceding
claim says (4.1). Therefore, by making use of these we can repeat the argu-
ments in the proof of the claim for the above M(Hn, Kn)X and M(H, K)X
to conclude
∥M(Hn, Kn)X −M(H, K)X∥1 = 0.
Case (c). As usual we may and do assume Hn = Kn and H = K thanks
to the 2 × 2-matrix trick, and we set α = supn ∥Hn∥(< ∞). Choose and
ﬁx δ > 0. Let us assume E{δ}(H) = 0 (where EΛ(H) denotes the spectral
measure for H) so that we have the strong convergence
Pn = E[0,δ)(Hn) −→P = E[0,δ)(H)
(see [74, Theorem VIII.24]). We consider the decomposition
Hn = HnPn + HnP ⊥
n ,
H = HP + HP ⊥.
Based on the integral expression in Remark 2.5, (ii) we easily have
M(Hn, Hn)X = M(HnPn, HnPn)(PnXPn) + M(HnPn, HnP ⊥
n )(PnXP ⊥
n )
+M(HnP ⊥
n , HnPn)(P ⊥
n XPn) + M(HnP ⊥
n , HnP ⊥
n )(P ⊥
n XP ⊥
n )
(and the similar decomposition of M(H, H)X).
We recall the general fact
|||L(H, K)X||| ≤L(∥H∥, ∥K∥) |||X|||
(see the paragraph before Lemma 3.11). Corollary 3.5 together with this im-
plies
|||M(HnPn, HnP ⊥
n )(PnXP ⊥
n )||| ≤|||L(HnPn, HnP ⊥
n )(PnXP ⊥
n )|||
≤L(∥HnPn∥, ∥HnP ⊥
n ∥) |||PnXP ⊥
n |||
≤L(δ, α) |||X|||
(4.3)
thanks to ∥HnPn∥≤δ, ∥HnP ⊥
n ∥≤α. Of course the same estimate is available
for

60
4 Convergence of means
|||M(HnP ⊥
n , HnPn)(P ⊥
n XPn)|||,
|||M(HP, HP ⊥)(PXP ⊥)|||
and
|||M(HP ⊥, HP)(P ⊥XP)|||.
Similarly we have

|||M(HnPn, HnPn)(PnXPn)||| ≤δ|||X|||,
|||M(HP, HP)(PXP)||| ≤δ|||X|||.
(4.4)
The estimates so far imply
|||M(Hn, Hn)X −M(H, H)X|||
≤|||M(HnP ⊥
n , HnP ⊥
n )(P ⊥
n XP ⊥
n ) −M(HP ⊥, HP ⊥)(P ⊥XP ⊥)|||
+(2δ + 4L(δ, α))|||X|||.
(4.5)
Note L(δ, α) ↘0 as δ ↘0. For each ε > 0, we can choose δ > 0 such that
(2δ + 4L(δ, α))|||X||| ≤ε
and
E{δ}(H) = 0
(due to the separability of our Hilbert space). Then, we have
|||M(Hn, Hn)X −M(H, H)X|||
≤|||M(HnP ⊥
n , HnP ⊥
n )(P ⊥
n XP ⊥
n ) −M(HP ⊥, HP ⊥)(P ⊥XP ⊥)||| + ε.
Since E{δ}(H) = 0, we have the strong convergence
sHnP ⊥
n = P ⊥
n −→sHP ⊥= P ⊥,
HnP ⊥
n −→HP ⊥
as was remarked at the beginning, and Case (b) (or more precisely Re-
mark 4.2, (1) below together with the obvious fact limn→∞|||P ⊥
n XP ⊥
n −
P ⊥XP ⊥||| = 0) guarantees
lim
n→∞|||M(HnP ⊥
n , HnP ⊥
n )(P ⊥
n XP ⊥
n ) −M(HP ⊥, HP ⊥)(P ⊥XP ⊥)||| = 0.
Therefore, we have
lim sup
n→∞|||M(Hn, Hn)X −M(H, H)X||| ≤ε,
and the proof is completed.
⊓⊔
Remark 4.2. Some remarks are in order.
(1) The conclusion of Theorem 4.1 can be a bit strengthened: if Xn, X ∈I(0)
|||·|||
and |||Xn −X||| →0, then
lim
n→∞|||M(Hn, Kn)Xn −M(H, K)X||| = 0
under the same situation. The result indeed follows from
|||M(Hn, Kn)Xn −M(H, K)X|||
≤|||M(Hn, Kn)(Xn −X)||| + |||M(Hn, Kn)X −M(H, K)X|||
≤κ|||Xn −X||| + |||M(Hn, Kn)X −M(H, K)X|||.

4.2 Related convergence results
61
(2) The case (a) covers the Schatten p-norm ∥· ∥p for 2 ≤p < ∞and the
operator norm ∥· ∥, so if M ⪯M∞and Hn →H, Kn →K strongly, then
we have
lim
n→∞∥M(Hn, Kn)X −M(H, K)X∥= 0
for all X ∈C(H)

= I(0)
∥·∥

, the algebra of all compact operators.
(3) The condition (b) is automatic as long as sH ≥sHn (for n large enough).
Hence, for example when either Hn ↗H, Kn ↗K or H, K are non-
singular, the condition (b) is satisﬁed. In fact, thanks to sHn ≥Hn(ε +
Hn)−1 (ε > 0) and the strong convergence Hn →H we have
(sHξ, ξ) ≥lim sup
n→∞(sHnξ, ξ) ≥lim inf
n→∞(sHnξ, ξ)
≥lim inf
n→∞(Hn(ε + Hn)−1ξ, ξ) = (H(ε + H)−1ξ, ξ)
for each vector ξ. By letting ε ↘0 one gets limn→∞(sHnξ, ξ) = (sHξ, ξ),
showing sHn →sH strongly.
(4) When M ∈M is a Schur multiplier, one can observe from the argument
before Remark 2.5 that M(H, K) on I|||·||| is the transpose of M(K, H) on
I(0)
|||·|||′ under the duality I|||·||| =

I(0)
|||·|||′
∗
. Here, ||| · |||′ is the conjugate
norm of |||·|||, and the duality is given by the bilinear form (X, Y ) ∈I|||·|||×
I(0)
|||·|||′ 
→Tr(XY ) ∈C. Hence M(H, K) on I|||·||| is w*-w*-continuous, that
is σ

I|||·|||, I(0)
|||·|||′

-σ

I|||·|||, I(0)
|||·|||′

-continuous, as in Remark 2.5, (i). It is
seen from this fact that M(Hn, Kn)X →M(H, K)X in σ

I|||·|||, I(0)
|||·|||′

for all X ∈I|||·||| in the situation of (b) or (c) in Theorem 4.1.
4.2 Related convergence results
Variants of the arguments presented in the proof of Theorem 4.1 enable us to
obtain some related convergence criteria in many settings. We begin with the
strong convergence M(Hn, Kn)X →M(H, K)X, which is somewhat easier to
handle.
Proposition 4.3. Assume that M ∈M satisﬁes M ⪯M∞. Let H, K, Hn
and Kn (n = 1, 2, . . . ) be positive operators such that Hn →H, Kn →K,
sHn →sH and sKn →sK in the strong operator topology. Then, for each
X ∈B(H), means M(Hn, Kn)X tend to M(H, K)X in the strong operator
topology.
Proof. As remarked in the proof of Theorem 4.1, we have the strong con-
vergence (HnsHn)ix →(HsH)ix, (KnsKn)ix →(KsK)ix (for each x ∈R).
We consider the special case M = M∞at ﬁrst. By substituting the integral
expression (3.11) to the right-hand side of the obvious equation

62
4 Convergence of means
∥(M∞(Hn, Kn)X −M∞(H, K)X) ξ∥
= sup
∥η∥≤1
| ((M∞(Hn, Kn)X −M∞(H, K)X) ξ, η) |,
we easily observe
∥(M∞(Hn, Kn)X −M∞(H, K)X) ξ∥
≤∥((HnX + XKn) −(HX + XK))ξ∥
+1
2
 ∞
−∞

(HnsHn)ix(HnX + XKn)(KnsKn)−ix
−(HsH)ix(HX + XK)(KsK)−ix
ξ
f(x) dx.
Since
(HnsHn)ix(HnX + XKn)(KnsKn)−ix −→(HsH)ix(HX + XK)(KsK)−ix
strongly, the above estimate (together with the Lebesgue dominated conver-
gence theorem) implies the strong convergence
M∞(Hn, Kn)X −→M∞(H, K)X.
Moreover, since Theorem 3.12 implies the uniform boundedness
sup
n ∥M∞(Hn, Kn)X∥< ∞,
(4.6)
the following strong convergence is also valid:
(HnsHn)ix(M∞(Hn, Kn)X)(KnsKn)−ix
−→(HsH)ix(M∞(H, K)X)(KsK)−ix.
(4.7)
We now assume M ⪯M∞. Then, based on Theorem 3.4 (i.e., (3.8)) we
obtain the similar estimate for ∥(M(Hn, Kn)X −M(H, K)X)ξ∥as above with
the integrand

(HnsHn)ix(M∞(Hn, Kn)X)(KnsKn)−ix
−(HsH)ix(M∞(H, K)X)(KsK)−ix
ξ
.
Therefore, (4.6), (4.7) and another use of the Lebesgue dominated convergence
theorem yield the strong convergence M(Hn, Kn)X →M(H, K)X.
⊓⊔
The strong convergence of M(Hn, Kn)X to M(H, K)X is also guaranteed
by (i) the strong convergence Hn →H, Kn →K, (ii) X ∈C(H) (i.e., X is
compact) and (iii) M ⪯L (i.e., the condition (c) in Theorem 4.1). We will
just sketch the arguments, and full details are left to the reader. In fact, by
using the same decomposition (as well as the notations) as in the proof of
Theorem 4.1, (c) and the estimates (4.3), (4.4) for ||| · ||| = ∥· ∥the operator
norm, we obtain the following estimate for each vector ξ:

4.2 Related convergence results
63
∥(M(Hn, Hn)X −M(H, H)X) ξ∥
≤

M(HnP ⊥
n , HnP ⊥
n )(P ⊥
n XP ⊥
n ) −M(HP ⊥, HP ⊥)(P ⊥XP ⊥)

ξ

+(2δ + 4L(δ, α))∥X∥× ∥ξ∥.
Therefore, we can repeat the arguments at the end of the part (c) in the proof
of Theorem 4.1 to get the desired convergence; in fact, use the above estimate
in place of (4.5) and apply Proposition 4.3 (see also Remark 4.2, (1)) together
with ∥P ⊥
n XP ⊥
n −P ⊥XP ⊥∥→0, which is a consequence of the compactness
of X.
We point out that the arguments in Case (b) in Theorem 4.1 gives us
the norm convergence M(Hn, Kn)X →M(H, K)X valid for all X ∈I|||·|||
(instead of I(0)
|||·||| under a stronger condition).
Proposition 4.4. Assume that M ∈M satisﬁes M ⪯M∞. Let H, K, Hn
and Kn (n = 1, 2, . . . ) be positive operators such that H, K are invertible,
∥Hn −H∥→0 and ∥Kn −K∥→0. Then for any unitarily invariant norm
||| · ||| we have
lim
n→∞|||M(Hn, Kn)X −M(H, K)X||| = 0
for all X ∈I|||·|||. In particular,
lim
n→∞∥M(Hn, Kn)X −M(H, K)X∥= 0
for all X ∈B(H).
Proof. Note that Hn, Kn are invertible for large n and ∥Hix
n −Hix∥→0,
∥Kix
n −Kix∥→0 for all x ∈R. By using the expression (3.11) (together with
Theorem A.5 and the Lebesgue dominated convergence theorem) it is easy to
see that
lim
n→∞|||M∞(Hn, Kn)X −M∞(H, K)X||| = 0
for all X ∈I|||·|||. Next, by using the expression
M(Hn, Kn)X =
 ∞
−∞
Hix
n (M∞(Hn, Kn)X)K−ix
n
dν(x)
and the same for H, K we obtain the conclusion.
⊓⊔

5
A-L-G interpolation means Mα
Three special one-parameter families of symmetric homogeneous means were
investigated in our previous article [39]: A-L-G interpolation means Mα,
Heinz-type means Aα and binomial means Bα (see also Chapter 1). We
obtained there a variety of comparison (in terms of the order ⪯) among
those means, which give norm inequalities including the familiar arithmetic-
logarithmic-geometric mean inequality for Hilbert space operators based on
Theorem 3.7 (though in [39] we restricted ourselves to the case of matrices).
In the rest we will deal with the same one-parameter families of means once
again, but our main aim here is to establish the norm continuity of their means
of operators in the parameter α (see Theorem 5.7 for instance). In this chap-
ter we begin with A-L-G interpolation means Mα while Heinz-type means Aα
and binomial means Bα will be dealt with in the subsequent two chapters.
5.1 Monotonicity and related results
The most typical one-parameter family of means in M is the following Mα
(−∞≤α ≤∞):
Mα(s, t) =



α −1
α
×
sα −tα
sα−1 −tα−1
(s ̸= t),
s
(s = t),
where Mα for α = −∞, 0, 1, ∞are understood as M−∞, G, L, M∞respectively
mentioned in (3.4). Indeed, notice
G(s, t) = lim
α→0 Mα(s, t), L(s, t) = lim
α→1 Mα(s, t), M±∞(s, t) =
lim
α→±∞Mα(s, t).
In this way, the one-parameter family Mα interpolates familiar means such as
F. Hiai and H. Kosaki: LNM 1820, pp. 65–78, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

66
5 A-L-G interpolation means Mα
M2 = A
(the arithmetic mean),
M1 = L
(the logarithmic mean),
M1/2 = G
(the geometric mean),
M−1 = Mhar (the harmonic mean).
The means Mα for the special values α =
n
n−1 (n = 2, 3, . . .) and α =
m
m+1
(m = 1, 2, . . .) are written as















M
n
n−1 (s, t) = 1
n × s
n
n−1 −t
n
n−1
s
1
n−1 −t
1
n−1 = 1
n
n−1

k=0
s
k
n−1 t
n−1−k
n−1 ,
M
m
m+1 (s, t) = 1
m × s
m
m+1 −t
m
m+1
s
−1
m+1 −t
−1
m+1 = 1
m
m

k=1
s
k
m+1 t
m+1−k
m+1 .
(5.1)
The former (resp. latter) means discretely interpolate A and L (resp. G and
L), and the corresponding operator means were thoroughly investigated in
[38] (where the notations An and Gm were used instead).
It was proved in [39] that
Mα ⪯Mβ
if −∞≤α < β ≤∞
(5.2)
(see (3.4) and its proof for typical cases). Hence Proposition 3.3 and Corollary
3.5 imply the following monotonicity:
Theorem 5.1. For every −∞≤α ≤∞the mean Mα is a Schur multiplier,
and if −∞≤α < β ≤∞, then
|||Mα(H, K)X||| ≤|||Mβ(H, K)X|||
for all H, K, X ∈B(H) with H, K ≥0 and for any unitarily invariant norm
||| · |||.
The estimate (3.16) and Theorem 5.1 guarantee the equivalence of the
norms of Mα(H, K)X for 2 ≤α ≤∞. The equivalence actually remains valid
for 1 < α ≤∞(but not for α ≤1), as will be seen in the proposition below
together with mutual norm bounds. This diﬀerence comes from the fact that
Mα(1, 0) > 0 for α > 1 in contrast with Mα(1, 0) = 0 for α ≤1 (see Remark
5.5, (i)).
Proposition 5.2. Let H, K be positive operators, X ∈B(H) and ||| · ||| be
any unitarily invariant norm. If 1 < α < β ≤∞, then we have
|||Mα(H, K)X||| ≤|||Mβ(H, K)X|||
≤(α + 1)β −2α
(α −1)β
× |||Mα(H, K)X|||,
(5.3)
and

5.1 Monotonicity and related results
67
|||Mα(H, K)X −Mβ(H, K)X||| ≤2(β −α)
(α −1)β × |||Mα(H, K)X|||.
(5.4)
Here, for β = ∞the constants (α+1)β−2α
(α−1)β
and 2(β−α)
(α−1)β are understood as α+1
α−1
and
2
α−1 respectively.
Proof. The ﬁrst inequality in (5.3) is due to Theorem 5.1. To show the second,
we ﬁrst assume 1 < α < β < ∞. Direct computations yield
Mβ(ex, 1)
Mα(ex, 1) = α(β −1)
(α −1)β × e(α−1)x −1
eαx −1
×
eβx −1
e(β−1)x −1
= α(β −1)
(α −1)β × sinh
 α−1
2 x

sinh
 α
2 x

×
sinh
 β
2 x

sinh
 β−1
2 x
.
(5.5)
From this we easily observe
1 −(α −1)β
α(β −1) × Mβ(ex, 1)
Mα(ex, 1)
= sinh
 α
2 x

sinh
 β−1
2 x

−sinh
 α−1
2 x

sinh
 β
2 x

sinh
 α
2 x

sinh
 β−1
2 x

= sinh
 x
2

sinh
 α
2 x
 × sinh
 β−α
2 x

sinh
 β−1
2 x

(5.6)
by using sinh
 α
2 x

= sinh
 α−1
2 x

cosh
 x
2

+cosh
 α−1
2 x

sinh
 x
2

(and the sim-
ilar formula for sinh
 β
2 x

). Thanks to 1 < α < β < ∞, the two functions
sinh
 x
2

/ sinh
 α
2 x

and sinh
 β−α
2 x

/ sinh
 β−1
2 x

here are positive deﬁnite (see
[39, (1.4)]) so that (5.6) is the Fourier transform of a positive measure with
total mass
β−α
α(β−1). This means that
M(s, t) = α(β −1)
β −α Mα(s, t) −(α −1)β
β −α Mβ(s, t)
is a mean in M and M ⪯Mα is satisﬁed. Therefore, from Corollary 3.5 we
get
|||α(β −1)
β −α Mα(H, K)X −(α −1)β
β −α Mβ(H, K)X||| ≤|||Mα(H, K)X|||
(5.7)
so that
(α −1)β
β −α |||Mβ(H, K)X|||
≤α(β −1)
β −α |||Mα(H, K)X|||
+|||α(β −1)
β −α Mα(H, K)X −(α −1)β
β −α Mβ(H, K)X|||
≤
α(β −1)
β −α
+ 1

|||Mα(H, K)X||| = (α + 1)β −2α
β −α
× |||Mα(H, K)X|||,

68
5 A-L-G interpolation means Mα
implying the second inequality in the case β < ∞.
The proof in the limiting case β = ∞is similar. Indeed, we can replace
the expressions (5.5) and (5.6) by
α
α −1 × e
|x|
2 sinh
 α−1
2 x

sinh
 α
2 x

and
e
1−α
2
|x| × sinh
 x
2

sinh
 α
2 x

respectively, and then we proceed as in the above case β < ∞. Here, we point
out that the function e
1−α
2
|x| is positive deﬁnite thanks to
e−a|x| = a
π
 ∞
−∞
eixy
y2 + a2 dy
(a > 0)
(5.8)
(see also (7.3)).
Finally, by noting α(β−1)
(α−1)β > 1 and recalling (5.7), we estimate
|||Mα(H, K)X −Mβ(H, K)X|||
≤
α(β −1)
(α −1)β −1

|||Mα(H, K)X|||
+|||α(β −1)
(α −1)β Mα(H, K)X −Mβ(H, K)X|||
≤
α(β −1)
(α −1)β −1 +
β −α
(α −1)β

|||Mα(H, K)X|||.
The last coeﬃcient here is 2(β−α)
(α−1)β so that (5.4) is obtained.
⊓⊔
From the means Mα with α =
n
n−1 (n = 2, 3, . . . ) we get
M
n
n−1 (H, K)X = 1
n
n−1

k=0
H
k
n−1 XK
n−1−k
n−1
(see (5.1)). We showed in [38] that the norm ||| 1
n
n−1
k=0 H
k
n−1 XK
n−1−k
n−1 ||| is
monotone decreasing in n (which can be thought of as a special case of Theo-
rem 5.1). Complementing this, we state the following special case of the above
proposition:
Corollary 5.3. Let H, K, X and |||·||| be as above. For all integers n > m ≥2,
||| 1
n
n−1

k=0
H
k
n−1 XK
n−1−k
n−1 ||| ≤||| 1
m
m−1

k=0
H
k
m−1 XK
m−1−k
m−1 |||
≤2n −m
m
× ||| 1
n
n−1

k=0
H
k
n−1 XK
n−1−k
n−1 |||
and

5.2 Characterization of |||M∞(H, K)X||| < ∞
69
||| 1
n
n−1

k=0
H
k
n−1 XK
n−1−k
n−1
−1
m
m−1

k=0
H
k
m−1 XK
m−1−k
m−1 |||
≤2(n −m)
m
× ||| 1
n
n−1

k=0
H
k
n−1 XK
n−1−k
n−1 |||.
5.2 Characterization of |||M
 (H, K)X||| < ∞
The following is also a consequence of Proposition 5.2:
Proposition 5.4. For every H, K ≥0, X ∈B(H) and any unitarily invari-
ant norm ||| · |||, the following conditions are mutually equivalent :
(i)
|||Mα(H, K)X||| < ∞for some 1 < α < ∞;
(ii)
|||M∞(H, K)X||| < ∞;
(iii) |||HX + XK||| < ∞.
Moreover, when one (and hence all) of these conditions is satisﬁed, then we
have the norm convergence
lim
α→β |||Mα(H, K)X −Mβ(H, K)X||| = 0
for every 1 < β ≤∞.
Remark 5.5. A few remarks are in order.
(i)
An estimate from the above such as the second inequality in (5.3) is
impossible (even for scalars) for α ≤1. In fact, it is straight-forward to
see lims↘0 Mβ(s, 1)/Mα(s, 1) = ∞for any β > α as long as α ≤1.
(ii) In [53] unitarily invariant norms ||| · ||| under which the map A →|A| is
Lipschitz continuous were characterized as interpolation norms (see [6, 56]
for general facts on interpolation spaces) between ∥·∥p1 and ∥·∥p2 with 1 <
p1, p2 < ∞, where the boundedness of the “upper triangular projection”
played a crucial role (see [30, 59]). For such norms the inequality (5.9) in
Proposition 5.6 below shows that the ﬁniteness condition |||HX +XK||| <
∞in Proposition 5.4 is equivalent to the requirement:
|||HX||| < ∞
and
|||XK||| < ∞.
Proposition 5.6. If ||| · ||| is an interpolation norm between some Schatten
p-norms ∥· ∥p1 and ∥· ∥p2 with 1 < p1, p2 < ∞, then one can ﬁnd a constant
κ (depending only on ||| · |||) such that
|||HX −XK||| ≤κ|||HX + XK|||
(5.9)
is valid for all H, K, X with H, K ≥0.

70
5 A-L-G interpolation means Mα
Proof. The inequality (5.9) for matrices is known (see [24] and also [53]),
where κ is a constant depending only upon ||| · ||| (independent of the size
of matrices). We have to generalize this inequality for inﬁnite-dimensional
operators. Thanks to the standard 2 × 2-matrix trick we may and do assume
H = K ≥0. Then, for any given ε > 0 one can ﬁnd a decomposition H =
Dε + Hε into self-adjoint operators such that |||Hε||| ≤ε and Dε is diagonal
(see [58] or [48, Chapter X, §2.2]). Note |||H −|Dε| ||| ≤const. |||Hε||| (with a
constant depending only upon ||| · |||) thanks to [53, Corollary 7]. Hence, by
replacing Dε, Hε by |Dε|, H −|Dε|, we may and do assume the positivity of
the diagonal operator Dε. Notice
 |||DεX ± XDε||| −|||HX ± XH|||

≤|||HεX||| + |||XHε||| ≤2|||Hε||| × ∥X∥≤2ε∥X∥.
Thus, to show (5.9) for inﬁnite-dimensional operators we may and do assume
that H (= K) is a positive diagonal operator from the beginning, and hence
one ﬁnds a sequence {pn}n=1,2,··· of ﬁnite-rank projections such that pn tends
to 1 in the strong operator topology and Hpn = pnH. We then estimate
|||HX −XH||| ≤lim inf
n→∞|||(pnHpn)(pnXpn) −(pnXpn)(pnHpn)|||
≤κ lim inf
n→∞|||(pnHpn)(pnXpn) + (pnXpn)(pnHpn)|||
(by (5.9) in the matrix case)
= κ lim inf
n→∞|||pn(HX + XH)pn|||
≤κ|||HX + XH|||
so that (5.9) for general operators is established.
⊓⊔
5.3 Norm continuity in parameter
In this section we will show the next theorem concerning the norm continuity
of Mα(H, K)X in the parameter α.
Theorem 5.7. Let H, K ≥0, X ∈B(H) and ||| · ||| be a unitarily invariant
norm. If −∞≤α0 ≤∞and |||Mβ(H, K)X||| < ∞for some β > min{α0, 1},
then
lim
α→α0 |||Mα(H, K)X −Mα0(H, K)X||| = 0.
At ﬁrst we prepare two easy lemmas for the proof of the theorem.
Lemma 5.8. Let ϕ, ϕn (n = 1, 2, . . .) be nonnegative functions in L1(R) such
that
lim
n→∞
 ∞
−∞
ϕn(x) dx =
 ∞
−∞
ϕ(x) dx.
If the Fourier transforms

5.3 Norm continuity in parameter
71
ˆϕ(x) =
 ∞
−∞
eixyϕ(y) dy,
ˆϕn(x) =
 ∞
−∞
eixyϕn(y) dy
are in L2(R) and
lim
n→∞∥ˆϕn −ˆϕ∥2 = 0,
then
lim
n→∞∥ϕn −ϕ∥1 = 0.
Proof. By the Fourier inversion formula we get ϕ, ϕn ∈L2(R) and
∥ϕn −ϕ∥2 = 1
2π ∥ˆϕn −ˆϕ∥2 −→0
(n →∞).
In particular, we have the convergence ϕn(x) →ϕ(x) in measure. The as-
sumption means
lim
n→∞
 ∞
−∞
(ϕn(x) + ϕ(x)) dx = 2
 ∞
−∞
ϕ(x) dx.
Hence, by applying the extended form of the Lebesgue dominated convergence
theorem (see [75, Chapter 11, Proposition 18] or [26, Theorem 3.6]) to |ϕn(x)−
ϕ(x)| ≤ϕn(x) + ϕ(x), we conclude ∥ϕn −ϕ∥1 →0.
⊓⊔
Lemma 5.9. For any θ > 0 and x > 0 the following inequalities hold :
(i)
θ
sinh(θx) ≤1
x,
(ii)
sinh(θx)
θ sinh((1 + θ)x) ≤
x
sinh(x).
Proof. (i) is just the well-known inequality x ≤sinh(x) for x ≥0. The in-
equality (ii) is equivalent to
xθ sinh((1 + θ)x) −sinh(θx) sinh(x) ≥0.
However, it is indeed the case because the derivative (with respect to θ) of
the above left-hand side is
x sinh((1 + θ)x) + x2θ cosh((1 + θ)x) −x cosh(θx) sinh(x)
= x sinh(θx) cosh(x) + x2θ cosh((1 + θ)x) ≥0.
⊓⊔
Proof of Theorem 5.7. The assertion for the case 1 < α0 ≤∞was already
shown in Proposition 5.4. To deal with the case −∞≤α0 ≤1, we will consider
the following cases separately:
(a) 0 < α0 < 1,
(b) α0 < 0,
(c) α0 = 1,
(d) α0 = 0.
(e) α0 = −∞,

72
5 A-L-G interpolation means Mα
(a) Case 0 < α0 < 1. By the assumption (also Corollary 3.5 and (5.2)) we
can choose α0 < β < 1 such that |||Mβ(H, K)X||| < ∞. For 0 < α < β we
compute
Mα(ex, 1)
Mβ(ex, 1) = (α −1)β
α(β −1) ×
eαx −1
e(α−1)x −1 × e(β−1)x −1
eβx −1
= (α −1)β
α(β −1) × sinh
 α
2 x

sinh
 β
2 x
 × sinh
 1−β
2 x

sinh
 1−α
2 x

= ˆϕα,β(x)
for some positive function ϕα,β ∈L1(R) with
 ∞
−∞ϕα,β(x)dx = 1 (see the
proof of [39, Theorem 2.1] or [39, (1.4)]). We note
sinh
 α
2 x

sinh
 β
2 x
 × sinh
 1−β
2 x

sinh
 1−α
2 x
 = O(e(α−β)|x|)
(as |x| →∞),
and take δ > 0 satisfying 0 < α0 −δ < α0 +δ < β. Then, ˆϕ2
α,β for |α−α0| < δ
are uniformly integrable. Moreover, it is obvious that ˆϕα,β(x) →ˆϕα0,β(x) as
α →α0 for all x ∈R. Thus, the Lebesgue dominated convergence theorem
yields
lim
α→α0 ∥ˆϕα,β −ˆϕα0,β∥2 = 0,
and so Lemma 5.8 implies
lim
α→α0 ∥ϕα,β −ϕα0,β∥1 = 0.
Since
Mα(H, K)X =
 ∞
−∞
(HsH)ix(Mβ(H, K)X)(KsK)−ixϕα,β(x) dx
(0 < α < β) by Theorem 3.4 and (5.2), we have
|||Mα(H, K)X −Mα0(H, K)X||| ≤∥ϕα,β −ϕα0,β∥1 × |||Mβ(H, K)X||| −→0
as α →α0.
(b) Case α0 < 0. We can choose α0 < β < α0
2 (or 2β < α0 < β) such
that |||Mβ(H, K)X||| < ∞. When 2β < α < β, we have (see the proof of [39,
Theorem 2.1])
Mα(ex, 1)
Mβ(ex, 1) = (1 −α)(−β)
(−α)(1 −β) × sinh
 −α
2 x

sinh
 1−α
2 x
 × sinh
 1−β
2 x

sinh
 −β
2 x

= (1 −α)(−β)
(−α)(1 −β)

1 +
sinh
 x
2

sinh
 1−α
2 x
 × sinh
 β−α
2 x

sinh
 −β
2 x


= (1 −α)(−β)
(−α)(1 −β) + ˆϕα,β(x)
(5.10)

5.3 Norm continuity in parameter
73
for some positive function ϕα,β ∈L1(R) with
 ∞
−∞
ϕα,β(x) dx = 1 −(1 −α)(−β)
(−α)(1 −β).
In the same way as in Case (a) we have
lim
α→α0 ∥ˆϕα,β −ˆϕα0,β∥2 = 0
so that Lemma 5.8 implies ∥ϕα,β −ϕα,β∥1 →0 as α →α0. Since
Mα(H, K)X =
 ∞
−∞
(HsH)is(Mβ(H, K)X)(KsK)−ixϕα,β(x) dx
+(1 −α)(−β)
(−α)(1 −β)Mβ(H, K)X
by (3.9) in Theorem 3.4, we get
|||Mα(H, K)X −Mα0(H, K)X|||
≤

∥ϕα,β −ϕα0,β∥1 +

(1 −α)(−β)
(−α)(1 −β) −(1 −α0)(−β)
(−α0)(1 −β)


×|||Mβ(H, K)X||| −→0
as α →α0.
(c) Case α0 = 1. Choose 1 < β < 2 such that |||Mβ(H, K)X||| < ∞. We
have
M1(ex, 1)
Mβ(ex, 1) =
β
β −1 × sinh
 x
2

sinh
 β−1
2 x

 x
2

sinh
 β
2 x

= ˆψ1,β(x)
for some positive function ψ1,β ∈L1(R) with
 ∞
−∞ψ1,β(x) dx = 1 by [39,
Corollary 2.4]. Notice ˆψ1,β ∈L2(R) because of ˆψ1,β(x)2 = O(x−2) as |x| →∞.
Now we deal with the two cases 1 < α < β and 0 < α < 1 separately.
First, consider the case 1 < α < β. We notice
Mα(ex, 1)
Mβ(ex, 1) = (α −1)β
α(β −1)

1 + sinh
 x
2

sinh
 β−α
2 x

sinh
 α−1
2 x

sinh
 β
2 x

	
= (α −1)β
α(β −1) + ˆψα,β(x)
for some positive function ψα,β ∈L1(R) with
 ∞
−∞
ψα,β(x) dx = 1 −(α −1)β
α(β −1).

74
5 A-L-G interpolation means Mα
Indeed, choose α = a0 < a1 < · · · < am = β such that ak < 2ak−1 −1
(1 ≤k ≤m). By the proof of [39, Theorem 2.1] there are positive functions
f1, . . . , fm ∈L1(R) such that
Mak−1(ex, 1)
Mak(ex, 1)
= (ak−1 −1)ak
ak−1(ak −1) + ˆfk(x)
(1 ≤k ≤m)
so that
Mα(ex, 1)
Mβ(ex, 1) =
m

k=1
(ak−1 −1)ak
ak−1(ak −1) + ˆfk(x)

= (α −1)β
α(β −1) + ˆψα,β(x).
Here, ψα,β is a linear combination (with positive coeﬃcients) of the convolu-
tions fk1 ∗fk2 ∗· · · ∗fkl for 1 ≤k1 < k2 < · · · < kl ≤m so that the positivity
of ψα,β is clear.
We have
ˆψα,β(x) = (α −1)β
α(β −1) × sinh
 x
2

sinh
 β−α
2 x

sinh
 α−1
2 x

sinh
 β
2 x

≤
β
α(β −1) × sinh
 x
2

sinh
 β−1
2 x

 x
2

sinh
 β
2 x

= 1
α × ˆψ1,β(x) ≤ˆψ1,β(x)
thanks to (α−1)/ sinh
 α−1
2 x

≤2
x (see Lemma 5.9, (i)) and the increasingness
sinh
 β−α
2 x

≤sinh
 β−1
2 x

(x ≥0). Moreover, ˆψα,β(x) →ˆψ1,β(x) as α ↘1
for all x ∈R. Therefore, the dominated convergence theorem shows
∥ˆψα,β −ˆψ1,β∥2 = 0,
and Lemma 5.8 implies ∥ψα,β −ψ1,β∥1 →0 as α ↘1. Since
M1(H, K)X =
 ∞
−∞
(HsH)ix(Mβ(H, K)X)(KsK)−ixψ1,β(x) dx,
Mα(H, K)X =
 ∞
−∞
(HsH)ix(Mβ(H, K)X)(KsK)−ixψα,β(x) dx
+(α −1)β
α(β −1)Mβ(H, K)X,
we get
|||Mα(H, K)X −M1(H, K)X|||
≤

∥ψα,β −ψ1,β∥1 + (α −1)β
α(β −1)

|||Mβ(H, K)X||| −→0
as α ↘1.

5.3 Norm continuity in parameter
75
Next, consider the case 0 < α < 1. Since
Mα(ex, 1)
Mβ(ex, 1) = Mα(ex, 1)
M1(ex, 1) × ˆψ1,β(x)
and Mα(ex, 1)/M1(ex, 1) is a positive deﬁnite function, there is a positive
function ϕα,β ∈L1(R) such that
Mα(ex, 1)
Mβ(ex, 1) = (1 −α)β
α(β −1) × sinh
 α
2 x

sinh
 β−1
2 x

sinh
 1−α
2 x

sinh
 β
2 x
 = ˆϕα,β(x).
We have
ˆϕα,β(x) ≤
β
α(β −1) × sinh
 x
2

sinh
 β−1
2 x

 x
2

sinh
 β
2 x

= 1
α × ˆψ1,β(x),
because of (1 −α)/ sinh
 1−α
2 x

≤2
x (see Lemma 5.9, (i)) and the increasing-
ness sinh
 α
2 x

≤sinh
 x
2

(x ≥0). Hence we get
lim
α↗1 ∥ˆϕα,β −ˆψ1,β∥2 = 0
by the dominated convergence theorem. Therefore, Lemma 5.8 implies ∥ϕα,β−
ψ1,β∥1 →0 as α ↗1, and consequently
lim
α↗1 |||Mα(H, K)X −M1(H, K)X||| = 0
as before.
(d) Case α0 = 0. Choose 0 < β < 1 such that |||Mβ(H, K)X||| < ∞, and
deal with the two cases 0 < α < β and −β < α < 0 separately. For 0 ≤α < β
we have
Mα(ex, 1)
Mβ(ex, 1) = (1 −α)β
α(1 −β) × sinh
 α
2 x

sinh
 β
2 x
 × sinh
 1−β
2 x

sinh
 1−α
2 x
 = ˆϕα,β(x)
for some positive function ϕα,β ∈L1(R). (Here, 1
α sinh
 α
2 x

for α = 0 means
x
2 .) Since Lemma 5.9, (ii) gives
1
α × sinh
α
2 x

≤
 x
2

sinh
 1+α
2 x

sinh
 x
2

,
we get
ˆϕα,β(x) ≤(1 −α)β
1 −β
×
 x
2

sinh
 1+α
2 x

sinh
 1−β
2 x

sinh
 x
2

sinh
 β
2 x

sinh
 1−α
2 x

≤(1 −α)β
1 −β
×
 x
2

sinh
 1+(β/2)
2
x

sinh
 1−β
2 x

sinh
 x
2

sinh
 β
2 x

sinh
 1−(β/2)
2
x

≤O(e−β
4 |x|)
(as |x| →∞)

76
5 A-L-G interpolation means Mα
when for example 0 < α < β
2 . Hence, as usual we have limα↘0 ∥ˆϕα,β−ˆϕ0,β∥2 =
0 and so limα↘0 ∥ϕα,β −ϕ0,β∥1 = 0. Consequently
lim
α↘0 |||Mα(H, K)X −M0(H, K)X||| = 0.
Now, consider the case −β < α < 0. We have
Mα(ex, 1)
Mβ(ex, 1) =
(1 −α)β
(−α)(1 −β) × sinh
 −α
2 x

sinh
 β
2 x
 × sinh
 1−β
2 x

sinh
 1−α
2 x
 = ˆϕα,β(x)
for some positive ϕα,β ∈L1(R). Since the estimate
sinh
 −α
2 x

(−α) sinh
 1−α
2 x
 ≤
 x
2

sinh
 x
2

(Lemma 5.9, (ii)) guarantees
ˆϕα,β(x) ≤(1 −α)β
1 −β
×
 x
2

sinh
 1−β
2 x

sinh
 x
2

sinh
 β
2 x
 = (1 −α) ˆϕ0,β(x),
we get limα↗0 ∥ˆϕα,β−ˆϕ0,β∥2 = 0. Therefore, we get limα↗0 ∥ϕα,β−ϕ0,β∥1 = 0
and
lim
α↗0 |||Mα(H, K)X −M0(H, K)X||| = 0
as before.
(e) Case α0 = −∞. We may and do assume that |||Mβ(H, K)X||| < ∞
for some β < −1. Then, for α < β we have sinh
 β−α
2 x

/ sinh
 1−α
2 x

≤1, and
hence ˆϕα,β(x) in (5.10) is majorized by the L2-function
(1 −α)(−β)
(−α)(1 −β) ×
sinh
 x
2

sinh
 −β
2 x
.
Therefore, it follows that ˆϕα,β converges in the ∥· ∥2-norm to the function
−β
1 −β × e
β−1
2
|x| ×
sinh
 x
2

sinh
 −β
2 x

as α →−∞. On the other hand, we notice
M−∞(ex, 1)
Mβ(ex, 1)
=
−β
1 −β × e−|x|
2 × sinh
 1−β
2 x

sinh
 −β
2 x

=
−β
1 −β

1 + e
β−1
2
|x| ×
sinh
 x
2

sinh
 −β
2 x


so that the desired convergence is obtained as before.
⊓⊔
For the operator norm ||| · ||| = ∥· ∥, the boundedness requirement in
Theorem 5.7 is automatic and hence we state

5.3 Norm continuity in parameter
77
Corollary 5.10. For each H, K ≥0, X ∈B(H) and for each −∞≤α0 ≤∞
we have
lim
α→α0 ∥Mα(H, K)X −Mα0(H, K)X∥= 0.
In Theorem 5.7 we required the existence of β > α0 satisfying the ﬁniteness
condition |||Mβ(H, K)X||| < ∞, which enabled us to combine relevant integral
expressions with the Lebesgue dominated convergence theorem. We now deal
with the limiting case β = α0.
Proposition 5.11. Let H, K ≥0, X ∈B(H) and |||·||| be a unitarily invari-
ant norm.
(i)
For each −∞≤α0 ≤∞we have
lim
α↗α0 |||Mα(H, K)X||| = |||Mα0(H, K)X||| (≤∞).
(ii) Assume −∞< α0 ≤∞. If I|||·||| is uniformly convex, then as long as
Mα0(H, K)X ∈I|||·||| we have Mα(H, K)X ∈I|||·||| for each α ≤α0 and
the norm convergence
lim
α↗α0 |||Mα(H, K)X −Mα0(H, K)X||| = 0.
The result also remains valid for the ideal C1(H) of trace class operators.
Note that the uniform convexity of I|||·||| is the same requirement as that of
I(0)
|||·|||. In fact, this condition actually implies the separability of I|||·|||, i.e.,
I|||·||| = I(0)
|||·||| (see [29, §III.6]), and that of the dual

I|||·|||
∗(see Corollary
A.11 in §A.5).
Proof. (i) By the lower semi-continuity of |||·||| in the weak operator topology
(see [37, Proposition 2.11]), Corollary 5.10 guarantees
|||Mα0(H, K)X||| ≤lim inf
α↗α0 |||Mα(H, K)X|||,
which (together with the monotonicity obtained in Theorem 5.1) shows the
result.
(ii) From (i) and the uniform convexity of I|||·|||, it suﬃces to show
lim
α↗α0 φ(Mα(H, K)X) = φ(Mα0(H, K)X)
for each φ ∈

I|||·|||
∗. However, thanks to the boundedness of |||Mα(H, K)X|||
for α < α0, we need to check this weak convergence only against φ’s in a dense
subset of

I|||·|||
∗. Thanks to the separability of

I|||·|||
∗, φ’s of the form
Tr(F ·) with a ﬁnite-rank operator F form a dense subspace in

I|||·|||
∗. But,
for φ = Tr(F ·) the above convergence is trivial by Corollary 5.10. Finally, the
assertion for C1(H) is seen from for example [77, Theorem 2.19].
⊓⊔

78
5 A-L-G interpolation means Mα
Proposition 5.11, (ii) is meaningful only in the case α0 ≤1. Actually,
a situation is much better in the case α0 > 1; in fact, the latter case is
automatically covered in Theorem 5.7. It is known ([18]) that the uniform
convexity of I|||·||| is equivalent to that of the corresponding sequence Banach
space. For example, the Schatten p-class Cp(H) for 1 < p < ∞is uniformly
convex.
5.4 Notes and references
In [39] A-L-G interpolation means {Mα}−∞≤α≤∞were introduced and the
monotonicity (Theorem 5.1) was proved (at least for matrices) as a reﬁne-
ment of the arithmetic-logarithmic-geometric mean inequality (1.8). For the
special values α =
n
n−1 and α =
m
m+1 the operator means M
n
n−1 (H, K)X and
M
m
m+1 (H, K)X are easy to handle for Hilbert space operators (at least as far
as the deﬁnition is concerned). In fact, the expression (5.1) enables us to set











M
n
n−1 (H, K)X = 1
n
n−1

k=0
H
k
n−1 XK
n−1−k
n−1 ,
M
m
m+1 (H, K)X = 1
m
m

k=1
H
k
m+1 XK
m+1−k
m+1
directly so that detailed analysis on Schur multipliers (in Chapter 2) is ir-
relevant in this special case. Besides (1.8) these operator means were studied
in [38]. In fact, the monotonicity of their norms (i.e., (1.9)) was shown as a
reﬁnement of (1.8).
In the appendix to [38] the norm convergence of M
n
n−1 (H, K)X and
M
m
m+1 (H, K)X to the logarithmic mean M1(H, K)X was examined under
suitable assumptions ([38, Propositions 6, 7, 8]). Theorem 5.7 (together with
the ﬁniteness criterion Proposition 5.4) and Proposition 5.11,(ii) in this chap-
ter give rise to quite complete and satisfactory answers to such convergence
problems to all Mα’s.

6
Heinz-type means Aα
In this chapter we will deal with the following means in M:
Aα(s, t) = A1−α(s, t) = 1
2(sαt1−α + s1−αtα)
(0 ≤α ≤1),
that interpolates the arithmetic mean A0 = A and the geometric one A1/2 =
G. Obviously, each Aα is a Schur multiplier, and one has
Aα(H, K)X = 1
2(HαXK1−α + H1−αXKα)
(6.1)
for all H, K ≥0 and X ∈B(H) (with the convention H0 = K0 = 1 in the
case α = 0, 1). We point out that operators of this form appear in Heinz-type
inequalities ([36]).
We noticed in [39] that
Aα ⪯Aβ
if
0 ≤β < α ≤1
2.
(6.2)
Hence, Corollary 3.5 implies that |||HαXK1−α + H1−αXKα||| is monotone
decreasing in α ∈[0, 1
2] for unitarily invariant norms, corresponding to the
well-known fact: the Heinz inequality (1.3) remains valid for these norms (see
§6.3, 1).
6.1 Norm continuity in parameter
The norm continuity of the Heinz mean Aα(H, K)X in the parameter α is
given as follows: Let ||| · ||| be a unitarily invariant norm and 0 < α0 ≤1
2. If
|||HβXK1−β + H1−βXKβ||| < ∞for some 0 ≤β < α0, then
lim
α→α0 |||(HαXK1−α + H1−αXKα) −(HβXK1−β + H1−βXKβ)||| = 0.
This can be proved by using the integral expression
F. Hiai and H. Kosaki: LNM 1820, pp. 79–87, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

80
6 Heinz-type means Aα
HαXK1−α + H1−αXKα
=
 ∞
−∞
(HsH)ix(HβXK1−β + H1−βXKβ)(KsK)−ixfα,β(x) dx
for 0 ≤β < α ≤1
2, where fα,β is a positive function with
 ∞
−∞fα,β(x) dx = 1
such that
Aα(ex, 1)
Aβ(ex, 1) = cosh
 1
2 −α

x

cosh
 1
2 −β

x
 = ˆfα,β(x).
In fact, we have an explicit form of the function fα,β (see [39, (1.5)]), and so
the proof is much easier than that of Theorem 5.7. Moreover, the above norm
convergence can be improved in Proposition 6.1 below.
Note that the convergence Aα(H, K)X →A(H, K)X as α →0 is not true
even in the matrix case. In fact, when P, Q are orthogonal projections with
P ⊥Q and X = 1, we have A(P, Q)1 = 1
2(P + Q) but Aα(P, Q)1 = 0 for all
0 < α ≤1
2.
One piece HαXK1−α of the mean (6.1) is asymmetric, however our
method using integral expressions can still work to treat it. Actually, the
following integral formula was obtained in [54, Theorem 6]:
HαXK1−α =
 ∞
−∞
(HsH)ix(HX + XK)(KsK)−ix
×
dx
2 cosh

πx + πi

α −1
2

(6.3)
for each 0 < α < 1 and for all H, K, X ∈B(H) with H, K ≥0. (A particular
case of this was given in Example 3.6,(a).) Let gα(x) be the density appearing
in (6.3). Then, Theorem A.5 implies
|||HαXK1−α||| ≤
 ∞
−∞
|gα(x)| dx

|||HX + XK|||,
(6.4)
which is the weak matrix Young inequality in [54] (see also [3]).
Proposition 6.1. Let H, K ≥0, X ∈B(H) and |||·||| be a unitarily invariant
norm. If 0 < α0 < 1 and |||HβXK1−β + HγXK1−γ||| < ∞for some 0 ≤γ <
α0 < β ≤1 (this is the case in particular when |||HX + XK||| < ∞), then
lim
α→α0 |||HαXK1−α −Hα0XK1−α0||| = 0.
Proof. Since
HβXK1−β + HγXK1−γ = Hβ−γ(HγXK1−β) + (HγXK1−β)Kβ−γ
and
HαXK1−α = (Hβ−γ)
α−γ
β−γ (HγXK1−β)(Kβ−γ)1−α−γ
β−γ ,

6.2 Convergence of operator Riemann sums
81
we may and do assume |||HX+XK||| < ∞(i.e., β = 1 and γ = 0) by replacing
H, K, X by Hβ−γ, Kβ−γ, HγXK1−β respectively. Then by (6.3) and Theorem
A.5, we get
|||HαXK1−α −Hα0XK1−α0||| ≤∥gα −gα0∥1 × |||HX + XK|||
for 0 < α, α0 < 1. Thus, it suﬃces to see that ∥gα −gα0∥1 →0 as α →α0.
However, by recalling ([54, p. 443])
|gα(x)| =
1
2

sinh2(πx) + cos2
π

α −1
2
,
(6.5)
we see that the above L1-convergence is an immediate consequence of the
Lebesgue dominated convergence theorem.
⊓⊔
6.2 Convergence of operator Riemann sums
We present another application of the integral expression (6.3) in a similar
nature. Let us consider the following operator Riemann sum:
R(n) = 1
n
n

k=1
HξkXK1−ξk
(with ξk ∈[ k−1
n , k
n]).
From (6.3) we get
R(n) =
 ∞
−∞
(HsH)ix(HX + XK)(KsK)−ixφn(x) dx
with
φn(x) = 1
n
n

k=1
1
2 cosh

πx + πi

ξk −1
2
.
For a moment we assume that Riemann sums are chosen symmetrically, i.e.,
ξn+1−k = 1 −ξk for each n and k. (Asymmetric Riemann sums will be con-
sidered in Proposition 6.3.) Then, we easily compute
φ2m(x) =
1
2m
2m

k=1
1
2 cosh

πx + πi

ξk −1
2

=
1
2m
m

k=1
cosh(πx) cos

π

ξk −1
2

cos2
π

ξk −1
2

+ sinh2(πx)
(6.6)
thanks to
cosh

πx + πi

ξk −1
2

= cosh(πx) cos

π

ξk −1
2

+ i sinh(πx) sin

π

ξk −1
2

.

82
6 Heinz-type means Aα
We similarly get
φ2m+1(x)
=
1
2m + 1
 m

k=1
cosh(πx) cos

π

ξk −1
2

cos2
π

ξk −1
2

+ sinh2(πx) +
1
2 cosh(πx)

,
(6.7)
where the last term arises from the midpoint ξm+1 = 1
2. On the other hand,
the logarithmic mean is given by
L =
 1
0
HsXK1−sds =
 ∞
−∞
(HsH)ix(HX + XK)(KsK)−ixφ(x) dx
with
φ(x) = 1
π log
coth
πx
2
	
(6.8)
(see [38, p. 305]).
Proposition 6.2. Let H, K ≥0, X ∈B(H), and we assume |||HX+HK||| <
∞for a unitarily invariant norm |||·|||. Then, as long as Riemann sums R(n)
are chosen symmetrically (i.e., ξn+1−k = 1 −ξk for each n and k) we have
lim
n→∞|||R(n) −
 1
0
HsXK1−sds||| = 0.
Proof. From the preceding integral expressions for R(n) and L we see
R(n) −L =
 ∞
−∞
(HsH)ix(HX + XK)(KsK)−ix(φn(x) −φ(x)) dx
so that Theorem A.5 shows
|||R(n) −L||| ≤∥φn −φ∥1 × |||HX + XK|||.
Hence, as usual it suﬃces to see limn→∞∥φn−φ∥1 = 0. The Fourier transform
of the positive and positive deﬁnite function φ is 1
x tanh
 x
2

(see [38, p. 306])
and hence
 ∞
−∞
φ(x) dx = 1
2.
On the other hand, the positive (and actually positive deﬁnite) function φn
also satisﬁes
 ∞
−∞
φn(x) dx = 1
2
because of (6.6), (6.7) and
 ∞
−∞
cosh(πx)
cos2
π

ξk −1
2

+ sinh2(πx) dx =
1
cos

π

ξk −1
2
,
 ∞
−∞
1
cosh(πx) dx = 1.

6.2 Convergence of operator Riemann sums
83
(The fact
 ∞
−∞φ(x)dx =
 ∞
−∞φn(x)dx = 1
2 can be also seen by simply setting
H = K = X = 1 in the integral expressions for R(n) and L.) We claim
lim
n→∞φn(x) = φ(x).
Indeed, from (6.6) and (6.7) we observe that the limit in the left-hand side is
equal to the following deﬁnite integral:
cosh(πx)
 0
−1
2
cos(πα)
cos2(πα) + sinh2(πx) dα
= cosh(πx)
 0
−1
2
cos(πα)
cosh2(πx) −sin2(πα) dα
= cosh(πx)
π
 0
−1
1
cosh2(πx) −t2 dt
= 1
2π
 0
−1

1
cosh(πx) + t +
1
cosh(πx) −t

dt
= −1
2π log

cosh(πx) −1
cosh(πx) + 1
 ,
which is obviously φ(x). The desired L1-convergence thus follows from the ex-
tended Lebesgue dominated convergence theorem (see [75, Chapter 11, Propo-
sition 18]).
⊓⊔
Proposition 6.2 (as well as Theorem 5.7) is a considerable generalization
of the convergence results obtained in the appendix to [38]. If Riemann sums
are asymmetric, then |||R(n)||| < ∞is no longer guaranteed (under the as-
sumption |||HX + XK||| < ∞). However, for interpolation norms between
∥· ∥p1 and ∥· ∥p2 with 1 < p1, p2 < ∞(see Remark 5.5, (ii)), the ﬁniteness
|||R(n)||| < ∞is indeed guaranteed (see the inequality at the beginning of
the proof of the proposition below). Actually, for such norms we have the
following strengthening of Proposition 6.2:
Proposition 6.3. For an interpolation norm between ∥· ∥p1 and ∥· ∥p2 with
1 < p1, p2 < ∞the convergence in Proposition 6.2 remains valid for general
Riemann sums (which are not necessarily symmetric).
Proof. We choose and ﬁx a small ε > 0, and split the sum n
k=1 HξkXK1−ξk
(appearing in the deﬁnition of the Riemann sum R(n)) into the following two
parts:
  ′ : summation over k’s satisfying [ k−1
n , k
n] ⊆[ε, 1 −ε],
 ′′ : summation over other k’s.
Thanks to the assumption on the norm ||| · |||, we have
|||HαXK1−α||| ≤κ|||HX + XK|||
(for each α ∈[0, 1])

84
6 Heinz-type means Aα
with a constant κ (depending only on ||| · |||) (see [39, Proposition 3.1] and
Proposition 5.6). By counting the number of subintervals “near the end-
points”, this inequality guarantees
||| 1
n
 ′′HξkXK1−ξk||| ≤2(nε + 1)
n
× κ|||HX + XK|||
= 2

ε + 1
n

κ|||HX + XK|||.
We similarly get
|||
 ε
0
HsXK1−sds +
 1
1−ε
HsXK1−sds||| ≤2εκ|||HX + XK|||.
From the estimates so far (near the endpoints), we conclude
|||R(n) −
 1
0
HsXK1−sds|||
≤||| 1
n
 ′HξkXK1−ξk −
 1−ε
ε
HsXK1−sds|||
+2

2ε + 1
n

κ|||HX + XK|||.
(6.9)
To see the limit (as n →∞) of the ﬁrst quantity in the right-hand side of
(6.9), we need to check the behavior of Riemann sums corresponding to the
interval [ε, 1 −ε]. From (6.3) we get
1
n
 ′HξkXK1−ξk =
 ∞
−∞
(HsH)ix(HX + XK)(KsK)−ixψn(x) dx,
 1−ε
ε
HsXK1−sds =
 ∞
−∞
(HsH)ix(HX + XK)(KsK)−ixψ(x) dx
with the densities
ψn(x) = 1
n
 ′
1
2 cosh

πx + πi

ξk −1
2
,
ψ(x) =
 1−ε
ε
1
2 cosh

πx + πi

α −1
2
 dα.
Of course we have limn→∞ψn(x) = ψ(x) from the deﬁnition of  ′ and the
continuity of the involved function. On the other hand, from (6.5) we observe
|ψn(x)| ≤1
2n
 ′
1

sinh2(πx) + cos2
π

ξk −1
2
.
From the deﬁnition of  ′ we have ε ≤ξk ≤1 −ε and hence

6.3 Notes and references
85
cos

π

ξk −1
2

≥cos

π
 1
2 −ε

> 0,
which enables us to obtain the following uniform (independent of n) bound:
|ψn(x)| ≤1
2 min

1
| sinh(πx)|,
1
cos

π
 1
2 −ε


.
The right side here being an L1-function, we see limn→∞∥ψn−ψ∥1 = 0 by the
Lebesgue dominated convergence theorem. The usual argument thus shows
||| 1
n
 ′HξkXK1−ξk −
 1−ε
ε
HsXK1−sds|||
≤∥ψn −ψ∥1 × |||HX + XK||| →0
as n →∞. Therefore, (6.9) implies
lim sup
n→∞|||R(n) −
 1
0
HsXK1−sds||| ≤4εκ|||HX + XK|||,
and consequently we get
lim
n→∞|||R(n) −
 1
0
HsXK1−sds||| = 0
due to the arbitrariness of ε > 0.
⊓⊔
6.3 Notes and references
1. Heinz inequality
The Heinz inequality (1.3) (in the operator norm) is equivalent to the
decreasingness of the function
α ∈[0, 1/2] 	→∥HαXK1−α + H1−αXKα∥.
For the special value α = 1
2 the Heinz inequality reduces to the arithmetic-
geometric inequality (1.4) (in the operator norm). The original proof in [36]
was quite involved, and in [64] A. McIntosh presented a simpler proof in two
steps: (i) a direct proof of the latter is obtained, (ii) the former is proved
from the latter by certain iteration arguments. In [10] the latter was shown
to remain valid for unitarily invariant norms, and hence so does the former
(i.e., the Heinz inequality). In fact, (although quite ingenious) the step (ii) is
based on just the triangle inequality (see [64, Theorem 4]). A slightly diﬀerent
proof can be found in [63, Theorem 2.3]. Proofs can be also found in [13, 54].
The proof in [13] uses a Schur multiplier while that in [54, 39] uses an integral
formula of the form (3.9) (which arises from the Poisson integral formula
below). Both proofs are essentially based on the positive deﬁniteness of

86
6 Heinz-type means Aα
cosh(ax)
cosh(x) =
 ∞
−∞
cos(πa/2) cosh(πy/2)
cosh(πy) + cos(πa)
eixydy
(0 ≤a < 1).
On the other hand,
sinh(ax)
sinh(x) = 1
2
 ∞
−∞
sin(πa)
cosh(πy) + cos(πa) eixydy
(0 < a < 1)
is also positive deﬁnite, which corresponds to the diﬀerence version
|||HθXK1−θ −H1−θXKθ||| ≤|2θ −1| × |||HX −XK|||
(for θ ∈[0, 1])
of the Heinz inequality (see [13, p. 219] or [54, p. 435] for instance). From this
we get the following inequality (see [53, Theorem 4]):
|||HX −XK||| ≤|||eH/2Xe−K/2 −e−H/2XeK/2|||,
where H, K are self-adjoint operators. This commutator estimate also follows
from the positive deﬁniteness of the function x/ sinh(x) (see (3.5)).
2. Matrix Young inequality and related topics
Almost all results in this chapter are based on the integral expression (6.3).
This formula appeared in [54], from which the weak Young inequality ((1.6)
and (6.4)) was derived. This inequality was motivated by T. Ando’s work [3]
on the (operator) Young inequality (1.5). The special case p = q = 2 was
obtained earlier by R. Bhatia and F. Kittaneh ([12]). Note that (1.5) actually
implies
|||f(|H
1
p K
1
q |)||| ≤|||f( 1
pH + 1
q K)|||
for p, q > 1 with p−1 + q−1 = 1 and a continuous increasing function f on
[0, ∞) satisfying f(0) = 0.
We observed
H
1
p XK
1
q =
 ∞
−∞
Hix(HX)K−ix
sin(π/q)
2 (cosh(πx) −cos(π/q)) dx
+
 ∞
−∞
Hix(XK)K−ix
sin(π/q)
2 (cosh(πx) + cos(π/q)) dx
in [54, §2]. This is nothing but the Poisson integral formula (for the strip
0 ≤Im z ≤1) applied for f(z) = H−izXK1+iz, and the reason why the
Fourier transform of sin(ax)/ sin(x) is given as above was also explained in
[54, Appendix B]. This integral expression immediately yields (1.7). We point
out that (1.7) is actually equivalent to the following multiplicative version:
|||H
1
p XK
1
q ||| ≤|||HX|||1/p|||XK|||1/q.
Indeed, (1.7) comes from the multiplicative version together with the Young
inequality (for scalars). On the other hand, with tpH and K/tq (t > 0) instead

6.3 Notes and references
87
of H, K (1.7) gives us |||H
1
p XK
1
q ||| ≤tp
p |||HX|||+ t−q
q |||XK|||. The minimum
of the right side here is |||HX|||1/p|||XK|||1/q as desired. The multiplicative
version ﬁrst appeared in [11] by R. Bhatia and C. Davis (see also [64, Theorem
4, (iii)]). It can be further extended for example to
||| |H
1
p XK
1
q |r ||| ≤||| |HX|r|||1/p||| |XK|r|||1/q

≤1
p||| |HX|r||| + 1
q ||| |XK|r|||

with r > 0 (see [43, Theorem 3], [54, Theorem 3] for instance). An updated
survey on these H¨older-type norm inequalities can be found in [84, §4.4].

7
Binomial means Bα
The “binomial means” introduced in [39] are
Bα(s, t) =
sα + tα
2
1/α
(−∞≤α ≤∞).
For special values of α we have
B1 = A
(the arithmetic mean)
B0 = G
(the geometric mean)
B∞= M∞.
In fact, notice limα→0 Bα(s, t) = G(s, t) and limα→±∞Bα(s, t) = M±∞(s, t).
In this chapter we will prove that the binomial means are Schur multipliers,
and norm continuity (in parameter) will be also discussed.
7.1 Majorization B
  ⪯M
 For means M (= Mα, Aα) in the preceding chapters the majorization M ⪯
M∞(which ensures that M is a Schur multiplier) is relatively easy to establish.
We also have Bα ⪯M∞, however more involved arguments are needed.
In what follows we (mainly) assume α > 0 and α ̸= 1
n (n = 1, 2, . . .). It is
plain to see
Bα(ex, 1)
M∞(ex, 1) =
1 + e−α|x|
2
1/α
(7.1)
so that we have
Bα(ex, 1)
M∞(ex, 1) −2−1/α = 2−1/α

1 + e−α|x|1/α
−1

.
We set
F. Hiai and H. Kosaki: LNM 1820, pp. 89–104, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

90
7 Binomial means Bα
φα(x) =

1 + e−α|x|1/α
−1 =

1 + e−α|x|β
−1
(7.2)
with β = 1/α ∈R+ \ N.
We consider the power series expansion of the analytic function
fβ(z) = (1 −z)β.
The radius of convergence here is obviously 1, and the n-th coeﬃcient is given
by
an = (−1)n
n!
× β(β −1)(β −2) · · · (β −(n −1))
for n = 1, 2, . . . and a0 = 1.
The next lemma is an obvious extension of the one presented in [74, p. 195],
which will be repeatedly used.
Lemma 7.1. We have the absolute convergence
∞

n=0
|an| < ∞.
Proof. From the above expression we observe that an’s are either all negative
or all positive (depending upon the parity of n0) for each n ≥n0 = [β] + 1.
We ﬁrst assume an < 0 for n ≥n0. For a real t with 0 < t < 1 we have
(1 −t)β −
n0−1

n=0
antn =
N

n=n0
antn +
∞

n=N+1
antn ≤
N

n=n0
antn
for N large enough. Therefore, we have
N

n=n0
|an| = −
N

n=n0
an = −lim
t↗1
N

n=n0
antn
≤lim
t↗1
n0−1

n=0
antn −(1 −t)β

=
n0−1

n=0
an.
By letting N →∞, we see
∞

n=n0
|an| ≤
n0−1

n=0
an.
We next assume an > 0 for n ≥n0 so that we have the reversed inequality
(1 −t)β −
n0−1

n=0
antn ≥
N

n=n0
antn
for 0 < t < 1. In this case we estimate

7.1 Majorization Bα ⪯M∞
91
N

n=n0
|an| =
N

n=n0
an = lim
t↗1
N

n=n0
antn
≤lim
t↗1

(1 −t)β −
n0−1

n=0
antn

= −
n0−1

n=0
an,
and hence
∞

n=n0
|an| ≤−
n0−1

n=0
an
by letting N →∞again.
⊓⊔
By substituting z = −e−α|x| ∈[−1, 0) to fβ(z) and then subtracting 1, we
have
φα(x) =
∞

n=0
an(−e−α|x|)n −1 =
∞

n=1
(−1)nane−nα|x| =
∞

n=1
bne−nα|x|
(see (7.2)) with
bn = (−1)nan = 1
n! × β(β −1)(β −2) · · · (β −(n −1))
for n ≥1. Note bn > 0 up to n = n0 and then the signs of bn’s oscillates
(i.e., bn0+1, bn0+3, · · · < 0). The above expression of φα(t) is absolutely con-
vergent thanks to Lemma 7.1, which guarantees the validity of the following
re-grouping of terms:
φα(x) = φα,+(x) −φα,−(x)
with

















φα,+(x) =

bn>0
bne−nα|x| =
n0−1

n=1
bne−nα|x| +
∞

n=0
bn0+2ne−(n0+2n)α|x|,
φα,−(x) =

bn<0
(−bn)e−nα|x| =
∞

n=0
(−bn0+2n+1)e−(n0+2n+1)α|x|
(with the convention
n0−1

n=1
= 0 in the case n0 = 1).
Theorem 7.2. For each α ∈[−∞, ∞] we have Bα ⪯M∞.
Proof. Recall B±∞= M±∞and B0 = G = M1/2 (the geometric mean),
for which the result is known (Theorem 5.1). For α = 1/n we obviously

92
7 Binomial means Bα
have Bα ⪯M∞because the binomial expansion is available. We also recall
M1/2 ⪯B−α for α < 0 ([39, Proposition 3.3]) so that we observe
Bα = B(−)
−α ⪯M (−)
1/2 = M1/2 ⪯M∞
(see (3.18)). Therefore, in the rest of the proof we may and do assume α > 0
and α ̸= 1
n (n = 1, 2, · · ·), and it suﬃces to see that the function φα(t) (see
(7.2)) is positive deﬁnite.
Recall that the Fourier transform of e−a|x| (with a > 0) is 2a(x2 + a2)−1:
 ∞
−∞
e−a|y|eixydy = 2π × a
π ×
1
x2 + a2 =
2a
x2 + a2
(7.3)
(thanks to (5.8) or by elementary direct computations). Lemma 7.1 and the
obvious estimate e−nα|x| ≤e−α|x| enable us to perform term-wise Fourier
transform for the above φα,±(x) (thanks to the dominated convergence theo-
rem), and we get















ˆφα,+(x) =
n0−1

n=1
bn
2nα
x2 + (nα)2 +
∞

n=0
bn0+2n
2(n0 + 2n)α
x2 + (n0 + 2n)2α2 ,
ˆφα,−(x) =
∞

n=0
(−bn0+2n+1)
2(n0 + 2n + 1) α
x2 + (n0 + 2n + 1)2α2
due to (7.3). To establish the positivity of ˆφα(x) = ˆφα,+(x) −ˆφα,−(x) (i.e.,
the positive deﬁniteness of φα), we will make use of the expression
ˆφα(x) −2
n0−1

n=1
bn
nα
x2 + (nα)2
= 2
∞

n=0

bn0+2n
(n0 + 2n)α
x2 + (n0 + 2n)2α2
−(−bn0+2n+1)
(n0 + 2n + 1)α
x2 + (n0 + 2n + 1)2α2

.
Indeed, because of
nα
x2+n2α2 ≤
1
nα ≤1
α and Lemma 7.1, the above sums for
ˆφα,±(x) are once again absolutely convergent so that re-grouping terms is
certainly legitimate. We note
−bn0+2n+1
bn0+2n
= −(β −(n0 + 2n))
n0 + 2n + 1
= n0 + 2n −β
n0 + 2n + 1 =
2n + γ
n0 + 2n + 1
with γ = n0 −β = [β] + 1 −β ∈(0, 1). Therefore, we can rewrite the above
quantity as follows:

7.2 Equivalence of |||Bα(H, K)X||| for α > 0
93
ˆφα(x) −2
n0−1

n=1
bn
nα
x2 + (nα)2
= 2
∞

n=0
bn0+2n

(n0 + 2n)α
x2 + (n0 + 2n)2α2
−
2n + γ
n0 + 2n + 1 ×
(n0 + 2n + 1)α
x2 + (n0 + 2n + 1)2α2

= 2
∞

n=0
αbn0+2n

n0 + 2n
x2 + (n0 + 2n)2α2 −
2n + γ
x2 + (n0 + 2n + 1)2α2

.
Hence, it suﬃces to check that the diﬀerence appearing in the above last
parenthesis is positive. However, by elementary computation this quantity is
equal to
(n0 −γ)x2 + (n0 + 2n) (1 + (n0 + 2n)(n0 −γ + 2)) α2
(x2 + (n0 + 2n)2α2) (x2 + (n0 + 2n + 1)2α2)
.
It is certainly positive as desired because of n0 −γ = β = 1/α > 0.
⊓⊔
Proposition 3.3, (b) and Theorem 7.2 guarantee that Bα(s, t) is a Schur
multiplier for each α ∈[−∞, ∞] so that Bα(H, K)X (∈B(H)) makes sense
for each operators H, K, X with H, K ≥0, and moreover we have
|||Bα(H, K)X||| ≤|||M∞(H, K)X|||.
(7.4)
7.2 Equivalence of |||B
 (H, K)X||| for α > 0
In this section we investigate mutual comparison for |||Bα(H, K)X||| akin to
Propositions 5.2 and 5.4.
Proposition 7.3. For each α > 0 one can ﬁnd a positive constant κα such
that
|||Bα(H, K)X||| ≤|||M∞(H, K)X||| ≤κα|||Bα(H, K)X|||
for each operators H, K, X with H, K ≥0 and each unitarily invariant norm
||| · |||. In particular, the following three conditions are mutually equivalent :
(i)
|||Bα(H, K)X||| < ∞for some α > 0;
(ii)
|||M∞(H, K)X||| < ∞;
(iii) |||HX + XK||| < ∞.
Proof. The ﬁrst inequality was already pointed out (see (7.4)), and it remains
to show the second. To do so, we note

94
7 Binomial means Bα
M∞(ex, 1)
Bα(ex, 1) = max{ex, 1}
 1+eαx
2
1/α = 21/α max{ex, 1}
(1 + eαx)1/α
= 21/α

1
1 + e−α|x|
1/α
= 21/α

e
α|x|
2
e
α|x|
2
+ e−α|x|
2
1/α
= 21/α

1 −
e−α|x|
2
e
α|x|
2
+ e−α|x|
2
1/α
= 21/α

1 −
e−α|x|
2
2 cosh
 αx
2

1/α
.
(7.5)
Recalling the Taylor series expansion of (1 −z)1/α (see Lemma 7.1 and the
paragraph before the lemma), we have
M∞(ex, 1)
Bα(ex, 1) = 21/α
∞

n=0
an
2n ×
e−nα|x|
2
coshn αx
2

with the absolutely convergent coeﬃcients ∞
n=0 2−n|an| < ∞(and a0 = 1).
For each n ≥1 both of the functions e−nα|x|
2
and 1/ coshn αx
2

are posi-
tive deﬁnite (see (5.8), (7.3) and Example 3.6, (a)) and hence their product
e−nα|x|
2
/ coshn αx
2

is the Fourier transform of a positive integrable function
fn(x) with
	 ∞
−∞fn(x) dx = 1. In particular, by considering the sums over n’s
with an > 0 and an < 0 separately, we observe that M∞(ex, 1)/Bα(ex, 1)
is the Fourier transform of a signed measure ν with ﬁnite total variation.
Therefore, we have
M∞(H, K)X =

 ∞
−∞
(HsH)ix(Bα(H, K)X)(KsK)−ixdν(x),
and consequently the second inequality is valid with the constant κα = |ν|(R).
⊓⊔
From the above proof we obviously have κα = |ν|(R) ≤21/α ∞
n=0 2−n|an|.
But this quantity diverges as α ↘0. On the other hand, for α > 1 one can
obtain a somewhat more precise estimate. To do so, we at ﬁrst point out
Lemma 7.4. If α > 1 and f(x) is a positive deﬁnite function satisfying 0 ≤
f(x) ≤1, then so is
g(x) = 1 −(1 −f(x))1/α.
Proof. As was seen in the proof of Lemma 7.1, the Taylor series expansion
(1 −z)1/α =
∞

k=0
anzn
(with ∞
n=0 |an| < ∞) satisﬁes an < 0 for each n ≥1 (and a0 = 1) due to
0 < 1/α < 1. By substituting z = f(x) ∈[0, 1], we observe

7.2 Equivalence of |||Bα(H, K)X||| for α > 0
95
g(x) = 1 −(1 −f(x))1/α =
∞

n=1
(−an)f(x)n.
The desired conclusion is clear from this expression since all the powers of
f(x) are positive deﬁnite.
⊓⊔
For instance, with α = 2 and f(x) = 1/ cosh2(x), we see the positive
deﬁniteness of g(x) = 1 −| tanh(x)|.
Proposition 7.5. Let H, K be positive operators, X ∈B(H) and ||| · ||| be
any unitarily invariant norm. For α > 1 we have
|||Bα(H, K)X||| ≤|||M∞(H, K)X||| ≤(21+ 1
α −1) |||Bα(H, K)X|||
(7.6)
and
|||Bα(H, K)X −M∞(H, K)X||| ≤2(21/α −1) |||Bα(H, K)X|||.
(7.7)
Proof. With the special choice
f(x) =
e−α|x|
2
2 cosh
 αx
2

(see (7.5)) in Lemma 7.4 we observe that the function
g(x) = 1 −

1
1 + e−α|x|
1/α
is positive deﬁnite. Therefore, it is the Fourier transform of a positive measure
with total mass g(0) = 1 −2−1/α. We actually have
g(x) = 1 −2−1/α M∞(ex, 1)
Bα(ex, 1)
due to (7.5), and as usual we get
|||Bα(H, K)X −2−1/α M∞(H, K)X||| ≤(1 −2−1/α) |||Bα(H, K)X|||.
(7.8)
From this we estimate
|||M∞(H, K)X||| ≤|||M∞(H, K)X −21/αBα(H, K)X|||
+21/α|||Bα(H, K)X|||
≤(21/α −1) |||Bα(H, K)X||| + 21/α|||Bα(H, K)X|||
= (21+ 1
α −1) |||Bα(H, K)X|||,
which (together with (7.4)) shows (7.6). On the other hand, (7.7) is shown
from (7.8) as follows:
|||M∞(H, K)X −Bα(H, K)X|||
≤|||M∞(H, K)X −21/αBα(H, K)X||| + (21/α −1) |||Bα(H, K)X|||
≤2(21/α −1) |||Bα(H, K)X|||.
⊓⊔

96
7 Binomial means Bα
7.3 Norm continuity in parameter
Our goal in the section is to show the following norm continuity (and related
results):
Theorem 7.6. Let H, K, X ∈B(H) with H, K ≥0, and ||| · ||| be a unitarily
invariant norm. If |||M∞(H, K)X||| < ∞(see Proposition 7.3), then one gets
lim
α→α0 |||Bα(H, K)X −Bα0(H, K)X||| = 0
for each α0 ∈[0, ∞].
Proposition 7.5 yields the case α0 = ∞in Theorem 7.6, and hence it
remains to show the case α0 ∈[0, ∞). The proof for the case α0 ∈(0, ∞) is
not so hard while we will make use of a certain uniform integrability (as in
the Vitali convergence theorem) to deal with the case α0 = 0 (see (7.11)).
For α > 0 the proof of Theorem 7.2 shows that
ˆψα(x) = Bα(ex, 1)
M∞(ex, 1) −2−1/α = 2−1/α

1 + e−α|x|1/α
−1


= 2−1/α φα(x)
(see (7.2))

with a positive integrable function ψα(x). For the limiting case α = 0 we have
ˆψ0(x) = B0(ex, 1)
M∞(ex, 1) = e−|x|/2 
= lim
α↘0
ˆψα(x)

with ψ0(x) =
1
2π

x2 + 1
4
−1 (see (5.8) and (7.3)). At ﬁrst we compute
∂
∂α

1 + e−α|x|1/α
= −

1 + e−α|x|1/α

|x|e−α|x|
α(1 + e−α|x|) + log

1 + e−α|x|
α2

< 0,
and hence
Lemma 7.7. The function φα(x) is monotone decreasing in α > 0.
The assertion (ii) of the next lemma will be proved after we prepare a few
lemmas.
Lemma 7.8.
(i)
lim
α→α0 ∥ˆψα −ˆψα0∥2 = 0 for α0 > 0,
(ii)
lim
α↘0 ∥ˆψα −ˆψ0∥2 = 0.

7.3 Norm continuity in parameter
97
We at ﬁrst assume α0 > 0 and choose a positive integer n0 with
1
n0 < α0.
For α ≥
1
n0 , thanks to Lemma 7.7 we observe
ˆψα(x) = 2−1/α φα(x) ≤φα(x) ≤φ 1
n0 (x).
Notice
φ 1
n0 (x) =

1 + e−|x|
n0
n0
−1 =
n0

k=1
n0
k

e−k
n0 |x|
≤(2n0 −1)e−|x|
n0 ∈L2(R).
When α →α0 (with α ≥
1
n0 ), we obviously have ˆψα(x) →ˆψα0(x) for each x ∈
R so that (i) in Lemma 7.8 follows from the Lebesgue dominated convergence
theorem.
We next deal with the case α0 = 0 (i.e., Lemma 7.8, (ii)). We begin with
the special case
lim
n→∞∥ˆψ 1
n −ˆψ0∥2 = 0.
Since all the relevant functions here are even, what we really have to show is
lim
n→∞
 ∞
0
|fn(t) −f∞(t)|2dt = 0
(7.9)
where
fn(t) = 2−n 
1 + e−t
n
n
−1

and
f∞(t) = e−t/2
(t ≥0).
To show (7.9) we use the binomial expansion
fn(t) = 2−n
n

k=1
n
k

e−k
n t.
Choose and ﬁx δ > 0 small, and we split the sum n
k=1 into the following two
parts:
  ′ : summation over k ∈{1, 2, . . ., n} with k
n > δ,
 ′′ : summation over k ∈{1, 2, . . ., n} with k
n ≤δ.
We observe
fn(t) ≤2−n  ′
n
k

e−δt + 2−n  ′′
n
k

e−k
n t
≤e−δt + 2−n  ′′
n
k

e−k
n t.
By making use of the obvious fact 0 ≤fn(t) ≤1, from the above inequality
we estimate

98
7 Binomial means Bα
 ∞
M
fn(t)2dt ≤
 ∞
M
fn(t) dt ≤
 ∞
M
e−δtdt + 2−n  ′′
n
k
  ∞
M
e−k
n tdt
= 1
δ e−δM + 2−n  ′′
n
k
n
k e−k
n M
≤1
δ e−δM + 2−n  ′′
n
k
n
k
(7.10)
for M > 0 (to be speciﬁed shortly). Note that the second factor (containing
binomial coeﬃcients) in the above far right side is no longer depending upon
M.
Lemma 7.9. When δ > 0 is small enough, we have
lim
n→∞2−n  ′′
n
k
n
k = 0.
Proof. Based on the Stirling formula we estimate
log

2−n
n
k
n
k

= −n log 2 + log(n!) −log(k!) −log((n −k)!) + log n −log k
= −n log 2 + n log n −n + 1
2 log n
−k log k + k −1
2 log k −(n −k) log(n −k) + (n −k) −1
2 log(n −k)
+ log n −log k + O(1)
≤−n log 2 −k log
k
n

−(n −k) log
n −k
n

+ 3
2 log n + O(1)
= −n

log 2 + k
n log
 k
n

+

1 −k
n

log

1 −k
n

+ 3
2 log n + O(1).
We set θ(x) = x log x, and notice θ(0) = θ(1) = 0 and θ(x) < 0 for x ∈(0, 1).
Choose and ﬁx 0 < ε0 < log 2, and assume that δ > 0 is chosen small enough
in such a way that
θ(x) + θ(1 −x) ≥−ε0
for 0 < x ≤δ
is guaranteed. Then, since k
n ≤δ for k’s appearing in the sum  ′′, we get
log 2 + k
n log
k
n

+

1 −k
n

log

1 −k
n

≥log 2 −ε0.
Thus, from the preceding estimate we get
log

2−n
n
k
n
k

≤−n(log 2 −ε0) + 3
2 log n + O(1),

7.3 Norm continuity in parameter
99
that is,
2−n
n
k
n
k ≤K × n3/2
eε0
2
n
(as long as k
n ≤δ)
for some constant K. Therefore, we conclude
1
2n
 ′′
n
k
n
k ≤K × n5/2
eε0
2
n
,
showing the desired convergence due to eε0
2 < 1.
⊓⊔
Lemma 7.10. The L2-convergence (7.9) is valid, that is, we have
lim
n→∞∥ˆψ 1
n −ˆψ0∥2 = 0.
Proof. Let ε > 0. We claim the following uniform integrability: one can ﬁnd
an integer N and a positive M such that
 ∞
M
fn(t)2dt < ε
for each n ≥N.
(7.11)
In fact, we recall the estimate (7.10), and ﬁx a small δ > 0 so that Lemma 7.9
is valid. From this lemma, we have 2−n  ′′n
k
 n
k < ε/2 for n large enough.
Then, one can choose M > 0 large enough so that 1
δ e−δM < ε/2.
We estimate
 ∞
0
|fn(t) −f∞(t)|2dt
≤
 M
0
|fn(t) −f∞(t)|2dt +
 ∞
M
(fn(t) + f∞(t))2dt
≤
 M
0
|fn(t) −f∞(t)|2dt + 2
 ∞
M
fn(t)2dt + 2
 ∞
M
f∞(t)2dt.
Fatou’s lemma shows
 ∞
M
f∞(t)2dt ≤lim inf
n→∞
 ∞
M
fn(t)2dt.
Thus, from the estimates so far and (7.11) we get
 ∞
0
|fn(t) −f∞(t)|2dt ≤
 M
0
|fn(t) −f∞(t)|2dt + 4ε
for n large enough, and hence
lim sup
n→∞
 ∞
0
|fn(t) −f∞(t)|2dt ≤lim sup
n→∞
 M
0
|fn(t) −f∞(t)|2dt + 4ε.
Note that lim sup in the right-hand side is 0 since fn(t) ≤1 enables us to use
the Lebesgue dominated convergence theorem on the ﬁnite interval [0, M].
Since ε > 0 is arbitrary, we are done.
⊓⊔

100
7 Binomial means Bα
Proof of Lemma 7.8, (ii). What we have to show is limk→∞∥ˆψαk −ˆψ0∥2 = 0
for each decreasing sequence {αk}k=1,2,··· converging to 0. For each k one takes
the natural number nk such that nk −1 < 1/αk ≤nk so that {nk}k=1,2,···
is an increasing sequence tending to ∞. Notice 2−nk ≤2−1/αk < 2 × 2−nk.
Hence, from Lemma 7.7 we have
ˆψαk(x) ≤2 × 2−nk

1 + e−αk|x|1/αk −1

≤2 × 2−nk

1 + e−|x|
nk
nk
−1

= 2 × ˆψ 1
nk (x).
Therefore, the Lp-version of the extended Lebesgue convergence theorem (see
[25, p. 122] or [26, Theorem 3.6]) and Lemma 7.10 yield limk→∞∥ˆψαk −ˆψ0∥2 =
0 as desired.
⊓⊔
Proof of Theorem 7.6. As was pointed out right after the theorem, we may
and do assume α0 ∈[0, ∞). Lemmas 5.8 and 7.8 yield
lim
α→α0 ∥ψα −ψα0∥1 = 0 (α0 > 0)
and
lim
α↘0 ∥ψα −ψ0∥1 = 0.
Thus, from the integral expressions
Bα(H, K)X = 2−1/αM∞(H, K)X
+
 ∞
−∞
(HsH)ix(M∞(H, K)X)(KsK)−ixψα(x) dx,
B0(H, K)X =
 ∞
−∞
(HsH)ix(M∞(H, K)X)(KsK)−ixψ0(x) dx,
we get
lim
α→α0 |||Bα(H, K)X −Bα0(H, K)X||| = 0
and
lim
α↘0 |||Bα(H, K)X −B0(H, K)X||| = 0.
It remains to show
lim
α↗0 |||Bα(H, K)X −B0(H, K)X||| = 0.
Thus, we assume α < 0 and set
ϕα(x) = Bα(ex, 1)
M∞(ex, 1) =
1 + e−α|x|
2
1/α
(see (7.1))
= e−|x|/2 cosh1/α
α|x|
2

= e−|x|/2

1
cosh
 (−α)x
2

	
1
−α
,
ϕ0(x) = B0(ex, 1)
M∞(ex, 1) = e−|x|/2.

7.3 Norm continuity in parameter
101
Then, ϕα is a positive deﬁnite function and ϕα = ˆψα (α ≤0) with a positive
integrable function ψα (see (5.8) and the proof of [39, Proposition 3.3], and also
see §A.6). Since ϕα(x) ≤ϕ0(x) = e−|x|/2 ∈L2(R) and limα↗0 ϕα(x) = ϕ0(x),
we have limα↗0 ∥φα −φ0∥2 = 0 by the Lebesgue dominated convergence
theorem. Since
 ∞
−∞
ψα(x) dx = ϕα(0) = 1
(α ≤0),
Lemma 5.8 shows
lim
α↗0 ∥ψα −ψ0∥1 = 0
and the desired convergence follows from the integral expression
Bα(H, K)X =
 ∞
−∞
(HsH)ix(M∞(H, K)X)(KsK)−ixψα(x) dx
(α ≤0).
⊓⊔
Recall B0(H, K)X = G(H, K)X = H1/2XK1/2, the geometric mean. For
operator means Bα(H, K)X with α < 0 we have
Proposition 7.11. If |||H1/2XK1/2||| < ∞, then
lim
α→α0 |||Bα(H, K)X −Bα0(H, K)X||| = 0
for every α0 ∈[−∞, 0).
Proof. We set
ϕα(x) = Bα(ex, 1)
G(ex, 1) = e−x/2
eαx + 1
2
1/α
= cosh1/α αx
2

=

1
cosh
 (−α)x
2

	
1
−α
for α < 0. Then, ϕα is a positive deﬁnite function and ϕα = ˆψα with a positive
function ψα ∈L1(R) (see the proof of [39, Proposition 3.3] or §A.6). Note that
ϕα(x) is monotone increasing in α because so is Bα(ex, 1) as noted just after
(7.4).
Let us assume α0 ̸= −∞. When |α −α0| ≤−α0
2 , we have α ≤α0
2 and
consequently 0 ≤ϕα(x) ≤ϕ α0
2 (x) with ϕ α0
2
∈L1(R). Of course we have
limα→α0 ϕα(x) = ϕα0(x), and the Lebesgue dominated convergence theorem
implies
lim
α→α0 ∥ϕα −ϕα0∥1 = 0.
Hence, for each sequence {αk}k=1,2,··· converging to α0 we get

102
7 Binomial means Bα
|ψαk(x) −ψα0(x)|
≤1
2π

 ∞
−∞
(ϕαk(y) −ϕα0(y))eixydy
 ≤1
2π × ∥ϕαk −ϕα0∥1 −→0
for a.e. x ∈R. Since
 ∞
−∞
ψα(x) dx = ϕα(0) = 1
for each α < 0,
we have
lim
α→α0 ∥ψα −ψα0∥1 = 0
as usual, and the required convergence can be seen from the integral expression
Bα(H, K)X =
 ∞
−∞
(HsH)ix(H1/2XK1/2)(KsK)−ixψα(x) dx.
Obviously the same proof works for α0 = −∞as well with ϕ−∞(x) = e−|x|/2
and ψ−∞(x) =
1
2π

x2 + 1
4
−1 (see (5.8) and (7.3)), and details are left to the
reader.
⊓⊔
Alternative proof of Proposition 7.11. As in the above proof we set
ϕα(x) =

1
cosh
 (−α)x
2


1
−α
(α < 0)
and
ϕ−∞(x) = e−|x|/2.
Then, ϕα is a positive deﬁnite function. In fact, we have ϕα = ˆψα with the
function
ψα(x) = 1
2π ×
2
1
−α
(−α)Γ
 1
−α
 ×
Γ

1
2(−α) + ix
−α

2
≥0.
Details are worked out in §A.6 (see (A.10)), and this explicit form was pointed
out in [13].
The obvious continuity of the Γ-function Γ(z) shows
lim
α→α0 ψα(x) = ψα0(x)
(7.12)
for α0 < 0. This fact remains valid for α0 = −∞as well. In fact, thanks to
Γ(z + 1) = zΓ(z) we compute
lim
α→−∞ψα(x) = 1
2π lim
β↘0

2ββ
Γ(β) ×
Γ
β
2 + ixβ

2
= 1
2π lim
β↘0

2ββ2
Γ(β + 1) ×
Γ
β
2 + ixβ

2
= 1
2π lim
β↘0 β2
Γ
β
2 + ixβ

2
.

7.4 Notes and references
103
Recall that 0, −1, −2, −3, . . . are simple poles of Γ(z) (see [80] for example).
The residue at 0 is 1 so that near the origin Γ(z) is of the form 1
z + f(z) with
a holomorphic function f(z). This means Γ
 β
2 + ixβ

∼
 β
2 + ixβ
−1 for β
small, and we conclude
lim
α→−∞ψα(x) = 1
2π lim
β↘0
β2
 β
2 + ixβ
2 = 1
2π ×
1
 1
2 + ix
2 = 1
2π ×
1
x2 + 1
4
.
This limit function is exactly ψ−∞(x) (see (5.8) and (7.3)), and hence (7.12)
has been checked for α0 = −∞.
We have
 ∞
−∞
ψα(x) dx = ϕα(0) = 1
for each α ∈[−∞, 0).
Hence, (7.12) and the extended Lebesgue dominated convergence theorem
yield
lim
α→α0 ∥ψα −ψα0∥1 = 0,
and as usual the required convergence can be seen from the integral expression
Bα(H, K)X =
 ∞
−∞
(HsH)ix(H1/2XK1/2)(KsK)−ixψα(x) dx.
⊓⊔
From Theorem 7.6 and Proposition 7.11 we get
Corollary 7.12. For each H, K, X ∈B(H) with H, K ≥0 and each −∞≤
α0 ≤∞we always have
lim
α→α0 ∥Bα(H, K)X −Bα0(H, K)X∥= 0
in the operator norm ∥· ∥.
7.4 Notes and references
The binomial means {Bα}−∞≤α≤∞and the corresponding means Bα(H, K)X
were studied in [39]. Only matrices were dealt with there so that the majoriza-
tion Bα ⪯M∞(Theorem7.2) was not necessary. This majorization (together
with Proposition 3.3, (b)) makes the notion of operator means Bα(H, K)X
legitimate for Hilbert space operators.
We note that Bα(s, t) is monotone increasing in α ∈[−∞, ∞] for each
ﬁxed s, t > 0. Indeed, when 0 < α < β, the concavity of the function tα/β
(t > 0) gives
sα + tα
2
≤
sβ + tβ
2
α/β
,

104
7 Binomial means Bα
i.e., Bα(s, t) ≤Bβ(s, t). The case α < β < 0 is similarly checked. However, the
comparison Bα ⪯Bβ (similar to (5.2) and (6.2)) for general −∞≤α < β ≤
∞is an interesting open problem. The following partial results were obtained
in [39, Proposition 3.3]:
(i) for α ≥0 we have B0 (= M1/2) ⪯Bα

⪯B∞(= M∞)

;
(ii) we have B 1
m ⪯B 1
n as long as n (∈N) divides m.

8
Certain alternating sums of operators
In this chapter we will deal with alternating sums
H
1
2 XK
1
2
H
1
3 XK
2
3 −H
2
3 XK
1
3
H
1
4 XK
3
4 −H
2
4 XK
2
4 + H
3
4 XK
1
4
H
1
5 XK
4
5 −H
2
5 XK
3
5 + H
3
5 XK
2
5 −H
4
5 XK
1
5
· · ·
XK −HX
XK −H
1
2 XK
1
2 + HX
XK −H
1
3 XK
2
3 + H
2
3 XK
1
3 −HX
XK −H
1
4 XK
3
4 + H
2
4 XK
2
4 −H
3
4 XK
1
4 + HX
· · · ,
and investigate behavior of unitarily invariant norms of these operators such
as mutual comparison, uniform bounds (independent of n, m), monotonicity
and so on (in §8.2 and §8.3). For convenience we set
A(n) =
n

k=1
(−1)k−1H
k
n+1 XK
n+1−k
n+1
(n = 1, 2, 3, · · ·),
B(m) =
m−1

k=0
(−1)kH
k
m−1 XK
m−1−k
m−1
(m = 2, 3, 4, · · ·),
and these notations will be kept throughout. We note
B(m) =
HX + XK −A(m −2)
for m = 3, 5, 7, · · ·,
−HX + XK −A(m −2)
for m = 4, 6, 8, · · ·.
(8.1)
The nature of the above two series of operators depends strongly on parities
of n and m, and it is quite obvious that we will have to treat odd and even
cases separately.
F. Hiai and H. Kosaki: LNM 1820, pp. 105–121, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

106
8 Certain alternating sums of operators
8.1 Preliminaries
For n = 1, 2, · · · and m = 2, 3, · · · we set
an(s, t) =
n

k=1
(−1)k−1s
k
n+1 t
n+1−k
n+1
and
bm(s, t) =
m−1

k=0
(−1)ks
k
m−1 t
m−1−k
m−1
(s, t ≥0) as scalar “means” corresponding to A(n) and B(m). For s, t > 0 we
compute
an(s, t) =
s
1
n+1 t
n
n+1

1 −(−1)n  s
t

n
n+1 
1 +
 s
t

1
n+1
=
t
 s
t

1
n+1 
1 −(−1)n  s
t

n
n+1 
1 +
 s
t

1
n+1
= t
s
t
 1
2 ×
 s
t
−1
2 ×
n
n+1 −(−1)n  s
t
 1
2 ×
n
n+1
 s
t
−1
2 ×
1
n+1 +
 s
t
 1
2 ×
1
n+1
= (st)
1
2 ×
 s
t
−1
2 ×
n
n+1 −(−1)n  s
t
 1
2 ×
n
n+1
 s
t
−1
2 ×
1
n+1 +
 s
t
 1
2 ×
1
n+1
.
Note that the denominator can be always expressed in terms of the hyperbolic
cosine function while for the numerator the hyperbolic sine function is also
needed for n even. Exactly the same computations yield
bm(s, t) = (st)
1
2 ×
 s
t
−1
2 ×
m
m−1 −(−1)m  s
t
 1
2 ×
m
m−1
 s
t
−1
2 ×
1
m−1 +
 s
t
 1
2 ×
1
m−1
.
These formulas will be freely and repeatedly used. We note the homogeneity
an(rs, rt) = ran(s, t),
bm(rs, rt) = rbm(s, t)
(with r ≥0) and
an(t, s) = (−1)n+1an(s, t),
bm(t, s) = (−1)m+1bm(s, t)
(see Proposition 8.2, (iii)).
We will repeatedly make use of the positive deﬁniteness of the following
functions (see §6.3, 1):
1
cosh(αx),
cosh(βx)
cosh(αx),
sinh(βx)
sinh(αx)
with 0 < β < α (as was done in preceding chapters). The next observation is
also useful.

8.1 Preliminaries
107
Lemma 8.1. For α, β > 0 one can ﬁnd a signed measure ν on R such that
cosh((α + β)x)
cosh(αx) cosh(βx) = ˆν(x)

=
 ∞
−∞
eixydν(y)

with |ν|(R) ≤5.
Proof. By the addition rule for the hyperbolic cosine function we observe
cosh((α + β)x)
cosh(αx) cosh(βx) = 1 + sinh(αx) sinh(βx)
cosh(αx) cosh(βx)
= 1 + | tanh(αx)| × | tanh(βx)|.
We set
p(x) = 1 −| tanh(αx)|,
q(x) = 1 −| tanh(βx)|.
As was shown in Lemma 7.4 (see the paragraph right after the lemma), they
are positive deﬁnite and we observe
cosh((α + β)x)
cosh(αx) cosh(βx) = 1 + (1 −p(x))(1 −q(x))
= (2 + p(x)q(x)) −(p(x) + q(x)).
Note that both of 2 + p(x)q(x) and p(x) + q(x) are positive deﬁnite with
2 + p(0)q(0) = 3
and
p(0) + q(0) = 2.
By the Bochner theorem there exist positive measures ν1, ν2 with the Fourier
transforms 2 + p(x)q(x), p(x) + q(x) respectively and ν1(R) = 3, ν2(R) = 2.
Hence, the diﬀerence measure ν = ν1 −ν2 does the job.
⊓⊔
Let M(s, t), N(s, t) be continuous functions on [0, ∞) × [0, ∞) satisfying
the homogeneity condition
M(rs, rt) = rM(s, t)
and
N(rs, rt) = rN(s, t)
(for r ≥0),
from which we obviously have
 M(s, 0) = sM(1, 0), N(s, 0) = sN(1, 0),
M(0, t) = tM(0, 1), N(0, t) = tN(0, 1).
(8.2)
We further assume that M(s, t), N(s, t) are Schur multipliers (relative to any
pair (H, K)) in the sense explained in §2.1. This assumption is not harmful
at all because the proposition below will be applied for an’s and bm’s (which
are obviously Schur multipliers). The corresponding “operator means” will be
denoted by M(H, K)X, N(H, K)X as in Chapter 3.
Many integral expressions were obtained in Chapter 3 to establish norm in-
equalities. In particular, Theorem 3.4 deals with the symmetric homogeneous

108
8 Certain alternating sums of operators
means; the proof is still valid if M(s, t), N(s, t) are symmetric homogeneous
functions and ν is a signed measure such that M(ex, 1)/N(ex, 1) = ˆν(x). The
next proposition (as well as its proof) is a variant of this result in the non-
symmetric case. The part (iii) plays a fundamental role in the present chapter
while the part (ii) will be used in our forthcoming article [55].
Proposition 8.2. We assume that homogeneous Schur multipliers as above
satisfy
M(ex, 1)
N(ex, 1) = ˆν(x)
with a signed measure ν on R.
(i)
When H, K ≥0 are non-singular, we have
M(H, K)X =
 ∞
−∞
Hix(N(H, K)X)K−ixdν(x).
(ii)
When M(1, 0) = M(0, 1) = 0, we have
M(H, K)X =
 ∞
−∞
(HsH)ix(N(H, K)X)(KsK)−ixdν(x).
(iii) When M(s, t) = −M(t, s) and N(s, t) = −N(t, s), we have
M(H, K)X =

{x̸=0}
(HsH)ix(N(H, K)X)(KsK)−ixdν(x)
+ν({0})N(H, K)X.
Proof. The assertions (i), (ii) directly follow from Proposition 2.11, and it
remains to prove (iii). To do so, we ﬁrstly note
M(s, t)
N(s, t) = M(t, s)
N(t, s)
(8.3)
by the assumption in (iii). Secondly, Lemma 2.9 and (8.2) show
N(H, K)X = sH(N(H, K)X)sK
+N(1, 0)HX(1 −sK) + N(0, 1)(1 −sH)XK
(8.4)
(which is a replacement of (3.10) in the proof of Theorem 3.4).
We claim
M(1, 0) = ν({0})N(1, 0)
and
M(0, 1) = ν({0})N(0, 1).
(8.5)
To see the claim, we begin by noting

8.1 Preliminaries
109
M(s, t) = tM(s/t, 1) = tN(s/t, 1)
 ∞
−∞
eix(log s−log t)dν(x)
= N(s, t)
 ∞
−∞
(s/t)ixdν(x)
(for s, t > 0)
(thanks to the assumption and the homogeneity). Thus, by the obvious con-
tinuity we get
|M(1, 0)| ≤|ν|(R) × |N(1, 0)|.
(8.6)
Firstly, if N(1, 0) = 0 (or equivalently N(0, 1) = 0), then we get M(1, 0) =
M(0, 1) = 0 by (8.6) and (8.5) is certainly valid. Secondly, let us assume
N(1, 0) ̸= 0. Since ν is a symmetric measure (by (8.3)), we have
lim
x→±∞ˆν(x) = lim
x→∞
M(ex, 1)
N(ex, 1) = lim
x→∞
M(1, e−x)
N(1, e−x) = M(1, 0)
N(1, 0) .
Therefore, the claim (i.e., (8.5)) follows from Corollary A.8 thanks to
lim
x→±∞ˆν(x) = M(1, 0)
N(1, 0) = M(0, 1)
N(0, 1) .
From Proposition 2.11 together with (8.5) we see
M(H, K)X =
 ∞
−∞
(HsH)ix(N(H, K)X)(KsK)−ixdν(x)
+ν({0})

sH(N(H, K)X)(1 −sK) + (1 −sH)(N(H, K)X)sK

.
Therefore, with (8.4) we compute
M(H, K)X
=
 ∞
−∞
(HsH)ix(N(H, K)X)(KsK)−ixdν(x)
+ν({0})

N(1, 0)HX(1 −sK) + N(0, 1)(1 −sH)XK

=

{x̸=0}
(HsH)ix(N(H, K)X)(KsK)−ixdν(x)
+ν({0})

sH(N(H, K)X)sK
+N(1, 0)HX(1 −sK) + N(0, 1)(1 −sH)XK

=

{x̸=0}
(HsH)ix(N(H, K)X)(KsK)−ixdν(x) + ν({0})N(H, K)X,
showing (iii).
⊓⊔

110
8 Certain alternating sums of operators
The integral expressions in the proposition yield
|||M(H, K)X||| ≤|ν|(R) × |||N(H, K)X|||
for each unitarily invariant norm |||·||| (when one of the conditions (i), (ii), (iii)
is satisﬁed). In fact, it follows from the Hahn decomposition ν = ν+ −ν−and
Theorem A.5. In the next two sections we will deal with signed measures ν
satisfying M(e2x, 1)/N(e2x, 1) = ˆν(x) instead. This means that our integral
expression is actually of the form
M(H, K)X =

{x̸=0}
(HsH)
ix
2 (N(H, K)X)(KsK)−ix
2 dν(x)
+ν({0})N(H, K)X
(for example in case (iii)), and hence we have the same estimate as above.
8.2 Uniform bounds for norms
In this section we investigate uniform (upper and lower) bounds for |||A(n)|||’s
and |||B(m)|||’s. We begin with comparison between |||A(n)||| and |||B(m)|||.
As was remarked before, odd and even cases have to be studied separately.
Theorem 8.3.
(i)
For n = 1, 3, 5, · · · and m = 3, 5, 7, · · · we have
|||A(n)||| ≤|||B(m)|||.
(ii) For n = 2, 4, 6, · · · and m = 2, 4, 6, · · · we have
n + 1
n
× |||A(n)||| ≤m −1
m
× |||B(m)|||.
Proof. We set
α =
1
n + 1
and
β =
1
m −1.
(i) We compute
an(e2x, 1)
bm(e2x, 1) =
cosh

n
n+1x

cosh

1
n+1x
 ×
cosh

1
m−1x

cosh

m
m−1x

= cosh((1 −α)x)
cosh(αx)
×
cosh(βx)
cosh((β + 1)x)
= cosh((1 −α + β)x) + cosh((1 −α −β)x)
2 cosh(αx) cosh((β + 1)x)
.

8.2 Uniform bounds for norms
111
We note
1 −α + β =
nm + 1
(n + 1)(m −1) > 0
and
1 −α −β = n(m −2) −1
(n + 1)(m −1) ≥0
thanks to n ≥1 and m ≥3. Since they are majorized by
β + 1 =
m
m −1 =
m(n + 1)
(n + 1)(m −1),
the ratio an(e2x, 1)/bm(e2x, 1) (whose value at x = 0 is 1) is positive deﬁnite.
(ii) In this case, we compute
an(e2x, 1)
bm(e2x, 1) = sinh((1 −α)x)
cosh(αx)
×
cosh(βx)
sinh((β + 1)x)
= sinh((1 −α + β)x) + sinh((1 −α −β)x)
2 cosh(αx) sinh((β + 1)x)
instead. When m ≥4 (i.e., m ̸= 2), as in (i) both of 1 −α ± β are positive
and majorized by β + 1 so that we have the positive deﬁniteness as above. If
m = 2, then 1 −α −β = −(n + 1)−1 < 0 so that the above argument does
not work. However, since β = 1 in this case, we have
an(e2x, 1)
b2(e2x, 1) = sinh((1 −α)x)
cosh(αx)
× cosh(x)
sinh(2x) =
sinh((1 −α)x)
2 cosh(αx) sinh(x),
which is also positive deﬁnite thanks to 0 < 1 −α =
n
n+1 < 1. Therefore, the
ratio an(e2x, 1)/bm(e2x, 1) is always positive deﬁnite, and we have
1 −α
β + 1 =
n
n + 1 × m −1
m
as the value at x = 0.
⊓⊔
The diﬀerence version of the Heinz inequality (see [36] and also §6.3, 1)
states
|||HθXK1−θ −H1−θXKθ|||
≤|2θ −1| × |||HX −XK|||
(for θ ∈[0, 1]).
(8.7)
Theorem 8.3, (ii) with n = m = 2 means
|||H
1
3 XK
2
3 −H
2
3 XK
1
3 ||| ≤1
3|||HX −XK|||,
which is exactly (8.7) for the special value θ = 1
3. More generally, the theorem
(with m = 2) states
|||A(2n)||| ≤
n
2n + 1 × |||HX −XK|||.

112
8 Certain alternating sums of operators
If one breaks the alternating sum A(2n) into pieces, then the repeated use of
(8.7) (together with the triangle inequality) gives us the constant
n

k=1
2 ×
k
2n + 1 −1
 =
n

k=1
2k −1
2n + 1 =
n2
2n + 1
so that the constant we obtained is far better.
In the next §8.3 we will see that both of
n →|||A(2n −1)|||
and
n →2n + 1
2n
× |||A(2n)|||
are monotone increasing (see Proposition 8.8) so that we have the following
uniform lower bounds:
|||H
1
2 XK
1
2 ||| = |||A(1)||| ≤|||A(2n −1)|||,
3n
2n + 1 × |||H
1
3 XK
2
3 −H
2
3 XK
1
3 ||| =
2n
2n + 1 × 3
2 × |||A(2)||| ≤|||A(2n)|||.
On the other hand, from Theorem 8.3 we have the upper bounds
|||A(2n −1)||| ≤|||B(3)||| = |||HX + XK −H
1
2 XK
1
2 |||,
|||A(2n)||| ≤|||B(2)||| = |||HX −XK|||,
that can be improved as is seen shortly (the remark below and Theorem 8.5).
Remark 8.4. The bound |||B(3)||| is comparable with |||HX + XK|||:
1
2|||HX + XK||| ≤|||HX + XK −H
1
2 XK
1
2 ||| ≤3
2|||HX + XK|||.
The arithmetic-geometric mean inequality (see (1.8)) actually shows the sec-
ond inequality, and the constant 3
2 can be removed for the Hilbert-Schmidt
norm |||·||| = ∥·∥2. Indeed, the ratio (2 cosh(x)−1)/2 cosh(x) is majorized by
1 (see [39, proposition 1.2]). But, since it is not positive deﬁnite, the constant
3
2 (for general unitarily invariant norms) seems optimal. On the other hand,
we estimate
|||HX + XK||| ≤|||HX + XK −H
1
2 XK
1
2 ||| + |||H
1
2 XK
1
2 |||
≤|||HX + XK −H
1
2 XK
1
2 ||| + 1
2|||HX + XK|||.
Thus, by subtracting 1
2|||HX + XK||| from the both sides, we get the ﬁrst
inequality.
We actually have

8.2 Uniform bounds for norms
113
Theorem 8.5.
(i)
For each n = 1, 2, 3, · · · we have
|||A(2n −1)||| ≤1
2|||HX + XK|||.
(ii) For each n = 1, 2, 3, · · · we have
|||A(2n)||| ≤
n
2n + 1 × |||HX −XK|||

≤1
2|||HX −XK|||

.
Proof. The arithmetic mean 1
2(HX +HK) corresponds to M2(s, t) = 1
2(s+t)
(see §5.1) and we have
a2n−1(e2x, 1)
M2(e2x, 1)
=
cosh
 2n−1
2n x

cosh(x) cosh
 1
2nx
.
On the other hand, we compute
a2n(s, t)
−s + t =
a2n(s, t)
(st)
1
2
 s
t
−1
2 −
 s
t
 1
2 
=
 s
t
−1
2 ×
2n
2n+1 −
 s
t
 1
2 ×
2n
2n+1
 s
t
−1
2 −
 s
t
 1
2   s
t
−1
2 ×
1
2n+1 +
 s
t
 1
2 ×
1
2n+1 .
Therefore, the corresponding function (i.e., s = e2x and t = 1) is
a2n(e2x, 1)
−e2x + 1 =
sinh

2n
2n+1x

2 sinh(x) cosh

1
2n+1x
.
The two functions are obviously positive deﬁnite so that we have the desired
inequalities. Notice that the coeﬃcient
n
2n+1 in (ii) appears as the value of the
second function at x = 0.
⊓⊔
Let us try to estimate |||A(2n −1)|||, |||A(2n)||| (from above and below)
in terms of the norms of the “leading terms”
H
1
2n XK
2n−1
2n
+ H
2n−1
2n XK
1
2n ,
H
1
2n+1 XK
2n
2n+1 −H
2n
2n+1 XK
1
2n+1 .
For instance the repeated use of the Heinz inequality (1.3) yields
|||A(5)||| = |||H
1
6 XK
5
6 −H
2
6 XK
4
6 + H
3
6 XK
3
6 −H
4
6 XK
2
6 + H
5
6 XK
1
6 |||
≤|||H
1
6 XK
5
6 + H
5
6 XK
1
6 ||| + |||H
2
6 XK
4
6 + H
4
6 XK
2
6 ||| + |||H
3
6 XK
3
6 |||
≤5
2|||H
1
6 XK
5
6 + H
5
6 XK
1
6 |||.

114
8 Certain alternating sums of operators
Note that this type of reasoning gives us only
|||A(2n −1)||| ≤2n −1
2
× |||H
1
2n XK
2n−1
2n
+ H
2n−1
2n XK
1
2n |||,
where the constant 2n−1
2
blows up. Instead, we actually have
Proposition 8.6.
(i)
We have
1
2 ≤
|||A(2n −1)|||
|||H
1
2n XK
2n−1
2n
+ H
2n−1
2n XK
1
2n |||
≤5
2
for each n.
(ii) We have
n
2n −1 ≤
|||A(2n)|||
|||H
1
2n+1 XK
2n
2n+1 −H
2n
2n+1 XK
1
2n+1 |||
≤3n −2
2n −1
for each n.
Proof. (i) Note that the sum 1
2

H
1
2n XK
2n−1
2n
+ H
2n−1
2n XK
1
2n

is the Heinz-
type mean A 1
2n (H, K)X (see (6.1)) and we have
A 1
2n (s, t) = 1
2

s
1
2n t
2n−1
2n
+ s
2n−1
2n t
1
2n

= (st)
1
2
2
×
s
t
 1
2 × n−1
n
+
s
t
−1
2 × n−1
n 
.
Since
A 1
2n (e2x, 1)
a2n−1(e2x, 1) = cosh
 1
2nx

cosh
 n−1
n x

cosh
 2n−1
2n x

= 1
2

1 + cosh
 2n−3
2n x

cosh
 2n−1
2n x


is positive deﬁnite, we get the ﬁrst inequality. To see the second estimate, we
need to look at the reciprocal
a2n−1(e2x, 1)
A 1
2n (e2x, 1) =
cosh
 2n−1
2n x

cosh
 1
2nx

cosh
 n−1
n x

and Lemma 8.1 says the desired inequality.
(ii) To see the ﬁrst inequality, we have to look at the ratio
cosh

1
2n+1x

sinh

2n−1
2n+1x

sinh

2n
2n+1x

= 1
2

1 +
sinh

2n−2
2n+1x

sinh

2n
2n+1x


.
This is positive deﬁnite and the value at x = 0 is

8.2 Uniform bounds for norms
115
1
2

1 + 2n −2
2n

= 2n −1
2n
.
The reciprocal
sinh

2n
2n+1x

cosh

1
2n+1x

sinh

2n−1
2n+1x

is equal to
sinh

1
2n+1x

cosh

2n−1
2n+1x

+ cosh

1
2n+1x

sinh

2n−1
2n+1x

cosh(
1
2n+1x) sinh( 2n−1
2n+1x)
= 2 +
sinh

1
2n+1x

cosh

2n−1
2n+1x

−cosh

1
2n+1x

sinh

2n−1
2n+1x

cosh

1
2n+1x

sinh

2n−1
2n+1x

= 2 −
sinh

2n−2
2n+1x

cosh

1
2n+1x

sinh

2n−1
2n+1x
.
Note that the subtracted ratio in the last expression is positive deﬁnite with
the value 2n−2
2n−1 at x = 0. Thus, the whole function can be expressed as the
Fourier transform of a signed measure with total variation at most
2 + 2n −2
2n −1 = 2(3n −2)
2n −1 ,
showing the second inequality.
⊓⊔
We next try to obtain uniform (upper and lower) bounds for |||B(m)|||’s,
and begin with the case m = 3, 5, 7, · · · (odd). At ﬁrst we note
M2(s, t)
bm(s, t) =
 s
t
 1
2 +
 s
t
−1
2
2
×
 s
t
 1
2 ×
1
m−1 +
 s
t
−1
2 ×
1
m−1
 s
t
 1
2 ×
m
m−1 +
 s
t
−1
2 ×
m
m−1 .
Since
M2(e2x, 1)
bm(e2x, 1) =
cosh(x) cosh

1
m−1x

cosh

m
m−1x

= 1
2

1 +
cosh

m−2
m−1x

cosh

m
m−1x



is positive deﬁnite, we conclude
1
2|||HX + XK||| = |||M2(H, K)X||| ≤|||B(m)|||
(m = 3, 5, 7, · · ·).
For an upper bound we obviously have

116
8 Certain alternating sums of operators
|||B(m)||| ≤|||HX + XK||| + |||A(m −2)||| ≤3
2|||HX + XK|||
thanks to (8.1) and Theorem 8.5, (i). (Note that a slightly diﬀerent estimate
based on Proposition 8.6, (i) is also possible.) We however point out that a
multiple of the norm |||
 1
0 HxXK1−xdx||| of the logarithmic mean cannot
majorize |||B(m)|||. Indeed, the leading term of bm(s, 1) is s while we have
M1(s, 1) =
 1
0
sxdx = s −1
log s .
We next consider the case m = 2, 4, 6, · · · (even). Theorem 8.5, (ii) and
(8.1) give rise to an upper bound for |||B(m)||| as follows:
|||B(m)||| ≤|||HX −XK||| + |||A(m −2)|||
≤|||HX −XK||| + m −2
m −1 × 1
2 × |||HX −XK|||
=

1 +
m −2
2(m −1)

× |||HX −XK|||
for m = 2, 4, 6, · · ·. To get a lower bound for |||B(m)||| (with m even), as in
the proof of Theorem 8.5 we compute
−e2x + 1
bm(e2x, 1) =
cosh

1
m−1x

sinh

m
m−1x
 × sinh(x)
=
sinh

1 +
1
m−1

x

+ sinh

1 −
1
m−1

x

2 sinh

m
m−1x

= 1
2

1 +
sinh

m−2
m−1x

sinh

m
m−1x


.
This function is positive deﬁnite (thanks to m−2
m−1 <
m
m−1) with the value m−1
m
at x = 0 so that we conclude
1
2|||HX −XK||| ≤m −1
m
× |||B(m)|||.
Summing up the discussions so far we have shown
Theorem 8.7.
(i)
For m = 3, 5, 7, · · · we have
1
2 ≤
|||B(m)|||
|||HX + XK||| ≤3
2.
(ii) For m = 2, 4, 6, · · · we have
1
2 ≤

m
2(m −1) ≤
|||B(m)|||
|||HX −XK||| ≤1 +
m −2
2(m −1)

≤3
2

.

8.3 Monotonicity of norms
117
8.3 Monotonicity of norms
Monotonicity for |||A(n)||| and |||B(m)||| (either odd or even) is studied in
this section. We begin with the former (which is quite straight-forward).
Proposition 8.8.
(i)
The norm |||A(2n −1)||| is monotone increasing in n (n = 1, 2, 3, · · ·).
(ii) The quantity 2n + 1
2n
× |||A(2n)||| is also monotone increasing in n (n =
1, 2, 3, · · ·).
Proof. For n′ ≥n (odd) we have
an(e2x, 1)
an′(e2x, 1) =
cosh

n
n+1x

cosh

1
n+1x
 ×
cosh

1
n′+1x

cosh

n′
n′+1x
.
Because of
n
n+1 ≤1,
1
n′+1 ≤
1
n+1 and
n
n+1 ≤
n′
n′+1 both functions are positive
deﬁnite and the values at x = 0 are 1. On the other hand, for n′ ≥n (even)
we have
an(e2x, 1)
an′(e2x, 1) =
sinh

n
n+1x

cosh

1
n+1x
 ×
cosh

1
n′+1x

sinh

n′
n′+1x
 .
Because of
1
n′+1 ≤
1
n+1 and
n
n+1 ≤
n′
n′+1 this function is positive deﬁnite and
the value at x = 0 is n′+1
n′
×
n
n+1.
⊓⊔
The case |||B(m)||| is more involved, and monotone decreasingness is ob-
tained only in a weak sense (except for the Hilbert-Schmidt norm ∥· ∥2).
Theorem 8.9.
(i)
We have
|||B(2m + 3) −B(2m + 1)||| ≤|||B(2m + 1)|||
for m = 1, 2, 3, · · ·, and in particular
|||B(2m + 3)||| ≤2|||B(2m + 1)|||.
(ii)
We have
|||B(2m + 2) −B(2m)||| ≤2m −1
2m
× |||B(2m)|||
for m = 1, 2, 3, · · ·, and in particular
|||B(2m + 2)||| ≤

1 + 2m −1
2m

× |||B(2m)|||

≤2 × |||B(2m)|||

.

118
8 Certain alternating sums of operators
(iii) For the Hilbert-Schmidt norm ∥·∥2 we have the monotone decreasingness
∥B(2m + 3)∥2 ≤∥B(2m + 1)∥2
and
∥B(2m + 2)∥2 ≤∥B(2m)∥2.
(iv) The monotone decreasingness
|||B(m′)||| ≤|||B(m)|||
(for m′ > m odd )
fails to hold for general unitarily invariant norms.
Proof. (i) For m′ ≥m ≥3 (odd) we have
bm′(e2x, 1)
bm(e2x, 1) =
cosh

1
m−1x

cosh

m
m−1x
 ×
cosh

m′
m′−1x

cosh

1
m′−1x
.
(8.8)
For convenience we set
α =
1
m′ −1
and
β =
1
m −1.
We compute
bm′(e2x, 1)
bm(e2x, 1) −1 = cosh((α + 1)x) cosh(βx)
cosh((β + 1)x) cosh(αx) −1
= cosh((α + 1)x) cosh(βx) −cosh((β + 1)x) cosh(αx)
cosh((β + 1)x) cosh(αx)
=
1
cosh((β + 1)x) cosh(αx) ×

cosh(αx) cosh(x) + sinh(αx) sinh(x)

cosh(βx)
−

cosh(βx) cosh(x) + sinh(βx) sinh(x)

cosh(αx)

=
sinh(x)
cosh((β + 1)x) cosh(αx) ×

sinh(αx) cosh(βx) −cosh(αx) sinh(βx)

= sinh(x) sinh((α −β)x)
cosh((β + 1)x) cosh(αx).
Since m′ ≥m, i.e., 0 < α ≤β, the above last quantity is negative so that we
have the (point-wise) monotone decreasingness
(0 ≤) bm′(s, t) ≤bm(s, t),
showing (iii) in the odd case (see [39, Proposition 1.2]). Notice
bm′(e2x, 1)
bm(e2x, 1) = 1 + sinh(x) sinh((α −β)x)
cosh((β + 1)x) cosh(αx)
= 1 + cosh((α −β + 1)x) −cosh((α −β −1)x)
2 cosh((β + 1)x) cosh(αx)
.
(8.9)

8.3 Monotonicity of norms
119
We now assume m′ = m + 2 (i.e., α =
1
m+1 and β =
1
m−1) so that





α −β + 1 =
m2−3
(m+1)(m−1) > 0,
α −β −1 = −
m2+1
(m+1)(m−1) < 0.
(8.10)
Notice that the hyperbolic cosine function is even and
m2 −3
(m + 1)(m −1) ≤
m
m −1
and
m2 + 1
(m + 1)(m −1) ≤
m
m −1
(8.11)
with
m
m −1 = β + 1. Consequently, the second term in the far right side of
(8.9) is a diﬀerence of two positive deﬁnite functions (with the value
1
2 at
x = 0), showing (i).
(ii) For m′ ≥m ≥2 (even) we have
bm′(e2x, 1)
bm(e2x, 1) =
cosh

1
m−1x

sinh

m
m−1x
 ×
sinh

m′
m′−1x

cosh

1
m′−1x
 = sinh((α + 1)x) cosh(βx)
sinh((β + 1)x) cosh(αx)
instead with α and β appearing above. Hence, the computations in (i) are
changed as follows:
bm′(e2x, 1)
bm(e2x, 1) −1 = sinh((α + 1)x) cosh(βx) −sinh((β + 1)x) cosh(αx)
sinh((β + 1)x) cosh(αx)
=
1
sinh((β + 1)x) cosh(αx) ×

sinh(αx) cosh(x) + cosh(αx) sinh(x)

cosh(βx)
−

sinh(βx) cosh(x) + cosh(βx) sinh(x)

cosh(αx)

=
cosh(x)
sinh((β + 1)x) cosh(αx) ×

sinh(αx) cosh(βx) −cosh(αx) sinh(βx)

= cosh(x) sinh((α −β)x)
sinh((β + 1)x) cosh(αx).
Since 0 < α ≤β, the above last quantity is negative so that once again we
have the point-wise monotone decreasingness
|bm′(s, t)| ≤|bm(s, t)|,
showing (iii) in the even case. We have
bm′(e2x, 1)
bm(e2x, 1) = 1 + cosh(x) sinh((α −β)x)
sinh((β + 1)x) cosh(αx)
= 1 + sinh((α −β + 1)x) + sinh((α −β −1)x)
2 sinh((β + 1)x) cosh(αx)
.

120
8 Certain alternating sums of operators
We now assume m′ = m + 2 as before. Since α −β −1 is negative (see (8.10))
and the hyperbolic sine function is odd, we have
bm+2(e2x, 1)
bm(e2x, 1)
= 1 + sinh((α −β + 1)x) −sinh((−α + β + 1)x)
2 sinh((β + 1)x) cosh(αx)
.
Therefore, (8.11) once again yields that the above ratio is a diﬀerence of
positive deﬁnite functions. Note that their values at x = 0 are
α −β + 1
β + 1
=
m2 −3
(m + 1)(m −1) × 1
2 × m −1
m
=
m2 −3
2m(m + 1),
−α + β + 1
β + 1
=
m2 + 1
(m + 1)(m −1) × 1
2 × m −1
m
=
m2 + 1
2m(m + 1)
respectively. They sum up to m−1
m
so that (by changing (even) m to 2m) we
get the inequality in (ii).
(iv)
When m is odd, it is obvious that the function bm(s, t) in s, t > 0 is
a symmetric homogeneous function such that bm(s, s) = s for all s > 0. Al-
though bm(s, 1) is not non-decreasing in s, the proof of (ii) ⇒(iv) in Theorem
3.7 (i.e., (ii) ⇒(v) in [39, Theorem 1.1]) works well (see also the proof of
Theorem A.3 in §A.1). Thus, if |||B(m′)||| ≤|||B(m)||| (for odd m′ > m ≥3)
were valid for all unitarily invariant norms, then
f(x) = bm′(e2x, 1)
bm(e2x, 1)
would be a positive deﬁnite function, i.e., f(x) = ˆν(x) for some probability
measure ν (because of f(0) = 1). However, by Proposition A.7 and (8.8) we
would have
ν({0}) =
lim
x→±∞f(x) = 1,
meaning f(x) = 1, a contradiction.
⊓⊔
In the part (iv) of the theorem, the monotone decreasingness |||B(m′)||| ≤
|||B(m)||| (for m′ > m odd) actually fails to hold for the operator norm
||| · ||| = ∥· ∥and for the trace norm ||| · ||| = ∥· ∥1. Indeed, the proof of [39,
Theorem 1.1] says that if the decreasingness (in case of matrices) were valid
for one of these norms then we would have the positive deﬁniteness of the
above function f(x).
We are unable to determine what happens in the even case.
8.4 Notes and references
Trivial modiﬁcation of the argument for the proof of the ﬁrst inequality in
Remark 8.4 enables us to obtain

8.4 Notes and references
121
2 + x
2
|||HX + XK||| ≤|||HX + XK + xH1/2XK1/2|||
for x ∈(−2, 0]. This fact and the ordinary Heinz inequality (1.3) imply that
the inequality (i) in §3.7, 2 holds true for each θ ∈[0, 1] as long as x ∈(−2, 0].
Inequalities involving the norm of an operator of the form
HθXK1−θ + H1−θXKθ + xH
1
2 XK
1
2
have been studied by many authors (see [13, 78, 83] for instance). Note that
the cases θ = 3
4, 1 (and x = −1) correspond to A(3), B(3) respectively, and
quite thorough investigation on inequalities involving these quantities will be
carried out in the forthcoming article [55].
Note that the logarithmic-geometric mean inequality (see (1.8)) says
|||A(1)||| = |||H
1
2 XK
1
2 ||| ≤|||
 1
0
HxXK1−xdx|||,
which should be compared with Theorem 8.5, (i). The estimate of this form
is no longer valid for |||A(3)|||, but it is possible to estimate (more generally)
|||A(2n −1)||| by a constant multiple of |||
 1
0 HxXK1−xdx||| ([55]).

A
Appendices
We collect six appendices here. In §A.1 we will deal with certain non-
symmetric means (by weakening the axioms stated in Deﬁnition 3.1), and
we will see that all the results in §3.2 remain valid for such means (sometimes
with obvious modiﬁcation). In §A.2–A.6 some technical results used in the
main body of the monograph are clariﬁed.
A.1 Non-symmetric means
We can deal with a wider class of (not necessarily symmetric) homogeneous
means for positive scalars. We denote by 
M the set of all continuous positive
real functions M(s, t) for s, t > 0 satisfying

the properties (b), (c) in Deﬁnition 3.1,
and M(s, s) = s for s > 0 in place of (d) there.
For M, N ∈
M the order M ⪯N is introduced in the same way as in Deﬁnition
3.2, that is, M ⪯N if and only if there exists a symmetric measure ν on R
such that M(ex, 1) = ˆν(x)N(ex, 1) (x ∈R).
Remark A.1. Here are some remarks on the above measure ν.
(i)
The measure ν in Deﬁnition 3.2 was automatically symmetric (since so
are M(s, t) and N(s, t)) while it is now a part of the requirement.
(ii) When M ⪯N, we have
M(s, t)/N(s, t) = M(t, s)/N(t, s)
(although M(s, t) and N(s, t) might be asymmetric). In fact, since ν is
symmetric, we compute
M(s, t)/N(s, t) = M(s/t, 1)/N(s/t, 1) = ˆν(log s −log t)
= ˆν(log t −log s) = M(t/s, 1)/N(t/s, 1) = M(t, s)/N(t, s).
F. Hiai and H. Kosaki: LNM 1820, pp. 123–139, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

124
A Appendices
(iii) The measure ν is a probability measure because of
M(e0, 1) = N(e0, 1) = 1.
As in the case of a mean in M, the domain of M ∈
M extends to [0, ∞) ×
[0, ∞) as follows:
M(s, 0) = lim
t↘0 M(s, t) = sM(1, 0)
(s > 0),
M(0, t) = lim
s↘0 M(s, t) = tM(0, 1)
(t > 0),
and M(0, 0) = 0 while M(1, 0) ̸= M(0, 1) in general. So, for positive operators
H, K ∈B(H) one can deﬁne the double integral transformation M(H, K)X
ﬁrst for X ∈C2(H) and then for all X ∈B(H) whenever M is a Schur
multiplier relative to (H, K).
We will show that the main results in §3.2 remain valid also for means in

M, and we begin with generalizations of Theorem 3.4 and Corollary 3.5 (see
also Proposition 8.2).
Theorem A.2. Assume that means M, N in 
M satisfy M ⪯N.
(i)
The integral expressions (i.e., (3.8) and (3.9)) in Theorem 3.4 remain
valid with the modiﬁcation of (3.8) by
M(H, K)X =
 ∞
−∞
(HsH)ix(N(H, K)X)(KsK)−ixdν(x)
+M(1, 0)HX(1 −sK) + M(0, 1)(1 −sH)XK.
(ii) The norm inequality in Corollary 3.5 also holds true.
Proof. The proof of Proposition 8.2 works here thanks to (8.3) and Remark
A.1, (ii). Note that the estimate (8.6) there is not necessary since we have the
stronger estimate M(1, 0) ≤N(1, 0) (due to Remark A.1, (iii)) as in the proof
of Theorem 3.4. Of course (ii) follows from Theorem A.5 as usual.
⊓⊔
We are now ready to prove a generalization of Theorem 3.7.
Theorem A.3. The conditions (i)–(iv) in Theorem 3.7 are all equivalent for
means M, N in 
M.
Proof. Theorem A.2, (i) and (ii) guarantee (iv) ⇒(i) and (iv) ⇒(ii) respec-
tively. The proof of (iv) ⇒(iii) is the same as in the proof of Theorem 3.7
while (i) ⇒(iv) is trivial as in the proof of Theorem 3.7.
It remains show (ii) ⇒(iv) and (iii) ⇒(iv). To this end, it suﬃces to prove
M ⪯N under the assumption that (iii) holds for all matrices H ≥0 and X
of any size. Now, for any s1, . . . , sn > 0 put H = diag(s1, . . . , sn). Since (iii)
means

A.1 Non-symmetric means
125
∥[M(si, sj)] ◦X∥≤∥[N(si, sj)] ◦X∥
for all n×n matrices X, one gets ∥T ◦X∥≤∥X∥with T =
 M(si,sj)
N(si,sj)

i,j=1,··· ,n.
Since Tr((T ◦X)Y ) = Tr(X(T t ◦Y )) for all n × n matrices X, Y , one has
∥T t ◦Y ∥1 ≤∥Y ∥1 so that
∥T ◦Y ∥1 = ∥(T ◦Y )t∥1 = ∥T t ◦Y t∥1 ≤∥Y t∥1 = ∥Y ∥1.
Choose the matrix of all entries 1 for Y ; then the above estimate gives
∥T ∥1 = ∥T ◦Y ∥≤∥Y ∥1 = n.
On the other hand, since M(s, s) = N(s, s) = s, the diagonals of T are all 1
and consequently
∥T ∥1 ≥Tr T = n.
Hence we have seen ∥T ∥1 = Tr T . Let T = V |T | with a unitary matrix V , and
assume that |T | is diagonalized with a unitary matrix U as follows:
|T | = Udiag(λ1, . . . , λn)U ∗.
Then, we observe
n

i=1
λi = ∥T ∥1 = Tr T = Tr

U ∗V Udiag(λ1, . . . , λn)

=
n

i=1
λiuii
with the unitary matrix U ∗V U = [uij]. Note uii = 1 as long as λi > 0 (thanks
to the obvious facts |uii| ≤1 and λi ≥0). Hence, by assuming say
λ1, . . . , λk > 0 = λk+1 = λk+2 = · · · = λn,
we can write
U ∗V U = Ik ⊕Wn−k,
and consequently
T = U(Ik ⊕Wn−k)U ∗Udiag(λ1, . . . , λk, 0, . . . , 0)U ∗
= Udiag(λ1, . . . , λk, 0, . . . , 0)U ∗.
This means T = |T | ≥0, and M ⪯N is shown.
⊓⊔
Let us present two simple examples for which Theorem A.2 is useful. Firstly
let us assume
0 < α ≤β < 1,
0 ≤δ ≤min{α, 1 −β},
and we set
M(s, t) = sαt1−α + sβt1−β,
N(s, t) = sα−δt1−α+δ + sβ+δt1−β−δ.

126
A Appendices
Although M, N fail to be symmetric, 1
2M, 1
2N fall into 
M and they satisfy
M(ex, 1)
N(ex, 1) =
eαx + eβx
e(α−δ)x + e(β+δ)x
=
e−β−α
2
x + e
β−α
2
x
e−( β−α
2
+δ)x + e( β−α
2
+δ)x =
cosh

β−α
2 x

cosh

( β−α
2
+ δ)x
,
which is positive deﬁnite (see [39, (1.5)] for example). Therefore, we have
M ⪯N, and Theorem A.2, (ii) implies
|||HαXK1−α + HβXK1−β||| ≤|||Hα−δXB1−α+δ + Aβ+δXK1−β−δ|||
for all unitarily invariant norms and all operators H, K ≥0 and X. It is also
possible to derive this inequality from Heinz-type inequalities (see Chapter
6), and details are left to the reader.
Secondly we assume
0 < α1, . . . , αk < 1
and
0 < β < min{α1, . . . , αk, 1 −α1, . . . , 1 −αk}.
For λ1, . . . , λk ≥0 with k
i=1 λi = 1 we consider M, N ∈
M deﬁned by
M(s, t) =
k

i=1
λisαit1−αi,
N(s, t) = 1
2
k

i=1
λi

sαi+βt1−αi−β + sαi−βt1−αi+β
.
Note N(s, t) = sβt−β+s−βtβ
2
× M(s, t) and
M(ex, 1)
N(ex, 1) =
1
cosh(βx)
is positive deﬁnite (see Example 3.6, (a)). Thus, once again Theorem A.2, (ii)
implies
|||
k

i=1
λiHαiXK1−αi|||
≤1
2|||
k

i=1
λi

Hαi+βXK1−αi−β + Hαi−βXK1−αi+β
|||.
In particular,
|||λHαXK1−α + (1 −λ)H1−αXKα|||
≤1
2|||λH2α−1
2 XK
3
2 −2α + H
1
2 XK
1
2 + (1 −λ)H
3
2 −2αXK2α−1
2 |||

A.2 Norm inequality for operator integrals
127
for every 1
4 ≤α ≤3
4 and 0 ≤λ ≤1.
The equivalent conditions for M, N ∈
M obtained in Theorem A.3 are
somewhat too restrictive, and it is also interesting to characterize the sit-
uation where |||M(H, K)X||| ≤C|||N(H, K)X||| holds with some univer-
sal constant C (for all H, K ≥0 and X). A suﬃcient condition is that
M(ex, 1)/N(ex, 1) = ˆµ(x) (x ∈R) for some signed measure µ on R. This
condition implies the above inequality with C = ∥µ∥(the total variation of
µ). A typical application of this reasoning is the weak Young inequality (6.4)
whose full details were worked out in [54]. Note that this method was employed
in Chapter 8 (although an(s, t), bm(s, t) there need not fall into 
M).
A.2 Norm inequality for operator integrals
We assume that F : Ω→B(H) is a weakly measurable operator-valued
function on a measure space (Ω, µ) in the sense that the function x ∈Ω→
(F(x)ξ, η) is measurable for each vectors ξ, η ∈H. In this section the operator
integral

Ω
F(x) dµ(x)
is considered, and its (unitarily invariant) norm estimate will be studied.
The proof of the next lemma is based on the separability assumption on
the ambient Hilbert space H.
Lemma A.4. For each unitarily invariant norm ||| · |||, the function
x ∈Ω→|||F(x)||| ∈[0, ∞]
is measurable.
Proof. At ﬁrst we claim that x →µn(F(x)) is measurable for each n =
0, 1, . . . , where µn(·) denotes the n-th singular number. When n = 0, we note
µ0(F(x)) = ∥F(x)∥, i.e., the operator norm, and by choosing a dense sequence
{ξi}i=1,2,··· in the unit ball of H we have
∥F(x)∥= sup
i,j
|(F(x)ξi, ξj)|.
Therefore, the weak measurability guarantees the measurability of x →
µ0(F(x)). To deal with general n’s, we recall the famous trick appearing for
example in the proof of the Weyl inequality (see [77, §1, (v)] for details) based
on anti-symmetric tensors. The main ingredient of the trick is the fact that
the n-fold anti-symmetric tensor product ∧n(F(x)) ∈B(∧nH) satisﬁes
∥∧n (F(x))∥=
n−1

k=0
µk(F(x)).

128
A Appendices
Hence, the preceding argument (using a dense sequence) applied for ∧n(F(x))
guarantees the measurability of x →n−1
k=0 µk(F(x)) (for each n) and we are
done.
Let Φ be the symmetric norm for (ﬁnite) sequences corresponding to |||·|||.
Since
|||F(x)||| = lim
n→∞Φ(µ0(F(x)), µ1(F(x)), . . . , µn(F(x)), 0, 0, . . . ),
to prove the lemma it suﬃces to check the measurability of
x ∈Ω→Φ(µ0(F(x)), µ1(F(x)), . . . , µn(F(x)), 0, 0, . . . ) ∈[0, ∞)
for each ﬁxed n. Note that this map is the composition of the measurable
map x →(µ0(F(x)), µ1(F(x)), . . . , µn(F(x))) (thanks to the ﬁrst half of the
proof) followed by
(a0, a1, . . . , an) ∈Rn+1 →Φ(a0, a1, . . . , an, 0, 0, . . . ) ∈[0, ∞).
However, the latter is a norm and hence continuous so that the composition
is clearly measurable.
⊓⊔
Next, we further require that a weakly measurable operator-valued func-
tion F : Ω→B(H) satisﬁes the ∥· ∥-integrability

Ω
∥F(x)∥dµ(x) < ∞.
Then, the operator integral Z =

ΩF(x)dµ(x) ∈B(H) can be deﬁned in the
weak sense, i.e.,
(Zξ, η) =

Ω
(F(x)ξ, η) dµ(x)
(for ξ, η ∈H),
and the following estimate is straight-forward:
∥Z∥≤

Ω
∥F(x)∥dµ(x).
The next theorem asserts that a similar norm estimate remains valid for every
unitarily invariant norm.
Theorem A.5. Let ||| · ||| be a unitarily invariant norm, and we assume that
a weakly measurable operator-valued function F : Ω→B(H) on a measure
space (Ω, µ) satisﬁes the ∥· ∥-integrability

Ω
∥F(x)∥dµ(x) < ∞.
Then, the norm of the operator Z =

ΩF(x)dµ(x) ∈B(H) (deﬁned in the
weak sense as above) admits the following estimate :
|||Z||| ≤

Ω
|||F(x)||| dµ(x) (≤∞).

A.2 Norm inequality for operator integrals
129
Proof. We at ﬁrst point out that one can reduce the proof to the case where
(Ω, µ) is a ﬁnite measure and |||F(·)||| is bounded.
(i) We can assume µ(Ω) < ∞. Indeed, (Ω, µ) can be assumed to be σ-
ﬁnite because F is supported on a σ-ﬁnite measurable set. So let {Ωi}i=1,2,···
be an increasing sequence of measurable subsets with µ(Ωi) < ∞(for each i)
exhausting the whole space Ω. We set
Zi =

Ωi
F(x) dµ(x)
(in the weak sense).
Then, the ∥· ∥-integrability of F(·) implies
| ((Z −Zi)ξ, η) | ≤∥ξ∥× ∥η∥×

Ω\Ωi
∥F(x)∥dµ(x)
(ξ, η ∈H),
which tends to 0 as i →∞due to the Lebesgue dominated convergence
theorem, i.e., {Zi}i=1,2,··· tends to Z in the weak operator topology. Therefore,
if the result is known for Ωi’s (of ﬁnite measure), then by the lower semi-
continuity of ||| · ||| in the weak operator topology (see [37, Proposition 2.11])
we get
|||Z||| ≤lim inf
i→∞|||Zi||| ≤lim inf
i→∞

Ωi
|||F(x)||| dµ(x) =

Ω
|||F(x)||| dµ(x).
Here, the last equality follows from the monotone convergence theorem.
(ii) We can assume the |||·|||-boundedness of F. Indeed, if

Ω|||F(x)|||dµ(x)
= ∞, we have nothing to prove. Hence, we may and do assume the integrability
of |||F(·)|||. In particular, we have |||F(x)||| < ∞for µ-a.e. x. We set
˜Ωn = {x ∈Ω: |||F(x)||| ≤n} and ˜Zn =

˜
Ωn
F(x) dµ(x) (in the weak sense).
Then { ˜Ωn}n=1,2,··· is increasing with 
n ˜Ωn = Ω(up to a null set). The same
arguments as in (i) show that { ˜Zn}n=1,2,··· tends to Z in the weak operator
topology, and we have |||Z||| ≤

Ω|||F(x)|||dµ(x) (if the result is known for
˜Ωn’s).
Thanks to (i) and (ii), we can assume µ(Ω) < ∞and the |||·|||-boundedness
of F in the rest of the proof. We choose and ﬁx ε > 0 and α satisfying α <
|||Z|||. (|||Z||| could be ∞a priori, in which case α can be anything. However,
our arguments in what follows will rule out the possibility of |||Z||| = ∞.)
The set {X ∈B(H) : |||X||| > α} is an open neighborhood of Z relative
to the weak topology from the lower semi-continuity of ||| · |||. Hence, vectors
ξ1, ξ2, . . . , ξN ∈H and δ > 0 can be chosen in such a way that
| ((X −Z)ξs, ξt) | ≤δ
(s, t = 1, . . . , N)
=⇒
|||X||| > α.
(A.1)
Choose and ﬁx a pair (s, t) ∈{1, 2, . . ., N}2 for a moment. Since ∥· ∥is
majorized by ||| · |||, (F(·)ξs, ξt) is a bounded measurable function. By dividing

130
A Appendices
the range of the function into small pieces and considering the corresponding
preimages, one can choose a ﬁnite measurable partition {S1, S2, . . . , Sℓ} of Ω
such that | (F(x)ξs, ξt) −(F(x′)ξs, ξt) | ≤
δ
µ(Ω) if x, x′ belong to the same Si.
Note that we have ﬁnitely many (s, t)’s and do the same for each of (s, t)’s.
By considering the common reﬁnement of all the partitions obtained in this
procedure (the reﬁnement is denoted by {S1, S2, . . . , Sℓ} again), we conclude
| (F(x)ξs, ξt) −(F(x′)ξs, ξt) | ≤
δ
µ(Ω)
(for all s, t)
(A.2)
as long as x, x′ sit in the same Si (i = 1, 2, . . ., ℓ).
On the other hand, since |||F(·)||| is bounded, we can also take a ﬁnite
measurable partition {T1, T2, . . . , Tm} of Ωsuch that
m

j=1
Mjµ(Tj) ≤

Ω
|||F(x)||| dµ(x) + ε
(A.3)
with
Mj = sup{|||F(x)||| : x ∈Tj}
(j = 1, 2, . . . , m).
Let {Qk}k=1,2,··· ,n be a renumbering of {Si∩Tj}i=1,2,··· ,ℓ; j=1,2,··· ,m, and we
choose xk from each Qk (k = 1, 2, . . . , n). Being a reﬁnement of {Si}i=1,2,··· ,ℓ,
the property (A.2) remains valid for the Qk’s. Firstly, for each s, t we estimate

 n

k=1
F(xk)µ(Qk) −Z

ξs, ξt
  =

n

k=1

Qk
((F(xk) −F(x))ξs, ξt) dµ(x)

≤
n

k=1

Qk
|((F(xk) −F(x))ξs, ξt)| dµ(x)
≤
δ
µ(Ω)
n

k=1
µ(Qk) = δ.
This means that
X =
n

k=1
F(xk)µ(Qk) ∈B(H)
satisﬁes the assumption of (A.1), and consequently we get |||X||| > α. Sec-
ondly, from the above deﬁnition of Mj we observe
|||X||| = |||
n

k=1
F(xk)µ(Qk)||| ≤
n

k=1
|||F(xk)|||µ(Qk) ≤
m

j=1
Mjµ(Tj)
since {Qk}k=1,2,··· ,n is a reﬁnement of {Tj}j=1,2,··· ,m. This estimate and (A.3)
imply
|||X||| ≤

Ω
|||F(x)||| dµ(x) + ε.

A.3 Decomposition of max{s, t}
131
Therefore, we conclude
α < |||X||| ≤

Ω
|||F(x)||| dµ(x) + ε.
Since α (< |||Z|||) and ε (> 0) were arbitrary, we are done.
⊓⊔
The following proof based on the duality I|||·||| =

I(0)
|||·|||′
∗
(see Remark
4.2, (4) and the ﬁrst part of the proof below) is also worth pointing out:
Alternative proof of Theorem A.5. Let ||| · |||′ be the conjugate norm of ||| · |||,
and recall that the duality I|||·||| =

I(0)
|||·|||′
∗
is given by the bilinear form
(X, Y ) ∈I|||·|||×I(0)
|||·|||′ →Tr(XY ) ∈C. On the other hand, from the deﬁnition
of the separable ideal I(0)
|||·|||′ each Y ∈I(0)
|||·|||′ can be approximated by ﬁnite-
rank operators with norm at most |||Y |||′. Therefore, we have
|||X||| = sup{|Tr(XY )| : Y is of ﬁnite-rank and |||Y |||′ ≤1}
(see the proof of [37, Proposition 2.11]). For each Y = n
i=1 ξi ⊗ηc
i with
|||Y |||′ ≤1 we estimate
|Tr(ZY )| =

n

i=1
(Zξi, ηi)
 =


Ω
n

i=1
(F(x)ξi, ηi) dµ(x)

≤

Ω

n

i=1
(F(x)ξi, ηi)
 dµ(x) =

Ω
Tr(F(x)Y ))
 dµ(x)
≤

Ω
|||F(x)||| dµ(x).
Thus, by taking the supremum over Y ’s, we get the conclusion.
⊓⊔
A.3 Decomposition of max{s, t}
We assume that the integral operator T acting on L2([a, b]) with a kernel
k(s, t) (∈L2([a, b] × [a, b])) is positive (i.e., k(s, t) is a positive deﬁnite in
the sense of §3.4), and let {λn}n=1,2,··· be the (strictly) positive eigenvalues
λ1 ≥λ2 ≥λ3 ≥· · · > 0 (with multiplicities counted). The spectral de-
composition theorem states T = 
n λnφn ⊗φc
n for an orthonormal system
{φn(t)}n=1,2,··· (⊆L2([a, b])) of corresponding eigenvectors. The following re-
sult (that is a consequence of Dini’s theorem) is known as Mercer’s theorem
(see [79, Theorem 7.7.2], [81, p. 125] or [82, Chapter 3 §2 32]): If a positive
deﬁnite kernel k(s, t) is a continuous function on [a, b] × [a, b], then so are
eigenfunctions φn(t) and moreover we have

132
A Appendices
k(s, t) =

n
λnφn(s)φn(t),
the series being uniformly and absolutely convergent on [a, b] × [a, b]. Based
on this theorem one can prove the absolute convergence
min{s, t} = 2
∞

n=1

2
(2n −1)π
2
sin
(2n −1)πs
2

sin
(2n −1)πt
2

(A.4)
for (s, t) ∈[0, 1] × [0, 1] (see the end of the section), which plays an impor-
tant role in analysis of the Brownian process. With slightly more involved
arguments the next decomposition can be also obtained.
Theorem A.6. The function max{s, t} on [0, 1] × [0, 1] admits the absolutely
convergent decomposition
max{s, t} = 2
α2 −1
α4
× cosh(αs) cosh(αt)
−
∞

n=1
1 + α2
n
α4n
× cos(αns) cos(αnt)

.
Here, α (> 1) is a unique positive real satisfying tanh(α) −1
α = 0 while
α1 < α2 < · · · are the positive roots for the equation tan(x) + 1
x = 0.
Proof. We consider the integral operator with the kernel max{s, t} acting
on the Hilbert space L2([0, 1]; dt), which is a self-adjoint operator sitting in
C2(L2([0, 1])). Let x(t) be an eigenvector with an eigenvalue λ ∈R:
λx(t) =
 1
0
max{t, s}x(s) ds = t
 t
0
x(s) ds +
 1
t
sx(s) ds.
(A.5)
When λ = 0, the diﬀerentiation of the right-hand side gives us
(0 =)
 t
0
x(s) ds + tx(t) −tx(t) =
 t
0
x(s) ds.
Hence, we must have x(s) = 0, that is, the operator is non-singular. In the
rest let us assume λ ̸= 0. Because of
 t
0
x(s) ds = λx′(t)
we observe x′(0) = 0 and x(t) = λx′′(t).
We begin with the case λ > 0. The general solution for the diﬀerential
equation x′′ −λ−1x = 0 is
x(t) = A exp

λ−1
2 t

+ B exp

−λ−1
2 t

.

A.3 Decomposition of max{s, t}
133
However, the boundary condition x′(0) = 0 forces A = B so that an eigenvec-
tor must be a constant multiple of
x(t) = cosh

λ−1
2 t

.
The direct computation of the right side of (A.5) with this function yields
t
 t
0
cosh

λ−1
2 s

ds +
 1
t
s cosh

λ−1
2 s

ds
= λ
1
2 sinh

λ−1
2

−λ cosh

λ−1
2

+ λ cosh

λ−1
2 t

.
(A.6)
Therefore, x(t) is an eigenvector if and only if
sinh

λ−1
2

−λ
1
2 cosh

λ−1
2

= 0, i.e., λ−1
2 = α,
showing that λ = 1/α2 is the only positive eigenvalue. The square of the
L2-norm of the eigenvector x(t) = cosh(αt) is
 1
0
cosh2(αs) ds = 1
2
 1
0

1 + cosh(2αs)

ds
= 1
2

1 + sinh(2α)
2α

= 1
2

1 + sinh(α) cosh(α)
α

.
We note
sinh(α) cosh(α) = tanh(α) cosh2(α) =
tanh(α)
1 −tanh2(α)
so that the above quantity is equal to
1
2

1 + 1
α ×
1
α
1 −
 1
α
2
	
=
α2
2(α2 −1).
Therefore, a unit eigenvector (for the eigenvalue λ = 1/α2) is given by
x0(t) =
√
2
√
α2 −1
α
× cosh(αt).
We next move to the case λ < 0. By setting ˜λ = −λ > 0, we consider the
diﬀerential equation x′′ + ˜λ−1x = 0 with the general solution
A sin

˜λ−1
2 t

+ B cos

˜λ−1
2 t

.
As before the boundary condition x′(0) = 0 forces A = 0 and we set
x(t) = cos

˜λ−1
2 t

.

134
A Appendices
Note that the computation (A.6) is replaced by
t
 t
0
cos

˜λ−1
2 s

ds +
 1
t
s cos

˜λ−1
2 s

ds
= ˜λ
1
2 sin

˜λ−1
2

+ ˜λ cos

˜λ−1
2

−˜λ cos

˜λ−1
2 t

.
Therefore, x(t) is an eigenvector if and only if
sin

˜λ−1
2

+ ˜λ
1
2 cos

˜λ−1
2

= 0,
that is, ˜λ−1
2 must be a (positive) solution for tan(x) + 1
x = 0. We assume
˜λ−1
2 = αn (n = 1, 2, · · ·). This means that λ = −˜λ = −1/α2
n is a negative
eigenvalue with an eigenvector x(t) = cos(αnt). The preceding computations
for normalization should be modiﬁed in the following way:
 1
0
cos2(αns) ds = 1
2
 1
0

1 + cos(2αns)

ds
= 1
2

1 + sin(2αn)
2αn

= 1
2

1 + sin(αn) cos(αn)
αn

= 1
2

1 + 1
αn
×
tan(αn)
1 + tan2(αn)

= 1
2


1 + 1
αn
×
−1
αn
1 +

−1
αn
2


=
α2
n
2(1 + α2n).
Thus, we conclude that
xn(t) =
√
2

1 + α2n
αn
× cos(αnt)
(n = 1, 2, · · ·)
is a normalized eigenvector for the negative eigenvalue λ = −1/α2
n.
The arguments so far show that the integral operator T with the kernel
max{s, t} admits the spectral decomposition
T = 1
α2 x0 ⊗xc
0 −
∞

n=1
1
α2n
xn ⊗xc
n.
Since the diﬀerence
1
α2 x0 ⊗xc
0 −T is a positive integral operator with the
continuous kernel
1
α2 x0(s)x0(t) −max{s, t}
= 1
α2 × 2(α2 −1)
α2
× cosh(αs) cosh(αt) −max{s, t},
the desired convergence follows from Mercer’s theorem.
⊓⊔

A.3 Decomposition of max{s, t}
135
Assume 0 ≤H, K ≤1 for instance. Then, the above theorem permits the
following alternative deﬁnition:
M∞(H, K)X = 2
α2 −1
α4
× cosh(αH)X cosh(αK)
−
∞

n=1
1 + α2
n
α4n
× cos(αnH)X cos(αnK)

, (A.7)
which coincides with the one considered in previous chapters (see Remark
2.5, (ii)). Substitutions s = t = 0 and s = t = 1 to the series in the theorem
give rise to
α2 −1
α4
=
∞

n=1
1 + α2
n
α4n
,
(A.8)
α2 −1
α4
× cosh2 α = 1
2 +
∞

n=1
1 + α2
n
α4n
× cos2 αn.
(A.9)
The expression (A.7) clearly shows |||M∞(H, K)H||| ≤κ|||X||| with
κ = 2

α2 −1
α4
× cosh2 α +
∞

n=1
1 + α2
n
α4n

.
Note that (A.8) and tanh α = 1/α yield
κ = 2 × α2 −1
α4
× (cosh2 α + 1) = 2 × 2α2 −1
α4
while (A.9) and tan αn = −1/αn show
κ = 2

1
2 +
∞

n=1
1 + α2
n
α4n
× (cos2 αn + 1)

= 1 + 2
∞

n=1
2α2
n + 1
α4n
.
From the ﬁrst expression for κ and α > 1 we observe κ < 2. On the other
hand, the second and the obvious fact αn < nπ (for n = 1, 2, · · ·) imply
κ > 1 + 2
∞

n=1
2π2n2 + 1
π4n4
= 1 + 4
π2
∞

n=1
1
n2 + 2
π4
∞

n=1
1
n4 = 1 + 31
45
(thanks to ∞
n=1 n−2 = π2/6 and ∞
n=1 n−4 = π4/90). Hence, (although the
expression (A.7) makes it trivial that max{s, t} is a Schur multiplier) it seems
impossible to get the optimal constant
2
√
3 obtained in Theorem 3.12.
Both of positive and negative eigenvalues appeared in the proof of Theorem
A.6. This phenomenon corresponds to the fact that M∞is not majorized (in
the sense of Deﬁnition 3.2) by the geometric mean G = M1/2 (see Proposition
3.10). The proof for (A.4) is easier since all the eigenvalues (which are actually
(2/(2n −1)π)2 with n = 1, 2, · · · ) are positive due to M−∞⪯G. Details are
left to the reader as an easy exercise.

136
A Appendices
A.4 Ces`aro limit of the Fourier transform
In this section the formula (i.e., Proposition A.9) that have appeared before
Theorem 3.4 and some related results are explained.
Proposition A.7. For every complex measure µ on R, we have
µ({0}) = lim
T →∞
1
2T
 T
−T
ˆµ(t) dt .
Proof. To prove the proposition, it suﬃces to show
µ({0}) = 0 =⇒
lim
T →∞
1
2T
 T
−T
ˆµ(t) dt = 0
(by considering µ−µ({0})δ0), and hence let us assume µ({0}) = 0. The Fubini
theorem shows
1
2T
 T
−T
ˆµ(t) dt = 1
2T
 T
−T
 ∞
−∞
eist dµ(s)

dt
=
 ∞
−∞

1
2T
 T
−T
eist dt

dµ(s)
=
 ∞
−∞
1
2T × eisT −e−isT
is
dµ(s)
=
 ∞
−∞
sin(sT)
sT
dµ(s).
Therefore, for each (small) δ > 0 we estimate

1
2T
 T
−T
ˆµ(t) dt
 ≤

|s|<δ
sin(sT)
sT
 d|µ|(s) +

|s|≥δ
sin(sT)
sT
 d|µ|(s)
≤|µ|((−δ, δ)) + 1
δT |µ|(R) ,
and hence
lim sup
T →∞

1
2T
 T
−T
ˆµ(t) dt
 ≤|µ|((−δ, δ)) .
Note that the assumption µ({0}) = 0 implies |µ|({0}) = 0. Since |µ|(R) < ∞,
we have |µ|((−δ, δ)) →0 as δ →+0 and consequently
lim sup
T →∞

1
2T
 T
−T
ˆµ(t) dt
 = 0
as desired.
⊓⊔

A.5 Reﬂexivity and separability of operator ideals
137
If ˆµ(t) →α as t →±∞, then it is plain to observe
lim
T →∞
1
2T
 T
−T
ˆµ(t) dt = α,
and hence we have
Corollary A.8. If
lim
|t|→∞ˆµ(t) exists, then it is equal to µ({0}).
Here is the formula mentioned before Theorem 3.4.
Proposition A.9. For a complex measure µ on R we have

t∈R
|µ({t})|2 = lim
T →∞
1
2T
 T
−T
|ˆµ(t)|2 dt .
Proof. Let us set ˜µ(S) = µ(−S) for S ⊂R. Then we easily observe ˆ˜µ(t) = ˆµ(t)
and hence

µ ∗˜µ(t) = ˆµ(t)ˆ˜µ(t) = |ˆµ(t)|2.
On the other hand, we note
µ ∗˜µ({0}) =
 ∞
−∞
˜µ({−t}) dµ(t) =
 ∞
−∞
µ({t}) dµ(t) =

t∈R
|µ({t})|2 .
Hence, Proposition A.7 applied to µ ∗˜µ gives the result.
⊓⊔
A.5 Reﬂexivity and separability of operator ideals
Here the reﬂexivity and separability of symmetrically normed ideals are dis-
cussed, and we need the following general facts on Banach spaces:
(i)
The uniform convexity implies the reﬂexivity ([74, Chapter V, Problem
15]).
(ii) A Banach space X is reﬂexive if and only if so is the dual X∗([25,
Corollary II.3.24]).
(iii) If X∗is separable, then so is X ([74, Theorem III.7]).
Proposition A.10. Let |||·||| be a unitarily invariant norm. If either I|||·||| or
I(0)
|||·||| is reﬂexive, then I|||·||| is separable, i.e., I|||·||| = I(0)
|||·||| (see [29, §III.6]).
Proof. We assume that I|||·||| is reﬂexive, and let ||| · |||′ be the conjugate
norm of ||| · |||. Then, the general duality I|||·||| =

I(0)
|||·|||′
∗
and (ii) yield the
reﬂexivity of I(0)
|||·|||′ so that we have

I|||·|||
∗=

I(0)
|||·|||′
∗∗
= I(0)
|||·|||′.

138
A Appendices
Hence

I|||·|||
∗is separable and so is I|||·||| by (iii).
Next, we assume that I(0)
|||·||| is reﬂexive. Since the dual space I|||·|||′ =

I(0)
|||·|||
∗
is reﬂexive by (ii), the ﬁrst half of the proof (applied to ||| · |||′)
guarantees that I|||·|||′ = I(0)
|||·|||′ so that we observe
I|||·||| =

I(0)
|||·|||′
∗
=

I|||·|||′∗=

I(0)
|||·|||
∗∗
= I(0)
|||·|||,
showing the separability of I|||·|||.
⊓⊔
Corollary A.11. If one of I|||·|||, I(0)
|||·|||, I|||·|||′ and I(0)
|||·|||′ is reﬂexive, then
all of them are reﬂexive and we have the separability I|||·||| = I(0)
|||·|||, I|||·|||′ =
I(0)
|||·|||′. We also get the same conclusion when one of I|||·|||, I(0)
|||·|||, I|||·|||′ and
I(0)
|||·|||′ is uniformly convex.
Proof. The proof of Proposition A.10 actually shows









the reﬂexivity of I|||·||| ⇒the reﬂexivity of I(0)
|||·|||′
and the separability of I|||·|||,
the reﬂexivity of I(0)
|||·||| ⇒the reﬂexivity of I|||·|||′
and the separability of I|||·|||.
Application of these to |||·||| and |||·|||′ easily shows the ﬁrst statement while
the second statement follows from the ﬁrst and (i).
⊓⊔
A.6 Fourier transform of 1/cosh
 (t)
The Fourier transform of 1/ coshα(t) for α > 0 can be found in standard tables
of Fourier transforms (see [65, p. 33] for instance). However, the authors are
unable to ﬁnd details in the literature so that computations are given here.
Since the function in question is even, we note
I =
	 ∞
−∞
1
coshα(t) eistdt =
	 ∞
−∞
cos(st)
coshα(t) dt = 2α
	 ∞
−∞
cos(st)
(et + e−t)α dt.
The change of variables t = 1
2 log

x
1−x

(hence
x
1−x = e2t and dt =
dx
2x(1−x))
gives us
I = 2α−1
	 1
0
cos
 s
2 log

x
1−x


x
1−x +

1−x
x
α ×
dx
x(1 −x)
= 2α−1
	 1
0
(x(1 −x))
α
2 × cos
 s
2 log

x
1−x

×
dx
x(1 −x)
= 2α−1
	 1
0
x
α
2 −1(1 −x)
α
2 −1 cos
 s
2 log

x
1−x

dx.

A.6 Fourier transform of 1/coshα(t)
139
Notice







cos
 s
2 log

x
1−x

= cos
 s
2 log x

cos
 s
2 log(1 −x)

+ sin
 s
2 log x

sin
 s
2 log(1 −x)

,
xz = xRe z cos(Im z log x) + ixRe z sin(Im z log x)
(for x > 0).
Based on these we easily observe
x
α
2 −1(1 −x)
α
2 −1 cos
 s
2 log

x
1−x

= Re

x
α
2 −1+ is
2 (1 −x)
α
2 −1−is
2 
,
and consequently
I = 2α−1Re
 1
0
x
α
2 −1+ is
2 (1 −x)
α
2 −1−is
2 dx
	
.
The integral here is
B
α
2 + is
2 , α
2 −is
2
	
= Γ
 α
2 + is
2

Γ
 α
2 −is
2

Γ(α)
in terms of the B-function (and the Γ-function), showing
I = 2α−1
Γ(α) × Re

Γ
α
2 + is
2
	
Γ
α
2 −is
2
		
.
Note Γ(¯z) = Γ(z) by the Schwarz reﬂection principle so that the above for-
mula actually means
 ∞
−∞
1
coshα(t) eistdt = 2α−1
Γ(α) ×




Γ
α
2 + is
2
	



2
,
or equivalently,
 ∞
−∞
1
cosh1/α(αt)
eistdt = 2
1
α −1
αΓ
 1
α
 ×




Γ
1 + is
2α
	



2
.
(A.10)

References
1. T. Ando, Majorizations, doubly stochastic matrices, and comparison of eigen-
values, Linear Algebra Appl., 118 (1989), 163–248.
2. T. Ando, Majorizations and inequalities in matrix theory, Linear Algebra Appl.,
199 (1994), 17–67.
3. T. Ando, Matrix Young inequalities, Oper. Theory Adv. Appl., 75 (1995), 33–38.
4. T. Ando, R. A. Horn and C. R. Johnson, The singular values of a Hadamard
product: a basic inequality, Linear and Multilinear Algebra, 21 (1987), 345–365.
5. T. Ando and K. Okubo, Induced norms of the Schur multiplier operator, Linear
Algebra Appl., 147 (1991), 181–199.
6. J. Bergh and J. L¨ofstr¨om, Interpolation Spaces, An Introduction, Springer-
Verlag, Berlin-New York, 1976.
7. R. Bhatia, A simple proof of an operator inequality of Joci´c and Kittaneh, J.
Operator Theory, 31 (1994), 21–22.
8. R. Bhatia, Matrix Analysis, Springer-Verlag, New York, 1996.
9. R. Bhatia, On the exponential metric increasing property, preprint (2002).
10. R. Bhatia and C. Davis, More matrix forms of the arithmetic geometric mean
inequality, SIAM J. Matrix Anal. Appl., 14 (1993), 132–136.
11. R. Bhatia and C. Davis, A Cauchy-Schwarz inequality for operators with appli-
cation, Linear Algebra Appl., 223/224 (1995), 119–129.
12. R. Bhatia and F. Kittaneh, On the singular values of a product of operators,
SIAM J. Matrix Anal. Appl., 11 (1990), 272–277.
13. R. Bhatia and K. R. Parthasarathy, Positive deﬁnite functions and operator
inequalities, Bull. London Math. Soc., 32 (2000), 214–228.
14. M. Sh. Birman and M. Z. Solomyak, Stieltjes double operator integrals, Dokl.
Akad. Nauk SSSR, 165 (1965), 1223-1226 (Russian); Soviet Math. Dokl., 6
(1965), 1567–1571.
15. M. Sh. Birman and M. Z. Solomyak, Stieltjes double-integral operators, Topics
in Mathematical Physics, Vol. 1, M. Sh. Birman (ed.), Consultants Bureau, New
York, 1967, pp. 25–54.
16. M. Sh. Birman and M. Z. Solomyak, Stieltjes double-integral operators. II, Topics
in Mathematical Physics, Vol. 2, M. Sh. Birman (ed.), Consultants Bureau, New
York, 1968, pp. 19–46.
17. M. Sh. Birman and M. Z. Solomyak, Spectral Theory of Self-Adjoint Operators
in Hilbert Space, D. Reidel Publishing Company, Dordrecht, 1986.
F. Hiai and H. Kosaki: LNM 1820, pp. 141–144, 2003.
c⃝Springer-Verlag Berlin Heidelberg 2003

142
References
18. V. I. Chilin, A. Krygin and F. A. Sukochev, Uniform convexity and local uniform
convexity of symmetric spaces of measurable operators, Dokl. Akad. Nauk SSSR,
317 (1991), 555–558 (Russian); Soviet Math. Dokl., 43 (1991), 445–448.
19. G. Corach. H. Porta, and L. Recht, An operator inequality, Linear Algebra Appl.,
142 (1990), 153–158.
20. G. Corach. H. Porta, and L. Recht, A geometric interpretation of Segal’s inequal-
ity ∥eX+Y ∥≤∥eX/2eY eX/2∥, Proc. Amer. Math. Soc., 115 (1992), 229–231.
21. C. C. Cowen, K. E. Debro and P. D. Sepanski, Geometry and the norms of
Hadamard multipliers, Linear Algebra Appl., 218 (1995), 239–249.
22. A. Van Daele, A new approach to the Tomita-Takesaki theory of generalized
Hilbert algebras, J. Funct. Anal., 15 (1974), 378–393.
23. A. Van Daele and M. Rieﬀel, A bounded operator approach to Tomita-Takesaki
theory, Paciﬁc J. Math., 69 (1977), 187-221.
24. E. B. Davies, Lipschitz continuity of functions of operators in the Schatten
classes, J. London Math. Soc. (2), 37 (1988), 148–157.
25. N. Dunford and J. Schwartz, Linear Operators Part I: General Theory, Wiley-
Interscience, New York, 1988.
26. T. Fack and H. Kosaki, Generalized s-numbers of τ-measurable operators, Paciﬁc
J. Math., 123 (1986), 269–300.
27. Yu. B. Farforovskaya, An estimate of the norm ∥f(A) −f(B)∥for self-adjoint
operators A and B, Zap. Nauch. Sem. LOMI, 56 (1976), 143–162.
28. J. Fujii, M. Fujii, T. Furuta and R. Nakamoto, Norm inequalities equivalent to
Heinz inequality, Proc. Amer. Math. Soc., 118 (1993), 827–830.
29. I. C. Gohberg and M. G. Krein, Introduction to the Theory of Linear Non-
selfadjoint Operators, Translations of Mathematical Monographs, Vol. 18, Amer.
Math. Soc., Providence, 1969.
30. I. C. Gohberg and M. G. Krein, Theory and Applications of Volterra Operators
in Hilbert Spaces, Translations of Mathematical Monographs, Vol. 24, Amer.
Math. Soc., Providence, 1970.
31. U. Haagerup, On Schur multipliers in C1, unpublished hand-written notes
(1980).
32. U. Haagerup, Decomposition of completely bounded maps on operator algebras,
unpublished hand-written notes (1980).
33. F. Hansen and G. K. Pedersen, Perturbation formulas for traces on C∗-algebras,
Publ. Res. Inst. Math. Sci., 31 (1995), 169–178.
34. G. Hardy, J. E. Littlewood and G. P´olya, Inequalities (Second edition), Cam-
bridge Univ. Press, 1952.
35. M. Hasumi, The extension property of complex Banach spaces, Tˆohoku Math.
J., 10 (1958), 135–142.
36. E. Heinz, Beitr¨age zur St¨orungstheorie der Spektralzerlegung, Math. Ann., 123
(1951), 415–438.
37. F. Hiai, Log-majorizations and norm inequalities for exponential operators, Lin-
ear Operators, Banach Center Publications, Vol. 38, Polish Academy of Sciences,
Warszawa, 1997, pp. 119–181.
38. F. Hiai and H. Kosaki, Comparison of various means for operators, J. Funct.
Anal., 163 (1999), 300–323.
39. F. Hiai and H. Kosaki, Means for matrices and comparison of their norms,
Indiana Univ. Math. J., 48 (1999), 899–936.
40. F. Hiai and H. Kosaki, Operator means and their norms, in “Operator Algebras
and Applications” to appear in ASPM.

References
143
41. R. A. Horn, Norm bounds for Hadamard products and the arithmetic-geometric
mean inequality for unitarily invariant norms, Linear Algebra Appl., 223/224
(1995), 355–361.
42. R. A. Horn and C. R. Johnson, Topics in Matrix Analysis, Cambridge Univ.
Press, 1990.
43. R. A. Horn and X. Zhan, Inequalities for C-S seminorms and Lieb functions,
Linear Algebra Appl., 291 (1999), 103-113.
44. T. Itoh and M. Nagisa, Numerical radius norm for bounded module maps and
Schur multipliers, preprint (2002).
45. D. J. Joci´c, Norm inequalities for self-adjoint derivations, J. Funct. Anal., 145
(1997), 24–34.
46. D. J. Joci´c and F. Kittaneh, Some perturbation inequalities for self-adjoint op-
erators, J. Operator Theory, 171 (1994), 3–10.
47. L. V. Kantorovich and G. P. Akilov, Functional Analysis (Second edition), Perg-
amon Press, Oxford, 1982.
48. T. Kato, Perturbation Theory for Linear Operators (Second edition), Springer-
Verlag, Berlin-New York, 1976.
49. Y. Katznelson, An Introduction to Harmonic Analysis (Second corrected edi-
tion), Dover, New York, 1976.
50. F. Kittaneh, A note on the arithmetic-geometric mean inequality for matrices,
Linear Algebra Appl., 171 (1992), 1–8.
51. F. Kittaneh, On some operator inequalities, Linear Algebra Appl., 208/209
(1994), 19–28.
52. L. S. Koplienko, On the theory of the spectral shift function, Topics in Mathe-
matical Physics, Vol. 5, M. Sh. Birman (ed.), Consultants Bureau, New York,
1972, pp. 51–59.
53. H. Kosaki, Unitarily invariant norms under which the map A →|A| is Lipschitz
continuous, Publ. Res. Inst. Math. Sci., 28 (1992), 299–313.
54. H. Kosaki, Arithmetic-geometric mean and related inequalities for operators, J.
Funct. Anal., 156 (1998), 429–451.
55. H. Kosaki, in preparation.
56. S. G. Krein, Ju. I. Petunin, and E. M. Semenov, Interpolation of Linear Op-
erators, Translations of Mathematical Monographs Vol. 54, Amer. Math. Soc.,
Providence, 1982.
57. F. Kubo and T. Ando, Means of positive linear operators, Math. Ann. 246
(1980), 205–224.
58. S. T. Kuroda, On a theorem of Weyl-von Neumann, Proc. Japan Acad., 34
(1958), 11–15.
59. S. Kwapie´n and A. Pelczy´nski, The main triangular projection in matrix spaces
and its applications, Studia Math., 34 (1970), 43–68.
60. S. Lang, Fundamentals of Diﬀerential Geometry, Springer-Verlag, 1999.
61. J. Lindenstrauss and A. Pelczy´nski, Absolutely summing operators in Lp-spaces
and their applications, Studia Math., 29 (1968), 275–326.
62. A. W. Marshall and I. Olkin, Inequalities: Theory of Majorization and Its Ap-
plications, Academic Press, New York, 1979.
63. R. Mathias, An Arithmetic-Geometric-Harmonic mean inequality involving
Hadamard products, Linear Algebra Appl., 184 (1993), 71–78.
64. A. McIntosh, Heinz inequalities and perturbation of spectral families, Macquarie
Mathematical Reports, 79-0006, 1979.

144
References
65. F. Oberhettinger, Tables of Fourier Transforms and Fourier Transforms of Dis-
tributions, Springer-Verlag, Berlin, 1990.
66. V. Paulsen, Completely Bounded Maps and Dilations, Pitman Res. Notes in
Math. Ser., Vol. 146, Longmann, Harlow, 1986.
67. G. K. Pedersen, On the operator equation HT + T H = K, Indiana Univ. Math.
J., 25 (1976), 1029–1033.
68. G. K. Pedersen, Operator diﬀerentiable functions, Publ. Res. Inst. Math. Sci.,
36 (2000), 139–157.
69. V. V. Peller, Hankel operators and diﬀerentiability properties of functions of self-
adjoint (unitary) operators, LOMI Preprints E-1-84, USSR Academy of Sciences
Steklov Mathematical Institute Leningrad Department, 1984.
70. V. V. Peller, Hankel operators in the perturbation theory of unitary and self-
adjoint operators, Funct. Anal. Appl., 19 (1985), 111–123.
71. V. V. Peller, Hankel Operators and Their Applications, Springer-Verlag, New
York-Berlin-Heidelberg, 2003.
72. A. Pietsch, Operator Ideals, North-Holland, Amsterdam-New York-Oxford,
1980.
73. W. Pusz and S. L. Woronowicz, Functional calculus for sesquilinear forms and
the puriﬁcation map, Rep. Math. Phys., 8 (1975), 159–170.
74. M. Reed and B. Simon, Methods of Modern Mathematical Physics I: Functional
Analysis, Academic Press, New York, 1980.
75. H. L. Royden, Real Analysis (Second edition), Macmillan, New York, 1968.
76. H. H. Schaefer, Banach Lattices and Positive Operators, Springer-Verlag, Berlin-
Heidelberg-New York, 1974
77. B. Simon, Trace Ideals and Their Applications, Cambridge Univ. Press, Cam-
bridge, 1979.
78. M. Singh, J. S. Aujla, and H. L. Vesudeva, Inequalities for Hadamard product
and unitarily invariant norms of matrices, Linear and Multilinear Algebra, 48
(2001), 247-262.
79. F. Smithies, Integral Equations, Cambridge Univ. Press, Cambridge, 1958.
80. F. C. Titchmarsh, The Theory of Functions (Second edition), Oxford Univ.
Press, London, 1939.
81. F. G. Tricomi, Integral Equations, Interscience Publ., New York, 1957.
82. K. Yosida, Lectures on Diﬀerential and Integral Equations, Interscience Publ.,
New York, 1960.
83. X. Zhan, Inequalities for unitarily invariant norms, SIAM J. Matrix Anal. Appl.,
20 (1998), 466-470.
84. X. Zhan, Matrix Inequalities, Lecture Notes in Math., Vol. 1790, Springer-
Verlag, 2002.

Index
(·, ·)C2(H), 7
(HsH)ix, 27
¯Φ(·), 21
◦, 1, 41, 125
ℓ2, 41
ϕ[1], 31
Γ-function, 102, 139
ˆν (Fourier transform), 34
C(H), 61
C1(H), 7, 8, 10, 77
C1(L2(λ), L2(µ)), 15
C2(H), 1, 7, 8, 58
Cp, 8
Cp(H), 7, 31, 49, 78
H, 1, 7
I|||·|||, 23
I(0)
|||·|||, 23
Iﬁn, 23, 40
Mhar (harmonic mean), 34, 66
 , 33, 53
µn, 3, 24, 127, 128
Φ(·), 8
φ(s, t), 8
πℓ, 8
πr, 8
σ(B(H), C1(H)), 21
σ
 I|||·|||, I(0)
|||·|||′

, 61
˜Φ(·), 18
˜φ(t, s), 18
˜Φt(·), 19
˜H, 30, 45
˜
X, 30, 45
Tr, 7, 15, 18, 61

 , 123
ξ ⊗ηc, 9
A-measurable, 13
1(L1(λ), L∞(µ)), 13
A(n), 6, 105
B(m), 6, 105
Lip α, 31
| · |, 3, 7, 69, 125
|| · ||, 3, 7
|| · ||(|||·|||, |||·|||), 23, 38
|| · ||(∞,∞), 21, 23, 41
|| · ||(1,1), 21, 23, 41
|| · ||1, 10
|| · ||2, 8, 57
|| · ||p, 7, 49, 61, 69
||| · |||, 3, 23
||| · |||′, 61, 131
||| · |||(n), 24
2 × 2-matrix trick, 30, 45, 70
A (arithmetic mean), 34, 66
A-L-G interpolation mean, 6, 65
Aα, 5, 79
an(s, t), 106
B-function, 139
B(H), 1, 7, 8
Bα, 5, 89
bm(s, t), 106
EB (conditional expectation), 13
G (geometric mean), 34, 66
K-functional, 24
KG, 14
L (logarithmic mean), 34, 66
L∞(µ)∗∗, 17

146
Index
Lp(A, λ), 13
M(H, K)X, 1, 2, 35
M(s, t), 1, 33
M ⪯N, 5, 33, 123
M (−)(s, t), 48, 53
M−∞, 34, 49, 135
Mα, 5, 65
M∞, 5, 34, 36, 49, 91, 135
M
m
m+1 (H, K)X, 6, 66, 78
M
n
n−1 (H, K)X, 6, 66, 78
Mn(C), 1, 41
SA, 41
sH (support projection), 24, 57
X∗, 137
trace, 13
absolute convergence, 90, 132
alternating sum of operators, 6, 105
Ando, 3, 86
Ando and Okubo, 55
Ando, Horn and Johnson, 55
anti-symmetric tensor product, 127
arithmetic mean, 6, 34, 49, 66, 79, 89,
113
arithmetic-geometric mean inequality,
3, 4, 53
arithmetic-logarithmic-geometric mean
inequality, 4, 55, 65
Banach space, 7, 13, 78, 137
Bhatia, 55
Bhatia and Davis, 3, 53, 87
Bhatia and Kittaneh, 86
Bhatia and Parthasarathy, 4, 54
bilinear form, 61, 131
binomial expansion, 5, 92, 97
binomial mean, 6, 89
Birman and Solomyak, 2, 22, 31, 32
Bochner theorem, 5, 34, 107
Cauchy-Schwarz inequality, 9, 10, 25
central decomposition, 22
Ces`aro limit, 136
closed graph theorem, 16
compact operator, 23, 49, 61
compact operator (on a Banach space),
13
complemented subspace, 17
complex measure, 37, 136, 137
concave, 103
conjugate norm, 61, 131
convolution, 39, 74
Corach, Porta and Recht, 54
Davies, 32
diagonal operator, 1, 70
diﬀerential equation, 132
Dini’s theorem, 131
direct integral, 22
directed set, 18
divided diﬀerence, 31
dominated convergence theorem, 74, 75,
92
double integral transformation, 2, 8, 35
duality, 2, 8, 18, 61, 131, 137
eigenvalue, 3, 55, 131, 132
eigenvector, 131
factorization, 14
Farforovskaya, 32
Fatou’s lemma, 99
ﬁnite-rank (Banach space) operator, 13
ﬁnite-rank operator, 10, 23
ﬁnite-rank projection, 45, 70
ﬁniteness condition, 5, 69, 77, 93
Finsler metric, 54
Fourier inversion formula, 71
Fourier transform, 27, 34, 70, 136
Fourier transform formula, 35, 39, 68,
82, 86, 92, 139
Fubini theorem, 19, 25, 29, 136
Fubini-Tonneli theorem, 10
geometric mean, 6, 34, 45, 53, 66, 89,
91, 101, 135
Golden-Thompson-type norm inequal-
ity, 55
Grothendieck constant, 14
Grothendieck theorem, 14
H¨older continuous, 31
H¨older inequality, 49
H¨older-type norm inequality, 87
Haagerup, 2, 55
Haagerup’s criterion, 41, 47
Hadamard product, 1, 41
Hahn decomposition, 110
harmonic mean, 34, 66

Index
147
Hasumi, 17
Heinz inequality, 3, 79, 85, 113, 126
Heinz inequality (diﬀerence version),
111
Heinz-type mean, 6, 79, 114
Hilbert space, 7
Hilbert-Schmidt class operator, 1, 7, 8
Hilbert-Schmidt norm, 112, 118
Horn, 54
inner product, 7, 19
integral expression, 5, 21, 27, 29, 30, 37,
39, 40, 80, 81, 82, 100, 101, 102,
103, 108, 124
integral operator, 131
interpolation norm, 69, 83
involution, 23
Itoh and Nagisa, 55
Joci´c, 54
Joci´c and Kittaneh, 54
kernel, 49
Kittaneh, 54
Koplienko, 54
Krein, 32
Kubo and Ando, 53
Ky Fan norm, 24
Lebesgue dominated convergence
theorem, 29, 58, 62, 63, 71, 72, 77,
81, 83, 85, 97, 99, 100, 101, 103,
129
Lipschitz condition, 8
Lipschitz continuous, 69
logarithmic mean, 6, 34, 57, 66, 78, 82,
116
lower semi-continuous, 11, 45, 77, 129
majorization theory, 55
Mathias, 54
matrix Young inequality, 3, 86
McIntosh, 3, 85
measurable partition, 13
Mercer’s theorem, 131
monotone convergence theorem, 129
non-singular positive operator, 5, 39,
49, 50, 51, 58, 61
non-symmetric mean, 123
norm-one projection, 17
numerical radius norm, 55
one-integral operator, 13
operator equation, 53
operator ideal, 8
operator ideal (on a Banach space), 13
operator mean, 53
operator monotone function, 53
operator norm, 2, 61, 62, 76, 103, 120
operator Riemann sum, 81, 82, 83
orthogonal complement, 27
orthonormal basis, 7, 19, 41, 43, 44, 46
partition, 130
Pedersen, 53
Peller, 2, 8, 32
Pietsch, 13
Poisson integral formula, 86
polar decomposition, 10
pole, 103
positive deﬁnite function, 5, 33, 67, 68,
75, 82, 94, 95, 101, 102, 126
positive deﬁnite kernel, 45, 131
positive operator, 3, 7
positive part, 3
positive semi-deﬁnite, 34, 42, 45
projection map, 17
Pusz and Woronowicz, 53
radius of convergence, 90
Radon-Nikodym derivative, 11, 28
range, 49
rank-one operator, 9, 20, 28, 40
reﬁnement, 18
reﬂexive operator ideal, 137, 138
residue, 103
Riemann-Stieltjes sum, 31
Schatten p-norm, 7, 61, 69
Schatten class, Schatten p-class, 7, 49,
78
Schur multiplication operator, 41
Schur multiplier, 2, 8, 36, 41
Schur product, 1, 41
Schur theorem, 45
Schwarz reﬂection principle, 139
Segal inequality, 54
separable, 7

148
Index
separable operator ideal, 23, 77, 131,
137, 138
signed measure, 27, 32, 94, 107, 108,
127
singular number, singular value, 3, 24,
55, 127
Sobolev type, 31
spectral decomposition, 2, 7, 131
spectral measure, 7, 59
spectral shift function, 32
Stirling formula, 98
support projection, 24
symmetric homogeneous mean, 4, 33
symmetric probability measure, 34, 36,
39
symmetrically normed ideal, 23
Taylor series expansion, 94
total variation, 94, 127
trace (for a Banach space operator), 13
trace (for a Hilbert space operator), 7,
15, 18
trace class operator, 7, 8, 77
trace norm, 2, 120
transpose, 8, 19
uniform integrability, 96, 99
uniformly convex operator ideal, 77, 78,
138
unitarily invariant norm, 3, 7, 23, 38,
48, 57, 63, 66, 69, 70, 77, 79, 80,
82, 93, 95, 96, 105, 127, 128, 137
upper triangular projection, 69
Vitali convergence theorem, 96
von Neumann algebra, 22
w*-compact, 18
w*-w*-continuity, 21, 61
weak matrix Young inequality, 3, 80, 86
weakly measurable operator-valued
function, 127
Weyl inequality, 127
Zhan, 54

